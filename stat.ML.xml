<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36890;&#36807;&#24341;&#20837;&#24322;&#26500;&#29305;&#24449;&#38598;&#25104;&#65292;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#24615;&#22238;&#24402;&#35774;&#32622;&#20013;&#26500;&#24314;&#30340;&#23725;&#22238;&#24402;&#38598;&#25104;&#30340;&#23398;&#20064;&#26354;&#32447;&#65292;&#32467;&#26524;&#34920;&#26126;&#24322;&#26500;&#29305;&#24449;&#38598;&#25104;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.03176</link><description>&lt;p&gt;
&#24322;&#26500;&#29305;&#24449;&#23376;&#37319;&#26679;&#30340;Ridge Ensemble&#30340;&#23398;&#20064;&#26354;&#32447;
&lt;/p&gt;
&lt;p&gt;
Learning Curves for Heterogeneous Feature-Subsampled Ridge Ensembles. (arXiv:2307.03176v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03176
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#24322;&#26500;&#29305;&#24449;&#38598;&#25104;&#65292;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#24615;&#22238;&#24402;&#35774;&#32622;&#20013;&#26500;&#24314;&#30340;&#23725;&#22238;&#24402;&#38598;&#25104;&#30340;&#23398;&#20064;&#26354;&#32447;&#65292;&#32467;&#26524;&#34920;&#26126;&#24322;&#26500;&#29305;&#24449;&#38598;&#25104;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29305;&#24449;&#21253;&#35013;&#26159;&#19968;&#31181;&#26088;&#22312;&#36890;&#36807;&#22312;&#38543;&#26426;&#23376;&#26679;&#26412;&#25110;&#29305;&#24449;&#25237;&#24433;&#19978;&#35757;&#32451;&#20272;&#35745;&#22120;&#26469;&#20943;&#23569;&#39044;&#27979;&#26041;&#24046;&#30340;&#25104;&#29087;&#38598;&#25104;&#26041;&#27861;&#12290;&#36890;&#24120;&#65292;&#38598;&#25104;&#36873;&#25321;&#26159;&#21516;&#36136;&#30340;&#65292;&#21363;&#20272;&#35745;&#22120;&#21487;&#29992;&#30340;&#29305;&#24449;&#32500;&#25968;&#22312;&#25972;&#20010;&#38598;&#25104;&#20013;&#26159;&#22343;&#21248;&#30340;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#24322;&#26500;&#29305;&#24449;&#38598;&#25104;&#26041;&#27861;&#65292;&#20854;&#20013;&#30340;&#20272;&#35745;&#22120;&#22522;&#20110;&#21464;&#21160;&#30340;&#29305;&#24449;&#32500;&#25968;&#65292;&#24182;&#30740;&#31350;&#20854;&#22312;&#32447;&#24615;&#22238;&#24402;&#35774;&#32622;&#20013;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#32447;&#24615;&#39044;&#27979;&#22120;&#30340;&#38598;&#25104;&#65292;&#27599;&#20010;&#39044;&#27979;&#22120;&#20351;&#29992;&#37096;&#20998;&#21487;&#29992;&#29305;&#24449;&#36827;&#34892;&#23725;&#22238;&#24402;&#25311;&#21512;&#12290;&#25105;&#20204;&#20801;&#35768;&#36825;&#20123;&#23376;&#38598;&#20013;&#21253;&#21547;&#30340;&#29305;&#24449;&#25968;&#37327;&#26377;&#25152;&#21464;&#21270;&#12290;&#21033;&#29992;&#32479;&#35745;&#29289;&#29702;&#20013;&#30340;&#22797;&#21046;&#25216;&#24039;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#20855;&#26377;&#30830;&#23450;&#24615;&#32447;&#24615;&#25513;&#27169;&#30340;&#23725;&#22238;&#24402;&#38598;&#25104;&#30340;&#23398;&#20064;&#26354;&#32447;&#12290;&#23545;&#20110;&#20855;&#26377;&#21508;&#21521;&#21516;&#24615;&#29305;&#24449;&#22122;&#22768;&#30340;&#31561;&#30456;&#30456;&#20851;&#25968;&#25454;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#23398;&#20064;&#26354;&#32447;&#30340;&#26174;&#24335;&#34920;&#36798;&#24335;&#12290;&#21033;&#29992;&#36825;&#20123;&#25512;&#23548;&#34920;&#36798;&#24335;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#38598;&#25104;&#22312;&#19981;&#21516;&#29305;&#24449;&#32500;&#25968;&#19979;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Feature bagging is a well-established ensembling method which aims to reduce prediction variance by training estimators in an ensemble on random subsamples or projections of features. Typically, ensembles are chosen to be homogeneous, in the sense the the number of feature dimensions available to an estimator is uniform across the ensemble. Here, we introduce heterogeneous feature ensembling, with estimators built on varying number of feature dimensions, and consider its performance in a linear regression setting. We study an ensemble of linear predictors, each fit using ridge regression on a subset of the available features. We allow the number of features included in these subsets to vary. Using the replica trick from statistical physics, we derive learning curves for ridge ensembles with deterministic linear masks. We obtain explicit expressions for the learning curves in the case of equicorrelated data with an isotropic feature noise. Using the derived expressions, we investigate t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#20351;&#29992;&#20102;&#23545;&#31216;&#38181;&#20056;&#27861;&#26435;&#37325;&#26356;&#26032;&#31639;&#27861;(SCMWU)&#65292;&#35813;&#31639;&#27861;&#22312;&#20219;&#24847;&#23545;&#31216;&#38181;&#30340;&#36857;&#20026;&#19968;&#22788;&#36827;&#34892;&#22312;&#32447;&#20248;&#21270;&#65292;&#24182;&#19988;&#22312;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#26159;&#26080;&#24724;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.03136</link><description>&lt;p&gt;
&#22312;&#23545;&#31216;&#38181;&#19978;&#36827;&#34892;&#30340;&#22312;&#32447;&#20984;&#20248;&#21270;&#30340;&#20056;&#27861;&#26356;&#26032;
&lt;/p&gt;
&lt;p&gt;
Multiplicative Updates for Online Convex Optimization over Symmetric Cones. (arXiv:2307.03136v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03136
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#20351;&#29992;&#20102;&#23545;&#31216;&#38181;&#20056;&#27861;&#26435;&#37325;&#26356;&#26032;&#31639;&#27861;(SCMWU)&#65292;&#35813;&#31639;&#27861;&#22312;&#20219;&#24847;&#23545;&#31216;&#38181;&#30340;&#36857;&#20026;&#19968;&#22788;&#36827;&#34892;&#22312;&#32447;&#20248;&#21270;&#65292;&#24182;&#19988;&#22312;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#26159;&#26080;&#24724;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32447;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#20854;&#20013;&#21487;&#33021;&#30340;&#25805;&#20316;&#26159;&#23545;&#31216;&#38181;&#20013;&#30340;&#36857;&#20026;&#19968;&#30340;&#20803;&#32032;&#65292;&#36825;&#25193;&#23637;&#20102;&#24191;&#27867;&#30740;&#31350;&#30340;&#19987;&#23478;&#35774;&#32622;&#21450;&#20854;&#37327;&#23376;&#23545;&#24212;&#29289;&#12290;&#23545;&#31216;&#38181;&#20026;&#19968;&#20123;&#26368;&#37325;&#35201;&#30340;&#20248;&#21270;&#27169;&#22411;&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#21253;&#25324;&#32447;&#24615;&#12289;&#20108;&#38454;&#38181;&#21644;&#21322;&#23450;&#20248;&#21270;&#12290;&#20351;&#29992;&#27431;&#20960;&#37324;&#24503;&#32422;&#26086;&#20195;&#25968;&#39046;&#22495;&#30340;&#24037;&#20855;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#23545;&#31216;&#38181;&#20056;&#27861;&#26435;&#37325;&#26356;&#26032;(SCMWU)&#65292;&#36825;&#26159;&#19968;&#20010;&#22312;&#20219;&#24847;&#23545;&#31216;&#38181;&#30340;&#36857;&#20026;&#19968;&#22788;&#36827;&#34892;&#22312;&#32447;&#20248;&#21270;&#30340;&#26080;&#25237;&#24433;&#31639;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;SCMWU&#31561;&#20215;&#20110;Follow-the-Regularized-Leader&#21644;Online Mirror Descent&#65292;&#20854;&#27491;&#21017;&#21270;&#22120;&#20026;&#23545;&#31216;&#38181;&#36127;&#29109;&#12290;&#36890;&#36807;&#36825;&#20010;&#32467;&#26500;&#32467;&#26524;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;SCMWU&#26159;&#26080;&#24724;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#22823;&#37327;&#23454;&#39564;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study online convex optimization where the possible actions are trace-one elements in a symmetric cone, generalizing the extensively-studied experts setup and its quantum counterpart. Symmetric cones provide a unifying framework for some of the most important optimization models, including linear, second-order cone, and semidefinite optimization. Using tools from the field of Euclidean Jordan Algebras, we introduce the Symmetric-Cone Multiplicative Weights Update (SCMWU), a projection-free algorithm for online optimization over the trace-one slice of an arbitrary symmetric cone. We show that SCMWU is equivalent to Follow-the-Regularized-Leader and Online Mirror Descent with symmetric-cone negative entropy as regularizer. Using this structural result we show that SCMWU is a no-regret algorithm, and verify our theoretical results with extensive experiments. Our results unify and generalize the analysis for the Multiplicative Weights Update method over the probability simplex and the M
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#30830;&#23450;&#39640;&#26031;&#36807;&#31243;&#22312;&#23454;&#38469;&#38382;&#39064;&#20013;&#30340;&#36866;&#29992;&#24615;&#65292;&#24182;&#24314;&#31435;&#19968;&#20010;&#31283;&#20581;&#19988;&#26126;&#30830;&#30340;&#27169;&#22411;&#12290;&#36890;&#36807;&#23545;&#26680;&#20989;&#25968;&#35774;&#35745;&#21644;&#35745;&#31639;&#21487;&#25193;&#23637;&#24615;&#36873;&#39033;&#30340;&#25351;&#23548;&#65292;&#35813;&#26694;&#26550;&#22312;&#20912;&#24029;&#39640;&#31243;&#21464;&#21270;&#30340;&#26696;&#20363;&#30740;&#31350;&#20013;&#23454;&#29616;&#20102;&#26356;&#20934;&#30830;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2307.03093</link><description>&lt;p&gt;
&#36229;&#36234;&#30452;&#35273;&#65292;&#23558;&#39640;&#26031;&#36807;&#31243;&#24212;&#29992;&#20110;&#23454;&#38469;&#25968;&#25454;&#30340;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Beyond Intuition, a Framework for Applying GPs to Real-World Data. (arXiv:2307.03093v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03093
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#30830;&#23450;&#39640;&#26031;&#36807;&#31243;&#22312;&#23454;&#38469;&#38382;&#39064;&#20013;&#30340;&#36866;&#29992;&#24615;&#65292;&#24182;&#24314;&#31435;&#19968;&#20010;&#31283;&#20581;&#19988;&#26126;&#30830;&#30340;&#27169;&#22411;&#12290;&#36890;&#36807;&#23545;&#26680;&#20989;&#25968;&#35774;&#35745;&#21644;&#35745;&#31639;&#21487;&#25193;&#23637;&#24615;&#36873;&#39033;&#30340;&#25351;&#23548;&#65292;&#35813;&#26694;&#26550;&#22312;&#20912;&#24029;&#39640;&#31243;&#21464;&#21270;&#30340;&#26696;&#20363;&#30740;&#31350;&#20013;&#23454;&#29616;&#20102;&#26356;&#20934;&#30830;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#65288;GPs&#65289;&#25552;&#20379;&#20102;&#19968;&#31181;&#29992;&#20110;&#23567;&#22411;&#12289;&#32467;&#26500;&#21270;&#21644;&#30456;&#20851;&#25968;&#25454;&#38598;&#30340;&#22238;&#24402;&#30340;&#21560;&#24341;&#20154;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#24212;&#29992;&#21463;&#21040;&#35745;&#31639;&#25104;&#26412;&#30340;&#38480;&#21046;&#65292;&#24182;&#19988;&#23545;&#20110;&#22914;&#20309;&#23558;GPs&#24212;&#29992;&#20110;&#22797;&#26434;&#30340;&#39640;&#32500;&#25968;&#25454;&#38598;&#30340;&#25351;&#23548;&#26377;&#38480;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#30830;&#23450;GPs&#22312;&#32473;&#23450;&#38382;&#39064;&#20013;&#30340;&#36866;&#29992;&#24615;&#20197;&#21450;&#22914;&#20309;&#24314;&#31435;&#19968;&#20010;&#24378;&#22823;&#19988;&#26126;&#30830;&#30340;GP&#27169;&#22411;&#12290;&#25351;&#23548;&#26041;&#38024;&#24418;&#24335;&#21270;&#20102;&#32463;&#39564;&#20016;&#23500;&#30340;GP&#23454;&#36341;&#32773;&#30340;&#20915;&#31574;&#65292;&#29305;&#21035;&#24378;&#35843;&#20102;&#26680;&#20989;&#25968;&#35774;&#35745;&#21644;&#35745;&#31639;&#21487;&#25193;&#23637;&#24615;&#36873;&#39033;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#35813;&#26694;&#26550;&#24212;&#29992;&#20110;&#20912;&#24029;&#39640;&#31243;&#21464;&#21270;&#30340;&#26696;&#20363;&#30740;&#31350;&#20013;&#65292;&#22312;&#27979;&#35797;&#26102;&#20135;&#29983;&#20102;&#26356;&#20934;&#30830;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian Processes (GPs) offer an attractive method for regression over small, structured and correlated datasets. However, their deployment is hindered by computational costs and limited guidelines on how to apply GPs beyond simple low-dimensional datasets. We propose a framework to identify the suitability of GPs to a given problem and how to set up a robust and well-specified GP model. The guidelines formalise the decisions of experienced GP practitioners, with an emphasis on kernel design and options for computational scalability. The framework is then applied to a case study of glacier elevation change yielding more accurate results at test time.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#19968;&#33324;&#35266;&#27979;&#27169;&#22411;&#19979;&#30340;&#19981;&#23433;&#23450;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;PCL-&#21487;&#32034;&#24341;&#24615;&#21644;Whittle&#32034;&#24341;&#30340;&#20998;&#26512;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#36817;&#20284;&#36807;&#31243;&#23558;&#38382;&#39064;&#36716;&#21270;&#20026;&#26377;&#38480;&#29366;&#24577;&#38382;&#39064;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#31639;&#27861;&#34920;&#29616;&#20248;&#31168;&#12290;</title><link>http://arxiv.org/abs/2307.03034</link><description>&lt;p&gt;
&#24102;&#26377;&#19968;&#33324;&#35266;&#27979;&#27169;&#22411;&#30340;&#19981;&#23433;&#23450;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;PCL-&#21487;&#32034;&#24341;&#24615;&#21644;Whittle&#32034;&#24341;
&lt;/p&gt;
&lt;p&gt;
PCL-Indexability and Whittle Index for Restless Bandits with General Observation Models. (arXiv:2307.03034v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03034
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#19968;&#33324;&#35266;&#27979;&#27169;&#22411;&#19979;&#30340;&#19981;&#23433;&#23450;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;PCL-&#21487;&#32034;&#24341;&#24615;&#21644;Whittle&#32034;&#24341;&#30340;&#20998;&#26512;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#36817;&#20284;&#36807;&#31243;&#23558;&#38382;&#39064;&#36716;&#21270;&#20026;&#26377;&#38480;&#29366;&#24577;&#38382;&#39064;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#31639;&#27861;&#34920;&#29616;&#20248;&#31168;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#31181;&#19968;&#33324;&#35266;&#27979;&#27169;&#22411;&#65292;&#29992;&#20110;&#19981;&#23433;&#23450;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#12290;&#30001;&#20110;&#36164;&#28304;&#32422;&#26463;&#25110;&#29615;&#22659;&#25110;&#22266;&#26377;&#22122;&#22768;&#65292;&#29609;&#23478;&#25805;&#20316;&#38656;&#35201;&#22522;&#20110;&#26576;&#31181;&#26377;&#35823;&#24046;&#30340;&#21453;&#39304;&#26426;&#21046;&#12290;&#36890;&#36807;&#24314;&#31435;&#21453;&#39304;/&#35266;&#27979;&#21160;&#21147;&#23398;&#30340;&#19968;&#33324;&#27010;&#29575;&#27169;&#22411;&#65292;&#25105;&#20204;&#23558;&#38382;&#39064;&#34920;&#36848;&#20026;&#19968;&#20010;&#20174;&#20219;&#24847;&#21021;&#22987;&#20449;&#24565;&#65288;&#20808;&#39564;&#20449;&#24687;&#65289;&#24320;&#22987;&#30340;&#20855;&#26377;&#21487;&#25968;&#20449;&#24565;&#29366;&#24577;&#31354;&#38388;&#30340;&#19981;&#23433;&#23450;&#36172;&#21338;&#26426;&#38382;&#39064;&#12290;&#25105;&#20204;&#21033;&#29992;&#20855;&#26377;&#37096;&#20998;&#23432;&#24658;&#23450;&#24459;&#65288;PCL&#65289;&#30340;&#21487;&#23454;&#29616;&#21306;&#22495;&#26041;&#27861;&#65292;&#20998;&#26512;&#20102;&#26080;&#38480;&#29366;&#24577;&#38382;&#39064;&#30340;&#21487;&#32034;&#24341;&#24615;&#21644;&#20248;&#20808;&#32423;&#32034;&#24341;&#65288;Whittle&#32034;&#24341;&#65289;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36817;&#20284;&#36807;&#31243;&#65292;&#23558;&#38382;&#39064;&#36716;&#21270;&#20026;&#21487;&#20197;&#24212;&#29992;Ni&#241;o-Mora&#21644;Bertsimas&#38024;&#23545;&#26377;&#38480;&#29366;&#24577;&#38382;&#39064;&#30340;AG&#31639;&#27861;&#30340;&#38382;&#39064;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#20855;&#26377;&#20986;&#33394;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we consider a general observation model for restless multi-armed bandit problems. The operation of the player needs to be based on certain feedback mechanism that is error-prone due to resource constraints or environmental or intrinsic noises. By establishing a general probabilistic model for dynamics of feedback/observation, we formulate the problem as a restless bandit with a countable belief state space starting from an arbitrary initial belief (a priori information). We apply the achievable region method with partial conservation law (PCL) to the infinite-state problem and analyze its indexability and priority index (Whittle index). Finally, we propose an approximation process to transform the problem into which the AG algorithm of Ni\~no-Mora and Bertsimas for finite-state problems can be applied to. Numerical experiments show that our algorithm has an excellent performance.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35752;&#35770;&#20102;&#25345;&#32493;&#24615;&#21516;&#35843;&#31209;&#20989;&#25968;&#22312;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#25351;&#20986;&#31209;&#20989;&#25968;&#30456;&#23545;&#20110;&#26465;&#30721;&#30340;&#20248;&#21183;&#22312;&#20110;&#26356;&#26131;&#20110;&#35745;&#31639;&#65292;&#24182;&#19988;&#21487;&#20197;&#30452;&#25509;&#24212;&#29992;&#20989;&#25968;&#25968;&#25454;&#20998;&#26512;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#31209;&#20989;&#25968;&#30340;&#31283;&#23450;&#24615;&#38382;&#39064;&#23578;&#24453;&#35299;&#20915;&#12290;</title><link>http://arxiv.org/abs/2307.02904</link><description>&lt;p&gt;
&#21487;&#35745;&#31639;&#30340;&#31283;&#23450;&#24615;&#23545;&#20110;&#25345;&#32493;&#24615;&#31209;&#20989;&#25968;&#26426;&#22120;&#23398;&#20064;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Computable Stability for Persistence Rank Function Machine Learning. (arXiv:2307.02904v1 [math.AT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02904
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#25345;&#32493;&#24615;&#21516;&#35843;&#31209;&#20989;&#25968;&#22312;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#25351;&#20986;&#31209;&#20989;&#25968;&#30456;&#23545;&#20110;&#26465;&#30721;&#30340;&#20248;&#21183;&#22312;&#20110;&#26356;&#26131;&#20110;&#35745;&#31639;&#65292;&#24182;&#19988;&#21487;&#20197;&#30452;&#25509;&#24212;&#29992;&#20989;&#25968;&#25968;&#25454;&#20998;&#26512;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#31209;&#20989;&#25968;&#30340;&#31283;&#23450;&#24615;&#38382;&#39064;&#23578;&#24453;&#35299;&#20915;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25345;&#32493;&#24615;&#21516;&#35843;&#26465;&#30721;&#21644;&#22270;&#26159;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#30340;&#22522;&#30784;&#12290;&#23427;&#20204;&#22312;&#35768;&#22810;&#30495;&#23454;&#25968;&#25454;&#29615;&#22659;&#20013;&#24471;&#21040;&#24191;&#27867;&#24212;&#29992;&#65292;&#23558;&#25299;&#25169;&#20449;&#24687;&#30340;&#21464;&#21270;&#65288;&#36890;&#36807;&#32454;&#32990;&#21516;&#35843;&#27979;&#37327;&#65289;&#19982;&#25968;&#25454;&#30340;&#21464;&#21270;&#30456;&#20851;&#32852;&#65292;&#28982;&#32780;&#65292;&#30001;&#20110;&#20854;&#22797;&#26434;&#30340;&#20960;&#20309;&#32467;&#26500;&#65292;&#23427;&#20204;&#22312;&#32479;&#35745;&#29615;&#22659;&#20013;&#30340;&#20351;&#29992;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#20102;&#25345;&#32493;&#24615;&#21516;&#35843;&#31209;&#20989;&#25968;&#8212;&#8212;&#19968;&#31181;&#34913;&#37327;&#8220;&#24418;&#29366;&#8221;&#30340;&#19981;&#21464;&#37327;&#65292;&#23427;&#22312;&#26465;&#30721;&#21644;&#25345;&#32493;&#24615;&#22270;&#20043;&#21069;&#34987;&#24341;&#20837;&#65292;&#24182;&#20197;&#26356;&#36866;&#21512;&#25968;&#25454;&#21644;&#35745;&#31639;&#30340;&#24418;&#24335;&#25429;&#25417;&#30456;&#21516;&#30340;&#20449;&#24687;&#12290;&#23588;&#20854;&#26159;&#65292;&#30001;&#20110;&#23427;&#20204;&#26159;&#20989;&#25968;&#65292;&#24403;&#25345;&#32493;&#24615;&#21516;&#35843;&#20197;&#31209;&#20989;&#25968;&#24418;&#24335;&#34920;&#31034;&#26102;&#65292;&#21487;&#20197;&#30452;&#25509;&#24212;&#29992;&#20989;&#25968;&#25968;&#25454;&#20998;&#26512;&#39046;&#22495;&#30340;&#25216;&#26415;&#65292;&#36825;&#26159;&#19968;&#31181;&#36866;&#29992;&#20110;&#20989;&#25968;&#30340;&#32479;&#35745;&#23398;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#19982;&#26465;&#30721;&#30456;&#27604;&#65292;&#31209;&#20989;&#25968;&#30340;&#21463;&#27426;&#36814;&#31243;&#24230;&#36739;&#20302;&#65292;&#22240;&#20026;&#23427;&#20204;&#38754;&#20020;&#30528;&#31283;&#23450;&#24615;&#30340;&#25361;&#25112;&#8212;&#8212;&#36825;&#26159;&#39564;&#35777;&#23427;&#20204;&#22312;&#25968;&#25454;&#20998;&#26512;&#20013;&#20351;&#29992;&#30340;&#20851;&#38190;&#24615;&#36136;&#65292;&#32780;&#36825;&#31181;&#31283;&#23450;&#24615;&#24456;&#38590;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Persistent homology barcodes and diagrams are a cornerstone of topological data analysis. Widely used in many real data settings, they relate variation in topological information (as measured by cellular homology) with variation in data, however, they are challenging to use in statistical settings due to their complex geometric structure. In this paper, we revisit the persistent homology rank function -- an invariant measure of ``shape" that was introduced before barcodes and persistence diagrams and captures the same information in a form that is more amenable to data and computation. In particular, since they are functions, techniques from functional data analysis -- a domain of statistics adapted for functions -- apply directly to persistent homology when represented by rank functions. Rank functions, however, have been less popular than barcodes because they face the challenge that stability -- a property that is crucial to validate their use in data analysis -- is difficult to gua
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#37096;&#20998;&#21487;&#35266;&#23519;&#30340;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;POMDPs&#65289;&#20013;&#23398;&#20064;&#30340;&#26679;&#26412;&#39640;&#25928;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#22686;&#24378;&#30340;&#21453;&#39304;&#27169;&#22411;&#65292;&#21033;&#29992;&#20107;&#21518;&#22810;&#35266;&#23519;&#25968;&#25454;&#23454;&#29616;&#20102;&#23545;&#20004;&#31181;&#26032;&#30340;POMDP&#23376;&#31867;&#30340;&#26679;&#26412;&#39640;&#25928;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2307.02884</link><description>&lt;p&gt;
&#20351;&#29992;&#20107;&#21518;&#22810;&#35266;&#23519;&#25968;&#25454;&#30340;POMDP&#26679;&#26412;&#39640;&#25928;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Sample-Efficient Learning of POMDPs with Multiple Observations In Hindsight. (arXiv:2307.02884v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02884
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#37096;&#20998;&#21487;&#35266;&#23519;&#30340;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;POMDPs&#65289;&#20013;&#23398;&#20064;&#30340;&#26679;&#26412;&#39640;&#25928;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#22686;&#24378;&#30340;&#21453;&#39304;&#27169;&#22411;&#65292;&#21033;&#29992;&#20107;&#21518;&#22810;&#35266;&#23519;&#25968;&#25454;&#23454;&#29616;&#20102;&#23545;&#20004;&#31181;&#26032;&#30340;POMDP&#23376;&#31867;&#30340;&#26679;&#26412;&#39640;&#25928;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#37096;&#20998;&#21487;&#35266;&#23519;&#30340;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;POMDPs&#65289;&#20013;&#23398;&#20064;&#30340;&#26679;&#26412;&#39640;&#25928;&#24615;&#65292;&#36825;&#26159;&#24378;&#21270;&#23398;&#20064;&#20013;&#19968;&#20010;&#22312;&#26368;&#22351;&#24773;&#20917;&#19979;&#34987;&#35777;&#26126;&#26159;&#25351;&#25968;&#32423;&#22256;&#38590;&#30340;&#38382;&#39064;&#12290;&#21463;&#21040;&#29616;&#23454;&#19990;&#30028;&#20013;&#28216;&#25103;&#20013;&#30340;&#21152;&#36733;&#31561;&#24773;&#26223;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22686;&#24378;&#30340;&#21453;&#39304;&#27169;&#22411;&#65292;&#31216;&#20026;&#8220;&#20107;&#21518;&#22810;&#35266;&#23519;&#25968;&#25454;&#8221;&#65292;&#20854;&#20013;&#22312;&#19982;POMDP&#36827;&#34892;&#20132;&#20114;&#30340;&#27599;&#20010;&#21608;&#26399;&#20043;&#21518;&#65292;&#23398;&#20064;&#32773;&#21487;&#20197;&#25910;&#38598;&#21040;&#20174;&#36935;&#21040;&#30340;&#28508;&#22312;&#29366;&#24577;&#21457;&#20986;&#30340;&#22810;&#20010;&#38468;&#21152;&#35266;&#27979;&#25968;&#25454;&#65292;&#20294;&#19981;&#33021;&#30452;&#25509;&#35266;&#27979;&#21040;&#28508;&#22312;&#29366;&#24577;&#26412;&#36523;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#36825;&#20010;&#21453;&#39304;&#27169;&#22411;&#19979;&#65292;&#23545;&#20110;&#20004;&#31181;&#26032;&#30340;POMDP&#23376;&#31867;&#65288;&#22810;&#35266;&#27979;&#23637;&#31034;POMDP&#21644;&#21487;&#21306;&#20998;POMDP&#65289;&#65292;&#21487;&#20197;&#23454;&#29616;&#26679;&#26412;&#39640;&#25928;&#30340;&#23398;&#20064;&#12290;&#36825;&#20004;&#20010;&#23376;&#31867;&#30456;&#23545;&#20110;&#24191;&#27867;&#30740;&#31350;&#30340;&#23637;&#31034;POMDP&#23376;&#31867;&#26469;&#35828;&#26356;&#21152;&#26222;&#36941;&#21644;&#25918;&#26494;&#65292;&#32780;&#22312;&#26631;&#20934;&#36712;&#36857;&#21453;&#39304;&#19979;&#21487;&#20197;&#23454;&#29616;&#26679;&#26412;&#39640;&#25928;&#23398;&#20064;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#21487;&#21306;&#20998;POMDP&#21482;&#38656;&#20351;&#29992;&#26368;&#23569;&#30340;&#35266;&#27979;&#25968;&#25454;&#21644;&#21453;&#39304;&#36827;&#34892;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the sample-efficiency of learning in Partially Observable Markov Decision Processes (POMDPs), a challenging problem in reinforcement learning that is known to be exponentially hard in the worst-case. Motivated by real-world settings such as loading in game playing, we propose an enhanced feedback model called ``multiple observations in hindsight'', where after each episode of interaction with the POMDP, the learner may collect multiple additional observations emitted from the encountered latent states, but may not observe the latent states themselves. We show that sample-efficient learning under this feedback model is possible for two new subclasses of POMDPs: \emph{multi-observation revealing POMDPs} and \emph{distinguishable POMDPs}. Both subclasses generalize and substantially relax \emph{revealing POMDPs} -- a widely studied subclass for which sample-efficient learning is possible under standard trajectory feedback. Notably, distinguishable POMDPs only require th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#20855;&#26377;&#22810;&#23618;&#30340;&#36229;&#22270;&#946;&#27169;&#22411;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#25512;&#23548;&#20102;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#29575;&#21644;&#26497;&#38480;&#20998;&#24067;&#65292;&#24182;&#26500;&#24314;&#20102;&#27169;&#22411;&#21442;&#25968;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#24314;&#31435;&#20102;&#36229;&#22270;&#946;&#27169;&#22411;&#20013;&#20284;&#28982;&#27604;&#26816;&#39564;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.02818</link><description>&lt;p&gt;
&#39640;&#38454;&#32593;&#32476;&#20013;&#30340;&#24230;&#24322;&#36136;&#24615;&#65306;&#36229;&#22270;&#946;&#27169;&#22411;&#30340;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Degree Heterogeneity in Higher-Order Networks: Inference in the Hypergraph $\boldsymbol{\beta}$-Model. (arXiv:2307.02818v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02818
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#20855;&#26377;&#22810;&#23618;&#30340;&#36229;&#22270;&#946;&#27169;&#22411;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#25512;&#23548;&#20102;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#29575;&#21644;&#26497;&#38480;&#20998;&#24067;&#65292;&#24182;&#26500;&#24314;&#20102;&#27169;&#22411;&#21442;&#25968;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#24314;&#31435;&#20102;&#36229;&#22270;&#946;&#27169;&#22411;&#20013;&#20284;&#28982;&#27604;&#26816;&#39564;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#22270;&#20013;&#30340;&#946;&#27169;&#22411;&#36890;&#24120;&#29992;&#20110;&#34920;&#31034;&#20855;&#26377;&#24230;&#24322;&#36136;&#24615;&#30340;&#32593;&#32476;&#20013;&#30340;&#37197;&#23545;&#20132;&#20114;&#12290;&#36229;&#22270;&#946;&#27169;&#22411;&#36229;&#36234;&#20102;&#37197;&#23545;&#20132;&#20114;&#65292;Stasi&#31561;&#20154;&#20110;2014&#24180;&#24341;&#20837;&#20102;&#36229;&#22270;&#946;&#27169;&#22411;&#65292;&#29992;&#20110;&#25429;&#25417;&#20855;&#26377;&#39640;&#38454;&#65288;&#22810;&#21521;&#65289;&#20132;&#20114;&#30340;&#32593;&#32476;&#20013;&#30340;&#24230;&#24322;&#36136;&#24615;&#12290;&#26412;&#25991;&#39318;&#27425;&#23545;&#20855;&#26377;&#22810;&#23618;&#30340;&#36229;&#22270;&#946;&#27169;&#22411;&#36827;&#34892;&#20102;&#20005;&#26684;&#30740;&#31350;&#65292;&#23427;&#20801;&#35768;&#22312;&#19981;&#21516;&#23618;&#27425;&#20013;&#23384;&#22312;&#19981;&#21516;&#22823;&#23567;&#30340;&#36229;&#36793;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#26368;&#22823;&#20284;&#28982;&#65288;ML&#65289;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#24182;&#30830;&#23450;&#20102;&#23427;&#20204;&#30340;&#26368;&#23567;&#26497;&#23567;&#36895;&#29575;&#12290;&#25105;&#20204;&#36824;&#25512;&#23548;&#20102;ML&#20272;&#35745;&#30340;&#26497;&#38480;&#20998;&#24067;&#65292;&#24182;&#26500;&#24314;&#20102;&#27169;&#22411;&#21442;&#25968;&#30340;&#28176;&#36817;&#26377;&#25928;&#32622;&#20449;&#21306;&#38388;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#36229;&#22270;&#946;&#27169;&#22411;&#20013;&#30340;&#25311;&#21512;&#20248;&#24230;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#22312;&#38646;&#20551;&#35774;&#19979;&#24314;&#31435;&#20102;&#20284;&#28982;&#27604;&#65288;LR&#65289;&#26816;&#39564;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The $\boldsymbol{\beta}$-model for random graphs is commonly used for representing pairwise interactions in a network with degree heterogeneity. Going beyond pairwise interactions, Stasi et al. (2014) introduced the hypergraph $\boldsymbol{\beta}$-model for capturing degree heterogeneity in networks with higher-order (multi-way) interactions. In this paper we initiate the rigorous study of the hypergraph $\boldsymbol{\beta}$-model with multiple layers, which allows for hyperedges of different sizes across the layers. To begin with, we derive the rates of convergence of the maximum likelihood (ML) estimate and establish their minimax rate optimality. We also derive the limiting distribution of the ML estimate and construct asymptotically valid confidence intervals for the model parameters. Next, we consider the goodness-of-fit problem in the hypergraph $\boldsymbol{\beta}$-model. Specifically, we establish the asymptotic normality of the likelihood ratio (LR) test under the null hypothe
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#26088;&#22312;&#25506;&#35752;&#20309;&#26102;&#22522;&#20110;&#32622;&#20449;&#24230;&#30340;&#32423;&#32852;&#24310;&#36831;&#21487;&#33021;&#22833;&#36133;&#65292;&#20197;&#21450;&#20309;&#26102;&#22791;&#36873;&#30340;&#24310;&#36831;&#31574;&#30053;&#21487;&#33021;&#34920;&#29616;&#26356;&#22909;&#12290;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#21644;&#23454;&#39564;&#35777;&#26126;&#20107;&#21518;&#24310;&#36831;&#26426;&#21046;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.02764</link><description>&lt;p&gt;
&#20309;&#26102;&#20351;&#29992;&#22522;&#20110;&#32622;&#20449;&#24230;&#30340;&#32423;&#32852;&#24310;&#36831;&#36275;&#22815;&#65311;
&lt;/p&gt;
&lt;p&gt;
When Does Confidence-Based Cascade Deferral Suffice?. (arXiv:2307.02764v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02764
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#26088;&#22312;&#25506;&#35752;&#20309;&#26102;&#22522;&#20110;&#32622;&#20449;&#24230;&#30340;&#32423;&#32852;&#24310;&#36831;&#21487;&#33021;&#22833;&#36133;&#65292;&#20197;&#21450;&#20309;&#26102;&#22791;&#36873;&#30340;&#24310;&#36831;&#31574;&#30053;&#21487;&#33021;&#34920;&#29616;&#26356;&#22909;&#12290;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#21644;&#23454;&#39564;&#35777;&#26126;&#20107;&#21518;&#24310;&#36831;&#26426;&#21046;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32423;&#32852;&#26159;&#19968;&#31181;&#32463;&#20856;&#30340;&#31574;&#30053;&#65292;&#21487;&#20197;&#23454;&#29616;&#36866;&#24212;&#24615;&#22320;&#22312;&#26679;&#26412;&#20043;&#38388;&#21464;&#21270;&#30340;&#25512;&#29702;&#25104;&#26412;&#65292;&#20854;&#20013;&#25353;&#39034;&#24207;&#35843;&#29992;&#19968;&#31995;&#21015;&#20998;&#31867;&#22120;&#12290;&#24310;&#36831;&#35268;&#21017;&#30830;&#23450;&#26159;&#21542;&#35843;&#29992;&#24207;&#21015;&#20013;&#30340;&#19979;&#19968;&#20010;&#20998;&#31867;&#22120;&#65292;&#25110;&#32773;&#32456;&#27490;&#39044;&#27979;&#12290;&#19968;&#31181;&#31616;&#21333;&#30340;&#24310;&#36831;&#35268;&#21017;&#21033;&#29992;&#24403;&#21069;&#20998;&#31867;&#22120;&#30340;&#32622;&#20449;&#24230;&#65292;&#20363;&#22914;&#22522;&#20110;&#26368;&#22823;&#39044;&#27979;&#30340;softmax&#27010;&#29575;&#12290;&#23613;&#31649;&#23545;&#32423;&#32852;&#32467;&#26500;&#19981;&#25935;&#24863;&#8212;&#8212;&#20363;&#22914;&#19981;&#24314;&#27169;&#19979;&#28216;&#27169;&#22411;&#30340;&#38169;&#35823;&#8212;&#8212;&#20294;&#36825;&#31181;&#22522;&#20110;&#32622;&#20449;&#24230;&#30340;&#24310;&#36831;&#32463;&#24120;&#22312;&#23454;&#36341;&#20013;&#34920;&#29616;&#20986;&#33394;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#26356;&#22909;&#22320;&#29702;&#35299;&#22522;&#20110;&#32622;&#20449;&#24230;&#30340;&#24310;&#36831;&#21487;&#33021;&#22833;&#36133;&#30340;&#26465;&#20214;&#65292;&#20197;&#21450;&#20309;&#26102;&#22791;&#36873;&#30340;&#24310;&#36831;&#31574;&#30053;&#21487;&#33021;&#26356;&#22909;&#12290;&#25105;&#20204;&#39318;&#20808;&#23545;&#26368;&#20248;&#24310;&#36831;&#35268;&#21017;&#36827;&#34892;&#20102;&#29702;&#35770;&#34920;&#24449;&#65292;&#31934;&#30830;&#22320;&#25551;&#36848;&#20102;&#22522;&#20110;&#32622;&#20449;&#24230;&#30340;&#24310;&#36831;&#21487;&#33021;&#21463;&#21040;&#24433;&#21709;&#30340;&#35774;&#32622;&#12290;&#28982;&#21518;&#25105;&#20204;&#30740;&#31350;&#20102;&#20107;&#21518;&#24310;&#36831;&#26426;&#21046;&#65292;&#24182;&#39564;&#35777;&#23427;&#20204;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Cascades are a classical strategy to enable inference cost to vary adaptively across samples, wherein a sequence of classifiers are invoked in turn. A deferral rule determines whether to invoke the next classifier in the sequence, or to terminate prediction. One simple deferral rule employs the confidence of the current classifier, e.g., based on the maximum predicted softmax probability. Despite being oblivious to the structure of the cascade -- e.g., not modelling the errors of downstream models -- such confidence-based deferral often works remarkably well in practice. In this paper, we seek to better understand the conditions under which confidence-based deferral may fail, and when alternate deferral strategies can perform better. We first present a theoretical characterisation of the optimal deferral rule, which precisely characterises settings under which confidence-based deferral may suffer. We then study post-hoc deferral mechanisms, and demonstrate they can significantly improv
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;PCA&#26041;&#27861;&#65292;&#21487;&#20197;&#20272;&#35745;&#26679;&#26412;&#30340;&#22122;&#22768;&#26041;&#24046;&#65292;&#20174;&#32780;&#25913;&#36827;&#19982;&#25968;&#25454;&#30340;&#20302;&#31209;&#32467;&#26500;&#30456;&#20851;&#30340;&#23376;&#31354;&#38388;&#22522;&#30784;&#30340;&#20272;&#35745;&#20540;&#12290;</title><link>http://arxiv.org/abs/2307.02745</link><description>&lt;p&gt;
ALPCAH&#65306;&#20855;&#26377;&#23614;&#37096;&#22855;&#24322;&#20540;&#27491;&#21017;&#21270;&#30340;&#26679;&#26412;&#24322;&#26041;&#24046;PCA
&lt;/p&gt;
&lt;p&gt;
ALPCAH: Sample-wise Heteroscedastic PCA with Tail Singular Value Regularization. (arXiv:2307.02745v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02745
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;PCA&#26041;&#27861;&#65292;&#21487;&#20197;&#20272;&#35745;&#26679;&#26412;&#30340;&#22122;&#22768;&#26041;&#24046;&#65292;&#20174;&#32780;&#25913;&#36827;&#19982;&#25968;&#25454;&#30340;&#20302;&#31209;&#32467;&#26500;&#30456;&#20851;&#30340;&#23376;&#31354;&#38388;&#22522;&#30784;&#30340;&#20272;&#35745;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#26159;&#25968;&#25454;&#38477;&#32500;&#39046;&#22495;&#20013;&#30340;&#20851;&#38190;&#24037;&#20855;&#65292;&#23545;&#20110;&#21508;&#31181;&#25968;&#25454;&#31185;&#23398;&#38382;&#39064;&#37117;&#38750;&#24120;&#26377;&#29992;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#24212;&#29992;&#28041;&#21450;&#21040;&#20855;&#26377;&#19981;&#21516;&#25968;&#25454;&#28304;&#30340;&#22122;&#22768;&#29305;&#24615;&#23548;&#33268;&#36136;&#37327;&#19981;&#22343;&#21248;&#30340;&#24322;&#36136;&#25968;&#25454;&#12290;&#22788;&#29702;&#36825;&#31181;&#28151;&#21512;&#25968;&#25454;&#38598;&#30340;&#26041;&#27861;&#34987;&#31216;&#20026;&#24322;&#26041;&#24046;&#26041;&#27861;&#12290;&#24403;&#21069;&#30340;&#26041;&#27861;&#22914;HePPCAT&#20551;&#35774;&#22522;&#30784;&#31995;&#25968;&#20026;&#39640;&#26031;&#20998;&#24067;&#65292;&#20294;&#22312;&#23454;&#36341;&#20013;&#21487;&#33021;&#19981;&#25104;&#31435;&#12290;&#20854;&#20182;&#26041;&#27861;&#22914;&#21152;&#26435;PCA&#65288;WPCA&#65289;&#20551;&#35774;&#22122;&#22768;&#26041;&#24046;&#24050;&#30693;&#65292;&#20294;&#22312;&#23454;&#36341;&#20013;&#24456;&#38590;&#30830;&#23450;&#12290;&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;PCA&#26041;&#27861;&#65292;&#21487;&#20197;&#20272;&#35745;&#26679;&#26412;&#30340;&#22122;&#22768;&#26041;&#24046;&#65292;&#24182;&#23558;&#36825;&#20123;&#20449;&#24687;&#29992;&#20110;&#27169;&#22411;&#20013;&#65292;&#20197;&#25913;&#36827;&#19982;&#25968;&#25454;&#30340;&#20302;&#31209;&#32467;&#26500;&#30456;&#20851;&#30340;&#23376;&#31354;&#38388;&#22522;&#30784;&#30340;&#20272;&#35745;&#20540;&#12290;&#36825;&#26679;&#20570;&#19981;&#38656;&#35201;&#23545;&#20302;&#31209;&#25104;&#20998;&#36827;&#34892;&#20998;&#24067;&#20551;&#35774;&#65292;&#20063;&#19981;&#38656;&#35201;&#20551;&#35774;&#22122;&#22768;&#26041;&#24046;&#24050;&#30693;&#12290;&#27169;&#25311;&#23454;&#39564;&#26174;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Principal component analysis (PCA) is a key tool in the field of data dimensionality reduction that is useful for various data science problems. However, many applications involve heterogeneous data that varies in quality due to noise characteristics associated with different sources of the data. Methods that deal with this mixed dataset are known as heteroscedastic methods. Current methods like HePPCAT make Gaussian assumptions of the basis coefficients that may not hold in practice. Other methods such as Weighted PCA (WPCA) assume the noise variances are known, which may be difficult to know in practice. This paper develops a PCA method that can estimate the sample-wise noise variances and use this information in the model to improve the estimate of the subspace basis associated with the low-rank structure of the data. This is done without distributional assumptions of the low-rank component and without assuming the noise variances are known. Simulations show the effectiveness of acc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#39318;&#27425;&#23545;&#20219;&#21153;&#32423;&#21035;&#30340;&#35780;&#20272;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#21457;&#29616;&#29616;&#26377;&#30340;&#23569;&#26679;&#26412;&#23398;&#20064;&#22522;&#20934;&#24182;&#19981;&#33021;&#20197;&#21487;&#38752;&#30340;&#26041;&#24335;&#35774;&#35745;&#65292;&#26080;&#27861;&#33719;&#21462;&#20851;&#20110;&#22914;&#20309;&#35780;&#20272;&#21644;&#36873;&#25321;&#27169;&#22411;&#30340;&#21487;&#38752;&#24773;&#20917;&#30340;&#23436;&#25972;&#30011;&#38754;&#12290;</title><link>http://arxiv.org/abs/2307.02732</link><description>&lt;p&gt;
&#35780;&#20272;&#35780;&#20272;&#22120;&#65306;&#24403;&#21069;&#30340;&#23569;&#26679;&#26412;&#23398;&#20064;&#22522;&#20934;&#36866;&#29992;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Evaluating the Evaluators: Are Current Few-Shot Learning Benchmarks Fit for Purpose?. (arXiv:2307.02732v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02732
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#39318;&#27425;&#23545;&#20219;&#21153;&#32423;&#21035;&#30340;&#35780;&#20272;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#21457;&#29616;&#29616;&#26377;&#30340;&#23569;&#26679;&#26412;&#23398;&#20064;&#22522;&#20934;&#24182;&#19981;&#33021;&#20197;&#21487;&#38752;&#30340;&#26041;&#24335;&#35774;&#35745;&#65292;&#26080;&#27861;&#33719;&#21462;&#20851;&#20110;&#22914;&#20309;&#35780;&#20272;&#21644;&#36873;&#25321;&#27169;&#22411;&#30340;&#21487;&#38752;&#24773;&#20917;&#30340;&#23436;&#25972;&#30011;&#38754;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#30340;&#21313;&#24180;&#20013;&#65292;&#25552;&#20986;&#20102;&#35768;&#22810;&#23569;&#26679;&#26412;&#23398;&#20064;&#30340;&#22522;&#20934;&#12290;&#28982;&#32780;&#65292;&#25152;&#26377;&#36825;&#20123;&#22522;&#20934;&#37117;&#38598;&#20013;&#22312;&#23545;&#35768;&#22810;&#20219;&#21153;&#24179;&#22343;&#24615;&#33021;&#30340;&#35780;&#20272;&#19978;&#65292;&#20294;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#22914;&#20309;&#21487;&#38752;&#22320;&#35780;&#20272;&#21644;&#35843;&#25972;&#38024;&#23545;&#20010;&#21035;&#20219;&#21153;&#35757;&#32451;&#30340;&#27169;&#22411;&#30340;&#38382;&#39064;&#23578;&#26410;&#35299;&#20915;&#12290;&#26412;&#25991;&#39318;&#27425;&#23545;&#20219;&#21153;&#32423;&#21035;&#30340;&#35780;&#20272;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#36825;&#22312;&#37096;&#32626;&#27169;&#22411;&#26102;&#26159;&#19968;&#20010;&#22522;&#26412;&#27493;&#39588;&#12290;&#25105;&#20204;&#27979;&#37327;&#20102;&#23569;&#26679;&#26412;&#22330;&#26223;&#20013;&#24615;&#33021;&#20272;&#35745;&#22120;&#30340;&#20934;&#30830;&#24615;&#65292;&#32771;&#34385;&#20102;&#27169;&#22411;&#36873;&#25321;&#30340;&#31574;&#30053;&#65292;&#24182;&#26816;&#26597;&#20102;&#36890;&#24120;&#34987;&#35748;&#20026;&#26159;&#40065;&#26834;&#30340;&#35780;&#20272;&#22120;&#22833;&#36133;&#30340;&#21407;&#22240;&#12290;&#25105;&#20204;&#24471;&#20986;&#32467;&#35770;&#65292;&#29992;&#36739;&#23569;&#30340;&#25240;&#21472;&#36827;&#34892;&#20132;&#21449;&#39564;&#35777;&#26159;&#30452;&#25509;&#20272;&#35745;&#27169;&#22411;&#24615;&#33021;&#30340;&#26368;&#20339;&#36873;&#25321;&#65292;&#32780;&#29992;&#33258;&#21161;&#27861;&#25110;&#22823;&#37327;&#25240;&#21472;&#36827;&#34892;&#20132;&#21449;&#39564;&#35777;&#26356;&#36866;&#21512;&#20110;&#27169;&#22411;&#36873;&#25321;&#30340;&#30446;&#30340;&#12290;&#24635;&#30340;&#26469;&#35828;&#65292;&#25105;&#20204;&#21457;&#29616;&#29616;&#26377;&#30340;&#23569;&#26679;&#26412;&#23398;&#20064;&#22522;&#20934;&#24182;&#19981;&#33021;&#20197;&#21487;&#38752;&#30340;&#26041;&#24335;&#35774;&#35745;&#65292;&#26080;&#27861;&#33719;&#21462;&#20851;&#20110;&#22914;&#20309;&#35780;&#20272;&#21644;&#36873;&#25321;&#27169;&#22411;&#30340;&#21487;&#38752;&#24773;&#20917;&#30340;&#23436;&#25972;&#30011;&#38754;&#12290;
&lt;/p&gt;
&lt;p&gt;
Numerous benchmarks for Few-Shot Learning have been proposed in the last decade. However all of these benchmarks focus on performance averaged over many tasks, and the question of how to reliably evaluate and tune models trained for individual tasks in this regime has not been addressed. This paper presents the first investigation into task-level evaluation -- a fundamental step when deploying a model. We measure the accuracy of performance estimators in the few-shot setting, consider strategies for model selection, and examine the reasons for the failure of evaluators usually thought of as being robust. We conclude that cross-validation with a low number of folds is the best choice for directly estimating the performance of a model, whereas using bootstrapping or cross validation with a large number of folds is better for model selection purposes. Overall, we find that existing benchmarks for few-shot learning are not designed in such a way that one can get a reliable picture of how e
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#31995;&#32479;&#30740;&#31350;&#27969;&#24335;&#21644;&#27744;&#24335;&#20027;&#21160;&#23398;&#20064;&#19979;&#30340;&#19981;&#30830;&#23450;&#24615;&#37319;&#26679;&#31639;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31561;&#25928;&#25439;&#22833;&#30340;&#27010;&#24565;&#65292;&#24182;&#35777;&#26126;&#19981;&#30830;&#23450;&#24615;&#37319;&#26679;&#31639;&#27861;&#23454;&#36136;&#19978;&#26159;&#38024;&#23545;&#35813;&#31561;&#25928;&#25439;&#22833;&#36827;&#34892;&#20248;&#21270;&#12290;</title><link>http://arxiv.org/abs/2307.02719</link><description>&lt;p&gt;
&#29702;&#35299;&#19981;&#30830;&#23450;&#24615;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Understanding Uncertainty Sampling. (arXiv:2307.02719v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02719
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#31995;&#32479;&#30740;&#31350;&#27969;&#24335;&#21644;&#27744;&#24335;&#20027;&#21160;&#23398;&#20064;&#19979;&#30340;&#19981;&#30830;&#23450;&#24615;&#37319;&#26679;&#31639;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31561;&#25928;&#25439;&#22833;&#30340;&#27010;&#24565;&#65292;&#24182;&#35777;&#26126;&#19981;&#30830;&#23450;&#24615;&#37319;&#26679;&#31639;&#27861;&#23454;&#36136;&#19978;&#26159;&#38024;&#23545;&#35813;&#31561;&#25928;&#25439;&#22833;&#36827;&#34892;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#30830;&#23450;&#24615;&#37319;&#26679;&#26159;&#19968;&#31181;&#24120;&#35265;&#30340;&#20027;&#21160;&#23398;&#20064;&#31639;&#27861;&#65292;&#23427;&#39034;&#24207;&#22320;&#26597;&#35810;&#24403;&#21069;&#39044;&#27979;&#27169;&#22411;&#23545;&#25968;&#25454;&#26679;&#26412;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#28982;&#32780;&#65292;&#19981;&#30830;&#23450;&#24615;&#37319;&#26679;&#30340;&#20351;&#29992;&#24448;&#24448;&#26159;&#21551;&#21457;&#24335;&#30340;&#65306;&#65288;i&#65289;&#20851;&#20110;&#22312;&#29305;&#23450;&#20219;&#21153;&#21644;&#29305;&#23450;&#25439;&#22833;&#20989;&#25968;&#19979;&#23545;&#8220;&#19981;&#30830;&#23450;&#24615;&#8221;&#30340;&#20934;&#30830;&#23450;&#20041;&#27809;&#26377;&#20849;&#35782;&#65307;&#65288;ii&#65289;&#27809;&#26377;&#29702;&#35770;&#20445;&#35777;&#33021;&#22815;&#32473;&#20986;&#19968;&#20010;&#26631;&#20934;&#21327;&#35758;&#26469;&#23454;&#26045;&#35813;&#31639;&#27861;&#65292;&#20363;&#22914;&#65292;&#22312;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31561;&#20248;&#21270;&#31639;&#27861;&#26694;&#26550;&#19979;&#22914;&#20309;&#22788;&#29702;&#39034;&#24207;&#21040;&#36798;&#30340;&#27880;&#37322;&#25968;&#25454;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#31995;&#32479;&#22320;&#30740;&#31350;&#20102;&#27969;&#24335;&#21644;&#27744;&#24335;&#20027;&#21160;&#23398;&#20064;&#19979;&#30340;&#19981;&#30830;&#23450;&#24615;&#37319;&#26679;&#31639;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31561;&#25928;&#25439;&#22833;&#30340;&#27010;&#24565;&#65292;&#35813;&#27010;&#24565;&#21462;&#20915;&#20110;&#20351;&#29992;&#30340;&#19981;&#30830;&#23450;&#24615;&#24230;&#37327;&#21644;&#21407;&#22987;&#25439;&#22833;&#20989;&#25968;&#65292;&#24182;&#30830;&#31435;&#20102;&#19981;&#30830;&#23450;&#24615;&#37319;&#26679;&#31639;&#27861;&#26412;&#36136;&#19978;&#26159;&#38024;&#23545;&#36825;&#31181;&#31561;&#25928;&#25439;&#22833;&#36827;&#34892;&#20248;&#21270;&#12290;&#36825;&#19968;&#35266;&#28857;&#39564;&#35777;&#20102;&#31639;&#27861;&#30340;&#36866;&#24403;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Uncertainty sampling is a prevalent active learning algorithm that queries sequentially the annotations of data samples which the current prediction model is uncertain about. However, the usage of uncertainty sampling has been largely heuristic: (i) There is no consensus on the proper definition of "uncertainty" for a specific task under a specific loss; (ii) There is no theoretical guarantee that prescribes a standard protocol to implement the algorithm, for example, how to handle the sequentially arrived annotated data under the framework of optimization algorithms such as stochastic gradient descent. In this work, we systematically examine uncertainty sampling algorithms under both stream-based and pool-based active learning. We propose a notion of equivalent loss which depends on the used uncertainty measure and the original loss function and establish that an uncertainty sampling algorithm essentially optimizes against such an equivalent loss. The perspective verifies the properne
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20027;&#35201;&#20171;&#32461;&#20102;NTK&#26041;&#27861;&#22312;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;&#65292;&#36890;&#36807;&#25214;&#21040;&#21487;&#22788;&#29702;&#30340;&#20869;&#26680;&#34920;&#36798;&#24418;&#24335;&#26469;&#35299;&#20915;&#19968;&#33324;&#26080;&#27861;&#35299;&#20915;&#30340;&#38382;&#39064;&#65292;&#37325;&#28857;&#35752;&#35770;&#20102;&#25968;&#25454;&#31934;&#28860;&#21644;&#23545;&#25239;&#40065;&#26834;&#24615;&#31561;&#23454;&#38469;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2307.02693</link><description>&lt;p&gt;
&#20869;&#26680;&#65292;&#25968;&#25454;&#21644;&#29289;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
Kernels, Data &amp; Physics. (arXiv:2307.02693v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02693
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20027;&#35201;&#20171;&#32461;&#20102;NTK&#26041;&#27861;&#22312;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;&#65292;&#36890;&#36807;&#25214;&#21040;&#21487;&#22788;&#29702;&#30340;&#20869;&#26680;&#34920;&#36798;&#24418;&#24335;&#26469;&#35299;&#20915;&#19968;&#33324;&#26080;&#27861;&#35299;&#20915;&#30340;&#38382;&#39064;&#65292;&#37325;&#28857;&#35752;&#35770;&#20102;&#25968;&#25454;&#31934;&#28860;&#21644;&#23545;&#25239;&#40065;&#26834;&#24615;&#31561;&#23454;&#38469;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#26159;Julia Kempe&#25945;&#25480;&#22312;Les Houches&#20030;&#21150;&#30340;&#22799;&#23395;&#23398;&#26657;&#8220;&#26426;&#22120;&#23398;&#20064;&#30340;&#32479;&#35745;&#29289;&#29702;&#8221;&#20013;&#25152;&#35762;&#25480;&#30340;&#35838;&#31243;&#31508;&#35760;&#12290;&#31508;&#35760;&#35752;&#35770;&#20102;&#25152;&#35859;&#30340;NTK&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#25214;&#21040;&#21487;&#22788;&#29702;&#30340;&#20869;&#26680;&#34920;&#36798;&#24418;&#24335;&#26469;&#29702;&#35299;&#19968;&#33324;&#26080;&#27861;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#31508;&#35760;&#20027;&#35201;&#20851;&#27880;&#23454;&#38469;&#24212;&#29992;&#65292;&#22914;&#25968;&#25454;&#31934;&#28860;&#21644;&#23545;&#25239;&#40065;&#26834;&#24615;&#65292;&#20063;&#35752;&#35770;&#20102;&#24402;&#32435;&#20559;&#24046;&#30340;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
Lecture notes from the course given by Professor Julia Kempe at the summer school "Statistical physics of Machine Learning" in Les Houches. The notes discuss the so-called NTK approach to problems in machine learning, which consists of gaining an understanding of generally unsolvable problems by finding a tractable kernel formulation. The notes are mainly focused on practical applications such as data distillation and adversarial robustness, examples of inductive bias are also discussed.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992;&#32467;&#26500;&#21270;&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#26041;&#27861;&#23545;&#38754;&#26495;&#25968;&#25454;&#36827;&#34892;&#23454;&#26102;&#39044;&#27979;&#65292;&#38024;&#23545;&#28151;&#21512;&#39057;&#29575;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#32467;&#26500;&#25552;&#20986;&#20102;&#31232;&#30095;&#32452; LASSO &#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#24182;&#19988;&#22312;&#23454;&#35777;&#32467;&#26524;&#20013;&#26174;&#31034;&#20986;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2307.02673</link><description>&lt;p&gt;
&#38754;&#26495;&#25968;&#25454;&#23454;&#26102;&#39044;&#27979;&#65306;&#20197;&#24066;&#30408;&#29575;&#20026;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
Panel Data Nowcasting: The Case of Price-Earnings Ratios. (arXiv:2307.02673v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02673
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#32467;&#26500;&#21270;&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#26041;&#27861;&#23545;&#38754;&#26495;&#25968;&#25454;&#36827;&#34892;&#23454;&#26102;&#39044;&#27979;&#65292;&#38024;&#23545;&#28151;&#21512;&#39057;&#29575;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#32467;&#26500;&#25552;&#20986;&#20102;&#31232;&#30095;&#32452; LASSO &#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#24182;&#19988;&#22312;&#23454;&#35777;&#32467;&#26524;&#20013;&#26174;&#31034;&#20986;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#32467;&#26500;&#21270;&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#26041;&#27861;&#65292;&#23545;&#30001;&#19981;&#21516;&#39057;&#29575;&#37319;&#26679;&#30340;&#31995;&#21015;&#25968;&#25454;&#36827;&#34892;&#38754;&#26495;&#25968;&#25454;&#23454;&#26102;&#39044;&#27979;&#12290;&#21463;&#21040;&#39044;&#27979;&#22823;&#37327;&#20844;&#21496;&#25910;&#30410;&#30340;&#38382;&#39064;&#30340;&#21551;&#21457;&#65292;&#32771;&#34385;&#21040;&#23439;&#35266;&#32463;&#27982;&#12289;&#37329;&#34701;&#21644;&#26032;&#38395;&#26102;&#38388;&#24207;&#21015;&#20197;&#19981;&#21516;&#39057;&#29575;&#37319;&#26679;&#30340;&#28151;&#21512;&#38754;&#26495;&#25968;&#25454;&#32467;&#26500;&#65292;&#25105;&#20204;&#37325;&#28857;&#30740;&#31350;&#20102;&#31232;&#30095;&#32452; LASSO &#27491;&#21017;&#21270;&#26041;&#27861;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#30456;&#27604;&#20998;&#26512;&#24072;&#30340;&#39044;&#27979;&#12289;&#39044;&#27979;&#32452;&#21512;&#12289;&#20844;&#21496;&#29305;&#23450;&#26102;&#38388;&#24207;&#21015;&#22238;&#24402;&#27169;&#22411;&#21644;&#26631;&#20934;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26426;&#22120;&#23398;&#20064;&#38754;&#26495;&#25968;&#25454;&#22238;&#24402;&#27169;&#22411;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
The paper uses structured machine learning regressions for nowcasting with panel data consisting of series sampled at different frequencies. Motivated by the problem of predicting corporate earnings for a large cross-section of firms with macroeconomic, financial, and news time series sampled at different frequencies, we focus on the sparse-group LASSO regularization which can take advantage of the mixed frequency time series panel data structures. Our empirical results show the superior performance of our machine learning panel data regression models over analysts' predictions, forecast combinations, firm-specific time series regression models, and standard machine learning methods.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#25551;&#36848;&#32467;&#26500;&#32570;&#22833;&#30340;&#20998;&#31867;&#20307;&#31995;&#65292;&#20854;&#20013;&#27599;&#20010;&#32570;&#22833;&#25351;&#31034;&#21521;&#37327;&#21487;&#20197;&#20381;&#36182;&#20110;&#38500;&#33258;&#36523;&#20043;&#22806;&#30340;&#25152;&#26377;&#32570;&#22833;&#25351;&#31034;&#21521;&#37327;&#21644;&#25968;&#25454;&#30697;&#38453;&#12290;&#23558;&#36825;&#20010;&#26032;&#26694;&#26550;&#23884;&#20837;&#21040;&#24050;&#26377;&#30340;MCAR&#12289;MAR&#21644;MNAR&#26426;&#21046;&#20998;&#35299;&#20013;&#12290;</title><link>http://arxiv.org/abs/2307.02650</link><description>&lt;p&gt;
&#32467;&#26500;&#32570;&#22833;&#30340;&#23436;&#25972;&#29305;&#24449;&#21270;
&lt;/p&gt;
&lt;p&gt;
A Complete Characterisation of Structured Missingness. (arXiv:2307.02650v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02650
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#25551;&#36848;&#32467;&#26500;&#32570;&#22833;&#30340;&#20998;&#31867;&#20307;&#31995;&#65292;&#20854;&#20013;&#27599;&#20010;&#32570;&#22833;&#25351;&#31034;&#21521;&#37327;&#21487;&#20197;&#20381;&#36182;&#20110;&#38500;&#33258;&#36523;&#20043;&#22806;&#30340;&#25152;&#26377;&#32570;&#22833;&#25351;&#31034;&#21521;&#37327;&#21644;&#25968;&#25454;&#30697;&#38453;&#12290;&#23558;&#36825;&#20010;&#26032;&#26694;&#26550;&#23884;&#20837;&#21040;&#24050;&#26377;&#30340;MCAR&#12289;MAR&#21644;MNAR&#26426;&#21046;&#20998;&#35299;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22788;&#29702;&#22823;&#22411;&#22797;&#26434;&#25968;&#25454;&#28304;&#30340;&#33021;&#21147;&#19981;&#26029;&#22686;&#21152;&#65292;&#20026;&#25105;&#20204;&#25552;&#20379;&#20102;&#26032;&#30340;&#37325;&#35201;&#24212;&#29992;&#30740;&#31350;&#38382;&#39064;&#65292;&#20363;&#22914;&#22914;&#20309;&#22788;&#29702;&#22823;&#35268;&#27169;&#25968;&#25454;&#24211;&#20013;&#30340;&#32570;&#22833;&#20540;&#12290;Mitra&#31561;&#20154;&#65288;2023&#24180;&#65289;&#27880;&#24847;&#21040;&#20102;&#32467;&#26500;&#32570;&#22833;&#65288;SM&#65289;&#30340;&#29616;&#35937;&#65292;&#21363;&#32570;&#22833;&#20855;&#26377;&#28508;&#22312;&#30340;&#32467;&#26500;&#12290;&#29616;&#26377;&#30340;&#32570;&#22833;&#26426;&#21046;&#23450;&#20041;&#20998;&#31867;&#36890;&#24120;&#20551;&#35774;&#21464;&#37327;&#30340;&#32570;&#22833;&#25351;&#31034;&#21521;&#37327;$M_1$&#65292;$M_2$&#65292;...&#65292;$M_p$&#22312;&#32473;&#23450;&#30456;&#20851;&#25968;&#25454;&#30697;&#38453;$\mathbf{X}$&#30340;&#26465;&#20214;&#19979;&#26159;&#29420;&#31435;&#30340;&#12290;&#37492;&#20110;&#36825;&#22312;&#22810;&#21464;&#37327;&#35774;&#32622;&#20013;&#36890;&#24120;&#19981;&#36866;&#29992;&#20110;&#25551;&#36848;SM&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;SM&#30340;&#20998;&#31867;&#20307;&#31995;&#65292;&#20854;&#20013;&#27599;&#20010;${M}_j$&#38500;&#20102;$\mathbf{X}$&#20043;&#22806;&#65292;&#36824;&#21487;&#20197;&#20381;&#36182;&#20110;$\mathbf{M}_{-j}$&#65288;&#21363;&#38500;&#20102;${M}_j$&#20043;&#22806;&#30340;&#25152;&#26377;&#32570;&#22833;&#25351;&#31034;&#21521;&#37327;&#65289;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#26032;&#26694;&#26550;&#23884;&#20837;&#21040;&#23558;&#26426;&#21046;&#20998;&#35299;&#20026;MCAR&#12289;MAR&#21644;MNAR&#65288;Rubin, 1976&#65289;&#30340;&#25104;&#29087;&#20998;&#35299;&#20013;&#65292;&#20174;&#32780;&#20801;&#35768;&#25105;&#20204;&#23558;&#26426;&#21046;&#37325;&#26032;&#32452;&#21512;&#21040;&#19968;&#20010;&#26356;&#24191;&#27867;&#30340;&#35774;&#32622;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
Our capacity to process large complex data sources is ever-increasing, providing us with new, important applied research questions to address, such as how to handle missing values in large-scale databases. Mitra et al. (2023) noted the phenomenon of Structured Missingness (SM), which is where missingness has an underlying structure. Existing taxonomies for defining missingness mechanisms typically assume that variables' missingness indicator vectors $M_1$, $M_2$, ..., $M_p$ are independent after conditioning on the relevant portion of the data matrix $\mathbf{X}$. As this is often unsuitable for characterising SM in multivariate settings, we introduce a taxonomy for SM, where each ${M}_j$ can depend on $\mathbf{M}_{-j}$ (i.e., all missingness indicator vectors except ${M}_j$), in addition to $\mathbf{X}$. We embed this new framework within the well-established decomposition of mechanisms into MCAR, MAR, and MNAR (Rubin, 1976), allowing us to recast mechanisms into a broader setting, wh
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#35299;&#20915;&#20102;&#34920;&#31034;&#23398;&#20064;&#20013;&#30340;&#28508;&#21464;&#37327;&#35782;&#21035;&#21644;"&#25903;&#25345;&#22806;"&#22270;&#20687;&#29983;&#25104;&#38382;&#39064;&#65292;&#23637;&#31034;&#20102;&#21152;&#27861;&#35299;&#30721;&#22120;&#33021;&#22815;&#23545;&#28508;&#21464;&#37327;&#36827;&#34892;&#35782;&#21035;&#65292;&#24182;&#25552;&#20379;&#20102;&#29702;&#35770;&#20381;&#25454;&#25903;&#25345;&#36825;&#31181;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.02598</link><description>&lt;p&gt;
&#28155;&#21152;&#35299;&#30721;&#22120;&#29992;&#20110;&#28508;&#21464;&#37327;&#35782;&#21035;&#21644;&#31515;&#21345;&#23572;&#31215;&#25512;&#31639;
&lt;/p&gt;
&lt;p&gt;
Additive Decoders for Latent Variables Identification and Cartesian-Product Extrapolation. (arXiv:2307.02598v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02598
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#35299;&#20915;&#20102;&#34920;&#31034;&#23398;&#20064;&#20013;&#30340;&#28508;&#21464;&#37327;&#35782;&#21035;&#21644;"&#25903;&#25345;&#22806;"&#22270;&#20687;&#29983;&#25104;&#38382;&#39064;&#65292;&#23637;&#31034;&#20102;&#21152;&#27861;&#35299;&#30721;&#22120;&#33021;&#22815;&#23545;&#28508;&#21464;&#37327;&#36827;&#34892;&#35782;&#21035;&#65292;&#24182;&#25552;&#20379;&#20102;&#29702;&#35770;&#20381;&#25454;&#25903;&#25345;&#36825;&#31181;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35299;&#20915;&#20102;&#34920;&#31034;&#23398;&#20064;&#20013;&#30340;&#28508;&#21464;&#37327;&#35782;&#21035;&#21644;&#8220;&#25903;&#25345;&#22806;&#8221;&#22270;&#20687;&#29983;&#25104;&#38382;&#39064;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#19968;&#31867;&#25105;&#20204;&#31216;&#20026;&#8220;&#21152;&#27861;&#8221;&#30340;&#35299;&#30721;&#22120;&#20013;&#65292;&#36825;&#20004;&#32773;&#26159;&#21487;&#33021;&#30340;&#65292;&#36825;&#20123;&#35299;&#30721;&#22120;&#31867;&#20284;&#20110;&#29992;&#20110;&#38754;&#21521;&#23545;&#35937;&#34920;&#31034;&#23398;&#20064;&#65288;OCRL&#65289;&#30340;&#35299;&#30721;&#22120;&#65292;&#24182;&#19988;&#38750;&#24120;&#36866;&#29992;&#20110;&#21487;&#20197;&#20998;&#35299;&#20026;&#22810;&#20010;&#29305;&#23450;&#23545;&#35937;&#22270;&#20687;&#30340;&#22270;&#20687;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#22312;&#20351;&#29992;&#21152;&#27861;&#35299;&#30721;&#22120;&#23436;&#20840;&#35299;&#20915;&#37325;&#26500;&#38382;&#39064;&#26102;&#65292;&#23545;&#28508;&#21464;&#37327;&#22359;&#36827;&#34892;&#20102;&#32622;&#25442;&#21644;&#22359;&#29366;&#36870;&#21464;&#25442;&#30340;&#35782;&#21035;&#30340;&#26465;&#20214;&#12290;&#36825;&#20010;&#20445;&#35777;&#20165;&#22522;&#20110;&#20851;&#20110;&#28508;&#22240;&#23376;&#20998;&#24067;&#30340;&#38750;&#24120;&#24369;&#30340;&#20551;&#35774;&#65292;&#28508;&#22240;&#23376;&#21487;&#33021;&#23384;&#22312;&#32479;&#35745;&#20381;&#36182;&#24182;&#19988;&#20855;&#26377;&#20960;&#20046;&#20219;&#24847;&#24418;&#29366;&#30340;&#25903;&#25345;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25552;&#20379;&#20102;&#38750;&#32447;&#24615;&#29420;&#31435;&#25104;&#20998;&#20998;&#26512;&#65288;ICA&#65289;&#21487;&#33021;&#24615;&#30340;&#26032;&#35774;&#32622;&#65292;&#24182;&#19988;&#22686;&#21152;&#20102;&#25105;&#20204;&#23545;OCRL&#26041;&#27861;&#30340;&#29702;&#35770;&#29702;&#35299;&#12290;&#25105;&#20204;&#36824;&#20174;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#21152;&#27861;&#35299;&#30721;&#22120;&#21487;&#20197;
&lt;/p&gt;
&lt;p&gt;
We tackle the problems of latent variables identification and "out-of-support" image generation in representation learning. We show that both are possible for a class of decoders that we call additive, which are reminiscent of decoders used for object-centric representation learning (OCRL) and well suited for images that can be decomposed as a sum of object-specific images. We provide conditions under which exactly solving the reconstruction problem using an additive decoder is guaranteed to identify the blocks of latent variables up to permutation and block-wise invertible transformations. This guarantee relies only on very weak assumptions about the distribution of the latent factors, which might present statistical dependencies and have an almost arbitrarily shaped support. Our result provides a new setting where nonlinear independent component analysis (ICA) is possible and adds to our theoretical understanding of OCRL methods. We also show theoretically that additive decoders can 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#27169;&#22411;&#38169;&#35823;&#19979;&#30340;&#26465;&#20214;&#29420;&#31435;&#24615;&#26816;&#39564;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#25552;&#20986;&#20102;&#26032;&#30340;&#36817;&#20284;&#25110;&#19978;&#30028;&#26469;&#34913;&#37327;&#22522;&#20110;&#22238;&#24402;&#30340;&#27979;&#35797;&#30340;&#27979;&#35797;&#35823;&#24046;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#22238;&#24402;&#30340;CI&#26816;&#39564;&#26041;&#27861;RBPT&#65292;&#23545;&#27169;&#22411;&#38169;&#35823;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.02520</link><description>&lt;p&gt;
&#27169;&#22411;&#38169;&#35823;&#19979;&#30340;&#26465;&#20214;&#29420;&#31435;&#24615;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Conditional independence testing under model misspecification. (arXiv:2307.02520v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02520
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#27169;&#22411;&#38169;&#35823;&#19979;&#30340;&#26465;&#20214;&#29420;&#31435;&#24615;&#26816;&#39564;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#25552;&#20986;&#20102;&#26032;&#30340;&#36817;&#20284;&#25110;&#19978;&#30028;&#26469;&#34913;&#37327;&#22522;&#20110;&#22238;&#24402;&#30340;&#27979;&#35797;&#30340;&#27979;&#35797;&#35823;&#24046;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#22238;&#24402;&#30340;CI&#26816;&#39564;&#26041;&#27861;RBPT&#65292;&#23545;&#27169;&#22411;&#38169;&#35823;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26465;&#20214;&#29420;&#31435;&#24615;&#65288;CI&#65289;&#26816;&#39564;&#26159;&#29616;&#20195;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#22522;&#30784;&#19988;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#12290;&#35768;&#22810;&#29616;&#20195;&#30340;CI&#26816;&#39564;&#26041;&#27861;&#20381;&#36182;&#20110;&#24378;&#22823;&#30340;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#26469;&#23398;&#20064;&#22238;&#24402;&#20989;&#25968;&#25110;&#36125;&#21494;&#26031;&#39044;&#27979;&#22120;&#20316;&#20026;&#20013;&#38388;&#27493;&#39588;&#12290;&#23613;&#31649;&#36825;&#20123;&#26041;&#27861;&#22312;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#20934;&#30830;&#20272;&#35745;&#22238;&#24402;&#20989;&#25968;&#25110;&#36125;&#21494;&#26031;&#39044;&#27979;&#22120;&#26102;&#20445;&#35777;&#20102;&#25511;&#21046;&#31532;&#19968;&#31867;&#38169;&#35823;&#65292;&#20294;&#23427;&#20204;&#22312;&#27169;&#22411;&#38169;&#35823;&#23548;&#33268;&#22833;&#36133;&#26102;&#30340;&#34892;&#20026;&#23578;&#19981;&#28165;&#26970;&#12290;&#20174;&#26356;&#24191;&#27867;&#30340;&#24847;&#20041;&#19978;&#35762;&#65292;&#21363;&#20351;&#20351;&#29992;&#20102;&#36890;&#29992;&#36924;&#36817;&#22120;&#65288;&#20363;&#22914;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65289;&#65292;&#27169;&#22411;&#38169;&#35823;&#20063;&#21487;&#33021;&#20986;&#29616;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#27169;&#22411;&#38169;&#35823;&#19979;&#30340;&#22522;&#20110;&#22238;&#24402;&#30340;CI&#26816;&#39564;&#30340;&#24615;&#33021;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26032;&#30340;&#36817;&#20284;&#25110;&#19978;&#30028;&#26469;&#34913;&#37327;&#20381;&#36182;&#20110;&#38169;&#35823;&#30340;&#19977;&#20010;&#22522;&#20110;&#22238;&#24402;&#30340;&#27979;&#35797;&#30340;&#27979;&#35797;&#35823;&#24046;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;Rao-Blackwellized Predictor Test&#65288;RBPT&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#22238;&#24402;&#30340;CI&#26816;&#39564;&#65292;&#23545;&#27169;&#22411;&#38169;&#35823;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conditional independence (CI) testing is fundamental and challenging in modern statistics and machine learning. Many modern methods for CI testing rely on powerful supervised learning methods to learn regression functions or Bayes predictors as an intermediate step. Although the methods are guaranteed to control Type-I error when the supervised learning methods accurately estimate the regression functions or Bayes predictors, their behavior is less understood when they fail due to model misspecification. In a broader sense, model misspecification can arise even when universal approximators (e.g., deep neural nets) are employed. Then, we study the performance of regression-based CI tests under model misspecification. Namely, we propose new approximations or upper bounds for the testing errors of three regression-based tests that depend on misspecification errors. Moreover, we introduce the Rao-Blackwellized Predictor Test (RBPT), a novel regression-based CI test robust against model mis
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#31639;&#27861;&#21644;&#25968;&#25454;&#30456;&#20851;&#30340;&#20551;&#35774;&#31867;&#30340;&#32463;&#39564;Rademacher&#22797;&#26434;&#24230;&#26469;&#25511;&#21046;&#27867;&#21270;&#38169;&#35823;&#30340;&#26041;&#27861;&#65292;&#22522;&#20110;&#26377;&#38480;&#20998;&#24418;&#32500;&#24230;&#33719;&#24471;&#20102;&#26032;&#30340;&#30028;&#38480;&#65292;&#24182;&#31616;&#21270;&#20102;&#23545;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#26080;&#32500;&#24230;&#27867;&#21270;&#30028;&#38480;&#30340;&#35777;&#26126;&#12290;</title><link>http://arxiv.org/abs/2307.02501</link><description>&lt;p&gt;
&#36890;&#36807;&#31639;&#27861;&#30456;&#20851;&#30340;Rademacher&#22797;&#26434;&#24230;&#23454;&#29616;&#27867;&#21270;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Generalization Guarantees via Algorithm-dependent Rademacher Complexity. (arXiv:2307.02501v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02501
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#31639;&#27861;&#21644;&#25968;&#25454;&#30456;&#20851;&#30340;&#20551;&#35774;&#31867;&#30340;&#32463;&#39564;Rademacher&#22797;&#26434;&#24230;&#26469;&#25511;&#21046;&#27867;&#21270;&#38169;&#35823;&#30340;&#26041;&#27861;&#65292;&#22522;&#20110;&#26377;&#38480;&#20998;&#24418;&#32500;&#24230;&#33719;&#24471;&#20102;&#26032;&#30340;&#30028;&#38480;&#65292;&#24182;&#31616;&#21270;&#20102;&#23545;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#26080;&#32500;&#24230;&#27867;&#21270;&#30028;&#38480;&#30340;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#27867;&#21270;&#34892;&#20026;&#38656;&#35201;&#31639;&#27861;&#21644;&#25968;&#25454;&#30456;&#20851;&#30340;&#27867;&#21270;&#30028;&#38480;&#26469;&#35299;&#37322;&#12290;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#65292;&#23384;&#22312;&#30528;&#28041;&#21450;(&#21508;&#31181;&#24418;&#24335;&#30340;)&#20114;&#20449;&#24687;&#30340;&#20449;&#24687;&#35770;&#27867;&#21270;&#30028;&#38480;&#65292;&#20197;&#21450;&#22522;&#20110;&#20551;&#35774;&#38598;&#31283;&#23450;&#24615;&#30340;&#30028;&#38480;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#25216;&#26415;&#19978;&#19981;&#21516;&#20294;&#22312;&#27010;&#24565;&#19978;&#30456;&#20851;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#65292;&#26469;&#25511;&#21046;&#27867;&#21270;&#38169;&#35823;&#65292;&#21363;&#31639;&#27861;&#21644;&#25968;&#25454;&#30456;&#20851;&#30340;&#20551;&#35774;&#31867;&#30340;&#32463;&#39564;Rademacher&#22797;&#26434;&#24230;&#12290;&#32467;&#21512;Rademacher&#22797;&#26434;&#24230;&#30340;&#26631;&#20934;&#23646;&#24615;&#21644;&#35813;&#31867;&#30340;&#20415;&#25463;&#32467;&#26500;&#65292;&#25105;&#20204;&#33021;&#22815;&#65306;(i)&#22522;&#20110;&#26377;&#38480;&#20998;&#24418;&#32500;&#24230;&#33719;&#24471;&#26032;&#30340;&#30028;&#38480;&#65292;&#36825;&#20123;&#30028;&#38480;&#23558;&#21069;&#20154;&#24037;&#20316;&#20013;&#30340;&#20998;&#24418;&#32500;&#24230;&#30028;&#38480;&#20174;&#36830;&#32493;&#30340;&#20551;&#35774;&#31867;&#25512;&#24191;&#21040;&#26377;&#38480;&#20551;&#35774;&#31867;&#65292;&#24182;&#19988;&#36991;&#20813;&#20102;&#20043;&#21069;&#24037;&#20316;&#20013;&#38656;&#35201;&#30340;&#20114;&#20449;&#24687;&#39033;&#65307;(ii)&#22823;&#22823;&#31616;&#21270;&#20102;&#26368;&#36817;&#25552;&#20986;&#30340;&#38024;&#23545;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#26080;&#32500;&#24230;&#27867;&#21270;&#30028;&#38480;&#30340;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
Algorithm- and data-dependent generalization bounds are required to explain the generalization behavior of modern machine learning algorithms. In this context, there exists information theoretic generalization bounds that involve (various forms of) mutual information, as well as bounds based on hypothesis set stability. We propose a conceptually related, but technically distinct complexity measure to control generalization error, which is the empirical Rademacher complexity of an algorithm- and data-dependent hypothesis class. Combining standard properties of Rademacher complexity with the convenient structure of this class, we are able to (i) obtain novel bounds based on the finite fractal dimension, which (a) extend previous fractal dimension-type bounds from continuous to finite hypothesis classes, and (b) avoid a mutual information term that was required in prior work; (ii) we greatly simplify the proof of a recent dimension-independent generalization bound for stochastic gradient 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;Pareto Optimal&#33258;&#30417;&#30563;&#26694;&#26550;&#65292;&#21033;&#29992;&#21487;&#29992;&#30340;&#32534;&#31243;&#30417;&#30563;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#30340;&#21709;&#24212;&#36827;&#34892;&#31995;&#32479;&#26657;&#20934;&#65292;&#36890;&#36807;&#20026;&#27599;&#20010;&#21709;&#24212;&#29983;&#25104;&#39118;&#38505;&#35780;&#20998;&#65292;&#32780;&#26080;&#38656;&#39069;&#22806;&#30340;&#25163;&#21160;&#24037;&#20316;&#12290;</title><link>http://arxiv.org/abs/2306.16564</link><description>&lt;p&gt;
&#36890;&#36807;Pareto Optimal&#33258;&#30417;&#30563;&#23454;&#29616;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#33258;&#21160;&#26657;&#20934;&#21644;&#38169;&#35823;&#20462;&#27491;
&lt;/p&gt;
&lt;p&gt;
Automatic Calibration and Error Correction for Large Language Models via Pareto Optimal Self-Supervision. (arXiv:2306.16564v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16564
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;Pareto Optimal&#33258;&#30417;&#30563;&#26694;&#26550;&#65292;&#21033;&#29992;&#21487;&#29992;&#30340;&#32534;&#31243;&#30417;&#30563;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#30340;&#21709;&#24212;&#36827;&#34892;&#31995;&#32479;&#26657;&#20934;&#65292;&#36890;&#36807;&#20026;&#27599;&#20010;&#21709;&#24212;&#29983;&#25104;&#39118;&#38505;&#35780;&#20998;&#65292;&#32780;&#26080;&#38656;&#39069;&#22806;&#30340;&#25163;&#21160;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLM)&#24050;&#32463;&#23637;&#29616;&#20102;&#20986;&#33394;&#30340;&#33021;&#21147;&#65292;&#36866;&#29992;&#20110;&#24191;&#27867;&#30340;&#24212;&#29992;&#39046;&#22495;&#65292;&#20294;&#26159;&#20934;&#30830;&#24615;&#20173;&#28982;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#22686;&#38271;&#39046;&#22495;&#65292;&#29305;&#21035;&#26159;&#22312;&#29983;&#29289;&#21307;&#23398;&#31561;&#20851;&#38190;&#39046;&#22495;&#12290;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26657;&#20934;LLM&#21709;&#24212;&#30340;&#32622;&#20449;&#27700;&#24179;&#65292;&#23545;&#20110;&#33258;&#21160;&#26816;&#27979;&#38169;&#35823;&#24182;&#20419;&#36827;&#20154;&#26426;&#21327;&#20316;&#39564;&#35777;&#33267;&#20851;&#37325;&#35201;&#12290;&#19968;&#20010;&#37325;&#35201;&#30340;&#26657;&#20934;&#20449;&#21495;&#26469;&#28304;&#26159;&#19987;&#23478;&#25351;&#23450;&#30340;&#32534;&#31243;&#30417;&#30563;&#65292;&#36890;&#24120;&#20855;&#26377;&#36739;&#20302;&#30340;&#25104;&#26412;&#65292;&#20294;&#20063;&#26377;&#20854;&#33258;&#36523;&#30340;&#23616;&#38480;&#24615;&#65292;&#22914;&#22122;&#22768;&#21644;&#35206;&#30422;&#33539;&#22260;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;Pareto Optimal&#33258;&#30417;&#30563;&#26694;&#26550;&#65292;&#21487;&#20197;&#21033;&#29992;&#21487;&#29992;&#30340;&#32534;&#31243;&#30417;&#30563;&#26469;&#31995;&#32479;&#22320;&#26657;&#20934;LLM&#21709;&#24212;&#65292;&#36890;&#36807;&#20026;&#27599;&#20010;&#21709;&#24212;&#29983;&#25104;&#39118;&#38505;&#35780;&#20998;&#65292;&#32780;&#19981;&#38656;&#35201;&#20219;&#20309;&#39069;&#22806;&#30340;&#25163;&#21160;&#24037;&#20316;&#12290;&#36825;&#36890;&#36807;&#23398;&#20064;&#19968;&#20010;&#35843;&#21644;&#27169;&#22411;&#26469;&#23454;&#29616;&#65292;&#23558;LLM&#36755;&#20986;&#19982;&#20854;&#20182;&#21487;&#29992;&#30340;&#30417;&#30563;&#26469;&#28304;&#30456;&#21327;&#35843;&#65292;&#23558;&#26356;&#19981;&#30830;&#23450;&#30340;&#21709;&#24212;&#20998;&#37197;&#26356;&#39640;&#30340;&#39118;&#38505;&#35780;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models (LLMs) have demonstrated remarkable capabilities out of box for a wide range of applications, yet accuracy still remains a major growth area, especially in mission-critical domains such as biomedicine. An effective method to calibrate the confidence level on LLM responses is essential to automatically detect errors and facilitate human-in-the-loop verification. An important source of calibration signals stems from expert-stipulated programmatic supervision, which is often available at low cost but has its own limitations such as noise and coverage. In this paper, we introduce a Pareto optimal self-supervision framework that can leverage available programmatic supervision to systematically calibrate LLM responses by producing a risk score for every response, without any additional manual efforts. This is accomplished by learning a harmonizer model to align LLM output with other available supervision sources, which would assign higher risk scores to more uncertain L
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;MAPS&#21644;MAPS-SE&#20004;&#20010;&#31639;&#27861;&#65292;&#21487;&#22312;&#22810;&#40657;&#30418;&#39044;&#35328;&#24773;&#20917;&#19979;&#65292;&#37319;&#29992;&#27169;&#20223;&#23398;&#20064;&#24182;&#20027;&#21160;&#36873;&#25321;&#21644;&#25913;&#36827;&#26368;&#20248;&#39044;&#35328;&#65292;&#26174;&#33879;&#25552;&#21319;&#20102;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.10259</link><description>&lt;p&gt;
&#22810;&#40657;&#30418;&#39044;&#35328;&#19979;&#30340;&#20027;&#21160;&#31574;&#30053;&#25913;&#36827;
&lt;/p&gt;
&lt;p&gt;
Active Policy Improvement from Multiple Black-box Oracles. (arXiv:2306.10259v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10259
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;MAPS&#21644;MAPS-SE&#20004;&#20010;&#31639;&#27861;&#65292;&#21487;&#22312;&#22810;&#40657;&#30418;&#39044;&#35328;&#24773;&#20917;&#19979;&#65292;&#37319;&#29992;&#27169;&#20223;&#23398;&#20064;&#24182;&#20027;&#21160;&#36873;&#25321;&#21644;&#25913;&#36827;&#26368;&#20248;&#39044;&#35328;&#65292;&#26174;&#33879;&#25552;&#21319;&#20102;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#22312;&#21508;&#31181;&#22797;&#26434;&#39046;&#22495;&#20013;&#21462;&#24471;&#20102;&#37325;&#22823;&#36827;&#23637;&#65292;&#20294;&#26159;&#36890;&#36807;&#24378;&#21270;&#23398;&#20064;&#30830;&#23450;&#26377;&#25928;&#31574;&#30053;&#24448;&#24448;&#38656;&#35201;&#36827;&#34892;&#24191;&#27867;&#30340;&#25506;&#32034;&#65292;&#32780;&#27169;&#20223;&#23398;&#20064;&#26088;&#22312;&#36890;&#36807;&#20351;&#29992;&#19987;&#23478;&#28436;&#31034;&#26469;&#25351;&#23548;&#25506;&#32034;&#65292;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#12290;&#22312;&#30495;&#23454;&#19990;&#30028;&#24773;&#22659;&#19979;&#65292;&#20154;&#20204;&#36890;&#24120;&#21482;&#33021;&#25509;&#35302;&#21040;&#22810;&#20010;&#27425;&#20248;&#30340;&#40657;&#30418;&#39044;&#35328;&#65292;&#32780;&#19981;&#26159;&#21333;&#20010;&#26368;&#20248;&#30340;&#39044;&#35328;&#65292;&#36825;&#20123;&#39044;&#35328;&#19981;&#33021;&#22312;&#25152;&#26377;&#29366;&#24577;&#19979;&#26222;&#36941;&#20248;&#20110;&#24444;&#27492;&#65292;&#36825;&#32473;&#20027;&#21160;&#20915;&#23450;&#22312;&#21738;&#31181;&#29366;&#24577;&#19979;&#20351;&#29992;&#21738;&#31181;&#39044;&#35328;&#20197;&#21450;&#22914;&#20309;&#25913;&#36827;&#21508;&#33258;&#20272;&#35745;&#20540;&#20989;&#25968;&#25552;&#20986;&#20102;&#25361;&#25112;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#21487;&#34892;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#21363;MAPS&#21644;MAPS-SE&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement learning (RL) has made significant strides in various complex domains. However, identifying an effective policy via RL often necessitates extensive exploration. Imitation learning aims to mitigate this issue by using expert demonstrations to guide exploration. In real-world scenarios, one often has access to multiple suboptimal black-box experts, rather than a single optimal oracle. These experts do not universally outperform each other across all states, presenting a challenge in actively deciding which oracle to use and in which state. We introduce MAPS and MAPS-SE, a class of policy improvement algorithms that perform imitation learning from multiple suboptimal oracles. In particular, MAPS actively selects which of the oracles to imitate and improve their value function estimates, and MAPS-SE additionally leverages an active state exploration criterion to determine which states one should explore. We provide a comprehensive theoretical analysis and demonstrate that MAP
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#22810;&#20803;Wasserstein barycenters&#25193;&#23637;`Strong Demographic Parity`&#30340;&#23450;&#20041;&#65292;&#23454;&#29616;&#22810;&#20219;&#21153;&#23398;&#20064;&#20013;&#30340;&#20844;&#24179;&#24615;&#65292;&#21253;&#25324;&#22238;&#24402;&#21644;&#20108;&#20803;&#20998;&#31867;&#20219;&#21153;&#12290;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.10155</link><description>&lt;p&gt;
&#36890;&#36807;Wasserstein Barycenters&#23454;&#29616;&#22810;&#20219;&#21153;&#23398;&#20064;&#20013;&#30340;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Fairness in Multi-Task Learning via Wasserstein Barycenters. (arXiv:2306.10155v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10155
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#22810;&#20803;Wasserstein barycenters&#25193;&#23637;`Strong Demographic Parity`&#30340;&#23450;&#20041;&#65292;&#23454;&#29616;&#22810;&#20219;&#21153;&#23398;&#20064;&#20013;&#30340;&#20844;&#24179;&#24615;&#65292;&#21253;&#25324;&#22238;&#24402;&#21644;&#20108;&#20803;&#20998;&#31867;&#20219;&#21153;&#12290;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31639;&#27861;&#20844;&#24179;&#24615;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#24050;&#32463;&#25104;&#29087;&#30340;&#39046;&#22495;&#65292;&#26088;&#22312;&#20943;&#23569;&#25968;&#25454;&#20013;&#30340;&#20559;&#24046;&#12290;&#26368;&#36817;&#30340;&#36827;&#23637;&#25552;&#20986;&#20102;&#21508;&#31181;&#26041;&#27861;&#26469;&#30830;&#20445;&#21333;&#21464;&#37327;&#29615;&#22659;&#19979;&#30340;&#20844;&#24179;&#24615;&#65292;&#21363;&#30446;&#26631;&#26159;&#21435;&#38500;&#21333;&#20010;&#20219;&#21153;&#30340;&#20559;&#24046;&#12290;&#28982;&#32780;&#65292;&#23558;&#20844;&#24179;&#24615;&#25193;&#23637;&#21040;&#22810;&#20219;&#21153;&#29615;&#22659;&#65292;&#20854;&#20013;&#20351;&#29992;&#20849;&#20139;&#34920;&#31034;&#26469;&#20248;&#21270;&#22810;&#20010;&#30446;&#26631;&#65292;&#20173;&#26410;&#24471;&#21040;&#20805;&#20998;&#24320;&#21457;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#21033;&#29992;&#22810;&#20803;Wasserstein barycenters&#23558;\textit{Strong Demographic Parity}&#30340;&#23450;&#20041;&#25193;&#23637;&#21040;&#22810;&#20219;&#21153;&#23398;&#20064;&#20013;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20026;&#26368;&#20248;&#30340;&#20844;&#24179;&#22810;&#20219;&#21153;&#39044;&#27979;&#22120;&#25552;&#20379;&#20102;&#23553;&#38381;&#24335;&#35299;&#65292;&#21253;&#25324;&#22238;&#24402;&#21644;&#20108;&#20803;&#20998;&#31867;&#20219;&#21153;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#20272;&#35745;&#36807;&#31243;&#65292;&#20197;&#23547;&#25214;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#36816;&#34892;&#25968;&#23383;&#23454;&#39564;&#12290;&#32463;&#39564;&#32467;&#26524;&#31361;&#26174;&#20102;&#25105;&#20204;&#30340;&#21518;&#22788;&#29702;&#26041;&#27861;&#22312;&#20419;&#36827;&#20844;&#24179;&#20915;&#31574;&#26041;&#38754;&#30340;&#23454;&#38469;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Algorithmic Fairness is an established field in machine learning that aims to reduce biases in data. Recent advances have proposed various methods to ensure fairness in a univariate environment, where the goal is to de-bias a single task. However, extending fairness to a multi-task setting, where more than one objective is optimised using a shared representation, remains underexplored. To bridge this gap, we develop a method that extends the definition of \textit{Strong Demographic Parity} to multi-task learning using multi-marginal Wasserstein barycenters. Our approach provides a closed form solution for the optimal fair multi-task predictor including both regression and binary classification tasks. We develop a data-driven estimation procedure for the solution and run numerical experiments on both synthetic and real datasets. The empirical results highlight the practical value of our post-processing methodology in promoting fair decision-making.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23545;R-SVD&#22312;&#20302;&#31209;&#20449;&#21495;&#21152;&#22122;&#22768;&#27979;&#37327;&#27169;&#22411;&#19979;&#30340;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#24403;&#20449;&#22122;&#27604;(SNR)&#36229;&#36807;&#26576;&#20010;&#20381;&#36182;&#20110;&#38477;&#32500;&#22240;&#23376;&#30340;&#21487;&#26816;&#27979;&#38376;&#38480;&#26102;&#65292;R-SVD&#20135;&#29983;&#30340;&#26368;&#22823;&#22855;&#24322;&#20540;&#26159;&#19968;&#20010;&#31163;&#32676;&#20540;&#65307;&#22312;&#38376;&#38480;&#20197;&#19979;&#65292;&#27809;&#26377;&#31163;&#32676;&#20540;&#20174;&#22855;&#24322;&#20540;&#22359;&#20013;&#20135;&#29983;</title><link>http://arxiv.org/abs/2305.17435</link><description>&lt;p&gt;
&#20851;&#20110;&#38543;&#26426;SVD&#30340;&#22122;&#22768;&#25935;&#24863;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Noise Sensitivity of the Randomized SVD. (arXiv:2305.17435v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17435
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;R-SVD&#22312;&#20302;&#31209;&#20449;&#21495;&#21152;&#22122;&#22768;&#27979;&#37327;&#27169;&#22411;&#19979;&#30340;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#24403;&#20449;&#22122;&#27604;(SNR)&#36229;&#36807;&#26576;&#20010;&#20381;&#36182;&#20110;&#38477;&#32500;&#22240;&#23376;&#30340;&#21487;&#26816;&#27979;&#38376;&#38480;&#26102;&#65292;R-SVD&#20135;&#29983;&#30340;&#26368;&#22823;&#22855;&#24322;&#20540;&#26159;&#19968;&#20010;&#31163;&#32676;&#20540;&#65307;&#22312;&#38376;&#38480;&#20197;&#19979;&#65292;&#27809;&#26377;&#31163;&#32676;&#20540;&#20174;&#22855;&#24322;&#20540;&#22359;&#20013;&#20135;&#29983;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#22855;&#24322;&#20540;&#20998;&#35299;(R-SVD)&#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#22522;&#20110;&#33609;&#22270;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#26377;&#25928;&#35745;&#31639;&#22823;&#30697;&#38453;&#30340;&#37096;&#20998;&#22855;&#24322;&#20540;&#20998;&#35299;&#12290;&#24403;&#30697;&#38453;&#26159;&#20302;&#31209;&#26102;&#65292;R-SVD&#21487;&#20197;&#31934;&#30830;&#22320;&#20135;&#29983;&#20854;&#37096;&#20998;&#22855;&#24322;&#20540;&#20998;&#35299;&#65307;&#20294;&#24403;&#31209;&#36739;&#22823;&#26102;&#65292;&#23427;&#21482;&#33021;&#20135;&#29983;&#36817;&#20284;&#20540;&#12290;&#21463;&#25968;&#25454;&#31185;&#23398;&#21644;&#20027;&#25104;&#20998;&#20998;&#26512;(PCA)&#24212;&#29992;&#30340;&#39537;&#21160;&#65292;&#25105;&#20204;&#22312;&#20302;&#31209;&#20449;&#21495;&#21152;&#22122;&#22768;&#27979;&#37327;&#27169;&#22411;&#19979;&#20998;&#26512;&#20102;R-SVD&#65307;&#20855;&#20307;&#26469;&#35828;&#65292;&#24403;&#20854;&#36755;&#20837;&#20026;&#23574;&#23792;&#22411;&#38543;&#26426;&#30697;&#38453;&#26102;&#12290;&#35777;&#26126;&#20102;R-SVD&#20135;&#29983;&#30340;&#22855;&#24322;&#20540;&#34920;&#29616;&#20986;&#31867;&#20284;BBP&#30340;&#30456;&#21464;&#65306;&#24403;&#20449;&#22122;&#27604;(SNR)&#36229;&#36807;&#26576;&#20010;&#20381;&#36182;&#20110;&#38477;&#32500;&#22240;&#23376;&#30340;&#21487;&#26816;&#27979;&#38376;&#38480;&#26102;&#65292;&#26368;&#22823;&#22855;&#24322;&#20540;&#26159;&#19968;&#20010;&#31163;&#32676;&#20540;&#65307;&#22312;&#38376;&#38480;&#20197;&#19979;&#65292;&#27809;&#26377;&#31163;&#32676;&#20540;&#20174;&#22855;&#24322;&#20540;&#22359;&#20013;&#20135;&#29983;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35745;&#31639;&#20102;&#22320;&#38754;&#30495;&#20540;&#20449;&#21495;&#22855;&#24322;&#21521;&#37327;&#19982;R-SVD&#20135;&#29983;&#30340;&#36817;&#20284;&#20540;&#20043;&#38388;&#30340;&#37325;&#21472;&#30340;&#28176;&#36817;&#20844;&#24335;&#12290;&#38477;&#32500;&#20855;&#26377;&#36127;&#38754;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
The randomized singular value decomposition (R-SVD) is a popular sketching-based algorithm for efficiently computing the partial SVD of a large matrix. When the matrix is low-rank, the R-SVD produces its partial SVD exactly; but when the rank is large, it only yields an approximation.  Motivated by applications in data science and principal component analysis (PCA), we analyze the R-SVD under a low-rank signal plus noise measurement model; specifically, when its input is a spiked random matrix. The singular values produced by the R-SVD are shown to exhibit a BBP-like phase transition: when the SNR exceeds a certain detectability threshold, that depends on the dimension reduction factor, the largest singular value is an outlier; below the threshold, no outlier emerges from the bulk of singular values. We further compute asymptotic formulas for the overlap between the ground truth signal singular vectors and the approximations produced by the R-SVD.  Dimensionality reduction has the adve
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#28151;&#21512;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#65292;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#21457;&#29616;&#20102;&#32479;&#35745;&#21644;&#35745;&#31639;&#20043;&#38388;&#30340;&#26435;&#34913;&#20851;&#31995;&#65292;&#24182;&#30830;&#23450;&#20102;&#26679;&#26412;&#22797;&#26434;&#24230;&#21644;&#36816;&#34892;&#26102;&#38388;&#20043;&#38388;&#30340;&#24179;&#28369;&#20449;&#24687;-&#35745;&#31639;&#26435;&#34913;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2303.02118</link><description>&lt;p&gt;
&#28151;&#21512;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#32479;&#35745;&#19982;&#35745;&#31639;&#26435;&#34913;
&lt;/p&gt;
&lt;p&gt;
Statistical-Computational Tradeoffs in Mixed Sparse Linear Regression. (arXiv:2303.02118v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.02118
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#28151;&#21512;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#65292;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#21457;&#29616;&#20102;&#32479;&#35745;&#21644;&#35745;&#31639;&#20043;&#38388;&#30340;&#26435;&#34913;&#20851;&#31995;&#65292;&#24182;&#30830;&#23450;&#20102;&#26679;&#26412;&#22797;&#26434;&#24230;&#21644;&#36816;&#34892;&#26102;&#38388;&#20043;&#38388;&#30340;&#24179;&#28369;&#20449;&#24687;-&#35745;&#31639;&#26435;&#34913;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20855;&#26377;&#20004;&#20010;&#37096;&#20998;&#30340;&#28151;&#21512;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#65292;&#20854;&#20013;&#38656;&#35201;&#20174;n&#20010;&#26080;&#26631;&#31614;&#30340;&#22122;&#22768;&#32447;&#24615;&#27979;&#37327;&#20013;&#24674;&#22797;&#20004;&#20010;&#23454;&#25968;k&#31232;&#30095;&#20449;&#21495;&#946;1&#12289;&#946;2&#12290;&#31232;&#30095;&#24230;&#20801;&#35768;&#22312;&#32500;&#24230;&#19978;&#26159;&#20122;&#32447;&#24615;&#30340;&#65292;&#19988;&#20551;&#35774;&#28155;&#21152;&#30340;&#22122;&#22768;&#26159;&#29420;&#31435;&#30340;&#39640;&#26031;&#22122;&#22768;&#65292;&#26041;&#24046;&#20026;&#963;&#178;&#12290;&#20043;&#21069;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#35813;&#38382;&#39064;&#23384;&#22312;&#19968;&#20010;k/SNR&#178;&#21040;k&#178;/SNR&#178;&#30340;&#32479;&#35745;&#21040;&#35745;&#31639;&#38388;&#38553;&#65292;&#31867;&#20284;&#20110;&#20854;&#20182;&#20855;&#26377;&#35745;&#31639;&#25361;&#25112;&#24615;&#30340;&#39640;&#32500;&#25512;&#26029;&#38382;&#39064;&#65292;&#22914;&#31232;&#30095;&#20027;&#25104;&#20998;&#20998;&#26512;&#21644;&#40065;&#26834;&#31232;&#30095;&#22343;&#20540;&#20272;&#35745;&#65307;&#36825;&#37324;&#30340;SNR&#26159;&#20449;&#22122;&#27604;&#12290;&#36890;&#36807;&#20302;&#27425;&#22810;&#39033;&#24335;&#26041;&#27861;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20010;&#38382;&#39064;&#23384;&#22312;&#26356;&#24191;&#27867;&#30340;&#35745;&#31639;&#38556;&#30861;&#65292;&#20294;&#21482;&#22312;&#38750;&#24120;&#29421;&#31364;&#30340;&#23545;&#31216;&#21442;&#25968;&#33539;&#22260;&#20869;&#25165;&#34920;&#29616;&#20986;&#35745;&#31639;&#22256;&#38590;&#12290;&#25105;&#20204;&#30830;&#23450;&#20102;&#26679;&#26412;&#22797;&#26434;&#24230;n&#21644;&#36816;&#34892;&#26102;&#38388;&#20043;&#38388;&#30340;&#24179;&#28369;&#20449;&#24687;-&#35745;&#31639;&#26435;&#34913;&#20851;&#31995;&#65292;&#23545;&#20110;&#20219;&#20309;&#38543;&#26426;&#21270;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of mixed sparse linear regression with two components, where two real $k$-sparse signals $\beta_1, \beta_2$ are to be recovered from $n$ unlabelled noisy linear measurements. The sparsity is allowed to be sublinear in the dimension, and additive noise is assumed to be independent Gaussian with variance $\sigma^2$. Prior work has shown that the problem suffers from a $\frac{k}{SNR^2}$-to-$\frac{k^2}{SNR^2}$ statistical-to-computational gap, resembling other computationally challenging high-dimensional inference problems such as Sparse PCA and Robust Sparse Mean Estimation; here $SNR$ is the signal-to-noise ratio. We establish the existence of a more extensive computational barrier for this problem through the method of low-degree polynomials, but show that the problem is computationally hard only in a very narrow symmetric parameter regime. We identify a smooth information-computation tradeoff between the sample complexity $n$ and runtime for any randomized algor
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;Stein&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#26377;&#38480;&#31890;&#23376;&#25910;&#25947;&#36895;&#24230;&#65292;&#35777;&#26126;&#20102;&#24403;&#30446;&#26631;&#20998;&#24067;&#20026;&#27425;&#39640;&#26031;&#19988;&#20855;&#26377;Lipschitz&#31215;&#20998;&#26680;&#26102;&#65292;&#20351;&#29992;&#36866;&#24403;&#30340;&#27493;&#38271;&#24207;&#21015;&#21644;&#31890;&#23376;&#25968;&#37327;&#65292;&#21487;&#20197;&#20197;1/&#8730;(log log n)&#30340;&#36895;&#24230;&#23558;&#26680;Stein&#24046;&#24322;&#36924;&#36817;&#38646;&#12290;</title><link>http://arxiv.org/abs/2211.09721</link><description>&lt;p&gt;
&#12298;Stein&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#30340;&#26377;&#38480;&#31890;&#23376;&#25910;&#25947;&#36895;&#24230;&#12299;
&lt;/p&gt;
&lt;p&gt;
A Finite-Particle Convergence Rate for Stein Variational Gradient Descent. (arXiv:2211.09721v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.09721
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;Stein&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#26377;&#38480;&#31890;&#23376;&#25910;&#25947;&#36895;&#24230;&#65292;&#35777;&#26126;&#20102;&#24403;&#30446;&#26631;&#20998;&#24067;&#20026;&#27425;&#39640;&#26031;&#19988;&#20855;&#26377;Lipschitz&#31215;&#20998;&#26680;&#26102;&#65292;&#20351;&#29992;&#36866;&#24403;&#30340;&#27493;&#38271;&#24207;&#21015;&#21644;&#31890;&#23376;&#25968;&#37327;&#65292;&#21487;&#20197;&#20197;1/&#8730;(log log n)&#30340;&#36895;&#24230;&#23558;&#26680;Stein&#24046;&#24322;&#36924;&#36817;&#38646;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#39318;&#27425;&#25552;&#20379;&#20102;Stein&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#65288;SVGD&#65289;&#30340;&#26377;&#38480;&#31890;&#23376;&#25910;&#25947;&#36895;&#24230;&#65292;&#36825;&#26159;&#19968;&#31181;&#29992;&#19968;&#32452;&#31890;&#23376;&#36924;&#36817;&#27010;&#29575;&#20998;&#24067;&#30340;&#27969;&#34892;&#31639;&#27861;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#21482;&#35201;&#30446;&#26631;&#20998;&#24067;&#26159;&#27425;&#39640;&#26031;&#30340;&#65292;&#24182;&#19988;&#20855;&#26377;Lipschitz&#31215;&#20998;&#26680;&#65292;&#20351;&#29992;n&#20010;&#31890;&#23376;&#21644;&#36866;&#24403;&#30340;&#27493;&#38271;&#24207;&#21015;&#36827;&#34892;SVGD&#65292;&#26680;Stein&#24046;&#24322;&#23558;&#20197;1/&#8730;(log log n)&#30340;&#36895;&#24230;&#36235;&#20110;&#38646;&#12290;&#25105;&#20204;&#24576;&#30097;n&#30340;&#20381;&#36182;&#24615;&#21487;&#20197;&#25913;&#36827;&#65292;&#24076;&#26395;&#25105;&#20204;&#30340;&#26126;&#30830;&#30340;&#38750;&#28176;&#36817;&#35777;&#26126;&#31574;&#30053;&#33021;&#20026;&#26410;&#26469;&#30340;&#25913;&#36827;&#25552;&#20379;&#27169;&#26495;&#12290;
&lt;/p&gt;
&lt;p&gt;
We provide the first finite-particle convergence rate for Stein variational gradient descent (SVGD), a popular algorithm for approximating a probability distribution with a collection of particles. Specifically, whenever the target distribution is sub-Gaussian with a Lipschitz score, SVGD with n particles and an appropriate step size sequence drives the kernel Stein discrepancy to zero at an order 1/sqrt(log log n) rate. We suspect that the dependence on n can be improved, and we hope that our explicit, non-asymptotic proof strategy will serve as a template for future refinements.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#35752;&#35770;&#20102;&#22312;&#32447;&#24179;&#21488;&#19978;&#20869;&#23481;&#21019;&#20316;&#32773;&#28608;&#21169;&#26426;&#21046;&#30340;&#24314;&#27169;&#65292;&#36890;&#36807;&#20998;&#26512;&#31639;&#27861;&#36873;&#25321;&#23545;&#26333;&#20809;&#28216;&#25103;&#65288;&#21253;&#25324;&#29616;&#20195;&#20998;&#35299;&#21644;&#20004;&#22612;&#26550;&#26500;&#65289;&#20013;&#65288;&#32435;&#20160;&#65289;&#22343;&#34913;&#30340;&#24433;&#21709;&#65292;&#25552;&#20986;&#20102;&#20351;&#29992;&#26333;&#20809;&#28216;&#25103;&#27169;&#22411;&#36827;&#34892;&#39044;&#37096;&#32626;&#23457;&#35745;&#30340;&#26041;&#27861;&#65292;&#20197;&#35782;&#21035;&#26399;&#26395;&#21644;&#28608;&#21169;&#20869;&#23481;&#20043;&#38388;&#30340;&#19981;&#21305;&#37197;&#12290;</title><link>http://arxiv.org/abs/2206.13102</link><description>&lt;p&gt;
&#22312;&#31639;&#27861;&#31574;&#21010;&#24179;&#21488;&#19978;&#24314;&#27169;&#20869;&#23481;&#21019;&#20316;&#32773;&#30340;&#28608;&#21169;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
Modeling Content Creator Incentives on Algorithm-Curated Platforms. (arXiv:2206.13102v2 [cs.GT] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.13102
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#35752;&#35770;&#20102;&#22312;&#32447;&#24179;&#21488;&#19978;&#20869;&#23481;&#21019;&#20316;&#32773;&#28608;&#21169;&#26426;&#21046;&#30340;&#24314;&#27169;&#65292;&#36890;&#36807;&#20998;&#26512;&#31639;&#27861;&#36873;&#25321;&#23545;&#26333;&#20809;&#28216;&#25103;&#65288;&#21253;&#25324;&#29616;&#20195;&#20998;&#35299;&#21644;&#20004;&#22612;&#26550;&#26500;&#65289;&#20013;&#65288;&#32435;&#20160;&#65289;&#22343;&#34913;&#30340;&#24433;&#21709;&#65292;&#25552;&#20986;&#20102;&#20351;&#29992;&#26333;&#20809;&#28216;&#25103;&#27169;&#22411;&#36827;&#34892;&#39044;&#37096;&#32626;&#23457;&#35745;&#30340;&#26041;&#27861;&#65292;&#20197;&#35782;&#21035;&#26399;&#26395;&#21644;&#28608;&#21169;&#20869;&#23481;&#20043;&#38388;&#30340;&#19981;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20869;&#23481;&#21019;&#20316;&#32773;&#22312;&#20105;&#22842;&#29992;&#25143;&#27880;&#24847;&#21147;&#12290;&#20182;&#20204;&#30340;&#24433;&#21709;&#21147;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#21462;&#20915;&#20110;&#22312;&#32447;&#24179;&#21488;&#24320;&#21457;&#32773;&#25152;&#20570;&#30340;&#31639;&#27861;&#36873;&#25321;&#12290;&#20026;&#20102;&#26368;&#22823;&#38480;&#24230;&#22320;&#25552;&#39640;&#26333;&#20809;&#29575;&#65292;&#35768;&#22810;&#21019;&#20316;&#32773;&#37319;&#21462;&#25112;&#30053;&#24615;&#30340;&#35843;&#25972;&#65292;&#22914;&#25628;&#32034;&#24341;&#25806;&#20248;&#21270;&#34892;&#19994;&#30340;&#20363;&#23376;&#25152;&#35777;&#26126;&#12290;&#36825;&#23548;&#33268;&#20102;&#23545;&#26377;&#38480;&#29992;&#25143;&#27880;&#24847;&#21147;&#27744;&#30340;&#31454;&#20105;&#12290;&#25105;&#20204;&#22312;&#25152;&#35859;&#30340;&#26333;&#20809;&#28216;&#25103;&#20013;&#24418;&#24335;&#21270;&#20102;&#36825;&#20123;&#21160;&#24577;&#65292;&#36825;&#26159;&#19968;&#31181;&#30001;&#31639;&#27861;&#24341;&#36215;&#30340;&#28608;&#21169;&#27169;&#22411;&#65292;&#20854;&#20013;&#21253;&#25324;&#29616;&#20195;&#20998;&#35299;&#21644;&#65288;&#28145;&#23618;&#65289;&#20004;&#22612;&#26550;&#26500;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#30475;&#20284;&#26080;&#23475;&#30340;&#31639;&#27861;&#36873;&#25321;&#65292;&#20363;&#22914;&#38750;&#36127;&#19982;&#26080;&#32422;&#26463;&#20998;&#35299;&#65292;&#22312;&#26333;&#20809;&#28216;&#25103;&#20013;&#26174;&#33879;&#24433;&#21709;&#65288;&#32435;&#20160;&#65289;&#22343;&#34913;&#30340;&#23384;&#22312;&#21644;&#29305;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#21019;&#20316;&#32773;&#34892;&#20026;&#27169;&#22411;&#65292;&#22914;&#26333;&#20809;&#28216;&#25103;&#65292;&#36827;&#34892;&#65288;ex-ante&#65289;&#39044;&#37096;&#32626;&#23457;&#35745;&#12290;&#36825;&#26679;&#30340;&#23457;&#35745;&#21487;&#20197;&#35782;&#21035;&#26399;&#26395;&#21644;&#28608;&#21169;&#20869;&#23481;&#20043;&#38388;&#30340;&#19981;&#21305;&#37197;&#65292;&#24182;&#22312;&#20869;&#23481;&#36807;&#28388;&#21644;&#31649;&#29702;&#31561;&#20107;&#21518;&#25514;&#26045;&#19978;&#36827;&#34892;&#34917;&#20805;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20123;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;
Content creators compete for user attention. Their reach crucially depends on algorithmic choices made by developers on online platforms. To maximize exposure, many creators adapt strategically, as evidenced by examples like the sprawling search engine optimization industry. This begets competition for the finite user attention pool. We formalize these dynamics in what we call an exposure game, a model of incentives induced by algorithms, including modern factorization and (deep) two-tower architectures. We prove that seemingly innocuous algorithmic choices, e.g., non-negative vs. unconstrained factorization, significantly affect the existence and character of (Nash) equilibria in exposure games. We proffer use of creator behavior models, like exposure games, for an (ex-ante) pre-deployment audit. Such an audit can identify misalignment between desirable and incentivized content, and thus complement post-hoc measures like content filtering and moderation. To this end, we propose tools 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20174;&#35270;&#35273;&#35266;&#23519;&#20013;&#30340;&#25361;&#25112;&#21644;&#26426;&#36935;&#65292;&#38024;&#23545;&#36825;&#19968;&#22797;&#26434;&#39046;&#22495;&#24314;&#31435;&#20102;&#35270;&#35273;&#39046;&#22495;&#20013;&#36830;&#32493;&#25511;&#21046;&#30340;&#31616;&#21333;&#22522;&#20934;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#31995;&#21015;&#22522;&#20934;&#20219;&#21153;&#65292;&#20197;&#26356;&#22909;&#22320;&#34920;&#31034;&#29616;&#23454;&#19990;&#30028;&#31163;&#32447;RL&#38382;&#39064;&#20013;&#30340;&#25968;&#25454;&#20998;&#24067;&#65292;&#24182;&#36890;&#36807;&#23545;&#20004;&#31181;&#22522;&#20110;&#35270;&#35273;&#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#30340;&#31616;&#21333;&#20462;&#25913;&#36827;&#34892;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2206.04779</link><description>&lt;p&gt;
&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20174;&#35270;&#35273;&#35266;&#23519;&#20013;&#30340;&#25361;&#25112;&#21644;&#26426;&#36935;
&lt;/p&gt;
&lt;p&gt;
Challenges and Opportunities in Offline Reinforcement Learning from Visual Observations. (arXiv:2206.04779v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.04779
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20174;&#35270;&#35273;&#35266;&#23519;&#20013;&#30340;&#25361;&#25112;&#21644;&#26426;&#36935;&#65292;&#38024;&#23545;&#36825;&#19968;&#22797;&#26434;&#39046;&#22495;&#24314;&#31435;&#20102;&#35270;&#35273;&#39046;&#22495;&#20013;&#36830;&#32493;&#25511;&#21046;&#30340;&#31616;&#21333;&#22522;&#20934;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#31995;&#21015;&#22522;&#20934;&#20219;&#21153;&#65292;&#20197;&#26356;&#22909;&#22320;&#34920;&#31034;&#29616;&#23454;&#19990;&#30028;&#31163;&#32447;RL&#38382;&#39064;&#20013;&#30340;&#25968;&#25454;&#20998;&#24067;&#65292;&#24182;&#36890;&#36807;&#23545;&#20004;&#31181;&#22522;&#20110;&#35270;&#35273;&#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#30340;&#31616;&#21333;&#20462;&#25913;&#36827;&#34892;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#24050;&#32463;&#23637;&#29616;&#20102;&#22312;&#21033;&#29992;&#22823;&#35268;&#27169;&#39044;&#20808;&#25910;&#38598;&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#31574;&#30053;&#23398;&#20064;&#26041;&#38754;&#30340;&#24040;&#22823;&#28508;&#21147;&#65292;&#20351;&#24471;Agent&#21487;&#20197;&#36991;&#20813;&#36890;&#24120;&#36153;&#26102;&#26114;&#36149;&#30340;&#22312;&#32447;&#25968;&#25454;&#25910;&#38598;&#12290;&#28982;&#32780;&#65292;&#22312;&#36830;&#32493;&#21160;&#20316;&#31354;&#38388;&#20013;&#65292;&#22522;&#20110;&#35270;&#35273;&#35266;&#23519;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20173;&#28982;&#26410;&#34987;&#20805;&#20998;&#25506;&#32034;&#65292;&#22312;&#36825;&#20010;&#22797;&#26434;&#30340;&#39046;&#22495;&#20013;&#23545;&#20851;&#38190;&#25361;&#25112;&#30340;&#29702;&#35299;&#26377;&#38480;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20026;&#35270;&#35273;&#39046;&#22495;&#20013;&#30340;&#36830;&#32493;&#25511;&#21046;&#24314;&#31435;&#31616;&#21333;&#30340;&#22522;&#20934;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31995;&#21015;&#38024;&#23545;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#22522;&#20934;&#20219;&#21153;&#65292;&#36825;&#20123;&#20219;&#21153;&#26088;&#22312;&#26356;&#22909;&#22320;&#34920;&#31034;&#29616;&#23454;&#19990;&#30028;&#31163;&#32447;RL&#38382;&#39064;&#20013;&#23384;&#22312;&#30340;&#25968;&#25454;&#20998;&#24067;&#65292;&#24182;&#21463;&#31163;&#32447;RL&#20174;&#35270;&#35273;&#35266;&#23519;&#20013;&#30340;&#19968;&#32452;&#26399;&#26395;&#25152;&#25351;&#23548;&#65292;&#21253;&#25324;&#23545;&#35270;&#35273;&#24178;&#25200;&#30340;&#31283;&#20581;&#24615;&#21644;&#21160;&#21147;&#23398;&#20013;&#21487;&#35270;&#21270;&#21464;&#21270;&#30340;&#35782;&#21035;&#33021;&#21147;&#12290;&#36890;&#36807;&#20351;&#29992;&#36825;&#22871;&#22522;&#20934;&#20219;&#21153;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23545;&#20004;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#22522;&#20110;&#35270;&#35273;&#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;DreamerV2&#21644;DrQ-v2&#36827;&#34892;&#31616;&#21333;&#20462;&#25913;&#30340;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Offline reinforcement learning has shown great promise in leveraging large pre-collected datasets for policy learning, allowing agents to forgo often-expensive online data collection. However, offline reinforcement learning from visual observations with continuous action spaces remains under-explored, with a limited understanding of the key challenges in this complex domain. In this paper, we establish simple baselines for continuous control in the visual domain and introduce a suite of benchmarking tasks for offline reinforcement learning from visual observations designed to better represent the data distributions present in real-world offline RL problems and guided by a set of desiderata for offline RL from visual observations, including robustness to visual distractions and visually identifiable changes in dynamics. Using this suite of benchmarking tasks, we show that simple modifications to two popular vision-based online reinforcement learning algorithms, DreamerV2 and DrQ-v2, suf
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20174;&#39640;&#32500;&#22122;&#22768;&#25968;&#25454;&#20013;&#23398;&#20064;&#20302;&#32500;&#38750;&#32447;&#24615;&#32467;&#26500;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20351;&#29992;&#33258;&#36866;&#24212;&#24102;&#23485;&#36873;&#25321;&#36807;&#31243;&#65292;&#24182;&#33719;&#24471;&#20102;&#29702;&#35770;&#19978;&#30340;&#25910;&#25947;&#24615;&#35777;&#26126;&#12290;&#31639;&#27861;&#30340;&#20302;&#32500;&#23884;&#20837;&#32467;&#26524;&#21487;&#29992;&#20110;&#25968;&#25454;&#21487;&#35270;&#21270;&#12289;&#32858;&#31867;&#21644;&#39044;&#27979;&#31561;&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2203.00126</link><description>&lt;p&gt;
&#20174;&#39640;&#32500;&#22122;&#22768;&#25968;&#25454;&#20013;&#23398;&#20064;&#20302;&#32500;&#38750;&#32447;&#24615;&#32467;&#26500;&#65306;&#19968;&#31181;&#31215;&#20998;&#31639;&#23376;&#26041;&#27861;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Learning Low-Dimensional Nonlinear Structures from High-Dimensional Noisy Data: An Integral Operator Approach. (arXiv:2203.00126v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.00126
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20174;&#39640;&#32500;&#22122;&#22768;&#25968;&#25454;&#20013;&#23398;&#20064;&#20302;&#32500;&#38750;&#32447;&#24615;&#32467;&#26500;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20351;&#29992;&#33258;&#36866;&#24212;&#24102;&#23485;&#36873;&#25321;&#36807;&#31243;&#65292;&#24182;&#33719;&#24471;&#20102;&#29702;&#35770;&#19978;&#30340;&#25910;&#25947;&#24615;&#35777;&#26126;&#12290;&#31639;&#27861;&#30340;&#20302;&#32500;&#23884;&#20837;&#32467;&#26524;&#21487;&#29992;&#20110;&#25968;&#25454;&#21487;&#35270;&#21270;&#12289;&#32858;&#31867;&#21644;&#39044;&#27979;&#31561;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26680;&#35889;&#23884;&#20837;&#31639;&#27861;&#65292;&#29992;&#20110;&#20174;&#39640;&#32500;&#22122;&#22768;&#35266;&#27979;&#20013;&#23398;&#20064;&#20302;&#32500;&#38750;&#32447;&#24615;&#32467;&#26500;&#65292;&#20854;&#20013;&#20551;&#35774;&#25968;&#25454;&#38598;&#20174;&#26412;&#36136;&#19978;&#26159;&#19968;&#20010;&#20302;&#32500;&#27969;&#24418;&#65292;&#24182;&#21463;&#21040;&#39640;&#32500;&#22122;&#22768;&#30340;&#27745;&#26579;&#12290;&#35813;&#31639;&#27861;&#37319;&#29992;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#24102;&#23485;&#36873;&#25321;&#36807;&#31243;&#65292;&#19981;&#20381;&#36182;&#20110;&#23545;&#24213;&#23618;&#27969;&#24418;&#30340;&#20808;&#39564;&#30693;&#35782;&#12290;&#25152;&#33719;&#24471;&#30340;&#20302;&#32500;&#23884;&#20837;&#36824;&#21487;&#20197;&#36827;&#19968;&#27493;&#29992;&#20110;&#25968;&#25454;&#21487;&#35270;&#21270;&#12289;&#32858;&#31867;&#21644;&#39044;&#27979;&#31561;&#19979;&#28216;&#20219;&#21153;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#29702;&#35770;&#19978;&#24471;&#21040;&#20102;&#35777;&#26126;&#65292;&#24182;&#19988;&#20855;&#26377;&#23454;&#38469;&#21487;&#35299;&#37322;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#22312;&#26679;&#26412;&#30340;&#32500;&#24230;&#21644;&#22823;&#23567;&#30456;&#23545;&#36739;&#22823;&#26102;&#65292;&#24314;&#31435;&#20102;&#26368;&#32456;&#23884;&#20837;&#21040;&#26080;&#22122;&#22768;&#23545;&#24212;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#21051;&#30011;&#20102;&#20449;&#22122;&#27604;&#23545;&#25910;&#25947;&#36895;&#24230;&#21644;&#30456;&#21464;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#23884;&#20837;&#21040;&#30001;&#26680;&#23450;&#20041;&#30340;&#31215;&#20998;&#31639;&#23376;&#30340;&#29305;&#24449;&#20989;&#25968;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a kernel-spectral embedding algorithm for learning low-dimensional nonlinear structures from high-dimensional and noisy observations, where the datasets are assumed to be sampled from an intrinsically low-dimensional manifold and corrupted by high-dimensional noise. The algorithm employs an adaptive bandwidth selection procedure which does not rely on prior knowledge of the underlying manifold. The obtained low-dimensional embeddings can be further utilized for downstream purposes such as data visualization, clustering and prediction. Our method is theoretically justified and practically interpretable. Specifically, we establish the convergence of the final embeddings to their noiseless counterparts when the dimension and size of the samples are comparably large, and characterize the effect of the signal-to-noise ratio on the rate of convergence and phase transition. We also prove convergence of the embeddings to the eigenfunctions of an integral operator defined by the kern
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23558;&#29616;&#26377;&#30340;&#31038;&#21306;&#26816;&#27979;&#26041;&#27861;&#26681;&#25454;&#30446;&#26631;&#20998;&#20026;&#25551;&#36848;&#24615;&#21644;&#25512;&#29702;&#24615;&#12290;&#25551;&#36848;&#24615;&#26041;&#27861;&#22522;&#20110;&#19978;&#19979;&#25991;&#30456;&#20851;&#30340;&#31038;&#21306;&#32467;&#26500;&#21457;&#29616;&#32593;&#32476;&#27169;&#24335;&#65292;&#32780;&#25512;&#29702;&#24615;&#26041;&#27861;&#36890;&#36807;&#29983;&#25104;&#27169;&#22411;&#25311;&#21512;&#25968;&#25454;&#65292;&#25581;&#31034;&#32593;&#32476;&#24418;&#25104;&#26426;&#21046;&#24182;&#20998;&#31163;&#32467;&#26500;&#21644;&#38543;&#26426;&#24615;&#12290;</title><link>http://arxiv.org/abs/2112.00183</link><description>&lt;p&gt;
&#22312;&#32593;&#32476;&#20013;&#30340;&#25551;&#36848;&#24615;&#19982;&#25512;&#29702;&#24615;&#31038;&#21306;&#26816;&#27979;&#65306;&#38519;&#38449;&#12289;&#35823;&#35299;&#21644;&#21322;&#30495;&#30456;
&lt;/p&gt;
&lt;p&gt;
Descriptive vs. inferential community detection in networks: pitfalls, myths, and half-truths. (arXiv:2112.00183v7 [physics.soc-ph] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.00183
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#29616;&#26377;&#30340;&#31038;&#21306;&#26816;&#27979;&#26041;&#27861;&#26681;&#25454;&#30446;&#26631;&#20998;&#20026;&#25551;&#36848;&#24615;&#21644;&#25512;&#29702;&#24615;&#12290;&#25551;&#36848;&#24615;&#26041;&#27861;&#22522;&#20110;&#19978;&#19979;&#25991;&#30456;&#20851;&#30340;&#31038;&#21306;&#32467;&#26500;&#21457;&#29616;&#32593;&#32476;&#27169;&#24335;&#65292;&#32780;&#25512;&#29702;&#24615;&#26041;&#27861;&#36890;&#36807;&#29983;&#25104;&#27169;&#22411;&#25311;&#21512;&#25968;&#25454;&#65292;&#25581;&#31034;&#32593;&#32476;&#24418;&#25104;&#26426;&#21046;&#24182;&#20998;&#31163;&#32467;&#26500;&#21644;&#38543;&#26426;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#21306;&#26816;&#27979;&#26159;&#32593;&#32476;&#31185;&#23398;&#20013;&#26368;&#37325;&#35201;&#30340;&#26041;&#27861;&#23398;&#39046;&#22495;&#20043;&#19968;&#65292;&#36807;&#21435;&#20960;&#21313;&#24180;&#26469;&#24341;&#36215;&#20102;&#30456;&#24403;&#22823;&#30340;&#20851;&#27880;&#12290;&#35813;&#39046;&#22495;&#28041;&#21450;&#23558;&#32593;&#32476;&#33258;&#21160;&#21010;&#20998;&#20026;&#22522;&#26412;&#26500;&#24314;&#22359;&#65292;&#20197;&#25552;&#20379;&#20854;&#22823;&#35268;&#27169;&#32467;&#26500;&#30340;&#25688;&#35201;&#12290;&#23613;&#31649;&#20854;&#37325;&#35201;&#24615;&#21644;&#24191;&#27867;&#24212;&#29992;&#65292;&#20294;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#30446;&#21069;&#30340;&#26041;&#27861;&#19982;&#34987;&#35748;&#20026;&#26159;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#20043;&#38388;&#23384;&#22312;&#26126;&#26174;&#24046;&#36317;&#12290;&#26412;&#25991;&#35797;&#22270;&#36890;&#36807;&#23558;&#29616;&#26377;&#26041;&#27861;&#20998;&#20026;&#8220;&#25551;&#36848;&#24615;&#8221;&#21644;&#8220;&#25512;&#29702;&#24615;&#8221;&#30446;&#26631;&#26469;&#35299;&#20915;&#36825;&#19968;&#24046;&#36317;&#12290;&#25551;&#36848;&#24615;&#26041;&#27861;&#26681;&#25454;&#20381;&#36182;&#20110;&#19978;&#19979;&#25991;&#30340;&#31038;&#21306;&#32467;&#26500;&#27010;&#24565;&#22312;&#32593;&#32476;&#20013;&#21457;&#29616;&#27169;&#24335;&#65292;&#32780;&#25512;&#29702;&#24615;&#26041;&#27861;&#26500;&#24314;&#29983;&#25104;&#27169;&#22411;&#65292;&#24182;&#23581;&#35797;&#23558;&#20854;&#25311;&#21512;&#21040;&#25968;&#25454;&#20013;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#24335;&#65292;&#23427;&#20204;&#33021;&#22815;&#25581;&#31034;&#32593;&#32476;&#24418;&#25104;&#30340;&#26426;&#21046;&#65292;&#24182;&#23558;&#32467;&#26500;&#19982;&#38543;&#26426;&#24615;&#20998;&#31163;&#24320;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;
Community detection is one of the most important methodological fields of network science, and one which has attracted a significant amount of attention over the past decades. This area deals with the automated division of a network into fundamental building blocks, with the objective of providing a summary of its large-scale structure. Despite its importance and widespread adoption, there is a noticeable gap between what is arguably the state-of-the-art and the methods that are actually used in practice in a variety of fields. Here we attempt to address this discrepancy by dividing existing methods according to whether they have a "descriptive" or an "inferential" goal. While descriptive methods find patterns in networks based on context-dependent notions of community structure, inferential methods articulate generative models, and attempt to fit them to data. In this way, they are able to provide insights into the mechanisms of network formation, and separate structure from randomnes
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20998;&#26512;&#20102;&#39640;&#26031;&#21464;&#20998;&#25512;&#26029;&#21644;&#25289;&#26222;&#25289;&#26031;&#36817;&#20284;&#30340;&#28176;&#36817;&#20984;&#24615;&#29305;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#20010;&#31639;&#27861;&#65288;CLA&#21644;CSVI&#65289;&#26469;&#21033;&#29992;&#36825;&#20123;&#29305;&#24615;&#12290;</title><link>http://arxiv.org/abs/2104.05886</link><description>&lt;p&gt;
&#39640;&#26031;&#21464;&#20998;&#25512;&#26029;&#21644;&#25289;&#26222;&#25289;&#26031;&#36817;&#20284;&#30340;&#35745;&#31639;&#28176;&#36817;&#29305;&#24615;
&lt;/p&gt;
&lt;p&gt;
The computational asymptotics of Gaussian variational inference and the Laplace approximation. (arXiv:2104.05886v3 [stat.CO] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2104.05886
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20998;&#26512;&#20102;&#39640;&#26031;&#21464;&#20998;&#25512;&#26029;&#21644;&#25289;&#26222;&#25289;&#26031;&#36817;&#20284;&#30340;&#28176;&#36817;&#20984;&#24615;&#29305;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#20010;&#31639;&#27861;&#65288;CLA&#21644;CSVI&#65289;&#26469;&#21033;&#29992;&#36825;&#20123;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#21464;&#20998;&#25512;&#26029;&#21644;&#25289;&#26222;&#25289;&#26031;&#36817;&#20284;&#26159;&#29992;&#31616;&#21333;&#19988;&#21487;&#25193;&#23637;&#30340;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#23558;&#36125;&#21494;&#26031;&#21518;&#39564;&#25512;&#26029;&#34920;&#36848;&#20026;&#20248;&#21270;&#38382;&#39064;&#30340;&#27969;&#34892;&#26367;&#20195;&#26041;&#27861;&#65292;&#28982;&#32780;&#65292;&#36825;&#20004;&#31181;&#26041;&#27861;&#30340;&#20851;&#38190;&#38480;&#21046;&#26159;&#20248;&#21270;&#38382;&#39064;&#30340;&#35299;&#36890;&#24120;&#26159;&#26080;&#27861;&#35745;&#31639;&#30340;&#65307;&#21363;&#20351;&#22312;&#31616;&#21333;&#30340;&#24773;&#20917;&#19979;&#65292;&#38382;&#39064;&#20063;&#26159;&#38750;&#20984;&#30340;&#12290;&#22240;&#27492;&#65292;&#26368;&#36817;&#21457;&#23637;&#30340;&#32479;&#35745;&#20445;&#35777; -- &#25152;&#26377;&#37117;&#28041;&#21450;&#21040;&#20840;&#23616;&#26368;&#20248;&#20540;&#30340;&#65288;&#25968;&#25454;&#65289;&#28176;&#36817;&#24615;&#36136; -- &#22312;&#23454;&#36341;&#20013;&#24182;&#19981;&#21487;&#38752;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20004;&#20010;&#37325;&#35201;&#30340;&#36129;&#29486;&#65306;&#23545;&#39640;&#26031;&#26063;&#21464;&#20998;&#25512;&#26029;&#21644;&#25289;&#26222;&#25289;&#26031;&#36817;&#20284;&#25152;&#38656;&#30340;&#26368;&#22823;&#21518;&#39564;&#27010;&#29575; (MAP) &#38382;&#39064;&#30340;&#28176;&#36817;&#20984;&#24615;&#24615;&#36136;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65307;&#24182;&#25552;&#20986;&#20102;&#20004;&#20010;&#31639;&#27861; -- &#19968;&#33268;&#25289;&#26222;&#25289;&#26031;&#36817;&#20284; (CLA) &#21644;&#19968;&#33268;&#38543;&#26426;&#21464;&#20998;&#25512;&#26029; (CSVI) -- &#21033;&#29992;&#36825;&#20123;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian variational inference and the Laplace approximation are popular alternatives to Markov chain Monte Carlo that formulate Bayesian posterior inference as an optimization problem, enabling the use of simple and scalable stochastic optimization algorithms. However, a key limitation of both methods is that the solution to the optimization problem is typically not tractable to compute; even in simple settings the problem is nonconvex. Thus, recently developed statistical guarantees -- which all involve the (data) asymptotic properties of the global optimum -- are not reliably obtained in practice. In this work, we provide two major contributions: a theoretical analysis of the asymptotic convexity properties of variational inference with a Gaussian family and the maximum a posteriori (MAP) problem required by the Laplace approximation; and two algorithms -- consistent Laplace approximation (CLA) and consistent stochastic variational inference (CSVI) -- that exploit these properties t
&lt;/p&gt;</description></item></channel></rss>