<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#32447;&#24615;&#27169;&#22411;&#30340;&#40065;&#26834;&#22240;&#26524;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#22797;&#26434;&#31995;&#32479;&#30340;&#24773;&#20917;&#19979;&#65292;&#29616;&#26377;&#26041;&#27861;&#26080;&#27861;&#20445;&#25345;&#36951;&#25022;&#27425;&#32447;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.19794</link><description>&lt;p&gt;
&#32447;&#24615;&#27169;&#22411;&#30340;&#40065;&#26834;&#22240;&#26524;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Robust Causal Bandits for Linear Models. (arXiv:2310.19794v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19794
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#32447;&#24615;&#27169;&#22411;&#30340;&#40065;&#26834;&#22240;&#26524;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#22797;&#26434;&#31995;&#32479;&#30340;&#24773;&#20917;&#19979;&#65292;&#29616;&#26377;&#26041;&#27861;&#26080;&#27861;&#20445;&#25345;&#36951;&#25022;&#27425;&#32447;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22240;&#26524;&#31995;&#32479;&#20013;&#65292;&#20248;&#21270;&#22238;&#25253;&#20989;&#25968;&#30340;&#39034;&#24207;&#23454;&#39564;&#35774;&#35745;&#21487;&#20197;&#26377;&#25928;&#22320;&#24314;&#27169;&#20026;&#22240;&#26524;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#39034;&#24207;&#24178;&#39044;&#35774;&#35745;&#12290;&#22312;&#24050;&#26377;&#30340;&#22240;&#26524;&#24378;&#21270;&#23398;&#20064;&#25991;&#29486;&#20013;&#65292;&#19968;&#20010;&#37325;&#35201;&#30340;&#20551;&#35774;&#26159;&#22240;&#26524;&#27169;&#22411;&#22312;&#26102;&#38388;&#19978;&#20445;&#25345;&#19981;&#21464;&#12290;&#28982;&#32780;&#65292;&#22312;&#22797;&#26434;&#31995;&#32479;&#20013;&#65292;&#25968;&#23398;&#27169;&#22411;&#24120;&#24120;&#21457;&#29983;&#26102;&#38388;&#19978;&#30340;&#27874;&#21160;&#65292;&#36825;&#20010;&#20551;&#35774;&#19981;&#19968;&#23450;&#25104;&#31435;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22240;&#26524;&#24378;&#21270;&#23398;&#20064;&#22312;&#27169;&#22411;&#27874;&#21160;&#23384;&#22312;&#19979;&#30340;&#40065;&#26834;&#24615;&#12290;&#37325;&#28857;&#30740;&#31350;&#20102;&#20855;&#26377;&#32447;&#24615;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411; (SEMs) &#30340;&#22240;&#26524;&#31995;&#32479;&#12290;SEMs &#21644;&#26102;&#38388;&#21464;&#21270;&#30340;&#24178;&#39044;&#21069;&#21518;&#32479;&#35745;&#27169;&#22411;&#22343;&#20026;&#26410;&#30693;&#12290;&#20197;&#32047;&#35745;&#36951;&#25022;&#20026;&#35774;&#35745;&#25351;&#26631;&#65292;&#22312;&#30693;&#36947;&#25972;&#20010;&#22240;&#26524;&#27169;&#22411;&#21450;&#20854;&#27874;&#21160;&#24773;&#20917;&#30340;&#31070;&#35861;&#30340;&#22522;&#30784;&#19978;&#65292;&#35774;&#35745;&#19968;&#31995;&#21015;&#24178;&#39044;&#20351;&#24471;&#32047;&#35745;&#36951;&#25022;&#26368;&#23567;&#21270;&#12290;&#39318;&#20808;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#29616;&#26377;&#26041;&#27861;&#26080;&#27861;&#20445;&#25345;&#36951;&#25022;&#27425;&#32447;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sequential design of experiments for optimizing a reward function in causal systems can be effectively modeled by the sequential design of interventions in causal bandits (CBs). In the existing literature on CBs, a critical assumption is that the causal models remain constant over time. However, this assumption does not necessarily hold in complex systems, which constantly undergo temporal model fluctuations. This paper addresses the robustness of CBs to such model fluctuations. The focus is on causal systems with linear structural equation models (SEMs). The SEMs and the time-varying pre- and post-interventional statistical models are all unknown. Cumulative regret is adopted as the design criteria, based on which the objective is to design a sequence of interventions that incur the smallest cumulative regret with respect to an oracle aware of the entire causal model and its fluctuations. First, it is established that the existing approaches fail to maintain regret sub-linearity with 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#39640;&#32500;&#39640;&#26031;&#25968;&#25454;&#30340;&#22810;&#32034;&#24341;&#22238;&#24402;&#38382;&#39064;&#20013;&#65292;&#36890;&#36807;&#26799;&#24230;&#27969;&#23398;&#20064;&#20302;&#31209;&#32447;&#24615;&#25237;&#24433;&#21644;&#20302;&#32500;&#36830;&#25509;&#20989;&#25968;&#65292;&#24314;&#31435;&#20102;&#20840;&#23616;&#25910;&#25947;&#24615;&#21644;&#23450;&#37327;&#25551;&#36848;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.19793</link><description>&lt;p&gt;
&#20851;&#20110;&#20351;&#29992;&#26799;&#24230;&#27969;&#23398;&#20064;&#39640;&#26031;&#22810;&#32034;&#24341;&#27169;&#22411;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Learning Gaussian Multi-index Models with Gradient Flow. (arXiv:2310.19793v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19793
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#39640;&#32500;&#39640;&#26031;&#25968;&#25454;&#30340;&#22810;&#32034;&#24341;&#22238;&#24402;&#38382;&#39064;&#20013;&#65292;&#36890;&#36807;&#26799;&#24230;&#27969;&#23398;&#20064;&#20302;&#31209;&#32447;&#24615;&#25237;&#24433;&#21644;&#20302;&#32500;&#36830;&#25509;&#20989;&#25968;&#65292;&#24314;&#31435;&#20102;&#20840;&#23616;&#25910;&#25947;&#24615;&#21644;&#23450;&#37327;&#25551;&#36848;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#39640;&#32500;&#39640;&#26031;&#25968;&#25454;&#30340;&#22810;&#32034;&#24341;&#22238;&#24402;&#38382;&#39064;&#20013;&#30340;&#26799;&#24230;&#27969;&#12290;&#22810;&#32034;&#24341;&#20989;&#25968;&#30001;&#26410;&#30693;&#30340;&#20302;&#31209;&#32447;&#24615;&#25237;&#24433;&#21644;&#20219;&#24847;&#26410;&#30693;&#30340;&#20302;&#32500;&#36830;&#25509;&#20989;&#25968;&#32452;&#25104;&#12290;&#22240;&#27492;&#65292;&#23427;&#20204;&#26500;&#25104;&#20102;&#31070;&#32463;&#32593;&#32476;&#20013;&#29305;&#24449;&#23398;&#20064;&#30340;&#33258;&#28982;&#27169;&#26495;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#20004;&#26102;&#38388;&#23610;&#24230;&#30340;&#31639;&#27861;&#65292;&#20854;&#20013;&#20302;&#32500;&#36830;&#25509;&#20989;&#25968;&#36890;&#36807;&#38750;&#21442;&#25968;&#27169;&#22411;&#27604;&#21442;&#25968;&#21270;&#20302;&#31209;&#25237;&#24433;&#30340;&#20302;&#32500;&#31354;&#38388;&#26356;&#24555;&#22320;&#23398;&#20064;&#12290;&#36890;&#36807;&#36866;&#24403;&#22320;&#21033;&#29992;&#26694;&#26550;&#30340;&#30456;&#20851;&#30697;&#38453;&#19978;&#30340;&#30697;&#38453;&#21322;&#32676;&#32467;&#26500;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#30001;Grassmannian&#20154;&#21475;&#26799;&#24230;&#27969;&#21160;&#21147;&#23398;&#24341;&#36215;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#65292;&#24182;&#23545;&#20854;&#30456;&#20851;&#30340;&#8220;&#38797;&#28857;&#21040;&#38797;&#28857;&#8221;&#21160;&#21147;&#23398;&#25552;&#20379;&#20102;&#23450;&#37327;&#25551;&#36848;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#27599;&#20010;&#38797;&#30340;&#26102;&#38388;&#23610;&#24230;&#21487;&#20197;&#26126;&#30830;&#22320;&#29992;&#30446;&#26631;&#36830;&#25509;&#20989;&#25968;&#30340;&#36866;&#24403;Hermite&#20998;&#35299;&#26469;&#34920;&#24449;&#12290;&#19982;&#36825;&#20123;&#20301;&#32622;&#30456;&#21453;&#30340;&#26159;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study gradient flow on the multi-index regression problem for high-dimensional Gaussian data. Multi-index functions consist of a composition of an unknown low-rank linear projection and an arbitrary unknown, low-dimensional link function. As such, they constitute a natural template for feature learning in neural networks.  We consider a two-timescale algorithm, whereby the low-dimensional link function is learnt with a non-parametric model infinitely faster than the subspace parametrizing the low-rank projection. By appropriately exploiting the matrix semigroup structure arising over the subspace correlation matrices, we establish global convergence of the resulting Grassmannian population gradient flow dynamics, and provide a quantitative description of its associated `saddle-to-saddle' dynamics. Notably, the timescales associated with each saddle can be explicitly characterized in terms of an appropriate Hermite decomposition of the target link function. In contrast with these pos
&lt;/p&gt;</description></item><item><title>DiffEnc&#26159;&#19968;&#31181;&#20351;&#29992;&#23398;&#20064;&#30340;&#32534;&#30721;&#22120;&#30340;&#21464;&#20998;&#25193;&#25955;&#27169;&#22411;&#65292;&#36890;&#36807;&#24341;&#20837;&#25968;&#25454;&#21644;&#28145;&#24230;&#30456;&#20851;&#30340;&#22343;&#20540;&#20989;&#25968;&#21644;&#21487;&#35843;&#33410;&#30340;&#22122;&#22768;&#26041;&#24046;&#27604;&#29575;&#65292;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#21487;&#33021;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.19789</link><description>&lt;p&gt;
DiffEnc: &#20351;&#29992;&#23398;&#20064;&#30340;&#32534;&#30721;&#22120;&#30340;&#21464;&#20998;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
DiffEnc: Variational Diffusion with a Learned Encoder. (arXiv:2310.19789v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19789
&lt;/p&gt;
&lt;p&gt;
DiffEnc&#26159;&#19968;&#31181;&#20351;&#29992;&#23398;&#20064;&#30340;&#32534;&#30721;&#22120;&#30340;&#21464;&#20998;&#25193;&#25955;&#27169;&#22411;&#65292;&#36890;&#36807;&#24341;&#20837;&#25968;&#25454;&#21644;&#28145;&#24230;&#30456;&#20851;&#30340;&#22343;&#20540;&#20989;&#25968;&#21644;&#21487;&#35843;&#33410;&#30340;&#22122;&#22768;&#26041;&#24046;&#27604;&#29575;&#65292;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#21487;&#20197;&#30475;&#20316;&#26159;&#20855;&#26377;&#20004;&#31181;&#25913;&#36827;&#30340;&#20998;&#23618;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAEs&#65289;&#65306;&#22312;&#29983;&#25104;&#36807;&#31243;&#20013;&#21442;&#25968;&#20849;&#20139;&#30340;&#26465;&#20214;&#20998;&#24067;&#21644;&#22312;&#23618;&#27425;&#32467;&#26500;&#19978;&#29420;&#31435;&#35745;&#31639;&#25439;&#22833;&#12290;&#25105;&#20204;&#23545;&#25193;&#25955;&#27169;&#22411;&#36827;&#34892;&#20102;&#20004;&#20010;&#21464;&#21270;&#65292;&#20445;&#30041;&#20102;&#36825;&#20123;&#20248;&#21183;&#30340;&#21516;&#26102;&#22686;&#21152;&#20102;&#27169;&#22411;&#30340;&#28789;&#27963;&#24615;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#22312;&#25193;&#25955;&#36807;&#31243;&#20013;&#24341;&#20837;&#20102;&#19968;&#20010;&#19982;&#25968;&#25454;&#21644;&#28145;&#24230;&#30456;&#20851;&#30340;&#22343;&#20540;&#20989;&#25968;&#65292;&#20174;&#32780;&#23548;&#33268;&#20102;&#20462;&#25913;&#21518;&#30340;&#25193;&#25955;&#25439;&#22833;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;DiffEnc&#22312;CIFAR-10&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#21487;&#33021;&#24615;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#35753;&#21453;&#21521;&#32534;&#30721;&#36807;&#31243;&#30340;&#22122;&#22768;&#26041;&#24046;&#19982;&#29983;&#25104;&#36807;&#31243;&#30340;&#27604;&#29575;&#25104;&#20026;&#19968;&#20010;&#33258;&#30001;&#30340;&#26435;&#37325;&#21442;&#25968;&#65292;&#32780;&#19981;&#26159;&#22266;&#23450;&#20026;1&#12290;&#36825;&#24102;&#26469;&#20102;&#29702;&#35770;&#19978;&#30340;&#27934;&#23519;&#21147;&#65306;&#23545;&#20110;&#26377;&#38480;&#28145;&#24230;&#23618;&#27425;&#65292;&#35777;&#25454;&#19979;&#30028;&#65288;ELBO&#65289;&#21487;&#20197;&#29992;&#20316;&#21152;&#26435;&#25193;&#25955;&#25439;&#22833;&#26041;&#27861;&#30340;&#30446;&#26631;&#65292;&#24182;&#29992;&#20110;&#19987;&#38376;&#20026;&#25512;&#29702;&#32780;&#20248;&#21270;&#22122;&#22768;&#35843;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models may be viewed as hierarchical variational autoencoders (VAEs) with two improvements: parameter sharing for the conditional distributions in the generative process and efficient computation of the loss as independent terms over the hierarchy. We consider two changes to the diffusion model that retain these advantages while adding flexibility to the model. Firstly, we introduce a data- and depth-dependent mean function in the diffusion process, which leads to a modified diffusion loss. Our proposed framework, DiffEnc, achieves state-of-the-art likelihood on CIFAR-10. Secondly, we let the ratio of the noise variance of the reverse encoder process and the generative process be a free weight parameter rather than being fixed to 1. This leads to theoretical insights: For a finite depth hierarchy, the evidence lower bound (ELBO) can be used as an objective for a weighted diffusion loss approach and for optimizing the noise schedule specifically for inference. For the infinite
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#35299;&#20915;&#20102;&#35782;&#21035;&#20855;&#26377;&#26368;&#39640;&#39044;&#26399;&#25928;&#26524;&#30340;&#27835;&#30103;&#26041;&#26696;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20855;&#26377;&#22266;&#23450;&#39044;&#31639;&#30340;&#23616;&#37096;&#26368;&#20248;&#31639;&#27861;&#26469;&#38477;&#20302;&#38169;&#35823;&#35782;&#21035;&#30340;&#27010;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.19788</link><description>&lt;p&gt;
&#20855;&#26377;&#22266;&#23450;&#39044;&#31639;&#30340;&#23616;&#37096;&#26368;&#20248;&#26368;&#20339;&#33218;&#35782;&#21035;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Locally Optimal Best Arm Identification with a Fixed Budget. (arXiv:2310.19788v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19788
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#35299;&#20915;&#20102;&#35782;&#21035;&#20855;&#26377;&#26368;&#39640;&#39044;&#26399;&#25928;&#26524;&#30340;&#27835;&#30103;&#26041;&#26696;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20855;&#26377;&#22266;&#23450;&#39044;&#31639;&#30340;&#23616;&#37096;&#26368;&#20248;&#31639;&#27861;&#26469;&#38477;&#20302;&#38169;&#35823;&#35782;&#21035;&#30340;&#27010;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#35782;&#21035;&#26368;&#20339;&#27835;&#30103;&#26041;&#26696;&#30340;&#38382;&#39064;&#65292;&#21363;&#20855;&#26377;&#26368;&#39640;&#39044;&#26399;&#25928;&#26524;&#30340;&#27835;&#30103;&#26041;&#26696;&#12290;&#25105;&#20204;&#26088;&#22312;&#36890;&#36807;&#38477;&#20302;&#38169;&#35823;&#35782;&#21035;&#30340;&#27010;&#29575;&#26469;&#30830;&#23450;&#26368;&#20339;&#27835;&#30103;&#26041;&#26696;&#65292;&#36825;&#19968;&#38382;&#39064;&#22312;&#35768;&#22810;&#30740;&#31350;&#39046;&#22495;&#20013;&#24050;&#34987;&#25506;&#32034;&#65292;&#21253;&#25324;&#26368;&#20339;&#33218;&#35782;&#21035;&#65288;Best Arm Identification&#65292;BAI&#65289;&#21644;&#24207;&#21015;&#20248;&#21270;&#12290;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#65292;&#27835;&#30103;&#20998;&#37197;&#30340;&#36718;&#25968;&#26159;&#22266;&#23450;&#30340;&#12290;&#22312;&#27599;&#19968;&#36718;&#20013;&#65292;&#20915;&#31574;&#32773;&#23558;&#19968;&#31181;&#27835;&#30103;&#26041;&#26696;&#20998;&#37197;&#32473;&#19968;&#20010;&#23454;&#39564;&#21333;&#20803;&#65292;&#24182;&#35266;&#23519;&#30456;&#24212;&#30340;&#32467;&#26524;&#65292;&#35813;&#32467;&#26524;&#36981;&#24490;&#19981;&#21516;&#27835;&#30103;&#26041;&#26696;&#20043;&#38388;&#26041;&#24046;&#19981;&#21516;&#30340;&#39640;&#26031;&#20998;&#24067;&#12290;&#22312;&#23454;&#39564;&#32467;&#26463;&#26102;&#65292;&#25105;&#20204;&#26681;&#25454;&#35266;&#23519;&#32467;&#26524;&#25512;&#33616;&#19968;&#31181;&#27835;&#30103;&#26041;&#26696;&#20316;&#20026;&#26368;&#20339;&#27835;&#30103;&#26041;&#26696;&#30340;&#20272;&#35745;&#20540;&#12290;&#20915;&#31574;&#32773;&#30340;&#30446;&#26631;&#26159;&#35774;&#35745;&#19968;&#20010;&#23454;&#39564;&#65292;&#20351;&#38169;&#35823;&#35782;&#21035;&#26368;&#20339;&#27835;&#30103;&#26041;&#26696;&#30340;&#27010;&#29575;&#26368;&#23567;&#21270;&#12290;&#22522;&#20110;&#36825;&#19968;&#30446;&#26631;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#35823;&#35782;&#21035;&#27010;&#29575;&#30340;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study investigates the problem of identifying the best treatment arm, a treatment arm with the highest expected outcome. We aim to identify the best treatment arm with a lower probability of misidentification, which has been explored under various names across numerous research fields, including \emph{best arm identification} (BAI) and ordinal optimization. In our experiments, the number of treatment-allocation rounds is fixed. In each round, a decision-maker allocates a treatment arm to an experimental unit and observes a corresponding outcome, which follows a Gaussian distribution with a variance different among treatment arms. At the end of the experiment, we recommend one of the treatment arms as an estimate of the best treatment arm based on the observations. The objective of the decision-maker is to design an experiment that minimizes the probability of misidentifying the best treatment arm. With this objective in mind, we develop lower bounds for the probability of misident
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#25351;&#25968;&#26063;&#20998;&#24067;&#30340;&#40065;&#26834;&#20027;&#25104;&#20998;&#20998;&#26512;&#26041;&#27861;$e^{\text{RPCA}}$&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#24674;&#22797;&#20302;&#31209;&#32467;&#26500;&#24182;&#36827;&#34892;&#24322;&#24120;&#28857;&#30340;&#35782;&#21035;&#21644;&#22788;&#29702;&#12290;</title><link>http://arxiv.org/abs/2310.19787</link><description>&lt;p&gt;
$e^{\text{RPCA}}$&#65306;&#38024;&#23545;&#25351;&#25968;&#26063;&#20998;&#24067;&#30340;&#40065;&#26834;&#20027;&#25104;&#20998;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
$e^{\text{RPCA}}$: Robust Principal Component Analysis for Exponential Family Distributions. (arXiv:2310.19787v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19787
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#25351;&#25968;&#26063;&#20998;&#24067;&#30340;&#40065;&#26834;&#20027;&#25104;&#20998;&#20998;&#26512;&#26041;&#27861;$e^{\text{RPCA}}$&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#24674;&#22797;&#20302;&#31209;&#32467;&#26500;&#24182;&#36827;&#34892;&#24322;&#24120;&#28857;&#30340;&#35782;&#21035;&#21644;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#40065;&#26834;&#20027;&#25104;&#20998;&#20998;&#26512;(RPCA)&#26159;&#19968;&#31181;&#24191;&#27867;&#24212;&#29992;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#21463;&#21040;&#26174;&#33879;&#21644;&#31232;&#30095;&#24322;&#24120;&#25968;&#25454;&#24178;&#25200;&#30340;&#25968;&#25454;&#30697;&#38453;&#20013;&#24674;&#22797;&#20302;&#31209;&#32467;&#26500;&#12290;&#36825;&#20123;&#24322;&#24120;&#21487;&#33021;&#26469;&#33258;&#36974;&#25377;&#12289;&#24694;&#24847;&#31713;&#25913;&#25110;&#20854;&#20182;&#24322;&#24120;&#21407;&#22240;&#65292;&#23545;&#20110;&#36807;&#31243;&#30417;&#27979;&#21644;&#35786;&#26029;&#65292;&#32852;&#21512;&#35782;&#21035;&#36825;&#20123;&#24322;&#24120;&#19982;&#20302;&#31209;&#32972;&#26223;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;RPCA&#26041;&#27861;&#21450;&#20854;&#25193;&#23637;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#26410;&#32771;&#34385;&#25968;&#25454;&#30697;&#38453;&#30340;&#27010;&#29575;&#20998;&#24067;&#65292;&#32780;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#65292;&#36825;&#20123;&#20998;&#24067;&#26159;&#24050;&#30693;&#30340;&#19988;&#21487;&#33021;&#39640;&#24230;&#38750;&#39640;&#26031;&#30340;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;&#38754;&#21521;&#25351;&#25968;&#26063;&#20998;&#24067;&#30340;&#40065;&#26834;&#20027;&#25104;&#20998;&#20998;&#26512;($e^{\text{RPCA}}$)&#65292;&#21487;&#20197;&#22312;&#25351;&#25968;&#26063;&#20998;&#24067;&#20869;&#36827;&#34892;&#25152;&#38656;&#30340;&#20302;&#31209;&#21644;&#31232;&#30095;&#30697;&#38453;&#20998;&#35299;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20132;&#26367;&#26041;&#21521;&#20056;&#23376;&#20248;&#21270;&#31639;&#27861;&#65292;&#29992;&#20110;&#39640;&#25928;&#30340;$e^{\text{RPCA}}$&#20998;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Robust Principal Component Analysis (RPCA) is a widely used method for recovering low-rank structure from data matrices corrupted by significant and sparse outliers. These corruptions may arise from occlusions, malicious tampering, or other causes for anomalies, and the joint identification of such corruptions with low-rank background is critical for process monitoring and diagnosis. However, existing RPCA methods and their extensions largely do not account for the underlying probabilistic distribution for the data matrices, which in many applications are known and can be highly non-Gaussian. We thus propose a new method called Robust Principal Component Analysis for Exponential Family distributions ($e^{\text{RPCA}}$), which can perform the desired decomposition into low-rank and sparse matrices when such a distribution falls within the exponential family. We present a novel alternating direction method of multiplier optimization algorithm for efficient $e^{\text{RPCA}}$ decomposition
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#30340;&#26426;&#21046;&#21644;&#20998;&#26512;&#24072;&#30340;&#36873;&#25321;&#22914;&#20309;&#24433;&#21709;Rashomon&#27604;&#29575;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#20010;&#31216;&#20026;&#27169;&#24335;&#22810;&#26679;&#24615;&#30340;&#25351;&#26631;&#26469;&#34913;&#37327;&#19981;&#21516;&#20998;&#31867;&#22120;&#20043;&#38388;&#30340;&#39044;&#27979;&#24046;&#24322;&#12290;</title><link>http://arxiv.org/abs/2310.19726</link><description>&lt;p&gt;
&#36215;&#22987;&#20110;&#22122;&#22768;&#30340;&#31616;&#21270;&#27169;&#22411;&#20043;&#36335;
&lt;/p&gt;
&lt;p&gt;
A Path to Simpler Models Starts With Noise. (arXiv:2310.19726v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19726
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#30340;&#26426;&#21046;&#21644;&#20998;&#26512;&#24072;&#30340;&#36873;&#25321;&#22914;&#20309;&#24433;&#21709;Rashomon&#27604;&#29575;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#20010;&#31216;&#20026;&#27169;&#24335;&#22810;&#26679;&#24615;&#30340;&#25351;&#26631;&#26469;&#34913;&#37327;&#19981;&#21516;&#20998;&#31867;&#22120;&#20043;&#38388;&#30340;&#39044;&#27979;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Rashomon&#38598;&#21512;&#26159;&#22312;&#32473;&#23450;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#36817;&#20046;&#30456;&#31561;&#30340;&#27169;&#22411;&#38598;&#21512;&#65292;Rashomon&#27604;&#29575;&#26159;&#22312;&#32473;&#23450;&#20551;&#35774;&#31354;&#38388;&#20013;&#22788;&#20110;Rashomon&#38598;&#21512;&#20013;&#30340;&#27169;&#22411;&#25152;&#21344;&#27604;&#20363;&#12290;&#22312;&#21009;&#20107;&#21496;&#27861;&#12289;&#21307;&#30103;&#20445;&#20581;&#12289;&#36151;&#27454;&#12289;&#25945;&#32946;&#31561;&#39046;&#22495;&#30340;&#34920;&#26684;&#22411;&#25968;&#25454;&#38598;&#20013;&#65292;Rashomon&#27604;&#29575;&#36890;&#24120;&#24456;&#39640;&#65292;&#36825;&#23545;&#20110;&#31616;&#21333;&#27169;&#22411;&#26159;&#21542;&#33021;&#36798;&#21040;&#19982;&#26356;&#22797;&#26434;&#27169;&#22411;&#30456;&#21516;&#30340;&#20934;&#30830;&#24615;&#20855;&#26377;&#23454;&#38469;&#24433;&#21709;&#12290;&#19968;&#20010;&#24320;&#25918;&#30340;&#38382;&#39064;&#26159;&#20026;&#20160;&#20040;Rashomon&#27604;&#29575;&#36890;&#24120;&#20542;&#21521;&#20110;&#24456;&#39640;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#24182;&#30740;&#31350;&#20102;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#30340;&#26426;&#21046;&#65292;&#20197;&#21450;&#20998;&#26512;&#24072;&#22312;&#23398;&#20064;&#36807;&#31243;&#20013;&#36890;&#24120;&#36827;&#34892;&#30340;&#36873;&#25321;&#65292;&#36825;&#20915;&#23450;&#20102;Rashomon&#27604;&#29575;&#30340;&#22823;&#23567;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#26356;&#22024;&#26434;&#30340;&#25968;&#25454;&#38598;&#20250;&#36890;&#36807;&#20174;&#19994;&#32773;&#35757;&#32451;&#27169;&#22411;&#30340;&#26041;&#24335;&#23548;&#33268;&#26356;&#39640;&#30340;Rashomon&#27604;&#29575;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#31216;&#20026;&#27169;&#24335;&#22810;&#26679;&#24615;&#30340;&#25351;&#26631;&#65292;&#35813;&#25351;&#26631;&#25429;&#25417;&#20102;&#19981;&#21516;&#20998;&#31867;&#22120;&#20043;&#38388;&#39044;&#27979;&#30340;&#24179;&#22343;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Rashomon set is the set of models that perform approximately equally well on a given dataset, and the Rashomon ratio is the fraction of all models in a given hypothesis space that are in the Rashomon set. Rashomon ratios are often large for tabular datasets in criminal justice, healthcare, lending, education, and in other areas, which has practical implications about whether simpler models can attain the same level of accuracy as more complex models. An open question is why Rashomon ratios often tend to be large. In this work, we propose and study a mechanism of the data generation process, coupled with choices usually made by the analyst during the learning process, that determines the size of the Rashomon ratio. Specifically, we demonstrate that noisier datasets lead to larger Rashomon ratios through the way that practitioners train models. Additionally, we introduce a measure called pattern diversity, which captures the average difference in predictions between distinct classifi
&lt;/p&gt;</description></item><item><title>&#25903;&#25345;&#30697;&#38453;&#26426;&#22120;&#26159;&#19968;&#31181;&#26032;&#20852;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#30697;&#38453;&#36755;&#20837;&#25968;&#25454;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#35889;&#24377;&#24615;&#32593;&#32476;&#24615;&#36136;&#20445;&#30041;&#20102;&#30697;&#38453;&#25968;&#25454;&#30340;&#32467;&#26500;&#20449;&#24687;&#12290;</title><link>http://arxiv.org/abs/2310.19717</link><description>&lt;p&gt;
&#25903;&#25345;&#30697;&#38453;&#26426;&#22120;&#65306;&#35780;&#35770;
&lt;/p&gt;
&lt;p&gt;
Support matrix machine: A review. (arXiv:2310.19717v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19717
&lt;/p&gt;
&lt;p&gt;
&#25903;&#25345;&#30697;&#38453;&#26426;&#22120;&#26159;&#19968;&#31181;&#26032;&#20852;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#30697;&#38453;&#36755;&#20837;&#25968;&#25454;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#35889;&#24377;&#24615;&#32593;&#32476;&#24615;&#36136;&#20445;&#30041;&#20102;&#30697;&#38453;&#25968;&#25454;&#30340;&#32467;&#26500;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25903;&#25345;&#21521;&#37327;&#26426;&#65288;SVM&#65289;&#26159;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#20013;&#26368;&#21463;&#30740;&#31350;&#30340;&#33539;&#24335;&#20043;&#19968;&#65292;&#29992;&#20110;&#20998;&#31867;&#21644;&#22238;&#24402;&#38382;&#39064;&#12290;&#23427;&#20381;&#36182;&#20110;&#21521;&#37327;&#21270;&#30340;&#36755;&#20837;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#35768;&#22810;&#25968;&#25454;&#23384;&#22312;&#20110;&#30697;&#38453;&#26684;&#24335;&#20013;&#65292;&#36825;&#20123;&#25968;&#25454;&#36890;&#36807;&#23558;&#30697;&#38453;&#37325;&#26032;&#25972;&#24418;&#20026;&#21521;&#37327;&#30340;&#26041;&#24335;&#36755;&#20837;&#21040;SVM&#20013;&#12290;&#37325;&#26032;&#25972;&#24418;&#30340;&#36807;&#31243;&#30772;&#22351;&#20102;&#30697;&#38453;&#25968;&#25454;&#20013;&#22266;&#26377;&#30340;&#31354;&#38388;&#30456;&#20851;&#24615;&#12290;&#27492;&#22806;&#65292;&#23558;&#30697;&#38453;&#36716;&#25442;&#20026;&#21521;&#37327;&#20250;&#23548;&#33268;&#36755;&#20837;&#25968;&#25454;&#30340;&#32500;&#24230;&#24456;&#39640;&#65292;&#24341;&#20837;&#20102;&#26174;&#30528;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#20998;&#31867;&#30697;&#38453;&#36755;&#20837;&#25968;&#25454;&#30340;&#36825;&#20123;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#25903;&#25345;&#30697;&#38453;&#26426;&#22120;&#65288;SMM&#65289;&#12290;&#23427;&#20195;&#34920;&#20102;&#19987;&#38376;&#29992;&#20110;&#22788;&#29702;&#30697;&#38453;&#36755;&#20837;&#25968;&#25454;&#30340;&#26032;&#20852;&#26041;&#27861;&#20043;&#19968;&#12290;SMM&#26041;&#27861;&#36890;&#36807;&#20351;&#29992;&#35889;&#24377;&#24615;&#32593;&#32476;&#24615;&#36136;&#65288;&#26680;&#33539;&#25968;&#21644;Frobenius&#33539;&#25968;&#30340;&#32452;&#21512;&#65289;&#20445;&#30041;&#20102;&#30697;&#38453;&#25968;&#25454;&#30340;&#32467;&#26500;&#20449;&#24687;&#12290;&#26412;&#25991;&#39318;&#27425;&#23545;&#25903;&#25345;&#30697;&#38453;&#26426;&#22120;&#30340;&#21457;&#23637;&#36827;&#34892;&#20102;&#28145;&#20837;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Support vector machine (SVM) is one of the most studied paradigms in the realm of machine learning for classification and regression problems. It relies on vectorized input data. However, a significant portion of the real-world data exists in matrix format, which is given as input to SVM by reshaping the matrices into vectors. The process of reshaping disrupts the spatial correlations inherent in the matrix data. Also, converting matrices into vectors results in input data with a high dimensionality, which introduces significant computational complexity. To overcome these issues in classifying matrix input data, support matrix machine (SMM) is proposed. It represents one of the emerging methodologies tailored for handling matrix input data. The SMM method preserves the structural information of the matrix data by using the spectral elastic net property which is a combination of the nuclear norm and Frobenius norm. This article provides the first in-depth analysis of the development of 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#22240;&#26524;&#32972;&#26223;&#26469;&#23558;&#21453;&#20107;&#23454;&#20844;&#24179;&#24615;&#12289;&#24378;&#20581;&#39044;&#27979;&#21644;&#32676;&#20307;&#20844;&#24179;&#24615;&#30456;&#36830;&#25509;&#12290;&#39318;&#20808;&#65292;&#36890;&#36807;&#21512;&#29702;&#26465;&#20214;&#19979;&#30340;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#21453;&#20107;&#23454;&#20844;&#24179;&#39044;&#27979;&#22120;&#22312;&#26080;&#20559;&#30446;&#26631;&#20998;&#24067;&#20013;&#26159;&#20934;&#30830;&#24615;&#26368;&#20248;&#30340;&#12290;&#20854;&#27425;&#65292;&#21457;&#23637;&#20102;&#25968;&#25454;&#29983;&#25104;&#30340;&#22240;&#26524;&#22270;&#19982;&#24378;&#20581;&#39044;&#27979;&#21644;&#32676;&#20307;&#20844;&#24179;&#24615;&#20043;&#38388;&#30340;&#23545;&#24212;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2310.19691</link><description>&lt;p&gt;
&#22240;&#26524;&#32972;&#26223;&#23558;&#21453;&#20107;&#23454;&#20844;&#24179;&#24615;&#19982;&#24378;&#20581;&#39044;&#27979;&#21644;&#32676;&#20307;&#20844;&#24179;&#24615;&#30456;&#36830;&#25509;
&lt;/p&gt;
&lt;p&gt;
Causal Context Connects Counterfactual Fairness to Robust Prediction and Group Fairness. (arXiv:2310.19691v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19691
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#22240;&#26524;&#32972;&#26223;&#26469;&#23558;&#21453;&#20107;&#23454;&#20844;&#24179;&#24615;&#12289;&#24378;&#20581;&#39044;&#27979;&#21644;&#32676;&#20307;&#20844;&#24179;&#24615;&#30456;&#36830;&#25509;&#12290;&#39318;&#20808;&#65292;&#36890;&#36807;&#21512;&#29702;&#26465;&#20214;&#19979;&#30340;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#21453;&#20107;&#23454;&#20844;&#24179;&#39044;&#27979;&#22120;&#22312;&#26080;&#20559;&#30446;&#26631;&#20998;&#24067;&#20013;&#26159;&#20934;&#30830;&#24615;&#26368;&#20248;&#30340;&#12290;&#20854;&#27425;&#65292;&#21457;&#23637;&#20102;&#25968;&#25454;&#29983;&#25104;&#30340;&#22240;&#26524;&#22270;&#19982;&#24378;&#20581;&#39044;&#27979;&#21644;&#32676;&#20307;&#20844;&#24179;&#24615;&#20043;&#38388;&#30340;&#23545;&#24212;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21453;&#20107;&#23454;&#20844;&#24179;&#24615;&#35201;&#27714;&#22914;&#26524;&#19968;&#20010;&#20154;&#23646;&#20110;&#19981;&#21516;&#30340;&#21463;&#20445;&#25252;&#31867;&#21035;&#65292;&#22914;&#19981;&#21516;&#30340;&#31181;&#26063;&#25110;&#24615;&#21035;&#65292;&#37027;&#20040;&#35813;&#20154;&#22312;&#20154;&#24037;&#26234;&#33021;&#25110;&#20854;&#20182;&#31639;&#27861;&#31995;&#32479;&#20013;&#23558;&#34987;&#20998;&#31867;&#20026;&#30456;&#21516;&#31867;&#21035;&#12290;&#36825;&#26159;&#19968;&#31181;&#30452;&#35266;&#30340;&#26631;&#20934;&#65292;&#21453;&#26144;&#22312;&#32654;&#22269;&#30340;&#27861;&#24459;&#20307;&#31995;&#20013;&#65292;&#20294;&#30001;&#20110;&#21453;&#20107;&#23454;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#20013;&#26080;&#27861;&#30452;&#25509;&#35266;&#23519;&#21040;&#65292;&#20854;&#20351;&#29992;&#21463;&#38480;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#32676;&#20307;&#20844;&#24179;&#24615;&#24230;&#37327;&#65288;&#22914;&#20154;&#21475;&#24179;&#34913;&#25110;&#24179;&#31561;&#36180;&#29575;&#65289;&#36739;&#23569;&#30452;&#35266;&#65292;&#20294;&#26356;&#23481;&#26131;&#35266;&#23519;&#21040;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#8220;&#22240;&#26524;&#32972;&#26223;&#8221;&#26469;&#24357;&#21512;&#21453;&#20107;&#23454;&#20844;&#24179;&#24615;&#12289;&#24378;&#20581;&#39044;&#27979;&#21644;&#32676;&#20307;&#20844;&#24179;&#24615;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#36890;&#36807;&#23637;&#31034;&#22312;&#21512;&#29702;&#30340;&#26465;&#20214;&#19979;&#65292;&#21453;&#20107;&#23454;&#20844;&#24179;&#39044;&#27979;&#22120;&#23454;&#38469;&#19978;&#22312;&#26080;&#20559;&#30446;&#26631;&#20998;&#24067;&#20013;&#26159;&#26368;&#20248;&#20934;&#30830;&#24615;&#30340;&#65292;&#20174;&#32780;&#28608;&#21457;&#20102;&#21453;&#20107;&#23454;&#20844;&#24179;&#24615;&#30340;&#21160;&#26426;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#21457;&#23637;&#20102;&#25968;&#25454;&#29983;&#25104;&#30340;&#22240;&#26524;&#22270;&#19982;&#24378;&#20581;&#39044;&#27979;&#21644;&#32676;&#20307;&#20844;&#24179;&#24615;&#20043;&#38388;&#30340;&#23545;&#24212;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Counterfactual fairness requires that a person would have been classified in the same way by an AI or other algorithmic system if they had a different protected class, such as a different race or gender. This is an intuitive standard, as reflected in the U.S. legal system, but its use is limited because counterfactuals cannot be directly observed in real-world data. On the other hand, group fairness metrics (e.g., demographic parity or equalized odds) are less intuitive but more readily observed. In this paper, we use $\textit{causal context}$ to bridge the gaps between counterfactual fairness, robust prediction, and group fairness. First, we motivate counterfactual fairness by showing that there is not necessarily a fundamental trade-off between fairness and accuracy because, under plausible conditions, the counterfactually fair predictor is in fact accuracy-optimal in an unbiased target distribution. Second, we develop a correspondence between the causal graph of the data-generating 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#23545;&#25239;&#30340;&#22522;&#20110;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#30340;&#23545;&#40784;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#32452;&#23545;&#40784;&#19978;&#30028;&#65292;&#35299;&#20915;&#20102;&#20808;&#21069;&#26041;&#27861;&#20013;&#23384;&#22312;&#30340;&#19981;&#31283;&#23450;&#24615;&#21644;&#38480;&#21046;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#31181;&#26032;&#39062;&#30340;&#23545;&#40784;&#25439;&#22833;&#21487;&#20197;&#22312;&#19981;&#25913;&#21464;&#21407;&#22987;&#26550;&#26500;&#30340;&#24773;&#20917;&#19979;&#21462;&#20195;&#23545;&#25239;&#25439;&#22833;&#65292;&#25193;&#23637;&#20102;&#24212;&#29992;&#33539;&#22260;&#12290;</title><link>http://arxiv.org/abs/2310.19690</link><description>&lt;p&gt;
&#36890;&#36807;&#21464;&#20998;&#30028;&#38480;&#23454;&#29616;&#23454;&#29992;&#30340;&#38750;&#23545;&#25239;&#20998;&#24067;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Towards Practical Non-Adversarial Distribution Alignment via Variational Bounds. (arXiv:2310.19690v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19690
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#23545;&#25239;&#30340;&#22522;&#20110;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#30340;&#23545;&#40784;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#32452;&#23545;&#40784;&#19978;&#30028;&#65292;&#35299;&#20915;&#20102;&#20808;&#21069;&#26041;&#27861;&#20013;&#23384;&#22312;&#30340;&#19981;&#31283;&#23450;&#24615;&#21644;&#38480;&#21046;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#31181;&#26032;&#39062;&#30340;&#23545;&#40784;&#25439;&#22833;&#21487;&#20197;&#22312;&#19981;&#25913;&#21464;&#21407;&#22987;&#26550;&#26500;&#30340;&#24773;&#20917;&#19979;&#21462;&#20195;&#23545;&#25239;&#25439;&#22833;&#65292;&#25193;&#23637;&#20102;&#24212;&#29992;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#23545;&#40784;&#21487;&#29992;&#20110;&#23398;&#20064;&#20855;&#26377;&#20844;&#24179;&#24615;&#21644;&#40065;&#26834;&#24615;&#24212;&#29992;&#30340;&#19981;&#21464;&#34920;&#31034;&#12290;&#22823;&#22810;&#25968;&#20808;&#21069;&#30340;&#24037;&#20316;&#37117;&#37319;&#29992;&#23545;&#25239;&#23545;&#40784;&#26041;&#27861;&#65292;&#20294;&#30001;&#27492;&#20135;&#29983;&#30340;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#19981;&#31283;&#23450;&#19988;&#38590;&#20197;&#20248;&#21270;&#12290;&#38750;&#23545;&#25239;&#30340;&#22522;&#20110;&#20284;&#28982;&#30340;&#26041;&#27861;&#35201;&#20040;&#38656;&#35201;&#27169;&#22411;&#21487;&#36870;&#24615;&#65292;&#35201;&#20040;&#23545;&#28508;&#22312;&#20808;&#39564;&#26045;&#21152;&#32422;&#26463;&#65292;&#35201;&#20040;&#32570;&#20047;&#36890;&#29992;&#30340;&#23545;&#40784;&#26694;&#26550;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#23545;&#25239;&#30340;&#22522;&#20110;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#30340;&#23545;&#40784;&#26041;&#27861;&#65292;&#21487;&#24212;&#29992;&#20110;&#20219;&#20309;&#27169;&#22411;&#31649;&#36947;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#32452;&#23545;&#40784;&#19978;&#30028;&#65288;&#21253;&#25324;&#19968;&#20010;&#21547;&#22122;&#38899;&#30340;&#19978;&#30028;&#65289;&#65292;&#20854;&#20855;&#26377;&#31867;&#20284;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#30340;&#30446;&#26631;&#20294;&#20855;&#26377;&#19981;&#21516;&#30340;&#35270;&#35282;&#12290;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#21644;&#23454;&#35777;&#19978;&#20180;&#32454;&#27604;&#36739;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#20808;&#21069;&#30340;&#22522;&#20110;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#30340;&#23545;&#40784;&#26041;&#27861;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#25105;&#20204;&#30340;&#26032;&#39062;&#23545;&#40784;&#25439;&#22833;&#21487;&#20197;&#22312;&#26631;&#20934;&#30340;&#19981;&#21464;&#34920;&#31034;&#23398;&#20064;&#31649;&#36947;&#20013;&#21462;&#20195;&#23545;&#25239;&#25439;&#22833;&#65292;&#32780;&#26080;&#38656;&#20462;&#25913;&#21407;&#22987;&#26550;&#26500;&#65292;&#20174;&#32780;&#26174;&#33879;&#25299;&#23637;&#20102;&#24212;&#29992;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;
Distribution alignment can be used to learn invariant representations with applications in fairness and robustness. Most prior works resort to adversarial alignment methods but the resulting minimax problems are unstable and challenging to optimize. Non-adversarial likelihood-based approaches either require model invertibility, impose constraints on the latent prior, or lack a generic framework for alignment. To overcome these limitations, we propose a non-adversarial VAE-based alignment method that can be applied to any model pipeline. We develop a set of alignment upper bounds (including a noisy bound) that have VAE-like objectives but with a different perspective. We carefully compare our method to prior VAE-based alignment approaches both theoretically and empirically. Finally, we demonstrate that our novel alignment losses can replace adversarial losses in standard invariant representation learning pipelines without modifying the original architectures -- thereby significantly bro
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#22312;&#32447;&#33258;&#21161;&#27861;&#29992;&#20110;&#22788;&#29702;&#22823;&#35268;&#27169;&#30340;&#26102;&#38388;&#24207;&#21015;&#21644;&#30456;&#20851;&#25968;&#25454;&#27969;&#65292;&#36890;&#36807;&#32771;&#34385;&#25968;&#25454;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#20379;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#22635;&#34917;&#20102;&#29616;&#26377;&#33258;&#21161;&#27861;&#22312;&#22797;&#26434;&#25968;&#25454;&#20381;&#36182;&#24773;&#20917;&#19979;&#30340;&#24212;&#29992;&#31354;&#30333;&#12290;</title><link>http://arxiv.org/abs/2310.19683</link><description>&lt;p&gt;
&#26102;&#38388;&#24207;&#21015;&#30340;&#22312;&#32447;&#33258;&#21161;&#27861;
&lt;/p&gt;
&lt;p&gt;
An Online Bootstrap for Time Series. (arXiv:2310.19683v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19683
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#22312;&#32447;&#33258;&#21161;&#27861;&#29992;&#20110;&#22788;&#29702;&#22823;&#35268;&#27169;&#30340;&#26102;&#38388;&#24207;&#21015;&#21644;&#30456;&#20851;&#25968;&#25454;&#27969;&#65292;&#36890;&#36807;&#32771;&#34385;&#25968;&#25454;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#20379;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#22635;&#34917;&#20102;&#29616;&#26377;&#33258;&#21161;&#27861;&#22312;&#22797;&#26434;&#25968;&#25454;&#20381;&#36182;&#24773;&#20917;&#19979;&#30340;&#24212;&#29992;&#31354;&#30333;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#20309;&#22788;&#29702;&#22823;&#35268;&#27169;&#30340;&#30456;&#20851;&#25968;&#25454;&#27969;&#65288;&#22914;&#26102;&#38388;&#24207;&#21015;&#25110;&#31354;&#38388;&#30456;&#20851;&#35266;&#27979;&#25968;&#25454;&#65289;&#26102;&#65292;&#20256;&#32479;&#30340;&#33258;&#21161;&#27861;&#21463;&#38480;&#21046;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20197;&#22312;&#32447;&#25191;&#34892;&#30340;&#26032;&#22411;&#33258;&#21161;&#27861;&#65292;&#19987;&#38376;&#29992;&#20110;&#32771;&#34385;&#25968;&#25454;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#20351;&#20854;&#29305;&#21035;&#36866;&#29992;&#20110;&#23454;&#26102;&#24212;&#29992;&#12290;&#36825;&#31181;&#26041;&#27861;&#22522;&#20110;&#19968;&#20010;&#33258;&#22238;&#24402;&#24207;&#21015;&#65292;&#20854;&#20013;&#21253;&#21547;&#36234;&#26469;&#36234;&#30456;&#20851;&#30340;&#37325;&#37319;&#26679;&#26435;&#37325;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#19968;&#33324;&#26465;&#20214;&#19979;&#25552;&#20986;&#30340;&#33258;&#21161;&#27861;&#30340;&#29702;&#35770;&#26377;&#25928;&#24615;&#12290;&#36890;&#36807;&#22823;&#37327;&#30340;&#27169;&#25311;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#26174;&#31034;&#23427;&#22312;&#22797;&#26434;&#25968;&#25454;&#20381;&#36182;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#25552;&#20379;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#22635;&#34917;&#20102;&#20256;&#32479;&#37325;&#37319;&#26679;&#25216;&#26415;&#19982;&#29616;&#20195;&#25968;&#25454;&#20998;&#26512;&#38656;&#27714;&#20043;&#38388;&#30340;&#40511;&#27807;&#65292;&#20026;&#30740;&#31350;&#20154;&#21592;&#21644;&#20174;&#19994;&#32773;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#20215;&#20540;&#30340;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;
Resampling methods such as the bootstrap have proven invaluable in the field of machine learning. However, the applicability of traditional bootstrap methods is limited when dealing with large streams of dependent data, such as time series or spatially correlated observations. In this paper, we propose a novel bootstrap method that is designed to account for data dependencies and can be executed online, making it particularly suitable for real-time applications. This method is based on an autoregressive sequence of increasingly dependent resampling weights. We prove the theoretical validity of the proposed bootstrap scheme under general conditions. We demonstrate the effectiveness of our approach through extensive simulations and show that it provides reliable uncertainty quantification even in the presence of complex data dependencies. Our work bridges the gap between classical resampling techniques and the demands of modern data analysis, providing a valuable tool for researchers and
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#31070;&#32463;&#25193;&#25955;&#21453;&#24212;&#36807;&#31243;&#23454;&#29616;&#21160;&#24577;&#24352;&#37327;&#20998;&#35299;&#30340;&#26041;&#27861;(DEMOTE)&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#26356;&#22909;&#22320;&#21033;&#29992;&#26102;&#38388;&#20449;&#24687;&#21644;&#31232;&#30095;&#35266;&#27979;&#24352;&#37327;&#26465;&#30446;&#20869;&#30340;&#32467;&#26500;&#30693;&#35782;&#65292;&#20197;&#25429;&#25417;&#28508;&#22312;&#30340;&#26102;&#24577;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2310.19666</link><description>&lt;p&gt;
&#36890;&#36807;&#31070;&#32463;&#25193;&#25955;&#21453;&#24212;&#36807;&#31243;&#23454;&#29616;&#21160;&#24577;&#24352;&#37327;&#20998;&#35299;
&lt;/p&gt;
&lt;p&gt;
Dynamic Tensor Decomposition via Neural Diffusion-Reaction Processes. (arXiv:2310.19666v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19666
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#31070;&#32463;&#25193;&#25955;&#21453;&#24212;&#36807;&#31243;&#23454;&#29616;&#21160;&#24577;&#24352;&#37327;&#20998;&#35299;&#30340;&#26041;&#27861;(DEMOTE)&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#26356;&#22909;&#22320;&#21033;&#29992;&#26102;&#38388;&#20449;&#24687;&#21644;&#31232;&#30095;&#35266;&#27979;&#24352;&#37327;&#26465;&#30446;&#20869;&#30340;&#32467;&#26500;&#30693;&#35782;&#65292;&#20197;&#25429;&#25417;&#28508;&#22312;&#30340;&#26102;&#24577;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24352;&#37327;&#20998;&#35299;&#26159;&#22810;&#32500;&#25968;&#25454;&#20998;&#26512;&#30340;&#37325;&#35201;&#24037;&#20855;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#25968;&#25454;&#24448;&#24448;&#31232;&#30095;&#20294;&#19982;&#20016;&#23500;&#30340;&#26102;&#38388;&#20449;&#24687;&#30456;&#20851;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#24120;&#24120;&#26410;&#20805;&#20998;&#21033;&#29992;&#26102;&#38388;&#20449;&#24687;&#65292;&#24182;&#24573;&#35270;&#31232;&#30095;&#35266;&#27979;&#24352;&#37327;&#26465;&#30446;&#20869;&#30340;&#32467;&#26500;&#30693;&#35782;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#65292;&#26356;&#22909;&#22320;&#25429;&#25417;&#28508;&#22312;&#30340;&#26102;&#24577;&#32467;&#26500;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21160;&#24577;&#24352;&#37327;&#20998;&#35299;&#26041;&#27861;Dynamic EMbedIngs fOr dynamic Tensor dEcomposition (DEMOTE)&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#31070;&#32463;&#25193;&#25955;&#21453;&#24212;&#36807;&#31243;&#26469;&#20272;&#35745;&#27599;&#20010;&#24352;&#37327;&#27169;&#24335;&#20013;&#23454;&#20307;&#30340;&#21160;&#24577;&#23884;&#20837;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#22522;&#20110;&#35266;&#27979;&#21040;&#30340;&#24352;&#37327;&#26465;&#30446;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#22810;&#37096;&#20998;&#22270;&#26469;&#32534;&#30721;&#23454;&#20307;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#22270;&#25193;&#25955;&#36807;&#31243;&#26469;&#20849;&#21516;&#28436;&#21270;&#30456;&#20851;&#23454;&#20307;&#30340;&#23884;&#20837;&#36712;&#36857;&#65292;&#24182;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#20026;&#27599;&#20010;&#21333;&#29420;&#30340;&#23454;&#20307;&#26500;&#24314;&#20102;&#19968;&#20010;&#21453;&#24212;&#36807;&#31243;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#24335;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#33021;&#22815;&#22312;&#28436;&#21270;&#36807;&#31243;&#20013;&#25429;&#25417;&#21040;&#20849;&#24615;&#21644;&#20010;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tensor decomposition is an important tool for multiway data analysis. In practice, the data is often sparse yet associated with rich temporal information. Existing methods, however, often under-use the time information and ignore the structural knowledge within the sparsely observed tensor entries. To overcome these limitations and to better capture the underlying temporal structure, we propose Dynamic EMbedIngs fOr dynamic Tensor dEcomposition (DEMOTE). We develop a neural diffusion-reaction process to estimate dynamic embeddings for the entities in each tensor mode. Specifically, based on the observed tensor entries, we build a multi-partite graph to encode the correlation between the entities. We construct a graph diffusion process to co-evolve the embedding trajectories of the correlated entities and use a neural network to construct a reaction process for each individual entity. In this way, our model can capture both the commonalities and personalities during the evolution of the
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#22312;&#39044;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#29983;&#25104;&#30340;&#26679;&#26412;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#26377;&#25928;&#20943;&#36731;&#20102;VAE&#20013;&#32534;&#30721;&#22120;&#30340;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.19653</link><description>&lt;p&gt;
&#20351;&#29992;&#25193;&#25955;&#27169;&#22411;&#25552;&#20379;&#30340;&#26080;&#38480;&#25968;&#25454;&#35745;&#21010;&#21319;&#32423;VAE&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Upgrading VAE Training With Unlimited Data Plans Provided by Diffusion Models. (arXiv:2310.19653v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19653
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#22312;&#39044;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#29983;&#25104;&#30340;&#26679;&#26412;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#26377;&#25928;&#20943;&#36731;&#20102;VAE&#20013;&#32534;&#30721;&#22120;&#30340;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#26159;&#19968;&#31181;&#24120;&#29992;&#30340;&#34920;&#31034;&#23398;&#20064;&#27169;&#22411;&#65292;&#20294;&#20854;&#32534;&#30721;&#22120;&#23481;&#26131;&#36807;&#25311;&#21512;&#65292;&#22240;&#20026;&#23427;&#20204;&#26159;&#22312;&#26377;&#38480;&#30340;&#35757;&#32451;&#38598;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#32780;&#19981;&#26159;&#30495;&#23454;&#65288;&#36830;&#32493;&#65289;&#25968;&#25454;&#20998;&#24067;$p_{\mathrm{data}}(\mathbf{x})$&#12290;&#19982;&#20043;&#30456;&#21453;&#65292;&#25193;&#25955;&#27169;&#22411;&#36890;&#36807;&#22266;&#23450;&#32534;&#30721;&#22120;&#36991;&#20813;&#20102;&#36825;&#20010;&#38382;&#39064;&#12290;&#36825;&#20351;&#24471;&#23427;&#20204;&#30340;&#34920;&#31034;&#19981;&#22826;&#21487;&#35299;&#37322;&#65292;&#20294;&#31616;&#21270;&#20102;&#35757;&#32451;&#65292;&#21487;&#20197;&#31934;&#30830;&#21644;&#36830;&#32493;&#22320;&#36924;&#36817;$p_{\mathrm{data}}(\mathbf{x})$&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#36807;&#22312;&#39044;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#29983;&#25104;&#30340;&#26679;&#26412;&#19978;&#35757;&#32451;&#65292;&#21487;&#20197;&#26377;&#25928;&#20943;&#36731;VAE&#20013;&#32534;&#30721;&#22120;&#30340;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;&#36825;&#20123;&#32467;&#26524;&#26377;&#20123;&#20986;&#20154;&#24847;&#26009;&#65292;&#22240;&#20026;&#26368;&#36817;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#20351;&#29992;&#21478;&#19968;&#20010;&#29983;&#25104;&#27169;&#22411;&#29983;&#25104;&#30340;&#25968;&#25454;&#19978;&#35757;&#32451;&#26102;&#65292;&#29983;&#25104;&#24615;&#33021;&#20250;&#19979;&#38477;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#20351;&#29992;&#25105;&#20204;&#30340;&#26041;&#27861;&#35757;&#32451;&#30340;VAE&#30340;&#27867;&#21270;&#24615;&#33021;&#12289;&#20998;&#25674;&#24046;&#36317;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variational autoencoders (VAEs) are popular models for representation learning but their encoders are susceptible to overfitting (Cremer et al., 2018) because they are trained on a finite training set instead of the true (continuous) data distribution $p_{\mathrm{data}}(\mathbf{x})$. Diffusion models, on the other hand, avoid this issue by keeping the encoder fixed. This makes their representations less interpretable, but it simplifies training, enabling accurate and continuous approximations of $p_{\mathrm{data}}(\mathbf{x})$. In this paper, we show that overfitting encoders in VAEs can be effectively mitigated by training on samples from a pre-trained diffusion model. These results are somewhat unexpected as recent findings (Alemohammad et al., 2023; Shumailov et al., 2023) observe a decay in generative performance when models are trained on data generated by another generative model. We analyze generalization performance, amortization gap, and robustness of VAEs trained with our pro
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#29992;&#20110;&#31232;&#30095;&#20856;&#22411;&#30456;&#20851;&#20272;&#35745;&#65292;&#36890;&#36807;&#22312;&#24314;&#27169;&#26694;&#26550;&#20013;&#30340;&#20004;&#20010;&#32423;&#21035;&#19978;&#40723;&#21169;&#31232;&#30095;&#65292;&#26469;&#23454;&#29616;&#23545;&#22810;&#35270;&#22270;&#39640;&#32500;&#25968;&#25454;&#30340;&#40065;&#26834;&#24314;&#27169;&#12290;</title><link>http://arxiv.org/abs/2310.19621</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#31232;&#30095;&#20856;&#22411;&#30456;&#20851;&#20272;&#35745;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Bayesian Methodology for Estimation for Sparse Canonical Correlation. (arXiv:2310.19621v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19621
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#65292;&#29992;&#20110;&#31232;&#30095;&#20856;&#22411;&#30456;&#20851;&#20272;&#35745;&#65292;&#36890;&#36807;&#22312;&#24314;&#27169;&#26694;&#26550;&#20013;&#30340;&#20004;&#20010;&#32423;&#21035;&#19978;&#40723;&#21169;&#31232;&#30095;&#65292;&#26469;&#23454;&#29616;&#23545;&#22810;&#35270;&#22270;&#39640;&#32500;&#25968;&#25454;&#30340;&#40065;&#26834;&#24314;&#27169;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23545;&#21442;&#19982;&#32852;&#21512;&#30740;&#31350;&#30340;&#27599;&#20010;&#34987;&#35797;&#25152;&#33719;&#21462;&#30340;&#26469;&#33258;&#19981;&#21516;&#23454;&#39564;&#30340;&#22810;&#35270;&#22270;&#39640;&#32500;&#25968;&#25454;&#36827;&#34892;&#32508;&#21512;&#32479;&#35745;&#20998;&#26512;&#26102;&#65292;&#21487;&#33021;&#24456;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20856;&#22411;&#30456;&#20851;&#20998;&#26512;(CCA)&#26159;&#19968;&#31181;&#29992;&#20110;&#30830;&#23450;&#36825;&#20123;&#25968;&#25454;&#38598;&#20043;&#38388;&#20851;&#31995;&#30340;&#32479;&#35745;&#36807;&#31243;&#12290;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#65292;&#32467;&#26500;&#31232;&#30095;CCA(ScSCCA)&#26159;&#19968;&#31181;&#24555;&#36895;&#23835;&#36215;&#30340;&#26041;&#27861;&#35770;&#39046;&#22495;&#65292;&#26088;&#22312;&#36890;&#36807;&#20551;&#35774;&#30456;&#24212;&#30340;CCA&#26041;&#21521;&#21521;&#37327;&#26159;&#31232;&#30095;&#30340;&#65292;&#26469;&#23545;&#19981;&#21516;&#25968;&#25454;&#27169;&#24577;&#20043;&#38388;&#30340;&#30456;&#20114;&#20851;&#31995;&#36827;&#34892;&#40065;&#26834;&#24314;&#27169;&#12290;&#34429;&#28982;&#36825;&#26159;&#19968;&#20010;&#24555;&#36895;&#21457;&#23637;&#30340;&#32479;&#35745;&#26041;&#27861;&#23398;&#39046;&#22495;&#65292;&#20294;&#22312;&#36125;&#21494;&#26031;&#33539;&#24335;&#19979;&#20173;&#38656;&#35201;&#24320;&#21457;&#30456;&#20851;&#26041;&#27861;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;ScSCCA&#26041;&#27861;&#65292;&#25105;&#20204;&#37319;&#29992;&#36125;&#21494;&#26031;&#26080;&#31351;&#22240;&#23376;&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;&#22312;&#24314;&#27169;&#26694;&#26550;&#30340;&#20004;&#20010;&#19981;&#21516;&#32423;&#21035;&#19978;&#40723;&#21169;&#31232;&#30095;&#26469;&#23454;&#29616;&#40065;&#26834;&#20272;&#35745;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#21033;&#29992;&#19968;&#20010;&#20056;&#27861;&#21322;-Cauchy&#36807;&#31243;&#20808;&#39564;&#26469;&#23454;&#29616;&#31232;&#30095;&#24314;&#27169;&#12290;
&lt;/p&gt;
&lt;p&gt;
It can be challenging to perform an integrative statistical analysis of multi-view high-dimensional data acquired from different experiments on each subject who participated in a joint study. Canonical Correlation Analysis (CCA) is a statistical procedure for identifying relationships between such data sets. In that context, Structured Sparse CCA (ScSCCA) is a rapidly emerging methodological area that aims for robust modeling of the interrelations between the different data modalities by assuming the corresponding CCA directional vectors to be sparse. Although it is a rapidly growing area of statistical methodology development, there is a need for developing related methodologies in the Bayesian paradigm. In this manuscript, we propose a novel ScSCCA approach where we employ a Bayesian infinite factor model and aim to achieve robust estimation by encouraging sparsity in two different levels of the modeling framework. Firstly, we utilize a multiplicative Half-Cauchy process prior to enc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#37096;&#20998;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#36716;&#21270;&#20026;&#27169;&#25311;&#36153;&#26364;-&#21345;&#20811;&#27169;&#22411;&#30340;&#39640;&#25928;&#37319;&#26679;&#35757;&#32451;&#31574;&#30053;&#65292;&#24182;&#36890;&#36807;&#21508;&#31181;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#35777;&#26126;&#20854;&#22312;&#39044;&#27979;&#24615;&#33021;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#12290;</title><link>http://arxiv.org/abs/2310.19608</link><description>&lt;p&gt;
&#35770;&#36153;&#26364;-&#21345;&#20811;&#35757;&#32451;&#37096;&#20998;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
On Feynman--Kac training of partial Bayesian neural networks. (arXiv:2310.19608v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19608
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#37096;&#20998;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#36716;&#21270;&#20026;&#27169;&#25311;&#36153;&#26364;-&#21345;&#20811;&#27169;&#22411;&#30340;&#39640;&#25928;&#37319;&#26679;&#35757;&#32451;&#31574;&#30053;&#65292;&#24182;&#36890;&#36807;&#21508;&#31181;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#35777;&#26126;&#20854;&#22312;&#39044;&#27979;&#24615;&#33021;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#37096;&#20998;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;(pBNNs)&#34987;&#35777;&#26126;&#19982;&#20840;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#20855;&#26377;&#31454;&#20105;&#21147;&#65292;&#20294;pBNNs&#22312;&#28508;&#21464;&#37327;&#31354;&#38388;&#20013;&#24448;&#24448;&#26159;&#22810;&#23792;&#30340;&#65292;&#22240;&#27492;&#29992;&#21442;&#25968;&#27169;&#22411;&#26469;&#36817;&#20284;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#22522;&#20110;&#37319;&#26679;&#30340;&#35757;&#32451;&#31574;&#30053;&#65292;&#21363;&#23558;pBNN&#30340;&#35757;&#32451;&#36716;&#21270;&#20026;&#27169;&#25311;&#36153;&#26364;-&#21345;&#20811;&#27169;&#22411;&#12290;&#25105;&#20204;&#36824;&#25551;&#36848;&#20102;&#24207;&#36143;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#22120;&#30340;&#21464;&#31181;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#20197;&#21487;&#34892;&#30340;&#35745;&#31639;&#25104;&#26412;&#21516;&#26102;&#20272;&#35745;&#21442;&#25968;&#21644;&#35813;&#27169;&#22411;&#30340;&#28508;&#22312;&#21518;&#39564;&#20998;&#24067;&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#35757;&#32451;&#26041;&#26696;&#22312;&#39044;&#27979;&#24615;&#33021;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, partial Bayesian neural networks (pBNNs), which only consider a subset of the parameters to be stochastic, were shown to perform competitively with full Bayesian neural networks. However, pBNNs are often multi-modal in the latent-variable space and thus challenging to approximate with parametric models. To address this problem, we propose an efficient sampling-based training strategy, wherein the training of a pBNN is formulated as simulating a Feynman--Kac model. We then describe variations of sequential Monte Carlo samplers that allow us to simultaneously estimate the parameters and the latent posterior distribution of this model at a tractable computational cost. We show on various synthetic and real-world datasets that our proposed training scheme outperforms the state of the art in terms of predictive performance.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23637;&#31034;&#20102;&#19968;&#31867;&#36830;&#32493;&#26102;&#38388;&#30340;&#28145;&#24230;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;DKFs&#65289;&#65292;&#21487;&#20197;&#36817;&#20284;&#23454;&#29616;&#19968;&#31867;&#38750;&#39532;&#23572;&#21487;&#22827;&#21644;&#26465;&#20214;&#39640;&#26031;&#20449;&#21495;&#36807;&#31243;&#30340;&#26465;&#20214;&#20998;&#24067;&#24459;&#65292;&#20174;&#32780;&#20855;&#26377;&#22312;&#25968;&#23398;&#37329;&#34701;&#39046;&#22495;&#20013;&#20256;&#32479;&#27169;&#22411;&#22522;&#30784;&#19978;&#30340;&#28388;&#27874;&#38382;&#39064;&#30340;&#24212;&#29992;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.19603</link><description>&lt;p&gt;
&#28145;&#24230;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#21487;&#20197;&#36827;&#34892;&#28388;&#27874;
&lt;/p&gt;
&lt;p&gt;
Deep Kalman Filters Can Filter. (arXiv:2310.19603v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19603
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23637;&#31034;&#20102;&#19968;&#31867;&#36830;&#32493;&#26102;&#38388;&#30340;&#28145;&#24230;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;DKFs&#65289;&#65292;&#21487;&#20197;&#36817;&#20284;&#23454;&#29616;&#19968;&#31867;&#38750;&#39532;&#23572;&#21487;&#22827;&#21644;&#26465;&#20214;&#39640;&#26031;&#20449;&#21495;&#36807;&#31243;&#30340;&#26465;&#20214;&#20998;&#24067;&#24459;&#65292;&#20174;&#32780;&#20855;&#26377;&#22312;&#25968;&#23398;&#37329;&#34701;&#39046;&#22495;&#20013;&#20256;&#32479;&#27169;&#22411;&#22522;&#30784;&#19978;&#30340;&#28388;&#27874;&#38382;&#39064;&#30340;&#24212;&#29992;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;DKFs&#65289;&#26159;&#19968;&#31867;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#21487;&#20197;&#20174;&#24207;&#21015;&#25968;&#25454;&#20013;&#29983;&#25104;&#39640;&#26031;&#27010;&#29575;&#27979;&#24230;&#12290;&#34429;&#28982;DKFs&#21463;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#30340;&#21551;&#21457;&#65292;&#20294;&#23427;&#20204;&#32570;&#20047;&#19982;&#38543;&#26426;&#28388;&#27874;&#38382;&#39064;&#30340;&#20855;&#20307;&#29702;&#35770;&#20851;&#32852;&#65292;&#20174;&#32780;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#20256;&#32479;&#27169;&#22411;&#22522;&#30784;&#19978;&#30340;&#28388;&#27874;&#38382;&#39064;&#30340;&#24212;&#29992;&#65292;&#20363;&#22914;&#25968;&#23398;&#37329;&#34701;&#20013;&#30340;&#20538;&#21048;&#21644;&#26399;&#26435;&#23450;&#20215;&#27169;&#22411;&#26657;&#20934;&#12290;&#25105;&#20204;&#36890;&#36807;&#23637;&#31034;&#19968;&#31867;&#36830;&#32493;&#26102;&#38388;DKFs&#65292;&#21487;&#20197;&#36817;&#20284;&#23454;&#29616;&#19968;&#31867;&#38750;&#39532;&#23572;&#21487;&#22827;&#21644;&#26465;&#20214;&#39640;&#26031;&#20449;&#21495;&#36807;&#31243;&#30340;&#26465;&#20214;&#20998;&#24067;&#24459;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#28145;&#24230;&#23398;&#20064;&#25968;&#23398;&#22522;&#30784;&#20013;&#30340;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#36817;&#20284;&#32467;&#26524;&#22312;&#36335;&#24452;&#30340;&#36275;&#22815;&#35268;&#21017;&#30340;&#32039;&#33268;&#23376;&#38598;&#19978;&#19968;&#33268;&#25104;&#31435;&#65292;&#20854;&#20013;&#36817;&#20284;&#35823;&#24046;&#30001;&#22312;&#32473;&#23450;&#32039;&#33268;&#36335;&#24452;&#38598;&#19978;&#22343;&#19968;&#22320;&#35745;&#31639;&#30340;&#26368;&#22351;&#24773;&#20917;2-Wasserstein&#36317;&#31163;&#37327;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep Kalman filters (DKFs) are a class of neural network models that generate Gaussian probability measures from sequential data. Though DKFs are inspired by the Kalman filter, they lack concrete theoretical ties to the stochastic filtering problem, thus limiting their applicability to areas where traditional model-based filters have been used, e.g.\ model calibration for bond and option prices in mathematical finance. We address this issue in the mathematical foundations of deep learning by exhibiting a class of continuous-time DKFs which can approximately implement the conditional law of a broad class of non-Markovian and conditionally Gaussian signal processes given noisy continuous-times measurements. Our approximation results hold uniformly over sufficiently regular compact subsets of paths, where the approximation error is quantified by the worst-case 2-Wasserstein distance computed uniformly over the given compact set of paths.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#20174;&#20855;&#26377;&#32473;&#23450;&#21021;&#22987;&#29366;&#24577;&#30340;&#35299;&#36807;&#31243;&#30340;&#20998;&#24067;&#20013;&#35782;&#21035;&#32447;&#24615;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;SDE&#65289;&#30340;&#21457;&#29983;&#22120;&#30340;&#26465;&#20214;&#65292;&#24182;&#19988;&#25552;&#20379;&#20102;&#23545;&#20110;&#20855;&#26377;&#21152;&#24615;&#21644;&#20056;&#24615;&#22122;&#22768;&#30340;SDE&#30340;&#35782;&#21035;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2310.19491</link><description>&lt;p&gt;
&#20855;&#26377;&#21152;&#24615;&#21644;&#20056;&#24615;&#22122;&#22768;&#30340;&#32447;&#24615;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#21457;&#29983;&#22120;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Generator Identification for Linear SDEs with Additive and Multiplicative Noise. (arXiv:2310.19491v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19491
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#20174;&#20855;&#26377;&#32473;&#23450;&#21021;&#22987;&#29366;&#24577;&#30340;&#35299;&#36807;&#31243;&#30340;&#20998;&#24067;&#20013;&#35782;&#21035;&#32447;&#24615;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;SDE&#65289;&#30340;&#21457;&#29983;&#22120;&#30340;&#26465;&#20214;&#65292;&#24182;&#19988;&#25552;&#20379;&#20102;&#23545;&#20110;&#20855;&#26377;&#21152;&#24615;&#21644;&#20056;&#24615;&#22122;&#22768;&#30340;SDE&#30340;&#35782;&#21035;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#20855;&#26377;&#32473;&#23450;&#22266;&#23450;&#21021;&#22987;&#29366;&#24577;&#30340;&#35299;&#36807;&#31243;&#30340;&#20998;&#24067;&#20013;&#35782;&#21035;&#32447;&#24615;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;SDE&#65289;&#30340;&#21457;&#29983;&#22120;&#30340;&#26465;&#20214;&#12290;&#36825;&#20123;&#21487;&#35782;&#21035;&#24615;&#26465;&#20214;&#22312;&#20351;&#29992;&#32447;&#24615;SDE&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#26102;&#33267;&#20851;&#37325;&#35201;&#65292;&#22240;&#20026;&#23427;&#20204;&#20351;&#24471;&#21487;&#20197;&#20174;&#20854;&#35266;&#27979;&#20998;&#24067;&#20013;&#35782;&#21035;&#20986;&#24178;&#39044;&#21518;&#30340;&#20998;&#24067;&#12290;&#25105;&#20204;&#20855;&#20307;&#25512;&#23548;&#20986;&#20102;&#35782;&#21035;&#20855;&#26377;&#21152;&#24615;&#22122;&#22768;&#30340;&#32447;&#24615;SDE&#30340;&#21457;&#29983;&#22120;&#30340;&#20805;&#20998;&#24517;&#35201;&#26465;&#20214;&#65292;&#20197;&#21450;&#35782;&#21035;&#20855;&#26377;&#20056;&#24615;&#22122;&#22768;&#30340;&#32447;&#24615;SDE&#30340;&#21457;&#29983;&#22120;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#20004;&#31181;&#31867;&#22411;&#30340;SDE&#65292;&#24471;&#21040;&#30340;&#26465;&#20214;&#26159;&#19968;&#33324;&#24615;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#24471;&#21040;&#30340;&#21487;&#35782;&#21035;&#24615;&#26465;&#20214;&#30340;&#20960;&#20309;&#35299;&#37322;&#65292;&#20197;&#22686;&#24378;&#23545;&#20854;&#30340;&#29702;&#35299;&#12290;&#20026;&#20102;&#39564;&#35777;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#31995;&#21015;&#30340;&#27169;&#25311;&#23454;&#39564;&#65292;&#36825;&#20123;&#23454;&#39564;&#25903;&#25345;&#24182;&#35777;&#23454;&#20102;&#25105;&#20204;&#25152;&#24471;&#21040;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#26234;&#33021;&#20307;&#21512;&#20316;&#23398;&#20064;&#31995;&#32479;&#20013;&#30340;&#36951;&#25022;&#26368;&#23567;&#21270;&#31639;&#27861;&#12290;&#36890;&#36807;&#20998;&#26512;&#19981;&#21516;&#39034;&#24207;&#20915;&#31574;&#38382;&#39064;&#19979;&#30340;MACL&#31995;&#32479;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#21512;&#20316;&#22810;&#26234;&#33021;&#20307;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#20013;&#20351;&#29992;&#20840;&#20449;&#24687;&#25110;&#20449;&#24687;&#26377;&#38480;&#21453;&#39304;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20132;&#25442;&#20449;&#24687;&#26469;&#25913;&#21892;&#23398;&#20064;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.19468</link><description>&lt;p&gt;
&#22810;&#26234;&#33021;&#20307;&#21512;&#20316;&#23398;&#20064;&#31995;&#32479;&#20013;&#30340;&#36951;&#25022;&#26368;&#23567;&#21270;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Regret-Minimization Algorithms for Multi-Agent Cooperative Learning Systems. (arXiv:2310.19468v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19468
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#26234;&#33021;&#20307;&#21512;&#20316;&#23398;&#20064;&#31995;&#32479;&#20013;&#30340;&#36951;&#25022;&#26368;&#23567;&#21270;&#31639;&#27861;&#12290;&#36890;&#36807;&#20998;&#26512;&#19981;&#21516;&#39034;&#24207;&#20915;&#31574;&#38382;&#39064;&#19979;&#30340;MACL&#31995;&#32479;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#21512;&#20316;&#22810;&#26234;&#33021;&#20307;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#20013;&#20351;&#29992;&#20840;&#20449;&#24687;&#25110;&#20449;&#24687;&#26377;&#38480;&#21453;&#39304;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20132;&#25442;&#20449;&#24687;&#26469;&#25913;&#21892;&#23398;&#20064;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#26234;&#33021;&#20307;&#21512;&#20316;&#23398;&#20064;(MACL)&#31995;&#32479;&#26159;&#19968;&#31181;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#65292;&#22810;&#20010;&#23398;&#20064;&#26234;&#33021;&#20307;&#20849;&#21516;&#23436;&#25104;&#19968;&#20010;&#20849;&#21516;&#20219;&#21153;&#12290;&#26368;&#36817;&#22312;&#21508;&#20010;&#39046;&#22495;&#65288;&#22914;&#20132;&#36890;&#25511;&#21046;&#12289;&#20113;&#35745;&#31639;&#12289;&#26426;&#22120;&#20154;&#25216;&#26415;&#65289;&#20013;&#65292;MACL&#31995;&#32479;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#23454;&#35777;&#25104;&#21151;&#65292;&#36825;&#28608;&#21457;&#20102;&#23545;&#35774;&#35745;&#21644;&#20998;&#26512;&#29992;&#20110;&#39034;&#24207;&#20915;&#31574;&#38382;&#39064;&#30340;MACL&#31995;&#32479;&#30340;&#30740;&#31350;&#12290;&#20915;&#31574;&#38382;&#39064;&#20013;&#23398;&#20064;&#31639;&#27861;&#30340;&#37325;&#35201;&#25351;&#26631;&#26159;&#36951;&#25022;&#65292;&#21363;&#31639;&#27861;&#23454;&#38469;&#33719;&#24471;&#30340;&#22870;&#21169;&#19982;&#26368;&#39640;&#21487;&#36798;&#22870;&#21169;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#35774;&#35745;&#21644;&#24320;&#21457;&#20855;&#26377;&#20302;&#36951;&#25022;&#23398;&#20064;&#31639;&#27861;&#30340;MACL&#31995;&#32479;&#21487;&#20197;&#21019;&#36896;&#24040;&#22823;&#30340;&#32463;&#27982;&#20215;&#20540;&#12290;&#26412;&#25991;&#20998;&#26512;&#20102;&#19981;&#21516;&#39034;&#24207;&#20915;&#31574;&#38382;&#39064;&#19979;&#30340;MACL&#31995;&#32479;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#31532;3&#31456;&#21644;&#31532;4&#31456;&#30740;&#31350;&#20102;&#20855;&#26377;&#20840;&#20449;&#24687;&#25110;&#32773;&#20449;&#24687;&#26377;&#38480;&#21453;&#39304;&#30340;&#21512;&#20316;&#22810;&#26234;&#33021;&#20307;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#65292;&#22312;&#36825;&#20123;&#38382;&#39064;&#20013;&#65292;&#22810;&#20010;&#23398;&#20064;&#26234;&#33021;&#20307;&#21487;&#20197;&#36890;&#36807;&#20132;&#25442;&#20449;&#24687;&#26469;&#25913;&#21892;&#23398;&#20064;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
A Multi-Agent Cooperative Learning (MACL) system is an artificial intelligence (AI) system where multiple learning agents work together to complete a common task. Recent empirical success of MACL systems in various domains (e.g. traffic control, cloud computing, robotics) has sparked active research into the design and analysis of MACL systems for sequential decision making problems. One important metric of the learning algorithm for decision making problems is its regret, i.e. the difference between the highest achievable reward and the actual reward that the algorithm gains. The design and development of a MACL system with low-regret learning algorithms can create huge economic values. In this thesis, I analyze MACL systems for different sequential decision making problems. Concretely, the Chapter 3 and 4 investigate the cooperative multi-agent multi-armed bandit problems, with full-information or bandit feedback, in which multiple learning agents can exchange their information throu
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;MMM&#21644;MMMSynth&#31639;&#27861;&#65292;&#29992;&#20110;&#32858;&#31867;&#24322;&#26500;&#34920;&#26684;&#25968;&#25454;&#21644;&#29983;&#25104;&#21512;&#25104;&#25968;&#25454;&#12290;MMM&#31639;&#27861;&#21033;&#29992;EM&#31639;&#27861;&#65292;&#22312;&#21516;&#31867;&#31639;&#27861;&#20013;&#34920;&#29616;&#26356;&#20248;&#65292;&#23545;&#20110;&#30830;&#23450;&#21512;&#25104;&#25968;&#25454;&#30340;&#32858;&#31867;&#20197;&#21450;&#24674;&#22797;&#30495;&#23454;&#25968;&#25454;&#30340;&#32467;&#26500;&#26377;&#36739;&#22909;&#30340;&#25928;&#26524;&#12290; MMMSynth&#31639;&#27861;&#21017;&#29992;&#20110;&#20174;&#30495;&#23454;&#25968;&#25454;&#29983;&#25104;&#21512;&#25104;&#34920;&#26684;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2310.19454</link><description>&lt;p&gt;
MMM&#21644;MMMSynth&#65306;&#24322;&#26500;&#34920;&#26684;&#25968;&#25454;&#30340;&#32858;&#31867;&#21644;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
MMM and MMMSynth: Clustering of heterogeneous tabular data, and synthetic data generation. (arXiv:2310.19454v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19454
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;MMM&#21644;MMMSynth&#31639;&#27861;&#65292;&#29992;&#20110;&#32858;&#31867;&#24322;&#26500;&#34920;&#26684;&#25968;&#25454;&#21644;&#29983;&#25104;&#21512;&#25104;&#25968;&#25454;&#12290;MMM&#31639;&#27861;&#21033;&#29992;EM&#31639;&#27861;&#65292;&#22312;&#21516;&#31867;&#31639;&#27861;&#20013;&#34920;&#29616;&#26356;&#20248;&#65292;&#23545;&#20110;&#30830;&#23450;&#21512;&#25104;&#25968;&#25454;&#30340;&#32858;&#31867;&#20197;&#21450;&#24674;&#22797;&#30495;&#23454;&#25968;&#25454;&#30340;&#32467;&#26500;&#26377;&#36739;&#22909;&#30340;&#25928;&#26524;&#12290; MMMSynth&#31639;&#27861;&#21017;&#29992;&#20110;&#20174;&#30495;&#23454;&#25968;&#25454;&#29983;&#25104;&#21512;&#25104;&#34920;&#26684;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#20010;&#19982;&#24322;&#26500;&#34920;&#26684;&#25968;&#25454;&#30456;&#20851;&#30340;&#20219;&#21153;&#30340;&#26032;&#31639;&#27861;&#65306;&#32858;&#31867;&#21644;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#12290;&#34920;&#26684;&#25968;&#25454;&#38598;&#36890;&#24120;&#30001;&#21015;&#20013;&#30340;&#24322;&#26500;&#25968;&#25454;&#31867;&#22411;&#65288;&#25968;&#20540;&#12289;&#26377;&#24207;&#12289;&#20998;&#31867;&#65289;&#32452;&#25104;&#65292;&#20294;&#34892;&#20013;&#21487;&#33021;&#36824;&#23384;&#22312;&#38544;&#34255;&#30340;&#32858;&#31867;&#32467;&#26500;&#65306;&#20363;&#22914;&#65292;&#23427;&#20204;&#21487;&#33021;&#26469;&#33258;&#24322;&#26500;&#30340;&#65288;&#22320;&#29702;&#12289;&#31038;&#20250;&#32463;&#27982;&#12289;&#26041;&#27861;&#35770;&#65289;&#26469;&#28304;&#65292;&#22240;&#27492;&#25152;&#25551;&#36848;&#30340;&#32467;&#26524;&#21464;&#37327;&#65288;&#22914;&#30142;&#30149;&#30340;&#23384;&#22312;&#65289;&#21487;&#33021;&#19981;&#20165;&#20381;&#36182;&#20854;&#20182;&#21464;&#37327;&#65292;&#36824;&#20381;&#36182;&#20110;&#32858;&#31867;&#19978;&#19979;&#25991;&#12290;&#27492;&#22806;&#65292;&#21307;&#23398;&#25968;&#25454;&#30340;&#20849;&#20139;&#36890;&#24120;&#21463;&#21040;&#24739;&#32773;&#38544;&#31169;&#27861;&#24459;&#30340;&#38480;&#21046;&#65292;&#22240;&#27492;&#30446;&#21069;&#23545;&#20110;&#36890;&#36807;&#28145;&#24230;&#23398;&#20064;&#31561;&#26041;&#27861;&#20174;&#30495;&#23454;&#25968;&#25454;&#29983;&#25104;&#21512;&#25104;&#34920;&#26684;&#25968;&#25454;&#30340;&#31639;&#27861;&#38750;&#24120;&#24863;&#20852;&#36259;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;EM&#30340;&#32858;&#31867;&#31639;&#27861;MMM&#65288;&#8220;Madras&#28151;&#21512;&#27169;&#22411;&#8221;&#65289;&#65292;&#23427;&#22312;&#30830;&#23450;&#21512;&#25104;&#24322;&#26500;&#25968;&#25454;&#30340;&#32858;&#31867;&#21644;&#24674;&#22797;&#30495;&#23454;&#25968;&#25454;&#32467;&#26500;&#26041;&#38754;&#20248;&#20110;&#26631;&#20934;&#31639;&#27861;&#12290;&#22522;&#20110;&#27492;&#65292;&#25105;&#20204;&#21487;&#23558;MMM&#24212;&#29992;&#20110;&#25968;&#25454;&#21512;&#25104;&#20219;&#21153;&#30340;MMMSynth&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We provide new algorithms for two tasks relating to heterogeneous tabular datasets: clustering, and synthetic data generation. Tabular datasets typically consist of heterogeneous data types (numerical, ordinal, categorical) in columns, but may also have hidden cluster structure in their rows: for example, they may be drawn from heterogeneous (geographical, socioeconomic, methodological) sources, such that the outcome variable they describe (such as the presence of a disease) may depend not only on the other variables but on the cluster context. Moreover, sharing of biomedical data is often hindered by patient confidentiality laws, and there is current interest in algorithms to generate synthetic tabular data from real data, for example via deep learning.  We demonstrate a novel EM-based clustering algorithm, MMM (``Madras Mixture Model''), that outperforms standard algorithms in determining clusters in synthetic heterogeneous data, and recovers structure in real data. Based on this, we
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#29992;&#20110;&#23545;&#36793;&#32536;&#38598;&#21512;&#19978;&#30340;&#20989;&#25968;&#36827;&#34892;&#24314;&#27169;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;Hodge&#20998;&#35299;&#24320;&#21457;&#20102;&#36866;&#29992;&#20110;&#19981;&#21516;&#24212;&#29992;&#22330;&#26223;&#30340;&#26080;&#25955;&#24230;&#21644;&#26080;&#26059;&#24230;&#30340;&#39640;&#26031;&#36807;&#31243;&#65292;&#24182;&#36890;&#36807;&#32452;&#21512;&#23427;&#20204;&#26469;&#34920;&#31034;&#20219;&#24847;&#36793;&#32536;&#20989;&#25968;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#36825;&#31181;&#26041;&#27861;&#22312;&#27969;&#21160;&#25968;&#25454;&#25512;&#26029;&#20013;&#20855;&#26377;&#28508;&#22312;&#30340;&#23454;&#38469;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2310.19450</link><description>&lt;p&gt;
Hodge-Compositional &#36793;&#32536;&#39640;&#26031;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Hodge-Compositional Edge Gaussian Processes. (arXiv:2310.19450v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19450
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#29992;&#20110;&#23545;&#36793;&#32536;&#38598;&#21512;&#19978;&#30340;&#20989;&#25968;&#36827;&#34892;&#24314;&#27169;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;Hodge&#20998;&#35299;&#24320;&#21457;&#20102;&#36866;&#29992;&#20110;&#19981;&#21516;&#24212;&#29992;&#22330;&#26223;&#30340;&#26080;&#25955;&#24230;&#21644;&#26080;&#26059;&#24230;&#30340;&#39640;&#26031;&#36807;&#31243;&#65292;&#24182;&#36890;&#36807;&#32452;&#21512;&#23427;&#20204;&#26469;&#34920;&#31034;&#20219;&#24847;&#36793;&#32536;&#20989;&#25968;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#36825;&#31181;&#26041;&#27861;&#22312;&#27969;&#21160;&#25968;&#25454;&#25512;&#26029;&#20013;&#20855;&#26377;&#28508;&#22312;&#30340;&#23454;&#38469;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36793;&#32536;&#38598;&#21512;&#30340;2-&#22797;&#24418;&#32467;&#26500;&#65288;&#31867;&#20284;&#20110;&#22270;&#24418;&#65292;&#20854;&#20013;&#36793;&#32536;&#21487;&#24418;&#25104;&#19977;&#35282;&#38754;&#65289;&#30340;&#20989;&#25968;&#24314;&#27169;&#30340;&#26377;&#21407;&#21017;&#30340;&#39640;&#26031;&#36807;&#31243;&#65288;GPs&#65289;&#12290;&#36825;&#31181;&#26041;&#27861;&#36866;&#29992;&#20110;&#23398;&#20064;&#32593;&#32476;&#19978;&#30340;&#27969;&#21160;&#31867;&#22411;&#25968;&#25454;&#65292;&#20854;&#20013;&#36793;&#32536;&#27969;&#21487;&#20197;&#36890;&#36807;&#31163;&#25955;&#30340;&#25955;&#24230;&#21644;&#26059;&#24230;&#26469;&#34920;&#24449;&#12290;&#20511;&#37492;Hodge&#20998;&#35299;&#65292;&#25105;&#20204;&#39318;&#20808;&#24320;&#21457;&#20102;&#36866;&#29992;&#20110;&#21508;&#31181;&#24212;&#29992;&#30340;&#26080;&#25955;&#24230;&#21644;&#26080;&#26059;&#28216;&#30340;&#36793;&#32536;GPs&#12290;&#28982;&#21518;&#23558;&#23427;&#20204;&#32452;&#21512;&#36215;&#26469;&#21019;&#24314;Hodge-&#32452;&#21512;&#36793;&#32536;GPs&#65292;&#36825;&#20123;GPs&#36275;&#22815;&#34920;&#36798;&#20219;&#20309;&#36793;&#32536;&#20989;&#25968;&#12290;&#36825;&#20123;GPs&#20415;&#20110;&#23545;&#36793;&#32536;&#20989;&#25968;&#30340;&#19981;&#21516;Hodge&#20998;&#37327;&#36827;&#34892;&#30452;&#25509;&#21644;&#29420;&#31435;&#30340;&#23398;&#20064;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#22312;&#36229;&#21442;&#25968;&#20248;&#21270;&#36807;&#31243;&#20013;&#25429;&#25417;&#23427;&#20204;&#30340;&#30456;&#20851;&#24615;&#12290;&#20026;&#20102;&#31361;&#26174;&#23427;&#20204;&#30340;&#23454;&#38469;&#28508;&#21147;&#65292;&#25105;&#20204;&#23558;&#23427;&#20204;&#24212;&#29992;&#20110;&#36135;&#24065;&#20817;&#25442;&#12289;&#28023;&#27915;&#27969;&#21160;&#21644;&#20379;&#27700;&#32593;&#32476;&#20013;&#30340;&#27969;&#21160;&#25968;&#25454;&#25512;&#26029;&#65292;&#24182;&#23558;&#20854;&#19982;&#26367;&#20195;&#27169;&#22411;&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose principled Gaussian processes (GPs) for modeling functions defined over the edge set of a simplicial 2-complex, a structure similar to a graph in which edges may form triangular faces. This approach is intended for learning flow-type data on networks where edge flows can be characterized by the discrete divergence and curl. Drawing upon the Hodge decomposition, we first develop classes of divergence-free and curl-free edge GPs, suitable for various applications. We then combine them to create \emph{Hodge-compositional edge GPs} that are expressive enough to represent any edge function. These GPs facilitate direct and independent learning for the different Hodge components of edge functions, enabling us to capture their relevance during hyperparameter optimization. To highlight their practical potential, we apply them for flow data inference in currency exchange, ocean flows and water supply networks, comparing them to alternative models.
&lt;/p&gt;</description></item><item><title>&#39318;&#27425;&#23558;&#21306;&#38388;&#20540;&#25968;&#25454;&#21644;&#21306;&#38388;&#20540;&#20989;&#25968;&#25968;&#25454;&#20316;&#20026;&#36755;&#20837;&#32771;&#34385;&#65292;&#22312;&#24207;&#25968;&#20998;&#31867;&#38382;&#39064;&#20013;&#25552;&#20986;&#20102;&#20845;&#31181;&#20998;&#31867;&#22120;&#65292;&#20854;&#20013;&#19968;&#31181;&#20351;&#29992;&#20102;&#26680;&#24341;&#23548;&#30340;&#24207;&#25968;&#38543;&#26426;&#26862;&#26519;&#26041;&#27861;&#65292;&#24182;&#19982;&#26420;&#32032;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;</title><link>http://arxiv.org/abs/2310.19433</link><description>&lt;p&gt;
&#21306;&#38388;&#20540;&#25968;&#25454;&#21644;&#21306;&#38388;&#20540;&#20989;&#25968;&#25968;&#25454;&#30340;&#24207;&#25968;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Ordinal classification for interval-valued data and interval-valued functional data. (arXiv:2310.19433v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19433
&lt;/p&gt;
&lt;p&gt;
&#39318;&#27425;&#23558;&#21306;&#38388;&#20540;&#25968;&#25454;&#21644;&#21306;&#38388;&#20540;&#20989;&#25968;&#25968;&#25454;&#20316;&#20026;&#36755;&#20837;&#32771;&#34385;&#65292;&#22312;&#24207;&#25968;&#20998;&#31867;&#38382;&#39064;&#20013;&#25552;&#20986;&#20102;&#20845;&#31181;&#20998;&#31867;&#22120;&#65292;&#20854;&#20013;&#19968;&#31181;&#20351;&#29992;&#20102;&#26680;&#24341;&#23548;&#30340;&#24207;&#25968;&#38543;&#26426;&#26862;&#26519;&#26041;&#27861;&#65292;&#24182;&#19982;&#26420;&#32032;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24207;&#25968;&#20998;&#31867;&#30340;&#30446;&#26631;&#26159;&#20174;&#19968;&#32452;&#35266;&#23519;&#21040;&#30340;&#36755;&#20837;&#20013;&#39044;&#27979;&#36755;&#20986;&#30340;&#26377;&#24207;&#26631;&#31614;&#12290;&#21306;&#38388;&#20540;&#25968;&#25454;&#25351;&#30340;&#26159;&#20197;&#21306;&#38388;&#24418;&#24335;&#34920;&#31034;&#30340;&#25968;&#25454;&#12290;&#39318;&#27425;&#23558;&#21306;&#38388;&#20540;&#25968;&#25454;&#21644;&#21306;&#38388;&#20540;&#20989;&#25968;&#25968;&#25454;&#20316;&#20026;&#24207;&#25968;&#20998;&#31867;&#38382;&#39064;&#30340;&#36755;&#20837;&#32771;&#34385;&#12290;&#25552;&#20986;&#20102;&#20845;&#31181;&#29992;&#20110;&#21306;&#38388;&#25968;&#25454;&#21644;&#21306;&#38388;&#20540;&#20989;&#25968;&#25968;&#25454;&#30340;&#24207;&#25968;&#20998;&#31867;&#22120;&#12290;&#20854;&#20013;&#19977;&#31181;&#26159;&#21442;&#25968;&#21270;&#30340;&#65292;&#19968;&#31181;&#22522;&#20110;&#24207;&#25968;&#20108;&#20803;&#20998;&#35299;&#65292;&#21478;&#22806;&#20004;&#31181;&#22522;&#20110;&#26377;&#24207;&#36923;&#36753;&#22238;&#24402;&#12290;&#21478;&#22806;&#19977;&#31181;&#26041;&#27861;&#22522;&#20110;&#21306;&#38388;&#25968;&#25454;&#20043;&#38388;&#30340;&#36317;&#31163;&#21644;&#21306;&#38388;&#25968;&#25454;&#19978;&#30340;&#26680;&#20989;&#25968;&#12290;&#20854;&#20013;&#19968;&#31181;&#26041;&#27861;&#20351;&#29992;&#21152;&#26435;$k$&#26368;&#36817;&#37051;&#25216;&#26415;&#36827;&#34892;&#24207;&#25968;&#20998;&#31867;&#12290;&#21478;&#19968;&#31181;&#26041;&#27861;&#32771;&#34385;&#20102;&#26680;&#20027;&#25104;&#20998;&#20998;&#26512;&#21644;&#19968;&#20010;&#24207;&#25968;&#20998;&#31867;&#22120;&#12290;&#32780;&#34920;&#29616;&#26368;&#22909;&#30340;&#31532;&#20845;&#31181;&#26041;&#27861;&#20351;&#29992;&#20102;&#22522;&#20110;&#26680;&#30340;&#24207;&#25968;&#38543;&#26426;&#26862;&#26519;&#12290;&#23427;&#20204;&#19982;&#26420;&#32032;&#26041;&#27861;&#22312;&#19968;&#20010;&#23454;&#39564;&#20013;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
The aim of ordinal classification is to predict the ordered labels of the output from a set of observed inputs. Interval-valued data refers to data in the form of intervals. For the first time, interval-valued data and interval-valued functional data are considered as inputs in an ordinal classification problem. Six ordinal classifiers for interval data and interval-valued functional data are proposed. Three of them are parametric, one of them is based on ordinal binary decompositions and the other two are based on ordered logistic regression. The other three methods are based on the use of distances between interval data and kernels on interval data. One of the methods uses the weighted $k$-nearest-neighbor technique for ordinal classification. Another method considers kernel principal component analysis plus an ordinal classifier. And the sixth method, which is the method that performs best, uses a kernel-induced ordinal random forest. They are compared with na\"ive approaches in an 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#20174;&#25968;&#25454;&#20013;&#30452;&#25509;&#25512;&#26029;&#38544;&#24335;&#32467;&#26500;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#25216;&#26415;&#65292;&#33021;&#22815;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#65292;&#24182;&#21487;&#33021;&#25913;&#21892;&#39044;&#27979;&#24615;&#33021;&#21644;&#26657;&#20934;&#12290;</title><link>http://arxiv.org/abs/2310.19390</link><description>&lt;p&gt;
&#38544;&#24335;&#27969;&#24418;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Implicit Manifold Gaussian Process Regression. (arXiv:2310.19390v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19390
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#20174;&#25968;&#25454;&#20013;&#30452;&#25509;&#25512;&#26029;&#38544;&#24335;&#32467;&#26500;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#25216;&#26415;&#65292;&#33021;&#22815;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#65292;&#24182;&#21487;&#33021;&#25913;&#21892;&#39044;&#27979;&#24615;&#33021;&#21644;&#26657;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#22240;&#20854;&#33021;&#22815;&#25552;&#20379;&#33391;&#22909;&#26657;&#20934;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#21644;&#22788;&#29702;&#23567;&#22411;&#25110;&#31232;&#30095;&#25968;&#25454;&#38598;&#30340;&#33021;&#21147;&#32780;&#34987;&#24191;&#27867;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#39640;&#32500;&#25968;&#25454;&#65292;&#23427;&#23384;&#22312;&#19968;&#23450;&#22256;&#38590;&#12290;&#19968;&#31181;&#23558;&#36825;&#31181;&#25216;&#26415;&#25193;&#23637;&#21040;&#26356;&#39640;&#32500;&#24230;&#30340;&#21487;&#33021;&#36884;&#24452;&#26159;&#21033;&#29992;&#25968;&#25454;&#23454;&#38469;&#25152;&#22788;&#30340;&#38544;&#24335;&#20302;&#32500;&#27969;&#24418;&#65292;&#36825;&#26159;&#27969;&#24418;&#20551;&#35774;&#25152;&#20551;&#23450;&#30340;&#12290;&#20808;&#21069;&#30340;&#24037;&#20316;&#36890;&#24120;&#35201;&#27714;&#26174;&#24335;&#25552;&#20379;&#27969;&#24418;&#32467;&#26500;&#65292;&#21363;&#30001;&#32593;&#26684;&#25110;&#24050;&#30693;&#20026;&#20247;&#25152;&#21608;&#30693;&#30340;&#27969;&#24418;&#20043;&#19968;&#65288;&#22914;&#29699;&#20307;&#65289;&#32473;&#20986;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#20197;&#23436;&#20840;&#21487;&#24494;&#30340;&#26041;&#24335;&#20174;&#25968;&#25454;&#65288;&#26631;&#35760;&#21644;&#26410;&#26631;&#35760;&#30340;&#65289;&#20013;&#25512;&#26029;&#20986;&#38544;&#24335;&#32467;&#26500;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#25216;&#26415;&#12290;&#23545;&#20110;&#24471;&#21040;&#30340;&#27169;&#22411;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#20854;&#22312;&#20551;&#35774;&#27969;&#24418;&#19978;&#25910;&#25947;&#20110;Mat&#233;rn&#39640;&#26031;&#36807;&#31243;&#12290;&#25105;&#20204;&#30340;&#25216;&#26415;&#21487;&#25193;&#23637;&#21040;&#25968;&#21313;&#19975;&#20010;&#25968;&#25454;&#28857;&#65292;&#24182;&#19988;&#21487;&#33021;&#25913;&#21892;&#39044;&#27979;&#24615;&#33021;&#21644;&#26657;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian process regression is widely used because of its ability to provide well-calibrated uncertainty estimates and handle small or sparse datasets. However, it struggles with high-dimensional data. One possible way to scale this technique to higher dimensions is to leverage the implicit low-dimensional manifold upon which the data actually lies, as postulated by the manifold hypothesis. Prior work ordinarily requires the manifold structure to be explicitly provided though, i.e. given by a mesh or be known to be one of the well-known manifolds like the sphere. In contrast, in this paper we propose a Gaussian process regression technique capable of inferring implicit structure directly from data (labeled and unlabeled) in a fully differentiable way. For the resulting model, we discuss its convergence to the Mat\'ern Gaussian process on the assumed manifold. Our technique scales up to hundreds of thousands of data points, and may improve the predictive performance and calibration of t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#26500;&#24314;&#23545;&#38750;&#21442;&#25968;&#27979;&#35797;&#38382;&#39064;&#36827;&#34892;&#24378;&#22823;&#30340;&#39034;&#24207;&#20551;&#35774;&#26816;&#39564;&#12290;&#19982;&#20256;&#32479;&#30340;&#25209;&#37327;&#27979;&#35797;&#30456;&#27604;&#65292;&#35813;&#26694;&#26550;&#21487;&#20197;&#25345;&#32493;&#30417;&#25511;&#22312;&#32447;&#25968;&#25454;&#27969;&#24182;&#26377;&#25928;&#22320;&#32858;&#21512;&#21453;&#23545;&#38646;&#20551;&#35774;&#30340;&#35777;&#25454;&#65292;&#21516;&#26102;&#20005;&#26684;&#25511;&#21046;I&#22411;&#38169;&#35823;&#65292;&#24182;&#26681;&#25454;&#38382;&#39064;&#30340;&#22256;&#38590;&#31243;&#24230;&#35843;&#25972;&#26679;&#26412;&#22823;&#23567;&#35201;&#27714;&#12290;</title><link>http://arxiv.org/abs/2310.19384</link><description>&lt;p&gt;
&#28145;&#24230;&#23454;&#26102;&#26377;&#25928;&#30340;&#20551;&#35774;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Deep anytime-valid hypothesis testing. (arXiv:2310.19384v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19384
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#26500;&#24314;&#23545;&#38750;&#21442;&#25968;&#27979;&#35797;&#38382;&#39064;&#36827;&#34892;&#24378;&#22823;&#30340;&#39034;&#24207;&#20551;&#35774;&#26816;&#39564;&#12290;&#19982;&#20256;&#32479;&#30340;&#25209;&#37327;&#27979;&#35797;&#30456;&#27604;&#65292;&#35813;&#26694;&#26550;&#21487;&#20197;&#25345;&#32493;&#30417;&#25511;&#22312;&#32447;&#25968;&#25454;&#27969;&#24182;&#26377;&#25928;&#22320;&#32858;&#21512;&#21453;&#23545;&#38646;&#20551;&#35774;&#30340;&#35777;&#25454;&#65292;&#21516;&#26102;&#20005;&#26684;&#25511;&#21046;I&#22411;&#38169;&#35823;&#65292;&#24182;&#26681;&#25454;&#38382;&#39064;&#30340;&#22256;&#38590;&#31243;&#24230;&#35843;&#25972;&#26679;&#26412;&#22823;&#23567;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#26500;&#24314;&#38750;&#21442;&#25968;&#27979;&#35797;&#38382;&#39064;&#30340;&#24378;&#22823;&#30340;&#39034;&#24207;&#20551;&#35774;&#26816;&#39564;&#12290;&#36825;&#20123;&#38382;&#39064;&#30340;&#38646;&#20551;&#35774;&#20351;&#29992;&#20004;&#20010;&#24050;&#30693;&#25805;&#20316;&#31526;&#23545;&#25968;&#25454;&#20998;&#24067;&#36827;&#34892;&#25277;&#35937;&#23450;&#20041;&#12290;&#36825;&#31181;&#25277;&#35937;&#20801;&#35768;&#23545;&#22810;&#20010;&#32463;&#20856;&#20219;&#21153;&#65288;&#22914;&#20004;&#26679;&#26412;&#26816;&#39564;&#12289;&#29420;&#31435;&#24615;&#26816;&#39564;&#21644;&#26465;&#20214;&#29420;&#31435;&#24615;&#26816;&#39564;&#65289;&#20197;&#21450;&#29616;&#20195;&#38382;&#39064;&#65288;&#22914;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#23545;&#25239;&#24615;&#40065;&#26834;&#24615;&#26816;&#39564;&#65289;&#36827;&#34892;&#32479;&#19968;&#22788;&#29702;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;&#30456;&#23545;&#20110;&#32463;&#20856;&#25209;&#37327;&#27979;&#35797;&#20855;&#26377;&#20197;&#19979;&#20248;&#21183;&#65306;1&#65289;&#23427;&#25345;&#32493;&#30417;&#25511;&#22312;&#32447;&#25968;&#25454;&#27969;&#24182;&#26377;&#25928;&#22320;&#32858;&#21512;&#21453;&#23545;&#38646;&#20551;&#35774;&#30340;&#35777;&#25454;&#65292;2&#65289;&#23427;&#22312;&#19981;&#38656;&#35201;&#22810;&#37325;&#27979;&#35797;&#20462;&#27491;&#30340;&#24773;&#20917;&#19979;&#23545;I&#22411;&#38169;&#35823;&#26377;&#20005;&#26684;&#25511;&#21046;&#65292;3&#65289;&#23427;&#23558;&#26679;&#26412;&#22823;&#23567;&#30340;&#35201;&#27714;&#35843;&#25972;&#21040;&#38382;&#39064;&#30340;&#26410;&#30693;&#22256;&#38590;&#31243;&#24230;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#34920;&#31034;&#33021;&#21147;&#30340;&#21407;&#21017;&#24615;&#26041;&#27861;&#65292;&#20197;&#8230;&#8230;
&lt;/p&gt;
&lt;p&gt;
We propose a general framework for constructing powerful, sequential hypothesis tests for a large class of nonparametric testing problems. The null hypothesis for these problems is defined in an abstract form using the action of two known operators on the data distribution. This abstraction allows for a unified treatment of several classical tasks, such as two-sample testing, independence testing, and conditional-independence testing, as well as modern problems, such as testing for adversarial robustness of machine learning (ML) models. Our proposed framework has the following advantages over classical batch tests: 1) it continuously monitors online data streams and efficiently aggregates evidence against the null, 2) it provides tight control over the type I error without the need for multiple testing correction, 3) it adapts the sample size requirement to the unknown hardness of the problem. We develop a principled approach of leveraging the representation capability of ML models wit
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#38480;&#22791;&#36873;&#26041;&#26696;&#38598;&#21512;&#20013;&#30340;&#32431;&#25506;&#32034;&#38382;&#39064;&#12290;&#36890;&#36807;&#20351;&#29992;&#23545;&#20598;&#21464;&#37327;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#35774;&#35745;&#21407;&#21017;&#65292;&#33021;&#22815;&#36991;&#20813;&#32452;&#21512;&#32467;&#26500;&#30340;&#22797;&#26434;&#24615;&#65292;&#23454;&#29616;&#39640;&#25928;&#32431;&#25506;&#32034;&#65292;&#20174;&#32780;&#20934;&#30830;&#22238;&#31572;&#26597;&#35810;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.19319</link><description>&lt;p&gt;
&#39640;&#25928;&#32431;&#25506;&#32034;&#30340;&#21452;&#21521;&#31639;&#27861;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Dual-Directed Algorithm Design for Efficient Pure Exploration. (arXiv:2310.19319v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19319
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#38480;&#22791;&#36873;&#26041;&#26696;&#38598;&#21512;&#20013;&#30340;&#32431;&#25506;&#32034;&#38382;&#39064;&#12290;&#36890;&#36807;&#20351;&#29992;&#23545;&#20598;&#21464;&#37327;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#35774;&#35745;&#21407;&#21017;&#65292;&#33021;&#22815;&#36991;&#20813;&#32452;&#21512;&#32467;&#26500;&#30340;&#22797;&#26434;&#24615;&#65292;&#23454;&#29616;&#39640;&#25928;&#32431;&#25506;&#32034;&#65292;&#20174;&#32780;&#20934;&#30830;&#22238;&#31572;&#26597;&#35810;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#26377;&#38480;&#30340;&#22791;&#36873;&#26041;&#26696;&#38598;&#21512;&#20013;&#30340;&#38543;&#26426;&#39034;&#24207;&#33258;&#36866;&#24212;&#23454;&#39564;&#30340;&#32431;&#25506;&#32034;&#38382;&#39064;&#12290;&#20915;&#31574;&#32773;&#30340;&#30446;&#26631;&#26159;&#36890;&#36807;&#26368;&#23567;&#30340;&#27979;&#37327;&#24037;&#20316;&#20197;&#39640;&#32622;&#20449;&#24230;&#20934;&#30830;&#22238;&#31572;&#19982;&#22791;&#36873;&#26041;&#26696;&#30456;&#20851;&#30340;&#26597;&#35810;&#38382;&#39064;&#12290;&#19968;&#20010;&#20856;&#22411;&#30340;&#26597;&#35810;&#38382;&#39064;&#26159;&#30830;&#23450;&#34920;&#29616;&#26368;&#20339;&#30340;&#22791;&#36873;&#26041;&#26696;&#65292;&#36825;&#22312;&#25490;&#21517;&#21644;&#36873;&#25321;&#38382;&#39064;&#20197;&#21450;&#26426;&#22120;&#23398;&#20064;&#25991;&#29486;&#20013;&#31216;&#20026;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#22266;&#23450;&#31934;&#24230;&#30340;&#35774;&#23450;&#65292;&#24182;&#23548;&#20986;&#20102;&#19968;&#20010;&#19982;&#26679;&#26412;&#26368;&#20248;&#20998;&#37197;&#26377;&#24378;&#25910;&#25947;&#24615;&#27010;&#24565;&#30456;&#20851;&#30340;&#20248;&#21270;&#26465;&#20214;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#20351;&#29992;&#23545;&#20598;&#21464;&#37327;&#65292;&#25105;&#20204;&#21051;&#30011;&#20102;&#19968;&#20010;&#20998;&#37197;&#26159;&#21542;&#26368;&#20248;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#12290;&#23545;&#20598;&#21464;&#37327;&#30340;&#20351;&#29992;&#20351;&#25105;&#20204;&#33021;&#22815;&#32469;&#36807;&#23436;&#20840;&#20381;&#36182;&#20110;&#21407;&#22987;&#21464;&#37327;&#30340;&#26368;&#20248;&#26465;&#20214;&#30340;&#32452;&#21512;&#32467;&#26500;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#36825;&#20123;&#26368;&#20248;&#26465;&#20214;&#20351;&#24471;&#21452;&#21521;&#31639;&#27861;&#35774;&#35745;&#21407;&#21017;&#30340;&#25193;&#23637;&#25104;&#20026;&#21487;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider pure-exploration problems in the context of stochastic sequential adaptive experiments with a finite set of alternative options. The goal of the decision-maker is to accurately answer a query question regarding the alternatives with high confidence with minimal measurement efforts. A typical query question is to identify the alternative with the best performance, leading to ranking and selection problems, or best-arm identification in the machine learning literature. We focus on the fixed-precision setting and derive a sufficient condition for optimality in terms of a notion of strong convergence to the optimal allocation of samples. Using dual variables, we characterize the necessary and sufficient conditions for an allocation to be optimal. The use of dual variables allow us to bypass the combinatorial structure of the optimality conditions that relies solely on primal variables. Remarkably, these optimality conditions enable an extension of top-two algorithm design princ
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#21160;&#24577;&#27835;&#30103;&#30340;&#38454;&#27573;&#24863;&#30693;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#20272;&#35745;DTR&#24182;&#20248;&#20808;&#32771;&#34385;&#27835;&#30103;&#36712;&#36857;&#19982;&#26368;&#20339;&#27835;&#30103;&#26041;&#26696;&#22312;&#20915;&#31574;&#38454;&#27573;&#19978;&#30340;&#19968;&#33268;&#24615;&#65292;&#22312;&#25552;&#39640;&#26679;&#26412;&#25928;&#29575;&#21644;&#31283;&#23450;&#24615;&#26041;&#38754;&#21462;&#24471;&#20102;&#37325;&#35201;&#36827;&#23637;&#12290;</title><link>http://arxiv.org/abs/2310.19300</link><description>&lt;p&gt;
&#38024;&#23545;&#21160;&#24577;&#27835;&#30103;&#30340;&#38454;&#27573;&#24863;&#30693;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Stage-Aware Learning for Dynamic Treatments. (arXiv:2310.19300v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19300
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#21160;&#24577;&#27835;&#30103;&#30340;&#38454;&#27573;&#24863;&#30693;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#20272;&#35745;DTR&#24182;&#20248;&#20808;&#32771;&#34385;&#27835;&#30103;&#36712;&#36857;&#19982;&#26368;&#20339;&#27835;&#30103;&#26041;&#26696;&#22312;&#20915;&#31574;&#38454;&#27573;&#19978;&#30340;&#19968;&#33268;&#24615;&#65292;&#22312;&#25552;&#39640;&#26679;&#26412;&#25928;&#29575;&#21644;&#31283;&#23450;&#24615;&#26041;&#38754;&#21462;&#24471;&#20102;&#37325;&#35201;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#23545;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;&#65288;DTRs&#65289;&#30340;&#30740;&#31350;&#21462;&#24471;&#20102;&#37325;&#35201;&#36827;&#23637;&#65292;&#25552;&#20986;&#20102;&#24378;&#22823;&#30340;&#20248;&#21270;&#27835;&#30103;&#25628;&#32034;&#31639;&#27861;&#65292;&#26681;&#25454;&#20010;&#20307;&#20855;&#20307;&#38656;&#27714;&#37327;&#36523;&#23450;&#21046;&#65292;&#24182;&#33021;&#26368;&#22823;&#21270;&#20854;&#39044;&#26399;&#30340;&#20020;&#24202;&#25928;&#30410;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#31639;&#27861;&#22312;&#20248;&#21270;&#27835;&#30103;&#19979;&#21487;&#33021;&#20250;&#21463;&#21040;&#26679;&#26412;&#37327;&#19981;&#36275;&#30340;&#22256;&#25200;&#65292;&#23588;&#20854;&#26159;&#22312;&#28041;&#21450;&#38271;&#26102;&#38388;&#20915;&#31574;&#38454;&#27573;&#30340;&#24930;&#24615;&#30142;&#30149;&#20013;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20010;&#20307;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#37325;&#28857;&#26159;&#20272;&#35745;DTR&#65292;&#24182;&#20248;&#20808;&#32771;&#34385;&#35266;&#23519;&#21040;&#30340;&#27835;&#30103;&#36712;&#36857;&#19982;&#26368;&#20339;&#27835;&#30103;&#26041;&#26696;&#22312;&#20915;&#31574;&#38454;&#27573;&#19978;&#30340;&#19968;&#33268;&#24615;&#12290;&#36890;&#36807;&#25918;&#23485;&#35266;&#23519;&#21040;&#30340;&#36712;&#36857;&#24517;&#39035;&#23436;&#20840;&#19982;&#26368;&#20339;&#27835;&#30103;&#19968;&#33268;&#30340;&#38480;&#21046;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22823;&#22823;&#25552;&#39640;&#20102;&#22522;&#20110;&#20498;&#25968;&#27010;&#29575;&#21152;&#26435;&#26041;&#27861;&#30340;&#26679;&#26412;&#25928;&#29575;&#21644;&#31283;&#23450;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25152;&#25552;&#20986;&#30340;&#23398;&#20064;&#26041;&#26696;&#26500;&#24314;&#20102;&#19968;&#20010;&#26356;&#36890;&#29992;&#30340;&#26694;&#26550;&#65292;&#21253;&#25324;&#20102;&#27969;&#34892;&#30340;&#32467;&#26524;&#21152;&#26435;&#23398;&#20064;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advances in dynamic treatment regimes (DTRs) provide powerful optimal treatment searching algorithms, which are tailored to individuals' specific needs and able to maximize their expected clinical benefits. However, existing algorithms could suffer from insufficient sample size under optimal treatments, especially for chronic diseases involving long stages of decision-making. To address these challenges, we propose a novel individualized learning method which estimates the DTR with a focus on prioritizing alignment between the observed treatment trajectory and the one obtained by the optimal regime across decision stages. By relaxing the restriction that the observed trajectory must be fully aligned with the optimal treatments, our approach substantially improves the sample efficiency and stability of inverse probability weighted based methods. In particular, the proposed learning scheme builds a more general framework which includes the popular outcome weighted learning framewo
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#20171;&#32461;&#20102;&#35760;&#24518;&#25200;&#21160;&#26041;&#31243;&#65288;MPE&#65289;&#65292;&#35813;&#26041;&#31243;&#36890;&#36807;&#24212;&#29992;&#36125;&#21494;&#26031;&#21407;&#29702;&#23558;&#27169;&#22411;&#30340;&#25935;&#24863;&#24615;&#19982;&#35757;&#32451;&#25968;&#25454;&#30340;&#25200;&#21160;&#32852;&#31995;&#36215;&#26469;&#65292;&#24182;&#19988;&#33021;&#22815;&#20934;&#30830;&#39044;&#27979;&#27169;&#22411;&#22312;&#26410;&#35265;&#27979;&#35797;&#25968;&#25454;&#19978;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.19273</link><description>&lt;p&gt;
The Memory Perturbation Equation: Understanding Model's Sensitivity to Data&#65288;&#29702;&#35299;&#27169;&#22411;&#23545;&#25968;&#25454;&#30340;&#25935;&#24863;&#24615;&#30340;&#35760;&#24518;&#25200;&#21160;&#26041;&#31243;&#65289;
&lt;/p&gt;
&lt;p&gt;
The Memory Perturbation Equation: Understanding Model's Sensitivity to Data. (arXiv:2310.19273v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19273
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#20171;&#32461;&#20102;&#35760;&#24518;&#25200;&#21160;&#26041;&#31243;&#65288;MPE&#65289;&#65292;&#35813;&#26041;&#31243;&#36890;&#36807;&#24212;&#29992;&#36125;&#21494;&#26031;&#21407;&#29702;&#23558;&#27169;&#22411;&#30340;&#25935;&#24863;&#24615;&#19982;&#35757;&#32451;&#25968;&#25454;&#30340;&#25200;&#21160;&#32852;&#31995;&#36215;&#26469;&#65292;&#24182;&#19988;&#33021;&#22815;&#20934;&#30830;&#39044;&#27979;&#27169;&#22411;&#22312;&#26410;&#35265;&#27979;&#35797;&#25968;&#25454;&#19978;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#27169;&#22411;&#23545;&#20854;&#35757;&#32451;&#25968;&#25454;&#30340;&#25935;&#24863;&#24615;&#23545;&#20110;&#35757;&#32451;&#36807;&#31243;&#33267;&#20851;&#37325;&#35201;&#65292;&#20294;&#20063;&#21487;&#33021;&#20855;&#26377;&#25361;&#25112;&#24615;&#21644;&#25104;&#26412;&#39640;&#26114;&#12290;&#20026;&#20102;&#31616;&#21270;&#36825;&#31867;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#35760;&#24518;&#25200;&#21160;&#26041;&#31243;&#65288;MPE&#65289;&#65292;&#23427;&#23558;&#27169;&#22411;&#30340;&#25935;&#24863;&#24615;&#19982;&#20854;&#35757;&#32451;&#25968;&#25454;&#30340;&#25200;&#21160;&#32852;&#31995;&#36215;&#26469;&#12290;&#20351;&#29992;&#36125;&#21494;&#26031;&#21407;&#29702;&#23548;&#20986;&#30340;MPE&#23558;&#29616;&#26377;&#30340;&#25935;&#24863;&#24615;&#24230;&#37327;&#32479;&#19968;&#36215;&#26469;&#65292;&#27867;&#21270;&#21040;&#21508;&#31181;&#27169;&#22411;&#21644;&#31639;&#27861;&#65292;&#24182;&#25581;&#31034;&#20102;&#26377;&#20851;&#25935;&#24863;&#24615;&#30340;&#26377;&#29992;&#24615;&#36136;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#35757;&#32451;&#36807;&#31243;&#20013;&#33719;&#24471;&#30340;&#25935;&#24863;&#24615;&#20272;&#35745;&#21487;&#20197;&#20934;&#30830;&#39044;&#27979;&#22312;&#26410;&#35265;&#27979;&#35797;&#25968;&#25454;&#19978;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#35813;&#25552;&#20986;&#30340;&#26041;&#31243;&#39044;&#35745;&#23558;&#23545;&#26410;&#26469;&#30340;&#40065;&#26834;&#21644;&#33258;&#36866;&#24212;&#23398;&#20064;&#30740;&#31350;&#26377;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding model's sensitivity to its training data is crucial but can also be challenging and costly, especially during training. To simplify such issues, we present the Memory-Perturbation Equation (MPE) which relates model's sensitivity to perturbation in its training data. Derived using Bayesian principles, the MPE unifies existing sensitivity measures, generalizes them to a wide-variety of models and algorithms, and unravels useful properties regarding sensitivities. Our empirical results show that sensitivity estimates obtained during training can be used to faithfully predict generalization on unseen test data. The proposed equation is expected to be useful for future research on robust and adaptive learning.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#22312;&#38750;&#27431;&#20960;&#37324;&#24503;&#23545;&#31216;&#31354;&#38388;&#19978;&#23450;&#20041;&#30340;&#32463;&#20856;&#39640;&#26031;&#26680;&#22312;&#20219;&#24847;&#21442;&#25968;&#36873;&#25321;&#19979;&#37117;&#19981;&#26159;&#27491;&#23450;&#30340;&#65292;&#36890;&#36807;&#21457;&#23637;&#26032;&#30340;&#20960;&#20309;&#21644;&#20998;&#26512;&#35770;&#35777;&#65292;&#24182;&#19988;&#32473;&#20986;&#20102;&#27491;&#23450;&#24615;&#30340;&#20005;&#26684;&#21051;&#30011;&#20197;&#21450;L$^{\!\scriptscriptstyle p}$-$\hspace{0.02cm}$Godement&#23450;&#29702;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2310.19270</link><description>&lt;p&gt;
&#22312;&#40654;&#26364;&#23545;&#31216;&#31354;&#38388;&#19978;&#30340;&#19981;&#21464;&#26680;&#65306;&#19968;&#31181;&#35856;&#27874;&#20998;&#26512;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Invariant kernels on Riemannian symmetric spaces: a harmonic-analytic approach. (arXiv:2310.19270v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19270
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#22312;&#38750;&#27431;&#20960;&#37324;&#24503;&#23545;&#31216;&#31354;&#38388;&#19978;&#23450;&#20041;&#30340;&#32463;&#20856;&#39640;&#26031;&#26680;&#22312;&#20219;&#24847;&#21442;&#25968;&#36873;&#25321;&#19979;&#37117;&#19981;&#26159;&#27491;&#23450;&#30340;&#65292;&#36890;&#36807;&#21457;&#23637;&#26032;&#30340;&#20960;&#20309;&#21644;&#20998;&#26512;&#35770;&#35777;&#65292;&#24182;&#19988;&#32473;&#20986;&#20102;&#27491;&#23450;&#24615;&#30340;&#20005;&#26684;&#21051;&#30011;&#20197;&#21450;L$^{\!\scriptscriptstyle p}$-$\hspace{0.02cm}$Godement&#23450;&#29702;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#35777;&#26126;&#32463;&#20856;&#30340;&#39640;&#26031;&#26680;&#65292;&#22312;&#38750;&#27431;&#20960;&#37324;&#24503;&#23545;&#31216;&#31354;&#38388;&#19978;&#23450;&#20041;&#26102;&#65292;&#23545;&#20110;&#20219;&#24847;&#21442;&#25968;&#36873;&#25321;&#37117;&#19981;&#26159;&#27491;&#23450;&#30340;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#26412;&#25991;&#21457;&#23637;&#20102;&#26032;&#30340;&#20960;&#20309;&#21644;&#20998;&#26512;&#35770;&#35777;&#12290;&#36825;&#20123;&#35770;&#35777;&#25552;&#20379;&#20102;&#39640;&#26031;&#26680;&#27491;&#23450;&#24615;&#30340;&#20005;&#26684;&#21051;&#30011;&#65292;&#20294;&#20165;&#38480;&#20110;&#22312;&#20302;&#32500;&#20013;&#36890;&#36807;&#25968;&#20540;&#35745;&#31639;&#22788;&#29702;&#30340;&#26377;&#38480;&#24773;&#20917;&#12290;&#20854;&#20013;&#26368;&#37325;&#35201;&#30340;&#32467;&#26524;&#26159;L$^{\!\scriptscriptstyle p}$-$\hspace{0.02cm}$Godement&#23450;&#29702;&#65288;&#20854;&#20013;$p = 1,2$&#65289;&#65292;&#23427;&#25552;&#20379;&#20102;&#23450;&#20041;&#22312;&#38750;&#32039;&#22411;&#23545;&#31216;&#31354;&#38388;&#19978;&#30340;&#26680;&#26159;&#27491;&#23450;&#30340;&#21487;&#39564;&#35777;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#12290;&#19968;&#31181;&#33879;&#21517;&#30340;&#23450;&#29702;&#65292;&#26377;&#26102;&#34987;&#31216;&#20026;Bochner-Godement&#23450;&#29702;&#65292;&#24050;&#32463;&#32473;&#20986;&#20102;&#36825;&#26679;&#30340;&#26465;&#20214;&#65292;&#24182;&#19988;&#22312;&#36866;&#29992;&#33539;&#22260;&#19978;&#26356;&#21152;&#24191;&#27867;&#65292;&#20294;&#24212;&#29992;&#36215;&#26469;&#23588;&#20026;&#22256;&#38590;&#12290;&#38500;&#20102;&#19982;&#39640;&#26031;&#26680;&#30340;&#20851;&#32852;&#22806;&#65292;&#22312;&#26412;&#25991;&#20013;&#30340;&#26032;&#32467;&#26524;&#20026;s&#25552;&#20379;&#20102;&#19968;&#20010;&#34013;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work aims to prove that the classical Gaussian kernel, when defined on a non-Euclidean symmetric space, is never positive-definite for any choice of parameter. To achieve this goal, the paper develops new geometric and analytical arguments. These provide a rigorous characterization of the positive-definiteness of the Gaussian kernel, which is complete but for a limited number of scenarios in low dimensions that are treated by numerical computations. Chief among these results are the L$^{\!\scriptscriptstyle p}$-$\hspace{0.02cm}$Godement theorems (where $p = 1,2$), which provide verifiable necessary and sufficient conditions for a kernel defined on a symmetric space of non-compact type to be positive-definite. A celebrated theorem, sometimes called the Bochner-Godement theorem, already gives such conditions and is far more general in its scope, but is especially hard to apply. Beyond the connection with the Gaussian kernel, the new results in this work lay out a blueprint for the s
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;FlowDRO&#30340;&#35745;&#31639;&#39640;&#25928;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#22522;&#20110;&#27969;&#30340;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#20351;&#29992;&#27969;&#27169;&#22411;&#21644;Wasserstein&#36817;&#31471;&#26799;&#24230;&#27969;&#31867;&#22411;&#30340;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#23545;&#20855;&#26377;&#26356;&#22823;&#26679;&#26412;&#22823;&#23567;&#30340;&#38382;&#39064;&#30340;&#21487;&#25193;&#23637;&#24615;&#21644;&#26356;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.19253</link><description>&lt;p&gt;
&#22522;&#20110;&#27969;&#30340;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Flow-based Distributionally Robust Optimization. (arXiv:2310.19253v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19253
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;FlowDRO&#30340;&#35745;&#31639;&#39640;&#25928;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#22522;&#20110;&#27969;&#30340;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#20351;&#29992;&#27969;&#27169;&#22411;&#21644;Wasserstein&#36817;&#31471;&#26799;&#24230;&#27969;&#31867;&#22411;&#30340;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#23545;&#20855;&#26377;&#26356;&#22823;&#26679;&#26412;&#22823;&#23567;&#30340;&#38382;&#39064;&#30340;&#21487;&#25193;&#23637;&#24615;&#21644;&#26356;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;FlowDRO&#30340;&#35745;&#31639;&#39640;&#25928;&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#20915;&#22522;&#20110;&#27969;&#30340;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#65288;DRO&#65289;&#38382;&#39064;&#65292;&#20854;&#20013;&#35201;&#27714;&#26368;&#22351;&#24773;&#20917;&#20998;&#24067;&#65288;&#20063;&#31216;&#20026;&#26368;&#19981;&#21033;&#20998;&#24067;&#65292;LFD&#65289;&#26159;&#36830;&#32493;&#30340;&#65292;&#20174;&#32780;&#20351;&#24471;&#31639;&#27861;&#33021;&#22815;&#21487;&#25193;&#23637;&#21040;&#20855;&#26377;&#26356;&#22823;&#26679;&#26412;&#22823;&#23567;&#30340;&#38382;&#39064;&#65292;&#24182;&#23454;&#29616;&#23545;&#35825;&#23548;&#30340;&#40065;&#26834;&#31639;&#27861;&#30340;&#26356;&#22909;&#27867;&#21270;&#33021;&#21147;&#12290;&#20026;&#20102;&#35299;&#20915;&#35745;&#31639;&#19978;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#26080;&#38480;&#32500;&#20248;&#21270;&#38382;&#39064;&#65292;&#25105;&#20204;&#21033;&#29992;&#22522;&#20110;&#27969;&#30340;&#27169;&#22411;&#65292;&#22312;&#25968;&#25454;&#20998;&#24067;&#21644;&#30446;&#26631;&#20998;&#24067;&#20043;&#38388;&#36827;&#34892;&#36830;&#32493;&#26102;&#38388;&#21487;&#36870;&#20256;&#36755;&#26144;&#23556;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;Wasserstein&#36817;&#31471;&#26799;&#24230;&#27969;&#31867;&#22411;&#30340;&#31639;&#27861;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#36880;&#27493;&#35757;&#32451;&#22359;&#20869;&#30340;&#31070;&#32463;&#32593;&#32476;&#24207;&#21015;&#26469;&#21442;&#25968;&#21270;&#20256;&#36755;&#26144;&#23556;&#12290;&#25105;&#20204;&#30340;&#35745;&#31639;&#26694;&#26550;&#36890;&#29992;&#65292;&#33021;&#22815;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#21644;&#22823;&#26679;&#26412;&#22823;&#23567;&#65292;&#24182;&#21487;&#29992;&#20110;&#21508;&#31181;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a computationally efficient framework, called \texttt{FlowDRO}, for solving flow-based distributionally robust optimization (DRO) problems with Wasserstein uncertainty sets, when requiring the worst-case distribution (also called the Least Favorable Distribution, LFD) to be continuous so that the algorithm can be scalable to problems with larger sample sizes and achieve better generalization capability for the induced robust algorithms. To tackle the computationally challenging infinitely dimensional optimization problem, we leverage flow-based models, continuous-time invertible transport maps between the data distribution and the target distribution, and develop a Wasserstein proximal gradient flow type of algorithm. In practice, we parameterize the transport maps by a sequence of neural networks progressively trained in blocks by gradient descent. Our computational framework is general, can handle high-dimensional data with large sample sizes, and can be useful for various
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#21333;&#36890;&#36947;&#24212;&#29992;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#35889;&#27491;&#21017;&#21270;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#28304;&#22797;&#21046;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#19968;&#33268;&#30340;&#32447;&#24615;LVM&#20248;&#21270;&#26694;&#26550;&#12290;</title><link>http://arxiv.org/abs/2310.19246</link><description>&lt;p&gt;
&#29992;&#20110;&#21333;&#36890;&#36947;&#24212;&#29992;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#35889;&#27491;&#21017;&#21270;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A spectral regularisation framework for latent variable models designed for single channel applications. (arXiv:2310.19246v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19246
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#21333;&#36890;&#36947;&#24212;&#29992;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#35889;&#27491;&#21017;&#21270;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#28304;&#22797;&#21046;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#19968;&#33268;&#30340;&#32447;&#24615;LVM&#20248;&#21270;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28508;&#21464;&#37327;&#27169;&#22411;&#65288;LVMs&#65289;&#24120;&#29992;&#20110;&#25429;&#25417;&#35266;&#27979;&#25968;&#25454;&#20013;&#30340;&#28508;&#22312;&#20381;&#36182;&#20851;&#31995;&#12289;&#27169;&#24335;&#21644;&#38544;&#34255;&#32467;&#26500;&#12290;&#25968;&#25454;hankel&#21270;&#30340;&#39044;&#22788;&#29702;&#27493;&#39588;&#23548;&#33268;&#28304;&#22797;&#21046;&#65292;&#36825;&#26159;&#21333;&#36890;&#36947;LVM&#24212;&#29992;&#20013;&#30340;&#19968;&#20010;&#21103;&#20135;&#21697;&#65292;&#38459;&#30861;&#20102;&#23454;&#38469;&#30340;LVM&#21033;&#29992;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#21517;&#20026;spectrally-regularised-LVMs&#30340;Python&#21253;&#12290;&#35813;&#21253;&#36890;&#36807;&#24341;&#20837;&#19968;&#39033;&#26032;&#30340;&#35889;&#27491;&#21017;&#21270;&#39033;&#26469;&#35299;&#20915;&#28304;&#22797;&#21046;&#38382;&#39064;&#12290;&#35813;&#21253;&#25552;&#20379;&#20102;&#19968;&#20010;&#29992;&#20110;&#21333;&#36890;&#36947;LVM&#24212;&#29992;&#30340;&#35889;&#27491;&#21017;&#21270;&#26694;&#26550;&#65292;&#20174;&#32780;&#26356;&#23481;&#26131;&#22320;&#30740;&#31350;&#21644;&#21033;&#29992;&#24102;&#26377;&#35889;&#27491;&#21017;&#21270;&#30340;LVMs&#12290;&#36825;&#36890;&#36807;&#23558;&#28508;&#21464;&#37327;&#27169;&#22411;&#30446;&#26631;&#20989;&#25968;&#30340;&#31526;&#21495;&#25110;&#26174;&#24335;&#34920;&#31034;&#32435;&#20837;&#21040;&#19968;&#20010;&#26694;&#26550;&#20013;&#65292;&#22312;LVM&#21442;&#25968;&#20272;&#35745;&#36807;&#31243;&#20013;&#20351;&#29992;&#35889;&#27491;&#21017;&#21270;&#26469;&#23454;&#29616;&#12290;&#35813;&#21253;&#30340;&#30446;&#26631;&#26159;&#25552;&#20379;&#19968;&#31181;&#19968;&#33268;&#30340;&#32447;&#24615;LVM&#20248;&#21270;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
Latent variable models (LVMs) are commonly used to capture the underlying dependencies, patterns, and hidden structure in observed data. Source duplication is a by-product of the data hankelisation pre-processing step common to single channel LVM applications, which hinders practical LVM utilisation. In this article, a Python package titled spectrally-regularised-LVMs is presented. The proposed package addresses the source duplication issue via the addition of a novel spectral regularisation term. This package provides a framework for spectral regularisation in single channel LVM applications, thereby making it easier to investigate and utilise LVMs with spectral regularisation. This is achieved via the use of symbolic or explicit representations of potential LVM objective functions which are incorporated into a framework that uses spectral regularisation during the LVM parameter estimation process. The objective of this package is to provide a consistent linear LVM optimisation framew
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#32423;&#20302;&#31209;&#30697;&#38453;&#20013;&#30340;&#22240;&#23376;&#25311;&#21512;&#12289;&#31209;&#20998;&#37197;&#21644;&#20998;&#21106;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#30456;&#24212;&#30340;&#35299;&#20915;&#26041;&#27861;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#24320;&#28304;&#36719;&#20214;&#21253;&#12290;</title><link>http://arxiv.org/abs/2310.19214</link><description>&lt;p&gt;
&#22312;&#22810;&#32423;&#20302;&#31209;&#30697;&#38453;&#20013;&#36827;&#34892;&#22240;&#23376;&#25311;&#21512;&#12289;&#31209;&#20998;&#37197;&#21644;&#20998;&#21106;
&lt;/p&gt;
&lt;p&gt;
Factor Fitting, Rank Allocation, and Partitioning in Multilevel Low Rank Matrices. (arXiv:2310.19214v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19214
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#32423;&#20302;&#31209;&#30697;&#38453;&#20013;&#30340;&#22240;&#23376;&#25311;&#21512;&#12289;&#31209;&#20998;&#37197;&#21644;&#20998;&#21106;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#30456;&#24212;&#30340;&#35299;&#20915;&#26041;&#27861;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#24320;&#28304;&#36719;&#20214;&#21253;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22810;&#32423;&#20302;&#31209;&#65288;MLR&#65289;&#30697;&#38453;&#65292;&#23450;&#20041;&#20026;&#19968;&#31995;&#21015;&#30697;&#38453;&#30340;&#34892;&#21644;&#21015;&#30340;&#25490;&#21015;&#65292;&#27599;&#20010;&#30697;&#38453;&#37117;&#26159;&#21069;&#19968;&#20010;&#30697;&#38453;&#30340;&#22359;&#23545;&#35282;&#20462;&#27491;&#65292;&#25152;&#26377;&#22359;&#20197;&#22240;&#23376;&#24418;&#24335;&#32473;&#20986;&#20302;&#31209;&#30697;&#38453;&#12290;MLR&#30697;&#38453;&#25193;&#23637;&#20102;&#20302;&#31209;&#30697;&#38453;&#30340;&#27010;&#24565;&#65292;&#20294;&#23427;&#20204;&#20849;&#20139;&#35768;&#22810;&#29305;&#24615;&#65292;&#20363;&#22914;&#25152;&#38656;&#24635;&#23384;&#20648;&#31354;&#38388;&#21644;&#30697;&#38453;&#21521;&#37327;&#20056;&#27861;&#30340;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#35299;&#20915;&#20102;&#29992;Frobenius&#33539;&#25968;&#25311;&#21512;&#32473;&#23450;&#30697;&#38453;&#21040;MLR&#30697;&#38453;&#30340;&#19977;&#20010;&#38382;&#39064;&#12290;&#31532;&#19968;&#20010;&#38382;&#39064;&#26159;&#22240;&#23376;&#25311;&#21512;&#65292;&#36890;&#36807;&#35843;&#25972;MLR&#30697;&#38453;&#30340;&#22240;&#23376;&#26469;&#35299;&#20915;&#12290;&#31532;&#20108;&#20010;&#38382;&#39064;&#26159;&#31209;&#20998;&#37197;&#65292;&#22312;&#27599;&#20010;&#32423;&#21035;&#20013;&#36873;&#25321;&#22359;&#30340;&#31209;&#65292;&#28385;&#36275;&#24635;&#31209;&#30340;&#32473;&#23450;&#20540;&#65292;&#20197;&#20445;&#25345;MLR&#30697;&#38453;&#25152;&#38656;&#30340;&#24635;&#23384;&#20648;&#31354;&#38388;&#12290;&#26368;&#21518;&#19968;&#20010;&#38382;&#39064;&#26159;&#36873;&#25321;&#34892;&#21644;&#21015;&#30340;&#23618;&#27425;&#20998;&#21106;&#65292;&#20197;&#21450;&#31209;&#21644;&#22240;&#23376;&#12290;&#26412;&#25991;&#38468;&#24102;&#20102;&#19968;&#20010;&#24320;&#28304;&#36719;&#20214;&#21253;&#65292;&#23454;&#29616;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider multilevel low rank (MLR) matrices, defined as a row and column permutation of a sum of matrices, each one a block diagonal refinement of the previous one, with all blocks low rank given in factored form. MLR matrices extend low rank matrices but share many of their properties, such as the total storage required and complexity of matrix-vector multiplication. We address three problems that arise in fitting a given matrix by an MLR matrix in the Frobenius norm. The first problem is factor fitting, where we adjust the factors of the MLR matrix. The second is rank allocation, where we choose the ranks of the blocks in each level, subject to the total rank having a given value, which preserves the total storage needed for the MLR matrix. The final problem is to choose the hierarchical partition of rows and columns, along with the ranks and factors. This paper is accompanied by an open source package that implements the proposed methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#20849;&#24418;&#24402;&#19968;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#32593;&#26684;&#32454;&#32990;&#22312;2D&#29289;&#29702;&#31354;&#38388;&#20013;&#30340;&#33258;&#25105;&#20301;&#32622;&#20449;&#24687;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#26174;&#33879;&#20943;&#23567;&#20301;&#32622;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2310.19192</link><description>&lt;p&gt;
&#32593;&#26684;&#32454;&#32990;&#20013;&#30340;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#20849;&#24418;&#24402;&#19968;&#21270;
&lt;/p&gt;
&lt;p&gt;
Conformal Normalization in Recurrent Neural Network of Grid Cells. (arXiv:2310.19192v1 [q-bio.NC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19192
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#20849;&#24418;&#24402;&#19968;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#32593;&#26684;&#32454;&#32990;&#22312;2D&#29289;&#29702;&#31354;&#38388;&#20013;&#30340;&#33258;&#25105;&#20301;&#32622;&#20449;&#24687;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#26174;&#33879;&#20943;&#23567;&#20301;&#32622;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21754;&#20083;&#21160;&#29289;&#22823;&#33041;&#20013;&#39070;&#21494;&#30382;&#23618;&#30340;&#32593;&#26684;&#32454;&#32990;&#22312;2D&#24320;&#25918;&#29615;&#22659;&#20013;&#20197;&#24778;&#20154;&#30340;&#20845;&#35282;&#24418;&#21457;&#23556;&#27169;&#24335;&#23637;&#31034;&#20986;&#21453;&#24212;&#22270;&#12290;&#32593;&#26684;&#32454;&#32990;&#32676;&#20307;&#30340;&#21453;&#24212;&#22312;&#39640;&#32500;&#31070;&#32463;&#27963;&#21160;&#31354;&#38388;&#20013;&#24418;&#25104;&#19968;&#20010;&#21521;&#37327;&#65292;&#36825;&#20010;&#21521;&#37327;&#34920;&#31034;&#20195;&#29702;&#22312;2D&#29289;&#29702;&#31354;&#38388;&#20013;&#30340;&#33258;&#25105;&#20301;&#32622;&#12290;&#24403;&#20195;&#29702;&#31227;&#21160;&#26102;&#65292;&#36825;&#20010;&#21521;&#37327;&#34987;&#19968;&#20010;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#36716;&#25442;&#65292;&#35813;&#32593;&#32476;&#23558;&#20195;&#29702;&#30340;&#36895;&#24230;&#20316;&#20026;&#36755;&#20837;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#36755;&#20837;&#36895;&#24230;&#36827;&#34892;&#31616;&#21333;&#32780;&#36890;&#29992;&#30340;&#20849;&#24418;&#24402;&#19968;&#21270;&#65292;&#20351;&#24471;&#39640;&#32500;&#31070;&#32463;&#31354;&#38388;&#20013;&#20301;&#32622;&#21521;&#37327;&#30340;&#23616;&#37096;&#20301;&#31227;&#19982;2D&#29289;&#29702;&#31354;&#38388;&#20013;&#20195;&#29702;&#30340;&#23616;&#37096;&#20301;&#31227;&#25104;&#27604;&#20363;&#65292;&#26080;&#35770;&#36755;&#20837;&#36895;&#24230;&#30340;&#26041;&#21521;&#22914;&#20309;&#12290;&#25105;&#20204;&#22312;&#26368;&#31616;&#21333;&#30340;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#24490;&#29615;&#32593;&#32476;&#19978;&#36827;&#34892;&#20102;&#25968;&#20540;&#23454;&#39564;&#65292;&#32467;&#26524;&#26174;&#31034;&#20849;&#24418;&#24402;&#19968;&#21270;&#23548;&#33268;&#25968;&#37327;&#32423;&#36739;&#23567;&#30340;&#20301;&#32622;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Grid cells in the entorhinal cortex of the mammalian brain exhibit striking hexagon firing patterns in their response maps as the animal (e.g., a rat) navigates in a 2D open environment. The responses of the population of grid cells collectively form a vector in a high-dimensional neural activity space, and this vector represents the self-position of the agent in the 2D physical space. As the agent moves, the vector is transformed by a recurrent neural network that takes the velocity of the agent as input. In this paper, we propose a simple and general conformal normalization of the input velocity for the recurrent neural network, so that the local displacement of the position vector in the high-dimensional neural space is proportional to the local displacement of the agent in the 2D physical space, regardless of the direction of the input velocity. Our numerical experiments on the minimally simple linear and non-linear recurrent networks show that conformal normalization leads to the 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#26631;&#20934;&#21270;&#27969;&#36741;&#21161;&#37325;&#35201;&#25277;&#26679;&#65288;NOFIS&#65289;&#30340;&#26041;&#27861;&#65292;&#20934;&#30830;&#20272;&#35745;&#32597;&#35265;&#20107;&#20214;&#30340;&#27010;&#29575;&#65292;&#36890;&#36807;&#23398;&#20064;&#19968;&#31995;&#21015;&#25552;&#35758;&#20998;&#24067;&#21644;&#37325;&#35201;&#25277;&#26679;&#26469;&#23454;&#29616;&#65292;&#22312;&#22810;&#20010;&#23450;&#24615;&#21644;&#23450;&#37327;&#23454;&#39564;&#20013;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2310.19167</link><description>&lt;p&gt;
&#36890;&#36807;&#26631;&#20934;&#21270;&#27969;&#36827;&#34892;&#32597;&#35265;&#20107;&#20214;&#27010;&#29575;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Rare Event Probability Learning by Normalizing Flows. (arXiv:2310.19167v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19167
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26631;&#20934;&#21270;&#27969;&#36741;&#21161;&#37325;&#35201;&#25277;&#26679;&#65288;NOFIS&#65289;&#30340;&#26041;&#27861;&#65292;&#20934;&#30830;&#20272;&#35745;&#32597;&#35265;&#20107;&#20214;&#30340;&#27010;&#29575;&#65292;&#36890;&#36807;&#23398;&#20064;&#19968;&#31995;&#21015;&#25552;&#35758;&#20998;&#24067;&#21644;&#37325;&#35201;&#25277;&#26679;&#26469;&#23454;&#29616;&#65292;&#22312;&#22810;&#20010;&#23450;&#24615;&#21644;&#23450;&#37327;&#23454;&#39564;&#20013;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32597;&#35265;&#20107;&#20214;&#34987;&#23450;&#20041;&#20026;&#21457;&#29983;&#27010;&#29575;&#36739;&#20302;&#12290;&#20934;&#30830;&#20272;&#35745;&#36825;&#31181;&#23567;&#27010;&#29575;&#22312;&#21508;&#20010;&#39046;&#22495;&#20013;&#33267;&#20851;&#37325;&#35201;&#12290;&#20256;&#32479;&#30340;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#25928;&#29575;&#20302;&#19979;&#65292;&#38656;&#35201;&#22823;&#37327;&#26679;&#26412;&#25165;&#33021;&#24471;&#21040;&#21487;&#38752;&#30340;&#20272;&#35745;&#12290;&#21463;&#26631;&#20934;&#21270;&#27969;&#30340;&#31934;&#30830;&#37319;&#26679;&#33021;&#21147;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#37325;&#26032;&#24605;&#32771;&#20102;&#36825;&#20010;&#25361;&#25112;&#65292;&#24182;&#25552;&#20986;&#20102;&#26631;&#20934;&#21270;&#27969;&#36741;&#21161;&#37325;&#35201;&#25277;&#26679;&#65288;NOFIS&#65289;&#26041;&#27861;&#12290;NOFIS&#39318;&#20808;&#36890;&#36807;&#26368;&#23567;&#21270;KL&#25955;&#24230;&#25439;&#22833;&#26469;&#23398;&#20064;&#19982;&#39044;&#23450;&#20041;&#30340;&#23884;&#22871;&#23376;&#38598;&#20107;&#20214;&#30456;&#20851;&#30340;&#19968;&#31995;&#21015;&#25552;&#35758;&#20998;&#24067;&#12290;&#28982;&#21518;&#65292;&#23427;&#21033;&#29992;&#37325;&#35201;&#25277;&#26679;&#21644;&#26368;&#21518;&#19968;&#20010;&#25552;&#35758;&#20998;&#24067;&#26469;&#20272;&#35745;&#32597;&#35265;&#20107;&#20214;&#30340;&#27010;&#29575;&#12290;&#36890;&#36807;&#20840;&#38754;&#30340;&#23450;&#24615;&#21487;&#35270;&#21270;&#39564;&#35777;&#20102;&#25105;&#20204;NOFIS&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#35777;&#23454;&#20102;&#23398;&#20064;&#25552;&#35758;&#20998;&#24067;&#30340;&#26368;&#20248;&#24615;&#65292;&#20197;&#21450;&#19968;&#31995;&#21015;&#21253;&#25324;10&#20010;&#19981;&#21516;&#27979;&#35797;&#26696;&#20363;&#30340;&#23450;&#37327;&#23454;&#39564;&#35777;&#26126;&#20102;NOFIS&#22312;&#22522;&#20934;&#26041;&#27861;&#19978;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
A rare event is defined by a low probability of occurrence. Accurate estimation of such small probabilities is of utmost importance across diverse domains. Conventional Monte Carlo methods are inefficient, demanding an exorbitant number of samples to achieve reliable estimates. Inspired by the exact sampling capabilities of normalizing flows, we revisit this challenge and propose normalizing flow assisted importance sampling, termed NOFIS. NOFIS first learns a sequence of proposal distributions associated with predefined nested subset events by minimizing KL divergence losses. Next, it estimates the rare event probability by utilizing importance sampling in conjunction with the last proposal. The efficacy of our NOFIS method is substantiated through comprehensive qualitative visualizations, affirming the optimality of the learned proposal distribution, as well as a series of quantitative experiments encompassing $10$ distinct test cases, which highlight NOFIS's superiority over baselin
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#38024;&#23545;&#22312;&#32593;&#32476;&#20013;&#21516;&#26102;&#20256;&#25773;&#30340;&#20004;&#20010;&#25193;&#25955;&#36807;&#31243;&#30340;&#36807;&#21435;&#21644;&#26410;&#26469;&#28436;&#21464;&#20272;&#35745;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#21644;&#25910;&#25947;&#30340;&#28040;&#24687;&#20256;&#36882;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#21518;&#21521;&#25512;&#29702;&#21644;&#21069;&#21521;&#25512;&#29702;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.19138</link><description>&lt;p&gt;
&#30456;&#20114;&#20316;&#29992;&#29420;&#31435;&#32423;&#32852;&#36807;&#31243;&#20013;&#30340;&#21518;&#21521;&#21644;&#21069;&#21521;&#25512;&#29702;&#65306;&#19968;&#31181;&#21487;&#25193;&#23637;&#21644;&#25910;&#25947;&#30340;&#28040;&#24687;&#20256;&#36882;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Backward and Forward Inference in Interacting Independent-Cascade Processes: A Scalable and Convergent Message-Passing Approach. (arXiv:2310.19138v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19138
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#38024;&#23545;&#22312;&#32593;&#32476;&#20013;&#21516;&#26102;&#20256;&#25773;&#30340;&#20004;&#20010;&#25193;&#25955;&#36807;&#31243;&#30340;&#36807;&#21435;&#21644;&#26410;&#26469;&#28436;&#21464;&#20272;&#35745;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#21644;&#25910;&#25947;&#30340;&#28040;&#24687;&#20256;&#36882;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#21518;&#21521;&#25512;&#29702;&#21644;&#21069;&#21521;&#25512;&#29702;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32593;&#32476;&#19978;&#21516;&#26102;&#20256;&#25773;&#30340;&#20004;&#20010;&#25193;&#25955;&#36807;&#31243;&#30340;&#36807;&#21435;&#21644;&#26410;&#26469;&#28436;&#21464;&#20272;&#35745;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#32473;&#23450;&#19968;&#20010;&#24050;&#30693;&#30340;&#32593;&#32476;$ G =&#65288;V&#65292;\overrightarrow {E}&#65289;$&#21644;&#65288;&#21487;&#33021;&#26159;&#22024;&#26434;&#30340;&#65289;&#22312;&#65288;&#21487;&#33021;&#26410;&#30693;&#30340;&#65289;&#26102;&#38388;$ W $&#25293;&#25668;&#30340;&#20854;&#29366;&#24577;&#30340;&#24555;&#29031;$ \mathcal {O} _n $&#65292;&#25105;&#20204;&#24076;&#26395;&#30830;&#23450;&#32593;&#32476;&#30340;&#21021;&#22987;&#29366;&#24577;&#21644;&#20854;&#33410;&#28857;&#30340;&#24863;&#26579;&#26102;&#38388;&#30340;&#21518;&#39564;&#20998;&#24067;&#12290;&#36825;&#20123;&#20998;&#24067;&#22312;&#26597;&#25214;&#27969;&#34892;&#30149;&#21644;&#35875;&#35328;&#30340;&#28304;&#33410;&#28857;&#20197;&#21450;&#20272;&#35745;&#22266;&#23450;&#28304;&#33410;&#28857;&#30340;&#20256;&#25773;&#26041;&#38754;&#38750;&#24120;&#26377;&#29992;&#12290;&#20026;&#20102;&#24314;&#27169;&#20004;&#20010;&#36807;&#31243;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#29420;&#31435;&#32423;&#32852;&#65288;IC&#65289;&#27169;&#22411;&#30340;&#25193;&#23637;&#65292;&#20854;&#20013;&#24403;&#19968;&#20010;&#33410;&#28857;&#34987;&#20854;&#20013;&#19968;&#20010;&#36807;&#31243;&#24863;&#26579;&#26102;&#65292;&#20854;&#23545;&#21478;&#19968;&#20010;&#36807;&#31243;&#30340;&#26131;&#24863;&#24615;&#21457;&#29983;&#21464;&#21270;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23548;&#20986;&#20102;&#32593;&#32476;&#21021;&#22987;&#29366;&#24577;&#21644;&#35266;&#23519;&#24555;&#29031;$ \mathcal {O} _n $&#30340;&#20934;&#30830;&#32852;&#21512;&#27010;&#29575;&#12290;&#28982;&#21518;&#65292;&#36890;&#36807;fact&#30340;&#26426;&#21046;&#25237;&#20837;&#21040;...&#65288;&#25991;&#29486;&#27809;&#26377;&#32473;&#20986;&#21518;&#32493;&#37096;&#20998;&#65289;
&lt;/p&gt;
&lt;p&gt;
We study the problems of estimating the past and future evolutions of two diffusion processes that spread concurrently on a network. Specifically, given a known network $G=(V, \overrightarrow{E})$ and a (possibly noisy) snapshot $\mathcal{O}_n$ of its state taken at (a possibly unknown) time $W$, we wish to determine the posterior distributions of the initial state of the network and the infection times of its nodes. These distributions are useful in finding source nodes of epidemics and rumors -- $\textit{backward inference}$ -- , and estimating the spread of a fixed set of source nodes -- $\textit{forward inference}$.  To model the interaction between the two processes, we study an extension of the independent-cascade (IC) model where, when a node gets infected with either process, its susceptibility to the other one changes. First, we derive the exact joint probability of the initial state of the network and the observation-snapshot $\mathcal{O}_n$. Then, using the machinery of fact
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35268;&#33539;&#26368;&#20248;&#36817;&#20284;&#23398;&#20064;&#65288;GOAL&#65289;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#23567;&#26679;&#26412;&#23398;&#20064;&#38382;&#39064;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#20943;&#23569;&#21644;&#26059;&#36716;&#29305;&#24449;&#31354;&#38388;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#21487;&#20998;&#26512;&#30340;&#32852;&#21512;&#35299;&#20915;&#26041;&#26696;&#65292;&#20854;&#20013;&#26368;&#20248;&#35299;&#26159;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#30340;&#20998;&#27573;&#32447;&#24615;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2310.19066</link><description>&lt;p&gt;
&#23567;&#26679;&#26412;&#20998;&#31867;&#38382;&#39064;&#30340;&#35268;&#33539;&#26368;&#20248;&#36817;&#20284;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Gauge-optimal approximate learning for small data classification problems. (arXiv:2310.19066v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19066
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35268;&#33539;&#26368;&#20248;&#36817;&#20284;&#23398;&#20064;&#65288;GOAL&#65289;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#23567;&#26679;&#26412;&#23398;&#20064;&#38382;&#39064;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#20943;&#23569;&#21644;&#26059;&#36716;&#29305;&#24449;&#31354;&#38388;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#21487;&#20998;&#26512;&#30340;&#32852;&#21512;&#35299;&#20915;&#26041;&#26696;&#65292;&#20854;&#20013;&#26368;&#20248;&#35299;&#26159;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#30340;&#20998;&#27573;&#32447;&#24615;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23567;&#26679;&#26412;&#23398;&#20064;&#38382;&#39064;&#30340;&#29305;&#28857;&#26159;&#26377;&#38480;&#30340;&#21709;&#24212;&#21464;&#37327;&#35266;&#27979;&#21644;&#24222;&#22823;&#30340;&#29305;&#24449;&#31354;&#38388;&#32500;&#24230;&#20043;&#38388;&#23384;&#22312;&#26174;&#33879;&#30340;&#24046;&#24322;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#24120;&#35265;&#30340;&#23398;&#20064;&#24037;&#20855;&#38590;&#20197;&#30830;&#23450;&#23545;&#20998;&#31867;&#20219;&#21153;&#37325;&#35201;&#30340;&#29305;&#24449;&#21644;&#19981;&#30456;&#20851;&#20449;&#24687;&#30340;&#29305;&#24449;&#65292;&#24182;&#19988;&#26080;&#27861;&#25512;&#23548;&#20986;&#36866;&#24403;&#30340;&#23398;&#20064;&#35268;&#21017;&#26469;&#21306;&#20998;&#19981;&#21516;&#30340;&#31867;&#21035;&#12290;&#20316;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#28508;&#22312;&#26041;&#27861;&#65292;&#25105;&#20204;&#21033;&#29992;&#20943;&#23569;&#21644;&#26059;&#36716;&#29305;&#24449;&#31354;&#38388;&#30340;&#24605;&#24819;&#65292;&#22312;&#19968;&#20010;&#20302;&#32500;&#24230;&#35268;&#33539;&#20013;&#25552;&#20986;&#20102;&#35268;&#33539;&#26368;&#20248;&#36817;&#20284;&#23398;&#20064;&#65288;GOAL&#65289;&#31639;&#27861;&#65292;&#20026;&#23567;&#26679;&#26412;&#23398;&#20064;&#38382;&#39064;&#30340;&#32500;&#24230;&#32553;&#20943;&#12289;&#29305;&#24449;&#20998;&#21106;&#21644;&#20998;&#31867;&#38382;&#39064;&#25552;&#20379;&#20102;&#19968;&#20010;&#21487;&#20998;&#26512;&#30340;&#32852;&#21512;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;GOAL&#31639;&#27861;&#30340;&#26368;&#20248;&#35299;&#26159;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#30340;&#20998;&#27573;&#32447;&#24615;&#20989;&#25968;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#21333;&#35843;&#25910;&#25947;&#36924;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;
Small data learning problems are characterized by a significant discrepancy between the limited amount of response variable observations and the large feature space dimension. In this setting, the common learning tools struggle to identify the features important for the classification task from those that bear no relevant information, and cannot derive an appropriate learning rule which allows to discriminate between different classes. As a potential solution to this problem, here we exploit the idea of reducing and rotating the feature space in a lower-dimensional gauge and propose the Gauge-Optimal Approximate Learning (GOAL) algorithm, which provides an analytically tractable joint solution to the dimension reduction, feature segmentation and classification problems for small data learning problems. We prove that the optimal solution of the GOAL algorithm consists in piecewise-linear functions in the Euclidean space, and that it can be approximated through a monotonically convergent
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;&#33529;&#26524;&#21697;&#23581;&#30340;&#21487;&#23398;&#20064;&#24615;&#65292;&#20174;&#32452;&#21512;&#35282;&#24230;&#30740;&#31350;&#20102;&#22312;&#32447;&#21487;&#23398;&#20064;&#24615;&#12290;&#20316;&#32773;&#36890;&#36807;&#24341;&#20837;Effective width&#21442;&#25968;&#65292;&#32039;&#23494;&#37327;&#21270;&#20102;&#22312;&#21487;&#23454;&#29616;&#35774;&#32622;&#20013;&#30340;&#26497;&#23567;&#26399;&#26395;&#38169;&#35823;&#65292;&#24182;&#22312;&#21487;&#23454;&#29616;&#35774;&#32622;&#20013;&#24314;&#31435;&#20102;&#26497;&#23567;&#26399;&#26395;&#38169;&#35823;&#25968;&#37327;&#30340;&#19977;&#20998;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.19064</link><description>&lt;p&gt;
&#37325;&#26032;&#23457;&#35270;&#33529;&#26524;&#21697;&#23581;&#30340;&#21487;&#23398;&#20064;&#24615;
&lt;/p&gt;
&lt;p&gt;
Revisiting the Learnability of Apple Tasting. (arXiv:2310.19064v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19064
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;&#33529;&#26524;&#21697;&#23581;&#30340;&#21487;&#23398;&#20064;&#24615;&#65292;&#20174;&#32452;&#21512;&#35282;&#24230;&#30740;&#31350;&#20102;&#22312;&#32447;&#21487;&#23398;&#20064;&#24615;&#12290;&#20316;&#32773;&#36890;&#36807;&#24341;&#20837;Effective width&#21442;&#25968;&#65292;&#32039;&#23494;&#37327;&#21270;&#20102;&#22312;&#21487;&#23454;&#29616;&#35774;&#32622;&#20013;&#30340;&#26497;&#23567;&#26399;&#26395;&#38169;&#35823;&#65292;&#24182;&#22312;&#21487;&#23454;&#29616;&#35774;&#32622;&#20013;&#24314;&#31435;&#20102;&#26497;&#23567;&#26399;&#26395;&#38169;&#35823;&#25968;&#37327;&#30340;&#19977;&#20998;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22312;&#32447;&#20108;&#20803;&#20998;&#31867;&#20013;&#65292;&#23398;&#20064;&#32773;&#21482;&#26377;&#22312;&#39044;&#27979;&#20026;"1"&#26102;&#35266;&#23519;&#21040;&#30495;&#23454;&#26631;&#31614;&#12290;&#26412;&#25991;&#37325;&#26032;&#30740;&#31350;&#20102;&#36825;&#31181;&#32463;&#20856;&#30340;&#37096;&#20998;&#21453;&#39304;&#35774;&#32622;&#65292;&#24182;&#20174;&#32452;&#21512;&#35282;&#24230;&#30740;&#31350;&#20102;&#22312;&#32447;&#21487;&#23398;&#20064;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#19981;&#21487;&#30693;&#35774;&#32622;&#19979;&#65292;Littlestone&#32500;&#24230;&#20173;&#28982;&#26159;&#33529;&#26524;&#21697;&#23581;&#30340;&#32039;&#23494;&#23450;&#37327;&#21051;&#30011;&#65292;&#35299;&#20915;&#20102;\cite{helmbold2000apple}&#25552;&#20986;&#30340;&#19968;&#20010;&#24748;&#32780;&#26410;&#20915;&#30340;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#32452;&#21512;&#21442;&#25968;&#65292;&#31216;&#20026;&#26377;&#25928;&#23485;&#24230;&#65292;&#32039;&#23494;&#37327;&#21270;&#20102;&#22312;&#21487;&#23454;&#29616;&#35774;&#32622;&#20013;&#30340;&#26497;&#23567;&#26399;&#26395;&#38169;&#35823;&#12290;&#20316;&#20026;&#25512;&#35770;&#65292;&#25105;&#20204;&#20351;&#29992;&#26377;&#25928;&#23485;&#24230;&#22312;&#21487;&#23454;&#29616;&#35774;&#32622;&#20013;&#24314;&#31435;&#20102;&#26497;&#23567;&#26399;&#26395;&#38169;&#35823;&#25968;&#37327;&#30340;&#19977;&#20998;&#27861;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#21487;&#23454;&#29616;&#35774;&#32622;&#20013;&#65292;&#20219;&#20309;&#23398;&#20064;&#32773;&#22312;&#33529;&#26524;&#21697;&#23581;&#21453;&#39304;&#19979;&#30340;&#26399;&#26395;&#38169;&#35823;&#25968;&#37327;&#21482;&#33021;&#26159;$\Theta(1), \Theta(\sqrt{T})$, &#25110; $\Theta(T)$&#12290;
&lt;/p&gt;
&lt;p&gt;
In online binary classification under \textit{apple tasting} feedback, the learner only observes the true label if it predicts "1". First studied by \cite{helmbold2000apple}, we revisit this classical partial-feedback setting and study online learnability from a combinatorial perspective. We show that the Littlestone dimension continues to prove a tight quantitative characterization of apple tasting in the agnostic setting, closing an open question posed by \cite{helmbold2000apple}. In addition, we give a new combinatorial parameter, called the Effective width, that tightly quantifies the minimax expected mistakes in the realizable setting. As a corollary, we use the Effective width to establish a \textit{trichotomy} of the minimax expected number of mistakes in the realizable setting. In particular, we show that in the realizable setting, the expected number of mistakes for any learner under apple tasting feedback can only be $\Theta(1), \Theta(\sqrt{T})$, or $\Theta(T)$.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#35780;&#20272;&#32435;&#31859;&#20809;&#23376;&#32467;&#26500;&#30340;&#26694;&#26550;&#21644;&#22522;&#20934;&#65292;&#29992;&#20110;&#35299;&#20915;&#21442;&#25968;&#32467;&#26500;&#35774;&#35745;&#38382;&#39064;&#65292;&#24182;&#25506;&#31350;&#20102;&#30005;&#21160;&#21147;&#23398;&#27169;&#25311;&#20013;&#32593;&#26684;&#22823;&#23567;&#30340;&#21464;&#21270;&#23545;&#32467;&#26524;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2310.19053</link><description>&lt;p&gt;
&#32435;&#31859;&#20809;&#23376;&#32467;&#26500;&#21644;&#21442;&#25968;&#35774;&#35745;&#27169;&#25311;&#30340;&#25968;&#25454;&#38598;&#21644;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
Datasets and Benchmarks for Nanophotonic Structure and Parametric Design Simulations. (arXiv:2310.19053v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19053
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#35780;&#20272;&#32435;&#31859;&#20809;&#23376;&#32467;&#26500;&#30340;&#26694;&#26550;&#21644;&#22522;&#20934;&#65292;&#29992;&#20110;&#35299;&#20915;&#21442;&#25968;&#32467;&#26500;&#35774;&#35745;&#38382;&#39064;&#65292;&#24182;&#25506;&#31350;&#20102;&#30005;&#21160;&#21147;&#23398;&#27169;&#25311;&#20013;&#32593;&#26684;&#22823;&#23567;&#30340;&#21464;&#21270;&#23545;&#32467;&#26524;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32435;&#31859;&#20809;&#23376;&#32467;&#26500;&#20855;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#65292;&#21253;&#25324;&#22826;&#38451;&#33021;&#30005;&#27744;&#12289;&#38450;&#21453;&#23556;&#28034;&#23618;&#12289;&#30005;&#30913;&#24178;&#25200;&#23631;&#34109;&#12289;&#20809;&#23398;&#28388;&#27874;&#22120;&#21644;&#21457;&#20809;&#20108;&#26497;&#31649;&#12290;&#20026;&#20102;&#35774;&#35745;&#21644;&#29702;&#35299;&#36825;&#20123;&#32435;&#31859;&#20809;&#23376;&#32467;&#26500;&#65292;&#30005;&#21160;&#21147;&#23398;&#27169;&#25311;&#26159;&#24517;&#19981;&#21487;&#23569;&#30340;&#12290;&#36825;&#20123;&#27169;&#25311;&#20351;&#25105;&#20204;&#33021;&#22815;&#27169;&#25311;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#30005;&#30913;&#22330;&#24182;&#35745;&#31639;&#20809;&#23398;&#24615;&#36136;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#29992;&#20110;&#35780;&#20272;&#32435;&#31859;&#20809;&#23376;&#32467;&#26500;&#30340;&#26694;&#26550;&#21644;&#22522;&#20934;&#65292;&#20197;&#35299;&#20915;&#21442;&#25968;&#32467;&#26500;&#35774;&#35745;&#38382;&#39064;&#12290;&#36825;&#20123;&#22522;&#20934;&#22312;&#35780;&#20272;&#20248;&#21270;&#31639;&#27861;&#24615;&#33021;&#21644;&#22522;&#20110;&#30446;&#26631;&#20809;&#23398;&#24615;&#36136;&#30830;&#23450;&#26368;&#20339;&#32467;&#26500;&#26041;&#38754;&#36215;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25506;&#35752;&#20102;&#30005;&#21160;&#21147;&#23398;&#27169;&#25311;&#20013;&#32593;&#26684;&#22823;&#23567;&#30340;&#21464;&#21270;&#23545;&#32467;&#26524;&#30340;&#24433;&#21709;&#65292;&#25581;&#31034;&#20102;&#22914;&#20309;&#22312;&#22686;&#24378;&#32467;&#26500;&#35774;&#35745;&#26041;&#38754;&#24039;&#22937;&#22320;&#21033;&#29992;&#35780;&#20272;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Nanophotonic structures have versatile applications including solar cells, anti-reflective coatings, electromagnetic interference shielding, optical filters, and light emitting diodes. To design and understand these nanophotonic structures, electrodynamic simulations are essential. These simulations enable us to model electromagnetic fields over time and calculate optical properties. In this work, we introduce frameworks and benchmarks to evaluate nanophotonic structures in the context of parametric structure design problems. The benchmarks are instrumental in assessing the performance of optimization algorithms and identifying an optimal structure based on target optical properties. Moreover, we explore the impact of varying grid sizes in electrodynamic simulations, shedding light on how evaluation fidelity can be strategically leveraged in enhancing structure designs.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#24046;&#20998;&#38544;&#31169;&#25490;&#21015;&#26816;&#39564;&#30340;&#26694;&#26550;&#65292;&#25193;&#23637;&#20102;&#32463;&#20856;&#30340;&#38750;&#31169;&#26377;&#25490;&#21015;&#26816;&#39564;&#65292;&#20197;&#22312;&#31169;&#26377;&#29615;&#22659;&#20013;&#20445;&#25345;&#26377;&#38480;&#26679;&#26412;&#26377;&#25928;&#24615;&#21644;&#24046;&#20998;&#38544;&#31169;&#24615;&#36136;&#12290;&#35813;&#26816;&#39564;&#30340;&#21151;&#29575;&#21462;&#20915;&#20110;&#26816;&#39564;&#32479;&#35745;&#37327;&#30340;&#36873;&#25321;&#65292;&#24182;&#24314;&#31435;&#20102;&#19968;&#33324;&#26465;&#20214;&#26469;&#20445;&#35777;&#19968;&#33268;&#24615;&#21644;&#38750;&#28176;&#36827;&#22343;&#21248;&#30340;&#21151;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.19043</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#25490;&#21015;&#26816;&#39564;&#65306;&#24212;&#29992;&#20110;&#26680;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Permutation Tests: Applications to Kernel Methods. (arXiv:2310.19043v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19043
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#24046;&#20998;&#38544;&#31169;&#25490;&#21015;&#26816;&#39564;&#30340;&#26694;&#26550;&#65292;&#25193;&#23637;&#20102;&#32463;&#20856;&#30340;&#38750;&#31169;&#26377;&#25490;&#21015;&#26816;&#39564;&#65292;&#20197;&#22312;&#31169;&#26377;&#29615;&#22659;&#20013;&#20445;&#25345;&#26377;&#38480;&#26679;&#26412;&#26377;&#25928;&#24615;&#21644;&#24046;&#20998;&#38544;&#31169;&#24615;&#36136;&#12290;&#35813;&#26816;&#39564;&#30340;&#21151;&#29575;&#21462;&#20915;&#20110;&#26816;&#39564;&#32479;&#35745;&#37327;&#30340;&#36873;&#25321;&#65292;&#24182;&#24314;&#31435;&#20102;&#19968;&#33324;&#26465;&#20214;&#26469;&#20445;&#35777;&#19968;&#33268;&#24615;&#21644;&#38750;&#28176;&#36827;&#22343;&#21248;&#30340;&#21151;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#20154;&#20204;&#23545;&#25935;&#24863;&#25968;&#25454;&#30340;&#38544;&#31169;&#38382;&#39064;&#36234;&#26469;&#36234;&#20851;&#27880;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#20123;&#38382;&#39064;&#65292;&#24046;&#20998;&#38544;&#31169;&#20316;&#20026;&#19968;&#31181;&#20005;&#26684;&#30340;&#38544;&#31169;&#20445;&#25252;&#26694;&#26550;&#24212;&#36816;&#32780;&#29983;&#65292;&#22312;&#23398;&#26415;&#30028;&#21644;&#24037;&#19994;&#30028;&#24191;&#27867;&#35748;&#21487;&#12290;&#23613;&#31649;&#22312;&#31169;&#26377;&#25968;&#25454;&#20998;&#26512;&#26041;&#38754;&#21462;&#24471;&#20102;&#30456;&#24403;&#22823;&#30340;&#36827;&#23637;&#65292;&#20294;&#29616;&#26377;&#30340;&#26041;&#27861;&#24448;&#24448;&#23384;&#22312;&#19981;&#23454;&#29992;&#25110;&#26126;&#26174;&#30340;&#32479;&#35745;&#25928;&#29575;&#25439;&#22833;&#12290;&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#24341;&#20837;&#24046;&#20998;&#38544;&#31169;&#25490;&#21015;&#26816;&#39564;&#26469;&#32531;&#35299;&#36825;&#20123;&#25285;&#24551;&#12290;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#23558;&#32463;&#20856;&#30340;&#38750;&#31169;&#26377;&#25490;&#21015;&#26816;&#39564;&#25193;&#23637;&#21040;&#31169;&#26377;&#29615;&#22659;&#20013;&#65292;&#20197;&#20005;&#26684;&#30340;&#26041;&#24335;&#20445;&#25345;&#26377;&#38480;&#26679;&#26412;&#26377;&#25928;&#24615;&#21644;&#24046;&#20998;&#38544;&#31169;&#24615;&#36136;&#12290;&#25152;&#25552;&#20986;&#30340;&#26816;&#39564;&#30340;&#21151;&#29575;&#21462;&#20915;&#20110;&#19968;&#20010;&#26816;&#39564;&#32479;&#35745;&#37327;&#30340;&#36873;&#25321;&#65292;&#24182;&#24314;&#31435;&#20102;&#19968;&#33324;&#26465;&#20214;&#20445;&#35777;&#20102;&#19968;&#33268;&#24615;&#21644;&#38750;&#28176;&#36827;&#22343;&#21248;&#30340;&#21151;&#29575;&#12290;&#20026;&#20102;&#35777;&#26126;&#25105;&#20204;&#26694;&#26550;&#30340;&#23454;&#29992;&#24615;&#21644;&#21487;&#34892;&#24615;&#65292;&#25105;&#20204;&#37325;&#28857;&#20851;&#27880;&#37325;&#29616;&#26680;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent years have witnessed growing concerns about the privacy of sensitive data. In response to these concerns, differential privacy has emerged as a rigorous framework for privacy protection, gaining widespread recognition in both academic and industrial circles. While substantial progress has been made in private data analysis, existing methods often suffer from impracticality or a significant loss of statistical efficiency. This paper aims to alleviate these concerns in the context of hypothesis testing by introducing differentially private permutation tests. The proposed framework extends classical non-private permutation tests to private settings, maintaining both finite-sample validity and differential privacy in a rigorous manner. The power of the proposed test depends on the choice of a test statistic, and we establish general conditions for consistency and non-asymptotic uniform power. To demonstrate the utility and practicality of our framework, we focus on reproducing kerne
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#25506;&#31350;&#22312;&#22810;&#27969;&#24418;&#27169;&#22411;&#19979;&#65292;&#23398;&#20064;&#30340;&#34920;&#31034;&#20309;&#26102;&#21487;&#20197;&#32447;&#24615;&#20998;&#31163;&#27969;&#24418;&#65292;&#25581;&#31034;&#20102;&#33258;&#30417;&#30563;&#23398;&#20064;&#22312;&#25968;&#25454;&#22686;&#24378;&#26041;&#38754;&#30340;&#39069;&#22806;&#22909;&#22788;&#65292;&#20174;&#32780;&#25913;&#21892;&#20102;&#32447;&#24615;&#20998;&#31163;&#33021;&#21147;&#30340;&#20449;&#24687;&#35770;&#26368;&#20248;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.19041</link><description>&lt;p&gt;
&#33258;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#30340;&#32447;&#24615;&#20998;&#31163;&#33021;&#21147;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Linear Separation Capacity of Self-Supervised Representation Learning. (arXiv:2310.19041v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19041
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#25506;&#31350;&#22312;&#22810;&#27969;&#24418;&#27169;&#22411;&#19979;&#65292;&#23398;&#20064;&#30340;&#34920;&#31034;&#20309;&#26102;&#21487;&#20197;&#32447;&#24615;&#20998;&#31163;&#27969;&#24418;&#65292;&#25581;&#31034;&#20102;&#33258;&#30417;&#30563;&#23398;&#20064;&#22312;&#25968;&#25454;&#22686;&#24378;&#26041;&#38754;&#30340;&#39069;&#22806;&#22909;&#22788;&#65292;&#20174;&#32780;&#25913;&#21892;&#20102;&#32447;&#24615;&#20998;&#31163;&#33021;&#21147;&#30340;&#20449;&#24687;&#35770;&#26368;&#20248;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#30417;&#30563;&#23398;&#20064;&#30340;&#26368;&#26032;&#36827;&#23637;&#24378;&#35843;&#20102;&#25968;&#25454;&#22686;&#24378;&#22312;&#20174;&#26080;&#26631;&#31614;&#25968;&#25454;&#20013;&#23398;&#20064;&#25968;&#25454;&#34920;&#31034;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;&#22312;&#36825;&#20123;&#22686;&#24378;&#34920;&#31034;&#20043;&#19978;&#35757;&#32451;&#32447;&#24615;&#27169;&#22411;&#21487;&#20197;&#24471;&#21040;&#19968;&#20010;&#29087;&#32451;&#30340;&#20998;&#31867;&#22120;&#12290;&#23613;&#31649;&#22312;&#23454;&#36341;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#26159;&#25968;&#25454;&#22686;&#24378;&#22914;&#20309;&#23558;&#38750;&#32447;&#24615;&#25968;&#25454;&#32467;&#26500;&#35299;&#24320;&#20026;&#32447;&#24615;&#21487;&#20998;&#31163;&#34920;&#31034;&#30340;&#26426;&#21046;&#20173;&#28982;&#19981;&#28165;&#26970;&#12290;&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#30740;&#31350;&#22312;&#20174;&#22810;&#27969;&#24418;&#27169;&#22411;&#20013;&#32472;&#21046;&#25968;&#25454;&#26102;&#65292;&#23398;&#20064;&#21040;&#30340;&#34920;&#31034;&#22312;&#20309;&#31181;&#26465;&#20214;&#19979;&#21487;&#20197;&#32447;&#24615;&#20998;&#31163;&#27969;&#24418;&#26469;&#22635;&#34917;&#36825;&#19968;&#24046;&#36317;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#25581;&#31034;&#20102;&#25968;&#25454;&#22686;&#24378;&#38500;&#20102;&#25552;&#20379;&#35266;&#23519;&#25968;&#25454;&#22806;&#65292;&#36824;&#25552;&#20379;&#20102;&#39069;&#22806;&#30340;&#20449;&#24687;&#65292;&#20174;&#32780;&#21487;&#20197;&#25913;&#21892;&#32447;&#24615;&#20998;&#31163;&#23481;&#37327;&#30340;&#20449;&#24687;&#35770;&#26368;&#20248;&#36895;&#29575;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#35777;&#26126;&#33258;&#30417;&#30563;&#23398;&#20064;&#21487;&#20197;&#20197;&#27604;&#26080;&#30417;&#30563;&#23398;&#20064;&#26356;&#23567;&#30340;&#36317;&#31163;&#32447;&#24615;&#20998;&#31163;&#27969;&#24418;&#65292;&#31361;&#26174;&#20102;&#25968;&#25454;&#22686;&#24378;&#30340;&#39069;&#22806;&#22909;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advances in self-supervised learning have highlighted the efficacy of data augmentation in learning data representation from unlabeled data. Training a linear model atop these enhanced representations can yield an adept classifier. Despite the remarkable empirical performance, the underlying mechanisms that enable data augmentation to unravel nonlinear data structures into linearly separable representations remain elusive. This paper seeks to bridge this gap by investigating under what conditions learned representations can linearly separate manifolds when data is drawn from a multi-manifold model. Our investigation reveals that data augmentation offers additional information beyond observed data and can thus improve the information-theoretic optimal rate of linear separation capacity. In particular, we show that self-supervised learning can linearly separate manifolds with a smaller distance than unsupervised learning, underscoring the additional benefits of data augmentation. 
&lt;/p&gt;</description></item><item><title>&#29615;&#22659;&#22686;&#24378;&#26080;&#27861;&#26681;&#26412;&#24615;&#22320;&#23398;&#20064;&#21040;&#19981;&#21464;&#30340;&#22270;&#34920;&#31034;&#65292;&#22240;&#27492;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#32452;&#26368;&#23567;&#30340;&#20551;&#35774;&#65292;&#29992;&#20110;&#21487;&#34892;&#30340;&#19981;&#21464;&#22270;&#23398;&#20064;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;GALA&#65292;&#35813;&#26694;&#26550;&#21253;&#21547;&#19968;&#20010;&#25935;&#24863;&#20110;&#22270;&#29615;&#22659;&#21464;&#21270;&#30340;&#21161;&#29702;&#27169;&#22411;&#65292;&#36890;&#36807;&#20195;&#29702;&#39044;&#27979;&#20934;&#30830;&#24615;&#26469;&#21306;&#20998;&#21464;&#24322;&#12290;</title><link>http://arxiv.org/abs/2310.19035</link><description>&lt;p&gt;
&#20351;&#29992;&#29615;&#22659;&#22686;&#24378;&#30340;&#19981;&#21464;&#22270;&#23398;&#20064;&#33021;&#22815;&#23398;&#20064;&#21040;&#19981;&#21464;&#24615;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Does Invariant Graph Learning via Environment Augmentation Learn Invariance?. (arXiv:2310.19035v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19035
&lt;/p&gt;
&lt;p&gt;
&#29615;&#22659;&#22686;&#24378;&#26080;&#27861;&#26681;&#26412;&#24615;&#22320;&#23398;&#20064;&#21040;&#19981;&#21464;&#30340;&#22270;&#34920;&#31034;&#65292;&#22240;&#27492;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#32452;&#26368;&#23567;&#30340;&#20551;&#35774;&#65292;&#29992;&#20110;&#21487;&#34892;&#30340;&#19981;&#21464;&#22270;&#23398;&#20064;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;GALA&#65292;&#35813;&#26694;&#26550;&#21253;&#21547;&#19968;&#20010;&#25935;&#24863;&#20110;&#22270;&#29615;&#22659;&#21464;&#21270;&#30340;&#21161;&#29702;&#27169;&#22411;&#65292;&#36890;&#36807;&#20195;&#29702;&#39044;&#27979;&#20934;&#30830;&#24615;&#26469;&#21306;&#20998;&#21464;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#21464;&#22270;&#34920;&#31034;&#23398;&#20064;&#26088;&#22312;&#23398;&#20064;&#19981;&#21516;&#29615;&#22659;&#19979;&#25968;&#25454;&#30340;&#19981;&#21464;&#24615;&#65292;&#20197;&#23454;&#29616;&#23545;&#22270;&#30340;&#36229;&#20986;&#20998;&#24067;&#30340;&#27867;&#21270;&#12290;&#30001;&#20110;&#22270;&#29615;&#22659;&#21010;&#20998;&#36890;&#24120;&#24456;&#26114;&#36149;&#65292;&#22686;&#24378;&#29615;&#22659;&#20449;&#24687;&#24050;&#25104;&#20026;&#20107;&#23454;&#19978;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#22686;&#24378;&#30340;&#29615;&#22659;&#20449;&#24687;&#30340;&#26377;&#25928;&#24615;&#36824;&#27809;&#26377;&#34987;&#39564;&#35777;&#36807;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;&#27809;&#26377;&#39069;&#22806;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#29615;&#22659;&#22686;&#24378;&#26080;&#27861;&#26681;&#26412;&#24615;&#22320;&#23398;&#20064;&#21040;&#19981;&#21464;&#30340;&#22270;&#34920;&#31034;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#32452;&#26368;&#23567;&#30340;&#20551;&#35774;&#65292;&#21253;&#25324;&#21464;&#21270;&#20805;&#20998;&#24615;&#21644;&#21464;&#21270;&#19968;&#33268;&#24615;&#65292;&#29992;&#20110;&#21487;&#34892;&#30340;&#19981;&#21464;&#22270;&#23398;&#20064;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550; Graph invAriant LearningAssistant (GALA)&#12290;GALA&#21253;&#21547;&#19968;&#20010;&#21161;&#29702;&#27169;&#22411;&#65292;&#38656;&#35201;&#23545;&#22270;&#29615;&#22659;&#30340;&#21464;&#21270;&#25110;&#20998;&#24067;&#30340;&#21464;&#21270;&#25935;&#24863;&#12290;&#22240;&#27492;&#65292;&#21161;&#29702;&#27169;&#22411;&#30340;&#20195;&#29702;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#21487;&#20197;&#21306;&#20998;&#21464;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Invariant graph representation learning aims to learn the invariance among data from different environments for out-of-distribution generalization on graphs. As the graph environment partitions are usually expensive to obtain, augmenting the environment information has become the de facto approach. However, the usefulness of the augmented environment information has never been verified. In this work, we find that it is fundamentally impossible to learn invariant graph representations via environment augmentation without additional assumptions. Therefore, we develop a set of minimal assumptions, including variation sufficiency and variation consistency, for feasible invariant graph learning. We then propose a new framework Graph invAriant Learning Assistant (GALA). GALA incorporates an assistant model that needs to be sensitive to graph environment changes or distribution shifts. The correctness of the proxy predictions by the assistant model hence can differentiate the variations in sp
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#23545;&#25239;&#24615;&#19978;&#19979;&#25991;&#36172;&#21338;&#38382;&#39064;&#30340;&#38754;&#21521;Oracle&#39640;&#25928;&#30340;&#25918;&#26494;&#26041;&#27861;&#65292;&#36890;&#36807;&#35843;&#29992;&#31163;&#32447;&#20248;&#21270;Oracle&#26469;&#38477;&#20302;&#36951;&#25022;&#30028;&#38480;&#65292;&#24182;&#19988;&#22312;&#30028;&#38480;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25913;&#36827;&#65292;&#36798;&#21040;&#20102;&#20808;&#21069;&#26368;&#20339;&#30028;&#38480;&#65292;&#24182;&#19982;&#21407;&#22987;&#30028;&#38480;&#30456;&#21305;&#37197;&#12290;</title><link>http://arxiv.org/abs/2310.19025</link><description>&lt;p&gt;
&#12298;&#19968;&#31181;&#25913;&#36827;&#30340;&#38754;&#21521;Oracle&#39640;&#25928;&#30340;&#23545;&#25239;&#24615;&#19978;&#19979;&#25991;&#36172;&#21338;&#38382;&#39064;&#30340;&#25918;&#26494;&#26041;&#27861;&#12299;
&lt;/p&gt;
&lt;p&gt;
An Improved Relaxation for Oracle-Efficient Adversarial Contextual Bandits. (arXiv:2310.19025v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19025
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#23545;&#25239;&#24615;&#19978;&#19979;&#25991;&#36172;&#21338;&#38382;&#39064;&#30340;&#38754;&#21521;Oracle&#39640;&#25928;&#30340;&#25918;&#26494;&#26041;&#27861;&#65292;&#36890;&#36807;&#35843;&#29992;&#31163;&#32447;&#20248;&#21270;Oracle&#26469;&#38477;&#20302;&#36951;&#25022;&#30028;&#38480;&#65292;&#24182;&#19988;&#22312;&#30028;&#38480;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25913;&#36827;&#65292;&#36798;&#21040;&#20102;&#20808;&#21069;&#26368;&#20339;&#30028;&#38480;&#65292;&#24182;&#19982;&#21407;&#22987;&#30028;&#38480;&#30456;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;Oracle&#39640;&#25928;&#30340;&#25918;&#26494;&#26041;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#23545;&#25239;&#24615;&#19978;&#19979;&#25991;&#36172;&#21338;&#38382;&#39064;&#65292;&#20854;&#20013;&#19978;&#19979;&#25991;&#26159;&#20174;&#24050;&#30693;&#20998;&#24067;&#20013;&#39034;&#24207;&#29420;&#31435;&#25277;&#21462;&#30340;&#65292;&#32780;&#25104;&#26412;&#24207;&#21015;&#21017;&#30001;&#22312;&#32447;&#23545;&#25163;&#36873;&#25321;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20855;&#26377;&#19968;&#20010;$O(T^{\frac{2}{3}}(K\log(|\Pi|))^{\frac{1}{3}})$&#30340;&#36951;&#25022;&#30028;&#38480;&#65292;&#24182;&#19988;&#27599;&#36718;&#26368;&#22810;&#35843;&#29992;$O(K)$&#27425;&#31163;&#32447;&#20248;&#21270;Oracle&#65292;&#20854;&#20013;$K$&#34920;&#31034;&#21160;&#20316;&#30340;&#25968;&#37327;&#65292;$T$&#34920;&#31034;&#36718;&#25968;&#65292;$\Pi$&#34920;&#31034;&#31574;&#30053;&#38598;&#12290;&#36825;&#26159;&#31532;&#19968;&#20010;&#25913;&#36827;Syrgkanis&#31561;&#20154;&#22312;NeurIPS 2016&#20013;&#33719;&#24471;&#30340;$O((TK)^{\frac{2}{3}}(\log(|\Pi|))^{\frac{1}{3}})$&#30028;&#38480;&#30340;&#32467;&#26524;&#65292;&#24182;&#19988;&#20063;&#26159;&#19982;Langford&#21644;Zhang&#22312;NeurIPS 2007&#20013;&#20026;&#38543;&#26426;&#24773;&#20917;&#25552;&#20986;&#30340;&#21407;&#22987;&#30028;&#38480;&#30456;&#21305;&#37197;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present an oracle-efficient relaxation for the adversarial contextual bandits problem, where the contexts are sequentially drawn i.i.d from a known distribution and the cost sequence is chosen by an online adversary. Our algorithm has a regret bound of $O(T^{\frac{2}{3}}(K\log(|\Pi|))^{\frac{1}{3}})$ and makes at most $O(K)$ calls per round to an offline optimization oracle, where $K$ denotes the number of actions, $T$ denotes the number of rounds and $\Pi$ denotes the set of policies. This is the first result to improve the prior best bound of $O((TK)^{\frac{2}{3}}(\log(|\Pi|))^{\frac{1}{3}})$ as obtained by Syrgkanis et al. at NeurIPS 2016, and the first to match the original bound of Langford and Zhang at NeurIPS 2007 which was obtained for the stochastic case.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#37325;&#26032;&#24605;&#32771;&#20102;&#32479;&#35745;&#23398;&#20064;&#20013;&#21442;&#25968;&#35745;&#25968;&#30340;&#29702;&#35770;&#65292;&#25361;&#25112;&#20102;&#21452;&#19979;&#38477;&#29616;&#35937;&#25193;&#23637;&#20256;&#32479;&#22797;&#26434;&#24230;-&#27867;&#31867;&#20851;&#31995;&#30028;&#38480;&#30340;&#35266;&#28857;&#12290;</title><link>http://arxiv.org/abs/2310.18988</link><description>&lt;p&gt;
&#23545;&#32479;&#35745;&#23398;&#20064;&#20013;&#21442;&#25968;&#35745;&#25968;&#30340;&#37325;&#26032;&#24605;&#32771;&#65306;&#23545;&#21452;&#19979;&#38477;&#30340;&#36716;&#21464;
&lt;/p&gt;
&lt;p&gt;
A U-turn on Double Descent: Rethinking Parameter Counting in Statistical Learning. (arXiv:2310.18988v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18988
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#37325;&#26032;&#24605;&#32771;&#20102;&#32479;&#35745;&#23398;&#20064;&#20013;&#21442;&#25968;&#35745;&#25968;&#30340;&#29702;&#35770;&#65292;&#25361;&#25112;&#20102;&#21452;&#19979;&#38477;&#29616;&#35937;&#25193;&#23637;&#20256;&#32479;&#22797;&#26434;&#24230;-&#27867;&#31867;&#20851;&#31995;&#30028;&#38480;&#30340;&#35266;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#32479;&#35745;&#23398;&#26234;&#24935;&#30830;&#31435;&#20102;&#27169;&#22411;&#22797;&#26434;&#24230;&#21644;&#39044;&#27979;&#35823;&#24046;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#36890;&#24120;&#20197;&#19968;&#20010;U&#24418;&#26354;&#32447;&#26469;&#34920;&#31034;&#65292;&#21453;&#26144;&#20102;&#27424;&#25311;&#21512;&#21644;&#36807;&#25311;&#21512;&#20043;&#38388;&#30340;&#36716;&#21464;&#12290;&#28982;&#32780;&#65292;&#21463;&#21040;&#36807;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#30340;&#25104;&#21151;&#30340;&#21551;&#21457;&#65292;&#26368;&#36817;&#26377;&#19968;&#20123;&#26377;&#24433;&#21709;&#21147;&#30340;&#24037;&#20316;&#35748;&#20026;&#36825;&#20010;&#29702;&#35770;&#36890;&#24120;&#26159;&#19981;&#23436;&#25972;&#30340;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#39069;&#22806;&#30340;&#21306;&#22495;&#65292;&#21363;&#22312;&#21442;&#25968;&#20010;&#25968;p&#36229;&#36807;&#26679;&#26412;&#22823;&#23567;n&#26102;&#65292;&#27979;&#35797;&#35823;&#24046;&#20250;&#20986;&#29616;&#31532;&#20108;&#27425;&#19979;&#38477;&#30340;&#29616;&#35937;&#65292;&#34987;&#31216;&#20026;&#21452;&#19979;&#38477;&#12290;&#34429;&#28982;&#22823;&#37096;&#20998;&#20851;&#27880;&#33258;&#28982;&#32780;&#28982;&#22320;&#38598;&#20013;&#22312;&#28145;&#24230;&#23398;&#20064;&#30340;&#35774;&#32622;&#19978;&#65292;&#20294;&#21452;&#19979;&#38477;&#29616;&#35937;&#24050;&#32463;&#22312;&#38750;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#20013;&#26356;&#19968;&#33324;&#22320;&#20986;&#29616;&#65292;&#24050;&#30693;&#30340;&#26696;&#20363;&#21253;&#25324;&#32447;&#24615;&#22238;&#24402;&#12289;&#26641;&#21644;Boosting&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23545;&#22260;&#32469;&#36825;&#20123;&#26356;&#32463;&#20856;&#30340;&#32479;&#35745;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#30340;&#35777;&#25454;&#36827;&#34892;&#20102;&#26356;&#35814;&#32454;&#30340;&#20998;&#26512;&#65292;&#24182;&#36136;&#30097;&#20102;&#21452;&#19979;&#38477;&#29616;&#35937;&#25193;&#23637;&#20102;&#20256;&#32479;U&#24418;&#22797;&#26434;&#24230;-&#27867;&#31867;&#20851;&#31995;&#30340;&#30028;&#38480;&#30340;&#35828;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conventional statistical wisdom established a well-understood relationship between model complexity and prediction error, typically presented as a U-shaped curve reflecting a transition between under- and overfitting regimes. However, motivated by the success of overparametrized neural networks, recent influential work has suggested this theory to be generally incomplete, introducing an additional regime that exhibits a second descent in test error as the parameter count p grows past sample size n - a phenomenon dubbed double descent. While most attention has naturally been given to the deep-learning setting, double descent was shown to emerge more generally across non-neural models: known cases include linear regression, trees, and boosting. In this work, we take a closer look at evidence surrounding these more classical statistical machine learning methods and challenge the claim that observed cases of double descent truly extend the limits of a traditional U-shaped complexity-genera
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#23618;ReLU&#21644;Leaky ReLU&#32593;&#32476;&#22312;&#20960;&#20046;&#27491;&#20132;&#25968;&#25454;&#19978;&#26799;&#24230;&#19979;&#38477;&#30340;&#38544;&#24335;&#20559;&#24046;&#12290;&#23545;&#20110;Leaky ReLU&#28608;&#27963;&#20989;&#25968;&#65292;&#26799;&#24230;&#19979;&#38477;&#33021;&#25214;&#21040;&#25910;&#25947;&#21040;1&#30340;&#31283;&#23450;&#31209;&#32593;&#32476;&#65307;&#23545;&#20110;ReLU&#28608;&#27963;&#20989;&#25968;&#65292;&#26799;&#24230;&#19979;&#38477;&#33021;&#25214;&#21040;&#31283;&#23450;&#31209;&#19978;&#30028;&#20026;&#24120;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;</title><link>http://arxiv.org/abs/2310.18935</link><description>&lt;p&gt;
&#23545;&#20110;&#20960;&#20046;&#27491;&#20132;&#25968;&#25454;&#30340;&#20004;&#23618;ReLU&#21644;Leaky ReLU&#32593;&#32476;&#65292;&#26799;&#24230;&#19979;&#38477;&#30340;&#38544;&#24335;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
Implicit Bias of Gradient Descent for Two-layer ReLU and Leaky ReLU Networks on Nearly-orthogonal Data. (arXiv:2310.18935v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18935
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#23618;ReLU&#21644;Leaky ReLU&#32593;&#32476;&#22312;&#20960;&#20046;&#27491;&#20132;&#25968;&#25454;&#19978;&#26799;&#24230;&#19979;&#38477;&#30340;&#38544;&#24335;&#20559;&#24046;&#12290;&#23545;&#20110;Leaky ReLU&#28608;&#27963;&#20989;&#25968;&#65292;&#26799;&#24230;&#19979;&#38477;&#33021;&#25214;&#21040;&#25910;&#25947;&#21040;1&#30340;&#31283;&#23450;&#31209;&#32593;&#32476;&#65307;&#23545;&#20110;ReLU&#28608;&#27963;&#20989;&#25968;&#65292;&#26799;&#24230;&#19979;&#38477;&#33021;&#25214;&#21040;&#31283;&#23450;&#31209;&#19978;&#30028;&#20026;&#24120;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#20854;&#23545;&#26377;&#21033;&#29305;&#24615;&#35299;&#30340;&#38544;&#24335;&#20559;&#22909;&#65292;&#22522;&#20110;&#26799;&#24230;&#20248;&#21270;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#33021;&#22815;&#24456;&#22909;&#22320;&#27867;&#21270;&#12290;&#34429;&#28982;&#26799;&#24230;&#27969;&#30340;&#38544;&#24335;&#20559;&#24046;&#24050;&#32463;&#34987;&#24191;&#27867;&#30740;&#31350;&#20102;&#22343;&#21248;&#31070;&#32463;&#32593;&#32476;&#65288;&#21253;&#25324;ReLU&#21644;Leaky ReLU&#32593;&#32476;&#65289;&#65292;&#20294;&#23545;&#20110;&#26799;&#24230;&#19979;&#38477;&#30340;&#38544;&#24335;&#20559;&#24046;&#30446;&#21069;&#21482;&#20102;&#35299;&#20102;&#24179;&#28369;&#31070;&#32463;&#32593;&#32476;&#12290;&#22240;&#27492;&#65292;&#23545;&#20110;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#38750;&#24179;&#28369;&#31070;&#32463;&#32593;&#32476;&#30340;&#38544;&#24335;&#20559;&#24046;&#20173;&#28982;&#26159;&#19968;&#20010;&#24320;&#25918;&#38382;&#39064;&#12290;&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#26799;&#24230;&#19979;&#38477;&#22312;&#35757;&#32451;&#20004;&#23618;&#20840;&#36830;&#25509;(Leaky) ReLU&#31070;&#32463;&#32593;&#32476;&#26102;&#30340;&#38544;&#24335;&#20559;&#24046;&#26469;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#35757;&#32451;&#25968;&#25454;&#20960;&#20046;&#27491;&#20132;&#26102;&#65292;&#23545;&#20110;Leaky ReLU&#28608;&#27963;&#20989;&#25968;&#65292;&#26799;&#24230;&#19979;&#38477;&#23558;&#25214;&#21040;&#19968;&#20010;&#25910;&#25947;&#21040;1&#30340;&#31283;&#23450;&#31209;&#32593;&#32476;&#65292;&#32780;&#23545;&#20110;ReLU&#28608;&#27963;&#20989;&#25968;&#65292;&#26799;&#24230;&#19979;&#38477;&#23558;&#25214;&#21040;&#19968;&#20010;&#31283;&#23450;&#31209;&#19978;&#30028;&#20026;&#24120;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
The implicit bias towards solutions with favorable properties is believed to be a key reason why neural networks trained by gradient-based optimization can generalize well. While the implicit bias of gradient flow has been widely studied for homogeneous neural networks (including ReLU and leaky ReLU networks), the implicit bias of gradient descent is currently only understood for smooth neural networks. Therefore, implicit bias in non-smooth neural networks trained by gradient descent remains an open question. In this paper, we aim to answer this question by studying the implicit bias of gradient descent for training two-layer fully connected (leaky) ReLU neural networks. We showed that when the training data are nearly-orthogonal, for leaky ReLU activation function, gradient descent will find a network with a stable rank that converges to $1$, whereas for ReLU activation function, gradient descent will find a neural network with a stable rank that is upper bounded by a constant. Addit
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35299;&#20915;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#24310;&#36831;&#21453;&#39304;&#23545;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340;&#25361;&#25112;&#65292;&#36890;&#36807;&#21518;&#39564;&#37319;&#26679;&#31639;&#27861;&#23454;&#29616;&#20102;&#22312;&#19981;&#21516;&#24773;&#20917;&#19979;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.18919</link><description>&lt;p&gt;
&#24310;&#36831;&#21453;&#39304;&#30340;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#21518;&#39564;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Posterior Sampling with Delayed Feedback for Reinforcement Learning with Linear Function Approximation. (arXiv:2310.18919v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18919
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35299;&#20915;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#24310;&#36831;&#21453;&#39304;&#23545;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340;&#25361;&#25112;&#65292;&#36890;&#36807;&#21518;&#39564;&#37319;&#26679;&#31639;&#27861;&#23454;&#29616;&#20102;&#22312;&#19981;&#21516;&#24773;&#20917;&#19979;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36816;&#29992;&#20989;&#25968;&#36924;&#36817;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#20294;&#29616;&#26377;&#30340;&#39640;&#25928;&#31639;&#27861;&#36890;&#24120;&#20381;&#36182;&#20110;&#21363;&#26102;&#21453;&#39304;&#12290;&#26412;&#25991;&#36890;&#36807;&#37319;&#29992;&#21518;&#39564;&#37319;&#26679;&#26469;&#35299;&#20915;&#24310;&#36831;&#21453;&#39304;&#23545;&#24378;&#21270;&#23398;&#20064;&#20013;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#30340;&#25361;&#25112;&#65292;&#39318;&#20808;&#20171;&#32461;&#20102;Delayed-PSVI&#31639;&#27861;&#65292;&#36890;&#36807;&#21518;&#39564;&#37319;&#26679;&#20013;&#30340;&#22122;&#22768;&#25200;&#21160;&#26377;&#25928;&#22320;&#25506;&#32034;&#20215;&#20540;&#20989;&#25968;&#31354;&#38388;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#24310;&#36831;&#21453;&#39304;&#24378;&#21270;&#23398;&#20064;&#20013;&#21518;&#39564;&#37319;&#26679;&#31639;&#27861;&#30340;&#39318;&#27425;&#20998;&#26512;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#19968;&#31995;&#21015;&#24773;&#20917;&#19979;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent studies in reinforcement learning (RL) have made significant progress by leveraging function approximation to alleviate the sample complexity hurdle for better performance. Despite the success, existing provably efficient algorithms typically rely on the accessibility of immediate feedback upon taking actions. The failure to account for the impact of delay in observations can significantly degrade the performance of real-world systems due to the regret blow-up. In this work, we tackle the challenge of delayed feedback in RL with linear function approximation by employing posterior sampling, which has been shown to empirically outperform the popular UCB algorithms in a wide range of regimes. We first introduce Delayed-PSVI, an optimistic value-based algorithm that effectively explores the value function space via noise perturbation with posterior sampling. We provide the first analysis for posterior sampling algorithms with delayed feedback in RL and show our algorithm achieves $
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#27169;&#22411;&#36866;&#24212;&#26469;&#26816;&#27979;&#21644;&#20943;&#36731;&#35821;&#35328;&#27169;&#22411;&#20013;&#24615;&#21035;&#20559;&#35265;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#33021;&#22815;&#26174;&#33879;&#20943;&#23569;&#20559;&#35265;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.18913</link><description>&lt;p&gt;
&#36890;&#36807;&#27169;&#22411;&#36866;&#24212;&#26469;&#21435;&#38500;&#20559;&#35265;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Debiasing Algorithm through Model Adaptation. (arXiv:2310.18913v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18913
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#27169;&#22411;&#36866;&#24212;&#26469;&#26816;&#27979;&#21644;&#20943;&#36731;&#35821;&#35328;&#27169;&#22411;&#20013;&#24615;&#21035;&#20559;&#35265;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#33021;&#22815;&#26174;&#33879;&#20943;&#23569;&#20559;&#35265;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#27491;&#22312;&#25104;&#20026;&#21508;&#31181;&#35821;&#35328;&#20219;&#21153;&#30340;&#39318;&#36873;&#35299;&#20915;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#23481;&#37327;&#30340;&#22686;&#38271;&#65292;&#27169;&#22411;&#24456;&#23481;&#26131;&#20381;&#36182;&#35757;&#32451;&#25968;&#25454;&#20013;&#23384;&#22312;&#30340;&#20559;&#35265;&#21644;&#21051;&#26495;&#21360;&#35937;&#25152;&#20135;&#29983;&#30340;&#34394;&#20551;&#30456;&#20851;&#24615;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#26469;&#26816;&#27979;&#21644;&#20943;&#36731;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#24615;&#21035;&#20559;&#35265;&#12290;&#25105;&#20204;&#36827;&#34892;&#22240;&#26524;&#20998;&#26512;&#65292;&#20197;&#35782;&#21035;&#38382;&#39064;&#27169;&#22411;&#32452;&#20214;&#65292;&#24182;&#21457;&#29616;&#20013;&#19978;&#23618;&#21069;&#39304;&#23618;&#26368;&#23481;&#26131;&#20256;&#36882;&#20559;&#35265;&#12290;&#26681;&#25454;&#20998;&#26512;&#32467;&#26524;&#65292;&#25105;&#20204;&#36890;&#36807;&#32447;&#24615;&#25237;&#24433;&#23558;&#36825;&#20123;&#23618;&#20056;&#20197;&#27169;&#22411;&#36827;&#34892;&#36866;&#24212;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;DAMA&#36890;&#36807;&#21508;&#31181;&#24230;&#37327;&#25351;&#26631;&#26126;&#26174;&#20943;&#23569;&#20102;&#20559;&#35265;&#65292;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#22312;&#21518;&#32493;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#21457;&#24067;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#21644;&#27169;&#22411;&#30340;&#20195;&#30721;&#65292;&#36890;&#36807;&#37325;&#26032;&#35757;&#32451;&#65292;&#20445;&#25345;&#20102;LLaMA&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#65292;&#21516;&#26102;&#20559;&#35265;&#26174;&#33879;&#20943;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models are becoming the go-to solution for various language tasks. However, with growing capacity, models are prone to rely on spurious correlations stemming from biases and stereotypes present in the training data. This work proposes a novel method for detecting and mitigating gender bias in language models. We perform causal analysis to identify problematic model components and discover that mid-upper feed-forward layers are most prone to convey biases. Based on the analysis results, we adapt the model by multiplying these layers by a linear projection. Our titular method, DAMA, significantly decreases bias as measured by diverse metrics while maintaining the model's performance on downstream tasks. We release code for our method and models, which retrain LLaMA's state-of-the-art performance while being significantly less biased.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21322;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#23454;&#20363;&#30456;&#20851;&#30340;&#38408;&#20540;&#26469;&#36873;&#25321;&#26377;&#20449;&#24515;&#30340;&#26410;&#26631;&#35760;&#23454;&#20363;&#65292;&#24182;&#23558;&#20854;&#32435;&#20837;&#35757;&#32451;&#38598;&#20013;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#23454;&#20363;&#32423;&#21035;&#30340;&#27169;&#31946;&#24230;&#21644;&#23454;&#20363;&#30456;&#20851;&#30340;&#38169;&#35823;&#29575;&#26469;&#35774;&#35745;&#38408;&#20540;&#20989;&#25968;&#65292;&#30456;&#27604;&#29616;&#26377;&#26041;&#27861;&#20855;&#26377;&#26356;&#39640;&#30340;&#33258;&#30001;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.18910</link><description>&lt;p&gt;
InstanT: &#22522;&#20110;&#23454;&#20363;&#30456;&#20851;&#38408;&#20540;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
InstanT: Semi-supervised Learning with Instance-dependent Thresholds. (arXiv:2310.18910v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18910
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21322;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#23454;&#20363;&#30456;&#20851;&#30340;&#38408;&#20540;&#26469;&#36873;&#25321;&#26377;&#20449;&#24515;&#30340;&#26410;&#26631;&#35760;&#23454;&#20363;&#65292;&#24182;&#23558;&#20854;&#32435;&#20837;&#35757;&#32451;&#38598;&#20013;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#23454;&#20363;&#32423;&#21035;&#30340;&#27169;&#31946;&#24230;&#21644;&#23454;&#20363;&#30456;&#20851;&#30340;&#38169;&#35823;&#29575;&#26469;&#35774;&#35745;&#38408;&#20540;&#20989;&#25968;&#65292;&#30456;&#27604;&#29616;&#26377;&#26041;&#27861;&#20855;&#26377;&#26356;&#39640;&#30340;&#33258;&#30001;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21322;&#30417;&#30563;&#23398;&#20064;&#19968;&#30452;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#25361;&#25112;&#12290;&#20266;&#26631;&#35760;&#31639;&#27861;&#26159;&#20027;&#35201;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#31639;&#27861;&#20043;&#19968;&#65292;&#23427;&#28041;&#21450;&#23558;&#20266;&#26631;&#31614;&#20998;&#37197;&#32473;&#26377;&#20449;&#24515;&#30340;&#26410;&#26631;&#35760;&#23454;&#20363;&#24182;&#23558;&#20854;&#32435;&#20837;&#35757;&#32451;&#38598;&#20013;&#12290;&#22240;&#27492;&#65292;&#26377;&#20449;&#24515;&#23454;&#20363;&#30340;&#36873;&#25321;&#26631;&#20934;&#23545;&#21322;&#30417;&#30563;&#23398;&#20064;&#30340;&#25104;&#21151;&#33267;&#20851;&#37325;&#35201;&#12290;&#26368;&#36817;&#65292;&#23545;&#20351;&#29992;&#21160;&#24577;&#25110;&#33258;&#36866;&#24212;&#38408;&#20540;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#30340;&#21457;&#23637;&#36234;&#26469;&#36234;&#24863;&#20852;&#36259;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#23558;&#30456;&#21516;&#30340;&#38408;&#20540;&#24212;&#29992;&#20110;&#25152;&#26377;&#26679;&#26412;&#65292;&#25110;&#32773;&#23545;&#23646;&#20110;&#26576;&#20010;&#31867;&#30340;&#23454;&#20363;&#20351;&#29992;&#31867;&#30456;&#20851;&#38408;&#20540;&#65292;&#32780;&#24573;&#30053;&#23454;&#20363;&#32423;&#21035;&#30340;&#20449;&#24687;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#30740;&#31350;&#23454;&#20363;&#30456;&#20851;&#38408;&#20540;&#30340;&#26041;&#27861;&#65292;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#20855;&#26377;&#26368;&#39640;&#30340;&#33258;&#30001;&#24230;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#21033;&#29992;&#23454;&#20363;&#32423;&#21035;&#30340;&#27169;&#31946;&#24230;&#21644;&#23454;&#20363;&#30456;&#20851;&#30340;&#38169;&#35823;&#29575;&#65292;&#20026;&#25152;&#26377;&#26410;&#26631;&#35760;&#23454;&#20363;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#23454;&#20363;&#30456;&#20851;&#38408;&#20540;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Semi-supervised learning (SSL) has been a fundamental challenge in machine learning for decades. The primary family of SSL algorithms, known as pseudo-labeling, involves assigning pseudo-labels to confident unlabeled instances and incorporating them into the training set. Therefore, the selection criteria of confident instances are crucial to the success of SSL. Recently, there has been growing interest in the development of SSL methods that use dynamic or adaptive thresholds. Yet, these methods typically apply the same threshold to all samples, or use class-dependent thresholds for instances belonging to a certain class, while neglecting instance-level information. In this paper, we propose the study of instance-dependent thresholds, which has the highest degree of freedom compared with existing methods. Specifically, we devise a novel instance-dependent threshold function for all unlabeled instances by utilizing their instance-level ambiguity and the instance-dependent error rates of
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;Wasserstein&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#20174;&#26368;&#20248;&#20256;&#36755;&#30340;&#35282;&#24230;&#25552;&#20986;&#20102;&#19968;&#31181;&#20272;&#35745;&#36895;&#29575;-&#22833;&#30495;&#20989;&#25968;R(D)&#30340;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#20302;&#36895;&#29575;&#28304;&#19978;&#21462;&#24471;&#20102;&#19982;&#26368;&#20808;&#36827;&#30340;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#30456;&#24403;&#25110;&#26356;&#24378;&#30340;&#24615;&#33021;&#30028;&#38480;&#65292;&#24182;&#19988;&#38656;&#35201;&#36739;&#23569;&#30340;&#35843;&#25972;&#21644;&#35745;&#31639;&#24037;&#20316;&#12290;</title><link>http://arxiv.org/abs/2310.18908</link><description>&lt;p&gt;
&#36890;&#36807;Wasserstein&#26799;&#24230;&#19979;&#38477;&#20272;&#35745;&#36895;&#29575;-&#22833;&#30495;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Estimating the Rate-Distortion Function by Wasserstein Gradient Descent. (arXiv:2310.18908v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18908
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;Wasserstein&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#20174;&#26368;&#20248;&#20256;&#36755;&#30340;&#35282;&#24230;&#25552;&#20986;&#20102;&#19968;&#31181;&#20272;&#35745;&#36895;&#29575;-&#22833;&#30495;&#20989;&#25968;R(D)&#30340;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#20302;&#36895;&#29575;&#28304;&#19978;&#21462;&#24471;&#20102;&#19982;&#26368;&#20808;&#36827;&#30340;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#30456;&#24403;&#25110;&#26356;&#24378;&#30340;&#24615;&#33021;&#30028;&#38480;&#65292;&#24182;&#19988;&#38656;&#35201;&#36739;&#23569;&#30340;&#35843;&#25972;&#21644;&#35745;&#31639;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26080;&#25439;&#21387;&#32553;&#29702;&#35770;&#20013;&#65292;&#36895;&#29575;-&#22833;&#30495;&#65288;R-D&#65289;&#20989;&#25968;R(D)&#25551;&#36848;&#20102;&#22312;&#20219;&#20309;&#32473;&#23450;&#30340;&#20445;&#30495;&#24230;&#65288;&#22833;&#30495;&#65289;&#27700;&#24179;&#19979;&#65292;&#25968;&#25454;&#28304;&#21487;&#20197;&#34987;&#21387;&#32553;&#30340;&#31243;&#24230;&#65288;&#27604;&#29305;&#29575;&#65289;&#12290;&#20174;&#26368;&#20248;&#20256;&#36755;&#30340;&#35282;&#24230;&#25552;&#20986;&#20102;&#19968;&#31181;&#20272;&#35745;R(D)&#30340;&#26032;&#26041;&#27861;&#12290;&#19982;&#32463;&#20856;&#30340;Blahut-Arimoto&#31639;&#27861;&#22312;&#20808;&#22266;&#23450;&#22797;&#21046;&#20998;&#24067;&#30340;&#25903;&#25345;&#30340;&#22522;&#30784;&#19978;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;Wasserstein&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#36890;&#36807;&#31227;&#21160;&#31890;&#23376;&#23398;&#20064;&#26368;&#20248;&#22797;&#21046;&#20998;&#24067;&#30340;&#25903;&#25345;&#12290;&#35777;&#26126;&#20102;&#20854;&#23616;&#37096;&#25910;&#25947;&#24615;&#65292;&#24182;&#36890;&#36807;&#19982;&#29109;&#26368;&#20248;&#20256;&#36755;&#30340;&#32852;&#31995;&#20998;&#26512;&#20102;&#25105;&#20204;&#30340;R-D&#20272;&#35745;&#22120;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#22312;&#20302;&#36895;&#29575;&#28304;&#19978;&#65292;&#25105;&#20204;&#23454;&#39564;&#19978;&#33719;&#24471;&#20102;&#19982;&#26368;&#20808;&#36827;&#30340;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#30456;&#24403;&#25110;&#26356;&#24378;&#30340;&#30028;&#38480;&#65292;&#21516;&#26102;&#38656;&#35201;&#36739;&#23569;&#30340;&#35843;&#25972;&#21644;&#35745;&#31639;&#24037;&#20316;&#12290;&#25105;&#20204;&#36824;&#24378;&#35843;&#20102;&#19982;&#26368;&#22823;&#20284;&#28982;&#26041;&#27861;&#30340;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the theory of lossy compression, the rate-distortion (R-D) function $R(D)$ describes how much a data source can be compressed (in bit-rate) at any given level of fidelity (distortion). Obtaining $R(D)$ for a given data source establishes the fundamental performance limit for all compression algorithms. We propose a new method to estimate $R(D)$ from the perspective of optimal transport. Unlike the classic Blahut--Arimoto algorithm which fixes the support of the reproduction distribution in advance, our Wasserstein gradient descent algorithm learns the support of the optimal reproduction distribution by moving particles. We prove its local convergence and analyze the sample complexity of our R-D estimator based on a connection to entropic optimal transport. Experimentally, we obtain comparable or tighter bounds than state-of-the-art neural network methods on low-rate sources while requiring considerably less tuning and computation effort. We also highlight a connection to maximum-lik
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#22686;&#24378;&#30340;&#31616;&#21333;&#38750;&#23545;&#31216;&#22270;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;GraphACL&#65292;&#36890;&#36807;&#32771;&#34385;&#37051;&#23621;&#33410;&#28857;&#30340;&#38750;&#23545;&#31216;&#35270;&#22270;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#26377;&#25928;&#22320;&#22312;&#21516;&#31867;&#21644;&#24322;&#31867;&#22270;&#19978;&#36827;&#34892;&#23545;&#27604;&#23398;&#20064;&#65292;&#23545;&#20110;&#24314;&#27169;&#24322;&#31867;&#22270;&#38750;&#24120;&#37325;&#35201;&#12290;</title><link>http://arxiv.org/abs/2310.18884</link><description>&lt;p&gt;
&#26080;&#38656;&#22686;&#24378;&#30340;&#31616;&#21333;&#38750;&#23545;&#31216;&#22270;&#23545;&#27604;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Simple and Asymmetric Graph Contrastive Learning without Augmentations. (arXiv:2310.18884v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18884
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#22686;&#24378;&#30340;&#31616;&#21333;&#38750;&#23545;&#31216;&#22270;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;GraphACL&#65292;&#36890;&#36807;&#32771;&#34385;&#37051;&#23621;&#33410;&#28857;&#30340;&#38750;&#23545;&#31216;&#35270;&#22270;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#26377;&#25928;&#22320;&#22312;&#21516;&#31867;&#21644;&#24322;&#31867;&#22270;&#19978;&#36827;&#34892;&#23545;&#27604;&#23398;&#20064;&#65292;&#23545;&#20110;&#24314;&#27169;&#24322;&#31867;&#22270;&#38750;&#24120;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#23545;&#27604;&#23398;&#20064;&#65288;GCL&#65289;&#22312;&#22270;&#32467;&#26500;&#25968;&#25454;&#30340;&#34920;&#31034;&#23398;&#20064;&#20013;&#26174;&#31034;&#20986;&#20102;&#20248;&#36234;&#30340;&#24615;&#33021;&#12290;&#23613;&#31649;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;GCL&#26041;&#27861;&#20381;&#36182;&#20110;&#39044;&#21046;&#30340;&#22270;&#22686;&#24378;&#21644;&#21516;&#31867;&#20551;&#35774;&#12290;&#22240;&#27492;&#65292;&#23427;&#20204;&#22312;&#36830;&#36890;&#33410;&#28857;&#21487;&#33021;&#20855;&#26377;&#19981;&#21516;&#31867;&#26631;&#31614;&#21644;&#19981;&#30456;&#20284;&#29305;&#24449;&#30340;&#24322;&#31867;&#22270;&#19978;&#26080;&#27861;&#24456;&#22909;&#22320;&#25512;&#24191;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#21516;&#31867;&#21644;&#24322;&#31867;&#22270;&#19978;&#36827;&#34892;&#23545;&#27604;&#23398;&#20064;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#36890;&#36807;&#32771;&#34385;&#37051;&#23621;&#33410;&#28857;&#30340;&#38750;&#23545;&#31216;&#35270;&#22270;&#65292;&#25105;&#20204;&#21487;&#20197;&#23454;&#29616;&#26377;&#24076;&#26395;&#30340;&#24615;&#33021;&#12290;&#30001;&#27492;&#20135;&#29983;&#30340;&#31616;&#21333;&#31639;&#27861;&#65292;&#31216;&#20026;&#22270;&#30340;&#38750;&#23545;&#31216;&#23545;&#27604;&#23398;&#20064;(GraphACL)&#65292;&#26131;&#20110;&#23454;&#29616;&#65292;&#19981;&#20381;&#36182;&#20110;&#22270;&#22686;&#24378;&#21644;&#21516;&#31867;&#20551;&#35774;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#29702;&#35770;&#21644;&#23454;&#35777;&#35777;&#25454;&#65292;&#35777;&#26126;GraphACL&#33021;&#22815;&#25429;&#25417;&#21333;&#36339;&#26412;&#22320;&#37051;&#22495;&#20449;&#24687;&#21644;&#21452;&#36339;&#21333;&#19968;&#30456;&#20284;&#24615;&#65292;&#36825;&#20004;&#32773;&#23545;&#20110;&#24314;&#27169;&#24322;&#31867;&#22270;&#38750;&#24120;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Contrastive Learning (GCL) has shown superior performance in representation learning in graph-structured data. Despite their success, most existing GCL methods rely on prefabricated graph augmentation and homophily assumptions. Thus, they fail to generalize well to heterophilic graphs where connected nodes may have different class labels and dissimilar features. In this paper, we study the problem of conducting contrastive learning on homophilic and heterophilic graphs. We find that we can achieve promising performance simply by considering an asymmetric view of the neighboring nodes. The resulting simple algorithm, Asymmetric Contrastive Learning for Graphs (GraphACL), is easy to implement and does not rely on graph augmentations and homophily assumptions. We provide theoretical and empirical evidence that GraphACL can capture one-hop local neighborhood information and two-hop monophily similarity, which are both important for modeling heterophilic graphs. Experimental results s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#20844;&#24335;&#30340;&#23725;&#22238;&#24402;&#26041;&#27861;&#65292;&#36890;&#36807;&#26399;&#26395;&#26368;&#22823;&#21270;&#26469;&#35843;&#33410;&#27491;&#21017;&#21270;&#36229;&#21442;&#25968;&#65292;&#35813;&#26041;&#27861;&#19981;&#38656;&#35201;&#25351;&#23450;&#20505;&#36873;&#30340;&#955;&#24182;&#19988;&#22312;&#22823;&#26679;&#26412;&#19979;&#21487;&#20197;&#25214;&#21040;&#21807;&#19968;&#30340;&#26368;&#20248;&#35299;&#12290;</title><link>http://arxiv.org/abs/2310.18860</link><description>&lt;p&gt;
Bayes&#25112;&#32988;&#20132;&#21449;&#39564;&#35777;&#65306;&#36890;&#36807;&#26399;&#26395;&#26368;&#22823;&#21270;&#23454;&#29616;&#39640;&#25928;&#20934;&#30830;&#30340;&#23725;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Bayes beats Cross Validation: Efficient and Accurate Ridge Regression via Expectation Maximization. (arXiv:2310.18860v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18860
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#20844;&#24335;&#30340;&#23725;&#22238;&#24402;&#26041;&#27861;&#65292;&#36890;&#36807;&#26399;&#26395;&#26368;&#22823;&#21270;&#26469;&#35843;&#33410;&#27491;&#21017;&#21270;&#36229;&#21442;&#25968;&#65292;&#35813;&#26041;&#27861;&#19981;&#38656;&#35201;&#25351;&#23450;&#20505;&#36873;&#30340;&#955;&#24182;&#19988;&#22312;&#22823;&#26679;&#26412;&#19979;&#21487;&#20197;&#25214;&#21040;&#21807;&#19968;&#30340;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#35843;&#33410;&#23725;&#22238;&#24402;&#30340;&#27491;&#21017;&#21270;&#36229;&#21442;&#25968;&#955;&#65292;&#35813;&#26041;&#27861;&#30340;&#35745;&#31639;&#36895;&#24230;&#27604;&#30041;&#19968;&#20132;&#21449;&#39564;&#35777;(LOOCV)&#24555;&#65292;&#21516;&#26102;&#22312;&#31232;&#30095;&#21327;&#21464;&#37327;&#30340;&#24773;&#20917;&#19979;&#21487;&#20197;&#33719;&#24471;&#19982;LOOCV&#30456;&#31561;&#25110;&#26356;&#22909;&#30340;&#22238;&#24402;&#21442;&#25968;&#20272;&#35745;&#12290;&#23545;&#20110;&#26377;&#38480;&#30340;n&#65292;LOOCV&#39118;&#38505;&#21487;&#33021;&#21463;&#21040;&#22810;&#20010;&#21644;&#19981;&#22909;&#30340;&#23616;&#37096;&#26368;&#23567;&#20540;&#30340;&#24433;&#21709;&#65292;&#22240;&#27492;&#38656;&#35201;&#25351;&#23450;&#19968;&#32452;&#20505;&#36873;&#30340;&#955;&#65292;&#36825;&#21487;&#33021;&#26080;&#27861;&#25552;&#20379;&#33391;&#22909;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#36275;&#22815;&#22823;&#30340;n&#19979;&#21487;&#20197;&#25214;&#21040;&#21807;&#19968;&#30340;&#26368;&#20248;&#35299;&#65292;&#24182;&#19988;&#19981;&#38656;&#35201;&#25351;&#23450;&#20219;&#20309;&#38590;&#20197;&#30830;&#23450;&#30340;&#36229;&#21442;&#25968;&#12290;&#36825;&#26159;&#22522;&#20110;&#23725;&#22238;&#24402;&#30340;&#36125;&#21494;&#26031;&#20844;&#24335;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#36275;&#22815;&#22823;&#30340;n&#65292;&#21518;&#39564;&#26159;&#21333;&#23792;&#30340;&#65292;&#21487;&#20197;&#21516;&#26102;&#23398;&#20064;&#26368;&#20248;&#30340;&#955;&#21644;&#22238;&#24402;&#31995;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a novel method for tuning the regularization hyper-parameter, $\lambda$, of a ridge regression that is faster to compute than leave-one-out cross-validation (LOOCV) while yielding estimates of the regression parameters of equal, or particularly in the setting of sparse covariates, superior quality to those obtained by minimising the LOOCV risk. The LOOCV risk can suffer from multiple and bad local minima for finite $n$ and thus requires the specification of a set of candidate $\lambda$, which can fail to provide good solutions. In contrast, we show that the proposed method is guaranteed to find a unique optimal solution for large enough $n$, under relatively mild conditions, without requiring the specification of any difficult to determine hyper-parameters. This is based on a Bayesian formulation of ridge regression that we prove to have a unimodal posterior for large enough $n$, allowing for both the optimal $\lambda$ and the regression coefficients to be jointly learned wi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#22312;&#27969;&#24418;&#19978;&#22788;&#29702;&#30690;&#37327;&#20540;&#20449;&#21495;&#30340;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#65292;&#20855;&#26377;&#20869;&#22312;&#23450;&#20041;&#21644;&#32771;&#34385;&#31354;&#38388;&#20960;&#20309;&#30340;&#29305;&#28857;&#65292;&#24182;&#20026;&#37096;&#32626;&#22312;&#20108;&#32500;&#29699;&#38754;&#21644;&#36229;&#26354;&#38754;&#19978;&#30340;Hodge-Mat\'ern&#39640;&#26031;&#21521;&#37327;&#22330;&#25552;&#20379;&#20102;&#35745;&#31639;&#22522;&#20803;&#12290;</title><link>http://arxiv.org/abs/2310.18824</link><description>&lt;p&gt;
&#29699;&#38754;&#19978;&#30340;&#20869;&#22312;&#39640;&#26031;&#21521;&#37327;&#22330;
&lt;/p&gt;
&lt;p&gt;
Intrinsic Gaussian Vector Fields on Manifolds. (arXiv:2310.18824v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18824
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#22312;&#27969;&#24418;&#19978;&#22788;&#29702;&#30690;&#37327;&#20540;&#20449;&#21495;&#30340;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#65292;&#20855;&#26377;&#20869;&#22312;&#23450;&#20041;&#21644;&#32771;&#34385;&#31354;&#38388;&#20960;&#20309;&#30340;&#29305;&#28857;&#65292;&#24182;&#20026;&#37096;&#32626;&#22312;&#20108;&#32500;&#29699;&#38754;&#21644;&#36229;&#26354;&#38754;&#19978;&#30340;Hodge-Mat\'ern&#39640;&#26031;&#21521;&#37327;&#22330;&#25552;&#20379;&#20102;&#35745;&#31639;&#22522;&#20803;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#26426;&#22120;&#20154;&#25216;&#26415;&#21040;&#27668;&#20505;&#31185;&#23398;&#31561;&#21508;&#31181;&#24212;&#29992;&#37117;&#38656;&#35201;&#23545;&#38750;&#27431;&#20960;&#37324;&#24471;&#22495;&#65288;&#22914;&#29699;&#38754;&#65289;&#19978;&#30340;&#20449;&#21495;&#36827;&#34892;&#24314;&#27169;&#12290;&#26368;&#36817;&#65292;&#22312;&#27969;&#34892;&#24230;&#37327;&#31354;&#38388;&#19978;&#25552;&#20986;&#20102;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#65292;&#23588;&#20854;&#26159;&#22312;&#38656;&#35201;&#36827;&#34892;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#20219;&#21153;&#20013;&#12290;&#22312;&#27969;&#24418;&#35774;&#32622;&#20013;&#65292;&#19982;&#26631;&#37327;&#20540;&#20449;&#21495;&#30456;&#27604;&#65292;&#30690;&#37327;&#20540;&#20449;&#21495;&#21487;&#33021;&#34920;&#29616;&#20986;&#25130;&#28982;&#19981;&#21516;&#30340;&#34892;&#20026;&#65292;&#36804;&#20170;&#20026;&#27490;&#30340;&#22823;&#37096;&#20998;&#36827;&#23637;&#37117;&#38598;&#20013;&#22312;&#23545;&#21069;&#32773;&#36827;&#34892;&#24314;&#27169;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#35768;&#22810;&#24212;&#29992;&#65292;&#22914;&#23545;&#26410;&#30693;&#21160;&#21147;&#31995;&#32479;&#30340;&#39118;&#36895;&#25110;&#21147;&#22330;&#36827;&#34892;&#24314;&#27169;&#65292;&#21518;&#32773;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#27969;&#24418;&#19978;&#20026;&#30690;&#37327;&#20540;&#20449;&#21495;&#25552;&#20379;&#20869;&#22312;&#23450;&#20041;&#24182;&#32771;&#34385;&#31354;&#38388;&#20960;&#20309;&#30340;&#26032;&#22411;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#37096;&#32626;&#25152;&#24471;&#21040;&#30340;Hodge-Mat\'ern&#39640;&#26031;&#21521;&#37327;&#22330;&#22312;&#20108;&#32500;&#29699;&#38754;&#21644;&#36229;&#26354;&#38754;&#19978;&#25152;&#38656;&#30340;&#35745;&#31639;&#22522;&#20803;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24378;&#35843;&#20102;&#20004;&#20010;&#25512;&#24191;&#26041;&#21521;&#65306;&#31163;&#25955;&#30340;&#20108;&#32500;&#32593;&#26684;&#21644;&#8221;ide&#8220;&#65288;&#26242;&#19988;&#35793;&#20026;&#65306;&#24819;&#27861;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Various applications ranging from robotics to climate science require modeling signals on non-Euclidean domains, such as the sphere. Gaussian process models on manifolds have recently been proposed for such tasks, in particular when uncertainty quantification is needed. In the manifold setting, vector-valued signals can behave very differently from scalar-valued ones, with much of the progress so far focused on modeling the latter. The former, however, are crucial for many applications, such as modeling wind speeds or force fields of unknown dynamical systems. In this paper, we propose novel Gaussian process models for vector-valued signals on manifolds that are intrinsically defined and account for the geometry of the space in consideration. We provide computational primitives needed to deploy the resulting Hodge-Mat\'ern Gaussian vector fields on the two-dimensional sphere and the hypertori. Further, we highlight two generalization directions: discrete two-dimensional meshes and "ide
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#22312;&#24179;&#26041;&#21709;&#24212;&#65288;$Y^2$&#65289;&#27809;&#26377;&#37325;&#23614;&#30340;&#28201;&#21644;&#26465;&#20214;&#19979;&#65292;&#38543;&#26426;&#26862;&#26519;&#20855;&#26377;&#31283;&#23450;&#24615;&#12290;&#21033;&#29992;&#31283;&#23450;&#24615;&#23646;&#24615;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#38543;&#26426;&#26862;&#26519;&#30340;&#39044;&#27979;&#21306;&#38388;&#30340;&#35206;&#30422;&#27010;&#29575;&#30340;&#38750;&#28176;&#36817;&#19979;&#30028;&#65292;&#24182;&#35752;&#35770;&#20102;&#27604;&#20197;&#21069;&#32771;&#34385;&#30340;&#26465;&#20214;&#26356;&#24369;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2310.18814</link><description>&lt;p&gt;
&#38543;&#26426;&#26862;&#26519;&#30340;&#31283;&#23450;&#24615;&#21644;&#38543;&#26426;&#26862;&#26519;&#39044;&#27979;&#21306;&#38388;&#30340;&#35206;&#30422;&#29575;
&lt;/p&gt;
&lt;p&gt;
Stability of Random Forests and Coverage of Random-Forest Prediction Intervals. (arXiv:2310.18814v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18814
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#22312;&#24179;&#26041;&#21709;&#24212;&#65288;$Y^2$&#65289;&#27809;&#26377;&#37325;&#23614;&#30340;&#28201;&#21644;&#26465;&#20214;&#19979;&#65292;&#38543;&#26426;&#26862;&#26519;&#20855;&#26377;&#31283;&#23450;&#24615;&#12290;&#21033;&#29992;&#31283;&#23450;&#24615;&#23646;&#24615;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#38543;&#26426;&#26862;&#26519;&#30340;&#39044;&#27979;&#21306;&#38388;&#30340;&#35206;&#30422;&#27010;&#29575;&#30340;&#38750;&#28176;&#36817;&#19979;&#30028;&#65292;&#24182;&#35752;&#35770;&#20102;&#27604;&#20197;&#21069;&#32771;&#34385;&#30340;&#26465;&#20214;&#26356;&#24369;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#24179;&#26041;&#21709;&#24212;&#65288;$Y^2$&#65289;&#27809;&#26377;&#37325;&#23614;&#30340;&#28201;&#21644;&#26465;&#20214;&#19979;&#65292;&#30830;&#31435;&#20102;&#38543;&#26426;&#26862;&#26519;&#30340;&#31283;&#23450;&#24615;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#36866;&#29992;&#20110;&#22312;&#27969;&#34892;&#36719;&#20214;&#21253;&#65288;&#22914;R&#20013;&#30340;randomForest&#65289;&#20013;&#23454;&#29616;&#30340;&#23454;&#38469;&#29256;&#26412;&#30340;&#38543;&#26426;&#26862;&#26519;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#31283;&#23450;&#24615;&#21487;&#33021;&#20250;&#36229;&#20986;&#25105;&#20204;&#30340;&#20551;&#35774;&#65292;&#24182;&#23545;&#37325;&#23614;&#30340;$Y^2$&#26377;&#25928;&#12290;&#21033;&#29992;&#31283;&#23450;&#24615;&#23646;&#24615;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#38543;&#26426;&#26862;&#26519;&#30340;out-of-bag&#35823;&#24046;&#26500;&#24314;&#30340;&#39044;&#27979;&#21306;&#38388;&#30340;&#35206;&#30422;&#27010;&#29575;&#30340;&#38750;&#28176;&#36817;&#19979;&#30028;&#12290;&#22312;$Y$&#36830;&#32493;&#26102;&#36890;&#24120;&#28385;&#36275;&#30340;&#20854;&#20182;&#28201;&#21644;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#36824;&#24314;&#31435;&#20102;&#19968;&#20010;&#34917;&#20805;&#30340;&#19978;&#30028;&#65292;&#36825;&#20010;&#19978;&#30028;&#20063;&#21487;&#20197;&#31867;&#20284;&#22320;&#24314;&#31435;&#22312;&#20219;&#24847;&#31283;&#23450;&#31639;&#27861;&#26500;&#24314;&#30340;jackknife&#39044;&#27979;&#21306;&#38388;&#19978;&#12290;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#22312;&#27604;&#20197;&#21069;&#25991;&#29486;&#32771;&#34385;&#30340;&#26465;&#20214;&#26356;&#24369;&#30340;&#20551;&#35774;&#19979;&#30340;&#28176;&#36817;&#35206;&#30422;&#27010;&#29575;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#34920;&#26126;&#65292;&#38543;&#26426;&#26862;&#26519;&#22312;&#31283;&#23450;&#24615;&#21644;&#35206;&#30422;&#29575;&#26041;&#38754;&#26159;&#26377;&#25928;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We establish stability of random forests under the mild condition that the squared response ($Y^2$) does not have a heavy tail. In particular, our analysis holds for the practical version of random forests that is implemented in popular packages like \texttt{randomForest} in \texttt{R}. Empirical results show that stability may persist even beyond our assumption and hold for heavy-tailed $Y^2$. Using the stability property, we prove a non-asymptotic lower bound for the coverage probability of prediction intervals constructed from the out-of-bag error of random forests. With another mild condition that is typically satisfied when $Y$ is continuous, we also establish a complementary upper bound, which can be similarly established for the jackknife prediction interval constructed from an arbitrary stable algorithm. We also discuss the asymptotic coverage probability under assumptions weaker than those considered in previous literature. Our work implies that random forests, with its stabil
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#19968;&#31867;&#38750;&#32447;&#24615;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#30340;&#39640;&#27010;&#29575;&#25910;&#25947;&#36793;&#30028;&#12290;&#23545;&#20110;&#20855;&#26377;Lipschitz&#36830;&#32493;&#26799;&#24230;&#30340;&#24378;&#20984;&#25439;&#22833;&#20989;&#25968;&#65292;&#21363;&#20351;&#22122;&#22768;&#26159;&#37325;&#23614;&#30340;&#65292;&#32467;&#26524;&#35777;&#26126;&#20102;&#23545;&#22833;&#36133;&#27010;&#29575;&#30340;&#23545;&#25968;&#20381;&#36182;&#12290;&#36825;&#20123;&#32467;&#26524;&#36866;&#29992;&#20110;&#21098;&#20999;&#12289;&#24402;&#19968;&#21270;&#21644;&#37327;&#21270;&#31561;&#20219;&#20309;&#20855;&#26377;&#26377;&#30028;&#36755;&#20986;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2310.18784</link><description>&lt;p&gt;
&#39640;&#27010;&#29575;&#25910;&#25947;&#36793;&#30028;&#19979;&#30340;&#38750;&#32447;&#24615;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#22312;&#37325;&#23614;&#22122;&#22768;&#19979;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
High-probability Convergence Bounds for Nonlinear Stochastic Gradient Descent Under Heavy-tailed Noise. (arXiv:2310.18784v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18784
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#19968;&#31867;&#38750;&#32447;&#24615;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#30340;&#39640;&#27010;&#29575;&#25910;&#25947;&#36793;&#30028;&#12290;&#23545;&#20110;&#20855;&#26377;Lipschitz&#36830;&#32493;&#26799;&#24230;&#30340;&#24378;&#20984;&#25439;&#22833;&#20989;&#25968;&#65292;&#21363;&#20351;&#22122;&#22768;&#26159;&#37325;&#23614;&#30340;&#65292;&#32467;&#26524;&#35777;&#26126;&#20102;&#23545;&#22833;&#36133;&#27010;&#29575;&#30340;&#23545;&#25968;&#20381;&#36182;&#12290;&#36825;&#20123;&#32467;&#26524;&#36866;&#29992;&#20110;&#21098;&#20999;&#12289;&#24402;&#19968;&#21270;&#21644;&#37327;&#21270;&#31561;&#20219;&#20309;&#20855;&#26377;&#26377;&#30028;&#36755;&#20986;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#20960;&#20010;&#30740;&#31350;&#24037;&#20316;&#30740;&#31350;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#21450;&#20854;&#21098;&#20999;&#21464;&#20307;&#30340;&#39640;&#27010;&#29575;&#25910;&#25947;&#12290;&#19982;&#26222;&#36890;&#30340;SGD&#30456;&#27604;&#65292;&#21098;&#20999;SGD&#22312;&#23454;&#38469;&#20013;&#26356;&#21152;&#31283;&#23450;&#65292;&#24182;&#19988;&#22312;&#29702;&#35770;&#19978;&#26377;&#23545;&#25968;&#20381;&#36182;&#20110;&#22833;&#36133;&#27010;&#29575;&#30340;&#39069;&#22806;&#22909;&#22788;&#12290;&#28982;&#32780;&#65292;&#20854;&#20182;&#23454;&#38469;&#38750;&#32447;&#24615;SGD&#21464;&#20307;&#65288;&#22914;&#31526;&#21495;SGD&#12289;&#37327;&#21270;SGD&#21644;&#24402;&#19968;&#21270;SGD&#65289;&#30340;&#25910;&#25947;&#24615;&#29702;&#35299;&#35201;&#23569;&#24471;&#22810;&#65292;&#36825;&#20123;&#26041;&#27861;&#23454;&#29616;&#20102;&#25913;&#36827;&#30340;&#36890;&#20449;&#25928;&#29575;&#25110;&#21152;&#36895;&#25910;&#25947;&#12290;&#22312;&#26412;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31867;&#24191;&#20041;&#38750;&#32447;&#24615;SGD&#26041;&#27861;&#30340;&#39640;&#27010;&#29575;&#25910;&#25947;&#36793;&#30028;&#12290;&#23545;&#20110;&#20855;&#26377;Lipschitz&#36830;&#32493;&#26799;&#24230;&#30340;&#24378;&#20984;&#25439;&#22833;&#20989;&#25968;&#65292;&#21363;&#20351;&#22122;&#22768;&#26159;&#37325;&#23614;&#30340;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#22833;&#36133;&#27010;&#29575;&#30340;&#23545;&#25968;&#20381;&#36182;&#12290;&#19982;&#21098;&#20999;SGD&#30340;&#32467;&#26524;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#26356;&#20026;&#19968;&#33324;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#26377;&#30028;&#36755;&#20986;&#30340;&#20219;&#20309;&#38750;&#32447;&#24615;&#20989;&#25968;&#65292;&#22914;&#21098;&#20999;&#12289;&#24402;&#19968;&#21270;&#21644;&#37327;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Several recent works have studied the convergence \textit{in high probability} of stochastic gradient descent (SGD) and its clipped variant. Compared to vanilla SGD, clipped SGD is practically more stable and has the additional theoretical benefit of logarithmic dependence on the failure probability. However, the convergence of other practical nonlinear variants of SGD, e.g., sign SGD, quantized SGD and normalized SGD, that achieve improved communication efficiency or accelerated convergence is much less understood. In this work, we study the convergence bounds \textit{in high probability} of a broad class of nonlinear SGD methods. For strongly convex loss functions with Lipschitz continuous gradients, we prove a logarithmic dependence on the failure probability, even when the noise is heavy-tailed. Strictly more general than the results for clipped SGD, our results hold for any nonlinearity with bounded (component-wise or joint) outputs, such as clipping, normalization, and quantizati
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#38750;&#20984;&#38543;&#26426;&#26799;&#24230;&#24773;&#20917;&#19979;&#26410;&#35843;&#25972;&#30340;&#24191;&#20041;&#21704;&#23494;&#23572;&#39039;&#33945;&#29305;&#21345;&#32599;&#20013;&#30340;&#21453;&#23556;&#32806;&#21512;&#65292;&#35777;&#26126;&#20102;Wasserstein 1&#36317;&#31163;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#23450;&#37327;&#39640;&#26031;&#38598;&#20013;&#30028;&#38480;&#65292;&#21516;&#26102;&#36824;&#32473;&#20986;&#20102;Wasserstein 2&#36317;&#31163;&#12289;&#24635;&#21464;&#24046;&#21644;&#30456;&#23545;&#29109;&#30340;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.18774</link><description>&lt;p&gt;
&#38750;&#20984;&#38543;&#26426;&#26799;&#24230;&#24773;&#20917;&#19979;&#26410;&#35843;&#25972;&#30340;&#24191;&#20041;&#21704;&#23494;&#23572;&#39039;&#33945;&#29305;&#21345;&#32599;&#20013;&#30340;&#21453;&#23556;&#32806;&#21512;
&lt;/p&gt;
&lt;p&gt;
Reflection coupling for unadjusted generalized Hamiltonian Monte Carlo in the nonconvex stochastic gradient case. (arXiv:2310.18774v1 [math.PR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18774
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#38750;&#20984;&#38543;&#26426;&#26799;&#24230;&#24773;&#20917;&#19979;&#26410;&#35843;&#25972;&#30340;&#24191;&#20041;&#21704;&#23494;&#23572;&#39039;&#33945;&#29305;&#21345;&#32599;&#20013;&#30340;&#21453;&#23556;&#32806;&#21512;&#65292;&#35777;&#26126;&#20102;Wasserstein 1&#36317;&#31163;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#23450;&#37327;&#39640;&#26031;&#38598;&#20013;&#30028;&#38480;&#65292;&#21516;&#26102;&#36824;&#32473;&#20986;&#20102;Wasserstein 2&#36317;&#31163;&#12289;&#24635;&#21464;&#24046;&#21644;&#30456;&#23545;&#29109;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21487;&#33021;&#38750;&#20984;&#30340;&#26465;&#20214;&#19979;&#65292;&#24314;&#31435;&#20102;&#20855;&#26377;&#38543;&#26426;&#26799;&#24230;&#30340;&#24191;&#20041;&#21704;&#23494;&#23572;&#39039;&#33945;&#29305;&#21345;&#32599;&#30340;Wasserstein 1&#36317;&#31163;&#30340;&#25910;&#25947;&#24615;&#65292;&#20854;&#20013;&#21253;&#25324;&#21160;&#21147;&#23398;Langevin&#25193;&#25955;&#30340;&#20998;&#35010;&#26041;&#26696;&#31639;&#27861;&#12290;&#20316;&#20026;&#32467;&#26524;&#65292;&#25552;&#20379;&#20102;&#32463;&#39564;&#24179;&#22343;&#20540;&#30340;&#23450;&#37327;&#39640;&#26031;&#38598;&#20013;&#30028;&#38480;&#12290;&#27492;&#22806;&#65292;&#36824;&#32473;&#20986;&#20102;Wasserstein 2&#36317;&#31163;&#12289;&#24635;&#21464;&#24046;&#21644;&#30456;&#23545;&#29109;&#30340;&#25910;&#25947;&#24615;&#65292;&#20197;&#21450;&#25968;&#20540;&#20559;&#24046;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Contraction in Wasserstein 1-distance with explicit rates is established for generalized Hamiltonian Monte Carlo with stochastic gradients under possibly nonconvex conditions. The algorithms considered include splitting schemes of kinetic Langevin diffusion. As consequence, quantitative Gaussian concentration bounds are provided for empirical averages. Convergence in Wasserstein 2-distance, total variation and relative entropy are also given, together with numerical bias estimates.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#31639;&#27861;&#29992;&#20110;&#20998;&#31867;&#25968;&#25454;&#30340;&#28508;&#22312;&#31867;&#21035;&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;&#26032;&#23450;&#20041;&#30340;&#27491;&#21017;&#21270;&#25289;&#26222;&#25289;&#26031;&#30697;&#38453;&#35745;&#31639;&#28508;&#22312;&#31867;&#21035;&#20998;&#26512;&#65292;&#32467;&#26524;&#34920;&#26126;&#31639;&#27861;&#20855;&#26377;&#29702;&#35770;&#25910;&#25947;&#36895;&#24230;&#21644;&#31283;&#23450;&#30340;&#19968;&#33268;&#24615;&#12290;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#20010;&#34913;&#37327;&#28508;&#22312;&#31867;&#21035;&#20998;&#26512;&#24378;&#24230;&#30340;&#24230;&#37327;&#26631;&#20934;&#21450;&#30456;&#20851;&#31243;&#24207;&#65292;&#36890;&#36807;&#27169;&#25311;&#23454;&#39564;&#39564;&#35777;&#20102;&#31639;&#27861;&#30340;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#65292;&#24182;&#24212;&#29992;&#20110;&#23454;&#38469;&#20998;&#31867;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2310.18727</link><description>&lt;p&gt;
&#36890;&#36807;&#27491;&#21017;&#21270;&#35889;&#32858;&#31867;&#36827;&#34892;&#28508;&#22312;&#31867;&#21035;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Latent class analysis by regularized spectral clustering. (arXiv:2310.18727v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18727
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#31639;&#27861;&#29992;&#20110;&#20998;&#31867;&#25968;&#25454;&#30340;&#28508;&#22312;&#31867;&#21035;&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;&#26032;&#23450;&#20041;&#30340;&#27491;&#21017;&#21270;&#25289;&#26222;&#25289;&#26031;&#30697;&#38453;&#35745;&#31639;&#28508;&#22312;&#31867;&#21035;&#20998;&#26512;&#65292;&#32467;&#26524;&#34920;&#26126;&#31639;&#27861;&#20855;&#26377;&#29702;&#35770;&#25910;&#25947;&#36895;&#24230;&#21644;&#31283;&#23450;&#30340;&#19968;&#33268;&#24615;&#12290;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#20010;&#34913;&#37327;&#28508;&#22312;&#31867;&#21035;&#20998;&#26512;&#24378;&#24230;&#30340;&#24230;&#37327;&#26631;&#20934;&#21450;&#30456;&#20851;&#31243;&#24207;&#65292;&#36890;&#36807;&#27169;&#25311;&#23454;&#39564;&#39564;&#35777;&#20102;&#31639;&#27861;&#30340;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#65292;&#24182;&#24212;&#29992;&#20110;&#23454;&#38469;&#20998;&#31867;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28508;&#22312;&#31867;&#21035;&#27169;&#22411;&#26159;&#22312;&#31038;&#20250;&#12289;&#24515;&#29702;&#21644;&#34892;&#20026;&#31185;&#23398;&#39046;&#22495;&#35782;&#21035;&#20855;&#26377;&#20849;&#21516;&#29305;&#24449;&#30340;&#28508;&#22312;&#31867;&#21035;&#30340;&#24378;&#22823;&#24037;&#20855;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#31639;&#27861;&#26469;&#20272;&#35745;&#29992;&#20110;&#20998;&#31867;&#25968;&#25454;&#30340;&#28508;&#22312;&#31867;&#21035;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#21033;&#29992;&#21709;&#24212;&#30697;&#38453;&#35745;&#31639;&#20986;&#30340;&#26032;&#23450;&#20041;&#30340;&#27491;&#21017;&#21270;&#25289;&#26222;&#25289;&#26031;&#30697;&#38453;&#36827;&#34892;&#24320;&#21457;&#12290;&#25105;&#20204;&#36890;&#36807;&#32771;&#34385;&#31232;&#30095;&#21442;&#25968;&#32473;&#20986;&#20102;&#31639;&#27861;&#30340;&#29702;&#35770;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#34920;&#26126;&#22312;&#36866;&#24230;&#26465;&#20214;&#19979;&#25105;&#20204;&#30340;&#31639;&#27861;&#31283;&#23450;&#22320;&#20135;&#29983;&#19968;&#33268;&#30340;&#28508;&#22312;&#31867;&#21035;&#20998;&#26512;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#34913;&#37327;&#28508;&#22312;&#31867;&#21035;&#20998;&#26512;&#24378;&#24230;&#30340;&#24230;&#37327;&#26631;&#20934;&#65292;&#24182;&#22522;&#20110;&#35813;&#24230;&#37327;&#26631;&#20934;&#35774;&#35745;&#20102;&#20960;&#20010;&#25512;&#26029;&#22312;&#23454;&#38469;&#20998;&#31867;&#25968;&#25454;&#20013;&#24212;&#35813;&#20351;&#29992;&#22810;&#23569;&#28508;&#22312;&#31867;&#21035;&#30340;&#31243;&#24207;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#27169;&#25311;&#23454;&#39564;&#39564;&#35777;&#20102;&#25105;&#20204;&#31639;&#27861;&#30340;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#65292;&#21516;&#26102;&#23558;&#25105;&#20204;&#30340;&#31639;&#27861;&#36827;&#19968;&#27493;&#24212;&#29992;&#20110;&#23454;&#38469;&#20998;&#31867;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
The latent class model is a powerful tool for identifying latent classes within populations that share common characteristics for categorical data in social, psychological, and behavioral sciences. In this article, we propose two new algorithms to estimate a latent class model for categorical data. Our algorithms are developed by using a newly defined regularized Laplacian matrix calculated from the response matrix. We provide theoretical convergence rates of our algorithms by considering a sparsity parameter and show that our algorithms stably yield consistent latent class analysis under mild conditions. Additionally, we propose a metric to capture the strength of latent class analysis and several procedures designed based on this metric to infer how many latent classes one should use for real-world categorical data. The efficiency and accuracy of our algorithms are verified by extensive simulated experiments, and we further apply our algorithms to real-world categorical data with pro
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#38543;&#26426;&#24352;&#37327;&#29702;&#35770;&#30740;&#31350;&#20102;Hotelling&#22411;&#38750;&#23545;&#31216;&#24352;&#37327;&#38500;&#27861;&#22312;&#22823;&#32500;&#24352;&#37327;&#19979;&#30340;&#20934;&#30830;&#24615;&#65292;&#23545;&#38500;&#27861;&#36807;&#31243;&#20013;&#30340;&#22855;&#24322;&#20540;&#21644;&#22855;&#24322;&#21521;&#37327;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#21487;&#20197;&#29992;&#20110;&#26500;&#36896;&#20449;&#22122;&#27604;&#21644;&#25490;&#21015;&#30340;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2310.18717</link><description>&lt;p&gt;
&#20851;&#20110;Hotelling&#22411;&#38750;&#23545;&#31216;&#24352;&#37327;&#38500;&#27861;&#30340;&#20934;&#30830;&#24615;&#65306;&#38543;&#26426;&#24352;&#37327;&#20998;&#26512;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Accuracy of Hotelling-Type Asymmetric Tensor Deflation: A Random Tensor Analysis. (arXiv:2310.18717v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18717
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#38543;&#26426;&#24352;&#37327;&#29702;&#35770;&#30740;&#31350;&#20102;Hotelling&#22411;&#38750;&#23545;&#31216;&#24352;&#37327;&#38500;&#27861;&#22312;&#22823;&#32500;&#24352;&#37327;&#19979;&#30340;&#20934;&#30830;&#24615;&#65292;&#23545;&#38500;&#27861;&#36807;&#31243;&#20013;&#30340;&#22855;&#24322;&#20540;&#21644;&#22855;&#24322;&#21521;&#37327;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#21487;&#20197;&#29992;&#20110;&#26500;&#36896;&#20449;&#22122;&#27604;&#21644;&#25490;&#21015;&#30340;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#22823;&#32500;&#24352;&#37327;&#30340;&#24773;&#20917;&#19979;&#65292;&#20171;&#32461;&#20102;&#22312;&#22122;&#22768;&#23384;&#22312;&#26102;Hotelling&#22411;&#24352;&#37327;&#38500;&#27861;&#30340;&#28176;&#36817;&#30740;&#31350;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#20302;&#31209;&#38750;&#23545;&#31216;&#24352;&#37327;&#27169;&#22411;&#65292;&#24418;&#24335;&#20026;$\sum_{i=1}^r \beta_i{\mathcal{A}}_i + {\mathcal{W}}$&#65292;&#20854;&#20013;$\beta_i\geq 0$&#65292;${\mathcal{A}}_i$&#26159;&#21333;&#20301;&#33539;&#25968;&#31209;&#19968;&#24352;&#37327;&#65292;&#28385;&#36275;&#23545;&#20110;$i\neq j$&#65292;$\left| \langle {\mathcal{A}}_i, {\mathcal{A}}_j \rangle \right| \in [0, 1]$&#65292;${\mathcal{W}}$&#26159;&#19968;&#20010;&#38468;&#21152;&#30340;&#22122;&#22768;&#39033;&#12290;&#20551;&#35774;&#20027;&#23548;&#30340;&#20998;&#37327;&#20174;&#22122;&#22768;&#35266;&#27979;&#20013;&#36880;&#27493;&#20272;&#35745;&#24182;&#36880;&#27493;&#20943;&#21435;&#65292;&#25105;&#20204;&#21033;&#29992;&#26368;&#36817;&#22312;&#28176;&#36817;&#22823;&#32500;&#24352;&#37327;&#30340;&#38543;&#26426;&#24352;&#37327;&#29702;&#35770;&#26041;&#38754;&#30340;&#36827;&#23637;&#65292;&#23545;&#20110;&#38500;&#27861;&#36807;&#31243;&#20013;&#27599;&#19968;&#27493;&#30340;&#20272;&#35745;&#22855;&#24322;&#20540;&#21644;&#20272;&#35745;&#30340;&#30495;&#23454;&#22855;&#24322;&#21521;&#37327;&#30340;&#25490;&#21015;&#36827;&#34892;&#20102;&#35299;&#26512;&#34920;&#24449;&#12290;&#27492;&#22806;&#65292;&#35813;&#32467;&#26524;&#21487;&#29992;&#20110;&#26500;&#36896;&#20449;&#22122;&#27604;$\beta_i$&#30340;&#20272;&#35745;&#22120;&#20197;&#21450;&#25490;&#21015;&#30340;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work introduces an asymptotic study of Hotelling-type tensor deflation in the presence of noise, in the regime of large tensor dimensions. Specifically, we consider a low-rank asymmetric tensor model of the form $\sum_{i=1}^r \beta_i{\mathcal{A}}_i + {\mathcal{W}}$ where $\beta_i\geq 0$ and the ${\mathcal{A}}_i$'s are unit-norm rank-one tensors such that $\left| \langle {\mathcal{A}}_i, {\mathcal{A}}_j \rangle \right| \in [0, 1]$ for $i\neq j$ and ${\mathcal{W}}$ is an additive noise term. Assuming that the dominant components are successively estimated from the noisy observation and subsequently subtracted, we leverage recent advances in random tensor theory in the regime of asymptotically large tensor dimensions to analytically characterize the estimated singular values and the alignment of estimated and true singular vectors at each step of the deflation procedure. Furthermore, this result can be used to construct estimators of the signal-to-noise ratios $\beta_i$ and the align
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#30340;ROAM&#21644;ROOM&#31639;&#27861;&#26694;&#26550;&#36890;&#36807;&#23558;&#20013;&#20301;&#25968;&#27861;&#19982;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#30456;&#32467;&#21512;&#65292;&#25552;&#20379;&#20102;&#23545;&#37325;&#23614;&#22870;&#21169;&#30340;&#30452;&#25509;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#20174;&#32780;&#22686;&#24378;&#20102;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#22312;&#29616;&#23454;&#24212;&#29992;&#20013;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.18715</link><description>&lt;p&gt;
&#20855;&#26377;&#37325;&#23614;&#22870;&#21169;&#30340;&#24378;&#21270;&#23398;&#20064;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#21644;&#20248;&#21270;&#30340;&#40065;&#26834;&#24615;&#25552;&#21319;
&lt;/p&gt;
&lt;p&gt;
Robust Offline Policy Evaluation and Optimization with Heavy-Tailed Rewards. (arXiv:2310.18715v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18715
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#30340;ROAM&#21644;ROOM&#31639;&#27861;&#26694;&#26550;&#36890;&#36807;&#23558;&#20013;&#20301;&#25968;&#27861;&#19982;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#30456;&#32467;&#21512;&#65292;&#25552;&#20379;&#20102;&#23545;&#37325;&#23614;&#22870;&#21169;&#30340;&#30452;&#25509;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#20174;&#32780;&#22686;&#24378;&#20102;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#22312;&#29616;&#23454;&#24212;&#29992;&#20013;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#22686;&#24378;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#22312;&#29616;&#23454;&#19990;&#30028;&#24212;&#29992;&#20013;&#26222;&#36941;&#23384;&#22312;&#30340;&#37325;&#23614;&#22870;&#21169;&#24773;&#20917;&#19979;&#30340;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#20010;&#31639;&#27861;&#26694;&#26550;&#65292;ROAM&#21644;ROOM&#65292;&#29992;&#20110;&#40065;&#26834;&#30340;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#21644;&#31163;&#32447;&#31574;&#30053;&#20248;&#21270;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#30340;&#26680;&#24515;&#26159;&#23558;&#20013;&#20301;&#25968;&#27861;&#19982;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#30456;&#32467;&#21512;&#65292;&#33021;&#22815;&#23545;&#20540;&#20989;&#25968;&#20272;&#35745;&#22120;&#36827;&#34892;&#30452;&#25509;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#36825;&#19981;&#20165;&#31526;&#21512;&#31163;&#32447;&#31574;&#30053;&#20248;&#21270;&#20013;&#30340;&#20445;&#23432;&#20027;&#20041;&#21407;&#21017;&#65292;&#32780;&#19988;&#28789;&#27963;&#22788;&#29702;&#37325;&#23614;&#22870;&#21169;&#12290;&#29702;&#35770;&#32467;&#26524;&#21644;&#24191;&#27867;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#20004;&#20010;&#26694;&#26550;&#22312;&#35760;&#24405;&#30340;&#25968;&#25454;&#38598;&#20013;&#23637;&#31034;&#20102;&#20855;&#26377;&#37325;&#23614;&#22870;&#21169;&#20998;&#24067;&#26102;&#36229;&#36234;&#29616;&#26377;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper endeavors to augment the robustness of offline reinforcement learning (RL) in scenarios laden with heavy-tailed rewards, a prevalent circumstance in real-world applications. We propose two algorithmic frameworks, ROAM and ROOM, for robust off-policy evaluation (OPE) and offline policy optimization (OPO), respectively. Central to our frameworks is the strategic incorporation of the median-of-means method with offline RL, enabling straightforward uncertainty estimation for the value function estimator. This not only adheres to the principle of pessimism in OPO but also adeptly manages heavy-tailed rewards. Theoretical results and extensive experiments demonstrate that our two frameworks outperform existing methods on the logged dataset exhibits heavy-tailed reward distributions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#24037;&#19994;&#23376;&#31995;&#32479;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#21644;&#30001;&#19987;&#23478;&#30693;&#35782;&#26500;&#24314;&#30340;&#22240;&#26524;&#22270;&#65292;&#20026;&#22797;&#26434;&#31995;&#32479;&#30340;&#22240;&#26524;&#20851;&#31995;&#21457;&#29616;&#26041;&#27861;&#30340;&#21457;&#23637;&#25552;&#20379;&#20102;&#19968;&#20010;&#27979;&#35797;&#24179;&#21488;&#12290;</title><link>http://arxiv.org/abs/2310.18654</link><description>&lt;p&gt;
&#22797;&#26434;&#24037;&#19994;&#31995;&#32479;&#20013;&#30340;&#22240;&#26524;&#20851;&#31995;&#21457;&#29616;&#65306;&#19968;&#20010;&#26102;&#38388;&#24207;&#21015;&#22522;&#20934;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Causal discovery in a complex industrial system: A time series benchmark. (arXiv:2310.18654v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18654
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#24037;&#19994;&#23376;&#31995;&#32479;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#21644;&#30001;&#19987;&#23478;&#30693;&#35782;&#26500;&#24314;&#30340;&#22240;&#26524;&#22270;&#65292;&#20026;&#22797;&#26434;&#31995;&#32479;&#30340;&#22240;&#26524;&#20851;&#31995;&#21457;&#29616;&#26041;&#27861;&#30340;&#21457;&#23637;&#25552;&#20379;&#20102;&#19968;&#20010;&#27979;&#35797;&#24179;&#21488;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#20851;&#31995;&#21457;&#29616;&#36890;&#36807;&#35266;&#27979;&#25968;&#25454;&#36755;&#20986;&#19968;&#20010;&#30001;&#22270;&#24418;&#34920;&#31034;&#30340;&#22240;&#26524;&#32467;&#26500;&#12290;&#38024;&#23545;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65292;&#23384;&#22312;&#21508;&#31181;&#26041;&#27861;&#65292;&#28982;&#32780;&#65292;&#35780;&#20272;&#36825;&#20123;&#26041;&#27861;&#22312;&#30495;&#23454;&#25968;&#25454;&#19978;&#24456;&#22256;&#38590;&#65292;&#22240;&#20026;&#29616;&#23454;&#24212;&#29992;&#22330;&#26223;&#24456;&#23569;&#20250;&#26377;&#19968;&#20010;&#24050;&#30693;&#30340;&#22240;&#26524;&#22270;&#26469;&#36827;&#34892;&#27604;&#36739;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#26469;&#33258;&#27431;&#27954;&#25955;&#35010;&#28304;&#30340;&#19968;&#20010;&#24037;&#19994;&#23376;&#31995;&#32479;&#30340;&#25968;&#25454;&#38598;&#20197;&#21450;&#30001;&#19987;&#23478;&#30693;&#35782;&#26500;&#24314;&#30340;&#22240;&#26524;&#22270;&#12290;&#36825;&#20026;&#20174;&#22797;&#26434;&#31995;&#32479;&#30340;&#26102;&#38388;&#24207;&#21015;&#35266;&#27979;&#20013;&#36827;&#34892;&#22240;&#26524;&#20851;&#31995;&#21457;&#29616;&#25552;&#20379;&#20102;&#19968;&#20010;&#27979;&#35797;&#24179;&#21488;&#65292;&#25105;&#20204;&#30456;&#20449;&#36825;&#21487;&#20197;&#24110;&#21161;&#25512;&#21160;&#22240;&#26524;&#20851;&#31995;&#21457;&#29616;&#26041;&#27861;&#30340;&#21457;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal discovery outputs a causal structure, represented by a graph, from observed data. For time series data, there is a variety of methods, however, it is difficult to evaluate these on real data as realistic use cases very rarely come with a known causal graph to which output can be compared. In this paper, we present a dataset from an industrial subsystem at the European Spallation Source along with its causal graph which has been constructed from expert knowledge. This provides a testbed for causal discovery from time series observations of complex systems, and we believe this can help inform the development of causal discovery methodology.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24754;&#35266;&#30340;&#20272;&#35745;&#22120;&#65292;&#29992;&#20110;&#35745;&#31639;&#31163;&#32447;&#22810;&#30446;&#26631;&#20248;&#21270;&#20013;&#30340;&#31574;&#30053;&#20540;&#65292;&#24182;&#36890;&#36807;&#31574;&#30053;&#26799;&#24230;&#36827;&#34892;&#20248;&#21270;&#12290;&#35813;&#20272;&#35745;&#22120;&#22522;&#20110;&#21453;&#21521;&#20542;&#21521;&#24615;&#20998;&#25968;&#65288;IPS&#65289;&#65292;&#22312;&#29702;&#35770;&#21644;&#23454;&#39564;&#20013;&#22343;&#34920;&#29616;&#20986;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.18617</link><description>&lt;p&gt;
&#24754;&#35266;&#30340;&#31163;&#32447;&#22810;&#30446;&#26631;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Pessimistic Off-Policy Multi-Objective Optimization. (arXiv:2310.18617v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18617
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24754;&#35266;&#30340;&#20272;&#35745;&#22120;&#65292;&#29992;&#20110;&#35745;&#31639;&#31163;&#32447;&#22810;&#30446;&#26631;&#20248;&#21270;&#20013;&#30340;&#31574;&#30053;&#20540;&#65292;&#24182;&#36890;&#36807;&#31574;&#30053;&#26799;&#24230;&#36827;&#34892;&#20248;&#21270;&#12290;&#35813;&#20272;&#35745;&#22120;&#22522;&#20110;&#21453;&#21521;&#20542;&#21521;&#24615;&#20998;&#25968;&#65288;IPS&#65289;&#65292;&#22312;&#29702;&#35770;&#21644;&#23454;&#39564;&#20013;&#22343;&#34920;&#29616;&#20986;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#30446;&#26631;&#20248;&#21270;&#26159;&#19968;&#31867;&#20915;&#31574;&#38382;&#39064;&#65292;&#20854;&#20013;&#23545;&#22810;&#20010;&#30456;&#20114;&#20914;&#31361;&#30340;&#30446;&#26631;&#36827;&#34892;&#20248;&#21270;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#20174;&#29616;&#26377;&#31574;&#30053;&#25910;&#38598;&#30340;&#25968;&#25454;&#20013;&#36827;&#34892;&#31163;&#32447;&#20248;&#21270;&#30340;&#22810;&#30446;&#26631;&#31574;&#30053;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24754;&#35266;&#30340;&#20272;&#35745;&#22120;&#65292;&#29992;&#20110;&#35745;&#31639;&#22810;&#30446;&#26631;&#31574;&#30053;&#20540;&#65292;&#24182;&#21487;&#20197;&#36731;&#26494;&#22320;&#25554;&#20837;&#21040;&#29616;&#26377;&#30340;&#36229;&#20307;&#31215;&#35745;&#31639;&#21644;&#20248;&#21270;&#20844;&#24335;&#20013;&#12290;&#35813;&#20272;&#35745;&#22120;&#22522;&#20110;&#21453;&#21521;&#20542;&#21521;&#24615;&#20998;&#25968;&#65288;IPS&#65289;&#65292;&#22312;&#29702;&#35770;&#21644;&#23454;&#39564;&#20013;&#22343;&#25913;&#36827;&#20102;&#26420;&#32032;&#30340;IPS&#20272;&#35745;&#22120;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#26159;&#19968;&#33324;&#30340;&#65292;&#36866;&#29992;&#20110;&#36229;&#20986;IPS&#20272;&#35745;&#22120;&#21644;&#20248;&#21270;&#26041;&#27861;&#30340;&#33539;&#22260;&#12290;&#24754;&#35266;&#30340;&#20272;&#35745;&#22120;&#21487;&#20197;&#36890;&#36807;&#31574;&#30053;&#26799;&#24230;&#36827;&#34892;&#20248;&#21270;&#65292;&#24182;&#22312;&#25105;&#20204;&#30340;&#25152;&#26377;&#23454;&#39564;&#20013;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-objective optimization is a type of decision making problems where multiple conflicting objectives are optimized. We study offline optimization of multi-objective policies from data collected by an existing policy. We propose a pessimistic estimator for the multi-objective policy values that can be easily plugged into existing formulas for hypervolume computation and optimized. The estimator is based on inverse propensity scores (IPS), and improves upon a naive IPS estimator in both theory and experiments. Our analysis is general, and applies beyond our IPS estimators and methods for optimizing them. The pessimistic estimator can be optimized by policy gradients and performs well in all of our experiments.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22312;&#38750;&#24179;&#31283;&#24773;&#20917;&#19979;&#65292;&#25506;&#32034;&#20102;&#26102;&#38388;&#35299;&#32544;&#34920;&#31034;&#23398;&#20064;&#30340;&#39532;&#23572;&#21487;&#22827;&#20551;&#35774;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#36741;&#21161;&#21464;&#37327;&#35266;&#27979;&#30340;&#26041;&#27861;&#26469;&#24674;&#22797;&#29420;&#31435;&#30340;&#28508;&#22312;&#20998;&#37327;&#12290;</title><link>http://arxiv.org/abs/2310.18615</link><description>&lt;p&gt;
&#26410;&#30693;&#38750;&#24179;&#31283;&#24773;&#20917;&#19979;&#30340;&#26102;&#38388;&#35299;&#32544;&#34920;&#31034;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Temporally Disentangled Representation Learning under Unknown Nonstationarity. (arXiv:2310.18615v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18615
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22312;&#38750;&#24179;&#31283;&#24773;&#20917;&#19979;&#65292;&#25506;&#32034;&#20102;&#26102;&#38388;&#35299;&#32544;&#34920;&#31034;&#23398;&#20064;&#30340;&#39532;&#23572;&#21487;&#22827;&#20551;&#35774;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#36741;&#21161;&#21464;&#37327;&#35266;&#27979;&#30340;&#26041;&#27861;&#26469;&#24674;&#22797;&#29420;&#31435;&#30340;&#28508;&#22312;&#20998;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20855;&#26377;&#26102;&#24310;&#28508;&#22312;&#22240;&#26524;&#24433;&#21709;&#30340;&#26102;&#24207;&#25968;&#25454;&#30340;&#26080;&#30417;&#30563;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#20013;&#65292;&#36890;&#36807;&#21033;&#29992;&#26102;&#38388;&#32467;&#26500;&#22312;&#31283;&#24577;&#24773;&#20917;&#19979;&#24050;&#32463;&#24314;&#31435;&#20102;&#26377;&#20851;&#22240;&#26524;&#30456;&#20851;&#28508;&#22312;&#21464;&#37327;&#35299;&#32544;&#30340;&#24378;&#21487;&#35782;&#21035;&#24615;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#22312;&#38750;&#24179;&#31283;&#24773;&#20917;&#19979;&#65292;&#29616;&#26377;&#30740;&#31350;&#21482;&#37096;&#20998;&#35299;&#20915;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#35201;&#20040;&#21033;&#29992;&#35266;&#27979;&#21040;&#30340;&#36741;&#21161;&#21464;&#37327;&#65288;&#22914;&#31867;&#21035;&#26631;&#31614;&#21644;/&#25110;&#22495;&#32034;&#24341;&#65289;&#20316;&#20026;&#36741;&#21161;&#20449;&#24687;&#65292;&#35201;&#20040;&#20551;&#35774;&#31616;&#21270;&#30340;&#28508;&#22312;&#22240;&#26524;&#21160;&#21147;&#23398;&#12290;&#36825;&#20004;&#32773;&#38480;&#21046;&#20102;&#26041;&#27861;&#30340;&#36866;&#29992;&#33539;&#22260;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25506;&#32034;&#20102;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#26102;&#38388;&#24310;&#36831;&#30456;&#20851;&#36807;&#31243;&#30340;&#39532;&#23572;&#21487;&#22827;&#20551;&#35774;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#28201;&#21644;&#26465;&#20214;&#19979;&#65292;&#21487;&#20197;&#22312;&#19981;&#35266;&#23519;&#36741;&#21161;&#21464;&#37327;&#30340;&#24773;&#20917;&#19979;&#20174;&#38750;&#32447;&#24615;&#28151;&#21512;&#20013;&#24674;&#22797;&#29420;&#31435;&#30340;&#28508;&#22312;&#20998;&#37327;&#65292;&#20294;&#21487;&#33021;&#23384;&#22312;&#25490;&#21015;&#21644;&#20998;&#37327;&#32423;&#36716;&#25442;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26377;&#21407;&#21017;&#30340;&#20272;&#35745;&#26694;&#26550;NCTRL&#26469;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
In unsupervised causal representation learning for sequential data with time-delayed latent causal influences, strong identifiability results for the disentanglement of causally-related latent variables have been established in stationary settings by leveraging temporal structure. However, in nonstationary setting, existing work only partially addressed the problem by either utilizing observed auxiliary variables (e.g., class labels and/or domain indexes) as side information or assuming simplified latent causal dynamics. Both constrain the method to a limited range of scenarios. In this study, we further explored the Markov Assumption under time-delayed causally related process in nonstationary setting and showed that under mild conditions, the independent latent components can be recovered from their nonlinear mixture up to a permutation and a component-wise transformation, without the observation of auxiliary variables. We then introduce NCTRL, a principled estimation framework, to r
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#20915;&#31574;&#35843;&#35299;&#30340;&#38382;&#39064;&#65292;&#21363;&#23398;&#20064;&#21644;&#35780;&#20272;&#20013;&#20171;&#31574;&#30053;&#26469;&#24179;&#34913;&#19987;&#23478;&#34892;&#20026;&#21644;&#20154;&#31867;&#34892;&#20026;&#65292;&#24182;&#25552;&#20379;&#19968;&#20010;&#39640;&#25928;&#30340;&#25509;&#21475;&#65292;&#20197;&#22788;&#29702;&#20154;&#31867;&#38169;&#35823;&#21644;&#19987;&#23478;&#21453;&#39304;&#12290;</title><link>http://arxiv.org/abs/2310.18601</link><description>&lt;p&gt;
&#22312;&#32447;&#20915;&#31574;&#35843;&#35299;
&lt;/p&gt;
&lt;p&gt;
Online Decision Mediation. (arXiv:2310.18601v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18601
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#20915;&#31574;&#35843;&#35299;&#30340;&#38382;&#39064;&#65292;&#21363;&#23398;&#20064;&#21644;&#35780;&#20272;&#20013;&#20171;&#31574;&#30053;&#26469;&#24179;&#34913;&#19987;&#23478;&#34892;&#20026;&#21644;&#20154;&#31867;&#34892;&#20026;&#65292;&#24182;&#25552;&#20379;&#19968;&#20010;&#39640;&#25928;&#30340;&#25509;&#21475;&#65292;&#20197;&#22788;&#29702;&#20154;&#31867;&#38169;&#35823;&#21644;&#19987;&#23478;&#21453;&#39304;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32771;&#34385;&#23398;&#20064;&#19968;&#20010;&#20915;&#31574;&#25903;&#25345;&#21161;&#25163;&#65292;&#20316;&#20026;(oracle)&#19987;&#23478;&#34892;&#20026;&#21644;(&#19981;&#23436;&#32654;)&#20154;&#31867;&#34892;&#20026;&#20043;&#38388;&#30340;&#20013;&#20171;&#65306;&#27599;&#27425;&#31639;&#27861;&#35266;&#23519;&#21040;&#19968;&#20010;&#30001;&#26131;&#20986;&#38169;&#30340;&#20195;&#29702;&#36873;&#25321;&#30340;&#21160;&#20316;&#65292;&#24182;&#20915;&#23450;&#26159;&#21542;&#25509;&#21463;&#20195;&#29702;&#30340;&#20915;&#31574;&#65292;&#24178;&#39044;&#26367;&#20195;&#65292;&#25110;&#35201;&#27714;&#19987;&#23478;&#30340;&#24847;&#35265;&#12290;&#22312;&#20020;&#24202;&#35786;&#26029;&#20013;&#65292;&#23436;&#20840;&#33258;&#20027;&#30340;&#26426;&#22120;&#34892;&#20026;&#24448;&#24448;&#36229;&#20986;&#20102;&#20262;&#29702;&#19978;&#30340;&#25215;&#21463;&#33539;&#22260;&#65292;&#22240;&#27492;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#20915;&#31574;&#25903;&#25345;&#24448;&#24448;&#21482;&#38480;&#20110;&#30417;&#27979;&#21644;&#39044;&#27979;&#12290;&#30456;&#21453;&#65292;&#36825;&#26679;&#30340;&#20013;&#20171;&#33021;&#22815;&#22312;&#32431;&#25351;&#23548;&#24615;&#26041;&#27861;&#21644;&#32431;&#25551;&#36848;&#24615;&#26041;&#27861;&#20043;&#38388;&#21462;&#24471;&#35880;&#24910;&#30340;&#24179;&#34913;&#65292;&#21516;&#26102;&#25552;&#20379;&#20154;&#31867;&#38169;&#35823;&#21644;&#19987;&#23478;&#21453;&#39304;&#20043;&#38388;&#30340;&#39640;&#25928;&#25509;&#21475;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#24418;&#24335;&#21270;&#20102;&#8220;&#22312;&#32447;&#20915;&#31574;&#35843;&#35299;&#8221;&#30340;&#39034;&#24207;&#38382;&#39064; - &#21363;&#20174;&#22836;&#24320;&#22987;&#21516;&#26102;&#23398;&#20064;&#21644;&#35780;&#20272;&#20013;&#20171;&#31574;&#30053;&#65292;&#20351;&#29992;&#8220;&#32570;&#22833;&#21453;&#39304;&#8221;&#65306;&#22312;&#27599;&#19968;&#36718;&#20013;&#65292;&#36981;&#24490;oracle&#30340;&#24314;&#35758;
&lt;/p&gt;
&lt;p&gt;
Consider learning a decision support assistant to serve as an intermediary between (oracle) expert behavior and (imperfect) human behavior: At each time, the algorithm observes an action chosen by a fallible agent, and decides whether to *accept* that agent's decision, *intervene* with an alternative, or *request* the expert's opinion. For instance, in clinical diagnosis, fully-autonomous machine behavior is often beyond ethical affordances, thus real-world decision support is often limited to monitoring and forecasting. Instead, such an intermediary would strike a prudent balance between the former (purely prescriptive) and latter (purely descriptive) approaches, while providing an efficient interface between human mistakes and expert feedback. In this work, we first formalize the sequential problem of *online decision mediation* -- that is, of simultaneously learning and evaluating mediator policies from scratch with *abstentive feedback*: In each round, deferring to the oracle obvia
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20844;&#24179;&#27969;&#24335;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#31639;&#27861;&#65292;&#24182;&#19988;&#22312;&#29702;&#35770;&#21644;&#23454;&#36341;&#19978;&#35299;&#20915;&#20102;&#20844;&#24179;PCA&#30340;&#20004;&#20010;&#20027;&#35201;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.18593</link><description>&lt;p&gt;
&#20844;&#24179;&#30340;&#27969;&#24335;&#20027;&#25104;&#20998;&#20998;&#26512;&#65306;&#32479;&#35745;&#23398;&#21644;&#31639;&#27861;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Fair Streaming Principal Component Analysis: Statistical and Algorithmic Viewpoint. (arXiv:2310.18593v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18593
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20844;&#24179;&#27969;&#24335;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#31639;&#27861;&#65292;&#24182;&#19988;&#22312;&#29702;&#35770;&#21644;&#23454;&#36341;&#19978;&#35299;&#20915;&#20102;&#20844;&#24179;PCA&#30340;&#20004;&#20010;&#20027;&#35201;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20844;&#24179;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#26159;&#19968;&#20010;&#38382;&#39064;&#35774;&#32622;&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#22312;&#25191;&#34892;PCA&#30340;&#21516;&#26102;&#20351;&#24471;&#24471;&#21040;&#30340;&#34920;&#31034;&#20844;&#24179;&#65292;&#21363;&#22312;&#25935;&#24863;&#23646;&#24615;&#26465;&#20214;&#19979;&#65292;&#25237;&#24433;&#20998;&#24067;&#30456;&#21305;&#37197;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#20844;&#24179;PCA&#26041;&#27861;&#23384;&#22312;&#20004;&#20010;&#20027;&#35201;&#38382;&#39064;&#65306;&#20174;&#29702;&#35770;&#19978;&#35762;&#65292;&#27809;&#26377;&#20197;&#21487;&#23398;&#20064;&#24615;&#20026;&#22522;&#30784;&#30340;&#20844;&#24179;PCA&#32479;&#35745;&#23398;&#20381;&#25454;&#65307;&#20174;&#23454;&#36341;&#19978;&#35762;&#65292;&#26377;&#38480;&#30340;&#20869;&#23384;&#20351;&#24471;&#25105;&#20204;&#26080;&#27861;&#20351;&#29992;&#29616;&#26377;&#26041;&#27861;&#65292;&#22240;&#20026;&#23427;&#20204;&#26126;&#30830;&#20381;&#36182;&#20110;&#23545;&#25972;&#20010;&#25968;&#25454;&#30340;&#23436;&#20840;&#35775;&#38382;&#12290;&#22312;&#29702;&#35770;&#26041;&#38754;&#65292;&#25105;&#20204;&#20351;&#29992;&#19968;&#31181;&#31216;&#20026;&#8220;&#21487;&#33021;&#36817;&#20284;&#20844;&#24179;&#21644;&#26368;&#20248;&#8221;&#65288;PAFO&#65289;&#21487;&#23398;&#20064;&#24615;&#30340;&#26032;&#27010;&#24565;&#65292;&#20005;&#26684;&#22320;&#21046;&#23450;&#20102;&#20844;&#24179;PCA&#12290;&#22312;&#23454;&#36341;&#26041;&#38754;&#65292;&#21463;&#21040;&#35299;&#20915;&#20869;&#23384;&#38480;&#21046;&#30340;&#27969;&#24335;&#31639;&#27861;&#30340;&#26368;&#26032;&#36827;&#23637;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#35774;&#32622;&#65292;&#31216;&#20026;&#8220;&#20844;&#24179;&#27969;&#24335;PCA&#8221;&#65292;&#20197;&#21450;&#19968;&#20010;&#20869;&#23384;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#20844;&#24179;&#22122;&#22768;&#21151;&#29575;&#26041;&#27861;&#65288;FNPM&#65289;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20854;&#22312;PAFO&#21487;&#23398;&#20064;&#24615;&#26041;&#38754;&#30340;&#32479;&#35745;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fair Principal Component Analysis (PCA) is a problem setting where we aim to perform PCA while making the resulting representation fair in that the projected distributions, conditional on the sensitive attributes, match one another. However, existing approaches to fair PCA have two main problems: theoretically, there has been no statistical foundation of fair PCA in terms of learnability; practically, limited memory prevents us from using existing approaches, as they explicitly rely on full access to the entire data. On the theoretical side, we rigorously formulate fair PCA using a new notion called \emph{probably approximately fair and optimal} (PAFO) learnability. On the practical side, motivated by recent advances in streaming algorithms for addressing memory limitation, we propose a new setting called \emph{fair streaming PCA} along with a memory-efficient algorithm, fair noisy power method (FNPM). We then provide its {\it statistical} guarantee in terms of PAFO-learnability, which
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21453;&#21521;&#20915;&#31574;&#24314;&#27169;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#23398;&#20064;&#24207;&#21015;&#20915;&#31574;&#34892;&#20026;&#30340;&#21442;&#25968;&#21270;&#34920;&#31034;&#12290;&#35813;&#26694;&#26550;&#33021;&#22815;&#25552;&#20379;&#36879;&#26126;&#30340;&#34892;&#20026;&#25551;&#36848;&#65292;&#24182;&#21487;&#20197;&#24191;&#27867;&#24212;&#29992;&#20110;&#34892;&#20026;&#34920;&#31034;&#30340;&#30740;&#31350;&#38382;&#39064;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#19968;&#20010;&#31034;&#20363;&#65292;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#22914;&#20309;&#23398;&#20064;&#21487;&#35299;&#37322;&#30340;&#26377;&#38480;&#29702;&#24615;&#34920;&#31034;&#65292;&#24182;&#33021;&#25429;&#25417;&#21040;&#27425;&#20248;&#21160;&#20316;&#21644;&#20559;&#35265;&#20449;&#20208;&#31561;&#30452;&#35266;&#27010;&#24565;&#12290;</title><link>http://arxiv.org/abs/2310.18591</link><description>&lt;p&gt;
&#21453;&#21521;&#20915;&#31574;&#24314;&#27169;&#65306;&#23398;&#20064;&#21487;&#35299;&#37322;&#34892;&#20026;&#30340;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Inverse Decision Modeling: Learning Interpretable Representations of Behavior. (arXiv:2310.18591v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18591
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21453;&#21521;&#20915;&#31574;&#24314;&#27169;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#23398;&#20064;&#24207;&#21015;&#20915;&#31574;&#34892;&#20026;&#30340;&#21442;&#25968;&#21270;&#34920;&#31034;&#12290;&#35813;&#26694;&#26550;&#33021;&#22815;&#25552;&#20379;&#36879;&#26126;&#30340;&#34892;&#20026;&#25551;&#36848;&#65292;&#24182;&#21487;&#20197;&#24191;&#27867;&#24212;&#29992;&#20110;&#34892;&#20026;&#34920;&#31034;&#30340;&#30740;&#31350;&#38382;&#39064;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#19968;&#20010;&#31034;&#20363;&#65292;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#22914;&#20309;&#23398;&#20064;&#21487;&#35299;&#37322;&#30340;&#26377;&#38480;&#29702;&#24615;&#34920;&#31034;&#65292;&#24182;&#33021;&#25429;&#25417;&#21040;&#27425;&#20248;&#21160;&#20316;&#21644;&#20559;&#35265;&#20449;&#20208;&#31561;&#30452;&#35266;&#27010;&#24565;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20915;&#31574;&#20998;&#26512;&#28041;&#21450;&#24314;&#27169;&#21644;&#22686;&#24378;&#20915;&#31574;&#36807;&#31243;&#12290;&#22312;&#25913;&#21892;&#34892;&#20026;&#26041;&#38754;&#30340;&#19968;&#20010;&#20027;&#35201;&#25361;&#25112;&#26159;&#39318;&#20808;&#33719;&#24471;&#29616;&#26377;&#34892;&#20026;&#30340;&#36879;&#26126;&#25551;&#36848;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21457;&#23637;&#20102;&#19968;&#20010;&#34920;&#36798;&#20016;&#23500;&#30340;&#36870;&#21521;&#20915;&#31574;&#24314;&#27169;&#30340;&#32479;&#19968;&#35270;&#35282;&#65306;&#19968;&#20010;&#23398;&#20064;&#21442;&#25968;&#21270;&#39034;&#24207;&#20915;&#31574;&#34892;&#20026;&#34920;&#31034;&#30340;&#26694;&#26550;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35268;&#33539;&#21270;&#20102;&#21069;&#21521;&#38382;&#39064;&#65288;&#20316;&#20026;&#35268;&#33539;&#26631;&#20934;&#65289;&#65292;&#21253;&#21547;&#20102;&#24120;&#35265;&#30340;&#25511;&#21046;&#34892;&#20026;&#31867;&#21035;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#20351;&#29992;&#36825;&#20010;&#26694;&#26550;&#26469;&#35268;&#33539;&#21270;&#36870;&#21521;&#38382;&#39064;&#65288;&#20316;&#20026;&#19968;&#20010;&#25551;&#36848;&#24615;&#27169;&#22411;&#65289;&#65292;&#24191;&#20041;&#19978;&#25512;&#24191;&#20102;&#29616;&#26377;&#20851;&#20110;&#27169;&#20223;/&#22870;&#21169;&#23398;&#20064;&#30340;&#24037;&#20316;&#65292;&#21516;&#26102;&#25171;&#24320;&#20102;&#26356;&#24191;&#27867;&#30340;&#34892;&#20026;&#34920;&#31034;&#30740;&#31350;&#38382;&#39064;&#31867;&#21035;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#19968;&#20010;&#20363;&#23376;&#65288;&#36870;&#21521;&#26377;&#38480;&#29702;&#24615;&#25511;&#21046;&#65289;&#23454;&#20363;&#21270;&#20102;&#36825;&#20010;&#26041;&#27861;&#65292;&#35828;&#26126;&#20102;&#36825;&#20010;&#32467;&#26500;&#22914;&#20309;&#33021;&#22815;&#23398;&#20064;&#65288;&#21487;&#35299;&#37322;&#30340;&#65289;&#26377;&#38480;&#29702;&#24615;&#34920;&#31034;-&#21516;&#26102;&#33258;&#28982;&#22320;&#25429;&#25417;&#21040;&#27425;&#20248;&#21160;&#20316;&#12289;&#20559;&#35265;&#20449;&#20208;&#31561;&#30452;&#35266;&#27010;&#24565;&#12290;
&lt;/p&gt;
&lt;p&gt;
Decision analysis deals with modeling and enhancing decision processes. A principal challenge in improving behavior is in obtaining a transparent description of existing behavior in the first place. In this paper, we develop an expressive, unifying perspective on inverse decision modeling: a framework for learning parameterized representations of sequential decision behavior. First, we formalize the forward problem (as a normative standard), subsuming common classes of control behavior. Second, we use this to formalize the inverse problem (as a descriptive model), generalizing existing work on imitation/reward learning -- while opening up a much broader class of research problems in behavior representation. Finally, we instantiate this approach with an example (inverse bounded rational control), illustrating how this structure enables learning (interpretable) representations of (bounded) rationality -while naturally capturing intuitive notions of suboptimal actions, biased beliefs, a
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26680;&#25216;&#24039;&#65292;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#35745;&#31639;&#20004;&#20010;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#20043;&#38388;&#36317;&#31163;&#30340;Wasserstein&#31867;&#22411;&#24230;&#37327;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#22312;&#26680;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#20013;&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.18586</link><description>&lt;p&gt;
&#29992;&#20110;&#26680;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#30340;&#26368;&#20248;&#20256;&#36755;
&lt;/p&gt;
&lt;p&gt;
Optimal Transport for Kernel Gaussian Mixture Models. (arXiv:2310.18586v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18586
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26680;&#25216;&#24039;&#65292;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#35745;&#31639;&#20004;&#20010;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#20043;&#38388;&#36317;&#31163;&#30340;Wasserstein&#31867;&#22411;&#24230;&#37327;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#22312;&#26680;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#20013;&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26469;&#33258;&#26368;&#20248;&#36136;&#37327;&#20256;&#36755;&#65288;OMT&#65289;&#30340;Wasserstein&#36317;&#31163;&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#25968;&#23398;&#24037;&#20855;&#65292;&#20855;&#26377;&#20247;&#22810;&#24212;&#29992;&#65292;&#25552;&#20379;&#20102;&#20004;&#20010;&#27010;&#29575;&#20998;&#24067;&#20043;&#38388;&#36317;&#31163;&#30340;&#33258;&#28982;&#24230;&#37327;&#12290;&#24050;&#24320;&#21457;&#20102;&#20960;&#31181;&#23558;OMT&#32435;&#20837;&#24191;&#27867;&#20351;&#29992;&#30340;&#27010;&#29575;&#27169;&#22411;&#65288;&#22914;&#39640;&#26031;&#25110;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65289;&#30340;&#26041;&#27861;&#65292;&#20197;&#22686;&#24378;&#24314;&#27169;&#22797;&#26434;&#22810;&#27169;&#24577;&#30495;&#23454;&#25968;&#25454;&#38598;&#23494;&#24230;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#24456;&#23569;&#26377;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#20013;&#30340;OMT&#38382;&#39064;&#65292;&#22312;&#20854;&#20013;&#21033;&#29992;&#20102;&#26680;&#25216;&#24039;&#65292;&#36991;&#20813;&#20102;&#38656;&#35201;&#26174;&#24335;&#26144;&#23556;&#36755;&#20837;&#25968;&#25454;&#21040;&#39640;&#32500;&#29305;&#24449;&#31354;&#38388;&#30340;&#38656;&#27714;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26680;&#25216;&#24039;&#65292;&#22312;RKHS&#20013;&#35745;&#31639;&#20004;&#20010;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#20043;&#38388;&#36317;&#31163;&#30340;Wasserstein&#31867;&#22411;&#24230;&#37327;&#65292;&#21363;&#26680;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Wasserstein distance from optimal mass transport (OMT) is a powerful mathematical tool with numerous applications that provides a natural measure of the distance between two probability distributions. Several methods to incorporate OMT into widely used probabilistic models, such as Gaussian or Gaussian mixture, have been developed to enhance the capability of modeling complex multimodal densities of real datasets. However, very few studies have explored the OMT problems in a reproducing kernel Hilbert space (RKHS), wherein the kernel trick is utilized to avoid the need to explicitly map input data into a high-dimensional feature space. In the current study, we propose a Wasserstein-type metric to compute the distance between two Gaussian mixtures in a RKHS via the kernel trick, i.e., kernel Gaussian mixture models.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#36951;&#25022;&#21040;&#32622;&#20449;&#38598;&#36716;&#25442;&#26041;&#27861;&#25913;&#36827;&#20102;&#36923;&#36753;&#22238;&#24402;&#36172;&#21338;&#26426;&#30340;&#36951;&#25022;&#30028;&#38480;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#30340;&#20984;&#32622;&#20449;&#38598;&#65292;&#24182;&#24212;&#29992;&#20110;&#20855;&#26377;&#26032;&#30340;&#38789;&#38598;&#20013;&#27493;&#39588;&#30340;&#36951;&#25022;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2310.18554</link><description>&lt;p&gt;
&#36890;&#36807;&#36951;&#25022;&#21040;&#32622;&#20449;&#38598;&#36716;&#25442;&#25913;&#36827;&#65288;&#22810;&#39033;&#24335;&#65289;&#36923;&#36753;&#22238;&#24402;&#36172;&#21338;&#26426;&#30340;&#36951;&#25022;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Improved Regret Bounds of (Multinomial) Logistic Bandits via Regret-to-Confidence-Set Conversion. (arXiv:2310.18554v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18554
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#36951;&#25022;&#21040;&#32622;&#20449;&#38598;&#36716;&#25442;&#26041;&#27861;&#25913;&#36827;&#20102;&#36923;&#36753;&#22238;&#24402;&#36172;&#21338;&#26426;&#30340;&#36951;&#25022;&#30028;&#38480;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#30340;&#20984;&#32622;&#20449;&#38598;&#65292;&#24182;&#24212;&#29992;&#20110;&#20855;&#26377;&#26032;&#30340;&#38789;&#38598;&#20013;&#27493;&#39588;&#30340;&#36951;&#25022;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36923;&#36753;&#22238;&#24402;&#36172;&#21338;&#26426;&#26159;&#24314;&#27169;&#29992;&#25143;&#36873;&#25321;&#30340;&#26222;&#36941;&#26694;&#26550;&#65292;&#20363;&#22914;&#24191;&#21578;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#28857;&#20987;&#19982;&#21542;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#20808;&#21069;&#30340;&#24037;&#20316;&#24573;&#35270;&#25110;&#24573;&#30053;&#20102;$S \geq \lVert \theta_\star \rVert_2$&#20013;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#20854;&#20013;$\theta_\star \in \mathbb{R}^d$&#26159;&#26410;&#30693;&#30340;&#21442;&#25968;&#21521;&#37327;&#65292;&#24403;$S$&#36739;&#22823;&#26102;&#65292;&#20363;&#22914;$S \geq d$&#65292;&#36825;&#20250;&#20135;&#29983;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#19968;&#31181;&#31216;&#20026;&#8220;&#36951;&#25022;&#21040;&#32622;&#20449;&#38598;&#36716;&#25442;&#65288;R2CS&#65289;&#8221;&#30340;&#26032;&#26041;&#27861;&#25913;&#21892;&#20102;&#23545;$S$&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#35813;&#26041;&#27861;&#20801;&#35768;&#25105;&#20204;&#26500;&#24314;&#19968;&#20010;&#22522;&#20110;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#23384;&#22312;&#24615;&#30340;&#20984;&#32622;&#20449;&#38598;&#12290;&#20351;&#29992;R2CS&#65292;&#25105;&#20204;&#22312;&#36923;&#36753;&#22238;&#24402;&#36172;&#21338;&#26426;&#30340;&#36951;&#25022;&#30028;&#38480;&#26041;&#38754;&#33719;&#24471;&#20102;&#20005;&#26684;&#30340;&#25913;&#36827;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#35745;&#31639;&#21487;&#34892;&#24615;&#21644;&#23545;&#20854;&#20182;&#22240;&#32032;&#65288;&#22914;$d$&#21644;$T$&#65289;&#30340;&#20381;&#36182;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26032;&#32622;&#20449;&#38598;&#24212;&#29992;&#20110;&#20855;&#26377;&#26032;&#30340;&#38789;&#38598;&#20013;&#27493;&#39588;&#30340;&#36923;&#36753;&#22238;&#24402;&#36172;&#21338;&#26426;&#30340;&#36951;&#25022;&#20998;&#26512;&#65292;&#20174;&#32780;&#36991;&#20813;&#20102;&#39069;&#22806;&#30340;&#22240;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;
Logistic bandit is a ubiquitous framework of modeling users' choices, e.g., click vs. no click for advertisement recommender system. We observe that the prior works overlook or neglect dependencies in $S \geq \lVert \theta_\star \rVert_2$, where $\theta_\star \in \mathbb{R}^d$ is the unknown parameter vector, which is particularly problematic when $S$ is large, e.g., $S \geq d$. In this work, we improve the dependency on $S$ via a novel approach called {\it regret-to-confidence set conversion (R2CS)}, which allows us to construct a convex confidence set based on only the \textit{existence} of an online learning algorithm with a regret guarantee. Using R2CS, we obtain a strict improvement in the regret bound w.r.t. $S$ in logistic bandits while retaining computational feasibility and the dependence on other factors such as $d$ and $T$. We apply our new confidence set to the regret analyses of logistic bandits with a new martingale concentration step that circumvents an additional factor
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21487;&#20197;&#21033;&#29992;&#22810;&#27169;&#24577;&#25968;&#25454;&#21644;&#24050;&#30693;&#29289;&#29702;&#23398;&#30693;&#35782;&#21457;&#29616;&#22240;&#26524;&#20851;&#31995;&#30340;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.18471</link><description>&lt;p&gt;
&#22810;&#27169;&#24577;&#25968;&#25454;&#30340;&#22240;&#26524;&#20998;&#35299;
&lt;/p&gt;
&lt;p&gt;
Causal disentanglement of multimodal data. (arXiv:2310.18471v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18471
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21487;&#20197;&#21033;&#29992;&#22810;&#27169;&#24577;&#25968;&#25454;&#21644;&#24050;&#30693;&#29289;&#29702;&#23398;&#30693;&#35782;&#21457;&#29616;&#22240;&#26524;&#20851;&#31995;&#30340;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#31639;&#27861;&#21457;&#29616;&#20102;&#25968;&#25454;&#30340;&#36739;&#20302;&#32500;&#24230;&#34920;&#31034;&#65292;&#21487;&#20197;&#23545;&#22240;&#26524;&#20851;&#31995;&#36827;&#34892;&#21487;&#35299;&#37322;&#30340;&#35299;&#37322;&#65307;&#30001;&#20110;&#23454;&#29616;&#36825;&#26679;&#30340;&#21487;&#35299;&#37322;&#34920;&#31034;&#24456;&#20855;&#25361;&#25112;&#24615;&#65292;&#35768;&#22810;&#22240;&#26524;&#23398;&#20064;&#31639;&#27861;&#21033;&#29992;&#20102;&#25351;&#31034;&#20808;&#39564;&#20449;&#24687;&#30340;&#20803;&#32032;&#65292;&#20363;&#22914;&#65288;&#32447;&#24615;&#65289;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#12289;&#24178;&#39044;&#25968;&#25454;&#25110;&#24369;&#30417;&#30563;&#12290;&#28982;&#32780;&#65292;&#22312;&#25506;&#32034;&#24615;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#20013;&#65292;&#36825;&#20123;&#20803;&#32032;&#21644;&#20808;&#39564;&#20449;&#24687;&#21487;&#33021;&#19981;&#21487;&#29992;&#25110;&#19981;&#21512;&#36866;&#12290;&#30456;&#21453;&#65292;&#31185;&#23398;&#25968;&#25454;&#38598;&#36890;&#24120;&#20855;&#26377;&#22810;&#20010;&#27169;&#24577;&#25110;&#22522;&#20110;&#29289;&#29702;&#23398;&#30340;&#32422;&#26463;&#65292;&#24182;&#19988;&#24050;&#32463;&#35777;&#26126;&#22312;&#23436;&#20840;&#26080;&#30417;&#30563;&#30340;&#35774;&#32622;&#20013;&#20351;&#29992;&#36825;&#31181;&#31185;&#23398;&#30340;&#22810;&#27169;&#24577;&#25968;&#25454;&#21487;&#20197;&#25913;&#21892;&#22240;&#26524;&#20998;&#35299;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#31639;&#27861;&#65288;causalPIMA&#65289;&#65292;&#23427;&#21487;&#20197;&#21033;&#29992;&#22810;&#27169;&#24577;&#25968;&#25454;&#21644;&#24050;&#30693;&#30340;&#29289;&#29702;&#23398;&#30693;&#35782;&#21457;&#29616;&#20855;&#26377;&#22240;&#26524;&#20851;&#31995;&#30340;&#37325;&#35201;&#29305;&#24449;&#12290;&#25105;&#20204;&#30340;&#21019;&#26032;&#31639;&#27861;&#21033;&#29992;&#26032;&#30340;&#21487;&#24494;&#21442;&#25968;&#21270;&#26469;&#23398;&#20064;&#36825;&#31181;&#22240;&#26524;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal representation learning algorithms discover lower-dimensional representations of data that admit a decipherable interpretation of cause and effect; as achieving such interpretable representations is challenging, many causal learning algorithms utilize elements indicating prior information, such as (linear) structural causal models, interventional data, or weak supervision. Unfortunately, in exploratory causal representation learning, such elements and prior information may not be available or warranted. Alternatively, scientific datasets often have multiple modalities or physics-based constraints, and the use of such scientific, multimodal data has been shown to improve disentanglement in fully unsupervised settings. Consequently, we introduce a causal representation learning algorithm (causalPIMA) that can use multimodal data and known physics to discover important features with causal relationships. Our innovative algorithm utilizes a new differentiable parametrization to lear
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#30740;&#31350;&#20102;&#24102;&#26377;Bandit&#21453;&#39304;&#30340;&#26497;&#23567;&#26497;&#22823;&#27425;&#27169;&#20248;&#21270;&#38382;&#39064;&#65292;&#22312;&#36825;&#20010;&#38382;&#39064;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#31532;&#19968;&#20010;&#26368;&#23567;&#26368;&#22823;&#19979;&#38480;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#33021;&#22815;&#19982;&#19979;&#38480;&#36951;&#25022;&#30456;&#21305;&#37197;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.18465</link><description>&lt;p&gt;
&#24102;&#26377;Bandit&#21453;&#39304;&#30340;&#26497;&#23567;&#26497;&#22823;&#27425;&#27169;&#20248;&#21270;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Minimax Optimal Submodular Optimization with Bandit Feedback. (arXiv:2310.18465v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18465
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#30740;&#31350;&#20102;&#24102;&#26377;Bandit&#21453;&#39304;&#30340;&#26497;&#23567;&#26497;&#22823;&#27425;&#27169;&#20248;&#21270;&#38382;&#39064;&#65292;&#22312;&#36825;&#20010;&#38382;&#39064;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#31532;&#19968;&#20010;&#26368;&#23567;&#26368;&#22823;&#19979;&#38480;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#33021;&#22815;&#19982;&#19979;&#38480;&#36951;&#25022;&#30456;&#21305;&#37197;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#38543;&#26426;Bandit&#21453;&#39304;&#19979;&#65292;&#26368;&#22823;&#21270;&#19968;&#20010;&#21333;&#35843;&#27425;&#27169;&#38598;&#20989;&#25968;$f&#65306;2 ^ {[n]} \rightarrow [0,1]$&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;$f$&#23545;&#20110;&#23398;&#20064;&#32773;&#26159;&#26410;&#30693;&#30340;&#65292;&#20294;&#26159;&#22312;&#27599;&#20010;&#26102;&#38388;$t=1,\dots,T$&#65292;&#23398;&#20064;&#32773;&#36873;&#25321;&#19968;&#20010;&#38598;&#21512;$S_t \subset [n]$&#65292;&#20854;&#20013;$|S_t|\leq k$&#65292;&#24182;&#25509;&#25910;&#22870;&#21169;$f(S_t)+\eta_t$&#65292;&#20854;&#20013;$\eta_t$&#26159;&#22343;&#20540;&#20026;&#38646;&#30340;&#27425;&#39640;&#26031;&#22122;&#22768;&#12290;&#30446;&#26631;&#26159;&#22312;$T$&#27425;&#20013;&#20351;&#24471;&#23398;&#20064;&#32773;&#23545;&#20110;&#24102;&#26377;$|S_*|=k$&#30340;&#26368;&#22823;$f(S_*)$&#30340;($1-e^{-1}$)&#36817;&#20284;&#30340;&#26368;&#23567;&#36951;&#25022;&#65292;&#36890;&#36807;&#23545;$f$&#30340;&#36138;&#23146;&#26368;&#22823;&#21270;&#26469;&#36798;&#21040;&#12290;&#21040;&#30446;&#21069;&#20026;&#27490;&#65292;&#25991;&#29486;&#20013;&#26368;&#22909;&#30340;&#36951;&#25022;&#36793;&#30028;&#25353;&#29031;$k n^{1/3} T^{2/3}$&#30340;&#27604;&#20363;&#32553;&#25918;&#12290;&#36890;&#36807;&#23558;&#27599;&#20010;&#38598;&#21512;&#31616;&#21333;&#22320;&#35270;&#20026;&#19968;&#20010;&#21807;&#19968;&#30340;arm&#65292;&#21487;&#20197;&#25512;&#26029;&#20986;$\sqrt{{n \choose k} T}$&#20063;&#26159;&#21487;&#23454;&#29616;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#36825;&#31181;&#24773;&#20917;&#19979;&#30340;&#31532;&#19968;&#20010;&#26497;&#23567;&#26497;&#22823;&#19979;&#38480;&#65292;&#20854;&#25353;&#29031;$\mathcal{O}(\min_{i \le k}(in^{1/3}T^{2/3} + \sqrt{n^{k-i}T}))$&#30340;&#27604;&#20363;&#32553;&#25918;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#33021;&#22815;&#19982;&#19979;&#38480;&#36951;&#25022;&#30456;&#21305;&#37197;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider maximizing a monotonic, submodular set function $f: 2^{[n]} \rightarrow [0,1]$ under stochastic bandit feedback. Specifically, $f$ is unknown to the learner but at each time $t=1,\dots,T$ the learner chooses a set $S_t \subset [n]$ with $|S_t| \leq k$ and receives reward $f(S_t) + \eta_t$ where $\eta_t$ is mean-zero sub-Gaussian noise. The objective is to minimize the learner's regret over $T$ times with respect to ($1-e^{-1}$)-approximation of maximum $f(S_*)$ with $|S_*| = k$, obtained through greedy maximization of $f$. To date, the best regret bound in the literature scales as $k n^{1/3} T^{2/3}$. And by trivially treating every set as a unique arm one deduces that $\sqrt{ {n \choose k} T }$ is also achievable. In this work, we establish the first minimax lower bound for this setting that scales like $\mathcal{O}(\min_{i \le k}(in^{1/3}T^{2/3} + \sqrt{n^{k-i}T}))$. Moreover, we propose an algorithm that is capable of matching the lower bound regret.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#31163;&#32447;&#65288;&#22810;&#36941;&#65289;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20013;&#30340;&#37325;&#23614;&#34892;&#20026;&#12290;&#36890;&#36807;&#23637;&#31034;&#31163;&#32447;SGD&#30340;&#31283;&#24577;&#20998;&#24067;&#34920;&#29616;&#20986;&#8220;&#36817;&#20284;&#8221;&#24130;&#24459;&#23614;&#37096;&#65292;&#25105;&#20204;&#22635;&#34917;&#20102;&#22312;&#26377;&#38480;&#30340;&#35757;&#32451;&#25968;&#25454;&#37327;&#24773;&#20917;&#19979;&#37325;&#23614;&#34892;&#20026;&#26426;&#21046;&#30340;&#31354;&#30333;&#12290;</title><link>http://arxiv.org/abs/2310.18455</link><description>&lt;p&gt;
&#31163;&#32447;&#65288;&#22810;&#36941;&#65289;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20013;&#30340;&#36817;&#20284;&#37325;&#23614;&#34892;&#20026;
&lt;/p&gt;
&lt;p&gt;
Approximate Heavy Tails in Offline (Multi-Pass) Stochastic Gradient Descent. (arXiv:2310.18455v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18455
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31163;&#32447;&#65288;&#22810;&#36941;&#65289;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20013;&#30340;&#37325;&#23614;&#34892;&#20026;&#12290;&#36890;&#36807;&#23637;&#31034;&#31163;&#32447;SGD&#30340;&#31283;&#24577;&#20998;&#24067;&#34920;&#29616;&#20986;&#8220;&#36817;&#20284;&#8221;&#24130;&#24459;&#23614;&#37096;&#65292;&#25105;&#20204;&#22635;&#34917;&#20102;&#22312;&#26377;&#38480;&#30340;&#35757;&#32451;&#25968;&#25454;&#37327;&#24773;&#20917;&#19979;&#37325;&#23614;&#34892;&#20026;&#26426;&#21046;&#30340;&#31354;&#30333;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#19968;&#31995;&#21015;&#23454;&#35777;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#23454;&#38469;&#24773;&#20917;&#19979;&#65292;SGD&#21487;&#33021;&#34920;&#29616;&#20986;&#37325;&#23614;&#34892;&#20026;&#65292;&#23614;&#37096;&#30340;&#37325;&#24230;&#21487;&#33021;&#19982;&#25972;&#20307;&#24615;&#33021;&#30456;&#20851;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#36825;&#31181;&#37325;&#23614;&#34892;&#20026;&#30340;&#20986;&#29616;&#12290;&#20043;&#21069;&#30340;&#24037;&#20316;&#21482;&#32771;&#34385;&#20102;&#22312;&#32447;&#65288;&#20063;&#31216;&#20026;&#21333;&#36941;&#65289;SGD&#65292;&#22312;&#29702;&#35770;&#21457;&#29616;&#20013;&#65292;&#37325;&#23614;&#29616;&#35937;&#30340;&#20986;&#29616;&#21462;&#20915;&#20110;&#23545;&#26080;&#38480;&#37327;&#25968;&#25454;&#30340;&#35775;&#38382;&#12290;&#22240;&#27492;&#65292;&#22312;&#35757;&#32451;&#25968;&#25454;&#37327;&#26377;&#38480;&#30340;&#23454;&#38469;&#24773;&#20917;&#19979;&#65292;&#20135;&#29983;&#25253;&#21578;&#30340;&#37325;&#23614;&#34892;&#20026;&#30340;&#26426;&#21046;&#20173;&#19981;&#28165;&#26970;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#26088;&#22312;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#31163;&#32447;&#65288;&#20063;&#31216;&#20026;&#22810;&#36941;&#65289;SGD&#30340;&#31283;&#24577;&#20998;&#24067;&#34920;&#29616;&#20986;&#8220;&#36817;&#20284;&#8221;&#24130;&#24459;&#23614;&#37096;&#65292;&#32780;&#36817;&#20284;&#35823;&#24046;&#30001;&#35757;&#32451;&#25968;&#25454;&#30340;&#32463;&#39564;&#20998;&#24067;&#22914;&#20309;&#24555;&#36895;&#25910;&#25947;&#20110;&#30495;&#23454;&#30340;&#22522;&#26412;&#25968;&#25454;&#20998;&#24067;&#25152;&#25511;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
A recent line of empirical studies has demonstrated that SGD might exhibit a heavy-tailed behavior in practical settings, and the heaviness of the tails might correlate with the overall performance. In this paper, we investigate the emergence of such heavy tails. Previous works on this problem only considered, up to our knowledge, online (also called single-pass) SGD, in which the emergence of heavy tails in theoretical findings is contingent upon access to an infinite amount of data. Hence, the underlying mechanism generating the reported heavy-tailed behavior in practical settings, where the amount of training data is finite, is still not well-understood. Our contribution aims to fill this gap. In particular, we show that the stationary distribution of offline (also called multi-pass) SGD exhibits 'approximate' power-law tails and the approximation error is controlled by how fast the empirical distribution of the training data converges to the true underlying data distribution in the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#22312;&#20915;&#31574;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#23398;&#20064;&#21487;&#34892;&#20915;&#31574;&#30340;&#20998;&#24067;&#65292;&#22312;&#21407;&#22987;&#31354;&#38388;&#21644;&#28508;&#22312;&#31354;&#38388;&#20043;&#38388;&#23454;&#29616;&#20102;&#21452;&#21521;&#26144;&#23556;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#20844;&#20849;&#20915;&#31574;&#21046;&#23450;&#20013;&#30340;&#38544;&#34255;&#32422;&#26463;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.18449</link><description>&lt;p&gt;
&#22522;&#20110;&#28508;&#22312;&#20915;&#31574;&#27169;&#22411;&#30340;&#20855;&#26377;&#38544;&#34255;&#32422;&#26463;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Bayesian Optimization with Hidden Constraints via Latent Decision Models. (arXiv:2310.18449v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18449
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#22312;&#20915;&#31574;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#23398;&#20064;&#21487;&#34892;&#20915;&#31574;&#30340;&#20998;&#24067;&#65292;&#22312;&#21407;&#22987;&#31354;&#38388;&#21644;&#28508;&#22312;&#31354;&#38388;&#20043;&#38388;&#23454;&#29616;&#20102;&#21452;&#21521;&#26144;&#23556;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#20844;&#20849;&#20915;&#31574;&#21046;&#23450;&#20013;&#30340;&#38544;&#34255;&#32422;&#26463;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;BO&#65289;&#24050;&#32463;&#25104;&#20026;&#35299;&#20915;&#22797;&#26434;&#20915;&#31574;&#38382;&#39064;&#30340;&#24378;&#22823;&#24037;&#20855;&#65292;&#23588;&#20854;&#22312;&#20844;&#20849;&#25919;&#31574;&#39046;&#22495;&#22914;&#35686;&#23519;&#21010;&#21306;&#26041;&#38754;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#23450;&#20041;&#21487;&#34892;&#21306;&#22495;&#30340;&#22797;&#26434;&#24615;&#21644;&#20915;&#31574;&#30340;&#39640;&#32500;&#24230;&#65292;&#20854;&#22312;&#20844;&#20849;&#20915;&#31574;&#21046;&#23450;&#20013;&#30340;&#24191;&#27867;&#24212;&#29992;&#21463;&#21040;&#20102;&#38459;&#30861;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#8212;&#8212;&#38544;&#34255;&#32422;&#26463;&#28508;&#22312;&#31354;&#38388;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;HC-LSBO&#65289;&#65292;&#35813;&#26041;&#27861;&#38598;&#25104;&#20102;&#28508;&#22312;&#20915;&#31574;&#27169;&#22411;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#26469;&#23398;&#20064;&#21487;&#34892;&#20915;&#31574;&#30340;&#20998;&#24067;&#65292;&#23454;&#29616;&#20102;&#21407;&#22987;&#20915;&#31574;&#31354;&#38388;&#19982;&#36739;&#20302;&#32500;&#24230;&#30340;&#28508;&#22312;&#31354;&#38388;&#20043;&#38388;&#30340;&#21452;&#21521;&#26144;&#23556;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#24335;&#65292;HC-LSBO&#25429;&#25417;&#20102;&#20844;&#20849;&#20915;&#31574;&#21046;&#23450;&#20013;&#22266;&#26377;&#30340;&#38544;&#34255;&#32422;&#26463;&#30340;&#32454;&#24494;&#24046;&#21035;&#65292;&#22312;&#28508;&#22312;&#31354;&#38388;&#20013;&#36827;&#34892;&#20248;&#21270;&#30340;&#21516;&#26102;&#65292;&#22312;&#21407;&#22987;&#31354;&#38388;&#20013;&#35780;&#20272;&#30446;&#26631;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#36827;&#34892;&#25968;&#20540;&#23454;&#39564;&#26469;&#39564;&#35777;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#29305;&#21035;&#20851;&#27880;&#22823;&#35268;&#27169;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian optimization (BO) has emerged as a potent tool for addressing intricate decision-making challenges, especially in public policy domains such as police districting. However, its broader application in public policymaking is hindered by the complexity of defining feasible regions and the high-dimensionality of decisions. This paper introduces the Hidden-Constrained Latent Space Bayesian Optimization (HC-LSBO), a novel BO method integrated with a latent decision model. This approach leverages a variational autoencoder to learn the distribution of feasible decisions, enabling a two-way mapping between the original decision space and a lower-dimensional latent space. By doing so, HC-LSBO captures the nuances of hidden constraints inherent in public policymaking, allowing for optimization in the latent space while evaluating objectives in the original space. We validate our method through numerical experiments on both synthetic and real data sets, with a specific focus on large-scal
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#23558;&#20998;&#24067;&#40065;&#26834;&#23398;&#20064;&#65288;DRL&#65289;&#19982;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#30456;&#32467;&#21512;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#12290;&#36890;&#36807;&#20351;&#29992;DRL&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#32531;&#35299;&#35757;&#32451;&#21644;&#27979;&#35797;&#29615;&#22659;&#20043;&#38388;&#30340;&#27169;&#22411;&#19981;&#21305;&#37197;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.18434</link><description>&lt;p&gt;
&#20998;&#24067;&#40065;&#26834;&#23398;&#20064;&#21644;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#26725;&#26753;&#65306;&#32531;&#35299;&#20998;&#24067;&#20559;&#31227;&#21644;&#37096;&#20998;&#25968;&#25454;&#35206;&#30422;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Bridging Distributionally Robust Learning and Offline RL: An Approach to Mitigate Distribution Shift and Partial Data Coverage. (arXiv:2310.18434v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18434
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#23558;&#20998;&#24067;&#40065;&#26834;&#23398;&#20064;&#65288;DRL&#65289;&#19982;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#30456;&#32467;&#21512;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#12290;&#36890;&#36807;&#20351;&#29992;DRL&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#32531;&#35299;&#35757;&#32451;&#21644;&#27979;&#35797;&#29615;&#22659;&#20043;&#38388;&#30340;&#27169;&#22411;&#19981;&#21305;&#37197;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#30340;&#30446;&#26631;&#26159;&#20351;&#29992;&#21382;&#21490;&#65288;&#31163;&#32447;&#65289;&#25968;&#25454;&#23398;&#20064;&#26368;&#20248;&#31574;&#30053;&#65292;&#32780;&#26080;&#38656;&#35775;&#38382;&#29615;&#22659;&#36827;&#34892;&#22312;&#32447;&#25506;&#32034;&#12290;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#20027;&#35201;&#25361;&#25112;&#20043;&#19968;&#26159;&#20998;&#24067;&#20559;&#31227;&#65292;&#21363;&#25968;&#25454;&#29983;&#25104;&#31574;&#30053;&#30340;&#29366;&#24577;-&#21160;&#20316;&#35775;&#38382;&#20998;&#24067;&#19982;&#23398;&#20064;&#31574;&#30053;&#30340;&#24046;&#24322;&#12290;&#35768;&#22810;&#26368;&#26032;&#30340;&#30740;&#31350;&#21033;&#29992;&#24754;&#35266;&#20027;&#20041;&#30340;&#24605;&#24819;&#24320;&#21457;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#22312;&#30456;&#23545;&#36739;&#24369;&#30340;&#21333;&#19968;&#31574;&#30053;&#38598;&#20013;&#24615;&#20551;&#35774;&#19979;&#34920;&#24449;&#20854;&#26679;&#26412;&#22797;&#26434;&#24615;&#12290;&#19982;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#25991;&#29486;&#19981;&#21516;&#65292;&#20998;&#24067;&#40065;&#26834;&#23398;&#20064;&#65288;DRL&#65289;&#30340;&#39046;&#22495;&#25552;&#20379;&#20102;&#19968;&#20010;&#21407;&#21017;&#24615;&#26694;&#26550;&#65292;&#37319;&#29992;&#26497;&#23567;&#26497;&#22823;&#24418;&#24335;&#26469;&#35299;&#20915;&#35757;&#32451;&#21644;&#27979;&#35797;&#29615;&#22659;&#20043;&#38388;&#30340;&#27169;&#22411;&#19981;&#21305;&#37197;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#36890;&#36807;&#23637;&#31034;DRL&#26041;&#27861;&#21487;&#20197;&#29992;&#26469;&#35299;&#20915;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
The goal of an offline reinforcement learning (RL) algorithm is to learn optimal polices using historical (offline) data, without access to the environment for online exploration. One of the main challenges in offline RL is the distribution shift which refers to the difference between the state-action visitation distribution of the data generating policy and the learning policy. Many recent works have used the idea of pessimism for developing offline RL algorithms and characterizing their sample complexity under a relatively weak assumption of single policy concentrability. Different from the offline RL literature, the area of distributionally robust learning (DRL) offers a principled framework that uses a minimax formulation to tackle model mismatch between training and testing environments. In this work, we aim to bridge these two areas by showing that the DRL approach can be used to tackle the distributional shift problem in offline RL. In particular, we propose two offline RL algor
&lt;/p&gt;</description></item><item><title>MCRAGE&#26159;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#26469;&#22686;&#24378;&#19981;&#24179;&#34913;&#30340;&#21307;&#30103;&#25968;&#25454;&#38598;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#23569;&#25968;&#32676;&#20307;&#22312;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#30340;&#19981;&#20844;&#24179;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.18430</link><description>&lt;p&gt;
MCRAGE: &#20844;&#24179;&#24615;&#30340;&#21512;&#25104;&#21307;&#30103;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
MCRAGE: Synthetic Healthcare Data for Fairness. (arXiv:2310.18430v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18430
&lt;/p&gt;
&lt;p&gt;
MCRAGE&#26159;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#26469;&#22686;&#24378;&#19981;&#24179;&#34913;&#30340;&#21307;&#30103;&#25968;&#25454;&#38598;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#23569;&#25968;&#32676;&#20307;&#22312;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#30340;&#19981;&#20844;&#24179;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21307;&#30103;&#39046;&#22495;&#65292;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#65288;EHR&#65289;&#26159;&#24320;&#21457;&#35786;&#26029;&#12289;&#27835;&#30103;&#21644;&#31649;&#29702;&#21307;&#30103;&#36164;&#28304;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#20851;&#38190;&#35757;&#32451;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#21307;&#30103;&#25968;&#25454;&#38598;&#22312;&#31181;&#26063;/&#27665;&#26063;&#12289;&#24615;&#21035;&#21644;&#24180;&#40836;&#31561;&#25935;&#24863;&#23646;&#24615;&#26041;&#38754;&#24448;&#24448;&#23384;&#22312;&#19981;&#24179;&#34913;&#12290;&#22312;&#31867;&#19981;&#24179;&#34913;&#30340;EHR&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#37096;&#32626;&#26102;&#65292;&#23545;&#20110;&#23569;&#25968;&#32676;&#20307;&#30340;&#20010;&#20307;&#32780;&#35328;&#65292;&#34920;&#29616;&#26174;&#33879;&#19981;&#22914;&#22810;&#25968;&#32676;&#20307;&#30340;&#26679;&#26412;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#23569;&#25968;&#32676;&#20307;&#30340;&#19981;&#20844;&#24179;&#21307;&#30103;&#32467;&#26524;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Minority Class Rebalancing through Augmentation by Generative modeling (MCRAGE)&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#30001;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#29983;&#25104;&#30340;&#26679;&#26412;&#26469;&#22686;&#24378;&#19981;&#24179;&#34913;&#30340;&#25968;&#25454;&#38598;&#12290;MCRAGE&#36807;&#31243;&#21253;&#25324;&#35757;&#32451;&#19968;&#20010;&#33021;&#22815;&#20174;&#23569;&#25968;&#32676;&#20307;&#20013;&#20135;&#29983;&#39640;&#36136;&#37327;&#21512;&#25104;EHR&#26679;&#26412;&#30340;&#26465;&#20214;&#21435;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65288;CDDPM&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the field of healthcare, electronic health records (EHR) serve as crucial training data for developing machine learning models for diagnosis, treatment, and the management of healthcare resources. However, medical datasets are often imbalanced in terms of sensitive attributes such as race/ethnicity, gender, and age. Machine learning models trained on class-imbalanced EHR datasets perform significantly worse in deployment for individuals of the minority classes compared to samples from majority classes, which may lead to inequitable healthcare outcomes for minority groups. To address this challenge, we propose Minority Class Rebalancing through Augmentation by Generative modeling (MCRAGE), a novel approach to augment imbalanced datasets using samples generated by a deep generative model. The MCRAGE process involves training a Conditional Denoising Diffusion Probabilistic Model (CDDPM) capable of generating high-quality synthetic EHR samples from underrepresented classes. We use this 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#31639;&#27861;&#20844;&#24179;&#24615;&#39046;&#22495;&#20013;&#23384;&#22312;&#30340;&#23616;&#37096;&#24046;&#24322;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#30340;&#20844;&#24179;&#23545;&#25239;&#23398;&#20064;&#26041;&#27861;&#65292;&#20197;&#23454;&#29616;&#38024;&#23545;&#23616;&#37096;&#29305;&#24449;&#31354;&#38388;&#30340;&#20844;&#24179;&#24615;&#26631;&#20934;&#12290;</title><link>http://arxiv.org/abs/2310.18413</link><description>&lt;p&gt;
&#20851;&#20110;&#36947;&#36335;&#20844;&#24179;&#24615;&#30340;&#30740;&#31350;&#65306;&#38024;&#23545;&#23545;&#25239;&#21435;&#20559;&#30340;&#40065;&#26834;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
On the Fairness ROAD: Robust Optimization for Adversarial Debiasing. (arXiv:2310.18413v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18413
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#31639;&#27861;&#20844;&#24179;&#24615;&#39046;&#22495;&#20013;&#23384;&#22312;&#30340;&#23616;&#37096;&#24046;&#24322;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#30340;&#20844;&#24179;&#23545;&#25239;&#23398;&#20064;&#26041;&#27861;&#65292;&#20197;&#23454;&#29616;&#38024;&#23545;&#23616;&#37096;&#29305;&#24449;&#31354;&#38388;&#30340;&#20844;&#24179;&#24615;&#26631;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31639;&#27861;&#20844;&#24179;&#24615;&#39046;&#22495;&#65292;&#20154;&#20204;&#19968;&#30452;&#20851;&#27880;&#32676;&#20307;&#20844;&#24179;&#24615;&#20934;&#21017;&#65292;&#22914;&#20154;&#21475;&#32479;&#35745;&#23398;&#24179;&#20215;&#21644;&#24179;&#31561;&#36180;&#29575;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#20197;&#20840;&#23616;&#24179;&#22343;&#20540;&#34913;&#37327;&#30340;&#30446;&#26631;&#24341;&#21457;&#20102;&#26377;&#20851;&#25935;&#24863;&#32676;&#20307;&#20043;&#38388;&#25345;&#32493;&#23616;&#37096;&#24046;&#24322;&#30340;&#25285;&#24551;&#12290;&#26412;&#30740;&#31350;&#35299;&#20915;&#20102;&#23616;&#37096;&#20844;&#24179;&#24615;&#38382;&#39064;&#65292;&#21363;&#30830;&#20445;&#39044;&#27979;&#22120;&#22312;&#25972;&#20010;&#20154;&#32676;&#20013;&#30340;&#26399;&#26395;&#20540;&#20197;&#21450;&#22312;&#35757;&#32451;&#26102;&#26410;&#30693;&#30340;&#20219;&#20309;&#29305;&#24449;&#31354;&#38388;&#30340;&#23376;&#21306;&#22495;&#20869;&#22343;&#26080;&#20559;&#35265;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#20010;&#30446;&#26631;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;ROAD&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#65288;DRO&#65289;&#26694;&#26550;&#26469;&#36827;&#34892;&#20844;&#24179;&#23545;&#25239;&#23398;&#20064;&#65292;&#20854;&#20013;&#23545;&#25163;&#35797;&#22270;&#20174;&#39044;&#27979;&#20013;&#25512;&#26029;&#20986;&#25935;&#24863;&#23646;&#24615;&#12290;&#36890;&#36807;&#23454;&#20363;&#32423;&#37325;&#26032;&#21152;&#26435;&#31574;&#30053;&#65292;ROAD&#34987;&#35774;&#35745;&#20026;&#20248;&#20808;&#32771;&#34385;&#21487;&#33021;&#20986;&#29616;&#23616;&#37096;&#19981;&#20844;&#24179;&#30340;&#36755;&#20837;&#65292;&#21363;&#23545;&#25163;&#22312;&#37325;&#24314;&#25935;&#24863;&#23646;&#24615;&#26102;&#26368;&#22256;&#38590;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the field of algorithmic fairness, significant attention has been put on group fairness criteria, such as Demographic Parity and Equalized Odds. Nevertheless, these objectives, measured as global averages, have raised concerns about persistent local disparities between sensitive groups. In this work, we address the problem of local fairness, which ensures that the predictor is unbiased not only in terms of expectations over the whole population, but also within any subregion of the feature space, unknown at training time. To enforce this objective, we introduce ROAD, a novel approach that leverages the Distributionally Robust Optimization (DRO) framework within a fair adversarial learning objective, where an adversary tries to infer the sensitive attribute from the predictions. Using an instance-level re-weighting strategy, ROAD is designed to prioritize inputs that are likely to be locally unfair, i.e. where the adversary faces the least difficulty in reconstructing the sensitive a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#27010;&#36848;&#20102;AdaBoost&#31639;&#27861;&#30340;&#19981;&#21516;&#35270;&#35282;&#65292;&#24182;&#36890;&#36807;&#32479;&#19968;&#30340;&#24418;&#24335;&#21270;&#26041;&#27861;&#23558;&#23427;&#20204;&#30456;&#20114;&#20851;&#32852;&#65292;&#24110;&#21161;&#35835;&#32773;&#26356;&#22909;&#22320;&#29702;&#35299;AdaBoost&#30340;&#21160;&#24577;&#12290;</title><link>http://arxiv.org/abs/2310.18323</link><description>&lt;p&gt;
AdaBoost&#27010;&#36848;&#65306;&#35843;&#21644;&#19981;&#21516;&#35270;&#35282;&#20197;&#26356;&#22909;&#22320;&#29702;&#35299;&#20854;&#21160;&#24577;
&lt;/p&gt;
&lt;p&gt;
Overview of AdaBoost : Reconciling its views to better understand its dynamics. (arXiv:2310.18323v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18323
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#27010;&#36848;&#20102;AdaBoost&#31639;&#27861;&#30340;&#19981;&#21516;&#35270;&#35282;&#65292;&#24182;&#36890;&#36807;&#32479;&#19968;&#30340;&#24418;&#24335;&#21270;&#26041;&#27861;&#23558;&#23427;&#20204;&#30456;&#20114;&#20851;&#32852;&#65292;&#24110;&#21161;&#35835;&#32773;&#26356;&#22909;&#22320;&#29702;&#35299;AdaBoost&#30340;&#21160;&#24577;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25552;&#21319;&#26041;&#27861;&#20110;20&#19990;&#32426;80&#24180;&#20195;&#26411;&#24341;&#20837;&#65292;&#20854;&#20135;&#29983;&#26159;&#22522;&#20110;PAC&#23398;&#20064;&#30340;&#29702;&#35770;&#26041;&#38754;&#12290;&#25552;&#21319;&#26041;&#27861;&#30340;&#20027;&#35201;&#24605;&#24819;&#26159;&#36890;&#36807;&#32452;&#21512;&#24369;&#23398;&#20064;&#22120;&#26469;&#33719;&#24471;&#24378;&#23398;&#20064;&#22120;&#12290;&#24369;&#23398;&#20064;&#22120;&#36890;&#36807;&#21551;&#21457;&#24335;&#31639;&#27861;&#36845;&#20195;&#22320;&#32416;&#27491;&#19978;&#19968;&#20010;&#24369;&#23398;&#20064;&#22120;&#30340;&#38169;&#35823;&#32780;&#33719;&#24471;&#12290;1995&#24180;&#65292;Freund&#21644;Schapire [18]&#24341;&#20837;&#20102;AdaBoost&#65292;&#36825;&#26159;&#19968;&#20010;&#33267;&#20170;&#20173;&#24191;&#27867;&#20351;&#29992;&#30340;&#25552;&#21319;&#31639;&#27861;&#12290;&#33258;&#37027;&#20197;&#21518;&#65292;&#38024;&#23545;&#35813;&#31639;&#27861;&#30340;&#35768;&#22810;&#35270;&#35282;&#34987;&#25552;&#20986;&#26469;&#20197;&#26356;&#22909;&#22320;&#35843;&#25511;&#20854;&#21160;&#24577;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#23581;&#35797;&#28085;&#30422;&#23545;&#20110;AdaBoost&#21487;&#33021;&#23384;&#22312;&#30340;&#25152;&#26377;&#35270;&#35282;&#12290;&#25105;&#20204;&#23558;&#20174;Freund&#21644;Schapire&#30340;&#21407;&#22987;&#35270;&#35282;&#24320;&#22987;&#65292;&#28982;&#21518;&#28085;&#30422;&#19981;&#21516;&#35270;&#35282;&#65292;&#24182;&#20351;&#29992;&#30456;&#21516;&#30340;&#24418;&#24335;&#21270;&#26041;&#27861;&#23558;&#23427;&#20204;&#32479;&#19968;&#36215;&#26469;&#12290;&#25105;&#20204;&#24076;&#26395;&#26412;&#25991;&#33021;&#24110;&#21161;&#38750;&#19987;&#19994;&#35835;&#32773;&#26356;&#22909;&#22320;&#29702;&#35299;AdaBoost&#30340;&#21160;&#24577;&#20197;&#21450;&#19981;&#21516;&#35270;&#35282;&#20043;&#38388;&#30340;&#31561;&#20215;&#24615;&#21644;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Boosting methods have been introduced in the late 1980's. They were born following the theoritical aspect of PAC learning. The main idea of boosting methods is to combine weak learners to obtain a strong learner. The weak learners are obtained iteratively by an heuristic which tries to correct the mistakes of the previous weak learner. In 1995, Freund and Schapire [18] introduced AdaBoost, a boosting algorithm that is still widely used today. Since then, many views of the algorithm have been proposed to properly tame its dynamics. In this paper, we will try to cover all the views that one can have on AdaBoost. We will start with the original view of Freund and Schapire before covering the different views and unify them with the same formalism. We hope this paper will help the non-expert reader to better understand the dynamics of AdaBoost and how the different views are equivalent and related to each other.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Q&#38598;&#25104;&#30340;CATE&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#20854;&#36890;&#36807;&#20351;&#29992;&#21452;&#37325;&#40065;&#26834;&#25439;&#22833;&#23454;&#29616;&#20102;&#32479;&#35745;&#19978;&#30340;&#26368;&#20339;&#39044;&#27979;&#27169;&#22411;&#36873;&#25321;&#36951;&#25022;&#29575;</title><link>http://arxiv.org/abs/2310.16945</link><description>&lt;p&gt;
Causal Q-Aggregation for CATE Model Selection&#65288;CATE&#27169;&#22411;&#36873;&#25321;&#20013;&#30340;&#22240;&#26524;Q&#38598;&#25104;&#65289;
&lt;/p&gt;
&lt;p&gt;
Causal Q-Aggregation for CATE Model Selection. (arXiv:2310.16945v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16945
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Q&#38598;&#25104;&#30340;CATE&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#20854;&#36890;&#36807;&#20351;&#29992;&#21452;&#37325;&#40065;&#26834;&#25439;&#22833;&#23454;&#29616;&#20102;&#32479;&#35745;&#19978;&#30340;&#26368;&#20339;&#39044;&#27979;&#27169;&#22411;&#36873;&#25321;&#36951;&#25022;&#29575;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20934;&#30830;&#20272;&#35745;&#26465;&#20214;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;CATE&#65289;&#26159;&#20010;&#24615;&#21270;&#20915;&#31574;&#30340;&#26680;&#24515;&#12290;&#23613;&#31649;&#26377;&#22823;&#37327;&#29992;&#20110;CATE&#20272;&#35745;&#30340;&#27169;&#22411;&#65292;&#20294;&#30001;&#20110;&#22240;&#26524;&#25512;&#26029;&#30340;&#22522;&#26412;&#38382;&#39064;&#65292;&#27169;&#22411;&#36873;&#25321;&#26159;&#19968;&#39033;&#38750;&#24120;&#26840;&#25163;&#30340;&#20219;&#21153;&#12290;&#26368;&#36817;&#30340;&#23454;&#35777;&#24037;&#20316;&#25552;&#20379;&#20102;&#26377;&#21033;&#20110;&#20855;&#26377;&#21452;&#37325;&#40065;&#26834;&#24615;&#36136;&#30340;&#20195;&#29702;&#25439;&#22833;&#24230;&#37327;&#21644;&#27169;&#22411;&#38598;&#25104;&#30340;&#35777;&#25454;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#36825;&#20123;&#27169;&#22411;&#30340;&#29702;&#35770;&#29702;&#35299;&#36824;&#19981;&#22815;&#12290;&#30452;&#25509;&#24212;&#29992;&#20808;&#21069;&#30340;&#29702;&#35770;&#24037;&#20316;&#20250;&#30001;&#20110;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#30340;&#38750;&#20984;&#24615;&#32780;&#23548;&#33268;&#27425;&#20248;&#30340;&#39044;&#27979;&#27169;&#22411;&#36873;&#25321;&#29575;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#29616;&#26377;&#20027;&#35201;CATE&#38598;&#25104;&#26041;&#27861;&#30340;&#36951;&#25022;&#29575;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21452;&#37325;&#40065;&#26834;&#25439;&#22833;&#30340;Q&#38598;&#25104;&#30340;&#26032;&#30340;CATE&#27169;&#22411;&#38598;&#25104;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#34920;&#26126;&#65292;&#22240;&#26524;Q&#38598;&#25104;&#22312;&#39044;&#27979;&#27169;&#22411;&#36873;&#25321;&#30340;&#36951;&#25022;&#29575;&#19978;&#36798;&#21040;&#20102;&#32479;&#35745;&#19978;&#30340;&#26368;&#20248;&#20540;&#20026;$\frac{\log(M)}{n}$&#65288;&#20854;&#20013;$M$&#20026;&#27169;&#22411;&#25968;&#65292;$n$&#20026;&#26679;&#26412;&#25968;&#65289;&#65292;&#21152;&#19978;&#39640;&#38454;&#20272;&#35745;&#35823;&#24046;&#39033;
&lt;/p&gt;
&lt;p&gt;
Accurate estimation of conditional average treatment effects (CATE) is at the core of personalized decision making. While there is a plethora of models for CATE estimation, model selection is a nontrivial task, due to the fundamental problem of causal inference. Recent empirical work provides evidence in favor of proxy loss metrics with double robust properties and in favor of model ensembling. However, theoretical understanding is lacking. Direct application of prior theoretical work leads to suboptimal oracle model selection rates due to the non-convexity of the model selection problem. We provide regret rates for the major existing CATE ensembling approaches and propose a new CATE model ensembling approach based on Q-aggregation using the doubly robust loss. Our main result shows that causal Q-aggregation achieves statistically optimal oracle model selection regret rates of $\frac{\log(M)}{n}$ (with $M$ models and $n$ samples), with the addition of higher-order estimation error term
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36817;&#20284;&#20449;&#24687;&#26368;&#22823;&#21270;&#30340;&#24378;&#30423;&#28216;&#25103;&#31639;&#27861;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;&#20851;&#38190;&#21464;&#37327;&#30340;&#20449;&#24687;&#36817;&#20284;&#20540;&#26469;&#36827;&#34892;&#20248;&#21270;&#65292;&#22312;&#20256;&#32479;&#24378;&#30423;&#35774;&#32622;&#20013;&#34920;&#29616;&#20986;&#24456;&#24378;&#30340;&#24615;&#33021;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#23545;&#20110;&#20004;&#33218;&#24378;&#30423;&#38382;&#39064;&#30340;&#28176;&#36817;&#26368;&#20248;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.12563</link><description>&lt;p&gt;
&#36866;&#29992;&#20110;&#24378;&#30423;&#28216;&#25103;&#30340;&#36817;&#20284;&#20449;&#24687;&#26368;&#22823;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Approximate information maximization for bandit games. (arXiv:2310.12563v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12563
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36817;&#20284;&#20449;&#24687;&#26368;&#22823;&#21270;&#30340;&#24378;&#30423;&#28216;&#25103;&#31639;&#27861;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;&#20851;&#38190;&#21464;&#37327;&#30340;&#20449;&#24687;&#36817;&#20284;&#20540;&#26469;&#36827;&#34892;&#20248;&#21270;&#65292;&#22312;&#20256;&#32479;&#24378;&#30423;&#35774;&#32622;&#20013;&#34920;&#29616;&#20986;&#24456;&#24378;&#30340;&#24615;&#33021;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#23545;&#20110;&#20004;&#33218;&#24378;&#30423;&#38382;&#39064;&#30340;&#28176;&#36817;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29109;&#26368;&#22823;&#21270;&#21644;&#33258;&#30001;&#33021;&#26368;&#23567;&#21270;&#26159;&#29992;&#20110;&#27169;&#25311;&#21508;&#31181;&#29289;&#29702;&#31995;&#32479;&#21160;&#24577;&#30340;&#19968;&#33324;&#29289;&#29702;&#21407;&#29702;&#12290;&#20854;&#20013;&#21253;&#25324;&#20351;&#29992;&#33258;&#30001;&#33021;&#21407;&#29702;&#23545;&#22823;&#33041;&#20869;&#30340;&#20915;&#31574;&#36827;&#34892;&#24314;&#27169;&#65292;&#20351;&#29992;&#20449;&#24687;&#29942;&#39048;&#21407;&#29702;&#23545;&#35775;&#38382;&#38544;&#34255;&#21464;&#37327;&#26102;&#20248;&#21270;&#20934;&#30830;&#24615;&#21644;&#22797;&#26434;&#24615;&#30340;&#26435;&#34913;&#65292;&#20197;&#21450;&#20351;&#29992;&#20449;&#24687;&#26368;&#22823;&#21270;&#36827;&#34892;&#38543;&#26426;&#29615;&#22659;&#23548;&#33322;&#12290;&#22522;&#20110;&#36825;&#19968;&#21407;&#29702;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24378;&#30423;&#31639;&#27861;&#31867;&#21035;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;&#31995;&#32479;&#20013;&#19968;&#20010;&#20851;&#38190;&#21464;&#37327;&#30340;&#20449;&#24687;&#36817;&#20284;&#26469;&#36827;&#34892;&#20248;&#21270;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#22522;&#20110;&#29289;&#29702;&#30340;&#36817;&#20284;&#20998;&#26512;&#29109;&#30340;&#34920;&#31034;&#26041;&#27861;&#65292;&#20197;&#39044;&#27979;&#27599;&#20010;&#21160;&#20316;&#30340;&#20449;&#24687;&#22686;&#30410;&#65292;&#24182;&#36138;&#23146;&#22320;&#36873;&#25321;&#20449;&#24687;&#22686;&#30410;&#26368;&#22823;&#30340;&#21160;&#20316;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#20256;&#32479;&#24378;&#30423;&#35774;&#32622;&#20013;&#34920;&#29616;&#20986;&#24456;&#24378;&#30340;&#24615;&#33021;&#12290;&#21463;&#21040;&#20854;&#32463;&#39564;&#24615;&#25104;&#21151;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20854;&#23545;&#20110;&#20004;&#33218;&#24378;&#30423;&#38382;&#39064;&#30340;&#28176;&#36817;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Entropy maximization and free energy minimization are general physical principles for modeling the dynamics of various physical systems. Notable examples include modeling decision-making within the brain using the free-energy principle, optimizing the accuracy-complexity trade-off when accessing hidden variables with the information bottleneck principle (Tishby et al., 2000), and navigation in random environments using information maximization (Vergassola et al., 2007). Built on this principle, we propose a new class of bandit algorithms that maximize an approximation to the information of a key variable within the system. To this end, we develop an approximated analytical physics-based representation of an entropy to forecast the information gain of each action and greedily choose the one with the largest information gain. This method yields strong performances in classical bandit settings. Motivated by its empirical success, we prove its asymptotic optimality for the two-armed bandit
&lt;/p&gt;</description></item><item><title>&#26412;&#32508;&#36848;&#31995;&#32479;&#20840;&#38754;&#22320;&#22238;&#39038;&#20102;&#21033;&#29992;&#36830;&#32493;&#21160;&#21147;&#23398;&#26694;&#26550;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#20197;&#24110;&#21161;&#20174;&#26681;&#26412;&#19978;&#29702;&#35299;&#21644;&#25913;&#36827;GNN&#30340;&#33021;&#21147;&#21644;&#32570;&#38519;&#12290;</title><link>http://arxiv.org/abs/2310.10121</link><description>&lt;p&gt;
&#20174;&#36830;&#32493;&#21160;&#21147;&#23398;&#21040;&#22270;&#31070;&#32463;&#32593;&#32476;&#65306;&#31070;&#32463;&#25193;&#25955;&#19982;&#26356;&#22810;
&lt;/p&gt;
&lt;p&gt;
From Continuous Dynamics to Graph Neural Networks: Neural Diffusion and Beyond. (arXiv:2310.10121v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10121
&lt;/p&gt;
&lt;p&gt;
&#26412;&#32508;&#36848;&#31995;&#32479;&#20840;&#38754;&#22320;&#22238;&#39038;&#20102;&#21033;&#29992;&#36830;&#32493;&#21160;&#21147;&#23398;&#26694;&#26550;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#20197;&#24110;&#21161;&#20174;&#26681;&#26412;&#19978;&#29702;&#35299;&#21644;&#25913;&#36827;GNN&#30340;&#33021;&#21147;&#21644;&#32570;&#38519;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#22312;&#24314;&#27169;&#20851;&#31995;&#25968;&#25454;&#26041;&#38754;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#28508;&#21147;&#65292;&#24182;&#22312;&#21508;&#20010;&#39046;&#22495;&#24471;&#21040;&#24191;&#27867;&#24212;&#29992;&#12290;GNN&#32972;&#21518;&#30340;&#20851;&#38190;&#26426;&#21046;&#26159;&#25152;&#35859;&#30340;&#28040;&#24687;&#20256;&#36882;&#65292;&#23427;&#36890;&#36807;&#20174;&#37051;&#23621;&#33410;&#28857;&#20013;&#38598;&#20013;&#22320;&#32858;&#21512;&#20449;&#24687;&#26469;&#36827;&#34892;&#36845;&#20195;&#12290;&#36825;&#31181;&#26041;&#26696;&#19982;&#31216;&#20026;&#28909;&#20256;&#23548;&#30340;&#29289;&#29702;&#36807;&#31243;&#23494;&#20999;&#30456;&#20851;&#65292;&#20854;&#20013;GNN&#30340;&#20256;&#25773;&#33258;&#28982;&#23545;&#24212;&#20110;&#28909;&#23494;&#24230;&#30340;&#28436;&#21270;&#12290;&#23558;&#28040;&#24687;&#20256;&#36882;&#36807;&#31243;&#31867;&#27604;&#20026;&#28909;&#21160;&#21147;&#23398;&#21487;&#20197;&#20174;&#26681;&#26412;&#19978;&#29702;&#35299;GNN&#30340;&#33021;&#21147;&#21644;&#32570;&#38519;&#65292;&#20174;&#32780;&#26377;&#21161;&#20110;&#26356;&#22909;&#22320;&#35774;&#35745;&#27169;&#22411;&#12290;&#26368;&#36817;&#20986;&#29616;&#20102;&#22823;&#37327;&#26088;&#22312;&#20943;&#36731;GNN&#24050;&#30693;&#38480;&#21046;&#65288;&#22914;&#36807;&#24230;&#24179;&#28369;&#21644;&#36807;&#24230;&#21387;&#32553;&#65289;&#30340;GNN&#25552;&#20986;&#20316;&#21697;&#65292;&#36825;&#20123;&#20316;&#21697;&#21463;&#21040;&#36830;&#32493;&#21160;&#21147;&#23398;&#30340;&#21551;&#21457;&#12290;&#22312;&#26412;&#32508;&#36848;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#31995;&#32479;&#20840;&#38754;&#22320;&#22238;&#39038;&#20102;&#21033;&#29992;&#36830;&#32493;&#21160;&#21147;&#23398;&#26694;&#26550;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph neural networks (GNNs) have demonstrated significant promise in modelling relational data and have been widely applied in various fields of interest. The key mechanism behind GNNs is the so-called message passing where information is being iteratively aggregated to central nodes from their neighbourhood. Such a scheme has been found to be intrinsically linked to a physical process known as heat diffusion, where the propagation of GNNs naturally corresponds to the evolution of heat density. Analogizing the process of message passing to the heat dynamics allows to fundamentally understand the power and pitfalls of GNNs and consequently informs better model design. Recently, there emerges a plethora of works that proposes GNNs inspired from the continuous dynamics formulation, in an attempt to mitigate the known limitations of GNNs, such as oversmoothing and oversquashing. In this survey, we provide the first systematic and comprehensive review of studies that leverage the continuou
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20302;&#31209;&#32467;&#26500;&#19979;&#30340;&#30697;&#38453;&#20272;&#35745;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;&#39057;&#35889;&#30340;&#26041;&#27861;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#20272;&#35745;&#22855;&#24322;&#23376;&#31354;&#38388;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#24182;&#19988;&#33021;&#22815;&#23454;&#29616;&#20960;&#20046;&#26368;&#23567;&#30340;&#36880;&#20803;&#32032;&#35823;&#24046;&#12290;&#36825;&#20123;&#26032;&#32467;&#26524;&#20026;&#20805;&#20998;&#21033;&#29992;&#20302;&#31209;&#32467;&#26500;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#30340;&#35774;&#35745;&#25552;&#20379;&#20102;&#21487;&#33021;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.06793</link><description>&lt;p&gt;
&#20302;&#31209;&#24378;&#21270;&#23398;&#20064;&#30340;&#39057;&#35889;&#36880;&#20803;&#32032;&#30697;&#38453;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Spectral Entry-wise Matrix Estimation for Low-Rank Reinforcement Learning. (arXiv:2310.06793v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06793
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20302;&#31209;&#32467;&#26500;&#19979;&#30340;&#30697;&#38453;&#20272;&#35745;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;&#39057;&#35889;&#30340;&#26041;&#27861;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#20272;&#35745;&#22855;&#24322;&#23376;&#31354;&#38388;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#24182;&#19988;&#33021;&#22815;&#23454;&#29616;&#20960;&#20046;&#26368;&#23567;&#30340;&#36880;&#20803;&#32032;&#35823;&#24046;&#12290;&#36825;&#20123;&#26032;&#32467;&#26524;&#20026;&#20805;&#20998;&#21033;&#29992;&#20302;&#31209;&#32467;&#26500;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#30340;&#35774;&#35745;&#25552;&#20379;&#20102;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#24378;&#21270;&#23398;&#20064;&#20013;&#20986;&#29616;&#30340;&#20302;&#31209;&#32467;&#26500;&#30340;&#30697;&#38453;&#20272;&#35745;&#38382;&#39064;&#12290;&#22312;&#20302;&#31209;&#36172;&#21338;&#26426;&#20013;&#65292;&#38656;&#35201;&#24674;&#22797;&#30340;&#30697;&#38453;&#25351;&#23450;&#20102;&#39044;&#26399;&#30340;&#33218;&#22870;&#21169;&#65292;&#32780;&#22312;&#20302;&#31209;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;(MDP)&#20013;&#65292;&#23427;&#21487;&#20197;&#25551;&#36848;MDP&#30340;&#36716;&#25442;&#26680;&#12290;&#22312;&#36825;&#20004;&#31181;&#24773;&#20917;&#19979;&#65292;&#30697;&#38453;&#30340;&#27599;&#20010;&#20803;&#32032;&#37117;&#25215;&#36733;&#37325;&#35201;&#20449;&#24687;&#65292;&#25105;&#20204;&#23547;&#27714;&#20855;&#26377;&#20302;&#36880;&#20803;&#32032;&#35823;&#24046;&#30340;&#20272;&#35745;&#26041;&#27861;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#36825;&#20123;&#26041;&#27861;&#36824;&#38656;&#35201;&#36866;&#24212;&#21487;&#29992;&#25968;&#25454;&#20013;&#30340;&#22266;&#26377;&#30456;&#20851;&#24615;&#65288;&#20363;&#22914;&#65292;&#23545;&#20110;MDPs&#65292;&#25968;&#25454;&#30001;&#31995;&#32479;&#36712;&#36857;&#32452;&#25104;&#65289;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#31616;&#21333;&#30340;&#22522;&#20110;&#39057;&#35889;&#30340;&#30697;&#38453;&#20272;&#35745;&#26041;&#27861;&#30340;&#24615;&#33021;&#65306;&#25105;&#20204;&#23637;&#31034;&#20102;&#23427;&#20204;&#26377;&#25928;&#22320;&#24674;&#22797;&#20102;&#30697;&#38453;&#30340;&#22855;&#24322;&#23376;&#31354;&#38388;&#65292;&#24182;&#19988;&#20855;&#26377;&#20960;&#20046;&#26368;&#23567;&#30340;&#36880;&#20803;&#32032;&#35823;&#24046;&#12290;&#36825;&#20123;&#20851;&#20110;&#20302;&#31209;&#30697;&#38453;&#20272;&#35745;&#30340;&#26032;&#32467;&#26524;&#20351;&#24471;&#35774;&#35745;&#23436;&#20840;&#21033;&#29992;&#24213;&#23618;&#20302;&#31209;&#32467;&#26500;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#25104;&#20026;&#21487;&#33021;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20004;&#20010;&#36825;&#26679;&#30340;&#31639;&#27861;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study matrix estimation problems arising in reinforcement learning (RL) with low-rank structure. In low-rank bandits, the matrix to be recovered specifies the expected arm rewards, and for low-rank Markov Decision Processes (MDPs), it may for example characterize the transition kernel of the MDP. In both cases, each entry of the matrix carries important information, and we seek estimation methods with low entry-wise error. Importantly, these methods further need to accommodate for inherent correlations in the available data (e.g. for MDPs, the data consists of system trajectories). We investigate the performance of simple spectral-based matrix estimation approaches: we show that they efficiently recover the singular subspaces of the matrix and exhibit nearly-minimal entry-wise error. These new results on low-rank matrix estimation make it possible to devise reinforcement learning algorithms that fully exploit the underlying low-rank structure. We provide two examples of such algorit
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#23450;&#20041;&#22312;&#32039;&#33268;Riemannian&#27969;&#24418;&#19978;&#30340;&#20869;&#22312;Matern&#39640;&#26031;&#36807;&#31243;&#21644;&#22806;&#22312;&#36807;&#31243;&#20043;&#38388;&#30340;&#25910;&#32553;&#36895;&#29575;&#65292;&#24182;&#21457;&#29616;&#23427;&#20204;&#30340;&#36895;&#29575;&#22312;&#36866;&#24403;&#21305;&#37197;&#24179;&#28369;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#26159;&#30456;&#31561;&#30340;&#12290;</title><link>http://arxiv.org/abs/2309.10918</link><description>&lt;p&gt;
Riemannian&#27969;&#24418;&#19978;Matern&#39640;&#26031;&#36807;&#31243;&#30340;&#21518;&#39564;&#25910;&#32553;&#36895;&#29575;
&lt;/p&gt;
&lt;p&gt;
Posterior Contraction Rates for Mat\'ern Gaussian Processes on Riemannian Manifolds. (arXiv:2309.10918v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.10918
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#23450;&#20041;&#22312;&#32039;&#33268;Riemannian&#27969;&#24418;&#19978;&#30340;&#20869;&#22312;Matern&#39640;&#26031;&#36807;&#31243;&#21644;&#22806;&#22312;&#36807;&#31243;&#20043;&#38388;&#30340;&#25910;&#32553;&#36895;&#29575;&#65292;&#24182;&#21457;&#29616;&#23427;&#20204;&#30340;&#36895;&#29575;&#22312;&#36866;&#24403;&#21305;&#37197;&#24179;&#28369;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#26159;&#30456;&#31561;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#22312;&#35768;&#22810;&#20381;&#36182;&#20110;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#34987;&#20351;&#29992;&#12290;&#26368;&#36817;&#65292;&#24050;&#32463;&#24320;&#21457;&#20102;&#22312;&#20960;&#20309;&#35774;&#32622;&#19979;&#22788;&#29702;&#36825;&#20123;&#27169;&#22411;&#30340;&#35745;&#31639;&#24037;&#20855;&#65292;&#20363;&#22914;&#65292;&#24403;&#36755;&#20837;&#20301;&#20110;Riemannian&#27969;&#24418;&#19978;&#26102;&#12290;&#36825;&#24341;&#20986;&#20102;&#19968;&#20010;&#38382;&#39064;&#65306;&#36825;&#20123;&#20869;&#22312;&#27169;&#22411;&#22312;&#29702;&#35770;&#19978;&#26159;&#21542;&#21487;&#20197;&#35777;&#26126;&#30456;&#27604;&#20110;&#23558;&#25152;&#26377;&#30456;&#20851;&#37327;&#23884;&#20837;&#21040;$\mathbb{R}^d$&#24182;&#20351;&#29992;&#26222;&#36890;&#27431;&#20960;&#37324;&#24503;&#39640;&#26031;&#36807;&#31243;&#30340;&#38480;&#21046;&#65292;&#21487;&#20197;&#24102;&#26469;&#26356;&#22909;&#30340;&#24615;&#33021;&#65311;&#20026;&#20102;&#30740;&#31350;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23450;&#20041;&#22312;&#32039;&#33268;Riemannian&#27969;&#24418;&#19978;&#30340;&#20869;&#22312;Matern&#39640;&#26031;&#36807;&#31243;&#30340;&#26368;&#20248;&#25910;&#32553;&#36895;&#29575;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#27969;&#24418;&#21644;&#29615;&#22659;Sobolev&#31354;&#38388;&#20043;&#38388;&#30340;&#36857;&#21644;&#25193;&#23637;&#23450;&#29702;&#35777;&#26126;&#20102;&#22806;&#22312;&#36807;&#31243;&#30340;&#31867;&#20284;&#36895;&#29575;&#65306;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#25152;&#24471;&#21040;&#30340;&#36895;&#29575;&#19982;&#20869;&#22312;&#36807;&#31243;&#30340;&#36895;&#29575;&#30456;&#31526;&#65292;&#21069;&#25552;&#26159;&#23427;&#20204;&#30340;&#24179;&#28369;&#21442;&#25968;&#36866;&#24403;&#21305;&#37197;&#12290;&#25105;&#20204;&#22312;&#19968;&#20123;&#23454;&#35777;&#25968;&#25454;&#19978;&#36827;&#34892;&#20102;&#23545;&#36825;&#20123;&#36895;&#29575;&#30340;&#28436;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian processes are used in many machine learning applications that rely on uncertainty quantification. Recently, computational tools for working with these models in geometric settings, such as when inputs lie on a Riemannian manifold, have been developed. This raises the question: can these intrinsic models be shown theoretically to lead to better performance, compared to simply embedding all relevant quantities into $\mathbb{R}^d$ and using the restriction of an ordinary Euclidean Gaussian process? To study this, we prove optimal contraction rates for intrinsic Mat\'ern Gaussian processes defined on compact Riemannian manifolds. We also prove analogous rates for extrinsic processes using trace and extension theorems between manifold and ambient Sobolev spaces: somewhat surprisingly, the rates obtained turn out to coincide with those of the intrinsic processes, provided that their smoothness parameters are matched appropriately. We illustrate these rates empirically on a number of
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38598;&#32676;&#21270;&#30340;&#22810;&#26234;&#33021;&#20307;&#32447;&#24615;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#26234;&#33021;&#20307;&#20043;&#38388;&#30340;&#21327;&#20316;&#26469;&#21152;&#36895;&#20248;&#21270;&#38382;&#39064;&#12290;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#21644;&#23454;&#35777;&#35780;&#20272;&#65292;&#35777;&#26126;&#20102;&#31639;&#27861;&#22312;&#36951;&#25022;&#26368;&#23567;&#21270;&#21644;&#32858;&#31867;&#36136;&#37327;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.08710</link><description>&lt;p&gt;
&#38598;&#32676;&#21270;&#30340;&#22810;&#26234;&#33021;&#20307;&#32447;&#24615;&#36172;&#21338;&#26426;
&lt;/p&gt;
&lt;p&gt;
Clustered Multi-Agent Linear Bandits. (arXiv:2309.08710v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08710
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38598;&#32676;&#21270;&#30340;&#22810;&#26234;&#33021;&#20307;&#32447;&#24615;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#26234;&#33021;&#20307;&#20043;&#38388;&#30340;&#21327;&#20316;&#26469;&#21152;&#36895;&#20248;&#21270;&#38382;&#39064;&#12290;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#21644;&#23454;&#35777;&#35780;&#20272;&#65292;&#35777;&#26126;&#20102;&#31639;&#27861;&#22312;&#36951;&#25022;&#26368;&#23567;&#21270;&#21644;&#32858;&#31867;&#36136;&#37327;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#22810;&#26234;&#33021;&#20307;&#32447;&#24615;&#38543;&#26426;&#36172;&#21338;&#38382;&#39064;&#30340;&#19968;&#20010;&#29305;&#23450;&#23454;&#20363;&#65292;&#21363;&#38598;&#32676;&#21270;&#30340;&#22810;&#26234;&#33021;&#20307;&#32447;&#24615;&#36172;&#21338;&#26426;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#22312;&#36825;&#20010;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#26234;&#33021;&#20307;&#20043;&#38388;&#30340;&#26377;&#25928;&#21327;&#20316;&#26469;&#21152;&#36895;&#25972;&#20307;&#20248;&#21270;&#38382;&#39064;&#12290;&#22312;&#36825;&#19968;&#36129;&#29486;&#20013;&#65292;&#32593;&#32476;&#25511;&#21046;&#22120;&#36127;&#36131;&#20272;&#35745;&#32593;&#32476;&#30340;&#22522;&#26412;&#38598;&#32676;&#32467;&#26500;&#24182;&#20248;&#21270;&#21516;&#19968;&#32452;&#20013;&#26234;&#33021;&#20307;&#20043;&#38388;&#30340;&#32463;&#39564;&#20998;&#20139;&#12290;&#25105;&#20204;&#23545;&#36951;&#25022;&#26368;&#23567;&#21270;&#38382;&#39064;&#21644;&#32858;&#31867;&#36136;&#37327;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#12290;&#36890;&#36807;&#23545;&#21512;&#25104;&#25968;&#25454;&#21644;&#30495;&#23454;&#25968;&#25454;&#36827;&#34892;&#19982;&#26368;&#20808;&#36827;&#31639;&#27861;&#30340;&#23454;&#35777;&#35780;&#20272;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65306;&#25105;&#20204;&#30340;&#31639;&#27861;&#26174;&#33879;&#25913;&#21892;&#20102;&#36951;&#25022;&#26368;&#23567;&#21270;&#65292;&#24182;&#25104;&#21151;&#24674;&#22797;&#20102;&#30495;&#23454;&#30340;&#22522;&#26412;&#38598;&#32676;&#21010;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;
We address in this paper a particular instance of the multi-agent linear stochastic bandit problem, called clustered multi-agent linear bandits. In this setting, we propose a novel algorithm leveraging an efficient collaboration between the agents in order to accelerate the overall optimization problem. In this contribution, a network controller is responsible for estimating the underlying cluster structure of the network and optimizing the experiences sharing among agents within the same groups. We provide a theoretical analysis for both the regret minimization problem and the clustering quality. Through empirical evaluation against state-of-the-art algorithms on both synthetic and real data, we demonstrate the effectiveness of our approach: our algorithm significantly improves regret minimization while managing to recover the true underlying cluster partitioning.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#35774;&#35745;&#20013;&#30340;&#24494;&#22937;&#36873;&#25321;&#65292;&#29305;&#21035;&#20851;&#27880;&#35745;&#31639;&#32479;&#35745;&#24046;&#36317;&#12290;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#39564;&#65292;&#21457;&#29616;&#31232;&#30095;&#21021;&#22987;&#21270;&#21644;&#22686;&#21152;&#32593;&#32476;&#23485;&#24230;&#21487;&#20197;&#25552;&#39640;&#26679;&#26412;&#25928;&#29575;&#65292;&#24182;&#19988;&#21512;&#25104;&#31232;&#30095;&#22855;&#20598;&#20219;&#21153;&#21487;&#20197;&#20316;&#20026;&#30495;&#23454;&#38382;&#39064;&#30340;&#20195;&#29702;&#12290;</title><link>http://arxiv.org/abs/2309.03800</link><description>&lt;p&gt;
&#31070;&#32463;&#29305;&#24449;&#23398;&#20064;&#20013;&#30340;&#24085;&#32047;&#25176;&#21069;&#27839;&#65306;&#25968;&#25454;&#12289;&#35745;&#31639;&#12289;&#23485;&#24230;&#21644;&#36816;&#27668;
&lt;/p&gt;
&lt;p&gt;
Pareto Frontiers in Neural Feature Learning: Data, Compute, Width, and Luck. (arXiv:2309.03800v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03800
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#28145;&#24230;&#23398;&#20064;&#31639;&#27861;&#35774;&#35745;&#20013;&#30340;&#24494;&#22937;&#36873;&#25321;&#65292;&#29305;&#21035;&#20851;&#27880;&#35745;&#31639;&#32479;&#35745;&#24046;&#36317;&#12290;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#39564;&#65292;&#21457;&#29616;&#31232;&#30095;&#21021;&#22987;&#21270;&#21644;&#22686;&#21152;&#32593;&#32476;&#23485;&#24230;&#21487;&#20197;&#25552;&#39640;&#26679;&#26412;&#25928;&#29575;&#65292;&#24182;&#19988;&#21512;&#25104;&#31232;&#30095;&#22855;&#20598;&#20219;&#21153;&#21487;&#20197;&#20316;&#20026;&#30495;&#23454;&#38382;&#39064;&#30340;&#20195;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#35745;&#31639;&#32479;&#35745;&#24046;&#36317;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#28145;&#24230;&#23398;&#20064;&#20013;&#24494;&#22937;&#30340;&#31639;&#27861;&#35774;&#35745;&#36873;&#25321;&#12290;&#25105;&#20204;&#39318;&#20808;&#32771;&#34385;&#20102;&#31163;&#32447;&#31232;&#30095;&#22855;&#20598;&#23398;&#20064;&#65292;&#36825;&#26159;&#19968;&#20010;&#26377;&#20851;&#22810;&#23618;&#24863;&#30693;&#22120;&#26799;&#24230;&#35757;&#32451;&#30340;&#30417;&#30563;&#20998;&#31867;&#38382;&#39064;&#65292;&#20854;&#20855;&#26377;&#32479;&#35745;&#26597;&#35810;&#19979;&#30028;&#12290;&#36825;&#20010;&#19979;&#30028;&#21487;&#20197;&#35299;&#37322;&#20026;&#22810;&#36164;&#28304;&#30340;&#26435;&#34913;&#21069;&#27839;&#65306;&#25104;&#21151;&#23398;&#20064;&#21482;&#26377;&#22312;&#19968;&#20010;&#36275;&#22815;&#20016;&#23500;&#65288;&#22823;&#22411;&#27169;&#22411;&#65289;&#12289;&#30693;&#35782;&#28170;&#21338;&#65288;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#65289;&#12289;&#32784;&#24515;&#65288;&#35757;&#32451;&#36845;&#20195;&#27425;&#25968;&#22810;&#65289;&#25110;&#24184;&#36816;&#65288;&#38543;&#26426;&#29468;&#27979;&#27425;&#25968;&#22810;&#65289;&#30340;&#24773;&#20917;&#19979;&#25165;&#33021;&#21457;&#29983;&#12290;&#25105;&#20204;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#39564;&#34920;&#26126;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#31232;&#30095;&#21021;&#22987;&#21270;&#21644;&#22686;&#21152;&#32593;&#32476;&#23485;&#24230;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#26679;&#26412;&#25928;&#29575;&#12290;&#22312;&#36825;&#37324;&#65292;&#23485;&#24230;&#36215;&#21040;&#20102;&#24182;&#34892;&#25628;&#32034;&#30340;&#20316;&#29992;&#65306;&#23427;&#22686;&#21152;&#20102;&#25214;&#21040;&#8220;&#24184;&#36816;&#31070;&#32463;&#20803;&#8221;&#30340;&#27010;&#29575;&#65292;&#36825;&#20123;&#31070;&#32463;&#20803;&#21487;&#20197;&#26356;&#39640;&#25928;&#22320;&#23398;&#20064;&#31232;&#30095;&#29305;&#24449;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#34920;&#26126;&#21512;&#25104;&#31232;&#30095;&#22855;&#20598;&#20219;&#21153;&#21487;&#20197;&#20316;&#20026;&#30495;&#23454;&#38382;&#39064;&#30340;&#20195;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work investigates the nuanced algorithm design choices for deep learning in the presence of computational-statistical gaps. We begin by considering offline sparse parity learning, a supervised classification problem which admits a statistical query lower bound for gradient-based training of a multilayer perceptron. This lower bound can be interpreted as a multi-resource tradeoff frontier: successful learning can only occur if one is sufficiently rich (large model), knowledgeable (large dataset), patient (many training iterations), or lucky (many random guesses). We show, theoretically and experimentally, that sparse initialization and increasing network width yield significant improvements in sample efficiency in this setting. Here, width plays the role of parallel search: it amplifies the probability of finding "lottery ticket" neurons, which learn sparse features more sample-efficiently. Finally, we show that the synthetic sparse parity task can be useful as a proxy for real pro
&lt;/p&gt;</description></item><item><title>NAS-X&#26159;&#19968;&#31181;&#22522;&#20110;&#25197;&#26354;&#30340;&#31070;&#32463;&#33258;&#36866;&#24212;&#24179;&#28369;&#26041;&#27861;&#65292;&#36890;&#36807;&#37325;&#26032;&#21152;&#26435;&#30340;&#21796;&#37266;-&#30561;&#30496;&#31639;&#27861;&#26469;&#23398;&#20064;&#21644;&#25512;&#26029;&#39034;&#24207;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#24182;&#22312;&#31163;&#25955;&#21644;&#36830;&#32493;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#20248;&#20110;&#20808;&#21069;&#26041;&#27861;&#30340;&#25512;&#26029;&#21644;&#21442;&#25968;&#24674;&#22797;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2308.14864</link><description>&lt;p&gt;
NAS-X: &#22522;&#20110;&#25197;&#26354;&#30340;&#31070;&#32463;&#33258;&#36866;&#24212;&#24179;&#28369;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
NAS-X: Neural Adaptive Smoothing via Twisting. (arXiv:2308.14864v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14864
&lt;/p&gt;
&lt;p&gt;
NAS-X&#26159;&#19968;&#31181;&#22522;&#20110;&#25197;&#26354;&#30340;&#31070;&#32463;&#33258;&#36866;&#24212;&#24179;&#28369;&#26041;&#27861;&#65292;&#36890;&#36807;&#37325;&#26032;&#21152;&#26435;&#30340;&#21796;&#37266;-&#30561;&#30496;&#31639;&#27861;&#26469;&#23398;&#20064;&#21644;&#25512;&#26029;&#39034;&#24207;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#24182;&#22312;&#31163;&#25955;&#21644;&#36830;&#32493;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#20248;&#20110;&#20808;&#21069;&#26041;&#27861;&#30340;&#25512;&#26029;&#21644;&#21442;&#25968;&#24674;&#22797;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;NAS-X&#30340;&#31070;&#32463;&#33258;&#36866;&#24212;&#24179;&#28369;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#37325;&#26032;&#21152;&#26435;&#30340;&#21796;&#37266;-&#30561;&#30496;&#31639;&#27861;&#36827;&#34892;&#39034;&#24207;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#23398;&#20064;&#21644;&#25512;&#26029;&#12290;NAS-X&#36866;&#29992;&#20110;&#31163;&#25955;&#21644;&#36830;&#32493;&#28508;&#21464;&#37327;&#65292;&#24182;&#21033;&#29992;&#24179;&#28369;SMC&#26041;&#27861;&#26469;&#25311;&#21512;&#27604;&#20256;&#32479;&#30340;&#37325;&#26032;&#21152;&#26435;&#21796;&#37266;-&#30561;&#30496;&#26041;&#27861;&#26356;&#24191;&#27867;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#22312;&#31163;&#25955;&#21644;&#36830;&#32493;&#20219;&#21153;&#19978;&#27979;&#35797;&#20102;NAS-X&#65292;&#24182;&#21457;&#29616;&#22312;&#25512;&#26029;&#21644;&#21442;&#25968;&#24674;&#22797;&#26041;&#38754;&#65292;&#23427;&#26126;&#26174;&#20248;&#20110;&#20808;&#21069;&#30340;&#21464;&#20998;&#21644;&#22522;&#20110;&#37325;&#26032;&#21152;&#26435;&#21796;&#37266;-&#30561;&#30496;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present Neural Adaptive Smoothing via Twisting (NAS-X), a method for learning and inference in sequential latent variable models based on reweighted wake-sleep (RWS). NAS-X works with both discrete and continuous latent variables, and leverages smoothing SMC to fit a broader range of models than traditional RWS methods. We test NAS-X on discrete and continuous tasks and find that it substantially outperforms previous variational and RWS-based methods in inference and parameter recovery.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20805;&#28385;&#22242;&#22270;&#30340;&#27010;&#24565;&#65292;&#24182;&#19988;&#21457;&#29616;&#22312;&#31616;&#21333;&#22270;&#20013;&#65292;&#20805;&#28385;&#22242;&#22270;&#30340;&#26368;&#22823;&#25968;&#37327;&#21462;&#20915;&#20110;&#39281;&#21644;&#22797;&#21512;&#20805;&#28385;&#22242;&#22270;&#12290;&#36890;&#36807;&#20855;&#20307;&#35745;&#31639;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#22312;n&#20010;&#39030;&#28857;&#19978;&#20855;&#26377;&#26368;&#22810;&#26368;&#22823;&#22242;&#25968;&#37327;&#30340;&#22270;&#24418;&#24335;&#34920;&#36798;&#24335;&#12290;</title><link>http://arxiv.org/abs/2307.14120</link><description>&lt;p&gt;
&#20316;&#20026;&#35745;&#31639;&#31616;&#21333;&#22270;&#30340;&#26368;&#22823;&#22242;&#30340;&#26368;&#22823;&#25968;&#37327;&#30340;&#25163;&#27573;&#30340;&#20805;&#28385;&#22242;&#22270;
&lt;/p&gt;
&lt;p&gt;
Cliqueful graphs as a means of calculating the maximal number of maximum cliques of simple graphs. (arXiv:2307.14120v1 [math.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.14120
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20805;&#28385;&#22242;&#22270;&#30340;&#27010;&#24565;&#65292;&#24182;&#19988;&#21457;&#29616;&#22312;&#31616;&#21333;&#22270;&#20013;&#65292;&#20805;&#28385;&#22242;&#22270;&#30340;&#26368;&#22823;&#25968;&#37327;&#21462;&#20915;&#20110;&#39281;&#21644;&#22797;&#21512;&#20805;&#28385;&#22242;&#22270;&#12290;&#36890;&#36807;&#20855;&#20307;&#35745;&#31639;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#22312;n&#20010;&#39030;&#28857;&#19978;&#20855;&#26377;&#26368;&#22810;&#26368;&#22823;&#22242;&#25968;&#37327;&#30340;&#22270;&#24418;&#24335;&#34920;&#36798;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#20010;&#31616;&#21333;&#22270;&#22312;n&#20010;&#39030;&#28857;&#19978;&#21487;&#33021;&#21253;&#21547;&#35768;&#22810;&#26368;&#22823;&#22242;&#12290;&#20294;&#23427;&#21487;&#33021;&#21253;&#21547;&#22810;&#23569;&#20010;&#21602;&#65311;&#25105;&#20204;&#23558;&#23637;&#31034;&#26368;&#22823;&#22242;&#30340;&#26368;&#22823;&#25968;&#37327;&#21462;&#20915;&#20110;&#25152;&#35859;&#30340;&#20805;&#28385;&#22242;&#22270;&#65292;&#20855;&#20307;&#22320;&#35828;&#65292;&#22914;&#26524;n&#8805;15&#65292;&#25105;&#20204;&#23558;&#23637;&#31034;&#23427;&#21462;&#20915;&#20110;&#39281;&#21644;&#22797;&#21512;&#20805;&#28385;&#22242;&#22270;&#12290;&#21033;&#29992;&#36825;&#19968;&#28857;&#65292;&#25105;&#20204;&#23558;&#23637;&#31034;&#21253;&#21547;3^{&#8970;n/3&#8971;}c&#20010;&#26368;&#22823;&#22242;&#30340;&#22270;&#22312;n&#20010;&#39030;&#28857;&#19978;&#20855;&#26377;&#26368;&#22810;&#30340;&#26368;&#22823;&#22242;&#25968;&#37327;&#65292;&#20854;&#20013;c&#8712;{1,4/3,2}&#65292;&#21462;&#20915;&#20110;n&#27169;3&#30340;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
A simple graph on $n$ vertices may contain a lot of maximum cliques. But how many can it potentially contain? We will show that the maximum number of maximum cliques is taken over so-called cliqueful graphs, more specifically, later we will show that it is taken over saturated composite cliqueful graphs, if $n \ge 15$. Using this we will show that the graph that contains $3^{\lfloor n/3 \rfloor}c$ maxcliques has the most number of maxcliques on $n$ vertices, where $c\in\{1,\frac{4}{3},2\}$, depending on $n \text{ mod } 3$.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#20559;&#22909;&#30340;&#25919;&#31574;&#23398;&#20064;&#26041;&#27861;&#22312;&#31163;&#32447;&#24773;&#22659;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#20013;&#30340;&#20248;&#21183;&#65292;&#24182;&#36890;&#36807;&#25913;&#36827;&#24314;&#27169;&#21644;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#36825;&#19968;&#26041;&#27861;&#30456;&#27604;&#20854;&#20182;&#25919;&#31574;&#23398;&#20064;&#26041;&#27861;&#20855;&#26377;&#26356;&#20302;&#30340;&#27425;&#20248;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.12975</link><description>&lt;p&gt;
&#20174;&#20154;&#31867;&#20559;&#22909;&#20013;&#23398;&#20064;&#30340;&#25919;&#31574;&#22312;&#24773;&#22659;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#20013;&#30340;&#21487;&#35777;&#26126;&#20248;&#21183;
&lt;/p&gt;
&lt;p&gt;
Provable Benefits of Policy Learning from Human Preferences in Contextual Bandit Problems. (arXiv:2307.12975v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12975
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#20559;&#22909;&#30340;&#25919;&#31574;&#23398;&#20064;&#26041;&#27861;&#22312;&#31163;&#32447;&#24773;&#22659;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#20013;&#30340;&#20248;&#21183;&#65292;&#24182;&#36890;&#36807;&#25913;&#36827;&#24314;&#27169;&#21644;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#36825;&#19968;&#26041;&#27861;&#30456;&#27604;&#20854;&#20182;&#25919;&#31574;&#23398;&#20064;&#26041;&#27861;&#20855;&#26377;&#26356;&#20302;&#30340;&#27425;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20915;&#31574;&#38382;&#39064;&#20013;&#65292;&#22870;&#21169;&#24037;&#31243;&#26159;&#19968;&#20010;&#20851;&#38190;&#30340;&#20219;&#21153;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#24448;&#24448;&#19981;&#23384;&#22312;&#26126;&#26174;&#30340;&#22870;&#21169;&#20989;&#25968;&#36873;&#25321;&#12290;&#22240;&#27492;&#65292;&#19968;&#31181;&#24120;&#35265;&#30340;&#26041;&#27861;&#26159;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#24341;&#20837;&#20154;&#31867;&#21453;&#39304;&#65292;&#24182;&#21033;&#29992;&#36825;&#31181;&#21453;&#39304;&#26469;&#23398;&#20064;&#22870;&#21169;&#20989;&#25968;&#12290;&#22312;&#20351;&#29992;&#20154;&#31867;&#21453;&#39304;&#30340;&#25152;&#26377;&#25919;&#31574;&#23398;&#20064;&#26041;&#27861;&#20013;&#65292;&#22522;&#20110;&#20559;&#22909;&#30340;&#26041;&#27861;&#22312;&#26368;&#36817;&#30340;&#23454;&#35777;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#65292;&#22914;InstructGPT&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#29702;&#35770;&#65292;&#21487;&#20197;&#35777;&#26126;&#22312;&#31163;&#32447;&#24773;&#22659;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#20013;&#65292;&#22522;&#20110;&#20559;&#22909;&#30340;&#26041;&#27861;&#20855;&#26377;&#26174;&#33879;&#30340;&#20248;&#21183;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25913;&#36827;&#20102;&#22312;&#20154;&#31867;&#35780;&#20998;&#26679;&#26412;&#19978;&#36816;&#34892;&#25919;&#31574;&#23398;&#20064;&#26041;&#27861;&#30340;&#24314;&#27169;&#21644;&#27425;&#20248;&#24615;&#20998;&#26512;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#20854;&#19982;&#22522;&#20110;&#20559;&#22909;&#30340;&#26041;&#27861;&#30340;&#27425;&#20248;&#24615;&#20445;&#35777;&#36827;&#34892;&#27604;&#36739;&#65292;&#24182;&#34920;&#26126;&#22522;&#20110;&#20559;&#22909;&#30340;&#26041;&#27861;&#20139;&#26377;&#26356;&#20302;&#30340;&#27425;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
A crucial task in decision-making problems is reward engineering. It is common in practice that no obvious choice of reward function exists. Thus, a popular approach is to introduce human feedback during training and leverage such feedback to learn a reward function. Among all policy learning methods that use human feedback, preference-based methods have demonstrated substantial success in recent empirical applications such as InstructGPT. In this work, we develop a theory that provably shows the benefits of preference-based methods in offline contextual bandits. In particular, we improve the modeling and suboptimality analysis for running policy learning methods on human-scored samples directly. Then, we compare it with the suboptimality guarantees of preference-based methods and show that preference-based methods enjoy lower suboptimality.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20174;&#27169;&#22411;&#22797;&#26434;&#24615;&#30340;&#35282;&#24230;&#37325;&#26032;&#24605;&#32771;&#29983;&#25104;&#24314;&#27169;&#30340;&#28508;&#22312;&#31354;&#38388;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#28508;&#22312;&#19982;&#25968;&#25454;&#20998;&#24067;&#20043;&#38388;&#30340;&#8220;&#36317;&#31163;&#8221;&#65292;&#24182;&#36890;&#36807;&#35813;&#36317;&#31163;&#30340;&#26368;&#23567;&#21270;&#26469;&#20248;&#21270;&#29983;&#25104;&#22120;&#30340;&#22797;&#26434;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.08283</link><description>&lt;p&gt;
&#22797;&#26434;&#24615;&#33267;&#20851;&#37325;&#35201;&#65306;&#37325;&#26032;&#24605;&#32771;&#29983;&#25104;&#24314;&#27169;&#30340;&#28508;&#22312;&#31354;&#38388;
&lt;/p&gt;
&lt;p&gt;
Complexity Matters: Rethinking the Latent Space for Generative Modeling. (arXiv:2307.08283v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08283
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20174;&#27169;&#22411;&#22797;&#26434;&#24615;&#30340;&#35282;&#24230;&#37325;&#26032;&#24605;&#32771;&#29983;&#25104;&#24314;&#27169;&#30340;&#28508;&#22312;&#31354;&#38388;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#28508;&#22312;&#19982;&#25968;&#25454;&#20998;&#24067;&#20043;&#38388;&#30340;&#8220;&#36317;&#31163;&#8221;&#65292;&#24182;&#36890;&#36807;&#35813;&#36317;&#31163;&#30340;&#26368;&#23567;&#21270;&#26469;&#20248;&#21270;&#29983;&#25104;&#22120;&#30340;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29983;&#25104;&#24314;&#27169;&#20013;&#65292;&#35768;&#22810;&#25104;&#21151;&#30340;&#26041;&#27861;&#21033;&#29992;&#20302;&#32500;&#28508;&#22312;&#31354;&#38388;&#65292;&#20363;&#22914;&#65292;&#31283;&#23450;&#25193;&#25955;&#27169;&#22411;&#36890;&#36807;&#32534;&#30721;&#22120;&#24341;&#23548;&#30340;&#28508;&#22312;&#31354;&#38388;&#29983;&#25104;&#22270;&#20687;&#65292;&#24182;&#36890;&#36807;&#37197;&#23545;&#30340;&#35299;&#30721;&#22120;&#36827;&#34892;&#29983;&#25104;&#12290;&#23613;&#31649;&#28508;&#22312;&#31354;&#38388;&#30340;&#36873;&#25321;&#22312;&#23454;&#36341;&#20013;&#38750;&#24120;&#37325;&#35201;&#65292;&#20294;&#30830;&#23450;&#26368;&#20248;&#36873;&#25321;&#21644;&#35782;&#21035;&#36807;&#31243;&#20173;&#19981;&#28165;&#26970;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#20174;&#27169;&#22411;&#22797;&#26434;&#24615;&#30340;&#35282;&#24230;&#37325;&#26032;&#24605;&#32771;&#28508;&#22312;&#31354;&#38388;&#65292;&#26469;&#25581;&#31034;&#36825;&#20010;&#26410;&#34987;&#20805;&#20998;&#25506;&#32034;&#30340;&#35805;&#39064;&#12290;&#25105;&#20204;&#30340;&#35843;&#26597;&#20174;&#32463;&#20856;&#30340;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GANs&#65289;&#24320;&#22987;&#12290;&#21463;&#21040;GAN&#35757;&#32451;&#30446;&#26631;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#28508;&#22312;&#19982;&#25968;&#25454;&#20998;&#24067;&#20043;&#38388;&#30340;&#8220;&#36317;&#31163;&#8221;&#65292;&#20854;&#26368;&#23567;&#21270;&#19982;&#29983;&#25104;&#22120;&#30340;&#22797;&#26434;&#24615;&#26368;&#23567;&#21270;&#30456;&#19968;&#33268;&#12290;&#36825;&#20010;&#36317;&#31163;&#30340;&#26368;&#23567;&#21270;&#32773;&#34987;&#25551;&#36848;&#20026;&#33021;&#22815;&#26368;&#26377;&#25928;&#22320;&#21033;&#29992;&#29983;&#25104;&#22120;&#23481;&#37327;&#30340;&#26368;&#20339;&#25968;&#25454;&#30456;&#20851;&#30340;&#28508;&#22312;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#32771;&#34385;&#36890;&#36807;&#32534;&#30721;&#22120;&#32593;&#32476;&#23545;&#36825;&#26679;&#30340;&#28508;&#22312;&#20998;&#24067;&#36827;&#34892;&#21442;&#25968;&#21270;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#26041;&#27861;...
&lt;/p&gt;
&lt;p&gt;
In generative modeling, numerous successful approaches leverage a low-dimensional latent space, e.g., Stable Diffusion models the latent space induced by an encoder and generates images through a paired decoder. Although the selection of the latent space is empirically pivotal, determining the optimal choice and the process of identifying it remain unclear. In this study, we aim to shed light on this under-explored topic by rethinking the latent space from the perspective of model complexity. Our investigation starts with the classic generative adversarial networks (GANs). Inspired by the GAN training objective, we propose a novel "distance" between the latent and data distributions, whose minimization coincides with that of the generator complexity. The minimizer of this distance is characterized as the optimal data-dependent latent that most effectively capitalizes on the generator's capacity. Then, we consider parameterizing such a latent distribution by an encoder network and propo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#25968;&#20540;&#19981;&#31283;&#23450;&#24615;&#23545;&#21464;&#20998;&#27969;&#20013;&#37319;&#26679;&#12289;&#23494;&#24230;&#35780;&#20272;&#21644;ELBO&#20272;&#35745;&#30340;&#21487;&#38752;&#24615;&#30340;&#24433;&#21709;&#12290;&#36890;&#36807;&#29702;&#35770;&#20445;&#35777;&#21644;&#23454;&#39564;&#39564;&#35777;&#65292;&#25105;&#20204;&#21457;&#29616;&#23613;&#31649;&#23384;&#22312;&#20005;&#37325;&#30340;&#25968;&#20540;&#19981;&#31283;&#23450;&#24615;&#65292;&#21464;&#20998;&#27969;&#20135;&#29983;&#30340;&#32467;&#26524;&#22312;&#24212;&#29992;&#20013;&#24120;&#24120;&#36275;&#22815;&#20934;&#30830;&#12290;</title><link>http://arxiv.org/abs/2307.06957</link><description>&lt;p&gt;
&#25317;&#25265;&#28151;&#20081;&#65306;&#25968;&#20540;&#19981;&#31283;&#23450;&#24615;&#22312;&#21464;&#20998;&#27969;&#20013;&#30340;&#20998;&#26512;&#21644;&#35786;&#26029;
&lt;/p&gt;
&lt;p&gt;
Embracing the chaos: analysis and diagnosis of numerical instability in variational flows. (arXiv:2307.06957v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06957
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#25968;&#20540;&#19981;&#31283;&#23450;&#24615;&#23545;&#21464;&#20998;&#27969;&#20013;&#37319;&#26679;&#12289;&#23494;&#24230;&#35780;&#20272;&#21644;ELBO&#20272;&#35745;&#30340;&#21487;&#38752;&#24615;&#30340;&#24433;&#21709;&#12290;&#36890;&#36807;&#29702;&#35770;&#20445;&#35777;&#21644;&#23454;&#39564;&#39564;&#35777;&#65292;&#25105;&#20204;&#21457;&#29616;&#23613;&#31649;&#23384;&#22312;&#20005;&#37325;&#30340;&#25968;&#20540;&#19981;&#31283;&#23450;&#24615;&#65292;&#21464;&#20998;&#27969;&#20135;&#29983;&#30340;&#32467;&#26524;&#22312;&#24212;&#29992;&#20013;&#24120;&#24120;&#36275;&#22815;&#20934;&#30830;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#25968;&#20540;&#19981;&#31283;&#23450;&#24615;&#23545;&#21464;&#20998;&#27969;&#20013;&#37319;&#26679;&#12289;&#23494;&#24230;&#35780;&#20272;&#21644;&#35777;&#25454;&#19979;&#30028;&#65288;ELBO&#65289;&#20272;&#35745;&#30340;&#21487;&#38752;&#24615;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#39318;&#20808;&#36890;&#36807;&#23454;&#35777;&#39564;&#35777;&#20102;&#24120;&#35265;&#27969;&#21487;&#33021;&#20986;&#29616;&#20005;&#37325;&#30340;&#38169;&#35823;&#32047;&#31215;&#65306;&#25968;&#20540;&#27969;&#26144;&#23556;&#19982;&#31934;&#30830;&#26144;&#23556;&#30340;&#20559;&#24046;&#26174;&#33879;&#65292;&#24433;&#21709;&#37319;&#26679;&#65307;&#25968;&#20540;&#36870;&#27969;&#26144;&#23556;&#26080;&#27861;&#20934;&#30830;&#24674;&#22797;&#21021;&#22987;&#36755;&#20837;&#65292;&#24433;&#21709;&#23494;&#24230;&#21644;ELBO&#35745;&#31639;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#24778;&#35766;&#22320;&#21457;&#29616;&#65292;&#23613;&#31649;&#23384;&#22312;&#20005;&#37325;&#30340;&#25968;&#20540;&#19981;&#31283;&#23450;&#24615;&#65292;&#27969;&#20135;&#29983;&#30340;&#32467;&#26524;&#24120;&#24120;&#36275;&#22815;&#20934;&#30830;&#24212;&#23545;&#24212;&#29992;&#38656;&#27714;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23558;&#21464;&#20998;&#27969;&#35270;&#20026;&#21160;&#21147;&#31995;&#32479;&#65292;&#24182;&#21033;&#29992;&#38452;&#24433;&#29702;&#35770;&#36890;&#36807;&#29702;&#35770;&#20445;&#35777;&#23545;&#37319;&#26679;&#12289;&#23494;&#24230;&#35780;&#20272;&#21644;ELBO&#20272;&#35745;&#30340;&#38169;&#35823;&#26469;&#38416;&#26126;&#36825;&#31181;&#34892;&#20026;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#24320;&#21457;&#24182;&#32463;&#39564;&#24615;&#22320;&#27979;&#35797;&#20102;&#19968;&#31181;&#21487;&#20197;&#29992;&#20110;&#39564;&#35777;&#25968;&#20540;&#32467;&#26524;&#30340;&#35786;&#26029;&#31243;&#24207;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we investigate the impact of numerical instability on the reliability of sampling, density evaluation, and evidence lower bound (ELBO) estimation in variational flows. We first empirically demonstrate that common flows can exhibit a catastrophic accumulation of error: the numerical flow map deviates significantly from the exact map -- which affects sampling -- and the numerical inverse flow map does not accurately recover the initial input -which affects density and ELBO computations. Surprisingly though, we find that results produced by flows are often accurate enough for applications despite the presence of serious numerical instability. In this work, we treat variational flows as dynamical systems, and leverage shadowing theory to elucidate this behavior via theoretical guarantees on the error of sampling, density evaluation, and ELBO estimation. Finally, we develop and empirically test a diagnostic procedure that can be used to validate results produced by numerica
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23545;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#21644;&#27169;&#22411;&#20043;&#38388;&#30340;$\beta$-&#20998;&#35299;&#36827;&#34892;&#21518;&#39564;&#37319;&#26679;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;$\beta$D-Bayes&#65292;&#19968;&#31181;&#33021;&#22815;&#23454;&#29616;&#24046;&#20998;&#26426;&#22120;&#23398;&#20064;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.05194</link><description>&lt;p&gt;
&#36890;&#36807;$\beta$-&#20998;&#35299;&#19968;&#21518;&#39564;&#37319;&#26679;&#23454;&#29616;&#24046;&#20998;&#35745;&#31639;&#26426;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Statistical Inference through $\beta$-Divergence One Posterior Sampling. (arXiv:2307.05194v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05194
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#21644;&#27169;&#22411;&#20043;&#38388;&#30340;$\beta$-&#20998;&#35299;&#36827;&#34892;&#21518;&#39564;&#37319;&#26679;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;$\beta$D-Bayes&#65292;&#19968;&#31181;&#33021;&#22815;&#23454;&#29616;&#24046;&#20998;&#26426;&#22120;&#23398;&#20064;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24046;&#20998;&#31169;&#23494;&#24615;&#30830;&#20445;&#20102;&#21253;&#21547;&#25935;&#24863;&#25968;&#25454;&#30340;&#32479;&#35745;&#20998;&#26512;&#32467;&#26524;&#21487;&#20197;&#22312;&#19981;&#25439;&#23475;&#20219;&#20309;&#20010;&#20307;&#38544;&#31169;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#21457;&#24067;&#12290;&#23454;&#29616;&#36825;&#31181;&#20445;&#35777;&#36890;&#24120;&#38656;&#35201;&#22312;&#21442;&#25968;&#20272;&#35745;&#25110;&#20272;&#35745;&#36807;&#31243;&#20013;&#30452;&#25509;&#27880;&#20837;&#22122;&#38899;&#12290;&#32780;&#37319;&#26679;&#26469;&#33258;&#36125;&#21494;&#26031;&#21518;&#39564;&#20998;&#24067;&#24050;&#34987;&#35777;&#26126;&#26159;&#25351;&#25968;&#26426;&#21046;&#30340;&#19968;&#31181;&#29305;&#27530;&#24773;&#20917;&#65292;&#21487;&#20197;&#20135;&#29983;&#19968;&#33268;&#19988;&#39640;&#25928;&#30340;&#31169;&#23494;&#20272;&#35745;&#65292;&#32780;&#19981;&#20250;&#25913;&#21464;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#26041;&#27861;&#30340;&#24212;&#29992;&#21463;&#21040;&#36739;&#24378;&#30340;&#36793;&#30028;&#20551;&#35774;&#30340;&#38480;&#21046;&#65292;&#36825;&#20123;&#20551;&#35774;&#23545;&#20110;&#22522;&#26412;&#27169;&#22411;&#65288;&#22914;&#31616;&#21333;&#30340;&#32447;&#24615;&#22238;&#24402;&#22120;&#65289;&#24182;&#19981;&#25104;&#31435;&#12290;&#20026;&#20102;&#25913;&#21892;&#36825;&#19968;&#28857;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;$\beta$D-Bayes&#65292;&#19968;&#31181;&#20174;&#24191;&#20041;&#21518;&#39564;&#20013;&#36827;&#34892;&#21518;&#39564;&#37319;&#26679;&#30340;&#26041;&#26696;&#65292;&#30446;&#26631;&#26159;&#26368;&#23567;&#21270;&#27169;&#22411;&#19982;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#20043;&#38388;&#30340;$\beta$-&#20998;&#35299;&#12290;&#36825;&#25552;&#20379;&#20102;&#31169;&#23494;&#20272;&#35745;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Differential privacy guarantees allow the results of a statistical analysis involving sensitive data to be released without compromising the privacy of any individual taking part. Achieving such guarantees generally requires the injection of noise, either directly into parameter estimates or into the estimation process. Instead of artificially introducing perturbations, sampling from Bayesian posterior distributions has been shown to be a special case of the exponential mechanism, producing consistent, and efficient private estimates without altering the data generative process. The application of current approaches has, however, been limited by their strong bounding assumptions which do not hold for basic models, such as simple linear regressors. To ameliorate this, we propose $\beta$D-Bayes, a posterior sampling scheme from a generalised posterior targeting the minimisation of the $\beta$-divergence between the model and the data generating process. This provides private estimation t
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#21487;&#23454;&#29616;&#22238;&#24402;&#38382;&#39064;&#30340;PAC&#23398;&#20064;&#21644;&#22312;&#32447;&#23398;&#20064;&#30340;&#32479;&#35745;&#22797;&#26434;&#24230;&#65292;&#24182;&#25552;&#20986;&#20102;&#23545;&#20110;&#21487;&#23398;&#20064;&#24615;&#30340;&#24517;&#35201;&#26465;&#20214;&#21644;&#20805;&#20998;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2307.03848</link><description>&lt;p&gt;
&#21487;&#23454;&#29616;&#22238;&#24402;&#30340;&#26368;&#20248;&#23398;&#20064;&#31639;&#27861;&#65306;PAC&#23398;&#20064;&#21644;&#22312;&#32447;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Optimal Learners for Realizable Regression: PAC Learning and Online Learning. (arXiv:2307.03848v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03848
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#21487;&#23454;&#29616;&#22238;&#24402;&#38382;&#39064;&#30340;PAC&#23398;&#20064;&#21644;&#22312;&#32447;&#23398;&#20064;&#30340;&#32479;&#35745;&#22797;&#26434;&#24230;&#65292;&#24182;&#25552;&#20986;&#20102;&#23545;&#20110;&#21487;&#23398;&#20064;&#24615;&#30340;&#24517;&#35201;&#26465;&#20214;&#21644;&#20805;&#20998;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#26088;&#22312;&#23545;&#21487;&#23454;&#29616;&#22238;&#24402;&#22312;PAC&#23398;&#20064;&#21644;&#22312;&#32447;&#23398;&#20064;&#30340;&#32479;&#35745;&#22797;&#26434;&#24230;&#36827;&#34892;&#21051;&#30011;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#35777;&#26126;&#20102;&#26377;&#38480;&#30340;fat shattering&#32500;&#24230;&#23545;&#20110;PAC&#23398;&#20064;&#30340;&#20805;&#20998;&#24615;&#20197;&#21450;&#26377;&#38480;&#30340;scaled Natarajan&#32500;&#24230;&#23545;&#20110;&#24517;&#35201;&#24615;&#30340;&#23384;&#22312;&#65292;&#20294;&#33258;&#20174;Simon 1997&#65288;SICOMP '97&#65289;&#30340;&#24037;&#20316;&#20197;&#26469;&#65292;&#23545;&#20110;&#26356;&#23436;&#25972;&#30340;&#21051;&#30011;&#30340;&#36827;&#23637;&#29978;&#23569;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#39318;&#20808;&#24341;&#20837;&#20102;&#19968;&#31181;&#26368;&#23567;&#21270;&#23454;&#20363;&#26368;&#20248;&#23398;&#20064;&#31639;&#27861;&#26469;&#23545;&#21487;&#23454;&#29616;&#22238;&#24402;&#36827;&#34892;&#23398;&#20064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26082;&#23450;&#24615;&#21448;&#23450;&#37327;&#22320;&#21051;&#30011;&#20102;&#21738;&#20123;&#31867;&#30340;&#23454;&#25968;&#39044;&#27979;&#22120;&#21487;&#20197;&#34987;&#23398;&#20064;&#30340;&#26032;&#39062;&#32500;&#24230;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#19968;&#20010;&#19982;&#22270;&#32500;&#24230;&#30456;&#20851;&#30340;&#32452;&#21512;&#32500;&#24230;&#65292;&#35813;&#32500;&#24230;&#21051;&#30011;&#20102;&#22312;&#21487;&#23454;&#29616;&#35774;&#32622;&#20013;&#30340;ERM&#21487;&#23398;&#20064;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#26681;&#25454;&#19982;DS&#32500;&#24230;&#30456;&#20851;&#30340;&#32452;&#21512;&#32500;&#24230;&#24314;&#31435;&#20102;&#23398;&#20064;&#21487;&#34892;&#24615;&#30340;&#24517;&#35201;&#26465;&#20214;&#65292;&#24182;&#29468;&#27979;&#23427;&#20063;&#21487;&#33021;&#26159;&#20805;&#20998;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we aim to characterize the statistical complexity of realizable regression both in the PAC learning setting and the online learning setting.  Previous work had established the sufficiency of finiteness of the fat shattering dimension for PAC learnability and the necessity of finiteness of the scaled Natarajan dimension, but little progress had been made towards a more complete characterization since the work of Simon 1997 (SICOMP '97). To this end, we first introduce a minimax instance optimal learner for realizable regression and propose a novel dimension that both qualitatively and quantitatively characterizes which classes of real-valued predictors are learnable. We then identify a combinatorial dimension related to the Graph dimension that characterizes ERM learnability in the realizable setting. Finally, we establish a necessary condition for learnability based on a combinatorial dimension related to the DS dimension, and conjecture that it may also be sufficient in 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#27169;&#22411;&#38169;&#35823;&#19979;&#30340;&#26465;&#20214;&#29420;&#31435;&#24615;&#26816;&#39564;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#25552;&#20986;&#20102;&#26032;&#30340;&#36817;&#20284;&#25110;&#19978;&#30028;&#26469;&#34913;&#37327;&#22522;&#20110;&#22238;&#24402;&#30340;&#27979;&#35797;&#30340;&#27979;&#35797;&#35823;&#24046;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#22238;&#24402;&#30340;CI&#26816;&#39564;&#26041;&#27861;RBPT&#65292;&#23545;&#27169;&#22411;&#38169;&#35823;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.02520</link><description>&lt;p&gt;
&#27169;&#22411;&#38169;&#35823;&#19979;&#30340;&#26465;&#20214;&#29420;&#31435;&#24615;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Conditional independence testing under model misspecification. (arXiv:2307.02520v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02520
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#27169;&#22411;&#38169;&#35823;&#19979;&#30340;&#26465;&#20214;&#29420;&#31435;&#24615;&#26816;&#39564;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#25552;&#20986;&#20102;&#26032;&#30340;&#36817;&#20284;&#25110;&#19978;&#30028;&#26469;&#34913;&#37327;&#22522;&#20110;&#22238;&#24402;&#30340;&#27979;&#35797;&#30340;&#27979;&#35797;&#35823;&#24046;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#22238;&#24402;&#30340;CI&#26816;&#39564;&#26041;&#27861;RBPT&#65292;&#23545;&#27169;&#22411;&#38169;&#35823;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26465;&#20214;&#29420;&#31435;&#24615;&#65288;CI&#65289;&#26816;&#39564;&#26159;&#29616;&#20195;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#22522;&#30784;&#19988;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#12290;&#35768;&#22810;&#29616;&#20195;&#30340;CI&#26816;&#39564;&#26041;&#27861;&#20381;&#36182;&#20110;&#24378;&#22823;&#30340;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#26469;&#23398;&#20064;&#22238;&#24402;&#20989;&#25968;&#25110;&#36125;&#21494;&#26031;&#39044;&#27979;&#22120;&#20316;&#20026;&#20013;&#38388;&#27493;&#39588;&#12290;&#23613;&#31649;&#36825;&#20123;&#26041;&#27861;&#22312;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#20934;&#30830;&#20272;&#35745;&#22238;&#24402;&#20989;&#25968;&#25110;&#36125;&#21494;&#26031;&#39044;&#27979;&#22120;&#26102;&#20445;&#35777;&#20102;&#25511;&#21046;&#31532;&#19968;&#31867;&#38169;&#35823;&#65292;&#20294;&#23427;&#20204;&#22312;&#27169;&#22411;&#38169;&#35823;&#23548;&#33268;&#22833;&#36133;&#26102;&#30340;&#34892;&#20026;&#23578;&#19981;&#28165;&#26970;&#12290;&#20174;&#26356;&#24191;&#27867;&#30340;&#24847;&#20041;&#19978;&#35762;&#65292;&#21363;&#20351;&#20351;&#29992;&#20102;&#36890;&#29992;&#36924;&#36817;&#22120;&#65288;&#20363;&#22914;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65289;&#65292;&#27169;&#22411;&#38169;&#35823;&#20063;&#21487;&#33021;&#20986;&#29616;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#27169;&#22411;&#38169;&#35823;&#19979;&#30340;&#22522;&#20110;&#22238;&#24402;&#30340;CI&#26816;&#39564;&#30340;&#24615;&#33021;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26032;&#30340;&#36817;&#20284;&#25110;&#19978;&#30028;&#26469;&#34913;&#37327;&#20381;&#36182;&#20110;&#38169;&#35823;&#30340;&#19977;&#20010;&#22522;&#20110;&#22238;&#24402;&#30340;&#27979;&#35797;&#30340;&#27979;&#35797;&#35823;&#24046;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;Rao-Blackwellized Predictor Test&#65288;RBPT&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#22238;&#24402;&#30340;CI&#26816;&#39564;&#65292;&#23545;&#27169;&#22411;&#38169;&#35823;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conditional independence (CI) testing is fundamental and challenging in modern statistics and machine learning. Many modern methods for CI testing rely on powerful supervised learning methods to learn regression functions or Bayes predictors as an intermediate step. Although the methods are guaranteed to control Type-I error when the supervised learning methods accurately estimate the regression functions or Bayes predictors, their behavior is less understood when they fail due to model misspecification. In a broader sense, model misspecification can arise even when universal approximators (e.g., deep neural nets) are employed. Then, we study the performance of regression-based CI tests under model misspecification. Namely, we propose new approximations or upper bounds for the testing errors of three regression-based tests that depend on misspecification errors. Moreover, we introduce the Rao-Blackwellized Predictor Test (RBPT), a novel regression-based CI test robust against model mis
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#35745;&#31639;&#26368;&#20248;&#36755;&#36816;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20999;&#29255;Wasserstein&#24191;&#20041;&#27979;&#22320;&#32447;&#36827;&#34892;&#36817;&#20284;&#65292;&#24471;&#21040;&#20102;&#19968;&#20010;&#22522;&#20110;&#19968;&#32500;&#26368;&#20248;&#25237;&#24433;&#30340;&#20195;&#29702;&#36317;&#31163;min-SWGG&#65292;&#24182;&#25552;&#20379;&#20102;&#30456;&#20851;&#30340;&#20256;&#36755;&#35745;&#21010;&#12290;&#36825;&#31181;&#26041;&#27861;&#20855;&#26377;&#36739;&#20302;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#36866;&#29992;&#20110;&#20248;&#21270;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.01770</link><description>&lt;p&gt;
&#24555;&#36895;&#36890;&#36807;&#20999;&#29255;Wasserstein&#24191;&#20041;&#27979;&#22320;&#32447;&#23454;&#29616;&#26368;&#20248;&#36755;&#36816;
&lt;/p&gt;
&lt;p&gt;
Fast Optimal Transport through Sliced Wasserstein Generalized Geodesics. (arXiv:2307.01770v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01770
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#35745;&#31639;&#26368;&#20248;&#36755;&#36816;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20999;&#29255;Wasserstein&#24191;&#20041;&#27979;&#22320;&#32447;&#36827;&#34892;&#36817;&#20284;&#65292;&#24471;&#21040;&#20102;&#19968;&#20010;&#22522;&#20110;&#19968;&#32500;&#26368;&#20248;&#25237;&#24433;&#30340;&#20195;&#29702;&#36317;&#31163;min-SWGG&#65292;&#24182;&#25552;&#20379;&#20102;&#30456;&#20851;&#30340;&#20256;&#36755;&#35745;&#21010;&#12290;&#36825;&#31181;&#26041;&#27861;&#20855;&#26377;&#36739;&#20302;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#36866;&#29992;&#20110;&#20248;&#21270;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Wassserstein&#36317;&#31163;&#21644;&#30456;&#20851;&#30340;&#26368;&#20248;&#36755;&#36816;&#35745;&#21010;&#22312;&#35768;&#22810;&#28041;&#21450;&#27010;&#29575;&#24230;&#37327;&#30340;&#24212;&#29992;&#20013;&#34987;&#35777;&#26126;&#26159;&#26377;&#29992;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#24179;&#26041;Wasserstein&#36317;&#31163;&#30340;&#20195;&#29702;&#65292;&#31216;&#20026;min-SWGG&#65292;&#23427;&#22522;&#20110;&#20004;&#20010;&#36755;&#20837;&#20998;&#24067;&#30340;&#19968;&#32500;&#26368;&#20248;&#25237;&#24433;&#24341;&#23548;&#30340;&#36816;&#36755;&#26144;&#23556;&#12290;&#25105;&#20204;&#22312;min-SWGG&#21644;Wasserstein&#24191;&#20041;&#27979;&#22320;&#32447;&#20043;&#38388;&#24314;&#31435;&#20102;&#32852;&#31995;&#65292;&#20854;&#20013;&#26530;&#32445;&#27979;&#24230;&#22312;&#19968;&#26465;&#30452;&#32447;&#19978;&#24471;&#21040;&#25903;&#25345;&#12290;&#25105;&#20204;&#29305;&#21035;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#30340;&#38381;&#21512;&#24418;&#24335;&#30340;&#31934;&#30830;Wasserstein&#36317;&#31163;&#65292;&#22312;&#20854;&#20013;&#19968;&#20010;&#20998;&#24067;&#25903;&#25345;&#22312;&#19968;&#26465;&#30452;&#32447;&#19978;&#30340;&#29305;&#27530;&#24773;&#20917;&#19979;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#25512;&#23548;&#20986;&#19968;&#31181;&#36866;&#29992;&#20110;&#26799;&#24230;&#19979;&#38477;&#20248;&#21270;&#30340;&#24555;&#36895;&#35745;&#31639;&#26041;&#26696;&#12290;&#25105;&#20204;&#34920;&#26126;min-SWGG&#26159;WD&#30340;&#19978;&#30028;&#65292;&#24182;&#19988;&#23427;&#20855;&#26377;&#19982;Sliced-Wasserstein&#31867;&#20284;&#30340;&#22797;&#26434;&#24230;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#19968;&#20010;&#30456;&#20851;&#30340;&#36755;&#36816;&#35745;&#21010;&#12290;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#19968;&#20123;&#29702;&#35770;&#24615;&#36136;&#65292;&#22914;&#36317;&#31163;&#24615;&#12289;&#24369;&#25910;&#25947;&#12289;&#35745;&#31639;&#21644;&#25299;&#25169;&#24615;&#36136;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;
Wasserstein distance (WD) and the associated optimal transport plan have been proven useful in many applications where probability measures are at stake. In this paper, we propose a new proxy of the squared WD, coined min-SWGG, that is based on the transport map induced by an optimal one-dimensional projection of the two input distributions. We draw connections between min-SWGG and Wasserstein generalized geodesics in which the pivot measure is supported on a line. We notably provide a new closed form for the exact Wasserstein distance in the particular case of one of the distributions supported on a line allowing us to derive a fast computational scheme that is amenable to gradient descent optimization. We show that min-SWGG is an upper bound of WD and that it has a complexity similar to as Sliced-Wasserstein, with the additional feature of providing an associated transport plan. We also investigate some theoretical properties such as metricity, weak convergence, computational and top
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#33258;&#36866;&#24212;&#20027;&#25104;&#20998;&#22238;&#24402;&#26041;&#27861;&#65292;&#24182;&#22312;&#38754;&#26495;&#25968;&#25454;&#20013;&#30340;&#24212;&#29992;&#20013;&#33719;&#24471;&#20102;&#22343;&#21248;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#29992;&#20110;&#38754;&#26495;&#25968;&#25454;&#20013;&#30340;&#23454;&#39564;&#35774;&#35745;&#65292;&#29305;&#21035;&#26159;&#24403;&#24178;&#39044;&#26041;&#26696;&#26159;&#33258;&#36866;&#24212;&#20998;&#37197;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2307.01357</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#20027;&#25104;&#20998;&#22238;&#24402;&#22312;&#38754;&#26495;&#25968;&#25454;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Adaptive Principal Component Regression with Applications to Panel Data. (arXiv:2307.01357v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01357
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#33258;&#36866;&#24212;&#20027;&#25104;&#20998;&#22238;&#24402;&#26041;&#27861;&#65292;&#24182;&#22312;&#38754;&#26495;&#25968;&#25454;&#20013;&#30340;&#24212;&#29992;&#20013;&#33719;&#24471;&#20102;&#22343;&#21248;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#29992;&#20110;&#38754;&#26495;&#25968;&#25454;&#20013;&#30340;&#23454;&#39564;&#35774;&#35745;&#65292;&#29305;&#21035;&#26159;&#24403;&#24178;&#39044;&#26041;&#26696;&#26159;&#33258;&#36866;&#24212;&#20998;&#37197;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20027;&#25104;&#20998;&#22238;&#24402;(PCR)&#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#22266;&#23450;&#35774;&#35745;&#35823;&#24046;&#21464;&#37327;&#22238;&#24402;&#25216;&#26415;&#65292;&#23427;&#26159;&#32447;&#24615;&#22238;&#24402;&#30340;&#25512;&#24191;&#65292;&#35266;&#27979;&#30340;&#21327;&#21464;&#37327;&#21463;&#21040;&#38543;&#26426;&#22122;&#22768;&#30340;&#27745;&#26579;&#12290;&#25105;&#20204;&#22312;&#25968;&#25454;&#25910;&#38598;&#26102;&#25552;&#20379;&#20102;&#22312;&#32447;&#65288;&#27491;&#21017;&#21270;&#65289;PCR&#30340;&#31532;&#19968;&#27425;&#22343;&#21248;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#12290;&#30001;&#20110;&#20998;&#26512;&#22266;&#23450;&#35774;&#35745;&#20013;PCR&#30340;&#35777;&#26126;&#25216;&#26415;&#26080;&#27861;&#24456;&#23481;&#26131;&#22320;&#25193;&#23637;&#21040;&#22312;&#32447;&#35774;&#32622;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#20381;&#36182;&#20110;&#23558;&#29616;&#20195;&#38789;&#27987;&#24230;&#30340;&#24037;&#20855;&#36866;&#24212;&#21040;&#35823;&#24046;&#21464;&#37327;&#35774;&#32622;&#20013;&#12290;&#20316;&#20026;&#25105;&#20204;&#30028;&#38480;&#30340;&#24212;&#29992;&#65292;&#25105;&#20204;&#22312;&#38754;&#26495;&#25968;&#25454;&#35774;&#32622;&#20013;&#25552;&#20379;&#20102;&#23454;&#39564;&#35774;&#35745;&#26694;&#26550;&#65292;&#24403;&#24178;&#39044;&#34987;&#33258;&#36866;&#24212;&#22320;&#20998;&#37197;&#26102;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#34987;&#35748;&#20026;&#26159;&#21512;&#25104;&#25511;&#21046;&#21644;&#21512;&#25104;&#24178;&#39044;&#26694;&#26550;&#30340;&#27867;&#21270;&#65292;&#20854;&#20013;&#25968;&#25454;&#26159;&#36890;&#36807;&#33258;&#36866;&#24212;&#24178;&#39044;&#20998;&#37197;&#31574;&#30053;&#25910;&#38598;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Principal component regression (PCR) is a popular technique for fixed-design error-in-variables regression, a generalization of the linear regression setting in which the observed covariates are corrupted with random noise. We provide the first time-uniform finite sample guarantees for online (regularized) PCR whenever data is collected adaptively. Since the proof techniques for analyzing PCR in the fixed design setting do not readily extend to the online setting, our results rely on adapting tools from modern martingale concentration to the error-in-variables setting. As an application of our bounds, we provide a framework for experiment design in panel data settings when interventions are assigned adaptively. Our framework may be thought of as a generalization of the synthetic control and synthetic interventions frameworks, where data is collected via an adaptive intervention assignment policy.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#20110;&#24322;&#36136;&#31181;&#32676;&#26377;&#23475;&#23454;&#39564;&#30340;&#26089;&#26399;&#20572;&#27490;&#26041;&#27861;CLASH&#65292;&#20351;&#29992;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#21487;&#20197;&#26377;&#25928;&#25552;&#21069;&#20572;&#27490;&#20020;&#24202;&#35797;&#39564;&#21644;A/B&#27979;&#35797;&#12290;</title><link>http://arxiv.org/abs/2306.11839</link><description>&lt;p&gt;
&#26159;&#21542;&#24212;&#35813;&#20572;&#27490;&#65306;&#20855;&#26377;&#24322;&#36136;&#31181;&#32676;&#30340;&#26089;&#26399;&#20572;&#27490;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Should I Stop or Should I Go: Early Stopping with Heterogeneous Populations. (arXiv:2306.11839v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11839
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#20110;&#24322;&#36136;&#31181;&#32676;&#26377;&#23475;&#23454;&#39564;&#30340;&#26089;&#26399;&#20572;&#27490;&#26041;&#27861;CLASH&#65292;&#20351;&#29992;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#21487;&#20197;&#26377;&#25928;&#25552;&#21069;&#20572;&#27490;&#20020;&#24202;&#35797;&#39564;&#21644;A/B&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#23454;&#39564;&#30001;&#20110;&#27835;&#30103;&#36896;&#25104;&#24847;&#22806;&#30340;&#26377;&#23475;&#24433;&#21709;&#65292;&#22240;&#27492;&#24448;&#24448;&#38656;&#35201;&#25552;&#21069;&#20572;&#27490;&#12290;&#30446;&#21069;&#30830;&#23450;&#20309;&#26102;&#25552;&#21069;&#32456;&#27490;&#23454;&#39564;&#30340;&#29616;&#26377;&#26041;&#27861;&#36890;&#24120;&#36866;&#29992;&#20110;&#24635;&#20307;&#25968;&#25454;&#65292;&#19981;&#32771;&#34385;&#27835;&#30103;&#25928;&#24212;&#30340;&#24322;&#36136;&#24615;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#38024;&#23545;&#24322;&#36136;&#31181;&#32676;&#26377;&#23475;&#23454;&#39564;&#30340;&#26089;&#26399;&#20572;&#27490;&#26041;&#27861;&#12290;&#25105;&#20204;&#39318;&#20808;&#30830;&#23450;&#29616;&#26377;&#26041;&#27861;&#22312;&#27835;&#30103;&#23545;&#23569;&#25968;&#21442;&#19982;&#32773;&#36896;&#25104;&#20260;&#23475;&#26102;&#24448;&#24448;&#26080;&#27861;&#20572;&#27490;&#23454;&#39564;&#12290;&#28982;&#21518;&#20351;&#29992;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#24320;&#21457;&#20102;CLASH&#65292;&#36825;&#26159;&#39318;&#20010;&#24191;&#27867;&#36866;&#29992;&#20110;&#24322;&#36136;&#26089;&#26399;&#20572;&#27490;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#22312;&#27169;&#25311;&#21644;&#23454;&#38469;&#25968;&#25454;&#19978;&#23637;&#31034;&#20102;CLASH&#30340;&#34920;&#29616;&#65292;&#24182;&#35777;&#26126;&#23427;&#22312;&#20020;&#24202;&#35797;&#39564;&#21644;A/B&#27979;&#35797;&#20013;&#37117;&#33021;&#26377;&#25928;&#25552;&#21069;&#20572;&#27490;&#12290;
&lt;/p&gt;
&lt;p&gt;
Randomized experiments often need to be stopped prematurely due to the treatment having an unintended harmful effect. Existing methods that determine when to stop an experiment early are typically applied to the data in aggregate and do not account for treatment effect heterogeneity. In this paper, we study the early stopping of experiments for harm on heterogeneous populations. We first establish that current methods often fail to stop experiments when the treatment harms a minority group of participants. We then use causal machine learning to develop CLASH, the first broadly-applicable method for heterogeneous early stopping. We demonstrate CLASH's performance on simulated and real data and show that it yields effective early stopping for both clinical trials and A/B tests.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#32034;&#20102;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#20174;&#39640;&#26031;&#36807;&#31243;&#21518;&#39564;&#20013;&#37319;&#26679;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#35745;&#31639;&#39640;&#25928;&#19988;&#33021;&#22312;&#36275;&#22815;&#35206;&#30422;&#25968;&#25454;&#30340;&#21306;&#22495;&#21644;&#36275;&#22815;&#36828;&#31163;&#25968;&#25454;&#30340;&#21306;&#22495;&#20013;&#20135;&#29983;&#25509;&#36817;&#30495;&#23454;&#21518;&#39564;&#30340;&#39044;&#27979;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2306.11589</link><description>&lt;p&gt;
&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20174;&#39640;&#26031;&#36807;&#31243;&#21518;&#39564;&#20013;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Sampling from Gaussian Process Posteriors using Stochastic Gradient Descent. (arXiv:2306.11589v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11589
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#32034;&#20102;&#20351;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#20174;&#39640;&#26031;&#36807;&#31243;&#21518;&#39564;&#20013;&#37319;&#26679;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#35745;&#31639;&#39640;&#25928;&#19988;&#33021;&#22312;&#36275;&#22815;&#35206;&#30422;&#25968;&#25454;&#30340;&#21306;&#22495;&#21644;&#36275;&#22815;&#36828;&#31163;&#25968;&#25454;&#30340;&#21306;&#22495;&#20013;&#20135;&#29983;&#25509;&#36817;&#30495;&#23454;&#21518;&#39564;&#30340;&#39044;&#27979;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#26159;&#29992;&#20110;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#21644;&#39034;&#24207;&#20915;&#31574;&#30340;&#24378;&#22823;&#26694;&#26550;&#65292;&#20294;&#20854;&#38656;&#35201;&#27714;&#35299;&#32447;&#24615;&#31995;&#32479;&#65292;&#27599;&#24403;&#25968;&#25454;&#38598;&#22823;&#23567;&#22686;&#21152;&#26102;&#20195;&#20215;&#26159;&#31435;&#26041;&#32423;&#21035;&#30340;&#19988;&#23545;&#26465;&#20214;&#25935;&#24863;&#12290;&#26412;&#25991;&#25506;&#32034;&#20102;&#38543;&#26426;&#26799;&#24230;&#31639;&#27861;&#20316;&#20026;&#19968;&#31181;&#35745;&#31639;&#39640;&#25928;&#30340;&#26041;&#27861;&#26469;&#36817;&#20284;&#35299;&#20915;&#36825;&#20123;&#32447;&#24615;&#31995;&#32479;&#65306;&#25105;&#20204;&#24320;&#21457;&#20102;&#20302;&#26041;&#24046;&#30340;&#26368;&#20248;&#21270;&#30446;&#26631;&#20197;&#20174;&#21518;&#39564;&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#24182;&#23558;&#20854;&#25193;&#23637;&#21040;&#24341;&#20837;&#28857;&#12290;&#20196;&#20154;&#24847;&#24819;&#19981;&#21040;&#30340;&#26159;&#65292;&#21363;&#20351;&#22312;&#19981;&#24555;&#36895;&#25910;&#25947;&#21040;&#26368;&#20248;&#35299;&#30340;&#24773;&#20917;&#19979;&#65292;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#36890;&#24120;&#20063;&#20250;&#20135;&#29983;&#20934;&#30830;&#30340;&#39044;&#27979;&#12290;&#25105;&#20204;&#36890;&#36807;&#38750;&#25910;&#25947;&#30340;&#38544;&#24335;&#20559;&#32622;&#30340;&#35889;&#29305;&#24449;&#26469;&#35299;&#37322;&#36825;&#19968;&#28857;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20250;&#22312;&#36275;&#22815;&#35206;&#30422;&#25968;&#25454;&#30340;&#21306;&#22495;&#21644;&#36275;&#22815;&#36828;&#31163;&#25968;&#25454;&#30340;&#21306;&#22495;&#20013;&#20135;&#29983;&#25509;&#36817;&#30495;&#23454;&#21518;&#39564;&#30340;&#39044;&#27979;&#20998;&#24067;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#23454;&#29616;&#20102;
&lt;/p&gt;
&lt;p&gt;
Gaussian processes are a powerful framework for quantifying uncertainty and for sequential decision-making but are limited by the requirement of solving linear systems. In general, this has a cubic cost in dataset size and is sensitive to conditioning. We explore stochastic gradient algorithms as a computationally efficient method of approximately solving these linear systems: we develop low-variance optimization objectives for sampling from the posterior and extend these to inducing points. Counterintuitively, stochastic gradient descent often produces accurate predictions, even in cases where it does not converge quickly to the optimum. We explain this through a spectral characterization of the implicit bias from non-convergence. We show that stochastic gradient descent produces predictive distributions close to the true posterior both in regions with sufficient data coverage, and in regions sufficiently far away from the data. Experimentally, stochastic gradient descent achieves sta
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21483;&#20570;&#32858;&#31867;&#31526;&#21512;&#24615;&#39044;&#27979;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#22810;&#31867;&#26465;&#20214;&#19979;&#25552;&#20379;&#31867;&#21035;&#26465;&#20214;&#31526;&#21512;&#24615;&#39044;&#27979;&#65292;&#38024;&#23545;&#22810;&#20010;&#31867;&#21035;&#30340;&#22270;&#20687;&#25968;&#25454;&#38598;&#20013;&#32463;&#39564;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126;&#20854;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.09335</link><description>&lt;p&gt;
&#22810;&#31867;&#26465;&#20214;&#19979;&#30340;&#31867;&#21035;&#26465;&#20214;&#31526;&#21512;&#24615;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Class-Conditional Conformal Prediction With Many Classes. (arXiv:2306.09335v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09335
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21483;&#20570;&#32858;&#31867;&#31526;&#21512;&#24615;&#39044;&#27979;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#22810;&#31867;&#26465;&#20214;&#19979;&#25552;&#20379;&#31867;&#21035;&#26465;&#20214;&#31526;&#21512;&#24615;&#39044;&#27979;&#65292;&#38024;&#23545;&#22810;&#20010;&#31867;&#21035;&#30340;&#22270;&#20687;&#25968;&#25454;&#38598;&#20013;&#32463;&#39564;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126;&#20854;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#20934;&#31526;&#21512;&#24615;&#39044;&#27979;&#26041;&#27861;&#25552;&#20379;&#36793;&#32536;&#35206;&#30422;&#20445;&#35777;&#65292;&#36825;&#24847;&#21619;&#30528;&#23545;&#20110;&#19968;&#20010;&#38543;&#26426;&#30340;&#27979;&#35797;&#28857;&#65292;&#31526;&#21512;&#24615;&#39044;&#27979;&#38598;&#21512;&#20197;&#29992;&#25143;&#36873;&#25321;&#30340;&#27010;&#29575;&#21253;&#21547;&#30495;&#23454;&#26631;&#31614;&#12290;&#22312;&#35768;&#22810;&#20998;&#31867;&#38382;&#39064;&#20013;&#65292;&#25105;&#20204;&#24076;&#26395;&#33719;&#24471;&#26356;&#24378;&#30340;&#20445;&#35777;&#8212;&#8212;&#23545;&#20110;&#29305;&#23450;&#31867;&#21035;&#30340;&#27979;&#35797;&#28857;&#65292;&#39044;&#27979;&#38598;&#20197;&#30456;&#21516;&#30340;&#29992;&#25143;&#36873;&#25321;&#27010;&#29575;&#21253;&#21547;&#30495;&#23454;&#26631;&#31614;&#12290;&#29616;&#26377;&#30340;&#31526;&#21512;&#24615;&#39044;&#27979;&#26041;&#27861;&#22312;&#27599;&#20010;&#31867;&#21035;&#26377;&#38480;&#30340;&#26631;&#35760;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#34920;&#29616;&#19981;&#20339;&#65292;&#32780;&#36825;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#24448;&#24448;&#26159;&#22823;&#37327;&#31867;&#21035;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#32858;&#31867;&#31526;&#21512;&#24615;&#39044;&#27979;&#30340;&#26041;&#27861;&#65292;&#23427;&#23558;&#20855;&#26377;&#8220;&#30456;&#20284;&#8221;&#31526;&#21512;&#24615;&#20998;&#25968;&#30340;&#31867;&#21035;&#32858;&#31867;&#22312;&#19968;&#36215;&#65292;&#28982;&#21518;&#22312;&#32858;&#31867;&#32423;&#21035;&#19978;&#25191;&#34892;&#31526;&#21512;&#24615;&#39044;&#27979;&#12290;&#22312;&#38024;&#23545;&#22810;&#20010;&#65288;&#22810;&#36798;1000&#65289;&#31867;&#21035;&#30340;&#22235;&#20010;&#22270;&#20687;&#25968;&#25454;&#38598;&#30340;&#32463;&#39564;&#35780;&#20272;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#65292;&#32858;&#31867;&#31526;&#21512;&#24615;&#36890;&#24120;&#22312;&#31867;&#26465;&#20214;&#35206;&#30422;&#21644;&#38598;&#21512;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Standard conformal prediction methods provide a marginal coverage guarantee, which means that for a random test point, the conformal prediction set contains the true label with a user-chosen probability. In many classification problems, we would like to obtain a stronger guarantee -- that for test points of a specific class, the prediction set contains the true label with the same user-chosen probability. Existing conformal prediction methods do not work well when there is a limited amount of labeled data per class, as is often the case in real applications where the number of classes is large. We propose a method called clustered conformal prediction, which clusters together classes that have "similar" conformal scores and then performs conformal prediction at the cluster level. Based on empirical evaluation across four image data sets with many (up to 1000) classes, we find that clustered conformal typically outperforms existing methods in terms of class-conditional coverage and set 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;MMD-FUSE&#26041;&#27861;&#65292;&#36890;&#36807;&#36866;&#24212;&#20869;&#26680;&#38598;&#21512;&#26368;&#22823;&#21270;&#22522;&#20110;MMD&#30340;&#21452;&#26679;&#26412;&#26816;&#39564;&#21151;&#29575;&#65292;&#36991;&#20813;&#25968;&#25454;&#20998;&#21106;&#65292;&#24182;&#22312;&#20302;&#32500;&#21512;&#25104;&#25968;&#25454;&#21644;&#39640;&#32500;&#23454;&#38469;&#25968;&#25454;&#19978;&#35777;&#26126;&#20102;&#20854;&#36866;&#29992;&#24615;&#21644;&#21151;&#29575;&#36229;&#36807;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#26680;&#26816;&#39564;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.08777</link><description>&lt;p&gt;
MMD-FUSE: &#22312;&#19981;&#20998;&#21106;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#23398;&#20064;&#21644;&#32452;&#21512;&#20869;&#26680;&#36827;&#34892;&#21452;&#26679;&#26412;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
MMD-FUSE: Learning and Combining Kernels for Two-Sample Testing Without Data Splitting. (arXiv:2306.08777v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08777
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;MMD-FUSE&#26041;&#27861;&#65292;&#36890;&#36807;&#36866;&#24212;&#20869;&#26680;&#38598;&#21512;&#26368;&#22823;&#21270;&#22522;&#20110;MMD&#30340;&#21452;&#26679;&#26412;&#26816;&#39564;&#21151;&#29575;&#65292;&#36991;&#20813;&#25968;&#25454;&#20998;&#21106;&#65292;&#24182;&#22312;&#20302;&#32500;&#21512;&#25104;&#25968;&#25454;&#21644;&#39640;&#32500;&#23454;&#38469;&#25968;&#25454;&#19978;&#35777;&#26126;&#20102;&#20854;&#36866;&#29992;&#24615;&#21644;&#21151;&#29575;&#36229;&#36807;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#26680;&#26816;&#39564;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32479;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#36866;&#24212;&#23450;&#20041;&#35813;&#26041;&#27861;&#30340;&#20869;&#26680;&#38598;&#21512;&#65292;&#26368;&#22823;&#21270;&#22522;&#20110;&#26368;&#22823;&#24179;&#22343;&#20559;&#24046;&#65288;MMD&#65289;&#30340;&#21452;&#26679;&#26412;&#26816;&#39564;&#30340;&#21151;&#29575;&#12290; &#23545;&#20110;&#26377;&#38480;&#38598;&#21512;&#65292;&#36825;&#23601;&#32553;&#23567;&#20102;&#36890;&#36807;&#21152;&#26435;&#36719;&#26368;&#22823;&#20540;&#32452;&#21512;&#65288;&#26631;&#20934;&#21270;&#30340;&#65289;&#27599;&#20010;&#20869;&#26680;&#19979;&#30340;MMD&#20540;&#12290; &#23545;&#20110;&#38646;&#20551;&#35774;&#21644;&#22791;&#25321;&#20551;&#35774;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#32479;&#35745;&#37327;&#30340;&#25351;&#25968;&#27987;&#24230;&#19978;&#38480;&#12290; &#25105;&#20204;&#36827;&#19968;&#27493;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#25968;&#25454;&#20381;&#36182;&#20294;&#19982;&#25490;&#21015;&#29420;&#31435;&#30340;&#26041;&#24335;&#36873;&#25321;&#36825;&#20123;&#20869;&#26680;&#65292;&#22312;&#19968;&#20010;&#32463;&#36807;&#33391;&#22909;&#26657;&#20934;&#30340;&#27979;&#35797;&#20013;&#36991;&#20813;&#25968;&#25454;&#20998;&#21106;&#12290; &#36825;&#31181;&#25216;&#26415;&#26356;&#24191;&#27867;&#22320;&#36866;&#29992;&#20110;&#22522;&#20110;&#19968;&#33324;&#25490;&#21015;&#30340;MMD&#27979;&#35797;&#65292;&#24182;&#19988;&#21253;&#25324;&#20351;&#29992;&#20351;&#29992;&#33258;&#32534;&#30721;&#22120;&#31561;&#26080;&#30417;&#30563;&#27169;&#22411;&#23398;&#20064;&#30340;&#28145;&#24230;&#20869;&#26680;&#12290; &#25105;&#20204;&#24378;&#35843;&#20102;&#25105;&#20204;&#30340;MMD-FUSE&#27979;&#35797;&#22312;&#21512;&#25104;&#20302;&#32500;&#25968;&#25454;&#21644;&#29616;&#23454;&#19990;&#30028;&#39640;&#32500;&#25968;&#25454;&#26041;&#38754;&#30340;&#36866;&#29992;&#24615;&#65292;&#24182;&#27604;&#36739;&#20102;&#20854;&#21151;&#29575;&#34920;&#29616;&#19982;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#20869;&#26680;&#26816;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose novel statistics which maximise the power of a two-sample test based on the Maximum Mean Discrepancy (MMD), by adapting over the set of kernels used in defining it. For finite sets, this reduces to combining (normalised) MMD values under each of these kernels via a weighted soft maximum. Exponential concentration bounds are proved for our proposed statistics under the null and alternative. We further show how these kernels can be chosen in a data-dependent but permutation-independent way, in a well-calibrated test, avoiding data splitting. This technique applies more broadly to general permutation-based MMD testing, and includes the use of deep kernels with features learnt using unsupervised models such as auto-encoders. We highlight the applicability of our MMD-FUSE test on both synthetic low-dimensional and real-world high-dimensional data, and compare its performance in terms of power against current state-of-the-art kernel tests.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36830;&#32493;&#26102;&#38388;&#32593;&#32476;&#34920;&#31034;&#23398;&#20064;&#26694;&#26550;&#65292;&#28085;&#30422;&#26680;&#24179;&#28369;&#30340;&#24378;&#24230;&#20989;&#25968;&#20272;&#35745;&#12289;&#26368;&#23567;&#21270;&#24378;&#24230;&#37325;&#26500;&#35823;&#24046;&#30340;&#25237;&#24433;&#23398;&#20064;&#21644;&#24402;&#32435;&#26500;&#36896;&#33410;&#28857;&#34920;&#31034;&#12290;&#36825;&#31181;&#34920;&#31034;&#20445;&#30041;&#20102;&#32593;&#32476;&#32467;&#26500;&#21644;&#26102;&#38388;&#19968;&#33268;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.06155</link><description>&lt;p&gt;
&#24378;&#24230;&#36718;&#24275;&#25237;&#24433;&#65306;&#29992;&#20110;&#21160;&#24577;&#32593;&#32476;&#30340;&#36830;&#32493;&#26102;&#38388;&#34920;&#31034;&#23398;&#20064;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
Intensity Profile Projection: A Framework for Continuous-Time Representation Learning for Dynamic Networks. (arXiv:2306.06155v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06155
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36830;&#32493;&#26102;&#38388;&#32593;&#32476;&#34920;&#31034;&#23398;&#20064;&#26694;&#26550;&#65292;&#28085;&#30422;&#26680;&#24179;&#28369;&#30340;&#24378;&#24230;&#20989;&#25968;&#20272;&#35745;&#12289;&#26368;&#23567;&#21270;&#24378;&#24230;&#37325;&#26500;&#35823;&#24046;&#30340;&#25237;&#24433;&#23398;&#20064;&#21644;&#24402;&#32435;&#26500;&#36896;&#33410;&#28857;&#34920;&#31034;&#12290;&#36825;&#31181;&#34920;&#31034;&#20445;&#30041;&#20102;&#32593;&#32476;&#32467;&#26500;&#21644;&#26102;&#38388;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#24378;&#24230;&#36718;&#24275;&#25237;&#24433;&#8221;&#30340;&#26032;&#31639;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#23398;&#20064;&#21160;&#24577;&#32593;&#32476;&#33410;&#28857;&#30340;&#36830;&#32493;&#26102;&#38388;&#34920;&#31034;&#65292;&#35813;&#21160;&#24577;&#32593;&#32476;&#30001;&#33410;&#28857;&#38598;&#21644;&#22312;&#36830;&#32493;&#26102;&#38388;&#20869;&#21457;&#29983;&#30340;&#30636;&#26102;&#20132;&#20114;&#20107;&#20214;&#30340;&#38598;&#21512;&#25152;&#29305;&#24449;&#21270;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21253;&#25324;&#19977;&#20010;&#38454;&#27573;&#65306;&#36890;&#36807;&#26680;&#24179;&#28369;&#31561;&#26041;&#27861;&#20272;&#35745;&#33410;&#28857;&#23545;&#20043;&#38388;&#20132;&#20114;&#30340;&#24378;&#24230;&#20989;&#25968;&#65307;&#23398;&#20064;&#19968;&#20010;&#26368;&#23567;&#21270;&#26576;&#31181;&#24378;&#24230;&#37325;&#26500;&#35823;&#24046;&#30340;&#25237;&#24433;&#65307;&#36890;&#36807;&#23398;&#20064;&#30340;&#25237;&#24433;&#24402;&#32435;&#26500;&#36896;&#20986;&#19981;&#26029;&#21457;&#23637;&#30340;&#33410;&#28857;&#34920;&#31034;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#34920;&#31034;&#20445;&#30041;&#20102;&#32593;&#32476;&#30340;&#22522;&#26412;&#32467;&#26500;&#65292;&#24182;&#20855;&#26377;&#26102;&#38388;&#19968;&#33268;&#24615;&#65292;&#36825;&#24847;&#21619;&#30528;&#33410;&#28857;&#34920;&#31034;&#21487;&#20197;&#22312;&#19981;&#21516;&#30340;&#26102;&#38388;&#28857;&#19978;&#36827;&#34892;&#26377;&#24847;&#20041;&#30340;&#27604;&#36739;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#20063;&#26500;&#24314;&#20102;&#20272;&#35745;&#29702;&#35770;&#26469;&#38416;&#26126;&#24179;&#28369;&#20316;&#20026;&#20559;&#24046;&#26041;&#24046;&#25240;&#34935;&#30340;&#20316;&#29992;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#38543;&#30528;&#20449;&#22122;&#27604;&#30340;&#22686;&#21152;&#32780;&#20943;&#23569;&#24179;&#28369;&#31243;&#24230;&#20197;&#33719;&#24471;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a new algorithmic framework, Intensity Profile Projection, for learning continuous-time representations of the nodes of a dynamic network, characterised by a node set and a collection of instantaneous interaction events which occur in continuous time. Our framework consists of three stages: estimating the intensity functions underlying the interactions between pairs of nodes, e.g. via kernel smoothing; learning a projection which minimises a notion of intensity reconstruction error; and inductively constructing evolving node representations via the learned projection. We show that our representations preserve the underlying structure of the network, and are temporally coherent, meaning that node representations can be meaningfully compared at different points in time. We develop estimation theory which elucidates the role of smoothing as a bias-variance trade-off, and shows how we can reduce smoothing as the signal-to-noise ratio increases on account of the algorithm `borrow
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#33258;&#36866;&#24212;&#31639;&#27861;(&#22914;Adagrad&#21644;Adam)&#30340;&#23398;&#20064;&#29575;&#20272;&#35745;&#26041;&#27861;Prodigy&#21644;Resetting&#65292;&#21487;&#20197;&#24555;&#36895;&#19988;&#27491;&#30830;&#22320;&#20272;&#35745;&#21040;&#36798;&#35299;&#20915;&#26041;&#26696;&#25152;&#38656;&#30340;&#36317;&#31163;D&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#23454;&#39564;&#34920;&#26126;&#35813;&#26041;&#27861;&#20248;&#20110;D-Adaptation&#24182;&#21487;&#36798;&#21040;&#25163;&#21160;&#35843;&#25972;Adam&#30340;&#27979;&#35797;&#20934;&#30830;&#24230;&#20540;&#12290;</title><link>http://arxiv.org/abs/2306.06101</link><description>&lt;p&gt;
Prodigy: &#19968;&#31181;&#24555;&#36895;&#33258;&#36866;&#24212;&#38646;&#21442;&#25968;&#23398;&#20064;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Prodigy: An Expeditiously Adaptive Parameter-Free Learner. (arXiv:2306.06101v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06101
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#33258;&#36866;&#24212;&#31639;&#27861;(&#22914;Adagrad&#21644;Adam)&#30340;&#23398;&#20064;&#29575;&#20272;&#35745;&#26041;&#27861;Prodigy&#21644;Resetting&#65292;&#21487;&#20197;&#24555;&#36895;&#19988;&#27491;&#30830;&#22320;&#20272;&#35745;&#21040;&#36798;&#35299;&#20915;&#26041;&#26696;&#25152;&#38656;&#30340;&#36317;&#31163;D&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#23454;&#39564;&#34920;&#26126;&#35813;&#26041;&#27861;&#20248;&#20110;D-Adaptation&#24182;&#21487;&#36798;&#21040;&#25163;&#21160;&#35843;&#25972;Adam&#30340;&#27979;&#35797;&#20934;&#30830;&#24230;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#33258;&#36866;&#24212;&#31639;&#27861;(&#22914;Adagrad&#21644;Adam)&#20013;&#30340;&#23398;&#20064;&#29575;&#20272;&#35745;&#38382;&#39064;&#65292;&#25551;&#36848;&#20102;&#20004;&#31181;&#25216;&#26415;Prodigy&#21644;Resetting&#65292;&#21487;&#20197;&#35777;&#26126;&#22320;&#20272;&#35745;&#21040;&#36798;&#35299;&#20915;&#26041;&#26696;&#25152;&#38656;&#30340;&#36317;&#31163;D&#65292;&#20197;&#20415;&#26368;&#20248;&#35774;&#32622;&#23398;&#20064;&#29575;&#12290;&#25105;&#20204;&#30340;&#25216;&#26415;&#26159;&#22522;&#20110;&#23398;&#20064;&#29575;&#33258;&#30001;&#30340;D-Adaptation&#26041;&#27861;&#30340;&#20462;&#25913;&#65292;&#24182;&#36890;&#36807;$O(\sqrt{\log(D/d_0)})$&#30340;&#22240;&#23376;&#25552;&#39640;&#20102;D-Adaptation&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#20854;&#20013;$d_0$&#26159;$D$&#30340;&#21021;&#22987;&#20272;&#35745;&#20540;&#12290;&#25105;&#20204;&#22312;12&#20010;&#24120;&#35265;&#30340;&#36923;&#36753;&#22238;&#24402;&#22522;&#20934;&#25968;&#25454;&#38598;&#12289;&#22312;CIFAR10&#19978;&#35757;&#32451;&#30340;VGG11&#21644;ResNet-50&#12289;&#22312;Imagenet&#19978;&#35757;&#32451;&#30340;ViT&#12289;&#22312;IWSLT14&#19978;&#35757;&#32451;&#30340;LSTM&#12289;&#22312;Criteo&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;DLRM&#12289;&#22312;Knee MRI&#25968;&#25454;&#38598;&#19978;&#30340;VarNet&#65292;&#20197;&#21450;&#22312;BookWiki&#19978;&#35757;&#32451;&#30340;RoBERTa&#21644;GPT transformer&#19978;&#27979;&#35797;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22987;&#32456;&#20248;&#20110;D-Adaptation&#65292;&#24182;&#36798;&#21040;&#25163;&#21160;&#35843;&#25972;Adam&#30340;&#27979;&#35797;&#20934;&#30830;&#24230;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of estimating the learning rate in adaptive methods, such as Adagrad and Adam. We describe two techniques, Prodigy and Resetting, to provably estimate the distance to the solution $D$, which is needed to set the learning rate optimally. Our techniques are modifications of the D-Adaptation method for learning-rate-free learning. Our methods improve upon the convergence rate of D-Adaptation by a factor of $O(\sqrt{\log(D/d_0)})$, where $d_0$ is the initial estimate of $D$. We test our methods on 12 common logistic-regression benchmark datasets, VGG11 and ResNet-50 training on CIFAR10, ViT training on Imagenet, LSTM training on IWSLT14, DLRM training on Criteo dataset, VarNet on Knee MRI dataset, as well as RoBERTa and GPT transformer training on BookWiki. Our experimental results show that our approaches consistently outperform D-Adaptation and reach test accuracy values close to that of hand-tuned Adam.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#36890;&#29992;&#30340;&#22823;&#35268;&#27169;&#21644;&#28508;&#22312;&#26410;&#30693;&#22270;&#19978;&#23450;&#20041;&#20989;&#25968;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#23398;&#20064;&#36866;&#24403;&#30340;&#22270;&#20869;&#26680;&#65292;&#36866;&#24212;&#30446;&#26631;&#20989;&#25968;&#34892;&#20026;&#12290;</title><link>http://arxiv.org/abs/2306.05304</link><description>&lt;p&gt;
&#22270;&#19978;&#20989;&#25968;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Bayesian Optimisation of Functions on Graphs. (arXiv:2306.05304v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05304
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#36890;&#29992;&#30340;&#22823;&#35268;&#27169;&#21644;&#28508;&#22312;&#26410;&#30693;&#22270;&#19978;&#23450;&#20041;&#20989;&#25968;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#23398;&#20064;&#36866;&#24403;&#30340;&#22270;&#20869;&#26680;&#65292;&#36866;&#24212;&#30446;&#26631;&#20989;&#25968;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#32467;&#26500;&#25968;&#25454;&#30340;&#19981;&#26029;&#28044;&#29616;&#25512;&#21160;&#20102;&#22312;&#22270;&#33410;&#28857;&#38598;&#19978;&#23450;&#20041;&#20989;&#25968;&#30340;&#20248;&#21270;&#20219;&#21153;&#12290;&#20256;&#32479;&#30340;&#22270;&#25628;&#32034;&#31639;&#27861;&#21487;&#29992;&#20110;&#27492;&#65292;&#20294;&#23427;&#20204;&#21487;&#33021;&#26679;&#26412;&#25928;&#29575;&#20302;&#19979;&#65292;&#24182;&#19988;&#19981;&#21033;&#29992;&#20851;&#20110;&#20989;&#25968;&#20540;&#30340;&#20449;&#24687;&#65307;&#21478;&#19968;&#26041;&#38754;&#65292;&#36125;&#21494;&#26031;&#20248;&#21270;&#26159;&#19968;&#31867;&#26377;&#21069;&#36884;&#30340;&#40657;&#30418;&#27714;&#35299;&#22120;&#65292;&#20855;&#26377;&#26356;&#39640;&#30340;&#26679;&#26412;&#25928;&#29575;&#65292;&#20294;&#23427;&#24456;&#23569;&#34987;&#24212;&#29992;&#20110;&#36825;&#26679;&#30340;&#26032;&#39062;&#35774;&#32622;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#20248;&#21270;&#22312;&#36890;&#29992;&#65292;&#22823;&#35268;&#27169;&#21644;&#28508;&#22312;&#30340;&#26410;&#30693;&#22270;&#19978;&#23450;&#20041;&#30340;&#20989;&#25968;&#12290;&#36890;&#36807;&#23398;&#20064;&#36866;&#24403;&#30340;&#22270;&#20869;&#26680;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#20855;&#26377;&#36866;&#24212;&#30446;&#26631;&#20989;&#25968;&#34892;&#20026;&#30340;&#20248;&#28857;&#12290;&#23616;&#37096;&#24314;&#27169;&#26041;&#27861;&#36827;&#19968;&#27493;&#20445;&#35777;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#25928;&#29575;&#12290;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#22270;&#19978;&#30340;&#22823;&#37327;&#23454;&#39564;&#34920;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#20248;&#21270;&#26694;&#26550;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The increasing availability of graph-structured data motivates the task of optimising over functions defined on the node set of graphs. Traditional graph search algorithms can be applied in this case, but they may be sample-inefficient and do not make use of information about the function values; on the other hand, Bayesian optimisation is a class of promising black-box solvers with superior sample efficiency, but it has been scarcely been applied to such novel setups. To fill this gap, we propose a novel Bayesian optimisation framework that optimises over functions defined on generic, large-scale and potentially unknown graphs. Through the learning of suitable kernels on graphs, our framework has the advantage of adapting to the behaviour of the target function. The local modelling approach further guarantees the efficiency of our method. Extensive experiments on both synthetic and real-world graphs demonstrate the effectiveness of the proposed optimisation framework.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#22343;&#20540;&#20272;&#35745;&#38382;&#39064;&#65292;&#25506;&#35752;&#20102;&#22312;&#36890;&#20449;&#21644;&#26412;&#22320;&#24046;&#20998;&#38544;&#31169;&#32422;&#26463;&#19979;&#30340;&#31934;&#30830;&#26368;&#20248;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#21033;&#29992;&#26059;&#36716;&#23545;&#31216;&#30340;&#20849;&#20139;&#38543;&#26426;&#30721;&#20070;&#65292;&#24182;&#36890;&#36807;$k$-closest&#32534;&#30721;&#23454;&#29616;&#20102;&#38543;&#26426;&#26059;&#36716;&#30340;&#21333;&#32431;&#24418;$c$&#30340;&#31934;&#30830;&#26368;&#20248;&#12290;</title><link>http://arxiv.org/abs/2306.04924</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#22343;&#20540;&#20272;&#35745;&#20013;&#30340;&#36890;&#20449;&#38544;&#31169;&#25928;&#29992;&#26435;&#34913;&#30340;&#31934;&#30830;&#26368;&#20248;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Exact Optimality of Communication-Privacy-Utility Tradeoffs in Distributed Mean Estimation. (arXiv:2306.04924v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04924
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#22343;&#20540;&#20272;&#35745;&#38382;&#39064;&#65292;&#25506;&#35752;&#20102;&#22312;&#36890;&#20449;&#21644;&#26412;&#22320;&#24046;&#20998;&#38544;&#31169;&#32422;&#26463;&#19979;&#30340;&#31934;&#30830;&#26368;&#20248;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#21033;&#29992;&#26059;&#36716;&#23545;&#31216;&#30340;&#20849;&#20139;&#38543;&#26426;&#30721;&#20070;&#65292;&#24182;&#36890;&#36807;$k$-closest&#32534;&#30721;&#23454;&#29616;&#20102;&#38543;&#26426;&#26059;&#36716;&#30340;&#21333;&#32431;&#24418;$c$&#30340;&#31934;&#30830;&#26368;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#36890;&#20449;&#21644;&#26412;&#22320;&#24046;&#20998;&#38544;&#31169;&#32422;&#26463;&#19979;&#30340;&#22343;&#20540;&#20272;&#35745;&#38382;&#39064;&#12290;&#34429;&#28982;&#20197;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#25552;&#20986;&#20102;&#30456;&#21516;&#38382;&#39064;&#30340;\emph{&#38454;}-&#26368;&#20248;&#31639;&#27861;&#65288;&#21363;&#24403;&#25105;&#20204;&#33457;&#36153;&#26356;&#22810;&#27604;&#29305;&#26102;&#28176;&#36827;&#26368;&#20248;&#65289;&#65292;&#20294;&#22312;&#38750;&#28176;&#36827;&#35774;&#32622;&#19979;&#20173;&#28982;&#27809;&#26377;&#23454;&#29616;\emph{&#31934;&#30830;}&#26368;&#20248;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36808;&#20986;&#20102;&#19968;&#27493;&#65292;&#25551;&#36848;&#20102;&#22312;&#20849;&#20139;&#38543;&#26426;&#24615;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#30340;\emph{&#31934;&#30830;}-&#26368;&#20248;&#26041;&#27861;&#65292;&#24182;&#30830;&#23450;&#20102;&#20960;&#20010;\emph{&#31934;&#30830;}&#26368;&#20248;&#30340;&#24517;&#35201;&#26465;&#20214;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20854;&#20013;&#19968;&#20010;&#24517;&#35201;&#26465;&#20214;&#26159;&#21033;&#29992;&#26059;&#36716;&#23545;&#31216;&#30340;&#20849;&#20139;&#38543;&#26426;&#30721;&#20070;&#12290;&#22522;&#20110;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#21270;&#26426;&#21046;&#65292;&#20854;&#20013;&#30721;&#20070;&#26159;&#38543;&#26426;&#26059;&#36716;&#30340;&#21333;&#32431;&#24418;&#8212;&#8212;&#28385;&#36275;\emph{&#31934;&#30830;}-&#26368;&#20248;&#30721;&#20070;&#30340;&#24517;&#35201;&#23646;&#24615;&#12290;&#35813;&#26426;&#21046;&#22522;&#20110;&#25105;&#20204;&#35777;&#26126;&#30340;$k$&#26368;&#36817;&#32534;&#30721;&#65292;&#23545;&#20110;&#38543;&#26426;&#26059;&#36716;&#30340;&#21333;&#32431;&#24418;$c$&#26469;&#35828;&#26159;\emph{&#31934;&#30830;}-&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the mean estimation problem under communication and local differential privacy constraints. While previous work has proposed \emph{order}-optimal algorithms for the same problem (i.e., asymptotically optimal as we spend more bits), \emph{exact} optimality (in the non-asymptotic setting) still has not been achieved. In this work, we take a step towards characterizing the \emph{exact}-optimal approach in the presence of shared randomness (a random variable shared between the server and the user) and identify several necessary conditions for \emph{exact} optimality. We prove that one of the necessary conditions is to utilize a rotationally symmetric shared random codebook. Based on this, we propose a randomization mechanism where the codebook is a randomly rotated simplex -- satisfying the necessary properties of the \emph{exact}-optimal codebook. The proposed mechanism is based on a $k$-closest encoding which we prove to be \emph{exact}-optimal for the randomly rotated simplex c
&lt;/p&gt;</description></item><item><title>SGD&#22312;&#35757;&#32451;&#36807;&#24230;&#34920;&#36798;&#30340;&#32593;&#32476;&#26102;&#65292;&#20250;&#38543;&#26426;&#22320;&#23558;&#21160;&#24577;&#21560;&#24341;&#21040;&#26356;&#31616;&#21333;&#30340;&#23376;&#32593;&#32476;&#65292;&#36825;&#31181;&#38543;&#26426;&#21560;&#24341;&#24615;&#33021;&#22815;&#25552;&#39640;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2306.04251</link><description>&lt;p&gt;
&#38543;&#26426;&#22349;&#32553;&#65306;&#22914;&#20309;&#21033;&#29992;&#26799;&#24230;&#22122;&#22768;&#20351;SGD&#21160;&#24577;&#36235;&#21521;&#26356;&#31616;&#21333;&#30340;&#23376;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Stochastic Collapse: How Gradient Noise Attracts SGD Dynamics Towards Simpler Subnetworks. (arXiv:2306.04251v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04251
&lt;/p&gt;
&lt;p&gt;
SGD&#22312;&#35757;&#32451;&#36807;&#24230;&#34920;&#36798;&#30340;&#32593;&#32476;&#26102;&#65292;&#20250;&#38543;&#26426;&#22320;&#23558;&#21160;&#24577;&#21560;&#24341;&#21040;&#26356;&#31616;&#21333;&#30340;&#23376;&#32593;&#32476;&#65292;&#36825;&#31181;&#38543;&#26426;&#21560;&#24341;&#24615;&#33021;&#22815;&#25552;&#39640;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25581;&#31034;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#19968;&#20010;&#24378;&#28872;&#38544;&#24335;&#20559;&#22909;&#65292;&#23427;&#23558;&#36807;&#24230;&#34920;&#36798;&#30340;&#32593;&#32476;&#39537;&#21160;&#21040;&#26356;&#31616;&#21333;&#30340;&#23376;&#32593;&#32476;&#65292;&#20174;&#32780;&#22823;&#22823;&#20943;&#23569;&#20102;&#29420;&#31435;&#21442;&#25968;&#30340;&#25968;&#37327;&#65292;&#24182;&#25552;&#39640;&#20102;&#27867;&#21270;&#33021;&#21147;&#12290;&#20026;&#20102;&#25581;&#31034;&#36825;&#20010;&#20559;&#22909;&#65292;&#25105;&#20204;&#35782;&#21035;&#20102;&#19981;&#21464;&#38598;&#65292;&#25110;&#32773;&#35828;&#26159;SGD&#26410;&#20462;&#25913;&#30340;&#21442;&#25968;&#31354;&#38388;&#30340;&#23376;&#38598;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#20004;&#31867;&#19981;&#21464;&#38598;&#65292;&#23427;&#20204;&#23545;&#24212;&#20110;&#29616;&#20195;&#26550;&#26500;&#20013;&#24120;&#35265;&#30340;&#26356;&#31616;&#21333;&#30340;&#23376;&#32593;&#32476;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#25581;&#31034;&#20102;SGD&#22312;&#36825;&#20123;&#31616;&#21333;&#19981;&#21464;&#38598;&#26041;&#38754;&#20855;&#26377;&#38543;&#26426;&#21560;&#24341;&#24615;&#30340;&#29305;&#24615;&#12290;&#25105;&#20204;&#26681;&#25454;&#25439;&#22833;&#26223;&#35266;&#22312;&#19981;&#21464;&#38598;&#21608;&#22260;&#30340;&#26354;&#29575;&#21644;&#38543;&#26426;&#26799;&#24230;&#24341;&#20837;&#30340;&#22122;&#22768;&#20043;&#38388;&#30340;&#31454;&#20105;&#24314;&#31435;&#20102;&#19968;&#31181;&#38543;&#26426;&#21560;&#24341;&#24615;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#21457;&#29616;&#22686;&#21152;&#22122;&#22768;&#27700;&#24179;&#20250;&#22686;&#24378;&#21560;&#24341;&#21147;&#65292;&#23548;&#33268;&#19982;&#38797;&#28857;&#25110;&#35757;&#32451;&#25439;&#22833;&#30340;&#23616;&#37096;&#26497;&#22823;&#20540;&#30456;&#20851;&#30340;&#21560;&#24341;&#19981;&#21464;&#38598;&#30340;&#20986;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we reveal a strong implicit bias of stochastic gradient descent (SGD) that drives overly expressive networks to much simpler subnetworks, thereby dramatically reducing the number of independent parameters, and improving generalization. To reveal this bias, we identify invariant sets, or subsets of parameter space that remain unmodified by SGD. We focus on two classes of invariant sets that correspond to simpler subnetworks and commonly appear in modern architectures. Our analysis uncovers that SGD exhibits a property of stochastic attractivity towards these simpler invariant sets. We establish a sufficient condition for stochastic attractivity based on a competition between the loss landscape's curvature around the invariant set and the noise introduced by stochastic gradients. Remarkably, we find that an increased level of noise strengthens attractivity, leading to the emergence of attractive invariant sets associated with saddle-points or local maxima of the train loss.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38590;&#27665;&#23433;&#32622;&#20013;&#30340;&#38543;&#26426;&#20998;&#24067;&#36716;&#31227;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#24182;&#27604;&#36739;&#20102;&#19977;&#31181;&#24314;&#27169;&#31574;&#30053;&#65292;&#26368;&#32456;&#21457;&#29616;&#28151;&#21512;&#26041;&#27861;&#20855;&#26377;&#36739;&#24378;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.02948</link><description>&lt;p&gt;
&#38590;&#27665;&#23433;&#32622;&#20013;&#30340;&#38543;&#26426;&#20998;&#24067;&#36716;&#31227;: &#24314;&#31435;&#20581;&#22766;&#27169;&#22411;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Random Distribution Shift in Refugee Placement: Strategies for Building Robust Models. (arXiv:2306.02948v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02948
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38590;&#27665;&#23433;&#32622;&#20013;&#30340;&#38543;&#26426;&#20998;&#24067;&#36716;&#31227;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#24182;&#27604;&#36739;&#20102;&#19977;&#31181;&#24314;&#27169;&#31574;&#30053;&#65292;&#26368;&#32456;&#21457;&#29616;&#28151;&#21512;&#26041;&#27861;&#20855;&#26377;&#36739;&#24378;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#31639;&#27861;&#20998;&#37197;&#38590;&#27665;&#21644;&#23547;&#27714;&#24199;&#25252;&#32773;&#21040;&#20027;&#26426;&#22269;&#23478;&#30340;&#22320;&#28857;&#24050;&#32463;&#24341;&#36215;&#20102;&#20851;&#27880;&#65292;&#22312;&#32654;&#22269;&#21644;&#29790;&#22763;&#23454;&#26045;&#12290;&#36825;&#20123;&#26041;&#27861;&#20351;&#29992;&#36807;&#21435;&#25269;&#36798;&#30340;&#25968;&#25454;&#29983;&#25104;&#21487;&#20197;&#29992;&#20110;&#21305;&#37197;&#23478;&#24237;&#21040;&#20301;&#32622;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65288;&#19982;&#20998;&#37197;&#31639;&#27861;&#19968;&#36215;&#20351;&#29992;&#65289;&#65292;&#30446;&#26631;&#26159;&#26368;&#22823;&#21270;&#25919;&#31574;&#30456;&#20851;&#30340;&#25972;&#21512;&#32467;&#26524;&#65292;&#22914;&#22312;&#19968;&#23450;&#26102;&#38388;&#21518;&#30340;&#23601;&#19994;&#29366;&#24577;&#12290;&#29616;&#26377;&#30340;&#23454;&#29616;&#21644;&#30740;&#31350;&#36890;&#36807;&#30452;&#25509;&#39044;&#27979;&#25919;&#31574;&#32467;&#26524;&#26469;&#35757;&#32451;&#27169;&#22411;&#65292;&#24182;&#23558;&#36825;&#20123;&#39044;&#27979;&#29992;&#20110;&#20998;&#37197;&#36807;&#31243;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#30340;&#20248;&#28857;&#65292;&#29305;&#21035;&#26159;&#22312;&#38750;&#31283;&#24577;&#29615;&#22659;&#19979;&#65292;&#23578;&#26410;&#34987;&#20808;&#21069;&#25506;&#35752;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#24182;&#27604;&#36739;&#20102;&#19977;&#31181;&#19981;&#21516;&#30340;&#24314;&#27169;&#31574;&#30053;&#65306;&#19978;&#36848;&#30340;&#26631;&#20934;&#26041;&#27861;&#12289;&#20351;&#29992;&#26356;&#26032;&#25968;&#25454;&#21644;&#20195;&#29702;&#32467;&#26524;&#30340;&#26041;&#27861;&#20197;&#21450;&#28151;&#21512;&#26041;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#28151;&#21512;&#26041;&#27861;&#22312;&#20998;&#24067;&#36716;&#31227;&#21644;&#24369;&#20195;&#29702;&#20851;&#31995;&#26041;&#38754;&#20855;&#26377;&#40065;&#26834;&#24615;-
&lt;/p&gt;
&lt;p&gt;
Algorithmic assignment of refugees and asylum seekers to locations within host countries has gained attention in recent years, with implementations in the US and Switzerland. These approaches use data on past arrivals to generate machine learning models that can be used (along with assignment algorithms) to match families to locations, with the goal of maximizing a policy-relevant integration outcome such as employment status after a certain duration. Existing implementations and research train models to predict the policy outcome directly, and use these predictions in the assignment procedure. However, the merits of this approach, particularly in non-stationary settings, has not been previously explored. This study proposes and compares three different modeling strategies: the standard approach described above, an approach that uses newer data and proxy outcomes, and a hybrid approach. We show that the hybrid approach is robust to both distribution shift and weak proxy relationships -
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;Early-Exit&#32593;&#32476;&#20013;&#23454;&#29616;&#26465;&#20214;&#21333;&#35843;&#24615;&#30340;&#26041;&#27861;&#65292;&#23558;&#28145;&#24230;&#27169;&#22411;&#36716;&#21270;&#20026;&#30495;&#27491;&#30340;&#38543;&#26102;&#20998;&#31867;&#22120;&#12290;</title><link>http://arxiv.org/abs/2306.02652</link><description>&lt;p&gt;
&#36890;&#36807;&#24378;&#21046;&#26465;&#20214;&#21333;&#35843;&#24615;&#22312;Early-Exit&#32467;&#26500;&#20013;&#23454;&#29616;&#38543;&#26102;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Towards Anytime Classification in Early-Exit Architectures by Enforcing Conditional Monotonicity. (arXiv:2306.02652v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02652
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;Early-Exit&#32593;&#32476;&#20013;&#23454;&#29616;&#26465;&#20214;&#21333;&#35843;&#24615;&#30340;&#26041;&#27861;&#65292;&#23558;&#28145;&#24230;&#27169;&#22411;&#36716;&#21270;&#20026;&#30495;&#27491;&#30340;&#38543;&#26102;&#20998;&#31867;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#39044;&#27979;&#27169;&#22411;&#36890;&#24120;&#37096;&#32626;&#22312;&#35745;&#31639;&#39044;&#31639;&#21160;&#24577;&#30340;&#29615;&#22659;&#20013;&#12290;&#38543;&#26102;&#31639;&#27861;&#38750;&#24120;&#36866;&#29992;&#20110;&#36825;&#31181;&#29615;&#22659;&#65292;&#22240;&#20026;&#23427;&#20204;&#22312;&#35745;&#31639;&#30340;&#20219;&#20309;&#26102;&#20505;&#37117;&#21487;&#20197;&#36755;&#20986;&#39044;&#27979;&#20540;&#65292;&#20854;&#36136;&#37327;&#26159;&#35745;&#31639;&#26102;&#38388;&#30340;&#20989;&#25968;&#12290;&#30001;&#20110;&#20854;&#33021;&#22815;&#22312;&#32593;&#32476;&#21508;&#20010;&#38454;&#27573;&#25552;&#20379;&#20013;&#38388;&#39044;&#27979;&#32467;&#26524;&#30340;&#33021;&#21147;&#65292;Early-Exit&#31070;&#32463;&#32593;&#32476;&#22312;&#38543;&#26102;&#35745;&#31639;&#30340;&#32972;&#26223;&#19979;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35777;&#26126;&#24403;&#21069;&#30340;Early-Exit&#32593;&#32476;&#24182;&#19981;&#30452;&#25509;&#36866;&#29992;&#20110;&#20219;&#20309;&#26102;&#20505;&#30340;&#35774;&#32622;&#65292;&#22240;&#20026;&#21333;&#20010;&#25968;&#25454;&#28857;&#30340;&#39044;&#27979;&#36136;&#37327;&#19981;&#33021;&#20445;&#35777;&#38543;&#30528;&#35745;&#31639;&#26102;&#38388;&#30340;&#22686;&#21152;&#32780;&#25552;&#39640;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#32570;&#38519;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20248;&#38597;&#30340;&#20107;&#21518;&#20462;&#25913;&#65292;&#22522;&#20110;&#19987;&#23478;&#20056;&#31215;&#65292;&#40723;&#21169;Early-Exit&#32593;&#32476;&#36880;&#28176;&#21464;&#24471;&#33258;&#20449;&#12290;&#36825;&#36171;&#20104;&#20102;&#25105;&#20204;&#30340;&#28145;&#24230;&#27169;&#22411;&#26465;&#20214;&#21333;&#35843;&#24615;&#30340;&#29305;&#24615;&#8212;&#8212;&#36825;&#26159;&#23454;&#29616;&#30495;&#27491;&#38543;&#26102;&#20998;&#31867;&#30340;&#37325;&#35201;&#22522;&#30707;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern predictive models are often deployed to environments in which computational budgets are dynamic. Anytime algorithms are well-suited to such environments as, at any point during computation, they can output a prediction whose quality is a function of computation time. Early-exit neural networks have garnered attention in the context of anytime computation due to their capability to provide intermediate predictions at various stages throughout the network. However, we demonstrate that current early-exit networks are not directly applicable to anytime settings, as the quality of predictions for individual data points is not guaranteed to improve with longer computation. To address this shortcoming, we propose an elegant post-hoc modification, based on the Product-of-Experts, that encourages an early-exit network to become gradually confident. This gives our deep models the property of conditional monotonicity in the prediction quality -- an essential stepping stone towards truly an
&lt;/p&gt;</description></item><item><title>&#20154;&#31867;&#19987;&#23478;&#30340;&#20215;&#20540;&#36229;&#20986;&#20102;&#31639;&#27861;&#21487;&#25429;&#25417;&#33539;&#22260;&#65292;&#25105;&#20204;&#21487;&#20197;&#29992;&#19968;&#20010;&#31616;&#21333;&#30340;&#31243;&#24207;&#27979;&#35797;&#36825;&#20010;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.01646</link><description>&lt;p&gt;
&#20154;&#31867;&#19987;&#23478;&#23457;&#26680;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Auditing for Human Expertise. (arXiv:2306.01646v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01646
&lt;/p&gt;
&lt;p&gt;
&#20154;&#31867;&#19987;&#23478;&#30340;&#20215;&#20540;&#36229;&#20986;&#20102;&#31639;&#27861;&#21487;&#25429;&#25417;&#33539;&#22260;&#65292;&#25105;&#20204;&#21487;&#20197;&#29992;&#19968;&#20010;&#31616;&#21333;&#30340;&#31243;&#24207;&#27979;&#35797;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#39118;&#38505;&#39044;&#27979;&#20219;&#21153;&#65288;&#20363;&#22914;&#24739;&#32773;&#35786;&#26029;&#65289;&#36890;&#24120;&#30001;&#25509;&#21463;&#22521;&#35757;&#30340;&#20154;&#31867;&#19987;&#23478;&#22788;&#29702;&#12290;&#22312;&#36825;&#20123;&#35774;&#32622;&#20013;&#65292;&#33258;&#21160;&#21270;&#30340;&#19968;&#20010;&#24120;&#35265;&#38382;&#39064;&#26159;&#65292;&#19987;&#23478;&#21487;&#33021;&#36816;&#29992;&#24456;&#38590;&#24314;&#27169;&#30340;&#30452;&#35273;&#65292;&#24182;&#19988;/&#25110;&#32773;&#21487;&#20197;&#33719;&#21462;&#20449;&#24687;&#65288;&#20363;&#22914;&#19982;&#24739;&#32773;&#30340;&#20132;&#35848;&#65289;&#65292;&#36825;&#20123;&#20449;&#24687;&#23545;&#20110;&#31639;&#27861;&#26469;&#35828;&#26159;&#19981;&#21487;&#29992;&#30340;&#12290;&#36825;&#24341;&#21457;&#20102;&#19968;&#20010;&#33258;&#28982;&#30340;&#38382;&#39064;&#65292;&#20154;&#31867;&#19987;&#23478;&#26159;&#21542;&#22686;&#21152;&#20102;&#26080;&#27861;&#34987;&#31639;&#27861;&#39044;&#27979;&#22120;&#25429;&#25417;&#21040;&#30340;&#20215;&#20540;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#32479;&#35745;&#26694;&#26550;&#65292;&#21487;&#20197;&#23558;&#36825;&#20010;&#38382;&#39064;&#25552;&#20986;&#20026;&#19968;&#20010;&#33258;&#28982;&#30340;&#20551;&#35774;&#26816;&#39564;&#12290;&#27491;&#22914;&#25105;&#20204;&#30340;&#26694;&#26550;&#25152;&#24378;&#35843;&#30340;&#37027;&#26679;&#65292;&#26816;&#27979;&#20154;&#31867;&#19987;&#19994;&#30693;&#35782;&#27604;&#31616;&#21333;&#27604;&#36739;&#19987;&#23478;&#39044;&#27979;&#20934;&#30830;&#24615;&#19982;&#29305;&#23450;&#23398;&#20064;&#31639;&#27861;&#20570;&#20986;&#30340;&#20934;&#30830;&#24615;&#26356;&#21152;&#24494;&#22937;&#12290;&#32780;&#26159;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#31243;&#24207;&#65292;&#27979;&#35797;&#19987;&#23478;&#39044;&#27979;&#26159;&#21542;&#22312;&#8220;&#29305;&#24449;&#8221;&#21487;&#29992;&#32780;&#26465;&#20214;&#19979;&#26159;&#21542;&#19982;&#24863;&#20852;&#36259;&#30340;&#32467;&#26524;&#32479;&#35745;&#19978;&#29420;&#31435;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#27979;&#35797;&#30340;&#25298;&#32477;&#34920;&#26126;&#20102;&#20154;&#31867;&#19987;&#19994;&#30693;&#35782;&#30830;&#23454;&#22686;&#21152;&#20102;&#36229;&#20986;&#31639;&#27861;&#21487;&#25429;&#25417;&#33539;&#22260;&#30340;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
High-stakes prediction tasks (e.g., patient diagnosis) are often handled by trained human experts. A common source of concern about automation in these settings is that experts may exercise intuition that is difficult to model and/or have access to information (e.g., conversations with a patient) that is simply unavailable to a would-be algorithm. This raises a natural question whether human experts add value which could not be captured by an algorithmic predictor. We develop a statistical framework under which we can pose this question as a natural hypothesis test. Indeed, as our framework highlights, detecting human expertise is more subtle than simply comparing the accuracy of expert predictions to those made by a particular learning algorithm. Instead, we propose a simple procedure which tests whether expert predictions are statistically independent from the outcomes of interest after conditioning on the available inputs (`features'). A rejection of our test thus suggests that huma
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39640;&#38454;&#30456;&#20114;&#20316;&#29992;&#30340;&#27979;&#37327;&#26041;&#27861;&#21644;&#22522;&#20110;&#26680;&#30340;&#27979;&#35797;&#26041;&#27861;&#65292;&#24182;&#19982;&#26684;&#29702;&#35770;&#24314;&#31435;&#20102;&#25968;&#23398;&#32852;&#31995;&#65292;&#20026;&#22686;&#24378;&#30456;&#20114;&#20316;&#29992;&#27169;&#22411;&#25552;&#20379;&#20102;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.00904</link><description>&lt;p&gt;
&#30456;&#20114;&#20316;&#29992;&#27979;&#37327;&#65292;&#20998;&#21306;&#26684;&#21644;&#26680;&#27979;&#35797;&#29992;&#20110;&#39640;&#38454;&#30456;&#20114;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
Interaction Measures, Partition Lattices and Kernel Tests for High-Order Interactions. (arXiv:2306.00904v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00904
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39640;&#38454;&#30456;&#20114;&#20316;&#29992;&#30340;&#27979;&#37327;&#26041;&#27861;&#21644;&#22522;&#20110;&#26680;&#30340;&#27979;&#35797;&#26041;&#27861;&#65292;&#24182;&#19982;&#26684;&#29702;&#35770;&#24314;&#31435;&#20102;&#25968;&#23398;&#32852;&#31995;&#65292;&#20026;&#22686;&#24378;&#30456;&#20114;&#20316;&#29992;&#27169;&#22411;&#25552;&#20379;&#20102;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20165;&#20381;&#36182;&#20110;&#25104;&#23545;&#20851;&#31995;&#30340;&#27169;&#22411;&#24448;&#24448;&#26080;&#27861;&#25429;&#25417;&#21040;&#21508;&#31181;&#39046;&#22495;&#65288;&#22914;&#31038;&#20250;&#32463;&#27982;&#12289;&#29983;&#24577;&#25110;&#29983;&#29289;&#21307;&#23398;&#31995;&#32479;&#65289;&#20013;&#25214;&#21040;&#30340;&#22797;&#26434;&#22810;&#21464;&#37327;&#25968;&#25454;&#30340;&#23436;&#25972;&#32479;&#35745;&#32467;&#26500;&#12290;&#20004;&#20010;&#20197;&#19978;&#21464;&#37327;&#32452;&#20043;&#38388;&#30340;&#38750;&#24179;&#20961;&#20381;&#36182;&#20851;&#31995;&#22312;&#36825;&#20123;&#31995;&#32479;&#30340;&#20998;&#26512;&#21644;&#24314;&#27169;&#20013;&#21487;&#20197;&#21457;&#25381;&#37325;&#35201;&#20316;&#29992;&#65292;&#20294;&#20174;&#25968;&#25454;&#20013;&#25552;&#21462;&#36825;&#26679;&#30340;&#39640;&#38454;&#30456;&#20114;&#20316;&#29992;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31995;&#21015;$d$-order ($d \geq 2$)&#30456;&#20114;&#20316;&#29992;&#27979;&#37327;&#65292;&#20381;&#27425;&#21253;&#25324;&#21487;&#33021;&#30340;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#20998;&#35299;&#65292;&#24182;&#23450;&#20041;&#20102;&#38750;&#21442;&#25968;&#12289;&#22522;&#20110;&#26680;&#30340;&#27979;&#35797;&#65292;&#20197;&#31995;&#32479;&#22320;&#30830;&#23450;$d$-order&#30456;&#20114;&#20316;&#29992;&#30340;&#32479;&#35745;&#26174;&#30528;&#24615;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19982;&#26684;&#29702;&#35770;&#30340;&#25968;&#23398;&#32852;&#31995;&#65292;&#38416;&#26126;&#20102;&#30456;&#20114;&#20316;&#29992;&#24230;&#37327;&#30340;&#23548;&#20986;&#21450;&#20854;&#22797;&#21512;&#25490;&#21015;&#27979;&#35797;&#30340;&#28085;&#20041;&#65307;&#28548;&#28165;&#20102;&#21333;&#32431;&#22797;&#21512;&#20307;&#19982;&#26680;&#30697;&#38453;&#20013;&#24515;&#21270;&#30340;&#32852;&#31995;&#65307;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#22686;&#24378;&#30456;&#20114;&#20316;&#29992;&#27169;&#22411;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Models that rely solely on pairwise relationships often fail to capture the complete statistical structure of the complex multivariate data found in diverse domains, such as socio-economic, ecological, or biomedical systems. Non-trivial dependencies between groups of more than two variables can play a significant role in the analysis and modelling of such systems, yet extracting such high-order interactions from data remains challenging. Here, we introduce a hierarchy of $d$-order ($d \geq 2$) interaction measures, increasingly inclusive of possible factorisations of the joint probability distribution, and define non-parametric, kernel-based tests to establish systematically the statistical significance of $d$-order interactions. We also establish mathematical links with lattice theory, which elucidate the derivation of the interaction measures and their composite permutation tests; clarify the connection of simplicial complexes with kernel matrix centring; and provide a means to enhan
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#29992;&#20110;&#20174;&#26410;&#30693;&#24178;&#39044;&#25968;&#25454;&#20013;&#25512;&#26029;&#38750;&#21442;&#25968;&#22240;&#26524;&#34920;&#36798;&#24335;&#23398;&#20064;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#22312;&#20004;&#20010;&#22240;&#26524;&#21464;&#37327;&#30340;&#22522;&#26412;&#35774;&#32622;&#20013;&#65292;&#26080;&#27861;&#28040;&#38500;&#19968;&#20123;&#30001;&#24178;&#39044;&#25968;&#25454;&#24341;&#36215;&#30340;&#27495;&#20041;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.00542</link><description>&lt;p&gt;
&#26410;&#30693;&#24178;&#39044;&#30340;&#22240;&#26524;&#34920;&#36798;&#24335;&#30340;&#38750;&#21442;&#25968;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Nonparametric Identifiability of Causal Representations from Unknown Interventions. (arXiv:2306.00542v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00542
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#29992;&#20110;&#20174;&#26410;&#30693;&#24178;&#39044;&#25968;&#25454;&#20013;&#25512;&#26029;&#38750;&#21442;&#25968;&#22240;&#26524;&#34920;&#36798;&#24335;&#23398;&#20064;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#22312;&#20004;&#20010;&#22240;&#26524;&#21464;&#37327;&#30340;&#22522;&#26412;&#35774;&#32622;&#20013;&#65292;&#26080;&#27861;&#28040;&#38500;&#19968;&#20123;&#30001;&#24178;&#39044;&#25968;&#25454;&#24341;&#36215;&#30340;&#27495;&#20041;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#22240;&#26524;&#34920;&#36798;&#24335;&#23398;&#20064;&#65292;&#21363;&#20174;&#21464;&#37327;&#30340;&#39640;&#32500;&#20989;&#25968;&#65288;&#8220;&#28151;&#21512;&#29289;&#8221;&#65289;&#20013;&#25512;&#26029;&#28508;&#22312;&#30340;&#22240;&#26524;&#21464;&#37327;&#21450;&#20854;&#22240;&#26524;&#20851;&#31995;&#30340;&#20219;&#21153;&#12290;&#20197;&#21069;&#30340;&#24037;&#20316;&#20381;&#36182;&#20110;&#24369;&#30417;&#30563;&#65292;&#22914;&#21453;&#20107;&#23454;&#30340;&#24178;&#39044;&#35266;&#23519;&#25110;&#26102;&#38388;&#32467;&#26500;&#65307;&#23545;&#28151;&#21512;&#20989;&#25968;&#25110;&#28508;&#22312;&#22240;&#26524;&#27169;&#22411;&#26045;&#21152;&#38480;&#21046;&#65292;&#22914;&#32447;&#24615;&#65307;&#25110;&#38656;&#35201;&#37096;&#20998;&#20102;&#35299;&#29983;&#25104;&#36807;&#31243;&#65292;&#22914;&#22240;&#26524;&#22270;&#25110;&#24178;&#39044;&#30446;&#26631;&#12290;&#25105;&#20204;&#32771;&#34385;&#21040;&#22240;&#26524;&#27169;&#22411;&#21644;&#28151;&#21512;&#20989;&#25968;&#37117;&#26159;&#38750;&#21442;&#25968;&#30340;&#19968;&#33324;&#24773;&#20917;&#12290;&#23398;&#20064;&#20449;&#21495;&#37319;&#29992;&#26469;&#33258;&#22522;&#30784;&#22240;&#26524;&#27169;&#22411;&#20013;&#26410;&#30693;&#24178;&#39044;&#30340;&#22810;&#20010;&#25968;&#25454;&#38598;&#25110;&#29615;&#22659;&#30340;&#24418;&#24335;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#23558;&#22320;&#38754;&#30495;&#23454;&#28508;&#21464;&#37327;&#21450;&#20854;&#22240;&#26524;&#22270;&#37492;&#23450;&#20986;&#26469;&#65292;&#21516;&#26102;&#35299;&#20915;&#19968;&#32452;&#20174;&#24178;&#39044;&#25968;&#25454;&#26080;&#27861;&#28040;&#38500;&#30340;&#27495;&#20041;&#38382;&#39064;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#20010;&#22240;&#26524;&#21464;&#37327;&#30340;&#22522;&#26412;&#35774;&#32622;&#65292;&#24182;&#35777;&#26126;&#20102;...
&lt;/p&gt;
&lt;p&gt;
We study causal representation learning, the task of inferring latent causal variables and their causal relations from high-dimensional functions ("mixtures") of the variables. Prior work relies on weak supervision, in the form of counterfactual pre- and post-intervention views or temporal structure; places restrictive assumptions, such as linearity, on the mixing function or latent causal model; or requires partial knowledge of the generative process, such as the causal graph or the intervention targets. We instead consider the general setting in which both the causal model and the mixing function are nonparametric. The learning signal takes the form of multiple datasets, or environments, arising from unknown interventions in the underlying causal model. Our goal is to identify both the ground truth latents and their causal graph up to a set of ambiguities which we show to be irresolvable from interventional data. We study the fundamental setting of two causal variables and prove that
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#21487;&#22797;&#21046;&#24615;&#65292;&#25552;&#20986;&#20102;&#21487;&#22797;&#21046;&#31639;&#27861;&#21644;&#26494;&#24347;&#21487;&#22797;&#21046;&#31639;&#27861;&#65292;&#24182;&#32473;&#20986;&#20102;&#30456;&#24212;&#30340;&#26102;&#38388;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#36825;&#23545;&#20110;RL&#31639;&#27861;&#35774;&#35745;&#20197;&#21450;&#26410;&#26469;&#30340;&#21487;&#22797;&#21046;&#24615;&#30740;&#31350;&#20855;&#26377;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2305.19562</link><description>&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#21487;&#22797;&#29616;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Replicability in Reinforcement Learning. (arXiv:2305.19562v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19562
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#21487;&#22797;&#21046;&#24615;&#65292;&#25552;&#20986;&#20102;&#21487;&#22797;&#21046;&#31639;&#27861;&#21644;&#26494;&#24347;&#21487;&#22797;&#21046;&#31639;&#27861;&#65292;&#24182;&#32473;&#20986;&#20102;&#30456;&#24212;&#30340;&#26102;&#38388;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#36825;&#23545;&#20110;RL&#31639;&#27861;&#35774;&#35745;&#20197;&#21450;&#26410;&#26469;&#30340;&#21487;&#22797;&#21046;&#24615;&#30740;&#31350;&#20855;&#26377;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#24378;&#21270;&#23398;&#20064; (RL) &#30340;&#32972;&#26223;&#19979;&#65292;&#23558;&#21487;&#22797;&#29616;&#24615;&#20316;&#20026;&#31639;&#27861;&#23646;&#24615;&#36827;&#34892;&#20102;&#25968;&#23398;&#30740;&#31350;&#12290;&#25105;&#20204;&#20851;&#27880;&#30340;&#26159;&#20855;&#26377;&#29983;&#25104;&#27169;&#22411;&#35775;&#38382;&#26435;&#30340;&#24102;&#25240;&#25187;&#34920;&#26684;MDP&#30340;&#22522;&#26412;&#35774;&#32622;&#12290;&#21463;Impagliazzo&#31561;&#20154; [2022]&#30340;&#21551;&#21457;&#65292;&#22914;&#26524;&#22312;&#20869;&#37096;&#38543;&#26426;&#24615;&#30456;&#21516;&#26102;&#65292;RL&#31639;&#27861;&#22312;&#20174;&#29983;&#25104;&#22120;&#25277;&#21462;&#30340;&#20004;&#20010;&#29420;&#31435;&#21644;&#21516;&#20998;&#24067;&#30340;&#26679;&#26412;&#19978;&#25191;&#34892;&#20004;&#27425;&#24182;&#36755;&#20986;&#23436;&#20840;&#30456;&#21516;&#30340;&#31574;&#30053;&#65292;&#21017;&#34920;&#31034;&#35813;RL&#31639;&#27861;&#26159;&#21487;&#22797;&#21046;&#30340;&#12290;&#25105;&#20204;&#39318;&#20808;&#25552;&#20379;&#19968;&#20010;&#26377;&#25928;&#30340;$\rho$-&#21487;&#22797;&#21046;&#31639;&#27861;&#65292;&#29992;&#20110;$(\varepsilon,\delta)$-&#26368;&#20248;&#31574;&#30053;&#20272;&#35745;&#65292;&#20854;&#26679;&#26412;&#21644;&#26102;&#38388;&#22797;&#26434;&#24230;&#20026; $\widetilde O\left(\frac{N^3\cdot\log(1/\delta)}{(1-\gamma)^5\cdot\varepsilon^2\cdot\rho^2}\right)$&#65292;&#20854;&#20013;$N$&#26159;&#29366;&#24577;-&#21160;&#20316;&#23545;&#30340;&#25968;&#37327;&#12290;&#28982;&#21518;&#65292;&#23545;&#20110;&#30830;&#23450;&#24615;&#31639;&#27861;&#30340;&#23376;&#31867;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102; $ \Omega\left(\frac {N^3}{(1-\gamma)^3\cdot\varepsilon^2\cdot\rho^2}\right) $ &#38454;&#30340;&#19979;&#38480;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;Kalavasis&#31561;&#20154;[2019]&#25552;&#20986;&#30340;&#21487;&#22797;&#21046;&#24615;&#30340;&#26494;&#24347;&#29256;&#26412;&#65292;&#20854;&#20013;&#20165;&#35201;&#27714;&#31639;&#27861;&#30340;&#36755;&#20986;&#25509;&#36817;&#22797;&#21046;&#31639;&#27861;&#30340;&#36755;&#20986;&#65292;&#32780;&#19981;&#26159;&#30456;&#21516;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#25928;&#31639;&#27861;&#65292;&#20854;&#26102;&#38388;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026; $\widetilde O\left(\frac{N^5\cdot\log(1/\delta)}{(1-\gamma)^9\cdot\varepsilon^4\cdot\rho^2}\right)$&#65292;&#29992;&#20110;$(\varepsilon,\delta)$&#24847;&#20041;&#19979;&#30340;&#21487;&#22797;&#21046;&#24615;&#65292;&#36825;&#27604;&#20808;&#21069;&#19982;&#30456;&#20851;&#38382;&#39064;&#30340;&#30028;&#38480;&#26356;&#22909;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#25105;&#20204;&#30340;&#32467;&#26524;&#23545;RL&#31639;&#27861;&#35774;&#35745;&#21644;&#21487;&#37325;&#22797;&#24615;&#30740;&#31350;&#30340;&#26410;&#26469;&#26041;&#21521;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
We initiate the mathematical study of replicability as an algorithmic property in the context of reinforcement learning (RL). We focus on the fundamental setting of discounted tabular MDPs with access to a generative model. Inspired by Impagliazzo et al. [2022], we say that an RL algorithm is replicable if, with high probability, it outputs the exact same policy after two executions on i.i.d. samples drawn from the generator when its internal randomness is the same. We first provide an efficient $\rho$-replicable algorithm for $(\varepsilon, \delta)$-optimal policy estimation with sample and time complexity $\widetilde O\left(\frac{N^3\cdot\log(1/\delta)}{(1-\gamma)^5\cdot\varepsilon^2\cdot\rho^2}\right)$, where $N$ is the number of state-action pairs. Next, for the subclass of deterministic algorithms, we provide a lower bound of order $\Omega\left(\frac{N^3}{(1-\gamma)^3\cdot\varepsilon^2\cdot\rho^2}\right)$. Then, we study a relaxed version of replicability proposed by Kalavasis et 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#21333;&#19968;&#29983;&#25104;&#27969;&#32593;&#32476;&#20013;&#32852;&#21512;&#24314;&#27169;&#36125;&#21494;&#26031;&#32593;&#32476;&#32467;&#26500;&#21644;&#21442;&#25968;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#38750;&#31163;&#25955;&#26679;&#26412;&#31354;&#38388;&#65292;&#25552;&#39640;&#20102;&#36125;&#21494;&#26031;&#32593;&#32476;&#23616;&#37096;&#27010;&#29575;&#27169;&#22411;&#30340;&#28789;&#27963;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.19366</link><description>&lt;p&gt;
&#21333;&#19968;&#29983;&#25104;&#27969;&#32593;&#32476;&#20013;&#30340;&#22270;&#32467;&#26500;&#19982;&#21442;&#25968;&#30340;&#32852;&#21512;&#36125;&#21494;&#26031;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Joint Bayesian Inference of Graphical Structure and Parameters with a Single Generative Flow Network. (arXiv:2305.19366v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19366
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#21333;&#19968;&#29983;&#25104;&#27969;&#32593;&#32476;&#20013;&#32852;&#21512;&#24314;&#27169;&#36125;&#21494;&#26031;&#32593;&#32476;&#32467;&#26500;&#21644;&#21442;&#25968;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#38750;&#31163;&#25955;&#26679;&#26412;&#31354;&#38388;&#65292;&#25552;&#39640;&#20102;&#36125;&#21494;&#26031;&#32593;&#32476;&#23616;&#37096;&#27010;&#29575;&#27169;&#22411;&#30340;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#27969;&#32593;&#32476;&#26159;&#19968;&#31867;&#23545;&#31163;&#25955;&#21644;&#32467;&#26500;&#21270;&#26679;&#26412;&#31354;&#38388;&#36827;&#34892;&#24314;&#27169;&#30340;&#29983;&#25104;&#27169;&#22411;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#24050;&#23558;&#20854;&#24212;&#29992;&#20110;&#25512;&#26029;&#32473;&#23450;&#35266;&#27979;&#25968;&#25454;&#30340;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;DAG&#65289;&#30340;&#36793;&#32536;&#21518;&#39564;&#20998;&#24067;&#12290;&#26412;&#25991;&#22522;&#20110;&#26368;&#36817;&#30340;&#30740;&#31350;&#36827;&#23637;&#65292;&#22312;&#38750;&#31163;&#25955;&#26679;&#26412;&#31354;&#38388;&#19978;&#23558;&#27492;&#26694;&#26550;&#25193;&#23637;&#21040;&#32852;&#21512;&#21518;&#39564;&#20998;&#24067;&#30340;&#24314;&#27169;&#65292;&#19981;&#20165;&#21253;&#25324;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#32467;&#26500;&#65292;&#36824;&#32771;&#34385;&#20102;&#20854;&#26465;&#20214;&#27010;&#29575;&#20998;&#24067;&#30340;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative Flow Networks (GFlowNets), a class of generative models over discrete and structured sample spaces, have been previously applied to the problem of inferring the marginal posterior distribution over the directed acyclic graph (DAG) of a Bayesian Network, given a dataset of observations. Based on recent advances extending this framework to non-discrete sample spaces, we propose in this paper to approximate the joint posterior over not only the structure of a Bayesian Network, but also the parameters of its conditional probability distributions. We use a single GFlowNet whose sampling policy follows a two-phase process: the DAG is first generated sequentially one edge at a time, and then the corresponding parameters are picked once the full structure is known. Since the parameters are included in the posterior distribution, this leaves more flexibility for the local probability models of the Bayesian Network, making our approach applicable even to non-linear models parametrized
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;Bayesian&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#26469;&#21387;&#32553;&#25968;&#25454;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270; $\beta$-ELBO &#30452;&#25509;&#20248;&#21270;&#30721;-&#22833;&#30495;&#24615;&#33021;&#65292;&#24182;&#36890;&#36807;&#35843;&#25972; $\beta$ &#26469;&#38024;&#23545;&#32473;&#23450;&#30340;&#32593;&#32476;&#32467;&#26500;&#23454;&#29616;&#19981;&#21516;&#30340;&#30721;-&#22833;&#30495;&#24179;&#34913;&#12290;</title><link>http://arxiv.org/abs/2305.19185</link><description>&lt;p&gt;
Bayesian&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#19979;&#30340;&#21387;&#32553;
&lt;/p&gt;
&lt;p&gt;
Compression with Bayesian Implicit Neural Representations. (arXiv:2305.19185v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19185
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;Bayesian&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#26469;&#21387;&#32553;&#25968;&#25454;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270; $\beta$-ELBO &#30452;&#25509;&#20248;&#21270;&#30721;-&#22833;&#30495;&#24615;&#33021;&#65292;&#24182;&#36890;&#36807;&#35843;&#25972; $\beta$ &#26469;&#38024;&#23545;&#32473;&#23450;&#30340;&#32593;&#32476;&#32467;&#26500;&#23454;&#29616;&#19981;&#21516;&#30340;&#30721;-&#22833;&#30495;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#24120;&#35265;&#31867;&#22411;&#30340;&#25968;&#25454;&#21487;&#20197;&#34920;&#31034;&#20026;&#23558;&#22352;&#26631;&#26144;&#23556;&#21040;&#20449;&#21495;&#20540;&#30340;&#20989;&#25968;&#65292;&#20363;&#22914;&#22270;&#20687;&#20013;&#30340;&#20687;&#32032;&#20301;&#32622;&#21040;RGB&#20540;&#12290;&#22522;&#20110;&#36825;&#20010;&#35266;&#28857;&#65292;&#21487;&#20197;&#36890;&#36807;&#23545;&#25968;&#25454;&#30340;&#21151;&#33021;&#34920;&#31034;&#36827;&#34892;&#36229;&#25311;&#21512;&#65292;&#28982;&#21518;&#32534;&#30721;&#32593;&#32476;&#26435;&#37325;&#26469;&#21387;&#32553;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#24403;&#21069;&#30340;&#35299;&#20915;&#26041;&#26696;&#37117;&#25928;&#29575;&#20302;&#19979;&#65292;&#22240;&#20026;&#23558;&#31934;&#24230;&#37327;&#21270;&#21040;&#20302;&#27604;&#29305;&#20250;&#22823;&#24133;&#38477;&#20302;&#37325;&#26500;&#36136;&#37327;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36807;&#24230;&#25311;&#21512;&#21464;&#20998;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#26469;&#21387;&#32553;&#36817;&#20284;&#21518;&#39564;&#26435;&#37325;&#26679;&#26412;&#65292;&#32780;&#19981;&#26159;&#37327;&#21270;&#21644;&#29109;&#32534;&#30721;&#23427;&#12290;&#35813;&#31574;&#30053;&#36890;&#36807;&#26368;&#23567;&#21270; $\beta$-ELBO &#30452;&#25509;&#20248;&#21270;&#30721;-&#22833;&#30495;&#24615;&#33021;&#65292;&#24182;&#36890;&#36807;&#35843;&#25972; $\beta$ &#26469;&#38024;&#23545;&#32473;&#23450;&#30340;&#32593;&#32476;&#32467;&#26500;&#23454;&#29616;&#19981;&#21516;&#30340;&#30721;-&#22833;&#30495;&#24179;&#34913;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#23398;&#20064;&#20808;&#39564;&#26435;&#37325;&#20998;&#24067;&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#24182;&#37319;&#29992;&#20027;&#21160;&#23610;&#23544;&#35843;&#25972;&#26469;&#36827;&#19968;&#27493;&#25552;&#39640;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many common types of data can be represented as functions that map coordinates to signal values, such as pixel locations to RGB values in the case of an image. Based on this view, data can be compressed by overfitting a compact neural network to its functional representation and then encoding the network weights. However, most current solutions for this are inefficient, as quantization to low-bit precision substantially degrades the reconstruction quality. To address this issue, we propose overfitting variational Bayesian neural networks to the data and compressing an approximate posterior weight sample using relative entropy coding instead of quantizing and entropy coding it. This strategy enables direct optimization of the rate-distortion performance by minimizing the $\beta$-ELBO, and target different rate-distortion trade-offs for a given network architecture by adjusting $\beta$. Moreover, we introduce an iterative algorithm for learning prior weight distributions and employ a pro
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340; Gram &#30697;&#38453;&#32467;&#26500;&#65292;&#35777;&#26126;&#20102;&#28608;&#27963;&#20989;&#25968;&#21644;&#23618;&#35268;&#33539;&#21270;&#32467;&#21512;&#20351;&#29992;&#21487;&#20197;&#22312;&#21021;&#22987;&#21270;&#26102;&#20559;&#21521;&#25351;&#25968;&#32423;&#28145;&#24230;&#31561;&#36317;&#65292;&#20174;&#32780;&#24357;&#34917;&#20102;&#29616;&#26377;&#29702;&#35770;&#30340;&#31354;&#30333;&#12290;</title><link>http://arxiv.org/abs/2305.18399</link><description>&lt;p&gt;
&#20851;&#20110;&#28608;&#27963;&#20989;&#25968;&#21644;&#35268;&#33539;&#21270;&#23545;&#21021;&#22987;&#21270;&#31561;&#36317;&#23884;&#20837;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
On the impact of activation and normalization in obtaining isometric embeddings at initialization. (arXiv:2305.18399v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18399
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340; Gram &#30697;&#38453;&#32467;&#26500;&#65292;&#35777;&#26126;&#20102;&#28608;&#27963;&#20989;&#25968;&#21644;&#23618;&#35268;&#33539;&#21270;&#32467;&#21512;&#20351;&#29992;&#21487;&#20197;&#22312;&#21021;&#22987;&#21270;&#26102;&#20559;&#21521;&#25351;&#25968;&#32423;&#28145;&#24230;&#31561;&#36317;&#65292;&#20174;&#32780;&#24357;&#34917;&#20102;&#29616;&#26377;&#29702;&#35770;&#30340;&#31354;&#30333;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#20498;&#25968;&#31532;&#20108;&#20010; Gram &#30697;&#38453;&#30340;&#32467;&#26500;&#65292;&#35813;&#30697;&#38453;&#21253;&#21547;&#19982;&#19968;&#25209;&#36755;&#20837;&#23545;&#24212;&#30340;&#36755;&#20986;&#20043;&#38388;&#30340;&#25104;&#23545;&#20869;&#31215;&#12290;&#22312;&#20960;&#31181;&#26550;&#26500;&#20013;&#65292;&#35266;&#23519;&#21040;&#22312;&#21021;&#22987;&#21270;&#26102;&#35813; Gram &#30697;&#38453;&#20250;&#38543;&#30528;&#28145;&#24230;&#21464;&#24471;&#36864;&#21270;&#65292;&#20174;&#32780;&#20005;&#37325;&#20943;&#32531;&#35757;&#32451;&#36895;&#24230;&#12290;&#35268;&#33539;&#21270;&#23618;&#22914;&#25209;&#22788;&#29702;&#35268;&#33539;&#21270;&#25110;&#23618;&#35268;&#33539;&#21270;&#65292;&#22312;&#38450;&#27490;&#31209;&#23849;&#28291;&#38382;&#39064;&#26041;&#38754;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#28982;&#32780;&#29616;&#26377;&#30340;&#29702;&#35770;&#32467;&#26524;&#26080;&#27861;&#20840;&#38754;&#35206;&#30422;&#24191;&#27867;&#29992;&#20110; transformer &#20013;&#30340;&#23618;&#35268;&#33539;&#21270;&#21644;&#26377;&#38480;&#28145;&#24230;&#19979;&#35268;&#33539;&#21270;&#30340;&#37327;&#21270;&#20559;&#24046;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#21021;&#22987;&#21270;&#26102;&#65292;&#32467;&#21512;&#28608;&#27963;&#20989;&#25968;&#23618;&#20351;&#29992;&#30340;&#23618;&#35268;&#33539;&#21270;&#21487;&#20197;&#20351;&#22810;&#23618;&#24863;&#30693;&#26426;&#30340; Gram &#30697;&#38453;&#20559;&#21521;&#25351;&#25968;&#32423;&#28145;&#24230;&#31561;&#36317;&#65292;&#24182;&#20351;&#29992;&#28608;&#27963;&#20989;&#25968;&#30340; Hermite &#23637;&#24320;&#26469;&#37327;&#21270;&#36825;&#20010;&#36895;&#24230;&#65292;&#20174;&#32780;&#22635;&#34917;&#20102;&#29616;&#26377;&#29702;&#35770;&#30340;&#31354;&#30333;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we explore the structure of the penultimate Gram matrix in deep neural networks, which contains the pairwise inner products of outputs corresponding to a batch of inputs. In several architectures it has been observed that this Gram matrix becomes degenerate with depth at initialization, which dramatically slows training. Normalization layers, such as batch or layer normalization, play a pivotal role in preventing the rank collapse issue. Despite promising advances, the existing theoretical results (i) do not extend to layer normalization, which is widely used in transformers, (ii) can not characterize the bias of normalization quantitatively at finite depth.  To bridge this gap, we provide a proof that layer normalization, in conjunction with activation layers, biases the Gram matrix of a multilayer perceptron towards isometry at an exponential rate with depth at initialization. We quantify this rate using the Hermite expansion of the activation function, highlighting th
&lt;/p&gt;</description></item><item><title>ITO Learning&#26159;&#19968;&#20010;&#23398;&#20064;&#20998;&#23376;&#21160;&#21147;&#23398;&#22810;&#26102;&#38388;&#20998;&#36776;&#29575;&#20195;&#29702;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#29983;&#25104;&#33258;&#27965;&#30340;&#38543;&#26426;&#21160;&#21147;&#23398;&#65292;&#33410;&#30465;&#25968;&#30334;&#20493;&#30340;&#26102;&#38388;&#12290;</title><link>http://arxiv.org/abs/2305.18046</link><description>&lt;p&gt;
&#38544;&#24335;&#36716;&#31227;&#31639;&#23376;&#23398;&#20064;&#65306;&#20998;&#23376;&#21160;&#21147;&#23398;&#22810;&#26102;&#38388;&#20998;&#36776;&#29575;&#20195;&#29702;
&lt;/p&gt;
&lt;p&gt;
Implicit Transfer Operator Learning: Multiple Time-Resolution Surrogates for Molecular Dynamics. (arXiv:2305.18046v1 [physics.chem-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18046
&lt;/p&gt;
&lt;p&gt;
ITO Learning&#26159;&#19968;&#20010;&#23398;&#20064;&#20998;&#23376;&#21160;&#21147;&#23398;&#22810;&#26102;&#38388;&#20998;&#36776;&#29575;&#20195;&#29702;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#29983;&#25104;&#33258;&#27965;&#30340;&#38543;&#26426;&#21160;&#21147;&#23398;&#65292;&#33410;&#30465;&#25968;&#30334;&#20493;&#30340;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35745;&#31639;&#20998;&#23376;&#31995;&#32479;&#30340;&#24615;&#36136;&#38656;&#35201;&#20272;&#35745;&#65288;&#26410;&#24402;&#19968;&#21270;&#30340;&#65289;&#29627;&#23572;&#20857;&#26364;&#20998;&#24067;&#30340;&#26399;&#26395;&#20540;&#12290;&#20998;&#23376;&#21160;&#21147;&#23398;&#65288;MD&#65289;&#26159;&#19968;&#31181;&#24191;&#27867;&#37319;&#29992;&#30340;&#25216;&#26415;&#65292;&#29992;&#20110;&#36817;&#20284;&#36825;&#31181;&#37327;&#12290;&#28982;&#32780;&#65292;&#31283;&#23450;&#30340;&#27169;&#25311;&#38656;&#35201;&#38750;&#24120;&#23567;&#30340;&#31215;&#20998;&#26102;&#38388;&#27493;&#38271;&#65288;$10^{-15}$&#31186;&#65289;&#65292;&#32780;&#19968;&#20123;&#30697;&#30340;&#25910;&#25947;&#24615;&#65292;&#20363;&#22914;&#32467;&#21512;&#33258;&#30001;&#33021;&#25110;&#36895;&#29575;&#65292;&#21487;&#33021;&#20381;&#36182;&#20110;&#38271;&#36798;$10^{-1}$&#31186;&#30340;&#26102;&#38388;&#23610;&#24230;&#19978;&#30340;&#37319;&#26679;&#36807;&#31243;&#65292;&#24182;&#19988;&#24517;&#39035;&#23545;&#27599;&#20010;&#20998;&#23376;&#31995;&#32479;&#36827;&#34892;&#29420;&#31435;&#27169;&#25311;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#38544;&#24335;&#36716;&#31227;&#31639;&#23376;&#65288;ITO&#65289;&#23398;&#20064;&#65292;&#36825;&#26159;&#19968;&#20010;&#23398;&#20064;&#20855;&#26377;&#22810;&#20010;&#26102;&#38388;&#20998;&#36776;&#29575;&#30340;&#27169;&#25311;&#36807;&#31243;&#20195;&#29702;&#30340;&#26694;&#26550;&#12290;&#25105;&#20204;&#20351;&#29992;&#20855;&#26377;&#26032;SE&#65288;3&#65289;&#31561;&#21464;&#20307;&#31995;&#32467;&#26500;&#30340;&#21435;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#23454;&#29616;ITO&#65292;&#24182;&#23637;&#31034;&#32467;&#26524;&#27169;&#22411;&#21487;&#20197;&#22312;&#22810;&#20010;&#26102;&#38388;&#23610;&#24230;&#19978;&#29983;&#25104;&#33258;&#27965;&#30340;&#38543;&#26426;&#21160;&#21147;&#23398;&#65292;&#21363;&#20351;&#21482;&#26377;&#37096;&#20998;&#35266;&#27979;&#21040;&#31995;&#32479;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31895;&#31890;&#21270;&#30340;CG-SE3-ITO&#27169;&#22411;&#65292;&#24182;&#23637;&#31034;&#23427;&#21487;&#20197;&#22312;&#27169;&#25311;&#36807;&#31243;&#20013;&#33410;&#30465;&#25968;&#30334;&#20493;&#30340;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
Computing properties of molecular systems rely on estimating expectations of the (unnormalized) Boltzmann distribution. Molecular dynamics (MD) is a broadly adopted technique to approximate such quantities. However, stable simulations rely on very small integration time-steps ($10^{-15}\,\mathrm{s}$), whereas convergence of some moments, e.g. binding free energy or rates, might rely on sampling processes on time-scales as long as $10^{-1}\, \mathrm{s}$, and these simulations must be repeated for every molecular system independently. Here, we present Implict Transfer Operator (ITO) Learning, a framework to learn surrogates of the simulation process with multiple time-resolutions. We implement ITO with denoising diffusion probabilistic models with a new SE(3) equivariant architecture and show the resulting models can generate self-consistent stochastic dynamics across multiple time-scales, even when the system is only partially observed. Finally, we present a coarse-grained CG-SE3-ITO mo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#36890;&#36807;&#36172;&#21338;&#30340;&#26041;&#24335;&#36827;&#34892;&#20844;&#24179;&#24615;&#23457;&#35745;&#30340;&#26041;&#27861;&#65292;&#30456;&#27604;&#20043;&#21069;&#30340;&#26041;&#27861;&#65292;&#36825;&#31181;&#26041;&#27861;&#20855;&#26377;&#26356;&#39640;&#30340;&#23454;&#29992;&#24615;&#21644;&#25928;&#29575;&#65292;&#33021;&#22815;&#23545;&#19981;&#26029;&#20135;&#29983;&#30340;&#25968;&#25454;&#36827;&#34892;&#36830;&#32493;&#30340;&#30417;&#25511;&#65292;&#24182;&#22788;&#29702;&#22240;&#20998;&#24067;&#28418;&#31227;&#23548;&#33268;&#30340;&#20844;&#24179;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.17570</link><description>&lt;p&gt;
&#36890;&#36807;&#36172;&#21338;&#36827;&#34892;&#20844;&#24179;&#24615;&#23457;&#35745;
&lt;/p&gt;
&lt;p&gt;
Auditing Fairness by Betting. (arXiv:2305.17570v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17570
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#36890;&#36807;&#36172;&#21338;&#30340;&#26041;&#24335;&#36827;&#34892;&#20844;&#24179;&#24615;&#23457;&#35745;&#30340;&#26041;&#27861;&#65292;&#30456;&#27604;&#20043;&#21069;&#30340;&#26041;&#27861;&#65292;&#36825;&#31181;&#26041;&#27861;&#20855;&#26377;&#26356;&#39640;&#30340;&#23454;&#29992;&#24615;&#21644;&#25928;&#29575;&#65292;&#33021;&#22815;&#23545;&#19981;&#26029;&#20135;&#29983;&#30340;&#25968;&#25454;&#36827;&#34892;&#36830;&#32493;&#30340;&#30417;&#25511;&#65292;&#24182;&#22788;&#29702;&#22240;&#20998;&#24067;&#28418;&#31227;&#23548;&#33268;&#30340;&#20844;&#24179;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20379;&#20102;&#23454;&#29992;&#12289;&#39640;&#25928;&#12289;&#38750;&#21442;&#25968;&#26041;&#27861;&#65292;&#29992;&#20110;&#23457;&#35745;&#24050;&#37096;&#32626;&#30340;&#20998;&#31867;&#21644;&#22238;&#24402;&#27169;&#22411;&#30340;&#20844;&#24179;&#24615;&#12290;&#30456;&#27604;&#20043;&#21069;&#20381;&#36182;&#20110;&#22266;&#23450;&#26679;&#26412;&#37327;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#24207;&#36143;&#30340;&#65292;&#24182;&#20801;&#35768;&#23545;&#19981;&#26029;&#20135;&#29983;&#30340;&#25968;&#25454;&#36827;&#34892;&#36830;&#32493;&#30340;&#30417;&#25511;&#65292;&#22240;&#27492;&#38750;&#24120;&#36866;&#29992;&#20110;&#36319;&#36394;&#29616;&#23454;&#19990;&#30028;&#31995;&#32479;&#30340;&#20844;&#24179;&#24615;&#12290;&#25105;&#20204;&#20063;&#20801;&#35768;&#25968;&#25454;&#36890;&#36807;&#27010;&#29575;&#31574;&#30053;&#36827;&#34892;&#25910;&#38598;&#65292;&#32780;&#19981;&#26159;&#20174;&#20154;&#21475;&#20013;&#22343;&#21248;&#37319;&#26679;&#12290;&#36825;&#20351;&#24471;&#23457;&#35745;&#21487;&#20197;&#22312;&#20026;&#20854;&#20182;&#30446;&#30340;&#25910;&#38598;&#30340;&#25968;&#25454;&#19978;&#36827;&#34892;&#12290;&#27492;&#22806;&#65292;&#35813;&#31574;&#30053;&#21487;&#20197;&#38543;&#26102;&#38388;&#25913;&#21464;&#65292;&#24182;&#19988;&#19981;&#21516;&#30340;&#23376;&#20154;&#32676;&#21487;&#20197;&#20351;&#29992;&#19981;&#21516;&#30340;&#31574;&#30053;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#22788;&#29702;&#22240;&#27169;&#22411;&#21464;&#26356;&#25110;&#22522;&#30784;&#20154;&#32676;&#21464;&#26356;&#23548;&#33268;&#30340;&#20998;&#24067;&#28418;&#31227;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#26368;&#36817;&#20851;&#20110; anytime-valid &#25512;&#26029;&#21644;&#21338;&#24328;&#32479;&#35745;&#23398;&#30340;&#36827;&#23637;&#65292;&#23588;&#20854;&#26159;"&#36890;&#36807;&#36172;&#21338;&#36827;&#34892;&#27979;&#35797;"&#26694;&#26550;&#12290;&#36825;&#20123;&#32852;&#31995;&#30830;&#20445;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#21487;&#35299;&#37322;&#24615;&#12289;&#24555;&#36895;&#21644;&#25552;&#20379;&#32479;&#35745;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
We provide practical, efficient, and nonparametric methods for auditing the fairness of deployed classification and regression models. Whereas previous work relies on a fixed-sample size, our methods are sequential and allow for the continuous monitoring of incoming data, making them highly amenable to tracking the fairness of real-world systems. We also allow the data to be collected by a probabilistic policy as opposed to sampled uniformly from the population. This enables auditing to be conducted on data gathered for another purpose. Moreover, this policy may change over time and different policies may be used on different subpopulations. Finally, our methods can handle distribution shift resulting from either changes to the model or changes in the underlying population. Our approach is based on recent progress in anytime-valid inference and game-theoretic statistics-the "testing by betting" framework in particular. These connections ensure that our methods are interpretable, fast, 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#20013;&#38388;&#38382;&#39064;&#65306;&#22240;&#26524;&#25104;&#20998;&#20998;&#26512;(CauCA)&#65292;&#23427;&#26159;&#29420;&#31435;&#25104;&#20998;&#20998;&#26512;(ICA)&#21644;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;(CRL)&#30340;&#27867;&#21270;&#21644;&#29305;&#20363;&#65292;&#20854;&#30446;&#26631;&#26159;&#23398;&#20064;&#35299;&#28151;&#20989;&#25968;&#21644;&#22240;&#26524;&#26426;&#21046;&#65292;&#39044;&#35774;&#20102;&#22240;&#26524;&#22270;&#30340;&#30693;&#35782;&#12290;</title><link>http://arxiv.org/abs/2305.17225</link><description>&lt;p&gt;
&#22240;&#26524;&#25104;&#20998;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Causal Component Analysis. (arXiv:2305.17225v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17225
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#20013;&#38388;&#38382;&#39064;&#65306;&#22240;&#26524;&#25104;&#20998;&#20998;&#26512;(CauCA)&#65292;&#23427;&#26159;&#29420;&#31435;&#25104;&#20998;&#20998;&#26512;(ICA)&#21644;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;(CRL)&#30340;&#27867;&#21270;&#21644;&#29305;&#20363;&#65292;&#20854;&#30446;&#26631;&#26159;&#23398;&#20064;&#35299;&#28151;&#20989;&#25968;&#21644;&#22240;&#26524;&#26426;&#21046;&#65292;&#39044;&#35774;&#20102;&#22240;&#26524;&#22270;&#30340;&#30693;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29420;&#31435;&#25104;&#20998;&#20998;&#26512;(ICA)&#30340;&#30446;&#26631;&#26159;&#20174;&#28151;&#21512;&#35266;&#27979;&#21040;&#30340;&#21464;&#37327;&#20013;&#24674;&#22797;&#29420;&#31435;&#30340;&#28508;&#22312;&#21464;&#37327;&#12290;&#32780;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;(CRL)&#30340;&#30446;&#26631;&#26159;&#25512;&#26029;&#22240;&#26524;&#20851;&#31995;&#24378;&#30456;&#20851;&#24615;&#30340;&#28508;&#22312;&#21464;&#37327;&#65292;&#20197;&#21450;&#32534;&#30721;&#23427;&#20204;&#30340;&#22240;&#26524;&#20851;&#31995;&#30340;&#26410;&#30693;&#22270;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#20013;&#38388;&#38382;&#39064;&#65292;&#31216;&#20026;&#22240;&#26524;&#25104;&#20998;&#20998;&#26512;(CauCA)&#12290;CauCA&#21487;&#20197;&#34987;&#30475;&#20316;&#26159;ICA&#30340;&#19968;&#31181;&#25512;&#24191;&#65292;&#23545;&#28508;&#22312;&#25104;&#20998;&#20043;&#38388;&#30340;&#22240;&#26524;&#20381;&#36182;&#24314;&#27169;&#65292;&#20063;&#26159;CRL&#30340;&#19968;&#20010;&#29305;&#20363;&#12290;&#19982;CRL&#19981;&#21516;&#30340;&#26159;&#65292;&#23427;&#39044;&#35774;&#20102;&#22240;&#26524;&#22270;&#30340;&#30693;&#35782;&#65292;&#20165;&#20851;&#27880;&#20110;&#23398;&#20064;&#35299;&#28151;&#20989;&#25968;&#21644;&#22240;&#26524;&#26426;&#21046;&#12290;&#25152;&#26377;&#20851;&#20110;CauCA&#22238;&#25910;&#22522;&#30784;&#30495;&#30456;&#30340;&#19981;&#21487;&#33021;&#32467;&#26524;&#20063;&#36866;&#29992;&#20110;CRL&#65292;&#32780;&#21487;&#33021;&#24615;&#32467;&#26524;&#21487;&#20197;&#20316;&#20026;&#25193;&#23637;CRL&#30340;&#22522;&#30784;&#12290;&#25105;&#20204;&#23558;&#20174;&#23545;&#28508;&#22312;&#22240;&#26524;&#21464;&#37327;&#23454;&#26045;&#19981;&#21516;&#31867;&#22411;&#24178;&#39044;&#30340;&#22810;&#20010;&#25968;&#25454;&#38598;&#20013;&#34920;&#24449;CauCA&#30340;&#21487;&#35782;&#21035;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Independent Component Analysis (ICA) aims to recover independent latent variables from observed mixtures thereof. Causal Representation Learning (CRL) aims instead to infer causally related (thus often statistically dependent) latent variables, together with the unknown graph encoding their causal relationships. We introduce an intermediate problem termed Causal Component Analysis (CauCA). CauCA can be viewed as a generalization of ICA, modelling the causal dependence among the latent components, and as a special case of CRL. In contrast to CRL, it presupposes knowledge of the causal graph, focusing solely on learning the unmixing function and the causal mechanisms. Any impossibility results regarding the recovery of the ground truth in CauCA also apply for CRL, while possibility results may serve as a stepping stone for extensions to CRL. We characterize CauCA identifiability from multiple datasets generated through different types of interventions on the latent causal variables. As a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26641;&#30340;&#25193;&#25955;&#34203;&#23450;&#35860;&#26725;&#31639;&#27861;(TreeDSB)&#26469;&#35299;&#20915;&#22810;&#20803;&#26368;&#20248;&#36755;&#36816;(mOT)&#30340;&#38382;&#39064;&#65292;&#24182;&#21487;&#20197;&#24212;&#29992;&#20110;&#39640;&#32500;&#35774;&#32622;&#22914;&#22270;&#20687;&#25554;&#20540;&#21644;&#36125;&#21494;&#26031;&#34701;&#21512;&#12290;</title><link>http://arxiv.org/abs/2305.16557</link><description>&lt;p&gt;
&#22522;&#20110;&#26641;&#30340;&#25193;&#25955;&#34203;&#23450;&#35860;&#26725;&#31639;&#27861;&#22312;Wasserstein&#37325;&#24515;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Tree-Based Diffusion Schr\"odinger Bridge with Applications to Wasserstein Barycenters. (arXiv:2305.16557v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16557
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26641;&#30340;&#25193;&#25955;&#34203;&#23450;&#35860;&#26725;&#31639;&#27861;(TreeDSB)&#26469;&#35299;&#20915;&#22810;&#20803;&#26368;&#20248;&#36755;&#36816;(mOT)&#30340;&#38382;&#39064;&#65292;&#24182;&#21487;&#20197;&#24212;&#29992;&#20110;&#39640;&#32500;&#35774;&#32622;&#22914;&#22270;&#20687;&#25554;&#20540;&#21644;&#36125;&#21494;&#26031;&#34701;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20803;&#26368;&#20248;&#36755;&#36816;(mOT)&#26159;&#26368;&#20248;&#36755;&#36816;(OT)&#30340;&#19968;&#31181;&#25512;&#24191;&#65292;&#20854;&#26088;&#22312;&#26368;&#23567;&#21270;&#25104;&#26412;&#20989;&#25968;&#30456;&#23545;&#20110;&#26576;&#20123;&#39044;&#20808;&#25351;&#23450;&#30340;&#36793;&#38469;&#20998;&#24067;&#30340;&#31215;&#20998;&#12290;&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#20010;&#26641;&#24418;&#20108;&#27425;&#25104;&#26412;&#30340;&#29109;&#29256;&#26412;&#65292;&#21363;&#19968;&#31181;&#21487;&#20197;&#20889;&#20316;&#26641;&#33410;&#28857;&#20043;&#38388;&#25104;&#23545;&#25104;&#26412;&#20989;&#25968;&#20043;&#21644;&#30340;&#20989;&#25968;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;Tree-based Diffusion Schr\"odinger Bridge(TreeDSB)&#65292;&#36825;&#26159;&#25193;&#23637;&#20102;&#25193;&#25955;&#34203;&#23450;&#35860;&#26725;(DSB)&#31639;&#27861;&#30340;&#31639;&#27861;&#12290;TreeDSB&#23545;&#24212;&#20110;&#22810;&#20803;Sinkhorn&#31639;&#27861;&#30340;&#21160;&#24577;&#36830;&#32493;&#29366;&#24577;&#31354;&#38388;&#12290;&#25105;&#20204;&#26041;&#27861;&#30340;&#19968;&#20010;&#26174;&#33879;&#24212;&#29992;&#26159;&#35745;&#31639;Wasserstein&#37325;&#24515;&#65292;&#23427;&#21487;&#20197;&#34987;&#37325;&#26032;&#36716;&#21270;&#20026;&#22522;&#20110;&#26143;&#24418;&#26641;&#30340;mOT&#38382;&#39064;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#39640;&#32500;&#35774;&#32622;&#65292;&#22914;&#22270;&#20687;&#25554;&#20540;&#21644;&#36125;&#21494;&#26031;&#34701;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-marginal Optimal Transport (mOT), a generalization of OT, aims at minimizing the integral of a cost function with respect to a distribution with some prescribed marginals. In this paper, we consider an entropic version of mOT with a tree-structured quadratic cost, i.e., a function that can be written as a sum of pairwise cost functions between the nodes of a tree. To address this problem, we develop Tree-based Diffusion Schr\"odinger Bridge (TreeDSB), an extension of the Diffusion Schr\"odinger Bridge (DSB) algorithm. TreeDSB corresponds to a dynamic and continuous state-space counterpart of the multimarginal Sinkhorn algorithm. A notable use case of our methodology is to compute Wasserstein barycenters which can be recast as the solution of a mOT problem on a star-shaped tree. We demonstrate that our methodology can be applied in high-dimensional settings such as image interpolation and Bayesian fusion.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DoWG&#30340;&#26080;&#21442;&#25968;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#23427;&#26159;&#31532;&#19968;&#20010;&#26082;&#39640;&#25928;&#21448;&#36890;&#29992;&#30340;&#31639;&#27861;&#65292;&#33021;&#22815;&#33258;&#36866;&#24212;&#20110;&#24179;&#31283;&#21644;&#38750;&#24179;&#31283;&#38382;&#39064;&#65292;&#24182;&#19988;&#26080;&#38656;&#22238;&#28335;&#25628;&#32034;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2305.16284</link><description>&lt;p&gt;
DoWG&#23637;&#31034;&#65306;&#19968;&#31181;&#39640;&#25928;&#30340;&#36890;&#29992;&#26080;&#21442;&#25968;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
DoWG Unleashed: An Efficient Universal Parameter-Free Gradient Descent Method. (arXiv:2305.16284v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16284
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DoWG&#30340;&#26080;&#21442;&#25968;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#23427;&#26159;&#31532;&#19968;&#20010;&#26082;&#39640;&#25928;&#21448;&#36890;&#29992;&#30340;&#31639;&#27861;&#65292;&#33021;&#22815;&#33258;&#36866;&#24212;&#20110;&#24179;&#31283;&#21644;&#38750;&#24179;&#31283;&#38382;&#39064;&#65292;&#24182;&#19988;&#26080;&#38656;&#22238;&#28335;&#25628;&#32034;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26131;&#20110;&#23454;&#29616;&#30340;&#26080;&#21442;&#25968;&#26799;&#24230;&#20248;&#21270;&#22120;&#65306;DoWG&#65288;Weighted Gradients&#30340;&#36317;&#31163;&#65289;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#26159;&#39640;&#25928;&#30340;&#8212;&#8212;&#22312;&#19981;&#35843;&#25972;&#20219;&#20309;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#21305;&#37197;&#20248;&#21270;&#20984;&#20248;&#21270;&#20013;&#26368;&#20248;&#35843;&#30340;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#30452;&#21040;&#23545;&#25968;&#22240;&#23376;&#65292;&#24182;&#19988;&#26159;&#36890;&#29992;&#30340;&#8212;&#8212;&#33258;&#21160;&#36866;&#24212;&#24179;&#28369;&#21644;&#38750;&#24179;&#28369;&#38382;&#39064;&#12290;&#19982;AdaGrad&#65292;Adam&#25110;DoG&#31561;&#27969;&#34892;&#31639;&#27861;&#35745;&#31639;&#24179;&#26041;&#26799;&#24230;&#30340;&#36816;&#34892;&#24179;&#22343;&#20540;&#19981;&#21516;&#65292;DoWG&#20445;&#25345;&#36816;&#34892;&#24179;&#22343;&#20540;&#30340;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#36317;&#31163;&#30340;&#21152;&#26435;&#29256;&#26412;&#65292;&#36825;&#23545;&#20110;&#23454;&#29616;&#25152;&#38656;&#30340;&#24615;&#36136;&#33267;&#20851;&#37325;&#35201;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;DoWG&#26159;&#31532;&#19968;&#20010;&#19981;&#38656;&#35201;&#22238;&#28335;&#25628;&#32034;&#36807;&#31243;&#30340;&#26080;&#21442;&#25968;&#65292;&#39640;&#25928;&#21644;&#36890;&#29992;&#31639;&#27861;&#12290;&#23427;&#36824;&#26159;&#31532;&#19968;&#20010;&#36866;&#24212;&#20110;&#24179;&#31283;&#20248;&#21270;&#30340;&#26080;&#21442;&#25968;AdaGrad&#26679;&#24335;&#31639;&#27861;&#12290;&#20026;&#20102;&#34917;&#20805;&#25105;&#20204;&#30340;&#29702;&#35770;&#65292;&#25105;&#20204;&#36824;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;DoWG&#22312;&#31283;&#23450;&#30340;&#36793;&#32536;&#35757;&#32451;&#65292;&#24182;&#35777;&#26126;&#20854;&#22312;&#23454;&#36341;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a new easy-to-implement parameter-free gradient-based optimizer: DoWG (Distance over Weighted Gradients). We prove that DoWG is efficient -- matching the convergence rate of optimally tuned gradient descent in convex optimization up to a logarithmic factor without tuning any parameters, and universal -- automatically adapting to both smooth and nonsmooth problems. While popular algorithms such as AdaGrad, Adam, or DoG compute a running average of the squared gradients, DoWG maintains a new distance-based weighted version of the running average, which is crucial to achieve the desired properties. To our best knowledge, DoWG is the first parameter-free, efficient, and universal algorithm that does not require backtracking search procedures. It is also the first parameter-free AdaGrad style algorithm that adapts to smooth optimization. To complement our theory, we also show empirically that DoWG trains at the edge of stability, and validate its effectiveness on practic
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#26469;&#25551;&#36848;&#22312;&#21327;&#20316;&#23398;&#20064;&#20013;&#31454;&#20105;&#23545;&#25163;&#30340;&#19981;&#35802;&#23454;&#34892;&#20026;&#65292;&#25552;&#20986;&#20102;&#26426;&#21046;&#26469;&#28608;&#21169;&#35802;&#23454;&#27807;&#36890;&#65292;&#24182;&#30830;&#20445;&#23398;&#20064;&#36136;&#37327;&#19982;&#20840;&#38754;&#21512;&#20316;&#30456;&#24403;&#12290;</title><link>http://arxiv.org/abs/2305.16272</link><description>&lt;p&gt;
&#22312;&#21327;&#21516;&#23398;&#20064;&#21644;&#20248;&#21270;&#20013;&#28608;&#21169;&#31454;&#20105;&#23545;&#25163;&#35802;&#23454;&#34892;&#20026;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Incentivizing Honesty among Competitors in Collaborative Learning and Optimization. (arXiv:2305.16272v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16272
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#26469;&#25551;&#36848;&#22312;&#21327;&#20316;&#23398;&#20064;&#20013;&#31454;&#20105;&#23545;&#25163;&#30340;&#19981;&#35802;&#23454;&#34892;&#20026;&#65292;&#25552;&#20986;&#20102;&#26426;&#21046;&#26469;&#28608;&#21169;&#35802;&#23454;&#27807;&#36890;&#65292;&#24182;&#30830;&#20445;&#23398;&#20064;&#36136;&#37327;&#19982;&#20840;&#38754;&#21512;&#20316;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21327;&#21516;&#23398;&#20064;&#25216;&#26415;&#33021;&#22815;&#35753;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#35757;&#32451;&#27604;&#20165;&#21033;&#29992;&#21333;&#19968;&#25968;&#25454;&#28304;&#30340;&#27169;&#22411;&#25928;&#26524;&#26356;&#22909;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#28508;&#22312;&#30340;&#21442;&#19982;&#32773;&#26159;&#19979;&#28216;&#20219;&#21153;&#20013;&#30340;&#31454;&#20105;&#23545;&#25163;&#65292;&#22914;&#27599;&#20010;&#37117;&#24076;&#26395;&#36890;&#36807;&#25552;&#20379;&#26368;&#20339;&#25512;&#33616;&#26469;&#21560;&#24341;&#23458;&#25143;&#30340;&#20844;&#21496;&#12290;&#36825;&#21487;&#33021;&#20250;&#28608;&#21169;&#19981;&#35802;&#23454;&#30340;&#26356;&#26032;&#65292;&#25439;&#23475;&#20854;&#20182;&#21442;&#19982;&#32773;&#30340;&#27169;&#22411;&#65292;&#20174;&#32780;&#21487;&#33021;&#30772;&#22351;&#21327;&#20316;&#30340;&#22909;&#22788;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21046;&#23450;&#20102;&#19968;&#20010;&#27169;&#22411;&#26469;&#25551;&#36848;&#36825;&#31181;&#20132;&#20114;&#65292;&#24182;&#22312;&#35813;&#26694;&#26550;&#20869;&#30740;&#31350;&#20102;&#20004;&#20010;&#23398;&#20064;&#20219;&#21153;&#65306;&#21333;&#36718;&#22343;&#20540;&#20272;&#35745;&#21644;&#24378;&#20984;&#30446;&#26631;&#30340;&#22810;&#36718; SGD&#12290;&#23545;&#20110;&#19968;&#31867;&#33258;&#28982;&#30340;&#21442;&#19982;&#32773;&#34892;&#20026;&#65292;&#25105;&#20204;&#21457;&#29616;&#29702;&#24615;&#30340;&#23458;&#25143;&#20250;&#34987;&#28608;&#21169;&#24378;&#28872;&#22320;&#25805;&#32437;&#20182;&#20204;&#30340;&#26356;&#26032;&#65292;&#20174;&#32780;&#38450;&#27490;&#23398;&#20064;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26426;&#21046;&#26469;&#28608;&#21169;&#35802;&#23454;&#27807;&#36890;&#65292;&#24182;&#30830;&#20445;&#23398;&#20064;&#36136;&#37327;&#19982;&#20840;&#38754;&#21512;&#20316;&#30456;&#24403;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#19968;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Collaborative learning techniques have the potential to enable training machine learning models that are superior to models trained on a single entity's data. However, in many cases, potential participants in such collaborative schemes are competitors on a downstream task, such as firms that each aim to attract customers by providing the best recommendations. This can incentivize dishonest updates that damage other participants' models, potentially undermining the benefits of collaboration. In this work, we formulate a game that models such interactions and study two learning tasks within this framework: single-round mean estimation and multi-round SGD on strongly-convex objectives. For a natural class of player actions, we show that rational clients are incentivized to strongly manipulate their updates, preventing learning. We then propose mechanisms that incentivize honest communication and ensure learning quality comparable to full cooperation. Lastly, we empirically demonstrate the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#36339;&#36291;&#25193;&#25955;&#27169;&#22411;&#23454;&#29616;&#20102;&#19968;&#31181;&#36328;&#32500;&#24230;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20854;&#22312;&#22788;&#29702;&#19981;&#21516;&#32500;&#24230;&#25968;&#25454;&#26102;&#20855;&#26377;&#26356;&#22909;&#30340;&#20860;&#23481;&#24615;&#21644;&#25554;&#20540;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2305.16261</link><description>&lt;p&gt;
&#36339;&#36291;&#25193;&#25955;&#27169;&#22411;&#23454;&#29616;&#30340;&#36328;&#32500;&#24230;&#29983;&#25104;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Trans-Dimensional Generative Modeling via Jump Diffusion Models. (arXiv:2305.16261v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16261
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#36339;&#36291;&#25193;&#25955;&#27169;&#22411;&#23454;&#29616;&#20102;&#19968;&#31181;&#36328;&#32500;&#24230;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20854;&#22312;&#22788;&#29702;&#19981;&#21516;&#32500;&#24230;&#25968;&#25454;&#26102;&#20855;&#26377;&#26356;&#22909;&#30340;&#20860;&#23481;&#24615;&#21644;&#25554;&#20540;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#36890;&#36807;&#32852;&#21512;&#24314;&#27169;&#27599;&#20010;&#25968;&#25454;&#28857;&#30340;&#29366;&#24577;&#21644;&#23610;&#23544;&#65292;&#33258;&#28982;&#22320;&#22788;&#29702;&#19981;&#21516;&#32500;&#24230;&#30340;&#25968;&#25454;&#12290;&#35813;&#29983;&#25104;&#36807;&#31243;&#34987;&#23450;&#20041;&#20026;&#22312;&#19981;&#21516;&#32500;&#24230;&#31354;&#38388;&#20043;&#38388;&#36827;&#34892;&#36339;&#36291;&#25193;&#25955;&#30340;&#36807;&#31243;&#12290;&#25105;&#20204;&#39318;&#20808;&#23450;&#20041;&#20102;&#19968;&#20010;&#30772;&#22351;&#23610;&#23544;&#30340;&#21069;&#21521;&#22122;&#22768;&#36807;&#31243;&#65292;&#28982;&#21518;&#25512;&#23548;&#20986;&#19968;&#20010;&#21019;&#36896;&#23610;&#23544;&#30340;&#36870;&#21521;&#29983;&#25104;&#36807;&#31243;&#65292;&#20197;&#21450;&#19968;&#20010;&#26032;&#39062;&#30340;&#35777;&#25454;&#19979;&#30028;&#35757;&#32451;&#30446;&#26631;&#26469;&#23398;&#20064;&#36924;&#36817;&#35813;&#29983;&#25104;&#36807;&#31243;&#12290;&#36890;&#36807;&#27169;&#25311;&#25105;&#20204;&#23398;&#20064;&#21040;&#30340;&#36870;&#21521;&#29983;&#25104;&#36807;&#31243;&#30340;&#36817;&#20284;&#20540;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#32852;&#21512;&#29983;&#25104;&#29366;&#24577;&#20540;&#21644;&#23610;&#23544;&#65292;&#20174;&#32780;&#25552;&#20379;&#19968;&#31181;&#22788;&#29702;&#19981;&#21516;&#32500;&#24230;&#25968;&#25454;&#30340;&#26377;&#25928;&#26041;&#27861;&#12290;&#25105;&#20204;&#22312;&#20998;&#23376;&#21644;&#35270;&#39057;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#30456;&#36739;&#20110;&#22266;&#23450;&#32500;&#24230;&#30340;&#27169;&#22411;&#65292;&#25105;&#20204;&#25253;&#21578;&#20102;&#26356;&#22909;&#30340;&#19982;&#27979;&#35797;&#26102;&#25193;&#25955;&#24341;&#23548;&#25554;&#20540;&#20219;&#21153;&#20860;&#23481;&#24615;&#21644;&#25913;&#36827;&#30340;&#25554;&#20540;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new class of generative models that naturally handle data of varying dimensionality by jointly modeling the state and dimension of each datapoint. The generative process is formulated as a jump diffusion process that makes jumps between different dimensional spaces. We first define a dimension destroying forward noising process, before deriving the dimension creating time-reversed generative process along with a novel evidence lower bound training objective for learning to approximate it. Simulating our learned approximation to the time-reversed generative process then provides an effective way of sampling data of varying dimensionality by jointly generating state values and dimensions. We demonstrate our approach on molecular and video datasets of varying dimensionality, reporting better compatibility with test-time diffusion guidance imputation tasks and improved interpolation capabilities versus fixed dimensional models that generate state values and dimensions separate
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Koopman&#26680;&#30340;&#22238;&#24402;&#26041;&#27861;&#65292;&#29992;&#20110;&#39044;&#27979;&#38750;&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#30340;&#26102;&#38388;&#28436;&#21464;&#12290;&#35813;&#26041;&#27861;&#22312;&#26426;&#22120;&#20154;&#25805;&#20316;&#65292;&#35270;&#39057;&#39044;&#27979;&#21644;&#20132;&#36890;&#39044;&#27979;&#31561;&#21508;&#31181;&#24212;&#29992;&#20013;&#22343;&#26377;&#20248;&#24322;&#34920;&#29616;&#65292;&#24182;&#20855;&#26377;&#21487;&#35777;&#26126;&#30340;&#23398;&#20064;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2305.16215</link><description>&lt;p&gt;
Koopman&#26680;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Koopman Kernel Regression. (arXiv:2305.16215v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16215
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Koopman&#26680;&#30340;&#22238;&#24402;&#26041;&#27861;&#65292;&#29992;&#20110;&#39044;&#27979;&#38750;&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#30340;&#26102;&#38388;&#28436;&#21464;&#12290;&#35813;&#26041;&#27861;&#22312;&#26426;&#22120;&#20154;&#25805;&#20316;&#65292;&#35270;&#39057;&#39044;&#27979;&#21644;&#20132;&#36890;&#39044;&#27979;&#31561;&#21508;&#31181;&#24212;&#29992;&#20013;&#22343;&#26377;&#20248;&#24322;&#34920;&#29616;&#65292;&#24182;&#20855;&#26377;&#21487;&#35777;&#26126;&#30340;&#23398;&#20064;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#20915;&#31574;&#21046;&#23450;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#22914;&#24378;&#21270;&#23398;&#20064;&#65292;&#20381;&#36182;&#20110;&#27169;&#25311;&#22120;&#25110;&#39044;&#27979;&#27169;&#22411;&#26469;&#39044;&#27979;&#24863;&#20852;&#36259;&#30340;&#37327;&#30340;&#26102;&#38388;&#28436;&#21464;&#65292;&#20363;&#22914;&#26234;&#33021;&#20307;&#30340;&#29366;&#24577;&#25110;&#31574;&#30053;&#30340;&#22870;&#21169;&#12290;&#36825;&#20123;&#22797;&#26434;&#29616;&#35937;&#30340;&#39044;&#27979;&#36890;&#24120;&#30001;&#39640;&#24230;&#38750;&#32447;&#24615;&#30340;&#21160;&#21147;&#31995;&#32479;&#25551;&#36848;&#65292;&#20351;&#24471;&#23427;&#20204;&#22312;&#22522;&#20110;&#20248;&#21270;&#30340;&#20915;&#31574;&#21046;&#23450;&#20013;&#30340;&#20351;&#29992;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;Koopman&#31639;&#23376;&#29702;&#35770;&#36890;&#36807;&#36890;&#36807;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#25551;&#36848;&#39044;&#27979;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#36825;&#20351;&#24471;&#31995;&#32479;&#20998;&#26512;&#21644;&#38271;&#26399;&#39044;&#27979;&#21464;&#24471;&#31616;&#21333;--&#21482;&#28041;&#21450;&#30697;&#38453;&#20056;&#27861;&#12290;&#28982;&#32780;&#65292;&#23558;&#20854;&#36716;&#21270;&#20026;&#32447;&#24615;&#31995;&#32479;&#36890;&#24120;&#26159;&#38750;&#24179;&#20961;&#30340;&#21644;&#26410;&#30693;&#30340;&#65292;&#38656;&#35201;&#22522;&#20110;&#23398;&#20064;&#30340;&#26041;&#27861;&#12290;&#34429;&#28982;&#23384;&#22312;&#21508;&#31181;&#26041;&#27861;&#65292;&#20294;&#23427;&#20204;&#36890;&#24120;&#32570;&#20047;&#20851;&#38190;&#30340;&#23398;&#20064;&#29702;&#35770;&#20445;&#35777;&#65292;&#22240;&#27492;&#25152;&#33719;&#24471;&#30340;&#27169;&#22411;&#22312;&#25968;&#25454;&#21644;&#32500;&#24230;&#22686;&#21152;&#26102;&#30340;&#34892;&#20026;&#36890;&#24120;&#19981;&#28165;&#26970;&#12290;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;Koopman&#26680;&#30340;&#22238;&#24402;&#26041;&#27861;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#19978;&#36848;&#25361;&#25112;&#65292;&#35813;&#26041;&#27861;&#30452;&#25509;&#20174;&#21382;&#21490;&#35266;&#23519;&#20013;&#23398;&#20064;&#21040;&#26410;&#26469;&#39044;&#27979;&#22312;Koopman&#31639;&#23376;&#31354;&#38388;&#20013;&#30340;&#26144;&#23556;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20139;&#26377;&#21487;&#35777;&#26126;&#30340;&#23398;&#20064;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#22312;&#24191;&#27867;&#30340;&#24212;&#29992;&#20013;&#19982;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#21305;&#37197;&#65288;&#25110;&#20248;&#20110;&#65289;&#65292;&#21253;&#25324;&#26426;&#22120;&#20154;&#25805;&#20316;&#65292;&#35270;&#39057;&#39044;&#27979;&#21644;&#20132;&#36890;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many machine learning approaches for decision making, such as reinforcement learning, rely on simulators or predictive models to forecast the time-evolution of quantities of interest, e.g., the state of an agent or the reward of a policy. Forecasts of such complex phenomena are commonly described by highly nonlinear dynamical systems, making their use in optimization-based decision-making challenging. Koopman operator theory offers a beneficial paradigm for addressing this problem by characterizing forecasts via linear dynamical systems. This makes system analysis and long-term predictions simple -- involving only matrix multiplications. However, the transformation to a linear system is generally non-trivial and unknown, requiring learning-based approaches. While there exists a variety of approaches, they usually lack crucial learning-theoretic guarantees, such that the behavior of the obtained models with increasing data and dimensionality is often unclear. We address the aforemention
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#35757;&#32451;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;(LDMs)&#65292;&#36890;&#36807;&#39044;&#35757;&#32451;&#33258;&#32534;&#30721;&#22120;&#23558;&#39640;&#32500;&#20687;&#32032;&#31354;&#38388;&#36716;&#21464;&#20026;&#20302;&#32500;&#28508;&#22312;&#31354;&#38388;&#23454;&#29616;&#26356;&#39640;&#25928;&#24555;&#36895;&#30340;DMs&#35757;&#32451;&#65292;&#24182;&#19988;&#36890;&#36807;&#21482;&#24494;&#35843;&#27880;&#24847;&#21147;&#27169;&#22359;&#20943;&#23569;&#20102;&#21487;&#35757;&#32451;&#21442;&#25968;&#30340;&#25968;&#37327;&#12290;</title><link>http://arxiv.org/abs/2305.15759</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Latent Diffusion Models. (arXiv:2305.15759v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15759
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#35757;&#32451;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;(LDMs)&#65292;&#36890;&#36807;&#39044;&#35757;&#32451;&#33258;&#32534;&#30721;&#22120;&#23558;&#39640;&#32500;&#20687;&#32032;&#31354;&#38388;&#36716;&#21464;&#20026;&#20302;&#32500;&#28508;&#22312;&#31354;&#38388;&#23454;&#29616;&#26356;&#39640;&#25928;&#24555;&#36895;&#30340;DMs&#35757;&#32451;&#65292;&#24182;&#19988;&#36890;&#36807;&#21482;&#24494;&#35843;&#27880;&#24847;&#21147;&#27169;&#22359;&#20943;&#23569;&#20102;&#21487;&#35757;&#32451;&#21442;&#25968;&#30340;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;(DMs)&#34987;&#24191;&#27867;&#29992;&#20110;&#29983;&#25104;&#39640;&#36136;&#37327;&#22270;&#20687;&#25968;&#25454;&#38598;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#23427;&#20204;&#30452;&#25509;&#22312;&#39640;&#32500;&#20687;&#32032;&#31354;&#38388;&#20013;&#36816;&#34892;&#65292;DMs&#30340;&#20248;&#21270;&#35745;&#31639;&#25104;&#26412;&#39640;&#65292;&#38656;&#35201;&#38271;&#26102;&#38388;&#30340;&#35757;&#32451;&#12290;&#36825;&#23548;&#33268;&#30001;&#20110;&#24046;&#20998;&#38544;&#31169;&#30340;&#21487;&#32452;&#21512;&#24615;&#23646;&#24615;&#65292;&#22823;&#37327;&#22122;&#38899;&#27880;&#20837;&#21040;&#24046;&#20998;&#38544;&#31169;&#23398;&#20064;&#36807;&#31243;&#20013;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#35757;&#32451;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;(LDMs)&#12290;LDMs&#20351;&#29992;&#24378;&#22823;&#30340;&#39044;&#35757;&#32451;&#33258;&#32534;&#30721;&#22120;&#23558;&#39640;&#32500;&#20687;&#32032;&#31354;&#38388;&#20943;&#23569;&#21040;&#26356;&#20302;&#32500;&#30340;&#28508;&#22312;&#31354;&#38388;&#65292;&#20351;&#35757;&#32451;DMs&#26356;&#21152;&#39640;&#25928;&#21644;&#24555;&#36895;&#12290;&#19982;[Ghalebikesabi&#31561;&#20154;&#65292;2023]&#39044;&#20808;&#29992;&#20844;&#20849;&#25968;&#25454;&#39044;&#35757;&#32451;DMs&#65292;&#28982;&#21518;&#20877;&#29992;&#38544;&#31169;&#25968;&#25454;&#36827;&#34892;&#24494;&#35843;&#19981;&#21516;&#65292;&#25105;&#20204;&#20165;&#24494;&#35843;LDMs&#20013;&#19981;&#21516;&#23618;&#30340;&#27880;&#24847;&#21147;&#27169;&#22359;&#20197;&#33719;&#24471;&#38544;&#31169;&#25935;&#24863;&#25968;&#25454;&#65292;&#30456;&#23545;&#20110;&#25972;&#20010;DM&#24494;&#35843;&#65292;&#21487;&#20943;&#23569;&#22823;&#32422;96%&#30340;&#21487;&#35757;&#32451;&#21442;&#25968;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models (DMs) are widely used for generating high-quality image datasets. However, since they operate directly in the high-dimensional pixel space, optimization of DMs is computationally expensive, requiring long training times. This contributes to large amounts of noise being injected into the differentially private learning process, due to the composability property of differential privacy. To address this challenge, we propose training Latent Diffusion Models (LDMs) with differential privacy. LDMs use powerful pre-trained autoencoders to reduce the high-dimensional pixel space to a much lower-dimensional latent space, making training DMs more efficient and fast. Unlike [Ghalebikesabi et al., 2023] that pre-trains DMs with public data then fine-tunes them with private data, we fine-tune only the attention modules of LDMs at varying layers with privacy-sensitive data, reducing the number of trainable parameters by approximately 96% compared to fine-tuning the entire DM. We te
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23545;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#65288;BBVI&#65289;&#30340;&#20998;&#26512;&#65292;&#21457;&#29616;&#19968;&#20123;&#24120;&#35265;&#30340;&#31639;&#27861;&#35774;&#35745;&#36873;&#25321;&#21487;&#33021;&#20250;&#23548;&#33268;&#27425;&#20248;&#25910;&#25947;&#36895;&#29575;&#65292;&#20294;&#20351;&#29992;&#24102;&#26377;&#36817;&#31471;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;BBVI&#21487;&#20197;&#23454;&#29616;&#26368;&#24378;&#25910;&#25947;&#29575;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2305.15349</link><description>&lt;p&gt;
&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#25910;&#25947;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Black-Box Variational Inference Converges. (arXiv:2305.15349v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15349
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#65288;BBVI&#65289;&#30340;&#20998;&#26512;&#65292;&#21457;&#29616;&#19968;&#20123;&#24120;&#35265;&#30340;&#31639;&#27861;&#35774;&#35745;&#36873;&#25321;&#21487;&#33021;&#20250;&#23548;&#33268;&#27425;&#20248;&#25910;&#25947;&#36895;&#29575;&#65292;&#20294;&#20351;&#29992;&#24102;&#26377;&#36817;&#31471;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;BBVI&#21487;&#20197;&#23454;&#29616;&#26368;&#24378;&#25910;&#25947;&#29575;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#23436;&#25972;&#30340;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#65288;BBVI&#65289;&#30340;&#25910;&#25947;&#20445;&#35777;&#65292;&#20063;&#31216;&#20026;&#33945;&#29305;&#21345;&#32599;&#21464;&#20998;&#25512;&#26029;&#12290;&#23613;&#31649;&#26089;&#26399;&#30340;&#30740;&#31350;&#21482;&#38024;&#23545;&#31616;&#21270;&#29256;&#26412;&#30340;BBVI&#36827;&#34892;&#20102;&#30740;&#31350;&#65288;&#20363;&#22914;&#65292;&#26377;&#30028;&#22495;&#12289;&#26377;&#30028;&#25903;&#25345;&#12289;&#20165;&#38024;&#23545;&#23610;&#24230;&#36827;&#34892;&#20248;&#21270;&#31561;&#65289;&#65292;&#20294;&#25105;&#20204;&#30340;&#35774;&#32622;&#19981;&#38656;&#35201;&#20219;&#20309;&#36825;&#26679;&#30340;&#31639;&#27861;&#20462;&#25913;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#36866;&#29992;&#20110;&#23545;&#25968;&#24179;&#28369;&#21518;&#39564;&#23494;&#24230;&#65292;&#26080;&#35770;&#26159;&#21542;&#24378;&#23545;&#25968;&#20985;&#24615;&#20197;&#21450;&#20301;&#32622;-&#23610;&#24230;&#21464;&#20998;&#26063;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#25581;&#31034;&#20986;&#20102;&#19968;&#20123;&#24120;&#35265;&#30340;&#31639;&#27861;&#35774;&#35745;&#36873;&#25321;&#65292;&#29305;&#21035;&#26159;&#21464;&#20998;&#36817;&#20284;&#23610;&#24230;&#30340;&#38750;&#32447;&#24615;&#21442;&#25968;&#21270;&#65292;&#21487;&#33021;&#20250;&#23548;&#33268;&#27425;&#20248;&#25910;&#25947;&#36895;&#29575;&#12290;&#24184;&#36816;&#30340;&#26159;&#65292;&#36816;&#34892;&#24102;&#26377;&#36817;&#31471;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;BBVI&#21487;&#20197;&#32416;&#27491;&#36825;&#20123;&#38480;&#21046;&#65292;&#20174;&#32780;&#23454;&#29616;&#24050;&#30693;&#30340;&#26368;&#24378;&#25910;&#25947;&#29575;&#20445;&#35777;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#36817;&#31471;SGD&#19982;&#20854;&#20182;&#26631;&#20934;&#30340;BBVI&#23454;&#29616;&#36827;&#34892;&#27604;&#36739;&#65292;&#39564;&#35777;&#20102;&#36825;&#19968;&#29702;&#35770;&#32467;&#35770;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We provide the first convergence guarantee for full black-box variational inference (BBVI), also known as Monte Carlo variational inference. While preliminary investigations worked on simplified versions of BBVI (e.g., bounded domain, bounded support, only optimizing for the scale, and such), our setup does not need any such algorithmic modifications. Our results hold for log-smooth posterior densities with and without strong log-concavity and the location-scale variational family. Also, our analysis reveals that certain algorithm design choices commonly employed in practice, particularly, nonlinear parameterizations of the scale of the variational approximation, can result in suboptimal convergence rates. Fortunately, running BBVI with proximal stochastic gradient descent fixes these limitations, and thus achieves the strongest known convergence rate guarantees. We evaluate this theoretical insight by comparing proximal SGD against other standard implementations of BBVI on large-scale
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#33021;&#37327;&#30340;&#24402;&#19968;&#21270;&#27969;&#27169;&#22411;&#65288;EBFlow&#65289;&#65292;&#36890;&#36807;&#24471;&#20998;&#21305;&#37197;&#30446;&#26631;&#20248;&#21270;&#20351;&#20854;&#35757;&#32451;&#26356;&#39640;&#25928;&#65292;&#21516;&#26102;&#24320;&#21457;&#19968;&#20123;&#25216;&#26415;&#22686;&#24378;EBFlow&#30340;&#35757;&#32451;&#31283;&#23450;&#24615;&#21644;&#23454;&#35777;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2305.15267</link><description>&lt;p&gt;
&#35757;&#32451;&#22522;&#20110;&#33021;&#37327;&#30340;&#24402;&#19968;&#21270;&#27969;&#27169;&#22411;&#30340;&#24471;&#20998;&#21305;&#37197;&#30446;&#26631;
&lt;/p&gt;
&lt;p&gt;
Training Energy-Based Normalizing Flow with Score-Matching Objectives. (arXiv:2305.15267v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15267
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#33021;&#37327;&#30340;&#24402;&#19968;&#21270;&#27969;&#27169;&#22411;&#65288;EBFlow&#65289;&#65292;&#36890;&#36807;&#24471;&#20998;&#21305;&#37197;&#30446;&#26631;&#20248;&#21270;&#20351;&#20854;&#35757;&#32451;&#26356;&#39640;&#25928;&#65292;&#21516;&#26102;&#24320;&#21457;&#19968;&#20123;&#25216;&#26415;&#22686;&#24378;EBFlow&#30340;&#35757;&#32451;&#31283;&#23450;&#24615;&#21644;&#23454;&#35777;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24314;&#31435;&#20102;&#27969;&#27169;&#22411;&#21644;&#33021;&#37327;&#27169;&#22411;&#21442;&#25968;&#21270;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#33021;&#37327;&#30340;&#24402;&#19968;&#21270;&#27969;&#24314;&#27169;&#26041;&#27861;&#65288;EBFlow&#65289;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#36807;&#24471;&#20998;&#21305;&#37197;&#30446;&#26631;&#20248;&#21270;EBFlow&#65292;&#21487;&#20197;&#23436;&#20840;&#36991;&#24320;&#32447;&#24615;&#21464;&#25442;&#30340;&#38597;&#21487;&#27604;&#34892;&#21015;&#24335;&#35745;&#31639;&#12290;&#36825;&#20351;&#24471;EBFlow&#22312;&#26500;&#24314;&#22522;&#20110;&#27969;&#30340;&#27169;&#22411;&#26102;&#20351;&#29992;&#20219;&#24847;&#32447;&#24615;&#23618;&#65292;&#32780;&#19981;&#20250;&#20351;&#27599;&#20010;&#35757;&#32451;&#36845;&#20195;&#30340;&#35745;&#31639;&#26102;&#38388;&#22797;&#26434;&#24230;&#20174;$\mathcal{O}(D^2L)$&#22686;&#21152;&#21040;$\mathcal{O}(D^3L)$&#65292;&#20854;&#20013;$L$&#20026;&#23618;&#25968;&#65292;$D$&#20026;&#36755;&#20837;&#32500;&#24230;&#12290;&#36825;&#20351;&#24471;EBFlow&#30340;&#35757;&#32451;&#27604;&#24120;&#29992;&#30340;&#26368;&#22823;&#20284;&#28982;&#35757;&#32451;&#26041;&#27861;&#26356;&#39640;&#25928;&#12290;&#38500;&#20102;&#20943;&#23569;&#36816;&#34892;&#26102;&#38388;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#22522;&#20110;&#20998;&#20540;&#21305;&#37197;&#26041;&#27861;&#30340;&#20998;&#26512;&#24320;&#21457;&#20102;&#19968;&#20123;&#25216;&#26415;&#65292;&#20197;&#22686;&#24378;EBFlow&#30340;&#35757;&#32451;&#31283;&#23450;&#24615;&#21644;&#23454;&#35777;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we establish a connection between the parameterization of flow-based and energy-based generative models, and present a new flow-based modeling approach called energy-based normalizing flow (EBFlow). We demonstrate that by optimizing EBFlow with score-matching objectives, the computation of Jacobian determinants for linear transformations can be entirely bypassed. This feature enables the use of arbitrary linear layers in the construction of flow-based models without increasing the computational time complexity of each training iteration from $\mathcal{O}(D^2L)$ to $\mathcal{O}(D^3L)$ for an $L$-layered model that accepts $D$-dimensional inputs. This makes the training of EBFlow more efficient than the commonly-adopted maximum likelihood training method. In addition to the reduction in runtime, we enhance the training stability and empirical performance of EBFlow through a number of techniques developed based on our analysis on the score-matching methods. The experimental
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26367;&#20195;&#22522;&#20110;&#25490;&#24207;&#30340;&#27169;&#25311;&#26657;&#20934;&#65288;SBC&#65289;&#30340;&#28789;&#27963;&#20998;&#31867;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#27979;&#35797;&#32479;&#35745;&#37327;&#65292;&#24182;&#35745;&#31639;&#20986;&#20174;&#20998;&#31867;&#20934;&#30830;&#24230;&#20013;&#35745;&#31639;&#20986;&#30340;&#35823;&#26657;&#20934;&#21457;&#25955;&#24230;&#24230;&#37327;&#65292;&#20855;&#26377;&#26356;&#39640;&#30340;&#32479;&#35745;&#21151;&#25928;&#65292;&#21487;&#20197;&#35299;&#20915;&#22810;&#37325;&#26816;&#39564;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2305.14593</link><description>&lt;p&gt;
&#21028;&#21035;&#26657;&#20934;
&lt;/p&gt;
&lt;p&gt;
Discriminative calibration. (arXiv:2305.14593v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14593
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26367;&#20195;&#22522;&#20110;&#25490;&#24207;&#30340;&#27169;&#25311;&#26657;&#20934;&#65288;SBC&#65289;&#30340;&#28789;&#27963;&#20998;&#31867;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#27979;&#35797;&#32479;&#35745;&#37327;&#65292;&#24182;&#35745;&#31639;&#20986;&#20174;&#20998;&#31867;&#20934;&#30830;&#24230;&#20013;&#35745;&#31639;&#20986;&#30340;&#35823;&#26657;&#20934;&#21457;&#25955;&#24230;&#24230;&#37327;&#65292;&#20855;&#26377;&#26356;&#39640;&#30340;&#32479;&#35745;&#21151;&#25928;&#65292;&#21487;&#20197;&#35299;&#20915;&#22810;&#37325;&#26816;&#39564;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#26816;&#39564;&#36125;&#21494;&#26031;&#35745;&#31639;&#30340;&#20934;&#30830;&#24615;&#65292;&#24120;&#24120;&#20351;&#29992;&#22522;&#20110;&#25490;&#24207;&#30340;&#27169;&#25311;&#26657;&#20934;&#65288;SBC&#65289;&#12290;&#28982;&#32780;&#65292;SBC &#23384;&#22312;&#19968;&#20123;&#32570;&#28857;&#65306;&#27979;&#35797;&#32479;&#35745;&#37327;&#30053;&#26174;&#38543;&#24847;&#65292;&#20132;&#20114;&#24615;&#38590;&#20197;&#26816;&#26597;&#65292;&#22810;&#37325;&#26816;&#39564;&#26159;&#19968;&#20010;&#25361;&#25112;&#65292;&#24182;&#19988;&#24471;&#21040;&#30340; P &#20540;&#19981;&#26159;&#19968;&#31181;&#21457;&#25955;&#24230;&#24230;&#37327;&#12290;&#25105;&#20204;&#25552;&#20986;&#29992;&#19968;&#31181;&#28789;&#27963;&#30340;&#20998;&#31867;&#26041;&#27861;&#26367;&#25442;&#36793;&#32536;&#25490;&#24207;&#26816;&#39564;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#27979;&#35797;&#32479;&#35745;&#37327;&#12290;&#35813;&#24230;&#37327;&#36890;&#24120;&#20855;&#26377;&#27604; SBC &#25490;&#21517;&#26816;&#39564;&#26356;&#39640;&#30340;&#32479;&#35745;&#21151;&#25928;&#65292;&#24182;&#36820;&#22238;&#20174;&#20998;&#31867;&#20934;&#30830;&#24230;&#35745;&#31639;&#20986;&#30340;&#21487;&#35299;&#37322;&#30340;&#35823;&#26657;&#20934;&#21457;&#25955;&#24230;&#24230;&#37327;&#12290;&#27492;&#26041;&#27861;&#21487;&#20197;&#19982;&#19981;&#21516;&#30340;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#19968;&#36215;&#20351;&#29992;&#65292;&#20197;&#24212;&#23545;&#26080;&#38656;&#20284;&#28982;&#25512;&#26029;&#25110;&#20256;&#32479;&#25512;&#26029;&#26041;&#27861;&#65288;&#22914;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#25110;&#21464;&#20998;&#25512;&#26029;&#65289;&#12290;&#25105;&#20204;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#21644;&#32479;&#35745;&#23398;&#21551;&#21457;&#24335;&#29305;&#24449;&#28436;&#31034;&#20102;&#19968;&#31181;&#33258;&#21160;&#21270;&#23454;&#29616;&#65292;&#24182;&#29992;&#25968;&#20540;&#21644;&#30495;&#23454;&#25968;&#25454;&#23454;&#39564;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
To check the accuracy of Bayesian computations, it is common to use rank-based simulation-based calibration (SBC). However, SBC has drawbacks: The test statistic is somewhat ad-hoc, interactions are difficult to examine, multiple testing is a challenge, and the resulting p-value is not a divergence metric. We propose to replace the marginal rank test with a flexible classification approach that learns test statistics from data. This measure typically has a higher statistical power than the SBC rank test and returns an interpretable divergence measure of miscalibration, computed from classification accuracy. This approach can be used with different data generating processes to address likelihood-free inference or traditional inference methods like Markov chain Monte Carlo or variational inference. We illustrate an automated implementation using neural networks and statistically-inspired features, and validate the method with numerical and real data experiments.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#26368;&#20248;&#39044;&#26465;&#20214;&#21644;&#36153;&#33293;&#23572;&#33258;&#36866;&#24212; Langevin &#37319;&#26679;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#26377;&#25928;&#19988;&#22312;&#39640;&#32500;&#20013;&#38750;&#24120;&#24378;&#20581;&#30340;&#33258;&#36866;&#24212; MCMC &#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2305.14442</link><description>&lt;p&gt;
&#26368;&#20248;&#39044;&#26465;&#20214;&#21644;&#36153;&#33293;&#23572;&#33258;&#36866;&#24212; Langevin &#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Optimal Preconditioning and Fisher Adaptive Langevin Sampling. (arXiv:2305.14442v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14442
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26368;&#20248;&#39044;&#26465;&#20214;&#21644;&#36153;&#33293;&#23572;&#33258;&#36866;&#24212; Langevin &#37319;&#26679;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#26377;&#25928;&#19988;&#22312;&#39640;&#32500;&#20013;&#38750;&#24120;&#24378;&#20581;&#30340;&#33258;&#36866;&#24212; MCMC &#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#36890;&#36807;&#20998;&#26512;&#26368;&#22823;&#21270;&#39044;&#26399;&#24179;&#26041;&#36339;&#36291;&#36317;&#31163;&#65292;&#20026; Langevin &#25193;&#25955;&#23450;&#20041;&#20102;&#26368;&#20248;&#39044;&#26465;&#20214;&#12290;&#36825;&#23548;&#33268;&#26368;&#20248;&#39044;&#26465;&#20214;&#20026;&#21453;&#36153;&#33293;&#23572;&#20449;&#24687;&#21327;&#26041;&#24046;&#30697;&#38453;&#65292;&#20854;&#20013;&#21327;&#26041;&#24046;&#30697;&#38453;&#26159;&#22312;&#30446;&#26631;&#19979;&#24179;&#22343;&#23545;&#25968;&#30446;&#26631;&#26799;&#24230;&#30340;&#22806;&#31215;&#12290;&#25105;&#20204;&#23558;&#27492;&#32467;&#26524;&#24212;&#29992;&#20110; Metropolis &#35843;&#25972; Langevin &#31639;&#27861; (MALA)&#65292;&#24182;&#25512;&#23548;&#20986;&#19968;&#31181;&#20174;&#31639;&#27861;&#36816;&#34892;&#20135;&#29983;&#30340;&#26799;&#24230;&#21382;&#21490;&#20013;&#23398;&#20064;&#39044;&#26465;&#20214;&#30340;&#35745;&#31639;&#26377;&#25928;&#30340;&#33258;&#36866;&#24212; MCMC &#26041;&#26696;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#22312;&#39640;&#32500;&#20013;&#38750;&#24120;&#24378;&#20581;&#65292;&#24182;&#19988;&#26126;&#26174;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#65292;&#21253;&#25324;&#20351;&#29992;&#26631;&#20934;&#33258;&#36866;&#24212; MCMC &#23398;&#20064;&#39044;&#26465;&#20214;&#21644;&#20301;&#32622;&#30456;&#20851;&#30340; Riemann &#27969;&#24418; MALA &#37319;&#26679;&#22120;&#30340;&#23494;&#20999;&#30456;&#20851;&#30340;&#33258;&#36866;&#24212; MALA &#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
We define an optimal preconditioning for the Langevin diffusion by analytically maximizing the expected squared jumped distance. This yields as the optimal preconditioning an inverse Fisher information covariance matrix, where the covariance matrix is computed as the outer product of log target gradients averaged under the target. We apply this result to the Metropolis adjusted Langevin algorithm (MALA) and derive a computationally efficient adaptive MCMC scheme that learns the preconditioning from the history of gradients produced as the algorithm runs. We show in several experiments that the proposed algorithm is very robust in high dimensions and significantly outperforms other methods, including a closely related adaptive MALA scheme that learns the preconditioning with standard adaptive MCMC as well as the position-dependent Riemannian manifold MALA sampler.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#31350;&#20102;&#39640;&#26031;-&#26031;&#22374;&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#21160;&#24577;&#24615;&#12290;&#23545;&#20110;&#20174;&#39640;&#26031;&#30446;&#26631;&#20013;&#37319;&#26679;&#65292;&#21482;&#35201;&#21021;&#22987;&#20540;&#26159;&#39640;&#26031;&#30340;&#65292;&#20855;&#26377;&#21452;&#32447;&#24615;&#26680;&#30340;SVGD&#21160;&#24577;&#23558;&#20445;&#25345;&#39640;&#26031;&#29366;&#24577;&#12290;&#24403;&#30446;&#26631;&#20989;&#25968;&#21576;&#29616;&#20986;&#24378;&#23545;&#25968;&#20985;&#24615;&#26102;&#65292;&#35777;&#26126;&#20102;&#22343;&#22330;&#39640;&#26031;-SVGD&#21160;&#24577;&#20250;&#32447;&#24615;&#25910;&#25947;&#20110;KL&#25955;&#24230;&#19979;&#26368;&#25509;&#36817;&#30446;&#26631;&#39640;&#26031;&#20998;&#24067;&#12290;&#22312;&#26377;&#38480;&#31890;&#23376;&#35774;&#32622;&#20013;&#65292;&#23384;&#22312;&#23545;&#22343;&#22330;&#26497;&#38480;&#30340;&#26102;&#38388;&#24494;&#27493;&#19968;&#33268;&#25910;&#25947;&#20197;&#21450;&#32447;&#24615;&#25910;&#25947;&#33267;&#30446;&#26631;&#39640;&#26031;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2305.14076</link><description>&lt;p&gt;
&#20851;&#20110;&#39640;&#26031;-&#26031;&#22374;&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#21160;&#24577;&#24615;&#30340;&#25506;&#31350;
&lt;/p&gt;
&lt;p&gt;
Towards Understanding the Dynamics of Gaussian--Stein Variational Gradient Descent. (arXiv:2305.14076v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14076
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#31350;&#20102;&#39640;&#26031;-&#26031;&#22374;&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#21160;&#24577;&#24615;&#12290;&#23545;&#20110;&#20174;&#39640;&#26031;&#30446;&#26631;&#20013;&#37319;&#26679;&#65292;&#21482;&#35201;&#21021;&#22987;&#20540;&#26159;&#39640;&#26031;&#30340;&#65292;&#20855;&#26377;&#21452;&#32447;&#24615;&#26680;&#30340;SVGD&#21160;&#24577;&#23558;&#20445;&#25345;&#39640;&#26031;&#29366;&#24577;&#12290;&#24403;&#30446;&#26631;&#20989;&#25968;&#21576;&#29616;&#20986;&#24378;&#23545;&#25968;&#20985;&#24615;&#26102;&#65292;&#35777;&#26126;&#20102;&#22343;&#22330;&#39640;&#26031;-SVGD&#21160;&#24577;&#20250;&#32447;&#24615;&#25910;&#25947;&#20110;KL&#25955;&#24230;&#19979;&#26368;&#25509;&#36817;&#30446;&#26631;&#39640;&#26031;&#20998;&#24067;&#12290;&#22312;&#26377;&#38480;&#31890;&#23376;&#35774;&#32622;&#20013;&#65292;&#23384;&#22312;&#23545;&#22343;&#22330;&#26497;&#38480;&#30340;&#26102;&#38388;&#24494;&#27493;&#19968;&#33268;&#25910;&#25947;&#20197;&#21450;&#32447;&#24615;&#25910;&#25947;&#33267;&#30446;&#26631;&#39640;&#26031;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Stein Variational Gradient Descent (SVGD)&#26159;&#19968;&#31181;&#38750;&#21442;&#25968;&#22522;&#20110;&#31890;&#23376;&#30340;&#30830;&#23450;&#24615;&#37319;&#26679;&#31639;&#27861;&#12290;&#23613;&#31649;&#20854;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#20294;&#29702;&#35299;SVGD&#30340;&#29702;&#35770;&#23646;&#24615;&#19968;&#30452;&#26159;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#12290;&#23545;&#20110;&#20174;&#39640;&#26031;&#30446;&#26631;&#20013;&#37319;&#26679;&#65292;&#21482;&#35201;&#21021;&#22987;&#20540;&#26159;&#39640;&#26031;&#30340;&#65292;&#20855;&#26377;&#21452;&#32447;&#24615;&#26680;&#30340;SVGD&#21160;&#24577;&#23558;&#20445;&#25345;&#39640;&#26031;&#29366;&#24577;&#12290;&#21463;&#27492;&#20107;&#23454;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#36890;&#36807;&#21452;&#32447;&#24615;&#26680;&#23558;SVGD&#25237;&#24433;&#21040;&#39640;&#26031;&#20998;&#24067;&#26063;&#20013;&#65292;&#21363;&#39640;&#26031;&#21464;&#20998;&#25512;&#26029; (GVI) &#19982; SVGD&#12290;&#25105;&#20204;&#36890;&#36807;&#32771;&#34385;&#22343;&#22330; PDE &#21644;&#31163;&#25955;&#31890;&#23376;&#31995;&#32479;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#23436;&#25972;&#30340;&#22270;&#20687;&#12290;&#24403;&#30446;&#26631;&#20989;&#25968;&#21576;&#29616;&#20986;&#24378;&#23545;&#25968;&#20985;&#24615;&#26102;&#65292;&#35777;&#26126;&#20102;&#22343;&#22330;&#39640;&#26031;-SVGD&#21160;&#24577;&#20250;&#32447;&#24615;&#25910;&#25947;&#20110;KL&#25955;&#24230;&#19979;&#26368;&#25509;&#36817;&#30446;&#26631;&#39640;&#26031;&#20998;&#24067;&#12290;&#22312;&#26377;&#38480;&#31890;&#23376;&#35774;&#32622;&#20013;&#65292;&#23384;&#22312;&#23545;&#22343;&#22330;&#26497;&#38480;&#30340;&#26102;&#38388;&#24494;&#27493;&#19968;&#33268;&#25910;&#25947;&#20197;&#21450;&#32447;&#24615;&#25910;&#25947;&#33267;&#30446;&#26631;&#39640;&#26031;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#22522;&#20110;&#19968;&#20010;&#26032;&#30340;&#20195;&#25968;&#24658;&#31561;&#24335;&#65292;&#35813;&#31561;&#24335;&#23558;&#30446;&#26631;&#39640;&#26031;&#20998;&#24067;&#30340;&#36153;&#24076;&#23572;&#20449;&#24687;&#30697;&#38453;&#19982;&#31890;&#23376;&#22343;&#21248;&#20998;&#24067;&#30340;&#36153;&#24076;&#23572;&#20449;&#24687;&#30697;&#38453;&#30456;&#20851;&#32852;&#12290;&#36825;&#20010;&#31561;&#24335;&#20026;&#25105;&#20204;&#25552;&#20379;&#20102;&#36879;&#35270; GVI with SVGD &#22312;&#22343;&#22330;&#21644;&#31890;&#23376;&#35774;&#32622;&#20013;&#30340;&#21160;&#24577;&#24615;&#30340;&#32479;&#19968;&#35270;&#35282;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stein Variational Gradient Descent (SVGD) is a nonparametric particle-based deterministic sampling algorithm. Despite its wide usage, understanding the theoretical properties of SVGD has remained a challenging problem. For sampling from a Gaussian target, the SVGD dynamics with a bilinear kernel will remain Gaussian as long as the initializer is Gaussian. Inspired by this fact, we undertake a detailed theoretical study of the Gaussian-SVGD, i.e., SVGD projected to the family of Gaussian distributions via the bilinear kernel, or equivalently Gaussian variational inference (GVI) with SVGD. We present a complete picture by considering both the mean-field PDE and discrete particle systems. When the target is strongly log-concave, the mean-field Gaussian-SVGD dynamics is proven to converge linearly to the Gaussian distribution closest to the target in KL divergence. In the finite-particle setting, there is both uniform in time convergence to the mean-field limit and linear convergence in ti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#24314;&#31435;&#23398;&#20064;&#29702;&#35770;&#21644;&#24212;&#29992;&#27010;&#29575;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#35777;&#26126;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;Wasserstein&#31283;&#23450;&#24615;&#30028;&#38480;&#30340;&#32479;&#19968;&#25351;&#21335;&#65292;&#24182;&#22312;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#19978;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#21253;&#25324;&#24378;&#20984;&#25439;&#22833;&#21644;&#24102;&#28155;&#21152;&#22122;&#22768;&#30340;&#38750;&#20984;&#25439;&#22833;&#12290;</title><link>http://arxiv.org/abs/2305.12056</link><description>&lt;p&gt;
&#65288;&#24102;&#22122;&#22768;&#30340;&#65289;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#26102;&#38388;&#22343;&#21248;Wasserstein&#31283;&#23450;&#24615;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Uniform-in-Time Wasserstein Stability Bounds for (Noisy) Stochastic Gradient Descent. (arXiv:2305.12056v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12056
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#24314;&#31435;&#23398;&#20064;&#29702;&#35770;&#21644;&#24212;&#29992;&#27010;&#29575;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#35777;&#26126;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;Wasserstein&#31283;&#23450;&#24615;&#30028;&#38480;&#30340;&#32479;&#19968;&#25351;&#21335;&#65292;&#24182;&#22312;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#19978;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#21253;&#25324;&#24378;&#20984;&#25439;&#22833;&#21644;&#24102;&#28155;&#21152;&#22122;&#22768;&#30340;&#38750;&#20984;&#25439;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31639;&#27861;&#31283;&#23450;&#24615;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#27010;&#24565;&#65292;&#23545;&#20110;&#25512;&#23548;&#23454;&#36341;&#31639;&#27861;&#30340;&#27867;&#21270;&#30028;&#38480;&#24050;&#34987;&#35777;&#26126;&#26159;&#26377;&#29992;&#30340;&#12290;&#36807;&#21435;&#21313;&#24180;&#24050;&#32463;&#35265;&#35777;&#20102;&#19981;&#21516;&#25439;&#22833;&#20989;&#25968;&#25152;&#24212;&#29992;&#30340;&#19981;&#21516;&#31639;&#27861;&#30340;&#31283;&#23450;&#24615;&#30028;&#38480;&#30340;&#22686;&#21152;&#12290;&#34429;&#28982;&#36825;&#20123;&#30028;&#38480;&#29031;&#20142;&#20102;&#20248;&#21270;&#31639;&#27861;&#30340;&#21508;&#31181;&#23646;&#24615;&#65292;&#20294;&#27599;&#20010;&#26696;&#20363;&#30340;&#20998;&#26512;&#36890;&#24120;&#38656;&#35201;&#19981;&#21516;&#30340;&#35777;&#26126;&#25216;&#26415;&#21644;&#26174;&#33879;&#19981;&#21516;&#30340;&#25968;&#23398;&#24037;&#20855;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#22312;&#23398;&#20064;&#29702;&#35770;&#21644;&#24212;&#29992;&#27010;&#29575;&#20043;&#38388;&#24314;&#31435;&#20102;&#26032;&#30340;&#32852;&#31995;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#31181;&#35777;&#26126;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#30340;Wasserstein&#31283;&#23450;&#24615;&#30028;&#38480;&#30340;&#32479;&#19968;&#25351;&#21335;&#12290;&#25105;&#20204;&#22312;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#19978;&#38416;&#36848;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#24182;&#33719;&#24471;&#20102;&#24378;&#20984;&#25439;&#22833;&#21644;&#24102;&#28155;&#21152;&#22122;&#22768;&#30340;&#38750;&#20984;&#25439;&#22833;&#30340;&#26102;&#38388;&#22343;&#21248;&#31283;&#23450;&#24615;&#30028;&#38480;&#65288;&#21363;&#65292;&#30028;&#38480;&#19981;&#38543;&#36845;&#20195;&#27425;&#25968;&#22686;&#21152;&#32780;&#22686;&#21152;&#65289;&#65292;&#22312;&#36825;&#20123;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#24674;&#22797;&#20102;&#19982;&#20808;&#21069;&#25991;&#29486;&#30456;&#20284;&#30340;&#32467;&#26524;&#25110;&#23558;&#23427;&#20204;&#25193;&#23637;&#21040;&#26356;&#24191;&#27867;&#12290;
&lt;/p&gt;
&lt;p&gt;
Algorithmic stability is an important notion that has proven powerful for deriving generalization bounds for practical algorithms. The last decade has witnessed an increasing number of stability bounds for different algorithms applied on different classes of loss functions. While these bounds have illuminated various properties of optimization algorithms, the analysis of each case typically required a different proof technique with significantly different mathematical tools. In this study, we make a novel connection between learning theory and applied probability and introduce a unified guideline for proving Wasserstein stability bounds for stochastic optimization algorithms. We illustrate our approach on stochastic gradient descent (SGD) and we obtain time-uniform stability bounds (i.e., the bound does not increase with the number of iterations) for strongly convex losses and non-convex losses with additive noise, where we recover similar results to the prior art or extend them to mor
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#25511;&#21046;&#29702;&#35770;&#30340;&#35270;&#35282;&#30740;&#31350;&#20102;&#22312;&#32447;&#23398;&#20064;&#29615;&#22659;&#19979;&#21487;&#33021;&#36973;&#21463;&#21040;&#30340;&#26631;&#31614;&#25200;&#21160;&#25915;&#20987;&#24773;&#20917;&#65292;&#24471;&#20986;&#25915;&#20987;&#24378;&#24230;&#36229;&#36807;&#20020;&#30028;&#38408;&#20540;&#26102;&#23398;&#20064;&#20934;&#30830;&#29575;&#23558;&#20986;&#29616;&#19981;&#36830;&#32493;&#36716;&#21464;&#30340;&#32467;&#35770;&#65292;&#24182;&#39564;&#35777;&#20102;&#29702;&#35770;&#22312;&#22797;&#26434;&#32467;&#26500;&#23398;&#20064;&#22120;&#19978;&#30340;&#36866;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.11132</link><description>&lt;p&gt;
&#22312;&#32447;&#23398;&#20064;&#32773;&#30340;&#25915;&#20987;&#65306;&#19968;&#39033;&#25945;&#24072;-&#23398;&#29983;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Attacks on Online Learners: a Teacher-Student Analysis. (arXiv:2305.11132v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11132
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#25511;&#21046;&#29702;&#35770;&#30340;&#35270;&#35282;&#30740;&#31350;&#20102;&#22312;&#32447;&#23398;&#20064;&#29615;&#22659;&#19979;&#21487;&#33021;&#36973;&#21463;&#21040;&#30340;&#26631;&#31614;&#25200;&#21160;&#25915;&#20987;&#24773;&#20917;&#65292;&#24471;&#20986;&#25915;&#20987;&#24378;&#24230;&#36229;&#36807;&#20020;&#30028;&#38408;&#20540;&#26102;&#23398;&#20064;&#20934;&#30830;&#29575;&#23558;&#20986;&#29616;&#19981;&#36830;&#32493;&#36716;&#21464;&#30340;&#32467;&#35770;&#65292;&#24182;&#39564;&#35777;&#20102;&#29702;&#35770;&#22312;&#22797;&#26434;&#32467;&#26500;&#23398;&#20064;&#22120;&#19978;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#36890;&#24120;&#23481;&#26131;&#21463;&#21040;&#23545;&#25239;&#24615;&#25915;&#20987;&#65306;&#25968;&#25454;&#30340;&#24494;&#23567;&#25200;&#21160;&#21487;&#33021;&#20250;&#20351;&#27169;&#22411;&#30340;&#39044;&#27979;&#32467;&#26524;&#20135;&#29983;&#28798;&#38590;&#24615;&#30340;&#24433;&#21709;&#12290;&#34429;&#28982;&#22823;&#37327;&#30340;&#25991;&#29486;&#30740;&#31350;&#20102;&#23545;&#24050;&#32463;&#39044;&#20808;&#35757;&#32451;&#30340;&#27169;&#22411;&#36827;&#34892;&#27979;&#35797;&#26102;&#30340;&#25915;&#20987;&#24773;&#20917;&#65292;&#20294;&#22312;&#32447;&#23398;&#20064;&#29615;&#22659;&#19979;&#30340;&#25915;&#20987;&#24773;&#20917;&#21364;&#40092;&#26377;&#30740;&#31350;&#12290;&#26412;&#25991;&#20351;&#29992;&#25511;&#21046;&#29702;&#35770;&#30340;&#35270;&#35282;&#30740;&#31350;&#20102;&#22312;&#32447;&#23398;&#20064;&#32773;&#21487;&#33021;&#23384;&#22312;&#30340;&#26631;&#31614;&#25200;&#21160;&#25915;&#20987;&#24773;&#20917;&#65292;&#32771;&#34385;&#20102;&#19981;&#21516;&#30340;&#25915;&#20987;&#31574;&#30053;&#65292;&#24182;&#38024;&#23545;&#31616;&#21333;&#32447;&#24615;&#23398;&#20064;&#22120;&#30340;&#31283;&#24577;&#33719;&#24471;&#20102;&#20998;&#26512;&#32467;&#26524;&#12290;&#36825;&#20123;&#32467;&#26524;&#21487;&#20197;&#35777;&#26126;&#65292;&#24403;&#25915;&#20987;&#24378;&#24230;&#36229;&#36807;&#20020;&#30028;&#38408;&#20540;&#26102;&#65292;&#23398;&#20064;&#22120;&#30340;&#20934;&#30830;&#29575;&#20250;&#20986;&#29616;&#19981;&#36830;&#32493;&#30340;&#36716;&#21464;&#12290;&#28982;&#21518;&#25105;&#20204;&#20351;&#29992;&#30495;&#23454;&#25968;&#25454;&#23545;&#22797;&#26434;&#32467;&#26500;&#30340;&#23398;&#20064;&#22120;&#36827;&#34892;&#20102;&#23454;&#35777;&#20998;&#26512;&#65292;&#39564;&#35777;&#20102;&#29702;&#35770;&#20998;&#26512;&#30340;&#27934;&#35265;&#24182;&#25581;&#31034;&#20102;&#36973;&#21463;&#25915;&#20987;&#30340;&#23398;&#20064;&#22120;&#30340;&#26032;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning models are famously vulnerable to adversarial attacks: small ad-hoc perturbations of the data that can catastrophically alter the model predictions. While a large literature has studied the case of test-time attacks on pre-trained models, the important case of attacks in an online learning setting has received little attention so far. In this work, we use a control-theoretical perspective to study the scenario where an attacker may perturb data labels to manipulate the learning dynamics of an online learner. We perform a theoretical analysis of the problem in a teacher-student setup, considering different attack strategies, and obtaining analytical results for the steady state of simple linear learners. These results enable us to prove that a discontinuous transition in the learner's accuracy occurs when the attack strength exceeds a critical threshold. We then study empirically attacks on learners with complex architectures using real data, confirming the insights of 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#31350;&#20102;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20449;&#24687;&#35774;&#35745;&#38382;&#39064;&#21450;&#20854;&#25361;&#25112;&#65292;&#25552;&#20986;&#20102;&#8220;&#39532;&#23572;&#31185;&#22827;&#20449;&#20196;&#21338;&#24328;&#8221;&#30340;&#27010;&#24565;&#12290;</title><link>http://arxiv.org/abs/2305.06807</link><description>&lt;p&gt;
&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20449;&#24687;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Information Design in Multi-Agent Reinforcement Learning. (arXiv:2305.06807v1 [cs.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06807
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#31350;&#20102;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#20449;&#24687;&#35774;&#35745;&#38382;&#39064;&#21450;&#20854;&#25361;&#25112;&#65292;&#25552;&#20986;&#20102;&#8220;&#39532;&#23572;&#31185;&#22827;&#20449;&#20196;&#21338;&#24328;&#8221;&#30340;&#27010;&#24565;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#27169;&#20223;&#20154;&#31867;&#21644;&#21160;&#29289;&#19982;&#29615;&#22659;&#20132;&#20114;&#30340;&#26041;&#24335;&#12290;&#28982;&#32780;&#23454;&#38469;&#29615;&#22659;&#20013;&#23384;&#22312;&#20854;&#20182;&#26377;&#33258;&#24049;&#30446;&#26631;&#30340;&#26234;&#33021;&#20307;&#65292;&#23427;&#20204;&#20250;&#36866;&#24212;&#22320;&#19982;&#33258;&#24049;&#30456;&#20114;&#20316;&#29992;&#12290;&#22240;&#27492;&#65292;&#20026;&#20102;&#22312;&#36825;&#20123;&#29615;&#22659;&#20013;&#25104;&#21151;&#65292;&#33258;&#20027;&#26234;&#33021;&#20307;&#38656;&#35201;&#24433;&#21709;&#20854;&#20182;&#26234;&#33021;&#20307;&#20197;&#20351;&#23427;&#20204;&#30340;&#34892;&#20026;&#26356;&#26377;&#30410;&#12290;&#20449;&#24687;&#35774;&#35745;&#26159;&#24433;&#21709;&#20854;&#20182;&#26234;&#33021;&#20307;&#34892;&#20026;&#30340;&#19968;&#31181;&#26041;&#27861;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#38024;&#23545;&#19968;&#32452;RL&#20195;&#29702;&#30340;&#20449;&#24687;&#35774;&#35745;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#8220;&#39532;&#23572;&#31185;&#22827;&#20449;&#20196;&#21338;&#24328;&#8221;&#30340;&#27010;&#24565;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement learning (RL) mimics how humans and animals interact with the environment. The setting is somewhat idealized because, in actual tasks, other agents in the environment have their own goals and behave adaptively to the ego agent. To thrive in those environments, the agent needs to influence other agents so their actions become more helpful and less harmful. Research in computational economics distills two ways to influence others directly: by providing tangible goods (mechanism design) and by providing information (information design). This work investigates information design problems for a group of RL agents. The main challenges are two-fold. One is the information provided will immediately affect the transition of the agent trajectories, which introduces additional non-stationarity. The other is the information can be ignored, so the sender must provide information that the receivers are willing to respect. We formulate the Markov signaling game, and develop the notions 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#26032;&#30340;&#21442;&#25968;Vononoi&#25439;&#22833;&#20989;&#25968;&#24182;&#24314;&#31435;&#20102;MLE&#30340;&#25910;&#25947;&#36895;&#24230;&#26469;&#35299;&#20915;&#39640;&#26031;&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#20013;&#30340;Softmax&#38376;&#25511;&#38382;&#39064;&#65292;&#30740;&#31350;&#34920;&#26126;&#35813;&#38376;&#25511;&#19982;&#39640;&#26031;&#20998;&#24067;&#20013;&#30340;&#19987;&#23478;&#20989;&#25968;&#36890;&#36807;&#20559;&#24494;&#20998;&#26041;&#31243;&#30456;&#20114;&#20316;&#29992;&#65292;&#26159;&#19968;&#20010;&#22797;&#26434;&#20381;&#36182;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2305.03288</link><description>&lt;p&gt;
&#35299;&#23494;&#39640;&#26031;&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#20013;&#30340;Softmax&#38376;&#25511;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Demystifying Softmax Gating in Gaussian Mixture of Experts. (arXiv:2305.03288v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.03288
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#26032;&#30340;&#21442;&#25968;Vononoi&#25439;&#22833;&#20989;&#25968;&#24182;&#24314;&#31435;&#20102;MLE&#30340;&#25910;&#25947;&#36895;&#24230;&#26469;&#35299;&#20915;&#39640;&#26031;&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#20013;&#30340;Softmax&#38376;&#25511;&#38382;&#39064;&#65292;&#30740;&#31350;&#34920;&#26126;&#35813;&#38376;&#25511;&#19982;&#39640;&#26031;&#20998;&#24067;&#20013;&#30340;&#19987;&#23478;&#20989;&#25968;&#36890;&#36807;&#20559;&#24494;&#20998;&#26041;&#31243;&#30456;&#20114;&#20316;&#29992;&#65292;&#26159;&#19968;&#20010;&#22797;&#26434;&#20381;&#36182;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;Softmax&#38376;&#25511;&#39640;&#26031;&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#30340;&#21442;&#25968;&#20272;&#35745;&#19968;&#30452;&#26159;&#25991;&#29486;&#20013;&#38271;&#26399;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#36825;&#20027;&#35201;&#26159;&#30001;&#20110;&#19977;&#20010;&#22522;&#26412;&#29702;&#35770;&#25361;&#25112;&#19982;Softmax&#38376;&#25511;&#30456;&#20851;&#65306;&#65288;i&#65289;&#21482;&#33021;&#35782;&#21035;&#21442;&#25968;&#30340;&#24179;&#31227;&#65307;&#65288;ii&#65289;Softmax&#38376;&#25511;&#21644;&#39640;&#26031;&#20998;&#24067;&#20013;&#19987;&#23478;&#20989;&#25968;&#20043;&#38388;&#36890;&#36807;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#20869;&#22312;&#30456;&#20114;&#20316;&#29992;&#65307;&#65288;iii&#65289;Softmax&#38376;&#25511;&#39640;&#26031;&#28151;&#21512;&#19987;&#23478;&#27169;&#22411;&#30340;&#26465;&#20214;&#23494;&#24230;&#30340;&#20998;&#23376;&#21644;&#20998;&#27597;&#20043;&#38388;&#30340;&#22797;&#26434;&#20381;&#36182;&#20851;&#31995;&#12290;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#26032;&#30340;&#21442;&#25968;Vononoi&#25439;&#22833;&#20989;&#25968;&#24182;&#24314;&#31435;MLE&#30340;&#25910;&#25947;&#36895;&#24230;&#26469;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#29992;&#20110;&#35299;&#20915;&#36825;&#20123;&#27169;&#22411;&#30340;&#21442;&#25968;&#20272;&#35745;&#12290;&#24403;&#19987;&#23478;&#25968;&#37327;&#26410;&#30693;&#19988;&#36229;&#39069;&#25351;&#23450;&#26102;&#65292;&#25105;&#20204;&#30340;&#21457;&#29616;&#34920;&#26126;MLE&#30340;&#36895;&#29575;&#19982;&#19968;&#32452;&#22810;&#39033;&#24335;&#26041;&#31243;&#30340;&#21487;&#35299;&#24615;&#38382;&#39064;&#26377;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding parameter estimation of softmax gating Gaussian mixture of experts has remained a long-standing open problem in the literature. It is mainly due to three fundamental theoretical challenges associated with the softmax gating: (i) the identifiability only up to the translation of the parameters; (ii) the intrinsic interaction via partial differential equation between the softmax gating and the expert functions in Gaussian distribution; (iii) the complex dependence between the numerator and denominator of the conditional density of softmax gating Gaussian mixture of experts. We resolve these challenges by proposing novel Vononoi loss functions among parameters and establishing the convergence rates of the maximum likelihood estimator (MLE) for solving parameter estimation in these models. When the number of experts is unknown and over-specified, our findings show a connection between the rate of MLE and a solvability problem of a system of polynomial equations.
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#31070;&#32463;&#31639;&#23376;&#26550;&#26500; DAFNO&#65292;&#21487;&#20197;&#23398;&#20064;&#24102;&#26377;&#19981;&#35268;&#21017;&#20960;&#20309;&#21644;&#19981;&#26029;&#21464;&#21270;&#30340;&#22495;&#30340;&#20195;&#29702;&#12290;&#36890;&#36807;&#23558;&#24179;&#28369;&#21270;&#30340;&#29305;&#24449;&#20989;&#25968;&#32435;&#20837; FNOs &#30340;&#31215;&#20998;&#23618;&#26550;&#26500;&#20013;&#65292;&#24182;&#21033;&#29992; FFT &#26469;&#23454;&#29616;&#24555;&#36895;&#35745;&#31639;&#65292;&#20197;&#26126;&#30830;&#30340;&#26041;&#24335;&#23558;&#20960;&#20309;&#20449;&#24687;&#32534;&#30721;&#21040;&#26550;&#26500;&#20013;&#65292;DAFNO &#30456;&#23545;&#20110;&#22522;&#32447;&#31070;&#32463;&#31639;&#23376;&#27169;&#22411;&#20855;&#26377;&#26368;&#20808;&#36827;&#30340;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2305.00478</link><description>&lt;p&gt;
&#22495;&#19981;&#21487;&#30693;&#20613;&#37324;&#21494;&#31070;&#32463;&#31639;&#23376;
&lt;/p&gt;
&lt;p&gt;
Domain Agnostic Fourier Neural Operators. (arXiv:2305.00478v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00478
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#31070;&#32463;&#31639;&#23376;&#26550;&#26500; DAFNO&#65292;&#21487;&#20197;&#23398;&#20064;&#24102;&#26377;&#19981;&#35268;&#21017;&#20960;&#20309;&#21644;&#19981;&#26029;&#21464;&#21270;&#30340;&#22495;&#30340;&#20195;&#29702;&#12290;&#36890;&#36807;&#23558;&#24179;&#28369;&#21270;&#30340;&#29305;&#24449;&#20989;&#25968;&#32435;&#20837; FNOs &#30340;&#31215;&#20998;&#23618;&#26550;&#26500;&#20013;&#65292;&#24182;&#21033;&#29992; FFT &#26469;&#23454;&#29616;&#24555;&#36895;&#35745;&#31639;&#65292;&#20197;&#26126;&#30830;&#30340;&#26041;&#24335;&#23558;&#20960;&#20309;&#20449;&#24687;&#32534;&#30721;&#21040;&#26550;&#26500;&#20013;&#65292;DAFNO &#30456;&#23545;&#20110;&#22522;&#32447;&#31070;&#32463;&#31639;&#23376;&#27169;&#22411;&#20855;&#26377;&#26368;&#20808;&#36827;&#30340;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20613;&#37324;&#21494;&#31070;&#32463;&#31639;&#23376;&#65288;FNOs&#65289;&#33021;&#22815;&#23398;&#20064;&#22312;&#20989;&#25968;&#31354;&#38388;&#20043;&#38388;&#39640;&#24230;&#38750;&#32447;&#24615;&#30340;&#26144;&#23556;&#65292;&#26368;&#36817;&#24050;&#25104;&#20026;&#23398;&#20064;&#22797;&#26434;&#29289;&#29702;&#31995;&#32479;&#21709;&#24212;&#30340;&#28909;&#38376;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#20026;&#20102;&#23454;&#29616;&#33391;&#22909;&#30340;&#31934;&#24230;&#21644;&#25928;&#29575;&#65292;FNOs &#20381;&#36182;&#20110;&#24555;&#36895;&#20613;&#37324;&#21494;&#21464;&#25442; (FFT)&#65292;&#35813;&#21464;&#25442;&#20165;&#38480;&#20110;&#30697;&#24418;&#22495;&#19978;&#30340;&#24314;&#27169;&#38382;&#39064;&#12290;&#20026;&#20102;&#28040;&#38500;&#36825;&#26679;&#30340;&#38480;&#21046;&#65292;&#20801;&#35768; FFT &#22312;&#19981;&#35268;&#21017;&#20960;&#20309;&#20197;&#21450;&#25299;&#25169;&#21464;&#21270;&#20013;&#20351;&#29992;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#22495;&#19981;&#21487;&#30693;&#20613;&#37324;&#21494;&#31070;&#32463;&#31639;&#23376; (DAFNO)&#65292;&#19968;&#31181;&#29992;&#20110;&#23398;&#20064;&#24102;&#26377;&#19981;&#35268;&#21017;&#20960;&#20309;&#21644;&#19981;&#26029;&#21464;&#21270;&#30340;&#22495;&#30340;&#20195;&#29702;&#30340;&#26032;&#30340;&#31070;&#32463;&#31639;&#23376;&#26550;&#26500;&#12290;&#20851;&#38190;&#24605;&#24819;&#26159;&#23558;&#24179;&#28369;&#21270;&#30340;&#29305;&#24449;&#20989;&#25968;&#32435;&#20837; FNOs &#30340;&#31215;&#20998;&#23618;&#26550;&#26500;&#20013;&#65292;&#24182;&#21033;&#29992; FFT &#26469;&#23454;&#29616;&#24555;&#36895;&#35745;&#31639;&#65292;&#20197;&#20415;&#20197;&#26126;&#30830;&#30340;&#26041;&#24335;&#23558;&#20960;&#20309;&#20449;&#24687;&#32534;&#30721;&#21040;&#26550;&#26500;&#20013;&#12290;&#22312;&#25105;&#20204;&#30340;&#23454;&#35777;&#35780;&#20272;&#20013;&#65292;DAFNO &#30456;&#23545;&#20110;&#22522;&#32447;&#31070;&#32463;&#31639;&#23376;&#27169;&#22411;&#20855;&#26377;&#26368;&#20808;&#36827;&#30340;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fourier neural operators (FNOs) can learn highly nonlinear mappings between function spaces, and have recently become a popular tool for learning responses of complex physical systems. However, to achieve good accuracy and efficiency, FNOs rely on the Fast Fourier transform (FFT), which is restricted to modeling problems on rectangular domains. To lift such a restriction and permit FFT on irregular geometries as well as topology changes, we introduce domain agnostic Fourier neural operator (DAFNO), a novel neural operator architecture for learning surrogates with irregular geometries and evolving domains. The key idea is to incorporate a smoothed characteristic function in the integral layer architecture of FNOs, and leverage FFT to achieve rapid computations, in such a way that the geometric information is explicitly encoded in the architecture. In our empirical evaluation, DAFNO has achieved state-of-the-art accuracy as compared to baseline neural operator models on two benchmark dat
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#21457;&#29616;&#65292;ERM&#26412;&#36136;&#19978;&#21516;&#26102;&#23398;&#20064;&#20102;&#20855;&#26377;&#35823;&#23548;&#24615;&#30340;&#29305;&#24449;&#21644;&#19981;&#21464;&#29305;&#24449;&#65292;&#22312;ERM&#39044;&#35757;&#32451;&#26399;&#38388;&#23398;&#20064;&#21040;&#30340;&#29305;&#24449;&#36136;&#37327;&#24433;&#21709;&#20102;&#26368;&#32456;&#30340;OOD&#24615;&#33021;&#65292;&#26410;&#33021;&#25429;&#33719;&#25152;&#26377;&#28508;&#22312;&#30340;&#26377;&#29992;&#29305;&#24449;&#23558;&#38480;&#21046;&#26368;&#32456;&#30340;OOD&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.11327</link><description>&lt;p&gt;
&#25506;&#32034;&#22806;&#37096;&#20998;&#24067;&#24191;&#20041;&#21270;&#20013;&#30340;&#29305;&#24449;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Towards Understanding Feature Learning in Out-of-Distribution Generalization. (arXiv:2304.11327v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11327
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#21457;&#29616;&#65292;ERM&#26412;&#36136;&#19978;&#21516;&#26102;&#23398;&#20064;&#20102;&#20855;&#26377;&#35823;&#23548;&#24615;&#30340;&#29305;&#24449;&#21644;&#19981;&#21464;&#29305;&#24449;&#65292;&#22312;ERM&#39044;&#35757;&#32451;&#26399;&#38388;&#23398;&#20064;&#21040;&#30340;&#29305;&#24449;&#36136;&#37327;&#24433;&#21709;&#20102;&#26368;&#32456;&#30340;OOD&#24615;&#33021;&#65292;&#26410;&#33021;&#25429;&#33719;&#25152;&#26377;&#28508;&#22312;&#30340;&#26377;&#29992;&#29305;&#24449;&#23558;&#38480;&#21046;&#26368;&#32456;&#30340;OOD&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#22806;&#37096;&#20998;&#24067;&#65288;OOD&#65289;&#24191;&#20041;&#21270;&#30340;&#22833;&#36133;&#65292;&#24120;&#35265;&#30340;&#35299;&#37322;&#26159;&#20351;&#29992;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;ERM&#65289;&#27169;&#22411;&#23398;&#20064;&#21040;&#20855;&#26377;&#35823;&#23548;&#24615;&#30340;&#29305;&#24449;&#32780;&#19981;&#26159;&#26399;&#26395;&#30340;&#19981;&#21464;&#29305;&#24449;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#20960;&#39033;&#30740;&#31350;&#25361;&#25112;&#20102;&#36825;&#31181;&#35299;&#37322;&#65292;&#21457;&#29616;&#28145;&#24230;&#32593;&#32476;&#21487;&#33021;&#24050;&#32463;&#23398;&#21040;&#20102;&#36275;&#22815;&#22909;&#30340;&#29305;&#24449;&#36827;&#34892;OOD&#24191;&#20041;&#21270;&#12290;&#36825;&#22330;&#36777;&#35770;&#25193;&#23637;&#21040;&#20102;&#35768;&#22810;OOD&#24191;&#20041;&#21270;&#20219;&#21153;&#30340;&#35757;&#32451;&#25110;&#24494;&#35843;&#31070;&#32463;&#32593;&#32476;&#30340;&#20869;&#37096;&#32452;&#32455;&#21644;OOD&#24615;&#33021;&#30456;&#20851;&#24615;&#20013;&#12290;&#20026;&#20102;&#29702;&#35299;&#36825;&#20123;&#20284;&#20046;&#30456;&#20114;&#30683;&#30462;&#30340;&#29616;&#35937;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#29702;&#35770;&#30740;&#31350;&#65292;&#21457;&#29616;ERM&#26412;&#36136;&#19978;&#21516;&#26102;&#23398;&#20064;&#20102;&#20855;&#26377;&#35823;&#23548;&#24615;&#30340;&#29305;&#24449;&#21644;&#19981;&#21464;&#29305;&#24449;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#22312;ERM&#39044;&#35757;&#32451;&#26399;&#38388;&#23398;&#20064;&#21040;&#30340;&#29305;&#24449;&#36136;&#37327;&#26174;&#33879;&#24433;&#21709;&#20102;&#26368;&#32456;&#30340;OOD&#24615;&#33021;&#65292;&#22240;&#20026;OOD&#23545;&#35937;&#24456;&#23569;&#23398;&#20064;&#21040;&#26032;&#21151;&#33021;&#12290;&#26410;&#33021;&#22312;&#39044;&#35757;&#32451;&#26399;&#38388;&#25429;&#33719;&#25152;&#26377;&#28508;&#22312;&#30340;&#26377;&#29992;&#29305;&#24449;&#23558;&#36827;&#19968;&#27493;&#38480;&#21046;&#26368;&#32456;&#30340;OOD&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
A common explanation for the failure of out-of-distribution (OOD) generalization is that the model trained with empirical risk minimization (ERM) learns spurious features instead of the desired invariant features. However, several recent studies challenged this explanation and found that deep networks may have already learned sufficiently good features for OOD generalization. The debate extends to the in-distribution and OOD performance correlations along with training or fine-tuning neural nets across a variety of OOD generalization tasks. To understand these seemingly contradicting phenomena, we conduct a theoretical investigation and find that ERM essentially learns both spurious features and invariant features. On the other hand, the quality of learned features during ERM pre-training significantly affects the final OOD performance, as OOD objectives rarely learn new features. Failing to capture all the underlying useful features during pre-training will further limit the final OOD
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#31639;&#27861;SVRS&#21644;AccSVRS&#65292;&#38024;&#23545;&#20998;&#24067;&#24335;&#20248;&#21270;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#21331;&#36234;&#30340;&#36890;&#20449;&#22797;&#26434;&#24230;&#12290;&#20854;&#20013;&#65292;AccSVRS&#31639;&#27861;&#23454;&#29616;&#20102;&#23436;&#20840;&#26080;&#24179;&#28369;&#24615;&#65292;&#36890;&#20449;&#22797;&#26434;&#24230;&#26356;&#26159;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2304.07504</link><description>&lt;p&gt;
&#22522;&#20110;&#24179;&#22343;&#20108;&#38454;&#30456;&#20284;&#24615;&#30340;&#38543;&#26426;&#20998;&#24067;&#24335;&#20248;&#21270;&#65306;&#31639;&#27861;&#19982;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Stochastic Distributed Optimization under Average Second-order Similarity: Algorithms and Analysis. (arXiv:2304.07504v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07504
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#31639;&#27861;SVRS&#21644;AccSVRS&#65292;&#38024;&#23545;&#20998;&#24067;&#24335;&#20248;&#21270;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#21331;&#36234;&#30340;&#36890;&#20449;&#22797;&#26434;&#24230;&#12290;&#20854;&#20013;&#65292;AccSVRS&#31639;&#27861;&#23454;&#29616;&#20102;&#23436;&#20840;&#26080;&#24179;&#28369;&#24615;&#65292;&#36890;&#20449;&#22797;&#26434;&#24230;&#26356;&#26159;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;$n$&#20010;&#23458;&#25143;&#31471;&#30340;&#26377;&#38480;&#21644;&#20998;&#24067;&#24335;&#20248;&#21270;&#38382;&#39064;&#65292;&#28385;&#36275;&#27969;&#34892;&#30340;$\delta$-&#30456;&#20284;&#24615;&#26465;&#20214;&#21644;$\mu$-&#24378;&#20984;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#31639;&#27861;&#65306;SVRS&#21644;AccSVRS&#65292;&#21551;&#21457;&#33258;&#20808;&#21069;&#30340;&#24037;&#20316;&#12290;&#38750;&#21152;&#36895;&#30340;SVRS&#26041;&#27861;&#32467;&#21512;&#20102;&#26799;&#24230;&#28369;&#21160;&#21644;&#26041;&#24046;&#32553;&#20943;&#25216;&#26415;&#65292;&#23454;&#29616;&#20102;&#21331;&#36234;&#30340;&#36890;&#20449;&#22797;&#26434;&#24230;$\tilde{\gO}(n {+} \sqrt{n}\delta/\mu)$&#65292;&#19982;&#29616;&#26377;&#30340;&#38750;&#21152;&#36895;&#31639;&#27861;&#30456;&#27604;&#26377;&#25152;&#25552;&#39640;&#12290;&#24212;&#29992;Katyusha X&#25552;&#20986;&#30340;&#26694;&#26550;&#65292;&#25105;&#20204;&#36824;&#24314;&#31435;&#20102;&#19968;&#20010;&#21517;&#20026;AccSVRS&#30340;&#30452;&#25509;&#21152;&#36895;&#23454;&#38469;&#29256;&#26412;&#65292;&#20854;&#23436;&#20840;&#26080;&#24179;&#28369;&#24615;&#65292;&#36890;&#20449;&#22797;&#26434;&#24230;&#20026;$\tilde{\gO}(n {+} n^{3/4}\sqrt{\delta/\mu})$&#65292;&#22312;&#30149;&#24577;&#24773;&#20917;&#19979;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#31181;&#25509;&#36817;&#21305;&#37197;&#30340;&#19979;&#30028;&#65292;&#20197;&#39564;&#35777;&#25105;&#20204;&#30340;AccSVRS&#26041;&#27861;&#30340;&#32039;&#23494;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study finite-sum distributed optimization problems with $n$-clients under popular $\delta$-similarity condition and $\mu$-strong convexity. We propose two new algorithms: SVRS and AccSVRS motivated by previous works. The non-accelerated SVRS method combines the techniques of gradient-sliding and variance reduction, which achieves superior communication complexity $\tilde{\gO}(n {+} \sqrt{n}\delta/\mu)$ compared to existing non-accelerated algorithms. Applying the framework proposed in Katyusha X, we also build a direct accelerated practical version named AccSVRS with totally smoothness-free $\tilde{\gO}(n {+} n^{3/4}\sqrt{\delta/\mu})$ communication complexity that improves upon existing algorithms on ill-conditioning cases. Furthermore, we show a nearly matched lower bound to verify the tightness of our AccSVRS method.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#28176;&#36817;&#24615;&#24037;&#20855;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20998;&#26512;Gibbs&#25277;&#26679;&#22120;&#30340;&#28151;&#21512;&#26102;&#38388;&#30340;&#28176;&#36817;&#34892;&#20026;&#65292;&#24182;&#22312;&#38543;&#26426;&#25968;&#25454;&#29983;&#25104;&#20551;&#35774;&#19979;&#33719;&#24471;&#20102;&#23545;&#20110;&#20855;&#26377;&#36890;&#29992;&#20284;&#28982;&#20989;&#25968;&#30340;&#24191;&#27867;&#30340;&#20108;&#32423;&#27169;&#22411;&#30340;&#26080;&#32500;&#24230;&#25910;&#25947;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2304.06993</link><description>&lt;p&gt;
&#22522;&#20110;&#36125;&#21494;&#26031;&#28176;&#36817;&#24615;&#30340;Gibbs&#25277;&#26679;&#22120;&#22797;&#26434;&#24615;
&lt;/p&gt;
&lt;p&gt;
Complexity of Gibbs samplers through Bayesian asymptotics. (arXiv:2304.06993v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06993
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#28176;&#36817;&#24615;&#24037;&#20855;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20998;&#26512;Gibbs&#25277;&#26679;&#22120;&#30340;&#28151;&#21512;&#26102;&#38388;&#30340;&#28176;&#36817;&#34892;&#20026;&#65292;&#24182;&#22312;&#38543;&#26426;&#25968;&#25454;&#29983;&#25104;&#20551;&#35774;&#19979;&#33719;&#24471;&#20102;&#23545;&#20110;&#20855;&#26377;&#36890;&#29992;&#20284;&#28982;&#20989;&#25968;&#30340;&#24191;&#27867;&#30340;&#20108;&#32423;&#27169;&#22411;&#30340;&#26080;&#32500;&#24230;&#25910;&#25947;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Gibbs&#25277;&#26679;&#22120;&#26159;&#29992;&#20110;&#36817;&#20284;&#26469;&#33258;&#36125;&#21494;&#26031;&#20998;&#23618;&#27169;&#22411;&#30340;&#21518;&#39564;&#20998;&#24067;&#30340;&#27969;&#34892;&#31639;&#27861;&#12290;&#23613;&#31649;&#23427;&#20204;&#38750;&#24120;&#27969;&#34892;&#19988;&#34920;&#29616;&#33391;&#22909;&#65292;&#20294;&#26159;&#20851;&#20110;&#23427;&#20204;&#30340;&#21487;&#25193;&#23637;&#24615;&#25110;&#19981;&#21487;&#25193;&#23637;&#24615;&#30340;&#23450;&#37327;&#29702;&#35770;&#32467;&#26524;&#30456;&#23545;&#36739;&#23569;&#65292;&#20363;&#22914;&#65292;&#27604;&#22522;&#20110;&#26799;&#24230;&#30340;&#25277;&#26679;&#26041;&#27861;&#35201;&#23569;&#24471;&#22810;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#28176;&#36817;&#24615;&#24037;&#20855;&#30340;&#26032;&#25216;&#26415;&#65292;&#29992;&#20110;&#20998;&#26512;Gibbs&#25277;&#26679;&#22120;&#30340;&#28151;&#21512;&#26102;&#38388;&#30340;&#28176;&#36817;&#34892;&#20026;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#39640;&#32500;&#20998;&#23618;&#27169;&#22411;&#65292;&#24182;&#22312;&#38543;&#26426;&#25968;&#25454;&#29983;&#25104;&#20551;&#35774;&#19979;&#33719;&#24471;&#20102;&#23545;&#20110;&#20855;&#26377;&#36890;&#29992;&#20284;&#28982;&#20989;&#25968;&#30340;&#24191;&#27867;&#30340;&#20108;&#32423;&#27169;&#22411;&#30340;&#26080;&#32500;&#24230;&#25910;&#25947;&#32467;&#26524;&#12290;&#35752;&#35770;&#20102;&#20855;&#26377;&#39640;&#26031;&#12289;&#20108;&#39033;&#24335;&#21644;&#20998;&#31867;&#20284;&#28982;&#30340;&#20855;&#20307;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gibbs samplers are popular algorithms to approximate posterior distributions arising from Bayesian hierarchical models. Despite their popularity and good empirical performances, however, there are still relatively few quantitative theoretical results on their scalability or lack thereof, e.g. much less than for gradient-based sampling methods. We introduce a novel technique to analyse the asymptotic behaviour of mixing times of Gibbs Samplers, based on tools of Bayesian asymptotics. We apply our methodology to high dimensional hierarchical models, obtaining dimension-free convergence results for Gibbs samplers under random data-generating assumptions, for a broad class of two-level models with generic likelihood function. Specific examples with Gaussian, binomial and categorical likelihoods are discussed.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#23545;&#25968;&#20985;&#37319;&#26679;&#30340;&#26597;&#35810;&#19979;&#30028;&#65292;&#22312;&#24378;&#23545;&#25968;&#20985;&#21644;&#23545;&#25968;&#20809;&#28369;&#20998;&#24067;&#20013;&#37319;&#26679;&#38656;&#35201; $\Omega(\log \kappa)$ &#26597;&#35810;&#65292;&#22312;&#37319;&#26679;&#39640;&#26031;&#20998;&#24067;&#20013;&#38656;&#35201; $\widetilde \Omega(\min(\sqrt\kappa \log d, d))$ &#26597;&#35810;&#12290;</title><link>http://arxiv.org/abs/2304.02599</link><description>&lt;p&gt;
&#23545;&#25968;&#20985;&#37319;&#26679;&#30340;&#26597;&#35810;&#19979;&#30028;
&lt;/p&gt;
&lt;p&gt;
Query lower bounds for log-concave sampling. (arXiv:2304.02599v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02599
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#23545;&#25968;&#20985;&#37319;&#26679;&#30340;&#26597;&#35810;&#19979;&#30028;&#65292;&#22312;&#24378;&#23545;&#25968;&#20985;&#21644;&#23545;&#25968;&#20809;&#28369;&#20998;&#24067;&#20013;&#37319;&#26679;&#38656;&#35201; $\Omega(\log \kappa)$ &#26597;&#35810;&#65292;&#22312;&#37319;&#26679;&#39640;&#26031;&#20998;&#24067;&#20013;&#38656;&#35201; $\widetilde \Omega(\min(\sqrt\kappa \log d, d))$ &#26597;&#35810;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#20960;&#24180;&#65292;&#23545;&#25968;&#20985;&#37319;&#26679;&#22312;&#31639;&#27861;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#36827;&#23637;&#65292;&#20294;&#30456;&#24212;&#30340;&#35777;&#26126;&#27492;&#20219;&#21153;&#30340;&#19979;&#30028;&#30340;&#38382;&#39064;&#20173;&#28982;&#24456;&#38590;&#65292;&#20197;&#21069;&#21482;&#30693;&#36947;&#22312;&#19968;&#32500;&#20013;&#23384;&#22312;&#36739;&#23567;&#30340;&#19979;&#30028;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#20197;&#19979;&#26597;&#35810;&#19979;&#30028;&#65306;&#65288;1&#65289;&#22312;&#32500;&#24230; $d\ge 2$&#20013;&#20174;&#24378;&#23545;&#25968;&#20985;&#21644;&#23545;&#25968;&#20809;&#28369;&#20998;&#24067;&#20013;&#37319;&#26679;&#38656;&#35201; $\Omega(\log \kappa)$ &#26597;&#35810;&#65292;&#36825;&#22312;&#20219;&#20309;&#22266;&#23450;&#32500;&#24230;&#19978;&#37117;&#26159;&#26368;&#20248;&#30340;&#65292;&#65288;2&#65289;&#20174;&#39640;&#26031;&#20998;&#24067;&#20013;&#37319;&#26679;&#38656;&#35201; $\widetilde \Omega(\min(\sqrt\kappa \log d, d))$ &#26597;&#35810;&#65288;&#22240;&#27492;&#20063;&#36866;&#29992;&#20110;&#22312;&#32500;&#25968; $d$ &#20013;&#37319;&#26679;&#19968;&#33324;&#30340;&#23545;&#25968;&#20985;&#21644;&#20809;&#28369;&#20998;&#24067;&#65289;&#65292;&#36825;&#23545;&#20110;&#39640;&#26031;&#31867;&#20960;&#20046;&#26159;&#26368;&#20248;&#30340;&#12290;&#36825;&#37324; $\kappa$ &#26159;&#30446;&#26631;&#20998;&#24067;&#30340;&#26465;&#20214;&#25968;&#12290;&#25105;&#20204;&#30340;&#35777;&#26126;&#20381;&#36182;&#20110;&#65288;1&#65289;&#19968;&#31181;&#22810;&#23610;&#24230;&#26500;&#36896;&#65292;&#21463;&#21040;&#20102;&#20851;&#20110;&#35856;&#25391;&#20998;&#26512;&#20013;&#30340;Kakeya&#29468;&#24819;&#30340;&#24037;&#20316;&#30340;&#21551;&#21457;&#65292;&#20197;&#21450;&#65288;2&#65289;&#19968;&#31181;&#26032;&#39062;&#30340;&#32422;&#31616;&#65292;&#35777;&#26126;&#20102;&#22359;Krylov&#31639;&#27861;&#22312;&#27492;&#38382;&#39064;&#20013;&#26159;&#26368;&#20339;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Log-concave sampling has witnessed remarkable algorithmic advances in recent years, but the corresponding problem of proving lower bounds for this task has remained elusive, with lower bounds previously known only in dimension one. In this work, we establish the following query lower bounds: (1) sampling from strongly log-concave and log-smooth distributions in dimension $d\ge 2$ requires $\Omega(\log \kappa)$ queries, which is sharp in any constant dimension, and (2) sampling from Gaussians in dimension $d$ (hence also from general log-concave and log-smooth distributions in dimension $d$) requires $\widetilde \Omega(\min(\sqrt\kappa \log d, d))$ queries, which is nearly sharp for the class of Gaussians. Here $\kappa$ denotes the condition number of the target distribution. Our proofs rely upon (1) a multiscale construction inspired by work on the Kakeya conjecture in harmonic analysis, and (2) a novel reduction that demonstrates that block Krylov algorithms are optimal for this probl
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#22411;&#25193;&#25955;&#26144;&#23556;&#31890;&#23376;&#31995;&#32479;(DMPS)&#65292;&#21487;&#20197;&#29992;&#20110;&#39640;&#25928;&#29983;&#25104;&#24314;&#27169;&#65292;&#23454;&#39564;&#34920;&#26126;&#22312;&#21253;&#21547;&#27969;&#24418;&#32467;&#26500;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#27604;&#20854;&#20182;&#26041;&#27861;&#26356;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2304.00200</link><description>&lt;p&gt;
&#22522;&#20110;&#25193;&#25955;&#26144;&#23556;&#30340;&#31890;&#23376;&#31995;&#32479;&#29992;&#20110;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Diffusion map particle systems for generative modeling. (arXiv:2304.00200v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.00200
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#22411;&#25193;&#25955;&#26144;&#23556;&#31890;&#23376;&#31995;&#32479;(DMPS)&#65292;&#21487;&#20197;&#29992;&#20110;&#39640;&#25928;&#29983;&#25104;&#24314;&#27169;&#65292;&#23454;&#39564;&#34920;&#26126;&#22312;&#21253;&#21547;&#27969;&#24418;&#32467;&#26500;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#27604;&#20854;&#20182;&#26041;&#27861;&#26356;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25193;&#25955;&#26144;&#23556;&#31890;&#23376;&#31995;&#32479;(DMPS)&#65292;&#29992;&#20110;&#29983;&#25104;&#24314;&#27169;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#25193;&#25955;&#26144;&#23556;&#21644;Laplacian&#35843;&#25972;&#30340;Wasserstein&#26799;&#24230;&#19979;&#38477;&#65288;LAWGD&#65289;&#12290;&#25193;&#25955;&#26144;&#23556;&#34987;&#29992;&#26469;&#20174;&#26679;&#26412;&#20013;&#36817;&#20284;Langevin&#25193;&#25955;&#36807;&#31243;&#30340;&#29983;&#25104;&#22120;&#65292;&#20174;&#32780;&#23398;&#20064;&#28508;&#22312;&#30340;&#25968;&#25454;&#29983;&#25104;&#27969;&#24418;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;LAWGD&#33021;&#22815;&#22312;&#21512;&#36866;&#30340;&#26680;&#20989;&#25968;&#36873;&#25321;&#19979;&#39640;&#25928;&#22320;&#20174;&#30446;&#26631;&#20998;&#24067;&#20013;&#25277;&#26679;&#65292;&#25105;&#20204;&#22312;&#36825;&#37324;&#36890;&#36807;&#25193;&#25955;&#26144;&#23556;&#35745;&#31639;&#29983;&#25104;&#22120;&#30340;&#35889;&#36924;&#36817;&#26469;&#26500;&#36896;&#26680;&#20989;&#25968;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21253;&#25324;&#20855;&#26377;&#27969;&#24418;&#32467;&#26500;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel diffusion map particle system (DMPS) for generative modeling, based on diffusion maps and Laplacian-adjusted Wasserstein gradient descent (LAWGD). Diffusion maps are used to approximate the generator of the Langevin diffusion process from samples, and hence to learn the underlying data-generating manifold. On the other hand, LAWGD enables efficient sampling from the target distribution given a suitable choice of kernel, which we construct here via a spectral approximation of the generator, computed with diffusion maps. Numerical experiments show that our method outperforms others on synthetic datasets, including examples with manifold structure.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#20998;&#24067;&#24335;&#34920;&#31034;&#65288;&#23884;&#20837;&#65289;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#32447;&#24615;&#26102;&#38388;&#20272;&#35745;softmax&#24402;&#19968;&#21270;&#24120;&#25968;&#26469;&#23454;&#29616;&#23398;&#20064;&#36807;&#31243;&#65292;&#35813;&#26041;&#27861;&#20248;&#20110;&#36127;&#37319;&#26679;&#26041;&#27861;&#24182;&#22312;&#22810;&#39033;&#27979;&#35797;&#20013;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.17475</link><description>&lt;p&gt;
&#36229;&#36234;&#36127;&#37319;&#26679;&#30340;&#39640;&#25928;&#20998;&#24067;&#24335;&#34920;&#31034;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Efficient distributed representations beyond negative sampling. (arXiv:2303.17475v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.17475
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#20998;&#24067;&#24335;&#34920;&#31034;&#65288;&#23884;&#20837;&#65289;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#32447;&#24615;&#26102;&#38388;&#20272;&#35745;softmax&#24402;&#19968;&#21270;&#24120;&#25968;&#26469;&#23454;&#29616;&#23398;&#20064;&#36807;&#31243;&#65292;&#35813;&#26041;&#27861;&#20248;&#20110;&#36127;&#37319;&#26679;&#26041;&#27861;&#24182;&#22312;&#22810;&#39033;&#27979;&#35797;&#20013;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#23398;&#20064;&#20998;&#24067;&#24335;&#34920;&#31034;&#65288;&#20063;&#31216;&#20026;&#23884;&#20837;&#65289;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#26368;&#23567;&#21270;&#19968;&#20010;&#31867;&#20284;&#20110;Word2Vec&#31639;&#27861;&#20013;&#24341;&#20837;&#24182;&#22312;&#22810;&#20010;&#24037;&#20316;&#20013;&#37319;&#29992;&#30340;&#30446;&#26631;&#20989;&#25968;&#26469;&#23454;&#29616;&#12290;&#20248;&#21270;&#35745;&#31639;&#30340;&#29942;&#39048;&#26159;softmax&#24402;&#19968;&#21270;&#24120;&#25968;&#30340;&#35745;&#31639;&#65292;&#36825;&#38656;&#35201;&#19982;&#26679;&#26412;&#22823;&#23567;&#21576;&#20108;&#27425;&#27604;&#20363;&#30340;&#25805;&#20316;&#25968;&#12290;&#36825;&#31181;&#22797;&#26434;&#24230;&#19981;&#36866;&#29992;&#20110;&#22823;&#22411;&#25968;&#25454;&#38598;&#65292;&#25152;&#20197;&#36127;&#37319;&#26679;&#26159;&#19968;&#20010;&#24120;&#35265;&#30340;&#35299;&#20915;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#19982;&#26679;&#26412;&#22823;&#23567;&#32447;&#24615;&#30456;&#20851;&#30340;&#26102;&#38388;&#20869;&#33719;&#24471;&#20998;&#24067;&#24335;&#34920;&#31034;&#12290;&#28982;&#32780;&#65292;&#36127;&#37319;&#26679;&#20250;&#25913;&#21464;&#25439;&#22833;&#20989;&#25968;&#65292;&#22240;&#27492;&#35299;&#20915;&#30340;&#26159;&#19982;&#26368;&#21021;&#25552;&#20986;&#30340;&#19981;&#21516;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#22312;&#20110;&#23637;&#31034;&#22914;&#20309;&#36890;&#36807;&#32447;&#24615;&#26102;&#38388;&#20272;&#35745;softmax&#24402;&#19968;&#21270;&#24120;&#25968;&#65292;&#20174;&#32780;&#35774;&#35745;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#20248;&#21270;&#31574;&#30053;&#26469;&#23398;&#20064;&#20998;&#24067;&#24335;&#34920;&#31034;&#12290;&#25105;&#20204;&#20351;&#29992;&#19981;&#21516;&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#27979;&#35797;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#23884;&#20837;&#36136;&#37327;&#21644;&#35757;&#32451;&#26102;&#38388;&#26041;&#38754;&#20248;&#20110;&#36127;&#37319;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article describes an efficient method to learn distributed representations, also known as embeddings. This is accomplished minimizing an objective function similar to the one introduced in the Word2Vec algorithm and later adopted in several works. The optimization computational bottleneck is the calculation of the softmax normalization constants for which a number of operations scaling quadratically with the sample size is required. This complexity is unsuited for large datasets and negative sampling is a popular workaround, allowing one to obtain distributed representations in linear time with respect to the sample size. Negative sampling consists, however, in a change of the loss function and hence solves a different optimization problem from the one originally proposed. Our contribution is to show that the sotfmax normalization constants can be estimated in linear time, allowing us to design an efficient optimization strategy to learn distributed representations. We test our ap
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#23545;&#20110;$C^k$&#65288;&#22312;&#23454;&#21464;&#37327;&#24847;&#20041;&#19979;&#65289;&#30340;&#20989;&#25968;&#65292;&#20351;&#29992;&#20855;&#26377;&#21333;&#23618;&#38544;&#34255;&#23618;&#21644;$m$&#20010;&#31070;&#32463;&#20803;&#30340;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#20197;&#38169;&#35823;&#29575;$m^{-k/(2n)}$&#23558;&#20854;&#36924;&#36817;&#12290;&#27492;&#22806;&#65292;&#22914;&#26524;&#36873;&#21462;&#26435;&#20540;$\sigma_j,b_j\in\mathbb{C}$&#21644;$\rho_j\in\mathbb{C}^n$&#23545;$f$&#36830;&#32493;&#65292;&#37027;&#20040;&#33719;&#24471;&#30340;&#36924;&#36817;&#36895;&#29575;&#26159;&#26368;&#20248;&#30340;&#12290;</title><link>http://arxiv.org/abs/2303.16813</link><description>&lt;p&gt;
&#27973;&#23618;&#22797;&#20540;&#31070;&#32463;&#32593;&#32476;&#23545;$C^k$-&#20989;&#25968;&#30340;&#26368;&#20248;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
Optimal approximation of $C^k$-functions using shallow complex-valued neural networks. (arXiv:2303.16813v1 [math.FA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16813
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#23545;&#20110;$C^k$&#65288;&#22312;&#23454;&#21464;&#37327;&#24847;&#20041;&#19979;&#65289;&#30340;&#20989;&#25968;&#65292;&#20351;&#29992;&#20855;&#26377;&#21333;&#23618;&#38544;&#34255;&#23618;&#21644;$m$&#20010;&#31070;&#32463;&#20803;&#30340;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#20197;&#38169;&#35823;&#29575;$m^{-k/(2n)}$&#23558;&#20854;&#36924;&#36817;&#12290;&#27492;&#22806;&#65292;&#22914;&#26524;&#36873;&#21462;&#26435;&#20540;$\sigma_j,b_j\in\mathbb{C}$&#21644;$\rho_j\in\mathbb{C}^n$&#23545;$f$&#36830;&#32493;&#65292;&#37027;&#20040;&#33719;&#24471;&#30340;&#36924;&#36817;&#36895;&#29575;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#20351;&#29992;&#27973;&#23618;&#22797;&#20540;&#31070;&#32463;&#32593;&#32476;&#23545;&#22797;&#31435;&#26041;&#20307;&#19978;$C^k$&#65288;&#22312;&#23454;&#21464;&#37327;&#24847;&#20041;&#19979;&#65289;&#30340;&#20989;&#25968;&#36827;&#34892;&#36924;&#36817;&#30340;&#37327;&#21270;&#32467;&#26524;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#32771;&#34385;&#20855;&#26377;&#21333;&#23618;&#38544;&#34255;&#23618;&#21644;$m$&#20010;&#31070;&#32463;&#20803;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#21363;&#24418;&#22914;$z \mapsto \sum_{j=1}^m \sigma_j \cdot \phi\big(\rho_j^T z + b_j\big)$&#30340;&#32593;&#32476;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#21487;&#20197;&#20351;&#29992;&#36825;&#31181;&#24418;&#24335;&#30340;&#20989;&#25968;&#36924;&#36817;$C^k \left(\Omega_n;\mathbb{C}\right)$&#20013;&#30340;&#20219;&#20309;&#20989;&#25968;&#65292;&#24403;$m\to\infty$&#26102;&#35823;&#24046;&#20026;$m^{-k/(2n)}$.&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#36873;&#21462;&#26435;&#20540;$\sigma_j,b_j\in\mathbb{C}$&#21644;$\rho_j\in\mathbb{C}^n$&#23545;$f$&#36830;&#32493;&#24182;&#19988;&#22312;&#36825;&#31181;&#36830;&#32493;&#24615;&#20551;&#35774;&#19979;&#33719;&#24471;&#30340;&#36924;&#36817;&#36895;&#29575;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We prove a quantitative result for the approximation of functions of regularity $C^k$ (in the sense of real variables) defined on the complex cube $\Omega_n := [-1,1]^n +i[-1,1]^n\subseteq \mathbb{C}^n$ using shallow complex-valued neural networks. Precisely, we consider neural networks with a single hidden layer and $m$ neurons, i.e., networks of the form $z \mapsto \sum_{j=1}^m \sigma_j \cdot \phi\big(\rho_j^T z + b_j\big)$ and show that one can approximate every function in $C^k \left( \Omega_n; \mathbb{C}\right)$ using a function of that form with error of the order $m^{-k/(2n)}$ as $m \to \infty$, provided that the activation function $\phi: \mathbb{C} \to \mathbb{C}$ is smooth but not polyharmonic on some non-empty open set. Furthermore, we show that the selection of the weights $\sigma_j, b_j \in \mathbb{C}$ and $\rho_j \in \mathbb{C}^n$ is continuous with respect to $f$ and prove that the derived rate of approximation is optimal under this continuity assumption. We also discuss
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#38750;&#32447;&#24615;&#37096;&#20998;&#21487;&#35266;&#27979;&#31995;&#32479;&#30340;&#23616;&#37096;&#32447;&#24615;&#21270;&#27010;&#29575;&#36870;&#20248;&#21270;&#25511;&#21046;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#29305;&#24449;&#21270;&#39034;&#24207;&#20915;&#31574;&#20219;&#21153;&#20013;&#30340;&#34892;&#20026;&#65292;&#24182;&#19988;&#20855;&#26377;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.16698</link><description>&lt;p&gt;
&#38024;&#23545;&#38750;&#32447;&#24615;&#37096;&#20998;&#21487;&#35266;&#27979;&#31995;&#32479;&#30340;&#23616;&#37096;&#32447;&#24615;&#21270;&#27010;&#29575;&#36870;&#20248;&#21270;&#25511;&#21046;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Probabilistic inverse optimal control with local linearization for non-linear partially observable systems. (arXiv:2303.16698v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16698
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#38750;&#32447;&#24615;&#37096;&#20998;&#21487;&#35266;&#27979;&#31995;&#32479;&#30340;&#23616;&#37096;&#32447;&#24615;&#21270;&#27010;&#29575;&#36870;&#20248;&#21270;&#25511;&#21046;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#29305;&#24449;&#21270;&#39034;&#24207;&#20915;&#31574;&#20219;&#21153;&#20013;&#30340;&#34892;&#20026;&#65292;&#24182;&#19988;&#20855;&#26377;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36870;&#20248;&#21270;&#25511;&#21046;&#26041;&#27861;&#21487;&#20197;&#29992;&#20110;&#29305;&#24449;&#21270;&#39034;&#24207;&#20915;&#31574;&#20219;&#21153;&#20013;&#30340;&#34892;&#20026;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#24037;&#20316;&#35201;&#27714;&#24050;&#30693;&#25511;&#21046;&#20449;&#21495;&#65292;&#25110;&#32773;&#20165;&#38480;&#20110;&#23436;&#20840;&#21487;&#35266;&#27979;&#25110;&#32447;&#24615;&#31995;&#32479;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#27010;&#29575;&#36870;&#20248;&#21270;&#25511;&#21046;&#26041;&#27861;&#65292;&#29992;&#20110;&#38750;&#32447;&#24615;&#38543;&#26426;&#31995;&#32479;&#30340;&#20002;&#22833;&#25511;&#21046;&#20449;&#21495;&#21644;&#37096;&#20998;&#21487;&#35266;&#27979;&#24615;&#65292;&#35813;&#26041;&#27861;&#32479;&#19968;&#20102;&#29616;&#26377;&#26041;&#27861;&#12290;&#36890;&#36807;&#20351;&#29992;&#20195;&#29702;&#30340;&#24863;&#35273;&#21644;&#25511;&#21046;&#31995;&#32479;&#30340;&#22122;&#22768;&#29305;&#24449;&#30340;&#26174;&#24335;&#27169;&#22411;&#20197;&#21450;&#23616;&#37096;&#32447;&#24615;&#21270;&#25216;&#26415;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#27169;&#22411;&#21442;&#25968;&#30340;&#36817;&#20284;&#20284;&#28982;&#20989;&#25968;&#65292;&#21487;&#20197;&#22312;&#21333;&#20010;&#27491;&#21521;&#20256;&#36882;&#20013;&#35745;&#31639;&#12290;&#25105;&#20204;&#22312;&#38543;&#26426;&#21644;&#37096;&#20998;&#21487;&#35266;&#27979;&#29256;&#26412;&#30340;&#32463;&#20856;&#25511;&#21046;&#20219;&#21153;&#65292;&#23548;&#33322;&#20219;&#21153;&#21644;&#25163;&#21160;&#36798;&#21040;&#20219;&#21153;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#20855;&#26377;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#65292;&#21487;&#29992;&#20110;&#27169;&#20223;&#23398;&#20064;&#21040;&#24863;&#35273;&#36816;&#21160;&#31070;&#32463;&#31185;&#23398;&#12290;
&lt;/p&gt;
&lt;p&gt;
Inverse optimal control methods can be used to characterize behavior in sequential decision-making tasks. Most existing work, however, requires the control signals to be known, or is limited to fully-observable or linear systems. This paper introduces a probabilistic approach to inverse optimal control for stochastic non-linear systems with missing control signals and partial observability that unifies existing approaches. By using an explicit model of the noise characteristics of the sensory and control systems of the agent in conjunction with local linearization techniques, we derive an approximate likelihood for the model parameters, which can be computed within a single forward pass. We evaluate our proposed method on stochastic and partially observable version of classic control tasks, a navigation task, and a manual reaching task. The proposed method has broad applicability, ranging from imitation learning to sensorimotor neuroscience.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;PDExplain&#65292;&#19968;&#31181;&#35299;&#37322;&#24615;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#35813;&#31639;&#27861;&#33021;&#22815;&#36890;&#36807;&#25552;&#20379;&#23569;&#37327;&#26679;&#26412;&#30340;&#26041;&#24335;&#65292;&#39044;&#27979;&#26410;&#26469;&#26102;&#38388;&#27493;&#30340;PDE&#35299;&#65292;&#26497;&#22823;&#22320;&#21327;&#21161;&#20102;&#24314;&#31435;&#29289;&#29702;&#31185;&#23398;&#20013;&#22522;&#20110;&#25968;&#25454;&#30340;&#29616;&#35937;&#24314;&#27169;&#12290;</title><link>http://arxiv.org/abs/2303.15827</link><description>&lt;p&gt;
PDExplain&#65306;PDEs &#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#24773;&#22659;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
PDExplain: Contextual Modeling of PDEs in the Wild. (arXiv:2303.15827v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15827
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;PDExplain&#65292;&#19968;&#31181;&#35299;&#37322;&#24615;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#35813;&#31639;&#27861;&#33021;&#22815;&#36890;&#36807;&#25552;&#20379;&#23569;&#37327;&#26679;&#26412;&#30340;&#26041;&#24335;&#65292;&#39044;&#27979;&#26410;&#26469;&#26102;&#38388;&#27493;&#30340;PDE&#35299;&#65292;&#26497;&#22823;&#22320;&#21327;&#21161;&#20102;&#24314;&#31435;&#29289;&#29702;&#31185;&#23398;&#20013;&#22522;&#20110;&#25968;&#25454;&#30340;&#29616;&#35937;&#24314;&#27169;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#37322;&#24615;&#30340;&#26041;&#27861;PDExplain&#29992;&#20110;&#35299;&#20915;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#22312;&#35757;&#32451;&#38454;&#27573;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#19968;&#20010;&#25805;&#20316;&#21592;&#23450;&#20041;&#30340;PDE&#23478;&#26063;&#30340;&#25968;&#25454;&#20197;&#21450;&#36825;&#20010;&#23478;&#26063;&#30340;&#19968;&#33324;&#24418;&#24335;&#36827;&#34892;&#39304;&#36865;&#12290;&#22312;&#25512;&#26029;&#38454;&#27573;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#20174;&#29616;&#35937;&#20013;&#25910;&#38598;&#21040;&#30340;&#26368;&#23567;&#26679;&#26412;&#65292;&#20854;&#20013;&#26679;&#26412;&#19982; PDE &#23478;&#26063;&#30456;&#20851;&#65292;&#20294;&#19981;&#19968;&#23450;&#23646;&#20110;&#35757;&#32451;&#38454;&#27573;&#30475;&#21040;&#30340;&#20855;&#20307; PDE &#38598;&#21512;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#31639;&#27861;&#22914;&#20309;&#39044;&#27979;&#26410;&#26469;&#26102;&#38388;&#27493;&#30340;PDE&#35299;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;PDE&#30340;&#21487;&#35299;&#37322;&#24418;&#24335;&#65292;&#36825;&#31181;&#29305;&#24449;&#21487;&#20197;&#21327;&#21161;&#36890;&#36807;&#29289;&#29702;&#31185;&#23398;&#25968;&#25454;&#26469;&#23545;&#29616;&#35937;&#36827;&#34892;&#24314;&#27169;&#12290;&#20026;&#20102;&#39564;&#35777;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#65292;&#32771;&#23519;&#20102;&#20854;&#22312;&#39044;&#27979;&#35823;&#24046;&#21644;&#21487;&#35299;&#37322;&#24615;&#26041;&#38754;&#30340;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose an explainable method for solving Partial Differential Equations by using a contextual scheme called PDExplain. During the training phase, our method is fed with data collected from an operator-defined family of PDEs accompanied by the general form of this family. In the inference phase, a minimal sample collected from a phenomenon is provided, where the sample is related to the PDE family but not necessarily to the set of specific PDEs seen in the training phase. We show how our algorithm can predict the PDE solution for future timesteps. Moreover, our method provides an explainable form of the PDE, a trait that can assist in modelling phenomena based on data in physical sciences. To verify our method, we conduct extensive experimentation, examining its quality both in terms of prediction error and explainability.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#26368;&#23567;&#29983;&#25104;&#26641;&#65288;MST&#65289;&#36827;&#34892;&#20998;&#21306;&#25968;&#25454;&#32858;&#31867;&#20219;&#21153;&#30340;&#24847;&#20041;&#31243;&#24230;&#65292;&#24182;&#21457;&#29616;MST&#26041;&#27861;&#22312;&#24635;&#20307;&#19978;&#20855;&#26377;&#24456;&#24378;&#30340;&#31454;&#20105;&#21147;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#22238;&#39038;&#12289;&#30740;&#31350;&#12289;&#25193;&#23637;&#21644;&#25512;&#24191;&#29616;&#26377;&#30340;MST-based&#21010;&#20998;&#26041;&#26696;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20123;&#26032;&#30340;&#21644;&#20540;&#24471;&#27880;&#24847;&#30340;&#26041;&#27861;&#12290;&#24635;&#20307;&#19978;&#65292;Genie&#21644;&#20449;&#24687;&#35770;&#26041;&#27861;&#24448;&#24448;&#20248;&#20110;&#20854;&#20182;&#38750;MST&#31639;&#27861;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;MST&#26041;&#27861;&#21487;&#33021;&#19981;&#22914;&#20854;&#20182;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2303.05679</link><description>&lt;p&gt;
&#20351;&#29992;&#26368;&#23567;&#29983;&#25104;&#26641;&#36827;&#34892;&#32858;&#31867;&#65306;&#33021;&#26377;&#22810;&#22909;&#65311;
&lt;/p&gt;
&lt;p&gt;
Clustering with minimum spanning trees: How good can it be?. (arXiv:2303.05679v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.05679
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#26368;&#23567;&#29983;&#25104;&#26641;&#65288;MST&#65289;&#36827;&#34892;&#20998;&#21306;&#25968;&#25454;&#32858;&#31867;&#20219;&#21153;&#30340;&#24847;&#20041;&#31243;&#24230;&#65292;&#24182;&#21457;&#29616;MST&#26041;&#27861;&#22312;&#24635;&#20307;&#19978;&#20855;&#26377;&#24456;&#24378;&#30340;&#31454;&#20105;&#21147;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#22238;&#39038;&#12289;&#30740;&#31350;&#12289;&#25193;&#23637;&#21644;&#25512;&#24191;&#29616;&#26377;&#30340;MST-based&#21010;&#20998;&#26041;&#26696;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20123;&#26032;&#30340;&#21644;&#20540;&#24471;&#27880;&#24847;&#30340;&#26041;&#27861;&#12290;&#24635;&#20307;&#19978;&#65292;Genie&#21644;&#20449;&#24687;&#35770;&#26041;&#27861;&#24448;&#24448;&#20248;&#20110;&#20854;&#20182;&#38750;MST&#31639;&#27861;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;MST&#26041;&#27861;&#21487;&#33021;&#19981;&#22914;&#20854;&#20182;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#23567;&#29983;&#25104;&#26641;&#65288;MST&#65289;&#22312;&#35768;&#22810;&#27169;&#24335;&#35782;&#21035;&#20219;&#21153;&#20013;&#21487;&#20197;&#25552;&#20379;&#26041;&#20415;&#30340;&#25968;&#25454;&#38598;&#34920;&#31034;&#65292;&#24182;&#19988;&#35745;&#31639;&#30456;&#23545;&#36739;&#24555;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#37327;&#21270;&#20102;MST&#22312;&#20302;&#32500;&#31354;&#38388;&#30340;&#20998;&#21306;&#25968;&#25454;&#32858;&#31867;&#20219;&#21153;&#20013;&#30340;&#24847;&#20041;&#31243;&#24230;&#12290;&#36890;&#36807;&#35782;&#21035;&#26368;&#20339;&#65288;oracle&#65289;&#31639;&#27861;&#19982;&#22823;&#37327;&#22522;&#20934;&#25968;&#25454;&#30340;&#19987;&#23478;&#26631;&#31614;&#20043;&#38388;&#30340;&#19968;&#33268;&#24615;&#19978;&#38480;&#65292;&#25105;&#20204;&#21457;&#29616;MST&#26041;&#27861;&#22312;&#24635;&#20307;&#19978;&#20855;&#26377;&#24456;&#24378;&#30340;&#31454;&#20105;&#21147;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#19981;&#26159;&#25552;&#20986;&#21478;&#19968;&#20010;&#21482;&#22312;&#26377;&#38480;&#30340;&#31034;&#20363;&#19978;&#34920;&#29616;&#33391;&#22909;&#30340;&#31639;&#27861;&#65292;&#32780;&#26159;&#22238;&#39038;&#12289;&#30740;&#31350;&#12289;&#25193;&#23637;&#21644;&#25512;&#24191;&#29616;&#26377;&#30340;&#26368;&#26032;MST-based&#21010;&#20998;&#26041;&#26696;&#12290;&#36825;&#23548;&#33268;&#20102;&#19968;&#20123;&#26032;&#30340;&#21644;&#20540;&#24471;&#27880;&#24847;&#30340;&#26041;&#27861;&#12290;&#24635;&#20307;&#19978;&#65292;Genie&#21644;&#20449;&#24687;&#35770;&#26041;&#27861;&#24448;&#24448;&#20248;&#20110;&#38750;MST&#31639;&#27861;&#65292;&#22914;k-means&#65292;&#39640;&#26031;&#28151;&#21512;&#65292;&#35889;&#32858;&#31867;&#65292;Birch&#65292;&#22522;&#20110;&#23494;&#24230;&#21644;&#32463;&#20856;&#23618;&#27425;&#32858;&#31867;&#31243;&#24207;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#25105;&#20204;&#36824;&#26159;&#21457;&#29616;MST&#26041;&#27861;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#21487;&#33021;&#19981;&#22914;&#20854;&#20182;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Minimum spanning trees (MSTs) provide a convenient representation of datasets in numerous pattern recognition activities. Moreover, they are relatively fast to compute. In this paper, we quantify the extent to which they can be meaningful in partitional data clustering tasks in low-dimensional spaces. By identifying the upper bounds for the agreement between the best (oracle) algorithm and the expert labels from a large battery of benchmark data, we discover that MST methods are overall very competitive. Next, instead of proposing yet another algorithm that performs well on a limited set of examples, we review, study, extend, and generalise existing, state-of-the-art MST-based partitioning schemes. This leads to a few new and noteworthy approaches. Overall, Genie and the information-theoretic methods often outperform the non-MST algorithms such as k-means, Gaussian mixtures, spectral clustering, Birch, density-based, and classical hierarchical agglomerative procedures. Nevertheless, we
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#22522;&#20110;&#22270;&#21367;&#31215;&#32593;&#32476;&#30340;&#26041;&#27861;&#65292;&#35299;&#20915;&#20132;&#36890;&#37327;&#20272;&#35745;&#20013;&#30340;&#19981;&#30830;&#23450;&#21644;&#38750;&#24179;&#34913;&#38382;&#39064;&#65292;&#23454;&#29616;&#20934;&#30830;&#30340;&#20840;&#38754;&#20132;&#36890;&#37327;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2303.05660</link><description>&lt;p&gt;
&#22522;&#20110;&#33258;&#36866;&#24212;&#30456;&#20851;&#22270;&#21367;&#31215;&#32593;&#32476;&#65292;&#23454;&#29616;&#20132;&#36890;&#37327;&#20272;&#35745;&#26356;&#22909;&#30340;&#24615;&#33021;&#65306;&#35299;&#20915;&#19981;&#30830;&#23450;&#21644;&#38750;&#24179;&#34913;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Towards better traffic volume estimation: Tackling both underdetermined and non-equilibrium problems via a correlation-adaptive graph convolution network. (arXiv:2303.05660v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.05660
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#22522;&#20110;&#22270;&#21367;&#31215;&#32593;&#32476;&#30340;&#26041;&#27861;&#65292;&#35299;&#20915;&#20132;&#36890;&#37327;&#20272;&#35745;&#20013;&#30340;&#19981;&#30830;&#23450;&#21644;&#38750;&#24179;&#34913;&#38382;&#39064;&#65292;&#23454;&#29616;&#20934;&#30830;&#30340;&#20840;&#38754;&#20132;&#36890;&#37327;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20132;&#36890;&#37327;&#26159;&#20132;&#36890;&#31649;&#29702;&#21644;&#25511;&#21046;&#25552;&#20379;&#32454;&#31890;&#24230;&#20449;&#24687;&#19981;&#21487;&#25110;&#32570;&#30340;&#22240;&#32032;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#20132;&#36890;&#20256;&#24863;&#22120;&#30340;&#26377;&#38480;&#37096;&#32626;&#65292;&#33719;&#21462;&#20840;&#38754;&#30340;&#20132;&#36890;&#37327;&#20449;&#24687;&#24182;&#19981;&#23481;&#26131;&#12290;&#29616;&#26377;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#25552;&#39640;&#29305;&#23450;&#26041;&#27861;&#30340;&#25972;&#20307;&#20272;&#35745;&#20934;&#30830;&#24615;&#19978;&#65292;&#24573;&#30053;&#20102;&#20132;&#36890;&#37327;&#20272;&#35745;&#30340;&#22522;&#26412;&#25361;&#25112;&#65292;&#22240;&#27492;&#22312;&#19968;&#20123;&#20851;&#38190;&#20219;&#21153;&#19978;&#34920;&#29616;&#36739;&#24046;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20132;&#36890;&#37327;&#20272;&#35745;&#20013;&#30340;&#20004;&#20010;&#20851;&#38190;&#38382;&#39064;: (1) &#30001;&#26410;&#26816;&#27979;&#21040;&#30340;&#34892;&#21160;&#24341;&#36215;&#30340;&#19981;&#30830;&#23450;&#20132;&#36890;&#27969;&#65292;&#20197;&#21450; (2) &#30001;&#25317;&#22581;&#20256;&#25773;&#24341;&#36215;&#30340;&#38750;&#24179;&#34913;&#20132;&#36890;&#27969;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#24418;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#21487;&#20197;&#25552;&#20379;&#25968;&#25454;&#39537;&#21160;&#30340;&#12289;&#26080;&#27169;&#22411;&#30340;&#21644;&#30456;&#20851;&#33258;&#36866;&#24212;&#26041;&#27861;&#26469;&#35299;&#20915;&#19978;&#36848;&#38382;&#39064;&#65292;&#24182;&#36827;&#34892;&#20934;&#30830;&#30340;&#20840;&#38754;&#20132;&#36890;&#37327;&#20272;&#35745;&#12290;&#29305;&#21035;&#22320;&#65292;&#20026;&#20102;&#37327;&#21270;&#20132;&#36890;&#36895;&#24230;&#21644;&#27969;&#37327;&#20043;&#38388;&#30340;&#21160;&#24577;&#21644;&#38750;&#32447;&#24615;&#20851;&#31995;&#65292;&#26412;&#25991;&#20171;&#32461;&#20102;&#29992;&#20110;&#24314;&#31435;&#20132;&#36890;&#27969;&#22270;&#30340;&#30456;&#20851;&#22270;&#21367;&#31215;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
Traffic volume is an indispensable ingredient to provide fine-grained information for traffic management and control. However, due to limited deployment of traffic sensors, obtaining full-scale volume information is far from easy. Existing works on this topic primarily focus on improving the overall estimation accuracy of a particular method and ignore the underlying challenges of volume estimation, thereby having inferior performances on some critical tasks. This paper studies two key problems with regard to traffic volume estimation: (1) underdetermined traffic flows caused by undetected movements, and (2) non-equilibrium traffic flows arise from congestion propagation. Here we demonstrate a graph-based deep learning method that can offer a data-driven, model-free and correlation adaptive approach to tackle the above issues and perform accurate network-wide traffic volume estimation. Particularly, in order to quantify the dynamic and nonlinear relationships between traffic speed and 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20851;&#20110;&#27491;&#30830;&#12289;&#38169;&#35823;&#21644;&#22806;&#22312;&#31561;&#21464;&#24615;&#30340;&#26222;&#36941;&#29702;&#35770;&#65292;&#36890;&#36807;&#36880;&#28857;&#23450;&#20041;&#37327;&#21270;&#20102;&#20989;&#25968;&#34920;&#29616;&#30340;&#27599;&#31181;&#31867;&#22411;&#31561;&#21464;&#24615;&#30340;&#31243;&#24230;&#65292;&#24182;&#30740;&#31350;&#20102;&#19981;&#27491;&#30830;&#25110;&#22806;&#22312;&#23545;&#31216;&#24615;&#23545;&#27169;&#22411;&#38169;&#35823;&#30340;&#24433;&#21709;&#12290;&#23454;&#39564;&#35777;&#23454;&#20102;&#36825;&#20123;&#32467;&#26524;&#12290; (230&#23383;&#31526;)</title><link>http://arxiv.org/abs/2303.04745</link><description>&lt;p&gt;
&#19968;&#20010;&#20851;&#20110;&#27491;&#30830;&#12289;&#38169;&#35823;&#21644;&#22806;&#22312;&#31561;&#21464;&#24615;&#30340;&#26222;&#36941;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
A General Theory of Correct, Incorrect, and Extrinsic Equivariance. (arXiv:2303.04745v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.04745
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20851;&#20110;&#27491;&#30830;&#12289;&#38169;&#35823;&#21644;&#22806;&#22312;&#31561;&#21464;&#24615;&#30340;&#26222;&#36941;&#29702;&#35770;&#65292;&#36890;&#36807;&#36880;&#28857;&#23450;&#20041;&#37327;&#21270;&#20102;&#20989;&#25968;&#34920;&#29616;&#30340;&#27599;&#31181;&#31867;&#22411;&#31561;&#21464;&#24615;&#30340;&#31243;&#24230;&#65292;&#24182;&#30740;&#31350;&#20102;&#19981;&#27491;&#30830;&#25110;&#22806;&#22312;&#23545;&#31216;&#24615;&#23545;&#27169;&#22411;&#38169;&#35823;&#30340;&#24433;&#21709;&#12290;&#23454;&#39564;&#35777;&#23454;&#20102;&#36825;&#20123;&#32467;&#26524;&#12290; (230&#23383;&#31526;)
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#31561;&#21464;&#26426;&#22120;&#23398;&#20064;&#22312;&#35768;&#22810;&#20219;&#21153;&#20013;&#35777;&#26126;&#26159;&#26377;&#25928;&#30340;&#65292;&#20294;&#25104;&#21151;&#24456;&#22823;&#31243;&#24230;&#19978;&#20381;&#36182;&#20110;&#20551;&#35774;&#22320;&#38754;&#30495;&#30456;&#20989;&#25968;&#22312;&#25972;&#20010;&#22495;&#19978;&#26159;&#23545;&#31216;&#30340;&#65292;&#19982;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#30340;&#23545;&#31216;&#24615;&#21305;&#37197;&#12290;&#31561;&#21464;&#23398;&#20064;&#25991;&#29486;&#20013;&#32570;&#23569;&#30340;&#19968;&#22359;&#26159;&#22312;&#22495;&#20013;&#20165;&#37096;&#20998;&#23384;&#22312;&#23545;&#31216;&#24615;&#26102;&#31561;&#21464;&#32593;&#32476;&#30340;&#20998;&#26512;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#36825;&#31181;&#24773;&#20917;&#30340;&#26222;&#36941;&#29702;&#35770;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#27491;&#30830;&#12289;&#38169;&#35823;&#21644;&#22806;&#22312;&#31561;&#21464;&#24615;&#30340;&#36880;&#28857;&#23450;&#20041;&#65292;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#36830;&#32493;&#22320;&#37327;&#21270;&#20989;&#25968;&#26174;&#31034;&#30340;&#27599;&#31181;&#31867;&#22411;&#31561;&#21464;&#24615;&#30340;&#31243;&#24230;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19981;&#27491;&#30830;&#25110;&#22806;&#22312;&#23545;&#31216;&#24615;&#30340;&#21508;&#31181;&#31243;&#24230;&#23545;&#27169;&#22411;&#38169;&#35823;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#37096;&#20998;&#19981;&#27491;&#30830;&#23545;&#31216;&#24615;&#30340;&#20998;&#31867;&#25110;&#22238;&#24402;&#35774;&#32622;&#20013;&#19981;&#21464;&#25110;&#31561;&#21464;&#32593;&#32476;&#23384;&#22312;&#38169;&#35823;&#30340;&#19979;&#30028;&#12290;&#25105;&#20204;&#36824;&#20998;&#26512;&#20102;&#22806;&#22312;&#31561;&#21464;&#24615;&#30340;&#28508;&#22312;&#26377;&#23475;&#24433;&#21709;&#12290;&#23454;&#39564;&#35777;&#23454;&#20102;&#36825;&#20123;&#32467;&#26524;&#22312;&#19977;&#31181;&#19981;&#21516;&#30340;&#23454;&#39564;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
Although equivariant machine learning has proven effective at many tasks, success depends heavily on the assumption that the ground truth function is symmetric over the entire domain matching the symmetry in an equivariant neural network. A missing piece in the equivariant learning literature is the analysis of equivariant networks when symmetry exists only partially in the domain. In this work, we present a general theory for such a situation. We propose pointwise definitions of correct, incorrect, and extrinsic equivariance, which allow us to quantify continuously the degree of each type of equivariance a function displays. We then study the impact of various degrees of incorrect or extrinsic symmetry on model error. We prove error lower bounds for invariant or equivariant networks in classification or regression settings with partially incorrect symmetry. We also analyze the potentially harmful effects of extrinsic equivariance. Experiments validate these results in three different 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21457;&#29616;&#20102;&#25968;&#25454;&#20998;&#25968;&#38543;&#26426;&#21453;&#21521;&#36807;&#31243;&#26159;&#19968;&#20010;&#38789;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26657;&#20934;&#20219;&#24847;&#39044;&#20808;&#35757;&#32451;&#30340;DPM&#65292;&#26377;&#25928;&#20943;&#23567;&#27169;&#22411;&#30340;&#24471;&#20998;&#21305;&#37197;&#25439;&#22833;&#65292;&#22686;&#21152;&#27169;&#22411;&#20284;&#28982;&#30340;&#19979;&#38480;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#33324;&#26657;&#20934;&#25351;&#21335;&#12290;</title><link>http://arxiv.org/abs/2302.10688</link><description>&lt;p&gt;
&#20851;&#20110;&#26657;&#20934;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
On Calibrating Diffusion Probabilistic Models. (arXiv:2302.10688v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.10688
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21457;&#29616;&#20102;&#25968;&#25454;&#20998;&#25968;&#38543;&#26426;&#21453;&#21521;&#36807;&#31243;&#26159;&#19968;&#20010;&#38789;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26657;&#20934;&#20219;&#24847;&#39044;&#20808;&#35757;&#32451;&#30340;DPM&#65292;&#26377;&#25928;&#20943;&#23567;&#27169;&#22411;&#30340;&#24471;&#20998;&#21305;&#37197;&#25439;&#22833;&#65292;&#22686;&#21152;&#27169;&#22411;&#20284;&#28982;&#30340;&#19979;&#38480;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#33324;&#26657;&#20934;&#25351;&#21335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65288;DPM&#65289;&#22312;&#21508;&#31181;&#29983;&#25104;&#24615;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;&#19968;&#20010;&#20856;&#22411;&#30340;DPM&#26694;&#26550;&#21253;&#25324;&#19968;&#20010;&#36880;&#28176;&#25193;&#25955;&#25968;&#25454;&#20998;&#24067;&#30340;&#27491;&#21521;&#36807;&#31243;&#21644;&#19968;&#20010;&#20174;&#26102;&#38388;&#30456;&#20851;&#25968;&#25454;&#20998;&#25968;&#20013;&#24674;&#22797;&#25968;&#25454;&#20998;&#24067;&#30340;&#38543;&#26426;&#21453;&#21521;&#36807;&#31243;&#12290;&#26412;&#25991;&#35266;&#23519;&#21040;&#25968;&#25454;&#20998;&#25968;&#30340;&#38543;&#26426;&#21453;&#21521;&#36807;&#31243;&#26159;&#19968;&#20010;&#38789;&#65292;&#20174;&#20013;&#21487;&#20197;&#23548;&#20986;&#25968;&#25454;&#20998;&#25968;&#30340;&#38598;&#20013;&#30028;&#21644;&#38543;&#26426;&#20572;&#27490;&#23450;&#29702;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#21457;&#29616;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#26657;&#20934;&#20219;&#24847;&#39044;&#20808;&#35757;&#32451;&#30340;DPM&#65292;&#20197;&#20943;&#23567;&#24471;&#20998;&#21305;&#37197;&#25439;&#22833;&#65292;&#24182;&#22240;&#27492;&#22686;&#21152;&#27169;&#22411;&#20284;&#28982;&#30340;&#19979;&#38480;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#21508;&#31181;&#27169;&#22411;&#21442;&#25968;&#21270;&#19979;&#30340;&#19968;&#33324;&#26657;&#20934;&#25351;&#21335;&#12290;&#25105;&#20204;&#30340;&#26657;&#20934;&#26041;&#27861;&#20165;&#25191;&#34892;&#19968;&#27425;&#65292;&#24182;&#19988;&#21487;&#20197;&#37325;&#22797;&#20351;&#29992;&#25152;&#24471;&#21040;&#30340;&#27169;&#22411;&#36827;&#34892;&#37319;&#26679;&#12290;&#25105;&#20204;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#23454;&#39564;&#65292;&#20197;&#32463;&#39564;&#24615;&#22320;&#39564;&#35777;&#25105;&#20204;&#30340;&#25552;&#35758;&#12290;&#25105;&#20204;&#30340;&#20195;&#30721;&#20301;&#20110;https://github.com/thudzj/Cal&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, diffusion probabilistic models (DPMs) have achieved promising results in diverse generative tasks. A typical DPM framework includes a forward process that gradually diffuses the data distribution and a reverse process that recovers the data distribution from time-dependent data scores. In this work, we observe that the stochastic reverse process of data scores is a martingale, from which concentration bounds and the optional stopping theorem for data scores can be derived. Then, we discover a simple way for calibrating an arbitrary pretrained DPM, with which the score matching loss can be reduced and the lower bounds of model likelihood can consequently be increased. We provide general calibration guidelines under various model parametrizations. Our calibration method is performed only once and the resulting models can be used repeatedly for sampling. We conduct experiments on multiple datasets to empirically validate our proposal. Our code is at https://github.com/thudzj/Cal
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#25512;&#24191;&#24179;&#22343;Lipschitz&#24179;&#28369;&#24615;&#21040;H&#246;lder&#24179;&#28369;&#24615;&#65292;&#24471;&#21040;&#20102;&#20851;&#20110;&#24179;&#22343;H&#246;lder&#24179;&#28369;&#24615;&#30340;&#19978;&#19979;&#39118;&#38505;&#30028;&#65292;&#26368;&#20248;&#30340;&#19979;&#30028;&#23545;&#25968;&#22240;&#23376;&#26368;&#22810;&#24046;&#19968;&#20010;&#65292;&#25552;&#20379;&#20102;&#29420;&#31435;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2302.06005</link><description>&lt;p&gt;
&#24179;&#22343;H&#246;lder&#24179;&#28369;&#24230;&#19979;&#30340;&#36817;&#20284;&#26368;&#20248;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Near-optimal learning with average H\"older smoothness. (arXiv:2302.06005v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.06005
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25512;&#24191;&#24179;&#22343;Lipschitz&#24179;&#28369;&#24615;&#21040;H&#246;lder&#24179;&#28369;&#24615;&#65292;&#24471;&#21040;&#20102;&#20851;&#20110;&#24179;&#22343;H&#246;lder&#24179;&#28369;&#24615;&#30340;&#19978;&#19979;&#39118;&#38505;&#30028;&#65292;&#26368;&#20248;&#30340;&#19979;&#30028;&#23545;&#25968;&#22240;&#23376;&#26368;&#22810;&#24046;&#19968;&#20010;&#65292;&#25552;&#20379;&#20102;&#29420;&#31435;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23558;Ashlagi&#31561;&#20154;&#65288;COLT 2021&#65289;&#25552;&#20986;&#30340;&#24179;&#22343;Lipschitz&#24179;&#28369;&#24615;&#27010;&#24565;&#25512;&#24191;&#21040;H&#246;lder&#24179;&#28369;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#20851;&#20110;&#24179;&#22343;H&#246;lder&#24179;&#28369;&#24615;&#30340;&#19978;&#19979;&#39118;&#38505;&#30028;&#65292;&#36825;&#20123;&#30028;&#30340;&#36895;&#29575;&#29978;&#33267;&#22312;&#24179;&#22343;Lipschitz&#24179;&#28369;&#24615;&#30340;&#29305;&#27530;&#24773;&#20917;&#19979;&#20063;&#20248;&#20110;&#20043;&#21069;&#24050;&#30693;&#30028;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#19979;&#30028;&#22312;&#21487;&#23454;&#29616;&#24773;&#20917;&#19979;&#26159;&#26368;&#20248;&#30340;&#65292;&#26368;&#22810;&#24046;&#19968;&#20010;&#23545;&#25968;&#22240;&#23376;&#65292;&#20174;&#32780;&#24314;&#31435;&#20102;&#26497;&#23567;&#20540;&#29575;&#12290;&#20174;&#31639;&#27861;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#30001;&#20110;&#25105;&#20204;&#23545;&#24179;&#22343;&#24179;&#28369;&#24230;&#30340;&#23450;&#20041;&#26159;&#38024;&#23545;&#26410;&#30693;&#30340;&#22522;&#30784;&#20998;&#24067;&#30340;&#65292;&#22240;&#27492;&#23398;&#20064;&#32773;&#27809;&#26377;&#20989;&#25968;&#31867;&#30340;&#26174;&#24335;&#34920;&#31034;&#65292;&#26080;&#27861;&#25191;&#34892;ERM&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#29420;&#31435;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We generalize the notion of average Lipschitz smoothness proposed by Ashlagi et al. (COLT 2021) by extending it to H\"older smoothness. This measure of the "effective smoothness" of a function is sensitive to the underlying distribution and can be dramatically smaller than its classic "worst-case H\"older constant. We consider both the realizable and the agnostic (noisy) regression settings, proving upper and lower risk bounds in terms of the average H\"older smoothness; these rates improve upon both previously known rates even in the special case of average Lipschitz smoothness. Moreover, our lower bound is tight in the realizable setting up to log factors, thus we establish the minimax rate. From an algorithmic perspective, since our notion of average smoothness is defined with respect to the unknown underlying distribution, the learner does not have an explicit representation of the function class, hence is unable to execute ERM. Nevertheless, we provide distinct learning algorithms
&lt;/p&gt;</description></item><item><title>&#21019;&#26032;&#28857;&#22312;&#20110;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#39532;&#23572;&#21487;&#22827;&#25193;&#25955;&#22122;&#22768;&#36807;&#31243;&#30340;&#26143;&#24418;&#38477;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65292;&#33021;&#22815;&#24191;&#27867;&#36866;&#29992;&#20110;&#25351;&#25968;&#26063;&#20013;&#30340;&#22810;&#31181;&#20998;&#24067;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#32422;&#26463;&#27969;&#24418;&#19978;&#30340;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2302.05259</link><description>&lt;p&gt;
&#26143;&#24418;&#38477;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Star-Shaped Denoising Diffusion Probabilistic Models. (arXiv:2302.05259v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.05259
&lt;/p&gt;
&lt;p&gt;
&#21019;&#26032;&#28857;&#22312;&#20110;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#39532;&#23572;&#21487;&#22827;&#25193;&#25955;&#22122;&#22768;&#36807;&#31243;&#30340;&#26143;&#24418;&#38477;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65292;&#33021;&#22815;&#24191;&#27867;&#36866;&#29992;&#20110;&#25351;&#25968;&#26063;&#20013;&#30340;&#22810;&#31181;&#20998;&#24067;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#32422;&#26463;&#27969;&#24418;&#19978;&#30340;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#38477;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65288;DDPM&#65289;&#30340;&#26041;&#27861;&#24050;&#32463;&#25104;&#20026;&#29983;&#25104;&#27169;&#22411;&#20013;&#26080;&#22788;&#19981;&#22312;&#30340;&#24037;&#20855;&#12290;&#20294;&#26159;&#65292;&#23427;&#20204;&#22823;&#22810;&#23616;&#38480;&#20110;&#39640;&#26031;&#21644;&#31163;&#25955;&#25193;&#25955;&#36807;&#31243;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#26143;&#24418;&#38477;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65288;SS-DDPM&#65289;&#65292;&#19968;&#31181;&#20855;&#26377;&#38750;&#39532;&#23572;&#21487;&#22827;&#25193;&#25955;&#22122;&#22768;&#36807;&#31243;&#30340;&#27169;&#22411;&#12290;&#22312;&#39640;&#26031;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#65292;&#35813;&#27169;&#22411;&#31561;&#25928;&#20110;&#39532;&#23572;&#21487;&#22827;DDPM&#12290;&#28982;&#32780;&#65292;&#23427;&#21487;&#20197;&#23450;&#20041;&#21644;&#36866;&#29992;&#20110;&#20219;&#24847;&#22122;&#22768;&#20998;&#24067;&#65292;&#24182;&#19988;&#23545;&#20110;&#33853;&#22312;&#25351;&#25968;&#26063;&#20013;&#30340;&#24191;&#27867;&#20998;&#24067;&#65292;&#23427;&#37319;&#29992;&#20102;&#39640;&#25928;&#30340;&#35757;&#32451;&#21644;&#37319;&#26679;&#31639;&#27861;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#37197;&#26041;&#65292;&#29992;&#20110;&#35774;&#35745;&#20855;&#26377;Beta&#65292;von Mises-Fisher&#65292;Dirichlet&#65292;Wishart&#31561;&#20998;&#24067;&#30340;&#25193;&#25955;&#26679;&#24335;&#27169;&#22411;&#65292;&#24403;&#25968;&#25454;&#20301;&#20110;&#32422;&#26463;&#27969;&#24418;&#19978;&#26102;&#29305;&#21035;&#26377;&#29992;&#65292;&#20363;&#22914;&#21333;&#20301;&#29699;&#65292;&#27491;&#21322;&#23450;&#30697;&#38453;&#30340;&#31354;&#38388;&#65292;&#27010;&#29575;&#21333;&#32431;&#24418;&#31561;&#12290;&#25105;&#20204;&#22312;&#19981;&#21516;&#30340;&#35774;&#32622;&#20013;&#35780;&#20272;&#20102;&#35813;&#27169;&#22411;&#65292;&#24182;&#21457;&#29616;&#23427;&#24456;&#26377;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Methods based on Denoising Diffusion Probabilistic Models (DDPM) became a ubiquitous tool in generative modeling. However, they are mostly limited to Gaussian and discrete diffusion processes. We propose Star-Shaped Denoising Diffusion Probabilistic Models (SS-DDPM), a model with a non-Markovian diffusion-like noising process. In the case of Gaussian distributions, this model is equivalent to Markovian DDPMs. However, it can be defined and applied with arbitrary noising distributions, and admits efficient training and sampling algorithms for a wide range of distributions that lie in the exponential family. We provide a simple recipe for designing diffusion-like models with distributions like Beta, von Mises--Fisher, Dirichlet, Wishart and others, which can be especially useful when data lies on a constrained manifold such as the unit sphere, the space of positive semi-definite matrices, the probabilistic simplex, etc. We evaluate the model in different settings and find it competitive 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#22270;&#25968;&#25454;&#30340;&#24322;&#24120;&#31283;&#20581;Gromov-Wasserstein&#26041;&#27861;&#65288;RGW&#65289;&#65292;&#36890;&#36807;&#24341;&#20837;&#20048;&#35266;&#25200;&#21160;&#30340;&#36793;&#38469;&#32422;&#26463;&#21644;&#20351;&#29992;Bregman&#36817;&#31471;&#20132;&#26367;&#32447;&#24615;&#21270;&#26368;&#23567;&#21270;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;GW&#36317;&#31163;&#23545;&#24322;&#24120;&#20540;&#25935;&#24863;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2302.04610</link><description>&lt;p&gt;
&#38024;&#23545;&#22270;&#25968;&#25454;&#30340;&#24322;&#24120;&#31283;&#20581;Gromov-Wasserstein&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Outlier-Robust Gromov-Wasserstein for Graph Data. (arXiv:2302.04610v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.04610
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#22270;&#25968;&#25454;&#30340;&#24322;&#24120;&#31283;&#20581;Gromov-Wasserstein&#26041;&#27861;&#65288;RGW&#65289;&#65292;&#36890;&#36807;&#24341;&#20837;&#20048;&#35266;&#25200;&#21160;&#30340;&#36793;&#38469;&#32422;&#26463;&#21644;&#20351;&#29992;Bregman&#36817;&#31471;&#20132;&#26367;&#32447;&#24615;&#21270;&#26368;&#23567;&#21270;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;GW&#36317;&#31163;&#23545;&#24322;&#24120;&#20540;&#25935;&#24863;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Gromov-Wasserstein&#65288;GW&#65289;&#36317;&#31163;&#26159;&#19968;&#31181;&#22312;&#19981;&#21516;&#24230;&#37327;&#31354;&#38388;&#19978;&#27604;&#36739;&#21644;&#23545;&#40784;&#27010;&#29575;&#20998;&#24067;&#30340;&#24378;&#22823;&#24037;&#20855;&#12290;&#26368;&#36817;&#65292;GW&#24050;&#25104;&#20026;&#24191;&#27867;&#24212;&#29992;&#20110;&#22270;&#23398;&#20064;&#20219;&#21153;&#20013;&#23545;&#40784;&#24322;&#26500;&#25968;&#25454;&#30340;&#20027;&#35201;&#24314;&#27169;&#25216;&#26415;&#12290;&#28982;&#32780;&#65292;&#24050;&#30693;GW&#36317;&#31163;&#23545;&#24322;&#24120;&#20540;&#38750;&#24120;&#25935;&#24863;&#65292;&#22914;&#26524;&#22312;&#30446;&#26631;&#20989;&#25968;&#20013;&#23558;&#24322;&#24120;&#20540;&#19982;&#20854;&#20182;&#26679;&#26412;&#36171;&#20104;&#30456;&#21516;&#30340;&#26435;&#37325;&#65292;&#21487;&#33021;&#20250;&#23548;&#33268;&#36739;&#22823;&#30340;&#19981;&#20934;&#30830;&#24615;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#12289;&#31283;&#20581;&#30340;GW&#36317;&#31163;&#31216;&#20026;RGW&#12290;RGW&#22312;&#22522;&#20110;Kullback-Leibler&#25955;&#24230;&#30340;&#27169;&#31946;&#38598;&#21512;&#20013;&#24341;&#20837;&#20102;&#20048;&#35266;&#25200;&#21160;&#30340;&#36793;&#38469;&#32422;&#26463;&#12290;&#20026;&#20102;&#26356;&#26041;&#20415;&#22320;&#22312;&#23454;&#36341;&#20013;&#20351;&#29992;RGW&#30340;&#22909;&#22788;&#65292;&#25105;&#20204;&#21033;&#29992;Bregman&#36817;&#31471;&#20132;&#26367;&#32447;&#24615;&#21270;&#26368;&#23567;&#21270;&#31639;&#27861;&#24320;&#21457;&#20102;&#19968;&#20010;&#35745;&#31639;&#39640;&#25928;&#19988;&#29702;&#35770;&#21487;&#35777;&#30340;&#36807;&#31243;&#12290;&#36890;&#36807;&#22823;&#37327;&#23454;&#39564;&#35777;&#23454;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#65292;&#24182;&#23637;&#31034;&#20102;RGW&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gromov-Wasserstein (GW) distance is a powerful tool for comparing and aligning probability distributions supported on different metric spaces. Recently, GW has become the main modeling technique for aligning heterogeneous data for a wide range of graph learning tasks. However, the GW distance is known to be highly sensitive to outliers, which can result in large inaccuracies if the outliers are given the same weight as other samples in the objective function. To mitigate this issue, we introduce a new and robust version of the GW distance called RGW. RGW features optimistically perturbed marginal constraints within a Kullback-Leibler divergence-based ambiguity set. To make the benefits of RGW more accessible in practice, we develop a computationally efficient and theoretically provable procedure using Bregman proximal alternating linearized minimization algorithm. Through extensive experimentation, we validate our theoretical results and demonstrate the effectiveness of RGW on real-wor
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#65292;&#21033;&#29992;&#20854;&#29702;&#35770;&#22522;&#30784;&#21644;&#23454;&#26045;&#30340;&#21487;&#34892;&#24615;&#65292;&#20174;&#32780;&#20272;&#35745;&#36830;&#32493;&#26292;&#38706;/&#27835;&#30103;&#30340;&#20998;&#24067;&#23545;&#25919;&#31574;&#30456;&#20851;&#32467;&#26524;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#25105;&#20204;&#23558;&#27492;&#26041;&#27861;&#24212;&#29992;&#20110;&#21253;&#21547;6800&#19975;&#20010;&#20010;&#20307;&#21644;2700&#19975;&#20010;&#32654;&#22269;&#22659;&#20869;&#27515;&#20129;&#20107;&#20214;&#30340;&#25968;&#25454;&#20013;&#65292;&#36890;&#36807;&#35780;&#20272;&#32654;&#22269;&#22269;&#23478;&#29615;&#22659;&#20445;&#25252;&#23616;&#65288;EPA&#65289;&#23545;PM2.5&#30340;&#22269;&#23478;&#29615;&#22659;&#31354;&#27668;&#36136;&#37327;&#26631;&#20934;&#65288;NAAQS&#65289;&#36827;&#34892;&#20462;&#35746;&#21518;&#30340;&#20581;&#24247;&#25928;&#30410;&#12290;</title><link>http://arxiv.org/abs/2302.02560</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#22312;&#22240;&#26524;&#20272;&#35745;&#20013;&#30340;&#24212;&#29992;: &#22312;&#32654;&#22269;&#35780;&#20272;&#26356;&#20005;&#26684;&#30340;&#31354;&#27668;&#36136;&#37327;&#26631;&#20934;&#30340;&#20581;&#24247;&#25928;&#30410;
&lt;/p&gt;
&lt;p&gt;
Causal Estimation of Exposure Shifts with Neural Networks: Evaluating the Health Benefits of Stricter Air Quality Standards in the US. (arXiv:2302.02560v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.02560
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#65292;&#21033;&#29992;&#20854;&#29702;&#35770;&#22522;&#30784;&#21644;&#23454;&#26045;&#30340;&#21487;&#34892;&#24615;&#65292;&#20174;&#32780;&#20272;&#35745;&#36830;&#32493;&#26292;&#38706;/&#27835;&#30103;&#30340;&#20998;&#24067;&#23545;&#25919;&#31574;&#30456;&#20851;&#32467;&#26524;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#25105;&#20204;&#23558;&#27492;&#26041;&#27861;&#24212;&#29992;&#20110;&#21253;&#21547;6800&#19975;&#20010;&#20010;&#20307;&#21644;2700&#19975;&#20010;&#32654;&#22269;&#22659;&#20869;&#27515;&#20129;&#20107;&#20214;&#30340;&#25968;&#25454;&#20013;&#65292;&#36890;&#36807;&#35780;&#20272;&#32654;&#22269;&#22269;&#23478;&#29615;&#22659;&#20445;&#25252;&#23616;&#65288;EPA&#65289;&#23545;PM2.5&#30340;&#22269;&#23478;&#29615;&#22659;&#31354;&#27668;&#36136;&#37327;&#26631;&#20934;&#65288;NAAQS&#65289;&#36827;&#34892;&#20462;&#35746;&#21518;&#30340;&#20581;&#24247;&#25928;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25919;&#31574;&#30740;&#31350;&#20013;&#65292;&#20272;&#35745;&#36830;&#32493;&#24615;&#26292;&#38706;/&#27835;&#30103;&#30340;&#20998;&#24067;&#23545;&#24863;&#20852;&#36259;&#30340;&#32467;&#26524;&#30340;&#22240;&#26524;&#25928;&#24212;&#26159;&#26368;&#20851;&#38190;&#30340;&#20998;&#26512;&#20219;&#21153;&#20043;&#19968;&#12290;&#25105;&#20204;&#31216;&#20043;&#20026;&#20559;&#31227;-&#21709;&#24212;&#20989;&#25968;&#65288;SRF&#65289;&#20272;&#35745;&#38382;&#39064;&#12290;&#29616;&#26377;&#30340;&#28041;&#21450;&#24378;&#20581;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#22120;&#30340;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#32570;&#20047;&#29702;&#35770;&#20445;&#35777;&#21644;&#23454;&#38469;&#23454;&#29616;&#65292;&#29992;&#20110;SRF&#20272;&#35745;&#12290;&#21463;&#20844;&#20849;&#21355;&#29983;&#20013;&#30340;&#20851;&#38190;&#25919;&#31574;&#38382;&#39064;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#21450;&#20854;&#29702;&#35770;&#22522;&#30784;&#65292;&#20197;&#25552;&#20379;&#20855;&#26377;&#24378;&#20581;&#24615;&#21644;&#25928;&#29575;&#20445;&#35777;&#30340;SRF&#20272;&#35745;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#21253;&#21547;6800&#19975;&#20010;&#20010;&#20307;&#21644;2700&#19975;&#20010;&#32654;&#22269;&#22659;&#20869;&#27515;&#20129;&#20107;&#20214;&#30340;&#25968;&#25454;&#20013;&#65292;&#20197;&#20272;&#35745;&#23558;&#32654;&#22269;&#22269;&#23478;&#29615;&#22659;&#20445;&#25252;&#23616;&#65288;EPA&#65289;&#26368;&#36817;&#25552;&#35758;&#20174;12 &#956;g/m&#179;&#25913;&#20026;9 &#956;g/m&#179;&#30340;PM2.5&#30340;&#32654;&#22269;&#22269;&#23478;&#29615;&#22659;&#31354;&#27668;&#36136;&#37327;&#26631;&#20934;&#65288;NAAQS&#65289;&#30340;&#20462;&#35746;&#23545;&#32467;&#26524;&#30340;&#22240;&#26524;&#25928;&#24212;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#39318;&#27425;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
In policy research, one of the most critical analytic tasks is to estimate the causal effect of a policy-relevant shift to the distribution of a continuous exposure/treatment on an outcome of interest. We call this problem shift-response function (SRF) estimation. Existing neural network methods involving robust causal-effect estimators lack theoretical guarantees and practical implementations for SRF estimation. Motivated by a key policy-relevant question in public health, we develop a neural network method and its theoretical underpinnings to estimate SRFs with robustness and efficiency guarantees. We then apply our method to data consisting of 68 million individuals and 27 million deaths across the U.S. to estimate the causal effect from revising the US National Ambient Air Quality Standards (NAAQS) for PM 2.5 from 12 $\mu g/m^3$ to 9 $\mu g/m^3$. This change has been recently proposed by the US Environmental Protection Agency (EPA). Our goal is to estimate, for the first time, the 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#38750;&#21442;&#25968;&#23494;&#24230;&#20272;&#35745;&#22312;&#20998;&#24067;&#28418;&#31227;&#19979;&#30340;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#32039;&#23494;&#26497;&#23567;&#39118;&#38505;&#30028;&#65292;&#24182;&#25512;&#24191;&#20102;&#20808;&#21069;&#20851;&#20110;&#23545;&#28418;&#31227;&#30340;&#26080;&#30693;&#23398;&#20064;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2302.02460</link><description>&lt;p&gt;
&#38750;&#21442;&#25968;&#23494;&#24230;&#20272;&#35745;&#22312;&#20998;&#24067;&#28418;&#31227;&#19979;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Nonparametric Density Estimation under Distribution Drift. (arXiv:2302.02460v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.02460
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#38750;&#21442;&#25968;&#23494;&#24230;&#20272;&#35745;&#22312;&#20998;&#24067;&#28418;&#31227;&#19979;&#30340;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#32039;&#23494;&#26497;&#23567;&#39118;&#38505;&#30028;&#65292;&#24182;&#25512;&#24191;&#20102;&#20808;&#21069;&#20851;&#20110;&#23545;&#28418;&#31227;&#30340;&#26080;&#30693;&#23398;&#20064;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#38750;&#39547;&#28857;&#28418;&#31227;&#35774;&#32622;&#19979;&#30340;&#38750;&#21442;&#25968;&#23494;&#24230;&#20272;&#35745;&#12290;&#32473;&#23450;&#26469;&#33258;&#19968;&#31995;&#21015;&#38543;&#26102;&#38388;&#36880;&#28176;&#21464;&#21270;&#30340;&#20998;&#24067;&#30340;&#29420;&#31435;&#26679;&#26412;&#24207;&#21015;&#65292;&#30446;&#26631;&#26159;&#35745;&#31639;&#24403;&#21069;&#20998;&#24067;&#30340;&#26368;&#20339;&#20272;&#35745;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#31163;&#25955;&#21644;&#36830;&#32493;&#24179;&#28369;&#23494;&#24230;&#30340;&#32039;&#23494;&#26497;&#23567;&#39118;&#38505;&#30028;&#65292;&#20854;&#20013;&#26497;&#23567;&#20540;&#26159;&#23545;&#25152;&#26377;&#21487;&#33021;&#20272;&#35745;&#30340;&#26368;&#23567;&#20540;&#65292;&#32780;&#26497;&#22823;&#20540;&#26159;&#23545;&#28385;&#36275;&#28418;&#31227;&#32422;&#26463;&#30340;&#25152;&#26377;&#21487;&#33021;&#20998;&#24067;&#30340;&#26368;&#22823;&#20540;&#12290;&#25105;&#20204;&#30340;&#25216;&#26415;&#36866;&#29992;&#20110;&#24191;&#27867;&#30340;&#28418;&#31227;&#27169;&#22411;&#65292;&#24182;&#25512;&#24191;&#20102;&#20808;&#21069;&#20851;&#20110;&#23545;&#28418;&#31227;&#30340;&#26080;&#30693;&#23398;&#20064;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study nonparametric density estimation in non-stationary drift settings. Given a sequence of independent samples taken from a distribution that gradually changes in time, the goal is to compute the best estimate for the current distribution. We prove tight minimax risk bounds for both discrete and continuous smooth densities, where the minimum is over all possible estimates and the maximum is over all possible distributions that satisfy the drift constraints. Our technique handles a broad class of drift models, and generalizes previous results on agnostic learning under drift.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32479;&#35745;&#20272;&#35745;&#22120;&#8212;&#8212;&#19978;&#19979;&#25991;&#22871;&#32034;&#65292;&#21487;&#20197;&#36890;&#36807;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#35299;&#20915;&#35299;&#37322;&#24615;&#21644;&#25311;&#21512;&#33021;&#21147;&#30340;&#30683;&#30462;&#38382;&#39064;&#65292;&#23454;&#29616;&#23545;&#21487;&#35299;&#37322;&#29305;&#24449;&#30340;&#31232;&#30095;&#25311;&#21512;&#65292;&#24182;&#19988;&#31232;&#30095;&#27169;&#24335;&#21644;&#31995;&#25968;&#20250;&#38543;&#30528;&#19978;&#19979;&#25991;&#29305;&#24449;&#30340;&#21464;&#21270;&#32780;&#21457;&#29983;&#21464;&#21270;&#12290;</title><link>http://arxiv.org/abs/2302.00878</link><description>&lt;p&gt;
&#19978;&#19979;&#25991;&#22871;&#32034;&#65306;&#36890;&#36807;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#23454;&#29616;&#31232;&#30095;&#32447;&#24615;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
The contextual lasso: Sparse linear models via deep neural networks. (arXiv:2302.00878v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.00878
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32479;&#35745;&#20272;&#35745;&#22120;&#8212;&#8212;&#19978;&#19979;&#25991;&#22871;&#32034;&#65292;&#21487;&#20197;&#36890;&#36807;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#35299;&#20915;&#35299;&#37322;&#24615;&#21644;&#25311;&#21512;&#33021;&#21147;&#30340;&#30683;&#30462;&#38382;&#39064;&#65292;&#23454;&#29616;&#23545;&#21487;&#35299;&#37322;&#29305;&#24449;&#30340;&#31232;&#30095;&#25311;&#21512;&#65292;&#24182;&#19988;&#31232;&#30095;&#27169;&#24335;&#21644;&#31995;&#25968;&#20250;&#38543;&#30528;&#19978;&#19979;&#25991;&#29305;&#24449;&#30340;&#21464;&#21270;&#32780;&#21457;&#29983;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31232;&#30095;&#32447;&#24615;&#27169;&#22411;&#26159;&#21487;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#30340;&#40644;&#37329;&#26631;&#20934;&#24037;&#20855;&#65292;&#26412;&#35770;&#25991;&#36890;&#36807;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23545;&#31232;&#30095;&#32447;&#24615;&#27169;&#22411;&#36827;&#34892;&#25913;&#36827;&#65292;&#23454;&#29616;&#20102;&#21487;&#35299;&#37322;&#24615;&#21644;&#24378;&#22823;&#30340;&#25311;&#21512;&#33021;&#21147;&#12290;&#19978;&#19979;&#25991;&#22871;&#32034;&#26159;&#19968;&#31181;&#26032;&#30340;&#32479;&#35745;&#20272;&#35745;&#22120;&#65292;&#23427;&#23558;&#36755;&#20837;&#29305;&#24449;&#20998;&#25104;&#21487;&#35299;&#37322;&#29305;&#24449;&#21644;&#19978;&#19979;&#25991;&#29305;&#24449;&#20004;&#32452;&#65292;&#24182;&#23545;&#21487;&#35299;&#37322;&#29305;&#24449;&#36827;&#34892;&#31232;&#30095;&#25311;&#21512;&#65292;&#21516;&#26102;&#20854;&#31232;&#30095;&#27169;&#24335;&#21644;&#31995;&#25968;&#20250;&#38543;&#30528;&#19978;&#19979;&#25991;&#29305;&#24449;&#30340;&#21464;&#21270;&#32780;&#21457;&#29983;&#21464;&#21270;&#65292;&#36825;&#20010;&#36807;&#31243;&#36890;&#36807;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26080;&#38656;&#21442;&#25968;&#22320;&#36827;&#34892;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sparse linear models are a gold standard tool for interpretable machine learning, a field of emerging importance as predictive models permeate decision-making in many domains. Unfortunately, sparse linear models are far less flexible as functions of their input features than black-box models like deep neural networks. With this capability gap in mind, we study a not-uncommon situation where the input features dichotomize into two groups: explanatory features, which are candidates for inclusion as variables in an interpretable model, and contextual features, which select from the candidate variables and determine their effects. This dichotomy leads us to the contextual lasso, a new statistical estimator that fits a sparse linear model to the explanatory features such that the sparsity pattern and coefficients vary as a function of the contextual features. The fitting process learns this function nonparametrically via a deep neural network. To attain sparse coefficients, we train the net
&lt;/p&gt;</description></item><item><title>&#22823;&#22411;Transformer&#27169;&#22411;&#20013;&#30340;&#38544;&#34255;&#34920;&#31034;&#20855;&#26377;&#31867;&#20284;&#30340;&#20960;&#20309;&#21644;&#32479;&#35745;&#29305;&#24615;&#65292;&#38543;&#30528;&#23618;&#32423;&#30340;&#31227;&#21160;&#65292;&#23427;&#20204;&#22312;&#26368;&#21021;&#30340;&#20960;&#23618;&#20013;&#21464;&#24471;&#39640;&#32500;&#65292;&#28982;&#21518;&#22312;&#20013;&#38388;&#23618;&#20013;&#26174;&#33879;&#25910;&#32553;&#65292;&#22312;&#27169;&#22411;&#30340;&#26368;&#21518;&#37096;&#20998;&#65292;&#20445;&#25345;&#24658;&#23450;&#25110;&#24418;&#25104;&#31532;&#20108;&#20010;&#27973;&#23792;&#12290;&#22312;&#31532;&#19968;&#20010;&#23792;&#20540;&#32467;&#26463;&#26102;&#65292;&#25968;&#25454;&#38598;&#30340;&#35821;&#20041;&#20449;&#24687;&#34987;&#26356;&#22909;&#22320;&#34920;&#36798;&#12290;</title><link>http://arxiv.org/abs/2302.00294</link><description>&lt;p&gt;
&#22823;&#22411;Transformer&#27169;&#22411;&#30340;&#38544;&#34255;&#34920;&#31034;&#30340;&#20960;&#20309;&#23398;
&lt;/p&gt;
&lt;p&gt;
The geometry of hidden representations of large transformer models. (arXiv:2302.00294v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.00294
&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;Transformer&#27169;&#22411;&#20013;&#30340;&#38544;&#34255;&#34920;&#31034;&#20855;&#26377;&#31867;&#20284;&#30340;&#20960;&#20309;&#21644;&#32479;&#35745;&#29305;&#24615;&#65292;&#38543;&#30528;&#23618;&#32423;&#30340;&#31227;&#21160;&#65292;&#23427;&#20204;&#22312;&#26368;&#21021;&#30340;&#20960;&#23618;&#20013;&#21464;&#24471;&#39640;&#32500;&#65292;&#28982;&#21518;&#22312;&#20013;&#38388;&#23618;&#20013;&#26174;&#33879;&#25910;&#32553;&#65292;&#22312;&#27169;&#22411;&#30340;&#26368;&#21518;&#37096;&#20998;&#65292;&#20445;&#25345;&#24658;&#23450;&#25110;&#24418;&#25104;&#31532;&#20108;&#20010;&#27973;&#23792;&#12290;&#22312;&#31532;&#19968;&#20010;&#23792;&#20540;&#32467;&#26463;&#26102;&#65292;&#25968;&#25454;&#38598;&#30340;&#35821;&#20041;&#20449;&#24687;&#34987;&#26356;&#22909;&#22320;&#34920;&#36798;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;Transformer&#27169;&#22411;&#26159;&#29992;&#20110;&#33258;&#30417;&#30563;&#25968;&#25454;&#20998;&#26512;&#30340;&#24378;&#22823;&#26550;&#26500;&#65292;&#21487;&#20197;&#22788;&#29702;&#21253;&#25324;&#34507;&#30333;&#36136;&#24207;&#21015;&#12289;&#22270;&#20687;&#21644;&#25991;&#26412;&#22312;&#20869;&#30340;&#21508;&#31181;&#25968;&#25454;&#31867;&#22411;&#12290;&#22312;&#36825;&#20123;&#27169;&#22411;&#20013;&#65292;&#25968;&#25454;&#38598;&#30340;&#35821;&#20041;&#32467;&#26500;&#36890;&#36807;&#19968;&#20010;&#34920;&#31034;&#19982;&#19979;&#19968;&#20010;&#34920;&#31034;&#20043;&#38388;&#30340;&#19968;&#31995;&#21015;&#21464;&#25442;&#32780;&#20986;&#29616;&#12290;&#25105;&#20204;&#34920;&#24449;&#20102;&#36825;&#20123;&#34920;&#31034;&#30340;&#20960;&#20309;&#21644;&#32479;&#35745;&#29305;&#24615;&#65292;&#20197;&#21450;&#23427;&#20204;&#22312;&#23618;&#32423;&#31227;&#21160;&#26102;&#30340;&#21464;&#21270;&#12290;&#36890;&#36807;&#20998;&#26512;&#20869;&#22312;&#32500;&#24230;&#65288;ID&#65289;&#21644;&#37051;&#23621;&#32452;&#25104;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;&#35757;&#32451;&#22312;&#34507;&#30333;&#36136;&#35821;&#35328;&#20219;&#21153;&#21644;&#22270;&#20687;&#37325;&#24314;&#20219;&#21153;&#19978;&#30340;Transformer&#27169;&#22411;&#20013;&#65292;&#34920;&#31034;&#20197;&#30456;&#20284;&#30340;&#26041;&#24335;&#28436;&#21270;&#12290;&#22312;&#26368;&#21021;&#30340;&#20960;&#23618;&#20013;&#65292;&#25968;&#25454;&#27969;&#24418;&#25193;&#23637;&#65292;&#21464;&#24471;&#39640;&#32500;&#65292;&#28982;&#21518;&#22312;&#20013;&#38388;&#23618;&#20013;&#26174;&#33879;&#25910;&#32553;&#12290;&#22312;&#27169;&#22411;&#30340;&#26368;&#21518;&#37096;&#20998;&#65292;ID&#20445;&#25345;&#22823;&#33268;&#24658;&#23450;&#25110;&#24418;&#25104;&#31532;&#20108;&#20010;&#27973;&#23792;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25968;&#25454;&#38598;&#30340;&#35821;&#20041;&#20449;&#24687;&#22312;&#31532;&#19968;&#20010;&#23792;&#20540;&#32467;&#26463;&#26102;&#26356;&#22909;&#22320;&#34920;&#36798;&#65292;&#36825;&#19968;&#29616;&#35937;&#21487;&#20197;&#34987;&#35266;&#23519;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large transformers are powerful architectures used for self-supervised data analysis across various data types, including protein sequences, images, and text. In these models, the semantic structure of the dataset emerges from a sequence of transformations between one representation and the next. We characterize the geometric and statistical properties of these representations and how they change as we move through the layers. By analyzing the intrinsic dimension (ID) and neighbor composition, we find that the representations evolve similarly in transformers trained on protein language tasks and image reconstruction tasks. In the first layers, the data manifold expands, becoming high-dimensional, and then contracts significantly in the intermediate layers. In the last part of the model, the ID remains approximately constant or forms a second shallow peak. We show that the semantic information of the dataset is better expressed at the end of the first peak, and this phenomenon can be ob
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#26680;&#25216;&#24039;&#23558;&#32047;&#35745;&#37327;&#25193;&#23637;&#21040;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#65292;&#25552;&#20379;&#20102;&#19968;&#32452;&#26032;&#30340;&#36890;&#29992;&#32479;&#35745;&#37327;&#12290;&#36229;&#36234;&#19968;&#38454;&#20855;&#26377;&#20960;&#20010;&#20248;&#21183;&#65292;&#24182;&#19988;&#22312;&#35745;&#31639;&#19978;&#20855;&#26377;&#30456;&#21516;&#30340;&#22797;&#26434;&#24230;&#21644;&#26368;&#23567;&#30340;&#24320;&#38144;&#12290;</title><link>http://arxiv.org/abs/2301.12466</link><description>&lt;p&gt;
&#26680;&#21270;&#32047;&#35745;&#37327;&#65306;&#36229;&#36234;&#26680;&#22343;&#20540;&#23884;&#20837;
&lt;/p&gt;
&lt;p&gt;
Kernelized Cumulants: Beyond Kernel Mean Embeddings. (arXiv:2301.12466v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.12466
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#26680;&#25216;&#24039;&#23558;&#32047;&#35745;&#37327;&#25193;&#23637;&#21040;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#65292;&#25552;&#20379;&#20102;&#19968;&#32452;&#26032;&#30340;&#36890;&#29992;&#32479;&#35745;&#37327;&#12290;&#36229;&#36234;&#19968;&#38454;&#20855;&#26377;&#20960;&#20010;&#20248;&#21183;&#65292;&#24182;&#19988;&#22312;&#35745;&#31639;&#19978;&#20855;&#26377;&#30456;&#21516;&#30340;&#22797;&#26434;&#24230;&#21644;&#26368;&#23567;&#30340;&#24320;&#38144;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;$d$&#32500;&#23454;&#25968;&#31354;&#38388;&#20013;&#65292;&#20247;&#25152;&#21608;&#30693;&#65292;&#32047;&#35745;&#37327;&#26159;&#19968;&#31181;&#26367;&#20195;&#30697;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#20197;&#36739;&#20302;&#30340;&#26041;&#24046;&#20272;&#35745;&#36798;&#21040;&#30456;&#21516;&#30340;&#30446;&#26631;&#12290;&#26412;&#25991;&#21033;&#29992;&#24352;&#37327;&#20195;&#25968;&#30340;&#24037;&#20855;&#23558;&#32047;&#35745;&#37327;&#25193;&#23637;&#21040;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#65292;&#24182;&#36890;&#36807;&#26680;&#25216;&#24039;&#35777;&#26126;&#20102;&#23427;&#20204;&#22312;&#35745;&#31639;&#19978;&#26159;&#21487;&#34892;&#30340;&#12290;&#36825;&#20123;&#26680;&#21270;&#32047;&#35745;&#37327;&#25552;&#20379;&#20102;&#19968;&#32452;&#26032;&#30340;&#36890;&#29992;&#32479;&#35745;&#37327;&#65307;&#32463;&#20856;&#30340;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#21644;&#24076;&#23572;&#20271;&#29305;-&#26045;&#23494;&#29305;&#29420;&#31435;&#24615;&#20934;&#21017;&#26159;&#25105;&#20204;&#19968;&#33324;&#26500;&#36896;&#20013;&#30340;&#19968;&#38454;&#23545;&#35937;&#12290;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#21644;&#23454;&#35777;&#19978;&#65288;&#20351;&#29992;&#21512;&#25104;&#12289;&#29615;&#22659;&#21644;&#27969;&#37327;&#25968;&#25454;&#20998;&#26512;&#65289;&#35770;&#35777;&#20102;&#36229;&#36234;&#19968;&#38454;&#20855;&#26377;&#20960;&#20010;&#20248;&#21183;&#65292;&#24182;&#19988;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#21487;&#20197;&#20197;&#30456;&#21516;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#21644;&#26368;&#23567;&#30340;&#39069;&#22806;&#24320;&#38144;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
In $\mathbb R^d$, it is well-known that cumulants provide an alternative to moments that can achieve the same goals with numerous benefits such as lower variance estimators. In this paper we extend cumulants to reproducing kernel Hilbert spaces (RKHS) using tools from tensor algebras and show that they are computationally tractable by a kernel trick. These kernelized cumulants provide a new set of all-purpose statistics; the classical maximum mean discrepancy and Hilbert-Schmidt independence criterion arise as the degree one objects in our general construction. We argue both theoretically and empirically (on synthetic, environmental, and traffic data analysis) that going beyond degree one has several advantages and can be achieved with the same computational complexity and minimal overhead in our experiments.
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#25552;&#20986;&#23569;&#26679;&#26412;&#23398;&#20064;&#30340;&#34920;&#29616;&#19982;&#20154;&#31867;&#34920;&#24449;&#30340;&#19968;&#33268;&#24615;&#23384;&#22312;U&#24418;&#20851;&#31995;&#65292;&#24182;&#36890;&#36807;&#35745;&#31639;&#26426;&#35270;&#35273;&#27169;&#22411;&#30340;&#23454;&#39564;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;&#39640;&#24230;&#23545;&#40784;&#30340;&#27169;&#22411;&#26356;&#21152;&#40065;&#26834;&#65292;&#23545;&#25968;&#25454;&#30340;&#21033;&#29992;&#26356;&#21152;&#26377;&#25928;&#65292;&#20294;&#19982;&#20154;&#31867;&#23545;&#40784;&#24182;&#38750;&#24517;&#35201;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2301.11990</link><description>&lt;p&gt;
&#19982;&#20154;&#31867;&#34920;&#24449;&#30340;&#19968;&#33268;&#24615;&#25903;&#25345;&#40065;&#26834;&#30340;&#23569;&#26679;&#26412;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Alignment with human representations supports robust few-shot learning. (arXiv:2301.11990v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11990
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#25552;&#20986;&#23569;&#26679;&#26412;&#23398;&#20064;&#30340;&#34920;&#29616;&#19982;&#20154;&#31867;&#34920;&#24449;&#30340;&#19968;&#33268;&#24615;&#23384;&#22312;U&#24418;&#20851;&#31995;&#65292;&#24182;&#36890;&#36807;&#35745;&#31639;&#26426;&#35270;&#35273;&#27169;&#22411;&#30340;&#23454;&#39564;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;&#39640;&#24230;&#23545;&#40784;&#30340;&#27169;&#22411;&#26356;&#21152;&#40065;&#26834;&#65292;&#23545;&#25968;&#25454;&#30340;&#21033;&#29992;&#26356;&#21152;&#26377;&#25928;&#65292;&#20294;&#19982;&#20154;&#31867;&#23545;&#40784;&#24182;&#38750;&#24517;&#35201;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#26159;&#21542;&#24212;&#35813;&#20851;&#24515;AI&#31995;&#32479;&#26159;&#21542;&#20855;&#26377;&#19982;&#20154;&#31867;&#30456;&#20284;&#30340;&#19990;&#30028;&#34920;&#24449;&#65311;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#20449;&#24687;&#35770;&#20998;&#26512;&#65292;&#24314;&#35758;&#22312;&#23569;&#26679;&#26412;&#23398;&#20064;&#20219;&#21153;&#30340;&#34920;&#29616;&#24230;&#19982;&#20154;&#31867;&#34920;&#24449;&#30340;&#19968;&#33268;&#24615;&#20043;&#38388;&#24212;&#35813;&#23384;&#22312;&#19968;&#20010;U&#24418;&#20851;&#31995;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;491&#20010;&#35745;&#31639;&#26426;&#35270;&#35273;&#27169;&#22411;&#30340;&#24615;&#33021;&#20998;&#26512;&#39564;&#35777;&#20102;&#36825;&#20010;&#39044;&#27979;&#30340;&#21487;&#34892;&#24615;&#65292;&#24182;&#19988;&#34920;&#26126;&#39640;&#24230;&#23545;&#40784;&#30340;&#27169;&#22411;&#26356;&#21152;&#40065;&#26834;&#20110;&#23545;&#25239;&#25915;&#20987;&#21644;&#22495;&#20559;&#31227;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#20154;&#31867;&#23545;&#40784;&#24448;&#24448;&#26159;&#27169;&#22411;&#26377;&#25928;&#21033;&#29992;&#26377;&#38480;&#25968;&#25454;&#12289;&#40065;&#26834;&#24615; &#20197;&#21450;&#27867;&#21270;&#33021;&#21147;&#30340;&#20805;&#20998;&#20294;&#19981;&#24517;&#35201;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
Should we care whether AI systems have representations of the world that are similar to those of humans? We provide an information-theoretic analysis that suggests that there should be a U-shaped relationship between the degree of representational alignment with humans and performance on few-shot learning tasks. We confirm this prediction empirically, finding such a relationship in an analysis of the performance of 491 computer vision models. We also show that highly-aligned models are more robust to both adversarial attacks and domain shifts. Our results suggest that human-alignment is often a sufficient, but not necessary, condition for models to make effective use of limited data, be robust, and generalize well.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#23567;&#30340;&#26465;&#20214;&#38598;&#26469;&#34920;&#24449;&#21644;&#23398;&#20064;&#22240;&#26524;&#22270;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#32422;&#26463;&#24615;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#22312;&#25968;&#25454;&#26377;&#38480;&#21644;&#26465;&#20214;&#38598;&#36739;&#22823;&#26102;&#30340;&#22256;&#38590;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;k-&#39532;&#23572;&#21487;&#22827;&#31561;&#20215;&#30340;&#27010;&#24565;&#65292;&#35813;&#27010;&#24565;&#22312;&#19981;&#33021;&#21033;&#29992;&#25152;&#26377;&#26465;&#20214;&#29420;&#31435;&#24615;&#35821;&#21477;&#26102;&#20173;&#28982;&#36866;&#29992;&#12290;</title><link>http://arxiv.org/abs/2301.09028</link><description>&lt;p&gt;
&#29992;&#23567;&#30340;&#26465;&#20214;&#38598;&#34920;&#24449;&#21644;&#23398;&#20064;&#22240;&#26524;&#22270;
&lt;/p&gt;
&lt;p&gt;
Characterization and Learning of Causal Graphs with Small Conditioning Sets. (arXiv:2301.09028v2 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.09028
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#23567;&#30340;&#26465;&#20214;&#38598;&#26469;&#34920;&#24449;&#21644;&#23398;&#20064;&#22240;&#26524;&#22270;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#32422;&#26463;&#24615;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#22312;&#25968;&#25454;&#26377;&#38480;&#21644;&#26465;&#20214;&#38598;&#36739;&#22823;&#26102;&#30340;&#22256;&#38590;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;k-&#39532;&#23572;&#21487;&#22827;&#31561;&#20215;&#30340;&#27010;&#24565;&#65292;&#35813;&#27010;&#24565;&#22312;&#19981;&#33021;&#21033;&#29992;&#25152;&#26377;&#26465;&#20214;&#29420;&#31435;&#24615;&#35821;&#21477;&#26102;&#20173;&#28982;&#36866;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32422;&#26463;&#24615;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#36890;&#36807;&#31995;&#32479;&#22320;&#27979;&#35797;&#25968;&#25454;&#20013;&#35266;&#23519;&#21040;&#30340;&#26465;&#20214;&#29420;&#31435;&#24615;&#26469;&#23398;&#20064;&#22240;&#26524;&#22270;&#30340;&#19968;&#37096;&#20998;&#32467;&#26500;&#12290;&#36825;&#20123;&#31639;&#27861;&#65292;&#22914;PC&#31639;&#27861;&#21450;&#20854;&#21464;&#20307;&#65292;&#20381;&#36182;&#20110;&#30001;Pearl&#25552;&#20986;&#30340;&#25152;&#35859;&#22240;&#26524;&#22270;&#31561;&#20215;&#31867;&#30340;&#22270;&#24418;&#34920;&#24449;&#12290;&#28982;&#32780;&#65292;&#24403;&#25968;&#25454;&#26377;&#38480;&#26102;&#65292;&#32422;&#26463;&#24615;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#24448;&#24448;&#38754;&#20020;&#22256;&#38590;&#65292;&#22240;&#20026;&#26465;&#20214;&#29420;&#31435;&#24615;&#26816;&#39564;&#24456;&#24555;&#22833;&#21435;&#32479;&#35745;&#33021;&#21147;&#65292;&#23588;&#20854;&#26159;&#24403;&#26465;&#20214;&#38598;&#24456;&#22823;&#26102;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#26465;&#20214;&#29420;&#31435;&#24615;&#26816;&#39564;&#65292;&#22312;&#40065;&#26834;&#30340;&#22240;&#26524;&#21457;&#29616;&#20013;&#23558;&#26465;&#20214;&#38598;&#30340;&#22823;&#23567;&#19978;&#38480;&#35774;&#32622;&#20026;&#26576;&#20010;&#25972;&#25968; k&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#22240;&#26524;&#22270;&#31561;&#20215;&#31867;&#30340;&#22270;&#24418;&#34920;&#24449;&#22312;&#25105;&#20204;&#19981;&#33021;&#21033;&#29992;&#25152;&#26377;&#30340;&#26465;&#20214;&#29420;&#31435;&#24615;&#35821;&#21477;&#26102;&#19981;&#36866;&#29992;&#12290;&#25105;&#20204;&#39318;&#20808;&#23450;&#20041;&#20102; k-&#39532;&#23572;&#21487;&#22827;&#31561;&#20215;&#30340;&#27010;&#24565;&#65306;&#22914;&#26524;&#20004;&#20010;&#22240;&#26524;&#22270;&#24471;&#21040;&#30456;&#21516;&#30340;&#26465;&#20214;&#29420;&#31435;&#24615;&#35821;&#21477;&#65292;&#23427;&#20204;&#26159; k-&#39532;&#23572;&#21487;&#22827;&#31561;&#20215;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Constraint-based causal discovery algorithms learn part of the causal graph structure by systematically testing conditional independences observed in the data. These algorithms, such as the PC algorithm and its variants, rely on graphical characterizations of the so-called equivalence class of causal graphs proposed by Pearl. However, constraint-based causal discovery algorithms struggle when data is limited since conditional independence tests quickly lose their statistical power, especially when the conditioning set is large. To address this, we propose using conditional independence tests where the size of the conditioning set is upper bounded by some integer $k$ for robust causal discovery. The existing graphical characterizations of the equivalence classes of causal graphs are not applicable when we cannot leverage all the conditional independence statements. We first define the notion of $k$-Markov equivalence: Two causal graphs are $k$-Markov equivalent if they entail the same c
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;JKO&#26041;&#26696;&#30340;&#21487;&#36870;&#24402;&#19968;&#21270;&#27969;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#25353;&#22359;&#36827;&#34892;&#27531;&#24046;&#22359;&#30340;&#35757;&#32451;&#65292;&#20943;&#23569;&#20102;&#20869;&#23384;&#36127;&#36733;&#21644;&#28145;&#24230;&#27969;&#32593;&#32476;&#35757;&#32451;&#30340;&#38590;&#24230;&#12290;&#24182;&#19988;&#36890;&#36807;&#33258;&#36866;&#24212;&#26102;&#38388;&#37325;&#26032;&#21442;&#25968;&#21270;&#30340;&#27969;&#32593;&#32476;&#65292;&#22312;&#27010;&#29575;&#31354;&#38388;&#20013;&#36880;&#27493;&#32454;&#21270;&#36712;&#36857;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#35757;&#32451;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2212.14424</link><description>&lt;p&gt;
&#22522;&#20110;JKO&#26041;&#26696;&#30340;&#21487;&#36870;&#24402;&#19968;&#21270;&#27969;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Invertible normalizing flow neural networks by JKO scheme. (arXiv:2212.14424v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.14424
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;JKO&#26041;&#26696;&#30340;&#21487;&#36870;&#24402;&#19968;&#21270;&#27969;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#25353;&#22359;&#36827;&#34892;&#27531;&#24046;&#22359;&#30340;&#35757;&#32451;&#65292;&#20943;&#23569;&#20102;&#20869;&#23384;&#36127;&#36733;&#21644;&#28145;&#24230;&#27969;&#32593;&#32476;&#35757;&#32451;&#30340;&#38590;&#24230;&#12290;&#24182;&#19988;&#36890;&#36807;&#33258;&#36866;&#24212;&#26102;&#38388;&#37325;&#26032;&#21442;&#25968;&#21270;&#30340;&#27969;&#32593;&#32476;&#65292;&#22312;&#27010;&#29575;&#31354;&#38388;&#20013;&#36880;&#27493;&#32454;&#21270;&#36712;&#36857;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#35757;&#32451;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24402;&#19968;&#21270;&#27969;&#26159;&#19968;&#31867;&#29992;&#20110;&#39640;&#25928;&#37319;&#26679;&#21644;&#23494;&#24230;&#20272;&#35745;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#12290;&#23454;&#38469;&#20013;&#65292;&#27969;&#36890;&#24120;&#34920;&#31034;&#20026;&#19968;&#31995;&#21015;&#21487;&#36870;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22359;&#38142;; &#20026;&#20102;&#20415;&#20110;&#35757;&#32451;&#65292;&#29616;&#26377;&#30340;&#24037;&#20316;&#23545;&#27969;&#36712;&#36857;&#36827;&#34892;&#20102;&#27491;&#21017;&#21270;&#65292;&#24182;&#35774;&#35745;&#20102;&#29305;&#27530;&#30340;&#32593;&#32476;&#26550;&#26500;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#21463;Jordan-Kinderleherer-Otto (JKO)&#26041;&#26696;&#21551;&#21457;&#30340;&#31070;&#32463;ODE&#27969;&#32593;&#32476;&#65292;&#23427;&#20801;&#35768;&#26377;&#25928;&#22320;&#25353;&#22359;&#36827;&#34892;&#27531;&#24046;&#22359;&#30340;&#35757;&#32451;&#65292;&#26080;&#38656;&#37319;&#26679;SDE&#36712;&#36857;&#25110;&#20998;&#25968;&#21305;&#37197;&#25110;&#21464;&#20998;&#23398;&#20064;&#30340;&#20869;&#24490;&#29615;&#12290;&#30001;&#20110;JKO&#26041;&#26696;&#23637;&#24320;&#20102;&#26799;&#24230;&#27969;&#30340;&#21160;&#24577;&#65292;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#33258;&#28982;&#22320;&#36880;&#20010;&#22534;&#21472;&#27531;&#24046;&#32593;&#32476;&#22359;&#65292;&#38477;&#20302;&#20102;&#20869;&#23384;&#36127;&#36733;&#21644;&#36827;&#34892;&#31471;&#21040;&#31471;&#28145;&#24230;&#27969;&#32593;&#32476;&#35757;&#32451;&#30340;&#38590;&#24230;&#12290;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#33258;&#36866;&#24212;&#26102;&#38388;&#37325;&#26032;&#21442;&#25968;&#21270;&#30340;&#27969;&#32593;&#32476;&#65292;&#36890;&#36807;&#22312;&#27010;&#29575;&#31354;&#38388;&#20013;&#36880;&#27493;&#32454;&#21270;&#36712;&#36857;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#35757;&#32451;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Normalizing flow is a class of deep generative models for efficient sampling and density estimation. In practice, the flow often appears as a chain of invertible neural network blocks; to facilitate training, existing works have regularized flow trajectories and designed special network architectures. The current paper develops a neural ODE flow network inspired by the Jordan-Kinderleherer-Otto (JKO) scheme, which allows efficient block-wise training of the residual blocks without sampling SDE trajectories or inner loops of score matching or variational learning. As the JKO scheme unfolds the dynamic of gradient flow, the proposed model naturally stacks residual network blocks one by one, reducing the memory load and difficulty in performing end-to-end deep flow network training. We also develop adaptive time reparameterization of the flow network with a progressive refinement of the trajectory in probability space, which improves the model training efficiency and accuracy in practice.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#24179;&#28369;&#26799;&#24230;&#19979;&#38477;&#19978;&#21319;&#27861; (DSGDA)&#65292;&#35813;&#31639;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#38750;&#20984;-&#38750;&#20985;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#65292;&#24182;&#19988;&#33021;&#22815;&#20840;&#23616;&#25910;&#25947;&#24182;&#28040;&#38500;&#26497;&#38480;&#29615;&#12290;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#65292;DSGDA &#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#36798;&#21040;&#20102;&#25991;&#29486;&#20013;&#21333;&#24490;&#29615;&#31639;&#27861;&#30340;&#26368;&#20339;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2212.12978</link><description>&lt;p&gt;
&#21452;&#37325;&#24179;&#28369;GDA&#65306;&#29992;&#20110;&#38750;&#20984;-&#38750;&#20985;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#30340;&#20840;&#23616;&#25910;&#25947;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Doubly Smoothed GDA: Global Convergent Algorithm for Constrained Nonconvex-Nonconcave Minimax Optimization. (arXiv:2212.12978v3 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.12978
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#24179;&#28369;&#26799;&#24230;&#19979;&#38477;&#19978;&#21319;&#27861; (DSGDA)&#65292;&#35813;&#31639;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#38750;&#20984;-&#38750;&#20985;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#65292;&#24182;&#19988;&#33021;&#22815;&#20840;&#23616;&#25910;&#25947;&#24182;&#28040;&#38500;&#26497;&#38480;&#29615;&#12290;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#65292;DSGDA &#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#36798;&#21040;&#20102;&#25991;&#29486;&#20013;&#21333;&#24490;&#29615;&#31639;&#27861;&#30340;&#26368;&#20339;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#20984;-&#38750;&#20985;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#36817;&#24180;&#26469;&#21463;&#21040;&#20102;&#24191;&#27867;&#30340;&#20851;&#27880;&#65292;&#20854;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#20855;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#31639;&#27861;&#19981;&#33021;&#20445;&#35777;&#20840;&#23616;&#25910;&#25947;&#65292;&#29978;&#33267;&#20250;&#36973;&#21463;&#26497;&#38480;&#29615;&#30340;&#22256;&#25200;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21333;&#24490;&#29615;&#31639;&#27861;&#65292;&#31216;&#20026;&#21452;&#37325;&#24179;&#28369;&#26799;&#24230;&#19979;&#38477;&#19978;&#21319;&#27861; (DSGDA)&#65292;&#23427;&#33021;&#22815;&#33258;&#28982;&#22320;&#24179;&#34913;&#21407;&#22987;&#19982;&#23545;&#20598;&#26356;&#26032;&#65292;&#24182;&#19988;&#23558;&#26497;&#20854;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38750;&#20984;-&#38750;&#20985;&#20363;&#23376;&#20013;&#30340;&#26497;&#38480;&#29615;&#28040;&#38500;&#65292;&#21253;&#25324; Forsaken&#65292;Bilinearly-coupled minimax&#65292;Sixth-order polynomial &#21644; PolarGame&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#65292;&#22312;&#19968;&#20010;&#21333;&#20391;&#30340; $\theta\in(0,1)$ Kurdyka-\L{}ojasiewicz&#26465;&#20214;&#65288;&#25110;&#20984;&#21407;&#22987;/&#20985;&#23545;&#20598;&#20989;&#25968;&#65289;&#19979;&#65292;DSGDA &#21487;&#20197;&#25214;&#21040;&#19968;&#20010;&#28216;&#25103;&#24179;&#34913;&#28857;&#65292;&#24182;&#19988;&#20855;&#26377;&#36845;&#20195;&#22797;&#26434;&#24230; $\mathcal{O}(\epsilon^{-2\max\{2\theta,1\}})$&#65288;&#25110; $\mathcal{O}(\epsilon^{-4})$&#65289;&#65292;&#36825;&#20123;&#19982;&#25991;&#29486;&#20013;&#21333;&#24490;&#29615;&#31639;&#27861;&#30340;&#26368;&#20339;&#32467;&#26524;&#30456;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;
Nonconvex-nonconcave minimax optimization has received intense attention over the last decade due to its broad applications in machine learning. Unfortunately, most existing algorithms cannot be guaranteed to converge globally and even suffer from limit cycles. To address this issue, we propose a novel single-loop algorithm called doubly smoothed gradient descent ascent method (DSGDA), which naturally balances the primal and dual updates. The proposed DSGDA can get rid of limit cycles in various challenging nonconvex-nonconcave examples in the literature, including Forsaken, Bilinearly-coupled minimax, Sixth-order polynomial, and PolarGame. We further show that under an one-sided Kurdyka-\L{}ojasiewicz condition with exponent $\theta\in(0,1)$ (resp. convex primal/concave dual function), DSGDA can find a game-stationary point with an iteration complexity of $\mathcal{O}(\epsilon^{-2\max\{2\theta,1\}})$ (resp. $\mathcal{O}(\epsilon^{-4})$). These match the best results for single-loop al
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992;&#29289;&#29702;&#23398;&#30693;&#35782;&#25351;&#23548;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#26041;&#27861;&#65292;&#35299;&#20915;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#27714;&#35299;&#22120;&#26080;&#27861;&#37327;&#21270;&#36817;&#20284;&#35823;&#24046;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2212.12474</link><description>&lt;p&gt;
&#29289;&#29702;&#23398;&#30693;&#35782;&#25351;&#23548;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#24212;&#29992;&#20110;&#35299;&#20915;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;
&lt;/p&gt;
&lt;p&gt;
Physics-Informed Gaussian Process Regression Generalizes Linear PDE Solvers. (arXiv:2212.12474v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.12474
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#29289;&#29702;&#23398;&#30693;&#35782;&#25351;&#23548;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#26041;&#27861;&#65292;&#35299;&#20915;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#27714;&#35299;&#22120;&#26080;&#27861;&#37327;&#21270;&#36817;&#20284;&#35823;&#24046;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#26159;&#19968;&#31867;&#37325;&#35201;&#19988;&#24191;&#27867;&#24212;&#29992;&#30340;&#26426;&#26800;&#27169;&#22411;&#65292;&#25551;&#36848;&#20102;&#29289;&#29702;&#36807;&#31243;&#65292;&#20363;&#22914;&#28909;&#20256;&#23548;&#12289;&#30005;&#30913;&#23398;&#21644;&#27874;&#20256;&#25773;&#31561;&#12290;&#23454;&#36341;&#20013;&#65292;&#36890;&#24120;&#20351;&#29992;&#22522;&#20110;&#31163;&#25955;&#21270;&#30340;&#19987;&#38376;&#25968;&#20540;&#26041;&#27861;&#26469;&#35299;&#20915;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#36825;&#20123;&#27714;&#35299;&#22120;&#36890;&#24120;&#20351;&#29992;&#26410;&#30693;&#27169;&#22411;&#21442;&#25968;&#30340;&#20272;&#35745;&#20540;&#20197;&#21450;&#22914;&#26524;&#21487;&#29992;&#30340;&#35805;&#65292;&#29289;&#29702;&#27979;&#37327;&#20540;&#29992;&#20110;&#21021;&#22987;&#21270;&#12290;&#36825;&#20123;&#27714;&#35299;&#22120;&#32463;&#24120;&#23884;&#20837;&#21040;&#20855;&#26377;&#19979;&#28216;&#24212;&#29992;&#30340;&#26356;&#22823;&#30340;&#31185;&#23398;&#27169;&#22411;&#20013;&#65292;&#22240;&#27492;&#35823;&#24046;&#37327;&#21270;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#32463;&#20856;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#27714;&#35299;&#22120;&#24573;&#30053;&#21442;&#25968;&#21644;&#27979;&#37327;&#19981;&#30830;&#23450;&#24615;&#65292;&#21487;&#33021;&#26080;&#27861;&#20135;&#29983;&#19968;&#33268;&#24615;&#30340;&#20272;&#35745;&#20540;&#65292;&#20197;&#29992;&#20110;&#35745;&#31639;&#20854;&#22266;&#26377;&#30340;&#36924;&#36817;&#35823;&#24046;&#12290;&#26412;&#25991;&#36890;&#36807;&#23558;&#27714;&#35299;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#35299;&#37322;&#20026;&#29289;&#29702;&#23398;&#30693;&#35782;&#25351;&#23548;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#25512;&#29702;&#23450;&#29702;&#30340;&#19968;&#20010;&#20851;&#38190;&#25512;&#24191;&#65292;&#35813;&#23450;&#29702;&#36866;&#29992;&#20110;&#36890;&#36807;&#20219;&#24847;&#30028;&#38754;&#36827;&#34892;&#35266;&#23519;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Linear partial differential equations (PDEs) are an important, widely applied class of mechanistic models, describing physical processes such as heat transfer, electromagnetism, and wave propagation. In practice, specialized numerical methods based on discretization are used to solve PDEs. They generally use an estimate of the unknown model parameters and, if available, physical measurements for initialization. Such solvers are often embedded into larger scientific models with a downstream application and thus error quantification plays a key role. However, by ignoring parameter and measurement uncertainty, classical PDE solvers may fail to produce consistent estimates of their inherent approximation error. In this work, we approach this problem in a principled fashion by interpreting solving linear PDEs as physics-informed Gaussian process (GP) regression. Our framework is based on a key generalization of the Gaussian process inference theorem to observations made via an arbitrary bou
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#32852;&#21512;&#38647;&#36798;&#36890;&#20449;&#20013;&#36890;&#36807;Beurling-Selberg&#26497;&#22823;&#21270;&#26041;&#27861;&#29992;&#20110;&#21452;&#30450;&#21453;&#21367;&#31215;&#24674;&#22797;&#30340;&#20248;&#21270;&#20998;&#31163;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2211.09253</link><description>&lt;p&gt;
Beurling-Selberg&#26497;&#22823;&#21270;&#29992;&#20110;&#32852;&#21512;&#38647;&#36798;&#36890;&#20449;&#20013;&#30340;&#21452;&#30450;&#21453;&#21367;&#31215;&#24674;&#22797;
&lt;/p&gt;
&lt;p&gt;
Beurling-Selberg Extremization for Dual-Blind Deconvolution Recovery in Joint Radar-Communications. (arXiv:2211.09253v3 [cs.IT] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.09253
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#32852;&#21512;&#38647;&#36798;&#36890;&#20449;&#20013;&#36890;&#36807;Beurling-Selberg&#26497;&#22823;&#21270;&#26041;&#27861;&#29992;&#20110;&#21452;&#30450;&#21453;&#21367;&#31215;&#24674;&#22797;&#30340;&#20248;&#21270;&#20998;&#31163;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#23545;&#32508;&#21512;&#24863;&#30693;&#21644;&#36890;&#20449;&#30340;&#20852;&#36259;&#23548;&#33268;&#20102;&#35774;&#35745;&#26032;&#30340;&#20449;&#21495;&#22788;&#29702;&#25216;&#26415;&#26469;&#20174;&#21472;&#21152;&#30340;&#38647;&#36798;&#36890;&#20449;&#20449;&#21495;&#20013;&#24674;&#22797;&#20449;&#24687;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#20851;&#27880;&#30340;&#26159;&#19968;&#20010;&#35889;&#20849;&#23384;&#30340;&#24773;&#20917;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#38647;&#36798;&#21644;&#36890;&#20449;&#31995;&#32479;&#30340;&#20449;&#36947;&#21644;&#21457;&#36865;&#20449;&#21495;&#23545;&#20110;&#26222;&#36890;&#25509;&#25910;&#22120;&#26469;&#35828;&#37117;&#26159;&#26410;&#30693;&#30340;&#12290;&#22312;&#36825;&#20010;&#21452;&#30450;&#21453;&#21367;&#31215;&#38382;&#39064;&#20013;&#65292;&#25509;&#25910;&#22120;&#25509;&#25910;&#19968;&#20010;&#22810;&#36733;&#27874;&#26080;&#32447;&#36890;&#20449;&#20449;&#21495;&#65292;&#35813;&#20449;&#21495;&#19982;&#20174;&#22810;&#20010;&#30446;&#26631;&#21453;&#23556;&#22238;&#26469;&#30340;&#38647;&#36798;&#20449;&#21495;&#30456;&#21472;&#21152;&#12290;&#36890;&#20449;&#21644;&#38647;&#36798;&#20449;&#36947;&#20998;&#21035;&#30001;&#22810;&#20010;&#20256;&#36755;&#36335;&#24452;&#21644;&#30446;&#26631;&#25152;&#23545;&#24212;&#30340;&#36830;&#32493;&#20540;&#33539;&#22260;&#26102;&#38388;&#25110;&#24310;&#36831;&#34920;&#31034;&#12290;&#20043;&#21069;&#30340;&#30740;&#31350;&#36890;&#36807;&#21407;&#23376;&#27867;&#20989;&#26368;&#23567;&#21270;&#26469;&#35299;&#20915;&#36825;&#20010;&#19981;&#36866;&#23450;&#30340;&#21452;&#30450;&#21453;&#21367;&#31215;&#38382;&#39064;&#20013;&#26410;&#30693;&#20449;&#36947;&#21644;&#20449;&#21495;&#30340;&#24674;&#22797;&#65292;&#20294;&#26159;&#38656;&#35201;&#38647;&#36798;&#21644;&#36890;&#20449;&#20449;&#36947;&#30340;&#21508;&#33258;&#26368;&#23567;&#20998;&#31163;&#26465;&#20214;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#26368;&#20248;&#30340;&#32852;&#21512;&#20998;&#31163;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent interest in integrated sensing and communications has led to the design of novel signal processing techniques to recover information from an overlaid radar-communications signal. Here, we focus on a spectral coexistence scenario, wherein the channels and transmit signals of both radar and communications systems are unknown to the common receiver. In this dual-blind deconvolution (DBD) problem, the receiver admits a multi-carrier wireless communications signal that is overlaid with the radar signal reflected off multiple targets. The communications and radar channels are represented by continuous-valued range-times or delays corresponding to multiple transmission paths and targets, respectively. Prior works addressed recovery of unknown channels and signals in this ill-posed DBD problem through atomic norm minimization but contingent on individual minimum separation conditions for radar and communications channels. In this paper, we provide an optimal joint separation condition u
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;BHMC&#30340;&#26032;&#30340;&#33945;&#29305;&#21345;&#32599;&#37319;&#26679;&#31639;&#27861;&#65292;&#33021;&#22815;&#20174;&#23450;&#20041;&#20102;&#32422;&#26463;&#30340;&#40654;&#26364;&#27969;&#24418;&#20013;&#36827;&#34892;&#26080;&#20559;&#37319;&#26679;&#65292;&#20854;&#20013;&#21253;&#21547;&#19968;&#31181;&#26032;&#30340;&#36807;&#28388;&#27493;&#39588;involution checking step&#12290;</title><link>http://arxiv.org/abs/2210.11925</link><description>&lt;p&gt;
&#33258;&#20849;&#36717;&#38556;&#30861;&#21704;&#23494;&#23572;&#39039;&#33945;&#29305;&#21345;&#27931;&#30340;&#26080;&#20559;&#32422;&#26463;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Unbiased constrained sampling with Self-Concordant Barrier Hamiltonian Monte Carlo. (arXiv:2210.11925v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.11925
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;BHMC&#30340;&#26032;&#30340;&#33945;&#29305;&#21345;&#32599;&#37319;&#26679;&#31639;&#27861;&#65292;&#33021;&#22815;&#20174;&#23450;&#20041;&#20102;&#32422;&#26463;&#30340;&#40654;&#26364;&#27969;&#24418;&#20013;&#36827;&#34892;&#26080;&#20559;&#37319;&#26679;&#65292;&#20854;&#20013;&#21253;&#21547;&#19968;&#31181;&#26032;&#30340;&#36807;&#28388;&#27493;&#39588;involution checking step&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#38556;&#30861;&#21704;&#23494;&#23572;&#39039;&#33945;&#29305;&#21345;&#32599;(BHMC)&#65292;&#23427;&#26159;HMC&#31639;&#27861;&#30340;&#19968;&#31181;&#21464;&#20307;&#65292;&#26088;&#22312;&#20174;&#24102;&#26377;&#33258;&#20849;&#36717;&#38556;&#30861;&#24230;&#37327;&#30340;&#27969;&#24418;&#20013;&#30340;Gibbs&#20998;&#24067;&#960;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;&#35813;&#26041;&#27861;&#20381;&#36182;&#20110;&#21253;&#21547;&#24230;&#37327;&#30340;Hamiltonian&#21160;&#21147;&#23398;&#12290;&#22240;&#27492;&#65292;&#23427;&#21253;&#21547;&#23450;&#20041;&#27969;&#24418;&#30340;&#32422;&#26463;&#65292;&#24182;&#33021;&#22815;&#21033;&#29992;&#20854;&#24213;&#23618;&#20960;&#20309;&#24418;&#29366;&#12290;&#28982;&#32780;&#65292;&#30456;&#24212;&#30340;Hamilton&#21160;&#21147;&#23398;&#26159;&#36890;&#36807;&#19981;&#21487;&#20998;&#31163;&#30340;&#24120;&#24494;&#20998;&#26041;&#31243;&#26469;&#23450;&#20041;&#30340;&#65292;&#19982;&#27431;&#20960;&#37324;&#24471;&#24773;&#20917;&#30456;&#21453;&#12290;&#36825;&#24847;&#21619;&#30528;&#23558;HMC&#25512;&#24191;&#21040;&#40654;&#26364;&#27969;&#24418;&#20013;&#20250;&#20135;&#29983;&#19981;&#21487;&#36991;&#20813;&#30340;&#20559;&#24046;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36807;&#28388;&#27493;&#39588;&#65292;&#31216;&#20026;&#8220;involution&#26816;&#26597;&#27493;&#39588;&#8221;&#12290;&#35813;&#27493;&#39588;&#22312;&#20004;&#20010;BHMC&#29256;&#26412;&#8212;&#8212;&#36830;&#32493;BHMC(c-BHMC)&#21644;&#25968;&#20540;BHMC(n-BHMC)&#20013;&#23454;&#29616;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#20004;&#20010;&#26032;&#31639;&#27861;&#29983;&#25104;&#21487;&#36870;Markov&#38142;&#19988;&#26080;&#20559;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose Barrier Hamiltonian Monte Carlo (BHMC), a version of the HMC algorithm which aims at sampling from a Gibbs distribution $\pi$ on a manifold $\mathrm{M}$, endowed with a Hessian metric $\mathfrak{g}$ derived from a self-concordant barrier. Our method relies on Hamiltonian dynamics which comprises $\mathfrak{g}$. Therefore, it incorporates the constraints defining $\mathrm{M}$ and is able to exploit its underlying geometry. However, the corresponding Hamiltonian dynamics is defined via non separable Ordinary Differential Equations (ODEs) in contrast to the Euclidean case. It implies unavoidable bias in existing generalization of HMC to Riemannian manifolds. In this paper, we propose a new filter step, called "involution checking step", to address this problem. This step is implemented in two versions of BHMC, coined continuous BHMC (c-BHMC) and numerical BHMC (n-BHMC) respectively. Our main results establish that these two new algorithms generate reversible Mark
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22312;&#32447;&#20984;&#20248;&#21270;&#26694;&#26550;&#65292;&#21487;&#20197;&#22788;&#29702;&#20915;&#31574;&#21382;&#21490;&#30340;&#38271;&#26399;&#20381;&#36182;&#20851;&#31995;&#65292;&#24182;&#20171;&#32461;&#20102;&#29992;&#20110;&#37327;&#21270;&#20381;&#36182;&#31243;&#24230;&#30340;$p$-&#26377;&#25928;&#20869;&#23384;&#23481;&#37327;&#30340;&#27010;&#24565;&#12290;</title><link>http://arxiv.org/abs/2210.09903</link><description>&lt;p&gt;
&#20855;&#26377;&#26080;&#38480;&#21046;&#20869;&#23384;&#30340;&#22312;&#32447;&#20984;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Online Convex Optimization with Unbounded Memory. (arXiv:2210.09903v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.09903
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22312;&#32447;&#20984;&#20248;&#21270;&#26694;&#26550;&#65292;&#21487;&#20197;&#22788;&#29702;&#20915;&#31574;&#21382;&#21490;&#30340;&#38271;&#26399;&#20381;&#36182;&#20851;&#31995;&#65292;&#24182;&#20171;&#32461;&#20102;&#29992;&#20110;&#37327;&#21270;&#20381;&#36182;&#31243;&#24230;&#30340;$p$-&#26377;&#25928;&#20869;&#23384;&#23481;&#37327;&#30340;&#27010;&#24565;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#20984;&#20248;&#21270;&#65288;OCO&#65289;&#26159;&#22312;&#32447;&#23398;&#20064;&#20013;&#24191;&#27867;&#20351;&#29992;&#30340;&#26694;&#26550;&#12290;&#28982;&#32780;&#65292;&#22312;&#24456;&#22810;&#24212;&#29992;&#20013;&#65292;&#23398;&#20064;&#32773;&#30340;&#25439;&#22833;&#19981;&#20165;&#21462;&#20915;&#20110;&#24403;&#21069;&#30340;&#20915;&#31574;&#65292;&#36824;&#21462;&#20915;&#20110;&#30452;&#21040;&#37027;&#20010;&#26102;&#38388;&#28857;&#30340;&#25152;&#26377;&#20915;&#31574;&#21382;&#21490;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;OCO&#30340;&#25193;&#23637;&#26694;&#26550;&#65292;&#8220;&#20855;&#26377;&#26080;&#38480;&#21046;&#20869;&#23384;&#30340;&#22312;&#32447;&#20984;&#20248;&#21270;&#8221;&#65292;&#26469;&#25429;&#25417;&#23545;&#36807;&#21435;&#20915;&#31574;&#30340;&#38271;&#26399;&#20381;&#36182;&#20851;&#31995;&#65292;&#24182;&#20171;&#32461;&#20102;$p$-&#26377;&#25928;&#20869;&#23384;&#23481;&#37327;&#30340;&#27010;&#24565;&#65292;$H_p$&#65292;&#23427;&#37327;&#21270;&#20102;$p$&#38454;&#24433;&#21709;&#30340;&#26368;&#22823;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Online convex optimization (OCO) is a widely used framework in online learning. In each round, the learner chooses a decision in a convex set and an adversary chooses a convex loss function, and then the learner suffers the loss associated with their current decision. However, in many applications the learner's loss depends not only on the current decision but on the entire history of decisions until that point. The OCO framework and its existing generalizations do not capture this, and they can only be applied to many settings of interest after a long series of approximation arguments. They also leave open the question of whether the dependence on memory is tight because there are no non-trivial lower bounds. In this work we introduce a generalization of the OCO framework, ``Online Convex Optimization with Unbounded Memory'', that captures long-term dependence on past decisions. We introduce the notion of $p$-effective memory capacity, $H_p$, that quantifies the maximum influence of p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35889;&#26041;&#27861;&#30340;&#39033;&#30446;&#21453;&#24212;&#29702;&#35770;&#31639;&#27861;&#65292;&#36890;&#36807;&#35745;&#31639;&#39532;&#23572;&#31185;&#22827;&#38142;&#30340;&#24179;&#31283;&#20998;&#24067;&#26469;&#20272;&#35745;&#27169;&#22411;&#21442;&#25968;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#20248;&#21270;&#24615;&#33021;&#21644;&#26377;&#38480;&#26679;&#26412;&#35823;&#24046;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2210.04317</link><description>&lt;p&gt;
&#22522;&#20110;&#35889;&#26041;&#27861;&#30340;&#39033;&#30446;&#21453;&#24212;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
A Spectral Approach to Item Response Theory. (arXiv:2210.04317v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.04317
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35889;&#26041;&#27861;&#30340;&#39033;&#30446;&#21453;&#24212;&#29702;&#35770;&#31639;&#27861;&#65292;&#36890;&#36807;&#35745;&#31639;&#39532;&#23572;&#31185;&#22827;&#38142;&#30340;&#24179;&#31283;&#20998;&#24067;&#26469;&#20272;&#35745;&#27169;&#22411;&#21442;&#25968;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#20248;&#21270;&#24615;&#33021;&#21644;&#26377;&#38480;&#26679;&#26412;&#35823;&#24046;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Rasch&#27169;&#22411;&#26159;&#39033;&#30446;&#21453;&#24212;&#29702;&#35770;&#20013;&#26368;&#22522;&#30784;&#30340;&#27169;&#22411;&#20043;&#19968;&#65292;&#24191;&#27867;&#24212;&#29992;&#20110;&#25945;&#32946;&#27979;&#35797;&#21644;&#25512;&#33616;&#31995;&#32479;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#39033;&#30446;&#20272;&#35745;&#31639;&#27861;&#65292;&#26680;&#24515;&#26159;&#35745;&#31639;&#22312;&#39033;&#30446;-&#39033;&#30446;&#22270;&#19978;&#23450;&#20041;&#30340;&#39532;&#23572;&#31185;&#22827;&#38142;&#30340;&#24179;&#31283;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Rasch model is one of the most fundamental models in \emph{item response theory} and has wide-ranging applications from education testing to recommendation systems. In a universe with $n$ users and $m$ items, the Rasch model assumes that the binary response $X_{li} \in \{0,1\}$ of a user $l$ with parameter $\theta^*_l$ to an item $i$ with parameter $\beta^*_i$ (e.g., a user likes a movie, a student correctly solves a problem) is distributed as $\Pr(X_{li}=1) = 1/(1 + \exp{-(\theta^*_l - \beta^*_i)})$. In this paper, we propose a \emph{new item estimation} algorithm for this celebrated model (i.e., to estimate $\beta^*$). The core of our algorithm is the computation of the stationary distribution of a Markov chain defined on an item-item graph. We complement our algorithmic contributions with finite-sample error guarantees, the first of their kind in the literature, showing that our algorithm is consistent and enjoys favorable optimality properties. We discuss practical modification
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22810;&#20307;&#36924;&#36817;&#30340;&#26041;&#27861;&#26469;&#20998;&#35299;&#38750;&#36127;&#24352;&#37327;&#65292;&#36890;&#36807;&#33021;&#37327;&#24314;&#27169;&#26469;&#36991;&#20813;&#20840;&#23616;&#20248;&#21270;&#21644;&#30446;&#26631;&#31209;&#36873;&#25321;&#30340;&#22256;&#38590;&#65292;&#21487;&#36890;&#36807;&#32771;&#34385;&#27169;&#24335;&#20043;&#38388;&#30340;&#20132;&#20114;&#36827;&#34892;&#20840;&#23616;&#20248;&#21270;; &#22312;&#35768;&#22810;&#20219;&#21153;&#20013;&#37117;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2209.15338</link><description>&lt;p&gt;
&#38750;&#36127;&#24352;&#37327;&#30340;&#22810;&#20307;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
Many-body Approximation for Non-negative Tensors. (arXiv:2209.15338v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.15338
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22810;&#20307;&#36924;&#36817;&#30340;&#26041;&#27861;&#26469;&#20998;&#35299;&#38750;&#36127;&#24352;&#37327;&#65292;&#36890;&#36807;&#33021;&#37327;&#24314;&#27169;&#26469;&#36991;&#20813;&#20840;&#23616;&#20248;&#21270;&#21644;&#30446;&#26631;&#31209;&#36873;&#25321;&#30340;&#22256;&#38590;&#65292;&#21487;&#36890;&#36807;&#32771;&#34385;&#27169;&#24335;&#20043;&#38388;&#30340;&#20132;&#20114;&#36827;&#34892;&#20840;&#23616;&#20248;&#21270;; &#22312;&#35768;&#22810;&#20219;&#21153;&#20013;&#37117;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26367;&#20195;&#26041;&#27861;&#26469;&#20998;&#35299;&#38750;&#36127;&#24352;&#37327;&#65292;&#31216;&#20026;&#22810;&#20307;&#36924;&#36817;&#12290;&#20256;&#32479;&#30340;&#20998;&#35299;&#26041;&#27861;&#20551;&#35774;&#34920;&#31034;&#20855;&#26377;&#20302;&#31209;&#24615;&#65292;&#23548;&#33268;&#20840;&#23616;&#20248;&#21270;&#21644;&#30446;&#26631;&#31209;&#36873;&#25321;&#30340;&#22256;&#38590;&#12290;&#25105;&#20204;&#36890;&#36807;&#24352;&#37327;&#30340;&#33021;&#37327;&#24314;&#27169;&#36991;&#20813;&#20102;&#36825;&#20123;&#38382;&#39064;&#65292;&#20854;&#20013;&#24352;&#37327;&#21644;&#20854;&#27169;&#24335;&#20998;&#21035;&#23545;&#24212;&#20110;&#27010;&#29575;&#20998;&#24067;&#21644;&#38543;&#26426;&#21464;&#37327;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#32771;&#34385;&#27169;&#24335;&#20043;&#38388;&#30340;&#20132;&#20114;&#26469;&#36827;&#34892;&#20840;&#23616;&#20248;&#21270;&#65292;&#21487;&#20197;&#27604;&#31209;&#26356;&#30452;&#35266;&#22320;&#36827;&#34892;&#35843;&#25972;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#27169;&#24335;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#21487;&#35270;&#21270;&#20026;&#24352;&#37327;&#32593;&#32476;&#65292;&#25581;&#31034;&#20102;&#22810;&#20307;&#36924;&#36817;&#21644;&#20302;&#31209;&#36924;&#36817;&#20043;&#38388;&#30340;&#38750;&#24179;&#20961;&#20851;&#31995;&#12290;&#25105;&#20204;&#22312;&#24352;&#37327;&#23436;&#25104;&#21644;&#36924;&#36817;&#20013;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present an alternative approach to decompose non-negative tensors, called many-body approximation. Traditional decomposition methods assume low-rankness in the representation, resulting in difficulties in global optimization and target rank selection. We avoid these problems by energy-based modeling of tensors, where a tensor and its mode correspond to a probability distribution and a random variable, respectively. Our model can be globally optimized in terms of the KL divergence minimization by taking the interaction between variables, i.e. modes, into account that can be tuned more intuitively than ranks. Furthermore, we visualize interactions between modes as tensor networks and reveal a nontrivial relationship between many-body approximation and low-rank approximation. We demonstrate the effectiveness of our approach in tensor completion and approximation.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#22823;&#30340;&#26368;&#22351;&#24773;&#20917;Lipschitz&#21442;&#25968;&#30340;&#24046;&#20998;&#38544;&#31169;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#19981;&#20381;&#36182;&#20110;&#32479;&#19968;Lipschitz&#21442;&#25968;&#30340;&#25509;&#36817;&#26368;&#20248;&#30340;&#36807;&#37327;&#39118;&#38505;&#30028;&#38480;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2209.07403</link><description>&lt;p&gt;
&#20855;&#26377;&#22823;&#30340;&#26368;&#22351;&#24773;&#20917;Lipschitz&#21442;&#25968;&#30340;&#31169;&#26377;&#38543;&#26426;&#20248;&#21270;&#65306;&#65288;&#38750;&#20809;&#28369;&#65289;&#20984;&#25439;&#22833;&#30340;&#26368;&#20248;&#36895;&#29575;&#21450;&#20854;&#23545;&#38750;&#20984;&#25439;&#22833;&#30340;&#25193;&#23637;
&lt;/p&gt;
&lt;p&gt;
Private Stochastic Optimization With Large Worst-Case Lipschitz Parameter: Optimal Rates for (Non-Smooth) Convex Losses and Extension to Non-Convex Losses. (arXiv:2209.07403v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.07403
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#22823;&#30340;&#26368;&#22351;&#24773;&#20917;Lipschitz&#21442;&#25968;&#30340;&#24046;&#20998;&#38544;&#31169;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#19981;&#20381;&#36182;&#20110;&#32479;&#19968;Lipschitz&#21442;&#25968;&#30340;&#25509;&#36817;&#26368;&#20248;&#30340;&#36807;&#37327;&#39118;&#38505;&#30028;&#38480;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#26368;&#22351;&#24773;&#20917;Lipschitz&#21442;&#25968;&#21487;&#33021;&#38750;&#24120;&#22823;&#30340;&#25439;&#22833;&#20989;&#25968;&#30340;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#38543;&#26426;&#20248;&#21270;&#65288;SO&#65289;&#12290;&#36804;&#20170;&#20026;&#27490;&#65292;&#22823;&#37096;&#20998;&#20851;&#20110;DP SO&#30340;&#24037;&#20316;&#37117;&#20551;&#35774;&#25439;&#22833;&#22312;&#25152;&#26377;&#25968;&#25454;&#28857;&#19978;&#26159;&#22343;&#21248;Lipschitz&#36830;&#32493;&#30340;&#65288;&#21363;&#38543;&#26426;&#26799;&#24230;&#22312;&#25152;&#26377;&#25968;&#25454;&#28857;&#19978;&#37117;&#26377;&#30028;&#65289;&#12290;&#34429;&#28982;&#36825;&#31181;&#20551;&#35774;&#24456;&#26041;&#20415;&#65292;&#20294;&#36890;&#24120;&#20250;&#23548;&#33268;&#24754;&#35266;&#30340;&#36807;&#37327;&#39118;&#38505;&#30028;&#38480;&#12290;&#22312;&#35768;&#22810;&#23454;&#38469;&#38382;&#39064;&#20013;&#65292;&#30001;&#20110;&#24322;&#24120;&#20540;&#65292;&#25439;&#22833;&#22312;&#25152;&#26377;&#25968;&#25454;&#28857;&#19978;&#30340;&#26368;&#22351;&#24773;&#20917;&#65288;&#32479;&#19968;&#65289;Lipschitz&#21442;&#25968;&#21487;&#33021;&#38750;&#24120;&#22823;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;DP SO&#30340;&#35823;&#24046;&#30028;&#38480;&#19982;&#25439;&#22833;&#30340;&#26368;&#22351;&#24773;&#20917;Lipschitz&#21442;&#25968;&#25104;&#27604;&#20363;&#65292;&#23558;&#20250;&#26159;&#31354;&#27934;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#65292;&#26412;&#24037;&#20316;&#25552;&#20379;&#20102;&#19968;&#31181;&#25509;&#36817;&#26368;&#20248;&#30340;&#36807;&#37327;&#39118;&#38505;&#30028;&#38480;&#65292;&#19981;&#20381;&#36182;&#20110;&#25439;&#22833;&#30340;&#32479;&#19968;Lipschitz&#21442;&#25968;&#12290;&#22312;&#26368;&#36817;&#30340;&#24037;&#20316;&#65288;Wang&#31561;&#20154;&#65292;2020; Kamath&#31561;&#20154;&#65292;2022&#65289;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#20551;&#35774;&#38543;&#26426;&#26799;&#24230;&#20855;&#26377;&#26377;&#30028;&#30340;k&#38454;&#30697;
&lt;/p&gt;
&lt;p&gt;
We study differentially private (DP) stochastic optimization (SO) with loss functions whose worst-case Lipschitz parameter over all data points may be extremely large. To date, the vast majority of work on DP SO assumes that the loss is uniformly Lipschitz continuous over data (i.e. stochastic gradients are uniformly bounded over all data points). While this assumption is convenient, it often leads to pessimistic excess risk bounds. In many practical problems, the worst-case (uniform) Lipschitz parameter of the loss over all data points may be extremely large due to outliers. In such cases, the error bounds for DP SO, which scale with the worst-case Lipschitz parameter of the loss, are vacuous. To address these limitations, this work provides near-optimal excess risk bounds that do not depend on the uniform Lipschitz parameter of the loss. Building on a recent line of work (Wang et al., 2020; Kamath et al., 2022), we assume that stochastic gradients have bounded $k$-th order moments fo
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#38480;&#21046;&#29627;&#23572;&#20857;&#26364;&#26426;&#22312;&#27169;&#24335;&#37325;&#26500;&#20013;&#30340;&#33021;&#21147;&#65292;&#21457;&#29616;&#38544;&#34255;&#23618;&#20808;&#39564;&#20998;&#24067;&#30340;&#23614;&#37096;&#34892;&#20026;&#23545;&#20110;&#24674;&#22797;&#38543;&#26426;&#27169;&#24335;&#30340;&#25928;&#26524;&#26377;&#20851;&#38190;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2205.07087</link><description>&lt;p&gt;
&#38480;&#21046;&#29627;&#23572;&#20857;&#26364;&#26426;&#30340;&#27169;&#24335;&#37325;&#26500;
&lt;/p&gt;
&lt;p&gt;
Pattern reconstruction with restricted Boltzmann machines. (arXiv:2205.07087v3 [math.PR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.07087
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#38480;&#21046;&#29627;&#23572;&#20857;&#26364;&#26426;&#22312;&#27169;&#24335;&#37325;&#26500;&#20013;&#30340;&#33021;&#21147;&#65292;&#21457;&#29616;&#38544;&#34255;&#23618;&#20808;&#39564;&#20998;&#24067;&#30340;&#23614;&#37096;&#34892;&#20026;&#23545;&#20110;&#24674;&#22797;&#38543;&#26426;&#27169;&#24335;&#30340;&#25928;&#26524;&#26377;&#20851;&#38190;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38480;&#21046;&#29627;&#23572;&#20857;&#26364;&#26426;&#26159;&#30001;&#21487;&#35265;&#23618;&#21644;&#38544;&#34255;&#23618;&#32452;&#25104;&#30340;&#33021;&#37327;&#27169;&#22411;&#12290;&#25105;&#20204;&#25214;&#21040;&#20102;&#25551;&#36848;&#21487;&#35265;&#21333;&#20803;&#19978;&#38646;&#28201;&#24230;&#29366;&#24577;&#30340;&#26377;&#25928;&#33021;&#37327;&#20989;&#25968;&#65292;&#35813;&#20989;&#25968;&#21482;&#20381;&#36182;&#20110;&#38544;&#34255;&#23618;&#20808;&#39564;&#20998;&#24067;&#30340;&#23614;&#37096;&#34892;&#20026;&#12290;&#36890;&#36807;&#30740;&#31350;&#35813;&#33021;&#37327;&#20989;&#25968;&#30340;&#23616;&#37096;&#26497;&#23567;&#20540;&#30340;&#20301;&#32622;&#65292;&#25105;&#20204;&#34920;&#26126;&#38480;&#21046;&#29627;&#23572;&#20857;&#26364;&#26426;&#37325;&#26500;&#38543;&#26426;&#27169;&#24335;&#30340;&#33021;&#21147;&#30830;&#23454;&#21482;&#21462;&#20915;&#20110;&#38544;&#34255;&#20808;&#39564;&#20998;&#24067;&#30340;&#23614;&#37096;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#20855;&#26377;&#20005;&#26684;&#36229;&#39640;&#26031;&#23614;&#37096;&#30340;&#38544;&#34255;&#20808;&#39564;&#20165;&#23548;&#33268;&#23545;&#27169;&#24335;&#24674;&#22797;&#30340;&#23545;&#25968;&#25439;&#22833;&#65292;&#32780;&#20855;&#26377;&#20005;&#26684;&#27425;&#39640;&#26031;&#23614;&#37096;&#30340;&#38544;&#34255;&#21333;&#20803;&#21017;&#23548;&#33268;&#26356;&#38590;&#36827;&#34892;&#26377;&#25928;&#30340;&#24674;&#22797;&#65307;&#22914;&#26524;&#38544;&#34255;&#20808;&#39564;&#20855;&#26377;&#39640;&#26031;&#23614;&#37096;&#65292;&#24674;&#22797;&#33021;&#21147;&#21462;&#20915;&#20110;&#38544;&#34255;&#21333;&#20803;&#30340;&#25968;&#37327;&#65288;&#19982;&#38669;&#26222;&#33778;&#23572;&#24503;&#27169;&#22411;&#31867;&#20284;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Restricted Boltzmann machines are energy models made of a visible and a hidden layer. We identify an effective energy function describing the zero-temperature landscape on the visible units and depending only on the tail behaviour of the hidden layer prior distribution. Studying the location of the local minima of such an energy function, we show that the ability of a restricted Boltzmann machine to reconstruct a random pattern depends indeed only on the tail of the hidden prior distribution. We find that hidden priors with strictly super-Gaussian tails give only a logarithmic loss in pattern retrieval, while an efficient retrieval is much harder with hidden units with strictly sub-Gaussian tails; if the hidden prior has Gaussian tails, the retrieval capability is determined by the number of hidden units (as in the Hopfield model).
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#31070;&#32463;&#31243;&#24207;&#32508;&#21512;&#26041;&#27861;&#22312;&#32452;&#21512;&#27867;&#21270;&#21644;&#20998;&#35299;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#22871;&#22522;&#20934;&#20219;&#21153;&#26469;&#35780;&#20272;&#36825;&#20123;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2204.03758</link><description>&lt;p&gt;
&#22312;&#31070;&#32463;&#31243;&#24207;&#32508;&#21512;&#20013;&#30340;&#32452;&#21512;&#27867;&#21270;&#21644;&#20998;&#35299;
&lt;/p&gt;
&lt;p&gt;
Compositional Generalization and Decomposition in Neural Program Synthesis. (arXiv:2204.03758v1 [cs.LG] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.03758
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#31070;&#32463;&#31243;&#24207;&#32508;&#21512;&#26041;&#27861;&#22312;&#32452;&#21512;&#27867;&#21270;&#21644;&#20998;&#35299;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#22871;&#22522;&#20934;&#20219;&#21153;&#26469;&#35780;&#20272;&#36825;&#20123;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#20154;&#20204;&#32534;&#20889;&#31243;&#24207;&#26102;&#65292;&#20182;&#20204;&#26377;&#33021;&#21147;&#36890;&#36807;&#23558;&#22797;&#26434;&#30340;&#20219;&#21153;&#20998;&#35299;&#20026;&#26356;&#23567;&#12289;&#26356;&#29087;&#24713;&#30340;&#23376;&#20219;&#21153;&#26469;&#35299;&#20915;&#12290;&#34429;&#28982;&#27979;&#37327;&#31070;&#32463;&#31243;&#24207;&#32508;&#21512;&#26041;&#27861;&#26159;&#21542;&#20855;&#26377;&#31867;&#20284;&#30340;&#33021;&#21147;&#26159;&#22256;&#38590;&#30340;&#65292;&#20294;&#25105;&#20204;&#21487;&#20197;&#27979;&#37327;&#30340;&#26159;&#23427;&#20204;&#26159;&#21542;&#21487;&#20197;&#20197;&#32452;&#21512;&#26041;&#24335;&#27867;&#21270;&#65292;&#21363;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#24050;&#32463;&#35757;&#32451;&#36807;&#31616;&#21333;&#23376;&#20219;&#21153;&#30340;&#27169;&#22411;&#26159;&#21542;&#33021;&#22815;&#35299;&#20915;&#26356;&#22797;&#26434;&#30340;&#20219;&#21153;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30528;&#37325;&#27979;&#37327;&#20102;&#23398;&#20064;&#30340;&#31243;&#24207;&#32508;&#21512;&#22120;&#20197;&#32452;&#21512;&#27867;&#21270;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#39318;&#20808;&#21051;&#30011;&#20102;&#31243;&#24207;&#32508;&#21512;&#26041;&#27861;&#24212;&#35813;&#20197;&#19981;&#21516;&#36724;&#26354;&#32447;&#27867;&#21270;&#65292;&#20363;&#22914;&#38271;&#24230;&#27867;&#21270;&#65292;&#25110;&#32773;&#32467;&#21512;&#22312;&#35757;&#32451;&#25968;&#25454;&#20013;&#19981;&#23384;&#22312;&#30340;&#26032;&#26041;&#27861;&#32452;&#21512;&#24050;&#30693;&#23376;&#20363;&#31243;&#30340;&#33021;&#21147;&#12290;&#26681;&#25454;&#36825;&#19968;&#21051;&#30011;&#65292;&#25105;&#20204;&#26681;&#25454;&#20004;&#20010;&#27969;&#34892;&#30340;&#29616;&#26377;&#25968;&#25454;&#38598;SCAN&#21644;RobustFill&#24341;&#20837;&#20102;&#19968;&#22871;&#20219;&#21153;&#22522;&#20934;&#26469;&#35780;&#20272;&#36825;&#20123;&#33021;&#21147;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#39318;&#27425;&#23581;&#35797;&#25913;&#36827;&#32452;&#21512;&#27867;&#21270;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
When writing programs, people have the ability to tackle a new complex task by decomposing it into smaller and more familiar subtasks. While it is difficult to measure whether neural program synthesis methods have similar capabilities, what we can measure is whether they compositionally generalize, that is, whether a model that has been trained on the simpler subtasks is subsequently able to solve more complex tasks. In this paper, we focus on measuring the ability of learned program synthesizers to compositionally generalize. We first characterize several different axes along which program synthesis methods would be desired to generalize, e.g., length generalization, or the ability to combine known subroutines in new ways that do not occur in the training data. Based on this characterization, we introduce a benchmark suite of tasks to assess these abilities based on two popular existing datasets, SCAN and RobustFill. Finally, we make first attempts to improve the compositional general
&lt;/p&gt;</description></item><item><title>CrossBeam&#26159;&#19968;&#31181;&#22312;&#33258;&#24213;&#21521;&#19978;&#31243;&#24207;&#21512;&#25104;&#20013;&#23398;&#20064;&#25628;&#32034;&#31574;&#30053;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35757;&#32451;&#31070;&#32463;&#27169;&#22411;&#26469;&#36873;&#25321;&#22914;&#20309;&#21512;&#24182;&#20808;&#21069;&#25506;&#32034;&#30340;&#31243;&#24207;&#65292;&#20197;&#25511;&#21046;&#25628;&#32034;&#31354;&#38388;&#30340;&#33192;&#32960;&#12290;</title><link>http://arxiv.org/abs/2203.10452</link><description>&lt;p&gt;
CrossBeam: &#22312;&#33258;&#24213;&#21521;&#19978;&#31243;&#24207;&#21512;&#25104;&#20013;&#23398;&#20064;&#25628;&#32034;
&lt;/p&gt;
&lt;p&gt;
CrossBeam: Learning to Search in Bottom-Up Program Synthesis. (arXiv:2203.10452v1 [cs.LG] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.10452
&lt;/p&gt;
&lt;p&gt;
CrossBeam&#26159;&#19968;&#31181;&#22312;&#33258;&#24213;&#21521;&#19978;&#31243;&#24207;&#21512;&#25104;&#20013;&#23398;&#20064;&#25628;&#32034;&#31574;&#30053;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35757;&#32451;&#31070;&#32463;&#27169;&#22411;&#26469;&#36873;&#25321;&#22914;&#20309;&#21512;&#24182;&#20808;&#21069;&#25506;&#32034;&#30340;&#31243;&#24207;&#65292;&#20197;&#25511;&#21046;&#25628;&#32034;&#31354;&#38388;&#30340;&#33192;&#32960;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#31243;&#24207;&#21512;&#25104;&#26041;&#27861;&#22312;&#24222;&#22823;&#30340;&#31243;&#24207;&#31354;&#38388;&#20013;&#36827;&#34892;&#25628;&#32034;&#65292;&#20197;&#25214;&#21040;&#28385;&#36275;&#32473;&#23450;&#35268;&#33539;&#30340;&#31243;&#24207;&#12290;&#20808;&#21069;&#30340;&#24037;&#20316;&#20351;&#29992;&#31070;&#32463;&#27169;&#22411;&#26469;&#25351;&#23548;&#32452;&#21512;&#25628;&#32034;&#31639;&#27861;&#65292;&#20294;&#26159;&#36825;&#26679;&#30340;&#26041;&#27861;&#20173;&#28982;&#25506;&#32034;&#20102;&#25628;&#32034;&#31354;&#38388;&#30340;&#24456;&#22823;&#37096;&#20998;&#65292;&#24182;&#19988;&#38543;&#30528;&#25152;&#38656;&#31243;&#24207;&#30340;&#22823;&#23567;&#22686;&#21152;&#65292;&#24456;&#24555;&#21464;&#24471;&#38590;&#20197;&#22788;&#29702;&#12290;&#20026;&#20102;&#25511;&#21046;&#25628;&#32034;&#31354;&#38388;&#30340;&#33192;&#32960;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35757;&#32451;&#31070;&#32463;&#27169;&#22411;&#26469;&#23398;&#20064;&#33258;&#24213;&#21521;&#19978;&#21512;&#25104;&#20013;&#30340;&#25628;&#32034;&#31574;&#30053;&#30340;&#26041;&#27861;&#65292;&#32780;&#19981;&#26159;&#20381;&#36182;&#20110;&#32452;&#21512;&#25628;&#32034;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#31216;&#20026;CrossBeam&#65292;&#20351;&#29992;&#31070;&#32463;&#27169;&#22411;&#26469;&#36873;&#25321;&#22914;&#20309;&#23558;&#20808;&#21069;&#25506;&#32034;&#30340;&#31243;&#24207;&#32452;&#21512;&#25104;&#26032;&#30340;&#31243;&#24207;&#65292;&#32771;&#34385;&#21040;&#25628;&#32034;&#21382;&#21490;&#21644;&#37096;&#20998;&#31243;&#24207;&#30340;&#25191;&#34892;&#12290;&#21463;&#32467;&#26500;&#21270;&#39044;&#27979;&#20013;&#23398;&#20064;&#25628;&#32034;&#30340;&#30456;&#20851;&#24037;&#20316;&#30340;&#21551;&#21457;&#65292;CrossBeam&#22312;&#35757;&#32451;&#20219;&#21153;&#19978;&#20351;&#29992;&#20174;&#33258;&#24049;&#30340;&#33258;&#24213;&#21521;&#19978;&#25628;&#32034;&#20013;&#25552;&#21462;&#30340;&#25968;&#25454;&#26469;&#36827;&#34892;&#26377;&#31574;&#30053;&#30340;&#35757;&#32451;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#38750;&#24120;&#19981;&#21516;&#30340;&#39046;&#22495;&#65292;&#23383;&#31526;&#20018;&#25805;&#20316;&#21644;&#36923;&#36753;&#32534;&#31243;&#20013;&#35780;&#20272;&#20102;CrossBeam&#12290;
&lt;/p&gt;
&lt;p&gt;
Many approaches to program synthesis perform a search within an enormous space of programs to find one that satisfies a given specification. Prior works have used neural models to guide combinatorial search algorithms, but such approaches still explore a huge portion of the search space and quickly become intractable as the size of the desired program increases. To tame the search space blowup, we propose training a neural model to learn a hands-on search policy for bottom-up synthesis, instead of relying on a combinatorial search algorithm. Our approach, called CrossBeam, uses the neural model to choose how to combine previously-explored programs into new programs, taking into account the search history and partial program executions. Motivated by work in structured prediction on learning to search, CrossBeam is trained on-policy using data extracted from its own bottom-up searches on training tasks. We evaluate CrossBeam in two very different domains, string manipulation and logic pr
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;$\phi$-&#31163;&#25955;&#24230;&#30340;&#20998;&#24067;&#40065;&#26834;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2203.02128</link><description>&lt;p&gt;
&#22522;&#20110;$\phi$-&#31163;&#25955;&#24230;&#30340;&#20998;&#24067;&#40065;&#26834;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Distributionally Robust Bayesian Optimization with $\phi$-divergences. (arXiv:2203.02128v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.02128
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;$\phi$-&#31163;&#25955;&#24230;&#30340;&#20998;&#24067;&#40065;&#26834;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#40065;&#26834;&#24615;&#30740;&#31350;&#22240;&#20854;&#22312;&#38754;&#23545;&#19981;&#30830;&#23450;&#24615;&#30340;&#35768;&#22810;&#31995;&#32479;&#20013;&#19981;&#21487;&#36991;&#20813;&#32780;&#21463;&#21040;&#24191;&#27867;&#20851;&#27880;&#12290;&#20854;&#20013;&#19968;&#20010;&#20363;&#23376;&#26159;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#23427;&#38754;&#20020;&#30528;&#22810;&#26041;&#38754;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#20294;&#20165;&#26377;&#23569;&#37327;&#30340;&#30740;&#31350;&#33268;&#21147;&#20110;&#36825;&#20010;&#26041;&#21521;&#12290;&#22312;&#29616;&#26377;&#30740;&#31350;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;$\phi$-&#31163;&#25955;&#24230;&#30340;&#20998;&#24067;&#40065;&#26834;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The study of robustness has received much attention due to its inevitability in data-driven settings where many systems face uncertainty. One such example of concern is Bayesian Optimization (BO), where uncertainty is multi-faceted, yet there only exists a limited number of works dedicated to this direction. In particular, there is the work of Kirschner et al. (2020), which bridges the existing literature of Distributionally Robust Optimization (DRO) by casting the BO problem from the lens of DRO. While this work is pioneering, it admittedly suffers from various practical shortcomings such as finite contexts assumptions, leaving behind the main question Can one devise a computationally tractable algorithm for solving this DRO-BO problem? In this work, we tackle this question to a large degree of generality by considering robustness against data-shift in $\phi$-divergences, which subsumes many popular choices, such as the $\chi^2$-divergence, Total Variation, and the extant Kullback-Lei
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22238;&#24402;&#31639;&#27861;LESS&#65292;&#36890;&#36807;&#29983;&#25104;&#20197;&#38543;&#26426;&#28857;&#20026;&#20013;&#24515;&#30340;&#23376;&#38598;&#24182;&#35757;&#32451;&#23616;&#37096;&#39044;&#27979;&#22120;&#65292;&#28982;&#21518;&#20197;&#26032;&#39062;&#30340;&#26041;&#24335;&#32452;&#21512;&#39044;&#27979;&#22120;&#24471;&#21040;&#25972;&#20307;&#39044;&#27979;&#22120;&#12290;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#27979;&#35797;&#34920;&#26126;&#65292;LESS&#26159;&#19968;&#31181;&#26377;&#31454;&#20105;&#21147;&#19988;&#39640;&#25928;&#30340;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2112.06251</link><description>&lt;p&gt;
&#23398;&#20064;&#19982;&#23376;&#38598;&#21472;&#21152;
&lt;/p&gt;
&lt;p&gt;
Learning with Subset Stacking. (arXiv:2112.06251v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.06251
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22238;&#24402;&#31639;&#27861;LESS&#65292;&#36890;&#36807;&#29983;&#25104;&#20197;&#38543;&#26426;&#28857;&#20026;&#20013;&#24515;&#30340;&#23376;&#38598;&#24182;&#35757;&#32451;&#23616;&#37096;&#39044;&#27979;&#22120;&#65292;&#28982;&#21518;&#20197;&#26032;&#39062;&#30340;&#26041;&#24335;&#32452;&#21512;&#39044;&#27979;&#22120;&#24471;&#21040;&#25972;&#20307;&#39044;&#27979;&#22120;&#12290;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#27979;&#35797;&#34920;&#26126;&#65292;LESS&#26159;&#19968;&#31181;&#26377;&#31454;&#20105;&#21147;&#19988;&#39640;&#25928;&#30340;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22238;&#24402;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20174;&#19968;&#32452;&#36755;&#20837;-&#36755;&#20986;&#23545;&#20013;&#36827;&#34892;&#23398;&#20064;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#36866;&#29992;&#20110;&#36755;&#20837;&#21464;&#37327;&#19982;&#36755;&#20986;&#21464;&#37327;&#20043;&#38388;&#30340;&#20851;&#31995;&#22312;&#39044;&#27979;&#31354;&#38388;&#20013;&#34920;&#29616;&#20986;&#24322;&#36136;&#34892;&#20026;&#30340;&#32676;&#20307;&#12290;&#35813;&#31639;&#27861;&#39318;&#20808;&#29983;&#25104;&#20197;&#36755;&#20837;&#31354;&#38388;&#20013;&#30340;&#38543;&#26426;&#28857;&#20026;&#20013;&#24515;&#30340;&#23376;&#38598;&#65292;&#28982;&#21518;&#20026;&#27599;&#20010;&#23376;&#38598;&#35757;&#32451;&#19968;&#20010;&#23616;&#37096;&#39044;&#27979;&#22120;&#12290;&#28982;&#21518;&#36825;&#20123;&#39044;&#27979;&#22120;&#20197;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#24335;&#32452;&#21512;&#22312;&#19968;&#36215;&#65292;&#24418;&#25104;&#19968;&#20010;&#25972;&#20307;&#39044;&#27979;&#22120;&#12290;&#25105;&#20204;&#23558;&#27492;&#31639;&#27861;&#31216;&#20026;&#8220;&#23398;&#20064;&#19982;&#23376;&#38598;&#21472;&#21152;&#8221;&#25110;LESS&#65292;&#22240;&#20026;&#23427;&#31867;&#20284;&#20110;&#21472;&#21152;&#22238;&#24402;&#22120;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#23558;LESS&#19982;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#36827;&#34892;&#27979;&#35797;&#24615;&#33021;&#27604;&#36739;&#12290;&#25105;&#20204;&#30340;&#27604;&#36739;&#32467;&#26524;&#34920;&#26126;&#65292;LESS&#26159;&#19968;&#31181;&#26377;&#31454;&#20105;&#21147;&#30340;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;LESS&#22312;&#35745;&#31639;&#26102;&#38388;&#19978;&#20063;&#38750;&#24120;&#39640;&#25928;&#65292;&#24182;&#19988;&#21487;&#20197;&#30452;&#25509;&#36827;&#34892;&#24182;&#34892;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new regression algorithm that learns from a set of input-output pairs. Our algorithm is designed for populations where the relation between the input variables and the output variable exhibits a heterogeneous behavior across the predictor space. The algorithm starts with generating subsets that are concentrated around random points in the input space. This is followed by training a local predictor for each subset. Those predictors are then combined in a novel way to yield an overall predictor. We call this algorithm ``LEarning with Subset Stacking'' or LESS, due to its resemblance to the method of stacking regressors. We compare the testing performance of LESS with state-of-the-art methods on several datasets. Our comparison shows that LESS is a competitive supervised learning method. Moreover, we observe that LESS is also efficient in terms of computation time and it allows a straightforward parallel implementation.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23637;&#31034;&#20102;&#19968;&#22823;&#31867;&#20855;&#26377;&#19968;&#33324;&#20998;&#21106;&#26041;&#21521;&#30340;&#38543;&#26426;&#26862;&#26519;&#33021;&#22815;&#22312;&#20219;&#24847;&#32500;&#24230;&#19978;&#23454;&#29616;&#26497;&#23567;&#26497;&#22823;&#30340;&#25910;&#25947;&#29575;&#65292;&#21253;&#25324;STIT&#26862;&#26519;&#21644;&#28304;&#33258;&#27850;&#26494;&#36229;&#24179;&#38754;&#38262;&#23884;&#30340;&#38543;&#26426;&#26862;&#26519;&#12290;</title><link>http://arxiv.org/abs/2109.10541</link><description>&lt;p&gt;
&#39640;&#32500;&#38543;&#26426;&#38262;&#23884;&#26862;&#26519;&#30340;&#26497;&#23567;&#26497;&#22823;&#29575;
&lt;/p&gt;
&lt;p&gt;
Minimax Rates for High-Dimensional Random Tessellation Forests. (arXiv:2109.10541v5 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.10541
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23637;&#31034;&#20102;&#19968;&#22823;&#31867;&#20855;&#26377;&#19968;&#33324;&#20998;&#21106;&#26041;&#21521;&#30340;&#38543;&#26426;&#26862;&#26519;&#33021;&#22815;&#22312;&#20219;&#24847;&#32500;&#24230;&#19978;&#23454;&#29616;&#26497;&#23567;&#26497;&#22823;&#30340;&#25910;&#25947;&#29575;&#65292;&#21253;&#25324;STIT&#26862;&#26519;&#21644;&#28304;&#33258;&#27850;&#26494;&#36229;&#24179;&#38754;&#38262;&#23884;&#30340;&#38543;&#26426;&#26862;&#26519;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#26862;&#26519;&#26159;&#19968;&#31181;&#24120;&#29992;&#20110;&#22238;&#24402;&#21644;&#20998;&#31867;&#30340;&#31639;&#27861;&#31867;&#12290;&#36825;&#20010;&#31639;&#27861;&#30001;Breiman&#20110;2001&#24180;&#24341;&#20837;&#65292;&#35768;&#22810;&#21464;&#20307;&#37117;&#26159;&#30001;&#29305;&#24449;&#31354;&#38388;&#30340;&#36724;&#23545;&#40784;&#21306;&#22495;&#21010;&#20998;&#26500;&#24314;&#30340;&#38543;&#26426;&#20915;&#31574;&#26641;&#30340;&#38598;&#21512;&#12290;&#20854;&#20013;&#19968;&#31181;&#21464;&#20307;&#31216;&#20026;Mondrian&#26862;&#26519;&#65292;&#29992;&#20110;&#22788;&#29702;&#22312;&#32447;&#35774;&#32622;&#65292;&#24182;&#19988;&#26159;&#31532;&#19968;&#20010;&#22312;&#20219;&#24847;&#32500;&#24230;&#19978;&#33719;&#24471;&#26368;&#23567;&#26497;&#22823;&#29575;&#30340;&#38543;&#26426;&#26862;&#26519;&#31867;&#21035;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#36724;&#23545;&#40784;&#20998;&#21106;&#30340;&#38480;&#21046;&#26080;&#27861;&#25429;&#25417;&#29305;&#24449;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#24182;&#19988;&#20351;&#29992;&#26012;&#20999;&#20998;&#21106;&#30340;&#38543;&#26426;&#26862;&#26519;&#22312;&#35768;&#22810;&#20219;&#21153;&#19978;&#26174;&#31034;&#20986;&#20102;&#25913;&#36827;&#30340;&#32463;&#39564;&#24615;&#33021;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#22823;&#31867;&#20855;&#26377;&#19968;&#33324;&#20998;&#21106;&#26041;&#21521;&#30340;&#38543;&#26426;&#26862;&#26519;&#20063;&#33021;&#22312;&#20219;&#24847;&#32500;&#24230;&#19978;&#23454;&#29616;&#26497;&#23567;&#26497;&#22823;&#25910;&#25947;&#29575;&#12290;&#36825;&#31867;&#38543;&#26426;&#26862;&#26519;&#21253;&#25324;STIT&#26862;&#26519;&#65292;&#23427;&#26159;Mondrian&#26862;&#26519;&#21040;&#20219;&#24847;&#20998;&#21106;&#26041;&#21521;&#30340;&#25512;&#24191;&#65292;&#20197;&#21450;&#28304;&#33258;&#27850;&#26494;&#36229;&#24179;&#38754;&#38262;&#23884;&#30340;&#38543;&#26426;&#26862;&#26519;&#12290;
&lt;/p&gt;
&lt;p&gt;
Random forests are a popular class of algorithms used for regression and classification. The algorithm introduced by Breiman in 2001 and many of its variants are ensembles of randomized decision trees built from axis-aligned partitions of the feature space. One such variant, called Mondrian forests, was proposed to handle the online setting and is the first class of random forests for which minimax rates were obtained in arbitrary dimension. However, the restriction to axis-aligned splits fails to capture dependencies between features, and random forests that use oblique splits have shown improved empirical performance for many tasks. In this work, we show that a large class of random forests with general split directions also achieve minimax optimal convergence rates in arbitrary dimension. This class includes STIT forests, a generalization of Mondrian forests to arbitrary split directions, as well as random forests derived from Poisson hyperplane tessellations. These are the first re
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#36830;&#32493;&#26465;&#20214;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;CcGAN&#65289;&#65292;&#39318;&#20010;&#29992;&#20110;&#22522;&#20110;&#36830;&#32493;&#26631;&#37327;&#26465;&#20214;&#30340;&#22270;&#20687;&#29983;&#25104;&#30340;&#29983;&#25104;&#27169;&#22411;&#12290;&#36890;&#36807;&#37325;&#26032;&#26500;&#24314;&#32463;&#39564;cGAN&#25439;&#22833;&#21644;&#25552;&#20986;&#26032;&#30340;&#26631;&#31614;&#36755;&#20837;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#22312;&#22238;&#24402;&#26631;&#31614;&#26465;&#20214;&#29983;&#25104;&#20013;&#23384;&#22312;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2011.07466</link><description>&lt;p&gt;
&#36830;&#32493;&#26465;&#20214;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65306;&#21019;&#26032;&#30340;&#32463;&#39564;&#25439;&#22833;&#21644;&#26631;&#31614;&#36755;&#20837;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
Continuous Conditional Generative Adversarial Networks: Novel Empirical Losses and Label Input Mechanisms. (arXiv:2011.07466v9 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2011.07466
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#36830;&#32493;&#26465;&#20214;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;CcGAN&#65289;&#65292;&#39318;&#20010;&#29992;&#20110;&#22522;&#20110;&#36830;&#32493;&#26631;&#37327;&#26465;&#20214;&#30340;&#22270;&#20687;&#29983;&#25104;&#30340;&#29983;&#25104;&#27169;&#22411;&#12290;&#36890;&#36807;&#37325;&#26032;&#26500;&#24314;&#32463;&#39564;cGAN&#25439;&#22833;&#21644;&#25552;&#20986;&#26032;&#30340;&#26631;&#31614;&#36755;&#20837;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#22312;&#22238;&#24402;&#26631;&#31614;&#26465;&#20214;&#29983;&#25104;&#20013;&#23384;&#22312;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#36830;&#32493;&#26465;&#20214;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;CcGAN&#65289;&#65292;&#36825;&#26159;&#39318;&#20010;&#29992;&#20110;&#22522;&#20110;&#36830;&#32493;&#26631;&#37327;&#26465;&#20214;&#65288;&#31216;&#20026;&#22238;&#24402;&#26631;&#31614;&#65289;&#30340;&#22270;&#20687;&#29983;&#25104;&#30340;&#29983;&#25104;&#27169;&#22411;&#12290;&#29616;&#26377;&#30340;&#26465;&#20214;GAN&#65288;cGAN&#65289;&#20027;&#35201;&#35774;&#35745;&#29992;&#20110;&#20998;&#31867;&#26465;&#20214;&#65288;&#20363;&#22914;&#31867;&#26631;&#31614;&#65289;&#65307;&#23545;&#20110;&#22238;&#24402;&#26631;&#31614;&#30340;&#26465;&#20214;&#29983;&#25104;&#21017;&#22312;&#25968;&#23398;&#19978;&#26377;&#25152;&#19981;&#21516;&#65292;&#24341;&#21457;&#20102;&#20004;&#20010;&#22522;&#26412;&#38382;&#39064;&#65306;&#65288;P1&#65289;&#30001;&#20110;&#26576;&#20123;&#22238;&#24402;&#26631;&#31614;&#21487;&#33021;&#27809;&#26377;&#30495;&#23454;&#22270;&#20687;&#65292;&#26368;&#23567;&#21270;&#29616;&#26377;&#30340;&#32463;&#39564;cGAN&#25439;&#22833;&#65288;&#20063;&#31216;&#20026;&#32463;&#39564;cGAN&#25439;&#22833;&#65289;&#22312;&#23454;&#36341;&#20013;&#36890;&#24120;&#19981;&#36215;&#20316;&#29992;&#65307;&#65288;P2&#65289;&#30001;&#20110;&#22238;&#24402;&#26631;&#31614;&#26159;&#36830;&#32493;&#30340;&#19988;&#26080;&#38480;&#22810;&#65292;&#20256;&#32479;&#30340;&#26631;&#31614;&#36755;&#20837;&#26041;&#27861;&#19981;&#36866;&#29992;&#12290;&#25152;&#25552;&#20986;&#30340;CcGAN&#36890;&#36807;&#20998;&#21035;&#65288;S1&#65289;&#37325;&#26032;&#26500;&#24314;&#29616;&#26377;&#30340;&#32463;&#39564;cGAN&#25439;&#22833;&#20197;&#36866;&#24212;&#36830;&#32493;&#22330;&#26223;&#65307;&#20197;&#21450;&#65288;S2&#65289;&#25552;&#20986;&#19968;&#31181;&#31616;&#21333;&#30340;&#26631;&#31614;&#36755;&#20837;&#65288;NLI&#65289;&#26041;&#27861;&#21644;&#19968;&#31181;&#25913;&#36827;&#30340;&#26631;&#31614;&#36755;&#20837;&#65288;ILI&#65289;&#26041;&#27861;&#23558;&#22238;&#24402;&#26631;&#31614;&#34701;&#20837;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#19978;&#36848;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work proposes the continuous conditional generative adversarial network (CcGAN), the first generative model for image generation conditional on continuous, scalar conditions (termed regression labels). Existing conditional GANs (cGANs) are mainly designed for categorical conditions (eg, class labels); conditioning on regression labels is mathematically distinct and raises two fundamental problems:(P1) Since there may be very few (even zero) real images for some regression labels, minimizing existing empirical versions of cGAN losses (aka empirical cGAN losses) often fails in practice;(P2) Since regression labels are scalar and infinitely many, conventional label input methods are not applicable. The proposed CcGAN solves the above problems, respectively, by (S1) reformulating existing empirical cGAN losses to be appropriate for the continuous scenario; and (S2) proposing a naive label input (NLI) method and an improved label input (ILI) method to incorporate regression labels into
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27880;&#24847;&#21147;&#22870;&#21169;&#30340;&#26463;&#25628;&#32034;&#35299;&#30721;&#31574;&#30053;&#65292;&#29992;&#20110;&#35299;&#20915;&#31070;&#32463;&#20851;&#38190;&#35789;&#29983;&#25104;&#20013;&#30340;&#24207;&#21015;&#38271;&#24230;&#20559;&#24046;&#21644;&#26463;&#22810;&#26679;&#24615;&#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#26174;&#33879;&#25552;&#39640;&#20102;&#29983;&#25104;&#20851;&#38190;&#35789;&#30340;&#35299;&#30721;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/1909.09485</link><description>&lt;p&gt;
BSDAR: &#22522;&#20110;&#27880;&#24847;&#21147;&#22870;&#21169;&#30340;&#31070;&#32463;&#20851;&#38190;&#35789;&#29983;&#25104;&#20013;&#30340;&#26463;&#25628;&#32034;&#35299;&#30721;
&lt;/p&gt;
&lt;p&gt;
BSDAR: Beam Search Decoding with Attention Reward in Neural Keyphrase Generation. (arXiv:1909.09485v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1909.09485
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27880;&#24847;&#21147;&#22870;&#21169;&#30340;&#26463;&#25628;&#32034;&#35299;&#30721;&#31574;&#30053;&#65292;&#29992;&#20110;&#35299;&#20915;&#31070;&#32463;&#20851;&#38190;&#35789;&#29983;&#25104;&#20013;&#30340;&#24207;&#21015;&#38271;&#24230;&#20559;&#24046;&#21644;&#26463;&#22810;&#26679;&#24615;&#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#26174;&#33879;&#25552;&#39640;&#20102;&#29983;&#25104;&#20851;&#38190;&#35789;&#30340;&#35299;&#30721;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20027;&#35201;&#30740;&#31350;&#31070;&#32463;&#20851;&#38190;&#35789;&#29983;&#25104;&#20013;&#30340;&#20004;&#20010;&#24120;&#35265;&#35299;&#30721;&#38382;&#39064;&#65306;&#24207;&#21015;&#38271;&#24230;&#20559;&#24046;&#21644;&#26463;&#22810;&#26679;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#35789;&#32423;&#21644;ngram&#32423;&#22870;&#21169;&#20989;&#25968;&#30340;&#26463;&#25628;&#32034;&#35299;&#30721;&#31574;&#30053;&#65292;&#20197;&#22312;&#27979;&#35797;&#26102;&#32422;&#26463;&#21644;&#20248;&#21270;Seq2Seq&#25512;&#29702;&#36807;&#31243;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#31616;&#21333;&#30340;&#25552;&#26696;&#21487;&#20197;&#20811;&#26381;&#31639;&#27861;&#23545;&#36739;&#30701;&#21644;&#20960;&#20046;&#30456;&#21516;&#30340;&#24207;&#21015;&#30340;&#20559;&#22909;&#65292;&#20174;&#32780;&#26174;&#33879;&#25552;&#39640;&#29983;&#25104;&#28304;&#25991;&#26412;&#20013;&#23384;&#22312;&#21644;&#19981;&#23384;&#22312;&#30340;&#20851;&#38190;&#35789;&#30340;&#35299;&#30721;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study mainly investigates two common decoding problems in neural keyphrase generation: sequence length bias and beam diversity. To tackle the problems, we introduce a beam search decoding strategy based on word-level and ngram-level reward function to constrain and refine Seq2Seq inference at test time. Results show that our simple proposal can overcome the algorithm bias to shorter and nearly identical sequences, resulting in a significant improvement of the decoding performance on generating keyphrases that are present and absent in source text.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;18&#31181;&#26032;&#30340;&#23545;&#25239;&#25915;&#20987;&#65292;&#24182;&#20351;&#29992;&#36825;&#20123;&#25915;&#20987;&#21019;&#24314;&#20102;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;&#23545;&#21508;&#31181;&#26410;&#39044;&#26009;&#21040;&#30340;&#23545;&#25163;&#30340;&#40065;&#26834;&#24615;&#30340;&#26032;&#22522;&#20934;&#12290;&#20316;&#32773;&#36824;&#21457;&#29616;&#20102;&#19968;&#31995;&#21015;&#38450;&#24481;&#31574;&#30053;&#65292;&#21487;&#20197;&#24110;&#21161;&#20811;&#26381;&#35757;&#32451;&#26399;&#38388;&#26410;&#32771;&#34385;&#21040;&#30340;&#23545;&#25163;&#30340;&#27867;&#21270;&#24046;&#36317;&#12290;&#35813;&#30740;&#31350;&#30340;&#32467;&#26524;&#23558;&#20026;&#30740;&#31350;&#29616;&#23454;&#19990;&#30028;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#40065;&#26834;&#24615;&#25552;&#20379;&#26377;&#29992;&#24037;&#20855;&#65292;&#20419;&#36827;&#24320;&#21457;&#26356;&#24378;&#22823;&#30340;&#38450;&#24481;&#25514;&#26045;&#12290;</title><link>http://arxiv.org/abs/1908.08016</link><description>&lt;p&gt;
&#38024;&#23545;&#26410;&#39044;&#26009;&#21040;&#30340;&#23545;&#25163;&#27979;&#35797;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Testing Robustness Against Unforeseen Adversaries. (arXiv:1908.08016v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1908.08016
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;18&#31181;&#26032;&#30340;&#23545;&#25239;&#25915;&#20987;&#65292;&#24182;&#20351;&#29992;&#36825;&#20123;&#25915;&#20987;&#21019;&#24314;&#20102;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;&#23545;&#21508;&#31181;&#26410;&#39044;&#26009;&#21040;&#30340;&#23545;&#25163;&#30340;&#40065;&#26834;&#24615;&#30340;&#26032;&#22522;&#20934;&#12290;&#20316;&#32773;&#36824;&#21457;&#29616;&#20102;&#19968;&#31995;&#21015;&#38450;&#24481;&#31574;&#30053;&#65292;&#21487;&#20197;&#24110;&#21161;&#20811;&#26381;&#35757;&#32451;&#26399;&#38388;&#26410;&#32771;&#34385;&#21040;&#30340;&#23545;&#25163;&#30340;&#27867;&#21270;&#24046;&#36317;&#12290;&#35813;&#30740;&#31350;&#30340;&#32467;&#26524;&#23558;&#20026;&#30740;&#31350;&#29616;&#23454;&#19990;&#30028;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#40065;&#26834;&#24615;&#25552;&#20379;&#26377;&#29992;&#24037;&#20855;&#65292;&#20419;&#36827;&#24320;&#21457;&#26356;&#24378;&#22823;&#30340;&#38450;&#24481;&#25514;&#26045;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32771;&#34385;&#29616;&#23454;&#19990;&#30028;&#30340;&#23545;&#25239;&#29615;&#22659;&#26102;&#65292;&#38450;&#24481;&#32773;&#22312;&#35757;&#32451;&#26399;&#38388;&#19981;&#22826;&#21487;&#33021;&#23545;&#25152;&#26377;&#21487;&#33021;&#30340;&#23545;&#25163;&#36827;&#34892;&#35757;&#32451;&#65292;&#24182;&#19988;&#23545;&#25163;&#24456;&#21487;&#33021;&#20351;&#29992;&#36924;&#30495;&#30340;&#23545;&#25239;&#25197;&#26354;&#65292;&#32780;&#19981;&#38480;&#20110;&#23567;&#30340;L_p&#32422;&#26463;&#25200;&#21160;&#12290;&#20026;&#20102;&#32553;&#23567;&#30740;&#31350;&#21644;&#29616;&#23454;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;18&#31181;&#26032;&#30340;&#23545;&#25239;&#25915;&#20987;&#65292;&#24182;&#20351;&#29992;&#23427;&#20204;&#21019;&#24314;&#20102;ImageNet-UA&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;&#27169;&#22411;&#23545;&#21508;&#31181;&#26410;&#39044;&#26009;&#21040;&#30340;&#23545;&#25163;&#30340;&#40065;&#26834;&#24615;&#30340;&#26032;&#22522;&#20934;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#20010;&#22522;&#20934;&#26469;&#35782;&#21035;&#19968;&#31995;&#21015;&#33021;&#22815;&#24110;&#21161;&#20811;&#26381;&#36825;&#31181;&#27867;&#21270;&#24046;&#36317;&#30340;&#38450;&#24481;&#31574;&#30053;&#65292;&#21457;&#29616;&#20102;&#21487;&#20197;&#25552;&#39640;&#23545;&#26410;&#39044;&#26009;&#21040;&#30340;&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#30340;&#25216;&#26415;&#30340;&#20016;&#23500;&#31354;&#38388;&#12290;&#25105;&#20204;&#24076;&#26395;ImageNet-UA&#30340;&#26356;&#22810;&#26679;&#24615;&#21644;&#36924;&#30495;&#24615;&#23558;&#25104;&#20026;&#37027;&#20123;&#30740;&#31350;&#29616;&#23454;&#19990;&#30028;&#26368;&#22351;&#24773;&#20917;&#30340;&#40065;&#26834;&#24615;&#30340;&#20154;&#30340;&#26377;&#29992;&#24037;&#20855;&#65292;&#20174;&#32780;&#20419;&#36827;&#24320;&#21457;&#33021;&#22815;&#22312;&#35757;&#32451;&#26399;&#38388;&#30475;&#19981;&#21040;&#30340;&#25915;&#20987;&#20013;&#36827;&#34892;&#27867;&#21270;&#30340;&#26356;&#24378;&#22823;&#30340;&#38450;&#24481;&#25514;&#26045;&#12290;
&lt;/p&gt;
&lt;p&gt;
When considering real-world adversarial settings, defenders are unlikely to have access to the full range of deployment-time adversaries during training, and adversaries are likely to use realistic adversarial distortions that will not be limited to small L_p-constrained perturbations. To narrow in on this discrepancy between research and reality we introduce eighteen novel adversarial attacks, which we use to create ImageNet-UA, a new benchmark for evaluating model robustness against a wide range of unforeseen adversaries. We make use of our benchmark to identify a range of defense strategies which can help overcome this generalization gap, finding a rich space of techniques which can improve unforeseen robustness. We hope the greater variety and realism of ImageNet-UA will make it a useful tool for those working on real-world worst-case robustness, enabling development of more robust defenses which can generalize beyond attacks seen during training.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#24102;&#26377;&#25197;&#26354;&#27010;&#29575;&#30340;&#38543;&#26426;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20197;UCB&#31639;&#27861;&#20026;&#22522;&#30784;&#12289;&#32771;&#34385;&#20102;&#22870;&#21169;&#25197;&#26354;&#24182;&#20855;&#26377;&#27425;&#32447;&#24615;&#21518;&#24724;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/1611.10283</link><description>&lt;p&gt;
&#21152;&#26435;&#36172;&#21338;&#26426;&#25110;&#32773;&#65306;&#36172;&#21338;&#26426;&#22914;&#20309;&#23398;&#20064;&#39044;&#26399;&#20043;&#22806;&#30340;&#25197;&#26354;&#20215;&#20540;
&lt;/p&gt;
&lt;p&gt;
Weighted bandits or: How bandits learn distorted values that are not expected. (arXiv:1611.10283v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1611.10283
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#24102;&#26377;&#25197;&#26354;&#27010;&#29575;&#30340;&#38543;&#26426;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20197;UCB&#31639;&#27861;&#20026;&#22522;&#30784;&#12289;&#32771;&#34385;&#20102;&#22870;&#21169;&#25197;&#26354;&#24182;&#20855;&#26377;&#27425;&#32447;&#24615;&#21518;&#24724;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#21040;&#29992;&#20110;&#35299;&#37322;&#24120;&#35265;&#20559;&#31163;&#20256;&#32479;&#39044;&#26399;&#20215;&#20540;&#20559;&#22909;&#30340;&#20154;&#31867;&#20915;&#31574;&#27169;&#22411;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#20010;&#24102;&#26377;&#25197;&#26354;&#27010;&#29575;&#30340;&#38543;&#26426;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65306;&#32463;&#20856;&#30340;K&#33218;&#36172;&#21338;&#26426;&#21644;&#32447;&#24615;&#21442;&#25968;&#21270;&#36172;&#21338;&#26426;&#35774;&#32622;&#12290;&#25105;&#20204;&#22312;&#23545;&#22810;&#33218;&#36172;&#21338;&#26426;&#30340;&#21518;&#24724;&#26368;&#23567;&#21270;&#21644;&#26368;&#20339;&#33218;&#35782;&#21035;&#26694;&#26550;&#19979;&#30740;&#31350;&#20102;&#19978;&#36848;&#38382;&#39064;&#12290;&#23545;&#20110;K&#33218;&#36172;&#21338;&#26426;&#20197;&#21450;&#32447;&#24615;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#21518;&#24724;&#26368;&#23567;&#21270;&#35774;&#32622;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21463;&#21040;&#19978;&#32622;&#20449;&#30028;(UCB)&#31639;&#27861;&#21551;&#21457;&#12289;&#21253;&#21547;&#22870;&#21169;&#25197;&#26354;&#24182;&#19988;&#20855;&#26377;&#27425;&#32447;&#24615;&#21518;&#24724;&#30340;&#31639;&#27861;&#12290;&#23545;&#20110;K&#33218;&#36172;&#21338;&#26426;&#35774;&#32622;&#65292;&#25105;&#20204;&#24471;&#20986;&#20102;&#23545;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#30340;&#39044;&#26399;&#21518;&#24724;&#30340;&#19978;&#30028;&#65292;&#28982;&#21518;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;&#21305;&#37197;&#30340;&#19979;&#30028;&#65292;&#20197;&#39564;&#35777;&#25105;&#20204;&#31639;&#27861;&#30340;&#27425;&#32447;&#24615;&#20248;&#21270;&#39034;&#24207;&#12290;&#23545;&#20110;&#32447;&#24615;&#21442;&#25968;&#21270;&#35774;&#32622;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#23454;&#29616;&#20102;&#19968;&#20010;&#21518;&#24724;&#19978;&#30028;&#65292;&#35813;&#19978;&#30028;&#26159;&#27425;&#32447;&#24615;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by models of human decision making proposed to explain commonly observed deviations from conventional expected value preferences, we formulate two stochastic multi-armed bandit problems with distorted probabilities on the reward distributions: the classic $K$-armed bandit and the linearly parameterized bandit settings. We consider the aforementioned problems in the regret minimization as well as best arm identification framework for multi-armed bandits. For the regret minimization setting in $K$-armed as well as linear bandit problems, we propose algorithms that are inspired by Upper Confidence Bound (UCB) algorithms, incorporate reward distortions, and exhibit sublinear regret. For the $K$-armed bandit setting, we derive an upper bound on the expected regret for our proposed algorithm, and then we prove a matching lower bound to establish the order-optimality of our algorithm. For the linearly parameterized setting, our algorithm achieves a regret upper bound that is of the 
&lt;/p&gt;</description></item></channel></rss>