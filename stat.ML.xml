<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25915;&#20987;&#26041;&#27861;&#65292;&#20854;&#20013;&#23545;&#25163;&#27450;&#39575;&#24615;&#22320;&#36951;&#28431;&#20102;&#37096;&#20998;&#30495;&#23454;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#20197;&#20559;&#21521;&#25152;&#38656;&#30340;&#26041;&#24335;&#26469;&#24433;&#21709;&#23398;&#20064;&#21040;&#30340;&#22240;&#26524;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2305.20043</link><description>&lt;p&gt;
&#36951;&#28431;&#27450;&#39575;&#65306;&#20351;&#29992;&#23545;&#25239;&#24615;&#32570;&#22833;&#26469;&#27745;&#26579;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Deception by Omission: Using Adversarial Missingness to Poison Causal Structure Learning. (arXiv:2305.20043v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.20043
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25915;&#20987;&#26041;&#27861;&#65292;&#20854;&#20013;&#23545;&#25163;&#27450;&#39575;&#24615;&#22320;&#36951;&#28431;&#20102;&#37096;&#20998;&#30495;&#23454;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#20197;&#20559;&#21521;&#25152;&#38656;&#30340;&#26041;&#24335;&#26469;&#24433;&#21709;&#23398;&#20064;&#21040;&#30340;&#22240;&#26524;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#35266;&#27979;&#25968;&#25454;&#25512;&#26029;&#22240;&#26524;&#32467;&#26500;&#26159;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#65307;&#22312;&#23454;&#36341;&#20013;&#65292;&#36825;&#20123;&#25968;&#25454;&#21487;&#33021;&#23384;&#22312;&#19981;&#23436;&#20840;&#35266;&#27979;&#30340;&#38382;&#39064;&#12290;&#27492;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#35777;&#26126;&#65292;&#23545;&#23436;&#20840;&#35266;&#27979;&#30340;&#35757;&#32451;&#25968;&#25454;&#36827;&#34892;&#23545;&#25239;&#24615;&#25200;&#21160;&#21487;&#33021;&#20250;&#23548;&#33268;&#23398;&#20064;&#21040;&#30340;&#22240;&#26524;&#32467;&#26500;&#27169;&#22411;&#65288;SCMs&#65289;&#19981;&#20934;&#30830;&#12290;&#28982;&#32780;&#65292;&#24403;&#25968;&#25454;&#21487;&#20197;&#36827;&#34892;&#27491;&#30830;&#24615;&#23457;&#35745;&#26102;&#65288;&#20363;&#22914;&#65292;&#23427;&#26159;&#30001;&#20854;&#28304;&#21152;&#23494;&#31614;&#21517;&#30340;&#65289;&#65292;&#36825;&#31181;&#23545;&#25239;&#24615;&#26426;&#21046;&#23601;&#20250;&#34987;&#39539;&#22238;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#25915;&#20987;&#26041;&#27861;&#65292;&#20854;&#20013;&#23545;&#25163;&#27450;&#39575;&#24615;&#22320;&#36951;&#28431;&#20102;&#37096;&#20998;&#30495;&#23454;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#20197;&#20559;&#21521;&#25152;&#38656;&#30340;&#26041;&#24335;&#26469;&#24433;&#21709;&#23398;&#20064;&#21040;&#30340;&#22240;&#26524;&#32467;&#26500;&#12290;&#38024;&#23545;&#20219;&#24847;SCMs&#30340;&#25915;&#20987;&#26426;&#21046;&#34987;&#29702;&#35770;&#19978;&#35777;&#26126;&#26159;&#26377;&#29992;&#30340;&#65292;&#23545;&#20110;&#39640;&#26031;SCMs&#65292;&#35813;&#25991;&#36824;&#32473;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#22522;&#20110;&#23398;&#20064;&#30340;&#21551;&#21457;&#24335;&#26041;&#27861;&#12290;&#22312;&#30495;&#23454;&#21644;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#39564;&#35777;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#32570;&#22833;&#25915;&#20987;&#23545;&#27450;&#39575;&#27969;&#34892;&#30340;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Inference of causal structures from observational data is a key component of causal machine learning; in practice, this data may be incompletely observed. Prior work has demonstrated that adversarial perturbations of completely observed training data may be used to force the learning of inaccurate causal structural models (SCMs). However, when the data can be audited for correctness (e.g., it is crytographically signed by its source), this adversarial mechanism is invalidated. This work introduces a novel attack methodology wherein the adversary deceptively omits a portion of the true training data to bias the learned causal structures in a desired manner. Theoretically sound attack mechanisms are derived for the case of arbitrary SCMs, and a sample-efficient learning-based heuristic is given for Gaussian SCMs. Experimental validation of these approaches on real and synthetic data sets demonstrates the effectiveness of adversarial missingness attacks at deceiving popular causal structu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#26367;&#20195;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#20316;&#20026;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#20195;&#29702;&#27169;&#22411;&#65292;&#24182;&#22312;&#22810;&#20010;&#22522;&#20934;&#38382;&#39064;&#19978;&#35777;&#26126;&#20102;&#20854;&#20248;&#20110;&#26631;&#20934;GP&#20195;&#29702;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2305.20028</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#26367;&#20195;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Study of Bayesian Neural Network Surrogates for Bayesian Optimization. (arXiv:2305.20028v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.20028
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#26367;&#20195;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#20316;&#20026;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#20195;&#29702;&#27169;&#22411;&#65292;&#24182;&#22312;&#22810;&#20010;&#22522;&#20934;&#38382;&#39064;&#19978;&#35777;&#26126;&#20102;&#20854;&#20248;&#20110;&#26631;&#20934;GP&#20195;&#29702;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#26159;&#19968;&#31181;&#39640;&#25928;&#30340;&#20248;&#21270;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#38590;&#20197;&#26597;&#35810;&#30340;&#30446;&#26631;&#20989;&#25968;&#12290;&#36825;&#20123;&#30446;&#26631;&#20989;&#25968;&#36890;&#24120;&#30001;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#20195;&#29702;&#27169;&#22411;&#34920;&#31034;&#65292;&#20854;&#26131;&#20110;&#20248;&#21270;&#24182;&#25903;&#25345;&#31934;&#30830;&#25512;&#29702;&#12290;&#34429;&#28982;&#26631;&#20934;&#30340;GP&#20195;&#29702;&#24050;&#32463;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#34987;&#24191;&#27867;&#24212;&#29992;&#65292;&#20294;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;BNNs&#65289;&#26368;&#36817;&#25104;&#20026;&#20102;&#19968;&#20010;&#23454;&#29992;&#30340;&#20989;&#25968;&#36924;&#36817;&#22120;&#65292;&#19982;&#26631;&#20934;&#30340;GP&#30456;&#27604;&#20855;&#26377;&#35768;&#22810;&#20248;&#28857;&#65292;&#20363;&#22914;&#22825;&#28982;&#22788;&#29702;&#38750;&#24179;&#31283;&#24615;&#20197;&#21450;&#23398;&#20064;&#39640;&#32500;&#25968;&#25454;&#30340;&#34920;&#31034;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;BNN&#20316;&#20026;&#26631;&#20934;GP&#20195;&#29702;&#30340;&#26367;&#20195;&#21697;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#21508;&#31181;&#26377;&#38480;&#23485;&#24230;BNN&#30340;&#36817;&#20284;&#25512;&#29702;&#36807;&#31243;&#65292;&#21253;&#25324;&#39640;&#36136;&#37327;Hamiltonian Monte Carlo&#65292;&#20302;&#25104;&#26412;&#30340;&#38543;&#26426;MCMC&#21644;&#21551;&#21457;&#24335;&#26041;&#27861;&#65288;&#22914;&#28145;&#24230;&#38598;&#25104;&#65289;&#12290;&#25105;&#20204;&#36824;&#32771;&#34385;&#20102;&#26080;&#38480;&#23485;&#24230;BNN&#21644;&#37096;&#20998;&#38543;&#26426;&#27169;&#22411;&#65292;&#20363;&#22914;&#28145;&#24230;&#26680;&#23398;&#20064;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#36825;&#20123;&#20195;&#29702;&#27169;&#22411;&#22312;&#22810;&#20010;&#22522;&#20934;&#38382;&#39064;&#19978;&#30340;&#34920;&#29616;&#65292;&#24182;&#35777;&#26126;&#23427;&#20204;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#21487;&#20197;&#20248;&#20110;&#26631;&#20934;GP&#20195;&#29702;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;BNN&#26159;&#20256;&#32479;&#20195;&#29702;&#27169;&#22411;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#19968;&#20010;&#24456;&#26377;&#21069;&#36884;&#30340;&#26367;&#20195;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian optimization is a highly efficient approach to optimizing objective functions which are expensive to query. These objectives are typically represented by Gaussian process (GP) surrogate models which are easy to optimize and support exact inference. While standard GP surrogates have been well-established in Bayesian optimization, Bayesian neural networks (BNNs) have recently become practical function approximators, with many benefits over standard GPs such as the ability to naturally handle non-stationarity and learn representations for high-dimensional data. In this paper, we study BNNs as alternatives to standard GP surrogates for optimization. We consider a variety of approximate inference procedures for finite-width BNNs, including high-quality Hamiltonian Monte Carlo, low-cost stochastic MCMC, and heuristics such as deep ensembles. We also consider infinite-width BNNs and partially stochastic models such as deep kernel learning. We evaluate this collection of surrogate mod
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#38480;&#21046;&#22240;&#26524;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#24050;&#30693;&#22240;&#26524;&#22270;&#20013;&#23547;&#25214;&#20248;&#21270;&#30446;&#26631;&#21464;&#37327;&#30340;&#24178;&#39044;&#26041;&#24335;&#24182;&#28385;&#36275;&#32422;&#26463;&#26465;&#20214;&#65292;&#25104;&#21151;&#22320;&#24179;&#34913;&#20102;&#24555;&#36895;&#25910;&#25947;&#21644;&#21487;&#34892;&#24178;&#39044;&#30334;&#20998;&#27604;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;</title><link>http://arxiv.org/abs/2305.20011</link><description>&lt;p&gt;
&#38480;&#21046;&#22240;&#26524;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Constrained Causal Bayesian Optimization. (arXiv:2305.20011v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.20011
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#38480;&#21046;&#22240;&#26524;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#24050;&#30693;&#22240;&#26524;&#22270;&#20013;&#23547;&#25214;&#20248;&#21270;&#30446;&#26631;&#21464;&#37327;&#30340;&#24178;&#39044;&#26041;&#24335;&#24182;&#28385;&#36275;&#32422;&#26463;&#26465;&#20214;&#65292;&#25104;&#21151;&#22320;&#24179;&#34913;&#20102;&#24555;&#36895;&#25910;&#25947;&#21644;&#21487;&#34892;&#24178;&#39044;&#30334;&#20998;&#27604;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#38480;&#21046;&#22240;&#26524;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;cCBO&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#24050;&#30693;&#22240;&#26524;&#22270;&#20013;&#25214;&#21040;&#20248;&#21270;&#30446;&#26631;&#21464;&#37327;&#30340;&#24178;&#39044;&#26041;&#27861;&#65292;&#24182;&#28385;&#36275;&#19968;&#20123;&#32422;&#26463;&#26465;&#20214;&#12290;cCBO&#39318;&#20808;&#36890;&#36807;&#21033;&#29992;&#22270;&#24418;&#32467;&#26500;&#21644;&#23384;&#22312;&#30340;&#35266;&#27979;&#25968;&#25454;&#20943;&#23569;&#25628;&#32034;&#31354;&#38388;&#65307;&#28982;&#21518;&#36890;&#36807;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#23545;&#30446;&#26631;&#21644;&#32422;&#26463;&#37327;&#36827;&#34892;&#24314;&#27169;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#21463;&#38480;&#26399;&#26395;&#25913;&#36827;&#33719;&#21462;&#20989;&#25968;&#20381;&#27425;&#36873;&#25321;&#24178;&#39044;&#26041;&#27861;&#26469;&#35299;&#20915;&#21463;&#38480;&#21046;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19981;&#21516;&#30340;&#20195;&#29702;&#27169;&#22411;&#65292;&#33021;&#22815;&#38598;&#25104;&#35266;&#27979;&#21644;&#24178;&#39044;&#25968;&#25454;&#65292;&#21516;&#26102;&#20197;&#19981;&#26029;&#25552;&#39640;&#30340;&#22797;&#26434;&#24230;&#25429;&#25417;&#25928;&#24212;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#12290;&#25105;&#20204;&#23545;&#20154;&#24037;&#21644;&#30495;&#23454;&#22240;&#26524;&#22270;&#36827;&#34892;&#20102;cCBO&#35780;&#20272;&#65292;&#25104;&#21151;&#22312;&#24555;&#36895;&#25910;&#25947;&#21644;&#21487;&#34892;&#24178;&#39044;&#30334;&#20998;&#27604;&#20043;&#38388;&#36798;&#25104;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose constrained causal Bayesian optimization (cCBO), an approach for finding interventions in a known causal graph that optimize a target variable under some constraints. cCBO first reduces the search space by exploiting the graph structure and, if available, an observational dataset; and then solves the restricted optimization problem by modelling target and constraint quantities using Gaussian processes and by sequentially selecting interventions via a constrained expected improvement acquisition function. We propose different surrogate models that enable to integrate observational and interventional data while capturing correlation among effects with increasing levels of sophistication. We evaluate cCBO on artificial and real-world causal graphs showing successful trade off between fast convergence and percentage of feasible interventions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#28508;&#22312;&#22270;&#35299;&#26500;&#27169;&#22411;&#23884;&#20837;&#30005;&#23376;&#30149;&#21382;&#25968;&#25454;&#30340;&#30693;&#35782;&#22270;&#35889;&#25216;&#26415;&#65292;&#20197;&#35299;&#20915;&#20174;EHR&#25968;&#25454;&#20013;&#33719;&#21462;&#21487;&#25512;&#24191;&#30340;&#30693;&#35782;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2305.19997</link><description>&lt;p&gt;
&#22522;&#20110;&#28508;&#22312;&#22270;&#35299;&#26500;&#27169;&#22411;&#30340;&#30005;&#23376;&#30149;&#21382;&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#25216;&#26415;
&lt;/p&gt;
&lt;p&gt;
Knowledge Graph Embedding with Electronic Health Records Data via Latent Graphical Block Model. (arXiv:2305.19997v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19997
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#28508;&#22312;&#22270;&#35299;&#26500;&#27169;&#22411;&#23884;&#20837;&#30005;&#23376;&#30149;&#21382;&#25968;&#25454;&#30340;&#30693;&#35782;&#22270;&#35889;&#25216;&#26415;&#65292;&#20197;&#35299;&#20915;&#20174;EHR&#25968;&#25454;&#20013;&#33719;&#21462;&#21487;&#25512;&#24191;&#30340;&#30693;&#35782;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#30005;&#23376;&#30149;&#21382;&#65288;EHR&#65289;&#24212;&#29992;&#30340;&#19981;&#26029;&#22686;&#21152;&#65292;&#22823;&#35268;&#27169;&#30340;EHR&#24050;&#25104;&#20026;&#36716;&#21270;&#24615;&#20020;&#24202;&#30740;&#31350;&#30340;&#21478;&#19968;&#31181;&#20016;&#23500;&#25968;&#25454;&#28304;&#12290;&#28982;&#32780;&#65292;&#20174;EHR&#25968;&#25454;&#20013;&#33719;&#21462;&#21487;&#25512;&#24191;&#30340;&#30693;&#35782;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#22312;&#22270;&#35299;&#26500;&#27169;&#22411;&#30340;&#30005;&#23376;&#30149;&#21382;&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#25216;&#26415;&#26469;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
Due to the increasing adoption of electronic health records (EHR), large scale EHRs have become another rich data source for translational clinical research. Despite its potential, deriving generalizable knowledge from EHR data remains challenging. First, EHR data are generated as part of clinical care with data elements too detailed and fragmented for research. Despite recent progress in mapping EHR data to common ontology with hierarchical structures, much development is still needed to enable automatic grouping of local EHR codes to meaningful clinical concepts at a large scale. Second, the total number of unique EHR features is large, imposing methodological challenges to derive reproducible knowledge graph, especially when interest lies in conditional dependency structure. Third, the detailed EHR data on a very large patient cohort imposes additional computational challenge to deriving a knowledge network. To overcome these challenges, we propose to infer the conditional dependenc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23884;&#22871;&#30697;&#38453;-&#24352;&#37327;&#27169;&#22411;&#65292;&#29992;&#20110;&#35299;&#20915;&#22810;&#35270;&#35282;&#32858;&#31867;&#38382;&#39064;&#65292;&#36890;&#36807;&#25191;&#34892;&#26368;&#20339;&#31209;&#19968;&#24352;&#37327;&#36924;&#36817;&#26469;&#20272;&#35745;&#38544;&#34255;&#30340;&#32858;&#31867;&#65292;&#29702;&#35770;&#32467;&#26524;&#21487;&#20197;&#39044;&#26399;&#31934;&#30830;&#20934;&#30830;&#24230;&#12290;</title><link>http://arxiv.org/abs/2305.19992</link><description>&lt;p&gt;
&#22122;&#22768;&#22810;&#35270;&#35282;&#32858;&#31867;&#30340;&#23884;&#22871;&#30697;&#38453;-&#24352;&#37327;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Nested Matrix-Tensor Model for Noisy Multi-view Clustering. (arXiv:2305.19992v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19992
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23884;&#22871;&#30697;&#38453;-&#24352;&#37327;&#27169;&#22411;&#65292;&#29992;&#20110;&#35299;&#20915;&#22810;&#35270;&#35282;&#32858;&#31867;&#38382;&#39064;&#65292;&#36890;&#36807;&#25191;&#34892;&#26368;&#20339;&#31209;&#19968;&#24352;&#37327;&#36924;&#36817;&#26469;&#20272;&#35745;&#38544;&#34255;&#30340;&#32858;&#31867;&#65292;&#29702;&#35770;&#32467;&#26524;&#21487;&#20197;&#39044;&#26399;&#31934;&#30830;&#20934;&#30830;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#23637;&#20102;&#19977;&#38454;&#38025;&#23376;&#31209;&#19968;&#24352;&#37327;&#27169;&#22411;&#30340;&#23884;&#22871;&#30697;&#38453;-&#24352;&#37327;&#27169;&#22411;&#12290;&#35813;&#27169;&#22411;&#29305;&#21035;&#38024;&#23545;&#22810;&#35270;&#35282;&#32858;&#31867;&#38382;&#39064;&#65292;&#20854;&#20013;&#33719;&#24471;&#20102;&#27599;&#20010;&#25968;&#25454;&#28857;&#30340;&#22810;&#20010;&#22024;&#26434;&#35266;&#23519;&#20540;&#65292;&#24182;&#19988;&#21487;&#33021;&#23384;&#22312;&#38750;&#22343;&#21248;&#30340;&#35270;&#35282;&#26041;&#24046;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25968;&#25454;&#21487;&#20197;&#36890;&#36807;&#23558;&#35270;&#35282;&#22534;&#21472;&#26469;&#33258;&#28982;&#34920;&#31034;&#20026;&#19977;&#38454;&#24352;&#37327;&#12290;&#32473;&#23450;&#36825;&#26679;&#19968;&#20010;&#24352;&#37327;&#65292;&#25105;&#20204;&#36890;&#36807;&#25191;&#34892;&#26368;&#20339;&#31209;&#19968;&#24352;&#37327;&#36924;&#36817;&#26469;&#32771;&#34385;&#20272;&#35745;&#38544;&#34255;&#30340;&#32858;&#31867;&#12290;&#20026;&#20102;&#30740;&#31350;&#35813;&#26041;&#27861;&#30340;&#29702;&#35770;&#24615;&#33021;&#65292;&#25105;&#20204;&#20197;&#22823;&#32500;&#24230;&#24773;&#20917;&#19979;&#33719;&#24471;&#30340;&#20998;&#37327;&#21521;&#37327;&#19982;&#38544;&#34255;&#27169;&#22411;&#21442;&#25968;&#21521;&#37327;&#30340;&#23545;&#40784;&#20316;&#20026;&#35780;&#20272;&#26631;&#20934;&#26469;&#34920;&#24449;&#26368;&#20339;&#31209;&#19968;&#36924;&#36817;&#30340;&#34892;&#20026;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#29702;&#35770;&#32467;&#26524;&#20801;&#35768;&#25105;&#20204;&#39044;&#26399;&#25152;&#25552;&#20986;&#30340;&#32858;&#31867;&#26041;&#27861;&#30340;&#31934;&#30830;&#20934;&#30830;&#24230;&#12290;&#27492;&#22806;&#65292;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#21033;&#29992;&#25105;&#20204;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#21487;&#20197;&#26356;&#22909;&#22320;&#35299;&#20915;&#22810;&#35270;&#35282;&#32858;&#31867;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a nested matrix-tensor model which extends the spiked rank-one tensor model of order three. This model is particularly motivated by a multi-view clustering problem in which multiple noisy observations of each data point are acquired, with potentially non-uniform variances along the views. In this case, data can be naturally represented by an order-three tensor where the views are stacked. Given such a tensor, we consider the estimation of the hidden clusters via performing a best rank-one tensor approximation. In order to study the theoretical performance of this approach, we characterize the behavior of this best rank-one approximation in terms of the alignments of the obtained component vectors with the hidden model parameter vectors, in the large-dimensional regime. In particular, we show that our theoretical results allow us to anticipate the exact accuracy of the proposed clustering approach. Furthermore, numerical experiments indicate that leveraging our
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#23558;NeSy&#27169;&#22411;&#20013;&#20986;&#29616;&#30340;&#25512;&#29702;&#24555;&#25463;&#26041;&#24335;&#23450;&#20041;&#20026;&#23398;&#20064;&#30446;&#26631;&#30340;&#24847;&#22806;&#26368;&#20248;&#35299;&#65292;&#24182;&#30830;&#23450;&#20854;&#21457;&#29983;&#30340;&#22235;&#20010;&#20851;&#38190;&#26465;&#20214;&#65292;&#25552;&#20986;&#20102;&#20960;&#31181;&#21487;&#34892;&#30340;&#32531;&#35299;&#31574;&#30053;&#24182;&#23545;&#20854;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#26174;&#31034;&#25512;&#29702;&#24555;&#25463;&#26041;&#24335;&#38590;&#20197;&#22788;&#29702;&#12290;</title><link>http://arxiv.org/abs/2305.19951</link><description>&lt;p&gt;
&#19981;&#26159;&#25152;&#26377;&#31070;&#32463;&#31526;&#21495;&#27010;&#24565;&#37117;&#26159;&#24179;&#31561;&#30340;&#65306; &#25512;&#29702;&#24555;&#25463;&#26041;&#24335;&#30340;&#20998;&#26512;&#21644;&#32531;&#35299;
&lt;/p&gt;
&lt;p&gt;
Not All Neuro-Symbolic Concepts Are Created Equal: Analysis and Mitigation of Reasoning Shortcuts. (arXiv:2305.19951v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19951
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#23558;NeSy&#27169;&#22411;&#20013;&#20986;&#29616;&#30340;&#25512;&#29702;&#24555;&#25463;&#26041;&#24335;&#23450;&#20041;&#20026;&#23398;&#20064;&#30446;&#26631;&#30340;&#24847;&#22806;&#26368;&#20248;&#35299;&#65292;&#24182;&#30830;&#23450;&#20854;&#21457;&#29983;&#30340;&#22235;&#20010;&#20851;&#38190;&#26465;&#20214;&#65292;&#25552;&#20986;&#20102;&#20960;&#31181;&#21487;&#34892;&#30340;&#32531;&#35299;&#31574;&#30053;&#24182;&#23545;&#20854;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#26174;&#31034;&#25512;&#29702;&#24555;&#25463;&#26041;&#24335;&#38590;&#20197;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#31526;&#21495;&#65288;NeSy&#65289;&#39044;&#27979;&#27169;&#22411;&#25215;&#35834;&#20855;&#26377;&#25913;&#36827;&#30340;&#32422;&#26463;&#36981;&#20174;&#24615;&#65292;&#31995;&#32479;&#21270;&#27867;&#21270;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#22240;&#20026;&#23427;&#20204;&#20801;&#35768;&#36890;&#36807;&#23545;&#20174;&#23376;&#31526;&#21495;&#36755;&#20837;&#20013;&#25552;&#21462;&#20986;&#30340;&#39640;&#32423;&#27010;&#24565;&#36827;&#34892;&#25512;&#29702;&#26469;&#25512;&#26029;&#19982;&#26576;&#20123;&#20808;&#39564;&#30693;&#35782;&#19968;&#33268;&#30340;&#26631;&#31614;&#12290;&#26368;&#36817;&#26174;&#31034;NeSy&#39044;&#27979;&#22120;&#21463;&#21040;&#25512;&#29702;&#24555;&#25463;&#26041;&#24335;&#30340;&#24433;&#21709;&#65306;&#23427;&#20204;&#21487;&#20197;&#36890;&#36807;&#21033;&#29992;&#20855;&#26377;&#24847;&#22806;&#35821;&#20041;&#30340;&#27010;&#24565;&#36798;&#21040;&#39640;&#31934;&#24230;&#65292;&#20174;&#32780;&#30701;&#20110;&#20854;&#25215;&#35834;&#30340;&#20248;&#21183;&#12290;&#20294;&#26159;&#65292;&#32570;&#23569;&#23545;&#25512;&#29702;&#24555;&#25463;&#26041;&#24335;&#21450;&#20854;&#28508;&#22312;&#32531;&#35299;&#31574;&#30053;&#30340;&#31995;&#32479;&#25551;&#36848;&#12290;&#26412;&#25991;&#36890;&#36807;&#23558;&#20854;&#34920;&#24449;&#20026;&#23398;&#20064;&#30446;&#26631;&#30340;&#24847;&#22806;&#26368;&#20248;&#35299;&#65292;&#24182;&#30830;&#23450;&#20854;&#21457;&#29983;&#32972;&#21518;&#30340;&#22235;&#20010;&#20851;&#38190;&#26465;&#20214;&#26469;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#12290;&#22522;&#20110;&#27492;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20960;&#31181;&#33258;&#28982;&#30340;&#32531;&#35299;&#31574;&#30053;&#65292;&#24182;&#20174;&#29702;&#35770;&#21644;&#23454;&#35777;&#35282;&#24230;&#20998;&#26512;&#23427;&#20204;&#30340;&#21151;&#25928;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#26174;&#31034;&#65292;&#25512;&#29702;&#24555;&#25463;&#26041;&#24335;&#24456;&#38590;&#22788;&#29702;&#65292;&#36825;&#23545;&#20110;&#20449;&#20219;&#23427;&#20204;&#30340;&#21512;&#29702;&#24615;&#20135;&#29983;&#20102;&#30097;&#38382;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neuro-Symbolic (NeSy) predictive models hold the promise of improved compliance with given constraints, systematic generalization, and interpretability, as they allow to infer labels that are consistent with some prior knowledge by reasoning over high-level concepts extracted from sub-symbolic inputs. It was recently shown that NeSy predictors are affected by reasoning shortcuts: they can attain high accuracy but by leveraging concepts with unintended semantics, thus coming short of their promised advantages. Yet, a systematic characterization of reasoning shortcuts and of potential mitigation strategies is missing. This work fills this gap by characterizing them as unintended optima of the learning objective and identifying four key conditions behind their occurrence. Based on this, we derive several natural mitigation strategies, and analyze their efficacy both theoretically and empirically. Our analysis shows reasoning shortcuts are difficult to deal with, casting doubts on the trus
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#20960;&#20309;&#32467;&#26500;&#65292;&#21457;&#29616;&#36890;&#36807;&#19968;&#20010;&#26126;&#30830;&#30340;&#20934;&#32447;&#24615;&#37319;&#26679;&#36712;&#36857;&#21644;&#21478;&#19968;&#20010;&#38544;&#24335;&#30340;&#21435;&#22122;&#36712;&#36857;&#24179;&#28369;&#36830;&#25509;&#20102;&#25968;&#25454;&#20998;&#24067;&#21644;&#22122;&#22768;&#20998;&#24067;&#65292;&#24314;&#31435;&#20102;&#22522;&#20110;ODE&#30340;&#26368;&#20248;&#37319;&#26679;&#21644;&#32463;&#20856;&#30340;&#22343;&#20540;&#28418;&#31227;&#31639;&#27861;&#20043;&#38388;&#30340;&#29702;&#35770;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2305.19947</link><description>&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#30340;&#20960;&#20309;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
A Geometric Perspective on Diffusion Models. (arXiv:2305.19947v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19947
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#20960;&#20309;&#32467;&#26500;&#65292;&#21457;&#29616;&#36890;&#36807;&#19968;&#20010;&#26126;&#30830;&#30340;&#20934;&#32447;&#24615;&#37319;&#26679;&#36712;&#36857;&#21644;&#21478;&#19968;&#20010;&#38544;&#24335;&#30340;&#21435;&#22122;&#36712;&#36857;&#24179;&#28369;&#36830;&#25509;&#20102;&#25968;&#25454;&#20998;&#24067;&#21644;&#22122;&#22768;&#20998;&#24067;&#65292;&#24314;&#31435;&#20102;&#22522;&#20110;ODE&#30340;&#26368;&#20248;&#37319;&#26679;&#21644;&#32463;&#20856;&#30340;&#22343;&#20540;&#28418;&#31227;&#31639;&#27861;&#20043;&#38388;&#30340;&#29702;&#35770;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#38024;&#23545;&#25193;&#25955;&#27169;&#22411;&#30340;&#39640;&#25928;&#35757;&#32451;&#21644;&#24555;&#36895;&#37319;&#26679;&#26041;&#27861;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#12290;&#26368;&#36817;&#30340;&#19968;&#20010;&#37325;&#35201;&#36827;&#23637;&#26159;&#20351;&#29992;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;SDE&#65289;&#26469;&#25551;&#36848;&#25968;&#25454;&#25200;&#21160;&#21644;&#29983;&#25104;&#24314;&#27169;&#65292;&#20197;&#23454;&#29616;&#32479;&#19968;&#30340;&#25968;&#23398;&#26694;&#26550;&#12290;&#26412;&#25991;&#25581;&#31034;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#20960;&#20010;&#26377;&#36259;&#30340;&#20960;&#20309;&#32467;&#26500;&#65292;&#24182;&#20026;&#20854;&#37319;&#26679;&#21160;&#21147;&#23398;&#25552;&#20379;&#20102;&#31616;&#21333;&#32780;&#24378;&#22823;&#30340;&#35299;&#37322;&#12290;&#36890;&#36807;&#20180;&#32454;&#26816;&#26597;&#19968;&#31181;&#27969;&#34892;&#30340;&#26041;&#24046;&#29190;&#28856;SDE&#21450;&#20854;&#20445;&#25345;&#36793;&#38469;&#30340;&#26222;&#36890;&#24494;&#20998;&#26041;&#31243;&#65288;ODE&#65289;&#29992;&#20110;&#37319;&#26679;&#65292;&#25105;&#20204;&#21457;&#29616;&#25968;&#25454;&#20998;&#24067;&#21644;&#22122;&#22768;&#20998;&#24067;&#36890;&#36807;&#19968;&#20010;&#26126;&#30830;&#30340;&#20934;&#32447;&#24615;&#37319;&#26679;&#36712;&#36857;&#21644;&#21478;&#19968;&#20010;&#38544;&#24335;&#30340;&#21435;&#22122;&#36712;&#36857;&#24179;&#28369;&#36830;&#25509;&#65292;&#21363;&#20351;&#22312;&#35270;&#35273;&#36136;&#37327;&#26041;&#38754;&#20063;&#25910;&#25947;&#26356;&#24555;&#12290;&#25105;&#20204;&#36824;&#24314;&#31435;&#36215;&#22522;&#20110;ODE&#30340;&#26368;&#20248;&#37319;&#26679;&#21644;&#32463;&#20856;&#30340;&#22343;&#20540;&#28418;&#31227;&#65288;&#23547;&#25214;&#27169;&#24335;&#65289;&#31639;&#27861;&#20043;&#38388;&#30340;&#29702;&#35770;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent years have witnessed significant progress in developing efficient training and fast sampling approaches for diffusion models. A recent remarkable advancement is the use of stochastic differential equations (SDEs) to describe data perturbation and generative modeling in a unified mathematical framework. In this paper, we reveal several intriguing geometric structures of diffusion models and contribute a simple yet powerful interpretation to their sampling dynamics. Through carefully inspecting a popular variance-exploding SDE and its marginal-preserving ordinary differential equation (ODE) for sampling, we discover that the data distribution and the noise distribution are smoothly connected with an explicit, quasi-linear sampling trajectory, and another implicit denoising trajectory, which even converges faster in terms of visual quality. We also establish a theoretical relationship between the optimal ODE-based sampling and the classic mean-shift (mode-seeking) algorithm, with w
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#20803;&#32032;&#21487;&#20197;&#23454;&#26102;&#22320;&#34987;&#25554;&#20837;&#21644;&#21024;&#38500;&#30340;&#24773;&#20917;&#19979;&#65292;&#26368;&#22823;&#21270;&#25311;&#38453;&#38480;&#21046;&#19979;&#30340;&#21333;&#35843;&#23376;&#27169;&#20989;&#25968;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#31639;&#27861;&#65292;&#26102;&#38388;&#22797;&#26434;&#24230;&#20026;$\tilde{O}(k^2)$&#65292;&#21487;&#20197;&#20135;&#29983;&#19968;&#20010;$4$&#36817;&#20284;&#35299;&#12290;</title><link>http://arxiv.org/abs/2305.19918</link><description>&lt;p&gt;
&#22312;&#25311;&#38453;&#19978;&#23436;&#20840;&#21160;&#24577;&#23376;&#27169;&#26368;&#22823;&#21270;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Fully Dynamic Submodular Maximization over Matroids. (arXiv:2305.19918v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19918
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#20803;&#32032;&#21487;&#20197;&#23454;&#26102;&#22320;&#34987;&#25554;&#20837;&#21644;&#21024;&#38500;&#30340;&#24773;&#20917;&#19979;&#65292;&#26368;&#22823;&#21270;&#25311;&#38453;&#38480;&#21046;&#19979;&#30340;&#21333;&#35843;&#23376;&#27169;&#20989;&#25968;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#31639;&#27861;&#65292;&#26102;&#38388;&#22797;&#26434;&#24230;&#20026;$\tilde{O}(k^2)$&#65292;&#21487;&#20197;&#20135;&#29983;&#19968;&#20010;$4$&#36817;&#20284;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25968;&#25454;&#25366;&#25496;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#26368;&#22823;&#21270;&#25311;&#38453;&#38480;&#21046;&#19979;&#30340;&#21333;&#35843;&#23376;&#27169;&#20989;&#25968;&#26159;&#19968;&#20010;&#20855;&#26377;&#22810;&#20010;&#24212;&#29992;&#30340;&#32463;&#20856;&#31639;&#27861;&#38382;&#39064;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#23436;&#20840;&#21160;&#24577;&#30340;&#24773;&#20917;&#19979;&#65292;&#21363;&#20803;&#32032;&#21487;&#20197;&#23454;&#26102;&#22320;&#34987;&#25554;&#20837;&#21644;&#21024;&#38500;&#30340;&#24773;&#20917;&#19979;&#30340;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;&#19968;&#31181;&#38543;&#26426;&#31639;&#27861;&#65292;&#23427;&#32500;&#25252;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#25968;&#25454;&#32467;&#26500;&#65292;&#20854;&#25674;&#38144;&#26356;&#26032;&#26102;&#38388;&#20026;$\tilde{O}(k^2)$&#65288;&#22312;&#28155;&#21152;&#21644;&#21024;&#38500;&#27425;&#25968;&#19978;&#65289;&#65292;&#24182;&#20135;&#29983;&#20102;&#19968;&#20010;$4$&#36817;&#20284;&#35299;&#65292;&#20854;&#20013;$k$&#26159;&#25311;&#38453;&#30340;&#31209;&#12290;
&lt;/p&gt;
&lt;p&gt;
Maximizing monotone submodular functions under a matroid constraint is a classic algorithmic problem with multiple applications in data mining and machine learning. We study this classic problem in the fully dynamic setting, where elements can be both inserted and deleted in real-time. Our main result is a randomized algorithm that maintains an efficient data structure with an $\tilde{O}(k^2)$ amortized update time (in the number of additions and deletions) and yields a $4$-approximate solution, where $k$ is the rank of the matroid.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#33258;&#36866;&#24212;&#26041;&#27861;&#65292;&#23427;&#22522;&#20110;&#29992;&#23616;&#37096;&#20998;&#25968;&#20998;&#24067;&#30340;&#20272;&#35745;&#26469;&#37325;&#26032;&#32553;&#25918;&#31526;&#21512;&#20998;&#25968;&#12290;&#35813;&#26041;&#27861;&#19981;&#20250;&#29306;&#29298;&#26657;&#20934;&#38598;&#22823;&#23567;&#65292;&#23454;&#29616;&#20102;&#23616;&#37096;&#35206;&#30422;&#24182;&#25552;&#39640;&#20102;&#31526;&#21512;&#39044;&#27979;&#38388;&#38548;&#30340;&#36866;&#29992;&#24615;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#20302;&#25968;&#25454;&#33539;&#22260;&#20869;&#30340;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2305.19901</link><description>&lt;p&gt;
&#24102;&#26377;Jackknife+ Rescaled Scores&#30340;&#33258;&#36866;&#24212;&#31526;&#21512;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Adaptive Conformal Regression with Jackknife+ Rescaled Scores. (arXiv:2305.19901v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19901
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#33258;&#36866;&#24212;&#26041;&#27861;&#65292;&#23427;&#22522;&#20110;&#29992;&#23616;&#37096;&#20998;&#25968;&#20998;&#24067;&#30340;&#20272;&#35745;&#26469;&#37325;&#26032;&#32553;&#25918;&#31526;&#21512;&#20998;&#25968;&#12290;&#35813;&#26041;&#27861;&#19981;&#20250;&#29306;&#29298;&#26657;&#20934;&#38598;&#22823;&#23567;&#65292;&#23454;&#29616;&#20102;&#23616;&#37096;&#35206;&#30422;&#24182;&#25552;&#39640;&#20102;&#31526;&#21512;&#39044;&#27979;&#38388;&#38548;&#30340;&#36866;&#29992;&#24615;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#20302;&#25968;&#25454;&#33539;&#22260;&#20869;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31526;&#21512;&#22238;&#24402;&#25552;&#20379;&#20102;&#20855;&#26377;&#20840;&#23616;&#35206;&#30422;&#20445;&#35777;&#30340;&#39044;&#27979;&#21306;&#38388;&#65292;&#20294;&#24448;&#24448;&#26080;&#27861;&#25429;&#33719;&#23616;&#37096;&#35823;&#24046;&#20998;&#24067;&#65292;&#23548;&#33268;&#19981;&#22343;&#21248;&#35206;&#30422;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#36866;&#24212;&#26041;&#27861;&#65292;&#23427;&#22522;&#20110;&#29992;&#23616;&#37096;&#20998;&#25968;&#20998;&#24067;&#30340;&#20272;&#35745;&#26469;&#37325;&#26032;&#32553;&#25918;&#31526;&#21512;&#20998;&#25968;&#65292;&#28789;&#24863;&#26469;&#33258;Jackknife+&#26041;&#27861;&#65292;&#23427;&#20351;&#24471;&#22312;&#19981;&#30772;&#22351;&#26657;&#20934;-&#27979;&#35797;&#20132;&#25442;&#24615;&#30340;&#24773;&#20917;&#19979;&#21487;&#20197;&#21033;&#29992;&#26657;&#20934;&#25968;&#25454;&#30340;&#31526;&#21512;&#20998;&#25968;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30830;&#20445;&#20102;&#27491;&#24335;&#30340;&#20840;&#23616;&#35206;&#30422;&#20445;&#35777;&#65292;&#24182;&#24471;&#21040;&#20102;&#20851;&#20110;&#23616;&#37096;&#35206;&#30422;&#30340;&#26032;&#29702;&#35770;&#32467;&#26524;&#65292;&#21253;&#25324;&#20219;&#20309;&#26657;&#20934;&#20998;&#25968;&#30340;&#21518;&#39564;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#20248;&#21183;&#22312;&#20110;&#23454;&#29616;&#20102;&#23616;&#37096;&#35206;&#30422;&#65292;&#32780;&#19981;&#29306;&#29298;&#26657;&#20934;&#38598;&#22823;&#23567;&#65292;&#25552;&#39640;&#20102;&#31526;&#21512;&#39044;&#27979;&#38388;&#38548;&#22312;&#21508;&#31181;&#35774;&#32622;&#20013;&#30340;&#36866;&#29992;&#24615;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;&#20248;&#20110;&#20808;&#21069;&#26041;&#27861;&#30340;&#39044;&#27979;&#21306;&#38388;&#65292;&#29305;&#21035;&#26159;&#22312;&#20302;&#25968;&#25454;&#33539;&#22260;&#20869;&#65292;&#20351;&#20854;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#23588;&#20026;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conformal regression provides prediction intervals with global coverage guarantees, but often fails to capture local error distributions, leading to non-homogeneous coverage. We address this with a new adaptive method based on rescaling conformal scores with an estimate of local score distribution, inspired by the Jackknife+ method, which enables the use of calibration data in conformal scores without breaking calibration-test exchangeability. Our approach ensures formal global coverage guarantees and is supported by new theoretical results on local coverage, including an a posteriori bound on any calibration score. The strength of our approach lies in achieving local coverage without sacrificing calibration set size, improving the applicability of conformal prediction intervals in various settings. As a result, our method provides prediction intervals that outperform previous methods, particularly in the low-data regime, making it especially relevant for real-world applications such a
&lt;/p&gt;</description></item><item><title>EAMDrift&#26159;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#27169;&#22411;&#65292;&#36890;&#36807;&#23545;&#22810;&#20010;&#39044;&#27979;&#22120;&#30340;&#39044;&#27979;&#36827;&#34892;&#21152;&#26435;&#65292;&#33258;&#21160;&#36866;&#24212;&#20998;&#24067;&#22806;&#27169;&#24335;&#65292;&#24182;&#22312;&#27599;&#20010;&#26102;&#21051;&#36873;&#25321;&#26368;&#21512;&#36866;&#30340;&#27169;&#22411;&#12290;&#20854;&#35774;&#35745;&#21253;&#25324;&#33258;&#21160;&#37325;&#35757;&#32451;&#26426;&#21046;&#21644;&#22522;&#20110;&#27010;&#24565;&#32534;&#30721;&#30340;&#35266;&#23519;&#32773;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2305.19837</link><description>&lt;p&gt;
EAMDrift&#65306;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#33258;&#25105;&#37325;&#35757;&#32451;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
EAMDrift: An interpretable self retrain model for time series. (arXiv:2305.19837v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19837
&lt;/p&gt;
&lt;p&gt;
EAMDrift&#26159;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#27169;&#22411;&#65292;&#36890;&#36807;&#23545;&#22810;&#20010;&#39044;&#27979;&#22120;&#30340;&#39044;&#27979;&#36827;&#34892;&#21152;&#26435;&#65292;&#33258;&#21160;&#36866;&#24212;&#20998;&#24067;&#22806;&#27169;&#24335;&#65292;&#24182;&#22312;&#27599;&#20010;&#26102;&#21051;&#36873;&#25321;&#26368;&#21512;&#36866;&#30340;&#27169;&#22411;&#12290;&#20854;&#35774;&#35745;&#21253;&#25324;&#33258;&#21160;&#37325;&#35757;&#32451;&#26426;&#21046;&#21644;&#22522;&#20110;&#27010;&#24565;&#32534;&#30721;&#30340;&#35266;&#23519;&#32773;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#21487;&#29992;&#24615;&#21644;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#19981;&#26029;&#21457;&#23637;&#65292;&#22312;&#21508;&#20010;&#34892;&#19994;&#20013;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#36827;&#34892;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#21464;&#24471;&#36234;&#26469;&#36234;&#27969;&#34892;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#30340;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#26041;&#27861;&#20381;&#36182;&#20110;&#39044;&#20808;&#20248;&#21270;&#30340;&#27169;&#22411;&#65292;&#38590;&#20197;&#22788;&#29702;&#25968;&#25454;&#20013;&#30340;&#19981;&#21487;&#39044;&#27979;&#27169;&#24335;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#8212;&#8212;EAMDrift&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#25353;&#24615;&#33021;&#24230;&#37327;&#21152;&#26435;&#27599;&#20010;&#39044;&#27979;&#65292;&#23558;&#22810;&#20010;&#29420;&#31435;&#39044;&#27979;&#22120;&#30340;&#39044;&#27979;&#32452;&#21512;&#36215;&#26469;&#12290; EAMDrift&#26088;&#22312;&#36890;&#36807;&#35299;&#37322;&#24615;&#26426;&#21046;&#33258;&#21160;&#36866;&#24212;&#25968;&#25454;&#20013;&#30340;&#20998;&#24067;&#22806;&#27169;&#24335;&#24182;&#35782;&#21035;&#27599;&#20010;&#26102;&#21051;&#20351;&#29992;&#30340;&#26368;&#21512;&#36866;&#30340;&#27169;&#22411;&#65292;&#20854;&#20013;&#21253;&#25324;&#33258;&#21160;&#37325;&#35757;&#32451;&#36807;&#31243;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20351;&#29992;&#19981;&#21516;&#30340;&#27169;&#22411;&#23545;&#19981;&#21516;&#30340;&#27010;&#24565;&#36827;&#34892;&#32534;&#30721;&#65292;&#27599;&#20010;&#27169;&#22411;&#20316;&#20026;&#29305;&#23450;&#34892;&#20026;&#30340;&#35266;&#23519;&#32773;&#12290;&#28982;&#21518;&#65292;&#25972;&#20307;&#27169;&#22411;&#30340;&#28608;&#27963;&#23558;&#30830;&#23450;&#21738;&#20010;&#27010;&#24565;&#35266;&#23519;&#32773;&#23376;&#38598;&#27491;&#22312;&#35782;&#21035;&#27010;&#24565;&#12290;
&lt;/p&gt;
&lt;p&gt;
The use of machine learning for time series prediction has become increasingly popular across various industries thanks to the availability of time series data and advancements in machine learning algorithms. However, traditional methods for time series forecasting rely on pre-optimized models that are ill-equipped to handle unpredictable patterns in data. In this paper, we present EAMDrift, a novel method that combines forecasts from multiple individual predictors by weighting each prediction according to a performance metric. EAMDrift is designed to automatically adapt to out-of-distribution patterns in data and identify the most appropriate models to use at each moment through interpretable mechanisms, which include an automatic retraining process. Specifically, we encode different concepts with different models, each functioning as an observer of specific behaviors. The activation of the overall model then identifies which subset of the concept observers is identifying concepts in 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#36870;&#38382;&#39064;&#30340;&#30452;&#25509;&#25193;&#25955;&#38142;&#26725;&#31639;&#27861;&#65292;&#25552;&#39640;&#20102;&#36870;&#38382;&#39064;&#27714;&#35299;&#22120;&#30340;&#24615;&#33021;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#25968;&#25454;&#19968;&#33268;&#24615;&#35299;&#20915;&#20102;&#24403;&#21069;DDB&#26694;&#26550;&#23384;&#22312;&#30340;&#20851;&#38190;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2305.19809</link><description>&lt;p&gt;
&#20351;&#29992;&#25968;&#25454;&#19968;&#33268;&#24615;&#30340;&#30452;&#25509;&#25193;&#25955;&#38142;&#26725;&#35299;&#20915;&#36870;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Direct Diffusion Bridge using Data Consistency for Inverse Problems. (arXiv:2305.19809v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19809
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#36870;&#38382;&#39064;&#30340;&#30452;&#25509;&#25193;&#25955;&#38142;&#26725;&#31639;&#27861;&#65292;&#25552;&#39640;&#20102;&#36870;&#38382;&#39064;&#27714;&#35299;&#22120;&#30340;&#24615;&#33021;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#25968;&#25454;&#19968;&#33268;&#24615;&#35299;&#20915;&#20102;&#24403;&#21069;DDB&#26694;&#26550;&#23384;&#22312;&#30340;&#20851;&#38190;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#36870;&#38382;&#39064;&#27714;&#35299;&#22120;&#34920;&#29616;&#20986;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#24615;&#33021;&#65292;&#20294;&#36895;&#24230;&#21463;&#38480;&#65292;&#20027;&#35201;&#26159;&#22240;&#20026;&#38656;&#35201;&#20174;&#22122;&#22768;&#24320;&#22987;&#36827;&#34892;&#21453;&#21521;&#25193;&#25955;&#37319;&#26679;&#12290;&#36817;&#26399;&#30340;&#19968;&#20123;&#24037;&#20316;&#23581;&#35797;&#36890;&#36807;&#26500;&#24314;&#25193;&#25955;&#36807;&#31243;&#26469;&#30452;&#25509;&#26725;&#25509;&#29305;&#23450;&#36870;&#38382;&#39064;&#30340;&#28165;&#27905;&#21644;&#27745;&#26579;&#25968;&#25454;&#20197;&#20943;&#36731;&#36825;&#20010;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#23558;&#36825;&#20123;&#29616;&#26377;&#24037;&#20316;&#32479;&#19968;&#21629;&#21517;&#20026;&#30452;&#25509;&#25193;&#25955;&#38142;&#26725;&#65288;DDB&#65289;&#65292;&#35777;&#26126;&#23613;&#31649;&#21463;&#19981;&#21516;&#29702;&#35770;&#30340;&#21551;&#21457;&#65292;&#20294;&#30001;&#27492;&#20135;&#29983;&#30340;&#31639;&#27861;&#22312;&#21442;&#25968;&#36873;&#25321;&#19978;&#30340;&#19981;&#21516;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24378;&#35843;&#24403;&#21069;DDB&#26694;&#26550;&#30340;&#19968;&#20010;&#20851;&#38190;&#38480;&#21046;&#65292;&#21363;&#23427;&#19981;&#33021;&#20445;&#35777;&#25968;&#25454;&#19968;&#33268;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#25913;&#30340;&#25512;&#26029;&#31243;&#24207;&#65292;&#23427;&#22312;&#19981;&#38656;&#35201;&#31934;&#32454;&#35843;&#25972;&#30340;&#24773;&#20917;&#19979;&#24378;&#21046;&#25968;&#25454;&#19968;&#33268;&#24615;&#12290;&#25105;&#20204;&#23558;&#24471;&#21040;&#30340;&#26041;&#27861;&#31216;&#20026;&#25968;&#25454;&#19968;&#33268;&#30340;DDB&#65288;CDDB&#65289;&#65292;&#23427;&#22312;&#24863;&#30693;&#21644;&#22833;&#30495;&#25351;&#26631;&#26041;&#38754;&#37117;&#20248;&#20110;&#19981;&#19968;&#33268;&#30340;&#23545;&#24212;&#29289;&#65292;&#20174;&#32780;&#26377;&#25928;&#22320;&#25512;&#21160;&#20102;&#36870;&#38382;&#39064;&#27714;&#35299;&#22120;&#30340;&#26368;&#26032;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion model-based inverse problem solvers have shown impressive performance, but are limited in speed, mostly as they require reverse diffusion sampling starting from noise. Several recent works have tried to alleviate this problem by building a diffusion process, directly bridging the clean and the corrupted for specific inverse problems. In this paper, we first unify these existing works under the name Direct Diffusion Bridges (DDB), showing that while motivated by different theories, the resulting algorithms only differ in the choice of parameters. Then, we highlight a critical limitation of the current DDB framework, namely that it does not ensure data consistency. To address this problem, we propose a modified inference procedure that imposes data consistency without the need for fine-tuning. We term the resulting method data Consistent DDB (CDDB), which outperforms its inconsistent counterpart in terms of both perception and distortion metrics, thereby effectively pushing the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#28388;&#27874;&#22120;&#26041;&#27861;&#65292;&#33021;&#26377;&#25928;&#22788;&#29702;&#19981;&#24179;&#34913;&#22810;&#31867;&#25968;&#25454;&#38598;&#19978;&#30340;&#29305;&#24449;&#36873;&#25321;&#38382;&#39064;&#65292;&#23427;&#22522;&#20110;Spearman&#25490;&#21517;&#30456;&#20851;&#24615;&#32780;&#19981;&#26159;&#29305;&#24449;&#26041;&#24046;&#12290;</title><link>http://arxiv.org/abs/2305.19804</link><description>&lt;p&gt;
&#36317;&#31163;&#25490;&#21517;&#20998;&#25968;&#65306;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#19978;&#26080;&#30417;&#30563;&#29305;&#24449;&#36873;&#25321;&#30340;&#28388;&#27874;&#22120;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Distance Rank Score: Unsupervised filter method for feature selection on imbalanced dataset. (arXiv:2305.19804v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19804
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#28388;&#27874;&#22120;&#26041;&#27861;&#65292;&#33021;&#26377;&#25928;&#22788;&#29702;&#19981;&#24179;&#34913;&#22810;&#31867;&#25968;&#25454;&#38598;&#19978;&#30340;&#29305;&#24449;&#36873;&#25321;&#38382;&#39064;&#65292;&#23427;&#22522;&#20110;Spearman&#25490;&#21517;&#30456;&#20851;&#24615;&#32780;&#19981;&#26159;&#29305;&#24449;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26080;&#30417;&#30563;&#29305;&#24449;&#36873;&#25321;&#30340;&#28388;&#27874;&#22120;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#22312;&#19981;&#24179;&#34913;&#30340;&#22810;&#31867;&#25968;&#25454;&#38598;&#19978;&#29305;&#21035;&#26377;&#25928;&#65292;&#22914;&#19981;&#21516;&#24322;&#24120;&#31867;&#22411;&#30340;&#32676;&#38598;&#20013;&#12290;&#29616;&#26377;&#26041;&#27861;&#36890;&#24120;&#28041;&#21450;&#29305;&#24449;&#30340;&#26041;&#24046;&#65292;&#24403;&#19981;&#21516;&#31867;&#22411;&#30340;&#35266;&#27979;&#27809;&#26377;&#34987;&#24179;&#31561;&#22320;&#34920;&#31034;&#26102;&#65292;&#36825;&#31181;&#26041;&#27861;&#24182;&#19981;&#36866;&#29992;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#35266;&#27979;&#19982;&#29305;&#24449;&#20540;&#20043;&#38388;&#30340;Spearman&#25490;&#21517;&#30456;&#20851;&#24615;&#65292;&#36991;&#20813;&#20102;&#36825;&#31181;&#32570;&#28857;&#12290;&#35813;&#26041;&#27861;&#30340;&#24615;&#33021;&#36890;&#36807;&#22810;&#20010;&#32858;&#31867;&#38382;&#39064;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#24182;&#19982;&#36866;&#29992;&#20110;&#26080;&#30417;&#30563;&#25968;&#25454;&#30340;&#29616;&#26377;&#28388;&#27874;&#22120;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a new filter method for unsupervised feature selection. This method is particularly effective on imbalanced multi-class dataset, as in case of clusters of different anomaly types. Existing methods usually involve the variance of the features, which is not suitable when the different types of observations are not represented equally. Our method, based on Spearman's Rank Correlation between distances on the observations and on feature values, avoids this drawback. The performance of the method is measured on several clustering problems and is compared with existing filter methods suitable for unsupervised data.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;aggVAE&#36827;&#34892;&#28145;&#24230;&#23398;&#20064;&#21644;MCMC&#22788;&#29702;&#34892;&#25919;&#36793;&#30028;&#21464;&#21270;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#26144;&#23556;&#20197;&#21439;&#20026;&#23618;&#32423;&#30340;&#32858;&#21512;&#32423;&#21035;&#25968;&#25454;&#65292;&#24182;&#22788;&#29702;&#34892;&#25919;&#36793;&#30028;&#30340;&#21464;&#21270;&#65292;&#30456;&#27604;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#34920;&#29616;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2305.19779</link><description>&lt;p&gt;
&#21033;&#29992;aggVAE&#36827;&#34892;&#28145;&#24230;&#23398;&#20064;&#21644;MCMC&#20197;&#22788;&#29702;&#34892;&#25919;&#36793;&#30028;&#21464;&#21270;&#65306;&#20197;&#32943;&#23612;&#20122;&#30340;&#30111;&#30142;&#24739;&#30149;&#29575;&#20026;&#20363;
&lt;/p&gt;
&lt;p&gt;
Deep learning and MCMC with aggVAE for shifting administrative boundaries: mapping malaria prevalence in Kenya. (arXiv:2305.19779v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19779
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;aggVAE&#36827;&#34892;&#28145;&#24230;&#23398;&#20064;&#21644;MCMC&#22788;&#29702;&#34892;&#25919;&#36793;&#30028;&#21464;&#21270;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#26144;&#23556;&#20197;&#21439;&#20026;&#23618;&#32423;&#30340;&#32858;&#21512;&#32423;&#21035;&#25968;&#25454;&#65292;&#24182;&#22788;&#29702;&#34892;&#25919;&#36793;&#30028;&#30340;&#21464;&#21270;&#65292;&#30456;&#27604;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#27169;&#22411;&#30340;&#30142;&#30149;&#26144;&#23556;&#26159;&#20844;&#20849;&#21355;&#29983;&#21644;&#30142;&#30149;&#30417;&#27979;&#20013;&#22522;&#26412;&#30340;&#25919;&#31574;&#20449;&#24687;&#24037;&#20855;&#65292;&#20998;&#23618;&#36125;&#21494;&#26031;&#27169;&#22411;&#26159;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;&#24403;&#22788;&#29702;&#21306;&#22495;&#25968;&#25454;&#65292;&#22914;&#34892;&#25919;&#21306;&#21010;&#21333;&#20301;&#65288;&#20363;&#22914;&#21439;&#25110;&#30465;&#65289;&#30340;&#32858;&#21512;&#25968;&#25454;&#26102;&#65292;&#24120;&#29992;&#30340;&#27169;&#22411;&#20381;&#36182;&#20110;&#21306;&#22495;&#21333;&#20803;&#30340;&#30456;&#37051;&#32467;&#26500;&#20197;&#32771;&#34385;&#31354;&#38388;&#30456;&#20851;&#24615;&#12290;&#30142;&#30149;&#30417;&#27979;&#31995;&#32479;&#30340;&#30446;&#26631;&#26159;&#38543;&#26102;&#38388;&#36319;&#36394;&#30142;&#30149;&#32467;&#26524;&#65292;&#20294;&#22312;&#21361;&#26426;&#24773;&#20917;&#19979;&#65288;&#20363;&#22914;&#25919;&#27835;&#21464;&#21270;&#23548;&#33268;&#34892;&#25919;&#36793;&#30028;&#26356;&#25913;&#65289;&#65292;&#36825;&#23558;&#24102;&#26469;&#25361;&#25112;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#12289;&#23454;&#29992;&#21644;&#26131;&#20110;&#23454;&#26045;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#35813;&#26041;&#26696;&#20381;&#36182;&#20110;&#32452;&#21512;&#28145;&#23618;&#29983;&#25104;&#27169;&#22411;&#21644;&#20840;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;&#25105;&#20204;&#24314;&#31435;&#22312;&#29616;&#26377;&#30340;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;(VAE) &#24037;&#20316;&#19978;&#65292;&#24182;&#23637;&#31034;&#25105;&#20204;&#25552;&#20986;&#30340;&#32858;&#21512;VAE(aggVAE)&#20307;&#31995;&#32467;&#26500;&#21487;&#29992;&#20110;&#22312;&#20197;&#21439;&#20026;&#23618;&#32423;&#30340;&#32858;&#21512;&#32423;&#21035;&#22788;&#29702;&#25968;&#25454;&#65292;&#20197;&#26144;&#23556;&#32943;&#23612;&#20122;&#30340;&#30111;&#30142;&#24739;&#30149;&#29575;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#21487;&#20197;&#20197;&#36830;&#32493;&#30340;&#26041;&#24335;&#32771;&#34385;&#31354;&#38388;&#30456;&#20851;&#24615;&#65292;&#32780;&#19981;&#20381;&#36182;&#20110;&#30456;&#37051;&#24615;&#20551;&#35774;&#65292;&#24182;&#19988;&#33021;&#22815;&#22788;&#29702;&#34892;&#25919;&#36793;&#30028;&#30340;&#21464;&#21270;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#30456;&#27604;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#21644;&#26356;&#20934;&#30830;&#30340;&#30111;&#30142;&#24739;&#30149;&#29575;&#26144;&#23556;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model-based disease mapping remains a fundamental policy-informing tool in public health and disease surveillance with hierarchical Bayesian models being the current state-of-the-art approach. When working with areal data, e.g. aggregates at the administrative unit level such as district or province, routinely used models rely on the adjacency structure of areal units to account for spatial correlations. The goal of disease surveillance systems is to track disease outcomes over time, but this provides challenging in situations of crises, such as political changes, leading to changes of administrative boundaries. Kenya is an example of such country. Moreover, adjacency-based approach ignores the continuous nature of spatial processes and cannot solve the change-of-support problem, i.e. when administrative boundaries change. We present a novel, practical, and easy to implement solution relying on a methodology combining deep generative modelling and fully Bayesian inference. We build on 
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#30340;&#39532;&#23572;&#21487;&#22827;&#36339;&#36291;&#36807;&#31243;&#30340;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#65292;&#21487;&#36890;&#36807;&#21453;&#21521;&#20256;&#25773;&#36827;&#34892;&#35757;&#32451;&#65292;&#29992;&#20110;&#36817;&#20284;&#21518;&#39564;&#39532;&#23572;&#21487;&#22827;&#36339;&#36291;&#36807;&#31243;&#30340;&#21021;&#22987;&#20998;&#24067;&#21644;&#26102;&#38388;&#30456;&#20851;&#30340;&#36716;&#31227;&#27010;&#29575;&#29575;&#65292;&#21516;&#26102;&#22312;&#20808;&#39564;&#36807;&#31243;&#30340;&#26102;&#38388;&#26080;&#20851;&#29575;&#19978;&#20063;&#26377;&#24456;&#22909;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2305.19744</link><description>&lt;p&gt;
&#31070;&#32463;&#39532;&#23572;&#21487;&#22827;&#36339;&#36291;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Neural Markov Jump Processes. (arXiv:2305.19744v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19744
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#30340;&#39532;&#23572;&#21487;&#22827;&#36339;&#36291;&#36807;&#31243;&#30340;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#65292;&#21487;&#36890;&#36807;&#21453;&#21521;&#20256;&#25773;&#36827;&#34892;&#35757;&#32451;&#65292;&#29992;&#20110;&#36817;&#20284;&#21518;&#39564;&#39532;&#23572;&#21487;&#22827;&#36339;&#36291;&#36807;&#31243;&#30340;&#21021;&#22987;&#20998;&#24067;&#21644;&#26102;&#38388;&#30456;&#20851;&#30340;&#36716;&#31227;&#27010;&#29575;&#29575;&#65292;&#21516;&#26102;&#22312;&#20808;&#39564;&#36807;&#31243;&#30340;&#26102;&#38388;&#26080;&#20851;&#29575;&#19978;&#20063;&#26377;&#24456;&#22909;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39532;&#23572;&#21487;&#22827;&#36339;&#36291;&#36807;&#31243;&#26159;&#20855;&#26377;&#24191;&#27867;&#24212;&#29992;&#30340;&#36830;&#32493;&#26102;&#38388;&#38543;&#26426;&#36807;&#31243;&#65292;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#33258;&#28982;&#21644;&#31038;&#20250;&#31185;&#23398;&#39046;&#22495;&#12290;&#23613;&#31649;&#23427;&#20204;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#20294;&#36825;&#20123;&#27169;&#22411;&#20013;&#30340;&#25512;&#26029;&#26159;&#38750;&#24120;&#22797;&#26434;&#30340;&#65292;&#36890;&#24120;&#38656;&#35201;&#36890;&#36807;&#33945;&#29305;&#21345;&#32599;&#25110;&#26399;&#26395;&#26368;&#22823;&#21270;&#26041;&#27861;&#36827;&#34892;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#30340;&#39532;&#23572;&#21487;&#22827;&#36339;&#36291;&#36807;&#31243;&#30340;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#65292;&#24182;&#21487;&#36890;&#36807;&#21453;&#21521;&#20256;&#25773;&#36827;&#34892;&#35757;&#32451;&#12290;&#35813;&#26041;&#27861;&#23398;&#20064;&#20102;&#35266;&#27979;&#25968;&#25454;&#30340;&#31070;&#32463;&#36830;&#32493;&#26102;&#38388;&#34920;&#31034;&#65292;&#29992;&#20110;&#36817;&#20284;&#21518;&#39564;&#39532;&#23572;&#21487;&#22827;&#36339;&#36291;&#36807;&#31243;&#30340;&#21021;&#22987;&#20998;&#24067;&#21644;&#26102;&#38388;&#30456;&#20851;&#30340;&#36716;&#31227;&#27010;&#29575;&#29575;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#20808;&#39564;&#36807;&#31243;&#30340;&#26102;&#38388;&#26080;&#20851;&#29575;&#21017;&#20687;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#19968;&#26679;&#36827;&#34892;&#35757;&#32451;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#25968;&#25454;&#19978;&#27979;&#35797;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#36825;&#20123;&#25968;&#25454;&#26159;&#20174;&#30495;&#23454;&#30340;&#39532;&#23572;&#21487;&#22827;&#36339;&#36291;&#36807;&#31243;&#12289;&#23454;&#39564;&#24615;&#24320;&#20851;&#31163;&#23376;&#36890;&#36947;&#25968;&#25454;&#21644;&#20998;&#23376;&#21160;&#21147;&#23398;&#27169;&#25311;&#20013;&#37319;&#26679;&#24471;&#21040;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Markov jump processes are continuous-time stochastic processes with a wide range of applications in both natural and social sciences. Despite their widespread use, inference in these models is highly non-trivial and typically proceeds via either Monte Carlo or expectation-maximization methods. In this work we introduce an alternative, variational inference algorithm for Markov jump processes which relies on neural ordinary differential equations, and is trainable via back-propagation. Our methodology learns neural, continuous-time representations of the observed data, that are used to approximate the initial distribution and time-dependent transition probability rates of the posterior Markov jump process. The time-independent rates of the prior process are in contrast trained akin to generative adversarial networks. We test our approach on synthetic data sampled from ground-truth Markov jump processes, experimental switching ion channel data and molecular dynamics simulations. Source c
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#22312;&#24179;&#28369;&#22270;&#20449;&#21495;&#20998;&#24067;&#31354;&#38388;&#20013;&#23884;&#20837;&#22270;&#26469;&#23450;&#20041;&#22270;&#30340;&#24179;&#22343;&#20540;&#65292;&#20854;&#20013;&#21487;&#20197;&#20351;&#29992;Wasserstein&#24230;&#37327;&#34913;&#37327;&#22270;&#30456;&#20284;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#37117;&#26377;&#24456;&#22909;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2305.19738</link><description>&lt;p&gt;
&#22270;&#30340;Bures-Wasserstein&#24179;&#22343;&#20540;
&lt;/p&gt;
&lt;p&gt;
Bures-Wasserstein Means of Graphs. (arXiv:2305.19738v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19738
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#22312;&#24179;&#28369;&#22270;&#20449;&#21495;&#20998;&#24067;&#31354;&#38388;&#20013;&#23884;&#20837;&#22270;&#26469;&#23450;&#20041;&#22270;&#30340;&#24179;&#22343;&#20540;&#65292;&#20854;&#20013;&#21487;&#20197;&#20351;&#29992;Wasserstein&#24230;&#37327;&#34913;&#37327;&#22270;&#30456;&#20284;&#24615;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#37117;&#26377;&#24456;&#22909;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#23398;&#20013;&#65292;&#25214;&#21040;&#37319;&#26679;&#25968;&#25454;&#30340;&#24179;&#22343;&#20540;&#26159;&#19968;&#39033;&#22522;&#26412;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#22312;&#25968;&#25454;&#26679;&#26412;&#20026;&#22270;&#23545;&#35937;&#30340;&#24773;&#20917;&#19979;&#65292;&#23450;&#20041;&#24179;&#22343;&#20540;&#26159;&#19968;&#39033;&#22256;&#38590;&#30340;&#20219;&#21153;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#22312;&#24179;&#28369;&#22270;&#20449;&#21495;&#20998;&#24067;&#31354;&#38388;&#20013;&#23884;&#20837;&#22270;&#26469;&#23450;&#20041;&#22270;&#30340;&#24179;&#22343;&#20540;&#65292;&#20854;&#20013;&#21487;&#20197;&#20351;&#29992;Wasserstein&#24230;&#37327;&#34913;&#37327;&#22270;&#30456;&#20284;&#24615;&#12290;&#36890;&#36807;&#22312;&#27492;&#23884;&#20837;&#31354;&#38388;&#20013;&#25214;&#21040;&#24179;&#22343;&#20540;&#65292;&#25105;&#20204;&#21487;&#20197;&#24674;&#22797;&#20445;&#30041;&#32467;&#26500;&#20449;&#24687;&#30340;&#24179;&#22343;&#22270;&#12290;&#25105;&#20204;&#30830;&#23450;&#20102;&#26032;&#30340;&#22270;&#24179;&#22343;&#20540;&#30340;&#23384;&#22312;&#21644;&#21807;&#19968;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#36845;&#20195;&#31639;&#27861;&#26469;&#35745;&#31639;&#23427;&#12290;&#20026;&#20102;&#23637;&#31034;&#25105;&#20204;&#30340;&#26694;&#26550;&#20316;&#20026;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#26377;&#20215;&#20540;&#30340;&#24037;&#20855;&#65292;&#25105;&#20204;&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#21253;&#25324;&#32467;&#26500;&#21270;&#22270;&#30340;k-means&#32858;&#31867;&#12289;&#21151;&#33021;&#24615;&#33041;&#32593;&#32476;&#30340;&#20998;&#31867;&#20197;&#21450;&#22810;&#23618;&#22270;&#30340;&#21322;&#30417;&#30563;&#33410;&#28857;&#20998;&#31867;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#23454;&#29616;&#20102;&#19968;&#33268;&#30340;p&#12290;
&lt;/p&gt;
&lt;p&gt;
Finding the mean of sampled data is a fundamental task in machine learning and statistics. However, in cases where the data samples are graph objects, defining a mean is an inherently difficult task. We propose a novel framework for defining a graph mean via embeddings in the space of smooth graph signal distributions, where graph similarity can be measured using the Wasserstein metric. By finding a mean in this embedding space, we can recover a mean graph that preserves structural information. We establish the existence and uniqueness of the novel graph mean, and provide an iterative algorithm for computing it. To highlight the potential of our framework as a valuable tool for practical applications in machine learning, it is evaluated on various tasks, including k-means clustering of structured graphs, classification of functional brain networks, and semi-supervised node classification in multi-layer graphs. Our experimental results demonstrate that our approach achieves consistent p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#20195;&#29702;&#20998;&#31867;&#25439;&#22833;&#30340;&#20551;&#35774;&#36801;&#31227;&#23398;&#20064;&#30340;&#23398;&#20064;&#29702;&#35770;&#65292;&#36890;&#36807;&#31639;&#27861;&#31283;&#23450;&#24615;&#25552;&#20379;&#20102;&#22312;&#28201;&#21644;&#20551;&#35774;&#19979;&#30340;&#23398;&#20064;&#20445;&#35777;&#65292;&#36866;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.19694</link><description>&lt;p&gt;
&#21033;&#29992;&#20195;&#29702;&#20998;&#31867;&#25439;&#22833;&#30340;&#20551;&#35774;&#36801;&#31227;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Hypothesis Transfer Learning with Surrogate Classification Losses. (arXiv:2305.19694v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19694
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#20195;&#29702;&#20998;&#31867;&#25439;&#22833;&#30340;&#20551;&#35774;&#36801;&#31227;&#23398;&#20064;&#30340;&#23398;&#20064;&#29702;&#35770;&#65292;&#36890;&#36807;&#31639;&#27861;&#31283;&#23450;&#24615;&#25552;&#20379;&#20102;&#22312;&#28201;&#21644;&#20551;&#35774;&#19979;&#30340;&#23398;&#20064;&#20445;&#35777;&#65292;&#36866;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20551;&#35774;&#36801;&#31227;&#23398;&#20064;&#65288;HTL&#65289;&#36890;&#36807;&#20801;&#35768;&#20808;&#21069;&#20219;&#21153;&#65288;&#21363;&#28304;&#20219;&#21153;&#65289;&#21521;&#19968;&#20010;&#26032;&#20219;&#21153;&#65288;&#30446;&#26631;&#20219;&#21153;&#65289;&#36716;&#31227;&#23398;&#20064;&#65292;&#32780;&#26080;&#38656;&#35775;&#38382;&#28304;&#25968;&#25454;&#65292;&#19982;&#39046;&#22495;&#33258;&#36866;&#24212;&#30456;&#23545;&#24212;&#12290;&#20107;&#23454;&#19978;&#65292;HTL&#20165;&#20381;&#36182;&#20110;&#20174;&#28304;&#25968;&#25454;&#23398;&#20064;&#21040;&#30340;&#20551;&#35774;&#65292;&#20813;&#38500;&#20102;&#22823;&#37327;&#25968;&#25454;&#23384;&#20648;&#30340;&#38556;&#30861;&#65292;&#24182;&#25552;&#20379;&#20102;&#24040;&#22823;&#30340;&#23454;&#38469;&#21033;&#30410;&#12290;&#22240;&#27492;&#65292;HTL&#23545;&#20110;&#20381;&#36182;&#20110;&#22823;&#25968;&#25454;&#30340;&#23454;&#38469;&#24212;&#29992;&#38750;&#24120;&#26377;&#21033;&#12290;&#26412;&#25991;&#36890;&#36807;&#31639;&#27861;&#31283;&#23450;&#24615;&#30740;&#31350;HTL&#30340;&#23398;&#20064;&#29702;&#35770;&#65292;&#36825;&#26159;&#19968;&#31181;&#29992;&#20110;&#20998;&#26512;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#26377;&#21560;&#24341;&#21147;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#29305;&#21035;&#26159;&#22312;&#20108;&#20998;&#31867;&#24773;&#20917;&#19979;&#24863;&#20852;&#36259;&#12290;&#25105;&#20204;&#30340;&#31283;&#23450;&#24615;&#20998;&#26512;&#25552;&#20379;&#20102;&#22312;&#28201;&#21644;&#20551;&#35774;&#19979;&#30340;&#23398;&#20064;&#20445;&#35777;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24471;&#20986;&#20102;&#20960;&#20010;&#27604;&#20197;&#21069;&#26356;&#32039;&#23494;&#30340;&#29702;&#35770;&#30028;&#38480;&#65292;&#36825;&#20123;&#30028;&#38480;&#21487;&#20197;&#23454;&#38469;&#24212;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hypothesis transfer learning (HTL) contrasts domain adaptation by allowing for a previous task leverage, named the source, into a new one, the target, without requiring access to the source data. Indeed, HTL relies only on a hypothesis learnt from such source data, relieving the hurdle of expansive data storage and providing great practical benefits. Hence, HTL is highly beneficial for real-world applications relying on big data. The analysis of such a method from a theoretical perspective faces multiple challenges, particularly in classification tasks. This paper deals with this problem by studying the learning theory of HTL through algorithmic stability, an attractive theoretical framework for machine learning algorithms analysis. In particular, we are interested in the statistical behaviour of the regularized empirical risk minimizers in the case of binary classification. Our stability analysis provides learning guarantees under mild assumptions. Consequently, we derive several comp
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35299;&#20915;&#20102;&#24322;&#27493;&#22810;&#20154;&#36172;&#21338;&#38382;&#39064;&#30340;&#38598;&#20013;&#24335;&#24773;&#20917;&#65292;&#25512;&#20986;&#20102;Cautious Greedy&#31639;&#27861;&#65292;&#21487;&#20197;&#20445;&#35777;&#24120;&#25968;&#36951;&#25022;&#65292;&#21516;&#26102;UCB&#31639;&#27861;&#30340;&#33258;&#28982;&#25193;&#23637;&#23637;&#29616;&#20986;&#20102; $\mathcal{O}(\sqrt{T\log(T)})$ &#26497;&#23567;&#21270;&#36951;&#25022;&#12290;</title><link>http://arxiv.org/abs/2305.19691</link><description>&lt;p&gt;
&#24322;&#27493;&#22810;&#20154;&#36172;&#21338;&#38382;&#39064;&#20013;&#30340;&#24120;&#25968;&#25110;&#23545;&#25968;&#36951;&#25022;
&lt;/p&gt;
&lt;p&gt;
Constant or logarithmic regret in asynchronous multiplayer bandits. (arXiv:2305.19691v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19691
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#24322;&#27493;&#22810;&#20154;&#36172;&#21338;&#38382;&#39064;&#30340;&#38598;&#20013;&#24335;&#24773;&#20917;&#65292;&#25512;&#20986;&#20102;Cautious Greedy&#31639;&#27861;&#65292;&#21487;&#20197;&#20445;&#35777;&#24120;&#25968;&#36951;&#25022;&#65292;&#21516;&#26102;UCB&#31639;&#27861;&#30340;&#33258;&#28982;&#25193;&#23637;&#23637;&#29616;&#20986;&#20102; $\mathcal{O}(\sqrt{T\log(T)})$ &#26497;&#23567;&#21270;&#36951;&#25022;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#30001;&#20110;&#22312;&#35748;&#30693;&#26080;&#32447;&#30005;&#32593;&#32476;&#20013;&#30340;&#24212;&#29992;&#65292;&#22810;&#20154;&#36172;&#21338;&#38382;&#39064;&#24471;&#21040;&#20102;&#24191;&#27867;&#30740;&#31350;&#12290;&#34429;&#28982;&#25991;&#29486;&#22823;&#22810;&#32771;&#34385;&#21516;&#27493;&#29609;&#23478;&#65292;&#20294;&#26080;&#32447;&#30005;&#32593;&#32476;&#65288;&#20363;&#22914;&#29289;&#32852;&#32593;&#65289; tend to have asynchronous devices&#12290;&#36825;&#24341;&#21457;&#20102;&#26356;&#21152;&#22256;&#38590;&#30340;&#24322;&#27493;&#22810;&#20154;&#36172;&#21338;&#38382;&#39064;&#65292;&#39318;&#20808;&#29992;&#25506;&#32034;&#28982;&#21518;&#25215;&#35834;&#65288;ETC&#65289;&#31639;&#27861;&#35299;&#20915;&#65288;&#35831;&#21442;&#35265; Dakdouk&#65292;2022&#65289;&#65292;&#36951;&#25022;&#19978;&#38480;&#20026; $\mathcal{O}(T^{\frac{2}{3}})$&#12290;&#29978;&#33267;&#22312;&#32771;&#34385;&#20998;&#25955;&#21270;&#20043;&#21069;&#65292;&#29702;&#35299;&#38598;&#20013;&#24335;&#24773;&#20917;&#20173;&#28982;&#26159;&#19968;&#20010;&#25361;&#25112;&#65292;&#22240;&#20026;&#19981;&#30693;&#36947;&#26159;&#21542;&#21487;&#33021;&#24471;&#21040;&#23567;&#20110; $\Omega(T^\frac{2}{3})$ &#30340;&#36951;&#25022;&#12290; &#25105;&#20204;&#23545;&#36825;&#20010;&#38382;&#39064;&#20316;&#20986;&#20102;&#32943;&#23450;&#22238;&#31572;&#65292;&#22240;&#20026;UCB&#30340;&#33258;&#28982;&#25193;&#23637;&#23637;&#29616;&#20986;&#20102; $\mathcal{O}(\sqrt{T\log(T)})$ &#26497;&#23567;&#21270;&#36951;&#25022;&#12290;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#21483;&#20570;&#8220;&#35880;&#24910;&#36138;&#23146;&#8221;&#30340;&#38598;&#20013;&#24335;&#31639;&#27861;&#65292;&#22914;&#26524;&#26368;&#20248;&#31574;&#30053;&#33267;&#23569;&#23558;&#19968;&#20010;&#29609;&#23478;&#25351;&#23450;&#22312;&#27599;&#20010;&#27494;&#22120;&#19978;&#65288;&#34987;&#35777;&#26126;&#20250;&#20986;&#29616;&#36825;&#31181;&#24773;&#20917;&#65289;&#65292;&#21017;&#21487;&#20197;&#20135;&#29983;&#24120;&#25968;&#20445;&#35777;&#30340;&#36951;&#25022;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multiplayer bandits have recently been extensively studied because of their application to cognitive radio networks.  While the literature mostly considers synchronous players, radio networks (e.g. for IoT) tend to have asynchronous devices. This motivates the harder, asynchronous multiplayer bandits problem, which was first tackled with an explore-then-commit (ETC) algorithm (see Dakdouk, 2022), with a regret upper-bound in $\mathcal{O}(T^{\frac{2}{3}})$. Before even considering decentralization, understanding the centralized case was still a challenge as it was unknown whether getting a regret smaller than $\Omega(T^{\frac{2}{3}})$ was possible.  We answer positively this question, as a natural extension of UCB exhibits a $\mathcal{O}(\sqrt{T\log(T)})$ minimax regret.  More importantly, we introduce Cautious Greedy, a centralized algorithm that yields constant instance-dependent regret if the optimal policy assigns at least one player on each arm (a situation that is proved to occur 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#25968;&#20540;&#27169;&#25311;&#26102;&#38388;&#28436;&#21270;&#34203;&#23450;&#35860;&#26041;&#31243;&#65292;&#21033;&#29992;&#39532;&#23572;&#21487;&#22827;&#25193;&#25955;&#37319;&#26679;&#26469;&#36866;&#24212;&#27874;&#20989;&#25968;&#30340;&#28508;&#22312;&#20302;&#32500;&#32467;&#26500;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#38543;&#26426;&#37327;&#23376;&#21147;&#23398;&#26041;&#31243;&#65292;&#20855;&#26377;&#32447;&#24615;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;&#25968;&#20540;&#27169;&#25311;&#26174;&#31034;&#20986;&#26174;&#30528;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2305.19685</link><description>&lt;p&gt;
&#28145;&#24230;&#38543;&#26426;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
Deep Stochastic Mechanics. (arXiv:2305.19685v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19685
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#25968;&#20540;&#27169;&#25311;&#26102;&#38388;&#28436;&#21270;&#34203;&#23450;&#35860;&#26041;&#31243;&#65292;&#21033;&#29992;&#39532;&#23572;&#21487;&#22827;&#25193;&#25955;&#37319;&#26679;&#26469;&#36866;&#24212;&#27874;&#20989;&#25968;&#30340;&#28508;&#22312;&#20302;&#32500;&#32467;&#26500;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#38543;&#26426;&#37327;&#23376;&#21147;&#23398;&#26041;&#31243;&#65292;&#20855;&#26377;&#32447;&#24615;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;&#25968;&#20540;&#27169;&#25311;&#26174;&#31034;&#20986;&#26174;&#30528;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#25968;&#20540;&#27169;&#25311;&#26102;&#38388;&#28436;&#21270;&#34203;&#23450;&#35860;&#26041;&#31243;&#65292;&#21463;&#38543;&#26426;&#21147;&#23398;&#21644;&#29983;&#25104;&#24615;&#25193;&#25955;&#27169;&#22411;&#30340;&#21551;&#21457;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20801;&#35768;&#25105;&#20204;&#36890;&#36807;&#20174;&#39532;&#23572;&#21487;&#22827;&#25193;&#25955;&#20013;&#37319;&#26679;&#26469;&#36866;&#24212;&#27874;&#20989;&#25968;&#28508;&#22312;&#30340;&#20302;&#32500;&#32467;&#26500;&#65292;&#22240;&#27492;&#21487;&#20197;&#22312;&#26356;&#39640;&#30340;&#32500;&#24230;&#19978;&#38477;&#20302;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26032;&#30340;&#38543;&#26426;&#37327;&#23376;&#21147;&#23398;&#26041;&#31243;&#65292;&#32467;&#26524;&#20855;&#26377;&#19982;&#32500;&#25968;&#25968;&#37327;&#32447;&#24615;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;&#25968;&#20540;&#27169;&#25311;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#21457;&#29616;&#65292;&#24182;&#26174;&#31034;&#20986;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#20854;&#20182;&#29992;&#20110;&#37327;&#23376;&#21147;&#23398;&#30340;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#30456;&#27604;&#20855;&#26377;&#26174;&#30528;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a novel deep-learning-based approach for numerical simulation of a time-evolving Schr\"odinger equation inspired by stochastic mechanics and generative diffusion models. Unlike existing approaches, which exhibit computational complexity that scales exponentially in the problem dimension, our method allows us to adapt to the latent low-dimensional structure of the wave function by sampling from the Markovian diffusion. Depending on the latent dimension, our method may have far lower computational complexity in higher dimensions. Moreover, we propose novel equations for stochastic quantum mechanics, resulting in linear computational complexity with respect to the number of dimensions. Numerical simulations verify our theoretical findings and show a significant advantage of our method compared to other deep-learning-based approaches used for quantum mechanics.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;Metropolis-Hastings&#32806;&#21512;&#21644;&#23616;&#37096;&#27169;&#24577;&#21021;&#22987;&#21270;&#30340;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#28145;&#24230;&#29627;&#23572;&#20857;&#26364;&#26426;&#20013;&#30340;&#20559;&#24046;&#26799;&#24230;&#20272;&#35745;&#38382;&#39064;&#65292;&#20351;&#24471;DBMs&#21487;&#20197;&#31471;&#21040;&#31471;&#22320;&#35757;&#32451;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#19982;&#20854;&#20182;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30456;&#24403;&#30340;&#29983;&#25104;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.19684</link><description>&lt;p&gt;
&#36890;&#36807;&#23616;&#37096;&#27169;&#24577;&#21021;&#22987;&#21270;&#21644;&#26080;&#20559;&#24046;&#23545;&#27604;&#25955;&#24230;&#23454;&#29616;&#28145;&#24230;&#29627;&#23572;&#20857;&#26364;&#26426;&#30340;&#31471;&#21040;&#31471;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
End-to-end Training of Deep Boltzmann Machines by Unbiased Contrastive Divergence with Local Mode Initialization. (arXiv:2305.19684v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19684
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;Metropolis-Hastings&#32806;&#21512;&#21644;&#23616;&#37096;&#27169;&#24577;&#21021;&#22987;&#21270;&#30340;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#28145;&#24230;&#29627;&#23572;&#20857;&#26364;&#26426;&#20013;&#30340;&#20559;&#24046;&#26799;&#24230;&#20272;&#35745;&#38382;&#39064;&#65292;&#20351;&#24471;DBMs&#21487;&#20197;&#31471;&#21040;&#31471;&#22320;&#35757;&#32451;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#19982;&#20854;&#20182;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30456;&#24403;&#30340;&#29983;&#25104;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35299;&#20915;&#20102;&#28145;&#24230;&#29627;&#23572;&#20857;&#26364;&#26426;&#65288;DBMs&#65289;&#20013;&#30340;&#20559;&#24046;&#26799;&#24230;&#20272;&#35745;&#38382;&#39064;&#12290;&#29616;&#26377;&#30340;&#33719;&#21462;&#26080;&#20559;&#20272;&#35745;&#37327;&#30340;&#26041;&#27861;&#20351;&#29992;&#22522;&#20110;Gibbs&#37319;&#26679;&#30340;&#26368;&#22823;&#32806;&#21512;&#65292;&#20294;&#24403;&#29366;&#24577;&#26159;&#39640;&#32500;&#26102;&#65292;&#20854;&#25910;&#25947;&#38656;&#35201;&#24456;&#38271;&#26102;&#38388;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;Metropolis-Hastings&#30340;&#32806;&#21512;&#65292;&#24182;&#22260;&#32469;&#30446;&#26631;&#20998;&#24067;&#30340;&#23616;&#37096;&#27169;&#24577;&#21021;&#22987;&#21270;&#29366;&#24577;&#12290;&#30001;&#20110;MH&#20542;&#21521;&#20110;&#25298;&#32477;&#25552;&#26696;&#65292;&#36825;&#31181;&#32806;&#21512;&#26377;&#24456;&#39640;&#30340;&#27010;&#29575;&#22312;&#19968;&#27493;&#20869;&#25910;&#25947;&#65292;&#22240;&#27492;&#20855;&#26377;&#39640;&#25928;&#24615;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#22312;&#19981;&#36827;&#34892;&#36138;&#24515;&#39044;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#31471;&#21040;&#31471;&#22320;&#35757;&#32451;DBMs&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#20123;&#23454;&#29992;&#25216;&#26415;&#65292;&#20197;&#36827;&#19968;&#27493;&#25552;&#39640;DBMs&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#35757;&#32451;&#31639;&#27861;&#20351;DBMs&#33021;&#22815;&#23637;&#29616;&#20986;&#19982;&#20854;&#20182;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30456;&#24403;&#30340;&#29983;&#25104;&#24615;&#33021;&#65292;&#22312;MNIST&#19978;&#36798;&#21040;&#20102;10.33&#30340;FID&#20998;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
We address the problem of biased gradient estimation in deep Boltzmann machines (DBMs). The existing method to obtain an unbiased estimator uses a maximal coupling based on a Gibbs sampler, but when the state is high-dimensional, it takes a long time to converge. In this study, we propose to use a coupling based on the Metropolis-Hastings (MH) and to initialize the state around a local mode of the target distribution. Because of the propensity of MH to reject proposals, the coupling tends to converge in only one step with a high probability, leading to high efficiency. We find that our method allows DBMs to be trained in an end-to-end fashion without greedy pretraining. We also propose some practical techniques to further improve the performance of DBMs. We empirically demonstrate that our training algorithm enables DBMs to show comparable generative performance to other deep generative models, achieving the FID score of 10.33 for MNIST.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#32447;&#23398;&#20064;&#28216;&#25103;&#8220;&#27867;&#21270;&#28216;&#25103;&#8221;&#30340;&#26694;&#26550;&#65292;&#23558;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#30340;&#34920;&#29616;&#21644;&#32479;&#35745;&#23398;&#20064;&#31639;&#27861;&#30340;&#27867;&#21270;&#30028;&#38480;&#32852;&#31995;&#20102;&#36215;&#26469;&#65292;&#24182;&#24471;&#20986;&#20102;&#19968;&#20123;&#26631;&#20934;&#30340;&#27867;&#21270;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2305.19674</link><description>&lt;p&gt;
&#22312;&#32447;&#21040;PAC&#30340;&#36716;&#25442;: &#36890;&#36807;&#36951;&#25022;&#20998;&#26512;&#24471;&#20986;&#27867;&#21270;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Online-to-PAC Conversions: Generalization Bounds via Regret Analysis. (arXiv:2305.19674v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19674
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#32447;&#23398;&#20064;&#28216;&#25103;&#8220;&#27867;&#21270;&#28216;&#25103;&#8221;&#30340;&#26694;&#26550;&#65292;&#23558;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#30340;&#34920;&#29616;&#21644;&#32479;&#35745;&#23398;&#20064;&#31639;&#27861;&#30340;&#27867;&#21270;&#30028;&#38480;&#32852;&#31995;&#20102;&#36215;&#26469;&#65292;&#24182;&#24471;&#20986;&#20102;&#19968;&#20123;&#26631;&#20934;&#30340;&#27867;&#21270;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#22312;&#32447;&#23398;&#20064;&#30340;&#35270;&#35282;&#25512;&#23548;&#20986;&#32479;&#35745;&#23398;&#20064;&#31639;&#27861;&#30340;&#27867;&#21270;&#30028;&#38480;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#22312;&#32447;&#23398;&#20064;&#28216;&#25103;&#31216;&#20026;&#8220;&#27867;&#21270;&#28216;&#25103;&#8221;&#65292;&#20854;&#20013;&#22312;&#32447;&#23398;&#20064;&#22120;&#35797;&#22270;&#19982;&#22266;&#23450;&#30340;&#32479;&#35745;&#23398;&#20064;&#31639;&#27861;&#31454;&#20105;&#65292;&#39044;&#27979;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#28857;&#35757;&#32451;&#38598;&#19978;&#30340;&#27867;&#21270;&#38388;&#38553;&#24207;&#21015;&#12290;&#25105;&#20204;&#36890;&#36807;&#23637;&#31034;&#22312;&#36825;&#20010;&#28216;&#25103;&#20013;&#23384;&#22312;&#26377;&#30028;&#36951;&#25022;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#19982;&#32479;&#35745;&#23398;&#20064;&#35774;&#32622;&#20043;&#38388;&#30340;&#32852;&#31995;&#26469;&#24314;&#31435;&#36825;&#31181;&#20851;&#32852;&#65292;&#36825;&#24847;&#21619;&#30528;&#32479;&#35745;&#23398;&#20064;&#31639;&#27861;&#30340;&#27867;&#21270;&#38169;&#35823;&#23384;&#22312;&#19968;&#20010;&#30028;&#38480;&#65292;&#30452;&#21040;&#19982;&#32479;&#35745;&#23398;&#20064;&#26041;&#27861;&#30340;&#22797;&#26434;&#24615;&#26080;&#20851;&#30340;&#38789;&#27987;&#24230;&#39033;&#12290;&#36825;&#31181;&#25216;&#26415;&#20801;&#35768;&#25105;&#20204;&#24674;&#22797;&#20960;&#20010;&#26631;&#20934;&#30340;&#27867;&#21270;&#38480;&#21046;&#65292;&#21253;&#25324;&#19968;&#31995;&#21015;&#30340;PAC-Bayesian&#20445;&#35777;&#21644;&#20449;&#24687;&#29702;&#35770;&#20445;&#35777;&#65292;&#20197;&#21450;&#23427;&#20204;&#30340;&#25512;&#24191;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a new framework for deriving bounds on the generalization bound of statistical learning algorithms from the perspective of online learning. Specifically, we construct an online learning game called the "generalization game", where an online learner is trying to compete with a fixed statistical learning algorithm in predicting the sequence of generalization gaps on a training set of i.i.d. data points. We establish a connection between the online and statistical learning setting by showing that the existence of an online learning algorithm with bounded regret in this game implies a bound on the generalization error of the statistical learning algorithm, up to a martingale concentration term that is independent of the complexity of the statistical learning method. This technique allows us to recover several standard generalization bounds including a range of PAC-Bayesian and information-theoretic guarantees, as well as generalizations thereof.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;ReLU&#32593;&#32476;&#20013;&#30340;&#25104;&#23545;&#23398;&#20064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;&#19968;&#33324;&#25439;&#22833;&#20989;&#25968;&#30340;&#35823;&#24046;&#20272;&#35745;&#30340;&#23574;&#38160;&#30028;&#38480;&#65292;&#24182;&#22522;&#20110;&#25104;&#23545;&#26368;&#23567;&#20108;&#20056;&#25439;&#22833;&#24471;&#20986;&#20960;&#20046;&#26368;&#20248;&#30340;&#36807;&#24230;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2305.19640</link><description>&lt;p&gt;
&#28145;&#24230;ReLU&#32593;&#32476;&#20013;&#30340;&#25104;&#23545;&#23398;&#20064;&#26368;&#20248;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Optimal Estimates for Pairwise Learning with Deep ReLU Networks. (arXiv:2305.19640v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19640
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;ReLU&#32593;&#32476;&#20013;&#30340;&#25104;&#23545;&#23398;&#20064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;&#19968;&#33324;&#25439;&#22833;&#20989;&#25968;&#30340;&#35823;&#24046;&#20272;&#35745;&#30340;&#23574;&#38160;&#30028;&#38480;&#65292;&#24182;&#22522;&#20110;&#25104;&#23545;&#26368;&#23567;&#20108;&#20056;&#25439;&#22833;&#24471;&#20986;&#20960;&#20046;&#26368;&#20248;&#30340;&#36807;&#24230;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25104;&#23545;&#23398;&#20064;&#25351;&#30340;&#26159;&#22312;&#25439;&#22833;&#20989;&#25968;&#20013;&#32771;&#34385;&#19968;&#23545;&#26679;&#26412;&#30340;&#23398;&#20064;&#20219;&#21153;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;ReLU&#32593;&#32476;&#20013;&#30340;&#25104;&#23545;&#23398;&#20064;&#65292;&#24182;&#20272;&#35745;&#20102;&#36807;&#24230;&#27867;&#21270;&#35823;&#24046;&#12290;&#23545;&#20110;&#28385;&#36275;&#26576;&#20123;&#28201;&#21644;&#26465;&#20214;&#30340;&#19968;&#33324;&#25439;&#22833;&#20989;&#25968;&#65292;&#24314;&#31435;&#20102;&#35823;&#24046;&#20272;&#35745;&#30340;&#23574;&#38160;&#30028;&#38480;&#65292;&#20854;&#35823;&#24046;&#20272;&#35745;&#30340;&#38454;&#25968;&#20026;O&#65288;&#65288;Vlog&#65288;n&#65289;/ n&#65289;1 /&#65288;2-&#946;&#65289;&#65289;&#12290;&#29305;&#21035;&#22320;&#65292;&#23545;&#20110;&#25104;&#23545;&#26368;&#23567;&#20108;&#20056;&#25439;&#22833;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#36807;&#24230;&#27867;&#21270;&#35823;&#24046;&#30340;&#20960;&#20046;&#26368;&#20248;&#30028;&#38480;&#65292;&#22312;&#30495;&#23454;&#30340;&#39044;&#27979;&#22120;&#28385;&#36275;&#26576;&#20123;&#20809;&#28369;&#24615;&#27491;&#21017;&#24615;&#26102;&#65292;&#26368;&#20248;&#30028;&#38480;&#36798;&#21040;&#20102;&#26368;&#23567;&#21270;&#30028;&#38480;&#65292;&#24046;&#36317;&#20165;&#20026;&#23545;&#25968;&#39033;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pairwise learning refers to learning tasks where a loss takes a pair of samples into consideration. In this paper, we study pairwise learning with deep ReLU networks and estimate the excess generalization error. For a general loss satisfying some mild conditions, a sharp bound for the estimation error of order $O((V\log(n) /n)^{1/(2-\beta)})$ is established. In particular, with the pairwise least squares loss, we derive a nearly optimal bound of the excess generalization error which achieves the minimax lower bound up to a logrithmic term when the true predictor satisfies some smoothness regularities.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#21442;&#25968;&#30340;&#25237;&#24433;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#33021;&#22815;&#33258;&#36866;&#24212;&#22320;&#22788;&#29702;&#21021;&#22987;&#28857;&#19982;&#26368;&#20248;&#35299;&#20043;&#38388;&#30340;&#36317;&#31163;&#20197;&#21450;&#23376;&#26799;&#24230;&#30340;&#24179;&#26041;&#21644;&#65292;&#36866;&#29992;&#20110;&#22312;&#38381;&#21512;&#20984;&#38598;&#19978;&#26368;&#23567;&#21270;&#20984;&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#24182;&#19988;&#33021;&#22815;&#22312;&#28385;&#36275;&#23545;&#25968;&#22240;&#23376;&#19979;&#30340;&#32047;&#31215;&#36951;&#25022;&#30340;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2305.19605</link><description>&lt;p&gt;
&#26080;&#21442;&#25968;&#25237;&#24433;&#26799;&#24230;&#19979;&#38477;
&lt;/p&gt;
&lt;p&gt;
Parameter-free projected gradient descent. (arXiv:2305.19605v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19605
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#21442;&#25968;&#30340;&#25237;&#24433;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#33021;&#22815;&#33258;&#36866;&#24212;&#22320;&#22788;&#29702;&#21021;&#22987;&#28857;&#19982;&#26368;&#20248;&#35299;&#20043;&#38388;&#30340;&#36317;&#31163;&#20197;&#21450;&#23376;&#26799;&#24230;&#30340;&#24179;&#26041;&#21644;&#65292;&#36866;&#29992;&#20110;&#22312;&#38381;&#21512;&#20984;&#38598;&#19978;&#26368;&#23567;&#21270;&#20984;&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#24182;&#19988;&#33021;&#22815;&#22312;&#28385;&#36275;&#23545;&#25968;&#22240;&#23376;&#19979;&#30340;&#32047;&#31215;&#36951;&#25022;&#30340;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#38381;&#21512;&#20984;&#38598;&#19978;&#26368;&#23567;&#21270;&#20984;&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#20351;&#29992;&#25237;&#24433;&#26799;&#24230;&#19979;&#38477;&#65288;PGD&#65289;&#36827;&#34892;&#27714;&#35299;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#23436;&#20840;&#26080;&#21442;&#25968;&#29256;&#26412;&#30340;AdaGrad&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#33258;&#36866;&#24212;&#22320;&#22788;&#29702;&#21021;&#22987;&#28857;&#19982;&#26368;&#20248;&#35299;&#20043;&#38388;&#30340;&#36317;&#31163;&#20197;&#21450;&#23376;&#26799;&#24230;&#30340;&#24179;&#26041;&#21644;&#12290;&#19982;&#32463;&#20856;&#30340;PGD&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#33021;&#22815;&#22788;&#29702;&#25237;&#24433;&#27493;&#39588;&#65292;&#26080;&#38656;&#37325;&#26032;&#21551;&#21160;&#12289;&#36712;&#36857;&#21152;&#26435;&#25110;&#39069;&#22806;&#30340;&#26799;&#24230;&#35780;&#20272;&#12290;&#21516;&#26102;&#65292;&#23427;&#36824;&#28385;&#36275;&#20102;&#22312;&#23545;&#25968;&#22240;&#23376;&#19979;&#30340;&#32047;&#31215;&#36951;&#25022;&#30340;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#23558;&#35813;&#26041;&#27861;&#25193;&#23637;&#21040;&#38543;&#26426;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#24182;&#36827;&#34892;&#20102;&#25903;&#25345;&#25152;&#24320;&#21457;&#30340;&#29702;&#35770;&#30340;&#25968;&#20540;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of minimizing a convex function over a closed convex set, with Projected Gradient Descent (PGD). We propose a fully parameter-free version of AdaGrad, which is adaptive to the distance between the initialization and the optimum, and to the sum of the square norm of the subgradients. Our algorithm is able to handle projection steps, does not involve restarts, reweighing along the trajectory or additional gradient evaluations compared to the classical PGD. It also fulfills optimal rates of convergence for cumulative regret up to logarithmic factors. We provide an extension of our approach to stochastic optimization and conduct numerical experiments supporting the developed theory.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#24102;&#24314;&#35758;&#30340;&#20027;&#21160;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#38382;&#39064;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#33258;&#36866;&#24212;&#25628;&#32034;&#31639;&#27861;&#65292;&#21487;&#20197;&#20174;&#24314;&#35758;&#20013;&#21463;&#30410;&#65292;&#21363;&#20351;&#24314;&#35758;&#26159;&#20219;&#24847;&#31967;&#31957;&#30340;&#24773;&#20917;&#19979;&#65292;&#20173;&#28982;&#20855;&#26377;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2305.19588</link><description>&lt;p&gt;
&#24102;&#24314;&#35758;&#30340;&#20027;&#21160;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Active causal structure learning with advice. (arXiv:2305.19588v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19588
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#24102;&#24314;&#35758;&#30340;&#20027;&#21160;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#38382;&#39064;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#33258;&#36866;&#24212;&#25628;&#32034;&#31639;&#27861;&#65292;&#21487;&#20197;&#20174;&#24314;&#35758;&#20013;&#21463;&#30410;&#65292;&#21363;&#20351;&#24314;&#35758;&#26159;&#20219;&#24847;&#31967;&#31957;&#30340;&#24773;&#20917;&#19979;&#65292;&#20173;&#28982;&#20855;&#26377;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#24102;&#24314;&#35758;&#30340;&#20027;&#21160;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#38382;&#39064;&#12290;&#22312;&#20856;&#22411;&#30340;&#30740;&#31350;&#20013;&#65292;&#23398;&#20064;&#31639;&#27861;&#38024;&#23545;&#35266;&#27979;&#20998;&#24067;&#33719;&#24471;&#26412;&#36136;&#22270;&#65292;&#24182;&#34987;&#35201;&#27714;&#22312;&#26368;&#23567;&#21270;&#24178;&#39044;&#27425;&#25968;&#30340;&#21516;&#26102;&#24674;&#22797;&#20986;&#28508;&#22312;&#30340;&#22240;&#26524;&#26377;&#21521;&#26080;&#29615;&#22270;(DAG) $G^*$&#12290;&#22312;&#25105;&#20204;&#30340;&#38382;&#39064;&#35774;&#23450;&#20013;&#65292;&#38500;&#20102;&#20851;&#20110; $G^*$&#30340;&#24517;&#35201;&#20449;&#24687;&#22806;&#65292;&#20363;&#22914;&#19968;&#20010;&#22768;&#31216;&#26159; $G^*$&#30340;DAG $G$&#65292;&#25105;&#20204;&#36824;&#20250;&#39069;&#22806;&#33719;&#24471;&#20851;&#20110; $G^*$&#30340;&#20391;&#38754;&#20449;&#24687;&#12290;&#25105;&#20204;&#24819;&#30693;&#36947;&#65292;&#24403;&#24314;&#35758;&#25509;&#36817;&#27491;&#30830;&#26102;&#65292;&#23398;&#20064;&#31639;&#27861;&#26159;&#21542;&#21487;&#20197;&#20174;&#24314;&#35758;&#20013;&#21463;&#30410;&#65292;&#21516;&#26102;&#21363;&#20351;&#24314;&#35758;&#26159;&#20219;&#24847;&#31967;&#31957;&#30340;&#24773;&#20917;&#19979;&#65292;&#20173;&#28982;&#20855;&#26377;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#20445;&#35777;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#19982;&#20851;&#20110;&#24102;&#39044;&#27979;&#31639;&#27861;&#30340;&#19981;&#26029;&#22686;&#21152;&#30340;&#30740;&#31350;&#39046;&#22495;&#30456;&#21516;&#12290;&#24403;&#24314;&#35758;&#26159;&#26377;&#21521;&#26080;&#29615;&#22270;$G$&#26102;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#33258;&#36866;&#24212;&#25628;&#32034;&#31639;&#27861;&#26469;&#24674;&#22797; $G^*$&#65292;&#20854;&#24178;&#39044;&#25104;&#26412;&#26368;&#22810;&#20026;&#39564;&#35777;$G^*$&#30340;&#25104;&#26412;&#30340;$O(max\{1, \log \psi\})$&#20493;&#12290;&#36825;&#37324;&#65292;$\psi$&#26159;$G$&#21644;$G^*$&#20043;&#38388;&#30340;&#36317;&#31163;&#24230;&#37327;&#65292;&#23427;&#34987;&#19978;&#30028;&#32422;&#26463;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce the problem of active causal structure learning with advice. In the typical well-studied setting, the learning algorithm is given the essential graph for the observational distribution and is asked to recover the underlying causal directed acyclic graph (DAG) $G^*$ while minimizing the number of interventions made. In our setting, we are additionally given side information about $G^*$ as advice, e.g. a DAG $G$ purported to be $G^*$. We ask whether the learning algorithm can benefit from the advice when it is close to being correct, while still having worst-case guarantees even when the advice is arbitrarily bad. Our work is in the same space as the growing body of research on algorithms with predictions. When the advice is a DAG $G$, we design an adaptive search algorithm to recover $G^*$ whose intervention cost is at most $O(\max\{1, \log \psi\})$ times the cost for verifying $G^*$; here, $\psi$ is a distance measure between $G$ and $G^*$ that is upper bounded by the numb
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;Hadamard&#21442;&#25968;&#21270;&#19979;&#31574;&#30053;&#26799;&#24230;&#30340;&#25910;&#25947;&#24615;&#65292;&#35777;&#26126;&#20102;&#31639;&#27861;&#20855;&#26377;&#20840;&#23616;&#32447;&#24615;&#25910;&#25947;&#24615;&#21644;&#23616;&#37096;&#32447;&#24615;&#25910;&#25947;&#36895;&#24230;&#26356;&#24555;&#30340;&#24615;&#36136;&#12290;</title><link>http://arxiv.org/abs/2305.19575</link><description>&lt;p&gt;
&#20851;&#20110;Hadamard&#21442;&#25968;&#21270;&#19979;&#31574;&#30053;&#26799;&#24230;&#30340;&#32447;&#24615;&#25910;&#25947;&#24615;.
&lt;/p&gt;
&lt;p&gt;
On the Linear Convergence of Policy Gradient under Hadamard Parameterization. (arXiv:2305.19575v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19575
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;Hadamard&#21442;&#25968;&#21270;&#19979;&#31574;&#30053;&#26799;&#24230;&#30340;&#25910;&#25947;&#24615;&#65292;&#35777;&#26126;&#20102;&#31639;&#27861;&#20855;&#26377;&#20840;&#23616;&#32447;&#24615;&#25910;&#25947;&#24615;&#21644;&#23616;&#37096;&#32447;&#24615;&#25910;&#25947;&#36895;&#24230;&#26356;&#24555;&#30340;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#34920;&#26684;&#24335;&#35774;&#32622;&#19979;Hadamard&#21442;&#25968;&#21270;&#19979;&#30830;&#23450;&#24615;&#31574;&#30053;&#26799;&#24230;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#24314;&#31435;&#20102;&#31639;&#27861;&#30340;&#20840;&#23616;&#32447;&#24615;&#25910;&#25947;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#20102;&#38169;&#35823;&#22312;&#25152;&#26377;&#36845;&#20195;&#20013;&#20197;$O(\frac{1}{k})$&#30340;&#36895;&#29575;&#19979;&#38477;&#12290;&#22522;&#20110;&#36825;&#20010;&#32467;&#26524;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#22312;$k_0$&#27425;&#36845;&#20195;&#20043;&#21518;&#20855;&#26377;&#26356;&#24555;&#30340;&#23616;&#37096;&#32447;&#24615;&#25910;&#25947;&#36895;&#24230;&#65292;&#20854;&#20013;$k_0$&#26159;&#20165;&#20381;&#36182;&#20110;MDP&#38382;&#39064;&#21644;&#27493;&#38271;&#30340;&#24120;&#25968;&#12290;&#24635;&#20307;&#32780;&#35328;&#65292;&#35813;&#31639;&#27861;&#26174;&#31034;&#20102;&#19968;&#20010;&#36739;&#24369;&#24120;&#25968;&#30340;&#32447;&#24615;&#25910;&#25947;&#29575;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#23616;&#37096;&#32447;&#24615;&#25910;&#25947;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
The convergence of deterministic policy gradient under the Hadamard parametrization is studied in the tabular setting and the global linear convergence of the algorithm is established. To this end, we first show that the error decreases at an $O(\frac{1}{k})$ rate for all the iterations. Based on this result, we further show that the algorithm has a faster local linear convergence rate after $k_0$ iterations, where $k_0$ is a constant that only depends on the MDP problem and the step size. Overall, the algorithm displays a linear convergence rate for all the iterations with a loose constant than that for the local linear convergence rate.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#26032;&#31639;&#27861;&#26469;&#35299;&#20915;&#22312;&#32447;&#26631;&#31614;&#31227;&#20301;&#38382;&#39064;&#65292;&#22312;&#26080;&#38656;&#20808;&#39564;&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#36890;&#36807;&#22312;&#32447;&#22238;&#24402;&#20445;&#35777;&#20102;&#26368;&#20248;&#21160;&#24577;&#36951;&#25022;&#65292;&#24182;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#22330;&#26223;&#20013;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.19570</link><description>&lt;p&gt;
&#22312;&#32447;&#26631;&#31614;&#31227;&#20301;&#65306;&#26368;&#20248;&#21160;&#24577;&#36951;&#25022;&#30456;&#36935;&#23454;&#29992;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Online Label Shift: Optimal Dynamic Regret meets Practical Algorithms. (arXiv:2305.19570v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19570
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#26032;&#31639;&#27861;&#26469;&#35299;&#20915;&#22312;&#32447;&#26631;&#31614;&#31227;&#20301;&#38382;&#39064;&#65292;&#22312;&#26080;&#38656;&#20808;&#39564;&#30693;&#35782;&#30340;&#24773;&#20917;&#19979;&#36890;&#36807;&#22312;&#32447;&#22238;&#24402;&#20445;&#35777;&#20102;&#26368;&#20248;&#21160;&#24577;&#36951;&#25022;&#65292;&#24182;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#22330;&#26223;&#20013;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20851;&#27880;&#30417;&#30563;&#21644;&#26080;&#30417;&#30563;&#22312;&#32447;&#26631;&#31614;&#31227;&#20301;&#65292;&#20854;&#20013;&#31867;&#36793;&#38469; $Q(y)$ &#21464;&#21270;&#65292;&#20294;&#31867;&#26465;&#20214; $Q(x|y)$ &#20445;&#25345;&#19981;&#21464;&#12290;&#22312;&#26080;&#30417;&#30563;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#36866;&#24212;&#19968;&#20010;&#20174;&#26576;&#20123;&#31163;&#32447;&#26631;&#35760;&#25968;&#25454;&#35757;&#32451;&#30340;&#23398;&#20064;&#22120;&#65292;&#20197;&#36866;&#24212;&#32473;&#23450;&#26410;&#26631;&#35760;&#22312;&#32447;&#25968;&#25454;&#19979;&#30340;&#21464;&#21270;&#26631;&#31614;&#20998;&#24067;&#12290;&#22312;&#30417;&#30563;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#24517;&#39035;&#23398;&#20064;&#20998;&#31867;&#22120;&#24182;&#36866;&#24212;&#21482;&#32473;&#23450;&#26377;&#26631;&#35760;&#22312;&#32447;&#25968;&#25454;&#30340;&#21160;&#24577;&#28436;&#21270;&#31867;&#36793;&#38469;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#26032;&#31639;&#27861;&#65292;&#23558;&#36866;&#24212;&#38382;&#39064;&#20943;&#23569;&#21040;&#22312;&#32447;&#22238;&#24402;&#24182;&#20445;&#35777;&#26080;&#20808;&#39564;&#30693;&#35782;&#19979;&#30340;&#26368;&#20248;&#21160;&#24577;&#36951;&#25022;&#12290;&#25105;&#20204;&#30340;&#35299;&#20915;&#26041;&#26696;&#22522;&#20110;&#24341;&#23548;&#22312;&#32447;&#22238;&#24402;&#39044;&#27979;&#22120;&#20272;&#35745;&#65292;&#20197;&#36319;&#36394;&#28418;&#31227;&#27604;&#20363;&#12290;&#22312;&#20247;&#22810;&#27169;&#25311;&#21644;&#30495;&#23454;&#19990;&#30028;&#30340;&#22312;&#32447;&#26631;&#31614;&#31227;&#20301;&#22330;&#26223;&#20013;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#26041;&#27861;&#30340;&#21331;&#36234;&#24615;&#33021;&#65292;&#36890;&#24120;&#23454;&#29616;1-3&#65285;&#30340;&#20934;&#30830;&#24615;&#25552;&#39640;&#65292;&#21516;&#26102;&#20855;&#26377;&#26356;&#23567;&#30340;&#35745;&#31639;&#21644;&#20869;&#23384;&#28040;&#32791;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper focuses on supervised and unsupervised online label shift, where the class marginals $Q(y)$ varies but the class-conditionals $Q(x|y)$ remain invariant. In the unsupervised setting, our goal is to adapt a learner, trained on some offline labeled data, to changing label distributions given unlabeled online data. In the supervised setting, we must both learn a classifier and adapt to the dynamically evolving class marginals given only labeled online data. We develop novel algorithms that reduce the adaptation problem to online regression and guarantee optimal dynamic regret without any prior knowledge of the extent of drift in the label distribution. Our solution is based on bootstrapping the estimates of \emph{online regression oracles} that track the drifting proportions. Experiments across numerous simulated and real-world online label shift scenarios demonstrate the superior performance of our proposed approaches, often achieving 1-3\% improvement in accuracy while being s
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#21487;&#22797;&#21046;&#24615;&#65292;&#25552;&#20986;&#20102;&#21487;&#22797;&#21046;&#31639;&#27861;&#21644;&#26494;&#24347;&#21487;&#22797;&#21046;&#31639;&#27861;&#65292;&#24182;&#32473;&#20986;&#20102;&#30456;&#24212;&#30340;&#26102;&#38388;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#36825;&#23545;&#20110;RL&#31639;&#27861;&#35774;&#35745;&#20197;&#21450;&#26410;&#26469;&#30340;&#21487;&#22797;&#21046;&#24615;&#30740;&#31350;&#20855;&#26377;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2305.19562</link><description>&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#21487;&#22797;&#29616;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Replicability in Reinforcement Learning. (arXiv:2305.19562v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19562
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#21487;&#22797;&#21046;&#24615;&#65292;&#25552;&#20986;&#20102;&#21487;&#22797;&#21046;&#31639;&#27861;&#21644;&#26494;&#24347;&#21487;&#22797;&#21046;&#31639;&#27861;&#65292;&#24182;&#32473;&#20986;&#20102;&#30456;&#24212;&#30340;&#26102;&#38388;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#36825;&#23545;&#20110;RL&#31639;&#27861;&#35774;&#35745;&#20197;&#21450;&#26410;&#26469;&#30340;&#21487;&#22797;&#21046;&#24615;&#30740;&#31350;&#20855;&#26377;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#24378;&#21270;&#23398;&#20064; (RL) &#30340;&#32972;&#26223;&#19979;&#65292;&#23558;&#21487;&#22797;&#29616;&#24615;&#20316;&#20026;&#31639;&#27861;&#23646;&#24615;&#36827;&#34892;&#20102;&#25968;&#23398;&#30740;&#31350;&#12290;&#25105;&#20204;&#20851;&#27880;&#30340;&#26159;&#20855;&#26377;&#29983;&#25104;&#27169;&#22411;&#35775;&#38382;&#26435;&#30340;&#24102;&#25240;&#25187;&#34920;&#26684;MDP&#30340;&#22522;&#26412;&#35774;&#32622;&#12290;&#21463;Impagliazzo&#31561;&#20154; [2022]&#30340;&#21551;&#21457;&#65292;&#22914;&#26524;&#22312;&#20869;&#37096;&#38543;&#26426;&#24615;&#30456;&#21516;&#26102;&#65292;RL&#31639;&#27861;&#22312;&#20174;&#29983;&#25104;&#22120;&#25277;&#21462;&#30340;&#20004;&#20010;&#29420;&#31435;&#21644;&#21516;&#20998;&#24067;&#30340;&#26679;&#26412;&#19978;&#25191;&#34892;&#20004;&#27425;&#24182;&#36755;&#20986;&#23436;&#20840;&#30456;&#21516;&#30340;&#31574;&#30053;&#65292;&#21017;&#34920;&#31034;&#35813;RL&#31639;&#27861;&#26159;&#21487;&#22797;&#21046;&#30340;&#12290;&#25105;&#20204;&#39318;&#20808;&#25552;&#20379;&#19968;&#20010;&#26377;&#25928;&#30340;$\rho$-&#21487;&#22797;&#21046;&#31639;&#27861;&#65292;&#29992;&#20110;$(\varepsilon,\delta)$-&#26368;&#20248;&#31574;&#30053;&#20272;&#35745;&#65292;&#20854;&#26679;&#26412;&#21644;&#26102;&#38388;&#22797;&#26434;&#24230;&#20026; $\widetilde O\left(\frac{N^3\cdot\log(1/\delta)}{(1-\gamma)^5\cdot\varepsilon^2\cdot\rho^2}\right)$&#65292;&#20854;&#20013;$N$&#26159;&#29366;&#24577;-&#21160;&#20316;&#23545;&#30340;&#25968;&#37327;&#12290;&#28982;&#21518;&#65292;&#23545;&#20110;&#30830;&#23450;&#24615;&#31639;&#27861;&#30340;&#23376;&#31867;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102; $ \Omega\left(\frac {N^3}{(1-\gamma)^3\cdot\varepsilon^2\cdot\rho^2}\right) $ &#38454;&#30340;&#19979;&#38480;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;Kalavasis&#31561;&#20154;[2019]&#25552;&#20986;&#30340;&#21487;&#22797;&#21046;&#24615;&#30340;&#26494;&#24347;&#29256;&#26412;&#65292;&#20854;&#20013;&#20165;&#35201;&#27714;&#31639;&#27861;&#30340;&#36755;&#20986;&#25509;&#36817;&#22797;&#21046;&#31639;&#27861;&#30340;&#36755;&#20986;&#65292;&#32780;&#19981;&#26159;&#30456;&#21516;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#25928;&#31639;&#27861;&#65292;&#20854;&#26102;&#38388;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026; $\widetilde O\left(\frac{N^5\cdot\log(1/\delta)}{(1-\gamma)^9\cdot\varepsilon^4\cdot\rho^2}\right)$&#65292;&#29992;&#20110;$(\varepsilon,\delta)$&#24847;&#20041;&#19979;&#30340;&#21487;&#22797;&#21046;&#24615;&#65292;&#36825;&#27604;&#20808;&#21069;&#19982;&#30456;&#20851;&#38382;&#39064;&#30340;&#30028;&#38480;&#26356;&#22909;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#25105;&#20204;&#30340;&#32467;&#26524;&#23545;RL&#31639;&#27861;&#35774;&#35745;&#21644;&#21487;&#37325;&#22797;&#24615;&#30740;&#31350;&#30340;&#26410;&#26469;&#26041;&#21521;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
We initiate the mathematical study of replicability as an algorithmic property in the context of reinforcement learning (RL). We focus on the fundamental setting of discounted tabular MDPs with access to a generative model. Inspired by Impagliazzo et al. [2022], we say that an RL algorithm is replicable if, with high probability, it outputs the exact same policy after two executions on i.i.d. samples drawn from the generator when its internal randomness is the same. We first provide an efficient $\rho$-replicable algorithm for $(\varepsilon, \delta)$-optimal policy estimation with sample and time complexity $\widetilde O\left(\frac{N^3\cdot\log(1/\delta)}{(1-\gamma)^5\cdot\varepsilon^2\cdot\rho^2}\right)$, where $N$ is the number of state-action pairs. Next, for the subclass of deterministic algorithms, we provide a lower bound of order $\Omega\left(\frac{N^3}{(1-\gamma)^3\cdot\varepsilon^2\cdot\rho^2}\right)$. Then, we study a relaxed version of replicability proposed by Kalavasis et 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#22312;&#39044;&#23450;&#21464;&#25442;&#32676;&#19979;&#23398;&#20064;&#19981;&#21464;&#30340;&#23383;&#20856;&#38382;&#39064;&#12290;&#21033;&#29992;&#38750;&#38463;&#36125;&#23572;&#20613;&#37324;&#21494;&#20998;&#26512;&#65292;&#25552;&#20379;&#20102;&#31639;&#27861;&#65292;&#24314;&#31435;&#20102;&#23383;&#20856;&#23398;&#20064;&#38382;&#39064;&#21487;&#20197;&#34987;&#26377;&#25928;&#22320;&#29702;&#35299;&#20026;&#26576;&#20123;&#30697;&#38453;&#20248;&#21270;&#38382;&#39064;&#30340;&#29702;&#35770;&#22522;&#30784;&#12290;</title><link>http://arxiv.org/abs/2305.19557</link><description>&lt;p&gt;
&#36890;&#36807;&#32676;&#34920;&#31034;&#23398;&#20064;&#23545;&#31216;&#19979;&#30340;&#23383;&#20856;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Dictionary Learning under Symmetries via Group Representations. (arXiv:2305.19557v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19557
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22312;&#39044;&#23450;&#21464;&#25442;&#32676;&#19979;&#23398;&#20064;&#19981;&#21464;&#30340;&#23383;&#20856;&#38382;&#39064;&#12290;&#21033;&#29992;&#38750;&#38463;&#36125;&#23572;&#20613;&#37324;&#21494;&#20998;&#26512;&#65292;&#25552;&#20379;&#20102;&#31639;&#27861;&#65292;&#24314;&#31435;&#20102;&#23383;&#20856;&#23398;&#20064;&#38382;&#39064;&#21487;&#20197;&#34987;&#26377;&#25928;&#22320;&#29702;&#35299;&#20026;&#26576;&#20123;&#30697;&#38453;&#20248;&#21270;&#38382;&#39064;&#30340;&#29702;&#35770;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23383;&#20856;&#23398;&#20064;&#38382;&#39064;&#21487;&#20197;&#34987;&#30475;&#20316;&#26159;&#19968;&#20010;&#25968;&#25454;&#39537;&#21160;&#30340;&#36807;&#31243;&#65292;&#26088;&#22312;&#23398;&#20064;&#19968;&#20010;&#21512;&#36866;&#30340;&#21464;&#25442;&#65292;&#20197;&#20415;&#36890;&#36807;&#31034;&#20363;&#25968;&#25454;&#30452;&#25509;&#34920;&#31034;&#25968;&#25454;&#30340;&#31232;&#30095;&#24615;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#39044;&#23450;&#30340;&#21464;&#25442;&#32676;&#19979;&#23398;&#20064;&#19981;&#21464;&#30340;&#23383;&#20856;&#38382;&#39064;&#12290;&#33258;&#28982;&#30340;&#24212;&#29992;&#39046;&#22495;&#21253;&#25324;&#20919;&#20923;&#30005;&#38236;&#12289;&#22810;&#30446;&#26631;&#36319;&#36394;&#12289;&#21516;&#27493;&#21644;&#23039;&#24577;&#20272;&#35745;&#31561;&#12290;&#25105;&#20204;&#29305;&#21035;&#20174;&#25968;&#23398;&#34920;&#31034;&#29702;&#35770;&#30340;&#35282;&#24230;&#30740;&#31350;&#20102;&#36825;&#20010;&#38382;&#39064;&#12290;&#36890;&#36807;&#21033;&#29992;&#38750;&#38463;&#36125;&#23572;&#20613;&#37324;&#21494;&#20998;&#26512;&#65292;&#25105;&#20204;&#20026;&#31526;&#21512;&#36825;&#20123;&#19981;&#21464;&#24615;&#30340;&#23383;&#20856;&#23398;&#20064;&#25552;&#20379;&#20102;&#31639;&#27861;&#12290;&#25105;&#20204;&#23558;&#33258;&#28982;&#30028;&#20013;&#30340;&#23383;&#20856;&#23398;&#20064;&#38382;&#39064;&#65292;&#20854;&#33258;&#28982;&#34987;&#24314;&#27169;&#20026;&#26080;&#38480;&#32500;&#24230;&#30340;&#38382;&#39064;&#65292;&#19982;&#30456;&#20851;&#30340;&#35745;&#31639;&#38382;&#39064;&#65292;&#36825;&#24517;&#28982;&#26159;&#26377;&#38480;&#32500;&#24230;&#30340;&#38382;&#39064;&#65292;&#32852;&#31995;&#36215;&#26469;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#23383;&#20856;&#23398;&#20064;&#38382;&#39064;&#21487;&#20197;&#34987;&#26377;&#25928;&#22320;&#29702;&#35299;&#20026;&#26576;&#20123;&#30697;&#38453;&#20248;&#21270;&#38382;&#39064;&#30340;&#29702;&#35770;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
The dictionary learning problem can be viewed as a data-driven process to learn a suitable transformation so that data is sparsely represented directly from example data. In this paper, we examine the problem of learning a dictionary that is invariant under a pre-specified group of transformations. Natural settings include Cryo-EM, multi-object tracking, synchronization, pose estimation, etc. We specifically study this problem under the lens of mathematical representation theory. Leveraging the power of non-abelian Fourier analysis for functions over compact groups, we prescribe an algorithmic recipe for learning dictionaries that obey such invariances. We relate the dictionary learning problem in the physical domain, which is naturally modelled as being infinite dimensional, with the associated computational problem, which is necessarily finite dimensional. We establish that the dictionary learning problem can be effectively understood as an optimization instance over certain matrix o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#20302;&#31209;&#25193;&#23637;&#21345;&#23572;&#26364;&#28388;&#27874;&#30340;&#39640;&#25928;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#20854;&#33021;&#22815;&#20272;&#35745;&#38750;&#32447;&#24615;&#20989;&#25968;&#30340;&#21442;&#25968;&#65292;&#20855;&#26377;&#26356;&#24555;&#30340;&#36866;&#24212;&#24615;&#21644;&#26356;&#24555;&#30340;&#22870;&#21169;&#31215;&#32047;&#12290;</title><link>http://arxiv.org/abs/2305.19535</link><description>&lt;p&gt;
&#22522;&#20110;&#27969;&#25968;&#25454;&#30340;&#31070;&#32463;&#32593;&#32476;&#22312;&#32447;&#23398;&#20064;&#30340;&#20302;&#31209;&#25193;&#23637;&#21345;&#23572;&#26364;&#28388;&#27874;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Low-rank extended Kalman filtering for online learning of neural networks from streaming data. (arXiv:2305.19535v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19535
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#20302;&#31209;&#25193;&#23637;&#21345;&#23572;&#26364;&#28388;&#27874;&#30340;&#39640;&#25928;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#20854;&#33021;&#22815;&#20272;&#35745;&#38750;&#32447;&#24615;&#20989;&#25968;&#30340;&#21442;&#25968;&#65292;&#20855;&#26377;&#26356;&#24555;&#30340;&#36866;&#24212;&#24615;&#21644;&#26356;&#24555;&#30340;&#22870;&#21169;&#31215;&#32047;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#22312;&#32447;&#36817;&#20284;&#36125;&#21494;&#26031;&#25512;&#29702;&#31639;&#27861;&#65292;&#29992;&#20110;&#20174;&#21487;&#33021;&#38750;&#24179;&#31283;&#30340;&#25968;&#25454;&#27969;&#20013;&#20272;&#35745;&#38750;&#32447;&#24615;&#20989;&#25968;&#30340;&#21442;&#25968;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#25193;&#23637;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;EKF&#65289;&#65292;&#20294;&#20351;&#29992;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20302;&#31209;&#21152;&#23545;&#35282;&#32447;&#30340;&#21518;&#39564;&#31934;&#24230;&#30697;&#38453;&#20998;&#35299;&#65292;&#20854;&#27599;&#27493;&#30340;&#25104;&#26412;&#19982;&#27169;&#22411;&#21442;&#25968;&#25968;&#37327;&#25104;&#32447;&#24615;&#20851;&#31995;&#12290;&#19982;&#22522;&#20110;&#38543;&#26426;&#21464;&#20998;&#25512;&#29702;&#30340;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#23436;&#20840;&#30830;&#23450;&#30340;&#65292;&#24182;&#19988;&#19981;&#38656;&#35201;&#27493;&#38271;&#35843;&#25972;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#23548;&#33268;&#26356;&#24555;&#65288;&#26356;&#39640;&#25928;&#65289;&#30340;&#23398;&#20064;&#65292;&#20174;&#32780;&#22312;&#29992;&#20316;&#19978;&#19979;&#25991;&#36172;&#21338;&#31639;&#27861;&#30340;&#19968;&#37096;&#20998;&#26102;&#23454;&#29616;&#26356;&#24555;&#36895;&#30340;&#36866;&#24212;&#24615;&#21644;&#26356;&#24555;&#30340;&#22870;&#21169;&#31215;&#32047;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose an efficient online approximate Bayesian inference algorithm for estimating the parameters of a nonlinear function from a potentially non-stationary data stream. The method is based on the extended Kalman filter (EKF), but uses a novel low-rank plus diagonal decomposition of the posterior precision matrix, which gives a cost per step which is linear in the number of model parameters. In contrast to methods based on stochastic variational inference, our method is fully deterministic, and does not require step-size tuning. We show experimentally that this results in much faster (more sample efficient) learning, which results in more rapid adaptation to changing distributions, and faster accumulation of reward when used as part of a contextual bandit algorithm.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;HRR&#30340;&#31070;&#32463;&#31526;&#21495;&#26041;&#27861;&#37325;&#26032;&#26500;&#24314;&#33258;&#27880;&#24847;&#21147;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#23454;&#29616;&#36739;&#20302;&#30340;&#26102;&#38388;&#21644;&#31354;&#38388;&#22797;&#26434;&#24230;&#65292;&#24182;&#22312;LRA&#22522;&#20934;&#27979;&#35797;&#20013;&#33719;&#24471;&#20102;&#25509;&#36817;&#20110;&#26368;&#20808;&#36827;&#30340;&#20934;&#30830;&#24230;&#12290;</title><link>http://arxiv.org/abs/2305.19534</link><description>&lt;p&gt;
&#29992;&#20840;&#24687;&#32422;&#21270;&#34920;&#31034;&#37325;&#26032;&#24314;&#27169;&#33258;&#27880;&#24847;&#21147;
&lt;/p&gt;
&lt;p&gt;
Recasting Self-Attention with Holographic Reduced Representations. (arXiv:2305.19534v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19534
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;HRR&#30340;&#31070;&#32463;&#31526;&#21495;&#26041;&#27861;&#37325;&#26032;&#26500;&#24314;&#33258;&#27880;&#24847;&#21147;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#23454;&#29616;&#36739;&#20302;&#30340;&#26102;&#38388;&#21644;&#31354;&#38388;&#22797;&#26434;&#24230;&#65292;&#24182;&#22312;LRA&#22522;&#20934;&#27979;&#35797;&#20013;&#33719;&#24471;&#20102;&#25509;&#36817;&#20110;&#26368;&#20808;&#36827;&#30340;&#20934;&#30830;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#33258;&#27880;&#24847;&#21147;&#24050;&#32463;&#25104;&#20026;&#21508;&#20010;&#39046;&#22495;&#24207;&#21015;&#24314;&#27169;&#30340;&#20027;&#35201;&#33539;&#20363;&#12290;&#28982;&#32780;&#65292;&#22312;&#24207;&#21015;&#38271;&#24230;&#38750;&#24120;&#38271;&#30340;&#39046;&#22495;&#20013;&#65292;&#22797;&#26434;&#24230;&#20026;$\mathcal{O}(T^2)$&#30340;&#20869;&#23384;&#21644;$\mathcal{O}(T^2 \cdot H)$&#30340;&#35745;&#31639;&#25104;&#26412;&#21487;&#33021;&#20250;&#20351;&#24471;&#20351;&#29992;&#21464;&#24418;&#37329;&#21018;&#32593;&#32476;&#19981;&#21487;&#34892;&#12290;&#21463;&#24778;&#29289;&#26816;&#27979;&#20013;$T \geq 100,000$&#30340;&#24207;&#21015;&#38271;&#24230;&#25104;&#20026;&#28145;&#24230;&#23398;&#20064;&#30340;&#25318;&#36335;&#34382;&#30340;&#38382;&#39064;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#20351;&#29992;&#20840;&#24687;&#32422;&#21270;&#34920;&#31034;&#65288;HRR&#65289;&#30340;&#31070;&#32463;&#31526;&#21495;&#21270;&#26041;&#27861;&#37325;&#26032;&#26500;&#24314;&#33258;&#27880;&#24847;&#21147;&#12290;&#36825;&#26679;&#25105;&#20204;&#25191;&#34892;&#30456;&#21516;&#30340;&#39640;&#32423;&#31574;&#30053;&#65292;&#21363;&#26631;&#20934;&#33258; &#27880;&#24847;&#21147;&#30340;&#26597;&#35810;&#21305;&#37197;&#38053;&#21273;&#65292;&#36820;&#22238;&#27599;&#20010;&#38190;&#30340;&#20540;&#30340;&#21152;&#26435;&#21709;&#24212;&#12290;&#36890;&#36807;&#23454;&#29616;&#8220;Hrrformer&#8221;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#19968;&#20123;&#22909;&#22788;&#65292;&#21253;&#25324;$\mathcal{O}(T H \log H)$&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#12289;$\mathcal{O}(T H)$&#30340;&#31354;&#38388;&#22797;&#26434;&#24230;&#21644;&#25910;&#25947;&#20110;$10\times$&#26356;&#23569;&#30340;&#36845;&#20195;&#27425;&#25968;&#12290;&#28982;&#32780;&#65292;Hrrformer&#22312;LRA&#22522;&#20934;&#27979;&#35797;&#20013;&#23454;&#29616;&#20102;&#25509;&#36817;&#20110;&#26368;&#20808;&#36827;&#30340;&#20934;&#30830;&#24230;&#65292;&#25105;&#20204;&#33021;&#22815;&#23398;&#20064;&#21040;&#28145;&#24230;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, self-attention has become the dominant paradigm for sequence modeling in a variety of domains. However, in domains with very long sequence lengths the $\mathcal{O}(T^2)$ memory and $\mathcal{O}(T^2 H)$ compute costs can make using transformers infeasible. Motivated by problems in malware detection, where sequence lengths of $T \geq 100,000$ are a roadblock to deep learning, we re-cast self-attention using the neuro-symbolic approach of Holographic Reduced Representations (HRR). In doing so we perform the same high-level strategy of the standard self-attention: a set of queries matching against a set of keys, and returning a weighted response of the values for each key. Implemented as a ``Hrrformer'' we obtain several benefits including $\mathcal{O}(T H \log H)$ time complexity, $\mathcal{O}(T H)$ space complexity, and convergence in $10\times$ fewer epochs. Nevertheless, the Hrrformer achieves near state-of-the-art accuracy on LRA benchmarks and we are able to learn wi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#30053;&#24494;&#36229;&#21442;&#25968;&#21270;&#30340;ReLU&#32593;&#32476;&#22312;&#26377;&#38480;&#36755;&#20837;&#25968;&#25454;&#38598;&#19978;&#30340;&#25439;&#22833;&#26223;&#35266;&#65292;&#35777;&#26126;&#20102;&#22823;&#22810;&#25968;&#28608;&#27963;&#27169;&#24335;&#23545;&#24212;&#30340;&#21442;&#25968;&#21306;&#22495;&#27809;&#26377;&#22351;&#30340;&#21487;&#24494;&#23616;&#37096;&#26497;&#23567;&#20540;&#65292;&#23545;&#20110;&#19968;&#32500;&#36755;&#20837;&#25968;&#25454;&#65292;&#32593;&#32476;&#21487;&#20197;&#36890;&#36807;&#22823;&#22810;&#25968;&#28608;&#27963;&#27169;&#24335;&#23454;&#29616;&#39640;&#32500;&#20840;&#23616;&#26497;&#23567;&#20540;&#38598;&#21512;&#32780;&#19981;&#20855;&#26377;&#22351;&#30340;&#23616;&#37096;&#26497;&#23567;&#20540;&#12290;</title><link>http://arxiv.org/abs/2305.19510</link><description>&lt;p&gt;
&#30053;&#24494;&#36229;&#21442;&#25968;&#21270;&#30340;ReLU&#32593;&#32476;&#20855;&#26377;&#26377;&#21033;&#30340;&#25439;&#22833;&#26223;&#35266;
&lt;/p&gt;
&lt;p&gt;
Mildly Overparameterized ReLU Networks Have a Favorable Loss Landscape. (arXiv:2305.19510v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19510
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#30053;&#24494;&#36229;&#21442;&#25968;&#21270;&#30340;ReLU&#32593;&#32476;&#22312;&#26377;&#38480;&#36755;&#20837;&#25968;&#25454;&#38598;&#19978;&#30340;&#25439;&#22833;&#26223;&#35266;&#65292;&#35777;&#26126;&#20102;&#22823;&#22810;&#25968;&#28608;&#27963;&#27169;&#24335;&#23545;&#24212;&#30340;&#21442;&#25968;&#21306;&#22495;&#27809;&#26377;&#22351;&#30340;&#21487;&#24494;&#23616;&#37096;&#26497;&#23567;&#20540;&#65292;&#23545;&#20110;&#19968;&#32500;&#36755;&#20837;&#25968;&#25454;&#65292;&#32593;&#32476;&#21487;&#20197;&#36890;&#36807;&#22823;&#22810;&#25968;&#28608;&#27963;&#27169;&#24335;&#23454;&#29616;&#39640;&#32500;&#20840;&#23616;&#26497;&#23567;&#20540;&#38598;&#21512;&#32780;&#19981;&#20855;&#26377;&#22351;&#30340;&#23616;&#37096;&#26497;&#23567;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26377;&#38480;&#36755;&#20837;&#25968;&#25454;&#38598;&#19978;&#65292;&#20108;&#23618;&#30053;&#24494;&#36229;&#21442;&#25968;&#21270;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#25439;&#22833;&#26223;&#35266;&#65292;&#20351;&#29992;&#20102;&#21442;&#25968;&#26144;&#23556;&#30340;Jacobian&#30697;&#38453;&#30340;&#31209;&#26469;&#20272;&#35745;&#23616;&#37096;&#21644;&#20840;&#23616;&#26497;&#23567;&#20540;&#38598;&#30340;&#32500;&#24230;&#12290;&#20351;&#29992;&#38543;&#26426;&#20108;&#36827;&#21046;&#30697;&#38453;&#30340;&#32467;&#26524;&#65292;&#25105;&#20204;&#35777;&#26126;&#22823;&#22810;&#25968;&#28608;&#27963;&#27169;&#24335;&#23545;&#24212;&#30340;&#21442;&#25968;&#21306;&#22495;&#27809;&#26377;&#22351;&#30340;&#21487;&#24494;&#23616;&#37096;&#26497;&#23567;&#20540;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#19968;&#32500;&#36755;&#20837;&#25968;&#25454;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#32593;&#32476;&#21487;&#20197;&#36890;&#36807;&#22823;&#22810;&#25968;&#30340;&#28608;&#27963;&#27169;&#24335;&#23454;&#29616;&#39640;&#32500;&#20840;&#23616;&#26497;&#23567;&#20540;&#38598;&#21512;&#32780;&#19981;&#20855;&#26377;&#22351;&#30340;&#23616;&#37096;&#26497;&#23567;&#20540;&#12290;&#25105;&#20204;&#36890;&#36807;&#21457;&#29616;&#22823;&#22810;&#25968;&#21306;&#22495;&#20855;&#26377;&#23436;&#25972;&#30340;&#31209;&#25110;&#32570;&#20047;&#31209;&#65292;&#20197;&#23454;&#39564;&#30340;&#26041;&#24335;&#35777;&#23454;&#20102;&#36825;&#20123;&#32467;&#26524;&#65292;&#36825;&#21462;&#20915;&#20110;&#36229;&#21442;&#25968;&#30340;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the loss landscape of two-layer mildly overparameterized ReLU neural networks on a generic finite input dataset for the squared error loss. Our approach involves bounding the dimension of the sets of local and global minima using the rank of the Jacobian of the parameterization map. Using results on random binary matrices, we show most activation patterns correspond to parameter regions with no bad differentiable local minima. Furthermore, for one-dimensional input data, we show most activation regions realizable by the network contain a high dimensional set of global minima and no bad local minima. We experimentally confirm these results by finding a phase transition from most regions having full rank to many regions having deficient rank depending on the amount of overparameterization.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#38544;&#31169;&#20445;&#38556;&#30340;&#33258;&#36866;&#24212;FDR&#25511;&#21046;&#26041;&#27861;&#65292;&#37319;&#29992;&#26032;&#39062;&#30340;p&#20540;&#36716;&#25442;&#26041;&#27861;&#21644;&#38236;&#20687;&#21093;&#31163;&#31639;&#27861;&#65292;&#21487;&#22312;&#29992;&#25143;&#25351;&#23450;&#30340;&#27700;&#24179;&#945;&#19979;&#30830;&#20999;&#22320;&#25511;&#21046;&#32463;&#20856;&#30340;FDR&#25351;&#26631;&#65292;&#34920;&#29616;&#26356;&#22909;&#19988;&#21487;&#20943;&#23567;&#38544;&#31169;&#27844;&#38706;&#39118;&#38505;&#12290;</title><link>http://arxiv.org/abs/2305.19482</link><description>&lt;p&gt;
&#24102;&#38544;&#31169;&#20445;&#38556;&#30340;&#33258;&#36866;&#24212;FDR&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Adaptive False Discovery Rate Control with Privacy Guarantee. (arXiv:2305.19482v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19482
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#38544;&#31169;&#20445;&#38556;&#30340;&#33258;&#36866;&#24212;FDR&#25511;&#21046;&#26041;&#27861;&#65292;&#37319;&#29992;&#26032;&#39062;&#30340;p&#20540;&#36716;&#25442;&#26041;&#27861;&#21644;&#38236;&#20687;&#21093;&#31163;&#31639;&#27861;&#65292;&#21487;&#22312;&#29992;&#25143;&#25351;&#23450;&#30340;&#27700;&#24179;&#945;&#19979;&#30830;&#20999;&#22320;&#25511;&#21046;&#32463;&#20856;&#30340;FDR&#25351;&#26631;&#65292;&#34920;&#29616;&#26356;&#22909;&#19988;&#21487;&#20943;&#23567;&#38544;&#31169;&#27844;&#38706;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#30340;&#22810;&#37325;&#26816;&#39564;&#31243;&#24207;&#21487;&#22312;&#20445;&#35777;&#20551;&#38451;&#24615;&#29575;&#30340;&#21516;&#26102;&#20445;&#25252;&#29992;&#20110;&#20551;&#35774;&#26816;&#39564;&#30340;&#20010;&#20307;&#20449;&#24687;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#30340;&#33258;&#36866;&#24212;FDR&#25511;&#21046;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#29992;&#25143;&#25351;&#23450;&#30340;&#27700;&#24179;&#945;&#19979;&#30830;&#20999;&#22320;&#25511;&#21046;&#32463;&#20856;&#30340;FDR&#25351;&#26631;&#65292;&#24182;&#25552;&#20379;&#38544;&#31169;&#20445;&#38556;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#22522;&#20110;&#20004;&#20010;&#20851;&#38190;&#27934;&#35265;&#65306;1&#65289;&#19968;&#31181;&#26032;&#39062;&#30340;p&#20540;&#36716;&#25442;&#26041;&#27861;&#65292;&#26082;&#20445;&#25252;&#38544;&#31169;&#65292;&#21516;&#26102;&#21448;&#20445;&#25345;&#20102;&#38236;&#20687;&#20445;&#23432;&#29305;&#24615;&#65307;2&#65289;&#19968;&#31181;&#38236;&#20687;&#21093;&#31163;&#31639;&#27861;&#65292;&#20801;&#35768;&#26500;&#24314;&#36807;&#28388;&#22120;&#65292;&#24182;&#24212;&#29992;&#26368;&#20248;&#20572;&#27490;&#25216;&#26415;&#12290;&#25968;&#20540;&#30740;&#31350;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;DP-AdaPT&#30456;&#27604;&#29616;&#26377;&#30340;&#24046;&#20998;&#38544;&#31169;FDR&#25511;&#21046;&#26041;&#27861;&#34920;&#29616;&#26356;&#22909;&#12290;&#19982;&#38750;&#38544;&#31169;&#30340;AdaPT&#30456;&#27604;&#65292;&#23427;&#20250;&#20135;&#29983;&#19968;&#20123;&#31934;&#24230;&#25439;&#22833;&#65292;&#20294;&#26174;&#33879;&#22320;&#20943;&#23567;&#20102;&#38544;&#31169;&#27844;&#38706;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;
Differentially private multiple testing procedures can protect the information of individuals used in hypothesis tests while guaranteeing a small fraction of false discoveries. In this paper, we propose a differentially private adaptive FDR control method that can control the classic FDR metric exactly at a user-specified level $\alpha$ with privacy guarantee, which is a non-trivial improvement compared to the differentially private Benjamini-Hochberg method proposed in Dwork et al. (2021). Our analysis is based on two key insights: 1) a novel p-value transformation that preserves both privacy and the mirror conservative property, and 2) a mirror peeling algorithm that allows the construction of the filtration and application of the optimal stopping technique. Numerical studies demonstrate that the proposed DP-AdaPT performs better compared to the existing differentially private FDR control methods. Compared to the non-private AdaPT, it incurs a small accuracy loss but significantly re
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#37319;&#26679;&#31639;&#27861;&#65292;&#22522;&#20110;&#23545;&#25968;&#20985;&#26465;&#20214;&#27010;&#29575;&#23494;&#24230;&#65292;&#20351;&#29992;&#31561;&#21521;&#24615;&#39640;&#26031;&#24179;&#28369;&#26469;&#35299;&#20915;&#39640;&#32500;&#19979;&#25277;&#26679;&#38590;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.19473</link><description>&lt;p&gt;
&#23545;&#25968;&#20985;&#39532;&#23572;&#21487;&#22827;&#38142;&#20043;&#38142;
&lt;/p&gt;
&lt;p&gt;
Chain of Log-Concave Markov Chains. (arXiv:2305.19473v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19473
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#37319;&#26679;&#31639;&#27861;&#65292;&#22522;&#20110;&#23545;&#25968;&#20985;&#26465;&#20214;&#27010;&#29575;&#23494;&#24230;&#65292;&#20351;&#29992;&#31561;&#21521;&#24615;&#39640;&#26031;&#24179;&#28369;&#26469;&#35299;&#20915;&#39640;&#32500;&#19979;&#25277;&#26679;&#38590;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#65288;MCMC&#65289;&#26159;&#19968;&#31181;&#20174;&#26410;&#26631;&#20934;&#21270;&#23494;&#24230;&#20013;&#25277;&#26679;&#30340;&#36890;&#29992;&#31639;&#27861;&#31867;&#12290;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#65292;MCMC&#38754;&#20020;&#20004;&#20010;&#20247;&#25152;&#21608;&#30693;&#30340;&#38382;&#39064;&#65306;(i)&#24863;&#20852;&#36259;&#30340;&#20998;&#24067;&#22312;&#30001;&#23567;&#27010;&#29575;&#22359;&#38548;&#24320;&#30340;&#21306;&#22495;&#20013;&#38598;&#20013;;(ii)&#23545;&#25968;&#20985;&#24615;&#30340;&#23567;&#27010;&#29575;&#22359;&#26412;&#36523;&#36890;&#24120;&#23384;&#22312;&#30149;&#24577;&#38382;&#39064;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#37319;&#29992;&#31561;&#21521;&#24615;&#39640;&#26031;&#24179;&#28369;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#30340;&#26694;&#26550;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#26080;&#35770;&#23494;&#24230;&#20989;&#25968;&#30340;&#26368;&#23567;&#20551;&#35774;&#26159;&#20160;&#20040;&#65292;&#20174;&#23494;&#24230;&#20989;&#25968;&#20013;&#37319;&#26679;&#24635;&#26159;&#21487;&#20197;&#20998;&#35299;&#20026;&#36890;&#36807;&#31561;&#22122;&#22768;&#27979;&#37327;&#30340;&#32047;&#31215;&#65292;&#20174;&#23545;&#25968;&#20985;&#24615;&#26465;&#20214;&#23494;&#24230;&#20013;&#37319;&#26679;&#30340;&#24207;&#21015;&#12290;&#35813;&#26500;&#36896;&#36319;&#36394;&#20102;&#26679;&#26412;&#21382;&#21490;&#65292;&#22240;&#27492;&#20316;&#20026;&#19968;&#20010;&#25972;&#20307;&#32780;&#35328;&#26159;&#38750;&#39532;&#23572;&#21487;&#22827;&#30340;&#65292;&#20294;&#21382;&#21490;&#20165;&#20197;&#32463;&#39564;&#22343;&#20540;&#30340;&#24418;&#24335;&#20986;&#29616;&#65292;&#20174;&#32780;&#20445;&#35777;&#20102;&#20869;&#23384;&#21360;&#36857;&#30340;&#26368;&#23567;&#21270;&#12290;&#25105;&#20204;&#30340;&#37319;&#26679;&#31639;&#27861;&#25512;&#24191;&#20102;&#27493;&#34892;&#36339;&#36291;&#37319;&#26679;&#65288;1&#65289;&#12290;"&#36208;"&#38454;&#27573;&#21464;&#25104;&#20102;&#23545;&#25968;&#20985;&#38142;&#30340;(&#38750;&#39532;&#23572;&#21487;&#22827;)&#38142;&#12290;
&lt;/p&gt;
&lt;p&gt;
Markov chain Monte Carlo (MCMC) is a class of general-purpose algorithms for sampling from unnormalized densities. There are two well-known problems facing MCMC in high dimensions: (i) The distributions of interest are concentrated in pockets separated by large regions with small probability mass, and (ii) The log-concave pockets themselves are typically ill-conditioned. We introduce a framework to tackle these problems using isotropic Gaussian smoothing. We prove one can always decompose sampling from a density (minimal assumptions made on the density) into a sequence of sampling from log-concave conditional densities via accumulation of noisy measurements with equal noise levels. This construction keeps track of a history of samples, making it non-Markovian as a whole, but the history only shows up in the form of an empirical mean, making the memory footprint minimal. Our sampling algorithm generalizes walk-jump sampling [1]. The "walk" phase becomes a (non-Markovian) chain of log-co
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;JLMs&#30340;&#26631;&#31614;&#23884;&#20837;&#26041;&#27861;&#65292;&#23558;&#22810;&#20803;&#20998;&#31867;&#38382;&#39064;&#36716;&#21270;&#20026;&#26377;&#38480;&#22238;&#24402;&#38382;&#39064;&#65292;&#20855;&#26377;&#36739;&#39640;&#30340;&#35745;&#31639;&#25928;&#29575;&#21644;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.19470</link><description>&lt;p&gt;
&#29992;Johnson-Lindenstrauss&#30697;&#38453;&#36827;&#34892;&#26631;&#31614;&#23884;&#20837;
&lt;/p&gt;
&lt;p&gt;
Label Embedding by Johnson-Lindenstrauss Matrices. (arXiv:2305.19470v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19470
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;JLMs&#30340;&#26631;&#31614;&#23884;&#20837;&#26041;&#27861;&#65292;&#23558;&#22810;&#20803;&#20998;&#31867;&#38382;&#39064;&#36716;&#21270;&#20026;&#26377;&#38480;&#22238;&#24402;&#38382;&#39064;&#65292;&#20855;&#26377;&#36739;&#39640;&#30340;&#35745;&#31639;&#25928;&#29575;&#21644;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;Johnson-Lindenstrauss&#30697;&#38453;&#65288;JLMs&#65289;&#30340;&#31616;&#21333;&#19988;&#21487;&#25193;&#23637;&#30340;&#26497;&#31471;&#22810;&#20803;&#20998;&#31867;&#26694;&#26550;&#12290;&#21033;&#29992;JLM&#30340;&#21015;&#26469;&#23884;&#20837;&#26631;&#31614;&#65292;&#23558;&#19968;&#20010;C&#31867;&#20998;&#31867;&#38382;&#39064;&#36716;&#21270;&#20026;&#20855;&#26377;$\cO(\log C)$&#36755;&#20986;&#32500;&#24230;&#30340;&#22238;&#24402;&#38382;&#39064;&#12290;&#25105;&#20204;&#24471;&#20986;&#20102;&#19968;&#20010;&#36229;&#37327;&#39118;&#38505;&#38480;&#21046;&#65292;&#38416;&#26126;&#20102;&#35745;&#31639;&#25928;&#29575;&#21644;&#39044;&#27979;&#20934;&#30830;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#24182;&#36827;&#19968;&#27493;&#34920;&#26126;&#65292;&#22312;Massart&#22122;&#22768;&#26465;&#20214;&#19979;&#65292;&#38477;&#32500;&#30340;&#24809;&#32602;&#20250;&#28040;&#22833;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26131;&#20110;&#24182;&#34892;&#21270;&#65292;&#24182;&#19988;&#23454;&#39564;&#32467;&#26524;&#23637;&#31034;&#20102;&#22312;&#22823;&#35268;&#27169;&#24212;&#29992;&#20013;&#20854;&#26377;&#25928;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a simple and scalable framework for extreme multiclass classification based on Johnson-Lindenstrauss matrices (JLMs). Using the columns of a JLM to embed the labels, a $C$-class classification problem is transformed into a regression problem with $\cO(\log C)$ output dimension. We derive an excess risk bound, revealing a tradeoff between computational efficiency and prediction accuracy, and further show that under the Massart noise condition, the penalty for dimension reduction vanishes. Our approach is easily parallelizable, and experimental results demonstrate its effectiveness and scalability in large-scale applications.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22522;&#20110;&#26641;&#29366;&#24352;&#37327;&#32593;&#32476;&#30340;CP&#31209;&#32422;&#26463;&#21644;&#24352;&#37327;&#20002;&#24323;&#65292;&#26469;&#26500;&#24314;&#20302;&#31209;&#20998;&#31867;&#22120;&#65292;&#24182;&#22312;&#26102;&#23578;-MNIST&#22270;&#20687;&#20998;&#31867;&#20013;&#23637;&#31034;&#20986;&#20102;&#20248;&#24322;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2305.19440</link><description>&lt;p&gt;
&#22522;&#20110;&#26641;&#24352;&#37327;&#32593;&#32476;&#12289;CP&#31209;&#32422;&#26463;&#21644;&#24352;&#37327;&#20002;&#24323;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning with tree tensor networks, CP rank constraints, and tensor dropout. (arXiv:2305.19440v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19440
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22522;&#20110;&#26641;&#29366;&#24352;&#37327;&#32593;&#32476;&#30340;CP&#31209;&#32422;&#26463;&#21644;&#24352;&#37327;&#20002;&#24323;&#65292;&#26469;&#26500;&#24314;&#20302;&#31209;&#20998;&#31867;&#22120;&#65292;&#24182;&#22312;&#26102;&#23578;-MNIST&#22270;&#20687;&#20998;&#31867;&#20013;&#23637;&#31034;&#20986;&#20102;&#20248;&#24322;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24352;&#37327;&#32593;&#32476;&#21487;&#20197;&#36890;&#36807;&#38477;&#20302;&#33258;&#30001;&#24230;&#26469;&#36817;&#20284;&#34920;&#31034;$N$&#38454;&#24352;&#37327;&#65292;&#24182;&#26500;&#25104;&#19968;&#31995;&#21015;&#21387;&#32553;&#30340;&#23567;&#24352;&#37327;&#32593;&#32476;&#12290;&#22312;[arXiv:2205.15296]&#25991;&#31456;&#20013;&#65292;&#20316;&#32773;&#25552;&#20986;&#21487;&#20197;&#36890;&#36807;&#23545;&#24352;&#37327;&#32593;&#32476;&#20013;&#30340;&#24352;&#37327;&#30340;CP&#31209;&#38468;&#21152;&#32422;&#26463;&#65292;&#36827;&#19968;&#27493;&#38477;&#20302;&#35745;&#31639;&#25104;&#26412;&#12290;&#26412;&#25991;&#26088;&#22312;&#23637;&#31034;&#22914;&#20309;&#21033;&#29992;&#22522;&#20110;&#26641;&#29366;&#24352;&#37327;&#32593;&#32476;(TTN)&#30340;CP&#31209;&#32422;&#26463;&#21644;&#24352;&#37327;&#20002;&#24323;&#30340;&#26041;&#27861;&#26469;&#36827;&#34892;&#26426;&#22120;&#23398;&#20064;&#65292;&#24182;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;&#26102;&#23578;-MNIST&#22270;&#20687;&#20998;&#31867;&#20013;&#20248;&#20110;&#20854;&#20182;&#22522;&#20110;&#24352;&#37327;&#32593;&#32476;&#30340;&#26041;&#27861;&#12290;&#24403;&#20998;&#25903;&#31995;&#25968;$b=4$&#26102;&#65292;&#20302;&#31209;TTN&#20998;&#31867;&#22120;&#36798;&#21040;&#20102;&#27979;&#35797;&#38598;&#20934;&#30830;&#29575;90.3\%&#65292;&#21516;&#26102;&#25317;&#26377;&#36739;&#20302;&#30340;&#35745;&#31639;&#25104;&#26412;&#12290;&#22522;&#20110;&#32447;&#24615;&#20803;&#32032;&#26500;&#25104;&#30340;&#24352;&#37327;&#32593;&#32476;&#20998;&#31867;&#22120;&#36991;&#20813;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#26799;&#24230;&#28040;&#22833;&#38382;&#39064;&#12290;CP&#31209;&#32422;&#26463;&#36824;&#26377;&#20854;&#20182;&#20248;&#28857;&#65306;&#21487;&#20197;&#20943;&#23569;&#21644;&#35843;&#25972;&#27169;&#22411;&#21442;&#25968;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tensor networks approximate order-$N$ tensors with a reduced number of degrees of freedom that is only polynomial in $N$ and arranged as a network of partially contracted smaller tensors. As suggested in [arXiv:2205.15296] in the context of quantum many-body physics, computation costs can be further substantially reduced by imposing constraints on the canonical polyadic (CP) rank of the tensors in such networks. Here we demonstrate how tree tensor networks (TTN) with CP rank constraints and tensor dropout can be used in machine learning. The approach is found to outperform other tensor-network based methods in Fashion-MNIST image classification. A low-rank TTN classifier with branching ratio $b=4$ reaches test set accuracy 90.3\% with low computation costs. Consisting of mostly linear elements, tensor network classifiers avoid the vanishing gradient problem of deep neural networks. The CP rank constraints have additional advantages: The number of parameters can be decreased and tuned m
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#22312;&#32570;&#22833;&#20540;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#20844;&#24179;&#30340;&#20998;&#31867;&#12290;&#20256;&#32479;&#26041;&#27861;&#20250;&#21152;&#21095;&#27495;&#35270;&#12290;&#26412;&#25991;&#35777;&#26126;&#20174;&#25554;&#34917;&#25968;&#25454;&#35757;&#32451;&#20998;&#31867;&#22120;&#20250;&#24694;&#21270;&#32452;&#20844;&#24179;&#24615;&#21644;&#24179;&#22343;&#20934;&#30830;&#24615;&#12290;&#20316;&#32773;&#25552;&#20986;&#21487;&#25193;&#23637;&#21644;&#36866;&#24212;&#24615;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#19982;&#20854;&#20182;&#20844;&#24179;&#24178;&#39044;&#31639;&#27861;&#32467;&#21512;&#20351;&#29992;&#65292;&#20197;&#22788;&#29702;&#25152;&#26377;&#21487;&#33021;&#30340;&#32570;&#22833;&#27169;&#24335;&#12290;</title><link>http://arxiv.org/abs/2305.19429</link><description>&lt;p&gt;
&#32570;&#22833;&#20540;&#19979;&#30340;&#20844;&#24179;&#24615;&#24178;&#39044;&#25514;&#26045;&#30340;&#36866;&#24212;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Adapting Fairness Interventions to Missing Values. (arXiv:2305.19429v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19429
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#22312;&#32570;&#22833;&#20540;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#20844;&#24179;&#30340;&#20998;&#31867;&#12290;&#20256;&#32479;&#26041;&#27861;&#20250;&#21152;&#21095;&#27495;&#35270;&#12290;&#26412;&#25991;&#35777;&#26126;&#20174;&#25554;&#34917;&#25968;&#25454;&#35757;&#32451;&#20998;&#31867;&#22120;&#20250;&#24694;&#21270;&#32452;&#20844;&#24179;&#24615;&#21644;&#24179;&#22343;&#20934;&#30830;&#24615;&#12290;&#20316;&#32773;&#25552;&#20986;&#21487;&#25193;&#23637;&#21644;&#36866;&#24212;&#24615;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#19982;&#20854;&#20182;&#20844;&#24179;&#24178;&#39044;&#31639;&#27861;&#32467;&#21512;&#20351;&#29992;&#65292;&#20197;&#22788;&#29702;&#25152;&#26377;&#21487;&#33021;&#30340;&#32570;&#22833;&#27169;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30495;&#23454;&#19990;&#30028;&#20013;&#25968;&#25454;&#30340;&#32570;&#22833;&#20540;&#23545;&#31639;&#27861;&#20844;&#24179;&#24615;&#25552;&#20986;&#20102;&#26174;&#33879;&#32780;&#29420;&#29305;&#30340;&#25361;&#25112;&#12290;&#19981;&#21516;&#30340;&#26063;&#32676;&#21487;&#33021;&#19981;&#20250;&#21516;&#31561;&#22320;&#21463;&#21040;&#32570;&#22833;&#25968;&#25454;&#30340;&#24433;&#21709;&#65292;&#32780;&#22788;&#29702;&#32570;&#22833;&#20540;&#30340;&#26631;&#20934;&#31243;&#24207;&#65292;&#21363;&#20808;&#23545;&#25968;&#25454;&#36827;&#34892;&#25554;&#34917;&#65292;&#28982;&#21518;&#20351;&#29992;&#25554;&#34917;&#30340;&#25968;&#25454;&#36827;&#34892;&#20998;&#31867;&#65292;&#36825;&#20010;&#36807;&#31243;&#34987;&#31216;&#20026;&#8220;&#25554;&#34917;&#20877;&#20998;&#31867;&#8221;&#65292;&#20250;&#21152;&#21095;&#27495;&#35270;&#12290;&#26412;&#25991;&#20998;&#26512;&#20102;&#32570;&#22833;&#20540;&#22914;&#20309;&#24433;&#21709;&#31639;&#27861;&#20844;&#24179;&#24615;&#12290;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#20102;&#20174;&#25554;&#34917;&#25968;&#25454;&#35757;&#32451;&#20998;&#31867;&#22120;&#20250;&#26174;&#33879;&#24694;&#21270;&#21487;&#20197;&#23454;&#29616;&#30340;&#32452;&#20844;&#24179;&#24615;&#21644;&#24179;&#22343;&#20934;&#30830;&#24615;&#30340;&#20540;&#12290;&#36825;&#26159;&#22240;&#20026;&#25554;&#34917;&#25968;&#25454;&#20250;&#23548;&#33268;&#25968;&#25454;&#32570;&#22833;&#27169;&#24335;&#30340;&#20002;&#22833;&#65292;&#25968;&#25454;&#32570;&#22833;&#27169;&#24335;&#36890;&#24120;&#20250;&#20256;&#36798;&#26377;&#20851;&#39044;&#27979;&#26631;&#31614;&#30340;&#20449;&#24687;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#21487;&#25193;&#23637;&#21644;&#36866;&#24212;&#24615;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#32570;&#22833;&#20540;&#30340;&#20844;&#24179;&#20998;&#31867;&#12290;&#36825;&#20123;&#31639;&#27861;&#21487;&#20197;&#19982;&#20219;&#20309;&#29616;&#26377;&#30340;&#20844;&#24179;&#24178;&#39044;&#31639;&#27861;&#32467;&#21512;&#20351;&#29992;&#65292;&#20197;&#22788;&#29702;&#25152;&#26377;&#21487;&#33021;&#30340;&#32570;&#22833;&#27169;&#24335;&#65292;&#24182;&#20445;&#30041;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
Missing values in real-world data pose a significant and unique challenge to algorithmic fairness. Different demographic groups may be unequally affected by missing data, and the standard procedure for handling missing values where first data is imputed, then the imputed data is used for classification -- a procedure referred to as "impute-then-classify" -- can exacerbate discrimination. In this paper, we analyze how missing values affect algorithmic fairness. We first prove that training a classifier from imputed data can significantly worsen the achievable values of group fairness and average accuracy. This is because imputing data results in the loss of the missing pattern of the data, which often conveys information about the predictive label. We present scalable and adaptive algorithms for fair classification with missing values. These algorithms can be combined with any preexisting fairness-intervention algorithm to handle all possible missing patterns while preserving informatio
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;In-Context Learning&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#30740;&#31350;&#65292;&#36890;&#36807;&#36125;&#21494;&#26031;&#27169;&#22411;&#24179;&#22343;&#31639;&#27861;&#26469;&#38544;&#24335;&#22320;&#23454;&#29616;ICL&#20272;&#35745;&#37327;&#65292;&#24182;&#37319;&#29992;&#22312;&#32447;&#23398;&#20064;&#30340;&#35282;&#24230;&#26469;&#20998;&#26512;ICL&#24615;&#33021;&#65292;&#24314;&#31435;&#21518;&#24724;&#30028;&#38480;&#65292;&#24182;&#36890;&#36807;&#20851;&#27880;&#26426;&#21046;&#36817;&#20284;&#21442;&#25968;&#21270;&#12290;</title><link>http://arxiv.org/abs/2305.19420</link><description>&lt;p&gt;
In-Context Learning&#23398;&#20064;&#20102;&#20160;&#20040;&#20197;&#21450;&#22914;&#20309;&#23398;&#20064;&#65311;&#36125;&#21494;&#26031;&#27169;&#22411;&#24179;&#22343;&#12289;&#21442;&#25968;&#21270;&#21644;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
What and How does In-Context Learning Learn? Bayesian Model Averaging, Parameterization, and Generalization. (arXiv:2305.19420v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19420
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;In-Context Learning&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#30740;&#31350;&#65292;&#36890;&#36807;&#36125;&#21494;&#26031;&#27169;&#22411;&#24179;&#22343;&#31639;&#27861;&#26469;&#38544;&#24335;&#22320;&#23454;&#29616;ICL&#20272;&#35745;&#37327;&#65292;&#24182;&#37319;&#29992;&#22312;&#32447;&#23398;&#20064;&#30340;&#35282;&#24230;&#26469;&#20998;&#26512;ICL&#24615;&#33021;&#65292;&#24314;&#31435;&#21518;&#24724;&#30028;&#38480;&#65292;&#24182;&#36890;&#36807;&#20851;&#27880;&#26426;&#21046;&#36817;&#20284;&#21442;&#25968;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#22238;&#31572;&#20960;&#20010;&#24320;&#25918;&#24615;&#38382;&#39064;&#65292;&#23545;In-Context Learning&#65288;ICL&#65289;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#30740;&#31350;&#65306;(a)&#22312;&#35821;&#35328;&#27169;&#22411;&#20013;&#23398;&#20064;&#30340;&#26159;&#20160;&#20040;&#31867;&#22411;&#30340;ICL&#20272;&#35745;&#37327;&#65311;(b)&#36866;&#21512;&#35780;&#20272;ICL&#30340;&#24615;&#33021;&#24230;&#37327;&#26159;&#20160;&#20040;&#65292;&#24182;&#19988;&#38169;&#35823;&#29575;&#26159;&#22810;&#23569;&#65311;(c)Transformer&#26550;&#26500;&#22914;&#20309;&#23454;&#29616;ICL&#65311;&#20026;&#20102;&#22238;&#31572;(a)&#65292;&#25105;&#20204;&#37319;&#21462;&#20102;&#36125;&#21494;&#26031;&#35266;&#28857;&#65292;&#24182;&#35777;&#26126;ICL&#38544;&#21547;&#23454;&#29616;&#20102;&#36125;&#21494;&#26031;&#27169;&#22411;&#24179;&#22343;&#31639;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20010;&#36125;&#21494;&#26031;&#27169;&#22411;&#24179;&#22343;&#31639;&#27861;&#21487;&#20197;&#36890;&#36807;&#20851;&#27880;&#26426;&#21046;&#36817;&#20284;&#21442;&#25968;&#21270;&#12290;(b)&#20174;&#22312;&#32447;&#23398;&#20064;&#30340;&#35282;&#24230;&#20998;&#26512;ICL&#24615;&#33021;&#65292;&#24314;&#31435;&#19968;&#20010;&#21518;&#24724;&#30028;&#38480; $\mathcal{O}(1/T)$&#65292;&#20854;&#20013;$T$&#26159;ICL&#36755;&#20837;&#24207;&#21015;&#38271;&#24230;&#12290;(c)&#38500;&#20102;&#22312;&#20851;&#27880;&#20013;&#32534;&#30721;&#30340;&#36125;&#21494;&#26031;&#27169;&#22411;&#24179;&#22343;&#31639;&#27861;&#65292;&#25105;&#20204;&#36824;&#34920;&#26126;&#65292;&#22312;&#28041;&#21450;&#26399;&#38388;&#65292;&#23398;&#20064;&#27169;&#22411;&#21644;&#21517;&#20041;&#27169;&#22411;&#20043;&#38388;&#30340;&#24635;&#21464;&#20998;&#36317;&#31163;&#34987;&#19968;&#20010;&#36817;&#20284;&#35823;&#24046;&#21644;&#19968;&#20010;&#27867;&#21270;&#35823;&#24046;&#20043;&#21644;&#25152;&#30028;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we conduct a comprehensive study of In-Context Learning (ICL) by addressing several open questions: (a) What type of ICL estimator is learned within language models? (b) What are suitable performance metrics to evaluate ICL accurately and what are the error rates? (c) How does the transformer architecture enable ICL? To answer (a), we take a Bayesian view and demonstrate that ICL implicitly implements the Bayesian model averaging algorithm. This Bayesian model averaging algorithm is proven to be approximately parameterized by the attention mechanism. For (b), we analyze the ICL performance from an online learning perspective and establish a regret bound $\mathcal{O}(1/T)$, where $T$ is the ICL input sequence length. To address (c), in addition to the encoded Bayesian model averaging algorithm in attention, we show that during pertaining, the total variation distance between the learned model and the nominal model is bounded by a sum of an approximation error and a genera
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;KrAD&#30340;&#26032;&#30340;Kronecker&#20998;&#35299;&#39044;&#22788;&#29702;&#26041;&#27861;&#65292;&#29992;&#20110;&#38477;&#20302;&#28145;&#24230;&#23398;&#20064;&#20013;&#20108;&#38454;&#20248;&#21270;&#22120;&#30340;&#20869;&#23384;&#21644;&#35745;&#31639;&#36164;&#28304;&#35201;&#27714;&#12290;&#36890;&#36807;KrADagrad&#26041;&#27861;&#65292;&#36991;&#20813;&#20102;64&#20301;&#31934;&#24230;&#35201;&#27714;&#65292;&#24182;&#22312;32&#20301;&#31934;&#24230;&#19979;&#34920;&#29616;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2305.19416</link><description>&lt;p&gt;
KrADagrad&#65306;Kronecker&#36817;&#20284;-&#20027;&#23548;&#26799;&#24230;&#39044;&#22788;&#29702;&#38543;&#26426;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
KrADagrad: Kronecker Approximation-Domination Gradient Preconditioned Stochastic Optimization. (arXiv:2305.19416v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19416
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;KrAD&#30340;&#26032;&#30340;Kronecker&#20998;&#35299;&#39044;&#22788;&#29702;&#26041;&#27861;&#65292;&#29992;&#20110;&#38477;&#20302;&#28145;&#24230;&#23398;&#20064;&#20013;&#20108;&#38454;&#20248;&#21270;&#22120;&#30340;&#20869;&#23384;&#21644;&#35745;&#31639;&#36164;&#28304;&#35201;&#27714;&#12290;&#36890;&#36807;KrADagrad&#26041;&#27861;&#65292;&#36991;&#20813;&#20102;64&#20301;&#31934;&#24230;&#35201;&#27714;&#65292;&#24182;&#22312;32&#20301;&#31934;&#24230;&#19979;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20108;&#38454;&#38543;&#26426;&#20248;&#21270;&#22120;&#20801;&#35768;&#21442;&#25968;&#26356;&#26032;&#27493;&#38271;&#21644;&#26041;&#21521;&#36866;&#24212;&#25439;&#22833;&#26354;&#29575;&#65292;&#20294;&#20256;&#32479;&#19978;&#23545;&#20110;&#28145;&#24230;&#23398;&#20064;&#32780;&#35328;&#38656;&#35201;&#22826;&#22810;&#30340;&#20869;&#23384;&#21644;&#35745;&#31639;&#36164;&#28304;&#12290;&#26368;&#36817;&#65292;Shampoo [Gupta et al.&#65292;2018]&#24341;&#20837;&#20102;Kronecker&#20998;&#35299;&#30340;&#39044;&#22788;&#29702;&#26041;&#27861;&#26469;&#20943;&#23569;&#36825;&#20123;&#35201;&#27714;&#65306; &#23427;&#29992;&#20110;&#22823;&#22411;&#28145;&#24230;&#27169;&#22411;[Anil et al.&#65292;2020]&#24182;&#19988;&#22312;&#29983;&#20135;&#20013;[Anil et al.&#65292;2022]&#12290; &#20294;&#26159;&#65292;&#23427;&#38656;&#35201;&#27714;&#35299;&#30149;&#24577;&#30697;&#38453;&#30340;&#36870;&#30697;&#38453;&#26681;&#12290;&#36825;&#38656;&#35201;64&#20301;&#31934;&#24230;&#65292;&#20250;&#20135;&#29983;&#24378;&#30828;&#20214;&#38480;&#21046;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#35299;&#26041;&#27861;&#65292;&#21363;Kronecker&#36817;&#20284;-&#20027;&#23548;&#65288;KrAD&#65289;&#12290; &#20351;&#29992;KrAD&#65292;&#25105;&#20204;&#26356;&#26032;&#19968;&#20010;&#30697;&#38453;&#65292;&#30452;&#25509;&#36817;&#20284;&#36870;&#32463;&#39564;Fisher&#30697;&#38453;&#65288;&#31867;&#20284;&#20110;&#23436;&#25972;&#30697;&#38453;AdaGrad&#65289;&#65292;&#36991;&#20813;&#27714;&#36870;&#30697;&#38453;&#65292;&#22240;&#27492;&#19981;&#38656;&#35201;64&#20301;&#31934;&#24230;&#12290;&#25105;&#20204;&#38543;&#21518;&#25552;&#20986;KrADagrad$^\star$&#65292;&#20854;&#35745;&#31639;&#25104;&#26412;&#19982;Shampoo&#30456;&#20284;&#24182;&#20855;&#26377;&#30456;&#21516;&#30340;&#21518;&#24724;&#20540;&#12290;&#22312;32&#20301;&#31934;&#24230;&#19979;&#65292;&#21512;&#25104;&#30340;&#30149;&#24577;&#23454;&#39564;&#34920;&#29616;&#20248;&#20110;Shampoo&#65292;&#21516;&#26102;&#22312;64&#20301;&#31934;&#24230;&#19979;&#23454;&#29616;&#20102;&#21487;&#27604;&#36739;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#20026;KrADagrad&#30340;&#25910;&#25947;&#24615;&#25552;&#20379;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#24182;&#22312;&#26631;&#20934;&#28145;&#24230;&#23398;&#20064;&#22522;&#20934;&#27979;&#35797;&#20013;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Second order stochastic optimizers allow parameter update step size and direction to adapt to loss curvature, but have traditionally required too much memory and compute for deep learning. Recently, Shampoo [Gupta et al., 2018] introduced a Kronecker factored preconditioner to reduce these requirements: it is used for large deep models [Anil et al., 2020] and in production [Anil et al., 2022]. However, it takes inverse matrix roots of ill-conditioned matrices. This requires 64-bit precision, imposing strong hardware constraints. In this paper, we propose a novel factorization, Kronecker Approximation-Domination (KrAD). Using KrAD, we update a matrix that directly approximates the inverse empirical Fisher matrix (like full matrix AdaGrad), avoiding inversion and hence 64-bit precision. We then propose KrADagrad$^\star$, with similar computational costs to Shampoo and the same regret. Synthetic ill-conditioned experiments show improved performance over Shampoo for 32-bit precision, while
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#21333;&#19968;&#29983;&#25104;&#27969;&#32593;&#32476;&#20013;&#32852;&#21512;&#24314;&#27169;&#36125;&#21494;&#26031;&#32593;&#32476;&#32467;&#26500;&#21644;&#21442;&#25968;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#38750;&#31163;&#25955;&#26679;&#26412;&#31354;&#38388;&#65292;&#25552;&#39640;&#20102;&#36125;&#21494;&#26031;&#32593;&#32476;&#23616;&#37096;&#27010;&#29575;&#27169;&#22411;&#30340;&#28789;&#27963;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.19366</link><description>&lt;p&gt;
&#21333;&#19968;&#29983;&#25104;&#27969;&#32593;&#32476;&#20013;&#30340;&#22270;&#32467;&#26500;&#19982;&#21442;&#25968;&#30340;&#32852;&#21512;&#36125;&#21494;&#26031;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Joint Bayesian Inference of Graphical Structure and Parameters with a Single Generative Flow Network. (arXiv:2305.19366v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19366
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#21333;&#19968;&#29983;&#25104;&#27969;&#32593;&#32476;&#20013;&#32852;&#21512;&#24314;&#27169;&#36125;&#21494;&#26031;&#32593;&#32476;&#32467;&#26500;&#21644;&#21442;&#25968;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#38750;&#31163;&#25955;&#26679;&#26412;&#31354;&#38388;&#65292;&#25552;&#39640;&#20102;&#36125;&#21494;&#26031;&#32593;&#32476;&#23616;&#37096;&#27010;&#29575;&#27169;&#22411;&#30340;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#27969;&#32593;&#32476;&#26159;&#19968;&#31867;&#23545;&#31163;&#25955;&#21644;&#32467;&#26500;&#21270;&#26679;&#26412;&#31354;&#38388;&#36827;&#34892;&#24314;&#27169;&#30340;&#29983;&#25104;&#27169;&#22411;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#24050;&#23558;&#20854;&#24212;&#29992;&#20110;&#25512;&#26029;&#32473;&#23450;&#35266;&#27979;&#25968;&#25454;&#30340;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;DAG&#65289;&#30340;&#36793;&#32536;&#21518;&#39564;&#20998;&#24067;&#12290;&#26412;&#25991;&#22522;&#20110;&#26368;&#36817;&#30340;&#30740;&#31350;&#36827;&#23637;&#65292;&#22312;&#38750;&#31163;&#25955;&#26679;&#26412;&#31354;&#38388;&#19978;&#23558;&#27492;&#26694;&#26550;&#25193;&#23637;&#21040;&#32852;&#21512;&#21518;&#39564;&#20998;&#24067;&#30340;&#24314;&#27169;&#65292;&#19981;&#20165;&#21253;&#25324;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#32467;&#26500;&#65292;&#36824;&#32771;&#34385;&#20102;&#20854;&#26465;&#20214;&#27010;&#29575;&#20998;&#24067;&#30340;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative Flow Networks (GFlowNets), a class of generative models over discrete and structured sample spaces, have been previously applied to the problem of inferring the marginal posterior distribution over the directed acyclic graph (DAG) of a Bayesian Network, given a dataset of observations. Based on recent advances extending this framework to non-discrete sample spaces, we propose in this paper to approximate the joint posterior over not only the structure of a Bayesian Network, but also the parameters of its conditional probability distributions. We use a single GFlowNet whose sampling policy follows a two-phase process: the DAG is first generated sequentially one edge at a time, and then the corresponding parameters are picked once the full structure is known. Since the parameters are included in the posterior distribution, this leaves more flexibility for the local probability models of the Bayesian Network, making our approach applicable even to non-linear models parametrized
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#26799;&#24230;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#38750;&#20984;&#36125;&#21494;&#26031;&#23398;&#20064;&#38382;&#39064;&#65292;&#20855;&#26377;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2305.19350</link><description>&lt;p&gt;
&#22522;&#20110;&#38543;&#26426;&#26799;&#24230;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#30340;&#38750;&#20984;&#36125;&#21494;&#26031;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Non-convex Bayesian Learning via Stochastic Gradient Markov Chain Monte Carlo. (arXiv:2305.19350v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19350
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#26799;&#24230;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#38750;&#20984;&#36125;&#21494;&#26031;&#23398;&#20064;&#38382;&#39064;&#65292;&#20855;&#26377;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#30340;&#20852;&#36215;&#21462;&#20915;&#20110;&#29616;&#20195;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#26377;&#25928;&#35757;&#32451;&#65292;&#36825;&#28041;&#21450;&#21040;&#38750;&#20984;&#20248;&#21270;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#24402;&#32467;&#20026;&#38750;&#20984;&#36125;&#21494;&#26031;&#23398;&#20064;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#26799;&#24230;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#36817;&#20284;&#21518;&#39564;&#20998;&#24067;&#24182;&#20855;&#26377;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
The rise of artificial intelligence (AI) hinges on the efficient training of modern deep neural networks (DNNs) for non-convex optimization and uncertainty quantification, which boils down to a non-convex Bayesian learning problem. A standard tool to handle the problem is Langevin Monte Carlo, which proposes to approximate the posterior distribution with theoretical guarantees. In this thesis, we start with the replica exchange Langevin Monte Carlo (also known as parallel tempering), which proposes appropriate swaps between exploration and exploitation to achieve accelerations. However, the na\"ive extension of swaps to big data problems leads to a large bias, and bias-corrected swaps are required. Such a mechanism leads to few effective swaps and insignificant accelerations. To alleviate this issue, we first propose a control variates method to reduce the variance of noisy energy estimators and show a potential to accelerate the exponential convergence. We also present the population-
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#38750;&#20984;&#32422;&#26463;&#38598;&#24773;&#20917;&#19979;&#30340;&#26354;&#32447;&#31354;&#38388;&#22312;&#32447;&#27979;&#22320;&#20984;&#20248;&#21270;&#30340;&#26080;&#25237;&#24433;&#31639;&#27861;&#65292;&#33719;&#24471;&#20102;&#27425;&#32447;&#24615;&#36951;&#25022;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2305.19349</link><description>&lt;p&gt;
&#20851;&#20110;&#40654;&#26364;&#27969;&#24418;&#19978;&#26080;&#25237;&#24433;&#22312;&#32447;&#23398;&#20064;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Riemannian Projection-free Online Learning. (arXiv:2305.19349v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19349
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#38750;&#20984;&#32422;&#26463;&#38598;&#24773;&#20917;&#19979;&#30340;&#26354;&#32447;&#31354;&#38388;&#22312;&#32447;&#27979;&#22320;&#20984;&#20248;&#21270;&#30340;&#26080;&#25237;&#24433;&#31639;&#27861;&#65292;&#33719;&#24471;&#20102;&#27425;&#32447;&#24615;&#36951;&#25022;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25237;&#24433;&#25805;&#20316;&#26159;&#35768;&#22810;&#20248;&#21270;&#31639;&#27861;&#65288;&#20363;&#22914;&#22312;&#32447;&#26799;&#24230;&#19979;&#38477;[OGD]&#65289;&#20013;&#24378;&#21046;&#32422;&#26463;&#21644;&#23454;&#29616;&#26368;&#20248;&#36951;&#25022;&#36793;&#30028;&#25152;&#24517;&#38656;&#30340;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#12290;&#28982;&#32780;&#65292;&#24403;&#22788;&#29702;&#39640;&#32500;&#35774;&#32622;&#25110;&#20855;&#26377;&#30149;&#24577;&#32422;&#26463;&#38598;&#26102;&#65292;&#23427;&#20250;&#21463;&#21040;&#35745;&#31639;&#22797;&#26434;&#24230;&#38480;&#21046;&#12290;&#26080;&#25237;&#24433;&#31639;&#27861;&#36890;&#36807;&#29992;&#26356;&#26377;&#25928;&#30340;&#20248;&#21270;&#23376;&#31243;&#24207;&#21462;&#20195;&#25237;&#24433;&#39044;&#27979;&#26469;&#35299;&#20915;&#27492;&#38382;&#39064;&#12290;&#20294;&#21040;&#30446;&#21069;&#20026;&#27490;&#65292;&#36825;&#20123;&#26041;&#27861;&#20027;&#35201;&#22312;&#27431;&#20960;&#37324;&#24471;&#35774;&#32622;&#20013;&#24320;&#21457;&#65292;&#24182;&#19988;&#34429;&#28982;&#36234;&#26469;&#36234;&#22810;&#22320;&#20851;&#27880;&#40654;&#26364;&#27969;&#24418;&#19978;&#30340;&#20248;&#21270;&#65292;&#20294;&#22312;&#23581;&#35797;&#21033;&#29992;&#26080;&#25237;&#24433;&#24037;&#20855;&#26041;&#38754;&#22522;&#26412;&#19978;&#27809;&#26377;&#24037;&#20316;&#12290;&#19968;&#20010;&#26126;&#26174;&#30340;&#38382;&#39064;&#26159;&#65292;&#22312;&#36825;&#20123;&#39046;&#22495;&#20013;&#65292;&#38750;&#24179;&#20961;&#30340;&#20223;&#23556;&#20989;&#25968;&#36890;&#24120;&#26159;&#38750;&#20984;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#22312;&#26354;&#32447;&#31354;&#38388;&#19978;&#36827;&#34892;&#22312;&#32447;&#27979;&#22320;&#20984;&#20248;&#21270;&#65292;&#20197;&#33719;&#24471;&#20004;&#31181;&#24773;&#20917;&#19979;&#30340;&#27425;&#32447;&#24615;&#36951;&#25022;&#20445;&#35777;&#65306;&#24403;&#25105;&#20204;&#35775;&#38382;&#65288;a&#65289;&#26102;
&lt;/p&gt;
&lt;p&gt;
The projection operation is a critical component in a wide range of optimization algorithms, such as online gradient descent (OGD), for enforcing constraints and achieving optimal regret bounds. However, it suffers from computational complexity limitations in high-dimensional settings or when dealing with ill-conditioned constraint sets. Projection-free algorithms address this issue by replacing the projection oracle with more efficient optimization subroutines. But to date, these methods have been developed primarily in the Euclidean setting, and while there has been growing interest in optimization on Riemannian manifolds, there has been essentially no work in trying to utilize projection-free tools here. An apparent issue is that non-trivial affine functions are generally non-convex in such domains. In this paper, we present methods for obtaining sub-linear regret guarantees in online geodesically convex optimization on curved spaces for two scenarios: when we have access to (a) a s
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#32773;&#23545;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19968;&#33324;&#35206;&#30422;&#26465;&#20214;&#65292;&#24182;&#21457;&#29616;&#26356;&#22810;&#30340;&#35206;&#30422;&#26465;&#20214;&#65292;&#25552;&#39640;&#20102;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#26679;&#26412;&#25928;&#29575;&#21644;&#34920;&#29616;&#65292;&#21516;&#26102;&#38416;&#26126;&#33391;&#22909;&#30340;&#35206;&#30422;&#26465;&#20214;&#20173;&#28982;&#26377;&#30410;&#20110;&#33719;&#24471;&#26368;&#20248;&#35299;&#12290;</title><link>http://arxiv.org/abs/2304.12886</link><description>&lt;p&gt;
&#38024;&#23545;&#20989;&#25968;&#36924;&#36817;&#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#19968;&#33324;&#35206;&#30422;&#26465;&#20214;&#30340;&#21487;&#35777;&#26126;&#20248;&#21183;
&lt;/p&gt;
&lt;p&gt;
Provable benefits of general coverage conditions in efficient online RL with function approximation. (arXiv:2304.12886v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12886
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#32773;&#23545;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19968;&#33324;&#35206;&#30422;&#26465;&#20214;&#65292;&#24182;&#21457;&#29616;&#26356;&#22810;&#30340;&#35206;&#30422;&#26465;&#20214;&#65292;&#25552;&#39640;&#20102;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#26679;&#26412;&#25928;&#29575;&#21644;&#34920;&#29616;&#65292;&#21516;&#26102;&#38416;&#26126;&#33391;&#22909;&#30340;&#35206;&#30422;&#26465;&#20214;&#20173;&#28982;&#26377;&#30410;&#20110;&#33719;&#24471;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#19982;&#20854;&#20351;&#29992;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDPs&#65289;&#30340;&#26631;&#20934;&#32467;&#26500;&#20551;&#35774;&#65292;&#20351;&#29992;&#26576;&#31181;&#35206;&#30422;&#26465;&#20214;&#65288;&#28304;&#33258;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#65289;&#36275;&#20197;&#30830;&#20445;&#26679;&#26412;&#26377;&#25928;&#20445;&#35777;&#65288;Xie&#31561;&#20154;&#65292;2023&#65289;&#12290;&#26412;&#25991;&#20851;&#27880;&#36825;&#20010;&#26032;&#26041;&#21521;&#65292;&#25366;&#25496;&#26356;&#22810;&#21487;&#33021;&#21644;&#26356;&#26222;&#36941;&#30340;&#35206;&#30422;&#26465;&#20214;&#65292;&#24182;&#30740;&#31350;&#23427;&#20204;&#22312;&#39640;&#25928;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#28508;&#21147;&#21644;&#29992;&#36884;&#12290;&#25105;&#20204;&#37492;&#23450;&#20102;&#26356;&#22810;&#27010;&#24565;&#65292;&#21253;&#25324;$L^p$&#21151;&#33021;&#38598;&#20013;&#24230;&#12289;&#23494;&#24230;&#27604;&#23454;&#29616;&#24615;&#20197;&#21450;&#37096;&#20998;/&#20840;&#35206;&#30422;&#26465;&#20214;&#30340;&#26435;&#34913;&#65292;&#36825;&#20123;&#27010;&#24565;&#20063;&#26377;&#30410;&#20110;&#23454;&#29616;&#26679;&#26412;&#26377;&#25928;&#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#65292;&#20174;&#32780;&#23454;&#29616;&#25913;&#36827;&#30340;&#36951;&#25022;&#36793;&#30028;&#12290;&#27492;&#22806;&#65292;&#22914;&#26524;&#21033;&#29992;&#25506;&#32034;&#24615;&#30340;&#31163;&#32447;&#25968;&#25454;&#65292;&#22312;&#25105;&#20204;&#30340;&#35206;&#30422;&#26465;&#20214;&#19979;&#65292;&#21487;&#20197;&#20026;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#23454;&#29616;&#32479;&#35745;&#21644;&#35745;&#31639;&#19978;&#39640;&#25928;&#30340;&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;&#21363;&#20351;MDP&#32467;&#26500;&#24050;&#32463;&#32473;&#20986;&#65292;&#20363;&#22914;&#32447;&#24615;MDP&#65292;&#25105;&#20204;&#20063;&#38416;&#26126;&#20102;&#33391;&#22909;&#30340;&#35206;&#30422;&#26465;&#20214;&#20173;&#28982;&#26377;&#30410;&#20110;&#33719;&#24471;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
In online reinforcement learning (RL), instead of employing standard structural assumptions on Markov decision processes (MDPs), using a certain coverage condition (original from offline RL) is enough to ensure sample-efficient guarantees (Xie et al. 2023). In this work, we focus on this new direction by digging more possible and general coverage conditions, and study the potential and the utility of them in efficient online RL. We identify more concepts, including the $L^p$ variant of concentrability, the density ratio realizability, and trade-off on the partial/rest coverage condition, that can be also beneficial to sample-efficient online RL, achieving improved regret bound. Furthermore, if exploratory offline data are used, under our coverage conditions, both statistically and computationally efficient guarantees can be achieved for online RL. Besides, even though the MDP structure is given, e.g., linear MDP, we elucidate that, good coverage conditions are still beneficial to obtai
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;&#20998;&#20301;&#25968;&#22238;&#24402;&#26862;&#26519;&#26469;&#23398;&#20064;&#38750;&#25311;&#21512;&#20998;&#25968;&#30340;&#20998;&#24067;&#65292;&#24182;&#21033;&#29992;&#20854;&#26435;&#37325;&#20998;&#37197;&#26356;&#22810;&#30340;&#37325;&#35201;&#24615;&#32473;&#27531;&#24046;&#19982;&#27979;&#35797;&#28857;&#30456;&#20284;&#30340;&#26679;&#26412;&#65292;&#20174;&#32780;&#23454;&#29616;&#26356;&#31526;&#21512;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;</title><link>http://arxiv.org/abs/2303.12695</link><description>&lt;p&gt;
&#38750;&#25311;&#21512;&#20998;&#25968;&#37325;&#26032;&#26435;&#37325;&#23454;&#29616;&#33258;&#36866;&#24212;&#19968;&#33268;&#24615;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Adaptive Conformal Prediction by Reweighting Nonconformity Score. (arXiv:2303.12695v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.12695
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;&#20998;&#20301;&#25968;&#22238;&#24402;&#26862;&#26519;&#26469;&#23398;&#20064;&#38750;&#25311;&#21512;&#20998;&#25968;&#30340;&#20998;&#24067;&#65292;&#24182;&#21033;&#29992;&#20854;&#26435;&#37325;&#20998;&#37197;&#26356;&#22810;&#30340;&#37325;&#35201;&#24615;&#32473;&#27531;&#24046;&#19982;&#27979;&#35797;&#28857;&#30456;&#20284;&#30340;&#26679;&#26412;&#65292;&#20174;&#32780;&#23454;&#29616;&#26356;&#31526;&#21512;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#20855;&#26377;&#21560;&#24341;&#20154;&#30340;&#29702;&#35770;&#20445;&#35777;&#21644;&#23454;&#38469;&#25104;&#21151;&#65292;&#20294;&#30001;&#19968;&#33268;&#24615;&#39044;&#27979;&#65288;CP&#65289;&#32473;&#20986;&#30340;&#39044;&#27979;&#21306;&#38388;&#65288;PI&#65289;&#21487;&#33021;&#26080;&#27861;&#21453;&#26144;&#32473;&#23450;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#36825;&#31181;&#38480;&#21046;&#28304;&#20110;CP&#26041;&#27861;&#23545;&#25152;&#26377;&#27979;&#35797;&#28857;&#20351;&#29992;&#24120;&#25968;&#20462;&#27491;&#65292;&#26080;&#35270;&#23427;&#20204;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#20197;&#30830;&#20445;&#35206;&#30422;&#29305;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#20998;&#20301;&#25968;&#22238;&#24402;&#26862;&#26519;&#65288;QRF&#65289;&#26469;&#23398;&#20064;&#38750;&#25311;&#21512;&#20998;&#25968;&#30340;&#20998;&#24067;&#65292;&#24182;&#21033;&#29992;QRF&#30340;&#26435;&#37325;&#23558;&#26356;&#22810;&#30340;&#37325;&#35201;&#24615;&#20998;&#37197;&#32473;&#27531;&#24046;&#19982;&#27979;&#35797;&#28857;&#30456;&#20284;&#30340;&#26679;&#26412;&#12290;&#36825;&#31181;&#26041;&#27861;&#23548;&#33268;&#30340;PI&#38271;&#24230;&#26356;&#31526;&#21512;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#27492;&#22806;&#65292;QRF&#23398;&#20064;&#21040;&#30340;&#26435;&#37325;&#25552;&#20379;&#20102;&#29305;&#24449;&#31354;&#38388;&#30340;&#21010;&#20998;&#65292;&#36890;&#36807;&#32452;&#21512;&#19968;&#33268;&#21270;&#21487;&#20197;&#23454;&#29616;&#26356;&#39640;&#25928;&#30340;&#35745;&#31639;&#21644;&#25913;&#36827;PI&#30340;&#36866;&#24212;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20139;&#26377;&#22522;&#20110;&#26679;&#26412;&#21644;&#22522;&#20110;&#35757;&#32451;&#26465;&#20214;&#30340;&#26080;&#20551;&#35774;&#26377;&#38480;&#35206;&#30422;&#29575;&#65292;&#24182;&#22312;&#36866;&#24403;&#30340;&#20551;&#35774;&#19979;&#65292;&#20063;&#21487;&#20197;
&lt;/p&gt;
&lt;p&gt;
Despite attractive theoretical guarantees and practical successes, Predictive Interval (PI) given by Conformal Prediction (CP) may not reflect the uncertainty of a given model. This limitation arises from CP methods using a constant correction for all test points, disregarding their individual uncertainties, to ensure coverage properties. To address this issue, we propose using a Quantile Regression Forest (QRF) to learn the distribution of nonconformity scores and utilizing the QRF's weights to assign more importance to samples with residuals similar to the test point. This approach results in PI lengths that are more aligned with the model's uncertainty. In addition, the weights learnt by the QRF provide a partition of the features space, allowing for more efficient computations and improved adaptiveness of the PI through groupwise conformalization. Our approach enjoys an assumption-free finite sample marginal and training-conditional coverage, and under suitable assumptions, it also
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#32479;&#35745;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#22788;&#29702;&#32039;&#33268;&#31354;&#38388;&#19978;&#30340;&#27979;&#24230;&#25968;&#25454;&#65292;&#24182;&#19988;&#21521;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#25299;&#25169;&#20449;&#24687;&#36827;&#34892;&#20998;&#31867;&#12290;</title><link>http://arxiv.org/abs/2303.08456</link><description>&lt;p&gt;
&#24212;&#29992;&#20110;&#25345;&#32493;&#22270;&#30340;&#27979;&#24230;&#32479;&#35745;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Statistical learning on measures: an application to persistence diagrams. (arXiv:2303.08456v1 [cs.CG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.08456
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#32479;&#35745;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#22788;&#29702;&#32039;&#33268;&#31354;&#38388;&#19978;&#30340;&#27979;&#24230;&#25968;&#25454;&#65292;&#24182;&#19988;&#21521;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#25299;&#25169;&#20449;&#24687;&#36827;&#34892;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#20108;&#20803;&#26377;&#30417;&#30563;&#23398;&#20064;&#20998;&#31867;&#38382;&#39064;&#65292;&#20854;&#20013;&#25105;&#20204;&#35266;&#23519;&#21040;&#32039;&#33268;&#31354;&#38388; $\mathcal{X}$ &#19978;&#30340;&#27979;&#24230;&#65292;&#32780;&#19981;&#26159;&#22312;&#26377;&#38480;&#32500;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#35266;&#23519;&#21040;&#25968;&#25454;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#25968;&#25454; $D_N = (\mu_1, Y_1), \ldots, (\mu_N, Y_N)$ &#65292;&#20854;&#20013; $\mu_i$ &#26159; $\mathcal{X}$ &#19978;&#30340;&#27979;&#24230;&#65292; $Y_i$ &#26159; $0$ &#25110; $1$ &#20013;&#30340;&#26631;&#31614;&#12290;&#23545;&#20110; $\mathcal{X}$ &#19978;&#30340;&#22522;&#20998;&#31867;&#22120;&#30340;&#38598;&#21512; $\mathcal{F}$ &#65292;&#25105;&#20204;&#22312;&#27979;&#24230;&#31354;&#38388;&#20013;&#26500;&#24314;&#30456;&#24212;&#30340;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#36825;&#31181;&#26032;&#20998;&#31867;&#22120;&#31867;&#30340; Rademacher &#22797;&#26434;&#24615;&#30340;&#19978;&#19979;&#30028;&#65292;&#23427;&#21487;&#20197;&#31616;&#21333;&#22320;&#29992; $\mathcal{F}$ &#31867;&#30456;&#20851;&#37327;&#26469;&#34920;&#36798;&#12290;&#22914;&#26524; $\mu_i$ &#26159;&#26377;&#38480;&#38598;&#19978;&#30340;&#22343;&#21248;&#20998;&#24067;&#65292;&#37027;&#20040;&#36825;&#20010;&#20998;&#31867;&#20219;&#21153;&#23601;&#20250;&#21464;&#25104;&#19968;&#20010;&#22810;&#23454;&#20363;&#23398;&#20064;&#38382;&#39064;&#12290;&#20294;&#26159;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20801;&#35768;&#25105;&#20204;&#22788;&#29702;&#26356;&#20855;&#26377;&#28789;&#27963;&#24615;&#21644;&#22810;&#26679;&#24615;&#30340;&#36755;&#20837;&#25968;&#25454;&#12290;&#34429;&#28982;&#36825;&#31181;&#26694;&#26550;&#26377;&#35768;&#22810;&#21487;&#33021;&#30340;&#24212;&#29992;&#65292;&#20294;&#26412;&#25991;&#24378;&#35843;&#36890;&#36807;&#25299;&#25169;&#25968;&#25454;&#36827;&#34892;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a binary supervised learning classification problem where instead of having data in a finite-dimensional Euclidean space, we observe measures on a compact space $\mathcal{X}$. Formally, we observe data $D_N = (\mu_1, Y_1), \ldots, (\mu_N, Y_N)$ where $\mu_i$ is a measure on $\mathcal{X}$ and $Y_i$ is a label in $\{0, 1\}$. Given a set $\mathcal{F}$ of base-classifiers on $\mathcal{X}$, we build corresponding classifiers in the space of measures. We provide upper and lower bounds on the Rademacher complexity of this new class of classifiers that can be expressed simply in terms of corresponding quantities for the class $\mathcal{F}$. If the measures $\mu_i$ are uniform over a finite set, this classification task boils down to a multi-instance learning problem. However, our approach allows more flexibility and diversity in the input data we can deal with. While such a framework has many possible applications, this work strongly emphasizes on classifying data via topological d
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#20197;&#39044;&#27979;&#20854;&#20182;&#31070;&#32463;&#32593;&#32476;&#39640;&#36136;&#37327;ImageNet&#21442;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#20351;&#29992;&#39044;&#27979;&#21442;&#25968;&#36827;&#34892;&#21021;&#22987;&#21270;&#65292;&#33021;&#22815;&#25552;&#39640;&#22810;&#31181;ImageNet&#27169;&#22411;&#30340;&#35757;&#32451;&#36895;&#24230;&#65292;&#24182;&#19988;&#22312;&#36716;&#31227;&#21040;&#20854;&#20182;&#25968;&#25454;&#38598;&#26102;&#21487;&#20197;&#26356;&#24555;&#22320;&#25910;&#25947;&#24182;&#36798;&#21040;&#31454;&#20105;&#21147;&#30340;&#26368;&#32456;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2303.04143</link><description>&lt;p&gt;
&#25105;&#20204;&#33021;&#21542;&#23558;Transformer&#24212;&#29992;&#21040;&#22810;&#31181;ImageNet&#27169;&#22411;&#30340;&#21442;&#25968;&#39044;&#27979;&#20013;&#36827;&#34892;&#25193;&#23637;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can We Scale Transformers to Predict Parameters of Diverse ImageNet Models?. (arXiv:2303.04143v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.04143
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#20197;&#39044;&#27979;&#20854;&#20182;&#31070;&#32463;&#32593;&#32476;&#39640;&#36136;&#37327;ImageNet&#21442;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#20351;&#29992;&#39044;&#27979;&#21442;&#25968;&#36827;&#34892;&#21021;&#22987;&#21270;&#65292;&#33021;&#22815;&#25552;&#39640;&#22810;&#31181;ImageNet&#27169;&#22411;&#30340;&#35757;&#32451;&#36895;&#24230;&#65292;&#24182;&#19988;&#22312;&#36716;&#31227;&#21040;&#20854;&#20182;&#25968;&#25454;&#38598;&#26102;&#21487;&#20197;&#26356;&#24555;&#22320;&#25910;&#25947;&#24182;&#36798;&#21040;&#31454;&#20105;&#21147;&#30340;&#26368;&#32456;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#23545;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#39044;&#35757;&#32451;&#24050;&#25104;&#20026;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#22522;&#30707;&#65292;&#20294;&#36825;&#21482;&#33021;&#30001;&#19968;&#20123;&#25317;&#26377;&#20805;&#36275;&#36164;&#28304;&#30340;&#31038;&#21306;&#23454;&#29616;&#12290;&#25105;&#20204;&#26088;&#22312;&#23454;&#29616;&#19968;&#20010;&#38596;&#24515;&#21187;&#21187;&#30340;&#30446;&#26631;&#65306;&#27665;&#20027;&#21270;&#39044;&#35757;&#32451;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#35757;&#32451;&#24182;&#21457;&#24067;&#20102;&#19968;&#20010;&#21333;&#19968;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#21487;&#20197;&#39044;&#27979;&#20854;&#20182;&#31070;&#32463;&#32593;&#32476;&#30340;&#39640;&#36136;&#37327;ImageNet&#21442;&#25968;&#12290;&#36890;&#36807;&#20351;&#29992;&#39044;&#27979;&#21442;&#25968;&#36827;&#34892;&#21021;&#22987;&#21270;&#65292;&#25105;&#20204;&#21487;&#20197;&#25552;&#39640;PyTorch&#20013;&#21487;&#29992;&#30340;&#21508;&#31181;ImageNet&#27169;&#22411;&#30340;&#35757;&#32451;&#36895;&#24230;&#12290;&#22312;&#36716;&#31227;&#21040;&#20854;&#20182;&#25968;&#25454;&#38598;&#26102;&#65292;&#20351;&#29992;&#39044;&#27979;&#21442;&#25968;&#21021;&#22987;&#21270;&#30340;&#27169;&#22411;&#20063;&#20250;&#26356;&#24555;&#22320;&#25910;&#25947;&#24182;&#36798;&#21040;&#31454;&#20105;&#21147;&#30340;&#26368;&#32456;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pretraining a neural network on a large dataset is becoming a cornerstone in machine learning that is within the reach of only a few communities with large-resources. We aim at an ambitious goal of democratizing pretraining. Towards that goal, we train and release a single neural network that can predict high quality ImageNet parameters of other neural networks. By using predicted parameters for initialization we are able to boost training of diverse ImageNet models available in PyTorch. When transferred to other datasets, models initialized with predicted parameters also converge faster and reach competitive final performance.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#23618;&#22810;&#20998;&#36776;&#29575;&#22270;&#29983;&#25104;&#27169;&#22411;&#65292;&#33021;&#36882;&#24402;&#22320;&#29983;&#25104;&#22810;&#20010;&#23618;&#27425;&#30340;&#31038;&#21306;&#32467;&#26500;&#65292;&#24182;&#31526;&#21512;&#35757;&#32451;&#25968;&#25454;&#20998;&#24067;&#12290;&#35813;&#26041;&#27861;&#30001;&#31895;&#21040;&#32454;&#22320;&#29983;&#25104;&#22270;&#65292;&#21516;&#26102;&#20855;&#26377;&#39640;&#24230;&#30340;&#21487;&#25193;&#23637;&#24615;&#65292;&#25552;&#21319;&#20102;&#29983;&#25104;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2303.03293</link><description>&lt;p&gt;
&#20851;&#20110;&#20998;&#23618;&#22810;&#20998;&#36776;&#29575;&#22270;&#29983;&#25104;&#27169;&#22411;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Hierarchical Multi-Resolution Graph Generative Models. (arXiv:2303.03293v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.03293
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#23618;&#22810;&#20998;&#36776;&#29575;&#22270;&#29983;&#25104;&#27169;&#22411;&#65292;&#33021;&#36882;&#24402;&#22320;&#29983;&#25104;&#22810;&#20010;&#23618;&#27425;&#30340;&#31038;&#21306;&#32467;&#26500;&#65292;&#24182;&#31526;&#21512;&#35757;&#32451;&#25968;&#25454;&#20998;&#24067;&#12290;&#35813;&#26041;&#27861;&#30001;&#31895;&#21040;&#32454;&#22320;&#29983;&#25104;&#22270;&#65292;&#21516;&#26102;&#20855;&#26377;&#39640;&#24230;&#30340;&#21487;&#25193;&#23637;&#24615;&#65292;&#25552;&#21319;&#20102;&#29983;&#25104;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#65292;&#22823;&#37096;&#20998;&#30340;&#22270;&#37117;&#20855;&#26377;&#23618;&#27425;&#32467;&#26500;&#12290;&#28982;&#32780;&#65292;&#25968;&#25454;&#39537;&#21160;&#30340;&#22270;&#29983;&#25104;&#20173;&#28982;&#27809;&#26377;&#26377;&#25928;&#22320;&#25429;&#25417;&#21040;&#36825;&#31181;&#32467;&#26500;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#20197;&#22810;&#20010;&#20998;&#36776;&#29575;&#36882;&#24402;&#22320;&#29983;&#25104;&#31038;&#21306;&#32467;&#26500;&#65292;&#29983;&#25104;&#30340;&#32467;&#26500;&#22312;&#27599;&#20010;&#23618;&#27425;&#32467;&#26500;&#19978;&#65292;&#37117;&#31526;&#21512;&#35757;&#32451;&#25968;&#25454;&#30340;&#20998;&#24067;&#12290;&#22270;&#30340;&#29983;&#25104;&#34987;&#35774;&#35745;&#20026;&#19968;&#31995;&#21015;&#30001;&#31895;&#21040;&#32454;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#20801;&#35768;&#25152;&#26377;&#23376;&#32467;&#26500;&#30340;&#24182;&#34892;&#29983;&#25104;&#65292;&#20174;&#32780;&#23454;&#29616;&#39640;&#24230;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#22810;&#20010;&#22270;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#29983;&#25104;&#24615;&#33021;&#30340;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;
In real world domains, most graphs naturally exhibit a hierarchical structure. However, data-driven graph generation is yet to effectively capture such structures. To address this, we propose a novel approach that recursively generates community structures at multiple resolutions, with the generated structures conforming to training data distribution at each level of the hierarchy. The graphs generation is designed as a sequence of coarse-to-fine generative models allowing for parallel generation of all sub-structures, resulting in a high degree of scalability. Our method demonstrates generative performance improvement on multiple graph datasets.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#25903;&#25345;&#19968;&#27493;&#29983;&#25104;&#19988;&#25903;&#25345;&#38646;&#26679;&#26412;&#32534;&#36753;&#30340;&#29983;&#25104;&#27169;&#22411;&#8212;&#8212;&#19968;&#33268;&#24615;&#27169;&#22411;&#65292;&#23427;&#20204;&#33021;&#22815;&#36890;&#36807;&#30452;&#25509;&#23558;&#22122;&#22768;&#26144;&#23556;&#21040;&#25968;&#25454;&#26469;&#29983;&#25104;&#39640;&#36136;&#37327;&#26679;&#26412;&#65292;&#25903;&#25345;&#24555;&#36895;&#30340;&#19968;&#27493;&#29983;&#25104;&#65292;&#19988;&#20173;&#28982;&#25903;&#25345;&#22810;&#27493;&#25277;&#26679;&#20197;&#25552;&#39640;&#26679;&#26412;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2303.01469</link><description>&lt;p&gt;
&#19968;&#31181;&#26032;&#30340;&#29983;&#25104;&#27169;&#22411;&#65306;&#19968;&#27493;&#29983;&#25104;&#19988;&#25903;&#25345;&#38646;&#26679;&#26412;&#32534;&#36753;&#8212;&#8212;&#19968;&#33268;&#24615;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Consistency Models. (arXiv:2303.01469v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.01469
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#25903;&#25345;&#19968;&#27493;&#29983;&#25104;&#19988;&#25903;&#25345;&#38646;&#26679;&#26412;&#32534;&#36753;&#30340;&#29983;&#25104;&#27169;&#22411;&#8212;&#8212;&#19968;&#33268;&#24615;&#27169;&#22411;&#65292;&#23427;&#20204;&#33021;&#22815;&#36890;&#36807;&#30452;&#25509;&#23558;&#22122;&#22768;&#26144;&#23556;&#21040;&#25968;&#25454;&#26469;&#29983;&#25104;&#39640;&#36136;&#37327;&#26679;&#26412;&#65292;&#25903;&#25345;&#24555;&#36895;&#30340;&#19968;&#27493;&#29983;&#25104;&#65292;&#19988;&#20173;&#28982;&#25903;&#25345;&#22810;&#27493;&#25277;&#26679;&#20197;&#25552;&#39640;&#26679;&#26412;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#22312;&#22270;&#20687;&#12289;&#38899;&#39057;&#21644;&#35270;&#39057;&#29983;&#25104;&#39046;&#22495;&#26377;&#20102;&#26174;&#33879;&#30340;&#36827;&#23637;&#65292;&#20294;&#23427;&#20204;&#20381;&#36182;&#20110;&#19968;&#20010;&#36845;&#20195;&#25277;&#26679;&#36807;&#31243;&#65292;&#23548;&#33268;&#29983;&#25104;&#36895;&#24230;&#32531;&#24930;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#33268;&#24615;&#27169;&#22411;&#65292;&#36825;&#26159;&#19968;&#26063;&#36890;&#36807;&#30452;&#25509;&#23558;&#22122;&#22768;&#26144;&#23556;&#21040;&#25968;&#25454;&#26469;&#29983;&#25104;&#39640;&#36136;&#37327;&#26679;&#26412;&#30340;&#26032;&#27169;&#22411;&#12290;&#23427;&#20204;&#36890;&#36807;&#35774;&#35745;&#25903;&#25345;&#24555;&#36895;&#30340;&#19968;&#27493;&#29983;&#25104;&#65292;&#21516;&#26102;&#20173;&#20801;&#35768;&#22810;&#27493;&#25277;&#26679;&#26469;&#20197;&#35745;&#31639;&#25442;&#21462;&#26679;&#26412;&#36136;&#37327;&#12290;&#23427;&#20204;&#36824;&#25903;&#25345;&#38646;&#26679;&#26412;&#25968;&#25454;&#32534;&#36753;&#65292;&#22914;&#22270;&#20687;&#20462;&#22797;&#12289;&#19978;&#33394;&#21644;&#36229;&#20998;&#36776;&#29575;&#65292;&#32780;&#26080;&#38656;&#26126;&#30830;&#35757;&#32451;&#36825;&#20123;&#20219;&#21153;&#12290;&#19968;&#33268;&#24615;&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#33976;&#39311;&#39044;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#26469;&#35757;&#32451;&#65292;&#20063;&#21487;&#20197;&#20316;&#20026;&#29420;&#31435;&#30340;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models have significantly advanced the fields of image, audio, and video generation, but they depend on an iterative sampling process that causes slow generation. To overcome this limitation, we propose consistency models, a new family of models that generate high quality samples by directly mapping noise to data. They support fast one-step generation by design, while still allowing multistep sampling to trade compute for sample quality. They also support zero-shot data editing, such as image inpainting, colorization, and super-resolution, without requiring explicit training on these tasks. Consistency models can be trained either by distilling pre-trained diffusion models, or as standalone generative models altogether. Through extensive experiments, we demonstrate that they outperform existing distillation techniques for diffusion models in one- and few-step sampling, achieving the new state-of-the-art FID of 3.55 on CIFAR-10 and 6.20 on ImageNet 64x64 for one-step generatio
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#21518;&#22788;&#29702;&#26694;&#26550;&#65292;&#29992;&#20110;&#20998;&#31163;&#23398;&#20064;&#21040;&#30340;&#34920;&#24449;&#20013;&#30340;&#20869;&#23481;&#21644;&#39118;&#26684;&#65292;&#22312;&#39046;&#22495;&#27867;&#21270;&#20013;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2302.09795</link><description>&lt;p&gt;
&#35270;&#35273;&#34920;&#24449;&#20013;&#39118;&#26684;&#19982;&#20869;&#23481;&#30340;&#31616;&#21333;&#20998;&#31163;
&lt;/p&gt;
&lt;p&gt;
Simple Disentanglement of Style and Content in Visual Representations. (arXiv:2302.09795v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09795
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#21518;&#22788;&#29702;&#26694;&#26550;&#65292;&#29992;&#20110;&#20998;&#31163;&#23398;&#20064;&#21040;&#30340;&#34920;&#24449;&#20013;&#30340;&#20869;&#23481;&#21644;&#39118;&#26684;&#65292;&#22312;&#39046;&#22495;&#27867;&#21270;&#20013;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#20855;&#26377;&#21487;&#35299;&#37322;&#29305;&#24449;&#30340;&#35270;&#35273;&#34920;&#24449;&#65292;&#21363;&#20998;&#31163;&#30340;&#34920;&#24449;&#65292;&#20173;&#28982;&#26159;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#12290;&#29616;&#26377;&#26041;&#27861;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#34920;&#29616;&#20986;&#25104;&#21151;&#65292;&#20294;&#35201;&#24212;&#29992;&#20110;&#20687;ImageNet&#36825;&#26679;&#30340;&#22823;&#35268;&#27169;&#35270;&#35273;&#25968;&#25454;&#38598;&#21017;&#24456;&#22256;&#38590;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#21518;&#22788;&#29702;&#26694;&#26550;&#65292;&#29992;&#20110;&#20174;&#39044;&#35757;&#32451;&#30340;&#35270;&#35273;&#27169;&#22411;&#20013;&#20998;&#31163;&#23398;&#20064;&#21040;&#30340;&#34920;&#24449;&#20013;&#30340;&#20869;&#23481;&#21644;&#39118;&#26684;&#12290;&#25105;&#20204;&#23558;&#39044;&#35757;&#32451;&#29305;&#24449;&#27010;&#29575;&#22320;&#24314;&#27169;&#20026;&#28508;&#22312;&#20869;&#23481;&#21644;&#39118;&#26684;&#22240;&#32032;&#30340;&#32447;&#24615;&#32508;&#21512;&#65292;&#24182;&#22522;&#20110;&#27010;&#29575;&#27169;&#22411;&#24320;&#21457;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#20998;&#31163;&#31639;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#33021;&#22815;&#21487;&#38752;&#22320;&#20998;&#31163;&#20869;&#23481;&#21644;&#39118;&#26684;&#29305;&#24449;&#65292;&#24182;&#22312;&#23454;&#36341;&#20013;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#22788;&#29702;&#21518;&#30340;&#29305;&#24449;&#22312;&#26679;&#24335;&#21464;&#21270;&#25110;&#19982;&#26679;&#24335;&#30456;&#20851;&#30340;&#34394;&#20551;&#30456;&#20851;&#24615;&#23548;&#33268;&#20998;&#24067;&#20559;&#31227;&#26102;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#39046;&#22495;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning visual representations with interpretable features, i.e., disentangled representations, remains a challenging problem. Existing methods demonstrate some success but are hard to apply to large-scale vision datasets like ImageNet. In this work, we propose a simple post-processing framework to disentangle content and style in learned representations from pre-trained vision models. We model the pre-trained features probabilistically as linearly entangled combinations of the latent content and style factors and develop a simple disentanglement algorithm based on the probabilistic model. We show that the method provably disentangles content and style features and verify its efficacy empirically. Our post-processed features yield significant domain generalization performance improvements when the distribution shift occurs due to style changes or style-related spurious correlations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#33258;&#36866;&#24212;&#20013;&#24515;&#34920;&#31034;&#8221;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#38646;&#26679;&#26412;&#25209;&#27425;&#32423;&#24322;&#24120;&#26816;&#27979;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#25209;&#37327;&#24402;&#19968;&#21270;&#26469;&#35757;&#32451;&#29616;&#25104;&#30340;&#28145;&#24230;&#24322;&#24120;&#26816;&#27979;&#22120;&#65292;&#21487;&#20197;&#33258;&#21160;&#38646;&#26679;&#26412;&#27867;&#21270;&#20026;&#26410;&#35265;&#36807;&#30340;AD&#20219;&#21153;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#35813;&#26041;&#27861;&#26174;&#31034;&#20986;&#20102;&#22312;&#22810;&#31181;&#25968;&#25454;&#38598;&#19978;&#30340;&#20248;&#31168;&#34920;&#29616;&#65292;&#23545;&#34920;&#26684;&#25968;&#25454;&#36827;&#34892;&#20102;&#38646;&#26679;&#26412;AD&#12290;</title><link>http://arxiv.org/abs/2302.07849</link><description>&lt;p&gt;
&#38646;&#26679;&#26412;&#25209;&#27425;&#32423;&#24322;&#24120;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Zero-Shot Batch-Level Anomaly Detection. (arXiv:2302.07849v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.07849
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#33258;&#36866;&#24212;&#20013;&#24515;&#34920;&#31034;&#8221;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#38646;&#26679;&#26412;&#25209;&#27425;&#32423;&#24322;&#24120;&#26816;&#27979;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#25209;&#37327;&#24402;&#19968;&#21270;&#26469;&#35757;&#32451;&#29616;&#25104;&#30340;&#28145;&#24230;&#24322;&#24120;&#26816;&#27979;&#22120;&#65292;&#21487;&#20197;&#33258;&#21160;&#38646;&#26679;&#26412;&#27867;&#21270;&#20026;&#26410;&#35265;&#36807;&#30340;AD&#20219;&#21153;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#35813;&#26041;&#27861;&#26174;&#31034;&#20986;&#20102;&#22312;&#22810;&#31181;&#25968;&#25454;&#38598;&#19978;&#30340;&#20248;&#31168;&#34920;&#29616;&#65292;&#23545;&#34920;&#26684;&#25968;&#25454;&#36827;&#34892;&#20102;&#38646;&#26679;&#26412;AD&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24322;&#24120;&#26816;&#27979;&#65288;AD&#65289;&#22312;&#35768;&#22810;&#23433;&#20840;&#20851;&#38190;&#30340;&#24212;&#29992;&#39046;&#22495;&#20013;&#21457;&#25381;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#36866;&#24212;&#27491;&#24120;&#25968;&#25454;&#20998;&#24067;&#28418;&#31227;&#30340;&#24322;&#24120;&#26816;&#27979;&#22120;&#35843;&#25972;&#65292;&#29305;&#21035;&#26159;&#24403;&#27809;&#26377;&#38024;&#23545;&#8220;&#26032;&#27491;&#24120;&#8221;&#36827;&#34892;&#35757;&#32451;&#30340;&#25968;&#25454;&#26102;&#65292;&#36825;&#19968;&#25361;&#25112;&#23548;&#33268;&#20135;&#29983;&#20102;&#38646;&#26679;&#26412;AD&#25216;&#26415;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#33258;&#36866;&#24212;&#20013;&#24515;&#34920;&#31034;&#65288;ACR&#65289;&#30340;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#38646;&#26679;&#26412;&#25209;&#27425;&#32423;AD&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#29992;&#25209;&#37327;&#24402;&#19968;&#21270;&#26469;&#35757;&#32451;&#29616;&#25104;&#30340;&#28145;&#24230;&#24322;&#24120;&#26816;&#27979;&#22120;&#65288;&#20363;&#22914;&#28145;&#24230;SVDD&#65289;&#26469;&#36866;&#24212;&#19968;&#32452;&#30456;&#20114;&#20851;&#32852;&#30340;&#35757;&#32451;&#25968;&#25454;&#20998;&#24067;&#65292;&#20351;&#20854;&#33021;&#22815;&#33258;&#21160;&#38646;&#26679;&#26412;&#27867;&#21270;&#20026;&#26410;&#35265;&#36807;&#30340;AD&#20219;&#21153;&#12290;&#36825;&#20010;&#31616;&#21333;&#30340;&#26041;&#27861;&#65292;&#25209;&#37327;&#24402;&#19968;&#21270;&#21152;&#20803;&#35757;&#32451;&#65292;&#26159;&#19968;&#31181;&#38750;&#24120;&#26377;&#25928;&#21644;&#22810;&#21151;&#33021;&#30340;&#24037;&#20855;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#23637;&#31034;&#20102;&#23545;&#34920;&#26684;&#25968;&#25454;&#30340;&#31532;&#19968;&#20010;&#38646;&#26679;&#26412;AD&#32467;&#26524;&#65292;&#24182;&#22312;&#26469;&#33258;&#19987;&#19994;&#39046;&#22495;&#30340;&#22270;&#20687;&#25968;&#25454;&#30340;&#38646;&#26679;&#26412;&#24322;&#24120;&#26816;&#27979;&#21644;&#20998;&#27573;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Anomaly detection (AD) plays a crucial role in many safety-critical application domains. The challenge of adapting an anomaly detector to drift in the normal data distribution, especially when no training data is available for the "new normal," has led to the development of zero-shot AD techniques. In this paper, we propose a simple yet effective method called Adaptive Centered Representations (ACR) for zero-shot batch-level AD. Our approach trains off-the-shelf deep anomaly detectors (such as deep SVDD) to adapt to a set of inter-related training data distributions in combination with batch normalization, enabling automatic zero-shot generalization for unseen AD tasks. This simple recipe, batch normalization plus meta-training, is a highly effective and versatile tool. Our results demonstrate the first zero-shot AD results for tabular data and outperform existing methods in zero-shot anomaly detection and segmentation on image data from specialized domains.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#20004;&#31181;&#22522;&#20110;&#20256;&#36755;&#26144;&#23556;&#30340;&#25277;&#26679;&#26041;&#27861;&#65292;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22522;&#20110;&#27969;&#30340;&#25552;&#35758;&#21487;&#20197;&#22788;&#29702;&#22810;&#23792;&#30446;&#26631;&#65292;&#22312;&#39640;&#32500;&#24230;&#21644;&#35757;&#32451;&#19981;&#33391;&#30340;&#24773;&#20917;&#19979;&#20351;&#29992;&#20381;&#36182;&#20110;&#37325;&#26032;&#21442;&#25968;&#21270;&#30340;&#26041;&#27861;&#26356;&#21152;&#31283;&#20581;&#12290;</title><link>http://arxiv.org/abs/2302.04763</link><description>&lt;p&gt;
&#20851;&#20110;&#20351;&#29992;&#36817;&#20284;&#20256;&#36755;&#26144;&#23556;&#36827;&#34892;&#25277;&#26679;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Sampling with Approximate Transport Maps. (arXiv:2302.04763v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.04763
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#20004;&#31181;&#22522;&#20110;&#20256;&#36755;&#26144;&#23556;&#30340;&#25277;&#26679;&#26041;&#27861;&#65292;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22522;&#20110;&#27969;&#30340;&#25552;&#35758;&#21487;&#20197;&#22788;&#29702;&#22810;&#23792;&#30446;&#26631;&#65292;&#22312;&#39640;&#32500;&#24230;&#21644;&#35757;&#32451;&#19981;&#33391;&#30340;&#24773;&#20917;&#19979;&#20351;&#29992;&#20381;&#36182;&#20110;&#37325;&#26032;&#21442;&#25968;&#21270;&#30340;&#26041;&#27861;&#26356;&#21152;&#31283;&#20581;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23558;&#20998;&#24067;&#36716;&#21270;&#20026;&#26131;&#20110;&#22788;&#29702;&#30340;&#20998;&#24067;&#65292;&#20256;&#36755;&#26144;&#23556;&#21487;&#20197;&#31616;&#21270;&#20855;&#26377;&#38750;&#24179;&#20961;&#20960;&#20309;&#32467;&#26500;&#30340;&#20998;&#24067;&#30340;&#25277;&#26679;&#12290;&#38543;&#30528;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#30340;&#20256;&#32479;&#27969;&#65288;NF&#65289;&#30340;&#21457;&#23637;&#65292;&#36825;&#31181;&#26041;&#27861;&#30340;&#28508;&#21147;&#19981;&#26029;&#25552;&#39640;&#12290;NF&#22686;&#24378;&#37319;&#26679;&#22120;&#26368;&#36817;&#25552;&#20986;&#20102;&#23558;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#19982;&#65288;i&#65289;&#26469;&#33258;&#27969;&#30340;&#25552;&#35758;&#32472;&#21046;&#25110;&#65288;ii&#65289;&#22522;&#20110;&#27969;&#30340;&#37325;&#26032;&#21442;&#25968;&#21270;&#30456;&#32467;&#21512;&#12290;&#22312;&#36825;&#20004;&#31181;&#24773;&#20917;&#19979;&#65292;&#23398;&#20064;&#21040;&#30340;&#20256;&#36755;&#30340;&#36136;&#37327;&#20250;&#24433;&#21709;&#24615;&#33021;&#12290;&#26412;&#30740;&#31350;&#39318;&#27425;&#38416;&#26126;&#20102;&#36825;&#20004;&#31181;&#26041;&#27861;&#30340;&#30456;&#23545;&#20248;&#21183;&#21644;&#21155;&#21183;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#24471;&#20986;&#32467;&#35770;&#65306;&#30452;&#21040;&#20013;&#31561;&#32500;&#24230;&#65292;&#21487;&#20197;&#21487;&#38752;&#22320;&#20351;&#29992;&#22522;&#20110;&#27969;&#30340;&#25552;&#35758;&#22788;&#29702;&#22810;&#23792;&#30446;&#26631;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#22312;&#39640;&#32500;&#24230;&#21644;&#35757;&#32451;&#19981;&#33391;&#30340;&#24773;&#20917;&#19979;&#65292;&#20381;&#36182;&#20110;&#37325;&#26032;&#21442;&#25968;&#21270;&#30340;&#26041;&#27861;&#22312;&#22810;&#27169;&#24335;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#65292;&#20294;&#20854;&#20182;&#26041;&#38754;&#26356;&#20026;&#31283;&#20581;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transport maps can ease the sampling of distributions with non-trivial geometries by transforming them into distributions that are easier to handle. The potential of this approach has risen with the development of Normalizing Flows (NF) which are maps parameterized with deep neural networks trained to push a reference distribution towards a target. NF-enhanced samplers recently proposed blend (Markov chain) Monte Carlo methods with either (i) proposal draws from the flow or (ii) a flow-based reparametrization. In both cases, the quality of the learned transport conditions performance. The present work clarifies for the first time the relative strengths and weaknesses of these two approaches. Our study concludes that multimodal targets can be reliably handled with flow-based proposals up to moderately high dimensions. In contrast, methods relying on reparametrization struggle with multimodality but are more robust otherwise in high-dimensional settings and under poor training. To furthe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#36890;&#36807;&#32452;&#21512;&#21333;&#20010;&#22266;&#23450;&#22823;&#23567;RELU&#32593;&#32476;&#65292;&#35777;&#26126;&#20102;&#20854;&#20855;&#26377;&#24778;&#20154;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#23588;&#20854;&#26159;&#22312;&#36924;&#36817;&#20855;&#26377;$1-$Lipschitz&#36830;&#32493;&#24615;&#21644;&#19968;&#33324;&#36830;&#32493;&#24615;&#30340;&#20989;&#25968;&#26102;&#12290;</title><link>http://arxiv.org/abs/2301.12353</link><description>&lt;p&gt;
&#36890;&#36807;&#21333;&#20010;&#22266;&#23450;&#22823;&#23567;RELU&#32593;&#32476;&#30340;&#32452;&#21512;&#26469;&#22686;&#24378;&#34920;&#36798;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
On Enhancing Expressive Power via Compositions of Single Fixed-Size ReLU Network. (arXiv:2301.12353v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.12353
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#36890;&#36807;&#32452;&#21512;&#21333;&#20010;&#22266;&#23450;&#22823;&#23567;RELU&#32593;&#32476;&#65292;&#35777;&#26126;&#20102;&#20854;&#20855;&#26377;&#24778;&#20154;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#23588;&#20854;&#26159;&#22312;&#36924;&#36817;&#20855;&#26377;$1-$Lipschitz&#36830;&#32493;&#24615;&#21644;&#19968;&#33324;&#36830;&#32493;&#24615;&#30340;&#20989;&#25968;&#26102;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#36890;&#36807;&#20989;&#25968;&#32452;&#21512;&#30340;&#26694;&#26550;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#37325;&#22797;&#32452;&#21512;&#21333;&#20010;&#22266;&#23450;&#22823;&#23567;RELU&#32593;&#32476;&#30340;&#24778;&#20154;&#34920;&#36798;&#33021;&#21147;&#65292;&#23613;&#31649;&#21333;&#20010;&#32593;&#32476;&#30340;&#34920;&#36798;&#33021;&#21147;&#26377;&#38480;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23558;&#27492;&#32467;&#26524;&#25193;&#23637;&#21040;&#20102;$[0,1]^d$&#19978;&#30340;&#19968;&#33324;&#36830;&#32493;&#20989;&#25968;&#65292;&#20854;&#36924;&#36817;&#35823;&#24046;&#30001;&#36830;&#32493;&#24615;&#27169;&#37327;&#34920;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper explores the expressive power of deep neural networks through the framework of function compositions. We demonstrate that the repeated compositions of a single fixed-size ReLU network exhibit surprising expressive power, despite the limited expressive capabilities of the individual network itself. Specifically, we prove by construction that $\mathcal{L}_2\circ \boldsymbol{g}^{\circ r}\circ \boldsymbol{\mathcal{L}}_1$ can approximate $1$-Lipschitz continuous functions on $[0,1]^d$ with an error $\mathcal{O}(r^{-1/d})$, where $\boldsymbol{g}$ is realized by a fixed-size ReLU network, $\boldsymbol{\mathcal{L}}_1$ and $\mathcal{L}_2$ are two affine linear maps matching the dimensions, and $\boldsymbol{g}^{\circ r}$ denotes the $r$-times composition of $\boldsymbol{g}$. Furthermore, we extend such a result to generic continuous functions on $[0,1]^d$ with the approximation error characterized by the modulus of continuity. Our results reveal that a continuous-depth network generat
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#35299;&#20915;&#20102;&#23398;&#20064;&#31232;&#30095;&#35266;&#27979;&#20132;&#20114;&#31995;&#32479;&#30340;&#21160;&#21147;&#23398;&#38382;&#39064;&#65292;&#23558;&#20854;&#20316;&#20026;&#35299;&#30340;&#23398;&#20064;&#25511;&#21046;&#24494;&#20998;&#26041;&#31243;&#65288;CDE&#65289;&#65292;&#21033;&#29992;&#31614;&#21517;&#29702;&#35770;&#23558;&#38750;&#32447;&#24615;&#38382;&#39064;&#36716;&#21270;&#20026;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#65292;&#20855;&#26377;&#26126;&#30830;&#30340;&#20381;&#36182;&#20110;&#20010;&#20307;&#29305;&#23450;&#37319;&#26679;&#26041;&#26696;&#30340;&#39044;&#27979;&#35823;&#24046;&#30340;oracle&#30028;&#38480;&#12290;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#22238;&#25910;&#23436;&#25972;&#26102;&#38388;&#24207;&#21015;&#65292;&#19988;&#35745;&#31639;&#25104;&#26412;&#36739;&#20302;&#12290;</title><link>http://arxiv.org/abs/2301.11647</link><description>&lt;p&gt;
&#23398;&#20064;&#31232;&#30095;&#35266;&#27979;&#20132;&#20114;&#31995;&#32479;&#30340;&#21160;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
Learning the Dynamics of Sparsely Observed Interacting Systems. (arXiv:2301.11647v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11647
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#35299;&#20915;&#20102;&#23398;&#20064;&#31232;&#30095;&#35266;&#27979;&#20132;&#20114;&#31995;&#32479;&#30340;&#21160;&#21147;&#23398;&#38382;&#39064;&#65292;&#23558;&#20854;&#20316;&#20026;&#35299;&#30340;&#23398;&#20064;&#25511;&#21046;&#24494;&#20998;&#26041;&#31243;&#65288;CDE&#65289;&#65292;&#21033;&#29992;&#31614;&#21517;&#29702;&#35770;&#23558;&#38750;&#32447;&#24615;&#38382;&#39064;&#36716;&#21270;&#20026;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#65292;&#20855;&#26377;&#26126;&#30830;&#30340;&#20381;&#36182;&#20110;&#20010;&#20307;&#29305;&#23450;&#37319;&#26679;&#26041;&#26696;&#30340;&#39044;&#27979;&#35823;&#24046;&#30340;oracle&#30028;&#38480;&#12290;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#22238;&#25910;&#23436;&#25972;&#26102;&#38388;&#24207;&#21015;&#65292;&#19988;&#35745;&#31639;&#25104;&#26412;&#36739;&#20302;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35299;&#20915;&#20102;&#19968;&#20010;&#38382;&#39064;&#65292;&#21363;&#23398;&#20064;&#26410;&#30693;&#30340;&#38750;&#21442;&#25968;&#31995;&#32479;&#30340;&#21160;&#21147;&#23398;&#65292;&#35813;&#31995;&#32479;&#23558;&#30446;&#26631;&#26102;&#38388;&#24207;&#21015;&#21644;&#29305;&#24449;&#26102;&#38388;&#24207;&#21015;&#32852;&#31995;&#36215;&#26469;&#12290;&#29305;&#24449;&#26102;&#38388;&#24207;&#21015;&#22312;&#31232;&#30095;&#21644;&#19981;&#35268;&#21017;&#30340;&#32593;&#26684;&#19978;&#27979;&#37327;&#65292;&#32780;&#25105;&#20204;&#21482;&#33021;&#35775;&#38382;&#30446;&#26631;&#26102;&#38388;&#24207;&#21015;&#30340;&#19968;&#20123;&#28857;&#12290;&#23398;&#20064;&#21518;&#65292;&#25105;&#20204;&#21487;&#20197;&#20351;&#29992;&#36825;&#20123;&#21160;&#24577;&#23558;&#29305;&#24449;&#26102;&#38388;&#24207;&#21015;&#30340;&#21069;&#20960;&#20010;&#26102;&#38388;&#28857;&#26469;&#39044;&#27979;&#30446;&#26631;&#30340;&#20540;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#20219;&#21153;&#20316;&#20026;&#25511;&#21046;&#24494;&#20998;&#26041;&#31243;&#65288;CDE&#65289;&#35299;&#30340;&#23398;&#20064;&#12290;&#36890;&#36807;&#21033;&#29992;&#31614;&#21517;&#29702;&#35770;&#30340;&#20016;&#23500;&#29702;&#35770;&#65292;&#25105;&#20204;&#33021;&#22815;&#23558;&#36825;&#20010;&#38750;&#32447;&#24615;&#38382;&#39064;&#36716;&#21270;&#20026;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#39044;&#27979;&#35823;&#24046;&#30340;oracle&#30028;&#38480;&#65292;&#20854;&#20855;&#26377;&#26126;&#30830;&#30340;&#20381;&#36182;&#20110;&#20010;&#20307;&#29305;&#23450;&#37319;&#26679;&#26041;&#26696;&#30340;&#20381;&#36182;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#36890;&#36807;&#27169;&#25311;&#24471;&#21040;&#20102;&#35777;&#26126;&#65292;&#34920;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#22238;&#25910;&#23436;&#25972;&#26102;&#38388;&#24207;&#21015;&#26102;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#65292;&#21516;&#26102;&#35745;&#31639;&#25104;&#26412;&#36739;&#20302;&#12290;&#25105;&#20204;&#26368;&#21518;&#23637;&#31034;&#20102;&#23427;&#22312;&#29616;&#23454;&#19990;&#30028;&#27969;&#34892;&#30149;&#23398;&#20013;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
We address the problem of learning the dynamics of an unknown non-parametric system linking a target and a feature time series. The feature time series is measured on a sparse and irregular grid, while we have access to only a few points of the target time series. Once learned, we can use these dynamics to predict values of the target from the previous values of the feature time series. We frame this task as learning the solution map of a controlled differential equation (CDE). By leveraging the rich theory of signatures, we are able to cast this non-linear problem as a high-dimensional linear regression. We provide an oracle bound on the prediction error which exhibits explicit dependencies on the individual-specific sampling schemes. Our theoretical results are illustrated by simulations which show that our method outperforms existing algorithms for recovering the full time series while being computationally cheap. We conclude by demonstrating its potential on real-world epidemiologi
&lt;/p&gt;</description></item><item><title>&#22312;&#20844;&#24179;&#20998;&#31867;&#20013;&#65292;&#27169;&#22411;&#30340;&#39044;&#27979;&#26041;&#24046;&#26159;&#19968;&#20010;&#37325;&#35201;&#20294;&#40092;&#20026;&#20154;&#30693;&#30340;&#35823;&#24046;&#26469;&#28304;&#38382;&#39064;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#20010;&#33258;&#27965;&#24615;&#26631;&#20934;&#26469;&#34913;&#37327;&#27979;&#37327;&#21644;&#20943;&#23569;&#38543;&#24847;&#24615;&#12290;&#20316;&#32773;&#36824;&#24320;&#21457;&#20102;&#19968;&#20010;&#31639;&#27861;&#26469;&#22788;&#29702;&#38543;&#24847;&#24615;&#39044;&#27979;&#65292;&#24182;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#25581;&#31034;&#20102;&#24403;&#21069;&#27169;&#22411;&#26080;&#27861;&#22788;&#29702;&#26576;&#20123;&#31867;&#22411;&#25968;&#25454;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2301.11562</link><description>&lt;p&gt;
&#39044;&#27979;&#26159;&#21542;&#38543;&#24847;&#65311;&#22312;&#20844;&#24179;&#20998;&#31867;&#20013;&#35780;&#20272;&#33258;&#27965;&#24615;
&lt;/p&gt;
&lt;p&gt;
Is My Prediction Arbitrary? Measuring Self-Consistency in Fair Classification. (arXiv:2301.11562v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11562
&lt;/p&gt;
&lt;p&gt;
&#22312;&#20844;&#24179;&#20998;&#31867;&#20013;&#65292;&#27169;&#22411;&#30340;&#39044;&#27979;&#26041;&#24046;&#26159;&#19968;&#20010;&#37325;&#35201;&#20294;&#40092;&#20026;&#20154;&#30693;&#30340;&#35823;&#24046;&#26469;&#28304;&#38382;&#39064;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#20010;&#33258;&#27965;&#24615;&#26631;&#20934;&#26469;&#34913;&#37327;&#27979;&#37327;&#21644;&#20943;&#23569;&#38543;&#24847;&#24615;&#12290;&#20316;&#32773;&#36824;&#24320;&#21457;&#20102;&#19968;&#20010;&#31639;&#27861;&#26469;&#22788;&#29702;&#38543;&#24847;&#24615;&#39044;&#27979;&#65292;&#24182;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#25581;&#31034;&#20102;&#24403;&#21069;&#27169;&#22411;&#26080;&#27861;&#22788;&#29702;&#26576;&#20123;&#31867;&#22411;&#25968;&#25454;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20844;&#24179;&#20998;&#31867;&#20013;&#65292;&#19981;&#21516;&#32463;&#36807;&#35757;&#32451;&#30340;&#27169;&#22411;&#20043;&#38388;&#30340;&#39044;&#27979;&#26041;&#24046;&#26159;&#19968;&#20010;&#37325;&#35201;&#20294;&#40092;&#20026;&#20154;&#30693;&#30340;&#35823;&#24046;&#26469;&#28304;&#38382;&#39064;&#12290; &#23454;&#35777;&#34920;&#26126;&#65292;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#39044;&#27979;&#30340;&#26041;&#24046;&#24046;&#24322;&#38750;&#24120;&#22823;&#65292;&#20197;&#33267;&#20110;&#20915;&#31574;&#23454;&#38469;&#19978;&#26159;&#38543;&#24847;&#30340;&#12290; &#20026;&#20102;&#30740;&#31350;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#22823;&#35268;&#27169;&#30340;&#23454;&#35777;&#30740;&#31350;&#65292;&#24182;&#20570;&#20986;&#20102;&#22235;&#20010;&#24635;&#20307;&#36129;&#29486;&#65306;&#25105;&#20204;1&#65289;&#23450;&#20041;&#20102;&#19968;&#31181;&#22522;&#20110;&#26041;&#24046;&#30340;&#24230;&#37327;&#26631;&#20934;&#65292;&#31216;&#20026;&#33258;&#27965;&#24615;&#65292;&#22312;&#27979;&#37327;&#21644;&#20943;&#23569;&#38543;&#24847;&#24615;&#26102;&#20351;&#29992;&#65307; 2&#65289;&#24320;&#21457;&#20102;&#19968;&#31181;&#21512;&#29702;&#30340;&#31639;&#27861;&#65292;&#24403;&#39044;&#27979;&#26080;&#27861;&#20570;&#20986;&#20915;&#31574;&#26102;&#65292;&#21487;&#20197;&#25918;&#24323;&#20998;&#31867;&#65307; 3&#65289;&#36827;&#34892;&#20102;&#36804;&#20170;&#20026;&#27490;&#26377;&#20851;&#20844;&#24179;&#20998;&#31867;&#20013;&#26041;&#24046;&#65288;&#30456;&#23545;&#20110;&#33258;&#27965;&#24615;&#21644;&#38543;&#24847;&#24615;&#65289;&#20316;&#29992;&#30340;&#26368;&#22823;&#35268;&#27169;&#23454;&#35777;&#30740;&#31350;&#65307; 4&#65289;&#25512;&#20986;&#20102;&#19968;&#20010;&#24037;&#20855;&#21253;&#65292;&#20351;&#32654;&#22269;&#20303;&#25151;&#25269;&#25276;&#36151;&#27454;&#25259;&#38706;&#27861;&#26696;&#65288;HMDA&#65289;&#25968;&#25454;&#38598;&#26131;&#20110;&#29992;&#20110;&#26410;&#26469;&#30740;&#31350;&#12290; &#24635;&#30340;&#26469;&#35828;&#65292;&#25105;&#20204;&#30340;&#23454;&#35777;&#32467;&#26524;&#25581;&#31034;&#20102;&#20851;&#20110;&#21487;&#37325;&#22797;&#24615;&#30340;&#20196;&#20154;&#38663;&#24778;&#30340;&#35265;&#35299;&#12290;&#24403;&#32771;&#34385;&#21040;&#26041;&#24046;&#21644;&#38543;&#24847;&#39044;&#27979;&#30340;&#21487;&#33021;&#24615;&#26102;&#65292;&#22823;&#22810;&#25968;&#20844;&#24179;&#20998;&#31867;&#22522;&#20934;&#25509;&#36817;&#20844;&#24179;&#12290; &#20294;&#26159;&#65292;&#19968;&#23567;&#37096;&#20998;&#23454;&#20363;&#26174;&#31034;&#20986;&#26497;&#22823;&#30340;&#38543;&#24847;&#24615;&#27700;&#24179;&#65292;&#36825;&#34920;&#26126;&#24403;&#21069;&#30340;&#27169;&#22411;&#21487;&#33021;&#26080;&#27861;&#22788;&#29702;&#26576;&#20123;&#31867;&#22411;&#30340;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variance in predictions across different trained models is a significant, under-explored source of error in fair classification. Empirically, the variance on some instances is so large that decisions can be effectively arbitrary. To study this problem, we perform a large-scale empirical study and make four overarching contributions: We 1) Define a metric called self-consistency, derived from variance, which we use as a proxy for measuring and reducing arbitrariness; 2) Develop an ensembling algorithm that abstains from classification when a prediction would be arbitrary; 3) Conduct the largest to-date empirical study of the role of variance (vis-a-vis self-consistency and arbitrariness) in fair classification; and, 4) Release a toolkit that makes the US Home Mortgage Disclosure Act (HMDA) datasets easily usable for future research. Altogether, our empirical results reveal shocking insights about reproducibility. Most fairness classification benchmarks are close-to-fair when taking into
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#39033;&#36873;&#25321;&#20247;&#21253;&#20219;&#21153;&#30340;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#24674;&#22797;&#26368;&#20196;&#20154;&#22256;&#24785;&#30340;&#31572;&#26696;&#21644;&#28151;&#28102;&#27010;&#29575;&#12290;&#22312;&#35813;&#27169;&#22411;&#19979;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#38454;&#27573;&#25512;&#26029;&#31639;&#27861;&#26469;&#25512;&#26029;&#26368;&#26377;&#21487;&#33021;&#30340;&#31572;&#26696;&#21644;&#28151;&#28102;&#27010;&#29575;&#12290;</title><link>http://arxiv.org/abs/2301.00006</link><description>&lt;p&gt;
&#22312;&#22810;&#39033;&#36873;&#25321;&#20247;&#21253;&#20013;&#24674;&#22797;&#21069;&#20004;&#20010;&#31572;&#26696;&#21644;&#28151;&#28102;&#27010;&#29575;
&lt;/p&gt;
&lt;p&gt;
Recovering Top-Two Answers and Confusion Probability in Multi-Choice Crowdsourcing. (arXiv:2301.00006v2 [cs.HC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.00006
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#39033;&#36873;&#25321;&#20247;&#21253;&#20219;&#21153;&#30340;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#24674;&#22797;&#26368;&#20196;&#20154;&#22256;&#24785;&#30340;&#31572;&#26696;&#21644;&#28151;&#28102;&#27010;&#29575;&#12290;&#22312;&#35813;&#27169;&#22411;&#19979;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#38454;&#27573;&#25512;&#26029;&#31639;&#27861;&#26469;&#25512;&#26029;&#26368;&#26377;&#21487;&#33021;&#30340;&#31572;&#26696;&#21644;&#28151;&#28102;&#27010;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20247;&#21253;&#24050;&#32463;&#25104;&#20026;&#19968;&#31181;&#26631;&#35760;&#22823;&#37327;&#25968;&#25454;&#30340;&#26377;&#25928;&#24179;&#21488;&#65292;&#20855;&#26377;&#25104;&#26412;&#21644;&#26102;&#38388;&#25928;&#30410;&#12290;&#22823;&#37096;&#20998;&#20808;&#21069;&#30340;&#24037;&#20316;&#37117;&#38598;&#20013;&#22312;&#35774;&#35745;&#19968;&#31181;&#26377;&#25928;&#30340;&#31639;&#27861;&#65292;&#20165;&#24674;&#22797;&#25968;&#25454;&#30340;&#30495;&#23454;&#26631;&#31614;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#22810;&#39033;&#36873;&#25321;&#20247;&#21253;&#20219;&#21153;&#65292;&#30446;&#26631;&#19981;&#20165;&#26159;&#24674;&#22797;&#30495;&#23454;&#26631;&#31614;&#65292;&#36824;&#21253;&#25324;&#26368;&#20196;&#20154;&#22256;&#24785;&#30340;&#31572;&#26696;&#21644;&#28151;&#28102;&#27010;&#29575;&#12290;&#26368;&#20196;&#20154;&#22256;&#24785;&#30340;&#31572;&#26696;&#25552;&#20379;&#20102;&#20851;&#20110;&#20219;&#21153;&#30340;&#26377;&#29992;&#20449;&#24687;&#65292;&#25581;&#31034;&#20102;&#38500;&#30495;&#23454;&#31572;&#26696;&#20197;&#22806;&#26368;&#21487;&#20449;&#30340;&#31572;&#26696;&#20197;&#21450;&#23427;&#30340;&#21487;&#20449;&#24230;&#12290;&#20026;&#20102;&#29702;&#35770;&#20998;&#26512;&#36825;&#26679;&#30340;&#24773;&#20917;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#65292;&#27599;&#20010;&#20219;&#21153;&#26377;&#20004;&#20010;&#26368;&#21487;&#20449;&#30340;&#31572;&#26696;&#65292;&#19982;&#20854;&#20182;&#36873;&#25321;&#26377;&#25152;&#19981;&#21516;&#12290;&#20219;&#21153;&#38590;&#24230;&#30001;&#21069;&#20004;&#20010;&#31572;&#26696;&#20043;&#38388;&#30340;&#28151;&#28102;&#27010;&#29575;&#37327;&#21270;&#65292;&#24037;&#20316;&#21487;&#38752;&#24615;&#30001;&#32473;&#20986;&#21069;&#20004;&#20010;&#31572;&#26696;&#30340;&#27010;&#29575;&#37327;&#21270;&#12290;&#22312;&#27492;&#27169;&#22411;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#38454;&#27573;&#25512;&#26029;&#31639;&#27861;&#26469;&#25512;&#26029;&#21069;&#20004;&#20010;&#31572;&#26696;&#21644;&#28151;&#28102;&#27010;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Crowdsourcing has emerged as an effective platform for labeling large amounts of data in a cost- and time-efficient manner. Most previous work has focused on designing an efficient algorithm to recover only the ground-truth labels of the data. In this paper, we consider multi-choice crowdsourcing tasks with the goal of recovering not only the ground truth, but also the most confusing answer and the confusion probability. The most confusing answer provides useful information about the task by revealing the most plausible answer other than the ground truth and how plausible it is. To theoretically analyze such scenarios, we propose a model in which there are the top two plausible answers for each task, distinguished from the rest of the choices. Task difficulty is quantified by the probability of confusion between the top two, and worker reliability is quantified by the probability of giving an answer among the top two. Under this model, we propose a two-stage inference algorithm to infe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#30446;&#26631;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#30340;Pareto&#26368;&#20248;&#24615;&#65292;&#25552;&#20986;&#20102;&#23545;&#25239;&#24615;&#22810;&#30446;&#26631;&#22810;&#33218;&#36172;&#21338;&#26426;&#30340;&#34920;&#36848;&#21644;&#23450;&#20041;&#20102;Pareto&#21518;&#24724;&#65292;&#25552;&#20986;&#20102;&#26032;&#31639;&#27861;&#65292;&#20998;&#26512;&#35777;&#26126;&#31639;&#27861;&#22312;&#23545;&#25239;&#24615;&#29615;&#22659;&#26368;&#20248;&#65292;&#22312;&#38543;&#26426;&#29615;&#22659;&#20013;&#20063;&#25509;&#36817;&#26368;&#20248;&#65292;&#24182;&#23558;&#23545;&#25239;&#24615;&#25915;&#20987;&#26426;&#21046;&#20174;&#36172;&#24466;&#25512;&#24191;&#21040;&#22810;&#30446;&#26631;&#39046;&#22495;&#12290;</title><link>http://arxiv.org/abs/2212.00884</link><description>&lt;p&gt;
&#22810;&#30446;&#26631;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#30340;Pareto&#21518;&#24724;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Pareto Regret Analyses in Multi-objective Multi-armed Bandit. (arXiv:2212.00884v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.00884
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#30446;&#26631;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#30340;Pareto&#26368;&#20248;&#24615;&#65292;&#25552;&#20986;&#20102;&#23545;&#25239;&#24615;&#22810;&#30446;&#26631;&#22810;&#33218;&#36172;&#21338;&#26426;&#30340;&#34920;&#36848;&#21644;&#23450;&#20041;&#20102;Pareto&#21518;&#24724;&#65292;&#25552;&#20986;&#20102;&#26032;&#31639;&#27861;&#65292;&#20998;&#26512;&#35777;&#26126;&#31639;&#27861;&#22312;&#23545;&#25239;&#24615;&#29615;&#22659;&#26368;&#20248;&#65292;&#22312;&#38543;&#26426;&#29615;&#22659;&#20013;&#20063;&#25509;&#36817;&#26368;&#20248;&#65292;&#24182;&#23558;&#23545;&#25239;&#24615;&#25915;&#20987;&#26426;&#21046;&#20174;&#36172;&#24466;&#25512;&#24191;&#21040;&#22810;&#30446;&#26631;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#30446;&#26631;&#22810;&#33218;&#36172;&#21338;&#26426;&#20013;&#30340;Pareto&#26368;&#20248;&#24615;&#12290;&#36890;&#36807;&#25552;&#20986;&#23545;&#25239;&#24615;&#22810;&#30446;&#26631;&#22810;&#33218;&#36172;&#21338;&#26426;&#30340;&#34920;&#36848;&#24182;&#23450;&#20041;&#20854;Pareto&#21518;&#24724;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#38543;&#26426;&#21644;&#23545;&#25239;&#24615;&#29615;&#22659;&#12290;&#36825;&#20123;&#21518;&#24724;&#19981;&#20381;&#36182;&#20110;&#20219;&#20309;&#26631;&#37327;&#21270;&#20989;&#25968;&#65292;&#24182;&#21453;&#26144;&#20102;&#19982;&#26631;&#37327;&#21270;&#21518;&#24724;&#30456;&#27604;&#30340;Pareto&#26368;&#20248;&#24615;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22312;&#26377;&#21644;&#26080;&#20808;&#39564;&#20449;&#24687;&#30340;&#22810;&#30446;&#26631;&#22810;&#33218;&#36172;&#21338;&#26426;&#29615;&#22659;&#19979;&#30340;&#26032;&#31639;&#27861;&#12290;&#36890;&#36807;&#25105;&#20204;&#23545;Pareto&#21518;&#24724;&#30340;&#19978;&#19979;&#30028;&#20998;&#26512;&#35777;&#26126;&#65292;&#22312;&#23545;&#25239;&#24615;&#29615;&#22659;&#20013;&#31639;&#27861;&#26159;&#26368;&#20248;&#30340;&#65292;&#22312;&#38543;&#26426;&#29615;&#22659;&#20013;&#20063;&#25509;&#36817;&#26368;&#20248;&#12290;&#27492;&#22806;&#65292;&#19979;&#30028;&#20998;&#26512;&#34920;&#26126;&#65292;&#26032;&#30340;&#21518;&#24724;&#19982;&#38543;&#26426;&#29615;&#22659;&#19979;&#30340;&#29616;&#26377;Pareto&#21518;&#24724;&#19968;&#33268;&#65292;&#24182;&#23558;&#23545;&#25239;&#24615;&#25915;&#20987;&#26426;&#21046;&#20174;&#36172;&#24466;&#25512;&#24191;&#21040;&#20102;&#22810;&#30446;&#26631;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study Pareto optimality in multi-objective multi-armed bandit by providing a formulation of adversarial multi-objective multi-armed bandit and defining its Pareto regrets that can be applied to both stochastic and adversarial settings. The regrets do not rely on any scalarization functions and reflect Pareto optimality compared to scalarized regrets. We also present new algorithms assuming both with and without prior information of the multi-objective multi-armed bandit setting. The algorithms are shown optimal in adversarial settings and nearly optimal up to a logarithmic factor in stochastic settings simultaneously by our established upper bounds and lower bounds on Pareto regrets. Moreover, the lower bound analyses show that the new regrets are consistent with the existing Pareto regret for stochastic settings and extend an adversarial attack mechanism from bandit to the multi-objective one.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#21457;&#29616;&#22270;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#23384;&#22312;&#36807;&#24230;&#24179;&#28369;&#21644;&#36807;&#24230;&#21387;&#32553;&#38382;&#39064;&#65292;&#36825;&#19968;&#38382;&#39064;&#19982;&#22270;&#24418;&#26354;&#29575;&#30456;&#20851;&#65292;&#20316;&#32773;&#21033;&#29992;Ollivier-Ricci&#26354;&#29575;&#25552;&#20986;&#20102;Batch Ollivier-Ricci Flow&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#36825;&#19968;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2211.15779</link><description>&lt;p&gt;
&#20351;&#29992;Ollivier-Ricci&#26354;&#29575;&#37325;&#26032;&#23457;&#35270;&#36807;&#24230;&#24179;&#28369;&#21644;&#36807;&#24230;&#21387;&#32553;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Revisiting Over-smoothing and Over-squashing Using Ollivier-Ricci Curvature. (arXiv:2211.15779v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.15779
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#21457;&#29616;&#22270;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#23384;&#22312;&#36807;&#24230;&#24179;&#28369;&#21644;&#36807;&#24230;&#21387;&#32553;&#38382;&#39064;&#65292;&#36825;&#19968;&#38382;&#39064;&#19982;&#22270;&#24418;&#26354;&#29575;&#30456;&#20851;&#65292;&#20316;&#32773;&#21033;&#29992;Ollivier-Ricci&#26354;&#29575;&#25552;&#20986;&#20102;Batch Ollivier-Ricci Flow&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#36825;&#19968;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;(GNN)&#22825;&#29983;&#23481;&#26131;&#20986;&#29616;&#36807;&#24230;&#24179;&#28369;&#21644;&#36807;&#24230;&#21387;&#32553;&#38382;&#39064;&#12290;&#36825;&#20123;&#38382;&#39064;&#38480;&#21046;&#20102;GNN&#22312;&#36827;&#34892;&#36828;&#36317;&#31163;&#20449;&#24687;&#22788;&#29702;&#26102;&#23545;&#22797;&#26434;&#22270;&#24418;&#30456;&#20114;&#20316;&#29992;&#24314;&#27169;&#30340;&#25928;&#21147;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#25581;&#31034;&#20102;&#23616;&#37096;&#22270;&#24418;&#31354;&#38388;&#21644;&#36825;&#20004;&#20010;&#38382;&#39064;&#20043;&#38388;&#30340;&#20851;&#38190;&#32852;&#31995;&#65292;&#20174;&#32780;&#25552;&#20379;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#26469;&#20351;&#29992;Ollivier-Ricci&#26354;&#29575;&#22312;&#23616;&#37096;&#23610;&#24230;&#19978;&#30740;&#31350;&#23427;&#20204;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#35777;&#26126;&#36807;&#24230;&#24179;&#28369;&#19982;&#27491;&#22270;&#26354;&#29575;&#30456;&#32852;&#31995;&#65292;&#32780;&#36807;&#24230;&#21387;&#32553;&#21017;&#19982;&#36127;&#22270;&#26354;&#29575;&#30456;&#32852;&#31995;&#12290;&#22522;&#20110;&#25105;&#20204;&#30340;&#29702;&#35770;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Batch Ollivier-Ricci Flow&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#37325;&#36830;&#31639;&#27861;&#65292;&#33021;&#22815;&#21516;&#26102;&#35299;&#20915;&#36807;&#24230;&#24179;&#28369;&#21644;&#36807;&#24230;&#21387;&#32553;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Networks (GNNs) had been demonstrated to be inherently susceptible to the problems of over-smoothing and over-squashing. These issues prohibit the ability of GNNs to model complex graph interactions by limiting their effectiveness in taking into account distant information. Our study reveals the key connection between the local graph geometry and the occurrence of both of these issues, thereby providing a unified framework for studying them at a local scale using the Ollivier-Ricci curvature. Specifically, we demonstrate that over-smoothing is linked to positive graph curvature while over-squashing is linked to negative graph curvature. Based on our theory, we propose the Batch Ollivier-Ricci Flow, a novel rewiring algorithm capable of simultaneously addressing both over-smoothing and over-squashing.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#23610;&#24230;&#25299;&#25169;&#22855;&#24322;&#24615;&#26816;&#27979;&#26041;&#27861;&#65292;&#21487;&#20197;&#35780;&#20272;&#25968;&#25454;&#30340;&#23616;&#37096;&#22266;&#26377;&#32500;&#24230;&#65292;&#24182;&#37327;&#21270;&#28857;&#30340;&#8220;&#27969;&#24418;&#24230;&#8221;&#65292;&#33021;&#22815;&#26816;&#27979;&#22797;&#26434;&#31354;&#38388;&#21644;&#22270;&#20687;&#20013;&#30340;&#22855;&#24322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2210.00069</link><description>&lt;p&gt;
&#22810;&#23610;&#24230;&#25299;&#25169;&#22855;&#24322;&#24615;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Topological Singularity Detection at Multiple Scales. (arXiv:2210.00069v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.00069
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#23610;&#24230;&#25299;&#25169;&#22855;&#24322;&#24615;&#26816;&#27979;&#26041;&#27861;&#65292;&#21487;&#20197;&#35780;&#20272;&#25968;&#25454;&#30340;&#23616;&#37096;&#22266;&#26377;&#32500;&#24230;&#65292;&#24182;&#37327;&#21270;&#28857;&#30340;&#8220;&#27969;&#24418;&#24230;&#8221;&#65292;&#33021;&#22815;&#26816;&#27979;&#22797;&#26434;&#31354;&#38388;&#21644;&#22270;&#20687;&#20013;&#30340;&#22855;&#24322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27969;&#24418;&#20551;&#35774;&#26159;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#30740;&#31350;&#30340;&#19968;&#20010;&#22522;&#26412;&#20551;&#35774;&#65292;&#23427;&#20551;&#23450;&#25968;&#25454;&#20301;&#20110;&#25110;&#25509;&#36817;&#20110;&#20302;&#22266;&#26377;&#32500;&#24230;&#30340;&#26410;&#30693;&#27969;&#24418;&#19978;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#29616;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#34920;&#29616;&#20986;&#26126;&#26174;&#30340;&#38750;&#27969;&#24418;&#32467;&#26500;&#65292;&#21363;&#22855;&#24322;&#24615;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#38169;&#35823;&#30340;&#21457;&#29616;&#12290;&#22240;&#27492;&#65292;&#26816;&#27979;&#36825;&#31181;&#22855;&#24322;&#24615;&#22312;&#25554;&#20540;&#21644;&#25512;&#26029;&#20219;&#21153;&#20043;&#21069;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#25105;&#20204;&#36890;&#36807;&#24320;&#21457;&#19968;&#20010;&#25299;&#25169;&#26694;&#26550;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#35813;&#26694;&#26550;&#33021;&#22815;&#65288;i&#65289;&#37327;&#21270;&#23616;&#37096;&#22266;&#26377;&#32500;&#24230;&#65292;&#20197;&#21450;&#65288;ii&#65289;&#22312;&#22810;&#20010;&#23610;&#24230;&#19978;&#20135;&#29983;&#8220;&#27431;&#20960;&#37324;&#24471;&#24615;&#8221;&#35780;&#20998;&#65292;&#29992;&#20197;&#35780;&#20272;&#28857;&#30340;&#8220;&#27969;&#24418;&#24230;&#8221;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#22312;&#22270;&#20687;&#25968;&#25454;&#20013;&#25429;&#33719;&#22797;&#26434;&#31354;&#38388;&#30340;&#22855;&#24322;&#24615;&#65292;&#21516;&#26102;&#25429;&#25417;&#22855;&#24322;&#32467;&#26500;&#21644;&#23616;&#37096;&#20960;&#20309;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The manifold hypothesis, which assumes that data lies on or close to an unknown manifold of low intrinsic dimension, is a staple of modern machine learning research. However, recent work has shown that real-world data exhibits distinct non-manifold structures, i.e. singularities, that can lead to erroneous findings. Detecting such singularities is therefore crucial as a precursor to interpolation and inference tasks. We address this issue by developing a topological framework that (i) quantifies the local intrinsic dimension, and (ii) yields a Euclidicity score for assessing the 'manifoldness' of a point along multiple scales. Our approach identifies singularities of complex spaces, while also capturing singular structures and local geometric complexity in image data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27010;&#29575;&#26694;&#26550;&#65292;&#20026;&#27599;&#20010;&#35266;&#27979;&#20540;&#25552;&#20379;&#31232;&#30095;&#30340;&#23616;&#37096;&#21453;&#20107;&#23454;&#35268;&#21017;&#65292;&#24182;&#23558;&#36825;&#20123;&#35268;&#21017;&#32858;&#21512;&#25104;&#21306;&#22495;&#21453;&#20107;&#23454;&#35268;&#21017;&#65292;&#20197;&#36866;&#24212;&#19981;&#31283;&#23450;&#30340;&#23454;&#29616;&#29615;&#22659;&#65292;&#24182;&#20135;&#29983;&#31283;&#20581;&#30340;&#25937;&#27982;&#25514;&#26045;&#12290;</title><link>http://arxiv.org/abs/2209.14568</link><description>&lt;p&gt;
&#37325;&#26032;&#24605;&#32771;&#21453;&#20107;&#23454;&#35299;&#37322;&#65306;&#20316;&#20026;&#23616;&#37096;&#21644;&#21306;&#22495;&#21453;&#20107;&#23454;&#25919;&#31574;&#30340;&#21453;&#20107;&#23454;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Rethinking Counterfactual Explanations as Local and Regional Counterfactual Policies. (arXiv:2209.14568v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.14568
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27010;&#29575;&#26694;&#26550;&#65292;&#20026;&#27599;&#20010;&#35266;&#27979;&#20540;&#25552;&#20379;&#31232;&#30095;&#30340;&#23616;&#37096;&#21453;&#20107;&#23454;&#35268;&#21017;&#65292;&#24182;&#23558;&#36825;&#20123;&#35268;&#21017;&#32858;&#21512;&#25104;&#21306;&#22495;&#21453;&#20107;&#23454;&#35268;&#21017;&#65292;&#20197;&#36866;&#24212;&#19981;&#31283;&#23450;&#30340;&#23454;&#29616;&#29615;&#22659;&#65292;&#24182;&#20135;&#29983;&#31283;&#20581;&#30340;&#25937;&#27982;&#25514;&#26045;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21453;&#20107;&#23454;&#35299;&#37322;&#65288;CE&#65289;&#38754;&#20020;&#30528;&#35768;&#22810;&#26410;&#35299;&#20915;&#30340;&#25361;&#25112;&#65292;&#22914;&#30830;&#20445;&#31283;&#23450;&#24615;&#12289;&#32508;&#21512;&#22810;&#20010;CE&#20197;&#21450;&#25552;&#20379;&#21512;&#29702;&#24615;&#21644;&#31232;&#30095;&#24615;&#20445;&#35777;&#12290;&#20174;&#26356;&#23454;&#38469;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#25152;&#35268;&#23450;&#30340;&#21453;&#20107;&#23454;&#25937;&#27982;&#25514;&#26045;&#36890;&#24120;&#19981;&#20250;&#34987;&#20010;&#20307;&#23436;&#20840;&#23454;&#26045;&#65292;&#24182;&#35777;&#26126;&#22823;&#22810;&#25968;&#26368;&#20808;&#36827;&#30340;CE&#31639;&#27861;&#22312;&#36825;&#31181;&#22024;&#26434;&#30340;&#29615;&#22659;&#20013;&#24456;&#21487;&#33021;&#22833;&#36133;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#27010;&#29575;&#26694;&#26550;&#65292;&#20026;&#27599;&#20010;&#35266;&#27979;&#20540;&#25552;&#20379;&#31232;&#30095;&#30340;&#23616;&#37096;&#21453;&#20107;&#23454;&#35268;&#21017;&#65292;&#25552;&#20379;&#33021;&#22815;&#20197;&#39640;&#27010;&#29575;&#25913;&#21464;&#20915;&#31574;&#30340;&#20540;&#33539;&#22260;&#30340;&#35268;&#21017;&#12290;&#36825;&#20123;&#35268;&#21017;&#20316;&#20026;&#22810;&#26679;&#30340;&#21453;&#20107;&#23454;&#35299;&#37322;&#30340;&#24635;&#32467;&#65292;&#24182;&#20135;&#29983;&#31283;&#20581;&#30340;&#25937;&#27982;&#25514;&#26045;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23558;&#36825;&#20123;&#23616;&#37096;&#35268;&#21017;&#32858;&#21512;&#25104;&#21306;&#22495;&#21453;&#20107;&#23454;&#35268;&#21017;&#65292;&#35782;&#21035;&#25968;&#25454;&#23376;&#32452;&#30340;&#20849;&#20139;&#25937;&#27982;&#25514;&#26045;&#12290;&#25105;&#20204;&#30340;&#23616;&#37096;&#21644;&#21306;&#22495;&#35268;&#21017;&#26469;&#33258;&#20110;&#38543;&#26426;&#26862;&#26519;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Counterfactual Explanations (CE) face several unresolved challenges, such as ensuring stability, synthesizing multiple CEs, and providing plausibility and sparsity guarantees. From a more practical point of view, recent studies [Pawelczyk et al., 2022] show that the prescribed counterfactual recourses are often not implemented exactly by individuals and demonstrate that most state-of-the-art CE algorithms are very likely to fail in this noisy environment. To address these issues, we propose a probabilistic framework that gives a sparse local counterfactual rule for each observation, providing rules that give a range of values capable of changing decisions with high probability. These rules serve as a summary of diverse counterfactual explanations and yield robust recourses. We further aggregate these local rules into a regional counterfactual rule, identifying shared recourses for subgroups of the data. Our local and regional rules are derived from the Random Forest algorithm, which of
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#20114;&#34917;&#26680;&#23398;&#20064;&#65288;BCKL&#65289;&#26694;&#26550;&#65292;&#23427;&#23558;&#26680;&#21270;&#20302;&#31209;&#24352;&#37327;&#20998;&#35299;&#21644;&#30701;&#31243;&#26102;&#31354;&#39640;&#26031;&#36807;&#31243;&#30456;&#32467;&#21512;&#65292;&#21487;&#26377;&#25928;&#22320;&#24314;&#27169;&#22810;&#32500;&#26102;&#31354;&#25968;&#25454;&#30340;&#22797;&#26434;&#30456;&#20851;&#24615;&#12290;</title><link>http://arxiv.org/abs/2208.09978</link><description>&lt;p&gt;
&#22810;&#32500;&#26102;&#31354;&#25968;&#25454;&#30340;&#36125;&#21494;&#26031;&#20114;&#34917;&#26680;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Bayesian Complementary Kernelized Learning for Multidimensional Spatiotemporal Data. (arXiv:2208.09978v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.09978
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#20114;&#34917;&#26680;&#23398;&#20064;&#65288;BCKL&#65289;&#26694;&#26550;&#65292;&#23427;&#23558;&#26680;&#21270;&#20302;&#31209;&#24352;&#37327;&#20998;&#35299;&#21644;&#30701;&#31243;&#26102;&#31354;&#39640;&#26031;&#36807;&#31243;&#30456;&#32467;&#21512;&#65292;&#21487;&#26377;&#25928;&#22320;&#24314;&#27169;&#22810;&#32500;&#26102;&#31354;&#25968;&#25454;&#30340;&#22797;&#26434;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#32500;&#26102;&#31354;&#25968;&#25454;&#30340;&#27010;&#29575;&#24314;&#27169;&#23545;&#35768;&#22810;&#29616;&#23454;&#24212;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#30001;&#20110;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#26102;&#31354;&#25968;&#25454;&#24448;&#24448;&#34920;&#29616;&#20986;&#38750;&#24179;&#31283;&#21644;&#38750;&#21487;&#20998;&#31163;&#30340;&#22797;&#26434;&#20381;&#36182;&#20851;&#31995;&#65292;&#22240;&#27492;&#24320;&#21457;&#26377;&#25928;&#19988;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#32479;&#35745;&#27169;&#22411;&#20197;&#36866;&#24212;&#21516;&#26102;&#21253;&#21547;&#38271;&#31243;&#21644;&#30701;&#31243;&#21464;&#21270;&#30340;&#38750;&#31283;&#24577;/&#19981;&#21487;&#20998;&#31163;&#36807;&#31243;&#21464;&#24471;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#23588;&#20854;&#26159;&#23545;&#20110;&#20855;&#26377;&#19981;&#21516;&#30772;&#22351;/&#32570;&#22833;&#32467;&#26500;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32479;&#35745;&#26694;&#26550; - &#36125;&#21494;&#26031;&#20114;&#34917;&#26680;&#23398;&#20064;&#65288;BCKL&#65289; - &#29992;&#20110;&#23454;&#29616;&#22810;&#32500;&#26102;&#31354;&#25968;&#25454;&#30340;&#21487;&#25193;&#23637;&#27010;&#29575;&#24314;&#27169;&#12290;&#20026;&#20102;&#26377;&#25928;&#22320;&#34920;&#24449;&#22797;&#26434;&#20381;&#36182;&#20851;&#31995;&#65292;BCKL&#38598;&#25104;&#20102;&#20004;&#20010;&#20114;&#34917;&#26041;&#27861;&#8212;&#8212;&#26680;&#20302;&#31209;&#24352;&#37327;&#20998;&#35299;&#21644;&#30701;&#31243;&#26102;&#31354;&#39640;&#26031;&#36807;&#31243;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20351;&#29992;&#22810;&#32447;&#24615;&#20302;&#31209;&#22240;&#23376;&#20998;&#35299;&#32452;&#20214;&#26469;&#25429;&#33719;&#20840;&#23616;/&#38271;&#31243;&#30456;&#20851;&#24615;&#65292;&#24182;&#20351;&#29992;&#30701;&#31243;&#26102;&#31354;&#39640;&#26031;&#36807;&#31243;&#26469;&#25429;&#33719;&#23616;&#37096;/&#30701;&#31243;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Probabilistic modeling of multidimensional spatiotemporal data is critical to many real-world applications. As real-world spatiotemporal data often exhibits complex dependencies that are nonstationary and nonseparable, developing effective and computationally efficient statistical models to accommodate nonstationary/nonseparable processes containing both long-range and short-scale variations becomes a challenging task, in particular for large-scale datasets with various corruption/missing structures. In this paper, we propose a new statistical framework -- Bayesian Complementary Kernelized Learning (BCKL) -to achieve scalable probabilistic modeling for multidimensional spatiotemporal data. To effectively characterize complex dependencies, BCKL integrates two complementary approaches -- kernelized low-rank tensor factorization and short-range spatiotemporal Gaussian Processes. Specifically, we use a multi-linear low-rank factorization component to capture the global/long-range correla
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#22312;&#20869;&#26680;&#29615;&#22659;&#19979;&#30340;&#26080;&#38480;&#23485;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65292;&#35777;&#26126;&#20102;&#28145;&#23618;CNN&#33021;&#22815;&#36866;&#24212;&#30446;&#26631;&#20989;&#25968;&#30340;&#31354;&#38388;&#23610;&#24230;&#65292;&#21363;&#20351;&#25968;&#25454;&#27809;&#26377;&#23616;&#37096;&#32467;&#26500;&#65292;&#28145;&#23618;CNN&#20063;&#21487;&#20197;&#23398;&#20064;&#65292;&#21482;&#35201;&#20840;&#23616;&#32467;&#26500;&#21487;&#20197;&#34987;&#21033;&#29992;&#12290;</title><link>http://arxiv.org/abs/2208.01003</link><description>&lt;p&gt;
&#23485;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#33021;&#22815;&#23398;&#21040;&#20160;&#20040;&#65311;
&lt;/p&gt;
&lt;p&gt;
What Can Be Learnt With Wide Convolutional Neural Networks?. (arXiv:2208.01003v5 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.01003
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22312;&#20869;&#26680;&#29615;&#22659;&#19979;&#30340;&#26080;&#38480;&#23485;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65292;&#35777;&#26126;&#20102;&#28145;&#23618;CNN&#33021;&#22815;&#36866;&#24212;&#30446;&#26631;&#20989;&#25968;&#30340;&#31354;&#38388;&#23610;&#24230;&#65292;&#21363;&#20351;&#25968;&#25454;&#27809;&#26377;&#23616;&#37096;&#32467;&#26500;&#65292;&#28145;&#23618;CNN&#20063;&#21487;&#20197;&#23398;&#20064;&#65292;&#21482;&#35201;&#20840;&#23616;&#32467;&#26500;&#21487;&#20197;&#34987;&#21033;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#22914;&#20309;&#39640;&#25928;&#22320;&#23398;&#20064;&#39640;&#32500;&#20989;&#25968;&#20173;&#28982;&#26159;&#19968;&#20010;&#22522;&#26412;&#25361;&#25112;&#12290;&#20154;&#20204;&#26222;&#36941;&#35748;&#20026;&#65292;&#36825;&#20123;&#27169;&#22411;&#21033;&#29992;&#20102;&#33258;&#28982;&#25968;&#25454;&#65288;&#22914;&#22270;&#20687;&#65289;&#30340;&#23616;&#37096;&#21644;&#20998;&#23618;&#32467;&#26500;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#32570;&#20047;&#22914;&#27492;&#32467;&#26500;&#22914;&#20309;&#24433;&#21709;&#24615;&#33021;&#30340;&#37327;&#21270;&#29702;&#35299;&#65292;&#22914;&#27867;&#21270;&#35823;&#24046;&#38543;&#35757;&#32451;&#26679;&#26412;&#25968;&#37327;&#30340;&#34928;&#20943;&#36895;&#29575;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20869;&#26680;&#29615;&#22659;&#19979;&#30340;&#26080;&#38480;&#23485;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#23637;&#31034;&#20102;&#30456;&#24212;&#26680;&#30340;&#35889;&#27839;&#34989;&#20102;&#32593;&#32476;&#30340;&#20998;&#23618;&#32467;&#26500;&#65292;&#24182;&#34920;&#24449;&#20102;&#20854;&#28176;&#36827;&#24615;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#36825;&#20010;&#32467;&#26524;&#19982;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#32467;&#21512;&#36215;&#26469;&#65292;&#35777;&#26126;&#20102;&#28145;&#23618;CNN&#33021;&#22815;&#36866;&#24212;&#30446;&#26631;&#20989;&#25968;&#30340;&#31354;&#38388;&#23610;&#24230;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#21457;&#29616;&#65292;&#22914;&#26524;&#30446;&#26631;&#20989;&#25968;&#20381;&#36182;&#20110;&#30456;&#37051;&#36755;&#20837;&#21464;&#37327;&#30340;&#20302;&#32500;&#23376;&#38598;&#65292;&#21017;&#35823;&#24046;&#30340;&#34928;&#20943;&#21463;&#21040;&#36825;&#20123;&#23376;&#38598;&#30340;&#26377;&#25928;&#32500;&#25968;&#30340;&#25511;&#21046;&#12290;&#30456;&#21453;&#65292;&#22914;&#26524;&#20989;&#25968;&#20381;&#36182;&#20110;&#39640;&#32500;&#32467;&#26500;&#65292;&#21017;&#26377;&#25928;&#32500;&#25968;&#21463;&#32593;&#32476;&#23485;&#24230;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#24773;&#20917;&#19979;&#65292;&#21363;&#20351;&#25968;&#25454;&#27809;&#26377;&#23616;&#37096;&#32467;&#26500;&#65292;&#28145;&#23618;CNN&#20063;&#21487;&#20197;&#23398;&#20064;&#65292;&#21482;&#35201;&#20840;&#23616;&#32467;&#26500;&#21487;&#20197;&#34987;&#21033;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding how convolutional neural networks (CNNs) can efficiently learn high-dimensional functions remains a fundamental challenge. A popular belief is that these models harness the local and hierarchical structure of natural data such as images. Yet, we lack a quantitative understanding of how such structure affects performance, e.g., the rate of decay of the generalisation error with the number of training samples. In this paper, we study infinitely-wide deep CNNs in the kernel regime. First, we show that the spectrum of the corresponding kernel inherits the hierarchical structure of the network, and we characterise its asymptotics. Then, we use this result together with generalisation bounds to prove that deep CNNs adapt to the spatial scale of the target function. In particular, we find that if the target function depends on low-dimensional subsets of adjacent input variables, then the decay of the error is controlled by the effective dimensionality of these subsets. Conversel
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21306;&#38388;&#20256;&#25773;&#30340;IBP&#27491;&#21017;&#21270;&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#25193;&#22823;&#30340;&#39046;&#22495;&#19978;&#36827;&#34892;&#23545;&#25239;&#24615;&#25915;&#20987;&#24182;&#32467;&#21512;&#19968;&#31181;&#22522;&#20110;&#24265;&#20215;&#21306;&#38388;&#20256;&#25773;&#30340;&#27491;&#21017;&#21270;&#39033;&#26469;&#24341;&#20837;&#32593;&#32476;&#30340;&#21487;&#39564;&#35777;&#24615;&#65292;&#20174;&#32780;&#23454;&#29616;&#23545;&#25239;&#35757;&#32451;&#32593;&#32476;&#30340;&#39564;&#35777;&#31283;&#20581;&#24615;&#12290;</title><link>http://arxiv.org/abs/2206.14772</link><description>&lt;p&gt;
&#22522;&#20110;&#21306;&#38388;&#20256;&#25773;&#30340;IBP&#27491;&#21017;&#21270;&#26041;&#27861;&#25552;&#39640;&#23545;&#25239;&#35757;&#32451;&#32593;&#32476;&#30340;&#39564;&#35777;&#31283;&#20581;&#24615;
&lt;/p&gt;
&lt;p&gt;
IBP Regularization for Verified Adversarial Robustness via Branch-and-Bound. (arXiv:2206.14772v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.14772
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21306;&#38388;&#20256;&#25773;&#30340;IBP&#27491;&#21017;&#21270;&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#25193;&#22823;&#30340;&#39046;&#22495;&#19978;&#36827;&#34892;&#23545;&#25239;&#24615;&#25915;&#20987;&#24182;&#32467;&#21512;&#19968;&#31181;&#22522;&#20110;&#24265;&#20215;&#21306;&#38388;&#20256;&#25773;&#30340;&#27491;&#21017;&#21270;&#39033;&#26469;&#24341;&#20837;&#32593;&#32476;&#30340;&#21487;&#39564;&#35777;&#24615;&#65292;&#20174;&#32780;&#23454;&#29616;&#23545;&#25239;&#35757;&#32451;&#32593;&#32476;&#30340;&#39564;&#35777;&#31283;&#20581;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#30340;&#24037;&#20316;&#23581;&#35797;&#36890;&#36807;&#22312;&#25193;&#22823;&#30340;&#39046;&#22495;&#19978;&#36816;&#34892;&#25915;&#20987;&#24182;&#21521;&#30446;&#26631;&#20989;&#25968;&#20013;&#28155;&#21152;&#21508;&#31181;&#27491;&#21017;&#39033;&#26469;&#22686;&#21152;&#23545;&#25239;&#35757;&#32451;&#32593;&#32476;&#30340;&#21487;&#39564;&#35777;&#24615;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#31639;&#27861;&#35201;&#20040;&#24615;&#33021;&#19981;&#20339;&#65292;&#35201;&#20040;&#38656;&#35201;&#22797;&#26434;&#21644;&#26114;&#36149;&#30340;&#20998;&#38454;&#27573;&#35757;&#32451;&#36807;&#31243;&#65292;&#20174;&#32780;&#24433;&#21709;&#20854;&#23454;&#38469;&#24212;&#29992;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#39564;&#35777;&#35757;&#32451;&#31639;&#27861;IBP-R&#65292;&#23427;&#26082;&#31616;&#21333;&#21448;&#26377;&#25928;&#12290;IBP-R&#36890;&#36807;&#22312;&#25193;&#22823;&#30340;&#39046;&#22495;&#19978;&#36827;&#34892;&#23545;&#25239;&#24615;&#25915;&#20987;&#24182;&#32467;&#21512;&#19968;&#31181;&#22522;&#20110;&#24265;&#20215;&#21306;&#38388;&#20256;&#25773;&#30340;&#27491;&#21017;&#21270;&#39033;&#26469;&#24341;&#20837;&#32593;&#32476;&#30340;&#21487;&#39564;&#35777;&#24615;&#65292;&#20174;&#32780;&#26368;&#23567;&#21270;&#38750;&#20984;&#39564;&#35777;&#38382;&#39064;&#19982;&#20854;&#36817;&#20284;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#36890;&#36807;&#21033;&#29992;&#26368;&#36817;&#30340;&#20998;&#25903;&#23450;&#30028;&#26694;&#26550;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;IBP-R&#22312;CIFAR-10&#23567;&#25200;&#21160;&#19978;&#33719;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#39564;&#35777;&#31283;&#20581;&#24615;-&#20934;&#30830;&#24615;&#24179;&#34913;&#65292;&#21516;&#26102;&#27604;&#30456;&#20851;&#20808;&#21069;&#24037;&#20316;&#35757;&#32451;&#36895;&#24230;&#26356;&#24555;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#25903;&#31639;&#27861;UPB&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent works have tried to increase the verifiability of adversarially trained networks by running the attacks over domains larger than the original perturbations and adding various regularization terms to the objective. However, these algorithms either underperform or require complex and expensive stage-wise training procedures, hindering their practical applicability. We present IBP-R, a novel verified training algorithm that is both simple and effective. IBP-R induces network verifiability by coupling adversarial attacks on enlarged domains with a regularization term, based on inexpensive interval bound propagation, that minimizes the gap between the non-convex verification problem and its approximations. By leveraging recent branch-and-bound frameworks, we show that IBP-R obtains state-of-the-art verified robustness-accuracy trade-offs for small perturbations on CIFAR-10 while training significantly faster than relevant previous work. Additionally, we present UPB, a novel branching
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#32467;&#21512;&#33021;&#37327;&#30340;&#27010;&#24565;&#65292;&#35777;&#26126;&#20102;&#24102;&#23545;&#31216;&#28388;&#27874;&#22120;&#30340;&#32447;&#24615;&#22270;&#21367;&#31215;&#21487;&#20197;&#22686;&#24378;&#39640;&#39057;&#29575;&#65292;&#20351;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#21516;&#36136;&#21644;&#24322;&#36136;&#20219;&#21153;&#20013;&#34920;&#29616;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2206.10991</link><description>&lt;p&gt;
&#36890;&#36807;&#22270;&#19978;&#30340;&#33021;&#37327;&#29702;&#35299;&#21367;&#31215;
&lt;/p&gt;
&lt;p&gt;
Understanding convolution on graphs via energies. (arXiv:2206.10991v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.10991
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#32467;&#21512;&#33021;&#37327;&#30340;&#27010;&#24565;&#65292;&#35777;&#26126;&#20102;&#24102;&#23545;&#31216;&#28388;&#27874;&#22120;&#30340;&#32447;&#24615;&#22270;&#21367;&#31215;&#21487;&#20197;&#22686;&#24378;&#39640;&#39057;&#29575;&#65292;&#20351;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#21516;&#36136;&#21644;&#24322;&#36136;&#20219;&#21153;&#20013;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#36890;&#24120;&#36890;&#36807;&#28040;&#24687;&#20256;&#36882;&#25805;&#20316;&#65292;&#20854;&#20013;&#33410;&#28857;&#30340;&#29366;&#24577;&#26159;&#22522;&#20110;&#20854;&#37051;&#23621;&#25910;&#21040;&#30340;&#20449;&#24687;&#36827;&#34892;&#26356;&#26032;&#30340;&#12290;&#22823;&#22810;&#25968;&#28040;&#24687;&#20256;&#36882;&#27169;&#22411;&#37117;&#26159;&#20316;&#20026;&#22270;&#21367;&#31215;&#36827;&#34892;&#25805;&#20316;&#30340;&#65292;&#20854;&#20013;&#29305;&#24449;&#22312;&#34987;&#20256;&#25773;&#21040;&#36793;&#32536;&#20043;&#21069;&#36890;&#36807;&#20849;&#20139;&#30340;&#32447;&#24615;&#21464;&#25442;&#28151;&#21512;&#12290;&#22312;&#33410;&#28857;&#20998;&#31867;&#20219;&#21153;&#20013;&#65292;&#22270;&#21367;&#31215;&#24050;&#32463;&#34920;&#29616;&#20986;&#20004;&#20010;&#38480;&#21046;&#65306;&#22312;heterophilic&#22270;&#19978;&#34920;&#29616;&#27424;&#20339;&#65292;&#24182;&#19988;&#36807;&#24230;&#24179;&#28369;&#12290;&#24120;&#35265;&#30340;&#30475;&#27861;&#26159;&#65292;&#36825;&#20004;&#31181;&#29616;&#35937;&#30340;&#21457;&#29983;&#26159;&#22240;&#20026;&#36825;&#31181;&#27169;&#22411;&#34920;&#29616;&#20026;&#20302;&#36890;&#28388;&#27874;&#22120;&#65292;&#24847;&#21619;&#30528;&#22312;&#22270;&#23618;&#38388;&#29305;&#24449;&#30340;Dirichlet&#33021;&#37327;&#20250;&#20943;&#23569;&#65292;&#23548;&#33268;&#24179;&#28369;&#25928;&#24212;&#65292;&#26368;&#32456;&#29305;&#24449;&#19981;&#20877;&#21487;&#21306;&#20998;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20005;&#35880;&#22320;&#35777;&#26126;&#20102;&#31616;&#21333;&#30340;&#22270;&#21367;&#31215;&#27169;&#22411;&#23454;&#38469;&#19978;&#21487;&#20197;&#22686;&#24378;&#39640;&#39057;&#29575;&#29978;&#33267;&#24341;&#23548;&#19968;&#31181;&#25105;&#20204;&#25152;&#31216;&#30340;&#36807;&#24230;&#38160;&#21270;&#30340;&#28176;&#36817;&#34892;&#20026;&#65292;&#19982;&#36807;&#24230;&#24179;&#28369;&#30456;&#21453;&#12290;&#25105;&#20204;&#36890;&#36807;&#34920;&#26126;&#23545;&#31216;&#28388;&#27874;&#22120;&#30340;&#32447;&#24615;&#22270;&#21367;&#31215;&#21487;&#20197;&#34987;&#35299;&#37322;&#20026;&#22312;&#22270;&#24418;&#19978;&#30340;&#33021;&#37327;&#26368;&#23567;&#21270;&#38382;&#39064;&#26469;&#20570;&#21040;&#36825;&#19968;&#28857;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#33021;&#37327;&#20989;&#25968;&#24809;&#32602;&#39640;&#33021;&#20449;&#21495;&#65292;&#26377;&#25928;&#22320;&#25233;&#21046;&#20302;&#39057;&#65292;&#21516;&#26102;&#20419;&#36827;&#30456;&#20851;&#30340;&#39640;&#39057;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#31934;&#24515;&#35774;&#35745;&#30340;&#22270;&#21367;&#31215;&#27169;&#22411;&#21487;&#20197;&#22312;&#21516;&#36136;&#21644;&#24322;&#36136;&#20219;&#21153;&#19978;&#25552;&#20379;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Networks (GNNs) typically operate by message-passing, where the state of a node is updated based on the information received from its neighbours. Most message-passing models act as graph convolutions, where features are mixed by a shared, linear transformation before being propagated over the edges. On node-classification tasks, graph convolutions have been shown to suffer from two limitations: poor performance on heterophilic graphs, and over-smoothing. It is common belief that both phenomena occur because such models behave as low-pass filters, meaning that the Dirichlet energy of the features decreases along the layers incurring a smoothing effect that ultimately makes features no longer distinguishable. In this work, we rigorously prove that simple graph-convolutional models can actually enhance high frequencies and even lead to an asymptotic behaviour we refer to as over-sharpening, opposite to over-smoothing. We do so by showing that linear graph convolutions with sy
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36974;&#34109;&#33258;&#32534;&#30721;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#22270;&#20687;&#21644;&#35270;&#39057;&#19978;&#35757;&#32451;&#19968;&#20010;&#31616;&#21333;&#30340;&#21333;&#19968;Vision Transformer&#27169;&#22411;&#65292;&#32780;&#19981;&#38656;&#35201;&#26631;&#35760;&#25968;&#25454;&#65292;&#35813;&#27169;&#22411;&#30340;&#35270;&#35273;&#34920;&#31034;&#21487;&#19982;&#21333;&#27169;&#24577;&#34920;&#31034;&#22312;&#22522;&#20934;&#27979;&#35797;&#19978;&#30456;&#24403;&#25110;&#26356;&#22909;&#65292;&#24182;&#19988;&#20351;&#29992;&#26356;&#31616;&#21333;&#30340;&#26550;&#26500;&#12290;</title><link>http://arxiv.org/abs/2206.08356</link><description>&lt;p&gt;
OmniMAE: &#22270;&#29255;&#21644;&#35270;&#39057;&#19978;&#30340;&#21333;&#19968;&#27169;&#22411;&#36974;&#34109;&#39044;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
OmniMAE: Single Model Masked Pretraining on Images and Videos. (arXiv:2206.08356v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.08356
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36974;&#34109;&#33258;&#32534;&#30721;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#22270;&#20687;&#21644;&#35270;&#39057;&#19978;&#35757;&#32451;&#19968;&#20010;&#31616;&#21333;&#30340;&#21333;&#19968;Vision Transformer&#27169;&#22411;&#65292;&#32780;&#19981;&#38656;&#35201;&#26631;&#35760;&#25968;&#25454;&#65292;&#35813;&#27169;&#22411;&#30340;&#35270;&#35273;&#34920;&#31034;&#21487;&#19982;&#21333;&#27169;&#24577;&#34920;&#31034;&#22312;&#22522;&#20934;&#27979;&#35797;&#19978;&#30456;&#24403;&#25110;&#26356;&#22909;&#65292;&#24182;&#19988;&#20351;&#29992;&#26356;&#31616;&#21333;&#30340;&#26550;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;Transformer&#30340;&#20307;&#31995;&#32467;&#26500;&#22312;&#21508;&#31181;&#35270;&#35273;&#39046;&#22495;&#20013;&#24050;&#21464;&#24471;&#31454;&#20105;&#21147;&#21313;&#36275;&#65292;&#20854;&#20013;&#26368;&#33879;&#21517;&#30340;&#26159;&#22270;&#20687;&#21644;&#35270;&#39057;&#12290;&#20043;&#21069;&#30340;&#24037;&#20316;&#36890;&#24120;&#26159;&#30740;&#31350;&#36825;&#20123;&#27169;&#24577;&#20043;&#38388;&#30340;&#38548;&#31163;&#65292;&#20294;&#26159;&#20855;&#26377;&#30456;&#21516;&#30340;&#26550;&#26500;&#24847;&#21619;&#30528;&#21487;&#20197;&#20026;&#22810;&#20010;&#35270;&#35273;&#27169;&#24577;&#35757;&#32451;&#19968;&#20010;&#21333;&#19968;&#30340;&#32479;&#19968;&#27169;&#22411;&#12290;&#20043;&#21069;&#30340;&#32479;&#19968;&#24314;&#27169;&#23581;&#35797;&#36890;&#24120;&#20351;&#29992;&#19987;&#38376;&#20026;&#35270;&#35273;&#20219;&#21153;&#37327;&#36523;&#23450;&#21046;&#30340;&#26550;&#26500;&#65292;&#25110;&#19982;&#21333;&#27169;&#24577;&#27169;&#22411;&#30456;&#27604;&#34920;&#29616;&#26356;&#24046;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36974;&#34109;&#33258;&#32534;&#30721;&#21487;&#20197;&#29992;&#20110;&#22312;&#22270;&#20687;&#21644;&#35270;&#39057;&#19978;&#35757;&#32451;&#19968;&#20010;&#31616;&#21333;&#30340;Vision Transformer&#27169;&#22411;&#65292;&#32780;&#26080;&#38656;&#20219;&#20309;&#26631;&#35760;&#25968;&#25454;&#12290;&#36825;&#20010;&#21333;&#19968;&#30340;&#27169;&#22411;&#23398;&#20064;&#30340;&#35270;&#35273;&#34920;&#31034;&#19982;&#21333;&#27169;&#24577;&#34920;&#31034;&#22312;&#22270;&#20687;&#21644;&#35270;&#39057;&#22522;&#20934;&#27979;&#35797;&#19978;&#30456;&#24403;&#25110;&#26356;&#22909;&#65292;&#21516;&#26102;&#20351;&#29992;&#26356;&#31616;&#21333;&#30340;&#26550;&#26500;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#21024;&#38500;90&#65285;&#30340;&#22270;&#20687;&#21644;95&#65285;&#30340;&#35270;&#39057;&#34917;&#19969;&#65292;&#21487;&#20197;&#23398;&#20064;&#35813;&#27169;&#22411;&#65292;&#20174;&#32780;&#23454;&#29616;&#26497;&#24555;&#30340;&#22823;&#22411;&#27169;&#22411;&#26550;&#26500;&#35757;&#32451;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#21333;&#19968;ViT-Hu
&lt;/p&gt;
&lt;p&gt;
Transformer-based architectures have become competitive across a variety of visual domains, most notably images and videos. While prior work studies these modalities in isolation, having a common architecture suggests that one can train a single unified model for multiple visual modalities. Prior attempts at unified modeling typically use architectures tailored for vision tasks, or obtain worse performance compared to single modality models. In this work, we show that masked autoencoding can be used to train a simple Vision Transformer on images and videos, without requiring any labeled data. This single model learns visual representations that are comparable to or better than single-modality representations on both image and video benchmarks, while using a much simpler architecture. Furthermore, this model can be learned by dropping 90% of the image and 95% of the video patches, enabling extremely fast training of huge model architectures. In particular, we show that our single ViT-Hu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992; PAC-Bayesian &#29702;&#35770;&#65292;&#25552;&#20986;&#20102;&#33258;&#36866;&#24212;&#20999;&#29255;&#29926;&#30782;&#26031;&#22374;&#36317;&#31163;&#30340;&#27010;&#25324;&#29305;&#24615;&#30028;&#38480;&#21644;&#19968;&#31181;&#22522;&#20110;&#30028;&#38480;&#30340;&#20999;&#29255;&#20998;&#24067;&#23398;&#20064;&#27969;&#31243;&#65292;&#20197;&#25552;&#39640; SW &#30340;&#21028;&#21035;&#24230;&#12290;</title><link>http://arxiv.org/abs/2206.03230</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#20999;&#29255;&#29926;&#30782;&#26031;&#22374;&#36317;&#31163;&#30340; PAC-Bayesian &#20809;&#29031;
&lt;/p&gt;
&lt;p&gt;
Shedding a PAC-Bayesian Light on Adaptive Sliced-Wasserstein Distances. (arXiv:2206.03230v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.03230
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992; PAC-Bayesian &#29702;&#35770;&#65292;&#25552;&#20986;&#20102;&#33258;&#36866;&#24212;&#20999;&#29255;&#29926;&#30782;&#26031;&#22374;&#36317;&#31163;&#30340;&#27010;&#25324;&#29305;&#24615;&#30028;&#38480;&#21644;&#19968;&#31181;&#22522;&#20110;&#30028;&#38480;&#30340;&#20999;&#29255;&#20998;&#24067;&#23398;&#20064;&#27969;&#31243;&#65292;&#20197;&#25552;&#39640; SW &#30340;&#21028;&#21035;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20999;&#29255;&#29926;&#30782;&#26031;&#22374;&#36317;&#31163;&#65288;SW&#65289;&#26159;&#29926;&#30782;&#26031;&#22374;&#36317;&#31163;&#30340;&#19968;&#31181;&#35745;&#31639;&#26377;&#25928;&#19988;&#29702;&#35770;&#22522;&#30784;&#33391;&#22909;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#20851;&#20110;&#20854;&#32479;&#35745;&#29305;&#24615;&#65288;&#25110;&#26356;&#20934;&#30830;&#22320;&#35828;&#65292;&#20851;&#20110;&#20854;&#30456;&#23545;&#20110;&#8220;&#20999;&#29255;&#8221;&#30340;&#20998;&#24067;&#30340;&#27010;&#25324;&#29305;&#24615;&#65292;&#36229;&#36234;&#22343;&#21248;&#20998;&#24067;&#65289;&#65292;&#25991;&#29486;&#36164;&#26009;&#26497;&#20026;&#26377;&#38480;&#12290;&#20026;&#20102;&#20026;&#36825;&#19968;&#30740;&#31350;&#26041;&#21521;&#24102;&#26469;&#26032;&#30340;&#36129;&#29486;&#65292;&#26412;&#25991;&#21033;&#29992; PAC-Bayesian &#29702;&#35770;&#21644;&#19968;&#20010;&#26680;&#24515;&#35266;&#23519;&#32467;&#26524;&#65306;SW &#21487;&#20197;&#34987;&#35299;&#37322;&#20026;&#24179;&#22343;&#39118;&#38505;&#65292;PAC-Bayesian &#30028;&#23450;&#20854;&#29305;&#24615;&#30340;&#37327;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#19977;&#31181;&#32467;&#26524;&#65306;i&#65289;PAC-Bayesian &#30340;&#27010;&#25324;&#24615;&#30028;&#38480;&#65292;&#36866;&#29992;&#20110;&#25105;&#20204;&#25152;&#31216;&#30340;&#33258;&#36866;&#24212;&#20999;&#29255;&#29926;&#30782;&#26031;&#22374;&#36317;&#31163;&#65292;&#21363;&#30456;&#23545;&#20110;&#20219;&#24847;&#20998;&#24067;&#30340;&#20999;&#29255;&#65288;&#21253;&#25324;&#25968;&#25454;&#30456;&#20851;&#20998;&#24067;&#65289;&#23450;&#20041;&#30340; SW&#65307;ii&#65289;&#19968;&#31181;&#22522;&#20110;&#29702;&#35770;&#30028;&#38480;&#30340;&#21407;&#21017;&#24615;&#27969;&#31243;&#65292;&#29992;&#20110;&#23398;&#20064;&#20999;&#29255;&#20998;&#24067;&#65292;&#20197;&#24471;&#21040;&#26368;&#22823;&#21028;&#21035; SW&#65307;iii&#65289;&#25105;&#20204;&#30340;&#29702;&#35770;&#21644;&#31639;&#27861;&#30340;&#23454;&#35777;&#35828;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Sliced-Wasserstein distance (SW) is a computationally efficient and theoretically grounded alternative to the Wasserstein distance. Yet, the literature on its statistical properties -- or, more accurately, its generalization properties -- with respect to the distribution of slices, beyond the uniform measure, is scarce. To bring new contributions to this line of research, we leverage the PAC-Bayesian theory and a central observation that SW may be interpreted as an average risk, the quantity PAC-Bayesian bounds have been designed to characterize. We provide three types of results: i) PAC-Bayesian generalization bounds that hold on what we refer as adaptive Sliced-Wasserstein distances, i.e. SW defined with respect to arbitrary distributions of slices (among which data-dependent distributions), ii) a principled procedure to learn the distribution of slices that yields maximally discriminative SW, by optimizing our theoretical bounds, and iii) empirical illustrations of our theoretic
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#24046;&#20998;&#38544;&#31169;&#19979;&#36817;&#20284;&#21033;&#26222;&#24076;&#33576;&#21644;&#24179;&#28369;&#20989;&#25968;&#30340;&#38745;&#24577;&#28857;&#38382;&#39064;&#12290;&#25552;&#20379;&#20102;&#26032;&#30340;&#39640;&#25928;&#31639;&#27861;&#21644;&#26500;&#36896;&#65292;&#20998;&#21035;&#22312;&#26377;&#38480;&#21644;&#38543;&#26426;&#24773;&#20917;&#19979;&#27604;&#29616;&#26377;&#31639;&#27861;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2206.00846</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#20248;&#21270;&#20013;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#21040;&#38745;&#24577;&#28857;
&lt;/p&gt;
&lt;p&gt;
Faster Rates of Convergence to Stationary Points in Differentially Private Optimization. (arXiv:2206.00846v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.00846
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#24046;&#20998;&#38544;&#31169;&#19979;&#36817;&#20284;&#21033;&#26222;&#24076;&#33576;&#21644;&#24179;&#28369;&#20989;&#25968;&#30340;&#38745;&#24577;&#28857;&#38382;&#39064;&#12290;&#25552;&#20379;&#20102;&#26032;&#30340;&#39640;&#25928;&#31639;&#27861;&#21644;&#26500;&#36896;&#65292;&#20998;&#21035;&#22312;&#26377;&#38480;&#21644;&#38543;&#26426;&#24773;&#20917;&#19979;&#27604;&#29616;&#26377;&#31639;&#27861;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;$(\varepsilon,\delta)$-&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#19979;&#65292;&#36817;&#20284;&#21033;&#26222;&#24076;&#33576;&#21644;&#24179;&#28369;&#20989;&#25968;&#30340;&#38745;&#24577;&#28857;&#30340;&#38382;&#39064;&#65292;&#28041;&#21450;&#20102;&#26377;&#38480;&#21644;&#21644;&#38543;&#26426;&#24773;&#20917;&#12290;&#22914;&#26524;$\|\nabla F(\widehat{w})\|\leq \alpha$&#65292;&#21017;&#31216;&#28857;$\widehat{w}$&#26159;&#20989;&#25968;$F:\mathbb{R}^d\rightarrow\mathbb{R}$&#30340;$\alpha$-&#38745;&#24577;&#28857;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#22312;&#26377;&#38480;&#21644;&#35774;&#32622;&#20013;&#25214;&#21040;&#19968;&#20010;$\tilde{O}\big(\big[\frac{\sqrt{d}}{n\varepsilon}\big]^{2/3}\big)$&#30340;&#38745;&#24577;&#28857;&#65292;&#20854;&#20013;$n$&#26159;&#26679;&#26412;&#25968;&#12290;&#36825;&#20248;&#20110;&#20197;&#21069;&#26368;&#20339;&#36895;&#29575;$\tilde{O}\big(\big[\frac{\sqrt{d}}{n\varepsilon}\big]^{1/2}\big)$&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#26500;&#36896;&#65292;&#25913;&#36827;&#20102;&#38543;&#26426;&#20248;&#21270;&#35774;&#32622;&#20013;&#29616;&#26377;&#30340;&#36895;&#29575;&#65292;&#22312;&#35813;&#35774;&#32622;&#20013;&#65292;&#30446;&#26631;&#26159;&#25214;&#21040;&#20154;&#21475;&#39118;&#38505;&#30340;&#36817;&#20284;&#38745;&#24577;&#28857;&#12290;&#25105;&#20204;&#30340;&#26500;&#36896;&#25214;&#21040;&#20102;&#19968;&#20010;$\tilde{O}\big(\frac{1}{n^{1/3}} + \big[\frac{\sqrt{d}}{n\varepsilon}\big]^{1/2}\big)$&#30340;&#20154;&#21475;&#39118;&#38505;&#38745;&#24577;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of approximating stationary points of Lipschitz and smooth functions under $(\varepsilon,\delta)$-differential privacy (DP) in both the finite-sum and stochastic settings. A point $\widehat{w}$ is called an $\alpha$-stationary point of a function $F:\mathbb{R}^d\rightarrow\mathbb{R}$ if $\|\nabla F(\widehat{w})\|\leq \alpha$. We provide a new efficient algorithm that finds an $\tilde{O}\big(\big[\frac{\sqrt{d}}{n\varepsilon}\big]^{2/3}\big)$-stationary point in the finite-sum setting, where $n$ is the number of samples. This improves on the previous best rate of $\tilde{O}\big(\big[\frac{\sqrt{d}}{n\varepsilon}\big]^{1/2}\big)$. We also give a new construction that improves over the existing rates in the stochastic optimization setting, where the goal is to find approximate stationary points of the population risk. Our construction finds a $\tilde{O}\big(\frac{1}{n^{1/3}} + \big[\frac{\sqrt{d}}{n\varepsilon}\big]^{1/2}\big)$-stationary point of the population risk 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21333;&#26426;&#20316;&#19994;&#35843;&#24230;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23398;&#20064;&#39044;&#27979;&#30340;&#38745;&#24577;&#35843;&#24230;&#31639;&#27861;&#65292;&#22312;&#31867;&#22411;&#26410;&#30693;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#27425;&#32447;&#24615;&#30340;&#36807;&#21097;&#25104;&#26412;&#65292;&#23588;&#20854;&#22312;&#25250;&#21344;&#24335;&#38382;&#39064;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#21487;&#20197;&#22312;&#19981;&#21516;&#20316;&#19994;&#31867;&#22411;&#25345;&#32493;&#26102;&#38388;&#30456;&#24046;&#24456;&#22823;&#26102;&#20248;&#20110;&#38750;&#25250;&#21344;&#21305;&#37197;&#12290;</title><link>http://arxiv.org/abs/2205.15695</link><description>&lt;p&gt;
&#36890;&#36807;&#39640;&#25928;&#25506;&#32034;&#23398;&#20064;&#39044;&#27979;&#30340;&#38745;&#24577;&#35843;&#24230;
&lt;/p&gt;
&lt;p&gt;
Static Scheduling with Predictions Learned through Efficient Exploration. (arXiv:2205.15695v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.15695
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21333;&#26426;&#20316;&#19994;&#35843;&#24230;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23398;&#20064;&#39044;&#27979;&#30340;&#38745;&#24577;&#35843;&#24230;&#31639;&#27861;&#65292;&#22312;&#31867;&#22411;&#26410;&#30693;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#27425;&#32447;&#24615;&#30340;&#36807;&#21097;&#25104;&#26412;&#65292;&#23588;&#20854;&#22312;&#25250;&#21344;&#24335;&#38382;&#39064;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#21487;&#20197;&#22312;&#19981;&#21516;&#20316;&#19994;&#31867;&#22411;&#25345;&#32493;&#26102;&#38388;&#30456;&#24046;&#24456;&#22823;&#26102;&#20248;&#20110;&#38750;&#25250;&#21344;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#21333;&#26426;&#20316;&#19994;&#35843;&#24230;&#65292;&#27599;&#20010;&#20316;&#19994;&#37117;&#23646;&#20110;&#20915;&#23450;&#20854;&#25345;&#32493;&#26102;&#38388;&#20998;&#24067;&#30340;&#20316;&#19994;&#31867;&#22411;&#12290;&#25105;&#20204;&#39318;&#20808;&#20998;&#26512;&#20102;&#31867;&#22411;&#29305;&#24449;&#24050;&#30693;&#30340;&#24773;&#20917;&#65292;&#28982;&#21518;&#36716;&#21521;&#20004;&#31181;&#23398;&#20064;&#24773;&#26223;&#65292;&#20854;&#20013;&#31867;&#22411;&#26410;&#30693;&#65306;&#38750;&#25250;&#21344;&#24335;&#38382;&#39064;&#65292;&#23427;&#35201;&#27714;&#23436;&#25104;&#24050;&#21551;&#21160;&#30340;&#20316;&#19994;&#65292;&#28982;&#21518;&#25165;&#33021;&#31227;&#21160;&#21040;&#21478;&#19968;&#20010;&#20316;&#19994;&#65307;&#21644;&#25250;&#21344;&#24335;&#38382;&#39064;&#65292;&#36825;&#37324;&#20316;&#19994;&#25191;&#34892;&#21487;&#20197;&#26242;&#20572;&#20197;&#20248;&#20808;&#36716;&#31227;&#21040;&#21478;&#19968;&#20010;&#20316;&#19994;&#12290;&#22312;&#20004;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35774;&#35745;&#30340;&#31639;&#27861;&#30456;&#23545;&#20110;&#24050;&#30693;&#31867;&#22411;&#30340;&#24615;&#33021;&#23454;&#29616;&#20102;&#27425;&#32447;&#24615;&#30340;&#36807;&#21097;&#25104;&#26412;&#65292;&#24182;&#35777;&#26126;&#20102;&#38750;&#25250;&#21344;&#24335;&#24773;&#20917;&#30340;&#19979;&#38480;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25250;&#21344;&#31639;&#27861;&#22312;&#19981;&#21516;&#20316;&#19994;&#31867;&#22411;&#25345;&#32493;&#26102;&#38388;&#30456;&#24046;&#24456;&#22823;&#26102;&#65292;&#29702;&#35770;&#19978;&#21644;&#36890;&#36807;&#27169;&#25311;&#30340;&#26041;&#24335;&#21487;&#20197;&#20248;&#20110;&#38750;&#25250;&#21344;&#21305;&#37197;&#65292;&#22312;&#31867;&#22411;&#25345;&#32493;&#26102;&#38388;&#24050;&#30693;&#26102;&#24182;&#19981;&#23384;&#22312;&#36825;&#31181;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study single-machine scheduling of jobs, each belonging to a job type that determines its duration distribution. We start by analyzing the scenario where the type characteristics are known and then move to two learning scenarios where the types are unknown: non-preemptive problems, where each started job must be completed before moving to another job; and preemptive problems, where job execution can be paused in the favor of moving to a different job. In both cases, we design algorithms that achieve sublinear excess cost, compared to the performance with known types, and prove lower bounds for the non-preemptive case. Notably, we demonstrate, both theoretically and through simulations, how preemptive algorithms can greatly outperform non-preemptive ones when the durations of different job types are far from one another, a phenomenon that does not occur when the type durations are known.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28151;&#21512;&#27169;&#22411;&#30340;&#22240;&#26524;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#35299;&#20915;&#28151;&#21512;&#38382;&#39064;&#21644;&#24674;&#22797;&#27010;&#29575;&#20998;&#24067;&#65292;&#21487;&#20197;&#30830;&#23450;&#21407;&#26412;&#26080;&#27861;&#30830;&#23450;&#30340;&#22240;&#26524;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2112.11602</link><description>&lt;p&gt;
&#36890;&#36807;&#28151;&#21512;&#27169;&#22411;&#36827;&#34892;&#26377;&#38480;&#20840;&#23616;&#28151;&#28102;&#30340;&#22240;&#26524;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Causal Inference Despite Limited Global Confounding via Mixture Models. (arXiv:2112.11602v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.11602
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28151;&#21512;&#27169;&#22411;&#30340;&#22240;&#26524;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#35299;&#20915;&#28151;&#21512;&#38382;&#39064;&#21644;&#24674;&#22797;&#27010;&#29575;&#20998;&#24067;&#65292;&#21487;&#20197;&#30830;&#23450;&#21407;&#26412;&#26080;&#27861;&#30830;&#23450;&#30340;&#22240;&#26524;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#32593;&#32476;&#26159;&#19968;&#32452;$n$&#20010;&#38543;&#26426;&#21464;&#37327;&#65288;&#22270;&#30340;&#39030;&#28857;&#65289;&#19978;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;DAG&#65289;; &#36125;&#21494;&#26031;&#32593;&#32476;&#20998;&#24067;&#65288;BND&#65289;&#26159;&#22312;&#22270;&#19978;&#39532;&#23572;&#21487;&#22827;&#30340;&#38543;&#26426;&#21464;&#37327;&#30340;&#27010;&#29575;&#20998;&#24067;&#12290;&#36825;&#31181;&#27169;&#22411;&#30340;&#26377;&#38480;$k$-&#28151;&#21512;&#30001;&#19968;&#20010;&#26356;&#22823;&#30340;&#22270;&#24418;&#24335;&#21270;&#34920;&#31034;&#65292;&#35813;&#22270;&#20855;&#26377;&#19968;&#20010;&#39069;&#22806;&#30340;&#8220;&#38544;&#34255;&#8221;&#65288;&#25110;&#8220;&#28508;&#22312;&#8221;&#65289;&#38543;&#26426;&#21464;&#37327;$U$&#65292;&#20854;&#33539;&#22260;&#20026;$\{1,\ldots,k\}$&#65292;&#24182;&#19988;$U$&#21040;&#27599;&#20010;&#20854;&#20182;&#39030;&#28857;&#37117;&#26377;&#19968;&#20010;&#26377;&#21521;&#36793;&#12290;&#36825;&#31181;&#31867;&#22411;&#30340;&#27169;&#22411;&#22312;&#22240;&#26524;&#25512;&#26029;&#20013;&#26159;&#22522;&#26412;&#30340;&#65292;&#20854;&#20013;$U$&#27169;&#25311;&#20102;&#22810;&#20010;&#32676;&#20307;&#30340;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#25928;&#24212;&#65292;&#20351;&#24471;&#21487;&#35266;&#23519;&#30340;DAG&#20013;&#30340;&#22240;&#26524;&#20851;&#31995;&#21464;&#24471;&#27169;&#31946;&#19981;&#28165;&#12290;&#36890;&#36807;&#35299;&#20915;&#28151;&#21512;&#38382;&#39064;&#24182;&#24674;&#22797;$U$&#19978;&#30340;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#65292;&#20256;&#32479;&#19978;&#26080;&#27861;&#30830;&#23450;&#30340;&#22240;&#26524;&#20851;&#31995;&#21464;&#24471;&#21487;&#30830;&#23450;&#12290;&#36890;&#36807;&#23558;&#20854;&#32422;&#21270;&#20026;&#26356;&#20026;&#30740;&#31350;&#30340;&#8220;&#31354;&#8221;&#22270;&#20013;&#30340;&#8220;&#20056;&#31215;&#8221;&#24773;&#20917;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#23398;&#20064;&#38750;&#31354;DAG&#30340;&#28151;&#21512;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
A Bayesian Network is a directed acyclic graph (DAG) on a set of $n$ random variables (the vertices); a Bayesian Network Distribution (BND) is a probability distribution on the random variables that is Markovian on the graph. A finite $k$-mixture of such models is graphically represented by a larger graph which has an additional "hidden" (or "latent") random variable $U$, ranging in $\{1,\ldots,k\}$, and a directed edge from $U$ to every other vertex. Models of this type are fundamental to causal inference, where $U$ models an unobserved confounding effect of multiple populations, obscuring the causal relationships in the observable DAG. By solving the mixture problem and recovering the joint probability distribution on $U$, traditionally unidentifiable causal relationships become identifiable. Using a reduction to the more well-studied "product" case on empty graphs, we give the first algorithm to learn mixtures of non-empty DAGs.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#29992;MMD&#33539;&#25968;&#25511;&#21046;Wasserstein&#36317;&#31163;&#30340;&#26465;&#20214;&#65292;&#38024;&#23545;&#21387;&#32553;&#32479;&#35745;&#23398;&#20064;&#25552;&#20986;&#20102;HLRIP&#23646;&#24615;&#65292;&#36890;&#36807;&#23548;&#20986;&#30340;&#26032;&#26680;&#33539;&#25968;&#25552;&#20379;&#20102;&#35745;&#31639;&#19978;&#39640;&#25928;&#30340;Wasserstein&#36317;&#31163;&#21387;&#32553;&#32479;&#35745;&#23398;&#20064;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2112.00423</link><description>&lt;p&gt;
&#29992;&#26680;&#33539;&#25968;&#25511;&#21046;Wasserstein&#36317;&#31163;&#65292;&#24182;&#22312;&#21387;&#32553;&#32479;&#35745;&#23398;&#20064;&#20013;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Controlling Wasserstein Distances by Kernel Norms with Application to Compressive Statistical Learning. (arXiv:2112.00423v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.00423
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#29992;MMD&#33539;&#25968;&#25511;&#21046;Wasserstein&#36317;&#31163;&#30340;&#26465;&#20214;&#65292;&#38024;&#23545;&#21387;&#32553;&#32479;&#35745;&#23398;&#20064;&#25552;&#20986;&#20102;HLRIP&#23646;&#24615;&#65292;&#36890;&#36807;&#23548;&#20986;&#30340;&#26032;&#26680;&#33539;&#25968;&#25552;&#20379;&#20102;&#35745;&#31639;&#19978;&#39640;&#25928;&#30340;Wasserstein&#36317;&#31163;&#21387;&#32553;&#32479;&#35745;&#23398;&#20064;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#20013;&#65292;&#27604;&#36739;&#27010;&#29575;&#20998;&#24067;&#26159;&#20851;&#38190;&#12290;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#65288;MMD&#65289;&#21644;Wasserstein&#36317;&#31163;&#26159;&#20004;&#31867;&#27010;&#29575;&#20998;&#24067;&#36317;&#31163;&#65292;&#36817;&#24180;&#26469;&#21463;&#21040;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#26412;&#25991;&#24314;&#31435;&#20102;&#19968;&#20123;&#26465;&#20214;&#65292;&#20351;&#24471;&#21487;&#20197;&#36890;&#36807;MMD&#33539;&#25968;&#26469;&#25511;&#21046;Wasserstein&#36317;&#31163;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#21463;&#21040;&#21387;&#32553;&#32479;&#35745;&#23398;&#20064;&#65288;CSL&#65289;&#29702;&#35770;&#30340;&#21551;&#21457;&#65292;&#36825;&#26159;&#19968;&#31181;&#36164;&#28304;&#26377;&#25928;&#30340;&#22823;&#35268;&#27169;&#23398;&#20064;&#36890;&#29992;&#26694;&#26550;&#65292;&#22312;&#20854;&#20013;&#35757;&#32451;&#25968;&#25454;&#22312;&#21333;&#20010;&#21521;&#37327;&#65288;&#31216;&#20026;&#33609;&#22270;&#65289;&#20013;&#36827;&#34892;&#24635;&#32467;&#65292;&#20197;&#25429;&#25417;&#19982;&#32771;&#34385;&#30340;&#23398;&#20064;&#20219;&#21153;&#30456;&#20851;&#30340;&#20449;&#24687;&#12290;&#25105;&#20204;&#22312;&#29616;&#26377;&#30340;CSL&#32467;&#26524;&#30340;&#21551;&#21457;&#19979;&#24341;&#20837;&#20102;H\"older Lower Restricted Isometric Property&#65292;&#24182;&#23637;&#31034;&#20102;&#36825;&#31181;&#23646;&#24615;&#23545;&#20110;&#21387;&#32553;&#32479;&#35745;&#23398;&#20064;&#20855;&#26377;&#26377;&#36259;&#30340;&#20445;&#35777;&#12290;&#22522;&#20110;MMD&#21644;Wasserstein&#36317;&#31163;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#22522;&#20110;MMD&#23548;&#20986;&#30340;&#26032;&#26680;&#33539;&#25968;&#30340;&#21387;&#32553;&#32479;&#35745;&#23398;&#20064;&#20445;&#35777;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20026;&#22312;&#21387;&#32553;&#32479;&#35745;&#23398;&#20064;&#20013;&#20351;&#29992;Wasserstein&#36317;&#31163;&#30340;&#23398;&#20064;&#25552;&#20379;&#20102;&#19968;&#31181;&#35745;&#31639;&#19978;&#39640;&#25928;&#30340;&#20004;&#27493;&#31639;&#27861;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#65292;&#23637;&#31034;&#20102;Wasserstein&#36317;&#31163;&#30456;&#23545;&#20110;CSL&#20013;&#20854;&#20182;&#24120;&#29992;&#36317;&#31163;&#30340;&#23454;&#36136;&#24615;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Comparing probability distributions is at the crux of many machine learning algorithms. Maximum Mean Discrepancies (MMD) and Wasserstein distances are two classes of distances between probability distributions that have attracted abundant attention in past years. This paper establishes some conditions under which the Wasserstein distance can be controlled by MMD norms. Our work is motivated by the compressive statistical learning (CSL) theory, a general framework for resource-efficient large scale learning in which the training data is summarized in a single vector (called sketch) that captures the information relevant to the considered learning task. Inspired by existing results in CSL, we introduce the H\"older Lower Restricted Isometric Property and show that this property comes with interesting guarantees for compressive statistical learning. Based on the relations between the MMD and the Wasserstein distances, we provide guarantees for compressive statistical learning by introduci
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#26368;&#20248;&#32479;&#35745;&#21327;&#20316;&#31639;&#27861;&#26694;&#26550;&#65292;&#31649;&#29702;&#20248;&#21270;&#35823;&#24046;&#36890;&#37327;&#21644;&#28436;&#21270;&#20013;&#30340;&#32479;&#35745;&#35823;&#24046;&#36890;&#37327;&#12290;&#35813;&#26694;&#26550;&#36890;&#29992;&#24615;&#24378;&#19988;&#36866;&#29992;&#20110;&#22810;&#31181;&#20989;&#25968;&#21644;&#20998;&#21306;&#26063;&#65292;&#24182;&#21551;&#21457;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#24046;&#33258;&#36866;&#24212;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2106.09215</link><description>&lt;p&gt;
&#38754;&#21521;&#36890;&#29992;&#21644;&#39640;&#25928;&#40657;&#30418;&#20248;&#21270;&#30340;&#26368;&#20248;&#32479;&#35745;&#21327;&#20316;
&lt;/p&gt;
&lt;p&gt;
Optimum-statistical Collaboration Towards General and Efficient Black-box Optimization. (arXiv:2106.09215v5 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.09215
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#26368;&#20248;&#32479;&#35745;&#21327;&#20316;&#31639;&#27861;&#26694;&#26550;&#65292;&#31649;&#29702;&#20248;&#21270;&#35823;&#24046;&#36890;&#37327;&#21644;&#28436;&#21270;&#20013;&#30340;&#32479;&#35745;&#35823;&#24046;&#36890;&#37327;&#12290;&#35813;&#26694;&#26550;&#36890;&#29992;&#24615;&#24378;&#19988;&#36866;&#29992;&#20110;&#22810;&#31181;&#20989;&#25968;&#21644;&#20998;&#21306;&#26063;&#65292;&#24182;&#21551;&#21457;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#24046;&#33258;&#36866;&#24212;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#38024;&#23545;&#20998;&#23618;&#36172;&#21338;&#26426;&#24335;&#40657;&#30418;&#20248;&#21270;&#31639;&#27861;&#20013;&#20998;&#36776;&#29575;&#21644;&#32479;&#35745;&#19981;&#30830;&#23450;&#24615;&#30340;&#20316;&#29992;&#36827;&#34892;&#20851;&#38190;&#38416;&#36848;&#65292;&#24341;&#23548;&#26356;&#20026;&#36890;&#29992;&#30340;&#20998;&#26512;&#21644;&#26356;&#39640;&#25928;&#30340;&#31639;&#27861;&#35774;&#35745;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#26368;&#20248;&#32479;&#35745;&#21327;&#20316;&#65292;&#19968;&#31181;&#31649;&#29702;&#20248;&#21270;&#35823;&#24046;&#36890;&#37327;&#21644;&#20248;&#21270;&#36807;&#31243;&#20013;&#28436;&#21270;&#30340;&#32479;&#35745;&#35823;&#24046;&#36890;&#37327;&#30456;&#20114;&#20316;&#29992;&#30340;&#31639;&#27861;&#26694;&#26550;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#27492;&#26694;&#26550;&#30340;&#36890;&#29992;&#20998;&#26512;&#65292;&#32780;&#19981;&#38656;&#35201;&#25351;&#23450;&#32479;&#35745;&#35823;&#24046;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#22120;&#30340;&#24418;&#24335;&#12290;&#30001;&#20110;&#20854;&#36890;&#29992;&#24615;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#21644;&#20998;&#26512;&#21487;&#24212;&#29992;&#20110;&#28385;&#36275;&#19981;&#21516;&#23616;&#37096;&#24179;&#28369;&#24615;&#20551;&#35774;&#21644;&#20855;&#26377;&#19981;&#21516;&#23616;&#37096;&#26368;&#20248;&#20540;&#25968;&#37327;&#30340;&#22823;&#37327;&#20989;&#25968;&#21644;&#20998;&#21306;&#26063;&#65292;&#36825;&#27604;&#20043;&#21069;&#30340;&#20316;&#21697;&#25152;&#30740;&#31350;&#30340;&#20989;&#25968;&#31867;&#35201;&#20016;&#23500;&#24471;&#22810;&#12290;&#35813;&#26694;&#26550;&#36824;&#21551;&#21457;&#25105;&#20204;&#25552;&#20986;&#26356;&#22909;&#30340;&#32479;&#35745;&#19981;&#30830;&#23450;&#24615;&#27979;&#37327;&#26041;&#27861;&#65292;&#22240;&#27492;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#24046;&#33258;&#36866;&#24212;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we make the key delineation on the roles of resolution and statistical uncertainty in hierarchical bandits-based black-box optimization algorithms, guiding a more general analysis and a more efficient algorithm design. We introduce the \textit{optimum-statistical collaboration}, an algorithm framework of managing the interaction between optimization error flux and statistical error flux evolving in the optimization process. We provide a general analysis of this framework without specifying the forms of statistical error and uncertainty quantifier. Our framework and its analysis, due to their generality, can be applied to a large family of functions and partitions that satisfy different local smoothness assumptions and have different numbers of local optimums, which is much richer than the class of functions studied in prior works. Our framework also inspires us to propose a better measure of the statistical uncertainty and consequently a variance-adaptive algorithm \text
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#26641;&#27169;&#22411;&#20013;&#35745;&#31639;Shapley&#20540;&#30340;&#20004;&#31181;&#26356;&#20934;&#30830;&#30340;&#20272;&#35745;&#22120;&#65292;&#30456;&#27604;&#20110;&#29616;&#26377;&#26041;&#27861;&#21487;&#20197;&#26356;&#39640;&#25928;&#22320;&#21033;&#29992;&#26641;&#32467;&#26500;&#65292;&#24182;&#25506;&#35752;&#20102;Shapley&#20540;&#20316;&#20026;&#23616;&#37096;&#35299;&#37322;&#30340;&#23616;&#38480;&#24615;&#12290;</title><link>http://arxiv.org/abs/2106.03820</link><description>&lt;p&gt;
&#35299;&#37322;&#26641;&#27169;&#22411;&#30340;&#20934;&#30830;Shapley&#20540;
&lt;/p&gt;
&lt;p&gt;
Accurate Shapley Values for explaining tree-based models. (arXiv:2106.03820v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.03820
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#26641;&#27169;&#22411;&#20013;&#35745;&#31639;Shapley&#20540;&#30340;&#20004;&#31181;&#26356;&#20934;&#30830;&#30340;&#20272;&#35745;&#22120;&#65292;&#30456;&#27604;&#20110;&#29616;&#26377;&#26041;&#27861;&#21487;&#20197;&#26356;&#39640;&#25928;&#22320;&#21033;&#29992;&#26641;&#32467;&#26500;&#65292;&#24182;&#25506;&#35752;&#20102;Shapley&#20540;&#20316;&#20026;&#23616;&#37096;&#35299;&#37322;&#30340;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Shapley&#20540;&#24191;&#27867;&#29992;&#20110;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#65292;&#20294;&#23427;&#20204;&#30340;&#20272;&#35745;&#21644;&#35299;&#37322;&#21487;&#33021;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#23548;&#33268;&#19981;&#20934;&#30830;&#30340;&#25512;&#35770;&#21644;&#35299;&#37322;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;&#26641;&#32467;&#26500;&#30340;Shapley&#20540;&#20272;&#35745;&#22120;&#65292;&#21033;&#29992;&#26641;&#32467;&#26500;&#39640;&#25928;&#22320;&#35745;&#31639;Shapley&#20540;&#65292;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#20934;&#30830;&#12290;&#36890;&#36807;&#19982;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;&#36827;&#34892;&#27169;&#25311;&#21644;&#27604;&#36739;&#65292;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#23454;&#38469;&#25910;&#30410;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;Shapley&#20540;&#20316;&#20026;&#23616;&#37096;&#35299;&#37322;&#30340;&#23616;&#38480;&#24615;&#12290;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#20316;&#20026;Python&#21253;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Shapley Values (SV) are widely used in explainable AI, but their estimation and interpretation can be challenging, leading to inaccurate inferences and explanations. As a starting point, we remind an invariance principle for SV and derive the correct approach for computing the SV of categorical variables that are particularly sensitive to the encoding used. In the case of tree-based models, we introduce two estimators of Shapley Values that exploit the tree structure efficiently and are more accurate than state-of-the-art methods. Simulations and comparisons are performed with state-of-the-art algorithms and show the practical gain of our approach. Finally, we discuss the limitations of Shapley Values as a local explanation. These methods are available as a Python package.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#20026;2&#30340;&#24102;&#38480;&#21046;&#38543;&#26426;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#36890;&#36807;&#25968;&#23398;&#35777;&#26126;&#30830;&#23450;&#20102;&#24403;&#38544;&#34255;&#21442;&#25968;&#20998;&#24067;&#20110;&#26377;&#30028;&#22495;&#26102;&#65292;&#32593;&#32476;&#21487;&#33021;&#26080;&#27861;&#36798;&#21040;&#38646;&#36924;&#36817;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2008.08427</link><description>&lt;p&gt;
&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#24102;&#38480;&#21046;&#30340;&#38543;&#26426;&#26435;&#37325;&#26377;&#22810;&#22823;&#30340;&#33021;&#21147;&#65311;
&lt;/p&gt;
&lt;p&gt;
How Powerful are Shallow Neural Networks with Bandlimited Random Weights?. (arXiv:2008.08427v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2008.08427
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#20026;2&#30340;&#24102;&#38480;&#21046;&#38543;&#26426;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#36890;&#36807;&#25968;&#23398;&#35777;&#26126;&#30830;&#23450;&#20102;&#24403;&#38544;&#34255;&#21442;&#25968;&#20998;&#24067;&#20110;&#26377;&#30028;&#22495;&#26102;&#65292;&#32593;&#32476;&#21487;&#33021;&#26080;&#27861;&#36798;&#21040;&#38646;&#36924;&#36817;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#28145;&#24230;&#20026;2&#30340;&#24102;&#38480;&#21046;&#38543;&#26426;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;&#38543;&#26426;&#32593;&#32476;&#26159;&#25351;&#38544;&#34255;&#23618;&#21442;&#25968;&#34987;&#20923;&#32467;&#24182;&#36171;&#20104;&#38543;&#26426;&#20998;&#37197;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#21482;&#26377;&#36755;&#20986;&#23618;&#21442;&#25968;&#36890;&#36807;&#25439;&#22833;&#26368;&#23567;&#21270;&#36827;&#34892;&#35757;&#32451;&#12290;&#20351;&#29992;&#38543;&#26426;&#26435;&#37325;&#30340;&#38544;&#34255;&#23618;&#26159;&#36991;&#20813;&#26631;&#20934;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#20013;&#30340;&#38750;&#20984;&#20248;&#21270;&#30340;&#26377;&#25928;&#26041;&#27861;&#65292;&#24182;&#24050;&#34987;&#36817;&#26399;&#28145;&#24230;&#23398;&#20064;&#29702;&#35770;&#25152;&#37319;&#29992;&#12290;&#23613;&#31649;&#31070;&#32463;&#32593;&#32476;&#26159;&#26222;&#36866;&#36924;&#36817;&#22120;&#30340;&#20247;&#25152;&#21608;&#30693;&#30340;&#20107;&#23454;&#65292;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25968;&#23398;&#19978;&#35777;&#26126;&#20102;&#24403;&#38544;&#34255;&#21442;&#25968;&#20998;&#24067;&#20110;&#26377;&#30028;&#22495;&#26102;&#65292;&#32593;&#32476;&#21487;&#33021;&#26080;&#27861;&#36798;&#21040;&#38646;&#36924;&#36817;&#35823;&#24046;&#12290;&#25105;&#20204;&#29305;&#21035;&#23548;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#38750;&#24179;&#20961;&#36924;&#36817;&#35823;&#24046;&#19979;&#30028;&#12290;&#35777;&#26126;&#21033;&#29992;&#20102;Ridgelet&#20998;&#26512;&#25216;&#26415;&#65292;&#36825;&#26159;&#19968;&#31181;&#20026;&#31070;&#32463;&#32593;&#32476;&#35774;&#35745;&#30340;&#35856;&#27874;&#20998;&#26512;&#26041;&#27861;&#12290;&#36825;&#31181;&#26041;&#27861;&#21463;&#21040;&#20102;&#32463;&#20856;&#20449;&#21495;&#22788;&#29702;&#20013;&#30340;&#22522;&#26412;&#21407;&#29702;&#30340;&#21551;&#21457;&#65292;&#29305;&#21035;&#26159;&#20449;&#21495;&#22312;&#26576;&#31181;&#38480;&#21046;&#19979;&#30340;&#37319;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the expressive power of depth-2 bandlimited random neural networks. A random net is a neural network where the hidden layer parameters are frozen with random assignment, and only the output layer parameters are trained by loss minimization. Using random weights for a hidden layer is an effective method to avoid non-convex optimization in standard gradient descent learning. It has also been adopted in recent deep learning theories. Despite the well-known fact that a neural network is a universal approximator, in this study, we mathematically show that when hidden parameters are distributed in a bounded domain, the network may not achieve zero approximation error. In particular, we derive a new nontrivial approximation error lower bound. The proof utilizes the technique of ridgelet analysis, a harmonic analysis method designed for neural networks. This method is inspired by fundamental principles in classical signal processing, specifically the idea that signals with limit
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24378;&#20581;&#27169;&#25311;&#31639;&#27861;&#30340;&#28176;&#36817;&#24615;&#36136;&#65292;&#23558;&#32463;&#39564;&#24179;&#22343;&#20540;&#26367;&#25442;&#25104;&#40065;&#26834;&#22343;&#20540;&#30340;&#26367;&#20195;&#29289;&#65292;&#20351;&#24471;&#24471;&#21040;&#30340;&#20272;&#35745;&#22120;&#20855;&#26377;&#27604;&#32463;&#20856;&#26041;&#27861;&#26356;&#24369;&#30340;&#20551;&#35774;&#26465;&#20214;&#19979;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#65292;&#19988;&#23545;&#20110;&#24191;&#27867;&#31867;&#30340;&#21442;&#25968;&#38382;&#39064;&#65292;&#24378;&#20581;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#26368;&#23567;&#21270;&#22120;&#20197;&#19982;&#30495;&#23454;&#39118;&#38505;&#30340;&#20272;&#35745;&#22120;&#30456;&#21516;&#30340;&#28176;&#36817;&#36895;&#29575;&#21644;&#26041;&#24046;&#25910;&#25947;&#12290;</title><link>http://arxiv.org/abs/2004.02328</link><description>&lt;p&gt;
&#24378;&#20581;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;
&lt;/p&gt;
&lt;p&gt;
Asymptotic normality of robust risk minimizers. (arXiv:2004.02328v4 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2004.02328
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24378;&#20581;&#27169;&#25311;&#31639;&#27861;&#30340;&#28176;&#36817;&#24615;&#36136;&#65292;&#23558;&#32463;&#39564;&#24179;&#22343;&#20540;&#26367;&#25442;&#25104;&#40065;&#26834;&#22343;&#20540;&#30340;&#26367;&#20195;&#29289;&#65292;&#20351;&#24471;&#24471;&#21040;&#30340;&#20272;&#35745;&#22120;&#20855;&#26377;&#27604;&#32463;&#20856;&#26041;&#27861;&#26356;&#24369;&#30340;&#20551;&#35774;&#26465;&#20214;&#19979;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#65292;&#19988;&#23545;&#20110;&#24191;&#27867;&#31867;&#30340;&#21442;&#25968;&#38382;&#39064;&#65292;&#24378;&#20581;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#26368;&#23567;&#21270;&#22120;&#20197;&#19982;&#30495;&#23454;&#39118;&#38505;&#30340;&#20272;&#35745;&#22120;&#30456;&#21516;&#30340;&#28176;&#36817;&#36895;&#29575;&#21644;&#26041;&#24046;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#21487;&#20197;&#30475;&#20316;&#32463;&#20856;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#24378;&#20581;&#27169;&#25311;&#31639;&#27861;&#30340;&#28176;&#36817;&#24615;&#36136;&#12290;&#36825;&#20123;&#31574;&#30053;&#22522;&#20110;&#29992;&#40065;&#26834;&#22343;&#20540;&#30340;&#26367;&#20195;&#29289;&#65288;&#22914;&#22343;&#20540;&#20013;&#20301;&#25968;&#20272;&#35745;&#30340;&#29256;&#26412;&#65289;&#26469;&#26367;&#25442;&#36890;&#24120;&#30340;&#32463;&#39564;&#24179;&#22343;&#20540;&#12290;&#29616;&#22312;&#24050;&#32463;&#20247;&#25152;&#21608;&#30693;&#65292;&#30001;&#36825;&#20123;&#26041;&#27861;&#24471;&#21040;&#30340;&#20272;&#35745;&#22120;&#30340;&#36807;&#21097;&#39118;&#38505;&#36890;&#24120;&#20197;&#27604;&#20854;&#8220;&#32463;&#20856;&#8221;&#23545;&#24212;&#29289;&#38656;&#35201;&#26356;&#24369;&#30340;&#20551;&#35774;&#25910;&#25947;&#20026;&#38646;&#12290;&#20294;&#26159;&#65292;&#23545;&#20110;&#20272;&#35745;&#37327;&#26412;&#36523;&#30340;&#28176;&#36817;&#24615;&#36136;&#30693;&#20043;&#29978;&#23569;&#65292;&#20363;&#22914;&#26159;&#21542;&#24378;&#20581;&#27169;&#25311;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#28176;&#36817;&#25928;&#29575;&#30456;&#21516;&#12290;&#25105;&#20204;&#37319;&#21462;&#19968;&#27493;&#25514;&#26045;&#22238;&#31572;&#36825;&#20123;&#38382;&#39064;&#65292;&#24182;&#34920;&#26126;&#23545;&#20110;&#24191;&#27867;&#31867;&#30340;&#21442;&#25968;&#38382;&#39064;&#65292;&#36866;&#24403;&#23450;&#20041;&#30340;&#24378;&#20581;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#26368;&#23567;&#21270;&#22120;&#20197;&#19982;&#26368;&#23567;&#21270;&#30495;&#23454;&#39118;&#38505;&#30340;&#20272;&#35745;&#22120;&#30456;&#21516;&#30340;&#36895;&#29575;&#25910;&#25947;&#65292;&#24182;&#19988;&#36890;&#24120;&#20855;&#26377;&#30456;&#21516;&#30340;&#28176;&#36817;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates asymptotic properties of algorithms that can be viewed as robust analogues of the classical empirical risk minimization. These strategies are based on replacing the usual empirical average by a robust proxy of the mean, such as the (version of) the median of means estimator. It is well known by now that the excess risk of resulting estimators often converges to zero at optimal rates under much weaker assumptions than those required by their ``classical'' counterparts. However, less is known about the asymptotic properties of the estimators themselves, for instance, whether robust analogues of the maximum likelihood estimators are asymptotically efficient. We make a step towards answering these questions and show that for a wide class of parametric problems, minimizers of the appropriately defined robust proxy of the risk converge to the minimizers of the true risk at the same rate, and often have the same asymptotic variance, as the estimators obtained by minimi
&lt;/p&gt;</description></item></channel></rss>