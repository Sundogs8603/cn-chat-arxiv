<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#37325;&#21551;&#8221;&#30340;&#26032;&#22411;&#37319;&#26679;&#31639;&#27861;&#65292;&#20197;&#26356;&#22909;&#22320;&#24179;&#34913;&#31163;&#25955;&#21270;&#35823;&#24046;&#21644;&#25910;&#32553;&#65292;&#21487;&#20197;&#20248;&#21270;&#29983;&#25104;&#36807;&#31243;&#20013;&#30340;&#37319;&#26679;&#36895;&#24230;&#21644;&#26679;&#26412;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2306.14878</link><description>&lt;p&gt;
&#37325;&#21551;&#37319;&#26679;&#20197;&#25552;&#39640;&#29983;&#25104;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Restart Sampling for Improving Generative Processes. (arXiv:2306.14878v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14878
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#37325;&#21551;&#8221;&#30340;&#26032;&#22411;&#37319;&#26679;&#31639;&#27861;&#65292;&#20197;&#26356;&#22909;&#22320;&#24179;&#34913;&#31163;&#25955;&#21270;&#35823;&#24046;&#21644;&#25910;&#32553;&#65292;&#21487;&#20197;&#20248;&#21270;&#29983;&#25104;&#36807;&#31243;&#20013;&#30340;&#37319;&#26679;&#36895;&#24230;&#21644;&#26679;&#26412;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#36807;&#31243;&#20013;&#35299;&#20915;&#24494;&#20998;&#26041;&#31243;&#30340;&#36807;&#31243;&#65292;&#22914;&#25193;&#25955;&#27169;&#22411;&#65292;&#38656;&#35201;&#24179;&#34913;&#36895;&#24230;&#21644;&#36136;&#37327;&#12290;&#22522;&#20110;ODE&#30340;&#37319;&#26679;&#22120;&#36895;&#24230;&#24555;&#20294;&#24615;&#33021;&#24179;&#31283;&#65292;&#32780;&#22522;&#20110;SDE&#30340;&#37319;&#26679;&#22120;&#25552;&#20379;&#26356;&#39640;&#30340;&#26679;&#26412;&#36136;&#37327;&#20294;&#38656;&#35201;&#26356;&#38271;&#30340;&#37319;&#26679;&#26102;&#38388;&#12290;&#25105;&#20204;&#23558;&#36825;&#31181;&#24046;&#24322;&#24402;&#22240;&#20110;&#37319;&#26679;&#35823;&#24046;&#65306;ODE&#37319;&#26679;&#22120;&#28041;&#21450;&#26356;&#23567;&#30340;&#31163;&#25955;&#21270;&#35823;&#24046;&#65292;&#32780;SDE&#30340;&#38543;&#26426;&#24615;&#20250;&#20351;&#32047;&#31215;&#35823;&#24046;&#32553;&#23567;&#12290;&#22522;&#20110;&#36825;&#20123;&#21457;&#29616;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#37325;&#21551;&#30340;&#26032;&#22411;&#37319;&#26679;&#31639;&#27861;&#65292;&#20197;&#26356;&#22909;&#22320;&#24179;&#34913;&#31163;&#25955;&#21270;&#35823;&#24046;&#21644;&#25910;&#32553;&#12290;&#35813;&#37319;&#26679;&#26041;&#27861;&#22312;&#39069;&#22806;&#21069;&#21521;&#27493;&#39588;&#20013;&#20132;&#26367;&#28155;&#21152;&#22823;&#37327;&#22122;&#22768;&#21644;&#20005;&#26684;&#36981;&#24490;&#21518;&#21521;ODE&#12290;&#32463;&#39564;&#35777;&#65292;&#37325;&#21551;&#37319;&#26679;&#22120;&#22312;&#36895;&#24230;&#21644;&#20934;&#30830;&#24615;&#26041;&#38754;&#22343;&#20248;&#20110;&#20808;&#21069;&#30340;SDE&#21644;ODE&#37319;&#26679;&#22120;&#12290;&#22312;CIFAR-10/ImageNet $64 \times 64$&#19978;&#65292;&#37325;&#21551;&#19981;&#20165;&#20248;&#20110;&#20808;&#21069;&#30340;&#26368;&#20339;SDE&#32467;&#26524;&#65292;&#32780;&#19988;&#21152;&#24555;&#20102;&#37319;&#26679;&#36895;&#24230;&#65292;&#20998;&#21035;&#20026;10&#20493;/2&#20493;&#12290;&#27492;&#22806;&#65292;&#23427;&#22312;&#36827;&#34892;&#22270;&#20687;&#29983;&#25104;&#26102;&#36824;&#25552;&#20379;&#20102;&#26356;&#22909;&#30340;&#26679;&#26412;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative processes that involve solving differential equations, such as diffusion models, frequently necessitate balancing speed and quality. ODE-based samplers are fast but plateau in performance while SDE-based samplers deliver higher sample quality at the cost of increased sampling time. We attribute this difference to sampling errors: ODE-samplers involve smaller discretization errors while stochasticity in SDE contracts accumulated errors. Based on these findings, we propose a novel sampling algorithm called Restart in order to better balance discretization errors and contraction. The sampling method alternates between adding substantial noise in additional forward steps and strictly following a backward ODE. Empirically, Restart sampler surpasses previous SDE and ODE samplers in both speed and accuracy. Restart not only outperforms the previous best SDE results, but also accelerates the sampling speed by 10-fold / 2-fold on CIFAR-10 / ImageNet $64 \times 64$. In addition, it at
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#39537;&#21160;&#25216;&#26415;&#65292;&#36319;&#36394;&#19981;&#30830;&#23450;&#24230;&#26925;&#29699;&#20307;&#30340;&#20960;&#20309;&#24418;&#29366;&#65292;&#20026;&#32447;&#24615;&#36172;&#21338;&#26426;&#31639;&#27861;&#24314;&#31435;&#23454;&#20363;&#30456;&#20851;&#30340;&#39057;&#29575;&#21518;&#24724;&#30028;&#65292;&#24182;&#23454;&#29616;&#20102;&#24179;&#34913;&#31639;&#27861;&#24615;&#33021;&#19982;&#29702;&#35770;&#20445;&#35777;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.14872</link><description>&lt;p&gt;
&#32447;&#24615;&#36172;&#21338;&#26426;&#20013;&#24179;&#34913;&#24615;&#33021;&#19982;&#29702;&#35770;&#20445;&#35777;&#30340;&#20960;&#20309;&#24863;&#30693;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Geometry-Aware Approaches for Balancing Performance and Theoretical Guarantees in Linear Bandits. (arXiv:2306.14872v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14872
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#39537;&#21160;&#25216;&#26415;&#65292;&#36319;&#36394;&#19981;&#30830;&#23450;&#24230;&#26925;&#29699;&#20307;&#30340;&#20960;&#20309;&#24418;&#29366;&#65292;&#20026;&#32447;&#24615;&#36172;&#21338;&#26426;&#31639;&#27861;&#24314;&#31435;&#23454;&#20363;&#30456;&#20851;&#30340;&#39057;&#29575;&#21518;&#24724;&#30028;&#65292;&#24182;&#23454;&#29616;&#20102;&#24179;&#34913;&#31639;&#27861;&#24615;&#33021;&#19982;&#29702;&#35770;&#20445;&#35777;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21463;&#32447;&#24615;&#36172;&#21338;&#26426;&#31639;&#27861;&#34920;&#29616;&#33391;&#22909;&#30340;&#23454;&#35777;&#24615;&#33021;&#19982;&#24754;&#35266;&#29702;&#35770;&#21518;&#24724;&#30028;&#20043;&#38388;&#30340;&#19981;&#19968;&#33268;&#24615;&#21551;&#21457;&#65292;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#39537;&#21160;&#25216;&#26415;&#65292;&#36319;&#36394;&#19981;&#30830;&#23450;&#24230;&#26925;&#29699;&#20307;&#30340;&#20960;&#20309;&#24418;&#29366;&#65292;&#20026;&#21253;&#25324;&#36138;&#24515;&#12289;OFUL&#21644;&#27748;&#26222;&#26862;&#25277;&#26679;&#31639;&#27861;&#22312;&#20869;&#30340;&#24191;&#27867;&#31639;&#27861;&#31867;&#24314;&#31435;&#23454;&#20363;&#30456;&#20851;&#30340;&#39057;&#29575;&#21518;&#24724;&#30028;&#65292;&#22312;&#20445;&#30041;&#22522;&#26412;&#31639;&#27861;&#22823;&#37096;&#20998;&#20248;&#33391;&#29305;&#24615;&#30340;&#21516;&#26102;&#8220;&#26657;&#27491;&#8221;&#22522;&#26412;&#31639;&#27861;&#22312;&#26576;&#20123;&#23454;&#20363;&#20013;&#34920;&#29616;&#24046;&#30340;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#28176;&#36817;&#26368;&#20248;&#21518;&#24724;&#30028;&#12290;&#25105;&#20204;&#36890;&#36807;&#20223;&#30495;&#23454;&#39564;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper is motivated by recent developments in the linear bandit literature, which have revealed a discrepancy between the promising empirical performance of algorithms such as Thompson sampling and Greedy, when compared to their pessimistic theoretical regret bounds. The challenge arises from the fact that while these algorithms may perform poorly in certain problem instances, they generally excel in typical instances. To address this, we propose a new data-driven technique that tracks the geometry of the uncertainty ellipsoid, enabling us to establish an instance-dependent frequentist regret bound for a broad class of algorithms, including Greedy, OFUL, and Thompson sampling. This result empowers us to identify and ``course-correct" instances in which the base algorithms perform poorly. The course-corrected algorithms achieve the minimax optimal regret of order $\tilde{\mathcal{O}}(d\sqrt{T})$, while retaining most of the desirable properties of the base algorithms. We present sim
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#20219;&#21153;&#32467;&#26500;&#30340;&#21487;&#35782;&#21035;&#24615;&#29702;&#35770;&#65292;&#25299;&#23637;&#20102;&#20808;&#21069;&#20165;&#38480;&#20110;&#21333;&#20219;&#21153;&#20998;&#31867;&#30340;&#24037;&#20316;&#12290;&#20219;&#21153;&#20998;&#24067;&#30340;&#23384;&#22312;&#23450;&#20041;&#20102;&#19968;&#20010;&#28508;&#22312;&#21464;&#37327;&#30340;&#26465;&#20214;&#20808;&#39564;&#65292;&#23558;&#21487;&#35782;&#21035;&#24615;&#30340;&#31561;&#20215;&#31867;&#38477;&#20302;&#21040;&#25490;&#21015;&#21644;&#32553;&#25918;&#12290;&#22312;&#20551;&#35774;&#20219;&#21153;&#20043;&#38388;&#23384;&#22312;&#22240;&#26524;&#20851;&#31995;&#26102;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;&#31616;&#21333;&#30340;&#26368;&#22823;&#36793;&#38469;&#20284;&#28982;&#20248;&#21270;&#65292;&#24182;&#22312;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#26041;&#38754;&#20855;&#26377;&#19979;&#28216;&#24212;&#29992;&#30340;&#21487;&#34892;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.14861</link><description>&lt;p&gt;
&#21033;&#29992;&#20219;&#21153;&#32467;&#26500;&#25552;&#39640;&#31070;&#32463;&#32593;&#32476;&#34920;&#31034;&#30340;&#21487;&#35782;&#21035;&#24615;
&lt;/p&gt;
&lt;p&gt;
Leveraging Task Structures for Improved Identifiability in Neural Network Representations. (arXiv:2306.14861v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14861
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#20219;&#21153;&#32467;&#26500;&#30340;&#21487;&#35782;&#21035;&#24615;&#29702;&#35770;&#65292;&#25299;&#23637;&#20102;&#20808;&#21069;&#20165;&#38480;&#20110;&#21333;&#20219;&#21153;&#20998;&#31867;&#30340;&#24037;&#20316;&#12290;&#20219;&#21153;&#20998;&#24067;&#30340;&#23384;&#22312;&#23450;&#20041;&#20102;&#19968;&#20010;&#28508;&#22312;&#21464;&#37327;&#30340;&#26465;&#20214;&#20808;&#39564;&#65292;&#23558;&#21487;&#35782;&#21035;&#24615;&#30340;&#31561;&#20215;&#31867;&#38477;&#20302;&#21040;&#25490;&#21015;&#21644;&#32553;&#25918;&#12290;&#22312;&#20551;&#35774;&#20219;&#21153;&#20043;&#38388;&#23384;&#22312;&#22240;&#26524;&#20851;&#31995;&#26102;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;&#31616;&#21333;&#30340;&#26368;&#22823;&#36793;&#38469;&#20284;&#28982;&#20248;&#21270;&#65292;&#24182;&#22312;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#26041;&#38754;&#20855;&#26377;&#19979;&#28216;&#24212;&#29992;&#30340;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25193;&#23637;&#20102;&#30417;&#30563;&#23398;&#20064;&#20013;&#21487;&#36776;&#21035;&#24615;&#30340;&#29702;&#35770;&#65292;&#32771;&#34385;&#20102;&#22312;&#25317;&#26377;&#20219;&#21153;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#30340;&#21518;&#26524;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21363;&#20351;&#22312;&#22238;&#24402;&#30340;&#24773;&#20917;&#19979;&#20063;&#21487;&#20197;&#23454;&#29616;&#21487;&#35782;&#21035;&#24615;&#65292;&#25193;&#23637;&#20102;&#20808;&#21069;&#20165;&#38480;&#20110;&#21333;&#20219;&#21153;&#20998;&#31867;&#24773;&#20917;&#30340;&#24037;&#20316;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20219;&#21153;&#20998;&#24067;&#30340;&#23384;&#22312;&#23450;&#20041;&#20102;&#19968;&#20010;&#28508;&#22312;&#21464;&#37327;&#30340;&#26465;&#20214;&#20808;&#39564;&#65292;&#23558;&#21487;&#35782;&#21035;&#24615;&#30340;&#31561;&#20215;&#31867;&#38477;&#20302;&#21040;&#25490;&#21015;&#21644;&#32553;&#25918;&#65292;&#36825;&#26159;&#19968;&#20010;&#26356;&#24378;&#22823;&#21644;&#26356;&#26377;&#29992;&#30340;&#32467;&#26524;&#12290;&#24403;&#25105;&#20204;&#36827;&#19968;&#27493;&#20551;&#35774;&#36825;&#20123;&#20219;&#21153;&#20043;&#38388;&#23384;&#22312;&#22240;&#26524;&#20851;&#31995;&#26102;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;&#31616;&#21333;&#30340;&#26368;&#22823;&#36793;&#38469;&#20284;&#28982;&#20248;&#21270;&#65292;&#24182;&#22312;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#26041;&#38754;&#20855;&#26377;&#19979;&#28216;&#24212;&#29992;&#30340;&#21487;&#34892;&#24615;&#12290;&#22312;&#32463;&#39564;&#19978;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#24674;&#22797;&#21512;&#25104;&#21644;&#29616;&#23454;&#19990;&#30028;&#25968;&#25454;&#30340;&#35268;&#33539;&#34920;&#31034;&#26041;&#38754;&#20248;&#20110;&#26356;&#19968;&#33324;&#30340;&#26080;&#30417;&#30563;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work extends the theory of identifiability in supervised learning by considering the consequences of having access to a distribution of tasks. In such cases, we show that identifiability is achievable even in the case of regression, extending prior work restricted to the single-task classification case. Furthermore, we show that the existence of a task distribution which defines a conditional prior over latent variables reduces the equivalence class for identifiability to permutations and scaling, a much stronger and more useful result. When we further assume a causal structure over these tasks, our approach enables simple maximum marginal likelihood optimization together with downstream applicability to causal representation learning. Empirically, we validate that our model outperforms more general unsupervised models in recovering canonical representations for synthetic and real-world data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#28145;&#24230;&#38750;&#21442;&#25968;&#22238;&#24402;&#30340;&#26377;&#25928;&#38389;&#21487;&#22827;&#26031;&#22522;&#32500;&#25968;&#34920;&#31034;&#26041;&#27861;&#65292;&#35777;&#26126;&#20102;&#28145;&#24230;&#38750;&#21442;&#25968;&#22238;&#24402;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20165;&#21462;&#20915;&#20110;&#25968;&#25454;&#38598;&#21608;&#22260;&#30340;&#23376;&#38598;&#30340;&#26377;&#25928;&#38389;&#21487;&#22827;&#26031;&#22522;&#32500;&#25968;&#12290;</title><link>http://arxiv.org/abs/2306.14859</link><description>&lt;p&gt;
&#28145;&#24230;&#38750;&#21442;&#25968;&#22238;&#24402;&#30340;&#26377;&#25928;&#38389;&#21487;&#22827;&#26031;&#22522;&#32500;&#25968;&#65306;&#20989;&#25968;&#36924;&#36817;&#21644;&#32479;&#35745;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Effective Minkowski Dimension of Deep Nonparametric Regression: Function Approximation and Statistical Theories. (arXiv:2306.14859v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14859
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#28145;&#24230;&#38750;&#21442;&#25968;&#22238;&#24402;&#30340;&#26377;&#25928;&#38389;&#21487;&#22827;&#26031;&#22522;&#32500;&#25968;&#34920;&#31034;&#26041;&#27861;&#65292;&#35777;&#26126;&#20102;&#28145;&#24230;&#38750;&#21442;&#25968;&#22238;&#24402;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20165;&#21462;&#20915;&#20110;&#25968;&#25454;&#38598;&#21608;&#22260;&#30340;&#23376;&#38598;&#30340;&#26377;&#25928;&#38389;&#21487;&#22827;&#26031;&#22522;&#32500;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;&#20851;&#20110;&#28145;&#24230;&#38750;&#21442;&#25968;&#22238;&#24402;&#30340;&#29702;&#35770;&#34920;&#26126;&#65292;&#24403;&#36755;&#20837;&#25968;&#25454;&#20301;&#20110;&#20302;&#32500;&#27969;&#24418;&#19978;&#26102;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#36866;&#24212;&#22266;&#26377;&#30340;&#25968;&#25454;&#32467;&#26500;&#12290;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#25968;&#25454;&#24688;&#22909;&#20301;&#20110;&#20302;&#32500;&#27969;&#24418;&#19978;&#30340;&#20551;&#35774;&#26159;&#33499;&#21051;&#30340;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#20010;&#26356;&#23485;&#26494;&#30340;&#20551;&#35774;&#65292;&#21363;&#36755;&#20837;&#25968;&#25454;&#38598;&#20013;&#22312;$\mathbb{R}^d$&#30340;&#19968;&#20010;&#23376;&#38598;$\mathcal{S}$&#21608;&#22260;&#65292;&#24182;&#19988;$\mathcal{S}$&#30340;&#20869;&#22312;&#32500;&#25968;&#21487;&#20197;&#29992;&#26032;&#30340;&#22797;&#26434;&#24230;&#34920;&#31034;&#8212;&#8212;&#26377;&#25928;&#38389;&#21487;&#22827;&#26031;&#22522;&#32500;&#25968;&#36827;&#34892;&#21051;&#30011;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#28145;&#24230;&#38750;&#21442;&#25968;&#22238;&#24402;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20165;&#21462;&#20915;&#20110;$\mathcal{S}$&#30340;&#26377;&#25928;&#38389;&#21487;&#22827;&#26031;&#22522;&#32500;&#25968;$p$&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#32771;&#34385;&#20855;&#26377;&#21508;&#21521;&#24322;&#24615;&#39640;&#26031;&#38543;&#26426;&#35774;&#35745;$ N(0&#65292;\Sigma)$&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#65292;&#36827;&#19968;&#27493;&#35828;&#26126;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#21457;&#29616;&#65292;&#20854;&#20013;$ \Sigma $&#20855;&#26377;&#20840;&#31209;&#12290;&#24403;$ \Sigma $&#30340;&#29305;&#24449;&#20540;&#26377;&#25351;&#25968;&#25110;&#22810;&#39033;&#24335;&#34928;&#20943;&#26102;&#65292;&#23376;&#38598;$ \mathcal {S }$&#30340;&#26377;&#25928;&#38389;&#21487;&#22827;&#26031;&#22522;&#32500;&#25968;&#34987;&#35777;&#26126;&#31561;&#20110;&#21508;&#21521;&#24322;&#24615;&#39640;&#26031;&#27969;&#24418;&#30340;&#20869;&#22312;&#32500;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing theories on deep nonparametric regression have shown that when the input data lie on a low-dimensional manifold, deep neural networks can adapt to the intrinsic data structures. In real world applications, such an assumption of data lying exactly on a low dimensional manifold is stringent. This paper introduces a relaxed assumption that the input data are concentrated around a subset of $\mathbb{R}^d$ denoted by $\mathcal{S}$, and the intrinsic dimension of $\mathcal{S}$ can be characterized by a new complexity notation -- effective Minkowski dimension. We prove that, the sample complexity of deep nonparametric regression only depends on the effective Minkowski dimension of $\mathcal{S}$ denoted by $p$. We further illustrate our theoretical findings by considering nonparametric regression with an anisotropic Gaussian random design $N(0,\Sigma)$, where $\Sigma$ is full rank. When the eigenvalues of $\Sigma$ have an exponential or polynomial decay, the effective Minkowski dimens
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#22914;&#20309;&#20174;&#22810;&#39033;&#24335;&#28151;&#27788;&#25193;&#23637;&#30340;&#35282;&#24230;&#20998;&#26512;DANN&#30340;&#31070;&#32463;&#20449;&#21495;&#22788;&#29702;&#65292;&#20026;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#25552;&#20379;&#20102;&#26356;&#22810;&#30340;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#27861;&#21644;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2306.14753</link><description>&lt;p&gt;
&#28145;&#24230;&#20219;&#24847;&#22810;&#39033;&#24335;&#28151;&#27788;&#31070;&#32463;&#32593;&#32476; - &#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22914;&#20309;&#21463;&#30410;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#21516;&#24577;&#28151;&#27788;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
The Deep Arbitrary Polynomial Chaos Neural Network or how Deep Artificial Neural Networks could benefit from Data-Driven Homogeneous Chaos Theory. (arXiv:2306.14753v1 [cs.NE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14753
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#22914;&#20309;&#20174;&#22810;&#39033;&#24335;&#28151;&#27788;&#25193;&#23637;&#30340;&#35282;&#24230;&#20998;&#26512;DANN&#30340;&#31070;&#32463;&#20449;&#21495;&#22788;&#29702;&#65292;&#20026;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#25552;&#20379;&#20102;&#26356;&#22810;&#30340;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#27861;&#21644;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#24037;&#26234;&#33021;&#21644;&#26426;&#22120;&#23398;&#20064;&#22312;&#25968;&#23398;&#35745;&#31639;&#12289;&#29289;&#29702;&#24314;&#27169;&#12289;&#35745;&#31639;&#31185;&#23398;&#12289;&#36890;&#35759;&#31185;&#23398;&#21644;&#38543;&#26426;&#20998;&#26512;&#31561;&#39046;&#22495;&#24471;&#21040;&#20102;&#24191;&#27867;&#24212;&#29992;&#12290;&#22522;&#20110;&#28145;&#24230;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#65288;DANN&#65289;&#30340;&#26041;&#27861;&#22312;&#24403;&#20170;&#38750;&#24120;&#27969;&#34892;&#12290;&#20294;&#23545;&#20110;&#22823;&#22810;&#25968;&#22522;&#20110;DANN&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#31070;&#32463;&#20449;&#21495;&#22788;&#29702;&#30340;&#26680;&#24515;&#32467;&#26500;&#20173;&#28982;&#26159;&#30456;&#21516;&#30340;&#65292;&#22312;&#36825;&#31181;&#32467;&#26500;&#19979;&#65292;&#33410;&#28857;&#21709;&#24212;&#34987;&#32534;&#30721;&#20026;&#31070;&#32463;&#27963;&#21160;&#30340;&#32447;&#24615;&#21472;&#21152;&#65292;&#32780;&#38750;&#32447;&#24615;&#21017;&#26159;&#30001;&#28608;&#27963;&#20989;&#25968;&#35302;&#21457;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24314;&#35758;&#20174;&#21516;&#24577;&#28151;&#27788;&#29702;&#35770;&#65288;&#22914;&#22810;&#39033;&#24335;&#28151;&#27788;&#25193;&#23637;&#65289;&#30340;&#35282;&#24230;&#20998;&#26512;DANN&#30340;&#31070;&#32463;&#20449;&#21495;&#22788;&#29702;&#12290;&#20174;PCE&#30340;&#35282;&#24230;&#30475;&#65292;DANN&#30340;&#27599;&#20010;&#33410;&#28857;&#30340;&#65288;&#32447;&#24615;&#65289;&#21709;&#24212;&#21487;&#20197;&#30475;&#20316;&#26159;&#19968;&#20010;&#21516;&#24577;&#28151;&#27788;&#36807;&#31243;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#23558;&#27963;&#24615;&#20989;&#25968;&#26367;&#25442;&#20026;&#38750;&#32447;&#24615;&#30340;&#27867;&#20989;&#26469;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;
Artificial Intelligence and Machine learning have been widely used in various fields of mathematical computing, physical modeling, computational science, communication science, and stochastic analysis. Approaches based on Deep Artificial Neural Networks (DANN) are very popular in our days. Depending on the learning task, the exact form of DANNs is determined via their multi-layer architecture, activation functions and the so-called loss function. However, for a majority of deep learning approaches based on DANNs, the kernel structure of neural signal processing remains the same, where the node response is encoded as a linear superposition of neural activity, while the non-linearity is triggered by the activation functions. In the current paper, we suggest to analyze the neural signal processing in DANNs from the point of view of homogeneous chaos theory as known from polynomial chaos expansion (PCE). From the PCE perspective, the (linear) response on each node of a DANN could be seen a
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24605;&#36335;&#65292;&#36890;&#36807;&#25506;&#32034; GPnn &#30340;&#40065;&#26834;&#24615;&#21644;&#26497;&#38480;&#34892;&#20026;&#23454;&#29616;&#22823;&#35268;&#27169;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#65292;&#21363;&#20351;&#22312;&#20986;&#29616;&#37325;&#22823;&#23567;&#38169;&#35823;&#30340;&#24773;&#20917;&#19979;&#21482;&#38656;&#35201;&#33457;&#36153;&#23569;&#37327;&#30340;&#24037;&#20316;&#36827;&#34892;&#21442;&#25968;&#20272;&#35745;&#21363;&#21487;&#23454;&#29616;&#39640; MSE &#20934;&#30830;&#24615;&#12290;&#21516;&#26102;&#65292;&#35813;&#30740;&#31350;&#25104;&#21151;&#35299;&#20915;&#20102;&#21152;&#24615;&#22122;&#22768;&#26041;&#24046;&#24102;&#26469;&#30340;&#19981;&#30830;&#23450;&#24230;&#26657;&#20934;&#21644; NLL &#20934;&#30830;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.14731</link><description>&lt;p&gt;
&#21033;&#29992;&#26412;&#22320;&#24615;&#21644;&#40065;&#26834;&#24615;&#23454;&#29616;&#22823;&#35268;&#27169;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Leveraging Locality and Robustness to Achieve Massively Scalable Gaussian Process Regression. (arXiv:2306.14731v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14731
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24605;&#36335;&#65292;&#36890;&#36807;&#25506;&#32034; GPnn &#30340;&#40065;&#26834;&#24615;&#21644;&#26497;&#38480;&#34892;&#20026;&#23454;&#29616;&#22823;&#35268;&#27169;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#65292;&#21363;&#20351;&#22312;&#20986;&#29616;&#37325;&#22823;&#23567;&#38169;&#35823;&#30340;&#24773;&#20917;&#19979;&#21482;&#38656;&#35201;&#33457;&#36153;&#23569;&#37327;&#30340;&#24037;&#20316;&#36827;&#34892;&#21442;&#25968;&#20272;&#35745;&#21363;&#21487;&#23454;&#29616;&#39640; MSE &#20934;&#30830;&#24615;&#12290;&#21516;&#26102;&#65292;&#35813;&#30740;&#31350;&#25104;&#21151;&#35299;&#20915;&#20102;&#21152;&#24615;&#22122;&#22768;&#26041;&#24046;&#24102;&#26469;&#30340;&#19981;&#30830;&#23450;&#24230;&#26657;&#20934;&#21644; NLL &#20934;&#30830;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#25152;&#25552;&#20379;&#30340;&#31934;&#30830;&#39044;&#27979;&#21644;&#21407;&#21017;&#24615;&#19981;&#30830;&#23450;&#24615;&#27979;&#37327;&#20250;&#20135;&#29983; O(n^3) &#30340;&#25104;&#26412;&#65292;&#36825;&#23545;&#20110;&#29616;&#20195;&#22823;&#35268;&#27169;&#24212;&#29992;&#26469;&#35828;&#26159;&#38590;&#20197;&#25215;&#21463;&#30340;&#12290;&#22240;&#27492;&#65292;&#20986;&#29616;&#20102;&#22823;&#37327;&#20851;&#20110;&#35745;&#31639;&#25928;&#29575;&#30340;&#30740;&#31350;&#12290;&#25105;&#20204;&#36890;&#36807;&#25506;&#32034; GP &#26368;&#36817;&#37051;&#39044;&#27979;(GPnn) &#30340;&#40065;&#26834;&#24615;&#21644;&#26497;&#38480;&#34892;&#20026;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#35270;&#35282;&#12290;&#25105;&#20204;&#36890;&#36807;&#29702;&#35770;&#21644;&#27169;&#25311;&#35777;&#26126;&#65292;&#38543;&#30528;&#25968;&#25454;&#37327; n &#30340;&#22686;&#21152;&#65292;&#20272;&#35745;&#21442;&#25968;&#21644; GP &#27169;&#22411;&#20551;&#35774;&#30340;&#20934;&#30830;&#24615;&#23545; GPnn &#39044;&#27979;&#20934;&#30830;&#24615;&#30340;&#24433;&#21709;&#36880;&#28176;&#20943;&#23567;&#12290;&#22240;&#27492;&#65292;&#20026;&#20102;&#23454;&#29616;&#39640; MSE &#20934;&#30830;&#24615;&#65292;&#21363;&#20351;&#22312;&#20986;&#29616;&#37325;&#22823;&#38169;&#35823;&#30340;&#24773;&#20917;&#19979;, &#21482;&#38656;&#35201;&#33457;&#36153;&#23569;&#37327;&#30340;&#24037;&#20316;&#36827;&#34892;&#21442;&#25968;&#20272;&#35745;&#21363;&#21487;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#38543;&#30528; n &#36235;&#36817;&#20110;&#26080;&#31351;&#22823;&#65292;&#25105;&#20204;&#21457;&#29616;&#19981;&#30830;&#23450;&#24230;&#26657;&#20934;&#21644; NLL &#20173;&#23545;&#19968;&#20010;&#21442;&#25968;&#25935;&#24863;&#65292;&#21363;&#21152;&#24615;&#22122;&#22768;&#26041;&#24046;&#65307;&#20294;&#25105;&#20204;&#35777;&#26126;&#21487;&#20197;&#32416;&#27491;&#36825;&#31181;&#19981;&#20934;&#30830;&#24615;&#65292;&#24182;&#23454;&#29616;&#33391;&#22909;&#30340;&#19981;&#30830;&#23450;&#24230;&#26657;&#20934;&#21644; NLL&#12290;
&lt;/p&gt;
&lt;p&gt;
The accurate predictions and principled uncertainty measures provided by GP regression incur O(n^3) cost which is prohibitive for modern-day large-scale applications. This has motivated extensive work on computationally efficient approximations. We introduce a new perspective by exploring robustness properties and limiting behaviour of GP nearest-neighbour (GPnn) prediction. We demonstrate through theory and simulation that as the data-size n increases, accuracy of estimated parameters and GP model assumptions become increasingly irrelevant to GPnn predictive accuracy. Consequently, it is sufficient to spend small amounts of work on parameter estimation in order to achieve high MSE accuracy, even in the presence of gross misspecification. In contrast, as n tends to infinity, uncertainty calibration and NLL are shown to remain sensitive to just one parameter, the additive noise-variance; but we show that this source of inaccuracy can be corrected for, thereby achieving both well-calibra
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#19968;&#33268;&#24615;&#25512;&#26029;&#24605;&#24819;&#30340;&#26032;&#26041;&#27861;&#65292;&#21487;&#22312;&#25511;&#21046;&#34394;&#20551;&#21457;&#29616;&#29575;&#30340;&#21069;&#25552;&#19979;&#65292;&#35782;&#21035;&#19968;&#32452;&#30495;&#23454;&#30340;&#36793;&#12290;</title><link>http://arxiv.org/abs/2306.14693</link><description>&lt;p&gt;
&#25511;&#21046;&#35823;&#24046;&#29575;&#30340;&#19968;&#33268;&#24615;&#38142;&#36335;&#39044;&#27979;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Conformal link prediction to control the error rate. (arXiv:2306.14693v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14693
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#19968;&#33268;&#24615;&#25512;&#26029;&#24605;&#24819;&#30340;&#26032;&#26041;&#27861;&#65292;&#21487;&#22312;&#25511;&#21046;&#34394;&#20551;&#21457;&#29616;&#29575;&#30340;&#21069;&#25552;&#19979;&#65292;&#35782;&#21035;&#19968;&#32452;&#30495;&#23454;&#30340;&#36793;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#38142;&#36335;&#39044;&#27979;&#26041;&#27861;&#36820;&#22238;&#22270;&#20013;&#32570;&#22833;&#36793;&#30340;&#36830;&#25509;&#27010;&#29575;&#30340;&#20272;&#35745;&#20540;&#12290;&#36825;&#31181;&#36755;&#20986;&#21487;&#29992;&#20110;&#25353;&#21487;&#33021;&#24615;&#22823;&#23567;&#23545;&#32570;&#22833;&#36793;&#36827;&#34892;&#25490;&#24207;&#65292;&#20294;&#24182;&#26410;&#30452;&#25509;&#25552;&#20379;&#30495;&#23454;&#21644;&#19981;&#23384;&#22312;&#30340;&#20998;&#31867;&#12290;&#26412;&#30740;&#31350;&#32771;&#34385;&#22312;&#25511;&#21046;&#34394;&#20551;&#21457;&#29616;&#29575;&#30340;&#21069;&#25552;&#19979;&#65292;&#35782;&#21035;&#19968;&#32452;&#30495;&#23454;&#30340;&#36793;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#19968;&#33268;&#24615;&#25512;&#26029;&#25991;&#29486;&#20013;&#39640;&#32423;&#24605;&#24819;&#30340;&#26032;&#26041;&#27861;&#12290;&#22270;&#24418;&#32467;&#26500;&#24341;&#20837;&#20102;&#25968;&#25454;&#20013;&#30340;&#22797;&#26434;&#20381;&#36182;&#20851;&#31995;&#65292;&#25105;&#20204;&#20180;&#32454;&#32771;&#34385;&#20102;&#36825;&#19968;&#28857;&#65292;&#22240;&#20026;&#36825;&#20351;&#24471;&#35774;&#32622;&#19981;&#21516;&#20110;&#19968;&#33324;&#30340;&#19968;&#33268;&#24615;&#25512;&#26029;&#35774;&#32622;&#65292;&#37027;&#37324;&#20551;&#23450;&#20102;&#20132;&#25442;&#24615;&#12290;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;FDR&#30340;&#25511;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most link prediction methods return estimates of the connection probability of missing edges in a graph. Such output can be used to rank the missing edges, from most to least likely to be a true edge, but it does not directly provide a classification into true and non-existent. In this work, we consider the problem of identifying a set of true edges with a control of the false discovery rate (FDR). We propose a novel method based on high-level ideas from the literature on conformal inference. The graph structure induces intricate dependence in the data, which we carefully take into account, as this makes the setup different from the usual setup in conformal inference, where exchangeability is assumed. The FDR control is empirically demonstrated for both simulated and real data.
&lt;/p&gt;</description></item><item><title>PWSHAP&#26159;&#19968;&#31181;&#29992;&#20110;&#25935;&#24863;&#39046;&#22495;&#20013;&#35780;&#20272;&#29305;&#23450;&#20108;&#36827;&#21046;&#21464;&#37327;&#30446;&#26631;&#25928;&#24212;&#30340;&#26694;&#26550;&#65292;&#20351;&#29992;&#29992;&#25143;&#23450;&#20041;&#30340;DAG&#21644;on-manifold Shapley&#20540;&#35782;&#21035;&#22240;&#26524;&#36335;&#24452;&#20013;&#30340;&#25928;&#24212;&#65292;&#21516;&#26102;&#23545;&#23545;&#25239;&#24615;&#25915;&#20987;&#20445;&#25345;&#31283;&#20581;&#24615;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#20934;&#30830;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.14672</link><description>&lt;p&gt;
PWSHAP&#65306;&#19968;&#31181;&#38024;&#23545;&#30446;&#26631;&#21464;&#37327;&#30340;&#36335;&#24452;&#35299;&#37322;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
PWSHAP: A Path-Wise Explanation Model for Targeted Variables. (arXiv:2306.14672v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14672
&lt;/p&gt;
&lt;p&gt;
PWSHAP&#26159;&#19968;&#31181;&#29992;&#20110;&#25935;&#24863;&#39046;&#22495;&#20013;&#35780;&#20272;&#29305;&#23450;&#20108;&#36827;&#21046;&#21464;&#37327;&#30446;&#26631;&#25928;&#24212;&#30340;&#26694;&#26550;&#65292;&#20351;&#29992;&#29992;&#25143;&#23450;&#20041;&#30340;DAG&#21644;on-manifold Shapley&#20540;&#35782;&#21035;&#22240;&#26524;&#36335;&#24452;&#20013;&#30340;&#25928;&#24212;&#65292;&#21516;&#26102;&#23545;&#23545;&#25239;&#24615;&#25915;&#20987;&#20445;&#25345;&#31283;&#20581;&#24615;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#20934;&#30830;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#27979;&#24615;&#40657;&#30418;&#27169;&#22411;&#21487;&#33021;&#34920;&#29616;&#20986;&#24456;&#39640;&#30340;&#20934;&#30830;&#24615;&#65292;&#20294;&#23427;&#20204;&#30340;&#19981;&#36879;&#26126;&#24615;&#38459;&#30861;&#20102;&#23427;&#20204;&#22312;&#23433;&#20840;&#20851;&#38190;&#30340;&#35745;&#31639;&#29615;&#22659;&#20013;&#30340;&#24212;&#29992;&#12290;&#35299;&#37322;&#26041;&#27861;&#65288;XAI&#65289;&#21487;&#20197;&#36890;&#36807;&#22686;&#21152;&#36879;&#26126;&#24230;&#26469;&#25552;&#39640;&#20915;&#31574;&#30340;&#20449;&#24515;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;XAI&#26041;&#27861;&#24182;&#19981;&#26159;&#38024;&#23545;&#25935;&#24863;&#39046;&#22495;&#20013;&#23545;&#20110;&#29305;&#23450;&#39044;&#27979;&#21464;&#37327;&#30340;&#35299;&#37322;&#65292;&#20363;&#22914;&#20020;&#24202;&#27169;&#22411;&#20013;&#30340;&#27835;&#30103;&#25928;&#26524;&#25110;&#25919;&#31574;&#27169;&#22411;&#20013;&#30340;&#31181;&#26063;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;Path-Wise Shapley Effects (PWSHAP)&#65292;&#36825;&#26159;&#19968;&#31181;&#26694;&#26550;&#65292;&#29992;&#20110;&#35780;&#20272;&#22797;&#26434;&#32467;&#26524;&#27169;&#22411;&#30340;&#20108;&#36827;&#21046;&#65288;&#20363;&#22914;&#27835;&#30103;&#65289;&#21464;&#37327;&#30340;&#30446;&#26631;&#25928;&#24212;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#29992;&#25143;&#23450;&#20041;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;DAG&#65289;&#26469;&#25193;&#20805;&#39044;&#27979;&#27169;&#22411;&#12290;&#35813;&#26041;&#27861;&#19982;on-manifold Shapley&#20540;&#19968;&#36215;&#20351;&#29992;&#22270;&#24418;&#26469;&#35782;&#21035;&#27839;&#22240;&#26524;&#36335;&#24452;&#30340;&#25928;&#24212;&#65292;&#21516;&#26102;&#20445;&#25345;&#23545;&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#31283;&#20581;&#24615;&#12290;&#25105;&#20204;&#30830;&#23450;&#20102;&#35782;&#21035;&#30340;&#36335;&#24452;Shapley&#25928;&#24212;&#21644;Shapley&#20540;&#30340;&#35823;&#24046;&#30028;&#38480;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;PWSHAP&#21487;&#20197;&#25191;&#34892;&#23616;&#37096;&#21452;...
&lt;/p&gt;
&lt;p&gt;
Predictive black-box models can exhibit high accuracy but their opaque nature hinders their uptake in safety-critical deployment environments. Explanation methods (XAI) can provide confidence for decision-making through increased transparency. However, existing XAI methods are not tailored towards models in sensitive domains where one predictor is of special interest, such as a treatment effect in a clinical model, or ethnicity in policy models. We introduce Path-Wise Shapley effects (PWSHAP), a framework for assessing the targeted effect of a binary (e.g.~treatment) variable from a complex outcome model. Our approach augments the predictive model with a user-defined directed acyclic graph (DAG). The method then uses the graph alongside on-manifold Shapley values to identify effects along causal pathways whilst maintaining robustness to adversarial attacks. We establish error bounds for the identified path-wise Shapley effects and for Shapley values. We show PWSHAP can perform local bi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#31454;&#20105;&#29615;&#22659;&#19979;&#30340;&#34892;&#20026;&#65292;&#21457;&#29616;&#25552;&#39640;&#25968;&#25454;&#34920;&#31034;&#36136;&#37327;&#21487;&#33021;&#20250;&#23548;&#33268;&#20379;&#24212;&#21830;&#25972;&#20307;&#39044;&#27979;&#20934;&#30830;&#24615;&#38477;&#20302;&#65292;&#20174;&#32780;&#38477;&#20302;&#31038;&#20250;&#31119;&#21033;&#12290;</title><link>http://arxiv.org/abs/2306.14670</link><description>&lt;p&gt;
&#31454;&#20105;&#29615;&#22659;&#19979;&#36125;&#21494;&#26031;&#39118;&#38505;&#30340;&#25552;&#39640;&#21487;&#33021;&#23548;&#33268;&#31038;&#20250;&#31119;&#21033;&#30340;&#38477;&#20302;
&lt;/p&gt;
&lt;p&gt;
Improved Bayes Risk Can Yield Reduced Social Welfare Under Competition. (arXiv:2306.14670v1 [cs.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14670
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#31454;&#20105;&#29615;&#22659;&#19979;&#30340;&#34892;&#20026;&#65292;&#21457;&#29616;&#25552;&#39640;&#25968;&#25454;&#34920;&#31034;&#36136;&#37327;&#21487;&#33021;&#20250;&#23548;&#33268;&#20379;&#24212;&#21830;&#25972;&#20307;&#39044;&#27979;&#20934;&#30830;&#24615;&#38477;&#20302;&#65292;&#20174;&#32780;&#38477;&#20302;&#31038;&#20250;&#31119;&#21033;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#35268;&#27169;&#30340;&#22686;&#38271;&#65292;&#32553;&#25918;&#23450;&#24459;&#31561;&#36235;&#21183;&#39044;&#35745;&#20250;&#23548;&#33268;&#39044;&#27979;&#20934;&#30830;&#24615;&#30340;&#25345;&#32493;&#25913;&#36827;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#36235;&#21183;&#21482;&#32771;&#34385;&#20102;&#21333;&#20010;&#27169;&#22411;&#20379;&#24212;&#21830;&#30340;&#35270;&#35282;&#65292;&#32780;&#23454;&#38469;&#19978;&#20379;&#24212;&#21830;&#20043;&#38388;&#24120;&#24120;&#31454;&#20105;&#29992;&#25143;&#12290;&#26412;&#25991;&#35777;&#26126;&#20102;&#31454;&#20105;&#21487;&#20197;&#20174;&#26681;&#26412;&#19978;&#25913;&#21464;&#36825;&#20123;&#32553;&#25918;&#36235;&#21183;&#30340;&#34892;&#20026;&#65292;&#29978;&#33267;&#21487;&#33021;&#36896;&#25104;&#25972;&#20307;&#39044;&#27979;&#20934;&#30830;&#24615;&#38543;&#30528;&#35268;&#27169;&#30340;&#22686;&#22823;&#32780;&#38750;&#21333;&#35843;&#25110;&#38477;&#20302;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;&#19968;&#20010;&#20998;&#31867;&#20219;&#21153;&#30340;&#31454;&#20105;&#27169;&#22411;&#65292;&#24182;&#20351;&#29992;&#25968;&#25454;&#34920;&#31034;&#20316;&#20026;&#30740;&#31350;&#35268;&#27169;&#22686;&#21152;&#30340;&#24433;&#21709;&#30340;&#38236;&#22836;&#12290;&#25105;&#20204;&#21457;&#29616;&#22312;&#19968;&#23478;&#24066;&#22330;&#19978;&#65292;&#25913;&#21892;&#25968;&#25454;&#34920;&#31034;&#36136;&#37327;&#65288;&#25353;&#36125;&#21494;&#26031;&#39118;&#38505;&#35745;&#37327;&#65289;&#21487;&#33021;&#20250;&#38477;&#20302;&#31454;&#20105;&#27169;&#22411;&#20379;&#24212;&#21830;&#30340;&#25972;&#20307;&#39044;&#27979;&#20934;&#30830;&#24615;&#65288;&#21363;&#31038;&#20250;&#31119;&#21033;&#65289;&#12290;&#25105;&#20204;&#30340;&#20363;&#23376;&#28085;&#30422;&#20102;&#31616;&#21333;&#35774;&#32622;&#20013;&#30340;&#23553;&#38381;&#24335;&#20844;&#24335;&#21040;&#39044;&#35757;&#32451;&#30340; CIFAR-10 &#27169;&#25311;&#12290;
&lt;/p&gt;
&lt;p&gt;
As the scale of machine learning models increases, trends such as scaling laws anticipate consistent downstream improvements in predictive accuracy. However, these trends take the perspective of a single model-provider in isolation, while in reality providers often compete with each other for users. In this work, we demonstrate that competition can fundamentally alter the behavior of these scaling trends, even causing overall predictive accuracy across users to be non-monotonic or decreasing with scale. We define a model of competition for classification tasks, and use data representations as a lens for studying the impact of increases in scale. We find many settings where improving data representation quality (as measured by Bayes risk) decreases the overall predictive accuracy across users (i.e., social welfare) for a marketplace of competing model-providers. Our examples range from closed-form formulas in simple settings to simulations with pretrained representations on CIFAR-10. At
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;CST-YOLO&#31639;&#27861;&#65292;&#22522;&#20110;&#25913;&#36827;&#30340;YOLOv7&#21644;CNN-Swin Transformer&#65292;&#24341;&#20837;&#20102;&#20960;&#20010;&#26377;&#29992;&#30340;&#27169;&#22411;&#65292;&#26377;&#25928;&#25552;&#39640;&#20102;&#34880;&#32454;&#32990;&#26816;&#27979;&#31934;&#24230;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#20854;&#22312;&#19977;&#20010;&#34880;&#32454;&#32990;&#25968;&#25454;&#38598;&#19978;&#22343;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.14590</link><description>&lt;p&gt;
CST-YOLO: &#19968;&#31181;&#22522;&#20110;&#25913;&#36827;&#30340;YOLOv7&#21644;CNN-Swin Transformer&#30340;&#34880;&#32454;&#32990;&#26816;&#27979;&#26032;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
CST-YOLO: A Novel Method for Blood Cell Detection Based on Improved YOLOv7 and CNN-Swin Transformer. (arXiv:2306.14590v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14590
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;CST-YOLO&#31639;&#27861;&#65292;&#22522;&#20110;&#25913;&#36827;&#30340;YOLOv7&#21644;CNN-Swin Transformer&#65292;&#24341;&#20837;&#20102;&#20960;&#20010;&#26377;&#29992;&#30340;&#27169;&#22411;&#65292;&#26377;&#25928;&#25552;&#39640;&#20102;&#34880;&#32454;&#32990;&#26816;&#27979;&#31934;&#24230;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#20854;&#22312;&#19977;&#20010;&#34880;&#32454;&#32990;&#25968;&#25454;&#38598;&#19978;&#22343;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34880;&#32454;&#32990;&#26816;&#27979;&#26159;&#35745;&#31639;&#26426;&#35270;&#35273;&#20013;&#20856;&#22411;&#30340;&#23567;&#29289;&#20307;&#26816;&#27979;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;CST-YOLO&#27169;&#22411;&#65292;&#22522;&#20110;YOLOv7&#32467;&#26500;&#24182;&#20351;&#29992;CNN-Swin Transformer&#65288;CST&#65289;&#36827;&#34892;&#22686;&#24378;&#65292;&#36825;&#26159;&#19968;&#31181;CNN-Transformer&#34701;&#21512;&#30340;&#26032;&#23581;&#35797;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#19977;&#20010;&#26377;&#29992;&#30340;&#27169;&#22411;&#65306;&#21152;&#26435;&#39640;&#25928;&#23618;&#32858;&#21512;&#32593;&#32476;&#65288;W-ELAN&#65289;&#12289;&#22810;&#23610;&#24230;&#36890;&#36947;&#20998;&#21106;&#65288;MCS&#65289;&#21644;&#32423;&#32852;&#21367;&#31215;&#23618;&#65288;CatConv&#65289;&#65292;&#20197;&#25552;&#39640;&#23567;&#29289;&#20307;&#26816;&#27979;&#31934;&#24230;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;CST-YOLO&#22312;&#19977;&#20010;&#34880;&#32454;&#32990;&#25968;&#25454;&#38598;&#19978;&#20998;&#21035;&#36798;&#21040;&#20102;92.7&#12289;95.6&#21644;91.1 mAP@0.5&#65292;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#29289;&#20307;&#26816;&#27979;&#22120;&#65292;&#22914;YOLOv5&#21644;YOLOv7&#12290;&#25105;&#20204;&#30340;&#20195;&#30721;&#21487;&#22312;https://github.com/mkang315/CST-YOLO&#19978;&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
Blood cell detection is a typical small-scale object detection problem in computer vision. In this paper, we propose a CST-YOLO model for blood cell detection based on YOLOv7 architecture and enhance it with the CNN-Swin Transformer (CST), which is a new attempt at CNN-Transformer fusion. We also introduce three other useful modules: Weighted Efficient Layer Aggregation Networks (W-ELAN), Multiscale Channel Split (MCS), and Concatenate Convolutional Layers (CatConv) in our CST-YOLO to improve small-scale object detection precision. Experimental results show that the proposed CST-YOLO achieves 92.7, 95.6, and 91.1 mAP@0.5 respectively on three blood cell datasets, outperforming state-of-the-art object detectors, e.g., YOLOv5 and YOLOv7. Our code is available at https://github.com/mkang315/CST-YOLO.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#31350;&#20102;&#22810;&#36755;&#20986;&#27169;&#22411;&#32452;&#25104;&#30340;&#21160;&#24577;&#38598;&#25104;&#22312;&#22810;&#27493;&#39044;&#27979;&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#21457;&#29616;&#22522;&#20110;&#20210;&#35009;&#21644;&#26102;&#38388;&#31383;&#21475;&#30340;&#21160;&#24577;&#38598;&#25104;&#34920;&#29616;&#26368;&#20339;&#12290;&#38543;&#30528;&#39044;&#27979;&#26102;&#38388;&#30340;&#22686;&#21152;&#65292;&#22823;&#22810;&#25968;&#26041;&#27861;&#38590;&#20197;&#32988;&#36807;&#38745;&#24577;&#38598;&#25104;&#12290;</title><link>http://arxiv.org/abs/2306.14563</link><description>&lt;p&gt;
&#22810;&#27493;&#39044;&#27979;&#30340;&#22810;&#36755;&#20986;&#38598;&#25104;
&lt;/p&gt;
&lt;p&gt;
Multi-output Ensembles for Multi-step Forecasting. (arXiv:2306.14563v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14563
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#31350;&#20102;&#22810;&#36755;&#20986;&#27169;&#22411;&#32452;&#25104;&#30340;&#21160;&#24577;&#38598;&#25104;&#22312;&#22810;&#27493;&#39044;&#27979;&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#21457;&#29616;&#22522;&#20110;&#20210;&#35009;&#21644;&#26102;&#38388;&#31383;&#21475;&#30340;&#21160;&#24577;&#38598;&#25104;&#34920;&#29616;&#26368;&#20339;&#12290;&#38543;&#30528;&#39044;&#27979;&#26102;&#38388;&#30340;&#22686;&#21152;&#65292;&#22823;&#22810;&#25968;&#26041;&#27861;&#38590;&#20197;&#32988;&#36807;&#38745;&#24577;&#38598;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#30001;&#22810;&#36755;&#20986;&#27169;&#22411;&#32452;&#25104;&#30340;&#38598;&#25104;&#22312;&#22810;&#27493;&#39044;&#27979;&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;&#12290;&#21160;&#24577;&#38598;&#25104;&#36890;&#24120;&#29992;&#20110;&#39044;&#27979;&#65292;&#20294;&#26159;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#21482;&#36866;&#29992;&#20110;&#19968;&#27493;&#39044;&#27979;&#20219;&#21153;&#12290;&#19982;&#27492;&#30456;&#23545;&#65292;&#21160;&#24577;&#38598;&#25104;&#22312;&#22810;&#27493;&#39044;&#27979;&#20013;&#30340;&#24212;&#29992;&#25991;&#29486;&#24456;&#23569;&#65292;&#19988;&#19981;&#28165;&#26970;&#32452;&#21512;&#35268;&#21017;&#22914;&#20309;&#24212;&#29992;&#20110;&#25972;&#20010;&#39044;&#27979;&#26102;&#27573;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#65292;&#20197;&#20998;&#26512;&#21160;&#24577;&#38598;&#25104;&#22312;&#22810;&#27493;&#39044;&#27979;&#20013;&#30340;&#24212;&#29992;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#20010;&#23454;&#20363;&#30740;&#31350;&#65292;&#21253;&#21547;3568&#20010;&#26102;&#38388;&#24207;&#21015;&#21644;&#19968;&#20010;&#30001;30&#20010;&#22810;&#36755;&#20986;&#27169;&#22411;&#32452;&#25104;&#30340;&#38598;&#25104;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22522;&#20110;&#20210;&#35009;&#21644;&#26102;&#38388;&#31383;&#21475;&#30340;&#21160;&#24577;&#38598;&#25104;&#22312;&#24179;&#22343;&#25490;&#21517;&#19978;&#34920;&#29616;&#26368;&#20339;&#12290;&#27492;&#22806;&#65292;&#38543;&#30528;&#39044;&#27979;&#26102;&#38388;&#36880;&#27493;&#22686;&#21152;&#65292;&#22823;&#22810;&#25968;&#26041;&#27861;&#37117;&#38590;&#20197;&#32988;&#36807;&#23558;&#25152;&#26377;&#27169;&#22411;&#20998;&#37197;&#30456;&#31561;&#26435;&#37325;&#30340;&#38745;&#24577;&#38598;&#25104;&#26041;&#27861;&#12290;&#23454;&#39564;&#20195;&#30721;&#24050;&#20844;&#24320;&#22312;&#19968;&#20010;&#20195;&#30721;&#24211;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the application of ensembles composed of multi-output models for multi-step ahead forecasting problems. Dynamic ensembles have been commonly used for forecasting. However, these are typically designed for one-step-ahead tasks. On the other hand, the literature regarding the application of dynamic ensembles for multi-step ahead forecasting is scarce. Moreover, it is not clear how the combination rule is applied across the forecasting horizon. We carried out extensive experiments to analyze the application of dynamic ensembles for multi-step forecasting. We resorted to a case study with 3568 time series and an ensemble of 30 multi-output models. We discovered that dynamic ensembles based on arbitrating and windowing present the best performance according to average rank. Moreover, as the horizon increases, most approaches struggle to outperform a static ensemble that assigns equal weights to all models. The experiments are publicly available in a repository.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#31216;&#20026;H-PCFE&#30340;&#26032;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#22810;&#39033;&#24335;&#30456;&#20851;&#20989;&#25968;&#25193;&#23637;&#65288;PCFE&#65289;&#21644;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#38598;&#25104;&#36215;&#26469;&#65292;&#24320;&#21457;&#20102;&#19968;&#20010;&#24378;&#22823;&#30340;&#22810;&#20445;&#30495;&#24230;&#20195;&#29702;&#27169;&#22411;&#65292;&#20197;&#36319;&#36394;&#25968;&#23383;&#23402;&#29983;&#31995;&#32479;&#12290;</title><link>http://arxiv.org/abs/2306.14430</link><description>&lt;p&gt;
&#22686;&#24378;&#30340;&#22810;&#20445;&#30495;&#24230;&#24314;&#27169;&#29992;&#20110;&#25968;&#23383;&#23402;&#29983;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Enhanced multi-fidelity modelling for digital twin and uncertainty quantification. (arXiv:2306.14430v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14430
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#31216;&#20026;H-PCFE&#30340;&#26032;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#23558;&#22810;&#39033;&#24335;&#30456;&#20851;&#20989;&#25968;&#25193;&#23637;&#65288;PCFE&#65289;&#21644;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#38598;&#25104;&#36215;&#26469;&#65292;&#24320;&#21457;&#20102;&#19968;&#20010;&#24378;&#22823;&#30340;&#22810;&#20445;&#30495;&#24230;&#20195;&#29702;&#27169;&#22411;&#65292;&#20197;&#36319;&#36394;&#25968;&#23383;&#23402;&#29983;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#23383;&#23402;&#29983;&#25216;&#26415;&#22312;&#33322;&#31354;&#33322;&#22825;&#12289;&#22522;&#30784;&#35774;&#26045;&#21644;&#27773;&#36710;&#31561;&#24037;&#31243;&#21644;&#24037;&#19994;&#39046;&#22495;&#30340;&#37325;&#35201;&#24847;&#20041;&#19981;&#23481;&#24573;&#35270;&#12290;&#28982;&#32780;&#65292;&#32570;&#20047;&#35814;&#32454;&#30340;&#24212;&#29992;&#29305;&#23450;&#20449;&#24687;&#23545;&#20854;&#22312;&#23454;&#38469;&#31995;&#32479;&#20013;&#30340;&#26080;&#32541;&#23454;&#26045;&#26500;&#25104;&#20102;&#25361;&#25112;&#12290;&#25968;&#25454;&#39537;&#21160;&#27169;&#22411;&#22312;&#25968;&#23383;&#23402;&#29983;&#20013;&#21457;&#25381;&#30528;&#20851;&#38190;&#20316;&#29992;&#65292;&#36890;&#36807;&#21033;&#29992;&#25968;&#25454;&#21644;&#35745;&#31639;&#27169;&#22411;&#23454;&#29616;&#23454;&#26102;&#26356;&#26032;&#21644;&#39044;&#27979;&#12290;&#28982;&#32780;&#65292;&#21487;&#29992;&#25968;&#25454;&#30340;&#20445;&#30495;&#24230;&#21644;&#20934;&#30830;&#20256;&#24863;&#22120;&#25968;&#25454;&#30340;&#32570;&#20047;&#24120;&#24120;&#38459;&#30861;&#20102;&#20195;&#29702;&#27169;&#22411;&#30340;&#39640;&#25928;&#23398;&#20064;&#65292;&#32780;&#36825;&#20123;&#27169;&#22411;&#26159;&#29289;&#29702;&#31995;&#32479;&#21644;&#25968;&#23383;&#23402;&#29983;&#27169;&#22411;&#20043;&#38388;&#30340;&#36830;&#25509;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#20174;&#24320;&#21457;&#19968;&#20010;&#24378;&#22823;&#30340;&#22810;&#20445;&#30495;&#24230;&#20195;&#29702;&#27169;&#22411;&#24320;&#22987;&#65292;&#38543;&#21518;&#24212;&#29992;&#20110;&#36319;&#36394;&#25968;&#23383;&#23402;&#29983;&#31995;&#32479;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#23558;&#22810;&#39033;&#24335;&#30456;&#20851;&#20989;&#25968;&#25193;&#23637;&#65288;PCFE&#65289;&#19982;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#38598;&#25104;&#36215;&#26469;&#65292;&#21019;&#24314;&#20986;&#19968;&#20010;&#26377;&#25928;&#30340;&#20195;&#29702;&#27169;&#22411;&#31216;&#20026;H-PCFE&#12290;
&lt;/p&gt;
&lt;p&gt;
The increasing significance of digital twin technology across engineering and industrial domains, such as aerospace, infrastructure, and automotive, is undeniable. However, the lack of detailed application-specific information poses challenges to its seamless implementation in practical systems. Data-driven models play a crucial role in digital twins, enabling real-time updates and predictions by leveraging data and computational models. Nonetheless, the fidelity of available data and the scarcity of accurate sensor data often hinder the efficient learning of surrogate models, which serve as the connection between physical systems and digital twin models. To address this challenge, we propose a novel framework that begins by developing a robust multi-fidelity surrogate model, subsequently applied for tracking digital twin systems. Our framework integrates polynomial correlated function expansion (PCFE) with the Gaussian process (GP) to create an effective surrogate model called H-PCFE.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#25968;&#20998;&#24067;&#21306;&#20998;&#30340;&#24322;&#24120;&#26816;&#27979;&#26041;&#27861;&#65292;&#20351;&#29992;Overlap Loss&#25439;&#22833;&#20989;&#25968;&#26368;&#23567;&#21270;&#27491;&#24120;&#21644;&#24322;&#24120;&#26679;&#26412;&#30340;&#20998;&#25968;&#20998;&#24067;&#37325;&#21472;&#21306;&#22495;&#65292;&#26080;&#38656;&#20154;&#24037;&#39044;&#23450;&#20041;&#30340;&#20998;&#25968;&#30446;&#26631;&#65292;&#33021;&#26356;&#22909;&#22320;&#36866;&#24212;&#19981;&#21516;&#25968;&#25454;&#22330;&#26223;&#65292;&#24182;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.14403</link><description>&lt;p&gt;
&#22522;&#20110;&#20998;&#25968;&#20998;&#24067;&#21306;&#20998;&#30340;&#24322;&#24120;&#26816;&#27979;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Anomaly Detection with Score Distribution Discrimination. (arXiv:2306.14403v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14403
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#25968;&#20998;&#24067;&#21306;&#20998;&#30340;&#24322;&#24120;&#26816;&#27979;&#26041;&#27861;&#65292;&#20351;&#29992;Overlap Loss&#25439;&#22833;&#20989;&#25968;&#26368;&#23567;&#21270;&#27491;&#24120;&#21644;&#24322;&#24120;&#26679;&#26412;&#30340;&#20998;&#25968;&#20998;&#24067;&#37325;&#21472;&#21306;&#22495;&#65292;&#26080;&#38656;&#20154;&#24037;&#39044;&#23450;&#20041;&#30340;&#20998;&#25968;&#30446;&#26631;&#65292;&#33021;&#26356;&#22909;&#22320;&#36866;&#24212;&#19981;&#21516;&#25968;&#25454;&#22330;&#26223;&#65292;&#24182;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#23545;&#20110;&#33021;&#22815;&#21033;&#29992;&#23569;&#37327;&#26631;&#27880;&#24322;&#24120;&#25968;&#25454;&#19982;&#22823;&#37327;&#26410;&#26631;&#27880;&#25968;&#25454;&#30340;&#24322;&#24120;&#26816;&#27979;&#26041;&#27861;&#21463;&#21040;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#29616;&#26377;&#30340;&#22522;&#20110;&#24322;&#24120;&#20449;&#24687;&#30340;&#24322;&#24120;&#26816;&#27979;&#26041;&#27861;&#20381;&#36182;&#20110;&#20154;&#24037;&#39044;&#23450;&#20041;&#30340;&#20998;&#25968;&#30446;&#26631;&#65292;&#20363;&#22914;&#20808;&#21069;&#30340;&#24120;&#37327;&#25110;&#36793;&#36317;&#36229;&#21442;&#25968;&#65292;&#20197;&#23454;&#29616;&#23545;&#27491;&#24120;&#21644;&#24322;&#24120;&#25968;&#25454;&#20043;&#38388;&#30340;&#24322;&#24120;&#20998;&#25968;&#21306;&#20998;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#23481;&#26131;&#21463;&#21040;&#26410;&#26631;&#27880;&#25968;&#25454;&#20013;&#24322;&#24120;&#27745;&#26579;&#30340;&#24433;&#21709;&#65292;&#24182;&#19988;&#32570;&#20047;&#23545;&#19981;&#21516;&#25968;&#25454;&#22330;&#26223;&#30340;&#36866;&#24212;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#25968;&#20998;&#24067;&#20248;&#21270;&#30340;&#24322;&#24120;&#35780;&#20998;&#20989;&#25968;&#65292;&#20174;&#32780;&#26356;&#22909;&#22320;&#20445;&#30041;&#36755;&#20837;&#25968;&#25454;&#30340;&#22810;&#26679;&#24615;&#21644;&#26356;&#32454;&#31890;&#24230;&#30340;&#20449;&#24687;&#65292;&#29305;&#21035;&#26159;&#24403;&#26410;&#26631;&#27880;&#25968;&#25454;&#21253;&#21547;&#26356;&#23454;&#38469;&#30340;&#24322;&#24120;&#22122;&#22768;&#26102;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#31216;&#20026;Overlap Loss&#30340;&#26032;&#22411;&#25439;&#22833;&#20989;&#25968;&#65292;&#23427;&#26368;&#23567;&#21270;&#27491;&#24120;&#21644;&#24322;&#24120;&#26679;&#26412;&#30340;&#20998;&#25968;&#20998;&#24067;&#37325;&#21472;&#21306;&#22495;&#65292;&#19981;&#20877;&#20381;&#36182;&#20110;&#20808;&#21069;&#30340;&#24322;&#24120;&#20449;&#24687;&#25110;&#39044;&#23450;&#20041;&#30340;&#30446;&#26631;&#12290;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#30340;&#22522;&#20110;&#24322;&#24120;&#20449;&#24687;&#30340;&#24322;&#24120;&#26816;&#27979;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent studies give more attention to the anomaly detection (AD) methods that can leverage a handful of labeled anomalies along with abundant unlabeled data. These existing anomaly-informed AD methods rely on manually predefined score target(s), e.g., prior constant or margin hyperparameter(s), to realize discrimination in anomaly scores between normal and abnormal data. However, such methods would be vulnerable to the existence of anomaly contamination in the unlabeled data, and also lack adaptation to different data scenarios. In this paper, we propose to optimize the anomaly scoring function from the view of score distribution, thus better retaining the diversity and more fine-grained information of input data, especially when the unlabeled data contains anomaly noises in more practical AD scenarios. We design a novel loss function called Overlap loss that minimizes the overlap area between the score distributions of normal and abnormal samples, which no longer depends on prior anom
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#27604;&#36739;&#20102;&#22240;&#26524;&#26694;&#26550;&#20013;&#30340;&#28508;&#22312;&#32467;&#26524;&#27169;&#22411;(RCM)&#21644;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;(SCM)&#65292;&#24182;&#38416;&#26126;&#20102;RCM&#25104;&#20026;SCM&#21487;&#34920;&#36798;&#30340;&#26465;&#20214;&#65292;&#20197;&#21450;&#27599;&#20010;RCM&#20316;&#20026;&#26576;&#20123;&#21487;&#34920;&#36798;&#30340;RCM&#30340;&#25277;&#35937;&#12290;&#20316;&#32773;&#20171;&#32461;&#20102;SCM&#21407;&#21017;&#22312;RCM&#32463;&#20856;&#24212;&#29992;&#20013;&#30340;&#37325;&#35201;&#20316;&#29992;&#65292;&#24182;&#25552;&#20986;&#20102;&#30001;&#22270;&#34920;&#31034;&#30340;&#20195;&#25968;&#32422;&#26463;&#30340;&#29305;&#24449;&#65292;&#26377;&#21161;&#20110;&#36827;&#19968;&#27493;&#27604;&#36739;&#20004;&#20010;&#26694;&#26550;&#12290;</title><link>http://arxiv.org/abs/2306.14351</link><description>&lt;p&gt;
&#27604;&#36739;&#22240;&#26524;&#26694;&#26550;&#65306;&#28508;&#22312;&#32467;&#26524;&#12289;&#32467;&#26500;&#27169;&#22411;&#12289;&#22270;&#21644;&#25277;&#35937;
&lt;/p&gt;
&lt;p&gt;
Comparing Causal Frameworks: Potential Outcomes, Structural Models, Graphs, and Abstractions. (arXiv:2306.14351v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14351
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#27604;&#36739;&#20102;&#22240;&#26524;&#26694;&#26550;&#20013;&#30340;&#28508;&#22312;&#32467;&#26524;&#27169;&#22411;(RCM)&#21644;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;(SCM)&#65292;&#24182;&#38416;&#26126;&#20102;RCM&#25104;&#20026;SCM&#21487;&#34920;&#36798;&#30340;&#26465;&#20214;&#65292;&#20197;&#21450;&#27599;&#20010;RCM&#20316;&#20026;&#26576;&#20123;&#21487;&#34920;&#36798;&#30340;RCM&#30340;&#25277;&#35937;&#12290;&#20316;&#32773;&#20171;&#32461;&#20102;SCM&#21407;&#21017;&#22312;RCM&#32463;&#20856;&#24212;&#29992;&#20013;&#30340;&#37325;&#35201;&#20316;&#29992;&#65292;&#24182;&#25552;&#20986;&#20102;&#30001;&#22270;&#34920;&#31034;&#30340;&#20195;&#25968;&#32422;&#26463;&#30340;&#29305;&#24449;&#65292;&#26377;&#21161;&#20110;&#36827;&#19968;&#27493;&#27604;&#36739;&#20004;&#20010;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#38416;&#26126;&#28508;&#22312;&#32467;&#26524;&#27169;&#22411;&#65288;RCM&#65289;&#19982;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#65288;SCM&#65289;&#26694;&#26550;&#22312;&#22240;&#26524;&#25512;&#26029;&#20013;&#30340;&#20851;&#31995;&#12290;&#37319;&#29992;&#20013;&#31435;&#30340;&#36923;&#36753;&#35270;&#35282;&#65292;&#20511;&#37492;&#20197;&#21069;&#30340;&#30740;&#31350;&#25104;&#26524;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;RCM&#25104;&#20026;SCM&#21487;&#34920;&#36798;&#30340;&#26465;&#20214;&#12290;&#19968;&#20010;&#20851;&#38190;&#32467;&#26524;&#26174;&#31034;&#65292;&#27599;&#20010;RCM -- &#21253;&#25324;&#37027;&#20123;&#36829;&#21453;SCM&#26694;&#26550;&#20013;&#26263;&#31034;&#30340;&#20195;&#25968;&#21407;&#21017;&#30340;RCM -- &#20316;&#20026;&#26576;&#20123;&#21487;&#34920;&#36798;&#30340;RCM&#30340;&#25277;&#35937;&#32780;&#20986;&#29616;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#20934;&#30830;&#23450;&#20301;SCM&#21407;&#21017;&#22312;RCM&#32463;&#20856;&#24212;&#29992;&#20013;&#30340;&#37325;&#35201;&#20316;&#29992;&#65292;&#38416;&#26126;&#20102;&#36825;&#31181;&#25913;&#36827;&#24615;&#35270;&#35282;&#30340;&#20248;&#21183;&#65307;&#21453;&#20043;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#30001;&#22270;&#34920;&#31034;&#30340;&#20195;&#25968;&#32422;&#26463;&#30340;&#29305;&#24449;&#65292;&#26377;&#21161;&#20110;&#36827;&#19968;&#27493;&#27604;&#36739;&#20004;&#20010;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
The aim of this paper is to make clear and precise the relationship between the Rubin causal model (RCM) and structural causal model (SCM) frameworks for causal inference. Adopting a neutral logical perspective, and drawing on previous work, we show what is required for an RCM to be representable by an SCM. A key result then shows that every RCM -- including those that violate algebraic principles implied by the SCM framework -- emerges as an abstraction of some representable RCM. Finally, we illustrate the power of this ameliorative perspective by pinpointing an important role for SCM principles in classic applications of RCMs; conversely, we offer a characterization of the algebraic constraints implied by a graph, helping to substantiate further comparisons between the two frameworks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#22522;&#20110;&#27979;&#35797;&#30340;&#26657;&#20934;&#35823;&#24046; &#65288;TCE&#65289;&#25351;&#26631;&#65292;&#20351;&#29992;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#32479;&#35745;&#26816;&#39564;&#30340;&#25439;&#22833;&#20989;&#25968;&#26469;&#34913;&#37327;&#27169;&#22411;&#39044;&#27979;&#19982;&#25968;&#25454;&#39044;&#20272;&#27010;&#29575;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#30456;&#23545;&#26631;&#20934;&#26657;&#20934;&#35823;&#24046;&#34920;&#31034;&#65292;&#20855;&#26377;&#35299;&#37322;&#28165;&#26224;&#12289;&#19968;&#33268;&#21051;&#24230;&#21644;&#22686;&#24378;&#35270;&#35273;&#34920;&#31034;&#31561;&#20248;&#28857;&#12290;</title><link>http://arxiv.org/abs/2306.14343</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#27979;&#35797;&#30340;&#26041;&#27861;&#26469;&#27979;&#37327;&#26657;&#20934;&#35823;&#24046;
&lt;/p&gt;
&lt;p&gt;
TCE: A Test-Based Approach to Measuring Calibration Error. (arXiv:2306.14343v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14343
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#22522;&#20110;&#27979;&#35797;&#30340;&#26657;&#20934;&#35823;&#24046; &#65288;TCE&#65289;&#25351;&#26631;&#65292;&#20351;&#29992;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#32479;&#35745;&#26816;&#39564;&#30340;&#25439;&#22833;&#20989;&#25968;&#26469;&#34913;&#37327;&#27169;&#22411;&#39044;&#27979;&#19982;&#25968;&#25454;&#39044;&#20272;&#27010;&#29575;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#30456;&#23545;&#26631;&#20934;&#26657;&#20934;&#35823;&#24046;&#34920;&#31034;&#65292;&#20855;&#26377;&#35299;&#37322;&#28165;&#26224;&#12289;&#19968;&#33268;&#21051;&#24230;&#21644;&#22686;&#24378;&#35270;&#35273;&#34920;&#31034;&#31561;&#20248;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#27979;&#37327;&#27010;&#29575;&#20108;&#20803;&#20998;&#31867;&#22120;&#30340;&#26657;&#20934;&#35823;&#24046;&#30340;&#26032;&#25351;&#26631;&#65292;&#31216;&#20026;&#22522;&#20110;&#27979;&#35797;&#30340;&#26657;&#20934;&#35823;&#24046; (TCE)&#12290;TCE&#37319;&#29992;&#19968;&#31181;&#22522;&#20110;&#32479;&#35745;&#27979;&#35797;&#30340;&#25439;&#22833;&#20989;&#25968;&#26469;&#26816;&#26597;&#27169;&#22411;&#39044;&#27979;&#19982;&#20174;&#25968;&#25454;&#20272;&#35745;&#30340;&#27010;&#29575;&#20043;&#38388;&#30340;&#24046;&#24322;&#31243;&#24230;&#12290;&#23427;&#25552;&#20379;&#20102;&#28165;&#26224;&#30340;&#35299;&#37322;&#12289;&#19968;&#20010;&#19981;&#21463;&#31867;&#21035;&#19981;&#24179;&#34913;&#24433;&#21709;&#30340;&#19968;&#33268;&#21051;&#24230;&#20197;&#21450;&#30456;&#23545;&#20110;&#26631;&#20934;&#21487;&#38752;&#24615;&#22270;&#30340;&#22686;&#24378;&#35270;&#35273;&#34920;&#31034;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#19968;&#20010;&#22522;&#20110;&#32463;&#39564;&#27010;&#29575;&#26368;&#23567;&#20272;&#35745;&#35823;&#24046;&#30340;&#26657;&#20934;&#35823;&#24046;&#20998;&#31665;&#31243;&#24207;&#30340;&#26368;&#20248;&#24615;&#20934;&#21017;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#30340;&#38024;&#23545;&#38480;&#21046;&#31665;&#23376;&#22823;&#23567;&#30340;&#26368;&#20248;&#31665;&#23376;&#30340;&#35745;&#31639;&#31639;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#22810;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#21644;ImageNet 1000&#31561;&#39564;&#35777;&#20102;TCE&#30340;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a new metric to measure the calibration error of probabilistic binary classifiers, called test-based calibration error (TCE). TCE incorporates a novel loss function based on a statistical test to examine the extent to which model predictions differ from probabilities estimated from data. It offers (i) a clear interpretation, (ii) a consistent scale that is unaffected by class imbalance, and (iii) an enhanced visual representation with repect to the standard reliability diagram. In addition, we introduce an optimality criterion for the binning procedure of calibration error metrics based on a minimal estimation error of the empirical probabilities. We provide a novel computational algorithm for optimal bins under bin-size constraints. We demonstrate properties of TCE through a range of experiments, including multiple real-world imbalanced datasets and ImageNet 1000.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20849;&#29983;&#23398;&#20064;&#30340;&#24322;&#26041;&#24046;&#22238;&#24402;&#30340;&#36817;&#20284;&#26368;&#20248;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#32479;&#35745;&#23398;&#12289;&#35745;&#37327;&#32463;&#27982;&#23398;&#12289;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#31561;&#39046;&#22495;&#65292;&#20197;&#21450;&#22312;&#19981;&#21516;&#26469;&#28304;&#25968;&#25454;&#36136;&#37327;&#19981;&#19968;&#30340;&#26426;&#22120;&#23398;&#20064;&#20013;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2306.14288</link><description>&lt;p&gt;
&#22522;&#20110;&#20849;&#29983;&#23398;&#20064;&#30340;&#24322;&#26041;&#24046;&#22238;&#24402;&#30340;&#36817;&#20284;&#26368;&#20248;&#31639;&#27861;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Near Optimal Heteroscedastic Regression with Symbiotic Learning. (arXiv:2306.14288v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14288
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20849;&#29983;&#23398;&#20064;&#30340;&#24322;&#26041;&#24046;&#22238;&#24402;&#30340;&#36817;&#20284;&#26368;&#20248;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#32479;&#35745;&#23398;&#12289;&#35745;&#37327;&#32463;&#27982;&#23398;&#12289;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#31561;&#39046;&#22495;&#65292;&#20197;&#21450;&#22312;&#19981;&#21516;&#26469;&#28304;&#25968;&#25454;&#36136;&#37327;&#19981;&#19968;&#30340;&#26426;&#22120;&#23398;&#20064;&#20013;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#32463;&#20856;&#30340;&#24322;&#26041;&#24046;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#23637;&#24320;&#35752;&#35770;&#12290;&#20551;&#35774;&#25105;&#20204;&#26377;n&#20010;&#26679;&#26412; $(\mathbf{x}_i, y_i) \in \mathbb{R}^d \times \mathbb{R}$&#65292;&#20854;&#20013; $y_i = \langle \mathbf{w}^{*}, \mathbf{x}_i \rangle + \epsilon_i \cdot \langle \mathbf{f}^{*}, \mathbf{x}_i \rangle$&#65292; $\mathbf{x}_i \sim N(0,\mathbf{I})$&#65292;$\epsilon_i \sim N(0,1)$&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#20272;&#35745; $\mathbf{w}^{*}$&#12290;&#22312;&#32479;&#35745;&#23398;&#12289;&#35745;&#37327;&#32463;&#27982;&#23398;&#12289;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#31561;&#39046;&#22495;&#65292;&#24322;&#26041;&#24046;&#27169;&#22411;&#20855;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#65292;&#21516;&#26102;&#65292;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#22914;&#26524;&#25968;&#25454;&#26469;&#28304;&#19981;&#21516;&#65292;&#32780;&#19981;&#21516;&#26469;&#28304;&#30340;&#25968;&#25454;&#36136;&#37327;&#20063;&#19981;&#19968;&#65292;&#21017;&#24322;&#26041;&#24046;&#27169;&#22411;&#20063;&#26174;&#24471;&#29305;&#21035;&#30456;&#20851;&#12290;&#26412;&#30740;&#31350;&#34920;&#26126;&#65292;&#25105;&#20204;&#21487;&#20197;&#20272;&#35745;&#20986;$\mathbf{w}^{*}$&#30340;&#24179;&#26041;&#33539;&#25968;&#65292;&#35823;&#24046;&#20026;$\tilde{O}\left(\|\mathbf{f}^{*}\|^2 \cdot \left(\frac{1}{n} + \left(\frac{d}{n}\right)^2\right)\right)$&#65292;&#24182;&#35777;&#26126;&#20102;&#19968;&#20010;&#21305;&#37197;&#30340;&#19979;&#38480;&#65288;&#19978;&#30028;&#23384;&#22312;&#23545;&#25968;&#22240;&#23376;&#65289;&#12290;&#26412;&#30740;&#31350;&#30340;&#32467;&#26524;&#26174;&#33879;&#25913;&#36827;&#20102;&#24322;&#26041;&#24046;&#22238;&#24402;&#38382;&#39064;&#30340;&#36817;&#20284;&#26368;&#20248;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the classical problem of heteroscedastic linear regression, where we are given $n$ samples $(\mathbf{x}_i, y_i) \in \mathbb{R}^d \times \mathbb{R}$ obtained from $y_i = \langle \mathbf{w}^{*}, \mathbf{x}_i \rangle + \epsilon_i \cdot \langle \mathbf{f}^{*}, \mathbf{x}_i \rangle$, where $\mathbf{x}_i \sim N(0,\mathbf{I})$, $\epsilon_i \sim N(0,1)$, and our task is to estimate $\mathbf{w}^{*}$. In addition to the classical applications of heteroscedastic models in fields such as statistics, econometrics, time series analysis etc., it is also particularly relevant in machine learning when data is collected from multiple sources of varying but apriori unknown quality, e.g., large model training. Our work shows that we can estimate $\mathbf{w}^{*}$ in squared norm up to an error of $\tilde{O}\left(\|\mathbf{f}^{*}\|^2 \cdot \left(\frac{1}{n} + \left(\frac{d}{n}\right)^2\right)\right)$ and prove a matching lower bound (up to logarithmic factors). Our result substantially improves 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22240;&#26524;&#20851;&#31995;&#35299;&#37322;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#35299;&#37322;&#20013;&#24341;&#20837;&#38750;&#34394;&#20551;&#24615;&#21644;&#25928;&#29575;&#65292;&#20174;&#22240;&#26524;&#25512;&#26029;&#30340;&#35282;&#24230;&#23450;&#20041;&#20102;&#22240;&#26524;&#27010;&#29575;&#65292;&#20174;&#32780;&#24314;&#31435;&#20102;&#24517;&#35201;&#21644;&#20805;&#20998;&#35299;&#37322;&#30340;&#20027;&#35201;&#32452;&#25104;&#37096;&#20998;&#65292;&#30456;&#27604;&#29616;&#26377;&#30340;&#22522;&#20110;&#20851;&#32852;&#30340;&#35299;&#37322;&#26041;&#27861;&#65292;&#36825;&#31181;&#26041;&#27861;&#26377;&#26356;&#21152;&#20248;&#36234;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2306.14115</link><description>&lt;p&gt;
&#26397;&#30528;&#21487;&#20449;&#30340;&#35299;&#37322;&#65306;&#22240;&#26524;&#20851;&#31995;&#35299;&#37322;&#35770;&#25991;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Towards Trustworthy Explanation: On Causal Rationalization. (arXiv:2306.14115v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14115
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22240;&#26524;&#20851;&#31995;&#35299;&#37322;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#35299;&#37322;&#20013;&#24341;&#20837;&#38750;&#34394;&#20551;&#24615;&#21644;&#25928;&#29575;&#65292;&#20174;&#22240;&#26524;&#25512;&#26029;&#30340;&#35282;&#24230;&#23450;&#20041;&#20102;&#22240;&#26524;&#27010;&#29575;&#65292;&#20174;&#32780;&#24314;&#31435;&#20102;&#24517;&#35201;&#21644;&#20805;&#20998;&#35299;&#37322;&#30340;&#20027;&#35201;&#32452;&#25104;&#37096;&#20998;&#65292;&#30456;&#27604;&#29616;&#26377;&#30340;&#22522;&#20110;&#20851;&#32852;&#30340;&#35299;&#37322;&#26041;&#27861;&#65292;&#36825;&#31181;&#26041;&#27861;&#26377;&#26356;&#21152;&#20248;&#36234;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#35299;&#37322;&#25104;&#20026;&#20102;&#36890;&#36807;&#36873;&#25321;&#36755;&#20837;&#25991;&#26412;&#30340;&#23376;&#38598;&#26469;&#35299;&#37322;&#40657;&#30418;&#27169;&#22411;&#20013;&#20027;&#35201;&#21464;&#21270;&#30340;&#19968;&#20010;&#22522;&#26412;&#30340;&#33258;&#25105;&#35299;&#37322;&#22270;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#22522;&#20110;&#20851;&#32852;&#30340;&#35299;&#37322;&#26041;&#27861;&#22312;&#20004;&#20010;&#25110;&#22810;&#20010;&#29255;&#27573;&#39640;&#24230;&#20114;&#30456;&#20851;&#32852;&#26102;&#26080;&#27861;&#35782;&#21035;&#30495;&#27491;&#30340;&#35299;&#37322;&#65292;&#22240;&#27492;&#23545;&#39044;&#27979;&#20934;&#30830;&#24615;&#25552;&#20379;&#31867;&#20284;&#30340;&#36129;&#29486;&#65292;&#25152;&#35859;&#30340;&#34394;&#20551;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#38480;&#21046;&#65292;&#25105;&#20204;&#20174;&#22240;&#26524;&#25512;&#26029;&#30340;&#35282;&#24230;&#26032;&#39062;&#22320;&#23558;&#20004;&#20010;&#22240;&#26524;&#26399;&#26395;&#20540;&#65288;&#38750;&#34394;&#20551;&#24615;&#21644;&#25928;&#29575;&#65289;&#24341;&#20837;&#20102;&#35299;&#37322;&#20013;&#12290;&#25105;&#20204;&#26681;&#25454;&#19968;&#31181;&#26032;&#25552;&#20986;&#30340;&#35299;&#37322;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#23450;&#20041;&#20102;&#19968;&#31995;&#21015;&#30340;&#22240;&#26524;&#27010;&#29575;&#65292;&#36890;&#36807;&#20854;&#29702;&#35770;&#37492;&#23450;&#65292;&#24314;&#31435;&#20102;&#24517;&#35201;&#21644;&#20805;&#20998;&#35299;&#37322;&#30340;&#20027;&#35201;&#32452;&#25104;&#37096;&#20998;&#12290;&#25105;&#20204;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#35780;&#35770;&#21644;&#21307;&#30103;&#25968;&#25454;&#38598;&#19978;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#22240;&#26524;&#20851;&#31995;&#35299;&#37322;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
With recent advances in natural language processing, rationalization becomes an essential self-explaining diagram to disentangle the black box by selecting a subset of input texts to account for the major variation in prediction. Yet, existing association-based approaches on rationalization cannot identify true rationales when two or more snippets are highly inter-correlated and thus provide a similar contribution to prediction accuracy, so-called spuriousness. To address this limitation, we novelly leverage two causal desiderata, non-spuriousness and efficiency, into rationalization from the causal inference perspective. We formally define a series of probabilities of causation based on a newly proposed structural causal model of rationalization, with its theoretical identification established as the main component of learning necessary and sufficient rationales. The superior performance of the proposed causal rationalization is demonstrated on real-world review and medical datasets w
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#23545;&#20110;&#24191;&#27867;&#30340;&#20559;&#22909;&#27169;&#22411;&#65292;&#25105;&#20204;&#21487;&#20197;&#20351;&#29992;&#29616;&#26377;&#30340;&#31639;&#27861;&#21644;&#25216;&#26415;&#30452;&#25509;&#35299;&#20915;&#22522;&#20110;&#20559;&#22909;&#30340;RL&#38382;&#39064;&#65292;&#32780;&#20960;&#20046;&#19981;&#38656;&#35201;&#39069;&#22806;&#30340;&#25104;&#26412;&#12290;</title><link>http://arxiv.org/abs/2306.14111</link><description>&lt;p&gt;
RLHF&#26159;&#21542;&#27604;&#26631;&#20934;RL&#26356;&#22256;&#38590;&#65311;
&lt;/p&gt;
&lt;p&gt;
Is RLHF More Difficult than Standard RL?. (arXiv:2306.14111v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14111
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#23545;&#20110;&#24191;&#27867;&#30340;&#20559;&#22909;&#27169;&#22411;&#65292;&#25105;&#20204;&#21487;&#20197;&#20351;&#29992;&#29616;&#26377;&#30340;&#31639;&#27861;&#21644;&#25216;&#26415;&#30452;&#25509;&#35299;&#20915;&#22522;&#20110;&#20559;&#22909;&#30340;RL&#38382;&#39064;&#65292;&#32780;&#20960;&#20046;&#19981;&#38656;&#35201;&#39069;&#22806;&#30340;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#20154;&#31867;&#21453;&#39304;&#23398;&#20064;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288;RLHF&#65289;&#26159;&#20174;&#20559;&#22909;&#20449;&#21495;&#23398;&#20064;&#65292;&#32780;&#26631;&#20934;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#21017;&#30452;&#25509;&#20174;&#22870;&#21169;&#20449;&#21495;&#23398;&#20064;&#12290;&#20559;&#22909;&#20449;&#21495;&#21487;&#33021;&#21253;&#21547;&#30340;&#20449;&#24687;&#27604;&#22870;&#21169;&#20449;&#21495;&#23569;&#65292;&#36825;&#20351;&#24471;&#22522;&#20110;&#20559;&#22909;&#30340;RL&#20284;&#20046;&#26356;&#21152;&#22256;&#38590;&#12290;&#26412;&#25991;&#29702;&#35770;&#19978;&#35777;&#26126;&#65292;&#23545;&#20110;&#24191;&#27867;&#30340;&#20559;&#22909;&#27169;&#22411;&#65292;&#25105;&#20204;&#21487;&#20197;&#20351;&#29992;&#29616;&#26377;&#30340;&#31639;&#27861;&#21644;&#25216;&#26415;&#30452;&#25509;&#35299;&#20915;&#22522;&#20110;&#20559;&#22909;&#30340;RL&#38382;&#39064;&#65292;&#32780;&#20960;&#20046;&#19981;&#38656;&#35201;&#39069;&#22806;&#30340;&#25104;&#26412;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23558;&#38382;&#39064;&#20998;&#20026;&#20004;&#31867;&#65306;&#65288;1&#65289;&#22522;&#20110;&#22870;&#21169;&#27010;&#29575;&#27169;&#22411;&#30340;&#20559;&#22909;&#65292;&#27492;&#26102;&#21487;&#20197;&#23558;&#38382;&#39064;&#31616;&#21270;&#20026;&#23481;&#24525;&#22870;&#21169;&#23567;&#35823;&#24046;&#30340;&#40065;&#26834;&#22870;&#21169;RL&#38382;&#39064;&#65307;&#65288;2&#65289;&#23545;&#20110;&#19968;&#33324;&#30340;&#20219;&#24847;&#20559;&#22909;&#19988;&#30446;&#26631;&#26159;&#25214;&#21040;von Neumann&#33719;&#32988;&#32773;&#30340;&#24773;&#20917;&#65292;&#25105;&#20204;&#23558;&#38382;&#39064;&#31616;&#21270;&#20026;&#22810;&#26234;&#33021;&#20307;&#22870;&#21169;RL&#38382;&#39064;&#65292;&#35813;&#38382;&#39064;&#21487;&#20197;&#22312;&#19968;&#32452;&#21463;&#38480;&#21046;&#30340;&#31574;&#30053;&#19979;&#25214;&#21040;&#39532;&#23572;&#21487;&#22827;&#21338;&#24328;&#30340;&#22240;&#23376;&#32435;&#20160;&#24179;&#34913;&#35299;&#12290;&#21518;&#19968;&#31181;&#24773;&#20917;&#21487;&#20197;&#36827;&#19968;&#27493;&#38477;&#20302;&#25104;&#23545;&#20851;&#31995;&#30340;MDP&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement learning from Human Feedback (RLHF) learns from preference signals, while standard Reinforcement Learning (RL) directly learns from reward signals. Preferences arguably contain less information than rewards, which makes preference-based RL seemingly more difficult. This paper theoretically proves that, for a wide range of preference models, we can solve preference-based RL directly using existing algorithms and techniques for reward-based RL, with small or no extra costs. Specifically, (1) for preferences that are drawn from reward-based probabilistic models, we reduce the problem to robust reward-based RL that can tolerate small errors in rewards; (2) for general arbitrary preferences where the objective is to find the von Neumann winner, we reduce the problem to multiagent reward-based RL which finds Nash equilibria for factored Markov games under a restricted set of policies. The latter case can be further reduce to adversarial MDP when preferences only depend on the f
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#19968;&#20010;&#26080;&#32447;&#31995;&#32479;&#20013;&#65292;&#32771;&#34385;&#21040;&#20449;&#24687;&#35770;&#38544;&#31169;&#30340;&#26465;&#20214;&#19979;&#65292;&#36890;&#36807;&#22522;&#31449;&#36830;&#25509;&#21040;&#32852;&#21512;&#22120;&#30340;&#23458;&#25143;&#31471;&#65292;&#22914;&#20309;&#35299;&#20915;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#38544;&#31169;&#25968;&#25454;&#32858;&#21512;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.14088</link><description>&lt;p&gt;
&#38750;&#21516;&#36136;&#21270;&#38598;&#32676;&#19979;&#30340;&#26080;&#32447;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#31169;&#26377;&#25968;&#25454;&#32858;&#21512;
&lt;/p&gt;
&lt;p&gt;
Private Aggregation in Wireless Federated Learning with Heterogeneous Clusters. (arXiv:2306.14088v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14088
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#19968;&#20010;&#26080;&#32447;&#31995;&#32479;&#20013;&#65292;&#32771;&#34385;&#21040;&#20449;&#24687;&#35770;&#38544;&#31169;&#30340;&#26465;&#20214;&#19979;&#65292;&#36890;&#36807;&#22522;&#31449;&#36830;&#25509;&#21040;&#32852;&#21512;&#22120;&#30340;&#23458;&#25143;&#31471;&#65292;&#22914;&#20309;&#35299;&#20915;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#38544;&#31169;&#25968;&#25454;&#32858;&#21512;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#26159;&#36890;&#36807;&#22810;&#20010;&#21442;&#19982;&#23458;&#25143;&#31471;&#31169;&#26377;&#25968;&#25454;&#30340;&#21327;&#21516;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#12290;&#22312;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#30340;&#36807;&#31243;&#20013;&#65292;&#20351;&#29992;&#19968;&#31181;&#33879;&#21517;&#24182;&#24191;&#27867;&#20351;&#29992;&#30340;&#36845;&#20195;&#20248;&#21270;&#31639;&#27861;&#8212;&#8212;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#12290;&#27599;&#20010;&#23458;&#25143;&#31471;&#20351;&#29992;&#26412;&#22320;&#25968;&#25454;&#35745;&#31639;&#23616;&#37096;&#26799;&#24230;&#24182;&#23558;&#20854;&#21457;&#36865;&#32473;&#32852;&#21512;&#22120;&#20197;&#36827;&#34892;&#32858;&#21512;&#12290;&#23458;&#25143;&#31471;&#25968;&#25454;&#30340;&#38544;&#31169;&#26159;&#19968;&#20010;&#20027;&#35201;&#38382;&#39064;&#12290;&#23454;&#38469;&#19978;&#65292;&#35266;&#23519;&#21040;&#23616;&#37096;&#26799;&#24230;&#23601;&#36275;&#20197;&#27844;&#38706;&#23458;&#25143;&#31471;&#30340;&#25968;&#25454;&#12290;&#24050;&#30740;&#31350;&#20102;&#29992;&#20110;&#24212;&#23545;&#32852;&#37030;&#23398;&#20064;&#20013;&#38544;&#31169;&#38382;&#39064;&#30340;&#31169;&#26377;&#32858;&#21512;&#26041;&#26696;&#65292;&#20854;&#20013;&#25152;&#26377;&#29992;&#25143;&#37117;&#24444;&#27492;&#36830;&#25509;&#24182;&#19982;&#32852;&#21512;&#22120;&#36830;&#25509;&#12290;&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#20010;&#26080;&#32447;&#31995;&#32479;&#26550;&#26500;&#65292;&#20854;&#20013;&#23458;&#25143;&#31471;&#20165;&#36890;&#36807;&#22522;&#31449;&#36830;&#25509;&#21040;&#32852;&#21512;&#22120;&#12290;&#24403;&#38656;&#35201;&#20449;&#24687;&#35770;&#38544;&#31169;&#26102;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#36890;&#20449;&#25104;&#26412;&#30340;&#22522;&#26412;&#26497;&#38480;&#65292;&#24182;&#24341;&#20837;&#21644;&#20998;&#26512;&#20102;&#19968;&#31181;&#38024;&#23545;&#36825;&#31181;&#24773;&#20917;&#37327;&#36523;&#23450;&#21046;&#30340;&#31169;&#26377;&#32858;&#21512;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated learning collaboratively trains a neural network on privately owned data held by several participating clients. The gradient descent algorithm, a well-known and popular iterative optimization procedure, is run to train the neural network. Every client uses its local data to compute partial gradients and sends it to the federator which aggregates the results. Privacy of the clients' data is a major concern. In fact, observing the partial gradients can be enough to reveal the clients' data. Private aggregation schemes have been investigated to tackle the privacy problem in federated learning where all the users are connected to each other and to the federator. In this paper, we consider a wireless system architecture where clients are only connected to the federator via base stations. We derive fundamental limits on the communication cost when information-theoretic privacy is required, and introduce and analyze a private aggregation scheme tailored for this setting.
&lt;/p&gt;</description></item><item><title>&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#22312;&#23454;&#29616;&#32479;&#35745;&#20445;&#35777;&#30028;&#38480;&#26102;&#23384;&#22312;&#38480;&#21046;&#21644;&#20445;&#23432;&#24615;&#38382;&#39064;&#65292;&#20294;&#24179;&#28369;&#30340;$f$-&#25955;&#24230;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#21487;&#22312;&#25351;&#25968;&#34928;&#20943;&#29575;&#26041;&#38754;&#23454;&#29616;&#26368;&#32039;&#23494;&#30340;&#32479;&#35745;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2306.14041</link><description>&lt;p&gt;
&#24179;&#28369;&#30340;$f$-&#25955;&#24230;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#65306;&#25351;&#25968;&#29575;&#25928;&#29575;&#21644;&#19981;&#24102;&#22797;&#26434;&#24615;&#30340;&#26657;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;
Smoothed $f$-Divergence Distributionally Robust Optimization: Exponential Rate Efficiency and Complexity-Free Calibration. (arXiv:2306.14041v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14041
&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#22312;&#23454;&#29616;&#32479;&#35745;&#20445;&#35777;&#30028;&#38480;&#26102;&#23384;&#22312;&#38480;&#21046;&#21644;&#20445;&#23432;&#24615;&#38382;&#39064;&#65292;&#20294;&#24179;&#28369;&#30340;$f$-&#25955;&#24230;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#21487;&#22312;&#25351;&#25968;&#34928;&#20943;&#29575;&#26041;&#38754;&#23454;&#29616;&#26368;&#32039;&#23494;&#30340;&#32479;&#35745;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25968;&#25454;&#39537;&#21160;&#30340;&#20248;&#21270;&#20013;&#65292;&#26679;&#26412;&#24179;&#22343;&#36924;&#36817;&#24050;&#30693;&#23384;&#22312;&#19968;&#20010;&#25152;&#35859;&#30340;&#20248;&#21270;&#32773;&#35781;&#21650;&#65292;&#20250;&#23548;&#33268;&#22312;&#35780;&#20272;&#35299;&#20915;&#26041;&#26696;&#24615;&#33021;&#26102;&#20135;&#29983;&#20048;&#35266;&#20559;&#24046;&#12290;&#21487;&#20197;&#36890;&#36807;&#22312;&#20272;&#35745;&#30340;&#30446;&#26631;&#20540;&#20013;&#22686;&#21152;&#8220;&#20445;&#35777;&#31354;&#38388;&#8221;&#25110;&#36890;&#36807;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#65288;DRO&#65289;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#21518;&#32773;&#26159;&#19968;&#31181;&#24555;&#36895;&#22686;&#38271;&#30340;&#26041;&#27861;&#65292;&#22522;&#20110;&#26368;&#22351;&#24773;&#20917;&#20998;&#26512;&#65292;&#20026;&#33719;&#24471;&#30340;&#30446;&#26631;&#20215;&#20540;&#25552;&#20379;&#20102;&#20445;&#25252;&#30028;&#38480;&#12290;&#28982;&#32780;&#65292;&#22312;&#25152;&#26377;&#36825;&#20123;&#29616;&#26377;&#26041;&#27861;&#20013;&#65292;&#23545;&#30495;&#23454;&#35299;&#20915;&#26041;&#26696;&#24615;&#33021;&#30340;&#32479;&#35745;&#20445;&#35777;&#30028;&#38480;&#35201;&#20040;&#38656;&#35201;&#23545;&#30446;&#26631;&#20989;&#25968;&#22797;&#26434;&#24615;&#26377;&#38480;&#21046;&#24615;&#26465;&#20214;&#21644;&#30693;&#35782;&#65292;&#35201;&#20040;&#20250;&#34920;&#29616;&#20986;&#21462;&#20915;&#20110;&#20998;&#24067;&#32500;&#24230;&#30340;&#36807;&#20110;&#20445;&#23432;&#30340;&#36895;&#29575;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#22312;&#36825;&#20123;&#25361;&#25112;&#26041;&#38754;&#65292;&#19968;&#31181;&#29305;&#27530;&#31867;&#22411;&#30340;DRO&#22312;&#29702;&#35770;&#19978;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#20248;&#21183;&#65306;&#23545;&#20110;&#19968;&#22823;&#31867;&#30446;&#26631;&#20989;&#25968;&#65292;&#23427;&#33719;&#24471;&#20102;&#23545;&#30495;&#23454;&#35299;&#30340;&#35299;&#20915;&#26041;&#26696;&#24615;&#33021;&#30340;&#32479;&#35745;&#30028;&#38480;&#65292;&#36825;&#22312;&#25351;&#25968;&#34928;&#20943;&#29575;&#26041;&#38754;&#26159;&#21487;&#33021;&#30340;&#65292;&#23601;&#20854;&#32039;&#32553;&#31243;&#24230;&#32780;&#35328;&#65292;&#35201;&#32039;&#23494;&#24471;&#22810;&#12290;
&lt;/p&gt;
&lt;p&gt;
In data-driven optimization, sample average approximation is known to suffer from the so-called optimizer's curse that causes optimistic bias in evaluating the solution performance. This can be tackled by adding a "margin" to the estimated objective value, or via distributionally robust optimization (DRO), a fast-growing approach based on worst-case analysis, which gives a protective bound on the attained objective value. However, in all these existing approaches, a statistically guaranteed bound on the true solution performance either requires restrictive conditions and knowledge on the objective function complexity, or otherwise exhibits an over-conservative rate that depends on the distribution dimension. We argue that a special type of DRO offers strong theoretical advantages in regard to these challenges: It attains a statistical bound on the true solution performance that is the tightest possible in terms of exponential decay rate, for a wide class of objective functions that not
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#38750;&#24179;&#28369;&#20248;&#21270;&#38382;&#39064;&#30340;&#23436;&#20840;&#20998;&#24067;&#24335;&#30340;&#24046;&#20998;&#38544;&#31169;&#23398;&#20064;&#31639;&#27861;&#65292;&#20445;&#35777;&#38646;&#38598;&#20013;&#24230;&#24046;&#20998;&#38544;&#31169;&#65292;&#20855;&#26377;&#26356;&#22909;&#30340;&#20934;&#30830;&#24615;&#21644;&#26356;&#24378;&#30340;&#20445;&#35777;&#65292;&#24182;&#19988;&#22788;&#29702;&#38750;&#24179;&#28369;&#21644;&#38750;&#24517;&#39035;&#24378;&#20984;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.14012</link><description>&lt;p&gt;
&#29992;&#20110;&#38750;&#24179;&#28369;&#30446;&#26631;&#20989;&#25968;&#30340;&#38646;&#38598;&#20013;&#24230;&#31169;&#26377;&#20998;&#24067;&#24335;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Zero-Concentrated Private Distributed Learning for Nonsmooth Objective Functions. (arXiv:2306.14012v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14012
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#38750;&#24179;&#28369;&#20248;&#21270;&#38382;&#39064;&#30340;&#23436;&#20840;&#20998;&#24067;&#24335;&#30340;&#24046;&#20998;&#38544;&#31169;&#23398;&#20064;&#31639;&#27861;&#65292;&#20445;&#35777;&#38646;&#38598;&#20013;&#24230;&#24046;&#20998;&#38544;&#31169;&#65292;&#20855;&#26377;&#26356;&#22909;&#30340;&#20934;&#30830;&#24615;&#21644;&#26356;&#24378;&#30340;&#20445;&#35777;&#65292;&#24182;&#19988;&#22788;&#29702;&#38750;&#24179;&#28369;&#21644;&#38750;&#24517;&#39035;&#24378;&#20984;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#23436;&#20840;&#20998;&#24067;&#24335;&#30340;&#24046;&#20998;&#38544;&#31169;&#23398;&#20064;&#31639;&#27861;&#26469;&#35299;&#20915;&#38750;&#24179;&#28369;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#23558;&#20132;&#26367;&#26041;&#21521;&#20056;&#23376;&#27861;&#65288;ADMM&#65289;&#20998;&#24067;&#21040;&#20998;&#24067;&#24335;&#35774;&#32622;&#20013;&#65292;&#24182;&#37319;&#29992;&#22686;&#24191;&#25289;&#26684;&#26391;&#26085;&#36817;&#20284;&#26469;&#22788;&#29702;&#38750;&#24179;&#28369;&#30446;&#26631;&#20989;&#25968;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#22312;&#27599;&#20010;&#20195;&#29702;&#22788;&#29992;&#26041;&#24046;&#36882;&#20943;&#30340;&#39640;&#26031;&#22122;&#22768;&#25200;&#21160;&#35745;&#31639;&#32467;&#26524;&#26469;&#30830;&#20445;&#38646;&#38598;&#20013;&#24046;&#20998;&#38544;&#31169;&#65288;zCDP&#65289;&#12290;&#36825;&#31181;&#38544;&#31169;&#20445;&#25252;&#26041;&#27861;&#20801;&#35768;&#27604;&#20256;&#32479;&#30340;$(\epsilon&#65292;\delta)$-DP&#26356;&#22909;&#30340;&#20934;&#30830;&#24615;&#65292;&#27604;&#26368;&#36817;&#30340;R&#233;nyi-DP&#25552;&#20379;&#26356;&#24378;&#30340;&#20445;&#35777;&#12290;&#24320;&#21457;&#30340;&#23436;&#20840;&#20998;&#24067;&#24335;&#31639;&#27861;&#20855;&#26377;&#31454;&#20105;&#24615;&#30340;&#38544;&#31169;&#20934;&#30830;&#24615;&#24179;&#34913;&#65292;&#24182;&#22788;&#29702;&#38750;&#24179;&#28369;&#21644;&#38750;&#24517;&#39035;&#24378;&#20984;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#38544;&#31169;&#20445;&#35777;&#21644;&#31639;&#27861;&#25910;&#25947;&#21040;&#31934;&#30830;&#35299;&#30340;&#23436;&#25972;&#29702;&#35770;&#35777;&#26126;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#65292;&#22312;&#20854;&#20182;&#20551;&#35774;&#19979;&#65292;&#35813;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#27604;&#38598;&#20013;&#24335;&#38750;&#31169;&#26377;&#31639;&#27861;&#26356;&#24555;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper develops a fully distributed differentially-private learning algorithm to solve nonsmooth optimization problems. We distribute the Alternating Direction Method of Multipliers (ADMM) to comply with the distributed setting and employ an approximation of the augmented Lagrangian to handle nonsmooth objective functions. Furthermore, we ensure zero-concentrated differential privacy (zCDP) by perturbing the outcome of the computation at each agent with a variance-decreasing Gaussian noise. This privacy-preserving method allows for better accuracy than the conventional $(\epsilon, \delta)$-DP and stronger guarantees than the more recent R\'enyi-DP. The developed fully distributed algorithm has a competitive privacy accuracy trade-off and handles nonsmooth and non-necessarily strongly convex problems. We provide complete theoretical proof for the privacy guarantees and the convergence of the algorithm to the exact solution. We also prove under additional assumptions that the algorit
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;&#26426;&#22120;&#23398;&#20064;&#29992;&#20110;&#26144;&#23556;&#33258;&#30001;&#33021;&#25200;&#21160;&#20013;&#30340;Boltzmann&#20998;&#24067;&#65292;&#20197;&#27714;&#24471;Deca-Alanine&#20998;&#23376;&#30340;&#33258;&#30001;&#33021;&#24046;&#24322;&#12290;&#24403;&#24377;&#31783;&#20013;&#24515;&#30456;&#38548;&#36739;&#36817;&#26102;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#24471;&#21040;&#20934;&#30830;&#30340;&#32467;&#26524;&#65292;&#20294;&#24403;&#24377;&#31783;&#20013;&#24515;&#30456;&#38548;&#36739;&#36828;&#26102;&#65292;&#35813;&#26041;&#27861;&#26080;&#27861;&#24471;&#21040;&#20195;&#34920;&#30446;&#26631;&#29366;&#24577;&#30340;&#32467;&#26500;&#21644;&#27491;&#30830;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.14010</link><description>&lt;p&gt;
&#23398;&#20064;&#26144;&#23556;&#29992;&#20110;&#32957;&#26500;&#35937;&#38388;&#30340;&#26377;&#38024;&#23545;&#24615;&#33258;&#30001;&#33021;&#25200;&#21160;
&lt;/p&gt;
&lt;p&gt;
Learned Mappings for Targeted Free Energy Perturbation between Peptide Conformations. (arXiv:2306.14010v1 [cond-mat.stat-mech])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14010
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;&#26426;&#22120;&#23398;&#20064;&#29992;&#20110;&#26144;&#23556;&#33258;&#30001;&#33021;&#25200;&#21160;&#20013;&#30340;Boltzmann&#20998;&#24067;&#65292;&#20197;&#27714;&#24471;Deca-Alanine&#20998;&#23376;&#30340;&#33258;&#30001;&#33021;&#24046;&#24322;&#12290;&#24403;&#24377;&#31783;&#20013;&#24515;&#30456;&#38548;&#36739;&#36817;&#26102;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#24471;&#21040;&#20934;&#30830;&#30340;&#32467;&#26524;&#65292;&#20294;&#24403;&#24377;&#31783;&#20013;&#24515;&#30456;&#38548;&#36739;&#36828;&#26102;&#65292;&#35813;&#26041;&#27861;&#26080;&#27861;&#24471;&#21040;&#20195;&#34920;&#30446;&#26631;&#29366;&#24577;&#30340;&#32467;&#26500;&#21644;&#27491;&#30830;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26377;&#38024;&#23545;&#24615;&#33258;&#30001;&#33021;&#25200;&#21160;&#21033;&#29992;&#21487;&#36870;&#26144;&#23556;&#26469;&#20419;&#36827;&#26500;&#35937;&#31354;&#38388;&#30340;&#37325;&#21472;&#21644;&#33258;&#30001;&#33021;&#20272;&#35745;&#30340;&#25910;&#25947;&#12290;&#28982;&#32780;&#65292;&#24320;&#21457;&#21512;&#36866;&#30340;&#26144;&#23556;&#21487;&#33021;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;Wirnsberger&#31561;&#20154;&#65288;2020&#65289;&#23637;&#31034;&#20102;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#26469;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#23558;&#19981;&#21516;&#28909;&#21147;&#23398;&#29366;&#24577;&#30340;Boltzmann&#20998;&#24067;&#20043;&#38388;&#36827;&#34892;&#26144;&#23556;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#20182;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#21040;&#20855;&#26377;&#19981;&#21516;&#24377;&#31783;&#20013;&#24515;&#30340;&#24377;&#24615;&#38190;&#21512;&#20998;&#23376;Deca-Alanine&#30340;&#33258;&#30001;&#33021;&#24046;&#24322;&#19978;&#12290;&#24403;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#21040;&#8220;&#25552;&#21069;&#20572;&#27490;&#8221;-&#21363;&#27979;&#35797;&#38598;&#30340;&#25439;&#22833;&#20540;&#22686;&#21152;&#26102;-&#25105;&#20204;&#21487;&#20197;&#35745;&#31639;&#20986;&#24377;&#31783;&#20013;&#24515;&#30456;&#38548;1&#197;&#21644;&#26377;&#26102;2&#197;&#30340;&#28909;&#21147;&#23398;&#29366;&#24577;&#20043;&#38388;&#30340;&#20934;&#30830;&#33258;&#30001;&#33021;&#24046;&#24322;&#12290;&#23545;&#20110;&#26356;&#36828;&#30340;&#28909;&#21147;&#23398;&#29366;&#24577;&#65292;&#35813;&#26144;&#23556;&#19981;&#20250;&#20135;&#29983;&#20195;&#34920;&#30446;&#26631;&#29366;&#24577;&#30340;&#32467;&#26500;&#65292;&#35813;&#26041;&#27861;&#20063;&#26080;&#27861;&#22797;&#29616;&#21442;&#32771;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;
Targeted free energy perturbation uses an invertible mapping to promote configuration space overlap and the convergence of free energy estimates. However, developing suitable mappings can be challenging. Wirnsberger et al. (2020) demonstrated the use of machine learning to train deep neural networks that map between Boltzmann distributions for different thermodynamic states. Here, we adapt their approach to free energy differences of a flexible bonded molecule, deca-alanine, with harmonic biases with different spring centers. When the neural network is trained until ``early stopping'' - when the loss value of the test set increases - we calculate accurate free energy differences between thermodynamic states with spring centers separated by 1 \r{A} and sometimes 2 \r{A}. For more distant thermodynamic states, the mapping does not produce structures representative of the target state and the method does not reproduce reference calculations.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39640;&#32500;&#20302;&#26679;&#26412;&#37327;&#25968;&#25454;&#20998;&#31867;&#30340;&#31283;&#20581;&#30340;&#25968;&#25454;&#33258;&#36866;&#24212;&#33021;&#37327;&#36317;&#31163;&#20998;&#31867;&#22120;&#65292;&#35813;&#20998;&#31867;&#22120;&#26080;&#38656;&#35843;&#21442;&#19988;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#21487;&#20197;&#23454;&#29616;&#23436;&#32654;&#20998;&#31867;&#65292;&#24050;&#22312;&#27169;&#25311;&#30740;&#31350;&#21644;&#23454;&#38469;&#25968;&#25454;&#20998;&#26512;&#20013;&#24471;&#21040;&#35777;&#26126;&#27604;&#20854;&#20182;&#26041;&#27861;&#34920;&#29616;&#26356;&#20248;&#12290;</title><link>http://arxiv.org/abs/2306.13985</link><description>&lt;p&gt;
&#20351;&#29992;&#25968;&#25454;&#33258;&#36866;&#24212;&#33021;&#37327;&#36317;&#31163;&#30340;&#39640;&#32500;&#25968;&#25454;&#31283;&#20581;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Robust Classification of High-Dimensional Data using Data-Adaptive Energy Distance. (arXiv:2306.13985v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13985
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39640;&#32500;&#20302;&#26679;&#26412;&#37327;&#25968;&#25454;&#20998;&#31867;&#30340;&#31283;&#20581;&#30340;&#25968;&#25454;&#33258;&#36866;&#24212;&#33021;&#37327;&#36317;&#31163;&#20998;&#31867;&#22120;&#65292;&#35813;&#20998;&#31867;&#22120;&#26080;&#38656;&#35843;&#21442;&#19988;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#21487;&#20197;&#23454;&#29616;&#23436;&#32654;&#20998;&#31867;&#65292;&#24050;&#22312;&#27169;&#25311;&#30740;&#31350;&#21644;&#23454;&#38469;&#25968;&#25454;&#20998;&#26512;&#20013;&#24471;&#21040;&#35777;&#26126;&#27604;&#20854;&#20182;&#26041;&#27861;&#34920;&#29616;&#26356;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#30495;&#23454;&#19990;&#30028;&#20013;&#65292;&#39640;&#32500;&#20302;&#26679;&#26412;&#37327;&#65288;HDLSS&#65289;&#25968;&#25454;&#30340;&#20998;&#31867;&#38754;&#20020;&#25361;&#25112;&#65292;&#20363;&#22914;&#22522;&#22240;&#34920;&#36798;&#30740;&#31350;&#12289;&#30284;&#30151;&#30740;&#31350;&#21644;&#21307;&#23398;&#25104;&#20687;&#31561;&#39046;&#22495;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20123;&#19987;&#38376;&#20026;HDLSS&#25968;&#25454;&#35774;&#35745;&#30340;&#20998;&#31867;&#22120;&#30340;&#24320;&#21457;&#21644;&#20998;&#26512;&#12290;&#36825;&#20123;&#20998;&#31867;&#22120;&#27809;&#26377;&#35843;&#33410;&#21442;&#25968;&#65292;&#24182;&#19988;&#26159;&#31283;&#20581;&#30340;&#65292;&#22240;&#20026;&#23427;&#20204;&#19981;&#21463;&#24213;&#23618;&#25968;&#25454;&#20998;&#24067;&#30340;&#20219;&#20309;&#30697;&#26465;&#20214;&#30340;&#24433;&#21709;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#19968;&#20123;&#30456;&#24403;&#26222;&#36941;&#30340;&#26465;&#20214;&#19979;&#65292;&#23427;&#20204;&#22312;HDLSS&#28176;&#36817;&#21306;&#22495;&#20869;&#21487;&#20197;&#23454;&#29616;&#23436;&#32654;&#20998;&#31867;&#12290;&#36824;&#27604;&#36739;&#20102;&#25152;&#25552;&#20986;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#24471;&#21040;&#20102;&#24191;&#27867;&#30340;&#27169;&#25311;&#30740;&#31350;&#21644;&#23454;&#38469;&#25968;&#25454;&#20998;&#26512;&#30340;&#25903;&#25345;&#65292;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#20998;&#31867;&#25216;&#26415;&#20248;&#20110;&#20960;&#31181;&#24191;&#27867;&#35748;&#21487;&#30340;&#26041;&#27861;&#30340;&#26377;&#24076;&#26395;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Classification of high-dimensional low sample size (HDLSS) data poses a challenge in a variety of real-world situations, such as gene expression studies, cancer research, and medical imaging. This article presents the development and analysis of some classifiers that are specifically designed for HDLSS data. These classifiers are free of tuning parameters and are robust, in the sense that they are devoid of any moment conditions of the underlying data distributions. It is shown that they yield perfect classification in the HDLSS asymptotic regime, under some fairly general conditions. The comparative performance of the proposed classifiers is also investigated. Our theoretical results are supported by extensive simulation studies and real data analysis, which demonstrate promising advantages of the proposed classification techniques over several widely recognized methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#35268;&#21017;&#21270;MFPCA&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#24179;&#28369;&#21644;&#22686;&#24378;&#22810;&#20803;&#20989;&#25968;PC&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#20026;&#20998;&#26512;&#21644;&#21457;&#29616;&#22797;&#26434;&#30340;&#22810;&#20803;&#20989;&#25968;&#25968;&#25454;&#20013;&#30340;&#20851;&#31995;&#24320;&#36767;&#20102;&#26032;&#30340;&#36884;&#24452;&#12290;</title><link>http://arxiv.org/abs/2306.13980</link><description>&lt;p&gt;
&#35268;&#21017;&#21270;&#30340;&#22810;&#20803;&#20989;&#25968;&#20027;&#25104;&#20998;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Regularized Multivariate Functional Principal Component Analysis. (arXiv:2306.13980v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13980
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#35268;&#21017;&#21270;MFPCA&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#24179;&#28369;&#21644;&#22686;&#24378;&#22810;&#20803;&#20989;&#25968;PC&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#20026;&#20998;&#26512;&#21644;&#21457;&#29616;&#22797;&#26434;&#30340;&#22810;&#20803;&#20989;&#25968;&#25968;&#25454;&#20013;&#30340;&#20851;&#31995;&#24320;&#36767;&#20102;&#26032;&#30340;&#36884;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20803;&#20989;&#25968;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;MFPCA&#65289;&#26159;&#25506;&#32034;&#22810;&#20803;&#20989;&#25968;&#25968;&#25454;&#20851;&#31995;&#21644;&#35782;&#21035;&#20849;&#20139;&#21464;&#21270;&#27169;&#24335;&#30340;&#26377;&#20215;&#20540;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#25511;&#21046;&#25552;&#21462;&#30340;&#20027;&#25104;&#20998;&#30340;&#24179;&#28369;&#24230;&#21487;&#33021;&#20250;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#31216;&#20026;&#35268;&#21017;&#21270;MFPCA&#65288;ReMFPCA&#65289;&#30340;&#26032;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#24182;&#22686;&#24378;&#22810;&#20803;&#20989;&#25968;PC&#30340;&#24179;&#28369;&#24230;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;ReMFPCA&#22312;&#24809;&#32602;&#26694;&#26550;&#20869;&#20351;&#29992;&#21442;&#25968;&#21521;&#37327;&#26469;&#35843;&#33410;&#27599;&#20010;&#20989;&#25968;&#21464;&#37327;&#30340;&#24179;&#28369;&#24230;&#65292;&#20869;&#21547;&#19968;&#20010;&#31895;&#31961;&#24230;&#24809;&#32602;&#39033;&#12290;&#35813;&#26041;&#27861;&#29983;&#25104;&#24179;&#28369;&#30340;&#22810;&#20803;&#20989;&#25968;PC&#65292;&#25552;&#20379;&#20102;&#25968;&#25454;&#30340;&#31616;&#26126;&#21644;&#21487;&#35299;&#37322;&#30340;&#34920;&#31034;&#12290;&#24191;&#27867;&#30340;&#27169;&#25311;&#21644;&#23454;&#38469;&#25968;&#25454;&#31034;&#20363;&#35777;&#26126;&#20102;ReMFPCA&#30340;&#26377;&#25928;&#24615;&#21644;&#20248;&#36234;&#24615;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20026;&#20998;&#26512;&#21644;&#21457;&#29616;&#22797;&#26434;&#30340;&#22810;&#20803;&#20989;&#25968;&#25968;&#25454;&#20013;&#30340;&#20851;&#31995;&#24320;&#36767;&#20102;&#26032;&#30340;&#36884;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multivariate Functional Principal Component Analysis (MFPCA) is a valuable tool for exploring relationships and identifying shared patterns of variation in multivariate functional data. However, controlling the roughness of the extracted Principal Components (PCs) can be challenging. This paper introduces a novel approach called regularized MFPCA (ReMFPCA) to address this issue and enhance the smoothness and interpretability of the multivariate functional PCs. ReMFPCA incorporates a roughness penalty within a penalized framework, using a parameter vector to regulate the smoothness of each functional variable. The proposed method generates smoothed multivariate functional PCs, providing a concise and interpretable representation of the data. Extensive simulations and real data examples demonstrate the effectiveness of ReMFPCA and its superiority over alternative methods. The proposed approach opens new avenues for analyzing and uncovering relationships in complex multivariate functional
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36229;&#21442;&#25968;&#35843;&#25972;&#26041;&#27861; OTSL&#65292;&#23427;&#37319;&#29992;&#22806;&#26679;&#26412;&#21644;&#37325;&#25277;&#26679;&#31574;&#30053;&#26469;&#20272;&#31639;&#32473;&#23450;&#36755;&#20837;&#25968;&#25454;&#38598;&#21644;&#32467;&#26500;&#23398;&#20064;&#31639;&#27861;&#30340;&#26368;&#20339;&#36229;&#21442;&#25968;&#37197;&#32622;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#65292;&#21487;&#25552;&#39640;&#32467;&#26500;&#23398;&#20064;&#31639;&#27861;&#30340;&#22270;&#24418;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.13932</link><description>&lt;p&gt;
&#21033;&#29992;&#22806;&#26679;&#26412;&#21644;&#37325;&#25277;&#26679;&#31574;&#30053;&#20248;&#21270;&#32467;&#26500;&#23398;&#20064;&#31639;&#27861;&#30340;&#36229;&#21442;&#25968;&#35843;&#25972;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Tuning structure learning algorithms with out-of-sample and resampling strategies. (arXiv:2306.13932v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13932
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36229;&#21442;&#25968;&#35843;&#25972;&#26041;&#27861; OTSL&#65292;&#23427;&#37319;&#29992;&#22806;&#26679;&#26412;&#21644;&#37325;&#25277;&#26679;&#31574;&#30053;&#26469;&#20272;&#31639;&#32473;&#23450;&#36755;&#20837;&#25968;&#25454;&#38598;&#21644;&#32467;&#26500;&#23398;&#20064;&#31639;&#27861;&#30340;&#26368;&#20339;&#36229;&#21442;&#25968;&#37197;&#32622;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#65292;&#21487;&#25552;&#39640;&#32467;&#26500;&#23398;&#20064;&#31639;&#27861;&#30340;&#22270;&#24418;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#23454;&#36341;&#32773;&#23558;&#32467;&#26500;&#23398;&#20064;&#31639;&#27861;&#24212;&#29992;&#20110;&#20854;&#25968;&#25454;&#26102;&#65292;&#38754;&#20020;&#30340;&#25361;&#25112;&#20043;&#19968;&#26159;&#30830;&#23450;&#19968;&#32452;&#36229;&#21442;&#25968;&#65307;&#21542;&#21017;&#65292;&#20551;&#23450;&#19968;&#32452;&#36229;&#21442;&#25968;&#40664;&#35748;&#20540;&#12290;&#26368;&#20339;&#36229;&#21442;&#25968;&#37197;&#32622;&#24120;&#24120;&#21462;&#20915;&#20110;&#22810;&#31181;&#22240;&#32032;&#65292;&#21253;&#25324;&#36890;&#24120;&#26410;&#30693;&#30340;&#30495;&#23454;&#24213;&#23618;&#22270;&#30340;&#22823;&#23567;&#21644;&#23494;&#24230;&#12289;&#36755;&#20837;&#25968;&#25454;&#30340;&#26679;&#26412;&#22823;&#23567;&#21644;&#32467;&#26500;&#23398;&#20064;&#31639;&#27861;&#31561;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36229;&#21442;&#25968;&#35843;&#25972;&#26041;&#27861;&#65292;&#21517;&#20026;Out-of-sample Tuning for Structure Learning&#65288;OTSL&#65289;&#65292;&#23427;&#37319;&#29992;&#22806;&#26679;&#26412;&#21644;&#37325;&#25277;&#26679;&#31574;&#30053;&#26469;&#20272;&#31639;&#32473;&#23450;&#36755;&#20837;&#25968;&#25454;&#38598;&#21644;&#32467;&#26500;&#23398;&#20064;&#31639;&#27861;&#30340;&#26368;&#20339;&#36229;&#21442;&#25968;&#37197;&#32622;&#12290;&#21512;&#25104;&#23454;&#39564;&#34920;&#26126;&#65292;&#20351;&#29992;OTSL&#20316;&#20026;&#28151;&#21512;&#21644;&#22522;&#20110;&#20998;&#25968;&#30340;&#32467;&#26500;&#23398;&#20064;&#31639;&#27861;&#30340;&#36229;&#21442;&#25968;&#35843;&#25972;&#25163;&#27573;&#65292;&#30456;&#23545;&#20110;&#29616;&#26377;&#25216;&#26415;&#65292;&#33021;&#22815;&#25552;&#39640;&#22270;&#24418;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#36824;&#28436;&#31034;&#20102;&#35813;&#26041;&#27861;&#22312;&#20960;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#20013;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
One of the challenges practitioners face when applying structure learning algorithms to their data involves determining a set of hyperparameters; otherwise, a set of hyperparameter defaults is assumed. The optimal hyperparameter configuration often depends on multiple factors, including the size and density of the usually unknown underlying true graph, the sample size of the input data, and the structure learning algorithm. We propose a novel hyperparameter tuning method, called the Out-of-sample Tuning for Structure Learning (OTSL), that employs out-of-sample and resampling strategies to estimate the optimal hyperparameter configuration for structure learning, given the input data set and structure learning algorithm. Synthetic experiments show that employing OTSL as a means to tune the hyperparameters of hybrid and score-based structure learning algorithms leads to improvements in graphical accuracy compared to the state-of-the-art. We also illustrate the applicability of this approa
&lt;/p&gt;</description></item><item><title>G-TRACER&#26159;&#19968;&#31181;&#27491;&#21017;&#21270;&#28145;&#24230;&#23398;&#20064;&#32467;&#26500;&#20248;&#21270;&#26041;&#26696;&#65292;&#37325;&#28857;&#35299;&#20915;&#20302;&#20449;&#22122;&#27604;&#38382;&#39064;&#65292;&#33021;&#26377;&#25928;&#20419;&#36827;&#27867;&#21270;&#24182;&#33719;&#24471;&#20102;&#31454;&#20105;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.13914</link><description>&lt;p&gt;
G-TRACER: &#39044;&#26399;&#28165;&#26224;&#24230;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
G-TRACER: Expected Sharpness Optimization. (arXiv:2306.13914v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13914
&lt;/p&gt;
&lt;p&gt;
G-TRACER&#26159;&#19968;&#31181;&#27491;&#21017;&#21270;&#28145;&#24230;&#23398;&#20064;&#32467;&#26500;&#20248;&#21270;&#26041;&#26696;&#65292;&#37325;&#28857;&#35299;&#20915;&#20302;&#20449;&#22122;&#27604;&#38382;&#39064;&#65292;&#33021;&#26377;&#25928;&#20419;&#36827;&#27867;&#21270;&#24182;&#33719;&#24471;&#20102;&#31454;&#20105;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#28145;&#24230;&#23398;&#20064;&#32467;&#26500;&#20248;&#21270;&#27491;&#21017;&#21270;&#26041;&#26696;&#65292;G-TRACER&#65288;"Geometric TRACE Ratio"&#65289;&#65292;&#36890;&#36807;&#23547;&#27714;&#24179;&#22374;&#26368;&#23567;&#20540;&#20419;&#36827;&#27867;&#21270;&#65292;&#24182;&#20855;&#26377;&#20197;&#24191;&#20041;Bayes&#30446;&#26631;&#30340;&#33258;&#28982;&#26799;&#24230;&#19979;&#38477;&#20026;&#22522;&#30784;&#30340;&#29702;&#35770;&#22522;&#30784;&#12290;&#36890;&#36807;&#20351;&#29992;TRACER&#22686;&#21152;&#25439;&#22833;&#20989;&#25968;&#65292;&#26354;&#29575;&#27491;&#21017;&#21270;&#20248;&#21270;&#22120;&#65288;&#20363;&#22914;SGD-TRACER&#21644;Adam-TRACER&#65289;&#21487;&#20197;&#20316;&#20026;&#29616;&#26377;&#20248;&#21270;&#22120;&#30340;&#20462;&#25913;&#31616;&#21333;&#22320;&#23454;&#29616;&#65292;&#19981;&#38656;&#35201;&#36827;&#34892;&#24191;&#27867;&#30340;&#35843;&#25972;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#25910;&#25947;&#20110;&#26410;&#27491;&#21017;&#21270;&#30446;&#26631;&#30340;&#23616;&#37096;&#26368;&#23567;&#20540;&#38468;&#36817;&#65288;&#21462;&#20915;&#20110;&#27491;&#21017;&#21270;&#24378;&#24230;&#30340;&#37051;&#22495;&#33539;&#22260;&#65289;&#65292;&#24182;&#22312;&#35768;&#22810;&#22522;&#20934;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;NLP&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#31454;&#20105;&#24615;&#33021;&#65292;&#29305;&#21035;&#20851;&#27880;&#25361;&#25112;&#24615;&#30340;&#20302;&#20449;&#22122;&#27604;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new regularization scheme for the optimization of deep learning architectures, G-TRACER ("Geometric TRACE Ratio"), which promotes generalization by seeking flat minima, and has a sound theoretical basis as an approximation to a natural-gradient descent based optimization of a generalized Bayes objective. By augmenting the loss function with a TRACER, curvature-regularized optimizers (eg SGD-TRACER and Adam-TRACER) are simple to implement as modifications to existing optimizers and don't require extensive tuning. We show that the method converges to a neighborhood (depending on the regularization strength) of a local minimum of the unregularized objective, and demonstrate competitive performance on a number of benchmark computer vision and NLP datasets, with a particular focus on challenging low signal-to-noise ratio problems.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#19968;&#31181;&#20351;&#29992;&#38543;&#26426;&#20998;&#32452;&#22871;&#32034;&#20272;&#35745;&#22120;&#36827;&#34892;&#24191;&#20041;&#27169;&#22411;&#30340;&#36873;&#25321;&#24615;&#25512;&#26029;&#26041;&#27861;&#65292;&#21487;&#20197;&#32771;&#34385;&#20998;&#31867;&#25110;&#20998;&#32452;&#21327;&#21464;&#37327;&#20197;&#21450;&#36830;&#32493;&#21327;&#21464;&#37327;&#65292;&#24182;&#19988;&#26377;&#35777;&#25454;&#34920;&#26126;&#20854;&#20855;&#26377;&#36866;&#24403;&#24615;&#21644;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.13829</link><description>&lt;p&gt;
&#20351;&#29992;&#38543;&#26426;&#20998;&#32452;&#22871;&#32034;&#20272;&#35745;&#22120;&#36827;&#34892;&#24191;&#20041;&#27169;&#22411;&#30340;&#36873;&#25321;&#24615;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
Selective inference using randomized group lasso estimators for general models. (arXiv:2306.13829v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13829
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#19968;&#31181;&#20351;&#29992;&#38543;&#26426;&#20998;&#32452;&#22871;&#32034;&#20272;&#35745;&#22120;&#36827;&#34892;&#24191;&#20041;&#27169;&#22411;&#30340;&#36873;&#25321;&#24615;&#25512;&#26029;&#26041;&#27861;&#65292;&#21487;&#20197;&#32771;&#34385;&#20998;&#31867;&#25110;&#20998;&#32452;&#21327;&#21464;&#37327;&#20197;&#21450;&#36830;&#32493;&#21327;&#21464;&#37327;&#65292;&#24182;&#19988;&#26377;&#35777;&#25454;&#34920;&#26126;&#20854;&#20855;&#26377;&#36866;&#24403;&#24615;&#21644;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#19982;&#24191;&#27867;&#30340;&#20998;&#24067;&#21644;&#25439;&#22833;&#20989;&#25968;&#19968;&#36215;&#20351;&#29992;&#65292;&#24320;&#21457;&#20102;&#36873;&#25321;&#24615;&#25512;&#29702;&#26041;&#27861;&#65292;&#29992;&#20110;&#32452;&#22871;&#32034;&#20272;&#35745;&#22120;&#12290;&#35813;&#26041;&#27861;&#21253;&#25324;&#20351;&#29992;&#25351;&#25968;&#23478;&#26063;&#20998;&#24067;&#65292;&#20197;&#21450;&#20687;&#36807;&#24230;&#31163;&#25955;&#35745;&#25968;&#25968;&#25454;&#30340;&#25311;&#28982;&#27169;&#22411;&#31561;&#65292;&#20801;&#35768;&#20998;&#31867;&#25110;&#20998;&#32452;&#21327;&#21464;&#37327;&#20197;&#21450;&#36830;&#32493;&#21327;&#21464;&#37327;&#12290;&#30740;&#31350;&#20102;&#19968;&#31181;&#38543;&#26426;&#30340;&#32452;&#27491;&#21017;&#21270;&#20248;&#21270;&#38382;&#39064;&#12290;&#28155;&#21152;&#30340;&#38543;&#26426;&#21270;&#20351;&#25105;&#20204;&#21487;&#20197;&#26500;&#24314;&#21518;&#36873;&#25321;&#20284;&#28982;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#26465;&#20214;&#36873;&#25321;&#20998;&#32452;&#21327;&#21464;&#37327;&#30340;&#20107;&#20214;&#19978;&#36866;&#29992;&#20110;&#36873;&#25321;&#24615;&#25512;&#26029;&#12290;&#36825;&#20010;&#20284;&#28982;&#20063;&#25552;&#20379;&#20102;&#19968;&#20010;&#36873;&#25321;&#24615;&#28857;&#20272;&#35745;&#65292;&#36890;&#36807;&#32452;&#22871;&#32034;&#32771;&#34385;&#20102;&#36873;&#25321;&#12290;&#36873;&#25321;&#30340;&#27169;&#22411;&#20013;&#22238;&#24402;&#21442;&#25968;&#30340;&#32622;&#20449;&#21306;&#38388;&#37319;&#29992;&#27779;&#23572;&#24503;&#31867;&#22411;&#30340;&#21306;&#38388;&#65292;&#24182;&#35777;&#26126;&#20855;&#26377;&#26377;&#30028;&#20307;&#31215;&#12290;&#20197;&#32654;&#22269;&#22269;&#23478;&#20581;&#24247;&#21644;&#33829;&#20859;&#35843;&#26597;&#30340;&#25968;&#25454;&#20026;&#20363;&#23637;&#31034;&#20102;&#32452;&#22871;&#32034;&#30340;&#36873;&#25321;&#24615;&#25512;&#29702;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Selective inference methods are developed for group lasso estimators for use with a wide class of distributions and loss functions. The method includes the use of exponential family distributions, as well as quasi-likelihood modeling for overdispersed count data, for example, and allows for categorical or grouped covariates as well as continuous covariates. A randomized group-regularized optimization problem is studied. The added randomization allows us to construct a post-selection likelihood which we show to be adequate for selective inference when conditioning on the event of the selection of the grouped covariates. This likelihood also provides a selective point estimator, accounting for the selection by the group lasso. Confidence regions for the regression parameters in the selected model take the form of Wald-type regions and are shown to have bounded volume. The selective inference method for grouped lasso is illustrated on data from the national health and nutrition examinatio
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24352;&#37327;&#30340;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#22810;&#39033;&#24335;&#28151;&#21512;&#27169;&#22411;&#65288;Tensor-DPMM&#65289;&#65292;&#36890;&#36807;&#24352;&#37327;&#20445;&#30041;&#20102;&#22810;&#32500;&#34892;&#31243;&#20449;&#24687;&#30340;&#22810;&#27169;&#24335;&#21644;&#20998;&#23618;&#32467;&#26500;&#65292;&#24182;&#20197;&#32479;&#19968;&#30340;&#19968;&#27493;&#26041;&#24335;&#36827;&#34892;&#20056;&#23458;&#36712;&#36857;&#32858;&#31867;&#65292;&#22312;&#33258;&#21160;&#30830;&#23450;&#32858;&#31867;&#25968;&#26041;&#38754;&#20855;&#26377;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.13794</link><description>&lt;p&gt;
&#20056;&#23458;&#36712;&#36857;&#32858;&#31867;&#30340;&#24352;&#37327;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#22810;&#39033;&#24335;&#28151;&#21512;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Tensor Dirichlet Process Multinomial Mixture Model for Passenger Trajectory Clustering. (arXiv:2306.13794v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13794
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24352;&#37327;&#30340;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#22810;&#39033;&#24335;&#28151;&#21512;&#27169;&#22411;&#65288;Tensor-DPMM&#65289;&#65292;&#36890;&#36807;&#24352;&#37327;&#20445;&#30041;&#20102;&#22810;&#32500;&#34892;&#31243;&#20449;&#24687;&#30340;&#22810;&#27169;&#24335;&#21644;&#20998;&#23618;&#32467;&#26500;&#65292;&#24182;&#20197;&#32479;&#19968;&#30340;&#19968;&#27493;&#26041;&#24335;&#36827;&#34892;&#20056;&#23458;&#36712;&#36857;&#32858;&#31867;&#65292;&#22312;&#33258;&#21160;&#30830;&#23450;&#32858;&#31867;&#25968;&#26041;&#38754;&#20855;&#26377;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#20986;&#34892;&#35760;&#24405;&#30340;&#20056;&#23458;&#32858;&#31867;&#23545;&#20110;&#36816;&#36755;&#36816;&#33829;&#21830;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#30001;&#20110;&#20056;&#23458;&#34892;&#31243;&#20449;&#24687;&#30340;&#20998;&#23618;&#32467;&#26500;&#32780;&#38590;&#20197;&#36731;&#26494;&#36827;&#34892;&#20056;&#23458;&#32858;&#31867;&#65292;&#21363;&#65306;&#27599;&#20010;&#20056;&#23458;&#26377;&#22810;&#27425;&#20986;&#34892;&#65292;&#27599;&#27425;&#20986;&#34892;&#21253;&#21547;&#22810;&#32500;&#22810;&#27169;&#24335;&#20449;&#24687;&#12290;&#27492;&#22806;&#65292;&#29616;&#26377;&#26041;&#27861;&#20381;&#36182;&#20110;&#31934;&#30830;&#25351;&#23450;&#32858;&#31867;&#25968;&#37327;&#24320;&#22987;&#65292;&#32780;&#27599;&#22825;&#26377;&#25968;&#30334;&#19975;&#36890;&#21220;&#32773;&#20351;&#29992;&#20132;&#36890;&#31995;&#32479;&#26102;&#36825;&#26159;&#22256;&#38590;&#30340;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#24352;&#37327;&#30340;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#22810;&#39033;&#24335;&#28151;&#21512;&#27169;&#22411;&#65288;Tensor-DPMM&#65289;&#65292;&#36890;&#36807;&#24352;&#37327;&#20445;&#30041;&#20102;&#22810;&#32500;&#34892;&#31243;&#20449;&#24687;&#30340;&#22810;&#27169;&#24335;&#21644;&#20998;&#23618;&#32467;&#26500;&#65292;&#24182;&#20197;&#32479;&#19968;&#30340;&#19968;&#27493;&#26041;&#24335;&#23545;&#23427;&#20204;&#36827;&#34892;&#32858;&#31867;&#12290;&#35813;&#27169;&#22411;&#36824;&#36890;&#36807;&#20351;&#29992;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#20915;&#23450;&#20056;&#23458;&#20998;&#37197;&#33267;&#29616;&#26377;&#32858;&#31867;&#36824;&#26159;&#24418;&#25104;&#26032;&#32858;&#31867;&#30340;&#27010;&#29575;&#65292;&#33258;&#21160;&#30830;&#23450;&#32858;&#31867;&#25968;&#30340;&#33021;&#21147;&#12290;&#22312;&#30495;&#23454;&#30340;&#20132;&#36890;&#36816;&#36755;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;Tensor-DPMM&#27169;&#22411;&#22312;&#20056;&#23458;&#36712;&#36857;&#32858;&#31867;&#26041;&#38754;&#20855;&#26377;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Passenger clustering based on travel records is essential for transportation operators. However, existing methods cannot easily cluster the passengers due to the hierarchical structure of the passenger trip information, namely: each passenger has multiple trips, and each trip contains multi-dimensional multi-mode information. Furthermore, existing approaches rely on an accurate specification of the clustering number to start, which is difficult when millions of commuters are using the transport systems on a daily basis. In this paper, we propose a novel Tensor Dirichlet Process Multinomial Mixture model (Tensor-DPMM), which is designed to preserve the multi-mode and hierarchical structure of the multi-dimensional trip information via tensor, and cluster them in a unified one-step manner. The model also has the ability to determine the number of clusters automatically by using the Dirichlet Process to decide the probabilities for a passenger to be either assigned in an existing cluster 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#27867;&#21270;&#35823;&#24046;&#30340;&#20272;&#35745;&#26041;&#27861;&#21644;&#25910;&#25947;&#24615;&#20998;&#26512;&#65292;&#21487;&#20197;&#22312;&#19981;&#38656;&#35201;&#31070;&#32463;&#32593;&#32476;&#30340;&#20219;&#20309;&#20551;&#35774;&#19979;&#23545;&#35823;&#24046;&#36827;&#34892;&#20272;&#35745;&#65292;&#24182;&#21482;&#35201;&#27714;&#31070;&#32463;&#32593;&#32476;&#20855;&#26377;&#36866;&#24403;&#30340;&#36924;&#36817;&#33021;&#21147;&#23601;&#21487;&#20197;&#23558;&#36817;&#20284;&#36716;&#21270;&#20026;&#30446;&#26631;&#20989;&#25968;f&#12290;</title><link>http://arxiv.org/abs/2306.13784</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#27867;&#21270;&#35823;&#24046;&#30340;&#26032;&#26041;&#27861;&#65306;&#20272;&#35745;&#21644;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
A new approach to generalisation error of machine learning algorithms: Estimates and convergence. (arXiv:2306.13784v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13784
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#27867;&#21270;&#35823;&#24046;&#30340;&#20272;&#35745;&#26041;&#27861;&#21644;&#25910;&#25947;&#24615;&#20998;&#26512;&#65292;&#21487;&#20197;&#22312;&#19981;&#38656;&#35201;&#31070;&#32463;&#32593;&#32476;&#30340;&#20219;&#20309;&#20551;&#35774;&#19979;&#23545;&#35823;&#24046;&#36827;&#34892;&#20272;&#35745;&#65292;&#24182;&#21482;&#35201;&#27714;&#31070;&#32463;&#32593;&#32476;&#20855;&#26377;&#36866;&#24403;&#30340;&#36924;&#36817;&#33021;&#21147;&#23601;&#21487;&#20197;&#23558;&#36817;&#20284;&#36716;&#21270;&#20026;&#30446;&#26631;&#20989;&#25968;f&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#28145;&#24230;&#31070;&#32463;&#23398;&#20064;&#30340;&#19968;&#20010;&#27169;&#22411;&#38382;&#39064;&#65292;&#21363;&#22312;&#26377;&#38480;&#30340;&#28857;&#38598;&#19978;&#24050;&#30693;&#19968;&#20010;&#20989;&#25968;&#30340;&#28857;&#20540;&#65292;&#23398;&#20064;&#35813;&#20989;&#25968;&#12290;&#36890;&#36807;&#20856;&#22411;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#65292;&#21253;&#25324;&#32473;&#23450;&#30340;DNN&#20307;&#31995;&#32467;&#26500;&#21644;&#19968;&#20010;&#34987;&#35748;&#20026;&#21487;&#20197;&#23436;&#20840;&#35299;&#20915;&#30340;&#20248;&#21270;&#27493;&#39588;&#65292;&#24471;&#21040;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#25554;&#20540;&#22120;&#65292;&#35813;&#25554;&#20540;&#22120;&#26159;f&#30340;&#36817;&#20284;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#20272;&#35745;&#65288;&#27867;&#21270;&#65289;&#35823;&#24046;&#21644;&#25910;&#25947;&#24615;&#30340;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#21253;&#25324;&#65306;&#65288;i&#65289;&#22312;&#31070;&#32463;&#32593;&#32476;&#27809;&#26377;&#20219;&#20309;&#32467;&#26500;&#24615;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#24182;&#22312;&#23398;&#20064;&#20989;&#25968;f&#30340;&#28201;&#21644;&#27491;&#21017;&#24615;&#20551;&#35774;&#19979;&#20272;&#35745;&#35823;&#24046;&#65292;&#65288;ii&#65289;&#21482;&#35201;&#31070;&#32463;&#32593;&#32476;&#31354;&#38388;&#20855;&#26377;&#36866;&#24403;&#30340;&#36924;&#36817;&#33021;&#21147;&#65292;&#23601;&#21487;&#20197;&#23558;&#36817;&#20284;&#36716;&#21270;&#20026;&#30446;&#26631;&#20989;&#25968;f&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work we consider a model problem of deep neural learning, namely the learning of a given function when it is assumed that we have access to its point values on a finite set of points. The deep neural network interpolant is the the resulting approximation of f, which is obtained by a typical machine learning algorithm involving a given DNN architecture and an optimisation step, which is assumed to be solved exactly. These are among the simplest regression algorithms based on neural networks. In this work we introduce a new approach to the estimation of the (generalisation) error and to convergence. Our results include (i) estimates of the error without any structural assumption on the neural networks and under mild regularity assumptions on the learning function f (ii) convergence of the approximations to the target function f by only requiring that the neural network spaces have appropriate approximation capability.
&lt;/p&gt;</description></item><item><title>&#26368;&#36817;&#30340;&#30740;&#31350;&#32858;&#28966;&#20110;&#22522;&#20110;&#39044;&#27979;&#30340;&#25512;&#26029;&#65292;&#24182;&#25552;&#20986;&#20102;&#20462;&#27491;&#27493;&#39588;&#20197;&#23454;&#29616;&#23545;&#26410;&#35266;&#27979;&#21040;&#21709;&#24212;&#21644;&#21327;&#21464;&#37327;&#20043;&#38388;&#20851;&#31995;&#30340;&#26377;&#25928;&#25512;&#26029;&#65292;Angelopoulos&#31561;&#20154;&#65288;2023&#65289;&#30340;&#26041;&#27861;&#25104;&#21151;&#25511;&#21046;&#20102;&#31532;&#19968;&#31867;&#38169;&#35823;&#29575;&#65292;&#24182;&#25552;&#20379;&#20102;&#27491;&#30830;&#21629;&#21517;&#35206;&#30422;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#20294;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#20854;&#23384;&#22312;&#20302;&#21151;&#29575;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.13746</link><description>&lt;p&gt;
&#22312;&#39044;&#27979;&#20043;&#21518;&#30340;&#26377;&#25928;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Valid inference after prediction. (arXiv:2306.13746v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13746
&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#32858;&#28966;&#20110;&#22522;&#20110;&#39044;&#27979;&#30340;&#25512;&#26029;&#65292;&#24182;&#25552;&#20986;&#20102;&#20462;&#27491;&#27493;&#39588;&#20197;&#23454;&#29616;&#23545;&#26410;&#35266;&#27979;&#21040;&#21709;&#24212;&#21644;&#21327;&#21464;&#37327;&#20043;&#38388;&#20851;&#31995;&#30340;&#26377;&#25928;&#25512;&#26029;&#65292;Angelopoulos&#31561;&#20154;&#65288;2023&#65289;&#30340;&#26041;&#27861;&#25104;&#21151;&#25511;&#21046;&#20102;&#31532;&#19968;&#31867;&#38169;&#35823;&#29575;&#65292;&#24182;&#25552;&#20379;&#20102;&#27491;&#30830;&#21629;&#21517;&#35206;&#30422;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#20294;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#20854;&#23384;&#22312;&#20302;&#21151;&#29575;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#30340;&#30740;&#31350;&#32858;&#28966;&#20110;&#22522;&#20110;&#39044;&#27979;&#30340;&#25512;&#26029;&#65292;&#21363;&#20351;&#29992;&#39044;&#20808;&#35757;&#32451;&#22909;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#39044;&#27979;&#26410;&#35266;&#27979;&#21040;&#30340;&#21709;&#24212;&#21464;&#37327;&#65292;&#28982;&#21518;&#23545;&#35813;&#39044;&#27979;&#21709;&#24212;&#19982;&#26576;&#20123;&#21327;&#21464;&#37327;&#20043;&#38388;&#30340;&#20851;&#31995;&#36827;&#34892;&#25512;&#26029;&#12290;&#28982;&#32780;&#65292;&#23558;&#26631;&#20934;&#25512;&#26029;&#26041;&#27861;&#24212;&#29992;&#20110;&#35813;&#36807;&#31243;&#24182;&#19981;&#33021;&#20934;&#30830;&#37327;&#21270;&#26410;&#35266;&#27979;&#21040;&#65288;&#32780;&#38750;&#39044;&#27979;&#21040;&#65289;&#21709;&#24212;&#19982;&#21327;&#21464;&#37327;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#26368;&#36817;&#65292;Wang&#31561;&#20154;&#65288;2020&#65289;&#21644;Angelopoulos&#31561;&#20154;&#65288;2023&#65289;&#25552;&#20986;&#20102;&#20462;&#27491;&#65288;ii&#65289;&#27493;&#39588;&#30340;&#26041;&#27861;&#65292;&#20197;&#23454;&#29616;&#23545;&#26410;&#35266;&#27979;&#21040;&#21709;&#24212;&#21644;&#21327;&#21464;&#37327;&#20043;&#38388;&#20851;&#31995;&#30340;&#26377;&#25928;&#25512;&#26029;&#12290;&#26412;&#25991;&#34920;&#26126;&#65292;Angelopoulos&#31561;&#20154;&#65288;2023&#65289;&#25552;&#20986;&#30340;&#26041;&#27861;&#25104;&#21151;&#22320;&#25511;&#21046;&#20102;&#31532;&#19968;&#31867;&#38169;&#35823;&#29575;&#65292;&#24182;&#25552;&#20379;&#20102;&#20855;&#26377;&#27491;&#30830;&#21629;&#21517;&#35206;&#30422;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#26080;&#35770;&#39044;&#20808;&#35757;&#32451;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#29992;&#20110;&#39044;&#27979;&#26410;&#35266;&#27979;&#21040;&#30340;&#21709;&#24212;&#30340;&#36136;&#37327;&#22914;&#20309;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#20063;&#21457;&#29616;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20855;&#26377;&#20302;&#21151;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent work has focused on the very common practice of prediction-based inference: that is, (i) using a pre-trained machine learning model to predict an unobserved response variable, and then (ii) conducting inference on the association between that predicted response and some covariates. As pointed out by Wang et al. [2020], applying a standard inferential approach in (ii) does not accurately quantify the association between the unobserved (as opposed to the predicted) response and the covariates. In recent work, Wang et al. [2020] and Angelopoulos et al. [2023] propose corrections to step (ii) in order to enable valid inference on the association between the unobserved response and the covariates. Here, we show that the method proposed by Angelopoulos et al. [2023] successfully controls the type 1 error rate and provides confidence intervals with correct nominal coverage, regardless of the quality of the pre-trained machine learning model used to predict the unobserved response. Howe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#23454;&#35777;&#26694;&#26550;&#65292;&#29992;&#20110;&#20272;&#31639;&#35777;&#25454;&#20915;&#31574;&#30340;&#20215;&#20540;&#21644;&#32479;&#35745;&#31934;&#24230;&#25237;&#36164;&#22238;&#25253;&#12290;</title><link>http://arxiv.org/abs/2306.13681</link><description>&lt;p&gt;
&#20272;&#31639;&#22522;&#20110;&#35777;&#25454;&#20915;&#31574;&#30340;&#20215;&#20540;
&lt;/p&gt;
&lt;p&gt;
Estimating the Value of Evidence-Based Decision Making. (arXiv:2306.13681v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13681
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#23454;&#35777;&#26694;&#26550;&#65292;&#29992;&#20110;&#20272;&#31639;&#35777;&#25454;&#20915;&#31574;&#30340;&#20215;&#20540;&#21644;&#32479;&#35745;&#31934;&#24230;&#25237;&#36164;&#22238;&#25253;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21830;&#19994;/&#25919;&#31574;&#20915;&#31574;&#36890;&#24120;&#22522;&#20110;&#38543;&#26426;&#23454;&#39564;&#21644;&#35266;&#23519;&#24615;&#30740;&#31350;&#30340;&#35777;&#25454;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#23454;&#35777;&#26694;&#26550;&#26469;&#20272;&#31639;&#22522;&#20110;&#35777;&#25454;&#30340;&#20915;&#31574;&#65288;EBDM&#65289;&#30340;&#20215;&#20540;&#21644;&#32479;&#35745;&#31934;&#24230;&#25237;&#36164;&#22238;&#25253;&#12290;
&lt;/p&gt;
&lt;p&gt;
Business/policy decisions are often based on evidence from randomized experiments and observational studies. In this article we propose an empirical framework to estimate the value of evidence-based decision making (EBDM) and the return on the investment in statistical precision.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;CongestEXP&#30340;&#20998;&#25955;&#31639;&#27861;&#65292;&#21487;&#20197;&#32447;&#24615;&#32553;&#25918;&#35774;&#26045;&#25968;&#37327;&#65292;&#23454;&#29616;&#22312;&#32447;&#25317;&#22622;&#21338;&#24328;&#30340;&#27425;&#32447;&#24615;&#36951;&#25022;&#19978;&#30028;&#65292;&#24182;&#20197;&#19982;&#24050;&#30693;&#26368;&#20339;&#19979;&#30028;&#30456;&#21305;&#37197;&#30340;&#36895;&#24230;&#24555;&#36895;&#25910;&#25947;&#21040;&#32435;&#20160;&#22343;&#34913;&#12290;</title><link>http://arxiv.org/abs/2306.13673</link><description>&lt;p&gt;
&#39550;&#39533;&#25351;&#25968;&#32423;&#30340;&#21160;&#20316;&#38598;&#65306;&#22312;&#32447;&#25317;&#22622;&#21338;&#24328;&#20013;&#27425;&#32447;&#24615;&#36951;&#25022;&#21644;&#24555;&#36895;&#25910;&#25947;&#21040;&#32435;&#20160;&#22343;&#34913;
&lt;/p&gt;
&lt;p&gt;
Taming the Exponential Action Set: Sublinear Regret and Fast Convergence to Nash Equilibrium in Online Congestion Games. (arXiv:2306.13673v1 [cs.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13673
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;CongestEXP&#30340;&#20998;&#25955;&#31639;&#27861;&#65292;&#21487;&#20197;&#32447;&#24615;&#32553;&#25918;&#35774;&#26045;&#25968;&#37327;&#65292;&#23454;&#29616;&#22312;&#32447;&#25317;&#22622;&#21338;&#24328;&#30340;&#27425;&#32447;&#24615;&#36951;&#25022;&#19978;&#30028;&#65292;&#24182;&#20197;&#19982;&#24050;&#30693;&#26368;&#20339;&#19979;&#30028;&#30456;&#21305;&#37197;&#30340;&#36895;&#24230;&#24555;&#36895;&#25910;&#25947;&#21040;&#32435;&#20160;&#22343;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25317;&#22622;&#21338;&#24328;&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#27169;&#22411;&#65292;&#28085;&#30422;&#20102;&#20132;&#36890;&#32593;&#32476;&#21644;&#36164;&#28304;&#20998;&#37197;&#31561;&#19968;&#31995;&#21015;&#24037;&#31243;&#31995;&#32479;&#12290;&#26412;&#25991;&#30740;&#31350;&#25317;&#22622;&#21338;&#24328;&#30340;&#22312;&#32447;&#24418;&#24335;&#65292;&#20854;&#20013;&#20195;&#29702;&#37325;&#22797;&#21442;&#19982;&#21338;&#24328;&#65292;&#24182;&#35266;&#23519;&#21040;&#24102;&#26377;&#38543;&#26426;&#24615;&#30340;&#21453;&#39304;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;CongestEXP&#30340;&#20998;&#25955;&#31639;&#27861;&#65292;&#24212;&#29992;&#20110;&#32463;&#20856;&#30340;&#25351;&#25968;&#26435;&#37325;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#35774;&#26045;&#32423;&#21035;&#19978;&#20445;&#25345;&#26435;&#37325;&#65292;&#36991;&#20813;&#20102;&#20256;&#32479;&#31639;&#27861;&#23545;&#21487;&#33021;&#35774;&#26045;&#38598;&#22823;&#23567;&#30340;&#25351;&#25968;&#20381;&#36182;&#65292;&#21363;$\binom{F}{k}\approx F^k$&#65292;&#24182;&#19988;&#20165;&#19982;$F$&#32447;&#24615;&#32553;&#25918;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#27599;&#20010;&#21333;&#29420;&#30340;&#29609;&#23478;&#65292;CongestEXP&#21487;&#20197;&#23454;&#29616;$O(kF\sqrt{T})$&#30340;&#36951;&#25022;&#19978;&#30028;&#65292;&#20854;&#20013;$T$&#26159;&#26102;&#38388;&#21608;&#26399;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#21033;&#29992;&#26435;&#37325;&#30340;&#25351;&#25968;&#22686;&#38271;&#20351;CongestEXP&#33021;&#22815;&#23454;&#29616;&#24555;&#36895;&#25910;&#25947;&#21040;&#32435;&#20160;&#22343;&#34913;&#65292;&#20854;&#25910;&#25947;&#36895;&#24230;&#20026;$O(\ln F/\sqrt{T})$&#65292;&#36825;&#19982;&#24050;&#30693;&#30340;&#26368;&#20339;&#19979;&#30028;&#30456;&#31526;&#65292;&#20165;&#30456;&#24046;&#23545;&#25968;&#22240;&#23376;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#20063;&#36866;&#29992;&#20110;&#26356;&#24191;&#27867;&#30340;&#28216;&#25103;&#31867;&#21035;&#65292;&#21253;&#25324;&#37027;&#20123;&#20855;&#26377;&#36830;&#32493;&#20998;&#24067;&#26435;&#37325;&#21644;&#37027;&#20123;&#20855;&#26377;&#20219;&#24847;&#29609;&#23478;&#34892;&#21160;&#30340;&#28216;&#25103;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#35777;&#26126;&#20102;CongestEXP&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The congestion game is a powerful model that encompasses a range of engineering systems such as traffic networks and resource allocation. It describes the behavior of a group of agents who share a common set of $F$ facilities and take actions as subsets with $k$ facilities. In this work, we study the online formulation of congestion games, where agents participate in the game repeatedly and observe feedback with randomness. We propose CongestEXP, a decentralized algorithm that applies the classic exponential weights method. By maintaining weights on the facility level, the regret bound of CongestEXP avoids the exponential dependence on the size of possible facility sets, i.e., $\binom{F}{k} \approx F^k$, and scales only linearly with $F$. Specifically, we show that CongestEXP attains a regret upper bound of $O(kF\sqrt{T})$ for every individual player, where $T$ is the time horizon. On the other hand, exploiting the exponential growth of weights enables CongestEXP to achieve a fast conv
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#37325;&#35201;&#24615;&#25277;&#26679;&#23454;&#29616;&#26377;&#25928;&#36890;&#20449;&#30340;&#32852;&#37030;&#23398;&#20064;&#26041;&#27861;&#65292;&#22823;&#22823;&#38477;&#20302;&#20102;&#21457;&#36865;&#27169;&#22411;&#26356;&#26032;&#30340;&#39640;&#36890;&#20449;&#25104;&#26412;&#65292;&#21033;&#29992;&#26381;&#21153;&#22120;&#31471;&#23458;&#25143;&#31471;&#20998;&#24067;&#21644;&#38468;&#21152;&#20449;&#24687;&#30340;&#25509;&#36817;&#20851;&#31995;&#65292;&#21482;&#38656;&#35201;&#36739;&#23569;&#30340;&#36890;&#20449;&#37327;&#21363;&#21487;&#23454;&#29616;&#12290;</title><link>http://arxiv.org/abs/2306.12625</link><description>&lt;p&gt;
&#36890;&#36807;&#37325;&#35201;&#24615;&#25277;&#26679;&#23454;&#29616;&#26377;&#25928;&#36890;&#20449;&#30340;&#32852;&#37030;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Communication-Efficient Federated Learning through Importance Sampling. (arXiv:2306.12625v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12625
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#37325;&#35201;&#24615;&#25277;&#26679;&#23454;&#29616;&#26377;&#25928;&#36890;&#20449;&#30340;&#32852;&#37030;&#23398;&#20064;&#26041;&#27861;&#65292;&#22823;&#22823;&#38477;&#20302;&#20102;&#21457;&#36865;&#27169;&#22411;&#26356;&#26032;&#30340;&#39640;&#36890;&#20449;&#25104;&#26412;&#65292;&#21033;&#29992;&#26381;&#21153;&#22120;&#31471;&#23458;&#25143;&#31471;&#20998;&#24067;&#21644;&#38468;&#21152;&#20449;&#24687;&#30340;&#25509;&#36817;&#20851;&#31995;&#65292;&#21482;&#38656;&#35201;&#36739;&#23569;&#30340;&#36890;&#20449;&#37327;&#21363;&#21487;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23458;&#25143;&#31471;&#21521;&#26381;&#21153;&#22120;&#21457;&#36865;&#27169;&#22411;&#26356;&#26032;&#30340;&#39640;&#36890;&#20449;&#25104;&#26412;&#26159;&#21487;&#25193;&#23637;&#32852;&#37030;&#23398;&#20064;&#65288;FL&#65289;&#30340;&#37325;&#35201;&#29942;&#39048;&#12290;&#29616;&#26377;&#26041;&#27861;&#20013;&#65292;&#20351;&#29992;&#38543;&#26426;&#21387;&#32553;&#26041;&#27861;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#27604;&#29305;&#29575;-&#20934;&#30830;&#24615;&#25240;&#34935;&#8212;&#8212;&#20854;&#20013;&#23458;&#25143;&#31471;n&#21457;&#36865;&#26469;&#33258;&#20165;&#20026;&#35813;&#23458;&#25143;&#31471;&#30340;&#27010;&#29575;&#20998;&#24067;q&#966;&#65288;n&#65289;&#30340;&#26679;&#26412;&#65292;&#26381;&#21153;&#22120;&#20351;&#29992;&#36825;&#20123;&#26679;&#26412;&#20272;&#35745;&#23458;&#25143;&#31471;&#20998;&#24067;&#30340;&#24179;&#22343;&#20540;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#27809;&#26377;&#20805;&#20998;&#21033;&#29992;FL&#30340;&#35774;&#32622;&#65292;&#20854;&#20013;&#26381;&#21153;&#22120;&#22312;&#25972;&#20010;&#35757;&#32451;&#36807;&#31243;&#20013;&#20855;&#26377;&#39044;&#25968;&#25454;&#20998;&#24067;p&#952;&#30340;&#38468;&#21152;&#20449;&#24687;&#65292;&#35813;&#20998;&#24067;&#19982;&#23458;&#25143;&#31471;&#20998;&#24067;q&#966;&#65288;n&#65289;&#22312;Kullback-Leibler&#65288;KL&#65289;&#21457;&#25955;&#26041;&#38754;&#25509;&#36817;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#26381;&#21153;&#22120;&#31471;&#23458;&#25143;&#31471;&#20998;&#24067;q&#966;&#65288;n)&#19982;&#38468;&#21152;&#20449;&#24687;p&#952;&#20043;&#38388;&#30340;&#36825;&#31181;&#25509;&#36817;&#20851;&#31995;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#38656;&#35201;&#22823;&#32422;Dkl&#65288;q&#966;&#65288;n&#65289;|| p&#952;&#65289;&#20301;&#30340;&#36890;&#20449;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
The high communication cost of sending model updates from the clients to the server is a significant bottleneck for scalable federated learning (FL). Among existing approaches, state-of-the-art bitrate-accuracy tradeoffs have been achieved using stochastic compression methods -- in which the client $n$ sends a sample from a client-only probability distribution $q_{\phi^{(n)}}$, and the server estimates the mean of the clients' distributions using these samples. However, such methods do not take full advantage of the FL setup where the server, throughout the training process, has side information in the form of a pre-data distribution $p_{\theta}$ that is close to the client's distribution $q_{\phi^{(n)}}$ in Kullback-Leibler (KL) divergence. In this work, we exploit this closeness between the clients' distributions $q_{\phi^{(n)}}$'s and the side information $p_{\theta}$ at the server, and propose a framework that requires approximately $D_{KL}(q_{\phi^{(n)}}|| p_{\theta})$ bits of com
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38543;&#26426;&#24179;&#28369;&#26041;&#27861;&#65292;&#21487;&#20197;&#26681;&#25454;&#22270;&#30340;&#19981;&#21516;&#39044;&#23450;&#20041;&#32467;&#26500;&#29983;&#25104;&#23545;&#24212;&#30340;&#40065;&#26834;&#24615;&#35777;&#20070;&#65292;&#20174;&#32780;&#22312;&#22810;&#20010;&#22522;&#20934;&#22270;&#20998;&#31867;&#20219;&#21153;&#20013;&#21462;&#24471;&#39046;&#20808;&#30340;&#23545;&#25239;&#24615;&#25915;&#20987;&#19979;&#40065;&#26834;&#24615;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.11915</link><description>&lt;p&gt;
&#22270;&#20998;&#31867;&#38382;&#39064;&#20013;&#32467;&#26500;&#24863;&#30693;&#30340;&#40065;&#26834;&#24615;&#35748;&#35777;
&lt;/p&gt;
&lt;p&gt;
Structure-Aware Robustness Certificates for Graph Classification. (arXiv:2306.11915v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11915
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38543;&#26426;&#24179;&#28369;&#26041;&#27861;&#65292;&#21487;&#20197;&#26681;&#25454;&#22270;&#30340;&#19981;&#21516;&#39044;&#23450;&#20041;&#32467;&#26500;&#29983;&#25104;&#23545;&#24212;&#30340;&#40065;&#26834;&#24615;&#35777;&#20070;&#65292;&#20174;&#32780;&#22312;&#22810;&#20010;&#22522;&#20934;&#22270;&#20998;&#31867;&#20219;&#21153;&#20013;&#21462;&#24471;&#39046;&#20808;&#30340;&#23545;&#25239;&#24615;&#25915;&#20987;&#19979;&#40065;&#26834;&#24615;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#22522;&#20110;&#22270;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#40065;&#26834;&#24615;&#35748;&#35777;&#26159;&#20445;&#35777;&#23433;&#20840;&#24615;&#30340;&#19968;&#20010;&#33267;&#20851;&#37325;&#35201;&#30340;&#25361;&#25112;&#12290;&#30446;&#21069;&#29992;&#20110;&#22270;&#20998;&#31867;&#22120;&#30340;&#40065;&#26834;&#24615;&#35777;&#26126;&#20445;&#35777;&#19982;&#33410;&#28857;&#23545;&#32763;&#36716;&#65288;&#28155;&#21152;&#25110;&#21024;&#38500;&#36793;&#32536;&#65289;&#30340;&#24635;&#25968;&#26377;&#20851;&#65292;&#36825;&#30456;&#24403;&#20110;&#20197;&#37051;&#25509;&#30697;&#38453;&#20026;&#20013;&#24515;&#30340;l0&#29699;&#12290;&#23613;&#31649;&#20174;&#29702;&#35770;&#19978;&#30475;&#24456;&#26377;&#21560;&#24341;&#21147;&#65292;&#20294;&#36825;&#31181;&#21508;&#21521;&#21516;&#24615;&#30340;&#32467;&#26500;&#22122;&#22768;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#21487;&#33021;&#36807;&#20110;&#20005;&#26684;&#65292;&#22240;&#20026;&#26377;&#20123;&#33410;&#28857;&#23545;&#20110;&#30830;&#23450;&#20998;&#31867;&#22120;&#30340;&#36755;&#20986;&#26356;&#20026;&#20851;&#38190;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#35777;&#20070;&#32473;&#20986;&#20102;&#23545;&#22270;&#27169;&#22411;&#40065;&#26834;&#24615;&#30340;&#24754;&#35266;&#25551;&#36848;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#24179;&#28369;&#30340;&#26041;&#27861;&#65292;&#23558;&#38750;&#21508;&#21521;&#21516;&#24615;&#30340;&#22122;&#22768;&#20998;&#24067;&#28155;&#21152;&#21040;&#36755;&#20837;&#22270;&#32467;&#26500;&#20013;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#36807;&#31243;&#20026;&#20998;&#31867;&#22120;&#29983;&#25104;&#20102;&#32467;&#26500;&#24863;&#30693;&#30340;&#35777;&#20070;&#65292;&#22240;&#27492;&#40065;&#26834;&#24615;&#35777;&#20070;&#30340;&#22823;&#23567;&#21487;&#20197;&#22312;&#22270;&#30340;&#19981;&#21516;&#39044;&#23450;&#20041;&#32467;&#26500;&#20043;&#38388;&#21464;&#21270;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#22522;&#20934;&#22270;&#20998;&#31867;&#20219;&#21153;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#20248;&#21183;&#65292;&#22312;&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#26041;&#38754;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Certifying the robustness of a graph-based machine learning model poses a critical challenge for safety. Current robustness certificates for graph classifiers guarantee output invariance with respect to the total number of node pair flips (edge addition or edge deletion), which amounts to an $l_{0}$ ball centred on the adjacency matrix. Although theoretically attractive, this type of isotropic structural noise can be too restrictive in practical scenarios where some node pairs are more critical than others in determining the classifier's output. The certificate, in this case, gives a pessimistic depiction of the robustness of the graph model. To tackle this issue, we develop a randomised smoothing method based on adding an anisotropic noise distribution to the input graph structure. We show that our process generates structural-aware certificates for our classifiers, whereby the magnitude of robustness certificates can vary across different pre-defined structures of the graph. We demon
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#20110;&#24322;&#36136;&#31181;&#32676;&#26377;&#23475;&#23454;&#39564;&#30340;&#26089;&#26399;&#20572;&#27490;&#26041;&#27861;CLASH&#65292;&#20351;&#29992;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#21487;&#20197;&#26377;&#25928;&#25552;&#21069;&#20572;&#27490;&#20020;&#24202;&#35797;&#39564;&#21644;A/B&#27979;&#35797;&#12290;</title><link>http://arxiv.org/abs/2306.11839</link><description>&lt;p&gt;
&#26159;&#21542;&#24212;&#35813;&#20572;&#27490;&#65306;&#20855;&#26377;&#24322;&#36136;&#31181;&#32676;&#30340;&#26089;&#26399;&#20572;&#27490;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Should I Stop or Should I Go: Early Stopping with Heterogeneous Populations. (arXiv:2306.11839v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11839
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#20110;&#24322;&#36136;&#31181;&#32676;&#26377;&#23475;&#23454;&#39564;&#30340;&#26089;&#26399;&#20572;&#27490;&#26041;&#27861;CLASH&#65292;&#20351;&#29992;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#21487;&#20197;&#26377;&#25928;&#25552;&#21069;&#20572;&#27490;&#20020;&#24202;&#35797;&#39564;&#21644;A/B&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#23454;&#39564;&#30001;&#20110;&#27835;&#30103;&#36896;&#25104;&#24847;&#22806;&#30340;&#26377;&#23475;&#24433;&#21709;&#65292;&#22240;&#27492;&#24448;&#24448;&#38656;&#35201;&#25552;&#21069;&#20572;&#27490;&#12290;&#30446;&#21069;&#30830;&#23450;&#20309;&#26102;&#25552;&#21069;&#32456;&#27490;&#23454;&#39564;&#30340;&#29616;&#26377;&#26041;&#27861;&#36890;&#24120;&#36866;&#29992;&#20110;&#24635;&#20307;&#25968;&#25454;&#65292;&#19981;&#32771;&#34385;&#27835;&#30103;&#25928;&#24212;&#30340;&#24322;&#36136;&#24615;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#38024;&#23545;&#24322;&#36136;&#31181;&#32676;&#26377;&#23475;&#23454;&#39564;&#30340;&#26089;&#26399;&#20572;&#27490;&#26041;&#27861;&#12290;&#25105;&#20204;&#39318;&#20808;&#30830;&#23450;&#29616;&#26377;&#26041;&#27861;&#22312;&#27835;&#30103;&#23545;&#23569;&#25968;&#21442;&#19982;&#32773;&#36896;&#25104;&#20260;&#23475;&#26102;&#24448;&#24448;&#26080;&#27861;&#20572;&#27490;&#23454;&#39564;&#12290;&#28982;&#21518;&#20351;&#29992;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#24320;&#21457;&#20102;CLASH&#65292;&#36825;&#26159;&#39318;&#20010;&#24191;&#27867;&#36866;&#29992;&#20110;&#24322;&#36136;&#26089;&#26399;&#20572;&#27490;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#22312;&#27169;&#25311;&#21644;&#23454;&#38469;&#25968;&#25454;&#19978;&#23637;&#31034;&#20102;CLASH&#30340;&#34920;&#29616;&#65292;&#24182;&#35777;&#26126;&#23427;&#22312;&#20020;&#24202;&#35797;&#39564;&#21644;A/B&#27979;&#35797;&#20013;&#37117;&#33021;&#26377;&#25928;&#25552;&#21069;&#20572;&#27490;&#12290;
&lt;/p&gt;
&lt;p&gt;
Randomized experiments often need to be stopped prematurely due to the treatment having an unintended harmful effect. Existing methods that determine when to stop an experiment early are typically applied to the data in aggregate and do not account for treatment effect heterogeneity. In this paper, we study the early stopping of experiments for harm on heterogeneous populations. We first establish that current methods often fail to stop experiments when the treatment harms a minority group of participants. We then use causal machine learning to develop CLASH, the first broadly-applicable method for heterogeneous early stopping. We demonstrate CLASH's performance on simulated and real data and show that it yields effective early stopping for both clinical trials and A/B tests.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25581;&#31034;&#20102;&#23454;&#29992;&#30340;&#38160;&#24230;&#24863;&#30693;&#20248;&#21270;&#31639;&#27861;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#19981;&#33021;&#22815;&#20840;&#31243;&#21521;&#26368;&#20248;&#28857;&#25910;&#25947;&#12290;</title><link>http://arxiv.org/abs/2306.09850</link><description>&lt;p&gt;
&#23454;&#29992;&#30340;&#38160;&#24230;&#24863;&#30693;&#20248;&#21270;&#31639;&#27861;&#19981;&#33021;&#20840;&#31243;&#21521;&#26368;&#20248;&#28857;&#25910;&#25947;
&lt;/p&gt;
&lt;p&gt;
Practical Sharpness-Aware Minimization Cannot Converge All the Way to Optima. (arXiv:2306.09850v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09850
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25581;&#31034;&#20102;&#23454;&#29992;&#30340;&#38160;&#24230;&#24863;&#30693;&#20248;&#21270;&#31639;&#27861;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#19981;&#33021;&#22815;&#20840;&#31243;&#21521;&#26368;&#20248;&#28857;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38160;&#24230;&#24863;&#30693;&#20248;&#21270;(SAM)&#26159;&#19968;&#31181;&#20248;&#21270;&#22120;&#65292;&#23427;&#22522;&#20110;&#24403;&#21069;&#28857;$x_t$&#30340;&#26799;&#24230;&#65292;&#22312;&#25200;&#21160;$y_t=x_t+\rho\frac{\nabla f(x_t)}{\lVert\nabla f(x_t)\rVert}$&#22788;&#36827;&#34892;&#19979;&#38477;&#12290;&#29616;&#26377;&#30740;&#31350;&#35777;&#26126;&#20102;SAM&#23545;&#20110;&#24179;&#28369;&#20989;&#25968;&#30340;&#25910;&#25947;&#24615;&#65292;&#20294;&#26159;&#23427;&#20204;&#20551;&#35774;&#25200;&#21160;&#30340;&#22823;&#23567;$\rho$&#36880;&#28176;&#34928;&#20943;&#21644;/&#25110;&#22312;$y_t$&#20013;&#27809;&#26377;&#26799;&#24230;&#24402;&#19968;&#21270;&#65292;&#36825;&#19982;&#23454;&#36341;&#19981;&#31526;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#23454;&#29992;&#37197;&#32622;&#65288;&#21363;&#24120;&#25968;$\rho$&#21644;$y_t$&#20013;&#30340;&#26799;&#24230;&#24402;&#19968;&#21270;&#65289;&#30340;&#30830;&#23450;&#24615;/&#38543;&#26426;&#29256;&#26412;&#30340;SAM&#65292;&#24182;&#25506;&#35752;&#20102;&#23427;&#20204;&#22312;&#20855;&#26377;&#65288;&#38750;&#65289;&#20984;&#24615;&#20551;&#35774;&#30340;&#24179;&#28369;&#20989;&#25968;&#19978;&#30340;&#25910;&#25947;&#24615;&#36136;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#21457;&#29616;SAM&#22312;&#25910;&#25947;&#21040;&#20840;&#23616;&#26368;&#23567;&#20540;&#25110;&#31283;&#23450;&#28857;&#26041;&#38754;&#20855;&#26377;&#26377;&#38480;&#30340;&#33021;&#21147;&#12290;&#23545;&#20110;&#24179;&#28369;&#24378;&#20984;&#20989;&#25968;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#30830;&#23450;&#24615;SAM&#20855;&#26377;&#20005;&#26684;&#30340;&#20840;&#23616;&#25910;&#25947;&#29575;&#20026;$\tilde\Theta(\frac{1}{T^2})$&#65292;&#32780;&#38543;&#26426;SAM&#30340;&#25910;&#25947;&#30028;&#21017;&#21463;&#21040;&#22122;&#22768;&#27700;&#24179;&#38477;&#20302;&#30340;&#24433;&#21709;&#65292;&#36825;&#34920;&#26126;&#20102;&#24179;&#38754;&#30446;&#26631;&#34920;&#38754;&#30340;&#23574;&#38160;&#24230;&#21644;&#24179;&#32531;&#24615;&#20043;&#38388;&#24179;&#34913;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sharpness-Aware Minimization (SAM) is an optimizer that takes a descent step based on the gradient at a perturbation $y_t = x_t + \rho \frac{\nabla f(x_t)}{\lVert \nabla f(x_t) \rVert}$ of the current point $x_t$. Existing studies prove convergence of SAM for smooth functions, but they do so by assuming decaying perturbation size $\rho$ and/or no gradient normalization in $y_t$, which is detached from practice. To address this gap, we study deterministic/stochastic versions of SAM with practical configurations (i.e., constant $\rho$ and gradient normalization in $y_t$) and explore their convergence properties on smooth functions with (non)convexity assumptions. Perhaps surprisingly, in many scenarios, we find out that SAM has limited capability to converge to global minima or stationary points. For smooth strongly convex functions, we show that while deterministic SAM enjoys tight global convergence rates of $\tilde \Theta(\frac{1}{T^2})$, the convergence bound of stochastic SAM suffer
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#12289;&#19981;&#38656;&#35201;&#23454;&#29616;&#24433;&#21709;&#20989;&#25968;&#19988;&#21487;&#35745;&#31639;&#30340;&#21435;&#20559;&#25554;&#20540;&#20272;&#35745;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.08598</link><description>&lt;p&gt;
&#26680;&#21435;&#20559;&#25554;&#20540;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Kernel Debiased Plug-in Estimation. (arXiv:2306.08598v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.08598
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#12289;&#19981;&#38656;&#35201;&#23454;&#29616;&#24433;&#21709;&#20989;&#25968;&#19988;&#21487;&#35745;&#31639;&#30340;&#21435;&#20559;&#25554;&#20540;&#20272;&#35745;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#22312;&#24178;&#25200;&#21442;&#25968;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#26631;&#37327;&#30446;&#26631;&#21442;&#25968;&#30340;&#38382;&#39064;&#12290;&#37319;&#29992;&#38750;&#21442;&#25968;&#20272;&#35745;&#22120;&#65288;&#20363;&#22914;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#27169;&#22411;&#65289;&#26367;&#25442;&#26410;&#30693;&#24178;&#25200;&#21442;&#25968;&#26159;&#26041;&#20415;&#30340;&#65292;&#20294;&#22240;&#23384;&#22312;&#36739;&#22823;&#20559;&#24046;&#32780;&#25928;&#29575;&#20302;&#19979;&#12290;&#20026;&#20102;&#36991;&#20813;&#20559;&#24046;-&#26041;&#24046;&#26435;&#34913;&#30340;&#27425;&#20248;&#36873;&#25321;&#65292;&#29616;&#20195;&#26041;&#27861;&#20250;&#36827;&#34892;&#25554;&#20540;&#39044;&#20272;&#30340;&#21435;&#20559;&#24046;&#25805;&#20316;&#65292;&#22914;&#26377;&#30446;&#26631;&#26368;&#23567;&#25439;&#22833;&#20272;&#35745;&#65288;TMLE&#65289;&#21644;&#21452;&#26426;&#22120;&#23398;&#20064;&#65288;DML&#65289;&#31561;&#12290;&#29616;&#26377;&#30340;&#21435;&#20559;&#26041;&#27861;&#38656;&#35201;&#23558;&#30446;&#26631;&#21442;&#25968;&#30340;&#24433;&#21709;&#20989;&#25968;&#65288;IF&#65289;&#20316;&#20026;&#36755;&#20837;&#65292;&#28982;&#32780;&#65292;IF&#30340;&#25512;&#23548;&#38656;&#35201;&#19987;&#19994;&#30693;&#35782;&#65292;&#20174;&#32780;&#38459;&#30861;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#36866;&#24212;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#25554;&#20837;&#20272;&#35745;&#22120;&#30340;&#26041;&#27861;&#65292;&#23427;&#65288;i&#65289;&#39640;&#25928;&#12289;&#65288;ii&#65289;&#19981;&#38656;&#35201;&#23454;&#29616;IF&#12289;&#65288;iii&#65289;&#21487;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of estimating a scalar target parameter in the presence of nuisance parameters. Replacing the unknown nuisance parameter with a nonparametric estimator, e.g.,a machine learning (ML) model, is convenient but has shown to be inefficient due to large biases. Modern methods, such as the targeted minimum loss-based estimation (TMLE) and double machine learning (DML), achieve optimal performance under flexible assumptions by harnessing ML estimates while mitigating the plug-in bias. To avoid a sub-optimal bias-variance trade-off, these methods perform a debiasing step of the plug-in pre-estimate. Existing debiasing methods require the influence function of the target parameter as input. However, deriving the IF requires specialized expertise and thus obstructs the adaptation of these methods by practitioners. We propose a novel way to debias plug-in estimators which (i) is efficient, (ii) does not require the IF to be implemented, (iii) is computationally tractable, a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22788;&#29702;&#36873;&#25321;&#24615;&#26631;&#35760;&#25968;&#25454;&#30340;&#23398;&#20064;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#21033;&#29992;&#21382;&#21490;&#20915;&#31574;&#30001;&#19968;&#32452;&#24322;&#36136;&#20915;&#31574;&#32773;&#20570;&#20986;&#30340;&#20107;&#23454;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#31181;&#26377;&#21407;&#29702;&#30340;&#24037;&#20855;&#21464;&#37327;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#26435;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#39044;&#27979;&#35268;&#21017;&#12290;</title><link>http://arxiv.org/abs/2306.07566</link><description>&lt;p&gt;
&#23398;&#20064;&#36873;&#25321;&#26631;&#31614;&#19979;&#30340;&#24322;&#36136;&#20915;&#31574;&#32773;&#65306;&#19968;&#31181;&#24037;&#20855;&#21464;&#37327;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Learning under Selective Labels with Heterogeneous Decision-makers: An Instrumental Variable Approach. (arXiv:2306.07566v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07566
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22788;&#29702;&#36873;&#25321;&#24615;&#26631;&#35760;&#25968;&#25454;&#30340;&#23398;&#20064;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#21033;&#29992;&#21382;&#21490;&#20915;&#31574;&#30001;&#19968;&#32452;&#24322;&#36136;&#20915;&#31574;&#32773;&#20570;&#20986;&#30340;&#20107;&#23454;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#31181;&#26377;&#21407;&#29702;&#30340;&#24037;&#20855;&#21464;&#37327;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#26435;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#39044;&#27979;&#35268;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#36873;&#25321;&#24615;&#26631;&#35760;&#25968;&#25454;&#19979;&#30340;&#23398;&#20064;&#38382;&#39064;&#12290;&#36825;&#31181;&#38382;&#39064;&#22312;&#21382;&#21490;&#20915;&#31574;&#23548;&#33268;&#32467;&#26524;&#20165;&#37096;&#20998;&#26631;&#35760;&#26102;&#20986;&#29616;&#12290;&#26631;&#35760;&#25968;&#25454;&#20998;&#24067;&#21487;&#33021;&#19982;&#25972;&#20307;&#20154;&#32676;&#26377;&#26174;&#33879;&#24046;&#24322;&#65292;&#29305;&#21035;&#26159;&#24403;&#21382;&#21490;&#20915;&#31574;&#21644;&#30446;&#26631;&#32467;&#26524;&#21487;&#20197;&#21516;&#26102;&#21463;&#26576;&#20123;&#26410;&#35266;&#23519;&#21040;&#30340;&#22240;&#32032;&#24433;&#21709;&#26102;&#12290;&#22240;&#27492;&#65292;&#20165;&#22522;&#20110;&#26631;&#35760;&#25968;&#25454;&#36827;&#34892;&#23398;&#20064;&#21487;&#33021;&#20250;&#23548;&#33268;&#22312;&#25972;&#20307;&#20154;&#32676;&#20013;&#30340;&#20005;&#37325;&#20559;&#24046;&#12290;&#25105;&#20204;&#30340;&#35770;&#25991;&#36890;&#36807;&#21033;&#29992;&#35768;&#22810;&#24212;&#29992;&#20013;&#21382;&#21490;&#20915;&#31574;&#30001;&#19968;&#32452;&#24322;&#36136;&#20915;&#31574;&#32773;&#20570;&#20986;&#30340;&#20107;&#23454;&#26469;&#35299;&#20915;&#27492;&#25361;&#25112;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#22312;&#19968;&#20010;&#26377;&#21407;&#29702;&#30340;&#24037;&#20855;&#21464;&#37327;&#26694;&#26550;&#19979;&#20998;&#26512;&#20102;&#36825;&#31181;&#35774;&#32622;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#28385;&#36275;&#35266;&#23519;&#21040;&#30340;&#25968;&#25454;&#26102;&#20219;&#20309;&#32473;&#23450;&#39044;&#27979;&#35268;&#21017;&#30340;&#20840;&#20307;&#39118;&#38505;&#30340;&#28857;&#35782;&#21035;&#26465;&#20214;&#65292;&#24182;&#22312;&#28857;&#35782;&#21035;&#22833;&#36133;&#26102;&#25552;&#20379;&#20102;&#23574;&#38160;&#30340;&#39118;&#38505;&#30028;&#38480;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#26435;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#39044;&#27979;&#35268;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of learning with selectively labeled data, which arises when outcomes are only partially labeled due to historical decision-making. The labeled data distribution may substantially differ from the full population, especially when the historical decisions and the target outcome can be simultaneously affected by some unobserved factors. Consequently, learning with only the labeled data may lead to severely biased results when deployed to the full population. Our paper tackles this challenge by exploiting the fact that in many applications the historical decisions were made by a set of heterogeneous decision-makers. In particular, we analyze this setup in a principled instrumental variable (IV) framework. We establish conditions for the full-population risk of any given prediction rule to be point-identified from the observed data and provide sharp risk bounds when the point identification fails. We further propose a weighted learning approach that learns prediction ru
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#21457;&#29616;&#65292;&#22914;&#26524;&#36873;&#25321;&#35268;&#21017;&#28385;&#36275;&#32622;&#25442;&#19981;&#21464;&#24615;&#21644;&#36229;&#24635;&#20307;&#20855;&#26377;&#32852;&#21512;&#21487;&#20132;&#25442;&#24615;&#26465;&#20214;&#65292;&#21017;&#38750;&#22343;&#21248;&#25277;&#26679;&#19979;&#32593;&#32476;&#25968;&#25454;&#20013;&#31526;&#21512;&#24615;&#39044;&#27979;&#20855;&#26377;&#26377;&#25928;&#24615;&#65292;&#32780;&#23545;&#20110;&#19982;&#33258;&#25105;&#32593;&#32476;&#21644;&#38634;&#29699;&#25277;&#26679;&#30456;&#20851;&#30340;&#26576;&#20123;&#36873;&#25321;&#20107;&#20214;&#65292;&#31526;&#21512;&#24615;&#39044;&#27979;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#26377;&#25928;&#24615;</title><link>http://arxiv.org/abs/2306.07252</link><description>&lt;p&gt;
&#38750;&#22343;&#21248;&#25277;&#26679;&#19979;&#32593;&#32476;&#25968;&#25454;&#20013;&#31526;&#21512;&#24615;&#39044;&#27979;&#30340;&#26377;&#25928;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Validity of Conformal Prediction for Network Data Under Non-Uniform Sampling. (arXiv:2306.07252v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07252
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#21457;&#29616;&#65292;&#22914;&#26524;&#36873;&#25321;&#35268;&#21017;&#28385;&#36275;&#32622;&#25442;&#19981;&#21464;&#24615;&#21644;&#36229;&#24635;&#20307;&#20855;&#26377;&#32852;&#21512;&#21487;&#20132;&#25442;&#24615;&#26465;&#20214;&#65292;&#21017;&#38750;&#22343;&#21248;&#25277;&#26679;&#19979;&#32593;&#32476;&#25968;&#25454;&#20013;&#31526;&#21512;&#24615;&#39044;&#27979;&#20855;&#26377;&#26377;&#25928;&#24615;&#65292;&#32780;&#23545;&#20110;&#19982;&#33258;&#25105;&#32593;&#32476;&#21644;&#38634;&#29699;&#25277;&#26679;&#30456;&#20851;&#30340;&#26576;&#20123;&#36873;&#25321;&#20107;&#20214;&#65292;&#31526;&#21512;&#24615;&#39044;&#27979;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#26377;&#25928;&#24615;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#38024;&#23545;&#24120;&#35265;&#38750;&#20195;&#34920;&#24615;&#33410;&#28857;&#37319;&#26679;&#26426;&#21046;&#19979;&#30340;&#32593;&#32476;&#25968;&#25454;&#31526;&#21512;&#24615;&#39044;&#27979;&#30340;&#24615;&#36136;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123;&#37319;&#26679;&#26426;&#21046;&#35299;&#37322;&#20026;&#24212;&#29992;&#20110;&#36229;&#24635;&#20307;&#30340;&#36873;&#25321;&#35268;&#21017;&#65292;&#24182;&#22312;&#36866;&#24403;&#30340;&#36873;&#25321;&#20107;&#20214;&#26465;&#20214;&#19979;&#30740;&#31350;&#31526;&#21512;&#24615;&#39044;&#27979;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#65292;&#22914;&#26524;&#36873;&#25321;&#35268;&#21017;&#28385;&#36275;&#32622;&#25442;&#19981;&#21464;&#24615;&#21644;&#36229;&#24635;&#20307;&#20855;&#26377;&#32852;&#21512;&#21487;&#20132;&#25442;&#24615;&#26465;&#20214;&#65292;&#21017;&#37319;&#26679;&#23376;&#38453;&#21015;&#22312;&#36873;&#25321;&#20107;&#20214;&#26465;&#20214;&#19979;&#26159;&#21487;&#20132;&#25442;&#30340;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#24847;&#21619;&#30528;&#23545;&#20110;&#19982;&#33258;&#25105;&#32593;&#32476;&#21644;&#38634;&#29699;&#25277;&#26679;&#30456;&#20851;&#30340;&#26576;&#20123;&#36873;&#25321;&#20107;&#20214;&#65292;&#31526;&#21512;&#24615;&#39044;&#27979;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#36824;&#34920;&#26126;&#65292;&#24403;&#25968;&#25454;&#36890;&#36807;&#22270;&#19978;&#30340;&#38543;&#26426;&#28216;&#36208;&#26469;&#37319;&#26679;&#26102;&#65292;&#21152;&#26435;&#31526;&#21512;&#24615;&#39044;&#27979;&#30340;&#21464;&#20307;&#21487;&#20197;&#23545;&#20154;&#21475;&#29420;&#31435;&#36873;&#25321;&#33410;&#28857;&#30340;&#39044;&#27979;&#38598;&#36827;&#34892;&#28176;&#36817;&#26377;&#25928;&#30340;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the properties of conformal prediction for network data under various sampling mechanisms that commonly arise in practice but often result in a non-representative sample of nodes. We interpret these sampling mechanisms as selection rules applied to a superpopulation and study the validity of conformal prediction conditional on an appropriate selection event. We show that the sampled subarray is exchangeable conditional on the selection event if the selection rule satisfies a permutation invariance property and a joint exchangeability condition holds for the superpopulation. Our result implies the finite-sample validity of conformal prediction for certain selection events related to ego networks and snowball sampling. We also show that when data are sampled via a random walk on a graph, a variant of weighted conformal prediction yields asymptotically valid prediction sets for an independently selected node from the population.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32771;&#34385;&#25915;&#20987;&#23545;&#36229;&#21442;&#25968;&#24433;&#21709;&#30340;&#26368;&#20248;&#25915;&#20987;&#20844;&#24335;&#65292;&#23558;&#25915;&#20987;&#24314;&#27169;&#20026;&#22810;&#30446;&#26631;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#35780;&#20272;&#31639;&#27861;&#40065;&#26834;&#24615;&#21644;&#23398;&#20064;&#36229;&#21442;&#25968;&#65292;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#35780;&#20272;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2306.01613</link><description>&lt;p&gt;
&#25968;&#25454;&#27745;&#26579;&#19979;&#30340;&#36229;&#21442;&#25968;&#23398;&#20064;&#65306;&#22522;&#20110;&#22810;&#30446;&#26631;&#20108;&#23618;&#20248;&#21270;&#30340;&#27491;&#21017;&#21270;&#24433;&#21709;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Hyperparameter Learning under Data Poisoning: Analysis of the Influence of Regularization via Multiobjective Bilevel Optimization. (arXiv:2306.01613v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01613
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32771;&#34385;&#25915;&#20987;&#23545;&#36229;&#21442;&#25968;&#24433;&#21709;&#30340;&#26368;&#20248;&#25915;&#20987;&#20844;&#24335;&#65292;&#23558;&#25915;&#20987;&#24314;&#27169;&#20026;&#22810;&#30446;&#26631;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#35780;&#20272;&#31639;&#27861;&#40065;&#26834;&#24615;&#21644;&#23398;&#20064;&#36229;&#21442;&#25968;&#65292;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#35780;&#20272;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#23481;&#26131;&#36973;&#21463;&#25968;&#25454;&#27745;&#26579;&#25915;&#20987;&#65292;&#21363;&#36890;&#36807;&#25805;&#32437;&#37096;&#20998;&#35757;&#32451;&#25968;&#25454;&#26469;&#26377;&#24847;&#30772;&#22351;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;&#26368;&#20248;&#25915;&#20987;&#21487;&#20197;&#34987;&#21046;&#23450;&#20026;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#26377;&#21161;&#20110;&#22312;&#26368;&#22351;&#24773;&#20917;&#19979;&#35780;&#20272;&#31639;&#27861;&#30340;&#24378;&#20581;&#24615;&#12290;&#25105;&#20204;&#21457;&#29616;&#24403;&#21069;&#30340;&#26041;&#27861;&#36890;&#24120;&#20551;&#23450;&#36229;&#21442;&#25968;&#20445;&#25345;&#19981;&#21464;&#65292;&#36825;&#23548;&#33268;&#20102;&#23545;&#31639;&#27861;&#40065;&#26834;&#24615;&#21644;&#27491;&#21017;&#21270;&#24433;&#21709;&#30340;&#36807;&#20110;&#24754;&#35266;&#30340;&#35266;&#28857;&#12290;&#22240;&#27492;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26368;&#20248;&#25915;&#20987;&#20844;&#24335;&#65292;&#32771;&#34385;&#25915;&#20987;&#23545;&#36229;&#21442;&#25968;&#30340;&#24433;&#21709;&#65292;&#24182;&#23558;&#25915;&#20987;&#24314;&#27169;&#20026;&#22810;&#30446;&#26631;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#12290;&#36825;&#20801;&#35768;&#21046;&#23450;&#26368;&#20248;&#25915;&#20987;&#12289;&#23398;&#20064;&#36229;&#21442;&#25968;&#24182;&#22312;&#26368;&#22351;&#24773;&#20917;&#19979;&#35780;&#20272;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#23558;&#27492;&#25915;&#20987;&#20844;&#24335;&#24212;&#29992;&#20110;&#20351;&#29992;$L_2$&#21644;$L_1$&#27491;&#21017;&#21270;&#30340;&#22810;&#20010;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#22120;&#19978;&#12290;&#25105;&#20204;&#23545;&#22810;&#20010;&#25968;&#25454;&#38598;&#30340;&#35780;&#20272;&#30830;&#35748;&#20102;&#20808;&#21069;&#31574;&#30053;&#30340;&#38480;&#21046;&#65292;&#24182;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#20855;&#26377;&#26356;&#31934;&#30830;&#30340;&#40065;&#26834;&#24615;&#35780;&#20272;&#21644;&#22312;&#23384;&#22312;&#25968;&#25454;&#27745;&#26579;&#25915;&#20987;&#26102;&#26356;&#26377;&#25928;&#22320;&#23398;&#20064;&#36229;&#21442;&#25968;&#30340;&#20248;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine Learning (ML) algorithms are vulnerable to poisoning attacks, where a fraction of the training data is manipulated to deliberately degrade the algorithms' performance. Optimal attacks can be formulated as bilevel optimization problems and help to assess their robustness in worst-case scenarios. We show that current approaches, which typically assume that hyperparameters remain constant, lead to an overly pessimistic view of the algorithms' robustness and of the impact of regularization. We propose a novel optimal attack formulation that considers the effect of the attack on the hyperparameters and models the attack as a multiobjective bilevel optimization problem. This allows to formulate optimal attacks, learn hyperparameters and evaluate robustness under worst-case conditions. We apply this attack formulation to several ML classifiers using $L_2$ and $L_1$ regularization. Our evaluation on multiple datasets confirms the limitations of previous strategies and evidences the ben
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#33021;&#37327;&#22522;&#27169;&#22411;&#30340;&#35757;&#32451;&#31639;&#27861;&#65292;&#20351;&#29992;&#24402;&#19968;&#21270;&#27969;&#36827;&#34892;&#37319;&#26679;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#32479;&#35745;&#31934;&#24230;&#21644;&#29983;&#25104;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.00684</link><description>&lt;p&gt;
&#20351;&#29992;&#33258;&#36866;&#24212;&#27969;&#37319;&#26679;&#24179;&#34913;&#35757;&#32451;&#33021;&#37327;&#22522;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Balanced Training of Energy-Based Models with Adaptive Flow Sampling. (arXiv:2306.00684v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00684
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#33021;&#37327;&#22522;&#27169;&#22411;&#30340;&#35757;&#32451;&#31639;&#27861;&#65292;&#20351;&#29992;&#24402;&#19968;&#21270;&#27969;&#36827;&#34892;&#37319;&#26679;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#32479;&#35745;&#31934;&#24230;&#21644;&#29983;&#25104;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33021;&#37327;&#22522;&#27169;&#22411; (EBM) &#26159;&#19968;&#31181;&#30452;&#25509;&#21442;&#25968;&#21270;&#26410;&#26631;&#20934;&#21270;&#23545;&#25968;&#23494;&#24230;&#30340;&#22810;&#21151;&#33021;&#23494;&#24230;&#20272;&#35745;&#27169;&#22411;&#12290;EBM &#38750;&#24120;&#28789;&#27963;&#65292;&#20294;&#32570;&#20047;&#27169;&#22411;&#30340;&#35268;&#33539;&#21270;&#24120;&#37327;&#65292;&#20351;&#27169;&#22411;&#30340;&#20284;&#28982;&#20989;&#25968;&#35745;&#31639;&#19981;&#21487;&#34892;&#12290;&#36817;&#24180;&#26469;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#35768;&#22810;&#36817;&#20284;&#37319;&#26679;&#22120;&#21644;&#21464;&#20998;&#25512;&#29702;&#25216;&#26415;&#26469;&#20272;&#35745;&#20284;&#28982;&#20989;&#25968;&#26799;&#24230;&#36827;&#34892;&#35757;&#32451;&#12290;&#36825;&#20123;&#25216;&#26415;&#22312;&#29983;&#25104;&#26679;&#26412;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#23545;&#20110;&#20272;&#35745;&#23494;&#24230;&#30340;&#32479;&#35745;&#31934;&#24230;&#65292;&#20363;&#22914;&#30830;&#23450;&#25968;&#25454;&#38598;&#20013;&#19981;&#21516;&#31867;&#30340;&#30456;&#23545;&#37325;&#35201;&#24615;&#65292;&#21364;&#20184;&#20986;&#20102;&#24456;&#23569;&#30340;&#20851;&#27880;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26368;&#22823;&#20284;&#28982;&#35757;&#32451;&#31639;&#27861;&#65292;&#20351;&#29992;&#19968;&#31181;&#19981;&#21516;&#31867;&#22411;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#24402;&#19968;&#21270;&#27969; (NF)&#65292;&#36825;&#31181;&#27169;&#22411;&#26368;&#36817;&#34987;&#25552;&#20986;&#20197;&#20415;&#20110;&#37319;&#26679;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#23558; NF &#25311;&#21512;&#21040; EBM &#19978;&#65292;&#20197;&#20415; NF &#36741;&#21161;&#19979;&#30340;&#37319;&#26679;&#26041;&#26696;&#33021;&#22815;&#22987;&#32456;&#20026; EBM &#25552;&#20379;&#20934;&#30830;&#30340;&#26799;&#24230;&#65292;&#26368;&#32456;&#25552;&#39640;&#27169;&#22411;&#30340;&#32479;&#35745;&#31934;&#24230;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#20256;&#32479; EBM &#35757;&#32451;&#25216;&#26415;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20135;&#29983;&#20102;&#26356;&#39640;&#36136;&#37327;&#30340;&#26679;&#26412;&#21644;&#26356;&#22909;&#30340;&#29983;&#25104;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Energy-based models (EBMs) are versatile density estimation models that directly parameterize an unnormalized log density. Although very flexible, EBMs lack a specified normalization constant of the model, making the likelihood of the model computationally intractable. Several approximate samplers and variational inference techniques have been proposed to estimate the likelihood gradients for training. These techniques have shown promising results in generating samples, but little attention has been paid to the statistical accuracy of the estimated density, such as determining the relative importance of different classes in a dataset. In this work, we propose a new maximum likelihood training algorithm for EBMs that uses a different type of generative model, normalizing flows (NF), which have recently been proposed to facilitate sampling. Our method fits an NF to an EBM during training so that an NF-assisted sampling scheme provides an accurate gradient for the EBMs at all times, ultim
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#20302;&#31209;&#25193;&#23637;&#21345;&#23572;&#26364;&#28388;&#27874;&#30340;&#39640;&#25928;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#20854;&#33021;&#22815;&#20272;&#35745;&#38750;&#32447;&#24615;&#20989;&#25968;&#30340;&#21442;&#25968;&#65292;&#20855;&#26377;&#26356;&#24555;&#30340;&#36866;&#24212;&#24615;&#21644;&#26356;&#24555;&#30340;&#22870;&#21169;&#31215;&#32047;&#12290;</title><link>http://arxiv.org/abs/2305.19535</link><description>&lt;p&gt;
&#22522;&#20110;&#27969;&#25968;&#25454;&#30340;&#31070;&#32463;&#32593;&#32476;&#22312;&#32447;&#23398;&#20064;&#30340;&#20302;&#31209;&#25193;&#23637;&#21345;&#23572;&#26364;&#28388;&#27874;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Low-rank extended Kalman filtering for online learning of neural networks from streaming data. (arXiv:2305.19535v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19535
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#20302;&#31209;&#25193;&#23637;&#21345;&#23572;&#26364;&#28388;&#27874;&#30340;&#39640;&#25928;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#20854;&#33021;&#22815;&#20272;&#35745;&#38750;&#32447;&#24615;&#20989;&#25968;&#30340;&#21442;&#25968;&#65292;&#20855;&#26377;&#26356;&#24555;&#30340;&#36866;&#24212;&#24615;&#21644;&#26356;&#24555;&#30340;&#22870;&#21169;&#31215;&#32047;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#22312;&#32447;&#36817;&#20284;&#36125;&#21494;&#26031;&#25512;&#29702;&#31639;&#27861;&#65292;&#29992;&#20110;&#20174;&#21487;&#33021;&#38750;&#24179;&#31283;&#30340;&#25968;&#25454;&#27969;&#20013;&#20272;&#35745;&#38750;&#32447;&#24615;&#20989;&#25968;&#30340;&#21442;&#25968;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#25193;&#23637;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;EKF&#65289;&#65292;&#20294;&#20351;&#29992;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20302;&#31209;&#21152;&#23545;&#35282;&#32447;&#30340;&#21518;&#39564;&#31934;&#24230;&#30697;&#38453;&#20998;&#35299;&#65292;&#20854;&#27599;&#27493;&#30340;&#25104;&#26412;&#19982;&#27169;&#22411;&#21442;&#25968;&#25968;&#37327;&#25104;&#32447;&#24615;&#20851;&#31995;&#12290;&#19982;&#22522;&#20110;&#38543;&#26426;&#21464;&#20998;&#25512;&#29702;&#30340;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#23436;&#20840;&#30830;&#23450;&#30340;&#65292;&#24182;&#19988;&#19981;&#38656;&#35201;&#27493;&#38271;&#35843;&#25972;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#23548;&#33268;&#26356;&#24555;&#65288;&#26356;&#39640;&#25928;&#65289;&#30340;&#23398;&#20064;&#65292;&#20174;&#32780;&#22312;&#29992;&#20316;&#19978;&#19979;&#25991;&#36172;&#21338;&#31639;&#27861;&#30340;&#19968;&#37096;&#20998;&#26102;&#23454;&#29616;&#26356;&#24555;&#36895;&#30340;&#36866;&#24212;&#24615;&#21644;&#26356;&#24555;&#30340;&#22870;&#21169;&#31215;&#32047;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose an efficient online approximate Bayesian inference algorithm for estimating the parameters of a nonlinear function from a potentially non-stationary data stream. The method is based on the extended Kalman filter (EKF), but uses a novel low-rank plus diagonal decomposition of the posterior precision matrix, which gives a cost per step which is linear in the number of model parameters. In contrast to methods based on stochastic variational inference, our method is fully deterministic, and does not require step-size tuning. We show experimentally that this results in much faster (more sample efficient) learning, which results in more rapid adaptation to changing distributions, and faster accumulation of reward when used as part of a contextual bandit algorithm.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;Bayesian&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#26469;&#21387;&#32553;&#25968;&#25454;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270; $\beta$-ELBO &#30452;&#25509;&#20248;&#21270;&#30721;-&#22833;&#30495;&#24615;&#33021;&#65292;&#24182;&#36890;&#36807;&#35843;&#25972; $\beta$ &#26469;&#38024;&#23545;&#32473;&#23450;&#30340;&#32593;&#32476;&#32467;&#26500;&#23454;&#29616;&#19981;&#21516;&#30340;&#30721;-&#22833;&#30495;&#24179;&#34913;&#12290;</title><link>http://arxiv.org/abs/2305.19185</link><description>&lt;p&gt;
Bayesian&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#19979;&#30340;&#21387;&#32553;
&lt;/p&gt;
&lt;p&gt;
Compression with Bayesian Implicit Neural Representations. (arXiv:2305.19185v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19185
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;Bayesian&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#26469;&#21387;&#32553;&#25968;&#25454;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270; $\beta$-ELBO &#30452;&#25509;&#20248;&#21270;&#30721;-&#22833;&#30495;&#24615;&#33021;&#65292;&#24182;&#36890;&#36807;&#35843;&#25972; $\beta$ &#26469;&#38024;&#23545;&#32473;&#23450;&#30340;&#32593;&#32476;&#32467;&#26500;&#23454;&#29616;&#19981;&#21516;&#30340;&#30721;-&#22833;&#30495;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#24120;&#35265;&#31867;&#22411;&#30340;&#25968;&#25454;&#21487;&#20197;&#34920;&#31034;&#20026;&#23558;&#22352;&#26631;&#26144;&#23556;&#21040;&#20449;&#21495;&#20540;&#30340;&#20989;&#25968;&#65292;&#20363;&#22914;&#22270;&#20687;&#20013;&#30340;&#20687;&#32032;&#20301;&#32622;&#21040;RGB&#20540;&#12290;&#22522;&#20110;&#36825;&#20010;&#35266;&#28857;&#65292;&#21487;&#20197;&#36890;&#36807;&#23545;&#25968;&#25454;&#30340;&#21151;&#33021;&#34920;&#31034;&#36827;&#34892;&#36229;&#25311;&#21512;&#65292;&#28982;&#21518;&#32534;&#30721;&#32593;&#32476;&#26435;&#37325;&#26469;&#21387;&#32553;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#24403;&#21069;&#30340;&#35299;&#20915;&#26041;&#26696;&#37117;&#25928;&#29575;&#20302;&#19979;&#65292;&#22240;&#20026;&#23558;&#31934;&#24230;&#37327;&#21270;&#21040;&#20302;&#27604;&#29305;&#20250;&#22823;&#24133;&#38477;&#20302;&#37325;&#26500;&#36136;&#37327;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36807;&#24230;&#25311;&#21512;&#21464;&#20998;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#26469;&#21387;&#32553;&#36817;&#20284;&#21518;&#39564;&#26435;&#37325;&#26679;&#26412;&#65292;&#32780;&#19981;&#26159;&#37327;&#21270;&#21644;&#29109;&#32534;&#30721;&#23427;&#12290;&#35813;&#31574;&#30053;&#36890;&#36807;&#26368;&#23567;&#21270; $\beta$-ELBO &#30452;&#25509;&#20248;&#21270;&#30721;-&#22833;&#30495;&#24615;&#33021;&#65292;&#24182;&#36890;&#36807;&#35843;&#25972; $\beta$ &#26469;&#38024;&#23545;&#32473;&#23450;&#30340;&#32593;&#32476;&#32467;&#26500;&#23454;&#29616;&#19981;&#21516;&#30340;&#30721;-&#22833;&#30495;&#24179;&#34913;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#23398;&#20064;&#20808;&#39564;&#26435;&#37325;&#20998;&#24067;&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#24182;&#37319;&#29992;&#20027;&#21160;&#23610;&#23544;&#35843;&#25972;&#26469;&#36827;&#19968;&#27493;&#25552;&#39640;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many common types of data can be represented as functions that map coordinates to signal values, such as pixel locations to RGB values in the case of an image. Based on this view, data can be compressed by overfitting a compact neural network to its functional representation and then encoding the network weights. However, most current solutions for this are inefficient, as quantization to low-bit precision substantially degrades the reconstruction quality. To address this issue, we propose overfitting variational Bayesian neural networks to the data and compressing an approximate posterior weight sample using relative entropy coding instead of quantizing and entropy coding it. This strategy enables direct optimization of the rate-distortion performance by minimizing the $\beta$-ELBO, and target different rate-distortion trade-offs for a given network architecture by adjusting $\beta$. Moreover, we introduce an iterative algorithm for learning prior weight distributions and employ a pro
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992;&#28789;&#27963;&#30340;PFN&#20316;&#20026;BO&#20195;&#29702;&#24314;&#27169;&#65292;&#35813;&#27169;&#22411;&#33021;&#22815;&#20801;&#35768;&#36827;&#19968;&#27493;&#20449;&#24687;&#32435;&#20837;&#20197;&#36827;&#34892;&#38750;&#36828;&#35270;BO&#12290;&#22312;&#19977;&#31181;&#19981;&#21516;&#30340;&#38382;&#39064;&#19978;&#24471;&#21040;&#20102;&#24456;&#22909;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2305.17535</link><description>&lt;p&gt;
PFN&#26159;&#36866;&#29992;&#20110;&#23454;&#38469;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#28789;&#27963;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
PFNs Are Flexible Models for Real-World Bayesian Optimization. (arXiv:2305.17535v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17535
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#28789;&#27963;&#30340;PFN&#20316;&#20026;BO&#20195;&#29702;&#24314;&#27169;&#65292;&#35813;&#27169;&#22411;&#33021;&#22815;&#20801;&#35768;&#36827;&#19968;&#27493;&#20449;&#24687;&#32435;&#20837;&#20197;&#36827;&#34892;&#38750;&#36828;&#35270;BO&#12290;&#22312;&#19977;&#31181;&#19981;&#21516;&#30340;&#38382;&#39064;&#19978;&#24471;&#21040;&#20102;&#24456;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#20808;&#39564;&#25968;&#25454;&#25311;&#21512;&#32593;&#32476;(PFNs)&#20316;&#20026;&#36125;&#21494;&#26031;&#20248;&#21270;(BO)&#30340;&#28789;&#27963;&#20195;&#29702;&#12290;PFN&#26159;&#19968;&#31181;&#31070;&#32463;&#36807;&#31243;&#65292;&#34987;&#35757;&#32451;&#29992;&#20110;&#36817;&#20284;&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;(PPD)&#65292;&#36866;&#29992;&#20110;&#20219;&#20309;&#21487;&#26377;&#25928;&#37319;&#26679;&#30340;&#20808;&#39564;&#20998;&#24067;&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;&#22914;&#20309;&#21033;&#29992;&#36825;&#31181;&#28789;&#27963;&#24615;&#26469;&#36827;&#34892;BO&#30340;&#20195;&#29702;&#24314;&#27169;&#12290;&#25105;&#20204;&#20351;&#29992;PFN&#26469;&#27169;&#25311;&#19968;&#20010;&#26420;&#32032;&#39640;&#26031;&#36807;&#31243;(GP)&#65292;&#19968;&#20010;&#20808;&#36827;&#30340;GP&#21644;&#19968;&#20010;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;(BNN)&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#36827;&#19968;&#27493;&#30340;&#20449;&#24687;&#32435;&#20837;&#20808;&#39564;&#65292;&#20363;&#22914;&#20801;&#35768;&#26377;&#20851;&#26368;&#20248;&#20301;&#32622;&#30340;&#25552;&#31034;(&#29992;&#25143;&#20808;&#39564;)&#65292;&#24573;&#30053;&#19981;&#30456;&#20851;&#30340;&#32500;&#24230;&#65292;&#24182;&#36890;&#36807;&#23398;&#20064;&#33719;&#21462;&#20989;&#25968;&#26469;&#25191;&#34892;&#38750;&#36828;&#35270;BO&#12290;&#36825;&#20123;&#25193;&#23637;&#30340;&#28789;&#27963;&#24615;&#20026;&#20351;&#29992;PFN&#36827;&#34892;BO&#24320;&#36767;&#20102;&#24191;&#38420;&#30340;&#21487;&#33021;&#24615;&#12290;&#25105;&#20204;&#22312;&#20154;&#24037;&#39640;&#26031;&#36807;&#31243;&#26679;&#26412;&#21644;&#19977;&#20010;&#19981;&#21516;&#30340;&#36229;&#21442;&#25968;&#20248;&#21270;&#27979;&#35797;&#24179;&#21488;&#19978;&#23637;&#31034;&#20102;PFN&#23545;BO&#30340;&#26377;&#29992;&#24615;&#65306;HPO-B&#12289;Bayesmark&#21644;PD1&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we use Prior-data Fitted Networks (PFNs) as a flexible surrogate for Bayesian Optimization (BO). PFNs are neural processes that are trained to approximate the posterior predictive distribution (PPD) for any prior distribution that can be efficiently sampled from. We describe how this flexibility can be exploited for surrogate modeling in BO. We use PFNs to mimic a naive Gaussian process (GP), an advanced GP, and a Bayesian Neural Network (BNN). In addition, we show how to incorporate further information into the prior, such as allowing hints about the position of optima (user priors), ignoring irrelevant dimensions, and performing non-myopic BO by learning the acquisition function. The flexibility underlying these extensions opens up vast possibilities for using PFNs for BO. We demonstrate the usefulness of PFNs for BO in a large-scale evaluation on artificial GP samples and three different hyperparameter optimization testbeds: HPO-B, Bayesmark, and PD1. We publish code 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#34920;&#31034;&#36801;&#31227;&#30340;&#23398;&#20064;&#26041;&#27861;&#65292;&#22312;&#32473;&#23450;&#24456;&#23569;&#25968;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#25552;&#20379;&#19968;&#32452;&#22312;&#21487;&#33021;&#19981;&#21516;&#30340;&#25968;&#25454;&#39046;&#22495;&#19978;&#35757;&#32451;&#30340;&#39044;&#35757;&#32451;&#22238;&#24402;&#27169;&#22411;&#65292;&#26469;&#26500;&#24314;&#30446;&#26631;&#27169;&#22411;&#65292;&#20351;&#29992;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#27169;&#22411;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2305.16440</link><description>&lt;p&gt;
&#22810;&#20010;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#34920;&#31034;&#36801;&#31227;&#23398;&#20064;&#22312;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Representation Transfer Learning via Multiple Pre-trained models for Linear Regression. (arXiv:2305.16440v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16440
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#34920;&#31034;&#36801;&#31227;&#30340;&#23398;&#20064;&#26041;&#27861;&#65292;&#22312;&#32473;&#23450;&#24456;&#23569;&#25968;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#25552;&#20379;&#19968;&#32452;&#22312;&#21487;&#33021;&#19981;&#21516;&#30340;&#25968;&#25454;&#39046;&#22495;&#19978;&#35757;&#32451;&#30340;&#39044;&#35757;&#32451;&#22238;&#24402;&#27169;&#22411;&#65292;&#26469;&#26500;&#24314;&#30446;&#26631;&#27169;&#22411;&#65292;&#20351;&#29992;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#27169;&#22411;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32473;&#23450;&#24456;&#23569;&#25968;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#65292;&#22914;&#20309;&#22312;&#24863;&#20852;&#36259;&#30340;&#25968;&#25454;&#39046;&#22495;&#65288;&#30446;&#26631;&#65289;&#19978;&#23398;&#20064;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#34920;&#31034;&#36801;&#31227;&#30340;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#25552;&#20379;&#19968;&#32452;&#22312;&#21487;&#33021;&#19981;&#21516;&#30340;&#25968;&#25454;&#39046;&#22495;&#65288;&#26469;&#28304;&#65289;&#19978;&#35757;&#32451;&#30340;&#39044;&#35757;&#32451;&#22238;&#24402;&#27169;&#22411;&#65292;&#26469;&#26500;&#24314;&#30446;&#26631;&#27169;&#22411;&#12290;&#35813;&#26041;&#27861;&#30001;&#20004;&#20010;&#38454;&#27573;&#32452;&#25104;&#65306;&#65288;i&#65289;&#21033;&#29992;&#19981;&#21516;&#30340;&#28304;&#34920;&#31034;&#26469;&#26500;&#36896;&#36866;&#24212;&#30446;&#26631;&#25968;&#25454;&#30340;&#34920;&#31034;&#65292;&#65288;ii&#65289;&#23558;&#25152;&#24471;&#21040;&#30340;&#27169;&#22411;&#20316;&#20026;&#21021;&#22987;&#20540;&#65292;&#36890;&#36807;&#24494;&#35843;&#31243;&#24207;&#65292;&#22312;&#30446;&#26631;&#25968;&#25454;&#19978;&#37325;&#26032;&#35757;&#32451;&#25972;&#20010;&#65288;&#36229;&#21442;&#25968;&#65289;&#22238;&#24402;&#27169;&#22411;&#12290;&#23545;&#20110;&#35757;&#32451;&#26041;&#27861;&#30340;&#27599;&#20010;&#38454;&#27573;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23398;&#20064;&#27169;&#22411;&#19982;&#30495;&#23454;&#25968;&#25454;&#29983;&#25104;&#30446;&#26631;&#27169;&#22411;&#20043;&#38388;&#30340;&#36229;&#39069;&#39118;&#38505;&#38480;&#21046;&#12290;&#23548;&#20986;&#30340;&#38480;&#21046;&#26174;&#31034;&#20102;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#25552;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we consider the problem of learning a linear regression model on a data domain of interest (target) given few samples. To aid learning, we are provided with a set of pre-trained regression models that are trained on potentially different data domains (sources). Assuming a representation structure for the data generating linear models at the sources and the target domains, we propose a representation transfer based learning method for constructing the target model. The proposed scheme is comprised of two phases: (i) utilizing the different source representations to construct a representation that is adapted to the target data, and (ii) using the obtained model as an initialization to a fine-tuning procedure that re-trains the entire (over-parameterized) regression model on the target data. For each phase of the training method, we provide excess risk bounds for the learned model compared to the true data generating target model. The derived bounds show a gain in sample co
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;Platt&#32553;&#25918;&#21450;&#20854;&#26657;&#20934;&#26041;&#27861;&#65292;&#20854;&#29702;&#35770;&#22522;&#30784;&#24378;&#22823;&#65292;&#21487;&#20197;&#22788;&#29702;&#20998;&#24067;&#28418;&#31227;&#21644;&#23545;&#25239;&#24615;&#32467;&#26524;&#24207;&#21015;&#65292;&#26080;&#38656;&#36229;&#21442;&#25968;&#35843;&#25972;&#65292;&#22312;&#19968;&#31995;&#21015;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.00070</link><description>&lt;p&gt;
&#22312;&#32447;Platt&#32553;&#25918;&#21450;&#20854;&#26657;&#20934;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Online Platt Scaling with Calibeating. (arXiv:2305.00070v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00070
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;Platt&#32553;&#25918;&#21450;&#20854;&#26657;&#20934;&#26041;&#27861;&#65292;&#20854;&#29702;&#35770;&#22522;&#30784;&#24378;&#22823;&#65292;&#21487;&#20197;&#22788;&#29702;&#20998;&#24067;&#28418;&#31227;&#21644;&#23545;&#25239;&#24615;&#32467;&#26524;&#24207;&#21015;&#65292;&#26080;&#38656;&#36229;&#21442;&#25968;&#35843;&#25972;&#65292;&#22312;&#19968;&#31995;&#21015;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#21518;&#26657;&#20934;&#26041;&#27861;&#65292;&#31216;&#20026;&#22312;&#32447;Platt&#32553;&#25918;(OPS)&#65292;&#23427;&#23558;Platt&#32553;&#25918;&#25216;&#26415;&#19982;&#22312;&#32447;&#36923;&#36753;&#22238;&#24402;&#30456;&#32467;&#21512;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;OPS&#22914;&#20309;&#22312;&#20998;&#24067;&#28418;&#31227;&#30340;i.i.d.&#21644;&#38750;i.i.d.&#24773;&#20917;&#19979;&#24179;&#31283;&#36866;&#24212;&#12290;&#27492;&#22806;&#65292;&#24403;&#26368;&#20339;&#30340;Platt&#32553;&#25918;&#27169;&#22411;&#26412;&#36523;&#34987;&#38169;&#35823;&#26657;&#20934;&#26102;&#65292;&#25105;&#20204;&#20351;&#29992;&#19968;&#31181;&#26368;&#36817;&#24320;&#21457;&#30340;&#31216;&#20026;calibeating&#30340;&#25216;&#26415;&#26469;&#22686;&#24378;OPS&#65292;&#20351;&#20854;&#26356;&#21152;&#40065;&#26834;&#12290;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#24471;&#21040;&#30340;OPS+calibeating&#26041;&#27861;&#23545;&#20110;&#23545;&#25239;&#24615;&#32467;&#26524;&#24207;&#21015;&#26159;&#20445;&#35777;&#26657;&#20934;&#30340;&#12290;&#22312;&#23454;&#39564;&#19978;&#65292;&#23427;&#22312;&#19968;&#31995;&#21015;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#22343;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#24615;&#33021;&#65292;&#26080;&#38656;&#36229;&#21442;&#25968;&#35843;&#25972;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#25152;&#26377;OPS&#24605;&#24819;&#25193;&#23637;&#21040;beta&#32553;&#25918;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present an online post-hoc calibration method, called Online Platt Scaling (OPS), which combines the Platt scaling technique with online logistic regression. We demonstrate that OPS smoothly adapts between i.i.d. and non-i.i.d. settings with distribution drift. Further, in scenarios where the best Platt scaling model is itself miscalibrated, we enhance OPS by incorporating a recently developed technique called calibeating to make it more robust. Theoretically, our resulting OPS+calibeating method is guaranteed to be calibrated for adversarial outcome sequences. Empirically, it is effective on a range of synthetic and real-world datasets, with and without distribution drifts, achieving superior performance without hyperparameter tuning. Finally, we extend all OPS ideas to the beta scaling method.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21344;&#25454;&#26680;PCA&#26041;&#27861;&#36827;&#34892;&#25925;&#38556;&#26816;&#27979;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#19988;&#36890;&#36807;&#25968;&#20540;&#27169;&#25311;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.11138</link><description>&lt;p&gt;
&#22522;&#20110;&#21344;&#25454;&#26680;&#20027;&#25104;&#20998;&#20998;&#26512;&#30340;&#25925;&#38556;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Fault Detection via Occupation Kernel Principal Component Analysis. (arXiv:2303.11138v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11138
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21344;&#25454;&#26680;PCA&#26041;&#27861;&#36827;&#34892;&#25925;&#38556;&#26816;&#27979;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#19988;&#36890;&#36807;&#25968;&#20540;&#27169;&#25311;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#21160;&#31995;&#32479;&#30340;&#21487;&#38752;&#25805;&#20316;&#24456;&#22823;&#31243;&#24230;&#19978;&#20381;&#36182;&#20110;&#26816;&#27979;&#22522;&#30784;&#21160;&#24577;&#31995;&#32479;&#20013;&#30340;&#25925;&#38556;&#12290;&#34429;&#28982;&#20256;&#32479;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#26041;&#27861;&#24050;&#34987;&#24191;&#27867;&#29992;&#20110;&#25925;&#38556;&#26816;&#27979;&#65292;&#20294;&#22522;&#20110;&#25968;&#25454;&#30340;&#26041;&#27861;&#22240;&#20854;&#26131;&#20110;&#37096;&#32626;&#21644;&#23545;&#19987;&#23478;&#30693;&#35782;&#38656;&#27714;&#26368;&#23567;&#30340;&#29305;&#28857;&#32780;&#21463;&#21040;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#21344;&#25454;&#26680;&#36827;&#34892;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#30340;&#26032;&#26041;&#27861;&#12290;&#21344;&#25454;&#26680;&#20135;&#29983;&#30340;&#29305;&#24449;&#26144;&#23556;&#36866;&#29992;&#20110;&#27979;&#37327;&#25968;&#25454;&#65292;&#30001;&#20110;&#20351;&#29992;&#31215;&#20998;&#20855;&#26377;&#20869;&#22312;&#30340;&#22122;&#22768;&#40065;&#26834;&#24615;&#65292;&#24182;&#19988;&#21487;&#20197;&#21033;&#29992;&#38271;&#24230;&#21487;&#21464;&#30340;&#19981;&#35268;&#21017;&#37319;&#26679;&#31995;&#32479;&#36712;&#36857;&#36827;&#34892;PCA&#12290;&#21344;&#25454;&#26680;PCA&#26041;&#27861;&#34987;&#29992;&#20110;&#24320;&#21457;&#19968;&#31181;&#37325;&#26500;&#35823;&#24046;&#26041;&#27861;&#36827;&#34892;&#25925;&#38556;&#26816;&#27979;&#65292;&#24182;&#19988;&#36890;&#36807;&#25968;&#20540;&#27169;&#25311;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The reliable operation of automatic systems is heavily dependent on the ability to detect faults in the underlying dynamical system. While traditional model-based methods have been widely used for fault detection, data-driven approaches have garnered increasing attention due to their ease of deployment and minimal need for expert knowledge. In this paper, we present a novel principal component analysis (PCA) method that uses occupation kernels. Occupation kernels result in feature maps that are tailored to the measured data, have inherent noise-robustness due to the use of integration, and can utilize irregularly sampled system trajectories of variable lengths for PCA. The occupation kernel PCA method is used to develop a reconstruction error approach to fault detection and its efficacy is validated using numerical simulations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#21333;&#20010;ReLU&#31070;&#32463;&#20803;&#30340;&#26377;&#38480;&#26679;&#26412;&#23398;&#20064;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#24863;&#30693;&#22120;&#31639;&#27861;GLM-tron&#30340;&#39118;&#38505;&#19978;&#19979;&#30028;&#65292;&#20854;&#20013;&#21253;&#25324;&#29305;&#27530;&#24773;&#20917;&#65292;&#20026;&#39640;&#32500;ReLU&#22238;&#24402;&#38382;&#39064;&#25552;&#20379;&#20102;&#28165;&#26224;&#30340;&#21051;&#30011;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#23545;&#31216;&#20271;&#21162;&#21033;&#25968;&#25454;&#30340;ReLU&#22238;&#24402;&#65292;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#36807;&#22810;&#39118;&#38505;&#19981;&#22914;GLM-tron&#12290;</title><link>http://arxiv.org/abs/2303.02255</link><description>&lt;p&gt;
&#39640;&#32500;&#21333;&#20010;ReLU&#31070;&#32463;&#20803;&#30340;&#26377;&#38480;&#26679;&#26412;&#23398;&#20064;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Finite-Sample Analysis of Learning High-Dimensional Single ReLU Neuron. (arXiv:2303.02255v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.02255
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#32500;&#21333;&#20010;ReLU&#31070;&#32463;&#20803;&#30340;&#26377;&#38480;&#26679;&#26412;&#23398;&#20064;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#24863;&#30693;&#22120;&#31639;&#27861;GLM-tron&#30340;&#39118;&#38505;&#19978;&#19979;&#30028;&#65292;&#20854;&#20013;&#21253;&#25324;&#29305;&#27530;&#24773;&#20917;&#65292;&#20026;&#39640;&#32500;ReLU&#22238;&#24402;&#38382;&#39064;&#25552;&#20379;&#20102;&#28165;&#26224;&#30340;&#21051;&#30011;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#23545;&#31216;&#20271;&#21162;&#21033;&#25968;&#25454;&#30340;ReLU&#22238;&#24402;&#65292;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#36807;&#22810;&#39118;&#38505;&#19981;&#22914;GLM-tron&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#36807;&#21442;&#25968;&#21270;&#30340;&#24773;&#20917;&#19979;&#65288;&#21363;&#36755;&#20837;&#32500;&#24230;&#21487;&#33021;&#36229;&#20986;&#26679;&#26412;&#25968;&#65289;&#65292;&#23398;&#20064;&#20855;&#26377;&#24179;&#26041;&#25439;&#22833;&#30340;&#21333;&#20010;ReLU&#31070;&#32463;&#20803;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#31216;&#20026;GLM-tron&#65288;Kakade&#31561;&#20154;&#65292;2011&#65289;&#30340;&#24863;&#30693;&#22120;&#31639;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#20854;&#32500;&#24230;&#26080;&#20851;&#30340;&#39118;&#38505;&#19978;&#30028;&#65292;&#29992;&#20110;&#39640;&#32500;ReLU&#22238;&#24402;&#30340;&#33391;&#22909;&#35268;&#23450;&#21644;&#35268;&#23450;&#38169;&#35823;&#35774;&#32622;&#12290;&#25105;&#20204;&#30340;&#39118;&#38505;&#19978;&#30028;&#24674;&#22797;&#20102;&#20960;&#20010;&#29616;&#26377;&#32467;&#26524;&#20316;&#20026;&#29305;&#20363;&#12290;&#27492;&#22806;&#65292;&#22312;&#33391;&#22909;&#35268;&#23450;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#20026;GLM-tron&#25552;&#20379;&#20102;&#19968;&#20010;&#23454;&#20363;&#21305;&#37197;&#39118;&#38505;&#19979;&#30028;&#12290;&#25105;&#20204;&#30340;&#19978;&#19979;&#39118;&#38505;&#30028;&#25552;&#20379;&#20102;&#23545;&#21487;&#20197;&#36890;&#36807;GLM-tron&#23398;&#20064;&#30340;&#39640;&#32500;ReLU&#22238;&#24402;&#38382;&#39064;&#30340;&#28165;&#26224;&#21051;&#30011;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#25105;&#20204;&#38024;&#23545;&#23545;&#31216;&#20271;&#21162;&#21033;&#25968;&#25454;&#30340;ReLU&#22238;&#24402;&#25552;&#20379;&#20102;&#19968;&#20123;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#36127;&#38754;&#32467;&#26524;&#65306;&#22914;&#26524;&#27169;&#22411;&#35268;&#23450;&#33391;&#22909;&#65292;&#21017;SGD&#30340;&#36807;&#22810;&#39118;&#38505;&#21487;&#35777;&#26126;&#19981;&#27604;&#26080;&#35270;&#24120;&#25968;&#22240;&#32032;&#30340;GLM-tron&#30340;&#36807;&#22810;&#39118;&#38505;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper considers the problem of learning a single ReLU neuron with squared loss (a.k.a., ReLU regression) in the overparameterized regime, where the input dimension can exceed the number of samples. We analyze a Perceptron-type algorithm called GLM-tron (Kakade et al., 2011) and provide its dimension-free risk upper bounds for high-dimensional ReLU regression in both well-specified and misspecified settings. Our risk bounds recover several existing results as special cases. Moreover, in the well-specified setting, we provide an instance-wise matching risk lower bound for GLM-tron. Our upper and lower risk bounds provide a sharp characterization of the high-dimensional ReLU regression problems that can be learned via GLM-tron. On the other hand, we provide some negative results for stochastic gradient descent (SGD) for ReLU regression with symmetric Bernoulli data: if the model is well-specified, the excess risk of SGD is provably no better than that of GLM-tron ignoring constant fa
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#23398;&#20064;&#20013;&#20869;&#29983;&#24615;&#38382;&#39064;&#30340;&#35299;&#20915;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#20351;&#29992;Two-Stage Least Squares&#26041;&#27861;&#30340;&#22312;&#32447;&#21464;&#20307;O2SLS&#26469;&#22788;&#29702;&#20869;&#29983;&#24615;&#65292;&#21462;&#24471;&#20102;&#36739;&#22909;&#30340;&#35782;&#21035;&#29575;&#21644;&#39044;&#27979;&#36951;&#25022;&#29575;&#12290;</title><link>http://arxiv.org/abs/2302.09357</link><description>&lt;p&gt;
&#22312;&#32447;&#24037;&#20855;&#21464;&#37327;&#22238;&#24402;: &#36951;&#25022;&#20998;&#26512;&#21644;Bandit&#21453;&#39304;
&lt;/p&gt;
&lt;p&gt;
Online Instrumental Variable Regression: Regret Analysis and Bandit Feedback. (arXiv:2302.09357v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09357
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#23398;&#20064;&#20013;&#20869;&#29983;&#24615;&#38382;&#39064;&#30340;&#35299;&#20915;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#20351;&#29992;Two-Stage Least Squares&#26041;&#27861;&#30340;&#22312;&#32447;&#21464;&#20307;O2SLS&#26469;&#22788;&#29702;&#20869;&#29983;&#24615;&#65292;&#21462;&#24471;&#20102;&#36739;&#22909;&#30340;&#35782;&#21035;&#29575;&#21644;&#39044;&#27979;&#36951;&#25022;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20869;&#29983;&#24615;&#26159;&#23454;&#38469;&#25968;&#25454;&#20013;&#24120;&#35265;&#30340;&#29616;&#35937;&#65292;&#22240;&#20026;&#36951;&#28431;&#21464;&#37327;&#12289;&#25112;&#30053;&#34892;&#20026;&#12289;&#27979;&#37327;&#35823;&#24046;&#31561;&#21407;&#22240;&#23548;&#33268;&#22122;&#22768;&#21644;&#21327;&#21464;&#37327;&#20043;&#38388;&#30340;&#20381;&#36182;&#24615;&#12290;&#19982;&#20043;&#30456;&#21453;&#65292;&#29616;&#26377;&#30340;&#26080;&#30028;&#22122;&#22768;&#21644;&#32447;&#24615;Bandit&#38543;&#26426;&#22312;&#32447;&#32447;&#24615;&#22238;&#24402;&#20998;&#26512;&#20005;&#37325;&#20381;&#36182;&#22806;&#29983;&#24615;&#65292;&#21363;&#22122;&#22768;&#21644;&#21327;&#21464;&#37327;&#20043;&#38388;&#30340;&#29420;&#31435;&#24615;&#12290;&#37492;&#20110;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#24037;&#20855;&#21464;&#37327;&#65288;IV&#65289;&#22238;&#24402;&#22312;&#38543;&#26426;&#22312;&#32447;&#23398;&#20064;&#20013;&#30340;&#36229;&#35782;&#21035;&#21644;&#24688;&#22909;&#35782;&#21035;&#24773;&#20917;&#12290;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;Two-Stage Least Squares&#26041;&#27861;&#30340;&#22312;&#32447;&#21464;&#20307;&#65288;&#21363;O2SLS&#65289;&#26469;&#22788;&#29702;&#20869;&#29983;&#24615;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;O2SLS&#23454;&#29616;&#20102;$ \mathcal{O} \left(d_x d_z \log ^ 2 T \right)$&#30340;&#35782;&#21035;&#29575;&#21644;$ \tilde {\mathcal {O}} \left(\gamma \sqrt {d_x T} \right)$&#30340;&#39044;&#27979;&#36951;&#25022;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Endogeneity, i.e. the dependence between noise and covariates, is a common phenomenon in real data due to omitted variables, strategic behaviours, measurement errors etc. In contrast, the existing analyses of stochastic online linear regression with unbounded noise and linear bandits depend heavily on exogeneity, i.e. the independence between noise and covariates. Motivated by this gap, we study the over-and just-identified Instrumental Variable (IV) regression for stochastic online learning. IV regression and the Two-Stage Least Squares approach to it are widely deployed in economics and causal inference to identify the underlying model from an endogenous dataset. Thus, we propose to use an online variant of Two-Stage Least Squares approach, namely O2SLS, to tackle endogeneity in stochastic online learning. Our analysis shows that O2SLS achieves $\mathcal{O}\left(d_x d_z \log ^2 T\right)$ identification and $\tilde{\mathcal{O}}\left(\gamma \sqrt{d_x T}\right)$ oracle regret after $T$ 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;BPLS&#65292;&#19968;&#31181;&#29992;&#20110;PLS&#30340;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#36890;&#36807;&#35299;&#26512;&#36924;&#36817;&#36873;&#25321;&#26631;&#31614;&#23454;&#20363;&#30340;&#26631;&#20934;&#65292;&#20197;&#36991;&#20813;&#30001;&#36807;&#24230;&#33258;&#20449;&#20294;&#38169;&#35823;&#39044;&#27979;&#30340;&#23454;&#20363;&#36873;&#25321;&#32780;&#23548;&#33268;&#30340;&#30830;&#35748;&#20559;&#24046;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2302.08883</link><description>&lt;p&gt;
&#36817;&#20046;&#36125;&#21494;&#26031;&#26368;&#20248;&#30340;&#20266;&#26631;&#31614;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Approximately Bayes-Optimal Pseudo Label Selection. (arXiv:2302.08883v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.08883
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;BPLS&#65292;&#19968;&#31181;&#29992;&#20110;PLS&#30340;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#36890;&#36807;&#35299;&#26512;&#36924;&#36817;&#36873;&#25321;&#26631;&#31614;&#23454;&#20363;&#30340;&#26631;&#20934;&#65292;&#20197;&#36991;&#20813;&#30001;&#36807;&#24230;&#33258;&#20449;&#20294;&#38169;&#35823;&#39044;&#27979;&#30340;&#23454;&#20363;&#36873;&#25321;&#32780;&#23548;&#33268;&#30340;&#30830;&#35748;&#20559;&#24046;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#35757;&#32451;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#20005;&#37325;&#20381;&#36182;&#20110;&#20266;&#26631;&#31614;&#36873;&#25321;&#65288;PLS&#65289;&#12290;&#36873;&#25321;&#36890;&#24120;&#21462;&#20915;&#20110;&#21021;&#22987;&#27169;&#22411;&#25311;&#21512;&#26631;&#35760;&#25968;&#25454;&#30340;&#31243;&#24230;&#12290;&#36807;&#26089;&#30340;&#36807;&#25311;&#21512;&#21487;&#33021;&#36890;&#36807;&#36873;&#25321;&#20855;&#26377;&#36807;&#24230;&#33258;&#20449;&#20294;&#38169;&#35823;&#30340;&#39044;&#27979;&#30340;&#23454;&#20363;&#65288;&#36890;&#24120;&#31216;&#20026;&#30830;&#35748;&#20559;&#24046;&#65289;&#32780;&#20256;&#25773;&#21040;&#26368;&#32456;&#27169;&#22411;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;BPLS&#65292;&#36825;&#26159;&#19968;&#31181;&#29992;&#20110;PLS&#30340;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#26088;&#22312;&#20943;&#36731;&#36825;&#20010;&#38382;&#39064;&#12290;&#20854;&#26680;&#24515;&#26159;&#36873;&#25321;&#26631;&#31614;&#23454;&#20363;&#30340;&#26631;&#20934;&#65306;&#20266;&#26679;&#26412;&#30340;&#21518;&#39564;&#39044;&#27979;&#30340;&#20998;&#26512;&#36817;&#20284;&#12290;&#25105;&#20204;&#36890;&#36807;&#35777;&#26126;&#20266;&#26679;&#26412;&#30340;&#21518;&#39564;&#39044;&#27979;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#24615;&#33719;&#24471;&#20102;&#36825;&#31181;&#36873;&#25321;&#26631;&#20934;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#36890;&#36807;&#35299;&#26512;&#36924;&#36817;&#20811;&#26381;&#35745;&#31639;&#38590;&#39064;&#12290;&#23427;&#19982;&#36793;&#38469;&#20284;&#28982;&#30340;&#20851;&#31995;&#20351;&#25105;&#20204;&#33021;&#22815;&#25552;&#20986;&#22522;&#20110;&#25289;&#26222;&#25289;&#26031;&#26041;&#27861;&#21644;&#39640;&#26031;&#31215;&#20998;&#30340;&#36924;&#36817;&#12290;&#25105;&#20204;&#38024;&#23545;&#21442;&#25968;&#24191;&#20041;&#32447;&#24615;&#21644;&#38750;&#21442;&#25968;&#24191;&#20041;&#21152;&#24615;&#27169;&#22411;&#23545;BPLS&#36827;&#34892;&#20102;&#23454;&#35777;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Semi-supervised learning by self-training heavily relies on pseudo-label selection (PLS). The selection often depends on the initial model fit on labeled data. Early overfitting might thus be propagated to the final model by selecting instances with overconfident but erroneous predictions, often referred to as confirmation bias. This paper introduces BPLS, a Bayesian framework for PLS that aims to mitigate this issue. At its core lies a criterion for selecting instances to label: an analytical approximation of the posterior predictive of pseudo-samples. We derive this selection criterion by proving Bayes optimality of the posterior predictive of pseudo-samples. We further overcome computational hurdles by approximating the criterion analytically. Its relation to the marginal likelihood allows us to come up with an approximation based on Laplace's method and the Gaussian integral. We empirically assess BPLS for parametric generalized linear and non-parametric generalized additive models
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#25512;&#24191;&#22240;&#26524;&#22270;&#27169;&#22411;&#65292;&#25551;&#36848;&#20102;&#24322;&#36136;&#24615;&#22240;&#26524;&#22270;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#30740;&#31350;&#19981;&#21516;&#35843;&#33410;&#22240;&#32032;&#23545;&#27835;&#30103;&#25928;&#26524;&#21644;&#28508;&#22312;&#20013;&#20171;&#21464;&#37327;&#30340;&#24433;&#21709;&#65292;&#35299;&#20915;&#20102;&#29616;&#23454;&#29983;&#27963;&#20013;&#39640;&#32500;&#24230;&#22330;&#26223;&#30340;&#25361;&#25112;&#65292;&#24182;&#22312;&#30495;&#23454;&#25968;&#25454;&#24212;&#29992;&#20013;&#21457;&#29616;&#20102;&#26032;&#30340;&#24322;&#36136;&#24615;&#27835;&#30103;&#25928;&#24212;&#12290;</title><link>http://arxiv.org/abs/2301.12383</link><description>&lt;p&gt;
&#20851;&#20110;&#24322;&#36136;&#24615;&#22240;&#26524;&#22270;&#20013;&#30340;&#24322;&#36136;&#24615;&#27835;&#30103;&#25928;&#24212;
&lt;/p&gt;
&lt;p&gt;
On Heterogeneous Treatment Effects in Heterogeneous Causal Graphs. (arXiv:2301.12383v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.12383
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25512;&#24191;&#22240;&#26524;&#22270;&#27169;&#22411;&#65292;&#25551;&#36848;&#20102;&#24322;&#36136;&#24615;&#22240;&#26524;&#22270;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#30740;&#31350;&#19981;&#21516;&#35843;&#33410;&#22240;&#32032;&#23545;&#27835;&#30103;&#25928;&#26524;&#21644;&#28508;&#22312;&#20013;&#20171;&#21464;&#37327;&#30340;&#24433;&#21709;&#65292;&#35299;&#20915;&#20102;&#29616;&#23454;&#29983;&#27963;&#20013;&#39640;&#32500;&#24230;&#22330;&#26223;&#30340;&#25361;&#25112;&#65292;&#24182;&#22312;&#30495;&#23454;&#25968;&#25454;&#24212;&#29992;&#20013;&#21457;&#29616;&#20102;&#26032;&#30340;&#24322;&#36136;&#24615;&#27835;&#30103;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24322;&#36136;&#24615;&#21644;&#20849;&#30149;&#26159;&#35768;&#22810;&#21307;&#30103;&#22256;&#22659;&#30340;&#20004;&#22823;&#25361;&#25112;&#65292;&#38459;&#30861;&#20102;&#38024;&#23545;&#26377;&#25928;&#27835;&#30103;&#30340;&#30740;&#31350;&#20197;&#21450;&#23545;&#28508;&#22312;&#31070;&#32463;&#29983;&#29289;&#26426;&#21046;&#30340;&#29702;&#35299;&#12290;&#26412;&#25991;&#39318;&#20808;&#36890;&#36807;&#25512;&#24191;&#22240;&#26524;&#22270;&#27169;&#22411;&#19982;&#28151;&#26434;&#21464;&#37327;&#20132;&#20114;&#21644;&#22810;&#20010;&#20013;&#20171;&#21464;&#37327;&#30340;&#27010;&#24565;&#65292;&#25226;&#24322;&#36136;&#24615;&#22240;&#26524;&#22270;&#65288;HCGs&#65289;&#36827;&#34892;&#20102;&#27010;&#25324;&#25551;&#36848;&#65292;&#36825;&#20123;&#19982;&#27835;&#30103;&#20132;&#20114;&#20316;&#29992;&#30340;&#28151;&#26434;&#21464;&#37327;&#34987;&#31216;&#20026;&#35843;&#33410;&#22240;&#32032;&#65292;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#28789;&#27963;&#22320;&#20135;&#29983;HCGs&#65292;&#32473;&#20986;&#19981;&#21516;&#30340;&#35843;&#33410;&#22240;&#32032;&#65292;&#26126;&#30830;&#25551;&#36848;&#27835;&#30103;&#25110;&#28508;&#22312;&#20013;&#20171;&#21464;&#37327;&#23545;&#32467;&#26524;&#30340;HCEs&#12290;&#25105;&#20204;&#22312;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#27169;&#22411;&#20013;&#24314;&#31435;&#20102;HCE&#30340;&#29702;&#35770;&#24418;&#24335;&#65292;&#24182;&#22312;&#20010;&#20307;&#23618;&#38754;&#19978;&#25512;&#23548;&#20102;&#20854;&#29305;&#24615;&#12290;&#20026;&#20102;&#22788;&#29702;&#39640;&#32500;&#24230;&#22330;&#26223;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#20132;&#20114;&#24335;&#32467;&#26500;&#23398;&#20064;&#65292;&#36890;&#36807;&#23558;&#21452;&#37325;&#26426;&#22120;&#23398;&#20064;&#31574;&#30053;&#32435;&#20837;&#20272;&#35745;&#35843;&#33410;&#22240;&#32032;&#20013;&#65292;&#26469;&#35299;&#20915;&#38382;&#39064;&#12290;&#25105;&#20204;&#36890;&#36807;&#27169;&#25311;&#21644;&#23545;HIV&#38451;&#24615;&#24739;&#32773;&#25106;&#28895;&#24178;&#39044;&#30340;&#30495;&#23454;&#25968;&#25454;&#24212;&#29992;&#31034;&#20363;&#26469;&#28436;&#31034;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#21644;&#21457;&#29616;&#20986;&#20808;&#21069;&#26410;&#35760;&#24405;&#30340;&#26032;&#30340;HCE&#12290;&#35813;&#26041;&#27861;&#22312;&#21508;&#20010;&#21307;&#30103;&#39046;&#22495;&#20013;&#20026;&#29702;&#35299;&#24322;&#36136;&#24615;&#27835;&#30103;&#25928;&#24212;&#21644;&#25913;&#21892;&#20010;&#24615;&#21270;&#21307;&#23398;&#25552;&#20379;&#20102;&#28508;&#22312;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Heterogeneity and comorbidity are two interwoven challenges associated with various healthcare problems that greatly hampered research on developing effective treatment and understanding of the underlying neurobiological mechanism. Very few studies have been conducted to investigate heterogeneous causal effects (HCEs) in graphical contexts due to the lack of statistical methods. To characterize this heterogeneity, we first conceptualize heterogeneous causal graphs (HCGs) by generalizing the causal graphical model with confounder-based interactions and multiple mediators. Such confounders with an interaction with the treatment are known as moderators. This allows us to flexibly produce HCGs given different moderators and explicitly characterize HCEs from the treatment or potential mediators on the outcome. We establish the theoretical forms of HCEs and derive their properties at the individual level in both linear and nonlinear models. An interactive structural learning is developed to 
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#36870;&#21487;&#35299;&#24615;&#21644;&#23433;&#20840;&#24615;&#30340;&#27010;&#24565;&#65292;&#20197;&#21450;&#20854;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#12290;&#35770;&#25991;&#25552;&#20379;&#20102;&#27169;&#22411;&#31034;&#20363;&#65292;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#22686;&#21152;&#29992;&#25143;&#25968;&#37327;&#26469;&#22686;&#21152;&#21487;&#35299;&#24615;&#21644;&#23433;&#20840;&#24615;&#12290;</title><link>http://arxiv.org/abs/2211.14115</link><description>&lt;p&gt;
&#36870;&#21487;&#35299;&#24615;&#21644;&#23433;&#20840;&#24615;&#21450;&#20854;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Inverse Solvability and Security with Applications to Federated Learning. (arXiv:2211.14115v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.14115
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#36870;&#21487;&#35299;&#24615;&#21644;&#23433;&#20840;&#24615;&#30340;&#27010;&#24565;&#65292;&#20197;&#21450;&#20854;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#12290;&#35770;&#25991;&#25552;&#20379;&#20102;&#27169;&#22411;&#31034;&#20363;&#65292;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#22686;&#21152;&#29992;&#25143;&#25968;&#37327;&#26469;&#22686;&#21152;&#21487;&#35299;&#24615;&#21644;&#23433;&#20840;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#36870;&#21487;&#35299;&#24615;&#21644;&#23433;&#20840;&#24615;&#30340;&#27010;&#24565;&#65292;&#36866;&#29992;&#20110;&#19968;&#33324;&#32447;&#24615;&#21069;&#21521;&#27169;&#22411;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#20854;&#24212;&#29992;&#20110;&#32852;&#37030;&#23398;&#20064;&#20013;&#20351;&#29992;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#36825;&#26679;&#30340;&#27169;&#22411;&#30340;&#31034;&#20363;&#65292;&#20854;&#36870;&#21487;&#35299;&#24615;&#21644;&#23433;&#20840;&#24615;&#22312;&#26412;&#25991;&#20013;&#24471;&#21040;&#23450;&#20041;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#21442;&#19982;&#32473;&#23450;&#36845;&#20195;&#30340;&#22823;&#37327;&#29992;&#25143;&#26469;&#22686;&#21152;&#21487;&#35299;&#24615;&#21644;&#23433;&#20840;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#25152;&#25552;&#20986;&#27010;&#24565;&#30340;&#21487;&#33021;&#25193;&#23637;&#65292;&#21253;&#25324;&#38750;&#32447;&#24615;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce the concepts of inverse solvability and security for a generic linear forward model and demonstrate how they can be applied to models used in federated learning. We provide examples of such models which differ in the resulting inverse solvability and security as defined in this paper. We also show how the large number of users participating in a given iteration of federated learning can be leveraged to increase both solvability and security. Finally, we discuss possible extensions of the presented concepts including the nonlinear case.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27979;&#22320;&#32447;&#21644;&#27700;&#24179;&#38754;&#25237;&#24433;&#30340;&#21452;&#26354;&#20999;&#29255;Wasserstein&#36317;&#31163;&#65292;&#21487;&#29992;&#20110;&#27604;&#36739;&#20855;&#26377;&#22522;&#30784;&#20998;&#23618;&#32467;&#26500;&#30340;&#25968;&#25454;&#20013;&#23450;&#20041;&#30340;&#27010;&#29575;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2211.10066</link><description>&lt;p&gt;
&#22522;&#20110;&#27979;&#22320;&#32447;&#21644;&#27700;&#24179;&#38754;&#25237;&#24433;&#30340;&#21452;&#26354;&#20999;&#29255;Wasserstein
&lt;/p&gt;
&lt;p&gt;
Hyperbolic Sliced-Wasserstein via Geodesic and Horospherical Projections. (arXiv:2211.10066v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.10066
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27979;&#22320;&#32447;&#21644;&#27700;&#24179;&#38754;&#25237;&#24433;&#30340;&#21452;&#26354;&#20999;&#29255;Wasserstein&#36317;&#31163;&#65292;&#21487;&#29992;&#20110;&#27604;&#36739;&#20855;&#26377;&#22522;&#30784;&#20998;&#23618;&#32467;&#26500;&#30340;&#25968;&#25454;&#20013;&#23450;&#20041;&#30340;&#27010;&#29575;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#34920;&#26126;&#65292;&#23545;&#20110;&#35768;&#22810;&#20855;&#26377;&#22522;&#30784;&#20998;&#23618;&#32467;&#26500;&#30340;&#25968;&#25454;&#65292;&#23558;&#20854;&#23884;&#20837;&#21452;&#26354;&#31354;&#38388;&#26159;&#26377;&#30410;&#30340;&#12290;&#22240;&#27492;&#65292;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#24037;&#20855;&#34987;&#25193;&#23637;&#21040;&#36825;&#20123;&#31354;&#38388;&#65292;&#20294;&#21482;&#26377;&#24456;&#23569;&#23545;&#20110;&#36825;&#20123;&#31354;&#38388;&#20013;&#23450;&#20041;&#30340;&#27010;&#29575;&#20998;&#24067;&#36827;&#34892;&#27604;&#36739;&#30340;&#19981;&#19968;&#33268;&#24615;&#23384;&#22312;&#12290;&#22312;&#21452;&#26354;&#31354;&#38388;&#19978;&#65292;&#26368;&#20248;&#36755;&#36816;&#36317;&#31163;&#22312;&#36825;&#26679;&#30340;&#40654;&#26364;&#27969;&#24418;&#19978;&#26159;&#26126;&#30830;&#23450;&#20041;&#30340;&#65292;&#24182;&#20855;&#26377;&#24378;&#22823;&#30340;&#29702;&#35770;&#24615;&#36136;&#65292;&#20294;&#35745;&#31639;&#25104;&#26412;&#36739;&#39640;&#12290;&#22312;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#19978;&#65292;&#20999;&#29255;Wasserstein&#36317;&#31163;&#26159;&#26356;&#20855;&#35745;&#31639;&#25928;&#29575;&#30340;&#26041;&#27861;&#65292;&#23427;&#21033;&#29992;&#19968;&#32500;Wasserstein&#36317;&#31163;&#30340;&#38381;&#21512;&#24418;&#24335;&#65292;&#20294;&#22312;&#21452;&#26354;&#31354;&#38388;&#19978;&#19981;&#26131;&#33719;&#24471;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26032;&#30340;&#21452;&#26354;&#20999;&#29255;Wasserstein&#19981;&#19968;&#33268;&#24615;&#26500;&#36896;&#12290;&#36825;&#20123;&#26500;&#36896;&#20351;&#29992;&#22522;&#26412;&#27979;&#22320;&#32447;&#19978;&#30340;&#27700;&#24179;&#38754;&#25110;&#27979;&#22320;&#32447;&#30340;&#25237;&#24433;&#12290;&#25105;&#20204;&#22312;&#19981;&#21516;&#30340;&#20219;&#21153;&#20013;&#30740;&#31350;&#21644;&#27604;&#36739;&#23427;&#20204;&#65292;&#20854;&#20013;&#21452;&#26354;&#34920;&#31034;&#26159;&#30456;&#20851;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
It has been shown beneficial for many types of data which present an underlying hierarchical structure to be embedded in hyperbolic spaces. Consequently, many tools of machine learning were extended to such spaces, but only few discrepancies to compare probability distributions defined over those spaces exist. Among the possible candidates, optimal transport distances are well defined on such Riemannian manifolds and enjoy strong theoretical properties, but suffer from high computational cost. On Euclidean spaces, sliced-Wasserstein distances, which leverage a closed-form of the Wasserstein distance in one dimension, are more computationally efficient, but are not readily available on hyperbolic spaces. In this work, we propose to derive novel hyperbolic sliced-Wasserstein discrepancies. These constructions use projections on the underlying geodesics either along horospheres or geodesics. We study and compare them on different tasks where hyperbolic representations are relevant, such a
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#28151;&#21512;&#31867;&#21035;&#30456;&#20851;&#26680;&#30340;&#39640;&#26031;&#36807;&#31243;&#20195;&#29702;&#65292;&#30456;&#36739;&#20110;&#20854;&#20182;&#29616;&#26377;&#27169;&#22411;&#22312;&#20998;&#26512;&#21644;&#24037;&#31243;&#38382;&#39064;&#19978;&#34920;&#29616;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2211.08262</link><description>&lt;p&gt;
&#19968;&#31181;&#28151;&#21512;&#31867;&#21035;&#30456;&#20851;&#26680;&#30340;&#39640;&#26031;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
A mixed-categorical correlation kernel for Gaussian process. (arXiv:2211.08262v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.08262
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#28151;&#21512;&#31867;&#21035;&#30456;&#20851;&#26680;&#30340;&#39640;&#26031;&#36807;&#31243;&#20195;&#29702;&#65292;&#30456;&#36739;&#20110;&#20854;&#20182;&#29616;&#26377;&#27169;&#22411;&#22312;&#20998;&#26512;&#21644;&#24037;&#31243;&#38382;&#39064;&#19978;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#20195;&#29702;&#30340;&#28151;&#21512;&#31867;&#21035;&#20803;&#27169;&#22411;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#19968;&#20123;&#29616;&#26377;&#30340;&#26041;&#27861;&#20351;&#29992;&#19981;&#21516;&#30340;&#31574;&#30053;&#65292;&#36890;&#36807;&#20351;&#29992;&#36830;&#32493;&#26680;&#65288;&#20363;&#22914;&#65292;&#36830;&#32493;&#26494;&#24347;&#21644;Gower&#36317;&#31163;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#65289;&#25110;&#36890;&#36807;&#30452;&#25509;&#20272;&#35745;&#30456;&#20851;&#30697;&#38453;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#30340;&#26041;&#27861;&#65292;&#23558;&#36830;&#32493;&#25351;&#25968;&#26680;&#25193;&#23637;&#20026;&#22788;&#29702;&#28151;&#21512;&#31867;&#21035;&#21464;&#37327;&#12290;&#25152;&#25552;&#20986;&#30340;&#26680;&#24341;&#23548;&#21040;&#20102;&#19968;&#20010;&#26032;&#30340;&#39640;&#26031;&#20195;&#29702;&#65292;&#23427;&#27010;&#25324;&#20102;&#36830;&#32493;&#26494;&#24347;&#21644;Gower&#36317;&#31163;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#12290;&#25105;&#20204;&#22312;&#20998;&#26512;&#21644;&#24037;&#31243;&#38382;&#39064;&#19978;&#35777;&#26126;&#20102;&#65292;&#25105;&#20204;&#30340;&#25552;&#20986;&#30340;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#27604;&#20854;&#20182;&#22522;&#20110;&#26680;&#30340;&#29616;&#26377;&#27169;&#22411;&#20855;&#26377;&#26356;&#39640;&#30340;&#21487;&#33021;&#24615;&#21644;&#26356;&#23567;&#30340;&#27531;&#24046;&#35823;&#24046;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20351;&#29992;&#24320;&#28304;&#36719;&#20214;SMT&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, there has been a growing interest for mixed-categorical meta-models based on Gaussian process (GP) surrogates. In this setting, several existing approaches use different strategies either by using continuous kernels (e.g., continuous relaxation and Gower distance based GP) or by using a direct estimation of the correlation matrix. In this paper, we present a kernel-based approach that extends continuous exponential kernels to handle mixed-categorical variables. The proposed kernel leads to a new GP surrogate that generalizes both the continuous relaxation and the Gower distance based GP models. We demonstrate, on both analytical and engineering problems, that our proposed GP model gives a higher likelihood and a smaller residual error than the other kernel-based state-of-the-art models. Our method is available in the open-source software SMT.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#23384;&#22312;&#24378;&#20551;&#30456;&#20851;&#30340;&#20559;&#32622;&#32593;&#32476;&#20013;&#25552;&#21462;&#26368;&#20248;&#26080;&#20559;&#23376;&#32593;&#32476;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20351;&#29992;&#23545;&#27604;&#21098;&#26525;&#26435;&#37325;&#35757;&#32451;&#23454;&#29616;&#21435;&#20559;&#32622;&#23376;&#32593;&#32476;&#30340;&#31639;&#27861; DCWP&#65292;&#22312;&#22810;&#20010;&#24212;&#29992;&#20013;&#37117;&#26377;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2210.05247</link><description>&lt;p&gt;
&#20351;&#29992;&#23545;&#27604;&#21098;&#26525;&#26435;&#37325;&#35757;&#32451;&#21435;&#20559;&#32622;&#23376;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Training Debiased Subnetworks with Contrastive Weight Pruning. (arXiv:2210.05247v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.05247
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#23384;&#22312;&#24378;&#20551;&#30456;&#20851;&#30340;&#20559;&#32622;&#32593;&#32476;&#20013;&#25552;&#21462;&#26368;&#20248;&#26080;&#20559;&#23376;&#32593;&#32476;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20351;&#29992;&#23545;&#27604;&#21098;&#26525;&#26435;&#37325;&#35757;&#32451;&#23454;&#29616;&#21435;&#20559;&#32622;&#23376;&#32593;&#32476;&#30340;&#31639;&#27861; DCWP&#65292;&#22312;&#22810;&#20010;&#24212;&#29992;&#20013;&#37117;&#26377;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#36890;&#24120;&#23384;&#22312;&#20559;&#32622;&#24615;&#65292;&#23548;&#33268;&#25552;&#20379;&#20855;&#26377;&#35823;&#23548;&#24615;&#30340;&#32479;&#35745;&#35777;&#25454;&#65292;&#19981;&#33021;&#24456;&#22909;&#22320;&#25512;&#24191;&#12290;&#22240;&#27492;&#65292;&#25552;&#20986;&#20102;&#22312;&#20559;&#32622;&#32593;&#32476;&#20013;&#25552;&#21462;&#26368;&#20248;&#26080;&#20559;&#21151;&#33021;&#23376;&#32593;&#32476;&#30340;&#38382;&#39064;&#12290;&#26412;&#25991;&#39318;&#20808;&#25552;&#20986;&#20102;&#29616;&#26377;&#31639;&#27861;&#22312;&#25506;&#32034;&#20855;&#26377;&#24378;&#20551;&#30456;&#20851;&#24615;&#30340;&#26080;&#20559;&#23376;&#32593;&#32476;&#23384;&#22312;&#38480;&#21046;&#30340;&#29702;&#35770;&#27934;&#35265;&#65292;&#28982;&#21518;&#36827;&#19968;&#27493;&#38416;&#26126;&#20102;&#20559;&#24046;&#20914;&#31361;&#26679;&#26412;&#23545;&#32467;&#26500;&#23398;&#20064;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#22522;&#20110;&#23398;&#20064;&#30340;&#65288;&#20266;&#65289;&#26080;&#20559;&#26679;&#26412;&#21644;&#36873;&#25321;&#24615;&#20559;&#24046;&#20914;&#31361;&#26679;&#26412;&#65292;&#25552;&#20986;&#20102;&#21435;&#20559;&#32622;&#23545;&#27604;&#21098;&#26525;&#65288;DCWP&#65289;&#31639;&#27861;&#12290;&#22312;&#22270;&#20687;&#20998;&#31867;&#12289;&#35821;&#35328;&#27169;&#22411;&#21644;&#24378;&#21270;&#23398;&#20064;&#31561;&#21508;&#31181;&#24212;&#29992;&#20013;&#39564;&#35777;&#20102; DCWP &#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural networks are often biased to spuriously correlated features that provide misleading statistical evidence that does not generalize. This raises an interesting question: ``Does an optimal unbiased functional subnetwork exist in a severely biased network? If so, how to extract such subnetwork?" While empirical evidence has been accumulated about the existence of such unbiased subnetworks, these observations are mainly based on the guidance of ground-truth unbiased samples. Thus, it is unexplored how to discover the optimal subnetworks with biased training datasets in practice. To address this, here we first present our theoretical insight that alerts potential limitations of existing algorithms in exploring unbiased subnetworks in the presence of strong spurious correlations. We then further elucidate the importance of bias-conflicting samples on structure learning. Motivated by these observations, we propose a Debiased Contrastive Weight Pruning (DCWP) algorithm, which probes unbi
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22238;&#24402;&#30340;&#36229;&#26631;&#27010;&#29575;&#39044;&#27979;&#26041;&#27861;&#65292;&#29992;&#20110;&#39044;&#27979;&#26174;&#33879;&#27874;&#39640;&#65292;&#36890;&#36807;&#21033;&#29992;&#39044;&#27979;&#26469;&#20272;&#35745;&#36229;&#26631;&#27010;&#29575;&#65292;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2206.09821</link><description>&lt;p&gt;
&#22522;&#20110;&#22238;&#24402;&#30340;&#36229;&#26631;&#27010;&#29575;&#39044;&#27979;&#26041;&#27861;&#29992;&#20110;&#26174;&#33879;&#27874;&#39640;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Exceedance Probability Forecasting via Regression for Significant Wave Height Prediction. (arXiv:2206.09821v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.09821
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22238;&#24402;&#30340;&#36229;&#26631;&#27010;&#29575;&#39044;&#27979;&#26041;&#27861;&#65292;&#29992;&#20110;&#39044;&#27979;&#26174;&#33879;&#27874;&#39640;&#65292;&#36890;&#36807;&#21033;&#29992;&#39044;&#27979;&#26469;&#20272;&#35745;&#36229;&#26631;&#27010;&#29575;&#65292;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26174;&#33879;&#27874;&#39640;&#39044;&#27979;&#26159;&#28023;&#27915;&#25968;&#25454;&#20998;&#26512;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#12290;&#39044;&#27979;&#26174;&#33879;&#27874;&#39640;&#23545;&#20110;&#20272;&#35745;&#27874;&#33021;&#20135;&#29983;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#27492;&#22806;&#65292;&#21450;&#26102;&#39044;&#27979;&#22823;&#28010;&#30340;&#21040;&#26469;&#23545;&#20110;&#30830;&#20445;&#33322;&#28023;&#20316;&#19994;&#30340;&#23433;&#20840;&#24456;&#37325;&#35201;&#12290;&#25105;&#20204;&#23558;&#39044;&#27979;&#26174;&#33879;&#27874;&#39640;&#30340;&#26497;&#31471;&#20540;&#20316;&#20026;&#36229;&#26631;&#27010;&#29575;&#39044;&#27979;&#38382;&#39064;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#26088;&#22312;&#20272;&#35745;&#26174;&#33879;&#27874;&#39640;&#23558;&#36229;&#36807;&#39044;&#23450;&#20041;&#38408;&#20540;&#30340;&#27010;&#29575;&#12290;&#36890;&#24120;&#20351;&#29992;&#27010;&#29575;&#20108;&#20998;&#31867;&#27169;&#22411;&#26469;&#35299;&#20915;&#36825;&#20010;&#20219;&#21153;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39044;&#27979;&#27169;&#22411;&#30340;&#26032;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#26410;&#26469;&#35266;&#27979;&#30340;&#39044;&#27979;&#26469;&#26681;&#25454;&#32047;&#31215;&#20998;&#24067;&#20989;&#25968;&#20272;&#35745;&#36229;&#26631;&#27010;&#29575;&#12290;&#25105;&#20204;&#20351;&#29992;&#26469;&#33258;&#21152;&#25343;&#22823;&#21704;&#21033;&#27861;&#20811;&#26031;&#28023;&#23736;&#30340;&#28014;&#26631;&#25968;&#25454;&#36827;&#34892;&#20102;&#23454;&#39564;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Significant wave height forecasting is a key problem in ocean data analytics. Predicting the significant wave height is crucial for estimating the energy production from waves. Moreover, the timely prediction of large waves is important to ensure the safety of maritime operations, e.g. passage of vessels. We frame the task of predicting extreme values of significant wave height as an exceedance probability forecasting problem. Accordingly, we aim at estimating the probability that the significant wave height will exceed a predefined threshold. This task is usually solved using a probabilistic binary classification model. Instead, we propose a novel approach based on a forecasting model. The method leverages the forecasts for the upcoming observations to estimate the exceedance probability according to the cumulative distribution function. We carried out experiments using data from a buoy placed in the coast of Halifax, Canada. The results suggest that the proposed methodology is better
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#32479;&#35745;&#20998;&#26512;&#20102;&#35299;&#36793;&#38469;&#20844;&#24179;&#24615;&#21644;&#20132;&#38598;&#20844;&#24179;&#24615;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#21462;&#24471;&#31934;&#30830;&#20851;&#31995;&#12290;&#22312;&#39640;&#27010;&#29575;&#19979;,&#36890;&#36807;&#36793;&#38469;&#20844;&#24179;&#24615;&#21644;&#20854;&#20182;&#26377;&#24847;&#20041;&#30340;&#32479;&#35745;&#37327;&#21487;&#20197;&#35745;&#31639;&#20986;&#20132;&#38598;&#20844;&#24179;&#24615;&#30340;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2206.05828</link><description>&lt;p&gt;
&#36890;&#36807;&#36793;&#38469;&#20844;&#24179;&#24615;&#26469;&#30028;&#23450;&#21644;&#36924;&#36817;&#20132;&#38598;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Bounding and Approximating Intersectional Fairness through Marginal Fairness. (arXiv:2206.05828v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.05828
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#32479;&#35745;&#20998;&#26512;&#20102;&#35299;&#36793;&#38469;&#20844;&#24179;&#24615;&#21644;&#20132;&#38598;&#20844;&#24179;&#24615;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#21462;&#24471;&#31934;&#30830;&#20851;&#31995;&#12290;&#22312;&#39640;&#27010;&#29575;&#19979;,&#36890;&#36807;&#36793;&#38469;&#20844;&#24179;&#24615;&#21644;&#20854;&#20182;&#26377;&#24847;&#20041;&#30340;&#32479;&#35745;&#37327;&#21487;&#20197;&#35745;&#31639;&#20986;&#20132;&#38598;&#20844;&#24179;&#24615;&#30340;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#27495;&#35270;&#36890;&#24120;&#28041;&#21450;&#22810;&#20010;&#32500;&#24230;&#65288;&#21363;&#20445;&#25252;&#23646;&#24615;&#65289;&#65307;&#22240;&#27492;&#65292;&#30830;&#20445;&#8220;&#20132;&#38598;&#20844;&#24179;&#24615;&#8221;&#65292;&#21363;&#19981;&#27495;&#35270;&#20219;&#20309;&#23376;&#32452;&#65292;&#26159;&#29702;&#24819;&#30340;&#12290;&#20247;&#25152;&#21608;&#30693;&#65292;&#20165;&#29420;&#31435;&#22320;&#20445;&#35777;&#27599;&#20010;&#32500;&#24230;&#30340;&#8220;&#36793;&#38469;&#20844;&#24179;&#24615;&#8221;&#36890;&#24120;&#26159;&#19981;&#36275;&#22815;&#30340;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#23376;&#32452;&#30340;&#25351;&#25968;&#25968;&#37327;&#65292;&#30452;&#25509;&#20174;&#25968;&#25454;&#20013;&#24230;&#37327;&#20132;&#38598;&#20844;&#24179;&#24615;&#26159;&#19981;&#21487;&#33021;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30340;&#20027;&#35201;&#30446;&#26631;&#26159;&#36890;&#36807;&#32479;&#35745;&#20998;&#26512;&#35814;&#32454;&#20102;&#35299;&#36793;&#38469;&#20844;&#24179;&#24615;&#21644;&#20132;&#38598;&#20844;&#24179;&#24615;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#39318;&#20808;&#30830;&#23450;&#20102;&#19968;&#32452;&#36275;&#22815;&#30340;&#26465;&#20214;&#65292;&#21487;&#20197;&#22312;&#20854;&#20013;&#33719;&#24471;&#31934;&#30830;&#20851;&#31995;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#65292;&#22312;&#39640;&#27010;&#29575;&#19979;&#36890;&#36807;&#36793;&#38469;&#20844;&#24179;&#24615;&#21644;&#20854;&#20182;&#26377;&#24847;&#20041;&#30340;&#32479;&#35745;&#37327;&#21487;&#20197;&#35745;&#31639;&#20986;&#20132;&#38598;&#20844;&#24179;&#24615;&#30340;&#30028;&#38480;&#12290;&#38500;&#20102;&#23427;&#20204;&#30340;&#25551;&#36848;&#20215;&#20540;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#36825;&#20123;&#29702;&#35770;&#30028;&#38480;&#21487;&#20197;&#21033;&#29992;&#21040;&#19968;&#31181;&#21551;&#21457;&#24335;&#30340;&#25552;&#39640;&#26041;&#27861;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
Discrimination in machine learning often arises along multiple dimensions (a.k.a. protected attributes); it is then desirable to ensure \emph{intersectional fairness} -- i.e., that no subgroup is discriminated against. It is known that ensuring \emph{marginal fairness} for every dimension independently is not sufficient in general. Due to the exponential number of subgroups, however, directly measuring intersectional fairness from data is impossible. In this paper, our primary goal is to understand in detail the relationship between marginal and intersectional fairness through statistical analysis. We first identify a set of sufficient conditions under which an exact relationship can be obtained. Then, we prove bounds (easily computable through marginal fairness and other meaningful statistical quantities) in high-probability on intersectional fairness in the general case. Beyond their descriptive value, we show that these theoretical bounds can be leveraged to derive a heuristic impro
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26377;&#25928;&#30340;&#31639;&#27861;&#26469;&#23558;&#26631;&#31614;&#20449;&#24687;&#19982;&#31232;&#30095;&#22270;&#32467;&#26500;&#30456;&#32467;&#21512;&#65292;&#35299;&#20915;&#20102;&#22522;&#20110;&#32593;&#32476;&#25299;&#25169;&#30340;&#32858;&#31867;&#22312;&#31232;&#30095;&#22270;&#19978;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2205.11677</link><description>&lt;p&gt;
&#31232;&#30095;&#22270;&#30340;&#21322;&#30417;&#30563;&#32858;&#31867;&#65306;&#36328;&#36234;&#20102;&#20449;&#24687;&#29702;&#35770;&#38376;&#27099;
&lt;/p&gt;
&lt;p&gt;
Semi-Supervised Clustering of Sparse Graphs: Crossing the Information-Theoretic Threshold. (arXiv:2205.11677v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.11677
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26377;&#25928;&#30340;&#31639;&#27861;&#26469;&#23558;&#26631;&#31614;&#20449;&#24687;&#19982;&#31232;&#30095;&#22270;&#32467;&#26500;&#30456;&#32467;&#21512;&#65292;&#35299;&#20915;&#20102;&#22522;&#20110;&#32593;&#32476;&#25299;&#25169;&#30340;&#32858;&#31867;&#22312;&#31232;&#30095;&#22270;&#19978;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#22359;&#27169;&#22411;&#26159;&#19968;&#31181;&#29992;&#20110;&#32593;&#32476;&#32467;&#26500;&#25968;&#25454;&#32858;&#31867;&#21644;&#31038;&#21306;&#26816;&#27979;&#30340;&#22522;&#26412;&#38543;&#26426;&#22270;&#27169;&#22411;&#12290;&#25968;&#21313;&#24180;&#26469;&#23545;&#35813;&#38382;&#39064;&#30340;&#24191;&#27867;&#30740;&#31350;&#24050;&#32463;&#24314;&#31435;&#20102;&#35768;&#22810;&#28145;&#21051;&#30340;&#32467;&#26524;&#65292;&#20854;&#20013;Kesten-Stigum&#38376;&#27099;&#22788;&#30340;&#30456;&#21464;&#29616;&#35937;&#29305;&#21035;&#26377;&#36259;&#65292;&#20174;&#25968;&#23398;&#21644;&#24212;&#29992;&#35282;&#24230;&#37117;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#23427;&#34920;&#26126;&#65292;&#22914;&#26524;&#27169;&#22411;&#21442;&#25968;&#22312;&#26576;&#20010;&#38376;&#27099;&#20197;&#19979;&#65292;&#22522;&#20110;&#32593;&#32476;&#25299;&#25169;&#30340;&#20219;&#20309;&#20272;&#35745;&#22120;&#22312;&#31232;&#30095;&#22270;&#19978;&#37117;&#19981;&#33021;&#27604;&#38543;&#26426;&#29468;&#27979;&#26356;&#22909;&#12290;&#28982;&#32780;&#65292;&#22914;&#26524;&#25105;&#20204;&#31245;&#24494;&#25193;&#23637;&#35270;&#37326;&#21040;&#26222;&#36941;&#23384;&#22312;&#30340;&#21322;&#30417;&#30563;&#35774;&#32622;&#65292;&#36825;&#26679;&#30340;&#22522;&#26412;&#38480;&#21046;&#23558;&#23436;&#20840;&#28040;&#22833;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#36890;&#36807;&#25581;&#31034;&#20986;&#20219;&#24847;&#19968;&#37096;&#20998;&#26631;&#35760;&#65292;&#21487;&#20197;&#22312;&#25972;&#20010;&#21442;&#25968;&#22495;&#20869;&#23545;&#26816;&#27979;&#38382;&#39064;&#36827;&#34892;&#22788;&#29702;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#31181;&#26377;&#25928;&#30340;&#31639;&#27861;&#65292;&#19968;&#31181;&#26159;&#22522;&#20110;&#32452;&#21512;&#30340;&#65292;&#19968;&#31181;&#26159;&#22522;&#20110;&#20248;&#21270;&#30340;&#65292;&#29992;&#20110;&#23558;&#26631;&#31614;&#20449;&#24687;&#19982;&#22270;&#32467;&#26500;&#30456;&#32467;&#21512;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#20026;&#38543;&#26426;&#22359;&#27169;&#22411;&#21644;&#21322;&#30417;&#30563;&#23398;&#20064;&#24102;&#26469;&#20102;&#20840;&#26032;&#30340;&#35270;&#35282;&#65292;&#26631;&#24535;&#30528;&#31232;&#30095;&#22270;&#32858;&#31867;&#39046;&#22495;&#30340;&#37325;&#22823;&#31361;&#30772;&#12290;
&lt;/p&gt;
&lt;p&gt;
The stochastic block model is a canonical random graph model for clustering and community detection on network-structured data. Decades of extensive study on the problem have established many profound results, among which the phase transition at the Kesten-Stigum threshold is particularly interesting both from a mathematical and an applied standpoint. It states that no estimator based on the network topology can perform substantially better than chance on sparse graphs if the model parameter is below certain threshold. Nevertheless, if we slightly extend the horizon to the ubiquitous semi-supervised setting, such a fundamental limitation will disappear completely. We prove that with arbitrary fraction of the labels revealed, the detection problem is feasible throughout the parameter domain. Moreover, we introduce two efficient algorithms, one combinatorial and one based on optimization, to integrate label information with graph structures. Our work brings a new perspective to stochasti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21033;&#29992;&#31070;&#32463;Q-&#23398;&#20064;&#31639;&#27861;&#35299;&#20915;&#26925;&#22278;&#22411;PDE&#25968;&#20540;&#26041;&#27861;&#65292;&#35813;&#31639;&#27861;&#26080;&#32593;&#26684;&#19988;&#20855;&#26377;&#20811;&#26381;&#32500;&#24230;&#28798;&#38590;&#30340;&#28508;&#21147;&#12290;&#26412;&#25991;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#22312;&#21333;&#35843;PDE&#30340;&#24773;&#20917;&#19979;&#24471;&#21040;&#20102;&#26497;&#38480;&#31070;&#32463;&#32593;&#32476;&#25910;&#25947;&#20110;PDE&#35299;&#30340;&#35777;&#26126;&#12290;</title><link>http://arxiv.org/abs/2203.17128</link><description>&lt;p&gt;
&#21033;&#29992;&#31070;&#32463;Q-&#23398;&#20064;&#35299;&#20915;&#20559;&#24494;&#20998;&#26041;&#31243;
&lt;/p&gt;
&lt;p&gt;
Neural Q-learning for solving PDEs. (arXiv:2203.17128v2 [math.NA] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.17128
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21033;&#29992;&#31070;&#32463;Q-&#23398;&#20064;&#31639;&#27861;&#35299;&#20915;&#26925;&#22278;&#22411;PDE&#25968;&#20540;&#26041;&#27861;&#65292;&#35813;&#31639;&#27861;&#26080;&#32593;&#26684;&#19988;&#20855;&#26377;&#20811;&#26381;&#32500;&#24230;&#28798;&#38590;&#30340;&#28508;&#21147;&#12290;&#26412;&#25991;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#22312;&#21333;&#35843;PDE&#30340;&#24773;&#20917;&#19979;&#24471;&#21040;&#20102;&#26497;&#38480;&#31070;&#32463;&#32593;&#32476;&#25910;&#25947;&#20110;PDE&#35299;&#30340;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35299;&#20915;&#39640;&#32500;&#20559;&#24494;&#20998;&#26041;&#31243;&#26159;&#31185;&#23398;&#35745;&#31639;&#20013;&#30340;&#19968;&#20010;&#20027;&#35201;&#25361;&#25112;&#12290;&#26412;&#25991;&#36890;&#36807;&#25913;&#36827;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;Q-&#23398;&#20064;&#31639;&#27861;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#35299;&#20915;&#26925;&#22278;&#22411;PDE&#30340;&#25968;&#20540;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#8220;Q-PDE&#8221;&#31639;&#27861;&#26159;&#26080;&#32593;&#26684;&#30340;&#65292;&#22240;&#27492;&#20855;&#26377;&#20811;&#26381;&#32500;&#24230;&#28798;&#38590;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#20351;&#29992;&#31070;&#32463;&#20999;&#21521;&#26680;&#65288;NTK&#65289;&#26041;&#27861;&#35777;&#26126;&#65292;&#20351;&#29992;Q-PDE&#31639;&#27861;&#35757;&#32451;&#30340;PDE&#35299;&#30340;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;&#22120;&#65292;&#38543;&#30528;&#38544;&#34255;&#23618;&#21333;&#20803;&#25968;&#30340;&#22686;&#21152;&#65292;&#25910;&#25947;&#20110;&#26080;&#31351;&#32500;&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;ODE&#65289;&#30340;&#36712;&#36857;&#12290;&#23545;&#20110;&#21333;&#35843;PDE&#65288;&#21363;&#30001;&#21333;&#35843;&#31639;&#31526;&#32473;&#20986;&#30340;&#21487;&#33021;&#26159;&#38750;&#32447;&#24615;&#30340;PDE&#65289;&#65292;&#23613;&#31649;NTK&#20013;&#32570;&#20047;&#35889;&#38388;&#38553;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#28385;&#36275;&#26080;&#31351;&#32500;ODE&#30340;&#26497;&#38480;&#31070;&#32463;&#32593;&#32476;&#20250;&#38543;&#30528;&#35757;&#32451;&#26102;&#38388;&#30340;&#22686;&#21152;&#25910;&#25947;&#20110;$L^2$&#20013;&#30340;PDE&#35299;&#12290;&#26356;&#19968;&#33324;&#22320;&#35828;&#65292;&#25105;&#20204;&#21487;&#20197;&#35777;&#26126;wi&#30340;&#20219;&#20309;&#19981;&#21160;&#28857;&#37117;&#26159;&#35813;&#26080;&#31351;&#32500;ODE&#30340;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Solving high-dimensional partial differential equations (PDEs) is a major challenge in scientific computing. We develop a new numerical method for solving elliptic-type PDEs by adapting the Q-learning algorithm in reinforcement learning. Our "Q-PDE" algorithm is mesh-free and therefore has the potential to overcome the curse of dimensionality. Using a neural tangent kernel (NTK) approach, we prove that the neural network approximator for the PDE solution, trained with the Q-PDE algorithm, converges to the trajectory of an infinite-dimensional ordinary differential equation (ODE) as the number of hidden units $\rightarrow \infty$. For monotone PDE (i.e. those given by monotone operators, which may be nonlinear), despite the lack of a spectral gap in the NTK, we then prove that the limit neural network, which satisfies the infinite-dimensional ODE, converges in $L^2$ to the PDE solution as the training time $\rightarrow \infty$. More generally, we can prove that any fixed point of the wi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#65292;&#36890;&#36807;&#35299;&#20915;&#19968;&#20010;&#24102;&#26377;&#24809;&#32602;&#39033;&#30340;&#31163;&#25955;&#36807;&#24230;&#21442;&#25968;&#21270;&#20248;&#21270;&#38382;&#39064;&#65292;&#21487;&#20197;&#25214;&#21040;&#36817;&#20046;&#26368;&#20248;&#30340; $\hat f$&#12290;</title><link>http://arxiv.org/abs/2203.15994</link><description>&lt;p&gt;
&#26368;&#20248;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Optimal Learning. (arXiv:2203.15994v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.15994
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#65292;&#36890;&#36807;&#35299;&#20915;&#19968;&#20010;&#24102;&#26377;&#24809;&#32602;&#39033;&#30340;&#31163;&#25955;&#36807;&#24230;&#21442;&#25968;&#21270;&#20248;&#21270;&#38382;&#39064;&#65292;&#21487;&#20197;&#25214;&#21040;&#36817;&#20046;&#26368;&#20248;&#30340; $\hat f$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#20851;&#20110; $f$ &#30340;&#32473;&#23450;&#25968;&#25454;&#23398;&#20064;&#26410;&#30693;&#20989;&#25968; $f$ &#30340;&#38382;&#39064;&#12290;&#23398;&#20064;&#38382;&#39064;&#26159;&#32473;&#20986;&#19968;&#20010;&#36817;&#20284;&#20540; $ \hat f $&#65292;&#29992;&#20110;&#39044;&#27979;&#25968;&#25454;&#22806;&#30340; $f$ &#20540;&#12290;&#36825;&#20010;&#23398;&#20064;&#38382;&#39064;&#30340;&#20934;&#30830;&#24615;&#21462;&#20915;&#20110;&#65306;&#65288;i&#65289;&#25105;&#20204;&#23545; $f$ &#26377;&#20160;&#20040;&#39069;&#22806;&#30340;&#20449;&#24687;&#65288;&#31216;&#20026;&#27169;&#22411;&#31867;&#20551;&#35774;&#65289;&#65292;&#65288;ii&#65289;&#25105;&#20204;&#22914;&#20309;&#24230;&#37327; $\hat f$ &#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#65292;&#65288;iii&#65289;&#25968;&#25454;&#21644;&#25968;&#25454;&#31449;&#28857;&#30340;&#24773;&#20917;&#65292;&#65288;iv&#65289;&#25968;&#25454;&#35266;&#23519;&#26159;&#21542;&#21463;&#21040;&#22122;&#22768;&#27745;&#26579;&#12290;&#22312;&#23384;&#22312;&#27169;&#22411;&#31867;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#24050;&#30693;&#26368;&#20248;&#24674;&#22797;&#24615;&#33021;&#30340;&#25968;&#23398;&#25551;&#36848;&#12290;&#22312;&#26631;&#20934;&#27169;&#22411;&#31867;&#20551;&#35774;&#19979;&#65292;&#26412;&#25991;&#35777;&#26126;&#65292;&#36890;&#36807;&#35299;&#20915;&#19968;&#20010;&#24102;&#26377;&#24809;&#32602;&#39033;&#30340;&#31163;&#25955;&#36807;&#24230;&#21442;&#25968;&#21270;&#20248;&#21270;&#38382;&#39064;&#65292;&#21487;&#20197;&#25214;&#21040;&#36817;&#20046;&#26368;&#20248;&#30340; $\hat f$&#12290;&#26368;&#20248;&#25351;&#30340;&#26159;&#35823;&#24046;&#21463;&#21040;&#22266;&#23450;&#20493;&#25968;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the problem of learning an unknown function $f$ from given data about $f$. The learning problem is to give an approximation $\hat f$ to $f$ that predicts the values of $f$ away from the data. There are numerous settings for this learning problem depending on (i) what additional information we have about $f$ (known as a model class assumption), (ii) how we measure the accuracy of how well $\hat f$ predicts $f$, (iii) what is known about the data and data sites, (iv) whether the data observations are polluted by noise. A mathematical description of the optimal performance possible (the smallest possible error of recovery) is known in the presence of a model class assumption. Under standard model class assumptions, it is shown in this paper that a near optimal $\hat f$ can be found by solving a certain discrete over-parameterized optimization problem with a penalty term. Here, near optimal means that the error is bounded by a fixed constant times the optimal error. This
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#36229;&#31435;&#26041;&#20307;&#25628;&#32034;&#30340;&#21487;&#35299;&#37322;&#31163;&#32447;&#31574;&#30053;&#23398;&#20064;&#31639;&#27861;&#65292;&#21487;&#20197;&#29992;&#21512;&#21462;&#33539;&#24335;&#34920;&#31034;&#65292;&#21487;&#20197;&#28789;&#27963;&#36924;&#36817;&#20219;&#20309;&#21487;&#27979;&#20989;&#25968;&#12290;&#22312;&#20020;&#24202;&#23454;&#36341;&#20013;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2203.02473</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#30340;&#31163;&#32447;&#31574;&#30053;&#23398;&#20064;&#65306;&#22522;&#20110;&#36229;&#31435;&#26041;&#20307;&#25628;&#32034;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Interpretable Off-Policy Learning via Hyperbox Search. (arXiv:2203.02473v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.02473
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#36229;&#31435;&#26041;&#20307;&#25628;&#32034;&#30340;&#21487;&#35299;&#37322;&#31163;&#32447;&#31574;&#30053;&#23398;&#20064;&#31639;&#27861;&#65292;&#21487;&#20197;&#29992;&#21512;&#21462;&#33539;&#24335;&#34920;&#31034;&#65292;&#21487;&#20197;&#28789;&#27963;&#36924;&#36817;&#20219;&#20309;&#21487;&#27979;&#20989;&#25968;&#12290;&#22312;&#20020;&#24202;&#23454;&#36341;&#20013;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#24615;&#21270;&#27835;&#30103;&#20915;&#31574;&#24050;&#25104;&#20026;&#29616;&#20195;&#21307;&#23398;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#12290;&#22240;&#27492;&#65292;&#30446;&#26631;&#26159;&#26681;&#25454;&#20010;&#20307;&#24739;&#32773;&#30340;&#29305;&#24449;&#36827;&#34892;&#27835;&#30103;&#20915;&#31574;&#12290;&#24050;&#32463;&#24320;&#21457;&#20102;&#35768;&#22810;&#26041;&#27861;&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#23398;&#20064;&#36825;&#26679;&#30340;&#31574;&#30053;&#65292;&#20197;&#23454;&#29616;&#22312;&#29305;&#23450;&#31574;&#30053;&#31867;&#21035;&#19979;&#33719;&#24471;&#26368;&#20339;&#32467;&#26524;&#12290;&#20294;&#26159;&#65292;&#36825;&#20123;&#26041;&#27861;&#24456;&#23569;&#20855;&#26377;&#21487;&#35299;&#37322;&#24615;&#12290;&#28982;&#32780;&#65292;&#21487;&#35299;&#37322;&#24615;&#36890;&#24120;&#26159;&#20020;&#24202;&#23454;&#36341;&#20013;&#31574;&#30053;&#23398;&#20064;&#30340;&#21069;&#25552;&#26465;&#20214;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36229;&#31435;&#26041;&#20307;&#25628;&#32034;&#30340;&#21487;&#35299;&#37322;&#31163;&#32447;&#31574;&#30053;&#23398;&#20064;&#31639;&#27861;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#30340;&#31574;&#30053;&#21487;&#20197;&#29992;&#21512;&#21462;&#33539;&#24335;&#34920;&#31034;&#65288;&#21363;AND&#30340;OR&#65289;&#65292;&#22240;&#27492;&#26159;&#23481;&#26131;&#29702;&#35299;&#30340;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;&#36890;&#29992;&#36924;&#36817;&#23450;&#29702;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31574;&#30053;&#31867;&#21487;&#20197;&#28789;&#27963;&#22320;&#36924;&#36817;&#20219;&#20309;&#21487;&#27979;&#20989;&#25968;&#12290;&#20026;&#20102;&#20248;&#21270;&#65292;&#25105;&#20204;&#22312;&#20998;&#25903;&#23450;&#30028;&#26694;&#26550;&#20869;&#24320;&#21457;&#20102;&#19968;&#20010;&#23450;&#21046;&#30340;&#21015;&#29983;&#25104;&#36807;&#31243;&#12290;&#36890;&#36807;&#27169;&#25311;&#30740;&#31350;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Personalized treatment decisions have become an integral part of modern medicine. Thereby, the aim is to make treatment decisions based on individual patient characteristics. Numerous methods have been developed for learning such policies from observational data that achieve the best outcome across a certain policy class. Yet these methods are rarely interpretable. However, interpretability is often a prerequisite for policy learning in clinical practice. In this paper, we propose an algorithm for interpretable off-policy learning via hyperbox search. In particular, our policies can be represented in disjunctive normal form (i.e., OR-of-ANDs) and are thus intelligible. We prove a universal approximation theorem that shows that our policy class is flexible enough to approximate any measurable function arbitrarily well. For optimization, we develop a tailored column generation procedure within a branch-and-bound framework. Using a simulation study, we demonstrate that our algorithm outpe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#35782;&#21035;&#39281;&#21644;&#22352;&#26631;&#21152;&#36895;&#35299;&#20915;&#38750;&#36127;&#21644;&#26377;&#30028;&#21464;&#37327;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#30340;&#25216;&#26415;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20854;&#20855;&#26377;&#20196;&#20154;&#20449;&#26381;&#30340;&#21152;&#36895;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2202.07258</link><description>&lt;p&gt;
&#20351;&#29992;&#23433;&#20840;&#31579;&#36873;&#21152;&#36895;&#38750;&#36127;&#21644;&#26377;&#30028;&#21464;&#37327;&#32447;&#24615;&#22238;&#24402;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Accelerating Non-Negative and Bounded-Variable Linear Regression Algorithms with Safe Screening. (arXiv:2202.07258v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.07258
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#35782;&#21035;&#39281;&#21644;&#22352;&#26631;&#21152;&#36895;&#35299;&#20915;&#38750;&#36127;&#21644;&#26377;&#30028;&#21464;&#37327;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#30340;&#25216;&#26415;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20854;&#20855;&#26377;&#20196;&#20154;&#20449;&#26381;&#30340;&#21152;&#36895;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#36127;&#21644;&#26377;&#30028;&#21464;&#37327;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#20449;&#21495;&#22788;&#29702;&#30340;&#21508;&#31181;&#24212;&#29992;&#20013;&#37117;&#26377;&#25152;&#28041;&#21450;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25216;&#26415;&#65292;&#36890;&#36807;&#22312;&#36845;&#20195;&#36807;&#31243;&#20013;&#35782;&#21035;&#39281;&#21644;&#22352;&#26631;&#65292;&#21152;&#36895;&#29616;&#26377;&#35299;&#20915;&#22120;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;&#36825;&#31867;&#20284;&#20110;&#20808;&#21069;&#38024;&#23545;&#31232;&#30095;&#27491;&#21017;&#21270;&#22238;&#24402;&#38382;&#39064;&#25552;&#20986;&#30340;&#23433;&#20840;&#31579;&#36873;&#25216;&#26415;&#12290;&#25152;&#25552;&#20986;&#30340;&#31574;&#30053;&#26159;&#32463;&#36807;&#35777;&#26126;&#26159;&#23433;&#20840;&#30340;&#65292;&#22240;&#20026;&#23427;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#65292;&#34920;&#26126;&#25152;&#35782;&#21035;&#30340;&#22352;&#26631;&#30830;&#23454;&#22312;&#26368;&#20248;&#35299;&#20013;&#26159;&#39281;&#21644;&#30340;&#12290;&#23545;&#21512;&#25104;&#25968;&#25454;&#21644;&#23454;&#38469;&#25968;&#25454;&#30340;&#23454;&#39564;&#32467;&#26524;&#37117;&#34920;&#26126;&#65292;&#23545;&#20110;&#38750;&#36127;&#21644;&#26377;&#30028;&#21464;&#37327;&#38382;&#39064;&#37117;&#20855;&#26377;&#20196;&#20154;&#20449;&#26381;&#30340;&#21152;&#36895;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Non-negative and bounded-variable linear regression problems arise in a variety of applications in machine learning and signal processing. In this paper, we propose a technique to accelerate existing solvers for these problems by identifying saturated coordinates in the course of iterations. This is akin to safe screening techniques previously proposed for sparsity-regularized regression problems. The proposed strategy is provably safe as it provides theoretical guarantees that the identified coordinates are indeed saturated in the optimal solution. Experimental results on synthetic and real data show compelling accelerations for both non-negative and bounded-variable problems.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#20989;&#25968;&#27987;&#24230;&#34920;&#36798;&#24335;&#65292;&#24182;&#32473;&#20986;&#20102;&#27987;&#24230;&#38598;&#20013;&#19982; Hanson-Wright&#19981;&#31561;&#24335;&#30340;&#24191;&#20041;&#25512;&#24191;&#65292;&#30740;&#31350;&#20102;&#38543;&#26426;&#30697;&#38453;XDX^(t)&#21450;&#20854;&#35299;&#26512;&#24335;Q&#12290;</title><link>http://arxiv.org/abs/2102.08020</link><description>&lt;p&gt;
&#27979;&#24230;&#38598;&#20013;&#21644;&#38543;&#26426;&#21521;&#37327;&#30340;&#24191;&#20041;&#31215;&#21450;&#20854;&#22312; Hanson-Wright &#19981;&#31561;&#24335;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Concentration of measure and generalized product of random vectors with an application to Hanson-Wright-like inequalities. (arXiv:2102.08020v5 [math.PR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2102.08020
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#20989;&#25968;&#27987;&#24230;&#34920;&#36798;&#24335;&#65292;&#24182;&#32473;&#20986;&#20102;&#27987;&#24230;&#38598;&#20013;&#19982; Hanson-Wright&#19981;&#31561;&#24335;&#30340;&#24191;&#20041;&#25512;&#24191;&#65292;&#30740;&#31350;&#20102;&#38543;&#26426;&#30697;&#38453;XDX^(t)&#21450;&#20854;&#35299;&#26512;&#24335;Q&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174; $m$ &#20010;&#38543;&#26426;&#21521;&#37327; $Z_1, \ldots, Z_m$ &#30697;&#38453;&#30340;&#27979;&#24230;&#38598;&#20013;&#20551;&#35774;&#20986;&#21457;&#65292;&#32473;&#20986;&#20102;&#20989;&#25968; $\phi(Z_1, \ldots, Z_m)$ &#30340;&#27987;&#24230;&#34920;&#36798;&#24335;&#12290;&#20854;&#20013;&#65292;$\phi$ &#22312;&#27599;&#20010;&#21464;&#37327;&#19978;&#30340;&#21464;&#21270;&#21462;&#20915;&#20110;&#20854;&#20182;&#21464;&#37327;&#30340;&#33539;&#25968;&#65288;&#25110;&#21322;&#33539;&#25968;&#65289;&#30340;&#31215;&#65288;&#23601;&#20687; $\phi$ &#26412;&#36523;&#23601;&#26159;&#19968;&#20010;&#31215;&#65289;&#12290;&#25105;&#20204;&#36890;&#36807;&#21508;&#31181; Hanson-Wright&#27987;&#24230;&#19981;&#31561;&#24335;&#30340;&#27867;&#21270;&#20030;&#20363;&#35828;&#26126;&#20102;&#36825;&#20010;&#32467;&#26524;&#30340;&#37325;&#35201;&#24615;&#65292;&#20197;&#21450;&#22312;&#32479;&#35745;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#20855;&#26377;&#22522;&#26412;&#24847;&#20041;&#30340;&#38543;&#26426;&#30697;&#38453; $XDX^T$ &#21450;&#20854;&#35299;&#26512;&#24335; $Q=(I_p&#8722;\frac{1}{n}XDX^T)^{-1}$ &#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Starting from concentration of measure hypotheses on $m$ random vectors $Z_1,\ldots, Z_m$, this article provides an expression of the concentration of functionals $\phi(Z_1,\ldots, Z_m)$ where the variations of $\phi$ on each variable depend on the product of the norms (or semi-norms) of the other variables (as if $\phi$ were a product). We illustrate the importance of this result through various generalizations of the Hanson-Wright concentration inequality as well as through a study of the random matrix $XDX^T$ and its resolvent $Q = (I_p - \frac{1}{n}XDX^T)^{-1}$, where $X$ and $D$ are random, which have fundamental interest in statistical machine learning applications.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;RELL&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#30693;&#35782;&#33976;&#39311;&#21644;&#30693;&#35782;&#20445;&#25345;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#20197;&#21327;&#21516;&#38598;&#25104;&#22312;&#19981;&#21516;&#20219;&#21153;&#19978;&#29420;&#31435;&#23398;&#20064;&#30340;&#34920;&#31034;&#65292;&#22312;&#20934;&#32447;&#24615;&#22797;&#26434;&#24230;&#19979;&#23454;&#29616;&#20102;&#21069;&#21521;&#21644;&#21518;&#21521;&#20256;&#36882;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#21508;&#31181;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#65292;RELL&#30340;&#34920;&#29616;&#20248;&#20110;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#65292;&#23588;&#20854;&#26159;&#22312;&#23384;&#22312;&#28798;&#38590;&#24615;&#36951;&#24536;&#30340;&#24773;&#20917;&#19979;&#65292;&#33021;&#22815;&#26174;&#30528;&#25913;&#21892;&#21453;&#21521;&#20256;&#36882;&#12290;</title><link>http://arxiv.org/abs/2004.12908</link><description>&lt;p&gt;
&#20195;&#34920;&#24615;&#38598;&#25104;&#22312;&#20934;&#32447;&#24615;&#22797;&#26434;&#24230;&#19979;&#23454;&#29616;&#21327;&#21516;&#29983;&#21629;&#21608;&#26399;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Representation Ensembling for Synergistic Lifelong Learning with Quasilinear Complexity. (arXiv:2004.12908v16 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2004.12908
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;RELL&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#30693;&#35782;&#33976;&#39311;&#21644;&#30693;&#35782;&#20445;&#25345;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#20197;&#21327;&#21516;&#38598;&#25104;&#22312;&#19981;&#21516;&#20219;&#21153;&#19978;&#29420;&#31435;&#23398;&#20064;&#30340;&#34920;&#31034;&#65292;&#22312;&#20934;&#32447;&#24615;&#22797;&#26434;&#24230;&#19979;&#23454;&#29616;&#20102;&#21069;&#21521;&#21644;&#21518;&#21521;&#20256;&#36882;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#21508;&#31181;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#65292;RELL&#30340;&#34920;&#29616;&#20248;&#20110;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#65292;&#23588;&#20854;&#26159;&#22312;&#23384;&#22312;&#28798;&#38590;&#24615;&#36951;&#24536;&#30340;&#24773;&#20917;&#19979;&#65292;&#33021;&#22815;&#26174;&#30528;&#25913;&#21892;&#21453;&#21521;&#20256;&#36882;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32456;&#36523;&#23398;&#20064;&#20013;&#65292;&#25968;&#25454;&#19981;&#20165;&#21487;&#20197;&#29992;&#20110;&#25913;&#36827;&#24403;&#21069;&#20219;&#21153;&#30340;&#24615;&#33021;&#65292;&#36824;&#21487;&#20197;&#29992;&#20110;&#20043;&#21069;&#21644;&#23578;&#26410;&#36935;&#21040;&#30340;&#20219;&#21153;&#12290;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#21017;&#20174;&#31354;&#30333;&#29366;&#24577;&#24320;&#22987;&#65292;&#20165;&#38024;&#23545;&#21333;&#20010;&#20219;&#21153;&#20351;&#29992;&#25968;&#25454;&#12290;&#34429;&#28982;&#20256;&#32479;&#36801;&#31227;&#23398;&#20064;&#31639;&#27861;&#21487;&#20197;&#25552;&#39640;&#26410;&#26469;&#20219;&#21153;&#30340;&#24615;&#33021;&#65292;&#20294;&#22312;&#23398;&#20064;&#26032;&#20219;&#21153;&#21518;&#23545;&#26087;&#20219;&#21153;&#30340;&#24615;&#33021;&#19979;&#38477;&#65288;&#31216;&#20026;&#36951;&#24536;&#65289;&#12290;&#36817;&#26399;&#38024;&#23545;&#36830;&#32493;&#25110;&#32456;&#36523;&#23398;&#20064;&#30340;&#35768;&#22810;&#26041;&#27861;&#37117;&#35797;&#22270;&#22312;&#32473;&#23450;&#26032;&#20219;&#21153;&#30340;&#24773;&#20917;&#19979;&#20445;&#25345;&#23545;&#26087;&#20219;&#21153;&#30340;&#24615;&#33021;&#12290;&#20294;&#26159;&#65292;&#20165;&#21162;&#21147;&#36991;&#20813;&#24536;&#35760;&#23558;&#30446;&#26631;&#23450;&#24471;&#36807;&#20302;&#12290;&#32456;&#36523;&#23398;&#20064;&#30340;&#30446;&#26631;&#19981;&#20165;&#24212;&#35813;&#26159;&#25552;&#39640;&#26410;&#26469;&#20219;&#21153;&#65288;&#21069;&#21521;&#20256;&#36882;&#65289;&#30340;&#24615;&#33021;&#65292;&#32780;&#19988;&#36824;&#24212;&#35813;&#26159;&#29992;&#20219;&#20309;&#26032;&#25968;&#25454;&#25552;&#39640;&#36807;&#21435;&#20219;&#21153;&#65288;&#21453;&#21521;&#20256;&#36882;&#65289;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#35265;&#35299;&#26159;&#65292;&#25105;&#20204;&#21487;&#20197;&#21327;&#21516;&#38598;&#25104;&#20998;&#21035;&#22312;&#19981;&#21516;&#20219;&#21153;&#19978;&#29420;&#31435;&#23398;&#20064;&#30340;&#34920;&#31034;&#65292;&#20197;&#23454;&#29616;&#20934;&#32447;&#24615;&#22797;&#26434;&#24230;&#19979;&#30340;&#21069;&#21521;&#21644;&#21518;&#21521;&#20256;&#36882;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#31216;&#20026;&#8220;&#32456;&#36523;&#23398;&#20064;&#20013;&#30340;&#34920;&#31034;&#38598;&#25104;&#65288;RELL&#65289;&#8221;&#65292;&#23427;&#38598;&#25104;&#20102;&#30693;&#35782;&#33976;&#39311;&#21644;&#30693;&#35782;&#20445;&#25345;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#20197;&#21033;&#29992;&#19981;&#21516;&#34920;&#31034;&#20013;&#21253;&#21547;&#30340;&#20114;&#34917;&#20449;&#24687;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;RELL&#22312;&#21508;&#31181;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#37117;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#26041;&#27861;&#65292;&#23588;&#20854;&#26159;&#22312;&#23384;&#22312;&#28798;&#38590;&#24615;&#36951;&#24536;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#26174;&#30528;&#26356;&#22909;&#30340;&#21453;&#21521;&#20256;&#36882;&#12290;
&lt;/p&gt;
&lt;p&gt;
In lifelong learning, data are used to improve performance not only on the current task, but also on previously encountered, and as yet unencountered tasks. In contrast, classical machine learning, which we define as, starts from a blank slate, or tabula rasa and uses data only for the single task at hand. While typical transfer learning algorithms can improve performance on future tasks, their performance on prior tasks degrades upon learning new tasks (called forgetting). Many recent approaches for continual or lifelong learning have attempted to maintain performance on old tasks given new tasks. But striving to avoid forgetting sets the goal unnecessarily low. The goal of lifelong learning should be not only to improve performance on future tasks (forward transfer) but also on past tasks (backward transfer) with any new data. Our key insight is that we can synergistically ensemble representations -- that were learned independently on disparate tasks -- to enable both forward and bac
&lt;/p&gt;</description></item></channel></rss>