<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#35299;&#20915;&#20102;&#36890;&#29992;&#24191;&#20041;&#32447;&#24615;&#23545;&#25239;&#24615;&#25490;&#21517;&#38382;&#39064;&#20013;&#30340;&#21338;&#23572;&#36798;&#21518;&#24724;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#39640;&#24230;&#34920;&#36798;&#21147;&#30340;&#27169;&#22411;&#65292;&#24182;&#20351;&#29992;&#19968;&#31181;&#26032;&#30340;&#8220;&#20808;&#25506;&#32034;&#20877;&#25191;&#34892;&#8221;&#31639;&#27861;&#36991;&#20813;&#20102;&#22256;&#38590;&#30340;&#21518;&#24724;&#19979;&#38480;&#12290;</title><link>http://arxiv.org/abs/2303.08816</link><description>&lt;p&gt;
Borda Regret Minimization for Generalized Linear Dueling Bandits (&#36890;&#29992;&#24191;&#20041;&#32447;&#24615;&#23545;&#25239;&#24615;&#25490;&#21517;&#38382;&#39064;&#30340;&#21338;&#23572;&#36798;&#21518;&#24724;&#26368;&#23567;&#21270;&#31639;&#27861;)
&lt;/p&gt;
&lt;p&gt;
Borda Regret Minimization for Generalized Linear Dueling Bandits. (arXiv:2303.08816v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.08816
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#36890;&#29992;&#24191;&#20041;&#32447;&#24615;&#23545;&#25239;&#24615;&#25490;&#21517;&#38382;&#39064;&#20013;&#30340;&#21338;&#23572;&#36798;&#21518;&#24724;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#39640;&#24230;&#34920;&#36798;&#21147;&#30340;&#27169;&#22411;&#65292;&#24182;&#20351;&#29992;&#19968;&#31181;&#26032;&#30340;&#8220;&#20808;&#25506;&#32034;&#20877;&#25191;&#34892;&#8221;&#31639;&#27861;&#36991;&#20813;&#20102;&#22256;&#38590;&#30340;&#21518;&#24724;&#19979;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#24615;&#25490;&#21517;&#38382;&#39064;(Dueling bandits)&#24120;&#34987;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#65292;&#22914;&#25512;&#33616;&#31995;&#32479;&#21644;&#25490;&#21517;&#38382;&#39064;&#12290;&#26412;&#25991;&#30740;&#31350;&#23545;&#25239;&#24615;&#25490;&#21517;&#38382;&#39064;&#20013;&#21338;&#23572;&#36798;&#21518;&#24724;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#26088;&#22312;&#30830;&#23450;&#20855;&#26377;&#26368;&#39640;&#21338;&#23572;&#36798;&#24471;&#20998;&#30340;&#39033;&#30446;&#65292;&#24182;&#21516;&#26102;&#26368;&#23567;&#21270;&#32047;&#35745;&#30340;&#21518;&#24724;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#12289;&#39640;&#24230;&#34920;&#36798;&#21147;&#30340;&#36890;&#29992;&#24191;&#20041;&#32447;&#24615;&#23545;&#25239;&#24615;&#25490;&#21517;&#27169;&#22411;&#65292;&#23427;&#21253;&#25324;&#35768;&#22810;&#29616;&#26377;&#27169;&#22411;&#12290; &#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#21338;&#23572;&#36798;&#21518;&#24724;&#26368;&#23567;&#21270;&#38382;&#39064;&#26159;&#22256;&#38590;&#30340;&#12290; &#25105;&#20204;&#35777;&#26126;&#20102;&#28176;&#36817;&#26102;&#38388;&#22797;&#26434;&#24230;&#30340;&#21518;&#24724;&#19979;&#38480;&#26159;$\Omega(d^{2/3} T^{2/3})$&#65292;&#20854;&#20013;$d$&#26159;&#19978;&#19979;&#25991;&#21521;&#37327;&#30340;&#32500;&#25968;&#65292;$T$&#26159;&#26102;&#38388;&#36328;&#24230;&#12290;&#20026;&#20102;&#36798;&#21040;&#19979;&#38480;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;"&#20808;&#25506;&#32034;&#20877;&#25191;&#34892;"&#30340;&#31639;&#27861;&#65292;&#23427;&#20855;&#26377;&#20960;&#20046;&#21305;&#37197;&#30340;&#19978;&#38480;&#22238;&#24402;&#35823;&#24046;$\tilde{O}(d^{2/3} T^{2/3})$&#12290;&#24403;&#39033;&#30446;&#25968;&#37327;$K$&#24456;&#23567;&#26102;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#21487;&#20197;&#36890;&#36807;&#36866;&#24403;&#36873;&#25321;&#36229;&#21442;&#25968;&#20197;&#36798;&#21040;&#26356;&#23567;&#30340;&#21518;&#24724;$\tilde{O}((d\log K)^{1/3}T^{2/3})$&#12290;
&lt;/p&gt;
&lt;p&gt;
Dueling bandits are widely used to model preferential feedback that is prevalent in machine learning applications such as recommendation systems and ranking. In this paper, we study the Borda regret minimization problem for dueling bandits, which aims to identify the item with the highest Borda score while minimizing the cumulative regret. We propose a new and highly expressive generalized linear dueling bandits model, which covers many existing models. Surprisingly, the Borda regret minimization problem turns out to be difficult, as we prove a regret lower bound of order $\Omega(d^{2/3} T^{2/3})$, where $d$ is the dimension of contextual vectors and $T$ is the time horizon. To attain the lower bound, we propose an explore-then-commit type algorithm, which has a nearly matching regret upper bound $\tilde{O}(d^{2/3} T^{2/3})$. When the number of items/arms $K$ is small, our algorithm can achieve a smaller regret $\tilde{O}( (d \log K)^{1/3} T^{2/3})$ with proper choices of hyperparamete
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;Anchors&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#36825;&#26159;&#19968;&#31181;&#22522;&#20110;&#35268;&#21017;&#30340;&#21487;&#35299;&#37322;&#24615;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#37322;&#25991;&#26412;&#20998;&#31867;&#22120;&#30340;&#20915;&#31574;&#12290;</title><link>http://arxiv.org/abs/2303.08806</link><description>&lt;p&gt;
&#29702;&#35299;&#20107;&#21518;&#35299;&#37322;&#22120;&#65306;&#20197;Anchors&#20026;&#20363;
&lt;/p&gt;
&lt;p&gt;
Understanding Post-hoc Explainers: The Case of Anchors. (arXiv:2303.08806v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.08806
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;Anchors&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#36825;&#26159;&#19968;&#31181;&#22522;&#20110;&#35268;&#21017;&#30340;&#21487;&#35299;&#37322;&#24615;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#37322;&#25991;&#26412;&#20998;&#31867;&#22120;&#30340;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21487;&#35299;&#37322;&#24615;&#26159;&#19968;&#39033;&#39640;&#24230;&#35201;&#27714;&#20294;&#38590;&#20197;&#23454;&#29616;&#30340;&#20219;&#21153;&#12290;&#20026;&#20102;&#35299;&#37322;&#36825;&#20123;&#27169;&#22411;&#30340;&#20010;&#20307;&#39044;&#27979;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#26412;&#22320;&#27169;&#22411;&#26080;&#20851;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#20135;&#29983;&#35299;&#37322;&#30340;&#36807;&#31243;&#23545;&#20110;&#29992;&#25143;&#26469;&#35828;&#21487;&#33021;&#19982;&#35201;&#35299;&#37322;&#30340;&#39044;&#27979;&#19968;&#26679;&#31070;&#31192;&#12290;&#27492;&#22806;&#65292;&#21487;&#35299;&#37322;&#24615;&#26041;&#27861;&#32463;&#24120;&#32570;&#20047;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#19988;&#23427;&#20204;&#22312;&#31616;&#21333;&#27169;&#22411;&#19978;&#30340;&#34892;&#20026;&#36890;&#24120;&#26159;&#26410;&#30693;&#30340;&#12290;&#26412;&#25991;&#23545;Anchors&#65288;Ribeiro&#31561;&#20154;&#65292;2018&#65289;&#36827;&#34892;&#29702;&#35770;&#20998;&#26512;&#65306;&#19968;&#31181;&#27969;&#34892;&#30340;&#22522;&#20110;&#35268;&#21017;&#30340;&#21487;&#35299;&#37322;&#24615;&#26041;&#27861;&#65292;&#23427;&#24378;&#35843;&#19968;&#23567;&#32452;&#21333;&#35789;&#20197;&#35299;&#37322;&#25991;&#26412;&#20998;&#31867;&#22120;&#30340;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;
In many scenarios, the interpretability of machine learning models is a highly required but difficult task. To explain the individual predictions of such models, local model-agnostic approaches have been proposed. However, the process generating the explanations can be, for a user, as mysterious as the prediction to be explained. Furthermore, interpretability methods frequently lack theoretical guarantees, and their behavior on simple models is frequently unknown. While it is difficult, if not impossible, to ensure that an explainer behaves as expected on a cutting-edge model, we can at least ensure that everything works on simple, already interpretable models. In this paper, we present a theoretical analysis of Anchors (Ribeiro et al., 2018): a popular rule-based interpretability method that highlights a small set of words to explain a text classifier's decision. After formalizing its algorithm and providing useful insights, we demonstrate mathematically that Anchors produces meaningf
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#36890;&#36807;&#27169;&#22411;&#36873;&#25321;&#21644;&#20132;&#21449;&#39564;&#35777;&#39118;&#38505;&#20272;&#35745;&#26469;&#23398;&#20064;&#30340;&#19968;&#33324;&#26041;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#26080;&#20998;&#24067;&#20559;&#24046;&#30028;&#65292;&#27604;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#26041;&#27861;&#26356;&#32039;&#23494;&#65292;&#22312;&#19968;&#20123;&#24773;&#20917;&#19979;&#34920;&#29616;&#26356;&#20248;&#12290;</title><link>http://arxiv.org/abs/2303.08777</link><description>&lt;p&gt;
&#27169;&#22411;&#36873;&#25321;&#37197;&#21512;&#20132;&#21449;&#39564;&#35777;&#39118;&#38505;&#20272;&#35745;&#30340;&#26080;&#20998;&#24067;&#20559;&#24046;&#30028;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Distribution-free Deviation Bounds of Learning via Model Selection with Cross-validation Risk Estimation. (arXiv:2303.08777v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.08777
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#36890;&#36807;&#27169;&#22411;&#36873;&#25321;&#21644;&#20132;&#21449;&#39564;&#35777;&#39118;&#38505;&#20272;&#35745;&#26469;&#23398;&#20064;&#30340;&#19968;&#33324;&#26041;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#26080;&#20998;&#24067;&#20559;&#24046;&#30028;&#65292;&#27604;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#26041;&#27861;&#26356;&#32039;&#23494;&#65292;&#22312;&#19968;&#20123;&#24773;&#20917;&#19979;&#34920;&#29616;&#26356;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20132;&#21449;&#39564;&#35777;&#26041;&#27861;&#30340;&#39118;&#38505;&#20272;&#35745;&#21644;&#27169;&#22411;&#36873;&#25321;&#22312;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#24471;&#21040;&#20102;&#24191;&#27867;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#23398;&#20064;&#36890;&#36807;&#27169;&#22411;&#36873;&#25321;&#19982;&#20132;&#21449;&#39564;&#35777;&#39118;&#38505;&#20272;&#35745;&#30340;&#29702;&#35770;&#24615;&#36136;&#30340;&#29702;&#35299;&#22312;&#20854;&#24191;&#27867;&#20351;&#29992;&#38754;&#21069;&#30456;&#24403;&#32570;&#20047;&#12290;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#65292;&#26412;&#25991;&#23558;&#23398;&#20064;&#36890;&#36807;&#27169;&#22411;&#36873;&#25321;&#19982;&#20132;&#21449;&#39564;&#35777;&#39118;&#38505;&#20272;&#35745;&#20316;&#20026;&#19968;&#31181;&#32463;&#20856;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#19968;&#33324;&#31995;&#32479;&#23398;&#20064;&#26694;&#26550;&#65292;&#24182;&#24314;&#31435;&#20102;&#22522;&#20110;VC&#32500;&#30340;&#26080;&#20998;&#24067;&#20559;&#24046;&#36793;&#30028;&#65292;&#32473;&#20986;&#20102;&#32467;&#26524;&#30340;&#35814;&#32454;&#35777;&#26126;&#65292;&#24182;&#32771;&#34385;&#20102;&#26377;&#30028;&#21644;&#26080;&#30028;&#30340;&#25439;&#22833;&#20989;&#25968;&#12290;&#25105;&#20204;&#36824;&#25512;&#23548;&#20986;&#22312;&#25972;&#20010;&#20551;&#35774;&#31354;&#38388;&#20013;&#65292;&#23398;&#20064;&#36890;&#36807;&#27169;&#22411;&#36873;&#25321;&#30340;&#20559;&#24046;&#30028;&#27604;&#36890;&#36807;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#23398;&#20064;&#30340;&#20559;&#24046;&#30028;&#26356;&#32039;&#23494;&#30340;&#26465;&#20214;&#65292;&#25903;&#25345;&#22312;&#19968;&#20123;&#24773;&#20917;&#19979;&#32463;&#39564;&#19978;&#35266;&#23519;&#21040;&#30340;&#27169;&#22411;&#36873;&#25321;&#26694;&#26550;&#30340;&#26356;&#22909;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Cross-validation techniques for risk estimation and model selection are widely used in statistics and machine learning. However, the understanding of the theoretical properties of learning via model selection with cross-validation risk estimation is quite low in face of its widespread use. In this context, this paper presents learning via model selection with cross-validation risk estimation as a general systematic learning framework within classical statistical learning theory and establishes distribution-free deviation bounds in terms of VC dimension, giving detailed proofs of the results and considering both bounded and unbounded loss functions. We also deduce conditions under which the deviation bounds of learning via model selection are tighter than that of learning via empirical risk minimization in the whole hypotheses space, supporting the better performance of model selection frameworks observed empirically in some instances.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#24320;&#21457;&#20102;&#19968;&#31181;&#22810;&#21464;&#37327;&#20915;&#31574;&#26641;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21487;&#39044;&#27979;&#22522;&#20110;&#20114;&#32852;&#32593;&#30340;&#27835;&#30103;&#23545;&#30406;&#33108;&#30140;&#30171;/&#31359;&#36879;&#38556;&#30861;&#24739;&#32773;&#30340;&#30151;&#29366;&#30340;&#22810;&#32500;&#32508;&#21512;&#35780;&#20998;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2303.08732</link><description>&lt;p&gt;
&#38024;&#23545;&#30406;&#33108;&#30140;&#30171;/&#31359;&#36879;&#38556;&#30861;&#30340;&#22522;&#20110;&#20114;&#32852;&#32593;&#27835;&#30103;&#30340;&#20010;&#20307;&#21270;&#39044;&#27979;&#65306;&#22810;&#21464;&#37327;&#20915;&#31574;&#26641;&#27169;&#22411;&#30340;&#24320;&#21457;&#21644;&#20869;&#37096;&#39564;&#35777;&#65288;arXiv&#65306;2303.08732v1 [stat.AP]&#65289;
&lt;/p&gt;
&lt;p&gt;
Predicting Individualized Effects of Internet-Based Treatment for Genito-Pelvic Pain/Penetration Disorder: Development and Internal Validation of a Multivariable Decision Tree Model. (arXiv:2303.08732v1 [stat.AP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.08732
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#24320;&#21457;&#20102;&#19968;&#31181;&#22810;&#21464;&#37327;&#20915;&#31574;&#26641;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21487;&#39044;&#27979;&#22522;&#20110;&#20114;&#32852;&#32593;&#30340;&#27835;&#30103;&#23545;&#30406;&#33108;&#30140;&#30171;/&#31359;&#36879;&#38556;&#30861;&#24739;&#32773;&#30340;&#30151;&#29366;&#30340;&#22810;&#32500;&#32508;&#21512;&#35780;&#20998;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30406;&#33108;&#30140;&#30171;/&#31359;&#36879;-&#38556;&#30861;&#65288;GPPPD&#65289;&#26159;&#19968;&#31181;&#24120;&#35265;&#30340;&#38556;&#30861;&#65292;&#20294;&#22312;&#26085;&#24120;&#25252;&#29702;&#20013;&#24456;&#23569;&#24471;&#21040;&#27835;&#30103;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#21487;&#20197;&#20351;&#29992;&#22522;&#20110;&#20114;&#32852;&#32593;&#30340;&#24515;&#29702;&#24178;&#39044;&#26377;&#25928;&#22320;&#27835;&#30103;GPPPD&#30151;&#29366;&#12290;&#28982;&#32780;&#65292;&#25152;&#26377;&#26368;&#20808;&#36827;&#30340;&#27835;&#30103;&#26041;&#27861;&#20173;&#28982;&#26222;&#36941;&#23384;&#22312;&#26410;&#21709;&#24212;&#30340;&#24773;&#20917;&#65292;&#30446;&#21069;&#23578;&#19981;&#28165;&#26970;&#21738;&#20123;&#24739;&#32773;&#32676;&#20307;&#26368;&#26377;&#26395;&#20174;&#22522;&#20110;&#20114;&#32852;&#32593;&#30340;&#24178;&#39044;&#20013;&#21463;&#30410;&#12290;&#22810;&#21464;&#37327;&#39044;&#27979;&#27169;&#22411;&#36234;&#26469;&#36234;&#22810;&#22320;&#29992;&#20110;&#30830;&#23450;&#24322;&#36136;&#24615;&#27835;&#30103;&#25928;&#24212;&#30340;&#39044;&#27979;&#22240;&#23376;&#65292;&#24182;&#20998;&#37197;&#20855;&#26377;&#26368;&#22823;&#39044;&#26399;&#25928;&#30410;&#30340;&#27835;&#30103;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#24182;&#20869;&#37096;&#39564;&#35777;&#20102;&#19968;&#31181;&#22810;&#21464;&#37327;&#20915;&#31574;&#26641;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#39044;&#27979;&#22522;&#20110;&#20114;&#32852;&#32593;&#30340;&#27835;&#30103;&#23545;GPPPD&#30151;&#29366;&#30340;&#22810;&#32500;&#32508;&#21512;&#35780;&#20998;&#30340;&#25928;&#26524;&#12290;&#20351;&#29992;&#19968;&#39033;&#23558;&#22522;&#20110;&#20114;&#32852;&#32593;&#30340;&#24178;&#39044;&#19982;&#31561;&#24453;&#21517;&#21333;&#23545;&#29031;&#32452;&#36827;&#34892;&#27604;&#36739;&#30340;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#30340;&#25968;&#25454;&#65288;N = 200&#65289;&#65292;&#21033;&#29992;&#22522;&#20110;&#27169;&#22411;&#30340;&#36882;&#24402;&#20998;&#21306;&#24320;&#21457;&#20102;&#19968;&#31181;&#20915;&#31574;&#26641;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Genito-Pelvic Pain/Penetration-Disorder (GPPPD) is a common disorder but rarely treated in routine care. Previous research documents that GPPPD symptoms can be treated effectively using internet-based psychological interventions. However, non-response remains common for all state-of-the-art treatments and it is unclear which patient groups are expected to benefit most from an internet-based intervention. Multivariable prediction models are increasingly used to identify predictors of heterogeneous treatment effects, and to allocate treatments with the greatest expected benefits. In this study, we developed and internally validated a multivariable decision tree model that predicts effects of an internet-based treatment on a multidimensional composite score of GPPPD symptoms. Data of a randomized controlled trial comparing the internet-based intervention to a waitlist control group (N =200) was used to develop a decision tree model using model-based recursive partitioning. Model performan
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#35780;&#20272;&#20102;&#29616;&#26377;&#25991;&#29486;&#20013;&#26377;&#28508;&#21147;&#28385;&#36275;&#25105;&#20204;&#35201;&#27714;&#30340;&#22495;&#36866;&#24212;&#22270;&#20687;&#20998;&#31867;&#20219;&#21153;&#30340;&#30028;&#38480;&#65292;&#21457;&#29616;&#25152;&#26377;&#30028;&#38480;&#37117;&#26159;&#31354;&#27867;&#30340;&#65292;&#26679;&#26412;&#27867;&#21270;&#26415;&#35821;&#21344;&#25454;&#20102;&#35266;&#23519;&#21040;&#30340;&#26494;&#24347;&#31243;&#24230;&#30340;&#24456;&#22823;&#37096;&#20998;&#65292;&#29305;&#21035;&#26159;&#24403;&#36825;&#20123;&#26415;&#35821;&#19982;&#22495;&#30340;&#24230;&#37327;&#20114;&#21160;&#26102;&#12290;</title><link>http://arxiv.org/abs/2303.08720</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#26080;&#30417;&#30563;&#22495;&#36866;&#24212;&#30340;&#27867;&#21270;&#20445;&#35777;&#30340;&#23454;&#29992;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Practicality of generalization guarantees for unsupervised domain adaptation with neural networks. (arXiv:2303.08720v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.08720
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#35780;&#20272;&#20102;&#29616;&#26377;&#25991;&#29486;&#20013;&#26377;&#28508;&#21147;&#28385;&#36275;&#25105;&#20204;&#35201;&#27714;&#30340;&#22495;&#36866;&#24212;&#22270;&#20687;&#20998;&#31867;&#20219;&#21153;&#30340;&#30028;&#38480;&#65292;&#21457;&#29616;&#25152;&#26377;&#30028;&#38480;&#37117;&#26159;&#31354;&#27867;&#30340;&#65292;&#26679;&#26412;&#27867;&#21270;&#26415;&#35821;&#21344;&#25454;&#20102;&#35266;&#23519;&#21040;&#30340;&#26494;&#24347;&#31243;&#24230;&#30340;&#24456;&#22823;&#37096;&#20998;&#65292;&#29305;&#21035;&#26159;&#24403;&#36825;&#20123;&#26415;&#35821;&#19982;&#22495;&#30340;&#24230;&#37327;&#20114;&#21160;&#26102;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#27867;&#21270;&#23545;&#20110;&#33258;&#20449;&#22320;&#35774;&#35745;&#21644;&#37096;&#32626;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#33267;&#20851;&#37325;&#35201;&#65292;&#29305;&#21035;&#26159;&#24403;&#37096;&#32626;&#24847;&#21619;&#30528;&#25968;&#25454;&#22495;&#30340;&#36716;&#31227;&#26102;&#12290;&#23545;&#20110;&#36825;&#26679;&#30340;&#22495;&#36866;&#24212;&#38382;&#39064;&#65292;&#25105;&#20204;&#23547;&#27714;&#21487;&#35745;&#31639;&#21644;&#32039;&#23494;&#30340;&#27867;&#21270;&#30028;&#38480;&#12290;&#22914;&#26524;&#21487;&#20197;&#23454;&#29616;&#36825;&#20123;&#35201;&#27714;&#65292;&#36825;&#20123;&#30028;&#38480;&#21487;&#20197;&#20316;&#20026;&#37096;&#32626;&#20013;&#20805;&#36275;&#24615;&#33021;&#30340;&#20445;&#35777;&#12290;&#28982;&#32780;&#65292;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26159;&#39318;&#36873;&#27169;&#22411;&#30340;&#24212;&#29992;&#20013;&#65292;&#25512;&#23548;&#20986;&#28385;&#36275;&#36825;&#20123;&#35201;&#27714;&#30340;&#32467;&#26524;&#20173;&#26159;&#19968;&#39033;&#26410;&#35299;&#20915;&#30340;&#25361;&#25112;&#65307;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#30028;&#38480;&#35201;&#20040;&#26159;&#31354;&#27867;&#30340;&#65292;&#35201;&#20040;&#26377;&#19981;&#21487;&#20272;&#35745;&#30340;&#26415;&#35821;&#65292;&#21363;&#20351;&#22312;&#26377;&#21033;&#26465;&#20214;&#19979;&#20063;&#26159;&#22914;&#27492;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#29616;&#26377;&#25991;&#29486;&#20013;&#26377;&#28508;&#21147;&#28385;&#36275;&#25105;&#20204;&#35201;&#27714;&#30340;&#22495;&#36866;&#24212;&#22270;&#20687;&#20998;&#31867;&#20219;&#21153;&#30340;&#30028;&#38480;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26159;&#39318;&#36873;&#12290;&#25105;&#20204;&#21457;&#29616;&#25152;&#26377;&#30028;&#38480;&#37117;&#26159;&#31354;&#27867;&#30340;&#65292;&#24182;&#19988;&#26679;&#26412;&#27867;&#21270;&#26415;&#35821;&#21344;&#25454;&#20102;&#35266;&#23519;&#21040;&#30340;&#26494;&#24347;&#31243;&#24230;&#30340;&#24456;&#22823;&#37096;&#20998;&#65292;&#29305;&#21035;&#26159;&#24403;&#36825;&#20123;&#26415;&#35821;&#19982;&#22495;&#30340;&#24230;&#37327;&#20114;&#21160;&#26102;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding generalization is crucial to confidently engineer and deploy machine learning models, especially when deployment implies a shift in the data domain. For such domain adaptation problems, we seek generalization bounds which are tractably computable and tight. If these desiderata can be reached, the bounds can serve as guarantees for adequate performance in deployment. However, in applications where deep neural networks are the models of choice, deriving results which fulfill these remains an unresolved challenge; most existing bounds are either vacuous or has non-estimable terms, even in favorable conditions. In this work, we evaluate existing bounds from the literature with potential to satisfy our desiderata on domain adaptation image classification tasks, where deep neural networks are preferred. We find that all bounds are vacuous and that sample generalization terms account for much of the observed looseness, especially when these terms interact with measures of domain
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;SSBM&#65292;&#23427;&#21482;&#38656;&#35201;&#20108;&#36827;&#21046;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#65292;&#24182;&#25506;&#32034;&#20102;&#20174;&#19981;&#23436;&#25972;&#30340;&#20108;&#36827;&#21046;&#35266;&#23519;&#20013;&#23398;&#20064;&#30340;&#26497;&#31471;&#24773;&#20917;&#12290;&#36825;&#20026;&#20174;&#20108;&#36827;&#21046;&#27979;&#37327;&#20013;&#24674;&#22797;&#20449;&#21495;&#25552;&#20379;&#20102;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#65292;&#24182;&#22312;&#19968;&#31995;&#21015;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;SSBM&#30340;&#21331;&#36234;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2303.08691</link><description>&lt;p&gt;
&#20174;&#20108;&#36827;&#21046;&#27979;&#37327;&#20013;&#23398;&#20064;&#20449;&#21495;&#37325;&#26500;
&lt;/p&gt;
&lt;p&gt;
Learning to Reconstruct Signals From Binary Measurements. (arXiv:2303.08691v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.08691
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;SSBM&#65292;&#23427;&#21482;&#38656;&#35201;&#20108;&#36827;&#21046;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#65292;&#24182;&#25506;&#32034;&#20102;&#20174;&#19981;&#23436;&#25972;&#30340;&#20108;&#36827;&#21046;&#35266;&#23519;&#20013;&#23398;&#20064;&#30340;&#26497;&#31471;&#24773;&#20917;&#12290;&#36825;&#20026;&#20174;&#20108;&#36827;&#21046;&#27979;&#37327;&#20013;&#24674;&#22797;&#20449;&#21495;&#25552;&#20379;&#20102;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#65292;&#24182;&#22312;&#19968;&#31995;&#21015;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;SSBM&#30340;&#21331;&#36234;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#23398;&#20064;&#30340;&#26368;&#26032;&#36827;&#23637;&#31361;&#20986;&#20102;&#20165;&#20174;&#22122;&#22768;&#21644;&#19981;&#23436;&#25972;&#30340;&#32447;&#24615;&#27979;&#37327;&#20013;&#23398;&#20064;&#20449;&#21495;&#37325;&#26500;&#30340;&#21487;&#33021;&#24615;&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#21307;&#23398;&#21644;&#31185;&#23398;&#25104;&#20687;&#20197;&#21450;&#20256;&#24863;&#20013;&#36215;&#21040;&#20851;&#38190;&#20316;&#29992;&#65292;&#20854;&#20013;&#22320;&#38754;&#30495;&#23454;&#25968;&#25454;&#32463;&#24120;&#31232;&#32570;&#25110;&#38590;&#20197;&#33719;&#24471;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#27979;&#37327;&#19981;&#20165;&#22122;&#22768;&#21644;&#19981;&#23436;&#25972;&#65292;&#32780;&#19988;&#36824;&#34987;&#37327;&#21270;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25506;&#32034;&#20174;&#20108;&#36827;&#21046;&#35266;&#23519;&#20013;&#23398;&#20064;&#30340;&#26497;&#31471;&#24773;&#20917;&#65292;&#24182;&#25552;&#20379;&#20102;&#20851;&#20110;&#20174;&#19981;&#23436;&#25972;&#20108;&#36827;&#21046;&#25968;&#25454;&#20013;&#35782;&#21035;&#19968;&#32452;&#20449;&#21495;&#25152;&#38656;&#30340;&#27979;&#37327;&#25968;&#37327;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26159;&#23545;&#20174;&#20108;&#36827;&#21046;&#27979;&#37327;&#20013;&#20449;&#21495;&#24674;&#22797;&#29616;&#26377;&#30028;&#38480;&#30340;&#34917;&#20805;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#65292;&#25105;&#20204;&#23558;&#20854;&#21629;&#21517;&#20026;&#8220;SSBM&#8221;&#65292;&#23427;&#20165;&#38656;&#35201;&#20108;&#36827;&#21046;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#12290;&#25105;&#20204;&#22312;&#19968;&#31995;&#21015;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;SSBM&#19982;&#30417;&#30563;&#23398;&#20064;&#30456;&#24403;&#65292;&#24182;&#20248;&#20110;&#31232;&#30095;&#37325;&#26500;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advances in unsupervised learning have highlighted the possibility of learning to reconstruct signals from noisy and incomplete linear measurements alone. These methods play a key role in medical and scientific imaging and sensing, where ground truth data is often scarce or difficult to obtain. However, in practice, measurements are not only noisy and incomplete but also quantized. Here we explore the extreme case of learning from binary observations and provide necessary and sufficient conditions on the number of measurements required for identifying a set of signals from incomplete binary data. Our results are complementary to existing bounds on signal recovery from binary measurements. Furthermore, we introduce a novel self-supervised learning approach, which we name SSBM, that only requires binary data for training. We demonstrate in a series of experiments with real datasets that SSBM performs on par with supervised learning and outperforms sparse reconstruction methods wit
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36229;&#30697;&#24418;&#30340;&#21487;&#35299;&#37322;&#30340;&#38598;&#25104;&#27169;&#22411;&#65292;&#23427;&#23558;&#22343;&#21248;&#29983;&#25104;&#30340;&#36724;&#23545;&#40784;&#36229;&#30697;&#24418;&#20316;&#20026;&#22522;&#27169;&#22411;&#65292;&#24182;&#25104;&#21151;&#22320;&#36991;&#20813;&#20102;&#36807;&#25311;&#21512;&#12290;</title><link>http://arxiv.org/abs/2303.08625</link><description>&lt;p&gt;
&#20316;&#20026;&#22522;&#30784;&#27169;&#22411;&#30340;&#36229;&#30697;&#24418;&#21487;&#35299;&#37322;&#38598;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Interpretable Ensembles of Hyper-Rectangles as Base Models. (arXiv:2303.08625v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.08625
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36229;&#30697;&#24418;&#30340;&#21487;&#35299;&#37322;&#30340;&#38598;&#25104;&#27169;&#22411;&#65292;&#23427;&#23558;&#22343;&#21248;&#29983;&#25104;&#30340;&#36724;&#23545;&#40784;&#36229;&#30697;&#24418;&#20316;&#20026;&#22522;&#27169;&#22411;&#65292;&#24182;&#25104;&#21151;&#22320;&#36991;&#20813;&#20102;&#36807;&#25311;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31616;&#21333;&#38598;&#25104;&#27169;&#22411;&#30340;&#26032;&#22411;&#27169;&#22411;&#65292;&#20351;&#29992;&#22343;&#21248;&#29983;&#25104;&#30340;&#36724;&#23545;&#40784;&#36229;&#30697;&#24418;&#20316;&#20026;&#22522;&#27169;&#22411;&#65288;HRBM&#65289;&#12290;&#30740;&#31350;&#20102;&#20004;&#31181;&#31867;&#22411;&#30340;HRBM&#65306;&#23553;&#38381;&#30697;&#24418;&#21644;&#35282;&#33853;&#12290;HRBM&#30340;&#20027;&#35201;&#24605;&#24819;&#26159;&#32771;&#34385;&#24182;&#35745;&#31639;&#27599;&#20010;&#30697;&#24418;&#20869;&#22806;&#30340;&#35757;&#32451;&#26679;&#20363;&#25968;&#37327;&#12290;&#25552;&#20986;&#23558;HRBM&#32435;&#20837;&#26799;&#24230;&#25552;&#21319;&#26426;&#65288;GBM&#65289;&#20013;&#12290;&#23613;&#31649;HRBM&#24456;&#31616;&#21333;&#65292;&#20294;&#36825;&#20123;&#31616;&#21333;&#30340;&#22522;&#30784;&#27169;&#22411;&#20801;&#35768;&#25105;&#20204;&#26500;&#24314;&#26377;&#25928;&#30340;&#38598;&#25104;&#27169;&#22411;&#24182;&#36991;&#20813;&#36807;&#25311;&#21512;&#12290;&#32771;&#34385;&#20102;&#19968;&#31181;&#35745;&#31639;&#38598;&#25104;&#27169;&#22411;&#30340;&#26368;&#20248;&#27491;&#21017;&#21270;&#21442;&#25968;&#30340;&#31616;&#21333;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#22312;GBM&#30340;&#27599;&#27425;&#36845;&#20195;&#20013;&#20197;&#26174;&#24335;&#26041;&#24335;&#20462;&#25913;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#20102;&#19968;&#31181;&#26032;&#30340;&#27491;&#21017;&#21270;&#65292;&#31216;&#20026;&#8220;&#38454;&#26799;&#39640;&#24230;&#24809;&#32602;&#8221;&#65292;&#38500;&#20102;&#26631;&#20934;&#30340;L1&#21644;L2&#27491;&#21017;&#21270;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#24120;&#31616;&#21333;&#30340;&#26041;&#27861;&#26469;&#20351;&#29992;&#33879;&#21517;&#30340;SHAP&#26041;&#27861;&#23545;&#25152;&#25552;&#20986;&#30340;&#38598;&#25104;&#27169;&#22411;&#39044;&#27979;&#36827;&#34892;&#35299;&#37322;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;G
&lt;/p&gt;
&lt;p&gt;
A new extremely simple ensemble-based model with the uniformly generated axis-parallel hyper-rectangles as base models (HRBM) is proposed. Two types of HRBMs are studied: closed rectangles and corners. The main idea behind HRBM is to consider and count training examples inside and outside each rectangle. It is proposed to incorporate HRBMs into the gradient boosting machine (GBM). Despite simplicity of HRBMs, it turns out that these simple base models allow us to construct effective ensemble-based models and avoid overfitting. A simple method for calculating optimal regularization parameters of the ensemble-based model, which can be modified in the explicit way at each iteration of GBM, is considered. Moreover, a new regularization called the "step height penalty" is studied in addition to the standard L1 and L2 regularizations. An extremely simple approach to the proposed ensemble-based model prediction interpretation by using the well-known method SHAP is proposed. It is shown that G
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#25991;&#26412;&#24341;&#23548;&#22270;&#20687;&#39118;&#26684;&#36801;&#31227;&#20013;&#30340;&#38646;&#26679;&#26412;&#23545;&#27604;&#25439;&#22833;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#19981;&#38656;&#35201;&#39069;&#22806;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#29983;&#25104;&#20855;&#26377;&#30456;&#21516;&#35821;&#20041;&#20869;&#23481;&#30340;&#22270;&#20687;&#12290;</title><link>http://arxiv.org/abs/2303.08622</link><description>&lt;p&gt;
&#38646;&#26679;&#26412;&#23545;&#27604;&#25439;&#22833;&#29992;&#20110;&#25991;&#26412;&#24341;&#23548;&#25193;&#25955;&#22270;&#20687;&#39118;&#26684;&#36801;&#31227;
&lt;/p&gt;
&lt;p&gt;
Zero-Shot Contrastive Loss for Text-Guided Diffusion Image Style Transfer. (arXiv:2303.08622v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.08622
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#25991;&#26412;&#24341;&#23548;&#22270;&#20687;&#39118;&#26684;&#36801;&#31227;&#20013;&#30340;&#38646;&#26679;&#26412;&#23545;&#27604;&#25439;&#22833;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#19981;&#38656;&#35201;&#39069;&#22806;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#29983;&#25104;&#20855;&#26377;&#30456;&#21516;&#35821;&#20041;&#20869;&#23481;&#30340;&#22270;&#20687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#22312;&#25991;&#26412;&#24341;&#23548;&#22270;&#20687;&#39118;&#26684;&#36801;&#31227;&#20013;&#34920;&#29616;&#20986;&#26497;&#22823;&#30340;&#28508;&#21147;&#65292;&#20294;&#30001;&#20110;&#20854;&#38543;&#26426;&#24615;&#32780;&#23384;&#22312;&#39118;&#26684;&#36716;&#25442;&#21644;&#20869;&#23481;&#20445;&#25252;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;&#29616;&#26377;&#26041;&#27861;&#38656;&#35201;&#35745;&#31639;&#23494;&#38598;&#30340;&#25193;&#25955;&#27169;&#22411;&#24494;&#35843;&#25110;&#38468;&#21152;&#31070;&#32463;&#32593;&#32476;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#22312;&#25193;&#25955;&#27169;&#22411;&#20013;&#25552;&#20986;&#20102;&#19968;&#31181;&#38646;&#26679;&#26412;&#23545;&#27604;&#25439;&#22833;&#65292;&#23427;&#19981;&#38656;&#35201;&#39069;&#22806;&#30340;&#24494;&#35843;&#25110;&#36741;&#21161;&#32593;&#32476;&#12290;&#36890;&#36807;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#25193;&#25955;&#27169;&#22411;&#20013;&#29983;&#25104;&#26679;&#26412;&#21644;&#21407;&#22987;&#22270;&#20687;&#23884;&#20837;&#20043;&#38388;&#30340;&#22270;&#22359;&#23545;&#27604;&#25439;&#22833;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#20197;&#38646;&#26679;&#26412;&#30340;&#26041;&#24335;&#29983;&#25104;&#20855;&#26377;&#19982;&#28304;&#22270;&#20687;&#30456;&#21516;&#35821;&#20041;&#20869;&#23481;&#30340;&#22270;&#20687;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20445;&#30041;&#20869;&#23481;&#19988;&#19981;&#38656;&#35201;&#39069;&#22806;&#35757;&#32451;&#30340;&#21516;&#26102;&#65292;&#22312;&#22270;&#20687;&#39118;&#26684;&#36801;&#31227;&#12289;&#22270;&#20687;&#21040;&#22270;&#20687;&#30340;&#36716;&#25442;&#21644;&#25805;&#20316;&#20013;&#22343;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#35777;&#23454;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models have shown great promise in text-guided image style transfer, but there is a trade-off between style transformation and content preservation due to their stochastic nature. Existing methods require computationally expensive fine-tuning of diffusion models or additional neural network. To address this, here we propose a zero-shot contrastive loss for diffusion models that doesn't require additional fine-tuning or auxiliary networks. By leveraging patch-wise contrastive loss between generated samples and original image embeddings in the pre-trained diffusion model, our method can generate images with the same semantic content as the source image in a zero-shot manner. Our approach outperforms existing methods while preserving content and requiring no additional training, not only for image style transfer but also for image-to-image translation and manipulation. Our experimental results validate the effectiveness of our proposed method.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35774;&#35745;&#20102;&#19968;&#31181;&#26679;&#26412;&#39640;&#25928;&#31639;&#27861;&#65292;&#23558; UCB &#31639;&#27861;&#65288;Auer&#31561;&#20154;&#65292;2002&#65289;&#24212;&#29992;&#20110;&#22996;&#25176;&#20195;&#29702;&#27169;&#22411;&#30340;&#22312;&#32447;&#35774;&#32622;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#36890;&#36807;&#19982;&#31574;&#30053;&#20195;&#29702;&#22810;&#27425;&#20114;&#21160;&#26469;&#35774;&#35745;&#26368;&#20248;&#30340;&#35745;&#20998;&#35268;&#21017;&#65292;&#24182;&#23454;&#29616;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2303.08613</link><description>&lt;p&gt;
&#23398;&#20064;&#22870;&#21169;&#20449;&#24687;&#33719;&#21462;&#65306;&#27491;&#30830;&#35745;&#20998;&#35268;&#21017;&#36935;&#21040;&#22996;&#25176;&#20195;&#29702;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Learning to Incentivize Information Acquisition: Proper Scoring Rules Meet Principal-Agent Model. (arXiv:2303.08613v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.08613
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35774;&#35745;&#20102;&#19968;&#31181;&#26679;&#26412;&#39640;&#25928;&#31639;&#27861;&#65292;&#23558; UCB &#31639;&#27861;&#65288;Auer&#31561;&#20154;&#65292;2002&#65289;&#24212;&#29992;&#20110;&#22996;&#25176;&#20195;&#29702;&#27169;&#22411;&#30340;&#22312;&#32447;&#35774;&#32622;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#36890;&#36807;&#19982;&#31574;&#30053;&#20195;&#29702;&#22810;&#27425;&#20114;&#21160;&#26469;&#35774;&#35745;&#26368;&#20248;&#30340;&#35745;&#20998;&#35268;&#21017;&#65292;&#24182;&#23454;&#29616;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22996;&#25176;&#20195;&#29702;&#27169;&#22411;&#20013;&#30340;&#28608;&#21169;&#20449;&#24687;&#33719;&#21462;&#38382;&#39064;&#12290;&#27492;&#38382;&#39064;&#34987;&#24314;&#27169;&#20026;&#22996;&#25176;&#26041;&#21644;&#20195;&#29702;&#26041;&#20043;&#38388;&#30340; Stackelberg &#21338;&#24328;&#65292;&#20854;&#20013;&#22996;&#25176;&#20154;&#23459;&#24067;&#20102;&#19968;&#26465;&#24471;&#20998;&#35268;&#21017;&#26469;&#25351;&#23450;&#20184;&#27454;&#65292;&#28982;&#21518;&#20195;&#29702;&#26041;&#36873;&#25321;&#26368;&#22823;&#21270;&#20854;&#33258;&#36523;&#21033;&#28070;&#21644;&#25253;&#21578;&#20449;&#24687;&#30340;&#21162;&#21147;&#27700;&#24179;&#12290;&#25105;&#20204;&#20174;&#22996;&#25176;&#26041;&#30340;&#35282;&#24230;&#30740;&#31350;&#36825;&#20010;&#38382;&#39064;&#30340;&#22312;&#32447;&#35774;&#32622;&#65292;&#21363;&#36890;&#36807;&#19982;&#31574;&#30053;&#20195;&#29702;&#22810;&#27425;&#20132;&#20114;&#26469;&#35774;&#35745;&#26368;&#20248;&#35745;&#20998;&#35268;&#21017;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#21487;&#35777;&#26126;&#30340;&#26679;&#26412;&#39640;&#25928;&#31639;&#27861;&#65292;&#23558; UCB &#31639;&#27861; (Auer et al., 2002) &#37327;&#36523;&#23450;&#21046;&#21040;&#25105;&#20204;&#30340;&#27169;&#22411;&#20013;&#65292;&#20854;&#22312; T &#27425;&#36845;&#20195;&#21518;&#23454;&#29616;&#20102;&#27425;&#32447;&#24615; $T^{2/3}$-&#36951;&#25022;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20855;&#26377;&#23545;&#22996;&#25176;&#26041;&#26368;&#20248;&#21033;&#28070;&#36827;&#34892;&#31934;&#32454;&#20272;&#35745;&#30340;&#36807;&#31243;&#20197;&#21450;&#20445;&#23432;&#32416;&#27491;&#26041;&#26696;&#65292;&#20197;&#30830;&#20445;&#20195;&#29702;&#26041;&#30340;&#34892;&#21160;&#24471;&#21040;&#26377;&#25928;&#28608;&#21169;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#36951;&#25022;&#30028;&#30340;&#19968;&#20010;&#20851;&#38190;&#29305;&#24449;&#26159;&#23427;&#26159;&#28176;&#36827;&#26368;&#23567;&#21487;&#23454;&#29616;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the incentivized information acquisition problem, where a principal hires an agent to gather information on her behalf. Such a problem is modeled as a Stackelberg game between the principal and the agent, where the principal announces a scoring rule that specifies the payment, and then the agent then chooses an effort level that maximizes her own profit and reports the information. We study the online setting of such a problem from the principal's perspective, i.e., designing the optimal scoring rule by repeatedly interacting with the strategic agent. We design a provably sample efficient algorithm that tailors the UCB algorithm (Auer et al., 2002) to our model, which achieves a sublinear $T^{2/3}$-regret after $T$ iterations. Our algorithm features a delicate estimation procedure for the optimal profit of the principal, and a conservative correction scheme that ensures the desired agent's actions are incentivized. Furthermore, a key feature of our regret bound is that it is i
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#24310;&#36831;&#24494;&#20998;&#26041;&#31243;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;Delay-SDE-net&#65292;&#21487;&#20197;&#20934;&#30830;&#22320;&#24314;&#27169;&#20855;&#26377;&#35760;&#24518;&#25928;&#24212;&#30340;&#26102;&#38388;&#24207;&#21015;&#65292;&#24182;&#19988;&#33021;&#22815;&#23545;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#23454;&#26102;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2303.08587</link><description>&lt;p&gt;
Delay-SDE-net&#65306;&#19968;&#31181;&#29992;&#20110;&#20855;&#26377;&#35760;&#24518;&#21644;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Delay-SDE-net: A deep learning approach for time series modelling with memory and uncertainty estimates. (arXiv:2303.08587v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.08587
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#24310;&#36831;&#24494;&#20998;&#26041;&#31243;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;Delay-SDE-net&#65292;&#21487;&#20197;&#20934;&#30830;&#22320;&#24314;&#27169;&#20855;&#26377;&#35760;&#24518;&#25928;&#24212;&#30340;&#26102;&#38388;&#24207;&#21015;&#65292;&#24182;&#19988;&#33021;&#22815;&#23545;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#23454;&#26102;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#39046;&#22495;&#20013;&#65292;&#20934;&#30830;&#22320;&#24314;&#27169;&#26102;&#38388;&#24207;&#21015;&#38750;&#24120;&#37325;&#35201;&#12290;&#30001;&#20110;&#19990;&#30028;&#36890;&#24120;&#36807;&#20110;&#22797;&#26434;&#20197;&#33267;&#26080;&#27861;&#20934;&#30830;&#22320;&#24314;&#27169;&#65292;&#22240;&#27492;&#35780;&#20272;&#21160;&#24577;&#31995;&#32479;&#22788;&#20110;&#29305;&#23450;&#29366;&#24577;&#30340;&#27010;&#29575;&#24120;&#24120;&#26377;&#24847;&#20041;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;Delay-SDE-net&#65292;&#36825;&#26159;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#24310;&#36831;&#24494;&#20998;&#26041;&#31243;&#65288;SDDEs&#65289;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#12290;&#20351;&#29992;&#20855;&#26377;&#22810;&#20010;&#24310;&#36831;&#30340;SDDE&#20316;&#20026;&#24314;&#27169;&#26694;&#26550;&#65292;&#20351;&#20854;&#25104;&#20026;&#20855;&#26377;&#35760;&#24518;&#25928;&#24212;&#30340;&#26102;&#38388;&#24207;&#21015;&#30340;&#21512;&#36866;&#27169;&#22411;&#65292;&#22240;&#20026;&#23427;&#36890;&#36807;&#31995;&#32479;&#20043;&#21069;&#30340;&#29366;&#24577;&#21253;&#25324;&#35760;&#24518;&#12290; Delay-SDE-net&#30340;&#38543;&#26426;&#37096;&#20998;&#25552;&#20379;&#20102;&#20272;&#35745;&#24314;&#27169;&#20013;&#19981;&#30830;&#23450;&#24615;&#30340;&#22522;&#30784;&#65292;&#24182;&#34987;&#20998;&#25104;&#20004;&#20010;&#31070;&#32463;&#32593;&#32476;&#20197;&#35299;&#37322;&#20808;&#39564;&#24615;&#21644;&#21518;&#39564;&#24615;&#19981;&#30830;&#23450;&#24615;&#12290;&#36825;&#31181;&#19981;&#30830;&#23450;&#24615;&#26159;&#23454;&#26102;&#25552;&#20379;&#30340;&#65292;&#20351;&#24471;&#35813;&#27169;&#22411;&#36866;&#29992;&#20110;&#26102;&#38388;&#21294;&#20047;&#30340;&#24212;&#29992;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;Delay-SDE-net&#30340;&#29702;&#35770;&#35823;&#24046;&#65292;&#24182;&#36827;&#34892;&#20102;&#25968;&#20540;&#25910;&#25947;&#29575;&#20998;&#26512;&#12290;&#22312;&#19982;&#31867;&#20284;&#27169;&#22411;&#30340;&#27604;&#36739;&#20013;&#65292;Delay-SDE-net&#26174;&#31034;&#20986;&#26356;&#21152;&#31283;&#23450;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
To model time series accurately is important within a wide range of fields. As the world is generally too complex to be modelled exactly, it is often meaningful to assess the probability of a dynamical system to be in a specific state. This paper presents the Delay-SDE-net, a neural network model based on stochastic delay differential equations (SDDEs). The use of SDDEs with multiple delays as modelling framework makes it a suitable model for time series with memory effects, as it includes memory through previous states of the system. The stochastic part of the Delay-SDE-net provides a basis for estimating uncertainty in modelling, and is split into two neural networks to account for aleatoric and epistemic uncertainty. The uncertainty is provided instantly, making the model suitable for applications where time is sparse. We derive the theoretical error of the Delay-SDE-net and analyze the convergence rate numerically. At comparisons with similar models, the Delay-SDE-net has consisten
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#32479;&#35745;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#22788;&#29702;&#32039;&#33268;&#31354;&#38388;&#19978;&#30340;&#27979;&#24230;&#25968;&#25454;&#65292;&#24182;&#19988;&#21521;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#25299;&#25169;&#20449;&#24687;&#36827;&#34892;&#20998;&#31867;&#12290;</title><link>http://arxiv.org/abs/2303.08456</link><description>&lt;p&gt;
&#24212;&#29992;&#20110;&#25345;&#32493;&#22270;&#30340;&#27979;&#24230;&#32479;&#35745;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Statistical learning on measures: an application to persistence diagrams. (arXiv:2303.08456v1 [cs.CG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.08456
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#32479;&#35745;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#22788;&#29702;&#32039;&#33268;&#31354;&#38388;&#19978;&#30340;&#27979;&#24230;&#25968;&#25454;&#65292;&#24182;&#19988;&#21521;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#25299;&#25169;&#20449;&#24687;&#36827;&#34892;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#20108;&#20803;&#26377;&#30417;&#30563;&#23398;&#20064;&#20998;&#31867;&#38382;&#39064;&#65292;&#20854;&#20013;&#25105;&#20204;&#35266;&#23519;&#21040;&#32039;&#33268;&#31354;&#38388; $\mathcal{X}$ &#19978;&#30340;&#27979;&#24230;&#65292;&#32780;&#19981;&#26159;&#22312;&#26377;&#38480;&#32500;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#35266;&#23519;&#21040;&#25968;&#25454;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#25968;&#25454; $D_N = (\mu_1, Y_1), \ldots, (\mu_N, Y_N)$ &#65292;&#20854;&#20013; $\mu_i$ &#26159; $\mathcal{X}$ &#19978;&#30340;&#27979;&#24230;&#65292; $Y_i$ &#26159; $0$ &#25110; $1$ &#20013;&#30340;&#26631;&#31614;&#12290;&#23545;&#20110; $\mathcal{X}$ &#19978;&#30340;&#22522;&#20998;&#31867;&#22120;&#30340;&#38598;&#21512; $\mathcal{F}$ &#65292;&#25105;&#20204;&#22312;&#27979;&#24230;&#31354;&#38388;&#20013;&#26500;&#24314;&#30456;&#24212;&#30340;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#36825;&#31181;&#26032;&#20998;&#31867;&#22120;&#31867;&#30340; Rademacher &#22797;&#26434;&#24615;&#30340;&#19978;&#19979;&#30028;&#65292;&#23427;&#21487;&#20197;&#31616;&#21333;&#22320;&#29992; $\mathcal{F}$ &#31867;&#30456;&#20851;&#37327;&#26469;&#34920;&#36798;&#12290;&#22914;&#26524; $\mu_i$ &#26159;&#26377;&#38480;&#38598;&#19978;&#30340;&#22343;&#21248;&#20998;&#24067;&#65292;&#37027;&#20040;&#36825;&#20010;&#20998;&#31867;&#20219;&#21153;&#23601;&#20250;&#21464;&#25104;&#19968;&#20010;&#22810;&#23454;&#20363;&#23398;&#20064;&#38382;&#39064;&#12290;&#20294;&#26159;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20801;&#35768;&#25105;&#20204;&#22788;&#29702;&#26356;&#20855;&#26377;&#28789;&#27963;&#24615;&#21644;&#22810;&#26679;&#24615;&#30340;&#36755;&#20837;&#25968;&#25454;&#12290;&#34429;&#28982;&#36825;&#31181;&#26694;&#26550;&#26377;&#35768;&#22810;&#21487;&#33021;&#30340;&#24212;&#29992;&#65292;&#20294;&#26412;&#25991;&#24378;&#35843;&#36890;&#36807;&#25299;&#25169;&#25968;&#25454;&#36827;&#34892;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a binary supervised learning classification problem where instead of having data in a finite-dimensional Euclidean space, we observe measures on a compact space $\mathcal{X}$. Formally, we observe data $D_N = (\mu_1, Y_1), \ldots, (\mu_N, Y_N)$ where $\mu_i$ is a measure on $\mathcal{X}$ and $Y_i$ is a label in $\{0, 1\}$. Given a set $\mathcal{F}$ of base-classifiers on $\mathcal{X}$, we build corresponding classifiers in the space of measures. We provide upper and lower bounds on the Rademacher complexity of this new class of classifiers that can be expressed simply in terms of corresponding quantities for the class $\mathcal{F}$. If the measures $\mu_i$ are uniform over a finite set, this classification task boils down to a multi-instance learning problem. However, our approach allows more flexibility and diversity in the input data we can deal with. While such a framework has many possible applications, this work strongly emphasizes on classifying data via topological d
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;Mixup&#23545;&#20110;&#29305;&#24449;&#23398;&#20064;&#30340;&#30410;&#22788;&#12290;&#28151;&#21512;&#35757;&#32451;&#21487;&#20197;&#26377;&#25928;&#22320;&#20174;&#28151;&#21512;&#25968;&#25454;&#20013;&#23398;&#20064;&#32597;&#35265;&#29305;&#24449;&#65292;&#30456;&#27604;&#20043;&#19979;&#65292;&#26631;&#20934;&#35757;&#32451;&#21487;&#33021;&#20250;&#28431;&#25481;&#36825;&#20123;&#32597;&#35265;&#29305;&#24449;&#12290;</title><link>http://arxiv.org/abs/2303.08433</link><description>&lt;p&gt;
&#28151;&#21512;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;Mixup&#23545;&#20110;&#29305;&#24449;&#23398;&#20064;&#30340;&#30410;&#22788;
&lt;/p&gt;
&lt;p&gt;
The Benefits of Mixup for Feature Learning. (arXiv:2303.08433v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.08433
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;Mixup&#23545;&#20110;&#29305;&#24449;&#23398;&#20064;&#30340;&#30410;&#22788;&#12290;&#28151;&#21512;&#35757;&#32451;&#21487;&#20197;&#26377;&#25928;&#22320;&#20174;&#28151;&#21512;&#25968;&#25454;&#20013;&#23398;&#20064;&#32597;&#35265;&#29305;&#24449;&#65292;&#30456;&#27604;&#20043;&#19979;&#65292;&#26631;&#20934;&#35757;&#32451;&#21487;&#33021;&#20250;&#28431;&#25481;&#36825;&#20123;&#32597;&#35265;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Mixup&#26159;&#19968;&#31181;&#31616;&#21333;&#30340;&#25968;&#25454;&#22686;&#24378;&#26041;&#27861;&#65292;&#36890;&#36807;&#32447;&#24615;&#25554;&#20540;&#38543;&#26426;&#28151;&#21512;&#20004;&#20010;&#25968;&#25454;&#28857;&#65292;&#24050;&#24191;&#27867;&#24212;&#29992;&#20110;&#21508;&#31181;&#28145;&#24230;&#23398;&#20064;&#24212;&#29992;&#20013;&#65292;&#20197;&#33719;&#24471;&#26356;&#22909;&#30340;&#27867;&#21270;&#25928;&#26524;&#12290;&#28982;&#32780;&#65292;&#20854;&#26377;&#25928;&#24615;&#30340;&#29702;&#35770;&#22522;&#30784;&#23578;&#26410;&#23436;&#20840;&#34987;&#29702;&#35299;&#12290;&#26412;&#25991;&#26088;&#22312;&#23547;&#27714;&#23545;Mixup&#30410;&#22788;&#30340;&#22522;&#26412;&#29702;&#35299;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23637;&#31034;Mixup&#22312;&#29305;&#24449;&#21644;&#26631;&#31614;&#20351;&#29992;&#19981;&#21516;&#30340;&#32447;&#24615;&#25554;&#20540;&#21442;&#25968;&#26102;&#20173;&#21487;&#23454;&#29616;&#31867;&#20284;&#20110;&#26631;&#20934;Mixup&#30340;&#24615;&#33021;&#12290;&#36825;&#34920;&#26126;&#65292;Zhang&#31561;&#20154;&#65288;2018&#65289;&#25552;&#20986;&#30340;&#30452;&#35266;&#32447;&#24615;&#35299;&#37322;&#21487;&#33021;&#24182;&#19981;&#33021;&#23436;&#20840;&#35299;&#37322;Mixup&#30340;&#25104;&#21151;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20174;&#29305;&#24449;&#23398;&#20064;&#30340;&#35282;&#24230;&#23545;Mixup&#36827;&#34892;&#29702;&#35770;&#30740;&#31350;&#12290;&#25105;&#20204;&#32771;&#34385;&#19968;&#20010;&#29305;&#24449;&#22122;&#22768;&#25968;&#25454;&#27169;&#22411;&#65292;&#24182;&#23637;&#31034;Mixup&#35757;&#32451;&#21487;&#20197;&#26377;&#25928;&#22320;&#20174;&#20854;&#19982;&#24120;&#35265;&#29305;&#24449;&#65288;&#20986;&#29616;&#22312;&#22823;&#37096;&#20998;&#25968;&#25454;&#20013;&#65289;&#28151;&#21512;&#20013;&#23398;&#20064;&#32597;&#35265;&#29305;&#24449;&#65288;&#20986;&#29616;&#22312;&#23569;&#37096;&#20998;&#25968;&#25454;&#20013;&#65289;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#26631;&#20934;&#35757;&#32451;&#21487;&#33021;&#20250;&#28431;&#25481;&#36825;&#20123;&#32597;&#35265;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Mixup, a simple data augmentation method that randomly mixes two data points via linear interpolation, has been extensively applied in various deep learning applications to gain better generalization. However, the theoretical underpinnings of its efficacy are not yet fully understood. In this paper, we aim to seek a fundamental understanding of the benefits of Mixup. We first show that Mixup using different linear interpolation parameters for features and labels can still achieve similar performance to the standard Mixup. This indicates that the intuitive linearity explanation in Zhang et al., (2018) may not fully explain the success of Mixup. Then we perform a theoretical study of Mixup from the feature learning perspective. We consider a feature-noise data model and show that Mixup training can effectively learn the rare features (appearing in a small fraction of data) from its mixture with the common features (appearing in a large fraction of data). In contrast, standard training ca
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#22312;&#20960;&#20046;&#32447;&#24615;&#20108;&#27425;&#22411;&#35843;&#33410;&#22120;&#31995;&#32479;&#20013;&#25214;&#21040;&#26368;&#20248;&#31574;&#30053;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31574;&#30053;&#26799;&#24230;&#31639;&#27861;&#65292;&#21487;&#20197;&#20197;&#32447;&#24615;&#36895;&#29575;&#25910;&#25947;&#20110;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;</title><link>http://arxiv.org/abs/2303.08431</link><description>&lt;p&gt;
&#25919;&#31574;&#26799;&#24230;&#31639;&#27861;&#25910;&#25947;&#20110;&#20960;&#20046;&#32447;&#24615;&#20108;&#27425;&#22411;&#35843;&#33410;&#22120;&#30340;&#20840;&#23616;&#26368;&#20248;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Policy Gradient Converges to the Globally Optimal Policy for Nearly Linear-Quadratic Regulators. (arXiv:2303.08431v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.08431
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#22312;&#20960;&#20046;&#32447;&#24615;&#20108;&#27425;&#22411;&#35843;&#33410;&#22120;&#31995;&#32479;&#20013;&#25214;&#21040;&#26368;&#20248;&#31574;&#30053;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31574;&#30053;&#26799;&#24230;&#31639;&#27861;&#65292;&#21487;&#20197;&#20197;&#32447;&#24615;&#36895;&#29575;&#25910;&#25947;&#20110;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20915;&#31574;&#32773;&#21482;&#33719;&#24471;&#20102;&#38750;&#23436;&#25972;&#20449;&#24687;&#30340;&#38750;&#32447;&#24615;&#25511;&#21046;&#31995;&#32479;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#26222;&#36941;&#23384;&#22312;&#12290;&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#65292;&#20197;&#25214;&#21040;&#20960;&#20046;&#32447;&#24615;&#20108;&#27425;&#22411;&#35843;&#33410;&#22120;&#31995;&#32479;&#20013;&#26368;&#20248;&#31574;&#30053;&#12290;&#25105;&#20204;&#32771;&#34385;&#19968;&#20010;&#21160;&#24577;&#31995;&#32479;&#65292;&#32467;&#21512;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#32452;&#25104;&#37096;&#20998;&#65292;&#24182;&#30001;&#30456;&#21516;&#32467;&#26500;&#30340;&#31574;&#30053;&#36827;&#34892;&#31649;&#29702;&#12290;&#22312;&#20551;&#35774;&#38750;&#32447;&#24615;&#32452;&#25104;&#37096;&#20998;&#21253;&#21547;&#20855;&#26377;&#23567;&#22411;Lipschitz&#31995;&#25968;&#30340;&#20869;&#26680;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#23545;&#25104;&#26412;&#20989;&#25968;&#30340;&#20248;&#21270;&#36827;&#34892;&#20102;&#34920;&#24449;&#12290;&#34429;&#28982;&#25104;&#26412;&#20989;&#25968;&#36890;&#24120;&#26159;&#38750;&#20984;&#30340;&#65292;&#20294;&#25105;&#20204;&#30830;&#31435;&#20102;&#20840;&#23616;&#26368;&#20248;&#35299;&#38468;&#36817;&#23616;&#37096;&#30340;&#24378;&#20984;&#24615;&#21644;&#20809;&#28369;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21021;&#22987;&#21270;&#26426;&#21046;&#65292;&#20197;&#21033;&#29992;&#36825;&#20123;&#23646;&#24615;&#12290;&#22312;&#27492;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#31574;&#30053;&#26799;&#24230;&#31639;&#27861;&#65292;&#21487;&#20197;&#20445;&#35777;&#20197;&#32447;&#24615;&#36895;&#29575;&#25910;&#25947;&#20110;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Nonlinear control systems with partial information to the decision maker are prevalent in a variety of applications. As a step toward studying such nonlinear systems, this work explores reinforcement learning methods for finding the optimal policy in the nearly linear-quadratic regulator systems. In particular, we consider a dynamic system that combines linear and nonlinear components, and is governed by a policy with the same structure. Assuming that the nonlinear component comprises kernels with small Lipschitz coefficients, we characterize the optimization landscape of the cost function. Although the cost function is nonconvex in general, we establish the local strong convexity and smoothness in the vicinity of the global optimizer. Additionally, we propose an initialization mechanism to leverage these properties. Building on the developments, we design a policy gradient algorithm that is guaranteed to converge to the globally optimal policy with a linear rate.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#38024;&#23545;&#22810;&#32500;&#27969;&#24335;&#26102;&#38388;&#24207;&#21015;&#30340;&#26368;&#20248;&#25277;&#26679;&#35774;&#35745;&#26041;&#27861;&#65292;&#24182;&#24212;&#29992;&#20110;&#39640;&#36895;&#30005;&#21147;&#28040;&#32791;&#25968;&#25454;&#30340;&#20302;&#25104;&#26412;&#23454;&#26102;&#20998;&#26512;&#65292;&#25552;&#39640;&#20102;&#35745;&#31639;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2303.08242</link><description>&lt;p&gt;
&#22810;&#32500;&#27969;&#24335;&#26102;&#38388;&#24207;&#21015;&#30340;&#26368;&#20248;&#25277;&#26679;&#35774;&#35745;&#21450;&#22312;&#30005;&#21147;&#31995;&#32479;&#30417;&#27979;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Optimal Sampling Designs for Multi-dimensional Streaming Time Series with Application to Power Grid Sensor Data. (arXiv:2303.08242v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.08242
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#38024;&#23545;&#22810;&#32500;&#27969;&#24335;&#26102;&#38388;&#24207;&#21015;&#30340;&#26368;&#20248;&#25277;&#26679;&#35774;&#35745;&#26041;&#27861;&#65292;&#24182;&#24212;&#29992;&#20110;&#39640;&#36895;&#30005;&#21147;&#28040;&#32791;&#25968;&#25454;&#30340;&#20302;&#25104;&#26412;&#23454;&#26102;&#20998;&#26512;&#65292;&#25552;&#39640;&#20102;&#35745;&#31639;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29289;&#32852;&#32593;&#31995;&#32479;&#20135;&#29983;&#20102;&#22823;&#37327;&#39640;&#36895;&#26102;&#38388;&#30456;&#20851;&#30340;&#27969;&#24335;&#25968;&#25454;&#65292;&#24182;&#32463;&#24120;&#19982;&#35745;&#31639;&#25110;&#33021;&#28304;&#32422;&#26463;&#19979;&#30340;&#22312;&#32447;&#25512;&#26029;&#20219;&#21153;&#30456;&#36830;&#12290;&#23545;&#36825;&#20123;&#27969;&#24335;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#22312;&#32447;&#20998;&#26512;&#32463;&#24120;&#38754;&#20020;&#32479;&#35745;&#25928;&#29575;&#21644;&#35745;&#31639;&#25104;&#26412;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;&#35299;&#20915;&#36825;&#31181;&#26435;&#34913;&#30340;&#19968;&#20010;&#37325;&#35201;&#26041;&#27861;&#26159;&#25277;&#26679;&#65292;&#20165;&#36873;&#25321;&#19968;&#23567;&#37096;&#20998;&#26679;&#26412;&#36827;&#34892;&#27169;&#22411;&#25311;&#21512;&#21644;&#26356;&#26032;&#12290;&#20026;&#20102;&#28385;&#36275;&#29289;&#32852;&#32593;&#31995;&#32479;&#21160;&#24577;&#20851;&#31995;&#20998;&#26512;&#30340;&#38656;&#27714;&#65292;&#26412;&#25991;&#30740;&#31350;&#20102;&#38754;&#21521;&#22810;&#32500;&#27969;&#24335;&#26102;&#38388;&#24207;&#21015;&#30340;&#25968;&#25454;&#20381;&#36182;&#25277;&#26679;&#36873;&#25321;&#21644;&#22312;&#32447;&#25512;&#26029;&#38382;&#39064;&#65292;&#26088;&#22312;&#25552;&#20379;&#39640;&#36895;&#30005;&#21147;&#28040;&#32791;&#25968;&#25454;&#30340;&#20302;&#25104;&#26412;&#23454;&#26102;&#20998;&#26512;&#12290;&#21463;&#23454;&#39564;&#35774;&#35745;&#20013;D-&#25928;&#24212;&#20934;&#21017;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31867;&#22312;&#32447;&#25968;&#25454;&#32553;&#20943;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#26368;&#20248;&#25277;&#26679;&#20934;&#21017;&#65292;&#24182;&#25552;&#39640;&#20102;&#22312;&#32447;&#20998;&#26512;&#30340;&#35745;&#31639;&#25928;&#29575;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;...
&lt;/p&gt;
&lt;p&gt;
The Internet of Things (IoT) system generates massive high-speed temporally correlated streaming data and is often connected with online inference tasks under computational or energy constraints. Online analysis of these streaming time series data often faces a trade-off between statistical efficiency and computational cost. One important approach to balance this trade-off is sampling, where only a small portion of the sample is selected for the model fitting and update. Motivated by the demands of dynamic relationship analysis of IoT system, we study the data-dependent sample selection and online inference problem for a multi-dimensional streaming time series, aiming to provide low-cost real-time analysis of high-speed power grid electricity consumption data. Inspired by D-optimality criterion in design of experiments, we propose a class of online data reduction methods that achieve an optimal sampling criterion and improve the computational efficiency of the online analysis. We show 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Beta-Bernoulli&#36807;&#31243;&#21644;&#38750;&#21442;&#25968;&#36845;&#20195;&#31639;&#27861;&#30340;&#28145;&#24230;&#31232;&#30095;&#32534;&#30721;&#27169;&#22411;&#65292;&#26088;&#22312;&#23398;&#20064;&#20855;&#26377;&#23610;&#24230;&#19981;&#21464;&#24615;&#30340;&#31163;&#25955;&#29305;&#24449;&#65292;&#24182;&#40723;&#21169;&#34920;&#31034;&#30340;&#31232;&#30095;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.08230</link><description>&lt;p&gt;
&#22522;&#20110;Beta-Bernoulli&#36807;&#31243;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#36125;&#21494;&#26031;&#31232;&#30095;&#32534;&#30721;
&lt;/p&gt;
&lt;p&gt;
Bayesian Beta-Bernoulli Process Sparse Coding with Deep Neural Networks. (arXiv:2303.08230v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.08230
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Beta-Bernoulli&#36807;&#31243;&#21644;&#38750;&#21442;&#25968;&#36845;&#20195;&#31639;&#27861;&#30340;&#28145;&#24230;&#31232;&#30095;&#32534;&#30721;&#27169;&#22411;&#65292;&#26088;&#22312;&#23398;&#20064;&#20855;&#26377;&#23610;&#24230;&#19981;&#21464;&#24615;&#30340;&#31163;&#25955;&#29305;&#24449;&#65292;&#24182;&#40723;&#21169;&#34920;&#31034;&#30340;&#31232;&#30095;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#28145;&#24230;&#31163;&#25955;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#20960;&#31181;&#36817;&#20284;&#25512;&#26029;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#22312;&#32463;&#20856;&#31232;&#30095;&#32534;&#30721;&#27169;&#22411;&#20013;&#25104;&#21151;&#24212;&#29992;&#30340;&#38750;&#21442;&#25968;&#26041;&#27861;&#65292;&#22312;&#28145;&#24230;&#27169;&#22411;&#30340;&#19978;&#19979;&#25991;&#20013;&#24456;&#23569;&#34987;&#25506;&#32034;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#36845;&#20195;&#31639;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#27492;&#31867;&#28145;&#24230;&#27169;&#22411;&#20013;&#30340;&#31163;&#25955;&#28508;&#22312;&#34920;&#31034;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#23398;&#20064;&#20855;&#26377;&#23610;&#24230;&#19981;&#21464;&#24615;&#30340;&#31163;&#25955;&#29305;&#24449;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26412;&#22320;&#25968;&#25454;&#32553;&#25918;&#21464;&#37327;&#12290;&#26368;&#21518;&#65292;&#20026;&#20102;&#22312;&#25105;&#20204;&#30340;&#34920;&#31034;&#20013;&#40723;&#21169;&#31232;&#30095;&#24615;&#65292;&#25105;&#20204;&#22312;&#28508;&#22312;&#22240;&#23376;&#19978;&#25552;&#20986;&#20102;Beta-Bernoulli&#36807;&#31243;&#20808;&#39564;&#12290;&#25105;&#20204;&#23545;&#32806;&#21512;&#19981;&#21516;&#20284;&#28982;&#27169;&#22411;&#30340;&#31232;&#30095;&#32534;&#30721;&#27169;&#22411;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;&#25105;&#20204;&#22312;&#20855;&#26377;&#19981;&#21516;&#29305;&#24449;&#30340;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#24182;&#23558;&#32467;&#26524;&#19982;&#24403;&#21069;&#30340;&#25674;&#38144;&#36817;&#20284;&#25512;&#26029;&#26041;&#27861;&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Several approximate inference methods have been proposed for deep discrete latent variable models. However, non-parametric methods which have previously been successfully employed for classical sparse coding models have largely been unexplored in the context of deep models. We propose a non-parametric iterative algorithm for learning discrete latent representations in such deep models. Additionally, to learn scale invariant discrete features, we propose local data scaling variables. Lastly, to encourage sparsity in our representations, we propose a Beta-Bernoulli process prior on the latent factors. We evaluate our spare coding model coupled with different likelihood models. We evaluate our method across datasets with varying characteristics and compare our results to current amortized approximate inference methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#22266;&#23450;&#19987;&#23478;&#24314;&#35758;&#19979;&#30340;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#20449;&#24687;&#35770;&#30340;&#36951;&#25022;&#30028;&#38480;&#65292;&#21487;&#20197;&#20351;&#24471;&#26576;&#20123;&#31639;&#27861;&#30340;&#36951;&#25022;&#26080;&#38480;&#25509;&#36817;&#20110;&#38646;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;KL&#25955;&#24230;&#26469;&#25551;&#36848;&#19987;&#23478;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#30028;&#38480;&#65292;&#24182;&#32473;&#20986;&#20102;&#19979;&#38480;&#35777;&#26126;&#31639;&#27861;&#30340;&#26368;&#20248;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.08102</link><description>&lt;p&gt;
&#22522;&#20110;&#20449;&#24687;&#29702;&#35770;&#30340;&#22266;&#23450;&#19987;&#23478;&#24314;&#35758;&#19979;&#36172;&#21338;&#26426;&#30340;&#36951;&#25022;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Information-Theoretic Regret Bounds for Bandits with Fixed Expert Advice. (arXiv:2303.08102v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.08102
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22266;&#23450;&#19987;&#23478;&#24314;&#35758;&#19979;&#30340;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#20449;&#24687;&#35770;&#30340;&#36951;&#25022;&#30028;&#38480;&#65292;&#21487;&#20197;&#20351;&#24471;&#26576;&#20123;&#31639;&#27861;&#30340;&#36951;&#25022;&#26080;&#38480;&#25509;&#36817;&#20110;&#38646;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;KL&#25955;&#24230;&#26469;&#25551;&#36848;&#19987;&#23478;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#30028;&#38480;&#65292;&#24182;&#32473;&#20986;&#20102;&#19979;&#38480;&#35777;&#26126;&#31639;&#27861;&#30340;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#19987;&#23478;&#26159;&#22266;&#23450;&#21644;&#24050;&#30693;&#30340;&#24773;&#20917;&#19979;&#65292;&#36172;&#21338;&#26426;&#19982;&#19987;&#23478;&#24314;&#35758;&#30340;&#38382;&#39064;&#65292;&#36825;&#20123;&#19987;&#23478;&#26159;&#34892;&#21160;&#22266;&#23450;&#21644;&#24050;&#30693;&#20998;&#24067;&#12290;&#30456;&#27604;&#20197;&#21069;&#30340;&#20998;&#26512;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#24773;&#20917;&#19979;&#36951;&#25022;&#26159;&#30001;&#34913;&#37327;&#19987;&#23478;&#20043;&#38388;&#30456;&#20284;&#24615;&#30340;&#20449;&#24687;&#35770;&#37327;&#25152;&#25511;&#21046;&#30340;&#12290;&#22312;&#19968;&#20123;&#33258;&#28982;&#29305;&#27530;&#24773;&#20917;&#19979;&#65292;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#33719;&#24471;EXP4&#30340;&#31532;&#19968;&#20010;&#36951;&#25022;&#30028;&#38480;&#65292;&#22914;&#26524;&#19987;&#23478;&#36275;&#22815;&#30456;&#20284;&#65292;&#21017;&#21487;&#20197;&#26080;&#38480;&#25509;&#36817;&#20110;&#38646;&#12290;&#20026;&#21478;&#19968;&#31181;&#31639;&#27861;&#25552;&#20379;&#20102;&#21487;&#20197;&#29992;KL&#25955;&#24230;&#26469;&#25551;&#36848;&#19987;&#23478;&#20043;&#38388;&#30456;&#20284;&#24615;&#30340;&#21478;&#19968;&#31181;&#30028;&#38480;&#65292;&#24182;&#19988;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20010;&#30028;&#38480;&#21487;&#20197;&#27604;EXP4&#26356;&#23567;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20026;&#26576;&#20123;&#19987;&#23478;&#31867;&#21035;&#25552;&#20379;&#20102;&#19979;&#38480;&#65292;&#23637;&#31034;&#20102;&#25105;&#20204;&#20998;&#26512;&#30340;&#31639;&#27861;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#26159;&#20960;&#20046;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the problem of bandits with expert advice when the experts are fixed and known distributions over the actions. Improving on previous analyses, we show that the regret in this setting is controlled by information-theoretic quantities that measure the similarity between experts. In some natural special cases, this allows us to obtain the first regret bound for EXP4 that can get arbitrarily close to zero if the experts are similar enough. While for a different algorithm, we provide another bound that describes the similarity between the experts in terms of the KL-divergence, and we show that this bound can be smaller than the one of EXP4 in some cases. Additionally, we provide lower bounds for certain classes of experts showing that the algorithms we analyzed are nearly optimal in some cases.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20803;&#23398;&#20064;&#25511;&#21046;&#21464;&#37327;&#30340;&#26041;&#27861;&#65292;&#21487;&#22312;&#26377;&#38480;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#20943;&#23567;&#33945;&#29305;&#21345;&#32599;&#20272;&#35745;&#22120;&#30340;&#26041;&#24046;&#65292;&#24182;&#23545;&#22810;&#20010;&#20219;&#21153;&#36827;&#34892;&#22788;&#29702;&#12290;</title><link>http://arxiv.org/abs/2303.04756</link><description>&lt;p&gt;
&#20803;&#23398;&#20064;&#25511;&#21046;&#21464;&#37327;&#65306;&#26377;&#38480;&#25968;&#25454;&#20013;&#26041;&#24046;&#32553;&#20943;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Meta-learning Control Variates: Variance Reduction with Limited Data. (arXiv:2303.04756v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.04756
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20803;&#23398;&#20064;&#25511;&#21046;&#21464;&#37327;&#30340;&#26041;&#27861;&#65292;&#21487;&#22312;&#26377;&#38480;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#20943;&#23567;&#33945;&#29305;&#21345;&#32599;&#20272;&#35745;&#22120;&#30340;&#26041;&#24046;&#65292;&#24182;&#23545;&#22810;&#20010;&#20219;&#21153;&#36827;&#34892;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25511;&#21046;&#21464;&#37327;&#26159;&#20943;&#23567;&#33945;&#29305;&#21345;&#32599;&#20272;&#35745;&#22120;&#26041;&#24046;&#30340;&#26377;&#21147;&#24037;&#20855;&#65292;&#20294;&#22312;&#26679;&#26412;&#25968;&#37327;&#36739;&#23567;&#30340;&#24773;&#20917;&#19979;&#26500;&#24314;&#26377;&#25928;&#30340;&#25511;&#21046;&#21464;&#37327;&#21487;&#33021;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#34920;&#26126;&#65292;&#24403;&#38656;&#35201;&#35745;&#31639;&#22823;&#37327;&#30456;&#20851;&#31215;&#20998;&#26102;&#65292;&#21363;&#20351;&#27599;&#20010;&#20219;&#21153;&#30340;&#26679;&#26412;&#25968;&#24456;&#23569;&#65292;&#20063;&#21487;&#20197;&#21033;&#29992;&#36825;&#20123;&#31215;&#20998;&#20219;&#21153;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#26469;&#25552;&#39640;&#24615;&#33021;&#12290;&#25105;&#20204;&#25152;&#25552;&#20986;&#30340;&#20803;&#23398;&#20064;CV&#65288;Meta-CVs&#65289;&#26041;&#27861;&#21487;&#29992;&#20110;&#22788;&#29702;&#25968;&#30334;&#20010;&#25110;&#25968;&#21315;&#20010;&#20219;&#21153;&#65292;&#24182;&#36890;&#36807;&#23454;&#35777;&#35780;&#20272;&#34920;&#26126;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;Meta-CVs&#21487;&#20197;&#26174;&#33879;&#20943;&#23567;&#26041;&#24046;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#30830;&#23450;&#20102;Meta-CVs&#25104;&#21151;&#35757;&#32451;&#30340;&#19968;&#33324;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
Control variates can be a powerful tool to reduce the variance of Monte Carlo estimators, but constructing effective control variates can be challenging when the number of samples is small. In this paper, we show that when a large number of related integrals need to be computed, it is possible to leverage the similarity between these integration tasks to improve performance even when the number of samples per task is very small. Our approach, called meta learning CVs (Meta-CVs), can be used for up to hundreds or thousands of tasks. Our empirical assessment indicates that Meta-CVs can lead to significant variance reduction in such settings, and our theoretical analysis establishes general conditions under which Meta-CVs can be successfully trained.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26102;&#38388;&#24207;&#21015;&#29983;&#25104;&#26041;&#27861;&#65292;&#20351;&#29992;&#21521;&#37327;&#37327;&#21270;&#25216;&#26415;&#21644;&#21452;&#21521;&#21464;&#21387;&#22120;&#27169;&#22411;&#26469;&#29983;&#25104;&#36136;&#37327;&#26356;&#22909;&#12289;&#27169;&#22359;&#21270;&#21464;&#21270;&#26356;&#24555;&#30340;&#21512;&#25104;&#20449;&#21495;&#12290;</title><link>http://arxiv.org/abs/2303.04743</link><description>&lt;p&gt;
&#24102;&#26377;&#21452;&#21521;&#20808;&#39564;&#27169;&#22411;&#30340;&#21521;&#37327;&#37327;&#21270;&#26102;&#38388;&#24207;&#21015;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Vector Quantized Time Series Generation with a Bidirectional Prior Model. (arXiv:2303.04743v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.04743
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26102;&#38388;&#24207;&#21015;&#29983;&#25104;&#26041;&#27861;&#65292;&#20351;&#29992;&#21521;&#37327;&#37327;&#21270;&#25216;&#26415;&#21644;&#21452;&#21521;&#21464;&#21387;&#22120;&#27169;&#22411;&#26469;&#29983;&#25104;&#36136;&#37327;&#26356;&#22909;&#12289;&#27169;&#22359;&#21270;&#21464;&#21270;&#26356;&#24555;&#30340;&#21512;&#25104;&#20449;&#21495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#24207;&#21015;&#29983;&#25104;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#20351;&#29992;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#19982;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#65288;RNN&#65289;&#21464;&#20307;&#30456;&#32467;&#21512;&#12290;&#28982;&#32780;&#65292;&#35757;&#32451; GAN &#30340;&#22522;&#26412;&#38480;&#21046;&#21644;&#25361;&#25112;&#20173;&#28982;&#23384;&#22312;&#12290;&#27492;&#22806;&#65292;RNN&#26063;&#36890;&#24120;&#22312;&#36828;&#31243;&#26102;&#38388;&#27493;&#20043;&#38388;&#30340;&#26102;&#38388;&#19968;&#33268;&#24615;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#12290;&#21463;&#21040;&#22270;&#20687;&#29983;&#25104;&#39046;&#22495;&#25104;&#21151;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986; TimeVQVAE&#65292;&#36825;&#26159;&#25105;&#20204;&#25152;&#30693;&#36947;&#30340;&#31532;&#19968;&#20010;&#20351;&#29992;&#21521;&#37327;&#37327;&#21270;&#65288;VQ&#65289;&#25216;&#26415;&#35299;&#20915; TSG &#38382;&#39064;&#30340;&#24037;&#20316;&#12290;&#27492;&#22806;&#65292;&#31163;&#25955;&#28508;&#22312;&#31354;&#38388;&#30340;&#20808;&#39564;&#20351;&#29992;&#21452;&#21521;&#21464;&#21387;&#22120;&#27169;&#22411;&#36827;&#34892;&#23398;&#20064;&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#25429;&#25417;&#20840;&#23616;&#26102;&#38388;&#19968;&#33268;&#24615;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#22312;&#26102;&#38388; - &#39057;&#29575;&#22495;&#20013;&#36827;&#34892; VQ &#24314;&#27169;&#65292;&#20998;&#20026;&#20302;&#39057;&#65288;LF&#65289;&#21644;&#39640;&#39057;&#65288;HF&#65289;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#20445;&#30041;&#26102;&#38388;&#24207;&#21015;&#30340;&#37325;&#35201;&#29305;&#24449;&#65292;&#24182;&#29983;&#25104;&#36136;&#37327;&#26356;&#22909;&#12289;&#27169;&#22359;&#24615;&#21464;&#21270;&#26356;&#24555;&#30340;&#26032;&#21512;&#25104;&#20449;&#21495;&#12290;
&lt;/p&gt;
&lt;p&gt;
Time series generation (TSG) studies have mainly focused on the use of Generative Adversarial Networks (GANs) combined with recurrent neural network (RNN) variants. However, the fundamental limitations and challenges of training GANs still remain. In addition, the RNN-family typically has difficulties with temporal consistency between distant timesteps. Motivated by the successes in the image generation (IMG) domain, we propose TimeVQVAE, the first work, to our knowledge, that uses vector quantization (VQ) techniques to address the TSG problem. Moreover, the priors of the discrete latent spaces are learned with bidirectional transformer models that can better capture global temporal consistency. We also propose VQ modeling in a time-frequency domain, separated into low-frequency (LF) and high-frequency (HF). This allows us to retain important characteristics of the time series and, in turn, generate new synthetic signals that are of better quality, with sharper changes in modularity, t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Fisher&#32447;&#24615;&#21028;&#21035;&#30340;&#39046;&#22495;&#33258;&#36866;&#24212;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#26159;&#20004;&#20010;&#20551;&#35774;&#30340;&#20984;&#32452;&#21512;&#65292;&#21487;&#20197;&#22312;&#19981;&#35775;&#38382;&#20219;&#20309;&#21333;&#20010;&#28304;&#20219;&#21153;&#30340;&#30452;&#25509;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#35745;&#31639;&#26368;&#20248;&#20998;&#31867;&#22120;&#65292;&#24182;&#22312;&#22522;&#20110;EEG&#21644;ECG&#30340;&#20998;&#31867;&#35774;&#32622;&#20013;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.14186</link><description>&lt;p&gt;
&#24102;&#26377;Fisher&#32447;&#24615;&#21028;&#21035;&#20998;&#26512;&#30340;&#36817;&#20284;&#26368;&#20248;&#39046;&#22495;&#33258;&#36866;&#24212;
&lt;/p&gt;
&lt;p&gt;
Approximately optimal domain adaptation with Fisher's Linear Discriminant Analysis. (arXiv:2302.14186v2 [eess.SP] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.14186
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Fisher&#32447;&#24615;&#21028;&#21035;&#30340;&#39046;&#22495;&#33258;&#36866;&#24212;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#26159;&#20004;&#20010;&#20551;&#35774;&#30340;&#20984;&#32452;&#21512;&#65292;&#21487;&#20197;&#22312;&#19981;&#35775;&#38382;&#20219;&#20309;&#21333;&#20010;&#28304;&#20219;&#21153;&#30340;&#30452;&#25509;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#35745;&#31639;&#26368;&#20248;&#20998;&#31867;&#22120;&#65292;&#24182;&#22312;&#22522;&#20110;EEG&#21644;ECG&#30340;&#20998;&#31867;&#35774;&#32622;&#20013;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31867;&#22522;&#20110;Fisher&#32447;&#24615;&#21028;&#21035;&#65288;FLD&#65289;&#30340;&#27169;&#22411;&#65292;&#29992;&#20110;&#39046;&#22495;&#33258;&#36866;&#24212;&#12290;&#35813;&#31867;&#27169;&#22411;&#26159;&#20004;&#20010;&#20551;&#35774;&#30340;&#20984;&#32452;&#21512;&#65306;i&#65289;&#20195;&#34920;&#20808;&#21069;&#30475;&#21040;&#30340;&#28304;&#20219;&#21153;&#30340;&#24179;&#22343;&#20551;&#35774;&#21644;ii&#65289;&#22312;&#26032;&#30340;&#30446;&#26631;&#20219;&#21153;&#19978;&#35757;&#32451;&#30340;&#20551;&#35774;&#12290;&#23545;&#20110;&#29305;&#23450;&#30340;&#29983;&#25104;&#35774;&#32622;&#65292;&#25105;&#20204;&#22312;0-1&#25439;&#22833;&#19979;&#23548;&#20986;&#20102;&#20004;&#31181;&#27169;&#22411;&#30340;&#26368;&#20248;&#20984;&#32452;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#35745;&#31639;&#30340;&#36924;&#36817;&#65292;&#24182;&#30740;&#31350;&#20102;&#21508;&#31181;&#21442;&#25968;&#35774;&#32622;&#23545;&#26368;&#20248;&#20551;&#35774;&#12289;&#20551;&#35774;i&#65289;&#21644;&#20551;&#35774;ii&#65289;&#20043;&#38388;&#30456;&#23545;&#39118;&#38505;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;&#26368;&#20248;&#20998;&#31867;&#22120;&#22312;&#22522;&#20110;EEG&#21644;ECG&#30340;&#20998;&#31867;&#35774;&#32622;&#20013;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#35748;&#20026;&#21487;&#20197;&#22312;&#19981;&#35775;&#38382;&#20219;&#20309;&#21333;&#20010;&#28304;&#20219;&#21153;&#30340;&#30452;&#25509;&#20449;&#24687;&#30340;&#24773;&#20917;&#19979;&#35745;&#31639;&#26368;&#20248;&#20998;&#31867;&#22120;&#12290;&#26368;&#21518;&#25105;&#20204;&#35752;&#35770;&#20102;&#36827;&#19968;&#27493;&#30340;&#24212;&#29992;&#12289;&#38480;&#21046;&#21644;&#21487;&#33021;&#30340;&#26410;&#26469;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a class of models based on Fisher's Linear Discriminant (FLD) in the context of domain adaptation. The class is the convex combination of two hypotheses: i) an average hypothesis representing previously seen source tasks and ii) a hypothesis trained on a new target task. For a particular generative setting we derive the optimal convex combination of the two models under 0-1 loss, propose a computable approximation, and study the effect of various parameter settings on the relative risks between the optimal hypothesis, hypothesis i), and hypothesis ii). We demonstrate the effectiveness of the proposed optimal classifier in the context of EEG- and ECG-based classification settings and argue that the optimal classifier can be computed without access to direct information from any of the individual source tasks. We conclude by discussing further applications, limitations, and possible future directions.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20851;&#20110;&#26680;&#23725;&#22238;&#24402;&#30340;&#21327;&#21464;&#37327;&#36716;&#31227;&#31574;&#30053;&#65292;&#36890;&#36807;&#20351;&#29992;&#20266;&#26631;&#31614;&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;&#65292;&#33021;&#22815;&#36866;&#24212;&#19981;&#21516;&#29305;&#24449;&#20998;&#24067;&#19979;&#30340;&#23398;&#20064;&#65292;&#23454;&#29616;&#22343;&#26041;&#35823;&#24046;&#26368;&#23567;&#21270;&#12290;</title><link>http://arxiv.org/abs/2302.10160</link><description>&lt;p&gt;
&#26680;&#23725;&#22238;&#24402;&#19979;&#20266;&#26631;&#31614;&#30340;&#21327;&#21464;&#37327;&#36716;&#31227;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Pseudo-Labeling for Kernel Ridge Regression under Covariate Shift. (arXiv:2302.10160v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.10160
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20851;&#20110;&#26680;&#23725;&#22238;&#24402;&#30340;&#21327;&#21464;&#37327;&#36716;&#31227;&#31574;&#30053;&#65292;&#36890;&#36807;&#20351;&#29992;&#20266;&#26631;&#31614;&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;&#65292;&#33021;&#22815;&#36866;&#24212;&#19981;&#21516;&#29305;&#24449;&#20998;&#24067;&#19979;&#30340;&#23398;&#20064;&#65292;&#23454;&#29616;&#22343;&#26041;&#35823;&#24046;&#26368;&#23567;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#24182;&#20998;&#26512;&#20102;&#19968;&#31181;&#22522;&#20110;&#21327;&#21464;&#37327;&#36716;&#31227;&#30340;&#26680;&#23725;&#22238;&#24402;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#22312;&#30446;&#26631;&#20998;&#24067;&#19978;&#23398;&#20064;&#19968;&#20010;&#22343;&#26041;&#35823;&#24046;&#26368;&#23567;&#30340;&#22238;&#24402;&#20989;&#25968;&#65292;&#22522;&#20110;&#20174;&#30446;&#26631;&#20998;&#24067;&#37319;&#26679;&#30340;&#26410;&#26631;&#35760;&#25968;&#25454;&#21644;&#21487;&#33021;&#20855;&#26377;&#19981;&#21516;&#29305;&#24449;&#20998;&#24067;&#30340;&#24050;&#26631;&#35760;&#25968;&#25454;&#12290;&#25105;&#20204;&#23558;&#24050;&#26631;&#35760;&#25968;&#25454;&#20998;&#25104;&#20004;&#20010;&#23376;&#38598;&#65292;&#24182;&#20998;&#21035;&#36827;&#34892;&#26680;&#23725;&#22238;&#24402;&#65292;&#20197;&#33719;&#24471;&#20505;&#36873;&#27169;&#22411;&#38598;&#21512;&#21644;&#19968;&#20010;&#22635;&#20805;&#27169;&#22411;&#12290;&#25105;&#20204;&#20351;&#29992;&#21518;&#32773;&#22635;&#20805;&#32570;&#22833;&#30340;&#26631;&#31614;&#65292;&#28982;&#21518;&#30456;&#24212;&#22320;&#36873;&#25321;&#26368;&#20339;&#30340;&#20505;&#36873;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#38750;&#28176;&#36817;&#24615;&#36807;&#37327;&#39118;&#38505;&#30028;&#34920;&#26126;&#65292;&#22312;&#30456;&#24403;&#19968;&#33324;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#33021;&#22815;&#36866;&#24212;&#30446;&#26631;&#20998;&#24067;&#20197;&#21450;&#21327;&#21464;&#37327;&#36716;&#31227;&#30340;&#32467;&#26500;&#12290;&#23427;&#33021;&#22815;&#23454;&#29616;&#28176;&#36817;&#27491;&#24577;&#35823;&#24046;&#29575;&#30452;&#21040;&#23545;&#25968;&#22240;&#23376;&#30340;&#26368;&#23567;&#26497;&#38480;&#20248;&#21270;&#12290;&#22312;&#27169;&#22411;&#36873;&#25321;&#20013;&#20351;&#29992;&#20266;&#26631;&#31614;&#19981;&#20250;&#20135;&#29983;&#20027;&#35201;&#36127;&#38754;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop and analyze a principled approach to kernel ridge regression under covariate shift. The goal is to learn a regression function with small mean squared error over a target distribution, based on unlabeled data from there and labeled data that may have a different feature distribution. We propose to split the labeled data into two subsets and conduct kernel ridge regression on them separately to obtain a collection of candidate models and an imputation model. We use the latter to fill the missing labels and then select the best candidate model accordingly. Our non-asymptotic excess risk bounds show that in quite general scenarios, our estimator adapts to the structure of the target distribution as well as the covariate shift. It achieves the minimax optimal error rate up to a logarithmic factor. The use of pseudo-labels in model selection does not have major negative impacts.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#33324;&#31867;&#30340;&#38750;&#32447;&#24615;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;&#22810;&#27169;&#24335;&#23545;&#27604;&#23398;&#20064;&#65292;&#25581;&#31034;&#20102;&#20854;&#19982;&#22855;&#24322;&#20540;&#20998;&#35299;&#30340;&#32852;&#31995;&#12290;&#24182;&#35777;&#26126;&#22312;&#38169;&#35823;&#21305;&#37197;&#30340;&#24773;&#20917;&#19979;&#65292;&#22810;&#27169;&#24335;&#23545;&#27604;&#23398;&#20064;&#21487;&#20197;&#27604;&#21333;&#27169;&#24335;&#23545;&#27604;&#23398;&#20064;&#34920;&#29616;&#26356;&#20339;&#65292;&#34920;&#29616;&#20102;&#20854;&#23545;&#22024;&#26434;&#25968;&#25454;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.06232</link><description>&lt;p&gt;
&#29702;&#35299;&#22810;&#27169;&#24335;&#23545;&#27604;&#23398;&#20064;&#21450;&#25972;&#21512;&#38750;&#37197;&#23545;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Understanding Multimodal Contrastive Learning and Incorporating Unpaired Data. (arXiv:2302.06232v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.06232
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#33324;&#31867;&#30340;&#38750;&#32447;&#24615;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;&#22810;&#27169;&#24335;&#23545;&#27604;&#23398;&#20064;&#65292;&#25581;&#31034;&#20102;&#20854;&#19982;&#22855;&#24322;&#20540;&#20998;&#35299;&#30340;&#32852;&#31995;&#12290;&#24182;&#35777;&#26126;&#22312;&#38169;&#35823;&#21305;&#37197;&#30340;&#24773;&#20917;&#19979;&#65292;&#22810;&#27169;&#24335;&#23545;&#27604;&#23398;&#20064;&#21487;&#20197;&#27604;&#21333;&#27169;&#24335;&#23545;&#27604;&#23398;&#20064;&#34920;&#29616;&#26356;&#20339;&#65292;&#34920;&#29616;&#20102;&#20854;&#23545;&#22024;&#26434;&#25968;&#25454;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#35821;&#35328;&#30417;&#30563;&#30340;&#35270;&#35273;&#27169;&#22411;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#39046;&#22495;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#26500;&#24314;&#36825;&#31181;&#27169;&#22411;&#30340;&#24120;&#35265;&#26041;&#27861;&#26159;&#20351;&#29992;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#22312;&#20004;&#31181;&#27169;&#24577;&#20043;&#38388;&#23545;&#37197;&#23545;&#25968;&#25454;&#36827;&#34892;&#23398;&#20064;&#65292;&#20363;&#22914;&#23545;&#27604;&#35821;&#35328; - &#22270;&#20687;&#39044;&#35757;&#32451;&#65288;CLIP&#65289;&#12290;&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#22312;&#32447;&#24615;&#34920;&#31034;&#35774;&#32622;&#19979;&#65292;&#65288;i&#65289;&#21551;&#21160;&#20102;&#19968;&#20010;&#20851;&#20110;&#22810;&#27169;&#24335;&#23545;&#27604;&#23398;&#20064;&#65288;MMCL&#65289;&#30340;&#19968;&#33324;&#38750;&#32447;&#24615;Loss&#20989;&#25968;&#30340;&#35843;&#26597;&#65292;&#21253;&#25324;CLIP Loss&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#19982;&#22855;&#24322;&#20540;&#20998;&#35299;&#65288;SVD&#65289;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;&#21363;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26799;&#24230;&#19979;&#38477;&#27599;&#19968;&#27493;Loss&#26368;&#23567;&#21270;&#21487;&#20197;&#34987;&#35270;&#20026;&#23545;&#19968;&#20010;&#23545;&#27604;&#24615;&#21327;&#26041;&#24046;&#30697;&#38453;&#36827;&#34892;SVD&#12290;&#22522;&#20110;&#36825;&#20010;&#27934;&#23519;&#65292;&#65288;ii&#65289;&#25105;&#20204;&#20998;&#26512;&#20102;MMCL&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#23450;&#37327;&#22320;&#34920;&#26126;&#65292;&#22312;&#38169;&#35823;&#21305;&#37197;&#30340;&#24773;&#20917;&#19979;&#65292;MMCL&#30340;&#29305;&#24449;&#23398;&#20064;&#33021;&#21147;&#21487;&#20197;&#27604;&#21333;&#27169;&#24335;&#23545;&#27604;&#23398;&#20064;&#24212;&#29992;&#20110;&#27599;&#31181;&#27169;&#24335;&#26356;&#22909;&#12290;&#36825;&#34920;&#24449;&#20102;MMCL&#23545;&#22024;&#26434;&#25968;&#25454;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Language-supervised vision models have recently attracted great attention in computer vision. A common approach to build such models is to use contrastive learning on paired data across the two modalities, as exemplified by Contrastive Language-Image Pre-Training (CLIP). In this paper, under linear representation settings, (i) we initiate the investigation of a general class of nonlinear loss functions for multimodal contrastive learning (MMCL) including CLIP loss and show its connection to singular value decomposition (SVD). Namely, we show that each step of loss minimization by gradient descent can be seen as performing SVD on a contrastive cross-covariance matrix. Based on this insight, (ii) we analyze the performance of MMCL. We quantitatively show that the feature learning ability of MMCL can be better than that of unimodal contrastive learning applied to each modality even under the presence of wrongly matched pairs. This characterizes the robustness of MMCL to noisy data. Furthe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#26041;&#27861;&#65292;&#29992;&#20110;&#40065;&#26834;&#30340;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#65292;&#24182;&#22312;&#21463;&#27745;&#26579;&#30340;&#25968;&#25454;&#27969;&#20013;&#35777;&#26126;&#20102;&#20854;&#24615;&#33021;&#34920;&#29616;&#20248;&#24322;&#65292;&#21516;&#26102;&#30830;&#20445;&#20102;&#31283;&#23450;&#24615;&#24182;&#20943;&#23569;&#24322;&#24120;&#20540;&#30340;&#36127;&#38754;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2302.00422</link><description>&lt;p&gt;
&#40065;&#26834;&#30340;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Robust online active learning. (arXiv:2302.00422v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.00422
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#26041;&#27861;&#65292;&#29992;&#20110;&#40065;&#26834;&#30340;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#65292;&#24182;&#22312;&#21463;&#27745;&#26579;&#30340;&#25968;&#25454;&#27969;&#20013;&#35777;&#26126;&#20102;&#20854;&#24615;&#33021;&#34920;&#29616;&#20248;&#24322;&#65292;&#21516;&#26102;&#30830;&#20445;&#20102;&#31283;&#23450;&#24615;&#24182;&#20943;&#23569;&#24322;&#24120;&#20540;&#30340;&#36127;&#38754;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#24037;&#19994;&#24212;&#29992;&#20013;&#65292;&#33719;&#24471;&#26631;&#35760;&#30340;&#35266;&#27979;&#25968;&#25454;&#24182;&#19981;&#31616;&#21333;&#65292;&#36890;&#24120;&#38656;&#35201;&#20154;&#24037;&#19987;&#23478;&#24178;&#39044;&#25110;&#20351;&#29992;&#26114;&#36149;&#30340;&#27979;&#35797;&#35774;&#22791;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#20027;&#21160;&#23398;&#20064;&#21487;&#20197;&#22823;&#22823;&#25552;&#39640;&#25311;&#21512;&#27169;&#22411;&#26102;&#26368;&#20449;&#24687;&#25968;&#25454;&#28857;&#30340;&#24314;&#35758;&#12290;&#20943;&#23569;&#27169;&#22411;&#24320;&#21457;&#25152;&#38656;&#30340;&#35266;&#27979;&#25968;&#25454;&#25968;&#37327;&#21487;&#20197;&#20943;&#36731;&#35757;&#32451;&#25152;&#38656;&#30340;&#35745;&#31639;&#36127;&#25285;&#21644;&#26631;&#35760;&#30456;&#20851;&#30340;&#25805;&#20316;&#25903;&#20986;&#12290;&#29305;&#21035;&#26159;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#65292;&#22312;&#38656;&#35201;&#22312;&#26497;&#30701;&#26102;&#38388;&#20869;&#20915;&#23450;&#26159;&#21542;&#33719;&#21462;&#25968;&#25454;&#28857;&#26631;&#35760;&#30340;&#39640;&#23481;&#37327;&#29983;&#20135;&#36807;&#31243;&#20013;&#38750;&#24120;&#26377;&#29992;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#26368;&#36817;&#33268;&#21147;&#20110;&#24320;&#21457;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#31574;&#30053;&#65292;&#20294;&#22312;&#23384;&#22312;&#24322;&#24120;&#20540;&#30340;&#24773;&#20917;&#19979;&#36825;&#20123;&#26041;&#27861;&#30340;&#34892;&#20026;&#20173;&#26410;&#24471;&#21040;&#24443;&#24213;&#30740;&#31350;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35843;&#26597;&#20102;&#22312;&#32447;&#20027;&#21160;&#32447;&#24615;&#22238;&#24402;&#22312;&#21463;&#27745;&#26579;&#30340;&#25968;&#25454;&#27969;&#20013;&#30340;&#24615;&#33021;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#26041;&#27861;&#65292;&#29992;&#20110;&#40065;&#26834;&#30340;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#65292;&#21516;&#26102;&#20445;&#35777;&#31283;&#23450;&#24615;&#24182;&#20943;&#23569;&#24322;&#24120;&#20540;&#30340;&#36127;&#38754;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
In many industrial applications, obtaining labeled observations is not straightforward as it often requires the intervention of human experts or the use of expensive testing equipment. In these circumstances, active learning can be highly beneficial in suggesting the most informative data points to be used when fitting a model. Reducing the number of observations needed for model development alleviates both the computational burden required for training and the operational expenses related to labeling. Online active learning, in particular, is useful in high-volume production processes where the decision about the acquisition of the label for a data point needs to be taken within an extremely short time frame. However, despite the recent efforts to develop online active learning strategies, the behavior of these methods in the presence of outliers has not been thoroughly examined. In this work, we investigate the performance of online active linear regression in contaminated data strea
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#21322;&#30417;&#30563;&#33258;&#32534;&#30721;&#22120;&#20197;&#21450;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#65292;&#20197;&#23613;&#21487;&#33021;&#23569;&#30340;&#26631;&#35760;&#26679;&#26412;&#26469;&#24320;&#21457;&#36719;&#27979;&#37327;&#20256;&#24863;&#22120;&#65292;&#20174;&#32780;&#26174;&#33879;&#38477;&#20302;&#20102;&#25104;&#26412;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#20316;&#32773;&#34920;&#26126;&#36825;&#31181;&#26041;&#27861;&#33021;&#22815;&#21462;&#24471;&#22909;&#30340;&#39044;&#27979;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2212.13067</link><description>&lt;p&gt;
&#20351;&#29992;&#21322;&#30417;&#30563;&#33258;&#32534;&#30721;&#22120;&#30340;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#36827;&#34892;&#36719;&#27979;&#37327;&#24320;&#21457;
&lt;/p&gt;
&lt;p&gt;
Online Active Learning for Soft Sensor Development using Semi-Supervised Autoencoders. (arXiv:2212.13067v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.13067
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#21322;&#30417;&#30563;&#33258;&#32534;&#30721;&#22120;&#20197;&#21450;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#65292;&#20197;&#23613;&#21487;&#33021;&#23569;&#30340;&#26631;&#35760;&#26679;&#26412;&#26469;&#24320;&#21457;&#36719;&#27979;&#37327;&#20256;&#24863;&#22120;&#65292;&#20174;&#32780;&#26174;&#33879;&#38477;&#20302;&#20102;&#25104;&#26412;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#20316;&#32773;&#34920;&#26126;&#36825;&#31181;&#26041;&#27861;&#33021;&#22815;&#21462;&#24471;&#22909;&#30340;&#39044;&#27979;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#39537;&#21160;&#30340;&#36719;&#27979;&#37327;&#22312;&#24037;&#19994;&#21644;&#21270;&#23398;&#36807;&#31243;&#20013;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#20197;&#39044;&#27979;&#38590;&#20197;&#27979;&#37327;&#30340;&#36807;&#31243;&#21464;&#37327;&#12290;&#36825;&#20123;&#20256;&#24863;&#22120;&#20351;&#29992;&#30340;&#22238;&#24402;&#27169;&#22411;&#36890;&#24120;&#38656;&#35201;&#22823;&#37327;&#26631;&#35760;&#30340;&#26679;&#26412;&#65292;&#28982;&#32780;&#65292;&#30001;&#20110;&#36136;&#37327;&#26816;&#26597;&#38656;&#35201;&#39640;&#26114;&#30340;&#26102;&#38388;&#21644;&#25104;&#26412;&#65292;&#33719;&#21462;&#26631;&#31614;&#20449;&#24687;&#21487;&#33021;&#38750;&#24120;&#26114;&#36149;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#21487;&#33021;&#38750;&#24120;&#26377;&#30410;&#65292;&#22240;&#20026;&#23427;&#20204;&#21487;&#20197;&#24314;&#35758;&#26597;&#35810;&#26368;&#20855;&#20449;&#24687;&#37327;&#30340;&#26631;&#31614;&#12290;&#28982;&#32780;&#65292;&#20026;&#22238;&#24402;&#25552;&#20986;&#30340;&#22823;&#22810;&#25968;&#20027;&#21160;&#23398;&#20064;&#31574;&#30053;&#37117;&#38598;&#20013;&#22312;&#31163;&#32447;&#22330;&#26223;&#12290;&#26412;&#25991;&#23558;&#20854;&#20013;&#19968;&#20123;&#26041;&#27861;&#36866;&#24212;&#20110;&#27969;&#24335;&#22330;&#26223;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#22522;&#20110;&#27491;&#20132;&#33258;&#32534;&#30721;&#22120;&#30340;&#21322;&#30417;&#30563;&#26550;&#26500;&#23398;&#20064;&#20302;&#32500;&#31354;&#38388;&#20013;&#30340;&#26174;&#33879;&#29305;&#24449;&#12290;&#25105;&#20204;&#20063;&#28436;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#30000;&#32435;&#35199;&#19996;&#26364;&#36807;&#31243;&#27604;&#36739;&#39044;&#27979;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data-driven soft sensors are extensively used in industrial and chemical processes to predict hard-to-measure process variables whose real value is difficult to track during routine operations. The regression models used by these sensors often require a large number of labeled examples, yet obtaining the label information can be very expensive given the high time and cost required by quality inspections. In this context, active learning methods can be highly beneficial as they can suggest the most informative labels to query. However, most of the active learning strategies proposed for regression focus on the offline setting. In this work, we adapt some of these approaches to the stream-based scenario and show how they can be used to select the most informative data points. We also demonstrate how to use a semi-supervised architecture based on orthogonal autoencoders to learn salient features in a lower dimensional space. The Tennessee Eastman Process is used to compare the predictive 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31163;&#32447;&#31574;&#30053;&#23398;&#20064;&#31639;&#27861;&#65292;&#23427;&#19981;&#38656;&#35201;&#32479;&#19968;&#20132;&#21472;&#20551;&#35774;&#65292;&#32780;&#26159;&#21033;&#29992;&#20215;&#20540;&#30340;&#19979;&#38480;&#32622;&#20449;&#21306;&#38388;&#65288;LCBs&#65289;&#20248;&#21270;&#31574;&#30053;&#65292;&#22240;&#27492;&#33021;&#22815;&#36866;&#24212;&#20801;&#35768;&#34892;&#20026;&#31574;&#30053;&#28436;&#21464;&#21644;&#20542;&#21521;&#24615;&#20943;&#24369;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2212.09900</link><description>&lt;p&gt;
&#26080;&#20132;&#21472;&#31574;&#30053;&#23398;&#20064;&#65306;&#24754;&#35266;&#21644;&#24191;&#20041;&#32463;&#39564;Bernstein&#19981;&#31561;&#24335;
&lt;/p&gt;
&lt;p&gt;
Policy learning "without'' overlap: Pessimism and generalized empirical Bernstein's inequality. (arXiv:2212.09900v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.09900
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31163;&#32447;&#31574;&#30053;&#23398;&#20064;&#31639;&#27861;&#65292;&#23427;&#19981;&#38656;&#35201;&#32479;&#19968;&#20132;&#21472;&#20551;&#35774;&#65292;&#32780;&#26159;&#21033;&#29992;&#20215;&#20540;&#30340;&#19979;&#38480;&#32622;&#20449;&#21306;&#38388;&#65288;LCBs&#65289;&#20248;&#21270;&#31574;&#30053;&#65292;&#22240;&#27492;&#33021;&#22815;&#36866;&#24212;&#20801;&#35768;&#34892;&#20026;&#31574;&#30053;&#28436;&#21464;&#21644;&#20542;&#21521;&#24615;&#20943;&#24369;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31163;&#32447;&#31574;&#30053;&#23398;&#20064;&#65292;&#26088;&#22312;&#21033;&#29992;&#20808;&#21069;&#25910;&#38598;&#21040;&#30340;&#35266;&#27979;&#65288;&#26469;&#33258;&#20110;&#22266;&#23450;&#30340;&#25110;&#26159;&#36866;&#24212;&#28436;&#21464;&#30340;&#34892;&#20026;&#31574;&#30053;&#65289;&#26469;&#23398;&#20064;&#32473;&#23450;&#31867;&#21035;&#20013;&#30340;&#26368;&#20248;&#20010;&#24615;&#21270;&#20915;&#31574;&#35268;&#21017;&#12290;&#29616;&#26377;&#30340;&#31574;&#30053;&#23398;&#20064;&#26041;&#27861;&#20381;&#36182;&#20110;&#19968;&#20010;&#32479;&#19968;&#20132;&#21472;&#20551;&#35774;&#65292;&#21363;&#31163;&#32447;&#25968;&#25454;&#38598;&#20013;&#25506;&#32034;&#25152;&#26377;&#20010;&#24615;&#21270;&#29305;&#24449;&#30340;&#25152;&#26377;&#21160;&#20316;&#30340;&#20542;&#21521;&#24615;&#19979;&#30028;&#12290;&#25442;&#21477;&#35805;&#35828;&#65292;&#36825;&#20123;&#26041;&#27861;&#30340;&#24615;&#33021;&#21462;&#20915;&#20110;&#31163;&#32447;&#25968;&#25454;&#38598;&#20013;&#26368;&#22351;&#30340;&#20542;&#21521;&#24615;&#12290;&#30001;&#20110;&#25968;&#25454;&#25910;&#38598;&#36807;&#31243;&#19981;&#21463;&#25511;&#21046;&#65292;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#36825;&#31181;&#20551;&#35774;&#21487;&#33021;&#19981;&#22826;&#29616;&#23454;&#65292;&#29305;&#21035;&#26159;&#24403;&#20801;&#35768;&#34892;&#20026;&#31574;&#30053;&#38543;&#26102;&#38388;&#28436;&#21464;&#24182;&#19988;&#20542;&#21521;&#24615;&#20943;&#24369;&#26102;&#12290;&#20026;&#27492;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#23427;&#20248;&#21270;&#31574;&#30053;&#20215;&#20540;&#30340;&#19979;&#38480;&#32622;&#20449;&#21306;&#38388;&#65288;LCBs&#65289;&#8212;&#8212;&#32780;&#19981;&#26159;&#28857;&#20272;&#35745;&#12290;LCBs&#36890;&#36807;&#37327;&#21270;&#22686;&#24378;&#20498;&#25968;&#20542;&#21521;&#26435;&#37325;&#30340;&#20272;&#35745;&#19981;&#30830;&#23450;&#24615;&#26469;&#26500;&#24314;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies offline policy learning, which aims at utilizing observations collected a priori (from either fixed or adaptively evolving behavior policies) to learn the optimal individualized decision rule in a given class. Existing policy learning methods rely on a uniform overlap assumption, i.e., the propensities of exploring all actions for all individual characteristics are lower bounded in the offline dataset. In other words, the performance of these methods depends on the worst-case propensity in the offline dataset. As one has no control over the data collection process, this assumption can be unrealistic in many situations, especially when the behavior policies are allowed to evolve over time with diminishing propensities.  In this paper, we propose a new algorithm that optimizes lower confidence bounds (LCBs) -- instead of point estimates -- of the policy values. The LCBs are constructed by quantifying the estimation uncertainty of the augmented inverse propensity weight
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#20010;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#65292;&#29992;&#20110;&#30452;&#25509;&#20174;&#35266;&#27979;&#36755;&#20837;&#21040;&#25152;&#38656;&#30340;&#20272;&#35745;&#22120;&#32479;&#35745;&#37327;&#23398;&#20064;&#36882;&#24402;&#26144;&#23556;&#65292;&#21487;&#20197;&#36817;&#20284;&#20272;&#35745;&#28508;&#22312;&#26102;&#38388;&#24207;&#21015;&#20449;&#21495;&#30340;&#26465;&#20214;&#32479;&#35745;&#37327;&#65292;&#22312;&#38750;&#32039;&#33268;&#22495;&#20013;&#26377;&#35823;&#24046;&#30028;&#38480;&#65292;&#22312;&#38271;&#26102;&#38388;&#19978;&#26377;&#33391;&#22909;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2211.00335</link><description>&lt;p&gt;
&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#21644;&#36125;&#21494;&#26031;&#28388;&#27874;&#22120;&#30340;&#36890;&#29992;&#36924;&#36817;&#24615;
&lt;/p&gt;
&lt;p&gt;
Recurrent Neural Networks and Universal Approximation of Bayesian Filters. (arXiv:2211.00335v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.00335
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#20010;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#65292;&#29992;&#20110;&#30452;&#25509;&#20174;&#35266;&#27979;&#36755;&#20837;&#21040;&#25152;&#38656;&#30340;&#20272;&#35745;&#22120;&#32479;&#35745;&#37327;&#23398;&#20064;&#36882;&#24402;&#26144;&#23556;&#65292;&#21487;&#20197;&#36817;&#20284;&#20272;&#35745;&#28508;&#22312;&#26102;&#38388;&#24207;&#21015;&#20449;&#21495;&#30340;&#26465;&#20214;&#32479;&#35745;&#37327;&#65292;&#22312;&#38750;&#32039;&#33268;&#22495;&#20013;&#26377;&#35823;&#24046;&#30028;&#38480;&#65292;&#22312;&#38271;&#26102;&#38388;&#19978;&#26377;&#33391;&#22909;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#36125;&#21494;&#26031;&#26368;&#20248;&#28388;&#27874;&#38382;&#39064;&#65292;&#21363;&#20174;&#35266;&#27979;&#24207;&#21015;&#20013;&#20272;&#35745;&#28508;&#22312;&#26102;&#38388;&#24207;&#21015;&#20449;&#21495;&#30340;&#26465;&#20214;&#32479;&#35745;&#37327;&#12290;&#20256;&#32479;&#26041;&#27861;&#36890;&#24120;&#20381;&#36182;&#20110;&#20551;&#23450;&#25110;&#20272;&#35745;&#30340;&#36716;&#31227;&#21644;&#35266;&#27979;&#27169;&#22411;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#21046;&#23450;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#65292;&#24182;&#35797;&#22270;&#30452;&#25509;&#20174;&#35266;&#27979;&#36755;&#20837;&#21040;&#25152;&#38656;&#30340;&#20272;&#35745;&#22120;&#32479;&#35745;&#37327;&#23398;&#20064;&#36882;&#24402;&#26144;&#23556;&#12290;&#26412;&#25991;&#30340;&#37325;&#28857;&#26159;&#27492;&#26694;&#26550;&#30340;&#36924;&#36817;&#33021;&#21147;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#33324;&#38750;&#32039;&#33268;&#22495;&#30340;&#28388;&#27874;&#36924;&#36817;&#35823;&#24046;&#30028;&#38480;&#12290;&#25105;&#20204;&#36824;&#32771;&#34385;&#20102;&#24378;&#26102;&#38388;&#19968;&#33268;&#30340;&#36924;&#36817;&#35823;&#24046;&#30028;&#38480;&#65292;&#20445;&#35777;&#33391;&#22909;&#30340;&#38271;&#26399;&#24615;&#33021;&#12290;&#25105;&#20204;&#35752;&#35770;&#21644;&#35828;&#26126;&#20102;&#36825;&#20123;&#32467;&#26524;&#30340;&#35768;&#22810;&#23454;&#38469;&#20851;&#27880;&#28857;&#21644;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the Bayesian optimal filtering problem: i.e. estimating some conditional statistics of a latent time-series signal from an observation sequence. Classical approaches often rely on the use of assumed or estimated transition and observation models. Instead, we formulate a generic recurrent neural network framework and seek to learn directly a recursive mapping from observational inputs to the desired estimator statistics. The main focus of this article is the approximation capabilities of this framework. We provide approximation error bounds for filtering in general non-compact domains. We also consider strong time-uniform approximation error bounds that guarantee good long-time performance. We discuss and illustrate a number of practical concerns and implications of these results.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#36880;&#27493;&#35745;&#31639;&#26816;&#27979;&#32479;&#35745;&#37327;&#30340;&#32047;&#31215;&#21644;&#26469;&#26816;&#27979;&#21464;&#28857;&#65292;&#24182;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#19978;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#21644;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2210.17312</link><description>&lt;p&gt;
&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#26102;&#24207;&#21464;&#28857;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Training Neural Networks for Sequential Change-point Detection. (arXiv:2210.17312v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.17312
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#36880;&#27493;&#35745;&#31639;&#26816;&#27979;&#32479;&#35745;&#37327;&#30340;&#32047;&#31215;&#21644;&#26469;&#26816;&#27979;&#21464;&#28857;&#65292;&#24182;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#19978;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#21644;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26816;&#27979;&#25968;&#25454;&#27969;&#20013;&#30340;&#31361;&#21464;&#20998;&#24067;&#36716;&#25442;&#65292;&#21363;&#25152;&#35859;&#30340;&#21464;&#28857;&#26816;&#27979;&#65292;&#26159;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#26469;&#36880;&#27493;&#35745;&#31639;&#26816;&#27979;&#32479;&#35745;&#37327;&#30340;&#32047;&#31215;&#21644;&#65292;&#24403;&#21457;&#29983;&#21464;&#28857;&#26102;&#65292;&#35813;&#37327;&#20250;&#26174;&#33879;&#21464;&#21270;&#12290;&#25105;&#20204;&#20351;&#29992;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#26816;&#27979;&#21464;&#28857;&#26041;&#38754;&#30340;&#20248;&#36234;&#24615;&#21644;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Detecting an abrupt distributional shift of a data stream, known as change-point detection, is a fundamental problem in statistics and machine learning. We introduce a novel approach for online change-point detection using neural networks. To be specific, our approach is training neural networks to compute the cumulative sum of a detection statistic sequentially, which exhibits a significant change when a change-point occurs. We demonstrated the superiority and potential of the proposed method in detecting change-point using both synthetic and real-world data.
&lt;/p&gt;</description></item><item><title>G2&#26159;&#19968;&#31181;&#21033;&#29992;&#26799;&#24230;&#38376;&#25511;&#26426;&#21046;&#30340;&#26032;&#22411;GNN&#26694;&#26550;&#65292;&#21487;&#32531;&#35299;&#36807;&#24230;&#24179;&#28369;&#38382;&#39064;&#65292;&#24182;&#23454;&#29616;&#20102;&#21508;&#31181;&#22270;&#23398;&#20064;&#20219;&#21153;&#19978;&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2210.00513</link><description>&lt;p&gt;
&#22522;&#20110;&#26799;&#24230;&#38376;&#25511;&#26426;&#21046;&#30340;&#22270;&#28145;&#24230;&#22810;&#36895;&#29575;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Gradient Gating for Deep Multi-Rate Learning on Graphs. (arXiv:2210.00513v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.00513
&lt;/p&gt;
&lt;p&gt;
G2&#26159;&#19968;&#31181;&#21033;&#29992;&#26799;&#24230;&#38376;&#25511;&#26426;&#21046;&#30340;&#26032;&#22411;GNN&#26694;&#26550;&#65292;&#21487;&#32531;&#35299;&#36807;&#24230;&#24179;&#28369;&#38382;&#39064;&#65292;&#24182;&#23454;&#29616;&#20102;&#21508;&#31181;&#22270;&#23398;&#20064;&#20219;&#21153;&#19978;&#30340;&#26368;&#20808;&#36827;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; Gradient Gating (G$^2$) &#30340;&#26032;&#22411;&#26694;&#26550;&#65292;&#26088;&#22312;&#25913;&#21892;&#22270;&#31070;&#32463;&#32593;&#32476; (GNNs) &#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#22522;&#20110;&#23545; GNN &#23618;&#30340;&#36755;&#20986;&#36827;&#34892;&#38376;&#25511;&#65292;&#20854;&#20013;&#21253;&#21547;&#20102;&#19968;&#31181;&#36328;&#26412;&#36136;&#22270;&#33410;&#28857;&#30340;&#28040;&#24687;&#20256;&#36882;&#20449;&#24687;&#30340;&#22810;&#36895;&#29575;&#27969;&#26426;&#21046;&#12290;&#26412;&#22320;&#26799;&#24230;&#34987;&#21033;&#29992;&#26469;&#36827;&#19968;&#27493;&#35843;&#21046;&#28040;&#24687;&#20256;&#36882;&#30340;&#26356;&#26032;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#28789;&#27963;&#22320;&#20801;&#35768;&#20351;&#29992;&#20219;&#20309;&#22522;&#26412;&#30340; GNN &#23618;&#20316;&#20026;&#21253;&#35013;&#22120;&#65292;&#20197;&#26500;&#24314;&#22810;&#36895;&#29575;&#26799;&#24230;&#38376;&#25511;&#26426;&#21046;&#12290;&#25105;&#20204;&#20005;&#26684;&#35777;&#26126; G$^2$ &#32531;&#35299;&#20102;&#36807;&#24230;&#24179;&#28369;&#38382;&#39064;&#65292;&#24182;&#20801;&#35768;&#35774;&#35745;&#28145;&#24230; GNNs&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#23454;&#35777;&#32467;&#26524;&#65292;&#35777;&#26126;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#22312;&#21508;&#31181;&#22270;&#23398;&#20064;&#20219;&#21153;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#21253;&#25324;&#22823;&#35268;&#27169;&#24322;&#36136;&#22270;&#19978;&#30340;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present Gradient Gating (G$^2$), a novel framework for improving the performance of Graph Neural Networks (GNNs). Our framework is based on gating the output of GNN layers with a mechanism for multi-rate flow of message passing information across nodes of the underlying graph. Local gradients are harnessed to further modulate message passing updates. Our framework flexibly allows one to use any basic GNN layer as a wrapper around which the multi-rate gradient gating mechanism is built. We rigorously prove that G$^2$ alleviates the oversmoothing problem and allows the design of deep GNNs. Empirical results are presented to demonstrate that the proposed framework achieves state-of-the-art performance on a variety of graph learning tasks, including on large-scale heterophilic graphs.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#24191;&#20041;&#26680;&#27491;&#21017;&#21270;&#26368;&#23567;&#20108;&#20056;&#27861; (gKRLS)&#65292;&#35299;&#20915;&#20102;&#26680;&#27491;&#21017;&#21270;&#26368;&#23567;&#20108;&#20056;&#27861; (KRLS) &#22312;&#24403;&#21069;&#20351;&#29992;&#20013;&#30340;&#20004;&#20010;&#38480;&#21046;&#65306;&#23427;&#30340;&#25193;&#23637;&#33021;&#21147;&#19981;&#36275;&#65292;&#19988;&#21363;&#20351;&#22312;&#23567;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#65292;&#20854;&#35745;&#31639;&#20195;&#20215;&#20063;&#38750;&#24120;&#39640;&#26114;&#12290;</title><link>http://arxiv.org/abs/2209.14355</link><description>&lt;p&gt;
&#24191;&#20041;&#26680;&#27491;&#21017;&#21270;&#26368;&#23567;&#20108;&#20056;&#27861;
&lt;/p&gt;
&lt;p&gt;
Generalized Kernel Regularized Least Squares. (arXiv:2209.14355v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.14355
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#24191;&#20041;&#26680;&#27491;&#21017;&#21270;&#26368;&#23567;&#20108;&#20056;&#27861; (gKRLS)&#65292;&#35299;&#20915;&#20102;&#26680;&#27491;&#21017;&#21270;&#26368;&#23567;&#20108;&#20056;&#27861; (KRLS) &#22312;&#24403;&#21069;&#20351;&#29992;&#20013;&#30340;&#20004;&#20010;&#38480;&#21046;&#65306;&#23427;&#30340;&#25193;&#23637;&#33021;&#21147;&#19981;&#36275;&#65292;&#19988;&#21363;&#20351;&#22312;&#23567;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#65292;&#20854;&#35745;&#31639;&#20195;&#20215;&#20063;&#38750;&#24120;&#39640;&#26114;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26680;&#27491;&#21017;&#21270;&#26368;&#23567;&#20108;&#20056;&#27861; (KRLS) &#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#28789;&#27963;&#22320;&#20272;&#35745;&#20855;&#26377;&#22797;&#26434;&#21464;&#37327;&#20851;&#31995;&#30340;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#20854;&#21487;&#29992;&#24615;&#22240;&#20004;&#20010;&#21407;&#22240;&#32780;&#21463;&#21040;&#35768;&#22810;&#30740;&#31350;&#20154;&#21592;&#30340;&#38480;&#21046;&#12290;&#39318;&#20808;&#65292;&#29616;&#26377;&#26041;&#27861;&#32570;&#20047;&#28789;&#27963;&#24615;&#65292;&#19981;&#20801;&#35768;&#23558;KRLS&#19982;&#29702;&#35770;&#21160;&#26426;&#19979;&#30340;&#25193;&#23637;&#22914;&#38543;&#26426;&#25928;&#24212;&#12289;&#26410;&#32463;&#27491;&#21017;&#21270;&#30340;&#22266;&#23450;&#25928;&#24212;&#25110;&#38750;&#39640;&#26031;&#32467;&#26524;&#32452;&#21512;&#20351;&#29992;&#12290;&#20854;&#27425;&#65292;&#21363;&#20351;&#26159;&#35268;&#27169;&#36739;&#23567;&#30340;&#25968;&#25454;&#38598;&#65292;&#20272;&#35745;&#20063;&#38750;&#24120;&#35745;&#31639;&#23494;&#38598;&#12290;&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#24191;&#20041;KRLS (gKRLS) &#26469;&#35299;&#20915;&#36825;&#20004;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#25351;&#20986;&#65292;KRLS&#21487;&#20197;&#37325;&#26032;&#35774;&#23450;&#20026;&#20998;&#23618;&#27169;&#22411;&#65292;&#20174;&#32780;&#20801;&#35768;&#36731;&#26494;&#25512;&#29702;&#21644;&#27169;&#22359;&#21270;&#27169;&#22411;&#26500;&#24314;&#65292;&#22312;&#20854;&#20013;KRLS&#21487;&#20197;&#19982;&#38543;&#26426;&#25928;&#24212;&#12289;&#26679;&#26465;&#21644;&#26410;&#32463;&#27491;&#21017;&#21270;&#30340;&#22266;&#23450;&#25928;&#24212;&#24182;&#29992;&#12290;&#22312;&#35745;&#31639;&#26041;&#38754;&#65292;&#25105;&#20204;&#36824;&#23454;&#29616;&#20102;&#38543;&#26426;&#33609;&#22270;&#26041;&#27861;&#65292;&#20197;&#26497;&#22823;&#22320;&#21152;&#36895;&#20272;&#35745;&#65292;&#24182;&#22312;&#20272;&#35745;&#36136;&#37327;&#19978;&#25215;&#25285;&#26377;&#38480;&#30340;&#24809;&#32602;&#12290;&#25105;&#20204;&#35777;&#26126;gKRLS&#21487;&#36866;&#29992;&#20110;&#20855;&#26377;&#22823;&#37327;&#26679;&#26412;&#30340;&#25968;&#25454;&#38598;&#30340;&#25311;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Kernel Regularized Least Squares (KRLS) is a popular method for flexibly estimating models that may have complex relationships between variables. However, its usefulness to many researchers is limited for two reasons. First, existing approaches are inflexible and do not allow KRLS to be combined with theoretically-motivated extensions such as random effects, unregularized fixed effects, or non-Gaussian outcomes. Second, estimation is extremely computationally intensive for even modestly sized datasets. Our paper addresses both concerns by introducing generalized KRLS (gKRLS). We note that KRLS can be re-formulated as a hierarchical model thereby allowing easy inference and modular model construction where KRLS can be used alongside random effects, splines, and unregularized fixed effects. Computationally, we also implement random sketching to dramatically accelerate estimation while incurring a limited penalty in estimation quality. We demonstrate that gKRLS can be fit on datasets with
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#24403;&#32593;&#32476;&#20013;&#23384;&#22312;&#19981;&#21305;&#37197;/&#26631;&#31614;&#28151;&#20081;&#30340;&#39030;&#28857;&#26102;&#65292;&#20004;&#20010;&#26679;&#26412;&#22270;&#20551;&#35774;&#26816;&#39564;&#20013;&#30340;&#21151;&#29575;&#25439;&#22833;&#65292;&#24182;&#36890;&#36807;&#22810;&#20010;&#23454;&#39564;&#21152;&#20197;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2208.08638</link><description>&lt;p&gt;
&#22312;&#38169;&#35823;&#26631;&#35760;&#30340;&#32593;&#32476;&#39030;&#28857;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#21151;&#32791;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
Lost in the Shuffle: Testing Power in the Presence of Errorful Network Vertex Labels. (arXiv:2208.08638v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.08638
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#24403;&#32593;&#32476;&#20013;&#23384;&#22312;&#19981;&#21305;&#37197;/&#26631;&#31614;&#28151;&#20081;&#30340;&#39030;&#28857;&#26102;&#65292;&#20004;&#20010;&#26679;&#26412;&#22270;&#20551;&#35774;&#26816;&#39564;&#20013;&#30340;&#21151;&#29575;&#25439;&#22833;&#65292;&#24182;&#36890;&#36807;&#22810;&#20010;&#23454;&#39564;&#21152;&#20197;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#20004;&#20010;&#26679;&#26412;&#30340;&#32593;&#32476;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#37117;&#26159;&#22312;&#39030;&#28857;&#23545;&#24212;&#22312;&#32593;&#32476;&#20043;&#38388;&#30340;&#38544;&#21547;&#20551;&#35774;&#19979;&#36816;&#34892;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#24403;&#32593;&#32476;&#20013;&#23384;&#22312;&#19981;&#21305;&#37197;/&#26631;&#31614;&#28151;&#20081;&#30340;&#39030;&#28857;&#26102;&#65292;&#20004;&#20010;&#26679;&#26412;&#22270;&#20551;&#35774;&#26816;&#39564;&#20013;&#30340;&#21151;&#29575;&#25439;&#22833;&#12290;&#22312;&#38543;&#26426;&#28857;&#20056;&#31215;&#21644;&#38543;&#26426;&#22359;&#27169;&#22411;&#32593;&#32476;&#30340;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#25506;&#35752;&#20102;&#30001;&#20110;&#28151;&#27927;&#23545;&#22522;&#20110;&#20272;&#35745;&#30340;&#36793;&#32536;&#27010;&#29575;&#30697;&#38453;&#25110;&#37051;&#25509;&#30697;&#38453;&#20043;&#38388;&#30340;Frobenius&#33539;&#25968;&#24046;&#24322;&#30340;&#19968;&#23545;&#20551;&#35774;&#26816;&#39564;&#30340;&#21151;&#29575;&#25439;&#22833;&#12290;&#21151;&#32791;&#27979;&#35797;&#30340;&#25439;&#22833;&#36890;&#36807;&#20247;&#22810;&#27169;&#25311;&#21644;&#23454;&#39564;&#36827;&#19968;&#27493;&#21152;&#24378;&#65292;&#22312;&#25991;&#29486;&#20013;&#27604;&#36739;&#20102;&#22810;&#20010;&#26368;&#36817;&#25552;&#20986;&#30340;&#27979;&#35797;&#20013;&#30340;&#21151;&#29575;&#25439;&#22833;&#65292;&#22312;&#38543;&#26426;&#22359;&#27169;&#22411;&#21644;&#38543;&#26426;&#28857;&#20056;&#31215;&#22270;&#27169;&#22411;&#20013;&#22343;&#26377;&#20307;&#29616;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#26469;&#33258;&#31070;&#32463;&#31185;&#23398;&#21644;&#31038;&#20132;&#32593;&#32476;&#20998;&#26512;&#30340;&#20004;&#20010;&#20363;&#23376;&#23637;&#31034;&#20102;&#28151;&#27927;&#21487;&#33021;&#23545;&#30495;&#23454;&#25968;&#25454;&#27979;&#35797;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many two-sample network hypothesis testing methodologies operate under the implicit assumption that the vertex correspondence across networks is a priori known. In this paper, we consider the degradation of power in two-sample graph hypothesis testing when there are misaligned/label-shuffled vertices across networks. In the context of random dot product and stochastic block model networks, we theoretically explore the power loss due to shuffling for a pair of hypothesis tests based on Frobenius norm differences between estimated edge probability matrices or between adjacency matrices. The loss in testing power is further reinforced by numerous simulations and experiments, both in the stochastic block model and in the random dot product graph model, where we compare the power loss across multiple recently proposed tests in the literature. Lastly, we demonstrate the impact that shuffling can have in real-data testing in a pair of examples from neuroscience and from social network analysi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27010;&#29575;&#35745;&#25968;&#26102;&#38388;&#24207;&#21015;&#35843;&#21644;&#26041;&#27861;&#65292;&#20135;&#29983;&#21327;&#35843;&#30340;&#27010;&#29575;&#36136;&#37327;&#20989;&#25968;&#65292;&#30456;&#27604;&#20110;&#27010;&#29575;&#39640;&#26031;&#35843;&#21644;&#65292;&#33021;&#22815;&#24102;&#26469;&#26174;&#33879;&#30340;&#39044;&#27979;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2207.09322</link><description>&lt;p&gt;
&#35745;&#25968;&#26102;&#38388;&#24207;&#21015;&#30340;&#27010;&#29575;&#35843;&#21644;
&lt;/p&gt;
&lt;p&gt;
Probabilistic Reconciliation of Count Time Series. (arXiv:2207.09322v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.09322
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27010;&#29575;&#35745;&#25968;&#26102;&#38388;&#24207;&#21015;&#35843;&#21644;&#26041;&#27861;&#65292;&#20135;&#29983;&#21327;&#35843;&#30340;&#27010;&#29575;&#36136;&#37327;&#20989;&#25968;&#65292;&#30456;&#27604;&#20110;&#27010;&#29575;&#39640;&#26031;&#35843;&#21644;&#65292;&#33021;&#22815;&#24102;&#26469;&#26174;&#33879;&#30340;&#39044;&#27979;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#27979;&#35843;&#21644;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#30740;&#31350;&#35838;&#39064;&#65292;&#20294;&#30446;&#21069;&#26082;&#27809;&#26377;&#24418;&#24335;&#21270;&#30340;&#26694;&#26550;&#65292;&#20063;&#27809;&#26377;&#38024;&#23545;&#27010;&#29575;&#35745;&#25968;&#26102;&#38388;&#24207;&#21015;&#35843;&#21644;&#30340;&#23454;&#29992;&#26041;&#27861;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#23454;&#20540;&#21644;&#35745;&#25968;&#21464;&#37327;&#30340;&#36830;&#36143;&#24615;&#21644;&#21327;&#35843;&#30340;&#27010;&#29575;&#39044;&#27979;&#23450;&#20041;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27010;&#29575;&#21327;&#35843;&#26041;&#27861;&#12290;&#23427;&#26159;&#22522;&#20110;&#36125;&#21494;&#26031;&#35268;&#21017;&#30340;&#27010;&#25324;&#65292;&#24182;&#19988;&#21487;&#20197;&#21327;&#35843;&#23454;&#25968;&#21644;&#35745;&#25968;&#21464;&#37327;&#12290;&#24403;&#29992;&#20110;&#35745;&#25968;&#21464;&#37327;&#26102;&#65292;&#23427;&#20250;&#20135;&#29983;&#21327;&#35843;&#30340;&#27010;&#29575;&#36136;&#37327;&#20989;&#25968;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#35745;&#25968;&#21464;&#37327;&#30340;&#26102;&#38388;&#21327;&#35843;&#23454;&#39564;&#34920;&#26126;&#65292;&#19982;&#27010;&#29575;&#39640;&#26031;&#35843;&#21644;&#30456;&#27604;&#65292;&#23427;&#23545;&#39044;&#27979;&#30340;&#25913;&#36827;&#38750;&#24120;&#22823;&#12290;
&lt;/p&gt;
&lt;p&gt;
Forecast reconciliation is an important research topic. Yet, there is currently neither formal framework nor practical method for the probabilistic reconciliation of count time series. In this paper we propose a definition of coherency and reconciled probabilistic forecast which applies to both real-valued and count variables and a novel method for probabilistic reconciliation. It is based on a generalization of Bayes' rule and it can reconcile both real-value and count variables. When applied to count variables, it yields a reconciled probability mass function. Our experiments with the temporal reconciliation of count variables show a major forecast improvement compared to the probabilistic Gaussian reconciliation.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;GAMI-Tree&#65292;&#20351;&#29992;&#22522;&#20110;&#27169;&#22411;&#30340;&#26641;&#20197;&#21450;&#26032;&#30340;&#20132;&#20114;&#36807;&#28388;&#26041;&#27861;&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#25311;&#21512;&#24213;&#23618;&#20132;&#20114;&#65292;&#20855;&#26377;&#26356;&#22909;&#30340;&#39044;&#27979;&#24615;&#33021;&#21644;&#26356;&#39640;&#30340;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2207.06950</link><description>&lt;p&gt;
&#20351;&#29992;&#22522;&#20110;&#27169;&#22411;&#30340;&#26641;&#21644;&#25552;&#21319;&#26041;&#27861;&#25311;&#21512;&#20302;&#38454;&#20989;&#25968;ANOVA&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Using Model-Based Trees with Boosting to Fit Low-Order Functional ANOVA Models. (arXiv:2207.06950v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.06950
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;GAMI-Tree&#65292;&#20351;&#29992;&#22522;&#20110;&#27169;&#22411;&#30340;&#26641;&#20197;&#21450;&#26032;&#30340;&#20132;&#20114;&#36807;&#28388;&#26041;&#27861;&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#25311;&#21512;&#24213;&#23618;&#20132;&#20114;&#65292;&#20855;&#26377;&#26356;&#22909;&#30340;&#39044;&#27979;&#24615;&#33021;&#21644;&#26356;&#39640;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20302;&#38454;&#20989;&#25968;ANOVA&#27169;&#22411;&#24050;&#32463;&#34987;&#26426;&#22120;&#23398;&#20064;&#31038;&#21306;&#37325;&#26032;&#21457;&#29616;&#65292;&#24182;&#31216;&#20043;&#20026;&#20869;&#22312;&#21487;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;GAMI-Tree&#65292;&#31867;&#20284;&#20110;EBM&#65292;&#20294;&#20855;&#26377;&#19968;&#20123;&#36235;&#21521;&#26356;&#22909;&#24615;&#33021;&#30340;&#29305;&#24615;&#12290;&#25105;&#20204;&#37319;&#29992;&#27169;&#22411;&#20026;&#22522;&#30784;&#30340;&#26641;&#65292;&#24182;&#34701;&#20837;&#19968;&#31181;&#26032;&#30340;&#20132;&#20114;&#36807;&#28388;&#26041;&#27861;&#65292;&#25552;&#39640;&#20102;&#23545;&#24213;&#23618;&#20132;&#20114;&#30340;&#25429;&#25417;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#36845;&#20195;&#35757;&#32451;&#26041;&#27861;&#25910;&#25947;&#20110;&#20855;&#26377;&#26356;&#22909;&#39044;&#27979;&#24615;&#33021;&#30340;&#27169;&#22411;&#65292;&#24182;&#30830;&#20445;&#30456;&#20114;&#20316;&#29992;&#22312;&#20998;&#23618;&#24847;&#20041;&#19978;&#27491;&#20132;&#20110;&#20027;&#25928;&#24212;&#12290;&#35813;&#31639;&#27861;&#19981;&#38656;&#35201;&#24191;&#27867;&#30340;&#35843;&#25972;&#65292;&#24182;&#19988;&#23454;&#29616;&#24555;&#36895;&#39640;&#25928;&#12290;&#25105;&#20204;&#20351;&#29992;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Low-order functional ANOVA (fANOVA) models have been rediscovered in the machine learning (ML) community under the guise of inherently interpretable machine learning. Explainable Boosting Machines or EBM (Lou et al. 2013) and GAMI-Net (Yang et al. 2021) are two recently proposed ML algorithms for fitting functional main effects and second-order interactions. We propose a new algorithm, called GAMI-Tree, that is similar to EBM, but has a number of features that lead to better performance. It uses model-based trees as base learners and incorporates a new interaction filtering method that is better at capturing the underlying interactions. In addition, our iterative training method converges to a model with better predictive performance, and the embedded purification ensures that interactions are hierarchically orthogonal to main effects. The algorithm does not need extensive tuning, and our implementation is fast and efficient. We use simulated and real datasets to compare the performanc
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#20462;&#25913;&#36807;&#30340;&#39532;&#36420;&#34444;&#20808;&#39564;&#30340;&#22810;&#35270;&#35282;&#28508;&#21464;&#37327;&#27169;&#22411;MuVI&#65292;&#29992;&#20110;&#24314;&#27169;&#32467;&#26500;&#31232;&#30095;&#24615;&#12290;&#23427;&#33021;&#22815;&#32435;&#20837;&#26377;&#38480;&#19988;&#22122;&#22768;&#30340;&#39046;&#22495;&#30693;&#35782;&#65292;&#20197;&#20869;&#22312;&#21487;&#35299;&#37322;&#30340;&#26041;&#24335;&#20998;&#26512;&#22810;&#35270;&#35282;&#25968;&#25454;&#65292;&#20248;&#20110;&#29616;&#26377;&#32467;&#26500;&#31232;&#30095;&#24615;&#24314;&#27169;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2204.06242</link><description>&lt;p&gt;
&#22810;&#35270;&#35282;&#28508;&#21464;&#37327;&#27169;&#22411;&#20013;&#30340;&#39046;&#22495;&#30693;&#35782;&#32534;&#30721;:&#24102;&#32467;&#26500;&#31232;&#30095;&#36125;&#21494;&#26031;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Encoding Domain Knowledge in Multi-view Latent Variable Models: A Bayesian Approach with Structured Sparsity. (arXiv:2204.06242v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.06242
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#20462;&#25913;&#36807;&#30340;&#39532;&#36420;&#34444;&#20808;&#39564;&#30340;&#22810;&#35270;&#35282;&#28508;&#21464;&#37327;&#27169;&#22411;MuVI&#65292;&#29992;&#20110;&#24314;&#27169;&#32467;&#26500;&#31232;&#30095;&#24615;&#12290;&#23427;&#33021;&#22815;&#32435;&#20837;&#26377;&#38480;&#19988;&#22122;&#22768;&#30340;&#39046;&#22495;&#30693;&#35782;&#65292;&#20197;&#20869;&#22312;&#21487;&#35299;&#37322;&#30340;&#26041;&#24335;&#20998;&#26512;&#22810;&#35270;&#35282;&#25968;&#25454;&#65292;&#20248;&#20110;&#29616;&#26377;&#32467;&#26500;&#31232;&#30095;&#24615;&#24314;&#27169;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#29616;&#23454;&#19990;&#30028;&#30340;&#31995;&#32479;&#19981;&#20165;&#26377;&#26469;&#33258;&#21333;&#20010;&#25968;&#25454;&#28304;&#30340;&#25968;&#25454;&#65292;&#36824;&#26377;&#26469;&#33258;&#22810;&#20010;&#25968;&#25454;&#35270;&#35282;&#30340;&#25968;&#25454;&#12290;&#20363;&#22914;&#65292;&#22312;&#22522;&#22240;&#32452;&#21307;&#23398;&#20013;&#65292;&#24739;&#32773;&#21487;&#20197;&#36890;&#36807;&#26469;&#33258;&#19981;&#21516;&#20998;&#23376;&#23618;&#38754;&#30340;&#25968;&#25454;&#36827;&#34892;&#25551;&#36848;&#12290;&#21033;&#29992;&#20855;&#26377;&#32467;&#26500;&#31232;&#30095;&#24615;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#26159;&#25581;&#31034;&#25968;&#25454;&#35270;&#35282;&#20869;&#21644;&#36328;&#35270;&#35282;&#21464;&#21270;&#30340;&#24120;&#29992;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#21487;&#35299;&#37322;&#24615;&#36739;&#24046;&#65292;&#38656;&#35201;&#19987;&#23478;&#30452;&#25509;&#26816;&#26597;&#21644;&#35299;&#37322;&#27599;&#20010;&#35201;&#32032;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;MuVI&#65292;&#19968;&#31181;&#22522;&#20110;&#20462;&#25913;&#36807;&#30340;&#39532;&#36420;&#34444;&#20808;&#39564;&#30340;&#26032;&#22411;&#22810;&#35270;&#35282;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#29992;&#20110;&#24314;&#27169;&#32467;&#26500;&#31232;&#30095;&#24615;&#12290;&#36825;&#26377;&#21161;&#20110;&#23545;&#26377;&#38480;&#30340;&#21644;&#22122;&#22768;&#39046;&#22495;&#30693;&#35782;&#36827;&#34892;&#32435;&#20837;&#65292;&#20174;&#32780;&#20197;&#20869;&#22312;&#21487;&#35299;&#37322;&#30340;&#26041;&#24335;&#20998;&#26512;&#22810;&#35270;&#35282;&#25968;&#25454;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#37325;&#24314;&#35823;&#24046;&#21644;&#31934;&#30830;&#24230;/&#21484;&#22238;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#30340;&#32467;&#26500;&#31232;&#30095;&#24615;&#24314;&#27169;&#26041;&#27861;&#65292;&#24182;&#19988;&#21487;&#20197;&#31283;&#20581;&#22320;&#25972;&#21512;&#22122;&#22768;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many real-world systems are described not only by data from a single source but via multiple data views. In genomic medicine, for instance, patients can be characterized by data from different molecular layers. Latent variable models with structured sparsity are a commonly used tool for disentangling variation within and across data views. However, their interpretability is cumbersome since it requires a direct inspection and interpretation of each factor from domain experts. Here, we propose MuVI, a novel multi-view latent variable model based on a modified horseshoe prior for modeling structured sparsity. This facilitates the incorporation of limited and noisy domain knowledge, thereby allowing for an analysis of multi-view data in an inherently explainable manner. We demonstrate that our model (i) outperforms state-of-the-art approaches for modeling structured sparsity in terms of the reconstruction error and the precision/recall, (ii) robustly integrates noisy domain expertise in t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#30340;&#20855;&#26377;&#24377;&#24615;&#30340;&#26080;&#32447;&#30005;&#36164;&#28304;&#31649;&#29702;&#31574;&#30053;&#65292;&#20197;&#23454;&#29616;&#39640;&#32858;&#21512;&#36895;&#29575;&#24182;&#30830;&#20445;&#25152;&#26377;&#29992;&#25143;&#30340;&#20844;&#24179;&#24615;&#65292;&#24182;&#20351;&#29992;&#21487;&#25193;&#23637;&#30340;&#32622;&#25442;&#31561;&#21464;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#26550;&#26500;&#22522;&#20110;&#30636;&#26102;&#20449;&#36947;&#26465;&#20214;&#25512;&#23548;&#20986;&#30340;&#22270;&#24418;&#25299;&#25169;&#26469;&#21442;&#25968;&#21270;RRM&#31574;&#30053;</title><link>http://arxiv.org/abs/2203.11012</link><description>&lt;p&gt;
&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#20855;&#26377;&#24377;&#24615;&#30340;&#26080;&#32447;&#30005;&#36164;&#28304;&#31649;&#29702;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Learning Resilient Radio Resource Management Policies with Graph Neural Networks. (arXiv:2203.11012v2 [eess.SP] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.11012
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#30340;&#20855;&#26377;&#24377;&#24615;&#30340;&#26080;&#32447;&#30005;&#36164;&#28304;&#31649;&#29702;&#31574;&#30053;&#65292;&#20197;&#23454;&#29616;&#39640;&#32858;&#21512;&#36895;&#29575;&#24182;&#30830;&#20445;&#25152;&#26377;&#29992;&#25143;&#30340;&#20844;&#24179;&#24615;&#65292;&#24182;&#20351;&#29992;&#21487;&#25193;&#23637;&#30340;&#32622;&#25442;&#31561;&#21464;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#26550;&#26500;&#22522;&#20110;&#30636;&#26102;&#20449;&#36947;&#26465;&#20214;&#25512;&#23548;&#20986;&#30340;&#22270;&#24418;&#25299;&#25169;&#26469;&#21442;&#25968;&#21270;RRM&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#22312;&#21253;&#21547;&#22810;&#20010;&#25509;&#20837;&#28857;&#21644;&#19968;&#32452;&#29992;&#25143;&#35774;&#22791;&#30340;&#26080;&#32447;&#24178;&#25200;&#32593;&#32476;&#20013;&#65292;&#23454;&#29616;&#29992;&#25143;&#36873;&#25321;&#21644;&#21151;&#29575;&#25511;&#21046;&#65292;&#20197;&#23454;&#29616;&#39640;&#32858;&#21512;&#36895;&#29575;&#24182;&#30830;&#20445;&#25152;&#26377;&#29992;&#25143;&#30340;&#20844;&#24179;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#21487;&#23398;&#20064;&#30340;&#26494;&#24347;&#21464;&#37327;&#65292;&#23558;&#24377;&#24615;&#26080;&#32447;&#30005;&#36164;&#28304;&#31649;&#29702;&#65288;RRM&#65289;&#31574;&#30053;&#20248;&#21270;&#38382;&#39064;&#19982;&#36866;&#24212;&#24213;&#23618;&#32593;&#32476;&#26465;&#20214;&#30340;&#27599;&#20010;&#29992;&#25143;&#26368;&#20302;&#23481;&#37327;&#32422;&#26463;&#30456;&#32467;&#21512;&#12290;&#25105;&#20204;&#22312;Lagrangian&#21452;&#37325;&#22495;&#20013;&#37325;&#26032;&#23450;&#20041;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#21487;&#20197;&#20351;&#29992;&#26377;&#38480;&#30340;&#21442;&#25968;&#38598;&#26469;&#21442;&#25968;&#21270;RRM&#31574;&#30053;&#65292;&#36890;&#36807;&#19968;&#20010;&#32463;&#36807;&#35777;&#23454;&#30340;&#23567;&#20559;&#24046;&#30340;&#26080;&#30417;&#30563;&#21407;&#22987;-&#21452;&#37325;&#26041;&#27861;&#36827;&#34892;&#35757;&#32451;&#12290;&#25105;&#20204;&#20351;&#29992;&#21487;&#25193;&#23637;&#30340;&#32622;&#25442;&#31561;&#21464;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#26550;&#26500;&#26469;&#22522;&#20110;&#30636;&#26102;&#20449;&#36947;&#26465;&#20214;&#25512;&#23548;&#20986;&#30340;&#22270;&#24418;&#25299;&#25169;&#21442;&#25968;&#21270;RRM&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problems of user selection and power control in wireless interference networks, comprising multiple access points (APs) communicating with a group of user equipment devices (UEs) over a shared wireless medium. To achieve a high aggregate rate, while ensuring fairness across all users, we formulate a resilient radio resource management (RRM) policy optimization problem with per-user minimum-capacity constraints that adapt to the underlying network conditions via learnable slack variables. We reformulate the problem in the Lagrangian dual domain, and show that we can parameterize the RRM policies using a finite set of parameters, which can be trained alongside the slack and dual variables via an unsupervised primal-dual approach thanks to a provably small duality gap. We use a scalable and permutation-equivariant graph neural network (GNN) architecture to parameterize the RRM policies based on a graph topology derived from the instantaneous channel conditions. Through exp
&lt;/p&gt;</description></item><item><title>Weisfeiler-Leman&#31639;&#27861;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#22788;&#29702;&#22270;&#21644;&#20851;&#31995;&#25968;&#25454;&#12290;&#26412;&#25991;&#20840;&#38754;&#20171;&#32461;&#20102;&#35813;&#31639;&#27861;&#22312;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#65292;&#21253;&#25324;&#29702;&#35770;&#32972;&#26223;&#12289;&#25193;&#23637;&#12289;&#19982;&#31561;&#21464;&#31070;&#32463;&#32593;&#26684;&#30340;&#32852;&#31995;&#12289;&#24182;&#21015;&#20986;&#20102;&#24403;&#21069;&#24212;&#29992;&#21644;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2112.09992</link><description>&lt;p&gt;
Weisfeiler&#21644;Leman&#26469;&#20570;&#26426;&#22120;&#23398;&#20064;&#20102;&#65306;&#30446;&#21069;&#30340;&#30740;&#31350;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
Weisfeiler and Leman go Machine Learning: The Story so far. (arXiv:2112.09992v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.09992
&lt;/p&gt;
&lt;p&gt;
Weisfeiler-Leman&#31639;&#27861;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#22788;&#29702;&#22270;&#21644;&#20851;&#31995;&#25968;&#25454;&#12290;&#26412;&#25991;&#20840;&#38754;&#20171;&#32461;&#20102;&#35813;&#31639;&#27861;&#22312;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#65292;&#21253;&#25324;&#29702;&#35770;&#32972;&#26223;&#12289;&#25193;&#23637;&#12289;&#19982;&#31561;&#21464;&#31070;&#32463;&#32593;&#26684;&#30340;&#32852;&#31995;&#12289;&#24182;&#21015;&#20986;&#20102;&#24403;&#21069;&#24212;&#29992;&#21644;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22522;&#20110;Weisfeiler-Leman&#31639;&#27861;&#30340;&#31639;&#27861;&#21644;&#31070;&#32463;&#26550;&#26500;&#24050;&#25104;&#20026;&#22788;&#29702;&#22270;&#21644;&#20851;&#31995;&#25968;&#25454;&#30340;&#26426;&#22120;&#23398;&#20064;&#30340;&#24378;&#22823;&#24037;&#20855;&#12290;&#26412;&#25991;&#20840;&#38754;&#20171;&#32461;&#31639;&#27861;&#22312;&#26426;&#22120;&#23398;&#20064;&#29615;&#22659;&#20013;&#30340;&#20351;&#29992;&#24773;&#20917;&#65292;&#37325;&#28857;&#20851;&#27880;&#30417;&#30563;&#23398;&#20064;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#29702;&#35770;&#32972;&#26223;&#65292;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#20854;&#29992;&#20110;&#30417;&#30563;&#22270;&#24418;&#21644;&#33410;&#28857;&#34920;&#31034;&#23398;&#20064;&#65292;&#35752;&#35770;&#20102;&#26368;&#36817;&#30340;&#25193;&#23637;&#65292;&#24182;&#27010;&#36848;&#20102;&#31639;&#27861;&#19982;&#65288;&#32622;&#25442;&#65289;&#31561;&#21464;&#31070;&#32463;&#32593;&#26684;&#30340;&#32852;&#31995;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#27010;&#36848;&#20102;&#24403;&#21069;&#30340;&#24212;&#29992;&#21644;&#26410;&#26469;&#30340;&#30740;&#31350;&#26041;&#21521;&#20197;&#21050;&#28608;&#36827;&#19968;&#27493;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, algorithms and neural architectures based on the Weisfeiler-Leman algorithm, a well-known heuristic for the graph isomorphism problem, have emerged as a powerful tool for machine learning with graphs and relational data. Here, we give a comprehensive overview of the algorithm's use in a machine-learning setting, focusing on the supervised regime. We discuss the theoretical background, show how to use it for supervised graph and node representation learning, discuss recent extensions, and outline the algorithm's connection to (permutation-)equivariant neural architectures. Moreover, we give an overview of current applications and future directions to stimulate further research.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#21457;&#29616;&#20102;&#23545;&#25239;&#35757;&#32451;&#20013;&#23384;&#22312;&#30340;&#26631;&#31614;&#22122;&#22768;&#65292;&#24182;&#35299;&#37322;&#20102;&#20854;&#23545;&#40065;&#26834;&#36807;&#24230;&#25311;&#21512;&#30340;&#26222;&#36941;&#23384;&#22312;&#20197;&#21450;&#25200;&#21160;&#21322;&#24452;&#21644;&#25968;&#25454;&#36136;&#37327;&#30340;&#20381;&#36182;&#24615;&#12290;&#36890;&#36807;&#35813;&#35770;&#25991;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#33258;&#21160;&#26657;&#20934;&#26631;&#31614;&#20197;&#24212;&#23545;&#26631;&#31614;&#22122;&#22768;&#21644;&#40065;&#26834;&#36807;&#24230;&#25311;&#21512;&#12290;</title><link>http://arxiv.org/abs/2110.03135</link><description>&lt;p&gt;
&#23545;&#25239;&#35757;&#32451;&#20013;&#30340;&#26631;&#31614;&#22122;&#22768;&#65306;&#30740;&#31350;&#40065;&#26834;&#36807;&#24230;&#25311;&#21512;&#30340;&#26032;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Label Noise in Adversarial Training: A Novel Perspective to Study Robust Overfitting. (arXiv:2110.03135v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.03135
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#21457;&#29616;&#20102;&#23545;&#25239;&#35757;&#32451;&#20013;&#23384;&#22312;&#30340;&#26631;&#31614;&#22122;&#22768;&#65292;&#24182;&#35299;&#37322;&#20102;&#20854;&#23545;&#40065;&#26834;&#36807;&#24230;&#25311;&#21512;&#30340;&#26222;&#36941;&#23384;&#22312;&#20197;&#21450;&#25200;&#21160;&#21322;&#24452;&#21644;&#25968;&#25454;&#36136;&#37327;&#30340;&#20381;&#36182;&#24615;&#12290;&#36890;&#36807;&#35813;&#35770;&#25991;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#33258;&#21160;&#26657;&#20934;&#26631;&#31614;&#20197;&#24212;&#23545;&#26631;&#31614;&#22122;&#22768;&#21644;&#40065;&#26834;&#36807;&#24230;&#25311;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#23545;&#25239;&#35757;&#32451;&#20013;&#23384;&#22312;&#26631;&#31614;&#22122;&#22768;&#12290;&#36825;&#31181;&#26631;&#31614;&#22122;&#22768;&#26159;&#30001;&#20110;&#23545;&#25239;&#26679;&#26412;&#30340;&#30495;&#23454;&#26631;&#31614;&#20998;&#24067;&#19982;&#20174;&#24178;&#20928;&#26679;&#26412;&#32487;&#25215;&#30340;&#26631;&#31614;&#20043;&#38388;&#30340;&#19981;&#21305;&#37197;&#36896;&#25104;&#30340; - &#30495;&#23454;&#26631;&#31614;&#20998;&#24067;&#34987;&#23545;&#25239;&#25200;&#21160;&#25197;&#26354;&#65292;&#20294;&#20174;&#24178;&#20928;&#26679;&#26412;&#32487;&#25215;&#26631;&#31614;&#30340;&#24120;&#35265;&#20570;&#27861;&#21364;&#24573;&#30053;&#20102;&#36825;&#19968;&#28857;&#12290;&#35748;&#35782;&#21040;&#26631;&#31614;&#22122;&#22768;&#26377;&#21161;&#20110;&#27934;&#23519;&#23545;&#25239;&#35757;&#32451;&#20013;&#40065;&#26834;&#36807;&#24230;&#25311;&#21512;&#30340;&#26222;&#36941;&#23384;&#22312;&#65292;&#24182;&#35299;&#37322;&#20102;&#20854;&#23545;&#25200;&#21160;&#21322;&#24452;&#21644;&#25968;&#25454;&#36136;&#37327;&#30340;&#22855;&#29305;&#20381;&#36182;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26631;&#31614;&#22122;&#22768;&#35270;&#35282;&#19982;&#25105;&#20204;&#23545;&#23545;&#25239;&#35757;&#32451;&#20013;&#32426;&#20803;&#21452;&#19979;&#38477;&#29616;&#35937;&#30340;&#35266;&#23519;&#30456;&#21563;&#21512;&#12290;&#22312;&#25105;&#20204;&#30340;&#20998;&#26512;&#25351;&#23548;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#33258;&#21160;&#26657;&#20934;&#26631;&#31614;&#20197;&#24212;&#23545;&#26631;&#31614;&#22122;&#22768;&#21644;&#40065;&#26834;&#36807;&#24230;&#25311;&#21512;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21508;&#31181;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#19968;&#33268;&#30340;&#24615;&#33021;&#25552;&#21319;&#65292;&#32780;&#19981;&#24341;&#20837;&#26032;&#30340;&#36229;&#21442;&#25968;&#25110;&#39069;&#22806;&#30340;&#35843;&#25972;&#12290;
&lt;/p&gt;
&lt;p&gt;
We show that label noise exists in adversarial training. Such label noise is due to the mismatch between the true label distribution of adversarial examples and the label inherited from clean examples - the true label distribution is distorted by the adversarial perturbation, but is neglected by the common practice that inherits labels from clean examples. Recognizing label noise sheds insights on the prevalence of robust overfitting in adversarial training, and explains its intriguing dependence on perturbation radius and data quality. Also, our label noise perspective aligns well with our observations of the epoch-wise double descent in adversarial training. Guided by our analyses, we proposed a method to automatically calibrate the label to address the label noise and robust overfitting. Our method achieves consistent performance improvements across various models and datasets without introducing new hyper-parameters or additional tuning.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#36125;&#21494;&#26031;&#31215;&#20998;&#26041;&#26696;&#65292;&#29992;&#20110;&#36793;&#32536;&#21270;&#39640;&#26031;&#36807;&#31243;&#26680;&#26063;&#65292;&#20197;&#33719;&#24471;&#20855;&#26377;&#33391;&#22909;&#26657;&#20934;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#28789;&#27963;&#27169;&#22411;&#65292;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#39640;&#25928;&#23454;&#29992;&#12290;</title><link>http://arxiv.org/abs/2106.07452</link><description>&lt;p&gt;
&#29992;&#36125;&#21494;&#26031;&#31215;&#20998;&#23545;&#24179;&#31283;&#26680;&#36827;&#34892;&#36793;&#32536;&#21270;
&lt;/p&gt;
&lt;p&gt;
Marginalising over Stationary Kernels with Bayesian Quadrature. (arXiv:2106.07452v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.07452
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#36125;&#21494;&#26031;&#31215;&#20998;&#26041;&#26696;&#65292;&#29992;&#20110;&#36793;&#32536;&#21270;&#39640;&#26031;&#36807;&#31243;&#26680;&#26063;&#65292;&#20197;&#33719;&#24471;&#20855;&#26377;&#33391;&#22909;&#26657;&#20934;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#28789;&#27963;&#27169;&#22411;&#65292;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#39640;&#25928;&#23454;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#39640;&#26031;&#36807;&#31243;&#26680;&#26063;&#36827;&#34892;&#36793;&#32536;&#21270;&#21487;&#20197;&#20135;&#29983;&#20855;&#26377;&#33391;&#22909;&#26657;&#20934;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#28789;&#27963;&#27169;&#22411;&#12290;&#29616;&#26377;&#26041;&#27861;&#38656;&#35201;&#35780;&#20272;&#35768;&#22810;&#26680;&#30340;&#20284;&#28982;&#24615;&#65292;&#20351;&#23427;&#20204;&#23545;&#20110;&#36739;&#22823;&#30340;&#25968;&#25454;&#38598;&#26469;&#35828;&#21464;&#24471;&#19981;&#20999;&#23454;&#38469;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#31215;&#20998;&#26041;&#26696;&#65292;&#20351;&#24471;&#36825;&#31181;&#36793;&#32536;&#21270;&#26356;&#21152;&#39640;&#25928;&#65292;&#22240;&#27492;&#26356;&#21152;&#23454;&#29992;&#12290;&#36890;&#36807;&#20351;&#29992;&#20998;&#24067;&#20043;&#38388;&#30340;&#26368;&#22823;&#24179;&#22343;&#24046;&#24322;&#65292;&#25105;&#20204;&#23450;&#20041;&#19968;&#31181;&#25429;&#25417;&#35889;&#28151;&#21512;&#65288;SM&#65289;&#26680;&#20043;&#38388;&#19981;&#21464;&#24615;&#30340;&#26680;&#12290;&#36890;&#36807;&#25512;&#24191;&#38590;&#20197;&#23450;&#20041;&#30340;&#21464;&#24418;&#36125;&#21494;&#26031;&#31215;&#20998;&#21462;&#24471;&#26679;&#26412;&#26680;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26694;&#26550;&#27604;&#26368;&#20808;&#36827;&#30340;&#22522;&#32447;&#20135;&#29983;&#26356;&#20934;&#30830;&#30340;&#39044;&#27979;&#65292;&#23588;&#20854;&#26159;&#24403;&#32473;&#20986;&#26377;&#38480;&#30340;&#65288;&#22681;&#26102;&#38047;&#65289;&#26102;&#38388;&#39044;&#31639;&#26102;&#20855;&#26377;&#26356;&#22909;&#30340;&#26657;&#20934;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Marginalising over families of Gaussian Process kernels produces flexible model classes with well-calibrated uncertainty estimates. Existing approaches require likelihood evaluations of many kernels, rendering them prohibitively expensive for larger datasets. We propose a Bayesian Quadrature scheme to make this marginalisation more efficient and thereby more practical. Through use of the maximum mean discrepancies between distributions, we define a kernel over kernels that captures invariances between Spectral Mixture (SM) Kernels. Kernel samples are selected by generalising an information-theoretic acquisition function for warped Bayesian Quadrature. We show that our framework achieves more accurate predictions with better calibrated uncertainty than state-of-the-art baselines, especially when given limited (wall-clock) time budgets.
&lt;/p&gt;</description></item></channel></rss>