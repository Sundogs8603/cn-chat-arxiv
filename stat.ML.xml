<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>DTOR&#26159;&#19968;&#31181;&#20915;&#31574;&#26641;&#24322;&#24120;&#20540;&#22238;&#24402;&#22120;&#65292;&#36890;&#36807;&#20272;&#35745;&#24322;&#24120;&#26816;&#27979;&#27169;&#22411;&#29983;&#25104;&#30340;&#24322;&#24120;&#20998;&#25968;&#26469;&#20135;&#29983;&#22522;&#20110;&#35268;&#21017;&#30340;&#35299;&#37322;&#65292;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#22823;&#37327;&#29305;&#24449;&#25968;&#25454;&#38598;&#12290;</title><link>https://arxiv.org/abs/2403.10903</link><description>&lt;p&gt;
DTOR&#65306;&#20915;&#31574;&#26641;&#24322;&#24120;&#20540;&#22238;&#24402;&#22120;&#29992;&#20110;&#35299;&#37322;&#24322;&#24120;
&lt;/p&gt;
&lt;p&gt;
DTOR: Decision Tree Outlier Regressor to explain anomalies
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10903
&lt;/p&gt;
&lt;p&gt;
DTOR&#26159;&#19968;&#31181;&#20915;&#31574;&#26641;&#24322;&#24120;&#20540;&#22238;&#24402;&#22120;&#65292;&#36890;&#36807;&#20272;&#35745;&#24322;&#24120;&#26816;&#27979;&#27169;&#22411;&#29983;&#25104;&#30340;&#24322;&#24120;&#20998;&#25968;&#26469;&#20135;&#29983;&#22522;&#20110;&#35268;&#21017;&#30340;&#35299;&#37322;&#65292;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#22823;&#37327;&#29305;&#24449;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35299;&#37322;&#24322;&#24120;&#20540;&#30340;&#20986;&#29616;&#20197;&#21450;&#20854;&#20135;&#29983;&#26426;&#21046;&#22312;&#21508;&#31181;&#39046;&#22495;&#20013;&#21487;&#33021;&#38750;&#24120;&#37325;&#35201;&#12290;&#25925;&#38556;&#12289;&#27450;&#35784;&#12289;&#23041;&#32961;&#31561;&#38382;&#39064;&#65292;&#38500;&#20102;&#34987;&#27491;&#30830;&#35782;&#21035;&#20043;&#22806;&#65292;&#36890;&#24120;&#38656;&#35201;&#26377;&#25928;&#30340;&#35299;&#37322;&#20197;&#26377;&#25928;&#25191;&#34892;&#21487;&#25805;&#20316;&#30340;&#23545;&#25239;&#25514;&#26045;&#12290;&#36234;&#26469;&#36234;&#24191;&#27867;&#22320;&#20351;&#29992;&#22797;&#26434;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#26469;&#35782;&#21035;&#24322;&#24120;&#20540;&#65292;&#20351;&#24471;&#36825;&#26679;&#30340;&#35299;&#37322;&#26356;&#20855;&#25361;&#25112;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20915;&#31574;&#26641;&#24322;&#24120;&#20540;&#22238;&#24402;&#22120;&#65288;DTOR&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#36890;&#36807;&#20272;&#35745;&#24322;&#24120;&#26816;&#27979;&#27169;&#22411;&#29983;&#25104;&#30340;&#24322;&#24120;&#20998;&#25968;&#26469;&#20026;&#21333;&#20010;&#25968;&#25454;&#28857;&#29983;&#25104;&#22522;&#20110;&#35268;&#21017;&#30340;&#35299;&#37322;&#30340;&#25216;&#26415;&#12290;&#36825;&#26159;&#36890;&#36807;&#39318;&#20808;&#24212;&#29992;&#20915;&#31574;&#26641;&#22238;&#24402;&#22120;&#26469;&#35745;&#31639;&#20272;&#35745;&#20998;&#25968;&#65292;&#28982;&#21518;&#25552;&#21462;&#19982;&#25968;&#25454;&#28857;&#20998;&#25968;&#30456;&#20851;&#32852;&#30340;&#30456;&#23545;&#36335;&#24452;&#26469;&#23454;&#29616;&#30340;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#21363;&#20351;&#22312;&#20855;&#26377;&#22823;&#37327;&#29305;&#24449;&#30340;&#25968;&#25454;&#38598;&#20013;&#65292;DTOR&#30340;&#40065;&#26834;&#24615;&#20063;&#24471;&#21040;&#20102;&#35777;&#23454;&#12290;&#27492;&#22806;&#65292;&#19982;&#20854;&#20182;&#22522;&#20110;&#35268;&#21017;&#30340;&#26041;&#27861;&#30456;&#27604;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10903v1 Announce Type: cross  Abstract: Explaining outliers occurrence and mechanism of their occurrence can be extremely important in a variety of domains. Malfunctions, frauds, threats, in addition to being correctly identified, oftentimes need a valid explanation in order to effectively perform actionable counteracts. The ever more widespread use of sophisticated Machine Learning approach to identify anomalies make such explanations more challenging. We present the Decision Tree Outlier Regressor (DTOR), a technique for producing rule-based explanations for individual data points by estimating anomaly scores generated by an anomaly detection model. This is accomplished by first applying a Decision Tree Regressor, which computes the estimation score, and then extracting the relative path associated with the data point score. Our results demonstrate the robustness of DTOR even in datasets with a large number of features. Additionally, in contrast to other rule-based approac
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20803;&#23398;&#20064;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#23398;&#20064;&#25512;&#36831;&#23545;&#20154;&#32676;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#22312;&#27979;&#35797;&#26102;&#36866;&#24212;&#21069;&#25152;&#26410;&#35265;&#30340;&#19987;&#23478;&#65292;&#20174;&#32780;&#26356;&#22909;&#22320;&#38754;&#23545;&#22256;&#38590;&#20915;&#31574;&#12290;</title><link>https://arxiv.org/abs/2403.02683</link><description>&lt;p&gt;
&#23398;&#20064;&#25512;&#36831;&#23545;&#20154;&#32676;&#30340;&#23398;&#20064;&#65306;&#19968;&#31181;&#20803;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Learning to Defer to a Population: A Meta-Learning Approach
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.02683
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20803;&#23398;&#20064;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#23398;&#20064;&#25512;&#36831;&#23545;&#20154;&#32676;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#22312;&#27979;&#35797;&#26102;&#36866;&#24212;&#21069;&#25152;&#26410;&#35265;&#30340;&#19987;&#23478;&#65292;&#20174;&#32780;&#26356;&#22909;&#22320;&#38754;&#23545;&#22256;&#38590;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02683v1 &#20844;&#21578;&#31867;&#22411;&#65306;&#26032; &#25688;&#35201;&#65306;&#23398;&#20064;&#25512;&#36831;&#65288;L2D&#65289;&#26694;&#26550;&#20801;&#35768;&#33258;&#20027;&#31995;&#32479;&#36890;&#36807;&#23558;&#22256;&#38590;&#20915;&#31574;&#22996;&#25176;&#32473;&#20154;&#31867;&#19987;&#23478;&#26469;&#20445;&#25345;&#23433;&#20840;&#21644;&#20581;&#22766;&#12290;&#25152;&#26377;&#29616;&#26377;&#30340;&#20851;&#20110;L2D&#30340;&#24037;&#20316;&#37117;&#20551;&#35774;&#27599;&#20010;&#19987;&#23478;&#37117;&#21487;&#20197;&#24456;&#22909;&#22320;&#30830;&#23450;&#65292;&#24182;&#19988;&#22914;&#26524;&#20219;&#20309;&#19987;&#23478;&#21457;&#29983;&#21464;&#21270;&#65292;&#31995;&#32479;&#24212;&#35813;&#37325;&#26032;&#35757;&#32451;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20943;&#36731;&#20102;&#36825;&#19968;&#38480;&#21046;&#65292;&#21046;&#23450;&#20102;&#19968;&#20010;L2D&#31995;&#32479;&#65292;&#23427;&#21487;&#20197;&#22312;&#27979;&#35797;&#26102;&#24212;&#23545;&#21069;&#25152;&#26410;&#35265;&#30340;&#19987;&#23478;&#12290;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#20803;&#23398;&#20064;&#26469;&#23454;&#29616;&#36825;&#19968;&#28857;&#65292;&#32771;&#34385;&#20102;&#22522;&#20110;&#20248;&#21270;&#21644;&#22522;&#20110;&#27169;&#22411;&#30340;&#21464;&#20307;&#12290;&#32473;&#23450;&#19968;&#20010;&#23567;&#30340;&#19978;&#19979;&#25991;&#38598;&#26469;&#25551;&#36848;&#24403;&#21069;&#21487;&#29992;&#30340;&#19987;&#23478;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#24555;&#36895;&#35843;&#25972;&#23427;&#30340;&#25512;&#36831;&#31574;&#30053;&#12290;&#23545;&#20110;&#22522;&#20110;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#19968;&#20010;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#33021;&#22815;&#23547;&#25214;&#19978;&#19979;&#25991;&#38598;&#20013;&#19982;&#32473;&#23450;&#27979;&#35797;&#28857;&#30456;&#20284;&#30340;&#28857;&#65292;&#20174;&#32780;&#26356;&#31934;&#30830;&#22320;&#35780;&#20272;&#19987;&#23478;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.02683v1 Announce Type: new  Abstract: The learning to defer (L2D) framework allows autonomous systems to be safe and robust by allocating difficult decisions to a human expert. All existing work on L2D assumes that each expert is well-identified, and if any expert were to change, the system should be re-trained. In this work, we alleviate this constraint, formulating an L2D system that can cope with never-before-seen experts at test-time. We accomplish this by using meta-learning, considering both optimization- and model-based variants. Given a small context set to characterize the currently available expert, our framework can quickly adapt its deferral policy. For the model-based approach, we employ an attention mechanism that is able to look for points in the context set that are similar to a given test point, leading to an even more precise assessment of the expert's abilities. In the experiments, we validate our methods on image recognition, traffic sign detection, and s
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#29289;&#29702;&#32422;&#26463;&#30340;&#22810;&#39033;&#24335;&#28151;&#27788;&#23637;&#24320;&#26041;&#27861;&#65292;&#23558;&#31185;&#23398;&#26426;&#22120;&#23398;&#20064;&#19982;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26080;&#32541;&#38598;&#25104;&#65292;&#26377;&#25928;&#22320;&#23454;&#29616;SciML&#20219;&#21153;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#22312;UQ&#20219;&#21153;&#20013;&#21033;&#29992;SciML&#25552;&#39640;&#19981;&#30830;&#23450;&#24615;&#35780;&#20272;&#12290;</title><link>https://arxiv.org/abs/2402.15115</link><description>&lt;p&gt;
&#29289;&#29702;&#32422;&#26463;&#30340;&#22810;&#39033;&#24335;&#28151;&#27788;&#23637;&#24320;&#29992;&#20110;&#31185;&#23398;&#26426;&#22120;&#23398;&#20064;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Physics-constrained polynomial chaos expansion for scientific machine learning and uncertainty quantification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15115
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#29289;&#29702;&#32422;&#26463;&#30340;&#22810;&#39033;&#24335;&#28151;&#27788;&#23637;&#24320;&#26041;&#27861;&#65292;&#23558;&#31185;&#23398;&#26426;&#22120;&#23398;&#20064;&#19982;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26080;&#32541;&#38598;&#25104;&#65292;&#26377;&#25928;&#22320;&#23454;&#29616;SciML&#20219;&#21153;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#22312;UQ&#20219;&#21153;&#20013;&#21033;&#29992;SciML&#25552;&#39640;&#19981;&#30830;&#23450;&#24615;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29289;&#29702;&#32422;&#26463;&#30340;&#22810;&#39033;&#24335;&#28151;&#27788;&#23637;&#24320;&#20316;&#20026;&#19968;&#31181;&#26367;&#20195;&#24314;&#27169;&#26041;&#27861;&#65292;&#33021;&#22815;&#25191;&#34892;&#31185;&#23398;&#26426;&#22120;&#23398;&#20064;&#65288;SciML&#65289;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65288;UQ&#65289;&#20219;&#21153;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20855;&#26377;&#29420;&#29305;&#30340;&#33021;&#21147;&#65306;&#23558;SciML&#19982;UQ&#26080;&#32541;&#38598;&#25104;&#65292;&#20174;&#32780;&#33021;&#22815;&#26377;&#25928;&#22320;&#37327;&#21270;SciML&#20219;&#21153;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#21033;&#29992;SciML&#26469;&#25913;&#21892;UQ&#30456;&#20851;&#20219;&#21153;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#35780;&#20272;&#12290;&#35813;&#26367;&#20195;&#27169;&#22411;&#21487;&#20197;&#26377;&#25928;&#22320;&#32435;&#20837;&#22810;&#31181;&#29289;&#29702;&#32422;&#26463;&#65292;&#22914;&#25903;&#37197;&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;PDEs&#65289;&#21450;&#20854;&#30456;&#20851;&#30340;&#21021;&#22987;&#21644;&#36793;&#30028;&#26465;&#20214;&#32422;&#26463;&#65292;&#19981;&#31561;&#24335;&#22411;&#32422;&#26463;&#65288;&#22914;&#21333;&#35843;&#24615;&#65292;&#20984;&#24615;&#65292;&#38750;&#36127;&#24615;&#31561;&#65289;&#65292;&#20197;&#21450;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#28155;&#21152;&#39069;&#22806;&#20808;&#39564;&#20449;&#24687;&#20197;&#36741;&#21161;&#26377;&#38480;&#25968;&#25454;&#12290;&#36825;&#30830;&#20445;&#20102;&#29289;&#29702;&#19978;&#21512;&#29702;&#30340;&#39044;&#27979;&#65292;&#24182;&#26174;&#33879;&#20943;&#23569;&#20102;&#26114;&#36149;&#35745;&#31639;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15115v1 Announce Type: cross  Abstract: We present a novel physics-constrained polynomial chaos expansion as a surrogate modeling method capable of performing both scientific machine learning (SciML) and uncertainty quantification (UQ) tasks. The proposed method possesses a unique capability: it seamlessly integrates SciML into UQ and vice versa, which allows it to quantify the uncertainties in SciML tasks effectively and leverage SciML for improved uncertainty assessment during UQ-related tasks. The proposed surrogate model can effectively incorporate a variety of physical constraints, such as governing partial differential equations (PDEs) with associated initial and boundary conditions constraints, inequality-type constraints (e.g., monotonicity, convexity, non-negativity, among others), and additional a priori information in the training process to supplement limited data. This ensures physically realistic predictions and significantly reduces the need for expensive comp
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#36866;&#29992;&#20110;&#39034;&#24207;&#38543;&#26426;&#25237;&#24433;&#30340;&#27010;&#29575;&#26694;&#26550;&#65292;&#36890;&#36807;&#26500;&#24314;&#20572;&#27490;&#36807;&#31243;&#24182;&#37319;&#29992;&#28151;&#21512;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#23545;&#19968;&#31995;&#21015;&#30456;&#20114;&#36830;&#25509;&#30340;&#27987;&#32553;&#20107;&#20214;&#30340;&#20998;&#26512;&#65292;&#20174;&#32780;&#21019;&#36896;&#20102;&#23545;Johnson-Lindenstrauss&#24341;&#29702;&#30340;&#38750;&#24179;&#20961;&#38789;&#25193;&#23637;&#12290;</title><link>https://arxiv.org/abs/2402.14026</link><description>&lt;p&gt;
&#29992;&#20110;&#39034;&#24207;&#38543;&#26426;&#25237;&#24433;&#30340;&#27010;&#29575;&#24037;&#20855;
&lt;/p&gt;
&lt;p&gt;
Probability Tools for Sequential Random Projection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14026
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#36866;&#29992;&#20110;&#39034;&#24207;&#38543;&#26426;&#25237;&#24433;&#30340;&#27010;&#29575;&#26694;&#26550;&#65292;&#36890;&#36807;&#26500;&#24314;&#20572;&#27490;&#36807;&#31243;&#24182;&#37319;&#29992;&#28151;&#21512;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#23545;&#19968;&#31995;&#21015;&#30456;&#20114;&#36830;&#25509;&#30340;&#27987;&#32553;&#20107;&#20214;&#30340;&#20998;&#26512;&#65292;&#20174;&#32780;&#21019;&#36896;&#20102;&#23545;Johnson-Lindenstrauss&#24341;&#29702;&#30340;&#38750;&#24179;&#20961;&#38789;&#25193;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#31532;&#19968;&#20010;&#19987;&#20026;&#39034;&#24207;&#38543;&#26426;&#25237;&#24433;&#23450;&#21046;&#30340;&#27010;&#29575;&#26694;&#26550;&#65292;&#36825;&#31181;&#26041;&#27861;&#26893;&#26681;&#20110;&#38754;&#23545;&#19981;&#30830;&#23450;&#24615;&#30340;&#39034;&#24207;&#20915;&#31574;&#30340;&#25361;&#25112;&#12290;&#20998;&#26512;&#21463;&#21040;&#38543;&#26426;&#21464;&#37327;&#30340;&#39034;&#24207;&#20381;&#36182;&#21644;&#39640;&#32500;&#24615;&#36136;&#30340;&#24433;&#21709;&#65292;&#36825;&#26159;&#39034;&#24207;&#20915;&#31574;&#36807;&#31243;&#20013;&#22266;&#26377;&#30340;&#33258;&#36866;&#24212;&#26426;&#21046;&#30340;&#21103;&#20135;&#21697;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#29305;&#28857;&#26159;&#26500;&#24314;&#20102;&#19968;&#20010;&#20572;&#27490;&#36807;&#31243;&#65292;&#20415;&#20110;&#20998;&#26512;&#19968;&#31995;&#21015;&#20197;&#39034;&#24207;&#26041;&#24335;&#30456;&#20114;&#36830;&#25509;&#30340;&#27987;&#32553;&#20107;&#20214;&#12290;&#36890;&#36807;&#22312;&#20174;&#20572;&#27490;&#36807;&#31243;&#24471;&#20986;&#30340;&#33258;&#35268;&#33539;&#36807;&#31243;&#20869;&#37319;&#29992;&#28151;&#21512;&#26041;&#27861;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#25152;&#38656;&#30340;&#38750;&#28176;&#36817;&#27010;&#29575;&#30028;&#38480;&#12290;&#35813;&#30028;&#38480;&#20195;&#34920;&#20102;&#23545;Johnson-Lindenstrauss&#65288;JL&#65289;&#24341;&#29702;&#30340;&#19968;&#20010;&#38750;&#24179;&#20961;&#30340;&#38789;&#25193;&#23637;&#65292;&#26631;&#24535;&#30528;&#23545;&#38543;&#26426;&#25237;&#24433;&#21644;&#39034;&#24207;&#20998;&#26512;&#30340;&#25991;&#29486;&#20570;&#20986;&#20102;&#24320;&#21019;&#24615;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14026v1 Announce Type: cross  Abstract: We introduce the first probabilistic framework tailored for sequential random projection, an approach rooted in the challenges of sequential decision-making under uncertainty. The analysis is complicated by the sequential dependence and high-dimensional nature of random variables, a byproduct of the adaptive mechanisms inherent in sequential decision processes. Our work features a novel construction of a stopped process, facilitating the analysis of a sequence of concentration events that are interconnected in a sequential manner. By employing the method of mixtures within a self-normalized process, derived from the stopped process, we achieve a desired non-asymptotic probability bound. This bound represents a non-trivial martingale extension of the Johnson-Lindenstrauss (JL) lemma, marking a pioneering contribution to the literature on random projection and sequential analysis.
&lt;/p&gt;</description></item><item><title>HyperAgent&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#12289;&#39640;&#25928;&#12289;&#21487;&#25193;&#23637;&#30340;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#22312;&#22797;&#26434;&#29615;&#22659;&#19979;&#33021;&#22815;&#23454;&#29616;&#39640;&#25928;&#30340;&#35745;&#31639;&#21644;&#25968;&#25454;&#36873;&#25321;&#65292;&#26159;&#39318;&#20010;&#36798;&#21040;&#21487;&#35777;&#26126;&#21487;&#25193;&#23637;&#30340;&#27599;&#27493;&#35745;&#31639;&#22797;&#26434;&#24230;&#20197;&#21450;&#27425;&#32447;&#24615;&#21518;&#24724;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.10228</link><description>&lt;p&gt;
HyperAgent&#65306;&#19968;&#31181;&#31616;&#21333;&#12289;&#21487;&#25193;&#23637;&#12289;&#39640;&#25928;&#19988;&#21487;&#35777;&#26126;&#29992;&#20110;&#22797;&#26434;&#29615;&#22659;&#30340;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
HyperAgent: A Simple, Scalable, Efficient and Provable Reinforcement Learning Framework for Complex Environments
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10228
&lt;/p&gt;
&lt;p&gt;
HyperAgent&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#12289;&#39640;&#25928;&#12289;&#21487;&#25193;&#23637;&#30340;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#22312;&#22797;&#26434;&#29615;&#22659;&#19979;&#33021;&#22815;&#23454;&#29616;&#39640;&#25928;&#30340;&#35745;&#31639;&#21644;&#25968;&#25454;&#36873;&#25321;&#65292;&#26159;&#39318;&#20010;&#36798;&#21040;&#21487;&#35777;&#26126;&#21487;&#25193;&#23637;&#30340;&#27599;&#27493;&#35745;&#31639;&#22797;&#26434;&#24230;&#20197;&#21450;&#27425;&#32447;&#24615;&#21518;&#24724;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#22312;&#36164;&#28304;&#32422;&#26463;&#19979;&#35299;&#20915;&#22797;&#26434;&#20219;&#21153;&#65292;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#20195;&#29702;&#38656;&#35201;&#31616;&#21333;&#12289;&#39640;&#25928;&#12289;&#21487;&#25193;&#23637;&#12289;&#20855;&#26377;&#22823;&#29366;&#24577;&#31354;&#38388;&#21644;&#19981;&#26029;&#31215;&#32047;&#30340;&#20132;&#20114;&#25968;&#25454;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;HyperAgent&#65292;&#36825;&#26159;&#19968;&#20010;&#20855;&#26377;&#36229;&#27169;&#22411;&#12289;&#32034;&#24341;&#25277;&#26679;&#26041;&#26696;&#21644;&#22686;&#37327;&#26356;&#26032;&#26426;&#21046;&#30340;RL&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#19968;&#33324;&#20215;&#20540;&#20989;&#25968;&#36924;&#36817;&#20013;&#36827;&#34892;&#35745;&#31639;&#39640;&#25928;&#30340;&#39034;&#24207;&#21518;&#39564;&#36924;&#36817;&#21644;&#25968;&#25454;&#39640;&#25928;&#30340;&#21160;&#20316;&#36873;&#25321;&#65292;&#36229;&#36234;&#20102;&#20849;&#36717;&#24615;&#12290;HyperAgent&#30340;&#23454;&#29616;&#31616;&#21333;&#65292;&#21482;&#38656;&#35201;&#22312;DDQN&#20013;&#28155;&#21152;&#19968;&#20010;&#27169;&#22359;&#21644;&#19968;&#34892;&#39069;&#22806;&#20195;&#30721;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;HyperAgent&#22312;&#22823;&#35268;&#27169;&#28145;&#24230;RL&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#31283;&#20581;&#30340;&#24615;&#33021;&#65292;&#26080;&#35770;&#26159;&#22312;&#25968;&#25454;&#36824;&#26159;&#35745;&#31639;&#26041;&#38754;&#37117;&#33719;&#24471;&#20102;&#26174;&#30528;&#30340;&#25928;&#29575;&#25552;&#21319;&#12290;&#22312;&#29702;&#35770;&#19978;&#65292;&#22312;&#23454;&#38469;&#21487;&#25193;&#23637;&#30340;&#31639;&#27861;&#20013;&#65292;HyperAgent&#26159;&#31532;&#19968;&#20010;&#33021;&#22815;&#23454;&#29616;&#21487;&#35777;&#26126;&#21487;&#25193;&#23637;&#30340;&#27599;&#27493;&#35745;&#31639;&#22797;&#26434;&#24230;&#20197;&#21450;&#27425;&#32447;&#24615;&#21518;&#24724;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10228v1 Announce Type: cross  Abstract: To solve complex tasks under resource constraints, reinforcement learning (RL) agents need to be simple, efficient, and scalable with (1) large state space and (2) increasingly accumulated data of interactions. We propose the HyperAgent, a RL framework with hypermodel, index sampling schemes and incremental update mechanism, enabling computation-efficient sequential posterior approximation and data-efficient action selection under general value function approximation beyond conjugacy. The implementation of \HyperAgent is simple as it only adds one module and one line of code additional to DDQN. Practically, HyperAgent demonstrates its robust performance in large-scale deep RL benchmarks with significant efficiency gain in terms of both data and computation. Theoretically, among the practically scalable algorithms, HyperAgent is the first method to achieve provably scalable per-step computational complexity as well as sublinear regret u
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#27604;&#36739;&#20102;&#26356;&#28145;&#30340;&#31070;&#32463;&#32593;&#32476;&#21644;&#26356;&#23485;&#30340;&#31070;&#32463;&#32593;&#32476;&#22312;Sobolev&#25439;&#22833;&#30340;&#26368;&#20248;&#27867;&#21270;&#35823;&#24046;&#26041;&#38754;&#30340;&#34920;&#29616;&#65292;&#30740;&#31350;&#21457;&#29616;&#31070;&#32463;&#32593;&#32476;&#30340;&#26550;&#26500;&#21463;&#22810;&#31181;&#22240;&#32032;&#24433;&#21709;&#65292;&#21442;&#25968;&#25968;&#37327;&#26356;&#22810;&#20542;&#21521;&#20110;&#36873;&#25321;&#26356;&#23485;&#30340;&#32593;&#32476;&#65292;&#32780;&#26679;&#26412;&#28857;&#25968;&#37327;&#21644;&#25439;&#22833;&#20989;&#25968;&#35268;&#21017;&#24615;&#26356;&#39640;&#20542;&#21521;&#20110;&#36873;&#25321;&#26356;&#28145;&#30340;&#32593;&#32476;&#12290;</title><link>https://arxiv.org/abs/2402.00152</link><description>&lt;p&gt;
&#26356;&#28145;&#36824;&#26159;&#26356;&#23485;: &#20174;Sobolev&#25439;&#22833;&#30340;&#26368;&#20248;&#27867;&#21270;&#35823;&#24046;&#35282;&#24230;&#30475;
&lt;/p&gt;
&lt;p&gt;
Deeper or Wider: A Perspective from Optimal Generalization Error with Sobolev Loss
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00152
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#27604;&#36739;&#20102;&#26356;&#28145;&#30340;&#31070;&#32463;&#32593;&#32476;&#21644;&#26356;&#23485;&#30340;&#31070;&#32463;&#32593;&#32476;&#22312;Sobolev&#25439;&#22833;&#30340;&#26368;&#20248;&#27867;&#21270;&#35823;&#24046;&#26041;&#38754;&#30340;&#34920;&#29616;&#65292;&#30740;&#31350;&#21457;&#29616;&#31070;&#32463;&#32593;&#32476;&#30340;&#26550;&#26500;&#21463;&#22810;&#31181;&#22240;&#32032;&#24433;&#21709;&#65292;&#21442;&#25968;&#25968;&#37327;&#26356;&#22810;&#20542;&#21521;&#20110;&#36873;&#25321;&#26356;&#23485;&#30340;&#32593;&#32476;&#65292;&#32780;&#26679;&#26412;&#28857;&#25968;&#37327;&#21644;&#25439;&#22833;&#20989;&#25968;&#35268;&#21017;&#24615;&#26356;&#39640;&#20542;&#21521;&#20110;&#36873;&#25321;&#26356;&#28145;&#30340;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26500;&#24314;&#31070;&#32463;&#32593;&#32476;&#30340;&#26550;&#26500;&#26159;&#26426;&#22120;&#23398;&#20064;&#30028;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#36861;&#27714;&#65292;&#21040;&#24213;&#26159;&#26356;&#28145;&#36824;&#26159;&#26356;&#23485;&#19968;&#30452;&#26159;&#19968;&#20010;&#25345;&#32493;&#30340;&#38382;&#39064;&#12290;&#26412;&#25991;&#25506;&#32034;&#20102;&#26356;&#28145;&#30340;&#31070;&#32463;&#32593;&#32476;&#65288;DeNNs&#65289;&#21644;&#20855;&#26377;&#26377;&#38480;&#38544;&#34255;&#23618;&#30340;&#26356;&#23485;&#30340;&#31070;&#32463;&#32593;&#32476;&#65288;WeNNs&#65289;&#22312;Sobolev&#25439;&#22833;&#30340;&#26368;&#20248;&#27867;&#21270;&#35823;&#24046;&#26041;&#38754;&#30340;&#27604;&#36739;&#12290;&#36890;&#36807;&#20998;&#26512;&#30740;&#31350;&#21457;&#29616;&#65292;&#31070;&#32463;&#32593;&#32476;&#30340;&#26550;&#26500;&#21487;&#20197;&#21463;&#21040;&#22810;&#31181;&#22240;&#32032;&#30340;&#26174;&#33879;&#24433;&#21709;&#65292;&#21253;&#25324;&#26679;&#26412;&#28857;&#30340;&#25968;&#37327;&#65292;&#31070;&#32463;&#32593;&#32476;&#20869;&#30340;&#21442;&#25968;&#20197;&#21450;&#25439;&#22833;&#20989;&#25968;&#30340;&#35268;&#21017;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#26356;&#22810;&#30340;&#21442;&#25968;&#20542;&#21521;&#20110;&#36873;&#25321;WeNNs&#65292;&#32780;&#26356;&#22810;&#30340;&#26679;&#26412;&#28857;&#21644;&#26356;&#39640;&#30340;&#25439;&#22833;&#20989;&#25968;&#35268;&#21017;&#24615;&#20542;&#21521;&#20110;&#36873;&#25321;DeNNs&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#36825;&#20010;&#29702;&#35770;&#24212;&#29992;&#20110;&#20351;&#29992;&#28145;&#24230;Ritz&#21644;&#29289;&#29702;&#24863;&#30693;&#31070;&#32463;&#32593;&#32476;&#65288;PINN&#65289;&#26041;&#27861;&#35299;&#20915;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Constructing the architecture of a neural network is a challenging pursuit for the machine learning community, and the dilemma of whether to go deeper or wider remains a persistent question. This paper explores a comparison between deeper neural networks (DeNNs) with a flexible number of layers and wider neural networks (WeNNs) with limited hidden layers, focusing on their optimal generalization error in Sobolev losses. Analytical investigations reveal that the architecture of a neural network can be significantly influenced by various factors, including the number of sample points, parameters within the neural networks, and the regularity of the loss function. Specifically, a higher number of parameters tends to favor WeNNs, while an increased number of sample points and greater regularity in the loss function lean towards the adoption of DeNNs. We ultimately apply this theory to address partial differential equations using deep Ritz and physics-informed neural network (PINN) methods,
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#22122;&#22768;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#26657;&#20934;&#38477;&#32500;&#36229;&#21442;&#25968;&#65292;&#25506;&#32034;&#20102;&#22256;&#24785;&#24230;&#21644;&#32500;&#24230;&#25968;&#37327;&#30340;&#20316;&#29992;&#12290;</title><link>https://arxiv.org/abs/2312.02946</link><description>&lt;p&gt;
&#22312;&#22122;&#22768;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#26657;&#20934;&#38477;&#32500;&#36229;&#21442;&#25968;
&lt;/p&gt;
&lt;p&gt;
Calibrating dimension reduction hyperparameters in the presence of noise
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.02946
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#22122;&#22768;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#26657;&#20934;&#38477;&#32500;&#36229;&#21442;&#25968;&#65292;&#25506;&#32034;&#20102;&#22256;&#24785;&#24230;&#21644;&#32500;&#24230;&#25968;&#37327;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38477;&#32500;&#24037;&#20855;&#30340;&#30446;&#26631;&#26159;&#26500;&#24314;&#39640;&#32500;&#25968;&#25454;&#30340;&#20302;&#32500;&#34920;&#31034;&#12290;&#36825;&#20123;&#24037;&#20855;&#34987;&#29992;&#20110;&#22122;&#22768;&#38477;&#20302;&#12289;&#21487;&#35270;&#21270;&#21644;&#38477;&#20302;&#35745;&#31639;&#25104;&#26412;&#31561;&#21508;&#31181;&#21407;&#22240;&#12290;&#28982;&#32780;&#65292;&#22312;&#38477;&#32500;&#25991;&#29486;&#20013;&#20960;&#20046;&#27809;&#26377;&#35752;&#35770;&#36807;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#26159;&#36807;&#25311;&#21512;&#65292;&#32780;&#22312;&#20854;&#20182;&#24314;&#27169;&#38382;&#39064;&#20013;&#36825;&#20010;&#38382;&#39064;&#24050;&#32463;&#34987;&#24191;&#27867;&#35752;&#35770;&#12290;&#22914;&#26524;&#25105;&#20204;&#23558;&#25968;&#25454;&#35299;&#37322;&#20026;&#20449;&#21495;&#21644;&#22122;&#22768;&#30340;&#32452;&#21512;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#23545;&#38477;&#32500;&#25216;&#26415;&#30340;&#35780;&#21028;&#26159;&#20854;&#26159;&#21542;&#33021;&#22815;&#25429;&#25417;&#21040;&#25968;&#25454;&#30340;&#20840;&#37096;&#20869;&#23481;&#65292;&#21363;&#20449;&#21495;&#21644;&#22122;&#22768;&#12290;&#22312;&#20854;&#20182;&#24314;&#27169;&#38382;&#39064;&#30340;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#20250;&#37319;&#29992;&#29305;&#24449;&#36873;&#25321;&#12289;&#20132;&#21449;&#39564;&#35777;&#21644;&#27491;&#21017;&#21270;&#31561;&#25216;&#26415;&#26469;&#38450;&#27490;&#36807;&#25311;&#21512;&#65292;&#20294;&#22312;&#36827;&#34892;&#38477;&#32500;&#26102;&#21364;&#27809;&#26377;&#37319;&#21462;&#31867;&#20284;&#30340;&#39044;&#38450;&#25514;&#26045;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#22122;&#22768;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#24314;&#27169;&#38477;&#32500;&#38382;&#39064;&#65292;&#24182;&#21033;&#29992;&#35813;&#26694;&#26550;&#25506;&#32034;&#20102;&#22256;&#24785;&#24230;&#21644;&#32500;&#24230;&#25968;&#37327;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
The goal of dimension reduction tools is to construct a low-dimensional representation of high-dimensional data. These tools are employed for a variety of reasons such as noise reduction, visualization, and to lower computational costs. However, there is a fundamental issue that is highly discussed in other modeling problems, but almost entirely ignored in the dimension reduction literature: overfitting. If we interpret data as a combination of signal and noise, prior works judge dimension reduction techniques on their ability to capture the entirety of the data, i.e. both the signal and the noise. In the context of other modeling problems, techniques such as feature-selection, cross-validation, and regularization are employed to combat overfitting, but no such precautions are taken when performing dimension reduction. In this paper, we present a framework that models dimension reduction problems in the presence of noise and use this framework to explore the role perplexity and number 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#24102;&#26377;&#26080;&#30028;&#26041;&#24046;&#30340;&#26377;&#20559;&#22122;&#22768;&#23545;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#30340;&#24433;&#21709;&#65292;&#24182;&#20171;&#32461;&#20102;&#35813;&#31639;&#27861;&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2312.02828</link><description>&lt;p&gt;
&#38543;&#26426;&#36924;&#36817;&#30340;&#25910;&#25947;&#36895;&#24230;&#65306;&#24102;&#26377;&#26080;&#30028;&#26041;&#24046;&#30340;&#26377;&#20559;&#22122;&#22768;&#21644;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Convergence Rates for Stochastic Approximation: Biased Noise with Unbounded Variance, and Applications. (arXiv:2312.02828v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.02828
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#24102;&#26377;&#26080;&#30028;&#26041;&#24046;&#30340;&#26377;&#20559;&#22122;&#22768;&#23545;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#30340;&#24433;&#21709;&#65292;&#24182;&#20171;&#32461;&#20102;&#35813;&#31639;&#27861;&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
1951&#24180;&#32599;&#23486;&#26031;&#21644;&#33707;&#27931;&#24341;&#20837;&#30340;&#38543;&#26426;&#36924;&#36817;&#65288;SA&#65289;&#31639;&#27861;&#24050;&#32463;&#25104;&#20026;&#35299;&#26041;&#31243;$\mathbf{f}({\boldsymbol{\theta}}) = \mathbf{0}$&#30340;&#26631;&#20934;&#26041;&#27861;&#65292;&#24403;&#21482;&#26377;$\mathbf{f}(\cdot)$&#30340;&#24102;&#22122;&#22768;&#27979;&#37327;&#21487;&#29992;&#26102;&#12290;&#22914;&#26524;&#23545;&#20110;&#26576;&#20010;&#20989;&#25968;$J(\cdot)$&#65292;$\mathbf{f}({\boldsymbol{\theta}}) = \nabla J({\boldsymbol{\theta}})$&#65292;&#37027;&#20040;SA&#20063;&#21487;&#20197;&#29992;&#26469;&#23547;&#25214;$J(\cdot)$&#30340;&#19968;&#20010;&#31283;&#23450;&#28857;&#12290;&#22312;&#27599;&#20010;&#26102;&#38388;$t$&#65292;&#24403;&#21069;&#30340;&#29468;&#27979;${\boldsymbol{\theta}}_t$&#36890;&#36807;&#24418;&#24335;&#20026;$\mathbf{f}({\boldsymbol{\theta}}_t) + {\boldsymbol{\xi}}_{t+1}$&#30340;&#24102;&#22122;&#22768;&#27979;&#37327;&#26356;&#26032;&#20026;${\boldsymbol{\theta}}_{t+1}$&#12290;&#22312;&#35768;&#22810;&#25991;&#29486;&#20013;&#65292;&#20551;&#35774;&#35823;&#24046;&#39033;${\boldsymbol{\xi}}_{t+1}$&#30340;&#26465;&#20214;&#22343;&#20540;&#20026;&#38646;&#65292;&#21644;/&#25110;&#32773;&#23427;&#30340;&#26465;&#20214;&#26041;&#24046;&#38543;$t$&#65288;&#32780;&#19981;&#26159;${\boldsymbol{\theta}}_t$&#65289;&#34987;&#38480;&#21046;&#12290;&#22810;&#24180;&#26469;&#65292;SA&#24050;&#32463;&#24212;&#29992;&#20110;&#21508;&#31181;&#39046;&#22495;&#65292;&#26412;&#25991;&#37325;&#28857;&#30740;&#31350;&#20854;&#20013;&#19968;&#20010;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Stochastic Approximation (SA) algorithm introduced by Robbins and Monro in 1951 has been a standard method for solving equations of the form $\mathbf{f}({\boldsymbol {\theta}}) = \mathbf{0}$, when only noisy measurements of $\mathbf{f}(\cdot)$ are available. If $\mathbf{f}({\boldsymbol {\theta}}) = \nabla J({\boldsymbol {\theta}})$ for some function $J(\cdot)$, then SA can also be used to find a stationary point of $J(\cdot)$. At each time $t$, the current guess ${\boldsymbol {\theta}}_t$ is updated to ${\boldsymbol {\theta}}_{t+1}$ using a noisy measurement of the form $\mathbf{f}({\boldsymbol {\theta}}_t) + {\boldsymbol {\xi}}_{t+1}$. In much of the literature, it is assumed that the error term ${\boldsymbol {\xi}}_{t+1}$ has zero conditional mean, and/or that its conditional variance is bounded as a function of $t$ (though not necessarily with respect to ${\boldsymbol {\theta}}_t$). Over the years, SA has been applied to a variety of areas, out of which the focus in this paper i
&lt;/p&gt;</description></item><item><title>&#22810;&#21333;&#20803;&#36719;&#27979;&#37327;&#26159;&#21033;&#29992;&#21487;&#36716;&#31227;&#24615;&#23398;&#20064;&#31639;&#27861;&#25913;&#36827;&#36719;&#27979;&#37327;&#30340;&#19968;&#31181;&#26041;&#27861;&#65292;&#33021;&#22815;&#36890;&#36807;&#35299;&#20915;&#22810;&#20010;&#20219;&#21153;&#26469;&#22686;&#24378;&#36719;&#27979;&#37327;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#29305;&#21035;&#36866;&#29992;&#20110;&#20855;&#26377;&#22810;&#20010;&#23454;&#29616;&#30340;&#36827;&#31243;&#12290;</title><link>http://arxiv.org/abs/2309.15828</link><description>&lt;p&gt;
&#22810;&#21333;&#20803;&#36719;&#27979;&#37327;&#20801;&#35768;&#23569;&#26679;&#26412;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Multi-unit soft sensing permits few-shot learning. (arXiv:2309.15828v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.15828
&lt;/p&gt;
&lt;p&gt;
&#22810;&#21333;&#20803;&#36719;&#27979;&#37327;&#26159;&#21033;&#29992;&#21487;&#36716;&#31227;&#24615;&#23398;&#20064;&#31639;&#27861;&#25913;&#36827;&#36719;&#27979;&#37327;&#30340;&#19968;&#31181;&#26041;&#27861;&#65292;&#33021;&#22815;&#36890;&#36807;&#35299;&#20915;&#22810;&#20010;&#20219;&#21153;&#26469;&#22686;&#24378;&#36719;&#27979;&#37327;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#29305;&#21035;&#36866;&#29992;&#20110;&#20855;&#26377;&#22810;&#20010;&#23454;&#29616;&#30340;&#36827;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#30340;&#30740;&#31350;&#25506;&#32034;&#20102;&#21033;&#29992;&#20855;&#26377;&#21487;&#36716;&#31227;&#24615;&#30340;&#23398;&#20064;&#31639;&#27861;&#26469;&#25913;&#36827;&#36719;&#27979;&#37327;&#30340;&#21508;&#31181;&#26041;&#27861;&#12290;&#24635;&#20307;&#26469;&#35828;&#65292;&#24403;&#19968;&#20010;&#36719;&#27979;&#37327;&#36890;&#36807;&#35299;&#20915;&#22810;&#20010;&#20219;&#21153;&#26469;&#23398;&#20064;&#26102;&#65292;&#20854;&#24615;&#33021;&#21487;&#20197;&#24471;&#21040;&#21152;&#24378;&#12290;&#21487;&#36716;&#31227;&#24615;&#30340;&#26377;&#29992;&#24615;&#21462;&#20915;&#20110;&#25152;&#35774;&#35745;&#30340;&#23398;&#20064;&#20219;&#21153;&#30340;&#30456;&#20851;&#24615;&#12290;&#22312;&#36719;&#27979;&#37327;&#35201;&#24212;&#29992;&#20110;&#26377;&#22810;&#20010;&#23454;&#29616;&#30340;&#36827;&#31243;&#65288;&#20363;&#22914;&#65292;&#26377;&#22810;&#20010;&#21487;&#29992;&#25968;&#25454;&#30340;&#31995;&#32479;&#25110;&#35774;&#22791;&#65289;&#26102;&#65292;&#23588;&#20854;&#30456;&#20851;&#12290;&#28982;&#21518;&#65292;&#27599;&#20010;&#23454;&#29616;&#37117;&#25552;&#20379;&#19968;&#20010;&#36719;&#27979;&#37327;&#23398;&#20064;&#20219;&#21153;&#65292;&#24182;&#19988;&#21512;&#29702;&#22320;&#26399;&#26395;&#36825;&#20123;&#19981;&#21516;&#20219;&#21153;&#20043;&#38388;&#20855;&#26377;&#24378;&#30456;&#20851;&#24615;&#12290;&#22312;&#36825;&#31181;&#35774;&#32622;&#20013;&#24212;&#29992;&#21487;&#36716;&#31227;&#24615;&#23548;&#33268;&#20102;&#25105;&#20204;&#25152;&#31216;&#30340;&#22810;&#21333;&#20803;&#36719;&#27979;&#37327;&#65292;&#20854;&#20013;&#36719;&#27979;&#37327;&#36890;&#36807;&#20174;&#25152;&#26377;&#23454;&#29616;&#30340;&#25968;&#25454;&#20013;&#23398;&#20064;&#26469;&#24314;&#27169;&#19968;&#20010;&#36827;&#31243;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#22810;&#21333;&#20803;&#36719;&#27979;&#37327;&#30340;&#23398;&#20064;&#33021;&#21147;&#65292;&#23427;&#34987;&#26500;&#24314;&#20026;&#19968;&#20010;&#20998;&#23618;&#27169;&#22411;&#65292;&#24182;&#20351;&#29992;...
&lt;/p&gt;
&lt;p&gt;
Recent literature has explored various ways to improve soft sensors using learning algorithms with transferability. Broadly put, the performance of a soft sensor may be strengthened when it is learned by solving multiple tasks. The usefulness of transferability depends on how strongly related the devised learning tasks are. A particularly relevant case for transferability, is when a soft sensor is to be developed for a process of which there are many realizations, e.g. system or device with many implementations from which data is available. Then, each realization presents a soft sensor learning task, and it is reasonable to expect that the different tasks are strongly related. Applying transferability in this setting leads to what we call multi-unit soft sensing, where a soft sensor models a process by learning from data from all of its realizations.  This paper explores the learning abilities of a multi-unit soft sensor, which is formulated as a hierarchical model and implemented usin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#31163;&#25955;&#20999;&#21106;Wasserstein&#25439;&#22833;&#30340;&#24615;&#36136;&#65292;&#24182;&#25506;&#35752;&#20102;&#20854;&#27491;&#21017;&#24615;&#21644;&#20248;&#21270;&#24615;&#36136;&#20197;&#21450;&#36890;&#36807;&#33945;&#29305;&#21345;&#27931;&#36817;&#20284;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.10352</link><description>&lt;p&gt;
&#31163;&#25955;&#20999;&#21106;Wasserstein&#25439;&#22833;&#30340;&#24615;&#36136;
&lt;/p&gt;
&lt;p&gt;
Properties of Discrete Sliced Wasserstein Losses. (arXiv:2307.10352v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10352
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31163;&#25955;&#20999;&#21106;Wasserstein&#25439;&#22833;&#30340;&#24615;&#36136;&#65292;&#24182;&#25506;&#35752;&#20102;&#20854;&#27491;&#21017;&#24615;&#21644;&#20248;&#21270;&#24615;&#36136;&#20197;&#21450;&#36890;&#36807;&#33945;&#29305;&#21345;&#27931;&#36817;&#20284;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20999;&#21106;Wasserstein&#65288;SW&#65289;&#36317;&#31163;&#24050;&#25104;&#20026;&#27604;&#36739;&#27010;&#29575;&#27979;&#24230;&#30340;Wasserstein&#36317;&#31163;&#30340;&#19968;&#31181;&#27969;&#34892;&#26367;&#20195;&#26041;&#27861;&#12290;&#24191;&#27867;&#24212;&#29992;&#21253;&#25324;&#22270;&#20687;&#22788;&#29702;&#12289;&#39046;&#22495;&#33258;&#36866;&#24212;&#21644;&#29983;&#25104;&#24314;&#27169;&#65292;&#24120;&#24120;&#38656;&#35201;&#20248;&#21270;&#19968;&#20123;&#21442;&#25968;&#20197;&#26368;&#23567;&#21270;SW&#65292;&#35813;&#21442;&#25968;&#20805;&#24403;&#31163;&#25955;&#27010;&#29575;&#27979;&#24230;&#20043;&#38388;&#30340;&#25439;&#22833;&#20989;&#25968;&#65288;&#22240;&#20026;&#20855;&#26377;&#23494;&#24230;&#30340;&#27979;&#24230;&#22312;&#25968;&#20540;&#19978;&#26159;&#26080;&#27861;&#23454;&#29616;&#30340;&#65289;&#12290;&#25152;&#26377;&#36825;&#20123;&#20248;&#21270;&#38382;&#39064;&#37117;&#23384;&#22312;&#30456;&#21516;&#30340;&#23376;&#38382;&#39064;&#65292;&#21363;&#26368;&#23567;&#21270;&#20999;&#21106;Wasserstein&#33021;&#37327;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;$\mathcal{E}: Y \longmapsto \mathrm{SW}_2^2(\gamma_Y, \gamma_Z)$&#30340;&#23646;&#24615;&#65292;&#21363;&#20004;&#20010;&#20855;&#26377;&#19982;&#19968;&#20010;&#27979;&#24230;&#30340;&#25903;&#25745;&#30456;&#21516;&#25968;&#37327;&#30340;&#31163;&#25955;&#22343;&#21248;&#27979;&#24230;&#20043;&#38388;&#30340;SW&#36317;&#31163;&#20316;&#20026;&#25903;&#25745;$Y \in \mathbb{R}^{n \times d}$&#20989;&#25968;&#30340;&#33021;&#37327;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#36825;&#20010;&#33021;&#37327;&#30340;&#27491;&#21017;&#24615;&#21644;&#20248;&#21270;&#24615;&#36136;&#65292;&#20197;&#21450;&#20854;&#36890;&#36807;&#33945;&#29305;&#21345;&#27931;&#36817;&#20284;$\mathcal{E}_p$&#65288;&#20351;&#29992;SW&#20013;&#30340;&#26399;&#26395;&#20272;&#35745;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Sliced Wasserstein (SW) distance has become a popular alternative to the Wasserstein distance for comparing probability measures. Widespread applications include image processing, domain adaptation and generative modelling, where it is common to optimise some parameters in order to minimise SW, which serves as a loss function between discrete probability measures (since measures admitting densities are numerically unattainable). All these optimisation problems bear the same sub-problem, which is minimising the Sliced Wasserstein energy. In this paper we study the properties of $\mathcal{E}: Y \longmapsto \mathrm{SW}_2^2(\gamma_Y, \gamma_Z)$, i.e. the SW distance between two uniform discrete measures with the same amount of points as a function of the support $Y \in \mathbb{R}^{n \times d}$ of one of the measures. We investigate the regularity and optimisation properties of this energy, as well as its Monte-Carlo approximation $\mathcal{E}_p$ (estimating the expectation in SW using 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#25913;&#30340;&#24452;&#21521;&#22522;&#20989;&#25968;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#36890;&#36807;&#23398;&#20064;&#31934;&#24230;&#30697;&#38453;&#65292;&#20174;&#35757;&#32451;&#23436;&#25104;&#21518;&#30340;&#27169;&#22411;&#20013;&#25552;&#21462;&#26377;&#29992;&#20449;&#24687;&#65292;&#21253;&#25324;&#27963;&#36291;&#23376;&#31354;&#38388;&#30340;&#26041;&#21521;&#21644;&#36755;&#20837;&#21464;&#37327;&#37325;&#35201;&#24615;&#30340;&#25490;&#24207;&#12290;</title><link>http://arxiv.org/abs/2307.05639</link><description>&lt;p&gt;
&#20351;&#29992;&#39640;&#26031;&#24452;&#21521;&#22522;&#20989;&#25968;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#27963;&#36291;&#23376;&#31354;&#38388;&#24182;&#21457;&#29616;&#37325;&#35201;&#29305;&#24449;
&lt;/p&gt;
&lt;p&gt;
Learning Active Subspaces and Discovering Important Features with Gaussian Radial Basis Functions Neural Networks. (arXiv:2307.05639v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05639
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#25913;&#30340;&#24452;&#21521;&#22522;&#20989;&#25968;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#36890;&#36807;&#23398;&#20064;&#31934;&#24230;&#30697;&#38453;&#65292;&#20174;&#35757;&#32451;&#23436;&#25104;&#21518;&#30340;&#27169;&#22411;&#20013;&#25552;&#21462;&#26377;&#29992;&#20449;&#24687;&#65292;&#21253;&#25324;&#27963;&#36291;&#23376;&#31354;&#38388;&#30340;&#26041;&#21521;&#21644;&#36755;&#20837;&#21464;&#37327;&#37325;&#35201;&#24615;&#30340;&#25490;&#24207;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25552;&#20379;&#19968;&#20010;&#26082;&#33021;&#36798;&#21040;&#24378;&#22823;&#39044;&#27979;&#24615;&#33021;&#65292;&#21448;&#33021;&#34987;&#20154;&#31867;&#35299;&#37322;&#30340;&#27169;&#22411;&#26159;&#26426;&#22120;&#23398;&#20064;&#30740;&#31350;&#20013;&#26368;&#22256;&#38590;&#30340;&#25361;&#25112;&#20043;&#19968;&#65292;&#30001;&#20110;&#36825;&#20004;&#20010;&#30446;&#26631;&#30340;&#20914;&#31361;&#24615;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#25913;&#30340;&#24452;&#21521;&#22522;&#20989;&#25968;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#36890;&#36807;&#20026;&#20854;&#39640;&#26031;&#26680;&#28155;&#21152;&#21487;&#23398;&#20064;&#30340;&#31934;&#24230;&#30697;&#38453;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#35757;&#32451;&#23436;&#25104;&#21518;&#21487;&#20197;&#20174;&#31934;&#24230;&#30697;&#38453;&#30340;&#35889;&#20013;&#25552;&#21462;&#23453;&#36149;&#30340;&#20449;&#24687;&#12290;&#29305;&#21035;&#26159;&#65292;&#29305;&#24449;&#21521;&#37327;&#35299;&#37322;&#20102;&#27169;&#22411;&#26368;&#25935;&#24863;&#30340;&#26041;&#21521;&#65292;&#25581;&#31034;&#20102;&#27963;&#36291;&#23376;&#31354;&#38388;&#65292;&#24182;&#25552;&#20986;&#20102;&#29992;&#20110;&#30417;&#30563;&#38477;&#32500;&#30340;&#28508;&#22312;&#24212;&#29992;&#12290;&#21516;&#26102;&#65292;&#29305;&#24449;&#21521;&#37327;&#20984;&#26174;&#20102;&#36755;&#20837;&#21644;&#28508;&#22312;&#21464;&#37327;&#20043;&#38388;&#30340;&#32477;&#23545;&#21464;&#21270;&#20851;&#31995;&#65292;&#20174;&#32780;&#20351;&#25105;&#20204;&#33021;&#22815;&#22522;&#20110;&#20854;&#23545;&#39044;&#27979;&#30340;&#37325;&#35201;&#24615;&#25552;&#21462;&#36755;&#20837;&#21464;&#37327;&#30340;&#25490;&#24207;&#12290;
&lt;/p&gt;
&lt;p&gt;
Providing a model that achieves a strong predictive performance and at the same time is interpretable by humans is one of the most difficult challenges in machine learning research due to the conflicting nature of these two objectives. To address this challenge, we propose a modification of the Radial Basis Function Neural Network model by equipping its Gaussian kernel with a learnable precision matrix. We show that precious information is contained in the spectrum of the precision matrix that can be extracted once the training of the model is completed. In particular, the eigenvectors explain the directions of maximum sensitivity of the model revealing the active subspace and suggesting potential applications for supervised dimensionality reduction. At the same time, the eigenvectors highlight the relationship in terms of absolute variation between the input and the latent variables, thereby allowing us to extract a ranking of the input variables based on their importance to the predi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#24230;&#30456;&#20284;&#30340;&#21464;&#20998;&#21518;&#39564;&#20998;&#24067;&#21644;&#20808;&#39564;&#20998;&#24067;&#20043;&#38388;&#30340;&#21518;&#39564;&#23849;&#28291;&#29616;&#35937;&#65292;&#29305;&#21035;&#22320;&#65292;&#36890;&#36807;&#23545;&#32447;&#24615;&#26465;&#20214;VAE&#21644;&#20998;&#23618;VAE&#36827;&#34892;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#36825;&#31181;&#29616;&#35937;&#26159;&#30001;&#20110;&#28508;&#22312;&#21464;&#37327;&#23618;&#27425;&#20851;&#31995;&#19981;&#28165;&#26224;&#32780;&#24341;&#36215;&#30340;&#12290;</title><link>http://arxiv.org/abs/2306.05023</link><description>&lt;p&gt;
&#32447;&#24615;&#26465;&#20214;VAE&#21644;&#20998;&#23618;VAE&#20013;&#30340;&#21518;&#39564;&#23849;&#28291;&#29616;&#35937;
&lt;/p&gt;
&lt;p&gt;
Posterior Collapse in Linear Conditional and Hierarchical Variational Autoencoders. (arXiv:2306.05023v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05023
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#24230;&#30456;&#20284;&#30340;&#21464;&#20998;&#21518;&#39564;&#20998;&#24067;&#21644;&#20808;&#39564;&#20998;&#24067;&#20043;&#38388;&#30340;&#21518;&#39564;&#23849;&#28291;&#29616;&#35937;&#65292;&#29305;&#21035;&#22320;&#65292;&#36890;&#36807;&#23545;&#32447;&#24615;&#26465;&#20214;VAE&#21644;&#20998;&#23618;VAE&#36827;&#34892;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#36825;&#31181;&#29616;&#35937;&#26159;&#30001;&#20110;&#28508;&#22312;&#21464;&#37327;&#23618;&#27425;&#20851;&#31995;&#19981;&#28165;&#26224;&#32780;&#24341;&#36215;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#20013;&#65292;&#21518;&#39564;&#23849;&#28291;&#29616;&#35937;&#25351;&#30340;&#26159;&#21464;&#20998;&#21518;&#39564;&#20998;&#24067;&#19982;&#20808;&#39564;&#20998;&#24067;&#30340;&#30456;&#20284;&#24230;&#36807;&#39640;&#65292;&#23548;&#33268;&#32534;&#30721;&#22120;&#25552;&#21462;&#30340;&#28508;&#22312;&#21464;&#37327;&#20445;&#23384;&#30340;&#36755;&#20837;&#25968;&#25454;&#20449;&#24687;&#36739;&#23569;&#65292;&#26080;&#27861;&#20026;&#35299;&#30721;&#22120;&#30340;&#25968;&#25454;&#37325;&#24314;&#36807;&#31243;&#20135;&#29983;&#26377;&#24847;&#20041;&#30340;&#34920;&#31034;&#12290;&#23613;&#31649;&#35813;&#29616;&#35937;&#19968;&#30452;&#26159;VAEs&#24615;&#33021;&#30340;&#30740;&#31350;&#28909;&#28857;&#65292;&#20294;&#26159;&#23545;&#20110;&#21518;&#39564;&#23849;&#28291;&#30340;&#29702;&#35770;&#21364;&#30456;&#23545;&#34180;&#24369;&#65292;&#29305;&#21035;&#26159;&#22312;&#38750;&#26631;&#20934;&#30340;VAEs&#20013;&#12290;&#26412;&#25991;&#36890;&#36807;&#23545;&#20004;&#31867;&#37325;&#35201;&#32780;&#24120;&#35265;&#21448;&#36739;&#23569;&#30740;&#31350;&#30340;VAEs&#36827;&#34892;&#38750;&#24179;&#20961;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#21363;&#20855;&#26377;&#20004;&#20010;&#28508;&#22312;&#21464;&#37327;&#23618;&#27425;&#30340;&#32447;&#24615;&#26465;&#20214;VAE&#21644;&#20998;&#23618;VAE&#65292;&#25552;&#21319;&#20102;&#23545;&#21518;&#39564;&#23849;&#28291;&#30340;&#29702;&#35770;&#35748;&#35782;&#65292;&#35777;&#26126;&#20102;&#20854;&#25104;&#22240;&#12290;
&lt;/p&gt;
&lt;p&gt;
The posterior collapse phenomenon in variational autoencoders (VAEs), where the variational posterior distribution closely matches the prior distribution, can hinder the quality of the learned latent variables. As a consequence of posterior collapse, the latent variables extracted by the encoder in VAEs preserve less information from the input data and thus fail to produce meaningful representations as input to the reconstruction process in the decoder. While this phenomenon has been an actively addressed topic related to VAEs performance, the theory for posterior collapse remains underdeveloped, especially beyond the standard VAEs. In this work, we advance the theoretical understanding of posterior collapse to two important and prevalent yet less studied classes of VAEs: conditional VAEs and hierarchical VAEs. Specifically, via a non-trivial theoretical analysis of linear conditional VAEs and hierarchical VAEs with two levels of latent, we prove that the cause of posterior collapses i
&lt;/p&gt;</description></item><item><title>MAGDiff&#26159;&#19968;&#31181;&#26032;&#30340;&#34920;&#31034;&#27861;&#65292;&#21487;&#20197;&#20174;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#20013;&#25552;&#21462;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#26816;&#27979;&#21327;&#21464;&#25968;&#25454;&#38598;&#36716;&#31227;&#65292;&#32780;&#19981;&#38656;&#35201;&#35757;&#32451;&#26032;&#27169;&#22411;&#12290;&#36825;&#21487;&#20197;&#36890;&#36807;&#23545;&#27604;&#31070;&#32463;&#32593;&#32476;&#28608;&#27963;&#22270;&#26469;&#35745;&#31639;&#65292;&#24182;&#36890;&#36807;&#20004;&#20010;&#26679;&#26412; Kolmogorov-Smirnov &#27979;&#35797;&#36827;&#34892;&#23454;&#35777;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2305.13271</link><description>&lt;p&gt;
MAGDiff: &#21033;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#28608;&#27963;&#22270;&#26816;&#27979;&#21327;&#21464;&#25968;&#25454;&#38598;&#36716;&#31227;
&lt;/p&gt;
&lt;p&gt;
MAGDiff: Covariate Data Set Shift Detection via Activation Graphs of Deep Neural Networks. (arXiv:2305.13271v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13271
&lt;/p&gt;
&lt;p&gt;
MAGDiff&#26159;&#19968;&#31181;&#26032;&#30340;&#34920;&#31034;&#27861;&#65292;&#21487;&#20197;&#20174;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#20013;&#25552;&#21462;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#26816;&#27979;&#21327;&#21464;&#25968;&#25454;&#38598;&#36716;&#31227;&#65292;&#32780;&#19981;&#38656;&#35201;&#35757;&#32451;&#26032;&#27169;&#22411;&#12290;&#36825;&#21487;&#20197;&#36890;&#36807;&#23545;&#27604;&#31070;&#32463;&#32593;&#32476;&#28608;&#27963;&#22270;&#26469;&#35745;&#31639;&#65292;&#24182;&#36890;&#36807;&#20004;&#20010;&#26679;&#26412; Kolmogorov-Smirnov &#27979;&#35797;&#36827;&#34892;&#23454;&#35777;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#31070;&#32463;&#32593;&#32476;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#21508;&#31181;&#20219;&#21153;&#65292;&#20294;&#20687;&#20854;&#20182;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#19968;&#26679;&#65292;&#23427;&#20204;&#21463;&#21040;&#25968;&#25454;&#36716;&#31227;&#30340;&#24433;&#21709;&#65292;&#22312;&#35757;&#32451;&#25968;&#25454;&#19982;&#23454;&#38469;&#24212;&#29992;&#25968;&#25454;&#20043;&#38388;&#20998;&#24067;&#23384;&#22312;&#24046;&#24322;&#26102;&#65292;&#20854;&#24615;&#33021;&#20250;&#21463;&#21040;&#20005;&#37325;&#24433;&#21709;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026; MAGDiff &#30340;&#26032;&#34920;&#31034;&#26041;&#27861;&#65292;&#21487;&#20197;&#20174;&#20219;&#20309;&#32473;&#23450;&#30340;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#20013;&#25552;&#21462;&#20986;&#26469;&#65292;&#24182;&#19988;&#21487;&#20197;&#26377;&#25928;&#22320;&#26816;&#27979;&#21327;&#21464;&#25968;&#25454;&#38598;&#36716;&#31227;&#65292;&#32780;&#19981;&#38656;&#35201;&#35757;&#32451;&#19987;&#38376;&#29992;&#20110;&#27492;&#20219;&#21153;&#30340;&#26032;&#27169;&#22411;&#12290;&#36825;&#20123;&#34920;&#31034;&#24418;&#24335;&#26159;&#36890;&#36807;&#27604;&#36739;&#31070;&#32463;&#32593;&#32476;&#28608;&#27963;&#22270;&#26469;&#35745;&#31639;&#30340;&#65292;&#23545;&#20110;&#23646;&#20110;&#35757;&#32451;&#20998;&#24067;&#21644;&#30446;&#26631;&#20998;&#24067;&#30340;&#26679;&#26412;&#65292;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#25968;&#25454;&#21644;&#20219;&#21153;&#33258;&#36866;&#24212;&#32479;&#35745;&#37327;&#65292;&#29992;&#20110;&#26816;&#27979;&#24120;&#29992;&#30340;&#25968;&#25454;&#38598;&#36716;&#31227;&#30340;&#20004;&#20010;&#26679;&#26412;&#27979;&#35797;&#12290;&#25105;&#20204;&#36890;&#36807;&#27979;&#37327;&#20004;&#20010;&#26679;&#26412; Kolmogorov-Smirnov&#65288;KS&#65289;&#27979;&#35797;&#30340;&#32479;&#35745;&#21151;&#29575;&#36827;&#34892;&#20102;&#23454;&#35777;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite their successful application to a variety of tasks, neural networks remain limited, like other machine learning methods, by their sensitivity to shifts in the data: their performance can be severely impacted by differences in distribution between the data on which they were trained and that on which they are deployed. In this article, we propose a new family of representations, called MAGDiff, that we extract from any given neural network classifier and that allows for efficient covariate data shift detection without the need to train a new model dedicated to this task. These representations are computed by comparing the activation graphs of the neural network for samples belonging to the training distribution and to the target distribution, and yield powerful data- and task-adapted statistics for the two-sample tests commonly used for data set shift detection. We demonstrate this empirically by measuring the statistical powers of two-sample Kolmogorov-Smirnov (KS) tests on sev
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#20351;&#29992;&#25968;&#25454;&#30340;&#37327;&#23376;&#36153;&#33293;&#23572;&#20449;&#24687;&#24230;&#37327;&#26469;&#35780;&#20272;&#25104;&#21151;&#35757;&#32451;&#21644;&#27867;&#21270;&#25152;&#38656;&#30340;&#30005;&#36335;&#21442;&#25968;&#21644;&#35757;&#32451;&#25968;&#25454;&#30340;&#25968;&#37327;&#65292;&#24182;&#23637;&#31034;&#36890;&#36807;&#21435;&#38500;&#23545;&#31216;&#24615;&#26469;&#25552;&#39640;&#27867;&#21270;&#33021;&#21147;&#65292;&#21516;&#26102;&#21457;&#29616;&#36229;&#20986;&#20998;&#24067;&#27867;&#21270;&#33021;&#21147;&#21487;&#20197;&#27604;&#20351;&#29992;&#30456;&#21516;&#20998;&#24067;&#26356;&#20248;&#12290;</title><link>http://arxiv.org/abs/2303.13462</link><description>&lt;p&gt;
&#21033;&#29992;&#37327;&#23376;&#20960;&#20309;&#36827;&#34892;&#23398;&#20064;&#24186;&#27491;&#21464;&#25442;&#30340;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Generalization with quantum geometry for learning unitaries. (arXiv:2303.13462v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.13462
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#20351;&#29992;&#25968;&#25454;&#30340;&#37327;&#23376;&#36153;&#33293;&#23572;&#20449;&#24687;&#24230;&#37327;&#26469;&#35780;&#20272;&#25104;&#21151;&#35757;&#32451;&#21644;&#27867;&#21270;&#25152;&#38656;&#30340;&#30005;&#36335;&#21442;&#25968;&#21644;&#35757;&#32451;&#25968;&#25454;&#30340;&#25968;&#37327;&#65292;&#24182;&#23637;&#31034;&#36890;&#36807;&#21435;&#38500;&#23545;&#31216;&#24615;&#26469;&#25552;&#39640;&#27867;&#21270;&#33021;&#21147;&#65292;&#21516;&#26102;&#21457;&#29616;&#36229;&#20986;&#20998;&#24067;&#27867;&#21270;&#33021;&#21147;&#21487;&#20197;&#27604;&#20351;&#29992;&#30456;&#21516;&#20998;&#24067;&#26356;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27867;&#21270;&#26159;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20174;&#35757;&#32451;&#25968;&#25454;&#23398;&#20064;&#20934;&#30830;&#39044;&#27979;&#26032;&#25968;&#25454;&#30340;&#33021;&#21147;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#24341;&#20837;&#25968;&#25454;&#30340;&#37327;&#23376;&#36153;&#33293;&#23572;&#20449;&#24687;&#24230;&#37327;(DQFIM)&#26469;&#30830;&#23450;&#27169;&#22411;&#20309;&#26102;&#33021;&#22815;&#27867;&#21270;&#12290;&#23545;&#20110;&#24186;&#27491;&#21464;&#25442;&#30340;&#21487;&#21464;&#23398;&#20064;&#65292;DQFIM&#37327;&#21270;&#20102;&#25104;&#21151;&#35757;&#32451;&#21644;&#27867;&#21270;&#25152;&#38656;&#30340;&#30005;&#36335;&#21442;&#25968;&#21644;&#35757;&#32451;&#25968;&#25454;&#30340;&#25968;&#37327;&#12290;&#25105;&#20204;&#24212;&#29992;DQFIM&#26469;&#35299;&#37322;&#20309;&#26102;&#24658;&#23450;&#25968;&#37327;&#30340;&#35757;&#32451;&#29366;&#24577;&#21644;&#22810;&#39033;&#24335;&#25968;&#37327;&#30340;&#21442;&#25968;&#36275;&#20197;&#23454;&#29616;&#27867;&#21270;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#20174;&#35757;&#32451;&#25968;&#25454;&#20013;&#21024;&#38500;&#23545;&#31216;&#24615;&#65292;&#21487;&#20197;&#25552;&#39640;&#27867;&#21270;&#33021;&#21147;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#26174;&#31034;&#65292;&#20351;&#29992;&#19981;&#21516;&#25968;&#25454;&#20998;&#24067;&#36827;&#34892;&#35757;&#32451;&#21644;&#27979;&#35797;&#30340;&#36229;&#20986;&#20998;&#24067;&#27867;&#21270;&#33021;&#21147;&#21487;&#20197;&#27604;&#20351;&#29992;&#30456;&#21516;&#20998;&#24067;&#30340;&#33021;&#21147;&#26356;&#20248;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#20026;&#25552;&#39640;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#27867;&#21270;&#33021;&#21147;&#24320;&#36767;&#20102;&#26032;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generalization is the ability of quantum machine learning models to make accurate predictions on new data by learning from training data. Here, we introduce the data quantum Fisher information metric (DQFIM) to determine when a model can generalize. For variational learning of unitaries, the DQFIM quantifies the amount of circuit parameters and training data needed to successfully train and generalize. We apply the DQFIM to explain when a constant number of training states and polynomial number of parameters are sufficient for generalization. Further, we can improve generalization by removing symmetries from training data. Finally, we show that out-of-distribution generalization, where training and testing data are drawn from different data distributions, can be better than using the same distribution. Our work opens up new approaches to improve generalization in quantum machine learning.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21518;&#26399;&#24773;&#33410;&#24335;&#24378;&#21270;&#23398;&#20064;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#35780;&#20272;&#21453;&#20107;&#23454;&#30340;&#33258;&#36866;&#24212;&#31574;&#30053;&#24182;&#20272;&#35745;&#21160;&#24577;&#22788;&#29702;&#25928;&#24212;&#65292;&#36890;&#36807;&#37325;&#26032;&#21152;&#26435;&#30340;$Z$-&#20272;&#35745;&#26041;&#27861;&#31283;&#23450;&#24773;&#33410;&#21464;&#21270;&#30340;&#20272;&#35745;&#26041;&#24046;&#12290;</title><link>http://arxiv.org/abs/2302.08854</link><description>&lt;p&gt;
&#21518;&#26399;&#24773;&#33410;&#24335;&#24378;&#21270;&#23398;&#20064;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Post-Episodic Reinforcement Learning Inference. (arXiv:2302.08854v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.08854
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21518;&#26399;&#24773;&#33410;&#24335;&#24378;&#21270;&#23398;&#20064;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#35780;&#20272;&#21453;&#20107;&#23454;&#30340;&#33258;&#36866;&#24212;&#31574;&#30053;&#24182;&#20272;&#35745;&#21160;&#24577;&#22788;&#29702;&#25928;&#24212;&#65292;&#36890;&#36807;&#37325;&#26032;&#21152;&#26435;&#30340;$Z$-&#20272;&#35745;&#26041;&#27861;&#31283;&#23450;&#24773;&#33410;&#21464;&#21270;&#30340;&#20272;&#35745;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20174;&#24773;&#33410;&#24335;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#25910;&#38598;&#30340;&#25968;&#25454;&#36827;&#34892;&#20272;&#35745;&#21644;&#25512;&#26029;&#65307;&#21363;&#22312;&#27599;&#20010;&#26102;&#26399;&#65288;&#20063;&#31216;&#20026;&#24773;&#33410;&#65289;&#20197;&#39034;&#24207;&#26041;&#24335;&#19982;&#21333;&#20010;&#21463;&#35797;&#21333;&#20803;&#22810;&#27425;&#20132;&#20114;&#30340;&#33258;&#36866;&#24212;&#35797;&#39564;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#22312;&#25910;&#38598;&#25968;&#25454;&#21518;&#33021;&#22815;&#35780;&#20272;&#21453;&#20107;&#23454;&#30340;&#33258;&#36866;&#24212;&#31574;&#30053;&#65292;&#24182;&#20272;&#35745;&#32467;&#26500;&#21442;&#25968;&#65292;&#22914;&#21160;&#24577;&#22788;&#29702;&#25928;&#24212;&#65292;&#36825;&#21487;&#20197;&#29992;&#20110;&#20449;&#29992;&#20998;&#37197;&#65288;&#20363;&#22914;&#65292;&#31532;&#19968;&#20010;&#26102;&#26399;&#30340;&#34892;&#21160;&#23545;&#26368;&#32456;&#32467;&#26524;&#30340;&#24433;&#21709;&#65289;&#12290;&#36825;&#20123;&#24863;&#20852;&#36259;&#30340;&#21442;&#25968;&#21487;&#20197;&#26500;&#25104;&#30697;&#26041;&#31243;&#30340;&#35299;&#65292;&#20294;&#19981;&#26159;&#24635;&#20307;&#25439;&#22833;&#20989;&#25968;&#30340;&#26368;&#23567;&#21270;&#22120;&#65292;&#22312;&#38745;&#24577;&#25968;&#25454;&#24773;&#20917;&#19979;&#23548;&#33268;&#20102;$Z$-&#20272;&#35745;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#36825;&#26679;&#30340;&#20272;&#35745;&#37327;&#22312;&#33258;&#36866;&#24212;&#25968;&#25454;&#25910;&#38598;&#30340;&#24773;&#20917;&#19979;&#19981;&#33021;&#28176;&#36817;&#27491;&#24577;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#37325;&#26032;&#21152;&#26435;&#30340;$Z$-&#20272;&#35745;&#26041;&#27861;&#65292;&#20351;&#29992;&#31934;&#24515;&#35774;&#35745;&#30340;&#33258;&#36866;&#24212;&#26435;&#37325;&#26469;&#31283;&#23450;&#24773;&#33410;&#21464;&#21270;&#30340;&#20272;&#35745;&#26041;&#24046;&#65292;&#36825;&#26159;&#30001;&#38750;...
&lt;/p&gt;
&lt;p&gt;
We consider estimation and inference with data collected from episodic reinforcement learning (RL) algorithms; i.e. adaptive experimentation algorithms that at each period (aka episode) interact multiple times in a sequential manner with a single treated unit. Our goal is to be able to evaluate counterfactual adaptive policies after data collection and to estimate structural parameters such as dynamic treatment effects, which can be used for credit assignment (e.g. what was the effect of the first period action on the final outcome). Such parameters of interest can be framed as solutions to moment equations, but not minimizers of a population loss function, leading to $Z$-estimation approaches in the case of static data. However, such estimators fail to be asymptotically normal in the case of adaptive data collection. We propose a re-weighted $Z$-estimation approach with carefully designed adaptive weights to stabilize the episode-varying estimation variance, which results from the non
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#26159;&#20851;&#20110;&#23558;&#24378;&#21270;&#23398;&#20064;&#24212;&#29992;&#20110;&#33258;&#36866;&#24212;&#24178;&#39044;&#20013;&#30340;&#31532;&#19968;&#20221;&#32479;&#19968;&#35843;&#26597;&#65292;&#24378;&#21270;&#23398;&#20064;&#22312;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;&#21644;&#31227;&#21160;&#20581;&#24247;&#20013;&#21363;&#26102;&#33258;&#36866;&#24212;&#24178;&#39044;&#36825;&#20004;&#20010;&#39046;&#22495;&#20013;&#37117;&#20855;&#26377;&#24456;&#22823;&#30340;&#24212;&#29992;&#28508;&#21147;&#12290;&#22312;&#36825;&#20004;&#20010;&#39046;&#22495;&#20043;&#38388;&#23384;&#22312;&#30456;&#20284;&#21644;&#19981;&#21516;&#20043;&#22788;&#38656;&#35201;&#32771;&#34385;&#65292;&#24182;&#19988;&#36825;&#37324;&#23384;&#22312;&#24040;&#22823;&#30340;&#21512;&#20316;&#26426;&#20250;&#12290;</title><link>http://arxiv.org/abs/2203.02605</link><description>&lt;p&gt;
&#29616;&#20195;&#29983;&#29289;&#32479;&#35745;&#20013;&#30340;&#24378;&#21270;&#23398;&#20064;&#65306;&#26500;&#24314;&#26368;&#20248;&#33258;&#36866;&#24212;&#24178;&#39044;
&lt;/p&gt;
&lt;p&gt;
Reinforcement Learning in Modern Biostatistics: Constructing Optimal Adaptive Interventions. (arXiv:2203.02605v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.02605
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26159;&#20851;&#20110;&#23558;&#24378;&#21270;&#23398;&#20064;&#24212;&#29992;&#20110;&#33258;&#36866;&#24212;&#24178;&#39044;&#20013;&#30340;&#31532;&#19968;&#20221;&#32479;&#19968;&#35843;&#26597;&#65292;&#24378;&#21270;&#23398;&#20064;&#22312;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;&#21644;&#31227;&#21160;&#20581;&#24247;&#20013;&#21363;&#26102;&#33258;&#36866;&#24212;&#24178;&#39044;&#36825;&#20004;&#20010;&#39046;&#22495;&#20013;&#37117;&#20855;&#26377;&#24456;&#22823;&#30340;&#24212;&#29992;&#28508;&#21147;&#12290;&#22312;&#36825;&#20004;&#20010;&#39046;&#22495;&#20043;&#38388;&#23384;&#22312;&#30456;&#20284;&#21644;&#19981;&#21516;&#20043;&#22788;&#38656;&#35201;&#32771;&#34385;&#65292;&#24182;&#19988;&#36825;&#37324;&#23384;&#22312;&#24040;&#22823;&#30340;&#21512;&#20316;&#26426;&#20250;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#22312;&#19982;&#20581;&#24247;&#30456;&#20851;&#30340;&#24207;&#21015;&#24615;&#20915;&#31574;&#20013;&#21344;&#25454;&#20102;&#37325;&#35201;&#22320;&#20301;&#65292;&#25104;&#20026;&#20132;&#20184;&#33258;&#36866;&#24212;&#24178;&#39044;&#65288;AIs&#65289;&#30340;&#36234;&#26469;&#36234;&#27969;&#34892;&#30340;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#20855;&#26377;&#28508;&#22312;&#20248;&#21183;&#65292;&#20294;&#20854;&#29616;&#23454;&#24212;&#29992;&#20173;&#28982;&#21463;&#21040;&#38480;&#21046;&#65292;&#37096;&#20998;&#26159;&#30001;&#20110;&#26041;&#27861;&#35770;&#21644;&#24212;&#29992;&#31038;&#21306;&#20043;&#38388;&#30340;&#21327;&#21516;&#19981;&#36275;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20851;&#20110;&#23398;&#20064;AIs&#30340;RL&#26041;&#27861;&#30340;&#31532;&#19968;&#20221;&#32479;&#19968;&#35843;&#26597;&#65292;&#21033;&#29992;RL&#30340;&#36890;&#29992;&#26041;&#27861;&#35770;&#20254;&#26469;&#26725;&#25509;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;&#21644;&#31227;&#21160;&#20581;&#24247;&#20013;&#21363;&#26102;&#33258;&#36866;&#24212;&#24178;&#39044;&#36825;&#20004;&#20010;AI&#39046;&#22495;&#12290;&#25105;&#20204;&#27010;&#36848;&#20102;&#36825;&#20004;&#20010;AI&#39046;&#22495;&#20043;&#38388;&#30340;&#24322;&#21516;&#65292;&#24182;&#35752;&#35770;&#20102;&#23427;&#20204;&#23545;&#20351;&#29992;RL&#30340;&#24433;&#21709;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;&#33258;&#24049;&#22312;&#20004;&#20010;&#39046;&#22495;&#20013;&#35774;&#35745;&#26696;&#20363;&#30740;&#31350;&#30340;&#32463;&#39564;&#65292;&#35828;&#26126;&#20102;&#22312;AIs&#39046;&#22495;&#20013;&#65292;&#32479;&#35745;&#23398;&#12289;RL&#21644;&#21307;&#30103;&#30740;&#31350;&#20154;&#21592;&#20043;&#38388;&#30340;&#24040;&#22823;&#21512;&#20316;&#26426;&#20250;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, reinforcement learning (RL) has acquired a prominent position in the space of health-related sequential decision-making, becoming an increasingly popular tool for delivering adaptive interventions (AIs). However, despite potential benefits, its real-life application is still limited, partly due to a poor synergy between the methodological and the applied communities. In this work, we provide the first unified survey on RL methods for learning AIs, using the common methodological umbrella of RL to bridge the two AI areas of dynamic treatment regimes and just-in-time adaptive interventions in mobile health. We outline similarities and differences between these two AI domains and discuss their implications for using RL. Finally, we leverage our experience in designing case studies in both areas to illustrate the tremendous collaboration opportunities between statistical, RL, and healthcare researchers in the space of AIs.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#35268;&#21017;&#30340;&#20998;&#31867;&#20248;&#21270;&#26041;&#27861;&#65292;&#21033;&#29992;&#21015;&#29983;&#25104;&#32447;&#24615;&#35268;&#21010;&#23454;&#29616;&#21487;&#25193;&#23637;&#24615;&#65292;&#24182;&#36890;&#36807;&#20998;&#37197;&#25104;&#26412;&#31995;&#25968;&#21644;&#24341;&#20837;&#39069;&#22806;&#32422;&#26463;&#35299;&#20915;&#20102;&#35299;&#37322;&#24615;&#21644;&#20844;&#24179;&#24615;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#22312;&#23616;&#37096;&#35299;&#37322;&#24615;&#21644;&#20844;&#24179;&#24615;&#20043;&#38388;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#24179;&#34913;&#12290;</title><link>http://arxiv.org/abs/2104.10751</link><description>&lt;p&gt;
&#20998;&#31867;&#35268;&#21017;&#29983;&#25104;&#65306;&#21487;&#25193;&#23637;&#24615;&#65292;&#35299;&#37322;&#24615;&#21644;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Rule Generation for Classification: Scalability, Interpretability, and Fairness. (arXiv:2104.10751v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2104.10751
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#35268;&#21017;&#30340;&#20998;&#31867;&#20248;&#21270;&#26041;&#27861;&#65292;&#21033;&#29992;&#21015;&#29983;&#25104;&#32447;&#24615;&#35268;&#21010;&#23454;&#29616;&#21487;&#25193;&#23637;&#24615;&#65292;&#24182;&#36890;&#36807;&#20998;&#37197;&#25104;&#26412;&#31995;&#25968;&#21644;&#24341;&#20837;&#39069;&#22806;&#32422;&#26463;&#35299;&#20915;&#20102;&#35299;&#37322;&#24615;&#21644;&#20844;&#24179;&#24615;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#22312;&#23616;&#37096;&#35299;&#37322;&#24615;&#21644;&#20844;&#24179;&#24615;&#20043;&#38388;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#35268;&#21017;&#30340;&#20998;&#31867;&#20248;&#21270;&#26041;&#27861;&#65292;&#20855;&#26377;&#32422;&#26463;&#26465;&#20214;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21033;&#29992;&#21015;&#29983;&#25104;&#32447;&#24615;&#35268;&#21010;&#65292;&#22240;&#27492;&#21487;&#25193;&#23637;&#21040;&#22823;&#22411;&#25968;&#25454;&#38598;&#12290;&#25152;&#24471;&#23450;&#20215;&#23376;&#38382;&#39064;&#34987;&#35777;&#26126;&#26159;NP&#38590;&#38382;&#39064;&#12290;&#25105;&#20204;&#37319;&#29992;&#22522;&#20110;&#20915;&#31574;&#26641;&#30340;&#21551;&#21457;&#24335;&#26041;&#27861;&#65292;&#24182;&#35299;&#20915;&#20102;&#19968;&#20010;&#20195;&#29702;&#23450;&#20215;&#23376;&#38382;&#39064;&#20197;&#21152;&#36895;&#12290;&#35813;&#26041;&#27861;&#36820;&#22238;&#19968;&#32452;&#35268;&#21017;&#20197;&#21450;&#23427;&#20204;&#30340;&#26368;&#20248;&#26435;&#37325;&#65292;&#25351;&#31034;&#27599;&#20010;&#35268;&#21017;&#23545;&#23398;&#20064;&#30340;&#37325;&#35201;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#20026;&#35268;&#21017;&#20998;&#37197;&#25104;&#26412;&#31995;&#25968;&#21644;&#24341;&#20837;&#39069;&#22806;&#32422;&#26463;&#26469;&#35299;&#20915;&#35299;&#37322;&#24615;&#21644;&#20844;&#24179;&#24615;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20851;&#27880;&#23616;&#37096;&#35299;&#37322;&#24615;&#65292;&#24182;&#23558;&#20844;&#24179;&#24615;&#30340;&#19968;&#33324;&#20998;&#31163;&#20934;&#21017;&#25512;&#24191;&#21040;&#22810;&#20010;&#25935;&#24863;&#23646;&#24615;&#21644;&#31867;&#21035;&#12290;&#25105;&#20204;&#22312;&#19968;&#31995;&#21015;&#25968;&#25454;&#38598;&#19978;&#27979;&#35797;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#24615;&#33021;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#26696;&#20363;&#30740;&#31350;&#26469;&#35814;&#32454;&#38416;&#36848;&#20854;&#19981;&#21516;&#26041;&#38754;&#12290;&#25152;&#25552;&#20986;&#30340;&#22522;&#20110;&#35268;&#21017;&#30340;&#23398;&#20064;&#26041;&#27861;&#22312;&#23616;&#37096;&#35299;&#37322;&#24615;&#21644;&#20844;&#24179;&#24615;&#20043;&#38388;&#36798;&#21040;&#20102;&#33391;&#22909;&#30340;&#24179;&#34913;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a new rule-based optimization method for classification with constraints. The proposed method leverages column generation for linear programming, and hence, is scalable to large datasets. The resulting pricing subproblem is shown to be NP-Hard. We recourse to a decision tree-based heuristic and solve a proxy pricing subproblem for acceleration. The method returns a set of rules along with their optimal weights indicating the importance of each rule for learning. We address interpretability and fairness by assigning cost coefficients to the rules and introducing additional constraints. In particular, we focus on local interpretability and generalize separation criterion in fairness to multiple sensitive attributes and classes. We test the performance of the proposed methodology on a collection of datasets and present a case study to elaborate on its different aspects. The proposed rule-based learning method exhibits a good compromise between local interpretability and fairn
&lt;/p&gt;</description></item></channel></rss>