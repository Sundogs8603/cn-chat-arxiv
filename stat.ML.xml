<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#23637;&#31034;&#20102;&#23545;&#40784;&#30340;LLM&#23545;&#31616;&#21333;&#33258;&#36866;&#24212;&#36234;&#29425;&#25915;&#20987;&#19981;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#24182;&#25104;&#21151;&#23454;&#29616;&#20102;&#22312;&#22810;&#20010;&#27169;&#22411;&#19978;&#20960;&#20046;100%&#30340;&#25915;&#20987;&#25104;&#21151;&#29575;&#65292;&#21516;&#26102;&#36824;&#20171;&#32461;&#20102;&#23545;&#20110;&#19981;&#20844;&#24320;logprobs&#30340;&#27169;&#22411;&#22914;&#20309;&#36827;&#34892;&#36234;&#29425;&#20197;&#21450;&#22914;&#20309;&#22312;&#21463;&#27745;&#26579;&#30340;&#27169;&#22411;&#20013;&#26597;&#25214;&#26408;&#39532;&#23383;&#31526;&#20018;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2404.02151</link><description>&lt;p&gt;
&#29992;&#31616;&#21333;&#33258;&#36866;&#24212;&#25915;&#20987;&#36234;&#29425;&#21151;&#33021;&#23545;&#40784;&#30340;LLM
&lt;/p&gt;
&lt;p&gt;
Jailbreaking Leading Safety-Aligned LLMs with Simple Adaptive Attacks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02151
&lt;/p&gt;
&lt;p&gt;
&#23637;&#31034;&#20102;&#23545;&#40784;&#30340;LLM&#23545;&#31616;&#21333;&#33258;&#36866;&#24212;&#36234;&#29425;&#25915;&#20987;&#19981;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#24182;&#25104;&#21151;&#23454;&#29616;&#20102;&#22312;&#22810;&#20010;&#27169;&#22411;&#19978;&#20960;&#20046;100%&#30340;&#25915;&#20987;&#25104;&#21151;&#29575;&#65292;&#21516;&#26102;&#36824;&#20171;&#32461;&#20102;&#23545;&#20110;&#19981;&#20844;&#24320;logprobs&#30340;&#27169;&#22411;&#22914;&#20309;&#36827;&#34892;&#36234;&#29425;&#20197;&#21450;&#22914;&#20309;&#22312;&#21463;&#27745;&#26579;&#30340;&#27169;&#22411;&#20013;&#26597;&#25214;&#26408;&#39532;&#23383;&#31526;&#20018;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23637;&#31034;&#20102;&#21363;&#20351;&#26159;&#26368;&#26032;&#30340;&#23433;&#20840;&#23545;&#40784;&#30340;LLM&#20063;&#19981;&#20855;&#26377;&#25269;&#25239;&#31616;&#21333;&#33258;&#36866;&#24212;&#36234;&#29425;&#25915;&#20987;&#30340;&#31283;&#20581;&#24615;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#25104;&#21151;&#21033;&#29992;&#23545;logprobs&#30340;&#35775;&#38382;&#36827;&#34892;&#36234;&#29425;&#65306;&#25105;&#20204;&#26368;&#21021;&#35774;&#35745;&#20102;&#19968;&#20010;&#23545;&#25239;&#24615;&#25552;&#31034;&#27169;&#26495;&#65288;&#26377;&#26102;&#20250;&#36866;&#24212;&#30446;&#26631;LLM&#65289;&#65292;&#28982;&#21518;&#25105;&#20204;&#22312;&#21518;&#32512;&#19978;&#24212;&#29992;&#38543;&#26426;&#25628;&#32034;&#20197;&#26368;&#22823;&#21270;&#30446;&#26631;logprob&#65288;&#20363;&#22914;token&#8220;Sure&#8221;&#65289;&#65292;&#21487;&#33021;&#20250;&#36827;&#34892;&#22810;&#27425;&#37325;&#21551;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#24335;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#23545;GPT-3.5/4&#12289;Llama-2-Chat-7B/13B/70B&#12289;Gemma-7B&#21644;&#38024;&#23545;GCG&#25915;&#20987;&#36827;&#34892;&#23545;&#25239;&#35757;&#32451;&#30340;HarmBench&#19978;&#30340;R2D2&#31561;&#20960;&#20046;100%&#30340;&#25915;&#20987;&#25104;&#21151;&#29575;--&#26681;&#25454;GPT-4&#30340;&#35780;&#21028;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#36716;&#31227;&#25110;&#39044;&#22635;&#20805;&#25915;&#20987;&#20197;100%&#30340;&#25104;&#21151;&#29575;&#23545;&#25152;&#26377;&#19981;&#26292;&#38706;logprobs&#30340;Claude&#27169;&#22411;&#36827;&#34892;&#36234;&#29425;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#22312;&#21463;&#27745;&#26579;&#30340;&#27169;&#22411;&#20013;&#20351;&#29992;&#23545;&#19968;&#32452;&#21463;&#38480;&#21046;&#30340;token&#25191;&#34892;&#38543;&#26426;&#25628;&#32034;&#20197;&#26597;&#25214;&#26408;&#39532;&#23383;&#31526;&#20018;&#30340;&#26041;&#27861;--&#36825;&#39033;&#20219;&#21153;&#19982;&#35768;&#22810;&#20854;&#20182;&#20219;&#21153;&#20849;&#20139;&#30456;&#21516;&#30340;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02151v1 Announce Type: cross  Abstract: We show that even the most recent safety-aligned LLMs are not robust to simple adaptive jailbreaking attacks. First, we demonstrate how to successfully leverage access to logprobs for jailbreaking: we initially design an adversarial prompt template (sometimes adapted to the target LLM), and then we apply random search on a suffix to maximize the target logprob (e.g., of the token "Sure"), potentially with multiple restarts. In this way, we achieve nearly 100\% attack success rate -- according to GPT-4 as a judge -- on GPT-3.5/4, Llama-2-Chat-7B/13B/70B, Gemma-7B, and R2D2 from HarmBench that was adversarially trained against the GCG attack. We also show how to jailbreak all Claude models -- that do not expose logprobs -- via either a transfer or prefilling attack with 100\% success rate. In addition, we show how to use random search on a restricted set of tokens for finding trojan strings in poisoned models -- a task that shares many s
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20351;&#29992;&#25289;&#32454;&#23391;&#21010;&#20998;&#38598;&#65292;&#25105;&#20204;&#33021;&#22815;&#22312;&#22240;&#23376;&#25968;&#25454;&#20013;&#31283;&#20581;&#22320;&#20272;&#35745;&#24322;&#36136;&#24615;&#65292;&#24182;&#23558;&#22240;&#23376;&#31354;&#38388;&#21010;&#20998;&#25104;&#21327;&#21464;&#37327;&#32452;&#21512;&#30340;&#8220;&#27744;&#8221;&#65292;&#20197;&#20415;&#21306;&#20998;&#32467;&#26524;&#30340;&#24046;&#24322;&#12290;</title><link>https://arxiv.org/abs/2404.02141</link><description>&lt;p&gt;
&#20351;&#29992;&#25289;&#32454;&#23391;&#21010;&#20998;&#22312;&#22240;&#23376;&#25968;&#25454;&#20013;&#31283;&#20581;&#20272;&#35745;&#24322;&#36136;&#24615;
&lt;/p&gt;
&lt;p&gt;
Robustly estimating heterogeneity in factorial data using Rashomon Partitions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02141
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;&#25289;&#32454;&#23391;&#21010;&#20998;&#38598;&#65292;&#25105;&#20204;&#33021;&#22815;&#22312;&#22240;&#23376;&#25968;&#25454;&#20013;&#31283;&#20581;&#22320;&#20272;&#35745;&#24322;&#36136;&#24615;&#65292;&#24182;&#23558;&#22240;&#23376;&#31354;&#38388;&#21010;&#20998;&#25104;&#21327;&#21464;&#37327;&#32452;&#21512;&#30340;&#8220;&#27744;&#8221;&#65292;&#20197;&#20415;&#21306;&#20998;&#32467;&#26524;&#30340;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#32479;&#35745;&#20998;&#26512;&#65292;&#26080;&#35770;&#26159;&#22312;&#35266;&#27979;&#25968;&#25454;&#36824;&#26159;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#20013;&#65292;&#37117;&#20250;&#38382;&#65306;&#24863;&#20852;&#36259;&#30340;&#32467;&#26524;&#22914;&#20309;&#38543;&#21487;&#35266;&#23519;&#21327;&#21464;&#37327;&#32452;&#21512;&#21464;&#21270;&#65311;&#19981;&#21516;&#30340;&#33647;&#29289;&#32452;&#21512;&#22914;&#20309;&#24433;&#21709;&#20581;&#24247;&#32467;&#26524;&#65292;&#31185;&#25216;&#37319;&#32435;&#22914;&#20309;&#20381;&#36182;&#28608;&#21169;&#21644;&#20154;&#21475;&#32479;&#35745;&#23398;&#65311;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#23558;&#36825;&#20010;&#22240;&#23376;&#31354;&#38388;&#21010;&#20998;&#25104;&#21327;&#21464;&#37327;&#32452;&#21512;&#30340;&#8220;&#27744;&#8221;&#65292;&#22312;&#36825;&#20123;&#27744;&#20013;&#32467;&#26524;&#20250;&#21457;&#29983;&#24046;&#24322;&#65288;&#20294;&#27744;&#20869;&#37096;&#19981;&#20250;&#21457;&#29983;&#65289;&#65292;&#32780;&#29616;&#26377;&#26041;&#27861;&#35201;&#20040;&#23547;&#25214;&#19968;&#20010;&#21333;&#19968;&#30340;&#8220;&#26368;&#20248;&#8221;&#20998;&#21106;&#65292;&#35201;&#20040;&#20174;&#21487;&#33021;&#20998;&#21106;&#30340;&#25972;&#20010;&#38598;&#21512;&#20013;&#25277;&#26679;&#12290;&#36825;&#20004;&#31181;&#26041;&#27861;&#37117;&#24573;&#35270;&#20102;&#36825;&#26679;&#19968;&#20010;&#20107;&#23454;&#65306;&#29305;&#21035;&#26159;&#22312;&#21327;&#21464;&#37327;&#20043;&#38388;&#23384;&#22312;&#30456;&#20851;&#32467;&#26500;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#33021;&#20197;&#35768;&#22810;&#31181;&#26041;&#24335;&#21010;&#20998;&#21327;&#21464;&#37327;&#31354;&#38388;&#65292;&#22312;&#32479;&#35745;&#19978;&#26159;&#26080;&#27861;&#21306;&#20998;&#30340;&#65292;&#23613;&#31649;&#23545;&#25919;&#31574;&#25110;&#31185;&#23398;&#26377;&#30528;&#38750;&#24120;&#19981;&#21516;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#25289;&#32454;&#23391;&#21010;&#20998;&#38598;&#30340;&#26367;&#20195;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02141v1 Announce Type: cross  Abstract: Many statistical analyses, in both observational data and randomized control trials, ask: how does the outcome of interest vary with combinations of observable covariates? How do various drug combinations affect health outcomes, or how does technology adoption depend on incentives and demographics? Our goal is to partition this factorial space into ``pools'' of covariate combinations where the outcome differs across the pools (but not within a pool). Existing approaches (i) search for a single ``optimal'' partition under assumptions about the association between covariates or (ii) sample from the entire set of possible partitions. Both these approaches ignore the reality that, especially with correlation structure in covariates, many ways to partition the covariate space may be statistically indistinguishable, despite very different implications for policy or science. We develop an alternative perspective, called Rashomon Partition Set
&lt;/p&gt;</description></item><item><title>&#25552;&#20379;&#20102;&#26032;&#30340;&#20840;&#38754;&#36817;&#20284;&#20445;&#35777;&#65292;&#25903;&#25345;&#26368;&#22823;&#22686;&#30410;&#27604;&#29575;&#21644;&#36817;&#20284;&#27425;&#27169;&#20989;&#25968;&#65292;&#21253;&#25324;&#22522;&#25968;&#32422;&#26463;&#19979;&#30340;&#26368;&#22823;&#21270;&#21644;&#26368;&#23567;&#25104;&#26412;&#35206;&#30422;&#20445;&#35777;&#65292;&#24182;&#19988;&#24341;&#20837;&#20102;&#33258;&#36866;&#24212;&#36873;&#25321;&#31574;&#30053;&#30340;&#26032;&#21442;&#25968;&#8220;&#26368;&#22823;&#22686;&#30410;&#27604;&#29575;&#8221;&#12290;</title><link>https://arxiv.org/abs/2404.01930</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#32452;&#21512;&#26368;&#22823;&#21270;&#65306;&#36229;&#36234;&#36817;&#20284;&#36138;&#24515;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Adaptive Combinatorial Maximization: Beyond Approximate Greedy Policies
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01930
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20379;&#20102;&#26032;&#30340;&#20840;&#38754;&#36817;&#20284;&#20445;&#35777;&#65292;&#25903;&#25345;&#26368;&#22823;&#22686;&#30410;&#27604;&#29575;&#21644;&#36817;&#20284;&#27425;&#27169;&#20989;&#25968;&#65292;&#21253;&#25324;&#22522;&#25968;&#32422;&#26463;&#19979;&#30340;&#26368;&#22823;&#21270;&#21644;&#26368;&#23567;&#25104;&#26412;&#35206;&#30422;&#20445;&#35777;&#65292;&#24182;&#19988;&#24341;&#20837;&#20102;&#33258;&#36866;&#24212;&#36873;&#25321;&#31574;&#30053;&#30340;&#26032;&#21442;&#25968;&#8220;&#26368;&#22823;&#22686;&#30410;&#27604;&#29575;&#8221;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#33258;&#36866;&#24212;&#32452;&#21512;&#26368;&#22823;&#21270;&#65292;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#26159;&#19968;&#20010;&#26680;&#24515;&#25361;&#25112;&#65292;&#24212;&#29992;&#20110;&#20027;&#21160;&#23398;&#20064;&#20197;&#21450;&#35768;&#22810;&#20854;&#20182;&#39046;&#22495;&#12290;&#25105;&#20204;&#30740;&#31350;&#36125;&#21494;&#26031;&#35774;&#32622;&#65292;&#24182;&#32771;&#34385;&#22312;&#22522;&#25968;&#32422;&#26463;&#21644;&#26368;&#23567;&#25104;&#26412;&#35206;&#30422;&#19979;&#30340;&#26368;&#22823;&#21270;&#30446;&#26631;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#26032;&#30340;&#20840;&#38754;&#36817;&#20284;&#20445;&#35777;&#65292;&#21253;&#21547;&#20808;&#21069;&#30340;&#32467;&#26524;&#65292;&#24182;&#23545;&#20854;&#36827;&#34892;&#20102;&#26126;&#26174;&#21152;&#24378;&#12290;&#25105;&#20204;&#30340;&#36817;&#20284;&#20445;&#35777;&#21516;&#26102;&#25903;&#25345;&#26368;&#22823;&#22686;&#30410;&#27604;&#29575;&#21644;&#36817;&#20284;&#27425;&#27169;&#20989;&#25968;&#65292;&#24182;&#21253;&#25324;&#22522;&#25968;&#32422;&#26463;&#19979;&#30340;&#26368;&#22823;&#21270;&#21644;&#26368;&#23567;&#25104;&#26412;&#35206;&#30422;&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20026;&#20462;&#25913;&#21518;&#30340;&#20808;&#39564;&#25552;&#20379;&#20102;&#19968;&#20010;&#36817;&#20284;&#20445;&#35777;&#65292;&#36825;&#23545;&#20110;&#33719;&#24471;&#19981;&#21462;&#20915;&#20110;&#20808;&#39564;&#20013;&#26368;&#23567;&#27010;&#29575;&#30340;&#20027;&#21160;&#23398;&#20064;&#20445;&#35777;&#33267;&#20851;&#37325;&#35201;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#33258;&#36866;&#24212;&#36873;&#25321;&#31574;&#30053;&#30340;&#19968;&#20010;&#26032;&#21442;&#25968;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#8220;&#26368;&#22823;&#22686;&#30410;&#27604;&#29575;&#8221;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01930v1 Announce Type: new  Abstract: We study adaptive combinatorial maximization, which is a core challenge in machine learning, with applications in active learning as well as many other domains. We study the Bayesian setting, and consider the objectives of maximization under a cardinality constraint and minimum cost coverage. We provide new comprehensive approximation guarantees that subsume previous results, as well as considerably strengthen them. Our approximation guarantees simultaneously support the maximal gain ratio as well as near-submodular utility functions, and include both maximization under a cardinality constraint and a minimum cost coverage guarantee. In addition, we provided an approximation guarantee for a modified prior, which is crucial for obtaining active learning guarantees that do not depend on the smallest probability in the prior. Moreover, we discover a new parameter of adaptive selection policies, which we term the "maximal gain ratio". We show
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#20855;&#26377;&#20999;&#25442;&#25104;&#26412;&#30340;&#23545;&#25239;&#24615;&#32452;&#21512;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25512;&#23548;&#20102;&#26497;&#23567;&#21518;&#24724;&#30340;&#19979;&#38480;&#24182;&#35774;&#35745;&#20102;&#36924;&#36817;&#31639;&#27861;&#12290;</title><link>https://arxiv.org/abs/2404.01883</link><description>&lt;p&gt;
&#20855;&#26377;&#20999;&#25442;&#25104;&#26412;&#30340;&#23545;&#25239;&#24615;&#32452;&#21512;&#36172;&#21338;&#26426;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Adversarial Combinatorial Bandits with Switching Costs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01883
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#20855;&#26377;&#20999;&#25442;&#25104;&#26412;&#30340;&#23545;&#25239;&#24615;&#32452;&#21512;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25512;&#23548;&#20102;&#26497;&#23567;&#21518;&#24724;&#30340;&#19979;&#38480;&#24182;&#35774;&#35745;&#20102;&#36924;&#36817;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#20999;&#25442;&#25104;&#26412;$\lambda$&#30340;&#23545;&#25239;&#24615;&#32452;&#21512;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#32771;&#34385;&#20102;&#36172;&#21338;&#26426;&#21453;&#39304;&#21644;&#21322;&#36172;&#21338;&#26426;&#21453;&#39304;&#35774;&#32622;&#12290;&#22312;&#24573;&#35270;&#23545;&#25163;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;$K$&#20010;&#22522;&#26412;&#33218;&#21644;&#26102;&#38388;&#36328;&#24230;$T$&#30340;&#26497;&#23567;&#21518;&#24724;&#30340;&#19979;&#38480;&#65292;&#24182;&#35774;&#35745;&#20102;&#31639;&#27861;&#26469;&#36924;&#36817;&#36825;&#20123;&#19979;&#38480;&#12290;&#20026;&#20102;&#35777;&#26126;&#36825;&#20123;&#19979;&#38480;&#65292;&#25105;&#20204;&#20026;&#20004;&#31181;&#21453;&#39304;&#35774;&#32622;&#35774;&#35745;&#20102;&#38543;&#26426;&#25439;&#22833;&#24207;&#21015;&#65292;&#20511;&#37492;&#20102;Dekel&#31561;&#20154;&#65288;2014&#24180;&#65289;&#20043;&#21069;&#24037;&#20316;&#20013;&#30340;&#19968;&#20010;&#24605;&#24819;&#12290;&#36172;&#21338;&#26426;&#21453;&#39304;&#30340;&#19979;&#38480;&#20026;$ \tilde{\Omega}\big( (\lambda K)^{\frac{1}{3}} (TI)^{\frac{2}{3}}\big)$&#65292;&#32780;&#21322;&#36172;&#21338;&#26426;&#21453;&#39304;&#30340;&#19979;&#38480;&#20026;$ \tilde{\Omega}\big( (\lambda K I)^{\frac{1}{3}} T^{\frac{2}{3}}\big)$&#65292;&#20854;&#20013;$I$&#26159;&#22312;&#27599;&#19968;&#36718;&#20013;&#25773;&#25918;&#30340;&#32452;&#21512;&#33218;&#20013;&#30340;&#22522;&#26412;&#33218;&#25968;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01883v1 Announce Type: cross  Abstract: We study the problem of adversarial combinatorial bandit with a switching cost $\lambda$ for a switch of each selected arm in each round, considering both the bandit feedback and semi-bandit feedback settings. In the oblivious adversarial case with $K$ base arms and time horizon $T$, we derive lower bounds for the minimax regret and design algorithms to approach them. To prove these lower bounds, we design stochastic loss sequences for both feedback settings, building on an idea from previous work in Dekel et al. (2014). The lower bound for bandit feedback is $ \tilde{\Omega}\big( (\lambda K)^{\frac{1}{3}} (TI)^{\frac{2}{3}}\big)$ while that for semi-bandit feedback is $ \tilde{\Omega}\big( (\lambda K I)^{\frac{1}{3}} T^{\frac{2}{3}}\big)$ where $I$ is the number of base arms in the combinatorial arm played in each round. To approach these lower bounds, we design algorithms that operate in batches by dividing the time horizon into batc
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#30417;&#30563;&#22411;&#33258;&#32534;&#30721;&#22120;&#30340;&#20351;&#29992;&#21644;&#21442;&#25968;&#35843;&#25972;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#21319;&#37329;&#34701;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#25928;&#26524;&#65292;&#23545;&#25237;&#36164;&#31574;&#30053;&#24615;&#33021;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2404.01866</link><description>&lt;p&gt;
&#30417;&#30563;&#22411;&#33258;&#32534;&#30721;&#22120;&#22810;&#23618;&#24863;&#30693;&#26426;&#29992;&#20110;&#37329;&#34701;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Supervised Autoencoder MLP for Financial Time Series Forecasting
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01866
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#30417;&#30563;&#22411;&#33258;&#32534;&#30721;&#22120;&#30340;&#20351;&#29992;&#21644;&#21442;&#25968;&#35843;&#25972;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#21319;&#37329;&#34701;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#25928;&#26524;&#65292;&#23545;&#25237;&#36164;&#31574;&#30053;&#24615;&#33021;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#36890;&#36807;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#30417;&#30563;&#22411;&#33258;&#32534;&#30721;&#22120;&#26469;&#22686;&#24378;&#37329;&#34701;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#65292;&#26088;&#22312;&#25913;&#21892;&#25237;&#36164;&#31574;&#30053;&#34920;&#29616;&#12290;&#20855;&#20307;&#30740;&#31350;&#20102;&#22122;&#22768;&#22686;&#24378;&#21644;&#19977;&#37325;&#38556;&#30861;&#26631;&#35760;&#23545;&#39118;&#38505;&#35843;&#25972;&#22238;&#25253;&#30340;&#24433;&#21709;&#65292;&#20351;&#29992;&#22799;&#26222;&#27604;&#29575;&#21644;&#20449;&#24687;&#27604;&#29575;&#12290;&#30740;&#31350;&#37325;&#28857;&#20851;&#27880;&#20102;&#20174;2010&#24180;1&#26376;1&#26085;&#33267;2022&#24180;4&#26376;30&#26085;&#26399;&#38388;&#20316;&#20026;&#20132;&#26131;&#36164;&#20135;&#30340;&#26631;&#26222;500&#25351;&#25968;&#65292;EUR/USD&#21644;BTC/USD&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#20855;&#26377;&#24179;&#34913;&#22122;&#22768;&#22686;&#24378;&#21644;&#29942;&#39048;&#22823;&#23567;&#30340;&#30417;&#30563;&#22411;&#33258;&#32534;&#30721;&#22120;&#26174;&#33879;&#25552;&#21319;&#20102;&#31574;&#30053;&#25928;&#26524;&#12290;&#28982;&#32780;&#65292;&#36807;&#22810;&#30340;&#22122;&#22768;&#21644;&#22823;&#30340;&#29942;&#39048;&#22823;&#23567;&#21487;&#33021;&#20250;&#25439;&#23475;&#34920;&#29616;&#65292;&#31361;&#20986;&#20102;&#31934;&#30830;&#21442;&#25968;&#35843;&#25972;&#30340;&#37325;&#35201;&#24615;&#12290;&#26412;&#25991;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20248;&#21270;&#25351;&#26631;&#30340;&#25512;&#23548;&#65292;&#21487;&#19982;&#19977;&#37325;&#38556;&#30861;&#26631;&#35760;&#19968;&#36215;&#20351;&#29992;&#12290;&#36825;&#39033;&#30740;&#31350;&#30340;&#32467;&#26524;&#23545;&#25919;&#31574;&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#65292;&#26263;&#31034;&#37329;&#34701;&#24066;&#22330;&#39044;&#27979;&#24037;&#20855;&#30340;&#25345;&#32493;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01866v1 Announce Type: new  Abstract: This paper investigates the enhancement of financial time series forecasting with the use of neural networks through supervised autoencoders, aiming to improve investment strategy performance. It specifically examines the impact of noise augmentation and triple barrier labeling on risk-adjusted returns, using the Sharpe and Information Ratios. The study focuses on the S&amp;P 500 index, EUR/USD, and BTC/USD as the traded assets from January 1, 2010, to April 30, 2022. Findings indicate that supervised autoencoders, with balanced noise augmentation and bottleneck size, significantly boost strategy effectiveness. However, excessive noise and large bottleneck sizes can impair performance, highlighting the importance of precise parameter tuning. This paper also presents a derivation of a novel optimization metric that can be used with triple barrier labeling. The results of this study have substantial policy implications, suggesting that financi
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#23637;&#31034;&#20102;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#19968;&#31181;&#27969;&#34892;&#30340;&#38750;&#21442;&#25968;&#26041;&#27861;&#8212;&#8212;&#22238;&#24402;&#26641;&#19978;&#65292;&#23376;&#25277;&#26679;&#32858;&#21512;&#65288;subagging&#65289;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#21457;&#29616;&#23545;&#20110;&#20219;&#20309;&#32473;&#23450;&#30340;&#20998;&#35010;&#25968;&#65292;subagging&#37117;&#21487;&#20197;&#20248;&#20110;&#21333;&#26869;&#26641;&#65292;&#24182;&#19988;&#22312;&#36739;&#22810;&#20998;&#35010;&#30340;&#24773;&#20917;&#19979;&#25913;&#36827;&#26356;&#22823;&#12290;</title><link>https://arxiv.org/abs/2404.01832</link><description>&lt;p&gt;
&#20309;&#26102;&#20351;&#29992;Subagging&#65311;
&lt;/p&gt;
&lt;p&gt;
When does Subagging Work?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01832
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#23637;&#31034;&#20102;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#19968;&#31181;&#27969;&#34892;&#30340;&#38750;&#21442;&#25968;&#26041;&#27861;&#8212;&#8212;&#22238;&#24402;&#26641;&#19978;&#65292;&#23376;&#25277;&#26679;&#32858;&#21512;&#65288;subagging&#65289;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#21457;&#29616;&#23545;&#20110;&#20219;&#20309;&#32473;&#23450;&#30340;&#20998;&#35010;&#25968;&#65292;subagging&#37117;&#21487;&#20197;&#20248;&#20110;&#21333;&#26869;&#26641;&#65292;&#24182;&#19988;&#22312;&#36739;&#22810;&#20998;&#35010;&#30340;&#24773;&#20917;&#19979;&#25913;&#36827;&#26356;&#22823;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#19968;&#31181;&#27969;&#34892;&#30340;&#38750;&#21442;&#25968;&#26041;&#27861;&#8212;&#8212;&#22238;&#24402;&#26641;&#19978;&#65292;&#23376;&#25277;&#26679;&#32858;&#21512;&#65288;subagging&#65289;&#30340;&#26377;&#25928;&#24615;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#26641;&#30340;&#36880;&#28857;&#19968;&#33268;&#24615;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#25105;&#20204;&#26126;&#30830;&#20102;&#65288;i&#65289;&#20559;&#24046;&#21462;&#20915;&#20110;&#21333;&#20803;&#30340;&#30452;&#24452;&#65292;&#22240;&#27492;&#65292;&#20855;&#26377;&#23569;&#25968;&#20998;&#35010;&#30340;&#26641;&#20542;&#21521;&#20110;&#23384;&#22312;&#20559;&#24046;&#65292;&#20197;&#21450;&#65288;ii&#65289;&#26041;&#24046;&#21462;&#20915;&#20110;&#21333;&#20803;&#20013;&#30340;&#35266;&#27979;&#25968;&#37327;&#65292;&#22240;&#27492;&#65292;&#20855;&#26377;&#35768;&#22810;&#20998;&#35010;&#30340;&#26641;&#20542;&#21521;&#20110;&#20855;&#26377;&#36739;&#22823;&#30340;&#26041;&#24046;&#12290;&#34429;&#28982;&#36825;&#20123;&#20851;&#20110;&#20559;&#24046;&#21644;&#26041;&#24046;&#30340;&#38472;&#36848;&#22312;&#21327;&#21464;&#37327;&#31354;&#38388;&#20013;&#26159;&#20840;&#23616;&#36866;&#29992;&#30340;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#65292;&#22312;&#26576;&#20123;&#32422;&#26463;&#26465;&#20214;&#19979;&#65292;&#23427;&#20204;&#22312;&#23616;&#37096;&#20063;&#26159;&#25104;&#31435;&#30340;&#12290;&#31532;&#20108;&#65292;&#25105;&#20204;&#27604;&#36739;&#20102;&#23376;&#25277;&#26679;&#32858;&#21512;&#21644;&#20855;&#26377;&#19981;&#21516;&#20998;&#35010;&#25968;&#30340;&#26641;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#23545;&#20110;&#20219;&#20309;&#32473;&#23450;&#30340;&#20998;&#35010;&#25968;&#65292;&#23376;&#25277;&#26679;&#32858;&#21512;&#37117;&#20248;&#20110;&#21333;&#26869;&#26641;&#65292;&#24182;&#19988;&#36825;&#31181;&#25913;&#36827;&#22312;&#36739;&#22810;&#20998;&#35010;&#30340;&#24773;&#20917;&#19979;&#27604;&#36739;&#23569;&#20998;&#35010;&#30340;&#24773;&#20917;&#19979;&#26356;&#22823;&#12290;&#28982;&#32780;&#65292;&#19968;&#20010;&#20197;&#26368;&#20339;&#22823;&#23567;&#29983;&#38271;&#30340;&#21333;&#26869;&#26641;&#21487;&#20197;&#20248;&#20110;&#23376;&#25277;&#26679;&#32858;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01832v1 Announce Type: cross  Abstract: We study the effectiveness of subagging, or subsample aggregating, on regression trees, a popular non-parametric method in machine learning. First, we give sufficient conditions for pointwise consistency of trees. We formalize that (i) the bias depends on the diameter of cells, hence trees with few splits tend to be biased, and (ii) the variance depends on the number of observations in cells, hence trees with many splits tend to have large variance. While these statements for bias and variance are known to hold globally in the covariate space, we show that, under some constraints, they are also true locally. Second, we compare the performance of subagging to that of trees across different numbers of splits. We find that (1) for any given number of splits, subagging improves upon a single tree, and (2) this improvement is larger for many splits than it is for few splits. However, (3) a single tree grown at optimal size can outperform su
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#26410;&#30693;&#35760;&#24405;&#31574;&#30053;&#21644;&#20215;&#20540;&#20989;&#25968;&#30340;&#21452;&#37325;&#31283;&#20581;&#31163;&#32447;&#35780;&#20272;&#20272;&#35745;&#22120;DRUnknown&#65292;&#23454;&#29616;&#20102;&#26368;&#23567;&#28176;&#36817;&#26041;&#24046;&#21644;&#21322;&#21442;&#25968;&#19979;&#30028;&#19979;&#26368;&#20339;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2404.01830</link><description>&lt;p&gt;
&#20272;&#35745;&#35760;&#24405;&#31574;&#30053;&#30340;&#21452;&#37325;&#31283;&#20581;&#31163;&#32447;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Doubly-Robust Off-Policy Evaluation with Estimated Logging Policy
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01830
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#26410;&#30693;&#35760;&#24405;&#31574;&#30053;&#21644;&#20215;&#20540;&#20989;&#25968;&#30340;&#21452;&#37325;&#31283;&#20581;&#31163;&#32447;&#35780;&#20272;&#20272;&#35745;&#22120;DRUnknown&#65292;&#23454;&#29616;&#20102;&#26368;&#23567;&#28176;&#36817;&#26041;&#24046;&#21644;&#21322;&#21442;&#25968;&#19979;&#30028;&#19979;&#26368;&#20339;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#26032;&#39062;&#30340;&#21452;&#37325;&#31283;&#20581;&#65288;DR&#65289;&#31163;&#32447;&#35780;&#20272;&#65288;OPE&#65289;&#20272;&#35745;&#22120;DRUnknown&#65292;&#26088;&#22312;&#24212;&#23545;&#35760;&#24405;&#31574;&#30053;&#21644;&#20215;&#20540;&#20989;&#25968;&#22343;&#26410;&#30693;&#30340;&#24773;&#20917;&#12290;&#35813;&#20272;&#35745;&#22120;&#39318;&#20808;&#20272;&#35745;&#35760;&#24405;&#31574;&#30053;&#65292;&#28982;&#21518;&#36890;&#36807;&#26368;&#23567;&#21270;&#20272;&#35745;&#22120;&#30340;&#28176;&#36817;&#26041;&#24046;&#26469;&#20272;&#35745;&#20215;&#20540;&#20989;&#25968;&#27169;&#22411;&#65292;&#21516;&#26102;&#32771;&#34385;&#35760;&#24405;&#31574;&#30053;&#30340;&#20272;&#35745;&#25928;&#26524;&#12290;&#24403;&#35760;&#24405;&#31574;&#30053;&#27169;&#22411;&#27491;&#30830;&#25351;&#23450;&#26102;&#65292;DRUnknown&#22312;&#29616;&#26377;OPE&#20272;&#35745;&#22120;&#31867;&#20013;&#36798;&#21040;&#26368;&#23567;&#30340;&#28176;&#36817;&#26041;&#24046;&#12290;&#24403;&#20215;&#20540;&#20989;&#25968;&#27169;&#22411;&#20063;&#34987;&#27491;&#30830;&#25351;&#23450;&#26102;&#65292;DRUnknown&#26159;&#26368;&#20248;&#30340;&#65292;&#22240;&#20026;&#23427;&#30340;&#28176;&#36817;&#26041;&#24046;&#36798;&#21040;&#20102;&#21322;&#21442;&#25968;&#19979;&#30028;&#12290;&#25105;&#20204;&#22312;&#24773;&#22659;&#33218;&#21644;&#24378;&#21270;&#23398;&#20064;&#20013;&#36827;&#34892;&#20102;&#23454;&#39564;&#32467;&#26524;&#65292;&#27604;&#36739;&#20102;DRUnknown&#19982;&#29616;&#26377;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01830v1 Announce Type: cross  Abstract: We introduce a novel doubly-robust (DR) off-policy evaluation (OPE) estimator for Markov decision processes, DRUnknown, designed for situations where both the logging policy and the value function are unknown. The proposed estimator initially estimates the logging policy and then estimates the value function model by minimizing the asymptotic variance of the estimator while considering the estimating effect of the logging policy. When the logging policy model is correctly specified, DRUnknown achieves the smallest asymptotic variance within the class containing existing OPE estimators. When the value function model is also correctly specified, DRUnknown is optimal as its asymptotic variance reaches the semiparametric lower bound. We present experimental results conducted in contextual bandits and reinforcement learning to compare the performance of DRUnknown with that of existing methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;&#26368;&#20248;KL&#32422;&#26463;&#30340;&#24378;&#21270;&#23398;&#20064;&#35299;&#30340;&#38381;&#21512;&#24418;&#24335;&#21051;&#30011;&#65292;&#35777;&#26126;&#20102;&#23454;&#29616;KL&#25955;&#24230;&#21644;&#22870;&#21169;&#20043;&#38388;&#26435;&#34913;&#30340;&#23545;&#40784;&#26041;&#27861;&#24517;&#39035;&#36817;&#20284;&#26368;&#20248;KL&#32422;&#26463;&#30340;RL&#35299;&#12290;</title><link>https://arxiv.org/abs/2404.01730</link><description>&lt;p&gt;
&#35821;&#35328;&#27169;&#22411;&#23545;&#40784;&#30340;&#28176;&#36827;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Asymptotics of Language Model Alignment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01730
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;&#26368;&#20248;KL&#32422;&#26463;&#30340;&#24378;&#21270;&#23398;&#20064;&#35299;&#30340;&#38381;&#21512;&#24418;&#24335;&#21051;&#30011;&#65292;&#35777;&#26126;&#20102;&#23454;&#29616;KL&#25955;&#24230;&#21644;&#22870;&#21169;&#20043;&#38388;&#26435;&#34913;&#30340;&#23545;&#40784;&#26041;&#27861;&#24517;&#39035;&#36817;&#20284;&#26368;&#20248;KL&#32422;&#26463;&#30340;RL&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35753;$p$&#34920;&#31034;&#19968;&#20010;&#29983;&#25104;&#24335;&#35821;&#35328;&#27169;&#22411;&#12290;&#35753;$r$&#34920;&#31034;&#19968;&#20010;&#22870;&#21169;&#27169;&#22411;&#65292;&#36820;&#22238;&#19968;&#20010;&#26631;&#37327;&#65292;&#25429;&#25417;&#20174;$p$&#20013;&#25277;&#21462;&#30340;&#20869;&#23481;&#34987;&#20559;&#22909;&#30340;&#31243;&#24230;&#12290;&#35821;&#35328;&#27169;&#22411;&#23545;&#40784;&#30340;&#30446;&#26631;&#26159;&#25913;&#21464;$p$&#20026;&#19968;&#20010;&#26032;&#30340;&#20998;&#24067;$\phi$&#65292;&#20351;&#24471;&#26399;&#26395;&#22870;&#21169;&#26356;&#39640;&#65292;&#21516;&#26102;&#20445;&#25345;$\phi$&#25509;&#36817;$p$&#12290;&#19968;&#31181;&#27969;&#34892;&#30340;&#23545;&#40784;&#26041;&#27861;&#26159;KL&#32422;&#26463;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#65292;&#36873;&#25321;&#19968;&#20010;&#20998;&#24067;$\phi_\Delta$&#65292;&#26368;&#22823;&#21270;$E_{\phi_{\Delta}} r(y)$&#65292;&#21516;&#26102;&#28385;&#36275;&#30456;&#23545;&#29109;&#32422;&#26463;$KL(\phi_\Delta || p) \leq \Delta$&#12290;&#21478;&#19968;&#31181;&#31616;&#21333;&#30340;&#23545;&#40784;&#26041;&#27861;&#26159;&#26368;&#20339;-$N$&#65292;&#20174;$p$&#20013;&#25277;&#21462;$N$&#20010;&#26679;&#26412;&#65292;&#24182;&#36873;&#25321;&#22870;&#21169;&#26368;&#39640;&#30340;&#19968;&#20010;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#26368;&#20248;KL&#32422;&#26463;&#30340;RL&#35299;&#30340;&#38381;&#21512;&#24418;&#24335;&#21051;&#30011;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20219;&#20309;&#23454;&#29616;KL&#25955;&#24230;&#21644;&#22870;&#21169;&#20043;&#38388;&#21487;&#27604;&#36739;&#30340;&#26435;&#34913;&#30340;&#23545;&#40784;&#26041;&#27861;&#65292;&#24517;&#39035;&#36817;&#20284;&#26368;&#20248;KL&#32422;&#26463;&#30340;RL&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01730v1 Announce Type: new  Abstract: Let $p$ denote a generative language model. Let $r$ denote a reward model that returns a scalar that captures the degree at which a draw from $p$ is preferred. The goal of language model alignment is to alter $p$ to a new distribution $\phi$ that results in a higher expected reward while keeping $\phi$ close to $p.$ A popular alignment method is the KL-constrained reinforcement learning (RL), which chooses a distribution $\phi_\Delta$ that maximizes $E_{\phi_{\Delta}} r(y)$ subject to a relative entropy constraint $KL(\phi_\Delta || p) \leq \Delta.$ Another simple alignment method is best-of-$N$, where $N$ samples are drawn from $p$ and one with highest reward is selected. In this paper, we offer a closed-form characterization of the optimal KL-constrained RL solution. We demonstrate that any alignment method that achieves a comparable trade-off between KL divergence and reward must approximate the optimal KL-constrained RL solution in t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#25237;&#24433;&#26041;&#24046;&#23545;&#39640;&#26031;&#36807;&#31243;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#24433;&#21709;&#65292;&#20197;&#21450;&#38598;&#25104;&#20102;&#35889;&#28151;&#21512;&#65288;SM&#65289;&#26680;&#21644;&#21487;&#24494;&#38543;&#26426;&#20613;&#31435;&#21494;&#29305;&#24449;&#65288;RFF&#65289;&#26680;&#36924;&#36817;&#26469;&#35299;&#20915;&#26680;&#28789;&#27963;&#24615;&#19981;&#36275;&#38382;&#39064;&#65292;&#20174;&#32780;&#38450;&#27490;&#27169;&#22411;&#23849;&#28291;&#12290;</title><link>https://arxiv.org/abs/2404.01697</link><description>&lt;p&gt;
&#38450;&#27490;&#39640;&#26031;&#36807;&#31243;&#28508;&#21464;&#37327;&#27169;&#22411;&#20013;&#30340;&#27169;&#22411;&#23849;&#28291;
&lt;/p&gt;
&lt;p&gt;
Preventing Model Collapse in Gaussian Process Latent Variable Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01697
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#25237;&#24433;&#26041;&#24046;&#23545;&#39640;&#26031;&#36807;&#31243;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#24433;&#21709;&#65292;&#20197;&#21450;&#38598;&#25104;&#20102;&#35889;&#28151;&#21512;&#65288;SM&#65289;&#26680;&#21644;&#21487;&#24494;&#38543;&#26426;&#20613;&#31435;&#21494;&#29305;&#24449;&#65288;RFF&#65289;&#26680;&#36924;&#36817;&#26469;&#35299;&#20915;&#26680;&#28789;&#27963;&#24615;&#19981;&#36275;&#38382;&#39064;&#65292;&#20174;&#32780;&#38450;&#27490;&#27169;&#22411;&#23849;&#28291;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Gaussian process latent variable models (GPLVMs)&#26159;&#19968;&#31867;&#22810;&#25165;&#22810;&#33402;&#30340;&#26080;&#30417;&#30563;&#23398;&#20064;&#27169;&#22411;&#65292;&#36890;&#24120;&#29992;&#20110;&#38477;&#32500;&#12290;&#28982;&#32780;&#65292;&#29992;GPLVMs&#23545;&#25968;&#25454;&#24314;&#27169;&#26102;&#24120;&#35265;&#30340;&#25361;&#25112;&#21253;&#25324;&#26680;&#28789;&#27963;&#24615;&#19981;&#36275;&#21644;&#25237;&#24433;&#22122;&#22768;&#36873;&#25321;&#19981;&#24403;&#65292;&#23548;&#33268;&#20102;&#19968;&#31181;&#20197;&#27169;&#31946;&#28508;&#21464;&#37327;&#34920;&#31034;&#20026;&#20027;&#35201;&#29305;&#24449;&#30340;&#27169;&#22411;&#23849;&#28291;&#65292;&#36825;&#31181;&#34920;&#31034;&#19981;&#21453;&#26144;&#25968;&#25454;&#30340;&#28508;&#22312;&#32467;&#26500;&#12290;&#26412;&#25991;&#39318;&#20808;&#20174;&#29702;&#35770;&#19978;&#36890;&#36807;&#32447;&#24615;GPLVM&#30340;&#35270;&#35282;&#30740;&#31350;&#20102;&#25237;&#24433;&#26041;&#24046;&#23545;&#27169;&#22411;&#23849;&#28291;&#30340;&#24433;&#21709;&#12290;&#20854;&#27425;&#65292;&#36890;&#36807;&#38598;&#25104;&#35889;&#28151;&#21512;&#65288;SM&#65289;&#26680;&#21644;&#21487;&#24494;&#38543;&#26426;&#20613;&#31435;&#21494;&#29305;&#24449;&#65288;RFF&#65289;&#26680;&#36924;&#36817;&#65292;&#35299;&#20915;&#20102;&#30001;&#20110;&#26680;&#28789;&#27963;&#24615;&#19981;&#36275;&#23548;&#33268;&#30340;&#27169;&#22411;&#23849;&#28291;&#38382;&#39064;&#65292;&#20174;&#32780;&#20445;&#35777;&#20102;&#36890;&#36807;&#29616;&#25104;&#30340;&#33258;&#21160;&#24494;&#20998;&#24037;&#20855;&#23454;&#29616;&#23398;&#20064;&#26680;&#21442;&#25968;&#30340;&#35745;&#31639;&#21487;&#25193;&#23637;&#24615;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01697v1 Announce Type: cross  Abstract: Gaussian process latent variable models (GPLVMs) are a versatile family of unsupervised learning models, commonly used for dimensionality reduction. However, common challenges in modeling data with GPLVMs include inadequate kernel flexibility and improper selection of the projection noise, which leads to a type of model collapse characterized primarily by vague latent representations that do not reflect the underlying structure of the data. This paper addresses these issues by, first, theoretically examining the impact of the projection variance on model collapse through the lens of a linear GPLVM. Second, we address the problem of model collapse due to inadequate kernel flexibility by integrating the spectral mixture (SM) kernel and a differentiable random Fourier feature (RFF) kernel approximation, which ensures computational scalability and efficiency through off-the-shelf automatic differentiation tools for learning the kernel hype
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#19981;&#21464;&#24615;&#21407;&#21017;&#35299;&#20915;&#20844;&#24179;&#21644;&#27867;&#21270;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#22522;&#20110;&#35757;&#32451;&#29615;&#22659;&#30340;oracle FAIRM&#65292;&#20197;&#21450;&#22312;&#32447;&#24615;&#27169;&#22411;&#20013;&#23454;&#29616;FAIRM&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#26497;&#23567;&#26368;&#20248;&#24615;&#12290;</title><link>https://arxiv.org/abs/2404.01608</link><description>&lt;p&gt;
FAIRM: &#23398;&#20064;&#19981;&#21464;&#34920;&#31034;&#20197;&#23454;&#29616;&#31639;&#27861;&#20844;&#24179;&#24615;&#21644;&#22495;&#27867;&#21270;&#30340;&#26497;&#23567;&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;
FAIRM: Learning invariant representations for algorithmic fairness and domain generalization with minimax optimality
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01608
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#19981;&#21464;&#24615;&#21407;&#21017;&#35299;&#20915;&#20844;&#24179;&#21644;&#27867;&#21270;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#22522;&#20110;&#35757;&#32451;&#29615;&#22659;&#30340;oracle FAIRM&#65292;&#20197;&#21450;&#22312;&#32447;&#24615;&#27169;&#22411;&#20013;&#23454;&#29616;FAIRM&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#26497;&#23567;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#36890;&#24120;&#20551;&#35774;&#27979;&#35797;&#25968;&#25454;&#19982;&#35757;&#32451;&#25968;&#25454;&#20855;&#26377;&#30456;&#21516;&#30340;&#20998;&#24067;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#24212;&#29992;&#20013;&#23384;&#22312;&#22810;&#20010;&#23618;&#27425;&#30340;&#24322;&#36136;&#24615;&#65292;&#36825;&#19968;&#20551;&#35774;&#21487;&#33021;&#19981;&#25104;&#31435;&#65292;&#20174;&#32780;&#24341;&#21457;&#31639;&#27861;&#20844;&#24179;&#24615;&#21644;&#22495;&#27867;&#21270;&#26041;&#38754;&#30340;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#19981;&#21464;&#24615;&#21407;&#21017;&#35299;&#20915;&#20102;&#20844;&#24179;&#19988;&#20855;&#26377;&#27867;&#21270;&#33021;&#21147;&#30340;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#35757;&#32451;&#29615;&#22659;&#30340;oracle&#65292;FAIRM&#65292;&#23427;&#22312;&#22810;&#26679;&#24615;&#31867;&#22411;&#26465;&#20214;&#19979;&#20855;&#26377;&#29702;&#24819;&#30340;&#20844;&#24179;&#24615;&#21644;&#22495;&#27867;&#21270;&#29305;&#24615;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#22312;&#24369;&#20998;&#24067;&#20551;&#35774;&#19979;&#25552;&#20379;&#20102;&#19968;&#20010;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#29702;&#35770;&#20445;&#35777;&#30340;&#32463;&#39564;FAIRM&#12290;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#26377;&#25928;&#30340;&#31639;&#27861;&#26469;&#22312;&#32447;&#24615;&#27169;&#22411;&#20013;&#23454;&#29616;FAIRM&#65292;&#24182;&#23637;&#31034;&#20102;&#20855;&#26377;&#26497;&#23567;&#26368;&#20248;&#24615;&#30340;&#38750;&#28176;&#36817;&#24615;&#33021;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#25968;&#25454;&#21644;MNIST&#25968;&#25454;&#30340;&#25968;&#20540;&#23454;&#39564;&#20013;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#20248;&#20110;&#23545;&#24212;&#26041;&#27861;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01608v1 Announce Type: cross  Abstract: Machine learning methods often assume that the test data have the same distribution as the training data. However, this assumption may not hold due to multiple levels of heterogeneity in applications, raising issues in algorithmic fairness and domain generalization. In this work, we address the problem of fair and generalizable machine learning by invariant principles. We propose a training environment-based oracle, FAIRM, which has desirable fairness and domain generalization properties under a diversity-type condition. We then provide an empirical FAIRM with finite-sample theoretical guarantees under weak distributional assumptions. We then develop efficient algorithms to realize FAIRM in linear models and demonstrate the nonasymptotic performance with minimax optimality. We evaluate our method in numerical experiments with synthetic data and MNIST data and show that it outperforms its counterparts.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#22810;&#27169;&#24577;&#34920;&#31034;&#23398;&#20064;&#20013;&#23545;&#40784;&#19981;&#37197;&#23545;&#26679;&#26412;&#25361;&#25112;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20272;&#35745;&#20542;&#21521;&#24471;&#20998;&#26469;&#23450;&#20041;&#26679;&#26412;&#20043;&#38388;&#30340;&#36317;&#31163;&#12290;</title><link>https://arxiv.org/abs/2404.01595</link><description>&lt;p&gt;
&#22810;&#27169;&#24577;&#25968;&#25454;&#26080;&#37197;&#23545;&#20542;&#21521;&#24471;&#20998;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Propensity Score Alignment of Unpaired Multimodal Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01595
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#22810;&#27169;&#24577;&#34920;&#31034;&#23398;&#20064;&#20013;&#23545;&#40784;&#19981;&#37197;&#23545;&#26679;&#26412;&#25361;&#25112;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20272;&#35745;&#20542;&#21521;&#24471;&#20998;&#26469;&#23450;&#20041;&#26679;&#26412;&#20043;&#38388;&#30340;&#36317;&#31163;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#27169;&#24577;&#34920;&#31034;&#23398;&#20064;&#25216;&#26415;&#36890;&#24120;&#20381;&#36182;&#20110;&#37197;&#23545;&#26679;&#26412;&#26469;&#23398;&#20064;&#20849;&#21516;&#30340;&#34920;&#31034;&#65292;&#20294;&#22312;&#29983;&#29289;&#23398;&#31561;&#39046;&#22495;&#65292;&#24448;&#24448;&#38590;&#20197;&#25910;&#38598;&#37197;&#23545;&#26679;&#26412;&#65292;&#22240;&#20026;&#27979;&#37327;&#35774;&#22791;&#36890;&#24120;&#20250;&#30772;&#22351;&#26679;&#26412;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#35299;&#20915;&#22810;&#27169;&#24577;&#34920;&#31034;&#23398;&#20064;&#20013;&#23545;&#40784;&#19981;&#37197;&#23545;&#26679;&#26412;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#23558;&#22240;&#26524;&#25512;&#26029;&#20013;&#30340;&#28508;&#22312;&#32467;&#26524;&#19982;&#22810;&#27169;&#24577;&#35266;&#23519;&#20013;&#30340;&#28508;&#22312;&#35270;&#22270;&#36827;&#34892;&#31867;&#27604;&#65292;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#20351;&#29992;Rubin&#30340;&#26694;&#26550;&#26469;&#20272;&#35745;&#19968;&#20010;&#20849;&#21516;&#30340;&#31354;&#38388;&#65292;&#20197;&#21305;&#37197;&#26679;&#26412;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20551;&#35774;&#25105;&#20204;&#25910;&#38598;&#20102;&#32463;&#36807;&#22788;&#29702;&#23454;&#39564;&#24178;&#25200;&#30340;&#26679;&#26412;&#65292;&#24182;&#21033;&#29992;&#27492;&#26469;&#20174;&#27599;&#31181;&#27169;&#24577;&#20013;&#20272;&#35745;&#20542;&#21521;&#24471;&#20998;&#65292;&#20854;&#20013;&#21253;&#25324;&#28508;&#22312;&#29366;&#24577;&#21644;&#22788;&#29702;&#20043;&#38388;&#30340;&#25152;&#26377;&#20849;&#20139;&#20449;&#24687;&#65292;&#24182;&#21487;&#29992;&#20110;&#23450;&#20041;&#26679;&#26412;&#20043;&#38388;&#30340;&#36317;&#31163;&#12290;&#25105;&#20204;&#23581;&#35797;&#20102;&#20004;&#31181;&#21033;&#29992;&#36825;&#19968;&#26041;&#27861;&#30340;&#23545;&#40784;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01595v1 Announce Type: new  Abstract: Multimodal representation learning techniques typically rely on paired samples to learn common representations, but paired samples are challenging to collect in fields such as biology where measurement devices often destroy the samples. This paper presents an approach to address the challenge of aligning unpaired samples across disparate modalities in multimodal representation learning. We draw an analogy between potential outcomes in causal inference and potential views in multimodal observations, which allows us to use Rubin's framework to estimate a common space in which to match samples. Our approach assumes we collect samples that are experimentally perturbed by treatments, and uses this to estimate a propensity score from each modality, which encapsulates all shared information between a latent state and treatment and can be used to define a distance between samples. We experiment with two alignment techniques that leverage this di
&lt;/p&gt;</description></item><item><title>Fair MP-Boost&#26159;&#19968;&#31181;&#26088;&#22312;&#24179;&#34913;&#20844;&#24179;&#24615;&#21644;&#20934;&#30830;&#24615;&#30340;Boosting&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#23398;&#20064;&#29305;&#24449;&#21644;&#35266;&#27979;&#26469;&#36873;&#25321;&#23567;&#25209;&#37327;&#65292;&#20197;&#21516;&#26102;&#25552;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#21644;&#20844;&#24179;&#24615;&#12290;</title><link>https://arxiv.org/abs/2404.01521</link><description>&lt;p&gt;
&#20844;&#24179;&#30340;MP-BOOST: &#20844;&#24179;&#19988;&#21487;&#35299;&#37322;&#30340;&#23567;&#25209;&#37327; Boosting
&lt;/p&gt;
&lt;p&gt;
Fair MP-BOOST: Fair and Interpretable Minipatch Boosting
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01521
&lt;/p&gt;
&lt;p&gt;
Fair MP-Boost&#26159;&#19968;&#31181;&#26088;&#22312;&#24179;&#34913;&#20844;&#24179;&#24615;&#21644;&#20934;&#30830;&#24615;&#30340;Boosting&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#23398;&#20064;&#29305;&#24449;&#21644;&#35266;&#27979;&#26469;&#36873;&#25321;&#23567;&#25209;&#37327;&#65292;&#20197;&#21516;&#26102;&#25552;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#21644;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38598;&#25104;&#26041;&#27861;&#65292;&#29305;&#21035;&#26159;Boosting&#65292;&#22312;&#34920;&#26684;&#25968;&#25454;&#20013;&#24050;&#34987;&#35777;&#26126;&#26159;&#39640;&#25928;&#19988;&#24191;&#27867;&#24212;&#29992;&#30340;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#21033;&#29992;&#20256;&#32479;Boosting&#26041;&#27861;&#30340;&#31283;&#20581;&#39044;&#27979;&#33021;&#21147;&#65292;&#21516;&#26102;&#22686;&#24378;&#20844;&#24179;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;&#20026;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;Fair MP-Boost&#65292;&#36825;&#26159;&#19968;&#31181;&#24179;&#34913;&#20844;&#24179;&#24615;&#21644;&#20934;&#30830;&#24615;&#30340;&#38543;&#26426;Boosting&#26041;&#26696;&#65292;&#36890;&#36807;&#22312;&#35757;&#32451;&#26399;&#38388;&#33258;&#36866;&#24212;&#23398;&#20064;&#29305;&#24449;&#21644;&#35266;&#23519;&#26469;&#23454;&#29616;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;Fair MP-Boost&#20381;&#25454;&#33258;&#36866;&#24212;&#23398;&#20064;&#30340;&#29305;&#24449;&#21644;&#35266;&#23519;&#37319;&#26679;&#27010;&#29575;&#65292;&#39034;&#24207;&#25277;&#21462;&#23567;&#25209;&#37327;&#35266;&#23519;&#21644;&#29305;&#24449;&#65292;&#34987;&#31216;&#20026;minipatches (MP)&#12290;&#25105;&#20204;&#36890;&#36807;&#32467;&#21512;&#25439;&#22833;&#20989;&#25968;&#25110;&#29305;&#24449;&#37325;&#35201;&#24615;&#20998;&#25968;&#26469;&#35774;&#35745;&#36825;&#20123;&#27010;&#29575;&#65292;&#20197;&#21516;&#26102;&#35299;&#20915;&#20934;&#30830;&#24615;&#21644;&#20844;&#24179;&#24615;&#38382;&#39064;&#12290;&#22240;&#27492;&#65292;Fair MP-Boost&#20248;&#20808;&#32771;&#34385;&#37325;&#35201;&#19988;&#20844;&#24179;&#30340;&#29305;&#24449;&#20197;&#21450;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#23454;&#20363;&#65292;&#20174;&#32780;&#36873;&#25321;&#26368;&#30456;&#20851;&#30340;&#23567;&#25209;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01521v1 Announce Type: cross  Abstract: Ensemble methods, particularly boosting, have established themselves as highly effective and widely embraced machine learning techniques for tabular data. In this paper, we aim to leverage the robust predictive power of traditional boosting methods while enhancing fairness and interpretability. To achieve this, we develop Fair MP-Boost, a stochastic boosting scheme that balances fairness and accuracy by adaptively learning features and observations during training. Specifically, Fair MP-Boost sequentially samples small subsets of observations and features, termed minipatches (MP), according to adaptively learned feature and observation sampling probabilities. We devise these probabilities by combining loss functions, or by combining feature importance scores to address accuracy and fairness simultaneously. Hence, Fair MP-Boost prioritizes important and fair features along with challenging instances, to select the most relevant minipatc
&lt;/p&gt;</description></item><item><title>&#22270;&#20687;&#32593;&#27169;&#22411;&#30340;&#20559;&#35265;&#26159;&#21542;&#33021;&#22815;&#35299;&#37322;&#27169;&#22411;&#30340;&#27867;&#21270;&#38382;&#39064;&#65292;&#23545;&#27492;&#36827;&#34892;&#20102;&#22823;&#35268;&#27169;&#30740;&#31350;&#12290;</title><link>https://arxiv.org/abs/2404.01509</link><description>&lt;p&gt;
&#22270;&#20687;&#32593;&#27169;&#22411;&#20013;&#30340;&#20559;&#35265;&#33021;&#35299;&#37322;&#27867;&#21270;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can Biases in ImageNet Models Explain Generalization?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01509
&lt;/p&gt;
&lt;p&gt;
&#22270;&#20687;&#32593;&#27169;&#22411;&#30340;&#20559;&#35265;&#26159;&#21542;&#33021;&#22815;&#35299;&#37322;&#27169;&#22411;&#30340;&#27867;&#21270;&#38382;&#39064;&#65292;&#23545;&#27492;&#36827;&#34892;&#20102;&#22823;&#35268;&#27169;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#38754;&#20020;&#30340;&#20027;&#35201;&#25361;&#25112;&#20043;&#19968;&#26159;&#27169;&#22411;&#23545;&#26469;&#33258;&#35757;&#32451;&#20998;&#24067;&#38271;&#23614;&#30340;&#31232;&#26377;&#20869;&#37096;&#20998;&#24067;&#65288;ID&#65289;&#26679;&#26412;&#21644;&#35757;&#32451;&#20998;&#24067;&#20043;&#22806;&#65288;OOD&#65289;&#26679;&#26412;&#30340;&#24378;&#22823;&#27867;&#21270;&#33021;&#21147;&#12290;&#23545;&#20110;&#22270;&#20687;&#20998;&#31867;&#65292;&#36825;&#20307;&#29616;&#22312;&#23545;&#25197;&#26354;&#22270;&#20687;&#30340;&#25915;&#20987;&#12289;&#24615;&#33021;&#19979;&#38477;&#20197;&#21450;&#23545;&#27010;&#24565;&#65288;&#22914;&#33609;&#22270;&#65289;&#30340;&#27867;&#21270;&#19981;&#36275;&#12290;&#30446;&#21069;&#23545;&#31070;&#32463;&#32593;&#32476;&#27867;&#21270;&#30340;&#29702;&#35299;&#38750;&#24120;&#26377;&#38480;&#65292;&#20294;&#21457;&#29616;&#20102;&#19968;&#20123;&#21306;&#21035;&#27169;&#22411;&#19982;&#20154;&#31867;&#35270;&#35273;&#30340;&#20559;&#35265;&#65292;&#36825;&#20123;&#20559;&#35265;&#21487;&#33021;&#23548;&#33268;&#36825;&#20123;&#38480;&#21046;&#12290;&#22240;&#27492;&#65292;&#24050;&#32463;&#23581;&#35797;&#20102;&#22810;&#31181;&#19981;&#21516;&#25104;&#21151;&#31243;&#24230;&#30340;&#26041;&#27861;&#26469;&#20943;&#23569;&#36825;&#20123;&#35757;&#32451;&#20013;&#30340;&#20559;&#35265;&#20197;&#25913;&#21892;&#27867;&#21270;&#24615;&#33021;&#12290;&#25105;&#20204;&#22312;&#24050;&#24314;&#31435;&#30340;ResNet-50&#26550;&#26500;&#19978;&#36827;&#34892;&#22823;&#35268;&#27169;&#30740;&#31350;&#65292;&#22312;48&#20010;&#36890;&#36807;&#19981;&#21516;&#33719;&#21462;&#36884;&#24452;&#33719;&#24471;&#30340;ImageNet&#27169;&#22411;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01509v1 Announce Type: cross  Abstract: The robust generalization of models to rare, in-distribution (ID) samples drawn from the long tail of the training distribution and to out-of-training-distribution (OOD) samples is one of the major challenges of current deep learning methods. For image classification, this manifests in the existence of adversarial attacks, the performance drops on distorted images, and a lack of generalization to concepts such as sketches. The current understanding of generalization in neural networks is very limited, but some biases that differentiate models from human vision have been identified and might be causing these limitations. Consequently, several attempts with varying success have been made to reduce these biases during training to improve generalization. We take a step back and sanity-check these attempts. Fixing the architecture to the well-established ResNet-50, we perform a large-scale study on 48 ImageNet models obtained via different 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#23545;&#20110;RMSProp&#21644;Adam&#22312;&#38750;&#20984;&#20248;&#21270;&#20013;&#30340;&#32039;&#33268;&#25910;&#25947;&#24615;&#20998;&#26512;&#65292;&#39318;&#27425;&#23637;&#31034;&#20102;&#22312;&#26368;&#23485;&#26494;&#30340;&#20551;&#35774;&#19979;&#30340;&#25910;&#25947;&#24615;&#32467;&#26524;&#65292;&#24182;&#23637;&#31034;&#20102;RMSProp&#21644;Adam&#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#20998;&#21035;&#20026;$\mathcal O(\epsilon^{-4})$&#12290;</title><link>https://arxiv.org/abs/2404.01436</link><description>&lt;p&gt;
RMSProp&#21644;Adam&#22312;&#20855;&#26377;&#20223;&#23556;&#22122;&#22768;&#26041;&#24046;&#30340;&#24191;&#20041;&#20809;&#28369;&#38750;&#20984;&#20248;&#21270;&#20013;&#30340;&#25910;&#25947;&#24615;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Convergence Guarantees for RMSProp and Adam in Generalized-smooth Non-convex Optimization with Affine Noise Variance
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01436
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#23545;&#20110;RMSProp&#21644;Adam&#22312;&#38750;&#20984;&#20248;&#21270;&#20013;&#30340;&#32039;&#33268;&#25910;&#25947;&#24615;&#20998;&#26512;&#65292;&#39318;&#27425;&#23637;&#31034;&#20102;&#22312;&#26368;&#23485;&#26494;&#30340;&#20551;&#35774;&#19979;&#30340;&#25910;&#25947;&#24615;&#32467;&#26524;&#65292;&#24182;&#23637;&#31034;&#20102;RMSProp&#21644;Adam&#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#20998;&#21035;&#20026;$\mathcal O(\epsilon^{-4})$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#22352;&#26631;&#32423;&#21035;&#24191;&#20041;&#20809;&#28369;&#24615;&#21644;&#20223;&#23556;&#22122;&#22768;&#26041;&#24046;&#30340;&#26368;&#23485;&#26494;&#20551;&#35774;&#19979;&#65292;&#20026;&#38750;&#20984;&#20248;&#21270;&#20013;&#30340;RMSProp&#21644;Adam&#25552;&#20379;&#20102;&#39318;&#20010;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;&#39318;&#20808;&#20998;&#26512;&#20102;RMSProp&#65292;&#23427;&#26159;&#19968;&#31181;&#20855;&#26377;&#33258;&#36866;&#24212;&#23398;&#20064;&#29575;&#20294;&#27809;&#26377;&#19968;&#38454;&#21160;&#37327;&#30340;Adam&#30340;&#29305;&#20363;&#12290;&#20855;&#20307;&#22320;&#65292;&#20026;&#20102;&#35299;&#20915;&#33258;&#36866;&#24212;&#26356;&#26032;&#12289;&#26080;&#30028;&#26799;&#24230;&#20272;&#35745;&#21644;Lipschitz&#24120;&#25968;&#20043;&#38388;&#30340;&#20381;&#36182;&#25361;&#25112;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19979;&#38477;&#24341;&#29702;&#20013;&#30340;&#19968;&#38454;&#39033;&#25910;&#25947;&#65292;&#24182;&#19988;&#20854;&#20998;&#27597;&#30001;&#26799;&#24230;&#33539;&#25968;&#30340;&#20989;&#25968;&#19978;&#30028;&#38480;&#21046;&#12290;&#22522;&#20110;&#36825;&#19968;&#32467;&#26524;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20351;&#29992;&#36866;&#24403;&#30340;&#36229;&#21442;&#25968;&#30340;RMSProp&#25910;&#25947;&#21040;&#19968;&#20010;$\epsilon$-&#31283;&#23450;&#28857;&#65292;&#20854;&#36845;&#20195;&#22797;&#26434;&#24230;&#20026;$\mathcal O(\epsilon^{-4})$&#12290;&#28982;&#21518;&#65292;&#23558;&#25105;&#20204;&#30340;&#20998;&#26512;&#25512;&#24191;&#21040;Adam&#65292;&#39069;&#22806;&#30340;&#25361;&#25112;&#26159;&#30001;&#20110;&#26799;&#24230;&#19982;&#19968;&#38454;&#21160;&#37327;&#20043;&#38388;&#30340;&#19981;&#21305;&#37197;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#19978;&#30028;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01436v1 Announce Type: cross  Abstract: This paper provides the first tight convergence analyses for RMSProp and Adam in non-convex optimization under the most relaxed assumptions of coordinate-wise generalized smoothness and affine noise variance. We first analyze RMSProp, which is a special case of Adam with adaptive learning rates but without first-order momentum. Specifically, to solve the challenges due to dependence among adaptive update, unbounded gradient estimate and Lipschitz constant, we demonstrate that the first-order term in the descent lemma converges and its denominator is upper bounded by a function of gradient norm. Based on this result, we show that RMSProp with proper hyperparameters converges to an $\epsilon$-stationary point with an iteration complexity of $\mathcal O(\epsilon^{-4})$. We then generalize our analysis to Adam, where the additional challenge is due to a mismatch between the gradient and first-order momentum. We develop a new upper bound on
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#27604;&#36739;&#25968;&#25454;&#21462;&#20195;&#21644;&#25968;&#25454;&#31215;&#32047;&#20004;&#31181;&#24773;&#20917;&#65292;&#21457;&#29616;&#32047;&#31215;&#25968;&#25454;&#21487;&#20197;&#38450;&#27490;&#27169;&#22411;&#23849;&#28291;&#12290;</title><link>https://arxiv.org/abs/2404.01413</link><description>&lt;p&gt;
&#27169;&#22411;&#23849;&#28291;&#26159;&#21542;&#19981;&#21487;&#36991;&#20813;&#65311;&#36890;&#36807;&#32047;&#31215;&#30495;&#23454;&#21644;&#21512;&#25104;&#25968;&#25454;&#25171;&#30772;&#36882;&#24402;&#30340;&#35781;&#21650;
&lt;/p&gt;
&lt;p&gt;
Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01413
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#27604;&#36739;&#25968;&#25454;&#21462;&#20195;&#21644;&#25968;&#25454;&#31215;&#32047;&#20004;&#31181;&#24773;&#20917;&#65292;&#21457;&#29616;&#32047;&#31215;&#25968;&#25454;&#21487;&#20197;&#38450;&#27490;&#27169;&#22411;&#23849;&#28291;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#29983;&#25104;&#27169;&#22411;&#30340;&#28608;&#22686;&#65292;&#20197;&#21450;&#22312;&#32593;&#32476;&#35268;&#27169;&#25968;&#25454;&#19978;&#30340;&#39044;&#35757;&#32451;&#65292;&#19968;&#20010;&#21450;&#26102;&#30340;&#38382;&#39064;&#28014;&#20986;&#27700;&#38754;&#65306;&#24403;&#36825;&#20123;&#27169;&#22411;&#34987;&#35757;&#32451;&#22312;&#23427;&#20204;&#33258;&#24049;&#29983;&#25104;&#30340;&#36755;&#20986;&#19978;&#26102;&#20250;&#21457;&#29983;&#20160;&#20040;&#65311;&#26368;&#36817;&#23545;&#27169;&#22411;&#25968;&#25454;&#21453;&#39304;&#24490;&#29615;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#36825;&#26679;&#30340;&#24490;&#29615;&#21487;&#33021;&#23548;&#33268;&#27169;&#22411;&#23849;&#28291;&#65292;&#21363;&#24615;&#33021;&#38543;&#30528;&#27599;&#27425;&#27169;&#22411;&#25311;&#21512;&#36845;&#20195;&#36880;&#28176;&#19979;&#38477;&#65292;&#30452;&#21040;&#26368;&#26032;&#30340;&#27169;&#22411;&#21464;&#24471;&#26080;&#29992;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#20960;&#31687;&#30740;&#31350;&#27169;&#22411;&#23849;&#28291;&#30340;&#35770;&#25991;&#37117;&#20551;&#35774;&#38543;&#30528;&#26102;&#38388;&#25512;&#31227;&#65292;&#26032;&#25968;&#25454;&#20250;&#21462;&#20195;&#26087;&#25968;&#25454;&#65292;&#32780;&#19981;&#26159;&#20551;&#35774;&#25968;&#25454;&#20250;&#38543;&#26102;&#38388;&#32047;&#31215;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#27604;&#36739;&#20102;&#36825;&#20004;&#31181;&#24773;&#20917;&#65292;&#24182;&#34920;&#26126;&#31215;&#32047;&#25968;&#25454;&#21487;&#20197;&#38450;&#27490;&#27169;&#22411;&#23849;&#28291;&#12290;&#25105;&#20204;&#39318;&#20808;&#30740;&#31350;&#20102;&#19968;&#20010;&#35299;&#26512;&#21487;&#22788;&#29702;&#30340;&#35774;&#32622;&#65292;&#20854;&#20013;&#19968;&#31995;&#21015;&#32447;&#24615;&#27169;&#22411;&#25311;&#21512;&#21040;&#20808;&#21069;&#27169;&#22411;&#30340;&#39044;&#27979;&#12290;&#20808;&#21069;&#30340;&#24037;&#20316;&#34920;&#26126;&#65292;&#22914;&#26524;&#25968;&#25454;&#34987;&#26367;&#25442;&#65292;&#27979;&#35797;&#35823;&#24046;&#20250;&#38543;&#30528;&#27169;&#22411;&#25311;&#21512;&#36845;&#20195;&#27425;&#25968;&#32447;&#24615;&#22686;&#21152;&#65307;&#25105;&#20204;&#25193;&#23637;&#20102;&#36825;&#20010;&#30740;&#31350;&#25506;&#35752;&#20102;&#25968;&#25454;&#36880;&#28176;&#32047;&#31215;&#30340;&#24773;&#20917;&#19979;&#20250;&#21457;&#29983;&#20160;&#20040;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01413v1 Announce Type: cross  Abstract: The proliferation of generative models, combined with pretraining on web-scale data, raises a timely question: what happens when these models are trained on their own generated outputs? Recent investigations into model-data feedback loops discovered that such loops can lead to model collapse, a phenomenon where performance progressively degrades with each model-fitting iteration until the latest model becomes useless. However, several recent papers studying model collapse assumed that new data replace old data over time rather than assuming data accumulate over time. In this paper, we compare these two settings and show that accumulating data prevents model collapse. We begin by studying an analytically tractable setup in which a sequence of linear models are fit to the previous models' predictions. Previous work showed if data are replaced, the test error increases linearly with the number of model-fitting iterations; we extend this r
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#21033;&#29992;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#25216;&#26415;&#35299;&#20915;&#20102;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#30340;&#20316;&#19994;&#36710;&#38388;&#35843;&#24230;&#38382;&#39064;&#65292;&#37325;&#28857;&#22312;&#20110;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#26041;&#27861;&#26469;&#22788;&#29702;&#20855;&#26377;&#19981;&#30830;&#23450;&#25345;&#32493;&#26102;&#38388;&#30340;JSSP&#12290;</title><link>https://arxiv.org/abs/2404.01308</link><description>&lt;p&gt;
&#23398;&#20064;&#22312;&#19981;&#30830;&#23450;&#24615;&#19979;&#35299;&#20915;&#20316;&#19994;&#36710;&#38388;&#35843;&#24230;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Learning to Solve Job Shop Scheduling under Uncertainty
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01308
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#21033;&#29992;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#25216;&#26415;&#35299;&#20915;&#20102;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#30340;&#20316;&#19994;&#36710;&#38388;&#35843;&#24230;&#38382;&#39064;&#65292;&#37325;&#28857;&#22312;&#20110;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#26041;&#27861;&#26469;&#22788;&#29702;&#20855;&#26377;&#19981;&#30830;&#23450;&#25345;&#32493;&#26102;&#38388;&#30340;JSSP&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20316;&#19994;&#36710;&#38388;&#35843;&#24230;&#38382;&#39064;&#65288;JSSP&#65289;&#26159;&#19968;&#20010;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#65292;&#20854;&#20013;&#20219;&#21153;&#38656;&#35201;&#22312;&#26426;&#22120;&#19978;&#36827;&#34892;&#35843;&#24230;&#65292;&#20197;&#26368;&#23567;&#21270;&#35832;&#22914;&#26368;&#22823;&#23436;&#24037;&#26102;&#38388;&#25110;&#24310;&#36831;&#31561;&#26631;&#20934;&#12290;&#20026;&#20102;&#35299;&#20915;&#26356;&#21152;&#29616;&#23454;&#30340;&#22330;&#26223;&#65292;&#25105;&#20204;&#20026;&#27599;&#20010;&#20219;&#21153;&#30340;&#25345;&#32493;&#26102;&#38388;&#20851;&#32852;&#20102;&#19968;&#20010;&#27010;&#29575;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#29983;&#25104;&#19968;&#20010;&#31283;&#20581;&#30340;&#35843;&#24230;&#65292;&#21363;&#26368;&#23567;&#21270;&#24179;&#22343;&#23436;&#24037;&#26102;&#38388;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#65288;DRL&#65289;&#25216;&#26415;&#26469;&#23547;&#25214;&#31283;&#20581;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#37325;&#28857;&#20851;&#27880;&#20855;&#26377;&#19981;&#30830;&#23450;&#25345;&#32493;&#26102;&#38388;&#30340;JSSP&#12290;&#26412;&#30740;&#31350;&#30340;&#20851;&#38190;&#36129;&#29486;&#21253;&#25324;&#65306;&#65288;1&#65289;DRL&#22312;JSSP&#24212;&#29992;&#20013;&#30340;&#36827;&#23637;&#65292;&#22686;&#24378;&#27867;&#21270;&#24615;&#21644;&#21487;&#20280;&#32553;&#24615;&#65292;&#65288;2&#65289;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#20855;&#26377;&#19981;&#30830;&#23450;&#25345;&#32493;&#26102;&#38388;&#30340;JSSP&#12290; Wheatley&#26041;&#27861;&#65292;&#38598;&#25104;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#21644;DRL&#65292;&#24050;&#20844;&#24320;&#21487;&#29992;&#20110;&#36827;&#19968;&#27493;&#30340;&#30740;&#31350;&#21644;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01308v1 Announce Type: new  Abstract: Job-Shop Scheduling Problem (JSSP) is a combinatorial optimization problem where tasks need to be scheduled on machines in order to minimize criteria such as makespan or delay. To address more realistic scenarios, we associate a probability distribution with the duration of each task. Our objective is to generate a robust schedule, i.e. that minimizes the average makespan. This paper introduces a new approach that leverages Deep Reinforcement Learning (DRL) techniques to search for robust solutions, emphasizing JSSPs with uncertain durations. Key contributions of this research include: (1) advancements in DRL applications to JSSPs, enhancing generalization and scalability, (2) a novel method for addressing JSSPs with uncertain durations. The Wheatley approach, which integrates Graph Neural Networks (GNNs) and DRL, is made publicly available for further research and applications.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Systemic Quantum Score (SQS)&#30340;&#26032;&#26041;&#27861;&#65292;&#23637;&#31034;&#22312;&#37329;&#34701;&#39046;&#22495;&#29983;&#20135;&#32423;&#24212;&#29992;&#26696;&#20363;&#20013;&#30456;&#27604;&#32431;&#32463;&#20856;&#27169;&#22411;&#26356;&#26377;&#20248;&#21183;&#65292;&#33021;&#22815;&#20174;&#36739;&#23569;&#25968;&#25454;&#28857;&#20013;&#25552;&#21462;&#27169;&#24335;&#24182;&#34920;&#29616;&#20986;&#26356;&#22909;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2404.00015</link><description>&lt;p&gt;
&#21033;&#29992;&#37327;&#23376;&#22686;&#24378;&#26426;&#22120;&#23398;&#20064;&#36171;&#33021;&#20449;&#29992;&#35780;&#20998;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Empowering Credit Scoring Systems with Quantum-Enhanced Machine Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00015
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Systemic Quantum Score (SQS)&#30340;&#26032;&#26041;&#27861;&#65292;&#23637;&#31034;&#22312;&#37329;&#34701;&#39046;&#22495;&#29983;&#20135;&#32423;&#24212;&#29992;&#26696;&#20363;&#20013;&#30456;&#27604;&#32431;&#32463;&#20856;&#27169;&#22411;&#26356;&#26377;&#20248;&#21183;&#65292;&#33021;&#22815;&#20174;&#36739;&#23569;&#25968;&#25454;&#28857;&#20013;&#25552;&#21462;&#27169;&#24335;&#24182;&#34920;&#29616;&#20986;&#26356;&#22909;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Quantum Kernels&#34987;&#35748;&#20026;&#22312;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#30340;&#26089;&#26399;&#38454;&#27573;&#25552;&#20379;&#20102;&#26377;&#29992;&#24615;&#12290;&#28982;&#32780;&#65292;&#22312;&#21033;&#29992;&#24222;&#22823;&#25968;&#25454;&#38598;&#26102;&#65292;&#39640;&#24230;&#22797;&#26434;&#30340;&#32463;&#20856;&#27169;&#22411;&#24456;&#38590;&#36229;&#36234;&#65292;&#29305;&#21035;&#26159;&#22312;&#29702;&#35299;&#21147;&#26041;&#38754;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#19968;&#26086;&#25968;&#25454;&#31232;&#32570;&#19988;&#20542;&#26012;&#65292;&#32463;&#20856;&#27169;&#22411;&#23601;&#20250;&#36935;&#21040;&#22256;&#38590;&#12290;&#37327;&#23376;&#29305;&#24449;&#31354;&#38388;&#34987;&#39044;&#35745;&#22312;&#36825;&#26679;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#24773;&#26223;&#20013;&#33021;&#22815;&#25214;&#21040;&#26356;&#22909;&#30340;&#25968;&#25454;&#29305;&#24449;&#21644;&#30446;&#26631;&#31867;&#21035;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#26368;&#37325;&#35201;&#30340;&#26159;&#22686;&#24378;&#20102;&#27867;&#21270;&#33021;&#21147;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Systemic Quantum Score (SQS)&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#21021;&#27493;&#32467;&#26524;&#65292;&#34920;&#26126;&#22312;&#37329;&#34701;&#34892;&#19994;&#29983;&#20135;&#32423;&#24212;&#29992;&#26696;&#20363;&#20013;&#65292;SQS&#21487;&#33021;&#27604;&#32431;&#32463;&#20856;&#27169;&#22411;&#20855;&#26377;&#20248;&#21183;&#12290;&#25105;&#20204;&#30340;&#20855;&#20307;&#30740;&#31350;&#34920;&#26126;&#65292;SQS&#33021;&#22815;&#20174;&#36739;&#23569;&#30340;&#25968;&#25454;&#28857;&#20013;&#25552;&#21462;&#20986;&#27169;&#24335;&#65292;&#24182;&#19988;&#22312;&#25968;&#25454;&#38656;&#27714;&#37327;&#22823;&#30340;&#31639;&#27861;&#65288;&#22914;XGBoost&#65289;&#19978;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#24102;&#26469;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00015v1 Announce Type: cross  Abstract: Quantum Kernels are projected to provide early-stage usefulness for quantum machine learning. However, highly sophisticated classical models are hard to surpass without losing interpretability, particularly when vast datasets can be exploited. Nonetheless, classical models struggle once data is scarce and skewed. Quantum feature spaces are projected to find better links between data features and the target class to be predicted even in such challenging scenarios and most importantly, enhanced generalization capabilities. In this work, we propose a novel approach called Systemic Quantum Score (SQS) and provide preliminary results indicating potential advantage over purely classical models in a production grade use case for the Finance sector. SQS shows in our specific study an increased capacity to extract patterns out of fewer data points as well as improved performance over data-hungry algorithms such as XGBoost, providing advantage i
&lt;/p&gt;</description></item><item><title>&#23545;&#20110;&#21487;&#20998;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#19978;&#30340;&#27010;&#29575;&#27979;&#24230;&#19982;&#20854;&#32463;&#39564;&#20998;&#24067;&#20043;&#38388;&#30340;&#26368;&#22823;&#20999;&#29255;1-Wasserstein&#36317;&#31163;&#65292;&#24471;&#21040;&#20102;&#23574;&#38160;&#30340;&#19978;&#19979;&#30028;&#38480;&#12290;</title><link>https://arxiv.org/abs/2403.00666</link><description>&lt;p&gt;
&#26368;&#22823;&#20999;&#29255;Wasserstein&#36317;&#31163;&#30340;&#23574;&#38160;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Sharp bounds for the max-sliced Wasserstein distance
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00666
&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#21487;&#20998;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#19978;&#30340;&#27010;&#29575;&#27979;&#24230;&#19982;&#20854;&#32463;&#39564;&#20998;&#24067;&#20043;&#38388;&#30340;&#26368;&#22823;&#20999;&#29255;1-Wasserstein&#36317;&#31163;&#65292;&#24471;&#21040;&#20102;&#23574;&#38160;&#30340;&#19978;&#19979;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24471;&#21040;&#20102;&#20851;&#20110;&#22312;&#21487;&#20998;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#19978;&#30340;&#27010;&#29575;&#27979;&#24230;&#19982;&#20174;$n$&#20010;&#26679;&#26412;&#20013;&#33719;&#24471;&#30340;&#32463;&#39564;&#20998;&#24067;&#20043;&#38388;&#26399;&#26395;&#30340;&#26368;&#22823;&#20999;&#29255;1-Wasserstein&#36317;&#31163;&#30340;&#23574;&#38160;&#19978;&#19979;&#30028;&#12290;&#25105;&#20204;&#36824;&#24471;&#21040;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;Banach&#31354;&#38388;&#19978;&#30340;&#27010;&#29575;&#27979;&#24230;&#30340;&#29256;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00666v1 Announce Type: cross  Abstract: We obtain sharp upper and lower bounds for the expected max-sliced 1-Wasserstein distance between a probability measure on a separable Hilbert space and its empirical distribution from $n$ samples. A version of this result for probability measures on Banach spaces is also obtained.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#23398;&#20064;&#24191;&#20041;&#26391;&#20043;&#19975;&#26041;&#31243;&#20013;&#35760;&#24518;&#26680;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#27491;&#21017;&#21270;Prony&#26041;&#27861;&#20272;&#35745;&#30456;&#20851;&#20989;&#25968;&#24182;&#22312;Sobolev&#33539;&#25968;Loss&#20989;&#25968;&#21644;RKHS&#27491;&#21017;&#21270;&#19979;&#23454;&#29616;&#22238;&#24402;&#65292;&#22312;&#25351;&#25968;&#21152;&#26435;&#30340;$L^2$&#31354;&#38388;&#20869;&#33719;&#24471;&#25913;&#36827;&#24615;&#33021;&#65292;&#23545;&#27604;&#20854;&#20182;&#22238;&#24402;&#20272;&#35745;&#22120;&#23637;&#31034;&#20102;&#20854;&#20248;&#36234;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.11705</link><description>&lt;p&gt;
&#22312;&#24191;&#20041;&#26391;&#20043;&#19975;&#26041;&#31243;&#20013;&#23398;&#20064;&#35760;&#24518;&#26680;
&lt;/p&gt;
&lt;p&gt;
Learning Memory Kernels in Generalized Langevin Equations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.11705
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#23398;&#20064;&#24191;&#20041;&#26391;&#20043;&#19975;&#26041;&#31243;&#20013;&#35760;&#24518;&#26680;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#27491;&#21017;&#21270;Prony&#26041;&#27861;&#20272;&#35745;&#30456;&#20851;&#20989;&#25968;&#24182;&#22312;Sobolev&#33539;&#25968;Loss&#20989;&#25968;&#21644;RKHS&#27491;&#21017;&#21270;&#19979;&#23454;&#29616;&#22238;&#24402;&#65292;&#22312;&#25351;&#25968;&#21152;&#26435;&#30340;$L^2$&#31354;&#38388;&#20869;&#33719;&#24471;&#25913;&#36827;&#24615;&#33021;&#65292;&#23545;&#27604;&#20854;&#20182;&#22238;&#24402;&#20272;&#35745;&#22120;&#23637;&#31034;&#20102;&#20854;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#26469;&#23398;&#20064;&#24191;&#20041;&#26391;&#20043;&#19975;&#26041;&#31243;&#20013;&#30340;&#35760;&#24518;&#26680;&#12290;&#35813;&#26041;&#27861;&#26368;&#21021;&#21033;&#29992;&#27491;&#21017;&#21270;Prony&#26041;&#27861;&#20174;&#36712;&#36857;&#25968;&#25454;&#20013;&#20272;&#35745;&#30456;&#20851;&#20989;&#25968;&#65292;&#28982;&#21518;&#36890;&#36807;&#22522;&#20110;Sobolev&#33539;&#25968;&#30340;&#22238;&#24402;&#21644;RKHS&#27491;&#21017;&#21270;&#26469;&#36827;&#34892;&#22238;&#24402;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20445;&#35777;&#22312;&#25351;&#25968;&#21152;&#26435;&#30340;$L^2$&#31354;&#38388;&#20869;&#33719;&#24471;&#20102;&#25913;&#36827;&#30340;&#24615;&#33021;&#65292;&#26680;&#20272;&#35745;&#35823;&#24046;&#21463;&#25511;&#20110;&#20272;&#35745;&#30456;&#20851;&#20989;&#25968;&#30340;&#35823;&#24046;&#12290;&#25105;&#20204;&#36890;&#36807;&#25968;&#20540;&#31034;&#20363;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#30456;&#23545;&#20110;&#20381;&#36182;&#20110;$L^2$&#25439;&#22833;&#20989;&#25968;&#30340;&#20854;&#20182;&#22238;&#24402;&#20272;&#35745;&#22120;&#20197;&#21450;&#20174;&#36870;&#25289;&#26222;&#25289;&#26031;&#21464;&#25442;&#25512;&#23548;&#20986;&#30340;&#20272;&#35745;&#22120;&#30340;&#20248;&#36234;&#24615;&#65292;&#36825;&#20123;&#31034;&#20363;&#31361;&#26174;&#20102;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#22312;&#21508;&#31181;&#26435;&#37325;&#21442;&#25968;&#36873;&#25321;&#19978;&#30340;&#25345;&#32493;&#20248;&#21183;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#21253;&#25324;&#21147;&#21644;&#28418;&#31227;&#39033;&#22312;&#26041;&#31243;&#20013;&#30340;&#24212;&#29992;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.11705v1 Announce Type: cross  Abstract: We introduce a novel approach for learning memory kernels in Generalized Langevin Equations. This approach initially utilizes a regularized Prony method to estimate correlation functions from trajectory data, followed by regression over a Sobolev norm-based loss function with RKHS regularization. Our approach guarantees improved performance within an exponentially weighted $L^2$ space, with the kernel estimation error controlled by the error in estimated correlation functions. We demonstrate the superiority of our estimator compared to other regression estimators that rely on $L^2$ loss functions and also an estimator derived from the inverse Laplace transform, using numerical examples that highlight its consistent advantage across various weight parameter selections. Additionally, we provide examples that include the application of force and drift terms in the equation.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#36335;&#24452;&#31354;&#38388;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;PKF&#65289;&#30340;&#25193;&#23637;&#31639;&#27861;&#65292;&#21487;&#20197;&#21160;&#24577;&#36319;&#36394;&#25968;&#25454;&#21644;&#20808;&#21069;&#30693;&#35782;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#29992;&#36125;&#21494;&#26031;&#26041;&#27861;&#37327;&#21270;&#19981;&#21516;&#30340;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#12290;&#36890;&#36807;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#25968;&#20540;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;PKF&#20248;&#20110;&#20256;&#32479;KF&#26041;&#27861;&#65292;&#24182;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;&#29983;&#29289;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#12290;</title><link>https://arxiv.org/abs/2402.04498</link><description>&lt;p&gt;
&#24102;&#26377;&#21160;&#24577;&#36807;&#31243;&#19981;&#30830;&#23450;&#24615;&#30340;&#36335;&#24452;&#31354;&#38388;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Pathspace Kalman Filters with Dynamic Process Uncertainty for Analyzing Time-course Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04498
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#36335;&#24452;&#31354;&#38388;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;PKF&#65289;&#30340;&#25193;&#23637;&#31639;&#27861;&#65292;&#21487;&#20197;&#21160;&#24577;&#36319;&#36394;&#25968;&#25454;&#21644;&#20808;&#21069;&#30693;&#35782;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#29992;&#36125;&#21494;&#26031;&#26041;&#27861;&#37327;&#21270;&#19981;&#21516;&#30340;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#12290;&#36890;&#36807;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#25968;&#20540;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;PKF&#20248;&#20110;&#20256;&#32479;KF&#26041;&#27861;&#65292;&#24182;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;&#29983;&#29289;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;KF&#65289;&#26159;&#19968;&#31181;&#26368;&#20248;&#32447;&#24615;&#29366;&#24577;&#39044;&#27979;&#31639;&#27861;&#65292;&#24191;&#27867;&#24212;&#29992;&#20110;&#24037;&#31243;&#23398;&#12289;&#32463;&#27982;&#23398;&#12289;&#26426;&#22120;&#20154;&#23398;&#21644;&#22826;&#31354;&#25506;&#32034;&#31561;&#39046;&#22495;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21457;&#23637;&#20102;KF&#30340;&#25193;&#23637;&#65292;&#31216;&#20026;&#36335;&#24452;&#31354;&#38388;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;PKF&#65289;&#65292;&#23427;&#20801;&#35768;&#25105;&#20204;&#21160;&#24577;&#36319;&#36394;&#19982;&#24213;&#23618;&#25968;&#25454;&#21644;&#20808;&#21069;&#30693;&#35782;&#30456;&#20851;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#20351;&#29992;&#36125;&#21494;&#26031;&#26041;&#27861;&#37327;&#21270;&#19981;&#21516;&#30340;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#12290;&#35813;&#31639;&#27861;&#30340;&#19968;&#20010;&#24212;&#29992;&#26159;&#33258;&#21160;&#26816;&#27979;&#20869;&#37096;&#26426;&#21046;&#27169;&#22411;&#19982;&#25968;&#25454;&#22312;&#26102;&#38388;&#19978;&#21457;&#29983;&#21464;&#21270;&#30340;&#26102;&#38388;&#31383;&#21475;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#25551;&#36848;PKF&#31639;&#27861;&#25910;&#25947;&#24615;&#30340;&#23450;&#29702;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;PKF&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#20248;&#20110;&#20256;&#32479;KF&#26041;&#27861;&#65292;&#24179;&#22343;&#22343;&#26041;&#35823;&#24046;&#38477;&#20302;&#20102;&#25968;&#20010;&#25968;&#37327;&#32423;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;&#29983;&#29289;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
Kalman Filter (KF) is an optimal linear state prediction algorithm, with applications in fields as diverse as engineering, economics, robotics, and space exploration. Here, we develop an extension of the KF, called a Pathspace Kalman Filter (PKF) which allows us to a) dynamically track the uncertainties associated with the underlying data and prior knowledge, and b) take as input an entire trajectory and an underlying mechanistic model, and using a Bayesian methodology quantify the different sources of uncertainty. An application of this algorithm is to automatically detect temporal windows where the internal mechanistic model deviates from the data in a time-dependent manner. First, we provide theorems characterizing the convergence of the PKF algorithm. Then, we numerically demonstrate that the PKF outperforms conventional KF methods on a synthetic dataset lowering the mean-squared-error by several orders of magnitude. Finally, we apply this method to biological time-course dataset i
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#36890;&#36807;&#25506;&#32034;&#22810;&#31181;&#26041;&#27861;&#65292;&#23558;&#38024;&#23545;&#20302;&#31209;MDPs&#30340;&#29616;&#26377;&#26041;&#27861;&#25193;&#23637;&#21040;&#36830;&#32493;&#21160;&#20316;&#31354;&#38388;&#65292;&#21516;&#26102;&#20445;&#25345;&#36817;&#20284;&#27491;&#30830;&#30340;&#23398;&#20064;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2311.03564</link><description>&lt;p&gt;
&#20855;&#26377;&#36830;&#32493;&#21160;&#20316;&#31354;&#38388;&#30340;&#20302;&#31209;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Low-Rank MDPs with Continuous Action Spaces
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.03564
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#36890;&#36807;&#25506;&#32034;&#22810;&#31181;&#26041;&#27861;&#65292;&#23558;&#38024;&#23545;&#20302;&#31209;MDPs&#30340;&#29616;&#26377;&#26041;&#27861;&#25193;&#23637;&#21040;&#36830;&#32493;&#21160;&#20316;&#31354;&#38388;&#65292;&#21516;&#26102;&#20445;&#25345;&#36817;&#20284;&#27491;&#30830;&#30340;&#23398;&#20064;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20302;&#31209;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDPs&#65289;&#26368;&#36817;&#22312;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#39046;&#22495;&#20013;&#23853;&#38706;&#22836;&#35282;&#65292;&#22240;&#20026;&#23427;&#20204;&#21487;&#20197;&#25552;&#20379;&#32422;&#31561;&#20110;&#27491;&#30830;&#65288;PAC&#65289;&#30340;&#23398;&#20064;&#20445;&#35777;&#65292;&#21516;&#26102;&#36824;&#21487;&#20197;&#34701;&#21512;ML&#31639;&#27861;&#36827;&#34892;&#34920;&#31034;&#23398;&#20064;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#23545;&#20302;&#31209;MDPs&#30340;&#26041;&#27861;&#23384;&#22312;&#23616;&#38480;&#24615;&#65292;&#23427;&#20204;&#21482;&#32771;&#34385;&#26377;&#38480;&#30340;&#21160;&#20316;&#31354;&#38388;&#65292;&#24182;&#19988;&#22312;&#21160;&#20316;&#25968;&#37327;$|\mathcal{A}| \to \infty$&#26102;&#32473;&#20986;&#20102;&#31354;&#27934;&#30340;&#30028;&#38480;&#65292;&#36825;&#26497;&#22823;&#22320;&#38480;&#21046;&#20102;&#23427;&#20204;&#30340;&#36866;&#29992;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#23558;&#36825;&#20123;&#26041;&#27861;&#25193;&#23637;&#21040;&#20855;&#26377;&#36830;&#32493;&#21160;&#20316;&#30340;&#35774;&#32622;&#30340;&#38382;&#39064;&#65292;&#24182;&#25506;&#35752;&#20102;&#22810;&#31181;&#20855;&#20307;&#30340;&#26041;&#27861;&#26469;&#36827;&#34892;&#36825;&#31181;&#25193;&#23637;&#12290;&#20316;&#20026;&#26696;&#20363;&#30740;&#31350;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;FLAMBE&#31639;&#27861;&#65288;Agarwal&#31561;&#65292;2020&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#29992;&#20110;&#20302;&#31209;MDPs&#30340;PAC RL&#30340;&#22870;&#21169;&#26080;&#20851;&#26041;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#65292;&#22312;&#19981;&#23545;&#31639;&#27861;&#36827;&#34892;&#20219;&#20309;&#20462;&#25913;&#30340;&#24773;&#20917;&#19979;&#65292;&#24403;&#20801;&#35768;&#21160;&#20316;&#20026;&#36830;&#32493;&#26102;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#31867;&#20284;&#30340;PAC&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.03564v2 Announce Type: replace-cross  Abstract: Low-Rank Markov Decision Processes (MDPs) have recently emerged as a promising framework within the domain of reinforcement learning (RL), as they allow for provably approximately correct (PAC) learning guarantees while also incorporating ML algorithms for representation learning. However, current methods for low-rank MDPs are limited in that they only consider finite action spaces, and give vacuous bounds as $|\mathcal{A}| \to \infty$, which greatly limits their applicability. In this work, we study the problem of extending such methods to settings with continuous actions, and explore multiple concrete approaches for performing this extension. As a case study, we consider the seminal FLAMBE algorithm (Agarwal et al., 2020), which is a reward-agnostic method for PAC RL with low-rank MDPs. We show that, without any modifications to the algorithm, we obtain a similar PAC bound when actions are allowed to be continuous. Specifical
&lt;/p&gt;</description></item><item><title>&#25913;&#36827;&#24739;&#32773;&#25252;&#29702;&#38656;&#35201;&#32771;&#34385;&#22240;&#26524;&#20851;&#31995;&#65292;&#24314;&#31435;&#21644;&#39564;&#35777;&#30340;&#39044;&#27979;&#27169;&#22411;&#24517;&#39035;&#23545;&#27835;&#30103;&#20915;&#31574;&#30340;&#22240;&#26524;&#20851;&#31995;&#36827;&#34892;&#32771;&#34385;&#65292;&#20197;&#36991;&#20813;&#22312;&#20915;&#31574;&#26102;&#36896;&#25104;&#20260;&#23475;&#12290;</title><link>https://arxiv.org/abs/2209.07397</link><description>&lt;p&gt;
&#20174;&#31639;&#27861;&#21040;&#34892;&#21160;&#65306;&#25913;&#36827;&#24739;&#32773;&#25252;&#29702;&#38656;&#35201;&#22240;&#26524;&#20851;&#31995;
&lt;/p&gt;
&lt;p&gt;
From algorithms to action: improving patient care requires causality
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2209.07397
&lt;/p&gt;
&lt;p&gt;
&#25913;&#36827;&#24739;&#32773;&#25252;&#29702;&#38656;&#35201;&#32771;&#34385;&#22240;&#26524;&#20851;&#31995;&#65292;&#24314;&#31435;&#21644;&#39564;&#35777;&#30340;&#39044;&#27979;&#27169;&#22411;&#24517;&#39035;&#23545;&#27835;&#30103;&#20915;&#31574;&#30340;&#22240;&#26524;&#20851;&#31995;&#36827;&#34892;&#32771;&#34385;&#65292;&#20197;&#36991;&#20813;&#22312;&#20915;&#31574;&#26102;&#36896;&#25104;&#20260;&#23475;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#30284;&#30151;&#30740;&#31350;&#20013;&#65292;&#24314;&#31435;&#21644;&#39564;&#35777;&#39044;&#27979;&#32467;&#26524;&#30340;&#20852;&#36259;&#24456;&#22823;&#65292;&#20197;&#25903;&#25345;&#27835;&#30103;&#20915;&#31574;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#22823;&#22810;&#25968;&#32467;&#26524;&#39044;&#27979;&#27169;&#22411;&#26159;&#22312;&#19981;&#32771;&#34385;&#27835;&#30103;&#20915;&#31574;&#30340;&#22240;&#26524;&#20851;&#31995;&#30340;&#24773;&#20917;&#19979;&#24320;&#21457;&#21644;&#39564;&#35777;&#30340;&#65292;&#35768;&#22810;&#24050;&#21457;&#34920;&#30340;&#32467;&#26524;&#39044;&#27979;&#27169;&#22411;&#22312;&#29992;&#20110;&#20915;&#31574;&#26102;&#21487;&#33021;&#20250;&#36896;&#25104;&#20260;&#23475;&#65292;&#23613;&#31649;&#22312;&#39564;&#35777;&#30740;&#31350;&#20013;&#34987;&#21457;&#29616;&#20934;&#30830;&#12290;&#12298;&#32654;&#22269;&#32852;&#21512;&#30284;&#30151;&#22996;&#21592;&#20250;&#39118;&#38505;&#27169;&#22411;&#35748;&#21487;&#26680;&#26597;&#21333;&#12299;&#23545;&#39044;&#27979;&#27169;&#22411;&#30340;&#39564;&#35777;&#25351;&#21335;&#21644;&#39118;&#38505;&#27169;&#22411;&#35748;&#21487;&#26680;&#26597;&#34920;&#26080;&#27861;&#38450;&#27490;&#22312;&#24320;&#21457;&#21644;&#39564;&#35777;&#36807;&#31243;&#20013;&#20934;&#30830;&#20294;&#22312;&#29992;&#20110;&#20915;&#31574;&#26102;&#26377;&#23475;&#30340;&#39044;&#27979;&#27169;&#22411;&#30340;&#20986;&#29616;&#12290;&#25105;&#20204;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#20250;&#20986;&#29616;&#36825;&#31181;&#24773;&#20917;&#20197;&#21450;&#22914;&#20309;&#26500;&#24314;&#21644;&#39564;&#35777;&#23545;&#20915;&#31574;&#26377;&#29992;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2209.07397v2 Announce Type: replace  Abstract: In cancer research there is much interest in building and validating outcome predicting outcomes to support treatment decisions. However, because most outcome prediction models are developed and validated without regard to the causal aspects of treatment decision making, many published outcome prediction models may cause harm when used for decision making, despite being found accurate in validation studies. Guidelines on prediction model validation and the checklist for risk model endorsement by the American Joint Committee on Cancer do not protect against prediction models that are accurate during development and validation but harmful when used for decision making. We explain why this is the case and how to build and validate models that are useful for decision making.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#20013;&#20351;&#29992;&#19981;&#21516;&#24120;&#29992;&#28608;&#27963;&#20989;&#25968;&#65288;&#22914;sigmoid&#21644;&#21452;&#26354;&#27491;&#20999;&#65289;&#26102;&#30340;VC&#32500;&#24230;&#65292;&#37319;&#29992;&#20102;Pfaffian&#20989;&#25968;&#29702;&#35770;&#26694;&#26550;&#65292;&#36890;&#36807;&#26550;&#26500;&#21442;&#25968;&#21644;&#21512;&#20316;&#25968;&#37327;&#25552;&#20379;&#20102;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2401.12362</link><description>&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#24102;&#26377;Pfaffian&#28608;&#27963;&#20989;&#25968;&#30340;VC&#32500;&#24230;
&lt;/p&gt;
&lt;p&gt;
VC dimension of Graph Neural Networks with Pfaffian activation functions. (arXiv:2401.12362v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12362
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#20013;&#20351;&#29992;&#19981;&#21516;&#24120;&#29992;&#28608;&#27963;&#20989;&#25968;&#65288;&#22914;sigmoid&#21644;&#21452;&#26354;&#27491;&#20999;&#65289;&#26102;&#30340;VC&#32500;&#24230;&#65292;&#37319;&#29992;&#20102;Pfaffian&#20989;&#25968;&#29702;&#35770;&#26694;&#26550;&#65292;&#36890;&#36807;&#26550;&#26500;&#21442;&#25968;&#21644;&#21512;&#20316;&#25968;&#37327;&#25552;&#20379;&#20102;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#36817;&#24180;&#26469;&#20316;&#20026;&#19968;&#31181;&#24378;&#22823;&#30340;&#24037;&#20855;&#20986;&#29616;&#65292;&#20197;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#24335;&#23398;&#20064;&#21508;&#31181;&#22270;&#39046;&#22495;&#30340;&#20219;&#21153;&#65307;&#22522;&#20110;&#28040;&#24687;&#20256;&#36882;&#26426;&#21046;&#65292;GNN&#30001;&#20110;&#20854;&#19982;Weisfeiler-Lehman&#65288;WL&#65289;&#22270;&#21516;&#26500;&#27979;&#35797;&#23494;&#20999;&#30456;&#20851;&#30340;&#30452;&#35266;&#34920;&#36798;&#32780;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#65292;&#23427;&#20204;&#24050;&#34987;&#35777;&#26126;&#31561;&#20215;&#12290;&#20174;&#29702;&#35770;&#35282;&#24230;&#30475;&#65292;GNN&#34987;&#35777;&#26126;&#26159;&#36890;&#29992;&#36924;&#36817;&#22120;&#65292;&#24182;&#19988;&#26368;&#36817;&#23545;&#20855;&#26377;&#20998;&#27573;&#22810;&#39033;&#24335;&#28608;&#27963;&#20989;&#25968;&#30340;GNN&#30340;&#27867;&#21270;&#33021;&#21147;&#65288;&#21363;&#65292;&#23545;Vapnik Cherovenikis&#65288;VC&#65289;&#32500;&#24230;&#30340;&#30028;&#38480;&#65289;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#30446;&#26631;&#26159;&#23558;&#23545;GNN&#30340;VC&#32500;&#24230;&#30340;&#20998;&#26512;&#25193;&#23637;&#21040;&#20854;&#20182;&#24120;&#29992;&#28608;&#27963;&#20989;&#25968;&#65292;&#22914;sigmoid&#21644;&#21452;&#26354;&#27491;&#20999;&#65292;&#20351;&#29992;Pfaffian&#20989;&#25968;&#29702;&#35770;&#26694;&#26550;&#12290;&#25552;&#20379;&#20102;&#19982;&#26550;&#26500;&#21442;&#25968;&#65288;&#28145;&#24230;&#65292;&#31070;&#32463;&#20803;&#25968;&#37327;&#65292;&#36755;&#20837;&#23610;&#23544;&#65289;&#20197;&#21450;&#19982;&#21512;&#20316;&#25968;&#37327;&#26377;&#20851;&#30340;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Networks (GNNs) have emerged in recent years as a powerful tool to learn tasks across a wide range of graph domains in a data-driven fashion; based on a message passing mechanism, GNNs have gained increasing popularity due to their intuitive formulation, closely linked with the Weisfeiler-Lehman (WL) test for graph isomorphism, to which they have proven equivalent. From a theoretical point of view, GNNs have been shown to be universal approximators, and their generalization capability (namely, bounds on the Vapnik Chervonekis (VC) dimension) has recently been investigated for GNNs with piecewise polynomial activation functions. The aim of our work is to extend this analysis on the VC dimension of GNNs to other commonly used activation functions, such as sigmoid and hyperbolic tangent, using the framework of Pfaffian function theory. Bounds are provided with respect to architecture parameters (depth, number of neurons, input size) as well as with respect to the number of co
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#24314;&#31435;&#26497;&#22823;&#20284;&#28982;&#20272;&#35745;&#37327;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#32467;&#26524;&#65292;&#22635;&#34917;&#20102;&#37197;&#23545;&#27604;&#36739;&#27169;&#22411;&#20013;&#32479;&#35745;&#25512;&#26029;&#30340;&#31354;&#30333;&#65292;&#20026;&#21508;&#31181;&#37197;&#23545;&#27604;&#36739;&#27169;&#22411;&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#26041;&#27861;&#65292;&#36229;&#36234;&#20102;Bradley-Terry&#27169;&#22411;&#65292;&#20026;&#23454;&#36341;&#32773;&#25552;&#20379;&#20102;&#22362;&#23454;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2401.08463</link><description>&lt;p&gt;
&#23545;&#20110;&#37197;&#23545;&#27604;&#36739;&#27169;&#22411;&#30340;&#32479;&#35745;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Statistical inference for pairwise comparison models. (arXiv:2401.08463v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.08463
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#24314;&#31435;&#26497;&#22823;&#20284;&#28982;&#20272;&#35745;&#37327;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#32467;&#26524;&#65292;&#22635;&#34917;&#20102;&#37197;&#23545;&#27604;&#36739;&#27169;&#22411;&#20013;&#32479;&#35745;&#25512;&#26029;&#30340;&#31354;&#30333;&#65292;&#20026;&#21508;&#31181;&#37197;&#23545;&#27604;&#36739;&#27169;&#22411;&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#26041;&#27861;&#65292;&#36229;&#36234;&#20102;Bradley-Terry&#27169;&#22411;&#65292;&#20026;&#23454;&#36341;&#32773;&#25552;&#20379;&#20102;&#22362;&#23454;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37197;&#23545;&#27604;&#36739;&#27169;&#22411;&#34987;&#29992;&#20110;&#21508;&#20010;&#39046;&#22495;&#30340;&#23454;&#29992;&#24615;&#21644;&#25490;&#21517;&#35780;&#20272;&#12290;&#29616;&#20195;&#38382;&#39064;&#35268;&#27169;&#30340;&#22686;&#21152;&#24378;&#35843;&#20102;&#23545;&#20110;&#24403;&#34987;&#27604;&#36739;&#23545;&#35937;&#25968;&#37327;&#26080;&#38480;&#22686;&#21152;&#26102;&#65292;&#23545;&#20110;&#36825;&#20123;&#27169;&#22411;&#20013;&#30340;&#32479;&#35745;&#25512;&#26029;&#30340;&#29702;&#35299;&#30340;&#38656;&#27714;&#12290;&#30446;&#21069;&#65292;&#25991;&#29486;&#20013;&#23545;&#20110;&#36825;&#20123;&#27169;&#22411;&#20013;&#30340;&#32479;&#35745;&#25512;&#26029;&#30340;&#29702;&#35299;&#36824;&#30456;&#24403;&#26377;&#38480;&#65292;&#38500;&#38750;&#21482;&#26159;&#22312;&#23569;&#25968;&#29305;&#27530;&#23454;&#20363;&#20013;&#12290;&#26412;&#25991;&#36890;&#36807;&#22312;&#24191;&#27867;&#30340;&#37197;&#23545;&#27604;&#36739;&#27169;&#22411;&#20013;&#24314;&#31435;&#26497;&#22823;&#20284;&#28982;&#20272;&#35745;&#37327;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#32467;&#26524;&#26469;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#12290;&#20851;&#38190;&#24605;&#24819;&#22312;&#20110;&#23558;&#36153;&#33293;&#23572;&#20449;&#24687;&#30697;&#38453;&#35782;&#21035;&#20026;&#21152;&#26435;&#22270;&#25289;&#26222;&#25289;&#26031;&#30697;&#38453;&#65292;&#36890;&#36807;&#19968;&#31181;&#32454;&#33268;&#20837;&#24494;&#30340;&#35889;&#20998;&#26512;&#26041;&#27861;&#26469;&#36827;&#34892;&#30740;&#31350;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#20026;&#22312;&#21508;&#31181;&#37197;&#23545;&#27604;&#36739;&#27169;&#22411;&#20013;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#32479;&#19968;&#30340;&#26041;&#27861;&#65292;&#36229;&#36234;&#20102;Bradley-Terry&#27169;&#22411;&#65292;&#20026;&#23454;&#36341;&#32773;&#25552;&#20379;&#20102;&#22362;&#23454;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#36890;&#36807;&#21033;&#29992;&#21512;&#25104;&#25968;&#25454;&#36827;&#34892;&#30340;&#27169;&#25311;&#39564;&#35777;&#36825;&#19968;&#28176;&#36817;&#27491;&#24577;&#24615;&#32467;&#26524;&#65292;&#28982;&#21518;&#36827;&#34892;&#20102;
&lt;/p&gt;
&lt;p&gt;
Pairwise comparison models are used for quantitatively evaluating utility and ranking in various fields. The increasing scale of modern problems underscores the need to understand statistical inference in these models when the number of subjects diverges, which is currently lacking in the literature except in a few special instances. This paper addresses this gap by establishing an asymptotic normality result for the maximum likelihood estimator in a broad class of pairwise comparison models. The key idea lies in identifying the Fisher information matrix as a weighted graph Laplacian matrix which can be studied via a meticulous spectral analysis. Our findings provide the first unified theory for performing statistical inference in a wide range of pairwise comparison models beyond the Bradley--Terry model, benefiting practitioners with a solid theoretical guarantee for their use. Simulations utilizing synthetic data are conducted to validate the asymptotic normality result, followed by 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#29983;&#25104;&#27169;&#22411;&#22312;&#28151;&#21512;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#23545;&#31283;&#23450;&#24615;&#30340;&#24433;&#21709;&#65292;&#36890;&#36807;&#35777;&#26126;&#21021;&#22987;&#29983;&#25104;&#27169;&#22411;&#36275;&#22815;&#25509;&#36817;&#25968;&#25454;&#20998;&#24067;&#24182;&#19988;&#25968;&#25454;&#27604;&#20363;&#36866;&#24403;&#65292;&#36845;&#20195;&#35757;&#32451;&#26159;&#31283;&#23450;&#30340;&#12290;</title><link>http://arxiv.org/abs/2310.00429</link><description>&lt;p&gt;
&#20851;&#20110;&#29983;&#25104;&#27169;&#22411;&#22312;&#20854;&#33258;&#24049;&#30340;&#25968;&#25454;&#19978;&#36845;&#20195;&#35757;&#32451;&#30340;&#31283;&#23450;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Stability of Iterative Retraining of Generative Models on their own Data. (arXiv:2310.00429v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00429
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#29983;&#25104;&#27169;&#22411;&#22312;&#28151;&#21512;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#23545;&#31283;&#23450;&#24615;&#30340;&#24433;&#21709;&#65292;&#36890;&#36807;&#35777;&#26126;&#21021;&#22987;&#29983;&#25104;&#27169;&#22411;&#36275;&#22815;&#25509;&#36817;&#25968;&#25454;&#20998;&#24067;&#24182;&#19988;&#25968;&#25454;&#27604;&#20363;&#36866;&#24403;&#65292;&#36845;&#20195;&#35757;&#32451;&#26159;&#31283;&#23450;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#22312;&#24314;&#27169;&#22797;&#26434;&#25968;&#25454;&#26041;&#38754;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#36827;&#23637;&#65292;&#24448;&#24448;&#23637;&#29616;&#20986;&#36229;&#36807;&#20856;&#22411;&#20154;&#31867;&#33021;&#21147;&#30340;&#26679;&#26412;&#30495;&#23454;&#24615;&#36776;&#21035;&#33021;&#21147;&#12290;&#36825;&#19968;&#25104;&#21151;&#30340;&#20851;&#38190;&#39537;&#21160;&#21147;&#26080;&#30097;&#26159;&#36825;&#20123;&#27169;&#22411;&#28040;&#32791;&#28023;&#37327;&#32593;&#32476;&#35268;&#27169;&#25968;&#25454;&#30340;&#32467;&#26524;&#12290;&#30001;&#20110;&#36825;&#20123;&#27169;&#22411;&#24778;&#20154;&#30340;&#24615;&#33021;&#21644;&#26131;&#24471;&#24615;&#65292;&#32593;&#32476;&#19978;&#23558;&#19981;&#21487;&#36991;&#20813;&#22320;&#20986;&#29616;&#36234;&#26469;&#36234;&#22810;&#30340;&#21512;&#25104;&#20869;&#23481;&#12290;&#36825;&#20010;&#20107;&#23454;&#30452;&#25509;&#24847;&#21619;&#30528;&#29983;&#25104;&#27169;&#22411;&#30340;&#26410;&#26469;&#36845;&#20195;&#24517;&#39035;&#38754;&#23545;&#19968;&#20010;&#29616;&#23454;&#65306;&#23427;&#20204;&#30340;&#35757;&#32451;&#25968;&#25454;&#30001;&#28165;&#27905;&#25968;&#25454;&#21644;&#20808;&#21069;&#27169;&#22411;&#29983;&#25104;&#30340;&#20154;&#24037;&#25968;&#25454;&#32452;&#25104;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#26694;&#26550;&#26469;&#23545;&#28151;&#21512;&#25968;&#25454;&#38598;&#65288;&#21253;&#25324;&#30495;&#23454;&#25968;&#25454;&#21644;&#21512;&#25104;&#25968;&#25454;&#65289;&#19978;&#35757;&#32451;&#29983;&#25104;&#27169;&#22411;&#23545;&#31283;&#23450;&#24615;&#30340;&#24433;&#21709;&#36827;&#34892;&#20005;&#26684;&#30740;&#31350;&#12290;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#20102;&#22312;&#21021;&#22987;&#29983;&#25104;&#27169;&#22411;&#36275;&#22815;&#22909;&#22320;&#36817;&#20284;&#25968;&#25454;&#20998;&#24067;&#24182;&#19988;&#30495;&#23454;&#25968;&#25454;&#19982;&#21512;&#25104;&#25968;&#25454;&#30340;&#27604;&#20363;&#36866;&#24403;&#30340;&#24773;&#20917;&#19979;&#65292;&#36845;&#20195;&#35757;&#32451;&#30340;&#31283;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep generative models have made tremendous progress in modeling complex data, often exhibiting generation quality that surpasses a typical human's ability to discern the authenticity of samples. Undeniably, a key driver of this success is enabled by the massive amounts of web-scale data consumed by these models. Due to these models' striking performance and ease of availability, the web will inevitably be increasingly populated with synthetic content. Such a fact directly implies that future iterations of generative models must contend with the reality that their training is curated from both clean data and artificially generated data from past models. In this paper, we develop a framework to rigorously study the impact of training generative models on mixed datasets (of real and synthetic data) on their stability. We first prove the stability of iterative training under the condition that the initial generative models approximate the data distribution well enough and the proportion o
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#22312;&#25968;&#25454;&#20998;&#24067;&#19978;&#26159;&#31283;&#23450;&#30340;&#65292;&#24182;&#21487;&#20197;&#19982;&#29616;&#26377;&#30340;&#27169;&#22411;&#31867;&#21644;&#20840;&#23616;&#21464;&#37327;&#37325;&#35201;&#24615;&#25351;&#26631;&#32467;&#21512;&#20351;&#29992;&#12290;</title><link>http://arxiv.org/abs/2309.13775</link><description>&lt;p&gt;
&#35770;&#25991;&#26631;&#39064;&#65306;The Rashomon Importance Distribution: &#25670;&#33073;&#19981;&#31283;&#23450;&#30340;&#22522;&#20110;&#21333;&#19968;&#27169;&#22411;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;
&lt;/p&gt;
&lt;p&gt;
The Rashomon Importance Distribution: Getting RID of Unstable, Single Model-based Variable Importance. (arXiv:2309.13775v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13775
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#22312;&#25968;&#25454;&#20998;&#24067;&#19978;&#26159;&#31283;&#23450;&#30340;&#65292;&#24182;&#21487;&#20197;&#19982;&#29616;&#26377;&#30340;&#27169;&#22411;&#31867;&#21644;&#20840;&#23616;&#21464;&#37327;&#37325;&#35201;&#24615;&#25351;&#26631;&#32467;&#21512;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#21270;&#21464;&#37327;&#37325;&#35201;&#24615;&#23545;&#20110;&#22238;&#31572;&#36951;&#20256;&#23398;&#12289;&#20844;&#20849;&#25919;&#31574;&#21644;&#21307;&#23398;&#31561;&#39046;&#22495;&#30340;&#37325;&#22823;&#38382;&#39064;&#33267;&#20851;&#37325;&#35201;&#12290;&#24403;&#21069;&#30340;&#26041;&#27861;&#36890;&#24120;&#35745;&#31639;&#32473;&#23450;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#32473;&#23450;&#27169;&#22411;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#32473;&#23450;&#25968;&#25454;&#38598;&#65292;&#21487;&#33021;&#26377;&#35768;&#22810;&#27169;&#22411;&#21516;&#26679;&#33021;&#35299;&#37322;&#30446;&#26631;&#32467;&#26524;;&#22914;&#26524;&#19981;&#32771;&#34385;&#25152;&#26377;&#21487;&#33021;&#30340;&#35299;&#37322;&#65292;&#19981;&#21516;&#30340;&#30740;&#31350;&#32773;&#21487;&#33021;&#20250;&#24471;&#20986;&#35768;&#22810;&#20914;&#31361;&#20294;&#21516;&#26679;&#26377;&#25928;&#30340;&#32467;&#35770;&#12290;&#27492;&#22806;&#65292;&#21363;&#20351;&#32771;&#34385;&#20102;&#32473;&#23450;&#25968;&#25454;&#38598;&#30340;&#25152;&#26377;&#21487;&#33021;&#35299;&#37322;&#65292;&#36825;&#20123;&#27934;&#23519;&#21147;&#21487;&#33021;&#19981;&#20855;&#26377;&#26222;&#36866;&#24615;&#65292;&#22240;&#20026;&#24182;&#38750;&#25152;&#26377;&#22909;&#30340;&#35299;&#37322;&#22312;&#21512;&#29702;&#30340;&#25968;&#25454;&#25200;&#21160;&#19979;&#37117;&#26159;&#31283;&#23450;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#37327;&#21270;&#20102;&#22312;&#25152;&#26377;&#22909;&#30340;&#27169;&#22411;&#38598;&#21512;&#20013;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#65292;&#24182;&#19988;&#22312;&#25968;&#25454;&#20998;&#24067;&#19978;&#26159;&#31283;&#23450;&#30340;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#38750;&#24120;&#28789;&#27963;&#65292;&#21487;&#20197;&#19982;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#27169;&#22411;&#31867;&#21644;&#20840;&#23616;&#21464;&#37327;&#37325;&#35201;&#24615;&#25351;&#26631;&#32467;&#21512;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantifying variable importance is essential for answering high-stakes questions in fields like genetics, public policy, and medicine. Current methods generally calculate variable importance for a given model trained on a given dataset. However, for a given dataset, there may be many models that explain the target outcome equally well; without accounting for all possible explanations, different researchers may arrive at many conflicting yet equally valid conclusions given the same data. Additionally, even when accounting for all possible explanations for a given dataset, these insights may not generalize because not all good explanations are stable across reasonable data perturbations. We propose a new variable importance framework that quantifies the importance of a variable across the set of all good models and is stable across the data distribution. Our framework is extremely flexible and can be integrated with most existing model classes and global variable importance metrics. We d
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;Samplet&#22352;&#26631;&#19979;&#26680;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;&#24341;&#20837;l1&#27491;&#21017;&#21270;&#39033;&#21487;&#20197;&#22686;&#21152;&#31995;&#25968;&#30340;&#31232;&#30095;&#24615;&#12290;&#30456;&#27604;&#20110;&#21333;&#23610;&#24230;&#22522;&#65292;Samplet&#22522;&#21487;&#20197;&#26356;&#22909;&#22320;&#34920;&#31034;&#26356;&#22810;&#31867;&#22411;&#30340;&#20449;&#21495;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#20351;&#29992;&#36719;&#38408;&#20540;&#21644;&#21322;&#20809;&#28369;&#29275;&#39039;&#27861;&#35299;&#20915;&#35813;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.10180</link><description>&lt;p&gt;
&#22522;&#20110;Samplet&#22522; Pursuit &#30340;&#26680;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Samplet basis pursuit. (arXiv:2306.10180v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10180
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;Samplet&#22352;&#26631;&#19979;&#26680;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;&#24341;&#20837;l1&#27491;&#21017;&#21270;&#39033;&#21487;&#20197;&#22686;&#21152;&#31995;&#25968;&#30340;&#31232;&#30095;&#24615;&#12290;&#30456;&#27604;&#20110;&#21333;&#23610;&#24230;&#22522;&#65292;Samplet&#22522;&#21487;&#20197;&#26356;&#22909;&#22320;&#34920;&#31034;&#26356;&#22810;&#31867;&#22411;&#30340;&#20449;&#21495;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#20351;&#29992;&#36719;&#38408;&#20540;&#21644;&#21322;&#20809;&#28369;&#29275;&#39039;&#27861;&#35299;&#20915;&#35813;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#22522;&#20110;l1&#27491;&#21017;&#21270;&#30340;Samplet&#22352;&#26631;&#19979;&#30340;&#26680;&#23398;&#20064;&#38382;&#39064;&#12290;&#22312;Samplet&#22522;&#30340;&#31995;&#25968;&#19978;&#65292;&#24212;&#29992;l1&#27491;&#21017;&#21270;&#39033;&#21487;&#20197;&#24378;&#21046;&#22686;&#21152;&#31232;&#30095;&#24615;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#31216;&#36825;&#31181;&#26041;&#27861;&#20026;Samplet&#22522; Pursuit&#12290;Samplet&#22522;&#26159;&#27874;&#24418;&#31867;&#22411;&#30340;&#26377;&#31526;&#21495;&#27979;&#24230;&#65292;&#19987;&#38376;&#29992;&#20110;&#25955;&#20081;&#25968;&#25454;&#12290;&#23427;&#20204;&#20855;&#26377;&#19982;&#23567;&#27874;&#30456;&#20284;&#30340;&#26412;&#22320;&#21270;&#12289;&#22810;&#20998;&#36776;&#29575;&#20998;&#26512;&#21644;&#25968;&#25454;&#21387;&#32553;&#24615;&#36136;&#12290;&#21487;&#20197;&#22312;Samplet&#22522;&#19978;&#31232;&#30095;&#22320;&#34920;&#31034;&#30340;&#20449;&#21495;&#31867;&#27604;&#21333;&#23610;&#24230;&#22522;&#19978;&#33021;&#22815;&#34920;&#31034;&#31232;&#30095;&#30340;&#20449;&#21495;&#31867;&#21035;&#35201;&#22823;&#24471;&#22810;&#12290;&#29305;&#21035;&#22320;&#65292;&#20165;&#29992;&#22522;&#20989;&#25968;&#26144;&#23556;&#30340;&#20960;&#20010;&#29305;&#24449;&#21472;&#21152;&#21363;&#21487;&#34920;&#31034;&#30340;&#25152;&#26377;&#20449;&#21495;&#20063;&#21487;&#20197;&#22312;Samplet&#22352;&#26631;&#19979;&#23454;&#29616;&#31232;&#30095;&#34920;&#31034;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#35299;&#20915;&#35813;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#23558;&#36719;&#38408;&#20540;&#21644;&#21322;&#20809;&#28369;&#29275;&#39039;&#27861;&#30456;&#32467;&#21512;&#65292;&#24182;&#23558;&#35813;&#26041;&#27861;&#19982;&#24555;&#36895;&#36845;&#20195;&#25910;&#32553;&#38408;&#20540;&#31639;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#31232;&#30095;&#24615;&#21644;&#39044;&#27979;&#31934;&#24230;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider kernel-based learning in samplet coordinates with l1-regularization. The application of an l1-regularization term enforces sparsity of the coefficients with respect to the samplet basis. Therefore, we call this approach samplet basis pursuit. Samplets are wavelet-type signed measures, which are tailored to scattered data. They provide similar properties as wavelets in terms of localization, multiresolution analysis, and data compression. The class of signals that can sparsely be represented in a samplet basis is considerably larger than the class of signals which exhibit a sparse representation in the single-scale basis. In particular, every signal that can be represented by the superposition of only a few features of the canonical feature map is also sparse in samplet coordinates. We propose the efficient solution of the problem under consideration by combining soft-shrinkage with the semi-smooth Newton method and compare the approach to the fast iterative shrinkage thresh
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#22522;&#20110;Python&#30340;&#25945;&#31243;&#65292;&#20171;&#32461;&#20102;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;MCMC&#26041;&#27861;&#24212;&#29992;&#65292;&#36890;&#36807;&#25945;&#31243;&#20351;&#24471;&#28145;&#24230;&#23398;&#20064;&#24320;&#21457;&#32773;&#33021;&#22815;&#26356;&#22909;&#22320;&#24212;&#29992;&#36125;&#21494;&#26031;&#25512;&#26029;&#36827;&#34892;&#21442;&#25968;&#20272;&#35745;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;</title><link>http://arxiv.org/abs/2304.02595</link><description>&lt;p&gt;
&#22522;&#20110;MCMC&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65306;&#22522;&#20110;Python&#30340;&#25945;&#31243;
&lt;/p&gt;
&lt;p&gt;
Bayesian neural networks via MCMC: a Python-based tutorial. (arXiv:2304.02595v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02595
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#22522;&#20110;Python&#30340;&#25945;&#31243;&#65292;&#20171;&#32461;&#20102;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;MCMC&#26041;&#27861;&#24212;&#29992;&#65292;&#36890;&#36807;&#25945;&#31243;&#20351;&#24471;&#28145;&#24230;&#23398;&#20064;&#24320;&#21457;&#32773;&#33021;&#22815;&#26356;&#22909;&#22320;&#24212;&#29992;&#36125;&#21494;&#26031;&#25512;&#26029;&#36827;&#34892;&#21442;&#25968;&#20272;&#35745;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#25512;&#26029;&#20026;&#26426;&#22120;&#23398;&#20064;&#21644;&#28145;&#24230;&#23398;&#20064;&#25552;&#20379;&#20102;&#21442;&#25968;&#20272;&#35745;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#26041;&#27861;&#12290;&#21464;&#20998;&#25512;&#26029;&#21644;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#65288;MCMC&#65289;&#37319;&#26679;&#25216;&#26415;&#29992;&#20110;&#23454;&#29616;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;&#22312;&#36807;&#21435;&#19977;&#21313;&#24180;&#20013;&#65292;MCMC&#26041;&#27861;&#22312;&#36866;&#24212;&#26356;&#22823;&#30340;&#27169;&#22411;&#65288;&#22914;&#28145;&#24230;&#23398;&#20064;&#65289;&#21644;&#22823;&#25968;&#25454;&#38382;&#39064;&#26041;&#38754;&#38754;&#20020;&#20102;&#35768;&#22810;&#25361;&#25112;&#12290;&#21253;&#25324;&#26799;&#24230;&#30340;&#39640;&#32423;&#25552;&#35758;&#65288;&#20363;&#22914;Langevin&#25552;&#35758;&#20998;&#24067;&#65289;&#25552;&#20379;&#20102;&#19968;&#31181;&#35299;&#20915;MCMC&#37319;&#26679;&#20013;&#30340;&#19968;&#20123;&#38480;&#21046;&#30340;&#26041;&#27861;&#65292;&#27492;&#22806;&#65292;MCMC&#26041;&#27861;&#36890;&#24120;&#34987;&#38480;&#21046;&#22312;&#32479;&#35745;&#23398;&#23478;&#30340;&#20351;&#29992;&#33539;&#22260;&#20869;&#65292;&#24182;&#19988;&#20173;&#19981;&#26159;&#28145;&#24230;&#23398;&#20064;&#30740;&#31350;&#20154;&#21592;&#30340;&#20027;&#27969;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;MCMC&#26041;&#27861;&#30340;&#25945;&#31243;&#65292;&#28085;&#30422;&#20102;&#31616;&#21333;&#30340;&#36125;&#21494;&#26031;&#32447;&#24615;&#21644;&#36923;&#36753;&#27169;&#22411;&#65292;&#20197;&#21450;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#12290;&#36825;&#20010;&#25945;&#31243;&#30340;&#30446;&#30340;&#26159;&#36890;&#36807;&#32534;&#30721;&#26469;&#24357;&#21512;&#29702;&#35770;&#21644;&#23454;&#29616;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#37492;&#20110;&#24403;&#21069;MCMC&#26041;&#27861;&#30340;&#26222;&#21450;&#31243;&#24230;&#20173;&#28982;&#36739;&#20302;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian inference provides a methodology for parameter estimation and uncertainty quantification in machine learning and deep learning methods. Variational inference and Markov Chain Monte-Carlo (MCMC) sampling techniques are used to implement Bayesian inference. In the past three decades, MCMC methods have faced a number of challenges in being adapted to larger models (such as in deep learning) and big data problems. Advanced proposals that incorporate gradients, such as a Langevin proposal distribution, provide a means to address some of the limitations of MCMC sampling for Bayesian neural networks. Furthermore, MCMC methods have typically been constrained to use by statisticians and are still not prominent among deep learning researchers. We present a tutorial for MCMC methods that covers simple Bayesian linear and logistic models, and Bayesian neural networks. The aim of this tutorial is to bridge the gap between theory and implementation via coding, given a general sparsity of li
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#20960;&#20046;&#32447;&#24615;&#26102;&#38388;&#20869;&#29992;&#40065;&#26834;&#20132;&#26367;&#26368;&#23567;&#21270;&#26041;&#27861;&#23436;&#25104;&#20302;&#31209;&#30697;&#38453;&#34917;&#20840;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#35266;&#23519;&#20960;&#20046;&#32447;&#24615;&#25968;&#37327;&#30340;&#26465;&#30446;&#21363;&#21487;&#24674;&#22797;&#30697;&#38453;$M$&#65292;&#27492;&#26041;&#27861;&#20811;&#26381;&#20102;&#20132;&#26367;&#26368;&#23567;&#21270;&#26041;&#27861;&#38656;&#35201;&#31934;&#30830;&#35745;&#31639;&#30340;&#38480;&#21046;&#65292;&#26356;&#31526;&#21512;&#23454;&#38469;&#23454;&#29616;&#20013;&#23545;&#25928;&#29575;&#30340;&#35201;&#27714;&#12290;</title><link>http://arxiv.org/abs/2302.11068</link><description>&lt;p&gt;
&#29992;&#40065;&#26834;&#20132;&#26367;&#26368;&#23567;&#21270;&#26041;&#27861;&#22312;&#20960;&#20046;&#32447;&#24615;&#26102;&#38388;&#20869;&#23436;&#25104;&#20302;&#31209;&#30697;&#38453;&#34917;&#20840;
&lt;/p&gt;
&lt;p&gt;
Low Rank Matrix Completion via Robust Alternating Minimization in Nearly Linear Time. (arXiv:2302.11068v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.11068
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#20960;&#20046;&#32447;&#24615;&#26102;&#38388;&#20869;&#29992;&#40065;&#26834;&#20132;&#26367;&#26368;&#23567;&#21270;&#26041;&#27861;&#23436;&#25104;&#20302;&#31209;&#30697;&#38453;&#34917;&#20840;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#35266;&#23519;&#20960;&#20046;&#32447;&#24615;&#25968;&#37327;&#30340;&#26465;&#30446;&#21363;&#21487;&#24674;&#22797;&#30697;&#38453;$M$&#65292;&#27492;&#26041;&#27861;&#20811;&#26381;&#20102;&#20132;&#26367;&#26368;&#23567;&#21270;&#26041;&#27861;&#38656;&#35201;&#31934;&#30830;&#35745;&#31639;&#30340;&#38480;&#21046;&#65292;&#26356;&#31526;&#21512;&#23454;&#38469;&#23454;&#29616;&#20013;&#23545;&#25928;&#29575;&#30340;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32473;&#23450;&#19968;&#20010;&#30697;&#38453;$M\in \mathbb{R}^{m\times n}$&#65292;&#20302;&#31209;&#30697;&#38453;&#34917;&#20840;&#38382;&#39064;&#35201;&#27714;&#25105;&#20204;&#36890;&#36807;&#21482;&#35266;&#23519;&#19968;&#32452;&#25351;&#23450;&#30340;&#26465;&#30446;$\Omega\subseteq [m]\times [n]$&#26469;&#25214;&#21040;$M$&#30340;&#31209;&#20026;$k$&#30340;&#36817;&#20284;$UV^\top$&#65292;&#20854;&#20013;$U\in \mathbb{R}^{m\times k}$&#65292;$V\in \mathbb{R}^{n\times k}$&#12290;&#26412;&#25991;&#20027;&#35201;&#30740;&#31350;&#20102;&#19968;&#31181;&#34987;&#24191;&#27867;&#20351;&#29992;&#30340;&#26041;&#27861;--&#20132;&#26367;&#26368;&#23567;&#21270;&#26694;&#26550;&#12290;Jain&#12289;Netrapalli&#21644;Sanghavi~\cite{jns13}&#35777;&#26126;&#20102;&#22914;&#26524;$M$&#30340;&#34892;&#21644;&#21015;&#26159;&#19981;&#30456;&#24178;&#30340;&#65292;&#37027;&#20040;&#20132;&#26367;&#26368;&#23567;&#21270;&#26041;&#27861;&#21487;&#20197;&#36890;&#36807;&#35266;&#23519;&#20960;&#20046;&#32447;&#24615;&#25968;&#37327;&#30340;&#26465;&#30446;&#21487;&#38752;&#22320;&#24674;&#22797;&#30697;&#38453;$M$&#12290;&#34429;&#28982;&#26679;&#26412;&#22797;&#26434;&#24230;&#20043;&#21518;&#34987;&#25913;&#36827;~\cite{glz17}&#65292;&#20294;&#20132;&#26367;&#26368;&#23567;&#21270;&#27493;&#39588;&#35201;&#27714;&#31934;&#30830;&#35745;&#31639;&#12290;&#36825;&#38459;&#30861;&#20102;&#26356;&#39640;&#25928;&#31639;&#27861;&#30340;&#24320;&#21457;&#65292;&#24182;&#26410;&#25551;&#36848;&#20132;&#26367;&#26368;&#23567;&#21270;&#30340;&#23454;&#38469;&#23454;&#29616;&#65292;&#20854;&#20013;&#26356;&#26032;&#36890;&#24120;&#26159;&#36817;&#20284;&#25191;&#34892;&#65292;&#20197;&#25552;&#39640;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Given a matrix $M\in \mathbb{R}^{m\times n}$, the low rank matrix completion problem asks us to find a rank-$k$ approximation of $M$ as $UV^\top$ for $U\in \mathbb{R}^{m\times k}$ and $V\in \mathbb{R}^{n\times k}$ by only observing a few entries specified by a set of entries $\Omega\subseteq [m]\times [n]$. In particular, we examine an approach that is widely used in practice -- the alternating minimization framework. Jain, Netrapalli and Sanghavi~\cite{jns13} showed that if $M$ has incoherent rows and columns, then alternating minimization provably recovers the matrix $M$ by observing a nearly linear in $n$ number of entries. While the sample complexity has been subsequently improved~\cite{glz17}, alternating minimization steps are required to be computed exactly. This hinders the development of more efficient algorithms and fails to depict the practical implementation of alternating minimization, where the updates are usually performed approximately in favor of efficiency.  In this p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#31867;&#20998;&#31867;&#22120;&#21644;&#24191;&#20041;&#20284;&#28982;&#27604;&#26816;&#39564;&#30340;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#22810;&#23618;&#24863;&#30693;&#22120;&#31070;&#32463;&#32593;&#32476;&#21644;&#25903;&#25345;&#21521;&#37327;&#26426;&#27169;&#22411;&#22312;&#25910;&#25947;&#26102;&#20250;&#34920;&#29616;&#20026;&#24191;&#20041;&#20284;&#28982;&#27604;&#26816;&#39564;&#12290;&#21516;&#26102;&#65292;&#20316;&#32773;&#36824;&#23637;&#31034;&#20102;&#19968;&#31867;&#26368;&#23567;&#20108;&#20056;SVM&#22312;&#25910;&#25947;&#26102;&#20063;&#33021;&#36798;&#21040;&#24191;&#20041;&#20284;&#28982;&#27604;&#26816;&#39564;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2210.12494</link><description>&lt;p&gt;
&#20851;&#20110;&#24191;&#20041;&#20284;&#28982;&#27604;&#26816;&#39564;&#21644;&#19968;&#31867;&#20998;&#31867;&#22120;
&lt;/p&gt;
&lt;p&gt;
On the Generalized Likelihood Ratio Test and One-Class Classifiers. (arXiv:2210.12494v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.12494
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#31867;&#20998;&#31867;&#22120;&#21644;&#24191;&#20041;&#20284;&#28982;&#27604;&#26816;&#39564;&#30340;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#22810;&#23618;&#24863;&#30693;&#22120;&#31070;&#32463;&#32593;&#32476;&#21644;&#25903;&#25345;&#21521;&#37327;&#26426;&#27169;&#22411;&#22312;&#25910;&#25947;&#26102;&#20250;&#34920;&#29616;&#20026;&#24191;&#20041;&#20284;&#28982;&#27604;&#26816;&#39564;&#12290;&#21516;&#26102;&#65292;&#20316;&#32773;&#36824;&#23637;&#31034;&#20102;&#19968;&#31867;&#26368;&#23567;&#20108;&#20056;SVM&#22312;&#25910;&#25947;&#26102;&#20063;&#33021;&#36798;&#21040;&#24191;&#20041;&#20284;&#28982;&#27604;&#26816;&#39564;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#31867;&#20998;&#31867;&#65288;OCC&#65289;&#26159;&#20915;&#23450;&#35266;&#23519;&#26679;&#26412;&#26159;&#21542;&#23646;&#20110;&#30446;&#26631;&#31867;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#32771;&#34385;&#22312;&#21253;&#21547;&#30446;&#26631;&#31867;&#26679;&#26412;&#30340;&#25968;&#25454;&#38598;&#19978;&#23398;&#20064;&#19968;&#20010;&#34920;&#29616;&#20026;&#24191;&#20041;&#20284;&#28982;&#27604;&#26816;&#39564;&#65288;GLRT&#65289;&#30340;OCC&#27169;&#22411;&#30340;&#38382;&#39064;&#12290;&#24403;&#30446;&#26631;&#31867;&#30340;&#32479;&#35745;&#20449;&#24687;&#21487;&#29992;&#26102;&#65292;GLRT&#35299;&#20915;&#20102;&#30456;&#21516;&#30340;&#38382;&#39064;&#12290;GLRT&#26159;&#19968;&#20010;&#20247;&#25152;&#21608;&#30693;&#19988;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#21487;&#35777;&#26126;&#26368;&#20339;&#30340;&#20998;&#31867;&#22120;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#22810;&#23618;&#24863;&#30693;&#22120;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#21644;&#25903;&#25345;&#21521;&#37327;&#26426;&#65288;SVM&#65289;&#27169;&#22411;&#12290;&#23427;&#20204;&#20351;&#29992;&#20154;&#24037;&#25968;&#25454;&#38598;&#35757;&#32451;&#20026;&#20004;&#31867;&#20998;&#31867;&#22120;&#65292;&#20854;&#20013;&#26367;&#20195;&#31867;&#20351;&#29992;&#22312;&#30446;&#26631;&#31867;&#25968;&#25454;&#38598;&#30340;&#23450;&#20041;&#22495;&#19978;&#22343;&#21248;&#29983;&#25104;&#30340;&#38543;&#26426;&#26679;&#26412;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#36866;&#24403;&#30340;&#20551;&#35774;&#19979;&#65292;&#27169;&#22411;&#22312;&#22823;&#25968;&#25454;&#38598;&#19978;&#25910;&#25947;&#21040;&#20102;GLRT&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#20855;&#26377;&#36866;&#24403;&#26680;&#20989;&#25968;&#30340;&#19968;&#31867;&#26368;&#23567;&#20108;&#20056;SVM&#65288;OCLSSVM&#65289;&#22312;&#25910;&#25947;&#26102;&#34920;&#29616;&#20026;GLRT&#12290;
&lt;/p&gt;
&lt;p&gt;
One-class classification (OCC) is the problem of deciding whether an observed sample belongs to a target class. We consider the problem of learning an OCC model that performs as the generalized likelihood ratio test (GLRT), given a dataset containing samples of the target class. The GLRT solves the same problem when the statistics of the target class are available. The GLRT is a well-known and provably optimal (under specific assumptions) classifier. To this end, we consider both the multilayer perceptron neural network (NN) and the support vector machine (SVM) models. They are trained as two-class classifiers using an artificial dataset for the alternative class, obtained by generating random samples, uniformly over the domain of the target-class dataset. We prove that, under suitable assumptions, the models converge (with a large dataset) to the GLRT. Moreover, we show that the one-class least squares SVM (OCLSSVM) with suitable kernels at convergence performs as the GLRT. Lastly, we
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;CP-PINNs&#27169;&#22411;&#65292;&#36890;&#36807;&#23558;PINNs&#19982;&#24635;&#21464;&#24046;&#24809;&#32602;&#30456;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#20934;&#30830;&#30340;&#21464;&#28857;&#26816;&#27979;&#21644;PDE&#30340;&#21457;&#29616;&#12290;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#20803;&#23398;&#20064;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#25968;&#25454;&#30340;&#36830;&#32493;&#25209;&#27425;&#19978;&#21160;&#24577;&#25913;&#36827;&#20248;&#21270;&#30446;&#26631;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#23384;&#22312;&#21464;&#28857;&#30340;&#24773;&#20917;&#19979;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#20934;&#30830;&#20272;&#35745;&#21442;&#25968;&#21644;&#27169;&#22411;&#23545;&#40784;&#65292;&#22312;&#27809;&#26377;&#21464;&#28857;&#30340;&#24773;&#20917;&#19979;&#33021;&#22815;&#25968;&#20540;&#19978;&#25910;&#25947;&#21040;&#21407;&#22987;PINNs&#27169;&#22411;&#30340;&#35299;&#12290;</title><link>http://arxiv.org/abs/2208.08626</link><description>&lt;p&gt;
CP-PINNs: &#20351;&#29992;&#29289;&#29702;&#30693;&#35782;&#31070;&#32463;&#32593;&#32476;&#21644;&#24635;&#21464;&#24046;&#24809;&#32602;&#36827;&#34892;PDE&#20013;&#30340;&#21464;&#28857;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
CP-PINNs: Changepoints Detection in PDEs using Physics Informed Neural Networks with Total-Variation Penalty. (arXiv:2208.08626v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.08626
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;CP-PINNs&#27169;&#22411;&#65292;&#36890;&#36807;&#23558;PINNs&#19982;&#24635;&#21464;&#24046;&#24809;&#32602;&#30456;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#20934;&#30830;&#30340;&#21464;&#28857;&#26816;&#27979;&#21644;PDE&#30340;&#21457;&#29616;&#12290;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#20803;&#23398;&#20064;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#25968;&#25454;&#30340;&#36830;&#32493;&#25209;&#27425;&#19978;&#21160;&#24577;&#25913;&#36827;&#20248;&#21270;&#30446;&#26631;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#23384;&#22312;&#21464;&#28857;&#30340;&#24773;&#20917;&#19979;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#20934;&#30830;&#20272;&#35745;&#21442;&#25968;&#21644;&#27169;&#22411;&#23545;&#40784;&#65292;&#22312;&#27809;&#26377;&#21464;&#28857;&#30340;&#24773;&#20917;&#19979;&#33021;&#22815;&#25968;&#20540;&#19978;&#25910;&#25947;&#21040;&#21407;&#22987;PINNs&#27169;&#22411;&#30340;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23637;&#31034;&#20102;&#22312;&#21442;&#25968;&#20013;&#23384;&#22312;&#26410;&#30693;&#21464;&#28857;&#30340;&#24773;&#20917;&#19979;&#65292;&#29289;&#29702;&#30693;&#35782;&#31070;&#32463;&#32593;&#32476;&#65288;PINNs&#65289;&#21487;&#33021;&#26080;&#27861;&#27491;&#30830;&#20272;&#35745;&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;PDE&#65289;&#30340;&#21160;&#24577;&#36807;&#31243;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;CP-PINNs&#27169;&#22411;&#65292;&#23558;PINNs&#19982;&#24635;&#21464;&#24046;&#24809;&#32602;&#30456;&#32467;&#21512;&#65292;&#29992;&#20110;&#20934;&#30830;&#30340;&#21464;&#28857;&#26816;&#27979;&#21644;PDE&#30340;&#21457;&#29616;&#12290;&#20026;&#20102;&#22312;&#27169;&#22411;&#25311;&#21512;&#12289;PDE&#21457;&#29616;&#21644;&#21464;&#28857;&#26816;&#27979;&#20219;&#21153;&#20043;&#38388;&#36827;&#34892;&#26368;&#20248;&#32452;&#21512;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#20803;&#23398;&#20064;&#31639;&#27861;&#65292;&#21033;&#29992;&#25209;&#37327;&#23398;&#20064;&#22312;&#25968;&#25454;&#30340;&#36830;&#32493;&#25209;&#27425;&#19978;&#21160;&#24577;&#25913;&#36827;&#20248;&#21270;&#30446;&#26631;&#12290;&#22312;&#23454;&#35777;&#26041;&#38754;&#65292;&#22312;&#21160;&#24577;&#36807;&#31243;&#20013;&#23384;&#22312;&#21464;&#28857;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#20934;&#30830;&#20272;&#35745;&#21442;&#25968;&#21644;&#27169;&#22411;&#23545;&#40784;&#65292;&#22312;&#25968;&#25454;&#20013;&#27809;&#26377;&#21464;&#28857;&#30340;&#24773;&#20917;&#19979;&#65292;&#25968;&#20540;&#19978;&#25910;&#25947;&#21040;&#21407;&#22987;PINNs&#27169;&#22411;&#30340;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
The paper shows that Physics-Informed Neural Networks (PINNs) can fail to estimate the correct Partial Differential Equations (PDEs) dynamics in cases of unknown changepoints in the parameters. To address this, we propose a new CP-PINNs model which integrates PINNs with Total-Variation penalty for accurate changepoints detection and PDEs discovery. In order to optimally combine the tasks of model fitting, PDEs discovery, and changepoints detection, we develop a new meta-learning algorithm that exploits batch learning to dynamically refines the optimization objective when moving over the consecutive batches of the data. Empirically, in case of changepoints in the dynamics, our approach demonstrates accurate parameter estimation and model alignment, and in case of no changepoints in the data, it converges numerically to the solution from the original PINNs model.
&lt;/p&gt;</description></item></channel></rss>