<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#36890;&#36807;&#27604;&#36739;&#25968;&#25454;&#21462;&#20195;&#21644;&#25968;&#25454;&#31215;&#32047;&#20004;&#31181;&#24773;&#20917;&#65292;&#21457;&#29616;&#32047;&#31215;&#25968;&#25454;&#21487;&#20197;&#38450;&#27490;&#27169;&#22411;&#23849;&#28291;&#12290;</title><link>https://arxiv.org/abs/2404.01413</link><description>&lt;p&gt;
&#27169;&#22411;&#23849;&#28291;&#26159;&#21542;&#19981;&#21487;&#36991;&#20813;&#65311;&#36890;&#36807;&#32047;&#31215;&#30495;&#23454;&#21644;&#21512;&#25104;&#25968;&#25454;&#25171;&#30772;&#36882;&#24402;&#30340;&#35781;&#21650;
&lt;/p&gt;
&lt;p&gt;
Is Model Collapse Inevitable? Breaking the Curse of Recursion by Accumulating Real and Synthetic Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01413
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#27604;&#36739;&#25968;&#25454;&#21462;&#20195;&#21644;&#25968;&#25454;&#31215;&#32047;&#20004;&#31181;&#24773;&#20917;&#65292;&#21457;&#29616;&#32047;&#31215;&#25968;&#25454;&#21487;&#20197;&#38450;&#27490;&#27169;&#22411;&#23849;&#28291;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#29983;&#25104;&#27169;&#22411;&#30340;&#28608;&#22686;&#65292;&#20197;&#21450;&#22312;&#32593;&#32476;&#35268;&#27169;&#25968;&#25454;&#19978;&#30340;&#39044;&#35757;&#32451;&#65292;&#19968;&#20010;&#21450;&#26102;&#30340;&#38382;&#39064;&#28014;&#20986;&#27700;&#38754;&#65306;&#24403;&#36825;&#20123;&#27169;&#22411;&#34987;&#35757;&#32451;&#22312;&#23427;&#20204;&#33258;&#24049;&#29983;&#25104;&#30340;&#36755;&#20986;&#19978;&#26102;&#20250;&#21457;&#29983;&#20160;&#20040;&#65311;&#26368;&#36817;&#23545;&#27169;&#22411;&#25968;&#25454;&#21453;&#39304;&#24490;&#29615;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#36825;&#26679;&#30340;&#24490;&#29615;&#21487;&#33021;&#23548;&#33268;&#27169;&#22411;&#23849;&#28291;&#65292;&#21363;&#24615;&#33021;&#38543;&#30528;&#27599;&#27425;&#27169;&#22411;&#25311;&#21512;&#36845;&#20195;&#36880;&#28176;&#19979;&#38477;&#65292;&#30452;&#21040;&#26368;&#26032;&#30340;&#27169;&#22411;&#21464;&#24471;&#26080;&#29992;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#20960;&#31687;&#30740;&#31350;&#27169;&#22411;&#23849;&#28291;&#30340;&#35770;&#25991;&#37117;&#20551;&#35774;&#38543;&#30528;&#26102;&#38388;&#25512;&#31227;&#65292;&#26032;&#25968;&#25454;&#20250;&#21462;&#20195;&#26087;&#25968;&#25454;&#65292;&#32780;&#19981;&#26159;&#20551;&#35774;&#25968;&#25454;&#20250;&#38543;&#26102;&#38388;&#32047;&#31215;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#27604;&#36739;&#20102;&#36825;&#20004;&#31181;&#24773;&#20917;&#65292;&#24182;&#34920;&#26126;&#31215;&#32047;&#25968;&#25454;&#21487;&#20197;&#38450;&#27490;&#27169;&#22411;&#23849;&#28291;&#12290;&#25105;&#20204;&#39318;&#20808;&#30740;&#31350;&#20102;&#19968;&#20010;&#35299;&#26512;&#21487;&#22788;&#29702;&#30340;&#35774;&#32622;&#65292;&#20854;&#20013;&#19968;&#31995;&#21015;&#32447;&#24615;&#27169;&#22411;&#25311;&#21512;&#21040;&#20808;&#21069;&#27169;&#22411;&#30340;&#39044;&#27979;&#12290;&#20808;&#21069;&#30340;&#24037;&#20316;&#34920;&#26126;&#65292;&#22914;&#26524;&#25968;&#25454;&#34987;&#26367;&#25442;&#65292;&#27979;&#35797;&#35823;&#24046;&#20250;&#38543;&#30528;&#27169;&#22411;&#25311;&#21512;&#36845;&#20195;&#27425;&#25968;&#32447;&#24615;&#22686;&#21152;&#65307;&#25105;&#20204;&#25193;&#23637;&#20102;&#36825;&#20010;&#30740;&#31350;&#25506;&#35752;&#20102;&#25968;&#25454;&#36880;&#28176;&#32047;&#31215;&#30340;&#24773;&#20917;&#19979;&#20250;&#21457;&#29983;&#20160;&#20040;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01413v1 Announce Type: cross  Abstract: The proliferation of generative models, combined with pretraining on web-scale data, raises a timely question: what happens when these models are trained on their own generated outputs? Recent investigations into model-data feedback loops discovered that such loops can lead to model collapse, a phenomenon where performance progressively degrades with each model-fitting iteration until the latest model becomes useless. However, several recent papers studying model collapse assumed that new data replace old data over time rather than assuming data accumulate over time. In this paper, we compare these two settings and show that accumulating data prevents model collapse. We begin by studying an analytically tractable setup in which a sequence of linear models are fit to the previous models' predictions. Previous work showed if data are replaced, the test error increases linearly with the number of model-fitting iterations; we extend this r
&lt;/p&gt;</description></item><item><title>&#21452;&#37325;/&#26080;&#20559;&#26426;&#22120;&#23398;&#20064;&#65288;DML&#65289;&#26041;&#27861;&#25913;&#36827;&#20102;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#20013;&#23545;&#38750;&#32447;&#24615;&#28151;&#28102;&#20851;&#31995;&#30340;&#35843;&#25972;&#65292;&#25670;&#33073;&#20256;&#32479;&#20989;&#25968;&#24418;&#24335;&#20551;&#35774;&#65292;&#20294;&#20173;&#28982;&#20381;&#36182;&#20110;&#26631;&#20934;&#22240;&#26524;&#20551;&#35774;&#12290;</title><link>https://arxiv.org/abs/2403.14385</link><description>&lt;p&gt;
&#29992;&#21452;&#26426;&#22120;&#23398;&#20064;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;--&#19968;&#31181;&#26041;&#27861;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Estimating Causal Effects with Double Machine Learning -- A Method Evaluation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14385
&lt;/p&gt;
&lt;p&gt;
&#21452;&#37325;/&#26080;&#20559;&#26426;&#22120;&#23398;&#20064;&#65288;DML&#65289;&#26041;&#27861;&#25913;&#36827;&#20102;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#20013;&#23545;&#38750;&#32447;&#24615;&#28151;&#28102;&#20851;&#31995;&#30340;&#35843;&#25972;&#65292;&#25670;&#33073;&#20256;&#32479;&#20989;&#25968;&#24418;&#24335;&#20551;&#35774;&#65292;&#20294;&#20173;&#28982;&#20381;&#36182;&#20110;&#26631;&#20934;&#22240;&#26524;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#35266;&#27979;&#25968;&#25454;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#20173;&#28982;&#26159;&#19968;&#20010;&#38750;&#24120;&#27963;&#36291;&#30340;&#30740;&#31350;&#39046;&#22495;&#12290;&#36817;&#24180;&#26469;&#65292;&#30740;&#31350;&#20154;&#21592;&#24320;&#21457;&#20102;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#25918;&#23485;&#20256;&#32479;&#20551;&#35774;&#20197;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#30340;&#26032;&#26694;&#26550;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#22238;&#39038;&#20102;&#20854;&#20013;&#19968;&#20010;&#26368;&#37325;&#35201;&#30340;&#26041;&#27861;-"&#21452;/&#26080;&#20559;&#26426;&#22120;&#23398;&#20064;"&#65288;DML&#65289;&#65292;&#24182;&#36890;&#36807;&#27604;&#36739;&#23427;&#22312;&#27169;&#25311;&#25968;&#25454;&#19978;&#30456;&#23545;&#20110;&#26356;&#20256;&#32479;&#30340;&#32479;&#35745;&#26041;&#27861;&#30340;&#34920;&#29616;&#65292;&#28982;&#21518;&#23558;&#20854;&#24212;&#29992;&#20110;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#36827;&#34892;&#20102;&#23454;&#35777;&#35780;&#20272;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21457;&#29616;&#34920;&#26126;&#65292;&#22312;DML&#20013;&#24212;&#29992;&#19968;&#20010;&#36866;&#24403;&#28789;&#27963;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#21487;&#20197;&#25913;&#36827;&#23545;&#21508;&#31181;&#38750;&#32447;&#24615;&#28151;&#28102;&#20851;&#31995;&#30340;&#35843;&#25972;&#12290;&#36825;&#31181;&#20248;&#21183;&#20351;&#24471;&#21487;&#20197;&#25670;&#33073;&#36890;&#24120;&#22312;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#20013;&#24517;&#38656;&#30340;&#20256;&#32479;&#20989;&#25968;&#24418;&#24335;&#20551;&#35774;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#34920;&#26126;&#35813;&#26041;&#27861;&#22312;&#20851;&#20110;&#22240;&#26524;&#20851;&#31995;&#30340;&#26631;&#20934;&#20551;&#35774;&#26041;&#38754;&#20173;&#28982;&#33267;&#20851;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14385v1 Announce Type: cross  Abstract: The estimation of causal effects with observational data continues to be a very active research area. In recent years, researchers have developed new frameworks which use machine learning to relax classical assumptions necessary for the estimation of causal effects. In this paper, we review one of the most prominent methods - "double/debiased machine learning" (DML) - and empirically evaluate it by comparing its performance on simulated data relative to more traditional statistical methods, before applying it to real-world data. Our findings indicate that the application of a suitably flexible machine learning algorithm within DML improves the adjustment for various nonlinear confounding relationships. This advantage enables a departure from traditional functional form assumptions typically necessary in causal effect estimation. However, we demonstrate that the method continues to critically depend on standard assumptions about causal 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22810;&#39033;&#24335;&#21442;&#25968;&#21270;sigmoid&#20989;&#25968;(SIGTRON)&#65292;&#24182;&#19988;&#20171;&#32461;&#20102;&#20854;&#20276;&#38543;&#30340;SIC&#27169;&#22411;&#12290;&#30456;&#27604;&#20256;&#32479;&#30340;&#25104;&#26412;&#25935;&#24863;&#23398;&#20064;&#27169;&#22411;&#65292;&#22312;&#32473;&#23450;&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#25509;&#36817;&#33391;&#22909;&#24179;&#34913;&#30340;&#26465;&#20214;&#19979;&#65292;&#25152;&#25552;&#20986;&#30340;SIC&#27169;&#22411;&#23545;&#20110;&#25968;&#25454;&#38598;&#30340;&#21464;&#21270;&#26356;&#21152;&#36866;&#24212;&#65292;&#24182;&#36890;&#36807;&#21019;&#24314;&#20542;&#26012;&#30340;&#36229;&#24179;&#38754;&#26041;&#31243;&#26469;&#23454;&#29616;&#12290;</title><link>https://arxiv.org/abs/2312.16043</link><description>&lt;p&gt;
&#19968;&#31181;&#38024;&#23545;&#19981;&#24179;&#34913;&#32447;&#24615;&#20998;&#31867;&#30340;&#25193;&#23637;&#38750;&#23545;&#31216;sigmoid&#21644;&#24863;&#30693;&#26426;(SIGTRON)
&lt;/p&gt;
&lt;p&gt;
An extended asymmetric sigmoid with Perceptron (SIGTRON) for imbalanced linear classification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.16043
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22810;&#39033;&#24335;&#21442;&#25968;&#21270;sigmoid&#20989;&#25968;(SIGTRON)&#65292;&#24182;&#19988;&#20171;&#32461;&#20102;&#20854;&#20276;&#38543;&#30340;SIC&#27169;&#22411;&#12290;&#30456;&#27604;&#20256;&#32479;&#30340;&#25104;&#26412;&#25935;&#24863;&#23398;&#20064;&#27169;&#22411;&#65292;&#22312;&#32473;&#23450;&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#25509;&#36817;&#33391;&#22909;&#24179;&#34913;&#30340;&#26465;&#20214;&#19979;&#65292;&#25152;&#25552;&#20986;&#30340;SIC&#27169;&#22411;&#23545;&#20110;&#25968;&#25454;&#38598;&#30340;&#21464;&#21270;&#26356;&#21152;&#36866;&#24212;&#65292;&#24182;&#36890;&#36807;&#21019;&#24314;&#20542;&#26012;&#30340;&#36229;&#24179;&#38754;&#26041;&#31243;&#26469;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22810;&#39033;&#24335;&#21442;&#25968;&#21270;sigmoid&#20989;&#25968;&#65292;&#31216;&#20026;SIGTRON&#65292;&#23427;&#26159;&#19968;&#31181;&#25193;&#23637;&#30340;&#38750;&#23545;&#31216;sigmoid&#20989;&#25968;&#21644;&#24863;&#30693;&#26426;&#30340;&#32467;&#21512;&#65292;&#20197;&#21450;&#23427;&#30340;&#20276;&#38543;&#20984;&#27169;&#22411;SIGTRON-&#19981;&#24179;&#34913;&#20998;&#31867;(SIC)&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#20351;&#29992;&#20102;&#34394;&#25311;SIGTRON&#20135;&#29983;&#30340;&#20984;&#25439;&#22833;&#20989;&#25968;&#12290;&#19982;&#20256;&#32479;&#30340;$\pi$-&#21152;&#26435;&#25104;&#26412;&#25935;&#24863;&#23398;&#20064;&#27169;&#22411;&#30456;&#27604;&#65292;SIC&#27169;&#22411;&#22312;&#25439;&#22833;&#20989;&#25968;&#19978;&#27809;&#26377;&#22806;&#37096;&#30340;$\pi$-&#26435;&#37325;&#65292;&#32780;&#26159;&#22312;&#34394;&#25311;&#30340;SIGTRON&#20135;&#29983;&#30340;&#25439;&#22833;&#20989;&#25968;&#20013;&#26377;&#20869;&#37096;&#21442;&#25968;&#12290;&#22240;&#27492;&#65292;&#24403;&#32473;&#23450;&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#25509;&#36817;&#33391;&#22909;&#24179;&#34913;&#30340;&#26465;&#20214;&#26102;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;SIC&#27169;&#22411;&#23545;&#25968;&#25454;&#38598;&#30340;&#21464;&#21270;&#26356;&#21152;&#36866;&#24212;&#65292;&#27604;&#22914;&#35757;&#32451;&#38598;&#21644;&#27979;&#35797;&#38598;&#20043;&#38388;&#27604;&#20363;&#19981;&#24179;&#34913;&#30340;&#19981;&#19968;&#33268;&#24615;&#12290;&#36825;&#31181;&#36866;&#24212;&#26159;&#36890;&#36807;&#21019;&#24314;&#19968;&#20010;&#20542;&#26012;&#30340;&#36229;&#24179;&#38754;&#26041;&#31243;&#26469;&#23454;&#29616;&#30340;&#12290;&#21478;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#25311;&#29275;&#39039;&#20248;&#21270;(L-BFGS)&#26694;&#26550;&#30340;&#34394;&#25311;&#20984;&#25439;&#22833;&#65292;&#36890;&#36807;&#24320;&#21457;&#19968;&#20010;&#22522;&#20110;&#21306;&#38388;&#30340;&#20108;&#20998;&#32447;&#24615;&#25628;&#32034;&#31639;&#27861;&#26469;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article presents a new polynomial parameterized sigmoid called SIGTRON, which is an extended asymmetric sigmoid with Perceptron, and its companion convex model called SIGTRON-imbalanced classification (SIC) model that employs a virtual SIGTRON-induced convex loss function. In contrast to the conventional $\pi$-weighted cost-sensitive learning model, the SIC model does not have an external $\pi$-weight on the loss function but has internal parameters in the virtual SIGTRON-induced loss function. As a consequence, when the given training dataset is close to the well-balanced condition, we show that the proposed SIC model is more adaptive to variations of the dataset, such as the inconsistency of the scale-class-imbalance ratio between the training and test datasets. This adaptation is achieved by creating a skewed hyperplane equation. Additionally, we present a quasi-Newton optimization(L-BFGS) framework for the virtual convex loss by developing an interval-based bisection line sear
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#26631;&#20934;&#21270;&#21644;Mondrian&#31526;&#21512;&#35268;&#33539;&#30340;&#26041;&#27861;&#22914;&#20309;&#26500;&#24314;&#33258;&#36866;&#24212;&#30340;&#39044;&#27979;&#21306;&#38388;&#65292;&#20197;&#35299;&#20915;&#22238;&#24402;&#38382;&#39064;&#20013;&#30340;&#24322;&#26041;&#24046;&#22122;&#22768;&#12290;</title><link>http://arxiv.org/abs/2309.08313</link><description>&lt;p&gt;
&#24322;&#26041;&#24046;&#25311;&#21512;&#32622;&#20449;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Heteroskedastic conformal regression. (arXiv:2309.08313v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08313
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#26631;&#20934;&#21270;&#21644;Mondrian&#31526;&#21512;&#35268;&#33539;&#30340;&#26041;&#27861;&#22914;&#20309;&#26500;&#24314;&#33258;&#36866;&#24212;&#30340;&#39044;&#27979;&#21306;&#38388;&#65292;&#20197;&#35299;&#20915;&#22238;&#24402;&#38382;&#39064;&#20013;&#30340;&#24322;&#26041;&#24046;&#22122;&#22768;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31526;&#21512;&#35268;&#33539;&#30340;&#39044;&#27979;&#20197;&#21450;&#29305;&#23450;&#30340;&#25286;&#20998;&#31526;&#21512;&#35268;&#33539;&#30340;&#39044;&#27979;&#25552;&#20379;&#20102;&#19968;&#31181;&#26080;&#20998;&#24067;&#30340;&#26041;&#27861;&#26469;&#20272;&#35745;&#20855;&#26377;&#32479;&#35745;&#20445;&#35777;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#24403;&#19987;&#27880;&#20110;&#36793;&#38469;&#35206;&#30422;&#26102;&#65292;&#21363;&#22312;&#26657;&#20934;&#25968;&#25454;&#38598;&#19978;&#65292;&#35813;&#26041;&#27861;&#20135;&#29983;&#30340;&#39044;&#27979;&#21306;&#38388;&#24179;&#22343;&#21253;&#21547;&#39044;&#23450;&#20041;&#35206;&#30422;&#27700;&#24179;&#30340;&#30495;&#23454;&#20540;&#65292;&#25286;&#20998;&#31526;&#21512;&#35268;&#33539;&#30340;&#39044;&#27979;&#21487;&#20197;&#20135;&#29983;&#26368;&#20808;&#36827;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;&#28982;&#32780;&#65292;&#36825;&#26679;&#30340;&#21306;&#38388;&#36890;&#24120;&#19981;&#26159;&#33258;&#36866;&#24212;&#30340;&#65292;&#36825;&#23545;&#20110;&#20855;&#26377;&#24322;&#26041;&#24046;&#22122;&#22768;&#30340;&#22238;&#24402;&#38382;&#39064;&#21487;&#33021;&#26159;&#26377;&#38382;&#39064;&#30340;&#12290;&#26412;&#25991;&#35797;&#22270;&#38416;&#26126;&#22914;&#20309;&#20351;&#29992;&#26631;&#20934;&#21270;&#21644;Mondrian&#31526;&#21512;&#35268;&#33539;&#30340;&#26041;&#27861;&#26469;&#26500;&#24314;&#33258;&#36866;&#24212;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;&#25105;&#20204;&#20197;&#31995;&#32479;&#30340;&#26041;&#24335;&#25552;&#20986;&#29702;&#35770;&#21644;&#23454;&#39564;&#32467;&#26524;&#26469;&#30740;&#31350;&#36825;&#20123;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conformal prediction, and split conformal prediction as a specific implementation, offer a distribution-free approach to estimating prediction intervals with statistical guarantees. Recent work has shown that split conformal prediction can produce state-of-the-art prediction intervals when focusing on marginal coverage, i.e., on a calibration dataset the method produces on average prediction intervals that contain the ground truth with a predefined coverage level. However, such intervals are often not adaptive, which can be problematic for regression problems with heteroskedastic noise. This paper tries to shed new light on how adaptive prediction intervals can be constructed using methods such as normalized and Mondrian conformal prediction. We present theoretical and experimental results in which these methods are investigated in a systematic way.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;"Cluster-DP"&#65292;&#23427;&#22312;&#20445;&#35777;&#38544;&#31169;&#30340;&#21516;&#26102;&#21033;&#29992;&#25968;&#25454;&#30340;&#32858;&#31867;&#32467;&#26500;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#26356;&#24378;&#30340;&#38544;&#31169;&#20445;&#35777;&#21644;&#36739;&#20302;&#30340;&#26041;&#24046;&#65292;&#21487;&#20197;&#29992;&#20110;&#36827;&#34892;&#22240;&#26524;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2308.00957</link><description>&lt;p&gt;
&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;(&#20998;&#32452;)&#32467;&#26524;&#30340;&#22240;&#26524;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Causal Inference with Differentially Private (Clustered) Outcomes. (arXiv:2308.00957v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.00957
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;"Cluster-DP"&#65292;&#23427;&#22312;&#20445;&#35777;&#38544;&#31169;&#30340;&#21516;&#26102;&#21033;&#29992;&#25968;&#25454;&#30340;&#32858;&#31867;&#32467;&#26500;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#26356;&#24378;&#30340;&#38544;&#31169;&#20445;&#35777;&#21644;&#36739;&#20302;&#30340;&#26041;&#24046;&#65292;&#21487;&#20197;&#29992;&#20110;&#36827;&#34892;&#22240;&#26524;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#38543;&#26426;&#23454;&#39564;&#20013;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#21482;&#26377;&#22312;&#21442;&#19982;&#32773;&#21516;&#24847;&#36879;&#38706;&#20182;&#20204;&#21487;&#33021;&#25935;&#24863;&#30340;&#21709;&#24212;&#26102;&#25165;&#21487;&#34892;&#12290;&#22312;&#30830;&#20445;&#38544;&#31169;&#30340;&#35768;&#22810;&#26041;&#27861;&#20013;&#65292;&#26631;&#31614;&#24046;&#20998;&#38544;&#31169;&#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#31639;&#27861;&#38544;&#31169;&#20445;&#35777;&#24230;&#37327;&#65292;&#21487;&#20197;&#40723;&#21169;&#21442;&#19982;&#32773;&#20998;&#20139;&#21709;&#24212;&#32780;&#19981;&#20250;&#38754;&#20020;&#21435;&#21311;&#21517;&#21270;&#30340;&#39118;&#38505;&#12290;&#35768;&#22810;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;&#20250;&#21521;&#21407;&#22987;&#25968;&#25454;&#38598;&#20013;&#27880;&#20837;&#22122;&#38899;&#26469;&#23454;&#29616;&#36825;&#31181;&#38544;&#31169;&#20445;&#35777;&#65292;&#36825;&#20250;&#22686;&#21152;&#22823;&#22810;&#25968;&#32479;&#35745;&#20272;&#35745;&#37327;&#30340;&#26041;&#24046;&#65292;&#20351;&#24471;&#31934;&#30830;&#27979;&#37327;&#22240;&#26524;&#25928;&#24212;&#21464;&#24471;&#22256;&#38590;&#65306;&#20174;&#24046;&#20998;&#38544;&#31169;&#25968;&#25454;&#36827;&#34892;&#22240;&#26524;&#20998;&#26512;&#23384;&#22312;&#30528;&#22266;&#26377;&#30340;&#38544;&#31169;-&#26041;&#24046;&#26435;&#34913;&#12290;&#20026;&#20102;&#23454;&#29616;&#26356;&#24378;&#38544;&#31169;&#20445;&#35777;&#30340;&#36739;&#20302;&#26041;&#24046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;"Cluster-DP"&#65292;&#23427;&#21033;&#29992;&#25968;&#25454;&#30340;&#20219;&#20309;&#32473;&#23450;&#30340;&#32858;&#31867;&#32467;&#26500;&#65292;&#21516;&#26102;&#20173;&#28982;&#20801;&#35768;&#23545;&#22240;&#26524;&#25928;&#24212;&#36827;&#34892;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating causal effects from randomized experiments is only feasible if participants agree to reveal their potentially sensitive responses. Of the many ways of ensuring privacy, label differential privacy is a widely used measure of an algorithm's privacy guarantee, which might encourage participants to share responses without running the risk of de-anonymization. Many differentially private mechanisms inject noise into the original data-set to achieve this privacy guarantee, which increases the variance of most statistical estimators and makes the precise measurement of causal effects difficult: there exists a fundamental privacy-variance trade-off to performing causal analyses from differentially private data. With the aim of achieving lower variance for stronger privacy guarantees, we suggest a new differential privacy mechanism, "Cluster-DP", which leverages any given cluster structure of the data while still allowing for the estimation of causal effects. We show that, depending 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#20195;&#25968;&#25299;&#25169;&#20013;&#30340;&#34920;&#31034;&#31283;&#23450;&#24615;&#65292;&#21487;&#20197;&#23450;&#20041;&#20986;&#19968;&#20010;&#21487;&#20197;&#20197;&#20219;&#24847;&#32500;&#24230;&#20026;&#36755;&#20837;&#30340;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#12290;&#36825;&#31181;&#26041;&#27861;&#20351;&#29992;&#26041;&#20415;&#65292;&#21482;&#38656;&#25351;&#23450;&#32593;&#32476;&#26550;&#26500;&#21644;&#31561;&#21464;&#24615;&#30340;&#32452;&#65292;&#19988;&#22312;&#20219;&#20309;&#35757;&#32451;&#36807;&#31243;&#20013;&#37117;&#21487;&#20197;&#20351;&#29992;&#12290;</title><link>http://arxiv.org/abs/2306.06327</link><description>&lt;p&gt;
&#20219;&#24847;&#32500;&#24230;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Any-dimensional equivariant neural networks. (arXiv:2306.06327v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06327
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#20195;&#25968;&#25299;&#25169;&#20013;&#30340;&#34920;&#31034;&#31283;&#23450;&#24615;&#65292;&#21487;&#20197;&#23450;&#20041;&#20986;&#19968;&#20010;&#21487;&#20197;&#20197;&#20219;&#24847;&#32500;&#24230;&#20026;&#36755;&#20837;&#30340;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#12290;&#36825;&#31181;&#26041;&#27861;&#20351;&#29992;&#26041;&#20415;&#65292;&#21482;&#38656;&#25351;&#23450;&#32593;&#32476;&#26550;&#26500;&#21644;&#31561;&#21464;&#24615;&#30340;&#32452;&#65292;&#19988;&#22312;&#20219;&#20309;&#35757;&#32451;&#36807;&#31243;&#20013;&#37117;&#21487;&#20197;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#30417;&#30563;&#23398;&#20064;&#26088;&#22312;&#36890;&#36807;&#23558;&#20989;&#25968;&#25311;&#21512;&#21040;&#19968;&#32452;&#20855;&#26377;&#22266;&#23450;&#32500;&#24230;&#30340;&#36755;&#20837;/&#36755;&#20986;&#23545;&#26469;&#23398;&#20064;&#26410;&#30693;&#26144;&#23556;&#12290;&#28982;&#21518;&#65292;&#22312;&#30456;&#21516;&#32500;&#24230;&#30340;&#36755;&#20837;&#19978;&#23450;&#20041;&#25311;&#21512;&#20989;&#25968;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#26410;&#30693;&#26144;&#23556;&#20197;&#20219;&#24847;&#32500;&#24230;&#30340;&#36755;&#20837;&#20316;&#20026;&#36755;&#20837;&#65307;&#20363;&#22914;&#65292;&#23450;&#20041;&#22312;&#20219;&#24847;&#22823;&#23567;&#30340;&#22270;&#24418;&#19978;&#30340;&#22270;&#24418;&#21442;&#25968;&#21644;&#23450;&#20041;&#22312;&#20219;&#24847;&#25968;&#37327;&#31890;&#23376;&#19978;&#30340;&#29289;&#29702;&#37327;&#12290;&#25105;&#20204;&#21033;&#29992;&#20195;&#25968;&#25299;&#25169;&#20013;&#30340;&#26032;&#29616;&#35937;&#8212;&#8212;&#34920;&#31034;&#31283;&#23450;&#24615;&#65292;&#26469;&#23450;&#20041;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#65292;&#21487;&#20197;&#20351;&#29992;&#22266;&#23450;&#32500;&#24230;&#30340;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#65292;&#28982;&#21518;&#22312;&#20219;&#24847;&#32500;&#24230;&#19978;&#25193;&#23637;&#25509;&#21463;&#36755;&#20837;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26131;&#20110;&#20351;&#29992;&#65292;&#21482;&#38656;&#35201;&#32593;&#32476;&#26550;&#26500;&#21644;&#31561;&#21464;&#24615;&#30340;&#32452;&#65292;&#24182;&#19988;&#21487;&#20197;&#19982;&#20219;&#20309;&#35757;&#32451;&#36807;&#31243;&#32467;&#21512;&#20351;&#29992;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#31616;&#21333;&#24320;&#28304;&#23454;&#29616;&#65292;&#24182;&#25552;&#20379;&#20102;&#21021;&#27493;&#30340;&#25968;&#20540;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Traditional supervised learning aims to learn an unknown mapping by fitting a function to a set of input-output pairs with a fixed dimension. The fitted function is then defined on inputs of the same dimension. However, in many settings, the unknown mapping takes inputs in any dimension; examples include graph parameters defined on graphs of any size and physics quantities defined on an arbitrary number of particles. We leverage a newly-discovered phenomenon in algebraic topology, called representation stability, to define equivariant neural networks that can be trained with data in a fixed dimension and then extended to accept inputs in any dimension. Our approach is user-friendly, requiring only the network architecture and the groups for equivariance, and can be combined with any training procedure. We provide a simple open-source implementation of our methods and offer preliminary numerical experiments.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37327;&#23376;&#26680;&#28151;&#21512;&#26041;&#27861;&#65292;&#21487;&#20197;&#29992;&#20110;&#34920;&#31034;&#36830;&#32493;&#21644;&#31163;&#25955;&#38543;&#26426;&#21464;&#37327;&#30340;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#12290;&#35813;&#26694;&#26550;&#20801;&#35768;&#26500;&#24314;&#21487;&#24494;&#20998;&#30340;&#27169;&#22411;&#65292;&#36866;&#29992;&#20110;&#23494;&#24230;&#20272;&#35745;&#12289;&#25512;&#29702;&#21644;&#37319;&#26679;&#65292;&#20197;&#21450;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#65292;&#21253;&#25324;&#29983;&#25104;&#24314;&#27169;&#21644;&#21028;&#21035;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2305.18204</link><description>&lt;p&gt;
&#27010;&#29575;&#28145;&#24230;&#23398;&#20064;&#30340;&#37327;&#23376;&#26680;&#28151;&#21512;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Quantum Kernel Mixtures for Probabilistic Deep Learning. (arXiv:2305.18204v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18204
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37327;&#23376;&#26680;&#28151;&#21512;&#26041;&#27861;&#65292;&#21487;&#20197;&#29992;&#20110;&#34920;&#31034;&#36830;&#32493;&#21644;&#31163;&#25955;&#38543;&#26426;&#21464;&#37327;&#30340;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#12290;&#35813;&#26694;&#26550;&#20801;&#35768;&#26500;&#24314;&#21487;&#24494;&#20998;&#30340;&#27169;&#22411;&#65292;&#36866;&#29992;&#20110;&#23494;&#24230;&#20272;&#35745;&#12289;&#25512;&#29702;&#21644;&#37319;&#26679;&#65292;&#20197;&#21450;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#65292;&#21253;&#25324;&#29983;&#25104;&#24314;&#27169;&#21644;&#21028;&#21035;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27010;&#29575;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#8212;&#8212;&#37327;&#23376;&#26680;&#28151;&#21512;&#65292;&#23427;&#26159;&#20174;&#37327;&#23376;&#23494;&#24230;&#30697;&#38453;&#30340;&#25968;&#23398;&#24418;&#24335;&#20013;&#25512;&#23548;&#20986;&#26469;&#30340;&#12290;&#35813;&#26041;&#27861;&#25552;&#20379;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26426;&#21046;&#65292;&#29992;&#20110;&#34920;&#31034;&#36830;&#32493;&#21644;&#31163;&#25955;&#38543;&#26426;&#21464;&#37327;&#30340;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#12290;&#35813;&#26694;&#26550;&#20801;&#35768;&#26500;&#24314;&#21487;&#24494;&#20998;&#30340;&#27169;&#22411;&#65292;&#29992;&#20110;&#23494;&#24230;&#20272;&#35745;&#12289;&#25512;&#29702;&#21644;&#37319;&#26679;&#65292;&#20174;&#32780;&#33021;&#22815;&#25972;&#21512;&#21040;&#31471;&#21040;&#31471;&#30340;&#28145;&#24230;&#31070;&#32463;&#27169;&#22411;&#20013;&#12290;&#36890;&#36807;&#36825;&#26679;&#20570;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#22810;&#21151;&#33021;&#30340;&#36793;&#38469;&#21644;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#34920;&#31034;&#65292;&#21487;&#20197;&#24320;&#21457;&#19968;&#31181;&#21487;&#24494;&#20998;&#30340;&#12289;&#32452;&#21512;&#30340;&#21644;&#21487;&#36870;&#30340;&#25512;&#29702;&#36807;&#31243;&#65292;&#28085;&#30422;&#20102;&#24191;&#27867;&#30340;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#65292;&#21253;&#25324;&#23494;&#24230;&#20272;&#35745;&#12289;&#21028;&#21035;&#23398;&#20064;&#21644;&#29983;&#25104;&#24314;&#27169;&#12290;&#25105;&#20204;&#36890;&#36807;&#20004;&#20010;&#31034;&#20363;&#26469;&#35828;&#26126;&#35813;&#26694;&#26550;&#30340;&#24191;&#27867;&#36866;&#29992;&#24615;&#65306;&#19968;&#20010;&#22270;&#20687;&#20998;&#31867;&#27169;&#22411;&#65292;&#23427;&#21487;&#20197;&#33258;&#28982;&#22320;&#36716;&#21270;&#20026;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#65292;&#24471;&#30410;&#20110;&#37327;&#23376;&#26680;&#28151;&#21512;&#30340;&#34920;&#31034;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a novel approach to probabilistic deep learning (PDL), quantum kernel mixtures, derived from the mathematical formalism of quantum density matrices, which provides a simpler yet effective mechanism for representing joint probability distributions of both continuous and discrete random variables. The framework allows for the construction of differentiable models for density estimation, inference, and sampling, enabling integration into end-to-end deep neural models. In doing so, we provide a versatile representation of marginal and joint probability distributions that allows us to develop a differentiable, compositional, and reversible inference procedure that covers a wide range of machine learning tasks, including density estimation, discriminative learning, and generative modeling. We illustrate the broad applicability of the framework with two examples: an image classification model, which can be naturally transformed into a conditional generative model thanks to
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20613;&#37324;&#21494;&#20998;&#26512;&#25216;&#26415;&#65292;&#29992;&#20110;&#20174;$\mathscr{L}_2(\mathbb{R})$&#30340;&#27491;&#20132;&#22522;&#20013;&#26500;&#24314;&#24179;&#31227;&#19981;&#21464;&#26680;&#20989;&#25968;&#30340;&#27491;&#20132;&#22522;&#23637;&#24320;&#65292;&#23454;&#29616;&#20102;&#39532;&#29305;&#23572;&#26680;&#20989;&#25968;&#12289;&#26607;&#35199;&#26680;&#20989;&#25968;&#21644;&#39640;&#26031;&#26680;&#20989;&#25968;&#30340;&#26126;&#30830;&#23637;&#24320;&#34920;&#36798;&#24335;&#12290;</title><link>http://arxiv.org/abs/2206.08648</link><description>&lt;p&gt;
&#24179;&#31227;&#19981;&#21464;&#26680;&#20989;&#25968;&#30340;&#27491;&#20132;&#23637;&#24320;
&lt;/p&gt;
&lt;p&gt;
Orthonormal Expansions for Translation-Invariant Kernels. (arXiv:2206.08648v3 [math.CA] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.08648
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20613;&#37324;&#21494;&#20998;&#26512;&#25216;&#26415;&#65292;&#29992;&#20110;&#20174;$\mathscr{L}_2(\mathbb{R})$&#30340;&#27491;&#20132;&#22522;&#20013;&#26500;&#24314;&#24179;&#31227;&#19981;&#21464;&#26680;&#20989;&#25968;&#30340;&#27491;&#20132;&#22522;&#23637;&#24320;&#65292;&#23454;&#29616;&#20102;&#39532;&#29305;&#23572;&#26680;&#20989;&#25968;&#12289;&#26607;&#35199;&#26680;&#20989;&#25968;&#21644;&#39640;&#26031;&#26680;&#20989;&#25968;&#30340;&#26126;&#30830;&#23637;&#24320;&#34920;&#36798;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#26500;&#24314;&#24179;&#31227;&#19981;&#21464;&#26680;&#20989;&#25968;&#30340;&#27491;&#20132;&#22522;&#23637;&#24320;&#30340;&#20613;&#37324;&#21494;&#20998;&#26512;&#25216;&#26415;&#65292;&#35813;&#25216;&#26415;&#21033;&#29992;$\mathscr{L}_2(\mathbb{R})$&#19978;&#30340;&#27491;&#20132;&#22522;&#65292;&#24471;&#21040;&#20102;&#23454;&#36724;&#19978;&#25152;&#26377;&#21322;&#25972;&#25968;&#38454;&#39532;&#29305;&#23572;&#26680;&#20989;&#25968;&#12289;&#26607;&#35199;&#26680;&#20989;&#25968;&#20197;&#21450;&#39640;&#26031;&#26680;&#20989;&#25968;&#30340;&#26126;&#30830;&#23637;&#24320;&#34920;&#36798;&#24335;&#65292;&#20998;&#21035;&#30001;&#30456;&#20851;&#30340;&#25289;&#30422;&#23572;&#20989;&#25968;&#12289;&#26377;&#29702;&#20989;&#25968;&#21644;&#21380;&#31859;&#20989;&#25968;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a general Fourier analytic technique for constructing orthonormal basis expansions of translation-invariant kernels from orthonormal bases of $\mathscr{L}_2(\mathbb{R})$. This allows us to derive explicit expansions on the real line for (i) Mat\'ern kernels of all half-integer orders in terms of associated Laguerre functions, (ii) the Cauchy kernel in terms of rational functions, and (iii) the Gaussian kernel in terms of Hermite functions.
&lt;/p&gt;</description></item></channel></rss>