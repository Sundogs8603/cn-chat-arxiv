<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#35780;&#20272;&#20102;&#22312;ImageNet&#19978;&#30340;&#22810;&#31181;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#22120;&#65292;&#21457;&#29616;&#34429;&#28982;&#26377;&#29702;&#35770;&#21162;&#21147;&#65292;&#20294;&#23454;&#36341;&#20013;&#23578;&#26410;&#23454;&#29616;&#19981;&#30830;&#23450;&#24615;&#30340;&#35299;&#24320;&#65292;&#21516;&#26102;&#25581;&#31034;&#20102;&#21738;&#20123;&#20272;&#35745;&#22120;&#22312;&#29305;&#23450;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#33394;&#65292;&#20026;&#20174;&#19994;&#32773;&#25552;&#20379;&#35265;&#35299;&#24182;&#25351;&#23548;&#26410;&#26469;&#30740;&#31350;&#12290;</title><link>https://arxiv.org/abs/2402.19460</link><description>&lt;p&gt;
&#20026;&#26631;&#20934;&#21270;&#30340;&#20219;&#21153;&#19987;&#38376;&#25351;&#23450;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65306;&#19987;&#38376;&#30340;&#19981;&#30830;&#23450;&#24615;&#29992;&#20110;&#19987;&#38376;&#30340;&#20219;&#21153;
&lt;/p&gt;
&lt;p&gt;
Benchmarking Uncertainty Disentanglement: Specialized Uncertainties for Specialized Tasks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.19460
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#35780;&#20272;&#20102;&#22312;ImageNet&#19978;&#30340;&#22810;&#31181;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#22120;&#65292;&#21457;&#29616;&#34429;&#28982;&#26377;&#29702;&#35770;&#21162;&#21147;&#65292;&#20294;&#23454;&#36341;&#20013;&#23578;&#26410;&#23454;&#29616;&#19981;&#30830;&#23450;&#24615;&#30340;&#35299;&#24320;&#65292;&#21516;&#26102;&#25581;&#31034;&#20102;&#21738;&#20123;&#20272;&#35745;&#22120;&#22312;&#29305;&#23450;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#33394;&#65292;&#20026;&#20174;&#19994;&#32773;&#25552;&#20379;&#35265;&#35299;&#24182;&#25351;&#23548;&#26410;&#26469;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#26366;&#32463;&#26159;&#19968;&#20010;&#29420;&#31435;&#30340;&#20219;&#21153;&#65292;&#24050;&#32463;&#21457;&#23637;&#25104;&#20026;&#19968;&#20010;&#21253;&#21547;&#39044;&#27979;&#25233;&#21046;&#12289;&#36234;&#30028;&#26816;&#27979;&#20197;&#21450;&#38543;&#26426;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#22312;&#20869;&#30340;&#20219;&#21153;&#35889;&#31995;&#12290;&#26368;&#26032;&#30340;&#30446;&#26631;&#26159;&#35299;&#24320;&#19981;&#30830;&#23450;&#24615;&#65306;&#26500;&#24314;&#22810;&#20010;&#20272;&#35745;&#22120;&#65292;&#27599;&#20010;&#37117;&#19987;&#38376;&#23450;&#21046;&#20110;&#19968;&#20010;&#29305;&#23450;&#20219;&#21153;&#12290;&#22240;&#27492;&#65292;&#26368;&#36817;&#26377;&#22823;&#37327;&#19981;&#21516;&#24847;&#22270;&#30340;&#26368;&#26032;&#36827;&#23637;&#8212;&#8212;&#36825;&#20123;&#24448;&#24448;&#23436;&#20840;&#20559;&#31163;&#23454;&#38469;&#34892;&#20026;&#12290;&#26412;&#25991;&#22312;ImageNet&#19978;&#23545;&#22810;&#31181;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#22120;&#36827;&#34892;&#20840;&#38754;&#35780;&#20272;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#23613;&#31649;&#26377;&#30528;&#39047;&#26377;&#24076;&#26395;&#30340;&#29702;&#35770;&#21162;&#21147;&#65292;&#23454;&#36341;&#20013;&#20173;&#26410;&#23454;&#29616;&#35299;&#24320;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#21738;&#20123;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#22120;&#22312;&#21738;&#20123;&#29305;&#23450;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#33394;&#65292;&#20026;&#20174;&#19994;&#32773;&#25552;&#20379;&#35265;&#35299;&#24182;&#24341;&#23548;&#26410;&#26469;&#30740;&#31350;&#26397;&#30528;&#22522;&#20110;&#20219;&#21153;&#21644;&#35299;&#24320;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#26041;&#27861;&#21457;&#23637;&#12290;&#25105;&#20204;&#30340;&#20195;&#30721;&#21487;&#22312; https://github.com/bmucsanyi/bud &#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.19460v1 Announce Type: new  Abstract: Uncertainty quantification, once a singular task, has evolved into a spectrum of tasks, including abstained prediction, out-of-distribution detection, and aleatoric uncertainty quantification. The latest goal is disentanglement: the construction of multiple estimators that are each tailored to one and only one task. Hence, there is a plethora of recent advances with different intentions - that often entirely deviate from practical behavior. This paper conducts a comprehensive evaluation of numerous uncertainty estimators across diverse tasks on ImageNet. We find that, despite promising theoretical endeavors, disentanglement is not yet achieved in practice. Additionally, we reveal which uncertainty estimators excel at which specific tasks, providing insights for practitioners and guiding future research toward task-centric and disentangled uncertainty estimation methods. Our code is available at https://github.com/bmucsanyi/bud.
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;Gibbs&#25193;&#25955;&#65288;GDiff&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#20132;&#26367;&#37319;&#26679;&#20449;&#21495;&#20808;&#39564;&#21644;&#22122;&#22768;&#20998;&#24067;&#26063;&#65292;&#20197;&#21450;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#26469;&#25512;&#26029;&#22122;&#22768;&#21442;&#25968;&#65292;&#35299;&#20915;&#20102;&#30450;&#21435;&#22122;&#20013;&#38656;&#35201;&#30693;&#36947;&#22122;&#22768;&#27700;&#24179;&#21644;&#21327;&#26041;&#24046;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.19455</link><description>&lt;p&gt;
&#21548;&#22122;&#22768;&#65306;&#20351;&#29992;Gibbs&#25193;&#25955;&#36827;&#34892;&#30450;&#21435;&#22122;
&lt;/p&gt;
&lt;p&gt;
Listening to the Noise: Blind Denoising with Gibbs Diffusion
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.19455
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;Gibbs&#25193;&#25955;&#65288;GDiff&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#20132;&#26367;&#37319;&#26679;&#20449;&#21495;&#20808;&#39564;&#21644;&#22122;&#22768;&#20998;&#24067;&#26063;&#65292;&#20197;&#21450;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#26469;&#25512;&#26029;&#22122;&#22768;&#21442;&#25968;&#65292;&#35299;&#20915;&#20102;&#30450;&#21435;&#22122;&#20013;&#38656;&#35201;&#30693;&#36947;&#22122;&#22768;&#27700;&#24179;&#21644;&#21327;&#26041;&#24046;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#21435;&#22122;&#38382;&#39064;&#19982;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30340;&#21457;&#23637;&#23494;&#19981;&#21487;&#20998;&#12290;&#29305;&#21035;&#26159;&#65292;&#25193;&#25955;&#27169;&#22411;&#34987;&#35757;&#32451;&#25104;&#21435;&#22122;&#22120;&#65292;&#23427;&#20204;&#25152;&#24314;&#27169;&#30340;&#20998;&#24067;&#19982;&#36125;&#21494;&#26031;&#22270;&#20687;&#20013;&#30340;&#21435;&#22122;&#20808;&#39564;&#30456;&#31526;&#12290;&#28982;&#32780;&#65292;&#36890;&#36807;&#22522;&#20110;&#25193;&#25955;&#30340;&#21518;&#39564;&#37319;&#26679;&#36827;&#34892;&#21435;&#22122;&#38656;&#35201;&#30693;&#36947;&#22122;&#22768;&#27700;&#24179;&#21644;&#21327;&#26041;&#24046;&#65292;&#36825;&#38459;&#30861;&#20102;&#30450;&#21435;&#22122;&#12290;&#25105;&#20204;&#36890;&#36807;&#24341;&#20837; Gibbs&#25193;&#25955;&#65288;GDiff&#65289;&#20811;&#26381;&#20102;&#36825;&#19968;&#38480;&#21046;&#65292;&#36825;&#26159;&#19968;&#31181;&#36890;&#29992;&#26041;&#27861;&#35770;&#65292;&#21487;&#20197;&#22788;&#29702;&#20449;&#21495;&#21644;&#22122;&#22768;&#21442;&#25968;&#30340;&#21518;&#39564;&#37319;&#26679;&#12290;&#20551;&#35774;&#20219;&#24847;&#21442;&#25968;&#21270;&#30340;&#39640;&#26031;&#22122;&#22768;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;Gibbs&#31639;&#27861;&#65292;&#20132;&#26367;&#22320;&#20174;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#35813;&#27169;&#22411;&#32463;&#36807;&#35757;&#32451;&#23558;&#20449;&#21495;&#20808;&#39564;&#26144;&#23556;&#21040;&#22122;&#22768;&#20998;&#24067;&#26063;&#65292;&#20197;&#21450;&#19968;&#20010;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#22120;&#26469;&#25512;&#26029;&#22122;&#22768;&#21442;&#25968;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#31361;&#20986;&#20102;&#28508;&#22312;&#30340;&#32570;&#38519;&#65292;&#25351;&#23548;&#20102;&#35786;&#26029;&#30340;&#20351;&#29992;&#65292;&#24182;&#37327;&#21270;&#20102;Gibbs s&#20013;&#30340;&#38169;&#35823;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.19455v1 Announce Type: cross  Abstract: In recent years, denoising problems have become intertwined with the development of deep generative models. In particular, diffusion models are trained like denoisers, and the distribution they model coincide with denoising priors in the Bayesian picture. However, denoising through diffusion-based posterior sampling requires the noise level and covariance to be known, preventing blind denoising. We overcome this limitation by introducing Gibbs Diffusion (GDiff), a general methodology addressing posterior sampling of both the signal and the noise parameters. Assuming arbitrary parametric Gaussian noise, we develop a Gibbs algorithm that alternates sampling steps from a conditional diffusion model trained to map the signal prior to the family of noise distributions, and a Monte Carlo sampler to infer the noise parameters. Our theoretical analysis highlights potential pitfalls, guides diagnostic usage, and quantifies errors in the Gibbs s
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#21457;&#29616;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#37325;&#23614;&#31867;&#21035;&#19981;&#24179;&#34913;&#38382;&#39064;&#23548;&#33268;&#20102;&#20248;&#21270;&#21160;&#24577;&#19978;&#30340;&#22256;&#38590;&#65292;Adam&#21644;&#22522;&#20110;&#31526;&#21495;&#30340;&#26041;&#27861;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#20248;&#20110;&#26799;&#24230;&#19979;&#38477;&#12290;</title><link>https://arxiv.org/abs/2402.19449</link><description>&lt;p&gt;
Heavy-Tailed Class Imbalance and Why Adam Outperforms Gradient Descent on Language Models
&lt;/p&gt;
&lt;p&gt;
Heavy-Tailed Class Imbalance and Why Adam Outperforms Gradient Descent on Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.19449
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#21457;&#29616;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#37325;&#23614;&#31867;&#21035;&#19981;&#24179;&#34913;&#38382;&#39064;&#23548;&#33268;&#20102;&#20248;&#21270;&#21160;&#24577;&#19978;&#30340;&#22256;&#38590;&#65292;Adam&#21644;&#22522;&#20110;&#31526;&#21495;&#30340;&#26041;&#27861;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#20248;&#20110;&#26799;&#24230;&#19979;&#38477;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#35821;&#35328;&#24314;&#27169;&#20219;&#21153;&#20013;&#23384;&#22312;&#30340;&#37325;&#23614;&#31867;&#21035;&#19981;&#24179;&#34913;&#38382;&#39064;&#65292;&#20197;&#21450;&#20026;&#20160;&#20040;Adam&#22312;&#20248;&#21270;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26102;&#30340;&#34920;&#29616;&#20248;&#20110;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#30001;&#20110;&#35821;&#35328;&#24314;&#27169;&#20219;&#21153;&#20013;&#23384;&#22312;&#30340;&#37325;&#23614;&#31867;&#21035;&#19981;&#24179;&#34913;&#65292;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#26102;&#65292;&#19982;&#19981;&#24120;&#35265;&#21333;&#35789;&#30456;&#20851;&#30340;&#25439;&#22833;&#19979;&#38477;&#36895;&#24230;&#27604;&#19982;&#24120;&#35265;&#21333;&#35789;&#30456;&#20851;&#30340;&#25439;&#22833;&#19979;&#38477;&#36895;&#24230;&#24930;&#12290;&#30001;&#20110;&#22823;&#22810;&#25968;&#26679;&#26412;&#26469;&#33258;&#30456;&#23545;&#19981;&#24120;&#35265;&#30340;&#21333;&#35789;&#65292;&#24179;&#22343;&#25439;&#22833;&#20540;&#22312;&#26799;&#24230;&#19979;&#38477;&#26102;&#19979;&#38477;&#36895;&#24230;&#36739;&#24930;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;Adam&#21644;&#22522;&#20110;&#31526;&#21495;&#30340;&#26041;&#27861;&#21364;&#19981;&#21463;&#27492;&#38382;&#39064;&#24433;&#21709;&#65292;&#24182;&#25913;&#21892;&#20102;&#25152;&#26377;&#31867;&#21035;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#25105;&#20204;&#22312;&#19981;&#21516;&#26550;&#26500;&#21644;&#25968;&#25454;&#31867;&#22411;&#19978;&#36827;&#34892;&#20102;&#23454;&#35777;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#36825;&#31181;&#34892;&#20026;&#30830;&#23454;&#26159;&#30001;&#31867;&#21035;&#19981;&#24179;&#34913;&#24341;&#36215;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.19449v1 Announce Type: cross  Abstract: Adam has been shown to outperform gradient descent in optimizing large language transformers empirically, and by a larger margin than on other tasks, but it is unclear why this happens. We show that the heavy-tailed class imbalance found in language modeling tasks leads to difficulties in the optimization dynamics. When training with gradient descent, the loss associated with infrequent words decreases slower than the loss associated with frequent ones. As most samples come from relatively infrequent words, the average loss decreases slowly with gradient descent. On the other hand, Adam and sign-based methods do not suffer from this problem and improve predictions on all classes. To establish that this behavior is indeed caused by class imbalance, we show empirically that it persist through different architectures and data types, on language transformers, vision CNNs, and linear models. We further study this phenomenon on a linear clas
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#22810;&#22836;softmax&#27880;&#24847;&#21147;&#27169;&#22411;&#22312;&#19978;&#19979;&#25991;&#23398;&#20064;&#20013;&#30340;&#35757;&#32451;&#21160;&#24577;&#65292;&#35777;&#26126;&#20102;&#20840;&#23616;&#25910;&#25947;&#24615;&#65292;&#24182;&#21457;&#29616;&#20102;&#8220;&#20219;&#21153;&#20998;&#37197;&#8221;&#29616;&#35937;&#65292;&#26799;&#24230;&#27969;&#21160;&#20998;&#20026;&#28909;&#36523;&#12289;&#28044;&#29616;&#21644;&#25910;&#25947;&#19977;&#20010;&#38454;&#27573;&#65292;&#26368;&#32456;&#35777;&#26126;&#20102;&#26799;&#24230;&#27969;&#30340;&#26368;&#20248;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.19442</link><description>&lt;p&gt;
&#22810;&#22836;softmax&#27880;&#24847;&#21147;&#26426;&#21046;&#22312;&#19978;&#19979;&#25991;&#23398;&#20064;&#20013;&#30340;&#35757;&#32451;&#21160;&#24577;&#65306;&#28044;&#29616;&#12289;&#25910;&#25947;&#21644;&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;
Training Dynamics of Multi-Head Softmax Attention for In-Context Learning: Emergence, Convergence, and Optimality
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.19442
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#22810;&#22836;softmax&#27880;&#24847;&#21147;&#27169;&#22411;&#22312;&#19978;&#19979;&#25991;&#23398;&#20064;&#20013;&#30340;&#35757;&#32451;&#21160;&#24577;&#65292;&#35777;&#26126;&#20102;&#20840;&#23616;&#25910;&#25947;&#24615;&#65292;&#24182;&#21457;&#29616;&#20102;&#8220;&#20219;&#21153;&#20998;&#37197;&#8221;&#29616;&#35937;&#65292;&#26799;&#24230;&#27969;&#21160;&#20998;&#20026;&#28909;&#36523;&#12289;&#28044;&#29616;&#21644;&#25910;&#25947;&#19977;&#20010;&#38454;&#27573;&#65292;&#26368;&#32456;&#35777;&#26126;&#20102;&#26799;&#24230;&#27969;&#30340;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#29992;&#20110;&#19978;&#19979;&#25991;&#23398;&#20064;&#30340;&#22810;&#20219;&#21153;&#32447;&#24615;&#22238;&#24402;&#30340;&#22810;&#22836;softmax&#27880;&#24847;&#21147;&#27169;&#22411;&#30340;&#26799;&#24230;&#27969;&#21160;&#21147;&#23398;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#36866;&#24403;&#30340;&#21021;&#22987;&#21270;&#36873;&#25321;&#19979;&#65292;&#26799;&#24230;&#27969;&#21160;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#26799;&#24230;&#27969;&#21160;&#21160;&#21147;&#23398;&#20013;&#20986;&#29616;&#20102;&#26377;&#36259;&#30340;&#8220;&#20219;&#21153;&#20998;&#37197;&#8221;&#29616;&#35937;&#65292;&#27599;&#20010;&#27880;&#24847;&#21147;&#22836;&#37117;&#19987;&#27880;&#20110;&#35299;&#20915;&#22810;&#20219;&#21153;&#27169;&#22411;&#20013;&#30340;&#21333;&#20010;&#20219;&#21153;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#26799;&#24230;&#27969;&#21160;&#21160;&#21147;&#23398;&#21487;&#20197;&#20998;&#20026;&#19977;&#20010;&#38454;&#27573;&#8212;&#8212;&#28909;&#36523;&#38454;&#27573;&#65292;&#22312;&#36825;&#20010;&#38454;&#27573;&#25439;&#22833;&#20943;&#23569;&#36895;&#24230;&#36739;&#24930;&#65292;&#27880;&#24847;&#21147;&#22836;&#36880;&#28176;&#20542;&#21521;&#20110;&#21508;&#33258;&#30340;&#20219;&#21153;&#65307;&#28044;&#29616;&#38454;&#27573;&#65292;&#22312;&#36825;&#20010;&#38454;&#27573;&#65292;&#27599;&#20010;&#22836;&#36873;&#25321;&#19968;&#20010;&#21333;&#29420;&#30340;&#20219;&#21153;&#65292;&#25439;&#22833;&#36805;&#36895;&#20943;&#23569;&#65307;&#21644;&#25910;&#25947;&#38454;&#27573;&#65292;&#22312;&#36825;&#20010;&#38454;&#27573;&#65292;&#27880;&#24847;&#21147;&#21442;&#25968;&#25910;&#25947;&#21040;&#19968;&#20010;&#26497;&#38480;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#26799;&#24230;&#27969;&#22312;&#23398;&#20064;&#26497;&#38480;&#27169;&#22411;&#26041;&#38754;&#30340;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.19442v1 Announce Type: cross  Abstract: We study the dynamics of gradient flow for training a multi-head softmax attention model for in-context learning of multi-task linear regression. We establish the global convergence of gradient flow under suitable choices of initialization. In addition, we prove that an interesting "task allocation" phenomenon emerges during the gradient flow dynamics, where each attention head focuses on solving a single task of the multi-task model. Specifically, we prove that the gradient flow dynamics can be split into three phases -- a warm-up phase where the loss decreases rather slowly and the attention heads gradually build up their inclination towards individual tasks, an emergence phase where each head selects a single task and the loss rapidly decreases, and a convergence phase where the attention parameters converge to a limit. Furthermore, we prove the optimality of gradient flow in the sense that the limiting model learned by gradient flo
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#36127;&#20108;&#39033;&#38543;&#26426;Gamma&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#65292;&#29992;&#20110;&#25913;&#36827;&#24322;&#36136;&#36807;&#24230;&#31163;&#25955;&#35745;&#25968;&#26102;&#38388;&#24207;&#21015;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#24182;&#21152;&#24555;&#25512;&#26029;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.18995</link><description>&lt;p&gt;
&#29992;&#20110;&#24322;&#36136;&#36807;&#24230;&#31163;&#25955;&#35745;&#25968;&#26102;&#38388;&#24207;&#21015;&#30340;&#36127;&#20108;&#39033;&#38543;&#26426;Gamma&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Negative-Binomial Randomized Gamma Markov Processes for Heterogeneous Overdispersed Count Time Series
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18995
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36127;&#20108;&#39033;&#38543;&#26426;Gamma&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#65292;&#29992;&#20110;&#25913;&#36827;&#24322;&#36136;&#36807;&#24230;&#31163;&#25955;&#35745;&#25968;&#26102;&#38388;&#24207;&#21015;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#24182;&#21152;&#24555;&#25512;&#26029;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#35745;&#25968;&#20540;&#26102;&#38388;&#24207;&#21015;&#30340;&#24314;&#27169;&#33258;&#28982;&#22320;&#22312;&#29289;&#29702;&#21644;&#31038;&#20250;&#39046;&#22495;&#20013;&#24341;&#36215;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;Poisson gamma&#21160;&#24577;&#31995;&#32479;&#65288;PGDSs&#65289;&#26159;&#26032;&#24320;&#21457;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#24456;&#22909;&#22320;&#25429;&#25417;&#35745;&#25968;&#24207;&#21015;&#32972;&#21518;&#34920;&#29616;&#20986;&#30340;&#26126;&#26174;&#30340;&#28508;&#22312;&#36716;&#25442;&#32467;&#26500;&#21644;&#31361;&#21457;&#21160;&#24577;&#12290;&#29305;&#21035;&#26159;&#65292;&#19982;&#22522;&#20110;&#32463;&#20856;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#65288;LDS&#65289;&#30340;&#26041;&#27861;&#30456;&#27604;&#65292;PGDSs&#22312;&#25968;&#25454;&#22635;&#20805;&#21644;&#39044;&#27979;&#26041;&#38754;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#33021;&#12290;&#23613;&#31649;&#20855;&#26377;&#36825;&#20123;&#20248;&#21183;&#65292;PGDS&#19981;&#33021;&#25429;&#25417;&#22522;&#30784;&#21160;&#24577;&#36807;&#31243;&#30340;&#24322;&#36136;&#36807;&#24230;&#31163;&#25955;&#34892;&#20026;&#12290;&#20026;&#20102;&#20943;&#36731;&#36825;&#19968;&#32570;&#38519;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36127;&#20108;&#39033;&#38543;&#26426;Gamma&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#65292;&#23427;&#19981;&#20165;&#26174;&#33879;&#25913;&#21892;&#20102;&#25152;&#25552;&#20986;&#30340;&#21160;&#24577;&#31995;&#32479;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#36824;&#20419;&#36827;&#20102;&#25512;&#26029;&#31639;&#27861;&#30340;&#24555;&#36895;&#25910;&#25947;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#20272;&#35745;&#22240;&#23376;&#32467;&#26500;&#21644;&#22270;&#32467;&#26500;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18995v1 Announce Type: cross  Abstract: Modeling count-valued time series has been receiving increasing attention since count time series naturally arise in physical and social domains. Poisson gamma dynamical systems (PGDSs) are newly-developed methods, which can well capture the expressive latent transition structure and bursty dynamics behind count sequences. In particular, PGDSs demonstrate superior performance in terms of data imputation and prediction, compared with canonical linear dynamical system (LDS) based methods. Despite these advantages, PGDS cannot capture the heterogeneous overdispersed behaviours of the underlying dynamic processes. To mitigate this defect, we propose a negative-binomial-randomized gamma Markov process, which not only significantly improves the predictive performance of the proposed dynamical system, but also facilitates the fast convergence of the inference algorithm. Moreover, we develop methods to estimate both factor-structured and graph
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#31181;&#21322;&#30417;&#30563; U-&#32479;&#35745;&#37327;&#65292;&#21033;&#29992;&#22823;&#37327;&#26410;&#26631;&#35760;&#25968;&#25454;&#65292;&#33719;&#24471;&#20102;&#28176;&#36817;&#27491;&#24577;&#20998;&#24067;&#30340;&#24615;&#36136;&#65292;&#24182;&#36890;&#36807;&#26377;&#25928;&#25972;&#21512;&#21508;&#31181;&#24378;&#22823;&#39044;&#27979;&#24037;&#20855;&#23454;&#29616;&#20102;&#26126;&#26174;&#30340;&#25928;&#29575;&#25552;&#21319;&#12290;</title><link>https://arxiv.org/abs/2402.18921</link><description>&lt;p&gt;
&#21322;&#30417;&#30563; U-&#32479;&#35745;&#37327;
&lt;/p&gt;
&lt;p&gt;
Semi-Supervised U-statistics
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18921
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;&#21322;&#30417;&#30563; U-&#32479;&#35745;&#37327;&#65292;&#21033;&#29992;&#22823;&#37327;&#26410;&#26631;&#35760;&#25968;&#25454;&#65292;&#33719;&#24471;&#20102;&#28176;&#36817;&#27491;&#24577;&#20998;&#24067;&#30340;&#24615;&#36136;&#65292;&#24182;&#36890;&#36807;&#26377;&#25928;&#25972;&#21512;&#21508;&#31181;&#24378;&#22823;&#39044;&#27979;&#24037;&#20855;&#23454;&#29616;&#20102;&#26126;&#26174;&#30340;&#25928;&#29575;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18921v1 &#36890;&#25253;&#31867;&#22411;: &#36328;&#39046;&#22495;  &#25688;&#35201;: &#21322;&#30417;&#30563;&#25968;&#25454;&#38598;&#22312;&#22810;&#20010;&#39046;&#22495;&#20013;&#26222;&#36941;&#23384;&#22312;&#65292;&#20854;&#20013;&#33719;&#24471;&#23436;&#20840;&#26631;&#35760;&#25968;&#25454;&#25104;&#26412;&#39640;&#26114;&#25110;&#32791;&#26102;&#12290;&#36825;&#31867;&#25968;&#25454;&#38598;&#30340;&#26222;&#36941;&#23384;&#22312;&#19968;&#30452;&#25512;&#21160;&#30528;&#23545;&#21033;&#29992;&#26410;&#26631;&#35760;&#25968;&#25454;&#28508;&#21147;&#30340;&#26032;&#24037;&#20855;&#21644;&#26041;&#27861;&#30340;&#38656;&#27714;&#12290;&#20026;&#20102;&#28385;&#36275;&#36825;&#31181;&#38656;&#27714;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#21463;&#30410;&#20110;&#22823;&#37327;&#26410;&#26631;&#35760;&#25968;&#25454;&#30340;&#21322;&#30417;&#30563; U-&#32479;&#35745;&#37327;&#65292;&#24182;&#30740;&#31350;&#20102;&#23427;&#20204;&#30340;&#32479;&#35745;&#29305;&#24615;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#28176;&#36817;&#22320;&#26381;&#20174;&#27491;&#24577;&#20998;&#24067;&#65292;&#24182;&#19988;&#36890;&#36807;&#26377;&#25928;&#22320;&#23558;&#21508;&#31181;&#24378;&#22823;&#30340;&#39044;&#27979;&#24037;&#20855;&#25972;&#21512;&#21040;&#26694;&#26550;&#20013;&#65292;&#33719;&#24471;&#20102;&#26126;&#26174;&#30340;&#25928;&#29575;&#25552;&#21319;&#65292;&#36229;&#36807;&#20102;&#32463;&#20856; U-&#32479;&#35745;&#37327;&#12290;&#20026;&#20102;&#29702;&#35299;&#38382;&#39064;&#30340;&#26681;&#26412;&#22256;&#38590;&#65292;&#25105;&#20204;&#22312;&#21322;&#30417;&#30563;&#35774;&#32622;&#20013;&#25512;&#23548;&#20102;&#26497;&#23567;&#26497;&#22823;&#19979;&#30028;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#27491;&#21017;&#26465;&#20214;&#19979;&#25105;&#20204;&#30340;&#36807;&#31243;&#26159;&#21322;&#21442;&#25968;&#26377;&#25928;&#30340;&#12290;&#27492;&#22806;&#65292;&#38024;&#23545;&#21452;&#21464;&#37327;&#26680;&#20989;&#25968;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#32988;&#36807;&#20102;&#32463;&#20856;&#30340; U-&#32479;&#35745;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18921v1 Announce Type: cross  Abstract: Semi-supervised datasets are ubiquitous across diverse domains where obtaining fully labeled data is costly or time-consuming. The prevalence of such datasets has consistently driven the demand for new tools and methods that exploit the potential of unlabeled data. Responding to this demand, we introduce semi-supervised U-statistics enhanced by the abundance of unlabeled data, and investigate their statistical properties. We show that the proposed approach is asymptotically Normal and exhibits notable efficiency gains over classical U-statistics by effectively integrating various powerful prediction tools into the framework. To understand the fundamental difficulty of the problem, we derive minimax lower bounds in semi-supervised settings and showcase that our procedure is semi-parametrically efficient under regularity conditions. Moreover, tailored to bivariate kernels, we propose a refined approach that outperforms the classical U-st
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#39044;&#21518;&#35780;&#20998;&#35843;&#25972;&#21487;&#20197;&#25552;&#39640;&#36923;&#36753;&#22238;&#24402;&#20013;&#26465;&#20214;&#27604;&#20540;&#30340;Wald&#26816;&#39564;&#30340;&#33021;&#21147;</title><link>https://arxiv.org/abs/2402.18900</link><description>&lt;p&gt;
&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#20013;&#36923;&#36753;&#22238;&#24402;&#30340;&#39044;&#21518;&#36741;&#21161;&#26657;&#27491;
&lt;/p&gt;
&lt;p&gt;
Prognostic Covariate Adjustment for Logistic Regression in Randomized Controlled Trials
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18900
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#39044;&#21518;&#35780;&#20998;&#35843;&#25972;&#21487;&#20197;&#25552;&#39640;&#36923;&#36753;&#22238;&#24402;&#20013;&#26465;&#20214;&#27604;&#20540;&#30340;Wald&#26816;&#39564;&#30340;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;&#29983;&#25104;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#31639;&#27861;&#39044;&#27979;&#23545;&#29031;&#32467;&#26524;&#65292;&#21363;&#25152;&#35859;&#30340;&#39044;&#21518;&#35780;&#20998;&#65292;&#26469;&#36827;&#34892;&#36923;&#36753;&#22238;&#24402;&#20013;&#30340;&#39044;&#21518;&#35780;&#20998;&#35843;&#25972;&#65292;&#20197;&#22686;&#21152;&#22266;&#23450;&#26679;&#26412;&#37327;&#26465;&#20214;&#19979;&#26465;&#20214;&#27604;&#20540;&#30340;Wald&#26816;&#39564;&#21147;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18900v1 Announce Type: cross  Abstract: Randomized controlled trials (RCTs) with binary primary endpoints introduce novel challenges for inferring the causal effects of treatments. The most significant challenge is non-collapsibility, in which the conditional odds ratio estimand under covariate adjustment differs from the unconditional estimand in the logistic regression analysis of RCT data. This issue gives rise to apparent paradoxes, such as the variance of the estimator for the conditional odds ratio from a covariate-adjusted model being greater than the variance of the estimator from the unadjusted model. We address this challenge in the context of adjustment based on predictions of control outcomes from generative artificial intelligence (AI) algorithms, which are referred to as prognostic scores. We demonstrate that prognostic score adjustment in logistic regression increases the power of the Wald test for the conditional odds ratio under a fixed sample size, or alter
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#30417;&#30563;&#23545;&#27604;&#34920;&#31034;&#23398;&#20064;&#65292;&#22312;&#36229;&#21442;&#25968;&#21270;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30740;&#31350;&#35299;&#20915;&#26041;&#26696;&#65292;&#25581;&#31034;&#20102;&#26368;&#23567;&#21270;SC&#25439;&#22833;&#30340;&#20840;&#23616;&#26368;&#23567;&#20540;&#21644;&#21807;&#19968;&#26368;&#23567;&#21270;&#22120;&#12290;</title><link>https://arxiv.org/abs/2402.18884</link><description>&lt;p&gt;
&#30417;&#30563;&#23545;&#27604;&#34920;&#31034;&#23398;&#20064;&#65306;&#20855;&#26377;&#19981;&#21463;&#38480;&#21046;&#29305;&#24449;&#30340;&#26223;&#35266;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Supervised Contrastive Representation Learning: Landscape Analysis with Unconstrained Features
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18884
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#30417;&#30563;&#23545;&#27604;&#34920;&#31034;&#23398;&#20064;&#65292;&#22312;&#36229;&#21442;&#25968;&#21270;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30740;&#31350;&#35299;&#20915;&#26041;&#26696;&#65292;&#25581;&#31034;&#20102;&#26368;&#23567;&#21270;SC&#25439;&#22833;&#30340;&#20840;&#23616;&#26368;&#23567;&#20540;&#21644;&#21807;&#19968;&#26368;&#23567;&#21270;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#36229;&#21442;&#25968;&#21270;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#32463;&#36807;&#38646;&#35757;&#32451;&#35823;&#24046;&#35757;&#32451;&#21518;&#30340;&#32593;&#32476;&#65292;&#22312;&#26368;&#21518;&#19968;&#23618;&#21576;&#29616;&#20986;&#20005;&#26684;&#30340;&#32467;&#26500;&#27169;&#24335;&#65292;&#34987;&#31216;&#20026;&#31070;&#32463;&#22349;&#22604;&#65288;NC&#65289;&#12290;&#36825;&#20123;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#36825;&#31181;&#32593;&#32476;&#20013;&#65292;&#26368;&#32456;&#38544;&#34255;&#23618;&#36755;&#20986;&#22312;&#35757;&#32451;&#38598;&#19978;&#26174;&#31034;&#20986;&#26368;&#23567;&#30340;&#31867;&#20869;&#21464;&#21270;&#12290;&#34429;&#28982;&#29616;&#26377;&#30740;&#31350;&#22312;&#20132;&#21449;&#29109;&#25439;&#22833;&#19979;&#24191;&#27867;&#25506;&#35752;&#20102;&#36825;&#19968;&#29616;&#35937;&#65292;&#20294;&#20851;&#20110;&#20854;&#23545;&#24212;&#30340;&#23545;&#27604;&#25439;&#22833;&#8212;&#8212;&#30417;&#30563;&#23545;&#27604;&#65288;SC&#65289;&#25439;&#22833;&#30340;&#30740;&#31350;&#36739;&#23569;&#12290;&#26412;&#25991;&#36890;&#36807;NC&#30340;&#35270;&#35282;&#65292;&#37319;&#29992;&#20998;&#26512;&#26041;&#27861;&#30740;&#31350;&#20102;&#20248;&#21270;SC&#25439;&#22833;&#25152;&#24471;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#37319;&#29992;&#19981;&#21463;&#38480;&#21046;&#29305;&#24449;&#27169;&#22411;&#65288;UFM&#65289;&#20316;&#20026;&#20195;&#34920;&#24615;&#20195;&#29702;&#65292;&#25581;&#31034;&#20102;&#22312;&#20805;&#20998;&#36229;&#21442;&#25968;&#21270;&#30340;&#28145;&#24230;&#32593;&#32476;&#20013;&#34893;&#29983;&#30340;&#19982;NC&#30456;&#20851;&#29616;&#35937;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#65292;&#23613;&#31649;SC&#25439;&#22833;&#26368;&#23567;&#21270;&#26159;&#38750;&#20984;&#30340;&#65292;&#20294;&#25152;&#26377;&#23616;&#37096;&#26368;&#23567;&#20540;&#37117;&#26159;&#20840;&#23616;&#26368;&#23567;&#20540;&#12290;&#27492;&#22806;&#65292;&#26368;&#23567;&#21270;&#22120;&#26159;&#21807;&#19968;&#30340;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18884v1 Announce Type: new  Abstract: Recent findings reveal that over-parameterized deep neural networks, trained beyond zero training-error, exhibit a distinctive structural pattern at the final layer, termed as Neural-collapse (NC). These results indicate that the final hidden-layer outputs in such networks display minimal within-class variations over the training set. While existing research extensively investigates this phenomenon under cross-entropy loss, there are fewer studies focusing on its contrastive counterpart, supervised contrastive (SC) loss. Through the lens of NC, this paper employs an analytical approach to study the solutions derived from optimizing the SC loss. We adopt the unconstrained features model (UFM) as a representative proxy for unveiling NC-related phenomena in sufficiently over-parameterized deep networks. We show that, despite the non-convexity of SC loss minimization, all local minima are global minima. Furthermore, the minimizer is unique (
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;&#22788;&#26041;&#32593;&#32476;&#65288;PNNs&#65289;&#36825;&#31181;&#26032;&#22411;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010;&#35757;&#32451;&#65292;&#32467;&#21512;&#21453;&#20107;&#23454;&#20272;&#35745;&#65292;&#22312;&#21307;&#30103;&#20915;&#31574;&#20013;&#23637;&#29616;&#20986;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#30340;&#34920;&#29616;&#65292;&#21487;&#20248;&#21270;&#27835;&#30103;&#31574;&#30053;&#65292;&#24182;&#20855;&#26377;&#26356;&#22823;&#30340;&#21487;&#35299;&#37322;&#24615;&#21644;&#26356;&#22797;&#26434;&#30340;&#31574;&#30053;&#32534;&#30721;&#33021;&#21147;&#12290;</title><link>https://arxiv.org/abs/2402.18851</link><description>&lt;p&gt;
&#22312;&#22788;&#26041;&#21644;&#39044;&#27979;&#20013;&#24212;&#29992;0-1&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Applications of 0-1 Neural Networks in Prescription and Prediction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18851
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#22788;&#26041;&#32593;&#32476;&#65288;PNNs&#65289;&#36825;&#31181;&#26032;&#22411;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010;&#35757;&#32451;&#65292;&#32467;&#21512;&#21453;&#20107;&#23454;&#20272;&#35745;&#65292;&#22312;&#21307;&#30103;&#20915;&#31574;&#20013;&#23637;&#29616;&#20986;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#30340;&#34920;&#29616;&#65292;&#21487;&#20248;&#21270;&#27835;&#30103;&#31574;&#30053;&#65292;&#24182;&#20855;&#26377;&#26356;&#22823;&#30340;&#21487;&#35299;&#37322;&#24615;&#21644;&#26356;&#22797;&#26434;&#30340;&#31574;&#30053;&#32534;&#30721;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21307;&#30103;&#20915;&#31574;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#26159;&#22312;&#26377;&#38480;&#30340;&#35266;&#23519;&#25968;&#25454;&#19979;&#23398;&#20064;&#38024;&#23545;&#24739;&#32773;&#30340;&#27835;&#30103;&#31574;&#30053;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#22788;&#26041;&#32593;&#32476;&#65288;PNNs&#65289;&#65292;&#36825;&#26159;&#29992;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010;&#35757;&#32451;&#30340;&#27973;&#23618;0-1&#31070;&#32463;&#32593;&#32476;&#65292;&#21487;&#20197;&#19982;&#21453;&#20107;&#23454;&#20272;&#35745;&#19968;&#36215;&#22312;&#20013;&#31561;&#25968;&#25454;&#24773;&#20917;&#19979;&#20248;&#21270;&#31574;&#30053;&#12290;&#36825;&#20123;&#27169;&#22411;&#27604;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20855;&#26377;&#26356;&#22823;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#19988;&#21487;&#20197;&#32534;&#30721;&#27604;&#24120;&#35265;&#27169;&#22411;&#65288;&#22914;&#20915;&#31574;&#26641;&#65289;&#26356;&#22797;&#26434;&#30340;&#31574;&#30053;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;PNNs&#22312;&#21512;&#25104;&#25968;&#25454;&#23454;&#39564;&#21644;&#20135;&#21518;&#39640;&#34880;&#21387;&#27835;&#30103;&#20998;&#37197;&#26696;&#20363;&#30740;&#31350;&#20013;&#34920;&#29616;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;&#29305;&#21035;&#26159;&#65292;PNNs&#34987;&#35777;&#26126;&#33021;&#22815;&#20135;&#29983;&#21487;&#38477;&#20302;&#39640;&#34880;&#21387;&#23792;&#20540;&#30340;&#27835;&#30103;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18851v1 Announce Type: cross  Abstract: A key challenge in medical decision making is learning treatment policies for patients with limited observational data. This challenge is particularly evident in personalized healthcare decision-making, where models need to take into account the intricate relationships between patient characteristics, treatment options, and health outcomes. To address this, we introduce prescriptive networks (PNNs), shallow 0-1 neural networks trained with mixed integer programming that can be used with counterfactual estimation to optimize policies in medium data settings. These models offer greater interpretability than deep neural networks and can encode more complex policies than common models such as decision trees. We show that PNNs can outperform existing methods in both synthetic data experiments and in a case study of assigning treatments for postpartum hypertension. In particular, PNNs are shown to produce policies that could reduce peak bloo
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;VEC-SBM&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#31038;&#20132;&#32593;&#32476;&#20013;&#20351;&#29992;&#21521;&#37327;&#36793;&#32536;&#21327;&#21464;&#37327;&#26469;&#26368;&#20248;&#22320;&#26816;&#27979;&#31038;&#21306;&#65292;&#35777;&#26126;&#20102;&#22312;&#31038;&#21306;&#26816;&#27979;&#36807;&#31243;&#20013;&#21033;&#29992;&#36793;&#32536;&#20449;&#24687;&#30340;&#38468;&#21152;&#20215;&#20540;&#12290;</title><link>https://arxiv.org/abs/2402.18805</link><description>&lt;p&gt;
VEC-SBM&#65306;&#20855;&#26377;&#21521;&#37327;&#36793;&#32536;&#21327;&#21464;&#37327;&#30340;&#26368;&#20248;&#31038;&#21306;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
VEC-SBM: Optimal Community Detection with Vectorial Edges Covariates
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18805
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;VEC-SBM&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#31038;&#20132;&#32593;&#32476;&#20013;&#20351;&#29992;&#21521;&#37327;&#36793;&#32536;&#21327;&#21464;&#37327;&#26469;&#26368;&#20248;&#22320;&#26816;&#27979;&#31038;&#21306;&#65292;&#35777;&#26126;&#20102;&#22312;&#31038;&#21306;&#26816;&#27979;&#36807;&#31243;&#20013;&#21033;&#29992;&#36793;&#32536;&#20449;&#24687;&#30340;&#38468;&#21152;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31038;&#20132;&#32593;&#32476;&#36890;&#24120;&#19982;&#20016;&#23500;&#30340;&#36793;&#32536;&#20449;&#24687;&#30456;&#20851;&#32852;&#65292;&#20363;&#22914;&#25991;&#26412;&#21644;&#22270;&#20687;&#12290;&#34429;&#28982;&#24050;&#32463;&#24320;&#21457;&#20102;&#35768;&#22810;&#26041;&#27861;&#26469;&#20174;&#25104;&#23545;&#20114;&#21160;&#20013;&#35782;&#21035;&#31038;&#21306;&#65292;&#20294;&#23427;&#20204;&#36890;&#24120;&#24573;&#30053;&#20102;&#36825;&#31181;&#36793;&#32536;&#20449;&#24687;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;SBM&#65289;&#30340;&#25193;&#23637;&#65292;&#36825;&#26159;&#19968;&#31181;&#24191;&#27867;&#29992;&#20110;&#31038;&#21306;&#26816;&#27979;&#30340;&#32479;&#35745;&#26694;&#26550;&#65292;&#23427;&#38598;&#25104;&#20102;&#21521;&#37327;&#36793;&#32536;&#21327;&#21464;&#37327;&#65306;&#21521;&#37327;&#36793;&#32536;&#21327;&#21464;&#37327;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;VEC-SBM&#65289;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36845;&#20195;&#32454;&#21270;&#25216;&#26415;&#30340;&#26032;&#31639;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#22312;VEC-SBM&#19979;&#30340;&#26368;&#20248;&#24674;&#22797;&#28508;&#22312;&#31038;&#21306;&#30340;&#33021;&#21147;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20005;&#26684;&#35780;&#20272;&#20102;&#22312;&#31038;&#21306;&#26816;&#27979;&#36807;&#31243;&#20013;&#21033;&#29992;&#36793;&#32536;&#20449;&#24687;&#30340;&#38468;&#21152;&#20215;&#20540;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#21512;&#25104;&#21644;&#21322;&#21512;&#25104;&#25968;&#25454;&#36827;&#34892;&#25968;&#20540;&#23454;&#39564;&#26469;&#34917;&#20805;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18805v1 Announce Type: cross  Abstract: Social networks are often associated with rich side information, such as texts and images. While numerous methods have been developed to identify communities from pairwise interactions, they usually ignore such side information. In this work, we study an extension of the Stochastic Block Model (SBM), a widely used statistical framework for community detection, that integrates vectorial edges covariates: the Vectorial Edges Covariates Stochastic Block Model (VEC-SBM). We propose a novel algorithm based on iterative refinement techniques and show that it optimally recovers the latent communities under the VEC-SBM. Furthermore, we rigorously assess the added value of leveraging edge's side information in the community detection process. We complement our theoretical results with numerical experiments on synthetic and semi-synthetic data.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;BlockEcho&#30340;&#26032;&#30697;&#38453;&#22635;&#20805;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#30697;&#38453;&#20998;&#35299;&#21644;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#30456;&#32467;&#21512;&#65292;&#21019;&#36896;&#24615;&#22320;&#20445;&#30041;&#20102;&#21407;&#22987;&#30697;&#38453;&#20013;&#30340;&#38271;&#36317;&#31163;&#20381;&#36182;&#20851;&#31995;&#65292;&#20197;&#35299;&#20915;&#22359;&#29366;&#32570;&#22833;&#25968;&#25454;&#23545;&#25968;&#25454;&#25554;&#20540;&#21644;&#39044;&#27979;&#33021;&#21147;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2402.18800</link><description>&lt;p&gt;
BlockEcho&#65306;&#20445;&#30041;&#38271;&#36317;&#31163;&#20381;&#36182;&#20851;&#31995;&#29992;&#20110;&#22635;&#34917;&#22359;&#29366;&#32570;&#22833;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
BlockEcho: Retaining Long-Range Dependencies for Imputing Block-Wise Missing Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18800
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;BlockEcho&#30340;&#26032;&#30697;&#38453;&#22635;&#20805;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#30697;&#38453;&#20998;&#35299;&#21644;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#30456;&#32467;&#21512;&#65292;&#21019;&#36896;&#24615;&#22320;&#20445;&#30041;&#20102;&#21407;&#22987;&#30697;&#38453;&#20013;&#30340;&#38271;&#36317;&#31163;&#20381;&#36182;&#20851;&#31995;&#65292;&#20197;&#35299;&#20915;&#22359;&#29366;&#32570;&#22833;&#25968;&#25454;&#23545;&#25968;&#25454;&#25554;&#20540;&#21644;&#39044;&#27979;&#33021;&#21147;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18800v1 &#31867;&#22411;&#65306;&#26032;  &#25688;&#35201;&#65306;&#22359;&#29366;&#32570;&#22833;&#25968;&#25454;&#22312;&#23454;&#38469;&#25968;&#25454;&#22635;&#34917;&#20219;&#21153;&#20013;&#24102;&#26469;&#20102;&#26174;&#33879;&#25361;&#25112;&#12290;&#19982;&#20998;&#25955;&#30340;&#32570;&#22833;&#25968;&#25454;&#30456;&#27604;&#65292;&#22359;&#29366;&#32570;&#22833;&#25968;&#25454;&#21152;&#21095;&#20102;&#23545;&#21518;&#32493;&#20998;&#26512;&#21644;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#30340;&#19981;&#21033;&#24433;&#21709;&#65292;&#22240;&#20026;&#32570;&#20047;&#23616;&#37096;&#30456;&#37051;&#20803;&#32032;&#26174;&#33879;&#38477;&#20302;&#20102;&#25554;&#20540;&#33021;&#21147;&#21644;&#39044;&#27979;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#36825;&#20010;&#38382;&#39064;&#23578;&#26410;&#24471;&#21040;&#20805;&#20998;&#20851;&#27880;&#12290;&#30001;&#20110;&#36807;&#24230;&#20381;&#36182;&#37051;&#36817;&#20803;&#32032;&#36827;&#34892;&#39044;&#27979;&#65292;&#22823;&#22810;&#25968;SOTA&#30697;&#38453;&#22635;&#20805;&#26041;&#27861;&#26174;&#31034;&#20986;&#36739;&#20302;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#31995;&#32479;&#22320;&#20998;&#26512;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#30697;&#38453;&#22635;&#20805;&#26041;&#27861;&#8220;BlockEcho&#8221;&#20197;&#25552;&#20379;&#26356;&#20840;&#38754;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#35813;&#26041;&#27861;&#21019;&#36896;&#24615;&#22320;&#23558;&#30697;&#38453;&#20998;&#35299;&#65288;MF&#65289;&#19982;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#30456;&#32467;&#21512;&#65292;&#20197;&#26126;&#30830;&#20445;&#30041;&#21407;&#22987;&#30697;&#38453;&#20013;&#30340;&#38271;&#36317;&#31163;&#20803;&#32032;&#38388;&#20851;&#31995;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#20026;GAN&#24341;&#20837;&#20102;&#19968;&#20010;&#39069;&#22806;&#30340;&#37492;&#21035;&#22120;&#65292;&#27604;&#36739;&#29983;&#25104;&#22120;&#30340;&#20013;&#38388;&#36827;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18800v1 Announce Type: new  Abstract: Block-wise missing data poses significant challenges in real-world data imputation tasks. Compared to scattered missing data, block-wise gaps exacerbate adverse effects on subsequent analytic and machine learning tasks, as the lack of local neighboring elements significantly reduces the interpolation capability and predictive power. However, this issue has not received adequate attention. Most SOTA matrix completion methods appeared less effective, primarily due to overreliance on neighboring elements for predictions. We systematically analyze the issue and propose a novel matrix completion method ``BlockEcho" for a more comprehensive solution. This method creatively integrates Matrix Factorization (MF) within Generative Adversarial Networks (GAN) to explicitly retain long-distance inter-element relationships in the original matrix. Besides, we incorporate an additional discriminator for GAN, comparing the generator's intermediate progre
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#20851;&#32852;&#35760;&#24518;&#27169;&#22359;&#30340;&#35757;&#32451;&#21160;&#24577;&#65292;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#39564;&#25581;&#31034;&#20102;&#22312;&#36807;&#21442;&#25968;&#21270;&#21644;&#27424;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#30340;&#23398;&#20064;&#21160;&#24577;&#21644;&#35823;&#24046;&#29305;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.18724</link><description>&lt;p&gt;
&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#20851;&#32852;&#35760;&#24518;
&lt;/p&gt;
&lt;p&gt;
Learning Associative Memories with Gradient Descent
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18724
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#20851;&#32852;&#35760;&#24518;&#27169;&#22359;&#30340;&#35757;&#32451;&#21160;&#24577;&#65292;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#39564;&#25581;&#31034;&#20102;&#22312;&#36807;&#21442;&#25968;&#21270;&#21644;&#27424;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#30340;&#23398;&#20064;&#21160;&#24577;&#21644;&#35823;&#24046;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#20027;&#35201;&#20851;&#27880;&#23384;&#20648;&#26631;&#35760;&#23884;&#20837;&#30340;&#22806;&#31215;&#30340;&#19968;&#20010;&#20851;&#32852;&#35760;&#24518;&#27169;&#22359;&#30340;&#35757;&#32451;&#21160;&#24577;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#38382;&#39064;&#31616;&#21270;&#20026;&#30740;&#31350;&#19968;&#20010;&#31890;&#23376;&#31995;&#32479;&#65292;&#36825;&#20123;&#31890;&#23376;&#26681;&#25454;&#25968;&#25454;&#20998;&#24067;&#30340;&#29305;&#24615;&#20197;&#21450;&#23884;&#20837;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#36827;&#34892;&#20132;&#20114;&#12290;&#36890;&#36807;&#29702;&#35770;&#21644;&#23454;&#39564;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20123;&#35265;&#35299;&#12290;&#22312;&#36807;&#21442;&#25968;&#21270;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#8220;&#20998;&#31867;&#36793;&#30028;&#8221;&#30340;&#23545;&#25968;&#22686;&#38271;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#34920;&#26126;&#26631;&#35760;&#39057;&#29575;&#30340;&#19981;&#24179;&#34913;&#21644;&#30001;&#30456;&#20851;&#23884;&#20837;&#23548;&#33268;&#30340;&#20869;&#23384;&#24178;&#25200;&#20250;&#23548;&#33268;&#25391;&#33633;&#30340;&#30636;&#24577;&#21306;&#22495;&#12290;&#25391;&#33633;&#22312;&#27493;&#38271;&#36739;&#22823;&#26102;&#26356;&#20026;&#26126;&#26174;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#33391;&#24615;&#25439;&#22833;&#23792;&#65292;&#23613;&#31649;&#36825;&#20123;&#23398;&#20064;&#29575;&#21152;&#36895;&#20102;&#21160;&#24577;&#24182;&#21152;&#36895;&#20102;&#28176;&#36817;&#25910;&#25947;&#12290;&#22312;&#27424;&#21442;&#25968;&#21270;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#38416;&#26126;&#20102;&#20132;&#21449;&#29109;&#25439;&#22833;&#22914;&#20309;&#23548;&#33268;&#27425;&#20248;&#30340;&#35760;&#24518;&#26041;&#26696;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#25105;&#20204;&#21457;&#29616;&#30340;&#22312;&#23567;&#35268;&#27169;Tr&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18724v1 Announce Type: cross  Abstract: This work focuses on the training dynamics of one associative memory module storing outer products of token embeddings. We reduce this problem to the study of a system of particles, which interact according to properties of the data distribution and correlations between embeddings. Through theory and experiments, we provide several insights. In overparameterized regimes, we obtain logarithmic growth of the ``classification margins.'' Yet, we show that imbalance in token frequencies and memory interferences due to correlated embeddings lead to oscillatory transitory regimes. The oscillations are more pronounced with large step sizes, which can create benign loss spikes, although these learning rates speed up the dynamics and accelerate the asymptotic convergence. In underparameterized regimes, we illustrate how the cross-entropy loss can lead to suboptimal memorization schemes. Finally, we assess the validity of our findings on small Tr
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#35782;&#21035;&#19968;&#20010;&#29983;&#25104;&#32593;&#32476;&#27169;&#22411;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#35774;&#32622;&#65292;IPF&#21487;&#20197;&#24674;&#22797;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65292;&#25581;&#31034;&#20102;&#20851;&#20110;&#22312;&#36825;&#31181;&#35774;&#32622;&#20013;&#20351;&#29992;IPF&#30340;&#38544;&#21547;&#20551;&#35774;&#65292;&#24182;&#21487;&#20197;&#20026;IPF&#30340;&#21442;&#25968;&#20272;&#35745;&#25552;&#20379;&#32467;&#26500;&#30456;&#20851;&#30340;&#35823;&#24046;&#30028;&#12290;</title><link>https://arxiv.org/abs/2402.18697</link><description>&lt;p&gt;
&#20174;&#36793;&#38469;&#25512;&#26029;&#21160;&#24577;&#32593;&#32476;&#30340;&#26041;&#27861;&#65306;&#36845;&#20195;&#27604;&#20363;&#25311;&#21512;
&lt;/p&gt;
&lt;p&gt;
Inferring Dynamic Networks from Marginals with Iterative Proportional Fitting
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18697
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#35782;&#21035;&#19968;&#20010;&#29983;&#25104;&#32593;&#32476;&#27169;&#22411;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#35774;&#32622;&#65292;IPF&#21487;&#20197;&#24674;&#22797;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65292;&#25581;&#31034;&#20102;&#20851;&#20110;&#22312;&#36825;&#31181;&#35774;&#32622;&#20013;&#20351;&#29992;IPF&#30340;&#38544;&#21547;&#20551;&#35774;&#65292;&#24182;&#21487;&#20197;&#20026;IPF&#30340;&#21442;&#25968;&#20272;&#35745;&#25552;&#20379;&#32467;&#26500;&#30456;&#20851;&#30340;&#35823;&#24046;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26469;&#33258;&#29616;&#23454;&#25968;&#25454;&#32422;&#26463;&#30340;&#24120;&#35265;&#32593;&#32476;&#25512;&#26029;&#38382;&#39064;&#26159;&#22914;&#20309;&#20174;&#26102;&#38388;&#32858;&#21512;&#30340;&#37051;&#25509;&#30697;&#38453;&#21644;&#26102;&#38388;&#21464;&#21270;&#36793;&#38469;&#65288;&#21363;&#34892;&#21521;&#37327;&#21644;&#21015;&#21521;&#37327;&#20043;&#21644;&#65289;&#25512;&#26029;&#21160;&#24577;&#32593;&#32476;&#12290;&#20808;&#21069;&#30340;&#26041;&#27861;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#37325;&#26032;&#21033;&#29992;&#20102;&#32463;&#20856;&#30340;&#36845;&#20195;&#27604;&#20363;&#25311;&#21512;&#65288;IPF&#65289;&#36807;&#31243;&#65292;&#20063;&#31216;&#20026;Sinkhorn&#31639;&#27861;&#65292;&#24182;&#21462;&#24471;&#20102;&#20196;&#20154;&#28385;&#24847;&#30340;&#32463;&#39564;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#20351;&#29992;IPF&#30340;&#32479;&#35745;&#22522;&#30784;&#23578;&#26410;&#24471;&#21040;&#24456;&#22909;&#30340;&#29702;&#35299;&#65306;&#22312;&#20160;&#20040;&#24773;&#20917;&#19979;&#65292;IPF&#25552;&#20379;&#20102;&#20174;&#36793;&#38469;&#20934;&#30830;&#20272;&#35745;&#21160;&#24577;&#32593;&#32476;&#30340;&#21407;&#21017;&#24615;&#65292;&#20197;&#21450;&#23427;&#22312;&#22810;&#22823;&#31243;&#24230;&#19978;&#20272;&#35745;&#20102;&#32593;&#32476;&#65311;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#36825;&#26679;&#19968;&#20010;&#35774;&#32622;&#65292;&#36890;&#36807;&#35782;&#21035;&#19968;&#20010;&#29983;&#25104;&#32593;&#32476;&#27169;&#22411;&#65292;IPF&#21487;&#20197;&#24674;&#22797;&#20854;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#25581;&#31034;&#20102;&#20851;&#20110;&#22312;&#36825;&#31181;&#35774;&#32622;&#20013;&#20351;&#29992;IPF&#30340;&#38544;&#21547;&#20551;&#35774;&#65292;&#24182;&#20351;&#24471;&#21487;&#20197;&#36827;&#34892;&#26032;&#30340;&#20998;&#26512;&#65292;&#22914;&#26377;&#20851;IPF&#21442;&#25968;&#20272;&#35745;&#30340;&#32467;&#26500;&#30456;&#20851;&#35823;&#24046;&#30028;&#12290;&#24403;IPF&#22833;&#36133;&#26102;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18697v1 Announce Type: cross  Abstract: A common network inference problem, arising from real-world data constraints, is how to infer a dynamic network from its time-aggregated adjacency matrix and time-varying marginals (i.e., row and column sums). Prior approaches to this problem have repurposed the classic iterative proportional fitting (IPF) procedure, also known as Sinkhorn's algorithm, with promising empirical results. However, the statistical foundation for using IPF has not been well understood: under what settings does IPF provide principled estimation of a dynamic network from its marginals, and how well does it estimate the network? In this work, we establish such a setting, by identifying a generative network model whose maximum likelihood estimates are recovered by IPF. Our model both reveals implicit assumptions on the use of IPF in such settings and enables new analyses, such as structure-dependent error bounds on IPF's parameter estimates. When IPF fails to c
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#26041;&#21521;&#20559;&#22909;&#23545;&#40784;&#65288;DPA&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#22810;&#30446;&#26631;&#22870;&#21169;&#27169;&#25311;&#19981;&#21516;&#20559;&#22909;&#37197;&#32622;&#65292;&#20197;&#23454;&#29616;&#29992;&#25143;&#30456;&#20851;&#30340;&#20559;&#22909;&#25511;&#21046;&#12290;</title><link>https://arxiv.org/abs/2402.18571</link><description>&lt;p&gt;
&#29992;&#20110;&#28385;&#36275;&#22810;&#26679;&#29992;&#25143;&#20559;&#22909;&#30340;&#31639;&#26415;&#25511;&#21046;LLMs&#65306;&#20855;&#26377;&#22810;&#30446;&#26631;&#22870;&#21169;&#30340;&#26041;&#21521;&#20559;&#22909;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Arithmetic Control of LLMs for Diverse User Preferences: Directional Preference Alignment with Multi-Objective Rewards
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18571
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#26041;&#21521;&#20559;&#22909;&#23545;&#40784;&#65288;DPA&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#22810;&#30446;&#26631;&#22870;&#21169;&#27169;&#25311;&#19981;&#21516;&#20559;&#22909;&#37197;&#32622;&#65292;&#20197;&#23454;&#29616;&#29992;&#25143;&#30456;&#20851;&#30340;&#20559;&#22909;&#25511;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#31934;&#32454;&#25511;&#21046;&#20173;&#28982;&#26159;&#19968;&#20010;&#37325;&#35201;&#25361;&#25112;&#65292;&#38459;&#30861;&#20102;&#23427;&#20204;&#36866;&#24212;&#21508;&#31181;&#29992;&#25143;&#38656;&#27714;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#26041;&#21521;&#20559;&#22909;&#23545;&#40784;&#65288;DPA&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#22810;&#30446;&#26631;&#22870;&#21169;&#24314;&#27169;&#26469;&#34920;&#31034;&#22810;&#26679;&#21270;&#30340;&#20559;&#22909;&#37197;&#32622;&#65292;&#23558;&#29992;&#25143;&#20559;&#22909;&#24314;&#27169;&#20026;&#22870;&#21169;&#31354;&#38388;&#20013;&#30340;&#26041;&#21521;&#65288;&#21363;&#21333;&#20301;&#21521;&#37327;&#65289;&#20197;&#23454;&#29616;&#29992;&#25143;&#30456;&#20851;&#30340;&#20559;&#22909;&#25511;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18571v1 Announce Type: cross  Abstract: Fine-grained control over large language models (LLMs) remains a significant challenge, hindering their adaptability to diverse user needs. While Reinforcement Learning from Human Feedback (RLHF) shows promise in aligning LLMs, its reliance on scalar rewards often limits its ability to capture diverse user preferences in real-world applications. To address this limitation, we introduce the Directional Preference Alignment (DPA) framework. Unlike the scalar-reward RLHF, DPA incorporates multi-objective reward modeling to represent diverse preference profiles. Additionally, DPA models user preferences as directions (i.e., unit vectors) in the reward space to achieve user-dependent preference control. Our method involves training a multi-objective reward model and then fine-tuning the LLM with a preference-conditioned variant of Rejection Sampling Finetuning (RSF), an RLHF method adopted by Llama 2. This method enjoys a better performance
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;RNNs&#21644;Transformer&#22312;&#22788;&#29702;&#31639;&#27861;&#38382;&#39064;&#26102;&#30340;&#34920;&#29616;&#33021;&#21147;&#24046;&#36317;&#65292;&#21457;&#29616;RNNs&#23384;&#22312;&#20851;&#38190;&#29942;&#39048;&#65292;&#21363;&#26080;&#27861;&#23436;&#32654;&#22320;&#20174;&#19978;&#19979;&#25991;&#20013;&#26816;&#32034;&#20449;&#24687;&#65292;&#23548;&#33268;&#26080;&#27861;&#20687;Transformer&#37027;&#26679;&#36731;&#26494;&#35299;&#20915;&#38656;&#35201;&#36825;&#31181;&#33021;&#21147;&#30340;&#20219;&#21153;&#12290;</title><link>https://arxiv.org/abs/2402.18510</link><description>&lt;p&gt;
RNNs&#36824;&#19981;&#26159;Transformer&#65306;&#22312;&#19978;&#19979;&#25991;&#26816;&#32034;&#20013;&#30340;&#20851;&#38190;&#29942;&#39048;
&lt;/p&gt;
&lt;p&gt;
RNNs are not Transformers (Yet): The Key Bottleneck on In-context Retrieval
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18510
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;RNNs&#21644;Transformer&#22312;&#22788;&#29702;&#31639;&#27861;&#38382;&#39064;&#26102;&#30340;&#34920;&#29616;&#33021;&#21147;&#24046;&#36317;&#65292;&#21457;&#29616;RNNs&#23384;&#22312;&#20851;&#38190;&#29942;&#39048;&#65292;&#21363;&#26080;&#27861;&#23436;&#32654;&#22320;&#20174;&#19978;&#19979;&#25991;&#20013;&#26816;&#32034;&#20449;&#24687;&#65292;&#23548;&#33268;&#26080;&#27861;&#20687;Transformer&#37027;&#26679;&#36731;&#26494;&#35299;&#20915;&#38656;&#35201;&#36825;&#31181;&#33021;&#21147;&#30340;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#65288;RNNs&#65289;&#21644;Transformer&#22312;&#35299;&#20915;&#31639;&#27861;&#38382;&#39064;&#26102;&#30340;&#34920;&#31034;&#33021;&#21147;&#24046;&#36317;&#12290;&#25105;&#20204;&#37325;&#28857;&#20851;&#27880;RNNs&#26159;&#21542;&#33021;&#22312;&#22788;&#29702;&#38271;&#24207;&#21015;&#26102;&#65292;&#36890;&#36807;Chain-of-Thought (CoT)&#25552;&#31034;&#65292;&#19982;Transformer&#30340;&#24615;&#33021;&#30456;&#21305;&#37197;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#26174;&#31034;CoT&#21487;&#20197;&#25913;&#36827;RNNs&#65292;&#20294;&#26080;&#27861;&#24357;&#34917;&#19982;Transformer&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#20851;&#38190;&#29942;&#39048;&#22312;&#20110;RNNs&#26080;&#27861;&#23436;&#20840;&#20174;&#19978;&#19979;&#25991;&#20013;&#26816;&#32034;&#20449;&#24687;&#65292;&#21363;&#20351;&#32463;&#36807;CoT&#30340;&#22686;&#24378;&#65306;&#23545;&#20110;&#20960;&#20010;&#26126;&#30830;&#25110;&#38544;&#24335;&#38656;&#35201;&#36825;&#31181;&#33021;&#21147;&#30340;&#20219;&#21153;&#65292;&#22914;&#32852;&#24819;&#21484;&#22238;&#21644;&#30830;&#23450;&#22270;&#26159;&#21542;&#20026;&#26641;&#65292;&#25105;&#20204;&#35777;&#26126;RNNs&#34920;&#36798;&#33021;&#21147;&#19981;&#36275;&#20197;&#35299;&#20915;&#36825;&#20123;&#20219;&#21153;&#65292;&#32780;Transformer&#21487;&#20197;&#36731;&#26494;&#35299;&#20915;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#35777;&#26126;&#37319;&#29992;&#22686;&#24378;RNNs&#19978;&#19979;&#25991;&#26816;&#32034;&#33021;&#21147;&#30340;&#25216;&#26415;&#65292;&#21253;&#25324;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18510v1 Announce Type: cross  Abstract: This paper investigates the gap in representation powers of Recurrent Neural Networks (RNNs) and Transformers in the context of solving algorithmic problems. We focus on understanding whether RNNs, known for their memory efficiency in handling long sequences, can match the performance of Transformers, particularly when enhanced with Chain-of-Thought (CoT) prompting. Our theoretical analysis reveals that CoT improves RNNs but is insufficient to close the gap with Transformers. A key bottleneck lies in the inability of RNNs to perfectly retrieve information from the context, even with CoT: for several tasks that explicitly or implicitly require this capability, such as associative recall and determining if a graph is a tree, we prove that RNNs are not expressive enough to solve the tasks while Transformers can solve them with ease. Conversely, we prove that adopting techniques to enhance the in-context retrieval capability of RNNs, inclu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21435;&#22122;&#25193;&#25955;&#36807;&#31243;&#30340;&#38646;&#38454;&#25193;&#25955;&#33945;&#29305;&#21345;&#27931;&#31639;&#27861;&#65292;&#20811;&#26381;&#20102;&#38750;&#23545;&#25968;&#20985;&#20998;&#24067;&#37319;&#26679;&#20013;&#30340;&#20122;&#31283;&#23450;&#24615;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20854;&#37319;&#26679;&#31934;&#24230;&#20855;&#26377;&#20498;&#22810;&#39033;&#24335;&#20381;&#36182;&#12290;</title><link>https://arxiv.org/abs/2402.17886</link><description>&lt;p&gt;
&#29992;&#20110;&#38750;&#23545;&#25968;&#20985;&#20998;&#24067;&#30340;&#38646;&#38454;&#37319;&#26679;&#26041;&#27861;&#65306;&#36890;&#36807;&#21435;&#22122;&#25193;&#25955;&#32531;&#35299;&#20122;&#31283;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
Zeroth-Order Sampling Methods for Non-Log-Concave Distributions: Alleviating Metastability by Denoising Diffusion
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17886
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21435;&#22122;&#25193;&#25955;&#36807;&#31243;&#30340;&#38646;&#38454;&#25193;&#25955;&#33945;&#29305;&#21345;&#27931;&#31639;&#27861;&#65292;&#20811;&#26381;&#20102;&#38750;&#23545;&#25968;&#20985;&#20998;&#24067;&#37319;&#26679;&#20013;&#30340;&#20122;&#31283;&#23450;&#24615;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20854;&#37319;&#26679;&#31934;&#24230;&#20855;&#26377;&#20498;&#22810;&#39033;&#24335;&#20381;&#36182;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#32771;&#34385;&#20102;&#22522;&#20110;&#20854;&#38750;&#23545;&#25968;&#20985;&#20998;&#24067;&#26410;&#24402;&#19968;&#21270;&#23494;&#24230;&#26597;&#35810;&#30340;&#37319;&#26679;&#38382;&#39064;&#12290;&#39318;&#20808;&#25551;&#36848;&#20102;&#19968;&#20010;&#22522;&#20110;&#27169;&#25311;&#21435;&#22122;&#25193;&#25955;&#36807;&#31243;&#30340;&#26694;&#26550;&#65292;&#21363;&#25193;&#25955;&#33945;&#29305;&#21345;&#27931;&#65288;DMC&#65289;&#65292;&#20854;&#24471;&#20998;&#20989;&#25968;&#36890;&#36807;&#36890;&#29992;&#33945;&#29305;&#21345;&#27931;&#20272;&#35745;&#22120;&#36924;&#36817;&#12290;DMC&#26159;&#19968;&#20010;&#22522;&#20110;&#31070;&#35861;&#30340;&#20803;&#31639;&#27861;&#65292;&#20854;&#20013;&#31070;&#35861;&#26159;&#20551;&#35774;&#21487;&#20197;&#35775;&#38382;&#29983;&#25104;&#33945;&#29305;&#21345;&#27931;&#20998;&#25968;&#20272;&#35745;&#22120;&#30340;&#26679;&#26412;&#30340;&#35775;&#38382;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#22522;&#20110;&#25298;&#32477;&#37319;&#26679;&#30340;&#36825;&#20010;&#31070;&#35861;&#30340;&#23454;&#29616;&#65292;&#36825;&#23558;DMC&#36716;&#21270;&#20026;&#19968;&#20010;&#30495;&#27491;&#30340;&#31639;&#27861;&#65292;&#31216;&#20026;&#38646;&#38454;&#25193;&#25955;&#33945;&#29305;&#21345;&#27931;&#65288;ZOD-MC&#65289;&#12290;&#25105;&#20204;&#36890;&#36807;&#39318;&#20808;&#26500;&#24314;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#21363;DMC&#30340;&#24615;&#33021;&#20445;&#35777;&#65292;&#32780;&#19981;&#20551;&#35774;&#30446;&#26631;&#20998;&#24067;&#20026;&#23545;&#25968;&#20985;&#25110;&#28385;&#36275;&#20219;&#20309;&#31561;&#21608;&#19981;&#31561;&#24335;&#65292;&#25552;&#20379;&#20102;&#25910;&#25947;&#20998;&#26512;&#12290;&#28982;&#21518;&#25105;&#20204;&#35777;&#26126;ZOD-MC&#23545;&#25152;&#38656;&#37319;&#26679;&#31934;&#24230;&#20855;&#26377;&#20498;&#22810;&#39033;&#24335;&#20381;&#36182;&#65292;&#23613;&#31649;&#20173;&#28982;&#21463;&#21040;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17886v1 Announce Type: cross  Abstract: This paper considers the problem of sampling from non-logconcave distribution, based on queries of its unnormalized density. It first describes a framework, Diffusion Monte Carlo (DMC), based on the simulation of a denoising diffusion process with its score function approximated by a generic Monte Carlo estimator. DMC is an oracle-based meta-algorithm, where its oracle is the assumed access to samples that generate a Monte Carlo score estimator. Then we provide an implementation of this oracle, based on rejection sampling, and this turns DMC into a true algorithm, termed Zeroth-Order Diffusion Monte Carlo (ZOD-MC). We provide convergence analyses by first constructing a general framework, i.e. a performance guarantee for DMC, without assuming the target distribution to be log-concave or satisfying any isoperimetric inequality. Then we prove that ZOD-MC admits an inverse polynomial dependence on the desired sampling accuracy, albeit sti
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#36923;&#36753;&#22238;&#24402;&#38382;&#39064;&#30340;&#31616;&#21333;&#38543;&#26426;&#25277;&#26679;&#31639;&#27861;&#65292;&#36890;&#36807;&#38543;&#26426;&#30697;&#38453;&#20056;&#27861;&#23454;&#29616;&#39640;&#36136;&#37327;&#36924;&#36817;&#20272;&#35745;&#27010;&#29575;&#21644;&#27169;&#22411;&#25972;&#20307;&#24046;&#24322;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.16326</link><description>&lt;p&gt;
&#36923;&#36753;&#22238;&#24402;&#30340;&#21487;&#35777;&#23454;&#20934;&#30830;&#24615;&#38543;&#26426;&#25277;&#26679;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Provably Accurate Randomized Sampling Algorithm for Logistic Regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.16326
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36923;&#36753;&#22238;&#24402;&#38382;&#39064;&#30340;&#31616;&#21333;&#38543;&#26426;&#25277;&#26679;&#31639;&#27861;&#65292;&#36890;&#36807;&#38543;&#26426;&#30697;&#38453;&#20056;&#27861;&#23454;&#29616;&#39640;&#36136;&#37327;&#36924;&#36817;&#20272;&#35745;&#27010;&#29575;&#21644;&#27169;&#22411;&#25972;&#20307;&#24046;&#24322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#36923;&#36753;&#22238;&#24402;&#26159;&#19968;&#31181;&#24191;&#27867;&#24212;&#29992;&#20110;&#20108;&#20998;&#31867;&#20219;&#21153;&#30340;&#30417;&#30563;&#23398;&#20064;&#25216;&#26415;&#12290;&#24403;&#35266;&#27979;&#25968;&#37327;&#36828;&#36828;&#36229;&#36807;&#39044;&#27979;&#21464;&#37327;&#25968;&#37327;&#26102;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#22522;&#20110;&#38543;&#26426;&#25277;&#26679;&#30340;&#36923;&#36753;&#22238;&#24402;&#38382;&#39064;&#31639;&#27861;&#65292;&#20445;&#35777;&#39640;&#36136;&#37327;&#36924;&#36817;&#20272;&#35745;&#27010;&#29575;&#21644;&#27169;&#22411;&#25972;&#20307;&#24046;&#24322;&#24615;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#24314;&#31435;&#22312;&#20004;&#20010;&#31616;&#21333;&#30340;&#32467;&#26500;&#26465;&#20214;&#22522;&#30784;&#19978;&#65292;&#36825;&#20004;&#20010;&#26465;&#20214;&#21487;&#24402;&#32467;&#20026;&#38543;&#26426;&#30697;&#38453;&#20056;&#27861;&#65292;&#26159;&#38543;&#26426;&#21270;&#25968;&#20540;&#32447;&#24615;&#20195;&#25968;&#30340;&#22522;&#26412;&#19988;&#28145;&#20837;&#29702;&#35299;&#30340;&#22522;&#20803;&#12290;&#24403;&#21033;&#29992;&#26464;&#26438;&#20998;&#25968;&#23545;&#35266;&#27979;&#36827;&#34892;&#25277;&#26679;&#26102;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#36923;&#36753;&#22238;&#24402;&#30340;&#20272;&#35745;&#27010;&#29575;&#23646;&#24615;&#65292;&#24182;&#35777;&#26126;&#20934;&#30830;&#36924;&#36817;&#21487;&#20197;&#36890;&#36807;&#36828;&#23567;&#20110;&#24635;&#35266;&#27979;&#25968;&#30340;&#26679;&#26412;&#23454;&#29616;&#12290;&#20026;&#20102;&#36827;&#19968;&#27493;&#39564;&#35777;&#25105;&#20204;&#30340;&#29702;&#35770;&#21457;&#29616;&#65292;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.16326v1 Announce Type: cross  Abstract: In statistics and machine learning, logistic regression is a widely-used supervised learning technique primarily employed for binary classification tasks. When the number of observations greatly exceeds the number of predictor variables, we present a simple, randomized sampling-based algorithm for logistic regression problem that guarantees high-quality approximations to both the estimated probabilities and the overall discrepancy of the model. Our analysis builds upon two simple structural conditions that boil down to randomized matrix multiplication, a fundamental and well-understood primitive of randomized numerical linear algebra. We analyze the properties of estimated probabilities of logistic regression when leverage scores are used to sample observations, and prove that accurate approximations can be achieved with a sample whose size is much smaller than the total number of observations. To further validate our theoretical findi
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;ISAHP&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#65292;&#21487;&#20197;&#20174;&#24322;&#27493;&#12289;&#30456;&#20114;&#20381;&#36182;&#30340;&#22810;&#31867;&#22411;&#20107;&#20214;&#24207;&#21015;&#20013;&#26080;&#30417;&#30563;&#22320;&#23398;&#20064;&#23454;&#20363;&#32423;&#30340;&#26684;&#20848;&#26480;&#22240;&#26524;&#20851;&#31995;&#12290;&#23427;&#26159;&#31532;&#19968;&#20010;&#28385;&#36275;&#26684;&#20848;&#26480;&#22240;&#26524;&#20851;&#31995;&#35201;&#27714;&#30340;&#31070;&#32463;&#28857;&#36807;&#31243;&#27169;&#22411;&#65292;&#24182;&#21033;&#29992;&#21464;&#21387;&#22120;&#30340;&#33258;&#25105;&#27880;&#24847;&#26426;&#21046;&#26469;&#23454;&#29616;&#26684;&#20848;&#26480;&#22240;&#26524;&#20851;&#31995;&#30340;&#25512;&#26029;&#12290;</title><link>https://arxiv.org/abs/2402.03726</link><description>&lt;p&gt;
&#20174;&#23454;&#20363;&#32423;&#30340;&#33258;&#25105;&#27880;&#24847;&#21147;Hawkes&#36807;&#31243;&#20013;&#23398;&#20064;&#26684;&#20848;&#26480;&#22240;&#26524;&#20851;&#31995;
&lt;/p&gt;
&lt;p&gt;
Learning Granger Causality from Instance-wise Self-attentive Hawkes Processes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03726
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;ISAHP&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#65292;&#21487;&#20197;&#20174;&#24322;&#27493;&#12289;&#30456;&#20114;&#20381;&#36182;&#30340;&#22810;&#31867;&#22411;&#20107;&#20214;&#24207;&#21015;&#20013;&#26080;&#30417;&#30563;&#22320;&#23398;&#20064;&#23454;&#20363;&#32423;&#30340;&#26684;&#20848;&#26480;&#22240;&#26524;&#20851;&#31995;&#12290;&#23427;&#26159;&#31532;&#19968;&#20010;&#28385;&#36275;&#26684;&#20848;&#26480;&#22240;&#26524;&#20851;&#31995;&#35201;&#27714;&#30340;&#31070;&#32463;&#28857;&#36807;&#31243;&#27169;&#22411;&#65292;&#24182;&#21033;&#29992;&#21464;&#21387;&#22120;&#30340;&#33258;&#25105;&#27880;&#24847;&#26426;&#21046;&#26469;&#23454;&#29616;&#26684;&#20848;&#26480;&#22240;&#26524;&#20851;&#31995;&#30340;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35299;&#20915;&#20102;&#20174;&#24322;&#27493;&#12289;&#30456;&#20114;&#20381;&#36182;&#30340;&#22810;&#31867;&#22411;&#20107;&#20214;&#24207;&#21015;&#20013;&#23398;&#20064;&#26684;&#20848;&#26480;&#22240;&#26524;&#20851;&#31995;&#30340;&#38382;&#39064;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#23545;&#20197;&#26080;&#30417;&#30563;&#30340;&#26041;&#24335;&#21457;&#29616;&#23454;&#20363;&#32423;&#30340;&#22240;&#26524;&#32467;&#26500;&#24863;&#20852;&#36259;&#12290;&#23454;&#20363;&#32423;&#22240;&#26524;&#20851;&#31995;&#35782;&#21035;&#21333;&#20010;&#20107;&#20214;&#20043;&#38388;&#30340;&#22240;&#26524;&#20851;&#31995;&#65292;&#20026;&#20915;&#31574;&#25552;&#20379;&#20102;&#26356;&#31934;&#32454;&#21270;&#30340;&#20449;&#24687;&#12290;&#29616;&#26377;&#25991;&#29486;&#20013;&#30340;&#24037;&#20316;&#35201;&#20040;&#38656;&#35201;&#24378;&#21152;&#19968;&#20123;&#20551;&#35774;&#65292;&#27604;&#22914;&#24378;&#21152;&#21040;&#24378;&#24230;&#20989;&#25968;&#20013;&#30340;&#32447;&#24615;&#20551;&#35774;&#65292;&#35201;&#20040;&#21551;&#21457;&#24335;&#22320;&#23450;&#20041;&#27169;&#22411;&#21442;&#25968;&#65292;&#36825;&#20123;&#19981;&#19968;&#23450;&#28385;&#36275;&#26684;&#20848;&#26480;&#22240;&#26524;&#20851;&#31995;&#30340;&#35201;&#27714;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#65292;&#21363;&#23454;&#20363;&#32423;&#33258;&#25105;&#27880;&#24847;&#21147;Hawkes&#36807;&#31243;&#65288;ISAHP&#65289;&#65292;&#21487;&#20197;&#30452;&#25509;&#25512;&#26029;&#20107;&#20214;&#23454;&#20363;&#32423;&#30340;&#26684;&#20848;&#26480;&#22240;&#26524;&#20851;&#31995;&#12290;ISAHP&#26159;&#31532;&#19968;&#20010;&#28385;&#36275;&#26684;&#20848;&#26480;&#22240;&#26524;&#20851;&#31995;&#35201;&#27714;&#30340;&#31070;&#32463;&#28857;&#36807;&#31243;&#27169;&#22411;&#12290;&#23427;&#21033;&#29992;&#20102;&#21464;&#21387;&#22120;&#30340;&#33258;&#25105;&#27880;&#24847;&#26426;&#21046;&#65292;&#19982;&#26684;&#20848;&#26480;&#22240;&#26524;&#20851;&#31995;&#30340;&#21407;&#29702;&#30456;&#19968;&#33268;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;ISAHP&#30340;&#26377;&#25928;&#24615;&#21644;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We address the problem of learning Granger causality from asynchronous, interdependent, multi-type event sequences. In particular, we are interested in discovering instance-level causal structures in an unsupervised manner. Instance-level causality identifies causal relationships among individual events, providing more fine-grained information for decision-making. Existing work in the literature either requires strong assumptions, such as linearity in the intensity function, or heuristically defined model parameters that do not necessarily meet the requirements of Granger causality. We propose Instance-wise Self-Attentive Hawkes Processes (ISAHP), a novel deep learning framework that can directly infer the Granger causality at the event instance level. ISAHP is the first neural point process model that meets the requirements of Granger causality. It leverages the self-attention mechanism of the transformer to align with the principles of Granger causality. We empirically demonstrate th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#26816;&#27979;&#21307;&#30103;AI&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#20013;&#30340;&#31639;&#27861;&#20559;&#20506;&#65292;&#36890;&#36807;&#37319;&#29992;CART&#31639;&#27861;&#26377;&#25928;&#22320;&#35782;&#21035;&#21307;&#30103;AI&#27169;&#22411;&#20013;&#30340;&#28508;&#22312;&#20559;&#20506;&#65292;&#24182;&#22312;&#21512;&#25104;&#25968;&#25454;&#23454;&#39564;&#21644;&#30495;&#23454;&#20020;&#24202;&#29615;&#22659;&#20013;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>https://arxiv.org/abs/2312.02959</link><description>&lt;p&gt;
&#22312;&#21307;&#30103;AI&#27169;&#22411;&#20013;&#26816;&#27979;&#31639;&#27861;&#20559;&#20506;
&lt;/p&gt;
&lt;p&gt;
Detecting algorithmic bias in medical AI-models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.02959
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#26816;&#27979;&#21307;&#30103;AI&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#20013;&#30340;&#31639;&#27861;&#20559;&#20506;&#65292;&#36890;&#36807;&#37319;&#29992;CART&#31639;&#27861;&#26377;&#25928;&#22320;&#35782;&#21035;&#21307;&#30103;AI&#27169;&#22411;&#20013;&#30340;&#28508;&#22312;&#20559;&#20506;&#65292;&#24182;&#22312;&#21512;&#25104;&#25968;&#25454;&#23454;&#39564;&#21644;&#30495;&#23454;&#20020;&#24202;&#29615;&#22659;&#20013;&#39564;&#35777;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#26426;&#22120;&#23398;&#20064;&#21644;&#20154;&#24037;&#26234;&#33021;&#21307;&#30103;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#26085;&#30410;&#26222;&#21450;&#65292;&#30830;&#20445;&#36825;&#20123;&#31995;&#32479;&#20197;&#20844;&#24179;&#12289;&#20844;&#27491;&#30340;&#26041;&#24335;&#25552;&#20379;&#24739;&#32773;&#32467;&#26524;&#21464;&#24471;&#21516;&#26679;&#37325;&#35201;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#26816;&#27979;&#21307;&#30103;AI&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#20013;&#30340;&#31639;&#27861;&#20559;&#20506;&#21306;&#22495;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#37319;&#29992;&#20998;&#31867;&#19982;&#22238;&#24402;&#26641;&#65288;CART&#65289;&#31639;&#27861;&#65292;&#22312;&#33043;&#27602;&#30151;&#39044;&#27979;&#32972;&#26223;&#19979;&#26377;&#25928;&#22320;&#35782;&#21035;&#21307;&#30103;AI&#27169;&#22411;&#20013;&#30340;&#28508;&#22312;&#20559;&#20506;&#12290;&#25105;&#20204;&#36890;&#36807;&#36827;&#34892;&#19968;&#31995;&#21015;&#21512;&#25104;&#25968;&#25454;&#23454;&#39564;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#23637;&#31034;&#20102;&#20854;&#22312;&#21463;&#25511;&#29615;&#22659;&#20013;&#20934;&#30830;&#20272;&#35745;&#20559;&#20506;&#21306;&#22495;&#30340;&#33021;&#21147;&#12290;&#36825;&#19968;&#27010;&#24565;&#30340;&#26377;&#25928;&#24615;&#36890;&#36807;&#20351;&#29992;&#20122;&#29305;&#20848;&#22823;&#20052;&#27835;&#20122;&#24030;&#26684;&#38647;&#36842;&#32426;&#24565;&#21307;&#38498;&#30340;&#30005;&#23376;&#30149;&#21382;&#36827;&#34892;&#23454;&#39564;&#36827;&#19968;&#27493;&#24471;&#21040;&#39564;&#35777;&#12290;&#36825;&#20123;&#27979;&#35797;&#23637;&#31034;&#20102;&#25105;&#20204;&#31574;&#30053;&#22312;&#20020;&#24202;&#20013;&#30340;&#23454;&#38469;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.02959v3 Announce Type: replace-cross  Abstract: With the growing prevalence of machine learning and artificial intelligence-based medical decision support systems, it is equally important to ensure that these systems provide patient outcomes in a fair and equitable fashion. This paper presents an innovative framework for detecting areas of algorithmic bias in medical-AI decision support systems. Our approach efficiently identifies potential biases in medical-AI models, specifically in the context of sepsis prediction, by employing the Classification and Regression Trees (CART) algorithm. We verify our methodology by conducting a series of synthetic data experiments, showcasing its ability to estimate areas of bias in controlled settings precisely. The effectiveness of the concept is further validated by experiments using electronic medical records from Grady Memorial Hospital in Atlanta, Georgia. These tests demonstrate the practical implementation of our strategy in a clini
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#26102;&#38388;&#22343;&#21248;&#32622;&#20449;&#29699;&#24207;&#21015;&#65292;&#21487;&#20197;&#21516;&#26102;&#39640;&#27010;&#29575;&#22320;&#21253;&#21547;&#21508;&#31181;&#26679;&#26412;&#37327;&#19979;&#38543;&#26426;&#21521;&#37327;&#30340;&#22343;&#20540;&#65292;&#24182;&#38024;&#23545;&#19981;&#21516;&#20998;&#24067;&#20551;&#35774;&#36827;&#34892;&#20102;&#25193;&#23637;&#21644;&#32479;&#19968;&#20998;&#26512;&#12290;</title><link>https://arxiv.org/abs/2311.08168</link><description>&lt;p&gt;
&#38543;&#26426;&#21521;&#37327;&#22343;&#20540;&#30340;&#26102;&#38388;&#22343;&#21248;&#32622;&#20449;&#29699;
&lt;/p&gt;
&lt;p&gt;
Time-Uniform Confidence Spheres for Means of Random Vectors
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.08168
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#26102;&#38388;&#22343;&#21248;&#32622;&#20449;&#29699;&#24207;&#21015;&#65292;&#21487;&#20197;&#21516;&#26102;&#39640;&#27010;&#29575;&#22320;&#21253;&#21547;&#21508;&#31181;&#26679;&#26412;&#37327;&#19979;&#38543;&#26426;&#21521;&#37327;&#30340;&#22343;&#20540;&#65292;&#24182;&#38024;&#23545;&#19981;&#21516;&#20998;&#24067;&#20551;&#35774;&#36827;&#34892;&#20102;&#25193;&#23637;&#21644;&#32479;&#19968;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25512;&#23548;&#24182;&#30740;&#31350;&#20102;&#26102;&#38388;&#22343;&#21248;&#32622;&#20449;&#29699;&#8212;&#8212;&#21253;&#21547;&#38543;&#26426;&#21521;&#37327;&#22343;&#20540;&#24182;&#19988;&#36328;&#36234;&#25152;&#26377;&#26679;&#26412;&#37327;&#20855;&#26377;&#24456;&#39640;&#27010;&#29575;&#30340;&#32622;&#20449;&#29699;&#24207;&#21015;&#65288;CSSs&#65289;&#12290;&#21463;Catoni&#21644;Giulini&#21407;&#22987;&#24037;&#20316;&#21551;&#21457;&#65292;&#25105;&#20204;&#32479;&#19968;&#24182;&#25193;&#23637;&#20102;&#20182;&#20204;&#30340;&#20998;&#26512;&#65292;&#28085;&#30422;&#39034;&#24207;&#35774;&#32622;&#24182;&#22788;&#29702;&#21508;&#31181;&#20998;&#24067;&#20551;&#35774;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#21253;&#25324;&#26377;&#30028;&#38543;&#26426;&#21521;&#37327;&#30340;&#32463;&#39564;&#20271;&#24681;&#26031;&#22374;CSS&#65288;&#23548;&#33268;&#26032;&#39062;&#30340;&#32463;&#39564;&#20271;&#24681;&#26031;&#22374;&#32622;&#20449;&#21306;&#38388;&#65292;&#28176;&#36817;&#23485;&#24230;&#25353;&#29031;&#30495;&#23454;&#26410;&#30693;&#26041;&#24046;&#25104;&#27604;&#20363;&#32553;&#25918;&#65289;&#12289;&#29992;&#20110;&#23376;-$\psi$&#38543;&#26426;&#21521;&#37327;&#30340;CSS&#65288;&#21253;&#25324;&#23376;&#20285;&#39532;&#12289;&#23376;&#27850;&#26494;&#21644;&#23376;&#25351;&#25968;&#20998;&#24067;&#65289;&#12289;&#21644;&#29992;&#20110;&#37325;&#23614;&#38543;&#26426;&#21521;&#37327;&#65288;&#20165;&#26377;&#20004;&#38454;&#30697;&#65289;&#30340;CSS&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20004;&#20010;&#25269;&#25239;Huber&#22122;&#22768;&#27745;&#26579;&#30340;CSS&#12290;&#31532;&#19968;&#20010;&#26159;&#25105;&#20204;&#32463;&#39564;&#20271;&#24681;&#26031;&#22374;CSS&#30340;&#40065;&#26834;&#29256;&#26412;&#65292;&#31532;&#20108;&#20010;&#25193;&#23637;&#20102;&#21333;&#21464;&#37327;&#24207;&#21015;&#26368;&#36817;&#30340;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.08168v2 Announce Type: replace-cross  Abstract: We derive and study time-uniform confidence spheres -- confidence sphere sequences (CSSs) -- which contain the mean of random vectors with high probability simultaneously across all sample sizes. Inspired by the original work of Catoni and Giulini, we unify and extend their analysis to cover both the sequential setting and to handle a variety of distributional assumptions. Our results include an empirical-Bernstein CSS for bounded random vectors (resulting in a novel empirical-Bernstein confidence interval with asymptotic width scaling proportionally to the true unknown variance), CSSs for sub-$\psi$ random vectors (which includes sub-gamma, sub-Poisson, and sub-exponential), and CSSs for heavy-tailed random vectors (two moments only). Finally, we provide two CSSs that are robust to contamination by Huber noise. The first is a robust version of our empirical-Bernstein CSS, and the second extends recent work in the univariate se
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#40065;&#26834;Wasserstein&#36317;&#31163;&#22788;&#29702;&#36755;&#36816;&#38382;&#39064;&#65292;&#25506;&#35752;&#20102;&#19982;$W_1$&#30340;&#20851;&#32852;&#65292;&#25512;&#23548;&#20102;&#38598;&#20013;&#19981;&#31561;&#24335;&#65292;&#24182;&#25552;&#20986;&#26368;&#23567;&#36317;&#31163;&#20272;&#35745;&#22120;&#20197;&#21450;&#20854;&#32479;&#35745;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2301.06297</link><description>&lt;p&gt;
&#32463;&#36807;&#40065;&#26834;&#20248;&#21270;&#36755;&#36816;&#30340;&#25512;&#26029;&#65306;&#29702;&#35770;&#19982;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Inference via robust optimal transportation: theory and methods
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2301.06297
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#40065;&#26834;Wasserstein&#36317;&#31163;&#22788;&#29702;&#36755;&#36816;&#38382;&#39064;&#65292;&#25506;&#35752;&#20102;&#19982;$W_1$&#30340;&#20851;&#32852;&#65292;&#25512;&#23548;&#20102;&#38598;&#20013;&#19981;&#31561;&#24335;&#65292;&#24182;&#25552;&#20986;&#26368;&#23567;&#36317;&#31163;&#20272;&#35745;&#22120;&#20197;&#21450;&#20854;&#32479;&#35745;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#20248;&#36755;&#36816;&#29702;&#35770;&#21450;&#30456;&#20851;&#30340;$p$-Wasserstein&#36317;&#31163;&#65288;$W_p$&#65292;$p\geq 1$&#65289;&#22312;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#34987;&#24191;&#27867;&#24212;&#29992;&#12290;&#23613;&#31649;&#23427;&#20204;&#24456;&#21463;&#27426;&#36814;&#65292;&#20294;&#22522;&#20110;&#36825;&#20123;&#24037;&#20855;&#30340;&#25512;&#26029;&#23384;&#22312;&#19968;&#20123;&#38382;&#39064;&#12290; &#20026;&#20102;&#24212;&#23545;&#36825;&#20123;&#38382;&#39064;&#65292;&#39318;&#20808;&#25105;&#20204;&#32771;&#34385;&#20102;&#21407;&#22987;&#36755;&#36816;&#38382;&#39064;&#30340;&#40065;&#26834;&#29256;&#26412;&#65292;&#24182;&#23637;&#31034;&#20854;&#23450;&#20041;&#20102;&#20381;&#36182;&#20110;&#35843;&#33410;&#21442;&#25968;$\lambda &gt; 0$&#30340;{&#40065;&#26834;Wasserstein&#36317;&#31163;}&#65292;$W^{(\lambda)}$&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;$W_1$&#21644;$W^{(\lambda)}$&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#24182;&#30740;&#31350;&#20102;&#20854;&#20851;&#38190;&#30340;&#27979;&#24230;&#35770;&#26041;&#38754;&#12290;&#31532;&#19977;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;$W^{(\lambda)}$&#30340;&#19968;&#20123;&#38598;&#20013;&#19981;&#31561;&#24335;&#12290;&#31532;&#22235;&#65292;&#25105;&#20204;&#21033;&#29992;$W^{(\lambda)}$&#23450;&#20041;&#20102;&#26368;&#23567;&#36317;&#31163;&#20272;&#35745;&#22120;&#65292;&#25552;&#20379;&#20102;&#23427;&#20204;&#30340;&#32479;&#35745;&#20445;&#35777;&#65292;&#24182;&#35828;&#26126;&#20102;&#22914;&#20309;&#24212;&#29992;&#25152;&#25512;&#23548;&#30340;&#38598;&#20013;&#19981;&#31561;&#24335;&#21040;&#25968;&#25454;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2301.06297v4 Announce Type: replace-cross  Abstract: Optimal transportation theory and the related $p$-Wasserstein distance ($W_p$, $p\geq 1$) are widely-applied in statistics and machine learning. In spite of their popularity, inference based on these tools has some issues. For instance, it is sensitive to outliers and it may not be even defined when the underlying model has infinite moments. To cope with these problems, first we consider a robust version of the primal transportation problem and show that it defines the {robust Wasserstein distance}, $W^{(\lambda)}$, depending on a tuning parameter $\lambda &gt; 0$. Second, we illustrate the link between $W_1$ and $W^{(\lambda)}$ and study its key measure theoretic aspects. Third, we derive some concentration inequalities for $W^{(\lambda)}$. Fourth, we use $W^{(\lambda)}$ to define minimum distance estimators, we provide their statistical guarantees and we illustrate how to apply the derived concentration inequalities for a data d
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#31070;&#32463;Galerkin&#26041;&#26696;&#32467;&#21512;&#28145;&#24230;&#23398;&#20064;&#21644;&#20027;&#21160;&#23398;&#20064;&#65292;&#33021;&#22815;&#33258;&#20027;&#29983;&#25104;&#35757;&#32451;&#25968;&#25454;&#29992;&#20110;&#39640;&#32500;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#25968;&#20540;&#27714;&#35299;</title><link>https://arxiv.org/abs/2203.01360</link><description>&lt;p&gt;
&#20855;&#26377;&#20027;&#21160;&#23398;&#20064;&#30340;&#31070;&#32463;Galerkin&#26041;&#26696;&#29992;&#20110;&#39640;&#32500;&#28436;&#21270;&#26041;&#31243;
&lt;/p&gt;
&lt;p&gt;
Neural Galerkin Schemes with Active Learning for High-Dimensional Evolution Equations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2203.01360
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#31070;&#32463;Galerkin&#26041;&#26696;&#32467;&#21512;&#28145;&#24230;&#23398;&#20064;&#21644;&#20027;&#21160;&#23398;&#20064;&#65292;&#33021;&#22815;&#33258;&#20027;&#29983;&#25104;&#35757;&#32451;&#25968;&#25454;&#29992;&#20110;&#39640;&#32500;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#25968;&#20540;&#27714;&#35299;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#24050;&#34987;&#35777;&#26126;&#33021;&#22815;&#22312;&#39640;&#32500;&#24230;&#20013;&#25552;&#20379;&#20934;&#30830;&#30340;&#20989;&#25968;&#36924;&#36817;&#12290;&#28982;&#32780;&#65292;&#25311;&#21512;&#32593;&#32476;&#21442;&#25968;&#38656;&#35201;&#20449;&#24687;&#20016;&#23500;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#22312;&#31185;&#23398;&#21644;&#24037;&#31243;&#24212;&#29992;&#20013;&#24448;&#24448;&#38590;&#20197;&#25910;&#38598;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#31070;&#32463;Galerkin&#26041;&#26696;&#65292;&#36890;&#36807;&#20027;&#21160;&#23398;&#20064;&#29983;&#25104;&#35757;&#32451;&#25968;&#25454;&#65292;&#29992;&#20110;&#25968;&#20540;&#27714;&#35299;&#39640;&#32500;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#31070;&#32463;Galerkin&#26041;&#26696;&#22522;&#20110;Dirac-Frenkel&#21464;&#20998;&#21407;&#29702;&#65292;&#36890;&#36807;&#38543;&#26102;&#38388;&#39034;&#24207;&#26368;&#23567;&#21270;&#27531;&#24046;&#26469;&#35757;&#32451;&#32593;&#32476;&#65292;&#36825;&#20351;&#24471;&#33021;&#22815;&#20197;&#33258;&#20027;&#12289;&#21160;&#24577;&#25551;&#36848;&#30340;&#26041;&#24335;&#25910;&#38598;&#26032;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#20197;&#25351;&#23548;&#20559;&#24494;&#20998;&#26041;&#31243;&#25551;&#36848;&#30340;&#21160;&#24577;&#12290;&#36825;&#19982;&#20854;&#20182;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#24418;&#25104;&#23545;&#27604;&#65292;&#20854;&#20182;&#26041;&#27861;&#26088;&#22312;&#20840;&#23616;&#26102;&#38388;&#20869;&#25311;&#21512;&#32593;&#32476;&#21442;&#25968;&#65292;&#32780;&#19981;&#32771;&#34385;&#35757;&#32451;&#25968;&#25454;&#33719;&#21462;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#26159;&#20027;&#21160;&#24418;&#24335;&#30340;
&lt;/p&gt;
&lt;p&gt;
arXiv:2203.01360v4 Announce Type: replace-cross  Abstract: Deep neural networks have been shown to provide accurate function approximations in high dimensions. However, fitting network parameters requires informative training data that are often challenging to collect in science and engineering applications. This work proposes Neural Galerkin schemes based on deep learning that generate training data with active learning for numerically solving high-dimensional partial differential equations. Neural Galerkin schemes build on the Dirac-Frenkel variational principle to train networks by minimizing the residual sequentially over time, which enables adaptively collecting new training data in a self-informed manner that is guided by the dynamics described by the partial differential equations. This is in contrast to other machine learning methods that aim to fit network parameters globally in time without taking into account training data acquisition. Our finding is that the active form of 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#31163;&#32447;&#26041;&#27861;&#29992;&#20110;&#26816;&#27979;&#22270;&#20449;&#21495;&#20013;&#22343;&#20540;&#21464;&#21270;&#28857;&#65292;&#36890;&#36807;&#22312;&#39057;&#35889;&#22495;&#35299;&#20915;&#38382;&#39064;&#65292;&#20805;&#20998;&#21033;&#29992;&#20102;&#31232;&#30095;&#24615;&#65292;&#37319;&#29992;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#33258;&#21160;&#30830;&#23450;&#21464;&#28857;&#30340;&#25968;&#37327;&#65292;&#24182;&#32473;&#20986;&#20102;&#38750;&#28176;&#36817;oracle&#19981;&#31561;&#24335;&#30340;&#35777;&#26126;&#12290;</title><link>https://arxiv.org/abs/2006.10628</link><description>&lt;p&gt;
&#31163;&#32447;&#26816;&#27979;&#24179;&#31283;&#22270;&#20449;&#21495;&#22343;&#20540;&#21464;&#21270;&#28857;
&lt;/p&gt;
&lt;p&gt;
Offline detection of change-points in the mean for stationary graph signals
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2006.10628
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#31163;&#32447;&#26041;&#27861;&#29992;&#20110;&#26816;&#27979;&#22270;&#20449;&#21495;&#20013;&#22343;&#20540;&#21464;&#21270;&#28857;&#65292;&#36890;&#36807;&#22312;&#39057;&#35889;&#22495;&#35299;&#20915;&#38382;&#39064;&#65292;&#20805;&#20998;&#21033;&#29992;&#20102;&#31232;&#30095;&#24615;&#65292;&#37319;&#29992;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#33258;&#21160;&#30830;&#23450;&#21464;&#28857;&#30340;&#25968;&#37327;&#65292;&#24182;&#32473;&#20986;&#20102;&#38750;&#28176;&#36817;oracle&#19981;&#31561;&#24335;&#30340;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#35299;&#20915;&#20102;&#22270;&#20449;&#21495;&#27969;&#20998;&#21106;&#30340;&#38382;&#39064;&#65306;&#25105;&#20204;&#26088;&#22312;&#26816;&#27979;&#24050;&#30693;&#22270;&#19978;&#30340;&#22810;&#21464;&#37327;&#20449;&#21495;&#22343;&#20540;&#21464;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31163;&#32447;&#26041;&#27861;&#65292;&#20381;&#36182;&#20110;&#22270;&#20449;&#21495;&#24179;&#31283;&#24615;&#30340;&#27010;&#24565;&#65292;&#24182;&#20801;&#35768;&#23558;&#38382;&#39064;&#20174;&#21407;&#22987;&#39030;&#28857;&#22495;&#36716;&#25442;&#21040;&#39057;&#35889;&#22495;&#65288;&#22270;&#20613;&#37324;&#21494;&#21464;&#25442;&#65289;&#65292;&#22312;&#37027;&#37324;&#26356;&#23481;&#26131;&#35299;&#20915;&#12290;&#34429;&#28982;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#33719;&#24471;&#30340;&#39057;&#35889;&#34920;&#31034;&#26159;&#31232;&#30095;&#30340;&#65292;&#20294;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#31181;&#29305;&#24615;&#22312;&#29616;&#26377;&#30456;&#20851;&#25991;&#29486;&#20013;&#23578;&#26410;&#24471;&#21040;&#20805;&#20998;&#21033;&#29992;&#12290;&#25105;&#20204;&#30340;&#21464;&#28857;&#26816;&#27979;&#26041;&#27861;&#37319;&#29992;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#32771;&#34385;&#20102;&#39057;&#35889;&#34920;&#31034;&#30340;&#31232;&#30095;&#24615;&#65292;&#24182;&#33258;&#21160;&#30830;&#23450;&#21464;&#28857;&#30340;&#25968;&#37327;&#12290;&#25105;&#20204;&#30340;&#26816;&#27979;&#22120;&#20276;&#38543;&#30528;&#38750;&#28176;&#36817;&#20248;&#31561;&#24615;&#30340;&#35777;&#26126;&#12290;&#25968;&#20540;&#23454;&#39564;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2006.10628v2 Announce Type: replace  Abstract: This paper addresses the problem of segmenting a stream of graph signals: we aim to detect changes in the mean of a multivariate signal defined over the nodes of a known graph. We propose an offline method that relies on the concept of graph signal stationarity and allows the convenient translation of the problem from the original vertex domain to the spectral domain (Graph Fourier Transform), where it is much easier to solve. Although the obtained spectral representation is sparse in real applications, to the best of our knowledge this property has not been sufficiently exploited in the existing related literature. Our change-point detection method adopts a model selection approach that takes into account the sparsity of the spectral representation and determines automatically the number of change-points. Our detector comes with a proof of a non-asymptotic oracle inequality. Numerical experiments demonstrate the performance of the p
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#23545;&#20110;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#22996;&#21592;&#20250;&#26426;&#22120;&#30340;&#20005;&#26684;&#29702;&#35770;&#22522;&#30784;&#21644;&#36817;&#20284;&#28040;&#24687;&#20256;&#36882;&#31639;&#27861;&#65292;&#25581;&#31034;&#20102;&#35745;&#31639;&#21040;&#32479;&#35745;&#23398;&#24046;&#36317;&#12290;</title><link>https://arxiv.org/abs/1806.05451</link><description>&lt;p&gt;
&#22996;&#21592;&#20250;&#26426;&#22120;&#65306;&#23398;&#20064;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#35745;&#31639;&#21040;&#32479;&#35745;&#23398;&#24046;&#36317;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
The committee machine: Computational to statistical gaps in learning a two-layers neural network
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/1806.05451
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#23545;&#20110;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#22996;&#21592;&#20250;&#26426;&#22120;&#30340;&#20005;&#26684;&#29702;&#35770;&#22522;&#30784;&#21644;&#36817;&#20284;&#28040;&#24687;&#20256;&#36882;&#31639;&#27861;&#65292;&#25581;&#31034;&#20102;&#35745;&#31639;&#21040;&#32479;&#35745;&#23398;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#21435;&#65292;&#32479;&#35745;&#29289;&#29702;&#23398;&#20013;&#30340;&#21551;&#21457;&#24335;&#24037;&#20855;&#34987;&#29992;&#26469;&#23450;&#20301;&#30456;&#21464;&#24182;&#35745;&#31639;&#22810;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#25945;&#24072;-&#23398;&#29983;&#22330;&#26223;&#20013;&#30340;&#26368;&#20248;&#23398;&#20064;&#21644;&#27867;&#21270;&#38169;&#35823;&#12290;&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#20026;&#19968;&#20010;&#21517;&#20026;&#22996;&#21592;&#20250;&#26426;&#22120;&#30340;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#25552;&#20379;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#20005;&#26684;&#29702;&#35770;&#22522;&#30784;&#12290;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#19968;&#20010;&#22996;&#21592;&#20250;&#26426;&#22120;&#30340;&#36817;&#20284;&#28040;&#24687;&#20256;&#36882;&#65288;AMP&#65289;&#31639;&#27861;&#29256;&#26412;&#65292;&#20801;&#35768;&#22312;&#22810;&#31181;&#21442;&#25968;&#19979;&#20197;&#22810;&#39033;&#24335;&#26102;&#38388;&#25191;&#34892;&#26368;&#20339;&#23398;&#20064;&#12290;&#25105;&#20204;&#21457;&#29616;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#34429;&#28982;AMP&#31639;&#27861;&#26080;&#27861;&#23454;&#29616;&#65292;&#20294;&#22312;&#20449;&#24687;&#29702;&#35770;&#19978;&#21487;&#20197;&#23454;&#29616;&#20302;&#27867;&#21270;&#38169;&#35823;&#29575;&#65292;&#36825;&#24378;&#28872;&#26263;&#31034;&#23545;&#20110;&#36825;&#20123;&#24773;&#20917;&#19981;&#23384;&#22312;&#26377;&#25928;&#31639;&#27861;&#65292;&#25581;&#31034;&#20102;&#19968;&#20010;&#24040;&#22823;&#30340;&#35745;&#31639;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:1806.05451v3 Announce Type: replace  Abstract: Heuristic tools from statistical physics have been used in the past to locate the phase transitions and compute the optimal learning and generalization errors in the teacher-student scenario in multi-layer neural networks. In this contribution, we provide a rigorous justification of these approaches for a two-layers neural network model called the committee machine. We also introduce a version of the approximate message passing (AMP) algorithm for the committee machine that allows to perform optimal learning in polynomial time for a large set of parameters. We find that there are regimes in which a low generalization error is information-theoretically achievable while the AMP algorithm fails to deliver it, strongly suggesting that no efficient algorithm exists for those cases, and unveiling a large computational gap.
&lt;/p&gt;</description></item><item><title>&#21327;&#20316;&#21644;&#21487;&#35299;&#37322;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26694;&#26550;(CoExBO)&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#24341;&#20837;&#20102;&#24490;&#29615;&#65292;&#24179;&#34913;&#20102;&#20154;&#24037;&#26234;&#33021;&#21644;&#20154;&#31867;&#30340;&#21512;&#20316;&#20851;&#31995;&#12290;&#23427;&#21033;&#29992;&#20559;&#22909;&#23398;&#20064;&#23558;&#29992;&#25143;&#35265;&#35299;&#34701;&#21512;&#21040;&#20248;&#21270;&#20013;&#65292;&#35299;&#37322;&#27599;&#27425;&#36845;&#20195;&#30340;&#20505;&#36873;&#36873;&#25321;&#65292;&#20174;&#32780;&#22686;&#24378;&#29992;&#25143;&#23545;&#20248;&#21270;&#36807;&#31243;&#30340;&#20449;&#20219;&#65292;&#24182;&#25552;&#20379;&#26080;&#23475;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2310.17273</link><description>&lt;p&gt;
&#23558;&#24490;&#29615;&#24341;&#20837;&#20154;&#31867;&#65306;&#21327;&#20316;&#21644;&#21487;&#35299;&#37322;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Looping in the Human: Collaborative and Explainable Bayesian Optimization. (arXiv:2310.17273v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17273
&lt;/p&gt;
&lt;p&gt;
&#21327;&#20316;&#21644;&#21487;&#35299;&#37322;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26694;&#26550;(CoExBO)&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#24341;&#20837;&#20102;&#24490;&#29615;&#65292;&#24179;&#34913;&#20102;&#20154;&#24037;&#26234;&#33021;&#21644;&#20154;&#31867;&#30340;&#21512;&#20316;&#20851;&#31995;&#12290;&#23427;&#21033;&#29992;&#20559;&#22909;&#23398;&#20064;&#23558;&#29992;&#25143;&#35265;&#35299;&#34701;&#21512;&#21040;&#20248;&#21270;&#20013;&#65292;&#35299;&#37322;&#27599;&#27425;&#36845;&#20195;&#30340;&#20505;&#36873;&#36873;&#25321;&#65292;&#20174;&#32780;&#22686;&#24378;&#29992;&#25143;&#23545;&#20248;&#21270;&#36807;&#31243;&#30340;&#20449;&#20219;&#65292;&#24182;&#25552;&#20379;&#26080;&#23475;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20687;&#35768;&#22810;&#20248;&#21270;&#22120;&#19968;&#26679;&#65292;&#36125;&#21494;&#26031;&#20248;&#21270;&#22312;&#33719;&#24471;&#29992;&#25143;&#20449;&#20219;&#26041;&#38754;&#24120;&#24120;&#23384;&#22312;&#19981;&#36275;&#65292;&#22240;&#20026;&#20854;&#19981;&#36879;&#26126;&#24615;&#12290;&#34429;&#28982;&#24050;&#32463;&#23581;&#35797;&#24320;&#21457;&#38754;&#21521;&#20154;&#31867;&#30340;&#20248;&#21270;&#22120;&#65292;&#20294;&#23427;&#20204;&#36890;&#24120;&#20551;&#35774;&#29992;&#25143;&#30693;&#35782;&#26159;&#26126;&#30830;&#19988;&#26080;&#35823;&#30340;&#65292;&#24182;&#20027;&#35201;&#23558;&#29992;&#25143;&#20316;&#20026;&#20248;&#21270;&#36807;&#31243;&#30340;&#30417;&#30563;&#32773;&#12290;&#25105;&#20204;&#25918;&#23485;&#20102;&#36825;&#20123;&#20551;&#35774;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#24179;&#34913;&#30340;&#20154;&#24037;&#26234;&#33021;&#21644;&#20154;&#31867;&#21512;&#20316;&#20249;&#20276;&#20851;&#31995;&#65292;&#21363;&#25105;&#20204;&#30340;&#21327;&#20316;&#21644;&#21487;&#35299;&#37322;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;CoExBO&#65289;&#26694;&#26550;&#12290;CoExBO&#20351;&#29992;&#20559;&#22909;&#23398;&#20064;&#26469;&#26080;&#32541;&#22320;&#23558;&#20154;&#31867;&#35265;&#35299;&#25972;&#21512;&#21040;&#20248;&#21270;&#20013;&#65292;&#20174;&#32780;&#20135;&#29983;&#19982;&#29992;&#25143;&#20351;&#29992;&#20559;&#22909;&#19968;&#33268;&#30340;&#31639;&#27861;&#24314;&#35758;&#12290;CoExBO&#35299;&#37322;&#20854;&#27599;&#27425;&#36845;&#20195;&#30340;&#20505;&#36873;&#36873;&#25321;&#65292;&#20197;&#22521;&#20859;&#20449;&#20219;&#65292;&#20351;&#29992;&#25143;&#26356;&#28165;&#26970;&#22320;&#25484;&#25569;&#20248;&#21270;&#30340;&#36807;&#31243;&#12290;&#27492;&#22806;&#65292;CoExBO&#25552;&#20379;&#26080;&#23475;&#20445;&#35777;&#65292;&#20801;&#35768;&#29992;&#25143;&#29359;&#38169;&#35823;&#65307;&#21363;&#20351;&#22312;&#26497;&#31471;&#23545;&#25239;&#24615;&#24178;&#25200;&#19979;&#65292;&#31639;&#27861;&#20063;&#20250;&#28176;&#36827;&#22320;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;
Like many optimizers, Bayesian optimization often falls short of gaining user trust due to opacity. While attempts have been made to develop human-centric optimizers, they typically assume user knowledge is well-specified and error-free, employing users mainly as supervisors of the optimization process. We relax these assumptions and propose a more balanced human-AI partnership with our Collaborative and Explainable Bayesian Optimization (CoExBO) framework. Instead of explicitly requiring a user to provide a knowledge model, CoExBO employs preference learning to seamlessly integrate human insights into the optimization, resulting in algorithmic suggestions that resonate with user preference. CoExBO explains its candidate selection every iteration to foster trust, empowering users with a clearer grasp of the optimization. Furthermore, CoExBO offers a no-harm guarantee, allowing users to make mistakes; even with extreme adversarial interventions, the algorithm converges asymptotically to
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;EDAIn&#30340;&#25193;&#23637;&#28145;&#24230;&#33258;&#36866;&#24212;&#36755;&#20837;&#35268;&#33539;&#21270;&#23618;&#65292;&#36890;&#36807;&#20197;&#31471;&#21040;&#31471;&#30340;&#26041;&#24335;&#23398;&#20064;&#22914;&#20309;&#36866;&#24403;&#22320;&#35268;&#33539;&#21270;&#26102;&#24207;&#25968;&#25454;&#65292;&#32780;&#19981;&#26159;&#20351;&#29992;&#22266;&#23450;&#30340;&#35268;&#33539;&#21270;&#26041;&#26696;&#65292;&#26469;&#25552;&#39640;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#26102;&#24207;&#39044;&#27979;&#21644;&#20998;&#31867;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#19981;&#21516;&#25968;&#25454;&#38598;&#19978;&#37117;&#21462;&#24471;&#20102;&#33391;&#22909;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.14720</link><description>&lt;p&gt;
&#25193;&#23637;&#28145;&#24230;&#33258;&#36866;&#24212;&#36755;&#20837;&#35268;&#33539;&#21270;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#23545;&#26102;&#24207;&#25968;&#25454;&#30340;&#39044;&#22788;&#29702;
&lt;/p&gt;
&lt;p&gt;
Extended Deep Adaptive Input Normalization for Preprocessing Time Series Data for Neural Networks. (arXiv:2310.14720v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14720
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;EDAIn&#30340;&#25193;&#23637;&#28145;&#24230;&#33258;&#36866;&#24212;&#36755;&#20837;&#35268;&#33539;&#21270;&#23618;&#65292;&#36890;&#36807;&#20197;&#31471;&#21040;&#31471;&#30340;&#26041;&#24335;&#23398;&#20064;&#22914;&#20309;&#36866;&#24403;&#22320;&#35268;&#33539;&#21270;&#26102;&#24207;&#25968;&#25454;&#65292;&#32780;&#19981;&#26159;&#20351;&#29992;&#22266;&#23450;&#30340;&#35268;&#33539;&#21270;&#26041;&#26696;&#65292;&#26469;&#25552;&#39640;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#26102;&#24207;&#39044;&#27979;&#21644;&#20998;&#31867;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#19981;&#21516;&#25968;&#25454;&#38598;&#19978;&#37117;&#21462;&#24471;&#20102;&#33391;&#22909;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#39044;&#22788;&#29702;&#26159;&#20219;&#20309;&#26426;&#22120;&#23398;&#20064;&#27969;&#31243;&#20013;&#33267;&#20851;&#37325;&#35201;&#30340;&#19968;&#37096;&#20998;&#65292;&#23427;&#23545;&#24615;&#33021;&#21644;&#35757;&#32451;&#25928;&#29575;&#37117;&#26377;&#37325;&#35201;&#24433;&#21709;&#12290;&#24403;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#26102;&#24207;&#39044;&#27979;&#21644;&#20998;&#31867;&#26102;&#65292;&#36825;&#19968;&#28857;&#23588;&#20026;&#26126;&#26174;&#65306;&#30495;&#23454;&#19990;&#30028;&#30340;&#26102;&#24207;&#25968;&#25454;&#36890;&#24120;&#34920;&#29616;&#20986;&#22810;&#26679;&#24615;&#12289;&#20559;&#26012;&#21644;&#24322;&#24120;&#20540;&#31561;&#19981;&#35268;&#21017;&#29305;&#24449;&#65292;&#22914;&#26524;&#19981;&#20805;&#20998;&#22788;&#29702;&#36825;&#20123;&#29305;&#24449;&#65292;&#27169;&#22411;&#24615;&#33021;&#24456;&#24555;&#20250;&#19979;&#38477;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;EDAIN&#65288;&#25193;&#23637;&#28145;&#24230;&#33258;&#36866;&#24212;&#36755;&#20837;&#35268;&#33539;&#21270;&#65289;&#23618;&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#33258;&#36866;&#24212;&#31070;&#32463;&#23618;&#65292;&#23427;&#33021;&#22815;&#20197;&#31471;&#21040;&#31471;&#30340;&#26041;&#24335;&#23398;&#20064;&#22914;&#20309;&#36866;&#24403;&#22320;&#35268;&#33539;&#21270;&#19981;&#35268;&#21017;&#30340;&#26102;&#24207;&#25968;&#25454;&#65292;&#32780;&#19981;&#26159;&#20351;&#29992;&#22266;&#23450;&#30340;&#35268;&#33539;&#21270;&#26041;&#26696;&#12290;&#36825;&#36890;&#36807;&#20351;&#29992;&#21453;&#21521;&#20256;&#25773;&#31639;&#27861;&#65292;&#21516;&#26102;&#20248;&#21270;&#20854;&#26410;&#30693;&#21442;&#25968;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26469;&#23454;&#29616;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#19968;&#26041;&#27861;&#22312;&#20351;&#29992;&#21512;&#25104;&#25968;&#25454;&#12289;&#20449;&#29992;&#36829;&#32422;&#39044;&#27979;&#25968;&#25454;&#38598;&#21644;&#22823;&#35268;&#27169;&#38480;&#20215;&#21333;&#31807;&#22522;&#20934;&#25968;&#25454;&#38598;&#26102;&#37117;&#21462;&#24471;&#20102;&#33391;&#22909;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data preprocessing is a crucial part of any machine learning pipeline, and it can have a significant impact on both performance and training efficiency. This is especially evident when using deep neural networks for time series prediction and classification: real-world time series data often exhibit irregularities such as multi-modality, skewness and outliers, and the model performance can degrade rapidly if these characteristics are not adequately addressed. In this work, we propose the EDAIN (Extended Deep Adaptive Input Normalization) layer, a novel adaptive neural layer that learns how to appropriately normalize irregular time series data for a given task in an end-to-end fashion, instead of using a fixed normalization scheme. This is achieved by optimizing its unknown parameters simultaneously with the deep neural network using back-propagation. Our experiments, conducted using synthetic data, a credit default prediction dataset, and a large-scale limit order book benchmark datase
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#27010;&#29575;&#26292;&#38706;&#27169;&#22411;&#65292;&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#20272;&#35745;&#24503;&#22269;&#23460;&#20869;&#27681;&#27668;&#20998;&#24067;&#65292;&#24182;&#20855;&#26377;&#26356;&#39640;&#30340;&#31354;&#38388;&#20998;&#36776;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.11143</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#27010;&#29575;&#26292;&#38706;&#27169;&#22411;&#30340;&#24503;&#22269;&#39640;&#20998;&#36776;&#29575;&#23460;&#20869;&#27681;&#27668;&#22320;&#22270;
&lt;/p&gt;
&lt;p&gt;
A new high-resolution indoor radon map for Germany using a machine learning based probabilistic exposure model. (arXiv:2310.11143v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11143
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#27010;&#29575;&#26292;&#38706;&#27169;&#22411;&#65292;&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#20272;&#35745;&#24503;&#22269;&#23460;&#20869;&#27681;&#27668;&#20998;&#24067;&#65292;&#24182;&#20855;&#26377;&#26356;&#39640;&#30340;&#31354;&#38388;&#20998;&#36776;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23460;&#20869;&#27681;&#27668;&#26159;&#19968;&#31181;&#33268;&#30284;&#30340;&#25918;&#23556;&#24615;&#27668;&#20307;&#65292;&#21487;&#20197;&#22312;&#23460;&#20869;&#31215;&#32047;&#12290;&#36890;&#24120;&#24773;&#20917;&#19979;&#65292;&#20840;&#22269;&#33539;&#22260;&#20869;&#30340;&#23460;&#20869;&#27681;&#26292;&#38706;&#26159;&#22522;&#20110;&#24191;&#27867;&#30340;&#27979;&#37327;&#27963;&#21160;&#20272;&#35745;&#24471;&#26469;&#30340;&#12290;&#28982;&#32780;&#65292;&#26679;&#26412;&#30340;&#29305;&#24449;&#24448;&#24448;&#19982;&#20154;&#21475;&#29305;&#24449;&#19981;&#21516;&#65292;&#36825;&#26159;&#30001;&#20110;&#35768;&#22810;&#30456;&#20851;&#22240;&#32032;&#65292;&#22914;&#22320;&#36136;&#28304;&#27681;&#27668;&#30340;&#21487;&#29992;&#24615;&#25110;&#27004;&#23618;&#27700;&#24179;&#12290;&#27492;&#22806;&#65292;&#26679;&#26412;&#22823;&#23567;&#36890;&#24120;&#19981;&#20801;&#35768;&#20197;&#39640;&#31354;&#38388;&#20998;&#36776;&#29575;&#36827;&#34892;&#26292;&#38706;&#20272;&#35745;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#27604;&#32431;&#25968;&#25454;&#26041;&#27861;&#26356;&#21152;&#29616;&#23454;&#22320;&#20272;&#35745;&#23460;&#20869;&#27681;&#20998;&#24067;&#65292;&#24182;&#20855;&#26377;&#26356;&#39640;&#30340;&#31354;&#38388;&#20998;&#36776;&#29575;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;&#20004;&#38454;&#27573;&#24314;&#27169;&#26041;&#27861;&#65306;1&#65289;&#24212;&#29992;&#20998;&#20301;&#25968;&#22238;&#24402;&#26862;&#26519;&#65292;&#20351;&#29992;&#29615;&#22659;&#21644;&#24314;&#31569;&#25968;&#25454;&#20316;&#20026;&#39044;&#27979;&#22240;&#23376;&#65292;&#20272;&#35745;&#20102;&#24503;&#22269;&#27599;&#20010;&#20303;&#23429;&#27004;&#30340;&#27599;&#20010;&#27004;&#23618;&#30340;&#23460;&#20869;&#27681;&#27010;&#29575;&#20998;&#24067;&#20989;&#25968;&#65307;2&#65289;&#20351;&#29992;&#27010;&#29575;&#33945;&#29305;&#21345;&#32599;&#25277;&#26679;&#25216;&#26415;&#20351;&#23427;&#20204;&#32452;&#21512;&#21644;&#12290;
&lt;/p&gt;
&lt;p&gt;
Radon is a carcinogenic, radioactive gas that can accumulate indoors. Indoor radon exposure at the national scale is usually estimated on the basis of extensive measurement campaigns. However, characteristics of the sample often differ from the characteristics of the population due to the large number of relevant factors such as the availability of geogenic radon or floor level. Furthermore, the sample size usually does not allow exposure estimation with high spatial resolution. We propose a model-based approach that allows a more realistic estimation of indoor radon distribution with a higher spatial resolution than a purely data-based approach. We applied a two-stage modelling approach: 1) a quantile regression forest using environmental and building data as predictors was applied to estimate the probability distribution function of indoor radon for each floor level of each residential building in Germany; (2) a probabilistic Monte Carlo sampling technique enabled the combination and
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38236;&#20687;&#25193;&#25955;&#27169;&#22411;&#65288;MDM&#65289;&#65292;&#21487;&#20197;&#22312;&#21463;&#38480;&#21046;&#38598;&#21512;&#19978;&#29983;&#25104;&#25968;&#25454;&#32780;&#19981;&#20007;&#22833;&#21487;&#36861;&#28335;&#24615;&#12290;&#36825;&#36890;&#36807;&#22312;&#19968;&#20010;&#26631;&#20934;&#30340;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#23398;&#20064;&#25193;&#25955;&#36807;&#31243;&#65292;&#24182;&#21033;&#29992;&#38236;&#20687;&#26144;&#23556;&#26469;&#23454;&#29616;&#12290;</title><link>http://arxiv.org/abs/2310.01236</link><description>&lt;p&gt;
&#21463;&#38480;&#21046;&#21644;&#24102;&#27700;&#21360;&#29983;&#25104;&#30340;&#38236;&#20687;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Mirror Diffusion Models for Constrained and Watermarked Generation. (arXiv:2310.01236v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01236
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38236;&#20687;&#25193;&#25955;&#27169;&#22411;&#65288;MDM&#65289;&#65292;&#21487;&#20197;&#22312;&#21463;&#38480;&#21046;&#38598;&#21512;&#19978;&#29983;&#25104;&#25968;&#25454;&#32780;&#19981;&#20007;&#22833;&#21487;&#36861;&#28335;&#24615;&#12290;&#36825;&#36890;&#36807;&#22312;&#19968;&#20010;&#26631;&#20934;&#30340;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#23398;&#20064;&#25193;&#25955;&#36807;&#31243;&#65292;&#24182;&#21033;&#29992;&#38236;&#20687;&#26144;&#23556;&#26469;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#25193;&#25955;&#27169;&#22411;&#22312;&#23398;&#20064;&#22797;&#26434;&#30340;&#39640;&#32500;&#25968;&#25454;&#20998;&#24067;&#26041;&#38754;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#36825;&#37096;&#20998;&#24402;&#21151;&#20110;&#20854;&#33021;&#22815;&#26500;&#24314;&#20855;&#26377;&#35299;&#26512;&#36716;&#31227;&#26680;&#20989;&#25968;&#21644;&#35780;&#20998;&#20989;&#25968;&#30340;&#25193;&#25955;&#36807;&#31243;&#12290;&#36825;&#31181;&#21487;&#36861;&#28335;&#24615;&#32467;&#26524;&#22312;&#19981;&#38656;&#35201;&#27169;&#25311;&#30340;&#26694;&#26550;&#20013;&#20855;&#26377;&#31283;&#23450;&#30340;&#22238;&#24402;&#25439;&#22833;&#65292;&#20174;&#32780;&#21487;&#20197;&#23398;&#20064;&#21040;&#21487;&#20197;&#25193;&#23637;&#30340;&#36870;&#21521;&#29983;&#25104;&#36807;&#31243;&#12290;&#28982;&#32780;&#65292;&#24403;&#25968;&#25454;&#34987;&#38480;&#21046;&#22312;&#21463;&#38480;&#21046;&#38598;&#21512;&#32780;&#19981;&#26159;&#26631;&#20934;&#30340;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#20013;&#26102;&#65292;&#26681;&#25454;&#20043;&#21069;&#30340;&#23581;&#35797;&#65292;&#36825;&#20123;&#29702;&#24819;&#30340;&#29305;&#24615;&#20284;&#20046;&#20007;&#22833;&#20102;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#38236;&#20687;&#25193;&#25955;&#27169;&#22411;&#65288;MDM&#65289;&#65292;&#19968;&#31181;&#26032;&#30340;&#25193;&#25955;&#27169;&#22411;&#31867;&#65292;&#21487;&#20197;&#22312;&#20984;&#32422;&#26463;&#38598;&#21512;&#19978;&#29983;&#25104;&#25968;&#25454;&#32780;&#19981;&#20007;&#22833;&#20219;&#20309;&#21487;&#36861;&#28335;&#24615;&#12290;&#36825;&#26159;&#36890;&#36807;&#22312;&#20174;&#38236;&#20687;&#26144;&#23556;&#26500;&#24314;&#30340;&#23545;&#20598;&#31354;&#38388;&#20013;&#23398;&#20064;&#25193;&#25955;&#36807;&#31243;&#26469;&#23454;&#29616;&#30340;&#65292;&#20851;&#38190;&#30340;&#26159;&#65292;&#36825;&#26159;&#19968;&#20010;&#26631;&#20934;&#30340;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#27969;&#34892;&#30340;&#32422;&#26463;&#38598;&#21512;&#65288;&#22914;&#21333;&#32431;&#24418;&#21644;$\ell_2$-&#29699;&#65289;&#30340;&#38236;&#20687;&#26144;&#23556;&#30340;&#26377;&#25928;&#35745;&#31639;&#65292;&#26174;&#31034;&#26126;&#26174;&#30340;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern successes of diffusion models in learning complex, high-dimensional data distributions are attributed, in part, to their capability to construct diffusion processes with analytic transition kernels and score functions. The tractability results in a simulation-free framework with stable regression losses, from which reversed, generative processes can be learned at scale. However, when data is confined to a constrained set as opposed to a standard Euclidean space, these desirable characteristics appear to be lost based on prior attempts. In this work, we propose Mirror Diffusion Models (MDM), a new class of diffusion models that generate data on convex constrained sets without losing any tractability. This is achieved by learning diffusion processes in a dual space constructed from a mirror map, which, crucially, is a standard Euclidean space. We derive efficient computation of mirror maps for popular constrained sets, such as simplices and $\ell_2$-balls, showing significantly im
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#20132;&#21449;&#39044;&#27979;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#36827;&#34892;&#25512;&#29702;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#20351;&#29992;&#19968;&#20010;&#23567;&#22411;&#26631;&#35760;&#25968;&#25454;&#38598;&#21644;&#19968;&#20010;&#22823;&#22411;&#26410;&#26631;&#35760;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#22635;&#34917;&#32570;&#22833;&#30340;&#26631;&#31614;&#65292;&#24182;&#37319;&#29992;&#21435;&#20559;&#24046;&#26041;&#27861;&#32416;&#27491;&#39044;&#27979;&#30340;&#19981;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.16598</link><description>&lt;p&gt;
&#22522;&#20110;&#20132;&#21449;&#39044;&#27979;&#30340;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Cross-Prediction-Powered Inference. (arXiv:2309.16598v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16598
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#20132;&#21449;&#39044;&#27979;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#36827;&#34892;&#25512;&#29702;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#20351;&#29992;&#19968;&#20010;&#23567;&#22411;&#26631;&#35760;&#25968;&#25454;&#38598;&#21644;&#19968;&#20010;&#22823;&#22411;&#26410;&#26631;&#35760;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#22635;&#34917;&#32570;&#22833;&#30340;&#26631;&#31614;&#65292;&#24182;&#37319;&#29992;&#21435;&#20559;&#24046;&#26041;&#27861;&#32416;&#27491;&#39044;&#27979;&#30340;&#19981;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#38752;&#30340;&#25968;&#25454;&#39537;&#21160;&#20915;&#31574;&#20381;&#36182;&#20110;&#39640;&#36136;&#37327;&#30340;&#26631;&#27880;&#25968;&#25454;&#65292;&#28982;&#32780;&#33719;&#21462;&#39640;&#36136;&#37327;&#30340;&#26631;&#27880;&#25968;&#25454;&#32463;&#24120;&#38656;&#35201;&#32321;&#29712;&#30340;&#20154;&#24037;&#26631;&#27880;&#25110;&#32773;&#32531;&#24930;&#26114;&#36149;&#30340;&#31185;&#23398;&#27979;&#37327;&#12290;&#26426;&#22120;&#23398;&#20064;&#20316;&#20026;&#19968;&#31181;&#26367;&#20195;&#26041;&#26696;&#27491;&#21464;&#24471;&#36234;&#26469;&#36234;&#26377;&#21560;&#24341;&#21147;&#65292;&#22240;&#20026;&#31934;&#23494;&#30340;&#39044;&#27979;&#25216;&#26415;&#21487;&#20197;&#24555;&#36895;&#12289;&#24265;&#20215;&#22320;&#20135;&#29983;&#22823;&#37327;&#39044;&#27979;&#26631;&#31614;&#65307;&#20363;&#22914;&#65292;&#39044;&#27979;&#30340;&#34507;&#30333;&#36136;&#32467;&#26500;&#34987;&#29992;&#26469;&#34917;&#20805;&#23454;&#39564;&#24471;&#21040;&#30340;&#32467;&#26500;&#65292;&#21355;&#26143;&#22270;&#20687;&#39044;&#27979;&#30340;&#31038;&#20250;&#32463;&#27982;&#25351;&#26631;&#34987;&#29992;&#26469;&#34917;&#20805;&#20934;&#30830;&#30340;&#35843;&#26597;&#25968;&#25454;&#31561;&#12290;&#30001;&#20110;&#39044;&#27979;&#20855;&#26377;&#19981;&#23436;&#32654;&#21644;&#28508;&#22312;&#20559;&#24046;&#30340;&#29305;&#28857;&#65292;&#36825;&#31181;&#20570;&#27861;&#23545;&#19979;&#28216;&#25512;&#29702;&#30340;&#26377;&#25928;&#24615;&#20135;&#29983;&#20102;&#36136;&#30097;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#20132;&#21449;&#39044;&#27979;&#26041;&#27861;&#65292;&#29992;&#20110;&#26377;&#25928;&#30340;&#25512;&#29702;&#12290;&#36890;&#36807;&#19968;&#20010;&#23567;&#30340;&#26631;&#35760;&#25968;&#25454;&#38598;&#21644;&#19968;&#20010;&#22823;&#30340;&#26410;&#26631;&#35760;&#25968;&#25454;&#38598;&#65292;&#20132;&#21449;&#39044;&#27979;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#22635;&#34917;&#32570;&#22833;&#30340;&#26631;&#31614;&#65292;&#24182;&#24212;&#29992;&#19968;&#31181;&#21435;&#20559;&#24046;&#30340;&#26041;&#27861;&#26469;&#32416;&#27491;&#39044;&#27979;&#19981;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
While reliable data-driven decision-making hinges on high-quality labeled data, the acquisition of quality labels often involves laborious human annotations or slow and expensive scientific measurements. Machine learning is becoming an appealing alternative as sophisticated predictive techniques are being used to quickly and cheaply produce large amounts of predicted labels; e.g., predicted protein structures are used to supplement experimentally derived structures, predictions of socioeconomic indicators from satellite imagery are used to supplement accurate survey data, and so on. Since predictions are imperfect and potentially biased, this practice brings into question the validity of downstream inferences. We introduce cross-prediction: a method for valid inference powered by machine learning. With a small labeled dataset and a large unlabeled dataset, cross-prediction imputes the missing labels via machine learning and applies a form of debiasing to remedy the prediction inaccurac
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20174;&#22122;&#22768;&#28151;&#21512;&#29289;&#20013;&#24674;&#22797;&#30446;&#26631;&#20449;&#21495;&#30340;&#32479;&#35745;&#20998;&#37327;&#20998;&#31163;&#26041;&#27861;&#65292;&#24182;&#19988;&#22312;&#22270;&#20687;&#38477;&#22122;&#20219;&#21153;&#20013;&#23637;&#31034;&#20102;&#20854;&#20248;&#20110;&#26631;&#20934;&#38477;&#22122;&#26041;&#27861;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2306.15012</link><description>&lt;p&gt;
&#29992;&#20110;&#22122;&#22768;&#28151;&#21512;&#29289;&#20013;&#30446;&#26631;&#20449;&#21495;&#24674;&#22797;&#30340;&#32479;&#35745;&#20998;&#37327;&#20998;&#31163;
&lt;/p&gt;
&lt;p&gt;
Statistical Component Separation for Targeted Signal Recovery in Noisy Mixtures. (arXiv:2306.15012v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15012
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20174;&#22122;&#22768;&#28151;&#21512;&#29289;&#20013;&#24674;&#22797;&#30446;&#26631;&#20449;&#21495;&#30340;&#32479;&#35745;&#20998;&#37327;&#20998;&#31163;&#26041;&#27861;&#65292;&#24182;&#19988;&#22312;&#22270;&#20687;&#38477;&#22122;&#20219;&#21153;&#20013;&#23637;&#31034;&#20102;&#20854;&#20248;&#20110;&#26631;&#20934;&#38477;&#22122;&#26041;&#27861;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21482;&#23545;&#32473;&#23450;&#20449;&#21495;&#30340;&#29305;&#23450;&#23646;&#24615;&#24863;&#20852;&#36259;&#26102;&#65292;&#20174;&#19968;&#20010;&#21152;&#24615;&#28151;&#21512;&#29289;&#20013;&#20998;&#31163;&#20449;&#21495;&#21487;&#33021;&#26159;&#19968;&#20010;&#19981;&#24517;&#35201;&#22320;&#22256;&#38590;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#26356;&#31616;&#21333;&#30340;&#8220;&#32479;&#35745;&#20998;&#37327;&#20998;&#31163;&#8221;&#38382;&#39064;&#65292;&#35813;&#38382;&#39064;&#19987;&#27880;&#20110;&#20174;&#22122;&#22768;&#28151;&#21512;&#29289;&#20013;&#24674;&#22797;&#30446;&#26631;&#20449;&#21495;&#30340;&#39044;&#23450;&#20041;&#32479;&#35745;&#25551;&#36848;&#37327;&#12290;&#20551;&#35774;&#21487;&#20197;&#33719;&#24471;&#22122;&#22768;&#36807;&#31243;&#30340;&#26679;&#26412;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#26088;&#22312;&#20351;&#21463;&#22122;&#22768;&#26679;&#26412;&#27745;&#26579;&#30340;&#35299;&#20915;&#26041;&#26696;&#20505;&#36873;&#30340;&#32479;&#35745;&#29305;&#24615;&#19982;&#35266;&#27979;&#30340;&#28151;&#21512;&#29289;&#30340;&#32479;&#35745;&#29305;&#24615;&#21305;&#37197;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#20351;&#29992;&#20855;&#26377;&#35299;&#26512;&#21487;&#36861;&#36394;&#35745;&#31639;&#30340;&#31616;&#21333;&#31034;&#20363;&#20998;&#26512;&#20102;&#35813;&#26041;&#27861;&#30340;&#34892;&#20026;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#20854;&#24212;&#29992;&#20110;&#22270;&#20687;&#38477;&#22122;&#29615;&#22659;&#20013;&#65292;&#20351;&#29992;&#20102;1&#65289;&#22522;&#20110;&#23567;&#27874;&#30340;&#25551;&#36848;&#31526;&#65292;2&#65289;&#38024;&#23545;&#22825;&#20307;&#29289;&#29702;&#21644;ImageNet&#25968;&#25454;&#30340;ConvNet-based&#25551;&#36848;&#31526;&#12290;&#22312;&#31532;&#19968;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#22823;&#22810;&#25968;&#24773;&#20917;&#19979;&#27604;&#26631;&#20934;&#38477;&#22122;&#26041;&#27861;&#26356;&#22909;&#22320;&#24674;&#22797;&#20102;&#30446;&#26631;&#25968;&#25454;&#30340;&#25551;&#36848;&#31526;&#12290;&#27492;&#22806;&#65292;&#23613;&#31649;&#19981;&#26159;&#20026;&#27492;&#30446;&#30340;&#26500;&#24314;&#30340;&#65292;&#23427;&#20063;&#34920;&#29616;&#20986;&#23545;&#30446;&#26631;&#20449;&#21495;&#25551;&#36848;&#31526;&#24674;&#22797;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Separating signals from an additive mixture may be an unnecessarily hard problem when one is only interested in specific properties of a given signal. In this work, we tackle simpler "statistical component separation" problems that focus on recovering a predefined set of statistical descriptors of a target signal from a noisy mixture. Assuming access to samples of the noise process, we investigate a method devised to match the statistics of the solution candidate corrupted by noise samples with those of the observed mixture. We first analyze the behavior of this method using simple examples with analytically tractable calculations. Then, we apply it in an image denoising context employing 1) wavelet-based descriptors, 2) ConvNet-based descriptors on astrophysics and ImageNet data. In the case of 1), we show that our method better recovers the descriptors of the target data than a standard denoising method in most situations. Additionally, despite not constructed for this purpose, it pe
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#25552;&#20986;&#20102;&#20351;&#29992;CNN&#23398;&#20064;&#31354;&#38388;&#36807;&#31243;&#30340;&#20284;&#28982;&#20989;&#25968;&#12290;&#21363;&#20351;&#22312;&#27809;&#26377;&#30830;&#20999;&#20284;&#28982;&#20989;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#20998;&#31867;&#20219;&#21153;&#36827;&#34892;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#65292;&#21487;&#20197;&#38544;&#24335;&#22320;&#23398;&#20064;&#20284;&#28982;&#20989;&#25968;&#12290;&#20351;&#29992;Platt&#32553;&#25918;&#21487;&#20197;&#25552;&#39640;&#31070;&#32463;&#20284;&#28982;&#38754;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.04634</link><description>&lt;p&gt;
&#31354;&#38388;&#36807;&#31243;&#30340;&#31070;&#32463;&#20284;&#28982;&#38754;
&lt;/p&gt;
&lt;p&gt;
Neural Likelihood Surfaces for Spatial Processes with Computationally Intensive or Intractable Likelihoods. (arXiv:2305.04634v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04634
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25552;&#20986;&#20102;&#20351;&#29992;CNN&#23398;&#20064;&#31354;&#38388;&#36807;&#31243;&#30340;&#20284;&#28982;&#20989;&#25968;&#12290;&#21363;&#20351;&#22312;&#27809;&#26377;&#30830;&#20999;&#20284;&#28982;&#20989;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#20998;&#31867;&#20219;&#21153;&#36827;&#34892;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#65292;&#21487;&#20197;&#38544;&#24335;&#22320;&#23398;&#20064;&#20284;&#28982;&#20989;&#25968;&#12290;&#20351;&#29992;Platt&#32553;&#25918;&#21487;&#20197;&#25552;&#39640;&#31070;&#32463;&#20284;&#28982;&#38754;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31354;&#38388;&#32479;&#35745;&#20013;&#65292;&#24403;&#25311;&#21512;&#31354;&#38388;&#36807;&#31243;&#21040;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#26102;&#65292;&#24555;&#36895;&#20934;&#30830;&#30340;&#21442;&#25968;&#20272;&#35745;&#21644;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#25163;&#27573;&#21487;&#33021;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#22240;&#20026;&#20284;&#28982;&#20989;&#25968;&#21487;&#33021;&#35780;&#20272;&#32531;&#24930;&#25110;&#38590;&#20197;&#22788;&#29702;&#12290; &#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#23398;&#20064;&#31354;&#38388;&#36807;&#31243;&#30340;&#20284;&#28982;&#20989;&#25968;&#12290;&#36890;&#36807;&#29305;&#23450;&#35774;&#35745;&#30340;&#20998;&#31867;&#20219;&#21153;&#65292;&#25105;&#20204;&#30340;&#31070;&#32463;&#32593;&#32476;&#38544;&#24335;&#22320;&#23398;&#20064;&#20284;&#28982;&#20989;&#25968;&#65292;&#21363;&#20351;&#22312;&#27809;&#26377;&#26174;&#24335;&#21487;&#29992;&#30340;&#30830;&#20999;&#20284;&#28982;&#20989;&#25968;&#30340;&#24773;&#20917;&#19979;&#20063;&#21487;&#20197;&#23454;&#29616;&#12290;&#19968;&#26086;&#22312;&#20998;&#31867;&#20219;&#21153;&#19978;&#36827;&#34892;&#20102;&#35757;&#32451;&#65292;&#25105;&#20204;&#30340;&#31070;&#32463;&#32593;&#32476;&#20351;&#29992;Platt&#32553;&#25918;&#36827;&#34892;&#26657;&#20934;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#31070;&#32463;&#20284;&#28982;&#38754;&#30340;&#20934;&#30830;&#24615;&#12290;&#20026;&#20102;&#23637;&#31034;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#27604;&#36739;&#20102;&#26469;&#33258;&#31070;&#32463;&#20284;&#28982;&#38754;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#21644;&#36817;&#20284;&#32622;&#20449;&#21306;&#38388;&#19982;&#20004;&#20010;&#19981;&#21516;&#31354;&#38388;&#36807;&#31243;&#65288;&#39640;&#26031;&#36807;&#31243;&#21644;&#23545;&#25968;&#39640;&#26031;Cox&#36807;&#31243;&#65289;&#30340;&#30456;&#24212;&#31934;&#30830;&#25110;&#36817;&#20284;&#30340;&#20284;&#28982;&#20989;&#25968;&#26500;&#25104;&#30340;&#31561;&#25928;&#29289;&#12290;
&lt;/p&gt;
&lt;p&gt;
In spatial statistics, fast and accurate parameter estimation coupled with a reliable means of uncertainty quantification can be a challenging task when fitting a spatial process to real-world data because the likelihood function might be slow to evaluate or intractable. In this work, we propose using convolutional neural networks (CNNs) to learn the likelihood function of a spatial process. Through a specifically designed classification task, our neural network implicitly learns the likelihood function, even in situations where the exact likelihood is not explicitly available. Once trained on the classification task, our neural network is calibrated using Platt scaling which improves the accuracy of the neural likelihood surfaces. To demonstrate our approach, we compare maximum likelihood estimates and approximate confidence regions constructed from the neural likelihood surface with the equivalent for exact or approximate likelihood for two different spatial processes: a Gaussian Pro
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;Langevin&#22411;&#31639;&#27861;&#24182;&#24212;&#29992;&#20110;&#21513;&#24067;&#26031;&#20998;&#24067;&#12290;&#36890;&#36807;&#25552;&#20986;&#30340;2-Wasserstein&#36317;&#31163;&#19978;&#38480;&#65292;&#25105;&#20204;&#21457;&#29616;&#21183;&#20989;&#25968;&#30340;&#32791;&#25955;&#24615;&#20197;&#21450;&#26799;&#24230; $\alpha&gt;1/3$ &#19979;&#30340; $\alpha$-H\"{o}lder&#36830;&#32493;&#24615;&#21487;&#20197;&#20445;&#35777;&#31639;&#27861;&#20855;&#26377;&#25509;&#36817;&#38646;&#30340;&#35823;&#24046;&#12290;&#26032;&#30340;Langevin&#22411;&#31639;&#27861;&#36824;&#21487;&#20197;&#24212;&#29992;&#20110;&#26080;&#20984;&#24615;&#25110;&#36830;&#32493;&#21487;&#24494;&#24615;&#30340;&#21183;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2303.12407</link><description>&lt;p&gt;
Langevin&#22411;Monte Carlo&#31639;&#27861;&#30340;&#38750;&#28176;&#36827;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Non-asymptotic analysis of Langevin-type Monte Carlo algorithms. (arXiv:2303.12407v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.12407
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;Langevin&#22411;&#31639;&#27861;&#24182;&#24212;&#29992;&#20110;&#21513;&#24067;&#26031;&#20998;&#24067;&#12290;&#36890;&#36807;&#25552;&#20986;&#30340;2-Wasserstein&#36317;&#31163;&#19978;&#38480;&#65292;&#25105;&#20204;&#21457;&#29616;&#21183;&#20989;&#25968;&#30340;&#32791;&#25955;&#24615;&#20197;&#21450;&#26799;&#24230; $\alpha&gt;1/3$ &#19979;&#30340; $\alpha$-H\"{o}lder&#36830;&#32493;&#24615;&#21487;&#20197;&#20445;&#35777;&#31639;&#27861;&#20855;&#26377;&#25509;&#36817;&#38646;&#30340;&#35823;&#24046;&#12290;&#26032;&#30340;Langevin&#22411;&#31639;&#27861;&#36824;&#21487;&#20197;&#24212;&#29992;&#20110;&#26080;&#20984;&#24615;&#25110;&#36830;&#32493;&#21487;&#24494;&#24615;&#30340;&#21183;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;Langevin&#22411;&#31639;&#27861;&#24212;&#29992;&#20110;&#21513;&#24067;&#26031;&#20998;&#24067;&#30340;&#24773;&#20917;&#65292;&#20854;&#20013;&#21183;&#20989;&#25968;&#26159;&#32791;&#25955;&#30340;&#65292;&#19988;&#20854;&#24369;&#26799;&#24230;&#20855;&#26377;&#26377;&#38480;&#30340;&#36830;&#32493;&#24615;&#27169;&#37327;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;2-Wasserstein&#36317;&#31163;&#19978;&#38480;&#30340;&#38750;&#28176;&#36827;&#24615;&#65292;&#23427;&#34913;&#37327;&#20102;&#21513;&#24067;&#26031;&#20998;&#24067;&#19982;&#22522;&#20110;Liptser-Shiryaev&#29702;&#35770;&#21644;&#20989;&#25968;&#19981;&#31561;&#24335;&#30340;Langevin&#22411;&#31639;&#27861;&#30340;&#19968;&#33324;&#20998;&#24067;&#20043;&#38388;&#30340;&#36317;&#31163;&#12290;&#25105;&#20204;&#24212;&#29992;&#36825;&#20010;&#19978;&#38480;&#26469;&#23637;&#31034;&#21183;&#20989;&#25968;&#30340;&#32791;&#25955;&#24615;&#20197;&#21450;&#26799;&#24230; $\alpha&gt;1/3$ &#19979;&#30340; $\alpha$-H\"{o}lder&#36830;&#32493;&#24615;&#26159;&#20805;&#20998;&#30340;&#65292;&#21487;&#20197;&#36890;&#36807;&#36866;&#24403;&#25511;&#21046;&#21442;&#25968;&#26469;&#33719;&#24471;Langevin Monte Carlo&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#36824;&#38024;&#23545;&#26080;&#20984;&#24615;&#25110;&#36830;&#32493;&#21487;&#24494;&#24615;&#30340;&#21183;&#20989;&#25968;&#25552;&#20986;&#20102;&#29699;&#24418;&#24179;&#28369;&#25216;&#26415;&#30340;Langevin&#22411;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the Langevin-type algorithms for Gibbs distributions such that the potentials are dissipative and their weak gradients have the finite moduli of continuity. Our main result is a non-asymptotic upper bound of the 2-Wasserstein distance between the Gibbs distribution and the law of general Langevin-type algorithms based on the Liptser--Shiryaev theory and functional inequalities. We apply this bound to show that the dissipativity of the potential and the $\alpha$-H\"{o}lder continuity of the gradient with $\alpha&gt;1/3$ are sufficient for the convergence of the Langevin Monte Carlo algorithm with appropriate control of the parameters. We also propose Langevin-type algorithms with spherical smoothing for potentials without convexity or continuous differentiability.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;StaPLR&#31639;&#27861;&#30340;&#26032;&#30340;&#22810;&#35270;&#35282;&#25968;&#25454;&#25554;&#34917;&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#38477;&#32500;&#31354;&#38388;&#20013;&#25191;&#34892;&#25554;&#34917;&#20197;&#35299;&#20915;&#35745;&#31639;&#25361;&#25112;&#65292;&#24182;&#22312;&#27169;&#25311;&#25968;&#25454;&#38598;&#20013;&#24471;&#21040;&#20102;&#31454;&#20105;&#24615;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2210.14484</link><description>&lt;p&gt;
&#22810;&#35270;&#35282;&#25968;&#25454;&#20013;&#32570;&#22833;&#20540;&#30340;&#25554;&#34917;&#38382;&#39064;&#35299;&#20915;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Imputation of missing values in multi-view data. (arXiv:2210.14484v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.14484
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;StaPLR&#31639;&#27861;&#30340;&#26032;&#30340;&#22810;&#35270;&#35282;&#25968;&#25454;&#25554;&#34917;&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#38477;&#32500;&#31354;&#38388;&#20013;&#25191;&#34892;&#25554;&#34917;&#20197;&#35299;&#20915;&#35745;&#31639;&#25361;&#25112;&#65292;&#24182;&#22312;&#27169;&#25311;&#25968;&#25454;&#38598;&#20013;&#24471;&#21040;&#20102;&#31454;&#20105;&#24615;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#35270;&#35282;&#25968;&#25454;&#26159;&#25351;&#30001;&#22810;&#20010;&#19981;&#21516;&#29305;&#24449;&#38598;&#25551;&#36848;&#30340;&#25968;&#25454;&#12290;&#22312;&#22788;&#29702;&#22810;&#35270;&#35282;&#25968;&#25454;&#26102;&#65292;&#33509;&#20986;&#29616;&#32570;&#22833;&#20540;&#65292;&#21017;&#19968;&#20010;&#35270;&#35282;&#20013;&#30340;&#25152;&#26377;&#29305;&#24449;&#26497;&#26377;&#21487;&#33021;&#21516;&#26102;&#32570;&#22833;&#65292;&#22240;&#32780;&#23548;&#33268;&#38750;&#24120;&#22823;&#37327;&#30340;&#32570;&#22833;&#25968;&#25454;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22810;&#35270;&#35282;&#23398;&#20064;&#31639;&#27861;&#20013;&#30340;&#25554;&#34917;&#26041;&#27861;&#65292;&#23427;&#22522;&#20110;&#22534;&#21472;&#24809;&#32602;&#36923;&#36753;&#22238;&#24402;(StaPLR)&#31639;&#27861;&#65292;&#22312;&#38477;&#32500;&#31354;&#38388;&#20013;&#25191;&#34892;&#25554;&#34917;&#65292;&#20197;&#35299;&#20915;&#22266;&#26377;&#30340;&#22810;&#35270;&#35282;&#35745;&#31639;&#25361;&#25112;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#27169;&#25311;&#25968;&#25454;&#38598;&#19978;&#20855;&#26377;&#31454;&#20105;&#24615;&#32467;&#26524;&#65292;&#32780;&#19988;&#20855;&#26377;&#26356;&#20302;&#30340;&#35745;&#31639;&#25104;&#26412;&#65292;&#20174;&#32780;&#21487;&#20197;&#20351;&#29992;&#20808;&#36827;&#30340;&#25554;&#34917;&#31639;&#27861;&#65292;&#20363;&#22914;missForest&#12290;
&lt;/p&gt;
&lt;p&gt;
Data for which a set of objects is described by multiple distinct feature sets (called views) is known as multi-view data. When missing values occur in multi-view data, all features in a view are likely to be missing simultaneously. This leads to very large quantities of missing data which, especially when combined with high-dimensionality, makes the application of conditional imputation methods computationally infeasible. We introduce a new imputation method based on the existing stacked penalized logistic regression (StaPLR) algorithm for multi-view learning. It performs imputation in a dimension-reduced space to address computational challenges inherent to the multi-view context. We compare the performance of the new imputation method with several existing imputation algorithms in simulated data sets. The results show that the new imputation method leads to competitive results at a much lower computational cost, and makes the use of advanced imputation algorithms such as missForest 
&lt;/p&gt;</description></item></channel></rss>