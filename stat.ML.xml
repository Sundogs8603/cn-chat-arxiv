<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Q&#38598;&#25104;&#30340;CATE&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#20854;&#36890;&#36807;&#20351;&#29992;&#21452;&#37325;&#40065;&#26834;&#25439;&#22833;&#23454;&#29616;&#20102;&#32479;&#35745;&#19978;&#30340;&#26368;&#20339;&#39044;&#27979;&#27169;&#22411;&#36873;&#25321;&#36951;&#25022;&#29575;</title><link>http://arxiv.org/abs/2310.16945</link><description>&lt;p&gt;
Causal Q-Aggregation for CATE Model Selection&#65288;CATE&#27169;&#22411;&#36873;&#25321;&#20013;&#30340;&#22240;&#26524;Q&#38598;&#25104;&#65289;
&lt;/p&gt;
&lt;p&gt;
Causal Q-Aggregation for CATE Model Selection. (arXiv:2310.16945v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16945
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Q&#38598;&#25104;&#30340;CATE&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#20854;&#36890;&#36807;&#20351;&#29992;&#21452;&#37325;&#40065;&#26834;&#25439;&#22833;&#23454;&#29616;&#20102;&#32479;&#35745;&#19978;&#30340;&#26368;&#20339;&#39044;&#27979;&#27169;&#22411;&#36873;&#25321;&#36951;&#25022;&#29575;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20934;&#30830;&#20272;&#35745;&#26465;&#20214;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;CATE&#65289;&#26159;&#20010;&#24615;&#21270;&#20915;&#31574;&#30340;&#26680;&#24515;&#12290;&#23613;&#31649;&#26377;&#22823;&#37327;&#29992;&#20110;CATE&#20272;&#35745;&#30340;&#27169;&#22411;&#65292;&#20294;&#30001;&#20110;&#22240;&#26524;&#25512;&#26029;&#30340;&#22522;&#26412;&#38382;&#39064;&#65292;&#27169;&#22411;&#36873;&#25321;&#26159;&#19968;&#39033;&#38750;&#24120;&#26840;&#25163;&#30340;&#20219;&#21153;&#12290;&#26368;&#36817;&#30340;&#23454;&#35777;&#24037;&#20316;&#25552;&#20379;&#20102;&#26377;&#21033;&#20110;&#20855;&#26377;&#21452;&#37325;&#40065;&#26834;&#24615;&#36136;&#30340;&#20195;&#29702;&#25439;&#22833;&#24230;&#37327;&#21644;&#27169;&#22411;&#38598;&#25104;&#30340;&#35777;&#25454;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#36825;&#20123;&#27169;&#22411;&#30340;&#29702;&#35770;&#29702;&#35299;&#36824;&#19981;&#22815;&#12290;&#30452;&#25509;&#24212;&#29992;&#20808;&#21069;&#30340;&#29702;&#35770;&#24037;&#20316;&#20250;&#30001;&#20110;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#30340;&#38750;&#20984;&#24615;&#32780;&#23548;&#33268;&#27425;&#20248;&#30340;&#39044;&#27979;&#27169;&#22411;&#36873;&#25321;&#29575;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#29616;&#26377;&#20027;&#35201;CATE&#38598;&#25104;&#26041;&#27861;&#30340;&#36951;&#25022;&#29575;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21452;&#37325;&#40065;&#26834;&#25439;&#22833;&#30340;Q&#38598;&#25104;&#30340;&#26032;&#30340;CATE&#27169;&#22411;&#38598;&#25104;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#34920;&#26126;&#65292;&#22240;&#26524;Q&#38598;&#25104;&#22312;&#39044;&#27979;&#27169;&#22411;&#36873;&#25321;&#30340;&#36951;&#25022;&#29575;&#19978;&#36798;&#21040;&#20102;&#32479;&#35745;&#19978;&#30340;&#26368;&#20248;&#20540;&#20026;$\frac{\log(M)}{n}$&#65288;&#20854;&#20013;$M$&#20026;&#27169;&#22411;&#25968;&#65292;$n$&#20026;&#26679;&#26412;&#25968;&#65289;&#65292;&#21152;&#19978;&#39640;&#38454;&#20272;&#35745;&#35823;&#24046;&#39033;
&lt;/p&gt;
&lt;p&gt;
Accurate estimation of conditional average treatment effects (CATE) is at the core of personalized decision making. While there is a plethora of models for CATE estimation, model selection is a nontrivial task, due to the fundamental problem of causal inference. Recent empirical work provides evidence in favor of proxy loss metrics with double robust properties and in favor of model ensembling. However, theoretical understanding is lacking. Direct application of prior theoretical work leads to suboptimal oracle model selection rates due to the non-convexity of the model selection problem. We provide regret rates for the major existing CATE ensembling approaches and propose a new CATE model ensembling approach based on Q-aggregation using the doubly robust loss. Our main result shows that causal Q-aggregation achieves statistically optimal oracle model selection regret rates of $\frac{\log(M)}{n}$ (with $M$ models and $n$ samples), with the addition of higher-order estimation error term
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#38480;&#39046;&#22495;&#20013;&#20174;&#25945;&#24072;&#21040;&#23398;&#29983;&#20998;&#31867;&#22120;&#36827;&#34892;&#30693;&#35782;&#20256;&#36882;&#30340;&#32479;&#35745;&#25928;&#29575;&#65292;&#21457;&#29616;&#29305;&#26435;&#20449;&#24687;&#20250;&#21152;&#36895;&#20256;&#36882;&#65292;&#36890;&#36807;&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#25439;&#22833;&#20989;&#25968;&#36798;&#21040;&#20102;&#30693;&#35782;&#20256;&#36882;&#30340;&#22522;&#26412;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2310.07838</link><description>&lt;p&gt;
&#25506;&#32034;&#26377;&#38480;&#39046;&#22495;&#30693;&#35782;&#20256;&#36882;&#30340;&#22522;&#26412;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
Towards the Fundamental Limits of Knowledge Transfer over Finite Domains. (arXiv:2310.07838v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07838
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#38480;&#39046;&#22495;&#20013;&#20174;&#25945;&#24072;&#21040;&#23398;&#29983;&#20998;&#31867;&#22120;&#36827;&#34892;&#30693;&#35782;&#20256;&#36882;&#30340;&#32479;&#35745;&#25928;&#29575;&#65292;&#21457;&#29616;&#29305;&#26435;&#20449;&#24687;&#20250;&#21152;&#36895;&#20256;&#36882;&#65292;&#36890;&#36807;&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#25439;&#22833;&#20989;&#25968;&#36798;&#21040;&#20102;&#30693;&#35782;&#20256;&#36882;&#30340;&#22522;&#26412;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23545;&#36890;&#36807;&#20174;&#25945;&#24072;&#21040;&#27010;&#29575;&#21270;&#23398;&#29983;&#20998;&#31867;&#22120;&#30340;n&#20010;&#26679;&#26412;&#36827;&#34892;&#30693;&#35782;&#20256;&#36882;&#30340;&#32479;&#35745;&#25928;&#29575;&#36827;&#34892;&#20102;&#34920;&#24449;&#65292;&#20854;&#20013;&#36755;&#20837;&#31354;&#38388;S&#21644;&#26631;&#31614;A&#20026;&#26377;&#38480;&#22495;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#19977;&#20010;&#28176;&#36827;&#32423;&#21035;&#19978;&#30340;&#29305;&#26435;&#20449;&#24687;&#21487;&#20197;&#21152;&#24555;&#20256;&#36882;&#30340;&#36895;&#24230;&#12290;&#22312;&#31532;&#19968;&#32423;&#21035;&#19978;&#65292;&#21482;&#26377;&#20855;&#26377;&#22256;&#38590;&#26631;&#31614;&#30340;&#26679;&#26412;&#26159;&#24050;&#30693;&#30340;&#65292;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#33021;&#22815;&#36798;&#21040;&#26368;&#23567;&#21270;&#36895;&#29575;sqrt(|S||A|/n)&#12290;&#31532;&#20108;&#32423;&#21035;&#19978;&#65292;&#38500;&#20102;&#24050;&#30693;&#30340;&#22256;&#38590;&#26631;&#31614;&#26679;&#26412;&#22806;&#65292;&#36824;&#26377;&#37319;&#26679;&#26631;&#31614;&#30340;&#25945;&#24072;&#27010;&#29575;&#21487;&#29992;&#65292;&#36825;&#23558;&#25910;&#25947;&#36895;&#24230;&#30340;&#19979;&#30028;&#25552;&#39640;&#21040;|S||A|/n&#12290;&#28982;&#32780;&#65292;&#22312;&#31532;&#20108;&#20010;&#25968;&#25454;&#37319;&#38598;&#21327;&#35758;&#19979;&#65292;&#26368;&#23567;&#21270;&#20132;&#21449;&#29109;&#25439;&#22833;&#30340;&#26420;&#32032;&#36866;&#24212;&#20250;&#23548;&#33268;&#28176;&#36817;&#20559;&#24046;&#30340;&#23398;&#29983;&#12290;&#25105;&#20204;&#20811;&#26381;&#20102;&#36825;&#20010;&#38480;&#21046;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#32463;&#39564;&#21464;&#20307;&#30340;&#24179;&#26041;&#35823;&#24046;&#36923;&#36753;&#25439;&#22833;&#26469;&#23454;&#29616;&#20102;&#22522;&#26412;&#38480;&#21046;&#12290;&#31532;&#19977;&#32423;&#21035;&#36827;&#19968;&#27493;&#36171;&#20104;&#23398;&#29983;&#36719;&#26631;&#31614;&#12290;
&lt;/p&gt;
&lt;p&gt;
We characterize the statistical efficiency of knowledge transfer through $n$ samples from a teacher to a probabilistic student classifier with input space $\mathcal S$ over labels $\mathcal A$. We show that privileged information at three progressive levels accelerates the transfer. At the first level, only samples with hard labels are known, via which the maximum likelihood estimator attains the minimax rate $\sqrt{{|{\mathcal S}||{\mathcal A}|}/{n}}$. The second level has the teacher probabilities of sampled labels available in addition, which turns out to boost the convergence rate lower bound to ${{|{\mathcal S}||{\mathcal A}|}/{n}}$. However, under this second data acquisition protocol, minimizing a naive adaptation of the cross-entropy loss results in an asymptotically biased student. We overcome this limitation and achieve the fundamental limit by using a novel empirical variant of the squared error logit loss. The third level further equips the student with the soft labels (com
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#25506;&#32034;&#32852;&#21512;&#32676;&#19981;&#21464;&#20989;&#25968;&#22312;&#25968;&#25454;-&#21442;&#25968;&#22495;&#19978;&#30340;&#20316;&#29992;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31995;&#32479;&#30340;&#35268;&#21017;&#26469;&#35299;&#30721;&#31070;&#32463;&#32593;&#32476;&#20869;&#37096;&#25968;&#25454;&#34920;&#31034;&#20013;&#30340;&#23545;&#31216;&#24615;&#21644;&#20960;&#20309;&#24615;&#12290;&#21033;&#29992;&#36825;&#19968;&#35268;&#21017;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#30001;&#32852;&#21512;&#19981;&#21464;&#20989;&#25968;&#23548;&#20986;&#30340;&#36890;&#29992;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#21033;&#29992;&#32676;&#35770;&#35777;&#26126;&#20102;&#20854;&#26222;&#36866;&#24615;&#12290;&#36825;&#19968;&#30740;&#31350;&#25581;&#31034;&#20102;&#36924;&#36817;&#29702;&#35770;&#21644;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#32676;&#35770;&#26041;&#38754;&#65292;&#24182;&#23558;&#20960;&#20309;&#28145;&#24230;&#23398;&#20064;&#19982;&#25277;&#35937;&#35843;&#21644;&#20998;&#26512;&#30456;&#36830;&#25509;&#12290;</title><link>http://arxiv.org/abs/2310.03530</link><description>&lt;p&gt;
&#22312;&#25968;&#25454;-&#21442;&#25968;&#22495;&#19978;&#65292;&#32852;&#21512;&#32676;&#19981;&#21464;&#20989;&#25968;&#24341;&#23548;&#20102;&#36890;&#29992;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Joint Group Invariant Functions on Data-Parameter Domain Induce Universal Neural Networks. (arXiv:2310.03530v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03530
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#25506;&#32034;&#32852;&#21512;&#32676;&#19981;&#21464;&#20989;&#25968;&#22312;&#25968;&#25454;-&#21442;&#25968;&#22495;&#19978;&#30340;&#20316;&#29992;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31995;&#32479;&#30340;&#35268;&#21017;&#26469;&#35299;&#30721;&#31070;&#32463;&#32593;&#32476;&#20869;&#37096;&#25968;&#25454;&#34920;&#31034;&#20013;&#30340;&#23545;&#31216;&#24615;&#21644;&#20960;&#20309;&#24615;&#12290;&#21033;&#29992;&#36825;&#19968;&#35268;&#21017;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#30001;&#32852;&#21512;&#19981;&#21464;&#20989;&#25968;&#23548;&#20986;&#30340;&#36890;&#29992;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#21033;&#29992;&#32676;&#35770;&#35777;&#26126;&#20102;&#20854;&#26222;&#36866;&#24615;&#12290;&#36825;&#19968;&#30740;&#31350;&#25581;&#31034;&#20102;&#36924;&#36817;&#29702;&#35770;&#21644;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#32676;&#35770;&#26041;&#38754;&#65292;&#24182;&#23558;&#20960;&#20309;&#28145;&#24230;&#23398;&#20064;&#19982;&#25277;&#35937;&#35843;&#21644;&#20998;&#26512;&#30456;&#36830;&#25509;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#36755;&#20837;&#25968;&#25454;&#30340;&#23545;&#31216;&#24615;&#21644;&#20960;&#20309;&#24615;&#32771;&#34385;&#20026;&#32534;&#30721;&#22312;&#31070;&#32463;&#32593;&#32476;&#20869;&#37096;&#25968;&#25454;&#34920;&#31034;&#20013;&#65292;&#20294;&#26159;&#20855;&#20307;&#30340;&#32534;&#30721;&#35268;&#21017;&#36824;&#27809;&#26377;&#24471;&#21040;&#28145;&#20837;&#30740;&#31350;&#12290;&#36890;&#36807;&#20851;&#27880;&#25968;&#25454;-&#21442;&#25968;&#22495;&#19978;&#30340;&#32852;&#21512;&#32676;&#19981;&#21464;&#20989;&#25968;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31995;&#32479;&#30340;&#35268;&#21017;&#65292;&#20174;&#25968;&#25454;&#22495;&#19978;&#30340;&#32676;&#20316;&#29992;&#20013;&#25214;&#21040;&#21442;&#25968;&#22495;&#19978;&#30340;&#21452;&#37325;&#32676;&#20316;&#29992;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#30001;&#32852;&#21512;&#19981;&#21464;&#20989;&#25968;&#23548;&#20986;&#30340;&#24191;&#20041;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#21033;&#29992;Schur&#24341;&#29702;&#32473;&#20986;&#20102;&#23427;&#20204;&#30340;&#26222;&#36941;&#24615;&#23450;&#29702;&#30340;&#26032;&#30340;&#32676;&#35770;&#35777;&#26126;&#12290;&#30001;&#20110;&#20256;&#32479;&#30340;&#26222;&#36941;&#24615;&#23450;&#29702;&#26159;&#22522;&#20110;&#20989;&#25968;&#20998;&#26512;&#26041;&#27861;&#36827;&#34892;&#35777;&#26126;&#30340;&#65292;&#36825;&#39033;&#30740;&#31350;&#25581;&#31034;&#20102;&#36924;&#36817;&#29702;&#35770;&#30340;&#32676;&#35770;&#26041;&#38754;&#65292;&#23558;&#20960;&#20309;&#28145;&#24230;&#23398;&#20064;&#19982;&#25277;&#35937;&#35843;&#21644;&#20998;&#26512;&#30456;&#36830;&#25509;&#12290;
&lt;/p&gt;
&lt;p&gt;
The symmetry and geometry of input data are considered to be encoded in the internal data representation inside the neural network, but the specific encoding rule has been less investigated. By focusing on a joint group invariant function on the data-parameter domain, we present a systematic rule to find a dual group action on the parameter domain from a group action on the data domain. Further, we introduce generalized neural networks induced from the joint invariant functions, and present a new group theoretic proof of their universality theorems by using Schur's lemma. Since traditional universality theorems were demonstrated based on functional analytical methods, this study sheds light on the group theoretic aspect of the approximation theory, connecting geometric deep learning to abstract harmonic analysis.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23545;&#25968;&#25454;&#31354;&#38388;&#19978;&#30340;&#32676;&#20316;&#29992;&#26469;&#35782;&#21035;DNN&#20869;&#37096;&#30340;&#38544;&#34255;&#23618;&#65292;&#24182;&#23558;DNN&#26500;&#24314;&#20026;&#30456;&#23545;&#20110;Koopman&#31639;&#23376;&#30340;&#21452;&#22768;&#21464;&#25442;&#65292;&#25105;&#20204;&#21033;&#29992;&#32676;&#35770;&#35770;&#35777;&#35777;&#26126;&#20102;&#36825;&#20123;DNN&#30340;&#26222;&#36866;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.03529</link><description>&lt;p&gt;
&#28145;&#24230;&#33034;&#27874;&#21464;&#25442;&#65306;&#20351;&#29992;Koopman&#31639;&#23376;&#35777;&#26126;&#20102;&#24418;&#24335;&#28145;&#24230;&#32593;&#32476;&#30340;&#26222;&#36866;&#24615;
&lt;/p&gt;
&lt;p&gt;
Deep Ridgelet Transform: Voice with Koopman Operator Proves Universality of Formal Deep Networks. (arXiv:2310.03529v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03529
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;&#25968;&#25454;&#31354;&#38388;&#19978;&#30340;&#32676;&#20316;&#29992;&#26469;&#35782;&#21035;DNN&#20869;&#37096;&#30340;&#38544;&#34255;&#23618;&#65292;&#24182;&#23558;DNN&#26500;&#24314;&#20026;&#30456;&#23545;&#20110;Koopman&#31639;&#23376;&#30340;&#21452;&#22768;&#21464;&#25442;&#65292;&#25105;&#20204;&#21033;&#29992;&#32676;&#35770;&#35770;&#35777;&#35777;&#26126;&#20102;&#36825;&#20123;DNN&#30340;&#26222;&#36866;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#36890;&#36807;&#23545;&#25968;&#25454;&#31354;&#38388;&#19978;&#30340;&#32676;&#20316;&#29992;&#26469;&#35782;&#21035;DNN&#20869;&#37096;&#30340;&#38544;&#34255;&#23618;&#65292;&#24182;&#23558;DNN&#26500;&#24314;&#20026;&#30456;&#23545;&#20110;Koopman&#31639;&#23376;&#30340;&#21452;&#22768;&#21464;&#25442;&#65292;Koopman&#31639;&#23376;&#26159;&#32676;&#20316;&#29992;&#30340;&#32447;&#24615;&#34920;&#31034;&#12290;&#22522;&#20110;&#32676;&#35770;&#35770;&#35777;&#65292;&#29305;&#21035;&#26159;&#21033;&#29992;Schur&#24341;&#29702;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#36825;&#20123;DNN&#26222;&#36866;&#24615;&#30340;&#31616;&#21333;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
We identify hidden layers inside a DNN with group actions on the data space, and formulate the DNN as a dual voice transform with respect to Koopman operator, a linear representation of the group action. Based on the group theoretic arguments, particularly by using Schur's lemma, we show a simple proof of the universality of those DNNs.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;&#29983;&#25104;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#21644;&#20915;&#31574;&#29702;&#35770;&#30456;&#32467;&#21512;&#30340;&#26032;&#26694;&#26550;&#65292;&#29992;&#20110;&#29983;&#25104;&#20010;&#24615;&#21270;&#30340;&#33008;&#23707;&#32032;&#27835;&#30103;&#31574;&#30053;&#12290;&#36890;&#36807;&#23398;&#20064;&#29983;&#25104;&#36924;&#30495;&#30340;&#20010;&#24615;&#21270;&#27835;&#30103;&#21644;&#26410;&#26469;&#32467;&#26524;&#36712;&#36857;&#65292;&#21487;&#20197;&#20026;&#20010;&#24615;&#21270;&#24739;&#32773;&#21382;&#21490;&#21305;&#37197;&#19988;&#38024;&#23545;&#26368;&#20339;&#26410;&#26469;&#25928;&#26524;&#30340;&#26032;&#22411;&#22810;&#21464;&#37327;&#27835;&#30103;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2309.16521</link><description>&lt;p&gt;
&#20351;&#29992;&#28145;&#24230;&#26465;&#20214;&#29983;&#25104;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#29983;&#25104;&#20010;&#24615;&#21270;&#30340;&#33008;&#23707;&#32032;&#27835;&#30103;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Generating Personalized Insulin Treatments Strategies with Deep Conditional Generative Time Series Models. (arXiv:2309.16521v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16521
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;&#29983;&#25104;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#21644;&#20915;&#31574;&#29702;&#35770;&#30456;&#32467;&#21512;&#30340;&#26032;&#26694;&#26550;&#65292;&#29992;&#20110;&#29983;&#25104;&#20010;&#24615;&#21270;&#30340;&#33008;&#23707;&#32032;&#27835;&#30103;&#31574;&#30053;&#12290;&#36890;&#36807;&#23398;&#20064;&#29983;&#25104;&#36924;&#30495;&#30340;&#20010;&#24615;&#21270;&#27835;&#30103;&#21644;&#26410;&#26469;&#32467;&#26524;&#36712;&#36857;&#65292;&#21487;&#20197;&#20026;&#20010;&#24615;&#21270;&#24739;&#32773;&#21382;&#21490;&#21305;&#37197;&#19988;&#38024;&#23545;&#26368;&#20339;&#26410;&#26469;&#25928;&#26524;&#30340;&#26032;&#22411;&#22810;&#21464;&#37327;&#27835;&#30103;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#23558;&#28145;&#24230;&#29983;&#25104;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#19982;&#20915;&#31574;&#29702;&#35770;&#30456;&#32467;&#21512;&#65292;&#29992;&#20110;&#29983;&#25104;&#20010;&#24615;&#21270;&#30340;&#27835;&#30103;&#31574;&#30053;&#12290;&#23427;&#21033;&#29992;&#21382;&#21490;&#24739;&#32773;&#36712;&#36857;&#25968;&#25454;&#65292;&#36890;&#36807;&#28145;&#24230;&#29983;&#25104;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#20849;&#21516;&#23398;&#20064;&#29983;&#25104;&#36924;&#30495;&#30340;&#20010;&#24615;&#21270;&#27835;&#30103;&#21644;&#26410;&#26469;&#32467;&#26524;&#36712;&#36857;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#26681;&#25454;&#26465;&#20214;&#21270;&#26399;&#26395;&#25928;&#29992;&#26368;&#22823;&#21270;&#35757;&#32451;&#29983;&#25104;&#19982;&#20010;&#24615;&#21270;&#24739;&#32773;&#21382;&#21490;&#21305;&#37197;&#19988;&#38024;&#23545;&#26368;&#20339;&#26410;&#26469;&#25928;&#26524;&#30340;&#26032;&#22411;&#22810;&#21464;&#37327;&#27835;&#30103;&#31574;&#30053;&#12290;&#25105;&#20204;&#36890;&#36807;&#20026;&#20303;&#38498;&#31958;&#23615;&#30149;&#24739;&#32773;&#29983;&#25104;&#20010;&#24615;&#21270;&#30340;&#33008;&#23707;&#32032;&#27835;&#30103;&#31574;&#30053;&#21644;&#34880;&#31958;&#39044;&#27979;&#26469;&#23637;&#31034;&#25105;&#20204;&#30340;&#26694;&#26550;&#65292;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#29983;&#25104;&#25913;&#36827;&#30340;&#20010;&#24615;&#21270;&#27835;&#30103;&#31574;&#30053;&#26041;&#38754;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel framework that combines deep generative time series models with decision theory for generating personalized treatment strategies. It leverages historical patient trajectory data to jointly learn the generation of realistic personalized treatment and future outcome trajectories through deep generative time series models. In particular, our framework enables the generation of novel multivariate treatment strategies tailored to the personalized patient history and trained for optimal expected future outcomes based on conditional expected utility maximization. We demonstrate our framework by generating personalized insulin treatment strategies and blood glucose predictions for hospitalized diabetes patients, showcasing the potential of our approach for generating improved personalized treatment strategies. Keywords: deep generative model, probabilistic decision support, personalized treatment generation, insulin and blood glucose prediction
&lt;/p&gt;</description></item><item><title>ODTlearn&#26159;&#19968;&#20010;&#24320;&#28304;&#30340;Python&#21253;&#65292;&#29992;&#20110;&#23398;&#20064;&#39044;&#27979;&#21644;&#22788;&#26041;&#30340;&#26368;&#20248;&#20915;&#31574;&#26641;&#12290;&#23427;&#25552;&#20379;&#20102;&#22810;&#31181;&#20248;&#21270;&#26041;&#27861;&#65292;&#24182;&#25903;&#25345;&#21508;&#31181;&#38382;&#39064;&#21644;&#31639;&#27861;&#30340;&#25193;&#23637;&#12290;</title><link>http://arxiv.org/abs/2307.15691</link><description>&lt;p&gt;
ODTlearn: &#19968;&#20010;&#29992;&#20110;&#23398;&#20064;&#39044;&#27979;&#21644;&#22788;&#26041;&#30340;&#26368;&#20248;&#20915;&#31574;&#26641;&#30340;&#21253;
&lt;/p&gt;
&lt;p&gt;
ODTlearn: A Package for Learning Optimal Decision Trees for Prediction and Prescription. (arXiv:2307.15691v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15691
&lt;/p&gt;
&lt;p&gt;
ODTlearn&#26159;&#19968;&#20010;&#24320;&#28304;&#30340;Python&#21253;&#65292;&#29992;&#20110;&#23398;&#20064;&#39044;&#27979;&#21644;&#22788;&#26041;&#30340;&#26368;&#20248;&#20915;&#31574;&#26641;&#12290;&#23427;&#25552;&#20379;&#20102;&#22810;&#31181;&#20248;&#21270;&#26041;&#27861;&#65292;&#24182;&#25903;&#25345;&#21508;&#31181;&#38382;&#39064;&#21644;&#31639;&#27861;&#30340;&#25193;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
ODTLearn&#26159;&#19968;&#20010;&#24320;&#28304;&#30340;Python&#21253;&#65292;&#25552;&#20379;&#20102;&#22522;&#20110;&#28151;&#21512;&#25972;&#25968;&#20248;&#21270;(MIO)&#26694;&#26550;&#30340;&#39640;&#39118;&#38505;&#39044;&#27979;&#21644;&#22788;&#26041;&#20219;&#21153;&#30340;&#26368;&#20248;&#20915;&#31574;&#26641;&#23398;&#20064;&#26041;&#27861;&#12290;&#35813;&#21253;&#30340;&#24403;&#21069;&#29256;&#26412;&#25552;&#20379;&#20102;&#23398;&#20064;&#26368;&#20248;&#20998;&#31867;&#26641;&#12289;&#20844;&#24179;&#26368;&#20248;&#20998;&#31867;&#26641;&#12289;&#40065;&#26834;&#26368;&#20248;&#20998;&#31867;&#26641;&#21644;&#20174;&#35266;&#27979;&#25968;&#25454;&#23398;&#20064;&#26368;&#20248;&#22788;&#26041;&#26641;&#30340;&#23454;&#29616;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#35813;&#21253;&#20197;&#20415;&#20110;&#32500;&#25252;&#21644;&#25193;&#23637;&#65292;&#24403;&#24341;&#20837;&#26032;&#30340;&#26368;&#20248;&#20915;&#31574;&#26641;&#38382;&#39064;&#31867;&#12289;&#37325;&#26500;&#31574;&#30053;&#21644;&#35299;&#20915;&#31639;&#27861;&#26102;&#65292;&#21487;&#20197;&#36731;&#26494;&#26356;&#26032;&#12290;&#20026;&#27492;&#65292;&#35813;&#21253;&#36981;&#24490;&#38754;&#21521;&#23545;&#35937;&#30340;&#35774;&#35745;&#21407;&#21017;&#65292;&#24182;&#25903;&#25345;&#21830;&#19994;(Gurobi)&#21644;&#24320;&#28304;(COIN-OR branch and cut)&#27714;&#35299;&#22120;&#12290;&#21253;&#30340;&#25991;&#26723;&#21644;&#35814;&#32454;&#29992;&#25143;&#25351;&#21335;&#21487;&#20197;&#22312;https://d3m-research-group.github.io/odtlearn/&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
ODTLearn is an open-source Python package that provides methods for learning optimal decision trees for high-stakes predictive and prescriptive tasks based on the mixed-integer optimization (MIO) framework proposed in Aghaei et al. (2019) and several of its extensions. The current version of the package provides implementations for learning optimal classification trees, optimal fair classification trees, optimal classification trees robust to distribution shifts, and optimal prescriptive trees from observational data. We have designed the package to be easy to maintain and extend as new optimal decision tree problem classes, reformulation strategies, and solution algorithms are introduced. To this end, the package follows object-oriented design principles and supports both commercial (Gurobi) and open source (COIN-OR branch and cut) solvers. The package documentation and an extensive user guide can be found at https://d3m-research-group.github.io/odtlearn/. Additionally, users can view
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#24615;&#36172;&#21338;&#26426;&#20013;&#36827;&#34892;&#20219;&#24847;&#27169;&#22411;&#36873;&#25321;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#27169;&#25311;&#20840;&#20449;&#24687;&#21453;&#39304;&#23454;&#29616;&#22312;&#36951;&#25022;&#26041;&#38754;&#20855;&#26377;&#25351;&#25968;&#25913;&#36827;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#19981;&#20381;&#36182;&#26102;&#38388;&#30028;&#38480;&#21644;&#32431;&#25506;&#32034;&#38454;&#27573;&#12290;</title><link>http://arxiv.org/abs/2307.12897</link><description>&lt;p&gt;
&#32447;&#24615;&#36172;&#21338;&#26426;&#20013;&#30340;&#20219;&#24847;&#27169;&#22411;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Anytime Model Selection in Linear Bandits. (arXiv:2307.12897v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12897
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#24615;&#36172;&#21338;&#26426;&#20013;&#36827;&#34892;&#20219;&#24847;&#27169;&#22411;&#36873;&#25321;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#27169;&#25311;&#20840;&#20449;&#24687;&#21453;&#39304;&#23454;&#29616;&#22312;&#36951;&#25022;&#26041;&#38754;&#20855;&#26377;&#25351;&#25968;&#25913;&#36827;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#19981;&#20381;&#36182;&#26102;&#38388;&#30028;&#38480;&#21644;&#32431;&#25506;&#32034;&#38454;&#27573;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36172;&#21338;&#20248;&#21270;&#20013;&#65292;&#27169;&#22411;&#36873;&#25321;&#26159;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#65292;&#22240;&#20026;&#23427;&#19981;&#20165;&#38656;&#35201;&#22312;&#34892;&#21160;&#36873;&#25321;&#26041;&#38754;&#24179;&#34913;&#25506;&#32034;&#21644;&#24320;&#21457;&#65292;&#36824;&#38656;&#35201;&#22312;&#27169;&#22411;&#36873;&#25321;&#26041;&#38754;&#24179;&#34913;&#25506;&#32034;&#21644;&#24320;&#21457;&#12290;&#19968;&#31181;&#33258;&#28982;&#30340;&#26041;&#27861;&#26159;&#20381;&#36182;&#20110;&#23558;&#19981;&#21516;&#27169;&#22411;&#35270;&#20026;&#19987;&#23478;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#22312;&#36951;&#25022;&#26041;&#38754;&#19982;&#27169;&#22411;&#25968;&#37327;$M$&#30340;&#35268;&#27169;&#65288;$\text{poly}M$&#65289;&#21576;&#19981;&#33391;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#27934;&#23519;&#26159;&#65292;&#22312;&#32447;&#24615;&#36172;&#21338;&#26426;&#30340;&#27169;&#22411;&#36873;&#25321;&#20013;&#65292;&#25105;&#20204;&#21487;&#20197;&#36890;&#36807;&#26377;&#21033;&#30340;&#20559;&#24046;-&#26041;&#24046;&#26435;&#34913;&#26469;&#27169;&#25311;&#20840;&#20449;&#24687;&#21453;&#39304;&#32473;&#22312;&#32447;&#23398;&#20064;&#32773;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#24320;&#21457;&#20986;&#20855;&#26377;&#25351;&#25968;&#25913;&#36827;&#65288;$\log M$&#65289;&#22312;&#36951;&#25022;&#26041;&#38754;&#23545;$M$&#20381;&#36182;&#24615;&#30340;ALEXP&#12290;ALEXP&#22312;&#36951;&#25022;&#26041;&#38754;&#20855;&#26377;&#20219;&#24847;&#20445;&#35777;&#65292;&#24182;&#19988;&#26082;&#19981;&#38656;&#35201;&#23545;&#26102;&#38388;&#30028;$n$&#20855;&#26377;&#30693;&#35782;&#65292;&#20063;&#19981;&#20381;&#36182;&#20110;&#21021;&#22987;&#30340;&#32431;&#25506;&#32034;&#38454;&#27573;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#20102;Lasso&#30340;&#19968;&#31181;&#26032;&#39062;&#30340;&#26102;&#38388;&#22343;&#21248;&#20998;&#26512;&#65292;&#24314;&#31435;&#20102;&#22312;&#32447;&#23398;&#20064;&#21644;&#39640;&#32500;&#32479;&#35745;&#20043;&#38388;&#30340;&#26032;&#36830;&#25509;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model selection in the context of bandit optimization is a challenging problem, as it requires balancing exploration and exploitation not only for action selection, but also for model selection. One natural approach is to rely on online learning algorithms that treat different models as experts. Existing methods, however, scale poorly ($\text{poly}M$) with the number of models $M$ in terms of their regret. Our key insight is that, for model selection in linear bandits, we can emulate full-information feedback to the online learner with a favorable bias-variance trade-off. This allows us to develop ALEXP, which has an exponentially improved ($\log M$) dependence on $M$ for its regret. ALEXP has anytime guarantees on its regret, and neither requires knowledge of the horizon $n$, nor relies on an initial purely exploratory stage. Our approach utilizes a novel time-uniform analysis of the Lasso, establishing a new connection between online learning and high-dimensional statistics.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;&#29289;&#29702;&#20449;&#30693;&#30340;&#31070;&#32463;&#32593;&#32476;(PINNs)&#35299;&#20915;&#39640;&#32500;&#24230;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;(PDEs)&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#25910;&#25947;&#24615;&#21644;&#20854;&#20182;&#26399;&#26395;&#23646;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.12306</link><description>&lt;p&gt;
&#29992;&#29289;&#29702;&#20449;&#30693;&#30340;&#31070;&#32463;&#32593;&#32476;&#35299;&#20915;&#32500;&#24230;&#35781;&#21650;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Tackling the Curse of Dimensionality with Physics-Informed Neural Networks. (arXiv:2307.12306v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12306
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;&#29289;&#29702;&#20449;&#30693;&#30340;&#31070;&#32463;&#32593;&#32476;(PINNs)&#35299;&#20915;&#39640;&#32500;&#24230;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;(PDEs)&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#25910;&#25947;&#24615;&#21644;&#20854;&#20182;&#26399;&#26395;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32500;&#24230;&#35781;&#21650;(CoD)&#38543;&#30528;&#32500;&#24230;&#30340;&#22686;&#21152;&#65292;&#20197;&#25351;&#25968;&#32423;&#22686;&#38271;&#30340;&#35745;&#31639;&#25104;&#26412;&#26469;&#26497;&#24230;&#31246;&#36153;&#35745;&#31639;&#36164;&#28304;&#12290;&#36825;&#22312;&#35299;&#20915;&#39640;&#32500;&#20559;&#24494;&#20998;&#26041;&#31243;(PDEs)&#20013;&#38754;&#20020;&#26497;&#22823;&#25361;&#25112;&#65292;&#27491;&#22914;Richard Bellman&#22312;60&#24180;&#21069;&#39318;&#27425;&#25351;&#20986;&#30340;&#37027;&#26679;&#12290;&#23613;&#31649;&#36817;&#24180;&#26469;&#22312;&#39640;&#32500;&#24230;&#19978;&#25968;&#20540;&#35299;&#20915;&#20559;&#24494;&#20998;&#26041;&#31243;(PDEs)&#21462;&#24471;&#20102;&#19968;&#20123;&#25104;&#21151;&#65292;&#20294;&#36825;&#26679;&#30340;&#35745;&#31639;&#20195;&#20215;&#36807;&#39640;&#65292;&#32780;&#23558;&#19968;&#33324;&#38750;&#32447;&#24615;PDEs&#25193;&#23637;&#21040;&#39640;&#32500;&#24230;&#20174;&#26410;&#23454;&#29616;&#36807;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#23558;&#29289;&#29702;&#20449;&#30693;&#30340;&#31070;&#32463;&#32593;&#32476;(PINNs)&#25193;&#23637;&#21040;&#35299;&#20915;&#20219;&#24847;&#39640;&#32500;PDEs&#12290;&#35813;&#26032;&#26041;&#27861;&#31216;&#20026;&#38543;&#26426;&#32500;&#24230;&#26799;&#24230;&#19979;&#38477;(SDGD)&#65292;&#23558;PDE&#30340;&#26799;&#24230;&#20998;&#35299;&#20026;&#19982;&#19981;&#21516;&#32500;&#24230;&#23545;&#24212;&#30340;&#37096;&#20998;&#65292;&#24182;&#22312;&#35757;&#32451;PINNs&#30340;&#27599;&#27425;&#36845;&#20195;&#20013;&#38543;&#26426;&#36873;&#25321;&#36825;&#20123;&#32500;&#24230;&#37096;&#20998;&#30340;&#23376;&#38598;&#36827;&#34892;&#37319;&#26679;&#12290;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#25910;&#25947;&#20445;&#35777;&#21644;&#20854;&#20182;&#26399;&#26395;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The curse-of-dimensionality (CoD) taxes computational resources heavily with exponentially increasing computational cost as the dimension increases. This poses great challenges in solving high-dimensional PDEs as Richard Bellman first pointed out over 60 years ago. While there has been some recent success in solving numerically partial differential equations (PDEs) in high dimensions, such computations are prohibitively expensive, and true scaling of general nonlinear PDEs to high dimensions has never been achieved. In this paper, we develop a new method of scaling up physics-informed neural networks (PINNs) to solve arbitrary high-dimensional PDEs. The new method, called Stochastic Dimension Gradient Descent (SDGD), decomposes a gradient of PDEs into pieces corresponding to different dimensions and samples randomly a subset of these dimensional pieces in each iteration of training PINNs. We theoretically prove the convergence guarantee and other desired properties of the proposed meth
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#32467;&#26500;&#21270;&#25903;&#25345;&#21521;&#37327;&#26426;&#30340;&#25509;&#36817;&#32447;&#24615;&#26102;&#38388;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#20108;&#27425;&#35268;&#21010;&#36755;&#20837;&#35268;&#27169;&#21644;&#35299;&#20915;&#26102;&#38388;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.07735</link><description>&lt;p&gt;
&#32467;&#26500;&#21270;&#25903;&#25345;&#21521;&#37327;&#26426;&#30340;&#25509;&#36817;&#32447;&#24615;&#26102;&#38388;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Nearly-Linear Time Algorithm for Structured Support Vector Machines. (arXiv:2307.07735v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07735
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#32467;&#26500;&#21270;&#25903;&#25345;&#21521;&#37327;&#26426;&#30340;&#25509;&#36817;&#32447;&#24615;&#26102;&#38388;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#20108;&#27425;&#35268;&#21010;&#36755;&#20837;&#35268;&#27169;&#21644;&#35299;&#20915;&#26102;&#38388;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20108;&#27425;&#35268;&#21010;&#26159;&#20984;&#20248;&#21270;&#39046;&#22495;&#20013;&#30340;&#22522;&#26412;&#38382;&#39064;&#12290;&#35768;&#22810;&#23454;&#38469;&#20219;&#21153;&#21487;&#20197;&#34920;&#31034;&#20026;&#20108;&#27425;&#35268;&#21010;&#65292;&#20363;&#22914;&#25903;&#25345;&#21521;&#37327;&#26426;&#65288;SVM&#65289;&#12290;&#22312;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#30427;&#34892;&#20043;&#21069;&#65292;&#32447;&#24615;SVM&#26159;&#36807;&#21435;&#19977;&#21313;&#24180;&#26469;&#26368;&#27969;&#34892;&#30340;&#26426;&#22120;&#23398;&#20064;&#24037;&#20855;&#20043;&#19968;&#12290;&#19968;&#33324;&#26469;&#35828;&#65292;&#19968;&#20010;&#20108;&#27425;&#35268;&#21010;&#30340;&#36755;&#20837;&#35268;&#27169;&#20026;&#920;(n^2)&#65288;&#20854;&#20013;n&#26159;&#21464;&#37327;&#30340;&#25968;&#37327;&#65289;&#65292;&#22240;&#27492;&#35299;&#20915;&#35813;&#38382;&#39064;&#38656;&#35201;&#937;(n^2)&#30340;&#26102;&#38388;&#12290;&#28982;&#32780;&#65292;SVM&#20135;&#29983;&#30340;&#20108;&#27425;&#35268;&#21010;&#30340;&#36755;&#20837;&#35268;&#27169;&#20026;O(n)&#65292;&#36825;&#20351;&#24471;&#35774;&#35745;&#25509;&#36817;&#32447;&#24615;&#26102;&#38388;&#31639;&#27861;&#25104;&#20026;&#21487;&#33021;&#12290;&#20004;&#20010;&#37325;&#35201;&#30340;SVM&#31867;&#21035;&#26159;&#20855;&#26377;&#20302;&#31209;&#26680;&#22240;&#24335;&#20998;&#35299;&#21644;&#20302;&#26641;&#23485;&#35268;&#27169;&#30340;&#31243;&#24207;&#12290;&#20302;&#26641;&#23485;&#20984;&#20248;&#21270;&#22312;&#36807;&#21435;&#20960;&#24180;&#20013;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#65288;&#20363;&#22914;&#32447;&#24615;&#35268;&#21010;[Dong, Lee and Ye 2021]&#21644;&#21322;&#23450;&#35268;&#21010;[Gu and Song 2022]&#65289;&#12290;&#22240;&#27492;&#65292;&#19968;&#20010;&#37325;&#35201;&#30340;&#24320;&#25918;&#38382;&#39064;&#26159;&#26159;&#21542;&#23384;&#22312;&#25509;&#36817;&#32447;&#24615;&#26102;&#38388;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quadratic programming is a fundamental problem in the field of convex optimization. Many practical tasks can be formulated as quadratic programming, for example, the support vector machine (SVM). Linear SVM is one of the most popular tools over the last three decades in machine learning before deep learning method dominating.  In general, a quadratic program has input size $\Theta(n^2)$ (where $n$ is the number of variables), thus takes $\Omega(n^2)$ time to solve. Nevertheless, quadratic programs coming from SVMs has input size $O(n)$, allowing the possibility of designing nearly-linear time algorithms. Two important classes of SVMs are programs admitting low-rank kernel factorizations and low-treewidth programs. Low-treewidth convex optimization has gained increasing interest in the past few years (e.g.~linear programming [Dong, Lee and Ye 2021] and semidefinite programming [Gu and Song 2022]). Therefore, an important open question is whether there exist nearly-linear time algorithms
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;PCA&#26041;&#27861;&#65292;&#21487;&#20197;&#20272;&#35745;&#26679;&#26412;&#30340;&#22122;&#22768;&#26041;&#24046;&#65292;&#20174;&#32780;&#25913;&#36827;&#19982;&#25968;&#25454;&#30340;&#20302;&#31209;&#32467;&#26500;&#30456;&#20851;&#30340;&#23376;&#31354;&#38388;&#22522;&#30784;&#30340;&#20272;&#35745;&#20540;&#12290;</title><link>http://arxiv.org/abs/2307.02745</link><description>&lt;p&gt;
ALPCAH&#65306;&#20855;&#26377;&#23614;&#37096;&#22855;&#24322;&#20540;&#27491;&#21017;&#21270;&#30340;&#26679;&#26412;&#24322;&#26041;&#24046;PCA
&lt;/p&gt;
&lt;p&gt;
ALPCAH: Sample-wise Heteroscedastic PCA with Tail Singular Value Regularization. (arXiv:2307.02745v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02745
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;PCA&#26041;&#27861;&#65292;&#21487;&#20197;&#20272;&#35745;&#26679;&#26412;&#30340;&#22122;&#22768;&#26041;&#24046;&#65292;&#20174;&#32780;&#25913;&#36827;&#19982;&#25968;&#25454;&#30340;&#20302;&#31209;&#32467;&#26500;&#30456;&#20851;&#30340;&#23376;&#31354;&#38388;&#22522;&#30784;&#30340;&#20272;&#35745;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#26159;&#25968;&#25454;&#38477;&#32500;&#39046;&#22495;&#20013;&#30340;&#20851;&#38190;&#24037;&#20855;&#65292;&#23545;&#20110;&#21508;&#31181;&#25968;&#25454;&#31185;&#23398;&#38382;&#39064;&#37117;&#38750;&#24120;&#26377;&#29992;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#24212;&#29992;&#28041;&#21450;&#21040;&#20855;&#26377;&#19981;&#21516;&#25968;&#25454;&#28304;&#30340;&#22122;&#22768;&#29305;&#24615;&#23548;&#33268;&#36136;&#37327;&#19981;&#22343;&#21248;&#30340;&#24322;&#36136;&#25968;&#25454;&#12290;&#22788;&#29702;&#36825;&#31181;&#28151;&#21512;&#25968;&#25454;&#38598;&#30340;&#26041;&#27861;&#34987;&#31216;&#20026;&#24322;&#26041;&#24046;&#26041;&#27861;&#12290;&#24403;&#21069;&#30340;&#26041;&#27861;&#22914;HePPCAT&#20551;&#35774;&#22522;&#30784;&#31995;&#25968;&#20026;&#39640;&#26031;&#20998;&#24067;&#65292;&#20294;&#22312;&#23454;&#36341;&#20013;&#21487;&#33021;&#19981;&#25104;&#31435;&#12290;&#20854;&#20182;&#26041;&#27861;&#22914;&#21152;&#26435;PCA&#65288;WPCA&#65289;&#20551;&#35774;&#22122;&#22768;&#26041;&#24046;&#24050;&#30693;&#65292;&#20294;&#22312;&#23454;&#36341;&#20013;&#24456;&#38590;&#30830;&#23450;&#12290;&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;PCA&#26041;&#27861;&#65292;&#21487;&#20197;&#20272;&#35745;&#26679;&#26412;&#30340;&#22122;&#22768;&#26041;&#24046;&#65292;&#24182;&#23558;&#36825;&#20123;&#20449;&#24687;&#29992;&#20110;&#27169;&#22411;&#20013;&#65292;&#20197;&#25913;&#36827;&#19982;&#25968;&#25454;&#30340;&#20302;&#31209;&#32467;&#26500;&#30456;&#20851;&#30340;&#23376;&#31354;&#38388;&#22522;&#30784;&#30340;&#20272;&#35745;&#20540;&#12290;&#36825;&#26679;&#20570;&#19981;&#38656;&#35201;&#23545;&#20302;&#31209;&#25104;&#20998;&#36827;&#34892;&#20998;&#24067;&#20551;&#35774;&#65292;&#20063;&#19981;&#38656;&#35201;&#20551;&#35774;&#22122;&#22768;&#26041;&#24046;&#24050;&#30693;&#12290;&#27169;&#25311;&#23454;&#39564;&#26174;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Principal component analysis (PCA) is a key tool in the field of data dimensionality reduction that is useful for various data science problems. However, many applications involve heterogeneous data that varies in quality due to noise characteristics associated with different sources of the data. Methods that deal with this mixed dataset are known as heteroscedastic methods. Current methods like HePPCAT make Gaussian assumptions of the basis coefficients that may not hold in practice. Other methods such as Weighted PCA (WPCA) assume the noise variances are known, which may be difficult to know in practice. This paper develops a PCA method that can estimate the sample-wise noise variances and use this information in the model to improve the estimate of the subspace basis associated with the low-rank structure of the data. This is done without distributional assumptions of the low-rank component and without assuming the noise variances are known. Simulations show the effectiveness of acc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20840;&#38754;&#20171;&#32461;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#26799;&#24230;&#28040;&#22833;&#21644;&#26799;&#24230;&#29190;&#28856;&#31561;&#20248;&#21270;&#25361;&#25112;&#65292;&#24182;&#36890;&#36807;&#25552;&#39640;&#26799;&#24230;&#27969;&#21644;&#23545;&#32593;&#32476;Lipschitz&#24120;&#25968;&#26045;&#21152;&#32422;&#26463;&#31561;&#25514;&#26045;&#36827;&#34892;&#20102;&#35299;&#20915;&#12290;&#26174;&#24335;&#20248;&#21270;&#21644;&#38544;&#24335;&#20248;&#21270;&#26159;&#20004;&#31181;&#35299;&#20915;&#20248;&#21270;&#38382;&#39064;&#30340;&#19981;&#21516;&#26041;&#24335;&#12290;</title><link>http://arxiv.org/abs/2306.09338</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#30340;&#20248;&#21270;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
Understanding Optimization of Deep Learning. (arXiv:2306.09338v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09338
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20840;&#38754;&#20171;&#32461;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#26799;&#24230;&#28040;&#22833;&#21644;&#26799;&#24230;&#29190;&#28856;&#31561;&#20248;&#21270;&#25361;&#25112;&#65292;&#24182;&#36890;&#36807;&#25552;&#39640;&#26799;&#24230;&#27969;&#21644;&#23545;&#32593;&#32476;Lipschitz&#24120;&#25968;&#26045;&#21152;&#32422;&#26463;&#31561;&#25514;&#26045;&#36827;&#34892;&#20102;&#35299;&#20915;&#12290;&#26174;&#24335;&#20248;&#21270;&#21644;&#38544;&#24335;&#20248;&#21270;&#26159;&#20004;&#31181;&#35299;&#20915;&#20248;&#21270;&#38382;&#39064;&#30340;&#19981;&#21516;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20840;&#38754;&#20171;&#32461;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#20248;&#21270;&#29702;&#35770;&#65292;&#20027;&#35201;&#20851;&#27880;&#26799;&#24230;&#28040;&#22833;&#21644;&#26799;&#24230;&#29190;&#28856;&#31561;&#38382;&#39064;&#25152;&#24102;&#26469;&#30340;&#27169;&#22411;&#34920;&#31034;&#33021;&#21147;&#38477;&#20302;&#21644;&#35757;&#32451;&#19981;&#31283;&#23450;&#24615;&#31561;&#25361;&#25112;&#12290;&#25105;&#20204;&#36890;&#36807;&#25552;&#39640;&#26799;&#24230;&#27969;&#21644;&#23545;&#32593;&#32476;Lipschitz &#24120;&#25968;&#26045;&#21152;&#32422;&#26463;&#31561;&#25514;&#26045;&#26469;&#20998;&#26512;&#36825;&#20004;&#20010;&#25361;&#25112;&#12290;&#20026;&#20102;&#24110;&#21161;&#29702;&#35299;&#24403;&#21069;&#30340;&#20248;&#21270;&#26041;&#27861;&#65292;&#25105;&#20204;&#23558;&#20854;&#20998;&#20026;&#26174;&#24335;&#20248;&#21270;&#26041;&#27861;&#21644;&#38544;&#24335;&#20248;&#21270;&#26041;&#27861;&#12290;&#26174;&#24335;&#20248;&#21270;&#26041;&#27861;&#28041;&#21450;&#30452;&#25509;&#25805;&#20316;&#20248;&#21270;&#22120;&#21442;&#25968;&#65292;&#21253;&#25324;&#26435;&#37325;&#12289;&#26799;&#24230;&#12289;&#23398;&#20064;&#29575;&#21644;&#26435;&#37325;&#34928;&#20943;&#31561;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#38544;&#24335;&#20248;&#21270;&#26041;&#27861;&#20391;&#37325;&#20110;&#36890;&#36807;&#22686;&#24378;&#32593;&#32476;&#27169;&#22359;&#65288;&#22914;&#27531;&#24046;&#24555;&#25463;&#26041;&#24335;&#12289;&#26631;&#20934;&#21270;&#26041;&#27861;&#12289;&#27880;&#24847;&#26426;&#21046;&#21644;&#28608;&#27963;&#65289;&#26469;&#25913;&#21892;&#32593;&#32476;&#25972;&#20307;&#24418;&#21183;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#28145;&#20837;&#30340;&#20998;&#26512;&#21644;&#23454;&#39564;&#65292;&#20197;&#24110;&#21161;&#30740;&#31350;&#20154;&#21592;&#26356;&#22909;&#22320;&#20102;&#35299;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#20248;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article provides a comprehensive understanding of optimization in deep learning, with a primary focus on the challenges of gradient vanishing and gradient exploding, which normally lead to diminished model representational ability and training instability, respectively. We analyze these two challenges through several strategic measures, including the improvement of gradient flow and the imposition of constraints on a network's Lipschitz constant. To help understand the current optimization methodologies, we categorize them into two classes: explicit optimization and implicit optimization. Explicit optimization methods involve direct manipulation of optimizer parameters, including weight, gradient, learning rate, and weight decay. Implicit optimization methods, by contrast, focus on improving the overall landscape of a network by enhancing its modules, such as residual shortcuts, normalization methods, attention mechanisms, and activations. In this article, we provide an in-depth a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#19968;&#31181;&#22522;&#20110;&#20027;&#21160;&#35810;&#38382;&#20915;&#31574;&#32773;&#20010;&#20154;&#20559;&#22909;&#30340;&#32622;&#20449;&#24230;&#26500;&#36896;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#32622;&#20449;&#24230;&#23545;&#20110;&#20915;&#31574;&#32773;&#20449;&#20219;&#20915;&#31574;&#30340;&#19981;&#20934;&#30830;&#38382;&#39064;&#65292;&#20174;&#32780;&#25552;&#39640;&#20915;&#31574;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2306.00074</link><description>&lt;p&gt;
&#20154;&#31867;&#23545;&#40784;&#26657;&#20934;&#29992;&#20110;AI&#36741;&#21161;&#20915;&#31574;&#21046;&#23450;
&lt;/p&gt;
&lt;p&gt;
Human-Aligned Calibration for AI-Assisted Decision Making. (arXiv:2306.00074v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00074
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#19968;&#31181;&#22522;&#20110;&#20027;&#21160;&#35810;&#38382;&#20915;&#31574;&#32773;&#20010;&#20154;&#20559;&#22909;&#30340;&#32622;&#20449;&#24230;&#26500;&#36896;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#32622;&#20449;&#24230;&#23545;&#20110;&#20915;&#31574;&#32773;&#20449;&#20219;&#20915;&#31574;&#30340;&#19981;&#20934;&#30830;&#38382;&#39064;&#65292;&#20174;&#32780;&#25552;&#39640;&#20915;&#31574;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#20351;&#29992;&#20108;&#20803;&#20998;&#31867;&#22120;&#25552;&#20379;&#20915;&#31574;&#25903;&#25345;&#26102;&#65292;&#23427;&#36890;&#24120;&#25552;&#20379;&#26631;&#31614;&#39044;&#27979;&#21644;&#32622;&#20449;&#24230;&#20540;&#12290;&#28982;&#21518;&#65292;&#20915;&#31574;&#32773;&#24212;&#20351;&#29992;&#32622;&#20449;&#24230;&#20540;&#26469;&#26657;&#20934;&#23545;&#39044;&#27979;&#30340;&#20449;&#20219;&#31243;&#24230;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#20154;&#20204;&#32463;&#24120;&#35748;&#20026;&#32622;&#20449;&#24230;&#20540;&#24212;&#23545;&#39044;&#27979;&#26631;&#31614;&#19982;&#23454;&#38469;&#26631;&#31614;&#21305;&#37197;&#30340;&#27010;&#29575;&#36827;&#34892;&#33391;&#22909;&#26657;&#20934;&#30340;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#22810;&#26465;&#23454;&#35777;&#35777;&#25454;&#34920;&#26126;&#65292;&#20915;&#31574;&#32773;&#38590;&#20197;&#20351;&#29992;&#36825;&#20123;&#32622;&#20449;&#24230;&#20540;&#24456;&#22909;&#22320;&#30830;&#23450;&#20309;&#26102;&#20449;&#20219;&#39044;&#27979;&#12290;&#26412;&#25991;&#30340;&#30446;&#26631;&#39318;&#20808;&#26159;&#29702;&#35299;&#20026;&#20160;&#20040;&#65292;&#28982;&#21518;&#30740;&#31350;&#22914;&#20309;&#26500;&#24314;&#26356;&#26377;&#29992;&#30340;&#32622;&#20449;&#24230;&#20540;&#12290;&#25105;&#20204;&#39318;&#20808;&#35748;&#20026;&#65292;&#22312;&#24191;&#27867;&#31867;&#30340;&#25928;&#29992;&#20989;&#25968;&#20013;&#65292;&#23384;&#22312;&#25968;&#25454;&#20998;&#24067;&#65292;&#23545;&#20110;&#36825;&#20123;&#20998;&#24067;&#65292;&#29702;&#24615;&#20915;&#31574;&#32773;&#36890;&#24120;&#38590;&#20197;&#20351;&#29992;&#20197;&#19978;&#32622;&#20449;&#24230;&#20540;&#21457;&#29616;&#26368;&#20339;&#20915;&#31574;&#25919;&#31574;&#8212;&#8212;&#26368;&#20339;&#30340;&#20915;&#31574;&#32773;&#38656;&#35201;&#20154;&#31867;&#23545;&#40784;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#20027;&#21160;&#35810;&#38382;&#20915;&#31574;&#32773;&#20182;&#20204;&#22312;&#25152;&#38754;&#20020;&#30340;&#20108;&#20803;&#20998;&#31867;&#20219;&#21153;&#30340;&#20915;&#31574;&#19978;&#30340;&#20010;&#20154;&#20559;&#22909;&#30340;&#26032;&#26041;&#27861;&#26469;&#26500;&#36896;&#32622;&#20449;&#24230;&#20540;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#20135;&#29983;&#30340;&#32622;&#20449;&#24230;&#20540;&#27604;&#20351;&#29992;&#26631;&#20934;&#32622;&#20449;&#24230;&#24230;&#37327;&#23548;&#33268;&#26356;&#22909;&#30340;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;
Whenever a binary classifier is used to provide decision support, it typically provides both a label prediction and a confidence value. Then, the decision maker is supposed to use the confidence value to calibrate how much to trust the prediction. In this context, it has been often argued that the confidence value should correspond to a well calibrated estimate of the probability that the predicted label matches the ground truth label. However, multiple lines of empirical evidence suggest that decision makers have difficulties at developing a good sense on when to trust a prediction using these confidence values. In this paper, our goal is first to understand why and then investigate how to construct more useful confidence values. We first argue that, for a broad class of utility functions, there exist data distributions for which a rational decision maker is, in general, unlikely to discover the optimal decision policy using the above confidence values -- an optimal decision maker wou
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#21160;&#37327;&#21305;&#37197;&#21435;&#22122;Gibbs&#37319;&#26679;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#32473;&#23450;&#8216;&#22024;&#26434;&#8217;&#30340;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#20174;&#24178;&#20928;&#30340;&#27169;&#22411;&#20013;&#26377;&#25928;&#22320;&#36827;&#34892;&#37319;&#26679;&#12290;</title><link>http://arxiv.org/abs/2305.11650</link><description>&lt;p&gt;
&#21160;&#37327;&#21305;&#37197;&#21435;&#22122;Gibbs&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Moment Matching Denoising Gibbs Sampling. (arXiv:2305.11650v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11650
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#21160;&#37327;&#21305;&#37197;&#21435;&#22122;Gibbs&#37319;&#26679;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#32473;&#23450;&#8216;&#22024;&#26434;&#8217;&#30340;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#20174;&#24178;&#20928;&#30340;&#27169;&#22411;&#20013;&#26377;&#25928;&#22320;&#36827;&#34892;&#37319;&#26679;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33021;&#37327;&#22522;&#27169;&#22411;&#65288;EBMs&#65289;&#20026;&#24314;&#27169;&#22797;&#26434;&#25968;&#25454;&#20998;&#24067;&#25552;&#20379;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#26694;&#26550;&#12290;&#28982;&#32780;&#65292;EBMs &#30340;&#35757;&#32451;&#21644;&#37319;&#26679;&#20173;&#28982;&#38754;&#20020;&#37325;&#22823;&#25361;&#25112;&#12290;&#29992;&#20110;&#21487;&#25193;&#23637; EBM &#35757;&#32451;&#30340;&#24191;&#27867;&#20351;&#29992;&#30340;&#21435;&#22122;&#20998;&#25968;&#21305;&#37197;&#65288;DSM&#65289;&#26041;&#27861;&#23384;&#22312;&#19981;&#19968;&#33268;&#24615;&#38382;&#39064;&#65292;&#23548;&#33268;&#33021;&#37327;&#27169;&#22411;&#23398;&#20064;&#21040;&#8220;&#22024;&#26434;&#8221;&#30340;&#25968;&#25454;&#20998;&#24067;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#37319;&#26679;&#26694;&#26550;&#65306;&#65288;&#20266;&#65289;Gibbs&#37319;&#26679;&#19982;&#21160;&#37327;&#21305;&#37197;&#65292;&#21487;&#20197;&#22312;&#32473;&#23450;&#32463;&#36807;DSM&#35757;&#32451;&#33391;&#22909;&#30340;&#8220;&#22024;&#26434;&#8221;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#20174;&#22522;&#30784;&#8220;&#24178;&#20928;&#8221;&#27169;&#22411;&#20013;&#26377;&#25928;&#22320;&#36827;&#34892;&#37319;&#26679;&#12290;&#25105;&#20204;&#25506;&#35752;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30456;&#23545;&#20110;&#30456;&#20851;&#26041;&#27861;&#30340;&#20248;&#21183;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#35813;&#26041;&#27861;&#25193;&#23637;&#21040;&#39640;&#32500;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
Energy-Based Models (EBMs) offer a versatile framework for modeling complex data distributions. However, training and sampling from EBMs continue to pose significant challenges. The widely-used Denoising Score Matching (DSM) method for scalable EBM training suffers from inconsistency issues, causing the energy model to learn a `noisy' data distribution. In this work, we propose an efficient sampling framework: (pseudo)-Gibbs sampling with moment matching, which enables effective sampling from the underlying clean model when given a `noisy' model that has been well-trained via DSM. We explore the benefits of our approach compared to related methods and demonstrate how to scale the method to high-dimensional datasets.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#39564;&#35777;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#21363;&#35757;&#32451;&#26131;&#20110;&#39564;&#35777;&#30340;&#38480;&#21046;&#27169;&#22411;&#31867;&#26469;&#35299;&#20915;&#20915;&#31574;&#26641;&#38598;&#25104;&#30340; NP-hard &#38382;&#39064;&#65292;&#24182;&#25104;&#21151;&#35774;&#35745;&#20986;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#31639;&#27861;&#65292;&#20351;&#24471;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#21487;&#20197;&#36827;&#34892;&#23433;&#20840;&#39564;&#35777;&#65292;&#32780;&#19988;&#20173;&#20445;&#25345;&#30528;&#35813;&#39046;&#22495;&#26368;&#22909;&#30340;&#40065;&#26834;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.03626</link><description>&lt;p&gt;
&#40065;&#26834;&#20915;&#31574;&#26641;&#38598;&#25104;&#30340;&#21487;&#39564;&#35777;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Verifiable Learning for Robust Tree Ensembles. (arXiv:2305.03626v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.03626
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#39564;&#35777;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#21363;&#35757;&#32451;&#26131;&#20110;&#39564;&#35777;&#30340;&#38480;&#21046;&#27169;&#22411;&#31867;&#26469;&#35299;&#20915;&#20915;&#31574;&#26641;&#38598;&#25104;&#30340; NP-hard &#38382;&#39064;&#65292;&#24182;&#25104;&#21151;&#35774;&#35745;&#20986;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#31639;&#27861;&#65292;&#20351;&#24471;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#21487;&#20197;&#36827;&#34892;&#23433;&#20840;&#39564;&#35777;&#65292;&#32780;&#19988;&#20173;&#20445;&#25345;&#30528;&#35813;&#39046;&#22495;&#26368;&#22909;&#30340;&#40065;&#26834;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#27979;&#35797;&#26102;&#38388;&#20869;&#39564;&#35777;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#23545;&#25239;&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#30740;&#31350;&#38382;&#39064;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#30830;&#23450;&#65292;&#23545;&#20110;&#20915;&#31574;&#26641;&#38598;&#25104;&#65292;&#36825;&#20010;&#38382;&#39064;&#26159; NP-hard &#65292;&#22240;&#27492;&#23545;&#20110;&#29305;&#23450;&#30340;&#36755;&#20837;&#26469;&#35828;&#26159;&#19981;&#21487;&#35299;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#19968;&#31867;&#21463;&#38480;&#20915;&#31574;&#26641;&#38598;&#25104;&#65292;&#31216;&#20026; large-spread &#38598;&#25104;&#65292;&#20854;&#20801;&#35768;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#36816;&#34892;&#23433;&#20840;&#39564;&#35777;&#31639;&#27861;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#31216;&#20026;&#21487;&#39564;&#35777;&#23398;&#20064;&#65292;&#35813;&#26041;&#27861;&#20513;&#23548;&#35757;&#32451;&#36825;&#31181;&#26131;&#20110;&#39564;&#35777;&#30340;&#21463;&#38480;&#27169;&#22411;&#31867;&#12290;&#25105;&#20204;&#36890;&#36807;&#35774;&#35745;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#31639;&#27861;&#65292;&#20174;&#26631;&#35760;&#25968;&#25454;&#20013;&#33258;&#21160;&#23398;&#20064; large-spread &#20915;&#31574;&#26641;&#38598;&#25104;&#26469;&#23637;&#31034;&#36825;&#31181;&#26041;&#27861;&#30340;&#30410;&#22788;&#65292;&#20174;&#32780;&#20351;&#20854;&#33021;&#22815;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#36827;&#34892;&#23433;&#20840;&#39564;&#35777;&#12290;&#20844;&#24320;&#21487;&#29992;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#35777;&#23454;&#65292;&#20351;&#29992;&#25105;&#20204;&#30340;&#31639;&#27861;&#35757;&#32451;&#30340; large-spread &#38598;&#25104;&#21487;&#20197;&#22312;&#20960;&#31186;&#38047;&#20869;&#20351;&#29992;&#26631;&#20934;&#21322;&#23450;&#32534;&#31243;&#27714;&#35299;&#22120;&#36827;&#34892;&#39564;&#35777;&#65292;&#21516;&#26102;&#23545;&#25239;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#25915;&#20987;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Verifying the robustness of machine learning models against evasion attacks at test time is an important research problem. Unfortunately, prior work established that this problem is NP-hard for decision tree ensembles, hence bound to be intractable for specific inputs. In this paper, we identify a restricted class of decision tree ensembles, called large-spread ensembles, which admit a security verification algorithm running in polynomial time. We then propose a new approach called verifiable learning, which advocates the training of such restricted model classes which are amenable for efficient verification. We show the benefits of this idea by designing a new training algorithm that automatically learns a large-spread decision tree ensemble from labelled data, thus enabling its security verification in polynomial time. Experimental results on publicly available datasets confirm that large-spread ensembles trained using our algorithm can be verified in a matter of seconds, using stand
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20449;&#24687;&#29702;&#35770;&#27867;&#21270;&#35823;&#24046;&#32039;&#30830;&#30028;&#65292;&#23545;&#20110;&#20856;&#22411;&#30340;&#20108;&#27425;&#39640;&#26031;&#22343;&#20540;&#20272;&#35745;&#38382;&#39064;&#65292;&#23427;&#26159;&#23436;&#20840;&#32039;&#30830;&#30340;&#12290;&#19982;&#29616;&#26377;&#30340;&#30028;&#19981;&#21516;&#65292;&#36825;&#20010;&#26032;&#30028;&#21033;&#29992;&#20102;&#20010;&#20307;&#26679;&#26412;&#30340;&#26041;&#27861;&#65292;&#24182;&#23545;&#27867;&#21270;&#35823;&#24046;&#20989;&#25968;&#36827;&#34892;&#20102;&#27979;&#37327;&#21464;&#25442;&#19981;&#31561;&#24335;&#21644;&#26465;&#20214;&#23548;&#20986;&#12290;</title><link>http://arxiv.org/abs/2305.00876</link><description>&lt;p&gt;
&#20108;&#27425;&#39640;&#26031;&#38382;&#39064;&#30340;&#20449;&#24687;&#29702;&#35770;&#27867;&#21270;&#35823;&#24046;&#30340;&#23436;&#20840;&#32039;&#30830;&#30028;
&lt;/p&gt;
&lt;p&gt;
Exactly Tight Information-Theoretic Generalization Error Bound for the Quadratic Gaussian Problem. (arXiv:2305.00876v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00876
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20449;&#24687;&#29702;&#35770;&#27867;&#21270;&#35823;&#24046;&#32039;&#30830;&#30028;&#65292;&#23545;&#20110;&#20856;&#22411;&#30340;&#20108;&#27425;&#39640;&#26031;&#22343;&#20540;&#20272;&#35745;&#38382;&#39064;&#65292;&#23427;&#26159;&#23436;&#20840;&#32039;&#30830;&#30340;&#12290;&#19982;&#29616;&#26377;&#30340;&#30028;&#19981;&#21516;&#65292;&#36825;&#20010;&#26032;&#30028;&#21033;&#29992;&#20102;&#20010;&#20307;&#26679;&#26412;&#30340;&#26041;&#27861;&#65292;&#24182;&#23545;&#27867;&#21270;&#35823;&#24046;&#20989;&#25968;&#36827;&#34892;&#20102;&#27979;&#37327;&#21464;&#25442;&#19981;&#31561;&#24335;&#21644;&#26465;&#20214;&#23548;&#20986;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#20449;&#24687;&#29702;&#35770;&#27867;&#21270;&#35823;&#24046;&#32039;&#30830;&#30028;&#65292;&#23545;&#20110;&#20856;&#22411;&#30340;&#20108;&#27425;&#39640;&#26031;&#22343;&#20540;&#20272;&#35745;&#38382;&#39064;&#65292;&#23427;&#26159;&#23436;&#20840;&#32039;&#30830;&#30340;&#65288;&#21363;&#21305;&#37197;&#24120;&#25968;&#65289;&#12290;&#23613;&#31649;&#22312;&#25512;&#23548;&#20449;&#24687;&#35770;&#27867;&#21270;&#35823;&#24046;&#30028;&#26041;&#38754;&#36827;&#34892;&#20102;&#30456;&#24403;&#22810;&#30340;&#21162;&#21147;&#65292;&#20294;&#23558;&#20854;&#24212;&#29992;&#20110;&#20351;&#29992;&#26679;&#26412;&#24179;&#22343;&#20316;&#20026;&#39640;&#26031;&#25968;&#25454;&#22343;&#20540;&#20272;&#35745;&#30340;&#31616;&#21333;&#35774;&#32622;&#24182;&#27809;&#26377;&#20135;&#29983;&#20196;&#20154;&#28385;&#24847;&#30340;&#32467;&#26524;&#12290;&#20107;&#23454;&#19978;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#30028;&#37117;&#26159;&#26494;&#25955;&#30340;&#65292;&#36825;&#24341;&#36215;&#20102;&#20154;&#20204;&#23545;&#20110;&#20449;&#24687;&#29702;&#35770;&#30028;&#22312;&#25512;&#29702;&#26426;&#22120;&#23398;&#20064;&#30340;&#27867;&#21270;&#34892;&#20026;&#26041;&#38754;&#30340;&#22522;&#26412;&#33021;&#21147;&#30340;&#20851;&#27880;&#12290;&#25552;&#20986;&#30340;&#26032;&#30340;&#30028;&#37319;&#29992;&#20102;Bu&#31561;&#20154;&#25552;&#20986;&#30340;&#22522;&#20110;&#21333;&#20010;&#26679;&#26412;&#30340;&#26041;&#27861;&#65292;&#20294;&#20063;&#26377;&#20960;&#20010;&#20851;&#38190;&#30340;&#26032;&#32452;&#25104;&#37096;&#20998;&#12290; &#39318;&#20808;&#65292;&#25105;&#20204;&#19981;&#26159;&#23558;&#27979;&#37327;&#21464;&#25442;&#19981;&#31561;&#24335;&#24212;&#29992;&#20110;&#25439;&#22833;&#20989;&#25968;&#65292;&#32780;&#26159;&#24212;&#29992;&#20110;&#27867;&#21270;&#35823;&#24046;&#20989;&#25968;&#26412;&#36523;&#65307;&#20854;&#27425;&#65292;&#30028;&#26159;&#26377;&#26465;&#20214;&#22320;&#23548;&#20986;&#30340;&#65307; &#26368;&#21518;&#65292;
&lt;/p&gt;
&lt;p&gt;
We provide a new information-theoretic generalization error bound that is exactly tight (i.e., matching even the constant) for the canonical quadratic Gaussian mean estimation problem. Despite considerable existing efforts in deriving information-theoretic generalization error bounds, applying them to this simple setting where sample average is used as the estimate of the mean value of Gaussian data has not yielded satisfying results. In fact, most existing bounds are order-wise loose in this setting, which has raised concerns about the fundamental capability of information-theoretic bounds in reasoning the generalization behavior for machine learning. The proposed new bound adopts the individual-sample-based approach proposed by Bu et al., but also has several key new ingredients. Firstly, instead of applying the change of measure inequality on the loss function, we apply it to the generalization error function itself; secondly, the bound is derived in a conditional manner; lastly, a 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#35777;&#26126;&#25910;&#25947;&#30340;PnP&#26041;&#27861;&#65292;&#20351;&#29992;&#25311;&#29275;&#39039;&#27493;&#39588;&#20197;&#21152;&#36895;&#25910;&#25947;&#65292;&#30456;&#23545;&#20110;&#29616;&#26377;&#30340;PnP&#26041;&#27861;&#23545;&#21435;&#22122;&#22120;&#25110;&#20445;&#30495;&#24230;&#20989;&#25968;&#26045;&#21152;&#20102;&#36739;&#36731;&#30340;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2303.07271</link><description>&lt;p&gt;
&#21487;&#35777;&#25910;&#25947;&#30340;&#21363;&#25554;&#21363;&#29992;&#25311;&#29275;&#39039;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Provably Convergent Plug-and-Play Quasi-Newton Methods. (arXiv:2303.07271v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.07271
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#35777;&#26126;&#25910;&#25947;&#30340;PnP&#26041;&#27861;&#65292;&#20351;&#29992;&#25311;&#29275;&#39039;&#27493;&#39588;&#20197;&#21152;&#36895;&#25910;&#25947;&#65292;&#30456;&#23545;&#20110;&#29616;&#26377;&#30340;PnP&#26041;&#27861;&#23545;&#21435;&#22122;&#22120;&#25110;&#20445;&#30495;&#24230;&#20989;&#25968;&#26045;&#21152;&#20102;&#36739;&#36731;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21363;&#25554;&#21363;&#29992;&#65288;PnP&#65289;&#26041;&#27861;&#26159;&#19968;&#31867;&#39640;&#25928;&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#26088;&#22312;&#21033;&#29992;&#32463;&#20856;&#20248;&#21270;&#31639;&#27861;&#65288;&#22914;ISTA&#25110;ADMM&#65289;&#65292;&#23558;&#25968;&#25454;&#20445;&#30495;&#24230;&#39033;&#21644;&#28145;&#24230;&#21435;&#22122;&#22120;&#30456;&#32467;&#21512;&#12290;&#29616;&#26377;&#30340;&#21487;&#35777;&#26126;&#30340;PnP&#26041;&#27861;&#23545;&#21435;&#22122;&#22120;&#25110;&#20445;&#30495;&#24230;&#20989;&#25968;&#26045;&#21152;&#20102;&#20005;&#26684;&#30340;&#38480;&#21046;&#65292;&#22914;&#38750;&#25193;&#24352;&#24615;&#25110;&#20005;&#26684;&#20984;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#35777;&#26126;&#30340;PnP&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#36817;&#31471;&#21435;&#22122;&#22120;&#26045;&#21152;&#30456;&#23545;&#36739;&#36731;&#30340;&#26465;&#20214;&#65292;&#24182;&#24341;&#20837;&#20102;&#25311;&#29275;&#39039;&#27493;&#39588;&#20197;&#22823;&#22823;&#21152;&#36895;&#25910;&#25947;&#12290;&#36890;&#36807;&#23558;&#28145;&#24230;&#21435;&#22122;&#22120;&#29305;&#21035;&#21442;&#25968;&#21270;&#20026;&#26799;&#24230;&#27493;&#39588;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#23558;&#25311;&#29275;&#39039;PnP&#31639;&#27861;&#30340;&#22266;&#23450;&#28857;&#34920;&#24449;&#20026;&#21487;&#33021;&#38750;&#20984;&#20989;&#25968;&#30340;&#20020;&#30028;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Plug-and-Play (PnP) methods are a class of efficient iterative methods that aim to combine data fidelity terms and deep denoisers using classical optimization algorithms, such as ISTA or ADMM. Existing provable PnP methods impose heavy restrictions on the denoiser or fidelity function, such as nonexpansiveness or strict convexity. In this work, we propose a provable PnP method that imposes relatively light conditions based on proximal denoisers, and introduce a quasi-Newton step to greatly accelerate convergence. By specially parameterizing the deep denoiser as a gradient step, we further characterize the fixed-points of the quasi-Newton PnP algorithm as critical points of a possibly non-convex function.
&lt;/p&gt;</description></item><item><title>&#21464;&#35843;&#31070;&#32463;ODEs &#65288;MoNODEs&#65289;&#26159;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#33021;&#22815;&#23558;&#21160;&#21147;&#23398;&#29366;&#24577;&#19982;&#22522;&#30784;&#38745;&#24577;&#21464;&#21270;&#22240;&#32032;&#20998;&#24320;&#65292;&#24182;&#25913;&#36827;&#20102;&#29616;&#26377;&#30340;&#31070;&#32463;ODE&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#24341;&#20837;&#26102;&#38388;&#19981;&#21464;&#30340;&#35843;&#21046;&#21464;&#37327;&#26469;&#25429;&#25417;&#36712;&#36857;&#38388;&#30340;&#21464;&#21270;&#65292;&#24182;&#22312;&#27979;&#35797;&#20013;&#23637;&#29616;&#20986;&#22312;&#25391;&#33633;&#31995;&#32479;&#12289;&#35270;&#39057;&#21644;&#20154;&#31867;&#34892;&#36208;&#36712;&#36857;&#31561;&#26041;&#38754;&#20855;&#26377;&#25552;&#39640;&#27169;&#22411;&#27867;&#21270;&#33021;&#21147;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2302.13262</link><description>&lt;p&gt;
&#21464;&#35843;&#31070;&#32463;ODEs
&lt;/p&gt;
&lt;p&gt;
Modulated Neural ODEs. (arXiv:2302.13262v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.13262
&lt;/p&gt;
&lt;p&gt;
&#21464;&#35843;&#31070;&#32463;ODEs &#65288;MoNODEs&#65289;&#26159;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#33021;&#22815;&#23558;&#21160;&#21147;&#23398;&#29366;&#24577;&#19982;&#22522;&#30784;&#38745;&#24577;&#21464;&#21270;&#22240;&#32032;&#20998;&#24320;&#65292;&#24182;&#25913;&#36827;&#20102;&#29616;&#26377;&#30340;&#31070;&#32463;ODE&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#24341;&#20837;&#26102;&#38388;&#19981;&#21464;&#30340;&#35843;&#21046;&#21464;&#37327;&#26469;&#25429;&#25417;&#36712;&#36857;&#38388;&#30340;&#21464;&#21270;&#65292;&#24182;&#22312;&#27979;&#35797;&#20013;&#23637;&#29616;&#20986;&#22312;&#25391;&#33633;&#31995;&#32479;&#12289;&#35270;&#39057;&#21644;&#20154;&#31867;&#34892;&#36208;&#36712;&#36857;&#31561;&#26041;&#38754;&#20855;&#26377;&#25552;&#39640;&#27169;&#22411;&#27867;&#21270;&#33021;&#21147;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;NODEs&#65289;&#24050;&#34987;&#35777;&#26126;&#23545;&#20110;&#23398;&#20064;&#20219;&#24847;&#36712;&#36857;&#30340;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#24456;&#26377;&#29992;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;NODE&#26041;&#27861;&#20165;&#36890;&#36807;&#21021;&#22987;&#29366;&#24577;&#20540;&#25110;&#33258;&#22238;&#24402;&#32534;&#30721;&#22120;&#26356;&#26032;&#26469;&#25429;&#25417;&#36712;&#36857;&#38388;&#30340;&#21464;&#21270;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#21464;&#35843;&#31070;&#32463;ODEs&#65288;MoNODEs&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#23558;&#21160;&#21147;&#23398;&#29366;&#24577;&#19982;&#22522;&#30784;&#38745;&#24577;&#21464;&#21270;&#22240;&#32032;&#20998;&#24320;&#24182;&#25913;&#36827;&#29616;&#26377;NODE&#26041;&#27861;&#30340;&#26032;&#26694;&#26550;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#30340;&#8220;&#26102;&#38388;&#19981;&#21464;&#35843;&#21046;&#21464;&#37327;&#8221;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#25552;&#20986;&#30340;&#26694;&#26550;&#32467;&#21512;&#21040;&#22235;&#31181;&#29616;&#26377;&#30340;NODE&#21464;&#20307;&#20013;&#12290;&#25105;&#20204;&#22312;&#25391;&#33633;&#31995;&#32479;&#12289;&#35270;&#39057;&#21644;&#20154;&#31867;&#34892;&#36208;&#36712;&#36857;&#19978;&#23545;MoNODE&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#20854;&#20013;&#27599;&#20010;&#36712;&#36857;&#37117;&#20855;&#26377;&#36712;&#36857;&#29305;&#23450;&#30340;&#35843;&#21046;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#22987;&#32456;&#25552;&#39640;&#20102;&#29616;&#26377;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#20351;&#20854;&#33021;&#22815;&#36866;&#24212;&#26032;&#30340;&#21160;&#24577;&#21442;&#25968;&#21270;&#24182;&#36827;&#34892;&#36828;&#26399;&#39044;&#27979;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#25552;&#20986;&#30340;&#35843;&#21046;&#21464;&#37327;&#30340;&#20449;&#24687;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural ordinary differential equations (NODEs) have been proven useful for learning non-linear dynamics of arbitrary trajectories. However, current NODE methods capture variations across trajectories only via the initial state value or by auto-regressive encoder updates. In this work, we introduce Modulated Neural ODEs (MoNODEs), a novel framework that sets apart dynamics states from underlying static factors of variation and improves the existing NODE methods. In particular, we introduce $\textit{time-invariant modulator variables}$ that are learned from the data. We incorporate our proposed framework into four existing NODE variants. We test MoNODE on oscillating systems, videos and human walking trajectories, where each trajectory has trajectory-specific modulation. Our framework consistently improves the existing model ability to generalize to new dynamic parameterizations and to perform far-horizon forecasting. In addition, we verify that the proposed modulator variables are infor
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#20248;&#20256;&#36755;&#30340;&#23454;&#20363;&#30456;&#20851;&#27867;&#21270;&#30028;&#38480;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#27867;&#21270;&#30340;&#20851;&#38190;&#22240;&#32032;&#65292;&#24182;&#19988;&#32771;&#34385;&#20102;&#21021;&#22987;&#21270;&#21644;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#24378;&#24402;&#32435;&#20559;&#24046;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#27169;&#22411;&#21442;&#25968;&#21270;&#19981;&#21487;&#30693;&#19988;&#35757;&#32451;&#26679;&#26412;&#25968;&#37327;&#36828;&#23567;&#20110;&#21442;&#25968;&#25968;&#37327;&#26102;&#34920;&#29616;&#33391;&#22909;&#65292;&#36824;&#21487;&#20197;&#24212;&#29992;&#20110;&#20302;&#32500;&#27969;&#24418;&#19978;&#30340;&#25968;&#25454;&#21644;&#20998;&#24067;&#36716;&#25442;&#24773;&#20917;&#19979;&#30340;&#27867;&#21270;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2211.01258</link><description>&lt;p&gt;
&#22522;&#20110;&#26368;&#20248;&#20256;&#36755;&#30340;&#23454;&#20363;&#30456;&#20851;&#27867;&#21270;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Instance-Dependent Generalization Bounds via Optimal Transport. (arXiv:2211.01258v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.01258
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#20248;&#20256;&#36755;&#30340;&#23454;&#20363;&#30456;&#20851;&#27867;&#21270;&#30028;&#38480;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#27867;&#21270;&#30340;&#20851;&#38190;&#22240;&#32032;&#65292;&#24182;&#19988;&#32771;&#34385;&#20102;&#21021;&#22987;&#21270;&#21644;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#24378;&#24402;&#32435;&#20559;&#24046;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#27169;&#22411;&#21442;&#25968;&#21270;&#19981;&#21487;&#30693;&#19988;&#35757;&#32451;&#26679;&#26412;&#25968;&#37327;&#36828;&#23567;&#20110;&#21442;&#25968;&#25968;&#37327;&#26102;&#34920;&#29616;&#33391;&#22909;&#65292;&#36824;&#21487;&#20197;&#24212;&#29992;&#20110;&#20302;&#32500;&#27969;&#24418;&#19978;&#30340;&#25968;&#25454;&#21644;&#20998;&#24067;&#36716;&#25442;&#24773;&#20917;&#19979;&#30340;&#27867;&#21270;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;&#27867;&#21270;&#30028;&#38480;&#26080;&#27861;&#35299;&#37322;&#24433;&#21709;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#27867;&#21270;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;&#30001;&#20110;&#36825;&#20123;&#30028;&#38480;&#36890;&#24120;&#23545;&#25152;&#26377;&#21442;&#25968;&#37117;&#26159;&#19968;&#33268;&#30340;&#65292;&#23427;&#20204;&#23481;&#26131;&#36807;&#24230;&#21442;&#25968;&#21270;&#65292;&#24182;&#19988;&#26080;&#27861;&#32771;&#34385;&#21040;&#21021;&#22987;&#21270;&#21644;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#24378;&#24402;&#32435;&#20559;&#24046;&#12290;&#20316;&#20026;&#26367;&#20195;&#26041;&#26696;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26368;&#20248;&#20256;&#36755;&#35299;&#37322;&#27867;&#21270;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#33719;&#24471;&#20381;&#36182;&#20110;&#25968;&#25454;&#31354;&#38388;&#20013;&#39044;&#27979;&#20989;&#25968;&#30340;&#23616;&#37096;&#21033;&#26222;&#24076;&#33576;&#27491;&#21017;&#24615;&#30340;&#23454;&#20363;&#30456;&#20851;&#27867;&#21270;&#30028;&#38480;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30340;&#30028;&#38480;&#23545;&#27169;&#22411;&#30340;&#21442;&#25968;&#21270;&#26159;&#19981;&#21487;&#30693;&#30340;&#65292;&#24182;&#19988;&#22312;&#35757;&#32451;&#26679;&#26412;&#25968;&#37327;&#36828;&#23567;&#20110;&#21442;&#25968;&#25968;&#37327;&#26102;&#34920;&#29616;&#33391;&#22909;&#12290;&#36890;&#36807;&#19968;&#20123;&#23567;&#30340;&#20462;&#25913;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20302;&#32500;&#27969;&#24418;&#19978;&#30340;&#25968;&#25454;&#19978;&#21487;&#20197;&#33719;&#24471;&#21152;&#36895;&#30340;&#36895;&#29575;&#65292;&#24182;&#19988;&#22312;&#20998;&#24067;&#36716;&#25442;&#19979;&#20855;&#26377;&#20445;&#35777;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#31070;&#32463;&#32593;&#32476;&#30340;&#23454;&#35777;&#20998;&#26512;&#26469;&#39564;&#35777;&#25105;&#20204;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#32467;&#26524;&#26174;&#31034;&#30028;&#38480;&#20540;&#26159;
&lt;/p&gt;
&lt;p&gt;
Existing generalization bounds fail to explain crucial factors that drive generalization of modern neural networks. Since such bounds often hold uniformly over all parameters, they suffer from over-parametrization, and fail to account for the strong inductive bias of initialization and stochastic gradient descent. As an alternative, we propose a novel optimal transport interpretation of the generalization problem. This allows us to derive instance-dependent generalization bounds that depend on the local Lipschitz regularity of the earned prediction function in the data space. Therefore, our bounds are agnostic to the parametrization of the model and work well when the number of training samples is much smaller than the number of parameters. With small modifications, our approach yields accelerated rates for data on low-dimensional manifolds, and guarantees under distribution shifts. We empirically analyze our generalization bounds for neural networks, showing that the bound values are 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#19968;&#33268;&#25490;&#24207;&#26694;&#26550;&#65292;&#21363;RankDice/RankIoU&#65292;&#29992;&#20110;&#35299;&#20915;&#30001;&#20110;&#29616;&#26377;&#30340;&#20998;&#21106;&#26694;&#26550;&#23545;&#20110;Dice/IoU&#25351;&#26631;&#32570;&#20047;&#19968;&#33268;&#24615;&#32780;&#21487;&#33021;&#23548;&#33268;&#30340;&#27425;&#20248;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2206.13086</link><description>&lt;p&gt;
RankSEG:&#19968;&#31181;&#22522;&#20110;&#19968;&#33268;&#25490;&#24207;&#30340;&#20998;&#21106;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
RankSEG: A Consistent Ranking-based Framework for Segmentation. (arXiv:2206.13086v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.13086
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#19968;&#33268;&#25490;&#24207;&#26694;&#26550;&#65292;&#21363;RankDice/RankIoU&#65292;&#29992;&#20110;&#35299;&#20915;&#30001;&#20110;&#29616;&#26377;&#30340;&#20998;&#21106;&#26694;&#26550;&#23545;&#20110;Dice/IoU&#25351;&#26631;&#32570;&#20047;&#19968;&#33268;&#24615;&#32780;&#21487;&#33021;&#23548;&#33268;&#30340;&#27425;&#20248;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#21106;&#24050;&#25104;&#20026;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#22522;&#26412;&#39046;&#22495;&#65292;&#23427;&#23558;&#26631;&#31614;&#20998;&#37197;&#32473;&#27599;&#20010;&#20687;&#32032;/&#29305;&#24449;&#65292;&#20197;&#20174;&#22270;&#20687;/&#25991;&#26412;&#20013;&#25552;&#21462;&#24863;&#20852;&#36259;&#30340;&#21306;&#22495;&#12290;&#20026;&#20102;&#35780;&#20272;&#20998;&#21106;&#24615;&#33021;&#65292;&#20351;&#29992;Dice&#21644;IoU&#25351;&#26631;&#26469;&#34913;&#37327;&#23454;&#38469;&#20540;&#21644;&#39044;&#27979;&#20998;&#21106;&#20043;&#38388;&#30340;&#37325;&#21472;&#31243;&#24230;&#12290;&#26412;&#25991;&#24314;&#31435;&#20102;&#19982;Dice/IoU&#25351;&#26631;&#30456;&#20851;&#30340;&#20998;&#21106;&#29702;&#35770;&#22522;&#30784;&#65292;&#21253;&#25324;&#31867;&#27604;&#20110;&#20998;&#31867;&#30340;&#36125;&#21494;&#26031;&#35268;&#21017;&#21644;Dice-/IoU-&#26657;&#20934;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#29616;&#26377;&#30340;&#22522;&#20110;&#38408;&#20540;&#30340;&#26694;&#26550;&#23545;&#20110;Dice/IoU&#25351;&#26631;&#32570;&#20047;&#19968;&#33268;&#24615;&#65292;&#22240;&#27492;&#21487;&#33021;&#23548;&#33268;&#27425;&#20248;&#35299;&#20915;&#26041;&#26696;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#19968;&#33268;&#25490;&#24207;&#26694;&#26550;&#65292;&#21363;RankDice/RankIoU&#65292;&#21463;&#36125;&#21494;&#26031;&#20998;&#21106;&#35268;&#21017;&#30340;&#25554;&#20837;&#27861;&#21017;&#30340;&#21551;&#21457;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#19977;&#20010;&#20351;&#29992;GPU&#24182;&#34892;&#25191;&#34892;&#30340;&#25968;&#23383;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Segmentation has emerged as a fundamental field of computer vision and natural language processing, which assigns a label to every pixel/feature to extract regions of interest from an image/text. To evaluate the performance of segmentation, the Dice and IoU metrics are used to measure the degree of overlap between the ground truth and the predicted segmentation. In this paper, we establish a theoretical foundation of segmentation with respect to the Dice/IoU metrics, including the Bayes rule and Dice-/IoU-calibration, analogous to classification-calibration or Fisher consistency in classification. We prove that the existing thresholding-based framework with most operating losses are not consistent with respect to the Dice/IoU metrics, and thus may lead to a suboptimal solution. To address this pitfall, we propose a novel consistent ranking-based framework, namely RankDice/RankIoU, inspired by plug-in rules of the Bayes segmentation rule. Three numerical algorithms with GPU parallel exe
&lt;/p&gt;</description></item></channel></rss>