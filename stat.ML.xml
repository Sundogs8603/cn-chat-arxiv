<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#22522;&#20110;&#21644;&#24179;&#26041;&#27861;&#30340;&#31169;&#26377;&#22270;&#20272;&#35745;&#31639;&#27861;&#39318;&#27425;&#23454;&#29616;&#20102;&#23398;&#20064;&#38543;&#26426;&#22359;&#27169;&#22411;&#21644;&#22270;&#20272;&#35745;&#30340;&#32431;&#33410;&#28857;&#24046;&#20998;&#38544;&#31169;&#31639;&#27861;&#65292;&#20855;&#26377;&#22810;&#39033;&#24335;&#36816;&#34892;&#26102;&#38388;&#65292;&#19982;&#20043;&#21069;&#26368;&#20339;&#30340;&#20449;&#24687;&#35770;&#33410;&#28857;&#31169;&#26377;&#26426;&#21046;&#20855;&#26377;&#30456;&#21305;&#37197;&#30340;&#32479;&#35745;&#25928;&#29992;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2403.12213</link><description>&lt;p&gt;
&#36890;&#36807;&#20108;&#27425;&#21644;&#26041;&#27861;&#36827;&#34892;&#31169;&#26377;&#22270;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Private graphon estimation via sum-of-squares
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12213
&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#21644;&#24179;&#26041;&#27861;&#30340;&#31169;&#26377;&#22270;&#20272;&#35745;&#31639;&#27861;&#39318;&#27425;&#23454;&#29616;&#20102;&#23398;&#20064;&#38543;&#26426;&#22359;&#27169;&#22411;&#21644;&#22270;&#20272;&#35745;&#30340;&#32431;&#33410;&#28857;&#24046;&#20998;&#38544;&#31169;&#31639;&#27861;&#65292;&#20855;&#26377;&#22810;&#39033;&#24335;&#36816;&#34892;&#26102;&#38388;&#65292;&#19982;&#20043;&#21069;&#26368;&#20339;&#30340;&#20449;&#24687;&#35770;&#33410;&#28857;&#31169;&#26377;&#26426;&#21046;&#20855;&#26377;&#30456;&#21305;&#37197;&#30340;&#32479;&#35745;&#25928;&#29992;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24320;&#21457;&#20102;&#29992;&#20110;&#23398;&#20064;&#38543;&#26426;&#22359;&#27169;&#22411;&#21644;&#22270;&#20272;&#35745;&#30340;&#31532;&#19968;&#20010;&#32431;&#33410;&#28857;&#24046;&#20998;&#38544;&#31169;&#31639;&#27861;&#65292;&#23545;&#20110;&#20219;&#24847;&#24120;&#25968;&#20010;&#22359;&#65292;&#20855;&#26377;&#22810;&#39033;&#24335;&#36816;&#34892;&#26102;&#38388;&#12290;&#32479;&#35745;&#25928;&#29992;&#20445;&#35777;&#19982;&#20808;&#21069;&#26368;&#20339;&#30340;&#20449;&#24687;&#35770;&#65288;&#25351;&#25968;&#26102;&#38388;&#65289;&#33410;&#28857;&#31169;&#26377;&#26426;&#21046;&#30456;&#21305;&#37197;&#12290;&#35813;&#31639;&#27861;&#22522;&#20110;&#19968;&#20010;&#22522;&#20110;&#25351;&#25968;&#26426;&#21046;&#30340;&#24471;&#20998;&#20989;&#25968;&#65292;&#35813;&#20989;&#25968;&#23450;&#20041;&#20026;&#20381;&#36182;&#20110;&#22359;&#25968;&#37327;&#30340;&#20108;&#27425;&#21644;&#26494;&#24347;&#12290;&#25105;&#20204;&#32467;&#26524;&#30340;&#20851;&#38190;&#35201;&#32032;&#26159;&#65306;(1) &#22312;&#24418;&#24335;&#19978;&#23450;&#20041;&#20026;&#20108;&#27425;&#20248;&#21270;&#22312;&#21452;&#37325;&#38543;&#26426;&#30697;&#38453;&#30340;&#22810;&#32990;&#20307;&#19978;&#30340;&#36317;&#31163;&#30340;&#29305;&#24449;&#21270;&#22359;&#22270;&#23450;&#20041;&#65292;(2) &#19968;&#33324;&#30340;&#22810;&#39033;&#24335;&#20248;&#21270;&#30340;&#21644;&#24179;&#26041;&#27861;&#22312;&#20219;&#24847;&#22810;&#32990;&#20307;&#19978;&#30340;&#25910;&#25947;&#32467;&#26524;&#65292;&#20197;&#21450;(3) &#25191;&#34892;&#21033;&#26222;&#24076;&#33576;&#25193;&#23637;&#30340;&#24471;&#20998;&#20989;&#25968;&#20316;&#20026;&#20108;&#27425;&#21644;&#31639;&#27861;&#33539;&#20363;&#30340;&#19968;&#33324;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12213v1 Announce Type: cross  Abstract: We develop the first pure node-differentially-private algorithms for learning stochastic block models and for graphon estimation with polynomial running time for any constant number of blocks. The statistical utility guarantees match those of the previous best information-theoretic (exponential-time) node-private mechanisms for these problems. The algorithm is based on an exponential mechanism for a score function defined in terms of a sum-of-squares relaxation whose level depends on the number of blocks. The key ingredients of our results are (1) a characterization of the distance between the block graphons in terms of a quadratic optimization over the polytope of doubly stochastic matrices, (2) a general sum-of-squares convergence result for polynomial optimization over arbitrary polytopes, and (3) a general approach to perform Lipschitz extensions of score functions as part of the sum-of-squares algorithmic paradigm.
&lt;/p&gt;</description></item><item><title>2023&#24180;&#30340;&#30740;&#31350;&#26174;&#31034;&#65292;&#21487;&#35299;&#37322;&#21644;&#21487;&#20449;&#36182;&#30340;&#26426;&#22120;&#23398;&#20064;&#21487;&#35270;&#21270;&#20173;&#28982;&#26159;&#19968;&#20010;&#37325;&#35201;&#19988;&#19981;&#26029;&#21457;&#23637;&#30340;&#39046;&#22495;&#65292;&#20026;&#21508;&#31181;&#39046;&#22495;&#25552;&#20379;&#20102;&#36235;&#21183;&#12289;&#35265;&#35299;&#21644;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2403.12005</link><description>&lt;p&gt;
2023&#24180;&#26426;&#22120;&#23398;&#20064;&#20013;&#20449;&#20219;&#21487;&#35270;&#21270;&#30340;&#26368;&#26032;&#36827;&#23637;
&lt;/p&gt;
&lt;p&gt;
Visualization for Trust in Machine Learning Revisited: The State of the Field in 2023
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12005
&lt;/p&gt;
&lt;p&gt;
2023&#24180;&#30340;&#30740;&#31350;&#26174;&#31034;&#65292;&#21487;&#35299;&#37322;&#21644;&#21487;&#20449;&#36182;&#30340;&#26426;&#22120;&#23398;&#20064;&#21487;&#35270;&#21270;&#20173;&#28982;&#26159;&#19968;&#20010;&#37325;&#35201;&#19988;&#19981;&#26029;&#21457;&#23637;&#30340;&#39046;&#22495;&#65292;&#20026;&#21508;&#31181;&#39046;&#22495;&#25552;&#20379;&#20102;&#36235;&#21183;&#12289;&#35265;&#35299;&#21644;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#35299;&#37322;&#21644;&#21487;&#20449;&#36182;&#30340;&#26426;&#22120;&#23398;&#20064;&#21487;&#35270;&#21270;&#20173;&#28982;&#26159;&#20449;&#24687;&#21487;&#35270;&#21270;&#21644;&#35270;&#35273;&#20998;&#26512;&#39046;&#22495;&#20013;&#26368;&#37325;&#35201;&#21644;&#28145;&#20837;&#30740;&#31350;&#30340;&#39046;&#22495;&#20043;&#19968;&#65292;&#28041;&#21450;&#21307;&#23398;&#12289;&#37329;&#34701;&#21644;&#29983;&#29289;&#20449;&#24687;&#23398;&#31561;&#21508;&#31181;&#24212;&#29992;&#39046;&#22495;&#12290;&#22312;&#25105;&#20204;2020&#24180;&#30340;&#26368;&#26032;&#25253;&#21578;&#20013;&#65292;&#21253;&#25324;&#20102;200&#31181;&#25216;&#26415;&#65292;&#25105;&#20204;&#22362;&#25345;&#25910;&#38598;&#21516;&#34892;&#35780;&#23457;&#30340;&#25991;&#31456;&#65292;&#25551;&#36848;&#21487;&#35270;&#21270;&#25216;&#26415;&#65292;&#26681;&#25454;&#20808;&#21069;&#24314;&#31435;&#30340;&#21253;&#21547;119&#20010;&#31867;&#21035;&#30340;&#20998;&#31867;&#27169;&#24335;&#23545;&#20854;&#36827;&#34892;&#20998;&#31867;&#65292;&#24182;&#22312;&#22312;&#32447;&#35843;&#26597;&#27983;&#35272;&#22120;&#20013;&#25552;&#20379;&#20102;542&#31181;&#25216;&#26415;&#30340;&#32467;&#26524;&#38598;&#12290;&#22312;&#26412;&#35843;&#26597;&#25991;&#31456;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#25130;&#33267;2023&#24180;&#31179;&#23395;&#20851;&#20110;&#36825;&#19968;&#25968;&#25454;&#38598;&#30340;&#26032;&#20998;&#26512;&#32467;&#26524;&#65292;&#24182;&#35752;&#35770;&#20102;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#20351;&#29992;&#21487;&#35270;&#21270;&#30340;&#36235;&#21183;&#12289;&#35265;&#35299;&#21644;&#20843;&#20010;&#24320;&#25918;&#25361;&#25112;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#35777;&#23454;&#20102;&#21487;&#35270;&#21270;&#25216;&#26415;&#22312;&#22686;&#21152;&#23545;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#20449;&#20219;&#26041;&#38754;&#21576;&#24555;&#36895;&#22686;&#38271;&#30340;&#36235;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12005v1 Announce Type: cross  Abstract: Visualization for explainable and trustworthy machine learning remains one of the most important and heavily researched fields within information visualization and visual analytics with various application domains, such as medicine, finance, and bioinformatics. After our 2020 state-of-the-art report comprising 200 techniques, we have persistently collected peer-reviewed articles describing visualization techniques, categorized them based on the previously established categorization schema consisting of 119 categories, and provided the resulting collection of 542 techniques in an online survey browser. In this survey article, we present the updated findings of new analyses of this dataset as of fall 2023 and discuss trends, insights, and eight open challenges for using visualizations in machine learning. Our results corroborate the rapidly growing trend of visualization techniques for increasing trust in machine learning models in the p
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#19968;&#31867;&#38750;&#32447;&#24615;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#30340;&#39640;&#27010;&#29575;&#25910;&#25947;&#36793;&#30028;&#12290;&#23545;&#20110;&#20855;&#26377;Lipschitz&#36830;&#32493;&#26799;&#24230;&#30340;&#24378;&#20984;&#25439;&#22833;&#20989;&#25968;&#65292;&#21363;&#20351;&#22122;&#22768;&#26159;&#37325;&#23614;&#30340;&#65292;&#32467;&#26524;&#35777;&#26126;&#20102;&#23545;&#22833;&#36133;&#27010;&#29575;&#30340;&#23545;&#25968;&#20381;&#36182;&#12290;&#36825;&#20123;&#32467;&#26524;&#36866;&#29992;&#20110;&#21098;&#20999;&#12289;&#24402;&#19968;&#21270;&#21644;&#37327;&#21270;&#31561;&#20219;&#20309;&#20855;&#26377;&#26377;&#30028;&#36755;&#20986;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2310.18784</link><description>&lt;p&gt;
&#39640;&#27010;&#29575;&#25910;&#25947;&#36793;&#30028;&#19979;&#30340;&#38750;&#32447;&#24615;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#22312;&#37325;&#23614;&#22122;&#22768;&#19979;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
High-probability Convergence Bounds for Nonlinear Stochastic Gradient Descent Under Heavy-tailed Noise. (arXiv:2310.18784v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18784
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#19968;&#31867;&#38750;&#32447;&#24615;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#30340;&#39640;&#27010;&#29575;&#25910;&#25947;&#36793;&#30028;&#12290;&#23545;&#20110;&#20855;&#26377;Lipschitz&#36830;&#32493;&#26799;&#24230;&#30340;&#24378;&#20984;&#25439;&#22833;&#20989;&#25968;&#65292;&#21363;&#20351;&#22122;&#22768;&#26159;&#37325;&#23614;&#30340;&#65292;&#32467;&#26524;&#35777;&#26126;&#20102;&#23545;&#22833;&#36133;&#27010;&#29575;&#30340;&#23545;&#25968;&#20381;&#36182;&#12290;&#36825;&#20123;&#32467;&#26524;&#36866;&#29992;&#20110;&#21098;&#20999;&#12289;&#24402;&#19968;&#21270;&#21644;&#37327;&#21270;&#31561;&#20219;&#20309;&#20855;&#26377;&#26377;&#30028;&#36755;&#20986;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#20960;&#20010;&#30740;&#31350;&#24037;&#20316;&#30740;&#31350;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#21450;&#20854;&#21098;&#20999;&#21464;&#20307;&#30340;&#39640;&#27010;&#29575;&#25910;&#25947;&#12290;&#19982;&#26222;&#36890;&#30340;SGD&#30456;&#27604;&#65292;&#21098;&#20999;SGD&#22312;&#23454;&#38469;&#20013;&#26356;&#21152;&#31283;&#23450;&#65292;&#24182;&#19988;&#22312;&#29702;&#35770;&#19978;&#26377;&#23545;&#25968;&#20381;&#36182;&#20110;&#22833;&#36133;&#27010;&#29575;&#30340;&#39069;&#22806;&#22909;&#22788;&#12290;&#28982;&#32780;&#65292;&#20854;&#20182;&#23454;&#38469;&#38750;&#32447;&#24615;SGD&#21464;&#20307;&#65288;&#22914;&#31526;&#21495;SGD&#12289;&#37327;&#21270;SGD&#21644;&#24402;&#19968;&#21270;SGD&#65289;&#30340;&#25910;&#25947;&#24615;&#29702;&#35299;&#35201;&#23569;&#24471;&#22810;&#65292;&#36825;&#20123;&#26041;&#27861;&#23454;&#29616;&#20102;&#25913;&#36827;&#30340;&#36890;&#20449;&#25928;&#29575;&#25110;&#21152;&#36895;&#25910;&#25947;&#12290;&#22312;&#26412;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31867;&#24191;&#20041;&#38750;&#32447;&#24615;SGD&#26041;&#27861;&#30340;&#39640;&#27010;&#29575;&#25910;&#25947;&#36793;&#30028;&#12290;&#23545;&#20110;&#20855;&#26377;Lipschitz&#36830;&#32493;&#26799;&#24230;&#30340;&#24378;&#20984;&#25439;&#22833;&#20989;&#25968;&#65292;&#21363;&#20351;&#22122;&#22768;&#26159;&#37325;&#23614;&#30340;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#22833;&#36133;&#27010;&#29575;&#30340;&#23545;&#25968;&#20381;&#36182;&#12290;&#19982;&#21098;&#20999;SGD&#30340;&#32467;&#26524;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#26356;&#20026;&#19968;&#33324;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#26377;&#30028;&#36755;&#20986;&#30340;&#20219;&#20309;&#38750;&#32447;&#24615;&#20989;&#25968;&#65292;&#22914;&#21098;&#20999;&#12289;&#24402;&#19968;&#21270;&#21644;&#37327;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Several recent works have studied the convergence \textit{in high probability} of stochastic gradient descent (SGD) and its clipped variant. Compared to vanilla SGD, clipped SGD is practically more stable and has the additional theoretical benefit of logarithmic dependence on the failure probability. However, the convergence of other practical nonlinear variants of SGD, e.g., sign SGD, quantized SGD and normalized SGD, that achieve improved communication efficiency or accelerated convergence is much less understood. In this work, we study the convergence bounds \textit{in high probability} of a broad class of nonlinear SGD methods. For strongly convex loss functions with Lipschitz continuous gradients, we prove a logarithmic dependence on the failure probability, even when the noise is heavy-tailed. Strictly more general than the results for clipped SGD, our results hold for any nonlinearity with bounded (component-wise or joint) outputs, such as clipping, normalization, and quantizati
&lt;/p&gt;</description></item><item><title>&#24191;&#20041;&#34203;&#23450;&#35860;&#26725;&#21305;&#37197;&#26159;&#19968;&#31181;&#26032;&#30340;&#20998;&#24067;&#21305;&#37197;&#31639;&#27861;&#65292;&#36890;&#36807;&#23558;&#20219;&#21153;&#29305;&#23450;&#30340;&#29366;&#24577;&#25104;&#26412;&#32771;&#34385;&#22312;&#20869;&#65292;&#25512;&#24191;&#20102;&#29616;&#20195;&#20998;&#24067;&#21305;&#37197;&#31639;&#27861;&#65292;&#24182;&#21487;&#29992;&#20110;&#35299;&#20915;&#26465;&#20214;&#38543;&#26426;&#26368;&#20248;&#25511;&#21046;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.02233</link><description>&lt;p&gt;
&#24191;&#20041;&#34203;&#23450;&#35860;&#26725;&#21305;&#37197;
&lt;/p&gt;
&lt;p&gt;
Generalized Schr\"odinger Bridge Matching. (arXiv:2310.02233v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02233
&lt;/p&gt;
&lt;p&gt;
&#24191;&#20041;&#34203;&#23450;&#35860;&#26725;&#21305;&#37197;&#26159;&#19968;&#31181;&#26032;&#30340;&#20998;&#24067;&#21305;&#37197;&#31639;&#27861;&#65292;&#36890;&#36807;&#23558;&#20219;&#21153;&#29305;&#23450;&#30340;&#29366;&#24577;&#25104;&#26412;&#32771;&#34385;&#22312;&#20869;&#65292;&#25512;&#24191;&#20102;&#29616;&#20195;&#20998;&#24067;&#21305;&#37197;&#31639;&#27861;&#65292;&#24182;&#21487;&#29992;&#20110;&#35299;&#20915;&#26465;&#20214;&#38543;&#26426;&#26368;&#20248;&#25511;&#21046;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#20998;&#24067;&#21305;&#37197;&#31639;&#27861;&#29992;&#20110;&#35757;&#32451;&#25193;&#25955;&#25110;&#27969;&#27169;&#22411;&#65292;&#30452;&#25509;&#35268;&#23450;&#20102;&#20004;&#20010;&#36793;&#30028;&#20998;&#24067;&#20043;&#38388;&#30340;&#36793;&#32536;&#20998;&#24067;&#30340;&#26102;&#38388;&#28436;&#21464;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#24191;&#20041;&#30340;&#20998;&#24067;&#21305;&#37197;&#35774;&#32622;&#65292;&#20854;&#20013;&#36825;&#20123;&#36793;&#32536;&#20998;&#24067;&#20165;&#20197;&#26576;&#20123;&#20219;&#21153;&#29305;&#23450;&#30446;&#26631;&#20989;&#25968;&#30340;&#35299;&#24418;&#24335;&#38544;&#21547;&#25551;&#36848;&#12290;&#36825;&#20010;&#38382;&#39064;&#35774;&#32622;&#34987;&#31216;&#20026;&#24191;&#20041;&#34203;&#23450;&#35860;&#26725;(GSB)&#65292;&#22312;&#35768;&#22810;&#31185;&#23398;&#39046;&#22495;&#20869;&#21644;&#26426;&#22120;&#23398;&#20064;&#20043;&#22806;&#24191;&#27867;&#20986;&#29616;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#24191;&#20041;&#34203;&#23450;&#35860;&#26725;&#21305;&#37197;(GSBM)&#65292;&#36825;&#26159;&#19968;&#31181;&#21463;&#26368;&#36817;&#36827;&#23637;&#21551;&#21457;&#30340;&#26032;&#30340;&#21305;&#37197;&#31639;&#27861;&#65292;&#23558;&#23427;&#20204;&#25512;&#24191;&#21040;&#21160;&#33021;&#26368;&#23567;&#21270;&#20043;&#22806;&#65292;&#24182;&#32771;&#34385;&#21040;&#20219;&#21153;&#29305;&#23450;&#30340;&#29366;&#24577;&#25104;&#26412;&#12290;&#25105;&#20204;&#35777;&#26126;&#36825;&#26679;&#30340;&#27867;&#21270;&#21487;&#20197;&#34987;&#24314;&#27169;&#20026;&#27714;&#35299;&#26465;&#20214;&#38543;&#26426;&#26368;&#20248;&#25511;&#21046;&#38382;&#39064;&#65292;&#20854;&#20013;&#21487;&#20197;&#20351;&#29992;&#39640;&#25928;&#30340;&#21464;&#20998;&#36817;&#20284;&#65292;&#24182;&#20511;&#21161;&#36335;&#24452;&#31215;&#20998;&#29702;&#35770;&#36827;&#19968;&#27493;&#21435;&#20559;&#24046;&#12290;&#19982;&#35299;&#20915;GSB&#38382;&#39064;&#30340;&#20808;&#21069;&#26041;&#27861;&#30456;&#27604;&#65292;
&lt;/p&gt;
&lt;p&gt;
Modern distribution matching algorithms for training diffusion or flow models directly prescribe the time evolution of the marginal distributions between two boundary distributions. In this work, we consider a generalized distribution matching setup, where these marginals are only implicitly described as a solution to some task-specific objective function. The problem setup, known as the Generalized Schr\"odinger Bridge (GSB), appears prevalently in many scientific areas both within and without machine learning. We propose Generalized Schr\"odinger Bridge Matching (GSBM), a new matching algorithm inspired by recent advances, generalizing them beyond kinetic energy minimization and to account for task-specific state costs. We show that such a generalization can be cast as solving conditional stochastic optimal control, for which efficient variational approximations can be used, and further debiased with the aid of path integral theory. Compared to prior methods for solving GSB problems,
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#21327;&#21516;&#25193;&#25955;&#24674;&#22797;&#20284;&#28982;&#65288;CDRL&#65289;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#21644;&#37319;&#26679;&#19968;&#31995;&#21015;&#22522;&#20110;&#33021;&#37327;&#30340;&#27169;&#22411;&#65288;EBMs&#65289;&#65292;&#36890;&#36807;&#22312;&#19981;&#26029;&#22024;&#26434;&#21270;&#30340;&#25968;&#25454;&#38598;&#29256;&#26412;&#19978;&#23450;&#20041;&#19981;&#21516;&#22122;&#22768;&#27700;&#24179;&#30340;EBMs&#65292;&#24182;&#19982;&#21021;&#22987;&#21270;&#27169;&#22411;&#37197;&#23545;&#21327;&#21516;&#35757;&#32451;&#12290;&#36825;&#31181;&#26041;&#27861;&#26088;&#22312;&#20851;&#38381;EBMs&#21644;&#20854;&#20182;&#29983;&#25104;&#26694;&#26550;&#20043;&#38388;&#30340;&#26679;&#26412;&#36136;&#37327;&#24046;&#36317;&#12290;</title><link>http://arxiv.org/abs/2309.05153</link><description>&lt;p&gt;
&#36890;&#36807;&#21327;&#21516;&#25193;&#25955;&#24674;&#22797;&#20284;&#28982;&#23398;&#20064;&#22522;&#20110;&#33021;&#37327;&#30340;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Learning Energy-Based Models by Cooperative Diffusion Recovery Likelihood. (arXiv:2309.05153v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05153
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#21327;&#21516;&#25193;&#25955;&#24674;&#22797;&#20284;&#28982;&#65288;CDRL&#65289;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#21644;&#37319;&#26679;&#19968;&#31995;&#21015;&#22522;&#20110;&#33021;&#37327;&#30340;&#27169;&#22411;&#65288;EBMs&#65289;&#65292;&#36890;&#36807;&#22312;&#19981;&#26029;&#22024;&#26434;&#21270;&#30340;&#25968;&#25454;&#38598;&#29256;&#26412;&#19978;&#23450;&#20041;&#19981;&#21516;&#22122;&#22768;&#27700;&#24179;&#30340;EBMs&#65292;&#24182;&#19982;&#21021;&#22987;&#21270;&#27169;&#22411;&#37197;&#23545;&#21327;&#21516;&#35757;&#32451;&#12290;&#36825;&#31181;&#26041;&#27861;&#26088;&#22312;&#20851;&#38381;EBMs&#21644;&#20854;&#20182;&#29983;&#25104;&#26694;&#26550;&#20043;&#38388;&#30340;&#26679;&#26412;&#36136;&#37327;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39640;&#32500;&#25968;&#25454;&#19978;&#20351;&#29992;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#35757;&#32451;&#33021;&#37327;&#22522;&#20934;&#27169;&#22411;&#65288;EBMs&#65289;&#21487;&#33021;&#20855;&#26377;&#25361;&#25112;&#24615;&#19988;&#32791;&#26102;&#36739;&#38271;&#12290;&#22240;&#27492;&#65292;EBMs&#21644;&#20854;&#20182;&#29983;&#25104;&#26694;&#26550;&#65288;&#22914;GANs&#21644;&#25193;&#25955;&#27169;&#22411;&#65289;&#20043;&#38388;&#23384;&#22312;&#26126;&#26174;&#30340;&#26679;&#26412;&#36136;&#37327;&#24046;&#36317;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#21463;&#26368;&#36817;&#36890;&#36807;&#26368;&#22823;&#21270;&#25193;&#25955;&#24674;&#22797;&#20284;&#28982;&#65288;DRL&#65289;&#26469;&#23398;&#20064;EBMs&#30340;&#21162;&#21147;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21327;&#21516;&#25193;&#25955;&#24674;&#22797;&#20284;&#28982;&#65288;CDRL&#65289;&#65292;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#26469;&#21487;&#34892;&#22320;&#23398;&#20064;&#21644;&#20174;&#19968;&#31995;&#21015;EBMs&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#36825;&#20123;EBMs&#23450;&#20041;&#22312;&#36234;&#26469;&#36234;&#22024;&#26434;&#30340;&#25968;&#25454;&#38598;&#29256;&#26412;&#19978;&#65292;&#24182;&#19982;&#27599;&#20010;EBM&#30340;&#21021;&#22987;&#21270;&#27169;&#22411;&#37197;&#23545;&#12290;&#22312;&#27599;&#20010;&#22122;&#22768;&#27700;&#24179;&#19978;&#65292;&#21021;&#22987;&#21270;&#27169;&#22411;&#23398;&#20064;&#22312;EBM&#30340;&#37319;&#26679;&#36807;&#31243;&#20013;&#20998;&#25674;&#65292;&#32780;&#20004;&#20010;&#27169;&#22411;&#22312;&#21327;&#21516;&#35757;&#32451;&#26694;&#26550;&#20869;&#20849;&#21516;&#20272;&#35745;&#12290;&#21021;&#22987;&#21270;&#27169;&#22411;&#29983;&#25104;&#30340;&#26679;&#26412;&#20316;&#20026;&#36215;&#22987;&#28857;&#65292;&#32463;&#36807;EBM&#30340;&#20960;&#20010;&#37319;&#26679;&#27493;&#39588;&#36827;&#34892;&#25913;&#36827;&#12290;&#36890;&#36807;&#25913;&#36827;&#21518;&#30340;&#26679;&#26412;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;&#24674;&#22797;&#20284;&#28982;&#26469;&#20248;&#21270;EBM&#12290;
&lt;/p&gt;
&lt;p&gt;
Training energy-based models (EBMs) with maximum likelihood estimation on high-dimensional data can be both challenging and time-consuming. As a result, there a noticeable gap in sample quality between EBMs and other generative frameworks like GANs and diffusion models. To close this gap, inspired by the recent efforts of learning EBMs by maximimizing diffusion recovery likelihood (DRL), we propose cooperative diffusion recovery likelihood (CDRL), an effective approach to tractably learn and sample from a series of EBMs defined on increasingly noisy versons of a dataset, paired with an initializer model for each EBM. At each noise level, the initializer model learns to amortize the sampling process of the EBM, and the two models are jointly estimated within a cooperative training framework. Samples from the initializer serve as starting points that are refined by a few sampling steps from the EBM. With the refined samples, the EBM is optimized by maximizing recovery likelihood, while t
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#30830;&#23450;&#24615;&#29305;&#24449;&#25490;&#24207;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#29305;&#24449;&#37325;&#35201;&#24615;&#20540;&#30340;&#20004;&#20004;&#27604;&#36739;&#65292;&#21487;&#20197;&#20135;&#29983;&#25490;&#24207;&#21644;&#21516;&#26102;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#24182;&#19988;&#21487;&#20197;&#36873;&#25321;&#21069;k&#20010;&#38598;&#21512;&#12290;</title><link>http://arxiv.org/abs/2307.15361</link><description>&lt;p&gt;
&#30830;&#23450;&#24615;&#29305;&#24449;&#25490;&#24207;
&lt;/p&gt;
&lt;p&gt;
Confident Feature Ranking. (arXiv:2307.15361v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15361
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#30830;&#23450;&#24615;&#29305;&#24449;&#25490;&#24207;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#29305;&#24449;&#37325;&#35201;&#24615;&#20540;&#30340;&#20004;&#20004;&#27604;&#36739;&#65292;&#21487;&#20197;&#20135;&#29983;&#25490;&#24207;&#21644;&#21516;&#26102;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#24182;&#19988;&#21487;&#20197;&#36873;&#25321;&#21069;k&#20010;&#38598;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29305;&#24449;&#37325;&#35201;&#24615;&#30340;&#35299;&#37322;&#36890;&#24120;&#20381;&#36182;&#20110;&#29305;&#24449;&#30340;&#30456;&#23545;&#39034;&#24207;&#32780;&#19981;&#26159;&#25968;&#20540;&#26412;&#36523;&#65292;&#20063;&#23601;&#26159;&#25490;&#24207;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#35745;&#31639;&#37325;&#35201;&#24615;&#20540;&#26102;&#20351;&#29992;&#30340;&#26679;&#26412;&#37327;&#36739;&#23567;&#65292;&#25490;&#24207;&#21487;&#33021;&#19981;&#31283;&#23450;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20107;&#21518;&#37325;&#35201;&#24615;&#26041;&#27861;&#65292;&#21487;&#20197;&#20135;&#29983;&#19968;&#31181;&#25490;&#24207;&#21644;&#21516;&#26102;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#22522;&#20110;&#29305;&#24449;&#37325;&#35201;&#24615;&#20540;&#30340;&#20004;&#20004;&#27604;&#36739;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#20445;&#35777;&#39640;&#27010;&#29575;&#21253;&#21547;&#8220;&#30495;&#23454;&#8221;&#65288;&#26080;&#38480;&#26679;&#26412;&#65289;&#25490;&#24207;&#65292;&#24182;&#20801;&#35768;&#36873;&#25321;&#21069;k&#20010;&#38598;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Interpretation of feature importance values often relies on the relative order of the features rather than on the value itself, referred to as ranking. However, the order may be unstable due to the small sample sizes used in calculating the importance values. We propose that post-hoc importance methods produce a ranking and simultaneous confident intervals for the rankings. Based on pairwise comparisons of the feature importance values, our method is guaranteed to include the ``true'' (infinite sample) ranking with high probability and allows for selecting top-k sets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#23398;&#20064;&#21160;&#24577;&#65292;&#21457;&#29616;&#32463;&#39564;&#39118;&#38505;&#30340;&#19979;&#38477;&#36895;&#29575;&#26159;&#38750;&#21333;&#35843;&#30340;&#12290;&#22312;&#20998;&#24067;&#31526;&#21512;&#21333;&#25351;&#25968;&#27169;&#22411;&#30340;&#39640;&#32500;&#23485;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#23398;&#20064;&#29575;&#21442;&#25968;&#21270;&#28165;&#26224;&#30340;&#38454;&#27573;&#36716;&#25442;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#32593;&#32476;&#23398;&#20064;&#21160;&#24577;&#30340;&#20840;&#38754;&#20998;&#26512;&#12290;&#25105;&#20204;&#36824;&#20026;&#26089;&#26399;&#23398;&#20064;&#26102;&#25152;&#23398;&#27169;&#22411;&#30340;&#31616;&#21333;&#24615;&#25552;&#20379;&#20102;&#29702;&#35770;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2303.00055</link><description>&lt;p&gt;
&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#23398;&#20064;&#26102;&#38388;&#23610;&#24230;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Learning time-scales in two-layers neural networks. (arXiv:2303.00055v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.00055
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#23398;&#20064;&#21160;&#24577;&#65292;&#21457;&#29616;&#32463;&#39564;&#39118;&#38505;&#30340;&#19979;&#38477;&#36895;&#29575;&#26159;&#38750;&#21333;&#35843;&#30340;&#12290;&#22312;&#20998;&#24067;&#31526;&#21512;&#21333;&#25351;&#25968;&#27169;&#22411;&#30340;&#39640;&#32500;&#23485;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#23398;&#20064;&#29575;&#21442;&#25968;&#21270;&#28165;&#26224;&#30340;&#38454;&#27573;&#36716;&#25442;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#32593;&#32476;&#23398;&#20064;&#21160;&#24577;&#30340;&#20840;&#38754;&#20998;&#26512;&#12290;&#25105;&#20204;&#36824;&#20026;&#26089;&#26399;&#23398;&#20064;&#26102;&#25152;&#23398;&#27169;&#22411;&#30340;&#31616;&#21333;&#24615;&#25552;&#20379;&#20102;&#29702;&#35770;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#20855;&#26377;&#22810;&#20010;&#24341;&#20154;&#27880;&#24847;&#30340;&#29305;&#28857;&#12290;&#23588;&#20854;&#26159;&#65292;&#22312;&#22823;&#25209;&#37327;&#25968;&#25454;&#24179;&#22343;&#21518;&#65292;&#32463;&#39564;&#39118;&#38505;&#30340;&#19979;&#38477;&#36895;&#29575;&#26159;&#38750;&#21333;&#35843;&#30340;&#12290;&#20960;&#20046;&#27809;&#26377;&#36827;&#23637;&#30340;&#38271;&#21608;&#26399;&#21644;&#24555;&#36895;&#19979;&#38477;&#30340;&#38388;&#38548;&#20132;&#26367;&#20986;&#29616;&#12290;&#36825;&#20123;&#36830;&#32493;&#30340;&#23398;&#20064;&#38454;&#27573;&#24448;&#24448;&#22312;&#38750;&#24120;&#19981;&#21516;&#30340;&#26102;&#38388;&#23610;&#24230;&#19978;&#36827;&#34892;&#12290;&#26368;&#21518;&#65292;&#22312;&#26089;&#26399;&#38454;&#27573;&#23398;&#20064;&#30340;&#27169;&#22411;&#36890;&#24120;&#26159;&#8220;&#31616;&#21333;&#30340;&#8221;&#25110;&#8220;&#26131;&#20110;&#23398;&#20064;&#30340;&#8221;&#65292;&#23613;&#31649;&#20197;&#38590;&#20197;&#24418;&#24335;&#21270;&#30340;&#26041;&#24335;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#24067;&#31526;&#21512;&#21333;&#25351;&#25968;&#27169;&#22411;&#30340;&#39640;&#32500;&#23485;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#26799;&#24230;&#27969;&#21160;&#21147;&#23398;&#65292;&#22312;&#19968;&#31995;&#21015;&#26032;&#30340;&#20005;&#23494;&#32467;&#26524;&#12289;&#38750;&#20005;&#23494;&#25968;&#23398;&#25512;&#23548;&#21644;&#25968;&#20540;&#23454;&#39564;&#30340;&#22522;&#30784;&#19978;&#65292;&#25552;&#20379;&#20102;&#23545;&#32593;&#32476;&#23398;&#20064;&#21160;&#24577;&#30340;&#20840;&#38754;&#20998;&#26512;&#12290;&#25105;&#20204;&#29305;&#21035;&#25351;&#20986;&#65292;&#25105;&#20204;&#36890;&#36807;&#23398;&#20064;&#29575;&#21442;&#25968;&#21270;&#28165;&#26224;&#30340;&#38454;&#27573;&#36716;&#25442;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#20204;&#19982;&#38271;&#21608;&#26399;&#30340;&#20986;&#29616;&#21644;&#28040;&#22833;&#26377;&#20851;&#12290;&#25105;&#20204;&#36824;&#20026;&#26089;&#26399;&#23398;&#20064;&#26102;&#25152;&#23398;&#27169;&#22411;&#30340;&#31616;&#21333;&#24615;&#25552;&#20379;&#20102;&#29702;&#35770;&#35299;&#37322;&#65292;&#24182;&#35777;&#26126;&#23427;&#20204;&#21487;&#20197;&#29992;&#20110;&#35268;&#33539;&#35757;&#32451;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gradient-based learning in multi-layer neural networks displays a number of striking features. In particular, the decrease rate of empirical risk is non-monotone even after averaging over large batches. Long plateaus in which one observes barely any progress alternate with intervals of rapid decrease. These successive phases of learning often take place on very different time scales. Finally, models learnt in an early phase are typically `simpler' or `easier to learn' although in a way that is difficult to formalize.  Although theoretical explanations of these phenomena have been put forward, each of them captures at best certain specific regimes. In this paper, we study the gradient flow dynamics of a wide two-layer neural network in high-dimension, when data are distributed according to a single-index model (i.e., the target function depends on a one-dimensional projection of the covariates). Based on a mixture of new rigorous results, non-rigorous mathematical derivations, and numer
&lt;/p&gt;</description></item></channel></rss>