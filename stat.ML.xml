<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#35780;&#20272;&#20102;&#27979;&#35797;&#36873;&#25321;&#26041;&#27861;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#27979;&#35797;&#20013;&#30340;&#31283;&#23450;&#24615;&#65292;&#36890;&#36807;&#25506;&#35752;&#36825;&#20123;&#26041;&#27861;&#30340;&#28508;&#22312;&#38519;&#38449;&#24182;&#36827;&#34892;&#23454;&#35777;&#30740;&#31350;&#65292;&#25581;&#31034;&#20102;&#23427;&#20204;&#30340;&#21487;&#38752;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.01314</link><description>&lt;p&gt;
&#35780;&#20272;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#27979;&#35797;&#36873;&#25321;&#26041;&#27861;&#30340;&#31283;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
Evaluating the Robustness of Test Selection Methods for Deep Neural Networks. (arXiv:2308.01314v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01314
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35780;&#20272;&#20102;&#27979;&#35797;&#36873;&#25321;&#26041;&#27861;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#27979;&#35797;&#20013;&#30340;&#31283;&#23450;&#24615;&#65292;&#36890;&#36807;&#25506;&#35752;&#36825;&#20123;&#26041;&#27861;&#30340;&#28508;&#22312;&#38519;&#38449;&#24182;&#36827;&#34892;&#23454;&#35777;&#30740;&#31350;&#65292;&#25581;&#31034;&#20102;&#23427;&#20204;&#30340;&#21487;&#38752;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#23545;&#25910;&#38598;&#30340;&#21407;&#22987;&#25968;&#25454;&#36827;&#34892;&#26631;&#35760;&#25152;&#38656;&#30340;&#26102;&#38388;&#21644;&#21171;&#21160;&#21147;&#65292;&#27979;&#35797;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#31995;&#32479;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#65292;&#20294;&#20063;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20026;&#20102;&#20943;&#36731;&#26631;&#35760;&#24037;&#20316;&#37327;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#22810;&#31181;&#27979;&#35797;&#36873;&#25321;&#26041;&#27861;&#65292;&#21482;&#38656;&#23545;&#27979;&#35797;&#25968;&#25454;&#30340;&#23376;&#38598;&#36827;&#34892;&#26631;&#35760;&#21363;&#21487;&#28385;&#36275;&#27979;&#35797;&#35201;&#27714;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#36825;&#20123;&#25253;&#36947;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#30340;&#26041;&#27861;&#21482;&#22312;&#31616;&#21333;&#24773;&#26223;&#19979;&#36827;&#34892;&#35780;&#20272;&#65292;&#20363;&#22914;&#65292;&#22312;&#21407;&#22987;&#27979;&#35797;&#25968;&#25454;&#19978;&#36827;&#34892;&#27979;&#35797;&#12290;&#36825;&#35753;&#25105;&#20204;&#20135;&#29983;&#20102;&#19968;&#20010;&#38382;&#39064;&#65306;&#23427;&#20204;&#24635;&#26159;&#21487;&#38752;&#30340;&#21527;&#65311;&#26412;&#25991;&#25506;&#35752;&#20102;&#27979;&#35797;&#36873;&#25321;&#26041;&#27861;&#22312;&#27979;&#35797;&#20013;&#22833;&#36133;&#30340;&#26102;&#38388;&#21644;&#31243;&#24230;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#39318;&#20808;&#65292;&#25105;&#20204;&#22522;&#20110;&#20854;&#26500;&#24314;&#26041;&#27861;&#65292;&#30830;&#23450;&#20102;&#26469;&#33258;&#39030;&#32423;&#20250;&#35758;&#30340;11&#31181;&#36873;&#25321;&#26041;&#27861;&#30340;&#28508;&#22312;&#38519;&#38449;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#23545;&#20116;&#20010;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#27599;&#20010;&#25968;&#25454;&#38598;&#26377;&#20004;&#20010;&#27169;&#22411;&#26550;&#26500;&#65292;&#20197;&#20174;&#32463;&#39564;&#19978;&#30830;&#35748;&#36825;&#20123;&#38519;&#38449;&#30340;&#23384;&#22312;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#28436;&#31034;&#20102;&#38519;&#38449;&#22914;&#20309;&#30772;&#22351;&#36825;&#20123;&#26041;&#27861;&#30340;&#21487;&#38752;&#24615;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25925;&#38556;&#26816;&#27979;&#26041;&#27861;&#30340;&#32570;&#38519;&#12290;
&lt;/p&gt;
&lt;p&gt;
Testing deep learning-based systems is crucial but challenging due to the required time and labor for labeling collected raw data. To alleviate the labeling effort, multiple test selection methods have been proposed where only a subset of test data needs to be labeled while satisfying testing requirements. However, we observe that such methods with reported promising results are only evaluated under simple scenarios, e.g., testing on original test data. This brings a question to us: are they always reliable? In this paper, we explore when and to what extent test selection methods fail for testing. Specifically, first, we identify potential pitfalls of 11 selection methods from top-tier venues based on their construction. Second, we conduct a study on five datasets with two model architectures per dataset to empirically confirm the existence of these pitfalls. Furthermore, we demonstrate how pitfalls can break the reliability of these methods. Concretely, methods for fault detection suf
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#23618;&#27425;&#21270;softmax&#30340;&#20840;&#23616;&#23618;&#27425;&#21270;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#23618;&#27425;&#32467;&#26500;&#30340;&#20998;&#31867;&#20219;&#21153;&#65292;&#24182;&#19988;&#22312;&#22235;&#20010;&#25991;&#26412;&#20998;&#31867;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#30456;&#36739;&#20110;&#24120;&#35268;softmax&#21644;&#24179;&#38754;&#20998;&#31867;&#22120;&#65292;&#23618;&#27425;&#21270;softmax&#33021;&#22815;&#21462;&#24471;&#26356;&#22909;&#30340;&#20998;&#31867;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.01210</link><description>&lt;p&gt;
&#20351;&#29992;&#23618;&#27425;&#21270;softmax&#30340;&#20840;&#23616;&#23618;&#27425;&#21270;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Global Hierarchical Neural Networks using Hierarchical Softmax. (arXiv:2308.01210v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01210
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#23618;&#27425;&#21270;softmax&#30340;&#20840;&#23616;&#23618;&#27425;&#21270;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#23618;&#27425;&#32467;&#26500;&#30340;&#20998;&#31867;&#20219;&#21153;&#65292;&#24182;&#19988;&#22312;&#22235;&#20010;&#25991;&#26412;&#20998;&#31867;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#30456;&#36739;&#20110;&#24120;&#35268;softmax&#21644;&#24179;&#38754;&#20998;&#31867;&#22120;&#65292;&#23618;&#27425;&#21270;softmax&#33021;&#22815;&#21462;&#24471;&#26356;&#22909;&#30340;&#20998;&#31867;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#22312;&#20854;&#20013;&#20351;&#29992;&#23618;&#27425;&#21270;softmax&#26469;&#21019;&#24314;&#19968;&#20010;&#20840;&#23616;&#23618;&#27425;&#21270;&#20998;&#31867;&#22120;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#20219;&#20309;&#20855;&#26377;&#33258;&#28982;&#23618;&#27425;&#32467;&#26500;&#30340;&#20998;&#31867;&#20219;&#21153;&#12290;&#25105;&#20204;&#22312;&#22235;&#20010;&#25991;&#26412;&#20998;&#31867;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#23454;&#35777;&#32467;&#26524;&#12290;&#22312;&#25152;&#26377;&#25968;&#25454;&#38598;&#20013;&#65292;&#30456;&#23545;&#20110;&#20351;&#29992;&#24179;&#38754;&#20998;&#31867;&#22120;&#30340;&#24120;&#35268;softmax&#65292;&#23618;&#27425;&#21270;softmax&#22312;&#23439;F1&#21644;&#23439;&#21484;&#22238;&#29575;&#26041;&#38754;&#37117;&#26377;&#25152;&#25552;&#21319;&#12290;&#22312;&#22235;&#20010;&#25968;&#25454;&#38598;&#20013;&#30340;&#19977;&#20010;&#25968;&#25454;&#38598;&#20013;&#65292;&#23618;&#27425;&#21270;softmax&#23454;&#29616;&#20102;&#26356;&#39640;&#30340;&#24494;&#20934;&#30830;&#29575;&#21644;&#23439;&#31934;&#30830;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a framework in which hierarchical softmax is used to create a global hierarchical classifier. The approach is applicable for any classification task where there is a natural hierarchy among classes. We show empirical results on four text classification datasets. In all datasets the hierarchical softmax improved on the regular softmax used in a flat classifier in terms of macro-F1 and macro-recall. In three out of four datasets hierarchical softmax achieved a higher micro-accuracy and macro-precision.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20010;&#24615;&#21270;&#26102;&#38388;&#34928;&#20943;&#20989;&#25968;&#30340;&#33258;&#36866;&#24212;&#21327;&#21516;&#36807;&#28388;&#37329;&#34701;&#20135;&#21697;&#25512;&#33616;&#31995;&#32479;&#65292;&#20197;&#35299;&#20915;&#20256;&#32479;&#25512;&#33616;&#31995;&#32479;&#22312;&#21160;&#24577;&#29615;&#22659;&#19979;&#25552;&#20379;&#21487;&#38752;&#25512;&#33616;&#30340;&#25361;&#25112;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#24314;&#27169;&#23458;&#25143;&#21644;&#20135;&#21697;&#20043;&#38388;&#30340;&#21160;&#24577;&#21327;&#21516;&#20449;&#21495;&#65292;&#22788;&#29702;&#37329;&#34701;&#25968;&#25454;&#30340;&#38750;&#24179;&#31283;&#24615;&#65292;&#20026;&#29992;&#25143;&#25552;&#20379;&#21487;&#38752;&#30340;&#25512;&#33616;&#12290;</title><link>http://arxiv.org/abs/2308.01208</link><description>&lt;p&gt;
&#20010;&#24615;&#21270;&#26102;&#38388;&#34928;&#20943;&#20989;&#25968;&#30340;&#33258;&#36866;&#24212;&#21327;&#21516;&#36807;&#28388;&#37329;&#34701;&#20135;&#21697;&#25512;&#33616;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Adaptive Collaborative Filtering with Personalized Time Decay Functions for Financial Product Recommendation. (arXiv:2308.01208v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01208
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20010;&#24615;&#21270;&#26102;&#38388;&#34928;&#20943;&#20989;&#25968;&#30340;&#33258;&#36866;&#24212;&#21327;&#21516;&#36807;&#28388;&#37329;&#34701;&#20135;&#21697;&#25512;&#33616;&#31995;&#32479;&#65292;&#20197;&#35299;&#20915;&#20256;&#32479;&#25512;&#33616;&#31995;&#32479;&#22312;&#21160;&#24577;&#29615;&#22659;&#19979;&#25552;&#20379;&#21487;&#38752;&#25512;&#33616;&#30340;&#25361;&#25112;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#24314;&#27169;&#23458;&#25143;&#21644;&#20135;&#21697;&#20043;&#38388;&#30340;&#21160;&#24577;&#21327;&#21516;&#20449;&#21495;&#65292;&#22788;&#29702;&#37329;&#34701;&#25968;&#25454;&#30340;&#38750;&#24179;&#31283;&#24615;&#65292;&#20026;&#29992;&#25143;&#25552;&#20379;&#21487;&#38752;&#30340;&#25512;&#33616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#25512;&#33616;&#31995;&#32479;&#36890;&#24120;&#20551;&#35774;&#21382;&#21490;&#25968;&#25454;&#26159;&#19981;&#21464;&#30340;&#65292;&#26080;&#27861;&#32771;&#34385;&#29992;&#25143;&#20559;&#22909;&#30340;&#21160;&#24577;&#24615;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#26102;&#38388;&#25935;&#24863;&#29615;&#22659;&#20013;&#25552;&#20379;&#21487;&#38752;&#25512;&#33616;&#30340;&#33021;&#21147;&#12290;&#36825;&#19968;&#20551;&#35774;&#22312;&#37329;&#34701;&#39046;&#22495;&#23588;&#20854;&#26377;&#38382;&#39064;&#65292;&#22240;&#20026;&#37329;&#34701;&#20135;&#21697;&#30340;&#20272;&#20540;&#19981;&#26029;&#21464;&#21270;&#65292;&#23548;&#33268;&#23458;&#25143;&#20852;&#36259;&#39057;&#32321;&#36716;&#31227;&#12290;&#36825;&#20123;&#28436;&#21464;&#30340;&#20852;&#36259;&#21487;&#20197;&#36890;&#36807;&#36807;&#21435;&#23458;&#25143;-&#20135;&#21697;&#20132;&#20114;&#20013;&#24635;&#32467;&#20986;&#26469;&#65292;&#20854;&#25928;&#29992;&#38543;&#30528;&#26102;&#38388;&#30340;&#25512;&#31227;&#20250;&#22240;&#23458;&#25143;&#32780;&#24322;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26102;&#38388;&#30456;&#20851;&#30340;&#21327;&#21516;&#36807;&#28388;&#31639;&#27861;&#65292;&#21487;&#20197;&#20351;&#29992;&#20010;&#24615;&#21270;&#34928;&#20943;&#20989;&#25968;&#33258;&#36866;&#24212;&#22320;&#25240;&#20215;&#36828;&#31163;&#30340;&#23458;&#25143;-&#20135;&#21697;&#20132;&#20114;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26088;&#22312;&#22788;&#29702;&#37329;&#34701;&#25968;&#25454;&#30340;&#38750;&#24179;&#31283;&#24615;&#65292;&#24182;&#36890;&#36807;&#24314;&#27169;&#23458;&#25143;&#21644;&#20135;&#21697;&#20043;&#38388;&#30340;&#21160;&#24577;&#21327;&#21516;&#20449;&#21495;&#26469;&#20135;&#29983;&#21487;&#38752;&#30340;&#25512;&#33616;&#12290;&#25105;&#20204;&#20351;&#29992;&#19987;&#26377;&#25968;&#25454;&#38598;&#23545;&#25105;&#20204;&#30340;&#26041;&#27861;&#36827;&#34892;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Classical recommender systems often assume that historical data are stationary and fail to account for the dynamic nature of user preferences, limiting their ability to provide reliable recommendations in time-sensitive settings. This assumption is particularly problematic in finance, where financial products exhibit continuous changes in valuations, leading to frequent shifts in client interests. These evolving interests, summarized in the past client-product interactions, see their utility fade over time with a degree that might differ from one client to another. To address this challenge, we propose a time-dependent collaborative filtering algorithm that can adaptively discount distant client-product interactions using personalized decay functions. Our approach is designed to handle the non-stationarity of financial data and produce reliable recommendations by modeling the dynamic collaborative signals between clients and products. We evaluate our method using a proprietary dataset 
&lt;/p&gt;</description></item><item><title>LLMs&#22312;&#22788;&#29702;&#21487;&#35299;&#37322;&#27169;&#22411;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#25552;&#20379;&#20102;&#20840;&#38754;&#30340;&#27169;&#22411;&#32423;&#24635;&#32467;&#21644;&#33258;&#21160;&#21270;&#30340;&#24322;&#24120;&#26816;&#27979;&#12289;&#21407;&#22240;&#25551;&#36848;&#21644;&#20462;&#22797;&#24314;&#35758;&#12290;&#22312;&#21307;&#30103;&#20445;&#20581;&#39046;&#22495;&#20351;&#29992;&#24191;&#20041;&#21487;&#21152;&#27169;&#22411;&#20316;&#20026;&#31034;&#20363;&#65292;&#21516;&#26102;&#20171;&#32461;&#20102;&#24320;&#28304;&#30340;LLM-GAM&#25509;&#21475;&#21253;$\texttt{TalkToEBM}$&#12290;</title><link>http://arxiv.org/abs/2308.01157</link><description>&lt;p&gt;
LLMs&#29702;&#35299;&#29627;&#29827;&#30418;&#27169;&#22411;&#65292;&#21457;&#29616;&#24778;&#21916;&#24182;&#25552;&#20986;&#20462;&#22797;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;
LLMs Understand Glass-Box Models, Discover Surprises, and Suggest Repairs. (arXiv:2308.01157v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01157
&lt;/p&gt;
&lt;p&gt;
LLMs&#22312;&#22788;&#29702;&#21487;&#35299;&#37322;&#27169;&#22411;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#25552;&#20379;&#20102;&#20840;&#38754;&#30340;&#27169;&#22411;&#32423;&#24635;&#32467;&#21644;&#33258;&#21160;&#21270;&#30340;&#24322;&#24120;&#26816;&#27979;&#12289;&#21407;&#22240;&#25551;&#36848;&#21644;&#20462;&#22797;&#24314;&#35758;&#12290;&#22312;&#21307;&#30103;&#20445;&#20581;&#39046;&#22495;&#20351;&#29992;&#24191;&#20041;&#21487;&#21152;&#27169;&#22411;&#20316;&#20026;&#31034;&#20363;&#65292;&#21516;&#26102;&#20171;&#32461;&#20102;&#24320;&#28304;&#30340;LLM-GAM&#25509;&#21475;&#21253;$\texttt{TalkToEBM}$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23637;&#31034;&#20102;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#22788;&#29702;&#21487;&#35299;&#37322;&#27169;&#22411;&#26041;&#38754;&#30340;&#20986;&#33394;&#34920;&#29616;&#65292;&#36825;&#20123;&#27169;&#22411;&#21487;&#20197;&#23558;&#22797;&#26434;&#32467;&#26524;&#20998;&#35299;&#20026;&#21333;&#19968;&#21464;&#37327;&#30340;&#22270;&#34920;&#31034;&#32452;&#20214;&#12290;&#36890;&#36807;&#37319;&#29992;&#23618;&#27425;&#25512;&#29702;&#30340;&#26041;&#27861;&#65292;LLMs&#33021;&#22815;&#22312;&#19981;&#38656;&#35201;&#25972;&#20010;&#27169;&#22411;&#36866;&#24212;&#19978;&#19979;&#25991;&#30340;&#24773;&#20917;&#19979;&#25552;&#20379;&#20840;&#38754;&#30340;&#27169;&#22411;&#32423;&#24635;&#32467;&#12290;&#36825;&#31181;&#26041;&#27861;&#20351;LLMs&#33021;&#22815;&#24212;&#29992;&#20854;&#24191;&#27867;&#30340;&#32972;&#26223;&#30693;&#35782;&#26469;&#33258;&#21160;&#23436;&#25104;&#25968;&#25454;&#31185;&#23398;&#20013;&#30340;&#24120;&#35265;&#20219;&#21153;&#65292;&#22914;&#26816;&#27979;&#19982;&#20808;&#21069;&#30693;&#35782;&#30456;&#30683;&#30462;&#30340;&#24322;&#24120;&#65292;&#25551;&#36848;&#24322;&#24120;&#30340;&#28508;&#22312;&#21407;&#22240;&#65292;&#24182;&#25552;&#20986;&#21435;&#38500;&#24322;&#24120;&#30340;&#20462;&#22797;&#24314;&#35758;&#12290;&#25105;&#20204;&#20351;&#29992;&#21307;&#30103;&#20445;&#20581;&#39046;&#22495;&#30340;&#22810;&#20010;&#31034;&#20363;&#26469;&#35777;&#26126;LLMs&#30340;&#36825;&#20123;&#26032;&#33021;&#21147;&#30340;&#23454;&#29992;&#24615;&#65292;&#29305;&#21035;&#24378;&#35843;&#24191;&#20041;&#21487;&#21152;&#27169;&#22411;(GAMs)&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;$\texttt{TalkToEBM}$&#21253;&#20316;&#20026;&#19968;&#20010;&#24320;&#28304;&#30340;LLM-GAM&#25509;&#21475;&#36827;&#34892;&#20171;&#32461;&#12290;
&lt;/p&gt;
&lt;p&gt;
We show that large language models (LLMs) are remarkably good at working with interpretable models that decompose complex outcomes into univariate graph-represented components. By adopting a hierarchical approach to reasoning, LLMs can provide comprehensive model-level summaries without ever requiring the entire model to fit in context. This approach enables LLMs to apply their extensive background knowledge to automate common tasks in data science such as detecting anomalies that contradict prior knowledge, describing potential reasons for the anomalies, and suggesting repairs that would remove the anomalies. We use multiple examples in healthcare to demonstrate the utility of these new capabilities of LLMs, with particular emphasis on Generalized Additive Models (GAMs). Finally, we present the package $\texttt{TalkToEBM}$ as an open-source LLM-GAM interface.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20840;&#23556;&#24207;&#21015;&#31070;&#32463;&#20284;&#28982;&#20272;&#35745;&#65288;SSNL&#65289;&#36827;&#34892;&#22522;&#20110;&#20223;&#30495;&#30340;&#25512;&#26029;&#30340;&#26032;&#26041;&#27861;&#65292;&#22312;&#27169;&#22411;&#20013;&#26080;&#27861;&#35745;&#31639;&#20284;&#28982;&#20989;&#25968;&#24182;&#19988;&#21482;&#33021;&#20351;&#29992;&#27169;&#25311;&#22120;&#29983;&#25104;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;SSNL&#36890;&#36807;&#25311;&#21512;&#38477;&#32500;&#30340;&#20840;&#23556;&#24402;&#19968;&#21270;&#27969;&#27169;&#22411;&#65292;&#24182;&#23558;&#20854;&#20316;&#20026;&#26367;&#20195;&#20284;&#28982;&#20989;&#25968;&#65292;&#35299;&#20915;&#20102;&#20808;&#21069;&#22522;&#20110;&#20284;&#28982;&#26041;&#27861;&#22312;&#39640;&#32500;&#25968;&#25454;&#38598;&#20013;&#36935;&#21040;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;&#21508;&#31181;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#20854;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.01054</link><description>&lt;p&gt;
&#20351;&#29992;&#20840;&#23556;&#24207;&#21015;&#31070;&#32463;&#20284;&#28982;&#20272;&#35745;&#36827;&#34892;&#22522;&#20110;&#20223;&#30495;&#30340;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Simulation-based inference using surjective sequential neural likelihood estimation. (arXiv:2308.01054v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01054
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20840;&#23556;&#24207;&#21015;&#31070;&#32463;&#20284;&#28982;&#20272;&#35745;&#65288;SSNL&#65289;&#36827;&#34892;&#22522;&#20110;&#20223;&#30495;&#30340;&#25512;&#26029;&#30340;&#26032;&#26041;&#27861;&#65292;&#22312;&#27169;&#22411;&#20013;&#26080;&#27861;&#35745;&#31639;&#20284;&#28982;&#20989;&#25968;&#24182;&#19988;&#21482;&#33021;&#20351;&#29992;&#27169;&#25311;&#22120;&#29983;&#25104;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;SSNL&#36890;&#36807;&#25311;&#21512;&#38477;&#32500;&#30340;&#20840;&#23556;&#24402;&#19968;&#21270;&#27969;&#27169;&#22411;&#65292;&#24182;&#23558;&#20854;&#20316;&#20026;&#26367;&#20195;&#20284;&#28982;&#20989;&#25968;&#65292;&#35299;&#20915;&#20102;&#20808;&#21069;&#22522;&#20110;&#20284;&#28982;&#26041;&#27861;&#22312;&#39640;&#32500;&#25968;&#25454;&#38598;&#20013;&#36935;&#21040;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;&#21508;&#31181;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#20854;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#20840;&#23556;&#24207;&#21015;&#31070;&#32463;&#20284;&#28982;&#65288;SSNL&#65289;&#20272;&#35745;&#26041;&#27861;&#65292;&#36825;&#26159;&#19968;&#31181;&#22312;&#27169;&#22411;&#20013;&#26080;&#27861;&#35745;&#31639;&#20284;&#28982;&#20989;&#25968;&#24182;&#19988;&#21482;&#33021;&#20351;&#29992;&#21487;&#20197;&#29983;&#25104;&#21512;&#25104;&#25968;&#25454;&#30340;&#27169;&#25311;&#22120;&#26102;&#36827;&#34892;&#22522;&#20110;&#20223;&#30495;&#30340;&#25512;&#26029;&#30340;&#26032;&#26041;&#27861;&#12290;SSNL&#25311;&#21512;&#19968;&#20010;&#38477;&#32500;&#30340;&#20840;&#23556;&#24402;&#19968;&#21270;&#27969;&#27169;&#22411;&#65292;&#24182;&#23558;&#20854;&#29992;&#20316;&#26367;&#20195;&#20284;&#28982;&#20989;&#25968;&#65292;&#20174;&#32780;&#21487;&#20197;&#20351;&#29992;&#20256;&#32479;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#65292;&#21253;&#25324;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#25110;&#21464;&#20998;&#25512;&#26029;&#12290;&#36890;&#36807;&#23558;&#25968;&#25454;&#23884;&#20837;&#21040;&#20302;&#32500;&#31354;&#38388;&#20013;&#65292;SSNL&#35299;&#20915;&#20102;&#20808;&#21069;&#22522;&#20110;&#20284;&#28982;&#26041;&#27861;&#22312;&#24212;&#29992;&#20110;&#39640;&#32500;&#25968;&#25454;&#38598;&#26102;&#36935;&#21040;&#30340;&#20960;&#20010;&#38382;&#39064;&#65292;&#20363;&#22914;&#21253;&#21547;&#26080;&#20449;&#24687;&#25968;&#25454;&#32500;&#24230;&#25110;&#20301;&#20110;&#36739;&#20302;&#32500;&#27969;&#24418;&#19978;&#30340;&#25968;&#25454;&#12290;&#25105;&#20204;&#23545;SSNL&#22312;&#21508;&#31181;&#23454;&#39564;&#20013;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#24182;&#34920;&#26126;&#23427;&#36890;&#24120;&#20248;&#20110;&#22312;&#22522;&#20110;&#20223;&#30495;&#25512;&#26029;&#20013;&#20351;&#29992;&#30340;&#29616;&#20195;&#26041;&#27861;&#65292;&#20363;&#22914;&#22312;&#19968;&#39033;&#26469;&#33258;&#22825;&#20307;&#29289;&#29702;&#23398;&#30340;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#30495;&#23454;&#19990;&#30028;&#20363;&#23376;&#19978;&#23545;&#30913;&#22330;&#27169;&#22411;&#30340;&#24314;&#27169;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present Surjective Sequential Neural Likelihood (SSNL) estimation, a novel method for simulation-based inference in models where the evaluation of the likelihood function is not tractable and only a simulator that can generate synthetic data is available. SSNL fits a dimensionality-reducing surjective normalizing flow model and uses it as a surrogate likelihood function which allows for conventional Bayesian inference using either Markov chain Monte Carlo methods or variational inference. By embedding the data in a low-dimensional space, SSNL solves several issues previous likelihood-based methods had when applied to high-dimensional data sets that, for instance, contain non-informative data dimensions or lie along a lower-dimensional manifold. We evaluate SSNL on a wide variety of experiments and show that it generally outperforms contemporary methods used in simulation-based inference, for instance, on a challenging real-world example from astrophysics which models the magnetic fi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;Hilbert&#31354;&#38388;&#20013;&#22788;&#29702;&#27491;&#21017;&#21464;&#21270;&#21644;&#21151;&#33021;&#26497;&#20540;&#30340;&#27010;&#29575;&#32479;&#35745;&#26694;&#26550;&#65292;&#21253;&#25324;&#23545;&#38543;&#26426;&#21464;&#37327;&#27491;&#21017;&#21464;&#21270;&#30340;&#26032;&#22411;&#34920;&#24449;&#21644;&#21151;&#33021;&#20027;&#25104;&#20998;&#20998;&#26512;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2308.01023</link><description>&lt;p&gt;
Hilbert&#31354;&#38388;&#20013;&#30340;&#27491;&#21017;&#21464;&#21270;&#19982;&#21151;&#33021;&#26497;&#20540;&#30340;&#20027;&#25104;&#20998;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Regular Variation in Hilbert Spaces and Principal Component Analysis for Functional Extremes. (arXiv:2308.01023v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.01023
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;Hilbert&#31354;&#38388;&#20013;&#22788;&#29702;&#27491;&#21017;&#21464;&#21270;&#21644;&#21151;&#33021;&#26497;&#20540;&#30340;&#27010;&#29575;&#32479;&#35745;&#26694;&#26550;&#65292;&#21253;&#25324;&#23545;&#38543;&#26426;&#21464;&#37327;&#27491;&#21017;&#21464;&#21270;&#30340;&#26032;&#22411;&#34920;&#24449;&#21644;&#21151;&#33021;&#20027;&#25104;&#20998;&#20998;&#26512;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21151;&#33021;&#24615;&#25968;&#25454;&#26085;&#30410;&#20016;&#23500;&#30340;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;$L^2[0,1]$&#20013;&#27491;&#21017;&#21464;&#21270;&#38543;&#26426;&#20803;&#32032;$X$&#30340;&#26497;&#20540;&#30340;&#19968;&#33324;&#27010;&#29575;&#32479;&#35745;&#26694;&#26550;&#12290;&#25105;&#20204;&#23558;&#33258;&#24049;&#32622;&#20110;&#19968;&#20010;&#23792;&#20540;&#36229;&#36807;&#38408;&#20540;&#30340;&#26694;&#26550;&#20013;&#65292;&#20854;&#20013;&#19968;&#20010;&#21151;&#33021;&#26497;&#20540;&#34987;&#23450;&#20041;&#20026;$L^2$&#33539;&#25968;$\|X\|$&#30456;&#23545;&#36739;&#22823;&#30340;&#35266;&#27979;&#20540;$X$&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#25552;&#20986;&#19968;&#20010;&#38477;&#32500;&#26694;&#26550;&#65292;&#20174;&#32780;&#20026;&#36825;&#31181;&#26497;&#20540;&#35266;&#27979;&#24471;&#21040;&#26377;&#38480;&#32500;&#24230;&#30340;&#25237;&#24433;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#26159;&#21452;&#37325;&#30340;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#38543;&#26426;&#25968;&#37327;&#22312;&#19968;&#33324;&#21487;&#20998;&#31163;&#30340;Hilbert&#31354;&#38388;&#20013;&#30340;&#27491;&#21017;&#21464;&#21270;&#27010;&#24565;&#65292;&#23545;&#27492;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20165;&#28041;&#21450;&#23454;&#20540;&#38543;&#26426;&#21464;&#37327;&#30340;&#38543;&#26426;&#25910;&#25947;&#30340;&#26032;&#22411;&#20855;&#20307;&#34920;&#24449;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21151;&#33021;&#24615;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#30340;&#27010;&#24565;&#65292;&#21487;&#20197;&#32771;&#34385;&#21151;&#33021;&#26497;&#20540;&#30340;&#20027;&#35201;&#8220;&#26041;&#21521;&#8221;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#32463;&#39564;&#21327;&#26041;&#24046;&#31639;&#23376;&#30340;&#32479;&#35745;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by the increasing availability of data of functional nature, we develop a general probabilistic and statistical framework for extremes of regularly varying random elements $X$ in $L^2[0,1]$. We place ourselves in a Peaks-Over-Threshold framework where a functional extreme is defined as an observation $X$ whose $L^2$-norm $\|X\|$ is comparatively large. Our goal is to propose a dimension reduction framework resulting into finite dimensional projections for such extreme observations. Our contribution is double. First, we investigate the notion of Regular Variation for random quantities valued in a general separable Hilbert space, for which we propose a novel concrete characterization involving solely stochastic convergence of real-valued random variables. Second, we propose a notion of functional Principal Component Analysis (PCA) accounting for the principal `directions' of functional extremes. We investigate the statistical properties of the empirical covariance operator of t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#35748;&#35777;&#30340;&#22810;&#27969;&#31243;&#38646;&#38454;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;MFDOO&#31639;&#27861;&#30340;&#35748;&#35777;&#21464;&#20307;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#20855;&#26377;&#36817;&#20284;&#26368;&#20248;&#30340;&#20195;&#20215;&#22797;&#26434;&#24230;&#12290;&#21516;&#26102;&#65292;&#36824;&#32771;&#34385;&#20102;&#26377;&#22122;&#22768;&#35780;&#20272;&#30340;&#29305;&#27530;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2308.00978</link><description>&lt;p&gt;
&#35748;&#35777;&#30340;&#22810;&#27969;&#31243;&#38646;&#38454;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Certified Multi-Fidelity Zeroth-Order Optimization. (arXiv:2308.00978v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.00978
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#35748;&#35777;&#30340;&#22810;&#27969;&#31243;&#38646;&#38454;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;MFDOO&#31639;&#27861;&#30340;&#35748;&#35777;&#21464;&#20307;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#20855;&#26377;&#36817;&#20284;&#26368;&#20248;&#30340;&#20195;&#20215;&#22797;&#26434;&#24230;&#12290;&#21516;&#26102;&#65292;&#36824;&#32771;&#34385;&#20102;&#26377;&#22122;&#22768;&#35780;&#20272;&#30340;&#29305;&#27530;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22810;&#27969;&#31243;&#38646;&#38454;&#20248;&#21270;&#30340;&#38382;&#39064;&#65292;&#22312;&#36825;&#20010;&#38382;&#39064;&#20013;&#65292;&#21487;&#20197;&#22312;&#19981;&#21516;&#30340;&#36817;&#20284;&#27700;&#24179;&#65288;&#20195;&#20215;&#19981;&#21516;&#65289;&#19978;&#35780;&#20272;&#20989;&#25968;$f$&#65292;&#30446;&#26631;&#26159;&#20197;&#23613;&#21487;&#33021;&#20302;&#30340;&#20195;&#20215;&#20248;&#21270;$f$&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;\emph{&#35748;&#35777;}&#31639;&#27861;&#65292;&#23427;&#20204;&#39069;&#22806;&#35201;&#27714;&#36755;&#20986;&#19968;&#20010;&#23545;&#20248;&#21270;&#35823;&#24046;&#30340;&#25968;&#25454;&#39537;&#21160;&#19978;&#30028;&#12290;&#25105;&#20204;&#39318;&#20808;&#20197;&#31639;&#27861;&#21644;&#35780;&#20272;&#29615;&#22659;&#20043;&#38388;&#30340;&#26497;&#23567;&#26497;&#22823;&#21338;&#24328;&#24418;&#24335;&#26469;&#24418;&#24335;&#21270;&#38382;&#39064;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;MFDOO&#31639;&#27861;&#30340;&#35748;&#35777;&#21464;&#20307;&#65292;&#24182;&#25512;&#23548;&#20986;&#20854;&#22312;&#20219;&#24847;Lipschitz&#20989;&#25968;$f$&#19978;&#30340;&#20195;&#20215;&#22797;&#26434;&#24230;&#19978;&#30028;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#19968;&#20010;&#20381;&#36182;&#20110;$f$&#30340;&#19979;&#30028;&#65292;&#34920;&#26126;&#35813;&#31639;&#27861;&#20855;&#26377;&#36817;&#20284;&#26368;&#20248;&#30340;&#20195;&#20215;&#22797;&#26434;&#24230;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#30452;&#25509;&#31034;&#20363;&#35299;&#20915;&#20102;&#26377;&#22122;&#22768;&#65288;&#38543;&#26426;&#65289;&#35780;&#20272;&#30340;&#29305;&#27530;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of multi-fidelity zeroth-order optimization, where one can evaluate a function $f$ at various approximation levels (of varying costs), and the goal is to optimize $f$ with the cheapest evaluations possible. In this paper, we study \emph{certified} algorithms, which are additionally required to output a data-driven upper bound on the optimization error. We first formalize the problem in terms of a min-max game between an algorithm and an evaluation environment. We then propose a certified variant of the MFDOO algorithm and derive a bound on its cost complexity for any Lipschitz function $f$. We also prove an $f$-dependent lower bound showing that this algorithm has a near-optimal cost complexity. We close the paper by addressing the special case of noisy (stochastic) evaluations as a direct example.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;"Cluster-DP"&#65292;&#23427;&#22312;&#20445;&#35777;&#38544;&#31169;&#30340;&#21516;&#26102;&#21033;&#29992;&#25968;&#25454;&#30340;&#32858;&#31867;&#32467;&#26500;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#26356;&#24378;&#30340;&#38544;&#31169;&#20445;&#35777;&#21644;&#36739;&#20302;&#30340;&#26041;&#24046;&#65292;&#21487;&#20197;&#29992;&#20110;&#36827;&#34892;&#22240;&#26524;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2308.00957</link><description>&lt;p&gt;
&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;(&#20998;&#32452;)&#32467;&#26524;&#30340;&#22240;&#26524;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Causal Inference with Differentially Private (Clustered) Outcomes. (arXiv:2308.00957v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.00957
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;"Cluster-DP"&#65292;&#23427;&#22312;&#20445;&#35777;&#38544;&#31169;&#30340;&#21516;&#26102;&#21033;&#29992;&#25968;&#25454;&#30340;&#32858;&#31867;&#32467;&#26500;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#26356;&#24378;&#30340;&#38544;&#31169;&#20445;&#35777;&#21644;&#36739;&#20302;&#30340;&#26041;&#24046;&#65292;&#21487;&#20197;&#29992;&#20110;&#36827;&#34892;&#22240;&#26524;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#38543;&#26426;&#23454;&#39564;&#20013;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#21482;&#26377;&#22312;&#21442;&#19982;&#32773;&#21516;&#24847;&#36879;&#38706;&#20182;&#20204;&#21487;&#33021;&#25935;&#24863;&#30340;&#21709;&#24212;&#26102;&#25165;&#21487;&#34892;&#12290;&#22312;&#30830;&#20445;&#38544;&#31169;&#30340;&#35768;&#22810;&#26041;&#27861;&#20013;&#65292;&#26631;&#31614;&#24046;&#20998;&#38544;&#31169;&#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#31639;&#27861;&#38544;&#31169;&#20445;&#35777;&#24230;&#37327;&#65292;&#21487;&#20197;&#40723;&#21169;&#21442;&#19982;&#32773;&#20998;&#20139;&#21709;&#24212;&#32780;&#19981;&#20250;&#38754;&#20020;&#21435;&#21311;&#21517;&#21270;&#30340;&#39118;&#38505;&#12290;&#35768;&#22810;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;&#20250;&#21521;&#21407;&#22987;&#25968;&#25454;&#38598;&#20013;&#27880;&#20837;&#22122;&#38899;&#26469;&#23454;&#29616;&#36825;&#31181;&#38544;&#31169;&#20445;&#35777;&#65292;&#36825;&#20250;&#22686;&#21152;&#22823;&#22810;&#25968;&#32479;&#35745;&#20272;&#35745;&#37327;&#30340;&#26041;&#24046;&#65292;&#20351;&#24471;&#31934;&#30830;&#27979;&#37327;&#22240;&#26524;&#25928;&#24212;&#21464;&#24471;&#22256;&#38590;&#65306;&#20174;&#24046;&#20998;&#38544;&#31169;&#25968;&#25454;&#36827;&#34892;&#22240;&#26524;&#20998;&#26512;&#23384;&#22312;&#30528;&#22266;&#26377;&#30340;&#38544;&#31169;-&#26041;&#24046;&#26435;&#34913;&#12290;&#20026;&#20102;&#23454;&#29616;&#26356;&#24378;&#38544;&#31169;&#20445;&#35777;&#30340;&#36739;&#20302;&#26041;&#24046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;"Cluster-DP"&#65292;&#23427;&#21033;&#29992;&#25968;&#25454;&#30340;&#20219;&#20309;&#32473;&#23450;&#30340;&#32858;&#31867;&#32467;&#26500;&#65292;&#21516;&#26102;&#20173;&#28982;&#20801;&#35768;&#23545;&#22240;&#26524;&#25928;&#24212;&#36827;&#34892;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating causal effects from randomized experiments is only feasible if participants agree to reveal their potentially sensitive responses. Of the many ways of ensuring privacy, label differential privacy is a widely used measure of an algorithm's privacy guarantee, which might encourage participants to share responses without running the risk of de-anonymization. Many differentially private mechanisms inject noise into the original data-set to achieve this privacy guarantee, which increases the variance of most statistical estimators and makes the precise measurement of causal effects difficult: there exists a fundamental privacy-variance trade-off to performing causal analyses from differentially private data. With the aim of achieving lower variance for stronger privacy guarantees, we suggest a new differential privacy mechanism, "Cluster-DP", which leverages any given cluster structure of the data while still allowing for the estimation of causal effects. We show that, depending 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;&#36125;&#21494;&#26031;&#19978;&#19979;&#25991;&#26641;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#21644;&#39044;&#27979;&#26041;&#27861;&#65292;&#36890;&#36807;&#23618;&#32423;&#36125;&#21494;&#26031;&#26694;&#26550;&#23558;&#31163;&#25955;&#29366;&#24577;&#21644;&#23454;&#20540;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#32452;&#21512;&#65292;&#26500;&#24314;&#20986;&#28789;&#27963;&#19988;&#21487;&#35299;&#37322;&#30340;&#28151;&#21512;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#26377;&#25928;&#30340;&#31639;&#27861;&#26469;&#36827;&#34892;&#36125;&#21494;&#26031;&#25512;&#26029;&#21644;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2308.00913</link><description>&lt;p&gt;
&#22522;&#20110;&#36125;&#21494;&#26031;&#19978;&#19979;&#25991;&#26641;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#21644;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
The Bayesian Context Trees State Space Model for time series modelling and forecasting. (arXiv:2308.00913v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.00913
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;&#36125;&#21494;&#26031;&#19978;&#19979;&#25991;&#26641;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#21644;&#39044;&#27979;&#26041;&#27861;&#65292;&#36890;&#36807;&#23618;&#32423;&#36125;&#21494;&#26031;&#26694;&#26550;&#23558;&#31163;&#25955;&#29366;&#24577;&#21644;&#23454;&#20540;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#32452;&#21512;&#65292;&#26500;&#24314;&#20986;&#28789;&#27963;&#19988;&#21487;&#35299;&#37322;&#30340;&#28151;&#21512;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#26377;&#25928;&#30340;&#31639;&#27861;&#26469;&#36827;&#34892;&#36125;&#21494;&#26031;&#25512;&#26029;&#21644;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#19968;&#20010;&#23618;&#32423;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#29992;&#20110;&#24320;&#21457;&#29992;&#20110;&#30495;&#23454;&#20540;&#26102;&#38388;&#24207;&#21015;&#30340;&#20016;&#23500;&#28151;&#21512;&#27169;&#22411;&#65292;&#20197;&#21450;&#19968;&#31995;&#21015;&#26377;&#25928;&#30340;&#23398;&#20064;&#21644;&#25512;&#26029;&#24037;&#20855;&#12290;&#22312;&#39030;&#23618;&#65292;&#36890;&#36807;&#36866;&#24403;&#37327;&#21270;&#26368;&#36817;&#26679;&#26412;&#30340;&#19968;&#20123;&#26377;&#24847;&#20041;&#30340;&#31163;&#25955;&#29366;&#24577;&#26469;&#36827;&#34892;&#37492;&#23450;&#12290;&#36825;&#20123;&#21487;&#35266;&#23519;&#29366;&#24577;&#30340;&#38598;&#21512;&#34987;&#25551;&#36848;&#20026;&#31163;&#25955;&#30340;&#19978;&#19979;&#25991;&#26641;&#27169;&#22411;&#12290;&#28982;&#21518;&#65292;&#22312;&#24213;&#23618;&#65292;&#23558;&#19968;&#20010;&#19981;&#21516;&#30340;&#12289;&#20219;&#24847;&#30340;&#23454;&#20540;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#65288;&#22522;&#26412;&#27169;&#22411;&#65289;&#19982;&#27599;&#20010;&#29366;&#24577;&#30456;&#20851;&#32852;&#12290;&#36825;&#23450;&#20041;&#20102;&#19968;&#20010;&#38750;&#24120;&#36890;&#29992;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#19982;&#20219;&#20309;&#29616;&#26377;&#27169;&#22411;&#31867;&#19968;&#36215;&#20351;&#29992;&#65292;&#26500;&#24314;&#28789;&#27963;&#19988;&#21487;&#35299;&#37322;&#30340;&#28151;&#21512;&#27169;&#22411;&#12290;&#25105;&#20204;&#23558;&#20854;&#31216;&#20026;&#36125;&#21494;&#26031;&#19978;&#19979;&#25991;&#26641;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65292;&#25110;&#32773;BCT-X&#26694;&#26550;&#12290;&#24341;&#20837;&#20102;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#23454;&#29616;&#26377;&#25928;&#30340;&#12289;&#31934;&#30830;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#65307;&#29305;&#21035;&#26159;&#21487;&#20197;&#30830;&#23450;&#26368;&#22823;&#21518;&#39564;&#27010;&#29575;&#65288;MAP&#65289;&#19978;&#19979;&#25991;&#26641;&#27169;&#22411;&#12290;&#36825;&#20123;&#31639;&#27861;&#21487;&#20197;&#39034;&#24207;&#26356;&#26032;&#65292;&#20197;&#20415;&#23454;&#29616;&#26377;&#25928;&#30340;&#25512;&#26029;&#21644;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
A hierarchical Bayesian framework is introduced for developing rich mixture models for real-valued time series, along with a collection of effective tools for learning and inference. At the top level, meaningful discrete states are identified as appropriately quantised values of some of the most recent samples. This collection of observable states is described as a discrete context-tree model. Then, at the bottom level, a different, arbitrary model for real-valued time series - a base model - is associated with each state. This defines a very general framework that can be used in conjunction with any existing model class to build flexible and interpretable mixture models. We call this the Bayesian Context Trees State Space Model, or the BCT-X framework. Efficient algorithms are introduced that allow for effective, exact Bayesian inference; in particular, the maximum a posteriori probability (MAP) context-tree model can be identified. These algorithms can be updated sequentially, facili
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32593;&#32476;&#29615;&#22659;&#20013;&#30340;&#20998;&#24067;&#24335;&#20272;&#35745;&#21644;&#23398;&#20064;&#38382;&#39064;&#65292;&#36890;&#36807;&#20132;&#25442;&#31169;&#26377;&#35266;&#27979;&#20449;&#24687;&#65292;&#20195;&#29702;&#21487;&#20197;&#38598;&#20307;&#20272;&#35745;&#26410;&#30693;&#25968;&#37327;&#65292;&#32780;&#20445;&#25252;&#38544;&#31169;&#12290;&#36890;&#36807;&#32447;&#24615;&#32858;&#21512;&#26041;&#26696;&#21644;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#35843;&#25972;&#30340;&#38543;&#26426;&#21270;&#26041;&#26696;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#22312;&#20445;&#35777;&#38544;&#31169;&#30340;&#21516;&#26102;&#39640;&#25928;&#32452;&#21512;&#35266;&#27979;&#25968;&#25454;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.15865</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#20998;&#24067;&#24335;&#20272;&#35745;&#21644;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Distributed Estimation and Learning. (arXiv:2306.15865v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15865
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32593;&#32476;&#29615;&#22659;&#20013;&#30340;&#20998;&#24067;&#24335;&#20272;&#35745;&#21644;&#23398;&#20064;&#38382;&#39064;&#65292;&#36890;&#36807;&#20132;&#25442;&#31169;&#26377;&#35266;&#27979;&#20449;&#24687;&#65292;&#20195;&#29702;&#21487;&#20197;&#38598;&#20307;&#20272;&#35745;&#26410;&#30693;&#25968;&#37327;&#65292;&#32780;&#20445;&#25252;&#38544;&#31169;&#12290;&#36890;&#36807;&#32447;&#24615;&#32858;&#21512;&#26041;&#26696;&#21644;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#35843;&#25972;&#30340;&#38543;&#26426;&#21270;&#26041;&#26696;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#22312;&#20445;&#35777;&#38544;&#31169;&#30340;&#21516;&#26102;&#39640;&#25928;&#32452;&#21512;&#35266;&#27979;&#25968;&#25454;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32593;&#32476;&#29615;&#22659;&#20013;&#30340;&#20998;&#24067;&#24335;&#20272;&#35745;&#21644;&#23398;&#20064;&#38382;&#39064;&#65292;&#20854;&#20013;&#20195;&#29702;&#36890;&#36807;&#20132;&#25442;&#20449;&#24687;&#26469;&#20272;&#35745;&#20174;&#20854;&#31169;&#19979;&#35266;&#23519;&#30340;&#26679;&#26412;&#20013;&#26410;&#30693;&#30340;&#32479;&#35745;&#23646;&#24615;&#12290;&#36890;&#36807;&#20132;&#25442;&#31169;&#26377;&#35266;&#27979;&#20449;&#24687;&#65292;&#20195;&#29702;&#21487;&#20197;&#38598;&#20307;&#20272;&#35745;&#26410;&#30693;&#25968;&#37327;&#65292;&#20294;&#20182;&#20204;&#20063;&#38754;&#20020;&#38544;&#31169;&#39118;&#38505;&#12290;&#25105;&#20204;&#30340;&#32858;&#21512;&#26041;&#26696;&#30340;&#30446;&#26631;&#26159;&#22312;&#26102;&#38388;&#21644;&#32593;&#32476;&#20013;&#39640;&#25928;&#22320;&#32452;&#21512;&#35266;&#27979;&#25968;&#25454;&#65292;&#21516;&#26102;&#28385;&#36275;&#20195;&#29702;&#30340;&#38544;&#31169;&#38656;&#27714;&#65292;&#32780;&#19981;&#38656;&#35201;&#20219;&#20309;&#36229;&#36234;&#20182;&#20204;&#26412;&#22320;&#38468;&#36817;&#30340;&#21327;&#35843;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20351;&#21442;&#19982;&#30340;&#20195;&#29702;&#33021;&#22815;&#20174;&#31163;&#32447;&#25110;&#38543;&#26102;&#38388;&#22312;&#32447;&#33719;&#21462;&#30340;&#31169;&#26377;&#20449;&#21495;&#20013;&#20272;&#35745;&#23436;&#25972;&#30340;&#20805;&#20998;&#32479;&#35745;&#37327;&#65292;&#24182;&#20445;&#25252;&#20854;&#20449;&#21495;&#21644;&#32593;&#32476;&#38468;&#36817;&#30340;&#38544;&#31169;&#12290;&#36825;&#26159;&#36890;&#36807;&#32447;&#24615;&#32858;&#21512;&#26041;&#26696;&#21644;&#35843;&#25972;&#30340;&#38543;&#26426;&#21270;&#26041;&#26696;&#23454;&#29616;&#30340;&#65292;&#23558;&#22122;&#22768;&#28155;&#21152;&#21040;&#20132;&#25442;&#30340;&#20272;&#35745;&#25968;&#25454;&#20013;&#20197;&#28385;&#36275;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study distributed estimation and learning problems in a networked environment in which agents exchange information to estimate unknown statistical properties of random variables from their privately observed samples. By exchanging information about their private observations, the agents can collectively estimate the unknown quantities, but they also face privacy risks. The goal of our aggregation schemes is to combine the observed data efficiently over time and across the network, while accommodating the privacy needs of the agents and without any coordination beyond their local neighborhoods. Our algorithms enable the participating agents to estimate a complete sufficient statistic from private signals that are acquired offline or online over time, and to preserve the privacy of their signals and network neighborhoods. This is achieved through linear aggregation schemes with adjusted randomization schemes that add noise to the exchanged estimates subject to differential privacy (DP
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#8220;&#30830;&#23450;&#24615;ADVI&#8221;&#65288;DADVI&#65289;&#65292;&#23427;&#29992;&#19968;&#31181;&#22266;&#23450;&#30340;&#33945;&#29305;&#21345;&#32599;&#36817;&#20284;&#26367;&#25442;&#20102;&#22343;&#20540;&#22330;&#21464;&#20998;&#36125;&#21494;&#26031;&#65288;MFVB&#65289;&#30340;&#19981;&#21487;&#35299;&#30446;&#26631;&#65292;&#21487;&#20197;&#20351;&#29992;&#29616;&#25104;&#30340;&#20108;&#38454;&#20248;&#21270;&#65292;&#36866;&#29992;&#20110;&#26356;&#20934;&#30830;&#30340;&#21518;&#39564;&#32447;&#24615;&#21709;&#24212;&#65288;LR&#65289;&#21327;&#26041;&#24046;&#20272;&#35745;&#65292;&#22312;&#26576;&#20123;&#24120;&#35265;&#30340;&#32479;&#35745;&#38382;&#39064;&#31867;&#21035;&#19978;&#25928;&#26524;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2304.05527</link><description>&lt;p&gt;
&#19968;&#31181;&#20351;&#29992;&#30830;&#23450;&#24615;&#30446;&#26631;&#30340;&#40657;&#21283;&#23376;&#21464;&#20998;&#25512;&#26029;&#65306;&#26356;&#24555;&#65292;&#26356;&#31934;&#30830;&#65292;&#26356;&#40657;&#12290;
&lt;/p&gt;
&lt;p&gt;
Black Box Variational Inference with a Deterministic Objective: Faster, More Accurate, and Even More Black Box. (arXiv:2304.05527v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05527
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#8220;&#30830;&#23450;&#24615;ADVI&#8221;&#65288;DADVI&#65289;&#65292;&#23427;&#29992;&#19968;&#31181;&#22266;&#23450;&#30340;&#33945;&#29305;&#21345;&#32599;&#36817;&#20284;&#26367;&#25442;&#20102;&#22343;&#20540;&#22330;&#21464;&#20998;&#36125;&#21494;&#26031;&#65288;MFVB&#65289;&#30340;&#19981;&#21487;&#35299;&#30446;&#26631;&#65292;&#21487;&#20197;&#20351;&#29992;&#29616;&#25104;&#30340;&#20108;&#38454;&#20248;&#21270;&#65292;&#36866;&#29992;&#20110;&#26356;&#20934;&#30830;&#30340;&#21518;&#39564;&#32447;&#24615;&#21709;&#24212;&#65288;LR&#65289;&#21327;&#26041;&#24046;&#20272;&#35745;&#65292;&#22312;&#26576;&#20123;&#24120;&#35265;&#30340;&#32479;&#35745;&#38382;&#39064;&#31867;&#21035;&#19978;&#25928;&#26524;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#21160;&#24494;&#20998;&#21464;&#20998;&#25512;&#26029;&#65288;ADVI&#65289;&#25552;&#20379;&#20102;&#22810;&#31181;&#29616;&#20195;&#27010;&#29575;&#32534;&#31243;&#35821;&#35328;&#20013;&#24555;&#36895;&#26131;&#29992;&#30340;&#21518;&#39564;&#36817;&#20284;&#26041;&#27861;&#12290;&#28982;&#32780;&#23427;&#30340;&#38543;&#26426;&#20248;&#21270;&#22120;&#32570;&#20047;&#26126;&#30830;&#30340;&#25910;&#25947;&#26631;&#20934;&#65292;&#24182;&#19988;&#38656;&#35201;&#35843;&#25972;&#21442;&#25968;&#12290;&#27492;&#22806;&#65292;ADVI&#32487;&#25215;&#20102;&#22343;&#20540;&#22330;&#21464;&#20998;&#36125;&#21494;&#26031;&#65288;MFVB&#65289;&#30340;&#36739;&#24046;&#21518;&#39564;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#8220;&#30830;&#23450;&#24615;ADVI&#8221;&#65288;DADVI&#65289;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;DADVI&#29992;&#22266;&#23450;&#30340;&#33945;&#29305;&#21345;&#32599;&#36817;&#20284;&#26367;&#25442;&#20102;MFVB&#30340;&#19981;&#21487;&#35299;&#30446;&#26631;&#65292;&#36825;&#19968;&#25216;&#26415;&#22312;&#38543;&#26426;&#20248;&#21270;&#25991;&#29486;&#20013;&#34987;&#31216;&#20026;&#8220;&#26679;&#26412;&#24179;&#22343;&#36817;&#20284;&#8221;&#65288;SAA&#65289;&#12290;&#36890;&#36807;&#20248;&#21270;&#36817;&#20284;&#20294;&#30830;&#23450;&#30340;&#30446;&#26631;&#65292;DADVI&#21487;&#20197;&#20351;&#29992;&#29616;&#25104;&#30340;&#20108;&#38454;&#20248;&#21270;&#65292;&#32780;&#19988;&#19982;&#26631;&#20934;&#22343;&#20540;&#22330;ADVI&#19981;&#21516;&#30340;&#26159;&#65292;&#21487;&#20197;&#36866;&#29992;&#20110;&#26356;&#20934;&#30830;&#30340;&#21518;&#39564;&#32447;&#24615;&#21709;&#24212;&#65288;LR&#65289;&#21327;&#26041;&#24046;&#20272;&#35745;&#12290;&#19982;&#29616;&#26377;&#30340;&#26368;&#22351;&#24773;&#20917;&#29702;&#35770;&#30456;&#21453;&#65292;&#25105;&#20204;&#34920;&#26126;&#65292;&#22312;&#26576;&#20123;&#24120;&#35265;&#30340;&#32479;&#35745;&#38382;&#39064;&#31867;&#21035;&#19978;&#65292;DADVI&#21644;SAA&#21487;&#20197;&#34920;&#29616;&#24471;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Automatic differentiation variational inference (ADVI) offers fast and easy-to-use posterior approximation in multiple modern probabilistic programming languages. However, its stochastic optimizer lacks clear convergence criteria and requires tuning parameters. Moreover, ADVI inherits the poor posterior uncertainty estimates of mean-field variational Bayes (MFVB). We introduce ``deterministic ADVI'' (DADVI) to address these issues. DADVI replaces the intractable MFVB objective with a fixed Monte Carlo approximation, a technique known in the stochastic optimization literature as the ``sample average approximation'' (SAA). By optimizing an approximate but deterministic objective, DADVI can use off-the-shelf second-order optimization, and, unlike standard mean-field ADVI, is amenable to more accurate posterior linear response (LR) covariance estimates. In contrast to existing worst-case theory, we show that, on certain classes of common statistical problems, DADVI and the SAA can perform 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25506;&#31350;&#20102;&#24322;&#26041;&#24046;&#39640;&#26031;&#24207;&#21015;&#27169;&#22411;&#20013;&#30340;&#31232;&#30095;&#20449;&#21495;&#26816;&#27979;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26368;&#23567;&#26497;&#22823;&#20998;&#31163;&#21322;&#24452;&#30340;&#19978;&#19979;&#30028;&#20197;&#21450;&#30456;&#24212;&#30340;&#27979;&#35797;&#65292;&#23637;&#31034;&#20102;&#20851;&#20110;&#31232;&#30095;&#24230;&#12289;&#36317;&#31163;&#34913;&#37327;&#21644;&#24322;&#26041;&#24046;&#24615;&#36136;&#30340;&#26032;&#30340;&#30456;&#21464;&#29305;&#24615;&#12290;</title><link>http://arxiv.org/abs/2211.08580</link><description>&lt;p&gt;
&#24322;&#26041;&#24046;&#39640;&#26031;&#24207;&#21015;&#27169;&#22411;&#20013;&#30340;&#31232;&#30095;&#20449;&#21495;&#26816;&#27979;: &#23574;&#38160;&#30340;&#26497;&#23567;&#26497;&#22823;&#36895;&#29575;
&lt;/p&gt;
&lt;p&gt;
Sparse Signal Detection in Heteroscedastic Gaussian Sequence Models: Sharp Minimax Rates. (arXiv:2211.08580v3 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.08580
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25506;&#31350;&#20102;&#24322;&#26041;&#24046;&#39640;&#26031;&#24207;&#21015;&#27169;&#22411;&#20013;&#30340;&#31232;&#30095;&#20449;&#21495;&#26816;&#27979;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26368;&#23567;&#26497;&#22823;&#20998;&#31163;&#21322;&#24452;&#30340;&#19978;&#19979;&#30028;&#20197;&#21450;&#30456;&#24212;&#30340;&#27979;&#35797;&#65292;&#23637;&#31034;&#20102;&#20851;&#20110;&#31232;&#30095;&#24230;&#12289;&#36317;&#31163;&#34913;&#37327;&#21644;&#24322;&#26041;&#24046;&#24615;&#36136;&#30340;&#26032;&#30340;&#30456;&#21464;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#19968;&#20010;&#20855;&#26377;&#26410;&#30693;&#22343;&#20540; $\theta \in \mathbb R^d$ &#21644;&#24050;&#30693;&#21327;&#26041;&#24046;&#30697;&#38453; $\Sigma = \operatorname{diag}(\sigma_1^2,\dots, \sigma_d^2)$ &#30340;&#24322;&#36136;&#39640;&#26031;&#24207;&#21015;&#27169;&#22411;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#38024;&#23545;&#31232;&#30095;&#22791;&#36873;&#26041;&#26696;&#30340;&#20449;&#21495;&#26816;&#27979;&#38382;&#39064;&#65292;&#23545;&#20110;&#24050;&#30693;&#30340;&#31232;&#30095;&#24230; $s$&#12290;&#20063;&#23601;&#26159;&#35828;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#26377;&#22810;&#22823;&#30340; $\epsilon^*&gt;0$&#65292;&#20197;&#20415;&#21487;&#20197;&#21306;&#20998;&#20986;&#38646;&#20551;&#35774; $\theta=0$ &#21644;&#30001; $\mathbb R^d$ &#20013; $s$-&#31232;&#30095;&#21521;&#37327;&#32452;&#25104;&#30340;&#22791;&#36873;&#35299;&#65292;&#23427;&#20204;&#36890;&#36807; $L^t$ &#33539;&#25968; ($t \in [1,\infty]$) &#19982; $0$ &#20998;&#24320;&#33267;&#23569; $\epsilon^*$ &#30340;&#27010;&#29575;&#24456;&#39640;&#12290;&#25105;&#20204;&#25214;&#21040;&#20102;&#26497;&#23567;&#26497;&#22823;&#20998;&#31163;&#21322;&#24452; $\epsilon^*$ &#30340;&#26497;&#23567;&#26497;&#22823;&#19978;&#19979;&#30028;&#65292;&#24182;&#35777;&#26126;&#23427;&#20204;&#24635;&#26159;&#21305;&#37197;&#30340;&#12290;&#25105;&#20204;&#36824;&#25512;&#23548;&#20102;&#30456;&#24212;&#30340;&#26497;&#23567;&#26497;&#22823;&#27979;&#35797;&#26469;&#23454;&#29616;&#36825;&#20123;&#30028;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25581;&#31034;&#20102;&#20851;&#20110; $\epsilon^*$ &#34892;&#20026;&#30340;&#26032;&#30340;&#30456;&#21464;&#29305;&#24615;&#65292;&#36825;&#21462;&#20915;&#20110;&#31232;&#30095;&#31243;&#24230;&#12289;$L^t$&#25351;&#26631;&#21644; $\Sigma$ &#30340;&#24322;&#26041;&#24046;&#29305;&#24615;&#12290;&#22312;&#27431;&#20960;&#37324;&#24471;&#65288;&#21363; $L^2$&#65289;&#20998;&#31163;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#20801;&#35768;&#25105;&#20204;&#24674;&#22797;&#20197;&#21069;&#30340;&#32467;&#26524;&#65292;&#24182;&#30830;&#23450;&#20102;&#30456;&#24212;&#30340;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Given a heterogeneous Gaussian sequence model with unknown mean $\theta \in \mathbb R^d$ and known covariance matrix $\Sigma = \operatorname{diag}(\sigma_1^2,\dots, \sigma_d^2)$, we study the signal detection problem against sparse alternatives, for known sparsity $s$. Namely, we characterize how large $\epsilon^*&gt;0$ should be, in order to distinguish with high probability the null hypothesis $\theta=0$ from the alternative composed of $s$-sparse vectors in $\mathbb R^d$, separated from $0$ in $L^t$ norm ($t \in [1,\infty]$) by at least $\epsilon^*$. We find minimax upper and lower bounds over the minimax separation radius $\epsilon^*$ and prove that they are always matching. We also derive the corresponding minimax tests achieving these bounds. Our results reveal new phase transitions regarding the behavior of $\epsilon^*$ with respect to the level of sparsity, to the $L^t$ metric, and to the heteroscedasticity profile of $\Sigma$. In the case of the Euclidean (i.e. $L^2$) separation,
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#20248;&#20256;&#36755;&#30340;&#23454;&#20363;&#30456;&#20851;&#27867;&#21270;&#30028;&#38480;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#27867;&#21270;&#30340;&#20851;&#38190;&#22240;&#32032;&#65292;&#24182;&#19988;&#32771;&#34385;&#20102;&#21021;&#22987;&#21270;&#21644;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#24378;&#24402;&#32435;&#20559;&#24046;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#27169;&#22411;&#21442;&#25968;&#21270;&#19981;&#21487;&#30693;&#19988;&#35757;&#32451;&#26679;&#26412;&#25968;&#37327;&#36828;&#23567;&#20110;&#21442;&#25968;&#25968;&#37327;&#26102;&#34920;&#29616;&#33391;&#22909;&#65292;&#36824;&#21487;&#20197;&#24212;&#29992;&#20110;&#20302;&#32500;&#27969;&#24418;&#19978;&#30340;&#25968;&#25454;&#21644;&#20998;&#24067;&#36716;&#25442;&#24773;&#20917;&#19979;&#30340;&#27867;&#21270;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2211.01258</link><description>&lt;p&gt;
&#22522;&#20110;&#26368;&#20248;&#20256;&#36755;&#30340;&#23454;&#20363;&#30456;&#20851;&#27867;&#21270;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Instance-Dependent Generalization Bounds via Optimal Transport. (arXiv:2211.01258v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.01258
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#20248;&#20256;&#36755;&#30340;&#23454;&#20363;&#30456;&#20851;&#27867;&#21270;&#30028;&#38480;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#27867;&#21270;&#30340;&#20851;&#38190;&#22240;&#32032;&#65292;&#24182;&#19988;&#32771;&#34385;&#20102;&#21021;&#22987;&#21270;&#21644;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#24378;&#24402;&#32435;&#20559;&#24046;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#27169;&#22411;&#21442;&#25968;&#21270;&#19981;&#21487;&#30693;&#19988;&#35757;&#32451;&#26679;&#26412;&#25968;&#37327;&#36828;&#23567;&#20110;&#21442;&#25968;&#25968;&#37327;&#26102;&#34920;&#29616;&#33391;&#22909;&#65292;&#36824;&#21487;&#20197;&#24212;&#29992;&#20110;&#20302;&#32500;&#27969;&#24418;&#19978;&#30340;&#25968;&#25454;&#21644;&#20998;&#24067;&#36716;&#25442;&#24773;&#20917;&#19979;&#30340;&#27867;&#21270;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;&#27867;&#21270;&#30028;&#38480;&#26080;&#27861;&#35299;&#37322;&#24433;&#21709;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#27867;&#21270;&#30340;&#20851;&#38190;&#22240;&#32032;&#12290;&#30001;&#20110;&#36825;&#20123;&#30028;&#38480;&#36890;&#24120;&#23545;&#25152;&#26377;&#21442;&#25968;&#37117;&#26159;&#19968;&#33268;&#30340;&#65292;&#23427;&#20204;&#23481;&#26131;&#36807;&#24230;&#21442;&#25968;&#21270;&#65292;&#24182;&#19988;&#26080;&#27861;&#32771;&#34385;&#21040;&#21021;&#22987;&#21270;&#21644;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#24378;&#24402;&#32435;&#20559;&#24046;&#12290;&#20316;&#20026;&#26367;&#20195;&#26041;&#26696;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26368;&#20248;&#20256;&#36755;&#35299;&#37322;&#27867;&#21270;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#33719;&#24471;&#20381;&#36182;&#20110;&#25968;&#25454;&#31354;&#38388;&#20013;&#39044;&#27979;&#20989;&#25968;&#30340;&#23616;&#37096;&#21033;&#26222;&#24076;&#33576;&#27491;&#21017;&#24615;&#30340;&#23454;&#20363;&#30456;&#20851;&#27867;&#21270;&#30028;&#38480;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30340;&#30028;&#38480;&#23545;&#27169;&#22411;&#30340;&#21442;&#25968;&#21270;&#26159;&#19981;&#21487;&#30693;&#30340;&#65292;&#24182;&#19988;&#22312;&#35757;&#32451;&#26679;&#26412;&#25968;&#37327;&#36828;&#23567;&#20110;&#21442;&#25968;&#25968;&#37327;&#26102;&#34920;&#29616;&#33391;&#22909;&#12290;&#36890;&#36807;&#19968;&#20123;&#23567;&#30340;&#20462;&#25913;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20302;&#32500;&#27969;&#24418;&#19978;&#30340;&#25968;&#25454;&#19978;&#21487;&#20197;&#33719;&#24471;&#21152;&#36895;&#30340;&#36895;&#29575;&#65292;&#24182;&#19988;&#22312;&#20998;&#24067;&#36716;&#25442;&#19979;&#20855;&#26377;&#20445;&#35777;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#31070;&#32463;&#32593;&#32476;&#30340;&#23454;&#35777;&#20998;&#26512;&#26469;&#39564;&#35777;&#25105;&#20204;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#32467;&#26524;&#26174;&#31034;&#30028;&#38480;&#20540;&#26159;
&lt;/p&gt;
&lt;p&gt;
Existing generalization bounds fail to explain crucial factors that drive generalization of modern neural networks. Since such bounds often hold uniformly over all parameters, they suffer from over-parametrization, and fail to account for the strong inductive bias of initialization and stochastic gradient descent. As an alternative, we propose a novel optimal transport interpretation of the generalization problem. This allows us to derive instance-dependent generalization bounds that depend on the local Lipschitz regularity of the earned prediction function in the data space. Therefore, our bounds are agnostic to the parametrization of the model and work well when the number of training samples is much smaller than the number of parameters. With small modifications, our approach yields accelerated rates for data on low-dimensional manifolds, and guarantees under distribution shifts. We empirically analyze our generalization bounds for neural networks, showing that the bound values are 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#26088;&#22312;&#35299;&#20915;&#22269;&#38469;&#31354;&#38388;&#31449;&#19978;&#39063;&#31890;&#29289;&#23545;&#20202;&#22120;&#30340;&#21361;&#23475;&#38382;&#39064;&#65292;&#36890;&#36807;Bi-GRU&#31639;&#27861;&#26500;&#24314;&#26089;&#26399;&#39044;&#35686;&#31995;&#32479;&#65292;&#39044;&#27979;&#39063;&#31890;&#29289;&#27700;&#24179;&#65292;&#24182;&#20026;&#23431;&#33322;&#21592;&#25552;&#20379;&#20805;&#36275;&#30340;&#21453;&#24212;&#26102;&#38388;&#12290;&#36825;&#39033;&#30740;&#31350;&#36824;&#26377;&#28508;&#21147;&#21457;&#23637;&#20026;&#19982;&#28779;&#28798;&#30456;&#20851;&#30340;&#36965;&#24863;&#28895;&#38654;&#25253;&#35686;&#35013;&#32622;&#12290;</title><link>http://arxiv.org/abs/2210.08549</link><description>&lt;p&gt;
&#22269;&#38469;&#31354;&#38388;&#31449;&#33258;&#21160;&#32039;&#24613;&#26080;&#23576;&#35299;&#20915;&#26041;&#26696;: &#24102;&#26377;Bi-GRU&#30340;(AED-ISS)
&lt;/p&gt;
&lt;p&gt;
Automatic Emergency Dust-Free solution on-board International Space Station with Bi-GRU (AED-ISS). (arXiv:2210.08549v2 [stat.AP] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.08549
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#26088;&#22312;&#35299;&#20915;&#22269;&#38469;&#31354;&#38388;&#31449;&#19978;&#39063;&#31890;&#29289;&#23545;&#20202;&#22120;&#30340;&#21361;&#23475;&#38382;&#39064;&#65292;&#36890;&#36807;Bi-GRU&#31639;&#27861;&#26500;&#24314;&#26089;&#26399;&#39044;&#35686;&#31995;&#32479;&#65292;&#39044;&#27979;&#39063;&#31890;&#29289;&#27700;&#24179;&#65292;&#24182;&#20026;&#23431;&#33322;&#21592;&#25552;&#20379;&#20805;&#36275;&#30340;&#21453;&#24212;&#26102;&#38388;&#12290;&#36825;&#39033;&#30740;&#31350;&#36824;&#26377;&#28508;&#21147;&#21457;&#23637;&#20026;&#19982;&#28779;&#28798;&#30456;&#20851;&#30340;&#36965;&#24863;&#28895;&#38654;&#25253;&#35686;&#35013;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#23545;PM2.5&#25110;PM0.3&#38382;&#39064;&#30340;&#20851;&#27880;&#19981;&#26029;&#22686;&#21152;&#65292;&#39063;&#31890;&#29289;&#19981;&#20165;&#23545;&#29615;&#22659;&#21644;&#20154;&#31867;&#26500;&#25104;&#28508;&#22312;&#23041;&#32961;&#65292;&#32780;&#19988;&#23545;&#22269;&#38469;&#31354;&#38388;&#31449;&#19978;&#30340;&#20202;&#22120;&#20063;&#20250;&#20135;&#29983;&#19981;&#21033;&#24433;&#21709;&#12290;&#26412;&#30740;&#31350;&#22242;&#38431;&#26088;&#22312;&#23558;&#21508;&#31181;&#39063;&#31890;&#29289;&#27987;&#24230;&#19982;&#30913;&#22330;&#12289;&#28287;&#24230;&#12289;&#21152;&#36895;&#24230;&#12289;&#28201;&#24230;&#12289;&#21387;&#21147;&#21644;CO2&#27987;&#24230;&#20851;&#32852;&#36215;&#26469;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#24314;&#31435;&#19968;&#20010;&#26089;&#26399;&#39044;&#35686;&#31995;&#32479;(EWS)&#65292;&#33021;&#22815;&#39044;&#27979;&#39063;&#31890;&#29289;&#27700;&#24179;&#65292;&#24182;&#20026;&#23431;&#33322;&#21592;&#25552;&#20379;&#20805;&#36275;&#30340;&#21453;&#24212;&#26102;&#38388;&#65292;&#20197;&#20445;&#25252;&#20182;&#20204;&#22312;&#26576;&#20123;&#23454;&#39564;&#20013;&#30340;&#20202;&#22120;&#65292;&#25110;&#32773;&#25552;&#39640;&#27979;&#37327;&#30340;&#20934;&#30830;&#24615;&#65307;&#27492;&#22806;&#65292;&#25152;&#26500;&#24314;&#30340;&#27169;&#22411;&#36824;&#21487;&#20197;&#36827;&#19968;&#27493;&#21457;&#23637;&#20026;&#19982;&#28779;&#28798;&#30456;&#20851;&#30340;&#36965;&#24863;&#28895;&#38654;&#25253;&#35686;&#35013;&#32622;&#30340;&#21407;&#22411;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#23454;&#29616;Bi-GRU(&#21452;&#21521;&#38376;&#25511;&#24490;&#29615;&#21333;&#20803;)&#31639;&#27861;&#65292;&#25910;&#38598;&#36807;&#21435;90&#20998;&#38047;&#30340;&#25968;&#25454;&#65292;&#24182;&#39044;&#27979;&#36229;&#36807;2.5&#24494;&#31859;&#30340;&#39063;&#31890;&#29289;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
With a rising attention for the issue of PM2.5 or PM0.3, particulate matters have become not only a potential threat to both the environment and human, but also a harming existence to instruments onboard International Space Station (ISS). Our team is aiming to relate various concentration of particulate matters to magnetic fields, humidity, acceleration, temperature, pressure and CO2 concentration. Our goal is to establish an early warning system (EWS), which is able to forecast the levels of particulate matters and provides ample reaction time for astronauts to protect their instruments in some experiments or increase the accuracy of the measurements; In addition, the constructed model can be further developed into a prototype of a remote-sensing smoke alarm for applications related to fires. In this article, we will implement the Bi-GRU (Bidirectional Gated Recurrent Unit) algorithms that collect data for past 90 minutes and predict the levels of particulates which over 2.5 micromete
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20855;&#26377;&#26377;&#38480;&#25903;&#25345;&#30340;&#19968;&#33324;&#21442;&#25968;&#26680;&#36827;&#34892;TPP&#25512;&#29702;&#30340;&#39640;&#25928;&#35299;&#20915;&#26041;&#26696;&#65292;&#35813;&#26041;&#27861;&#37319;&#29992;&#20102;&#31163;&#25955;&#21270;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#22810;&#39033;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#32479;&#35745;&#21644;&#35745;&#31639;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2210.04635</link><description>&lt;p&gt;
FaDIn: &#38024;&#23545;&#20855;&#26377;&#19968;&#33324;&#21442;&#25968;&#26680;&#30340;Hawkes&#36807;&#31243;&#30340;&#24555;&#36895;&#31163;&#25955;&#21270;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
FaDIn: Fast Discretized Inference for Hawkes Processes with General Parametric Kernels. (arXiv:2210.04635v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.04635
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20855;&#26377;&#26377;&#38480;&#25903;&#25345;&#30340;&#19968;&#33324;&#21442;&#25968;&#26680;&#36827;&#34892;TPP&#25512;&#29702;&#30340;&#39640;&#25928;&#35299;&#20915;&#26041;&#26696;&#65292;&#35813;&#26041;&#27861;&#37319;&#29992;&#20102;&#31163;&#25955;&#21270;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#22810;&#39033;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#32479;&#35745;&#21644;&#35745;&#31639;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#28857;&#36807;&#31243;&#26159;&#24314;&#27169;&#20107;&#20214;&#25968;&#25454;&#30340;&#33258;&#28982;&#24037;&#20855;&#12290;&#22312;&#25152;&#26377;&#30340;&#26102;&#38388;&#28857;&#36807;&#31243;&#27169;&#22411;&#20013;&#65292;Hawkes&#36807;&#31243;&#34987;&#35777;&#26126;&#26159;&#26368;&#24191;&#27867;&#20351;&#29992;&#30340;&#65292;&#20027;&#35201;&#26159;&#30001;&#20110;&#23427;&#20204;&#23545;&#20110;&#21508;&#31181;&#24212;&#29992;&#30340;&#36866;&#24403;&#24314;&#27169;&#65292;&#29305;&#21035;&#26159;&#22312;&#32771;&#34385;&#25351;&#25968;&#25110;&#38750;&#21442;&#25968;&#26680;&#26102;&#12290;&#23613;&#31649;&#38750;&#21442;&#25968;&#26680;&#26159;&#19968;&#31181;&#36873;&#25321;&#65292;&#20294;&#36825;&#20123;&#27169;&#22411;&#38656;&#35201;&#22823;&#22411;&#25968;&#25454;&#38598;&#12290;&#32780;&#25351;&#25968;&#26680;&#26356;&#20855;&#25968;&#25454;&#25928;&#29575;&#65292;&#23545;&#20110;&#31435;&#21363;&#35302;&#21457;&#26356;&#22810;&#20107;&#20214;&#30340;&#29305;&#23450;&#24212;&#29992;&#26356;&#26377;&#25928;&#65292;&#20294;&#23545;&#20110;&#38656;&#35201;&#20272;&#35745;&#24310;&#36831;&#30340;&#24212;&#29992;&#65288;&#22914;&#31070;&#32463;&#31185;&#23398;&#65289;&#65292;&#23427;&#20204;&#19981;&#22826;&#36866;&#29992;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#25552;&#20379;&#19968;&#31181;&#20351;&#29992;&#20855;&#26377;&#26377;&#38480;&#25903;&#25345;&#30340;&#19968;&#33324;&#21442;&#25968;&#26680;&#36827;&#34892;TPP&#25512;&#29702;&#30340;&#39640;&#25928;&#35299;&#20915;&#26041;&#26696;&#12290;&#25152;&#24320;&#21457;&#30340;&#35299;&#20915;&#26041;&#26696;&#21253;&#25324;&#21033;&#29992;&#20107;&#20214;&#30340;&#31163;&#25955;&#21270;&#30340;&#24555;&#36895;$\ell_2$&#26799;&#24230;&#27714;&#35299;&#22120;&#12290;&#22312;&#29702;&#35770;&#19978;&#25903;&#25345;&#31163;&#25955;&#21270;&#30340;&#20351;&#29992;&#21518;&#65292;&#36890;&#36807;&#22810;&#31181;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#35813;&#26032;&#26041;&#27861;&#30340;&#32479;&#35745;&#21644;&#35745;&#31639;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Temporal point processes (TPP) are a natural tool for modeling event-based data. Among all TPP models, Hawkes processes have proven to be the most widely used, mainly due to their adequate modeling for various applications, particularly when considering exponential or non-parametric kernels. Although non-parametric kernels are an option, such models require large datasets. While exponential kernels are more data efficient and relevant for specific applications where events immediately trigger more events, they are ill-suited for applications where latencies need to be estimated, such as in neuroscience. This work aims to offer an efficient solution to TPP inference using general parametric kernels with finite support. The developed solution consists of a fast $\ell_2$ gradient-based solver leveraging a discretized version of the events. After theoretically supporting the use of discretization, the statistical and computational efficiency of the novel approach is demonstrated through va
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#22522;&#20110;&#26143;&#24418;&#32454;&#32990;&#20316;&#29992;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#31361;&#35302;&#30340;&#31454;&#20105;&#21644;&#24378;&#24230;&#24179;&#34913;&#23454;&#29616;&#29616;&#26377;&#21644;&#35760;&#24518;&#24615;&#30340;&#22823;&#33041;&#21487;&#22609;&#24615;&#21644;&#31361;&#35302;&#24418;&#25104;&#65292;&#24182;&#25506;&#35752;&#20102;&#19982;&#20851;&#38190;&#26399;&#30456;&#20851;&#30340;&#31070;&#32463;&#32010;&#20081;&#21644;&#36127;&#38754;&#21644;&#27491;&#38754;&#35760;&#24518;&#30340;&#25345;&#20037;&#24615;&#23545;&#31361;&#35302;&#28608;&#27963;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2203.11740</link><description>&lt;p&gt;
&#22522;&#20110;&#26143;&#24418;&#32454;&#32990;&#23545;&#20851;&#38190;&#26399;&#30340;&#31070;&#32463;&#21487;&#22609;&#24615;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#29616;&#26377;&#21644;&#35760;&#24518;&#24615;&#30340;&#22823;&#33041;&#21487;&#22609;&#24615;&#21644;&#31361;&#35302;&#24418;&#25104;&#23454;&#29616;&#31361;&#35302;&#31454;&#20105;&#21644;&#24378;&#24230;&#24179;&#34913;&#12290;&#65288;arXiv: 2203.11740v12 [cs.NE] UPDATED&#65289;
&lt;/p&gt;
&lt;p&gt;
Plasticity Neural Network Based on Astrocytic effects at Critical Period, Synaptic Competition and Strength Rebalance by Current and Mnemonic Brain Plasticity and Synapse Formation. (arXiv:2203.11740v12 [cs.NE] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.11740
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#22522;&#20110;&#26143;&#24418;&#32454;&#32990;&#20316;&#29992;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#31361;&#35302;&#30340;&#31454;&#20105;&#21644;&#24378;&#24230;&#24179;&#34913;&#23454;&#29616;&#29616;&#26377;&#21644;&#35760;&#24518;&#24615;&#30340;&#22823;&#33041;&#21487;&#22609;&#24615;&#21644;&#31361;&#35302;&#24418;&#25104;&#65292;&#24182;&#25506;&#35752;&#20102;&#19982;&#20851;&#38190;&#26399;&#30456;&#20851;&#30340;&#31070;&#32463;&#32010;&#20081;&#21644;&#36127;&#38754;&#21644;&#27491;&#38754;&#35760;&#24518;&#30340;&#25345;&#20037;&#24615;&#23545;&#31361;&#35302;&#28608;&#27963;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38500;&#20102;&#31361;&#35302;&#20849;&#20139;&#36830;&#25509;&#26435;&#37325;&#20043;&#22806;&#65292;PNN&#36824;&#21253;&#25324;&#31361;&#35302;&#26377;&#25928;&#33539;&#22260;&#30340;&#26435;&#37325;[14-25]&#12290;PNN&#32771;&#34385;&#31361;&#35302;&#24378;&#24230;&#24179;&#34913;&#22312;&#31361;&#35302;&#21534;&#22124;&#30340;&#21160;&#24577;&#21644;&#38271;&#24230;&#24120;&#25968;&#20043;&#21644;&#30340;&#38745;&#24577;&#20013;[14]&#65292;&#24182;&#21253;&#21547;&#20102;&#40060;&#32676;&#34892;&#20026;&#30340;&#20808;&#23548;&#34892;&#20026;&#12290;&#31361;&#35302;&#24418;&#25104;&#22312;&#23454;&#39564;&#21644;&#27169;&#25311;&#20013;&#20250;&#25233;&#21046;&#26641;&#31361;&#29983;&#25104;[15]&#12290;&#31867;&#20284;&#20110;Spring Boot&#20013;&#30340;&#24378;&#21046;&#38887;&#24615;&#65292;&#21453;&#21521;&#22238;&#36335;&#30340;&#35760;&#24518;&#25345;&#20037;&#24230;&#26799;&#24230;&#20063;&#23384;&#22312;&#12290;&#30456;&#23545;&#36739;&#22909;&#21644;&#36739;&#24046;&#30340;&#26799;&#24230;&#20449;&#24687;&#23384;&#20648;&#22312;&#31867;&#20284;&#20110;&#33041;&#35126;&#30340;&#35760;&#24518;&#30165;&#36857;&#32454;&#32990;&#20013;&#65292;&#22312;&#21453;&#21521;&#22238;&#36335;&#30340;&#31361;&#35302;&#24418;&#25104;&#20013;&#12290;&#20105;&#35758;&#35748;&#20026;&#20154;&#31867;&#28023;&#39532;&#31070;&#32463;&#20803;&#30340;&#20877;&#29983;&#33021;&#21147;&#26159;&#21542;&#25345;&#32493;&#21040;&#32769;&#24180;&#65292;&#24182;&#21487;&#33021;&#22312;&#21518;&#26399;&#36845;&#20195;&#20013;&#24418;&#25104;&#26032;&#30340;&#26356;&#38271;&#30340;&#22238;&#36335;[17,18]&#12290;&#20851;&#38381;&#20851;&#38190;&#26399;&#20250;&#23548;&#33268;&#31070;&#32463;&#32010;&#20081;&#22312;&#23454;&#39564;&#21644;&#27169;&#25311;&#20013;[19]&#12290;&#32771;&#34385;&#21040;&#36127;&#38754;&#21644;&#27491;&#38754;&#35760;&#24518;&#30340;&#25345;&#20037;&#24615;&#65292;&#26377;&#21161;&#20110;&#26356;&#22909;&#22320;&#28608;&#27963;&#31361;&#35302;&#12290;
&lt;/p&gt;
&lt;p&gt;
In addition to the weights of synaptic shared connections, PNN includes weights of synaptic effective ranges [14-25]. PNN considers synaptic strength balance in dynamic of phagocytosing of synapses and static of constant sum of synapses length [14], and includes the lead behavior of the school of fish. Synapse formation will inhibit dendrites generation in experiments and simulations [15]. The memory persistence gradient of retrograde circuit similar to the Enforcing Resilience in a Spring Boot. The relatively good and inferior gradient information stored in memory engram cells in synapse formation of retrograde circuit like the folds in brain [16]. The controversy was claimed if human hippocampal neurogenesis persists throughout aging, may have a new and longer circuit in late iteration [17,18]. Closing the critical period will cause neurological disorder in experiments and simulations [19]. Considering both negative and positive memories persistence help activate synapse better than 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32508;&#21512;&#26465;&#20214;&#20272;&#35745;-&#20248;&#21270;&#65288;ICEO&#65289;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#32771;&#34385;&#20248;&#21270;&#38382;&#39064;&#32467;&#26500;&#30340;&#21516;&#26102;&#20272;&#35745;&#38543;&#26426;&#21442;&#25968;&#30340;&#26465;&#20214;&#20998;&#24067;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20123;&#24615;&#33021;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2110.12351</link><description>&lt;p&gt;
&#32508;&#21512;&#26465;&#20214;&#20272;&#35745;-&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Integrated Conditional Estimation-Optimization. (arXiv:2110.12351v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.12351
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32508;&#21512;&#26465;&#20214;&#20272;&#35745;-&#20248;&#21270;&#65288;ICEO&#65289;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#32771;&#34385;&#20248;&#21270;&#38382;&#39064;&#32467;&#26500;&#30340;&#21516;&#26102;&#20272;&#35745;&#38543;&#26426;&#21442;&#25968;&#30340;&#26465;&#20214;&#20998;&#24067;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20123;&#24615;&#33021;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#23454;&#38469;&#20248;&#21270;&#38382;&#39064;&#28041;&#21450;&#20855;&#26377;&#27010;&#29575;&#20998;&#24067;&#30340;&#19981;&#30830;&#23450;&#21442;&#25968;&#65292;&#21487;&#20197;&#20351;&#29992;&#19978;&#19979;&#25991;&#29305;&#24449;&#20449;&#24687;&#36827;&#34892;&#20272;&#35745;&#12290;&#19982;&#20808;&#20272;&#35745;&#19981;&#30830;&#23450;&#21442;&#25968;&#30340;&#20998;&#24067;&#28982;&#21518;&#22522;&#20110;&#20272;&#35745;&#20248;&#21270;&#30446;&#26631;&#30340;&#26631;&#20934;&#26041;&#27861;&#30456;&#21453;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#32508;&#21512;&#26465;&#20214;&#20272;&#35745;-&#20248;&#21270;&#65288;ICEO&#65289;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#22312;&#32771;&#34385;&#20248;&#21270;&#38382;&#39064;&#32467;&#26500;&#30340;&#21516;&#26102;&#20272;&#35745;&#38543;&#26426;&#21442;&#25968;&#30340;&#26465;&#20214;&#20998;&#24067;&#12290;&#25105;&#20204;&#30452;&#25509;&#24314;&#27169;&#38543;&#26426;&#21442;&#25968;&#30340;&#26465;&#20214;&#20998;&#24067;&#19982;&#19978;&#19979;&#25991;&#29305;&#24449;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#28982;&#21518;&#29992;&#19982;&#19979;&#28216;&#20248;&#21270;&#38382;&#39064;&#19968;&#33268;&#30340;&#30446;&#26631;&#20272;&#35745;&#27010;&#29575;&#27169;&#22411;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;ICEO&#26041;&#27861;&#22312;&#36866;&#24230;&#35268;&#21017;&#26465;&#20214;&#19979;&#26159;&#28176;&#36827;&#19968;&#33268;&#30340;&#65292;&#24182;&#36827;&#19968;&#27493;&#25552;&#20379;&#20102;&#19968;&#20123;&#25512;&#24191;&#30028;&#38480;&#24418;&#24335;&#30340;&#26377;&#38480;&#24615;&#33021;&#20445;&#35777;&#12290;&#35745;&#31639;&#19978;&#65292;&#20351;&#29992;
&lt;/p&gt;
&lt;p&gt;
Many real-world optimization problems involve uncertain parameters with probability distributions that can be estimated using contextual feature information. In contrast to the standard approach of first estimating the distribution of uncertain parameters and then optimizing the objective based on the estimation, we propose an integrated conditional estimation-optimization (ICEO) framework that estimates the underlying conditional distribution of the random parameter while considering the structure of the optimization problem. We directly model the relationship between the conditional distribution of the random parameter and the contextual features, and then estimate the probabilistic model with an objective that aligns with the downstream optimization problem. We show that our ICEO approach is asymptotically consistent under moderate regularity conditions and further provide finite performance guarantees in the form of generalization bounds. Computationally, performing estimation with
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21322;&#38750;&#21442;&#25968;&#28508;&#22312;&#31867;&#36873;&#25321;&#27169;&#22411;&#65292;&#37319;&#29992;&#28151;&#21512;&#27169;&#22411;&#30340;&#24418;&#24335;&#26469;&#25551;&#36848;&#28508;&#22312;&#31867;&#21035;&#65292;&#24182;&#36890;&#36807;&#27604;&#36739;&#19981;&#21516;&#30340;&#25351;&#26631;&#65292;&#21457;&#29616;&#28151;&#21512;&#27169;&#22411;&#22312;&#36873;&#25321;&#36807;&#31243;&#20013;&#20855;&#26377;&#26356;&#22909;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2007.02739</link><description>&lt;p&gt;
&#21322;&#38750;&#21442;&#25968;&#28508;&#22312;&#31867;&#36873;&#25321;&#27169;&#22411;&#19982;&#28789;&#27963;&#30340;&#31867;&#25104;&#21592;&#32452;&#20214;&#65306;&#28151;&#21512;&#27169;&#22411;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Semi-nonparametric Latent Class Choice Model with a Flexible Class Membership Component: A Mixture Model Approach. (arXiv:2007.02739v1 [econ.EM] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2007.02739
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21322;&#38750;&#21442;&#25968;&#28508;&#22312;&#31867;&#36873;&#25321;&#27169;&#22411;&#65292;&#37319;&#29992;&#28151;&#21512;&#27169;&#22411;&#30340;&#24418;&#24335;&#26469;&#25551;&#36848;&#28508;&#22312;&#31867;&#21035;&#65292;&#24182;&#36890;&#36807;&#27604;&#36739;&#19981;&#21516;&#30340;&#25351;&#26631;&#65292;&#21457;&#29616;&#28151;&#21512;&#27169;&#22411;&#22312;&#36873;&#25321;&#36807;&#31243;&#20013;&#20855;&#26377;&#26356;&#22909;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#28789;&#27963;&#31867;&#25104;&#21592;&#32452;&#20214;&#30340;&#21322;&#38750;&#21442;&#25968;&#28508;&#22312;&#31867;&#36873;&#25321;&#27169;&#22411;(LCCM)&#12290;&#35813;&#27169;&#22411;&#21033;&#29992;&#28151;&#21512;&#27169;&#22411;&#26469;&#25551;&#36848;&#28508;&#22312;&#30340;&#31867;&#21035;&#65292;&#20316;&#20026;&#20256;&#32479;&#38543;&#26426;&#25928;&#29992;&#27169;&#22411;&#30340;&#26367;&#20195;&#26041;&#27861;&#65292;&#26088;&#22312;&#27604;&#36739;&#36825;&#20004;&#31181;&#26041;&#27861;&#22312;&#39044;&#27979;&#20934;&#30830;&#24615;&#21644;&#36873;&#25321;&#36807;&#31243;&#20013;&#24322;&#36136;&#24615;&#34920;&#31034;&#31561;&#22810;&#20010;&#25351;&#26631;&#19978;&#30340;&#34920;&#29616;&#12290;&#28151;&#21512;&#27169;&#22411;&#26159;&#19968;&#31181;&#22522;&#20110;&#21442;&#25968;&#30340;&#27169;&#22411;&#32858;&#31867;&#25216;&#26415;&#65292;&#22312;&#26426;&#22120;&#23398;&#20064;&#12289;&#25968;&#25454;&#25366;&#25496;&#21644;&#27169;&#24335;&#35782;&#21035;&#31561;&#39046;&#22495;&#24191;&#27867;&#24212;&#29992;&#20110;&#32858;&#31867;&#21644;&#20998;&#31867;&#38382;&#39064;&#12290;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26399;&#26395;&#26368;&#22823;&#21270;(EM)&#31639;&#27861;&#30340;&#20272;&#35745;&#26041;&#27861;&#29992;&#20110;&#35813;&#27169;&#22411;&#12290;&#36890;&#36807;&#20004;&#20010;&#19981;&#21516;&#30340;&#20986;&#34892;&#26041;&#24335;&#36873;&#25321;&#34892;&#20026;&#30340;&#26696;&#20363;&#30740;&#31350;&#65292;&#23558;&#35813;&#27169;&#22411;&#19982;&#20256;&#32479;&#31163;&#25955;&#36873;&#25321;&#27169;&#22411;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#20998;&#26512;&#21442;&#25968;&#20272;&#35745;&#30340;&#31526;&#21495;&#12289;&#26102;&#38388;&#20215;&#20540;&#12289;&#32479;&#35745;&#25311;&#21512;&#24230;&#37327;&#21644;&#20132;&#21449;&#39564;&#35777;&#27979;&#35797;&#31561;&#25351;&#26631;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#28151;&#21512;&#27169;&#22411;&#22312;&#22810;&#20010;&#25351;&#26631;&#19978;&#30456;&#27604;&#20256;&#32479;&#36873;&#25321;&#27169;&#22411;&#20855;&#26377;&#26356;&#22909;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study presents a semi-nonparametric Latent Class Choice Model (LCCM) with a flexible class membership component. The proposed model formulates the latent classes using mixture models as an alternative approach to the traditional random utility specification with the aim of comparing the two approaches on various measures including prediction accuracy and representation of heterogeneity in the choice process. Mixture models are parametric model-based clustering techniques that have been widely used in areas such as machine learning, data mining and patter recognition for clustering and classification problems. An Expectation-Maximization (EM) algorithm is derived for the estimation of the proposed model. Using two different case studies on travel mode choice behavior, the proposed model is compared to traditional discrete choice models on the basis of parameter estimates' signs, value of time, statistical goodness-of-fit measures, and cross-validation tests. Results show that mixtu
&lt;/p&gt;</description></item></channel></rss>