<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;RED CoMETS&#30340;&#38598;&#25104;&#20998;&#31867;&#22120;&#65292;&#29992;&#20110;&#22788;&#29702;&#31526;&#21495;&#21270;&#34920;&#31034;&#30340;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#12290;&#23427;&#22312;&#22810;&#21464;&#37327;&#35774;&#32622;&#20013;&#23637;&#29616;&#20986;&#31454;&#20105;&#21147;&#30340;&#20934;&#30830;&#24615;&#65292;&#24182;&#22312;'HandMovementDirection'&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#39640;&#30340;&#25253;&#21578;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.13679</link><description>&lt;p&gt;
RED CoMETS: &#19968;&#31181;&#29992;&#20110;&#31526;&#21495;&#21270;&#34920;&#31034;&#30340;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#30340;&#38598;&#25104;&#20998;&#31867;&#22120;
&lt;/p&gt;
&lt;p&gt;
RED CoMETS: An ensemble classifier for symbolically represented multivariate time series. (arXiv:2307.13679v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13679
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;RED CoMETS&#30340;&#38598;&#25104;&#20998;&#31867;&#22120;&#65292;&#29992;&#20110;&#22788;&#29702;&#31526;&#21495;&#21270;&#34920;&#31034;&#30340;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#12290;&#23427;&#22312;&#22810;&#21464;&#37327;&#35774;&#32622;&#20013;&#23637;&#29616;&#20986;&#31454;&#20105;&#21147;&#30340;&#20934;&#30830;&#24615;&#65292;&#24182;&#22312;'HandMovementDirection'&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26368;&#39640;&#30340;&#25253;&#21578;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#26159;&#19968;&#20010;&#24555;&#36895;&#21457;&#23637;&#30340;&#30740;&#31350;&#39046;&#22495;&#65292;&#21487;&#22312;&#37329;&#34701;&#12289;&#21307;&#30103;&#12289;&#24037;&#31243;&#31561;&#23454;&#38469;&#24212;&#29992;&#20013;&#20351;&#29992;&#12290;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#20998;&#31867;&#22797;&#26434;&#24615;&#26469;&#33258;&#20110;&#20854;&#39640;&#32500;&#24230;&#12289;&#26102;&#38388;&#20381;&#36182;&#24615;&#21644;&#38271;&#24230;&#19981;&#19968;&#33268;&#24615;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;RED CoMETS&#65288;Random Enhanced Co-eye for Multivariate Time Series&#65289;&#30340;&#26032;&#22411;&#38598;&#25104;&#20998;&#31867;&#22120;&#65292;&#23427;&#35299;&#20915;&#20102;&#36825;&#20123;&#25361;&#25112;&#12290;RED CoMETS&#22522;&#20110;Co-eye&#30340;&#25104;&#21151;&#65292;&#24182;&#23558;&#20854;&#33021;&#21147;&#25193;&#23637;&#21040;&#22788;&#29702;&#22810;&#21464;&#37327;&#25968;&#25454;&#12290;&#20351;&#29992;UCR&#26723;&#26696;&#20013;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#23545;RED CoMETS&#30340;&#24615;&#33021;&#36827;&#34892;&#35780;&#20272;&#65292;&#22312;&#22810;&#21464;&#37327;&#35774;&#32622;&#20013;&#19982;&#26368;&#20808;&#36827;&#30340;&#25216;&#26415;&#30456;&#27604;&#65292;&#23427;&#26174;&#31034;&#20986;&#31454;&#20105;&#21147;&#30340;&#20934;&#30830;&#24615;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#23427;&#22312;&#25991;&#29486;&#20013;&#23545;&#20110;'HandMovementDirection'&#25968;&#25454;&#38598;&#23454;&#29616;&#20102;&#26368;&#39640;&#30340;&#25253;&#21578;&#20934;&#30830;&#24615;&#12290;&#27492;&#22806;&#65292;&#35813;&#26041;&#27861;&#26174;&#33879;&#22320;&#25913;&#36827;&#20102;&#20256;&#32479;&#30340;Co-eye&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multivariate time series classification is a rapidly growing research field with practical applications in finance, healthcare, engineering, and more. The complexity of classifying multivariate time series data arises from its high dimensionality, temporal dependencies, and varying lengths. This paper introduces a novel ensemble classifier called RED CoMETS (Random Enhanced Co-eye for Multivariate Time Series), which addresses these challenges. RED CoMETS builds upon the success of Co-eye, an ensemble classifier specifically designed for symbolically represented univariate time series, and extends its capabilities to handle multivariate data. The performance of RED CoMETS is evaluated on benchmark datasets from the UCR archive, where it demonstrates competitive accuracy when compared to state-of-the-art techniques in multivariate settings. Notably, it achieves the highest reported accuracy in the literature for the 'HandMovementDirection' dataset. Moreover, the proposed method signific
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#32771;&#34385;&#21464;&#37327;&#20043;&#38388;&#30340;&#28508;&#22312;&#30456;&#20114;&#20316;&#29992;&#65292;&#20943;&#23569;&#39118;&#38505;&#24314;&#27169;&#20013;&#30340;&#25311;&#35758;&#24046;&#21035;&#65292;&#20197;&#23454;&#29616;&#26356;&#20844;&#24179;&#30340;&#20445;&#38505;&#23450;&#20215;&#21644;&#39118;&#38505;&#36873;&#25321;&#12290;</title><link>http://arxiv.org/abs/2307.13616</link><description>&lt;p&gt;
AI&#19982;&#20445;&#38505;&#20262;&#29702;&#65306;&#22312;&#39118;&#38505;&#24314;&#27169;&#20013;&#20943;&#23569;&#25311;&#35758;&#24046;&#21035;&#30340;&#26032;&#35299;&#20915;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
AI and ethics in insurance: a new solution to mitigate proxy discrimination in risk modeling. (arXiv:2307.13616v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13616
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#36890;&#36807;&#32771;&#34385;&#21464;&#37327;&#20043;&#38388;&#30340;&#28508;&#22312;&#30456;&#20114;&#20316;&#29992;&#65292;&#20943;&#23569;&#39118;&#38505;&#24314;&#27169;&#20013;&#30340;&#25311;&#35758;&#24046;&#21035;&#65292;&#20197;&#23454;&#29616;&#26356;&#20844;&#24179;&#30340;&#20445;&#38505;&#23450;&#20215;&#21644;&#39118;&#38505;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#30340;&#21457;&#23637;&#24341;&#36215;&#20102;&#24191;&#22823;&#20844;&#20247;&#30340;&#20851;&#27880;&#65292;&#22312;&#26368;&#36817;&#20960;&#24180;&#20013;&#65292;&#26377;&#35768;&#22810;&#26032;&#38395;&#25991;&#31456;&#36136;&#30097;&#20854;&#23458;&#35266;&#24615;&#65306;&#31181;&#26063;&#20027;&#20041;&#65292;&#24615;&#21035;&#27495;&#35270;&#31561;&#12290;&#21463;&#30417;&#31649;&#26426;&#26500;&#23545;&#20445;&#38505;&#20013;&#25968;&#25454;&#36947;&#24503;&#20351;&#29992;&#30340;&#20851;&#27880;&#26085;&#30410;&#22686;&#38271;&#65292;&#20445;&#38505;&#31934;&#31639;&#24072;&#31038;&#21306;&#24517;&#39035;&#37325;&#26032;&#24605;&#32771;&#23450;&#20215;&#21644;&#39118;&#38505;&#36873;&#25321;&#23454;&#36341;&#65292;&#20197;&#23454;&#29616;&#26356;&#20844;&#24179;&#30340;&#20445;&#38505;&#12290;&#20844;&#24179;&#26159;&#19968;&#20010;&#21746;&#23398;&#27010;&#24565;&#65292;&#22312;&#27599;&#20010;&#21496;&#27861;&#31649;&#36758;&#21306;&#37117;&#26377;&#24456;&#22810;&#19981;&#21516;&#30340;&#23450;&#20041;&#65292;&#36825;&#20123;&#23450;&#20041;&#30456;&#20114;&#24433;&#21709;&#65292;&#30446;&#21069;&#23578;&#26410;&#36798;&#25104;&#19968;&#33268;&#24847;&#35265;&#12290;&#22312;&#27431;&#27954;&#65292;&#22522;&#26412;&#26435;&#21033;&#23466;&#31456;&#35268;&#23450;&#20102;&#26377;&#20851;&#27495;&#35270;&#21644;&#31639;&#27861;&#20013;&#20351;&#29992;&#25935;&#24863;&#20010;&#20154;&#25968;&#25454;&#30340;&#25351;&#23548;&#26041;&#38024;&#12290;&#22914;&#26524;&#31616;&#21333;&#22320;&#21024;&#38500;&#21463;&#20445;&#25252;&#21464;&#37327;&#21487;&#20197;&#38450;&#27490;&#20219;&#20309;&#25152;&#35859;&#30340;&#8220;&#30452;&#25509;&#8221;&#27495;&#35270;&#65292;&#37027;&#20040;&#27169;&#22411;&#20173;&#28982;&#21487;&#20197;&#36890;&#36807;&#21464;&#37327;&#20043;&#38388;&#28508;&#22312;&#30340;&#30456;&#20114;&#20316;&#29992;&#8220;&#38388;&#25509;&#8221;&#27495;&#35270;&#20010;&#20154;&#65292;&#20174;&#32780;&#24102;&#26469;&#26356;&#22909;&#30340;&#24615;&#33021;&#65288;&#22240;&#27492;&#26356;&#22909;&#22320;&#37327;&#21270;&#39118;&#38505;&#65292;&#36827;&#34892;&#32454;&#20998;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
The development of Machine Learning is experiencing growing interest from the general public, and in recent years there have been numerous press articles questioning its objectivity: racism, sexism, \dots Driven by the growing attention of regulators on the ethical use of data in insurance, the actuarial community must rethink pricing and risk selection practices for fairer insurance. Equity is a philosophy concept that has many different definitions in every jurisdiction that influence each other without currently reaching consensus. In Europe, the Charter of Fundamental Rights defines guidelines on discrimination, and the use of sensitive personal data in algorithms is regulated. If the simple removal of the protected variables prevents any so-called `direct' discrimination, models are still able to `indirectly' discriminate between individuals thanks to latent interactions between variables, which bring better performance (and therefore a better quantification of risk, segmentation 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#23574;&#23792;Wishart&#27169;&#22411;&#19979;&#65292;&#36890;&#36807;&#19968;&#31867;&#23376;&#31354;&#38388;&#24182;&#38598;&#27169;&#22411;&#25429;&#25417;&#20449;&#21495;&#32467;&#26500;&#30340;&#20027;&#25104;&#20998;&#20998;&#26512;&#38382;&#39064;&#12290;&#36890;&#36807;&#32479;&#35745;&#21644;&#35745;&#31639;&#30340;&#35270;&#35282;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#22522;&#26412;&#38480;&#21046;&#65292;&#24182;&#23637;&#31034;&#20102;&#33258;&#28982;&#30340;&#25237;&#24433;&#21151;&#29575;&#26041;&#27861;&#22312;&#35299;&#20915;&#26041;&#26696;&#30340;&#32479;&#35745;&#36817;&#20284;&#26368;&#20248;&#37051;&#22495;&#20013;&#30340;&#23616;&#37096;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#20855;&#20307;&#26696;&#20363;&#30340;&#20998;&#26512;&#23637;&#31034;&#20102;&#35745;&#31639;&#38590;&#24230;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#23545;&#20110;&#22522;&#26412;&#31232;&#30095;PCA&#35266;&#23519;&#21040;&#30340;&#29616;&#35937;&#22312;&#20854;&#32467;&#26500;&#21270;&#23545;&#24212;&#29289;&#20013;&#20063;&#21516;&#26679;&#23384;&#22312;&#12290;</title><link>http://arxiv.org/abs/2307.13535</link><description>&lt;p&gt;
&#31639;&#27861;&#21644;&#31232;&#30095;&#20027;&#25104;&#20998;&#20998;&#26512;&#30340;&#38556;&#30861;&#26159;&#21542;&#36866;&#29992;&#20110;&#20854;&#20182;&#32467;&#26500;&#35774;&#32622;&#65311;
&lt;/p&gt;
&lt;p&gt;
Do algorithms and barriers for sparse principal component analysis extend to other structured settings?. (arXiv:2307.13535v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13535
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#23574;&#23792;Wishart&#27169;&#22411;&#19979;&#65292;&#36890;&#36807;&#19968;&#31867;&#23376;&#31354;&#38388;&#24182;&#38598;&#27169;&#22411;&#25429;&#25417;&#20449;&#21495;&#32467;&#26500;&#30340;&#20027;&#25104;&#20998;&#20998;&#26512;&#38382;&#39064;&#12290;&#36890;&#36807;&#32479;&#35745;&#21644;&#35745;&#31639;&#30340;&#35270;&#35282;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#22522;&#26412;&#38480;&#21046;&#65292;&#24182;&#23637;&#31034;&#20102;&#33258;&#28982;&#30340;&#25237;&#24433;&#21151;&#29575;&#26041;&#27861;&#22312;&#35299;&#20915;&#26041;&#26696;&#30340;&#32479;&#35745;&#36817;&#20284;&#26368;&#20248;&#37051;&#22495;&#20013;&#30340;&#23616;&#37096;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#20855;&#20307;&#26696;&#20363;&#30340;&#20998;&#26512;&#23637;&#31034;&#20102;&#35745;&#31639;&#38590;&#24230;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#23545;&#20110;&#22522;&#26412;&#31232;&#30095;PCA&#35266;&#23519;&#21040;&#30340;&#29616;&#35937;&#22312;&#20854;&#32467;&#26500;&#21270;&#23545;&#24212;&#29289;&#20013;&#20063;&#21516;&#26679;&#23384;&#22312;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23574;&#23792;Wishart&#27169;&#22411;&#19979;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#20027;&#25104;&#20998;&#20998;&#26512;&#38382;&#39064;&#65292;&#20854;&#20013;&#20449;&#21495;&#20013;&#30340;&#32467;&#26500;&#36890;&#36807;&#19968;&#31867;&#23376;&#31354;&#38388;&#24182;&#38598;&#27169;&#22411;&#26469;&#25429;&#25417;&#12290;&#36825;&#20010;&#36890;&#29992;&#31867;&#21035;&#21253;&#25324;&#22522;&#26412;&#31232;&#30095;PCA&#20197;&#21450;&#24102;&#26377;&#22270;&#31232;&#30095;&#24615;&#30340;&#21464;&#20307;&#12290;&#20026;&#20102;&#22312;&#32479;&#35745;&#21644;&#35745;&#31639;&#30340;&#32479;&#19968;&#35270;&#35282;&#19979;&#30740;&#31350;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19982;&#38382;&#39064;&#23454;&#20363;&#30340;&#20960;&#20309;&#26377;&#20851;&#30340;&#22522;&#26412;&#38480;&#21046;&#65292;&#24182;&#23637;&#31034;&#20102;&#33258;&#28982;&#30340;&#25237;&#24433;&#21151;&#29575;&#26041;&#27861;&#22312;&#35299;&#20915;&#26041;&#26696;&#30340;&#32479;&#35745;&#36817;&#20284;&#26368;&#20248;&#37051;&#22495;&#20013;&#30340;&#23616;&#37096;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#26222;&#36866;&#22522;&#30784;&#20013;&#36335;&#24452;&#31232;&#30095;&#24615;&#21644;&#26641;&#31232;&#30095;&#24615;&#30340;&#20004;&#31181;&#37325;&#35201;&#29305;&#27530;&#24773;&#20917;&#36827;&#34892;&#31471;&#21040;&#31471;&#20998;&#26512;&#65292;&#34917;&#20805;&#20102;&#36825;&#20123;&#32467;&#26524;&#65292;&#23637;&#31034;&#20102;&#21021;&#22987;&#21270;&#26041;&#27861;&#21644;&#30456;&#21305;&#37197;&#30340;&#35745;&#31639;&#38590;&#24230;&#35777;&#25454;&#12290;&#24635;&#30340;&#26469;&#35828;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#23545;&#20110;&#22522;&#26412;&#31232;&#30095;PCA&#35266;&#23519;&#21040;&#30340;&#20960;&#20010;&#29616;&#35937;&#33258;&#28982;&#22320;&#25193;&#23637;&#21040;&#20854;&#32467;&#26500;&#21270;&#23545;&#24212;&#29289;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study a principal component analysis problem under the spiked Wishart model in which the structure in the signal is captured by a class of union-of-subspace models. This general class includes vanilla sparse PCA as well as its variants with graph sparsity. With the goal of studying these problems under a unified statistical and computational lens, we establish fundamental limits that depend on the geometry of the problem instance, and show that a natural projected power method exhibits local convergence to the statistically near-optimal neighborhood of the solution. We complement these results with end-to-end analyses of two important special cases given by path and tree sparsity in a general basis, showing initialization methods and matching evidence of computational hardness. Overall, our results indicate that several of the phenomena observed for vanilla sparse PCA extend in a natural fashion to its structured counterparts.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#36830;&#32493;&#26102;&#38388;&#20013;&#23398;&#20064;&#19981;&#35268;&#21017;&#26102;&#38388;&#24207;&#21015;&#30340;&#35777;&#25454;&#20998;&#24067;&#30340;&#31574;&#30053;&#65292;&#33021;&#22815;&#22312;&#20219;&#20309;&#24863;&#20852;&#36259;&#30340;&#26102;&#38388;&#19978;&#23545;&#37096;&#20998;&#35266;&#27979;&#21040;&#30340;&#29305;&#24449;&#36827;&#34892;&#33391;&#22909;&#26657;&#20934;&#21644;&#28789;&#27963;&#30340;&#25512;&#26029;&#65292;&#24182;&#19988;&#22312;&#31232;&#30095;&#12289;&#19981;&#35268;&#21017;&#35266;&#27979;&#30340;&#26102;&#38388;&#19978;&#25193;&#23637;&#19981;&#30830;&#23450;&#24615;&#12290;&#35813;&#26041;&#27861;&#22312;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#31454;&#20105;&#24615;&#30340;&#24615;&#33021;&#65292;&#24182;&#33021;&#22815;&#22312;&#36935;&#21040;&#22122;&#38899;&#25968;&#25454;&#26102;&#23454;&#29616;&#22522;&#20110;&#19981;&#30830;&#23450;&#24615;&#30340;&#25512;&#26029;&#12290;</title><link>http://arxiv.org/abs/2307.13503</link><description>&lt;p&gt;
&#19981;&#35268;&#21017;&#26102;&#38388;&#24207;&#21015;&#30340;&#36830;&#32493;&#26102;&#38388;&#35777;&#25454;&#20998;&#24067;
&lt;/p&gt;
&lt;p&gt;
Continuous Time Evidential Distributions for Irregular Time Series. (arXiv:2307.13503v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13503
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#36830;&#32493;&#26102;&#38388;&#20013;&#23398;&#20064;&#19981;&#35268;&#21017;&#26102;&#38388;&#24207;&#21015;&#30340;&#35777;&#25454;&#20998;&#24067;&#30340;&#31574;&#30053;&#65292;&#33021;&#22815;&#22312;&#20219;&#20309;&#24863;&#20852;&#36259;&#30340;&#26102;&#38388;&#19978;&#23545;&#37096;&#20998;&#35266;&#27979;&#21040;&#30340;&#29305;&#24449;&#36827;&#34892;&#33391;&#22909;&#26657;&#20934;&#21644;&#28789;&#27963;&#30340;&#25512;&#26029;&#65292;&#24182;&#19988;&#22312;&#31232;&#30095;&#12289;&#19981;&#35268;&#21017;&#35266;&#27979;&#30340;&#26102;&#38388;&#19978;&#25193;&#23637;&#19981;&#30830;&#23450;&#24615;&#12290;&#35813;&#26041;&#27861;&#22312;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#31454;&#20105;&#24615;&#30340;&#24615;&#33021;&#65292;&#24182;&#33021;&#22815;&#22312;&#36935;&#21040;&#22122;&#38899;&#25968;&#25454;&#26102;&#23454;&#29616;&#22522;&#20110;&#19981;&#30830;&#23450;&#24615;&#30340;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#22330;&#26223;&#20013;&#65292;&#22914;&#21307;&#30103;&#20445;&#20581;&#39046;&#22495;&#65292;&#19981;&#35268;&#21017;&#26102;&#38388;&#24207;&#21015;&#24456;&#38590;&#36827;&#34892;&#39044;&#27979;&#12290;&#24403;&#35266;&#27979;&#19981;&#36830;&#32493;&#26102;&#65292;&#22312;&#20219;&#20309;&#32473;&#23450;&#26102;&#38388;&#25512;&#26029;&#29305;&#24449;&#30340;&#20540;&#26159;&#22256;&#38590;&#30340;&#65292;&#22240;&#20026;&#23427;&#21487;&#33021;&#21462;&#20915;&#20110;&#26368;&#21518;&#19968;&#27425;&#35266;&#23519;&#30340;&#26102;&#38388;&#32780;&#20855;&#26377;&#19968;&#31995;&#21015;&#30340;&#20540;&#12290;&#20026;&#20102;&#25551;&#36848;&#36825;&#31181;&#19981;&#30830;&#23450;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;EDICT&#65292;&#19968;&#31181;&#22312;&#36830;&#32493;&#26102;&#38388;&#20013;&#23398;&#20064;&#19981;&#35268;&#21017;&#26102;&#38388;&#24207;&#21015;&#30340;&#35777;&#25454;&#20998;&#24067;&#30340;&#31574;&#30053;&#12290;&#36825;&#20010;&#20998;&#24067;&#21487;&#20197;&#22312;&#20219;&#20309;&#24863;&#20852;&#36259;&#30340;&#26102;&#38388;&#19978;&#23545;&#37096;&#20998;&#35266;&#27979;&#21040;&#30340;&#29305;&#24449;&#36827;&#34892;&#33391;&#22909;&#26657;&#20934;&#21644;&#28789;&#27963;&#30340;&#25512;&#26029;&#65292;&#21516;&#26102;&#22312;&#31232;&#30095;&#12289;&#19981;&#35268;&#21017;&#35266;&#27979;&#30340;&#26102;&#38388;&#19978;&#25193;&#23637;&#19981;&#30830;&#23450;&#24615;&#12290;&#25105;&#20204;&#28436;&#31034;&#20102;EDICT&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#31454;&#20105;&#24615;&#30340;&#24615;&#33021;&#65292;&#24182;&#22312;&#36935;&#21040;&#22122;&#38899;&#25968;&#25454;&#26102;&#23454;&#29616;&#20102;&#22522;&#20110;&#19981;&#30830;&#23450;&#24615;&#30340;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
Prevalent in many real-world settings such as healthcare, irregular time series are challenging to formulate predictions from. It is difficult to infer the value of a feature at any given time when observations are sporadic, as it could take on a range of values depending on when it was last observed. To characterize this uncertainty we present EDICT, a strategy that learns an evidential distribution over irregular time series in continuous time. This distribution enables well-calibrated and flexible inference of partially observed features at any time of interest, while expanding uncertainty temporally for sparse, irregular observations. We demonstrate that EDICT attains competitive performance on challenging time series classification tasks and enabling uncertainty-guided inference when encountering noisy data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#24322;&#26500;&#22270;&#31070;&#32463;&#32593;&#32476;&#26469;&#23547;&#25214;&#27927;&#38065;&#32773;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#30495;&#23454;&#30340;&#38134;&#34892;&#20132;&#26131;&#21644;&#21830;&#19994;&#35282;&#33394;&#25968;&#25454;&#26500;&#24314;&#30340;&#22823;&#22411;&#24322;&#26500;&#32593;&#32476;&#20013;&#35782;&#21035;&#27927;&#38065;&#27963;&#21160;&#12290;&#20026;&#20102;&#35299;&#20915;&#27927;&#38065;&#27963;&#21160;&#20013;&#29359;&#32618;&#20998;&#23376;&#30340;&#21512;&#20316;&#38382;&#39064;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;&#21516;&#36136;&#22270;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#28040;&#24687;&#32858;&#21512;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.13499</link><description>&lt;p&gt;
&#20351;&#29992;&#24322;&#26500;&#22270;&#31070;&#32463;&#32593;&#32476;&#23547;&#25214;&#27927;&#38065;&#32773;
&lt;/p&gt;
&lt;p&gt;
Finding Money Launderers Using Heterogeneous Graph Neural Networks. (arXiv:2307.13499v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13499
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#24322;&#26500;&#22270;&#31070;&#32463;&#32593;&#32476;&#26469;&#23547;&#25214;&#27927;&#38065;&#32773;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#30495;&#23454;&#30340;&#38134;&#34892;&#20132;&#26131;&#21644;&#21830;&#19994;&#35282;&#33394;&#25968;&#25454;&#26500;&#24314;&#30340;&#22823;&#22411;&#24322;&#26500;&#32593;&#32476;&#20013;&#35782;&#21035;&#27927;&#38065;&#27963;&#21160;&#12290;&#20026;&#20102;&#35299;&#20915;&#27927;&#38065;&#27963;&#21160;&#20013;&#29359;&#32618;&#20998;&#23376;&#30340;&#21512;&#20316;&#38382;&#39064;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;&#21516;&#36136;&#22270;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#28040;&#24687;&#32858;&#21512;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#30340;&#21453;&#27927;&#38065;&#31995;&#32479;&#20027;&#35201;&#22522;&#20110;&#35268;&#21017;&#65292;&#23384;&#22312;&#26126;&#26174;&#30340;&#38382;&#39064;&#65292;&#38590;&#20197;&#39640;&#25928;&#21644;&#20934;&#30830;&#22320;&#26816;&#27979;&#27927;&#38065;&#27963;&#21160;&#12290;&#22240;&#27492;&#65292;&#36817;&#24180;&#26469;&#20986;&#29616;&#20102;&#23545;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#30340;&#26367;&#20195;&#26041;&#27861;&#30340;&#25506;&#32034;&#28909;&#28526;&#12290;&#30001;&#20110;&#29359;&#32618;&#20998;&#23376;&#36890;&#24120;&#22312;&#27927;&#38065;&#27963;&#21160;&#20013;&#21512;&#20316;&#65292;&#22240;&#27492;&#32771;&#34385;&#21040;&#19981;&#21516;&#31867;&#22411;&#30340;&#23458;&#25143;&#20851;&#31995;&#21644;&#38142;&#25509;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#30340;&#26041;&#27861;&#65292;&#20174;&#25386;&#23041;&#26368;&#22823;&#30340;&#38134;&#34892;DNB&#30340;&#30495;&#23454;&#38134;&#34892;&#20132;&#26131;&#21644;&#21830;&#19994;&#35282;&#33394;&#25968;&#25454;&#26500;&#24314;&#30340;&#22823;&#22411;&#24322;&#26500;&#32593;&#32476;&#20013;&#35782;&#21035;&#27927;&#38065;&#27963;&#21160;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;&#19968;&#31181;&#31216;&#20026;&#28040;&#24687;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#65288;MPNN&#65289;&#30340;&#21516;&#36136;GNN&#26041;&#27861;&#65292;&#20197;&#22312;&#24322;&#26500;&#22270;&#19978;&#26377;&#25928;&#36816;&#34892;&#12290;&#20316;&#20026;&#35813;&#26041;&#27861;&#30340;&#19968;&#37096;&#20998;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#22270;&#30340;&#19981;&#21516;&#36793;&#20043;&#38388;&#32858;&#21512;&#28040;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
Current anti-money laundering (AML) systems, predominantly rule-based, exhibit notable shortcomings in efficiently and precisely detecting instances of money laundering. As a result, there has been a recent surge toward exploring alternative approaches, particularly those utilizing machine learning. Since criminals often collaborate in their money laundering endeavors, accounting for diverse types of customer relations and links becomes crucial. In line with this, the present paper introduces a graph neural network (GNN) approach to identify money laundering activities within a large heterogeneous network constructed from real-world bank transactions and business role data belonging to DNB, Norway's largest bank. Specifically, we extend the homogeneous GNN method known as the Message Passing Neural Network (MPNN) to operate effectively on a heterogeneous graph. As part of this procedure, we propose a novel method for aggregating messages across different edges of the graph. Our finding
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#37319;&#29992;&#30456;&#23545;&#35770;&#37327;&#23376;&#22330;&#35770;&#21644;&#37327;&#23376;&#22810;&#20307;&#31995;&#32479;&#20013;&#30340;Lieb-Robinson&#30028;&#38480;&#65292;&#25209;&#21028;&#24615;&#22320;&#25506;&#35752;&#20102;&#22522;&#20110;&#22240;&#26524;&#24615;&#30340;&#24555;&#36895;&#37327;&#23376;&#23384;&#20648;&#22120;&#30340;&#20869;&#22312;&#30028;&#38480;&#12290;&#30740;&#31350;&#34920;&#26126;&#22312;&#28151;&#21512;&#37327;&#23376;&#22768;&#23398;&#31995;&#32479;&#20013;&#65292;QRAM&#21487;&#20197;&#23481;&#32435;&#26368;&#22810;O(10^7)&#20010;&#36923;&#36753;&#27604;&#29305;&#30340;&#19968;&#32500;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2307.13460</link><description>&lt;p&gt;
&#37327;&#23376;&#38543;&#26426;&#35775;&#38382;&#20869;&#23384;&#30340;&#22522;&#26412;&#22240;&#26524;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Fundamental causal bounds of quantum random access memories. (arXiv:2307.13460v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13460
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#37319;&#29992;&#30456;&#23545;&#35770;&#37327;&#23376;&#22330;&#35770;&#21644;&#37327;&#23376;&#22810;&#20307;&#31995;&#32479;&#20013;&#30340;Lieb-Robinson&#30028;&#38480;&#65292;&#25209;&#21028;&#24615;&#22320;&#25506;&#35752;&#20102;&#22522;&#20110;&#22240;&#26524;&#24615;&#30340;&#24555;&#36895;&#37327;&#23376;&#23384;&#20648;&#22120;&#30340;&#20869;&#22312;&#30028;&#38480;&#12290;&#30740;&#31350;&#34920;&#26126;&#22312;&#28151;&#21512;&#37327;&#23376;&#22768;&#23398;&#31995;&#32479;&#20013;&#65292;QRAM&#21487;&#20197;&#23481;&#32435;&#26368;&#22810;O(10^7)&#20010;&#36923;&#36753;&#27604;&#29305;&#30340;&#19968;&#32500;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#23376;&#35774;&#22791;&#24212;&#36981;&#23432;&#37327;&#23376;&#29289;&#29702;&#21407;&#21017;&#12290;&#37327;&#23376;&#38543;&#26426;&#35775;&#38382;&#20869;&#23384;&#65288;QRAM&#65289;&#26159;&#35768;&#22810;&#37325;&#35201;&#37327;&#23376;&#31639;&#27861;&#65288;&#22914;&#32447;&#24615;&#20195;&#25968;&#12289;&#25968;&#25454;&#25628;&#32034;&#21644;&#26426;&#22120;&#23398;&#20064;&#65289;&#30340;&#22522;&#26412;&#32452;&#20214;&#65292;&#36890;&#24120;&#34987;&#35748;&#20026;&#22312;&#32473;&#23450;N&#20010;&#37327;&#23376;&#27604;&#29305;&#26102;&#65292;&#21487;&#20197;&#20197;O(log N)&#30340;&#30005;&#36335;&#28145;&#24230;&#22788;&#29702;O(N)&#30340;&#25968;&#25454;&#37327;&#12290;&#28982;&#32780;&#65292;&#24403;&#22788;&#29702;&#22823;&#37327;&#37327;&#23376;&#27604;&#29305;&#30340;&#30456;&#20114;&#20316;&#29992;&#23616;&#37096;&#30340;&#37327;&#23376;&#26448;&#26009;&#26102;&#65292;&#36825;&#19968;&#20027;&#24352;&#20284;&#20046;&#36829;&#21453;&#20102;&#30456;&#23545;&#35770;&#21407;&#29702;&#12290;&#22312;&#25105;&#20204;&#30340;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25209;&#21028;&#24615;&#22320;&#25506;&#35752;&#20102;&#22522;&#20110;&#22240;&#26524;&#24615;&#30340;&#24555;&#36895;&#37327;&#23376;&#23384;&#20648;&#22120;&#30340;&#20869;&#22312;&#30028;&#38480;&#65292;&#21033;&#29992;&#30456;&#23545;&#35770;&#37327;&#23376;&#22330;&#35770;&#21644;Lieb-Robinson&#30028;&#38480;&#22312;&#37327;&#23376;&#22810;&#20307;&#31995;&#32479;&#20013;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#22312;&#28151;&#21512;&#37327;&#23376;&#22768;&#23398;&#31995;&#32479;&#20013;&#39640;&#25928;&#30340;&#30828;&#20214;&#35774;&#35745;&#30340;QRAM&#12290;&#20551;&#35774;&#26102;&#38047;&#21608;&#26399;&#32422;&#20026;10^{-3}&#31186;&#65292;&#26684;&#23376;&#38388;&#36317;&#32422;&#20026;1&#24494;&#31859;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;QRAM&#21487;&#20197;&#23481;&#32435;&#26368;&#22810;O(10^7)&#20010;&#36923;&#36753;&#27604;&#29305;&#30340;&#19968;&#32500;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantum devices should operate in adherence to quantum physics principles. Quantum random access memory (QRAM), a fundamental component of many essential quantum algorithms for tasks such as linear algebra, data search, and machine learning, is often proposed to offer $\mathcal{O}(\log N)$ circuit depth for $\mathcal{O}(N)$ data size, given $N$ qubits. However, this claim appears to breach the principle of relativity when dealing with a large number of qubits in quantum materials interacting locally. In our study we critically explore the intrinsic bounds of rapid quantum memories based on causality, employing the relativistic quantum field theory and Lieb-Robinson bounds in quantum many-body systems. In this paper, we consider a hardware-efficient QRAM design in hybrid quantum acoustic systems. Assuming clock cycle times of approximately $10^{-3}$ seconds and a lattice spacing of about 1 micrometer, we show that QRAM can accommodate up to $\mathcal{O}(10^7)$ logical qubits in 1 dimens
&lt;/p&gt;</description></item><item><title>Scaff-PD&#26159;&#19968;&#20010;&#39640;&#25928;&#36890;&#20449;&#12289;&#20844;&#24179;&#21450;&#40065;&#26834;&#30340;&#20998;&#24067;&#24335;&#23398;&#20064;&#31639;&#27861;&#12290;&#23427;&#36890;&#36807;&#20248;&#21270;&#19968;&#31995;&#21015;&#38024;&#23545;&#24322;&#26500;&#23458;&#25143;&#31471;&#30340;&#20998;&#24067;&#40065;&#26834;&#30446;&#26631;&#26469;&#25552;&#39640;&#20844;&#24179;&#24615;&#65292;&#21033;&#29992;&#29305;&#27530;&#32467;&#26500;&#21644;&#21152;&#36895;&#30340;&#21407;&#22987;-&#23545;&#20598;&#31639;&#27861;&#65292;&#22312;&#36890;&#20449;&#25928;&#29575;&#21644;&#25910;&#25947;&#36895;&#24230;&#26041;&#38754;&#21462;&#24471;&#26174;&#33879;&#30340;&#25552;&#21319;&#12290;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#35780;&#20272;&#32467;&#26524;&#26174;&#31034;&#65292;Scaff-PD&#22312;&#25552;&#39640;&#20844;&#24179;&#24615;&#21644;&#40065;&#26834;&#24615;&#26041;&#38754;&#26377;&#25928;&#65292;&#24182;&#21516;&#26102;&#20445;&#25345;&#31454;&#20105;&#24615;&#30340;&#20934;&#30830;&#24615;&#12290;&#36825;&#20351;&#24471;Scaff-PD&#25104;&#20026;&#36164;&#28304;&#21463;&#38480;&#21644;&#24322;&#26500;&#29615;&#22659;&#19979;&#20998;&#24067;&#24335;&#23398;&#20064;&#30340;&#19968;&#31181;&#26377;&#21069;&#26223;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.13381</link><description>&lt;p&gt;
Scaff-PD:&#39640;&#25928;&#29575;&#36890;&#20449;&#12289;&#20844;&#24179;&#21450;&#40065;&#26834;&#30340;&#20998;&#24067;&#24335;&#23398;&#20064;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Scaff-PD: Communication Efficient Fair and Robust Federated Learning. (arXiv:2307.13381v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13381
&lt;/p&gt;
&lt;p&gt;
Scaff-PD&#26159;&#19968;&#20010;&#39640;&#25928;&#36890;&#20449;&#12289;&#20844;&#24179;&#21450;&#40065;&#26834;&#30340;&#20998;&#24067;&#24335;&#23398;&#20064;&#31639;&#27861;&#12290;&#23427;&#36890;&#36807;&#20248;&#21270;&#19968;&#31995;&#21015;&#38024;&#23545;&#24322;&#26500;&#23458;&#25143;&#31471;&#30340;&#20998;&#24067;&#40065;&#26834;&#30446;&#26631;&#26469;&#25552;&#39640;&#20844;&#24179;&#24615;&#65292;&#21033;&#29992;&#29305;&#27530;&#32467;&#26500;&#21644;&#21152;&#36895;&#30340;&#21407;&#22987;-&#23545;&#20598;&#31639;&#27861;&#65292;&#22312;&#36890;&#20449;&#25928;&#29575;&#21644;&#25910;&#25947;&#36895;&#24230;&#26041;&#38754;&#21462;&#24471;&#26174;&#33879;&#30340;&#25552;&#21319;&#12290;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#35780;&#20272;&#32467;&#26524;&#26174;&#31034;&#65292;Scaff-PD&#22312;&#25552;&#39640;&#20844;&#24179;&#24615;&#21644;&#40065;&#26834;&#24615;&#26041;&#38754;&#26377;&#25928;&#65292;&#24182;&#21516;&#26102;&#20445;&#25345;&#31454;&#20105;&#24615;&#30340;&#20934;&#30830;&#24615;&#12290;&#36825;&#20351;&#24471;Scaff-PD&#25104;&#20026;&#36164;&#28304;&#21463;&#38480;&#21644;&#24322;&#26500;&#29615;&#22659;&#19979;&#20998;&#24067;&#24335;&#23398;&#20064;&#30340;&#19968;&#31181;&#26377;&#21069;&#26223;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Scaff-PD&#30340;&#24555;&#36895;&#21644;&#39640;&#25928;&#36890;&#20449;&#30340;&#20998;&#24067;&#24335;&#23398;&#20064;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#20248;&#21270;&#19968;&#31995;&#21015;&#38024;&#23545;&#24322;&#26500;&#23458;&#25143;&#31471;&#30340;&#20998;&#24067;&#40065;&#26834;&#30446;&#26631;&#26469;&#25913;&#21892;&#20844;&#24179;&#24615;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#20123;&#30446;&#26631;&#30340;&#29305;&#27530;&#32467;&#26500;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#20010;&#21152;&#36895;&#30340;&#21407;&#22987;-&#23545;&#20598;&#65288;APD&#65289;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20351;&#29992;&#20462;&#27491;&#20559;&#24046;&#30340;&#23616;&#37096;&#27493;&#39588;&#65288;&#22914;Scaffold&#65289;&#20197;&#22312;&#36890;&#20449;&#25928;&#29575;&#21644;&#25910;&#25947;&#36895;&#24230;&#26041;&#38754;&#21462;&#24471;&#26174;&#33879;&#30340;&#25552;&#21319;&#12290;&#25105;&#20204;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;Scaff-PD&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;&#25552;&#39640;&#20844;&#24179;&#24615;&#21644;&#40065;&#26834;&#24615;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#65292;&#21516;&#26102;&#20445;&#25345;&#31454;&#20105;&#24615;&#30340;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;Scaff-PD&#26159;&#22312;&#36164;&#28304;&#21463;&#38480;&#21644;&#24322;&#26500;&#29615;&#22659;&#20013;&#36827;&#34892;&#20998;&#24067;&#24335;&#23398;&#20064;&#30340;&#19968;&#31181;&#26377;&#21069;&#26223;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present Scaff-PD, a fast and communication-efficient algorithm for distributionally robust federated learning. Our approach improves fairness by optimizing a family of distributionally robust objectives tailored to heterogeneous clients. We leverage the special structure of these objectives, and design an accelerated primal dual (APD) algorithm which uses bias corrected local steps (as in Scaffold) to achieve significant gains in communication efficiency and convergence speed. We evaluate Scaff-PD on several benchmark datasets and demonstrate its effectiveness in improving fairness and robustness while maintaining competitive accuracy. Our results suggest that Scaff-PD is a promising approach for federated learning in resource-constrained and heterogeneous settings.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;BALLET&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#39640;&#32500;&#21644;&#38750;&#24179;&#31283;&#22330;&#26223;&#19979;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#12290;&#23427;&#20351;&#29992;&#20004;&#20010;&#27010;&#29575;&#27169;&#22411;&#65292;&#19968;&#20010;&#31895;&#31961;&#30340;&#39640;&#26031;&#36807;&#31243;&#29992;&#20110;&#35782;&#21035;&#24863;&#20852;&#36259;&#30340;&#21306;&#22495;&#65292;&#19968;&#20010;&#23616;&#37096;&#39640;&#26031;&#36807;&#31243;&#29992;&#20110;&#20248;&#21270;&#35813;&#21306;&#22495;&#12290;BALLET&#33021;&#22815;&#26377;&#25928;&#22320;&#32553;&#23567;&#25628;&#32034;&#31354;&#38388;&#65292;&#24182;&#19988;&#27604;&#26631;&#20934;&#30340;&#26080;&#24863;&#20852;&#36259;&#21306;&#22495;&#36807;&#28388;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#20855;&#26377;&#26356;&#32039;&#30340;&#36951;&#25022;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2307.13371</link><description>&lt;p&gt;
&#23398;&#20064;&#36866;&#24212;&#24615;&#27700;&#24179;&#38598;&#20272;&#35745;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#24863;&#20852;&#36259;&#21306;&#22495;
&lt;/p&gt;
&lt;p&gt;
Learning Regions of Interest for Bayesian Optimization with Adaptive Level-Set Estimation. (arXiv:2307.13371v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13371
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;BALLET&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#39640;&#32500;&#21644;&#38750;&#24179;&#31283;&#22330;&#26223;&#19979;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#12290;&#23427;&#20351;&#29992;&#20004;&#20010;&#27010;&#29575;&#27169;&#22411;&#65292;&#19968;&#20010;&#31895;&#31961;&#30340;&#39640;&#26031;&#36807;&#31243;&#29992;&#20110;&#35782;&#21035;&#24863;&#20852;&#36259;&#30340;&#21306;&#22495;&#65292;&#19968;&#20010;&#23616;&#37096;&#39640;&#26031;&#36807;&#31243;&#29992;&#20110;&#20248;&#21270;&#35813;&#21306;&#22495;&#12290;BALLET&#33021;&#22815;&#26377;&#25928;&#22320;&#32553;&#23567;&#25628;&#32034;&#31354;&#38388;&#65292;&#24182;&#19988;&#27604;&#26631;&#20934;&#30340;&#26080;&#24863;&#20852;&#36259;&#21306;&#22495;&#36807;&#28388;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#20855;&#26377;&#26356;&#32039;&#30340;&#36951;&#25022;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#39640;&#32500;&#21644;&#38750;&#24179;&#31283;&#22330;&#26223;&#19979;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;BO&#65289;&#12290;&#29616;&#26377;&#30340;&#31639;&#27861;&#36890;&#24120;&#38656;&#35201;&#22823;&#37327;&#30340;&#36229;&#21442;&#25968;&#35843;&#25972;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#30340;&#23454;&#38469;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;BALLET&#30340;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#20197;&#38750;&#21442;&#25968;&#27010;&#29575;&#27169;&#22411;&#65288;&#22914;&#39640;&#26031;&#36807;&#31243;&#65289;&#30340;&#36229;&#32423;&#32423;&#38598;&#30340;&#39640;&#32622;&#20449;&#24230;&#24863;&#20852;&#36259;&#21306;&#22495;&#65288;ROI&#65289;&#20026;&#33258;&#36866;&#24212;&#36807;&#28388;&#22120;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26131;&#20110;&#35843;&#25972;&#65292;&#24182;&#19988;&#33021;&#22815;&#19987;&#27880;&#20110;&#21487;&#20197;&#36890;&#36807;&#29616;&#26377;&#30340;BO&#26041;&#27861;&#35299;&#20915;&#30340;&#20248;&#21270;&#31354;&#38388;&#30340;&#23616;&#37096;&#21306;&#22495;&#12290;&#20851;&#38190;&#24605;&#24819;&#26159;&#20351;&#29992;&#20004;&#20010;&#27010;&#29575;&#27169;&#22411;&#65306;&#19968;&#20010;&#31895;&#31961;&#30340;&#39640;&#26031;&#36807;&#31243;&#29992;&#20110;&#35782;&#21035;ROI&#65292;&#19968;&#20010;&#23616;&#37096;&#39640;&#26031;&#36807;&#31243;&#29992;&#20110;ROI&#20869;&#30340;&#20248;&#21270;&#12290;&#25105;&#20204;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;BALLET&#21487;&#20197;&#39640;&#25928;&#22320;&#32553;&#23567;&#25628;&#32034;&#31354;&#38388;&#65292;&#24182;&#19988;&#27604;&#26631;&#20934;&#30340;&#26080;ROI&#36807;&#28388;&#30340;BO&#20855;&#26377;&#26356;&#32039;&#30340;&#36951;&#25022;&#30028;&#38480;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#30340;&#20248;&#21270;&#20219;&#21153;&#20013;&#32463;&#39564;&#24615;&#22320;&#35777;&#26126;&#20102;BALLET&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study Bayesian optimization (BO) in high-dimensional and non-stationary scenarios. Existing algorithms for such scenarios typically require extensive hyperparameter tuning, which limits their practical effectiveness. We propose a framework, called BALLET, which adaptively filters for a high-confidence region of interest (ROI) as a superlevel-set of a nonparametric probabilistic model such as a Gaussian process (GP). Our approach is easy to tune, and is able to focus on local region of the optimization space that can be tackled by existing BO methods. The key idea is to use two probabilistic models: a coarse GP to identify the ROI, and a localized GP for optimization within the ROI. We show theoretically that BALLET can efficiently shrink the search space, and can exhibit a tighter regret bound than standard BO without ROI filtering. We demonstrate empirically the effectiveness of BALLET on both synthetic and real-world optimization tasks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35745;&#31639;&#21452;&#35268;&#21017;&#21270;Wasserstein&#37325;&#24515;&#30340;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#38459;&#23612;Sinkhorn&#36845;&#20195;&#21644;&#31934;&#30830;&#30340;&#26368;&#22823;&#21270;/&#26368;&#23567;&#21270;&#27493;&#39588;&#20445;&#35777;&#20102;&#25910;&#25947;&#24615;&#12290;&#27492;&#31639;&#27861;&#30340;&#38750;&#31934;&#30830;&#21464;&#20307;&#20351;&#29992;&#36817;&#20284;&#30340;&#33945;&#29305;&#21345;&#32599;&#37319;&#26679;&#23454;&#29616;&#65292;&#22312;&#33258;&#30001;&#25903;&#25745;/&#32593;&#26684;&#33258;&#30001;&#35774;&#32622;&#20013;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#38750;&#28176;&#36817;&#25910;&#25947;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2307.13370</link><description>&lt;p&gt;
&#36890;&#36807;&#38459;&#23612;Sinkhorn&#36845;&#20195;&#23454;&#29616;&#21452;&#29109;Wasserstein&#37325;&#24515;&#30340;&#35745;&#31639;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Computational Guarantees for Doubly Entropic Wasserstein Barycenters via Damped Sinkhorn Iterations. (arXiv:2307.13370v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13370
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35745;&#31639;&#21452;&#35268;&#21017;&#21270;Wasserstein&#37325;&#24515;&#30340;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#38459;&#23612;Sinkhorn&#36845;&#20195;&#21644;&#31934;&#30830;&#30340;&#26368;&#22823;&#21270;/&#26368;&#23567;&#21270;&#27493;&#39588;&#20445;&#35777;&#20102;&#25910;&#25947;&#24615;&#12290;&#27492;&#31639;&#27861;&#30340;&#38750;&#31934;&#30830;&#21464;&#20307;&#20351;&#29992;&#36817;&#20284;&#30340;&#33945;&#29305;&#21345;&#32599;&#37319;&#26679;&#23454;&#29616;&#65292;&#22312;&#33258;&#30001;&#25903;&#25745;/&#32593;&#26684;&#33258;&#30001;&#35774;&#32622;&#20013;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#38750;&#28176;&#36817;&#25910;&#25947;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#21452;&#35268;&#21017;&#21270;Wasserstein&#37325;&#24515;&#30340;&#35745;&#31639;&#65292;&#36825;&#26159;&#19968;&#31181;&#26368;&#36817;&#24341;&#20837;&#30340;&#30001;&#20869;&#37096;&#21644;&#22806;&#37096;&#35268;&#21017;&#21270;&#24378;&#24230;&#25511;&#21046;&#30340;&#29109;&#37325;&#24515;&#26063;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#21508;&#31181;&#35268;&#21017;&#21270;&#21442;&#25968;&#36873;&#25321;&#32479;&#19968;&#20102;&#20960;&#20010;&#29109;&#24809;&#32602;&#37325;&#24515;&#30340;&#27010;&#24565;&#65292;&#21516;&#26102;&#25581;&#31034;&#20102;&#26032;&#30340;&#27010;&#24565;&#65292;&#21253;&#25324;&#20559;&#24046;&#37325;&#24515;&#30340;&#29305;&#27530;&#24773;&#20917;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#24182;&#20998;&#26512;&#20102;&#19968;&#31181;&#35745;&#31639;&#21452;&#35268;&#21017;&#21270;Wasserstein&#37325;&#24515;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#36807;&#31243;&#22522;&#20110;&#38459;&#23612;Sinkhorn&#36845;&#20195;&#65292;&#28982;&#21518;&#26159;&#31934;&#30830;&#30340;&#26368;&#22823;&#21270;/&#26368;&#23567;&#21270;&#27493;&#39588;&#65292;&#23545;&#20219;&#20309;&#35268;&#21017;&#21270;&#21442;&#25968;&#30340;&#36873;&#25321;&#37117;&#20445;&#35777;&#25910;&#25947;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#30340;&#38750;&#31934;&#30830;&#21464;&#20307;&#65292;&#21487;&#20197;&#20351;&#29992;&#36817;&#20284;&#30340;&#33945;&#29305;&#21345;&#32599;&#37319;&#26679;&#26469;&#23454;&#29616;&#65292;&#22312;&#33258;&#30001;&#25903;&#25745;/&#32593;&#26684;&#33258;&#30001;&#35774;&#32622;&#20013;&#20026;&#36817;&#20284;Wasserstein&#37325;&#24515;&#20043;&#38388;&#30340;&#31163;&#25955;&#28857;&#20113;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#38750;&#28176;&#36817;&#25910;&#25947;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the computation of doubly regularized Wasserstein barycenters, a recently introduced family of entropic barycenters governed by inner and outer regularization strengths. Previous research has demonstrated that various regularization parameter choices unify several notions of entropy-penalized barycenters while also revealing new ones, including a special case of debiased barycenters. In this paper, we propose and analyze an algorithm for computing doubly regularized Wasserstein barycenters. Our procedure builds on damped Sinkhorn iterations followed by exact maximization/minimization steps and guarantees convergence for any choice of regularization parameters. An inexact variant of our algorithm, implementable using approximate Monte Carlo sampling, offers the first non-asymptotic convergence guarantees for approximating Wasserstein barycenters between discrete point clouds in the free-support/grid-free setting.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#24615;&#31163;&#31574;&#30053;&#20540;&#20989;&#25968;&#20272;&#35745;&#20013;&#30340;&#36924;&#36817;&#22240;&#23376;&#65292;&#24182;&#22312;&#22810;&#31181;&#35774;&#32622;&#19979;&#24314;&#31435;&#20102;&#26368;&#20248;&#30340;&#28176;&#36817;&#36924;&#36817;&#22240;&#23376;&#65292;&#36825;&#20123;&#22240;&#23376;&#20915;&#23450;&#20102;&#31163;&#31574;&#30053;&#35780;&#20272;&#30340;&#22256;&#38590;&#31243;&#24230;&#12290;</title><link>http://arxiv.org/abs/2307.13332</link><description>&lt;p&gt;
&#22312;&#38169;&#35823;&#25351;&#23450;&#30340;&#31163;&#31574;&#30053;&#20540;&#20989;&#25968;&#20272;&#35745;&#20013;&#30340;&#26368;&#20339;&#36924;&#36817;&#22240;&#23376;
&lt;/p&gt;
&lt;p&gt;
The Optimal Approximation Factors in Misspecified Off-Policy Value Function Estimation. (arXiv:2307.13332v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13332
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#24615;&#31163;&#31574;&#30053;&#20540;&#20989;&#25968;&#20272;&#35745;&#20013;&#30340;&#36924;&#36817;&#22240;&#23376;&#65292;&#24182;&#22312;&#22810;&#31181;&#35774;&#32622;&#19979;&#24314;&#31435;&#20102;&#26368;&#20248;&#30340;&#28176;&#36817;&#36924;&#36817;&#22240;&#23376;&#65292;&#36825;&#20123;&#22240;&#23376;&#20915;&#23450;&#20102;&#31163;&#31574;&#30053;&#35780;&#20272;&#30340;&#22256;&#38590;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24050;&#32463;&#30693;&#36947;&#65292;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#29702;&#35770;&#20445;&#35777;&#22312;&#20989;&#25968;&#36924;&#36817;&#30340;&#38169;&#35823;&#25351;&#23450;&#20013;&#20250;&#20986;&#29616;&#20056;&#27861;&#25918;&#22823;&#22240;&#23376;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;\emph{&#36924;&#36817;&#22240;&#23376;}&#30340;&#24615;&#36136;&#65292;&#29305;&#21035;&#26159;&#22312;&#32473;&#23450;&#30340;&#23398;&#20064;&#38382;&#39064;&#20013;&#30340;&#26368;&#20339;&#24418;&#24335;&#65292;&#20173;&#28982;&#19981;&#20026;&#20154;&#25152;&#20102;&#35299;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#36825;&#20010;&#38382;&#39064;&#22312;&#32447;&#24615;&#31163;&#31574;&#30053;&#20540;&#20989;&#25968;&#20272;&#35745;&#20013;&#30340;&#24191;&#27867;&#35774;&#32622;&#20013;&#30340;&#36924;&#36817;&#22240;&#23376;&#65292;&#20854;&#20013;&#20173;&#26377;&#35768;&#22810;&#24320;&#25918;&#38382;&#39064;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#22810;&#31181;&#35774;&#32622;&#19979;&#30340;&#36924;&#36817;&#22240;&#23376;&#65292;&#20363;&#22914;&#21152;&#26435;$L_2$&#33539;&#25968;&#65288;&#20854;&#20013;&#21152;&#26435;&#26159;&#31163;&#32447;&#29366;&#24577;&#20998;&#24067;&#65289;&#65292;$L_\infty$&#33539;&#25968;&#65292;&#29366;&#24577;&#21035;&#21517;&#30340;&#23384;&#22312;&#19982;&#21542;&#20197;&#21450;&#23545;&#29366;&#24577;&#31354;&#38388;&#30340;&#20840;&#38754;&#19982;&#37096;&#20998;&#35206;&#30422;&#12290;&#23545;&#20110;&#25152;&#26377;&#36825;&#20123;&#35774;&#32622;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#26368;&#20248;&#30340;&#28176;&#36817;&#36924;&#36817;&#22240;&#23376;&#65288;&#33267;&#22810;&#24120;&#25968;&#65289;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#30340;&#30028;&#38480;&#30830;&#23450;&#20102;$L_2(\mu)$&#33539;&#25968;&#30340;&#20004;&#20010;&#20381;&#36182;&#20110;&#23454;&#20363;&#30340;&#22240;&#23376;&#21644;$L_\infty$&#33539;&#25968;&#30340;&#19968;&#20010;&#22240;&#23376;&#65292;&#23427;&#20204;&#34987;&#35777;&#26126;&#20915;&#23450;&#20102;&#31163;&#31574;&#30053;&#35780;&#20272;&#30340;&#22256;&#38590;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Theoretical guarantees in reinforcement learning (RL) are known to suffer multiplicative blow-up factors with respect to the misspecification error of function approximation. Yet, the nature of such \emph{approximation factors} -especially their optimal form in a given learning problem -- is poorly understood. In this paper we study this question in linear off-policy value function estimation, where many open questions remain. We study the approximation factor in a broad spectrum of settings, such as with the weighted $L_2$-norm (where the weighting is the offline state distribution), the $L_\infty$ norm, the presence vs. absence of state aliasing, and full vs. partial coverage of the state space. We establish the optimal asymptotic approximation factors (up to constants) for all of these settings. In particular, our bounds identify two instance-dependent factors for the $L_2(\mu)$ norm and only one for the $L_\infty$ norm, which are shown to dictate the hardness of off-policy evalua
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#20989;&#25968;&#31354;&#38388;&#20013;&#20462;&#25913;&#35757;&#32451;&#26041;&#21521;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#31070;&#32463;&#32593;&#32476;&#20989;&#25968;&#31354;&#38388;&#20013;&#36827;&#34892;&#29305;&#24449;&#20998;&#35299;&#21644;&#32479;&#35745;&#29702;&#35770;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#38477;&#20302;&#24635;&#30340;&#27867;&#21270;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2307.13290</link><description>&lt;p&gt;
&#22312;&#20989;&#25968;&#31354;&#38388;&#20013;&#20462;&#25913;&#35757;&#32451;&#26041;&#21521;&#20197;&#38477;&#20302;&#27867;&#21270;&#35823;&#24046;
&lt;/p&gt;
&lt;p&gt;
Modify Training Directions in Function Space to Reduce Generalization Error. (arXiv:2307.13290v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13290
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#20989;&#25968;&#31354;&#38388;&#20013;&#20462;&#25913;&#35757;&#32451;&#26041;&#21521;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#31070;&#32463;&#32593;&#32476;&#20989;&#25968;&#31354;&#38388;&#20013;&#36827;&#34892;&#29305;&#24449;&#20998;&#35299;&#21644;&#32479;&#35745;&#29702;&#35770;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#38477;&#20302;&#24635;&#30340;&#27867;&#21270;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#22312;&#31070;&#32463;&#32593;&#32476;&#20989;&#25968;&#31354;&#38388;&#20013;&#22522;&#20110;&#31070;&#32463;&#20999;&#25442;&#26680;&#21644;Fisher&#20449;&#24687;&#30697;&#38453;&#30340;&#29305;&#24449;&#20998;&#35299;&#30340;&#20462;&#25913;&#33258;&#28982;&#26799;&#24230;&#19979;&#38477;&#27861;&#30340;&#29702;&#35770;&#20998;&#26512;&#12290;&#25105;&#20204;&#39318;&#20808;&#32473;&#20986;&#20102;&#22312;&#39640;&#26031;&#20998;&#24067;&#21644;&#26080;&#38480;&#23485;&#24230;&#26497;&#38480;&#30340;&#20551;&#35774;&#19979;&#65292;&#36890;&#36807;&#29702;&#35770;&#26041;&#27861;&#20174;&#29305;&#24449;&#20998;&#35299;&#21644;&#32479;&#35745;&#29702;&#35770;&#20013;&#26174;&#24335;&#25512;&#23548;&#20986;&#35813;&#20462;&#25913;&#33258;&#28982;&#26799;&#24230;&#25152;&#23398;&#20064;&#30340;&#20989;&#25968;&#30340;&#34920;&#36798;&#24335;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#36890;&#36807;&#23558;&#24635;&#30340;&#27867;&#21270;&#35823;&#24046;&#20998;&#35299;&#20026;&#20989;&#25968;&#31354;&#38388;&#20013;&#19981;&#21516;&#29305;&#24449;&#31354;&#38388;&#30340;&#35823;&#24046;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#24179;&#34913;&#35757;&#32451;&#38598;&#35823;&#24046;&#21644;&#35757;&#32451;&#38598;&#19982;&#30495;&#23454;&#25968;&#25454;&#20043;&#38388;&#20998;&#24067;&#24046;&#24322;&#30340;&#20934;&#21017;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#27861;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#22312;&#20989;&#25968;&#31354;&#38388;&#20013;&#20462;&#25913;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#26041;&#21521;&#20250;&#23548;&#33268;&#24635;&#30340;&#27867;&#21270;&#35823;&#24046;&#30340;&#20943;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose theoretical analyses of a modified natural gradient descent method in the neural network function space based on the eigendecompositions of neural tangent kernel and Fisher information matrix. We firstly present analytical expression for the function learned by this modified natural gradient under the assumptions of Gaussian distribution and infinite width limit. Thus, we explicitly derive the generalization error of the learned neural network function using theoretical methods from eigendecomposition and statistics theory. By decomposing of the total generalization error attributed to different eigenspace of the kernel in function space, we propose a criterion for balancing the errors stemming from training set and the distribution discrepancy between the training set and the true data. Through this approach, we establish that modifying the training direction of the neural network in function space leads to a reduction in the total generalization error. Furthermore, We demo
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#23558;&#36335;&#24452;&#30456;&#20851;&#30340;NJ-ODE&#26041;&#27861;&#25193;&#23637;&#21040;&#20855;&#26377;&#22122;&#22768;&#35266;&#27979;&#21644;&#30456;&#20851;&#35266;&#27979;&#26694;&#26550;&#30340;&#38382;&#39064;&#12290;&#30740;&#31350;&#25552;&#20986;&#20102;&#20004;&#31181;&#25193;&#23637;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#21644;&#23454;&#35777;&#31034;&#20363;&#12290;</title><link>http://arxiv.org/abs/2307.13147</link><description>&lt;p&gt;
&#23558;&#36335;&#24452;&#30456;&#20851;&#30340;NJ-ODE&#25193;&#23637;&#21040;&#26377;&#22122;&#22768;&#30340;&#35266;&#27979;&#21644;&#30456;&#20851;&#35266;&#27979;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Extending Path-Dependent NJ-ODEs to Noisy Observations and a Dependent Observation Framework. (arXiv:2307.13147v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13147
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#23558;&#36335;&#24452;&#30456;&#20851;&#30340;NJ-ODE&#26041;&#27861;&#25193;&#23637;&#21040;&#20855;&#26377;&#22122;&#22768;&#35266;&#27979;&#21644;&#30456;&#20851;&#35266;&#27979;&#26694;&#26550;&#30340;&#38382;&#39064;&#12290;&#30740;&#31350;&#25552;&#20986;&#20102;&#20004;&#31181;&#25193;&#23637;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#21644;&#23454;&#35777;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36335;&#24452;&#30456;&#20851;&#30340;&#31070;&#32463;&#36339;&#36291;ODE (PD-NJ-ODE) &#26159;&#19968;&#31181;&#29992;&#20110;&#39044;&#27979;&#20855;&#26377;&#19981;&#35268;&#21017;&#21644;&#19981;&#23436;&#25972;&#35266;&#27979;&#30340;&#36830;&#32493;&#26102;&#38388;&#38543;&#26426;&#36807;&#31243;&#30340;&#27169;&#22411;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#23398;&#20064;&#32473;&#23450;&#19981;&#35268;&#21017;&#37319;&#26679;&#30340;&#19981;&#23436;&#25972;&#36807;&#21435;&#35266;&#27979;&#30340;&#26368;&#20248;&#39044;&#27979;&#12290;&#36804;&#20170;&#20026;&#27490;&#65292;&#20551;&#35774;&#36807;&#31243;&#26412;&#36523;&#21644;&#22352;&#26631;&#20998;&#21035;&#35266;&#27979;&#26102;&#38388;&#26159;&#29420;&#31435;&#30340;&#65292;&#24182;&#19988;&#20551;&#35774;&#35266;&#27979;&#26159;&#26080;&#22122;&#22768;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#20004;&#31181;&#25193;&#23637;&#26469;&#35299;&#38500;&#36825;&#20123;&#38480;&#21046;&#65292;&#24182;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#20197;&#21450;&#23427;&#20204;&#30340;&#23454;&#35777;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Path-Dependent Neural Jump ODE (PD-NJ-ODE) is a model for predicting continuous-time stochastic processes with irregular and incomplete observations. In particular, the method learns optimal forecasts given irregularly sampled time series of incomplete past observations. So far the process itself and the coordinate-wise observation times were assumed to be independent and observations were assumed to be noiseless. In this work we discuss two extensions to lift these restrictions and provide theoretical guarantees as well as empirical examples for them.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#21152;&#26435;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#20351;&#29992;&#25935;&#24863;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#20445;&#25252;&#38544;&#31169;&#12290;&#36825;&#26159;&#31532;&#19968;&#20010;&#22312;&#26435;&#37325;ERM&#20013;&#24212;&#29992;&#24046;&#20998;&#38544;&#31169;&#30340;&#31639;&#27861;&#65292;&#24182;&#19988;&#22312;&#19968;&#23450;&#30340;&#26465;&#20214;&#19979;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;DP&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2307.13127</link><description>&lt;p&gt;
&#19968;&#20010;&#24046;&#20998;&#38544;&#31169;&#21152;&#26435;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#31639;&#27861;&#21450;&#20854;&#22312;&#32467;&#26524;&#21152;&#26435;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
A Differentially Private Weighted Empirical Risk Minimization Procedure and its Application to Outcome Weighted Learning. (arXiv:2307.13127v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13127
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#21152;&#26435;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#20351;&#29992;&#25935;&#24863;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#20445;&#25252;&#38544;&#31169;&#12290;&#36825;&#26159;&#31532;&#19968;&#20010;&#22312;&#26435;&#37325;ERM&#20013;&#24212;&#29992;&#24046;&#20998;&#38544;&#31169;&#30340;&#31639;&#27861;&#65292;&#24182;&#19988;&#22312;&#19968;&#23450;&#30340;&#26465;&#20214;&#19979;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;DP&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;(ERM)&#26694;&#26550;&#20013;&#65292;&#20351;&#29992;&#21253;&#21547;&#20010;&#20154;&#20449;&#24687;&#30340;&#25968;&#25454;&#26469;&#26500;&#24314;&#39044;&#27979;&#27169;&#22411;&#26159;&#24120;&#35265;&#30340;&#20570;&#27861;&#12290;&#23613;&#31649;&#36825;&#20123;&#27169;&#22411;&#22312;&#39044;&#27979;&#19978;&#21487;&#20197;&#38750;&#24120;&#20934;&#30830;&#65292;&#20294;&#20351;&#29992;&#25935;&#24863;&#25968;&#25454;&#24471;&#21040;&#30340;&#32467;&#26524;&#21487;&#33021;&#23481;&#26131;&#21463;&#21040;&#38544;&#31169;&#25915;&#20987;&#12290;&#24046;&#20998;&#38544;&#31169;(DP)&#26159;&#19968;&#31181;&#26377;&#21560;&#24341;&#21147;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#36890;&#36807;&#25552;&#20379;&#25968;&#23398;&#19978;&#21487;&#35777;&#26126;&#30340;&#38544;&#31169;&#25439;&#22833;&#30028;&#38480;&#26469;&#35299;&#20915;&#36825;&#20123;&#25968;&#25454;&#38544;&#31169;&#38382;&#39064;&#12290;&#20808;&#21069;&#30340;&#24037;&#20316;&#20027;&#35201;&#38598;&#20013;&#22312;&#23558;DP&#24212;&#29992;&#20110;&#26080;&#26435;&#37325;&#30340;ERM&#20013;&#12290;&#25105;&#20204;&#32771;&#34385;&#21040;&#20102;&#26435;&#37325;ERM(wERM)&#30340;&#37325;&#35201;&#25512;&#24191;&#12290;&#22312;wERM&#20013;&#65292;&#21487;&#20197;&#20026;&#27599;&#20010;&#20010;&#20307;&#30340;&#30446;&#26631;&#20989;&#25968;&#36129;&#29486;&#20998;&#37197;&#19981;&#21516;&#30340;&#26435;&#37325;&#12290;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#26377;&#24046;&#20998;&#38544;&#31169;&#20445;&#38556;&#30340;wERM&#31639;&#27861;&#65292;&#24182;&#22312;&#19968;&#23450;&#30340;&#27491;&#21017;&#26465;&#20214;&#19979;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#29702;&#35770;&#35777;&#26126;&#12290;&#23558;&#29616;&#26377;&#30340;DP-ERM&#31243;&#24207;&#25193;&#23637;&#21040;wERM&#20026;&#32467;&#26524;&#21152;&#26435;&#23398;&#20064;&#38138;&#24179;&#20102;&#36947;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is commonplace to use data containing personal information to build predictive models in the framework of empirical risk minimization (ERM). While these models can be highly accurate in prediction, results obtained from these models with the use of sensitive data may be susceptible to privacy attacks. Differential privacy (DP) is an appealing framework for addressing such data privacy issues by providing mathematically provable bounds on the privacy loss incurred when releasing information from sensitive data. Previous work has primarily concentrated on applying DP to unweighted ERM. We consider an important generalization to weighted ERM (wERM). In wERM, each individual's contribution to the objective function can be assigned varying weights. In this context, we propose the first differentially private wERM algorithm, backed by a rigorous theoretical proof of its DP guarantees under mild regularity conditions. Extending the existing DP-ERM procedures to wERM paves a path to derivin
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38750;&#21442;&#25968;&#30340;&#27169;&#22411;&#26080;&#20851;&#26694;&#26550;&#65292;&#29992;&#20110;&#24314;&#31435;&#20445;&#38505;&#29702;&#36180;&#30340;&#39044;&#27979;&#21306;&#38388;&#65292;&#24182;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#30340;&#32479;&#35745;&#20445;&#35777;&#65292;&#25193;&#23637;&#20102;split conformal prediction&#25216;&#26415;&#21040;&#20004;&#38454;&#27573;&#39057;&#29575;-&#20005;&#37325;&#24615;&#24314;&#27169;&#39046;&#22495;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#38543;&#26426;&#26862;&#26519;&#20316;&#20026;&#20005;&#37325;&#24615;&#27169;&#22411;&#65292;&#21033;&#29992;&#20102;&#34955;&#22806;&#26426;&#21046;&#28040;&#38500;&#20102;&#26657;&#20934;&#38598;&#30340;&#38656;&#35201;&#65292;&#24182;&#23454;&#29616;&#20102;&#20855;&#26377;&#33258;&#36866;&#24212;&#23485;&#24230;&#30340;&#39044;&#27979;&#21306;&#38388;&#30340;&#29983;&#25104;&#12290;</title><link>http://arxiv.org/abs/2307.13124</link><description>&lt;p&gt;
&#39057;&#29575;-&#20005;&#37325;&#24615;&#24314;&#27169;&#30340;&#31526;&#21512;&#24615;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Conformal prediction for frequency-severity modeling. (arXiv:2307.13124v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13124
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38750;&#21442;&#25968;&#30340;&#27169;&#22411;&#26080;&#20851;&#26694;&#26550;&#65292;&#29992;&#20110;&#24314;&#31435;&#20445;&#38505;&#29702;&#36180;&#30340;&#39044;&#27979;&#21306;&#38388;&#65292;&#24182;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#30340;&#32479;&#35745;&#20445;&#35777;&#65292;&#25193;&#23637;&#20102;split conformal prediction&#25216;&#26415;&#21040;&#20004;&#38454;&#27573;&#39057;&#29575;-&#20005;&#37325;&#24615;&#24314;&#27169;&#39046;&#22495;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#38543;&#26426;&#26862;&#26519;&#20316;&#20026;&#20005;&#37325;&#24615;&#27169;&#22411;&#65292;&#21033;&#29992;&#20102;&#34955;&#22806;&#26426;&#21046;&#28040;&#38500;&#20102;&#26657;&#20934;&#38598;&#30340;&#38656;&#35201;&#65292;&#24182;&#23454;&#29616;&#20102;&#20855;&#26377;&#33258;&#36866;&#24212;&#23485;&#24230;&#30340;&#39044;&#27979;&#21306;&#38388;&#30340;&#29983;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#38750;&#21442;&#25968;&#30340;&#27169;&#22411;&#26080;&#20851;&#26694;&#26550;&#65292;&#29992;&#20110;&#24314;&#31435;&#20445;&#38505;&#29702;&#36180;&#30340;&#39044;&#27979;&#21306;&#38388;&#65292;&#24182;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#30340;&#32479;&#35745;&#20445;&#35777;&#65292;&#23558;&#20998;&#21106;&#31526;&#21512;&#24615;&#39044;&#27979;&#25216;&#26415;&#25193;&#23637;&#21040;&#20004;&#38454;&#27573;&#39057;&#29575;-&#20005;&#37325;&#24615;&#24314;&#27169;&#39046;&#22495;&#12290;&#36890;&#36807;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#23637;&#31034;&#20102;&#35813;&#26694;&#26550;&#30340;&#26377;&#25928;&#24615;&#12290;&#24403;&#22522;&#30784;&#20005;&#37325;&#24615;&#27169;&#22411;&#26159;&#38543;&#26426;&#26862;&#26519;&#26102;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;&#20004;&#38454;&#27573;&#20998;&#21106;&#31526;&#21512;&#24615;&#39044;&#27979;&#36807;&#31243;&#65292;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#34955;&#22806;&#26426;&#21046;&#28040;&#38500;&#26657;&#20934;&#38598;&#30340;&#38656;&#35201;&#65292;&#24182;&#23454;&#29616;&#20855;&#26377;&#33258;&#36866;&#24212;&#23485;&#24230;&#30340;&#39044;&#27979;&#21306;&#38388;&#30340;&#29983;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a nonparametric model-agnostic framework for building prediction intervals of insurance claims, with finite sample statistical guarantees, extending the technique of split conformal prediction to the domain of two-stage frequency-severity modeling. The effectiveness of the framework is showcased with simulated and real datasets. When the underlying severity model is a random forest, we extend the two-stage split conformal prediction procedure, showing how the out-of-bag mechanism can be leveraged to eliminate the need for a calibration set and to enable the production of prediction intervals with adaptive width.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#26641;&#29366;&#25968;&#25454;&#30340;&#26032;&#22411;&#27169;&#24335;&#8212;&#8212;&#20855;&#26377;&#30456;&#21516;&#26631;&#31614;&#20998;&#24067;&#30340;&#24120;&#35265;&#23376;&#26641;&#30340;&#26816;&#27979;&#26041;&#27861;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#22797;&#26434;&#30340;&#25628;&#32034;&#31639;&#27861;&#26469;&#35299;&#20915;&#21516;&#26500;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26641;&#24418;&#26080;&#25439;&#21387;&#32553;&#26041;&#26696;&#36827;&#34892;&#27169;&#24335;&#26522;&#20030;&#65292;&#20174;&#29702;&#35770;&#21644;&#23454;&#36341;&#26041;&#38754;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2307.13068</link><description>&lt;p&gt;
&#26816;&#27979;&#20855;&#26377;&#30456;&#21516;&#26631;&#31614;&#20998;&#24067;&#30340;&#24120;&#35265;&#23376;&#26641;
&lt;/p&gt;
&lt;p&gt;
Detection of Common Subtrees with Identical Label Distribution. (arXiv:2307.13068v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13068
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#26641;&#29366;&#25968;&#25454;&#30340;&#26032;&#22411;&#27169;&#24335;&#8212;&#8212;&#20855;&#26377;&#30456;&#21516;&#26631;&#31614;&#20998;&#24067;&#30340;&#24120;&#35265;&#23376;&#26641;&#30340;&#26816;&#27979;&#26041;&#27861;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#22797;&#26434;&#30340;&#25628;&#32034;&#31639;&#27861;&#26469;&#35299;&#20915;&#21516;&#26500;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26641;&#24418;&#26080;&#25439;&#21387;&#32553;&#26041;&#26696;&#36827;&#34892;&#27169;&#24335;&#26522;&#20030;&#65292;&#20174;&#29702;&#35770;&#21644;&#23454;&#36341;&#26041;&#38754;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39057;&#32321;&#27169;&#24335;&#25366;&#25496;&#26159;&#19968;&#31181;&#20998;&#26512;&#32467;&#26500;&#21270;&#25968;&#25454;&#30340;&#30456;&#20851;&#26041;&#27861;&#65292;&#22914;&#24207;&#21015;&#65292;&#26641;&#25110;&#22270;&#12290;&#23427;&#30340;&#30446;&#30340;&#26159;&#35782;&#21035;&#25968;&#25454;&#38598;&#30340;&#29305;&#24449;&#23376;&#32467;&#26500;&#12290;&#26412;&#25991;&#38024;&#23545;&#26641;&#29366;&#25968;&#25454;&#30340;&#19968;&#31181;&#26032;&#31867;&#22411;&#30340;&#27169;&#24335;&#36827;&#34892;&#20102;&#25506;&#35752;&#65306;&#20855;&#26377;&#30456;&#21516;&#26631;&#31614;&#20998;&#24067;&#30340;&#24120;&#35265;&#23376;&#26641;&#12290;&#30001;&#20110;&#22522;&#30784;&#21516;&#26500;&#38382;&#39064;&#26159;&#22270;&#21516;&#26500;&#23436;&#20840;&#38382;&#39064;&#65292;&#22240;&#27492;&#20854;&#26816;&#27979;&#36828;&#38750;&#26126;&#26174;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#31934;&#24515;&#35774;&#35745;&#30340;&#25628;&#32034;&#31639;&#27861;&#65292;&#24182;&#20174;&#29702;&#35770;&#21644;&#25968;&#20540;&#35282;&#24230;&#36827;&#34892;&#20102;&#20998;&#26512;&#12290;&#22522;&#20110;&#27492;&#65292;&#36890;&#36807;&#19968;&#31181;&#21517;&#20026;DAG-RW&#30340;&#26032;&#30340;&#26641;&#24418;&#26080;&#25439;&#21387;&#32553;&#26041;&#26696;&#26469;&#25191;&#34892;&#27169;&#24335;&#30340;&#26522;&#20030;&#65292;&#20854;&#22797;&#26434;&#24615;&#20063;&#24471;&#21040;&#20102;&#30740;&#31350;&#12290;&#35813;&#26041;&#27861;&#22312;&#35745;&#31639;&#26102;&#38388;&#21644;&#23545;&#25991;&#29486;&#20013;&#30340;&#23454;&#38469;&#25968;&#25454;&#38598;&#30340;&#20998;&#26512;&#26041;&#38754;&#37117;&#34920;&#29616;&#20986;&#38750;&#24120;&#22909;&#30340;&#24615;&#33021;&#12290;&#19982;&#20854;&#20182;&#23376;&#32467;&#26500;&#65288;&#22914;&#25299;&#25169;&#23376;&#26641;&#21644;&#26631;&#35760;&#23376;&#26641;&#65289;&#30456;&#27604;&#65292;&#20854;&#21516;&#26500;&#38382;&#39064;&#26159;&#32447;&#24615;&#30340;&#65292;&#25152;&#21457;&#29616;&#30340;&#27169;&#24335;&#25552;&#20379;&#20102;&#25968;&#25454;&#30340;&#26356;&#33410;&#32422;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Frequent pattern mining is a relevant method to analyse structured data, like sequences, trees or graphs. It consists in identifying characteristic substructures of a dataset. This paper deals with a new type of patterns for tree data: common subtrees with identical label distribution. Their detection is far from obvious since the underlying isomorphism problem is graph isomorphism complete. An elaborated search algorithm is developed and analysed from both theoretical and numerical perspectives. Based on this, the enumeration of patterns is performed through a new lossless compression scheme for trees, called DAG-RW, whose complexity is investigated as well. The method shows very good properties, both in terms of computation times and analysis of real datasets from the literature. Compared to other substructures like topological subtrees and labelled subtrees for which the isomorphism problem is linear, the patterns found provide a more parsimonious representation of the data.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20351;&#29992;&#24352;&#37327;&#20998;&#35299;&#21644;&#33298;&#23572;&#22810;&#39033;&#24335;&#29702;&#35770;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#26631;&#20934;&#39640;&#26031;&#20998;&#24067;&#19979;&#23398;&#20064;$k$&#20010;ReLU&#28608;&#27963;&#30340;&#32447;&#24615;&#32452;&#21512;&#12290;&#36825;&#20010;&#31639;&#27861;&#22312;&#26679;&#26412;&#21644;&#35745;&#31639;&#22797;&#26434;&#24615;&#19978;&#25509;&#36817;&#26368;&#20248;&#65292;&#24182;&#33021;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#25214;&#21040;&#36739;&#23567;&#30340;&#39640;&#38454;&#30697;&#35823;&#24046;&#24352;&#37327;&#12290;</title><link>http://arxiv.org/abs/2307.12840</link><description>&lt;p&gt;
&#36890;&#36807;&#33298;&#23572;&#22810;&#39033;&#24335;&#39640;&#25928;&#23398;&#20064;&#20855;&#26377;&#19968;&#20010;&#38544;&#34255;&#23618;&#30340;ReLU&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Efficiently Learning One-Hidden-Layer ReLU Networks via Schur Polynomials. (arXiv:2307.12840v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12840
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;&#24352;&#37327;&#20998;&#35299;&#21644;&#33298;&#23572;&#22810;&#39033;&#24335;&#29702;&#35770;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#26631;&#20934;&#39640;&#26031;&#20998;&#24067;&#19979;&#23398;&#20064;$k$&#20010;ReLU&#28608;&#27963;&#30340;&#32447;&#24615;&#32452;&#21512;&#12290;&#36825;&#20010;&#31639;&#27861;&#22312;&#26679;&#26412;&#21644;&#35745;&#31639;&#22797;&#26434;&#24615;&#19978;&#25509;&#36817;&#26368;&#20248;&#65292;&#24182;&#33021;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#25214;&#21040;&#36739;&#23567;&#30340;&#39640;&#38454;&#30697;&#35823;&#24046;&#24352;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#26631;&#20934;&#39640;&#26031;&#20998;&#24067;&#19979;&#65292;&#20851;&#20110;&#24179;&#26041;&#25439;&#22833;&#30340;PAC&#23398;&#20064;$k$&#20010;ReLU&#28608;&#27963;&#30340;&#32447;&#24615;&#32452;&#21512;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;&#38024;&#23545;&#36825;&#20010;&#23398;&#20064;&#20219;&#21153;&#30340;&#19968;&#31181;&#39640;&#25928;&#31639;&#27861;&#65292;&#20854;&#26679;&#26412;&#21644;&#35745;&#31639;&#22797;&#26434;&#24615;&#20026;$(dk/\epsilon)^{O(k)}$&#65292;&#20854;&#20013;$\epsilon&gt;0$&#26159;&#30446;&#26631;&#31934;&#24230;&#12290;&#20043;&#21069;&#30340;&#24037;&#20316;&#32473;&#20986;&#20102;&#19968;&#20010;&#22797;&#26434;&#24615;&#20026;$(dk/\epsilon)^{h(k)}$&#30340;&#31639;&#27861;&#65292;&#20854;&#20013;&#20989;&#25968;$h(k)$&#22312;$k$&#19978;&#30340;&#35268;&#27169;&#26159;&#36229;&#22810;&#39033;&#24335;&#30340;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#30456;&#20851;&#32479;&#35745;&#26597;&#35810;&#31639;&#27861;&#31867;&#20013;&#25509;&#36817;&#26368;&#20248;&#12290;&#24635;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#20351;&#29992;&#24352;&#37327;&#20998;&#35299;&#26469;&#35782;&#21035;&#19968;&#20010;&#23376;&#31354;&#38388;&#65292;&#20351;&#24471;&#25152;&#26377;$O(k)$&#38454;&#30697;&#22312;&#27491;&#20132;&#26041;&#21521;&#19978;&#37117;&#24456;&#23567;&#12290;&#20854;&#20998;&#26512;&#22522;&#20110;&#33298;&#23572;&#22810;&#39033;&#24335;&#29702;&#35770;&#65292;&#20197;&#26174;&#31034;&#36739;&#20302;&#38454;&#35823;&#24046;&#24352;&#37327;&#30340;&#24773;&#20917;&#19979;&#65292;&#26356;&#39640;&#38454;&#30340;&#35823;&#24046;&#24352;&#37327;&#20063;&#24456;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of PAC learning a linear combination of $k$ ReLU activations under the standard Gaussian distribution on $\mathbb{R}^d$ with respect to the square loss. Our main result is an efficient algorithm for this learning task with sample and computational complexity $(dk/\epsilon)^{O(k)}$, where $\epsilon&gt;0$ is the target accuracy. Prior work had given an algorithm for this problem with complexity $(dk/\epsilon)^{h(k)}$, where the function $h(k)$ scales super-polynomially in $k$. Interestingly, the complexity of our algorithm is near-optimal within the class of Correlational Statistical Query algorithms. At a high-level, our algorithm uses tensor decomposition to identify a subspace such that all the $O(k)$-order moments are small in the orthogonal directions. Its analysis makes essential use of the theory of Schur polynomials to show that the higher-moment error tensors are small given that the lower-order ones are.
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#28508;&#22312;&#25928;&#29992;Q&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#23558;&#24739;&#32773;&#20559;&#22909;&#32435;&#20837;&#22797;&#21512;&#32467;&#26524;&#30340;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;&#20013;&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;&#26041;&#27861;&#23545;&#26102;&#38388;&#28857;&#21644;&#32467;&#26524;&#25968;&#37327;&#30340;&#38480;&#21046;&#65292;&#33021;&#22815;&#23454;&#29616;&#24378;&#22823;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.12022</link><description>&lt;p&gt;
&#23558;&#24739;&#32773;&#20559;&#22909;&#32435;&#20837;Q&#23398;&#20064;&#30340;&#28789;&#27963;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Flexible Framework for Incorporating Patient Preferences Into Q-Learning. (arXiv:2307.12022v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12022
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#28508;&#22312;&#25928;&#29992;Q&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#23558;&#24739;&#32773;&#20559;&#22909;&#32435;&#20837;&#22797;&#21512;&#32467;&#26524;&#30340;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;&#20013;&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;&#26041;&#27861;&#23545;&#26102;&#38388;&#28857;&#21644;&#32467;&#26524;&#25968;&#37327;&#30340;&#38480;&#21046;&#65292;&#33021;&#22815;&#23454;&#29616;&#24378;&#22823;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#21307;&#30103;&#38382;&#39064;&#20013;&#65292;&#36890;&#24120;&#23384;&#22312;&#22810;&#20010;&#31454;&#20105;&#24615;&#30340;&#20851;&#27880;&#28857;&#65292;&#22914;&#27835;&#30103;&#30103;&#25928;&#21644;&#21103;&#20316;&#29992;&#20005;&#37325;&#31243;&#24230;&#12290;&#28982;&#32780;&#65292;&#29992;&#20110;&#20272;&#35745;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696; (DTRs) &#30340;&#32479;&#35745;&#26041;&#27861;&#36890;&#24120;&#20551;&#35774;&#21482;&#26377;&#19968;&#20010;&#20851;&#27880;&#28857;&#65292;&#32780;&#22788;&#29702;&#22797;&#21512;&#32467;&#26524;&#30340;&#26041;&#27861;&#24456;&#23569;&#65292;&#23384;&#22312;&#37325;&#35201;&#38480;&#21046;&#65292;&#21253;&#25324;&#23545;&#21333;&#20010;&#26102;&#38388;&#28857;&#21644;&#20004;&#20010;&#32467;&#26524;&#30340;&#38480;&#21046;&#12289;&#26080;&#27861;&#32435;&#20837;&#24739;&#32773;&#30340;&#33258;&#36848;&#20559;&#22909;&#20197;&#21450;&#26377;&#38480;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#28508;&#22312;&#25928;&#29992;Q&#23398;&#20064;(LUQ-Learning)&#12290;LUQ-Learning&#37319;&#29992;&#28508;&#22312;&#27169;&#22411;&#26041;&#27861;&#65292;&#33258;&#28982;&#22320;&#23558;Q&#23398;&#20064;&#25193;&#23637;&#21040;&#22797;&#21512;&#32467;&#26524;&#35774;&#32622;&#65292;&#24182;&#20026;&#27599;&#20010;&#24739;&#32773;&#36873;&#25321;&#29702;&#24819;&#30340;&#32467;&#26524;&#26435;&#34913;&#12290;&#19982;&#20043;&#21069;&#30340;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#20801;&#35768;&#20219;&#24847;&#25968;&#37327;&#30340;&#26102;&#38388;&#28857;&#21644;&#32467;&#26524;&#65292;&#32435;&#20837;&#38472;&#36848;&#30340;&#20559;&#22909;&#65292;&#24182;&#23454;&#29616;&#24378;&#22823;&#30340;&#28176;&#36817;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In real-world healthcare problems, there are often multiple competing outcomes of interest, such as treatment efficacy and side effect severity. However, statistical methods for estimating dynamic treatment regimes (DTRs) usually assume a single outcome of interest, and the few methods that deal with composite outcomes suffer from important limitations. This includes restrictions to a single time point and two outcomes, the inability to incorporate self-reported patient preferences and limited theoretical guarantees. To this end, we propose a new method to address these limitations, which we dub Latent Utility Q-Learning (LUQ-Learning). LUQ-Learning uses a latent model approach to naturally extend Q-learning to the composite outcome setting and adopt the ideal trade-off between outcomes to each patient. Unlike previous approaches, our framework allows for an arbitrary number of time points and outcomes, incorporates stated preferences and achieves strong asymptotic performance with rea
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65292;&#31526;&#21512;Feldman&#30340;&#38271;&#23614;&#29702;&#35770;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#38271;&#23614;&#20998;&#24067;&#24773;&#20917;&#19979;&#65292;&#38750;&#32447;&#24615;&#20998;&#31867;&#22120;&#21487;&#20197;&#25552;&#39640;&#27867;&#21270;&#33021;&#21147;&#65292;&#32780;&#32447;&#24615;&#20998;&#31867;&#22120;&#19981;&#33021;&#12290;&#35813;&#32467;&#26524;&#24378;&#35843;&#20102;&#23545;&#20110;&#38271;&#23614;&#20998;&#24067;&#65292;&#38656;&#35201;&#32771;&#34385;&#32597;&#35265;&#30340;&#35757;&#32451;&#26679;&#26412;&#20197;&#23454;&#29616;&#26368;&#20339;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2307.10736</link><description>&lt;p&gt;
&#39640;&#26031;&#28151;&#21512;&#19979;&#30340;&#38271;&#23614;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Long-Tail Theory under Gaussian Mixtures. (arXiv:2307.10736v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10736
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65292;&#31526;&#21512;Feldman&#30340;&#38271;&#23614;&#29702;&#35770;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#38271;&#23614;&#20998;&#24067;&#24773;&#20917;&#19979;&#65292;&#38750;&#32447;&#24615;&#20998;&#31867;&#22120;&#21487;&#20197;&#25552;&#39640;&#27867;&#21270;&#33021;&#21147;&#65292;&#32780;&#32447;&#24615;&#20998;&#31867;&#22120;&#19981;&#33021;&#12290;&#35813;&#32467;&#26524;&#24378;&#35843;&#20102;&#23545;&#20110;&#38271;&#23614;&#20998;&#24067;&#65292;&#38656;&#35201;&#32771;&#34385;&#32597;&#35265;&#30340;&#35757;&#32451;&#26679;&#26412;&#20197;&#23454;&#29616;&#26368;&#20339;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#26469;&#29983;&#25104;&#36981;&#24490;Feldman&#30340;&#38271;&#23614;&#29702;&#35770;&#65288;2020&#65289;&#30340;&#25968;&#25454;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#25552;&#20986;&#30340;&#27169;&#22411;&#20013;&#65292;&#32447;&#24615;&#20998;&#31867;&#22120;&#26080;&#27861;&#23558;&#27867;&#21270;&#35823;&#24046;&#38477;&#20302;&#21040;&#19968;&#23450;&#27700;&#24179;&#20197;&#19979;&#65292;&#32780;&#20855;&#26377;&#35760;&#24518;&#33021;&#21147;&#30340;&#38750;&#32447;&#24615;&#20998;&#31867;&#22120;&#21487;&#20197;&#12290;&#36825;&#35777;&#23454;&#20102;&#23545;&#20110;&#38271;&#23614;&#20998;&#24067;&#65292;&#24517;&#39035;&#32771;&#34385;&#32597;&#35265;&#30340;&#35757;&#32451;&#26679;&#26412;&#20197;&#23454;&#29616;&#23545;&#26032;&#25968;&#25454;&#30340;&#26368;&#20339;&#27867;&#21270;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#24403;&#23376;&#32676;&#20307;&#39057;&#29575;&#20998;&#24067;&#30340;&#23614;&#37096;&#21464;&#30701;&#26102;&#65292;&#32447;&#24615;&#27169;&#22411;&#21644;&#38750;&#32447;&#24615;&#27169;&#22411;&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#36317;&#21487;&#20197;&#20943;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;
We suggest a simple Gaussian mixture model for data generation that complies with Feldman's long tail theory (2020). We demonstrate that a linear classifier cannot decrease the generalization error below a certain level in the proposed model, whereas a nonlinear classifier with a memorization capacity can. This confirms that for long-tailed distributions, rare training examples must be considered for optimal generalization to new data. Finally, we show that the performance gap between linear and nonlinear models can be lessened as the tail becomes shorter in the subpopulation frequency distribution, as confirmed by experiments on synthetic and real data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#25552;&#21319;&#29616;&#26377;&#30340;&#19979;&#30028;&#26469;&#21305;&#37197;&#26368;&#20339;&#19978;&#30028;&#65292;&#23545;&#21305;&#37197;&#36861;&#36394;&#30340;&#24615;&#33021;&#36827;&#34892;&#20102;&#31934;&#30830;&#25551;&#36848;&#65292;&#24182;&#26500;&#36896;&#20102;&#19968;&#20010;&#26368;&#22351;&#24773;&#20917;&#30340;&#23383;&#20856;&#26469;&#35777;&#26126;&#29616;&#26377;&#19978;&#30028;&#30340;&#26080;&#27861;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2307.07679</link><description>&lt;p&gt;
&#21305;&#37197;&#36861;&#36394;&#30340;&#24555;&#36895;&#25910;&#25947;&#36895;&#24230;
&lt;/p&gt;
&lt;p&gt;
Sharp Convergence Rates for Matching Pursuit. (arXiv:2307.07679v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07679
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25552;&#21319;&#29616;&#26377;&#30340;&#19979;&#30028;&#26469;&#21305;&#37197;&#26368;&#20339;&#19978;&#30028;&#65292;&#23545;&#21305;&#37197;&#36861;&#36394;&#30340;&#24615;&#33021;&#36827;&#34892;&#20102;&#31934;&#30830;&#25551;&#36848;&#65292;&#24182;&#26500;&#36896;&#20102;&#19968;&#20010;&#26368;&#22351;&#24773;&#20917;&#30340;&#23383;&#20856;&#26469;&#35777;&#26126;&#29616;&#26377;&#19978;&#30028;&#30340;&#26080;&#27861;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21305;&#37197;&#36861;&#36394;&#30340;&#22522;&#26412;&#38480;&#21046;&#65292;&#21363;&#36890;&#36807;&#23383;&#20856;&#20013;&#30340;&#20803;&#32032;&#30340;&#31232;&#30095;&#32447;&#24615;&#32452;&#21512;&#26469;&#36817;&#20284;&#30446;&#26631;&#20989;&#25968;&#30340;&#32431;&#36138;&#23146;&#31639;&#27861;&#12290;&#24403;&#30446;&#26631;&#20989;&#25968;&#21253;&#21547;&#22312;&#23545;&#24212;&#20110;&#23383;&#20856;&#30340;&#21464;&#21270;&#31354;&#38388;&#20013;&#26102;&#65292;&#35768;&#22810;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#30740;&#31350;&#22312;&#36807;&#21435;&#20960;&#21313;&#24180;&#20013;&#33719;&#24471;&#20102;&#21305;&#37197;&#36861;&#36394;&#30340;&#25910;&#25947;&#36895;&#24230;&#30340;&#19978;&#30028;&#21644;&#19979;&#30028;&#65292;&#20294;&#23427;&#20204;&#24182;&#19981;&#21305;&#37197;&#12290;&#26412;&#25991;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#22635;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#24182;&#33719;&#24471;&#21305;&#37197;&#36861;&#36394;&#24615;&#33021;&#30340;&#31934;&#30830;&#25551;&#36848;&#12290;&#25105;&#20204;&#36890;&#36807;&#25913;&#36827;&#29616;&#26377;&#30340;&#19979;&#30028;&#20197;&#21305;&#37197;&#26368;&#20339;&#19978;&#30028;&#26469;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#26500;&#36896;&#20102;&#19968;&#20010;&#26368;&#22351;&#24773;&#20917;&#30340;&#23383;&#20856;&#65292;&#35777;&#26126;&#20102;&#29616;&#26377;&#30340;&#19978;&#30028;&#19981;&#33021;&#25913;&#36827;&#12290;&#20107;&#23454;&#35777;&#26126;&#65292;&#19982;&#20854;&#20182;&#36138;&#23146;&#31639;&#27861;&#21464;&#20307;&#19981;&#21516;&#65292;&#25910;&#25947;&#36895;&#24230;&#26159;&#27425;&#20248;&#30340;&#65292;&#24182;&#19988;&#30001;&#35299;&#26576;&#20010;&#38750;&#32447;&#24615;&#26041;&#31243;&#30340;&#35299;&#20915;&#26041;&#26696;&#20915;&#23450;&#12290;&#36825;&#20351;&#25105;&#20204;&#24471;&#20986;&#32467;&#35770;&#65292;&#20219;&#24847;&#31243;&#24230;&#30340;&#25910;&#32553;&#37117;&#20250;&#25913;&#21892;&#21305;&#37197;&#36861;&#36394;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the fundamental limits of matching pursuit, or the pure greedy algorithm, for approximating a target function by a sparse linear combination of elements from a dictionary. When the target function is contained in the variation space corresponding to the dictionary, many impressive works over the past few decades have obtained upper and lower bounds on the convergence rate of matching pursuit, but they do not match. The main contribution of this paper is to close this gap and obtain a sharp characterization of the performance of matching pursuit. We accomplish this by improving the existing lower bounds to match the best upper bound. Specifically, we construct a worst case dictionary which proves that the existing upper bound cannot be improved. It turns out that, unlike other greedy algorithm variants, the converge rate is suboptimal and is determined by the solution to a certain non-linear equation. This enables us to conclude that any amount of shrinkage improves matching pu
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#24402;&#19968;&#21270;&#22788;&#29702;&#65292;&#23454;&#29616;&#20132;&#36890;&#39044;&#27979;&#27169;&#22411;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#26356;&#39640;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2307.05946</link><description>&lt;p&gt;
&#19968;&#31181;&#36125;&#21494;&#26031;&#26041;&#27861;&#29992;&#20110;&#37327;&#21270;&#20132;&#36890;&#39044;&#27979;&#27169;&#22411;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#21644;&#25913;&#21892;&#27867;&#21270;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
A Bayesian approach to quantifying uncertainties and improving generalizability in traffic prediction models. (arXiv:2307.05946v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05946
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#24402;&#19968;&#21270;&#22788;&#29702;&#65292;&#23454;&#29616;&#20132;&#36890;&#39044;&#27979;&#27169;&#22411;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#26356;&#39640;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20132;&#36890;&#25968;&#25454;&#39044;&#27979;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#22810;&#23618;&#26550;&#26500;&#23545;&#22797;&#26434;&#20989;&#25968;&#36827;&#34892;&#20248;&#21270;&#24314;&#27169;&#65292;&#20294;&#36825;&#20123;&#26041;&#27861;&#30340;&#19968;&#20010;&#20027;&#35201;&#32570;&#28857;&#26159;&#22823;&#22810;&#25968;&#26041;&#27861;&#19981;&#25552;&#20379;&#24102;&#26377;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#39044;&#27979;&#32467;&#26524;&#65292;&#32780;&#36825;&#23545;&#20110;&#20132;&#36890;&#36816;&#33829;&#21644;&#25511;&#21046;&#26159;&#24517;&#38656;&#30340;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#35889;&#24402;&#19968;&#21270;&#21040;&#20854;&#38544;&#34255;&#23618;&#65292;&#23454;&#29616;&#20132;&#36890;&#39044;&#27979;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#26356;&#39640;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#35770;&#25991;&#34920;&#26126;&#65292;&#24402;&#19968;&#21270;&#36890;&#36807;&#25511;&#21046;&#27169;&#22411;&#30340;&#22797;&#26434;&#24615;&#24182;&#20943;&#23569;&#23545;&#35757;&#32451;&#25968;&#25454;&#30340;&#36807;&#24230;&#25311;&#21512;&#39118;&#38505;&#65292;&#25913;&#21892;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep-learning models for traffic data prediction can have superior performance in modeling complex functions using a multi-layer architecture. However, a major drawback of these approaches is that most of these approaches do not offer forecasts with uncertainty estimates, which are essential for traffic operations and control. Without uncertainty estimates, it is difficult to place any level of trust to the model predictions, and operational strategies relying on overconfident predictions can lead to worsening traffic conditions. In this study, we propose a Bayesian recurrent neural network framework for uncertainty quantification in traffic prediction with higher generalizability by introducing spectral normalization to its hidden layers. In our paper, we have shown that normalization alters the training process of deep neural networks by controlling the model's complexity and reducing the risk of overfitting to the training data. This, in turn, helps improve the generalization perfor
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32593;&#32476;&#29615;&#22659;&#20013;&#30340;&#20998;&#24067;&#24335;&#20272;&#35745;&#21644;&#23398;&#20064;&#38382;&#39064;&#65292;&#36890;&#36807;&#20132;&#25442;&#31169;&#26377;&#35266;&#27979;&#20449;&#24687;&#65292;&#20195;&#29702;&#21487;&#20197;&#38598;&#20307;&#20272;&#35745;&#26410;&#30693;&#25968;&#37327;&#65292;&#32780;&#20445;&#25252;&#38544;&#31169;&#12290;&#36890;&#36807;&#32447;&#24615;&#32858;&#21512;&#26041;&#26696;&#21644;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#35843;&#25972;&#30340;&#38543;&#26426;&#21270;&#26041;&#26696;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#22312;&#20445;&#35777;&#38544;&#31169;&#30340;&#21516;&#26102;&#39640;&#25928;&#32452;&#21512;&#35266;&#27979;&#25968;&#25454;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.15865</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#20998;&#24067;&#24335;&#20272;&#35745;&#21644;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Distributed Estimation and Learning. (arXiv:2306.15865v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15865
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32593;&#32476;&#29615;&#22659;&#20013;&#30340;&#20998;&#24067;&#24335;&#20272;&#35745;&#21644;&#23398;&#20064;&#38382;&#39064;&#65292;&#36890;&#36807;&#20132;&#25442;&#31169;&#26377;&#35266;&#27979;&#20449;&#24687;&#65292;&#20195;&#29702;&#21487;&#20197;&#38598;&#20307;&#20272;&#35745;&#26410;&#30693;&#25968;&#37327;&#65292;&#32780;&#20445;&#25252;&#38544;&#31169;&#12290;&#36890;&#36807;&#32447;&#24615;&#32858;&#21512;&#26041;&#26696;&#21644;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#35843;&#25972;&#30340;&#38543;&#26426;&#21270;&#26041;&#26696;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#22312;&#20445;&#35777;&#38544;&#31169;&#30340;&#21516;&#26102;&#39640;&#25928;&#32452;&#21512;&#35266;&#27979;&#25968;&#25454;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32593;&#32476;&#29615;&#22659;&#20013;&#30340;&#20998;&#24067;&#24335;&#20272;&#35745;&#21644;&#23398;&#20064;&#38382;&#39064;&#65292;&#20854;&#20013;&#20195;&#29702;&#36890;&#36807;&#20132;&#25442;&#20449;&#24687;&#26469;&#20272;&#35745;&#20174;&#20854;&#31169;&#19979;&#35266;&#23519;&#30340;&#26679;&#26412;&#20013;&#26410;&#30693;&#30340;&#32479;&#35745;&#23646;&#24615;&#12290;&#36890;&#36807;&#20132;&#25442;&#31169;&#26377;&#35266;&#27979;&#20449;&#24687;&#65292;&#20195;&#29702;&#21487;&#20197;&#38598;&#20307;&#20272;&#35745;&#26410;&#30693;&#25968;&#37327;&#65292;&#20294;&#20182;&#20204;&#20063;&#38754;&#20020;&#38544;&#31169;&#39118;&#38505;&#12290;&#25105;&#20204;&#30340;&#32858;&#21512;&#26041;&#26696;&#30340;&#30446;&#26631;&#26159;&#22312;&#26102;&#38388;&#21644;&#32593;&#32476;&#20013;&#39640;&#25928;&#22320;&#32452;&#21512;&#35266;&#27979;&#25968;&#25454;&#65292;&#21516;&#26102;&#28385;&#36275;&#20195;&#29702;&#30340;&#38544;&#31169;&#38656;&#27714;&#65292;&#32780;&#19981;&#38656;&#35201;&#20219;&#20309;&#36229;&#36234;&#20182;&#20204;&#26412;&#22320;&#38468;&#36817;&#30340;&#21327;&#35843;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20351;&#21442;&#19982;&#30340;&#20195;&#29702;&#33021;&#22815;&#20174;&#31163;&#32447;&#25110;&#38543;&#26102;&#38388;&#22312;&#32447;&#33719;&#21462;&#30340;&#31169;&#26377;&#20449;&#21495;&#20013;&#20272;&#35745;&#23436;&#25972;&#30340;&#20805;&#20998;&#32479;&#35745;&#37327;&#65292;&#24182;&#20445;&#25252;&#20854;&#20449;&#21495;&#21644;&#32593;&#32476;&#38468;&#36817;&#30340;&#38544;&#31169;&#12290;&#36825;&#26159;&#36890;&#36807;&#32447;&#24615;&#32858;&#21512;&#26041;&#26696;&#21644;&#35843;&#25972;&#30340;&#38543;&#26426;&#21270;&#26041;&#26696;&#23454;&#29616;&#30340;&#65292;&#23558;&#22122;&#22768;&#28155;&#21152;&#21040;&#20132;&#25442;&#30340;&#20272;&#35745;&#25968;&#25454;&#20013;&#20197;&#28385;&#36275;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study distributed estimation and learning problems in a networked environment in which agents exchange information to estimate unknown statistical properties of random variables from their privately observed samples. By exchanging information about their private observations, the agents can collectively estimate the unknown quantities, but they also face privacy risks. The goal of our aggregation schemes is to combine the observed data efficiently over time and across the network, while accommodating the privacy needs of the agents and without any coordination beyond their local neighborhoods. Our algorithms enable the participating agents to estimate a complete sufficient statistic from private signals that are acquired offline or online over time, and to preserve the privacy of their signals and network neighborhoods. This is achieved through linear aggregation schemes with adjusted randomization schemes that add noise to the exchanged estimates subject to differential privacy (DP
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#26080;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#21542;&#23450;&#20998;&#26512;&#24072;&#23545;&#22522;&#20110;&#21452;&#37325;&#26426;&#22120;&#23398;&#20064;&#20272;&#35745;&#30340;Wald&#32622;&#20449;&#21306;&#38388;&#22312;&#24191;&#27867;&#30340;&#21452;&#37325;&#31283;&#20581;&#20989;&#25968;&#31867;&#20013;&#30340;&#26377;&#25928;&#24615;&#30340;&#35777;&#26126;&#12290;</title><link>http://arxiv.org/abs/2306.10590</link><description>&lt;p&gt;
&#25105;&#20204;&#33021;&#21542;&#22312;&#19981;&#20570;&#20219;&#20309;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#35777;&#20266;Wald&#32622;&#20449;&#21306;&#38388;&#22312;&#21452;&#37325;&#31283;&#20581;&#20989;&#25968;&#19979;&#30340;&#26377;&#25928;&#24615;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can we falsify the justification of the validity of Wald confidence intervals of doubly robust functionals, without assumptions?. (arXiv:2306.10590v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10590
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#26080;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#21542;&#23450;&#20998;&#26512;&#24072;&#23545;&#22522;&#20110;&#21452;&#37325;&#26426;&#22120;&#23398;&#20064;&#20272;&#35745;&#30340;Wald&#32622;&#20449;&#21306;&#38388;&#22312;&#24191;&#27867;&#30340;&#21452;&#37325;&#31283;&#20581;&#20989;&#25968;&#31867;&#20013;&#30340;&#26377;&#25928;&#24615;&#30340;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#34892;&#30340;&#29256;&#26412;&#30340;&#26080;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#21542;&#23450;&#20998;&#26512;&#24072;&#23545;&#25253;&#36947;&#30340;&#20197;&#21452;&#37325;&#26426;&#22120;&#23398;&#20064;(DML)&#20272;&#35745;&#37327;&#20026;&#20013;&#24515;&#30340;&#21517;&#20041;$(1-\alpha)$Wald&#32622;&#20449;&#21306;&#38388;&#30340;&#26377;&#25928;&#24615;&#30340;&#35777;&#26126;&#65292;&#23545;Rotnitzky&#31561;&#20154;&#25152;&#30740;&#31350;&#30340;&#21452;&#37325;&#31283;&#20581;(DR)&#20989;&#25968;&#31867;&#30340;&#20219;&#20309;&#25104;&#21592;&#36827;&#34892;&#26816;&#39564;&#12290;DR&#20989;&#25968;&#31867;&#22312;&#32463;&#27982;&#23398;&#21644;&#29983;&#29289;&#32479;&#35745;&#23398;&#20013;&#20855;&#26377;&#24191;&#27867;&#21644;&#26680;&#24515;&#30340;&#37325;&#35201;&#24615;&#12290;&#23427;&#20005;&#26684;&#21253;&#25324;&#20004;&#20010;&#31867;&#21035;&#65292;&#21363;(i)&#21487;&#20197;&#34987;&#20889;&#25104;&#26465;&#20214;&#26399;&#26395;&#30340;&#20223;&#23556;&#20989;&#25968;&#26399;&#26395;&#30340;&#22343;&#26041;&#36830;&#32493;&#20989;&#25968;&#30340;&#31867;&#21035;&#65292;&#36825;&#26159;&#30001;Chernozhukov&#31561;&#20154;&#30740;&#31350;&#30340;&#65292;&#20197;&#21450;Robins&#31561;&#20154;&#25152;&#30740;&#31350;&#30340;&#31867;&#21035;&#12290;&#30446;&#21069;DR&#20989;&#25968;&#30340;&#26368;&#20808;&#36827;&#30340;&#20272;&#35745;&#20540;&#26159;DML&#20272;&#35745;&#20540;&#12290;$\hat{\psi}_{1}$&#30340;&#20559;&#24046;&#21462;&#20915;&#20110;&#20004;&#20010;&#36741;&#21161;&#20989;&#25968;$b$&#21644;$p$&#30340;&#20272;&#35745;&#29575;&#30340;&#20056;&#31215;&#12290;&#26368;&#24120;&#35265;&#30340;&#26159;&#65292;&#20998;&#26512;&#24072;&#35777;&#26126;&#20102;
&lt;/p&gt;
&lt;p&gt;
In this article we develop a feasible version of the assumption-lean tests in Liu et al. 20 that can falsify an analyst's justification for the validity of a reported nominal $(1 - \alpha)$ Wald confidence interval (CI) centered at a double machine learning (DML) estimator for any member of the class of doubly robust (DR) functionals studied by Rotnitzky et al. 21. The class of DR functionals is broad and of central importance in economics and biostatistics. It strictly includes both (i) the class of mean-square continuous functionals that can be written as an expectation of an affine functional of a conditional expectation studied by Chernozhukov et al. 22 and the class of functionals studied by Robins et al. 08. The present state-of-the-art estimators for DR functionals $\psi$ are DML estimators $\hat{\psi}_{1}$. The bias of $\hat{\psi}_{1}$ depends on the product of the rates at which two nuisance functions $b$ and $p$ are estimated. Most commonly an analyst justifies the validity o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#22312;&#39044;&#23450;&#21464;&#25442;&#32676;&#19979;&#23398;&#20064;&#19981;&#21464;&#30340;&#23383;&#20856;&#38382;&#39064;&#12290;&#21033;&#29992;&#38750;&#38463;&#36125;&#23572;&#20613;&#37324;&#21494;&#20998;&#26512;&#65292;&#25552;&#20379;&#20102;&#31639;&#27861;&#65292;&#24314;&#31435;&#20102;&#23383;&#20856;&#23398;&#20064;&#38382;&#39064;&#21487;&#20197;&#34987;&#26377;&#25928;&#22320;&#29702;&#35299;&#20026;&#26576;&#20123;&#30697;&#38453;&#20248;&#21270;&#38382;&#39064;&#30340;&#29702;&#35770;&#22522;&#30784;&#12290;</title><link>http://arxiv.org/abs/2305.19557</link><description>&lt;p&gt;
&#36890;&#36807;&#32676;&#34920;&#31034;&#23398;&#20064;&#23545;&#31216;&#19979;&#30340;&#23383;&#20856;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Dictionary Learning under Symmetries via Group Representations. (arXiv:2305.19557v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19557
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22312;&#39044;&#23450;&#21464;&#25442;&#32676;&#19979;&#23398;&#20064;&#19981;&#21464;&#30340;&#23383;&#20856;&#38382;&#39064;&#12290;&#21033;&#29992;&#38750;&#38463;&#36125;&#23572;&#20613;&#37324;&#21494;&#20998;&#26512;&#65292;&#25552;&#20379;&#20102;&#31639;&#27861;&#65292;&#24314;&#31435;&#20102;&#23383;&#20856;&#23398;&#20064;&#38382;&#39064;&#21487;&#20197;&#34987;&#26377;&#25928;&#22320;&#29702;&#35299;&#20026;&#26576;&#20123;&#30697;&#38453;&#20248;&#21270;&#38382;&#39064;&#30340;&#29702;&#35770;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23383;&#20856;&#23398;&#20064;&#38382;&#39064;&#21487;&#20197;&#34987;&#30475;&#20316;&#26159;&#19968;&#20010;&#25968;&#25454;&#39537;&#21160;&#30340;&#36807;&#31243;&#65292;&#26088;&#22312;&#23398;&#20064;&#19968;&#20010;&#21512;&#36866;&#30340;&#21464;&#25442;&#65292;&#20197;&#20415;&#36890;&#36807;&#31034;&#20363;&#25968;&#25454;&#30452;&#25509;&#34920;&#31034;&#25968;&#25454;&#30340;&#31232;&#30095;&#24615;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#39044;&#23450;&#30340;&#21464;&#25442;&#32676;&#19979;&#23398;&#20064;&#19981;&#21464;&#30340;&#23383;&#20856;&#38382;&#39064;&#12290;&#33258;&#28982;&#30340;&#24212;&#29992;&#39046;&#22495;&#21253;&#25324;&#20919;&#20923;&#30005;&#38236;&#12289;&#22810;&#30446;&#26631;&#36319;&#36394;&#12289;&#21516;&#27493;&#21644;&#23039;&#24577;&#20272;&#35745;&#31561;&#12290;&#25105;&#20204;&#29305;&#21035;&#20174;&#25968;&#23398;&#34920;&#31034;&#29702;&#35770;&#30340;&#35282;&#24230;&#30740;&#31350;&#20102;&#36825;&#20010;&#38382;&#39064;&#12290;&#36890;&#36807;&#21033;&#29992;&#38750;&#38463;&#36125;&#23572;&#20613;&#37324;&#21494;&#20998;&#26512;&#65292;&#25105;&#20204;&#20026;&#31526;&#21512;&#36825;&#20123;&#19981;&#21464;&#24615;&#30340;&#23383;&#20856;&#23398;&#20064;&#25552;&#20379;&#20102;&#31639;&#27861;&#12290;&#25105;&#20204;&#23558;&#33258;&#28982;&#30028;&#20013;&#30340;&#23383;&#20856;&#23398;&#20064;&#38382;&#39064;&#65292;&#20854;&#33258;&#28982;&#34987;&#24314;&#27169;&#20026;&#26080;&#38480;&#32500;&#24230;&#30340;&#38382;&#39064;&#65292;&#19982;&#30456;&#20851;&#30340;&#35745;&#31639;&#38382;&#39064;&#65292;&#36825;&#24517;&#28982;&#26159;&#26377;&#38480;&#32500;&#24230;&#30340;&#38382;&#39064;&#65292;&#32852;&#31995;&#36215;&#26469;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#23383;&#20856;&#23398;&#20064;&#38382;&#39064;&#21487;&#20197;&#34987;&#26377;&#25928;&#22320;&#29702;&#35299;&#20026;&#26576;&#20123;&#30697;&#38453;&#20248;&#21270;&#38382;&#39064;&#30340;&#29702;&#35770;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
The dictionary learning problem can be viewed as a data-driven process to learn a suitable transformation so that data is sparsely represented directly from example data. In this paper, we examine the problem of learning a dictionary that is invariant under a pre-specified group of transformations. Natural settings include Cryo-EM, multi-object tracking, synchronization, pose estimation, etc. We specifically study this problem under the lens of mathematical representation theory. Leveraging the power of non-abelian Fourier analysis for functions over compact groups, we prescribe an algorithmic recipe for learning dictionaries that obey such invariances. We relate the dictionary learning problem in the physical domain, which is naturally modelled as being infinite dimensional, with the associated computational problem, which is necessarily finite dimensional. We establish that the dictionary learning problem can be effectively understood as an optimization instance over certain matrix o
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#36712;&#36857;&#30340;&#20248;&#21270;&#26041;&#27861;&#26469;&#22788;&#29702;&#38543;&#26426;&#27969;&#34892;&#30149;&#23398;&#27169;&#22411;&#65292;&#21487;&#20197;&#25214;&#21040;&#19982;&#23454;&#38469;&#35266;&#27979;&#20540;&#25509;&#36817;&#30340;&#23454;&#38469;&#36712;&#36857;&#65292;&#32780;&#19981;&#26159;&#20165;&#20351;&#24179;&#22343;&#27169;&#25311;&#32467;&#26524;&#19982;&#23454;&#27979;&#25968;&#25454;&#30456;&#31526;&#12290;</title><link>http://arxiv.org/abs/2305.03926</link><description>&lt;p&gt;
&#22522;&#20110;&#36712;&#36857;&#30340;&#38543;&#26426;&#27969;&#34892;&#30149;&#23398;&#27169;&#22411;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Trajectory-oriented optimization of stochastic epidemiological models. (arXiv:2305.03926v1 [stat.AP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.03926
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#36712;&#36857;&#30340;&#20248;&#21270;&#26041;&#27861;&#26469;&#22788;&#29702;&#38543;&#26426;&#27969;&#34892;&#30149;&#23398;&#27169;&#22411;&#65292;&#21487;&#20197;&#25214;&#21040;&#19982;&#23454;&#38469;&#35266;&#27979;&#20540;&#25509;&#36817;&#30340;&#23454;&#38469;&#36712;&#36857;&#65292;&#32780;&#19981;&#26159;&#20165;&#20351;&#24179;&#22343;&#27169;&#25311;&#32467;&#26524;&#19982;&#23454;&#27979;&#25968;&#25454;&#30456;&#31526;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#38543;&#26426;&#27169;&#22411;&#65292;&#20026;&#20102;&#36827;&#34892;&#39044;&#27979;&#21644;&#36816;&#34892;&#27169;&#25311;&#65292;&#38656;&#35201;&#36827;&#34892;&#22320;&#38754;&#23454;&#27979;&#26631;&#23450;&#12290;&#30001;&#20110;&#36755;&#20986;&#32467;&#26524;&#36890;&#24120;&#26159;&#36890;&#36807;&#38598;&#25104;&#25110;&#20998;&#24067;&#26469;&#25551;&#36848;&#65292;&#22240;&#27492;&#38656;&#35201;&#23545;&#27599;&#20010;&#25104;&#21592;&#36827;&#34892;&#26631;&#23450;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#20195;&#29702;&#21644;Thompson&#37319;&#26679;&#30340;&#20248;&#21270;&#31574;&#30053;&#26469;&#23547;&#25214;&#19982;&#20107;&#23454;&#30456;&#19968;&#33268;&#30340;&#36755;&#20837;&#21442;&#25968;&#35774;&#32622;&#21644;&#38543;&#26426;&#25968;&#31181;&#23376;&#65292;&#35813;Trajectory Oriented Optimization&#65288;TOO&#65289;&#26041;&#27861;&#21487;&#20197;&#20135;&#29983;&#19982;&#23454;&#38469;&#35266;&#27979;&#20540;&#25509;&#36817;&#30340;&#23454;&#38469;&#36712;&#36857;&#65292;&#32780;&#19981;&#26159;&#20165;&#34429;&#28982;&#27169;&#25311;&#30340;&#24179;&#22343;&#34892;&#20026;&#19982;&#20107;&#23454;&#30456;&#31526;&#12290;
&lt;/p&gt;
&lt;p&gt;
Epidemiological models must be calibrated to ground truth for downstream tasks such as producing forward projections or running what-if scenarios. The meaning of calibration changes in case of a stochastic model since output from such a model is generally described via an ensemble or a distribution. Each member of the ensemble is usually mapped to a random number seed (explicitly or implicitly). With the goal of finding not only the input parameter settings but also the random seeds that are consistent with the ground truth, we propose a class of Gaussian process (GP) surrogates along with an optimization strategy based on Thompson sampling. This Trajectory Oriented Optimization (TOO) approach produces actual trajectories close to the empirical observations instead of a set of parameter settings where only the mean simulation behavior matches with the ground truth.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;Transformer&#30340;&#35757;&#32451;&#21160;&#24577;&#65292;&#21457;&#29616;&#20302;&#27880;&#24847;&#21147;&#29109;&#20276;&#38543;&#30528;&#39640;&#35757;&#32451;&#19981;&#31283;&#23450;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;$\sigma$Reparam&#65292;&#25104;&#21151;&#22320;&#38450;&#27490;&#20102;&#27880;&#24847;&#21147;&#23618;&#20013;&#30340;&#29109;&#23849;&#28291;&#65292;&#20419;&#36827;&#20102;&#26356;&#31283;&#23450;&#30340;&#35757;&#32451;&#12290;</title><link>http://arxiv.org/abs/2303.06296</link><description>&lt;p&gt;
&#38450;&#27490;&#27880;&#24847;&#21147;&#29109;&#23849;&#28291;&#30340;Transformer&#35757;&#32451;&#31283;&#23450;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Stabilizing Transformer Training by Preventing Attention Entropy Collapse. (arXiv:2303.06296v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06296
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;Transformer&#30340;&#35757;&#32451;&#21160;&#24577;&#65292;&#21457;&#29616;&#20302;&#27880;&#24847;&#21147;&#29109;&#20276;&#38543;&#30528;&#39640;&#35757;&#32451;&#19981;&#31283;&#23450;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;$\sigma$Reparam&#65292;&#25104;&#21151;&#22320;&#38450;&#27490;&#20102;&#27880;&#24847;&#21147;&#23618;&#20013;&#30340;&#29109;&#23849;&#28291;&#65292;&#20419;&#36827;&#20102;&#26356;&#31283;&#23450;&#30340;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates the training dynamics of Transformers and proposes a simple and efficient solution, $\sigma$Reparam, to prevent entropy collapse in the attention layers, promoting more stable training.
&lt;/p&gt;
&lt;p&gt;
&#35757;&#32451;&#31283;&#23450;&#24615;&#23545;&#20110;Transformer&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#27880;&#24847;&#21147;&#23618;&#30340;&#28436;&#21464;&#26469;&#25506;&#31350;Transformer&#30340;&#35757;&#32451;&#21160;&#24577;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#36319;&#36394;&#27599;&#20010;&#27880;&#24847;&#21147;&#22836;&#30340;&#27880;&#24847;&#21147;&#29109;&#65292;&#36825;&#26159;&#27169;&#22411;&#38160;&#24230;&#30340;&#20195;&#29702;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#19981;&#21516;&#30340;&#26550;&#26500;&#21644;&#20219;&#21153;&#20013;&#23384;&#22312;&#19968;&#31181;&#24120;&#35265;&#27169;&#24335;&#65292;&#21363;&#20302;&#27880;&#24847;&#21147;&#29109;&#20276;&#38543;&#30528;&#39640;&#35757;&#32451;&#19981;&#31283;&#23450;&#24615;&#65292;&#36825;&#21487;&#33021;&#37319;&#21462;&#25391;&#33633;&#25439;&#22833;&#25110;&#21457;&#25955;&#30340;&#24418;&#24335;&#12290;&#25105;&#20204;&#23558;&#30149;&#24577;&#20302;&#27880;&#24847;&#21147;&#29109;&#65292;&#23545;&#24212;&#39640;&#24230;&#38598;&#20013;&#30340;&#27880;&#24847;&#21147;&#20998;&#25968;&#65292;&#31216;&#20026;$\textit{&#29109;&#23849;&#28291;}$&#12290;&#20316;&#20026;&#19968;&#31181;&#35299;&#20915;&#26041;&#26696;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;$\sigma$Reparam&#65292;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20854;&#20013;&#25105;&#20204;&#20351;&#29992;&#35889;&#24402;&#19968;&#21270;&#21644;&#39069;&#22806;&#30340;&#23398;&#20064;&#26631;&#37327;&#37325;&#26032;&#21442;&#25968;&#21270;&#25152;&#26377;&#32447;&#24615;&#23618;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#37325;&#26032;&#21442;&#25968;&#21270;&#25104;&#21151;&#22320;&#38450;&#27490;&#20102;&#27880;&#24847;&#21147;&#23618;&#20013;&#30340;&#29109;&#23849;&#28291;&#65292;&#20419;&#36827;&#20102;&#26356;&#31283;&#23450;&#30340;&#35757;&#32451;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;
&lt;/p&gt;
&lt;p&gt;
Training stability is of great importance to Transformers. In this work, we investigate the training dynamics of Transformers by examining the evolution of the attention layers. In particular, we track the attention entropy for each attention head during the course of training, which is a proxy for model sharpness. We identify a common pattern across different architectures and tasks, where low attention entropy is accompanied by high training instability, which can take the form of oscillating loss or divergence. We denote the pathologically low attention entropy, corresponding to highly concentrated attention scores, as $\textit{entropy collapse}$. As a remedy, we propose $\sigma$Reparam, a simple and efficient solution where we reparametrize all linear layers with spectral normalization and an additional learned scalar. We demonstrate that the proposed reparameterization successfully prevents entropy collapse in the attention layers, promoting more stable training. Additionally, we 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#20855;&#26377;&#26126;&#30830;&#38750;&#28176;&#36817;&#36229;&#32447;&#24615;&#25910;&#25947;&#36895;&#29575;&#30340;&#20840;&#23616;&#25910;&#25947;&#25311;&#29275;&#39039;&#26041;&#27861;&#65292;&#24182;&#37319;&#29992;&#28151;&#21512;&#36817;&#31471;&#22806;&#26799;&#24230;&#27861;&#32467;&#26500;&#21644;&#22312;&#32447;&#23398;&#20064;&#26694;&#26550;&#26469;&#26356;&#26032;Hessian&#36924;&#36817;&#30697;&#38453;&#12290;</title><link>http://arxiv.org/abs/2302.08580</link><description>&lt;p&gt;
&#22312;&#32447;&#23398;&#20064;&#24341;&#23548;&#30340;&#26354;&#29575;&#36924;&#36817;&#65306;&#20855;&#26377;&#20840;&#23616;&#38750;&#28176;&#36817;&#36229;&#32447;&#24615;&#25910;&#25947;&#30340;&#25311;&#29275;&#39039;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Online Learning Guided Curvature Approximation: A Quasi-Newton Method with Global Non-Asymptotic Superlinear Convergence. (arXiv:2302.08580v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.08580
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#20855;&#26377;&#26126;&#30830;&#38750;&#28176;&#36817;&#36229;&#32447;&#24615;&#25910;&#25947;&#36895;&#29575;&#30340;&#20840;&#23616;&#25910;&#25947;&#25311;&#29275;&#39039;&#26041;&#27861;&#65292;&#24182;&#37319;&#29992;&#28151;&#21512;&#36817;&#31471;&#22806;&#26799;&#24230;&#27861;&#32467;&#26500;&#21644;&#22312;&#32447;&#23398;&#20064;&#26694;&#26550;&#26469;&#26356;&#26032;Hessian&#36924;&#36817;&#30697;&#38453;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25311;&#29275;&#39039;&#31639;&#27861;&#26159;&#35299;&#20915;&#26080;&#32422;&#26463;&#26368;&#23567;&#21270;&#38382;&#39064;&#20013;&#26368;&#21463;&#27426;&#36814;&#30340;&#36845;&#20195;&#26041;&#27861;&#20043;&#19968;&#65292;&#36825;&#20027;&#35201;&#24402;&#21151;&#20110;&#20854;&#33391;&#22909;&#30340;&#36229;&#32447;&#24615;&#25910;&#25947;&#24615;&#36136;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#31639;&#27861;&#32467;&#26524;&#23384;&#22312;&#38480;&#21046;&#65292;&#35201;&#20040;&#25552;&#20379;&#20102;&#20855;&#26377;&#28176;&#36817;&#36229;&#32447;&#24615;&#25910;&#25947;&#36895;&#24230;&#30340;&#20840;&#23616;&#25910;&#25947;&#20445;&#35777;&#65292;&#35201;&#20040;&#20165;&#22312;&#21021;&#22987;&#28857;&#21644;&#21021;&#22987;Hessian&#36924;&#36817;&#36873;&#25321;&#36866;&#24403;&#30340;&#24773;&#20917;&#19979;&#25552;&#20379;&#20102;&#23616;&#37096;&#38750;&#28176;&#36817;&#36229;&#32447;&#24615;&#36895;&#29575;&#12290;&#29305;&#21035;&#22320;&#65292;&#30446;&#21069;&#27809;&#26377;&#25311;&#29275;&#39039;&#26041;&#27861;&#30340;&#20998;&#26512;&#20445;&#35777;&#20102;&#20855;&#26377;&#26126;&#30830;&#36229;&#32447;&#24615;&#25910;&#25947;&#36895;&#29575;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#22635;&#34917;&#20102;&#36825;&#19968;&#31354;&#30333;&#65292;&#24182;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#20855;&#26377;&#26126;&#30830;&#38750;&#28176;&#36817;&#36229;&#32447;&#24615;&#25910;&#25947;&#36895;&#29575;&#30340;&#20840;&#23616;&#25910;&#25947;&#25311;&#29275;&#39039;&#26041;&#27861;&#12290;&#19982;&#20256;&#32479;&#30340;&#25311;&#29275;&#39039;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#22522;&#20110;&#28151;&#21512;&#36817;&#31471;&#22806;&#26799;&#24230;&#27861;&#26500;&#24314;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22312;&#32447;&#23398;&#20064;&#26694;&#26550;&#26469;&#26356;&#26032;Hessian&#36924;&#36817;&#30697;&#38453;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quasi-Newton algorithms are among the most popular iterative methods for solving unconstrained minimization problems, largely due to their favorable superlinear convergence property. However, existing results for these algorithms are limited as they provide either (i) a global convergence guarantee with an asymptotic superlinear convergence rate, or (ii) a local non-asymptotic superlinear rate for the case that the initial point and the initial Hessian approximation are chosen properly. In particular, no current analysis for quasi-Newton methods guarantees global convergence with an explicit superlinear convergence rate. In this paper, we close this gap and present the first globally convergent quasi-Newton method with an explicit non-asymptotic superlinear convergence rate. Unlike classical quasi-Newton methods, we build our algorithm upon the hybrid proximal extragradient method and propose a novel online learning framework for updating the Hessian approximation matrices. Specificall
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#20998;&#25968;&#30340;&#26465;&#20214;&#27169;&#22411;&#20013;&#23398;&#20064;&#34920;&#31034;&#30340;&#32467;&#26500;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#25968;&#23398;&#24418;&#24335;&#21270;&#34920;&#36798;&#27010;&#24565;&#34987;&#32534;&#30721;&#20026;&#34920;&#31034;&#31354;&#38388;&#23376;&#31354;&#38388;&#30340;&#24605;&#24819;&#12290;&#21033;&#29992;&#36825;&#20010;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#26469;&#35782;&#21035;&#32473;&#23450;&#27010;&#24565;&#23545;&#24212;&#30340;&#34920;&#31034;&#37096;&#20998;&#65292;&#24182;&#36890;&#36807;&#20195;&#25968;&#25805;&#20316;&#25805;&#32437;&#27169;&#22411;&#25152;&#34920;&#36798;&#30340;&#27010;&#24565;&#12290;</title><link>http://arxiv.org/abs/2302.03693</link><description>&lt;p&gt;
&#22522;&#20110;&#20998;&#25968;&#30340;&#26465;&#20214;&#27169;&#22411;&#30340;&#27010;&#24565;&#20195;&#25968;
&lt;/p&gt;
&lt;p&gt;
Concept Algebra for Score-Based Conditional Models. (arXiv:2302.03693v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.03693
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#20998;&#25968;&#30340;&#26465;&#20214;&#27169;&#22411;&#20013;&#23398;&#20064;&#34920;&#31034;&#30340;&#32467;&#26500;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#25968;&#23398;&#24418;&#24335;&#21270;&#34920;&#36798;&#27010;&#24565;&#34987;&#32534;&#30721;&#20026;&#34920;&#31034;&#31354;&#38388;&#23376;&#31354;&#38388;&#30340;&#24605;&#24819;&#12290;&#21033;&#29992;&#36825;&#20010;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#26469;&#35782;&#21035;&#32473;&#23450;&#27010;&#24565;&#23545;&#24212;&#30340;&#34920;&#31034;&#37096;&#20998;&#65292;&#24182;&#36890;&#36807;&#20195;&#25968;&#25805;&#20316;&#25805;&#32437;&#27169;&#22411;&#25152;&#34920;&#36798;&#30340;&#27010;&#24565;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#25991;&#26412;&#24341;&#23548;&#29983;&#25104;&#27169;&#22411;&#20013;&#23398;&#20064;&#34920;&#31034;&#30340;&#32467;&#26500;&#65292;&#37325;&#28857;&#20851;&#27880;&#22522;&#20110;&#20998;&#25968;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#32858;&#28966;&#20110;&#27010;&#24565;&#34987;&#32534;&#30721;&#20026;&#26576;&#31181;&#34920;&#31034;&#31354;&#38388;&#30340;&#23376;&#31354;&#38388;&#65288;&#25110;&#26041;&#21521;&#65289;&#30340;&#24605;&#24819;&#65292;&#24182;&#24320;&#21457;&#20102;&#36825;&#20010;&#24605;&#24819;&#30340;&#25968;&#23398;&#24418;&#24335;&#21270;&#12290;&#21033;&#29992;&#36825;&#20010;&#24418;&#24335;&#21270;&#26041;&#27861;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26377;&#19968;&#20010;&#33258;&#28982;&#30340;&#34920;&#31034;&#36873;&#25321;&#20855;&#26377;&#36825;&#31181;&#24615;&#36136;&#65292;&#24182;&#19988;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#26041;&#27861;&#26469;&#35782;&#21035;&#19982;&#32473;&#23450;&#27010;&#24565;&#23545;&#24212;&#30340;&#34920;&#31034;&#37096;&#20998;&#12290;&#29305;&#21035;&#26159;&#65292;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#36890;&#36807;&#23545;&#34920;&#31034;&#30340;&#20195;&#25968;&#25805;&#20316;&#26469;&#25805;&#32437;&#27169;&#22411;&#25152;&#34920;&#36798;&#30340;&#27010;&#24565;&#12290;&#25105;&#20204;&#20351;&#29992;&#31283;&#23450;&#25193;&#25955;&#22312;&#25991;&#26412;&#24341;&#23548;&#22270;&#20687;&#29983;&#25104;&#30340;&#31034;&#20363;&#20013;&#28436;&#31034;&#20102;&#36825;&#20010;&#24605;&#24819;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper concerns the structure of learned representations in text-guided generative models, focusing on score-based models. Here, we focus on the idea that concepts are encoded as subspaces (or directions) of some representation space. We develop a mathematical formalization of this idea.Using this formalism, we show there's a natural choice of representation with this property, and we develop a simple method for identifying the part of the representation corresponding to a given concept. In particular, this allows us to manipulate the concepts expressed by the model through algebraic manipulation of the representation. We demonstrate the idea with examples text-guided image generation, using Stable Diffusion.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#37327;&#23376;&#31639;&#27861;&#22312;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;&#65292;&#21457;&#29616;&#22312;&#21487;&#20197;&#26597;&#35810;&#22870;&#21169;&#30340;&#38543;&#26426;&#24615;&#20197;&#21450;&#33218;&#30340;&#21472;&#21152;&#24577;&#26102;&#21487;&#20197;&#23454;&#29616;&#20108;&#27425;&#21152;&#36895;&#65292;&#20294;&#22312;&#21482;&#33021;&#26377;&#38480;&#22320;&#35775;&#38382;&#22870;&#21169;&#30340;&#38543;&#26426;&#24615;&#26102;&#65292;&#26597;&#35810;&#22797;&#26434;&#24230;&#19982;&#32463;&#20856;&#31639;&#27861;&#30456;&#21516;&#12290;</title><link>http://arxiv.org/abs/2301.08544</link><description>&lt;p&gt;
&#22810;&#33218;&#36172;&#21338;&#26426;&#21644;&#37327;&#23376;&#36890;&#36947;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Multi-Armed Bandits and Quantum Channel Oracles. (arXiv:2301.08544v2 [quant-ph] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.08544
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#37327;&#23376;&#31639;&#27861;&#22312;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;&#65292;&#21457;&#29616;&#22312;&#21487;&#20197;&#26597;&#35810;&#22870;&#21169;&#30340;&#38543;&#26426;&#24615;&#20197;&#21450;&#33218;&#30340;&#21472;&#21152;&#24577;&#26102;&#21487;&#20197;&#23454;&#29616;&#20108;&#27425;&#21152;&#36895;&#65292;&#20294;&#22312;&#21482;&#33021;&#26377;&#38480;&#22320;&#35775;&#38382;&#22870;&#21169;&#30340;&#38543;&#26426;&#24615;&#26102;&#65292;&#26597;&#35810;&#22797;&#26434;&#24230;&#19982;&#32463;&#20856;&#31639;&#27861;&#30456;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#33218;&#36172;&#21338;&#26426;&#26159;&#24378;&#21270;&#23398;&#20064;&#29702;&#35770;&#30340;&#37325;&#35201;&#25903;&#26609;&#20043;&#19968;&#12290;&#26368;&#36817;&#65292;&#20154;&#20204;&#24320;&#22987;&#30740;&#31350;&#29992;&#20110;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#37327;&#23376;&#31639;&#27861;&#65292;&#24182;&#21457;&#29616;&#24403;&#21487;&#20197;&#22312;&#21472;&#21152;&#24577;&#20013;&#26597;&#35810;&#33218;&#21644;&#22870;&#21169;&#38543;&#26426;&#24615;&#26102;&#65292;&#21487;&#20197;&#23454;&#29616;&#20108;&#27425;&#21152;&#36895;&#65288;&#22312;&#26597;&#35810;&#22797;&#26434;&#24230;&#19978;&#65289;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#36827;&#19968;&#27493;&#30340;&#36172;&#21338;&#26426;&#27169;&#22411;&#65292;&#20854;&#20013;&#25105;&#20204;&#21482;&#33021;&#26377;&#38480;&#22320;&#35775;&#38382;&#22870;&#21169;&#30340;&#38543;&#26426;&#24615;&#65292;&#20294;&#25105;&#20204;&#20173;&#28982;&#21487;&#20197;&#22312;&#21472;&#21152;&#24577;&#20013;&#26597;&#35810;&#33218;&#12290;&#25105;&#20204;&#35777;&#26126;&#24403;&#22914;&#27492;&#26102;&#26597;&#35810;&#22797;&#26434;&#24230;&#19982;&#32463;&#20856;&#31639;&#27861;&#30456;&#21516;&#12290;&#36825;&#25512;&#24191;&#20102;&#20808;&#21069;&#30340;&#32467;&#26524;&#65292;&#21363;&#24403;&#39044;&#27979;&#22120;&#20855;&#26377;&#27491;&#30340;&#22833;&#25928;&#27010;&#29575;&#26102;&#65292;&#23545;&#20110;&#26410;&#32467;&#26500;&#21270;&#25628;&#32034;&#26080;&#27861;&#23454;&#29616;&#21152;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-armed bandits are one of the theoretical pillars of reinforcement learning. Recently, the investigation of quantum algorithms for multi-armed bandit problems was started, and it was found that a quadratic speed-up (in query complexity) is possible when the arms and the randomness of the rewards of the arms can be queried in superposition. Here we introduce further bandit models where we only have limited access to the randomness of the rewards, but we can still query the arms in superposition. We show that then the query complexity is the same as for classical algorithms. This generalizes the prior result that no speed-up is possible for unstructured search when the oracle has positive failure probability.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#20215;&#26684;&#30340;&#32593;&#32476;&#25910;&#30410;&#31649;&#29702;&#38382;&#39064;&#65292;&#21516;&#26102;&#32771;&#34385;&#20102;&#38656;&#27714;&#23398;&#20064;&#21644;&#20844;&#24179;&#36164;&#28304;&#28040;&#32791;&#24179;&#34913;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;UCB&#38656;&#27714;&#23398;&#20064;&#26041;&#27861;&#30340;&#21407;&#22987;&#23545;&#20598;&#22312;&#32447;&#31574;&#30053;&#26469;&#26368;&#22823;&#21270;&#35268;&#33539;&#21270;&#25910;&#30410;&#12290;</title><link>http://arxiv.org/abs/2207.11159</link><description>&lt;p&gt;
&#22522;&#20110;&#38656;&#27714;&#23398;&#20064;&#21644;&#20844;&#24179;&#36164;&#28304;&#28040;&#32791;&#24179;&#34913;&#30340;&#32593;&#32476;&#25910;&#30410;&#31649;&#29702;
&lt;/p&gt;
&lt;p&gt;
Network Revenue Management with Demand Learning and Fair Resource-Consumption Balancing. (arXiv:2207.11159v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.11159
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#20215;&#26684;&#30340;&#32593;&#32476;&#25910;&#30410;&#31649;&#29702;&#38382;&#39064;&#65292;&#21516;&#26102;&#32771;&#34385;&#20102;&#38656;&#27714;&#23398;&#20064;&#21644;&#20844;&#24179;&#36164;&#28304;&#28040;&#32791;&#24179;&#34913;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;UCB&#38656;&#27714;&#23398;&#20064;&#26041;&#27861;&#30340;&#21407;&#22987;&#23545;&#20598;&#22312;&#32447;&#31574;&#30053;&#26469;&#26368;&#22823;&#21270;&#35268;&#33539;&#21270;&#25910;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38500;&#20102;&#26368;&#22823;&#21270;&#24635;&#25910;&#30410;&#22806;&#65292;&#24456;&#22810;&#34892;&#19994;&#30340;&#20915;&#31574;&#32773;&#36824;&#24076;&#26395;&#30830;&#20445;&#19981;&#21516;&#36164;&#28304;&#20043;&#38388;&#28040;&#32791;&#30340;&#24179;&#34913;&#12290;&#20363;&#22914;&#65292;&#22312;&#38646;&#21806;&#34892;&#19994;&#20013;&#65292;&#30830;&#20445;&#26469;&#33258;&#19981;&#21516;&#20379;&#24212;&#21830;&#30340;&#36164;&#28304;&#24179;&#34913;&#28040;&#32791;&#26377;&#21161;&#20110;&#25552;&#39640;&#20844;&#24179;&#24615;&#24182;&#32500;&#25345;&#33391;&#22909;&#30340;&#28192;&#36947;&#20851;&#31995;&#65307;&#22312;&#20113;&#35745;&#31639;&#34892;&#19994;&#20013;&#65292;&#36164;&#28304;&#28040;&#32791;&#30340;&#24179;&#34913;&#26377;&#21161;&#20110;&#25552;&#39640;&#23458;&#25143;&#28385;&#24847;&#24230;&#24182;&#38477;&#20302;&#36816;&#33829;&#25104;&#26412;&#12290;&#38024;&#23545;&#36825;&#20123;&#23454;&#38469;&#38656;&#27714;&#65292;&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#20215;&#26684;&#30340;&#32593;&#32476;&#25910;&#30410;&#31649;&#29702;&#38382;&#39064;&#65292;&#21516;&#26102;&#32771;&#34385;&#20102;&#38656;&#27714;&#23398;&#20064;&#21644;&#20844;&#24179;&#36164;&#28304;&#28040;&#32791;&#24179;&#34913;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#35268;&#33539;&#21270;&#25910;&#30410;&#30340;&#27010;&#24565;&#65292;&#21363;&#36890;&#36807;&#24179;&#34913;&#27491;&#21017;&#21270;&#23558;&#20844;&#24179;&#30340;&#36164;&#28304;&#28040;&#32791;&#24179;&#34913;&#32435;&#20837;&#21040;&#25910;&#30410;&#26368;&#22823;&#21270;&#30340;&#30446;&#26631;&#20013;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#19978;&#32622;&#20449;&#30028;&#38480;&#65288;UCB&#65289;&#38656;&#27714;&#23398;&#20064;&#26041;&#27861;&#30340;&#21407;&#22987;&#23545;&#20598;&#22312;&#32447;&#31574;&#30053;&#26469;&#26368;&#22823;&#21270;&#35268;&#33539;&#21270;&#25910;&#30410;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;&#20960;&#20010;&#21019;&#26032;&#26041;&#27861;&#26469;&#24212;&#23545;&#38656;&#27714;&#23398;&#20064;&#21644;&#36164;&#28304;&#28040;&#32791;&#24179;&#34913;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;
In addition to maximizing the total revenue, decision-makers in lots of industries would like to guarantee balanced consumption across different resources. For instance, in the retailing industry, ensuring a balanced consumption of resources from different suppliers enhances fairness and helps main a good channel relationship; in the cloud computing industry, resource-consumption balance helps increase customer satisfaction and reduce operational costs. Motivated by these practical needs, this paper studies the price-based network revenue management (NRM) problem with both demand learning and fair resource-consumption balancing. We introduce the regularized revenue, i.e., the total revenue with a balancing regularization, as our objective to incorporate fair resource-consumption balancing into the revenue maximization goal. We propose a primal-dual-type online policy with the Upper-Confidence-Bound (UCB) demand learning method to maximize the regularized revenue. We adopt several innov
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#36335;&#24452;&#30456;&#20851;&#30340;&#31070;&#32463;&#36339;&#36291;ODE&#23545;&#36890;&#29992;&#21160;&#21147;&#23398;&#36827;&#34892;&#26368;&#20248;&#20272;&#35745;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#25903;&#25345;&#20102;&#36825;&#20123;&#29702;&#35770;&#32467;&#26524;&#65292;&#23637;&#31034;&#20102;&#20854;&#22312;&#38750;&#39532;&#23572;&#21487;&#22827;&#25968;&#25454;&#21644;&#38480;&#20215;&#35746;&#21333;&#31807;&#25968;&#25454;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2206.14284</link><description>&lt;p&gt;
&#20351;&#29992;&#36335;&#24452;&#30456;&#20851;&#30340;&#31070;&#32463;&#36339;&#36291;ODE&#23545;&#36890;&#29992;&#21160;&#21147;&#23398;&#36827;&#34892;&#26368;&#20248;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Optimal Estimation of Generic Dynamics by Path-Dependent Neural Jump ODEs. (arXiv:2206.14284v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.14284
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#36335;&#24452;&#30456;&#20851;&#30340;&#31070;&#32463;&#36339;&#36291;ODE&#23545;&#36890;&#29992;&#21160;&#21147;&#23398;&#36827;&#34892;&#26368;&#20248;&#20272;&#35745;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#25903;&#25345;&#20102;&#36825;&#20123;&#29702;&#35770;&#32467;&#26524;&#65292;&#23637;&#31034;&#20102;&#20854;&#22312;&#38750;&#39532;&#23572;&#21487;&#22827;&#25968;&#25454;&#21644;&#38480;&#20215;&#35746;&#21333;&#31807;&#25968;&#25454;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#31070;&#32463;&#36339;&#36291;ODE&#65288;NJ-ODE&#65289;&#26694;&#26550;&#30340;&#36335;&#24452;&#30456;&#20851;&#25193;&#23637;&#26469;&#39044;&#27979;&#19968;&#33324;&#38543;&#26426;&#36807;&#31243;&#30340;&#38382;&#39064;&#12290;&#34429;&#28982;NJ-ODE&#26159;&#31532;&#19968;&#20010;&#24314;&#31435;&#36215;&#38024;&#23545;&#19981;&#35268;&#21017;&#35266;&#27979;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#25910;&#25947;&#24615;&#20445;&#35777;&#30340;&#26694;&#26550;&#65292;&#20294;&#36825;&#20123;&#32467;&#26524;&#20165;&#36866;&#29992;&#20110;&#26469;&#33258;&#20855;&#26377;&#23436;&#25972;&#35266;&#27979;&#30340;It\^o&#25193;&#25955;&#30340;&#25968;&#25454;&#65292;&#29305;&#21035;&#26159;&#25152;&#26377;&#22352;&#26631;&#21516;&#26102;&#35266;&#27979;&#21040;&#30340;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#21033;&#29992;&#31614;&#21517;&#21464;&#25442;&#30340;&#37325;&#26500;&#24615;&#36136;&#23558;&#36825;&#20123;&#32467;&#26524;&#25512;&#24191;&#21040;&#36890;&#29992;&#30340;&#12289;&#21487;&#33021;&#26159;&#38750;&#39532;&#23572;&#21487;&#22827;&#25110;&#19981;&#36830;&#32493;&#30340;&#38543;&#26426;&#36807;&#31243;&#65292;&#24182;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#25903;&#25345;&#20102;&#36825;&#20123;&#29702;&#35770;&#32467;&#26524;&#65292;&#22312;&#38750;&#39532;&#23572;&#21487;&#22827;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#36335;&#24452;&#30456;&#20851;&#30340;NJ-ODE&#20248;&#20110;&#21407;&#22987;NJ-ODE&#26694;&#26550;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;PD-NJ-ODE&#21487;&#20197;&#25104;&#21151;&#24212;&#29992;&#20110;&#32463;&#20856;&#30340;&#38543;&#26426;&#28388;&#27874;&#38382;&#39064;&#21644;&#38480;&#20215;&#35746;&#21333;&#31807;&#65288;LOB&#65289;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the problem of forecasting general stochastic processes using a path-dependent extension of the Neural Jump ODE (NJ-ODE) framework. While NJ-ODE was the first framework to establish convergence guarantees for the prediction of irregularly observed time series, these results were limited to data stemming from It\^o-diffusions with complete observations, in particular Markov processes where all coordinates are observed simultaneously. In this work, we generalise these results to generic, possibly non-Markovian or discontinuous, stochastic processes with incomplete observations, by utilising the reconstruction properties of the signature transform. These theoretical results are supported by empirical studies, where it is shown that the path-dependent NJ-ODE outperforms the original NJ-ODE framework in the case of non-Markovian data. Moreover, we show that PD-NJ-ODE can be applied successfully to classical stochastic filtering problems and to limit order book (LOB) data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#26041;&#27861;&#30340;&#38750;&#24179;&#31283;&#32447;&#24615;&#36172;&#33218;&#31639;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#22823;&#35268;&#27169;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#39640;&#32500;&#19978;&#19979;&#25991;&#20449;&#24687;&#12290;&#36890;&#36807;&#20351;&#29992;&#38543;&#26426;&#25237;&#24433;&#21644;&#25351;&#25968;&#22686;&#38271;&#30340;&#26435;&#37325;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#36866;&#24212;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#30340;&#21160;&#24577;&#21464;&#21270;&#65292;&#24182;&#21462;&#24471;&#20102;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2202.03167</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#36125;&#21494;&#26031;&#38750;&#24179;&#31283;&#32447;&#24615;&#36172;&#33218;
&lt;/p&gt;
&lt;p&gt;
Bayesian Non-stationary Linear Bandits for Large-Scale Recommender Systems. (arXiv:2202.03167v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.03167
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#26041;&#27861;&#30340;&#38750;&#24179;&#31283;&#32447;&#24615;&#36172;&#33218;&#31639;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#22823;&#35268;&#27169;&#25512;&#33616;&#31995;&#32479;&#20013;&#30340;&#39640;&#32500;&#19978;&#19979;&#25991;&#20449;&#24687;&#12290;&#36890;&#36807;&#20351;&#29992;&#38543;&#26426;&#25237;&#24433;&#21644;&#25351;&#25968;&#22686;&#38271;&#30340;&#26435;&#37325;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#36866;&#24212;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#30340;&#21160;&#24577;&#21464;&#21270;&#65292;&#24182;&#21462;&#24471;&#20102;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20805;&#20998;&#21033;&#29992;&#19978;&#19979;&#25991;&#20449;&#24687;&#21487;&#33021;&#20250;&#25552;&#39640;&#25512;&#33616;&#31995;&#32479;&#30340;&#24615;&#33021;&#12290;&#22312;&#22823;&#25968;&#25454;&#26102;&#20195;&#65292;&#36825;&#31181;&#38468;&#21152;&#20449;&#24687;&#36890;&#24120;&#20855;&#26377;&#22810;&#20010;&#32500;&#24230;&#12290;&#22240;&#27492;&#65292;&#24320;&#21457;&#33021;&#22815;&#23454;&#26102;&#22788;&#29702;&#36825;&#31181;&#39640;&#32500;&#19978;&#19979;&#25991;&#30340;&#20915;&#31574;&#31639;&#27861;&#38750;&#24120;&#37325;&#35201;&#12290;&#24403;&#20915;&#31574;&#32773;&#38656;&#35201;&#25512;&#33616;&#22810;&#31181;&#29289;&#21697;&#26102;&#65292;&#36825;&#20855;&#26377;&#29305;&#27530;&#30340;&#25361;&#25112;&#24615;&#12290;&#27492;&#22806;&#65292;&#29289;&#21697;&#30340;&#27969;&#34892;&#24230;&#25110;&#29992;&#25143;&#30340;&#20559;&#22909;&#21464;&#21270;&#21487;&#33021;&#20250;&#30001;&#20110;&#29615;&#22659;&#20013;&#20998;&#24067;&#21464;&#21270;&#30340;&#40065;&#26834;&#24615;&#19981;&#36275;&#32780;&#24433;&#21709;&#24050;&#37096;&#32626;&#25512;&#33616;&#31995;&#32479;&#30340;&#24615;&#33021;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#22312;&#32447;&#24615;&#19978;&#19979;&#25991;&#22810;&#33218;&#36172;&#21338;&#26426;&#26694;&#26550;&#30340;&#22522;&#30784;&#19978;&#35299;&#20915;&#20102;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#38024;&#23545;&#39640;&#32500;&#29305;&#24449;&#21521;&#37327;&#12289;&#22823;&#37327;&#33218;&#21644;&#38750;&#24179;&#31283;&#29983;&#25104;&#22870;&#21169;&#30340;&#38382;&#39064;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#27748;&#26222;&#26862;&#25277;&#26679;&#30340;&#20915;&#31574;&#31574;&#30053;&#12290;&#25105;&#20204;&#30340;&#31574;&#30053;&#36890;&#36807;&#38543;&#26426;&#25237;&#24433;&#20943;&#23569;&#20102;&#29305;&#24449;&#21521;&#37327;&#30340;&#32500;&#24230;&#65292;&#24182;&#20351;&#29992;&#20102;&#25351;&#25968;&#22686;&#38271;&#30340;&#26435;&#37325;&#26469;&#36866;&#24212;&#38750;&#24179;&#31283;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Taking advantage of contextual information can potentially boost the performance of recommender systems. In the era of big data, such side information often has several dimensions. Thus, developing decision-making algorithms to cope with such a high-dimensional context in real time is essential. That is specifically challenging when the decision-maker has a variety of items to recommend. In addition, changes in items' popularity or users' preferences can hinder the performance of the deployed recommender system due to a lack of robustness to distribution shifts in the environment. In this paper, we build upon the linear contextual multi-armed bandit framework to address this problem. We develop a decision-making policy for a linear bandit problem with high-dimensional feature vectors, a large set of arms, and non-stationary reward-generating processes. Our Thompson sampling-based policy reduces the dimension of feature vectors using random projection and uses exponentially increasing w
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#36125;&#21494;&#26031;&#26368;&#20248;&#33218;&#35782;&#21035;&#30340;&#36895;&#29575;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#26131;&#34892;&#30340;&#31639;&#27861;&#65292;&#20854;&#21305;&#37197;&#20102;&#19979;&#30028;&#65292;&#21482;&#24046;&#19968;&#20010;&#24120;&#25968;&#22240;&#23376;&#12290;</title><link>http://arxiv.org/abs/2111.09885</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#26368;&#20248;&#33218;&#35782;&#21035;&#20013;&#30340;&#26368;&#20248;&#31616;&#21333;&#36951;&#25022;
&lt;/p&gt;
&lt;p&gt;
Optimal Simple Regret in Bayesian Best Arm Identification. (arXiv:2111.09885v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.09885
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#36125;&#21494;&#26031;&#26368;&#20248;&#33218;&#35782;&#21035;&#30340;&#36895;&#29575;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#26131;&#34892;&#30340;&#31639;&#27861;&#65292;&#20854;&#21305;&#37197;&#20102;&#19979;&#30028;&#65292;&#21482;&#24046;&#19968;&#20010;&#24120;&#25968;&#22240;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#30340;&#26368;&#20248;&#33218;&#35782;&#21035;&#12290;&#22312;&#20808;&#39564;&#26465;&#20214;&#20855;&#26377;&#19968;&#23450;&#30340;&#36830;&#32493;&#24615;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#34920;&#24449;&#20102;&#36125;&#21494;&#26031;&#31616;&#21333;&#36951;&#25022;&#30340;&#36895;&#29575;&#12290;&#19982;&#36125;&#21494;&#26031;&#36951;&#25022;&#26368;&#23567;&#21270;&#19981;&#21516;&#65292;&#36125;&#21494;&#26031;&#31616;&#21333;&#36951;&#25022;&#30340;&#20027;&#23548;&#39033;&#26469;&#28304;&#20110;&#26368;&#20248;&#33218;&#21644;&#27425;&#20248;&#33218;&#20043;&#38388;&#38388;&#38553;&#23567;&#20110;$\sqrt{\frac{\log T}{T}}$&#30340;&#21306;&#22495;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#26131;&#34892;&#30340;&#35745;&#31639;&#31639;&#27861;&#65292;&#20854;&#20027;&#23548;&#39033;&#21305;&#37197;&#20102;&#19979;&#30028;&#65292;&#21482;&#24046;&#19968;&#20010;&#24120;&#25968;&#22240;&#23376;&#65307;&#27169;&#25311;&#32467;&#26524;&#25903;&#25345;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider best arm identification in the multi-armed bandit problem. Assuming certain continuity conditions of the prior, we characterize the rate of the Bayesian simple regret. Differing from Bayesian regret minimization (Lai, 1987), the leading term in the Bayesian simple regret derives from the region where the gap between optimal and suboptimal arms is smaller than $\sqrt{\frac{\log T}{T}}$. We propose a simple and easy-to-compute algorithm with its leading term matching with the lower bound up to a constant factor; simulation results support our theoretical findings.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#38750;&#20809;&#28369;&#38543;&#26426;&#20248;&#21270;&#20013;&#65292;&#38543;&#26426;&#23376;&#26799;&#24230;&#19979;&#38477;&#27861;&#65288;SGD&#65289;&#23545;&#27963;&#21160;&#20005;&#26684;&#38797;&#28857;&#30340;&#38750;&#25910;&#25947;&#24615;&#12290;&#36890;&#36807;&#24341;&#20837;Verdier&#20998;&#23618;&#26465;&#20214;&#21644;&#35282;&#24230;&#26465;&#20214;&#65292;&#25105;&#20204;&#34920;&#26126;&#22312;&#24369;&#20984;&#20989;&#25968;&#31867;&#20013;&#65292;SGD&#36890;&#24120;&#25910;&#25947;&#20110;&#23616;&#37096;&#26497;&#23567;&#20540;&#28857;&#12290;</title><link>http://arxiv.org/abs/2108.02072</link><description>&lt;p&gt;
&#38543;&#26426;&#23376;&#26799;&#24230;&#19979;&#38477;&#36867;&#31163;&#24369;&#20984;&#20989;&#25968;&#30340;&#27963;&#21160;&#20005;&#26684;&#38797;&#28857;
&lt;/p&gt;
&lt;p&gt;
Stochastic Subgradient Descent Escapes Active Strict Saddles on Weakly Convex Functions. (arXiv:2108.02072v4 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2108.02072
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#38750;&#20809;&#28369;&#38543;&#26426;&#20248;&#21270;&#20013;&#65292;&#38543;&#26426;&#23376;&#26799;&#24230;&#19979;&#38477;&#27861;&#65288;SGD&#65289;&#23545;&#27963;&#21160;&#20005;&#26684;&#38797;&#28857;&#30340;&#38750;&#25910;&#25947;&#24615;&#12290;&#36890;&#36807;&#24341;&#20837;Verdier&#20998;&#23618;&#26465;&#20214;&#21644;&#35282;&#24230;&#26465;&#20214;&#65292;&#25105;&#20204;&#34920;&#26126;&#22312;&#24369;&#20984;&#20989;&#25968;&#31867;&#20013;&#65292;SGD&#36890;&#24120;&#25910;&#25947;&#20110;&#23616;&#37096;&#26497;&#23567;&#20540;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#38750;&#20809;&#28369;&#38543;&#26426;&#20248;&#21270;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#38543;&#26426;&#23376;&#26799;&#24230;&#19979;&#38477;&#27861;&#65288;SGD&#65289;&#23545;&#26368;&#36817;&#30001;Davis&#21644;Drusvyatskiy&#31216;&#20026;&#27963;&#21160;&#20005;&#26684;&#38797;&#28857;&#30340;&#25910;&#25947;&#24615;&#22833;&#36133;&#12290;&#36825;&#20123;&#28857;&#20301;&#20110;&#20989;&#25968;$f$&#20855;&#26377;&#20108;&#38454;&#36127;&#26354;&#29575;&#26041;&#21521;&#30340;&#27969;&#24418;$M$&#19978;&#12290;&#22312;&#36825;&#20010;&#27969;&#24418;&#20043;&#22806;&#65292;$f$&#30340;Clarke&#20122;&#24494;&#20998;&#30340;&#33539;&#25968;&#26377;&#19979;&#30028;&#12290;&#25105;&#20204;&#23545;$f$&#26377;&#20004;&#20010;&#26465;&#20214;&#12290;&#31532;&#19968;&#20010;&#20551;&#35774;&#26159;&#19968;&#20010;Verdier&#20998;&#23618;&#26465;&#20214;&#65292;&#23427;&#26159;Whitney&#20998;&#23618;&#30340;&#19968;&#31181;&#32454;&#21270;&#12290;&#23427;&#20351;&#25105;&#20204;&#33021;&#22815;&#24314;&#31435;Bolte&#31561;&#20154;&#20851;&#20110;Whitney&#20998;&#23618;&#20989;&#25968;&#30340;&#25237;&#24433;&#20844;&#24335;&#30340;&#22686;&#24378;&#29256;&#26412;&#65292;&#36825;&#23545;&#29420;&#31435;&#30340;&#20852;&#36259;&#12290;&#31532;&#20108;&#20010;&#20551;&#35774;&#65292;&#31216;&#20026;&#35282;&#24230;&#26465;&#20214;&#65292;&#21487;&#20197;&#25511;&#21046;&#36845;&#20195;&#28857;&#21040;$M$&#30340;&#36317;&#31163;&#12290;&#24403;$f$&#26159;&#24369;&#20984;&#30340;&#26102;&#20505;&#65292;&#25105;&#20204;&#30340;&#20551;&#35774;&#26159;&#27867;&#21270;&#30340;&#12290;&#22240;&#27492;&#65292;&#22312;&#21487;&#23450;&#20041;&#30340;&#24369;&#20984;&#20989;&#25968;&#31867;&#20013;&#65292;SGD&#36890;&#24120;&#25910;&#25947;&#20110;&#23616;&#37096;&#26497;&#23567;&#20540;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
In non-smooth stochastic optimization, we establish the non-convergence of the stochastic subgradient descent (SGD) to the critical points recently called active strict saddles by Davis and Drusvyatskiy. Such points lie on a manifold $M$ where the function $f$ has a direction of second-order negative curvature. Off this manifold, the norm of the Clarke subdifferential of $f$ is lower-bounded. We require two conditions on $f$. The first assumption is a Verdier stratification condition, which is a refinement of the popular Whitney stratification. It allows us to establish a reinforced version of the projection formula of Bolte \emph{et.al.} for Whitney stratifiable functions, and which is of independent interest. The second assumption, termed the angle condition, allows to control the distance of the iterates to $M$. When $f$ is weakly convex, our assumptions are generic. Consequently, generically in the class of definable weakly convex functions, the SGD converges to a local minimizer.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#21463;&#38480;&#20998;&#31867;&#21644;&#31574;&#30053;&#23398;&#20064;&#20013;&#26367;&#20195;&#25439;&#22833;&#31243;&#24207;&#30340;&#19968;&#33268;&#24615;&#21644;&#36866;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2106.12886</link><description>&lt;p&gt;
&#21463;&#38480;&#20998;&#31867;&#21644;&#31574;&#30053;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Constrained Classification and Policy Learning. (arXiv:2106.12886v2 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.12886
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#21463;&#38480;&#20998;&#31867;&#21644;&#31574;&#30053;&#23398;&#20064;&#20013;&#26367;&#20195;&#25439;&#22833;&#31243;&#24207;&#30340;&#19968;&#33268;&#24615;&#21644;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#23545;&#20110;&#20998;&#31867;&#38382;&#39064;&#20351;&#29992;&#20102;&#19968;&#20123;&#26367;&#20195;&#25439;&#22833;&#25216;&#26415;&#65292;&#22914;AdaBoost&#12289;&#25903;&#25345;&#21521;&#37327;&#26426;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#20197;&#32469;&#36807;&#26368;&#23567;&#21270;&#32463;&#39564;&#20998;&#31867;&#39118;&#38505;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#12290;&#36825;&#20123;&#25216;&#26415;&#22312;&#22240;&#26524;&#31574;&#30053;&#23398;&#20064;&#38382;&#39064;&#20013;&#20063;&#24456;&#26377;&#29992;&#65292;&#22240;&#20026;&#20010;&#24615;&#21270;&#27835;&#30103;&#35268;&#21017;&#30340;&#20272;&#35745;&#21487;&#20197;&#34987;&#35270;&#20026;&#19968;&#31181;&#21152;&#26435;&#65288;&#25104;&#26412;&#25935;&#24863;&#65289;&#20998;&#31867;&#38382;&#39064;&#12290;Zhang&#65288;2004&#24180;&#65289;&#21644;Bartlett&#31561;&#20154;&#65288;2006&#24180;&#65289;&#30740;&#31350;&#30340;&#26367;&#20195;&#25439;&#22833;&#26041;&#27861;&#30340;&#19968;&#33268;&#24615;&#20851;&#38190;&#20381;&#36182;&#20110;&#27491;&#30830;&#35268;&#33539;&#30340;&#20551;&#35774;&#65292;&#21363;&#25351;&#23450;&#30340;&#20998;&#31867;&#22120;&#38598;&#21512;&#36275;&#22815;&#20016;&#23500;&#65292;&#21253;&#21547;&#19968;&#20010;&#26368;&#20339;&#20998;&#31867;&#22120;&#12290;&#28982;&#32780;&#65292;&#24403;&#20998;&#31867;&#22120;&#38598;&#21512;&#21463;&#21040;&#21487;&#35299;&#37322;&#24615;&#25110;&#20844;&#24179;&#24615;&#30340;&#38480;&#21046;&#26102;&#65292;&#36825;&#20010;&#20551;&#35774;&#36739;&#19981;&#21487;&#38752;&#65292;&#36825;&#23548;&#33268;&#22312;&#36825;&#31181;&#27425;&#20339;&#24773;&#26223;&#19979;&#26367;&#20195;&#25439;&#22833;&#26041;&#27861;&#30340;&#36866;&#29992;&#24615;&#26410;&#30693;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#21463;&#38480;&#31867;&#38598;&#21512;&#26465;&#20214;&#19979;&#30340;&#26367;&#20195;&#25439;&#22833;&#31243;&#24207;&#30340;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern machine learning approaches to classification, including AdaBoost, support vector machines, and deep neural networks, utilize surrogate loss techniques to circumvent the computational complexity of minimizing empirical classification risk. These techniques are also useful for causal policy learning problems, since estimation of individualized treatment rules can be cast as a weighted (cost-sensitive) classification problem. Consistency of the surrogate loss approaches studied in Zhang (2004) and Bartlett et al. (2006) crucially relies on the assumption of correct specification, meaning that the specified set of classifiers is rich enough to contain a first-best classifier. This assumption is, however, less credible when the set of classifiers is constrained by interpretability or fairness, leaving the applicability of surrogate loss based algorithms unknown in such second-best scenarios. This paper studies consistency of surrogate loss procedures under a constrained set of class
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22122;&#22768;&#20302;&#31209;&#30697;&#38453;&#24674;&#22797;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#40065;&#26834;&#38169;&#35823;&#23450;&#20301;&#20960;&#20309;&#20998;&#26512;&#31639;&#27861;&#21644;&#36830;&#32493;&#23376;&#31354;&#38388;&#20248;&#21270;&#31639;&#27861;&#65292;&#20998;&#21035;&#29992;&#20110;&#31934;&#30830;&#21442;&#25968;&#21270;&#21644;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#24773;&#20917;&#12290;&#36890;&#36807;&#32422;&#26463;&#31561;&#24322;&#24615;&#24615;&#36136;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#20840;&#23616;&#26368;&#20248;&#35299;&#19982;&#23616;&#37096;&#35299;&#20043;&#38388;&#30340;&#26368;&#22823;&#36317;&#31163;&#30340;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2105.08232</link><description>&lt;p&gt;
&#22122;&#22768;&#20302;&#31209;&#30697;&#38453;&#24674;&#22797;&#30340;&#20960;&#20309;&#20998;&#26512;&#22312;&#31934;&#30830;&#21442;&#25968;&#21270;&#21644;&#36807;&#24230;&#21442;&#25968;&#21270;&#21306;&#38388;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Geometric Analysis of Noisy Low-rank Matrix Recovery in the Exact Parameterized and the Overparameterized Regimes. (arXiv:2105.08232v3 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2105.08232
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22122;&#22768;&#20302;&#31209;&#30697;&#38453;&#24674;&#22797;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#40065;&#26834;&#38169;&#35823;&#23450;&#20301;&#20960;&#20309;&#20998;&#26512;&#31639;&#27861;&#21644;&#36830;&#32493;&#23376;&#31354;&#38388;&#20248;&#21270;&#31639;&#27861;&#65292;&#20998;&#21035;&#29992;&#20110;&#31934;&#30830;&#21442;&#25968;&#21270;&#21644;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#24773;&#20917;&#12290;&#36890;&#36807;&#32422;&#26463;&#31561;&#24322;&#24615;&#24615;&#36136;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#20840;&#23616;&#26368;&#20248;&#35299;&#19982;&#23616;&#37096;&#35299;&#20043;&#38388;&#30340;&#26368;&#22823;&#36317;&#31163;&#30340;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30697;&#38453;&#24863;&#30693;&#38382;&#39064;&#26159;&#19968;&#31181;&#37325;&#35201;&#30340;&#20302;&#31209;&#20248;&#21270;&#38382;&#39064;&#65292;&#22312;&#30697;&#38453;&#34917;&#20840;&#12289;&#30456;&#20301;&#21516;&#27493;/&#24674;&#22797;&#12289;&#31283;&#20581;PCA&#21644;&#30005;&#21147;&#31995;&#32479;&#29366;&#24577;&#20272;&#35745;&#31561;&#39046;&#22495;&#37117;&#26377;&#24191;&#27867;&#24212;&#29992;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#36890;&#36807;&#32447;&#24615;&#27979;&#37327;&#25439;&#22351;&#30340;&#22122;&#22768;&#20302;&#31209;&#30697;&#38453;&#24863;&#30693;&#38382;&#39064;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#25628;&#32034;&#31209;r&#31561;&#20110;&#26410;&#30693;&#30495;&#23454;&#31209;r*&#30340;&#24773;&#20917;&#65288;&#31934;&#30830;&#21442;&#25968;&#21270;&#24773;&#20917;&#65289;&#65292;&#20197;&#21450;r&#22823;&#20110;r*&#30340;&#24773;&#20917;&#65288;&#36807;&#24230;&#21442;&#25968;&#21270;&#24773;&#20917;&#65289;&#12290;&#25105;&#20204;&#37327;&#21270;&#20102;&#32422;&#26463;&#31561;&#24322;&#24615;&#24615;&#36136;&#65288;restricted isometry property&#65292;RIP&#65289;&#22312;&#22609;&#36896;&#38750;&#20984;&#20998;&#35299;&#20844;&#24335;&#30340;&#25972;&#20307;&#26223;&#35266;&#21644;&#24110;&#21161;&#23616;&#37096;&#25628;&#32034;&#31639;&#27861;&#25104;&#21151;&#26041;&#38754;&#30340;&#20316;&#29992;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#22312;RIP&#24120;&#25968;&#23567;&#20110; 1/(1+sqrt(r*/r))&#30340;&#20551;&#35774;&#19979;&#65292;&#23545;&#38750;&#20984;&#38382;&#39064;&#30340;&#20219;&#24847;&#23616;&#37096;&#26497;&#23567;&#20540;&#21644;&#30495;&#23454;&#20540;&#20043;&#38388;&#30340;&#26368;&#22823;&#36317;&#31163;&#36827;&#34892;&#20102;&#20840;&#23616;&#20445;&#35777;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;&#40065;&#26834;&#38169;&#35823;&#23450;&#20301;&#20960;&#20309;&#20998;&#26512;&#65288;Robust Error-Locating Geometric Analysis&#65292;RELGA&#65289;&#31639;&#27861;&#65292;&#29992;&#20110;&#23454;&#29616;&#22312;&#23384;&#22312;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#30340;&#31934;&#30830;&#20302;&#31209;&#30697;&#38453;&#24674;&#22797;&#12290;RELGA&#31639;&#27861;&#36890;&#36807;&#32452;&#21512;&#38169;&#35823;&#23450;&#20301;&#26426;&#21046;&#21644;&#20960;&#20309;&#20998;&#26512;&#65292;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#65292;&#21363;&#20351;&#22312;&#22122;&#22768;&#27700;&#24179;&#30456;&#23545;&#36739;&#22823;&#30340;&#24773;&#20917;&#19979;&#65292;&#20063;&#21487;&#20197;&#23454;&#29616;&#31934;&#30830;&#30340;&#30697;&#38453;&#24674;&#22797;&#12290;&#23545;&#20110;&#36807;&#24230;&#21442;&#25968;&#21270;&#24773;&#20917;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23616;&#37096;&#25628;&#32034;&#31639;&#27861;&#65292;&#31216;&#20026;&#36830;&#32493;&#23376;&#31354;&#38388;&#20248;&#21270;&#65288;Successive Subspace Optimization&#65292;SSO&#65289;&#31639;&#27861;&#65292;&#22312;&#22122;&#22768;&#27700;&#24179;&#21644;RIP&#24120;&#25968;&#30340;&#19968;&#23450;&#26465;&#20214;&#19979;&#65292;&#21487;&#20197;&#25910;&#25947;&#21040;&#30495;&#23454;&#35299;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#25581;&#31034;&#20102;SSO&#30340;&#25104;&#21151;&#21462;&#20915;&#20110;&#21021;&#22987;&#21270;&#12289;&#38750;&#36864;&#21270;&#24615;&#21644;&#20960;&#20309;&#26465;&#20214;&#30340;&#32452;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
The matrix sensing problem is an important low-rank optimization problem that has found a wide range of applications, such as matrix completion, phase synchornization/retrieval, robust PCA, and power system state estimation. In this work, we focus on the general matrix sensing problem with linear measurements that are corrupted by random noise. We investigate the scenario where the search rank $r$ is equal to the true rank $r^*$ of the unknown ground truth (the exact parametrized case), as well as the scenario where $r$ is greater than $r^*$ (the overparametrized case). We quantify the role of the restricted isometry property (RIP) in shaping the landscape of the non-convex factorized formulation and assisting with the success of local search algorithms. First, we develop a global guarantee on the maximum distance between an arbitrary local minimizer of the non-convex problem and the ground truth under the assumption that the RIP constant is smaller than $1/(1+\sqrt{r^*/r})$. We then p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992;&#22797;&#21046;&#26041;&#27861;&#20272;&#35745;&#20102;&#20855;&#26377;&#39532;&#23572;&#31185;&#22827;&#25110;&#38544;&#39532;&#23572;&#31185;&#22827;&#20449;&#21495;&#20808;&#39564;&#30340;&#32447;&#24615;&#27169;&#22411;&#30340;&#33258;&#30001;&#33021;&#12289;&#24179;&#22343;&#20114;&#20449;&#24687;&#21644;&#26368;&#23567;&#22343;&#26041;&#35823;&#24046;&#65288;MMSE&#65289;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#21518;&#39564;&#22343;&#20540;&#20272;&#35745;&#22120;&#19979;&#65292;&#32447;&#24615;&#27169;&#22411;&#21487;&#20197;&#20998;&#35299;&#20026;&#20855;&#26377;&#29366;&#24577;&#20449;&#24687;&#30340;&#21333;&#36755;&#20837;AWGN&#20449;&#36947;&#65292;&#32780;&#29366;&#24577;&#20998;&#24067;&#36981;&#24490;&#39532;&#23572;&#31185;&#22827;&#38142;&#30340;&#38543;&#26426;&#30697;&#38453;&#30340;&#24038;Perron-Frobenius&#29305;&#24449;&#21521;&#37327;&#12290;&#25968;&#20540;&#32467;&#26524;&#35777;&#26126;&#65292;&#36890;&#36807;&#22797;&#21046;&#26041;&#27861;&#24471;&#21040;&#30340;&#32467;&#26524;&#19982;Metropolis-Hastings&#31639;&#27861;&#25110;&#20854;&#20182;&#36817;&#20284;&#20256;&#36882;&#31639;&#27861;&#30340;&#32467;&#26524;&#38750;&#24120;&#25509;&#36817;&#12290;</title><link>http://arxiv.org/abs/2009.13370</link><description>&lt;p&gt;
&#20855;&#26377;&#39532;&#23572;&#31185;&#22827;&#25110;&#38544;&#39532;&#23572;&#31185;&#22827;&#20449;&#21495;&#20808;&#39564;&#30340;&#32447;&#24615;&#27169;&#22411;&#30340;&#22797;&#21046;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Replica Analysis of the Linear Model with Markov or Hidden Markov Signal Priors. (arXiv:2009.13370v5 [cs.IT] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2009.13370
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#22797;&#21046;&#26041;&#27861;&#20272;&#35745;&#20102;&#20855;&#26377;&#39532;&#23572;&#31185;&#22827;&#25110;&#38544;&#39532;&#23572;&#31185;&#22827;&#20449;&#21495;&#20808;&#39564;&#30340;&#32447;&#24615;&#27169;&#22411;&#30340;&#33258;&#30001;&#33021;&#12289;&#24179;&#22343;&#20114;&#20449;&#24687;&#21644;&#26368;&#23567;&#22343;&#26041;&#35823;&#24046;&#65288;MMSE&#65289;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#21518;&#39564;&#22343;&#20540;&#20272;&#35745;&#22120;&#19979;&#65292;&#32447;&#24615;&#27169;&#22411;&#21487;&#20197;&#20998;&#35299;&#20026;&#20855;&#26377;&#29366;&#24577;&#20449;&#24687;&#30340;&#21333;&#36755;&#20837;AWGN&#20449;&#36947;&#65292;&#32780;&#29366;&#24577;&#20998;&#24067;&#36981;&#24490;&#39532;&#23572;&#31185;&#22827;&#38142;&#30340;&#38543;&#26426;&#30697;&#38453;&#30340;&#24038;Perron-Frobenius&#29305;&#24449;&#21521;&#37327;&#12290;&#25968;&#20540;&#32467;&#26524;&#35777;&#26126;&#65292;&#36890;&#36807;&#22797;&#21046;&#26041;&#27861;&#24471;&#21040;&#30340;&#32467;&#26524;&#19982;Metropolis-Hastings&#31639;&#27861;&#25110;&#20854;&#20182;&#36817;&#20284;&#20256;&#36882;&#31639;&#27861;&#30340;&#32467;&#26524;&#38750;&#24120;&#25509;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22522;&#20110;&#32479;&#35745;&#29289;&#29702;&#20013;&#30340;&#22797;&#21046;&#26041;&#27861;&#65292;&#20272;&#35745;&#20102;&#22312;&#32447;&#24615;&#27169;&#22411;&#19979;&#30340;&#33258;&#30001;&#33021;&#12289;&#24179;&#22343;&#20114;&#20449;&#24687;&#21644;&#26368;&#23567;&#22343;&#26041;&#35823;&#24046;&#65288;MMSE&#65289;&#65292;&#24182;&#20551;&#35774;&#20102;&#20004;&#20010;&#26465;&#20214;&#65306;&#65288;1&#65289;&#28304;&#30001;&#39532;&#23572;&#31185;&#22827;&#38142;&#29983;&#25104;&#65292;&#65288;2&#65289;&#28304;&#36890;&#36807;&#38544;&#34255;&#39532;&#23572;&#31185;&#22827;&#27169;&#22411;&#29983;&#25104;&#12290;&#25105;&#20204;&#30340;&#20272;&#35745;&#26159;&#22522;&#20110;&#21518;&#39564;&#22343;&#20540;&#20272;&#35745;&#22120;&#65292;&#34920;&#26126;&#20855;&#26377;&#39532;&#23572;&#31185;&#22827;&#28304;&#25110;&#38544;&#34255;&#39532;&#23572;&#31185;&#22827;&#28304;&#30340;&#32447;&#24615;&#27169;&#22411;&#21487;&#20197;&#20998;&#35299;&#20026;&#20855;&#26377;&#29366;&#24577;&#20449;&#24687;&#30340;&#21333;&#36755;&#20837;AWGN&#20449;&#36947;&#65292;&#20854;&#20013;&#29366;&#24577;&#20998;&#24067;&#36981;&#24490;&#39532;&#23572;&#31185;&#22827;&#38142;&#30340;&#38543;&#26426;&#30697;&#38453;&#30340;&#24038;Perron-Frobenius&#29305;&#24449;&#21521;&#37327;&#65292;&#20854;&#26364;&#21704;&#39039;&#33539;&#25968;&#20026;1&#12290;&#25968;&#20540;&#32467;&#26524;&#34920;&#26126;&#65292;&#36890;&#36807;&#22797;&#21046;&#26041;&#27861;&#33719;&#24471;&#30340;&#33258;&#30001;&#33021;&#21644;&#22343;&#26041;&#35823;&#24046;&#19982;&#30740;&#31350;&#25991;&#29486;&#20013;Metropolis-Hastings&#31639;&#27861;&#25110;&#19968;&#20123;&#20247;&#25152;&#21608;&#30693;&#30340;&#36817;&#20284;&#20256;&#36882;&#31639;&#27861;&#30340;&#23545;&#24212;&#32467;&#26524;&#38750;&#24120;&#25509;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper estimates free energy, average mutual information, and minimum mean square error (MMSE) of a linear model under two assumptions: (1) the source is generated by a Markov chain, (2) the source is generated via a hidden Markov model. Our estimates are based on the replica method in statistical physics. We show that under the posterior mean estimator, the linear model with Markov sources or hidden Markov sources is decoupled into single-input AWGN channels with state information available at both encoder and decoder where the state distribution follows the left Perron-Frobenius eigenvector with unit Manhattan norm of the stochastic matrix of Markov chains. Numerical results show that the free energies and MSEs obtained via the replica method are closely approximate to their counterparts achieved by the Metropolis-Hastings algorithm or some well-known approximate message passing algorithms in the research literature.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20154;&#24037;&#31070;&#32463;&#20803;&#27169;&#22411;&#21644;&#28608;&#27963;&#20989;&#25968;&#65292;&#36890;&#36807;&#20351;&#29992;&#21333;&#20010;&#31070;&#32463;&#20803;&#23398;&#20064;&#38750;&#32447;&#24615;&#20915;&#31574;&#36793;&#30028;&#65292;&#24182;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2003.03229</link><description>&lt;p&gt;
&#20855;&#26377;&#31867;&#20154;&#31867;&#26641;&#31361;&#28608;&#27963;&#30340;&#38750;&#32447;&#24615;&#31070;&#32463;&#20803;
&lt;/p&gt;
&lt;p&gt;
Non-linear Neurons with Human-like Apical Dendrite Activations. (arXiv:2003.03229v4 [cs.NE] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2003.03229
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20154;&#24037;&#31070;&#32463;&#20803;&#27169;&#22411;&#21644;&#28608;&#27963;&#20989;&#25968;&#65292;&#36890;&#36807;&#20351;&#29992;&#21333;&#20010;&#31070;&#32463;&#20803;&#23398;&#20064;&#38750;&#32447;&#24615;&#20915;&#31574;&#36793;&#30028;&#65292;&#24182;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#23545;&#32447;&#24615;&#19981;&#21487;&#20998;&#30340;&#25968;&#25454;&#36827;&#34892;&#20998;&#31867;&#65292;&#36890;&#24120;&#23558;&#31070;&#32463;&#20803;&#32452;&#32455;&#25104;&#33267;&#23569;&#21253;&#21547;&#19968;&#20010;&#38544;&#34255;&#23618;&#30340;&#22810;&#23618;&#31070;&#32463;&#32593;&#32476;&#12290;&#21463;&#31070;&#32463;&#31185;&#23398;&#30340;&#19968;&#20123;&#26368;&#26032;&#21457;&#29616;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20154;&#24037;&#31070;&#32463;&#20803;&#27169;&#22411;&#21644;&#19968;&#31181;&#26032;&#39062;&#30340;&#28608;&#27963;&#20989;&#25968;&#65292;&#21487;&#20351;&#29992;&#21333;&#20010;&#31070;&#32463;&#20803;&#23398;&#20064;&#38750;&#32447;&#24615;&#20915;&#31574;&#36793;&#30028;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#20010;&#26631;&#20934;&#31070;&#32463;&#20803;&#25509;&#19978;&#25105;&#20204;&#30340;&#26032;&#22411;&#26641;&#31361;&#28608;&#27963;&#20989;&#25968;&#65288;ADA&#65289;&#21487;&#20197;&#20197;100%&#30340;&#20934;&#30830;&#29575;&#23398;&#20064;XOR&#36923;&#36753;&#20989;&#25968;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23545;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#20449;&#21495;&#22788;&#29702;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#30340;&#20845;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#21363;MOROCO&#12289;UTKFace&#12289;CREMA-D&#12289;Fashion-MNIST&#12289;Tiny ImageNet&#21644;ImageNet&#65292;&#32467;&#26524;&#26174;&#31034;ADA&#21644;&#28431;&#30005;ADA&#20989;&#25968;&#22312;&#21508;&#31181;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#65288;&#22914;&#19968;&#23618;&#25110;&#20004;&#23618;&#38544;&#34255;&#23618;&#30340;&#22810;&#23618;&#24863;&#30693;&#26426;&#21644;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65289;&#19978;&#20248;&#20110;&#20462;&#27491;&#32447;&#24615;&#21333;&#20803;&#65288;ReLU&#65289;&#12289;&#28431;&#30005;ReLU&#12289;&#24452;&#21521;&#22522;&#20989;&#25968;&#65288;RBF&#65289;&#21644;Swish&#12290;
&lt;/p&gt;
&lt;p&gt;
In order to classify linearly non-separable data, neurons are typically organized into multi-layer neural networks that are equipped with at least one hidden layer. Inspired by some recent discoveries in neuroscience, we propose a new model of artificial neuron along with a novel activation function enabling the learning of nonlinear decision boundaries using a single neuron. We show that a standard neuron followed by our novel apical dendrite activation (ADA) can learn the XOR logical function with 100% accuracy. Furthermore, we conduct experiments on six benchmark data sets from computer vision, signal processing and natural language processing, i.e. MOROCO, UTKFace, CREMA-D, Fashion-MNIST, Tiny ImageNet and ImageNet, showing that the ADA and the leaky ADA functions provide superior results to Rectified Linear Units (ReLU), leaky ReLU, RBF and Swish, for various neural network architectures, e.g. one-hidden-layer or two-hidden-layer multi-layer perceptrons (MLPs) and convolutional ne
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#22312;&#32039;&#33268;&#40654;&#26364;&#27969;&#24418;&#19978;&#23450;&#20041;&#20102;&#19968;&#31181;&#20960;&#20309;&#25955;&#23556;&#21464;&#25442;&#65292;&#35813;&#21464;&#25442;&#31867;&#20284;&#20110;&#27431;&#20960;&#37324;&#24471;&#25955;&#23556;&#21464;&#25442;&#65292;&#20855;&#26377;&#23616;&#37096;&#21516;&#26500;&#30340;&#19981;&#21464;&#24615;&#21644;&#26576;&#20123;&#31867;&#22411;&#30340;&#24494;&#20998;&#21516;&#32986;&#30340;&#31283;&#23450;&#24615;&#65292;&#23454;&#35777;&#32467;&#26524;&#35777;&#26126;&#20102;&#20854;&#22312;&#20960;&#20309;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#23454;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/1905.10448</link><description>&lt;p&gt;
&#22312;&#32039;&#33268;&#40654;&#26364;&#27969;&#24418;&#19978;&#30340;&#20960;&#20309;&#23567;&#27874;&#25955;&#23556;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Geometric Wavelet Scattering Networks on Compact Riemannian Manifolds. (arXiv:1905.10448v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1905.10448
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#22312;&#32039;&#33268;&#40654;&#26364;&#27969;&#24418;&#19978;&#23450;&#20041;&#20102;&#19968;&#31181;&#20960;&#20309;&#25955;&#23556;&#21464;&#25442;&#65292;&#35813;&#21464;&#25442;&#31867;&#20284;&#20110;&#27431;&#20960;&#37324;&#24471;&#25955;&#23556;&#21464;&#25442;&#65292;&#20855;&#26377;&#23616;&#37096;&#21516;&#26500;&#30340;&#19981;&#21464;&#24615;&#21644;&#26576;&#20123;&#31867;&#22411;&#30340;&#24494;&#20998;&#21516;&#32986;&#30340;&#31283;&#23450;&#24615;&#65292;&#23454;&#35777;&#32467;&#26524;&#35777;&#26126;&#20102;&#20854;&#22312;&#20960;&#20309;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#21313;&#24180;&#21069;&#65292;&#27431;&#20960;&#37324;&#24471;&#25955;&#23556;&#21464;&#25442;&#34987;&#24341;&#20837;&#20197;&#25913;&#21892;&#23545;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#25968;&#23398;&#29702;&#35299;&#12290;&#21463;&#21040;&#26368;&#36817;&#23545;&#20960;&#20309;&#28145;&#24230;&#23398;&#20064;&#30340;&#20852;&#36259;&#30340;&#21551;&#21457;&#65292;&#35813;&#23398;&#31185;&#26088;&#22312;&#23558;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#25512;&#24191;&#21040;&#27969;&#24418;&#21644;&#22270;&#32467;&#26500;&#22495;&#65292;&#25105;&#20204;&#22312;&#27969;&#24418;&#19978;&#23450;&#20041;&#20102;&#19968;&#31181;&#20960;&#20309;&#25955;&#23556;&#21464;&#25442;&#12290;&#31867;&#20284;&#20110;&#27431;&#20960;&#37324;&#24471;&#25955;&#23556;&#21464;&#25442;&#65292;&#20960;&#20309;&#25955;&#23556;&#21464;&#25442;&#22522;&#20110;&#19968;&#31995;&#21015;&#23567;&#27874;&#28388;&#27874;&#22120;&#21644;&#36880;&#28857;&#38750;&#32447;&#24615;&#12290;&#23427;&#23545;&#23616;&#37096;&#21516;&#26500;&#20855;&#26377;&#19981;&#21464;&#24615;&#65292;&#23545;&#26576;&#20123;&#31867;&#22411;&#30340;&#24494;&#20998;&#21516;&#32986;&#20855;&#26377;&#31283;&#23450;&#24615;&#12290;&#23454;&#35777;&#32467;&#26524;&#35777;&#26126;&#20102;&#23427;&#22312;&#20960;&#20309;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#23454;&#29992;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25512;&#24191;&#20102;&#27431;&#20960;&#37324;&#24471;&#25955;&#23556;&#30340;&#21464;&#24418;&#31283;&#23450;&#24615;&#21644;&#23616;&#37096;&#24179;&#31227;&#19981;&#21464;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#23558;&#20351;&#29992;&#30340;&#28388;&#27874;&#22120;&#32467;&#26500;&#19982;&#25968;&#25454;&#30340;&#22522;&#30784;&#20960;&#20309;&#32852;&#31995;&#36215;&#26469;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Euclidean scattering transform was introduced nearly a decade ago to improve the mathematical understanding of convolutional neural networks. Inspired by recent interest in geometric deep learning, which aims to generalize convolutional neural networks to manifold and graph-structured domains, we define a geometric scattering transform on manifolds. Similar to the Euclidean scattering transform, the geometric scattering transform is based on a cascade of wavelet filters and pointwise nonlinearities. It is invariant to local isometries and stable to certain types of diffeomorphisms. Empirical results demonstrate its utility on several geometric learning tasks. Our results generalize the deformation stability and local translation invariance of Euclidean scattering, and demonstrate the importance of linking the used filter structures to the underlying geometry of the data.
&lt;/p&gt;</description></item></channel></rss>