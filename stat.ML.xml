<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#32852;&#21512;&#19978;&#28216;&#21644;&#19979;&#28216;&#27169;&#22411;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#30340;&#19968;&#27493;&#31574;&#30053;&#65292;&#26174;&#33879;&#20943;&#23569;&#20102;&#20559;&#35823;&#65292;&#22312;CEO&#26102;&#38388;&#21033;&#29992;&#25968;&#25454;&#30340;&#24212;&#29992;&#20013;&#20135;&#29983;&#20102;&#37325;&#35201;&#25928;&#26524;&#65292;&#36866;&#21512;&#24212;&#29992;&#30740;&#31350;&#20154;&#21592;&#12290;</title><link>https://arxiv.org/abs/2402.15585</link><description>&lt;p&gt;
&#20351;&#29992;&#26469;&#33258;&#38750;&#32467;&#26500;&#21270;&#25968;&#25454;&#29983;&#25104;&#30340;&#21464;&#37327;&#36827;&#34892;&#22238;&#24402;&#30340;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Inference for Regression with Variables Generated from Unstructured Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15585
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#32852;&#21512;&#19978;&#28216;&#21644;&#19979;&#28216;&#27169;&#22411;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#30340;&#19968;&#27493;&#31574;&#30053;&#65292;&#26174;&#33879;&#20943;&#23569;&#20102;&#20559;&#35823;&#65292;&#22312;CEO&#26102;&#38388;&#21033;&#29992;&#25968;&#25454;&#30340;&#24212;&#29992;&#20013;&#20135;&#29983;&#20102;&#37325;&#35201;&#25928;&#26524;&#65292;&#36866;&#21512;&#24212;&#29992;&#30740;&#31350;&#20154;&#21592;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#26512;&#38750;&#32467;&#26500;&#21270;&#25968;&#25454;&#30340;&#20027;&#35201;&#31574;&#30053;&#21253;&#25324;&#20004;&#20010;&#27493;&#39588;&#12290;&#39318;&#20808;&#65292;&#20351;&#29992;&#19978;&#28216;&#20449;&#24687;&#26816;&#32034;&#27169;&#22411;&#20272;&#35745;&#24863;&#20852;&#36259;&#30340;&#28508;&#22312;&#32463;&#27982;&#21464;&#37327;&#12290;&#20854;&#27425;&#65292;&#23558;&#20272;&#35745;&#20540;&#35270;&#20026;&#19979;&#28216;&#35745;&#37327;&#32463;&#27982;&#27169;&#22411;&#20013;&#30340;&#8220;&#25968;&#25454;&#8221;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#29702;&#35770;&#35770;&#28857;&#65292;&#35299;&#37322;&#20026;&#20160;&#20040;&#22312;&#23454;&#35777;&#21512;&#29702;&#30340;&#35774;&#32622;&#20013;&#65292;&#36825;&#31181;&#20004;&#27493;&#31574;&#30053;&#20250;&#23548;&#33268;&#20559;&#35823;&#30340;&#25512;&#26029;&#12290;&#26356;&#20855;&#24314;&#35774;&#24615;&#30340;&#26159;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26377;&#25928;&#25512;&#26029;&#30340;&#19968;&#27493;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#21516;&#26102;&#20351;&#29992;&#19978;&#28216;&#21644;&#19979;&#28216;&#27169;&#22411;&#12290;&#22312;&#27169;&#25311;&#20013;&#65292;&#36825;&#19968;&#27493;&#31574;&#30053;(i) &#26174;&#33879;&#20943;&#23569;&#20102;&#20559;&#35823;&#65307;(ii) &#22312;&#20351;&#29992;CEO&#26102;&#38388;&#21033;&#29992;&#25968;&#25454;&#30340;&#20027;&#35201;&#24212;&#29992;&#20013;&#20135;&#29983;&#20102;&#23450;&#37327;&#37325;&#35201;&#30340;&#25928;&#26524;&#65307;(iii) &#21487;&#20197;&#24456;&#23481;&#26131;&#22320;&#34987;&#24212;&#29992;&#30740;&#31350;&#20154;&#21592;&#37319;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15585v1 Announce Type: new  Abstract: The leading strategy for analyzing unstructured data uses two steps. First, latent variables of economic interest are estimated with an upstream information retrieval model. Second, the estimates are treated as "data" in a downstream econometric model. We establish theoretical arguments for why this two-step strategy leads to biased inference in empirically plausible settings. More constructively, we propose a one-step strategy for valid inference that uses the upstream and downstream models jointly. The one-step strategy (i) substantially reduces bias in simulations; (ii) has quantitatively important effects in a leading application using CEO time-use data; and (iii) can be readily adapted by applied researchers.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38598;&#25104;&#26041;&#27861;Riemann-Lebesgue Forest (RLF)&#29992;&#20110;&#22238;&#24402;&#38382;&#39064;&#65292;&#36890;&#36807;&#21010;&#20998;&#20989;&#25968;&#30340;&#20540;&#22495;&#20026;&#22810;&#20010;&#21306;&#38388;&#26469;&#36924;&#36817;&#21487;&#27979;&#20989;&#25968;&#30340;&#24605;&#24819;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#26641;&#23398;&#20064;&#31639;&#27861;Riemann-Lebesgue Tree&#12290;&#36890;&#36807;Hoeffding&#20998;&#35299;&#21644;Stein&#26041;&#27861;&#25512;&#23548;&#20102;RLF&#22312;&#19981;&#21516;&#21442;&#25968;&#35774;&#32622;&#19979;&#30340;&#28176;&#36817;&#24615;&#33021;&#65292;&#24182;&#22312;&#20223;&#30495;&#25968;&#25454;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#20013;&#35777;&#26126;&#20102;RLF&#19982;&#21407;&#22987;&#38543;&#26426;&#26862;&#26519;&#30456;&#27604;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.04550</link><description>&lt;p&gt;
Riemann-Lebesgue Forest&#22238;&#24402;&#26041;&#27861;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Riemann-Lebesgue Forest for Regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04550
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38598;&#25104;&#26041;&#27861;Riemann-Lebesgue Forest (RLF)&#29992;&#20110;&#22238;&#24402;&#38382;&#39064;&#65292;&#36890;&#36807;&#21010;&#20998;&#20989;&#25968;&#30340;&#20540;&#22495;&#20026;&#22810;&#20010;&#21306;&#38388;&#26469;&#36924;&#36817;&#21487;&#27979;&#20989;&#25968;&#30340;&#24605;&#24819;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#26641;&#23398;&#20064;&#31639;&#27861;Riemann-Lebesgue Tree&#12290;&#36890;&#36807;Hoeffding&#20998;&#35299;&#21644;Stein&#26041;&#27861;&#25512;&#23548;&#20102;RLF&#22312;&#19981;&#21516;&#21442;&#25968;&#35774;&#32622;&#19979;&#30340;&#28176;&#36817;&#24615;&#33021;&#65292;&#24182;&#22312;&#20223;&#30495;&#25968;&#25454;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#20013;&#35777;&#26126;&#20102;RLF&#19982;&#21407;&#22987;&#38543;&#26426;&#26862;&#26519;&#30456;&#27604;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29992;&#20110;&#22238;&#24402;&#38382;&#39064;&#30340;&#38598;&#25104;&#26041;&#27861;&#65292;&#31216;&#20026;Riemann-Lebesgue Forest (RLF)&#12290;RLF&#30340;&#26680;&#24515;&#24605;&#24819;&#26159;&#36890;&#36807;&#23558;&#20989;&#25968;&#30340;&#20540;&#22495;&#21010;&#20998;&#20026;&#20960;&#20010;&#21306;&#38388;&#26469;&#27169;&#25311;&#21487;&#27979;&#20989;&#25968;&#30340;&#36924;&#36817;&#26041;&#24335;&#12290;&#22522;&#20110;&#36825;&#20010;&#24605;&#24819;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#26641;&#23398;&#20064;&#31639;&#27861;&#65292;&#31216;&#20026;Riemann-Lebesgue Tree&#65292;&#23427;&#22312;&#27599;&#20010;&#38750;&#21494;&#33410;&#28857;&#19978;&#26377;&#26426;&#20250;&#20174;&#21709;&#24212;Y&#25110;&#29305;&#24449;&#31354;&#38388;X&#20013;&#30340;&#26041;&#21521;&#36827;&#34892;&#20999;&#21106;&#12290;&#25105;&#20204;&#36890;&#36807;Hoeffding&#20998;&#35299;&#21644;Stein&#26041;&#27861;&#26469;&#25512;&#23548;&#19981;&#21516;&#21442;&#25968;&#35774;&#32622;&#19979;RLF&#30340;&#28176;&#36817;&#24615;&#33021;&#12290;&#24403;&#24213;&#23618;&#20989;&#25968;Y=f(X)&#36981;&#24490;&#21152;&#27861;&#22238;&#24402;&#27169;&#22411;&#26102;&#65292;RLF&#19982;Scornet&#31561;&#20154;&#30340;&#35770;&#35777;&#65288;2014&#24180;&#65289;&#20445;&#25345;&#19968;&#33268;&#12290;&#36890;&#36807;&#22312;&#20223;&#30495;&#25968;&#25454;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;RLF&#19982;&#21407;&#22987;&#38543;&#26426;&#26862;&#26519;&#30456;&#27604;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel ensemble method called Riemann-Lebesgue Forest (RLF) for regression. The core idea of RLF is to mimic the way how a measurable function can be approximated by partitioning its range into a few intervals. With this idea in mind, we develop a new tree learner named Riemann-Lebesgue Tree which has a chance to split the node from response $Y$ or a direction in feature space $\mathbf{X}$ at each non-terminal node. We generalize the asymptotic performance of RLF under different parameter settings mainly through Hoeffding decomposition \cite{Vaart} and Stein's method \cite{Chen2010NormalAB}. When the underlying function $Y=f(\mathbf{X})$ follows an additive regression model, RLF is consistent with the argument from \cite{Scornet2014ConsistencyOR}. The competitive performance of RLF against original random forest \cite{Breiman2001RandomF} is demonstrated by experiments in simulation data and real world datasets.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#20248;&#21270;&#30340;&#20999;&#29255;&#20998;&#24067;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#24555;&#36895;&#36827;&#34892;&#33945;&#29305;&#21345;&#27931;&#26399;&#26395;&#20272;&#35745;&#12290;&#36890;&#36807;&#21033;&#29992;&#38543;&#26426;&#21521;&#37327;&#20043;&#38388;&#30340;&#24402;&#19968;&#21270;&#24046;&#24322;&#26500;&#24314;&#38543;&#26426;&#36335;&#24452;&#25237;&#24433;&#26041;&#21521;&#65292;&#20174;&#32780;&#24471;&#21040;&#20102;&#38543;&#26426;&#36335;&#24452;&#20999;&#29255;&#20998;&#24067;&#21644;&#20004;&#20010;&#20999;&#29255;&#29926;&#29791;&#26031;&#22374;&#30340;&#21464;&#31181;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#25299;&#25169;&#12289;&#32479;&#35745;&#21644;&#35745;&#31639;&#24615;&#36136;&#19978;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2401.15889</link><description>&lt;p&gt;
&#24102;&#26377;&#38543;&#26426;&#36335;&#24452;&#25237;&#24433;&#26041;&#21521;&#30340;&#20999;&#29255;&#29926;&#29791;&#26031;&#22374;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Sliced Wasserstein with Random-Path Projecting Directions. (arXiv:2401.15889v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15889
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#20248;&#21270;&#30340;&#20999;&#29255;&#20998;&#24067;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#24555;&#36895;&#36827;&#34892;&#33945;&#29305;&#21345;&#27931;&#26399;&#26395;&#20272;&#35745;&#12290;&#36890;&#36807;&#21033;&#29992;&#38543;&#26426;&#21521;&#37327;&#20043;&#38388;&#30340;&#24402;&#19968;&#21270;&#24046;&#24322;&#26500;&#24314;&#38543;&#26426;&#36335;&#24452;&#25237;&#24433;&#26041;&#21521;&#65292;&#20174;&#32780;&#24471;&#21040;&#20102;&#38543;&#26426;&#36335;&#24452;&#20999;&#29255;&#20998;&#24067;&#21644;&#20004;&#20010;&#20999;&#29255;&#29926;&#29791;&#26031;&#22374;&#30340;&#21464;&#31181;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#25299;&#25169;&#12289;&#32479;&#35745;&#21644;&#35745;&#31639;&#24615;&#36136;&#19978;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24212;&#29992;&#20013;&#65292;&#20999;&#29255;&#20998;&#24067;&#36873;&#25321;&#24050;&#34987;&#29992;&#20316;&#25552;&#39640;&#22522;&#20110;&#26368;&#23567;&#21270;&#20999;&#29255;&#29926;&#29791;&#26031;&#22374;&#36317;&#31163;&#30340;&#21442;&#25968;&#20272;&#35745;&#22120;&#24615;&#33021;&#30340;&#26377;&#25928;&#25216;&#26415;&#12290;&#20808;&#21069;&#30340;&#24037;&#20316;&#35201;&#20040;&#21033;&#29992;&#26114;&#36149;&#30340;&#20248;&#21270;&#26469;&#36873;&#25321;&#20999;&#29255;&#20998;&#24067;&#65292;&#35201;&#20040;&#20351;&#29992;&#38656;&#35201;&#26114;&#36149;&#30340;&#25277;&#26679;&#26041;&#27861;&#30340;&#20999;&#29255;&#20998;&#24067;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#20248;&#21270;&#30340;&#20999;&#29255;&#20998;&#24067;&#65292;&#21487;&#20197;&#24555;&#36895;&#36827;&#34892;&#33945;&#29305;&#21345;&#27931;&#26399;&#26395;&#20272;&#35745;&#30340;&#25277;&#26679;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#38543;&#26426;&#36335;&#24452;&#25237;&#24433;&#26041;&#21521;&#65288;RPD&#65289;&#65292;&#23427;&#26159;&#36890;&#36807;&#21033;&#29992;&#20004;&#20010;&#36755;&#20837;&#27979;&#37327;&#20013;&#20004;&#20010;&#38543;&#26426;&#21521;&#37327;&#20043;&#38388;&#30340;&#24402;&#19968;&#21270;&#24046;&#24322;&#26500;&#24314;&#30340;&#12290;&#20174;RPD&#20013;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#38543;&#26426;&#36335;&#24452;&#20999;&#29255;&#20998;&#24067;&#65288;RPSD&#65289;&#21644;&#20004;&#20010;&#20999;&#29255;&#29926;&#29791;&#26031;&#22374;&#30340;&#21464;&#31181;&#65292;&#21363;&#38543;&#26426;&#36335;&#24452;&#25237;&#24433;&#20999;&#29255;&#29926;&#29791;&#26031;&#22374;&#65288;RPSW&#65289;&#21644;&#37325;&#35201;&#24615;&#21152;&#26435;&#38543;&#26426;&#36335;&#24452;&#25237;&#24433;&#20999;&#29255;&#29926;&#29791;&#26031;&#22374;&#65288;IWRPSW&#65289;&#12290;&#28982;&#21518;&#25105;&#20204;&#35752;&#35770;&#20102;&#25299;&#25169;&#12289;&#32479;&#35745;&#21644;&#35745;&#31639;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
Slicing distribution selection has been used as an effective technique to improve the performance of parameter estimators based on minimizing sliced Wasserstein distance in applications. Previous works either utilize expensive optimization to select the slicing distribution or use slicing distributions that require expensive sampling methods. In this work, we propose an optimization-free slicing distribution that provides a fast sampling for the Monte Carlo estimation of expectation. In particular, we introduce the random-path projecting direction (RPD) which is constructed by leveraging the normalized difference between two random vectors following the two input measures. From the RPD, we derive the random-path slicing distribution (RPSD) and two variants of sliced Wasserstein, i.e., the Random-Path Projection Sliced Wasserstein (RPSW) and the Importance Weighted Random-Path Projection Sliced Wasserstein (IWRPSW). We then discuss the topological, statistical, and computational propert
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#23450;&#20041;&#29420;&#31435;&#22240;&#26524;&#26426;&#21046;&#65292;&#25552;&#20986;&#20102;ICM-VAE&#26694;&#26550;&#65292;&#20351;&#24471;&#23398;&#20064;&#22240;&#26524;&#35299;&#32544;&#32469;&#34920;&#31034;&#26356;&#20934;&#30830;</title><link>http://arxiv.org/abs/2306.01213</link><description>&lt;p&gt;
&#22522;&#20110;&#29420;&#31435;&#22240;&#26524;&#26426;&#21046;&#21407;&#21017;&#23398;&#20064;&#22240;&#26524;&#35299;&#32544;&#32469;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Learning Causally Disentangled Representations via the Principle of Independent Causal Mechanisms. (arXiv:2306.01213v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01213
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23450;&#20041;&#29420;&#31435;&#22240;&#26524;&#26426;&#21046;&#65292;&#25552;&#20986;&#20102;ICM-VAE&#26694;&#26550;&#65292;&#20351;&#24471;&#23398;&#20064;&#22240;&#26524;&#35299;&#32544;&#32469;&#34920;&#31034;&#26356;&#20934;&#30830;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#35299;&#32544;&#32469;&#30340;&#22240;&#26524;&#34920;&#31034;&#26159;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#65292;&#36817;&#24180;&#26469;&#22240;&#20854;&#23545;&#25552;&#21462;&#19979;&#28216;&#20219;&#21153;&#30340;&#26377;&#24847;&#20041;&#20449;&#24687;&#32780;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#26412;&#25991;&#20174;&#29420;&#31435;&#22240;&#26524;&#26426;&#21046;&#30340;&#35282;&#24230;&#23450;&#20041;&#20102;&#19968;&#31181;&#26032;&#30340;&#22240;&#26524;&#35299;&#32544;&#32469;&#27010;&#24565;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;ICM-VAE&#26694;&#26550;&#65292;&#36890;&#36807;&#22240;&#22240;&#26524;&#20851;&#31995;&#35266;&#23519;&#26631;&#31614;&#26469;&#30417;&#30563;&#23398;&#20064;&#22240;&#26524;&#35299;&#32544;&#32469;&#34920;&#31034;&#12290;&#25105;&#20204;&#20351;&#29992;&#21487;&#23398;&#20064;&#30340;&#22522;&#20110;&#27969;&#30340;&#24494;&#20998;&#21516;&#32986;&#20989;&#25968;&#23558;&#22122;&#22768;&#21464;&#37327;&#26144;&#23556;&#21040;&#28508;&#22312;&#22240;&#26524;&#21464;&#37327;&#20013;&#26469;&#24314;&#27169;&#22240;&#26524;&#26426;&#21046;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#20419;&#36827;&#22240;&#26524;&#35201;&#32032;&#30340;&#35299;&#32544;&#32469;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#26524;&#35299;&#32544;&#32469;&#20808;&#39564;&#65292;&#21033;&#29992;&#24050;&#30693;&#30340;&#22240;&#26524;&#32467;&#26500;&#26469;&#40723;&#21169;&#22312;&#28508;&#22312;&#31354;&#38388;&#20013;&#23398;&#20064;&#22240;&#26524;&#20998;&#35299;&#20998;&#24067;&#12290;&#22312;&#30456;&#23545;&#28201;&#21644;&#30340;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#29702;&#35770;&#32467;&#26524;&#65292;&#26174;&#31034;&#20102;&#22240;&#26524;&#35201;&#32032;&#21644;&#26426;&#21046;&#30340;&#21487;&#35782;&#21035;&#24615;&#65292;&#30452;&#21040;&#25490;&#21015;&#21644;&#36880;&#20803;&#37325;&#21442;&#25968;&#21270;&#30340;&#38480;&#24230;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#23454;&#35777;&#30740;&#31350;...
&lt;/p&gt;
&lt;p&gt;
Learning disentangled causal representations is a challenging problem that has gained significant attention recently due to its implications for extracting meaningful information for downstream tasks. In this work, we define a new notion of causal disentanglement from the perspective of independent causal mechanisms. We propose ICM-VAE, a framework for learning causally disentangled representations supervised by causally related observed labels. We model causal mechanisms using learnable flow-based diffeomorphic functions to map noise variables to latent causal variables. Further, to promote the disentanglement of causal factors, we propose a causal disentanglement prior that utilizes the known causal structure to encourage learning a causally factorized distribution in the latent space. Under relatively mild conditions, we provide theoretical results showing the identifiability of causal factors and mechanisms up to permutation and elementwise reparameterization. We empirically demons
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36830;&#32493;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#35760;&#24518;&#20013;&#32500;&#25252;&#36935;&#21040;&#24207;&#21015;&#27169;&#24335;&#30340;&#25551;&#36848;&#31526;&#26469;&#23454;&#29616;&#65292;&#33021;&#22815;&#26377;&#25928;&#22788;&#29702;&#26032;&#30340;&#34892;&#20026;&#27169;&#24335;&#30340;&#36830;&#32493;&#20986;&#29616;&#12290;</title><link>http://arxiv.org/abs/2203.00936</link><description>&lt;p&gt;
&#24102;&#22806;&#37096;&#35760;&#24518;&#30340;&#22810;&#27169;&#24577;&#21160;&#24577;&#36830;&#32493;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Continual Learning of Multi-modal Dynamics with External Memory. (arXiv:2203.00936v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.00936
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36830;&#32493;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#35760;&#24518;&#20013;&#32500;&#25252;&#36935;&#21040;&#24207;&#21015;&#27169;&#24335;&#30340;&#25551;&#36848;&#31526;&#26469;&#23454;&#29616;&#65292;&#33021;&#22815;&#26377;&#25928;&#22788;&#29702;&#26032;&#30340;&#34892;&#20026;&#27169;&#24335;&#30340;&#36830;&#32493;&#20986;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26032;&#30340;&#34892;&#20026;&#27169;&#24335;&#36830;&#32493;&#20986;&#29616;&#26102;&#65292;&#22914;&#20309;&#23558;&#27169;&#22411;&#25311;&#21512;&#21040;&#21160;&#24577;&#29615;&#22659;&#20013;&#12290;&#23398;&#20064;&#27169;&#22411;&#33021;&#22815;&#24847;&#35782;&#21040;&#26032;&#30340;&#27169;&#24335;&#20986;&#29616;&#65292;&#20294;&#23427;&#27809;&#26377;&#35775;&#38382;&#21333;&#20010;&#35757;&#32451;&#24207;&#21015;&#30340;&#30495;&#23454;&#27169;&#24335;&#30340;&#20449;&#24687;&#12290;&#30446;&#21069;&#30340;&#36830;&#32493;&#23398;&#20064;&#26041;&#27861;&#26080;&#27861;&#22788;&#29702;&#36825;&#31181;&#24773;&#20917;&#65292;&#22240;&#20026;&#21442;&#25968;&#20256;&#36882;&#21463;&#21040;&#28798;&#38590;&#24615;&#24178;&#25200;&#30340;&#24433;&#21709;&#65292;&#32780;&#24773;&#33410;&#35760;&#24518;&#35774;&#35745;&#38656;&#35201;&#30693;&#36947;&#24207;&#21015;&#30340;&#30495;&#23454;&#27169;&#24335;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#30340;&#36830;&#32493;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#31070;&#32463;&#24773;&#33410;&#35760;&#24518;&#20013;&#32500;&#25252;&#36935;&#21040;&#30340;&#24207;&#21015;&#27169;&#24335;&#30340;&#25551;&#36848;&#31526;&#26469;&#20811;&#26381;&#36825;&#20004;&#20010;&#38480;&#21046;&#12290;&#25105;&#20204;&#22312;&#35760;&#24518;&#30340;&#27880;&#24847;&#26435;&#37325;&#19978;&#20351;&#29992;Dirichlet&#36807;&#31243;&#20808;&#39564;&#65292;&#20197;&#20419;&#36827;&#27169;&#24335;&#25551;&#36848;&#31526;&#30340;&#26377;&#25928;&#23384;&#20648;&#12290;&#36890;&#36807;&#26816;&#32034;&#20808;&#21069;&#20219;&#21153;&#30456;&#20284;&#27169;&#24335;&#30340;&#25551;&#36848;&#31526;&#65292;&#24182;&#23558;&#27492;&#25551;&#36848;&#31526;&#39304;&#20837;&#20854;&#36716;&#31227;&#20013;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#22312;&#20219;&#21153;&#20043;&#38388;&#20256;&#36882;&#30693;&#35782;&#26469;&#25191;&#34892;&#36830;&#32493;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of fitting a model to a dynamical environment when new modes of behavior emerge sequentially. The learning model is aware when a new mode appears, but it does not have access to the true modes of individual training sequences. The state-of-the-art continual learning approaches cannot handle this setup, because parameter transfer suffers from catastrophic interference and episodic memory design requires the knowledge of the ground-truth modes of sequences. We devise a novel continual learning method that overcomes both limitations by maintaining a descriptor of the mode of an encountered sequence in a neural episodic memory. We employ a Dirichlet Process prior on the attention weights of the memory to foster efficient storage of the mode descriptors. Our method performs continual learning by transferring knowledge across tasks by retrieving the descriptors of similar modes of past tasks to the mode of a current sequence and feeding this descriptor into its transitio
&lt;/p&gt;</description></item></channel></rss>