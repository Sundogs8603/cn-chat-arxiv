<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#29305;&#24449;&#27169;&#20223;&#32593;&#32476;&#65288;FIN&#65289;&#22312;&#37329;&#34701;&#12289;&#35821;&#38899;&#21644;&#29983;&#29702;&#39046;&#22495;&#20013;&#30340;&#24212;&#29992;&#65292;&#21457;&#29616;FIN&#22312;&#27604;&#29305;&#24065;&#20215;&#26684;&#39044;&#27979;&#12289;&#35821;&#38899;&#24773;&#24863;&#35782;&#21035;&#21644;&#24930;&#24615;&#39048;&#30171;&#26816;&#27979;&#26041;&#38754;&#33021;&#22815;&#26174;&#33879;&#25913;&#21892;&#24615;&#33021;&#65292;&#20026;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#25552;&#20379;&#20102;&#26377;&#24076;&#26395;&#30340;&#22522;&#30784;&#12290;</title><link>http://arxiv.org/abs/2309.12279</link><description>&lt;p&gt;
&#29305;&#24449;&#27169;&#20223;&#30340;&#24191;&#27867;&#24433;&#21709;&#65306;&#37329;&#34701;&#12289;&#35821;&#38899;&#21644;&#29983;&#29702;&#39046;&#22495;&#20013;&#30340;&#31070;&#32463;&#22686;&#24378;
&lt;/p&gt;
&lt;p&gt;
The Broad Impact of Feature Imitation: Neural Enhancements Across Financial, Speech, and Physiological Domains. (arXiv:2309.12279v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12279
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#29305;&#24449;&#27169;&#20223;&#32593;&#32476;&#65288;FIN&#65289;&#22312;&#37329;&#34701;&#12289;&#35821;&#38899;&#21644;&#29983;&#29702;&#39046;&#22495;&#20013;&#30340;&#24212;&#29992;&#65292;&#21457;&#29616;FIN&#22312;&#27604;&#29305;&#24065;&#20215;&#26684;&#39044;&#27979;&#12289;&#35821;&#38899;&#24773;&#24863;&#35782;&#21035;&#21644;&#24930;&#24615;&#39048;&#30171;&#26816;&#27979;&#26041;&#38754;&#33021;&#22815;&#26174;&#33879;&#25913;&#21892;&#24615;&#33021;&#65292;&#20026;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#25552;&#20379;&#20102;&#26377;&#24076;&#26395;&#30340;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#26435;&#37325;&#30340;&#21021;&#22987;&#21270;&#22312;&#30830;&#23450;&#23427;&#20204;&#30340;&#24615;&#33021;&#26041;&#38754;&#36215;&#21040;&#20851;&#38190;&#20316;&#29992;&#12290;&#29305;&#24449;&#27169;&#20223;&#32593;&#32476;&#65288;FIN&#65289;&#36890;&#36807;&#23558;&#26435;&#37325;&#21021;&#22987;&#21270;&#20026;&#36817;&#20284;&#29305;&#23450;&#30340;&#38381;&#21512;&#32479;&#35745;&#29305;&#24449;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#31574;&#30053;&#65292;&#20026;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#22880;&#23450;&#20102;&#26377;&#24076;&#26395;&#30340;&#22522;&#30784;&#12290;&#34429;&#28982;FIN&#30340;&#36866;&#29992;&#24615;&#20027;&#35201;&#22312;&#29983;&#29289;&#21307;&#23398;&#39046;&#22495;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#20294;&#26412;&#30740;&#31350;&#23558;&#20854;&#25193;&#23637;&#21040;&#20102;&#20854;&#20182;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#12290;&#26412;&#30740;&#31350;&#36827;&#34892;&#20102;&#19977;&#20010;&#19981;&#21516;&#30340;&#23454;&#39564;&#65292;&#20197;&#27979;&#35797;&#27169;&#20223;Tsallis&#29109;&#20197;&#25552;&#39640;&#24615;&#33021;&#30340;&#36866;&#29992;&#24615;&#65306;&#27604;&#29305;&#24065;&#20215;&#26684;&#39044;&#27979;&#65292;&#35821;&#38899;&#24773;&#24863;&#35782;&#21035;&#21644;&#24930;&#24615;&#39048;&#30171;&#26816;&#27979;&#12290;&#22312;&#27604;&#29305;&#24065;&#20215;&#26684;&#39044;&#27979;&#20013;&#65292;&#23884;&#20837;&#26377;FIN&#30340;&#27169;&#22411;&#23558;&#22343;&#26041;&#26681;&#35823;&#24046;&#20943;&#23569;&#20102;&#32422;1000&#19982;&#22522;&#20934;&#30456;&#27604;&#12290;&#22312;&#35821;&#38899;&#24773;&#24863;&#35782;&#21035;&#20219;&#21153;&#20013;&#65292;FIN&#22686;&#24378;&#27169;&#22411;&#30340;&#20998;&#31867;&#20934;&#30830;&#29575;&#25552;&#39640;&#20102;3&#65285;&#20197;&#19978;&#12290;&#26368;&#21518;&#65292;&#22312;CNP&#26816;&#27979;&#23454;&#39564;&#20013;&#65292;&#25913;&#36827;&#32422;&#20026;7&#65285;&#12290;
&lt;/p&gt;
&lt;p&gt;
Initialization of neural network weights plays a pivotal role in determining their performance. Feature Imitating Networks (FINs) offer a novel strategy by initializing weights to approximate specific closed-form statistical features, setting a promising foundation for deep learning architectures. While the applicability of FINs has been chiefly tested in biomedical domains, this study extends its exploration into other time series datasets. Three different experiments are conducted in this study to test the applicability of imitating Tsallis entropy for performance enhancement: Bitcoin price prediction, speech emotion recognition, and chronic neck pain detection. For the Bitcoin price prediction, models embedded with FINs reduced the root mean square error by around 1000 compared to the baseline. In the speech emotion recognition task, the FIN-augmented model increased classification accuracy by over 3 percent. Lastly, in the CNP detection experiment, an improvement of about 7 percent
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#38750;&#21442;&#25968;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#36827;&#34892;&#22522;&#20110;&#27169;&#22411;&#30340;&#32858;&#31867;&#26102;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#65292;&#24182;&#25552;&#20986;&#20102;&#30456;&#24212;&#30340;&#32858;&#31867;&#26041;&#27861;&#12290;&#36890;&#36807;&#30740;&#31350;&#20998;&#31867;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#21644;&#32858;&#31867;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#30830;&#23450;&#20102;&#32858;&#31867;&#20219;&#21153;&#30340;&#38590;&#24230;&#12290;&#21516;&#26102;&#65292;&#22312;&#25554;&#20540;&#20998;&#31867;&#22120;&#21644;&#22312;&#32447;&#35774;&#32622;&#20013;&#30340;&#32467;&#26524;&#20063;&#24471;&#21040;&#20102;&#35777;&#26126;&#12290;&#27169;&#25311;&#23454;&#39564;&#39564;&#35777;&#20102;&#36825;&#20123;&#21457;&#29616;&#12290;</title><link>http://arxiv.org/abs/2309.12238</link><description>&lt;p&gt;
&#20351;&#29992;&#38750;&#21442;&#25968;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Model-based Clustering using Non-parametric Hidden Markov Models. (arXiv:2309.12238v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12238
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#38750;&#21442;&#25968;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#36827;&#34892;&#22522;&#20110;&#27169;&#22411;&#30340;&#32858;&#31867;&#26102;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#65292;&#24182;&#25552;&#20986;&#20102;&#30456;&#24212;&#30340;&#32858;&#31867;&#26041;&#27861;&#12290;&#36890;&#36807;&#30740;&#31350;&#20998;&#31867;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#21644;&#32858;&#31867;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#30830;&#23450;&#20102;&#32858;&#31867;&#20219;&#21153;&#30340;&#38590;&#24230;&#12290;&#21516;&#26102;&#65292;&#22312;&#25554;&#20540;&#20998;&#31867;&#22120;&#21644;&#22312;&#32447;&#35774;&#32622;&#20013;&#30340;&#32467;&#26524;&#20063;&#24471;&#21040;&#20102;&#35777;&#26126;&#12290;&#27169;&#25311;&#23454;&#39564;&#39564;&#35777;&#20102;&#36825;&#20123;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#21442;&#25968;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#65288;HMM&#65289;&#30001;&#20110;&#20854;&#20381;&#36182;&#32467;&#26500;&#65292;&#21487;&#20197;&#22312;&#19981;&#25351;&#23450;&#32676;&#32452;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#22522;&#20110;&#27169;&#22411;&#30340;&#32858;&#31867;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20351;&#29992;HMM&#36827;&#34892;&#32858;&#31867;&#26102;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#65292;&#24182;&#25552;&#20986;&#20102;&#30456;&#24212;&#30340;&#32858;&#31867;&#26041;&#27861;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#23558;&#20998;&#31867;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#19982;&#32858;&#31867;&#30340;&#36125;&#21494;&#26031;&#39118;&#38505;&#32852;&#31995;&#36215;&#26469;&#30340;&#32467;&#26524;&#65292;&#29992;&#20197;&#30830;&#23450;&#32858;&#31867;&#20219;&#21153;&#30340;&#38590;&#24230;&#30340;&#20851;&#38190;&#25968;&#37327;&#12290;&#25105;&#20204;&#36824;&#22312;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#26694;&#26550;&#19979;&#35777;&#26126;&#20102;&#36825;&#19968;&#32467;&#26524;&#65292;&#36825;&#21487;&#33021;&#20855;&#26377;&#29420;&#31435;&#30340;&#20852;&#36259;&#12290;&#28982;&#21518;&#25105;&#20204;&#30740;&#31350;&#20102;&#25554;&#20540;&#20998;&#31867;&#22120;&#30340;&#36807;&#24230;&#39118;&#38505;&#12290;&#25152;&#26377;&#36825;&#20123;&#32467;&#26524;&#37117;&#34987;&#35777;&#26126;&#22312;&#22312;&#32447;&#35774;&#32622;&#20013;&#20173;&#28982;&#26377;&#25928;&#65292;&#22312;&#35813;&#35774;&#32622;&#19979;&#65292;&#35266;&#27979;&#32467;&#26524;&#34987;&#39034;&#24207;&#32858;&#31867;&#12290;&#27169;&#25311;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Thanks to their dependency structure, non-parametric Hidden Markov Models (HMMs) are able to handle model-based clustering without specifying group distributions. The aim of this work is to study the Bayes risk of clustering when using HMMs and to propose associated clustering procedures. We first give a result linking the Bayes risk of classification and the Bayes risk of clustering, which we use to identify the key quantity determining the difficulty of the clustering task. We also give a proof of this result in the i.i.d. framework, which might be of independent interest. Then we study the excess risk of the plugin classifier. All these results are shown to remain valid in the online setting where observations are clustered sequentially. Simulations illustrate our findings.
&lt;/p&gt;</description></item><item><title>&#21306;&#22495;&#21487;&#21152;&#27169;&#22411; (RAMs) &#26159;&#19968;&#31181;&#35774;&#35745;&#21487;&#35299;&#37322;&#27169;&#22411;&#65292;&#36890;&#36807;&#22312;&#29305;&#24449;&#31354;&#38388;&#20869;&#35782;&#21035;&#23376;&#21306;&#22495;&#26469;&#26368;&#23567;&#21270;&#29305;&#24449;&#30340;&#20132;&#20114;&#12290;&#30456;&#27604;&#20110;&#24191;&#20041;&#21487;&#21152;&#27169;&#22411;(GAMs)&#65292;RAMs&#33021;&#25317;&#26377;&#26356;&#20016;&#23500;&#30340;&#27169;&#22411;&#34920;&#36798;&#33021;&#21147;&#65292;&#21516;&#26102;&#20445;&#25345;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.12215</link><description>&lt;p&gt;
&#21306;&#22495;&#21487;&#21152;&#27169;&#22411;: &#26368;&#23567;&#21270;&#29305;&#24449;&#20132;&#20114;&#30340;&#35774;&#35745;&#21487;&#35299;&#37322;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Regionally Additive Models: Explainable-by-design models minimizing feature interactions. (arXiv:2309.12215v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12215
&lt;/p&gt;
&lt;p&gt;
&#21306;&#22495;&#21487;&#21152;&#27169;&#22411; (RAMs) &#26159;&#19968;&#31181;&#35774;&#35745;&#21487;&#35299;&#37322;&#27169;&#22411;&#65292;&#36890;&#36807;&#22312;&#29305;&#24449;&#31354;&#38388;&#20869;&#35782;&#21035;&#23376;&#21306;&#22495;&#26469;&#26368;&#23567;&#21270;&#29305;&#24449;&#30340;&#20132;&#20114;&#12290;&#30456;&#27604;&#20110;&#24191;&#20041;&#21487;&#21152;&#27169;&#22411;(GAMs)&#65292;RAMs&#33021;&#25317;&#26377;&#26356;&#20016;&#23500;&#30340;&#27169;&#22411;&#34920;&#36798;&#33021;&#21147;&#65292;&#21516;&#26102;&#20445;&#25345;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24191;&#20041;&#21487;&#21152;&#27169;&#22411; (GAMs) &#26159;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#24191;&#27867;&#20351;&#29992;&#30340;&#35774;&#35745;&#21487;&#35299;&#37322;&#27169;&#22411;&#12290; GAMs&#20551;&#35774;&#36755;&#20986;&#21487;&#20197;&#34920;&#31034;&#20026;&#19968;&#32452;&#21333;&#21464;&#37327;&#20989;&#25968;&#30340;&#21644;&#65292;&#31216;&#20026;&#32452;&#20214;&#12290;&#28982;&#32780;&#65292;&#22312;&#36755;&#20986;&#20381;&#36182;&#20110;&#22810;&#20010;&#29305;&#24449;&#21516;&#26102;&#30340;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20013;&#65292;&#36825;&#31181;&#20551;&#35774;&#19981;&#25104;&#31435;&#12290;&#22312;&#36825;&#20123;&#24773;&#20917;&#19979;&#65292;GAMs&#26080;&#27861;&#25429;&#25417;&#21040;&#24213;&#23618;&#20989;&#25968;&#30340;&#20132;&#20114;&#39033;&#65292;&#23548;&#33268;&#20934;&#30830;&#24615;&#19981;&#20339;&#12290;&#20026;&#20102;(&#37096;&#20998;)&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21306;&#22495;&#21487;&#21152;&#27169;&#22411; (RAMs)&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#35774;&#35745;&#21487;&#35299;&#37322;&#27169;&#22411;&#12290;RAMs&#35782;&#21035;&#29305;&#24449;&#31354;&#38388;&#20869;&#30340;&#23376;&#21306;&#22495;&#65292;&#22312;&#36825;&#20123;&#23376;&#21306;&#22495;&#20013;&#26368;&#23567;&#21270;&#20102;&#29305;&#24449;&#30340;&#20132;&#20114;&#12290;&#22312;&#36825;&#20123;&#21306;&#22495;&#20869;&#65292;&#25226;&#36755;&#20986;&#34920;&#31034;&#20026;&#19968;&#32452;&#21333;&#21464;&#37327;&#20989;&#25968; (&#32452;&#20214;) &#30456;&#23545;&#20110;&#25226;&#36755;&#20986;&#34920;&#31034;&#20026;&#19968;&#20010;&#29305;&#24449;&#30340;&#21333;&#21464;&#37327;&#20989;&#25968;&#26356;&#21152;&#20934;&#30830;&#12290;&#22240;&#27492;&#65292;RAMs&#30456;&#27604;&#20110;GAMs&#25317;&#26377;&#26356;&#20016;&#23500;&#30340;&#27169;&#22411;&#34920;&#36798;&#33021;&#21147;&#65292;&#21516;&#26102;&#20445;&#25345;&#21487;&#35299;&#37322;&#24615;&#12290;RAM&#26694;&#26550;&#30001;&#19977;&#20010;&#27493;&#39588;&#32452;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generalized Additive Models (GAMs) are widely used explainable-by-design models in various applications. GAMs assume that the output can be represented as a sum of univariate functions, referred to as components. However, this assumption fails in ML problems where the output depends on multiple features simultaneously. In these cases, GAMs fail to capture the interaction terms of the underlying function, leading to subpar accuracy. To (partially) address this issue, we propose Regionally Additive Models (RAMs), a novel class of explainable-by-design models. RAMs identify subregions within the feature space where interactions are minimized. Within these regions, it is more accurate to express the output as a sum of univariate functions (components). Consequently, RAMs fit one component per subregion of each feature instead of one component per feature. This approach yields a more expressive model compared to GAMs while retaining interpretability. The RAM framework consists of three step
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#36125;&#21494;&#26031;&#27169;&#22411;&#32553;&#20943;&#20316;&#20026;&#19968;&#31181;&#26356;&#39640;&#25928;&#30340;&#26367;&#20195;&#26041;&#27861;&#26469;&#20462;&#21098;&#27169;&#22411;&#26435;&#37325;&#65292;&#20197;&#25552;&#39640;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#35745;&#31639;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2309.12095</link><description>&lt;p&gt;
&#20855;&#26377;&#36125;&#21494;&#26031;&#27169;&#22411;&#32553;&#20943;&#30340;&#36125;&#21494;&#26031;&#31232;&#30095;&#24615;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Bayesian sparsification for deep neural networks with Bayesian model reduction. (arXiv:2309.12095v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12095
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#36125;&#21494;&#26031;&#27169;&#22411;&#32553;&#20943;&#20316;&#20026;&#19968;&#31181;&#26356;&#39640;&#25928;&#30340;&#26367;&#20195;&#26041;&#27861;&#26469;&#20462;&#21098;&#27169;&#22411;&#26435;&#37325;&#65292;&#20197;&#25552;&#39640;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#35745;&#31639;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#30340;&#24040;&#22823;&#33021;&#21147;&#24120;&#24120;&#21463;&#21040;&#20854;&#27169;&#22411;&#22797;&#26434;&#24615;&#30340;&#38480;&#21046;&#65292;&#22240;&#27492;&#23545;&#20110;&#26377;&#25928;&#30340;&#31232;&#30095;&#25216;&#26415;&#30340;&#38656;&#27714;&#19981;&#26029;&#22686;&#21152;&#12290;&#36125;&#21494;&#26031;&#31232;&#30095;&#24615;&#23545;&#20110;&#28145;&#24230;&#23398;&#20064;&#32780;&#35328;&#26159;&#19968;&#31181;&#20851;&#38190;&#26041;&#27861;&#65292;&#21487;&#20197;&#20419;&#36827;&#22312;&#21508;&#31181;&#28145;&#24230;&#23398;&#20064;&#24212;&#29992;&#20013;&#35774;&#35745;&#26082;&#20855;&#26377;&#35745;&#31639;&#25928;&#29575;&#21448;&#20855;&#26377;&#31454;&#20105;&#24615;&#33021;&#30340;&#27169;&#22411;&#12290;&#30446;&#21069;&#65292;&#36125;&#21494;&#26031;&#31232;&#30095;&#21270;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#26032;&#25216;&#26415;&#26159;&#23558;&#32467;&#26500;&#25910;&#32553;&#20808;&#39564;&#24212;&#29992;&#20110;&#27169;&#22411;&#26435;&#37325;&#65292;&#24182;&#32467;&#21512;&#22522;&#20110;&#40657;&#30418;&#38543;&#26426;&#21464;&#20998;&#25512;&#26029;&#30340;&#36817;&#20284;&#25512;&#26029;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#19982;&#26631;&#20934;&#30340;&#28145;&#24230;&#23398;&#20064;&#28857;&#20272;&#35745;&#30456;&#27604;&#65292;&#23436;&#25972;&#29983;&#25104;&#27169;&#22411;&#30340;&#27169;&#22411;&#21453;&#28436;&#22312;&#35745;&#31639;&#26041;&#38754;&#38750;&#24120;&#32791;&#36153;&#26102;&#38388;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25552;&#20513;&#20351;&#29992;&#36125;&#21494;&#26031;&#27169;&#22411;&#32553;&#20943;&#65288;BMR&#65289;&#20316;&#20026;&#27169;&#22411;&#26435;&#37325;&#20462;&#21098;&#30340;&#26356;&#39640;&#25928;&#26367;&#20195;&#26041;&#27861;&#12290;&#20316;&#20026;&#20915;&#31574;&#29575;&#30340;&#25512;&#24191;&#65292;BMR&#20801;&#35768;&#23545;&#27169;&#22411;&#26435;&#37325;&#36827;&#34892;&#20107;&#21518;&#28040;&#38500;
&lt;/p&gt;
&lt;p&gt;
Deep learning's immense capabilities are often constrained by the complexity of its models, leading to an increasing demand for effective sparsification techniques. Bayesian sparsification for deep learning emerges as a crucial approach, facilitating the design of models that are both computationally efficient and competitive in terms of performance across various deep learning applications. The state-of-the-art -- in Bayesian sparsification of deep neural networks -- combines structural shrinkage priors on model weights with an approximate inference scheme based on black-box stochastic variational inference. However, model inversion of the full generative model is exceptionally computationally demanding, especially when compared to standard deep learning of point estimates. In this context, we advocate for the use of Bayesian model reduction (BMR) as a more efficient alternative for pruning of model weights. As a generalization of the Savage-Dickey ratio, BMR allows a post-hoc elimina
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20154;&#26426;&#21327;&#21516;&#30340;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#29983;&#25104;&#27969;&#32593;&#25353;&#29031;&#22522;&#20110;&#35780;&#20998;&#20989;&#25968;&#30340;&#20449;&#24565;&#20998;&#24067;&#37319;&#26679;&#31062;&#20808;&#22270;&#65292;&#24182;&#24341;&#20837;&#26368;&#20339;&#23454;&#39564;&#35774;&#35745;&#19982;&#19987;&#23478;&#20114;&#21160;&#65292;&#20197;&#25552;&#20379;&#19987;&#23478;&#21487;&#39564;&#35777;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#24182;&#36845;&#20195;&#25913;&#36827;&#22240;&#26524;&#25512;&#26029;&#12290;</title><link>http://arxiv.org/abs/2309.12032</link><description>&lt;p&gt;
&#20154;&#26426;&#21327;&#21516;&#19979;&#20351;&#29992;&#31062;&#20808;GFlowNets&#36827;&#34892;&#28508;&#22312;&#28151;&#28102;&#30340;&#22240;&#26524;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Human-in-the-Loop Causal Discovery under Latent Confounding using Ancestral GFlowNets. (arXiv:2309.12032v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12032
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20154;&#26426;&#21327;&#21516;&#30340;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#29983;&#25104;&#27969;&#32593;&#25353;&#29031;&#22522;&#20110;&#35780;&#20998;&#20989;&#25968;&#30340;&#20449;&#24565;&#20998;&#24067;&#37319;&#26679;&#31062;&#20808;&#22270;&#65292;&#24182;&#24341;&#20837;&#26368;&#20339;&#23454;&#39564;&#35774;&#35745;&#19982;&#19987;&#23478;&#20114;&#21160;&#65292;&#20197;&#25552;&#20379;&#19987;&#23478;&#21487;&#39564;&#35777;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#24182;&#36845;&#20195;&#25913;&#36827;&#22240;&#26524;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32467;&#26500;&#23398;&#20064;&#26159;&#22240;&#26524;&#25512;&#26029;&#30340;&#20851;&#38190;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#24403;&#25968;&#25454;&#31232;&#32570;&#26102;&#65292;&#22240;&#26524;&#21457;&#29616;&#65288;CD&#65289;&#31639;&#27861;&#24456;&#33030;&#24369;&#65292;&#21487;&#33021;&#25512;&#26029;&#20986;&#19982;&#19987;&#23478;&#30693;&#35782;&#30456;&#30683;&#30462;&#30340;&#19981;&#20934;&#30830;&#22240;&#26524;&#20851;&#31995;&#65292;&#23588;&#20854;&#26159;&#32771;&#34385;&#21040;&#28508;&#22312;&#28151;&#28102;&#22240;&#32032;&#26102;&#26356;&#26159;&#22914;&#27492;&#12290;&#20026;&#20102;&#21152;&#37325;&#36825;&#20010;&#38382;&#39064;&#65292;&#22823;&#22810;&#25968;CD&#26041;&#27861;&#24182;&#19981;&#25552;&#20379;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#36825;&#20351;&#24471;&#29992;&#25143;&#38590;&#20197;&#35299;&#37322;&#32467;&#26524;&#21644;&#25913;&#36827;&#25512;&#26029;&#36807;&#31243;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#23613;&#31649;CD&#26159;&#19968;&#20010;&#20197;&#20154;&#20026;&#20013;&#24515;&#30340;&#20107;&#21153;&#65292;&#20294;&#27809;&#26377;&#20219;&#20309;&#30740;&#31350;&#19987;&#27880;&#20110;&#26500;&#24314;&#26082;&#33021;&#36755;&#20986;&#19987;&#23478;&#21487;&#39564;&#35777;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#21448;&#33021;&#19982;&#19987;&#23478;&#36827;&#34892;&#20132;&#20114;&#36845;&#20195;&#25913;&#36827;&#30340;&#26041;&#27861;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20351;&#29992;&#29983;&#25104;&#27969;&#32593;&#65292;&#26681;&#25454;&#22522;&#20110;&#35780;&#20998;&#20989;&#25968;&#65288;&#22914;&#36125;&#21494;&#26031;&#20449;&#24687;&#20934;&#21017;&#65289;&#30340;&#20449;&#24565;&#20998;&#24067;&#65292;&#25353;&#27604;&#20363;&#23545;&#65288;&#22240;&#26524;&#65289;&#31062;&#20808;&#22270;&#36827;&#34892;&#37319;&#26679;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;&#20505;&#36873;&#22270;&#30340;&#22810;&#26679;&#24615;&#24182;&#24341;&#20837;&#26368;&#20339;&#23454;&#39564;&#35774;&#35745;&#65292;&#20197;&#36845;&#20195;&#24615;&#22320;&#25506;&#32034;&#23454;&#39564;&#26469;&#19982;&#19987;&#23478;&#20114;&#21160;&#12290;
&lt;/p&gt;
&lt;p&gt;
Structure learning is the crux of causal inference. Notably, causal discovery (CD) algorithms are brittle when data is scarce, possibly inferring imprecise causal relations that contradict expert knowledge -- especially when considering latent confounders. To aggravate the issue, most CD methods do not provide uncertainty estimates, making it hard for users to interpret results and improve the inference process. Surprisingly, while CD is a human-centered affair, no works have focused on building methods that both 1) output uncertainty estimates that can be verified by experts and 2) interact with those experts to iteratively refine CD. To solve these issues, we start by proposing to sample (causal) ancestral graphs proportionally to a belief distribution based on a score function, such as the Bayesian information criterion (BIC), using generative flow networks. Then, we leverage the diversity in candidate graphs and introduce an optimal experimental design to iteratively probe the expe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20813;&#30123;&#30340;&#27010;&#29575;&#65292;&#25552;&#20986;&#20102;&#20813;&#30123;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#65292;&#20197;&#21450;&#949;-&#26377;&#30028;&#20813;&#30123;&#30340;&#26465;&#20214;&#12290;&#21516;&#26102;&#65292;&#20511;&#21161;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#20272;&#35745;&#21463;&#30410;&#27010;&#29575;&#65292;&#24182;&#24471;&#21040;&#27604;&#29616;&#26377;&#36793;&#30028;&#26356;&#32039;&#23494;&#30340;&#27010;&#29575;&#36793;&#30028;&#12290;&#27492;&#22806;&#65292;&#20171;&#32461;&#20102;&#38388;&#25509;&#20813;&#30123;&#30340;&#27010;&#24565;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22788;&#29702;&#26410;&#27979;&#37327;&#28151;&#28102;&#30340;&#20813;&#30123;&#27010;&#29575;&#25935;&#24863;&#24615;&#20998;&#26512;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2309.11942</link><description>&lt;p&gt;
&#20851;&#20110;&#20813;&#30123;&#30340;&#27010;&#29575;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Probability of Immunity. (arXiv:2309.11942v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.11942
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20813;&#30123;&#30340;&#27010;&#29575;&#65292;&#25552;&#20986;&#20102;&#20813;&#30123;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#65292;&#20197;&#21450;&#949;-&#26377;&#30028;&#20813;&#30123;&#30340;&#26465;&#20214;&#12290;&#21516;&#26102;&#65292;&#20511;&#21161;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#20272;&#35745;&#21463;&#30410;&#27010;&#29575;&#65292;&#24182;&#24471;&#21040;&#27604;&#29616;&#26377;&#36793;&#30028;&#26356;&#32039;&#23494;&#30340;&#27010;&#29575;&#36793;&#30028;&#12290;&#27492;&#22806;&#65292;&#20171;&#32461;&#20102;&#38388;&#25509;&#20813;&#30123;&#30340;&#27010;&#24565;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22788;&#29702;&#26410;&#27979;&#37327;&#28151;&#28102;&#30340;&#20813;&#30123;&#27010;&#29575;&#25935;&#24863;&#24615;&#20998;&#26512;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#33268;&#21147;&#20110;&#30740;&#31350;&#20813;&#30123;&#30340;&#27010;&#29575;&#65292;&#21363;&#26080;&#35770;&#26292;&#38706;&#19982;&#21542;&#65292;&#25928;&#26524;&#37117;&#20250;&#21457;&#29983;&#12290;&#25105;&#20204;&#23548;&#20986;&#20102;&#20813;&#30123;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#20197;&#21450;&#949;-&#26377;&#30028;&#20813;&#30123;&#30340;&#26465;&#20214;&#65292;&#21069;&#32773;&#20801;&#35768;&#25105;&#20204;&#20174;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#20013;&#20272;&#35745;&#21463;&#30410;&#30340;&#27010;&#29575;&#65288;&#21363;&#21482;&#26377;&#22312;&#26292;&#38706;&#30340;&#24773;&#20917;&#19979;&#25928;&#26524;&#25165;&#20250;&#21457;&#29983;&#65289;&#65292;&#21518;&#32773;&#20801;&#35768;&#25105;&#20204;&#24471;&#21040;&#27604;&#29616;&#26377;&#30340;&#36793;&#30028;&#26356;&#32039;&#23494;&#30340;&#21463;&#30410;&#27010;&#29575;&#36793;&#30028;&#12290;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#38388;&#25509;&#20813;&#30123;&#30340;&#27010;&#24565;&#65288;&#36890;&#36807;&#20171;&#36136;&#65289;&#65292;&#24182;&#23545;&#20854;&#36827;&#34892;&#20102;&#21069;&#36848;&#20998;&#26512;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22312;&#26410;&#27979;&#37327;&#28151;&#28102;&#24773;&#20917;&#19979;&#36827;&#34892;&#20813;&#30123;&#27010;&#29575;&#25935;&#24863;&#24615;&#20998;&#26512;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work is devoted to the study of the probability of immunity, i.e. the effect occurs whether exposed or not. We derive necessary and sufficient conditions for non-immunity and $\epsilon$-bounded immunity, i.e. the probability of immunity is zero and $\epsilon$-bounded, respectively. The former allows us to estimate the probability of benefit (i.e., the effect occurs if and only if exposed) from a randomized controlled trial, and the latter allows us to produce bounds of the probability of benefit that are tighter than the existing ones. We also introduce the concept of indirect immunity (i.e., through a mediator) and repeat our previous analysis for it. Finally, we propose a method for sensitivity analysis of the probability of immunity under unmeasured confounding.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#25913;&#36827;&#30340;&#26041;&#24046;&#26368;&#23567;&#21270;&#30340;&#20998;&#22359;&#37327;&#21270;&#31574;&#30053;&#65292;&#29992;&#20110;&#21387;&#32553;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#28608;&#27963;&#65292;&#23454;&#29616;&#20869;&#23384;&#28040;&#32791;&#30340;&#38477;&#20302;&#21644;&#36816;&#34892;&#26102;&#30340;&#21152;&#36895;&#12290;</title><link>http://arxiv.org/abs/2309.11856</link><description>&lt;p&gt;
&#20351;&#29992;&#25913;&#36827;&#30340;&#26041;&#24046;&#26368;&#23567;&#21270;&#30340;&#20998;&#22359;&#37327;&#21270;&#23545;&#22270;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#28608;&#27963;&#21387;&#32553;
&lt;/p&gt;
&lt;p&gt;
Activation Compression of Graph Neural Networks using Block-wise Quantization with Improved Variance Minimization. (arXiv:2309.11856v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.11856
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#25913;&#36827;&#30340;&#26041;&#24046;&#26368;&#23567;&#21270;&#30340;&#20998;&#22359;&#37327;&#21270;&#31574;&#30053;&#65292;&#29992;&#20110;&#21387;&#32553;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#28608;&#27963;&#65292;&#23454;&#29616;&#20869;&#23384;&#28040;&#32791;&#30340;&#38477;&#20302;&#21644;&#36816;&#34892;&#26102;&#30340;&#21152;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24050;&#32463;&#30740;&#31350;&#20102;&#22823;&#35268;&#27169;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#30340;&#39640;&#25928;&#35757;&#32451;&#65292;&#37325;&#28857;&#26159;&#20943;&#23569;&#20854;&#20869;&#23384;&#28040;&#32791;&#12290;Liu&#31561;&#20154;&#65288;2022&#24180;&#65289;&#25552;&#20986;&#20102;&#26497;&#38480;&#28608;&#27963;&#21387;&#32553;&#65288;EXACT&#65289;&#65292;&#36890;&#36807;&#23558;&#20013;&#38388;&#28608;&#27963;&#22270;&#30340;&#37327;&#21270;&#38477;&#33267;INT2&#31934;&#24230;&#65292;&#23454;&#29616;&#20102;&#20869;&#23384;&#28040;&#32791;&#30340;&#21095;&#28872;&#20943;&#23569;&#12290;&#20182;&#20204;&#22312;&#23454;&#29616;&#22823;&#24133;&#20943;&#23569;GPU&#20869;&#23384;&#28040;&#32791;&#30340;&#21516;&#26102;&#65292;&#34920;&#29616;&#20960;&#20046;&#27809;&#26377;&#38477;&#20302;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#20013;&#38388;&#28608;&#27963;&#22270;&#30340;&#20998;&#22359;&#37327;&#21270;&#65292;&#23545;EXACT&#31574;&#30053;&#36827;&#34892;&#20102;&#25913;&#36827;&#12290;&#25105;&#20204;&#23454;&#39564;&#20998;&#26512;&#20102;&#19981;&#21516;&#30340;&#22359;&#22823;&#23567;&#65292;&#24182;&#23637;&#31034;&#20102;&#36827;&#19968;&#27493;&#30340;&#20869;&#23384;&#28040;&#32791;&#38477;&#20302;&#65288;&gt;15%&#65289;&#21644;&#27599;&#20010;epoch&#30340;&#36816;&#34892;&#26102;&#21152;&#36895;&#65288;&#32422;5%&#65289;&#65292;&#21363;&#20351;&#36827;&#34892;&#20102;&#26497;&#20854;&#22823;&#30340;&#37327;&#21270;&#31243;&#24230;&#65292;&#20063;&#33021;&#33719;&#24471;&#19982;&#21407;&#22987;EXACT&#30456;&#20284;&#30340;&#24615;&#33021;&#26435;&#34913;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23545;EXACT&#20013;&#20851;&#20110;&#20013;&#38388;&#28608;&#27963;&#22270;&#20998;&#24067;&#30340;&#20551;&#35774;&#36827;&#34892;&#20102;&#32416;&#27491;&#65288;&#20551;&#35774;&#20026;u
&lt;/p&gt;
&lt;p&gt;
Efficient training of large-scale graph neural networks (GNNs) has been studied with a specific focus on reducing their memory consumption. Work by Liu et al. (2022) proposed extreme activation compression (EXACT) which demonstrated drastic reduction in memory consumption by performing quantization of the intermediate activation maps down to using INT2 precision. They showed little to no reduction in performance while achieving large reductions in GPU memory consumption. In this work, we present an improvement to the EXACT strategy by using block-wise quantization of the intermediate activation maps. We experimentally analyze different block sizes and show further reduction in memory consumption (&gt;15%), and runtime speedup per epoch (about 5%) even when performing extreme extents of quantization with similar performance trade-offs as with the original EXACT. Further, we present a correction to the assumptions on the distribution of intermediate activation maps in EXACT (assumed to be u
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20934;&#33945;&#29305;&#21345;&#27931;&#65288;QMC&#65289;&#26041;&#27861;&#29992;&#20110;&#19977;&#32500;&#20999;&#29255;Wasserstein&#65288;SW&#65289;&#30340;&#36817;&#20284;&#35745;&#31639;&#65292;&#24182;&#36890;&#36807;&#22810;&#31181;&#26041;&#27861;&#22312;&#19977;&#32500;&#21333;&#20301;&#36229;&#29699;&#38754;&#19978;&#26500;&#36896;&#20102;QMC&#28857;&#38598;&#12290;&#27492;&#22806;&#65292;&#36824;&#20171;&#32461;&#20102;&#23558;QSW&#25193;&#23637;&#20026;&#38543;&#26426;&#20934;&#20999;&#29255;Wasserstein&#65288;RQSW&#65289;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2309.11713</link><description>&lt;p&gt;
&#19977;&#32500;&#20999;&#29255;Wasserstein&#30340;&#20934;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Quasi-Monte Carlo for 3D Sliced Wasserstein. (arXiv:2309.11713v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.11713
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20934;&#33945;&#29305;&#21345;&#27931;&#65288;QMC&#65289;&#26041;&#27861;&#29992;&#20110;&#19977;&#32500;&#20999;&#29255;Wasserstein&#65288;SW&#65289;&#30340;&#36817;&#20284;&#35745;&#31639;&#65292;&#24182;&#36890;&#36807;&#22810;&#31181;&#26041;&#27861;&#22312;&#19977;&#32500;&#21333;&#20301;&#36229;&#29699;&#38754;&#19978;&#26500;&#36896;&#20102;QMC&#28857;&#38598;&#12290;&#27492;&#22806;&#65292;&#36824;&#20171;&#32461;&#20102;&#23558;QSW&#25193;&#23637;&#20026;&#38543;&#26426;&#20934;&#20999;&#29255;Wasserstein&#65288;RQSW&#65289;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Monte Carlo (MC)&#26041;&#27861;&#34987;&#29992;&#20316;&#35745;&#31639;&#20999;&#29255;Wasserstein (SW)&#36317;&#31163;&#30340;&#26631;&#20934;&#26041;&#27861;&#65292;&#22240;&#20026;&#23427;&#22312;&#20998;&#26512;&#24418;&#24335;&#20013;&#20855;&#26377;&#26840;&#25163;&#30340;&#26399;&#26395;&#12290;&#28982;&#32780;&#65292;MC&#26041;&#27861;&#22312;&#26368;&#23567;&#21270;&#32477;&#23545;&#36817;&#20284;&#35823;&#24046;&#26041;&#38754;&#24182;&#19981;&#20248;&#21270;&#12290;&#20026;&#20102;&#25552;&#20379;&#26356;&#22909;&#30340;&#32463;&#39564;SW&#31867;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#20934;&#33945;&#29305;&#21345;&#27931;&#65288;QMC&#65289;&#26041;&#27861;&#30340;&#20934;&#20999;&#29255;Wasserstein&#65288;QSW&#65289;&#36924;&#36817;&#12290;&#20026;&#20102;&#23545;SW&#30340;QMC&#36827;&#34892;&#20840;&#38754;&#30340;&#30740;&#31350;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#19977;&#32500;&#35774;&#32622;&#65292;&#29305;&#21035;&#26159;&#35745;&#31639;&#19977;&#32500;&#27010;&#29575;&#27979;&#24230;&#20043;&#38388;&#30340;SW&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#36890;&#36807;&#23454;&#35777;&#39564;&#35777;&#20102;&#22312;&#19977;&#32500;&#21333;&#20301;&#36229;&#29699;&#38754;&#19978;&#26500;&#36896;QMC&#28857;&#38598;&#30340;&#22810;&#31181;&#26041;&#27861;&#65292;&#21253;&#25324;&#22522;&#20110;&#39640;&#26031;&#30340;&#26144;&#23556;&#65292;&#31561;&#38754;&#31215;&#26144;&#23556;&#65292;&#24191;&#20041;&#34746;&#26059;&#28857;&#21644;&#26368;&#20248;&#21270;&#24046;&#24322;&#33021;&#37327;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#33719;&#24471;&#38543;&#26426;&#20248;&#21270;&#30340;&#26080;&#20559;&#20272;&#35745;&#65292;&#25105;&#20204;&#36890;&#36807;&#22312;&#25152;&#35752;&#35770;&#30340;&#20302;&#32500;&#35774;&#32622;&#20013;&#24341;&#20837;&#38543;&#26426;&#24615;&#65292;&#23558;QSW&#25193;&#23637;&#20026;&#38543;&#26426;&#20934;&#20999;&#29255;Wasserstein&#65288;RQSW&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Monte Carlo (MC) approximation has been used as the standard computation approach for the Sliced Wasserstein (SW) distance, which has an intractable expectation in its analytical form. However, the MC method is not optimal in terms of minimizing the absolute approximation error. To provide a better class of empirical SW, we propose quasi-sliced Wasserstein (QSW) approximations that rely on Quasi-Monte Carlo (QMC) methods. For a comprehensive investigation of QMC for SW, we focus on the 3D setting, specifically computing the SW between probability measures in three dimensions. In greater detail, we empirically verify various ways of constructing QMC points sets on the 3D unit-hypersphere, including Gaussian-based mapping, equal area mapping, generalized spiral points, and optimizing discrepancy energies. Furthermore, to obtain an unbiased estimation for stochastic optimization, we extend QSW into Randomized Quasi-Sliced Wasserstein (RQSW) by introducing randomness to the discussed low-d
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#38543;&#26426;&#20998;&#24067;&#40065;&#26834;&#30340;&#20844;&#24179;&#24615;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#35757;&#32451;&#21644;&#27979;&#35797;&#25968;&#25454;&#20998;&#24067;&#19981;&#19968;&#33268;&#26102;&#20844;&#24179;&#27169;&#22411;&#34920;&#29616;&#19981;&#20934;&#30830;&#30340;&#38382;&#39064;&#65292;&#24182;&#19988;&#19981;&#38656;&#35201;&#30693;&#36947;&#22240;&#26524;&#22270;&#65292;&#20063;&#25903;&#25345;&#20351;&#29992;&#23567;&#25209;&#37327;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2309.11682</link><description>&lt;p&gt;
Dr. FERMI&#65306;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#20998;&#24067;&#40065;&#26834;&#30340;&#20844;&#24179;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Dr. FERMI: A Stochastic Distributionally Robust Fair Empirical Risk Minimization Framework. (arXiv:2309.11682v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.11682
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#38543;&#26426;&#20998;&#24067;&#40065;&#26834;&#30340;&#20844;&#24179;&#24615;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#35757;&#32451;&#21644;&#27979;&#35797;&#25968;&#25454;&#20998;&#24067;&#19981;&#19968;&#33268;&#26102;&#20844;&#24179;&#27169;&#22411;&#34920;&#29616;&#19981;&#20934;&#30830;&#30340;&#38382;&#39064;&#65292;&#24182;&#19988;&#19981;&#38656;&#35201;&#30693;&#36947;&#22240;&#26524;&#22270;&#65292;&#20063;&#25903;&#25345;&#20351;&#29992;&#23567;&#25209;&#37327;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#26368;&#36817;&#20960;&#24180;&#24050;&#32463;&#24191;&#27867;&#30740;&#31350;&#20102;&#35757;&#32451;&#20844;&#24179;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#20294;&#22823;&#22810;&#25968;&#26041;&#27861;&#37117;&#20381;&#36182;&#20110;&#35757;&#32451;&#21644;&#27979;&#35797;&#25968;&#25454;&#20855;&#26377;&#30456;&#20284;&#30340;&#20998;&#24067;&#30340;&#20551;&#35774;&#12290;&#22312;&#20998;&#24067;&#21457;&#29983;&#21464;&#21270;&#30340;&#24773;&#20917;&#19979;&#65292;&#20844;&#24179;&#27169;&#22411;&#21487;&#33021;&#22312;&#27979;&#35797;&#25968;&#25454;&#19978;&#34920;&#29616;&#19981;&#20844;&#24179;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#19968;&#20123;&#38024;&#23545;&#20998;&#24067;&#21464;&#21270;&#30340;&#20844;&#24179;&#23398;&#20064;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#35299;&#20915;&#26041;&#26696;&#37117;&#22522;&#20110;&#20855;&#26377;&#25551;&#36848;&#19981;&#21516;&#29305;&#24449;&#20132;&#20114;&#30340;&#22240;&#26524;&#22270;&#30340;&#20551;&#35774;&#12290;&#27492;&#22806;&#65292;&#29616;&#26377;&#30340;&#31639;&#27861;&#38656;&#35201;&#23436;&#20840;&#35775;&#38382;&#25968;&#25454;&#65292;&#19981;&#33021;&#22312;&#20351;&#29992;&#23567;&#25209;&#37327;&#65288;&#38543;&#26426;/&#25209;&#37327;&#23454;&#29616;&#65289;&#26102;&#20351;&#29992;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#20855;&#26377;&#25910;&#25947;&#20445;&#35777;&#30340;&#38543;&#26426;&#20998;&#24067;&#40065;&#26834;&#20844;&#24179;&#24615;&#26694;&#26550;&#65292;&#19981;&#38656;&#35201;&#23545;&#22240;&#26524;&#22270;&#26377;&#20219;&#20309;&#30693;&#35782;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23558;&#22312;&#20998;&#24067;&#21457;&#29983;&#21464;&#21270;&#30340;&#24773;&#20917;&#19979;&#30340;&#20844;&#24179;&#25512;&#26029;&#38382;&#39064;&#21046;&#23450;&#20026;$L_p$-&#33539;&#30340;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
While training fair machine learning models has been studied extensively in recent years, most developed methods rely on the assumption that the training and test data have similar distributions. In the presence of distribution shifts, fair models may behave unfairly on test data. There have been some developments for fair learning robust to distribution shifts to address this shortcoming. However, most proposed solutions are based on the assumption of having access to the causal graph describing the interaction of different features. Moreover, existing algorithms require full access to data and cannot be used when small batches are used (stochastic/batch implementation). This paper proposes the first stochastic distributionally robust fairness framework with convergence guarantees that do not require knowledge of the causal graph. More specifically, we formulate the fair inference in the presence of the distribution shift as a distributionally robust optimization problem under $L_p$ n
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#31532;&#19968;&#20010;&#22312;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#22238;&#24402;&#38382;&#39064;&#20013;&#22788;&#29702;&#21152;&#27861;&#26080;&#24847;&#35782;&#22122;&#22768;&#30340;&#31639;&#27861;&#12290;&#31639;&#27861;&#30340;&#30446;&#26631;&#26159;&#36890;&#36807;&#26679;&#26412;&#35775;&#38382;&#26469;&#20934;&#30830;&#22320;&#24674;&#22797;&#21442;&#25968;&#21521;&#37327;&#65292;&#20351;&#24471;&#27169;&#22411;&#30340;&#39044;&#27979;&#19982;&#30495;&#23454;&#20540;&#30340;&#35823;&#24046;&#23613;&#21487;&#33021;&#23567;&#12290;</title><link>http://arxiv.org/abs/2309.11657</link><description>&lt;p&gt;
GLM&#22238;&#24402;&#19982;&#26080;&#24847;&#35782;&#25968;&#25454;&#25439;&#22351;
&lt;/p&gt;
&lt;p&gt;
GLM Regression with Oblivious Corruptions. (arXiv:2309.11657v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.11657
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#31532;&#19968;&#20010;&#22312;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#22238;&#24402;&#38382;&#39064;&#20013;&#22788;&#29702;&#21152;&#27861;&#26080;&#24847;&#35782;&#22122;&#22768;&#30340;&#31639;&#27861;&#12290;&#31639;&#27861;&#30340;&#30446;&#26631;&#26159;&#36890;&#36807;&#26679;&#26412;&#35775;&#38382;&#26469;&#20934;&#30830;&#22320;&#24674;&#22797;&#21442;&#25968;&#21521;&#37327;&#65292;&#20351;&#24471;&#27169;&#22411;&#30340;&#39044;&#27979;&#19982;&#30495;&#23454;&#20540;&#30340;&#35823;&#24046;&#23613;&#21487;&#33021;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#65288;GLMs&#65289;&#30340;&#22238;&#24402;&#38382;&#39064;&#20013;&#65292;&#23384;&#22312;&#21152;&#27861;&#26080;&#24847;&#35782;&#22122;&#22768;&#30340;&#31532;&#19968;&#20010;&#31639;&#27861;&#12290;&#25105;&#20204;&#20551;&#35774;&#25105;&#20204;&#26377;&#26679;&#26412;&#35775;&#38382;&#21040;&#30340;&#20363;&#23376;$(x, y)$&#65292;&#20854;&#20013;$y$&#26159;$g(w^* \cdot x)$&#30340;&#24102;&#22122;&#22768;&#27979;&#37327;&#20540;&#12290;&#29305;&#21035;&#22320;&#65292;&#22122;&#22768;&#26631;&#31614;&#30340;&#24418;&#24335;&#20026;$y = g(w^* \cdot x) + \xi + \epsilon$&#65292;&#20854;&#20013;$\xi$&#26159;&#19982;$x$&#29420;&#31435;&#25277;&#21462;&#30340;&#26080;&#24847;&#35782;&#22122;&#22768;&#28385;&#36275;$\Pr[\xi = 0] \geq o(1)$&#65292;&#32780;$\epsilon \sim \mathcal N(0, \sigma^2)$&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#20934;&#30830;&#22320;&#24674;&#22797;&#19968;&#20010;&#21442;&#25968;&#21521;&#37327;$w$&#65292;&#20351;&#24471;&#20989;&#25968;$g(w \cdot x)$&#19982;&#30495;&#23454;&#20540;$g(w^* \cdot x)$&#30456;&#27604;&#20855;&#26377;&#20219;&#24847;&#23567;&#30340;&#35823;&#24046;&#65292;&#32780;&#19981;&#26159;&#19982;&#22122;&#22768;&#27979;&#37327;$y$&#30456;&#27604;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#26368;&#19968;&#33324;&#30340;&#19982;&#20998;&#24067;&#26080;&#20851;&#30340;&#24773;&#20917;&#65292;&#20854;&#20013;&#35299;&#21487;&#33021;&#29978;&#33267;&#19981;&#21487;&#35782;&#21035;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#36820;&#22238;&#19968;&#20010;&#20934;&#30830;&#30340;&#20272;&#35745;&#65292;&#22914;&#26524;&#23427;&#26159;&#21487;&#35782;&#21035;&#30340;&#65292;&#21542;&#21017;
&lt;/p&gt;
&lt;p&gt;
We demonstrate the first algorithms for the problem of regression for generalized linear models (GLMs) in the presence of additive oblivious noise. We assume we have sample access to examples $(x, y)$ where $y$ is a noisy measurement of $g(w^* \cdot x)$. In particular, \new{the noisy labels are of the form} $y = g(w^* \cdot x) + \xi + \epsilon$, where $\xi$ is the oblivious noise drawn independently of $x$ \new{and satisfies} $\Pr[\xi = 0] \geq o(1)$, and $\epsilon \sim \mathcal N(0, \sigma^2)$. Our goal is to accurately recover a \new{parameter vector $w$ such that the} function $g(w \cdot x)$ \new{has} arbitrarily small error when compared to the true values $g(w^* \cdot x)$, rather than the noisy measurements $y$.  We present an algorithm that tackles \new{this} problem in its most general distribution-independent setting, where the solution may not \new{even} be identifiable. \new{Our} algorithm returns \new{an accurate estimate of} the solution if it is identifiable, and otherwise
&lt;/p&gt;</description></item><item><title>&#36817;&#24180;&#26469;&#65292;&#20851;&#20110;&#37327;&#23376;&#31995;&#32479;&#23398;&#20064;&#24615;&#36136;&#20197;&#21450;&#36890;&#36807;&#37327;&#23376;&#35745;&#31639;&#22788;&#29702;&#32463;&#20856;&#25110;&#37327;&#23376;&#25968;&#25454;&#30340;&#38382;&#39064;&#26085;&#30410;&#27963;&#36291;&#12290;&#36825;&#31687;&#25991;&#31456;&#22238;&#39038;&#20102;&#37327;&#23376;&#23398;&#20064;&#30340;&#32479;&#35745;&#22797;&#26434;&#24615;&#65292;&#37325;&#28857;&#20851;&#27880;&#25968;&#25454;&#22797;&#26434;&#24615;&#12289;&#22797;&#21046;&#22797;&#26434;&#24615;&#21644;&#27169;&#22411;&#22797;&#26434;&#24615;&#12290;&#37327;&#23376;&#27979;&#37327;&#30772;&#22351;&#24615;&#23548;&#33268;&#22797;&#21046;&#22797;&#26434;&#24615;&#65292;&#38480;&#21046;&#20102;&#20174;&#37327;&#23376;&#25968;&#25454;&#20013;&#25552;&#21462;&#20449;&#24687;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2309.11617</link><description>&lt;p&gt;
&#37327;&#23376;&#23398;&#20064;&#30340;&#32479;&#35745;&#22797;&#26434;&#24615;
&lt;/p&gt;
&lt;p&gt;
Statistical Complexity of Quantum Learning. (arXiv:2309.11617v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.11617
&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#20851;&#20110;&#37327;&#23376;&#31995;&#32479;&#23398;&#20064;&#24615;&#36136;&#20197;&#21450;&#36890;&#36807;&#37327;&#23376;&#35745;&#31639;&#22788;&#29702;&#32463;&#20856;&#25110;&#37327;&#23376;&#25968;&#25454;&#30340;&#38382;&#39064;&#26085;&#30410;&#27963;&#36291;&#12290;&#36825;&#31687;&#25991;&#31456;&#22238;&#39038;&#20102;&#37327;&#23376;&#23398;&#20064;&#30340;&#32479;&#35745;&#22797;&#26434;&#24615;&#65292;&#37325;&#28857;&#20851;&#27880;&#25968;&#25454;&#22797;&#26434;&#24615;&#12289;&#22797;&#21046;&#22797;&#26434;&#24615;&#21644;&#27169;&#22411;&#22797;&#26434;&#24615;&#12290;&#37327;&#23376;&#27979;&#37327;&#30772;&#22351;&#24615;&#23548;&#33268;&#22797;&#21046;&#22797;&#26434;&#24615;&#65292;&#38480;&#21046;&#20102;&#20174;&#37327;&#23376;&#25968;&#25454;&#20013;&#25552;&#21462;&#20449;&#24687;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#20960;&#24180;&#65292;&#22312;&#20351;&#29992;&#25968;&#25454;&#23398;&#20064;&#20851;&#20110;&#37327;&#23376;&#31995;&#32479;&#30340;&#24615;&#36136;&#25110;&#36890;&#36807;&#37327;&#23376;&#35745;&#31639;&#22788;&#29702;&#32463;&#20856;&#25110;&#37327;&#23376;&#25968;&#25454;&#30340;&#38382;&#39064;&#19978;&#20986;&#29616;&#20102;&#30456;&#24403;&#22823;&#30340;&#27963;&#36291;&#24230;&#12290;&#19982;&#32463;&#20856;&#23398;&#20064;&#31867;&#20284;&#65292;&#37327;&#23376;&#23398;&#20064;&#38382;&#39064;&#28041;&#21450;&#21040;&#25968;&#25454;&#29983;&#25104;&#26426;&#21046;&#26410;&#30693;&#30340;&#35774;&#32622;&#65292;&#23398;&#20064;&#31639;&#27861;&#30340;&#20027;&#35201;&#30446;&#26631;&#26159;&#22312;&#20165;&#26377;&#25968;&#25454;&#21644;&#21487;&#33021;&#30340;&#36741;&#21161;&#20449;&#24687;&#65288;&#27604;&#22914;&#19987;&#23478;&#30693;&#35782;&#65289;&#30340;&#24773;&#20917;&#19979;&#20445;&#35777;&#28385;&#24847;&#30340;&#20934;&#30830;&#24230;&#27700;&#24179;&#12290;&#26412;&#25991;&#36890;&#36807;&#24212;&#29992;&#20449;&#24687;&#35770;&#25216;&#26415;&#65292;&#37325;&#28857;&#20851;&#27880;&#25968;&#25454;&#22797;&#26434;&#24615;&#12289;&#22797;&#21046;&#22797;&#26434;&#24615;&#21644;&#27169;&#22411;&#22797;&#26434;&#24615;&#65292;&#22238;&#39038;&#20102;&#37327;&#23376;&#23398;&#20064;&#30340;&#22797;&#26434;&#24615;&#12290;&#22797;&#21046;&#22797;&#26434;&#24615;&#28304;&#20110;&#37327;&#23376;&#27979;&#37327;&#30340;&#30772;&#22351;&#24615;&#65292;&#36825;&#31181;&#27979;&#37327;&#20250;&#19981;&#21487;&#36870;&#22320;&#25913;&#21464;&#24453;&#22788;&#29702;&#30340;&#29366;&#24577;&#65292;&#38480;&#21046;&#20102;&#33021;&#20174;&#37327;&#23376;&#25968;&#25454;&#20013;&#25552;&#21462;&#30340;&#20449;&#24687;&#12290;&#20363;&#22914;&#65292;&#22312;&#37327;&#23376;&#31995;&#32479;&#20013;&#65292;&#19982;&#32463;&#20856;&#26426;&#22120;&#23398;&#20064;&#19981;&#21516;&#65292;&#36890;&#24120;&#19981;&#21487;&#33021;&#21516;&#26102;&#35780;&#20272;&#35757;&#32451;&#25439;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent years have seen significant activity on the problem of using data for the purpose of learning properties of quantum systems or of processing classical or quantum data via quantum computing. As in classical learning, quantum learning problems involve settings in which the mechanism generating the data is unknown, and the main goal of a learning algorithm is to ensure satisfactory accuracy levels when only given access to data and, possibly, side information such as expert knowledge. This article reviews the complexity of quantum learning using information-theoretic techniques by focusing on data complexity, copy complexity, and model complexity. Copy complexity arises from the destructive nature of quantum measurements, which irreversibly alter the state to be processed, limiting the information that can be extracted about quantum data. For example, in a quantum system, unlike in classical machine learning, it is generally not possible to evaluate the training loss simultaneously
&lt;/p&gt;</description></item><item><title>TrueLearn&#26159;&#19968;&#20010;Python&#24211;&#65292;&#29992;&#20110;&#26500;&#24314;&#20010;&#24615;&#21270;&#30340;&#20449;&#24687;&#25512;&#33616;&#31995;&#32479;&#65292;&#24182;&#25552;&#20379;&#20102;&#20016;&#23500;&#30340;&#25991;&#26723;&#21644;&#32534;&#30721;&#31034;&#20363;&#65292;&#21487;&#24110;&#21161;&#24320;&#21457;&#20154;&#21592;&#21644;&#20174;&#19994;&#32773;&#20351;&#29992;&#12290;&#23427;&#37319;&#29992;&#20102;&#24320;&#25918;&#23398;&#20064;&#32773;&#30340;&#27010;&#24565;&#21644;&#20154;&#24615;&#21270;&#30340;&#29992;&#25143;&#34920;&#36798;&#26041;&#24335;&#65292;&#21516;&#26102;&#25903;&#25345;&#29992;&#25143;&#21487;&#35270;&#21270;&#21644;&#27169;&#22411;&#24615;&#33021;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2309.11527</link><description>&lt;p&gt;
TrueLearn: &#19968;&#31181;&#29992;&#20110;&#20010;&#24615;&#21270;&#20449;&#24687;&#25512;&#33616;&#30340;Python&#24211;&#65288;&#24102;&#26377;&#65288;&#38544;&#24335;&#65289;&#21453;&#39304;&#65289;
&lt;/p&gt;
&lt;p&gt;
TrueLearn: A Python Library for Personalised Informational Recommendations with (Implicit) Feedback. (arXiv:2309.11527v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.11527
&lt;/p&gt;
&lt;p&gt;
TrueLearn&#26159;&#19968;&#20010;Python&#24211;&#65292;&#29992;&#20110;&#26500;&#24314;&#20010;&#24615;&#21270;&#30340;&#20449;&#24687;&#25512;&#33616;&#31995;&#32479;&#65292;&#24182;&#25552;&#20379;&#20102;&#20016;&#23500;&#30340;&#25991;&#26723;&#21644;&#32534;&#30721;&#31034;&#20363;&#65292;&#21487;&#24110;&#21161;&#24320;&#21457;&#20154;&#21592;&#21644;&#20174;&#19994;&#32773;&#20351;&#29992;&#12290;&#23427;&#37319;&#29992;&#20102;&#24320;&#25918;&#23398;&#20064;&#32773;&#30340;&#27010;&#24565;&#21644;&#20154;&#24615;&#21270;&#30340;&#29992;&#25143;&#34920;&#36798;&#26041;&#24335;&#65292;&#21516;&#26102;&#25903;&#25345;&#29992;&#25143;&#21487;&#35270;&#21270;&#21644;&#27169;&#22411;&#24615;&#33021;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;TrueLearn Python&#24211;&#65292;&#20854;&#20013;&#21253;&#21547;&#19968;&#32452;&#22312;&#32447;&#23398;&#20064;&#36125;&#21494;&#26031;&#27169;&#22411;&#65292;&#29992;&#20110;&#26500;&#24314;&#25945;&#32946;&#65288;&#25110;&#26356;&#19968;&#33324;&#22320;&#35828;&#65292;&#20449;&#24687;&#65289;&#25512;&#33616;&#31995;&#32479;&#12290;&#36825;&#32452;&#27169;&#22411;&#26159;&#26681;&#25454;&#8220;&#24320;&#25918;&#23398;&#20064;&#32773;&#8221;&#30340;&#27010;&#24565;&#35774;&#35745;&#30340;&#65292;&#20351;&#29992;&#30452;&#35266;&#30340;&#29992;&#25143;&#34920;&#36798;&#12290;&#20026;&#20102;&#21487;&#35299;&#37322;&#24615;&#21644;&#35753;&#29992;&#25143;&#26377;&#25511;&#21046;&#24863;&#65292;TrueLearn&#24211;&#36824;&#21253;&#21547;&#19981;&#21516;&#30340;&#34920;&#31034;&#24418;&#24335;&#65292;&#20197;&#24110;&#21161;&#26368;&#32456;&#29992;&#25143;&#21487;&#35270;&#21270;&#23398;&#20064;&#32773;&#27169;&#22411;&#65292;&#36825;&#21487;&#33021;&#26377;&#21161;&#20110;&#23558;&#26469;&#29992;&#25143;&#19982;&#33258;&#24049;&#30340;&#27169;&#22411;&#36827;&#34892;&#20132;&#20114;&#12290;&#19982;&#35813;&#24211;&#19968;&#36215;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#20010;&#20808;&#21069;&#20844;&#24320;&#21457;&#24067;&#30340;&#38544;&#24335;&#21453;&#39304;&#25945;&#32946;&#25968;&#25454;&#38598;&#21644;&#35780;&#20272;&#25351;&#26631;&#65292;&#20197;&#34913;&#37327;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#20016;&#23500;&#30340;&#25991;&#26723;&#21644;&#32534;&#30721;&#31034;&#20363;&#20351;&#35813;&#24211;&#23545;&#26426;&#22120;&#23398;&#20064;&#24320;&#21457;&#20154;&#21592;&#21644;&#25945;&#32946;&#25968;&#25454;&#25366;&#25496;&#21644;&#23398;&#20064;&#20998;&#26512;&#20174;&#19994;&#32773;&#37117;&#38750;&#24120;&#26131;&#20110;&#20351;&#29992;&#12290;&#35813;&#24211;&#21644;&#24102;&#26377;&#31034;&#20363;&#30340;&#25903;&#25345;&#25991;&#26723;&#21487;&#22312;https&#65306;//&#33719;&#24471;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work describes the TrueLearn Python library, which contains a family of online learning Bayesian models for building educational (or more generally, informational) recommendation systems. This family of models was designed following the "open learner" concept, using humanly-intuitive user representations. For the sake of interpretability and putting the user in control, the TrueLearn library also contains different representations to help end-users visualise the learner models, which may in the future facilitate user interaction with their own models. Together with the library, we include a previously publicly released implicit feedback educational dataset with evaluation metrics to measure the performance of the models. The extensive documentation and coding examples make the library highly accessible to both machine learning developers and educational data mining and learning analytic practitioners. The library and the support documentation with examples are available at https:/
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#24052;&#35199;&#33889;&#33796;&#29273;&#35821;&#30340;&#20551;&#26032;&#38395;&#26816;&#27979;&#24179;&#21488;&#65292;&#37319;&#29992;&#26426;&#22120;&#23398;&#20064;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#25216;&#26415;&#65292;&#33021;&#22815;&#39640;&#25928;&#20934;&#30830;&#22320;&#35782;&#21035;&#20551;&#26032;&#38395;&#65292;&#21516;&#26102;&#25552;&#20379;&#23454;&#26102;&#20998;&#26512;&#21644;&#39564;&#35777;&#26032;&#38395;&#25991;&#31456;&#30495;&#23454;&#24615;&#30340;&#29992;&#25143;&#21451;&#22909;&#24179;&#21488;&#12290;</title><link>http://arxiv.org/abs/2309.11052</link><description>&lt;p&gt;
Fake News BR: &#19968;&#31181;&#29992;&#20110;&#24052;&#35199;&#33889;&#33796;&#29273;&#35821;&#30340;&#20551;&#26032;&#38395;&#26816;&#27979;&#24179;&#21488;
&lt;/p&gt;
&lt;p&gt;
Fake News BR: A Fake News Detection Platform for Brazilian Portuguese. (arXiv:2309.11052v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.11052
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#24052;&#35199;&#33889;&#33796;&#29273;&#35821;&#30340;&#20551;&#26032;&#38395;&#26816;&#27979;&#24179;&#21488;&#65292;&#37319;&#29992;&#26426;&#22120;&#23398;&#20064;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#25216;&#26415;&#65292;&#33021;&#22815;&#39640;&#25928;&#20934;&#30830;&#22320;&#35782;&#21035;&#20551;&#26032;&#38395;&#65292;&#21516;&#26102;&#25552;&#20379;&#23454;&#26102;&#20998;&#26512;&#21644;&#39564;&#35777;&#26032;&#38395;&#25991;&#31456;&#30495;&#23454;&#24615;&#30340;&#29992;&#25143;&#21451;&#22909;&#24179;&#21488;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#20551;&#26032;&#38395;&#20256;&#25773;&#35823;&#23548;&#20844;&#20247;&#33286;&#35770;&#30340;&#28508;&#21147;&#65292;&#20854;&#20256;&#25773;&#24050;&#25104;&#20026;&#36817;&#26399;&#20851;&#27880;&#30340;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#12290;&#26412;&#25991;&#23545;&#24052;&#35199;&#33889;&#33796;&#29273;&#35821;&#20013;&#30340;&#20551;&#26032;&#38395;&#26816;&#27979;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#30740;&#31350;&#65292;&#37325;&#28857;&#20851;&#27880;&#26032;&#38395;&#31867;&#22411;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#25216;&#26415;&#65292;&#21253;&#25324;TF-IDF&#21644;Word2Vec&#65292;&#20174;&#25991;&#26412;&#25968;&#25454;&#20013;&#25552;&#21462;&#29305;&#24449;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#21508;&#31181;&#20998;&#31867;&#31639;&#27861;&#30340;&#24615;&#33021;&#65292;&#22914;&#36923;&#36753;&#22238;&#24402;&#12289;&#25903;&#25345;&#21521;&#37327;&#26426;&#12289;&#38543;&#26426;&#26862;&#26519;&#12289;AdaBoost&#21644;LightGBM&#65292;&#20351;&#29992;&#21253;&#21547;&#30495;&#23454;&#21644;&#20551;&#26032;&#38395;&#25991;&#31456;&#30340;&#25968;&#25454;&#38598;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#20934;&#30830;&#29575;&#21644;F1&#24471;&#20998;&#19978;&#37117;&#21462;&#24471;&#20102;&#39640;&#27700;&#24179;&#65292;&#35777;&#26126;&#20102;&#20854;&#35782;&#21035;&#20551;&#26032;&#38395;&#30340;&#26377;&#25928;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#29992;&#25143;&#21451;&#22909;&#30340;&#32593;&#31449;&#24179;&#21488;FAKENEWSBR.COM&#65292;&#20197;&#20415;&#39564;&#35777;&#26032;&#38395;&#25991;&#31456;&#30340;&#30495;&#23454;&#24615;&#12290;&#25105;&#20204;&#30340;&#24179;&#21488;&#25552;&#20379;&#23454;&#26102;&#20998;&#26512;&#65292;&#20801;&#35768;&#29992;&#25143;&#26816;&#26597;&#26032;&#38395;&#25991;&#31456;&#30340;&#30495;&#23454;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The proliferation of fake news has become a significant concern in recent times due to its potential to spread misinformation and manipulate public opinion. In this paper, we present a comprehensive study on the detection of fake news in Brazilian Portuguese, focusing on journalistic-type news. We propose a machine learning-based approach that leverages natural language processing techniques, including TF-IDF and Word2Vec, to extract features from textual data. We evaluate the performance of various classification algorithms, such as logistic regression, support vector machine, random forest, AdaBoost, and LightGBM, on a dataset containing both true and fake news articles. The proposed approach achieves a high level of accuracy and F1-Score, demonstrating its effectiveness in identifying fake news. Additionally, we develop a user-friendly web platform, FAKENEWSBR.COM, to facilitate the verification of news articles' veracity. Our platform provides real-time analysis, allowing users to 
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#35299;&#20915;&#20102;&#23545;&#20110;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#20013;&#19981;&#21516;&#27169;&#24335;&#30340;&#36861;&#36394;&#21644;&#29702;&#35299;&#30340;&#38382;&#39064;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#30456;&#20301;&#22270;&#26469;&#21306;&#20998;&#22122;&#22768;&#20027;&#23548;&#30340;SGD&#21644;&#22823;&#27493;&#39588;&#20027;&#23548;&#30340;SGD&#12290;</title><link>http://arxiv.org/abs/2309.10688</link><description>&lt;p&gt;
&#20851;&#20110;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#19981;&#21516;&#27169;&#24335;
&lt;/p&gt;
&lt;p&gt;
On the different regimes of Stochastic Gradient Descent. (arXiv:2309.10688v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.10688
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#35299;&#20915;&#20102;&#23545;&#20110;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#20013;&#19981;&#21516;&#27169;&#24335;&#30340;&#36861;&#36394;&#21644;&#29702;&#35299;&#30340;&#38382;&#39064;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#30456;&#20301;&#22270;&#26469;&#21306;&#20998;&#22122;&#22768;&#20027;&#23548;&#30340;SGD&#21644;&#22823;&#27493;&#39588;&#20027;&#23548;&#30340;SGD&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#28145;&#24230;&#32593;&#32476;&#36890;&#36807;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#36827;&#34892;&#35757;&#32451;&#65292;&#20854;&#20851;&#38190;&#21442;&#25968;&#26159;&#27599;&#20010;&#27493;&#39588;&#32771;&#34385;&#30340;&#25968;&#25454;&#37327;&#25110;&#25209;&#37327;&#22823;&#23567;B&#20197;&#21450;&#27493;&#38271;&#25110;&#23398;&#20064;&#29575;&#951;&#12290;&#23545;&#20110;&#23567;&#30340;B&#21644;&#22823;&#30340;&#951;&#65292;SGD&#23545;&#24212;&#20110;&#21442;&#25968;&#30340;&#38543;&#26426;&#28436;&#21270;&#65292;&#20854;&#22122;&#22768;&#24133;&#24230;&#30001;&#8220;&#28201;&#24230;&#8221;T=&#951;/B&#25511;&#21046;&#12290;&#28982;&#32780;&#24403;&#25209;&#37327;&#22823;&#23567;B&#8805;B^*&#36275;&#22815;&#22823;&#26102;&#65292;&#36825;&#31181;&#25551;&#36848;&#34987;&#35266;&#23519;&#21040;&#22833;&#25928;&#65292;&#25110;&#32773;&#22312;&#28201;&#24230;&#36275;&#22815;&#23567;&#26102;&#31616;&#21270;&#20026;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#12290;&#29702;&#35299;&#36825;&#20123;&#20132;&#21449;&#21457;&#29983;&#30340;&#20301;&#32622;&#20173;&#28982;&#26159;&#19968;&#20010;&#20013;&#24515;&#25361;&#25112;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#36825;&#20123;&#38382;&#39064;&#65292;&#22312;&#19968;&#20010;&#25945;&#24072;-&#23398;&#29983;&#24863;&#30693;&#22120;&#20998;&#31867;&#27169;&#22411;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#20851;&#38190;&#39044;&#27979;&#20173;&#36866;&#29992;&#20110;&#28145;&#24230;&#32593;&#32476;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#22312;B-&#951;&#24179;&#38754;&#19978;&#33719;&#24471;&#20102;&#19968;&#20010;&#30456;&#20301;&#22270;&#65292;&#23558;&#19977;&#20010;&#21160;&#24577;&#38454;&#27573;&#20998;&#24320;&#65306;&#65288;i&#65289;&#21463;&#28201;&#24230;&#25511;&#21046;&#30340;&#22122;&#22768;&#20027;&#23548;&#30340;SGD&#65292;&#65288;ii&#65289;&#22823;&#27493;&#39588;&#20027;&#23548;&#30340;SGD&#21644;
&lt;/p&gt;
&lt;p&gt;
Modern deep networks are trained with stochastic gradient descent (SGD) whose key parameters are the number of data considered at each step or batch size $B$, and the step size or learning rate $\eta$. For small $B$ and large $\eta$, SGD corresponds to a stochastic evolution of the parameters, whose noise amplitude is governed by the `temperature' $T\equiv \eta/B$. Yet this description is observed to break down for sufficiently large batches $B\geq B^*$, or simplifies to gradient descent (GD) when the temperature is sufficiently small. Understanding where these cross-overs take place remains a central challenge. Here we resolve these questions for a teacher-student perceptron classification model, and show empirically that our key predictions still apply to deep networks. Specifically, we obtain a phase diagram in the $B$-$\eta$ plane that separates three dynamical phases: $\textit{(i)}$ a noise-dominated SGD governed by temperature, $\textit{(ii)}$ a large-first-step-dominated SGD and
&lt;/p&gt;</description></item><item><title>&#23398;&#20064;&#20108;&#20803;&#20551;&#35774;&#31867;&#20855;&#26377;&#26679;&#26412;&#21387;&#32553;&#26041;&#26696;&#65292;&#32780;&#22810;&#31867;&#21035;&#20551;&#35774;&#31867;&#21017;&#19981;&#20855;&#22791;&#36825;&#20010;&#24615;&#36136;&#12290;</title><link>http://arxiv.org/abs/2308.06424</link><description>&lt;p&gt;
&#23398;&#20064;&#33021;&#21147;&#19982;&#26679;&#26412;&#21387;&#32553;&#24182;&#19981;&#30456;&#21516;&#30340;&#22810;&#31867;&#21035;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Multiclass Learnability Does Not Imply Sample Compression. (arXiv:2308.06424v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06424
&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#20108;&#20803;&#20551;&#35774;&#31867;&#20855;&#26377;&#26679;&#26412;&#21387;&#32553;&#26041;&#26696;&#65292;&#32780;&#22810;&#31867;&#21035;&#20551;&#35774;&#31867;&#21017;&#19981;&#20855;&#22791;&#36825;&#20010;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#26524;&#19968;&#20010;&#20551;&#35774;&#31867;&#33021;&#22815;&#36890;&#36807;&#21482;&#20445;&#30041;&#19968;&#20010;&#23567;&#30340;&#23376;&#26679;&#26412;&#25512;&#26029;&#20986;&#25972;&#20010;&#26679;&#26412;&#30340;&#26631;&#31614;&#65292;&#37027;&#20040;&#23427;&#23601;&#20855;&#26377;&#26679;&#26412;&#21387;&#32553;&#26041;&#26696;&#12290;&#23398;&#20064;&#20108;&#20803;&#20551;&#35774;&#31867;&#65288;&#24517;&#39035;&#20855;&#26377;&#26377;&#38480;&#30340;VC&#32500;&#24230;&#65289;&#37117;&#21487;&#20197;&#36890;&#36807;VC&#32500;&#24230;&#30340;&#19968;&#20010;&#26377;&#38480;&#20989;&#25968;&#22823;&#23567;&#30340;&#26679;&#26412;&#21387;&#32553;&#26041;&#26696;&#23454;&#29616;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#22810;&#31867;&#21035;&#20551;&#35774;&#31867;&#26469;&#35828;&#65292;DS&#32500;&#24230;&#26159;&#30456;&#23545;&#24212;&#30340;&#65292;&#25105;&#20204;&#21457;&#29616;&#23398;&#20064;&#22810;&#31867;&#21035;&#20551;&#35774;&#31867;&#65288;&#24517;&#39035;&#20855;&#26377;&#26377;&#38480;&#30340;DS&#32500;&#24230;&#65289;&#24182;&#19981;&#33021;&#36890;&#36807;&#19968;&#20010;DS&#32500;&#24230;&#30340;&#26377;&#38480;&#20989;&#25968;&#22823;&#23567;&#30340;&#26679;&#26412;&#21387;&#32553;&#26041;&#26696;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
A hypothesis class admits a sample compression scheme, if for every sample labeled by a hypothesis from the class, it is possible to retain only a small subsample, using which the labels on the entire sample can be inferred. The size of the compression scheme is an upper bound on the size of the subsample produced. Every learnable binary hypothesis class (which must necessarily have finite VC dimension) admits a sample compression scheme of size only a finite function of its VC dimension, independent of the sample size. For multiclass hypothesis classes, the analog of VC dimension is the DS dimension. We show that the analogous statement pertaining to sample compression is not true for multiclass hypothesis classes: every learnable multiclass hypothesis class, which must necessarily have finite DS dimension, does not admit a sample compression scheme of size only a finite function of its DS dimension.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#24773;&#22659;&#36172;&#21338;&#35774;&#32622;&#30340;&#26032;&#22411;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#36172;&#21338;&#31639;&#27861;&#65292;&#20855;&#26377;&#31616;&#21333;&#21644;&#32047;&#31215;&#36951;&#25022;&#26368;&#23567;&#21270;&#30340;&#20248;&#21183;&#65292;&#24182;&#21487;&#33258;&#36866;&#24212;&#27169;&#22411;&#38169;&#35823;&#35268;&#33539;&#21644;&#36830;&#32493;&#33218;&#35774;&#32622;&#12290;&#35813;&#31639;&#27861;&#21033;&#29992;"&#19968;&#33268;&#33218;&#38598;"&#65288;CAS&#65289;&#26469;&#25552;&#20379;&#22312;&#27599;&#20010;&#24773;&#22659;&#19979;&#22218;&#25324;&#24773;&#22659;&#29305;&#23450;&#30340;&#26368;&#20339;&#33218;&#30340;&#19968;&#32452;&#33218;&#65292;&#36328;&#36234;&#24773;&#22659;&#20998;&#24067;&#12290;&#36825;&#31687;&#35770;&#25991;&#23545;&#31616;&#21333;&#21644;&#32047;&#31215;&#36951;&#25022;&#20445;&#35777;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#27491;&#38754;&#32467;&#26524;&#65292;&#21516;&#26102;&#20063;&#25581;&#31034;&#20102;&#26080;&#27861;&#23454;&#29616;&#23454;&#20363;&#20381;&#36182;&#24615;&#30340;&#31616;&#21333;&#36951;&#25022;&#20445;&#35777;&#30340;&#28040;&#26497;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2307.02108</link><description>&lt;p&gt;
&#27604;&#20363;&#21709;&#24212;&#65306;&#29992;&#20110;&#31616;&#21333;&#21644;&#32047;&#31215;&#36951;&#25022;&#26368;&#23567;&#21270;&#30340;&#24773;&#22659;&#36172;&#21338;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Proportional Response: Contextual Bandits for Simple and Cumulative Regret Minimization. (arXiv:2307.02108v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02108
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#24773;&#22659;&#36172;&#21338;&#35774;&#32622;&#30340;&#26032;&#22411;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#36172;&#21338;&#31639;&#27861;&#65292;&#20855;&#26377;&#31616;&#21333;&#21644;&#32047;&#31215;&#36951;&#25022;&#26368;&#23567;&#21270;&#30340;&#20248;&#21183;&#65292;&#24182;&#21487;&#33258;&#36866;&#24212;&#27169;&#22411;&#38169;&#35823;&#35268;&#33539;&#21644;&#36830;&#32493;&#33218;&#35774;&#32622;&#12290;&#35813;&#31639;&#27861;&#21033;&#29992;"&#19968;&#33268;&#33218;&#38598;"&#65288;CAS&#65289;&#26469;&#25552;&#20379;&#22312;&#27599;&#20010;&#24773;&#22659;&#19979;&#22218;&#25324;&#24773;&#22659;&#29305;&#23450;&#30340;&#26368;&#20339;&#33218;&#30340;&#19968;&#32452;&#33218;&#65292;&#36328;&#36234;&#24773;&#22659;&#20998;&#24067;&#12290;&#36825;&#31687;&#35770;&#25991;&#23545;&#31616;&#21333;&#21644;&#32047;&#31215;&#36951;&#25022;&#20445;&#35777;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#27491;&#38754;&#32467;&#26524;&#65292;&#21516;&#26102;&#20063;&#25581;&#31034;&#20102;&#26080;&#27861;&#23454;&#29616;&#23454;&#20363;&#20381;&#36182;&#24615;&#30340;&#31616;&#21333;&#36951;&#25022;&#20445;&#35777;&#30340;&#28040;&#26497;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21307;&#30103;&#20445;&#20581;&#21644;&#30005;&#23376;&#21830;&#21153;&#31561;&#39046;&#22495;&#65292;&#31616;&#21333;&#36951;&#25022;&#26368;&#23567;&#21270;&#26159;&#23398;&#20064;&#26368;&#20339;&#27835;&#30103;&#20998;&#37197;&#31574;&#30053;&#30340;&#20851;&#38190;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#24773;&#22659;&#36172;&#21338;&#35774;&#32622;&#20013;&#30340;&#31616;&#21333;&#36951;&#25022;&#26368;&#23567;&#21270;&#38382;&#39064;&#20173;&#26410;&#20805;&#20998;&#30740;&#31350;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#36172;&#21338;&#31639;&#27861;&#26063;&#65292;&#38024;&#23545;&#38543;&#26426;&#24773;&#22659;&#36172;&#21338;&#35774;&#32622;&#65292;&#22312;&#32047;&#31215;&#36951;&#25022;&#26368;&#23567;&#21270;&#65288;&#20855;&#26377;&#36817;&#20046;&#26368;&#20248;&#30340;&#26497;&#23567;&#26497;&#22823;&#20445;&#35777;&#65289;&#21644;&#31616;&#21333;&#36951;&#25022;&#26368;&#23567;&#21270;&#65288;&#20855;&#26377;SOTA&#20445;&#35777;&#65289;&#26041;&#38754;&#20855;&#26377;&#28789;&#27963;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#23545;&#27169;&#22411;&#38169;&#35823;&#35268;&#33539;&#36827;&#34892;&#33258;&#36866;&#24212;&#65292;&#24182;&#25193;&#23637;&#21040;&#36830;&#32493;&#33218;&#35774;&#32622;&#12290;&#36825;&#20123;&#20248;&#21183;&#26469;&#33258;&#20110;&#26500;&#24314;&#21644;&#20381;&#36182;&#20110;&#8220;&#19968;&#33268;&#33218;&#38598;&#8221;&#65288;CAS&#65289;&#65292;CAS&#22312;&#27599;&#20010;&#24773;&#22659;&#19979;&#25552;&#20379;&#19968;&#32452;&#33218;&#65292;&#36825;&#20123;&#33218;&#20197;&#19968;&#23450;&#30340;&#27010;&#29575;&#22218;&#25324;&#20102;&#24773;&#22659;&#29305;&#23450;&#30340;&#26368;&#20339;&#33218;&#65292;&#36328;&#36234;&#20102;&#24773;&#22659;&#20998;&#24067;&#12290;&#25105;&#20204;&#20851;&#20110;&#31616;&#21333;&#21644;&#32047;&#31215;&#36951;&#25022;&#20445;&#35777;&#30340;&#31215;&#26497;&#32467;&#26524;&#19982;&#19968;&#20010;&#28040;&#26497;&#32467;&#26524;&#24418;&#25104;&#23545;&#27604;&#65292;&#21518;&#32773;&#34920;&#26126;&#19968;&#20010;&#31639;&#27861;&#26080;&#27861;&#23454;&#29616;&#23454;&#20363;&#20381;&#36182;&#24615;&#30340;&#31616;&#21333;&#36951;&#25022;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Simple regret minimization is a critical problem in learning optimal treatment assignment policies across various domains, including healthcare and e-commerce. However, it remains understudied in the contextual bandit setting. We propose a new family of computationally efficient bandit algorithms for the stochastic contextual bandit settings, with the flexibility to be adapted for cumulative regret minimization (with near-optimal minimax guarantees) and simple regret minimization (with SOTA guarantees). Furthermore, our algorithms adapt to model misspecification and extend to the continuous arm settings. These advantages come from constructing and relying on "conformal arm sets" (CASs), which provide a set of arms at every context that encompass the context-specific optimal arm with some probability across the context distribution. Our positive results on simple and cumulative regret guarantees are contrasted by a negative result, which shows that an algorithm can't achieve instance-de
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#33258;&#36866;&#24212;&#31639;&#27861;(&#22914;Adagrad&#21644;Adam)&#30340;&#23398;&#20064;&#29575;&#20272;&#35745;&#26041;&#27861;Prodigy&#21644;Resetting&#65292;&#21487;&#20197;&#24555;&#36895;&#19988;&#27491;&#30830;&#22320;&#20272;&#35745;&#21040;&#36798;&#35299;&#20915;&#26041;&#26696;&#25152;&#38656;&#30340;&#36317;&#31163;D&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#23454;&#39564;&#34920;&#26126;&#35813;&#26041;&#27861;&#20248;&#20110;D-Adaptation&#24182;&#21487;&#36798;&#21040;&#25163;&#21160;&#35843;&#25972;Adam&#30340;&#27979;&#35797;&#20934;&#30830;&#24230;&#20540;&#12290;</title><link>http://arxiv.org/abs/2306.06101</link><description>&lt;p&gt;
Prodigy: &#19968;&#31181;&#24555;&#36895;&#33258;&#36866;&#24212;&#38646;&#21442;&#25968;&#23398;&#20064;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Prodigy: An Expeditiously Adaptive Parameter-Free Learner. (arXiv:2306.06101v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06101
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#33258;&#36866;&#24212;&#31639;&#27861;(&#22914;Adagrad&#21644;Adam)&#30340;&#23398;&#20064;&#29575;&#20272;&#35745;&#26041;&#27861;Prodigy&#21644;Resetting&#65292;&#21487;&#20197;&#24555;&#36895;&#19988;&#27491;&#30830;&#22320;&#20272;&#35745;&#21040;&#36798;&#35299;&#20915;&#26041;&#26696;&#25152;&#38656;&#30340;&#36317;&#31163;D&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#23454;&#39564;&#34920;&#26126;&#35813;&#26041;&#27861;&#20248;&#20110;D-Adaptation&#24182;&#21487;&#36798;&#21040;&#25163;&#21160;&#35843;&#25972;Adam&#30340;&#27979;&#35797;&#20934;&#30830;&#24230;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#33258;&#36866;&#24212;&#31639;&#27861;(&#22914;Adagrad&#21644;Adam)&#20013;&#30340;&#23398;&#20064;&#29575;&#20272;&#35745;&#38382;&#39064;&#65292;&#25551;&#36848;&#20102;&#20004;&#31181;&#25216;&#26415;Prodigy&#21644;Resetting&#65292;&#21487;&#20197;&#35777;&#26126;&#22320;&#20272;&#35745;&#21040;&#36798;&#35299;&#20915;&#26041;&#26696;&#25152;&#38656;&#30340;&#36317;&#31163;D&#65292;&#20197;&#20415;&#26368;&#20248;&#35774;&#32622;&#23398;&#20064;&#29575;&#12290;&#25105;&#20204;&#30340;&#25216;&#26415;&#26159;&#22522;&#20110;&#23398;&#20064;&#29575;&#33258;&#30001;&#30340;D-Adaptation&#26041;&#27861;&#30340;&#20462;&#25913;&#65292;&#24182;&#36890;&#36807;$O(\sqrt{\log(D/d_0)})$&#30340;&#22240;&#23376;&#25552;&#39640;&#20102;D-Adaptation&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#20854;&#20013;$d_0$&#26159;$D$&#30340;&#21021;&#22987;&#20272;&#35745;&#20540;&#12290;&#25105;&#20204;&#22312;12&#20010;&#24120;&#35265;&#30340;&#36923;&#36753;&#22238;&#24402;&#22522;&#20934;&#25968;&#25454;&#38598;&#12289;&#22312;CIFAR10&#19978;&#35757;&#32451;&#30340;VGG11&#21644;ResNet-50&#12289;&#22312;Imagenet&#19978;&#35757;&#32451;&#30340;ViT&#12289;&#22312;IWSLT14&#19978;&#35757;&#32451;&#30340;LSTM&#12289;&#22312;Criteo&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;DLRM&#12289;&#22312;Knee MRI&#25968;&#25454;&#38598;&#19978;&#30340;VarNet&#65292;&#20197;&#21450;&#22312;BookWiki&#19978;&#35757;&#32451;&#30340;RoBERTa&#21644;GPT transformer&#19978;&#27979;&#35797;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22987;&#32456;&#20248;&#20110;D-Adaptation&#65292;&#24182;&#36798;&#21040;&#25163;&#21160;&#35843;&#25972;Adam&#30340;&#27979;&#35797;&#20934;&#30830;&#24230;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of estimating the learning rate in adaptive methods, such as Adagrad and Adam. We describe two techniques, Prodigy and Resetting, to provably estimate the distance to the solution $D$, which is needed to set the learning rate optimally. Our techniques are modifications of the D-Adaptation method for learning-rate-free learning. Our methods improve upon the convergence rate of D-Adaptation by a factor of $O(\sqrt{\log(D/d_0)})$, where $d_0$ is the initial estimate of $D$. We test our methods on 12 common logistic-regression benchmark datasets, VGG11 and ResNet-50 training on CIFAR10, ViT training on Imagenet, LSTM training on IWSLT14, DLRM training on Criteo dataset, VarNet on Knee MRI dataset, as well as RoBERTa and GPT transformer training on BookWiki. Our experimental results show that our approaches consistently outperform D-Adaptation and reach test accuracy values close to that of hand-tuned Adam.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#21151;&#33021;&#24615;&#36755;&#20837;&#31070;&#32463;&#32593;&#32476;&#65292;&#21487;&#20197;&#22312;&#24102;&#26435;&#37325;&#31354;&#38388;&#19978;&#23436;&#25104;&#20840;&#23616;&#20989;&#25968;&#36924;&#36817;&#12290;&#36825;&#19968;&#26041;&#27861;&#36866;&#29992;&#20110;&#36830;&#32493;&#20989;&#25968;&#30340;&#25512;&#24191;&#65292;&#36824;&#21487;&#29992;&#20110;&#36335;&#24452;&#31354;&#38388;&#20989;&#25968;&#30340;&#36924;&#36817;&#65292;&#21516;&#26102;&#20063;&#21487;&#20197;&#36924;&#36817;&#32447;&#24615;&#20989;&#25968;&#31614;&#21517;&#12290;</title><link>http://arxiv.org/abs/2306.03303</link><description>&lt;p&gt;
&#24102;&#26435;&#37325;&#31354;&#38388;&#19978;&#21151;&#33021;&#24615;&#36755;&#20837;&#26144;&#23556;&#30340;&#20840;&#23616;&#26222;&#36866;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
Global universal approximation of functional input maps on weighted spaces. (arXiv:2306.03303v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03303
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#21151;&#33021;&#24615;&#36755;&#20837;&#31070;&#32463;&#32593;&#32476;&#65292;&#21487;&#20197;&#22312;&#24102;&#26435;&#37325;&#31354;&#38388;&#19978;&#23436;&#25104;&#20840;&#23616;&#20989;&#25968;&#36924;&#36817;&#12290;&#36825;&#19968;&#26041;&#27861;&#36866;&#29992;&#20110;&#36830;&#32493;&#20989;&#25968;&#30340;&#25512;&#24191;&#65292;&#36824;&#21487;&#29992;&#20110;&#36335;&#24452;&#31354;&#38388;&#20989;&#25968;&#30340;&#36924;&#36817;&#65292;&#21516;&#26102;&#20063;&#21487;&#20197;&#36924;&#36817;&#32447;&#24615;&#20989;&#25968;&#31614;&#21517;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#25152;&#35859;&#30340;&#21151;&#33021;&#24615;&#36755;&#20837;&#31070;&#32463;&#32593;&#32476;&#65292;&#23450;&#20041;&#22312;&#21487;&#33021;&#26159;&#26080;&#38480;&#32500;&#24102;&#26435;&#37325;&#31354;&#38388;&#19978;&#65292;&#20854;&#20540;&#20063;&#22312;&#21487;&#33021;&#26159;&#26080;&#38480;&#32500;&#30340;&#36755;&#20986;&#31354;&#38388;&#20013;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#21152;&#24615;&#26063;&#20316;&#20026;&#38544;&#34255;&#23618;&#26144;&#23556;&#65292;&#20197;&#21450;&#19968;&#20010;&#38750;&#32447;&#24615;&#28608;&#27963;&#20989;&#25968;&#24212;&#29992;&#20110;&#27599;&#20010;&#38544;&#34255;&#23618;&#12290;&#20381;&#38752;&#24102;&#26435;&#37325;&#31354;&#38388;&#19978;&#30340;Stone-Weierstrass&#23450;&#29702;&#65292;&#25105;&#20204;&#21487;&#20197;&#35777;&#26126;&#36830;&#32493;&#20989;&#25968;&#30340;&#25512;&#24191;&#30340;&#20840;&#23616;&#26222;&#36866;&#36924;&#36817;&#32467;&#26524;&#65292;&#36229;&#36234;&#20102;&#24120;&#35268;&#32039;&#38598;&#36924;&#36817;&#12290;&#36825;&#29305;&#21035;&#36866;&#29992;&#20110;&#36890;&#36807;&#21151;&#33021;&#24615;&#36755;&#20837;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;&#65288;&#38750;&#20808;&#35265;&#20043;&#26126;&#30340;&#65289;&#36335;&#24452;&#31354;&#38388;&#20989;&#25968;&#12290;&#20316;&#20026;&#24102;&#26435;Stone-Weierstrass&#23450;&#29702;&#30340;&#36827;&#19968;&#27493;&#24212;&#29992;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#32447;&#24615;&#20989;&#25968;&#31614;&#21517;&#30340;&#20840;&#23616;&#26222;&#36866;&#36924;&#36817;&#32467;&#26524;&#12290;&#25105;&#20204;&#36824;&#22312;&#36825;&#20010;&#35774;&#32622;&#20013;&#24341;&#20837;&#20102;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#35266;&#28857;&#65292;&#24182;&#23637;&#31034;&#20102;&#31614;&#21517;&#20869;&#26680;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#26159;&#26576;&#20123;&#39640;&#26031;&#36807;&#31243;&#30340;Cameron-Martin&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce so-called functional input neural networks defined on a possibly infinite dimensional weighted space with values also in a possibly infinite dimensional output space. To this end, we use an additive family as hidden layer maps and a non-linear activation function applied to each hidden layer. Relying on Stone-Weierstrass theorems on weighted spaces, we can prove a global universal approximation result for generalizations of continuous functions going beyond the usual approximation on compact sets. This then applies in particular to approximation of (non-anticipative) path space functionals via functional input neural networks. As a further application of the weighted Stone-Weierstrass theorem we prove a global universal approximation result for linear functions of the signature. We also introduce the viewpoint of Gaussian process regression in this setting and show that the reproducing kernel Hilbert space of the signature kernels are Cameron-Martin spaces of certain Gauss
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;Grassmann&#27969;&#24418;&#23398;&#20064;&#20998;&#24067;&#30340;&#26041;&#27861;&#65292;&#20197;&#29983;&#25104;&#31283;&#23450;&#30340;&#24418;&#29366;&#12290;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#29983;&#25104;&#39640;&#36136;&#37327;&#26679;&#26412;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2211.02900</link><description>&lt;p&gt;
Grassmann&#27969;&#24418;&#27969;&#29992;&#20110;&#31283;&#23450;&#24418;&#29366;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Grassmann Manifold Flows for Stable Shape Generation. (arXiv:2211.02900v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.02900
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;Grassmann&#27969;&#24418;&#23398;&#20064;&#20998;&#24067;&#30340;&#26041;&#27861;&#65292;&#20197;&#29983;&#25104;&#31283;&#23450;&#30340;&#24418;&#29366;&#12290;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#29983;&#25104;&#39640;&#36136;&#37327;&#26679;&#26412;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#26426;&#22120;&#23398;&#20064;&#30340;&#30740;&#31350;&#38598;&#20013;&#22312;&#21033;&#29992;&#29305;&#23450;&#27969;&#24418;&#20013;&#30340;&#23545;&#31216;&#24615;&#20316;&#20026;&#24402;&#32435;&#20559;&#24046;&#30340;&#26041;&#27861;&#19978;&#12290;Grassmann&#27969;&#24418;&#25552;&#20379;&#20102;&#22788;&#29702;&#20197;&#24418;&#29366;&#31354;&#38388;&#34920;&#31034;&#30340;&#22522;&#26412;&#24418;&#29366;&#30340;&#33021;&#21147;&#65292;&#23454;&#29616;&#20102;&#31283;&#23450;&#30340;&#24418;&#29366;&#20998;&#26512;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#36830;&#32493;&#30340;&#24402;&#19968;&#21270;&#27969;&#22312;Grassmann&#27969;&#24418;&#19978;&#24314;&#31435;&#23398;&#20064;&#20998;&#24067;&#30340;&#29702;&#35770;&#22522;&#30784;&#65292;&#26126;&#30830;&#30340;&#30446;&#26631;&#26159;&#29983;&#25104;&#31283;&#23450;&#30340;&#24418;&#29366;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#22312;Grassmann&#27969;&#24418;&#20869;&#23398;&#20064;&#21644;&#29983;&#25104;&#65292;&#26377;&#25928;&#22320;&#28040;&#38500;&#20102;&#26059;&#36716;&#21644;&#32763;&#36716;&#31561;&#22806;&#37096;&#21464;&#25442;&#30340;&#24433;&#21709;&#65292;&#20174;&#32780;&#23454;&#29616;&#26356;&#31283;&#20581;&#30340;&#29983;&#25104;&#65292;&#20197;&#36866;&#24212;&#23545;&#35937;&#30340;&#22522;&#26412;&#24418;&#29366;&#20449;&#24687;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#33021;&#22815;&#36890;&#36807;&#25429;&#25417;&#25968;&#25454;&#32467;&#26500;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#26679;&#26412;&#12290;&#27492;&#22806;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;t&#26041;&#38754;&#26174;&#33879;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, studies on machine learning have focused on methods that use symmetry implicit in a specific manifold as an inductive bias. Grassmann manifolds provide the ability to handle fundamental shapes represented as shape spaces, enabling stable shape analysis. In this paper, we present a novel approach in which we establish the theoretical foundations for learning distributions on the Grassmann manifold via continuous normalization flows, with the explicit goal of generating stable shapes. Our approach facilitates more robust generation by effectively eliminating the influence of extraneous transformations, such as rotations and inversions, through learning and generating within a Grassmann manifolds designed to accommodate the essential shape information of the object. The experimental results indicated that the proposed method can generate high-quality samples by capturing the data structure. Furthermore, the proposed method significantly outperformed state-of-the-art methods in t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#33258;&#21327;&#35843;&#19988;&#30456;&#23545;&#24179;&#28369;&#30340;&#26368;&#23567;&#21270;&#31639;&#27861;&#65292;&#36890;&#36807;&#20998;&#26512;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#31639;&#27861;&#22312;&#20984;&#20989;&#25968;&#19978;&#30340;&#36951;&#25022;&#65292;&#25913;&#36827;&#20102;&#22312;&#32447;&#25237;&#36164;&#32452;&#21512;&#36873;&#25321;&#31639;&#27861;&#30340;&#24615;&#33021;&#65292;&#24182;&#22312;&#22312;&#32447;&#23398;&#20064;&#37327;&#23376;&#24577;&#38382;&#39064;&#20013;&#36798;&#21040;&#20102;&#19982;Soft-Bayes&#31639;&#27861;&#30456;&#24403;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2210.00997</link><description>&lt;p&gt;
&#22312;&#32447;&#33258;&#21327;&#35843;&#19988;&#30456;&#23545;&#24179;&#28369;&#30340;&#26368;&#23567;&#21270;&#38382;&#39064;&#21450;&#20854;&#22312;&#22312;&#32447;&#25237;&#36164;&#32452;&#21512;&#36873;&#25321;&#21644;&#23398;&#20064;&#37327;&#23376;&#24577;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Online Self-Concordant and Relatively Smooth Minimization, With Applications to Online Portfolio Selection and Learning Quantum States. (arXiv:2210.00997v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.00997
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#33258;&#21327;&#35843;&#19988;&#30456;&#23545;&#24179;&#28369;&#30340;&#26368;&#23567;&#21270;&#31639;&#27861;&#65292;&#36890;&#36807;&#20998;&#26512;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#31639;&#27861;&#22312;&#20984;&#20989;&#25968;&#19978;&#30340;&#36951;&#25022;&#65292;&#25913;&#36827;&#20102;&#22312;&#32447;&#25237;&#36164;&#32452;&#21512;&#36873;&#25321;&#31639;&#27861;&#30340;&#24615;&#33021;&#65292;&#24182;&#22312;&#22312;&#32447;&#23398;&#20064;&#37327;&#23376;&#24577;&#38382;&#39064;&#20013;&#36798;&#21040;&#20102;&#19982;Soft-Bayes&#31639;&#27861;&#30456;&#24403;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#19968;&#31867;&#22312;&#32447;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#20854;&#20013;&#25439;&#22833;&#20989;&#25968;&#26159;&#33258;&#21327;&#35843;&#38556;&#30861;&#20989;&#25968;&#65292;&#22312;&#26576;&#20010;&#20984;&#20989;&#25968;h&#30340;&#30456;&#23545;&#24179;&#28369;&#65292;&#21487;&#33021;&#19981;&#26159;Lipschitz&#30340;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#31639;&#27861;&#22312;h&#19978;&#30340;&#36951;&#25022;&#65292;&#24182;&#22522;&#20110;&#32467;&#26524;&#20197;&#32479;&#19968;&#30340;&#26041;&#24335;&#35777;&#26126;&#20102;&#20197;&#19979;&#32467;&#35770;&#12290;&#23545;&#20110;&#22312;&#32447;&#25237;&#36164;&#32452;&#21512;&#36873;&#25321;&#38382;&#39064;&#65292;&#24403;T&gt;4d/logd&#26102;&#65292;&#25913;&#36827;&#20102;Helmbold&#31561;&#20154;&#25552;&#20986;&#30340;&#25351;&#25968;&#21270;&#26799;&#24230;&#31639;&#27861;&#30340;&#36951;&#25022;&#30028;&#20026;O(T^{2/3} d^{1/3})&#65292;&#21407;&#26377;&#30028;&#26159;O(T^{3/4} d^{1/2})&#12290;&#23545;&#20110;&#22312;&#32447;&#25237;&#36164;&#32452;&#21512;&#36873;&#25321;&#38382;&#39064;&#65292;&#20351;&#29992;&#23545;&#25968;&#38556;&#30861;&#30340;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#31639;&#27861;&#30340;&#36951;&#25022;&#30028;&#20026;O(sqrt(Td))&#65292;&#19982;Orseau&#31561;&#20154;&#30340;Soft-Bayes&#31639;&#27861;&#20855;&#26377;&#30456;&#21516;&#30340;&#36951;&#25022;&#30028;&#65292;&#38500;&#21435;&#23545;&#25968;&#22240;&#23376;&#12290;&#23545;&#20110;&#20351;&#29992;&#23545;&#25968;&#25439;&#22833;&#30340;&#22312;&#32447;&#23398;&#20064;&#37327;&#23376;&#24577;&#38382;&#39064;&#65292;&#20351;&#29992;&#23545;&#25968;&#38556;&#30861;&#30340;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#31639;&#27861;&#30340;&#36951;&#25022;&#30028;&#26159;...
&lt;/p&gt;
&lt;p&gt;
Consider an online convex optimization problem where the loss functions are self-concordant barriers, smooth relative to a convex function $h$, and possibly non-Lipschitz. We analyze the regret of online mirror descent with $h$. Then, based on the result, we prove the following in a unified manner. Denote by $T$ the time horizon and $d$ the parameter dimension. 1. For online portfolio selection, the regret of $\widetilde{\text{EG}}$, a variant of exponentiated gradient due to Helmbold et al., is $\tilde{O} ( T^{2/3} d^{1/3} )$ when $T &gt; 4 d / \log d$. This improves on the original $\tilde{O} ( T^{3/4} d^{1/2} )$ regret bound for $\widetilde{\text{EG}}$. 2. For online portfolio selection, the regret of online mirror descent with the logarithmic barrier is $\tilde{O}(\sqrt{T d})$. The regret bound is the same as that of Soft-Bayes due to Orseau et al. up to logarithmic terms. 3. For online learning quantum states with the logarithmic loss, the regret of online mirror descent with the log
&lt;/p&gt;</description></item></channel></rss>