<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#39640;&#20284;&#28982;&#21306;&#22495;&#23558;&#19981;&#20250;&#34987;&#29983;&#25104;&#22914;&#26524;&#23427;&#20204;&#21253;&#21547;&#26368;&#23567;&#27010;&#29575;&#36136;&#37327;&#65292;&#22522;&#20110;&#27492;&#35266;&#23519;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26412;&#22320;&#22266;&#26377;&#32500;&#24230;&#20272;&#35745;&#36827;&#34892;&#31163;&#32676;&#26816;&#27979;&#30340;&#26041;&#27861;</title><link>https://arxiv.org/abs/2403.18910</link><description>&lt;p&gt;
&#23545;&#31163;&#32676;&#25968;&#25454;&#26816;&#27979;&#24726;&#35770;&#30340;&#20284;&#28982;&#20960;&#20309;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
A Geometric Explanation of the Likelihood OOD Detection Paradox
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18910
&lt;/p&gt;
&lt;p&gt;
&#39640;&#20284;&#28982;&#21306;&#22495;&#23558;&#19981;&#20250;&#34987;&#29983;&#25104;&#22914;&#26524;&#23427;&#20204;&#21253;&#21547;&#26368;&#23567;&#27010;&#29575;&#36136;&#37327;&#65292;&#22522;&#20110;&#27492;&#35266;&#23519;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26412;&#22320;&#22266;&#26377;&#32500;&#24230;&#20272;&#35745;&#36827;&#34892;&#31163;&#32676;&#26816;&#27979;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#20284;&#28982;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;(DGMs)&#36890;&#24120;&#34920;&#29616;&#20986;&#20196;&#20154;&#22256;&#24785;&#30340;&#34892;&#20026;&#65306;&#24403;&#22312;&#30456;&#23545;&#22797;&#26434;&#30340;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#26102;&#65292;&#23427;&#20204;&#20250;&#32473;&#26469;&#33258;&#26356;&#31616;&#21333;&#26469;&#28304;&#30340;&#31163;&#32676;&#25968;&#25454;&#36171;&#20104;&#26356;&#39640;&#30340;&#20284;&#28982;&#20540;&#12290;&#26356;&#20351;&#20154;&#24863;&#21040;&#31070;&#31192;&#30340;&#26159;&#65292;&#23613;&#31649;&#20855;&#26377;&#26356;&#39640;&#30340;&#20284;&#28982;&#20540;&#65292;&#20294;&#36825;&#20123;DGMs&#20174;&#26410;&#29983;&#25104;&#36807;&#31163;&#32676;&#26679;&#26412;&#12290;&#36825;&#20010;&#21452;&#31649;&#40784;&#19979;&#30340;&#24726;&#35770;&#23578;&#26410;&#24471;&#21040;&#26368;&#32456;&#35299;&#37322;&#65292;&#20351;&#24471;&#22522;&#20110;&#20284;&#28982;&#30340;&#31163;&#32676;&#26816;&#27979;&#19981;&#21487;&#38752;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#35266;&#23519;&#26159;&#65292;&#22914;&#26524;&#39640;&#20284;&#28982;&#21306;&#22495;&#20013;&#21253;&#21547;&#20102;&#26368;&#23567;&#27010;&#29575;&#36136;&#37327;&#65292;&#37027;&#20040;&#36825;&#20123;&#21306;&#22495;&#23558;&#19981;&#20250;&#34987;&#29983;&#25104;&#12290;&#25105;&#20204;&#28436;&#31034;&#20102;&#22312;&#22260;&#32469;&#20302;&#32500;&#27969;&#24418;&#25968;&#25454;&#30340;&#22320;&#26041;&#21487;&#33021;&#20986;&#29616;&#22823;&#23494;&#24230;&#20294;&#20302;&#27010;&#29575;&#36136;&#37327;&#30340;&#30475;&#20284;&#30683;&#30462;&#24773;&#20917;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#36890;&#36807;&#26412;&#22320;&#22266;&#26377;&#32500;&#24230;(LID)&#20272;&#35745;&#21487;&#20197;&#35782;&#21035;&#36825;&#31181;&#22330;&#26223;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#39044;&#35757;&#32451;&#30340;DGM&#33719;&#24471;&#30340;&#20284;&#28982;&#21644;LID&#20272;&#35745;&#30456;&#37197;&#23545;&#30340;&#31163;&#32676;&#26816;&#27979;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18910v1 Announce Type: cross  Abstract: Likelihood-based deep generative models (DGMs) commonly exhibit a puzzling behaviour: when trained on a relatively complex dataset, they assign higher likelihood values to out-of-distribution (OOD) data from simpler sources. Adding to the mystery, OOD samples are never generated by these DGMs despite having higher likelihoods. This two-pronged paradox has yet to be conclusively explained, making likelihood-based OOD detection unreliable. Our primary observation is that high-likelihood regions will not be generated if they contain minimal probability mass. We demonstrate how this seeming contradiction of large densities yet low probability mass can occur around data confined to low-dimensional manifolds. We also show that this scenario can be identified through local intrinsic dimension (LID) estimation, and propose a method for OOD detection which pairs the likelihoods and LID estimates obtained from a pre-trained DGM. Our method can b
&lt;/p&gt;</description></item><item><title>&#24320;&#21457;&#20102;&#19968;&#20010;&#31639;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#23558;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#36890;&#29992;&#38750;&#32447;&#24615;&#36870;&#30340;&#34920;&#36798;&#25968;&#25454;&#20808;&#39564;&#12290;</title><link>https://arxiv.org/abs/2403.17042</link><description>&lt;p&gt;
&#21487;&#35777;&#23454;&#40065;&#26834;&#30340;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#21518;&#39564;&#37319;&#26679;&#29992;&#20110;&#21363;&#25554;&#21363;&#29992;&#22270;&#20687;&#37325;&#24314;
&lt;/p&gt;
&lt;p&gt;
Provably Robust Score-Based Diffusion Posterior Sampling for Plug-and-Play Image Reconstruction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.17042
&lt;/p&gt;
&lt;p&gt;
&#24320;&#21457;&#20102;&#19968;&#20010;&#31639;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#23558;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#36890;&#29992;&#38750;&#32447;&#24615;&#36870;&#30340;&#34920;&#36798;&#25968;&#25454;&#20808;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#30340;&#35768;&#22810;&#20219;&#21153;&#20013;&#65292;&#30446;&#26631;&#26159;&#20174;&#24050;&#30693;&#25551;&#36848;&#26576;&#31181;&#24863;&#30693;&#25110;&#25104;&#20687;&#27169;&#24335;&#30340;&#24050;&#30693;&#21069;&#21521;&#27169;&#22411;&#25910;&#38598;&#30340;&#23569;&#37327;&#27979;&#37327;&#20013;&#25512;&#26029;&#26410;&#30693;&#22270;&#20687;&#12290;&#30001;&#20110;&#36164;&#28304;&#38480;&#21046;&#65292;&#36825;&#20010;&#20219;&#21153;&#36890;&#24120;&#38750;&#24120;&#19981;&#36866;&#21512;&#65292;&#36825;&#23601;&#38656;&#35201;&#37319;&#32435;&#34920;&#36798;&#20016;&#23500;&#30340;&#20808;&#39564;&#20449;&#24687;&#26469;&#35268;&#33539;&#35299;&#31354;&#38388;&#12290;&#30001;&#20110;&#20854;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#32463;&#39564;&#25104;&#21151;&#65292;&#22522;&#20110;&#20998;&#25968;&#30340;&#25193;&#25955;&#27169;&#22411;&#24050;&#32463;&#25104;&#20026;&#22270;&#20687;&#37325;&#24314;&#20013;&#19968;&#20010;&#20855;&#26377;&#21560;&#24341;&#21147;&#30340;&#34920;&#36798;&#20808;&#39564;&#30340;&#20505;&#36873;&#32773;&#12290;&#20026;&#20102;&#19968;&#27425;&#24615;&#23481;&#32435;&#22810;&#26679;&#30340;&#20219;&#21153;&#65292;&#24320;&#21457;&#23558;&#22270;&#20687;&#20808;&#39564;&#20998;&#24067;&#30340;&#26080;&#26465;&#20214;&#35780;&#20998;&#20989;&#25968;&#19982;&#28789;&#27963;&#30340;&#21069;&#21521;&#27169;&#22411;&#36873;&#25321;&#30456;&#32467;&#21512;&#30340;&#39640;&#25928;&#12289;&#19968;&#33268;&#21644;&#40065;&#26834;&#31639;&#27861;&#38750;&#24120;&#37325;&#35201;&#12290;&#36825;&#39033;&#24037;&#20316;&#24320;&#21457;&#20102;&#19968;&#20010;&#31639;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#23558;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#20316;&#20026;&#36890;&#29992;&#38750;&#32447;&#24615;&#36870;&#30340;&#34920;&#36798;&#25968;&#25454;&#20808;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.17042v1 Announce Type: cross  Abstract: In a great number of tasks in science and engineering, the goal is to infer an unknown image from a small number of measurements collected from a known forward model describing certain sensing or imaging modality. Due to resource constraints, this task is often extremely ill-posed, which necessitates the adoption of expressive prior information to regularize the solution space. Score-based diffusion models, due to its impressive empirical success, have emerged as an appealing candidate of an expressive prior in image reconstruction. In order to accommodate diverse tasks at once, it is of great interest to develop efficient, consistent and robust algorithms that incorporate {\em unconditional} score functions of an image prior distribution in conjunction with flexible choices of forward models.   This work develops an algorithmic framework for employing score-based diffusion models as an expressive data prior in general nonlinear invers
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#21033;&#29992;&#21487;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#65292;&#35813;&#30740;&#31350;&#24378;&#35843;&#20102;&#29305;&#23450;&#32593;&#32476;&#29305;&#24449;&#21450;&#20854;&#30456;&#20114;&#20316;&#29992;&#65292;&#26377;&#21161;&#20110;&#21306;&#20998;&#29983;&#25104;&#27169;&#22411;&#12289;&#29702;&#35299;&#22797;&#26434;&#32593;&#32476;&#32467;&#26500;&#21644;&#29983;&#25104;&#30495;&#23454;&#19990;&#30028;&#32593;&#32476;</title><link>https://arxiv.org/abs/2403.13215</link><description>&lt;p&gt;
&#20160;&#20040;&#36896;&#23601;&#20102;&#19968;&#20010;&#23567;&#19990;&#30028;&#32593;&#32476;&#65311;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#36827;&#34892;&#32593;&#32476;&#30340;&#31283;&#20581;&#39044;&#27979;&#21644;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
What makes a small-world network? Leveraging machine learning for the robust prediction and classification of networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13215
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#21033;&#29992;&#21487;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#65292;&#35813;&#30740;&#31350;&#24378;&#35843;&#20102;&#29305;&#23450;&#32593;&#32476;&#29305;&#24449;&#21450;&#20854;&#30456;&#20114;&#20316;&#29992;&#65292;&#26377;&#21161;&#20110;&#21306;&#20998;&#29983;&#25104;&#27169;&#22411;&#12289;&#29702;&#35299;&#22797;&#26434;&#32593;&#32476;&#32467;&#26500;&#21644;&#29983;&#25104;&#30495;&#23454;&#19990;&#30028;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#27969;&#34892;&#30149;&#23398;&#21040;&#35745;&#31639;&#26426;&#31185;&#23398;&#65292;&#22522;&#20110;&#23454;&#35777;&#25968;&#25454;&#27169;&#25311;&#30495;&#23454;&#32593;&#32476;&#30340;&#33021;&#21147;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#20219;&#21153;&#12290;&#36890;&#24120;&#65292;&#27169;&#25311;&#26041;&#27861;&#28041;&#21450;&#36873;&#25321;&#36866;&#21512;&#30340;&#32593;&#32476;&#29983;&#25104;&#27169;&#22411;&#65292;&#22914;Erd\"os-R\'enyi&#25110;&#23567;&#19990;&#30028;&#12290;&#28982;&#32780;&#65292;&#24456;&#23569;&#26377;&#24037;&#20855;&#21487;&#29992;&#20110;&#37327;&#21270;&#29305;&#23450;&#29983;&#25104;&#27169;&#22411;&#26159;&#21542;&#36866;&#21512;&#25429;&#25417;&#32473;&#23450;&#30340;&#32593;&#32476;&#32467;&#26500;&#25110;&#32452;&#32455;&#12290;&#25105;&#20204;&#21033;&#29992;&#21487;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#36827;&#23637;&#65292;&#26681;&#25454;&#21508;&#31181;&#32593;&#32476;&#23646;&#24615;&#20197;&#21450;&#23427;&#20204;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#23545;&#25105;&#20204;&#30340;&#29983;&#25104;&#27169;&#22411;&#23545;&#27169;&#25311;&#32593;&#32476;&#36827;&#34892;&#20998;&#31867;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#24378;&#35843;&#20102;&#29305;&#23450;&#32593;&#32476;&#29305;&#24449;&#21450;&#20854;&#30456;&#20114;&#20316;&#29992;&#22312;&#21306;&#20998;&#29983;&#25104;&#27169;&#22411;&#12289;&#29702;&#35299;&#22797;&#26434;&#32593;&#32476;&#32467;&#26500;&#20197;&#21450;&#24418;&#25104;&#29616;&#23454;&#19990;&#30028;&#32593;&#32476;&#20013;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13215v1 Announce Type: cross  Abstract: The ability to simulate realistic networks based on empirical data is an important task across scientific disciplines, from epidemiology to computer science. Often simulation approaches involve selecting a suitable network generative model such as Erd\"os-R\'enyi or small-world. However, few tools are available to quantify if a particular generative model is suitable for capturing a given network structure or organization. We utilize advances in interpretable machine learning to classify simulated networks by our generative models based on various network attributes, using both primary features and their interactions. Our study underscores the significance of specific network features and their interactions in distinguishing generative models, comprehending complex network structures, and forming real-world networks
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#32479;&#19968;&#26694;&#26550;&#19979;&#24314;&#31435;&#20102;&#8220;&#36890;&#36807;&#36845;&#20195;&#23454;&#29616;&#38544;&#31169;&#25918;&#22823;&#8221;&#29616;&#35937;&#65292;&#25552;&#39640;&#20102;&#20808;&#21069;&#20998;&#26512;&#30340;&#27700;&#24179;&#65292;&#24182;&#30001;&#27492;&#33719;&#24471;&#20102;&#20854;&#20182;&#24046;&#20998;&#38544;&#31169;&#27010;&#24565;&#26356;&#32039;&#23494;&#30340;&#38544;&#31169;&#26680;&#31639;&#12290;</title><link>https://arxiv.org/abs/2403.00278</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#30340;&#24179;&#31227;&#25554;&#20540;
&lt;/p&gt;
&lt;p&gt;
Shifted Interpolation for Differential Privacy
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00278
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#32479;&#19968;&#26694;&#26550;&#19979;&#24314;&#31435;&#20102;&#8220;&#36890;&#36807;&#36845;&#20195;&#23454;&#29616;&#38544;&#31169;&#25918;&#22823;&#8221;&#29616;&#35937;&#65292;&#25552;&#39640;&#20102;&#20808;&#21069;&#20998;&#26512;&#30340;&#27700;&#24179;&#65292;&#24182;&#30001;&#27492;&#33719;&#24471;&#20102;&#20854;&#20182;&#24046;&#20998;&#38544;&#31169;&#27010;&#24565;&#26356;&#32039;&#23494;&#30340;&#38544;&#31169;&#26680;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21927;&#22179;&#30340;&#26799;&#24230;&#19979;&#38477;&#21450;&#20854;&#21464;&#31181;&#26159;&#24046;&#20998;&#38544;&#31169;&#26426;&#22120;&#23398;&#20064;&#20013;&#20027;&#23548;&#30340;&#31639;&#27861;&#12290;&#37327;&#21270;&#23427;&#20204;&#30340;&#38544;&#31169;&#27844;&#28431;&#26159;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#65292;&#28982;&#32780;&#21363;&#20351;&#22312;&#20984;&#25439;&#22833;&#30340;&#22522;&#30784;&#35774;&#32622;&#20013;&#65292;&#32039;&#33268;&#30340;&#34920;&#24449;&#20173;&#28982;&#26159;&#24320;&#25918;&#30340;&#12290;&#26412;&#25991;&#36890;&#36807;&#22312;$f$-&#24046;&#20998;&#38544;&#31169;&#30340;&#32479;&#19968;&#26694;&#26550;&#19979;&#24314;&#31435;&#65288;&#21644;&#25913;&#36827;&#65289;&#8220;&#36890;&#36807;&#36845;&#20195;&#23454;&#29616;&#38544;&#31169;&#25918;&#22823;&#8221;&#29616;&#35937;&#65292;&#25552;&#39640;&#20102;&#20808;&#21069;&#20998;&#26512;&#30340;&#27700;&#24179;--&#36825;&#31181;&#26041;&#27861;&#32039;&#32039;&#25429;&#25417;&#20102;&#38544;&#31169;&#25439;&#22833;&#30340;&#25152;&#26377;&#26041;&#38754;&#65292;&#24182;&#31435;&#21363;&#33719;&#24471;&#20102;&#20854;&#20182;&#24046;&#20998;&#38544;&#31169;&#27010;&#24565;&#65288;&#22914;$(\varepsilon,\delta)$-DP&#21644;Renyi DP&#65289;&#26356;&#32039;&#23494;&#30340;&#38544;&#31169;&#26680;&#31639;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#25216;&#26415;&#35265;&#35299;&#26159;&#26500;&#24314;&#20102;&#25581;&#31034;&#20102;&#27969;&#34892;&#30340;&#24179;&#31227;&#25955;&#24230;&#35770;&#35777;&#30340;&#24179;&#31227;&#25554;&#20540;&#36807;&#31243;&#65292;&#20351;&#24471;&#36229;&#36234;&#22522;&#20110;&#25955;&#24230;&#30340;&#24046;&#20998;&#38544;&#31169;&#25918;&#23485;&#30340;&#27867;&#21270;&#25104;&#20026;&#21487;&#33021;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#36825;&#23548;&#33268;&#20102;&#22312;&#24378;&#20984;&#22522;&#30784;&#35774;&#32622;&#20013;&#30340;&#31532;&#19968;&#20010;&#31934;&#30830;&#38544;&#31169;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00278v1 Announce Type: new  Abstract: Noisy gradient descent and its variants are the predominant algorithms for differentially private machine learning. It is a fundamental question to quantify their privacy leakage, yet tight characterizations remain open even in the foundational setting of convex losses. This paper improves over previous analyses by establishing (and refining) the "privacy amplification by iteration" phenomenon in the unifying framework of $f$-differential privacy--which tightly captures all aspects of the privacy loss and immediately implies tighter privacy accounting in other notions of differential privacy, e.g., $(\varepsilon,\delta)$-DP and Renyi DP. Our key technical insight is the construction of shifted interpolated processes that unravel the popular shifted-divergences argument, enabling generalizations beyond divergence-based relaxations of DP. Notably, this leads to the first exact privacy analysis in the foundational setting of strongly convex
&lt;/p&gt;</description></item><item><title>BaM&#26159;&#19968;&#31181;&#22522;&#20110;&#20998;&#25968;&#30340;&#31163;&#25955;&#30340;BBVI&#26367;&#20195;&#26041;&#27861;&#65292;&#38024;&#23545;&#39640;&#26041;&#24046;&#26799;&#24230;&#20272;&#35745;&#24930;&#25910;&#25947;&#38382;&#39064;&#65292;&#33021;&#22815;&#22312;&#39640;&#26031;&#21464;&#20998;&#26063;&#20013;&#36890;&#36807;&#23553;&#38381;&#24418;&#24335;&#30340;&#36817;&#31471;&#26356;&#26032;&#36827;&#34892;&#20248;&#21270;&#65292;&#22312;&#30446;&#26631;&#20998;&#24067;&#20026;&#39640;&#26031;&#26102;&#65292;&#25209;&#22788;&#29702;&#22823;&#23567;&#36235;&#20110;&#26080;&#31351;&#26102;&#21464;&#20998;&#21442;&#25968;&#26356;&#26032;&#23558;&#25351;&#25968;&#24555;&#36895;&#25910;&#25947;&#21040;&#30446;&#26631;&#22343;&#20540;&#21644;&#21327;&#26041;&#24046;&#65292;BaM&#22312;&#22810;&#31181;&#29983;&#25104;&#27169;&#22411;&#25512;&#26029;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#24615;&#33021;</title><link>https://arxiv.org/abs/2402.14758</link><description>&lt;p&gt;
&#25209;&#22788;&#29702;&#21644;&#21305;&#37197;&#65306;&#22522;&#20110;&#20998;&#25968;&#30340;&#31163;&#25955;&#30340;&#40657;&#21283;&#23376;&#21464;&#20998;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Batch and match: black-box variational inference with a score-based divergence
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14758
&lt;/p&gt;
&lt;p&gt;
BaM&#26159;&#19968;&#31181;&#22522;&#20110;&#20998;&#25968;&#30340;&#31163;&#25955;&#30340;BBVI&#26367;&#20195;&#26041;&#27861;&#65292;&#38024;&#23545;&#39640;&#26041;&#24046;&#26799;&#24230;&#20272;&#35745;&#24930;&#25910;&#25947;&#38382;&#39064;&#65292;&#33021;&#22815;&#22312;&#39640;&#26031;&#21464;&#20998;&#26063;&#20013;&#36890;&#36807;&#23553;&#38381;&#24418;&#24335;&#30340;&#36817;&#31471;&#26356;&#26032;&#36827;&#34892;&#20248;&#21270;&#65292;&#22312;&#30446;&#26631;&#20998;&#24067;&#20026;&#39640;&#26031;&#26102;&#65292;&#25209;&#22788;&#29702;&#22823;&#23567;&#36235;&#20110;&#26080;&#31351;&#26102;&#21464;&#20998;&#21442;&#25968;&#26356;&#26032;&#23558;&#25351;&#25968;&#24555;&#36895;&#25910;&#25947;&#21040;&#30446;&#26631;&#22343;&#20540;&#21644;&#21327;&#26041;&#24046;&#65292;BaM&#22312;&#22810;&#31181;&#29983;&#25104;&#27169;&#22411;&#25512;&#26029;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#20027;&#35201;&#30340;&#40657;&#21283;&#23376;&#21464;&#20998;&#25512;&#26029;&#65288;BBVI&#65289;&#23454;&#29616;&#37117;&#26159;&#22522;&#20110;&#20248;&#21270;&#38543;&#26426;&#35777;&#25454;&#19979;&#30028;&#65288;ELBO&#65289;&#12290;&#20294;&#26159;&#65292;&#36825;&#31181;BBVI&#26041;&#27861;&#36890;&#24120;&#30001;&#20110;&#20854;&#26799;&#24230;&#20272;&#35745;&#30340;&#39640;&#26041;&#24046;&#32780;&#25910;&#25947;&#32531;&#24930;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#25209;&#22788;&#29702;&#21644;&#21305;&#37197;&#65288;BaM&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#22522;&#20110;&#20998;&#25968;&#30340;&#31163;&#25955;&#30340;BBVI&#26367;&#20195;&#26041;&#27861;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#36825;&#31181;&#22522;&#20110;&#20998;&#25968;&#30340;&#31163;&#25955;&#21487;&#20197;&#36890;&#36807;&#23545;&#20855;&#26377;&#20840;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#39640;&#26031;&#21464;&#20998;&#26063;&#20351;&#29992;&#23553;&#38381;&#24418;&#24335;&#30340;&#36817;&#31471;&#26356;&#26032;&#36827;&#34892;&#20248;&#21270;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#24403;&#30446;&#26631;&#20998;&#24067;&#20026;&#39640;&#26031;&#20998;&#24067;&#26102;BaM&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#35777;&#26126;&#22312;&#25209;&#37327;&#22823;&#23567;&#36235;&#20110;&#26080;&#31351;&#26102;&#21464;&#20998;&#21442;&#25968;&#26356;&#26032;&#20250;&#25351;&#25968;&#25910;&#25947;&#21040;&#30446;&#26631;&#22343;&#20540;&#21644;&#21327;&#26041;&#24046;&#12290;&#25105;&#20204;&#36824;&#35780;&#20272;&#20102;BaM&#22312;&#28304;&#33258;&#23618;&#27425;&#21644;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#21518;&#39564;&#25512;&#26029;&#30340;&#39640;&#26031;&#21644;&#38750;&#39640;&#26031;&#30446;&#26631;&#20998;&#24067;&#19978;&#30340;&#24615;&#33021;&#12290;&#22312;&#36825;&#20123;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;BaM&#22312;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14758v1 Announce Type: cross  Abstract: Most leading implementations of black-box variational inference (BBVI) are based on optimizing a stochastic evidence lower bound (ELBO). But such approaches to BBVI often converge slowly due to the high variance of their gradient estimates. In this work, we propose batch and match (BaM), an alternative approach to BBVI based on a score-based divergence. Notably, this score-based divergence can be optimized by a closed-form proximal update for Gaussian variational families with full covariance matrices. We analyze the convergence of BaM when the target distribution is Gaussian, and we prove that in the limit of infinite batch size the variational parameter updates converge exponentially quickly to the target mean and covariance. We also evaluate the performance of BaM on Gaussian and non-Gaussian target distributions that arise from posterior inference in hierarchical and deep generative models. In these experiments, we find that BaM ty
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#32771;&#34385;&#22806;&#25512;&#30340;&#38750;&#21442;&#25968;&#32479;&#35745;&#25512;&#26029;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31867;&#22806;&#25512;&#20551;&#35774;&#65292;&#32467;&#21512;&#29616;&#26377;&#25512;&#26029;&#25216;&#26415;&#21487;&#20197;&#24471;&#20986;&#21463;&#22806;&#25512;&#24433;&#21709;&#30340;&#32467;&#35770;&#12290;</title><link>https://arxiv.org/abs/2402.09758</link><description>&lt;p&gt;
&#32771;&#34385;&#22806;&#25512;&#30340;&#38750;&#21442;&#25968;&#32479;&#35745;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Extrapolation-Aware Nonparametric Statistical Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09758
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#32771;&#34385;&#22806;&#25512;&#30340;&#38750;&#21442;&#25968;&#32479;&#35745;&#25512;&#26029;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31867;&#22806;&#25512;&#20551;&#35774;&#65292;&#32467;&#21512;&#29616;&#26377;&#25512;&#26029;&#25216;&#26415;&#21487;&#20197;&#24471;&#20986;&#21463;&#22806;&#25512;&#24433;&#21709;&#30340;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23558;&#22806;&#25512;&#23450;&#20041;&#20026;&#23545;&#36229;&#20986;&#26465;&#20214;&#21464;&#37327;&#25903;&#25345;&#33539;&#22260;&#30340;&#26465;&#20214;&#20989;&#25968;&#65288;&#20363;&#22914;&#26465;&#20214;&#26399;&#26395;&#25110;&#26465;&#20214;&#20998;&#20301;&#25968;&#65289;&#36827;&#34892;&#30340;&#20219;&#20309;&#31867;&#22411;&#30340;&#32479;&#35745;&#25512;&#26029;&#12290;&#36825;&#31181;&#22806;&#25512;&#31867;&#22411;&#22312;&#35768;&#22810;&#25968;&#25454;&#20998;&#26512;&#24212;&#29992;&#20013;&#37117;&#20986;&#29616;&#65292;&#24182;&#19988;&#22914;&#26524;&#19981;&#32771;&#34385;&#23427;&#20204;&#21487;&#33021;&#20250;&#20351;&#24471;&#32467;&#26524;&#30340;&#32467;&#35770;&#22833;&#25928;&#12290;&#23613;&#31649;&#22312;&#21442;&#25968;&#27169;&#22411;&#20013;&#22806;&#25512;&#26159;&#30452;&#25509;&#30340;&#65292;&#20294;&#22312;&#38750;&#21442;&#25968;&#27169;&#22411;&#20013;&#21364;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23558;&#38750;&#21442;&#25968;&#32479;&#35745;&#27169;&#22411;&#25193;&#23637;&#21040;&#26126;&#30830;&#20801;&#35768;&#22806;&#25512;&#65292;&#24182;&#24341;&#20837;&#19968;&#31867;&#21487;&#20197;&#19982;&#29616;&#26377;&#25512;&#26029;&#25216;&#26415;&#32467;&#21512;&#20351;&#29992;&#30340;&#22806;&#25512;&#20551;&#35774;&#65292;&#20197;&#24471;&#20986;&#21463;&#22806;&#25512;&#24433;&#21709;&#30340;&#32467;&#35770;&#12290;&#25552;&#20986;&#30340;&#22806;&#25512;&#20551;&#35774;&#31867;&#35268;&#23450;&#65292;&#26465;&#20214;&#20989;&#25968;&#22312;&#35266;&#23519;&#21040;&#30340;&#25903;&#25345;&#33539;&#22260;&#20869;&#30340;&#27599;&#20010;&#26041;&#21521;&#19978;&#37117;&#36798;&#21040;&#20854;&#26368;&#23567;&#21644;&#26368;&#22823;&#26041;&#21521;&#23548;&#25968;&#12290;&#25105;&#20204;&#28436;&#31034;&#20102;&#35813;&#26694;&#26550;&#22914;&#20309;&#24212;&#29992;&#20110;&#20960;&#20010;&#23454;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09758v1 Announce Type: cross  Abstract: We define extrapolation as any type of statistical inference on a conditional function (e.g., a conditional expectation or conditional quantile) evaluated outside of the support of the conditioning variable. This type of extrapolation occurs in many data analysis applications and can invalidate the resulting conclusions if not taken into account. While extrapolating is straightforward in parametric models, it becomes challenging in nonparametric models. In this work, we extend the nonparametric statistical model to explicitly allow for extrapolation and introduce a class of extrapolation assumptions that can be combined with existing inference techniques to draw extrapolation-aware conclusions. The proposed class of extrapolation assumptions stipulate that the conditional function attains its minimal and maximal directional derivative, in each direction, within the observed support. We illustrate how the framework applies to several st
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#36890;&#36807;&#32463;&#39564;&#36125;&#21494;&#26031;&#24179;&#28369;&#22312;&#39640;&#32500;&#25968;&#25454;&#20013;&#20272;&#35745;&#26410;&#30693;&#27010;&#29575;&#20998;&#24067;&#30340;&#20998;&#25968;&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#26680;&#30340;&#27491;&#21017;&#21270;&#20998;&#25968;&#20272;&#35745;&#22120;&#65292;&#22312;score matching&#25439;&#22833;&#20989;&#25968;&#19979;&#36798;&#21040;&#20102;&#26368;&#20248;&#36895;&#29575;&#65292;&#24182;&#25581;&#31034;&#20102;&#32500;&#24230;&#22686;&#38271;&#23545;&#26679;&#26412;&#22797;&#26434;&#24615;&#30340;&#25351;&#25968;&#32423;&#24433;&#21709;&#12290;</title><link>https://arxiv.org/abs/2402.07747</link><description>&lt;p&gt;
&#36890;&#36807;&#32463;&#39564;&#36125;&#21494;&#26031;&#24179;&#28369;&#36827;&#34892;&#26368;&#20248;&#20998;&#25968;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Optimal score estimation via empirical Bayes smoothing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07747
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#36890;&#36807;&#32463;&#39564;&#36125;&#21494;&#26031;&#24179;&#28369;&#22312;&#39640;&#32500;&#25968;&#25454;&#20013;&#20272;&#35745;&#26410;&#30693;&#27010;&#29575;&#20998;&#24067;&#30340;&#20998;&#25968;&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#26680;&#30340;&#27491;&#21017;&#21270;&#20998;&#25968;&#20272;&#35745;&#22120;&#65292;&#22312;score matching&#25439;&#22833;&#20989;&#25968;&#19979;&#36798;&#21040;&#20102;&#26368;&#20248;&#36895;&#29575;&#65292;&#24182;&#25581;&#31034;&#20102;&#32500;&#24230;&#22686;&#38271;&#23545;&#26679;&#26412;&#22797;&#26434;&#24615;&#30340;&#25351;&#25968;&#32423;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20174;$d$&#32500;&#29420;&#31435;&#21516;&#20998;&#24067;&#35266;&#27979;&#20013;&#20272;&#35745;&#26410;&#30693;&#27010;&#29575;&#20998;&#24067;$\rho^*$&#30340;&#20998;&#25968;&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;&#22312;&#20551;&#35774;$\rho^*$&#26159;&#20122;&#39640;&#26031;&#30340;&#24182;&#19988;&#20855;&#26377;Lipschitz&#36830;&#32493;&#30340;&#20998;&#25968;&#20989;&#25968;$s^*$&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#22312;score matching&#25991;&#29486;&#20013;&#24120;&#29992;&#30340;&#25439;&#22833;&#20989;&#25968;$\|\hat s - s^*\|^2_{L^2(\rho^*)}$&#19979;&#24314;&#31435;&#20102;&#35813;&#20272;&#35745;&#38382;&#39064;&#30340;&#26368;&#20248;&#36895;&#29575;&#20026;$\tilde \Theta(n^{-\frac{2}{d+4}})$&#65292;&#24378;&#35843;&#20102;&#32500;&#24230;$d$&#30340;&#22686;&#38271;&#23545;&#20110;&#20934;&#30830;&#20998;&#25968;&#20272;&#35745;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#21576;&#25351;&#25968;&#32423;&#22686;&#38271;&#30340;&#22256;&#22659;&#12290;&#20511;&#21161;&#32463;&#39564;&#36125;&#21494;&#26031;&#29702;&#35770;&#30340;&#20851;&#38190;&#35265;&#35299;&#20197;&#21450;&#24179;&#28369;&#32463;&#39564;&#20998;&#24067;&#22312;Hellinger&#36317;&#31163;&#19979;&#30340;&#26032;&#25910;&#25947;&#36895;&#29575;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22522;&#20110;&#39640;&#26031;&#26680;&#30340;&#27491;&#21017;&#21270;&#20998;&#25968;&#20272;&#35745;&#22120;&#33021;&#22815;&#36798;&#21040;&#35813;&#36895;&#29575;&#65292;&#24182;&#36890;&#36807;&#21305;&#37197;&#26368;&#23567;&#20540;&#19979;&#30028;&#35777;&#26126;&#20102;&#20854;&#26368;&#20248;&#24615;&#12290;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#25105;&#20204;&#29702;&#35770;&#23545;&#20110;&#22522;&#20110;&#20998;&#25968;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of estimating the score function of an unknown probability distribution $\rho^*$ from $n$ independent and identically distributed observations in $d$ dimensions. Assuming that $\rho^*$ is subgaussian and has a Lipschitz-continuous score function $s^*$, we establish the optimal rate of $\tilde \Theta(n^{-\frac{2}{d+4}})$ for this estimation problem under the loss function $\|\hat s - s^*\|^2_{L^2(\rho^*)}$ that is commonly used in the score matching literature, highlighting the curse of dimensionality where sample complexity for accurate score estimation grows exponentially with the dimension $d$. Leveraging key insights in empirical Bayes theory as well as a new convergence rate of smoothed empirical distribution in Hellinger distance, we show that a regularized score estimator based on a Gaussian kernel attains this rate, shown optimal by a matching minimax lower bound. We also discuss the implication of our theory on the sample complexity of score-based generativ
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21363;&#19968;&#33268;&#24615;&#33945;&#29305;&#21345;&#27931;&#20803;&#23398;&#20064;&#27169;&#22411;&#65292;&#29992;&#20110;&#39044;&#27979;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#12290;&#36890;&#36807;&#21033;&#29992;&#19968;&#33268;&#24615;&#39044;&#27979;&#31995;&#32479;&#12289;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#21644;CATE&#20803;&#23398;&#20064;&#27169;&#22411;&#65292;&#35813;&#26041;&#27861;&#29983;&#25104;&#21487;&#29992;&#20110;&#20010;&#24615;&#21270;&#20915;&#31574;&#30340;&#39044;&#27979;&#20998;&#24067;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#35813;&#26041;&#27861;&#22312;&#20445;&#25345;&#36739;&#23567;&#21306;&#38388;&#23485;&#24230;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#24378;&#22823;&#30340;&#23454;&#39564;&#35206;&#30422;&#33539;&#22260;&#65292;&#21487;&#20197;&#25552;&#20379;&#30495;&#23454;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#30340;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2402.04906</link><description>&lt;p&gt;
&#39044;&#27979;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#30340;&#19968;&#33268;&#24615;&#33945;&#29305;&#21345;&#27931;&#20803;&#23398;&#20064;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Conformal Monte Carlo Meta-learners for Predictive Inference of Individual Treatment Effects
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04906
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21363;&#19968;&#33268;&#24615;&#33945;&#29305;&#21345;&#27931;&#20803;&#23398;&#20064;&#27169;&#22411;&#65292;&#29992;&#20110;&#39044;&#27979;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#12290;&#36890;&#36807;&#21033;&#29992;&#19968;&#33268;&#24615;&#39044;&#27979;&#31995;&#32479;&#12289;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#21644;CATE&#20803;&#23398;&#20064;&#27169;&#22411;&#65292;&#35813;&#26041;&#27861;&#29983;&#25104;&#21487;&#29992;&#20110;&#20010;&#24615;&#21270;&#20915;&#31574;&#30340;&#39044;&#27979;&#20998;&#24067;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#35813;&#26041;&#27861;&#22312;&#20445;&#25345;&#36739;&#23567;&#21306;&#38388;&#23485;&#24230;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#24378;&#22823;&#30340;&#23454;&#39564;&#35206;&#30422;&#33539;&#22260;&#65292;&#21487;&#20197;&#25552;&#20379;&#30495;&#23454;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#30340;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35748;&#35782;&#24178;&#39044;&#25928;&#26524;&#65292;&#21363;&#27835;&#30103;&#25928;&#26524;&#65292;&#23545;&#20110;&#20915;&#31574;&#33267;&#20851;&#37325;&#35201;&#12290;&#29992;&#26465;&#20214;&#24179;&#22343;&#27835;&#30103;&#25928;&#26524; (CATE) &#20272;&#35745;&#31561;&#26041;&#27861;&#36890;&#24120;&#21482;&#25552;&#20379;&#27835;&#30103;&#25928;&#26524;&#30340;&#28857;&#20272;&#35745;&#65292;&#32780;&#24120;&#24120;&#38656;&#35201;&#39069;&#22806;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#26041;&#27861;&#65292;&#21363;&#19968;&#33268;&#24615;&#33945;&#29305;&#21345;&#27931; (CMC) &#20803;&#23398;&#20064;&#27169;&#22411;&#65292;&#21033;&#29992;&#19968;&#33268;&#24615;&#39044;&#27979;&#31995;&#32479;&#12289;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#21644; CATE &#20803;&#23398;&#20064;&#27169;&#22411;&#65292;&#26469;&#20135;&#29983;&#21487;&#29992;&#20110;&#20010;&#24615;&#21270;&#20915;&#31574;&#30340;&#39044;&#27979;&#20998;&#24067;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#32467;&#26524;&#22122;&#22768;&#20998;&#24067;&#30340;&#29305;&#23450;&#20551;&#35774;&#22914;&#20309;&#20005;&#37325;&#24433;&#21709;&#36825;&#20123;&#19981;&#30830;&#23450;&#24615;&#39044;&#27979;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;CMC&#26694;&#26550;&#23637;&#31034;&#20102;&#24378;&#22823;&#30340;&#23454;&#39564;&#35206;&#30422;&#33539;&#22260;&#65292;&#21516;&#26102;&#20445;&#25345;&#36739;&#23567;&#30340;&#21306;&#38388;&#23485;&#24230;&#65292;&#20197;&#25552;&#20379;&#30495;&#23454;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#30340;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Knowledge of the effect of interventions, called the treatment effect, is paramount for decision-making. Approaches to estimating this treatment effect, e.g. by using Conditional Average Treatment Effect (CATE) estimators, often only provide a point estimate of this treatment effect, while additional uncertainty quantification is frequently desired instead. Therefore, we present a novel method, the Conformal Monte Carlo (CMC) meta-learners, leveraging conformal predictive systems, Monte Carlo sampling, and CATE meta-learners, to instead produce a predictive distribution usable in individualized decision-making. Furthermore, we show how specific assumptions on the noise distribution of the outcome heavily affect these uncertainty predictions. Nonetheless, the CMC framework shows strong experimental coverage while retaining small interval widths to provide estimates of the true individual treatment effect.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#30740;&#31350;&#24046;&#20998;&#38544;&#31169;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;DP-SGD&#65289;&#20013;&#30340;&#24635;&#26799;&#24230;&#26041;&#24046;&#65292;&#25105;&#20204;&#21457;&#29616;&#22823;&#25209;&#27425;&#22823;&#23567;&#26377;&#21161;&#20110;&#20943;&#23567;&#21063;&#37319;&#27171;&#24341;&#36215;&#30340;&#26041;&#24046;&#65292;&#20174;&#32780;&#25552;&#39640;&#20248;&#21270;&#25928;&#26524;&#12290;</title><link>https://arxiv.org/abs/2402.03990</link><description>&lt;p&gt;
&#21063;&#37319;&#27171;&#24182;&#19981;&#26159;&#39764;&#27861;: &#22823;&#25209;&#37327;&#22823;&#23567;&#28858;&#20160;&#40636;&#36969;&#29992;&#26044;&#24046;&#20998;&#38577;&#31169;&#38568;&#27231;&#20778;&#21270;
&lt;/p&gt;
&lt;p&gt;
Subsampling is not Magic: Why Large Batch Sizes Work for Differentially Private Stochastic Optimisation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03990
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#30740;&#31350;&#24046;&#20998;&#38544;&#31169;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;DP-SGD&#65289;&#20013;&#30340;&#24635;&#26799;&#24230;&#26041;&#24046;&#65292;&#25105;&#20204;&#21457;&#29616;&#22823;&#25209;&#27425;&#22823;&#23567;&#26377;&#21161;&#20110;&#20943;&#23567;&#21063;&#37319;&#27171;&#24341;&#36215;&#30340;&#26041;&#24046;&#65292;&#20174;&#32780;&#25552;&#39640;&#20248;&#21270;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20497;&#30740;&#31350;&#20102;&#25209;&#27425;&#22823;&#23567;&#23565;&#24046;&#20998;&#38577;&#31169;&#38568;&#27231;&#26799;&#24230;&#19979;&#38477;&#65288;DP-SGD&#65289;&#20013;&#32317;&#26799;&#24230;&#26041;&#24046;&#30340;&#24433;&#38911;&#65292;&#23563;&#27714;&#23565;&#22823;&#25209;&#27425;&#22823;&#23567;&#26377;&#29992;&#24615;&#30340;&#29702;&#35542;&#35299;&#37323;&#12290;&#30001;&#26044;DP-SGD&#26159;&#29694;&#20195;&#24046;&#20998;&#38577;&#31169;&#28145;&#24230;&#23416;&#32722;&#30340;&#22522;&#30990;&#65292;&#20854;&#24615;&#36074;&#24050;&#34987;&#24291;&#27867;&#30740;&#31350;&#65292;&#26368;&#36817;&#30340;&#24037;&#20316;&#22312;&#23526;&#36368;&#20013;&#30332;&#29694;&#22823;&#25209;&#27425;&#22823;&#23567;&#26377;&#30410;&#12290;&#28982;&#32780;&#65292;&#23565;&#26044;&#36889;&#31278;&#22909;&#34389;&#30340;&#29702;&#35542;&#35299;&#37323;&#30446;&#21069;&#26368;&#22810;&#21482;&#33021;&#35498;&#26159;&#21855;&#30332;&#24335;&#30340;&#12290;&#25105;&#20497;&#39318;&#20808;&#35264;&#23519;&#21040;&#65292;&#22312;DP-SGD&#20013;&#65292;&#32317;&#26799;&#24230;&#26041;&#24046;&#21487;&#20197;&#20998;&#35299;&#28858;&#30001;&#21063;&#37319;&#27171;&#21644;&#22122;&#32882;&#24341;&#36215;&#30340;&#26041;&#24046;&#12290;&#28982;&#24460;&#65292;&#25105;&#20497;&#35657;&#26126;&#22312;&#28961;&#38480;&#27425;&#36845;&#20195;&#30340;&#26997;&#38480;&#24773;&#27841;&#19979;&#65292;&#26377;&#25928;&#30340;&#22122;&#32882;&#24341;&#36215;&#30340;&#26041;&#24046;&#23565;&#25209;&#27425;&#22823;&#23567;&#26159;&#19981;&#35722;&#30340;&#12290;&#21097;&#19979;&#30340;&#21063;&#37319;&#27171;&#24341;&#36215;&#30340;&#26041;&#24046;&#38568;&#33879;&#25209;&#27425;&#22823;&#23567;&#30340;&#22686;&#22823;&#32780;&#28187;&#23567;&#65292;&#22240;&#27492;&#22823;&#25209;&#27425;&#22823;&#23567;&#28187;&#23567;&#20102;&#26377;&#25928;&#30340;&#32317;&#26799;&#24230;&#26041;&#24046;&#12290;&#25105;&#20497;&#22312;&#25976;&#20540;&#19978;&#30906;&#35469;&#36889;&#31278;&#28472;&#36914;&#30340;&#24773;&#27841;&#22312;&#23526;&#38555;&#29872;&#22659;&#20013;&#26159;&#30456;&#38364;&#30340;&#65292;&#30070;&#25209;&#27425;&#22823;&#23567;&#19981;&#23567;&#30340;&#26178;&#20505;&#26371;&#36215;&#20316;&#29992;&#65292;&#20006;&#19988;&#30332;&#29694;
&lt;/p&gt;
&lt;p&gt;
We study the effect of the batch size to the total gradient variance in differentially private stochastic gradient descent (DP-SGD), seeking a theoretical explanation for the usefulness of large batch sizes. As DP-SGD is the basis of modern DP deep learning, its properties have been widely studied, and recent works have empirically found large batch sizes to be beneficial. However, theoretical explanations of this benefit are currently heuristic at best. We first observe that the total gradient variance in DP-SGD can be decomposed into subsampling-induced and noise-induced variances. We then prove that in the limit of an infinite number of iterations, the effective noise-induced variance is invariant to the batch size. The remaining subsampling-induced variance decreases with larger batch sizes, so large batches reduce the effective total gradient variance. We confirm numerically that the asymptotic regime is relevant in practical settings when the batch size is not small, and find tha
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#12289;&#39640;&#25928;&#19988;&#24378;&#22823;&#30340;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#65288;RMIA&#65289;&#65292;&#20855;&#26377;&#26356;&#20934;&#30830;&#30340;&#24314;&#27169;&#21644;&#26356;&#39640;&#30340;&#27979;&#35797;&#33021;&#21147;&#65292;&#36866;&#29992;&#20110;&#38544;&#31169;&#39118;&#38505;&#35780;&#20272;&#12290;</title><link>https://arxiv.org/abs/2312.03262</link><description>&lt;p&gt;
&#20302;&#25104;&#26412;&#39640;&#21151;&#29575;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Low-Cost High-Power Membership Inference Attacks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.03262
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#12289;&#39640;&#25928;&#19988;&#24378;&#22823;&#30340;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#65288;RMIA&#65289;&#65292;&#20855;&#26377;&#26356;&#20934;&#30830;&#30340;&#24314;&#27169;&#21644;&#26356;&#39640;&#30340;&#27979;&#35797;&#33021;&#21147;&#65292;&#36866;&#29992;&#20110;&#38544;&#31169;&#39118;&#38505;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#65288;MIA&#65289;&#26088;&#22312;&#26816;&#27979;&#29305;&#23450;&#25968;&#25454;&#28857;&#26159;&#21542;&#22312;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26102;&#20351;&#29992;&#12290;&#26368;&#36817;&#19968;&#20123;&#24378;&#22823;&#30340;&#25915;&#20987;&#20855;&#26377;&#36739;&#39640;&#30340;&#35745;&#31639;&#25104;&#26412;&#65292;&#24182;&#22312;&#19981;&#21516;&#26465;&#20214;&#19979;&#34920;&#29616;&#19981;&#19968;&#33268;&#65292;&#20351;&#23427;&#20204;&#23545;&#20110;&#23454;&#38469;&#30340;&#38544;&#31169;&#39118;&#38505;&#35780;&#20272;&#19981;&#21487;&#38752;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#39062;&#12289;&#39640;&#25928;&#19988;&#24378;&#22823;&#30340;&#25104;&#21592;&#25512;&#26029;&#25915;&#20987;&#65288;RMIA&#65289;&#65292;&#33021;&#22815;&#20934;&#30830;&#21306;&#20998;&#27169;&#22411;&#30340;&#24635;&#20307;&#25968;&#25454;&#21644;&#35757;&#32451;&#25968;&#25454;&#65292;&#21516;&#26102;&#35745;&#31639;&#24320;&#38144;&#26368;&#23567;&#12290;&#25105;&#20204;&#36890;&#36807;&#22312;&#20284;&#28982;&#27604;&#26816;&#39564;&#20013;&#26356;&#20934;&#30830;&#22320;&#24314;&#27169;&#38646;&#20551;&#35774;&#35774;&#32622;&#65292;&#24182;&#26377;&#25928;&#22320;&#21033;&#29992;&#26469;&#33258;&#24635;&#20307;&#30340;&#21442;&#32771;&#27169;&#22411;&#21644;&#21442;&#32771;&#25968;&#25454;&#26679;&#26412;&#65292;&#23454;&#29616;&#20102;&#36825;&#19968;&#30446;&#26631;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#30495;&#27491;&#29575;&#65288;true-positive rate&#65289;&#26041;&#38754;&#34920;&#29616;&#20986;&#27604;&#20808;&#21069;&#26041;&#27861;&#26356;&#39640;&#30340;&#27979;&#35797;&#33021;&#21147;&#65292;&#25972;&#20010;TPR-FPR&#26354;&#32447;&#37117;&#20855;&#22791;&#36825;&#31181;&#20248;&#21183;&#65292;&#21363;&#20351;&#22312;&#26497;&#20302;&#30340;&#35823;&#25253;&#29575;&#19979;&#65288;&#20302;&#33267;0&#65289;&#20063;&#26159;&#22914;&#27492;&#12290;&#22312;&#35745;&#31639;&#32422;&#26463;&#26465;&#20214;&#19979;&#65292;&#21482;&#26377;&#26377;&#38480;&#25968;&#37327;&#30340;&#24773;&#20917;&#19979;&#65292;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.03262v2 Announce Type: replace-cross  Abstract: Membership inference attacks (MIA) aim to detect if a particular data point was used in training a machine learning model. Recent strong attacks have high computational costs and inconsistent performance under varying conditions, rendering them unreliable for practical privacy risk assessment. We design a novel, efficient, and robust membership inference attack (RMIA) which accurately differentiates between population data and training data of a model, with minimal computational overhead. We achieve this by a more accurate modeling of the null hypothesis setting in our likelihood ratio tests, and effectively leveraging both reference models and reference data samples from the population. Our algorithm exhibits superior test power (true-positive rate) compared to prior methods, throughout the TPR-FPR curve including at extremely low false-positive rates (as low as 0). Under computation constraints, where only a limited number of
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25506;&#35752;&#20102;&#22914;&#20309;&#21033;&#29992;&#20844;&#20849;&#25968;&#25454;&#26469;&#25913;&#36827;&#31169;&#26377;&#23398;&#20064;&#30340;&#38382;&#39064;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#36890;&#36807;&#23398;&#20064;&#20844;&#20849;&#25968;&#25454;&#20013;&#30340;&#20849;&#20139;&#34920;&#31034;&#65292;&#21487;&#20197;&#22312;&#20004;&#31181;&#36801;&#31227;&#23398;&#20064;&#22330;&#26223;&#20013;&#23454;&#29616;&#26368;&#20248;&#30340;&#23398;&#20064;&#25928;&#26524;&#12290;&#22312;&#21333;&#20219;&#21153;&#36801;&#31227;&#22330;&#26223;&#20013;&#65292;&#31639;&#27861;&#22312;&#32473;&#23450;&#23376;&#31354;&#38388;&#33539;&#22260;&#20869;&#25628;&#32034;&#32447;&#24615;&#27169;&#22411;&#65292;&#24182;&#23454;&#29616;&#20102;&#26368;&#20248;&#36229;&#39069;&#39118;&#38505;&#12290;&#22312;&#22810;&#20219;&#21153;&#20010;&#24615;&#21270;&#22330;&#26223;&#20013;&#65292;&#36275;&#22815;&#30340;&#20844;&#20849;&#25968;&#25454;&#21487;&#20197;&#28040;&#38500;&#31169;&#26377;&#21327;&#35843;&#38656;&#27714;&#65292;&#24182;&#36890;&#36807;&#32431;&#23616;&#37096;&#23398;&#20064;&#36798;&#21040;&#30456;&#21516;&#30340;&#25928;&#29992;&#12290;</title><link>http://arxiv.org/abs/2312.15551</link><description>&lt;p&gt;
&#21033;&#29992;&#20844;&#20849;&#34920;&#31034;&#26469;&#36827;&#34892;&#31169;&#26377;&#36801;&#31227;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Leveraging Public Representations for Private Transfer Learning. (arXiv:2312.15551v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.15551
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25506;&#35752;&#20102;&#22914;&#20309;&#21033;&#29992;&#20844;&#20849;&#25968;&#25454;&#26469;&#25913;&#36827;&#31169;&#26377;&#23398;&#20064;&#30340;&#38382;&#39064;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#36890;&#36807;&#23398;&#20064;&#20844;&#20849;&#25968;&#25454;&#20013;&#30340;&#20849;&#20139;&#34920;&#31034;&#65292;&#21487;&#20197;&#22312;&#20004;&#31181;&#36801;&#31227;&#23398;&#20064;&#22330;&#26223;&#20013;&#23454;&#29616;&#26368;&#20248;&#30340;&#23398;&#20064;&#25928;&#26524;&#12290;&#22312;&#21333;&#20219;&#21153;&#36801;&#31227;&#22330;&#26223;&#20013;&#65292;&#31639;&#27861;&#22312;&#32473;&#23450;&#23376;&#31354;&#38388;&#33539;&#22260;&#20869;&#25628;&#32034;&#32447;&#24615;&#27169;&#22411;&#65292;&#24182;&#23454;&#29616;&#20102;&#26368;&#20248;&#36229;&#39069;&#39118;&#38505;&#12290;&#22312;&#22810;&#20219;&#21153;&#20010;&#24615;&#21270;&#22330;&#26223;&#20013;&#65292;&#36275;&#22815;&#30340;&#20844;&#20849;&#25968;&#25454;&#21487;&#20197;&#28040;&#38500;&#31169;&#26377;&#21327;&#35843;&#38656;&#27714;&#65292;&#24182;&#36890;&#36807;&#32431;&#23616;&#37096;&#23398;&#20064;&#36798;&#21040;&#30456;&#21516;&#30340;&#25928;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#21040;&#23558;&#20844;&#20849;&#25968;&#25454;&#32435;&#20837;&#24046;&#20998;&#38544;&#31169;&#23398;&#20064;&#30340;&#26368;&#26032;&#23454;&#35777;&#25104;&#21151;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#30740;&#31350;&#20102;&#20174;&#20844;&#20849;&#25968;&#25454;&#20013;&#23398;&#21040;&#30340;&#20849;&#20139;&#34920;&#31034;&#22914;&#20309;&#25913;&#36827;&#31169;&#26377;&#23398;&#20064;&#12290;&#25105;&#20204;&#25506;&#35752;&#20102;&#32447;&#24615;&#22238;&#24402;&#30340;&#20004;&#31181;&#24120;&#35265;&#36801;&#31227;&#23398;&#20064;&#22330;&#26223;&#65292;&#20004;&#32773;&#37117;&#20551;&#35774;&#20844;&#20849;&#20219;&#21153;&#21644;&#31169;&#26377;&#20219;&#21153;&#65288;&#22238;&#24402;&#21521;&#37327;&#65289;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#20849;&#20139;&#19968;&#20010;&#20302;&#31209;&#23376;&#31354;&#38388;&#12290;&#22312;&#31532;&#19968;&#31181;&#21333;&#20219;&#21153;&#36801;&#31227;&#22330;&#26223;&#20013;&#65292;&#30446;&#26631;&#26159;&#23398;&#20064;&#19968;&#20010;&#22312;&#25152;&#26377;&#29992;&#25143;&#20043;&#38388;&#20849;&#20139;&#30340;&#21333;&#19968;&#27169;&#22411;&#65292;&#27599;&#20010;&#29992;&#25143;&#23545;&#24212;&#25968;&#25454;&#38598;&#20013;&#30340;&#19968;&#34892;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#21305;&#37197;&#30340;&#19978;&#19979;&#30028;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#32473;&#23450;&#23376;&#31354;&#38388;&#20272;&#35745;&#33539;&#22260;&#20869;&#25628;&#32034;&#32447;&#24615;&#27169;&#22411;&#30340;&#31639;&#27861;&#31867;&#20013;&#23454;&#29616;&#20102;&#26368;&#20248;&#36229;&#39069;&#39118;&#38505;&#12290;&#22312;&#22810;&#20219;&#21153;&#27169;&#22411;&#20010;&#24615;&#21270;&#30340;&#31532;&#20108;&#31181;&#24773;&#26223;&#20013;&#65292;&#25105;&#20204;&#34920;&#26126;&#22312;&#26377;&#36275;&#22815;&#30340;&#20844;&#20849;&#25968;&#25454;&#24773;&#20917;&#19979;&#65292;&#29992;&#25143;&#21487;&#20197;&#36991;&#20813;&#31169;&#26377;&#21327;&#35843;&#65292;&#22240;&#20026;&#22312;&#32473;&#23450;&#23376;&#31354;&#38388;&#20869;&#32431;&#31929;&#30340;&#23616;&#37096;&#23398;&#20064;&#21487;&#20197;&#36798;&#21040;&#30456;&#21516;&#30340;&#25928;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by the recent empirical success of incorporating public data into differentially private learning, we theoretically investigate how a shared representation learned from public data can improve private learning. We explore two common scenarios of transfer learning for linear regression, both of which assume the public and private tasks (regression vectors) share a low-rank subspace in a high-dimensional space. In the first single-task transfer scenario, the goal is to learn a single model shared across all users, each corresponding to a row in a dataset. We provide matching upper and lower bounds showing that our algorithm achieves the optimal excess risk within a natural class of algorithms that search for the linear model within the given subspace estimate. In the second scenario of multitask model personalization, we show that with sufficient public data, users can avoid private coordination, as purely local learning within the given subspace achieves the same utility. Take
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#36125;&#21494;&#26031;EM&#31639;&#27861;&#65292;&#29992;&#20110;&#20174;&#20108;&#20803;&#21644;&#26377;&#24207;&#39033;&#30446;&#21709;&#24212;&#20013;&#20272;&#35745;&#31232;&#30095;&#22240;&#23376;&#36733;&#33655;&#65292;&#24182;&#36890;&#36807;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#35299;&#20915;&#20102;&#26410;&#30693;&#28508;&#22312;&#22240;&#23376;&#32500;&#24230;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.17820</link><description>&lt;p&gt;
&#31232;&#30095;&#36125;&#21494;&#26031;&#22810;&#32500;&#39033;&#30446;&#21453;&#24212;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Sparse Bayesian Multidimensional Item Response Theory. (arXiv:2310.17820v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17820
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#36125;&#21494;&#26031;EM&#31639;&#27861;&#65292;&#29992;&#20110;&#20174;&#20108;&#20803;&#21644;&#26377;&#24207;&#39033;&#30446;&#21709;&#24212;&#20013;&#20272;&#35745;&#31232;&#30095;&#22240;&#23376;&#36733;&#33655;&#65292;&#24182;&#36890;&#36807;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#35299;&#20915;&#20102;&#26410;&#30693;&#28508;&#22312;&#22240;&#23376;&#32500;&#24230;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#21464;&#37327;&#39033;&#30446;&#21453;&#24212;&#29702;&#35770;&#65288;MIRT&#65289;&#34987;&#24212;&#29992;&#30740;&#31350;&#20154;&#21592;&#24191;&#27867;&#20351;&#29992;&#65292;&#20197;&#23547;&#25214;&#38382;&#21367;&#25968;&#25454;&#20013;&#21709;&#24212;&#27169;&#24335;&#32972;&#21518;&#30340;&#21487;&#35299;&#37322;&#65288;&#31232;&#30095;&#65289;&#35299;&#37322;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#23545;&#20110;&#36825;&#31181;&#31232;&#30095;&#24615;&#21457;&#29616;&#24037;&#20855;&#30340;&#38656;&#27714;&#23578;&#26410;&#24471;&#21040;&#28385;&#36275;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20108;&#20803;&#21644;&#26377;&#24207;&#39033;&#30446;MIRT&#30340;&#36125;&#21494;&#26031;&#24179;&#21488;&#65292;&#20854;&#38656;&#35201;&#26368;&#23569;&#30340;&#35843;&#25972;&#65292;&#24182;&#19988;&#30001;&#20110;&#20854;&#21487;&#24182;&#34892;&#21270;&#30340;&#29305;&#24615;&#65292;&#22312;&#30456;&#23545;&#36739;&#22823;&#30340;&#25968;&#25454;&#38598;&#19978;&#20855;&#26377;&#33391;&#22909;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;MIRT&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#20256;&#32479;&#19978;&#20381;&#36182;&#20110;MCMC&#27169;&#25311;&#65292;&#22312;&#23454;&#36341;&#20013;&#21487;&#33021;&#26082;&#36153;&#26102;&#21448;&#38590;&#20197;&#36890;&#36807;&#39069;&#22806;&#30340;&#38408;&#20540;&#35774;&#23450;&#23454;&#29616;&#31934;&#30830;&#30340;&#31232;&#30095;&#24674;&#22797;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#36125;&#21494;&#26031;EM&#31639;&#27861;&#65292;&#29992;&#20110;&#20174;&#20108;&#20803;&#21644;&#26377;&#24207;&#39033;&#30446;&#21709;&#24212;&#20013;&#20272;&#35745;&#31232;&#30095;&#22240;&#23376;&#36733;&#33655;&#12290;&#25105;&#20204;&#21033;&#29992;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#35299;&#20915;&#20102;&#26410;&#30693;&#28508;&#22312;&#22240;&#23376;&#32500;&#24230;&#30340;&#30475;&#20284;&#19981;&#21487;&#36926;&#36234;&#30340;&#38382;&#39064;&#65292;&#20174;&#32780;&#20351;&#24471;&#21487;&#20197;&#20272;&#35745;&#22240;&#23376;&#30340;&#25968;&#37327;&#12290;&#36890;&#36807;&#26059;&#36716;&#21487;&#20197;&#23454;&#29616;&#31232;&#30095;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multivariate Item Response Theory (MIRT) is sought-after widely by applied researchers looking for interpretable (sparse) explanations underlying response patterns in questionnaire data. There is, however, an unmet demand for such sparsity discovery tools in practice. Our paper develops a Bayesian platform for binary and ordinal item MIRT which requires minimal tuning and scales well on relatively large datasets due to its parallelizable features. Bayesian methodology for MIRT models has traditionally relied on MCMC simulation, which cannot only be slow in practice, but also often renders exact sparsity recovery impossible without additional thresholding. In this work, we develop a scalable Bayesian EM algorithm to estimate sparse factor loadings from binary and ordinal item responses. We address the seemingly insurmountable problem of unknown latent factor dimensionality with tools from Bayesian nonparametrics which enable estimating the number of factors. Rotations to sparsity throug
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#27491;&#20132;&#30697;&#38453;&#38598;&#21512;&#21021;&#22987;&#21270;&#26435;&#37325;&#24182;&#20351;&#29992;tanh&#28608;&#27963;&#20989;&#25968;&#65292;&#35299;&#20915;&#20102;&#20840;&#36830;&#25509;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#21021;&#22987;&#21270;&#20013;&#20855;&#26377;&#19982;&#28145;&#24230;&#26080;&#20851;&#30340;&#32447;&#24615;&#27874;&#21160;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21457;&#29616;&#31070;&#32463;&#20999;&#21521;&#26680;&#65288;NTK&#65289;&#21450;&#20854;&#21518;&#20195;&#30340;&#25152;&#26377;&#30456;&#20851;&#20989;&#25968;&#22312;&#36870;&#23485;&#24230;&#30340;&#20027;&#23548;&#38454;&#27573;&#22312;&#28145;&#24230;&#32422;&#20026;20&#30340;&#20301;&#32622;&#39281;&#21644;&#65292;&#32780;&#19981;&#26159;&#19981;&#26029;&#22686;&#38271;&#12290;</title><link>http://arxiv.org/abs/2310.07765</link><description>&lt;p&gt;
&#20855;&#26377;&#27491;&#20132;&#26435;&#37325;&#30340;&#28145;&#24230;&#32593;&#32476;&#20013;&#30340;&#29305;&#24449;&#23398;&#20064;&#19982;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Feature Learning and Generalization in Deep Networks with Orthogonal Weights. (arXiv:2310.07765v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07765
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#27491;&#20132;&#30697;&#38453;&#38598;&#21512;&#21021;&#22987;&#21270;&#26435;&#37325;&#24182;&#20351;&#29992;tanh&#28608;&#27963;&#20989;&#25968;&#65292;&#35299;&#20915;&#20102;&#20840;&#36830;&#25509;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#21021;&#22987;&#21270;&#20013;&#20855;&#26377;&#19982;&#28145;&#24230;&#26080;&#20851;&#30340;&#32447;&#24615;&#27874;&#21160;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21457;&#29616;&#31070;&#32463;&#20999;&#21521;&#26680;&#65288;NTK&#65289;&#21450;&#20854;&#21518;&#20195;&#30340;&#25152;&#26377;&#30456;&#20851;&#20989;&#25968;&#22312;&#36870;&#23485;&#24230;&#30340;&#20027;&#23548;&#38454;&#27573;&#22312;&#28145;&#24230;&#32422;&#20026;20&#30340;&#20301;&#32622;&#39281;&#21644;&#65292;&#32780;&#19981;&#26159;&#19981;&#26029;&#22686;&#38271;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;&#20174;&#27491;&#20132;&#30697;&#38453;&#38598;&#21512;&#21021;&#22987;&#21270;&#30340;&#26435;&#37325;&#21644;tanh&#28608;&#27963;&#20989;&#25968;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20840;&#36830;&#25509;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#21021;&#22987;&#21270;&#26102;&#20855;&#26377;&#19982;&#23485;&#24230;&#26080;&#20851;&#30340;&#21069;&#28608;&#27963;&#27874;&#21160;&#65292;&#36825;&#26159;&#36890;&#36807;&#35745;&#31639;&#35777;&#26126;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#21021;&#22987;&#21270;&#26102;&#65292;&#28041;&#21450;&#31070;&#32463;&#20999;&#21521;&#26680;&#65288;NTK&#65289;&#21450;&#20854;&#21518;&#20195;&#30340;&#25152;&#26377;&#30456;&#20851;&#20989;&#25968;&#22312;&#36870;&#23485;&#24230;&#30340;&#20027;&#23548;&#38454;&#27573;&#39281;&#21644;&#22312;&#28145;&#24230;&#32422;&#20026;20&#30340;&#20301;&#32622;&#65292;&#32780;&#19981;&#26159;&#20687;&#39640;&#26031;&#21021;&#22987;&#21270;&#30340;&#24773;&#20917;&#37027;&#26679;&#19981;&#26029;&#22686;&#38271;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fully-connected deep neural networks with weights initialized from independent Gaussian distributions can be tuned to criticality, which prevents the exponential growth or decay of signals propagating through the network. However, such networks still exhibit fluctuations that grow linearly with the depth of the network, which may impair the training of networks with width comparable to depth. We show analytically that rectangular networks with tanh activations and weights initialized from the ensemble of orthogonal matrices have corresponding preactivation fluctuations which are independent of depth, to leading order in inverse width. Moreover, we demonstrate numerically that, at initialization, all correlators involving the neural tangent kernel (NTK) and its descendants at leading order in inverse width -- which govern the evolution of observables during training -- saturate at a depth of $\sim 20$, rather than growing without bound as in the case of Gaussian initializations. We spec
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19977;&#31181;&#37327;&#23376;&#22122;&#22768;&#39537;&#21160;&#30340;&#29983;&#25104;&#25193;&#25955;&#27169;&#22411;&#65292;&#21033;&#29992;&#20102;&#37327;&#23376;&#29305;&#24615;&#20197;&#20811;&#26381;&#20256;&#32479;&#27169;&#22411;&#30340;&#20027;&#35201;&#35745;&#31639;&#22256;&#38590;&#65292;&#24182;&#24314;&#35758;&#23558;&#37327;&#23376;&#22122;&#22768;&#35270;&#20026;&#21487;&#21033;&#29992;&#30340;&#29305;&#24615;&#32780;&#38750;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.12013</link><description>&lt;p&gt;
&#37327;&#23376;&#22122;&#22768;&#39537;&#21160;&#30340;&#29983;&#25104;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Quantum-Noise-driven Generative Diffusion Models. (arXiv:2308.12013v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12013
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19977;&#31181;&#37327;&#23376;&#22122;&#22768;&#39537;&#21160;&#30340;&#29983;&#25104;&#25193;&#25955;&#27169;&#22411;&#65292;&#21033;&#29992;&#20102;&#37327;&#23376;&#29305;&#24615;&#20197;&#20811;&#26381;&#20256;&#32479;&#27169;&#22411;&#30340;&#20027;&#35201;&#35745;&#31639;&#22256;&#38590;&#65292;&#24182;&#24314;&#35758;&#23558;&#37327;&#23376;&#22122;&#22768;&#35270;&#20026;&#21487;&#21033;&#29992;&#30340;&#29305;&#24615;&#32780;&#38750;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#23454;&#29616;&#30340;&#29983;&#25104;&#27169;&#22411;&#26159;&#20174;&#26377;&#38480;&#30340;&#35757;&#32451;&#26679;&#26412;&#20013;&#25512;&#26029;&#20986;&#22797;&#26434;&#21644;&#26410;&#30693;&#25968;&#25454;&#20998;&#24067;&#24182;&#20135;&#29983;&#26032;&#30340;&#21512;&#25104;&#25968;&#25454;&#30340;&#24378;&#22823;&#24037;&#20855;&#12290;&#25193;&#25955;&#27169;&#22411;&#26159;&#19968;&#31181;&#26032;&#20852;&#30340;&#26694;&#26550;&#65292;&#26368;&#36817;&#22312;&#21019;&#24314;&#21512;&#25104;&#25991;&#26412;&#21644;&#39640;&#36136;&#37327;&#22270;&#20687;&#26041;&#38754;&#24050;&#32463;&#36229;&#36234;&#20102;&#29983;&#25104;&#23545;&#25239;&#24615;&#32593;&#32476;&#30340;&#24615;&#33021;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#24182;&#35752;&#35770;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#37327;&#23376;&#25512;generalization&#65292;&#21363;&#19977;&#31181;&#21487;&#33021;&#22312;&#23454;&#38469;&#37327;&#23376;&#31995;&#32479;&#19978;&#36827;&#34892;&#23454;&#39564;&#30340;&#37327;&#23376;&#22122;&#22768;&#39537;&#21160;&#30340;&#29983;&#25104;&#25193;&#25955;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#24819;&#27861;&#26159;&#21033;&#29992;&#29420;&#29305;&#30340;&#37327;&#23376;&#29305;&#24615;&#65292;&#29305;&#21035;&#26159;&#30446;&#21069;&#21487;&#29992;&#30340;&#26377;&#22122;&#22768;&#37327;&#23376;&#22788;&#29702;&#22120;&#19981;&#21487;&#36991;&#20813;&#22320;&#21463;&#21040;&#30340;&#30456;&#24178;&#24615;&#12289;&#32416;&#32544;&#24615;&#21644;&#22122;&#22768;&#20043;&#38388;&#30340;&#38750;&#24179;&#20961;&#30456;&#20114;&#20316;&#29992;&#65292;&#20197;&#20811;&#26381;&#20256;&#32479;&#25193;&#25955;&#27169;&#22411;&#22312;&#25512;&#26029;&#36807;&#31243;&#20013;&#30340;&#20027;&#35201;&#35745;&#31639;&#36127;&#25285;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24314;&#35758;&#23558;&#37327;&#23376;&#22122;&#22768;&#19981;&#20316;&#20026;&#38656;&#35201;&#26816;&#27979;&#21644;&#35299;&#20915;&#30340;&#38382;&#39064;&#65292;&#32780;&#26159;&#20316;&#20026;&#19968;&#31181;&#21487;&#21033;&#29992;&#30340;&#29305;&#24615;&#65292;&#20351;&#24471;&#25193;&#25955;&#27169;&#22411;&#33021;&#22815;&#26356;&#22909;&#22320;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative models realized with machine learning techniques are powerful tools to infer complex and unknown data distributions from a finite number of training samples in order to produce new synthetic data. Diffusion models are an emerging framework that have recently overcome the performance of the generative adversarial networks in creating synthetic text and high-quality images. Here, we propose and discuss the quantum generalization of diffusion models, i.e., three quantum-noise-driven generative diffusion models that could be experimentally tested on real quantum systems. The idea is to harness unique quantum features, in particular the non-trivial interplay among coherence, entanglement and noise that the currently available noisy quantum processors do unavoidably suffer from, in order to overcome the main computational burdens of classical diffusion models during inference. Hence, we suggest to exploit quantum noise not as an issue to be detected and solved but instead as a ver
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#28151;&#21512;VAE&#27169;&#22411;&#23398;&#20064;&#27969;&#24418;&#30340;&#26041;&#27861;&#65292;&#24182;&#23558;&#20854;&#29992;&#20110;&#35299;&#20915;&#36870;&#38382;&#39064;&#65292;&#32467;&#26524;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#65292;&#21487;&#29992;&#20110;&#27169;&#31946;&#21644;&#30005;&#38459;&#25239;&#23618;&#26512;&#25104;&#20687;&#12290;</title><link>http://arxiv.org/abs/2303.15244</link><description>&lt;p&gt;
&#29992;&#28151;&#21512;VAE&#27169;&#22411;&#23398;&#20064;&#27969;&#24418;&#26469;&#35299;&#20915;&#36870;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Manifold Learning by Mixture Models of VAEs for Inverse Problems. (arXiv:2303.15244v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15244
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#28151;&#21512;VAE&#27169;&#22411;&#23398;&#20064;&#27969;&#24418;&#30340;&#26041;&#27861;&#65292;&#24182;&#23558;&#20854;&#29992;&#20110;&#35299;&#20915;&#36870;&#38382;&#39064;&#65292;&#32467;&#26524;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#65292;&#21487;&#29992;&#20110;&#27169;&#31946;&#21644;&#30005;&#38459;&#25239;&#23618;&#26512;&#25104;&#20687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#36341;&#20013;&#65292;&#20351;&#29992;&#29983;&#25104;&#27169;&#22411;&#34920;&#31034;&#39640;&#32500;&#25968;&#25454;&#30340;&#27969;&#24418;&#24050;&#34987;&#35777;&#26126;&#20855;&#26377;&#35745;&#31639;&#25928;&#29575;&#12290;&#28982;&#32780;&#65292;&#36825;&#35201;&#27714;&#25968;&#25454;&#27969;&#24418;&#20855;&#26377;&#20840;&#23616;&#21442;&#25968;&#21270;&#12290;&#20026;&#20102;&#34920;&#31034;&#20219;&#24847;&#25299;&#25169;&#30340;&#27969;&#24418;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23398;&#20064;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#30340;&#28151;&#21512;&#27169;&#22411;&#12290;&#36825;&#37324;&#65292;&#27599;&#20010;&#32534;&#30721;&#22120;-&#35299;&#30721;&#22120;&#23545;&#34920;&#31034;&#27969;&#24418;&#30340;&#19968;&#20010;&#22270;&#34920;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25439;&#22833;&#20989;&#25968;&#26469;&#26368;&#22823;&#21270;&#20284;&#28982;&#20272;&#35745;&#27169;&#22411;&#26435;&#37325;&#65292;&#24182;&#36873;&#25321;&#19968;&#20010;&#26550;&#26500;&#65292;&#20026;&#25105;&#20204;&#25552;&#20379;&#22270;&#34920;&#21450;&#20854;&#36870;&#30340;&#35299;&#26512;&#34920;&#36798;&#24335;&#12290;&#19968;&#26086;&#23398;&#20064;&#20102;&#27969;&#24418;&#65292;&#25105;&#20204;&#23558;&#20854;&#29992;&#20110;&#36890;&#36807;&#23558;&#25968;&#25454;&#25311;&#21512;&#39033;&#38480;&#21046;&#22312;&#23398;&#20064;&#30340;&#27969;&#24418;&#19978;&#26469;&#35299;&#20915;&#36870;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#25152;&#20135;&#29983;&#30340;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#25105;&#20204;&#22312;&#23398;&#20064;&#30340;&#27969;&#24418;&#19978;&#25552;&#20986;&#20102;&#19968;&#31181;&#40654;&#26364;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20302;&#32500;&#29609;&#20855;&#20363;&#23376;&#20197;&#21450;&#27169;&#31946;&#21644;&#30005;&#38459;&#25239;&#23618;&#26512;&#25104;&#20687;&#26041;&#38754;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Representing a manifold of very high-dimensional data with generative models has been shown to be computationally efficient in practice. However, this requires that the data manifold admits a global parameterization. In order to represent manifolds of arbitrary topology, we propose to learn a mixture model of variational autoencoders. Here, every encoder-decoder pair represents one chart of a manifold. We propose a loss function for maximum likelihood estimation of the model weights and choose an architecture that provides us the analytical expression of the charts and of their inverses. Once the manifold is learned, we use it for solving inverse problems by minimizing a data fidelity term restricted to the learned manifold. To solve the arising minimization problem we propose a Riemannian gradient descent algorithm on the learned manifold. We demonstrate the performance of our method for low-dimensional toy examples as well as for deblurring and electrical impedance tomography on cert
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#21033;&#29992;&#29305;&#26435;&#20449;&#24687;&#36827;&#34892;&#39046;&#22495;&#36866;&#24212;&#65288;DALUPI&#65289;&#31639;&#27861;&#65292;&#20197;&#22312;&#23398;&#20064;&#20013;&#25918;&#23485;&#20551;&#35774;&#26465;&#20214;&#24182;&#25552;&#39640;&#26679;&#26412;&#25928;&#29575;&#65292;&#36890;&#36807;&#20943;&#23569;&#38169;&#35823;&#26469;&#20419;&#36827;&#21307;&#23398;&#22270;&#20687;&#20998;&#26512;&#31561;&#24212;&#29992;&#30340;&#21457;&#23637;&#12290;</title><link>http://arxiv.org/abs/2303.09350</link><description>&lt;p&gt;
&#21033;&#29992;&#29305;&#26435;&#20449;&#24687;&#36827;&#34892;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;
&lt;/p&gt;
&lt;p&gt;
Unsupervised domain adaptation by learning using privileged information. (arXiv:2303.09350v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.09350
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#21033;&#29992;&#29305;&#26435;&#20449;&#24687;&#36827;&#34892;&#39046;&#22495;&#36866;&#24212;&#65288;DALUPI&#65289;&#31639;&#27861;&#65292;&#20197;&#22312;&#23398;&#20064;&#20013;&#25918;&#23485;&#20551;&#35774;&#26465;&#20214;&#24182;&#25552;&#39640;&#26679;&#26412;&#25928;&#29575;&#65292;&#36890;&#36807;&#20943;&#23569;&#38169;&#35823;&#26469;&#20419;&#36827;&#21307;&#23398;&#22270;&#20687;&#20998;&#26512;&#31561;&#24212;&#29992;&#30340;&#21457;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25104;&#21151;&#30340;&#26080;&#30417;&#30563;&#39046;&#22495;&#33258;&#36866;&#24212;&#65288;UDA&#65289;&#21482;&#22312;&#24378;&#20551;&#35774;&#26465;&#20214;&#19979;&#24471;&#20197;&#23454;&#29616;&#65292;&#22914;&#21327;&#21464;&#37327;&#31227;&#20301;&#21644;&#36755;&#20837;&#39046;&#22495;&#20043;&#38388;&#30340;&#37325;&#21472;&#12290;&#21518;&#32773;&#22312;&#39640;&#32500;&#24212;&#29992;&#20013;&#32463;&#24120;&#34987;&#36829;&#21453;&#65292;&#27604;&#22914;&#22270;&#20687;&#20998;&#31867;&#65292;&#22312;&#38754;&#23545;&#36825;&#31181;&#25361;&#25112;&#26102;&#65292;&#22270;&#20687;&#20998;&#31867;&#20173;&#28982;&#26159;&#31639;&#27861;&#24320;&#21457;&#30340;&#28789;&#24863;&#21644;&#22522;&#20934;&#12290;&#26412;&#25991;&#34920;&#26126;&#65292;&#33719;&#21462;&#28304;&#22495;&#21644;&#30446;&#26631;&#22495;&#26679;&#26412;&#30340;&#26377;&#20851;&#20449;&#24687;&#33021;&#22815;&#24110;&#21161;&#25918;&#23485;&#36825;&#20123;&#20551;&#35774;&#65292;&#24182;&#22312;&#23398;&#20064;&#20013;&#25552;&#39640;&#26679;&#26412;&#25928;&#29575;&#65292;&#20195;&#20215;&#26159;&#25910;&#38598;&#26356;&#20016;&#23500;&#30340;&#21464;&#37327;&#38598;&#12290;&#25105;&#20204;&#31216;&#20043;&#20026;&#21033;&#29992;&#29305;&#26435;&#20449;&#24687;&#36827;&#34892;&#39046;&#22495;&#36866;&#24212;&#65288;DALUPI&#65289;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#20004;&#38454;&#27573;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;&#22810;&#26631;&#31614;&#22270;&#20687;&#20998;&#31867;&#30340;&#23454;&#29992;&#31471;&#21040;&#31471;&#31639;&#27861;&#65292;&#21463;&#21040;&#25105;&#20204;&#20998;&#26512;&#30340;&#21551;&#21457;&#12290;&#36890;&#36807;&#19968;&#31995;&#21015;&#23454;&#39564;&#65292;&#21253;&#25324;&#21307;&#23398;&#22270;&#20687;&#20998;&#26512;&#30340;&#24212;&#29992;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#23398;&#20064;&#36807;&#31243;&#20013;&#21152;&#20837;&#29305;&#26435;&#20449;&#24687;&#21487;&#20197;&#20943;&#23569;&#38169;&#35823;&#12290;
&lt;/p&gt;
&lt;p&gt;
Successful unsupervised domain adaptation (UDA) is guaranteed only under strong assumptions such as covariate shift and overlap between input domains. The latter is often violated in high-dimensional applications such as image classification which, despite this challenge, continues to serve as inspiration and benchmark for algorithm development. In this work, we show that access to side information about examples from the source and target domains can help relax these assumptions and increase sample efficiency in learning, at the cost of collecting a richer variable set. We call this domain adaptation by learning using privileged information (DALUPI). Tailored for this task, we propose a simple two-stage learning algorithm inspired by our analysis and a practical end-to-end algorithm for multi-label image classification. In a suite of experiments, including an application to medical image analysis, we demonstrate that incorporating privileged information in learning can reduce errors i
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#35777;&#26126;&#20102;&#22312;&#23398;&#20064;&#26410;&#30693;&#32447;&#24615;&#39640;&#26031;&#31995;&#32479;&#19982;&#20108;&#27425;&#20195;&#20215;&#26102;&#65292;&#23384;&#22312;&#36951;&#25022;&#19979;&#38480;&#65292;&#24182;&#19988;&#36825;&#20010;&#19979;&#38480;&#30340;&#27604;&#20363;&#23610;&#24230;&#32423;&#21035;&#20026; $\sqrt{T}$&#12290;&#36890;&#36807;&#23545;&#25511;&#21046;&#29702;&#35770;&#21442;&#25968;&#30340;&#20934;&#30830;&#25429;&#25417;&#65292;&#25105;&#20204;&#35777;&#26126;&#38590;&#20197;&#25511;&#21046;&#30340;&#31995;&#32479;&#20063;&#38590;&#20197;&#23398;&#20064;&#25511;&#21046;&#12290;&#21516;&#26679;&#22320;&#65292;&#23545;&#20110;&#19968;&#31867;&#37096;&#20998;&#35266;&#23519;&#21040;&#30340;&#31995;&#32479;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#20102;&#20855;&#26377;&#36739;&#24046;&#21487;&#35266;&#27979;&#32467;&#26500;&#30340;&#31995;&#32479;&#20063;&#38590;&#20197;&#23398;&#20064;&#25511;&#21046;&#12290;</title><link>http://arxiv.org/abs/2201.01680</link><description>&lt;p&gt;
&#23398;&#20064;&#32447;&#24615;&#20108;&#27425;&#39640;&#26031;&#31995;&#32479;&#30340;&#36951;&#25022;&#19979;&#38480;
&lt;/p&gt;
&lt;p&gt;
Regret Lower Bounds for Learning Linear Quadratic Gaussian Systems. (arXiv:2201.01680v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.01680
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#35777;&#26126;&#20102;&#22312;&#23398;&#20064;&#26410;&#30693;&#32447;&#24615;&#39640;&#26031;&#31995;&#32479;&#19982;&#20108;&#27425;&#20195;&#20215;&#26102;&#65292;&#23384;&#22312;&#36951;&#25022;&#19979;&#38480;&#65292;&#24182;&#19988;&#36825;&#20010;&#19979;&#38480;&#30340;&#27604;&#20363;&#23610;&#24230;&#32423;&#21035;&#20026; $\sqrt{T}$&#12290;&#36890;&#36807;&#23545;&#25511;&#21046;&#29702;&#35770;&#21442;&#25968;&#30340;&#20934;&#30830;&#25429;&#25417;&#65292;&#25105;&#20204;&#35777;&#26126;&#38590;&#20197;&#25511;&#21046;&#30340;&#31995;&#32479;&#20063;&#38590;&#20197;&#23398;&#20064;&#25511;&#21046;&#12290;&#21516;&#26679;&#22320;&#65292;&#23545;&#20110;&#19968;&#31867;&#37096;&#20998;&#35266;&#23519;&#21040;&#30340;&#31995;&#32479;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#20102;&#20855;&#26377;&#36739;&#24046;&#21487;&#35266;&#27979;&#32467;&#26500;&#30340;&#31995;&#32479;&#20063;&#38590;&#20197;&#23398;&#20064;&#25511;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20026;&#33258;&#36866;&#24212;&#25511;&#21046;&#26410;&#30693;&#30340;&#32447;&#24615;&#39640;&#26031;&#31995;&#32479;&#19982;&#20108;&#27425;&#20195;&#20215;&#24314;&#31435;&#36951;&#25022;&#19979;&#38480;&#12290;&#25105;&#20204;&#32467;&#21512;&#20102;&#23454;&#39564;&#35774;&#35745;&#12289;&#20272;&#35745;&#29702;&#35770;&#21644;&#26576;&#20123;&#20449;&#24687;&#30697;&#38453;&#30340;&#25200;&#21160;&#30028;&#38480;&#30340;&#24605;&#24819;&#65292;&#24471;&#21040;&#20102;&#20851;&#20110;&#26102;&#38388;&#36328;&#24230;$T$&#30340;&#36951;&#25022;&#19979;&#38480;&#65292;&#20854;&#27604;&#20363;&#23610;&#24230;&#32423;&#21035;&#20026; $\sqrt{T}$&#12290;&#25105;&#20204;&#30340;&#19979;&#38480;&#20934;&#30830;&#22320;&#25429;&#25417;&#20102;&#25511;&#21046;&#29702;&#35770;&#21442;&#25968;&#30340;&#20316;&#29992;&#65292;&#24182;&#19988;&#25105;&#20204;&#33021;&#22815;&#34920;&#26126;&#38590;&#20197;&#25511;&#21046;&#30340;&#31995;&#32479;&#20063;&#38590;&#20197;&#23398;&#20064;&#25511;&#21046;&#65307;&#24403;&#20855;&#20307;&#21270;&#20026;&#29366;&#24577;&#21453;&#39304;&#31995;&#32479;&#26102;&#65292;&#25105;&#20204;&#24674;&#22797;&#20102;&#26089;&#26399;&#24037;&#20316;&#30340;&#32500;&#24230;&#20381;&#36182;&#20851;&#31995;&#65292;&#20294;&#25913;&#21892;&#20102;&#38543;&#31995;&#32479;&#29702;&#35770;&#24120;&#25968;&#65288;&#22914;&#31995;&#32479;&#25104;&#26412;&#21644;&#26684;&#25289;&#31859;&#24681;&#30697;&#38453;&#65289;&#30340;&#27604;&#20363;&#23610;&#24230;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#32467;&#26524;&#25193;&#23637;&#21040;&#19968;&#31867;&#37096;&#20998;&#35266;&#23519;&#21040;&#30340;&#31995;&#32479;&#65292;&#24182;&#35777;&#26126;&#20855;&#26377;&#36739;&#24046;&#21487;&#35266;&#27979;&#32467;&#26500;&#30340;&#31995;&#32479;&#20063;&#38590;&#20197;&#23398;&#20064;&#25511;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
TWe establish regret lower bounds for adaptively controlling an unknown linear Gaussian system with quadratic costs. We combine ideas from experiment design, estimation theory and a perturbation bound of certain information matrices to derive regret lower bounds exhibiting scaling on the order of magnitude $\sqrt{T}$ in the time horizon $T$. Our bounds accurately capture the role of control-theoretic parameters and we are able to show that systems that are hard to control are also hard to learn to control; when instantiated to state feedback systems we recover the dimensional dependency of earlier work but with improved scaling with system-theoretic constants such as system costs and Gramians. Furthermore, we extend our results to a class of partially observed systems and demonstrate that systems with poor observability structure also are hard to learn to control.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#23618;&#30456;&#20851;&#32858;&#31867;&#26041;&#27861;&#65292;&#21487;&#24212;&#29992;&#20110;&#27491;&#36127;&#37197;&#23545;&#19981;&#30456;&#20284;&#24230;&#65292;&#24182;&#30740;&#31350;&#20102;&#20351;&#29992;&#27492;&#26041;&#27861;&#36827;&#34892;&#26080;&#30417;&#30563;&#34920;&#24449;&#23398;&#20064;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2002.07756</link><description>&lt;p&gt;
&#20998;&#23618;&#30456;&#20851;&#32858;&#31867;&#21644;&#32500;&#25345;&#26641;&#32467;&#26500;&#23884;&#20837;
&lt;/p&gt;
&lt;p&gt;
Hierarchical Correlation Clustering and Tree Preserving Embedding. (arXiv:2002.07756v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2002.07756
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#23618;&#30456;&#20851;&#32858;&#31867;&#26041;&#27861;&#65292;&#21487;&#24212;&#29992;&#20110;&#27491;&#36127;&#37197;&#23545;&#19981;&#30456;&#20284;&#24230;&#65292;&#24182;&#30740;&#31350;&#20102;&#20351;&#29992;&#27492;&#26041;&#27861;&#36827;&#34892;&#26080;&#30417;&#30563;&#34920;&#24449;&#23398;&#20064;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#23618;&#30456;&#20851;&#32858;&#31867;&#26041;&#27861;&#65292;&#25193;&#23637;&#20102;&#33879;&#21517;&#30340;&#30456;&#20851;&#32858;&#31867;&#26041;&#27861;&#65292;&#21487;&#20197;&#20135;&#29983;&#36866;&#29992;&#20110;&#27491;&#36127;&#37197;&#23545;&#19981;&#30456;&#20284;&#24230;&#30340;&#20998;&#23618;&#32858;&#31867;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20351;&#29992;&#36825;&#31181;&#20998;&#23618;&#30456;&#20851;&#32858;&#31867;&#30340;&#26080;&#30417;&#30563;&#34920;&#24449;&#23398;&#20064;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#39318;&#20808;&#30740;&#31350;&#23558;&#30456;&#24212;&#30340;&#20998;&#23618;&#23884;&#20837;&#29992;&#20110;&#32500;&#25345;&#26641;&#32467;&#26500;&#23884;&#20837;&#21644;&#29305;&#24449;&#25552;&#21462;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#26368;&#23567;&#26368;&#22823;&#36317;&#31163;&#24230;&#37327;&#25193;&#23637;&#21040;&#30456;&#20851;&#32858;&#31867;&#30340;&#26041;&#27861;&#65292;&#20316;&#20026;&#21478;&#19968;&#31181;&#34920;&#24449;&#23398;&#20064;&#33539;&#24335;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a hierarchical correlation clustering method that extends the well-known correlation clustering to produce hierarchical clusters applicable to both positive and negative pairwise dissimilarities. Then, in the following, we study unsupervised representation learning with such hierarchical correlation clustering. For this purpose, we first investigate embedding the respective hierarchy to be used for tree-preserving embedding and feature extraction. Thereafter, we study the extension of minimax distance measures to correlation clustering, as another representation learning paradigm. Finally, we demonstrate the performance of our methods on several datasets.
&lt;/p&gt;</description></item></channel></rss>