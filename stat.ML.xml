<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35780;&#20272;&#29983;&#25104;&#27169;&#22411;&#26032;&#39062;&#24615;&#30340;&#22522;&#20110;&#26680;&#30340;&#29109;&#26032;&#39062;&#24615; (KEN) &#20998;&#25968;</title><link>https://arxiv.org/abs/2402.17287</link><description>&lt;p&gt;
&#19968;&#20010;&#21487;&#35299;&#37322;&#30340;&#29983;&#25104;&#27169;&#22411;&#29109;&#20540;&#26032;&#39062;&#24615;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
An Interpretable Evaluation of Entropy-based Novelty of Generative Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17287
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35780;&#20272;&#29983;&#25104;&#27169;&#22411;&#26032;&#39062;&#24615;&#30340;&#22522;&#20110;&#26680;&#30340;&#29109;&#26032;&#39062;&#24615; (KEN) &#20998;&#25968;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#27169;&#22411;&#26694;&#26550;&#21644;&#26550;&#26500;&#30340;&#24040;&#22823;&#21457;&#23637;&#38656;&#35201;&#26377;&#21407;&#21017;&#30340;&#26041;&#27861;&#26469;&#35780;&#20272;&#27169;&#22411;&#30456;&#23545;&#20110;&#21442;&#32771;&#25968;&#25454;&#38598;&#25110;&#22522;&#32447;&#29983;&#25104;&#27169;&#22411;&#30340;&#26032;&#39062;&#24615;&#12290; &#34429;&#28982;&#26368;&#36817;&#30340;&#25991;&#29486;&#24050;&#24191;&#27867;&#30740;&#31350;&#20102;&#29983;&#25104;&#27169;&#22411;&#30340;&#36136;&#37327;&#12289;&#22810;&#26679;&#24615;&#21644;&#27867;&#21270;&#33021;&#21147;&#30340;&#35780;&#20272;&#65292;&#20294;&#19982;&#22522;&#32447;&#27169;&#22411;&#30456;&#27604;&#30340;&#27169;&#22411;&#26032;&#39062;&#24615;&#35780;&#20272;&#22312;&#26426;&#22120;&#23398;&#20064;&#31038;&#21306;&#20013;&#23578;&#26410;&#24471;&#21040;&#20805;&#20998;&#30740;&#31350;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20851;&#27880;&#22810;&#27169;&#24577;&#29983;&#25104;&#27169;&#22411;&#19979;&#30340;&#26032;&#39062;&#24615;&#35780;&#20272;&#65292;&#24182;&#23581;&#35797;&#22238;&#31572;&#20197;&#19979;&#38382;&#39064;&#65306;&#32473;&#23450;&#29983;&#25104;&#27169;&#22411; $\mathcal{G}$ &#30340;&#26679;&#26412;&#21644;&#21442;&#32771;&#25968;&#25454;&#38598; $\mathcal{S}$&#65292;&#25105;&#20204;&#22914;&#20309;&#21457;&#29616;&#24182;&#35745;&#31639; $\mathcal{G}$ &#27604; $\mathcal{S}$ &#20013;&#26356;&#39057;&#32321;&#22320;&#34920;&#36798;&#30340;&#27169;&#24335;&#12290; &#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#35889;&#26041;&#27861;&#26469;&#25551;&#36848;&#36825;&#19968;&#20219;&#21153;&#65292;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;&#26680;&#30340;&#29109;&#26032;&#39062;&#24615; (KEN) &#20998;&#25968;&#26469;&#37327;&#21270;&#22522;&#20110;&#27169;&#24335;&#30340;&#26032;&#39062;&#24615;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17287v1 Announce Type: new  Abstract: The massive developments of generative model frameworks and architectures require principled methods for the evaluation of a model's novelty compared to a reference dataset or baseline generative models. While the recent literature has extensively studied the evaluation of the quality, diversity, and generalizability of generative models, the assessment of a model's novelty compared to a baseline model has not been adequately studied in the machine learning community. In this work, we focus on the novelty assessment under multi-modal generative models and attempt to answer the following question: Given the samples of a generative model $\mathcal{G}$ and a reference dataset $\mathcal{S}$, how can we discover and count the modes expressed by $\mathcal{G}$ more frequently than in $\mathcal{S}$. We introduce a spectral approach to the described task and propose the Kernel-based Entropic Novelty (KEN) score to quantify the mode-based novelty 
&lt;/p&gt;</description></item><item><title>HyperAgent&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#12289;&#39640;&#25928;&#12289;&#21487;&#25193;&#23637;&#30340;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#22312;&#22797;&#26434;&#29615;&#22659;&#19979;&#33021;&#22815;&#23454;&#29616;&#39640;&#25928;&#30340;&#35745;&#31639;&#21644;&#25968;&#25454;&#36873;&#25321;&#65292;&#26159;&#39318;&#20010;&#36798;&#21040;&#21487;&#35777;&#26126;&#21487;&#25193;&#23637;&#30340;&#27599;&#27493;&#35745;&#31639;&#22797;&#26434;&#24230;&#20197;&#21450;&#27425;&#32447;&#24615;&#21518;&#24724;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2402.10228</link><description>&lt;p&gt;
HyperAgent&#65306;&#19968;&#31181;&#31616;&#21333;&#12289;&#21487;&#25193;&#23637;&#12289;&#39640;&#25928;&#19988;&#21487;&#35777;&#26126;&#29992;&#20110;&#22797;&#26434;&#29615;&#22659;&#30340;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
HyperAgent: A Simple, Scalable, Efficient and Provable Reinforcement Learning Framework for Complex Environments
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10228
&lt;/p&gt;
&lt;p&gt;
HyperAgent&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#12289;&#39640;&#25928;&#12289;&#21487;&#25193;&#23637;&#30340;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#22312;&#22797;&#26434;&#29615;&#22659;&#19979;&#33021;&#22815;&#23454;&#29616;&#39640;&#25928;&#30340;&#35745;&#31639;&#21644;&#25968;&#25454;&#36873;&#25321;&#65292;&#26159;&#39318;&#20010;&#36798;&#21040;&#21487;&#35777;&#26126;&#21487;&#25193;&#23637;&#30340;&#27599;&#27493;&#35745;&#31639;&#22797;&#26434;&#24230;&#20197;&#21450;&#27425;&#32447;&#24615;&#21518;&#24724;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#22312;&#36164;&#28304;&#32422;&#26463;&#19979;&#35299;&#20915;&#22797;&#26434;&#20219;&#21153;&#65292;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#20195;&#29702;&#38656;&#35201;&#31616;&#21333;&#12289;&#39640;&#25928;&#12289;&#21487;&#25193;&#23637;&#12289;&#20855;&#26377;&#22823;&#29366;&#24577;&#31354;&#38388;&#21644;&#19981;&#26029;&#31215;&#32047;&#30340;&#20132;&#20114;&#25968;&#25454;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;HyperAgent&#65292;&#36825;&#26159;&#19968;&#20010;&#20855;&#26377;&#36229;&#27169;&#22411;&#12289;&#32034;&#24341;&#25277;&#26679;&#26041;&#26696;&#21644;&#22686;&#37327;&#26356;&#26032;&#26426;&#21046;&#30340;RL&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#19968;&#33324;&#20215;&#20540;&#20989;&#25968;&#36924;&#36817;&#20013;&#36827;&#34892;&#35745;&#31639;&#39640;&#25928;&#30340;&#39034;&#24207;&#21518;&#39564;&#36924;&#36817;&#21644;&#25968;&#25454;&#39640;&#25928;&#30340;&#21160;&#20316;&#36873;&#25321;&#65292;&#36229;&#36234;&#20102;&#20849;&#36717;&#24615;&#12290;HyperAgent&#30340;&#23454;&#29616;&#31616;&#21333;&#65292;&#21482;&#38656;&#35201;&#22312;DDQN&#20013;&#28155;&#21152;&#19968;&#20010;&#27169;&#22359;&#21644;&#19968;&#34892;&#39069;&#22806;&#20195;&#30721;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;HyperAgent&#22312;&#22823;&#35268;&#27169;&#28145;&#24230;RL&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#31283;&#20581;&#30340;&#24615;&#33021;&#65292;&#26080;&#35770;&#26159;&#22312;&#25968;&#25454;&#36824;&#26159;&#35745;&#31639;&#26041;&#38754;&#37117;&#33719;&#24471;&#20102;&#26174;&#30528;&#30340;&#25928;&#29575;&#25552;&#21319;&#12290;&#22312;&#29702;&#35770;&#19978;&#65292;&#22312;&#23454;&#38469;&#21487;&#25193;&#23637;&#30340;&#31639;&#27861;&#20013;&#65292;HyperAgent&#26159;&#31532;&#19968;&#20010;&#33021;&#22815;&#23454;&#29616;&#21487;&#35777;&#26126;&#21487;&#25193;&#23637;&#30340;&#27599;&#27493;&#35745;&#31639;&#22797;&#26434;&#24230;&#20197;&#21450;&#27425;&#32447;&#24615;&#21518;&#24724;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10228v1 Announce Type: cross  Abstract: To solve complex tasks under resource constraints, reinforcement learning (RL) agents need to be simple, efficient, and scalable with (1) large state space and (2) increasingly accumulated data of interactions. We propose the HyperAgent, a RL framework with hypermodel, index sampling schemes and incremental update mechanism, enabling computation-efficient sequential posterior approximation and data-efficient action selection under general value function approximation beyond conjugacy. The implementation of \HyperAgent is simple as it only adds one module and one line of code additional to DDQN. Practically, HyperAgent demonstrates its robust performance in large-scale deep RL benchmarks with significant efficiency gain in terms of both data and computation. Theoretically, among the practically scalable algorithms, HyperAgent is the first method to achieve provably scalable per-step computational complexity as well as sublinear regret u
&lt;/p&gt;</description></item><item><title>&#22270;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#30340;&#26410;&#26469;&#26041;&#21521;&#24212;&#35813;&#26159;&#21457;&#23637;&#19968;&#20010;&#26356;&#21152;&#22343;&#34913;&#30340;&#29702;&#35770;&#65292;&#20174;&#26356;&#23436;&#25972;&#30340;&#35282;&#24230;&#25506;&#31350;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#36798;&#33021;&#21147;&#12289;&#27867;&#21270;&#21644;&#20248;&#21270;&#20043;&#38388;&#30340;&#30456;&#20114;&#20851;&#31995;&#12290;</title><link>https://arxiv.org/abs/2402.02287</link><description>&lt;p&gt;
&#22270;&#26426;&#22120;&#23398;&#20064;&#22522;&#30784;&#30340;&#26410;&#26469;&#26041;&#21521;
&lt;/p&gt;
&lt;p&gt;
Future Directions in Foundations of Graph Machine Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02287
&lt;/p&gt;
&lt;p&gt;
&#22270;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#30340;&#26410;&#26469;&#26041;&#21521;&#24212;&#35813;&#26159;&#21457;&#23637;&#19968;&#20010;&#26356;&#21152;&#22343;&#34913;&#30340;&#29702;&#35770;&#65292;&#20174;&#26356;&#23436;&#25972;&#30340;&#35282;&#24230;&#25506;&#31350;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#36798;&#33021;&#21147;&#12289;&#27867;&#21270;&#21644;&#20248;&#21270;&#20043;&#38388;&#30340;&#30456;&#20114;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22270;&#25968;&#25454;&#22312;&#19981;&#21516;&#23398;&#31185;&#65288;&#20174;&#29983;&#21629;&#31185;&#23398;&#21040;&#31038;&#20250;&#31185;&#23398;&#21644;&#24037;&#31243;&#31185;&#23398;&#65289;&#19978;&#30340;&#24191;&#27867;&#24212;&#29992;&#65292;&#22270;&#26426;&#22120;&#23398;&#20064;&#65292;&#23588;&#20854;&#26159;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#65292;&#24341;&#36215;&#20102;&#20154;&#20204;&#27987;&#21402;&#30340;&#20852;&#36259;&#12290;&#23613;&#31649;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#25105;&#20204;&#23545;GNNs&#24615;&#36136;&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#38750;&#24120;&#19981;&#23436;&#25972;&#12290;&#26368;&#36817;&#30340;&#29702;&#35770;&#21457;&#23637;&#20027;&#35201;&#38598;&#20013;&#22312;&#38416;&#26126;GNNs&#31895;&#31890;&#24230;&#34920;&#36798;&#33021;&#21147;&#26041;&#38754;&#65292;&#20027;&#35201;&#37319;&#29992;&#32452;&#21512;&#25216;&#24039;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#30740;&#31350;&#19982;&#23454;&#36341;&#24182;&#19981;&#23436;&#20840;&#19968;&#33268;&#65292;&#29305;&#21035;&#26159;&#22312;&#20351;&#29992;&#38543;&#26426;&#19968;&#38454;&#20248;&#21270;&#25216;&#26415;&#35757;&#32451;GNNs&#26102;&#65292;&#23545;GNNs&#30340;&#27867;&#21270;&#34892;&#20026;&#30340;&#29702;&#35299;&#12290;&#22312;&#36825;&#31687;&#23450;&#20301;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#35748;&#20026;&#22270;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#38656;&#35201;&#23558;&#27880;&#24847;&#21147;&#36716;&#31227;&#21040;&#21457;&#23637;&#19968;&#20010;&#26356;&#21152;&#22343;&#34913;&#30340;&#22270;&#26426;&#22120;&#23398;&#20064;&#29702;&#35770;&#19978;&#26469;&#65292;&#37325;&#28857;&#20851;&#27880;&#34920;&#36798;&#33021;&#21147;&#12289;&#27867;&#21270;&#21644;&#20248;&#21270;&#30340;&#30456;&#20114;&#20851;&#31995;&#30340;&#26356;&#20840;&#38754;&#30340;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning on graphs, especially using graph neural networks (GNNs), has seen a surge in interest due to the wide availability of graph data across a broad spectrum of disciplines, from life to social and engineering sciences. Despite their practical success, our theoretical understanding of the properties of GNNs remains highly incomplete. Recent theoretical advancements primarily focus on elucidating the coarse-grained expressive power of GNNs, predominantly employing combinatorial techniques. However, these studies do not perfectly align with practice, particularly in understanding the generalization behavior of GNNs when trained with stochastic first-order optimization techniques. In this position paper, we argue that the graph machine learning community needs to shift its attention to developing a more balanced theory of graph machine learning, focusing on a more thorough understanding of the interplay of expressive power, generalization, and optimization.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24378;&#21270;&#23398;&#20064;&#35774;&#35745;&#25511;&#21046;&#22330;&#30340;&#26041;&#26696;&#25104;&#21151;&#29983;&#25104;&#20102;&#38750;&#32463;&#20856;&#24577;&#65292;&#20197;&#24212;&#29992;&#20110;&#33258;&#26059;&#21387;&#32553;&#24577;&#30340;&#20135;&#29983;&#12290;&#35813;&#26041;&#27861;&#22312;&#20445;&#25345;&#21387;&#32553;&#21644;&#32416;&#32544;&#30340;&#21516;&#26102;&#25552;&#20379;&#20102;&#19981;&#21516;&#30340;&#25511;&#21046;&#24207;&#21015;&#65292;&#24182;&#35266;&#23519;&#21040;&#25511;&#21046;&#33033;&#20914;&#23494;&#38598;&#24212;&#29992;&#21487;&#20197;&#25552;&#39640;&#32467;&#26524;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.16320</link><description>&lt;p&gt;
&#21033;&#29992;&#24378;&#21270;&#23398;&#20064;&#29983;&#25104;&#38750;&#32463;&#20856;&#38598;&#21512;&#33258;&#26059;&#24577;&#30340;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
Prepare Non-classical Collective Spin State by Reinforcement Learning. (arXiv:2401.16320v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16320
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24378;&#21270;&#23398;&#20064;&#35774;&#35745;&#25511;&#21046;&#22330;&#30340;&#26041;&#26696;&#25104;&#21151;&#29983;&#25104;&#20102;&#38750;&#32463;&#20856;&#24577;&#65292;&#20197;&#24212;&#29992;&#20110;&#33258;&#26059;&#21387;&#32553;&#24577;&#30340;&#20135;&#29983;&#12290;&#35813;&#26041;&#27861;&#22312;&#20445;&#25345;&#21387;&#32553;&#21644;&#32416;&#32544;&#30340;&#21516;&#26102;&#25552;&#20379;&#20102;&#19981;&#21516;&#30340;&#25511;&#21046;&#24207;&#21015;&#65292;&#24182;&#35266;&#23519;&#21040;&#25511;&#21046;&#33033;&#20914;&#23494;&#38598;&#24212;&#29992;&#21487;&#20197;&#25552;&#39640;&#32467;&#26524;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#24378;&#21270;&#23398;&#20064;&#26469;&#35774;&#35745;&#25511;&#21046;&#22330;&#30340;&#26041;&#26696;&#65292;&#29992;&#20110;&#29983;&#25104;&#38750;&#32463;&#20856;&#24577;&#12290;&#35813;&#26041;&#26696;&#20197;&#24212;&#29992;&#20110;&#24320;&#25918;&#38598;&#20307;&#33258;&#26059;&#27169;&#22411;&#20013;&#30340;&#33258;&#26059;&#21387;&#32553;&#24577;&#20026;&#20363;&#65292;&#20854;&#20013;&#35774;&#35745;&#20102;&#19968;&#20010;&#32447;&#24615;&#25511;&#21046;&#39033;&#26469;&#25511;&#21046;&#21160;&#21147;&#23398;&#12290;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#26681;&#25454;&#20197;&#32791;&#25955;&#21644;&#21435;&#30456;&#24178;&#20026;&#29305;&#24449;&#30340;&#29615;&#22659;&#20013;&#30340;&#30456;&#24178;&#33258;&#26059;&#24577;&#24320;&#22987;&#65292;&#30830;&#23450;&#20102;&#25511;&#21046;&#33033;&#20914;&#30340;&#26102;&#38388;&#24207;&#21015;&#12290;&#19982;&#24658;&#23450;&#25511;&#21046;&#26041;&#26696;&#30456;&#27604;&#65292;&#36825;&#31181;&#26041;&#27861;&#25552;&#20379;&#20102;&#22810;&#31181;&#25511;&#21046;&#24207;&#21015;&#65292;&#20445;&#25345;&#20102;&#38598;&#20307;&#33258;&#26059;&#21387;&#32553;&#21644;&#32416;&#32544;&#12290;&#35266;&#23519;&#21040;&#25511;&#21046;&#33033;&#20914;&#30340;&#23494;&#38598;&#24212;&#29992;&#21487;&#20197;&#22686;&#24378;&#32467;&#26524;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#28155;&#21152;&#25511;&#21046;&#25805;&#20316;&#65292;&#24615;&#33021;&#24471;&#21040;&#20102;&#36731;&#24494;&#22686;&#24378;&#12290;&#25152;&#25552;&#20986;&#30340;&#31574;&#30053;&#22312;&#36739;&#22823;&#31995;&#32479;&#20013;&#23637;&#29616;&#20102;&#26356;&#39640;&#30340;&#25928;&#26524;&#12290;&#23545;&#20648;&#22791;&#28909;&#28608;&#21457;&#23545;&#25511;&#21046;&#32467;&#26524;&#26377;&#19981;&#21033;&#24433;&#21709;&#12290;&#24212;&#35813;&#30830;&#35748;&#36825;&#19968;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a scheme leveraging reinforcement learning to engineer control fields for generating non-classical states. It is exemplified by the application to prepare spin squeezed state for an open collective spin model where a linear control term is designed to govern the dynamics. The reinforcement learning agent determines the temporal sequence of control pulses, commencing from coherent spin state in an environment characterized by dissipation and dephasing. When compared to constant control scenarios, this approach provides various control sequences maintaining collective spin squeezing and entanglement. It is observed that denser application of the control pulses enhances the performance of the outcomes. Furthermore, there is a minor enhancement in the performance by adding control actions. The proposed strategy demonstrates increased effectiveness for larger systems. And thermal excitations of the reservoir are detrimental to the control outcomes. It should be confirmed that thi
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;AdamQLR&#65292;&#23427;&#26159;&#19968;&#20010;&#36890;&#36807;&#23558;K-FAC&#20013;&#30340;&#25216;&#26415;&#19982;Adam&#30340;&#26356;&#26032;&#26041;&#27861;&#30456;&#32467;&#21512;&#30340;&#20248;&#21270;&#22120;&#65292;&#36890;&#36807;&#32771;&#34385;&#20108;&#38454;&#25968;&#25454;&#19978;&#30340;Adam&#34892;&#20026;&#32780;&#24471;&#21040;&#21551;&#21457;&#12290;&#22312;&#22238;&#24402;&#21644;&#20998;&#31867;&#20219;&#21153;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#32467;&#26524;&#26174;&#31034;AdamQLR&#22312;&#36816;&#34892;&#26102;&#38388;&#21644;&#25512;&#24191;&#24615;&#33021;&#26041;&#38754;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#31454;&#20105;&#21147;&#12290;</title><link>http://arxiv.org/abs/2310.14963</link><description>&lt;p&gt;
&#36890;&#36807;&#20108;&#38454;&#36879;&#38236;&#30475;Adam
&lt;/p&gt;
&lt;p&gt;
Adam through a Second-Order Lens. (arXiv:2310.14963v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14963
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;AdamQLR&#65292;&#23427;&#26159;&#19968;&#20010;&#36890;&#36807;&#23558;K-FAC&#20013;&#30340;&#25216;&#26415;&#19982;Adam&#30340;&#26356;&#26032;&#26041;&#27861;&#30456;&#32467;&#21512;&#30340;&#20248;&#21270;&#22120;&#65292;&#36890;&#36807;&#32771;&#34385;&#20108;&#38454;&#25968;&#25454;&#19978;&#30340;Adam&#34892;&#20026;&#32780;&#24471;&#21040;&#21551;&#21457;&#12290;&#22312;&#22238;&#24402;&#21644;&#20998;&#31867;&#20219;&#21153;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#32467;&#26524;&#26174;&#31034;AdamQLR&#22312;&#36816;&#34892;&#26102;&#38388;&#21644;&#25512;&#24191;&#24615;&#33021;&#26041;&#38754;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#31454;&#20105;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#20248;&#21270;&#30740;&#31350;&#23384;&#22312;&#19968;&#31181;&#32039;&#24352;&#29366;&#24577;&#65292;&#21363;&#31532;&#19968;&#38454;&#26799;&#24230;&#27861;&#65288;&#22914;SGD&#21644;Adam&#65289;&#30340;&#35745;&#31639;&#25928;&#29575;&#19982;&#31532;&#20108;&#38454;&#26354;&#29575;&#27861;&#65288;&#22914;&#25311;&#29275;&#39039;&#26041;&#27861;&#21644;K-FAC&#65289;&#30340;&#29702;&#35770;&#25928;&#29575;&#20043;&#38388;&#30340;&#32039;&#24352;&#20851;&#31995;&#12290;&#25105;&#20204;&#35797;&#22270;&#23558;&#36825;&#20004;&#31181;&#26041;&#27861;&#30340;&#20248;&#28857;&#32467;&#21512;&#21040;&#19968;&#20010;&#35745;&#31639;&#19978;&#39640;&#25928;&#30340;&#31639;&#27861;&#20013;&#12290;&#27880;&#24847;&#21040;&#20108;&#38454;&#26041;&#27861;&#36890;&#24120;&#20381;&#36182;&#20110;&#31283;&#23450;&#30340;&#21551;&#21457;&#24335;&#26041;&#27861;&#65288;&#22914;Levenberg-Marquardt&#38459;&#23612;&#65289;&#65292;&#25105;&#20204;&#25552;&#20986;AdamQLR&#65306;&#19968;&#20010;&#23558;K-FAC&#20013;&#30340;&#38459;&#23612;&#21644;&#23398;&#20064;&#29575;&#36873;&#25321;&#25216;&#26415;&#19982;Adam&#25552;&#20986;&#30340;&#26356;&#26032;&#26041;&#21521;&#30456;&#32467;&#21512;&#30340;&#20248;&#21270;&#22120;&#65292;&#36890;&#36807;&#32771;&#34385;Adam&#22312;&#20108;&#38454;&#25968;&#25454;&#19978;&#30340;&#34920;&#29616;&#32780;&#24471;&#21040;&#21551;&#21457;&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#35268;&#27169;&#30340;&#22238;&#24402;&#21644;&#20998;&#31867;&#20219;&#21153;&#19978;&#35780;&#20272;&#20102;AdamQLR&#65292;&#22312;&#36816;&#34892;&#26102;&#38388;&#19982;&#31454;&#20105;&#24615;&#25512;&#24191;&#24615;&#33021;&#20043;&#38388;&#21462;&#24471;&#20102;&#31454;&#20105;&#24615;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Research into optimisation for deep learning is characterised by a tension between the computational efficiency of first-order, gradient-based methods (such as SGD and Adam) and the theoretical efficiency of second-order, curvature-based methods (such as quasi-Newton methods and K-FAC). We seek to combine the benefits of both approaches into a single computationally-efficient algorithm. Noting that second-order methods often depend on stabilising heuristics (such as Levenberg-Marquardt damping), we propose AdamQLR: an optimiser combining damping and learning rate selection techniques from K-FAC (Martens and Grosse, 2015) with the update directions proposed by Adam, inspired by considering Adam through a second-order lens. We evaluate AdamQLR on a range of regression and classification tasks at various scales, achieving competitive generalisation performance vs runtime.
&lt;/p&gt;</description></item><item><title>SmoothLLM&#26159;&#31532;&#19968;&#20010;&#29992;&#20110;&#20943;&#36731;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19978;&#36234;&#29425;&#25915;&#20987;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#36755;&#20837;&#25552;&#31034;&#19978;&#38543;&#26426;&#25200;&#21160;&#24182;&#27719;&#24635;&#39044;&#27979;&#32467;&#26524;&#26469;&#26816;&#27979;&#23545;&#25239;&#24615;&#36755;&#20837;&#65292;&#23558;&#25915;&#20987;&#25104;&#21151;&#29575;&#38477;&#20302;&#33267;&#19981;&#21040;&#19968;&#20010;&#30334;&#20998;&#28857;&#65292;&#24182;&#25552;&#20379;&#20102;&#21487;&#35777;&#26126;&#30340;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2310.03684</link><description>&lt;p&gt;
SmoothLLM&#65306;&#38450;&#24481;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20813;&#21463;&#36234;&#29425;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks. (arXiv:2310.03684v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03684
&lt;/p&gt;
&lt;p&gt;
SmoothLLM&#26159;&#31532;&#19968;&#20010;&#29992;&#20110;&#20943;&#36731;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19978;&#36234;&#29425;&#25915;&#20987;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#36755;&#20837;&#25552;&#31034;&#19978;&#38543;&#26426;&#25200;&#21160;&#24182;&#27719;&#24635;&#39044;&#27979;&#32467;&#26524;&#26469;&#26816;&#27979;&#23545;&#25239;&#24615;&#36755;&#20837;&#65292;&#23558;&#25915;&#20987;&#25104;&#21151;&#29575;&#38477;&#20302;&#33267;&#19981;&#21040;&#19968;&#20010;&#30334;&#20998;&#28857;&#65292;&#24182;&#25552;&#20379;&#20102;&#21487;&#35777;&#26126;&#30340;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#21162;&#21147;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#19982;&#20154;&#31867;&#20215;&#20540;&#35266;&#20445;&#25345;&#19968;&#33268;&#65292;&#20294;&#24191;&#27867;&#20351;&#29992;&#30340;LLM&#65288;&#22914;GPT&#12289;Llama&#12289;Claude&#21644;PaLM&#65289;&#20173;&#28982;&#23481;&#26131;&#21463;&#21040;&#36234;&#29425;&#25915;&#20987;&#65292;&#21363;&#23545;&#30446;&#26631;LLM&#36827;&#34892;&#27450;&#39575;&#65292;&#20197;&#29983;&#25104;&#19981;&#21512;&#36866;&#30340;&#20869;&#23481;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#28431;&#27934;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;SmoothLLM&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#26088;&#22312;&#20943;&#36731;LLM&#19978;&#30340;&#36234;&#29425;&#25915;&#20987;&#30340;&#31639;&#27861;&#12290;&#22522;&#20110;&#25105;&#20204;&#30340;&#21457;&#29616;&#65292;&#23545;&#25239;&#24615;&#29983;&#25104;&#30340;&#25552;&#31034;&#23545;&#23383;&#31526;&#32423;&#21035;&#30340;&#25913;&#21464;&#24456;&#33030;&#24369;&#65292;&#25105;&#20204;&#30340;&#38450;&#24481;&#39318;&#20808;&#38543;&#26426;&#25200;&#21160;&#32473;&#23450;&#36755;&#20837;&#25552;&#31034;&#30340;&#22810;&#20010;&#21103;&#26412;&#65292;&#28982;&#21518;&#27719;&#24635;&#30456;&#24212;&#30340;&#39044;&#27979;&#32467;&#26524;&#26469;&#26816;&#27979;&#23545;&#25239;&#24615;&#36755;&#20837;&#12290;SmoothLLM&#23558;&#20247;&#22810;&#28909;&#38376;LLM&#30340;&#25915;&#20987;&#25104;&#21151;&#29575;&#38477;&#20302;&#33267;&#19981;&#21040;&#19968;&#20010;&#30334;&#20998;&#28857;&#65292;&#36991;&#20813;&#20102;&#19981;&#24517;&#35201;&#30340;&#20445;&#23432;&#24615;&#65292;&#24182;&#23545;&#25915;&#20987;&#32531;&#35299;&#25552;&#20379;&#20102;&#21487;&#35777;&#26126;&#30340;&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#38450;&#24481;&#20351;&#29992;&#30340;&#26597;&#35810;&#25968;&#37327;&#27604;&#29616;&#26377;&#30340;&#25915;&#20987;&#26041;&#27861;&#23569;&#24471;&#22810;&#65292;&#24182;&#19988;&#19982;&#20219;&#20309;LLM&#20860;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite efforts to align large language models (LLMs) with human values, widely-used LLMs such as GPT, Llama, Claude, and PaLM are susceptible to jailbreaking attacks, wherein an adversary fools a targeted LLM into generating objectionable content. To address this vulnerability, we propose SmoothLLM, the first algorithm designed to mitigate jailbreaking attacks on LLMs. Based on our finding that adversarially-generated prompts are brittle to character-level changes, our defense first randomly perturbs multiple copies of a given input prompt, and then aggregates the corresponding predictions to detect adversarial inputs. SmoothLLM reduces the attack success rate on numerous popular LLMs to below one percentage point, avoids unnecessary conservatism, and admits provable guarantees on attack mitigation. Moreover, our defense uses exponentially fewer queries than existing attacks and is compatible with any LLM.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#38750;&#35268;&#21017;&#31354;&#38388;&#25968;&#25454;&#30340;&#21442;&#25968;&#20272;&#35745;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#25193;&#23637;&#20102;&#31070;&#32463;&#36125;&#21494;&#26031;&#20272;&#35745;&#22120;&#30340;&#24212;&#29992;&#33539;&#22260;&#65292;&#24182;&#24102;&#26469;&#20102;&#26174;&#33879;&#30340;&#35745;&#31639;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2310.02600</link><description>&lt;p&gt;
&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#38750;&#35268;&#21017;&#31354;&#38388;&#25968;&#25454;&#30340;&#31070;&#32463;&#36125;&#21494;&#26031;&#20272;&#35745;&#22120;
&lt;/p&gt;
&lt;p&gt;
Neural Bayes Estimators for Irregular Spatial Data using Graph Neural Networks. (arXiv:2310.02600v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02600
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#38750;&#35268;&#21017;&#31354;&#38388;&#25968;&#25454;&#30340;&#21442;&#25968;&#20272;&#35745;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#25193;&#23637;&#20102;&#31070;&#32463;&#36125;&#21494;&#26031;&#20272;&#35745;&#22120;&#30340;&#24212;&#29992;&#33539;&#22260;&#65292;&#24182;&#24102;&#26469;&#20102;&#26174;&#33879;&#30340;&#35745;&#31639;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#36125;&#21494;&#26031;&#20272;&#35745;&#22120;&#26159;&#19968;&#31181;&#20197;&#24555;&#36895;&#21644;&#20813;&#20284;&#28982;&#26041;&#24335;&#36924;&#36817;&#36125;&#21494;&#26031;&#20272;&#35745;&#22120;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#23427;&#20204;&#22312;&#31354;&#38388;&#27169;&#22411;&#21644;&#25968;&#25454;&#20013;&#30340;&#20351;&#29992;&#38750;&#24120;&#21560;&#24341;&#20154;&#65292;&#22240;&#20026;&#20272;&#35745;&#32463;&#24120;&#26159;&#35745;&#31639;&#19978;&#30340;&#29942;&#39048;&#12290;&#28982;&#32780;&#65292;&#21040;&#30446;&#21069;&#20026;&#27490;&#65292;&#31354;&#38388;&#24212;&#29992;&#20013;&#30340;&#31070;&#32463;&#36125;&#21494;&#26031;&#20272;&#35745;&#22120;&#20165;&#38480;&#20110;&#22312;&#35268;&#21017;&#30340;&#32593;&#26684;&#19978;&#25910;&#38598;&#30340;&#25968;&#25454;&#12290;&#36825;&#20123;&#20272;&#35745;&#22120;&#30446;&#21069;&#36824;&#20381;&#36182;&#20110;&#39044;&#20808;&#35268;&#23450;&#30340;&#31354;&#38388;&#20301;&#32622;&#65292;&#36825;&#24847;&#21619;&#30528;&#31070;&#32463;&#32593;&#32476;&#38656;&#35201;&#37325;&#26032;&#35757;&#32451;&#20197;&#36866;&#24212;&#26032;&#30340;&#25968;&#25454;&#38598;&#65307;&#36825;&#20351;&#23427;&#20204;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#21464;&#24471;&#19981;&#23454;&#29992;&#65292;&#24182;&#38459;&#30861;&#20102;&#23427;&#20204;&#30340;&#24191;&#27867;&#24212;&#29992;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#37319;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#26469;&#35299;&#20915;&#20174;&#20219;&#24847;&#31354;&#38388;&#20301;&#32622;&#25910;&#38598;&#30340;&#25968;&#25454;&#36827;&#34892;&#21442;&#25968;&#20272;&#35745;&#30340;&#37325;&#35201;&#38382;&#39064;&#12290;&#38500;&#20102;&#23558;&#31070;&#32463;&#36125;&#21494;&#26031;&#20272;&#35745;&#25193;&#23637;&#21040;&#38750;&#35268;&#21017;&#31354;&#38388;&#25968;&#25454;&#20043;&#22806;&#65292;&#25105;&#20204;&#30340;&#26550;&#26500;&#36824;&#24102;&#26469;&#20102;&#26174;&#30528;&#30340;&#35745;&#31639;&#20248;&#21183;&#65292;&#22240;&#20026;&#35813;&#20272;&#35745;&#22120;&#21487;&#20197;&#29992;&#20110;&#20219;&#20309;&#25490;&#21015;&#25110;&#25968;&#37327;&#30340;&#20301;&#32622;&#21644;&#29420;&#31435;&#30340;&#37325;&#22797;&#23454;&#39564;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural Bayes estimators are neural networks that approximate Bayes estimators in a fast and likelihood-free manner. They are appealing to use with spatial models and data, where estimation is often a computational bottleneck. However, neural Bayes estimators in spatial applications have, to date, been restricted to data collected over a regular grid. These estimators are also currently dependent on a prescribed set of spatial locations, which means that the neural network needs to be re-trained for new data sets; this renders them impractical in many applications and impedes their widespread adoption. In this work, we employ graph neural networks to tackle the important problem of parameter estimation from data collected over arbitrary spatial locations. In addition to extending neural Bayes estimation to irregular spatial data, our architecture leads to substantial computational benefits, since the estimator can be used with any arrangement or number of locations and independent repli
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#8220;&#21021;&#22987;&#29468;&#27979;&#20559;&#24046;&#8221;&#29616;&#35937;&#65292;&#21363;&#22312;&#26410;&#32463;&#36807;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#30001;&#20110;&#26550;&#26500;&#36873;&#25321;&#30340;&#24433;&#21709;&#65292;&#27169;&#22411;&#24448;&#24448;&#20250;&#23558;&#25152;&#26377;&#39044;&#27979;&#25351;&#21521;&#21516;&#19968;&#20010;&#31867;&#21035;&#12290;&#35813;&#29616;&#35937;&#23545;&#26550;&#26500;&#36873;&#25321;&#21644;&#21021;&#22987;&#21270;&#26377;&#23454;&#38469;&#25351;&#23548;&#24847;&#20041;&#65292;&#24182;&#20855;&#26377;&#29702;&#35770;&#21518;&#26524;&#65292;&#20363;&#22914;&#33410;&#28857;&#32622;&#25442;&#23545;&#31216;&#24615;&#30340;&#23849;&#28291;&#21644;&#28145;&#24230;&#24102;&#26469;&#30340;&#38750;&#24179;&#20961;&#24046;&#24322;&#12290;</title><link>http://arxiv.org/abs/2306.00809</link><description>&lt;p&gt;
&#21021;&#22987;&#29468;&#27979;&#20559;&#24046;&#65306;&#26410;&#32463;&#36807;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#20542;&#21521;&#20110;&#26576;&#20123;&#31867;&#21035;
&lt;/p&gt;
&lt;p&gt;
Initial Guessing Bias: How Untrained Networks Favor Some Classes. (arXiv:2306.00809v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00809
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#8220;&#21021;&#22987;&#29468;&#27979;&#20559;&#24046;&#8221;&#29616;&#35937;&#65292;&#21363;&#22312;&#26410;&#32463;&#36807;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#30001;&#20110;&#26550;&#26500;&#36873;&#25321;&#30340;&#24433;&#21709;&#65292;&#27169;&#22411;&#24448;&#24448;&#20250;&#23558;&#25152;&#26377;&#39044;&#27979;&#25351;&#21521;&#21516;&#19968;&#20010;&#31867;&#21035;&#12290;&#35813;&#29616;&#35937;&#23545;&#26550;&#26500;&#36873;&#25321;&#21644;&#21021;&#22987;&#21270;&#26377;&#23454;&#38469;&#25351;&#23548;&#24847;&#20041;&#65292;&#24182;&#20855;&#26377;&#29702;&#35770;&#21518;&#26524;&#65292;&#20363;&#22914;&#33410;&#28857;&#32622;&#25442;&#23545;&#31216;&#24615;&#30340;&#23849;&#28291;&#21644;&#28145;&#24230;&#24102;&#26469;&#30340;&#38750;&#24179;&#20961;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#30340;&#21021;&#22987;&#29366;&#24577;&#22312;&#35843;&#33410;&#21518;&#32493;&#30340;&#35757;&#32451;&#36807;&#31243;&#20013;&#25198;&#28436;&#37325;&#35201;&#35282;&#33394;&#12290;&#22312;&#20998;&#31867;&#38382;&#39064;&#30340;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#35777;&#26126;&#31070;&#32463;&#32593;&#32476;&#30340;&#32467;&#26500;&#21487;&#20197;&#22312;&#35757;&#32451;&#20043;&#21069;&#65292;&#29978;&#33267;&#22312;&#19981;&#23384;&#22312;&#26174;&#24335;&#20559;&#24046;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#27169;&#22411;&#23558;&#25152;&#26377;&#39044;&#27979;&#37117;&#25351;&#21521;&#21516;&#19968;&#20010;&#31867;&#21035;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#29616;&#35937;&#30340;&#23384;&#22312;&#65292;&#31216;&#20026;&#8220;&#21021;&#22987;&#29468;&#27979;&#20559;&#24046;&#8221;&#65288;Initial Guessing Bias&#65292;IGB&#65289;&#65292;&#36825;&#21462;&#20915;&#20110;&#26550;&#26500;&#36873;&#25321;&#65292;&#20363;&#22914;&#28608;&#27963;&#20989;&#25968;&#12289;&#26368;&#22823;&#27744;&#21270;&#23618;&#21644;&#32593;&#32476;&#28145;&#24230;&#12290;&#25105;&#20204;&#23545;IGB&#36827;&#34892;&#30340;&#20998;&#26512;&#20855;&#26377;&#23454;&#38469;&#24847;&#20041;&#65292;&#21487;&#20197;&#25351;&#23548;&#26550;&#26500;&#30340;&#36873;&#25321;&#21644;&#21021;&#22987;&#21270;&#12290;&#25105;&#20204;&#36824;&#24378;&#35843;&#29702;&#35770;&#21518;&#26524;&#65292;&#20363;&#22914;&#33410;&#28857;&#32622;&#25442;&#23545;&#31216;&#24615;&#30340;&#23849;&#28291;&#12289;&#33258;&#24179;&#22343;&#30340;&#30772;&#22351;&#12289;&#26576;&#20123;&#22343;&#22330;&#36817;&#20284;&#30340;&#26377;&#25928;&#24615;&#20197;&#21450;&#28145;&#24230;&#24102;&#26469;&#30340;&#38750;&#24179;&#20961;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
The initial state of neural networks plays a central role in conditioning the subsequent training dynamics. In the context of classification problems, we provide a theoretical analysis demonstrating that the structure of a neural network can condition the model to assign all predictions to the same class, even before the beginning of training, and in the absence of explicit biases. We show that the presence of this phenomenon, which we call "Initial Guessing Bias" (IGB), depends on architectural choices such as activation functions, max-pooling layers, and network depth. Our analysis of IGB has practical consequences, in that it guides architecture selection and initialization. We also highlight theoretical consequences, such as the breakdown of node-permutation symmetry, the violation of self-averaging, the validity of some mean-field approximations, and the non-trivial differences arising with depth.
&lt;/p&gt;</description></item></channel></rss>