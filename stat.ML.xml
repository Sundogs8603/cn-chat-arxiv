<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#25968;&#25454;&#20381;&#36182;&#32806;&#21512;&#26469;&#26500;&#24314;&#29983;&#25104;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#36229;&#20998;&#36776;&#29575;&#21644;&#20462;&#22797;&#20219;&#21153;&#20013;&#30340;&#23454;&#39564;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.03725</link><description>&lt;p&gt;
&#20855;&#26377;&#25968;&#25454;&#20381;&#36182;&#32806;&#21512;&#30340;&#38543;&#26426;&#25554;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic interpolants with data-dependent couplings. (arXiv:2310.03725v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03725
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#25968;&#25454;&#20381;&#36182;&#32806;&#21512;&#26469;&#26500;&#24314;&#29983;&#25104;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#36229;&#20998;&#36776;&#29575;&#21644;&#20462;&#22797;&#20219;&#21153;&#20013;&#30340;&#23454;&#39564;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#21160;&#24577;&#27979;&#24230;&#20256;&#36755;&#21551;&#21457;&#30340;&#29983;&#25104;&#27169;&#22411;&#65288;&#22914;&#27969;&#21644;&#25193;&#25955;&#65289;&#26500;&#24314;&#20102;&#20004;&#20010;&#27010;&#29575;&#23494;&#24230;&#20043;&#38388;&#30340;&#36830;&#32493;&#26102;&#38388;&#26144;&#23556;&#12290;&#25353;&#29031;&#20256;&#32479;&#26041;&#27861;&#65292;&#20854;&#20013;&#19968;&#20010;&#26159;&#30446;&#26631;&#23494;&#24230;&#65292;&#21482;&#33021;&#36890;&#36807;&#26679;&#26412;&#35775;&#38382;&#65292;&#32780;&#21478;&#19968;&#20010;&#26159;&#31616;&#21333;&#30340;&#22522;&#30784;&#23494;&#24230;&#65292;&#19982;&#25968;&#25454;&#26080;&#20851;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#38543;&#26426;&#25554;&#20540;&#30340;&#26694;&#26550;&#65292;&#35268;&#33539;&#21270;&#20102;&#22914;&#20309;&#8220;&#32806;&#21512;&#8221;&#22522;&#26412;&#23494;&#24230;&#21644;&#30446;&#26631;&#23494;&#24230;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#23558;&#31867;&#21035;&#26631;&#31614;&#25110;&#36830;&#32493;&#23884;&#20837;&#30340;&#20449;&#24687;&#32435;&#20837;&#21040;&#26500;&#24314;&#21160;&#24577;&#20256;&#36755;&#26144;&#23556;&#30340;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#20013;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#36807;&#35299;&#20915;&#31867;&#20284;&#20110;&#26631;&#20934;&#29420;&#31435;&#35774;&#32622;&#30340;&#31616;&#21333;&#24179;&#26041;&#25439;&#22833;&#22238;&#24402;&#38382;&#39064;&#26469;&#23398;&#20064;&#36825;&#20123;&#20256;&#36755;&#26144;&#23556;&#12290;&#36890;&#36807;&#36229;&#20998;&#36776;&#29575;&#21644;&#20462;&#22797;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#26500;&#24314;&#20381;&#36182;&#32806;&#21512;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative models inspired by dynamical transport of measure -- such as flows and diffusions -- construct a continuous-time map between two probability densities. Conventionally, one of these is the target density, only accessible through samples, while the other is taken as a simple base density that is data-agnostic. In this work, using the framework of stochastic interpolants, we formalize how to \textit{couple} the base and the target densities. This enables us to incorporate information about class labels or continuous embeddings to construct dynamical transport maps that serve as conditional generative models. We show that these transport maps can be learned by solving a simple square loss regression problem analogous to the standard independent setting. We demonstrate the usefulness of constructing dependent couplings in practice through experiments in super-resolution and in-painting.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#8220;e-process&#8221;&#21644;&#32622;&#20449;&#24207;&#21015;&#26041;&#27861;&#65292;&#20998;&#21035;&#36890;&#36807;&#26367;&#25442;Lai&#30340;&#28151;&#21512;&#26041;&#27861;&#65292;&#24182;&#20998;&#26512;&#20102;&#25152;&#24471;&#32467;&#26524;&#30340;&#23485;&#24230;&#12290;</title><link>http://arxiv.org/abs/2310.03722</link><description>&lt;p&gt;
&#26410;&#30693;&#26041;&#24046;&#19979;&#30340;&#39640;&#26031;&#22343;&#20540;&#30340;&#20219;&#24847;&#26377;&#25928;T&#26816;&#39564;&#21644;&#32622;&#20449;&#24207;&#21015;
&lt;/p&gt;
&lt;p&gt;
Anytime-valid t-tests and confidence sequences for Gaussian means with unknown variance. (arXiv:2310.03722v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03722
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#8220;e-process&#8221;&#21644;&#32622;&#20449;&#24207;&#21015;&#26041;&#27861;&#65292;&#20998;&#21035;&#36890;&#36807;&#26367;&#25442;Lai&#30340;&#28151;&#21512;&#26041;&#27861;&#65292;&#24182;&#20998;&#26512;&#20102;&#25152;&#24471;&#32467;&#26524;&#30340;&#23485;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;1976&#24180;&#65292;Lai&#26500;&#36896;&#20102;&#19968;&#20010;&#38750;&#24179;&#20961;&#30340;&#22343;&#20540;$\mu$&#30340;&#39640;&#26031;&#20998;&#24067;&#30340;&#32622;&#20449;&#24207;&#21015;&#65292;&#35813;&#20998;&#24067;&#30340;&#26041;&#24046;$\sigma$&#26159;&#26410;&#30693;&#30340;&#12290;&#20182;&#20351;&#29992;&#20102;&#20851;&#20110;$\sigma$&#30340;&#19981;&#36866;&#24403;&#65288;&#21491;Haar&#65289;&#28151;&#21512;&#21644;&#20851;&#20110;$\mu$&#30340;&#19981;&#36866;&#24403;&#65288;&#24179;&#22374;&#65289;&#28151;&#21512;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35814;&#32454;&#35828;&#26126;&#20102;&#20182;&#26500;&#24314;&#30340;&#32454;&#33410;&#65292;&#20854;&#20013;&#20351;&#29992;&#20102;&#24191;&#20041;&#30340;&#19981;&#21487;&#31215;&#20998;&#38789;&#21644;&#25193;&#23637;&#30340;&#32500;&#23572;&#19981;&#31561;&#24335;&#12290;&#23613;&#31649;&#36825;&#30830;&#23454;&#20135;&#29983;&#20102;&#19968;&#20010;&#39034;&#24207;T&#26816;&#39564;&#65292;&#20294;&#30001;&#20110;&#20182;&#30340;&#38789;&#19981;&#21487;&#31215;&#20998;&#65292;&#23427;&#24182;&#27809;&#26377;&#20135;&#29983;&#19968;&#20010;&#8220;e-process&#8221;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20026;&#30456;&#21516;&#30340;&#35774;&#32622;&#24320;&#21457;&#20102;&#20004;&#20010;&#26032;&#30340;&#8220;e-process&#8221;&#21644;&#32622;&#20449;&#24207;&#21015;&#65306;&#19968;&#20010;&#26159;&#22312;&#32553;&#20943;&#28388;&#27874;&#22120;&#20013;&#30340;&#27979;&#35797;&#38789;&#65292;&#21478;&#19968;&#20010;&#26159;&#22312;&#35268;&#33539;&#25968;&#25454;&#28388;&#27874;&#22120;&#20013;&#30340;&#8220;e-process&#8221;&#12290;&#36825;&#20123;&#20998;&#21035;&#26159;&#36890;&#36807;&#23558;Lai&#30340;&#24179;&#22374;&#28151;&#21512;&#26367;&#25442;&#20026;&#39640;&#26031;&#28151;&#21512;&#65292;&#24182;&#23558;&#23545;$\sigma$&#30340;&#21491;Haar&#28151;&#21512;&#26367;&#25442;&#20026;&#22312;&#38646;&#31354;&#38388;&#19979;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65292;&#23601;&#20687;&#22312;&#36890;&#29992;&#25512;&#26029;&#20013;&#19968;&#26679;&#12290;&#25105;&#20204;&#36824;&#20998;&#26512;&#20102;&#25152;&#24471;&#32467;&#26524;&#30340;&#23485;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
In 1976, Lai constructed a nontrivial confidence sequence for the mean $\mu$ of a Gaussian distribution with unknown variance $\sigma$. Curiously, he employed both an improper (right Haar) mixture over $\sigma$ and an improper (flat) mixture over $\mu$. Here, we elaborate carefully on the details of his construction, which use generalized nonintegrable martingales and an extended Ville's inequality. While this does yield a sequential t-test, it does not yield an ``e-process'' (due to the nonintegrability of his martingale). In this paper, we develop two new e-processes and confidence sequences for the same setting: one is a test martingale in a reduced filtration, while the other is an e-process in the canonical data filtration. These are respectively obtained by swapping Lai's flat mixture for a Gaussian mixture, and swapping the right Haar mixture over $\sigma$ with the maximum likelihood estimate under the null, as done in universal inference. We also analyze the width of resulting 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#22810;&#21464;&#37327;&#38750;&#32447;&#24615;&#28608;&#27963;&#20989;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#22312;Banach&#31354;&#38388;&#30340;&#20248;&#21270;&#24615;&#65292;&#24182;&#26500;&#24314;&#20102;&#19968;&#31867;&#26032;&#30340;Banach&#31354;&#38388;&#23478;&#26063;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#23398;&#20064;&#38382;&#39064;&#30340;&#35299;&#38598;&#23436;&#20840;&#30001;&#20855;&#26377;&#22810;&#21464;&#37327;&#38750;&#32447;&#24615;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#26469;&#25551;&#36848;&#12290;&#36825;&#20123;&#26368;&#20248;&#26550;&#26500;&#20855;&#26377;&#36339;&#36291;&#36830;&#25509;&#65292;&#24182;&#19982;&#27491;&#20132;&#26435;&#37325;&#24402;&#19968;&#21270;&#21644;&#22810;&#32034;&#24341;&#27169;&#22411;&#23494;&#20999;&#30456;&#20851;&#12290;</title><link>http://arxiv.org/abs/2310.03696</link><description>&lt;p&gt;
&#20855;&#26377;&#22810;&#21464;&#37327;&#38750;&#32447;&#24615;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#30340;Banach&#31354;&#38388;&#20248;&#21270;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Banach Space Optimality of Neural Architectures With Multivariate Nonlinearities. (arXiv:2310.03696v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03696
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#22810;&#21464;&#37327;&#38750;&#32447;&#24615;&#28608;&#27963;&#20989;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#22312;Banach&#31354;&#38388;&#30340;&#20248;&#21270;&#24615;&#65292;&#24182;&#26500;&#24314;&#20102;&#19968;&#31867;&#26032;&#30340;Banach&#31354;&#38388;&#23478;&#26063;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#23398;&#20064;&#38382;&#39064;&#30340;&#35299;&#38598;&#23436;&#20840;&#30001;&#20855;&#26377;&#22810;&#21464;&#37327;&#38750;&#32447;&#24615;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#26469;&#25551;&#36848;&#12290;&#36825;&#20123;&#26368;&#20248;&#26550;&#26500;&#20855;&#26377;&#36339;&#36291;&#36830;&#25509;&#65292;&#24182;&#19982;&#27491;&#20132;&#26435;&#37325;&#24402;&#19968;&#21270;&#21644;&#22810;&#32034;&#24341;&#27169;&#22411;&#23494;&#20999;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#22823;&#31867;&#20855;&#26377;&#22810;&#21464;&#37327;&#38750;&#32447;&#24615;/&#28608;&#27963;&#20989;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#30340;&#21464;&#20998;&#20248;&#21270;&#24615;&#65288;&#20855;&#20307;&#32780;&#35328;&#65292;&#26159;Banach&#31354;&#38388;&#20248;&#21270;&#24615;&#65289;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#36890;&#36807;&#27491;&#21017;&#21270;&#31639;&#23376;&#21644;k-&#24179;&#38754;&#21464;&#25442;&#26500;&#24314;&#20102;&#19968;&#31867;&#26032;&#30340;Banach&#31354;&#38388;&#23478;&#26063;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;&#34920;&#31034;&#23450;&#29702;&#65292;&#35813;&#23450;&#29702;&#35828;&#26126;&#22312;&#36825;&#20123;Banach&#31354;&#38388;&#19978;&#25552;&#20986;&#30340;&#23398;&#20064;&#38382;&#39064;&#30340;&#35299;&#38598;&#23436;&#20840;&#30001;&#20855;&#26377;&#22810;&#21464;&#37327;&#38750;&#32447;&#24615;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#26469;&#25551;&#36848;&#12290;&#36825;&#20123;&#26368;&#20248;&#30340;&#26550;&#26500;&#20855;&#26377;&#36339;&#36291;&#36830;&#25509;&#65292;&#24182;&#19982;&#27491;&#20132;&#26435;&#37325;&#24402;&#19968;&#21270;&#21644;&#22810;&#32034;&#24341;&#27169;&#22411;&#24687;&#24687;&#30456;&#20851;&#65292;&#36825;&#20004;&#20010;&#27169;&#22411;&#22312;&#31070;&#32463;&#32593;&#32476;&#30028;&#24341;&#36215;&#20102;&#30456;&#24403;&#22823;&#30340;&#20852;&#36259;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#36866;&#29992;&#20110;&#21253;&#25324;&#20462;&#27491;&#32447;&#24615;&#21333;&#20803;&#65288;ReLU&#65289;&#28608;&#27963;&#20989;&#25968;&#12289;&#33539;&#25968;&#28608;&#27963;&#20989;&#25968;&#20197;&#21450;&#22312;&#34180;&#26495;/&#22810;&#27425;&#35856;&#27874;&#26679;&#26465;&#29702;&#35770;&#20013;&#25214;&#21040;&#30340;&#24452;&#21521;&#22522;&#20989;&#25968;&#22312;&#20869;&#30340;&#22810;&#31181;&#32463;&#20856;&#38750;&#32447;&#24615;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the variational optimality (specifically, the Banach space optimality) of a large class of neural architectures with multivariate nonlinearities/activation functions. To that end, we construct a new family of Banach spaces defined via a regularization operator and the $k$-plane transform. We prove a representer theorem that states that the solution sets to learning problems posed over these Banach spaces are completely characterized by neural architectures with multivariate nonlinearities. These optimal architectures have skip connections and are tightly connected to orthogonal weight normalization and multi-index models, both of which have received considerable interest in the neural network community. Our framework is compatible with a number of classical nonlinearities including the rectified linear unit (ReLU) activation function, the norm activation function, and the radial basis functions found in the theory of thin-plate/polyharmonic splines. We also show that the
&lt;/p&gt;</description></item><item><title>SmoothLLM&#26159;&#31532;&#19968;&#20010;&#29992;&#20110;&#20943;&#36731;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19978;&#36234;&#29425;&#25915;&#20987;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#36755;&#20837;&#25552;&#31034;&#19978;&#38543;&#26426;&#25200;&#21160;&#24182;&#27719;&#24635;&#39044;&#27979;&#32467;&#26524;&#26469;&#26816;&#27979;&#23545;&#25239;&#24615;&#36755;&#20837;&#65292;&#23558;&#25915;&#20987;&#25104;&#21151;&#29575;&#38477;&#20302;&#33267;&#19981;&#21040;&#19968;&#20010;&#30334;&#20998;&#28857;&#65292;&#24182;&#25552;&#20379;&#20102;&#21487;&#35777;&#26126;&#30340;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2310.03684</link><description>&lt;p&gt;
SmoothLLM&#65306;&#38450;&#24481;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20813;&#21463;&#36234;&#29425;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
SmoothLLM: Defending Large Language Models Against Jailbreaking Attacks. (arXiv:2310.03684v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03684
&lt;/p&gt;
&lt;p&gt;
SmoothLLM&#26159;&#31532;&#19968;&#20010;&#29992;&#20110;&#20943;&#36731;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#19978;&#36234;&#29425;&#25915;&#20987;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#36755;&#20837;&#25552;&#31034;&#19978;&#38543;&#26426;&#25200;&#21160;&#24182;&#27719;&#24635;&#39044;&#27979;&#32467;&#26524;&#26469;&#26816;&#27979;&#23545;&#25239;&#24615;&#36755;&#20837;&#65292;&#23558;&#25915;&#20987;&#25104;&#21151;&#29575;&#38477;&#20302;&#33267;&#19981;&#21040;&#19968;&#20010;&#30334;&#20998;&#28857;&#65292;&#24182;&#25552;&#20379;&#20102;&#21487;&#35777;&#26126;&#30340;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#21162;&#21147;&#23558;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#19982;&#20154;&#31867;&#20215;&#20540;&#35266;&#20445;&#25345;&#19968;&#33268;&#65292;&#20294;&#24191;&#27867;&#20351;&#29992;&#30340;LLM&#65288;&#22914;GPT&#12289;Llama&#12289;Claude&#21644;PaLM&#65289;&#20173;&#28982;&#23481;&#26131;&#21463;&#21040;&#36234;&#29425;&#25915;&#20987;&#65292;&#21363;&#23545;&#30446;&#26631;LLM&#36827;&#34892;&#27450;&#39575;&#65292;&#20197;&#29983;&#25104;&#19981;&#21512;&#36866;&#30340;&#20869;&#23481;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#28431;&#27934;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;SmoothLLM&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#26088;&#22312;&#20943;&#36731;LLM&#19978;&#30340;&#36234;&#29425;&#25915;&#20987;&#30340;&#31639;&#27861;&#12290;&#22522;&#20110;&#25105;&#20204;&#30340;&#21457;&#29616;&#65292;&#23545;&#25239;&#24615;&#29983;&#25104;&#30340;&#25552;&#31034;&#23545;&#23383;&#31526;&#32423;&#21035;&#30340;&#25913;&#21464;&#24456;&#33030;&#24369;&#65292;&#25105;&#20204;&#30340;&#38450;&#24481;&#39318;&#20808;&#38543;&#26426;&#25200;&#21160;&#32473;&#23450;&#36755;&#20837;&#25552;&#31034;&#30340;&#22810;&#20010;&#21103;&#26412;&#65292;&#28982;&#21518;&#27719;&#24635;&#30456;&#24212;&#30340;&#39044;&#27979;&#32467;&#26524;&#26469;&#26816;&#27979;&#23545;&#25239;&#24615;&#36755;&#20837;&#12290;SmoothLLM&#23558;&#20247;&#22810;&#28909;&#38376;LLM&#30340;&#25915;&#20987;&#25104;&#21151;&#29575;&#38477;&#20302;&#33267;&#19981;&#21040;&#19968;&#20010;&#30334;&#20998;&#28857;&#65292;&#36991;&#20813;&#20102;&#19981;&#24517;&#35201;&#30340;&#20445;&#23432;&#24615;&#65292;&#24182;&#23545;&#25915;&#20987;&#32531;&#35299;&#25552;&#20379;&#20102;&#21487;&#35777;&#26126;&#30340;&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#38450;&#24481;&#20351;&#29992;&#30340;&#26597;&#35810;&#25968;&#37327;&#27604;&#29616;&#26377;&#30340;&#25915;&#20987;&#26041;&#27861;&#23569;&#24471;&#22810;&#65292;&#24182;&#19988;&#19982;&#20219;&#20309;LLM&#20860;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite efforts to align large language models (LLMs) with human values, widely-used LLMs such as GPT, Llama, Claude, and PaLM are susceptible to jailbreaking attacks, wherein an adversary fools a targeted LLM into generating objectionable content. To address this vulnerability, we propose SmoothLLM, the first algorithm designed to mitigate jailbreaking attacks on LLMs. Based on our finding that adversarially-generated prompts are brittle to character-level changes, our defense first randomly perturbs multiple copies of a given input prompt, and then aggregates the corresponding predictions to detect adversarial inputs. SmoothLLM reduces the attack success rate on numerous popular LLMs to below one percentage point, avoids unnecessary conservatism, and admits provable guarantees on attack mitigation. Moreover, our defense uses exponentially fewer queries than existing attacks and is compatible with any LLM.
&lt;/p&gt;</description></item><item><title>&#22312;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#21512;&#20316;&#20013;&#65292;&#38656;&#35201;&#37325;&#26032;&#24605;&#32771;&#20844;&#24179;&#24615;&#65292;&#22240;&#20026;&#23436;&#20840;&#36981;&#23432;&#31639;&#27861;&#20915;&#31574;&#24456;&#23569;&#26159;&#29616;&#23454;&#21487;&#34892;&#30340;&#65292;&#22240;&#27492;&#25105;&#20204;&#38656;&#35201;&#35774;&#35745;&#31283;&#20581;&#20844;&#24179;&#30340;&#31639;&#27861;&#25512;&#33616;&#26469;&#25552;&#21319;&#20844;&#24179;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.03647</link><description>&lt;p&gt;
&#37325;&#26032;&#24605;&#32771;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#21512;&#20316;&#30340;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Rethinking Fairness for Human-AI Collaboration. (arXiv:2310.03647v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03647
&lt;/p&gt;
&lt;p&gt;
&#22312;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#21512;&#20316;&#20013;&#65292;&#38656;&#35201;&#37325;&#26032;&#24605;&#32771;&#20844;&#24179;&#24615;&#65292;&#22240;&#20026;&#23436;&#20840;&#36981;&#23432;&#31639;&#27861;&#20915;&#31574;&#24456;&#23569;&#26159;&#29616;&#23454;&#21487;&#34892;&#30340;&#65292;&#22240;&#27492;&#25105;&#20204;&#38656;&#35201;&#35774;&#35745;&#31283;&#20581;&#20844;&#24179;&#30340;&#31639;&#27861;&#25512;&#33616;&#26469;&#25552;&#21319;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#30340;&#31639;&#27861;&#20844;&#24179;&#24615;&#26041;&#27861;&#26088;&#22312;&#30830;&#20445;&#20154;&#31867;&#20915;&#31574;&#32773;&#23436;&#20840;&#36981;&#23432;&#31639;&#27861;&#20915;&#31574;&#26102;&#23454;&#29616;&#20844;&#24179;&#30340;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#22312;&#20154;&#24037;&#26234;&#33021;&#19982;&#20154;&#31867;&#21512;&#20316;&#20013;&#65292;&#23436;&#20840;&#36981;&#23432;&#31639;&#27861;&#20915;&#31574;&#24456;&#23569;&#26159;&#29616;&#23454;&#25110;&#29702;&#24819;&#30340;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#23545;&#20844;&#24179;&#31639;&#27861;&#30340;&#36873;&#25321;&#24615;&#36981;&#23432;&#20250;&#30456;&#23545;&#20110;&#20154;&#31867;&#20197;&#21069;&#30340;&#25919;&#31574;&#22686;&#21152;&#27495;&#35270;&#12290;&#22240;&#27492;&#65292;&#30830;&#20445;&#20844;&#24179;&#32467;&#26524;&#38656;&#35201;&#22522;&#26412;&#19981;&#21516;&#30340;&#31639;&#27861;&#35774;&#35745;&#21407;&#21017;&#65292;&#20197;&#30830;&#20445;&#23545;&#20915;&#31574;&#32773;&#65288;&#20107;&#20808;&#19981;&#30693;&#36947;&#65289;&#30340;&#36981;&#23432;&#27169;&#24335;&#20855;&#26377;&#31283;&#20581;&#24615;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;&#19968;&#31181;&#36981;&#23432;&#31283;&#20581;&#20844;&#24179;&#30340;&#31639;&#27861;&#25512;&#33616;&#65292;&#26080;&#35770;&#20154;&#31867;&#30340;&#36981;&#23432;&#27169;&#24335;&#22914;&#20309;&#65292;&#23427;&#20204;&#37117;&#33021;&#30830;&#20445;&#22312;&#20915;&#31574;&#20013;&#25913;&#21892;&#20844;&#24179;&#24615;&#65288;&#24369;&#24418;&#24847;&#20041;&#19978;&#65289;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#20248;&#21270;&#31574;&#30053;&#26469;&#30830;&#23450;&#26368;&#20339;&#30340;&#24615;&#33021;&#25913;&#36827;&#36981;&#23432;&#31283;&#20581;&#20844;&#24179;&#31574;&#30053;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#21457;&#29616;&#35774;&#35745;&#31639;&#27861;&#25512;&#33616;&#21487;&#33021;&#26159;&#19981;&#21487;&#34892;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing approaches to algorithmic fairness aim to ensure equitable outcomes if human decision-makers comply perfectly with algorithmic decisions. However, perfect compliance with the algorithm is rarely a reality or even a desirable outcome in human-AI collaboration. Yet, recent studies have shown that selective compliance with fair algorithms can amplify discrimination relative to the prior human policy. As a consequence, ensuring equitable outcomes requires fundamentally different algorithmic design principles that ensure robustness to the decision-maker's (a priori unknown) compliance pattern. We define the notion of compliance-robustly fair algorithmic recommendations that are guaranteed to (weakly) improve fairness in decisions, regardless of the human's compliance pattern. We propose a simple optimization strategy to identify the best performance-improving compliance-robustly fair policy. However, we show that it may be infeasible to design algorithmic recommendations that are s
&lt;/p&gt;</description></item><item><title>CLEVRER-Humans&#26159;&#19968;&#20010;&#29992;&#20110;&#22240;&#26524;&#21028;&#26029;&#30340;&#35270;&#39057;&#25512;&#29702;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#20154;&#24037;&#26631;&#27880;&#26469;&#35299;&#20915;&#21512;&#25104;&#20107;&#20214;&#21644;&#21512;&#25104;&#35821;&#35328;&#25551;&#36848;&#30340;&#32570;&#20047;&#22810;&#26679;&#24615;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#36845;&#20195;&#20107;&#20214;&#22635;&#31354;&#21644;&#31070;&#32463;&#35821;&#35328;&#29983;&#25104;&#27169;&#22411;&#25552;&#39640;&#25968;&#25454;&#25910;&#38598;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.03635</link><description>&lt;p&gt;
CLEVRER-Humans: &#29992;&#20154;&#31867;&#30340;&#26041;&#24335;&#25551;&#36848;&#29289;&#29702;&#21644;&#22240;&#26524;&#20107;&#20214;
&lt;/p&gt;
&lt;p&gt;
CLEVRER-Humans: Describing Physical and Causal Events the Human Way. (arXiv:2310.03635v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03635
&lt;/p&gt;
&lt;p&gt;
CLEVRER-Humans&#26159;&#19968;&#20010;&#29992;&#20110;&#22240;&#26524;&#21028;&#26029;&#30340;&#35270;&#39057;&#25512;&#29702;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#20154;&#24037;&#26631;&#27880;&#26469;&#35299;&#20915;&#21512;&#25104;&#20107;&#20214;&#21644;&#21512;&#25104;&#35821;&#35328;&#25551;&#36848;&#30340;&#32570;&#20047;&#22810;&#26679;&#24615;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#36845;&#20195;&#20107;&#20214;&#22635;&#31354;&#21644;&#31070;&#32463;&#35821;&#35328;&#29983;&#25104;&#27169;&#22411;&#25552;&#39640;&#25968;&#25454;&#25910;&#38598;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26500;&#24314;&#33021;&#22815;&#25512;&#29702;&#29289;&#29702;&#20107;&#20214;&#21450;&#20854;&#22240;&#26524;&#20851;&#31995;&#30340;&#26426;&#22120;&#23545;&#20110;&#19982;&#29289;&#29702;&#19990;&#30028;&#36827;&#34892;&#28789;&#27963;&#20114;&#21160;&#38750;&#24120;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#22823;&#22810;&#25968;&#29289;&#29702;&#21644;&#22240;&#26524;&#25512;&#29702;&#22522;&#20934;&#37117;&#20165;&#22522;&#20110;&#21512;&#25104;&#20107;&#20214;&#21644;&#21512;&#25104;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#30340;&#22240;&#26524;&#20851;&#31995;&#12290;&#36825;&#31181;&#35774;&#35745;&#23384;&#22312;&#20004;&#20010;&#38382;&#39064;&#65306;&#19968;&#26159;&#20107;&#20214;&#31867;&#22411;&#21644;&#33258;&#28982;&#35821;&#35328;&#25551;&#36848;&#32570;&#20047;&#22810;&#26679;&#24615;&#65307;&#20108;&#26159;&#22522;&#20110;&#25163;&#21160;&#23450;&#20041;&#30340;&#21551;&#21457;&#24335;&#35268;&#21017;&#30340;&#22240;&#26524;&#20851;&#31995;&#19982;&#20154;&#31867;&#21028;&#26029;&#19981;&#19968;&#33268;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20004;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;CLEVRER-Humans&#22522;&#20934;&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20154;&#24037;&#26631;&#27880;&#30340;&#35270;&#39057;&#25512;&#29702;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#23545;&#29289;&#29702;&#20107;&#20214;&#30340;&#22240;&#26524;&#21028;&#26029;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;&#20004;&#31181;&#25216;&#26415;&#26469;&#25552;&#39640;&#25968;&#25454;&#25910;&#38598;&#25928;&#29575;&#65306;&#39318;&#20808;&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#36845;&#20195;&#20107;&#20214;&#22635;&#31354;&#20219;&#21153;&#65292;&#20197; eliciting &#35270;&#39057;&#20013;&#20107;&#20214;&#30340;&#26032;&#34920;&#31034;&#26041;&#24335;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#22240;&#26524;&#20107;&#20214;&#22270; (CEGs)&#65307;&#20854;&#27425;&#65292;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#35821;&#35328;&#29983;&#25104;&#27169;&#22411;&#30340;&#25968;&#25454;&#22686;&#24378;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
Building machines that can reason about physical events and their causal relationships is crucial for flexible interaction with the physical world. However, most existing physical and causal reasoning benchmarks are exclusively based on synthetically generated events and synthetic natural language descriptions of causal relationships. This design brings up two issues. First, there is a lack of diversity in both event types and natural language descriptions; second, causal relationships based on manually-defined heuristics are different from human judgments. To address both shortcomings, we present the CLEVRER-Humans benchmark, a video reasoning dataset for causal judgment of physical events with human labels. We employ two techniques to improve data collection efficiency: first, a novel iterative event cloze task to elicit a new representation of events in videos, which we term Causal Event Graphs (CEGs); second, a data augmentation technique based on neural language generative models.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#26799;&#24230;&#27969;&#25277;&#26679;&#26041;&#27861;&#30340;&#30740;&#31350;&#26041;&#21521;&#22312;&#35745;&#31639;&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#20013;&#30340;&#26799;&#24230;&#27969;&#30340;&#35774;&#35745;&#32452;&#25104;&#37096;&#20998;&#65292;&#25552;&#20986;&#20102;&#19977;&#20010;&#36129;&#29486;&#65306;Kullback-Leibler&#25955;&#24230;&#20316;&#20026;&#33021;&#37327;&#27867;&#20989;&#30340;&#29420;&#29305;&#23646;&#24615;&#12289;&#24230;&#37327;&#30340;&#36873;&#25321;&#19982;&#19981;&#21464;&#24615;&#30340;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2310.03597</link><description>&lt;p&gt;
&#22312;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#20013;&#36890;&#36807;&#26799;&#24230;&#27969;&#36827;&#34892;&#25277;&#26679;
&lt;/p&gt;
&lt;p&gt;
Sampling via Gradient Flows in the Space of Probability Measures. (arXiv:2310.03597v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03597
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26799;&#24230;&#27969;&#25277;&#26679;&#26041;&#27861;&#30340;&#30740;&#31350;&#26041;&#21521;&#22312;&#35745;&#31639;&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#20013;&#30340;&#26799;&#24230;&#27969;&#30340;&#35774;&#35745;&#32452;&#25104;&#37096;&#20998;&#65292;&#25552;&#20986;&#20102;&#19977;&#20010;&#36129;&#29486;&#65306;Kullback-Leibler&#25955;&#24230;&#20316;&#20026;&#33021;&#37327;&#27867;&#20989;&#30340;&#29420;&#29305;&#23646;&#24615;&#12289;&#24230;&#37327;&#30340;&#36873;&#25321;&#19982;&#19981;&#21464;&#24615;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35745;&#31639;&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#65292;&#20351;&#29992;&#26410;&#30693;&#24402;&#19968;&#21270;&#24120;&#25968;&#30340;&#30446;&#26631;&#27010;&#29575;&#20998;&#24067;&#36827;&#34892;&#25277;&#26679;&#26159;&#19968;&#39033;&#22522;&#26412;&#30340;&#25361;&#25112;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#36890;&#36807;&#32771;&#34385;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#20013;&#30340;&#26799;&#24230;&#27969;&#27966;&#29983;&#30340;&#31639;&#27861;&#20026;&#31639;&#27861;&#24320;&#21457;&#24320;&#36767;&#20102;&#26032;&#30340;&#36884;&#24452;&#12290;&#26412;&#25991;&#36890;&#36807;&#23457;&#26597;&#36825;&#31181;&#26799;&#24230;&#27969;&#30340;&#35774;&#35745;&#32452;&#25104;&#37096;&#20998;&#65292;&#23545;&#36825;&#31181;&#25277;&#26679;&#26041;&#27861;&#20570;&#20986;&#20102;&#19977;&#20010;&#36129;&#29486;&#12290;&#25277;&#26679;&#30340;&#20219;&#20309;&#23454;&#20363;&#21270;&#37117;&#38656;&#35201;&#19968;&#20010;&#33021;&#37327;&#27867;&#20989;&#21644;&#19968;&#20010;&#24230;&#37327;&#26469;&#30830;&#23450;&#27969;&#21160;&#65292;&#20197;&#21450;&#27969;&#21160;&#30340;&#25968;&#20540;&#36817;&#20284;&#26469;&#25512;&#23548;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#31532;&#19968;&#20010;&#36129;&#29486;&#26159;&#23637;&#31034;&#20102;Kullback-Leibler&#25955;&#24230;&#20316;&#20026;&#19968;&#20010;&#33021;&#37327;&#27867;&#20989;&#20855;&#26377;&#21807;&#19968;&#30340;&#29305;&#24449;&#65288;&#22312;&#25152;&#26377;f-&#25955;&#24230;&#20013;&#65289;&#65292;&#21363;&#30001;&#20854;&#24471;&#21040;&#30340;&#26799;&#24230;&#27969;&#19981;&#20381;&#36182;&#20110;&#30446;&#26631;&#20998;&#24067;&#30340;&#24402;&#19968;&#21270;&#24120;&#25968;&#12290;&#25105;&#20204;&#30340;&#31532;&#20108;&#20010;&#36129;&#29486;&#26159;&#20174;&#19981;&#21464;&#24615;&#30340;&#35282;&#24230;&#30740;&#31350;&#24230;&#37327;&#30340;&#36873;&#25321;&#12290;Fisher-Rao&#24230;&#37327;&#34987;&#31216;&#20026;t
&lt;/p&gt;
&lt;p&gt;
Sampling a target probability distribution with an unknown normalization constant is a fundamental challenge in computational science and engineering. Recent work shows that algorithms derived by considering gradient flows in the space of probability measures open up new avenues for algorithm development. This paper makes three contributions to this sampling approach by scrutinizing the design components of such gradient flows. Any instantiation of a gradient flow for sampling needs an energy functional and a metric to determine the flow, as well as numerical approximations of the flow to derive algorithms. Our first contribution is to show that the Kullback-Leibler divergence, as an energy functional, has the unique property (among all f-divergences) that gradient flows resulting from it do not depend on the normalization constant of the target distribution. Our second contribution is to study the choice of metric from the perspective of invariance. The Fisher-Rao metric is known as t
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#20998;&#26512;&#20102;&#20174;&#26377;&#38480;&#26679;&#26412;&#22797;&#26434;&#24230;&#20013;&#35757;&#32451;&#22522;&#20110;&#27969;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#23574;&#38160;&#30340;&#31471;&#21040;&#31471;&#20998;&#26512;&#12290;&#25105;&#20204;&#25214;&#21040;&#20102;&#23398;&#20064;&#21040;&#30340;&#36895;&#24230;&#22330;&#30340;&#32039;&#20945;&#29305;&#24615;&#65292;&#24182;&#25551;&#36848;&#20102;&#29983;&#25104;&#27969;&#30340;&#36817;&#20284;&#65292;&#35813;&#36817;&#20284;&#23558;&#22522;&#26412;&#39640;&#26031;&#23494;&#24230;&#25512;&#21521;&#30446;&#26631;&#23494;&#24230;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#29983;&#25104;&#28151;&#21512;&#29289;&#22343;&#20540;&#19982;&#30446;&#26631;&#28151;&#21512;&#29289;&#22343;&#20540;&#20043;&#38388;&#36317;&#31163;&#30340;&#38381;&#24335;&#20844;&#24335;&#65292;&#24182;&#35777;&#26126;&#20854;&#34928;&#20943;&#36895;&#24230;&#20026;$\Theta_n(\frac{1}{n})$&#65292;&#36825;&#23454;&#38469;&#19978;&#26159;&#36125;&#21494;&#26031;&#26368;&#20248;&#30340;&#12290;</title><link>http://arxiv.org/abs/2310.03575</link><description>&lt;p&gt;
&#20174;&#26377;&#38480;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20013;&#23398;&#20064;&#22522;&#20110;&#27969;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Analysis of learning a flow-based generative model from limited sample complexity. (arXiv:2310.03575v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03575
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20998;&#26512;&#20102;&#20174;&#26377;&#38480;&#26679;&#26412;&#22797;&#26434;&#24230;&#20013;&#35757;&#32451;&#22522;&#20110;&#27969;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#23574;&#38160;&#30340;&#31471;&#21040;&#31471;&#20998;&#26512;&#12290;&#25105;&#20204;&#25214;&#21040;&#20102;&#23398;&#20064;&#21040;&#30340;&#36895;&#24230;&#22330;&#30340;&#32039;&#20945;&#29305;&#24615;&#65292;&#24182;&#25551;&#36848;&#20102;&#29983;&#25104;&#27969;&#30340;&#36817;&#20284;&#65292;&#35813;&#36817;&#20284;&#23558;&#22522;&#26412;&#39640;&#26031;&#23494;&#24230;&#25512;&#21521;&#30446;&#26631;&#23494;&#24230;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#29983;&#25104;&#28151;&#21512;&#29289;&#22343;&#20540;&#19982;&#30446;&#26631;&#28151;&#21512;&#29289;&#22343;&#20540;&#20043;&#38388;&#36317;&#31163;&#30340;&#38381;&#24335;&#20844;&#24335;&#65292;&#24182;&#35777;&#26126;&#20854;&#34928;&#20943;&#36895;&#24230;&#20026;$\Theta_n(\frac{1}{n})$&#65292;&#36825;&#23454;&#38469;&#19978;&#26159;&#36125;&#21494;&#26031;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#35757;&#32451;&#19968;&#20010;&#30001;&#20004;&#23618;&#33258;&#32534;&#30721;&#22120;&#21442;&#25968;&#21270;&#30340;&#27969;&#24335;&#29983;&#25104;&#27169;&#22411;&#65292;&#20197;&#20174;&#39640;&#32500;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#20013;&#25277;&#26679;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#23545;&#36825;&#20010;&#38382;&#39064;&#36827;&#34892;&#20102;&#23574;&#38160;&#30340;&#31471;&#21040;&#31471;&#20998;&#26512;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#32039;&#23494;&#30340;&#38381;&#24335;&#29305;&#24449;&#21270;&#23398;&#20064;&#21040;&#30340;&#36895;&#24230;&#22330;&#65292;&#24403;&#21442;&#25968;&#21270;&#20026;&#19968;&#20010;&#22312;&#30446;&#26631;&#20998;&#24067;&#19978;&#20174;&#26377;&#38480;&#25968;&#37327;&#30340;&#26679;&#26412;$ n $&#20013;&#36827;&#34892;&#35757;&#32451;&#30340;&#27973;&#23618;&#21435;&#22122;&#33258;&#32534;&#30721;&#22120;&#26102;&#12290;&#22312;&#27492;&#20998;&#26512;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#24212;&#30340;&#29983;&#25104;&#27969;&#30340;&#23574;&#38160;&#25551;&#36848;&#65292;&#23558;&#22522;&#26412;&#39640;&#26031;&#23494;&#24230;&#25512;&#21521;&#30446;&#26631;&#23494;&#24230;&#30340;&#36817;&#20284;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#29983;&#25104;&#28151;&#21512;&#29289;&#30340;&#22343;&#20540;&#19982;&#30446;&#26631;&#28151;&#21512;&#29289;&#22343;&#20540;&#20043;&#38388;&#30340;&#36317;&#31163;&#30340;&#38381;&#24335;&#20844;&#24335;&#65292;&#25105;&#20204;&#35777;&#26126;&#36825;&#20010;&#36317;&#31163;&#20250;&#34928;&#20943;&#20026;$\Theta_n(\frac{1}{n})$&#12290;&#26368;&#21518;&#65292;&#36825;&#20010;&#36895;&#29575;&#34987;&#35777;&#26126;&#23454;&#38469;&#19978;&#26159;&#36125;&#21494;&#26031;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of training a flow-based generative model, parametrized by a two-layer autoencoder, to sample from a high-dimensional Gaussian mixture. We provide a sharp end-to-end analysis of the problem. First, we provide a tight closed-form characterization of the learnt velocity field, when parametrized by a shallow denoising auto-encoder trained on a finite number $n$ of samples from the target distribution. Building on this analysis, we provide a sharp description of the corresponding generative flow, which pushes the base Gaussian density forward to an approximation of the target density. In particular, we provide closed-form formulae for the distance between the mean of the generated mixture and the mean of the target mixture, which we show decays as $\Theta_n(\frac{1}{n})$. Finally, this rate is shown to be in fact Bayes-optimal.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;Leave-One-Out&#26368;&#22823;&#23545;&#25968;&#20284;&#28982;&#30446;&#26631;&#31283;&#23450;&#35757;&#32451;&#27010;&#29575;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#26680;&#23494;&#24230;&#20272;&#35745;&#27169;&#22411;&#21644;&#30041;&#19968;&#27861;&#26368;&#22823;&#23545;&#25968;&#20284;&#28982;&#20934;&#21017;&#65292;&#35299;&#20915;&#20102;&#25968;&#25454;&#23494;&#24230;&#19981;&#22343;&#21248;&#22256;&#38590;&#65292;&#24182;&#36890;&#36807;&#20998;&#37197;&#21487;&#23398;&#20064;&#26435;&#37325;&#25193;&#23637;&#27169;&#22411;&#65292;&#21152;&#36895;&#20102;&#35757;&#32451;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2310.03556</link><description>&lt;p&gt;
&#20351;&#29992;Leave-One-Out&#26368;&#22823;&#23545;&#25968;&#20284;&#28982;&#30446;&#26631;&#31283;&#23450;&#35757;&#32451;&#27010;&#29575;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Stable Training of Probabilistic Models Using the Leave-One-Out Maximum Log-Likelihood Objective. (arXiv:2310.03556v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03556
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;Leave-One-Out&#26368;&#22823;&#23545;&#25968;&#20284;&#28982;&#30446;&#26631;&#31283;&#23450;&#35757;&#32451;&#27010;&#29575;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#26680;&#23494;&#24230;&#20272;&#35745;&#27169;&#22411;&#21644;&#30041;&#19968;&#27861;&#26368;&#22823;&#23545;&#25968;&#20284;&#28982;&#20934;&#21017;&#65292;&#35299;&#20915;&#20102;&#25968;&#25454;&#23494;&#24230;&#19981;&#22343;&#21248;&#22256;&#38590;&#65292;&#24182;&#36890;&#36807;&#20998;&#37197;&#21487;&#23398;&#20064;&#26435;&#37325;&#25193;&#23637;&#27169;&#22411;&#65292;&#21152;&#36895;&#20102;&#35757;&#32451;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30005;&#21147;&#31995;&#32479;&#36816;&#34892;&#21644;&#35268;&#21010;&#36807;&#31243;&#30340;&#27010;&#29575;&#24314;&#27169;&#20381;&#36182;&#20110;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#65292;&#36825;&#38656;&#35201;&#36275;&#22815;&#22823;&#30340;&#25968;&#25454;&#38598;&#12290;&#24403;&#21382;&#21490;&#25968;&#25454;&#19981;&#36275;&#26102;&#65292;&#24076;&#26395;&#23558;&#28508;&#22312;&#30340;&#25968;&#25454;&#29983;&#25104;&#26426;&#21046;&#24314;&#27169;&#20026;&#27010;&#29575;&#20998;&#24067;&#65292;&#20197;&#35780;&#20272;&#25968;&#25454;&#36136;&#37327;&#24182;&#29983;&#25104;&#26356;&#22810;&#25968;&#25454;&#12290;&#22522;&#20110;&#26680;&#23494;&#24230;&#20272;&#35745;&#65288;KDE&#65289;&#30340;&#27169;&#22411;&#26159;&#36825;&#19968;&#20219;&#21153;&#30340;&#24120;&#29992;&#36873;&#25321;&#65292;&#20294;&#23427;&#20204;&#26080;&#27861;&#36866;&#24212;&#23494;&#24230;&#19981;&#22343;&#21248;&#30340;&#25968;&#25454;&#21306;&#22495;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#37319;&#29992;&#33258;&#36866;&#24212;KDE&#27169;&#22411;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#27169;&#22411;&#20013;&#30340;&#27599;&#20010;&#26680;&#20989;&#25968;&#20855;&#26377;&#29420;&#31435;&#30340;&#24102;&#23485;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#30041;&#19968;&#27861;&#26368;&#22823;&#23545;&#25968;&#20284;&#28982;&#65288;LOO-MLL&#65289;&#20934;&#21017;&#65292;&#20197;&#38450;&#27490;&#24120;&#35268;&#30340;&#26368;&#22823;&#23545;&#25968;&#20284;&#28982;&#20934;&#21017;&#20135;&#29983;&#22855;&#24322;&#35299;&#65292;&#24182;&#35777;&#26126;LOO-MLL&#21487;&#20197;&#38450;&#27490;&#36825;&#31181;&#24773;&#20917;&#12290;&#22312;&#27492;&#20445;&#35777;&#30340;&#40065;&#26834;&#24615;&#22522;&#30784;&#19978;&#65292;&#36890;&#36807;&#20026;&#26680;&#20989;&#25968;&#20998;&#37197;&#21487;&#23398;&#20064;&#26435;&#37325;&#25193;&#23637;&#20102;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#20351;&#29992;&#25913;&#36827;&#30340;&#26399;&#26395;&#26368;&#22823;&#21270;&#31639;&#27861;&#26469;&#21152;&#36895;&#35757;&#32451;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Probabilistic modelling of power systems operation and planning processes depends on data-driven methods, which require sufficiently large datasets. When historical data lacks this, it is desired to model the underlying data generation mechanism as a probability distribution to assess the data quality and generate more data, if needed. Kernel density estimation (KDE) based models are popular choices for this task, but they fail to adapt to data regions with varying densities. In this paper, an adaptive KDE model is employed to circumvent this, where each kernel in the model has an individual bandwidth. The leave-one-out maximum log-likelihood (LOO-MLL) criterion is proposed to prevent the singular solutions that the regular MLL criterion gives rise to, and it is proven that LOO-MLL prevents these. Relying on this guaranteed robustness, the model is extended by assigning learnable weights to the kernels. In addition, a modified expectation-maximization algorithm is employed to accelerat
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#25554;&#25300;&#24335;&#21518;&#39564;&#37319;&#26679;&#31639;&#27861;&#65288;PnP-ULA&#65289;&#65292;&#36890;&#36807;&#23558;&#29289;&#29702;&#27979;&#37327;&#27169;&#22411;&#19982;&#28145;&#24230;&#23398;&#20064;&#20808;&#39564;&#30456;&#32467;&#21512;&#65292;&#35299;&#20915;&#20102;&#25104;&#20687;&#36870;&#38382;&#39064;&#12290;&#25105;&#20204;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#21644;&#25968;&#20540;&#39564;&#35777;&#65292;&#37327;&#21270;&#20102;PnP-ULA&#22312;&#19981;&#21305;&#37197;&#21518;&#39564;&#20998;&#24067;&#19979;&#30340;&#35823;&#24046;&#30028;&#38480;&#65292;&#32467;&#26524;&#34920;&#26126;PnP-ULA&#23545;&#20110;&#27979;&#37327;&#27169;&#22411;&#21644;&#21435;&#22122;&#22120;&#30340;&#19981;&#21305;&#37197;&#38750;&#24120;&#25935;&#24863;&#12290;</title><link>http://arxiv.org/abs/2310.03546</link><description>&lt;p&gt;
&#25554;&#25300;&#24335;&#21518;&#39564;&#37319;&#26679;&#22312;&#19981;&#21305;&#37197;&#27979;&#37327;&#21644;&#20808;&#39564;&#27169;&#22411;&#19979;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Plug-and-Play Posterior Sampling under Mismatched Measurement and Prior Models. (arXiv:2310.03546v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03546
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#25554;&#25300;&#24335;&#21518;&#39564;&#37319;&#26679;&#31639;&#27861;&#65288;PnP-ULA&#65289;&#65292;&#36890;&#36807;&#23558;&#29289;&#29702;&#27979;&#37327;&#27169;&#22411;&#19982;&#28145;&#24230;&#23398;&#20064;&#20808;&#39564;&#30456;&#32467;&#21512;&#65292;&#35299;&#20915;&#20102;&#25104;&#20687;&#36870;&#38382;&#39064;&#12290;&#25105;&#20204;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#21644;&#25968;&#20540;&#39564;&#35777;&#65292;&#37327;&#21270;&#20102;PnP-ULA&#22312;&#19981;&#21305;&#37197;&#21518;&#39564;&#20998;&#24067;&#19979;&#30340;&#35823;&#24046;&#30028;&#38480;&#65292;&#32467;&#26524;&#34920;&#26126;PnP-ULA&#23545;&#20110;&#27979;&#37327;&#27169;&#22411;&#21644;&#21435;&#22122;&#22120;&#30340;&#19981;&#21305;&#37197;&#38750;&#24120;&#25935;&#24863;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21518;&#39564;&#37319;&#26679;&#24050;&#34987;&#35777;&#26126;&#26159;&#35299;&#20915;&#25104;&#20687;&#36870;&#38382;&#39064;&#30340;&#24378;&#22823;&#36125;&#21494;&#26031;&#26041;&#27861;&#12290;&#26368;&#36817;&#21457;&#23637;&#36215;&#26469;&#30340;&#25554;&#25300;&#24335;&#26410;&#35843;&#25972;&#26391;&#20043;&#19975;&#31639;&#27861;&#65288;PnP-ULA&#65289;&#36890;&#36807;&#23558;&#29289;&#29702;&#27979;&#37327;&#27169;&#22411;&#19982;&#20351;&#29992;&#22270;&#20687;&#21435;&#22122;&#22120;&#25351;&#23450;&#30340;&#28145;&#24230;&#23398;&#20064;&#20808;&#39564;&#30456;&#32467;&#21512;&#65292;&#25104;&#20026;&#19968;&#31181;&#26377;&#21069;&#26223;&#30340;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#21644;&#26368;&#23567;&#22343;&#26041;&#35823;&#24046;&#65288;MMSE&#65289;&#20272;&#35745;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;PnP-ULA&#30340;&#37319;&#26679;&#20998;&#24067;&#19982;&#19981;&#21305;&#37197;&#30340;&#25968;&#25454;&#20445;&#30495;&#24230;&#21644;&#21435;&#22122;&#22120;&#20043;&#38388;&#30340;&#22797;&#26434;&#20851;&#31995;&#23578;&#26410;&#32463;&#36807;&#29702;&#35770;&#20998;&#26512;&#12290;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#21518;&#39564;-L2&#25311;&#24230;&#37327;&#24182;&#21033;&#29992;&#23427;&#26469;&#37327;&#21270;PnP-ULA&#22312;&#19981;&#21305;&#37197;&#30340;&#21518;&#39564;&#20998;&#24067;&#19979;&#30340;&#26174;&#24335;&#35823;&#24046;&#30028;&#38480;&#26469;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#12290;&#25105;&#20204;&#22312;&#22810;&#20010;&#36870;&#38382;&#39064;&#19978;&#23545;&#25105;&#20204;&#30340;&#29702;&#35770;&#36827;&#34892;&#20102;&#25968;&#20540;&#39564;&#35777;&#65292;&#22914;&#20174;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#21644;&#22270;&#20687;&#21435;&#27169;&#31946;&#20013;&#37319;&#26679;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;PnP-ULA&#30340;&#37319;&#26679;&#20998;&#24067;&#23545;&#20110;&#27979;&#37327;&#27169;&#22411;&#21644;&#21435;&#22122;&#22120;&#30340;&#19981;&#21305;&#37197;&#38750;&#24120;&#25935;&#24863;&#65292;&#24182;&#21487;&#20197;&#31934;&#30830;&#22320;&#25551;&#36848;&#20854;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Posterior sampling has been shown to be a powerful Bayesian approach for solving imaging inverse problems. The recent plug-and-play unadjusted Langevin algorithm (PnP-ULA) has emerged as a promising method for Monte Carlo sampling and minimum mean squared error (MMSE) estimation by combining physical measurement models with deep-learning priors specified using image denoisers. However, the intricate relationship between the sampling distribution of PnP-ULA and the mismatched data-fidelity and denoiser has not been theoretically analyzed. We address this gap by proposing a posterior-L2 pseudometric and using it to quantify an explicit error bound for PnP-ULA under mismatched posterior distribution. We numerically validate our theory on several inverse problems such as sampling from Gaussian mixture models and image deblurring. Our results suggest that the sensitivity of the sampling distribution of PnP-ULA to a mismatch in the measurement model and the denoiser can be precisely characte
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#25506;&#32034;&#32852;&#21512;&#32676;&#19981;&#21464;&#20989;&#25968;&#22312;&#25968;&#25454;-&#21442;&#25968;&#22495;&#19978;&#30340;&#20316;&#29992;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31995;&#32479;&#30340;&#35268;&#21017;&#26469;&#35299;&#30721;&#31070;&#32463;&#32593;&#32476;&#20869;&#37096;&#25968;&#25454;&#34920;&#31034;&#20013;&#30340;&#23545;&#31216;&#24615;&#21644;&#20960;&#20309;&#24615;&#12290;&#21033;&#29992;&#36825;&#19968;&#35268;&#21017;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#30001;&#32852;&#21512;&#19981;&#21464;&#20989;&#25968;&#23548;&#20986;&#30340;&#36890;&#29992;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#21033;&#29992;&#32676;&#35770;&#35777;&#26126;&#20102;&#20854;&#26222;&#36866;&#24615;&#12290;&#36825;&#19968;&#30740;&#31350;&#25581;&#31034;&#20102;&#36924;&#36817;&#29702;&#35770;&#21644;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#32676;&#35770;&#26041;&#38754;&#65292;&#24182;&#23558;&#20960;&#20309;&#28145;&#24230;&#23398;&#20064;&#19982;&#25277;&#35937;&#35843;&#21644;&#20998;&#26512;&#30456;&#36830;&#25509;&#12290;</title><link>http://arxiv.org/abs/2310.03530</link><description>&lt;p&gt;
&#22312;&#25968;&#25454;-&#21442;&#25968;&#22495;&#19978;&#65292;&#32852;&#21512;&#32676;&#19981;&#21464;&#20989;&#25968;&#24341;&#23548;&#20102;&#36890;&#29992;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Joint Group Invariant Functions on Data-Parameter Domain Induce Universal Neural Networks. (arXiv:2310.03530v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03530
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#25506;&#32034;&#32852;&#21512;&#32676;&#19981;&#21464;&#20989;&#25968;&#22312;&#25968;&#25454;-&#21442;&#25968;&#22495;&#19978;&#30340;&#20316;&#29992;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31995;&#32479;&#30340;&#35268;&#21017;&#26469;&#35299;&#30721;&#31070;&#32463;&#32593;&#32476;&#20869;&#37096;&#25968;&#25454;&#34920;&#31034;&#20013;&#30340;&#23545;&#31216;&#24615;&#21644;&#20960;&#20309;&#24615;&#12290;&#21033;&#29992;&#36825;&#19968;&#35268;&#21017;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#30001;&#32852;&#21512;&#19981;&#21464;&#20989;&#25968;&#23548;&#20986;&#30340;&#36890;&#29992;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#21033;&#29992;&#32676;&#35770;&#35777;&#26126;&#20102;&#20854;&#26222;&#36866;&#24615;&#12290;&#36825;&#19968;&#30740;&#31350;&#25581;&#31034;&#20102;&#36924;&#36817;&#29702;&#35770;&#21644;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#32676;&#35770;&#26041;&#38754;&#65292;&#24182;&#23558;&#20960;&#20309;&#28145;&#24230;&#23398;&#20064;&#19982;&#25277;&#35937;&#35843;&#21644;&#20998;&#26512;&#30456;&#36830;&#25509;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#36755;&#20837;&#25968;&#25454;&#30340;&#23545;&#31216;&#24615;&#21644;&#20960;&#20309;&#24615;&#32771;&#34385;&#20026;&#32534;&#30721;&#22312;&#31070;&#32463;&#32593;&#32476;&#20869;&#37096;&#25968;&#25454;&#34920;&#31034;&#20013;&#65292;&#20294;&#26159;&#20855;&#20307;&#30340;&#32534;&#30721;&#35268;&#21017;&#36824;&#27809;&#26377;&#24471;&#21040;&#28145;&#20837;&#30740;&#31350;&#12290;&#36890;&#36807;&#20851;&#27880;&#25968;&#25454;-&#21442;&#25968;&#22495;&#19978;&#30340;&#32852;&#21512;&#32676;&#19981;&#21464;&#20989;&#25968;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31995;&#32479;&#30340;&#35268;&#21017;&#65292;&#20174;&#25968;&#25454;&#22495;&#19978;&#30340;&#32676;&#20316;&#29992;&#20013;&#25214;&#21040;&#21442;&#25968;&#22495;&#19978;&#30340;&#21452;&#37325;&#32676;&#20316;&#29992;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#30001;&#32852;&#21512;&#19981;&#21464;&#20989;&#25968;&#23548;&#20986;&#30340;&#24191;&#20041;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#21033;&#29992;Schur&#24341;&#29702;&#32473;&#20986;&#20102;&#23427;&#20204;&#30340;&#26222;&#36941;&#24615;&#23450;&#29702;&#30340;&#26032;&#30340;&#32676;&#35770;&#35777;&#26126;&#12290;&#30001;&#20110;&#20256;&#32479;&#30340;&#26222;&#36941;&#24615;&#23450;&#29702;&#26159;&#22522;&#20110;&#20989;&#25968;&#20998;&#26512;&#26041;&#27861;&#36827;&#34892;&#35777;&#26126;&#30340;&#65292;&#36825;&#39033;&#30740;&#31350;&#25581;&#31034;&#20102;&#36924;&#36817;&#29702;&#35770;&#30340;&#32676;&#35770;&#26041;&#38754;&#65292;&#23558;&#20960;&#20309;&#28145;&#24230;&#23398;&#20064;&#19982;&#25277;&#35937;&#35843;&#21644;&#20998;&#26512;&#30456;&#36830;&#25509;&#12290;
&lt;/p&gt;
&lt;p&gt;
The symmetry and geometry of input data are considered to be encoded in the internal data representation inside the neural network, but the specific encoding rule has been less investigated. By focusing on a joint group invariant function on the data-parameter domain, we present a systematic rule to find a dual group action on the parameter domain from a group action on the data domain. Further, we introduce generalized neural networks induced from the joint invariant functions, and present a new group theoretic proof of their universality theorems by using Schur's lemma. Since traditional universality theorems were demonstrated based on functional analytical methods, this study sheds light on the group theoretic aspect of the approximation theory, connecting geometric deep learning to abstract harmonic analysis.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23545;&#25968;&#25454;&#31354;&#38388;&#19978;&#30340;&#32676;&#20316;&#29992;&#26469;&#35782;&#21035;DNN&#20869;&#37096;&#30340;&#38544;&#34255;&#23618;&#65292;&#24182;&#23558;DNN&#26500;&#24314;&#20026;&#30456;&#23545;&#20110;Koopman&#31639;&#23376;&#30340;&#21452;&#22768;&#21464;&#25442;&#65292;&#25105;&#20204;&#21033;&#29992;&#32676;&#35770;&#35770;&#35777;&#35777;&#26126;&#20102;&#36825;&#20123;DNN&#30340;&#26222;&#36866;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.03529</link><description>&lt;p&gt;
&#28145;&#24230;&#33034;&#27874;&#21464;&#25442;&#65306;&#20351;&#29992;Koopman&#31639;&#23376;&#35777;&#26126;&#20102;&#24418;&#24335;&#28145;&#24230;&#32593;&#32476;&#30340;&#26222;&#36866;&#24615;
&lt;/p&gt;
&lt;p&gt;
Deep Ridgelet Transform: Voice with Koopman Operator Proves Universality of Formal Deep Networks. (arXiv:2310.03529v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03529
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;&#25968;&#25454;&#31354;&#38388;&#19978;&#30340;&#32676;&#20316;&#29992;&#26469;&#35782;&#21035;DNN&#20869;&#37096;&#30340;&#38544;&#34255;&#23618;&#65292;&#24182;&#23558;DNN&#26500;&#24314;&#20026;&#30456;&#23545;&#20110;Koopman&#31639;&#23376;&#30340;&#21452;&#22768;&#21464;&#25442;&#65292;&#25105;&#20204;&#21033;&#29992;&#32676;&#35770;&#35770;&#35777;&#35777;&#26126;&#20102;&#36825;&#20123;DNN&#30340;&#26222;&#36866;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#36890;&#36807;&#23545;&#25968;&#25454;&#31354;&#38388;&#19978;&#30340;&#32676;&#20316;&#29992;&#26469;&#35782;&#21035;DNN&#20869;&#37096;&#30340;&#38544;&#34255;&#23618;&#65292;&#24182;&#23558;DNN&#26500;&#24314;&#20026;&#30456;&#23545;&#20110;Koopman&#31639;&#23376;&#30340;&#21452;&#22768;&#21464;&#25442;&#65292;Koopman&#31639;&#23376;&#26159;&#32676;&#20316;&#29992;&#30340;&#32447;&#24615;&#34920;&#31034;&#12290;&#22522;&#20110;&#32676;&#35770;&#35770;&#35777;&#65292;&#29305;&#21035;&#26159;&#21033;&#29992;Schur&#24341;&#29702;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#36825;&#20123;DNN&#26222;&#36866;&#24615;&#30340;&#31616;&#21333;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
We identify hidden layers inside a DNN with group actions on the data space, and formulate the DNN as a dual voice transform with respect to Koopman operator, a linear representation of the group action. Based on the group theoretic arguments, particularly by using Schur's lemma, we show a simple proof of the universality of those DNNs.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#32500;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#32452;&#27979;&#35797;&#26469;&#35782;&#21035;&#27963;&#21160;&#21464;&#37327;&#65292;&#20197;&#23454;&#29616;&#39640;&#25928;&#20248;&#21270;&#12290;&#35813;&#26041;&#27861;&#22312;&#22810;&#20010;&#21512;&#25104;&#21644;&#30495;&#23454;&#39640;&#32500;&#20248;&#21270;&#20219;&#21153;&#19978;&#19982;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#30456;&#31454;&#20105;&#12290;</title><link>http://arxiv.org/abs/2310.03515</link><description>&lt;p&gt;
&#39640;&#32500;&#36125;&#21494;&#26031;&#20248;&#21270;&#19982;&#32452;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
High-dimensional Bayesian Optimization with Group Testing. (arXiv:2310.03515v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03515
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#32500;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#32452;&#27979;&#35797;&#26469;&#35782;&#21035;&#27963;&#21160;&#21464;&#37327;&#65292;&#20197;&#23454;&#29616;&#39640;&#25928;&#20248;&#21270;&#12290;&#35813;&#26041;&#27861;&#22312;&#22810;&#20010;&#21512;&#25104;&#21644;&#30495;&#23454;&#39640;&#32500;&#20248;&#21270;&#20219;&#21153;&#19978;&#19982;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#30456;&#31454;&#20105;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#26159;&#19968;&#31181;&#20248;&#21270;&#26114;&#36149;&#30340;&#40657;&#31665;&#20989;&#25968;&#30340;&#26377;&#25928;&#26041;&#27861;&#12290;&#39640;&#32500;&#38382;&#39064;&#29305;&#21035;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#22240;&#20026;&#30446;&#26631;&#30340;&#26367;&#20195;&#27169;&#22411;&#21463;&#21040;&#32500;&#24230;&#28798;&#38590;&#30340;&#24433;&#21709;&#65292;&#24456;&#38590;&#36827;&#34892;&#20934;&#30830;&#24314;&#27169;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#32452;&#27979;&#35797;&#26041;&#27861;&#26469;&#35782;&#21035;&#27963;&#21160;&#21464;&#37327;&#65292;&#20197;&#20415;&#22312;&#36825;&#20123;&#39046;&#22495;&#20013;&#23454;&#29616;&#39640;&#25928;&#20248;&#21270;&#12290;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#65292;&#31216;&#20026;&#32452;&#27979;&#35797;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;GTBO&#65289;&#65292;&#39318;&#20808;&#36816;&#34892;&#19968;&#20010;&#27979;&#35797;&#38454;&#27573;&#65292;&#22312;&#36825;&#20010;&#38454;&#27573;&#65292;&#31995;&#32479;&#22320;&#36873;&#25321;&#19968;&#32452;&#21464;&#37327;&#65292;&#24182;&#27979;&#35797;&#23427;&#20204;&#23545;&#30446;&#26631;&#30340;&#24433;&#21709;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#23558;&#24191;&#20026;&#20154;&#30693;&#30340;&#32452;&#27979;&#35797;&#29702;&#35770;&#25193;&#23637;&#21040;&#36830;&#32493;&#33539;&#22260;&#20989;&#25968;&#12290;&#22312;&#31532;&#20108;&#38454;&#27573;&#65292;GTBO&#36890;&#36807;&#23545;&#27963;&#21160;&#32500;&#24230;&#32473;&#20104;&#26356;&#22810;&#37325;&#35270;&#26469;&#25351;&#23548;&#20248;&#21270;&#12290;&#36890;&#36807;&#21033;&#29992;&#36724;&#23545;&#40784;&#23376;&#31354;&#38388;&#20551;&#35774;&#65292;GTBO&#22312;&#20960;&#20010;&#21512;&#25104;&#21644;&#30495;&#23454;&#39640;&#32500;&#20248;&#21270;&#20219;&#21153;&#19978;&#19982;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#30456;&#31454;&#20105;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian optimization is an effective method for optimizing expensive-to-evaluate black-box functions. High-dimensional problems are particularly challenging as the surrogate model of the objective suffers from the curse of dimensionality, which makes accurate modeling difficult. We propose a group testing approach to identify active variables to facilitate efficient optimization in these domains. The proposed algorithm, Group Testing Bayesian Optimization (GTBO), first runs a testing phase where groups of variables are systematically selected and tested on whether they influence the objective. To that end, we extend the well-established theory of group testing to functions of continuous ranges. In the second phase, GTBO guides optimization by placing more importance on the active dimensions. By exploiting the axis-aligned subspace assumption, GTBO is competitive against state-of-the-art methods on several synthetic and real-world high-dimensional optimization tasks. Furthermore, GTBO 
&lt;/p&gt;</description></item><item><title>&#21464;&#20998;&#25512;&#26029;&#22312;GARCH&#23478;&#26063;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#20013;&#26159;&#19968;&#31181;&#21487;&#38752;&#21644;&#21487;&#34892;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.03435</link><description>&lt;p&gt;
GARCH&#23478;&#26063;&#27169;&#22411;&#30340;&#21464;&#20998;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Variational Inference for GARCH-family Models. (arXiv:2310.03435v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03435
&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#25512;&#26029;&#22312;GARCH&#23478;&#26063;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#20013;&#26159;&#19968;&#31181;&#21487;&#38752;&#21644;&#21487;&#34892;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20272;&#35745;GARCH&#23478;&#26063;&#27169;&#22411;&#36890;&#24120;&#37319;&#29992;&#33945;&#29305;&#21345;&#32599;&#25277;&#26679;&#26041;&#27861;&#12290;&#21464;&#20998;&#25512;&#26029;&#20316;&#20026;&#19968;&#31181;&#21487;&#38752;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#22312;&#22797;&#26434;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#65292;&#20294;&#22312;&#35745;&#37327;&#32463;&#27982;&#23398;&#21644;&#37329;&#34701;&#39046;&#22495;&#30340;&#24212;&#29992;&#36824;&#26377;&#38480;&#12290;&#26412;&#25991;&#35752;&#35770;&#20102;&#21464;&#20998;&#25512;&#26029;&#22312;GARCH&#31867;&#27169;&#22411;&#36125;&#21494;&#26031;&#25512;&#26029;&#20013;&#26159;&#21542;&#26159;&#19968;&#31181;&#21487;&#38752;&#21644;&#21487;&#34892;&#30340;&#26367;&#20195;&#33945;&#29305;&#21345;&#32599;&#25277;&#26679;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#28041;&#21450;&#26631;&#20934;&#26222;&#23572;500&#25351;&#25968;&#25104;&#20998;&#32929;&#30340;&#22823;&#35268;&#27169;&#23454;&#39564;&#65292;&#37319;&#29992;&#22810;&#31181;&#21464;&#20998;&#25512;&#26029;&#20248;&#21270;&#31639;&#27861;&#21644;&#27874;&#21160;&#24615;&#27169;&#22411;&#65292;&#24182;&#36827;&#34892;&#20102;&#26696;&#20363;&#30740;&#31350;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21464;&#20998;&#25512;&#26029;&#26159;&#19968;&#31181;&#26377;&#21560;&#24341;&#21147;&#12289;&#38750;&#24120;&#33391;&#22909;&#26657;&#20934;&#21644;&#26377;&#31454;&#20105;&#21147;&#30340;&#36125;&#21494;&#26031;&#23398;&#20064;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Bayesian estimation of GARCH-family models has been typically addressed through Monte Carlo sampling. Variational Inference is gaining popularity and attention as a robust approach for Bayesian inference in complex machine learning models; however, its adoption in econometrics and finance is limited. This paper discusses the extent to which Variational Inference constitutes a reliable and feasible alternative to Monte Carlo sampling for Bayesian inference in GARCH-like models. Through a large-scale experiment involving the constituents of the S&amp;P 500 index, several Variational Inference optimizers, a variety of volatility models, and a case study, we show that Variational Inference is an attractive, remarkably well-calibrated, and competitive method for Bayesian learning.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;Gromov-Wasserstein&#21487;&#23454;&#29616;&#22312;&#32858;&#31867;&#21644;&#38477;&#32500;&#20043;&#38388;&#25554;&#20540;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#35299;&#20915;&#21322;&#26494;&#24347;&#30340;&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;&#65292;&#35745;&#31639;&#36755;&#20837;&#21644;&#23884;&#20837;&#26679;&#26412;&#20043;&#38388;&#30340;&#23545;&#24212;&#20851;&#31995;&#65292;&#20174;&#32780;&#23454;&#29616;&#21516;&#26102;&#20943;&#23569;&#26679;&#26412;&#21644;&#29305;&#24449;&#25968;&#37327;&#30340;&#38477;&#32500;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#24403;&#23884;&#20837;&#30340;&#32500;&#24230;&#19981;&#21463;&#32422;&#26463;&#26102;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#20379;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#30828;&#32858;&#31867;&#12290;&#36890;&#36807;&#23558;&#38477;&#32500;&#21644;&#32858;&#31867;&#34701;&#21512;&#20026;&#20013;&#38388;&#38454;&#27573;&#65292;&#25105;&#20204;&#24378;&#35843;&#20102;&#35813;&#26041;&#27861;&#22312;&#24635;&#32467;&#30495;&#23454;&#25968;&#25454;&#26041;&#38754;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#22312;&#22270;&#20687;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#21487;&#35270;&#21270;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2310.03398</link><description>&lt;p&gt;
&#22312;Gromov-Wasserstein&#20013;&#25554;&#20540;&#32858;&#31867;&#21644;&#38477;&#32500;&#20043;&#38388;
&lt;/p&gt;
&lt;p&gt;
Interpolating between Clustering and Dimensionality Reduction with Gromov-Wasserstein. (arXiv:2310.03398v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03398
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;Gromov-Wasserstein&#21487;&#23454;&#29616;&#22312;&#32858;&#31867;&#21644;&#38477;&#32500;&#20043;&#38388;&#25554;&#20540;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#35299;&#20915;&#21322;&#26494;&#24347;&#30340;&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;&#65292;&#35745;&#31639;&#36755;&#20837;&#21644;&#23884;&#20837;&#26679;&#26412;&#20043;&#38388;&#30340;&#23545;&#24212;&#20851;&#31995;&#65292;&#20174;&#32780;&#23454;&#29616;&#21516;&#26102;&#20943;&#23569;&#26679;&#26412;&#21644;&#29305;&#24449;&#25968;&#37327;&#30340;&#38477;&#32500;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#24403;&#23884;&#20837;&#30340;&#32500;&#24230;&#19981;&#21463;&#32422;&#26463;&#26102;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#20379;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#30828;&#32858;&#31867;&#12290;&#36890;&#36807;&#23558;&#38477;&#32500;&#21644;&#32858;&#31867;&#34701;&#21512;&#20026;&#20013;&#38388;&#38454;&#27573;&#65292;&#25105;&#20204;&#24378;&#35843;&#20102;&#35813;&#26041;&#27861;&#22312;&#24635;&#32467;&#30495;&#23454;&#25968;&#25454;&#26041;&#38754;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#22312;&#22270;&#20687;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#21487;&#35270;&#21270;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#29616;&#26377;&#38477;&#32500;&#30446;&#26631;&#30340;&#36890;&#29992;&#36866;&#24212;&#24615;&#26041;&#27861;&#65292;&#33021;&#22815;&#21516;&#26102;&#20943;&#23569;&#26679;&#26412;&#21644;&#29305;&#24449;&#25968;&#37327;&#12290;&#36890;&#36807;&#21322;&#26494;&#24347;&#30340;Gromov-Wasserstein&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;&#35745;&#31639;&#36755;&#20837;&#21644;&#23884;&#20837;&#26679;&#26412;&#20043;&#38388;&#30340;&#23545;&#24212;&#20851;&#31995;&#12290;&#24403;&#23884;&#20837;&#26679;&#26412;&#25968;&#37327;&#19982;&#36755;&#20837;&#26679;&#26412;&#25968;&#37327;&#30456;&#21305;&#37197;&#26102;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#24674;&#22797;&#20102;&#32463;&#20856;&#30340;&#27969;&#34892;&#38477;&#32500;&#27169;&#22411;&#12290;&#24403;&#23884;&#20837;&#30340;&#32500;&#24230;&#19981;&#21463;&#32422;&#26463;&#26102;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26368;&#20248;&#20256;&#36755;&#26041;&#26696;&#25552;&#20379;&#20102;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#30828;&#32858;&#31867;&#12290;&#25105;&#20204;&#24378;&#35843;&#20102;&#23558;&#38477;&#32500;&#21644;&#32858;&#31867;&#34701;&#21512;&#20026;&#20013;&#38388;&#38454;&#27573;&#20197;&#24635;&#32467;&#30495;&#23454;&#25968;&#25454;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#21487;&#35270;&#21270;&#22270;&#20687;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a versatile adaptation of existing dimensionality reduction (DR) objectives, enabling the simultaneous reduction of both sample and feature sizes. Correspondances between input and embedding samples are computed through a semi-relaxed Gromov-Wasserstein optimal transport (OT) problem. When the embedding sample size matches that of the input, our model recovers classical popular DR models. When the embedding's dimensionality is unconstrained, we show that the OT plan delivers a competitive hard clustering. We emphasize the importance of intermediate stages that blend DR and clustering for summarizing real data and apply our method to visualize datasets of images.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#21464;&#37327;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#38750;&#23618;&#27425;&#21270;&#22810;&#20445;&#30495;&#24230;&#33258;&#36866;&#24212;&#37319;&#26679;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#21033;&#29992;&#19981;&#21516;&#20445;&#30495;&#24230;&#27169;&#22411;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#20197;&#26356;&#39640;&#25928;&#22320;&#25506;&#32034;&#21644;&#21033;&#29992;&#35774;&#35745;&#31354;&#38388;&#12290;</title><link>http://arxiv.org/abs/2310.03298</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#38750;&#23618;&#27425;&#21270;&#22810;&#20445;&#30495;&#24230;&#33258;&#36866;&#24212;&#37319;&#26679;&#30340;&#28508;&#21464;&#37327;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Latent Variable Approach for Non-Hierarchical Multi-Fidelity Adaptive Sampling. (arXiv:2310.03298v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03298
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#21464;&#37327;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#38750;&#23618;&#27425;&#21270;&#22810;&#20445;&#30495;&#24230;&#33258;&#36866;&#24212;&#37319;&#26679;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#21033;&#29992;&#19981;&#21516;&#20445;&#30495;&#24230;&#27169;&#22411;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#20197;&#26356;&#39640;&#25928;&#22320;&#25506;&#32034;&#21644;&#21033;&#29992;&#35774;&#35745;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20445;&#30495;&#24230;&#65288;MF&#65289;&#26041;&#27861;&#22312;&#25552;&#39640;&#26367;&#20195;&#27169;&#22411;&#21644;&#35774;&#35745;&#20248;&#21270;&#26041;&#38754;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#65292;&#36890;&#36807;&#25972;&#21512;&#26469;&#33258;&#19981;&#21516;&#20302;&#20445;&#30495;&#24230;&#65288;LF&#65289;&#27169;&#22411;&#30340;&#25968;&#25454;&#12290;&#23613;&#31649;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;MF&#26041;&#27861;&#20551;&#23450;&#20102;&#19968;&#20010;&#22266;&#23450;&#30340;&#25968;&#25454;&#38598;&#65292;&#20294;&#26159;&#21160;&#24577;&#20998;&#37197;&#36164;&#28304;&#22312;&#19981;&#21516;&#20445;&#30495;&#24230;&#27169;&#22411;&#20043;&#38388;&#21487;&#20197;&#23454;&#29616;&#26356;&#39640;&#30340;&#25506;&#32034;&#21644;&#21033;&#29992;&#35774;&#35745;&#31354;&#38388;&#30340;&#25928;&#29575;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;MF&#26041;&#27861;&#20381;&#36182;&#20110;&#20445;&#30495;&#24230;&#32423;&#21035;&#30340;&#23618;&#27425;&#20551;&#35774;&#65292;&#25110;&#32773;&#26080;&#27861;&#25429;&#25417;&#22810;&#20010;&#20445;&#30495;&#24230;&#32423;&#21035;&#20043;&#38388;&#30340;&#30456;&#20114;&#20851;&#31995;&#24182;&#21033;&#29992;&#20854;&#26469;&#37327;&#21270;&#26410;&#26469;&#26679;&#26412;&#30340;&#20215;&#20540;&#21644;&#23548;&#33322;&#33258;&#36866;&#24212;&#37319;&#26679;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38556;&#30861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#19981;&#21516;&#20445;&#30495;&#24230;&#27169;&#22411;&#30340;&#28508;&#21464;&#37327;&#23884;&#20837;&#21644;&#30456;&#20851;&#30340;&#20808;&#39564;-&#21518;&#39564;&#20998;&#26512;&#30340;&#26694;&#26550;&#65292;&#20197;&#26174;&#24335;&#22320;&#21033;&#29992;&#23427;&#20204;&#30340;&#30456;&#20851;&#24615;&#36827;&#34892;&#33258;&#36866;&#24212;&#37319;&#26679;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#20013;&#65292;&#27599;&#20010;&#22635;&#20805;&#37319;&#26679;&#36845;&#20195;&#21253;&#25324;&#20004;&#20010;&#27493;&#39588;&#65306;&#39318;&#20808;&#25105;&#20204;&#30830;&#23450;&#20855;&#26377;&#26368;&#22823;&#28508;&#21147;&#24433;&#21709;&#30340;&#20301;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-fidelity (MF) methods are gaining popularity for enhancing surrogate modeling and design optimization by incorporating data from various low-fidelity (LF) models. While most existing MF methods assume a fixed dataset, adaptive sampling methods that dynamically allocate resources among fidelity models can achieve higher efficiency in the exploring and exploiting the design space. However, most existing MF methods rely on the hierarchical assumption of fidelity levels or fail to capture the intercorrelation between multiple fidelity levels and utilize it to quantify the value of the future samples and navigate the adaptive sampling. To address this hurdle, we propose a framework hinged on a latent embedding for different fidelity models and the associated pre-posterior analysis to explicitly utilize their correlation for adaptive sampling. In this framework, each infill sampling iteration includes two steps: We first identify the location of interest with the greatest potential imp
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28508;&#22312;&#25552;&#31034;Transformer&#27169;&#22411;&#65292;&#29992;&#20110;&#35299;&#20915;&#20998;&#23376;&#35774;&#35745;&#20013;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#35813;&#27169;&#22411;&#21253;&#25324;&#28508;&#22312;&#21521;&#37327;&#12289;&#20998;&#23376;&#29983;&#25104;&#27169;&#22411;&#21644;&#24615;&#36136;&#39044;&#27979;&#27169;&#22411;&#65292;&#36890;&#36807;&#23545;&#29616;&#26377;&#20998;&#23376;&#36827;&#34892;&#35757;&#32451;&#21518;&#36827;&#34892;&#27169;&#22411;&#20998;&#24067;&#30340;&#36880;&#28176;&#36716;&#31227;&#12290;</title><link>http://arxiv.org/abs/2310.03253</link><description>&lt;p&gt;
&#28508;&#22312;&#25552;&#31034;Transformer&#27169;&#22411;&#22312;&#20998;&#23376;&#35774;&#35745;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Molecule Design by Latent Prompt Transformer. (arXiv:2310.03253v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03253
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28508;&#22312;&#25552;&#31034;Transformer&#27169;&#22411;&#65292;&#29992;&#20110;&#35299;&#20915;&#20998;&#23376;&#35774;&#35745;&#20013;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#35813;&#27169;&#22411;&#21253;&#25324;&#28508;&#22312;&#21521;&#37327;&#12289;&#20998;&#23376;&#29983;&#25104;&#27169;&#22411;&#21644;&#24615;&#36136;&#39044;&#27979;&#27169;&#22411;&#65292;&#36890;&#36807;&#23545;&#29616;&#26377;&#20998;&#23376;&#36827;&#34892;&#35757;&#32451;&#21518;&#36827;&#34892;&#27169;&#22411;&#20998;&#24067;&#30340;&#36880;&#28176;&#36716;&#31227;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#20998;&#23376;&#35774;&#35745;&#31561;&#20855;&#26377;&#25361;&#25112;&#24615;&#20248;&#21270;&#38382;&#39064;&#30340;&#28508;&#22312;&#25552;&#31034;Transformer&#27169;&#22411;&#65292;&#20854;&#20013;&#30446;&#26631;&#26159;&#25214;&#21040;&#20855;&#26377;&#30446;&#26631;&#21270;&#23398;&#25110;&#29983;&#29289;&#24615;&#36136;&#26368;&#20248;&#20540;&#30340;&#20998;&#23376;&#65292;&#35813;&#20540;&#21487;&#20197;&#30001;&#29616;&#26377;&#36719;&#20214;&#35745;&#31639;&#24471;&#20986;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#27169;&#22411;&#21253;&#25324;&#19977;&#20010;&#32452;&#20214;&#65306;&#65288;1&#65289;&#28508;&#22312;&#21521;&#37327;&#65292;&#20854;&#20808;&#39564;&#20998;&#24067;&#30001;&#39640;&#26031;&#30333;&#22122;&#22768;&#21521;&#37327;&#30340;Unet&#21464;&#25442;&#24314;&#27169;&#12290;&#65288;2&#65289;&#20998;&#23376;&#29983;&#25104;&#27169;&#22411;&#65292;&#22312;&#65288;1&#65289;&#20013;&#32473;&#23450;&#28508;&#22312;&#21521;&#37327;&#30340;&#26465;&#20214;&#19979;&#29983;&#25104;&#22522;&#20110;&#23383;&#31526;&#20018;&#30340;&#20998;&#23376;&#34920;&#31034;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;&#20197;&#65288;1&#65289;&#20013;&#30340;&#28508;&#22312;&#21521;&#37327;&#20316;&#20026;&#25552;&#31034;&#30340;&#22240;&#26524;Transformer&#27169;&#22411;&#12290;&#65288;3&#65289;&#24615;&#36136;&#39044;&#27979;&#27169;&#22411;&#65292;&#26681;&#25454;&#65288;1&#65289;&#20013;&#30340;&#28508;&#22312;&#21521;&#37327;&#36827;&#34892;&#38750;&#32447;&#24615;&#22238;&#24402;&#39044;&#27979;&#20998;&#23376;&#30340;&#30446;&#26631;&#24615;&#36136;&#20540;&#12290;&#25105;&#20204;&#31216;&#35813;&#25552;&#20986;&#30340;&#27169;&#22411;&#20026;&#28508;&#22312;&#25552;&#31034;Transformer&#27169;&#22411;&#12290;&#22312;&#23545;&#29616;&#26377;&#20998;&#23376;&#21450;&#20854;&#24615;&#36136;&#20540;&#36827;&#34892;&#21021;&#27493;&#35757;&#32451;&#21518;&#65292;&#25105;&#20204;&#36880;&#28176;&#36716;&#31227;&#27169;&#22411;&#20998;&#24067;&#30340;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a latent prompt Transformer model for solving challenging optimization problems such as molecule design, where the goal is to find molecules with optimal values of a target chemical or biological property that can be computed by an existing software. Our proposed model consists of three components. (1) A latent vector whose prior distribution is modeled by a Unet transformation of a Gaussian white noise vector. (2) A molecule generation model that generates the string-based representation of molecule conditional on the latent vector in (1). We adopt the causal Transformer model that takes the latent vector in (1) as prompt. (3) A property prediction model that predicts the value of the target property of a molecule based on a non-linear regression on the latent vector in (1). We call the proposed model the latent prompt Transformer model. After initial training of the model on existing molecules and their property values, we then gradually shift the model distributi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#31232;&#30095;&#28145;&#24230;&#23398;&#20064;&#22312;&#20381;&#36182;&#25968;&#25454;&#65288;&#22914;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65289;&#19978;&#30340;&#29702;&#35770;&#21644;&#24212;&#29992;&#12290;&#36890;&#36807;&#30740;&#31350;&#65292;&#25105;&#20204;&#21457;&#29616;&#31232;&#30095;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#33021;&#22815;&#19968;&#33268;&#22320;&#20272;&#35745;&#65292;&#24182;&#23545;&#20854;&#39044;&#27979;&#36827;&#34892;&#27491;&#30830;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#25968;&#20540;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#31232;&#30095;&#28145;&#24230;&#23398;&#20064;&#22312;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#26041;&#38754;&#20248;&#20110;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.03243</link><description>&lt;p&gt;
&#31232;&#30095;&#28145;&#24230;&#23398;&#20064;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65306;&#29702;&#35770;&#19982;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Sparse Deep Learning for Time Series Data: Theory and Applications. (arXiv:2310.03243v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03243
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31232;&#30095;&#28145;&#24230;&#23398;&#20064;&#22312;&#20381;&#36182;&#25968;&#25454;&#65288;&#22914;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65289;&#19978;&#30340;&#29702;&#35770;&#21644;&#24212;&#29992;&#12290;&#36890;&#36807;&#30740;&#31350;&#65292;&#25105;&#20204;&#21457;&#29616;&#31232;&#30095;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#33021;&#22815;&#19968;&#33268;&#22320;&#20272;&#35745;&#65292;&#24182;&#23545;&#20854;&#39044;&#27979;&#36827;&#34892;&#27491;&#30830;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#25968;&#20540;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#31232;&#30095;&#28145;&#24230;&#23398;&#20064;&#22312;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#26041;&#38754;&#20248;&#20110;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31232;&#30095;&#28145;&#24230;&#23398;&#20064;&#24050;&#25104;&#20026;&#25552;&#21319;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12289;&#21464;&#37327;&#36873;&#25321;&#21644;&#22823;&#35268;&#27169;&#32593;&#32476;&#21387;&#32553;&#31561;&#39046;&#22495;&#24615;&#33021;&#30340;&#27969;&#34892;&#25216;&#26415;&#12290;&#28982;&#32780;&#65292;&#22823;&#37096;&#20998;&#29616;&#26377;&#30740;&#31350;&#37117;&#38598;&#20013;&#22312;&#35266;&#27979;&#30456;&#20114;&#29420;&#31435;&#19988;&#21516;&#20998;&#24067;&#65288;i.i.d.&#65289;&#30340;&#38382;&#39064;&#19978;&#65292;&#24182;&#19988;&#22312;&#28041;&#21450;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20013;&#30340;&#39034;&#24207;&#25968;&#25454;&#31561;&#35266;&#27979;&#30456;&#20114;&#20381;&#36182;&#30340;&#38382;&#39064;&#19978;&#20960;&#20046;&#27809;&#26377;&#30456;&#20851;&#24037;&#20316;&#12290;&#26412;&#25991;&#26088;&#22312;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#30740;&#31350;&#20855;&#26377;&#20381;&#36182;&#25968;&#25454;&#30340;&#31232;&#30095;&#28145;&#24230;&#23398;&#20064;&#30340;&#29702;&#35770;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#31232;&#30095;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#65288;RNN&#65289;&#21487;&#20197;&#19968;&#33268;&#22320;&#20272;&#35745;&#65292;&#24182;&#19988;&#23427;&#20204;&#30340;&#39044;&#27979;&#22312;&#36866;&#24403;&#30340;&#20551;&#35774;&#19979;&#28176;&#36817;&#22320;&#26381;&#20174;&#27491;&#24577;&#20998;&#24067;&#65292;&#20174;&#32780;&#33021;&#22815;&#27491;&#30830;&#37327;&#21270;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#12290;&#25105;&#20204;&#30340;&#25968;&#20540;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#31232;&#30095;&#28145;&#24230;&#23398;&#20064;&#22312;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#38754;&#32988;&#36807;&#20102;&#35832;&#22914;&#20381;&#29031;&#24615;&#39044;&#27979;&#31561;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sparse deep learning has become a popular technique for improving the performance of deep neural networks in areas such as uncertainty quantification, variable selection, and large-scale network compression. However, most existing research has focused on problems where the observations are independent and identically distributed (i.i.d.), and there has been little work on the problems where the observations are dependent, such as time series data and sequential data in natural language processing. This paper aims to address this gap by studying the theory for sparse deep learning with dependent data. We show that sparse recurrent neural networks (RNNs) can be consistently estimated, and their predictions are asymptotically normally distributed under appropriate assumptions, enabling the prediction uncertainty to be correctly quantified. Our numerical results show that sparse deep learning outperforms state-of-the-art methods, such as conformal predictions, in prediction uncertainty qua
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#26032;&#30340;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#65292;&#31216;&#20026;&#38750;&#20809;&#28369;&#24369;&#20984;&#26377;&#38480;&#21644;&#32806;&#21512;&#32452;&#21512;&#20248;&#21270;(NSWC FCCO)&#65292;&#36890;&#36807;&#25193;&#23637;&#24050;&#26377;&#30340;&#30740;&#31350;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#38750;&#20809;&#28369;&#24369;&#20984;FCCO&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21333;&#24490;&#29615;&#31639;&#27861;&#26469;&#25214;&#21040;Moreau&#29615;&#30340;&#949;-&#31283;&#23450;&#28857;&#12290;</title><link>http://arxiv.org/abs/2310.03234</link><description>&lt;p&gt;
&#38750;&#20809;&#28369;&#24369;&#20984;&#26377;&#38480;&#21644;&#32806;&#21512;&#32452;&#21512;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Non-Smooth Weakly-Convex Finite-sum Coupled Compositional Optimization. (arXiv:2310.03234v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03234
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#26032;&#30340;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#65292;&#31216;&#20026;&#38750;&#20809;&#28369;&#24369;&#20984;&#26377;&#38480;&#21644;&#32806;&#21512;&#32452;&#21512;&#20248;&#21270;(NSWC FCCO)&#65292;&#36890;&#36807;&#25193;&#23637;&#24050;&#26377;&#30340;&#30740;&#31350;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#38750;&#20809;&#28369;&#24369;&#20984;FCCO&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21333;&#24490;&#29615;&#31639;&#27861;&#26469;&#25214;&#21040;Moreau&#29615;&#30340;&#949;-&#31283;&#23450;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#26032;&#30340;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#65292;&#31216;&#20026;&#38750;&#20809;&#28369;&#24369;&#20984;&#26377;&#38480;&#21644;&#32806;&#21512;&#32452;&#21512;&#20248;&#21270;(NSWC FCCO)&#12290;&#30001;&#20110;&#20854;&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#20154;&#24037;&#26234;&#33021;&#39046;&#22495;&#30340;&#24191;&#27867;&#24212;&#29992;&#20197;&#21450;&#20854;&#35299;&#20915;&#22522;&#20110;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#38543;&#26426;&#31639;&#27861;&#30340;&#23616;&#38480;&#24615;&#65292;FCCO&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#23545;&#20110;FCCO&#30340;&#30740;&#31350;&#20551;&#35774;&#20869;&#22806;&#20989;&#25968;&#37117;&#26159;&#20809;&#28369;&#30340;&#65292;&#38480;&#21046;&#20102;&#20854;&#33021;&#22815;&#35299;&#20915;&#26356;&#22810;&#31181;&#31867;&#30340;&#38382;&#39064;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#20174;&#38750;&#20809;&#28369;&#24369;&#20984;FCCO&#30340;&#35282;&#24230;&#36827;&#34892;&#20102;&#25193;&#23637;&#65292;&#20854;&#20013;&#22806;&#20989;&#25968;&#26159;&#24369;&#20984;&#19988;&#38750;&#36882;&#20943;&#30340;&#65292;&#20869;&#20989;&#25968;&#26159;&#24369;&#20984;&#30340;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#19968;&#31181;&#21333;&#24490;&#29615;&#31639;&#27861;&#65292;&#24182;&#30830;&#23450;&#20854;&#22312;&#25214;&#21040;Moreau&#29615;&#30340;&#949;-&#31283;&#23450;&#28857;&#30340;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates new families of compositional optimization problems, called $\underline{\bf n}$on-$\underline{\bf s}$mooth $\underline{\bf w}$eakly-$\underline{\bf c}$onvex $\underline{\bf f}$inite-sum $\underline{\bf c}$oupled $\underline{\bf c}$ompositional $\underline{\bf o}$ptimization (NSWC FCCO). There has been a growing interest in FCCO due to its wide-ranging applications in machine learning and AI, as well as its ability to address the shortcomings of stochastic algorithms based on empirical risk minimization. However, current research on FCCO presumes that both the inner and outer functions are smooth, limiting their potential to tackle a more diverse set of problems. Our research expands on this area by examining non-smooth weakly-convex FCCO, where the outer function is weakly convex and non-decreasing, and the inner function is weakly-convex. We analyze a single-loop algorithm and establish its complexity for finding an $\epsilon$-stationary point of the Moreau env
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#25193;&#25955;&#25913;&#36827;&#30340;&#38271;&#26399; MCMC&#37319;&#26679;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#33021;&#37327;&#20808;&#39564;&#27169;&#22411;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.03218</link><description>&lt;p&gt;
&#29992;&#25193;&#25955;&#25913;&#36827;&#30340; MCMC &#23398;&#20064;&#33021;&#37327;&#20808;&#39564;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Learning Energy-Based Prior Model with Diffusion-Amortized MCMC. (arXiv:2310.03218v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03218
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#25193;&#25955;&#25913;&#36827;&#30340;&#38271;&#26399; MCMC&#37319;&#26679;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#33021;&#37327;&#20808;&#39564;&#27169;&#22411;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38544;&#21464;&#37327;&#31354;&#38388;&#30340;&#33021;&#37327;&#22522;&#27169;&#22411;&#65288;EBMs&#65289;&#65292;&#20063;&#31216;&#20026;&#33021;&#37327;&#20808;&#39564;&#27169;&#22411;&#65292;&#30001;&#20110;&#20854;&#22312;&#20844;&#24335;&#21270;&#21644;&#28508;&#22312;&#31354;&#38388;&#30340;&#24378;&#24314;&#27169;&#33021;&#21147;&#19978;&#30340;&#28789;&#27963;&#24615;&#65292;&#24341;&#36215;&#20102;&#29983;&#25104;&#24314;&#27169;&#39046;&#22495;&#30340;&#26085;&#30410;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#20351;&#29992;&#38750;&#25910;&#25947;&#30340;&#30701;&#26399; MCMC &#36827;&#34892;&#20808;&#39564;&#21644;&#21518;&#39564;&#37319;&#26679;&#26469;&#23398;&#20064;&#38544;&#21464;&#37327;&#31354;&#38388;&#30340;&#33021;&#37327;&#20808;&#39564;&#27169;&#22411;&#30340;&#24120;&#35265;&#20570;&#27861;&#65292;&#38459;&#30861;&#20102;&#27169;&#22411;&#30340;&#36827;&#19968;&#27493;&#21457;&#23637;&#65307;&#23454;&#36341;&#20013;&#36864;&#21270;&#30340; MCMC &#37319;&#26679;&#36136;&#37327;&#36890;&#24120;&#23548;&#33268;&#29983;&#25104;&#36136;&#37327;&#19979;&#38477;&#21644;&#35757;&#32451;&#19981;&#31283;&#23450;&#65292;&#29305;&#21035;&#26159;&#22312;&#39640;&#22810;&#27169;&#24577;&#21644;/&#25110;&#39640;&#32500;&#30446;&#26631;&#20998;&#24067;&#20013;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#37319;&#26679;&#38382;&#39064;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#31616;&#21333;&#20294;&#26377;&#25928;&#30340;&#22522;&#20110;&#25193;&#25955;&#30340;&#25674;&#38144;&#26041;&#27861;&#65292;&#29992;&#20110;&#38271;&#26399; MCMC &#37319;&#26679;&#65292;&#24182;&#22522;&#20110;&#27492;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#23398;&#20064;&#31639;&#27861;&#26469;&#23398;&#20064;&#38544;&#21464;&#37327;&#31354;&#38388;&#30340;EBM&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#29702;&#35770;&#35777;&#25454;&#65292;&#34920;&#26126;&#23398;&#20064;&#21040;&#30340;MCMC&#25674;&#38144;&#26159;&#19968;&#20010;&#26377;&#25928;&#30340;&#38271;&#26399;MCMC&#37319;&#26679;&#22120;&#12290;&#22312;&#20960;&#20010;&#22270;&#20687;&#24314;&#27169;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;
&lt;/p&gt;
&lt;p&gt;
Latent space Energy-Based Models (EBMs), also known as energy-based priors, have drawn growing interests in the field of generative modeling due to its flexibility in the formulation and strong modeling power of the latent space. However, the common practice of learning latent space EBMs with non-convergent short-run MCMC for prior and posterior sampling is hindering the model from further progress; the degenerate MCMC sampling quality in practice often leads to degraded generation quality and instability in training, especially with highly multi-modal and/or high-dimensional target distributions. To remedy this sampling issue, in this paper we introduce a simple but effective diffusion-based amortization method for long-run MCMC sampling and develop a novel learning algorithm for the latent space EBM based on it. We provide theoretical evidence that the learned amortization of MCMC is a valid long-run MCMC sampler. Experiments on several image modeling benchmark datasets demonstrate t
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#21033;&#29992;&#22522;&#20110;&#27169;&#22411;&#30340;&#26641;&#20316;&#20026;&#21487;&#35299;&#37322;&#30340;&#26367;&#20195;&#27169;&#22411;&#65292;&#36890;&#36807;&#20915;&#31574;&#35268;&#21017;&#23558;&#29305;&#24449;&#31354;&#38388;&#21010;&#20998;&#20026;&#21487;&#35299;&#37322;&#30340;&#21306;&#22495;&#65292;&#24182;&#20351;&#29992;&#22522;&#20110;&#21487;&#21152;&#24615;&#20027;&#25928;&#24212;&#30340;&#21487;&#35299;&#37322;&#27169;&#22411;&#26469;&#36817;&#20284;&#40657;&#30418;&#23376;&#27169;&#22411;&#30340;&#34892;&#20026;&#65292;&#20197;&#22312;&#21487;&#35299;&#37322;&#24615;&#21644;&#24615;&#33021;&#20043;&#38388;&#36798;&#21040;&#26368;&#20339;&#24179;&#34913;&#12290;</title><link>http://arxiv.org/abs/2310.03112</link><description>&lt;p&gt;
&#21033;&#29992;&#22522;&#20110;&#27169;&#22411;&#30340;&#26641;&#20316;&#20026;&#21487;&#35299;&#37322;&#30340;&#26367;&#20195;&#27169;&#22411;&#36827;&#34892;&#27169;&#22411;&#33976;&#39311;
&lt;/p&gt;
&lt;p&gt;
Leveraging Model-based Trees as Interpretable Surrogate Models for Model Distillation. (arXiv:2310.03112v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03112
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#21033;&#29992;&#22522;&#20110;&#27169;&#22411;&#30340;&#26641;&#20316;&#20026;&#21487;&#35299;&#37322;&#30340;&#26367;&#20195;&#27169;&#22411;&#65292;&#36890;&#36807;&#20915;&#31574;&#35268;&#21017;&#23558;&#29305;&#24449;&#31354;&#38388;&#21010;&#20998;&#20026;&#21487;&#35299;&#37322;&#30340;&#21306;&#22495;&#65292;&#24182;&#20351;&#29992;&#22522;&#20110;&#21487;&#21152;&#24615;&#20027;&#25928;&#24212;&#30340;&#21487;&#35299;&#37322;&#27169;&#22411;&#26469;&#36817;&#20284;&#40657;&#30418;&#23376;&#27169;&#22411;&#30340;&#34892;&#20026;&#65292;&#20197;&#22312;&#21487;&#35299;&#37322;&#24615;&#21644;&#24615;&#33021;&#20043;&#38388;&#36798;&#21040;&#26368;&#20339;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26367;&#20195;&#27169;&#22411;&#22312;&#36890;&#36807;&#27169;&#22411;&#33976;&#39311;&#22238;&#39038;&#24615;&#22320;&#35299;&#37322;&#22797;&#26434;&#32780;&#24378;&#22823;&#30340;&#40657;&#30418;&#23376;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#26412;&#25991;&#30528;&#37325;&#20110;&#20351;&#29992;&#22522;&#20110;&#27169;&#22411;&#30340;&#26641;&#20316;&#20026;&#26367;&#20195;&#27169;&#22411;&#65292;&#36890;&#36807;&#20915;&#31574;&#35268;&#21017;&#23558;&#29305;&#24449;&#31354;&#38388;&#21010;&#20998;&#20026;&#21487;&#35299;&#37322;&#30340;&#21306;&#22495;&#12290;&#22312;&#27599;&#20010;&#21306;&#22495;&#20869;&#65292;&#20351;&#29992;&#22522;&#20110;&#21487;&#21152;&#24615;&#20027;&#25928;&#24212;&#30340;&#21487;&#35299;&#37322;&#27169;&#22411;&#26469;&#36817;&#20284;&#40657;&#30418;&#23376;&#27169;&#22411;&#30340;&#34892;&#20026;&#65292;&#20197;&#22312;&#21487;&#35299;&#37322;&#24615;&#21644;&#24615;&#33021;&#20043;&#38388;&#36798;&#21040;&#26368;&#20339;&#24179;&#34913;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#22235;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#26641;&#31639;&#27861;&#65288;SLIM&#65292;GUIDE&#65292;MOB&#21644;CTree&#65289;&#22312;&#29983;&#25104;&#36825;&#26679;&#30340;&#26367;&#20195;&#27169;&#22411;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#20445;&#30495;&#24230;&#12289;&#21487;&#35299;&#37322;&#24615;&#12289;&#31283;&#23450;&#24615;&#20197;&#21450;&#31639;&#27861;&#25429;&#25417;&#20132;&#20114;&#25928;&#24212;&#30340;&#33021;&#21147;&#36827;&#34892;&#20102;&#20840;&#38754;&#20998;&#26512;&#12290;&#26368;&#21518;&#65292;&#22522;&#20110;&#25105;&#20204;&#30340;&#32508;&#21512;&#20998;&#26512;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#29992;&#25143;&#29305;&#23450;&#30340;&#25512;&#33616;&#27010;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;
Surrogate models play a crucial role in retrospectively interpreting complex and powerful black box machine learning models via model distillation. This paper focuses on using model-based trees as surrogate models which partition the feature space into interpretable regions via decision rules. Within each region, interpretable models based on additive main effects are used to approximate the behavior of the black box model, striking for an optimal balance between interpretability and performance. Four model-based tree algorithms, namely SLIM, GUIDE, MOB, and CTree, are compared regarding their ability to generate such surrogate models. We investigate fidelity, interpretability, stability, and the algorithms' capability to capture interaction effects through appropriate splits. Based on our comprehensive analyses, we finally provide an overview of user-specific recommendations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36127;&#36317;&#31163;&#26680;&#30340;&#26368;&#22823;&#24179;&#22343;&#36317;&#31163;(MMD)&#30340;&#26465;&#20214;&#27969;&#26041;&#27861;&#65292;&#29992;&#20110;&#21518;&#39564;&#25277;&#26679;&#21644;&#26465;&#20214;&#29983;&#25104;&#24314;&#27169;&#12290;&#36890;&#36807;&#31163;&#25955;&#30340;Wasserstein&#26799;&#24230;&#27969;&#36817;&#20284;&#32852;&#21512;&#20998;&#24067;&#65292;&#35777;&#26126;&#20102;&#31890;&#23376;&#27969;&#26159;&#36866;&#24403;&#21151;&#33021;&#30340;Wasserstein&#26799;&#24230;&#27969;&#12290;&#22312;&#26465;&#20214;&#22270;&#20687;&#29983;&#25104;&#21644;&#36229;&#20998;&#36776;&#29575;&#31561;&#36870;&#38382;&#39064;&#20013;&#23637;&#31034;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.03054</link><description>&lt;p&gt;
&#22522;&#20110;&#36127;&#36317;&#31163;&#26680;&#30340;&#26368;&#22823;&#24179;&#22343;&#36317;&#31163;(MMD)&#26799;&#24230;&#27969;&#30340;&#21518;&#39564;&#25277;&#26679;
&lt;/p&gt;
&lt;p&gt;
Posterior Sampling Based on Gradient Flows of the MMD with Negative Distance Kernel. (arXiv:2310.03054v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03054
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36127;&#36317;&#31163;&#26680;&#30340;&#26368;&#22823;&#24179;&#22343;&#36317;&#31163;(MMD)&#30340;&#26465;&#20214;&#27969;&#26041;&#27861;&#65292;&#29992;&#20110;&#21518;&#39564;&#25277;&#26679;&#21644;&#26465;&#20214;&#29983;&#25104;&#24314;&#27169;&#12290;&#36890;&#36807;&#31163;&#25955;&#30340;Wasserstein&#26799;&#24230;&#27969;&#36817;&#20284;&#32852;&#21512;&#20998;&#24067;&#65292;&#35777;&#26126;&#20102;&#31890;&#23376;&#27969;&#26159;&#36866;&#24403;&#21151;&#33021;&#30340;Wasserstein&#26799;&#24230;&#27969;&#12290;&#22312;&#26465;&#20214;&#22270;&#20687;&#29983;&#25104;&#21644;&#36229;&#20998;&#36776;&#29575;&#31561;&#36870;&#38382;&#39064;&#20013;&#23637;&#31034;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#36127;&#36317;&#31163;&#26680;&#30340;&#26368;&#22823;&#24179;&#22343;&#36317;&#31163;(MMD)&#30340;&#26465;&#20214;&#27969;&#29992;&#20110;&#21518;&#39564;&#25277;&#26679;&#21644;&#26465;&#20214;&#29983;&#25104;&#24314;&#27169;&#12290;&#36825;&#20010;MMD&#65292;&#20063;&#34987;&#31216;&#20026;&#33021;&#37327;&#36317;&#31163;&#65292;&#20855;&#26377;&#20687;&#36890;&#36807;&#20999;&#29255;&#21644;&#25490;&#24207;&#36827;&#34892;&#39640;&#25928;&#35745;&#31639;&#30340;&#20960;&#20010;&#26377;&#30410;&#23646;&#24615;&#12290;&#25105;&#20204;&#20351;&#29992;&#31163;&#25955;&#30340;Wasserstein&#26799;&#24230;&#27969;&#26469;&#36817;&#20284;&#30495;&#23454;&#24773;&#20917;&#21644;&#35266;&#23519;&#20540;&#30340;&#32852;&#21512;&#20998;&#24067;&#65292;&#24182;&#20026;&#21518;&#39564;&#20998;&#24067;&#24314;&#31435;&#20102;&#35823;&#24046;&#30028;&#38480;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31890;&#23376;&#27969;&#30830;&#23454;&#26159;&#36866;&#24403;&#21151;&#33021;&#30340;Wasserstein&#26799;&#24230;&#27969;&#12290;&#25105;&#20204;&#26041;&#27861;&#30340;&#33021;&#21147;&#36890;&#36807;&#25968;&#23383;&#31034;&#20363;&#36827;&#34892;&#20102;&#28436;&#31034;&#65292;&#21253;&#25324;&#26465;&#20214;&#22270;&#20687;&#29983;&#25104;&#21644;&#35832;&#22914;&#36229;&#20998;&#36776;&#29575;&#12289;&#20462;&#22797;&#21644;&#20302;&#21058;&#37327;&#21644;&#26377;&#38480;&#35282;&#24230;&#35774;&#32622;&#19979;&#30340;&#35745;&#31639;&#26426;&#26029;&#23618;&#25195;&#25551;&#31561;&#36870;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose conditional flows of the maximum mean discrepancy (MMD) with the negative distance kernel for posterior sampling and conditional generative modeling. This MMD, which is also known as energy distance, has several advantageous properties like efficient computation via slicing and sorting. We approximate the joint distribution of the ground truth and the observations using discrete Wasserstein gradient flows and establish an error bound for the posterior distributions. Further, we prove that our particle flow is indeed a Wasserstein gradient flow of an appropriate functional. The power of our method is demonstrated by numerical examples including conditional image generation and inverse problems like superresolution, inpainting and computed tomography in low-dose and limited-angle settings.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;Softmax&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21160;&#24577;&#31574;&#30053;&#26799;&#24230;&#30340;&#32452;&#21512;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#23545;&#21442;&#25968;&#36827;&#34892;&#21453;&#21521;&#35757;&#32451;&#26469;&#26356;&#22909;&#22320;&#21033;&#29992;&#30456;&#20851;&#24615;&#32467;&#26500;&#65292;&#23454;&#29616;&#21521;&#20840;&#23616;&#26368;&#20248;&#20540;&#30340;&#25910;&#25947;&#12290;</title><link>http://arxiv.org/abs/2310.02671</link><description>&lt;p&gt;
&#36229;&#36234;&#31283;&#23450;&#24615;&#65306;&#38543;&#26426;Softmax&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#30340;&#25910;&#25947;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Beyond Stationarity: Convergence Analysis of Stochastic Softmax Policy Gradient Methods. (arXiv:2310.02671v1 [math.OC] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02671
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;Softmax&#31574;&#30053;&#26799;&#24230;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21160;&#24577;&#31574;&#30053;&#26799;&#24230;&#30340;&#32452;&#21512;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#23545;&#21442;&#25968;&#36827;&#34892;&#21453;&#21521;&#35757;&#32451;&#26469;&#26356;&#22909;&#22320;&#21033;&#29992;&#30456;&#20851;&#24615;&#32467;&#26500;&#65292;&#23454;&#29616;&#21521;&#20840;&#23616;&#26368;&#20248;&#20540;&#30340;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDP&#65289;&#26159;&#19968;&#31181;&#24418;&#24335;&#21270;&#26694;&#26550;&#65292;&#29992;&#20110;&#24314;&#27169;&#21644;&#35299;&#20915;&#24207;&#36143;&#20915;&#31574;&#38382;&#39064;&#12290;&#22312;&#26377;&#38480;&#26102;&#38388;&#33539;&#22260;&#20869;&#65292;&#36825;&#20123;&#38382;&#39064;&#19982;&#26368;&#20248;&#20572;&#27490;&#25110;&#29305;&#23450;&#20379;&#24212;&#38142;&#38382;&#39064;&#20197;&#21450;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#35757;&#32451;&#30456;&#20851;&#12290;&#19982;&#26080;&#38480;&#26102;&#38388;&#33539;&#22260;&#20869;&#30340;MDP&#19981;&#21516;&#65292;&#26368;&#20248;&#31574;&#30053;&#24182;&#19981;&#26159;&#31283;&#23450;&#30340;&#65292;&#31574;&#30053;&#24517;&#39035;&#22312;&#27599;&#20010;&#26102;&#26399;&#21333;&#29420;&#36827;&#34892;&#23398;&#20064;&#12290;&#23454;&#38469;&#19978;&#65292;&#24448;&#24448;&#21516;&#26102;&#35757;&#32451;&#25152;&#26377;&#21442;&#25968;&#65292;&#24573;&#35270;&#20102;&#21160;&#24577;&#35268;&#21010;&#25152;&#26263;&#31034;&#30340;&#20869;&#22312;&#32467;&#26500;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21160;&#24577;&#35268;&#21010;&#21644;&#31574;&#30053;&#26799;&#24230;&#30340;&#32452;&#21512;&#26041;&#27861;&#65292;&#31216;&#20026;&#21160;&#24577;&#31574;&#30053;&#26799;&#24230;&#65292;&#20854;&#20013;&#21442;&#25968;&#22312;&#26102;&#38388;&#19978;&#20197;&#21453;&#21521;&#26041;&#24335;&#36827;&#34892;&#35757;&#32451;&#12290;&#23545;&#20110;&#34920;&#26684;Softmax&#21442;&#25968;&#21270;&#65292;&#25105;&#20204;&#23545;&#21516;&#26102;&#21644;&#21160;&#24577;&#31574;&#30053;&#26799;&#24230;&#22312;&#31934;&#30830;&#26799;&#24230;&#21644;&#37319;&#26679;&#26799;&#24230;&#35774;&#32622;&#19979;&#21521;&#20840;&#23616;&#26368;&#20248;&#20540;&#36827;&#34892;&#20102;&#25910;&#25947;&#20998;&#26512;&#65292;&#19988;&#27809;&#26377;&#24341;&#20837;&#27491;&#21017;&#21270;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#20351;&#29992;&#21160;&#24577;&#31574;&#30053;&#26799;&#24230;&#35757;&#32451;&#21487;&#20197;&#26356;&#22909;&#22320;&#21033;&#29992;&#30456;&#20851;&#24615;&#32467;&#26500;&#65292;&#24182;&#25552;&#20379;&#20102;&#25910;&#25947;&#24615;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
Markov Decision Processes (MDPs) are a formal framework for modeling and solving sequential decision-making problems. In finite-time horizons such problems are relevant for instance for optimal stopping or specific supply chain problems, but also in the training of large language models. In contrast to infinite horizon MDPs optimal policies are not stationary, policies must be learned for every single epoch. In practice all parameters are often trained simultaneously, ignoring the inherent structure suggested by dynamic programming. This paper introduces a combination of dynamic programming and policy gradient called dynamic policy gradient, where the parameters are trained backwards in time. For the tabular softmax parametrisation we carry out the convergence analysis for simultaneous and dynamic policy gradient towards global optima, both in the exact and sampled gradient settings without regularisation. It turns out that the use of dynamic policy gradient training much better exploi
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#24418;&#32467;&#26500;&#65292;&#29992;&#20110;&#22312;&#32447;&#24615;&#21644;&#39640;&#26031;&#24615;&#20551;&#35774;&#19979;&#31283;&#23450;&#30340;&#28508;&#21464;&#37327;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35745;&#31639;&#35813;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#31561;&#20215;&#20110;&#35757;&#32451;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#23454;&#29616;&#20102;&#19968;&#20010;&#22522;&#20110;GPU&#30340;&#31639;&#27861;&#26469;&#36827;&#34892;&#35745;&#31639;&#12290;</title><link>http://arxiv.org/abs/2309.14073</link><description>&lt;p&gt;
&#28508;&#21464;&#37327;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65306;&#19968;&#31181;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Maximum Likelihood Estimation of Latent Variable Structural Equation Models: A Neural Network Approach. (arXiv:2309.14073v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.14073
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#24418;&#32467;&#26500;&#65292;&#29992;&#20110;&#22312;&#32447;&#24615;&#21644;&#39640;&#26031;&#24615;&#20551;&#35774;&#19979;&#31283;&#23450;&#30340;&#28508;&#21464;&#37327;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#35745;&#31639;&#35813;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#31561;&#20215;&#20110;&#35757;&#32451;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#23454;&#29616;&#20102;&#19968;&#20010;&#22522;&#20110;GPU&#30340;&#31639;&#27861;&#26469;&#36827;&#34892;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#24615;&#21644;&#39640;&#26031;&#24615;&#20551;&#35774;&#19979;&#31283;&#23450;&#30340;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#30340;&#22270;&#24418;&#32467;&#26500;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#35745;&#31639;&#36825;&#20010;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#31561;&#20215;&#20110;&#35757;&#32451;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#12290;&#25105;&#20204;&#23454;&#29616;&#20102;&#19968;&#20010;&#22522;&#20110;GPU&#30340;&#31639;&#27861;&#26469;&#35745;&#31639;&#36825;&#20123;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a graphical structure for structural equation models that is stable under marginalization under linearity and Gaussianity assumptions. We show that computing the maximum likelihood estimation of this model is equivalent to training a neural network. We implement a GPU-based algorithm that computes the maximum likelihood estimation of these models.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#31867;&#20284;&#30340;&#35745;&#31639;&#26041;&#27861;&#65292;&#20026;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;(SAM)&#65292;&#19968;&#31181;&#25913;&#36827;&#27867;&#21270;&#24615;&#33021;&#30340;&#26799;&#24230;&#19979;&#38477;&#21464;&#31181;&#65292;&#30830;&#23450;&#20102;&#19968;&#20010;&#31283;&#23450;&#24615;&#36793;&#30028;&#65292;&#35813;&#36793;&#30028;&#21462;&#20915;&#20110;&#26799;&#24230;&#30340;&#33539;&#25968;&#12290;</title><link>http://arxiv.org/abs/2309.12488</link><description>&lt;p&gt;
&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#21644;&#31283;&#23450;&#24615;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sharpness-Aware Minimization and the Edge of Stability. (arXiv:2309.12488v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.12488
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#31867;&#20284;&#30340;&#35745;&#31639;&#26041;&#27861;&#65292;&#20026;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;(SAM)&#65292;&#19968;&#31181;&#25913;&#36827;&#27867;&#21270;&#24615;&#33021;&#30340;&#26799;&#24230;&#19979;&#38477;&#21464;&#31181;&#65292;&#30830;&#23450;&#20102;&#19968;&#20010;&#31283;&#23450;&#24615;&#36793;&#30028;&#65292;&#35813;&#36793;&#30028;&#21462;&#20915;&#20110;&#26799;&#24230;&#30340;&#33539;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#24403;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;(GD)&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#26102;&#65292;&#25439;&#22833;&#20989;&#25968;&#30340;Hessian&#30697;&#38453;&#30340;&#25805;&#20316;&#31526;&#33539;&#25968;&#20250;&#22686;&#38271;&#65292;&#30452;&#21040;&#25509;&#36817;$2/\eta$&#65292;&#20043;&#21518;&#20250;&#22312;&#35813;&#20540;&#21608;&#22260;&#27874;&#21160;&#12290;&#26681;&#25454;&#23545;&#25439;&#22833;&#20989;&#25968;&#30340;&#23616;&#37096;&#20108;&#27425;&#36924;&#36817;&#65292;$2/\eta$&#34987;&#31216;&#20026;&#8220;&#31283;&#23450;&#24615;&#36793;&#30028;&#8221;&#12290;&#25105;&#20204;&#20351;&#29992;&#31867;&#20284;&#30340;&#35745;&#31639;&#26041;&#27861;&#65292;&#20026;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;(SAM)&#30830;&#23450;&#20102;&#19968;&#20010;&#8220;&#31283;&#23450;&#24615;&#36793;&#30028;&#8221;&#65292;SAM&#26159;&#19968;&#31181;&#25913;&#36827;&#27867;&#21270;&#24615;&#33021;&#30340;GD&#21464;&#31181;&#12290;&#19982;GD&#19981;&#21516;&#65292;SAM&#30340;&#31283;&#23450;&#24615;&#36793;&#30028;&#21462;&#20915;&#20110;&#26799;&#24230;&#30340;&#33539;&#25968;&#12290;&#36890;&#36807;&#19977;&#20010;&#28145;&#24230;&#23398;&#20064;&#20219;&#21153;&#30340;&#23454;&#35777;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;SAM&#22312;&#36825;&#20010;&#20998;&#26512;&#20013;&#30830;&#23450;&#30340;&#31283;&#23450;&#24615;&#36793;&#30028;&#19978;&#36816;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent experiments have shown that, often, when training a neural network with gradient descent (GD) with a step size $\eta$, the operator norm of the Hessian of the loss grows until it approximately reaches $2/\eta$, after which it fluctuates around this value.  The quantity $2/\eta$ has been called the "edge of stability" based on consideration of a local quadratic approximation of the loss. We perform a similar calculation to arrive at an "edge of stability" for Sharpness-Aware Minimization (SAM), a variant of GD which has been shown to improve its generalization. Unlike the case for GD, the resulting SAM-edge depends on the norm of the gradient. Using three deep learning training tasks, we see empirically that SAM operates on the edge of stability identified by this analysis.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;RMSProp&#21644;Adam&#23384;&#22312;&#38544;&#24335;&#35268;&#33539;&#21270;&#20316;&#29992;&#65292;&#20854;&#21462;&#20915;&#20110;&#36229;&#21442;&#25968;&#21644;&#35757;&#32451;&#38454;&#27573;&#65292;&#24182;&#35752;&#35770;&#20102;&#36825;&#20123;&#35777;&#26126;&#20107;&#23454;&#23545;&#27867;&#21270;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2309.00079</link><description>&lt;p&gt;
&#20851;&#20110;Adam&#30340;&#38544;&#24335;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
On the Implicit Bias of Adam. (arXiv:2309.00079v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00079
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;RMSProp&#21644;Adam&#23384;&#22312;&#38544;&#24335;&#35268;&#33539;&#21270;&#20316;&#29992;&#65292;&#20854;&#21462;&#20915;&#20110;&#36229;&#21442;&#25968;&#21644;&#35757;&#32451;&#38454;&#27573;&#65292;&#24182;&#35752;&#35770;&#20102;&#36825;&#20123;&#35777;&#26126;&#20107;&#23454;&#23545;&#27867;&#21270;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20197;&#21069;&#30340;&#25991;&#29486;&#20013;&#65292;&#21518;&#21521;&#35823;&#24046;&#20998;&#26512;&#34987;&#29992;&#26469;&#25214;&#21040;&#36817;&#20284;&#26799;&#24230;&#19979;&#38477;&#36712;&#36857;&#30340;&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;ODEs&#65289;&#12290;&#21457;&#29616;&#26377;&#38480;&#27493;&#38271;&#20250;&#38544;&#24335;&#22320;&#35268;&#33539;&#21270;&#35299;&#20915;&#26041;&#26696;&#65292;&#22240;&#20026;&#20986;&#29616;&#22312;ODE&#20013;&#30340;&#39033;&#20250;&#24809;&#32602;&#25439;&#22833;&#26799;&#24230;&#30340;&#20108;&#33539;&#25968;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;RMSProp&#21644;Adam&#20013;&#26159;&#21542;&#23384;&#22312;&#31867;&#20284;&#30340;&#38544;&#24335;&#35268;&#33539;&#21270;&#21462;&#20915;&#20110;&#23427;&#20204;&#30340;&#36229;&#21442;&#25968;&#21644;&#35757;&#32451;&#38454;&#27573;&#65292;&#20294;&#28041;&#21450;&#30340;&#8220;&#33539;&#25968;&#8221;&#19981;&#21516;&#65306;&#23545;&#24212;&#30340;ODE&#39033;&#35201;&#20040;&#24809;&#32602;&#65288;&#25200;&#21160;&#30340;&#65289;&#25439;&#22833;&#26799;&#24230;&#30340;&#19968;&#33539;&#25968;&#65292;&#35201;&#20040;&#30456;&#21453;&#22320;&#38459;&#27490;&#20854;&#20943;&#23567;&#65288;&#21518;&#19968;&#31181;&#24773;&#20917;&#26159;&#20856;&#22411;&#30340;&#65289;&#12290;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#25968;&#20540;&#23454;&#39564;&#65292;&#24182;&#35752;&#35770;&#20102;&#36825;&#20123;&#35777;&#26126;&#20107;&#23454;&#22914;&#20309;&#24433;&#21709;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
In previous literature, backward error analysis was used to find ordinary differential equations (ODEs) approximating the gradient descent trajectory. It was found that finite step sizes implicitly regularize solutions because terms appearing in the ODEs penalize the two-norm of the loss gradients. We prove that the existence of similar implicit regularization in RMSProp and Adam depends on their hyperparameters and the training stage, but with a different "norm" involved: the corresponding ODE terms either penalize the (perturbed) one-norm of the loss gradients or, on the contrary, hinder its decrease (the latter case being typical). We also conduct numerical experiments and discuss how the proven facts can influence generalization.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#25581;&#31034;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#26500;&#24314;&#20013;&#30340;&#26679;&#26412;&#25286;&#20998;&#26041;&#27861;&#30340;&#22885;&#31192;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#26469;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#20174;&#26679;&#26412;&#25286;&#20998;&#20013;&#24471;&#21040;&#30340;&#26368;&#20248;&#36229;&#21442;&#25968;&#21487;&#20197;&#20351;&#24471;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#26368;&#23567;&#21270;&#39044;&#27979;&#39118;&#38505;&#12290;</title><link>http://arxiv.org/abs/2307.07726</link><description>&lt;p&gt;
&#36808;&#21521;&#26368;&#20248;&#31070;&#32463;&#32593;&#32476;&#65306;&#26679;&#26412;&#25286;&#20998;&#22312;&#36229;&#21442;&#25968;&#36873;&#25321;&#20013;&#30340;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
Towards Optimal Neural Networks: the Role of Sample Splitting in Hyperparameter Selection. (arXiv:2307.07726v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07726
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25581;&#31034;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#26500;&#24314;&#20013;&#30340;&#26679;&#26412;&#25286;&#20998;&#26041;&#27861;&#30340;&#22885;&#31192;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#26469;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#20174;&#26679;&#26412;&#25286;&#20998;&#20013;&#24471;&#21040;&#30340;&#26368;&#20248;&#36229;&#21442;&#25968;&#21487;&#20197;&#20351;&#24471;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#26368;&#23567;&#21270;&#39044;&#27979;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#22312;&#21508;&#20010;&#39046;&#22495;&#23637;&#29616;&#20986;&#21331;&#36234;&#30340;&#23454;&#36341;&#25104;&#21151;&#26102;&#65292;&#20851;&#20110;&#23427;&#20204;&#30340;&#29702;&#35770;&#29305;&#24615;&#65292;&#22914;&#36924;&#36817;&#33021;&#21147;&#12289;&#32479;&#35745;&#24615;&#36136;&#21644;&#27867;&#21270;&#24615;&#33021;&#31561;&#30340;&#30740;&#31350;&#20063;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#25581;&#31034;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#26500;&#24314;&#20013;&#19968;&#31181;&#24120;&#35265;&#23454;&#36341;&#32972;&#21518;&#30340;&#22885;&#31192;&#65306;&#26679;&#26412;&#25286;&#20998;&#65292;&#26500;&#24314;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#29702;&#35770;&#26469;&#29702;&#35299;&#31070;&#32463;&#32593;&#32476;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#35777;&#26126;&#65292;&#20174;&#26679;&#26412;&#25286;&#20998;&#20013;&#24471;&#21040;&#30340;&#26368;&#20248;&#36229;&#21442;&#25968;&#21487;&#20197;&#20351;&#24471;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#28176;&#36827;&#22320;&#26368;&#23567;&#21270;&#39044;&#27979;&#39118;&#38505;&#12290;&#25105;&#20204;&#22312;&#19981;&#21516;&#30340;&#24212;&#29992;&#22330;&#26223;&#21644;&#32593;&#32476;&#32467;&#26500;&#20013;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#65292;&#23454;&#39564;&#32467;&#26524;&#35777;&#23454;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
When artificial neural networks have demonstrated exceptional practical success in a variety of domains, investigations into their theoretical characteristics, such as their approximation power, statistical properties, and generalization performance, have made significant strides. In this paper, we construct a novel theory for understanding the effectiveness of neural networks by discovering the mystery underlying a common practice during neural network model construction: sample splitting. Our theory demonstrates that, the optimal hyperparameters derived from sample splitting can enable a neural network model that asymptotically minimizes the prediction risk. We conduct extensive experiments across different application scenarios and network architectures, and the results manifest our theory's effectiveness.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#38543;&#26426;&#39640;&#26031;&#26435;&#37325;&#21644;&#20559;&#32622;&#30340;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#24067;&#65292;&#24471;&#21040;&#20102;&#22312;&#22823;&#20294;&#26377;&#38480;&#30340; $n$ &#21644;&#20219;&#24847;&#22266;&#23450;&#32593;&#32476;&#28145;&#24230;&#19979;&#25104;&#31435;&#30340;&#27491;&#24577;&#36924;&#36817;&#30340;&#23450;&#37327;&#30028;&#38480;&#65292;&#35777;&#26126;&#20102;&#38543;&#26426;&#20840;&#36830;&#25509;&#32593;&#32476;&#19982;&#30456;&#24212;&#30340;&#26080;&#38480;&#23485;&#39640;&#26031;&#36807;&#31243;&#20043;&#38388;&#30340;&#36317;&#31163;&#25353;&#29031; $n^{-\gamma}$ &#32553;&#25918;&#65292;&#30028;&#38480;&#22312;&#32593;&#32476;&#23485;&#24230;&#30340;&#20381;&#36182;&#24615;&#26041;&#38754;&#20248;&#20110;&#20197;&#21069;&#30340;&#30740;&#31350;&#12290;</title><link>http://arxiv.org/abs/2307.06092</link><description>&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#23450;&#37327;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;
&lt;/p&gt;
&lt;p&gt;
Quantitative CLTs in Deep Neural Networks. (arXiv:2307.06092v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06092
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#38543;&#26426;&#39640;&#26031;&#26435;&#37325;&#21644;&#20559;&#32622;&#30340;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#24067;&#65292;&#24471;&#21040;&#20102;&#22312;&#22823;&#20294;&#26377;&#38480;&#30340; $n$ &#21644;&#20219;&#24847;&#22266;&#23450;&#32593;&#32476;&#28145;&#24230;&#19979;&#25104;&#31435;&#30340;&#27491;&#24577;&#36924;&#36817;&#30340;&#23450;&#37327;&#30028;&#38480;&#65292;&#35777;&#26126;&#20102;&#38543;&#26426;&#20840;&#36830;&#25509;&#32593;&#32476;&#19982;&#30456;&#24212;&#30340;&#26080;&#38480;&#23485;&#39640;&#26031;&#36807;&#31243;&#20043;&#38388;&#30340;&#36317;&#31163;&#25353;&#29031; $n^{-\gamma}$ &#32553;&#25918;&#65292;&#30028;&#38480;&#22312;&#32593;&#32476;&#23485;&#24230;&#30340;&#20381;&#36182;&#24615;&#26041;&#38754;&#20248;&#20110;&#20197;&#21069;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#38543;&#26426;&#39640;&#26031;&#26435;&#37325;&#21644;&#20559;&#32622;&#30340;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#24067;&#65292;&#20854;&#20013;&#38544;&#34255;&#23618;&#23485;&#24230;&#19982;&#22823;&#24120;&#25968; $n$ &#25104;&#27604;&#20363;&#12290;&#22312;&#38750;&#32447;&#24615;&#30340;&#28201;&#21644;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#22312;&#22823;&#20294;&#26377;&#38480;&#30340; $n$ &#21644;&#20219;&#24847;&#22266;&#23450;&#32593;&#32476;&#28145;&#24230;&#19979;&#25104;&#31435;&#30340;&#27491;&#24577;&#36924;&#36817;&#30340;&#23450;&#37327;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#23450;&#29702;&#34920;&#26126;&#65292;&#26080;&#35770;&#26159;&#23545;&#20110;&#26377;&#38480;&#32500;&#20998;&#24067;&#36824;&#26159;&#25972;&#20010;&#36807;&#31243;&#65292;&#38543;&#26426;&#20840;&#36830;&#25509;&#32593;&#32476;&#65288;&#21450;&#20854;&#23548;&#25968;&#65289;&#19982;&#30456;&#24212;&#30340;&#26080;&#38480;&#23485;&#39640;&#26031;&#36807;&#31243;&#20043;&#38388;&#30340;&#36317;&#31163;&#37117;&#20250;&#25353;&#29031; $n^{-\gamma}$ &#32553;&#25918;&#65292;&#20854;&#20013; $\gamma&gt;0$&#65292;&#25351;&#25968;&#21462;&#20915;&#20110;&#29992;&#20110;&#24230;&#37327;&#24046;&#24322;&#30340;&#24230;&#37327;&#26041;&#24335;&#12290;&#25105;&#20204;&#30340;&#30028;&#38480;&#22312;&#32593;&#32476;&#23485;&#24230;&#30340;&#20381;&#36182;&#24615;&#26041;&#38754;&#27604;&#25991;&#29486;&#20013;&#20197;&#21069;&#25552;&#20379;&#30340;&#20219;&#20309;&#30028;&#38480;&#37117;&#35201;&#24378;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the distribution of a fully connected neural network with random Gaussian weights and biases in which the hidden layer widths are proportional to a large constant $n$. Under mild assumptions on the non-linearity, we obtain quantitative bounds on normal approximations valid at large but finite $n$ and any fixed network depth. Our theorems show, both for the finite-dimensional distributions and the entire process, that the distance between a random fully connected network (and its derivatives) to the corresponding infinite width Gaussian process scales like $n^{-\gamma}$ for $\gamma&gt;0,$ with the exponent depending on the metric used to measure discrepancy. Our bounds are stronger in terms of their dependence on network width than any previously available in the literature.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#25968;&#23398;&#20998;&#26512;&#35777;&#26126;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#24182;&#19981;&#33021;&#35299;&#20915;&#24179;&#28369;&#36807;&#24230;&#38382;&#39064;&#65292;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#38656;&#35201;&#26356;&#22810;&#20851;&#27880;&#19981;&#23545;&#31216;&#12289;&#29366;&#24577;&#30456;&#20851;&#21644;&#26377;&#21521;&#22270;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2305.16102</link><description>&lt;p&gt;
&#25581;&#31034;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#24179;&#28369;&#36807;&#24230;&#29616;&#35937;
&lt;/p&gt;
&lt;p&gt;
Demystifying Oversmoothing in Attention-Based Graph Neural Networks. (arXiv:2305.16102v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16102
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25968;&#23398;&#20998;&#26512;&#35777;&#26126;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#24182;&#19981;&#33021;&#35299;&#20915;&#24179;&#28369;&#36807;&#24230;&#38382;&#39064;&#65292;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#38656;&#35201;&#26356;&#22810;&#20851;&#27880;&#19981;&#23545;&#31216;&#12289;&#29366;&#24577;&#30456;&#20851;&#21644;&#26377;&#21521;&#22270;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#24179;&#28369;&#36807;&#24230;&#25351;&#30340;&#26159;&#22686;&#21152;&#32593;&#32476;&#28145;&#24230;&#23548;&#33268;&#33410;&#28857;&#34920;&#31034;&#21464;&#24471;&#30456;&#21516;&#30340;&#29616;&#35937;&#12290;&#23613;&#31649;&#20043;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#35777;&#23454;&#20102;&#22270;&#21367;&#31215;&#32593;&#32476;(GCN)&#20250;&#25351;&#25968;&#32423;&#22833;&#21435;&#34920;&#36798;&#33021;&#21147;&#65292;&#20294;&#26159;&#22270;&#27880;&#24847;&#21147;&#26426;&#21046;&#26159;&#21542;&#21487;&#20197;&#32531;&#35299;&#24179;&#28369;&#36807;&#24230;&#38382;&#39064;&#36824;&#23384;&#22312;&#20105;&#35758;&#12290;&#26412;&#25991;&#36890;&#36807;&#23558;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#35270;&#20026;&#38750;&#32447;&#24615;&#26102;&#21464;&#21160;&#24577;&#31995;&#32479;&#65292;&#24182;&#32467;&#21512;&#38750;&#40784;&#27425;&#30697;&#38453;&#20056;&#31215;&#21644;&#32852;&#21512;&#35889;&#21322;&#24452;&#29702;&#35770;&#30340;&#24037;&#20855;&#21644;&#25216;&#26415;&#65292;&#23545;&#36825;&#20010;&#38382;&#39064;&#36827;&#34892;&#20102;&#20005;&#26684;&#30340;&#25968;&#23398;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26126;&#30830;&#30340;&#31572;&#26696;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#19982;&#27969;&#34892;&#35266;&#28857;&#30456;&#21453;&#65292;&#22270;&#27880;&#24847;&#21147;&#26426;&#21046;&#19981;&#33021;&#38450;&#27490;&#24179;&#28369;&#36807;&#24230;&#29616;&#35937;&#65292;&#24182;&#19988;&#21576;&#25351;&#25968;&#32423;&#22833;&#21435;&#34920;&#36798;&#33021;&#21147;&#12290;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#23558;&#23545;&#31216;GCN&#30340;&#24179;&#28369;&#36807;&#24230;&#38382;&#39064;&#25193;&#23637;&#21040;&#20102;&#26356;&#24191;&#27867;&#30340;GNN&#27169;&#22411;&#31867;&#21035;&#20013;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#32771;&#34385;&#20102;&#22312;&#29616;&#23454;&#24212;&#29992;&#20013;&#26222;&#36941;&#23384;&#22312;&#30340;&#19981;&#23545;&#31216;&#12289;&#29366;&#24577;&#30456;&#20851;&#21644;&#26377;&#21521;&#22270;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
Oversmoothing in Graph Neural Networks (GNNs) refers to the phenomenon where increasing network depth leads to homogeneous node representations. While previous work has established that Graph Convolutional Networks (GCNs) exponentially lose expressive power, it remains controversial whether the graph attention mechanism can mitigate oversmoothing. In this work, we provide a definitive answer to this question through a rigorous mathematical analysis, by viewing attention-based GNNs as nonlinear time-varying dynamical systems and incorporating tools and techniques from the theory of products of inhomogeneous matrices and the joint spectral radius. We establish that, contrary to popular belief, the graph attention mechanism cannot prevent oversmoothing and loses expressive power exponentially. The proposed framework extends the existing results on oversmoothing for symmetric GCNs to a significantly broader class of GNN models. In particular, our analysis accounts for asymmetric, state-dep
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#39318;&#20010;&#36890;&#29992;&#30340;&#26041;&#27861;&#26469;&#22788;&#29702;&#22522;&#20110;&#27169;&#25311;&#30340;&#25512;&#35770;&#65288;&#22914;ABC&#21644;NPE&#65289;&#20013;&#30001;&#20110;&#27169;&#22411;&#38169;&#35823;&#24341;&#36215;&#30340;&#19981;&#21487;&#38752;&#25512;&#35770;&#12290;&#36890;&#36807;&#32422;&#26463;&#32479;&#35745;&#37327;&#30340;&#36873;&#25321;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#24809;&#32602;&#19982;&#25968;&#25454;&#21644;&#27169;&#22411;&#20043;&#38388;&#19981;&#21305;&#37197;&#30340;&#32479;&#35745;&#37327;&#26469;&#38450;&#27490;&#19981;&#21487;&#38752;&#25512;&#35770;&#32467;&#26524;&#12290;&#25105;&#20204;&#22312;&#39640;&#32500;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#26412;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.15871</link><description>&lt;p&gt;
&#23398;&#20064;&#40065;&#26834;&#32479;&#35745;&#29992;&#20110;&#27169;&#22411;&#38169;&#35823;&#24773;&#20917;&#19979;&#30340;&#22522;&#20110;&#27169;&#25311;&#25512;&#35770;
&lt;/p&gt;
&lt;p&gt;
Learning Robust Statistics for Simulation-based Inference under Model Misspecification. (arXiv:2305.15871v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15871
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#39318;&#20010;&#36890;&#29992;&#30340;&#26041;&#27861;&#26469;&#22788;&#29702;&#22522;&#20110;&#27169;&#25311;&#30340;&#25512;&#35770;&#65288;&#22914;ABC&#21644;NPE&#65289;&#20013;&#30001;&#20110;&#27169;&#22411;&#38169;&#35823;&#24341;&#36215;&#30340;&#19981;&#21487;&#38752;&#25512;&#35770;&#12290;&#36890;&#36807;&#32422;&#26463;&#32479;&#35745;&#37327;&#30340;&#36873;&#25321;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#24809;&#32602;&#19982;&#25968;&#25454;&#21644;&#27169;&#22411;&#20043;&#38388;&#19981;&#21305;&#37197;&#30340;&#32479;&#35745;&#37327;&#26469;&#38450;&#27490;&#19981;&#21487;&#38752;&#25512;&#35770;&#32467;&#26524;&#12290;&#25105;&#20204;&#22312;&#39640;&#32500;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#26412;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#27169;&#25311;&#30340;&#25512;&#35770;&#26041;&#27861;&#65288;&#22914;&#36817;&#20284;&#36125;&#21494;&#26031;&#35745;&#31639;&#65288;ABC&#65289;&#65292;&#21512;&#25104;&#20284;&#28982;&#24615;&#21644;&#31070;&#32463;&#21518;&#39564;&#20272;&#35745;&#65288;NPE&#65289;&#65289;&#20381;&#36182;&#20110;&#27169;&#25311;&#32479;&#35745;&#37327;&#20197;&#25512;&#26029;&#38590;&#20197;&#35745;&#31639;&#30340;&#20284;&#28982;&#27169;&#22411;&#30340;&#21442;&#25968;&#12290;&#28982;&#32780;&#65292;&#24050;&#30693;&#36825;&#31181;&#26041;&#27861;&#22312;&#27169;&#22411;&#38169;&#35823;&#24773;&#20917;&#19979;&#20250;&#20135;&#29983;&#19981;&#21487;&#20449;&#21644;&#35823;&#23548;&#24615;&#30340;&#25512;&#35770;&#32467;&#26524;&#65292;&#20174;&#32780;&#38459;&#30861;&#20102;&#23427;&#20204;&#30340;&#24191;&#27867;&#24212;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#36890;&#29992;&#26041;&#27861;&#26469;&#22788;&#29702;&#36328;&#19981;&#21516;&#31867;&#21035;&#30340;SBI&#26041;&#27861;&#30340;&#27169;&#22411;&#38169;&#35823;&#24773;&#20917;&#12290;&#21033;&#29992;&#32479;&#35745;&#37327;&#30340;&#36873;&#25321;&#30830;&#23450;SBI&#20013;&#30340;&#35823;&#24046;&#31243;&#24230;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#27491;&#21017;&#21270;&#25439;&#22833;&#20989;&#25968;&#65292;&#24809;&#32602;&#37027;&#20123;&#22686;&#21152;&#25968;&#25454;&#21644;&#27169;&#22411;&#20043;&#38388;&#19981;&#21305;&#37197;&#30340;&#32479;&#35745;&#37327;&#12290;&#20197;NPE&#21644;ABC&#20026;&#24212;&#29992;&#26696;&#20363;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20154;&#24037;&#38169;&#35823;&#35268;&#33539;&#21270;&#30340;&#39640;&#32500;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#19978;&#34920;&#29616;&#20986;&#20248;&#36234;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#36824;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#26469;&#33258;&#26080;&#32447;&#30005;&#20256;&#25773;&#39046;&#22495;&#30340;&#23454;&#38469;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Simulation-based inference (SBI) methods such as approximate Bayesian computation (ABC), synthetic likelihood, and neural posterior estimation (NPE) rely on simulating statistics to infer parameters of intractable likelihood models. However, such methods are known to yield untrustworthy and misleading inference outcomes under model misspecification, thus hindering their widespread applicability. In this work, we propose the first general approach to handle model misspecification that works across different classes of SBI methods. Leveraging the fact that the choice of statistics determines the degree of misspecification in SBI, we introduce a regularized loss function that penalises those statistics that increase the mismatch between the data and the model. Taking NPE and ABC as use cases, we demonstrate the superior performance of our method on high-dimensional time-series models that are artificially misspecified. We also apply our method to real data from the field of radio propagat
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#8212;&#8212;&#38750;&#37197;&#23545;&#31070;&#32463;&#34203;&#23450;&#35860;&#26725; (UNSB)&#65292;&#23427;&#32467;&#21512;&#20102;&#34203;&#23450;&#35860;&#26725;&#12289;&#23545;&#25239;&#35757;&#32451;&#21644;&#27491;&#21017;&#21270;&#65292;&#29992;&#20110;&#22312;&#38750;&#37197;&#23545;&#25968;&#25454;&#20043;&#38388;&#23398;&#20064; SDE&#65292;&#24182;&#25104;&#21151;&#35299;&#20915;&#20102;&#35768;&#22810;&#38750;&#37197;&#23545;&#22270;&#20687;&#36716;&#25442;&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2305.15086</link><description>&lt;p&gt;
&#20351;&#29992;&#31070;&#32463;&#34203;&#23450;&#35860;&#26725;&#23454;&#29616;&#38750;&#37197;&#23545;&#22270;&#20687;&#36716;&#25442;
&lt;/p&gt;
&lt;p&gt;
Unpaired Image-to-Image Translation via Neural Schr\"odinger Bridge. (arXiv:2305.15086v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15086
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#8212;&#8212;&#38750;&#37197;&#23545;&#31070;&#32463;&#34203;&#23450;&#35860;&#26725; (UNSB)&#65292;&#23427;&#32467;&#21512;&#20102;&#34203;&#23450;&#35860;&#26725;&#12289;&#23545;&#25239;&#35757;&#32451;&#21644;&#27491;&#21017;&#21270;&#65292;&#29992;&#20110;&#22312;&#38750;&#37197;&#23545;&#25968;&#25454;&#20043;&#38388;&#23398;&#20064; SDE&#65292;&#24182;&#25104;&#21151;&#35299;&#20915;&#20102;&#35768;&#22810;&#38750;&#37197;&#23545;&#22270;&#20687;&#36716;&#25442;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#26159;&#19968;&#31867;&#29983;&#25104;&#27169;&#22411;&#65292;&#23427;&#36890;&#36807;&#27169;&#25311;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;SDE&#65289;&#20174;&#22122;&#22768;&#29983;&#25104;&#25968;&#25454;&#12290;&#23613;&#31649;&#25193;&#25955;&#27169;&#22411;&#22312;&#26368;&#36817;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#20294;&#30001;&#20110;&#39640;&#26031;&#20808;&#39564;&#20551;&#35774;&#65292;&#23427;&#20204;&#22312;&#38750;&#37197;&#23545;&#30340;&#22270;&#20687;&#36716;&#25442;&#20219;&#21153;&#20013;&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;&#34203;&#23450;&#35860;&#26725;&#26159;&#19968;&#31181;&#23398;&#20064; SDE &#20197;&#22312;&#20004;&#20010;&#20219;&#24847;&#20998;&#24067;&#20043;&#38388;&#36716;&#25442;&#30340;&#26041;&#27861;&#65292;&#34987;&#35270;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#19968;&#31181;&#26377;&#21560;&#24341;&#21147;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#36804;&#20170;&#20026;&#27490;&#65292;&#34203;&#23450;&#35860;&#26725;&#27169;&#22411;&#22312;&#39640;&#20998;&#36776;&#29575;&#22270;&#20687;&#20043;&#38388;&#30340;&#38750;&#37197;&#23545;&#36716;&#25442;&#26041;&#38754;&#24182;&#19981;&#25104;&#21151;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#38750;&#37197;&#23545;&#31070;&#32463;&#34203;&#23450;&#35860;&#26725;&#65288;UNSB&#65289;&#65292;&#23427;&#23558;&#34203;&#23450;&#35860;&#26725;&#19982;&#23545;&#25239;&#24615;&#35757;&#32451;&#21644;&#27491;&#21017;&#21270;&#30456;&#32467;&#21512;&#65292;&#20197;&#23398;&#20064;&#38750;&#37197;&#23545;&#25968;&#25454;&#20043;&#38388;&#30340; SDE&#12290;&#25105;&#20204;&#35777;&#26126;&#20102; UNSB &#26159;&#21487;&#20280;&#32553;&#30340;&#65292;&#24182;&#19988;&#25104;&#21151;&#35299;&#20915;&#20102;&#21508;&#31181;&#38750;&#37197;&#23545;&#22270;&#20687;&#36716;&#25442;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models are a powerful class of generative models which simulate stochastic differential equations (SDEs) to generate data from noise. Although diffusion models have achieved remarkable progress in recent years, they have limitations in the unpaired image-to-image translation tasks due to the Gaussian prior assumption. Schr\"odinger Bridge (SB), which learns an SDE to translate between two arbitrary distributions, have risen as an attractive solution to this problem. However, none of SB models so far have been successful at unpaired translation between high-resolution images. In this work, we propose the Unpaired Neural Schr\"odinger Bridge (UNSB), which combines SB with adversarial training and regularization to learn a SB between unpaired data. We demonstrate that UNSB is scalable, and that it successfully solves various unpaired image-to-image translation tasks. Code: \url{https://github.com/cyclomon/UNSB}
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#23567;&#27874;&#22495;&#30340;&#23646;&#24615;&#26041;&#27861;WCAM&#65292;&#33021;&#22815;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#23545;&#22270;&#20687;&#25439;&#22351;&#30340;&#25935;&#24863;&#24615;&#65292;&#30830;&#23450;&#39044;&#27979;&#30340;&#36275;&#22815;&#20449;&#24687;&#65292;&#24182;&#38416;&#26126;&#32553;&#25918;&#22914;&#20309;&#22686;&#21152;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.14979</link><description>&lt;p&gt;
&#23610;&#24230;&#24456;&#37325;&#35201;&#65306;&#22522;&#20110;&#23567;&#27874;&#22495;&#30340;&#23646;&#24615;&#26041;&#27861;&#35299;&#37322;&#27169;&#22411;&#23545;&#22270;&#20687;&#25439;&#22351;&#30340;&#25935;&#24863;&#24615;
&lt;/p&gt;
&lt;p&gt;
Scale Matters: Attribution Meets the Wavelet Domain to Explain Model Sensitivity to Image Corruptions. (arXiv:2305.14979v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14979
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#23567;&#27874;&#22495;&#30340;&#23646;&#24615;&#26041;&#27861;WCAM&#65292;&#33021;&#22815;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#23545;&#22270;&#20687;&#25439;&#22351;&#30340;&#25935;&#24863;&#24615;&#65292;&#30830;&#23450;&#39044;&#27979;&#30340;&#36275;&#22815;&#20449;&#24687;&#65292;&#24182;&#38416;&#26126;&#32553;&#25918;&#22914;&#20309;&#22686;&#21152;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#26041;&#38754;&#34920;&#29616;&#20986;&#20102;&#20986;&#33394;&#30340;&#24615;&#33021;&#65292;&#20294;&#23427;&#20204;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#37096;&#32626;&#30001;&#20110;&#23545;&#22270;&#20687;&#25439;&#22351;&#30340;&#25935;&#24863;&#24615;&#32780;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#29616;&#26377;&#30340;&#23646;&#24615;&#26041;&#27861;&#23545;&#20110;&#35299;&#37322;&#23545;&#22270;&#20687;&#25439;&#22351;&#30340;&#25935;&#24863;&#24615;&#26159;&#26080;&#25928;&#30340;&#65292;&#32780;&#24378;&#20581;&#24615;&#39046;&#22495;&#30340;&#25991;&#29486;&#20165;&#25552;&#20379;&#22522;&#20110;&#27169;&#22411;&#30340;&#35299;&#37322;&#12290;&#28982;&#32780;&#65292;&#22312;&#22270;&#20687;&#25439;&#22351;&#30340;&#24773;&#20917;&#19979;&#65292;&#23457;&#26597;&#27169;&#22411;&#30340;&#34892;&#20026;&#33021;&#21147;&#23545;&#20110;&#25552;&#39640;&#29992;&#25143;&#20449;&#20219;&#33267;&#20851;&#37325;&#35201;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;Wavelet sCale Attribution Method (WCAM)&#65292;&#23427;&#26159;&#20174;&#20687;&#32032;&#22495;&#21040;&#31354;&#38388;&#23610;&#24230;&#22495;&#30340;&#23646;&#24615;&#26041;&#27861;&#30340;&#27010;&#25324;&#12290;&#22312;&#31354;&#38388;&#23610;&#24230;&#22495;&#20013;&#36827;&#34892;&#23646;&#24615;&#25581;&#31034;&#20102;&#27169;&#22411;&#30340;&#20851;&#27880;&#28857;&#21644;&#23610;&#24230;&#12290;&#25105;&#20204;&#23637;&#31034;WCAM&#35299;&#37322;&#20102;&#27169;&#22411;&#22312;&#22270;&#20687;&#30772;&#22351;&#19979;&#30340;&#22833;&#25928;&#65292;&#30830;&#23450;&#20102;&#39044;&#27979;&#30340;&#36275;&#22815;&#20449;&#24687;&#65292;&#24182;&#35299;&#37322;&#20102;&#22914;&#20309;&#36890;&#36807;&#32553;&#25918;&#22686;&#21152;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural networks have shown remarkable performance in computer vision, but their deployment in real-world scenarios is challenging due to their sensitivity to image corruptions. Existing attribution methods are uninformative for explaining the sensitivity to image corruptions, while the literature on robustness only provides model-based explanations. However, the ability to scrutinize models' behavior under image corruptions is crucial to increase the user's trust. Towards this end, we introduce the Wavelet sCale Attribution Method (WCAM), a generalization of attribution from the pixel domain to the space-scale domain. Attribution in the space-scale domain reveals where and on what scales the model focuses. We show that the WCAM explains models' failures under image corruptions, identifies sufficient information for prediction, and explains how zoom-in increases accuracy.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22522;&#20110;&#32422;&#26463;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#20197;&#20462;&#25913;&#36755;&#30005;&#32447;&#36335;&#20445;&#25252;&#35774;&#32622;&#20026;&#25932;&#23545;&#25915;&#20987;&#30340;&#20505;&#36873;&#26041;&#26696;&#65292;&#25506;&#35752;&#20102;&#26368;&#22823;&#21270;&#32423;&#32852;&#32593;&#32476;&#36864;&#21270;&#30340;&#20445;&#25252;&#35774;&#32622;&#35268;&#24459;&#65292;&#21457;&#29616;&#23558;&#25152;&#26377;&#30005;&#32593;&#32447;&#36335;&#30340;&#20445;&#25252;&#35774;&#32622;&#26368;&#22823;&#22833;&#37197;&#24182;&#19981;&#20250;&#23548;&#33268;&#26368;&#22810;&#30340;&#32423;&#32852;&#12290;</title><link>http://arxiv.org/abs/2304.14420</link><description>&lt;p&gt;
&#20351;&#29992;&#32422;&#26463;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#32593;&#32476;&#32423;&#32852;&#28431;&#27934;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Network Cascade Vulnerability using Constrained Bayesian Optimization. (arXiv:2304.14420v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14420
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22522;&#20110;&#32422;&#26463;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#20197;&#20462;&#25913;&#36755;&#30005;&#32447;&#36335;&#20445;&#25252;&#35774;&#32622;&#20026;&#25932;&#23545;&#25915;&#20987;&#30340;&#20505;&#36873;&#26041;&#26696;&#65292;&#25506;&#35752;&#20102;&#26368;&#22823;&#21270;&#32423;&#32852;&#32593;&#32476;&#36864;&#21270;&#30340;&#20445;&#25252;&#35774;&#32622;&#35268;&#24459;&#65292;&#21457;&#29616;&#23558;&#25152;&#26377;&#30005;&#32593;&#32447;&#36335;&#30340;&#20445;&#25252;&#35774;&#32622;&#26368;&#22823;&#22833;&#37197;&#24182;&#19981;&#20250;&#23548;&#33268;&#26368;&#22810;&#30340;&#32423;&#32852;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35780;&#20272;&#30005;&#32593;&#30340;&#33030;&#24369;&#24615;&#24120;&#24120;&#26159;&#36890;&#36807;&#25932;&#25163;&#33021;&#22815;&#23545;&#32593;&#32476;&#36896;&#25104;&#30340;&#25439;&#23475;&#37327;&#26469;&#34913;&#37327;&#30340;&#12290;&#28982;&#32780;&#65292;&#36825;&#26679;&#25915;&#20987;&#30340;&#32423;&#32852;&#24433;&#21709;&#36890;&#24120;&#34987;&#24573;&#35270;&#65292;&#23613;&#31649;&#32423;&#32852;&#26159;&#22823;&#35268;&#27169;&#20572;&#30005;&#30340;&#20027;&#35201;&#21407;&#22240;&#20043;&#19968;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#23558;&#36755;&#30005;&#32447;&#36335;&#20445;&#25252;&#35774;&#32622;&#20462;&#25913;&#20026;&#25932;&#23545;&#25915;&#20987;&#30340;&#20505;&#36873;&#26041;&#26696;&#65292;&#21482;&#35201;&#32593;&#32476;&#24179;&#34913;&#29366;&#24577;&#19981;&#25913;&#21464;&#65292;&#25915;&#20987;&#23601;&#21487;&#20197;&#20445;&#25345;&#19981;&#34987;&#26816;&#27979;&#21040;&#12290;&#36825;&#26500;&#25104;&#20102;&#36125;&#21494;&#26031;&#20248;&#21270;&#36807;&#31243;&#20013;&#30340;&#19968;&#20010;&#40657;&#30418;&#23376;&#20989;&#25968;&#22522;&#30784;&#65292;&#20854;&#30446;&#26631;&#26159;&#25214;&#21040;&#26368;&#22823;&#21270;&#32423;&#32852;&#32593;&#32476;&#36864;&#21270;&#30340;&#20445;&#25252;&#35774;&#32622;&#12290;&#24191;&#27867;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#19982;&#24120;&#35782;&#30456;&#21453;&#65292;&#23558;&#25152;&#26377;&#32593;&#32476;&#32447;&#36335;&#30340;&#20445;&#25252;&#35774;&#32622;&#26368;&#22823;&#22833;&#37197;&#24182;&#19981;&#20250;&#23548;&#33268;&#26368;&#22810;&#30340;&#32423;&#32852;&#12290;&#26356;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#21363;&#20351;&#22312;&#36164;&#28304;&#21463;&#38480;&#30340;&#24773;&#20917;&#19979;&#65292;&#20173;&#28982;&#21487;&#20197;&#25214;&#21040;&#33021;&#22815;&#20135;&#29983;&#19982;&#23454;&#20363;&#30456;&#24403;&#20005;&#37325;&#30340;&#32423;&#32852;&#30340;&#35774;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;
Measures of power grid vulnerability are often assessed by the amount of damage an adversary can exact on the network. However, the cascading impact of such attacks is often overlooked, even though cascades are one of the primary causes of large-scale blackouts. This paper explores modifications of transmission line protection settings as candidates for adversarial attacks, which can remain undetectable as long as the network equilibrium state remains unaltered. This forms the basis of a black-box function in a Bayesian optimization procedure, where the objective is to find protection settings that maximize network degradation due to cascading. Extensive experiments reveal that, against conventional wisdom, maximally misconfiguring the protection settings of all network lines does not cause the most cascading. More surprisingly, even when the degree of misconfiguration is resource constrained, it is still possible to find settings that produce cascades comparable in severity to instanc
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;Transformer&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#23454;&#29616;&#31526;&#21495;&#28040;&#24687;&#20256;&#36882;&#21644;&#20851;&#31995;&#25512;&#29702;&#65292;&#24182;&#36890;&#36807;&#20851;&#31995;&#20132;&#21449;&#27880;&#24847;&#21147;&#26426;&#21046;&#23454;&#29616;&#24863;&#24615;&#29366;&#24577;&#19982;&#25277;&#35937;&#29366;&#24577;&#20043;&#38388;&#30340;&#32465;&#23450;&#12290;</title><link>http://arxiv.org/abs/2304.00195</link><description>&lt;p&gt;
&#25277;&#35937;&#22120;&#65306;&#22522;&#20110;Transformer&#30340;&#31526;&#21495;&#28040;&#24687;&#20256;&#36882;&#21644;&#20851;&#31995;&#25512;&#29702;&#27169;&#22359;
&lt;/p&gt;
&lt;p&gt;
Abstractors: Transformer Modules for Symbolic Message Passing and Relational Reasoning. (arXiv:2304.00195v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.00195
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;Transformer&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#23454;&#29616;&#31526;&#21495;&#28040;&#24687;&#20256;&#36882;&#21644;&#20851;&#31995;&#25512;&#29702;&#65292;&#24182;&#36890;&#36807;&#20851;&#31995;&#20132;&#21449;&#27880;&#24847;&#21147;&#26426;&#21046;&#23454;&#29616;&#24863;&#24615;&#29366;&#24577;&#19982;&#25277;&#35937;&#29366;&#24577;&#20043;&#38388;&#30340;&#32465;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#23558;&#20851;&#31995;&#23398;&#20064;&#36716;&#21270;&#20026;Transformer&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;&#20851;&#31995;&#20132;&#21449;&#27880;&#24847;&#21147;&#26426;&#21046;&#23454;&#29616;&#24863;&#24615;&#29366;&#24577;&#19982;&#25277;&#35937;&#29366;&#24577;&#20043;&#38388;&#30340;&#32465;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;
A framework is proposed that casts relational learning in terms of transformers, implementing binding between sensory states and abstract states with relational cross attention mechanisms.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35745;&#31639;&#26694;&#26550;DMSB&#65292;&#23427;&#21487;&#20197;&#23398;&#20064;&#28385;&#36275;&#26102;&#38388;&#19978;&#20301;&#32622;&#36793;&#38469;&#32422;&#26463;&#30340;&#38543;&#26426;&#31995;&#32479;&#30340;&#24179;&#28369;&#24230;&#37327;&#20540;&#26679;&#26465;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#22810;&#36793;&#38469;&#36712;&#36857;&#25512;&#26029;&#20219;&#21153;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#24615;&#33021;&#20248;&#21183;&#12290;&#21516;&#26102;&#65292;&#35813;&#26694;&#26550;&#36824;&#20026;&#35299;&#20915;&#20855;&#26377;&#21508;&#31181;&#31867;&#22411;&#30340;&#36793;&#38469;&#32422;&#26463;&#30340;&#38543;&#26426;&#36712;&#36857;&#37325;&#24314;&#20219;&#21153;&#25552;&#20379;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#12290;</title><link>http://arxiv.org/abs/2303.01751</link><description>&lt;p&gt;
&#28145;&#21160;&#37327;&#22810;&#37325;&#36793;&#38469;Schr\"odinger&#26725;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Deep Momentum Multi-Marginal Schr\"odinger Bridge. (arXiv:2303.01751v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.01751
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35745;&#31639;&#26694;&#26550;DMSB&#65292;&#23427;&#21487;&#20197;&#23398;&#20064;&#28385;&#36275;&#26102;&#38388;&#19978;&#20301;&#32622;&#36793;&#38469;&#32422;&#26463;&#30340;&#38543;&#26426;&#31995;&#32479;&#30340;&#24179;&#28369;&#24230;&#37327;&#20540;&#26679;&#26465;&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#22810;&#36793;&#38469;&#36712;&#36857;&#25512;&#26029;&#20219;&#21153;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#24615;&#33021;&#20248;&#21183;&#12290;&#21516;&#26102;&#65292;&#35813;&#26694;&#26550;&#36824;&#20026;&#35299;&#20915;&#20855;&#26377;&#21508;&#31181;&#31867;&#22411;&#30340;&#36793;&#38469;&#32422;&#26463;&#30340;&#38543;&#26426;&#36712;&#36857;&#37325;&#24314;&#20219;&#21153;&#25552;&#20379;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31895;&#30053;&#26102;&#38388;&#38388;&#38548;&#19979;&#65292;&#20351;&#29992;&#26410;&#26631;&#35760;&#26679;&#26412;&#20174;&#20998;&#24067;&#20013;&#37325;&#24314;&#20154;&#21475;&#21160;&#24577;&#26159;&#19968;&#20010;&#20851;&#38190;&#30340;&#25361;&#25112;&#12290;&#26368;&#36817;&#30340;&#26041;&#27861;&#22914;&#27969;&#27169;&#22411;&#25110;Schr\"odinger&#26725;&#27169;&#22411;&#34920;&#29616;&#20986;&#35825;&#20154;&#30340;&#24615;&#33021;&#65292;&#20294;&#26159;&#25512;&#26029;&#20986;&#30340;&#26679;&#26412;&#36712;&#36857;&#26410;&#33021;&#35299;&#37322;&#28508;&#22312;&#30340;&#38543;&#26426;&#24615;&#65292;&#25110;&#32773;&#26159;DMSB&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#35745;&#31639;&#26694;&#26550;&#65292;&#23427;&#33021;&#22815;&#23398;&#20064;&#28385;&#36275;&#26102;&#38388;&#19978;&#20301;&#32622;&#36793;&#38469;&#32422;&#26463;&#30340;&#38543;&#26426;&#31995;&#32479;&#30340;&#24179;&#28369;&#24230;&#37327;&#20540;&#26679;&#26465;&#12290;&#36890;&#36807;&#35843;&#25972;&#33879;&#21517;&#30340;Bregman&#36845;&#20195;&#21644;&#23558;&#27604;&#20363;&#25311;&#21512;&#36845;&#20195;&#25193;&#23637;&#21040;&#30456;&#31354;&#38388;&#65292;&#25105;&#20204;&#25104;&#21151;&#22320;&#39640;&#25928;&#22788;&#29702;&#20102;&#39640;&#32500;&#22810;&#36793;&#38469;&#36712;&#36857;&#25512;&#26029;&#20219;&#21153;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#30495;&#23454;&#30340;&#21333;&#32454;&#32990;RNA&#24207;&#21015;&#25968;&#25454;&#38598;&#23454;&#39564;&#20013;&#26174;&#33879;&#20248;&#20110;&#22522;&#32447;&#12290;&#27492;&#22806;&#65292;&#25152;&#25552;&#20986;&#30340;DMSB&#26694;&#26550;&#20026;&#35299;&#20915;&#20855;&#26377;&#21508;&#31181;&#31867;&#22411;&#30340;&#36793;&#38469;&#32422;&#26463;&#30340;&#38543;&#26426;&#36712;&#36857;&#37325;&#24314;&#20219;&#21153;&#25552;&#20379;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is a crucial challenge to reconstruct population dynamics using unlabeled samples from distributions at coarse time intervals. Recent approaches such as flow-based models or Schr\"odinger Bridge (SB) models have demonstrated appealing performance, yet the inferred sample trajectories either fail to account for the underlying stochasticity or are $\underline{D}$eep $\underline{M}$omentum Multi-Marginal $\underline{S}$chr\"odinger $\underline{B}$ridge(DMSB), a novel computational framework that learns the smooth measure-valued spline for stochastic systems that satisfy position marginal constraints across time. By tailoring the celebrated Bregman Iteration and extending the Iteration Proportional Fitting to phase space, we manage to handle high-dimensional multi-marginal trajectory inference tasks efficiently. Our algorithm outperforms baselines significantly, as evidenced by experiments for synthetic datasets and a real-world single-cell RNA sequence dataset. Additionally, the propos
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#21033;&#29992;&#32447;&#24615;&#28151;&#21512;&#25928;&#24212;&#27169;&#22411;&#65288;LMEM&#65289;&#26469;&#20998;&#26512;&#26426;&#22120;&#23398;&#20064;&#24615;&#33021;&#35780;&#20272;&#20998;&#25968;&#65292;&#24182;&#32771;&#34385;&#22810;&#20010;&#26041;&#24046;&#26469;&#28304;&#21450;&#20854;&#19982;&#25968;&#25454;&#29305;&#24615;&#30456;&#20114;&#20316;&#29992;&#65292;&#20174;&#32780;&#35780;&#20272;&#21487;&#38752;&#24615;&#21644;&#21487;&#22797;&#21046;&#24615;&#65292;&#20419;&#36827;&#23545;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#34892;&#20026;&#30340;&#26356;&#20840;&#38754;&#29702;&#35299;&#12290;</title><link>http://arxiv.org/abs/2302.04054</link><description>&lt;p&gt;
&#36861;&#27714;&#26426;&#22120;&#23398;&#20064;&#30740;&#31350;&#30340;&#25512;&#29702;&#22797;&#29616;&#24615;
&lt;/p&gt;
&lt;p&gt;
Towards Inferential Reproducibility of Machine Learning Research. (arXiv:2302.04054v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.04054
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#21033;&#29992;&#32447;&#24615;&#28151;&#21512;&#25928;&#24212;&#27169;&#22411;&#65288;LMEM&#65289;&#26469;&#20998;&#26512;&#26426;&#22120;&#23398;&#20064;&#24615;&#33021;&#35780;&#20272;&#20998;&#25968;&#65292;&#24182;&#32771;&#34385;&#22810;&#20010;&#26041;&#24046;&#26469;&#28304;&#21450;&#20854;&#19982;&#25968;&#25454;&#29305;&#24615;&#30456;&#20114;&#20316;&#29992;&#65292;&#20174;&#32780;&#35780;&#20272;&#21487;&#38752;&#24615;&#21644;&#21487;&#22797;&#21046;&#24615;&#65292;&#20419;&#36827;&#23545;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#34892;&#20026;&#30340;&#26356;&#20840;&#38754;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#35780;&#20272;&#30340;&#21487;&#38752;&#24615;&#8212;&#8212;&#21363;&#22312;&#22797;&#21046;&#30340;&#27169;&#22411;&#35757;&#32451;&#36816;&#34892;&#20013;&#35266;&#23519;&#21040;&#30340;&#35780;&#20272;&#20998;&#25968;&#30340;&#19968;&#33268;&#24615;&#8212;&#8212;&#21463;&#21040;&#20960;&#31181;&#38750;&#30830;&#23450;&#24615;&#26469;&#28304;&#30340;&#24433;&#21709;&#65292;&#21487;&#20197;&#34987;&#35270;&#20026;&#27979;&#37327;&#22122;&#22768;&#12290;&#30446;&#21069;&#30340;&#36235;&#21183;&#26159;&#21435;&#38500;&#22122;&#22768;&#65292;&#20197;&#24378;&#21046;&#30740;&#31350;&#32467;&#26524;&#30340;&#21487;&#22797;&#21046;&#24615;&#65292;&#24573;&#30053;&#20102;&#23454;&#29616;&#23618;&#38754;&#22266;&#26377;&#30340;&#38750;&#30830;&#23450;&#24615;&#20197;&#21450;&#31639;&#27861;&#22122;&#22768;&#22240;&#32032;&#21644;&#25968;&#25454;&#29305;&#24615;&#20043;&#38388;&#30340;&#20851;&#38190;&#30456;&#20114;&#20316;&#29992;&#25928;&#24212;&#12290;&#36825;&#38480;&#21046;&#20102;&#20174;&#36825;&#20123;&#23454;&#39564;&#20013;&#21487;&#20197;&#24471;&#20986;&#30340;&#32467;&#35770;&#33539;&#22260;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#26159;&#23558;&#20960;&#20010;&#26041;&#24046;&#26469;&#28304;&#65292;&#21253;&#25324;&#23427;&#20204;&#19982;&#25968;&#25454;&#29305;&#24615;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#32435;&#20837;&#26426;&#22120;&#23398;&#20064;&#35780;&#20272;&#30340;&#26174;&#33879;&#24615;&#21644;&#21487;&#38752;&#24615;&#20998;&#26512;&#20013;&#65292;&#20197;&#26399;&#20174;&#35757;&#32451;&#27169;&#22411;&#30340;&#29305;&#23450;&#23454;&#20363;&#24471;&#20986;&#25512;&#29702;&#32467;&#35770;, &#32780;&#38750;&#21435;&#38500;&#22122;&#22768;&#12290;&#25105;&#20204;&#23637;&#31034;&#22914;&#20309;&#20351;&#29992;&#32447;&#24615;&#28151;&#21512;&#25928;&#24212;&#27169;&#22411;&#65288;LMEM&#65289;&#26469;&#20998;&#26512;&#24615;&#33021;&#35780;&#20272;&#20998;&#25968;&#65292;&#24182;&#29992;&#24191;&#20041;&#20284;&#28982;&#27604;&#26816;&#39564;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;&#19968;&#31181;&#31995;&#32479;&#30340;&#26041;&#24335;&#26469;&#32771;&#34385;&#31639;&#27861;&#21644;&#25968;&#25454;&#30456;&#20851;&#30340;&#22122;&#22768;&#26469;&#28304;&#65292;&#24182;&#20351;&#25105;&#20204;&#33021;&#22815;&#37327;&#21270;&#21508;&#20010;&#26041;&#24046;&#26469;&#28304;&#23545;&#26426;&#22120;&#23398;&#20064;&#23454;&#39564;&#30340;&#21487;&#38752;&#24615;&#21644;&#21487;&#22797;&#21046;&#24615;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#22312;&#19968;&#31995;&#21015;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#28436;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#65292;&#24182;&#35828;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22914;&#20309;&#20419;&#36827;&#23545;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#34892;&#20026;&#30340;&#26356;&#20840;&#38754;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reliability of machine learning evaluation -- the consistency of observed evaluation scores across replicated model training runs -- is affected by several sources of nondeterminism which can be regarded as measurement noise. Current tendencies to remove noise in order to enforce reproducibility of research results neglect inherent nondeterminism at the implementation level and disregard crucial interaction effects between algorithmic noise factors and data properties. This limits the scope of conclusions that can be drawn from such experiments. Instead of removing noise, we propose to incorporate several sources of variance, including their interaction with data properties, into an analysis of significance and reliability of machine learning evaluation, with the aim to draw inferences beyond particular instances of trained models. We show how to use linear mixed effects models (LMEMs) to analyze performance evaluation scores, and to conduct statistical inference with a generalized lik
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24320;&#21457;&#20102;&#38598;&#21512;&#21345;&#23572;&#26364;&#26356;&#26032;&#30340;&#38750;&#28176;&#36817;&#20998;&#26512;&#65292;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#22312;&#20808;&#21069;&#30340;&#21327;&#26041;&#24046;&#20855;&#26377;&#20013;&#31561;&#30340;&#26377;&#25928;&#32500;&#24230;&#12289;&#24555;&#36895;&#35889;&#34928;&#20943;&#25110;&#36817;&#20284;&#31232;&#30095;&#30340;&#24773;&#20917;&#19979;&#65292;&#23567;&#30340;&#38598;&#21512;&#22823;&#23567;&#23601;&#36275;&#22815;&#20102;&#12290;</title><link>http://arxiv.org/abs/2208.03246</link><description>&lt;p&gt;
&#38598;&#21512;&#21345;&#23572;&#26364;&#26356;&#26032;&#30340;&#38750;&#28176;&#36817;&#20998;&#26512;: &#26377;&#25928;&#32500;&#24230;&#21644;&#26412;&#22320;&#21270;
&lt;/p&gt;
&lt;p&gt;
Non-Asymptotic Analysis of Ensemble Kalman Updates: Effective Dimension and Localization. (arXiv:2208.03246v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.03246
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24320;&#21457;&#20102;&#38598;&#21512;&#21345;&#23572;&#26364;&#26356;&#26032;&#30340;&#38750;&#28176;&#36817;&#20998;&#26512;&#65292;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#22312;&#20808;&#21069;&#30340;&#21327;&#26041;&#24046;&#20855;&#26377;&#20013;&#31561;&#30340;&#26377;&#25928;&#32500;&#24230;&#12289;&#24555;&#36895;&#35889;&#34928;&#20943;&#25110;&#36817;&#20284;&#31232;&#30095;&#30340;&#24773;&#20917;&#19979;&#65292;&#23567;&#30340;&#38598;&#21512;&#22823;&#23567;&#23601;&#36275;&#22815;&#20102;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#29992;&#20110;&#21453;&#38382;&#39064;&#21644;&#25968;&#25454;&#21516;&#21270;&#30340;&#29616;&#20195;&#31639;&#27861;&#20381;&#36182;&#20110;&#38598;&#21512;&#21345;&#23572;&#26364;&#26356;&#26032;&#26469;&#23558;&#20808;&#21069;&#30340;&#39044;&#27979;&#32467;&#26524;&#19982;&#35266;&#27979;&#25968;&#25454;&#34701;&#21512;&#12290;&#38598;&#21512;&#21345;&#23572;&#26364;&#26041;&#27861;&#36890;&#24120;&#22312;&#23567;&#38598;&#21512;&#22823;&#23567;&#26102;&#34920;&#29616;&#33391;&#22909;&#65292;&#36825;&#22312;&#29983;&#25104;&#27599;&#20010;&#31890;&#23376;&#24456;&#26114;&#36149;&#30340;&#24212;&#29992;&#20013;&#26159;&#24517;&#35201;&#30340;&#12290;&#26412;&#25991;&#24320;&#21457;&#20102;&#38598;&#21512;&#21345;&#23572;&#26364;&#26356;&#26032;&#30340;&#38750;&#28176;&#36817;&#20998;&#26512;&#65292;&#20174;&#29702;&#35770;&#19978;&#20005;&#26684;&#35828;&#26126;&#20102;&#20026;&#20160;&#20040;&#22914;&#26524;&#20808;&#21069;&#30340;&#21327;&#26041;&#24046;&#20855;&#26377;&#20013;&#31561;&#30340;&#26377;&#25928;&#32500;&#24230;&#65292;&#24555;&#36895;&#35889;&#34928;&#20943;&#25110;&#36817;&#20284;&#31232;&#30095;&#65292;&#21017;&#23567;&#30340;&#38598;&#21512;&#22823;&#23567;&#23601;&#36275;&#22815;&#20102;&#12290;&#25105;&#20204;&#22312;&#32479;&#19968;&#26694;&#26550;&#19979;&#25552;&#20986;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#65292;&#27604;&#36739;&#20102;&#20351;&#29992;&#25200;&#21160;&#35266;&#27979;&#12289;&#24179;&#26041;&#26681;&#28388;&#27874;&#21644;&#26412;&#22320;&#21270;&#30340;&#38598;&#21512;&#21345;&#23572;&#26364;&#26356;&#26032;&#30340;&#20960;&#31181;&#23454;&#29616;&#12290;&#20316;&#20026;&#25105;&#20204;&#20998;&#26512;&#30340;&#19968;&#37096;&#20998;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#36866;&#29992;&#20110;&#36817;&#20284;&#31232;&#30095;&#30697;&#38453;&#30340;&#26080;&#32500;&#24230;&#21327;&#26041;&#24046;&#20272;&#35745;&#30028;&#38480;&#65292;&#36825;&#21487;&#33021;&#26159;&#29420;&#31435;&#24863;&#20852;&#36259;&#30340;&#20869;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many modern algorithms for inverse problems and data assimilation rely on ensemble Kalman updates to blend prior predictions with observed data. Ensemble Kalman methods often perform well with a small ensemble size, which is essential in applications where generating each particle is costly. This paper develops a non-asymptotic analysis of ensemble Kalman updates that rigorously explains why a small ensemble size suffices if the prior covariance has moderate effective dimension due to fast spectrum decay or approximate sparsity. We present our theory in a unified framework, comparing several implementations of ensemble Kalman updates that use perturbed observations, square root filtering, and localization. As part of our analysis, we develop new dimension-free covariance estimation bounds for approximately sparse matrices that may be of independent interest.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#22270;&#32806;&#21512;&#30340;&#27010;&#29575;&#32479;&#35745;&#26694;&#26550;&#65292;&#26469;&#32479;&#19968;&#29702;&#35299;&#19981;&#21516;&#30340;&#38477;&#32500;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#29616;&#26377;&#26041;&#27861;&#22312;&#20445;&#30041;&#31895;&#31890;&#24230;&#20381;&#36182;&#24615;&#26041;&#38754;&#23384;&#22312;&#32479;&#35745;&#19981;&#36275;&#12290;&#36890;&#36807;&#23545;&#27169;&#22411;&#36827;&#34892;&#25913;&#36827;&#21644;&#25193;&#23637;&#65292;&#25105;&#20204;&#33021;&#22815;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#24182;&#19982;&#20854;&#20182;&#38477;&#32500;&#26041;&#27861;&#24314;&#31435;&#20102;&#26032;&#30340;&#32852;&#31995;&#12290;</title><link>http://arxiv.org/abs/2201.13053</link><description>&lt;p&gt;
&#38477;&#32500;&#30340;&#27010;&#29575;&#22270;&#32806;&#21512;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
A Probabilistic Graph Coupling View of Dimension Reduction. (arXiv:2201.13053v3 [math.PR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.13053
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#22270;&#32806;&#21512;&#30340;&#27010;&#29575;&#32479;&#35745;&#26694;&#26550;&#65292;&#26469;&#32479;&#19968;&#29702;&#35299;&#19981;&#21516;&#30340;&#38477;&#32500;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#29616;&#26377;&#26041;&#27861;&#22312;&#20445;&#30041;&#31895;&#31890;&#24230;&#20381;&#36182;&#24615;&#26041;&#38754;&#23384;&#22312;&#32479;&#35745;&#19981;&#36275;&#12290;&#36890;&#36807;&#23545;&#27169;&#22411;&#36827;&#34892;&#25913;&#36827;&#21644;&#25193;&#23637;&#65292;&#25105;&#20204;&#33021;&#22815;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#24182;&#19982;&#20854;&#20182;&#38477;&#32500;&#26041;&#27861;&#24314;&#31435;&#20102;&#26032;&#30340;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#27969;&#34892;&#30340;&#38477;&#32500;&#26041;&#27861;&#65288;&#22914;t-SNE&#21644;UMAP&#65289;&#22522;&#20110;&#26368;&#23567;&#21270;&#36755;&#20837;&#21644;&#28508;&#22312;&#31354;&#38388;&#20013;&#25104;&#23545;&#30456;&#20284;&#24230;&#20043;&#38388;&#30340;&#25104;&#26412;&#12290;&#23613;&#31649;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#20294;&#36825;&#20123;&#26041;&#27861;&#32570;&#20047;&#28165;&#26224;&#30340;&#27010;&#29575;&#22522;&#30784;&#65292;&#26080;&#27861;&#23436;&#20840;&#29702;&#35299;&#23427;&#20204;&#30340;&#23646;&#24615;&#21644;&#23616;&#38480;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#22522;&#20110;&#20132;&#21449;&#29109;&#30340;&#38544;&#34255;&#22270;&#32806;&#21512;&#30340;&#32479;&#19968;&#32479;&#35745;&#26694;&#26550;&#12290;&#36825;&#20123;&#22270;&#22312;&#36755;&#20837;&#31354;&#38388;&#21644;&#28508;&#22312;&#31354;&#38388;&#20013;&#30340;&#35266;&#27979;&#20043;&#38388;&#24341;&#20837;&#20102;&#39532;&#23572;&#31185;&#22827;&#38543;&#26426;&#22330;&#20381;&#36182;&#32467;&#26500;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#29616;&#26377;&#30340;&#25104;&#23545;&#30456;&#20284;&#24230;&#38477;&#32500;&#26041;&#27861;&#21487;&#20197;&#20174;&#25105;&#20204;&#30340;&#26694;&#26550;&#20013;&#36890;&#36807;&#23545;&#22270;&#30340;&#20808;&#39564;&#36827;&#34892;&#29305;&#23450;&#36873;&#25321;&#26469;&#26816;&#32034;&#12290;&#27492;&#22806;&#65292;&#36825;&#25581;&#31034;&#20102;&#36825;&#20123;&#26041;&#27861;&#22312;&#20445;&#30041;&#31895;&#31890;&#24230;&#20381;&#36182;&#24615;&#26041;&#38754;&#23384;&#22312;&#32479;&#35745;&#19978;&#30340;&#19981;&#36275;&#65292;&#20174;&#32780;&#35299;&#37322;&#20102;&#24615;&#33021;&#30340;&#19981;&#20339;&#12290;&#25105;&#20204;&#21033;&#29992;&#21644;&#25193;&#23637;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#20197;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#24182;&#23558;&#20854;&#19982;&#25289;&#26222;&#25289;&#26031;&#29305;&#24449;&#26144;&#23556;&#21644;PCA&#24314;&#31435;&#20102;&#26032;&#30340;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most popular dimension reduction (DR) methods like t-SNE and UMAP are based on minimizing a cost between input and latent pairwise similarities. Though widely used, these approaches lack clear probabilistic foundations to enable a full understanding of their properties and limitations. To that extent, we introduce a unifying statistical framework based on the coupling of hidden graphs using cross entropy. These graphs induce a Markov random field dependency structure among the observations in both input and latent spaces. We show that existing pairwise similarity DR methods can be retrieved from our framework with particular choices of priors for the graphs. Moreover this reveals that these methods suffer from a statistical deficiency that explains poor performances in conserving coarse-grain dependencies. Our model is leveraged and extended to address this issue while new links are drawn with Laplacian eigenmaps and PCA.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;WGANs&#30340;1-Wasserstein&#36317;&#31163;&#36827;&#34892;&#20102;&#26368;&#20248;&#21270;&#30740;&#31350;&#65292;&#25581;&#31034;&#20102;&#26679;&#26412;&#22823;&#23567;&#22266;&#23450;&#26102;&#30340;&#26368;&#20248;&#26041;&#26696;&#19982;&#26368;&#23567;&#21270;&#26679;&#26412;&#28857;&#20043;&#38388;&#24179;&#26041;&#27431;&#27663;&#36317;&#31163;&#30340;&#21644;&#26377;&#23494;&#20999;&#20851;&#32852;&#65292;&#21516;&#26102;&#21457;&#29616;&#22312;&#26679;&#26412;&#22823;&#23567;&#36235;&#21521;&#26080;&#31351;&#22823;&#30340;&#24773;&#20917;&#19979;&#65292;WGANs&#33021;&#22815;&#20197;&#32473;&#23450;&#30340;&#25910;&#25947;&#29575;&#26080;&#38480;&#25509;&#36817;&#30446;&#26631;&#20998;&#24067;&#65292;&#21069;&#25552;&#26159;&#29983;&#25104;Lipschitz&#20989;&#25968;&#26063;&#22686;&#38271;&#21512;&#36866;&#12290;</title><link>http://arxiv.org/abs/2201.02824</link><description>&lt;p&gt;
WGANs&#30340;&#26368;&#20248;1-Wasserstein&#36317;&#31163;
&lt;/p&gt;
&lt;p&gt;
Optimal 1-Wasserstein Distance for WGANs. (arXiv:2201.02824v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.02824
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;WGANs&#30340;1-Wasserstein&#36317;&#31163;&#36827;&#34892;&#20102;&#26368;&#20248;&#21270;&#30740;&#31350;&#65292;&#25581;&#31034;&#20102;&#26679;&#26412;&#22823;&#23567;&#22266;&#23450;&#26102;&#30340;&#26368;&#20248;&#26041;&#26696;&#19982;&#26368;&#23567;&#21270;&#26679;&#26412;&#28857;&#20043;&#38388;&#24179;&#26041;&#27431;&#27663;&#36317;&#31163;&#30340;&#21644;&#26377;&#23494;&#20999;&#20851;&#32852;&#65292;&#21516;&#26102;&#21457;&#29616;&#22312;&#26679;&#26412;&#22823;&#23567;&#36235;&#21521;&#26080;&#31351;&#22823;&#30340;&#24773;&#20917;&#19979;&#65292;WGANs&#33021;&#22815;&#20197;&#32473;&#23450;&#30340;&#25910;&#25947;&#29575;&#26080;&#38480;&#25509;&#36817;&#30446;&#26631;&#20998;&#24067;&#65292;&#21069;&#25552;&#26159;&#29983;&#25104;Lipschitz&#20989;&#25968;&#26063;&#22686;&#38271;&#21512;&#36866;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#32972;&#21518;&#30340;&#25968;&#23398;&#21147;&#37327;&#24341;&#21457;&#20102;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#29702;&#35770;&#38382;&#39064;&#12290;&#20026;&#20102;&#34920;&#24449;&#29983;&#25104;&#20998;&#24067;&#30340;&#20960;&#20309;&#29305;&#24615;&#65292;&#25105;&#20204;&#23545;&#26377;&#38480;&#26679;&#26412;&#21644;&#28176;&#36817;&#39046;&#22495;&#20013;&#30340;Wasserstein GANs&#65288;WGANs&#65289;&#36827;&#34892;&#20102;&#24443;&#24213;&#30340;&#20998;&#26512;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#28508;&#31354;&#38388;&#20026;&#21333;&#21464;&#37327;&#30340;&#29305;&#27530;&#24773;&#20917;&#65292;&#24182;&#24471;&#20986;&#20102;&#22312;&#36755;&#20986;&#31354;&#38388;&#32500;&#24230;&#26080;&#20851;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#29305;&#21035;&#34920;&#26126;&#65292;&#23545;&#20110;&#22266;&#23450;&#30340;&#26679;&#26412;&#22823;&#23567;&#65292;&#26368;&#20248;WGANs&#19982;&#36830;&#25509;&#36335;&#24452;&#26368;&#23567;&#21270;&#26679;&#26412;&#28857;&#20043;&#38388;&#30340;&#24179;&#26041;&#27431;&#27663;&#36317;&#31163;&#30340;&#21644;&#23494;&#20999;&#30456;&#20851;&#12290;&#25105;&#20204;&#36824;&#24378;&#35843;&#20102;WGANs&#33021;&#22815;&#20197;&#32473;&#23450;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#24182;&#22312;&#29983;&#25104;&#30340;Lipschitz&#20989;&#25968;&#26063;&#36866;&#24403;&#22686;&#38271;&#30340;&#26465;&#20214;&#19979;&#65292;&#26080;&#38480;&#25509;&#36817;&#65288;&#23545;&#20110;1-Wasserstein&#36317;&#31163;&#65289;&#30446;&#26631;&#20998;&#24067;&#12290;&#25105;&#20204;&#39034;&#20415;&#25512;&#23548;&#20102;&#21322;&#31163;&#25955;&#26368;&#20248;&#36755;&#36816;&#29702;&#35770;&#30340;&#26032;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
The mathematical forces at work behind Generative Adversarial Networks raise challenging theoretical issues. Motivated by the important question of characterizing the geometrical properties of the generated distributions, we provide a thorough analysis of Wasserstein GANs (WGANs) in both the finite sample and asymptotic regimes. We study the specific case where the latent space is univariate and derive results valid regardless of the dimension of the output space. We show in particular that for a fixed sample size, the optimal WGANs are closely linked with connected paths minimizing the sum of the squared Euclidean distances between the sample points. We also highlight the fact that WGANs are able to approach (for the 1-Wasserstein distance) the target distribution as the sample size tends to infinity, at a given convergence rate and provided the family of generative Lipschitz functions grows appropriately. We derive in passing new results on optimal transport theory in the semi-discre
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#27169;&#22411;&#31867;&#21035;&#65292;&#29992;&#20110;&#34920;&#31034;&#20855;&#26377;&#26410;&#35266;&#27979;&#21040;&#30340;&#28151;&#28102;&#22240;&#32032;&#30340;&#26102;&#38388;&#24207;&#21015;&#30340;&#22240;&#26524;&#20851;&#31995;&#21644;&#29420;&#31435;&#24615;&#12290;&#36890;&#36807;&#20351;&#29992;&#36825;&#20123;&#26032;&#30340;&#22270;&#27169;&#22411;&#65292;&#21487;&#20197;&#24471;&#20986;&#26356;&#24378;&#30340;&#22240;&#26524;&#25512;&#26029;&#65292;&#32780;&#26080;&#38656;&#39069;&#22806;&#30340;&#20551;&#35774;&#12290;</title><link>http://arxiv.org/abs/2112.08417</link><description>&lt;p&gt;
&#23545;&#20855;&#26377;&#28508;&#22312;&#28151;&#28102;&#22240;&#32032;&#30340;&#26102;&#38388;&#24207;&#21015;&#36827;&#34892;&#22240;&#26524;&#31062;&#20808;&#22270;&#29305;&#24449;&#21270;
&lt;/p&gt;
&lt;p&gt;
Characterization of causal ancestral graphs for time series with latent confounders. (arXiv:2112.08417v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.08417
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#27169;&#22411;&#31867;&#21035;&#65292;&#29992;&#20110;&#34920;&#31034;&#20855;&#26377;&#26410;&#35266;&#27979;&#21040;&#30340;&#28151;&#28102;&#22240;&#32032;&#30340;&#26102;&#38388;&#24207;&#21015;&#30340;&#22240;&#26524;&#20851;&#31995;&#21644;&#29420;&#31435;&#24615;&#12290;&#36890;&#36807;&#20351;&#29992;&#36825;&#20123;&#26032;&#30340;&#22270;&#27169;&#22411;&#65292;&#21487;&#20197;&#24471;&#20986;&#26356;&#24378;&#30340;&#22240;&#26524;&#25512;&#26029;&#65292;&#32780;&#26080;&#38656;&#39069;&#22806;&#30340;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22270;&#27169;&#22411;&#31867;&#21035;&#65292;&#29992;&#20110;&#34920;&#31034;&#20855;&#26377;&#26410;&#35266;&#27979;&#21040;&#30340;&#28151;&#28102;&#22240;&#32032;&#30340;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#30340;&#26102;&#38388;&#28382;&#21518;&#29305;&#23450;&#30340;&#22240;&#26524;&#20851;&#31995;&#21644;&#29420;&#31435;&#24615;&#12290;&#25105;&#20204;&#23436;&#20840;&#29305;&#24449;&#21270;&#20102;&#36825;&#20123;&#22270;&#65292;&#24182;&#35777;&#26126;&#23427;&#20204;&#26159;&#24403;&#21069;&#20351;&#29992;&#30340;&#27169;&#22411;&#31867;&#21035;&#30340;&#36866;&#24403;&#23376;&#38598;&#12290;&#27491;&#22914;&#25105;&#20204;&#25152;&#23637;&#31034;&#30340;&#65292;&#36890;&#36807;&#20351;&#29992;&#36825;&#20123;&#26032;&#30340;&#22270;&#21487;&#20197;&#24471;&#20986;&#26356;&#24378;&#30340;&#22240;&#26524;&#25512;&#26029;&#65292;&#32780;&#26080;&#38656;&#39069;&#22806;&#30340;&#20551;&#35774;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#34920;&#31034;&#36825;&#20123;&#26032;&#22270;&#30340;&#39532;&#23572;&#21487;&#22827;&#31561;&#20215;&#31867;&#30340;&#22270;&#24418;&#34920;&#31034;&#12290;&#19982;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#25152;&#23398;&#21040;&#30340;&#20869;&#23481;&#30456;&#27604;&#65292;&#36825;&#31181;&#22270;&#24418;&#34920;&#31034;&#21253;&#21547;&#26356;&#22810;&#30340;&#22240;&#26524;&#30693;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we introduce a novel class of graphical models for representing time lag specific causal relationships and independencies of multivariate time series with unobserved confounders. We completely characterize these graphs and show that they constitute proper subsets of the currently employed model classes. As we show, from the novel graphs one can thus draw stronger causal inferences -- without additional assumptions. We further introduce a graphical representation of Markov equivalence classes of the novel graphs. This graphical representation contains more causal knowledge than what current state-of-the-art causal discovery algorithms learn.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;FA-LD&#30340;&#32852;&#37030;&#24179;&#22343;Langevin&#31639;&#27861;&#65292;&#21487;&#20197;&#29992;&#20110;&#20998;&#24067;&#24335;&#23458;&#25143;&#31471;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#22343;&#20540;&#39044;&#27979;&#12290;&#31639;&#27861;&#32771;&#34385;&#20102;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#30340;&#24378;&#23545;&#25968;&#20985;&#20998;&#24067;&#65292;&#24182;&#30740;&#31350;&#20102;&#27880;&#20837;&#22122;&#22768;&#12289;&#38543;&#26426;&#26799;&#24230;&#22122;&#22768;&#12289;&#25968;&#25454;&#24322;&#36136;&#24615;&#21644;&#21464;&#21270;&#30340;&#23398;&#20064;&#29575;&#31561;&#22240;&#32032;&#23545;&#25910;&#25947;&#24615;&#30340;&#24433;&#21709;&#65292;&#20026;&#26368;&#23567;&#21270;&#36890;&#20449;&#24320;&#38144;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2112.05120</link><description>&lt;p&gt;
&#20851;&#20110;&#32852;&#37030;&#24179;&#22343; Langevin &#21160;&#21147;&#23398;&#30340;&#25910;&#25947;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Convergence of Federated Averaging Langevin Dynamics. (arXiv:2112.05120v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.05120
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;FA-LD&#30340;&#32852;&#37030;&#24179;&#22343;Langevin&#31639;&#27861;&#65292;&#21487;&#20197;&#29992;&#20110;&#20998;&#24067;&#24335;&#23458;&#25143;&#31471;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#22343;&#20540;&#39044;&#27979;&#12290;&#31639;&#27861;&#32771;&#34385;&#20102;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#30340;&#24378;&#23545;&#25968;&#20985;&#20998;&#24067;&#65292;&#24182;&#30740;&#31350;&#20102;&#27880;&#20837;&#22122;&#22768;&#12289;&#38543;&#26426;&#26799;&#24230;&#22122;&#22768;&#12289;&#25968;&#25454;&#24322;&#36136;&#24615;&#21644;&#21464;&#21270;&#30340;&#23398;&#20064;&#29575;&#31561;&#22240;&#32032;&#23545;&#25910;&#25947;&#24615;&#30340;&#24433;&#21709;&#65292;&#20026;&#26368;&#23567;&#21270;&#36890;&#20449;&#24320;&#38144;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20998;&#24067;&#24335;&#23458;&#25143;&#31471;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#22343;&#20540;&#39044;&#27979;&#30340;&#32852;&#37030;&#24179;&#22343; Langevin &#31639;&#27861;&#65288;FA-LD&#65289;&#12290;&#25105;&#20204;&#29305;&#21035;&#32771;&#34385;&#20102;&#19968;&#33324;&#27169;&#22411;&#30340;&#27491;&#24120;&#21518;&#39564;&#20998;&#24067;&#30340;&#25512;&#24191;&#12290;&#25105;&#20204;&#20026; FA-LD &#24320;&#21457;&#20102;&#29702;&#35770;&#20445;&#35777;&#65292;&#38024;&#23545;&#20855;&#26377;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#25968;&#25454;&#30340;&#24378;&#23545;&#25968;&#20985;&#20998;&#24067;&#65292;&#30740;&#31350;&#20102;&#27880;&#20837;&#22122;&#22768;&#12289;&#38543;&#26426;&#26799;&#24230;&#22122;&#22768;&#12289;&#25968;&#25454;&#24322;&#36136;&#24615;&#21644;&#21464;&#21270;&#30340;&#23398;&#20064;&#29575;&#23545;&#25910;&#25947;&#24615;&#30340;&#24433;&#21709;&#12290;&#36825;&#26679;&#30340;&#20998;&#26512;&#25581;&#31034;&#20102;&#22312;&#26368;&#23567;&#21270;&#36890;&#20449;&#24320;&#38144;&#26041;&#38754;&#36873;&#25321;&#26412;&#22320;&#26356;&#26032;&#30340;&#26368;&#20339;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#37325;&#35201;&#20043;&#22788;&#22312;&#20110;&#65292;Langevin &#31639;&#27861;&#20013;&#27880;&#20837;&#22122;&#22768;&#19981;&#20250;&#25439;&#23475;&#36890;&#20449;&#25928;&#29575;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22312; FA-LD &#31639;&#27861;&#20013;&#30740;&#31350;&#20102;&#22312;&#19981;&#21516;&#23458;&#25143;&#31471;&#19978;&#20351;&#29992;&#29420;&#31435;&#21644;&#30456;&#20851;&#22122;&#22768;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#22312;&#36890;&#20449;&#12289;&#20934;&#30830;&#24615;&#21644;&#25968;&#25454;&#38544;&#31169;&#20043;&#38388;&#23384;&#22312;&#30528;&#26435;&#34913;&#12290;&#30001;&#20110;&#26412;&#22320;&#35774;&#22791;&#21487;&#33021;&#22312;&#32852;&#37030;&#32593;&#32476;&#20013;&#21464;&#24471;&#19981;&#27963;&#36291;&#65292;
&lt;/p&gt;
&lt;p&gt;
We propose a federated averaging Langevin algorithm (FA-LD) for uncertainty quantification and mean predictions with distributed clients. In particular, we generalize beyond normal posterior distributions and consider a general class of models. We develop theoretical guarantees for FA-LD for strongly log-concave distributions with non-i.i.d data and study how the injected noise and the stochastic-gradient noise, the heterogeneity of data, and the varying learning rates affect the convergence. Such an analysis sheds light on the optimal choice of local updates to minimize communication costs. Important to our approach is that the communication efficiency does not deteriorate with the injected noise in the Langevin algorithms. In addition, we examine in our FA-LD algorithm both independent and correlated noise used over different clients. We observe there is a trade-off between the pairs among communication, accuracy, and data privacy. As local devices may become inactive in federated ne
&lt;/p&gt;</description></item></channel></rss>