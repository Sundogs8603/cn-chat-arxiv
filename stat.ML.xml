<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26641;&#30340;&#21487;&#21464;&#31995;&#25968;&#27169;&#22411;&#65292;&#20351;&#29992;&#24490;&#29615;&#26799;&#24230;&#25552;&#21319;&#26426;&#36827;&#34892;&#24314;&#27169;&#65292;&#23454;&#29616;&#20102;&#36880;&#32500;&#26089;&#20572;&#21644;&#29305;&#24449;&#37325;&#35201;&#24615;&#35780;&#20998;&#65292;&#35813;&#27169;&#22411;&#33021;&#22815;&#20135;&#29983;&#19982;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;VCM&#30456;&#24403;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2401.05982</link><description>&lt;p&gt;
&#22522;&#20110;&#26641;&#30340;&#21487;&#21464;&#31995;&#25968;&#27169;&#22411;&#20171;&#32461;
&lt;/p&gt;
&lt;p&gt;
A tree-based varying coefficient model. (arXiv:2401.05982v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05982
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26641;&#30340;&#21487;&#21464;&#31995;&#25968;&#27169;&#22411;&#65292;&#20351;&#29992;&#24490;&#29615;&#26799;&#24230;&#25552;&#21319;&#26426;&#36827;&#34892;&#24314;&#27169;&#65292;&#23454;&#29616;&#20102;&#36880;&#32500;&#26089;&#20572;&#21644;&#29305;&#24449;&#37325;&#35201;&#24615;&#35780;&#20998;&#65292;&#35813;&#27169;&#22411;&#33021;&#22815;&#20135;&#29983;&#19982;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;VCM&#30456;&#24403;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26641;&#30340;&#21487;&#21464;&#31995;&#25968;&#27169;&#22411;(VCM)&#65292;&#20854;&#20013;&#21487;&#21464;&#31995;&#25968;&#20351;&#29992;Delong&#31561;&#20154;(2023)&#30340;&#24490;&#29615;&#26799;&#24230;&#25552;&#21319;&#26426;(CGBM)&#36827;&#34892;&#24314;&#27169;&#12290;&#20351;&#29992;CGBM&#23545;&#31995;&#25968;&#20989;&#25968;&#36827;&#34892;&#24314;&#27169;&#65292;&#21487;&#20197;&#36827;&#34892;&#36880;&#32500;&#26089;&#20572;&#21644;&#29305;&#24449;&#37325;&#35201;&#24615;&#35780;&#20998;&#12290;&#36880;&#32500;&#26089;&#20572;&#19981;&#20165;&#21487;&#20197;&#20943;&#23569;&#32500;&#24230;&#29305;&#23450;&#30340;&#36807;&#25311;&#21512;&#39118;&#38505;&#65292;&#36824;&#21487;&#20197;&#25581;&#31034;&#32500;&#24230;&#20043;&#38388;&#27169;&#22411;&#22797;&#26434;&#24615;&#30340;&#24046;&#24322;&#12290;&#20351;&#29992;&#29305;&#24449;&#37325;&#35201;&#24615;&#35780;&#20998;&#21487;&#20197;&#36827;&#34892;&#31616;&#21333;&#30340;&#29305;&#24449;&#36873;&#25321;&#21644;&#26131;&#20110;&#35299;&#37322;&#30340;&#27169;&#22411;&#35299;&#37322;&#12290;&#35813;&#27169;&#22411;&#22312;Richman&#21644;W&#252;thrich&#65288;2023&#65289;&#20351;&#29992;&#30340;&#30456;&#21516;&#30340;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#31034;&#20363;&#19978;&#36827;&#34892;&#35780;&#20272;&#65292;&#32467;&#26524;&#34920;&#26126;&#65292;&#23427;&#22312;&#26679;&#26412;&#22806;&#25439;&#22833;&#26041;&#38754;&#20135;&#29983;&#20102;&#19982;&#20182;&#20204;&#30340;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;VCM LocalGLMnet&#30456;&#24403;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
The paper introduces a tree-based varying coefficient model (VCM) where the varying coefficients are modelled using the cyclic gradient boosting machine (CGBM) from Delong et al. (2023). Modelling the coefficient functions using a CGBM allows for dimension-wise early stopping and feature importance scores. The dimension-wise early stopping not only reduces the risk of dimension-specific overfitting, but also reveals differences in model complexity across dimensions. The use of feature importance scores allows for simple feature selection and easy model interpretation. The model is evaluated on the same simulated and real data examples as those used in Richman and W\"uthrich (2023), and the results show that it produces results in terms of out of sample loss that are comparable to those of their neural network-based VCM called LocalGLMnet.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23558;&#27491;&#21017;&#21270;&#27969;&#21644;&#20934;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#36890;&#36807;&#20351;&#29992;&#20934;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#37319;&#26679;&#27969;&#30340;&#21021;&#22987;&#20998;&#24067;&#65292;&#23454;&#29616;&#20102;&#20855;&#26377;&#26174;&#33879;&#26356;&#20302;&#26041;&#24046;&#30340;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2401.05934</link><description>&lt;p&gt;
&#32467;&#21512;&#27491;&#21017;&#21270;&#27969;&#21644;&#20934;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Combining Normalizing Flows and Quasi-Monte Carlo. (arXiv:2401.05934v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05934
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23558;&#27491;&#21017;&#21270;&#27969;&#21644;&#20934;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#36890;&#36807;&#20351;&#29992;&#20934;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#37319;&#26679;&#27969;&#30340;&#21021;&#22987;&#20998;&#24067;&#65292;&#23454;&#29616;&#20102;&#20855;&#26377;&#26174;&#33879;&#26356;&#20302;&#26041;&#24046;&#30340;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#30340;&#26368;&#26032;&#36827;&#23637;&#20419;&#20351;&#20102;&#25913;&#36827;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#65288;&#22914;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#21644;&#37325;&#35201;&#24615;&#37319;&#26679;&#65289;&#30340;&#26032;&#26041;&#27861;&#30340;&#21457;&#23637;&#12290;&#20854;&#20013;&#19968;&#31181;&#26041;&#27861;&#26159;&#27491;&#21017;&#21270;&#27969;&#65292;&#23427;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#36890;&#36807;&#36880;&#28857;&#35780;&#20272;&#26469;&#36817;&#20284;&#20998;&#24067;&#12290;&#27491;&#21017;&#21270;&#27969;&#24050;&#34987;&#35777;&#26126;&#21487;&#20197;&#25552;&#39640;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#21644;&#37325;&#35201;&#24615;&#37319;&#26679;&#30340;&#24615;&#33021;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#65288;&#38543;&#26426;&#65289;&#20934;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#29992;&#20110;&#36827;&#34892;&#25968;&#20540;&#31215;&#20998;&#65292;&#23427;&#20204;&#29992;&#26356;&#22343;&#21248;&#22320;&#35206;&#30422;&#36229;&#31435;&#26041;&#20307;&#30340;&#24207;&#21015;&#21462;&#20195;&#20102;&#33945;&#29305;&#21345;&#27931;&#30340;&#38543;&#26426;&#37319;&#26679;&#65292;&#20174;&#32780;&#20351;&#35823;&#24046;&#30340;&#25910;&#25947;&#36895;&#24230;&#26356;&#24555;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#20934;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#23545;&#27969;&#36827;&#34892;&#21021;&#22987;&#37319;&#26679;&#30340;&#26041;&#24335;&#32467;&#21512;&#20102;&#36825;&#20004;&#31181;&#26041;&#27861;&#12290;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#65292;&#19982;&#20351;&#29992;&#32463;&#20856;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#30340;&#27969;&#30456;&#27604;&#65292;&#36825;&#31181;&#32452;&#21512;&#21487;&#20197;&#23548;&#33268;&#20855;&#26377;&#26174;&#33879;&#26356;&#20302;&#26041;&#24046;&#30340;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advances in machine learning have led to the development of new methods for enhancing Monte Carlo methods such as Markov chain Monte Carlo (MCMC) and importance sampling (IS). One such method is normalizing flows, which use a neural network to approximate a distribution by evaluating it pointwise. Normalizing flows have been shown to improve the performance of MCMC and IS. On the other side, (randomized) quasi-Monte Carlo methods are used to perform numerical integration. They replace the random sampling of Monte Carlo by a sequence which cover the hypercube more uniformly, resulting in better convergence rates for the error that plain Monte Carlo. In this work, we combine these two methods by using quasi-Monte Carlo to sample the initial distribution that is transported by the flow. We demonstrate through numerical experiments that this combination can lead to an estimator with significantly lower variance than if the flow was sampled with a classic Monte Carlo.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;FSFC&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#35299;&#20915;&#20102;&#22312;&#20855;&#26377;&#20998;&#31867;&#21709;&#24212;&#21644;&#32437;&#21521;&#29305;&#24449;&#30340;&#24773;&#20917;&#19979;&#21516;&#26102;&#36827;&#34892;&#21151;&#33021;&#25968;&#25454;&#29305;&#24449;&#36873;&#25321;&#21644;&#20998;&#31867;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2401.05765</link><description>&lt;p&gt;
&#21151;&#33021;&#25968;&#25454;&#20998;&#31867;&#30340;&#29305;&#24449;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Feature Selection for Functional Data Classification. (arXiv:2401.05765v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05765
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;FSFC&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#35299;&#20915;&#20102;&#22312;&#20855;&#26377;&#20998;&#31867;&#21709;&#24212;&#21644;&#32437;&#21521;&#29305;&#24449;&#30340;&#24773;&#20917;&#19979;&#21516;&#26102;&#36827;&#34892;&#21151;&#33021;&#25968;&#25454;&#29305;&#24449;&#36873;&#25321;&#21644;&#20998;&#31867;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21151;&#33021;&#25968;&#25454;&#20998;&#26512;&#24050;&#32463;&#25104;&#20026;&#35768;&#22810;&#38656;&#35201;&#25972;&#21512;&#21644;&#35299;&#37322;&#22797;&#26434;&#25968;&#25454;&#30340;&#24403;&#20195;&#31185;&#23398;&#39046;&#22495;&#20013;&#30340;&#20851;&#38190;&#24037;&#20855;&#12290;&#27492;&#22806;&#65292;&#26032;&#25216;&#26415;&#30340;&#20986;&#29616;&#20419;&#36827;&#20102;&#22823;&#37327;&#32437;&#21521;&#21464;&#37327;&#30340;&#25910;&#38598;&#65292;&#20351;&#24471;&#29305;&#24449;&#36873;&#25321;&#23545;&#20110;&#36991;&#20813;&#36807;&#25311;&#21512;&#21644;&#25552;&#39640;&#39044;&#27979;&#24615;&#33021;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;FSFC&#65288;&#21151;&#33021;&#20998;&#31867;&#29305;&#24449;&#36873;&#25321;&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#35299;&#20915;&#20102;&#22312;&#20855;&#26377;&#20998;&#31867;&#21709;&#24212;&#21644;&#32437;&#21521;&#29305;&#24449;&#30340;&#24773;&#20917;&#19979;&#21516;&#26102;&#36827;&#34892;&#21151;&#33021;&#25968;&#25454;&#29305;&#24449;&#36873;&#25321;&#21644;&#20998;&#31867;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#35299;&#20915;&#20102;&#19968;&#20010;&#26032;&#23450;&#20041;&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#23558;&#36923;&#36753;&#25439;&#22833;&#21644;&#21151;&#33021;&#29305;&#24449;&#32467;&#21512;&#36215;&#26469;&#65292;&#20197;&#35782;&#21035;&#29992;&#20110;&#20998;&#31867;&#30340;&#26368;&#20851;&#38190;&#29305;&#24449;&#12290;&#20026;&#20102;&#35299;&#20915;&#26368;&#23567;&#21270;&#36807;&#31243;&#65292;&#25105;&#20204;&#20351;&#29992;&#21151;&#33021;&#20027;&#25104;&#20998;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#36866;&#24212;&#29256;&#26412;&#30340;&#21452;&#22686;&#24191;Lagrange&#31639;&#27861;&#65292;&#21033;&#29992;&#20102;&#12290;&#12290;&#12290;
&lt;/p&gt;
&lt;p&gt;
Functional data analysis has emerged as a crucial tool in many contemporary scientific domains that require the integration and interpretation of complex data. Moreover, the advent of new technologies has facilitated the collection of a large number of longitudinal variables, making feature selection pivotal for avoiding overfitting and improving prediction performance. This paper introduces a novel methodology called FSFC (Feature Selection for Functional Classification), that addresses the challenge of jointly performing feature selection and classification of functional data in scenarios with categorical responses and longitudinal features. Our approach tackles a newly defined optimization problem that integrates logistic loss and functional features to identify the most crucial features for classification. To address the minimization procedure, we employ functional principal components and develop a new adaptive version of the Dual Augmented Lagrangian algorithm that leverages the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#36890;&#36807;&#26597;&#35810;&#40657;&#30418;&#20989;&#25968;&#26469;&#20272;&#35745;&#24402;&#19968;&#21270;&#24120;&#25968;&#30340;&#38382;&#39064;&#65292;&#21457;&#29616;&#38382;&#39064;&#30340;&#38590;&#24230;&#21462;&#20915;&#20110;&#38382;&#39064;&#21442;&#25968;$\lambda$&#30340;&#22823;&#23567;&#65292;&#24403;$\lambda$&#36235;&#36817;&#20110;&#38646;&#26102;&#31867;&#20284;&#20110;&#36125;&#21494;&#26031;&#31215;&#20998;(BQ)&#65292;&#24403;$\lambda$&#36235;&#36817;&#20110;&#26080;&#31351;&#22823;&#26102;&#31867;&#20284;&#20110;&#36125;&#21494;&#26031;&#20248;&#21270;(BO)&#65292;&#19988;&#36825;&#31181;&#27169;&#24335;&#36866;&#29992;&#20110;&#23384;&#22312;&#22122;&#22768;&#30340;&#24773;&#20917;&#12290;&#32467;&#26524;&#24471;&#21040;&#20102;&#31639;&#27861;&#26080;&#20851;&#30340;&#19979;&#30028;&#21644;&#19978;&#30028;&#30340;&#25903;&#25345;&#65292;&#20197;&#21450;&#27169;&#25311;&#30740;&#31350;&#30340;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2401.05716</link><description>&lt;p&gt;
&#22522;&#20110;&#26680;&#20989;&#25968;&#30340;&#24402;&#19968;&#21270;&#24120;&#25968;&#20272;&#35745;&#65306;&#36830;&#25509;&#36125;&#21494;&#26031;&#31215;&#20998;&#21644;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Kernelized Normalizing Constant Estimation: Bridging Bayesian Quadrature and Bayesian Optimization. (arXiv:2401.05716v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05716
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#36890;&#36807;&#26597;&#35810;&#40657;&#30418;&#20989;&#25968;&#26469;&#20272;&#35745;&#24402;&#19968;&#21270;&#24120;&#25968;&#30340;&#38382;&#39064;&#65292;&#21457;&#29616;&#38382;&#39064;&#30340;&#38590;&#24230;&#21462;&#20915;&#20110;&#38382;&#39064;&#21442;&#25968;$\lambda$&#30340;&#22823;&#23567;&#65292;&#24403;$\lambda$&#36235;&#36817;&#20110;&#38646;&#26102;&#31867;&#20284;&#20110;&#36125;&#21494;&#26031;&#31215;&#20998;(BQ)&#65292;&#24403;$\lambda$&#36235;&#36817;&#20110;&#26080;&#31351;&#22823;&#26102;&#31867;&#20284;&#20110;&#36125;&#21494;&#26031;&#20248;&#21270;(BO)&#65292;&#19988;&#36825;&#31181;&#27169;&#24335;&#36866;&#29992;&#20110;&#23384;&#22312;&#22122;&#22768;&#30340;&#24773;&#20917;&#12290;&#32467;&#26524;&#24471;&#21040;&#20102;&#31639;&#27861;&#26080;&#20851;&#30340;&#19979;&#30028;&#21644;&#19978;&#30028;&#30340;&#25903;&#25345;&#65292;&#20197;&#21450;&#27169;&#25311;&#30740;&#31350;&#30340;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#36890;&#36807;&#40657;&#30418;&#20989;&#25968;&#26597;&#35810;&#26469;&#20272;&#35745;&#24402;&#19968;&#21270;&#24120;&#25968;$\int e^{-\lambda f(x)}dx$&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;$f$&#23646;&#20110;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;(RKHS)&#65292;&#32780;$\lambda$&#26159;&#19968;&#20010;&#38382;&#39064;&#21442;&#25968;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#20026;&#20102;&#22312;&#30456;&#23545;&#35823;&#24046;&#36739;&#23567;&#30340;&#24773;&#20917;&#19979;&#20272;&#35745;&#24402;&#19968;&#21270;&#24120;&#25968;&#65292;&#38590;&#24230;&#30340;&#32423;&#21035;&#21462;&#20915;&#20110;$\lambda$&#30340;&#20540;&#65306;&#24403;$\lambda$&#36235;&#36817;&#20110;&#38646;&#26102;&#65292;&#38382;&#39064;&#31867;&#20284;&#20110;&#36125;&#21494;&#26031;&#31215;&#20998;(BQ)&#65292;&#32780;&#24403;$\lambda$&#36235;&#36817;&#20110;&#26080;&#31351;&#22823;&#26102;&#65292;&#38382;&#39064;&#31867;&#20284;&#20110;&#36125;&#21494;&#26031;&#20248;&#21270;(BO)&#12290;&#26356;&#19968;&#33324;&#22320;&#65292;&#38382;&#39064;&#22312;BQ&#21644;BO&#20043;&#38388;&#21464;&#21270;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#21363;&#20351;&#22312;&#20989;&#25968;&#35780;&#20272;&#23384;&#22312;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#31181;&#27169;&#24335;&#20173;&#28982;&#36866;&#29992;&#65292;&#20026;&#35813;&#20027;&#39064;&#24102;&#26469;&#20102;&#26032;&#30340;&#26041;&#38754;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#24471;&#21040;&#20102;&#31639;&#27861;&#26080;&#20851;&#30340;&#19979;&#30028;&#21644;&#31639;&#27861;&#19978;&#30028;&#30340;&#25903;&#25345;&#65292;&#20197;&#21450;&#22312;&#21508;&#31181;&#22522;&#20934;&#20989;&#25968;&#19978;&#36827;&#34892;&#30340;&#27169;&#25311;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study the problem of estimating the normalizing constant $\int e^{-\lambda f(x)}dx$ through queries to the black-box function $f$, where $f$ belongs to a reproducing kernel Hilbert space (RKHS), and $\lambda$ is a problem parameter. We show that to estimate the normalizing constant within a small relative error, the level of difficulty depends on the value of $\lambda$: When $\lambda$ approaches zero, the problem is similar to Bayesian quadrature (BQ), while when $\lambda$ approaches infinity, the problem is similar to Bayesian optimization (BO). More generally, the problem varies between BQ and BO. We find that this pattern holds true even when the function evaluations are noisy, bringing new aspects to this topic. Our findings are supported by both algorithm-independent lower bounds and algorithmic upper bounds, as well as simulation studies conducted on a variety of benchmark functions.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22686;&#24378;&#24778;&#21916;&#24341;&#23548;&#30340;&#39034;&#24207;&#23398;&#20064;&#26694;&#26550;SurpriseAF-BO&#65292;&#29992;&#20110;&#39044;&#27979;&#29076;&#27744;&#20960;&#20309;&#24418;&#29366;&#12290;&#36825;&#31181;&#26694;&#26550;&#36890;&#36807;&#36845;&#20195;&#33258;&#36866;&#24212;&#23398;&#20064;&#36807;&#31243;&#65292;&#27169;&#25311;&#20102;&#24037;&#33402;&#21442;&#25968;&#19982;&#29076;&#27744;&#29305;&#24615;&#20043;&#38388;&#30340;&#21160;&#21147;&#23398;&#20851;&#31995;&#65292;&#24182;&#22312;&#26377;&#38480;&#25968;&#25454;&#38598;&#26465;&#20214;&#19979;&#36827;&#34892;&#20102;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2401.05579</link><description>&lt;p&gt;
&#38024;&#23545;&#39044;&#27979;&#29076;&#27744;&#20960;&#20309;&#24418;&#29366;&#30340;&#22686;&#24378;&#24778;&#21916;&#24341;&#23548;&#30340;&#39034;&#24207;&#23398;&#20064;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
An Augmented Surprise-guided Sequential Learning Framework for Predicting the Melt Pool Geometry. (arXiv:2401.05579v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05579
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22686;&#24378;&#24778;&#21916;&#24341;&#23548;&#30340;&#39034;&#24207;&#23398;&#20064;&#26694;&#26550;SurpriseAF-BO&#65292;&#29992;&#20110;&#39044;&#27979;&#29076;&#27744;&#20960;&#20309;&#24418;&#29366;&#12290;&#36825;&#31181;&#26694;&#26550;&#36890;&#36807;&#36845;&#20195;&#33258;&#36866;&#24212;&#23398;&#20064;&#36807;&#31243;&#65292;&#27169;&#25311;&#20102;&#24037;&#33402;&#21442;&#25968;&#19982;&#29076;&#27744;&#29305;&#24615;&#20043;&#38388;&#30340;&#21160;&#21147;&#23398;&#20851;&#31995;&#65292;&#24182;&#22312;&#26377;&#38480;&#25968;&#25454;&#38598;&#26465;&#20214;&#19979;&#36827;&#34892;&#20102;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37329;&#23646;&#22686;&#26448;&#21046;&#36896;&#65288;MAM&#65289;&#24050;&#32463;&#37325;&#22609;&#20102;&#21046;&#36896;&#19994;&#65292;&#25552;&#20379;&#20102;&#22797;&#26434;&#35774;&#35745;&#12289;&#26368;&#23567;&#28010;&#36153;&#12289;&#24555;&#36895;&#21407;&#22411;&#12289;&#26448;&#26009;&#22810;&#26679;&#24615;&#21644;&#23450;&#21046;&#35299;&#20915;&#26041;&#26696;&#31561;&#20248;&#21183;&#12290;&#28982;&#32780;&#65292;&#20854;&#22312;&#24037;&#19994;&#20013;&#30340;&#20840;&#38754;&#24212;&#29992;&#38754;&#20020;&#25361;&#25112;&#65292;&#29305;&#21035;&#26159;&#22312;&#30830;&#20445;&#20135;&#21697;&#36136;&#37327;&#30340;&#19968;&#33268;&#24615;&#26041;&#38754;&#12290;MAM&#25104;&#21151;&#30340;&#20851;&#38190;&#22240;&#32032;&#26159;&#29702;&#35299;&#24037;&#33402;&#21442;&#25968;&#19982;&#29076;&#27744;&#29305;&#24615;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#23558;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#34701;&#20837;MAM&#26159;&#24517;&#19981;&#21487;&#23569;&#30340;&#12290;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#34429;&#28982;&#26377;&#25928;&#65292;&#21364;&#20381;&#36182;&#20110;&#22823;&#25968;&#25454;&#38598;&#26469;&#25429;&#25417;&#22797;&#26434;&#20851;&#31995;&#65292;&#32780;&#22312;MAM&#20013;&#65292;&#30001;&#20110;&#38656;&#35201;&#22823;&#37327;&#30340;&#26102;&#38388;&#21644;&#36164;&#28304;&#26469;&#21019;&#24314;&#25968;&#25454;&#38598;&#65292;&#36825;&#26159;&#19968;&#20010;&#37325;&#22823;&#25361;&#25112;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22686;&#24378;&#24778;&#21916;&#24341;&#23548;&#30340;&#39034;&#24207;&#23398;&#20064;&#26694;&#26550;SurpriseAF-BO&#65292;&#26631;&#24535;&#30528;MAM&#30340;&#37325;&#22823;&#36716;&#21464;&#12290;&#35813;&#26694;&#26550;&#37319;&#29992;&#36845;&#20195;&#33258;&#36866;&#24212;&#23398;&#20064;&#36807;&#31243;&#65292;&#23545;&#24037;&#33402;&#21442;&#25968;&#19982;&#29076;&#27744;&#29305;&#24615;&#20043;&#38388;&#30340;&#21160;&#21147;&#23398;&#36827;&#34892;&#24314;&#27169;&#65292;&#24182;&#22312;&#26377;&#38480;&#25968;&#25454;&#38598;&#26465;&#20214;&#19979;&#36827;&#34892;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Metal Additive Manufacturing (MAM) has reshaped the manufacturing industry, offering benefits like intricate design, minimal waste, rapid prototyping, material versatility, and customized solutions. However, its full industry adoption faces hurdles, particularly in achieving consistent product quality. A crucial aspect for MAM's success is understanding the relationship between process parameters and melt pool characteristics. Integrating Artificial Intelligence (AI) into MAM is essential. Traditional machine learning (ML) methods, while effective, depend on large datasets to capture complex relationships, a significant challenge in MAM due to the extensive time and resources required for dataset creation. Our study introduces a novel surprise-guided sequential learning framework, SurpriseAF-BO, signaling a significant shift in MAM. This framework uses an iterative, adaptive learning process, modeling the dynamics between process parameters and melt pool characteristics with limited da
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20351;&#29992;&#20462;&#21098;&#22343;&#20540;&#31867;&#22411;&#30340;&#20013;&#24515;&#28857;&#20272;&#35745;&#30340;&#28151;&#21512;&#32858;&#31867;&#25216;&#26415;&#65292;&#29992;&#20110;&#22312;&#23384;&#22312;&#27425;&#39640;&#26031;&#35823;&#24046;&#30340;&#20013;&#24515;&#28857;&#21608;&#22260;&#20998;&#24067;&#30340;&#24369;&#21021;&#22987;&#21270;&#26465;&#20214;&#19979;&#20135;&#29983;&#26368;&#20248;&#38169;&#35823;&#26631;&#35760;&#20445;&#35777;&#65292;&#24182;&#19988;&#22312;&#23384;&#22312;&#25932;&#23545;&#24322;&#24120;&#20540;&#30340;&#24773;&#20917;&#19979;&#20173;&#28982;&#26377;&#25928;&#12290;</title><link>http://arxiv.org/abs/2401.05574</link><description>&lt;p&gt;
&#36890;&#36807;&#20462;&#21098;&#22343;&#20540;&#30340;&#40065;&#26834;&#32858;&#31867;&#30340;&#19968;&#33324;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
A general theory for robust clustering via trimmed mean. (arXiv:2401.05574v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05574
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20351;&#29992;&#20462;&#21098;&#22343;&#20540;&#31867;&#22411;&#30340;&#20013;&#24515;&#28857;&#20272;&#35745;&#30340;&#28151;&#21512;&#32858;&#31867;&#25216;&#26415;&#65292;&#29992;&#20110;&#22312;&#23384;&#22312;&#27425;&#39640;&#26031;&#35823;&#24046;&#30340;&#20013;&#24515;&#28857;&#21608;&#22260;&#20998;&#24067;&#30340;&#24369;&#21021;&#22987;&#21270;&#26465;&#20214;&#19979;&#20135;&#29983;&#26368;&#20248;&#38169;&#35823;&#26631;&#35760;&#20445;&#35777;&#65292;&#24182;&#19988;&#22312;&#23384;&#22312;&#25932;&#23545;&#24322;&#24120;&#20540;&#30340;&#24773;&#20917;&#19979;&#20173;&#28982;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23384;&#22312;&#24322;&#36136;&#25968;&#25454;&#30340;&#32479;&#35745;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#32858;&#31867;&#26159;&#19968;&#31181;&#22522;&#26412;&#24037;&#20855;&#12290;&#35768;&#22810;&#26368;&#36817;&#30340;&#32467;&#26524;&#20027;&#35201;&#20851;&#27880;&#22312;&#25968;&#25454;&#22260;&#32469;&#24102;&#26377;&#27425;&#39640;&#26031;&#35823;&#24046;&#30340;&#20013;&#24515;&#28857;&#20998;&#24067;&#26102;&#30340;&#26368;&#20248;&#38169;&#35823;&#26631;&#35760;&#20445;&#35777;&#12290;&#28982;&#32780;&#65292;&#38480;&#21046;&#24615;&#30340;&#27425;&#39640;&#26031;&#27169;&#22411;&#22312;&#23454;&#36341;&#20013;&#24120;&#24120;&#26080;&#25928;&#65292;&#22240;&#20026;&#21508;&#31181;&#23454;&#38469;&#24212;&#29992;&#23637;&#31034;&#20102;&#22260;&#32469;&#20013;&#24515;&#28857;&#30340;&#37325;&#23614;&#20998;&#24067;&#25110;&#21463;&#21040;&#21487;&#33021;&#30340;&#25932;&#23545;&#25915;&#20987;&#65292;&#38656;&#35201;&#20855;&#26377;&#40065;&#26834;&#25968;&#25454;&#39537;&#21160;&#21021;&#22987;&#21270;&#30340;&#40065;&#26834;&#32858;&#31867;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#19968;&#31181;&#28151;&#21512;&#32858;&#31867;&#25216;&#26415;&#65292;&#21033;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#22810;&#21464;&#37327;&#20462;&#21098;&#22343;&#20540;&#31867;&#22411;&#30340;&#20013;&#24515;&#28857;&#20272;&#35745;&#65292;&#22312;&#20013;&#24515;&#28857;&#21608;&#22260;&#30340;&#35823;&#24046;&#20998;&#24067;&#30340;&#24369;&#21021;&#22987;&#21270;&#26465;&#20214;&#19979;&#20135;&#29983;&#38169;&#35823;&#26631;&#35760;&#20445;&#35777;&#12290;&#25105;&#20204;&#36824;&#32473;&#20986;&#20102;&#19968;&#20010;&#30456;&#21305;&#37197;&#30340;&#19979;&#30028;&#65292;&#19978;&#30028;&#20381;&#36182;&#20110;&#32858;&#31867;&#30340;&#25968;&#37327;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21363;&#20351;&#22312;&#23384;&#22312;&#25932;&#23545;&#24322;&#24120;&#20540;&#30340;&#24773;&#20917;&#19979;&#20063;&#33021;&#20135;&#29983;&#26368;&#20248;&#38169;&#35823;&#26631;&#35760;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#31616;&#21270;&#20026;&#20122;&#39640;&#26031;&#27169;&#22411;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Clustering is a fundamental tool in statistical machine learning in the presence of heterogeneous data. Many recent results focus primarily on optimal mislabeling guarantees, when data are distributed around centroids with sub-Gaussian errors. Yet, the restrictive sub-Gaussian model is often invalid in practice, since various real-world applications exhibit heavy tail distributions around the centroids or suffer from possible adversarial attacks that call for robust clustering with a robust data-driven initialization. In this paper, we introduce a hybrid clustering technique with a novel multivariate trimmed mean type centroid estimate to produce mislabeling guarantees under a weak initialization condition for general error distributions around the centroids. A matching lower bound is derived, up to factors depending on the number of clusters. In addition, our approach also produces the optimal mislabeling even in the presence of adversarial outliers. Our results reduce to the sub-Gaus
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#26862;&#26519;&#20462;&#21098;&#26041;&#27861;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20860;&#39038;&#38543;&#26426;&#26862;&#26519;&#20934;&#30830;&#24615;&#21644;&#20915;&#31574;&#26641;&#21487;&#35299;&#37322;&#24615;&#30340;&#26041;&#27861;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#22823;&#22810;&#25968;&#24773;&#26223;&#19979;&#65292;&#36825;&#31181;&#26041;&#27861;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#38543;&#26426;&#26862;&#26519;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.05535</link><description>&lt;p&gt;
&#36890;&#36807;&#26862;&#26519;&#20462;&#21098;&#25552;&#39640;&#38543;&#26426;&#26862;&#26519;&#30340;&#20934;&#30830;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;
&lt;/p&gt;
&lt;p&gt;
Improving the Accuracy and Interpretability of Random Forests via Forest Pruning. (arXiv:2401.05535v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05535
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26862;&#26519;&#20462;&#21098;&#26041;&#27861;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20860;&#39038;&#38543;&#26426;&#26862;&#26519;&#20934;&#30830;&#24615;&#21644;&#20915;&#31574;&#26641;&#21487;&#35299;&#37322;&#24615;&#30340;&#26041;&#27861;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#22823;&#22810;&#25968;&#24773;&#26223;&#19979;&#65292;&#36825;&#31181;&#26041;&#27861;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#38543;&#26426;&#26862;&#26519;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25509;&#36817;&#20960;&#21313;&#24180;&#30340;&#21457;&#23637;&#20043;&#21518;&#65292;&#38543;&#26426;&#26862;&#26519;&#20173;&#28982;&#22312;&#21508;&#31181;&#23398;&#20064;&#38382;&#39064;&#20013;&#25552;&#20379;&#26368;&#20808;&#36827;&#30340;&#20934;&#30830;&#24615;&#65292;&#22312;&#36825;&#26041;&#38754;&#36229;&#36234;&#20102;&#20915;&#31574;&#26641;&#29978;&#33267;&#31070;&#32463;&#32593;&#32476;&#31561;&#26367;&#20195;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#12290;&#28982;&#32780;&#65292;&#20316;&#20026;&#19968;&#31181;&#38598;&#25104;&#26041;&#27861;&#65292;&#38543;&#26426;&#26862;&#26519;&#22312;&#35299;&#37322;&#24615;&#26041;&#38754;&#24448;&#24448;&#27604;&#20915;&#31574;&#26641;&#34920;&#29616;&#19981;&#20339;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20107;&#21518;&#26041;&#27861;&#65292;&#26088;&#22312;&#20860;&#39038;&#38543;&#26426;&#26862;&#26519;&#30340;&#20934;&#30830;&#24615;&#21644;&#20915;&#31574;&#26641;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26862;&#26519;&#20462;&#21098;&#26041;&#27861;&#65292;&#20197;&#22312;&#32473;&#23450;&#30340;&#38543;&#26426;&#26862;&#26519;&#20869;&#25214;&#21040;&#26368;&#20339;&#23376;&#26862;&#26519;&#65292;&#28982;&#21518;&#22312;&#36866;&#29992;&#30340;&#24773;&#20917;&#19979;&#23558;&#36873;&#23450;&#30340;&#26641;&#21512;&#24182;&#20026;&#19968;&#26869;&#12290;&#25105;&#20204;&#30340;&#31532;&#19968;&#31181;&#26041;&#27861;&#20381;&#36182;&#20110;&#32422;&#26463;&#31351;&#20030;&#25628;&#32034;&#65292;&#32780;&#31532;&#20108;&#31181;&#26041;&#27861;&#22522;&#20110;LASSO&#26041;&#27861;&#30340;&#25913;&#36827;&#12290;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#22823;&#22810;&#25968;&#24773;&#26223;&#19979;&#65292;&#36825;&#20004;&#31181;&#26041;&#27861;&#20013;&#33267;&#23569;&#26377;&#19968;&#31181;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#38543;&#26426;&#26862;&#26519;&#30340;&#20934;&#30830;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Decades after their inception, random forests continue to provide state-of-the-art accuracy in a variety of learning problems, outperforming in this respect alternative machine learning algorithms such as decision trees or even neural networks. However, being an ensemble method, the one aspect where random forests tend to severely underperform decision trees is interpretability. In the present work, we propose a post-hoc approach that aims to have the best of both worlds: the accuracy of random forests and the interpretability of decision trees. To this end, we present two forest-pruning methods to find an optimal sub-forest within a given random forest, and then, when applicable, combine the selected trees into one. Our first method relies on constrained exhaustive search, while our second method is based on an adaptation of the LASSO methodology. Extensive experiments over synthetic and real world datasets show that, in the majority of scenarios, at least one of the two methods propo
&lt;/p&gt;</description></item><item><title>Holographic Metasurface Transceivers (HMTs) are being used as cost-effective substitutes for large antenna arrays for beamforming in Millimeter and TeraHertz wave communication. In this work, a learning algorithm is developed to optimize beamforming in far-field regions, by using a fixed-budget multi-armed bandit framework to maximize received signal strength. The algorithm exploits the parametric form of channel gains and works with the discrete values of phase-shifting parameters.</title><link>http://arxiv.org/abs/2401.05420</link><description>&lt;p&gt;
HoloBeam:&#23398;&#20064;&#36828;&#22330;&#20840;&#24687;&#20803;&#34920;&#38754;&#25910;&#21457;&#22120;&#20013;&#30340;&#26368;&#20339;&#27874;&#26463;&#25104;&#22411;
&lt;/p&gt;
&lt;p&gt;
HoloBeam: Learning Optimal Beamforming in Far-Field Holographic Metasurface Transceivers. (arXiv:2401.05420v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05420
&lt;/p&gt;
&lt;p&gt;
Holographic Metasurface Transceivers (HMTs) are being used as cost-effective substitutes for large antenna arrays for beamforming in Millimeter and TeraHertz wave communication. In this work, a learning algorithm is developed to optimize beamforming in far-field regions, by using a fixed-budget multi-armed bandit framework to maximize received signal strength. The algorithm exploits the parametric form of channel gains and works with the discrete values of phase-shifting parameters.
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20840;&#24687;&#20803;&#34920;&#38754;&#25910;&#21457;&#22120;&#65288;HMT&#65289;&#27491;&#20197;&#32463;&#27982;&#23454;&#24800;&#30340;&#26041;&#24335;&#25104;&#20026;&#27627;&#31859;&#21644;&#22826;&#36203;&#20857;&#27874;&#36890;&#20449;&#20013;&#27874;&#26463;&#25104;&#22411;&#30340;&#26367;&#20195;&#21697;&#12290;&#28982;&#32780;&#65292;&#22312;HMT&#20013;&#36890;&#36807;&#27874;&#26463;&#25104;&#22411;&#23454;&#29616;&#25152;&#38656;&#20449;&#36947;&#22686;&#30410;&#38656;&#35201;&#36866;&#24403;&#35774;&#32622;&#22823;&#37327;&#20803;&#32032;&#30340;&#30456;&#31227;&#65292;&#36825;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#26368;&#20339;&#30456;&#31227;&#20381;&#36182;&#20110;&#25509;&#25910;&#22120;&#20301;&#32622;&#65292;&#36825;&#21487;&#33021;&#26159;&#26410;&#30693;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;{\it &#22266;&#23450;&#39044;&#31639;&#22810;&#33218;&#32769;&#34382;&#26426;&#31639;&#27861;}&#24320;&#21457;&#20102;&#19968;&#20010;&#23398;&#20064;&#31639;&#27861;&#65292;&#20197;&#22312;&#36828;&#22330;&#21306;&#22495;&#36827;&#34892;&#27874;&#26463;&#25104;&#22411;&#24182;&#26368;&#22823;&#21270;&#25509;&#25910;&#20449;&#21495;&#24378;&#24230;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#21517;&#20026; \Algo&#65292;&#21033;&#29992;&#20102;&#27874;&#26463;&#30340;&#36890;&#36947;&#22686;&#30410;&#21442;&#25968;&#24418;&#24335;&#65292;&#23427;&#21487;&#20197;&#29992;&#20004;&#20010;{\it &#30456;&#31227;&#21442;&#25968;}&#34920;&#31034;&#12290;&#21363;&#20351;&#36827;&#34892;&#21442;&#25968;&#21270;&#65292;&#38382;&#39064;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#22240;&#20026;&#30456;&#31227;&#21442;&#25968;&#37319;&#29992;&#36830;&#32493;&#20540;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#38382;&#39064;&#65292;\HB &#20351;&#29992;&#30456;&#31227;&#21442;&#25968;&#30340;&#31163;&#25955;&#20540;&#24182;&#21033;&#29992;&#20854;&#23376;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
Holographic Metasurface Transceivers (HMTs) are emerging as cost-effective substitutes to large antenna arrays for beamforming in Millimeter and TeraHertz wave communication. However, to achieve desired channel gains through beamforming in HMT, phase-shifts of a large number of elements need to be appropriately set, which is challenging. Also, these optimal phase-shifts depend on the location of the receivers, which could be unknown. In this work, we develop a learning algorithm using a {\it fixed-budget multi-armed bandit framework} to beamform and maximize received signal strength at the receiver for far-field regions. Our algorithm, named \Algo exploits the parametric form of channel gains of the beams, which can be expressed in terms of two {\it phase-shifting parameters}. Even after parameterization, the problem is still challenging as phase-shifting parameters take continuous values. To overcome this, {\it\HB} works with the discrete values of phase-shifting parameters and exploi
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#36845;&#20195;&#27491;&#21017;&#21270;&#31639;&#27861;IRKSN&#65292;&#23427;&#36890;&#36807;&#20351;&#29992;$k$&#25903;&#25745;&#33539;&#25968;&#27491;&#21017;&#21270;&#23454;&#29616;&#31232;&#30095;&#24674;&#22797;&#65292;&#24182;&#25552;&#20379;&#20102;&#26465;&#20214;&#12290;&#36825;&#26159;&#23545;&#22522;&#20110;$\ell_1$&#33539;&#25968;&#30340;&#36845;&#20195;&#26041;&#27861;&#30340;&#19968;&#31181;&#37325;&#35201;&#34917;&#20805;&#12290;</title><link>http://arxiv.org/abs/2401.05394</link><description>&lt;p&gt;
&#36845;&#20195;&#27491;&#21017;&#21270;&#19982;k&#25903;&#25745;&#33539;&#25968;&#65306;&#31232;&#30095;&#24674;&#22797;&#30340;&#37325;&#35201;&#34917;&#20805;
&lt;/p&gt;
&lt;p&gt;
Iterative Regularization with k-Support Norm: an Important Complement to Sparse Recovery. (arXiv:2401.05394v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05394
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#36845;&#20195;&#27491;&#21017;&#21270;&#31639;&#27861;IRKSN&#65292;&#23427;&#36890;&#36807;&#20351;&#29992;$k$&#25903;&#25745;&#33539;&#25968;&#27491;&#21017;&#21270;&#23454;&#29616;&#31232;&#30095;&#24674;&#22797;&#65292;&#24182;&#25552;&#20379;&#20102;&#26465;&#20214;&#12290;&#36825;&#26159;&#23545;&#22522;&#20110;$\ell_1$&#33539;&#25968;&#30340;&#36845;&#20195;&#26041;&#27861;&#30340;&#19968;&#31181;&#37325;&#35201;&#34917;&#20805;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31232;&#30095;&#24674;&#22797;&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#20449;&#21495;&#22788;&#29702;&#20013;&#26080;&#22788;&#19981;&#22312;&#12290;&#30001;&#20110;&#31232;&#30095;&#24674;&#22797;&#30340;NP&#22256;&#38590;&#24615;&#36136;&#65292;&#29616;&#26377;&#26041;&#27861;&#36890;&#24120;&#35201;&#20040;&#21463;&#38480;&#20110;&#36866;&#29992;&#26465;&#20214;&#65288;&#29978;&#33267;&#26410;&#30693;&#65289;&#65292;&#35201;&#20040;&#35745;&#31639;&#25104;&#26412;&#39640;&#12290;&#26368;&#36817;&#65292;&#36845;&#20195;&#27491;&#21017;&#21270;&#26041;&#27861;&#20316;&#20026;&#19968;&#31181;&#24555;&#36895;&#26041;&#27861;&#20986;&#29616;&#65292;&#22240;&#20026;&#23427;&#20204;&#21487;&#20197;&#36890;&#36807;&#25552;&#21069;&#20572;&#27490;&#19968;&#27425;&#36890;&#36807;&#26469;&#23454;&#29616;&#31232;&#30095;&#24674;&#22797;&#65292;&#32780;&#19981;&#26159;&#20256;&#32479;&#26041;&#27861;&#20013;&#32321;&#29712;&#30340;&#32593;&#26684;&#25628;&#32034;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#36825;&#20123;&#36845;&#20195;&#26041;&#27861;&#37117;&#22522;&#20110;$\ell_1$&#33539;&#25968;&#65292;&#38656;&#35201;&#21463;&#38480;&#30340;&#36866;&#29992;&#26465;&#20214;&#65292;&#24182;&#19988;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#21487;&#33021;&#20250;&#22833;&#36133;&#12290;&#22240;&#27492;&#65292;&#36845;&#20195;&#27491;&#21017;&#21270;&#26041;&#27861;&#22312;&#26356;&#24191;&#27867;&#30340;&#26465;&#20214;&#19979;&#23454;&#29616;&#31232;&#30095;&#24674;&#22797;&#20173;&#38656;&#36827;&#19968;&#27493;&#25506;&#32034;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36845;&#20195;&#27491;&#21017;&#21270;&#31639;&#27861;IRKSN&#65292;&#23427;&#22522;&#20110;$k$&#25903;&#25745;&#33539;&#25968;&#27491;&#21017;&#21270;&#32780;&#19981;&#26159;$\ell_1$&#33539;&#25968;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20351;&#29992;IRKSN&#36827;&#34892;&#31232;&#30095;&#24674;&#22797;&#30340;&#26465;&#20214;&#65292;&#24182;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sparse recovery is ubiquitous in machine learning and signal processing. Due to the NP-hard nature of sparse recovery, existing methods are known to suffer either from restrictive (or even unknown) applicability conditions, or high computational cost. Recently, iterative regularization methods have emerged as a promising fast approach because they can achieve sparse recovery in one pass through early stopping, rather than the tedious grid-search used in the traditional methods. However, most of those iterative methods are based on the $\ell_1$ norm which requires restrictive applicability conditions and could fail in many cases. Therefore, achieving sparse recovery with iterative regularization methods under a wider range of conditions has yet to be further explored. To address this issue, we propose a novel iterative regularization algorithm, IRKSN, based on the $k$-support norm regularizer rather than the $\ell_1$ norm. We provide conditions for sparse recovery with IRKSN, and compar
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20581;&#24247;&#24515;&#30005;&#22270;&#25968;&#25454;&#35757;&#32451;&#30340;&#21435;&#22122;&#25193;&#25955;&#29983;&#25104;&#27169;&#22411;&#65292;&#25104;&#21151;&#29983;&#25104;&#36924;&#30495;&#30340;&#24515;&#30005;&#22270;&#20449;&#21495;&#65292;&#24182;&#19988;&#24212;&#29992;&#20110;&#24515;&#33039;&#20581;&#24247;&#30417;&#27979;&#21644;&#35786;&#26029;&#39046;&#22495;&#65292;&#23454;&#29616;&#20102;&#26657;&#27491;QT&#38388;&#26399;&#12289;&#22122;&#22768;&#25233;&#21046;&#12289;&#24515;&#30005;&#22270;&#23548;&#32852;&#24674;&#22797;&#21644;&#24322;&#24120;&#35835;&#25968;&#35782;&#21035;&#31561;&#37325;&#35201;&#20020;&#24202;&#24037;&#20855;&#30340;&#24320;&#21457;&#12290;</title><link>http://arxiv.org/abs/2401.05388</link><description>&lt;p&gt;
&#20351;&#29992;&#21435;&#22122;&#25193;&#25955;&#29983;&#25104;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#24515;&#30005;&#22270;&#37325;&#24314;
&lt;/p&gt;
&lt;p&gt;
Bayesian ECG reconstruction using denoising diffusion generative models. (arXiv:2401.05388v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05388
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20581;&#24247;&#24515;&#30005;&#22270;&#25968;&#25454;&#35757;&#32451;&#30340;&#21435;&#22122;&#25193;&#25955;&#29983;&#25104;&#27169;&#22411;&#65292;&#25104;&#21151;&#29983;&#25104;&#36924;&#30495;&#30340;&#24515;&#30005;&#22270;&#20449;&#21495;&#65292;&#24182;&#19988;&#24212;&#29992;&#20110;&#24515;&#33039;&#20581;&#24247;&#30417;&#27979;&#21644;&#35786;&#26029;&#39046;&#22495;&#65292;&#23454;&#29616;&#20102;&#26657;&#27491;QT&#38388;&#26399;&#12289;&#22122;&#22768;&#25233;&#21046;&#12289;&#24515;&#30005;&#22270;&#23548;&#32852;&#24674;&#22797;&#21644;&#24322;&#24120;&#35835;&#25968;&#35782;&#21035;&#31561;&#37325;&#35201;&#20020;&#24202;&#24037;&#20855;&#30340;&#24320;&#21457;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20581;&#24247;&#24515;&#30005;&#22270;&#25968;&#25454;&#35757;&#32451;&#30340;&#21435;&#22122;&#25193;&#25955;&#29983;&#25104;&#27169;&#22411;&#65288;DDGM&#65289;&#65292;&#35813;&#27169;&#22411;&#20851;&#27880;&#24515;&#30005;&#22270;&#24418;&#24577;&#21644;&#23548;&#32852;&#38388;&#30340;&#30456;&#20851;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#31181;&#21019;&#26032;&#30340;&#29983;&#25104;&#27169;&#22411;&#21487;&#20197;&#25104;&#21151;&#29983;&#25104;&#36924;&#30495;&#30340;&#24515;&#30005;&#22270;&#20449;&#21495;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25506;&#32034;&#20102;&#20351;&#29992;DDGM&#35299;&#20915;&#32447;&#24615;&#21453;&#38382;&#39064;&#30340;&#26368;&#26032;&#31361;&#30772;&#22312;&#24515;&#30005;&#22270;&#37325;&#24314;&#20013;&#30340;&#24212;&#29992;&#65292;&#36825;&#20026;&#21457;&#23637;&#20960;&#31181;&#37325;&#35201;&#30340;&#20020;&#24202;&#24037;&#20855;&#25552;&#20379;&#20102;&#21487;&#33021;&#12290;&#36825;&#20123;&#24037;&#20855;&#21253;&#25324;&#26657;&#27491;QT&#38388;&#26399;(QTc)&#30340;&#35745;&#31639;&#12289;&#24515;&#30005;&#22270;&#20449;&#21495;&#30340;&#26377;&#25928;&#22122;&#22768;&#25233;&#21046;&#12289;&#20002;&#22833;&#30340;&#24515;&#30005;&#22270;&#23548;&#32852;&#30340;&#24674;&#22797;&#20197;&#21450;&#24322;&#24120;&#35835;&#25968;&#30340;&#35782;&#21035;&#65292;&#20174;&#32780;&#22312;&#24515;&#33039;&#20581;&#24247;&#30417;&#27979;&#21644;&#35786;&#26029;&#26041;&#38754;&#21462;&#24471;&#20102;&#37325;&#22823;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we propose a denoising diffusion generative model (DDGM) trained with healthy electrocardiogram (ECG) data that focuses on ECG morphology and inter-lead dependence. Our results show that this innovative generative model can successfully generate realistic ECG signals. Furthermore, we explore the application of recent breakthroughs in solving linear inverse Bayesian problems using DDGM. This approach enables the development of several important clinical tools. These include the calculation of corrected QT intervals (QTc), effective noise suppression of ECG signals, recovery of missing ECG leads, and identification of anomalous readings, enabling significant advances in cardiac health monitoring and diagnosis.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#28145;&#20837;&#20998;&#26512;&#24191;&#20041;&#31561;&#22686;&#36882;&#24402;&#20998;&#21106;&#31639;&#27861;&#65288;GIRP&#65289;&#65292;&#22312;&#21487;&#20998;&#31163;&#20984;&#25439;&#22833;&#21644;&#19981;&#21487;&#24494;&#25439;&#22833;&#30340;&#24773;&#20917;&#19979;&#65292;&#35299;&#20915;&#20102;&#31561;&#22686;&#22238;&#24402;&#38382;&#39064;&#30340;&#23384;&#22312;&#24615;&#21644;&#21807;&#19968;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#36882;&#24402;&#20108;&#20998;&#20998;&#21106;&#30340;&#26041;&#27861;&#26469;&#25214;&#21040;&#35299;&#12290;</title><link>http://arxiv.org/abs/2401.04847</link><description>&lt;p&gt;
&#20851;&#20110;&#24191;&#20041;&#31561;&#22686;&#36882;&#24402;&#20998;&#21106;&#31639;&#27861;&#30340;&#27491;&#30830;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Correctness of the Generalized Isotonic Recursive Partitioning Algorithm. (arXiv:2401.04847v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04847
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#28145;&#20837;&#20998;&#26512;&#24191;&#20041;&#31561;&#22686;&#36882;&#24402;&#20998;&#21106;&#31639;&#27861;&#65288;GIRP&#65289;&#65292;&#22312;&#21487;&#20998;&#31163;&#20984;&#25439;&#22833;&#21644;&#19981;&#21487;&#24494;&#25439;&#22833;&#30340;&#24773;&#20917;&#19979;&#65292;&#35299;&#20915;&#20102;&#31561;&#22686;&#22238;&#24402;&#38382;&#39064;&#30340;&#23384;&#22312;&#24615;&#21644;&#21807;&#19968;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#36882;&#24402;&#20108;&#20998;&#20998;&#21106;&#30340;&#26041;&#27861;&#26469;&#25214;&#21040;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#28145;&#20837;&#20998;&#26512;&#20102;&#24191;&#20041;&#31561;&#22686;&#36882;&#24402;&#20998;&#21106;&#31639;&#27861;&#65288;GIRP&#65289;&#65292;&#35813;&#31639;&#27861;&#29992;&#20110;&#25311;&#21512;&#21487;&#20998;&#31163;&#20984;&#25439;&#22833;&#19979;&#30340;&#31561;&#22686;&#27169;&#22411;&#65292;&#35813;&#31639;&#27861;&#30001;Luss&#21644;Rosset&#25552;&#20986; [J. Comput. Graph. Statist., 23 (2014), pp. 192--201] &#24182;&#30001;Painsky&#21644;Rosset [IEEE Trans. Pattern Anal. Mach. Intell., 38 (2016), pp. 308-321] &#25193;&#23637;&#36866;&#29992;&#20110;&#19981;&#21487;&#24494;&#25439;&#22833;&#12290;GIRP&#31639;&#27861;&#20855;&#26377;&#21560;&#24341;&#20154;&#30340;&#29305;&#28857;&#65292;&#21363;&#22312;&#31639;&#27861;&#30340;&#27599;&#19968;&#27493;&#20013;&#65292;&#20013;&#38388;&#35299;&#28385;&#36275;&#31561;&#22686;&#32422;&#26463;&#12290;&#25991;&#31456;&#20197;&#19968;&#20010;&#20363;&#23376;&#24320;&#22987;&#65292;&#23637;&#31034;&#20102;&#25991;&#29486;&#20013;&#25551;&#36848;&#30340;GIRP&#31639;&#27861;&#21487;&#33021;&#26080;&#27861;&#20135;&#29983;&#31561;&#22686;&#27169;&#22411;&#30340;&#24773;&#20917;&#65292;&#34920;&#26126;&#24517;&#39035;&#20180;&#32454;&#35752;&#35770;&#31561;&#22686;&#22238;&#24402;&#38382;&#39064;&#30340;&#35299;&#30340;&#23384;&#22312;&#24615;&#21644;&#21807;&#19968;&#24615;&#12290;&#25991;&#31456;&#25509;&#30528;&#23637;&#31034;&#65292;&#21487;&#33021;&#23384;&#22312;&#35768;&#22810;&#35299;&#20043;&#19968;&#65292;&#21487;&#20197;&#36890;&#36807;&#23545;&#35266;&#23519;&#25968;&#25454;&#38598;&#36827;&#34892;&#36882;&#24402;&#20108;&#20998;&#20998;&#21106;&#26469;&#25214;&#21040;&#35299;&#12290;&#19968;&#20010;&#23567;&#30340;&#20462;&#25913;
&lt;/p&gt;
&lt;p&gt;
This paper presents an in-depth analysis of the generalized isotonic recursive partitioning (GIRP) algorithm for fitting isotonic models under separable convex losses, proposed by Luss and Rosset [J. Comput. Graph. Statist., 23 (2014), pp. 192--201] for differentiable losses and extended by Painsky and Rosset [IEEE Trans. Pattern Anal. Mach. Intell., 38 (2016), pp. 308-321] for nondifferentiable losses. The GIRP algorithm poseses an attractive feature that in each step of the algorithm, the intermediate solution satisfies the isotonicity constraint. The paper begins with an example showing that the GIRP algorithm as described in the literature may fail to produce an isotonic model, suggesting that the existence and uniqueness of the solution to the isotonic regression problem must be carefully addressed. It proceeds with showing that, among possibly many solutions, there indeed exists a solution that can be found by recursive binary partitioning of the set of observed data. A small mod
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#24773;&#20917;&#19979;&#26816;&#27979;&#21644;&#20998;&#31867;&#33041;&#32959;&#30244;&#65292;&#24182;&#35299;&#20915;&#20102;&#22312;&#32597;&#35265;&#24773;&#20917;&#19979;&#30340;&#32959;&#30244;&#26816;&#27979;&#38382;&#39064;&#12290;&#30740;&#31350;&#20351;&#29992;&#20102;&#26469;&#33258;&#22269;&#23478;&#33041;&#26144;&#23556;&#23454;&#39564;&#23460;&#30340;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#20462;&#25913;&#26679;&#26412;&#25968;&#37327;&#21644;&#24739;&#32773;&#20998;&#24067;&#65292;&#20351;&#27169;&#22411;&#33021;&#22815;&#24212;&#23545;&#30495;&#23454;&#19990;&#30028;&#22330;&#26223;&#20013;&#30340;&#24322;&#24120;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2401.03302</link><description>&lt;p&gt;
&#34892;&#21160;&#20013;&#30340;&#29616;&#23454;&#20027;&#20041;&#65306;&#20351;&#29992;YOLOv8&#21644;DeiT&#20174;&#21307;&#23398;&#22270;&#20687;&#20013;&#35786;&#26029;&#33041;&#32959;&#30244;&#30340;&#24322;&#24120;&#24863;&#30693;
&lt;/p&gt;
&lt;p&gt;
Realism in Action: Anomaly-Aware Diagnosis of Brain Tumors from Medical Images Using YOLOv8 and DeiT. (arXiv:2401.03302v1 [eess.IV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03302
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#24773;&#20917;&#19979;&#26816;&#27979;&#21644;&#20998;&#31867;&#33041;&#32959;&#30244;&#65292;&#24182;&#35299;&#20915;&#20102;&#22312;&#32597;&#35265;&#24773;&#20917;&#19979;&#30340;&#32959;&#30244;&#26816;&#27979;&#38382;&#39064;&#12290;&#30740;&#31350;&#20351;&#29992;&#20102;&#26469;&#33258;&#22269;&#23478;&#33041;&#26144;&#23556;&#23454;&#39564;&#23460;&#30340;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#20462;&#25913;&#26679;&#26412;&#25968;&#37327;&#21644;&#24739;&#32773;&#20998;&#24067;&#65292;&#20351;&#27169;&#22411;&#33021;&#22815;&#24212;&#23545;&#30495;&#23454;&#19990;&#30028;&#22330;&#26223;&#20013;&#30340;&#24322;&#24120;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21307;&#23398;&#31185;&#23398;&#39046;&#22495;&#65292;&#30001;&#20110;&#33041;&#32959;&#30244;&#22312;&#24739;&#32773;&#20013;&#30340;&#32597;&#35265;&#31243;&#24230;&#65292;&#21487;&#38752;&#22320;&#26816;&#27979;&#21644;&#20998;&#31867;&#33041;&#32959;&#30244;&#20173;&#28982;&#26159;&#19968;&#20010;&#33392;&#24040;&#30340;&#25361;&#25112;&#12290;&#22240;&#27492;&#65292;&#22312;&#24322;&#24120;&#24773;&#20917;&#19979;&#26816;&#27979;&#32959;&#30244;&#30340;&#33021;&#21147;&#23545;&#20110;&#30830;&#20445;&#21450;&#26102;&#24178;&#39044;&#21644;&#25913;&#21892;&#24739;&#32773;&#32467;&#26524;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#30740;&#31350;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#24773;&#20917;&#19979;&#26816;&#27979;&#21644;&#20998;&#31867;&#33041;&#32959;&#30244;&#12290;&#26469;&#33258;&#22269;&#23478;&#33041;&#26144;&#23556;&#23454;&#39564;&#23460;&#65288;NBML&#65289;&#30340;&#31934;&#36873;&#25968;&#25454;&#38598;&#21253;&#25324;81&#21517;&#24739;&#32773;&#65292;&#20854;&#20013;&#21253;&#25324;30&#20363;&#32959;&#30244;&#30149;&#20363;&#21644;51&#20363;&#27491;&#24120;&#30149;&#20363;&#12290;&#26816;&#27979;&#21644;&#20998;&#31867;&#27969;&#31243;&#34987;&#20998;&#20026;&#20004;&#20010;&#36830;&#32493;&#30340;&#20219;&#21153;&#12290;&#26816;&#27979;&#38454;&#27573;&#21253;&#25324;&#20840;&#38754;&#30340;&#25968;&#25454;&#20998;&#26512;&#21644;&#39044;&#22788;&#29702;&#65292;&#20197;&#20462;&#25913;&#22270;&#20687;&#26679;&#26412;&#21644;&#27599;&#20010;&#31867;&#21035;&#30340;&#24739;&#32773;&#25968;&#37327;&#65292;&#20197;&#31526;&#21512;&#30495;&#23454;&#19990;&#30028;&#22330;&#26223;&#20013;&#30340;&#24322;&#24120;&#20998;&#24067;&#65288;9&#20010;&#27491;&#24120;&#26679;&#26412;&#23545;&#24212;1&#20010;&#32959;&#30244;&#26679;&#26412;&#65289;&#12290;&#27492;&#22806;&#65292;&#22312;&#27979;&#35797;&#20013;&#38500;&#20102;&#24120;&#35265;&#30340;&#35780;&#20272;&#25351;&#26631;&#22806;&#65292;&#25105;&#20204;&#36824;&#37319;&#29992;&#20102;... [&#25688;&#35201;&#38271;&#24230;&#24050;&#36798;&#21040;&#19978;&#38480;]
&lt;/p&gt;
&lt;p&gt;
In the field of medical sciences, reliable detection and classification of brain tumors from images remains a formidable challenge due to the rarity of tumors within the population of patients. Therefore, the ability to detect tumors in anomaly scenarios is paramount for ensuring timely interventions and improved patient outcomes. This study addresses the issue by leveraging deep learning (DL) techniques to detect and classify brain tumors in challenging situations. The curated data set from the National Brain Mapping Lab (NBML) comprises 81 patients, including 30 Tumor cases and 51 Normal cases. The detection and classification pipelines are separated into two consecutive tasks. The detection phase involved comprehensive data analysis and pre-processing to modify the number of image samples and the number of patients of each class to anomaly distribution (9 Normal per 1 Tumor) to comply with real world scenarios. Next, in addition to common evaluation metrics for the testing, we emplo
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;NLP&#27169;&#22411;&#30340;&#23884;&#20837;&#23618;&#32423;&#36827;&#34892;&#25805;&#20316;&#65292;&#20511;&#37492;&#20102;&#26368;&#26032;&#30340;&#35299;&#37322;&#24615;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#65292;&#36890;&#36807;&#23884;&#20837;&#36716;&#25442;&#26469;&#28040;&#38500;&#38544;&#21547;&#30340;&#25935;&#24863;&#20449;&#24687;&#65292;&#20174;&#32780;&#23454;&#29616;&#27169;&#22411;&#30340;&#20844;&#24179;&#24615;&#12290;</title><link>http://arxiv.org/abs/2312.06499</link><description>&lt;p&gt;
TaCo&#65306;&#36890;&#36807;&#20449;&#24687;&#35770;&#21644;&#21487;&#35299;&#37322;&#24615;&#22312;NLP&#20013;&#30340;&#36755;&#20986;&#23884;&#20837;&#20013;&#23454;&#29616;&#26377;&#38024;&#23545;&#24615;&#30340;&#27010;&#24565;&#21435;&#38500;
&lt;/p&gt;
&lt;p&gt;
TaCo: Targeted Concept Removal in Output Embeddings for NLP via Information Theory and Explainability. (arXiv:2312.06499v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.06499
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;NLP&#27169;&#22411;&#30340;&#23884;&#20837;&#23618;&#32423;&#36827;&#34892;&#25805;&#20316;&#65292;&#20511;&#37492;&#20102;&#26368;&#26032;&#30340;&#35299;&#37322;&#24615;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#65292;&#36890;&#36807;&#23884;&#20837;&#36716;&#25442;&#26469;&#28040;&#38500;&#38544;&#21547;&#30340;&#25935;&#24863;&#20449;&#24687;&#65292;&#20174;&#32780;&#23454;&#29616;&#27169;&#22411;&#30340;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#27169;&#22411;&#30340;&#20844;&#24179;&#24615;&#24050;&#25104;&#20026;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#12290;&#20449;&#24687;&#35770;&#34920;&#26126;&#65292;&#20026;&#20102;&#23454;&#29616;&#20844;&#24179;&#24615;&#65292;&#27169;&#22411;&#19981;&#24212;&#33021;&#22815;&#39044;&#27979;&#25935;&#24863;&#21464;&#37327;&#65292;&#22914;&#24615;&#21035;&#12289;&#31181;&#26063;&#21644;&#24180;&#40836;&#12290;&#28982;&#32780;&#65292;&#19982;&#36825;&#20123;&#21464;&#37327;&#30456;&#20851;&#30340;&#20449;&#24687;&#36890;&#24120;&#20197;&#38544;&#24335;&#30340;&#26041;&#24335;&#20986;&#29616;&#22312;&#35821;&#35328;&#20013;&#65292;&#36825;&#32473;&#35782;&#21035;&#21644;&#20943;&#23569;&#20559;&#35265;&#24102;&#26469;&#20102;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#22312;NLP&#27169;&#22411;&#30340;&#23884;&#20837;&#23618;&#32423;&#19978;&#25805;&#20316;&#65292;&#29420;&#31435;&#20110;&#20855;&#20307;&#30340;&#26550;&#26500;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20511;&#37492;&#20102;&#26368;&#36817;&#35299;&#37322;&#24615;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#30340;&#36827;&#23637;&#65292;&#24182;&#37319;&#29992;&#23884;&#20837;&#36716;&#25442;&#26469;&#28040;&#38500;&#36873;&#23450;&#21464;&#37327;&#20013;&#30340;&#38544;&#24335;&#20449;&#24687;&#12290;&#36890;&#36807;&#30452;&#25509;&#25805;&#32437;&#26368;&#21518;&#19968;&#23618;&#30340;&#23884;&#20837;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#26080;&#32541;&#38598;&#25104;&#21040;&#29616;&#26377;&#27169;&#22411;&#20013;&#65292;&#32780;&#26080;&#38656;&#36827;&#34892;&#37325;&#22823;&#20462;&#25913;&#25110;&#37325;&#35757;&#32451;&#12290;&#22312;&#35780;&#20272;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#21518;&#22788;&#29702;&#26041;&#27861;&#26174;&#33879;&#38477;&#20302;&#20102;&#19982;&#24615;&#21035;&#30456;&#20851;&#30340;&#20851;&#32852;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The fairness of Natural Language Processing (NLP) models has emerged as a crucial concern. Information theory indicates that to achieve fairness, a model should not be able to predict sensitive variables, such as gender, ethnicity, and age. However, information related to these variables often appears implicitly in language, posing a challenge in identifying and mitigating biases effectively. To tackle this issue, we present a novel approach that operates at the embedding level of an NLP model, independent of the specific architecture. Our method leverages insights from recent advances in XAI techniques and employs an embedding transformation to eliminate implicit information from a selected variable. By directly manipulating the embeddings in the final layer, our approach enables a seamless integration into existing models without requiring significant modifications or retraining. In evaluation, we show that the proposed post-hoc approach significantly reduces gender-related associati
&lt;/p&gt;</description></item><item><title>&#26412;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#30340;&#20811;&#32599;&#20869;&#20811;&#36817;&#20284;&#26354;&#29575;&#31639;&#27861;&#65292;&#21487;&#20197;&#21152;&#36895;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#21644;&#20943;&#23569;&#35745;&#31639;&#25104;&#26412;&#12290;&#20316;&#32773;&#21457;&#29616;&#20102;&#20004;&#31181;&#20855;&#26377;&#32447;&#24615;&#26435;&#37325;&#20849;&#20139;&#23618;&#19981;&#21516;&#35774;&#32622;&#65292;&#24182;&#35777;&#26126;&#20102;&#30456;&#24212;&#35774;&#32622;&#19979;&#30340;K-FAC&#31639;&#27861;&#30340;&#31934;&#30830;&#24615;&#12290;K-FAC-reduce&#36890;&#24120;&#27604;K-FAC-expand&#26356;&#24555;&#65292;&#21487;&#20197;&#29992;&#20110;&#21152;&#36895;&#33258;&#21160;&#36229;&#21442;&#25968;&#36873;&#25321;&#12290;</title><link>http://arxiv.org/abs/2311.00636</link><description>&lt;p&gt;
Kronecker-Factored Approximate Curvature for Modern Neural Network Architectures&#65288;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#30340;&#20811;&#32599;&#20869;&#20811;&#36817;&#20284;&#26354;&#29575;&#65289;
&lt;/p&gt;
&lt;p&gt;
Kronecker-Factored Approximate Curvature for Modern Neural Network Architectures. (arXiv:2311.00636v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00636
&lt;/p&gt;
&lt;p&gt;
&#26412;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#30340;&#20811;&#32599;&#20869;&#20811;&#36817;&#20284;&#26354;&#29575;&#31639;&#27861;&#65292;&#21487;&#20197;&#21152;&#36895;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#21644;&#20943;&#23569;&#35745;&#31639;&#25104;&#26412;&#12290;&#20316;&#32773;&#21457;&#29616;&#20102;&#20004;&#31181;&#20855;&#26377;&#32447;&#24615;&#26435;&#37325;&#20849;&#20139;&#23618;&#19981;&#21516;&#35774;&#32622;&#65292;&#24182;&#35777;&#26126;&#20102;&#30456;&#24212;&#35774;&#32622;&#19979;&#30340;K-FAC&#31639;&#27861;&#30340;&#31934;&#30830;&#24615;&#12290;K-FAC-reduce&#36890;&#24120;&#27604;K-FAC-expand&#26356;&#24555;&#65292;&#21487;&#20197;&#29992;&#20110;&#21152;&#36895;&#33258;&#21160;&#36229;&#21442;&#25968;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#30340;&#26680;&#24515;&#32452;&#20214;&#65292;&#22914;transformers&#12289;&#21367;&#31215;&#25110;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#21487;&#20197;&#34920;&#36798;&#20026;&#20855;&#26377;&#8220;&#26435;&#37325;&#20849;&#20139;&#8221;&#30340;&#32447;&#24615;&#23618;&#12290;&#20811;&#32599;&#20869;&#20811;&#36817;&#20284;&#26354;&#29575;&#65288;K-FAC&#65289;&#26159;&#19968;&#31181;&#20108;&#38454;&#20248;&#21270;&#26041;&#27861;&#65292;&#24050;&#26174;&#31034;&#20986;&#21152;&#36895;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#24182;&#20943;&#23569;&#35745;&#31639;&#25104;&#26412;&#30340;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#36824;&#27809;&#26377;&#23558;&#20854;&#24212;&#29992;&#20110;&#36890;&#29992;&#30340;&#26550;&#26500;&#30340;&#26694;&#26550;&#65292;&#29305;&#21035;&#26159;&#20855;&#26377;&#32447;&#24615;&#26435;&#37325;&#20849;&#20139;&#23618;&#30340;&#26550;&#26500;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#20855;&#26377;&#32447;&#24615;&#26435;&#37325;&#20849;&#20139;&#23618;&#30340;&#20004;&#31181;&#19981;&#21516;&#35774;&#32622;&#65292;&#36825;&#20419;&#20351;&#20102;&#20004;&#31181;K-FAC&#30340;&#21464;&#20307;&#8212;&#8212;&#8220;&#25193;&#23637;&#8221;&#21644;&#8220;&#20943;&#23569;&#8221;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#23545;&#20110;&#20855;&#26377;&#30456;&#24212;&#35774;&#32622;&#30340;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#65292;&#23427;&#20204;&#26159;&#31934;&#30830;&#30340;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;K-FAC-reduce&#36890;&#24120;&#27604;K-FAC-expand&#26356;&#24555;&#65292;&#25105;&#20204;&#21033;&#29992;&#23427;&#26469;&#21152;&#36895;&#36890;&#36807;&#20248;&#21270;Wide ResNet&#30340;&#36793;&#38469;&#20284;&#28982;&#26469;&#36873;&#25321;&#33258;&#21160;&#36229;&#21442;&#25968;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#22312;
&lt;/p&gt;
&lt;p&gt;
The core components of many modern neural network architectures, such as transformers, convolutional, or graph neural networks, can be expressed as linear layers with $\textit{weight-sharing}$. Kronecker-Factored Approximate Curvature (K-FAC), a second-order optimisation method, has shown promise to speed up neural network training and thereby reduce computational costs. However, there is currently no framework to apply it to generic architectures, specifically ones with linear weight-sharing layers. In this work, we identify two different settings of linear weight-sharing layers which motivate two flavours of K-FAC -- $\textit{expand}$ and $\textit{reduce}$. We show that they are exact for deep linear networks with weight-sharing in their respective setting. Notably, K-FAC-reduce is generally faster than K-FAC-expand, which we leverage to speed up automatic hyperparameter selection via optimising the marginal likelihood for a Wide ResNet. Finally, we observe little difference between 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#19977;&#20540;&#20915;&#31574;&#26641;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#25913;&#21892;&#20915;&#31574;&#26641;&#22312;&#22788;&#29702;&#32570;&#22833;&#25968;&#25454;&#26102;&#30340;&#34920;&#29616;&#12290;&#19982;&#20854;&#20182;&#26041;&#27861;&#19981;&#21516;&#65292;&#35813;&#31639;&#27861;&#19981;&#20551;&#35774;&#32570;&#22833;&#20540;&#21253;&#21547;&#20219;&#20309;&#20851;&#20110;&#21709;&#24212;&#30340;&#20449;&#24687;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#29305;&#23450;&#32570;&#22833;&#25968;&#25454;&#22330;&#26223;&#19979;&#65292;&#19977;&#20540;&#20915;&#31574;&#26641;&#22312;MCAR&#35774;&#32622;&#20013;&#34920;&#29616;&#20248;&#24322;&#65292;&#22312;IM&#35774;&#32622;&#20013;&#30053;&#36874;&#19968;&#31609;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#23558;&#19977;&#20540;&#20915;&#31574;&#26641;&#19982;&#32570;&#22833;&#22312;&#23646;&#24615;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#33719;&#24471;&#26356;&#31283;&#20581;&#30340;&#24615;&#33021;&#12290;&#23613;&#31649;&#35757;&#32451;&#36895;&#24230;&#36739;&#24930;&#65292;&#20294;&#19977;&#20540;&#20915;&#31574;&#26641;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#21069;&#36884;&#19988;&#26356;&#20934;&#30830;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2309.03561</link><description>&lt;p&gt;
&#32570;&#22833;&#20540;&#22788;&#29702;&#30340;&#19977;&#20540;&#20915;&#31574;&#26641;
&lt;/p&gt;
&lt;p&gt;
Trinary Decision Trees for missing value handling. (arXiv:2309.03561v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03561
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#19977;&#20540;&#20915;&#31574;&#26641;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#25913;&#21892;&#20915;&#31574;&#26641;&#22312;&#22788;&#29702;&#32570;&#22833;&#25968;&#25454;&#26102;&#30340;&#34920;&#29616;&#12290;&#19982;&#20854;&#20182;&#26041;&#27861;&#19981;&#21516;&#65292;&#35813;&#31639;&#27861;&#19981;&#20551;&#35774;&#32570;&#22833;&#20540;&#21253;&#21547;&#20219;&#20309;&#20851;&#20110;&#21709;&#24212;&#30340;&#20449;&#24687;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#29305;&#23450;&#32570;&#22833;&#25968;&#25454;&#22330;&#26223;&#19979;&#65292;&#19977;&#20540;&#20915;&#31574;&#26641;&#22312;MCAR&#35774;&#32622;&#20013;&#34920;&#29616;&#20248;&#24322;&#65292;&#22312;IM&#35774;&#32622;&#20013;&#30053;&#36874;&#19968;&#31609;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#23558;&#19977;&#20540;&#20915;&#31574;&#26641;&#19982;&#32570;&#22833;&#22312;&#23646;&#24615;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#33719;&#24471;&#26356;&#31283;&#20581;&#30340;&#24615;&#33021;&#12290;&#23613;&#31649;&#35757;&#32451;&#36895;&#24230;&#36739;&#24930;&#65292;&#20294;&#19977;&#20540;&#20915;&#31574;&#26641;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#21069;&#36884;&#19988;&#26356;&#20934;&#30830;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19977;&#20540;&#20915;&#31574;&#26641;&#65292;&#36825;&#26159;&#19968;&#31181;&#26088;&#22312;&#25913;&#21892;&#20915;&#31574;&#26641;&#22238;&#24402;&#22120;&#21644;&#20998;&#31867;&#22120;&#20013;&#22788;&#29702;&#32570;&#22833;&#25968;&#25454;&#30340;&#31639;&#27861;&#12290;&#19982;&#20854;&#20182;&#26041;&#27861;&#19981;&#21516;&#65292;&#19977;&#20540;&#20915;&#31574;&#26641;&#19981;&#20551;&#35774;&#32570;&#22833;&#20540;&#21253;&#21547;&#26377;&#20851;&#21709;&#24212;&#30340;&#20219;&#20309;&#20449;&#24687;&#12290;&#26412;&#25991;&#36890;&#36807;&#29702;&#35770;&#35745;&#31639;&#21644;&#20351;&#29992;&#30495;&#23454;&#25968;&#25454;&#38598;&#30340;&#25968;&#20540;&#31034;&#20363;&#65292;&#27604;&#36739;&#20102;&#20854;&#22312;&#19981;&#21516;&#32570;&#22833;&#25968;&#25454;&#22330;&#26223;&#65288;&#23436;&#20840;&#38543;&#26426;&#32570;&#22833;&#65288;MCAR&#65289;&#21644;&#20449;&#24687;&#24615;&#32570;&#22833;&#65288;IM&#65289;&#65289;&#20013;&#19982;&#24050;&#24314;&#31435;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#22312;MCAR&#35774;&#32622;&#20013;&#65292;&#19977;&#20540;&#26641;&#22312;&#21482;&#26377;&#26679;&#26412;&#22806;&#32570;&#22833;&#25968;&#25454;&#26102;&#34920;&#29616;&#20248;&#20110;&#20854;&#21516;&#34892;&#65292;&#32780;&#22312;IM&#35774;&#32622;&#20013;&#33853;&#21518;&#12290;&#19968;&#20010;&#28151;&#21512;&#27169;&#22411;&#65292;&#21363;&#19977;&#20540;&#32570;&#22833;&#22312;&#23646;&#24615;&#65288;MIA&#65289;&#26041;&#27861;&#21644;&#19977;&#20540;&#26641;&#30456;&#32467;&#21512;&#30340;TrinaryMIA&#26641;&#65292;&#22312;&#25152;&#26377;&#32570;&#22833;&#31867;&#22411;&#20013;&#34920;&#29616;&#20986;&#24378;&#22823;&#30340;&#24615;&#33021;&#12290;&#23613;&#31649;&#35757;&#32451;&#36895;&#24230;&#36739;&#24930;&#21487;&#33021;&#26159;&#19968;&#20010;&#28508;&#22312;&#30340;&#32570;&#28857;&#65292;&#20294;&#19977;&#20540;&#20915;&#31574;&#26641;&#25552;&#20379;&#20102;&#19968;&#20010;&#26377;&#21069;&#36884;&#19988;&#26356;&#20934;&#30830;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces the Trinary decision tree, an algorithm designed to improve the handling of missing data in decision tree regressors and classifiers. Unlike other approaches, the Trinary decision tree does not assume that missing values contain any information about the response. Both theoretical calculations on estimator bias and numerical illustrations using real data sets are presented to compare its performance with established algorithms in different missing data scenarios (Missing Completely at Random (MCAR), and Informative Missingness (IM)). Notably, the Trinary tree outperforms its peers in MCAR settings, especially when data is only missing out-of-sample, while lacking behind in IM settings. A hybrid model, the TrinaryMIA tree, which combines the Trinary tree and the Missing In Attributes (MIA) approach, shows robust performance in all types of missingness. Despite the potential drawback of slower training speed, the Trinary tree offers a promising and more accurate met
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#28145;&#24230;&#22270;&#24418;&#22238;&#24402;&#26041;&#27861;&#26469;&#32852;&#21512;&#35843;&#33410;&#21644;&#39044;&#27979;&#28595;&#22823;&#21033;&#20122;&#37326;&#28779;&#30340;&#26032;&#26041;&#27861;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#23545;&#20110;&#28779;&#28798;&#30340;&#20840;&#20998;&#24067;&#24314;&#27169;&#26159;&#38750;&#24120;&#20851;&#38190;&#30340;&#65292;&#22240;&#20026;&#26497;&#31471;&#37326;&#28779;&#21487;&#33021;&#23548;&#33268;&#24040;&#22823;&#30340;&#24433;&#21709;&#65292;&#32780;&#23567;&#35268;&#27169;&#21644;&#20013;&#31561;&#35268;&#27169;&#28779;&#28798;&#20173;&#28982;&#20250;&#23545;&#24403;&#22320;&#31038;&#21306;&#21644;&#29983;&#24577;&#31995;&#32479;&#36896;&#25104;&#37325;&#22823;&#30772;&#22351;&#12290;</title><link>http://arxiv.org/abs/2308.14547</link><description>&lt;p&gt;
&#28145;&#24230;&#22270;&#24418;&#22238;&#24402;&#29992;&#20110;&#32852;&#21512;&#35843;&#33410;&#21644;&#26497;&#31471;&#28595;&#22823;&#21033;&#20122;&#37326;&#28779;
&lt;/p&gt;
&lt;p&gt;
Deep graphical regression for jointly moderate and extreme Australian wildfires. (arXiv:2308.14547v1 [stat.AP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14547
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#28145;&#24230;&#22270;&#24418;&#22238;&#24402;&#26041;&#27861;&#26469;&#32852;&#21512;&#35843;&#33410;&#21644;&#39044;&#27979;&#28595;&#22823;&#21033;&#20122;&#37326;&#28779;&#30340;&#26032;&#26041;&#27861;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#23545;&#20110;&#28779;&#28798;&#30340;&#20840;&#20998;&#24067;&#24314;&#27169;&#26159;&#38750;&#24120;&#20851;&#38190;&#30340;&#65292;&#22240;&#20026;&#26497;&#31471;&#37326;&#28779;&#21487;&#33021;&#23548;&#33268;&#24040;&#22823;&#30340;&#24433;&#21709;&#65292;&#32780;&#23567;&#35268;&#27169;&#21644;&#20013;&#31561;&#35268;&#27169;&#28779;&#28798;&#20173;&#28982;&#20250;&#23545;&#24403;&#22320;&#31038;&#21306;&#21644;&#29983;&#24577;&#31995;&#32479;&#36896;&#25104;&#37325;&#22823;&#30772;&#22351;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28595;&#22823;&#21033;&#20122;&#26368;&#36817;&#30340;&#37326;&#28779;&#36896;&#25104;&#20102;&#24040;&#22823;&#30340;&#32463;&#27982;&#25439;&#22833;&#21644;&#36130;&#20135;&#30772;&#22351;&#65292;&#20154;&#20204;&#36234;&#26469;&#36234;&#25285;&#24515;&#27668;&#20505;&#21464;&#21270;&#21487;&#33021;&#21152;&#21095;&#20854;&#24378;&#24230;&#12289;&#25345;&#32493;&#26102;&#38388;&#21644;&#39057;&#29575;&#12290;&#23545;&#20110;&#26497;&#31471;&#37326;&#28779;&#30340;&#28798;&#23475;&#35780;&#20272;&#26159;&#37326;&#28779;&#31649;&#29702;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#65292;&#23427;&#26377;&#21161;&#20110;&#36164;&#28304;&#20998;&#37197;&#30340;&#39640;&#25928;&#24615;&#12289;&#36127;&#38754;&#24433;&#21709;&#30340;&#20943;&#36731;&#21644;&#24674;&#22797;&#24037;&#20316;&#30340;&#24320;&#23637;&#12290;&#28982;&#32780;&#65292;&#34429;&#28982;&#26497;&#31471;&#37326;&#28779;&#36890;&#24120;&#20855;&#26377;&#26368;&#22823;&#30340;&#24433;&#21709;&#21147;&#65292;&#20294;&#23567;&#35268;&#27169;&#21644;&#20013;&#31561;&#35268;&#27169;&#30340;&#28779;&#28798;&#20173;&#28982;&#21487;&#20197;&#23545;&#24403;&#22320;&#31038;&#21306;&#21644;&#29983;&#24577;&#31995;&#32479;&#36896;&#25104;&#27585;&#28781;&#24615;&#30340;&#24433;&#21709;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#36843;&#20999;&#38656;&#35201;&#24320;&#21457;&#31283;&#20581;&#30340;&#32479;&#35745;&#26041;&#27861;&#26469;&#21487;&#38752;&#22320;&#24314;&#27169;&#37326;&#28779;&#30340;&#20840;&#20998;&#24067;&#12290;&#25105;&#20204;&#23545;1999&#24180;&#33267;2019&#24180;&#30340;&#28595;&#22823;&#21033;&#20122;&#37326;&#28779;&#36827;&#34892;&#20102;&#26032;&#30340;&#25968;&#25454;&#38598;&#20998;&#26512;&#65292;&#24182;&#20998;&#26512;&#20102;&#22823;&#32422;&#30456;&#24403;&#20110;&#32479;&#35745;&#21306;&#22495;&#23618;&#27425;1&#21644;&#23618;&#27425;2&#65288;SA1/SA2&#65289;&#21306;&#22495;&#30340;&#28779;&#28798;&#26376;&#24230;&#34067;&#24310;&#12290;&#37492;&#20110;&#37326;&#28779;&#28857;&#29123;&#21644;&#34067;&#24310;&#30340;&#22797;&#26434;&#24615;&#65292;&#25105;&#20204;&#21033;&#29992;&#20102;&#32479;&#35745;&#28145;&#24230;&#23398;&#20064;&#21644;&#22806;&#37096;&#20449;&#24687;&#30340;&#26368;&#26032;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent wildfires in Australia have led to considerable economic loss and property destruction, and there is increasing concern that climate change may exacerbate their intensity, duration, and frequency. hazard quantification for extreme wildfires is an important component of wildfire management, as it facilitates efficient resource distribution, adverse effect mitigation, and recovery efforts. However, although extreme wildfires are typically the most impactful, both small and moderate fires can still be devastating to local communities and ecosystems. Therefore, it is imperative to develop robust statistical methods to reliably model the full distribution of wildfire spread. We do so for a novel dataset of Australian wildfires from 1999 to 2019, and analyse monthly spread over areas approximately corresponding to Statistical Areas Level 1 and 2 (SA1/SA2) regions. Given the complex nature of wildfire ignition and spread, we exploit recent advances in statistical deep learning and extr
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28155;&#21152;&#22122;&#22768;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#24182;&#20351;&#29992;Gibbs&#37319;&#26679;&#22120;&#20174;&#21518;&#39564;&#20998;&#24067;&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#35813;&#26041;&#27861;&#22312;&#30495;&#23454;&#25968;&#25454;&#21644;&#21512;&#25104;&#25968;&#25454;&#20013;&#33021;&#22815;&#36798;&#21040;&#31867;&#20284;&#20110;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.02729</link><description>&lt;p&gt;
Gibbs&#37319;&#26679;&#31070;&#32463;&#32593;&#32476;&#30340;&#21518;&#39564;&#20998;&#24067;
&lt;/p&gt;
&lt;p&gt;
Gibbs Sampling the Posterior of Neural Networks. (arXiv:2306.02729v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02729
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28155;&#21152;&#22122;&#22768;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#24182;&#20351;&#29992;Gibbs&#37319;&#26679;&#22120;&#20174;&#21518;&#39564;&#20998;&#24067;&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#35813;&#26041;&#27861;&#22312;&#30495;&#23454;&#25968;&#25454;&#21644;&#21512;&#25104;&#25968;&#25454;&#20013;&#33021;&#22815;&#36798;&#21040;&#31867;&#20284;&#20110;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#31070;&#32463;&#32593;&#32476;&#30340;&#21518;&#39564;&#20998;&#24067;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27010;&#29575;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#22312;&#32593;&#32476;&#30340;&#27599;&#20010;&#39044;&#28608;&#27963;&#21644;&#21518;&#28608;&#27963;&#20013;&#28155;&#21152;&#22122;&#22768;&#65292;&#24182;&#35748;&#20026;&#20351;&#29992;&#26377;&#25928;&#30340;Gibbs&#37319;&#26679;&#22120;&#21487;&#20197;&#37319;&#26679;&#24471;&#21040;&#25152;&#24471;&#21040;&#30340;&#21518;&#39564;&#20998;&#24067;&#12290;&#22312;&#30495;&#23454;&#25968;&#25454;&#21644;&#21512;&#25104;&#25968;&#25454;&#19978;&#65292;Gibbs&#37319;&#26679;&#22120;&#33021;&#22815;&#36798;&#21040;&#31867;&#20284;&#20110;&#29366;&#24577;-of-the-art&#30340;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#65288;&#22914;&#21704;&#23494;&#39039;&#33945;&#29305;&#21345;&#27931;&#25110;Metropolis&#35843;&#25972;Langevin&#31639;&#27861;&#65289;&#30340;&#24615;&#33021;&#12290;&#36890;&#36807;&#22312;&#24072;&#29983;&#35774;&#32622;&#20013;&#36827;&#34892;&#20998;&#26512;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#28909;&#21270;&#20934;&#21017;&#65292;&#35813;&#20934;&#21017;&#20801;&#35768;&#25105;&#20204;&#26816;&#27979;&#31639;&#27861;&#22312;&#20351;&#29992;&#21512;&#25104;&#26631;&#31614;&#30340;&#25968;&#25454;&#19978;&#36816;&#34892;&#26102;&#26159;&#21542;&#26080;&#27861;&#20174;&#21518;&#39564;&#20998;&#24067;&#20013;&#37319;&#26679;&#12290;&#35813;&#20934;&#21017;&#22522;&#20110;&#24072;&#29983;&#35774;&#32622;&#20013;&#30340;&#20107;&#23454;&#65292;&#25105;&#20204;&#21487;&#20197;&#30452;&#25509;&#22312;&#24179;&#34913;&#28857;&#22788;&#21021;&#22987;&#21270;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study sampling from a posterior derived from a neural network. We propose a new probabilistic model consisting of adding noise at every pre- and post-activation in the network, arguing that the resulting posterior can be sampled using an efficient Gibbs sampler. The Gibbs sampler attains similar performances as the state-of-the-art Monte Carlo Markov chain methods, such as the Hamiltonian Monte Carlo or the Metropolis adjusted Langevin algorithm, both on real and synthetic data. By framing our analysis in the teacher-student setting, we introduce a thermalization criterion that allows us to detect when an algorithm, when run on data with synthetic labels, fails to sample from the posterior. The criterion is based on the fact that in the teacher-student setting we can initialize an algorithm directly at equilibrium.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;&#8220;&#25239;&#24178;&#25200;&#32422;&#26463;&#23398;&#20064;&#8221;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#22312;&#37096;&#32626;&#26426;&#22120;&#23398;&#20064;&#35299;&#20915;&#26041;&#26696;&#26102;&#38656;&#35201;&#28385;&#36275;&#38500;&#20102;&#20934;&#30830;&#24615;&#20197;&#22806;&#30340;&#22810;&#20010;&#35201;&#27714;&#65292;&#24182;&#20197;&#24179;&#34913;&#20174;&#25918;&#23485;&#20013;&#33719;&#24471;&#30340;&#24615;&#33021;&#22686;&#30410;&#19982;&#29992;&#25143;&#23450;&#20041;&#30340;&#25918;&#23485;&#25104;&#26412;&#20043;&#38388;&#30340;&#20851;&#31995;&#30340;&#26041;&#24335;&#25918;&#26494;&#23398;&#20064;&#32422;&#26463;&#12290;</title><link>http://arxiv.org/abs/2306.02426</link><description>&lt;p&gt;
&#25239;&#24178;&#25200;&#32422;&#26463;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Resilient Constrained Learning. (arXiv:2306.02426v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02426
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;&#8220;&#25239;&#24178;&#25200;&#32422;&#26463;&#23398;&#20064;&#8221;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#22312;&#37096;&#32626;&#26426;&#22120;&#23398;&#20064;&#35299;&#20915;&#26041;&#26696;&#26102;&#38656;&#35201;&#28385;&#36275;&#38500;&#20102;&#20934;&#30830;&#24615;&#20197;&#22806;&#30340;&#22810;&#20010;&#35201;&#27714;&#65292;&#24182;&#20197;&#24179;&#34913;&#20174;&#25918;&#23485;&#20013;&#33719;&#24471;&#30340;&#24615;&#33021;&#22686;&#30410;&#19982;&#29992;&#25143;&#23450;&#20041;&#30340;&#25918;&#23485;&#25104;&#26412;&#20043;&#38388;&#30340;&#20851;&#31995;&#30340;&#26041;&#24335;&#25918;&#26494;&#23398;&#20064;&#32422;&#26463;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#37096;&#32626;&#26426;&#22120;&#23398;&#20064;&#35299;&#20915;&#26041;&#26696;&#26102;&#65292;&#38500;&#20102;&#20934;&#30830;&#24615;&#20043;&#22806;&#65292;&#23427;&#20204;&#24517;&#39035;&#28385;&#36275;&#22810;&#20010;&#35201;&#27714;&#65292;&#22914;&#20844;&#24179;&#24615;&#12289;&#40065;&#26834;&#24615;&#25110;&#23433;&#20840;&#24615;&#12290;&#36825;&#20123;&#35201;&#27714;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#24809;&#32602;&#26469;&#38544;&#24335;&#22320;&#26045;&#21152;&#65292;&#25110;&#32773;&#36890;&#36807;&#22522;&#20110;Lagrangian&#23545;&#20598;&#30340;&#32422;&#26463;&#20248;&#21270;&#26041;&#27861;&#26469;&#26174;&#24335;&#22320;&#26045;&#21152;&#12290;&#26080;&#35770;&#21738;&#31181;&#26041;&#24335;&#65292;&#25351;&#23450;&#35201;&#27714;&#37117;&#21463;&#21040;&#22949;&#21327;&#21644;&#26377;&#38480;&#30340;&#26377;&#20851;&#25968;&#25454;&#30340;&#20808;&#21069;&#30693;&#35782;&#30340;&#24433;&#21709;&#12290;&#27492;&#22806;&#65292;&#23427;&#20204;&#23545;&#24615;&#33021;&#30340;&#24433;&#21709;&#36890;&#24120;&#21482;&#33021;&#36890;&#36807;&#23454;&#38469;&#35299;&#20915;&#23398;&#20064;&#38382;&#39064;&#26469;&#35780;&#20272;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32422;&#26463;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#21516;&#26102;&#35299;&#20915;&#23398;&#20064;&#20219;&#21153;&#30340;&#21516;&#26102;&#35843;&#25972;&#35201;&#27714;&#12290;&#20026;&#27492;&#65292;&#23427;&#20197;&#24179;&#34913;&#20174;&#25918;&#23485;&#20013;&#33719;&#24471;&#30340;&#24615;&#33021;&#22686;&#30410;&#19982;&#29992;&#25143;&#23450;&#20041;&#30340;&#25918;&#23485;&#25104;&#26412;&#20043;&#38388;&#30340;&#20851;&#31995;&#30340;&#26041;&#24335;&#25918;&#26494;&#20102;&#23398;&#20064;&#32422;&#26463;&#12290;&#25105;&#20204;&#23558;&#27492;&#26041;&#27861;&#31216;&#20026;&#20855;&#26377;&#24377;&#24615;&#30340;&#32422;&#26463;&#23398;&#20064;&#65292;&#36825;&#26159;&#23545;&#29992;&#20110;&#25551;&#36848;&#29983;&#24577;&#31995;&#32479;&#30340;&#26415;&#35821;&#30340;&#19968;&#31181;&#20511;&#37492;&#12290;
&lt;/p&gt;
&lt;p&gt;
When deploying machine learning solutions, they must satisfy multiple requirements beyond accuracy, such as fairness, robustness, or safety. These requirements are imposed during training either implicitly, using penalties, or explicitly, using constrained optimization methods based on Lagrangian duality. Either way, specifying requirements is hindered by the presence of compromises and limited prior knowledge about the data. Furthermore, their impact on performance can often only be evaluated by actually solving the learning problem. This paper presents a constrained learning approach that adapts the requirements while simultaneously solving the learning task. To do so, it relaxes the learning constraints in a way that contemplates how much they affect the task at hand by balancing the performance gains obtained from the relaxation against a user-defined cost of that relaxation. We call this approach resilient constrained learning after the term used to describe ecological systems tha
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#36830;&#32493;&#24615;&#32467;&#26524;&#30340;&#37096;&#20998;&#21453;&#20107;&#23454;&#35782;&#21035;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25935;&#24863;&#24615;&#27169;&#22411;&#8212;&#8212;&#26354;&#29575;&#25935;&#24863;&#27169;&#22411;&#65292;&#36890;&#36807;&#38480;&#21046;&#20989;&#25968;&#32423;&#38598;&#30340;&#26354;&#29575;&#26469;&#33719;&#24471;&#20449;&#24687;&#36793;&#30028;&#12290;</title><link>http://arxiv.org/abs/2306.01424</link><description>&lt;p&gt;
&#24102;&#26354;&#29575;&#25935;&#24863;&#27169;&#22411;&#30340;&#36830;&#32493;&#24615;&#32467;&#26524;&#30340;&#37096;&#20998;&#21453;&#20107;&#23454;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Partial Counterfactual Identification of Continuous Outcomes with a Curvature Sensitivity Model. (arXiv:2306.01424v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01424
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#36830;&#32493;&#24615;&#32467;&#26524;&#30340;&#37096;&#20998;&#21453;&#20107;&#23454;&#35782;&#21035;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25935;&#24863;&#24615;&#27169;&#22411;&#8212;&#8212;&#26354;&#29575;&#25935;&#24863;&#27169;&#22411;&#65292;&#36890;&#36807;&#38480;&#21046;&#20989;&#25968;&#32423;&#38598;&#30340;&#26354;&#29575;&#26469;&#33719;&#24471;&#20449;&#24687;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21453;&#20107;&#23454;&#25512;&#26029;&#26088;&#22312;&#22238;&#31572;&#8220;&#22914;&#26524;&#8221;&#38382;&#39064;&#65292;&#22240;&#27492;&#23646;&#20110;Pearl&#22240;&#26524;&#20851;&#31995;&#38454;&#26799;&#20013;&#26368;&#31934;&#32454;&#30340;&#25512;&#29702;&#31867;&#22411;&#12290;&#29616;&#26377;&#30340;&#38024;&#23545;&#20855;&#26377;&#36830;&#32493;&#32467;&#26524;&#30340;&#21453;&#20107;&#23454;&#25512;&#26029;&#26041;&#27861;&#26088;&#22312;&#36827;&#34892;&#28857;&#35782;&#21035;&#65292;&#22240;&#27492;&#23545;&#22522;&#30784;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#36827;&#34892;&#20102;&#24378;&#26377;&#21147;&#19988;&#19981;&#33258;&#28982;&#30340;&#20551;&#35774;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25918;&#23485;&#20102;&#36825;&#20123;&#20551;&#35774;&#65292;&#26088;&#22312;&#36827;&#34892;&#36830;&#32493;&#32467;&#26524;&#30340;&#37096;&#20998;&#21453;&#20107;&#23454;&#35782;&#21035;&#65292;&#21363;&#24403;&#21453;&#20107;&#23454;&#26597;&#35810;&#23384;&#22312;&#20855;&#26377;&#20449;&#24687;&#36793;&#30028;&#30340;&#26080;&#30693;&#21306;&#38388;&#20013;&#26102;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#65292;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#65292;&#21363;&#20351;&#26159;&#36830;&#32493;&#21487;&#24494;&#30340;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#20989;&#25968;&#30340;&#32423;&#38598;&#30340;&#26354;&#29575;&#20063;&#26159;&#38750;&#20449;&#24687;&#30340;&#65292;&#21453;&#20107;&#23454;&#26597;&#35810;&#30340;&#26080;&#30693;&#21306;&#38388;&#20063;&#26159;&#38750;&#20449;&#24687;&#30340;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25935;&#24863;&#24615;&#27169;&#22411;&#31216;&#20026;&#26354;&#29575;&#25935;&#24863;&#27169;&#22411;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#23427;&#20801;&#35768;&#25105;&#20204;&#36890;&#36807;&#38480;&#21046;&#20989;&#25968;&#32423;&#38598;&#30340;&#26354;&#29575;&#26469;&#33719;&#24471;&#20449;&#24687;&#36793;&#30028;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23637;&#31034;&#20102;&#29616;&#26377;&#30340;&#28857;&#21453;&#20107;&#23454;&#35782;&#21035;&#26041;&#27861;&#21487;&#20197;&#35270;&#20026;&#25105;&#20204;&#25552;&#20986;&#26694;&#26550;&#30340;&#29305;&#23450;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Counterfactual inference aims to answer retrospective ''what if'' questions and thus belongs to the most fine-grained type of inference in Pearl's causality ladder. Existing methods for counterfactual inference with continuous outcomes aim at point identification and thus make strong and unnatural assumptions about the underlying structural causal model. In this paper, we relax these assumptions and aim at partial counterfactual identification of continuous outcomes, i.e., when the counterfactual query resides in an ignorance interval with informative bounds. We prove that, in general, the ignorance interval of the counterfactual queries has non-informative bounds, already when functions of structural causal models are continuously differentiable. As a remedy, we propose a novel sensitivity model called Curvature Sensitivity Model. This allows us to obtain informative bounds by bounding the curvature of level sets of the functions. We further show that existing point counterfactual ide
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23545;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#65288;BBVI&#65289;&#30340;&#20998;&#26512;&#65292;&#21457;&#29616;&#19968;&#20123;&#24120;&#35265;&#30340;&#31639;&#27861;&#35774;&#35745;&#36873;&#25321;&#21487;&#33021;&#20250;&#23548;&#33268;&#27425;&#20248;&#25910;&#25947;&#36895;&#29575;&#65292;&#20294;&#20351;&#29992;&#24102;&#26377;&#36817;&#31471;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;BBVI&#21487;&#20197;&#23454;&#29616;&#26368;&#24378;&#25910;&#25947;&#29575;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2305.15349</link><description>&lt;p&gt;
&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#25910;&#25947;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Black-Box Variational Inference Converges. (arXiv:2305.15349v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15349
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#65288;BBVI&#65289;&#30340;&#20998;&#26512;&#65292;&#21457;&#29616;&#19968;&#20123;&#24120;&#35265;&#30340;&#31639;&#27861;&#35774;&#35745;&#36873;&#25321;&#21487;&#33021;&#20250;&#23548;&#33268;&#27425;&#20248;&#25910;&#25947;&#36895;&#29575;&#65292;&#20294;&#20351;&#29992;&#24102;&#26377;&#36817;&#31471;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;BBVI&#21487;&#20197;&#23454;&#29616;&#26368;&#24378;&#25910;&#25947;&#29575;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#23436;&#25972;&#30340;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#65288;BBVI&#65289;&#30340;&#25910;&#25947;&#20445;&#35777;&#65292;&#20063;&#31216;&#20026;&#33945;&#29305;&#21345;&#32599;&#21464;&#20998;&#25512;&#26029;&#12290;&#23613;&#31649;&#26089;&#26399;&#30340;&#30740;&#31350;&#21482;&#38024;&#23545;&#31616;&#21270;&#29256;&#26412;&#30340;BBVI&#36827;&#34892;&#20102;&#30740;&#31350;&#65288;&#20363;&#22914;&#65292;&#26377;&#30028;&#22495;&#12289;&#26377;&#30028;&#25903;&#25345;&#12289;&#20165;&#38024;&#23545;&#23610;&#24230;&#36827;&#34892;&#20248;&#21270;&#31561;&#65289;&#65292;&#20294;&#25105;&#20204;&#30340;&#35774;&#32622;&#19981;&#38656;&#35201;&#20219;&#20309;&#36825;&#26679;&#30340;&#31639;&#27861;&#20462;&#25913;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#36866;&#29992;&#20110;&#23545;&#25968;&#24179;&#28369;&#21518;&#39564;&#23494;&#24230;&#65292;&#26080;&#35770;&#26159;&#21542;&#24378;&#23545;&#25968;&#20985;&#24615;&#20197;&#21450;&#20301;&#32622;-&#23610;&#24230;&#21464;&#20998;&#26063;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#25581;&#31034;&#20986;&#20102;&#19968;&#20123;&#24120;&#35265;&#30340;&#31639;&#27861;&#35774;&#35745;&#36873;&#25321;&#65292;&#29305;&#21035;&#26159;&#21464;&#20998;&#36817;&#20284;&#23610;&#24230;&#30340;&#38750;&#32447;&#24615;&#21442;&#25968;&#21270;&#65292;&#21487;&#33021;&#20250;&#23548;&#33268;&#27425;&#20248;&#25910;&#25947;&#36895;&#29575;&#12290;&#24184;&#36816;&#30340;&#26159;&#65292;&#36816;&#34892;&#24102;&#26377;&#36817;&#31471;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;BBVI&#21487;&#20197;&#32416;&#27491;&#36825;&#20123;&#38480;&#21046;&#65292;&#20174;&#32780;&#23454;&#29616;&#24050;&#30693;&#30340;&#26368;&#24378;&#25910;&#25947;&#29575;&#20445;&#35777;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#36817;&#31471;SGD&#19982;&#20854;&#20182;&#26631;&#20934;&#30340;BBVI&#23454;&#29616;&#36827;&#34892;&#27604;&#36739;&#65292;&#39564;&#35777;&#20102;&#36825;&#19968;&#29702;&#35770;&#32467;&#35770;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We provide the first convergence guarantee for full black-box variational inference (BBVI), also known as Monte Carlo variational inference. While preliminary investigations worked on simplified versions of BBVI (e.g., bounded domain, bounded support, only optimizing for the scale, and such), our setup does not need any such algorithmic modifications. Our results hold for log-smooth posterior densities with and without strong log-concavity and the location-scale variational family. Also, our analysis reveals that certain algorithm design choices commonly employed in practice, particularly, nonlinear parameterizations of the scale of the variational approximation, can result in suboptimal convergence rates. Fortunately, running BBVI with proximal stochastic gradient descent fixes these limitations, and thus achieves the strongest known convergence rate guarantees. We evaluate this theoretical insight by comparing proximal SGD against other standard implementations of BBVI on large-scale
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#21151;&#33021;&#20462;&#21098;&#30340;&#38750;&#21442;&#25968;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#31639;&#27861;&#65292;&#33021;&#22815;&#24555;&#36895;&#39640;&#25928;&#22320;&#26816;&#27979;&#39640;&#39057;&#25968;&#25454;&#27969;&#20013;&#30340;&#24322;&#24120;&#21644;&#21464;&#21270;&#65292;&#24182;&#19988;&#19981;&#20381;&#36182;&#20110;&#36829;&#21453;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#21442;&#25968;&#20551;&#35774;&#12290;</title><link>http://arxiv.org/abs/2302.02718</link><description>&lt;p&gt;
&#19968;&#20010;&#22522;&#20110;&#21151;&#33021;&#20462;&#21098;&#30340;&#38750;&#21442;&#25968;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#31639;&#27861;&#30340;&#23545;&#25968;&#32447;&#24615;&#23454;&#29616;
&lt;/p&gt;
&lt;p&gt;
A Log-Linear Non-Parametric Online Changepoint Detection Algorithm based on Functional Pruning. (arXiv:2302.02718v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.02718
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#21151;&#33021;&#20462;&#21098;&#30340;&#38750;&#21442;&#25968;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#31639;&#27861;&#65292;&#33021;&#22815;&#24555;&#36895;&#39640;&#25928;&#22320;&#26816;&#27979;&#39640;&#39057;&#25968;&#25454;&#27969;&#20013;&#30340;&#24322;&#24120;&#21644;&#21464;&#21270;&#65292;&#24182;&#19988;&#19981;&#20381;&#36182;&#20110;&#36829;&#21453;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#21442;&#25968;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#26088;&#22312;&#23454;&#26102;&#26816;&#27979;&#39640;&#39057;&#25968;&#25454;&#27969;&#20013;&#30340;&#24322;&#24120;&#21644;&#21464;&#21270;&#65292;&#26377;&#26102;&#20505;&#24102;&#26377;&#26377;&#38480;&#30340;&#35745;&#31639;&#36164;&#28304;&#12290;&#36825;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#20219;&#21153;&#65292;&#26681;&#28304;&#20110;&#35768;&#22810;&#29616;&#23454;&#24212;&#29992;&#65292;&#21253;&#25324;&#20294;&#19981;&#38480;&#20110;&#32593;&#32476;&#23433;&#20840;&#12289;&#21307;&#23398;&#21644;&#22825;&#20307;&#29289;&#29702;&#23398;&#12290;&#34429;&#28982;&#26368;&#36817;&#24341;&#20837;&#20102;&#24555;&#36895;&#39640;&#25928;&#30340;&#22312;&#32447;&#31639;&#27861;&#65292;&#20294;&#36825;&#20123;&#31639;&#27861;&#37117;&#20381;&#36182;&#20110;&#24120;&#34987;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#36829;&#21453;&#30340;&#21442;&#25968;&#20551;&#35774;&#12290;&#21463;&#30005;&#20449;&#39046;&#22495;&#25968;&#25454;&#27969;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#31181;&#28789;&#27963;&#30340;&#38750;&#21442;&#25968;&#26041;&#27861;&#26469;&#26816;&#27979;&#24207;&#21015;&#20998;&#24067;&#20013;&#30340;&#21464;&#21270;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;NP-FOCuS&#65292;&#22312;&#25968;&#25454;&#30340;&#32463;&#39564;&#32047;&#31215;&#23494;&#24230;&#20989;&#25968;&#30340;&#19968;&#32452;&#28857;&#19978;&#26500;&#24314;&#20102;&#19968;&#20010;&#24207;&#21015;&#20284;&#28982;&#27604;&#26816;&#39564;&#65292;&#29992;&#20110;&#26816;&#27979;&#21464;&#21270;&#12290;&#36890;&#36807;&#36319;&#36394;&#36229;&#20986;&#25110;&#20302;&#20110;&#36825;&#20123;&#28857;&#30340;&#35266;&#27979;&#27425;&#25968;&#65292;&#23454;&#29616;&#20102;&#36825;&#19968;&#30446;&#26631;&#12290;&#30001;&#20110;&#21151;&#33021;&#20462;&#21098;&#30340;&#24605;&#24819;&#65292;NP-FOCuS&#30340;&#35745;&#31639;&#25104;&#26412;&#19982;&#35266;&#27979;&#27425;&#25968;&#30340;&#23545;&#25968;&#25104;&#32447;&#24615;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Online changepoint detection aims to detect anomalies and changes in real-time in high-frequency data streams, sometimes with limited available computational resources. This is an important task that is rooted in many real-world applications, including and not limited to cybersecurity, medicine and astrophysics. While fast and efficient online algorithms have been recently introduced, these rely on parametric assumptions which are often violated in practical applications. Motivated by data streams from the telecommunications sector, we build a flexible nonparametric approach to detect a change in the distribution of a sequence. Our procedure, NP-FOCuS, builds a sequential likelihood ratio test for a change in a set of points of the empirical cumulative density function of our data. This is achieved by keeping track of the number of observations above or below those points. Thanks to functional pruning ideas, NP-FOCuS has a computational cost that is log-linear in the number of observat
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;ARMA&#21333;&#20803;&#65292;&#19968;&#31181;&#26356;&#31616;&#21333;&#12289;&#27169;&#22359;&#21270;&#21644;&#26377;&#25928;&#30340;&#31070;&#32463;&#32593;&#32476;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#26041;&#27861;&#65292;&#33021;&#22815;&#33258;&#28982;&#22320;&#22788;&#29702;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#65292;&#24182;&#24341;&#20837;&#20102;ConvARMA&#21333;&#20803;&#20316;&#20026;&#19968;&#31181;&#35299;&#20915;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2208.14919</link><description>&lt;p&gt;
ARMA&#21333;&#20803;&#65306;&#31070;&#32463;&#33258;&#22238;&#24402;&#24314;&#27169;&#30340;&#27169;&#22359;&#21270;&#21644;&#26377;&#25928;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
ARMA Cell: A Modular and Effective Approach for Neural Autoregressive Modeling. (arXiv:2208.14919v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.14919
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;ARMA&#21333;&#20803;&#65292;&#19968;&#31181;&#26356;&#31616;&#21333;&#12289;&#27169;&#22359;&#21270;&#21644;&#26377;&#25928;&#30340;&#31070;&#32463;&#32593;&#32476;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#26041;&#27861;&#65292;&#33021;&#22815;&#33258;&#28982;&#22320;&#22788;&#29702;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#65292;&#24182;&#24341;&#20837;&#20102;ConvARMA&#21333;&#20803;&#20316;&#20026;&#19968;&#31181;&#35299;&#20915;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#22238;&#24402;&#31227;&#21160;&#24179;&#22343;(ARMA)&#27169;&#22411;&#26159;&#19968;&#31181;&#32463;&#20856;&#30340;&#12289;&#34987;&#24191;&#27867;&#30740;&#31350;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#24314;&#27169;&#26041;&#27861;&#12290;&#23427;&#20855;&#26377;&#24341;&#20154;&#20837;&#32988;&#30340;&#29702;&#35770;&#24615;&#36136;&#65292;&#22312;&#23454;&#36341;&#20013;&#34987;&#24191;&#27867;&#24212;&#29992;&#12290;&#26368;&#36817;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#26222;&#21450;&#20102;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;(RNN)&#65292;&#29305;&#21035;&#26159;&#38271;&#30701;&#26399;&#35760;&#24518;(LSTM)&#21333;&#20803;&#65292;&#22312;&#31070;&#32463;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#20013;&#25104;&#20026;&#34920;&#29616;&#26368;&#22909;&#21644;&#26368;&#24120;&#35265;&#30340;&#26500;&#24314;&#27169;&#22359;&#20043;&#19968;&#12290;&#34429;&#28982;&#22797;&#26434;&#30340;RNN&#21333;&#20803;&#23545;&#20110;&#20855;&#26377;&#38271;&#26399;&#24433;&#21709;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#25110;&#24207;&#21015;&#26377;&#20248;&#21183;&#65292;&#20294;&#24182;&#19981;&#24635;&#26159;&#24517;&#38656;&#30340;&#65292;&#26377;&#26102;&#29978;&#33267;&#19981;&#22914;&#26356;&#31616;&#21333;&#30340;&#24490;&#29615;&#26041;&#27861;&#22909;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;ARMA&#21333;&#20803;&#65292;&#36825;&#26159;&#19968;&#31181;&#26356;&#31616;&#21333;&#12289;&#27169;&#22359;&#21270;&#21644;&#26377;&#25928;&#30340;&#31070;&#32463;&#32593;&#32476;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#26041;&#27861;&#12290;&#36825;&#20010;&#21333;&#20803;&#21487;&#20197;&#22312;&#20219;&#20309;&#23384;&#22312;&#24490;&#29615;&#32467;&#26500;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#20013;&#20351;&#29992;&#65292;&#24182;&#19988;&#21487;&#20197;&#33258;&#28982;&#22320;&#22788;&#29702;&#22810;&#21464;&#37327;&#26102;&#38388;&#24207;&#21015;&#65292;&#20351;&#29992;&#21521;&#37327;&#33258;&#22238;&#24402;&#25216;&#26415;&#12290;&#25105;&#20204;&#36824;&#20171;&#32461;&#20102;ConvARMA&#21333;&#20803;&#20316;&#20026;&#19968;&#31181;&#33258;&#28982;&#30340;&#35299;&#20915;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The autoregressive moving average (ARMA) model is a classical, and arguably one of the most studied approaches to model time series data. It has compelling theoretical properties and is widely used among practitioners. More recent deep learning approaches popularize recurrent neural networks (RNNs) and, in particular, Long Short-Term Memory (LSTM) cells that have become one of the best performing and most common building blocks in neural time series modeling. While advantageous for time series data or sequences with long-term effects, complex RNN cells are not always a must and can sometimes even be inferior to simpler recurrent approaches. In this work, we introduce the ARMA cell, a simpler, modular, and effective approach for time series modeling in neural networks. This cell can be used in any neural network architecture where recurrent structures are present and naturally handles multivariate time series using vector autoregression. We also introduce the ConvARMA cell as a natural 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;CP-PINNs&#27169;&#22411;&#65292;&#36890;&#36807;&#23558;PINNs&#19982;&#24635;&#21464;&#24046;&#24809;&#32602;&#30456;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#20934;&#30830;&#30340;&#21464;&#28857;&#26816;&#27979;&#21644;PDE&#30340;&#21457;&#29616;&#12290;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#20803;&#23398;&#20064;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#25968;&#25454;&#30340;&#36830;&#32493;&#25209;&#27425;&#19978;&#21160;&#24577;&#25913;&#36827;&#20248;&#21270;&#30446;&#26631;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#23384;&#22312;&#21464;&#28857;&#30340;&#24773;&#20917;&#19979;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#20934;&#30830;&#20272;&#35745;&#21442;&#25968;&#21644;&#27169;&#22411;&#23545;&#40784;&#65292;&#22312;&#27809;&#26377;&#21464;&#28857;&#30340;&#24773;&#20917;&#19979;&#33021;&#22815;&#25968;&#20540;&#19978;&#25910;&#25947;&#21040;&#21407;&#22987;PINNs&#27169;&#22411;&#30340;&#35299;&#12290;</title><link>http://arxiv.org/abs/2208.08626</link><description>&lt;p&gt;
CP-PINNs: &#20351;&#29992;&#29289;&#29702;&#30693;&#35782;&#31070;&#32463;&#32593;&#32476;&#21644;&#24635;&#21464;&#24046;&#24809;&#32602;&#36827;&#34892;PDE&#20013;&#30340;&#21464;&#28857;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
CP-PINNs: Changepoints Detection in PDEs using Physics Informed Neural Networks with Total-Variation Penalty. (arXiv:2208.08626v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.08626
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;CP-PINNs&#27169;&#22411;&#65292;&#36890;&#36807;&#23558;PINNs&#19982;&#24635;&#21464;&#24046;&#24809;&#32602;&#30456;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#20934;&#30830;&#30340;&#21464;&#28857;&#26816;&#27979;&#21644;PDE&#30340;&#21457;&#29616;&#12290;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#20803;&#23398;&#20064;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#25968;&#25454;&#30340;&#36830;&#32493;&#25209;&#27425;&#19978;&#21160;&#24577;&#25913;&#36827;&#20248;&#21270;&#30446;&#26631;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#23384;&#22312;&#21464;&#28857;&#30340;&#24773;&#20917;&#19979;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#20934;&#30830;&#20272;&#35745;&#21442;&#25968;&#21644;&#27169;&#22411;&#23545;&#40784;&#65292;&#22312;&#27809;&#26377;&#21464;&#28857;&#30340;&#24773;&#20917;&#19979;&#33021;&#22815;&#25968;&#20540;&#19978;&#25910;&#25947;&#21040;&#21407;&#22987;PINNs&#27169;&#22411;&#30340;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23637;&#31034;&#20102;&#22312;&#21442;&#25968;&#20013;&#23384;&#22312;&#26410;&#30693;&#21464;&#28857;&#30340;&#24773;&#20917;&#19979;&#65292;&#29289;&#29702;&#30693;&#35782;&#31070;&#32463;&#32593;&#32476;&#65288;PINNs&#65289;&#21487;&#33021;&#26080;&#27861;&#27491;&#30830;&#20272;&#35745;&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;PDE&#65289;&#30340;&#21160;&#24577;&#36807;&#31243;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;CP-PINNs&#27169;&#22411;&#65292;&#23558;PINNs&#19982;&#24635;&#21464;&#24046;&#24809;&#32602;&#30456;&#32467;&#21512;&#65292;&#29992;&#20110;&#20934;&#30830;&#30340;&#21464;&#28857;&#26816;&#27979;&#21644;PDE&#30340;&#21457;&#29616;&#12290;&#20026;&#20102;&#22312;&#27169;&#22411;&#25311;&#21512;&#12289;PDE&#21457;&#29616;&#21644;&#21464;&#28857;&#26816;&#27979;&#20219;&#21153;&#20043;&#38388;&#36827;&#34892;&#26368;&#20248;&#32452;&#21512;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#20803;&#23398;&#20064;&#31639;&#27861;&#65292;&#21033;&#29992;&#25209;&#37327;&#23398;&#20064;&#22312;&#25968;&#25454;&#30340;&#36830;&#32493;&#25209;&#27425;&#19978;&#21160;&#24577;&#25913;&#36827;&#20248;&#21270;&#30446;&#26631;&#12290;&#22312;&#23454;&#35777;&#26041;&#38754;&#65292;&#22312;&#21160;&#24577;&#36807;&#31243;&#20013;&#23384;&#22312;&#21464;&#28857;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#20934;&#30830;&#20272;&#35745;&#21442;&#25968;&#21644;&#27169;&#22411;&#23545;&#40784;&#65292;&#22312;&#25968;&#25454;&#20013;&#27809;&#26377;&#21464;&#28857;&#30340;&#24773;&#20917;&#19979;&#65292;&#25968;&#20540;&#19978;&#25910;&#25947;&#21040;&#21407;&#22987;PINNs&#27169;&#22411;&#30340;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
The paper shows that Physics-Informed Neural Networks (PINNs) can fail to estimate the correct Partial Differential Equations (PDEs) dynamics in cases of unknown changepoints in the parameters. To address this, we propose a new CP-PINNs model which integrates PINNs with Total-Variation penalty for accurate changepoints detection and PDEs discovery. In order to optimally combine the tasks of model fitting, PDEs discovery, and changepoints detection, we develop a new meta-learning algorithm that exploits batch learning to dynamically refines the optimization objective when moving over the consecutive batches of the data. Empirically, in case of changepoints in the dynamics, our approach demonstrates accurate parameter estimation and model alignment, and in case of no changepoints in the data, it converges numerically to the solution from the original PINNs model.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#21472;&#21152;&#38598;&#25104;&#27169;&#22411;&#65292;&#29992;&#20110;&#38745;&#24577;&#26080;&#36335;&#24452;&#20272;&#35745;&#21040;&#36798;&#26102;&#38388;&#12290;&#35813;&#27169;&#22411;&#23558;&#22810;&#20010;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#32452;&#21512;&#25104;&#19968;&#20010;&#26032;&#30340;&#38598;&#25104;&#32467;&#26500;&#65292;&#33021;&#22815;&#36229;&#36234;&#20808;&#21069;&#30340;&#26368;&#20808;&#36827;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2203.09438</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#38745;&#24577;&#26080;&#36335;&#24452;&#20272;&#35745;&#21040;&#36798;&#26102;&#38388;&#30340;&#21487;&#35299;&#37322;&#21472;&#21152;&#38598;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
An Explainable Stacked Ensemble Model for Static Route-Free Estimation of Time of Arrival. (arXiv:2203.09438v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.09438
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#21472;&#21152;&#38598;&#25104;&#27169;&#22411;&#65292;&#29992;&#20110;&#38745;&#24577;&#26080;&#36335;&#24452;&#20272;&#35745;&#21040;&#36798;&#26102;&#38388;&#12290;&#35813;&#27169;&#22411;&#23558;&#22810;&#20010;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#32452;&#21512;&#25104;&#19968;&#20010;&#26032;&#30340;&#38598;&#25104;&#32467;&#26500;&#65292;&#33021;&#22815;&#36229;&#36234;&#20808;&#21069;&#30340;&#26368;&#20808;&#36827;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#27604;&#36739;&#22791;&#36873;&#30340;&#20986;&#31199;&#36710;&#34892;&#31243;&#24182;&#35745;&#31639;&#23427;&#20204;&#65292;&#20197;&#21450;&#20026;&#39550;&#39542;&#21592;&#21644;&#20056;&#23458;&#25552;&#20379;&#20851;&#20110;&#21363;&#23558;&#21040;&#26469;&#30340;&#20986;&#31199;&#36710;&#34892;&#31243;&#30340;&#35265;&#35299;&#65292;&#38656;&#35201;&#39044;&#27979;&#34892;&#31243;&#30340;&#25345;&#32493;&#26102;&#38388;&#25110;&#20854;&#39044;&#35745;&#21040;&#36798;&#26102;&#38388;&#65288;ETA&#65289;&#12290;&#20026;&#20102;&#36798;&#21040;&#36739;&#39640;&#30340;&#39044;&#27979;&#31934;&#24230;&#65292;ETA&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26159;&#30446;&#21069;&#30340;&#25216;&#26415;&#27700;&#24179;&#12290;&#36827;&#19968;&#27493;&#25552;&#39640;&#39044;&#27979;&#31934;&#24230;&#30340;&#19968;&#20010;&#23578;&#26410;&#24320;&#21457;&#30340;&#36873;&#39033;&#26159;&#23558;&#22810;&#20010;ETA&#27169;&#22411;&#32452;&#21512;&#25104;&#19968;&#20010;&#38598;&#25104;&#27169;&#22411;&#12290;&#23613;&#31649;&#39044;&#27979;&#31934;&#24230;&#21487;&#33021;&#20250;&#22686;&#21152;&#65292;&#20294;&#36825;&#31181;&#38598;&#25104;&#27169;&#22411;&#30340;&#39044;&#27979;&#32467;&#26524;&#30001;&#20110;&#22797;&#26434;&#30340;&#38598;&#25104;&#32467;&#26500;&#32780;&#21464;&#24471;&#19981;&#22815;&#36879;&#26126;&#12290;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#19968;&#31181;&#26041;&#27861;&#26159;&#24212;&#29992;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#12290;&#26412;&#25991;&#30340;&#36129;&#29486;&#26377;&#19977;&#20010;&#26041;&#38754;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#20808;&#21069;&#24037;&#20316;&#20013;&#30340;&#22810;&#20010;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#32452;&#21512;&#25104;&#19968;&#20010;&#20004;&#23618;&#30340;&#38598;&#25104;&#27169;&#22411;- &#19968;&#20010;&#21472;&#21152;&#38598;&#25104;&#27169;&#22411;- &#36825;&#26412;&#36523;&#23601;&#26159;&#19968;&#31181;&#21019;&#26032;&#65307;&#22240;&#27492;&#65292;&#25105;&#20204;&#21487;&#20197;&#36229;&#36234;&#20808;&#21069;&#30340;&#38745;&#24577;&#36335;&#24452;&#26080;&#20851;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
To compare alternative taxi schedules and to compute them, as well as to provide insights into an upcoming taxi trip to drivers and passengers, the duration of a trip or its Estimated Time of Arrival (ETA) is predicted. To reach a high prediction precision, machine learning models for ETA are state of the art. One yet unexploited option to further increase prediction precision is to combine multiple ETA models into an ensemble. While an increase of prediction precision is likely, the main drawback is that the predictions made by such an ensemble become less transparent due to the sophisticated ensemble architecture. One option to remedy this drawback is to apply eXplainable Artificial Intelligence (XAI). The contribution of this paper is three-fold. First, we combine multiple machine learning models from our previous work for ETA into a two-level ensemble model - a stacked ensemble model - which on its own is novel; therefore, we can outperform previous state-of-the-art static route-fr
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;GPEX&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#37322;&#28145;&#24230;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#25512;&#23548;&#20986;&#19968;&#20010;&#35777;&#25454;&#19979;&#30028;&#26469;&#21305;&#37197;&#31070;&#32463;&#32593;&#32476;&#30340;&#36755;&#20986;&#65292;&#32780;&#19981;&#23545;&#31070;&#32463;&#32593;&#32476;&#20570;&#20986;&#20219;&#20309;&#29305;&#23450;&#35201;&#27714;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#19968;&#20123;&#29702;&#35770;&#20551;&#35774;&#19979;&#65292;&#21482;&#38656;&#35201;&#31616;&#21333;&#30340;&#32593;&#32476;&#32467;&#26500;&#21363;&#21487;&#36798;&#21040;&#33391;&#22909;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2112.09820</link><description>&lt;p&gt;
GPEX&#65292;&#29992;&#20110;&#35299;&#37322;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#30340;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
GPEX, A Framework For Interpreting Artificial Neural Networks. (arXiv:2112.09820v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.09820
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;GPEX&#26694;&#26550;&#65292;&#29992;&#20110;&#35299;&#37322;&#28145;&#24230;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#25512;&#23548;&#20986;&#19968;&#20010;&#35777;&#25454;&#19979;&#30028;&#26469;&#21305;&#37197;&#31070;&#32463;&#32593;&#32476;&#30340;&#36755;&#20986;&#65292;&#32780;&#19981;&#23545;&#31070;&#32463;&#32593;&#32476;&#20570;&#20986;&#20219;&#20309;&#29305;&#23450;&#35201;&#27714;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#19968;&#20123;&#29702;&#35770;&#20551;&#35774;&#19979;&#65292;&#21482;&#38656;&#35201;&#31616;&#21333;&#30340;&#32593;&#32476;&#32467;&#26500;&#21363;&#21487;&#36798;&#21040;&#33391;&#22909;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#65288;GPs&#65289;&#19982;&#28145;&#24230;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#65288;ANNs&#65289;&#20043;&#38388;&#30340;&#31867;&#27604;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#65292;&#24182;&#26174;&#31034;&#20986;&#25581;&#31034;&#28145;&#24230;ANN&#30340;&#40657;&#31665;&#30340;&#28508;&#21147;&#12290;&#29616;&#26377;&#30340;&#29702;&#35770;&#24037;&#20316;&#23545;ANN&#25552;&#20986;&#20102;&#20005;&#26684;&#30340;&#20551;&#35774;&#65288;&#20363;&#22914;&#65292;&#35201;&#27714;&#25152;&#26377;&#20013;&#38388;&#23618;&#20026;&#23485;&#23618;&#65292;&#25110;&#20351;&#29992;&#29305;&#23450;&#30340;&#28608;&#27963;&#20989;&#25968;&#65289;&#12290;&#36866;&#24212;&#36825;&#20123;&#29702;&#35770;&#20551;&#35774;&#22312;&#26368;&#36817;&#30340;&#28145;&#23618;&#26550;&#26500;&#20013;&#24456;&#22256;&#38590;&#65292;&#24182;&#19988;&#38543;&#30528;&#26032;&#30340;&#28145;&#23618;&#26550;&#26500;&#30340;&#20986;&#29616;&#65292;&#36825;&#20123;&#29702;&#35770;&#26465;&#20214;&#38656;&#35201;&#36827;&#19968;&#27493;&#23436;&#21892;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#19968;&#20010;&#35777;&#25454;&#19979;&#30028;&#65292;&#40723;&#21169;GP&#30340;&#21518;&#39564;&#19982;ANN&#30340;&#36755;&#20986;&#21305;&#37197;&#65292;&#32780;&#19981;&#23545;ANN&#20570;&#20219;&#20309;&#35201;&#27714;&#12290;&#20351;&#29992;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;5&#20010;&#25968;&#25454;&#38598;&#19978;&#65292;&#21482;&#26377;&#19968;&#37096;&#20998;&#29702;&#35770;&#20551;&#35774;&#23601;&#36275;&#22815;&#20102;&#12290;&#23454;&#38469;&#19978;&#65292;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#19968;&#20010;&#26222;&#36890;&#30340;ResNet-18&#25110;&#21069;&#39304;&#39592;&#24178;&#32593;&#32476;&#65292;&#24182;&#22312;&#26411;&#31471;&#20351;&#29992;&#20102;&#19968;&#20010;&#23485;&#23618;&#12290;&#35757;&#32451;GPs&#30340;&#19968;&#20010;&#23616;&#38480;&#24615;&#26159;&#22312;&#20110;&#19982;&#35825;&#23548;&#28857;&#25968;&#37327;&#30340;&#21487;&#25193;&#23637;&#24615;&#30340;&#32570;&#20047;&#12290;
&lt;/p&gt;
&lt;p&gt;
The analogy between Gaussian processes (GPs) and deep artificial neural networks (ANNs) has received a lot of interest, and has shown promise to unbox the blackbox of deep ANNs. Existing theoretical works put strict assumptions on the ANN (e.g. requiring all intermediate layers to be wide, or using specific activation functions). Accommodating those theoretical assumptions is hard in recent deep architectures, and those theoretical conditions need refinement as new deep architectures emerge. In this paper we derive an evidence lower-bound that encourages the GP's posterior to match the ANN's output without any requirement on the ANN. Using our method we find out that on 5 datasets, only a subset of those theoretical assumptions are sufficient. Indeed, in our experiments we used a normal ResNet-18 or feed-forward backbone with a single wide layer in the end. One limitation of training GPs is the lack of scalability with respect to the number of inducing points. We use novel computationa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#33258;&#36866;&#24212;&#21464;&#20998;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#22810;&#20010;&#27169;&#22411;&#19978;&#36816;&#34892;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#33258;&#36866;&#24212;&#22320;&#23454;&#29616;&#26368;&#20248;&#30340;&#25910;&#32553;&#36895;&#29575;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#25216;&#26415;&#26041;&#27861;&#26469;&#20445;&#25345;&#21487;&#35745;&#31639;&#24615;&#21644;&#33258;&#36866;&#24212;&#26368;&#20248;&#24615;&#12290;</title><link>http://arxiv.org/abs/2109.03204</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#21464;&#20998;&#36125;&#21494;&#26031;&#65306;&#20248;&#21270;&#24615;&#36136;&#65292;&#35745;&#31639;&#21644;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Adaptive variational Bayes: Optimality, computation and applications. (arXiv:2109.03204v3 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.03204
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#33258;&#36866;&#24212;&#21464;&#20998;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#22810;&#20010;&#27169;&#22411;&#19978;&#36816;&#34892;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#33258;&#36866;&#24212;&#22320;&#23454;&#29616;&#26368;&#20248;&#30340;&#25910;&#32553;&#36895;&#29575;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#25216;&#26415;&#26041;&#27861;&#26469;&#20445;&#25345;&#21487;&#35745;&#31639;&#24615;&#21644;&#33258;&#36866;&#24212;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#22522;&#20110;&#21464;&#20998;&#36125;&#21494;&#26031;&#30340;&#33258;&#36866;&#24212;&#25512;&#26029;&#12290;&#34429;&#28982;&#24050;&#32463;&#36827;&#34892;&#20102;&#19968;&#20123;&#30740;&#31350;&#26469;&#20998;&#26512;&#21464;&#20998;&#21518;&#39564;&#30340;&#25910;&#25947;&#24615;&#36136;&#65292;&#20294;&#20173;&#28982;&#32570;&#20047;&#19968;&#31181;&#36890;&#29992;&#19988;&#20855;&#26377;&#35745;&#31639;&#21487;&#34892;&#24615;&#30340;&#33258;&#36866;&#24212;&#21464;&#20998;&#36125;&#21494;&#26031;&#26041;&#27861;&#12290;&#20026;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#33258;&#36866;&#24212;&#21464;&#20998;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#22810;&#20010;&#27169;&#22411;&#19978;&#36816;&#34892;&#12290;&#35813;&#26694;&#26550;&#39318;&#20808;&#20998;&#21035;&#35745;&#31639;&#27599;&#20010;&#21333;&#29420;&#27169;&#22411;&#30340;&#21464;&#20998;&#21518;&#39564;&#65292;&#28982;&#21518;&#23558;&#23427;&#20204;&#19982;&#19968;&#23450;&#30340;&#26435;&#37325;&#32467;&#21512;&#36215;&#26469;&#65292;&#20135;&#29983;&#25972;&#20010;&#27169;&#22411;&#30340;&#21464;&#20998;&#21518;&#39564;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#20010;&#32452;&#21512;&#30340;&#21464;&#20998;&#21518;&#39564;&#26159;&#22312;&#39044;&#23450;&#20041;&#30340;&#19968;&#26063;&#36817;&#20284;&#20998;&#24067;&#20013;&#26368;&#25509;&#36817;&#25972;&#20010;&#27169;&#22411;&#30340;&#21518;&#39564;&#30340;&#25104;&#21592;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#38750;&#24120;&#26222;&#36941;&#30340;&#26465;&#20214;&#19979;&#65292;&#33258;&#36866;&#24212;&#21464;&#20998;&#36125;&#21494;&#26031;&#21487;&#20197;&#33258;&#36866;&#24212;&#22320;&#23454;&#29616;&#26368;&#20248;&#30340;&#25910;&#32553;&#36895;&#29575;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#31181;&#25216;&#26415;&#26041;&#27861;&#26469;&#20445;&#25345;&#21487;&#35745;&#31639;&#24615;&#21644;&#33258;&#36866;&#24212;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we explore adaptive inference based on variational Bayes. Although several studies have been conducted to analyze the contraction properties of variational posteriors, there is still a lack of a general and computationally tractable variational Bayes method that performs adaptive inference. To fill this gap, we propose a novel adaptive variational Bayes framework, which can operate on a collection of models. The proposed framework first computes a variational posterior over each individual model separately and then combines them with certain weights to produce a variational posterior over the entire model. It turns out that this combined variational posterior is the closest member to the posterior over the entire model in a predefined family of approximating distributions. We show that the adaptive variational Bayes attains optimal contraction rates adaptively under very general conditions. We also provide a methodology to maintain the tractability and adaptive optimalit
&lt;/p&gt;</description></item></channel></rss>