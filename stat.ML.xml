<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#20301;&#32622;&#32534;&#30721;&#26041;&#27861;&#65292;&#32966;&#23618;&#20301;&#32622;&#32534;&#30721;&#65288;BiPE&#65289;&#65292;&#36890;&#36807;&#23558;&#20998;&#27573;&#20869;&#32534;&#30721;&#21644;&#20998;&#27573;&#38388;&#32534;&#30721;&#32467;&#21512;&#36215;&#26469;&#65292;&#20197;&#25552;&#39640;&#27169;&#22411;&#23545;&#35821;&#20041;&#20449;&#24687;&#30340;&#25429;&#25417;&#21644;&#25512;&#27979;&#33021;&#21147;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;BiPE&#22312;&#19981;&#21516;&#25991;&#26412;&#27169;&#24577;&#30340;&#20219;&#21153;&#20013;&#20855;&#26377;&#20248;&#36234;&#30340;&#38271;&#24230;&#25512;&#27979;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2401.16421</link><description>&lt;p&gt;
&#20004;&#31181;&#30707;&#22836;&#20987;&#25171;&#19968;&#21482;&#40479;&#65306;&#32966;&#23618;&#20301;&#32622;&#32534;&#30721;&#20197;&#26356;&#22909;&#22320;&#25512;&#27979;&#38271;&#24230;
&lt;/p&gt;
&lt;p&gt;
Two Stones Hit One Bird: Bilevel Positional Encoding for Better Length Extrapolation. (arXiv:2401.16421v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16421
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#20301;&#32622;&#32534;&#30721;&#26041;&#27861;&#65292;&#32966;&#23618;&#20301;&#32622;&#32534;&#30721;&#65288;BiPE&#65289;&#65292;&#36890;&#36807;&#23558;&#20998;&#27573;&#20869;&#32534;&#30721;&#21644;&#20998;&#27573;&#38388;&#32534;&#30721;&#32467;&#21512;&#36215;&#26469;&#65292;&#20197;&#25552;&#39640;&#27169;&#22411;&#23545;&#35821;&#20041;&#20449;&#24687;&#30340;&#25429;&#25417;&#21644;&#25512;&#27979;&#33021;&#21147;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;BiPE&#22312;&#19981;&#21516;&#25991;&#26412;&#27169;&#24577;&#30340;&#20219;&#21153;&#20013;&#20855;&#26377;&#20248;&#36234;&#30340;&#38271;&#24230;&#25512;&#27979;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#35821;&#35328;&#24207;&#21015;&#30340;&#20869;&#22312;&#20998;&#21106;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#30340;&#20301;&#32622;&#32534;&#30721;&#26041;&#27861;&#65292;&#31216;&#20026;&#32966;&#23618;&#20301;&#32622;&#32534;&#30721;&#65288;BiPE&#65289;&#12290;&#23545;&#20110;&#27599;&#20010;&#20301;&#32622;&#65292;&#25105;&#20204;&#30340;BiPE&#23558;&#20998;&#27573;&#20869;&#32534;&#30721;&#21644;&#20998;&#27573;&#38388;&#32534;&#30721;&#34701;&#21512;&#22312;&#19968;&#36215;&#12290;&#20998;&#27573;&#20869;&#32534;&#30721;&#29992;&#20110;&#35782;&#21035;&#27573;&#20869;&#20301;&#32622;&#65292;&#24182;&#36890;&#36807;&#32477;&#23545;&#20301;&#32622;&#32534;&#30721;&#24110;&#21161;&#27169;&#22411;&#25429;&#25417;&#20854;&#20013;&#30340;&#35821;&#20041;&#20449;&#24687;&#12290;&#20998;&#27573;&#38388;&#32534;&#30721;&#21017;&#29992;&#20110;&#25351;&#23450;&#27573;&#32034;&#24341;&#65292;&#24314;&#27169;&#27573;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#26088;&#22312;&#36890;&#36807;&#30456;&#23545;&#20301;&#32622;&#32534;&#30721;&#25552;&#39640;&#25512;&#27979;&#33021;&#21147;&#12290;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;&#20301;&#32622;&#20449;&#24687;&#30340;&#35299;&#32806;&#20351;&#23398;&#20064;&#26356;&#21152;&#26377;&#25928;&#12290;&#32463;&#39564;&#32467;&#26524;&#36824;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;BiPE&#22312;&#19981;&#21516;&#25991;&#26412;&#27169;&#24577;&#30340;&#21508;&#31181;&#20219;&#21153;&#20013;&#20855;&#26377;&#20248;&#36234;&#30340;&#38271;&#24230;&#25512;&#27979;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we leverage the intrinsic segmentation of language sequences and design a new positional encoding method called Bilevel Positional Encoding (BiPE). For each position, our BiPE blends an intra-segment encoding and an inter-segment encoding. The intra-segment encoding identifies the locations within a segment and helps the model capture the semantic information therein via absolute positional encoding. The inter-segment encoding specifies the segment index, models the relationships between segments, and aims to improve extrapolation capabilities via relative positional encoding. Theoretical analysis shows this disentanglement of positional information makes learning more effective. The empirical results also show that our BiPE has superior length extrapolation capabilities across a wide range of tasks in diverse text modalities.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21322;&#21442;&#25968;&#19987;&#23478;&#36125;&#21494;&#26031;&#32593;&#32476;&#23398;&#20064;&#27169;&#22411;&#65292;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#21644;Horseshoe&#20808;&#39564;&#24341;&#20837;&#26368;&#23567;&#30340;&#38750;&#32447;&#24615;&#32452;&#20214;&#65292;&#20248;&#21270;&#20102;&#24046;&#20998;Horseshoe&#23610;&#24230;&#65292;&#36890;&#36807;&#29983;&#25104;&#22810;&#26679;&#30340;&#22270;&#26469;&#36866;&#24212;&#29992;&#25143;&#36755;&#20837;&#65292;&#35299;&#20915;&#21487;&#36776;&#35782;&#24615;&#38382;&#39064;&#24182;&#22686;&#24378;&#21487;&#35299;&#37322;&#24615;&#65292;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126;&#35813;&#27169;&#22411;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#21322;&#21442;&#25968;&#36125;&#21494;&#26031;&#32593;&#32476;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2401.16419</link><description>&lt;p&gt;
&#29992;&#39640;&#26031;&#36807;&#31243;&#21644;Horseshoe&#20808;&#39564;&#30340;&#21322;&#21442;&#25968;&#19987;&#23478;&#36125;&#21494;&#26031;&#32593;&#32476;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Semi-parametric Expert Bayesian Network Learning with Gaussian Processes and Horseshoe Priors. (arXiv:2401.16419v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16419
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21322;&#21442;&#25968;&#19987;&#23478;&#36125;&#21494;&#26031;&#32593;&#32476;&#23398;&#20064;&#27169;&#22411;&#65292;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#21644;Horseshoe&#20808;&#39564;&#24341;&#20837;&#26368;&#23567;&#30340;&#38750;&#32447;&#24615;&#32452;&#20214;&#65292;&#20248;&#21270;&#20102;&#24046;&#20998;Horseshoe&#23610;&#24230;&#65292;&#36890;&#36807;&#29983;&#25104;&#22810;&#26679;&#30340;&#22270;&#26469;&#36866;&#24212;&#29992;&#25143;&#36755;&#20837;&#65292;&#35299;&#20915;&#21487;&#36776;&#35782;&#24615;&#38382;&#39064;&#24182;&#22686;&#24378;&#21487;&#35299;&#37322;&#24615;&#65292;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#35780;&#20272;&#32467;&#26524;&#34920;&#26126;&#35813;&#27169;&#22411;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#21322;&#21442;&#25968;&#36125;&#21494;&#26031;&#32593;&#32476;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#19987;&#23478;&#36125;&#21494;&#26031;&#32593;&#32476;&#65288;SEBN&#65289;&#20013;&#23398;&#20064;&#21322;&#21442;&#25968;&#20851;&#31995;&#30340;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#20855;&#26377;&#32447;&#24615;&#21442;&#25968;&#21644;&#32467;&#26500;&#32422;&#26463;&#12290;&#25105;&#20204;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#21644;Horseshoe&#20808;&#39564;&#24341;&#20837;&#26368;&#23567;&#30340;&#38750;&#32447;&#24615;&#32452;&#20214;&#12290;&#20026;&#20102;&#20248;&#20808;&#35843;&#25972;&#19987;&#23478;&#22270;&#32780;&#19981;&#26159;&#28155;&#21152;&#26032;&#36793;&#65292;&#25105;&#20204;&#20248;&#21270;&#20102;&#24046;&#20998;Horseshoe&#23610;&#24230;&#12290;&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#20013;&#65292;&#25105;&#20204;&#29983;&#25104;&#20102;&#22810;&#26679;&#30340;&#22270;&#20197;&#36866;&#24212;&#29992;&#25143;&#36755;&#20837;&#65292;&#35299;&#20915;&#20102;&#21487;&#36776;&#35782;&#24615;&#38382;&#39064;&#24182;&#22686;&#24378;&#20102;&#21487;&#35299;&#37322;&#24615;&#12290;&#20351;&#29992;&#32467;&#26500;Hamming&#36317;&#31163;&#21644;&#27979;&#35797;&#20284;&#28982;&#31561;&#25351;&#26631;&#22312;&#21512;&#25104;&#21644;UCI&#32925;&#30149;&#25968;&#25454;&#38598;&#19978;&#30340;&#35780;&#20272;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#21322;&#21442;&#25968;&#36125;&#21494;&#26031;&#32593;&#32476;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a model learning Semi-parametric rela- tionships in an Expert Bayesian Network (SEBN) with linear parameter and structure constraints. We use Gaussian Pro- cesses and a Horseshoe prior to introduce minimal nonlinear components. To prioritize modifying the expert graph over adding new edges, we optimize differential Horseshoe scales. In real-world datasets with unknown truth, we gen- erate diverse graphs to accommodate user input, addressing identifiability issues and enhancing interpretability. Evalua- tion on synthetic and UCI Liver Disorders datasets, using metrics like structural Hamming Distance and test likelihood, demonstrates our models outperform state-of-the-art semi- parametric Bayesian Network model.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#23558;&#24067;&#23572;&#36923;&#36753;&#29992;&#20316;&#31070;&#32463;&#32593;&#32476;&#30340;&#38169;&#35823;&#21453;&#39304;&#26426;&#21046;&#65292;&#24182;&#36827;&#34892;&#20102;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2401.16418</link><description>&lt;p&gt;
&#24067;&#23572;&#36923;&#36753;&#20316;&#20026;&#19968;&#20010;&#38169;&#35823;&#21453;&#39304;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
Boolean Logic as an Error feedback mechanism. (arXiv:2401.16418v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16418
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#23558;&#24067;&#23572;&#36923;&#36753;&#29992;&#20316;&#31070;&#32463;&#32593;&#32476;&#30340;&#38169;&#35823;&#21453;&#39304;&#26426;&#21046;&#65292;&#24182;&#36827;&#34892;&#20102;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#24067;&#23572;&#36923;&#36753;&#21453;&#21521;&#20256;&#25773;&#30340;&#27010;&#24565;&#65292;&#29992;&#20110;&#26500;&#24314;&#20855;&#26377;&#24067;&#23572;&#25968;&#23383;&#26435;&#37325;&#21644;&#28608;&#27963;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#22823;&#37096;&#20998;&#35745;&#31639;&#21487;&#20197;&#20351;&#29992;&#24067;&#23572;&#36923;&#36753;&#32780;&#19981;&#26159;&#23454;&#25968;&#31639;&#26415;&#36827;&#34892;&#65292;&#22312;&#35757;&#32451;&#21644;&#25512;&#29702;&#38454;&#27573;&#37117;&#21487;&#20197;&#20351;&#29992;&#12290;&#20294;&#26159;&#24213;&#23618;&#30340;&#31163;&#25955;&#20248;&#21270;&#38382;&#39064;&#26159;NP&#38590;&#30340;&#65292;&#24182;&#19988;&#24067;&#23572;&#36923;&#36753;&#27809;&#26377;&#20445;&#35777;&#12290;&#26412;&#25991;&#22312;&#26631;&#20934;&#38750;&#20984;&#20551;&#35774;&#19979;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
The notion of Boolean logic backpropagation was introduced to build neural networks with weights and activations being Boolean numbers. Most of computations can be done with Boolean logic instead of real arithmetic, both during training and inference phases. But the underlying discrete optimization problem is NP-hard, and the Boolean logic has no guarantee. In this work we propose the first convergence analysis, under standard non-convex assumptions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;ReTaSA&#30340;&#38750;&#21442;&#25968;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#36830;&#32493;&#30446;&#26631;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#65292;&#36890;&#36807;&#20272;&#35745;&#37325;&#35201;&#26435;&#37325;&#20989;&#25968;&#26469;&#35299;&#20915;&#35813;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.16410</link><description>&lt;p&gt;
ReTaSA&#65306;&#19968;&#31181;&#35299;&#20915;&#36830;&#32493;&#30446;&#26631;&#20998;&#24067;&#20559;&#31227;&#30340;&#38750;&#21442;&#25968;&#20989;&#25968;&#20272;&#35745;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
ReTaSA: A Nonparametric Functional Estimation Approach for Addressing Continuous Target Shift. (arXiv:2401.16410v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16410
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;ReTaSA&#30340;&#38750;&#21442;&#25968;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#36830;&#32493;&#30446;&#26631;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#65292;&#36890;&#36807;&#20272;&#35745;&#37325;&#35201;&#26435;&#37325;&#20989;&#25968;&#26469;&#35299;&#20915;&#35813;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#20559;&#31227;&#30340;&#23384;&#22312;&#22312;&#23558;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#37096;&#32626;&#21040;&#23454;&#38469;&#24212;&#29992;&#20013;&#25552;&#20986;&#20102;&#37325;&#35201;&#25361;&#25112;&#12290;&#26412;&#25991;&#20851;&#27880;&#22238;&#24402;&#22330;&#26223;&#20013;&#30340;&#30446;&#26631;&#20559;&#31227;&#38382;&#39064;&#65292;&#29305;&#21035;&#26159;&#30446;&#26631;&#21464;&#37327; y&#65288;&#20063;&#31216;&#20026;&#21709;&#24212;&#21464;&#37327;&#65289;&#22312;&#35757;&#32451;&#26469;&#28304;&#21644;&#27979;&#35797;&#39046;&#22495;&#20013;&#20855;&#26377;&#19981;&#21516;&#30340;&#36793;&#32536;&#20998;&#24067;&#65292;&#32780;&#32473;&#23450; y &#30340;&#29305;&#24449; x &#30340;&#26465;&#20214;&#20998;&#24067;&#20445;&#25345;&#19981;&#21464;&#12290;&#34429;&#28982;&#22823;&#37096;&#20998;&#25991;&#29486;&#38598;&#20013;&#22312;&#26377;&#38480;&#30446;&#26631;&#31354;&#38388;&#30340;&#20998;&#31867;&#20219;&#21153;&#19978;&#65292;&#20294;&#22238;&#24402;&#38382;&#39064;&#20855;&#26377;&#26080;&#38480;&#32500;&#30340;&#30446;&#26631;&#31354;&#38388;&#65292;&#36825;&#20351;&#24471;&#35768;&#22810;&#29616;&#26377;&#26041;&#27861;&#19981;&#36866;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21487;&#20197;&#36890;&#36807;&#20174;&#19968;&#20010;&#30149;&#24577;&#31215;&#20998;&#26041;&#31243;&#20272;&#35745;&#37325;&#35201;&#26435;&#37325;&#20989;&#25968;&#26469;&#35299;&#20915;&#36830;&#32493;&#30446;&#26631;&#20559;&#31227;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#27491;&#21017;&#21270;&#26041;&#27861; ReTaSA &#26469;&#35299;&#20915;&#30149;&#24577;&#31215;&#20998;&#26041;&#31243;&#65292;&#24182;&#25552;&#20379;&#20102;&#29702;&#35770;&#19978;&#30340;&#20381;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
The presence of distribution shifts poses a significant challenge for deploying modern machine learning models in real-world applications. This work focuses on the target shift problem in a regression setting (Zhang et al., 2013; Nguyen et al., 2016). More specifically, the target variable y (also known as the response variable), which is continuous, has different marginal distributions in the training source and testing domain, while the conditional distribution of features x given y remains the same. While most literature focuses on classification tasks with finite target space, the regression problem has an infinite dimensional target space, which makes many of the existing methods inapplicable. In this work, we show that the continuous target shift problem can be addressed by estimating the importance weight function from an ill-posed integral equation. We propose a nonparametric regularized approach named ReTaSA to solve the ill-posed integral equation and provide theoretical just
&lt;/p&gt;</description></item><item><title>K&#25240;&#20132;&#21449;&#39564;&#35777;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#26159;&#24120;&#29992;&#30340;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#20294;&#22312;&#22788;&#29702;&#23567;&#26679;&#26412;&#25968;&#25454;&#38598;&#21644;&#24322;&#36136;&#25968;&#25454;&#28304;&#26102;&#23384;&#22312;&#22256;&#38590;&#12290;</title><link>http://arxiv.org/abs/2401.16407</link><description>&lt;p&gt;
K&#25240;&#20132;&#21449;&#39564;&#35777;&#26159;&#21542;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#22909;&#30340;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65311;
&lt;/p&gt;
&lt;p&gt;
Is K-fold cross validation the best model selection method for Machine Learning?. (arXiv:2401.16407v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16407
&lt;/p&gt;
&lt;p&gt;
K&#25240;&#20132;&#21449;&#39564;&#35777;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#26159;&#24120;&#29992;&#30340;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#20294;&#22312;&#22788;&#29702;&#23567;&#26679;&#26412;&#25968;&#25454;&#38598;&#21644;&#24322;&#36136;&#25968;&#25454;&#28304;&#26102;&#23384;&#22312;&#22256;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20316;&#20026;&#19968;&#31181;&#33021;&#22815;&#32039;&#20945;&#34920;&#31034;&#22797;&#26434;&#27169;&#24335;&#30340;&#25216;&#26415;&#65292;&#20855;&#26377;&#26174;&#33879;&#30340;&#39044;&#27979;&#25512;&#29702;&#28508;&#21147;&#12290;K&#25240;&#20132;&#21449;&#39564;&#35777;&#65288;CV&#65289;&#26159;&#30830;&#23450;&#26426;&#22120;&#23398;&#20064;&#32467;&#26524;&#26159;&#21542;&#26159;&#38543;&#26426;&#29983;&#25104;&#30340;&#26368;&#24120;&#29992;&#26041;&#27861;&#65292;&#24182;&#32463;&#24120;&#20248;&#20110;&#20256;&#32479;&#30340;&#20551;&#35774;&#26816;&#39564;&#12290;&#36825;&#31181;&#25913;&#36827;&#21033;&#29992;&#20102;&#30452;&#25509;&#20174;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#20013;&#33719;&#24471;&#30340;&#24230;&#37327;&#65292;&#27604;&#22914;&#20934;&#30830;&#24615;&#65292;&#36825;&#20123;&#24230;&#37327;&#27809;&#26377;&#21442;&#25968;&#25551;&#36848;&#12290;&#20026;&#20102;&#22312;&#26426;&#22120;&#23398;&#20064;&#27969;&#31243;&#20013;&#36827;&#34892;&#39057;&#29575;&#20998;&#26512;&#65292;&#21487;&#20197;&#28155;&#21152;&#25490;&#21015;&#27979;&#35797;&#25110;&#26469;&#33258;&#25968;&#25454;&#20998;&#21306;&#65288;&#21363;&#25240;&#21472;&#65289;&#30340;&#31616;&#21333;&#32479;&#35745;&#37327;&#26469;&#20272;&#35745;&#32622;&#20449;&#21306;&#38388;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#26080;&#35770;&#26159;&#21442;&#25968;&#21270;&#36824;&#26159;&#38750;&#21442;&#25968;&#21270;&#27979;&#35797;&#37117;&#26080;&#27861;&#35299;&#20915;&#22260;&#32469;&#20998;&#21106;&#23567;&#26679;&#26412;&#25968;&#25454;&#38598;&#21644;&#26469;&#33258;&#24322;&#36136;&#25968;&#25454;&#28304;&#30340;&#23398;&#20064;&#22266;&#26377;&#38382;&#39064;&#12290;&#26426;&#22120;&#23398;&#20064;&#20005;&#37325;&#20381;&#36182;&#23398;&#20064;&#21442;&#25968;&#21644;&#25968;&#25454;&#22312;&#25240;&#21472;&#20013;&#30340;&#20998;&#24067;&#65292;&#36825;&#37325;&#26032;&#27010;&#25324;&#20102;&#29087;&#24713;&#30340;&#22256;&#38590;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
As a technique that can compactly represent complex patterns, machine learning has significant potential for predictive inference. K-fold cross-validation (CV) is the most common approach to ascertaining the likelihood that a machine learning outcome is generated by chance and frequently outperforms conventional hypothesis testing. This improvement uses measures directly obtained from machine learning classifications, such as accuracy, that do not have a parametric description. To approach a frequentist analysis within machine learning pipelines, a permutation test or simple statistics from data partitions (i.e. folds) can be added to estimate confidence intervals. Unfortunately, neither parametric nor non-parametric tests solve the inherent problems around partitioning small sample-size datasets and learning from heterogeneous data sources. The fact that machine learning strongly depends on the learning parameters and the distribution of data across folds recapitulates familiar diffic
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#8220;&#36845;&#20195;&#25968;&#25454;&#24179;&#28369;&#8221;&#30340;&#25913;&#36827;&#22870;&#21169;&#23398;&#20064;&#31639;&#27861;&#65292;&#29992;&#20110;&#20943;&#36731;&#24378;&#21270;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#30340;&#36807;&#25311;&#21512;&#21644;&#36807;&#20248;&#21270;&#38382;&#39064;&#12290;&#36890;&#36807;&#22312;&#27599;&#20010;&#35757;&#32451;&#36718;&#27425;&#20013;&#26356;&#26032;&#27169;&#22411;&#21644;&#25968;&#25454;&#65292;&#24182;&#29992;&#36719;&#26631;&#31614;&#26367;&#25442;&#30828;&#26631;&#31614;&#65292;&#35813;&#26041;&#27861;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.16335</link><description>&lt;p&gt;
&#36845;&#20195;&#25968;&#25454;&#24179;&#28369;&#65306;&#20943;&#36731;&#24378;&#21270;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#36807;&#25311;&#21512;&#21644;&#36807;&#20248;&#21270;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Iterative Data Smoothing: Mitigating Reward Overfitting and Overoptimization in RLHF. (arXiv:2401.16335v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16335
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#8220;&#36845;&#20195;&#25968;&#25454;&#24179;&#28369;&#8221;&#30340;&#25913;&#36827;&#22870;&#21169;&#23398;&#20064;&#31639;&#27861;&#65292;&#29992;&#20110;&#20943;&#36731;&#24378;&#21270;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#30340;&#36807;&#25311;&#21512;&#21644;&#36807;&#20248;&#21270;&#38382;&#39064;&#12290;&#36890;&#36807;&#22312;&#27599;&#20010;&#35757;&#32451;&#36718;&#27425;&#20013;&#26356;&#26032;&#27169;&#22411;&#21644;&#25968;&#25454;&#65292;&#24182;&#29992;&#36719;&#26631;&#31614;&#26367;&#25442;&#30828;&#26631;&#31614;&#65292;&#35813;&#26041;&#27861;&#34920;&#29616;&#20986;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#65288;RLHF&#65289;&#26159;&#19968;&#31181;&#20351;&#35821;&#35328;&#27169;&#22411;&#19982;&#20154;&#31867;&#20013;&#24515;&#20215;&#20540;&#32039;&#23494;&#23545;&#40784;&#30340;&#20851;&#38190;&#25216;&#26415;&#12290;RLHF&#30340;&#21021;&#22987;&#38454;&#27573;&#28041;&#21450;&#20351;&#29992;&#25490;&#21517;&#25968;&#25454;&#30340;&#22870;&#21169;&#27169;&#22411;&#26469;&#23398;&#20064;&#20154;&#31867;&#20215;&#20540;&#35266;&#12290;&#35266;&#23519;&#21040;&#22312;&#19968;&#36718;&#35757;&#32451;&#21518;&#65292;&#22870;&#21169;&#27169;&#22411;&#30340;&#24615;&#33021;&#20250;&#19979;&#38477;&#65292;&#24182;&#19988;&#36807;&#22810;&#22320;&#20248;&#21270;&#23398;&#20064;&#21040;&#30340;&#22870;&#21169;&#27169;&#22411;&#26368;&#32456;&#20250;&#38459;&#30861;&#30495;&#27491;&#30340;&#30446;&#26631;&#12290;&#26412;&#25991;&#28145;&#20837;&#30740;&#31350;&#20102;&#36825;&#20123;&#38382;&#39064;&#65292;&#24182;&#21033;&#29992;&#29702;&#35770;&#27934;&#23519;&#21147;&#35774;&#35745;&#20102;&#25913;&#36827;&#30340;&#22870;&#21169;&#23398;&#20064;&#31639;&#27861;&#65292;&#31216;&#20026;&#8220;&#36845;&#20195;&#25968;&#25454;&#24179;&#28369;&#8221;&#65288;IDS&#65289;&#12290;&#26680;&#24515;&#24605;&#24819;&#26159;&#22312;&#27599;&#20010;&#35757;&#32451;&#36718;&#27425;&#20013;&#65292;&#25105;&#20204;&#19981;&#20165;&#29992;&#25968;&#25454;&#26356;&#26032;&#27169;&#22411;&#65292;&#36824;&#29992;&#27169;&#22411;&#26356;&#26032;&#25968;&#25454;&#65292;&#29992;&#36719;&#26631;&#31614;&#26367;&#25442;&#30828;&#26631;&#31614;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#21457;&#29616;&#31361;&#20986;&#20102;&#36825;&#31181;&#26041;&#27861;&#30456;&#23545;&#20110;&#20256;&#32479;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement Learning from Human Feedback (RLHF) is a pivotal technique that aligns language models closely with human-centric values. The initial phase of RLHF involves learning human values using a reward model from ranking data. It is observed that the performance of the reward model degrades after one epoch of training, and optimizing too much against the learned reward model eventually hinders the true objective. This paper delves into these issues, leveraging the theoretical insights to design improved reward learning algorithm termed 'Iterative Data Smoothing' (IDS). The core idea is that during each training epoch, we not only update the model with the data, but also update the date using the model, replacing hard labels with soft labels. Our empirical findings highlight the superior performance of this approach over the traditional methods.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24378;&#21270;&#23398;&#20064;&#35774;&#35745;&#25511;&#21046;&#22330;&#30340;&#26041;&#26696;&#25104;&#21151;&#29983;&#25104;&#20102;&#38750;&#32463;&#20856;&#24577;&#65292;&#20197;&#24212;&#29992;&#20110;&#33258;&#26059;&#21387;&#32553;&#24577;&#30340;&#20135;&#29983;&#12290;&#35813;&#26041;&#27861;&#22312;&#20445;&#25345;&#21387;&#32553;&#21644;&#32416;&#32544;&#30340;&#21516;&#26102;&#25552;&#20379;&#20102;&#19981;&#21516;&#30340;&#25511;&#21046;&#24207;&#21015;&#65292;&#24182;&#35266;&#23519;&#21040;&#25511;&#21046;&#33033;&#20914;&#23494;&#38598;&#24212;&#29992;&#21487;&#20197;&#25552;&#39640;&#32467;&#26524;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.16320</link><description>&lt;p&gt;
&#21033;&#29992;&#24378;&#21270;&#23398;&#20064;&#29983;&#25104;&#38750;&#32463;&#20856;&#38598;&#21512;&#33258;&#26059;&#24577;&#30340;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
Prepare Non-classical Collective Spin State by Reinforcement Learning. (arXiv:2401.16320v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16320
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24378;&#21270;&#23398;&#20064;&#35774;&#35745;&#25511;&#21046;&#22330;&#30340;&#26041;&#26696;&#25104;&#21151;&#29983;&#25104;&#20102;&#38750;&#32463;&#20856;&#24577;&#65292;&#20197;&#24212;&#29992;&#20110;&#33258;&#26059;&#21387;&#32553;&#24577;&#30340;&#20135;&#29983;&#12290;&#35813;&#26041;&#27861;&#22312;&#20445;&#25345;&#21387;&#32553;&#21644;&#32416;&#32544;&#30340;&#21516;&#26102;&#25552;&#20379;&#20102;&#19981;&#21516;&#30340;&#25511;&#21046;&#24207;&#21015;&#65292;&#24182;&#35266;&#23519;&#21040;&#25511;&#21046;&#33033;&#20914;&#23494;&#38598;&#24212;&#29992;&#21487;&#20197;&#25552;&#39640;&#32467;&#26524;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#24378;&#21270;&#23398;&#20064;&#26469;&#35774;&#35745;&#25511;&#21046;&#22330;&#30340;&#26041;&#26696;&#65292;&#29992;&#20110;&#29983;&#25104;&#38750;&#32463;&#20856;&#24577;&#12290;&#35813;&#26041;&#26696;&#20197;&#24212;&#29992;&#20110;&#24320;&#25918;&#38598;&#20307;&#33258;&#26059;&#27169;&#22411;&#20013;&#30340;&#33258;&#26059;&#21387;&#32553;&#24577;&#20026;&#20363;&#65292;&#20854;&#20013;&#35774;&#35745;&#20102;&#19968;&#20010;&#32447;&#24615;&#25511;&#21046;&#39033;&#26469;&#25511;&#21046;&#21160;&#21147;&#23398;&#12290;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#26681;&#25454;&#20197;&#32791;&#25955;&#21644;&#21435;&#30456;&#24178;&#20026;&#29305;&#24449;&#30340;&#29615;&#22659;&#20013;&#30340;&#30456;&#24178;&#33258;&#26059;&#24577;&#24320;&#22987;&#65292;&#30830;&#23450;&#20102;&#25511;&#21046;&#33033;&#20914;&#30340;&#26102;&#38388;&#24207;&#21015;&#12290;&#19982;&#24658;&#23450;&#25511;&#21046;&#26041;&#26696;&#30456;&#27604;&#65292;&#36825;&#31181;&#26041;&#27861;&#25552;&#20379;&#20102;&#22810;&#31181;&#25511;&#21046;&#24207;&#21015;&#65292;&#20445;&#25345;&#20102;&#38598;&#20307;&#33258;&#26059;&#21387;&#32553;&#21644;&#32416;&#32544;&#12290;&#35266;&#23519;&#21040;&#25511;&#21046;&#33033;&#20914;&#30340;&#23494;&#38598;&#24212;&#29992;&#21487;&#20197;&#22686;&#24378;&#32467;&#26524;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#28155;&#21152;&#25511;&#21046;&#25805;&#20316;&#65292;&#24615;&#33021;&#24471;&#21040;&#20102;&#36731;&#24494;&#22686;&#24378;&#12290;&#25152;&#25552;&#20986;&#30340;&#31574;&#30053;&#22312;&#36739;&#22823;&#31995;&#32479;&#20013;&#23637;&#29616;&#20102;&#26356;&#39640;&#30340;&#25928;&#26524;&#12290;&#23545;&#20648;&#22791;&#28909;&#28608;&#21457;&#23545;&#25511;&#21046;&#32467;&#26524;&#26377;&#19981;&#21033;&#24433;&#21709;&#12290;&#24212;&#35813;&#30830;&#35748;&#36825;&#19968;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a scheme leveraging reinforcement learning to engineer control fields for generating non-classical states. It is exemplified by the application to prepare spin squeezed state for an open collective spin model where a linear control term is designed to govern the dynamics. The reinforcement learning agent determines the temporal sequence of control pulses, commencing from coherent spin state in an environment characterized by dissipation and dephasing. When compared to constant control scenarios, this approach provides various control sequences maintaining collective spin squeezing and entanglement. It is observed that denser application of the control pulses enhances the performance of the outcomes. Furthermore, there is a minor enhancement in the performance by adding control actions. The proposed strategy demonstrates increased effectiveness for larger systems. And thermal excitations of the reservoir are detrimental to the control outcomes. It should be confirmed that thi
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21452;&#29305;&#24449;&#21644;&#22522;&#20110;&#31034;&#20363;&#30340;&#35299;&#37322;&#26041;&#27861;&#65292;&#36890;&#36807;&#36873;&#25321;&#20984;&#21253;&#26469;&#23545;&#23454;&#20363;&#36827;&#34892;&#21452;&#37325;&#34920;&#31034;&#65292;&#24182;&#20351;&#29992;&#31616;&#21333;&#30340;&#30697;&#38453;&#35745;&#31639;&#26469;&#35745;&#31639;&#35299;&#37322;&#29305;&#24449;&#30340;&#37325;&#35201;&#24615;&#20540;&#12290;</title><link>http://arxiv.org/abs/2401.16294</link><description>&lt;p&gt;
&#22522;&#20110;&#21452;&#29305;&#24449;&#21644;&#22522;&#20110;&#31034;&#20363;&#30340;&#35299;&#37322;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Dual feature-based and example-based explanation methods. (arXiv:2401.16294v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16294
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21452;&#29305;&#24449;&#21644;&#22522;&#20110;&#31034;&#20363;&#30340;&#35299;&#37322;&#26041;&#27861;&#65292;&#36890;&#36807;&#36873;&#25321;&#20984;&#21253;&#26469;&#23545;&#23454;&#20363;&#36827;&#34892;&#21452;&#37325;&#34920;&#31034;&#65292;&#24182;&#20351;&#29992;&#31616;&#21333;&#30340;&#30697;&#38453;&#35745;&#31639;&#26469;&#35745;&#31639;&#35299;&#37322;&#29305;&#24449;&#30340;&#37325;&#35201;&#24615;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23616;&#37096;&#21644;&#20840;&#23616;&#35299;&#37322;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#36873;&#21462;&#19968;&#20010;&#22312;&#35299;&#37322;&#23454;&#20363;&#21608;&#22260;&#30340;&#26377;&#38480;&#28857;&#26500;&#36896;&#30340;&#20984;&#21253;&#12290;&#20984;&#21253;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#20197;&#20984;&#32452;&#21512;&#30340;&#24418;&#24335;&#23545;&#23454;&#20363;&#36827;&#34892;&#21452;&#37325;&#34920;&#31034;&#65292;&#36825;&#20123;&#20984;&#32452;&#21512;&#30001;&#20135;&#29983;&#30340;&#22810;&#38754;&#20307;&#30340;&#26497;&#28857;&#32452;&#25104;&#12290;&#19982;&#22312;&#27431;&#20960;&#37324;&#24471;&#29305;&#24449;&#31354;&#38388;&#20013;&#25200;&#21160;&#26032;&#23454;&#20363;&#19981;&#21516;&#65292;&#20984;&#32452;&#21512;&#31995;&#25968;&#30340;&#21521;&#37327;&#26159;&#20174;&#21333;&#20301;&#21333;&#32431;&#24418;&#20013;&#22343;&#21248;&#29983;&#25104;&#30340;&#65292;&#24182;&#19988;&#23427;&#20204;&#24418;&#25104;&#19968;&#20010;&#26032;&#30340;&#21452;&#37325;&#25968;&#25454;&#38598;&#12290;&#22312;&#21452;&#37325;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#21452;&#32447;&#24615;&#20195;&#29702;&#27169;&#22411;&#12290;&#36890;&#36807;&#31616;&#21333;&#30340;&#30697;&#38453;&#35745;&#31639;&#26469;&#35745;&#31639;&#35299;&#37322;&#29305;&#24449;&#30340;&#37325;&#35201;&#24615;&#20540;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#30475;&#20316;&#26159;&#33879;&#21517;&#27169;&#22411;LIME&#30340;&#19968;&#31181;&#20462;&#25913;&#12290;&#21452;&#37325;&#34920;&#31034;&#26412;&#36136;&#19978;&#20351;&#25105;&#20204;&#33021;&#22815;&#33719;&#24471;&#22522;&#20110;&#31034;&#20363;&#30340;&#35299;&#37322;&#12290;&#31070;&#32463;&#28155;&#21152;&#27169;&#22411;&#20063;&#34987;&#35270;&#20026;&#23454;&#29616;&#22522;&#20110;&#31034;&#20363;&#30340;&#35299;&#37322;&#26041;&#27861;&#30340;&#24037;&#20855;&#12290;&#36890;&#36807;&#23545;&#30495;&#23454;&#25968;&#25454;&#38598;&#36827;&#34892;&#35768;&#22810;&#25968;&#20540;&#23454;&#39564;&#26469;&#35780;&#20272;&#35813;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
A new approach to the local and global explanation is proposed. It is based on selecting a convex hull constructed for the finite number of points around an explained instance. The convex hull allows us to consider a dual representation of instances in the form of convex combinations of extreme points of a produced polytope. Instead of perturbing new instances in the Euclidean feature space, vectors of convex combination coefficients are uniformly generated from the unit simplex, and they form a new dual dataset. A dual linear surrogate model is trained on the dual dataset. The explanation feature importance values are computed by means of simple matrix calculations. The approach can be regarded as a modification of the well-known model LIME. The dual representation inherently allows us to get the example-based explanation. The neural additive model is also considered as a tool for implementing the example-based explanation approach. Many numerical experiments with real datasets are pe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26080;&#32500;&#24230;&#36793;&#30028;&#65292;&#20026;&#38543;&#26426;&#36882;&#24402;&#26799;&#24230;&#31639;&#27861;Prob-SARAH&#22312;&#38750;&#20984;&#26377;&#38480;&#21644;&#38382;&#39064;&#20013;&#25552;&#20379;&#20102;&#39640;&#27010;&#29575;&#20445;&#35777;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;Prob-SARAH&#22312;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#20855;&#26377;&#20248;&#31168;&#30340;&#27010;&#29575;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.15890</link><description>&lt;p&gt;
&#38750;&#20984;&#26377;&#38480;&#21644;&#38382;&#39064;&#20013;&#38543;&#26426;&#36882;&#24402;&#26799;&#24230;&#30340;&#27010;&#29575;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Probabilistic Guarantees of Stochastic Recursive Gradient in Non-Convex Finite Sum Problems. (arXiv:2401.15890v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15890
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26080;&#32500;&#24230;&#36793;&#30028;&#65292;&#20026;&#38543;&#26426;&#36882;&#24402;&#26799;&#24230;&#31639;&#27861;Prob-SARAH&#22312;&#38750;&#20984;&#26377;&#38480;&#21644;&#38382;&#39064;&#20013;&#25552;&#20379;&#20102;&#39640;&#27010;&#29575;&#20445;&#35777;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;Prob-SARAH&#22312;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#20855;&#26377;&#20248;&#31168;&#30340;&#27010;&#29575;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#20855;&#26377;&#38543;&#26426;&#20010;&#20307;&#36793;&#30028;&#30340;&#38789;&#24046;&#24207;&#21015;&#30340;&#27714;&#21644;&#33539;&#25968;&#19978;&#21457;&#23637;&#20102;&#19968;&#31181;&#26032;&#30340;&#26080;&#32500;&#24230;Azuma-Hoeffding&#31867;&#22411;&#30340;&#30028;&#38480;&#12290;&#20511;&#21161;&#36825;&#19968;&#21019;&#26032;&#32467;&#26524;&#65292;&#25105;&#20204;&#20026;&#25552;&#20986;&#30340;&#31639;&#27861;Prob-SARAH&#20013;&#30340;&#26799;&#24230;&#33539;&#25968;&#20272;&#35745;&#25552;&#20379;&#20102;&#39640;&#27010;&#29575;&#30028;&#12290;Prob-SARAH&#26159;StochAstic Recursive grAdient algoritHm (SARAH)&#30340;&#25913;&#36827;&#29256;&#26412;&#65292;SARAH&#26159;&#19968;&#31181;&#29616;&#26377;&#30340;&#26041;&#24046;&#32553;&#20943;&#31639;&#27861;&#65292;&#22312;&#26399;&#26395;&#19979;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#19978;&#36798;&#21040;&#20102;&#26368;&#20248;&#27700;&#24179;&#12290;Prob-SARAH&#30340;&#27010;&#29575;&#22797;&#26434;&#24230;&#19982;&#26368;&#20248;&#26399;&#26395;&#32467;&#26524;&#21305;&#37197;&#65292;&#24046;&#36317;&#20165;&#20026;&#23545;&#25968;&#22240;&#23376;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#20854;&#20182;&#27969;&#34892;&#31639;&#27861;&#30456;&#27604;&#65292;Prob-SARAH&#22312;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#20855;&#26377;&#26356;&#20248;&#30340;&#27010;&#29575;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper develops a new dimension-free Azuma-Hoeffding type bound on summation norm of a martingale difference sequence with random individual bounds. With this novel result, we provide high-probability bounds for the gradient norm estimator in the proposed algorithm Prob-SARAH, which is a modified version of the StochAstic Recursive grAdient algoritHm (SARAH), a state-of-art variance reduced algorithm that achieves optimal computational complexity in expectation for the finite sum problem. The in-probability complexity by Prob-SARAH matches the best in-expectation result up to logarithmic factors. Empirical experiments demonstrate the superior probabilistic performance of Prob-SARAH on real datasets compared to other popular algorithms.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#20248;&#21270;&#30340;&#20999;&#29255;&#20998;&#24067;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#24555;&#36895;&#36827;&#34892;&#33945;&#29305;&#21345;&#27931;&#26399;&#26395;&#20272;&#35745;&#12290;&#36890;&#36807;&#21033;&#29992;&#38543;&#26426;&#21521;&#37327;&#20043;&#38388;&#30340;&#24402;&#19968;&#21270;&#24046;&#24322;&#26500;&#24314;&#38543;&#26426;&#36335;&#24452;&#25237;&#24433;&#26041;&#21521;&#65292;&#20174;&#32780;&#24471;&#21040;&#20102;&#38543;&#26426;&#36335;&#24452;&#20999;&#29255;&#20998;&#24067;&#21644;&#20004;&#20010;&#20999;&#29255;&#29926;&#29791;&#26031;&#22374;&#30340;&#21464;&#31181;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#25299;&#25169;&#12289;&#32479;&#35745;&#21644;&#35745;&#31639;&#24615;&#36136;&#19978;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2401.15889</link><description>&lt;p&gt;
&#24102;&#26377;&#38543;&#26426;&#36335;&#24452;&#25237;&#24433;&#26041;&#21521;&#30340;&#20999;&#29255;&#29926;&#29791;&#26031;&#22374;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Sliced Wasserstein with Random-Path Projecting Directions. (arXiv:2401.15889v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15889
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#20248;&#21270;&#30340;&#20999;&#29255;&#20998;&#24067;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#24555;&#36895;&#36827;&#34892;&#33945;&#29305;&#21345;&#27931;&#26399;&#26395;&#20272;&#35745;&#12290;&#36890;&#36807;&#21033;&#29992;&#38543;&#26426;&#21521;&#37327;&#20043;&#38388;&#30340;&#24402;&#19968;&#21270;&#24046;&#24322;&#26500;&#24314;&#38543;&#26426;&#36335;&#24452;&#25237;&#24433;&#26041;&#21521;&#65292;&#20174;&#32780;&#24471;&#21040;&#20102;&#38543;&#26426;&#36335;&#24452;&#20999;&#29255;&#20998;&#24067;&#21644;&#20004;&#20010;&#20999;&#29255;&#29926;&#29791;&#26031;&#22374;&#30340;&#21464;&#31181;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#25299;&#25169;&#12289;&#32479;&#35745;&#21644;&#35745;&#31639;&#24615;&#36136;&#19978;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24212;&#29992;&#20013;&#65292;&#20999;&#29255;&#20998;&#24067;&#36873;&#25321;&#24050;&#34987;&#29992;&#20316;&#25552;&#39640;&#22522;&#20110;&#26368;&#23567;&#21270;&#20999;&#29255;&#29926;&#29791;&#26031;&#22374;&#36317;&#31163;&#30340;&#21442;&#25968;&#20272;&#35745;&#22120;&#24615;&#33021;&#30340;&#26377;&#25928;&#25216;&#26415;&#12290;&#20808;&#21069;&#30340;&#24037;&#20316;&#35201;&#20040;&#21033;&#29992;&#26114;&#36149;&#30340;&#20248;&#21270;&#26469;&#36873;&#25321;&#20999;&#29255;&#20998;&#24067;&#65292;&#35201;&#20040;&#20351;&#29992;&#38656;&#35201;&#26114;&#36149;&#30340;&#25277;&#26679;&#26041;&#27861;&#30340;&#20999;&#29255;&#20998;&#24067;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#20248;&#21270;&#30340;&#20999;&#29255;&#20998;&#24067;&#65292;&#21487;&#20197;&#24555;&#36895;&#36827;&#34892;&#33945;&#29305;&#21345;&#27931;&#26399;&#26395;&#20272;&#35745;&#30340;&#25277;&#26679;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#38543;&#26426;&#36335;&#24452;&#25237;&#24433;&#26041;&#21521;&#65288;RPD&#65289;&#65292;&#23427;&#26159;&#36890;&#36807;&#21033;&#29992;&#20004;&#20010;&#36755;&#20837;&#27979;&#37327;&#20013;&#20004;&#20010;&#38543;&#26426;&#21521;&#37327;&#20043;&#38388;&#30340;&#24402;&#19968;&#21270;&#24046;&#24322;&#26500;&#24314;&#30340;&#12290;&#20174;RPD&#20013;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#38543;&#26426;&#36335;&#24452;&#20999;&#29255;&#20998;&#24067;&#65288;RPSD&#65289;&#21644;&#20004;&#20010;&#20999;&#29255;&#29926;&#29791;&#26031;&#22374;&#30340;&#21464;&#31181;&#65292;&#21363;&#38543;&#26426;&#36335;&#24452;&#25237;&#24433;&#20999;&#29255;&#29926;&#29791;&#26031;&#22374;&#65288;RPSW&#65289;&#21644;&#37325;&#35201;&#24615;&#21152;&#26435;&#38543;&#26426;&#36335;&#24452;&#25237;&#24433;&#20999;&#29255;&#29926;&#29791;&#26031;&#22374;&#65288;IWRPSW&#65289;&#12290;&#28982;&#21518;&#25105;&#20204;&#35752;&#35770;&#20102;&#25299;&#25169;&#12289;&#32479;&#35745;&#21644;&#35745;&#31639;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
Slicing distribution selection has been used as an effective technique to improve the performance of parameter estimators based on minimizing sliced Wasserstein distance in applications. Previous works either utilize expensive optimization to select the slicing distribution or use slicing distributions that require expensive sampling methods. In this work, we propose an optimization-free slicing distribution that provides a fast sampling for the Monte Carlo estimation of expectation. In particular, we introduce the random-path projecting direction (RPD) which is constructed by leveraging the normalized difference between two random vectors following the two input measures. From the RPD, we derive the random-path slicing distribution (RPSD) and two variants of sliced Wasserstein, i.e., the Random-Path Projection Sliced Wasserstein (RPSW) and the Importance Weighted Random-Path Projection Sliced Wasserstein (IWRPSW). We then discuss the topological, statistical, and computational propert
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;lil'HDoC&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#23567;&#38408;&#20540;&#38388;&#38553;&#19979;&#30340;&#22909;&#33218;&#35782;&#21035;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#31639;&#27861;&#22312;&#26679;&#26412;&#25928;&#29575;&#19978;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.15879</link><description>&lt;p&gt;
&#23567;&#38408;&#20540;&#38388;&#38553;&#19979;&#30340;&#22909;&#33218;&#35782;&#21035;&#31639;&#27861;: lil'HDoC
&lt;/p&gt;
&lt;p&gt;
lil'HDoC: An Algorithm for Good Arm Identification under Small Threshold Gap. (arXiv:2401.15879v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15879
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;lil'HDoC&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#23567;&#38408;&#20540;&#38388;&#38553;&#19979;&#30340;&#22909;&#33218;&#35782;&#21035;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#31639;&#27861;&#22312;&#26679;&#26412;&#25928;&#29575;&#19978;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22909;&#33218;&#35782;&#21035;&#65288;GAI&#65289;&#26159;&#19968;&#20010;&#32431;&#25506;&#32034;&#24615;&#30340;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#22312;&#36825;&#20010;&#38382;&#39064;&#20013;&#65292;&#19968;&#20010;&#21333;&#29420;&#30340;&#23398;&#20064;&#22120;&#20250;&#22312;&#30830;&#23450;&#19968;&#20010;&#33218;&#26159;&#22909;&#33218;&#26102;&#31435;&#21363;&#36755;&#20986;&#35813;&#33218;&#12290;&#22909;&#33218;&#34987;&#23450;&#20041;&#20026;&#26399;&#26395;&#22238;&#25253;&#22823;&#20110;&#31561;&#20110;&#32473;&#23450;&#38408;&#20540;&#30340;&#33218;&#12290;&#26412;&#25991;&#32858;&#28966;&#20110;&#23567;&#38408;&#20540;&#38388;&#38553;&#19979;&#30340;GAI&#38382;&#39064;&#65292;&#35813;&#38388;&#38553;&#25351;&#30340;&#26159;&#33218;&#30340;&#26399;&#26395;&#22238;&#25253;&#19982;&#32473;&#23450;&#38408;&#20540;&#20043;&#38388;&#30340;&#36317;&#31163;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;lil'HDoC&#30340;&#26032;&#31639;&#27861;&#65292;&#26174;&#33879;&#25913;&#21892;&#20102;HDoC&#31639;&#27861;&#30340;&#24635;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#23567;&#38408;&#20540;&#38388;&#38553;&#19979;&#65292;lil'HDoC&#31639;&#27861;&#36755;&#20986;&#30340;&#31532;&#19968;&#20010;&#955;&#33218;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#19982;&#21407;&#22987;HDoC&#31639;&#27861;&#30456;&#27604;&#20165;&#26377;&#24494;&#23567;&#30340;&#24046;&#24322;&#12290;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Good arm identification (GAI) is a pure-exploration bandit problem in which a single learner outputs an arm as soon as it is identified as a good arm. A good arm is defined as an arm with an expected reward greater than or equal to a given threshold. This paper focuses on the GAI problem under a small threshold gap, which refers to the distance between the expected rewards of arms and the given threshold. We propose a new algorithm called lil'HDoC to significantly improve the total sample complexity of the HDoC algorithm. We demonstrate that the sample complexity of the first $\lambda$ output arm in lil'HDoC is bounded by the original HDoC algorithm, except for one negligible term, when the distance between the expected reward and threshold is small. Extensive experiments confirm that our algorithm outperforms the state-of-the-art algorithms in both synthetic and real-world datasets.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#39044;&#27979;&#20154;&#31867;&#27963;&#21160;&#30456;&#20851;&#20107;&#20214;&#30340;&#21457;&#29983;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#23558;&#30701;&#24207;&#21015;&#23884;&#20837;&#21040;&#38544;&#34255;&#34920;&#31034;&#20013;&#65292;&#24182;&#21033;&#29992;&#36825;&#20123;&#34920;&#31034;&#36827;&#34892;&#39044;&#27979;&#12290;&#36825;&#31181;&#26041;&#27861;&#35299;&#20915;&#20102;&#38271;&#24207;&#21015;&#19981;&#21487;&#29992;&#21644;&#38271;&#26399;&#39044;&#27979;&#22256;&#38590;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.15846</link><description>&lt;p&gt;
&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26102;&#38388;&#28857;&#36807;&#31243;&#30340;&#20803;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Meta-Learning for Neural Network-based Temporal Point Processes. (arXiv:2401.15846v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15846
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#39044;&#27979;&#20154;&#31867;&#27963;&#21160;&#30456;&#20851;&#20107;&#20214;&#30340;&#21457;&#29983;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#23558;&#30701;&#24207;&#21015;&#23884;&#20837;&#21040;&#38544;&#34255;&#34920;&#31034;&#20013;&#65292;&#24182;&#21033;&#29992;&#36825;&#20123;&#34920;&#31034;&#36827;&#34892;&#39044;&#27979;&#12290;&#36825;&#31181;&#26041;&#27861;&#35299;&#20915;&#20102;&#38271;&#24207;&#21015;&#19981;&#21487;&#29992;&#21644;&#38271;&#26399;&#39044;&#27979;&#22256;&#38590;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20154;&#31867;&#27963;&#21160;&#20135;&#29983;&#21508;&#31181;&#20107;&#20214;&#24207;&#21015;&#65292;&#22914;&#20986;&#31199;&#36710;&#34892;&#31243;&#35760;&#24405;&#12289;&#20849;&#20139;&#21333;&#36710;&#21462;&#36710;&#12289;&#29359;&#32618;&#21457;&#29983;&#21644;&#20256;&#26579;&#30149;&#20256;&#25773;&#31561;&#12290;&#28857;&#36807;&#31243;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#39044;&#27979;&#19982;&#20154;&#31867;&#27963;&#21160;&#30456;&#20851;&#30340;&#20107;&#20214;&#12290;&#28982;&#32780;&#65292;&#22312;&#39044;&#27979;&#19982;&#20154;&#31867;&#27963;&#21160;&#30456;&#20851;&#30340;&#20107;&#20214;&#26041;&#38754;&#65292;&#28857;&#36807;&#31243;&#23384;&#22312;&#20004;&#20010;&#38382;&#39064;&#12290;&#39318;&#20808;&#65292;&#26368;&#36817;&#30340;&#39640;&#24615;&#33021;&#28857;&#36807;&#31243;&#27169;&#22411;&#38656;&#35201;&#36755;&#20837;&#36275;&#22815;&#25968;&#37327;&#30340;&#38271;&#26399;&#25910;&#38598;&#30340;&#20107;&#20214;&#65288;&#21363;&#38271;&#24207;&#21015;&#65289;&#36827;&#34892;&#35757;&#32451;&#65292;&#20294;&#22312;&#29616;&#23454;&#24773;&#20917;&#19979;&#24448;&#24448;&#19981;&#21487;&#29992;&#12290;&#20854;&#27425;&#65292;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#38656;&#35201;&#36827;&#34892;&#38271;&#26399;&#39044;&#27979;&#27604;&#36739;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20803;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#21608;&#26399;&#24615;&#24863;&#30693;&#39044;&#27979;&#26410;&#26469;&#20107;&#20214;&#32473;&#20986;&#30701;&#24207;&#21015;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#39318;&#20808;&#36890;&#36807;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#23558;&#30701;&#24207;&#21015;&#23884;&#20837;&#21040;&#38544;&#34255;&#34920;&#31034;&#65288;&#21363;&#20219;&#21153;&#34920;&#31034;&#65289;&#20013;&#65292;&#20174;&#30701;&#24207;&#21015;&#21019;&#24314;&#39044;&#27979;&#12290;&#28982;&#21518;&#24314;&#31435;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Human activities generate various event sequences such as taxi trip records, bike-sharing pick-ups, crime occurrence, and infectious disease transmission. The point process is widely used in many applications to predict such events related to human activities. However, point processes present two problems in predicting events related to human activities. First, recent high-performance point process models require the input of sufficient numbers of events collected over a long period (i.e., long sequences) for training, which are often unavailable in realistic situations. Second, the long-term predictions required in real-world applications are difficult. To tackle these problems, we propose a novel meta-learning approach for periodicity-aware prediction of future events given short sequences. The proposed method first embeds short sequences into hidden representations (i.e., task representations) via recurrent neural networks for creating predictions from short sequences. It then model
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20132;&#26367;&#26041;&#21521;&#20056;&#23376;&#27861;&#30340;&#20998;&#24067;&#24335;&#25277;&#26679;&#26041;&#26696;&#65292;&#33021;&#22815;&#22312;&#20998;&#24067;&#24335;&#29615;&#22659;&#20013;&#36827;&#34892;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#25277;&#26679;&#65292;&#20174;&#32780;&#23454;&#29616;&#36125;&#21494;&#26031;&#25512;&#26029;&#20219;&#21153;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#26696;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.15838</link><description>&lt;p&gt;
&#22522;&#20110;&#20132;&#26367;&#26041;&#21521;&#20056;&#23376;&#27861;&#30340;&#20998;&#24067;&#24335;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#25277;&#26679;
&lt;/p&gt;
&lt;p&gt;
Distributed Markov Chain Monte Carlo Sampling based on the Alternating Direction Method of Multipliers. (arXiv:2401.15838v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15838
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20132;&#26367;&#26041;&#21521;&#20056;&#23376;&#27861;&#30340;&#20998;&#24067;&#24335;&#25277;&#26679;&#26041;&#26696;&#65292;&#33021;&#22815;&#22312;&#20998;&#24067;&#24335;&#29615;&#22659;&#20013;&#36827;&#34892;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#25277;&#26679;&#65292;&#20174;&#32780;&#23454;&#29616;&#36125;&#21494;&#26031;&#25512;&#26029;&#20219;&#21153;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#26696;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#38656;&#35201;&#23545;&#31354;&#38388;&#20998;&#24067;&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#25805;&#20316;&#12290;&#23613;&#31649;&#25216;&#26415;&#36827;&#27493;&#65292;&#20294;&#38544;&#31169;&#32771;&#34385;&#21644;&#36890;&#20449;&#32422;&#26463;&#21487;&#33021;&#38459;&#27490;&#23558;&#25972;&#20010;&#25968;&#25454;&#38598;&#25910;&#38598;&#21040;&#19968;&#20010;&#20013;&#24515;&#21333;&#20301;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20132;&#26367;&#26041;&#21521;&#20056;&#23376;&#27861;&#30340;&#20998;&#24067;&#24335;&#25277;&#26679;&#26041;&#26696;&#65292;&#35813;&#26041;&#27861;&#30001;&#20110;&#20854;&#24555;&#36895;&#25910;&#25947;&#22312;&#20248;&#21270;&#25991;&#29486;&#20013;&#24120;&#34987;&#20351;&#29992;&#12290;&#19982;&#20998;&#24067;&#24335;&#20248;&#21270;&#30456;&#27604;&#65292;&#20998;&#24067;&#24335;&#25277;&#26679;&#21487;&#20197;&#22312;&#36125;&#21494;&#26031;&#25512;&#26029;&#20219;&#21153;&#20013;&#36827;&#34892;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#31639;&#27861;&#25910;&#25947;&#30340;&#29702;&#35770;&#20445;&#35777;&#21644;&#23454;&#39564;&#25968;&#25454;&#35777;&#26126;&#20854;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;&#22312;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#20984;&#20248;&#21270;&#24037;&#20855;&#24314;&#31435;&#20102;&#29983;&#25104;&#30340;&#26412;&#22320;&#26679;&#26412;&#36845;&#20195;&#30340;&#22522;&#26412;&#19981;&#31561;&#24335;&#12290;&#36825;&#20010;&#19981;&#31561;&#24335;&#20351;&#25105;&#20204;&#33021;&#22815;&#35777;&#26126;&#19982;&#36825;&#20123;&#36845;&#20195;&#30456;&#20851;&#30340;&#20998;&#24067;&#20197;Wasserstein&#36317;&#31163;&#25910;&#25947;&#21040;&#28508;&#22312;&#30446;&#26631;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many machine learning applications require operating on a spatially distributed dataset. Despite technological advances, privacy considerations and communication constraints may prevent gathering the entire dataset in a central unit. In this paper, we propose a distributed sampling scheme based on the alternating direction method of multipliers, which is commonly used in the optimization literature due to its fast convergence. In contrast to distributed optimization, distributed sampling allows for uncertainty quantification in Bayesian inference tasks. We provide both theoretical guarantees of our algorithm's convergence and experimental evidence of its superiority to the state-of-the-art. For our theoretical results, we use convex optimization tools to establish a fundamental inequality on the generated local sample iterates. This inequality enables us to show convergence of the distribution associated with these iterates to the underlying target distribution in Wasserstein distance.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#29992;&#20110;&#20302;&#22266;&#26377;&#25968;&#25454;&#32500;&#24230;&#30340;&#29983;&#25104;&#23545;&#25239;&#27169;&#22411;&#30340;&#32479;&#35745;&#23646;&#24615;&#65292;&#25552;&#20986;&#20102;&#20851;&#20110;&#20272;&#35745;&#23494;&#24230;&#30340;&#32479;&#35745;&#20445;&#35777;&#65292;&#28041;&#21450;&#25968;&#25454;&#21644;&#28508;&#31354;&#38388;&#30340;&#20869;&#22312;&#32500;&#24230;&#65292;&#24182;&#35777;&#26126;&#20102;&#20272;&#35745;&#32467;&#26524;&#19982;&#30446;&#26631;&#30340;&#26399;&#26395;Wasserstein-1&#36317;&#31163;&#30340;&#32553;&#25918;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2401.15801</link><description>&lt;p&gt;
&#20851;&#20110;&#29992;&#20110;&#20302;&#22266;&#26377;&#25968;&#25454;&#32500;&#24230;&#30340;&#29983;&#25104;&#23545;&#25239;&#27169;&#22411;&#30340;&#32479;&#35745;&#23646;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Statistical Properties of Generative Adversarial Models for Low Intrinsic Data Dimension. (arXiv:2401.15801v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15801
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#29992;&#20110;&#20302;&#22266;&#26377;&#25968;&#25454;&#32500;&#24230;&#30340;&#29983;&#25104;&#23545;&#25239;&#27169;&#22411;&#30340;&#32479;&#35745;&#23646;&#24615;&#65292;&#25552;&#20986;&#20102;&#20851;&#20110;&#20272;&#35745;&#23494;&#24230;&#30340;&#32479;&#35745;&#20445;&#35777;&#65292;&#28041;&#21450;&#25968;&#25454;&#21644;&#28508;&#31354;&#38388;&#30340;&#20869;&#22312;&#32500;&#24230;&#65292;&#24182;&#35777;&#26126;&#20102;&#20272;&#35745;&#32467;&#26524;&#19982;&#30446;&#26631;&#30340;&#26399;&#26395;Wasserstein-1&#36317;&#31163;&#30340;&#32553;&#25918;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GANs&#65289;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#23454;&#35777;&#25104;&#21151;&#65292;&#20294;&#20854;&#32479;&#35745;&#20934;&#30830;&#24615;&#30340;&#29702;&#35770;&#20445;&#35777;&#20173;&#28982;&#30456;&#23545;&#24754;&#35266;&#12290;&#29305;&#21035;&#26159;&#22312;&#24212;&#29992;GANs&#30340;&#25968;&#25454;&#20998;&#24067;&#65288;&#22914;&#33258;&#28982;&#22270;&#20687;&#65289;&#20013;&#65292;&#36890;&#24120;&#20551;&#35774;&#20854;&#22312;&#39640;&#32500;&#29305;&#24449;&#31354;&#38388;&#20013;&#20855;&#26377;&#22266;&#26377;&#30340;&#20302;&#32500;&#32467;&#26500;&#65292;&#20294;&#36825;&#22312;&#29616;&#26377;&#20998;&#26512;&#20013;&#24448;&#24448;&#27809;&#26377;&#24471;&#21040;&#21453;&#26144;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35797;&#22270;&#36890;&#36807;&#25512;&#23548;&#20851;&#20110;&#25968;&#25454;&#21644;&#28508;&#31354;&#38388;&#30340;&#20869;&#22312;&#32500;&#24230;&#30340;&#32479;&#35745;&#20445;&#35777;&#26469;&#24357;&#21512;GANs&#21450;&#20854;&#21452;&#21521;&#21464;&#20307;BiGANs&#22312;&#29702;&#35770;&#21644;&#23454;&#36341;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#25105;&#20204;&#20998;&#26512;&#22320;&#35777;&#26126;&#65292;&#22914;&#26524;&#25105;&#20204;&#26377;&#26469;&#33258;&#26410;&#30693;&#30446;&#26631;&#20998;&#24067;&#30340; n &#20010;&#26679;&#26412;&#65292;&#24182;&#19988;&#36873;&#25321;&#20102;&#36866;&#24403;&#30340;&#32593;&#32476;&#26550;&#26500;&#65292;&#37027;&#20040;&#20174;&#30446;&#26631;&#20013;&#20272;&#35745;&#24471;&#20986;&#30340;&#26399;&#26395; Wasserstein-1 &#36317;&#31163;&#20250;&#25353;&#29031; $O(n^{-1/d_\mu })$ &#32553;&#25918;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the remarkable empirical successes of Generative Adversarial Networks (GANs), the theoretical guarantees for their statistical accuracy remain rather pessimistic. In particular, the data distributions on which GANs are applied, such as natural images, are often hypothesized to have an intrinsic low-dimensional structure in a typically high-dimensional feature space, but this is often not reflected in the derived rates in the state-of-the-art analyses. In this paper, we attempt to bridge the gap between the theory and practice of GANs and their bidirectional variant, Bi-directional GANs (BiGANs), by deriving statistical guarantees on the estimated densities in terms of the intrinsic dimension of the data and the latent space. We analytically show that if one has access to $n$ samples from the unknown target distribution and the network architectures are properly chosen, the expected Wasserstein-1 distance of the estimates from the target scales as $O\left( n^{-1/d_\mu } \right)$
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21033;&#29992;&#22810;&#37325;&#20551;&#35774;&#26816;&#39564;&#30340;&#24605;&#24819;&#65292;&#26469;&#35774;&#35745;&#21487;&#38752;&#22320;&#25490;&#21517;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#26368;&#37325;&#35201;&#29305;&#24449;&#30340;&#29305;&#24449;&#24402;&#22240;&#26041;&#27861;&#65292;&#26088;&#22312;&#35299;&#20915;SHAP&#21644;LIME&#31561;&#24120;&#29992;&#26041;&#27861;&#30001;&#20110;&#38543;&#26426;&#37319;&#26679;&#23548;&#33268;&#30340;&#39640;&#24230;&#19981;&#31283;&#23450;&#24615;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#35745;&#31639;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2401.15800</link><description>&lt;p&gt;
&#20351;&#29992;SHAP&#21644;LIME&#36827;&#34892;&#21487;&#35777;&#26126;&#31283;&#23450;&#30340;&#29305;&#24449;&#25490;&#21517;
&lt;/p&gt;
&lt;p&gt;
Provably Stable Feature Rankings with SHAP and LIME. (arXiv:2401.15800v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15800
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21033;&#29992;&#22810;&#37325;&#20551;&#35774;&#26816;&#39564;&#30340;&#24605;&#24819;&#65292;&#26469;&#35774;&#35745;&#21487;&#38752;&#22320;&#25490;&#21517;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#26368;&#37325;&#35201;&#29305;&#24449;&#30340;&#29305;&#24449;&#24402;&#22240;&#26041;&#27861;&#65292;&#26088;&#22312;&#35299;&#20915;SHAP&#21644;LIME&#31561;&#24120;&#29992;&#26041;&#27861;&#30001;&#20110;&#38543;&#26426;&#37319;&#26679;&#23548;&#33268;&#30340;&#39640;&#24230;&#19981;&#31283;&#23450;&#24615;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#35745;&#31639;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29305;&#24449;&#24402;&#22240;&#26159;&#20102;&#35299;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#39044;&#27979;&#30340;&#26222;&#36941;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#29992;&#20110;&#35780;&#20998;&#36755;&#20837;&#21464;&#37327;&#30340;&#24120;&#29992;&#26041;&#27861;&#65292;&#22914;SHAP&#21644;LIME&#65292;&#30001;&#20110;&#38543;&#26426;&#37319;&#26679;&#32780;&#20855;&#26377;&#39640;&#24230;&#19981;&#31283;&#23450;&#24615;&#12290;&#20511;&#37492;&#22810;&#37325;&#20551;&#35774;&#26816;&#39564;&#30340;&#24605;&#24819;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#33021;&#22815;&#20197;&#39640;&#27010;&#29575;&#27491;&#30830;&#25490;&#21517;&#26368;&#37325;&#35201;&#29305;&#24449;&#30340;&#24402;&#22240;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;RankSHAP&#20445;&#35777;$K$&#20010;&#26368;&#39640;Shapley&#20540;&#20855;&#26377;&#36229;&#36807;$1-\alpha$&#30340;&#27491;&#30830;&#25490;&#24207;&#27010;&#29575;&#12290;&#23454;&#35777;&#32467;&#26524;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#21644;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#35745;&#31639;&#25928;&#29575;&#12290;&#25105;&#20204;&#36824;&#22312;&#20043;&#21069;&#30340;&#24037;&#20316;&#22522;&#30784;&#19978;&#20026;LIME&#25552;&#20379;&#20102;&#31867;&#20284;&#30340;&#32467;&#26524;&#65292;&#30830;&#20445;&#20197;&#27491;&#30830;&#39034;&#24207;&#36873;&#25321;&#26368;&#37325;&#35201;&#30340;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Feature attributions are ubiquitous tools for understanding the predictions of machine learning models. However, popular methods for scoring input variables such as SHAP and LIME suffer from high instability due to random sampling. Leveraging ideas from multiple hypothesis testing, we devise attribution methods that correctly rank the most important features with high probability. Our algorithm RankSHAP guarantees that the $K$ highest Shapley values have the proper ordering with probability exceeding $1-\alpha$. Empirical results demonstrate its validity and impressive computational efficiency. We also build on previous work to yield similar results for LIME, ensuring the most important features are selected in the right order.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#26694;&#26550;&#65292;&#22312;&#39640;&#32500;&#24230;&#30456;&#20851;&#21464;&#37327;&#24773;&#20917;&#19979;&#23454;&#29616;&#34394;&#35686;&#29575;&#25511;&#21046;&#65292;&#36890;&#36807;&#32508;&#21512;&#23618;&#27425;&#22270;&#27169;&#22411;&#22312;T-Rex&#26694;&#26550;&#20013;&#21033;&#29992;&#20381;&#36182;&#32467;&#26500;&#65292;&#21033;&#29992;&#38789;&#35770;&#35777;&#26126;&#21464;&#37327;&#24809;&#32602;&#26426;&#21046;&#30830;&#20445;&#20102;FDR&#30340;&#25511;&#21046;&#12290;</title><link>http://arxiv.org/abs/2401.15796</link><description>&lt;p&gt;
&#39640;&#32500;&#24230;&#30456;&#20851;&#21464;&#37327;&#30340;&#34394;&#35686;&#29575;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
High-Dimensional False Discovery Rate Control for Dependent Variables. (arXiv:2401.15796v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15796
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#26694;&#26550;&#65292;&#22312;&#39640;&#32500;&#24230;&#30456;&#20851;&#21464;&#37327;&#24773;&#20917;&#19979;&#23454;&#29616;&#34394;&#35686;&#29575;&#25511;&#21046;&#65292;&#36890;&#36807;&#32508;&#21512;&#23618;&#27425;&#22270;&#27169;&#22411;&#22312;T-Rex&#26694;&#26550;&#20013;&#21033;&#29992;&#20381;&#36182;&#32467;&#26500;&#65292;&#21033;&#29992;&#38789;&#35770;&#35777;&#26126;&#21464;&#37327;&#24809;&#32602;&#26426;&#21046;&#30830;&#20445;&#20102;FDR&#30340;&#25511;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22823;&#35268;&#27169;&#12289;&#39640;&#32500;&#24230;&#25968;&#25454;&#20013;&#30830;&#20445;&#21487;&#22797;&#29616;&#30340;&#21457;&#29616;&#32467;&#26524;&#30340;&#31639;&#27861;&#22312;&#35768;&#22810;&#20449;&#21495;&#22788;&#29702;&#24212;&#29992;&#20013;&#33267;&#20851;&#37325;&#35201;&#12290;&#36817;&#24180;&#26469;&#65292;&#20986;&#29616;&#20102;&#22810;&#21464;&#37327;&#34394;&#35686;&#29575;&#65288;FDR&#65289;&#25511;&#21046;&#26041;&#27861;&#65292;&#21363;&#20351;&#22312;&#21464;&#37327;&#25968;&#37327;&#36229;&#36807;&#26679;&#26412;&#25968;&#37327;&#30340;&#39640;&#32500;&#24773;&#20917;&#19979;&#65292;&#20063;&#33021;&#25552;&#20379;&#20445;&#35777;&#12290;&#28982;&#32780;&#65292;&#22312;&#23384;&#22312;&#39640;&#24230;&#30456;&#20851;&#21464;&#37327;&#32452;&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#20123;&#26041;&#27861;&#24448;&#24448;&#26080;&#27861;&#21487;&#38752;&#22320;&#25511;&#21046;FDR&#65292;&#22312;&#22522;&#22240;&#32452;&#23398;&#21644;&#37329;&#34701;&#31561;&#39046;&#22495;&#20013;&#24456;&#24120;&#35265;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#20851;&#38190;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#32771;&#34385;&#19968;&#33324;&#20381;&#36182;&#32467;&#26500;&#30340;&#26032;&#26694;&#26550;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#20381;&#36182;&#24863;&#30693;T-Rex&#36873;&#25321;&#22120;&#23558;&#23618;&#27425;&#22270;&#27169;&#22411;&#25972;&#21512;&#21040;T-Rex&#26694;&#26550;&#20013;&#65292;&#20197;&#26377;&#25928;&#21033;&#29992;&#21464;&#37327;&#20043;&#38388;&#30340;&#20381;&#36182;&#32467;&#26500;&#12290;&#21033;&#29992;&#38789;&#35770;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#21464;&#37327;&#24809;&#32602;&#26426;&#21046;&#30830;&#20445;&#20102;FDR&#30340;&#25511;&#21046;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#36890;&#36807;&#38472;&#36848;&#21644;&#35777;&#26126;&#20102;&#19968;&#20010;&#28165;&#26224;&#30340;FDR&#25511;&#21046;&#26694;&#26550;&#30340;&#25512;&#24191;&#12290;
&lt;/p&gt;
&lt;p&gt;
Algorithms that ensure reproducible findings from large-scale, high-dimensional data are pivotal in numerous signal processing applications. In recent years, multivariate false discovery rate (FDR) controlling methods have emerged, providing guarantees even in high-dimensional settings where the number of variables surpasses the number of samples. However, these methods often fail to reliably control the FDR in the presence of highly dependent variable groups, a common characteristic in fields such as genomics and finance. To tackle this critical issue, we introduce a novel framework that accounts for general dependency structures. Our proposed dependency-aware T-Rex selector integrates hierarchical graphical models within the T-Rex framework to effectively harness the dependency structure among variables. Leveraging martingale theory, we prove that our variable penalization mechanism ensures FDR control. We further generalize the FDR-controlling framework by stating and proving a clea
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;Sign-Perturbed Sum (SPS)&#35782;&#21035;&#26041;&#27861;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#65292;&#29305;&#21035;&#26159;&#22312;&#26631;&#37327;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#20013;&#65292;&#36890;&#36807;&#20998;&#26512;&#20854;&#32622;&#20449;&#21306;&#38388;&#30340;&#34892;&#20026;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22914;&#26524;&#35266;&#27979;&#22122;&#22768;&#26159;&#27425;&#39640;&#26031;&#30340;&#35805;&#65292;SPS&#32622;&#20449;&#21306;&#38388;&#30340;&#22823;&#23567;&#20197;&#20960;&#20309;&#36895;&#29575;&#32553;&#23567;&#21040;&#30495;&#23454;&#21442;&#25968;&#30340;&#38468;&#36817;&#12290;</title><link>http://arxiv.org/abs/2401.15792</link><description>&lt;p&gt;
Sign-Perturbed Sums&#35782;&#21035;&#26041;&#27861;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#65306;&#26631;&#37327;&#24773;&#20917;
&lt;/p&gt;
&lt;p&gt;
Sample Complexity of the Sign-Perturbed Sums Identification Method: Scalar Case. (arXiv:2401.15792v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15792
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;Sign-Perturbed Sum (SPS)&#35782;&#21035;&#26041;&#27861;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#65292;&#29305;&#21035;&#26159;&#22312;&#26631;&#37327;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#20013;&#65292;&#36890;&#36807;&#20998;&#26512;&#20854;&#32622;&#20449;&#21306;&#38388;&#30340;&#34892;&#20026;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22914;&#26524;&#35266;&#27979;&#22122;&#22768;&#26159;&#27425;&#39640;&#26031;&#30340;&#35805;&#65292;SPS&#32622;&#20449;&#21306;&#38388;&#30340;&#22823;&#23567;&#20197;&#20960;&#20309;&#36895;&#29575;&#32553;&#23567;&#21040;&#30495;&#23454;&#21442;&#25968;&#30340;&#38468;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Sign-Perturbed Sum (SPS)&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#26377;&#38480;&#26679;&#26412;&#31995;&#32479;&#35782;&#21035;&#31639;&#27861;&#65292;&#21487;&#20197;&#26500;&#24314;&#30495;&#23454;&#25968;&#25454;&#29983;&#25104;&#31995;&#32479;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#24182;&#20855;&#26377;&#31934;&#30830;&#30340;&#35206;&#30422;&#27010;&#29575;&#65292;&#36866;&#29992;&#20110;&#20219;&#20309;&#26377;&#38480;&#30340;&#26679;&#26412;&#22823;&#23567;&#12290;SPS&#22312;&#19968;&#31995;&#21015;&#35770;&#25991;&#20013;&#36827;&#34892;&#20102;&#21457;&#23637;&#65292;&#24182;&#20855;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#65292;&#20174;&#19968;&#33324;&#32447;&#24615;&#31995;&#32479;&#65292;&#29978;&#33267;&#38381;&#29615;&#35774;&#32622;&#19979;&#65292;&#21040;&#38750;&#32447;&#24615;&#21644;&#38750;&#21442;&#25968;&#26041;&#27861;&#12290;&#34429;&#28982;SPS&#30340;&#20960;&#20010;&#29702;&#35770;&#24615;&#36136;&#22312;&#25991;&#29486;&#20013;&#24050;&#34987;&#35777;&#26126;&#65292;&#20294;&#35813;&#26041;&#27861;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#23578;&#26410;&#36827;&#34892;&#20998;&#26512;&#12290;&#26412;&#25991;&#26088;&#22312;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#24182;&#39318;&#27425;&#25552;&#20379;&#20102;&#20851;&#20110;SPS&#26679;&#26412;&#22797;&#26434;&#24615;&#30340;&#32467;&#26524;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#26631;&#37327;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#65292;&#21363;&#30740;&#31350;SPS&#32622;&#20449;&#21306;&#38388;&#30340;&#34892;&#20026;&#12290;&#25105;&#20204;&#22312;&#19977;&#20010;&#19981;&#21516;&#30340;&#20551;&#35774;&#38598;&#19979;&#25552;&#20379;&#20102;&#39640;&#27010;&#29575;&#30340;&#19978;&#30028;&#65292;&#34920;&#26126;&#22914;&#26524;&#35266;&#27979;&#22122;&#22768;&#26159;&#27425;&#39640;&#26031;&#30340;&#35805;&#65292;SPS&#32622;&#20449;&#21306;&#38388;&#30340;&#22823;&#23567;&#20197;&#20960;&#20309;&#36895;&#29575;&#32553;&#23567;&#21040;&#30495;&#23454;&#21442;&#25968;&#30340;&#38468;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sign-Perturbed Sum (SPS) is a powerful finite-sample system identification algorithm which can construct confidence regions for the true data generating system with exact coverage probabilities, for any finite sample size. SPS was developed in a series of papers and it has a wide range of applications, from general linear systems, even in a closed-loop setup, to nonlinear and nonparametric approaches. Although several theoretical properties of SPS were proven in the literature, the sample complexity of the method was not analysed so far. This paper aims to fill this gap and provides the first results on the sample complexity of SPS. Here, we focus on scalar linear regression problems, that is we study the behaviour of SPS confidence intervals. We provide high probability upper bounds, under three different sets of assumptions, showing that the sizes of SPS confidence intervals shrink at a geometric rate around the true parameter, if the observation noises are subgaussian. We also show 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25913;&#36827;&#20102;&#22522;&#20110;&#20869;&#26680;&#30340;&#38750;&#28176;&#36817;&#21516;&#26102;&#32622;&#20449;&#24102;&#30340;&#26500;&#24314;&#26041;&#27861;&#65292;&#36890;&#36807;&#25918;&#23485;&#22122;&#22768;&#20551;&#35774;&#12289;&#25913;&#36827;&#30446;&#26631;&#20989;&#25968;&#33539;&#25968;&#20272;&#35745;&#21644;&#21152;&#24378;&#38544;&#21547;&#20984;&#20248;&#21270;&#38382;&#39064;&#32422;&#26463;&#26469;&#25552;&#21319;&#20102;&#26500;&#24314;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2401.15791</link><description>&lt;p&gt;
&#25913;&#36827;&#22522;&#20110;&#20869;&#26680;&#30340;&#38750;&#28176;&#36817;&#21516;&#26102;&#32622;&#20449;&#24102;
&lt;/p&gt;
&lt;p&gt;
Improving Kernel-Based Nonasymptotic Simultaneous Confidence Bands. (arXiv:2401.15791v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15791
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25913;&#36827;&#20102;&#22522;&#20110;&#20869;&#26680;&#30340;&#38750;&#28176;&#36817;&#21516;&#26102;&#32622;&#20449;&#24102;&#30340;&#26500;&#24314;&#26041;&#27861;&#65292;&#36890;&#36807;&#25918;&#23485;&#22122;&#22768;&#20551;&#35774;&#12289;&#25913;&#36827;&#30446;&#26631;&#20989;&#25968;&#33539;&#25968;&#20272;&#35745;&#21644;&#21152;&#24378;&#38544;&#21547;&#20984;&#20248;&#21270;&#38382;&#39064;&#32422;&#26463;&#26469;&#25552;&#21319;&#20102;&#26500;&#24314;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#26500;&#24314;&#38750;&#21442;&#25968;&#30340;&#12289;&#20855;&#26377;&#38750;&#28176;&#36817;&#21644;&#20998;&#24067;&#26080;&#20851;&#20445;&#35777;&#30340;&#21516;&#26102;&#32622;&#20449;&#24102;&#30340;&#38382;&#39064;&#12290;&#30446;&#26631;&#20989;&#25968;&#34987;&#20551;&#35774;&#20026;&#24102;&#38480;&#20989;&#25968;&#65292;&#26041;&#27861;&#22522;&#20110;Paley-Wiener&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#29702;&#35770;&#12290;&#35770;&#25991;&#36215;&#28857;&#26159;&#19968;&#20010;&#26368;&#36817;&#24320;&#21457;&#30340;&#31639;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19977;&#31181;&#25913;&#36827;&#26041;&#27861;&#12290;&#39318;&#20808;&#65292;&#36890;&#36807;&#29992;&#36739;&#24369;&#30340;&#20998;&#24067;&#19981;&#21464;&#24615;&#21407;&#29702;&#21462;&#20195;&#23545;&#22122;&#22768;&#30340;&#23545;&#31216;&#24615;&#20551;&#35774;&#26469;&#25918;&#23485;&#23545;&#22122;&#22768;&#30340;&#20551;&#35774;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#39640;&#25928;&#30340;&#20272;&#35745;&#30446;&#26631;&#20989;&#25968;&#33539;&#25968;&#30340;&#26041;&#27861;&#65292;&#26368;&#21518;&#36890;&#36807;&#21152;&#24378;&#38544;&#21547;&#20984;&#20248;&#21270;&#38382;&#39064;&#30340;&#32422;&#26463;&#26469;&#22686;&#24378;&#32622;&#20449;&#24102;&#30340;&#26500;&#24314;&#12290;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#20063;&#23545;&#36825;&#20123;&#25913;&#36827;&#36827;&#34892;&#20102;&#35828;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
The paper studies the problem of constructing nonparametric simultaneous confidence bands with nonasymptotic and distribition-free guarantees. The target function is assumed to be band-limited and the approach is based on the theory of Paley-Wiener reproducing kernel Hilbert spaces. The starting point of the paper is a recently developed algorithm to which we propose three types of improvements. First, we relax the assumptions on the noises by replacing the symmetricity assumption with a weaker distributional invariance principle. Then, we propose a more efficient way to estimate the norm of the target function, and finally we enhance the construction of the confidence bands by tightening the constraints of the underlying convex optimization problems. The refinements are also illustrated through numerical experiments.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#19982;&#26368;&#26032;&#30340;&#20915;&#31574;&#29702;&#35770;&#27169;&#22411;&#30456;&#32467;&#21512;&#30340;&#40065;&#26834;&#20248;&#21270;&#20934;&#21017;&#65292;&#36890;&#36807;&#36825;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#20013;&#33719;&#24471;&#26377;&#31283;&#23450;&#24615;&#21644;&#20248;&#36234;&#24615;&#33021;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2401.15771</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#19982;&#25968;&#25454;&#39537;&#21160;&#40065;&#26834;&#20248;&#21270;&#30340;&#32467;&#21512;
&lt;/p&gt;
&lt;p&gt;
Bayesian Nonparametrics meets Data-Driven Robust Optimization. (arXiv:2401.15771v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15771
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#19982;&#26368;&#26032;&#30340;&#20915;&#31574;&#29702;&#35770;&#27169;&#22411;&#30456;&#32467;&#21512;&#30340;&#40065;&#26834;&#20248;&#21270;&#20934;&#21017;&#65292;&#36890;&#36807;&#36825;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#20013;&#33719;&#24471;&#26377;&#31283;&#23450;&#24615;&#21644;&#20248;&#36234;&#24615;&#33021;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#27169;&#22411;&#36890;&#24120;&#28041;&#21450;&#20248;&#21270;&#25968;&#25454;&#39537;&#21160;&#30340;&#39118;&#38505;&#20934;&#21017;&#12290;&#39118;&#38505;&#36890;&#24120;&#26159;&#26681;&#25454;&#32463;&#39564;&#25968;&#25454;&#20998;&#24067;&#35745;&#31639;&#30340;&#65292;&#20294;&#30001;&#20110;&#20998;&#24067;&#19981;&#30830;&#23450;&#24615;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#24615;&#33021;&#19981;&#31283;&#23450;&#21644;&#19981;&#22909;&#30340;&#26679;&#26412;&#22806;&#34920;&#29616;&#12290;&#22312;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#30340;&#31934;&#31070;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#40065;&#26834;&#20934;&#21017;&#65292;&#23558;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#65288;&#21363;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#65289;&#29702;&#35770;&#21644;&#26368;&#36817;&#30340;&#24179;&#28369;&#27169;&#31946;&#35268;&#36991;&#20559;&#22909;&#30340;&#20915;&#31574;&#29702;&#35770;&#27169;&#22411;&#30340;&#35265;&#35299;&#30456;&#32467;&#21512;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#24378;&#35843;&#20102;&#19982;&#26631;&#20934;&#27491;&#21017;&#21270;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#25216;&#26415;&#30340;&#26032;&#36830;&#25509;&#65292;&#20854;&#20013;&#21253;&#25324;&#23725;&#22238;&#24402;&#21644;&#22871;&#32034;&#22238;&#24402;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20174;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#40065;&#26834;&#20248;&#21270;&#36807;&#31243;&#22312;&#26377;&#38480;&#26679;&#26412;&#21644;&#28176;&#36817;&#32479;&#35745;&#20445;&#35777;&#26041;&#38754;&#30340;&#26377;&#21033;&#24615;&#23384;&#22312;&#12290;&#23545;&#20110;&#23454;&#38469;&#23454;&#26045;&#65292;&#25105;&#20204;&#25552;&#20986;&#24182;&#30740;&#31350;&#20102;&#22522;&#20110;&#20247;&#25152;&#21608;&#30693;&#30340;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#34920;&#31034;&#30340;&#21487;&#34892;&#36817;&#20284;&#20934;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;
Training machine learning and statistical models often involves optimizing a data-driven risk criterion. The risk is usually computed with respect to the empirical data distribution, but this may result in poor and unstable out-of-sample performance due to distributional uncertainty. In the spirit of distributionally robust optimization, we propose a novel robust criterion by combining insights from Bayesian nonparametric (i.e., Dirichlet Process) theory and recent decision-theoretic models of smooth ambiguity-averse preferences. First, we highlight novel connections with standard regularized empirical risk minimization techniques, among which Ridge and LASSO regressions. Then, we theoretically demonstrate the existence of favorable finite-sample and asymptotic statistical guarantees on the performance of the robust optimization procedure. For practical implementation, we propose and study tractable approximations of the criterion based on well-known Dirichlet Process representations. 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38598;&#21512;&#30340;&#36864;&#28779;&#37325;&#35201;&#24615;&#25277;&#26679;&#31639;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#20154;&#21475;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#26469;&#25552;&#39640;&#25277;&#26679;&#25928;&#29575;&#65292;&#24182;&#21033;&#29992;&#38598;&#21512;&#30340;&#30456;&#20114;&#20316;&#29992;&#20419;&#36827;&#26410;&#21457;&#29616;&#27169;&#24577;&#30340;&#25506;&#32034;&#12290;</title><link>http://arxiv.org/abs/2401.15645</link><description>&lt;p&gt;
&#22522;&#20110;&#38598;&#21512;&#30340;&#36864;&#28779;&#37325;&#35201;&#24615;&#25277;&#26679;
&lt;/p&gt;
&lt;p&gt;
Ensemble-Based Annealed Importance Sampling. (arXiv:2401.15645v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15645
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38598;&#21512;&#30340;&#36864;&#28779;&#37325;&#35201;&#24615;&#25277;&#26679;&#31639;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#20154;&#21475;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#26469;&#25552;&#39640;&#25277;&#26679;&#25928;&#29575;&#65292;&#24182;&#21033;&#29992;&#38598;&#21512;&#30340;&#30456;&#20114;&#20316;&#29992;&#20419;&#36827;&#26410;&#21457;&#29616;&#27169;&#24577;&#30340;&#25506;&#32034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#22810;&#27169;&#24577;&#20998;&#24067;&#20013;&#36827;&#34892;&#25277;&#26679;&#26159;&#35745;&#31639;&#31185;&#23398;&#21644;&#32479;&#35745;&#23398;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#19988;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#12290;&#22312;&#21508;&#31181;&#26041;&#27861;&#20013;&#65292;&#19968;&#31181;&#27969;&#34892;&#30340;&#26041;&#27861;&#26159;&#36864;&#28779;&#37325;&#35201;&#24615;&#25277;&#26679;&#65288;AIS&#65289;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#38598;&#21512;&#30340;AIS&#29256;&#26412;&#65292;&#36890;&#36807;&#23558;&#20854;&#19982;&#22522;&#20110;&#20154;&#21475;&#30340;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#20197;&#25552;&#39640;&#20854;&#25928;&#29575;&#12290;&#36890;&#36807;&#36319;&#36394;&#38598;&#21512;&#32780;&#19981;&#26159;&#21333;&#20010;&#31890;&#23376;&#27839;&#36215;&#22987;&#20998;&#24067;&#21644;&#30446;&#26631;&#20998;&#24067;&#20043;&#38388;&#30340;&#26576;&#20010;&#24310;&#32493;&#36335;&#24452;&#65292;&#25105;&#20204;&#21033;&#29992;&#38598;&#21512;&#20869;&#30340;&#30456;&#20114;&#20316;&#29992;&#26469;&#20419;&#36827;&#26410;&#21457;&#29616;&#27169;&#24577;&#30340;&#25506;&#32034;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#30340;&#20027;&#35201;&#24605;&#24819;&#26159;&#21033;&#29992;Snooker&#31639;&#27861;&#25110;&#36827;&#21270;&#33945;&#29305;&#21345;&#27931;&#20013;&#20351;&#29992;&#30340;&#36951;&#20256;&#31639;&#27861;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#22914;&#20309;&#23454;&#29616;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#65292;&#24182;&#25512;&#23548;&#20102;&#22312;&#36830;&#32493;&#26102;&#38388;&#21644;&#22343;&#22330;&#26497;&#38480;&#19979;&#25511;&#21046;&#38598;&#21512;&#28436;&#21270;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#25105;&#20204;&#36824;&#27979;&#35797;&#20102;&#25152;&#25552;&#31639;&#27861;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sampling from a multimodal distribution is a fundamental and challenging problem in computational science and statistics. Among various approaches proposed for this task, one popular method is Annealed Importance Sampling (AIS). In this paper, we propose an ensemble-based version of AIS by combining it with population-based Monte Carlo methods to improve its efficiency. By keeping track of an ensemble instead of a single particle along some continuation path between the starting distribution and the target distribution, we take advantage of the interaction within the ensemble to encourage the exploration of undiscovered modes. Specifically, our main idea is to utilize either the snooker algorithm or the genetic algorithm used in Evolutionary Monte Carlo. We discuss how the proposed algorithm can be implemented and derive a partial differential equation governing the evolution of the ensemble under the continuous time and mean-field limit. We also test the efficiency of the proposed alg
&lt;/p&gt;</description></item><item><title>GT-PCA&#26159;&#19968;&#31181;&#39640;&#25928;&#19988;&#21487;&#35299;&#37322;&#30340;&#20027;&#25104;&#20998;&#20998;&#26512;&#30340;&#38477;&#32500;&#26041;&#27861;&#65292;&#19982;&#20855;&#20307;&#36716;&#25442;&#19981;&#21464;&#65292;&#33021;&#26174;&#33879;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.15623</link><description>&lt;p&gt;
GT-PCA&#65306;&#20855;&#26377;&#26222;&#36866;&#21464;&#25442;&#19981;&#21464;&#24615;&#30340;&#20027;&#25104;&#20998;&#20998;&#26512;&#30340;&#39640;&#25928;&#21644;&#21487;&#35299;&#37322;&#30340;&#38477;&#32500;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
GT-PCA: Effective and Interpretable Dimensionality Reduction with General Transform-Invariant Principal Component Analysis. (arXiv:2401.15623v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15623
&lt;/p&gt;
&lt;p&gt;
GT-PCA&#26159;&#19968;&#31181;&#39640;&#25928;&#19988;&#21487;&#35299;&#37322;&#30340;&#20027;&#25104;&#20998;&#20998;&#26512;&#30340;&#38477;&#32500;&#26041;&#27861;&#65292;&#19982;&#20855;&#20307;&#36716;&#25442;&#19981;&#21464;&#65292;&#33021;&#26174;&#33879;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#20998;&#26512;&#36890;&#24120;&#38656;&#35201;&#19982;&#29305;&#23450;&#36716;&#25442;&#19981;&#21464;&#30340;&#26041;&#27861;&#65292;&#20363;&#22914;&#38024;&#23545;&#22270;&#20687;&#30340;&#26059;&#36716;&#25110;&#22270;&#20687;&#21644;&#26102;&#38388;&#24207;&#21015;&#30340;&#31227;&#21160;&#12290;&#34429;&#28982;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#38477;&#32500;&#25216;&#26415;&#65292;&#20294;&#22312;&#36825;&#20123;&#36716;&#25442;&#26041;&#38754;&#32570;&#20047;&#40065;&#26834;&#24615;&#12290;&#29616;&#20195;&#26367;&#20195;&#26041;&#27861;&#65292;&#22914;&#33258;&#21160;&#32534;&#30721;&#22120;&#65292;&#21487;&#20197;&#19982;&#29305;&#23450;&#36716;&#25442;&#19981;&#21464;&#65292;&#20294;&#36890;&#24120;&#19981;&#21487;&#35299;&#37322;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;GT-PCA&#30340;&#26222;&#36866;&#21464;&#25442;&#19981;&#21464;&#30340;&#20027;&#25104;&#20998;&#20998;&#26512;&#26041;&#27861;&#65292;&#20316;&#20026;PCA&#21644;&#33258;&#21160;&#32534;&#30721;&#22120;&#30340;&#39640;&#25928;&#21487;&#35299;&#37322;&#26367;&#20195;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#65292;&#26377;&#25928;&#20272;&#35745;&#21508;&#20010;&#25104;&#20998;&#65292;&#24182;&#22312;&#22522;&#20110;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#30340;&#23454;&#39564;&#20013;&#35777;&#26126;GT-PCA&#26126;&#26174;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data analysis often requires methods that are invariant with respect to specific transformations, such as rotations in case of images or shifts in case of images and time series. While principal component analysis (PCA) is a widely-used dimension reduction technique, it lacks robustness with respect to these transformations. Modern alternatives, such as autoencoders, can be invariant with respect to specific transformations but are generally not interpretable. We introduce General Transform-Invariant Principal Component Analysis (GT-PCA) as an effective and interpretable alternative to PCA and autoencoders. We propose a neural network that efficiently estimates the components and show that GT-PCA significantly outperforms alternative methods in experiments based on synthetic and real data.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39044;&#39564;&#35777;&#30340;&#23725;&#22238;&#24402;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#22312;&#39640;&#32500;&#25968;&#25454;&#20013;&#19982;&#36923;&#36753;&#22238;&#24402;&#38750;&#24120;&#25509;&#36817;&#65292;&#20294;&#20855;&#26377;&#26356;&#39640;&#30340;&#35745;&#31639;&#25928;&#29575;&#21644;&#20960;&#20046;&#27809;&#26377;&#36229;&#21442;&#25968;&#12290;&#23427;&#36890;&#36807;&#21033;&#29992;&#22312;&#25311;&#21512;&#36807;&#31243;&#20013;&#35745;&#31639;&#24471;&#21040;&#30340;&#25968;&#37327;&#26469;&#32553;&#25918;&#27169;&#22411;&#31995;&#25968;&#65292;&#24182;&#26368;&#23567;&#21270;&#19968;&#32452;&#39044;&#39564;&#35777;&#39044;&#27979;&#30340;&#23545;&#25968;&#25439;&#22833;&#12290;</title><link>http://arxiv.org/abs/2401.15610</link><description>&lt;p&gt;
&#39044;&#39564;&#35777;&#30340;&#23725;&#22238;&#24402;&#26159;&#39640;&#32500;&#25968;&#25454;&#20013;&#36923;&#36753;&#22238;&#24402;&#30340;&#39640;&#25928;&#26367;&#20195;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Prevalidated ridge regression is a highly-efficient drop-in replacement for logistic regression for high-dimensional data. (arXiv:2401.15610v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15610
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39044;&#39564;&#35777;&#30340;&#23725;&#22238;&#24402;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#22312;&#39640;&#32500;&#25968;&#25454;&#20013;&#19982;&#36923;&#36753;&#22238;&#24402;&#38750;&#24120;&#25509;&#36817;&#65292;&#20294;&#20855;&#26377;&#26356;&#39640;&#30340;&#35745;&#31639;&#25928;&#29575;&#21644;&#20960;&#20046;&#27809;&#26377;&#36229;&#21442;&#25968;&#12290;&#23427;&#36890;&#36807;&#21033;&#29992;&#22312;&#25311;&#21512;&#36807;&#31243;&#20013;&#35745;&#31639;&#24471;&#21040;&#30340;&#25968;&#37327;&#26469;&#32553;&#25918;&#27169;&#22411;&#31995;&#25968;&#65292;&#24182;&#26368;&#23567;&#21270;&#19968;&#32452;&#39044;&#39564;&#35777;&#39044;&#27979;&#30340;&#23545;&#25968;&#25439;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36923;&#36753;&#22238;&#24402;&#26159;&#19968;&#31181;&#24120;&#35265;&#30340;&#27010;&#29575;&#20998;&#31867;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#36923;&#36753;&#22238;&#24402;&#30340;&#26377;&#25928;&#24615;&#21462;&#20915;&#20110;&#20180;&#32454;&#19988;&#30456;&#23545;&#35745;&#31639;&#23494;&#38598;&#30340;&#35843;&#20248;&#65292;&#23588;&#20854;&#26159;&#23545;&#20110;&#27491;&#21017;&#21270;&#36229;&#21442;&#25968;&#65292;&#24182;&#19988;&#23588;&#20854;&#22312;&#39640;&#32500;&#25968;&#25454;&#30340;&#32972;&#26223;&#19979;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39044;&#39564;&#35777;&#30340;&#23725;&#22238;&#24402;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#22312;&#20998;&#31867;&#38169;&#35823;&#21644;&#23545;&#25968;&#25439;&#22833;&#26041;&#38754;&#19982;&#36923;&#36753;&#22238;&#24402;&#38750;&#24120;&#25509;&#36817;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#39640;&#32500;&#25968;&#25454;&#65292;&#21516;&#26102;&#22312;&#35745;&#31639;&#25928;&#29575;&#19978;&#26126;&#26174;&#26356;&#39640;&#65292;&#24182;&#19988;&#38500;&#20102;&#27491;&#21017;&#21270;&#20043;&#22806;&#27809;&#26377;&#36229;&#21442;&#25968;&#12290;&#25105;&#20204;&#36890;&#36807;&#32553;&#25918;&#27169;&#22411;&#30340;&#31995;&#25968;&#26469;&#26368;&#23567;&#21270;&#30001;&#20272;&#35745;&#30340;&#30041;&#19968;&#20132;&#21449;&#39564;&#35777;&#35823;&#24046;&#25512;&#23548;&#20986;&#30340;&#19968;&#32452;&#39044;&#39564;&#35777;&#39044;&#27979;&#30340;&#23545;&#25968;&#25439;&#22833;&#12290;&#36825;&#21033;&#29992;&#20102;&#22312;&#25311;&#21512;&#23725;&#22238;&#24402;&#27169;&#22411;&#36807;&#31243;&#20013;&#24050;&#32463;&#35745;&#31639;&#30340;&#25968;&#37327;&#65292;&#20197;&#25214;&#21040;&#20855;&#26377;&#21517;&#20041;&#38468;&#21152;&#35745;&#31639;&#24320;&#38144;&#30340;&#32553;&#25918;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Logistic regression is a ubiquitous method for probabilistic classification. However, the effectiveness of logistic regression depends upon careful and relatively computationally expensive tuning, especially for the regularisation hyperparameter, and especially in the context of high-dimensional data. We present a prevalidated ridge regression model that closely matches logistic regression in terms of classification error and log-loss, particularly for high-dimensional data, while being significantly more computationally efficient and having effectively no hyperparameters beyond regularisation. We scale the coefficients of the model so as to minimise log-loss for a set of prevalidated predictions derived from the estimated leave-one-out cross-validation error. This exploits quantities already computed in the course of fitting the ridge regression model in order to find the scaling parameter with nominal additional computational expense.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#25193;&#25955;&#27169;&#22411;&#20013;&#20998;&#25968;&#20272;&#35745;&#30340;&#20248;&#21270;&#21644;&#27867;&#21270;&#26041;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#23545;&#20998;&#25968;&#20272;&#35745;&#36827;&#34892;&#20998;&#26512;&#30340;&#25968;&#23398;&#26694;&#26550;&#12290;</title><link>http://arxiv.org/abs/2401.15604</link><description>&lt;p&gt;
&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#25193;&#25955;&#27169;&#22411;&#20013;&#30340;&#20998;&#25968;&#20272;&#35745;&#65306;&#20248;&#21270;&#21644;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Neural Network-Based Score Estimation in Diffusion Models: Optimization and Generalization. (arXiv:2401.15604v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15604
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#25193;&#25955;&#27169;&#22411;&#20013;&#20998;&#25968;&#20272;&#35745;&#30340;&#20248;&#21270;&#21644;&#27867;&#21270;&#26041;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#23545;&#20998;&#25968;&#20272;&#35745;&#36827;&#34892;&#20998;&#26512;&#30340;&#25968;&#23398;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#24050;&#32463;&#25104;&#20026;&#19982;GANs&#30456;&#23218;&#32654;&#30340;&#24378;&#22823;&#24037;&#20855;&#65292;&#21487;&#20197;&#29983;&#25104;&#20855;&#26377;&#25913;&#36827;&#20445;&#30495;&#24230;&#65292;&#28789;&#27963;&#24615;&#21644;&#40065;&#26834;&#24615;&#30340;&#39640;&#36136;&#37327;&#26679;&#26412;&#12290;&#36825;&#20123;&#27169;&#22411;&#30340;&#19968;&#20010;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#26159;&#36890;&#36807;&#20998;&#25968;&#21305;&#37197;&#26469;&#23398;&#20064;&#20998;&#25968;&#20989;&#25968;&#12290;&#23613;&#31649;&#22312;&#21508;&#31181;&#20219;&#21153;&#19978;&#21462;&#24471;&#20102;&#23454;&#35777;&#25104;&#21151;&#65292;&#20294;&#23578;&#19981;&#28165;&#26970;&#22522;&#20110;&#26799;&#24230;&#30340;&#31639;&#27861;&#26159;&#21542;&#21487;&#20197;&#20197;&#21487;&#35777;&#23454;&#30340;&#20934;&#30830;&#24615;&#23398;&#20064;&#20998;&#25968;&#20989;&#25968;&#12290;&#20316;&#20026;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#30340;&#39318;&#35201;&#27493;&#39588;&#65292;&#26412;&#25991;&#24314;&#31435;&#20102;&#19968;&#20010;&#25968;&#23398;&#26694;&#26550;&#65292;&#29992;&#20110;&#20998;&#26512;&#29992;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#26469;&#36827;&#34892;&#20998;&#25968;&#20272;&#35745;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#21253;&#25324;&#23398;&#20064;&#36807;&#31243;&#30340;&#20248;&#21270;&#21644;&#27867;&#21270;&#26041;&#38754;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21442;&#25968;&#21270;&#24418;&#24335;&#26469;&#23558;&#21435;&#22122;&#20998;&#25968;&#21305;&#37197;&#38382;&#39064;&#21046;&#23450;&#20026;&#24102;&#26377;&#22122;&#22768;&#26631;&#31614;&#30340;&#22238;&#24402;&#38382;&#39064;&#12290;&#19982;&#26631;&#20934;&#30340;&#30417;&#30563;&#23398;&#20064;&#35774;&#32622;&#30456;&#27604;&#65292;&#20998;&#25968;&#21305;&#37197;&#38382;&#39064;&#24341;&#20837;&#20102;&#29420;&#29305;&#30340;&#25361;&#25112;&#65292;&#21253;&#25324;&#26080;&#30028;&#36755;&#20837;&#65292;&#21521;&#37327;&#20540;&#36755;&#20986;&#21644;&#39069;&#22806;&#30340;&#26102;&#38388;&#21464;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models have emerged as a powerful tool rivaling GANs in generating high-quality samples with improved fidelity, flexibility, and robustness. A key component of these models is to learn the score function through score matching. Despite empirical success on various tasks, it remains unclear whether gradient-based algorithms can learn the score function with a provable accuracy. As a first step toward answering this question, this paper establishes a mathematical framework for analyzing score estimation using neural networks trained by gradient descent. Our analysis covers both the optimization and the generalization aspects of the learning procedure. In particular, we propose a parametric form to formulate the denoising score-matching problem as a regression with noisy labels. Compared to the standard supervised learning setup, the score-matching problem introduces distinct challenges, including unbounded input, vector-valued output, and an additional time variable, preventing
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#38789;&#30456;&#20851;&#25110;&#21487;&#20132;&#25442;&#38543;&#26426;&#23545;&#31216;&#30697;&#38453;&#30340;&#26032;&#38598;&#20013;&#19981;&#31561;&#24335;&#65292;&#36825;&#20123;&#19981;&#31561;&#24335;&#22312;&#22810;&#31181;&#23614;&#26465;&#20214;&#19979;&#25104;&#31435;&#65292;&#22312;&#27931;&#20234;&#32435;&#39034;&#24207;&#34920;&#31034;&#65292;&#24182;&#19988;&#26377;&#26102;&#22312;&#20219;&#24847;&#25968;&#25454;&#30456;&#20851;&#20572;&#27490;&#26102;&#38388;&#37117;&#36866;&#29992;&#12290;</title><link>http://arxiv.org/abs/2401.15567</link><description>&lt;p&gt;
&#30697;&#38453;&#36229;&#38789;&#21644;&#38543;&#26426;&#30697;&#38453;&#38598;&#20013;&#19981;&#31561;&#24335;
&lt;/p&gt;
&lt;p&gt;
Matrix Supermartingales and Randomized Matrix Concentration Inequalities. (arXiv:2401.15567v1 [math.PR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15567
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#38789;&#30456;&#20851;&#25110;&#21487;&#20132;&#25442;&#38543;&#26426;&#23545;&#31216;&#30697;&#38453;&#30340;&#26032;&#38598;&#20013;&#19981;&#31561;&#24335;&#65292;&#36825;&#20123;&#19981;&#31561;&#24335;&#22312;&#22810;&#31181;&#23614;&#26465;&#20214;&#19979;&#25104;&#31435;&#65292;&#22312;&#27931;&#20234;&#32435;&#39034;&#24207;&#34920;&#31034;&#65292;&#24182;&#19988;&#26377;&#26102;&#22312;&#20219;&#24847;&#25968;&#25454;&#30456;&#20851;&#20572;&#27490;&#26102;&#38388;&#37117;&#36866;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#22810;&#31181;&#23614;&#26465;&#20214;&#19979;&#65292;&#25552;&#20986;&#20102;&#38024;&#23545;&#38789;&#30456;&#20851;&#25110;&#21487;&#20132;&#25442;&#38543;&#26426;&#23545;&#31216;&#30697;&#38453;&#30340;&#26032;&#38598;&#20013;&#19981;&#31561;&#24335;&#65292;&#21253;&#25324;&#26631;&#20934;&#30340;&#20999;&#23572;&#35834;&#22827;&#19978;&#30028;&#21644;&#33258;&#24402;&#19968;&#21270;&#37325;&#23614;&#35774;&#32622;&#12290;&#36825;&#20123;&#19981;&#31561;&#24335;&#36890;&#24120;&#20197;&#27931;&#20234;&#32435;&#39034;&#24207;&#34920;&#31034;&#65292;&#24182;&#19988;&#26377;&#26102;&#22312;&#20219;&#24847;&#25968;&#25454;&#30456;&#20851;&#20572;&#27490;&#26102;&#38388;&#37117;&#25104;&#31435;&#12290;&#22312;&#27492;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#30697;&#38453;&#36229;&#38789;&#21644;&#26497;&#20540;&#19981;&#31561;&#24335;&#30340;&#29702;&#35770;&#65292;&#21487;&#33021;&#20855;&#26377;&#29420;&#31435;&#30340;&#30740;&#31350;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present new concentration inequalities for either martingale dependent or exchangeable random symmetric matrices under a variety of tail conditions, encompassing standard Chernoff bounds to self-normalized heavy-tailed settings. These inequalities are often randomized in a way that renders them strictly tighter than existing deterministic results in the literature, are typically expressed in the Loewner order, and are sometimes valid at arbitrary data-dependent stopping times.  Along the way, we explore the theory of matrix supermartingales and maximal inequalities, potentially of independent interest.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20132;&#21449;&#38598;&#20013;&#37319;&#26679;&#65288;CCS&#65289;&#27169;&#22411;&#22312;&#30697;&#38453;&#34917;&#20840;&#20013;&#30340;&#40065;&#26834;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#38750;&#20984;&#36845;&#20195;&#31639;&#27861;&#65288;RCURC&#65289;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#39564;&#35777;&#20102;&#20854;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2401.15566</link><description>&lt;p&gt;
&#20851;&#20110;&#30697;&#38453;&#34917;&#20840;&#30340;&#20132;&#21449;&#38598;&#20013;&#37319;&#26679;&#30340;&#40065;&#26834;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Robustness of Cross-Concentrated Sampling for Matrix Completion. (arXiv:2401.15566v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15566
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20132;&#21449;&#38598;&#20013;&#37319;&#26679;&#65288;CCS&#65289;&#27169;&#22411;&#22312;&#30697;&#38453;&#34917;&#20840;&#20013;&#30340;&#40065;&#26834;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#38750;&#20984;&#36845;&#20195;&#31639;&#27861;&#65288;RCURC&#65289;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#39564;&#35777;&#20102;&#20854;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30697;&#38453;&#34917;&#20840;&#26159;&#29616;&#20195;&#25968;&#25454;&#31185;&#23398;&#30740;&#31350;&#20013;&#30340;&#37325;&#35201;&#24037;&#20855;&#20043;&#19968;&#12290;&#26368;&#36817;&#65292;&#19968;&#31181;&#26032;&#30340;&#30697;&#38453;&#34917;&#20840;&#37319;&#26679;&#27169;&#22411;&#65292;&#21363;&#20132;&#21449;&#38598;&#20013;&#37319;&#26679;&#65288;CCS&#65289;&#65292;&#24341;&#36215;&#20102;&#24456;&#22810;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30740;&#31350;&#20013;&#23545;CCS&#27169;&#22411;&#23545;&#31232;&#30095;&#24322;&#24120;&#20540;&#30340;&#40065;&#26834;&#24615;&#20173;&#19981;&#28165;&#26970;&#12290;&#26412;&#25991;&#36890;&#36807;&#25506;&#32034;&#19968;&#31181;&#26032;&#39062;&#30340;&#40065;&#26834;CCS&#34917;&#20840;&#38382;&#39064;&#26469;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#38750;&#20984;&#36845;&#20195;&#31639;&#27861;&#65292;&#21629;&#21517;&#20026;&#40065;&#26834;CUR&#34917;&#20840;&#65288;RCURC&#65289;&#12290;&#36890;&#36807;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#39564;&#35777;&#20102;&#25152;&#25552;&#31639;&#27861;&#22312;&#25928;&#29575;&#21644;&#40065;&#26834;&#24615;&#26041;&#38754;&#30340;&#23454;&#38469;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Matrix completion is one of the crucial tools in modern data science research. Recently, a novel sampling model for matrix completion coined cross-concentrated sampling (CCS) has caught much attention. However, the robustness of the CCS model against sparse outliers remains unclear in the existing studies. In this paper, we aim to answer this question by exploring a novel Robust CCS Completion problem. A highly efficient non-convex iterative algorithm, dubbed Robust CUR Completion (RCURC), is proposed. The empirical performance of the proposed algorithm, in terms of both efficiency and robustness, is verified in synthetic and real datasets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26410;&#30693;&#20998;&#24067;&#19979;&#30340;Oracle-Efficient&#28151;&#21512;&#22312;&#32447;&#23398;&#20064;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#35745;&#31639;&#39640;&#25928;&#30340;&#22312;&#32447;&#39044;&#27979;&#22120;&#65292;&#23427;&#22312;&#26377;&#38480;&#30340;VC&#31867;&#21644;&#20855;&#26377;&#29305;&#23450;&#32500;&#24230;&#30340;&#31867;&#20013;&#20998;&#21035;&#23454;&#29616;&#20102;&#27425;&#32447;&#24615;&#30340;&#36951;&#25022;&#19978;&#30028;&#12290;&#27492;&#22806;&#65292;&#36824;&#23558;&#32467;&#26524;&#25512;&#24191;&#21040;&#20102;&#20855;&#26377;&#20998;&#24067;&#25913;&#21464;&#30340;&#24773;&#20917;&#65292;&#24182;&#24314;&#31435;&#20102;&#30456;&#24212;&#30340;&#36951;&#25022;&#30028;&#12290;</title><link>http://arxiv.org/abs/2401.15520</link><description>&lt;p&gt;
&#26410;&#30693;&#20998;&#24067;&#19979;&#30340;Oracle-Efficient&#28151;&#21512;&#22312;&#32447;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Oracle-Efficient Hybrid Online Learning with Unknown Distribution. (arXiv:2401.15520v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15520
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26410;&#30693;&#20998;&#24067;&#19979;&#30340;Oracle-Efficient&#28151;&#21512;&#22312;&#32447;&#23398;&#20064;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#35745;&#31639;&#39640;&#25928;&#30340;&#22312;&#32447;&#39044;&#27979;&#22120;&#65292;&#23427;&#22312;&#26377;&#38480;&#30340;VC&#31867;&#21644;&#20855;&#26377;&#29305;&#23450;&#32500;&#24230;&#30340;&#31867;&#20013;&#20998;&#21035;&#23454;&#29616;&#20102;&#27425;&#32447;&#24615;&#30340;&#36951;&#25022;&#19978;&#30028;&#12290;&#27492;&#22806;&#65292;&#36824;&#23558;&#32467;&#26524;&#25512;&#24191;&#21040;&#20102;&#20855;&#26377;&#20998;&#24067;&#25913;&#21464;&#30340;&#24773;&#20917;&#65292;&#24182;&#24314;&#31435;&#20102;&#30456;&#24212;&#30340;&#36951;&#25022;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#29305;&#24449;&#30001;&#26410;&#30693;i.i.d.&#36807;&#31243;&#29983;&#25104;&#65292;&#26631;&#31614;&#30001;&#23545;&#25239;&#29983;&#25104;&#26102;&#30340;Oracle-Efficient&#28151;&#21512;&#22312;&#32447;&#23398;&#20064;&#38382;&#39064;&#12290;&#20551;&#35774;&#21487;&#20197;&#35775;&#38382;&#19968;&#20010;&#65288;&#31163;&#32447;&#65289;ERM Oracle&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23384;&#22312;&#19968;&#20010;&#35745;&#31639;&#39640;&#25928;&#30340;&#22312;&#32447;&#39044;&#27979;&#22120;&#65292;&#23545;&#20110;&#26377;&#38480;&#30340;VC&#31867;&#65292;&#36951;&#25022;&#19978;&#30028;&#20026;$\tilde{O}(T^{\frac{3}{4}})$&#65292;&#23545;&#20110;&#20855;&#26377;$\alpha$ fat-shattering&#32500;&#24230;$\alpha^{-p}$&#30340;&#31867;&#65292;&#36951;&#25022;&#19978;&#30028;&#20026;$\tilde{O}(T^{\frac{p+1}{p+2}})$&#65292;&#36825;&#20026;&#20855;&#26377;&#26410;&#30693;&#29305;&#24449;&#29983;&#25104;&#36807;&#31243;&#30340;&#28151;&#21512;&#22312;&#32447;&#23398;&#20064;&#25552;&#20379;&#20102;&#39318;&#20010;&#24050;&#30693;&#30340;Oracle-Efficient&#27425;&#32447;&#24615;&#36951;&#25022;&#30028;&#12290;&#29305;&#21035;&#22320;&#65292;&#23427;&#39564;&#35777;&#20102;Lazaric&#21644;Munos&#65288;JCSS 2012&#65289;&#30340;&#19968;&#20010;&#29468;&#24819;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#32467;&#26524;&#25512;&#24191;&#21040;&#20102;&#20855;&#26377;$K$&#20010;&#20998;&#24067;&#25913;&#21464;&#30340;&#24773;&#20917;&#19979;&#65292;&#24471;&#21040;&#20102;&#19968;&#20010;$\tilde{O}(T^{\frac{4}{5}}K^{\frac{1}{5}})$&#38454;&#30340;&#36951;&#25022;&#30028;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;$\tilde{O}((K^{\frac{2}{3}}(\log|\mathcal{H}|)^{\frac{1}{3}}+K)\cdot T^{\frac{4}{5}})$&#30340;&#36951;&#25022;&#30028;&#65292;&#20854;&#20013;$\mathcal{H}$&#26159;&#19968;&#20010;&#20989;&#25968;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of oracle-efficient hybrid online learning when the features are generated by an unknown i.i.d. process and the labels are generated adversarially. Assuming access to an (offline) ERM oracle, we show that there exists a computationally efficient online predictor that achieves a regret upper bounded by $\tilde{O}(T^{\frac{3}{4}})$ for a finite-VC class, and upper bounded by $\tilde{O}(T^{\frac{p+1}{p+2}})$ for a class with $\alpha$ fat-shattering dimension $\alpha^{-p}$. This provides the first known oracle-efficient sublinear regret bounds for hybrid online learning with an unknown feature generation process. In particular, it confirms a conjecture of Lazaric and Munos (JCSS 2012). We then extend our result to the scenario of shifting distributions with $K$ changes, yielding a regret of order $\tilde{O}(T^{\frac{4}{5}}K^{\frac{1}{5}})$. Finally, we establish a regret of $\tilde{O}((K^{\frac{2}{3}}(\log|\mathcal{H}|)^{\frac{1}{3}}+K)\cdot T^{\frac{4}{5}})$ for the c
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#36125;&#21494;&#26031;&#26816;&#39564;&#26694;&#26550;&#65292;&#21033;&#29992;&#35268;&#33539;&#21270;&#30340;&#25968;&#25454;&#29983;&#25104;&#26426;&#21046;&#26469;&#36827;&#34892;&#25512;&#26029;&#65292;&#24182;&#36991;&#20813;&#20102;&#23545;&#23436;&#25972;&#25968;&#25454;&#29983;&#25104;&#26426;&#21046;&#30340;&#24314;&#27169;&#38656;&#27714;&#12290;&#35813;&#26694;&#26550;&#20855;&#26377;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#22312;&#35745;&#31639;&#19978;&#20855;&#26377;&#23454;&#36136;&#24615;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2401.15502</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#36125;&#21494;&#26031;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Bayesian Tests. (arXiv:2401.15502v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15502
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#36125;&#21494;&#26031;&#26816;&#39564;&#26694;&#26550;&#65292;&#21033;&#29992;&#35268;&#33539;&#21270;&#30340;&#25968;&#25454;&#29983;&#25104;&#26426;&#21046;&#26469;&#36827;&#34892;&#25512;&#26029;&#65292;&#24182;&#36991;&#20813;&#20102;&#23545;&#23436;&#25972;&#25968;&#25454;&#29983;&#25104;&#26426;&#21046;&#30340;&#24314;&#27169;&#38656;&#27714;&#12290;&#35813;&#26694;&#26550;&#20855;&#26377;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#22312;&#35745;&#31639;&#19978;&#20855;&#26377;&#23454;&#36136;&#24615;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21033;&#29992;&#26426;&#23494;&#25968;&#25454;&#36827;&#34892;&#31185;&#23398;&#20551;&#35774;&#26816;&#39564;&#30340;&#39046;&#22495;&#20013;&#65292;&#24046;&#20998;&#38544;&#31169;&#24050;&#32463;&#25104;&#20026;&#19968;&#20010;&#37325;&#35201;&#30340;&#22522;&#30707;&#12290;&#22312;&#25253;&#21578;&#31185;&#23398;&#21457;&#29616;&#26102;&#65292;&#24191;&#27867;&#37319;&#29992;&#36125;&#21494;&#26031;&#26816;&#39564;&#65292;&#22240;&#20026;&#23427;&#20204;&#26377;&#25928;&#22320;&#36991;&#20813;&#20102;P&#20540;&#30340;&#20027;&#35201;&#25209;&#35780;&#65292;&#21363;&#32570;&#20047;&#21487;&#35299;&#37322;&#24615;&#21644;&#26080;&#27861;&#37327;&#21270;&#23545;&#31454;&#20105;&#20551;&#35774;&#30340;&#25903;&#25345;&#35777;&#25454;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#24046;&#20998;&#38544;&#31169;&#36125;&#21494;&#26031;&#20551;&#35774;&#26816;&#39564;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#22312;&#22522;&#20110;&#35268;&#33539;&#21270;&#30340;&#25968;&#25454;&#29983;&#25104;&#26426;&#21046;&#22522;&#30784;&#19978;&#33258;&#28982;&#20135;&#29983;&#65292;&#20174;&#32780;&#20445;&#25345;&#20102;&#25512;&#26029;&#32467;&#26524;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#19987;&#27880;&#20110;&#22522;&#20110;&#24191;&#27867;&#20351;&#29992;&#30340;&#26816;&#39564;&#32479;&#35745;&#37327;&#30340;&#24046;&#20998;&#38544;&#31169;&#36125;&#21494;&#26031;&#22240;&#23376;&#65292;&#25105;&#20204;&#36991;&#20813;&#20102;&#23545;&#23436;&#25972;&#25968;&#25454;&#29983;&#25104;&#26426;&#21046;&#24314;&#27169;&#30340;&#38656;&#27714;&#65292;&#24182;&#30830;&#20445;&#20102;&#23454;&#36136;&#24615;&#30340;&#35745;&#31639;&#20248;&#21183;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#32452;&#20805;&#20998;&#26465;&#20214;&#65292;&#20197;&#22312;&#25152;&#25552;&#26694;&#26550;&#19979;&#30830;&#31435;&#36125;&#21494;&#26031;&#22240;&#23376;&#19968;&#33268;&#24615;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Differential privacy has emerged as an significant cornerstone in the realm of scientific hypothesis testing utilizing confidential data. In reporting scientific discoveries, Bayesian tests are widely adopted since they effectively circumnavigate the key criticisms of P-values, namely, lack of interpretability and inability to quantify evidence in support of the competing hypotheses. We present a novel differentially private Bayesian hypotheses testing framework that arise naturally under a principled data generative mechanism, inherently maintaining the interpretability of the resulting inferences. Furthermore, by focusing on differentially private Bayes factors based on widely used test statistics, we circumvent the need to model the complete data generative mechanism and ensure substantial computational benefits. We also provide a set of sufficient conditions to establish results on Bayes factor consistency under the proposed framework. The utility of the devised technology is showc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#36719;&#26631;&#31614;&#23545;&#36125;&#21494;&#26031;&#20108;&#20998;&#31867;&#22120;&#30340;&#35823;&#25253;&#29575;&#36827;&#34892;&#20272;&#35745;&#65292;&#24182;&#32771;&#34385;&#20102;&#36719;&#26631;&#31614;&#21644;&#26377;&#22122;&#22768;&#26631;&#31614;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2401.15500</link><description>&lt;p&gt;
&#22522;&#20110;&#36719;&#26631;&#31614;&#30340;&#36125;&#21494;&#26031;&#20108;&#20998;&#31867;&#22120;&#35823;&#25253;&#29575;&#30340;&#25968;&#25454;&#39537;&#21160;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Data-Driven Estimation of the False Positive Rate of the Bayes Binary Classifier via Soft Labels. (arXiv:2401.15500v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15500
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#36719;&#26631;&#31614;&#23545;&#36125;&#21494;&#26031;&#20108;&#20998;&#31867;&#22120;&#30340;&#35823;&#25253;&#29575;&#36827;&#34892;&#20272;&#35745;&#65292;&#24182;&#32771;&#34385;&#20102;&#36719;&#26631;&#31614;&#21644;&#26377;&#22122;&#22768;&#26631;&#31614;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#31867;&#26159;&#35768;&#22810;&#24212;&#29992;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#20219;&#21153;&#65292;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#24050;&#32463;&#26174;&#31034;&#20986;&#20102;&#20986;&#33394;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#30830;&#23450;&#36825;&#20123;&#26041;&#27861;&#26159;&#21542;&#36798;&#21040;&#20102;&#26368;&#20339;&#24615;&#33021;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#36825;&#20027;&#35201;&#26159;&#22240;&#20026;&#36890;&#24120;&#26080;&#27861;&#30693;&#36947;&#26368;&#20339;&#21487;&#36798;&#24615;&#33021;&#65292;&#22240;&#27492;&#26377;&#25928;&#22320;&#20272;&#35745;&#23427;&#26159;&#38750;&#24120;&#37325;&#35201;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20108;&#20998;&#31867;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#23545;&#20110;&#32473;&#23450;&#25968;&#25454;&#38598;&#20013;&#36125;&#21494;&#26031;&#20998;&#31867;&#22120;&#30340;&#35823;&#25253;&#29575;&#65288;FPR&#65289;&#30340;&#20272;&#35745;&#26041;&#27861;&#65292;&#21363;&#30456;&#23545;&#20110;&#20934;&#30830;&#29575;&#32780;&#35328;&#26368;&#20248;&#30340;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#20102;&#36719;&#26631;&#31614;&#25110;&#32773;&#23454;&#20540;&#26631;&#31614;&#65292;&#30001;&#20110;&#20854;&#29305;&#24615;&#65292;&#36719;&#26631;&#31614;&#27491;&#22312;&#33719;&#24471;&#26174;&#30528;&#30340;&#20851;&#27880;&#12290;&#25105;&#20204;&#23545;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#30340;&#21508;&#31181;&#29702;&#35770;&#24615;&#36136;&#36827;&#34892;&#20102;&#24443;&#24213;&#30340;&#30740;&#31350;&#65292;&#21253;&#25324;&#20854;&#19968;&#33268;&#24615;&#12289;&#26080;&#20559;&#24615;&#12289;&#25910;&#25947;&#36895;&#24230;&#21644;&#26041;&#24046;&#12290;&#20026;&#20102;&#22686;&#24378;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#22312;&#36719;&#26631;&#31614;&#20043;&#22806;&#30340;&#36890;&#29992;&#24615;&#65292;&#25105;&#20204;&#36824;&#32771;&#34385;&#20102;&#21253;&#21547;&#20108;&#20803;&#26631;&#31614;&#30340;&#26377;&#22122;&#22768;&#26631;&#31614;&#12290;
&lt;/p&gt;
&lt;p&gt;
Classification is a fundamental task in many applications on which data-driven methods have shown outstanding performances. However, it is challenging to determine whether such methods have achieved the optimal performance. This is mainly because the best achievable performance is typically unknown and hence, effectively estimating it is of prime importance. In this paper, we consider binary classification problems and we propose an estimator for the false positive rate (FPR) of the Bayes classifier, that is, the optimal classifier with respect to accuracy, from a given dataset. Our method utilizes soft labels, or real-valued labels, which are gaining significant traction thanks to their properties. We thoroughly examine various theoretical properties of our estimator, including its consistency, unbiasedness, rate of convergence, and variance. To enhance the versatility of our estimator beyond soft labels, we also consider noisy labels, which encompass binary labels. For noisy labels, 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#26799;&#24230;&#25554;&#20540;&#21644;&#26680;&#24179;&#28369;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20010;&#24615;&#21270;&#36830;&#32493;&#22788;&#29702;&#25928;&#26524;&#20272;&#35745;&#12290;&#36890;&#36807;&#22686;&#21152;&#29420;&#31435;&#37319;&#26679;&#30340;&#22788;&#29702;&#21644;&#25512;&#26029;&#30340;&#21453;&#20107;&#23454;&#32467;&#26524;&#26469;&#22788;&#29702;&#35757;&#32451;&#25968;&#25454;&#20013;&#30340;&#28151;&#28102;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#21453;&#20107;&#23454;&#39044;&#27979;&#24615;&#33021;&#19978;&#20248;&#20110;&#20854;&#20182;&#20845;&#31181;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.15447</link><description>&lt;p&gt;
&#20351;&#29992;&#26799;&#24230;&#25554;&#20540;&#21644;&#26680;&#24179;&#28369;&#20272;&#35745;&#36830;&#32493;&#22788;&#29702;&#25928;&#26524;
&lt;/p&gt;
&lt;p&gt;
Continuous Treatment Effect Estimation Using Gradient Interpolation and Kernel Smoothing. (arXiv:2401.15447v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15447
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#26799;&#24230;&#25554;&#20540;&#21644;&#26680;&#24179;&#28369;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#20010;&#24615;&#21270;&#36830;&#32493;&#22788;&#29702;&#25928;&#26524;&#20272;&#35745;&#12290;&#36890;&#36807;&#22686;&#21152;&#29420;&#31435;&#37319;&#26679;&#30340;&#22788;&#29702;&#21644;&#25512;&#26029;&#30340;&#21453;&#20107;&#23454;&#32467;&#26524;&#26469;&#22788;&#29702;&#35757;&#32451;&#25968;&#25454;&#20013;&#30340;&#28151;&#28102;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#21453;&#20107;&#23454;&#39044;&#27979;&#24615;&#33021;&#19978;&#20248;&#20110;&#20854;&#20182;&#20845;&#31181;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35299;&#20915;&#20102;&#20010;&#24615;&#21270;&#36830;&#32493;&#22788;&#29702;&#25928;&#26524;&#65288;ICTE&#65289;&#20272;&#35745;&#38382;&#39064;&#65292;&#36890;&#36807;&#35266;&#27979;&#25968;&#25454;&#39044;&#27979;&#20219;&#20309;&#36830;&#32493;&#20540;&#22788;&#29702;&#23545;&#20010;&#20307;&#30340;&#25928;&#26524;&#12290;&#36825;&#20010;&#20272;&#35745;&#20219;&#21153;&#30340;&#20027;&#35201;&#25361;&#25112;&#26159;&#35757;&#32451;&#25968;&#25454;&#20013;&#22788;&#29702;&#20998;&#37197;&#19982;&#20010;&#20307;&#21327;&#21464;&#37327;&#30340;&#28508;&#22312;&#28151;&#28102;&#65292;&#32780;&#22312;&#25512;&#26029;ICTE&#26102;&#38656;&#35201;&#23545;&#29420;&#31435;&#37319;&#26679;&#30340;&#22788;&#29702;&#36827;&#34892;&#39044;&#27979;&#12290;&#19982;&#20043;&#21069;&#20381;&#36182;&#20110;&#27491;&#21017;&#21270;&#22120;&#25110;&#19981;&#31283;&#23450;&#30340;GAN&#35757;&#32451;&#30340;&#24037;&#20316;&#30456;&#21453;&#65292;&#25105;&#20204;&#20027;&#24352;&#30452;&#25509;&#26041;&#27861;&#65292;&#21363;&#36890;&#36807;&#22686;&#21152;&#29420;&#31435;&#37319;&#26679;&#30340;&#22788;&#29702;&#21644;&#25512;&#26029;&#30340;&#21453;&#20107;&#23454;&#32467;&#26524;&#26469;&#22686;&#24378;&#35757;&#32451;&#20010;&#20307;&#12290; &#25105;&#20204;&#20351;&#29992;&#20004;&#31181;&#31574;&#30053;&#25512;&#26029;&#21453;&#20107;&#23454;&#32467;&#26524;&#65306;&#23545;&#25509;&#36817;&#35266;&#23519;&#21040;&#30340;&#22788;&#29702;&#36827;&#34892;&#26799;&#24230;&#25554;&#20540;&#65292;&#20197;&#21450;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#30340;&#26680;&#24179;&#28369;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#20943;&#23567;&#25512;&#26029;&#30340;&#39640;&#26041;&#24046;&#12290;&#25105;&#20204;&#22312;&#20116;&#20010;&#22522;&#20934;&#27979;&#35797;&#19978;&#35780;&#20272;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#24182;&#26174;&#31034;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21453;&#20107;&#23454;&#39044;&#27979;&#24615;&#33021;&#19978;&#32988;&#36807;&#20845;&#31181;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We address the Individualized continuous treatment effect (ICTE) estimation problem where we predict the effect of any continuous-valued treatment on an individual using observational data. The main challenge in this estimation task is the potential confounding of treatment assignment with an individual's covariates in the training data, whereas during inference ICTE requires prediction on independently sampled treatments. In contrast to prior work that relied on regularizers or unstable GAN training, we advocate the direct approach of augmenting training individuals with independently sampled treatments and inferred counterfactual outcomes. We infer counterfactual outcomes using a two-pronged strategy: a Gradient Interpolation for close-to-observed treatments, and a Gaussian Process based Kernel Smoothing which allows us to downweigh high variance inferences. We evaluate our method on five benchmarks and show that our method outperforms six state-of-the-art methods on the counterfactu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;$\ell_\infty$-&#25200;&#21160;&#19979;&#30340;&#23545;&#25239;&#24615;&#35757;&#32451;&#65292;&#35777;&#26126;&#24403;&#30495;&#23454;&#21442;&#25968;&#20026;0&#26102;&#65292;&#23545;&#25239;&#24615;&#35757;&#32451;&#20272;&#35745;&#22120;&#22312;&#35813;&#25200;&#21160;&#19979;&#30340;&#26497;&#38480;&#20998;&#24067;&#21487;&#33021;&#22312;0&#22788;&#26377;&#19968;&#20010;&#27491;&#27010;&#29575;&#36136;&#37327;&#65292;&#25552;&#20379;&#20102;&#31232;&#30095;&#24615;&#24674;&#22797;&#33021;&#21147;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20004;&#27493;&#36807;&#31243;&#8212;&#8212;&#33258;&#36866;&#24212;&#23545;&#25239;&#24615;&#35757;&#32451;&#65292;&#21487;&#20197;&#36827;&#19968;&#27493;&#25552;&#39640;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.15262</link><description>&lt;p&gt;
&#22312;$\ell_\infty$-&#25200;&#21160;&#19979;&#23545;&#25239;&#24615;&#35757;&#32451;&#20272;&#35745;&#22120;&#30340;&#28176;&#36817;&#34892;&#20026;
&lt;/p&gt;
&lt;p&gt;
Asymptotic Behavior of Adversarial Training Estimator under $\ell_\infty$-Perturbation. (arXiv:2401.15262v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15262
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;$\ell_\infty$-&#25200;&#21160;&#19979;&#30340;&#23545;&#25239;&#24615;&#35757;&#32451;&#65292;&#35777;&#26126;&#24403;&#30495;&#23454;&#21442;&#25968;&#20026;0&#26102;&#65292;&#23545;&#25239;&#24615;&#35757;&#32451;&#20272;&#35745;&#22120;&#22312;&#35813;&#25200;&#21160;&#19979;&#30340;&#26497;&#38480;&#20998;&#24067;&#21487;&#33021;&#22312;0&#22788;&#26377;&#19968;&#20010;&#27491;&#27010;&#29575;&#36136;&#37327;&#65292;&#25552;&#20379;&#20102;&#31232;&#30095;&#24615;&#24674;&#22797;&#33021;&#21147;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20004;&#27493;&#36807;&#31243;&#8212;&#8212;&#33258;&#36866;&#24212;&#23545;&#25239;&#24615;&#35757;&#32451;&#65292;&#21487;&#20197;&#36827;&#19968;&#27493;&#25552;&#39640;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#24615;&#35757;&#32451;&#34987;&#25552;&#20986;&#26469;&#25269;&#24481;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#27169;&#22411;&#20013;&#30340;&#23545;&#25239;&#24615;&#25915;&#20987;&#12290;&#26412;&#25991;&#37325;&#28857;&#30740;&#31350;&#20102;&#22312;$\ell_\infty$-&#25200;&#21160;&#19979;&#30340;&#23545;&#25239;&#24615;&#35757;&#32451;&#65292;&#36825;&#20010;&#38382;&#39064;&#26368;&#36817;&#24341;&#36215;&#20102;&#24456;&#22810;&#30740;&#31350;&#30340;&#20851;&#27880;&#12290;&#22312;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#20013;&#30740;&#31350;&#20102;&#23545;&#25239;&#24615;&#35757;&#32451;&#20272;&#35745;&#22120;&#30340;&#28176;&#36817;&#34892;&#20026;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#24403;&#30495;&#23454;&#21442;&#25968;&#20026;0&#26102;&#65292;&#23545;&#25239;&#24615;&#35757;&#32451;&#20272;&#35745;&#22120;&#22312;$\ell_\infty$-&#25200;&#21160;&#19979;&#30340;&#26497;&#38480;&#20998;&#24067;&#21487;&#33021;&#22312;0&#22788;&#26377;&#19968;&#20010;&#27491;&#27010;&#29575;&#36136;&#37327;&#65292;&#20026;&#30456;&#20851;&#30340;&#31232;&#30095;&#24615;&#24674;&#22797;&#33021;&#21147;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20004;&#27493;&#36807;&#31243;&#8212;&#8212;&#33258;&#36866;&#24212;&#23545;&#25239;&#24615;&#35757;&#32451;&#65292;&#21487;&#20197;&#36827;&#19968;&#27493;&#25552;&#39640;&#22312;$\ell_\infty$-&#25200;&#21160;&#19979;&#30340;&#23545;&#25239;&#24615;&#35757;&#32451;&#30340;&#24615;&#33021;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25152;&#25552;&#20986;&#30340;&#36807;&#31243;&#21487;&#20197;&#23454;&#29616;&#28176;&#36817;&#26080;&#20559;&#24615;&#21644;&#21464;&#37327;&#36873;&#25321;&#19968;&#33268;&#24615;&#12290;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#23637;&#31034;&#20102;&#31232;&#30095;&#24615;&#24674;&#22797;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adversarial training has been proposed to hedge against adversarial attacks in machine learning and statistical models. This paper focuses on adversarial training under $\ell_\infty$-perturbation, which has recently attracted much research attention. The asymptotic behavior of the adversarial training estimator is investigated in the generalized linear model. The results imply that the limiting distribution of the adversarial training estimator under $\ell_\infty$-perturbation could put a positive probability mass at $0$ when the true parameter is $0$, providing a theoretical guarantee of the associated sparsity-recovery ability. Alternatively, a two-step procedure is proposed -adaptive adversarial training, which could further improve the performance of adversarial training under $\ell_\infty$-perturbation. Specifically, the proposed procedure could achieve asymptotic unbiasedness and variable-selection consistency. Numerical experiments are conducted to show the sparsity-recovery a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#20219;&#24847;&#39044;&#27979;&#22120;&#26500;&#24314;&#32447;&#24615;&#27169;&#22411;&#21442;&#25968;&#30340;&#26377;&#38480;&#26679;&#26412;&#32622;&#20449;&#21306;&#38388;&#12290;&#35813;&#26041;&#27861;&#23545;&#22122;&#22768;&#30340;&#35201;&#27714;&#24456;&#23569;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#20005;&#26684;&#32447;&#24615;&#20989;&#25968;&#20559;&#24046;&#19968;&#23450;&#38408;&#20540;&#30340;&#20989;&#25968;&#12290;&#36825;&#31181;&#26041;&#27861;&#33021;&#22815;&#36827;&#34892;&#40065;&#26834;&#20248;&#21270;&#65292;&#24182;&#25552;&#21462;&#29305;&#23450;&#21442;&#25968;&#22352;&#26631;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#20063;&#33021;&#29992;&#20110;&#20551;&#35774;&#26816;&#39564;&#12290;</title><link>http://arxiv.org/abs/2401.15254</link><description>&lt;p&gt;
&#29992;&#20219;&#24847;&#39044;&#27979;&#22120;&#26500;&#24314;&#32447;&#24615;&#22238;&#24402;&#21442;&#25968;&#30340;&#26377;&#38480;&#26679;&#26412;&#32622;&#20449;&#21306;&#38388;
&lt;/p&gt;
&lt;p&gt;
Finite Sample Confidence Regions for Linear Regression Parameters Using Arbitrary Predictors. (arXiv:2401.15254v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15254
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#20219;&#24847;&#39044;&#27979;&#22120;&#26500;&#24314;&#32447;&#24615;&#27169;&#22411;&#21442;&#25968;&#30340;&#26377;&#38480;&#26679;&#26412;&#32622;&#20449;&#21306;&#38388;&#12290;&#35813;&#26041;&#27861;&#23545;&#22122;&#22768;&#30340;&#35201;&#27714;&#24456;&#23569;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#20005;&#26684;&#32447;&#24615;&#20989;&#25968;&#20559;&#24046;&#19968;&#23450;&#38408;&#20540;&#30340;&#20989;&#25968;&#12290;&#36825;&#31181;&#26041;&#27861;&#33021;&#22815;&#36827;&#34892;&#40065;&#26834;&#20248;&#21270;&#65292;&#24182;&#25552;&#21462;&#29305;&#23450;&#21442;&#25968;&#22352;&#26631;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#20063;&#33021;&#29992;&#20110;&#20551;&#35774;&#26816;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25506;&#32034;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#20219;&#24847;&#39044;&#27979;&#22120;&#26500;&#24314;&#32447;&#24615;&#27169;&#22411;&#21442;&#25968;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#23545;&#22122;&#22768;&#30340;&#35201;&#27714;&#24456;&#23569;&#65292;&#24182;&#19988;&#21487;&#20197;&#25193;&#23637;&#21040;&#20005;&#26684;&#32447;&#24615;&#20989;&#25968;&#20559;&#24046;&#19968;&#23450;&#38408;&#20540;&#30340;&#20989;&#25968;&#65292;&#20174;&#32780;&#36866;&#24212;&#20102;&#24191;&#27867;&#32780;&#23454;&#29992;&#30340;&#20989;&#25968;&#38598;&#21512;&#12290;&#24471;&#20986;&#30340;&#32622;&#20449;&#21306;&#38388;&#21487;&#20197;&#20316;&#20026;&#28151;&#21512;&#25972;&#25968;&#32447;&#24615;&#35268;&#21010;&#26694;&#26550;&#20013;&#30340;&#32422;&#26463;&#26465;&#20214;&#65292;&#20174;&#32780;&#23454;&#29616;&#32447;&#24615;&#30446;&#26631;&#30340;&#20248;&#21270;&#12290;&#36825;&#31181;&#34920;&#31034;&#26041;&#24335;&#33021;&#22815;&#36827;&#34892;&#40065;&#26834;&#20248;&#21270;&#65292;&#24182;&#25552;&#21462;&#29305;&#23450;&#21442;&#25968;&#22352;&#26631;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#19982;&#20197;&#21069;&#30340;&#26041;&#27861;&#19981;&#21516;&#30340;&#26159;&#65292;&#32622;&#20449;&#21306;&#38388;&#21487;&#33021;&#20026;&#31354;&#65292;&#36825;&#21487;&#20197;&#29992;&#20110;&#20551;&#35774;&#26816;&#39564;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#22312;&#21512;&#25104;&#25968;&#25454;&#19978;&#39564;&#35777;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#23454;&#35777;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We explore a novel methodology for constructing confidence regions for parameters of linear models, using predictions from any arbitrary predictor. Our framework requires minimal assumptions on the noise and can be extended to functions deviating from strict linearity up to some adjustable threshold, thereby accommodating a comprehensive and pragmatically relevant set of functions. The derived confidence regions can be cast as constraints within a Mixed Integer Linear Programming framework, enabling optimisation of linear objectives. This representation enables robust optimization and the extraction of confidence intervals for specific parameter coordinates. Unlike previous methods, the confidence region can be empty, which can be used for hypothesis testing. Finally, we validate the empirical applicability of our method on synthetic data.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20174;&#29702;&#35770;&#35282;&#24230;&#25506;&#35752;&#20102;&#22312;&#39044;&#35757;&#32451;&#20013;&#36890;&#36807;&#23545;&#25239;&#35757;&#32451;&#25913;&#36827;&#34920;&#31034;&#30340;&#24605;&#36335;&#65292;&#24182;&#35777;&#26126;&#20102;&#29305;&#24449;&#20928;&#21270;&#22312;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#21644;&#19979;&#28216;&#20219;&#21153;&#20043;&#38388;&#36215;&#21040;&#37325;&#35201;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2401.15248</link><description>&lt;p&gt;
&#22312;&#39044;&#35757;&#32451;&#20013;&#36890;&#36807;&#23545;&#25239;&#35757;&#32451;&#25913;&#36827;&#34920;&#31034;&#65306;&#20174;&#29702;&#35770;&#35282;&#24230;&#20986;&#21457;
&lt;/p&gt;
&lt;p&gt;
Better Representations via Adversarial Training in Pre-Training: A Theoretical Perspective. (arXiv:2401.15248v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15248
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20174;&#29702;&#35770;&#35282;&#24230;&#25506;&#35752;&#20102;&#22312;&#39044;&#35757;&#32451;&#20013;&#36890;&#36807;&#23545;&#25239;&#35757;&#32451;&#25913;&#36827;&#34920;&#31034;&#30340;&#24605;&#36335;&#65292;&#24182;&#35777;&#26126;&#20102;&#29305;&#24449;&#20928;&#21270;&#22312;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#21644;&#19979;&#28216;&#20219;&#21153;&#20043;&#38388;&#36215;&#21040;&#37325;&#35201;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39044;&#35757;&#32451;&#34987;&#35748;&#20026;&#21487;&#20197;&#20026;&#22823;&#35268;&#27169;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#19979;&#28216;&#20219;&#21153;&#29983;&#25104;&#36890;&#29992;&#34920;&#31034;&#65292;&#20363;&#22914;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#12290;&#29616;&#26377;&#25991;&#29486;&#20363;&#22914;\cite{kim2020adversarial}&#32463;&#39564;&#24615;&#22320;&#35266;&#23519;&#21040;&#19979;&#28216;&#20219;&#21153;&#21487;&#20197;&#32487;&#25215;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#36825;&#31181;&#40065;&#26834;&#24615;&#32487;&#25215;&#29616;&#35937;&#30340;&#29702;&#35770;&#35777;&#26126;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#25581;&#31034;&#20102;&#22312;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#29305;&#24449;&#20928;&#21270;&#22312;&#36830;&#25509;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;&#21644;&#19979;&#28216;&#20219;&#21153;&#20013;&#36215;&#37325;&#35201;&#20316;&#29992;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;(i)&#36890;&#36807;&#23545;&#25239;&#35757;&#32451;&#65292;&#27599;&#20010;&#38544;&#34255;&#33410;&#28857;&#20542;&#21521;&#20110;&#36873;&#25321;&#21482;&#26377;&#19968;&#20010;&#65288;&#25110;&#20960;&#20010;&#65289;&#29305;&#24449;&#65307;(ii)&#22312;&#27809;&#26377;&#23545;&#25239;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#65292;&#38544;&#34255;&#33410;&#28857;&#21487;&#33021;&#23481;&#26131;&#21463;&#21040;&#25915;&#20987;&#12290;&#36825;&#20010;&#35266;&#23519;&#23545;&#20110;&#30417;&#30563;&#39044;&#35757;&#32451;&#21644;&#23545;&#27604;&#23398;&#20064;&#37117;&#26159;&#26377;&#25928;&#30340;&#12290;&#36890;&#36807;&#20928;&#21270;&#33410;&#28857;&#65292;&#20107;&#23454;&#35777;&#26126;&#22312;&#19979;&#28216;&#20219;&#21153;&#20013;&#65292;&#20165;&#20165;&#36827;&#34892;&#24178;&#20928;&#35757;&#32451;&#23601;&#36275;&#20197;&#23454;&#29616;&#23545;&#25239;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Pre-training is known to generate universal representations for downstream tasks in large-scale deep learning such as large language models. Existing literature, e.g., \cite{kim2020adversarial}, empirically observe that the downstream tasks can inherit the adversarial robustness of the pre-trained model. We provide theoretical justifications for this robustness inheritance phenomenon. Our theoretical results reveal that feature purification plays an important role in connecting the adversarial robustness of the pre-trained model and the downstream tasks in two-layer neural networks. Specifically, we show that (i) with adversarial training, each hidden node tends to pick only one (or a few) feature; (ii) without adversarial training, the hidden nodes can be vulnerable to attacks. This observation is valid for both supervised pre-training and contrastive learning. With purified nodes, it turns out that clean training is enough to achieve adversarial robustness in downstream tasks.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#23637;&#30340;T-Rex&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#31232;&#30095;&#37329;&#34701;&#25351;&#25968;&#36319;&#36394;&#20013;&#36873;&#25321;&#23569;&#25968;&#30456;&#20851;&#21464;&#37327;&#65292;&#24182;&#36890;&#36807;&#38598;&#25104;&#26368;&#36817;&#37051;&#24809;&#32602;&#26426;&#21046;&#65292;&#21487;&#38752;&#25511;&#21046;&#35823;&#21457;&#29616;&#29575;&#65288;FDR&#65289;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#36807;&#21435;20&#24180;&#20869;&#22522;&#20110;&#23569;&#37327;&#32929;&#31080;&#20934;&#30830;&#36319;&#36394;&#26631;&#20934;&#26222;&#23572;500&#25351;&#25968;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2401.15139</link><description>&lt;p&gt;
FDR&#25511;&#21046;&#30340;&#31232;&#30095;&#37329;&#34701;&#25351;&#25968;&#36319;&#36394;&#25237;&#36164;&#32452;&#21512;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
FDR-Controlled Portfolio Optimization for Sparse Financial Index Tracking. (arXiv:2401.15139v1 [q-fin.PM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15139
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#23637;&#30340;T-Rex&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#31232;&#30095;&#37329;&#34701;&#25351;&#25968;&#36319;&#36394;&#20013;&#36873;&#25321;&#23569;&#25968;&#30456;&#20851;&#21464;&#37327;&#65292;&#24182;&#36890;&#36807;&#38598;&#25104;&#26368;&#36817;&#37051;&#24809;&#32602;&#26426;&#21046;&#65292;&#21487;&#38752;&#25511;&#21046;&#35823;&#21457;&#29616;&#29575;&#65288;FDR&#65289;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#36807;&#21435;20&#24180;&#20869;&#22522;&#20110;&#23569;&#37327;&#32929;&#31080;&#20934;&#30830;&#36319;&#36394;&#26631;&#20934;&#26222;&#23572;500&#25351;&#25968;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39640;&#32500;&#25968;&#25454;&#20998;&#26512;&#20013;&#65292;&#22914;&#37329;&#34701;&#25351;&#25968;&#36319;&#36394;&#25110;&#29983;&#29289;&#21307;&#23398;&#24212;&#29992;&#20013;&#65292;&#20851;&#38190;&#26159;&#22312;&#20445;&#25345;&#23545;&#35823;&#21457;&#29616;&#29575;&#65288;FDR&#65289;&#30340;&#25511;&#21046;&#30340;&#21516;&#26102;&#36873;&#25321;&#23569;&#25968;&#30456;&#20851;&#21464;&#37327;&#12290;&#22312;&#36825;&#20123;&#24212;&#29992;&#20013;&#65292;&#21464;&#37327;&#20043;&#38388;&#32463;&#24120;&#23384;&#22312;&#24378;&#20381;&#36182;&#20851;&#31995;&#65288;&#20363;&#22914;&#32929;&#31080;&#25910;&#30410;&#65289;&#65292;&#36825;&#21487;&#33021;&#20250;&#21066;&#24369;&#29616;&#26377;&#26041;&#27861;&#65288;&#22914;&#27169;&#22411;X knockoff&#26041;&#27861;&#25110;T-Rex&#36873;&#25321;&#22120;&#65289;&#30340;FDR&#25511;&#21046;&#29305;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;T-Rex&#26694;&#26550;&#65292;&#20197;&#36866;&#24212;&#39640;&#24230;&#30456;&#20851;&#21464;&#37327;&#30340;&#37325;&#21472;&#32452;&#12290;&#36825;&#26159;&#36890;&#36807;&#23558;&#26368;&#36817;&#37051;&#24809;&#32602;&#26426;&#21046;&#38598;&#25104;&#21040;&#26694;&#26550;&#20013;&#23454;&#29616;&#30340;&#65292;&#35813;&#26426;&#21046;&#33021;&#22815;&#22312;&#29992;&#25143;&#23450;&#20041;&#30340;&#30446;&#26631;&#27700;&#24179;&#19978;&#21487;&#38752;&#25511;&#21046;FDR&#12290;&#31232;&#30095;&#25351;&#25968;&#36319;&#36394;&#30340;&#23454;&#20363;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#22312;&#36807;&#21435;20&#24180;&#20869;&#22522;&#20110;&#23569;&#37327;&#32929;&#31080;&#20934;&#30830;&#36319;&#36394;&#26631;&#20934;&#26222;&#23572;500&#25351;&#25968;&#30340;&#33021;&#21147;&#12290;&#22312;CRAN&#19978;&#25552;&#20379;&#20102;R&#21253;TRexSelector&#30340;&#24320;&#28304;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
In high-dimensional data analysis, such as financial index tracking or biomedical applications, it is crucial to select the few relevant variables while maintaining control over the false discovery rate (FDR). In these applications, strong dependencies often exist among the variables (e.g., stock returns), which can undermine the FDR control property of existing methods like the model-X knockoff method or the T-Rex selector. To address this issue, we have expanded the T-Rex framework to accommodate overlapping groups of highly correlated variables. This is achieved by integrating a nearest neighbors penalization mechanism into the framework, which provably controls the FDR at the user-defined target level. A real-world example of sparse index tracking demonstrates the proposed method's ability to accurately track the S&amp;P 500 index over the past 20 years based on a small number of stocks. An open-source implementation is provided within the R package TRexSelector on CRAN.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#20419;&#36827;&#25968;&#20540;MD&#27169;&#25311;&#24182;&#26377;&#25928;&#27169;&#25311;&#34507;&#30333;&#36136;-&#37197;&#20307;&#32467;&#21512;&#21160;&#21147;&#23398;&#30340;NeuralMD&#26041;&#27861;&#65292;&#37319;&#29992;&#29289;&#29702;&#20449;&#24687;&#22810;&#32423;&#23545;&#31216;&#26694;&#26550;&#65292;&#23454;&#29616;&#20102;&#20934;&#30830;&#24314;&#27169;&#22810;&#32423;&#34507;&#30333;&#36136;-&#37197;&#20307;&#30456;&#20114;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2401.15122</link><description>&lt;p&gt;
&#19968;&#31181;&#22810;&#32423;&#23545;&#31216;&#24494;&#20998;&#26041;&#31243;&#27169;&#22411;&#29992;&#20110;&#23398;&#20064;&#34507;&#30333;&#36136;-&#37197;&#20307;&#32467;&#21512;&#21160;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
A Multi-Grained Symmetric Differential Equation Model for Learning Protein-Ligand Binding Dynamics. (arXiv:2401.15122v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15122
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#20419;&#36827;&#25968;&#20540;MD&#27169;&#25311;&#24182;&#26377;&#25928;&#27169;&#25311;&#34507;&#30333;&#36136;-&#37197;&#20307;&#32467;&#21512;&#21160;&#21147;&#23398;&#30340;NeuralMD&#26041;&#27861;&#65292;&#37319;&#29992;&#29289;&#29702;&#20449;&#24687;&#22810;&#32423;&#23545;&#31216;&#26694;&#26550;&#65292;&#23454;&#29616;&#20102;&#20934;&#30830;&#24314;&#27169;&#22810;&#32423;&#34507;&#30333;&#36136;-&#37197;&#20307;&#30456;&#20114;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#33647;&#29289;&#21457;&#29616;&#20013;&#65292;&#34507;&#30333;&#36136;-&#37197;&#20307;&#32467;&#21512;&#30340;&#20998;&#23376;&#21160;&#21147;&#23398;&#65288;MD&#65289;&#27169;&#25311;&#25552;&#20379;&#20102;&#19968;&#31181;&#24378;&#22823;&#30340;&#24037;&#20855;&#65292;&#29992;&#20110;&#39044;&#27979;&#32467;&#21512;&#20146;&#21644;&#21147;&#65292;&#20272;&#35745;&#36816;&#36755;&#24615;&#33021;&#21644;&#25506;&#32034;&#21475;&#34955;&#20301;&#28857;&#12290;&#36890;&#36807;&#25913;&#36827;&#25968;&#20540;&#26041;&#27861;&#20197;&#21450;&#26368;&#36817;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#26041;&#27861;&#22686;&#24378;MD&#27169;&#25311;&#30340;&#25928;&#29575;&#24050;&#32463;&#26377;&#20102;&#24456;&#38271;&#30340;&#21382;&#21490;&#12290;&#28982;&#32780;&#65292;&#20173;&#28982;&#23384;&#22312;&#19968;&#20123;&#25361;&#25112;&#65292;&#20363;&#22914;&#20934;&#30830;&#24314;&#27169;&#25193;&#23637;&#26102;&#38388;&#23610;&#24230;&#30340;&#27169;&#25311;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;NeuralMD&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#33021;&#22815;&#20419;&#36827;&#25968;&#20540;MD&#24182;&#25552;&#20379;&#20934;&#30830;&#30340;&#34507;&#30333;&#36136;-&#37197;&#20307;&#32467;&#21512;&#21160;&#21147;&#23398;&#27169;&#25311;&#30340;ML&#36741;&#21161;&#24037;&#20855;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21512;&#29702;&#30340;&#26041;&#27861;&#65292;&#23558;&#19968;&#31181;&#26032;&#30340;&#29289;&#29702;&#20449;&#24687;&#22810;&#32423;&#23545;&#31216;&#26694;&#26550;&#32435;&#20837;&#27169;&#22411;&#20013;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#65288;1&#65289;&#19968;&#20010;&#20351;&#29992;&#21521;&#37327;&#26694;&#26550;&#28385;&#36275;&#32676;&#23545;&#31216;&#24615;&#24182;&#25429;&#33719;&#22810;&#32423;&#34507;&#30333;&#36136;-&#37197;&#20307;&#30456;&#20114;&#20316;&#29992;&#30340;BindingNet&#27169;&#22411;&#65292;&#20197;&#21450;&#65288;2&#65289;&#19968;&#20010;&#22686;&#24378;&#30340;&#31070;&#32463;&#24494;&#20998;&#26041;&#31243;&#27714;&#35299;&#22120;&#65292;&#23398;&#20064;&#36712;&#36857;&#30340;&#28436;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
In drug discovery, molecular dynamics (MD) simulation for protein-ligand binding provides a powerful tool for predicting binding affinities, estimating transport properties, and exploring pocket sites. There has been a long history of improving the efficiency of MD simulations through better numerical methods and, more recently, by augmenting them with machine learning (ML) methods. Yet, challenges remain, such as accurate modeling of extended-timescale simulations. To address this issue, we propose NeuralMD, the first ML surrogate that can facilitate numerical MD and provide accurate simulations of protein-ligand binding dynamics. We propose a principled approach that incorporates a novel physics-informed multi-grained group symmetric framework. Specifically, we propose (1) a BindingNet model that satisfies group symmetry using vector frames and captures the multi-level protein-ligand interactions, and (2) an augmented neural differential equation solver that learns the trajectory und
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20108;&#36827;&#21046;&#24863;&#30693;&#26426;&#30340;&#23481;&#37327;&#38382;&#39064;&#65292;&#22312;&#30830;&#23450;&#20102;&#19978;&#30028;&#21644;&#19979;&#30028;&#21518;&#65292;&#32473;&#20986;&#20102;&#35777;&#26126;&#35813;&#23481;&#37327;&#23567;&#20110;0.847&#30340;&#26465;&#20214;&#19968;&#38454;&#30697;&#26041;&#27861;&#19982;&#24050;&#30693;&#32467;&#26524;&#30340;&#32467;&#21512;&#12290;</title><link>http://arxiv.org/abs/2401.15092</link><description>&lt;p&gt;
&#20108;&#36827;&#21046;&#24863;&#30693;&#26426;&#23481;&#37327;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A note on the capacity of the binary perceptron. (arXiv:2401.15092v1 [math.PR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15092
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20108;&#36827;&#21046;&#24863;&#30693;&#26426;&#30340;&#23481;&#37327;&#38382;&#39064;&#65292;&#22312;&#30830;&#23450;&#20102;&#19978;&#30028;&#21644;&#19979;&#30028;&#21518;&#65292;&#32473;&#20986;&#20102;&#35777;&#26126;&#35813;&#23481;&#37327;&#23567;&#20110;0.847&#30340;&#26465;&#20214;&#19968;&#38454;&#30697;&#26041;&#27861;&#19982;&#24050;&#30693;&#32467;&#26524;&#30340;&#32467;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30830;&#23450;&#20108;&#36827;&#21046;&#24863;&#30693;&#26426;&#30340;&#23481;&#37327;&#945;c&#26159;&#19968;&#20010;&#38271;&#26399;&#23384;&#22312;&#30340;&#38382;&#39064;&#12290;Krauth&#21644;Mezard&#65288;1989&#65289;&#29468;&#27979;&#20102;&#945;c&#30340;&#26126;&#30830;&#20540;&#65292;&#22823;&#32422;&#31561;&#20110;0.833&#65292;&#26368;&#36817;Ding&#21644;Sun&#65288;2019&#65289;&#24314;&#31435;&#20102;&#19982;&#27492;&#39044;&#27979;&#30456;&#31526;&#30340;&#20005;&#26684;&#19979;&#30028;&#12290;&#20851;&#20110;&#19978;&#30028;&#65292;Kim&#21644;Roche&#65288;1998&#65289;&#20197;&#21450;Talagrand&#65288;1999&#65289;&#20998;&#21035;&#26174;&#31034;&#945;c &lt; 0.996&#65292;&#32780;Krauth&#21644;Mezard&#27010;&#36848;&#20102;&#19968;&#20010;&#21487;&#20197;&#29992;&#20110;&#26174;&#31034;&#945;c &lt; 0.847&#30340;&#35770;&#35777;&#12290;&#36825;&#20010;&#35828;&#26126;&#30340;&#30446;&#30340;&#26159;&#35760;&#24405;&#19968;&#20010;&#23436;&#25972;&#30340;&#35777;&#26126;&#945;c &lt; 0.847&#30340;&#35777;&#26126;&#12290;&#35813;&#35777;&#26126;&#26159;&#19968;&#31181;&#26465;&#20214;&#19968;&#38454;&#30697;&#26041;&#27861;&#19982;&#24050;&#30693;&#30340;&#29699;&#24418;&#24863;&#30693;&#26426;&#32467;&#26524;&#30456;&#32467;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Determining the capacity $\alpha_c$ of the Binary Perceptron is a long-standing problem. Krauth and Mezard (1989) conjectured an explicit value of $\alpha_c$, approximately equal to .833, and a rigorous lower bound matching this prediction was recently established by Ding and Sun (2019). Regarding the upper bound, Kim and Roche (1998) and Talagrand (1999) independently showed that $\alpha_c$ &lt; .996, while Krauth and Mezard outlined an argument which can be used to show that $\alpha_c$ &lt; .847. The purpose of this expository note is to record a complete proof of the bound $\alpha_c$ &lt; .847. The proof is a conditional first moment method combined with known results on the spherical perceptron
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24471;&#20998;&#32467;&#26500;&#20808;&#39564;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#37096;&#20998;&#24050;&#30693;&#39640;&#26031;&#22270;&#27169;&#22411;&#12290;&#36890;&#36807;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#26469;&#20272;&#35745;&#22270;&#30340;&#24471;&#20998;&#20989;&#25968;&#65292;&#25105;&#20204;&#21487;&#20197;&#22312;&#29983;&#25104;&#26679;&#26412;&#26102;&#21033;&#29992;&#36864;&#28779;&#26391;&#26684;&#32500;&#33021;&#25193;&#25955;&#65292;&#20174;&#32780;&#26356;&#20934;&#30830;&#22320;&#20272;&#35745;&#21518;&#39564;&#20998;&#24067;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#26126;&#26174;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2401.14340</link><description>&lt;p&gt;
&#22522;&#20110;&#24471;&#20998;&#32467;&#26500;&#20808;&#39564;&#30340;&#37096;&#20998;&#24050;&#30693;&#39640;&#26031;&#22270;&#27169;&#22411;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Estimation of partially known Gaussian graphical models with score-based structural priors. (arXiv:2401.14340v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14340
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24471;&#20998;&#32467;&#26500;&#20808;&#39564;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#37096;&#20998;&#24050;&#30693;&#39640;&#26031;&#22270;&#27169;&#22411;&#12290;&#36890;&#36807;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#26469;&#20272;&#35745;&#22270;&#30340;&#24471;&#20998;&#20989;&#25968;&#65292;&#25105;&#20204;&#21487;&#20197;&#22312;&#29983;&#25104;&#26679;&#26412;&#26102;&#21033;&#29992;&#36864;&#28779;&#26391;&#26684;&#32500;&#33021;&#25193;&#25955;&#65292;&#20174;&#32780;&#26356;&#20934;&#30830;&#22320;&#20272;&#35745;&#21518;&#39564;&#20998;&#24067;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#26126;&#26174;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#25903;&#25345;&#20272;&#35745;&#37096;&#20998;&#24050;&#30693;&#30340;&#39640;&#26031;&#22270;&#27169;&#22411;&#65292;&#24182;&#19988;&#32467;&#21512;&#20102;&#20851;&#20110;&#24213;&#23618;&#22270;&#30340;&#20808;&#39564;&#20449;&#24687;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#27604;&#65292;&#20256;&#32479;&#26041;&#27861;&#20351;&#29992;&#28857;&#20272;&#35745;&#26041;&#27861;&#22522;&#20110;&#26368;&#22823;&#20284;&#28982;&#25110;&#26368;&#22823;&#21518;&#39564;&#20934;&#21017;&#65292;&#24182;&#20351;&#29992;&#65288;&#31616;&#21333;&#30340;&#65289;&#31934;&#24230;&#30697;&#38453;&#20808;&#39564;&#26469;&#25552;&#20379;&#28857;&#20272;&#35745;&#12290;&#25105;&#20204;&#32771;&#34385;&#23545;&#22270;&#36827;&#34892;&#20808;&#39564;&#65292;&#24182;&#20381;&#36182;&#36864;&#28779;&#26391;&#26684;&#32500;&#33021;&#25193;&#25955;&#20174;&#21518;&#39564;&#20998;&#24067;&#20013;&#29983;&#25104;&#26679;&#26412;&#12290;&#30001;&#20110;&#26391;&#26684;&#32500;&#33021;&#37319;&#26679;&#22120;&#38656;&#35201;&#35775;&#38382;&#24213;&#23618;&#22270;&#20808;&#39564;&#30340;&#24471;&#20998;&#20989;&#25968;&#65292;&#22240;&#27492;&#25105;&#20204;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#26469;&#26377;&#25928;&#22320;&#20174;&#22270;&#25968;&#25454;&#38598;&#65288;&#20107;&#20808;&#21487;&#29992;&#25110;&#20174;&#24050;&#30693;&#20998;&#24067;&#29983;&#25104;&#65289;&#20272;&#35745;&#24471;&#20998;&#12290;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel algorithm for the support estimation of partially known Gaussian graphical models that incorporates prior information about the underlying graph. In contrast to classical approaches that provide a point estimate based on a maximum likelihood or a maximum a posteriori criterion using (simple) priors on the precision matrix, we consider a prior on the graph and rely on annealed Langevin diffusion to generate samples from the posterior distribution. Since the Langevin sampler requires access to the score function of the underlying graph prior, we use graph neural networks to effectively estimate the score from a graph dataset (either available beforehand or generated from a known distribution). Numerical experiments demonstrate the benefits of our approach.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#26368;&#20248;&#20256;&#36755;&#36827;&#34892;&#20998;&#24067;&#24335;&#23545;&#25239;&#35299;&#37322;&#30340;&#26041;&#27861;DISCOUNT&#65292;&#23558;&#23545;&#25239;&#35299;&#37322;&#30340;&#27010;&#24565;&#25193;&#23637;&#21040;&#25972;&#20010;&#36755;&#20837;&#36755;&#20986;&#20998;&#24067;&#65292;&#24182;&#36890;&#36807;&#32479;&#35745;&#32622;&#20449;&#24230;&#26469;&#25903;&#25745;&#36825;&#19968;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.13112</link><description>&lt;p&gt;
DISCOUNT: &#20351;&#29992;&#26368;&#20248;&#20256;&#36755;&#36827;&#34892;&#20998;&#24067;&#24335;&#23545;&#25239;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
DISCOUNT: Distributional Counterfactual Explanation With Optimal Transport. (arXiv:2401.13112v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13112
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#26368;&#20248;&#20256;&#36755;&#36827;&#34892;&#20998;&#24067;&#24335;&#23545;&#25239;&#35299;&#37322;&#30340;&#26041;&#27861;DISCOUNT&#65292;&#23558;&#23545;&#25239;&#35299;&#37322;&#30340;&#27010;&#24565;&#25193;&#23637;&#21040;&#25972;&#20010;&#36755;&#20837;&#36755;&#20986;&#20998;&#24067;&#65292;&#24182;&#36890;&#36807;&#32479;&#35745;&#32622;&#20449;&#24230;&#26469;&#25903;&#25745;&#36825;&#19968;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#35299;&#37322;&#26159;&#22312;&#40657;&#30418;&#20915;&#31574;&#27169;&#22411;&#20013;&#25552;&#20379;&#27934;&#23519;&#21147;&#21644;&#21487;&#35299;&#37322;&#24615;&#30340;&#20107;&#23454;&#26041;&#27861;&#65292;&#36890;&#36807;&#30830;&#23450;&#23548;&#33268;&#19981;&#21516;&#32467;&#26524;&#30340;&#26367;&#20195;&#36755;&#20837;&#23454;&#20363;&#26469;&#23454;&#29616;&#12290;&#26412;&#25991;&#23558;&#23545;&#25239;&#35299;&#37322;&#30340;&#27010;&#24565;&#25193;&#23637;&#21040;&#20998;&#24067;&#19978;&#19979;&#25991;&#65292;&#20174;&#20010;&#20307;&#25968;&#25454;&#28857;&#25193;&#22823;&#21040;&#25972;&#20010;&#36755;&#20837;&#36755;&#20986;&#20998;&#24067;&#65292;&#21629;&#21517;&#20026;&#20998;&#24067;&#24335;&#23545;&#25239;&#35299;&#37322;&#12290;&#22312;&#20998;&#24067;&#24335;&#23545;&#25239;&#35299;&#37322;&#20013;&#65292;&#25105;&#20204;&#30340;&#37325;&#28857;&#36716;&#21521;&#20998;&#26512;&#20107;&#23454;&#21644;&#23545;&#25239;&#30340;&#20998;&#24067;&#23646;&#24615;&#65292;&#31867;&#20284;&#20110;&#35780;&#20272;&#20010;&#20307;&#23454;&#20363;&#21450;&#20854;&#32467;&#26524;&#20915;&#31574;&#30340;&#32463;&#20856;&#26041;&#27861;&#12290;&#25105;&#20204;&#21033;&#29992;&#26368;&#20248;&#20256;&#36755;&#26469;&#26500;&#24314;&#19968;&#20010;&#26426;&#20250;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#65292;&#26088;&#22312;&#23548;&#20986;&#19982;&#20107;&#23454;&#23545;&#24212;&#30340;&#23545;&#25239;&#20998;&#24067;&#65292;&#20197;&#32479;&#35745;&#32622;&#20449;&#24230;&#20570;&#25903;&#25745;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#20248;&#21270;&#26041;&#27861;DISCOUNT&#22312;&#36755;&#20837;&#21644;&#36755;&#20986;&#20998;&#24067;&#20043;&#38388;&#24179;&#34913;&#36825;&#31181;&#32622;&#20449;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Counterfactual Explanations (CE) is the de facto method for providing insight and interpretability in black-box decision-making models by identifying alternative input instances that lead to different outcomes. This paper extends the concept of CEs to a distributional context, broadening the scope from individual data points to entire input and output distributions, named Distributional Counterfactual Explanation (DCE). In DCE, our focus shifts to analyzing the distributional properties of the factual and counterfactual, drawing parallels to the classical approach of assessing individual instances and their resulting decisions. We leverage Optimal Transport (OT) to frame a chance-constrained optimization problem, aiming to derive a counterfactual distribution that closely aligns with its factual counterpart, substantiated by statistical confidence. Our proposed optimization method, DISCOUNT, strategically balances this confidence across both input and output distributions. This algorit
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#26576;&#20123;&#38590;&#20197;&#27169;&#25311;&#24213;&#23618;&#29366;&#24577;&#21464;&#37327;&#30340;&#38543;&#26426;&#26368;&#20248;&#25511;&#21046;&#38382;&#39064;&#65292;&#24341;&#20837;&#20102;&#20351;&#29992;&#22810;&#20219;&#21153;&#31070;&#32463;&#32593;&#32476;&#30340;&#26377;&#25928;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.12923</link><description>&lt;p&gt;
&#29992;&#20110;&#35299;&#20915;&#19968;&#20123;&#38543;&#26426;&#26368;&#20248;&#25511;&#21046;&#38382;&#39064;&#30340;&#28145;&#24230;&#22810;&#20219;&#21153;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Deep multitask neural networks for solving some stochastic optimal control problems. (arXiv:2401.12923v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12923
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#26576;&#20123;&#38590;&#20197;&#27169;&#25311;&#24213;&#23618;&#29366;&#24577;&#21464;&#37327;&#30340;&#38543;&#26426;&#26368;&#20248;&#25511;&#21046;&#38382;&#39064;&#65292;&#24341;&#20837;&#20102;&#20351;&#29992;&#22810;&#20219;&#21153;&#31070;&#32463;&#32593;&#32476;&#30340;&#26377;&#25928;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#29992;&#20110;&#20351;&#29992;&#30456;&#20851;&#30340;&#21453;&#21521;&#21160;&#24577;&#35268;&#21010;&#21407;&#29702;&#35299;&#20915;&#38543;&#26426;&#26368;&#20248;&#25511;&#21046;&#38382;&#39064;&#65292;&#36825;&#20123;&#26041;&#27861;&#20381;&#36182;&#20110;&#27169;&#25311;&#24213;&#23618;&#29366;&#24577;&#21464;&#37327;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#22312;&#26576;&#20123;&#38382;&#39064;&#20013;&#65292;&#36825;&#31181;&#27169;&#25311;&#26159;&#19981;&#21487;&#34892;&#30340;&#65292;&#23548;&#33268;&#29366;&#24577;&#21464;&#37327;&#31354;&#38388;&#30340;&#31163;&#25955;&#21270;&#21644;&#38656;&#35201;&#20026;&#27599;&#20010;&#25968;&#25454;&#28857;&#35757;&#32451;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#12290;&#24403;&#22788;&#29702;&#22823;&#30340;&#29366;&#24577;&#21464;&#37327;&#31354;&#38388;&#26102;&#65292;&#36825;&#31181;&#26041;&#27861;&#22312;&#35745;&#31639;&#19978;&#21464;&#24471;&#20302;&#25928;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#31867;&#36825;&#31181;&#31867;&#22411;&#30340;&#38543;&#26426;&#26368;&#20248;&#25511;&#21046;&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#20351;&#29992;&#22810;&#20219;&#21153;&#31070;&#32463;&#32593;&#32476;&#30340;&#26377;&#25928;&#35299;&#20915;&#26041;&#26696;&#12290;&#20026;&#20102;&#35757;&#32451;&#25105;&#20204;&#30340;&#22810;&#20219;&#21153;&#31070;&#32463;&#32593;&#32476;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#26696;&#65292;&#22312;&#20219;&#21153;&#20043;&#38388;&#21160;&#24577;&#24179;&#34913;&#23398;&#20064;&#12290;&#36890;&#36807;&#23545;&#30495;&#23454;&#19990;&#30028;&#30340;&#34893;&#29983;&#21697;&#23450;&#20215;&#38382;&#39064;&#36827;&#34892;&#25968;&#20540;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most existing neural network-based approaches for solving stochastic optimal control problems using the associated backward dynamic programming principle rely on the ability to simulate the underlying state variables. However, in some problems, this simulation is infeasible, leading to the discretization of state variable space and the need to train one neural network for each data point. This approach becomes computationally inefficient when dealing with large state variable spaces. In this paper, we consider a class of this type of stochastic optimal control problems and introduce an effective solution employing multitask neural networks. To train our multitask neural network, we introduce a novel scheme that dynamically balances the learning across tasks. Through numerical experiments on real-world derivatives pricing problems, we prove that our method outperforms state-of-the-art approaches.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#21453;&#20363;&#35777;&#26126;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#21363;&#20351;&#35780;&#20998;&#20989;&#25968;&#23398;&#20064;&#33391;&#22909;&#65292;&#22522;&#20110;&#35780;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#65288;SGMs&#65289;&#20173;&#28982;&#26080;&#27861;&#29983;&#25104;&#25509;&#36817;&#30495;&#23454;&#25968;&#25454;&#20998;&#24067;&#30340;&#26679;&#26412;&#65292;&#24182;&#19988;&#21482;&#33021;&#20135;&#29983;&#35757;&#32451;&#25968;&#25454;&#28857;&#30340;&#39640;&#26031;&#27169;&#31946;&#26679;&#26412;&#12290;</title><link>http://arxiv.org/abs/2401.04856</link><description>&lt;p&gt;
&#19968;&#20010;&#22909;&#30340;&#35780;&#20998;&#24182;&#19981;&#20250;&#23548;&#33268;&#19968;&#20010;&#22909;&#30340;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Good Score Does not Lead to A Good Generative Model. (arXiv:2401.04856v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04856
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#21453;&#20363;&#35777;&#26126;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#21363;&#20351;&#35780;&#20998;&#20989;&#25968;&#23398;&#20064;&#33391;&#22909;&#65292;&#22522;&#20110;&#35780;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#65288;SGMs&#65289;&#20173;&#28982;&#26080;&#27861;&#29983;&#25104;&#25509;&#36817;&#30495;&#23454;&#25968;&#25454;&#20998;&#24067;&#30340;&#26679;&#26412;&#65292;&#24182;&#19988;&#21482;&#33021;&#20135;&#29983;&#35757;&#32451;&#25968;&#25454;&#28857;&#30340;&#39640;&#26031;&#27169;&#31946;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#35780;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#65288;SGMs&#65289;&#26159;&#29983;&#25104;&#24314;&#27169;&#20013;&#30340;&#19968;&#31181;&#20027;&#35201;&#26041;&#27861;&#65292;&#20197;&#20854;&#33021;&#22815;&#20174;&#22797;&#26434;&#30340;&#39640;&#32500;&#25968;&#25454;&#20998;&#24067;&#20013;&#29983;&#25104;&#39640;&#36136;&#37327;&#26679;&#26412;&#32780;&#38395;&#21517;&#12290;&#35813;&#26041;&#27861;&#22312;&#32463;&#39564;&#19978;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#24182;&#19988;&#26377;&#30528;&#20005;&#26684;&#30340;&#29702;&#35770;&#25910;&#25947;&#24615;&#36136;&#30340;&#25903;&#25345;&#12290;&#29305;&#21035;&#26159;&#24050;&#32463;&#35777;&#26126;&#65292;&#22914;&#26524;&#23398;&#20064;&#21040;&#30340;&#24213;&#23618;&#35780;&#20998;&#20989;&#25968;&#33391;&#22909;&#65292;SGMs&#33021;&#22815;&#29983;&#25104;&#25509;&#36817;&#30495;&#23454;&#25968;&#25454;&#20998;&#24067;&#30340;&#26679;&#26412;&#65292;&#36825;&#34920;&#26126;&#20102;SGM&#20316;&#20026;&#29983;&#25104;&#27169;&#22411;&#30340;&#25104;&#21151;&#20043;&#22788;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#21453;&#20363;&#12290;&#36890;&#36807;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#20998;&#26512;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#29305;&#23450;&#30340;&#35774;&#32622;&#65292;&#20854;&#20013;&#35780;&#20998;&#20989;&#25968;&#23398;&#20064;&#24471;&#24456;&#22909;&#12290;&#28982;&#32780;&#65292;&#22312;&#36825;&#20010;&#35774;&#32622;&#20013;&#65292;SGMs&#21482;&#33021;&#36755;&#20986;&#35757;&#32451;&#25968;&#25454;&#28857;&#30340;&#39640;&#26031;&#27169;&#31946;&#26679;&#26412;&#65292;&#27169;&#25311;&#26680;&#23494;&#24230;&#20272;&#35745;&#30340;&#25928;&#26524;&#12290;&#36825;&#19968;&#21457;&#29616;&#19982;&#26368;&#36817;&#30340;&#19968;&#31995;&#21015;&#21457;&#29616;&#30456;&#19968;&#33268;&#65292;&#25581;&#31034;&#20102;SGMs&#21487;&#33021;&#34920;&#29616;&#20986;&#24378;&#22823;&#30340;&#35760;&#24518;&#25928;&#24212;&#24182;&#19988;&#26080;&#27861;&#29983;&#25104;&#26679;&#26412;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Score-based Generative Models (SGMs) is one leading method in generative modeling, renowned for their ability to generate high-quality samples from complex, high-dimensional data distributions. The method enjoys empirical success and is supported by rigorous theoretical convergence properties. In particular, it has been shown that SGMs can generate samples from a distribution that is close to the ground-truth if the underlying score function is learned well, suggesting the success of SGM as a generative model. We provide a counter-example in this paper. Through the sample complexity argument, we provide one specific setting where the score function is learned well. Yet, SGMs in this setting can only output samples that are Gaussian blurring of training data points, mimicking the effects of kernel density estimation. The finding resonates a series of recent finding that reveal that SGMs can demonstrate strong memorization effect and fail to generate.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;KL&#32422;&#26463;&#19979;&#30340;&#21453;&#39304;&#24378;&#21270;&#23398;&#20064;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#26377;&#25928;&#30340;&#31639;&#27861;&#21644;&#23454;&#36341;&#12290;&#23454;&#35777;&#35780;&#20272;&#34920;&#26126;&#65292;&#35813;&#26694;&#26550;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23545;&#40784;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2312.11456</link><description>&lt;p&gt;
&#20154;&#31867;&#21453;&#39304;&#30340;&#36845;&#20195;&#20559;&#22909;&#23398;&#20064;&#65306;&#22312;KL&#32422;&#26463;&#19979;&#23558;&#29702;&#35770;&#19982;&#23454;&#36341;&#32852;&#31995;&#36215;&#26469;&#30340;RLHF
&lt;/p&gt;
&lt;p&gt;
Iterative Preference Learning from Human Feedback: Bridging Theory and Practice for RLHF under KL-Constraint. (arXiv:2312.11456v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.11456
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;KL&#32422;&#26463;&#19979;&#30340;&#21453;&#39304;&#24378;&#21270;&#23398;&#20064;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#26377;&#25928;&#30340;&#31639;&#27861;&#21644;&#23454;&#36341;&#12290;&#23454;&#35777;&#35780;&#20272;&#34920;&#26126;&#65292;&#35813;&#26694;&#26550;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23545;&#40784;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#29983;&#25104;&#27169;&#22411;&#19982;&#24378;&#21270;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#30340;&#23545;&#40784;&#36807;&#31243;&#30340;&#29702;&#35770;&#26694;&#26550;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#26631;&#20934;&#30340;&#25968;&#23398;&#34920;&#36798;&#24335;&#65292;&#21363;&#21453;&#21521;KL&#27491;&#21017;&#21270;&#30340;&#19978;&#19979;&#25991;&#22810;&#33218;&#36172;&#21338;&#26426;&#29992;&#20110;RLHF&#12290;&#23613;&#31649;&#23427;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#23454;&#38469;&#24212;&#29992;&#65292;&#20294;&#23545;&#36825;&#20010;&#20844;&#24335;&#30340;&#20005;&#26684;&#29702;&#35770;&#20998;&#26512;&#20173;&#28982;&#24456;&#24320;&#25918;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#23427;&#22312;&#31163;&#32447;&#12289;&#22312;&#32447;&#21644;&#28151;&#21512;&#19977;&#31181;&#19981;&#21516;&#22330;&#26223;&#19979;&#30340;&#34892;&#20026;&#65292;&#24182;&#25552;&#20986;&#20102;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#29702;&#35770;&#20445;&#35777;&#30340;&#39640;&#25928;&#31639;&#27861;&#12290;&#26397;&#30528;&#23454;&#38469;&#24212;&#29992;&#30340;&#26041;&#21521;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#36890;&#36807;&#23545;&#20449;&#24687;&#29702;&#35770;&#31574;&#30053;&#25913;&#36827;&#39044;&#35328;&#30340;&#31283;&#20581;&#36817;&#20284;&#65292;&#33258;&#28982;&#22320;&#20135;&#29983;&#20102;&#20960;&#31181;&#26032;&#39062;&#30340;RLHF&#31639;&#27861;&#12290;&#36825;&#21253;&#25324;&#22312;&#32447;&#22330;&#26223;&#20013;&#30340;&#36845;&#20195;&#29256;&#26412;&#30340;&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;(DPO)&#31639;&#27861;&#65292;&#20197;&#21450;&#31163;&#32447;&#24773;&#26223;&#19979;&#30340;&#22810;&#27493;&#25298;&#32477;&#25277;&#26679;&#31574;&#30053;&#12290;&#25105;&#20204;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#30495;&#23454;&#23545;&#40784;&#23454;&#39564;&#36827;&#34892;&#20102;&#23454;&#35777;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the theoretical framework of the alignment process of generative models with Reinforcement Learning from Human Feedback (RLHF). We consider a standard mathematical formulation, the reverse-KL regularized contextual bandit for RLHF. Despite its widespread practical application, a rigorous theoretical analysis of this formulation remains open. We investigate its behavior in three distinct settings -- offline, online, and hybrid -- and propose efficient algorithms with finite-sample theoretical guarantees.  Moving towards practical applications, our framework, with a robust approximation of the information-theoretical policy improvement oracle, naturally gives rise to several novel RLHF algorithms. This includes an iterative version of the Direct Preference Optimization (DPO) algorithm for online settings, and a multi-step rejection sampling strategy for offline scenarios. Our empirical evaluations on real-world alignment experiment of large language model demonstrate t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35299;&#20915;&#20102;&#22810;&#20998;&#24067;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#38382;&#39064;&#65292;&#24182;&#32473;&#20986;&#20102;&#21305;&#37197;&#19979;&#30028;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2312.04027</link><description>&lt;p&gt;
&#22810;&#20998;&#24067;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;
&lt;/p&gt;
&lt;p&gt;
The sample complexity of multi-distribution learning. (arXiv:2312.04027v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.04027
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#22810;&#20998;&#24067;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#38382;&#39064;&#65292;&#24182;&#32473;&#20986;&#20102;&#21305;&#37197;&#19979;&#30028;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20998;&#24067;&#23398;&#20064;&#23558;&#32463;&#20856;&#30340;PAC&#23398;&#20064;&#25512;&#24191;&#21040;&#22788;&#29702;&#26469;&#33258;&#22810;&#20010;&#20998;&#24067;&#30340;&#25968;&#25454;&#12290;&#32473;&#23450;&#19968;&#32452;$k$&#20010;&#25968;&#25454;&#20998;&#24067;&#21644;&#19968;&#20010;VC&#32500;&#24230;&#20026;$d$&#30340;&#20551;&#35774;&#31867;&#65292;&#30446;&#26631;&#26159;&#23398;&#20064;&#19968;&#20010;&#20551;&#35774;&#65292;&#20351;&#24471;&#22312;$k$&#20010;&#20998;&#24067;&#19978;&#30340;&#26368;&#22823;&#24635;&#20307;&#25439;&#22833;&#26368;&#23567;&#65292;&#35823;&#24046;&#19981;&#36229;&#36807;$\epsilon$&#12290;&#26412;&#25991;&#36890;&#36807;&#32473;&#20986;&#19968;&#20010;&#26679;&#26412;&#22797;&#26434;&#24230;&#31639;&#27861;$\widetilde{O}((d+k)\epsilon^{-2}) \cdot (k/\epsilon)^{o(1)}$&#26469;&#35299;&#20915;&#22810;&#20998;&#24067;&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#38382;&#39064;&#12290;&#36825;&#20010;&#32467;&#26524;&#19982;&#19979;&#30028;&#30456;&#21305;&#37197;&#65292;&#35299;&#20915;&#20102;Awasthi&#12289;Haghtalab&#21644;Zhao&#22312;COLT 2023&#20013;&#25552;&#20986;&#30340;&#24320;&#25918;&#38382;&#39064; [AHZ23]&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-distribution learning generalizes the classic PAC learning to handle data coming from multiple distributions. Given a set of $k$ data distributions and a hypothesis class of VC dimension $d$, the goal is to learn a hypothesis that minimizes the maximum population loss over $k$ distributions, up to $\epsilon$ additive error. In this paper, we settle the sample complexity of multi-distribution learning by giving an algorithm of sample complexity $\widetilde{O}((d+k)\epsilon^{-2}) \cdot (k/\epsilon)^{o(1)}$. This matches the lower bound up to sub-polynomial factor and resolves the COLT 2023 open problem of Awasthi, Haghtalab and Zhao [AHZ23].
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#22312;&#22635;&#20805;&#32570;&#22833;&#25968;&#25454;&#26102;&#23558;&#26631;&#31614;&#19982;&#36755;&#20837;&#22534;&#21472;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#22635;&#20805;&#25928;&#26524;&#65292;&#24182;&#21516;&#26102;&#22635;&#20805;&#26631;&#31614;&#21644;&#36755;&#20837;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#21508;&#31181;&#31867;&#22411;&#30340;&#25968;&#25454;&#65292;&#19988;&#22312;&#23454;&#39564;&#35777;&#26126;&#20855;&#26377;&#26377;&#24076;&#26395;&#30340;&#20934;&#30830;&#24615;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2311.16877</link><description>&lt;p&gt;
&#20351;&#29992;&#35757;&#32451;&#26631;&#31614;&#36827;&#34892;&#22635;&#20805;&#21644;&#36890;&#36807;&#26631;&#31614;&#22635;&#20805;&#36827;&#34892;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Imputation using training labels and classification via label imputation. (arXiv:2311.16877v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.16877
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#22312;&#22635;&#20805;&#32570;&#22833;&#25968;&#25454;&#26102;&#23558;&#26631;&#31614;&#19982;&#36755;&#20837;&#22534;&#21472;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#22635;&#20805;&#25928;&#26524;&#65292;&#24182;&#21516;&#26102;&#22635;&#20805;&#26631;&#31614;&#21644;&#36755;&#20837;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#21508;&#31181;&#31867;&#22411;&#30340;&#25968;&#25454;&#65292;&#19988;&#22312;&#23454;&#39564;&#35777;&#26126;&#20855;&#26377;&#26377;&#24076;&#26395;&#30340;&#20934;&#30830;&#24615;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#32570;&#22833;&#25968;&#25454;&#26159;&#19968;&#20010;&#24120;&#35265;&#30340;&#38382;&#39064;&#12290;&#24050;&#32463;&#24320;&#21457;&#20102;&#21508;&#31181;&#22635;&#20805;&#26041;&#27861;&#26469;&#22788;&#29702;&#32570;&#22833;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#35757;&#32451;&#25968;&#25454;&#36890;&#24120;&#37117;&#26377;&#26631;&#31614;&#65292;&#20294;&#24120;&#35265;&#30340;&#22635;&#20805;&#26041;&#27861;&#36890;&#24120;&#21482;&#20381;&#36182;&#20110;&#36755;&#20837;&#32780;&#24573;&#30053;&#26631;&#31614;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#38416;&#36848;&#20102;&#23558;&#26631;&#31614;&#22534;&#21472;&#21040;&#36755;&#20837;&#20013;&#21487;&#20197;&#26174;&#30528;&#25552;&#39640;&#36755;&#20837;&#30340;&#22635;&#20805;&#25928;&#26524;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#31867;&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#23558;&#39044;&#27979;&#30340;&#27979;&#35797;&#26631;&#31614;&#21021;&#22987;&#21270;&#20026;&#32570;&#22833;&#20540;&#65292;&#24182;&#23558;&#26631;&#31614;&#19982;&#36755;&#20837;&#22534;&#21472;&#22312;&#19968;&#36215;&#36827;&#34892;&#22635;&#20805;&#12290;&#36825;&#26679;&#21487;&#20197;&#21516;&#26102;&#22635;&#20805;&#26631;&#31614;&#21644;&#36755;&#20837;&#12290;&#32780;&#19988;&#65292;&#35813;&#25216;&#26415;&#33021;&#22815;&#22788;&#29702;&#20855;&#26377;&#32570;&#22833;&#26631;&#31614;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#26080;&#38656;&#20219;&#20309;&#20808;&#21069;&#30340;&#22635;&#20805;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#36830;&#32493;&#22411;&#12289;&#20998;&#31867;&#22411;&#25110;&#28151;&#21512;&#22411;&#25968;&#25454;&#12290;&#23454;&#39564;&#35777;&#26126;&#22312;&#20934;&#30830;&#24615;&#26041;&#38754;&#21462;&#24471;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Missing data is a common problem in practical settings. Various imputation methods have been developed to deal with missing data. However, even though the label is usually available in the training data, the common practice of imputation usually only relies on the input and ignores the label. In this work, we illustrate how stacking the label into the input can significantly improve the imputation of the input. In addition, we propose a classification strategy that initializes the predicted test label with missing values and stacks the label with the input for imputation. This allows imputing the label and the input at the same time. Also, the technique is capable of handling data training with missing labels without any prior imputation and is applicable to continuous, categorical, or mixed-type data. Experiments show promising results in terms of accuracy.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30340;&#26102;&#38388;&#24207;&#21015;&#26041;&#27861;&#65292;&#21033;&#29992;&#28508;&#22312;&#26102;&#38388;&#36807;&#31243;&#26469;&#27169;&#25311;&#22797;&#26434;&#30142;&#30149;&#36712;&#36857;&#12290;&#36890;&#36807;&#32467;&#21512;&#21307;&#23398;&#30693;&#35782;&#21644;&#21322;&#30417;&#30563;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#35299;&#37322;&#21644;&#20840;&#38754;&#20998;&#26512;&#30142;&#30149;&#36712;&#36857;&#65292;&#24182;&#29992;&#20110;&#36827;&#19968;&#27493;&#30340;&#25968;&#25454;&#20998;&#26512;&#21644;&#20020;&#24202;&#20551;&#35774;&#27979;&#35797;&#12290;</title><link>http://arxiv.org/abs/2311.08149</link><description>&lt;p&gt;
&#20351;&#29992;&#21547;&#26377;&#21322;&#30417;&#30563;&#28508;&#22312;&#36807;&#31243;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#24314;&#27169;&#22797;&#26434;&#30142;&#30149;&#36712;&#36857;
&lt;/p&gt;
&lt;p&gt;
Modeling Complex Disease Trajectories using Deep Generative Models with Semi-Supervised Latent Processes. (arXiv:2311.08149v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.08149
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30340;&#26102;&#38388;&#24207;&#21015;&#26041;&#27861;&#65292;&#21033;&#29992;&#28508;&#22312;&#26102;&#38388;&#36807;&#31243;&#26469;&#27169;&#25311;&#22797;&#26434;&#30142;&#30149;&#36712;&#36857;&#12290;&#36890;&#36807;&#32467;&#21512;&#21307;&#23398;&#30693;&#35782;&#21644;&#21322;&#30417;&#30563;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#35299;&#37322;&#21644;&#20840;&#38754;&#20998;&#26512;&#30142;&#30149;&#36712;&#36857;&#65292;&#24182;&#29992;&#20110;&#36827;&#19968;&#27493;&#30340;&#25968;&#25454;&#20998;&#26512;&#21644;&#20020;&#24202;&#20551;&#35774;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#28508;&#22312;&#26102;&#38388;&#36807;&#31243;&#30340;&#28145;&#24230;&#29983;&#25104;&#26102;&#38388;&#24207;&#21015;&#26041;&#27861;&#65292;&#29992;&#20110;&#27169;&#25311;&#21644;&#20840;&#38754;&#20998;&#26512;&#22797;&#26434;&#30142;&#30149;&#36712;&#36857;&#12290;&#25105;&#20204;&#26088;&#22312;&#25214;&#21040;&#33021;&#22815;&#35299;&#37322;&#35266;&#23519;&#21040;&#30340;&#30142;&#30149;&#36712;&#36857;&#30340;&#26377;&#24847;&#20041;&#30340;&#26102;&#38388;&#28508;&#22312;&#34920;&#31034;&#65292;&#24182;&#20197;&#19968;&#31181;&#21487;&#35299;&#37322;&#21644;&#20840;&#38754;&#30340;&#26041;&#24335;&#36827;&#34892;&#20998;&#26512;&#12290;&#20026;&#20102;&#25552;&#39640;&#36825;&#20123;&#26102;&#38388;&#28508;&#22312;&#36807;&#31243;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#21322;&#30417;&#30563;&#26041;&#27861;&#65292;&#21033;&#29992;&#24050;&#24314;&#31435;&#30340;&#21307;&#23398;&#27010;&#24565;&#23545;&#28508;&#22312;&#31354;&#38388;&#36827;&#34892;&#35299;&#32544;&#12290;&#36890;&#36807;&#23558;&#29983;&#25104;&#26041;&#27861;&#19982;&#21307;&#23398;&#30693;&#35782;&#30456;&#32467;&#21512;&#65292;&#25105;&#20204;&#21033;&#29992;&#20102;&#21457;&#29616;&#30142;&#30149;&#26032;&#26041;&#38754;&#30340;&#33021;&#21147;&#65292;&#21516;&#26102;&#23558;&#21307;&#23398;&#27010;&#24565;&#25972;&#21512;&#21040;&#27169;&#22411;&#20013;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#23398;&#24471;&#30340;&#26102;&#38388;&#28508;&#22312;&#36807;&#31243;&#21487;&#20197;&#29992;&#20110;&#36827;&#19968;&#27493;&#30340;&#25968;&#25454;&#20998;&#26512;&#21644;&#20020;&#24202;&#20551;&#35774;&#27979;&#35797;&#65292;&#21253;&#25324;&#26597;&#25214;&#30456;&#20284;&#24739;&#32773;&#21644;&#23558;&#30142;&#30149;&#32858;&#31867;&#20026;&#26032;&#30340;&#20122;&#22411;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36824;&#21487;&#20197;&#23454;&#29616;&#20010;&#24615;&#21270;&#30340;&#22312;&#32447;&#30417;&#27979;&#21644;&#39044;&#27979;&#22810;&#21464;&#37327;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a deep generative time series approach using latent temporal processes for modeling and holistically analyzing complex disease trajectories. We aim to find meaningful temporal latent representations of an underlying generative process that explain the observed disease trajectories in an interpretable and comprehensive way. To enhance the interpretability of these latent temporal processes, we develop a semi-supervised approach for disentangling the latent space using established medical concepts. By combining the generative approach with medical knowledge, we leverage the ability to discover novel aspects of the disease while integrating medical concepts into the model. We show that the learned temporal latent processes can be utilized for further data analysis and clinical hypothesis testing, including finding similar patients and clustering the disease into new sub-types. Moreover, our method enables personalized online monitoring and prediction of multivari
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#22312;&#36827;&#21270;&#31639;&#27861;&#25191;&#34892;&#20013;&#36873;&#25321;&#36866;&#24403;&#30340;&#36817;&#20284;&#20989;&#25968;&#25104;&#26412;&#30340;&#25216;&#26415;&#65292;&#29992;&#20110;&#21152;&#36895;&#35299;&#20915;&#40657;&#30418;&#20248;&#21270;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.13349</link><description>&lt;p&gt;
&#21152;&#36895;&#28436;&#21270;&#31639;&#27861;&#35299;&#20915;&#40657;&#30418;&#20248;&#21270;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Speeding-up Evolutionary Algorithms to solve Black-Box Optimization Problems. (arXiv:2309.13349v1 [cs.NE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.13349
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#22312;&#36827;&#21270;&#31639;&#27861;&#25191;&#34892;&#20013;&#36873;&#25321;&#36866;&#24403;&#30340;&#36817;&#20284;&#20989;&#25968;&#25104;&#26412;&#30340;&#25216;&#26415;&#65292;&#29992;&#20110;&#21152;&#36895;&#35299;&#20915;&#40657;&#30418;&#20248;&#21270;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22788;&#29702;&#35745;&#31639;&#22797;&#26434;&#30340;&#40657;&#30418;&#20248;&#21270;&#38382;&#39064;&#26102;&#65292;&#24120;&#24120;&#20351;&#29992;&#22522;&#20110;&#32676;&#20307;&#30340;&#28436;&#21270;&#31639;&#27861;&#12290;&#23427;&#20204;&#36890;&#36807;&#36873;&#25321;&#26426;&#21046;&#20174;&#32473;&#23450;&#30340;&#32676;&#20307;&#20013;&#36873;&#25321;&#26368;&#20339;&#35299;&#20915;&#26041;&#26696;&#65292;&#27604;&#36739;&#23427;&#20204;&#30340;&#30446;&#26631;&#20540;&#65292;&#28982;&#21518;&#29992;&#36825;&#20123;&#30446;&#26631;&#20540;&#29983;&#25104;&#19979;&#19968;&#20195;&#32676;&#20307;&#12290;&#36825;&#20010;&#36845;&#20195;&#36807;&#31243;&#33021;&#22815;&#39640;&#25928;&#22320;&#25506;&#32034;&#35299;&#31354;&#38388;&#65292;&#36880;&#27493;&#25913;&#21892;&#35299;&#20915;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#31639;&#27861;&#38656;&#35201;&#22823;&#37327;&#30340;&#35780;&#20272;&#25165;&#33021;&#25552;&#20379;&#19968;&#20010;&#20248;&#36136;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#24403;&#35780;&#20272;&#25104;&#26412;&#24456;&#39640;&#26102;&#65292;&#21487;&#33021;&#20250;&#36896;&#25104;&#35745;&#31639;&#19978;&#30340;&#36127;&#25285;&#12290;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#29992;&#25104;&#26412;&#36739;&#20302;&#30340;&#19981;&#22826;&#20934;&#30830;&#30340;&#36817;&#20284;&#20989;&#25968;&#26367;&#25442;&#21407;&#22987;&#30446;&#26631;&#20989;&#25968;&#12290;&#36825;&#23601;&#24341;&#20837;&#20102;&#35780;&#20272;&#25104;&#26412;&#19982;&#20934;&#30830;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#22312;&#20248;&#21270;&#31639;&#27861;&#25191;&#34892;&#36807;&#31243;&#20013;&#36873;&#25321;&#36866;&#24403;&#30340;&#36817;&#20284;&#20989;&#25968;&#25104;&#26412;&#30340;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
Population-based evolutionary algorithms are often considered when approaching computationally expensive black-box optimization problems. They employ a selection mechanism to choose the best solutions from a given population after comparing their objective values, which are then used to generate the next population. This iterative process explores the solution space efficiently, leading to improved solutions over time. However, these algorithms require a large number of evaluations to provide a quality solution, which might be computationally expensive when the evaluation cost is high. In some cases, it is possible to replace the original objective function with a less accurate approximation of lower cost. This introduces a trade-off between the evaluation cost and its accuracy.  In this paper, we propose a technique capable of choosing an appropriate approximate function cost during the execution of the optimization algorithm. The proposal finds the minimum evaluation cost at which th
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#39640;&#33021;&#30005;&#23376;-&#27491;&#30005;&#23376;&#30896;&#25758;&#20013;&#30340;&#31890;&#23376;&#27969;&#37325;&#24314;&#65292;&#20351;&#29992;&#21487;&#25193;&#23637;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;&#36229;&#21442;&#25968;&#35843;&#20248;&#21644;&#30828;&#20214;&#22788;&#29702;&#22120;&#30340;&#39640;&#24230;&#21487;&#31227;&#26893;&#24615;&#65292;&#21462;&#24471;&#20102;&#30495;&#23454;&#19988;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#29289;&#29702;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.06782</link><description>&lt;p&gt;
&#21487;&#25193;&#23637;&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#21644;&#21315;&#20806;&#32423;&#25968;&#25454;&#38598;&#29992;&#20110;&#31890;&#23376;&#27969;&#37325;&#24314;
&lt;/p&gt;
&lt;p&gt;
Scalable neural network models and terascale datasets for particle-flow reconstruction. (arXiv:2309.06782v1 [physics.data-an])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06782
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#39640;&#33021;&#30005;&#23376;-&#27491;&#30005;&#23376;&#30896;&#25758;&#20013;&#30340;&#31890;&#23376;&#27969;&#37325;&#24314;&#65292;&#20351;&#29992;&#21487;&#25193;&#23637;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;&#36229;&#21442;&#25968;&#35843;&#20248;&#21644;&#30828;&#20214;&#22788;&#29702;&#22120;&#30340;&#39640;&#24230;&#21487;&#31227;&#26893;&#24615;&#65292;&#21462;&#24471;&#20102;&#30495;&#23454;&#19988;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#29289;&#29702;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#39640;&#33021;&#30005;&#23376;-&#27491;&#30005;&#23376;&#30896;&#25758;&#20013;&#22522;&#20110;&#39640;&#24230;&#31890;&#24230;&#25506;&#27979;&#22120;&#27169;&#25311;&#30340;&#23436;&#25972;&#20107;&#20214;&#37325;&#24314;&#65292;&#30740;&#31350;&#20102;&#21487;&#25193;&#23637;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#12290;&#31890;&#23376;&#27969;&#65288;PF&#65289;&#37325;&#24314;&#21487;&#36890;&#36807;&#36319;&#36394;&#21644;&#37327;&#33021;&#22120;&#22242;&#31751;&#25110;&#20987;&#20013;&#26469;&#26500;&#24314;&#30417;&#30563;&#23398;&#20064;&#20219;&#21153;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#21644;&#22522;&#20110;&#20869;&#26680;&#30340;&#21464;&#25442;&#22120;&#65292;&#24182;&#35777;&#26126;&#20004;&#32773;&#37117;&#36991;&#20813;&#20102;&#20108;&#27425;&#20869;&#23384;&#20998;&#37197;&#21644;&#35745;&#31639;&#25104;&#26412;&#65292;&#21516;&#26102;&#23454;&#29616;&#20102;&#30495;&#23454;&#30340;&#31890;&#23376;&#27969;&#37325;&#24314;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#36229;&#32423;&#35745;&#31639;&#26426;&#19978;&#36827;&#34892;&#30340;&#36229;&#21442;&#25968;&#35843;&#20248;&#26174;&#33879;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#29289;&#29702;&#24615;&#33021;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#25152;&#24471;&#27169;&#22411;&#22312;&#30828;&#20214;&#22788;&#29702;&#22120;&#19978;&#20855;&#26377;&#39640;&#24230;&#21487;&#31227;&#26893;&#24615;&#65292;&#25903;&#25345;NVIDIA, AMD&#21644;&#33521;&#29305;&#23572; Habana&#21345;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#27169;&#22411;&#21487;&#20197;&#22312;&#30001;&#36319;&#36394;&#21644;&#37327;&#33021;&#22120;&#20987;&#20013;&#32452;&#25104;&#30340;&#39640;&#31890;&#24230;&#36755;&#20837;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#20174;&#32780;&#33719;&#24471;&#19982;&#22522;&#20934;&#30456;&#31454;&#20105;&#30340;&#29289;&#29702;&#24615;&#33021;&#12290;&#26377;&#20851;&#22797;&#29616;&#30740;&#31350;&#30340;&#25968;&#25454;&#38598;&#21644;&#36719;&#20214;&#24050;&#21457;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study scalable machine learning models for full event reconstruction in high-energy electron-positron collisions based on a highly granular detector simulation. Particle-flow (PF) reconstruction can be formulated as a supervised learning task using tracks and calorimeter clusters or hits. We compare a graph neural network and kernel-based transformer and demonstrate that both avoid quadratic memory allocation and computational cost while achieving realistic PF reconstruction. We show that hyperparameter tuning on a supercomputer significantly improves the physics performance of the models. We also demonstrate that the resulting model is highly portable across hardware processors, supporting Nvidia, AMD, and Intel Habana cards. Finally, we demonstrate that the model can be trained on highly granular inputs consisting of tracks and calorimeter hits, resulting in a competitive physics performance with the baseline. Datasets and software to reproduce the studies are published following 
&lt;/p&gt;</description></item><item><title>UTrans&#26159;&#19968;&#31181;&#32479;&#19968;&#36716;&#31227;&#23398;&#20064;&#27169;&#22411;&#65292;&#23427;&#33021;&#26816;&#27979;&#21487;&#36716;&#31227;&#21464;&#37327;&#21644;&#28304;&#25968;&#25454;&#65292;&#24182;&#20855;&#26377;&#36739;&#20302;&#30340;&#20272;&#35745;&#21644;&#39044;&#27979;&#35823;&#24046;&#65292;&#21516;&#26102;&#20445;&#25345;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.00238</link><description>&lt;p&gt;
&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#30340;&#32479;&#19968;&#36716;&#31227;&#23398;&#20064;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Unified Transfer Learning Models for High-Dimensional Linear Regression. (arXiv:2307.00238v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00238
&lt;/p&gt;
&lt;p&gt;
UTrans&#26159;&#19968;&#31181;&#32479;&#19968;&#36716;&#31227;&#23398;&#20064;&#27169;&#22411;&#65292;&#23427;&#33021;&#26816;&#27979;&#21487;&#36716;&#31227;&#21464;&#37327;&#21644;&#28304;&#25968;&#25454;&#65292;&#24182;&#20855;&#26377;&#36739;&#20302;&#30340;&#20272;&#35745;&#21644;&#39044;&#27979;&#35823;&#24046;&#65292;&#21516;&#26102;&#20445;&#25345;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29616;&#20195;&#25968;&#25454;&#20998;&#26512;&#20013;&#65292;&#24403;&#30446;&#26631;&#25968;&#25454;&#31232;&#32570;&#32780;&#28304;&#25968;&#25454;&#20805;&#36275;&#65292;&#25110;&#32773;&#28304;&#25968;&#25454;&#21644;&#30446;&#26631;&#25968;&#25454;&#30340;&#20998;&#24067;&#19981;&#21516;&#30340;&#24773;&#20917;&#19979;&#65292;&#36716;&#31227;&#23398;&#20064;&#22312;&#21457;&#25381;&#37325;&#35201;&#20316;&#29992;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#32479;&#19968;&#36716;&#31227;&#23398;&#20064;&#27169;&#22411;&#65292;&#31216;&#20026;UTrans&#65292;&#35813;&#27169;&#22411;&#33021;&#22815;&#26816;&#27979;&#21487;&#36716;&#31227;&#21464;&#37327;&#21644;&#28304;&#25968;&#25454;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#20272;&#35745;&#35823;&#24046;&#30028;&#38480;&#65292;&#24182;&#35777;&#26126;&#25105;&#20204;&#30340;&#30028;&#38480;&#20302;&#20110;&#20165;&#26377;&#30446;&#26631;&#25968;&#25454;&#30340;&#30028;&#38480;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22522;&#20110;&#20551;&#35774;&#26816;&#39564;&#25552;&#20986;&#20102;&#19968;&#31181;&#28304;&#25968;&#25454;&#26816;&#27979;&#31639;&#27861;&#65292;&#29992;&#20110;&#25490;&#38500;&#19981;&#21487;&#36716;&#31227;&#30340;&#25968;&#25454;&#12290;&#25105;&#20204;&#22312;&#22810;&#20010;&#23454;&#39564;&#20013;&#35780;&#20272;&#21644;&#27604;&#36739;&#20102;UTrans&#19982;&#29616;&#26377;&#31639;&#27861;&#12290;&#32467;&#26524;&#26174;&#31034;&#65292;UTrans&#22312;&#20445;&#25345;&#21487;&#35299;&#37322;&#24615;&#30340;&#21516;&#26102;&#65292;&#27604;&#29616;&#26377;&#26041;&#27861;&#20855;&#26377;&#26356;&#20302;&#30340;&#20272;&#35745;&#21644;&#39044;&#27979;&#35823;&#24046;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#20854;&#24212;&#29992;&#20110;&#32654;&#22269;&#20195;&#38469;&#27969;&#21160;&#25968;&#25454;&#65292;&#24182;&#23558;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#19982;&#32463;&#20856;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transfer learning plays a key role in modern data analysis when: (1) the target data are scarce but the source data are sufficient; (2) the distributions of the source and target data are heterogeneous. This paper develops an interpretable unified transfer learning model, termed as UTrans, which can detect both transferable variables and source data. More specifically, we establish the estimation error bounds and prove that our bounds are lower than those with target data only. Besides, we propose a source detection algorithm based on hypothesis testing to exclude the nontransferable data. We evaluate and compare UTrans to the existing algorithms in multiple experiments. It is shown that UTrans attains much lower estimation and prediction errors than the existing methods, while preserving interpretability. We finally apply it to the US intergenerational mobility data and compare our proposed algorithms to the classical machine learning algorithms.
&lt;/p&gt;</description></item><item><title>AdaStop&#26159;&#19968;&#31181;&#22522;&#20110;&#22810;&#32452;&#24207;&#21015;&#27979;&#35797;&#30340;&#26032;&#32479;&#35745;&#27979;&#35797;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#27604;&#36739;&#22810;&#20010;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#26469;&#35299;&#20915;&#23454;&#39564;&#32467;&#26524;&#21487;&#22797;&#21046;&#24615;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.10882</link><description>&lt;p&gt;
AdaStop&#65306;&#29992;&#20110;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#27604;&#36739;&#30340;&#39640;&#25928;&#21487;&#38752;&#24207;&#21015;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
AdaStop: sequential testing for efficient and reliable comparisons of Deep RL Agents. (arXiv:2306.10882v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10882
&lt;/p&gt;
&lt;p&gt;
AdaStop&#26159;&#19968;&#31181;&#22522;&#20110;&#22810;&#32452;&#24207;&#21015;&#27979;&#35797;&#30340;&#26032;&#32479;&#35745;&#27979;&#35797;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#27604;&#36739;&#22810;&#20010;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#26469;&#35299;&#20915;&#23454;&#39564;&#32467;&#26524;&#21487;&#22797;&#21046;&#24615;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#23454;&#39564;&#32467;&#26524;&#30340;&#21487;&#22797;&#29616;&#24615;&#21463;&#21040;&#36136;&#30097;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#21487;&#22797;&#29616;&#24615;&#21361;&#26426;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29702;&#35770;&#19978;&#21487;&#38752;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#27604;&#36739;&#22810;&#20010;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#12290;&#30001;&#20110;&#19968;&#20010;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#30340;&#19968;&#27425;&#25191;&#34892;&#24615;&#33021;&#26159;&#38543;&#26426;&#30340;&#65292;&#25152;&#20197;&#38656;&#35201;&#36827;&#34892;&#29420;&#31435;&#30340;&#22810;&#27425;&#25191;&#34892;&#26469;&#31934;&#30830;&#35780;&#20272;&#23427;&#12290;&#24403;&#27604;&#36739;&#22810;&#20010;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#26102;&#65292;&#19968;&#20010;&#20027;&#35201;&#38382;&#39064;&#26159;&#38656;&#35201;&#36827;&#34892;&#22810;&#23569;&#27425;&#25191;&#34892;&#65292;&#24182;&#19988;&#22914;&#20309;&#30830;&#20445;&#36825;&#26679;&#27604;&#36739;&#30340;&#32467;&#26524;&#22312;&#29702;&#35770;&#19978;&#26159;&#21487;&#38752;&#30340;&#12290;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30340;&#30740;&#31350;&#20154;&#21592;&#36890;&#24120;&#20351;&#29992;&#23569;&#20110;5&#20010;&#29420;&#31435;&#25191;&#34892;&#26469;&#27604;&#36739;&#31639;&#27861;&#65306;&#25105;&#20204;&#35748;&#20026;&#36825;&#36890;&#24120;&#26159;&#19981;&#22815;&#30340;&#12290;&#32780;&#19988;&#65292;&#24403;&#21516;&#26102;&#27604;&#36739;&#20960;&#20010;&#31639;&#27861;&#26102;&#65292;&#27599;&#20010;&#27604;&#36739;&#30340;&#35823;&#24046;&#37117;&#20250;&#32047;&#31215;&#65292;&#24517;&#39035;&#37319;&#29992;&#22810;&#37325;&#27979;&#35797;&#31243;&#24207;&#26469;&#32771;&#34385;&#36825;&#20123;&#35823;&#24046;&#65292;&#20197;&#32500;&#25345;&#20302;&#35823;&#24046;&#20445;&#35777;&#12290;&#20026;&#20102;&#20197;&#32479;&#35745;&#23398;&#19978;&#30340;&#21487;&#38752;&#26041;&#24335;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;AdaStop&#65292;&#36825;&#26159;&#19968;&#31181;&#22522;&#20110;&#22810;&#32452;&#24207;&#21015;&#27979;&#35797;&#30340;&#26032;&#32479;&#35745;&#27979;&#35797;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The reproducibility of many experimental results in Deep Reinforcement Learning (RL) is under question. To solve this reproducibility crisis, we propose a theoretically sound methodology to compare multiple Deep RL algorithms. The performance of one execution of a Deep RL algorithm is random so that independent executions are needed to assess it precisely. When comparing several RL algorithms, a major question is how many executions must be made and how can we assure that the results of such a comparison is theoretically sound. Researchers in Deep RL often use less than 5 independent executions to compare algorithms: we claim that this is not enough in general. Moreover, when comparing several algorithms at once, the error of each comparison accumulates and must be taken into account with a multiple tests procedure to preserve low error guarantees. To address this problem in a statistically sound way, we introduce AdaStop, a new statistical test based on multiple group sequential tests
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#23436;&#22791;&#24615;&#30340;&#37096;&#20998;&#35782;&#21035;&#26041;&#27861;&#65292;&#23427;&#20026;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#32452;&#30028;&#38480;&#65292;&#29992;&#20110;&#22312;&#26410;&#33021;&#25511;&#21046;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#24418;&#19979;&#65292;&#35780;&#20272;&#27835;&#30103;&#23545;&#32467;&#26524;&#21464;&#37327;&#22240;&#26524;&#25928;&#24212;&#12290;</title><link>http://arxiv.org/abs/2304.04374</link><description>&lt;p&gt;
&#21033;&#29992;&#20195;&#29702;&#21464;&#37327;&#36827;&#34892;&#22240;&#26524;&#25928;&#24212;&#37096;&#20998;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Partial Identification of Causal Effects Using Proxy Variables. (arXiv:2304.04374v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04374
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#23436;&#22791;&#24615;&#30340;&#37096;&#20998;&#35782;&#21035;&#26041;&#27861;&#65292;&#23427;&#20026;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#32452;&#30028;&#38480;&#65292;&#29992;&#20110;&#22312;&#26410;&#33021;&#25511;&#21046;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#24418;&#19979;&#65292;&#35780;&#20272;&#27835;&#30103;&#23545;&#32467;&#26524;&#21464;&#37327;&#22240;&#26524;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#36817;&#31471;&#22240;&#26524;&#25512;&#26029;&#34987;&#25552;&#20986;&#20026;&#19968;&#31181;&#22312;&#26410;&#33021;&#25511;&#21046;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#24418;&#19979;&#35780;&#20272;&#27835;&#30103;&#23545;&#32467;&#26524;&#21464;&#37327;&#22240;&#26524;&#25928;&#24212;&#30340;&#26694;&#26550;&#12290;&#20854;&#20013;&#21033;&#29992;&#26410;&#34987;&#35266;&#27979;&#21040;&#30340;&#28151;&#28102;&#22240;&#32032;&#30340;&#20195;&#29702;&#21464;&#37327;&#36827;&#34892;&#28857;&#20272;&#35745;&#65292;&#21069;&#25552;&#26159;&#36825;&#26679;&#30340;&#20195;&#29702;&#21464;&#37327;&#23545;&#28151;&#28102;&#22240;&#32032;&#30456;&#24403;&#26377;&#20851;&#65292;&#28982;&#32780;&#36825;&#31181;&#23436;&#22791;&#24615;&#21364;&#26159;&#32463;&#39564;&#19981;&#21487;&#26816;&#39564;&#30340;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#19981;&#35201;&#27714;&#23436;&#22791;&#24615;&#30340;&#37096;&#20998;&#35782;&#21035;&#26041;&#27861;&#65292;&#24182;&#20026;&#24863;&#20852;&#36259;&#30340;&#22240;&#26524;&#25928;&#24212;&#25552;&#20379;&#20102;&#19968;&#32452;&#30028;&#38480;&#12290;&#35813;&#26041;&#27861;&#24314;&#31435;&#22312;&#25935;&#24863;&#24615;&#20998;&#26512;&#30340;&#22522;&#30784;&#19978;&#65292;&#24182;&#19988;&#27604;&#29616;&#26377;&#30340;&#22522;&#20110;&#20195;&#29702;&#21464;&#37327;&#30340;&#26041;&#27861;&#35201;&#27714;&#26356;&#24369;&#12290;&#36825;&#39033;&#24037;&#20316;&#22312;&#27169;&#25311;&#25968;&#25454;&#21644;&#29616;&#23454;&#25968;&#25454;&#19978;&#36827;&#34892;&#20102;&#23637;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Proximal causal inference is a recently proposed framework for evaluating the causal effect of a treatment on an outcome variable in the presence of unmeasured confounding (Miao et al., 2018a; Tchetgen Tchetgen et al., 2020). For nonparametric point identification, the framework leverages proxy variables of unobserved confounders, provided that such proxies are sufficiently relevant for the latter, a requirement that has previously been formalized as a completeness condition. Completeness is key to connecting the observed proxy data to hidden factors via a so-called confounding bridge function, identification of which is an important step towards proxy-based point identification of causal effects. However, completeness is well-known not to be empirically testable, therefore potentially restricting the application of the proximal causal framework. In this paper, we propose partial identification methods that do not require completeness and obviate the need for identification of a bridge
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28151;&#21512;&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#24378;&#21487;&#36776;&#35782;&#24615;&#26465;&#20214;&#12289;&#21442;&#25968;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#24230;&#21644;&#36125;&#21494;&#26031;&#21518;&#39564;&#25910;&#32553;&#34892;&#20026;&#65292;&#36866;&#29992;&#20110;&#24120;&#35265;&#30340;&#38142;&#20989;&#25968;&#21644;&#26465;&#20214;&#20998;&#24067;&#26063;&#12290;</title><link>http://arxiv.org/abs/2212.04091</link><description>&lt;p&gt;
&#24378;&#21487;&#36776;&#35782;&#24615;&#21644;&#24322;&#36136;&#21709;&#24212;&#22238;&#24402;&#20013;&#30340;&#21442;&#25968;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Strong identifiability and parameter learning in regression with heterogeneous response. (arXiv:2212.04091v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.04091
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28151;&#21512;&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#24378;&#21487;&#36776;&#35782;&#24615;&#26465;&#20214;&#12289;&#21442;&#25968;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#24230;&#21644;&#36125;&#21494;&#26031;&#21518;&#39564;&#25910;&#32553;&#34892;&#20026;&#65292;&#36866;&#29992;&#20110;&#24120;&#35265;&#30340;&#38142;&#20989;&#25968;&#21644;&#26465;&#20214;&#20998;&#24067;&#26063;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28151;&#21512;&#22238;&#24402;&#26159;&#19968;&#31867;&#24378;&#22823;&#30340;&#27169;&#22411;&#65292;&#29992;&#20110;&#23545;&#39640;&#24230;&#19981;&#30830;&#23450;&#21644;&#24322;&#36136;&#30340;&#30446;&#26631;&#21709;&#24212;&#21464;&#37327;&#36827;&#34892;&#22238;&#24402;&#23398;&#20064;&#12290;&#38500;&#20102;&#20316;&#20026;&#32473;&#23450;&#19968;&#20123;&#21327;&#21464;&#37327;&#30340;&#21709;&#24212;&#30340;&#20016;&#23500;&#39044;&#27979;&#27169;&#22411;&#20043;&#22806;&#65292;&#35813;&#27169;&#22411;&#31867;&#20013;&#30340;&#21442;&#25968;&#36824;&#25552;&#20379;&#26377;&#20851;&#25968;&#25454;&#24635;&#20307;&#20013;&#24322;&#36136;&#24615;&#30340;&#26377;&#29992;&#20449;&#24687;&#65292;&#35813;&#24322;&#36136;&#24615;&#30001;&#19982;&#33509;&#24178;&#20010;&#19981;&#21516;&#20294;&#28508;&#22312;&#30340;&#23376;&#32676;&#20307;&#30456;&#20851;&#32852;&#30340;&#21327;&#21464;&#37327;&#32473;&#23450;&#21709;&#24212;&#30340;&#26465;&#20214;&#20998;&#24067;&#34920;&#31034;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#28151;&#21512;&#22238;&#24402;&#27169;&#22411;&#20013;&#30340;&#24378;&#21487;&#36776;&#35782;&#24615;&#26465;&#20214;&#12289;&#26465;&#20214;&#23494;&#24230;&#21644;&#21442;&#25968;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#20197;&#21450;&#22312;&#31934;&#30830;&#25311;&#21512;&#21644;&#36807;&#25311;&#21512;&#35774;&#32622;&#20197;&#21450;&#32452;&#20998;&#25968;&#37327;&#26410;&#30693;&#26102;&#20135;&#29983;&#30340;&#36125;&#21494;&#26031;&#21518;&#39564;&#25910;&#32553;&#34892;&#20026;&#12290;&#35813;&#29702;&#35770;&#36866;&#29992;&#20110;&#23454;&#36341;&#32773;&#24120;&#35265;&#30340;&#38142;&#20989;&#25968;&#21644;&#26465;&#20214;&#20998;&#24067;&#26063;&#30340;&#36873;&#25321;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#27169;&#25311;&#30740;&#31350;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Mixtures of regression are a powerful class of models for regression learning with respect to a highly uncertain and heterogeneous response variable of interest. In addition to being a rich predictive model for the response given some covariates, the parameters in this model class provide useful information about the heterogeneity in the data population, which is represented by the conditional distributions for the response given the covariates associated with a number of distinct but latent subpopulations. In this paper, we investigate conditions of strong identifiability, rates of convergence for conditional density and parameter estimation, and the Bayesian posterior contraction behavior arising in finite mixture of regression models, under exact-fitted and over-fitted settings and when the number of components is unknown. This theory is applicable to common choices of link functions and families of conditional distributions employed by practitioners. We provide simulation studies a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23436;&#20840;&#38543;&#26426;&#30340;&#20449;&#20219;&#21306;&#38388;&#39034;&#24207;&#20108;&#27425;&#35268;&#21010;&#31639;&#27861;(TR-StoSQP)&#65292;&#29992;&#20110;&#35299;&#20915;&#38750;&#32447;&#24615;&#20248;&#21270;&#38382;&#39064;&#65292;&#20854;&#20013;&#21253;&#21547;&#38543;&#26426;&#30446;&#26631;&#21644;&#30830;&#23450;&#24615;&#31561;&#24335;&#32422;&#26463;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#33258;&#36866;&#24212;&#36873;&#25321;&#20449;&#20219;&#21306;&#38388;&#21322;&#24452;&#65292;&#24182;&#20801;&#35768;&#20351;&#29992;&#26410;&#32463;&#20462;&#25913;&#30340;Hessian&#30697;&#38453;&#65292;&#22312;SQP&#23376;&#38382;&#39064;&#20013;&#24212;&#23545;&#19981;&#21487;&#34892;&#24615;&#38382;&#39064;&#12290;&#20026;&#20102;&#25511;&#21046;&#35797;&#39564;&#27493;&#38271;&#30340;&#38271;&#24230;&#24182;&#20445;&#35777;&#23610;&#24230;&#19981;&#21464;&#24615;&#65292;&#20316;&#32773;&#37319;&#29992;&#33258;&#36866;&#24212;&#30340;&#26494;&#24347;&#25216;&#26415;&#35745;&#31639;&#35797;&#39564;&#27493;&#38271;&#12290;</title><link>http://arxiv.org/abs/2211.15943</link><description>&lt;p&gt;
&#23436;&#20840;&#38543;&#26426;&#20449;&#20219;&#21306;&#38388;&#39034;&#24207;&#20108;&#27425;&#35268;&#21010;&#26041;&#27861;&#29992;&#20110;&#31561;&#24335;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Fully Stochastic Trust-Region Sequential Quadratic Programming for Equality-Constrained Optimization Problems. (arXiv:2211.15943v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.15943
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23436;&#20840;&#38543;&#26426;&#30340;&#20449;&#20219;&#21306;&#38388;&#39034;&#24207;&#20108;&#27425;&#35268;&#21010;&#31639;&#27861;(TR-StoSQP)&#65292;&#29992;&#20110;&#35299;&#20915;&#38750;&#32447;&#24615;&#20248;&#21270;&#38382;&#39064;&#65292;&#20854;&#20013;&#21253;&#21547;&#38543;&#26426;&#30446;&#26631;&#21644;&#30830;&#23450;&#24615;&#31561;&#24335;&#32422;&#26463;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#33258;&#36866;&#24212;&#36873;&#25321;&#20449;&#20219;&#21306;&#38388;&#21322;&#24452;&#65292;&#24182;&#20801;&#35768;&#20351;&#29992;&#26410;&#32463;&#20462;&#25913;&#30340;Hessian&#30697;&#38453;&#65292;&#22312;SQP&#23376;&#38382;&#39064;&#20013;&#24212;&#23545;&#19981;&#21487;&#34892;&#24615;&#38382;&#39064;&#12290;&#20026;&#20102;&#25511;&#21046;&#35797;&#39564;&#27493;&#38271;&#30340;&#38271;&#24230;&#24182;&#20445;&#35777;&#23610;&#24230;&#19981;&#21464;&#24615;&#65292;&#20316;&#32773;&#37319;&#29992;&#33258;&#36866;&#24212;&#30340;&#26494;&#24347;&#25216;&#26415;&#35745;&#31639;&#35797;&#39564;&#27493;&#38271;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20449;&#20219;&#21306;&#38388;&#38543;&#26426;&#39034;&#24207;&#20108;&#27425;&#35268;&#21010;&#31639;&#27861;(TR-StoSQP)&#65292;&#29992;&#20110;&#35299;&#20915;&#20855;&#26377;&#38543;&#26426;&#30446;&#26631;&#21644;&#30830;&#23450;&#24615;&#31561;&#24335;&#32422;&#26463;&#30340;&#38750;&#32447;&#24615;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#23436;&#20840;&#38543;&#26426;&#30340;&#24773;&#20917;&#65292;&#22312;&#27599;&#19968;&#27493;&#20013;&#29983;&#25104;&#19968;&#20010;&#26679;&#26412;&#26469;&#20272;&#35745;&#30446;&#26631;&#26799;&#24230;&#12290;&#35813;&#31639;&#27861;&#33258;&#36866;&#24212;&#22320;&#36873;&#25321;&#20449;&#20219;&#21306;&#38388;&#21322;&#24452;&#65292;&#24182;&#19988;&#19982;&#29616;&#26377;&#30340;&#32447;&#25628;&#32034;StoSQP&#26041;&#26696;&#30456;&#27604;&#65292;&#20801;&#35768;&#25105;&#20204;&#22312;SQP&#23376;&#38382;&#39064;&#20013;&#20351;&#29992;&#38750;&#30830;&#23450;Hessian&#30697;&#38453;&#65288;&#21363;&#26410;&#32463;&#20462;&#25913;&#30340;Hessian&#30697;&#38453;&#65289;&#12290;&#20316;&#20026;&#32422;&#26463;&#20248;&#21270;&#30340;&#20449;&#20219;&#21306;&#38388;&#26041;&#27861;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#24517;&#39035;&#35299;&#20915;&#19968;&#20010;&#19981;&#21487;&#34892;&#24615;&#38382;&#39064;--&#32447;&#24615;&#21270;&#30340;&#31561;&#24335;&#32422;&#26463;&#21644;&#20449;&#20219;&#21306;&#38388;&#32422;&#26463;&#21487;&#33021;&#23548;&#33268;&#19981;&#21487;&#34892;&#30340;SQP&#23376;&#38382;&#39064;&#12290;&#22312;&#36825;&#26041;&#38754;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#30340;&#26494;&#24347;&#25216;&#26415;&#26469;&#35745;&#31639;&#35797;&#39564;&#27493;&#38271;&#65292;&#21253;&#25324;&#19968;&#20010;&#27491;&#24120;&#27493;&#38271;&#21644;&#19968;&#20010;&#20999;&#32447;&#27493;&#38271;&#12290;&#20026;&#20102;&#25511;&#21046;&#36825;&#20004;&#20010;&#27493;&#38271;&#30340;&#38271;&#24230;&#65292;&#21516;&#26102;&#30830;&#20445;&#19968;&#20010;&#23610;&#24230;&#19981;&#21464;&#30340;&#23646;&#24615;&#65292;&#25105;&#20204;&#33258;&#36866;&#24212;&#22320;&#35013;&#39280;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a trust-region stochastic sequential quadratic programming algorithm (TR-StoSQP) to solve nonlinear optimization problems with stochastic objectives and deterministic equality constraints. We consider a fully stochastic setting, where at each step a single sample is generated to estimate the objective gradient. The algorithm adaptively selects the trust-region radius and, compared to the existing line-search StoSQP schemes, allows us to utilize indefinite Hessian matrices (i.e., Hessians without modification) in SQP subproblems. As a trust-region method for constrained optimization, our algorithm must address an infeasibility issue -- the linearized equality constraints and trust-region constraints may lead to infeasible SQP subproblems. In this regard, we propose an adaptive relaxation technique to compute the trial step, consisting of a normal step and a tangential step. To control the lengths of these two steps while ensuring a scale-invariant property, we adaptively deco
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#31163;&#32447;&#20272;&#35745;&#26377;&#38480;&#25511;&#21046;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#36716;&#31227;&#27010;&#29575;&#30697;&#38453;&#30340;&#38750;&#21442;&#25968;&#20272;&#35745;&#22120;&#65292;&#24182;&#36890;&#36807;&#35760;&#24405;&#31574;&#30053;&#30340;&#28151;&#21512;&#29305;&#24615;&#24314;&#31435;&#20102;&#26679;&#26412;&#22797;&#26434;&#24615;&#30028;&#38480;&#21644;&#26368;&#23567;&#21270;&#26465;&#20214;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#23454;&#29616;&#29305;&#23450;&#30340;&#32479;&#35745;&#39118;&#38505;&#30028;&#38480;&#28041;&#21450;&#21040;&#28151;&#21512;&#29305;&#24615;&#30340;&#24378;&#24230;&#21644;&#26679;&#26412;&#25968;&#37327;&#20043;&#38388;&#24494;&#22937;&#32780;&#26377;&#36259;&#30340;&#26435;&#34913;&#12290;&#36824;&#20351;&#29992;&#36825;&#20123;&#26679;&#26412;&#22797;&#26434;&#24615;&#30028;&#38480;&#24314;&#31435;&#20102;&#31163;&#32447;&#35780;&#20272;&#24658;&#23450;&#39532;&#23572;&#21487;&#22827;&#25511;&#21046;&#31574;&#30053;&#30340;&#30456;&#20851;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2211.07092</link><description>&lt;p&gt;
&#31163;&#32447;&#20272;&#35745;&#25511;&#21046;&#39532;&#23572;&#21487;&#22827;&#38142;&#65306;&#26368;&#23567;&#21270;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;
&lt;/p&gt;
&lt;p&gt;
Offline Estimation of Controlled Markov Chains: Minimaxity and Sample Complexity. (arXiv:2211.07092v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.07092
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#31163;&#32447;&#20272;&#35745;&#26377;&#38480;&#25511;&#21046;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#36716;&#31227;&#27010;&#29575;&#30697;&#38453;&#30340;&#38750;&#21442;&#25968;&#20272;&#35745;&#22120;&#65292;&#24182;&#36890;&#36807;&#35760;&#24405;&#31574;&#30053;&#30340;&#28151;&#21512;&#29305;&#24615;&#24314;&#31435;&#20102;&#26679;&#26412;&#22797;&#26434;&#24615;&#30028;&#38480;&#21644;&#26368;&#23567;&#21270;&#26465;&#20214;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#23454;&#29616;&#29305;&#23450;&#30340;&#32479;&#35745;&#39118;&#38505;&#30028;&#38480;&#28041;&#21450;&#21040;&#28151;&#21512;&#29305;&#24615;&#30340;&#24378;&#24230;&#21644;&#26679;&#26412;&#25968;&#37327;&#20043;&#38388;&#24494;&#22937;&#32780;&#26377;&#36259;&#30340;&#26435;&#34913;&#12290;&#36824;&#20351;&#29992;&#36825;&#20123;&#26679;&#26412;&#22797;&#26434;&#24615;&#30028;&#38480;&#24314;&#31435;&#20102;&#31163;&#32447;&#35780;&#20272;&#24658;&#23450;&#39532;&#23572;&#21487;&#22827;&#25511;&#21046;&#31574;&#30053;&#30340;&#30456;&#20851;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#26377;&#38480;&#25511;&#21046;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#36716;&#31227;&#27010;&#29575;&#30697;&#38453;&#30340;&#33258;&#28982;&#38750;&#21442;&#25968;&#20272;&#35745;&#22120;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#22266;&#23450;&#25968;&#25454;&#38598;&#30340;&#31163;&#32447;&#35774;&#32622;&#65292;&#35813;&#25968;&#25454;&#38598;&#26159;&#20351;&#29992;&#25152;&#35859;&#30340;&#35760;&#24405;&#31574;&#30053;&#25910;&#38598;&#30340;&#12290;&#25105;&#20204;&#20026;&#20272;&#35745;&#22120;&#24320;&#21457;&#20102;&#26679;&#26412;&#22797;&#26434;&#24615;&#30340;&#30028;&#38480;&#65292;&#24182;&#24314;&#31435;&#20102;&#26368;&#23567;&#21270;&#30340;&#26465;&#20214;&#12290;&#25105;&#20204;&#30340;&#32479;&#35745;&#30028;&#38480;&#36890;&#36807;&#35760;&#24405;&#31574;&#30053;&#30340;&#28151;&#21512;&#29305;&#24615;&#26469;&#30830;&#23450;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#23454;&#29616;&#29305;&#23450;&#30340;&#32479;&#35745;&#39118;&#38505;&#30028;&#38480;&#28041;&#21450;&#21040;&#28151;&#21512;&#29305;&#24615;&#30340;&#24378;&#24230;&#21644;&#26679;&#26412;&#25968;&#37327;&#20043;&#38388;&#24494;&#22937;&#32780;&#26377;&#36259;&#30340;&#26435;&#34913;&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#31034;&#20363;&#20013;&#39564;&#35777;&#20102;&#25105;&#20204;&#32467;&#26524;&#30340;&#26377;&#25928;&#24615;&#65292;&#21253;&#25324;&#36951;&#20256;&#39532;&#23572;&#21487;&#22827;&#38142;&#65292;&#24369;&#36951;&#20256;&#38750;&#40784;&#27425;&#39532;&#23572;&#21487;&#22827;&#38142;&#21644;&#20855;&#26377;&#38750;&#24179;&#31283;&#39532;&#23572;&#21487;&#22827;&#12289;&#38454;&#27573;&#24615;&#21644;&#36138;&#23146;&#25511;&#21046;&#30340;&#25511;&#21046;&#39532;&#23572;&#21487;&#22827;&#38142;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#36825;&#20123;&#26679;&#26412;&#22797;&#26434;&#24615;&#30028;&#38480;&#26469;&#24314;&#31435;&#31163;&#32447;&#35780;&#20272;&#24658;&#23450;&#39532;&#23572;&#21487;&#22827;&#25511;&#21046;&#31574;&#30053;&#30340;&#30456;&#20851;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we study a natural nonparametric estimator of the transition probability matrices of a finite controlled Markov chain. We consider an offline setting with a fixed dataset, collected using a so-called logging policy. We develop sample complexity bounds for the estimator and establish conditions for minimaxity. Our statistical bounds depend on the logging policy through its mixing properties. We show that achieving a particular statistical risk bound involves a subtle and interesting trade-off between the strength of the mixing properties and the number of samples. We demonstrate the validity of our results under various examples, such as ergodic Markov chains, weakly ergodic inhomogeneous Markov chains, and controlled Markov chains with non-stationary Markov, episodic, and greedy controls. Lastly, we use these sample complexity bounds to establish concomitant ones for offline evaluation of stationary Markov control policies.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32852;&#37030;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#21487;&#20197;&#22788;&#29702;&#21307;&#30103;&#26426;&#26500;&#38388;&#25968;&#25454;&#20849;&#20139;&#30340;&#38544;&#31169;&#38480;&#21046;&#21644;&#24322;&#36136;&#24615;&#38382;&#39064;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#36890;&#20449;&#25928;&#29575;&#21644;&#38544;&#31169;&#20445;&#25252;&#24615;&#12290;&#35813;&#31639;&#27861;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#35777;&#26126;&#20197;&#21450;&#22312;&#29616;&#23454;&#21307;&#23398;&#25968;&#25454;&#38598;&#19978;&#30340;&#27169;&#25311;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#21644;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2206.05581</link><description>&lt;p&gt;
&#32852;&#37030;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Federated Offline Reinforcement Learning. (arXiv:2206.05581v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.05581
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32852;&#37030;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#21487;&#20197;&#22788;&#29702;&#21307;&#30103;&#26426;&#26500;&#38388;&#25968;&#25454;&#20849;&#20139;&#30340;&#38544;&#31169;&#38480;&#21046;&#21644;&#24322;&#36136;&#24615;&#38382;&#39064;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#36890;&#20449;&#25928;&#29575;&#21644;&#38544;&#31169;&#20445;&#25252;&#24615;&#12290;&#35813;&#31639;&#27861;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#35777;&#26126;&#20197;&#21450;&#22312;&#29616;&#23454;&#21307;&#23398;&#25968;&#25454;&#38598;&#19978;&#30340;&#27169;&#25311;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#35777;&#25454;&#25110;&#25968;&#25454;&#30340;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;&#23545;&#20110;&#20010;&#24615;&#21270;&#21307;&#30103;&#33267;&#20851;&#37325;&#35201;&#65292;&#21487;&#20197;&#21463;&#30410;&#20110;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#12290;&#34429;&#28982;&#21307;&#30103;&#26426;&#26500;&#38388;&#26377;&#22823;&#37327;&#20581;&#24247;&#25968;&#25454;&#21487;&#29992;&#65292;&#20294;&#30001;&#20110;&#38544;&#31169;&#38480;&#21046;&#65292;&#23427;&#20204;&#26080;&#27861;&#20849;&#20139;&#12290;&#27492;&#22806;&#65292;&#19981;&#21516;&#31449;&#28857;&#23384;&#22312;&#24322;&#36136;&#24615;&#12290;&#22240;&#27492;&#65292;&#32852;&#37030;&#31163;&#32447;RL&#31639;&#27861;&#26159;&#24517;&#35201;&#30340;&#19988;&#26377;&#21069;&#36884;&#65292;&#20197;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#31449;&#28857;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#27169;&#22411;&#65292;&#20801;&#35768;&#31449;&#28857;&#20043;&#38388;&#30340;&#21516;&#36136;&#24615;&#21644;&#24322;&#36136;&#24615;&#25928;&#24212;&#12290;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#21487;&#20197;&#20998;&#26512;&#31449;&#28857;&#32423;&#29305;&#24449;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#31532;&#19968;&#20010;&#20855;&#26377;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#31163;&#32447;RL&#32852;&#37030;&#31574;&#30053;&#20248;&#21270;&#31639;&#27861;&#12290;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#20855;&#26377;&#36890;&#20449;&#25928;&#29575;&#21644;&#38544;&#31169;&#20445;&#25252;&#24615;&#65292;&#20165;&#38656;&#35201;&#36890;&#36807;&#20132;&#25442;&#25688;&#35201;&#32479;&#35745;&#37327;&#36827;&#34892;&#19968;&#36718;&#36890;&#20449;&#20132;&#20114;&#12290;&#25105;&#20204;&#20026;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#65292;&#26080;&#38656;&#20551;&#35774;&#31449;&#28857;&#20043;&#38388;&#20855;&#26377;&#30456;&#21516;&#30340;&#36716;&#25442;&#21160;&#24577;&#12290;&#25105;&#20204;&#22312;&#29616;&#23454;&#21307;&#23398;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#27169;&#25311;&#65292;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Evidence-based or data-driven dynamic treatment regimes are essential for personalized medicine, which can benefit from offline reinforcement learning (RL). Although massive healthcare data are available across medical institutions, they are prohibited from sharing due to privacy constraints. Besides, heterogeneity exists in different sites. As a result, federated offline RL algorithms are necessary and promising to deal with the problems. In this paper, we propose a multi-site Markov decision process model which allows both homogeneous and heterogeneous effects across sites. The proposed model makes the analysis of the site-level features possible. We design the first federated policy optimization algorithm for offline RL with sample complexity. The proposed algorithm is communication-efficient and privacy-preserving, which requires only a single round of communication interaction by exchanging summary statistics. We give a theoretical guarantee for the proposed algorithm without the 
&lt;/p&gt;</description></item><item><title>AugLoss&#26159;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#32479;&#19968;&#25968;&#25454;&#22686;&#24378;&#21644;&#31283;&#20581;&#25439;&#22833;&#20989;&#25968;&#65292;&#23454;&#29616;&#20102;&#23545;&#35757;&#32451;&#26102;&#30340;&#22122;&#22768;&#26631;&#27880;&#21644;&#27979;&#35797;&#26102;&#30340;&#29305;&#24449;&#20998;&#24067;&#36716;&#31227;&#30340;&#31283;&#20581;&#24615;&#12290;</title><link>http://arxiv.org/abs/2206.02286</link><description>&lt;p&gt;
AugLoss&#65306;&#19968;&#31181;&#31283;&#20581;&#30340;&#22522;&#20110;&#25968;&#25454;&#22686;&#24378;&#30340;&#24494;&#35843;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
AugLoss: A Robust Augmentation-based Fine Tuning Methodology. (arXiv:2206.02286v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.02286
&lt;/p&gt;
&lt;p&gt;
AugLoss&#26159;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#32479;&#19968;&#25968;&#25454;&#22686;&#24378;&#21644;&#31283;&#20581;&#25439;&#22833;&#20989;&#25968;&#65292;&#23454;&#29616;&#20102;&#23545;&#35757;&#32451;&#26102;&#30340;&#22122;&#22768;&#26631;&#27880;&#21644;&#27979;&#35797;&#26102;&#30340;&#29305;&#24449;&#20998;&#24067;&#36716;&#31227;&#30340;&#31283;&#20581;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#22312;&#35768;&#22810;&#39046;&#22495;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#36234;&#26469;&#36234;&#38754;&#20020;&#23433;&#20840;&#24615;&#21644;&#40065;&#26834;&#24615;&#26041;&#38754;&#30340;&#38382;&#39064;&#65292;&#21253;&#25324;&#35757;&#32451;&#38454;&#27573;&#30340;&#22122;&#22768;&#26631;&#27880;&#21644;&#27979;&#35797;&#38454;&#27573;&#30340;&#29305;&#24449;&#20998;&#24067;&#36716;&#31227;&#12290;&#20197;&#24448;&#30340;&#30740;&#31350;&#22312;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#20294;&#20027;&#35201;&#38598;&#20013;&#22312;&#19968;&#27425;&#21482;&#35299;&#20915;&#19968;&#20010;&#38382;&#39064;&#30340;&#35299;&#20915;&#26041;&#26696;&#19978;&#12290;&#20363;&#22914;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#25552;&#20986;&#20102;&#20351;&#29992;&#21487;&#35843;&#30340;&#31283;&#20581;&#25439;&#22833;&#20989;&#25968;&#26469;&#20943;&#36731;&#26631;&#31614;&#22122;&#22768;&#65292;&#20197;&#21450;&#20351;&#29992;&#25968;&#25454;&#22686;&#24378;&#65288;&#20363;&#22914;AugMix&#65289;&#26469;&#35299;&#20915;&#20998;&#24067;&#36716;&#31227;&#38382;&#39064;&#12290;&#20026;&#20102;&#21516;&#26102;&#35299;&#20915;&#36825;&#20004;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;AugLoss&#65292;&#19968;&#31181;&#31616;&#21333;&#20294;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#32479;&#19968;&#25968;&#25454;&#22686;&#24378;&#21644;&#31283;&#20581;&#25439;&#22833;&#20989;&#25968;&#65292;&#23454;&#29616;&#20102;&#23545;&#35757;&#32451;&#26102;&#30340;&#22122;&#22768;&#26631;&#27880;&#21644;&#27979;&#35797;&#26102;&#30340;&#29305;&#24449;&#20998;&#24067;&#36716;&#31227;&#30340;&#31283;&#20581;&#24615;&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#30495;&#23454;&#25968;&#25454;&#38598;&#25439;&#22351;&#35774;&#32622;&#19979;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#23454;&#39564;&#65292;&#23637;&#31034;&#20102;&#19982;&#20197;&#21069;&#26041;&#27861;&#30456;&#27604;AugLoss&#25152;&#21462;&#24471;&#30340;&#25910;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep Learning (DL) models achieve great successes in many domains. However, DL models increasingly face safety and robustness concerns, including noisy labeling in the training stage and feature distribution shifts in the testing stage. Previous works made significant progress in addressing these problems, but the focus has largely been on developing solutions for only one problem at a time. For example, recent work has argued for the use of tunable robust loss functions to mitigate label noise, and data augmentation (e.g., AugMix) to combat distribution shifts. As a step towards addressing both problems simultaneously, we introduce AugLoss, a simple but effective methodology that achieves robustness against both train-time noisy labeling and test-time feature distribution shifts by unifying data augmentation and robust loss functions. We conduct comprehensive experiments in varied settings of real-world dataset corruption to showcase the gains achieved by AugLoss compared to previous 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;&#29992;&#20110;&#19968;&#33324;&#25552;&#26696;&#30340;&#20248;&#21270;&#33258;&#36866;&#24212;&#37325;&#35201;&#25277;&#26679;&#22120;&#65288;OAIS&#65289;&#30340;&#24615;&#33021;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#21487;&#20197;&#20840;&#23616;&#20248;&#21270;$\chi^2$&#25955;&#24230;&#30340;&#26041;&#26696;&#12290;&#35813;&#26041;&#26696;&#36890;&#36807;&#21033;&#29992;&#38750;&#20984;&#20248;&#21270;&#29702;&#35770;&#65292;&#22635;&#34917;&#20102;&#23545;&#20110;&#19968;&#33324;&#25552;&#26696;&#30340;&#20840;&#23616;&#20248;&#21270;&#32570;&#22833;&#12290;&#24471;&#21040;&#30340;AIS&#26041;&#26696;&#20855;&#26377;&#26174;&#24335;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#19988;&#20445;&#35777;&#22312;&#20219;&#24847;&#26102;&#21051;&#22343;&#25104;&#31435;&#12290;</title><link>http://arxiv.org/abs/2201.00409</link><description>&lt;p&gt;
&#20248;&#21270;&#33258;&#36866;&#24212;&#37325;&#35201;&#25277;&#26679;&#22120;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Global convergence of optimized adaptive importance samplers. (arXiv:2201.00409v2 [stat.CO] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.00409
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#29992;&#20110;&#19968;&#33324;&#25552;&#26696;&#30340;&#20248;&#21270;&#33258;&#36866;&#24212;&#37325;&#35201;&#25277;&#26679;&#22120;&#65288;OAIS&#65289;&#30340;&#24615;&#33021;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#21487;&#20197;&#20840;&#23616;&#20248;&#21270;$\chi^2$&#25955;&#24230;&#30340;&#26041;&#26696;&#12290;&#35813;&#26041;&#26696;&#36890;&#36807;&#21033;&#29992;&#38750;&#20984;&#20248;&#21270;&#29702;&#35770;&#65292;&#22635;&#34917;&#20102;&#23545;&#20110;&#19968;&#33324;&#25552;&#26696;&#30340;&#20840;&#23616;&#20248;&#21270;&#32570;&#22833;&#12290;&#24471;&#21040;&#30340;AIS&#26041;&#26696;&#20855;&#26377;&#26174;&#24335;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#19988;&#20445;&#35777;&#22312;&#20219;&#24847;&#26102;&#21051;&#22343;&#25104;&#31435;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#29992;&#20110;&#19968;&#33324;&#25552;&#26696;&#30340;&#20248;&#21270;&#33258;&#36866;&#24212;&#37325;&#35201;&#25277;&#26679;&#22120;&#65288;OAIS&#65289;&#22312;&#36827;&#34892;&#33945;&#29305;&#21345;&#32599;&#31215;&#20998;&#26102;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#21033;&#29992;&#20102;&#19968;&#20010;&#32463;&#20856;&#32467;&#26524;&#65292;&#35813;&#32467;&#26524;&#26174;&#31034;&#20102;&#37325;&#35201;&#25277;&#26679;&#30340;&#20559;&#24046;&#21644;&#22343;&#26041;&#35823;&#24046;&#65288;MSE&#65289;&#19982;&#30446;&#26631;&#21644;&#25552;&#26696;&#20043;&#38388;&#30340;$\chi^2$&#25955;&#24230;&#21576;&#27604;&#20363;&#20851;&#31995;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#26041;&#26696;&#65292;&#21487;&#20197;&#23545;$\chi^2$&#25955;&#24230;&#36827;&#34892;&#20840;&#23616;&#20248;&#21270;&#12290;&#34429;&#28982;&#23545;&#20110;&#25351;&#25968;&#26063;&#25552;&#26696;&#65292;&#24050;&#30693;&#35813;&#37327;&#26159;&#20984;&#30340;&#65292;&#20294;&#23545;&#20110;&#19968;&#33324;&#25552;&#26696;&#65292;&#36825;&#20010;&#38382;&#39064;&#19968;&#30452;&#26159;&#19968;&#20010;&#26410;&#35299;&#20043;&#35868;&#12290;&#25105;&#20204;&#36890;&#36807;&#21033;&#29992;&#38543;&#26426;&#26799;&#24230;Langevin&#21160;&#24577;&#65288;SGLD&#65289;&#30340;&#38750;&#28176;&#36817;&#36793;&#30028;&#36827;&#34892;$\chi^2$&#25955;&#24230;&#30340;&#20840;&#23616;&#20248;&#21270;&#65292;&#24182;&#21033;&#29992;&#26368;&#36817;&#30340;&#38750;&#20984;&#20248;&#21270;&#25991;&#29486;&#30340;&#32467;&#26524;&#25512;&#23548;&#20986;MSE&#30340;&#38750;&#28176;&#36817;&#36793;&#30028;&#65292;&#26469;&#22635;&#34917;&#36825;&#20010;&#31354;&#30333;&#12290;&#24471;&#21040;&#30340;AIS&#26041;&#26696;&#20855;&#26377;&#26174;&#24335;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#19988;&#20445;&#35777;&#22312;&#20219;&#24847;&#26102;&#21051;&#22343;&#25104;&#31435;&#12290;
&lt;/p&gt;
&lt;p&gt;
We analyze the optimized adaptive importance sampler (OAIS) for performing Monte Carlo integration with general proposals. We leverage a classical result which shows that the bias and the mean-squared error (MSE) of the importance sampling scales with the $\chi^2$-divergence between the target and the proposal and develop a scheme which performs global optimization of $\chi^2$-divergence. While it is known that this quantity is convex for exponential family proposals, the case of the general proposals has been an open problem. We close this gap by utilizing the nonasymptotic bounds for stochastic gradient Langevin dynamics (SGLD) for the global optimization of $\chi^2$-divergence and derive nonasymptotic bounds for the MSE by leveraging recent results from non-convex optimization literature. The resulting AIS schemes have explicit theoretical guarantees that are uniform-in-time.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#35780;&#20272;&#20102;&#35745;&#31639;&#26426;&#35270;&#35273;&#33258;&#30417;&#30563;&#23398;&#20064;&#26694;&#26550;&#22312;&#26102;&#38388;&#24207;&#21015;&#19978;&#30340;&#25928;&#26524;&#65292;&#24182;&#19988;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#26041;&#27861;&#65292;&#36890;&#36807;&#25913;&#36827;&#21327;&#26041;&#24046;&#39033;&#21644;&#28155;&#21152;&#36845;&#20195;&#24402;&#19968;&#21270;&#23618;&#65292;&#21152;&#36895;&#20102;&#27169;&#22411;&#30340;&#25910;&#25947;&#12290;</title><link>http://arxiv.org/abs/2109.00783</link><description>&lt;p&gt;
&#35745;&#31639;&#26426;&#35270;&#35273;&#20013;&#22522;&#20110;&#33258;&#30417;&#30563;&#23398;&#20064;&#30340;&#26102;&#24207;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Computer Vision Self-supervised Learning Methods on Time Series. (arXiv:2109.00783v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.00783
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#35780;&#20272;&#20102;&#35745;&#31639;&#26426;&#35270;&#35273;&#33258;&#30417;&#30563;&#23398;&#20064;&#26694;&#26550;&#22312;&#26102;&#38388;&#24207;&#21015;&#19978;&#30340;&#25928;&#26524;&#65292;&#24182;&#19988;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#26041;&#27861;&#65292;&#36890;&#36807;&#25913;&#36827;&#21327;&#26041;&#24046;&#39033;&#21644;&#28155;&#21152;&#36845;&#20195;&#24402;&#19968;&#21270;&#23618;&#65292;&#21152;&#36895;&#20102;&#27169;&#22411;&#30340;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#30417;&#30563;&#23398;&#20064;&#65288;SSL&#65289;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#39046;&#22495;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#12290;&#30446;&#21069;&#20027;&#27969;&#30340;&#35745;&#31639;&#26426;&#35270;&#35273;&#33258;&#30417;&#30563;&#23398;&#20064;&#26694;&#26550;&#22823;&#22810;&#22522;&#20110;Siamese&#32593;&#32476;&#26550;&#26500;&#12290;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#20381;&#36182;&#20110;&#31934;&#24515;&#35774;&#35745;&#30340;&#25439;&#22833;&#20989;&#25968;&#21644;&#35757;&#32451;&#35774;&#32622;&#65292;&#20197;&#36991;&#20813;&#29305;&#24449;&#23849;&#28291;&#12290;&#26412;&#30740;&#31350;&#35780;&#20272;&#20102;&#36825;&#20123;&#35745;&#31639;&#26426;&#35270;&#35273;&#33258;&#30417;&#30563;&#23398;&#20064;&#26694;&#26550;&#22312;&#19981;&#21516;&#27169;&#24577;&#65288;&#21363;&#26102;&#38388;&#24207;&#21015;&#65289;&#19978;&#30340;&#25928;&#26524;&#12290;&#25105;&#20204;&#22312;UCR&#21644;UEA&#26723;&#26696;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#35777;&#26126;&#65292;&#35745;&#31639;&#26426;&#35270;&#35273;&#33258;&#30417;&#30563;&#23398;&#20064;&#26694;&#26550;&#22312;&#26102;&#38388;&#24207;&#21015;&#19978;&#21516;&#26679;&#26377;&#25928;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#26368;&#36817;&#25552;&#20986;&#30340;VICReg&#26041;&#27861;&#30340;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#25913;&#36827;&#20102;VICReg&#20013;&#25552;&#20986;&#30340;&#19968;&#20010;&#8220;&#21327;&#26041;&#24046;&#8221;&#39033;&#65292;&#21516;&#26102;&#22312;&#26550;&#26500;&#30340;&#22836;&#37096;&#22686;&#21152;&#20102;&#19968;&#20010;&#36845;&#20195;&#24402;&#19968;&#21270;&#23618;&#65292;&#21152;&#36895;&#20102;&#27169;&#22411;&#30340;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;
Self-supervised learning (SSL) has had great success in both computer vision. Most of the current mainstream computer vision SSL frameworks are based on Siamese network architecture. These approaches often rely on cleverly crafted loss functions and training setups to avoid feature collapse. In this study, we evaluate if those computer-vision SSL frameworks are also effective on a different modality (\textit{i.e.,} time series). The effectiveness is experimented and evaluated on the UCR and UEA archives, and we show that the computer vision SSL frameworks can be effective even for time series. In addition, we propose a new method that improves on the recently proposed VICReg method. Our method improves on a \textit{covariance} term proposed in VICReg, and in addition we augment the head of the architecture by an iterative normalization layer that accelerates the convergence of the model.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21160;&#24577;&#21327;&#21464;&#37327;&#24179;&#34913;&#26041;&#27861;&#65292;&#22522;&#20110;&#36807;&#21435;&#21382;&#21490;&#19978;&#28508;&#22312;&#32467;&#26524;&#26399;&#26395;&#30340;&#23616;&#37096;&#25237;&#24433;&#65292;&#20272;&#35745;&#38754;&#26495;&#25968;&#25454;&#20013;&#21160;&#24577;&#21464;&#21270;&#30340;&#27835;&#30103;&#25928;&#26524;&#65292;&#24182;&#32771;&#34385;&#32467;&#26524;&#21644;&#26102;&#38388;&#21464;&#21270;&#30340;&#21327;&#21464;&#37327;&#19982;&#27835;&#30103;&#36712;&#36857;&#30340;&#20851;&#31995;&#20197;&#21450;&#27835;&#30103;&#25928;&#24212;&#30340;&#24322;&#36136;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#20855;&#26377;&#33391;&#22909;&#30340;&#28176;&#36817;&#24615;&#36136;&#21644;&#25968;&#20540;&#29305;&#24615;&#65292;&#22312;&#23454;&#35777;&#24212;&#29992;&#20013;&#20855;&#26377;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2103.01280</link><description>&lt;p&gt;
&#21160;&#24577;&#21327;&#21464;&#37327;&#24179;&#34913;&#65306;&#22522;&#20110;&#28508;&#22312;&#23616;&#37096;&#25237;&#24433;&#30340;&#27835;&#30103;&#25928;&#26524;&#38543;&#26102;&#38388;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Dynamic covariate balancing: estimating treatment effects over time with potential local projections. (arXiv:2103.01280v3 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2103.01280
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#21160;&#24577;&#21327;&#21464;&#37327;&#24179;&#34913;&#26041;&#27861;&#65292;&#22522;&#20110;&#36807;&#21435;&#21382;&#21490;&#19978;&#28508;&#22312;&#32467;&#26524;&#26399;&#26395;&#30340;&#23616;&#37096;&#25237;&#24433;&#65292;&#20272;&#35745;&#38754;&#26495;&#25968;&#25454;&#20013;&#21160;&#24577;&#21464;&#21270;&#30340;&#27835;&#30103;&#25928;&#26524;&#65292;&#24182;&#32771;&#34385;&#32467;&#26524;&#21644;&#26102;&#38388;&#21464;&#21270;&#30340;&#21327;&#21464;&#37327;&#19982;&#27835;&#30103;&#36712;&#36857;&#30340;&#20851;&#31995;&#20197;&#21450;&#27835;&#30103;&#25928;&#24212;&#30340;&#24322;&#36136;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#20855;&#26377;&#33391;&#22909;&#30340;&#28176;&#36817;&#24615;&#36136;&#21644;&#25968;&#20540;&#29305;&#24615;&#65292;&#22312;&#23454;&#35777;&#24212;&#29992;&#20013;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38754;&#26495;&#25968;&#25454;&#20013;&#27835;&#30103;&#21382;&#21490;&#30340;&#20272;&#35745;&#21644;&#25512;&#26029;&#38382;&#39064;&#65292;&#29305;&#21035;&#26159;&#22312;&#27835;&#30103;&#22312;&#26102;&#38388;&#19978;&#21160;&#24577;&#21464;&#21270;&#30340;&#24773;&#20917;&#19979;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#20801;&#35768;&#27835;&#30103;&#26681;&#25454;&#39640;&#32500;&#21327;&#21464;&#37327;&#12289;&#36807;&#21435;&#30340;&#32467;&#26524;&#21644;&#27835;&#30103;&#21160;&#24577;&#20998;&#37197;&#65292;&#21516;&#26102;&#32771;&#34385;&#32467;&#26524;&#21644;&#26102;&#38388;&#21464;&#21270;&#30340;&#21327;&#21464;&#37327;&#19982;&#27835;&#30103;&#36712;&#36857;&#30340;&#20851;&#31995;&#65292;&#20197;&#21450;&#27835;&#30103;&#25928;&#24212;&#30340;&#24322;&#36136;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#22312;&#36807;&#21435;&#21382;&#21490;&#19978;&#23545;&#28508;&#22312;&#32467;&#26524;&#26399;&#26395;&#36827;&#34892;&#36882;&#24402;&#25237;&#24433;&#65292;&#28982;&#21518;&#36890;&#36807;&#24179;&#34913;&#21160;&#24577;&#21487;&#35266;&#27979;&#29305;&#24449;&#26469;&#25511;&#21046;&#20559;&#24046;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#20272;&#35745;&#37327;&#30340;&#28176;&#36817;&#24615;&#36136;&#21644;&#25968;&#20540;&#29305;&#24615;&#65292;&#24182;&#22312;&#23454;&#35777;&#24212;&#29992;&#20013;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the estimation and inference of treatment histories in panel data settings when treatments change dynamically over time.  We propose a method that allows for (i) treatments to be assigned dynamically over time based on high-dimensional covariates, past outcomes and treatments; (ii) outcomes and time-varying covariates to depend on treatment trajectories; (iii) heterogeneity of treatment effects.  Our approach recursively projects potential outcomes' expectations on past histories. It then controls the bias by balancing dynamically observable characteristics. We study the asymptotic and numerical properties of the estimator and illustrate the benefits of the procedure in an empirical application.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21487;&#20197;&#23545;&#20219;&#24847;&#21442;&#25968;&#32500;&#24230;&#19979;&#30340;&#20219;&#24847;&#22495;&#20869;&#27491;&#24577;&#20998;&#24067;&#36827;&#34892;&#31215;&#20998;&#30340;&#26041;&#27861;&#65292;&#25552;&#20379;&#20102;&#27861;&#21521;&#21521;&#37327;&#20989;&#25968;&#30340;&#30456;&#20851;&#27010;&#29575;&#23494;&#24230;&#21644;&#32479;&#35745;&#25351;&#26631;&#65292;&#21516;&#26102;&#36824;&#25552;&#20379;&#20102;&#21487;&#20197;&#23545;&#20219;&#24847;&#25968;&#37327;&#27491;&#24577;&#20998;&#24067;&#36827;&#34892;&#20998;&#31867;&#30340;&#26041;&#27861;&#21644;&#32500;&#24230;&#38477;&#20302;&#21644;&#21487;&#35270;&#21270;&#30340;&#25216;&#26415;&#12290;</title><link>http://arxiv.org/abs/2012.14331</link><description>&lt;p&gt;
&#19968;&#31181;&#25972;&#21512;&#21644;&#20998;&#31867;&#27491;&#24577;&#20998;&#24067;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A method to integrate and classify normal distributions. (arXiv:2012.14331v8 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2012.14331
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21487;&#20197;&#23545;&#20219;&#24847;&#21442;&#25968;&#32500;&#24230;&#19979;&#30340;&#20219;&#24847;&#22495;&#20869;&#27491;&#24577;&#20998;&#24067;&#36827;&#34892;&#31215;&#20998;&#30340;&#26041;&#27861;&#65292;&#25552;&#20379;&#20102;&#27861;&#21521;&#21521;&#37327;&#20989;&#25968;&#30340;&#30456;&#20851;&#27010;&#29575;&#23494;&#24230;&#21644;&#32479;&#35745;&#25351;&#26631;&#65292;&#21516;&#26102;&#36824;&#25552;&#20379;&#20102;&#21487;&#20197;&#23545;&#20219;&#24847;&#25968;&#37327;&#27491;&#24577;&#20998;&#24067;&#36827;&#34892;&#20998;&#31867;&#30340;&#26041;&#27861;&#21644;&#32500;&#24230;&#38477;&#20302;&#21644;&#21487;&#35270;&#21270;&#30340;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21333;&#21464;&#37327;&#21644;&#22810;&#21464;&#37327;&#27491;&#24577;&#27010;&#29575;&#20998;&#24067;&#22312;&#27169;&#25311;&#19981;&#30830;&#23450;&#24615;&#20915;&#31574;&#20013;&#34987;&#24191;&#27867;&#20351;&#29992;&#12290;&#35745;&#31639;&#36825;&#20123;&#27169;&#22411;&#30340;&#24615;&#33021;&#38656;&#35201;&#22312;&#29305;&#23450;&#21306;&#22495;&#20869;&#23545;&#36825;&#20123;&#20998;&#24067;&#36827;&#34892;&#31215;&#20998;&#65292;&#36825;&#22312;&#19981;&#21516;&#30340;&#27169;&#22411;&#20013;&#21487;&#20197;&#26377;&#24456;&#22823;&#30340;&#24046;&#24322;&#12290;&#38500;&#20102;&#19968;&#20123;&#29305;&#27530;&#24773;&#20917;&#65292;&#30446;&#21069;&#19981;&#23384;&#22312;&#36890;&#29992;&#30340;&#20998;&#26512;&#34920;&#36798;&#24335;&#12289;&#26631;&#20934;&#25968;&#20540;&#26041;&#27861;&#25110;&#36719;&#20214;&#26469;&#35745;&#31639;&#36825;&#20123;&#31215;&#20998;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#25968;&#23398;&#32467;&#26524;&#21644;&#24320;&#28304;&#36719;&#20214;&#65292;&#21487;&#20197;&#25552;&#20379;&#20197;&#19979;&#20869;&#23481;&#65306;&#65288;i&#65289;&#20219;&#24847;&#21442;&#25968;&#32500;&#24230;&#19979;&#20219;&#24847;&#22495;&#20869;&#27861;&#21521;&#30340;&#27010;&#29575;&#65292;&#65288;ii&#65289;&#27861;&#21521;&#21521;&#37327;&#20989;&#25968;&#30340;&#27010;&#29575;&#23494;&#24230;&#12289;&#32047;&#31215;&#20998;&#24067;&#21644;&#36870;&#32047;&#31215;&#20998;&#24067;&#65292;&#65288;iii&#65289;&#20219;&#24847;&#25968;&#37327;&#27491;&#24577;&#20998;&#24067;&#20043;&#38388;&#30340;&#20998;&#31867;&#35823;&#24046;&#12289;&#36125;&#21494;&#26031;&#26368;&#20248;&#36776;&#21035;&#25351;&#25968;&#20197;&#21450;&#20854;&#19982;&#24037;&#20316;&#29305;&#24449;&#26354;&#32447;&#30340;&#20851;&#31995;&#65292;&#65288;iv&#65289;&#27492;&#31867;&#38382;&#39064;&#30340;&#32500;&#24230;&#38477;&#20302;&#21644;&#21487;&#35270;&#21270;&#65292;&#20197;&#21450;&#65288;v&#65289;&#23545;&#20110;&#32473;&#23450;&#25968;&#25454;&#36825;&#20123;&#26041;&#27861;&#30340;&#21487;&#38752;&#24615;&#27979;&#35797;&#12290;&#25105;&#20204;&#36890;&#36807;&#20960;&#20010;&#20855;&#20307;&#30340;&#20363;&#23376;&#65292;&#21253;&#25324;&#37329;&#34701;&#12289;&#29983;&#29289;&#21644;&#24515;&#29702;&#23398;&#26469;&#28436;&#31034;&#36825;&#20123;&#21151;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Univariate and multivariate normal probability distributions are widely used when modeling decisions under uncertainty. Computing the performance of such models requires integrating these distributions over specific domains, which can vary widely across models. Besides some special cases, there exist no general analytical expressions, standard numerical methods or software for these integrals. Here we present mathematical results and open-source software that provide (i) the probability in any domain of a normal in any dimensions with any parameters, (ii) the probability density, cumulative distribution, and inverse cumulative distribution of any function of a normal vector, (iii) the classification errors among any number of normal distributions, the Bayes-optimal discriminability index and relation to the operating characteristic, (iv) dimension reduction and visualizations for such problems, and (v) tests for how reliably these methods may be used on given data. We demonstrate these
&lt;/p&gt;</description></item><item><title>&#36873;&#25321;&#21512;&#36866;&#30340;&#20803;&#23398;&#20064;&#22120;&#23545;&#20110;&#22810;&#35270;&#35282;&#22534;&#21472;&#20013;&#30340;&#35270;&#22270;&#36873;&#25321;&#21644;&#20998;&#31867;&#20934;&#30830;&#24615;&#26159;&#38750;&#24120;&#37325;&#35201;&#30340;&#65292;&#36890;&#36807;&#23545;&#19971;&#31181;&#19981;&#21516;&#30340;&#31639;&#27861;&#36827;&#34892;&#35780;&#20272;&#65292;&#38750;&#36127;&#22871;&#32034;&#12289;&#38750;&#36127;&#33258;&#36866;&#24212;&#22871;&#32034;&#21644;&#38750;&#36127;&#24377;&#24615;&#32593;&#32476;&#34987;&#35748;&#20026;&#26159;&#26368;&#21512;&#36866;&#30340;&#20803;&#23398;&#20064;&#22120;&#12290;</title><link>http://arxiv.org/abs/2010.16271</link><description>&lt;p&gt;
&#22810;&#35270;&#35282;&#22534;&#21472;&#20013;&#30340;&#35270;&#22270;&#36873;&#25321;&#65306;&#36873;&#25321;&#20803;&#23398;&#20064;&#22120;
&lt;/p&gt;
&lt;p&gt;
View selection in multi-view stacking: Choosing the meta-learner. (arXiv:2010.16271v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2010.16271
&lt;/p&gt;
&lt;p&gt;
&#36873;&#25321;&#21512;&#36866;&#30340;&#20803;&#23398;&#20064;&#22120;&#23545;&#20110;&#22810;&#35270;&#35282;&#22534;&#21472;&#20013;&#30340;&#35270;&#22270;&#36873;&#25321;&#21644;&#20998;&#31867;&#20934;&#30830;&#24615;&#26159;&#38750;&#24120;&#37325;&#35201;&#30340;&#65292;&#36890;&#36807;&#23545;&#19971;&#31181;&#19981;&#21516;&#30340;&#31639;&#27861;&#36827;&#34892;&#35780;&#20272;&#65292;&#38750;&#36127;&#22871;&#32034;&#12289;&#38750;&#36127;&#33258;&#36866;&#24212;&#22871;&#32034;&#21644;&#38750;&#36127;&#24377;&#24615;&#32593;&#32476;&#34987;&#35748;&#20026;&#26159;&#26368;&#21512;&#36866;&#30340;&#20803;&#23398;&#20064;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#35270;&#35282;&#22534;&#21472;&#26159;&#19968;&#31181;&#23558;&#26469;&#33258;&#19981;&#21516;&#35270;&#22270;&#65288;&#21363;&#19981;&#21516;&#30340;&#29305;&#24449;&#38598;&#65289;&#25551;&#36848;&#30456;&#21516;&#23545;&#35937;&#30340;&#20449;&#24687;&#30456;&#32467;&#21512;&#30340;&#26694;&#26550;&#12290;&#22312;&#35813;&#26694;&#26550;&#20013;&#65292;&#22522;&#23398;&#20064;&#31639;&#27861;&#20998;&#21035;&#22312;&#27599;&#20010;&#35270;&#22270;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#23427;&#20204;&#30340;&#39044;&#27979;&#32467;&#26524;&#30001;&#20803;&#23398;&#20064;&#31639;&#27861;&#32452;&#21512;&#12290;&#22312;&#20043;&#21069;&#30340;&#30740;&#31350;&#20013;&#65292;&#22534;&#21472;&#30340;&#32602;&#20998;&#36923;&#36753;&#22238;&#24402;&#65292;&#20316;&#20026;&#22810;&#35270;&#35282;&#22534;&#21472;&#30340;&#19968;&#31181;&#29305;&#27530;&#24773;&#20917;&#65292;&#24050;&#34987;&#35777;&#26126;&#22312;&#35782;&#21035;&#23545;&#39044;&#27979;&#26368;&#37325;&#35201;&#30340;&#35270;&#22270;&#26041;&#38754;&#26159;&#26377;&#29992;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#32771;&#34385;&#19971;&#31181;&#19981;&#21516;&#30340;&#31639;&#27861;&#20316;&#20026;&#20803;&#23398;&#20064;&#22120;&#65292;&#24182;&#22312;&#27169;&#25311;&#21644;&#20004;&#20010;&#30495;&#23454;&#30340;&#22522;&#22240;&#34920;&#36798;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#23427;&#20204;&#30340;&#35270;&#22270;&#36873;&#25321;&#21644;&#20998;&#31867;&#24615;&#33021;&#65292;&#25193;&#23637;&#20102;&#36825;&#39033;&#30740;&#31350;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#22914;&#26524;&#35270;&#22270;&#36873;&#25321;&#21644;&#20998;&#31867;&#20934;&#30830;&#24615;&#23545;&#30740;&#31350;&#37117;&#24456;&#37325;&#35201;&#65292;&#37027;&#20040;&#38750;&#36127;&#22871;&#32034;&#12289;&#38750;&#36127;&#33258;&#36866;&#24212;&#22871;&#32034;&#21644;&#38750;&#36127;&#24377;&#24615;&#32593;&#32476;&#37117;&#26159;&#21512;&#36866;&#30340;&#20803;&#23398;&#20064;&#22120;&#12290;&#20855;&#20307;&#22312;&#36825;&#19977;&#31181;&#26041;&#27861;&#20013;&#35813;&#36873;&#25321;&#21738;&#19968;&#31181;&#21462;&#20915;&#20110;...
&lt;/p&gt;
&lt;p&gt;
Multi-view stacking is a framework for combining information from different views (i.e. different feature sets) describing the same set of objects. In this framework, a base-learner algorithm is trained on each view separately, and their predictions are then combined by a meta-learner algorithm. In a previous study, stacked penalized logistic regression, a special case of multi-view stacking, has been shown to be useful in identifying which views are most important for prediction. In this article we expand this research by considering seven different algorithms to use as the meta-learner, and evaluating their view selection and classification performance in simulations and two applications on real gene-expression data sets. Our results suggest that if both view selection and classification accuracy are important to the research at hand, then the nonnegative lasso, nonnegative adaptive lasso and nonnegative elastic net are suitable meta-learners. Exactly which among these three is to be
&lt;/p&gt;</description></item><item><title>&#12298;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#30452;&#35266;&#25945;&#31243;&#12299;&#26159;&#19968;&#31687;&#20171;&#32461;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#25945;&#31243;&#65292;&#26088;&#22312;&#30452;&#35266;&#22320;&#35299;&#37322;GPR&#30340;&#22522;&#26412;&#27010;&#24565;&#12289;&#25552;&#20379;&#23454;&#29616;&#20195;&#30721;&#65292;&#24182;&#22238;&#39038;&#26368;&#20808;&#36827;&#30340;&#39640;&#26031;&#36807;&#31243;&#31639;&#27861;&#12290;&#36866;&#21512;&#26426;&#22120;&#23398;&#20064;&#21021;&#23398;&#32773;&#38405;&#35835;&#65292;&#24110;&#21161;&#20182;&#20204;&#28165;&#26224;&#29702;&#35299;GPR&#30340;&#22522;&#26412;&#21407;&#29702;&#12290;</title><link>http://arxiv.org/abs/2009.10862</link><description>&lt;p&gt;
&#12298;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#30452;&#35266;&#25945;&#31243;&#12299;
&lt;/p&gt;
&lt;p&gt;
An Intuitive Tutorial to Gaussian Process Regression. (arXiv:2009.10862v5 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2009.10862
&lt;/p&gt;
&lt;p&gt;
&#12298;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#30452;&#35266;&#25945;&#31243;&#12299;&#26159;&#19968;&#31687;&#20171;&#32461;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#25945;&#31243;&#65292;&#26088;&#22312;&#30452;&#35266;&#22320;&#35299;&#37322;GPR&#30340;&#22522;&#26412;&#27010;&#24565;&#12289;&#25552;&#20379;&#23454;&#29616;&#20195;&#30721;&#65292;&#24182;&#22238;&#39038;&#26368;&#20808;&#36827;&#30340;&#39640;&#26031;&#36807;&#31243;&#31639;&#27861;&#12290;&#36866;&#21512;&#26426;&#22120;&#23398;&#20064;&#21021;&#23398;&#32773;&#38405;&#35835;&#65292;&#24110;&#21161;&#20182;&#20204;&#28165;&#26224;&#29702;&#35299;GPR&#30340;&#22522;&#26412;&#21407;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25945;&#31243;&#26088;&#22312;&#30452;&#35266;&#20171;&#32461;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#65288;GPR&#65289;&#12290;&#30001;&#20110;&#20854;&#28789;&#27963;&#24615;&#21644;&#23545;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#22266;&#26377;&#33021;&#21147;&#65292;GPR&#27169;&#22411;&#22312;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#24471;&#21040;&#24191;&#27867;&#24212;&#29992;&#12290;&#25945;&#31243;&#20174;&#35299;&#37322;&#39640;&#26031;&#36807;&#31243;&#26500;&#24314;&#30340;&#22522;&#26412;&#27010;&#24565;&#24320;&#22987;&#65292;&#21253;&#25324;&#22810;&#20803;&#27491;&#24577;&#20998;&#24067;&#12289;&#26680;&#20989;&#25968;&#12289;&#38750;&#21442;&#25968;&#27169;&#22411;&#20197;&#21450;&#32852;&#21512;&#27010;&#29575;&#21644;&#26465;&#20214;&#27010;&#29575;&#12290;&#28982;&#21518;&#65292;&#23427;&#25552;&#20379;&#20102;&#23545;GPR&#30340;&#31616;&#26126;&#25551;&#36848;&#21644;&#26631;&#20934;GPR&#31639;&#27861;&#30340;&#23454;&#29616;&#12290;&#27492;&#22806;&#65292;&#25945;&#31243;&#36824;&#22238;&#39038;&#20102;&#23454;&#29616;&#26368;&#20808;&#36827;&#30340;&#39640;&#26031;&#36807;&#31243;&#31639;&#27861;&#30340;&#36719;&#20214;&#21253;&#12290;&#26412;&#25945;&#31243;&#36866;&#29992;&#20110;&#24191;&#27867;&#30340;&#21463;&#20247;&#65292;&#21253;&#25324;&#23545;&#26426;&#22120;&#23398;&#20064;&#19981;&#29087;&#24713;&#30340;&#20154;&#65292;&#20197;&#30830;&#20445;&#23545;GPR&#30340;&#22522;&#26412;&#21407;&#29702;&#26377;&#28165;&#26224;&#30340;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
This tutorial aims to provide an intuitive introduction to Gaussian process regression (GPR). GPR models have been widely used in machine learning applications due to their representation flexibility and inherent capability to quantify uncertainty over predictions. The tutorial starts with explaining the basic concepts that a Gaussian process is built on, including multivariate normal distribution, kernels, non-parametric models, and joint and conditional probability. It then provides a concise description of GPR and an implementation of a standard GPR algorithm. In addition, the tutorial reviews packages for implementing state-of-the-art Gaussian process algorithms. This tutorial is accessible to a broad audience, including those new to machine learning, ensuring a clear understanding of GPR fundamentals.
&lt;/p&gt;</description></item><item><title>&#22312;&#38750;&#20984;&#20248;&#21270;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#38543;&#26426;&#26799;&#24230;&#21704;&#23494;&#39039;&#33945;&#29305;&#21345;&#32599;&#65288;SGHMC&#65289;&#30340;&#38750;&#28176;&#36827;&#24615;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;SGHMC&#20316;&#20026;&#37319;&#26679;&#22120;&#30340;&#20851;&#38190;&#29702;&#35770;&#24615;&#36136;&#65292;&#24182;&#22312;&#23616;&#37096;&#26465;&#20214;&#19979;&#33719;&#24471;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#30340;&#38750;&#28176;&#36827;&#24615;&#30028;&#38480;&#65292;&#35813;&#26041;&#27861;&#22312;&#36845;&#20195;&#27425;&#25968;&#19978;&#21487;&#20197;&#25552;&#20379;&#39640;&#31934;&#24230;&#30340;&#32467;&#26524;&#65292;&#24182;&#20197;&#24050;&#30693;&#26368;&#20339;&#36895;&#29575;&#25910;&#25947;&#21040;&#20840;&#23616;&#26368;&#23567;&#20540;&#12290;</title><link>http://arxiv.org/abs/2002.05465</link><description>&lt;p&gt;
&#38750;&#28176;&#36827;&#24615;&#20998;&#26512;&#20013;&#30340;&#38543;&#26426;&#26799;&#24230;&#21704;&#23494;&#39039;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#22312;&#38750;&#20984;&#20248;&#21270;&#20013;&#30340;&#23616;&#37096;&#26465;&#20214;&#19979;
&lt;/p&gt;
&lt;p&gt;
Nonasymptotic analysis of Stochastic Gradient Hamiltonian Monte Carlo under local conditions for nonconvex optimization. (arXiv:2002.05465v4 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2002.05465
&lt;/p&gt;
&lt;p&gt;
&#22312;&#38750;&#20984;&#20248;&#21270;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#38543;&#26426;&#26799;&#24230;&#21704;&#23494;&#39039;&#33945;&#29305;&#21345;&#32599;&#65288;SGHMC&#65289;&#30340;&#38750;&#28176;&#36827;&#24615;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;SGHMC&#20316;&#20026;&#37319;&#26679;&#22120;&#30340;&#20851;&#38190;&#29702;&#35770;&#24615;&#36136;&#65292;&#24182;&#22312;&#23616;&#37096;&#26465;&#20214;&#19979;&#33719;&#24471;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#30340;&#38750;&#28176;&#36827;&#24615;&#30028;&#38480;&#65292;&#35813;&#26041;&#27861;&#22312;&#36845;&#20195;&#27425;&#25968;&#19978;&#21487;&#20197;&#25552;&#20379;&#39640;&#31934;&#24230;&#30340;&#32467;&#26524;&#65292;&#24182;&#20197;&#24050;&#30693;&#26368;&#20339;&#36895;&#29575;&#25910;&#25947;&#21040;&#20840;&#23616;&#26368;&#23567;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#19981;&#20551;&#35774;&#23545;&#25968;&#20985;&#24615;&#30340;&#24773;&#20917;&#19979;&#65292;&#23545;&#38543;&#26426;&#26799;&#24230;&#21704;&#23494;&#39039;&#33945;&#29305;&#21345;&#32599;&#65288;SGHMC&#65289;&#30340;&#25910;&#25947;&#24615;&#36827;&#34892;&#20102;&#38750;&#28176;&#36827;&#24615;&#20998;&#26512;&#65292;&#20197;Wasserstein-2&#36317;&#31163;&#34913;&#37327;&#23427;&#21040;&#30446;&#26631;&#27979;&#24230;&#30340;&#25910;&#25947;&#31243;&#24230;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#22312;&#23616;&#37096;&#26465;&#20214;&#19979;&#65292;&#37327;&#21270;&#20102;SGHMC&#20316;&#20026;&#37319;&#26679;&#22120;&#30340;&#20851;&#38190;&#29702;&#35770;&#24615;&#36136;&#65292;&#26174;&#33879;&#25913;&#36827;&#20102;&#20043;&#21069;&#32467;&#26524;&#30340;&#21457;&#29616;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#30446;&#26631;&#19982;SGHMC&#27861;&#21017;&#20043;&#38388;&#30340;Wasserstein-2&#36317;&#31163;&#30001;&#31639;&#27861;&#30340;&#27493;&#38271;&#32479;&#19968;&#25511;&#21046;&#65292;&#20174;&#32780;&#35777;&#26126;&#20102;SGHMC&#22312;&#36845;&#20195;&#27425;&#25968;&#19978;&#21487;&#20197;&#25552;&#20379;&#39640;&#31934;&#24230;&#30340;&#32467;&#26524;&#12290;&#35813;&#20998;&#26512;&#36824;&#20351;&#25105;&#20204;&#33021;&#22815;&#22312;&#23616;&#37096;&#26465;&#20214;&#19979;&#33719;&#24471;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#30340;&#38750;&#28176;&#36827;&#24615;&#30028;&#38480;&#65292;&#24182;&#24847;&#21619;&#30528;&#23558;SGHMC&#35270;&#20026;&#38750;&#20984;&#20248;&#21270;&#22120;&#26102;&#65292;&#23427;&#20197;&#24050;&#30693;&#26368;&#20339;&#36895;&#29575;&#25910;&#25947;&#21040;&#20840;&#23616;&#26368;&#23567;&#20540;&#12290;&#25105;&#20204;&#24212;&#29992;&#25105;&#20204;&#30340;&#32467;&#26524;&#26469;&#33719;&#24471;&#21487;&#25193;&#23637;&#30340;&#36125;&#21494;&#26031;&#25512;&#29702;&#21644;&#38750;&#28176;&#36827;&#24615;&#27867;&#21270;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
We provide a nonasymptotic analysis of the convergence of the stochastic gradient Hamiltonian Monte Carlo (SGHMC) to a target measure in Wasserstein-2 distance without assuming log-concavity. Our analysis quantifies key theoretical properties of the SGHMC as a sampler under local conditions which significantly improves the findings of previous results. In particular, we prove that the Wasserstein-2 distance between the target and the law of the SGHMC is uniformly controlled by the step-size of the algorithm, therefore demonstrate that the SGHMC can provide high-precision results uniformly in the number of iterations. The analysis also allows us to obtain nonasymptotic bounds for nonconvex optimization problems under local conditions and implies that the SGHMC, when viewed as a nonconvex optimizer, converges to a global minimum with the best known rates. We apply our results to obtain nonasymptotic bounds for scalable Bayesian inference and nonasymptotic generalization bounds.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#20803;&#26799;&#24230;&#26041;&#24335;&#23545;&#22270;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#35757;&#32451;&#26102;&#25915;&#20987;&#65292;&#36890;&#36807;&#24494;&#23567;&#30340;&#22270;&#25200;&#21160;&#23548;&#33268;&#24615;&#33021;&#19979;&#38477;&#65292;&#24182;&#35777;&#26126;&#20102;&#21363;&#20351;&#22312;&#26080;&#30417;&#30563;&#23884;&#20837;&#20013;&#20063;&#33021;&#20135;&#29983;&#36801;&#31227;&#25928;&#24212;&#12290;&#36825;&#20123;&#25915;&#20987;&#19981;&#38656;&#35201;&#20219;&#20309;&#20851;&#20110;&#30446;&#26631;&#20998;&#31867;&#22120;&#30340;&#30693;&#35782;&#25110;&#35775;&#38382;&#26435;&#38480;&#12290;</title><link>http://arxiv.org/abs/1902.08412</link><description>&lt;p&gt;
&#36890;&#36807;&#20803;&#23398;&#20064;&#23545;&#22270;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#23545;&#25239;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Adversarial Attacks on Graph Neural Networks via Meta Learning. (arXiv:1902.08412v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1902.08412
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#20803;&#26799;&#24230;&#26041;&#24335;&#23545;&#22270;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#35757;&#32451;&#26102;&#25915;&#20987;&#65292;&#36890;&#36807;&#24494;&#23567;&#30340;&#22270;&#25200;&#21160;&#23548;&#33268;&#24615;&#33021;&#19979;&#38477;&#65292;&#24182;&#35777;&#26126;&#20102;&#21363;&#20351;&#22312;&#26080;&#30417;&#30563;&#23884;&#20837;&#20013;&#20063;&#33021;&#20135;&#29983;&#36801;&#31227;&#25928;&#24212;&#12290;&#36825;&#20123;&#25915;&#20987;&#19981;&#38656;&#35201;&#20219;&#20309;&#20851;&#20110;&#30446;&#26631;&#20998;&#31867;&#22120;&#30340;&#30693;&#35782;&#25110;&#35775;&#38382;&#26435;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#35768;&#22810;&#20219;&#21153;&#20013;&#24182;&#21462;&#24471;&#20102;&#26368;&#26032;&#30340;&#25104;&#21151;&#65292;&#20294;&#23427;&#20204;&#30340;&#40065;&#26834;&#24615;&#36824;&#30693;&#20043;&#29978;&#23569;&#12290;&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#23545;&#33410;&#28857;&#20998;&#31867;&#20013;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#30340;&#35757;&#32451;&#26102;&#25915;&#20987;&#65292;&#22312;&#31163;&#25955;&#22270;&#32467;&#26500;&#19978;&#36827;&#34892;&#24494;&#23567;&#25200;&#21160;&#12290;&#25105;&#20204;&#30340;&#26680;&#24515;&#21407;&#21017;&#26159;&#20351;&#29992;&#20803;&#26799;&#24230;&#26469;&#35299;&#20915;&#35757;&#32451;&#26102;&#25915;&#20987;&#32972;&#21518;&#30340;&#21452;&#23618;&#38382;&#39064;&#65292;&#26412;&#36136;&#19978;&#23558;&#22270;&#35270;&#20026;&#20248;&#21270;&#30340;&#36229;&#21442;&#25968;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#24494;&#23567;&#30340;&#22270;&#25200;&#21160;&#36890;&#24120;&#20250;&#23548;&#33268;&#22270;&#21367;&#31215;&#32593;&#32476;&#24615;&#33021;&#30340;&#22823;&#24133;&#19979;&#38477;&#65292;&#29978;&#33267;&#20256;&#36882;&#32473;&#26080;&#30417;&#30563;&#23884;&#20837;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#25152;&#21019;&#24314;&#30340;&#25200;&#21160;&#21487;&#20197;&#35823;&#23548;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#20351;&#20854;&#24615;&#33021;&#27604;&#24573;&#30053;&#25152;&#26377;&#20851;&#32852;&#20449;&#24687;&#30340;&#31616;&#21333;&#22522;&#32447;&#27169;&#22411;&#26356;&#24046;&#12290;&#25105;&#20204;&#30340;&#25915;&#20987;&#19981;&#38656;&#35201;&#20219;&#20309;&#20851;&#20110;&#30446;&#26631;&#20998;&#31867;&#22120;&#30340;&#30693;&#35782;&#25110;&#35775;&#38382;&#26435;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning models for graphs have advanced the state of the art on many tasks. Despite their recent success, little is known about their robustness. We investigate training time attacks on graph neural networks for node classification that perturb the discrete graph structure. Our core principle is to use meta-gradients to solve the bilevel problem underlying training-time attacks, essentially treating the graph as a hyperparameter to optimize. Our experiments show that small graph perturbations consistently lead to a strong decrease in performance for graph convolutional networks, and even transfer to unsupervised embeddings. Remarkably, the perturbations created by our algorithm can misguide the graph neural networks such that they perform worse than a simple baseline that ignores all relational information. Our attacks do not assume any knowledge about or access to the target classifiers.
&lt;/p&gt;</description></item></channel></rss>