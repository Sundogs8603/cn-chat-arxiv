<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#27169;&#22411;&#35268;&#33539;&#38169;&#35823;&#30340;&#26465;&#20214;&#19979;&#65292;&#30001;&#20110;&#20998;&#24067;&#36716;&#21464;&#23548;&#33268;&#30340;&#38169;&#35823;&#25918;&#22823;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.12216</link><description>&lt;p&gt;
&#29992;&#20110;&#20943;&#36731;&#20998;&#24067;&#36716;&#21464;&#30340;&#38169;&#35823;&#22238;&#24402;&#30340;&#26041;&#27861;&#21450;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Mitigating Covariate Shift in Misspecified Regression with Applications to Reinforcement Learning. (arXiv:2401.12216v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12216
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#27169;&#22411;&#35268;&#33539;&#38169;&#35823;&#30340;&#26465;&#20214;&#19979;&#65292;&#30001;&#20110;&#20998;&#24067;&#36716;&#21464;&#23548;&#33268;&#30340;&#38169;&#35823;&#25918;&#22823;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#26222;&#36941;&#23384;&#22312;&#30340;&#19968;&#20010;&#29616;&#35937;&#26159;&#20998;&#24067;&#36716;&#21464;&#65292;&#25351;&#30340;&#26159;&#35757;&#32451;&#21644;&#37096;&#32626;&#26465;&#20214;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#30001;&#20110;&#20998;&#24067;&#36716;&#21464;&#36890;&#24120;&#23548;&#33268;&#24615;&#33021;&#19979;&#38477;&#65292;&#22240;&#27492;&#20154;&#20204;&#19968;&#30452;&#33268;&#21147;&#20110;&#31639;&#27861;&#24178;&#39044;&#20197;&#20943;&#36731;&#36825;&#20123;&#19981;&#21033;&#24433;&#21709;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#27169;&#22411;&#35268;&#33539;&#38169;&#35823;&#30340;&#24773;&#20917;&#19979;&#20998;&#24067;&#36716;&#21464;&#30340;&#24433;&#21709;&#65292;&#20855;&#20307;&#20851;&#27880;L&#8734;-&#38169;&#35823;&#22238;&#24402;&#21644;&#23545;&#25239;&#24615;&#21327;&#21464;&#37327;&#36716;&#21464;&#65292;&#20854;&#20013;&#22238;&#24402;&#30446;&#26631;&#20445;&#25345;&#19981;&#21464;&#65292;&#32780;&#21327;&#21464;&#37327;&#20998;&#24067;&#20219;&#24847;&#21464;&#21270;&#12290;&#25105;&#20204;&#21457;&#29616;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#25110;&#26631;&#20934;&#26368;&#23567;&#20108;&#20056;&#22238;&#24402;&#21487;&#33021;&#23548;&#33268;&#19981;&#21487;&#21462;&#30340;&#38169;&#35823;&#25918;&#22823;&#65292;&#20854;&#20013;&#30001;&#20110;&#35268;&#33539;&#38169;&#35823;&#32780;&#20135;&#29983;&#30340;&#35823;&#24046;&#34987;&#35757;&#32451;&#21644;&#27979;&#35797;&#20998;&#24067;&#20043;&#38388;&#30340;&#23494;&#24230;&#27604;&#25918;&#22823;&#12290;&#20316;&#20026;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#8212;&#8212;&#21463;&#40065;&#26834;&#20248;&#21270;&#25216;&#26415;&#21551;&#21457;&#8212;&#8212;&#20197;&#36991;&#20813;&#36825;&#31181;&#19981;&#21487;&#21462;&#30340;&#38169;&#35823;&#25918;&#22823;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;
A pervasive phenomenon in machine learning applications is distribution shift, where training and deployment conditions for a machine learning model differ. As distribution shift typically results in a degradation in performance, much attention has been devoted to algorithmic interventions that mitigate these detrimental effects. In this paper, we study the effect of distribution shift in the presence of model misspecification, specifically focusing on $L_{\infty}$-misspecified regression and adversarial covariate shift, where the regression target remains fixed while the covariate distribution changes arbitrarily. We show that empirical risk minimization, or standard least squares regression, can result in undesirable misspecification amplification where the error due to misspecification is amplified by the density ratio between the training and testing distributions. As our main result, we develop a new algorithm -- inspired by robust optimization techniques -- that avoids this undes
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#38543;&#26426;&#20984;&#20248;&#21270;&#20013;&#26799;&#24230;&#26041;&#27861;&#30340;&#27867;&#21270;&#24615;&#33021;&#20197;&#21450;&#32500;&#24230;&#20381;&#36182;&#24615;&#12290;&#25105;&#20204;&#21457;&#29616;&#26631;&#20934;&#30340;&#20840;&#25209;&#37327;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#22312;&#32500;&#24230;$d = O(n^2)$&#26102;&#38656;&#35201;&#33267;&#23569;$\Omega(\sqrt{d})$&#20010;&#35757;&#32451;&#26679;&#26412;&#25165;&#33021;&#36798;&#21040;&#38750;&#24179;&#20961;&#30340;&#27979;&#35797;&#35823;&#24046;&#12290;&#32780;&#23545;&#20110;&#26631;&#20934;&#30340;&#19968;&#36941;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#21516;&#26679;&#30340;&#32500;&#24230;&#19979;&#30028;&#20063;&#36866;&#29992;&#12290;</title><link>http://arxiv.org/abs/2401.12058</link><description>&lt;p&gt;
&#29992;&#26799;&#24230;&#26469;&#21453;&#20987;&#32500;&#24230;&#65306;&#38543;&#26426;&#20984;&#20248;&#21270;&#20013;&#26799;&#24230;&#26041;&#27861;&#30340;&#27867;&#21270;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
The Dimension Strikes Back with Gradients: Generalization of Gradient Methods in Stochastic Convex Optimization. (arXiv:2401.12058v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12058
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#38543;&#26426;&#20984;&#20248;&#21270;&#20013;&#26799;&#24230;&#26041;&#27861;&#30340;&#27867;&#21270;&#24615;&#33021;&#20197;&#21450;&#32500;&#24230;&#20381;&#36182;&#24615;&#12290;&#25105;&#20204;&#21457;&#29616;&#26631;&#20934;&#30340;&#20840;&#25209;&#37327;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#22312;&#32500;&#24230;$d = O(n^2)$&#26102;&#38656;&#35201;&#33267;&#23569;$\Omega(\sqrt{d})$&#20010;&#35757;&#32451;&#26679;&#26412;&#25165;&#33021;&#36798;&#21040;&#38750;&#24179;&#20961;&#30340;&#27979;&#35797;&#35823;&#24046;&#12290;&#32780;&#23545;&#20110;&#26631;&#20934;&#30340;&#19968;&#36941;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#21516;&#26679;&#30340;&#32500;&#24230;&#19979;&#30028;&#20063;&#36866;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#26799;&#24230;&#26041;&#27861;&#22312;&#22522;&#30784;&#38543;&#26426;&#20984;&#20248;&#21270;&#35774;&#32622;&#20013;&#30340;&#27867;&#21270;&#24615;&#33021;&#65292;&#24182;&#30528;&#37325;&#20851;&#27880;&#20854;&#32500;&#24230;&#20381;&#36182;&#24615;&#12290;&#39318;&#20808;&#65292;&#38024;&#23545;&#20840;&#25209;&#37327;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#65292;&#25105;&#20204;&#26500;&#36896;&#20102;&#19968;&#20010;&#22312;&#32500;&#24230;$d=O(n^2)$&#19979;&#30340;&#23398;&#20064;&#38382;&#39064;&#65292;&#20854;&#20013;&#32463;&#36807;&#35843;&#25972;&#20197;&#36798;&#21040;&#32463;&#39564;&#39118;&#38505;&#30340;&#26368;&#20339;&#24615;&#33021;&#30340;&#26631;&#20934;GD&#65288;&#20351;&#29992;$n$&#20010;&#35757;&#32451;&#26679;&#26412;&#36827;&#34892;&#35757;&#32451;&#65289;&#20197;&#24120;&#25968;&#27010;&#29575;&#25910;&#25947;&#21040;&#19968;&#20010;&#36817;&#20284;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#22120;&#65292;&#20854;&#20154;&#21475;&#36807;&#21097;&#39118;&#38505;&#20026;$\Omega(1)$&#12290;&#25105;&#20204;&#30340;&#30028;&#38480;&#21487;&#20197;&#36716;&#21270;&#20026;&#26631;&#20934;GD&#38656;&#35201;$\Omega(\sqrt{d})$&#20010;&#35757;&#32451;&#26679;&#26412;&#25165;&#33021;&#36798;&#21040;&#38750;&#24179;&#20961;&#30340;&#27979;&#35797;&#35823;&#24046;&#65292;&#20174;&#32780;&#22238;&#31572;&#20102;Feldman&#65288;2016&#65289;&#21644;Amir&#12289;Koren&#12289;Livni&#65288;2021b&#65289;&#25552;&#20986;&#30340;&#19968;&#20010;&#24320;&#25918;&#38382;&#39064;&#65292;&#24182;&#34920;&#26126;&#38750;&#24179;&#20961;&#30340;&#32500;&#24230;&#20381;&#36182;&#24615;&#26159;&#19981;&#21487;&#36991;&#20813;&#30340;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#26631;&#20934;&#30340;&#19968;&#36941;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#65292;&#25105;&#20204;&#21457;&#29616;&#21516;&#26679;&#30340;&#26500;&#36896;&#25216;&#26415;&#21487;&#20197;&#25552;&#20379;&#31867;&#20284;&#30340;$\Omega(\sqrt{d})$&#30340;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the generalization performance of gradient methods in the fundamental stochastic convex optimization setting, focusing on its dimension dependence. First, for full-batch gradient descent (GD) we give a construction of a learning problem in dimension $d=O(n^2)$, where the canonical version of GD (tuned for optimal performance of the empirical risk) trained with $n$ training examples converges, with constant probability, to an approximate empirical risk minimizer with $\Omega(1)$ population excess risk. Our bound translates to a lower bound of $\Omega (\sqrt{d})$ on the number of training examples required for standard GD to reach a non-trivial test error, answering an open question raised by Feldman (2016) and Amir, Koren, and Livni (2021b) and showing that a non-trivial dimension dependence is unavoidable. Furthermore, for standard one-pass stochastic gradient descent (SGD), we show that an application of the same construction technique provides a similar $\Omega(\sqrt{d})$ lo
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#23558;&#32479;&#35745;&#26174;&#33879;&#24615;&#21644;&#21028;&#21035;&#33021;&#21147;&#34701;&#20837;&#27169;&#24335;&#21457;&#29616;&#20013;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#21516;&#26102;&#28385;&#36275;&#27169;&#24335;&#36136;&#37327;&#21644;&#32479;&#35745;&#26631;&#20934;&#65292;&#22312;&#19977;&#20803;&#32858;&#31867;&#20219;&#21153;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.12000</link><description>&lt;p&gt;
&#23558;&#32479;&#35745;&#26174;&#33879;&#24615;&#21644;&#21028;&#21035;&#33021;&#21147;&#34701;&#20837;&#27169;&#24335;&#21457;&#29616;&#20013;
&lt;/p&gt;
&lt;p&gt;
Integrating Statistical Significance and Discriminative Power in Pattern Discovery. (arXiv:2401.12000v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12000
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#23558;&#32479;&#35745;&#26174;&#33879;&#24615;&#21644;&#21028;&#21035;&#33021;&#21147;&#34701;&#20837;&#27169;&#24335;&#21457;&#29616;&#20013;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#21516;&#26102;&#28385;&#36275;&#27169;&#24335;&#36136;&#37327;&#21644;&#32479;&#35745;&#26631;&#20934;&#65292;&#22312;&#19977;&#20803;&#32858;&#31867;&#20219;&#21153;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#24335;&#21457;&#29616;&#22312;&#22810;&#20010;&#39046;&#22495;&#30340;&#25551;&#36848;&#24615;&#21644;&#39044;&#27979;&#24615;&#20219;&#21153;&#20013;&#36215;&#30528;&#26680;&#24515;&#20316;&#29992;&#12290;&#21487;&#25805;&#20316;&#30340;&#27169;&#24335;&#24517;&#39035;&#28385;&#36275;&#20005;&#26684;&#30340;&#32479;&#35745;&#26174;&#33879;&#24615;&#26631;&#20934;&#65292;&#24182;&#19988;&#22312;&#30446;&#26631;&#21464;&#37327;&#23384;&#22312;&#26102;&#36827;&#19968;&#27493;&#20855;&#26377;&#21028;&#21035;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#35299;&#20915;&#20102;&#22312;&#29616;&#26377;&#31639;&#27861;&#20013;&#23558;&#32479;&#35745;&#26174;&#33879;&#24615;&#21644;&#21028;&#21035;&#33021;&#21147;&#26631;&#20934;&#34701;&#20837;&#27169;&#24335;&#21457;&#29616;&#30340;&#23578;&#26410;&#28145;&#20837;&#30740;&#31350;&#30340;&#39046;&#22495;&#65292;&#21516;&#26102;&#20445;&#25345;&#27169;&#24335;&#36136;&#37327;&#12290;&#25105;&#20204;&#36824;&#35299;&#20915;&#20102;&#19968;&#20123;&#31639;&#27861;&#24341;&#20837;&#30340;&#27169;&#24335;&#36136;&#37327;&#38408;&#20540;&#22914;&#20309;&#35843;&#25972;&#20197;&#36866;&#24212;&#36825;&#20123;&#39069;&#22806;&#26631;&#20934;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#27979;&#35797;&#36825;&#31181;&#26041;&#27861;&#65292;&#25105;&#20204;&#36873;&#25321;&#19977;&#20803;&#32858;&#31867;&#20219;&#21153;&#20316;&#20026;&#27169;&#24335;&#21457;&#29616;&#26696;&#20363;&#65292;&#24182;&#25193;&#23637;&#20102;&#20004;&#20010;&#33879;&#21517;&#30340;&#36138;&#23146;&#21644;&#22810;&#30446;&#26631;&#20248;&#21270;&#19977;&#20803;&#32858;&#31867;&#31639;&#27861;&#65292;&#21363;&#948;-Trimax&#21644;TriGen&#65292;&#23427;&#20204;&#20351;&#29992;&#20102;&#21508;&#31181;&#27169;&#24335;&#36136;&#37327;&#26631;&#20934;&#65292;&#20363;&#22914;&#22343;&#26041;&#27531;&#24046;&#65288;MSR&#65289;&#12289;&#26368;&#23567;&#20108;&#20056;&#32447;&#65288;LSL&#65289;&#21644;&#22810;&#26012;&#29575;&#27979;&#37327;&#65288;MSL&#65289;&#12290;&#19977;&#20010;&#26696;&#20363;&#30740;&#31350;&#30340;&#32467;&#26524;&#26174;&#31034;
&lt;/p&gt;
&lt;p&gt;
Pattern discovery plays a central role in both descriptive and predictive tasks across multiple domains. Actionable patterns must meet rigorous statistical significance criteria and, in the presence of target variables, further uphold discriminative power. Our work addresses the underexplored area of guiding pattern discovery by integrating statistical significance and discriminative power criteria into state-of-the-art algorithms while preserving pattern quality. We also address how pattern quality thresholds, imposed by some algorithms, can be rectified to accommodate these additional criteria. To test the proposed methodology, we select the triclustering task as the guiding pattern discovery case and extend well-known greedy and multi-objective optimization triclustering algorithms, $\delta$-Trimax and TriGen, that use various pattern quality criteria, such as Mean Squared Residual (MSR), Least Squared Lines (LSL), and Multi Slope Measure (MSL). Results from three case studies show 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20132;&#21449;&#39564;&#35777;&#30340;&#26032;&#22411;&#21512;&#35268;&#39118;&#38505;&#25511;&#21046;&#26041;&#27861;(CV-CRC)&#65292;&#23427;&#25193;&#23637;&#20102;&#19968;&#33268;&#24615;&#39044;&#27979;&#30340;&#27010;&#24565;&#65292;&#33021;&#22815;&#25511;&#21046;&#26356;&#24191;&#27867;&#30340;&#39118;&#38505;&#20989;&#25968;&#65292;&#24182;&#22312;&#39044;&#27979;&#22120;&#38598;&#21512;&#30340;&#24179;&#22343;&#39118;&#38505;&#19978;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2401.11974</link><description>&lt;p&gt;
&#20132;&#21449;&#39564;&#35777;&#21512;&#35268;&#39118;&#38505;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Cross-Validation Conformal Risk Control. (arXiv:2401.11974v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11974
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20132;&#21449;&#39564;&#35777;&#30340;&#26032;&#22411;&#21512;&#35268;&#39118;&#38505;&#25511;&#21046;&#26041;&#27861;(CV-CRC)&#65292;&#23427;&#25193;&#23637;&#20102;&#19968;&#33268;&#24615;&#39044;&#27979;&#30340;&#27010;&#24565;&#65292;&#33021;&#22815;&#25511;&#21046;&#26356;&#24191;&#27867;&#30340;&#39118;&#38505;&#20989;&#25968;&#65292;&#24182;&#22312;&#39044;&#27979;&#22120;&#38598;&#21512;&#30340;&#24179;&#22343;&#39118;&#38505;&#19978;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21512;&#35268;&#39118;&#38505;&#25511;&#21046;&#65288;CRC&#65289;&#26159;&#19968;&#31181;&#26368;&#36817;&#25552;&#20986;&#30340;&#25216;&#26415;&#65292;&#23427;&#24212;&#29992;&#20110;&#20256;&#32479;&#30340;&#28857;&#39044;&#27979;&#22120;&#19978;&#65292;&#20197;&#25552;&#20379;&#26657;&#20934;&#20445;&#35777;&#12290;&#22312;CRC&#20013;&#25512;&#24191;&#19968;&#33268;&#24615;&#39044;&#27979;&#65288;CP&#65289;&#65292;&#36890;&#36807;&#20174;&#28857;&#39044;&#27979;&#22120;&#20013;&#25552;&#21462;&#19968;&#20010;&#39044;&#27979;&#22120;&#38598;&#21512;&#26469;&#25511;&#21046;&#39118;&#38505;&#20989;&#25968;&#65288;&#22914;&#35823;&#35206;&#30422;&#27010;&#29575;&#25110;&#38169;&#35823;&#36127;&#20363;&#29575;&#65289;&#65292;&#20174;&#32780;&#30830;&#20445;&#26657;&#20934;&#24615;&#12290;&#21407;&#22987;&#30340;CRC&#38656;&#35201;&#23558;&#21487;&#29992;&#25968;&#25454;&#38598;&#20998;&#20026;&#35757;&#32451;&#21644;&#39564;&#35777;&#25968;&#25454;&#38598;&#12290;&#24403;&#25968;&#25454;&#21487;&#29992;&#24615;&#26377;&#38480;&#26102;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#39044;&#27979;&#22120;&#38598;&#21512;&#25928;&#29575;&#20302;&#19979;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#20132;&#21449;&#39564;&#35777;&#32780;&#19981;&#26159;&#21407;&#22987;CRC&#30340;&#26032;&#22411;CRC&#26041;&#27861;&#12290;&#25152;&#25552;&#20986;&#30340;&#20132;&#21449;&#39564;&#35777;CRC&#65288;CV-CRC&#65289;&#23558;CP&#30340;&#19968;&#31181;&#29256;&#26412;&#25193;&#23637;&#21040;CRC&#65292;&#21487;&#20197;&#25511;&#21046;&#26356;&#24191;&#27867;&#30340;&#39118;&#38505;&#20989;&#25968;&#12290;CV-CRC&#34987;&#35777;&#26126;&#22312;&#39044;&#27979;&#22120;&#38598;&#21512;&#30340;&#24179;&#22343;&#39118;&#38505;&#19978;&#20855;&#26377;&#29702;&#35770;&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;CV-CRC&#22312;&#23454;&#36341;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conformal risk control (CRC) is a recently proposed technique that applies post-hoc to a conventional point predictor to provide calibration guarantees. Generalizing conformal prediction (CP), with CRC, calibration is ensured for a set predictor that is extracted from the point predictor to control a risk function such as the probability of miscoverage or the false negative rate. The original CRC requires the available data set to be split between training and validation data sets. This can be problematic when data availability is limited, resulting in inefficient set predictors. In this paper, a novel CRC method is introduced that is based on cross-validation, rather than on validation as the original CRC. The proposed cross-validation CRC (CV-CRC) extends a version of the jackknife-minmax from CP to CRC, allowing for the control of a broader range of risk functions. CV-CRC is proved to offer theoretical guarantees on the average risk of the set predictor. Furthermore, numerical exper
&lt;/p&gt;</description></item><item><title>RUMBoost&#27169;&#22411;&#23558;&#38543;&#26426;&#25928;&#29992;&#27169;&#22411;&#65288;RUMs&#65289;&#30340;&#35299;&#37322;&#24615;&#21644;&#34892;&#20026;&#40065;&#26834;&#24615;&#19982;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#30340;&#27867;&#21270;&#33021;&#21147;&#30456;&#32467;&#21512;&#65292;&#36890;&#36807;&#20351;&#29992;&#26799;&#24230;&#25552;&#21319;&#22238;&#24402;&#26641;&#30340;&#38598;&#21512;&#26469;&#33719;&#24471;&#38750;&#32447;&#24615;&#25928;&#29992;&#20989;&#25968;&#30340;&#23436;&#25972;&#20989;&#25968;&#24418;&#24335;&#65292;&#23454;&#29616;&#20102;&#23545;&#36755;&#20837;&#21464;&#37327;&#30340;&#20219;&#20309;&#21487;&#33021;&#32452;&#21512;&#36827;&#34892;&#24120;&#25968;&#25554;&#34917;&#12290;</title><link>http://arxiv.org/abs/2401.11954</link><description>&lt;p&gt;
RUMBoost&#65306;&#26799;&#24230;&#25552;&#21319;&#30340;&#38543;&#26426;&#25928;&#29992;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
RUMBoost: Gradient Boosted Random Utility Models. (arXiv:2401.11954v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11954
&lt;/p&gt;
&lt;p&gt;
RUMBoost&#27169;&#22411;&#23558;&#38543;&#26426;&#25928;&#29992;&#27169;&#22411;&#65288;RUMs&#65289;&#30340;&#35299;&#37322;&#24615;&#21644;&#34892;&#20026;&#40065;&#26834;&#24615;&#19982;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#30340;&#27867;&#21270;&#33021;&#21147;&#30456;&#32467;&#21512;&#65292;&#36890;&#36807;&#20351;&#29992;&#26799;&#24230;&#25552;&#21319;&#22238;&#24402;&#26641;&#30340;&#38598;&#21512;&#26469;&#33719;&#24471;&#38750;&#32447;&#24615;&#25928;&#29992;&#20989;&#25968;&#30340;&#23436;&#25972;&#20989;&#25968;&#24418;&#24335;&#65292;&#23454;&#29616;&#20102;&#23545;&#36755;&#20837;&#21464;&#37327;&#30340;&#20219;&#20309;&#21487;&#33021;&#32452;&#21512;&#36827;&#34892;&#24120;&#25968;&#25554;&#34917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31163;&#25955;&#36873;&#25321;&#24314;&#27169;&#26041;&#27861;&#65292;RUMBoost&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#23558;&#38543;&#26426;&#25928;&#29992;&#27169;&#22411;&#65288;RUMs&#65289;&#30340;&#21487;&#35299;&#37322;&#24615;&#21644;&#34892;&#20026;&#40065;&#26834;&#24615;&#19982;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#30340;&#27867;&#21270;&#33021;&#21147;&#21644;&#39044;&#27979;&#33021;&#21147;&#30456;&#32467;&#21512;&#12290;&#25105;&#20204;&#36890;&#36807;&#29992;&#26799;&#24230;&#25552;&#21319;&#22238;&#24402;&#26641;&#30340;&#38598;&#21512;&#26367;&#25442;RUM&#30340;&#25928;&#29992;&#20989;&#25968;&#20013;&#30340;&#32447;&#24615;&#21442;&#25968;&#26469;&#33719;&#24471;&#38750;&#32447;&#24615;&#25928;&#29992;&#20989;&#25968;&#30340;&#23436;&#25972;&#20989;&#25968;&#24418;&#24335;&#12290;&#36825;&#20351;&#24471;&#21487;&#20197;&#30452;&#25509;&#20174;&#25968;&#25454;&#20013;&#20026;&#25152;&#26377;&#22791;&#36873;&#26041;&#26696;&#30340;&#25928;&#29992;&#20540;&#36827;&#34892;&#20998;&#27573;&#24120;&#25968;&#25554;&#34917;&#65292;&#20197;&#36866;&#24212;&#20219;&#20309;&#21487;&#33021;&#30340;&#36755;&#20837;&#21464;&#37327;&#32452;&#21512;&#12290;&#25105;&#20204;&#23545;&#38598;&#21512;&#24341;&#20837;&#20102;&#39069;&#22806;&#30340;&#32422;&#26463;&#26465;&#20214;&#65292;&#20197;&#30830;&#20445;&#25928;&#29992;&#20989;&#25968;&#20855;&#26377;&#19977;&#20010;&#20851;&#38190;&#29305;&#24449;&#65306;&#65288;i&#65289;&#27599;&#20010;&#22791;&#36873;&#26041;&#26696;&#30340;&#25928;&#29992;&#20165;&#20381;&#36182;&#20110;&#35813;&#22791;&#36873;&#26041;&#26696;&#30340;&#23646;&#24615;&#65292;&#65288;ii&#65289;&#36793;&#38469;&#25928;&#29992;&#21333;&#35843;&#24615;&#65292;&#20197;&#21450;&#65288;iii&#65289;&#20869;&#22312;&#21487;&#35299;&#37322;&#30340;&#20989;&#25968;&#24418;&#24335;&#65292;&#20351;&#24471;&#27169;&#22411;&#22312;&#25972;&#20010;&#36755;&#20837;&#31354;&#38388;&#20013;&#30340;&#21709;&#24212;&#37117;&#26159;&#24050;&#30693;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces the RUMBoost model, a novel discrete choice modelling approach that combines the interpretability and behavioural robustness of Random Utility Models (RUMs) with the generalisation and predictive ability of deep learning methods. We obtain the full functional form of non-linear utility specifications by replacing each linear parameter in the utility functions of a RUM with an ensemble of gradient boosted regression trees. This enables piece-wise constant utility values to be imputed for all alternatives directly from the data for any possible combination of input variables. We introduce additional constraints on the ensembles to ensure three crucial features of the utility specifications: (i) dependency of the utilities of each alternative on only the attributes of that alternative, (ii) monotonicity of marginal utilities, and (iii) an intrinsically interpretable functional form, where the exact response of the model is known throughout the entire input space. Fur
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20998;&#35299;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#35299;&#20915;&#20302;&#32990;&#29366;&#31209;&#24352;&#37327;&#24674;&#22797;&#38382;&#39064;&#30340;&#39640;&#25928;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#23558;&#22823;&#24352;&#37327;&#20998;&#35299;&#20026;&#20004;&#20010;&#36739;&#23567;&#30340;&#22240;&#23376;&#24352;&#37327;&#65292;&#22312;&#20943;&#23569;&#35745;&#31639;&#25104;&#26412;&#21644;&#23384;&#20648;&#38656;&#27714;&#30340;&#21516;&#26102;&#65292;&#30830;&#20445;&#20102;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.11940</link><description>&lt;p&gt;
&#36890;&#36807;&#20998;&#35299;&#26799;&#24230;&#19979;&#38477;&#23454;&#29616;&#20302;&#32990;&#29366;&#31209;&#24352;&#37327;&#24674;&#22797;
&lt;/p&gt;
&lt;p&gt;
Low-Tubal-Rank Tensor Recovery via Factorized Gradient Descent. (arXiv:2401.11940v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11940
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20998;&#35299;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#35299;&#20915;&#20302;&#32990;&#29366;&#31209;&#24352;&#37327;&#24674;&#22797;&#38382;&#39064;&#30340;&#39640;&#25928;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#23558;&#22823;&#24352;&#37327;&#20998;&#35299;&#20026;&#20004;&#20010;&#36739;&#23567;&#30340;&#22240;&#23376;&#24352;&#37327;&#65292;&#22312;&#20943;&#23569;&#35745;&#31639;&#25104;&#26412;&#21644;&#23384;&#20648;&#38656;&#27714;&#30340;&#21516;&#26102;&#65292;&#30830;&#20445;&#20102;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#23569;&#37327;&#34987;&#30772;&#22351;&#30340;&#32447;&#24615;&#27979;&#37327;&#20013;&#24674;&#22797;&#20855;&#26377;&#20302;&#32990;&#29366;&#31209;&#32467;&#26500;&#30340;&#24352;&#37327;&#30340;&#38382;&#39064;&#12290;&#20256;&#32479;&#26041;&#27861;&#38656;&#35201;&#35745;&#31639;&#24352;&#37327;&#22855;&#24322;&#20540;&#20998;&#35299;&#65288;t-SVD&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#35745;&#31639;&#23494;&#38598;&#30340;&#36807;&#31243;&#65292;&#20351;&#23427;&#20204;&#38590;&#20197;&#22788;&#29702;&#22823;&#35268;&#27169;&#24352;&#37327;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31867;&#20284;&#20110;Burer-Monteiro&#65288;BM&#65289;&#26041;&#27861;&#30340;&#20998;&#35299;&#36807;&#31243;&#30340;&#39640;&#25928;&#20302;&#32990;&#29366;&#31209;&#24352;&#37327;&#24674;&#22797;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#22522;&#26412;&#26041;&#27861;&#28041;&#21450;&#23558;&#19968;&#20010;&#22823;&#24352;&#37327;&#20998;&#35299;&#20026;&#20004;&#20010;&#36739;&#23567;&#30340;&#22240;&#23376;&#24352;&#37327;&#65292;&#28982;&#21518;&#36890;&#36807;&#20998;&#35299;&#26799;&#24230;&#19979;&#38477;&#65288;FGD&#65289;&#26469;&#35299;&#20915;&#38382;&#39064;&#12290;&#35813;&#31574;&#30053;&#28040;&#38500;&#20102;t-SVD&#35745;&#31639;&#30340;&#38656;&#35201;&#65292;&#20174;&#32780;&#20943;&#23569;&#20102;&#35745;&#31639;&#25104;&#26412;&#21644;&#23384;&#20648;&#38656;&#27714;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#20197;&#20445;&#35777;FGD&#22312;&#26080;&#22122;&#22768;&#21644;&#26377;&#22122;&#22768;&#24773;&#20917;&#19979;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper considers the problem of recovering a tensor with an underlying low-tubal-rank structure from a small number of corrupted linear measurements. Traditional approaches tackling such a problem require the computation of tensor Singular Value Decomposition (t-SVD), that is a computationally intensive process, rendering them impractical for dealing with large-scale tensors. Aim to address this challenge, we propose an efficient and effective low-tubal-rank tensor recovery method based on a factorization procedure akin to the Burer-Monteiro (BM) method. Precisely, our fundamental approach involves decomposing a large tensor into two smaller factor tensors, followed by solving the problem through factorized gradient descent (FGD). This strategy eliminates the need for t-SVD computation, thereby reducing computational costs and storage requirements. We provide rigorous theoretical analysis to ensure the convergence of FGD under both noise-free and noisy situations. Additionally, it 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#35780;&#20272;&#20102;&#22810;&#31181;&#26102;&#38388;&#21040;&#20107;&#20214;&#32467;&#26524;&#30340;&#20122;&#32452;&#20998;&#26512;&#31639;&#27861;&#65292;&#22635;&#34917;&#20102;&#36825;&#19968;&#39046;&#22495;&#30340;&#30740;&#31350;&#31354;&#30333;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#65292;&#21487;&#20197;&#25506;&#32034;&#19981;&#21516;&#30340;&#24322;&#36136;&#24615;&#24773;&#26223;&#12290;</title><link>http://arxiv.org/abs/2401.11842</link><description>&lt;p&gt;
&#24322;&#36136;&#24615;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#20013;&#26102;&#38388;&#21040;&#20107;&#20214;&#32467;&#26524;&#30340;&#20122;&#32452;&#20998;&#26512;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Subgroup analysis methods for time-to-event outcomes in heterogeneous randomized controlled trials. (arXiv:2401.11842v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11842
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#35780;&#20272;&#20102;&#22810;&#31181;&#26102;&#38388;&#21040;&#20107;&#20214;&#32467;&#26524;&#30340;&#20122;&#32452;&#20998;&#26512;&#31639;&#27861;&#65292;&#22635;&#34917;&#20102;&#36825;&#19968;&#39046;&#22495;&#30340;&#30740;&#31350;&#31354;&#30333;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#65292;&#21487;&#20197;&#25506;&#32034;&#19981;&#21516;&#30340;&#24322;&#36136;&#24615;&#24773;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#26174;&#33879;&#30340;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#21487;&#33021;&#38544;&#34255;&#20102;&#23545;&#23454;&#39564;&#24615;&#33647;&#29289;&#26377;&#33391;&#22909;&#21453;&#24212;&#30340;&#20122;&#32452;&#65292;&#20174;&#32780;&#38459;&#30861;&#20102;&#21518;&#32493;&#30340;&#21457;&#23637;&#12290;&#37492;&#23450;&#36825;&#31181;&#24322;&#36136;&#24615;&#27835;&#30103;&#25928;&#24212;&#23545;&#20110;&#31934;&#20934;&#21307;&#23398;&#33267;&#20851;&#37325;&#35201;&#65292;&#20026;&#27492;&#24050;&#32463;&#24320;&#21457;&#20986;&#35768;&#22810;&#20107;&#21518;&#20998;&#26512;&#26041;&#27861;&#12290;&#34429;&#28982;&#24050;&#32463;&#36827;&#34892;&#20102;&#20960;&#20010;&#22522;&#20934;&#27979;&#35797;&#26469;&#37492;&#23450;&#36825;&#20123;&#26041;&#27861;&#30340;&#20248;&#28857;&#21644;&#32570;&#28857;&#65292;&#23588;&#20854;&#26159;&#23545;&#20110;&#20108;&#36827;&#21046;&#21644;&#36830;&#32493;&#32456;&#28857;&#65292;&#20294;&#26159;&#23545;&#20110;&#26102;&#38388;&#21040;&#20107;&#20214;&#32456;&#28857;&#30340;&#20122;&#32452;&#20998;&#26512;&#32570;&#20047;&#31867;&#20284;&#30340;&#31995;&#32479;&#23454;&#35777;&#35780;&#20272;&#12290;&#26412;&#24037;&#20316;&#26088;&#22312;&#36890;&#36807;&#35780;&#20272;&#20960;&#31181;&#26102;&#38388;&#21040;&#20107;&#20214;&#32467;&#26524;&#30340;&#20122;&#32452;&#20998;&#26512;&#31639;&#27861;&#26469;&#22635;&#34917;&#36825;&#20010;&#31354;&#30333;&#65292;&#36890;&#36807;&#19977;&#20010;&#19981;&#21516;&#30340;&#30740;&#31350;&#38382;&#39064;&#65306;&#26159;&#21542;&#23384;&#22312;&#24322;&#36136;&#24615;&#65311;&#20160;&#20040;&#29983;&#29289;&#26631;&#24535;&#29289;&#26159;&#23548;&#33268;&#36825;&#31181;&#24322;&#36136;&#24615;&#30340;&#21407;&#22240;&#65311;&#35841;&#26159;&#23545;&#27835;&#30103;&#26377;&#33391;&#22909;&#21453;&#24212;&#30340;&#20154;&#65311;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21512;&#25104;&#21644;&#21322;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#65292;&#20351;&#20154;&#20204;&#33021;&#22815;&#25506;&#32034;&#24191;&#27867;&#30340;&#24322;&#36136;&#24615;&#24773;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;
Non-significant randomized control trials can hide subgroups of good responders to experimental drugs, thus hindering subsequent development. Identifying such heterogeneous treatment effects is key for precision medicine and many post-hoc analysis methods have been developed for that purpose. While several benchmarks have been carried out to identify the strengths and weaknesses of these methods, notably for binary and continuous endpoints, similar systematic empirical evaluation of subgroup analysis for time-to-event endpoints are lacking. This work aims to fill this gap by evaluating several subgroup analysis algorithms in the context of time-to-event outcomes, by means of three different research questions: Is there heterogeneity? What are the biomarkers responsible for such heterogeneity? Who are the good responders to treatment? In this context, we propose a new synthetic and semi-synthetic data generation process that allows one to explore a wide range of heterogeneity scenarios 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#27424;&#38459;&#23612; Langevin Monte Carlo &#21152;&#36895;&#30340;&#36817;&#20284; Thompson &#37319;&#26679;&#31574;&#30053;&#65292;&#36890;&#36807;&#29305;&#23450;&#21183;&#20989;&#25968;&#30340;&#35774;&#35745;&#25913;&#21892;&#20102;&#39640;&#32500;&#38382;&#39064;&#20013;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24182;&#22312;&#39640;&#32500;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2401.11665</link><description>&lt;p&gt;
&#20351;&#29992;&#27424;&#38459;&#23612; Langevin Monte Carlo &#21152;&#36895;&#36817;&#20284; Thompson &#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Accelerating Approximate Thompson Sampling with Underdamped Langevin Monte Carlo. (arXiv:2401.11665v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11665
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#27424;&#38459;&#23612; Langevin Monte Carlo &#21152;&#36895;&#30340;&#36817;&#20284; Thompson &#37319;&#26679;&#31574;&#30053;&#65292;&#36890;&#36807;&#29305;&#23450;&#21183;&#20989;&#25968;&#30340;&#35774;&#35745;&#25913;&#21892;&#20102;&#39640;&#32500;&#38382;&#39064;&#20013;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24182;&#22312;&#39640;&#32500;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#27424;&#38459;&#23612; Langevin Monte Carlo &#30340;&#36817;&#20284; Thompson &#37319;&#26679;&#26041;&#27861;&#25193;&#23637;&#20102;&#20854;&#36866;&#29992;&#33539;&#22260;&#65292;&#20174;&#39640;&#26031;&#21518;&#39564;&#37319;&#26679;&#25193;&#23637;&#21040;&#26356;&#19968;&#33324;&#30340;&#24179;&#28369;&#21518;&#39564;&#12290;&#28982;&#32780;&#65292;&#22312;&#39640;&#32500;&#38382;&#39064;&#20013;&#35201;&#27714;&#39640;&#20934;&#30830;&#24615;&#26102;&#65292;&#20173;&#28982;&#38754;&#20020;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#20284; Thompson &#37319;&#26679;&#31574;&#30053;&#65292;&#21033;&#29992;&#27424;&#38459;&#23612; Langevin Monte Carlo&#65292;&#21518;&#32773;&#26159;&#27169;&#25311;&#39640;&#32500;&#21518;&#39564;&#30340;&#36890;&#29992;&#24037;&#20855;&#12290;&#22522;&#20110;&#26631;&#20934;&#30340;&#24179;&#28369;&#24615;&#21644;&#23545;&#25968;&#20985;&#24615;&#26465;&#20214;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20351;&#29992;&#29305;&#23450;&#21183;&#20989;&#25968;&#30340;&#21152;&#36895;&#21518;&#39564;&#38598;&#20013;&#21644;&#37319;&#26679;&#12290;&#35813;&#35774;&#35745;&#25913;&#36827;&#20102;&#23454;&#29616;&#23545;&#25968;&#36951;&#25022;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#20174;$\mathcal{\tilde O}(d)$&#25913;&#36827;&#21040;$\mathcal{\tilde O}(\sqrt{d})$&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#21512;&#25104;&#23454;&#39564;&#22312;&#39640;&#32500;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#32463;&#39564;&#39564;&#35777;&#20102;&#25105;&#20204;&#31639;&#27861;&#30340;&#21487;&#25193;&#23637;&#24615;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Approximate Thompson sampling with Langevin Monte Carlo broadens its reach from Gaussian posterior sampling to encompass more general smooth posteriors. However, it still encounters scalability issues in high-dimensional problems when demanding high accuracy. To address this, we propose an approximate Thompson sampling strategy, utilizing underdamped Langevin Monte Carlo, where the latter is the go-to workhorse for simulations of high-dimensional posteriors. Based on the standard smoothness and log-concavity conditions, we study the accelerated posterior concentration and sampling using a specific potential function. This design improves the sample complexity for realizing logarithmic regrets from $\mathcal{\tilde O}(d)$ to $\mathcal{\tilde O}(\sqrt{d})$. The scalability and robustness of our algorithm are also empirically validated through synthetic experiments in high-dimensional bandit problems.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Variance-Reduced Sketching&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#39640;&#32500;&#24230;&#20013;&#20272;&#35745;&#23494;&#24230;&#20989;&#25968;&#21644;&#38750;&#21442;&#25968;&#22238;&#24402;&#20989;&#25968;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#23558;&#20989;&#25968;&#27010;&#24565;&#21270;&#20026;&#30697;&#38453;&#65292;&#24182;&#37319;&#29992;&#33609;&#22270;&#25216;&#26415;&#26469;&#38477;&#20302;&#32500;&#24230;&#28798;&#38590;&#24341;&#36215;&#30340;&#26041;&#24046;&#65292;&#23637;&#31034;&#20102;&#40065;&#26834;&#24615;&#33021;&#21644;&#26174;&#33879;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2401.11646</link><description>&lt;p&gt;
&#36890;&#36807;&#26041;&#24046;&#38477;&#20302;&#30340;&#33609;&#22270;&#36827;&#34892;&#38750;&#21442;&#25968;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Nonparametric Estimation via Variance-Reduced Sketching. (arXiv:2401.11646v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11646
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Variance-Reduced Sketching&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#39640;&#32500;&#24230;&#20013;&#20272;&#35745;&#23494;&#24230;&#20989;&#25968;&#21644;&#38750;&#21442;&#25968;&#22238;&#24402;&#20989;&#25968;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#23558;&#20989;&#25968;&#27010;&#24565;&#21270;&#20026;&#30697;&#38453;&#65292;&#24182;&#37319;&#29992;&#33609;&#22270;&#25216;&#26415;&#26469;&#38477;&#20302;&#32500;&#24230;&#28798;&#38590;&#24341;&#36215;&#30340;&#26041;&#24046;&#65292;&#23637;&#31034;&#20102;&#40065;&#26834;&#24615;&#33021;&#21644;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#21442;&#25968;&#27169;&#22411;&#22312;&#21508;&#20010;&#31185;&#23398;&#21644;&#24037;&#31243;&#39046;&#22495;&#20013;&#22791;&#21463;&#20851;&#27880;&#12290;&#32463;&#20856;&#30340;&#26680;&#26041;&#27861;&#22312;&#20302;&#32500;&#24773;&#20917;&#19979;&#20855;&#26377;&#25968;&#20540;&#31283;&#23450;&#24615;&#21644;&#32479;&#35745;&#21487;&#38752;&#24615;&#65292;&#20294;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#30001;&#20110;&#32500;&#24230;&#28798;&#38590;&#21464;&#24471;&#19981;&#22815;&#36866;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#21517;&#20026;Variance-Reduced Sketching&#65288;VRS&#65289;&#30340;&#26032;&#26694;&#26550;&#65292;&#19987;&#38376;&#29992;&#20110;&#22312;&#38477;&#20302;&#32500;&#24230;&#28798;&#38590;&#30340;&#21516;&#26102;&#22312;&#39640;&#32500;&#24230;&#20013;&#20272;&#35745;&#23494;&#24230;&#20989;&#25968;&#21644;&#38750;&#21442;&#25968;&#22238;&#24402;&#20989;&#25968;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#23558;&#22810;&#21464;&#37327;&#20989;&#25968;&#27010;&#24565;&#21270;&#20026;&#26080;&#38480;&#22823;&#23567;&#30340;&#30697;&#38453;&#65292;&#24182;&#20511;&#37492;&#20102;&#25968;&#20540;&#32447;&#24615;&#20195;&#25968;&#25991;&#29486;&#20013;&#30340;&#19968;&#31181;&#26032;&#30340;&#33609;&#22270;&#25216;&#26415;&#26469;&#38477;&#20302;&#20272;&#35745;&#38382;&#39064;&#20013;&#30340;&#26041;&#24046;&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#31995;&#21015;&#30340;&#27169;&#25311;&#23454;&#39564;&#21644;&#30495;&#23454;&#25968;&#25454;&#24212;&#29992;&#23637;&#31034;&#20102;VRS&#30340;&#40065;&#26834;&#24615;&#33021;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#22312;&#35768;&#22810;&#23494;&#24230;&#20272;&#35745;&#38382;&#39064;&#20013;&#65292;VRS&#30456;&#36739;&#20110;&#29616;&#26377;&#30340;&#31070;&#32463;&#32593;&#32476;&#20272;&#35745;&#22120;&#21644;&#32463;&#20856;&#30340;&#26680;&#26041;&#27861;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
Nonparametric models are of great interest in various scientific and engineering disciplines. Classical kernel methods, while numerically robust and statistically sound in low-dimensional settings, become inadequate in higher-dimensional settings due to the curse of dimensionality. In this paper, we introduce a new framework called Variance-Reduced Sketching (VRS), specifically designed to estimate density functions and nonparametric regression functions in higher dimensions with a reduced curse of dimensionality. Our framework conceptualizes multivariable functions as infinite-size matrices, and facilitates a new sketching technique motivated by numerical linear algebra literature to reduce the variance in estimation problems. We demonstrate the robust numerical performance of VRS through a series of simulated experiments and real-world data applications. Notably, VRS shows remarkable improvement over existing neural network estimators and classical kernel methods in numerous density 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;ELLE&#30340;&#27491;&#21017;&#21270;&#39033;&#65292;&#29992;&#20110;&#39640;&#25928;&#22320;&#20943;&#36731;&#21333;&#27493;&#23545;&#25239;&#24615;&#35757;&#32451;&#20013;&#30340;&#28798;&#38590;&#24615;&#36807;&#25311;&#21512;&#12290;&#23427;&#33021;&#22815;&#20445;&#25345;&#25439;&#22833;&#20989;&#25968;&#22312;&#36755;&#20837;&#19978;&#30340;&#23616;&#37096;&#32447;&#24615;&#24615;&#65292;&#19982;&#20256;&#32479;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#30456;&#27604;&#65292;ELLE&#26356;&#21152;&#39640;&#25928;&#65292;&#33021;&#22815;&#26377;&#25928;&#24212;&#23545;&#22823;&#23545;&#25239;&#24615;&#25200;&#21160;&#21644;&#38271;&#35757;&#32451;&#35745;&#21010;&#31561;&#22256;&#38590;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2401.11618</link><description>&lt;p&gt;
&#29992;&#20110;&#20811;&#26381;&#28798;&#38590;&#24615;&#36807;&#25311;&#21512;&#30340;&#39640;&#25928;&#26412;&#22320;&#32447;&#24615;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
Efficient local linearity regularization to overcome catastrophic overfitting. (arXiv:2401.11618v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11618
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;ELLE&#30340;&#27491;&#21017;&#21270;&#39033;&#65292;&#29992;&#20110;&#39640;&#25928;&#22320;&#20943;&#36731;&#21333;&#27493;&#23545;&#25239;&#24615;&#35757;&#32451;&#20013;&#30340;&#28798;&#38590;&#24615;&#36807;&#25311;&#21512;&#12290;&#23427;&#33021;&#22815;&#20445;&#25345;&#25439;&#22833;&#20989;&#25968;&#22312;&#36755;&#20837;&#19978;&#30340;&#23616;&#37096;&#32447;&#24615;&#24615;&#65292;&#19982;&#20256;&#32479;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#30456;&#27604;&#65292;ELLE&#26356;&#21152;&#39640;&#25928;&#65292;&#33021;&#22815;&#26377;&#25928;&#24212;&#23545;&#22823;&#23545;&#25239;&#24615;&#25200;&#21160;&#21644;&#38271;&#35757;&#32451;&#35745;&#21010;&#31561;&#22256;&#38590;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21333;&#27493;&#23545;&#25239;&#24615;&#35757;&#32451;&#20013;&#30340;&#28798;&#38590;&#24615;&#36807;&#25311;&#21512; (CO) &#23548;&#33268;&#23545;&#25239;&#24615;&#27979;&#35797;&#20934;&#30830;&#29575;&#31361;&#28982;&#19979;&#38477;&#65288;&#29978;&#33267;&#38477;&#33267;0%&#65289;&#12290;&#23545;&#20110;&#20351;&#29992;&#22810;&#27493;&#23545;&#25239;&#24615;&#35757;&#32451;&#35757;&#32451;&#30340;&#27169;&#22411;&#65292;&#24050;&#35266;&#23519;&#21040;&#25439;&#22833;&#20989;&#25968;&#22312;&#36755;&#20837;&#19978;&#20855;&#26377;&#23616;&#37096;&#32447;&#24615;&#24615;&#65292;&#20294;&#36825;&#31181;&#29305;&#24615;&#22312;&#21333;&#27493;&#23545;&#25239;&#24615;&#35757;&#32451;&#20013;&#20002;&#22833;&#12290;&#20026;&#20102;&#35299;&#20915;&#21333;&#27493;&#23545;&#25239;&#24615;&#35757;&#32451;&#20013;&#30340;CO&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20960;&#31181;&#36890;&#36807;&#27491;&#21017;&#21270;&#26469;&#24378;&#21046;&#25439;&#22833;&#20989;&#25968;&#23616;&#37096;&#32447;&#24615;&#24615;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#21452;&#37325;&#21453;&#21521;&#20256;&#25773;&#65292;&#36825;&#20123;&#27491;&#21017;&#21270;&#39033;&#20250;&#26174;&#33879;&#20943;&#24930;&#35757;&#32451;&#36895;&#24230;&#12290;&#19982;&#20043;&#30456;&#21453;&#65292;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#19968;&#31181;&#31216;&#20026;ELLE&#30340;&#27491;&#21017;&#21270;&#39033;&#65292;&#20197;&#22312;&#32463;&#20856;&#23545;&#25239;&#24615;&#35757;&#32451;&#35780;&#20272;&#20013;&#26377;&#25928;&#19988;&#39640;&#25928;&#22320;&#20943;&#36731;CO&#38382;&#39064;&#65292;&#22312;&#19968;&#20123;&#26356;&#22256;&#38590;&#30340;&#24773;&#20917;&#19979;&#20063;&#33021;&#36215;&#20316;&#29992;&#65292;&#20363;&#22914;&#22823;&#23545;&#25239;&#24615;&#25200;&#21160;&#21644;&#38271;&#35757;&#32451;&#35745;&#21010;&#12290;&#25105;&#20204;&#30340;&#27491;&#21017;&#21270;&#39033;&#22312;&#29702;&#35770;&#19978;&#19982;&#25439;&#22833;&#20989;&#25968;&#30340;&#26354;&#29575;&#26377;&#32852;&#31995;&#65292;&#24182;&#19988;&#36890;&#36807;&#36991;&#20813;&#21452;&#37325;&#21453;&#21521;&#20256;&#25773;&#32780;&#20855;&#26377;&#27604;&#20808;&#21069;&#26041;&#27861;&#26356;&#20302;&#30340;&#35745;&#31639;&#25104;&#26412;&#12290;&#36890;&#36807;&#24443;&#24213;&#30340;&#23454;&#39564;&#30740;&#31350;...
&lt;/p&gt;
&lt;p&gt;
Catastrophic overfitting (CO) in single-step adversarial training (AT) results in abrupt drops in the adversarial test accuracy (even down to 0%). For models trained with multi-step AT, it has been observed that the loss function behaves locally linearly with respect to the input, this is however lost in single-step AT. To address CO in single-step AT, several methods have been proposed to enforce local linearity of the loss via regularization. However, these regularization terms considerably slow down training due to Double Backpropagation. Instead, in this work, we introduce a regularization term, called ELLE, to mitigate CO effectively and efficiently in classical AT evaluations, as well as some more difficult regimes, e.g., large adversarial perturbations and long training schedules. Our regularization term can be theoretically linked to curvature of the loss function and is computationally cheaper than previous methods by avoiding Double Backpropagation. Our thorough experimental 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20026;&#20160;&#20040;&#20351;&#29992;&#22823;&#23398;&#20064;&#29575;&#38271;&#26102;&#38388;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#23454;&#29616;&#26356;&#22909;&#30340;&#27867;&#21270;&#12290;&#36890;&#36807;&#35266;&#23519;&#35757;&#32451;&#21644;&#27979;&#35797;&#25439;&#22833;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#25105;&#20204;&#21457;&#29616;&#22823;&#23398;&#20064;&#29575;&#19979;&#30340;&#35757;&#32451;&#36712;&#36857;&#33021;&#22815;&#25509;&#36817;&#27979;&#35797;&#25439;&#22833;&#30340;&#26368;&#23567;&#20540;&#38468;&#36817;&#12290;&#22522;&#20110;&#36825;&#20010;&#21457;&#29616;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#19982;&#30495;&#23454;&#31070;&#32463;&#32593;&#32476;&#31867;&#20284;&#30340;&#38750;&#32447;&#24615;&#27169;&#22411;&#65292;&#24182;&#35777;&#26126;&#20102;&#20351;&#29992;&#22823;&#23398;&#20064;&#29575;&#36827;&#34892;&#24310;&#38271;&#38454;&#27573;&#30340;&#35757;&#32451;&#21487;&#20197;&#23454;&#29616;&#26356;&#25509;&#36817;&#26368;&#20248;&#27867;&#21270;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2401.11600</link><description>&lt;p&gt;
&#29702;&#35299;&#21518;&#26399;&#23398;&#20064;&#29575;&#34928;&#20943;&#30340;&#27867;&#21270;&#20248;&#21183;
&lt;/p&gt;
&lt;p&gt;
Understanding the Generalization Benefits of Late Learning Rate Decay. (arXiv:2401.11600v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11600
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20026;&#20160;&#20040;&#20351;&#29992;&#22823;&#23398;&#20064;&#29575;&#38271;&#26102;&#38388;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#23454;&#29616;&#26356;&#22909;&#30340;&#27867;&#21270;&#12290;&#36890;&#36807;&#35266;&#23519;&#35757;&#32451;&#21644;&#27979;&#35797;&#25439;&#22833;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#25105;&#20204;&#21457;&#29616;&#22823;&#23398;&#20064;&#29575;&#19979;&#30340;&#35757;&#32451;&#36712;&#36857;&#33021;&#22815;&#25509;&#36817;&#27979;&#35797;&#25439;&#22833;&#30340;&#26368;&#23567;&#20540;&#38468;&#36817;&#12290;&#22522;&#20110;&#36825;&#20010;&#21457;&#29616;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#19982;&#30495;&#23454;&#31070;&#32463;&#32593;&#32476;&#31867;&#20284;&#30340;&#38750;&#32447;&#24615;&#27169;&#22411;&#65292;&#24182;&#35777;&#26126;&#20102;&#20351;&#29992;&#22823;&#23398;&#20064;&#29575;&#36827;&#34892;&#24310;&#38271;&#38454;&#27573;&#30340;&#35757;&#32451;&#21487;&#20197;&#23454;&#29616;&#26356;&#25509;&#36817;&#26368;&#20248;&#27867;&#21270;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20160;&#20040;&#29992;&#22823;&#23398;&#20064;&#29575;&#38271;&#26102;&#38388;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#36890;&#24120;&#33021;&#22815;&#23454;&#29616;&#26356;&#22909;&#30340;&#27867;&#21270;&#21602;&#65311;&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#31070;&#32463;&#32593;&#32476;&#20013;&#35757;&#32451;&#25439;&#22833;&#21644;&#27979;&#35797;&#25439;&#22833;&#20043;&#38388;&#30340;&#20851;&#31995;&#26469;&#25506;&#35752;&#36825;&#20010;&#38382;&#39064;&#12290;&#36890;&#36807;&#21487;&#35270;&#21270;&#36825;&#20123;&#25439;&#22833;&#24773;&#20917;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#22312;&#22823;&#23398;&#20064;&#29575;&#19979;&#30340;&#35757;&#32451;&#36712;&#36857;&#20250;&#36890;&#36807;&#35757;&#32451;&#25439;&#22833;&#30340;&#26497;&#23567;&#20540;&#27969;&#24418;&#65292;&#26368;&#32456;&#25509;&#36817;&#20110;&#27979;&#35797;&#25439;&#22833;&#30340;&#26497;&#23567;&#20540;&#38468;&#36817;&#12290;&#22312;&#36825;&#20010;&#21457;&#29616;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#38750;&#32447;&#24615;&#27169;&#22411;&#65292;&#20854;&#25439;&#22833;&#26223;&#35266;&#19982;&#30495;&#23454;&#31070;&#32463;&#32593;&#32476;&#35266;&#23519;&#21040;&#30340;&#30456;&#20284;&#12290;&#36890;&#36807;&#22312;&#25105;&#20204;&#30340;&#27169;&#22411;&#19978;&#20351;&#29992;SGD&#30740;&#31350;&#35757;&#32451;&#36807;&#31243;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#22823;&#23398;&#20064;&#29575;&#19979;&#30340;&#24310;&#38271;&#38454;&#27573;&#21487;&#20197;&#23558;&#25105;&#20204;&#30340;&#27169;&#22411;&#24341;&#23548;&#21521;&#35757;&#32451;&#25439;&#22833;&#30340;&#26368;&#23567;&#33539;&#25968;&#35299;&#65292;&#36825;&#21487;&#33021;&#23454;&#29616;&#25509;&#36817;&#26368;&#20248;&#30340;&#27867;&#21270;&#65292;&#20174;&#32780;&#35777;&#23454;&#20102;&#21518;&#26399;&#23398;&#20064;&#29575;&#34928;&#20943;&#30340;&#32463;&#39564;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Why do neural networks trained with large learning rates for a longer time often lead to better generalization? In this paper, we delve into this question by examining the relation between training and testing loss in neural networks. Through visualization of these losses, we note that the training trajectory with a large learning rate navigates through the minima manifold of the training loss, finally nearing the neighborhood of the testing loss minimum. Motivated by these findings, we introduce a nonlinear model whose loss landscapes mirror those observed for real neural networks. Upon investigating the training process using SGD on our model, we demonstrate that an extended phase with a large learning rate steers our model towards the minimum norm solution of the training loss, which may achieve near-optimal generalization, thereby affirming the empirically observed benefits of late learning rate decay.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#22122;&#38899;&#19978;&#19979;&#25991;&#30340;&#38543;&#26426;&#36172;&#33218;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;Thompson&#37319;&#26679;&#31639;&#27861;&#65292;&#36890;&#36807;&#36125;&#21494;&#26031;&#26694;&#26550;&#36827;&#34892;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#36125;&#21494;&#26031;&#21518;&#24724;&#65292;&#24182;&#25193;&#23637;&#20102;&#38382;&#39064;&#21040;&#24310;&#36831;&#35266;&#23519;&#30495;&#23454;&#19978;&#19979;&#25991;&#30340;&#24773;&#20917;&#65292;&#24182;&#23454;&#35777;&#20102;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.11565</link><description>&lt;p&gt;
Thompson&#37319;&#26679;&#29992;&#20110;&#20855;&#26377;&#22122;&#38899;&#19978;&#19979;&#25991;&#30340;&#38543;&#26426;&#36172;&#33218;&#38382;&#39064;&#30340;&#20449;&#24687;&#35770;&#24615;&#21518;&#24724;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Thompson Sampling for Stochastic Bandits with Noisy Contexts: An Information-Theoretic Regret Analysis. (arXiv:2401.11565v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11565
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#22122;&#38899;&#19978;&#19979;&#25991;&#30340;&#38543;&#26426;&#36172;&#33218;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;Thompson&#37319;&#26679;&#31639;&#27861;&#65292;&#36890;&#36807;&#36125;&#21494;&#26031;&#26694;&#26550;&#36827;&#34892;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#36125;&#21494;&#26031;&#21518;&#24724;&#65292;&#24182;&#25193;&#23637;&#20102;&#38382;&#39064;&#21040;&#24310;&#36831;&#35266;&#23519;&#30495;&#23454;&#19978;&#19979;&#25991;&#30340;&#24773;&#20917;&#65292;&#24182;&#23454;&#35777;&#20102;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#38543;&#26426;&#19978;&#19979;&#25991;&#32447;&#24615;&#36172;&#33218;&#38382;&#39064;&#65292;&#20854;&#20013;&#20195;&#29702;&#36890;&#36807;&#19968;&#20010;&#26410;&#30693;&#22122;&#22768;&#21442;&#25968;&#30340;&#22122;&#22768;&#20449;&#36947;&#35266;&#23519;&#21040;&#30495;&#23454;&#19978;&#19979;&#25991;&#30340;&#22122;&#22768;&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#35774;&#35745;&#19968;&#20010;&#21160;&#20316;&#31574;&#30053;&#65292;&#21487;&#20197;&#36817;&#20284;&#20110;&#20855;&#26377;&#22870;&#21169;&#27169;&#22411;&#12289;&#22122;&#22768;&#21442;&#25968;&#21644;&#20174;&#35266;&#23519;&#21040;&#30340;&#22122;&#22768;&#19978;&#19979;&#25991;&#20013;&#30495;&#23454;&#19978;&#19979;&#25991;&#30340;&#39044;&#27979;&#20998;&#24067;&#30340;oracle&#30340;&#21160;&#20316;&#31574;&#30053;&#12290;&#22312;&#36125;&#21494;&#26031;&#26694;&#26550;&#19979;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#38024;&#23545;&#20855;&#26377;&#39640;&#26031;&#19978;&#19979;&#25991;&#22122;&#22768;&#30340;&#39640;&#26031;&#36172;&#33218;&#30340;Thompson&#37319;&#26679;&#31639;&#27861;&#12290;&#37319;&#29992;&#20449;&#24687;&#35770;&#20998;&#26512;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#30456;&#23545;&#20110;oracle&#30340;&#21160;&#20316;&#31574;&#30053;&#30340;&#36125;&#21494;&#26031;&#21518;&#24724;&#12290;&#25105;&#20204;&#36824;&#23558;&#36825;&#20010;&#38382;&#39064;&#25193;&#23637;&#21040;&#20102;&#20195;&#29702;&#22312;&#25509;&#25910;&#21040;&#22870;&#21169;&#21518;&#24310;&#36831;&#35266;&#23519;&#21040;&#30495;&#23454;&#19978;&#19979;&#25991;&#30340;&#24773;&#20917;&#65292;&#24182;&#23637;&#31034;&#20102;&#24310;&#36831;&#30495;&#23454;&#19978;&#19979;&#25991;&#23548;&#33268;&#26356;&#20302;&#30340;&#36125;&#21494;&#26031;&#21518;&#24724;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#19982;&#22522;&#32447;&#31639;&#27861;&#30340;&#27604;&#36739;&#23454;&#35777;&#22320;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We explore a stochastic contextual linear bandit problem where the agent observes a noisy, corrupted version of the true context through a noise channel with an unknown noise parameter. Our objective is to design an action policy that can approximate" that of an oracle, which has access to the reward model, the channel parameter, and the predictive distribution of the true context from the observed noisy context. In a Bayesian framework, we introduce a Thompson sampling algorithm for Gaussian bandits with Gaussian context noise. Adopting an information-theoretic analysis, we demonstrate the Bayesian regret of our algorithm concerning the oracle's action policy. We also extend this problem to a scenario where the agent observes the true context with some delay after receiving the reward and show that delayed true contexts lead to lower Bayesian regret. Finally, we empirically demonstrate the performance of the proposed algorithms against baselines.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#20351;&#29992;Wasserstein&#36317;&#31163;&#36827;&#34892;&#21152;&#26435;&#30340;&#31639;&#27861;&#65292;&#22312;&#26631;&#35760;&#30340;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#36924;&#36817;&#22312;&#20854;&#20182;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#24471;&#21040;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#31639;&#27861;&#21487;&#20197;&#36755;&#20986;&#25509;&#36817;&#26368;&#20248;&#30340;&#21152;&#26435;&#65292;&#19988;&#31639;&#27861;&#31616;&#21333;&#21487;&#25193;&#23637;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#21487;&#20197;&#26377;&#24847;&#22320;&#24341;&#20837;&#20998;&#24067;&#20559;&#31227;&#36827;&#34892;&#22810;&#30446;&#26631;&#20248;&#21270;&#12290;&#20316;&#20026;&#24212;&#29992;&#23454;&#20363;&#65292;&#25105;&#20204;&#35757;&#32451;&#20102;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#26469;&#35782;&#21035;&#23545;&#32454;&#32990;&#20449;&#21495;&#20256;&#23548;&#30340;MAP&#28608;&#37238;&#20855;&#26377;&#38750;&#32467;&#21512;&#24615;&#30340;&#23567;&#20998;&#23376;&#32467;&#21512;&#29289;&#12290;</title><link>http://arxiv.org/abs/2401.11562</link><description>&lt;p&gt;
&#20351;&#29992;Wasserstein&#36317;&#31163;&#36827;&#34892;&#21152;&#26435;&#20197;&#22686;&#24378;&#36873;&#25321;&#24615;
&lt;/p&gt;
&lt;p&gt;
Enhancing selectivity using Wasserstein distance based reweighing. (arXiv:2401.11562v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11562
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#20351;&#29992;Wasserstein&#36317;&#31163;&#36827;&#34892;&#21152;&#26435;&#30340;&#31639;&#27861;&#65292;&#22312;&#26631;&#35760;&#30340;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#36924;&#36817;&#22312;&#20854;&#20182;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#24471;&#21040;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#31639;&#27861;&#21487;&#20197;&#36755;&#20986;&#25509;&#36817;&#26368;&#20248;&#30340;&#21152;&#26435;&#65292;&#19988;&#31639;&#27861;&#31616;&#21333;&#21487;&#25193;&#23637;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#21487;&#20197;&#26377;&#24847;&#22320;&#24341;&#20837;&#20998;&#24067;&#20559;&#31227;&#36827;&#34892;&#22810;&#30446;&#26631;&#20248;&#21270;&#12290;&#20316;&#20026;&#24212;&#29992;&#23454;&#20363;&#65292;&#25105;&#20204;&#35757;&#32451;&#20102;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#26469;&#35782;&#21035;&#23545;&#32454;&#32990;&#20449;&#21495;&#20256;&#23548;&#30340;MAP&#28608;&#37238;&#20855;&#26377;&#38750;&#32467;&#21512;&#24615;&#30340;&#23567;&#20998;&#23376;&#32467;&#21512;&#29289;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32473;&#23450;&#20004;&#20010;&#26631;&#35760;&#25968;&#25454;&#38598;&#119982;&#21644;&#119983;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#31616;&#21333;&#39640;&#25928;&#30340;&#36138;&#23146;&#31639;&#27861;&#26469;&#23545;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;&#21152;&#26435;&#65292;&#20351;&#24471;&#22312;&#119982;&#19978;&#35757;&#32451;&#24471;&#21040;&#30340;&#31070;&#32463;&#32593;&#32476;&#26435;&#37325;&#30340;&#26497;&#38480;&#20998;&#24067;&#36924;&#36817;&#22312;&#119983;&#19978;&#35757;&#32451;&#24471;&#21040;&#30340;&#26497;&#38480;&#20998;&#24067;&#12290;&#22312;&#29702;&#35770;&#26041;&#38754;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#36755;&#20837;&#25968;&#25454;&#38598;&#30340;&#24230;&#37327;&#29109;&#26377;&#30028;&#26102;&#65292;&#25105;&#20204;&#30340;&#36138;&#23146;&#31639;&#27861;&#36755;&#20986;&#25509;&#36817;&#26368;&#20248;&#30340;&#21152;&#26435;&#65292;&#21363;&#32593;&#32476;&#26435;&#37325;&#30340;&#20004;&#20010;&#19981;&#21464;&#20998;&#24067;&#22312;&#24635;&#21464;&#24046;&#36317;&#31163;&#19978;&#21487;&#20197;&#35777;&#26126;&#25509;&#36817;&#12290;&#27492;&#22806;&#65292;&#35813;&#31639;&#27861;&#31616;&#21333;&#21487;&#25193;&#23637;&#65292;&#24182;&#19988;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#25928;&#29575;&#19978;&#30028;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#21487;&#20197;&#26377;&#24847;&#22320;&#24341;&#20837;&#20998;&#24067;&#20559;&#31227;&#20197;&#36827;&#34892;&#65288;&#36719;&#65289;&#22810;&#30446;&#26631;&#20248;&#21270;&#12290;&#20316;&#20026;&#19968;&#20010;&#21160;&#26426;&#24212;&#29992;&#65292;&#25105;&#20204;&#35757;&#32451;&#20102;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#26469;&#35782;&#21035;&#23545;MNK2&#65288;&#19968;&#31181;&#32454;&#32990;&#20449;&#21495;&#20256;&#23548;&#30340;MAP&#28608;&#37238;&#65289;&#20855;&#26377;&#38750;&#32467;&#21512;&#24615;&#30340;&#23567;&#20998;&#23376;&#32467;&#21512;&#29289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Given two labeled data-sets $\mathcal{S}$ and $\mathcal{T}$, we design a simple and efficient greedy algorithm to reweigh the loss function such that the limiting distribution of the neural network weights that result from training on $\mathcal{S}$ approaches the limiting distribution that would have resulted by training on $\mathcal{T}$.  On the theoretical side, we prove that when the metric entropy of the input data-sets is bounded, our greedy algorithm outputs a close to optimal reweighing, i.e., the two invariant distributions of network weights will be provably close in total variation distance. Moreover, the algorithm is simple and scalable, and we prove bounds on the efficiency of the algorithm as well.  Our algorithm can deliberately introduce distribution shift to perform (soft) multi-criteria optimization. As a motivating application, we train a neural net to recognize small molecule binders to MNK2 (a MAP Kinase, responsible for cell signaling) which are non-binders to MNK1
&lt;/p&gt;</description></item><item><title>MoMA&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#20026;&#22522;&#30784;&#30340;&#38236;&#20687;&#19978;&#21319;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#26080;&#38480;&#21046;&#30340;&#31574;&#30053;&#31867;&#21035;&#21644;&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#26469;&#23454;&#29616;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#65292;&#20805;&#20998;&#21033;&#29992;&#20102;&#27169;&#22411;&#20026;&#22522;&#30784;&#26041;&#27861;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2401.11380</link><description>&lt;p&gt;
MoMA: &#27169;&#22411;&#20026;&#22522;&#30784;&#30340;&#38236;&#20687;&#19978;&#21319;&#31639;&#27861;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
MoMA: Model-based Mirror Ascent for Offline Reinforcement Learning. (arXiv:2401.11380v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11380
&lt;/p&gt;
&lt;p&gt;
MoMA&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#20026;&#22522;&#30784;&#30340;&#38236;&#20687;&#19978;&#21319;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#26080;&#38480;&#21046;&#30340;&#31574;&#30053;&#31867;&#21035;&#21644;&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#26469;&#23454;&#29616;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#65292;&#20805;&#20998;&#21033;&#29992;&#20102;&#27169;&#22411;&#20026;&#22522;&#30784;&#26041;&#27861;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#22411;&#20026;&#22522;&#30784;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#22312;&#35768;&#22810;&#20915;&#31574;&#38382;&#39064;&#20013;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#24471;&#30410;&#20110;&#23427;&#20204;&#30340;&#26679;&#26412;&#25928;&#29575;&#21644;&#36890;&#29992;&#24615;&#12290;&#23613;&#31649;&#21462;&#24471;&#20102;&#36825;&#20123;&#36827;&#23637;&#65292;&#20294;&#29616;&#26377;&#30340;&#27169;&#22411;&#20026;&#22522;&#30784;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#35201;&#20040;&#20391;&#37325;&#20110;&#29702;&#35770;&#30740;&#31350;&#32780;&#27809;&#26377;&#24320;&#21457;&#23454;&#38469;&#31639;&#27861;&#65292;&#35201;&#20040;&#20381;&#36182;&#20110;&#21463;&#38480;&#30340;&#21442;&#25968;&#21270;&#31574;&#30053;&#31354;&#38388;&#65292;&#22240;&#27492;&#27809;&#26377;&#20805;&#20998;&#21033;&#29992;&#27169;&#22411;&#20026;&#22522;&#30784;&#26041;&#27861;&#22266;&#26377;&#30340;&#26080;&#38480;&#21046;&#31574;&#30053;&#31354;&#38388;&#30340;&#20248;&#21183;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;MoMA&#65292;&#19968;&#20010;&#22312;&#31163;&#32447;&#25968;&#25454;&#37096;&#20998;&#35206;&#30422;&#19979;&#20351;&#29992;&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#30340;&#27169;&#22411;&#20026;&#22522;&#30784;&#30340;&#38236;&#20687;&#19978;&#21319;&#31639;&#27861;&#12290;MoMA&#36890;&#36807;&#37319;&#29992;&#26080;&#38480;&#21046;&#30340;&#31574;&#30053;&#31867;&#21035;&#65292;&#21306;&#21035;&#20110;&#29616;&#26377;&#25991;&#29486;&#12290;&#22312;&#27599;&#20010;&#36845;&#20195;&#20013;&#65292;MoMA&#22312;&#31574;&#30053;&#35780;&#20272;&#27493;&#39588;&#20013;&#36890;&#36807;&#22312;&#36807;&#28193;&#27169;&#22411;&#30340;&#32622;&#20449;&#21306;&#38388;&#20869;&#36827;&#34892;&#26368;&#23567;&#21270;&#36807;&#31243;&#26469;&#20445;&#23432;&#22320;&#20272;&#35745;&#20540;&#20989;&#25968;&#65292;&#28982;&#21518;&#20351;&#29992;&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#26469;&#26356;&#26032;&#31574;&#30053;&#65292;&#32780;&#19981;&#26159;&#24120;&#29992;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model-based offline reinforcement learning methods (RL) have achieved state-of-the-art performance in many decision-making problems thanks to their sample efficiency and generalizability. Despite these advancements, existing model-based offline RL approaches either focus on theoretical studies without developing practical algorithms or rely on a restricted parametric policy space, thus not fully leveraging the advantages of an unrestricted policy space inherent to model-based methods. To address this limitation, we develop MoMA, a model-based mirror ascent algorithm with general function approximations under partial coverage of offline data. MoMA distinguishes itself from existing literature by employing an unrestricted policy class. In each iteration, MoMA conservatively estimates the value function by a minimization procedure within a confidence set of transition models in the policy evaluation step, then updates the policy with general function approximations instead of commonly-use
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#30340;&#20840;&#38754;&#22238;&#39038;&#65292;&#28085;&#30422;&#20102;&#22312;NISQ&#25216;&#26415;&#21644;&#23481;&#38169;&#37327;&#23376;&#35745;&#31639;&#30828;&#20214;&#19978;&#20351;&#29992;&#30340;&#25216;&#26415;&#21644;&#31639;&#27861;&#65292;&#24182;&#28145;&#20837;&#35752;&#35770;&#20102;&#19982;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#30456;&#20851;&#30340;&#22522;&#26412;&#27010;&#24565;&#21644;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#12290;</title><link>http://arxiv.org/abs/2401.11351</link><description>&lt;p&gt;
&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#65306;&#20174;NISQ&#21040;&#23481;&#38169;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantum Machine Learning: from NISQ to Fault Tolerance. (arXiv:2401.11351v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11351
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#23545;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#30340;&#20840;&#38754;&#22238;&#39038;&#65292;&#28085;&#30422;&#20102;&#22312;NISQ&#25216;&#26415;&#21644;&#23481;&#38169;&#37327;&#23376;&#35745;&#31639;&#30828;&#20214;&#19978;&#20351;&#29992;&#30340;&#25216;&#26415;&#21644;&#31639;&#27861;&#65292;&#24182;&#28145;&#20837;&#35752;&#35770;&#20102;&#19982;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#30456;&#20851;&#30340;&#22522;&#26412;&#27010;&#24565;&#21644;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#26159;&#22312;&#37327;&#23376;&#35774;&#22791;&#19978;&#36816;&#34892;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#36807;&#31243;&#65292;&#22312;&#23398;&#26415;&#30028;&#21644;&#21830;&#19994;&#30028;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#26412;&#25991;&#23545;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#28044;&#29616;&#30340;&#21508;&#31181;&#27010;&#24565;&#36827;&#34892;&#20102;&#20840;&#38754;&#32780;&#20844;&#27491;&#30340;&#22238;&#39038;&#12290;&#36825;&#21253;&#25324;&#22312;&#22122;&#22768;&#20013;&#38388;&#23610;&#24230;&#37327;&#23376;&#65288;NISQ&#65289;&#25216;&#26415;&#20013;&#20351;&#29992;&#30340;&#25216;&#26415;&#65292;&#20197;&#21450;&#19982;&#23481;&#38169;&#37327;&#23376;&#35745;&#31639;&#30828;&#20214;&#20860;&#23481;&#30340;&#31639;&#27861;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#22238;&#39038;&#28085;&#30422;&#20102;&#19982;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#30456;&#20851;&#30340;&#22522;&#26412;&#27010;&#24565;&#12289;&#31639;&#27861;&#21644;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantum machine learning, which involves running machine learning algorithms on quantum devices, has garnered significant attention in both academic and business circles. In this paper, we offer a comprehensive and unbiased review of the various concepts that have emerged in the field of quantum machine learning. This includes techniques used in Noisy Intermediate-Scale Quantum (NISQ) technologies and approaches for algorithms compatible with fault-tolerant quantum computing hardware. Our review covers fundamental concepts, algorithms, and the statistical learning theory pertinent to quantum machine learning.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#20855;&#26377;&#21644;&#27809;&#26377;&#31454;&#20105;&#39118;&#38505;&#30340;&#29983;&#23384;&#32467;&#26524;&#30340;&#25130;&#23614;&#26080;&#20559;&#21464;&#25442;&#26041;&#27861;&#65292;&#21487;&#20197;&#20272;&#35745;&#24322;&#36136;&#27835;&#30103;&#25928;&#24212;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#26356;&#22810;&#26368;&#20808;&#36827;&#30340;&#36866;&#29992;&#20110;&#34987;&#25130;&#23614;&#32467;&#26524;&#30340;HTE&#23398;&#20064;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#38480;&#21046;&#26377;&#38480;&#26679;&#26412;&#36807;&#24230;&#39118;&#38505;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.11263</link><description>&lt;p&gt;
&#36890;&#36807;&#65288;&#27491;&#20132;&#65289;&#23436;&#20840;&#26080;&#20559;&#30340;&#25130;&#23614;&#23398;&#20064;&#26469;&#20272;&#35745;&#29983;&#23384;&#32467;&#26524;&#30340;&#24322;&#36136;&#27835;&#30103;&#25928;&#24212;
&lt;/p&gt;
&lt;p&gt;
Estimating heterogeneous treatment effect from survival outcomes via (orthogonal) censoring unbiased learning. (arXiv:2401.11263v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11263
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#20855;&#26377;&#21644;&#27809;&#26377;&#31454;&#20105;&#39118;&#38505;&#30340;&#29983;&#23384;&#32467;&#26524;&#30340;&#25130;&#23614;&#26080;&#20559;&#21464;&#25442;&#26041;&#27861;&#65292;&#21487;&#20197;&#20272;&#35745;&#24322;&#36136;&#27835;&#30103;&#25928;&#24212;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#26356;&#22810;&#26368;&#20808;&#36827;&#30340;&#36866;&#29992;&#20110;&#34987;&#25130;&#23614;&#32467;&#26524;&#30340;HTE&#23398;&#20064;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#38480;&#21046;&#26377;&#38480;&#26679;&#26412;&#36807;&#24230;&#39118;&#38505;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#35266;&#23519;&#25968;&#25454;&#20013;&#20272;&#35745;&#24322;&#36136;&#27835;&#30103;&#25928;&#24212;&#65288;HTE&#65289;&#30340;&#26041;&#27861;&#20027;&#35201;&#38598;&#20013;&#22312;&#36830;&#32493;&#25110;&#20108;&#20803;&#32467;&#26524;&#19978;&#65292;&#36739;&#23569;&#20851;&#27880;&#29983;&#23384;&#32467;&#26524;&#65292;&#20960;&#20046;&#27809;&#26377;&#20851;&#27880;&#31454;&#20105;&#39118;&#38505;&#24773;&#26223;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#36866;&#29992;&#20110;&#20855;&#26377;&#21644;&#27809;&#26377;&#31454;&#20105;&#39118;&#38505;&#30340;&#29983;&#23384;&#32467;&#26524;&#30340;&#25130;&#23614;&#26080;&#20559;&#21464;&#25442;&#65288;CUTs&#65289;&#12290;&#20351;&#29992;&#36825;&#20123;CUTs&#23558;&#26102;&#38388;&#21040;&#20107;&#20214;&#32467;&#26524;&#36716;&#25442;&#21518;&#65292;&#23545;&#36830;&#32493;&#32467;&#26524;&#30340;HTE&#23398;&#20064;&#26041;&#27861;&#30340;&#30452;&#25509;&#24212;&#29992;&#21487;&#20197;&#20135;&#29983;&#19968;&#33268;&#20272;&#35745;&#30340;&#24322;&#36136;&#32047;&#31215;&#21457;&#29983;&#29575;&#25928;&#24212;&#12289;&#24635;&#25928;&#24212;&#21644;&#21487;&#20998;&#31163;&#30452;&#25509;&#25928;&#24212;&#12290;&#25105;&#20204;&#30340;CUTs&#21487;&#20197;&#20351;&#29992;&#27604;&#20197;&#21069;&#26356;&#22810;&#30340;&#26368;&#20808;&#36827;&#30340;&#36866;&#29992;&#20110;&#34987;&#25130;&#23614;&#32467;&#26524;&#30340;HTE&#23398;&#20064;&#26041;&#27861;&#65292;&#29305;&#21035;&#26159;&#22312;&#31454;&#20105;&#39118;&#38505;&#24773;&#26223;&#19979;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#36890;&#29992;&#30340;&#26080;&#27169;&#22411;&#23398;&#20064;&#29305;&#23450;oracle&#19981;&#31561;&#24335;&#26469;&#38480;&#21046;&#26377;&#38480;&#26679;&#26412;&#30340;&#36807;&#24230;&#39118;&#38505;&#12290;oracle&#25928;&#29575;&#32467;&#26524;&#21462;&#20915;&#20110;&#19968;&#20010;oracle&#36873;&#25321;&#22120;&#21644;&#20174;&#25152;&#26377;&#27493;&#39588;&#20013;&#20272;&#35745;&#30340;&#24178;&#25200;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Methods for estimating heterogeneous treatment effects (HTE) from observational data have largely focused on continuous or binary outcomes, with less attention paid to survival outcomes and almost none to settings with competing risks. In this work, we develop censoring unbiased transformations (CUTs) for survival outcomes both with and without competing risks.After converting time-to-event outcomes using these CUTs, direct application of HTE learners for continuous outcomes yields consistent estimates of heterogeneous cumulative incidence effects, total effects, and separable direct effects. Our CUTs enable application of a much larger set of state of the art HTE learners for censored outcomes than had previously been available, especially in competing risks settings. We provide generic model-free learner-specific oracle inequalities bounding the finite-sample excess risk. The oracle efficiency results depend on the oracle selector and estimated nuisance functions from all steps invol
&lt;/p&gt;</description></item><item><title>AFS-BM&#36890;&#36807;&#32852;&#21512;&#20248;&#21270;&#23454;&#29616;&#20102;&#33258;&#36866;&#24212;&#29305;&#24449;&#36873;&#25321;&#21644;&#27169;&#22411;&#35757;&#32451;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#20934;&#30830;&#24615;&#24182;&#20943;&#23569;&#20102;&#35745;&#31639;&#38656;&#27714;&#12290;</title><link>http://arxiv.org/abs/2401.11250</link><description>&lt;p&gt;
AFS-BM:&#36890;&#36807;&#33258;&#36866;&#24212;&#29305;&#24449;&#36873;&#25321;&#21644;&#20108;&#20540;&#23631;&#34109;&#22686;&#24378;&#27169;&#22411;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;
AFS-BM: Enhancing Model Performance through Adaptive Feature Selection with Binary Masking. (arXiv:2401.11250v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11250
&lt;/p&gt;
&lt;p&gt;
AFS-BM&#36890;&#36807;&#32852;&#21512;&#20248;&#21270;&#23454;&#29616;&#20102;&#33258;&#36866;&#24212;&#29305;&#24449;&#36873;&#25321;&#21644;&#27169;&#22411;&#35757;&#32451;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#20934;&#30830;&#24615;&#24182;&#20943;&#23569;&#20102;&#35745;&#31639;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#20013;&#29305;&#24449;&#36873;&#25321;&#30340;&#38382;&#39064;&#65292;&#36825;&#26159;&#35813;&#39046;&#22495;&#20013;&#26368;&#20851;&#38190;&#30340;&#20027;&#39064;&#20043;&#19968;&#12290;&#23613;&#31649;&#23384;&#22312;&#35768;&#22810;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#65292;&#20294;&#26159;&#36825;&#20123;&#26041;&#27861;&#38754;&#20020;&#21487;&#25193;&#23637;&#24615;&#12289;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#12289;&#22788;&#29702;&#30456;&#20851;&#29305;&#24449;&#12289;&#36866;&#24212;&#21487;&#21464;&#29305;&#24449;&#37325;&#35201;&#24615;&#21644;&#25972;&#21512;&#39046;&#22495;&#30693;&#35782;&#31561;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#8220;&#33258;&#36866;&#24212;&#29305;&#24449;&#36873;&#25321;&#21644;&#20108;&#20540;&#23631;&#34109;&#8221;(AFS-BM)&#12290;AFS-BM&#36890;&#36807;&#32852;&#21512;&#20248;&#21270;&#26469;&#21516;&#26102;&#36827;&#34892;&#29305;&#24449;&#36873;&#25321;&#21644;&#27169;&#22411;&#35757;&#32451;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#36890;&#36807;&#32852;&#21512;&#20248;&#21270;&#21644;&#20108;&#20540;&#23631;&#34109;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#25345;&#32493;&#35843;&#25972;&#29305;&#24449;&#38598;&#21644;&#27169;&#22411;&#21442;&#25968;&#12290;&#36825;&#31181;&#26041;&#27861;&#26174;&#33879;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#65292;&#24182;&#20943;&#23569;&#20102;&#35745;&#31639;&#38656;&#27714;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#31995;&#21015;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#23558;AFS-BM&#19982;&#24050;&#26377;&#30340;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of feature selection in general machine learning (ML) context, which is one of the most critical subjects in the field. Although, there exist many feature selection methods, however, these methods face challenges such as scalability, managing high-dimensional data, dealing with correlated features, adapting to variable feature importance, and integrating domain knowledge. To this end, we introduce the ``Adaptive Feature Selection with Binary Masking" (AFS-BM) which remedies these problems. AFS-BM achieves this by joint optimization for simultaneous feature selection and model training. In particular, we do the joint optimization and binary masking to continuously adapt the set of features and model parameters during the training process. This approach leads to significant improvements in model accuracy and a reduction in computational requirements. We provide an extensive set of experiments where we compare AFS-BM with the established feature selection methods usin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24037;&#20855;&#21464;&#37327;&#27861;&#35782;&#21035;&#21644;&#20272;&#35745;&#36830;&#32493;&#22788;&#29702;&#30340;&#22240;&#26524;&#25928;&#24212;&#24322;&#36136;&#24615;&#30340;&#26041;&#27861;&#65292;&#24182;&#24320;&#21457;&#20102;&#19977;&#31867;&#30456;&#24212;&#30340;&#20272;&#35745;&#22120;&#65292;&#24182;&#23545;&#20854;&#36827;&#34892;&#20102;&#32479;&#35745;&#24615;&#36136;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/2401.11130</link><description>&lt;p&gt;
&#36890;&#36807;&#24037;&#20855;&#21464;&#37327;&#27861;&#35782;&#21035;&#21644;&#20272;&#35745;&#26465;&#20214;&#24179;&#22343;&#20559;&#22240;&#26524;&#25928;&#24212;
&lt;/p&gt;
&lt;p&gt;
Identification and Estimation of Conditional Average Partial Causal Effects via Instrumental Variable. (arXiv:2401.11130v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11130
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24037;&#20855;&#21464;&#37327;&#27861;&#35782;&#21035;&#21644;&#20272;&#35745;&#36830;&#32493;&#22788;&#29702;&#30340;&#22240;&#26524;&#25928;&#24212;&#24322;&#36136;&#24615;&#30340;&#26041;&#27861;&#65292;&#24182;&#24320;&#21457;&#20102;&#19977;&#31867;&#30456;&#24212;&#30340;&#20272;&#35745;&#22120;&#65292;&#24182;&#23545;&#20854;&#36827;&#34892;&#20102;&#32479;&#35745;&#24615;&#36136;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#23545;&#20110;&#20272;&#35745;&#24322;&#36136;&#22240;&#26524;&#25928;&#24212;&#30340;&#20852;&#36259;&#26085;&#30410;&#22686;&#21152;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#26465;&#20214;&#24179;&#22343;&#20559;&#22240;&#26524;&#25928;&#24212;&#65288;CAPCE&#65289;&#65292;&#20197;&#25581;&#31034;&#36830;&#32493;&#22788;&#29702;&#30340;&#22240;&#26524;&#25928;&#24212;&#30340;&#24322;&#36136;&#24615;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#22312;&#24037;&#20855;&#21464;&#37327;&#35774;&#32622;&#19979;&#35782;&#21035;CAPCE&#30340;&#26465;&#20214;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19977;&#31867;CAPCE&#20272;&#35745;&#22120;&#65306;&#31579;&#36873;&#12289;&#21442;&#25968;&#21270;&#21644;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;-&#22522;&#30784;&#65292;&#20998;&#26512;&#20102;&#23427;&#20204;&#30340;&#32479;&#35745;&#24615;&#36136;&#12290;&#25105;&#20204;&#36890;&#36807;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#23545;&#25552;&#20986;&#30340;CAPCE&#20272;&#35745;&#22120;&#36827;&#34892;&#20102;&#35828;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
There has been considerable recent interest in estimating heterogeneous causal effects. In this paper, we introduce conditional average partial causal effects (CAPCE) to reveal the heterogeneity of causal effects with continuous treatment. We provide conditions for identifying CAPCE in an instrumental variable setting. We develop three families of CAPCE estimators: sieve, parametric, and reproducing kernel Hilbert space (RKHS)-based, and analyze their statistical properties. We illustrate the proposed CAPCE estimators on synthetic and real-world data.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#21152;&#26435;K&#26368;&#36817;&#37051;&#31639;&#27861;&#39640;&#25928;&#35745;&#31639;Data Shapley&#20540;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20854;&#22312;&#25968;&#25454;&#36136;&#37327;&#21028;&#21035;&#26041;&#38754;&#20248;&#20110;&#26410;&#21152;&#26435;&#29256;&#26412;&#12290;</title><link>http://arxiv.org/abs/2401.11103</link><description>&lt;p&gt;
&#21152;&#26435;&#26368;&#36817;&#37051;&#31639;&#27861;&#30340;&#39640;&#25928;&#25968;&#25454;Shapley&#20540;&#35745;&#31639;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Efficient Data Shapley for Weighted Nearest Neighbor Algorithms. (arXiv:2401.11103v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11103
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#21152;&#26435;K&#26368;&#36817;&#37051;&#31639;&#27861;&#39640;&#25928;&#35745;&#31639;Data Shapley&#20540;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20854;&#22312;&#25968;&#25454;&#36136;&#37327;&#21028;&#21035;&#26041;&#38754;&#20248;&#20110;&#26410;&#21152;&#26435;&#29256;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#35299;&#20915;&#25968;&#25454;&#35780;&#20272;&#25991;&#29486;&#20013;&#20851;&#20110;&#21152;&#26435;K&#26368;&#36817;&#37051;&#31639;&#27861;&#30340;&#25968;&#25454;Shapley&#20540;&#65288;WKNN-Shapley&#65289;&#39640;&#25928;&#35745;&#31639;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#23558;&#30828;&#26631;&#31614;KNN&#30340;&#20934;&#30830;&#24230;&#19982;&#31163;&#25955;&#26435;&#37325;&#35270;&#20026;&#25928;&#29992;&#20989;&#25968;&#65292;&#25105;&#20204;&#23558;WKNN-Shapley&#20540;&#30340;&#35745;&#31639;&#36716;&#21270;&#20026;&#19968;&#20010;&#35745;&#25968;&#38382;&#39064;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#20108;&#27425;&#26102;&#38388;&#22797;&#26434;&#24230;&#30340;&#31639;&#27861;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#23545;&#29616;&#26377;&#25991;&#29486;&#20013;O(N^K)&#30340;&#26368;&#20339;&#32467;&#26524;&#30340;&#26174;&#33879;&#25913;&#36827;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#30830;&#23450;&#24615;&#36817;&#20284;&#31639;&#27861;&#65292;&#36827;&#19968;&#27493;&#25552;&#39640;&#20102;&#35745;&#31639;&#25928;&#29575;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;Shapley&#20540;&#30340;&#20851;&#38190;&#20844;&#24179;&#24615;&#36136;&#12290;&#36890;&#36807;&#22823;&#37327;&#23454;&#39564;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;WKNN-Shapley&#20540;&#30340;&#35745;&#31639;&#25928;&#29575;&#20197;&#21450;&#19982;&#26410;&#21152;&#26435;&#29256;&#26412;&#30456;&#27604;&#22312;&#21028;&#26029;&#25968;&#25454;&#36136;&#37327;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work aims to address an open problem in data valuation literature concerning the efficient computation of Data Shapley for weighted $K$ nearest neighbor algorithm (WKNN-Shapley). By considering the accuracy of hard-label KNN with discretized weights as the utility function, we reframe the computation of WKNN-Shapley into a counting problem and introduce a quadratic-time algorithm, presenting a notable improvement from $O(N^K)$, the best result from existing literature. We develop a deterministic approximation algorithm that further improves computational efficiency while maintaining the key fairness properties of the Shapley value. Through extensive experiments, we demonstrate WKNN-Shapley's computational efficiency and its superior performance in discerning data quality compared to its unweighted counterpart.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#32858;&#21512;&#21709;&#24212;&#20013;&#23398;&#20064;&#30340;&#20004;&#31181;&#25439;&#22833;&#20989;&#25968;&#65306;&#21253;&#32423;&#21035;&#25439;&#22833;&#21644;&#23454;&#20363;&#32423;&#21035;&#25439;&#22833;&#65292;&#24182;&#21457;&#29616;&#23454;&#20363;&#32423;&#21035;&#25439;&#22833;&#21487;&#20197;&#34987;&#35270;&#20026;&#21253;&#32423;&#21035;&#25439;&#22833;&#30340;&#27491;&#21017;&#21270;&#24418;&#24335;&#12290;</title><link>http://arxiv.org/abs/2401.11081</link><description>&lt;p&gt;
&#20174;&#32858;&#21512;&#21709;&#24212;&#20013;&#23398;&#20064;&#65306;&#23454;&#20363;&#32423;&#21035;&#19982;&#21253;&#32423;&#21035;&#30340;&#25439;&#22833;&#20989;&#25968;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
Learning from Aggregate responses: Instance Level versus Bag Level Loss Functions. (arXiv:2401.11081v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11081
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#32858;&#21512;&#21709;&#24212;&#20013;&#23398;&#20064;&#30340;&#20004;&#31181;&#25439;&#22833;&#20989;&#25968;&#65306;&#21253;&#32423;&#21035;&#25439;&#22833;&#21644;&#23454;&#20363;&#32423;&#21035;&#25439;&#22833;&#65292;&#24182;&#21457;&#29616;&#23454;&#20363;&#32423;&#21035;&#25439;&#22833;&#21487;&#20197;&#34987;&#35270;&#20026;&#21253;&#32423;&#21035;&#25439;&#22833;&#30340;&#27491;&#21017;&#21270;&#24418;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#38544;&#31169;&#38382;&#39064;&#30340;&#22686;&#21152;&#65292;&#22312;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#35757;&#32451;&#25968;&#25454;&#22312;&#19982;&#23398;&#20064;&#32773;&#20849;&#20139;&#20043;&#21069;&#20250;&#34987;&#32858;&#21512;&#36215;&#26469;&#65292;&#20197;&#20445;&#25252;&#29992;&#25143;&#25935;&#24863;&#21709;&#24212;&#30340;&#38544;&#31169;&#12290;&#22312;&#32858;&#21512;&#23398;&#20064;&#26694;&#26550;&#20013;&#65292;&#25968;&#25454;&#38598;&#34987;&#20998;&#32452;&#25104;&#26679;&#26412;&#30340;&#21253;&#65292;&#27599;&#20010;&#21253;&#21482;&#25552;&#20379;&#19968;&#20010;&#32858;&#21512;&#21709;&#24212;&#65292;&#25552;&#20379;&#20102;&#35813;&#21253;&#20013;&#20010;&#20307;&#21709;&#24212;&#30340;&#25688;&#35201;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#32858;&#21512;&#21709;&#24212;&#20013;&#23398;&#20064;&#30340;&#20004;&#31181;&#33258;&#28982;&#25439;&#22833;&#20989;&#25968;&#65306;&#21253;&#32423;&#21035;&#25439;&#22833;&#21644;&#23454;&#20363;&#32423;&#21035;&#25439;&#22833;&#12290;&#22312;&#21069;&#32773;&#20013;&#65292;&#27169;&#22411;&#36890;&#36807;&#26368;&#23567;&#21270;&#32858;&#21512;&#21709;&#24212;&#19982;&#32858;&#21512;&#27169;&#22411;&#39044;&#27979;&#20043;&#38388;&#30340;&#25439;&#22833;&#26469;&#23398;&#20064;&#65292;&#32780;&#22312;&#21518;&#32773;&#20013;&#65292;&#27169;&#22411;&#26088;&#22312;&#23558;&#20010;&#20307;&#39044;&#27979;&#19982;&#32858;&#21512;&#21709;&#24212;&#25311;&#21512;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#34920;&#26126;&#23454;&#20363;&#32423;&#21035;&#25439;&#22833;&#21487;&#20197;&#34987;&#35270;&#20026;&#21253;&#32423;&#21035;&#25439;&#22833;&#30340;&#27491;&#21017;&#21270;&#24418;&#24335;&#12290;&#36825;&#20010;&#35266;&#23519;&#35753;&#25105;&#20204;&#33021;&#22815;&#27604;&#36739;&#36825;&#20004;&#31181;&#26041;&#27861;&#20851;&#20110;&#25152;&#24471;&#20272;&#35745;&#20540;&#30340;&#20559;&#24046;&#21644;&#26041;&#24046;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#25554;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Due to the rise of privacy concerns, in many practical applications the training data is aggregated before being shared with the learner, in order to protect privacy of users' sensitive responses. In an aggregate learning framework, the dataset is grouped into bags of samples, where each bag is available only with an aggregate response, providing a summary of individuals' responses in that bag. In this paper, we study two natural loss functions for learning from aggregate responses: bag-level loss and the instance-level loss. In the former, the model is learnt by minimizing a loss between aggregate responses and aggregate model predictions, while in the latter the model aims to fit individual predictions to the aggregate responses. In this work, we show that the instance-level loss can be perceived as a regularized form of the bag-level loss. This observation lets us compare the two approaches with respect to bias and variance of the resulting estimators, and introduce a novel interpol
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22343;&#20540;&#22330;&#21464;&#20998;&#26063;&#21644;&#28385;&#31209;&#21464;&#20998;&#26063;&#20043;&#38388;&#30340;&#29702;&#35770;&#20013;&#38388;&#22320;&#24102;&#65306;&#32467;&#26500;&#21270;&#21464;&#20998;&#26063;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#35777;&#26126;&#32467;&#26500;&#21270;&#21464;&#20998;&#26063;&#21487;&#20197;&#22312;&#36845;&#20195;&#22797;&#26434;&#24615;&#19978;&#34920;&#29616;&#26356;&#22909;&#65292;&#32553;&#25918;&#25928;&#26524;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2401.10989</link><description>&lt;p&gt;
&#20855;&#26377;&#32467;&#26500;&#21270;&#21464;&#20998;&#26063;&#30340;&#21487;&#35777;&#20280;&#32553;&#24615;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Provably Scalable Black-Box Variational Inference with Structured Variational Families. (arXiv:2401.10989v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10989
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22343;&#20540;&#22330;&#21464;&#20998;&#26063;&#21644;&#28385;&#31209;&#21464;&#20998;&#26063;&#20043;&#38388;&#30340;&#29702;&#35770;&#20013;&#38388;&#22320;&#24102;&#65306;&#32467;&#26500;&#21270;&#21464;&#20998;&#26063;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#35777;&#26126;&#32467;&#26500;&#21270;&#21464;&#20998;&#26063;&#21487;&#20197;&#22312;&#36845;&#20195;&#22797;&#26434;&#24615;&#19978;&#34920;&#29616;&#26356;&#22909;&#65292;&#32553;&#25918;&#25928;&#26524;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24050;&#30693;&#20855;&#26377;&#28385;&#31209;&#21327;&#26041;&#24046;&#36924;&#36817;&#30340;&#21464;&#20998;&#26063;&#22312;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#20013;&#34920;&#29616;&#19981;&#20339;&#65292;&#26080;&#35770;&#26159;&#20174;&#23454;&#35777;&#19978;&#36824;&#26159;&#29702;&#35770;&#19978;&#12290;&#20107;&#23454;&#19978;&#65292;&#26368;&#36817;&#23545;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#30340;&#35745;&#31639;&#22797;&#26434;&#24615;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#22343;&#20540;&#22330;&#21464;&#20998;&#26063;&#30456;&#27604;&#65292;&#28385;&#31209;&#21464;&#20998;&#26063;&#22312;&#38382;&#39064;&#30340;&#32500;&#24230;&#19978;&#25193;&#23637;&#24471;&#24456;&#24046;&#12290;&#36825;&#23545;&#20855;&#26377;&#26412;&#22320;&#21464;&#37327;&#30340;&#20998;&#23618;&#36125;&#21494;&#26031;&#27169;&#22411;&#23588;&#20026;&#20851;&#38190;&#65292;&#23427;&#20204;&#30340;&#32500;&#24230;&#38543;&#30528;&#25968;&#25454;&#38598;&#30340;&#22823;&#23567;&#32780;&#22686;&#21152;&#12290;&#22240;&#27492;&#65292;&#36845;&#20195;&#22797;&#26434;&#24615;&#23545;&#25968;&#25454;&#38598;&#22823;&#23567;N&#23384;&#22312;&#26126;&#30830;&#30340;O(N^2)&#20381;&#36182;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#22343;&#20540;&#22330;&#21464;&#20998;&#26063;&#21644;&#28385;&#31209;&#21464;&#20998;&#26063;&#20043;&#38388;&#30340;&#29702;&#35770;&#20013;&#38388;&#22320;&#24102;&#65306;&#32467;&#26500;&#21270;&#21464;&#20998;&#26063;&#12290;&#25105;&#20204;&#20005;&#26684;&#35777;&#26126;&#20102;&#26576;&#20123;&#23610;&#24230;&#30697;&#38453;&#32467;&#26500;&#21487;&#20197;&#23454;&#29616;&#26356;&#22909;&#30340;&#36845;&#20195;&#22797;&#26434;&#24615;O(N)&#65292;&#20174;&#32780;&#19982;N&#30340;&#32553;&#25918;&#26356;&#22909;&#22320;&#21305;&#37197;&#12290;&#25105;&#20204;&#22312;&#29616;&#23454;&#20013;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;
&lt;/p&gt;
&lt;p&gt;
Variational families with full-rank covariance approximations are known not to work well in black-box variational inference (BBVI), both empirically and theoretically. In fact, recent computational complexity results for BBVI have established that full-rank variational families scale poorly with the dimensionality of the problem compared to e.g. mean field families. This is particularly critical to hierarchical Bayesian models with local variables; their dimensionality increases with the size of the datasets. Consequently, one gets an iteration complexity with an explicit $\mathcal{O}(N^2)$ dependence on the dataset size $N$. In this paper, we explore a theoretical middle ground between mean-field variational families and full-rank families: structured variational families. We rigorously prove that certain scale matrix structures can achieve a better iteration complexity of $\mathcal{O}(N)$, implying better scaling with respect to $N$. We empirically verify our theoretical results on l
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#21322;&#27491;&#23450;&#35268;&#21010;&#36827;&#34892;&#20154;&#32676;&#32858;&#31867;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#35745;&#31639;&#39640;&#25928;&#30340;&#31639;&#27861;&#12290;&#36825;&#20123;&#31639;&#27861;&#21487;&#20197;&#26681;&#25454;&#23567;&#26679;&#26412;&#25968;&#25454;&#30340;&#21407;&#22987;&#31181;&#32676;&#23558;&#25968;&#25454;&#20998;&#20026;&#20004;&#32452;&#65292;&#36866;&#29992;&#20110;&#31181;&#32676;&#20043;&#38388;&#24046;&#24322;&#36739;&#23567;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2401.10927</link><description>&lt;p&gt;
&#20351;&#29992;&#21322;&#27491;&#23450;&#35268;&#21010;&#30340;&#21435;&#20559;&#21644;&#23616;&#37096;&#20998;&#26512;&#36827;&#34892;&#20154;&#32676;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Debiasing and a local analysis for population clustering using semidefinite programming. (arXiv:2401.10927v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10927
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#21322;&#27491;&#23450;&#35268;&#21010;&#36827;&#34892;&#20154;&#32676;&#32858;&#31867;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#35745;&#31639;&#39640;&#25928;&#30340;&#31639;&#27861;&#12290;&#36825;&#20123;&#31639;&#27861;&#21487;&#20197;&#26681;&#25454;&#23567;&#26679;&#26412;&#25968;&#25454;&#30340;&#21407;&#22987;&#31181;&#32676;&#23558;&#25968;&#25454;&#20998;&#20026;&#20004;&#32452;&#65292;&#36866;&#29992;&#20110;&#31181;&#32676;&#20043;&#38388;&#24046;&#24322;&#36739;&#23567;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#20174;&#28151;&#21512;&#30340;2&#20010;&#27425;&#39640;&#26031;&#20998;&#24067;&#20013;&#25277;&#21462;&#30340;&#23567;&#25968;&#25454;&#26679;&#26412;&#30340;&#20998;&#21306;&#38382;&#39064;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#21516;&#19968;&#20316;&#32773;&#25552;&#20986;&#30340;&#35745;&#31639;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#23558;&#25968;&#25454;&#26681;&#25454;&#20854;&#21407;&#22987;&#31181;&#32676;&#22823;&#33268;&#20998;&#20026;&#20004;&#32452;&#65292;&#32473;&#23450;&#19968;&#20010;&#23567;&#26679;&#26412;&#12290;&#26412;&#25991;&#30340;&#30740;&#31350;&#21160;&#26426;&#26159;&#23558;&#20010;&#20307;&#26681;&#25454;&#20854;&#21407;&#22987;&#31181;&#32676;&#20351;&#29992;p&#20010;&#26631;&#35760;&#36827;&#34892;&#32858;&#31867;&#65292;&#24403;&#20219;&#24847;&#20004;&#20010;&#31181;&#32676;&#20043;&#38388;&#30340;&#24046;&#24322;&#24456;&#23567;&#26102;&#12290;&#25105;&#20204;&#22522;&#20110;&#25972;&#25968;&#20108;&#27425;&#35268;&#21010;&#30340;&#21322;&#27491;&#23450;&#26494;&#24347;&#24418;&#24335;&#26500;&#24314;&#65292;&#35813;&#35268;&#21010;&#38382;&#39064;&#26412;&#36136;&#19978;&#26159;&#22312;&#19968;&#20010;&#22270;&#19978;&#25214;&#21040;&#26368;&#22823;&#21106;&#65292;&#20854;&#20013;&#21106;&#20013;&#30340;&#36793;&#26435;&#37325;&#34920;&#31034;&#22522;&#20110;&#23427;&#20204;&#30340;p&#20010;&#29305;&#24449;&#30340;&#20004;&#20010;&#33410;&#28857;&#20043;&#38388;&#30340;&#19981;&#30456;&#20284;&#24230;&#24471;&#20998;&#12290;&#25105;&#20204;&#29992;&#916;^2:=p&#947;&#26469;&#34920;&#31034;&#20004;&#20010;&#20013;&#24515;&#65288;&#22343;&#20540;&#21521;&#37327;&#65289;&#20043;&#38388;&#30340;&#8467;_2^2&#36317;&#31163;&#65292;&#21363;&#956;^(1), &#956;^(2)&#8712;&#8477;^p&#12290;&#30446;&#26631;&#26159;&#22312;&#20132;&#25442;&#31934;&#24230;&#21644;&#35745;&#31639;&#25928;&#29575;&#20043;&#38388;&#25552;&#20379;&#20840;&#38754;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we consider the problem of partitioning a small data sample of size $n$ drawn from a mixture of $2$ sub-gaussian distributions. In particular, we analyze computational efficient algorithms proposed by the same author, to partition data into two groups approximately according to their population of origin given a small sample. This work is motivated by the application of clustering individuals according to their population of origin using $p$ markers, when the divergence between any two of the populations is small. We build upon the semidefinite relaxation of an integer quadratic program that is formulated essentially as finding the maximum cut on a graph, where edge weights in the cut represent dissimilarity scores between two nodes based on their $p$ features. Here we use $\Delta^2 :=p \gamma$ to denote the $\ell_2^2$ distance between two centers (mean vectors), namely, $\mu^{(1)}$, $\mu^{(2)}$ $\in$ $\mathbb{R}^p$. The goal is to allow a full range of tradeoffs between
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#20272;&#35745;Hessian&#30697;&#38453;&#36870;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;Robbins-Monro&#36807;&#31243;&#65292;&#33021;&#22815; drastical reducescomputational complexity,&#24182;&#21457;&#23637;&#20102;&#36890;&#29992;&#30340;&#38543;&#26426;&#29275;&#39039;&#31639;&#27861;&#65292;&#30740;&#31350;&#20102;&#25152;&#25552;&#26041;&#27861;&#30340;&#28176;&#36827;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2401.10923</link><description>&lt;p&gt;
&#22312;&#20855;&#26377;&#36890;&#29992;&#38543;&#26426;&#29275;&#39039;&#31639;&#27861;&#24212;&#29992;&#20110;&#38543;&#26426;&#20248;&#21270;&#30340;&#24773;&#20917;&#19979;&#65292;&#20851;&#20110;Hessian&#30697;&#38453;&#30340;&#36870;&#30340;&#22312;&#32447;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Online estimation of the inverse of the Hessian for stochastic optimization with application to universal stochastic Newton algorithms. (arXiv:2401.10923v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10923
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#20272;&#35745;Hessian&#30697;&#38453;&#36870;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;Robbins-Monro&#36807;&#31243;&#65292;&#33021;&#22815; drastical reducescomputational complexity,&#24182;&#21457;&#23637;&#20102;&#36890;&#29992;&#30340;&#38543;&#26426;&#29275;&#39039;&#31639;&#27861;&#65292;&#30740;&#31350;&#20102;&#25152;&#25552;&#26041;&#27861;&#30340;&#28176;&#36827;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#20197;&#26399;&#26395;&#24418;&#24335;&#34920;&#31034;&#30340;&#20984;&#20989;&#25968;&#30340;&#27425;&#20248;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#30452;&#25509;&#36882;&#24402;&#20272;&#35745;&#36870;Hessian&#30697;&#38453;&#30340;&#25216;&#26415;&#65292;&#37319;&#29992;&#20102;Robbins-Monro&#36807;&#31243;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#22823;&#24133;&#38477;&#20302;&#35745;&#31639;&#22797;&#26434;&#24615;&#65292;&#24182;&#19988;&#20801;&#35768;&#24320;&#21457;&#36890;&#29992;&#30340;&#38543;&#26426;&#29275;&#39039;&#26041;&#27861;&#65292;&#24182;&#30740;&#31350;&#25152;&#25552;&#26041;&#27861;&#30340;&#28176;&#36817;&#25928;&#29575;&#12290;&#36825;&#39033;&#24037;&#20316;&#25193;&#23637;&#20102;&#22312;&#38543;&#26426;&#20248;&#21270;&#20013;&#20108;&#38454;&#31639;&#27861;&#30340;&#24212;&#29992;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper addresses second-order stochastic optimization for estimating the minimizer of a convex function written as an expectation. A direct recursive estimation technique for the inverse Hessian matrix using a Robbins-Monro procedure is introduced. This approach enables to drastically reduces computational complexity. Above all, it allows to develop universal stochastic Newton methods and investigate the asymptotic efficiency of the proposed approach. This work so expands the application scope of secondorder algorithms in stochastic optimization.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#23618;&#32593;&#32476;&#35757;&#32451;&#20013;&#30340;&#26089;&#26399;&#23545;&#40784;&#29616;&#35937;&#65292;&#21457;&#29616;&#22312;&#23567;&#21021;&#22987;&#21270;&#21644;&#19968;&#20010;&#38544;&#34255;&#30340;ReLU&#23618;&#32593;&#32476;&#20013;&#65292;&#31070;&#32463;&#20803;&#20250;&#22312;&#35757;&#32451;&#30340;&#26089;&#26399;&#38454;&#27573;&#21521;&#20851;&#38190;&#26041;&#21521;&#36827;&#34892;&#23545;&#40784;&#65292;&#23548;&#33268;&#32593;&#32476;&#31232;&#30095;&#34920;&#31034;&#20197;&#21450;&#26799;&#24230;&#27969;&#22312;&#25910;&#25947;&#26102;&#30340;&#38544;&#21547;&#20559;&#22909;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#31232;&#30095;&#35825;&#23548;&#30340;&#23545;&#40784;&#20063;&#20351;&#24471;&#35757;&#32451;&#30446;&#26631;&#30340;&#26368;&#23567;&#21270;&#21464;&#24471;&#22256;&#38590;&#12290;</title><link>http://arxiv.org/abs/2401.10791</link><description>&lt;p&gt;
&#20004;&#23618;&#32593;&#32476;&#35757;&#32451;&#20013;&#30340;&#26089;&#26399;&#23545;&#40784;&#26159;&#19968;&#25226;&#21452;&#20995;&#21073;
&lt;/p&gt;
&lt;p&gt;
Early alignment in two-layer networks training is a two-edged sword. (arXiv:2401.10791v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.10791
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#23618;&#32593;&#32476;&#35757;&#32451;&#20013;&#30340;&#26089;&#26399;&#23545;&#40784;&#29616;&#35937;&#65292;&#21457;&#29616;&#22312;&#23567;&#21021;&#22987;&#21270;&#21644;&#19968;&#20010;&#38544;&#34255;&#30340;ReLU&#23618;&#32593;&#32476;&#20013;&#65292;&#31070;&#32463;&#20803;&#20250;&#22312;&#35757;&#32451;&#30340;&#26089;&#26399;&#38454;&#27573;&#21521;&#20851;&#38190;&#26041;&#21521;&#36827;&#34892;&#23545;&#40784;&#65292;&#23548;&#33268;&#32593;&#32476;&#31232;&#30095;&#34920;&#31034;&#20197;&#21450;&#26799;&#24230;&#27969;&#22312;&#25910;&#25947;&#26102;&#30340;&#38544;&#21547;&#20559;&#22909;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#31232;&#30095;&#35825;&#23548;&#30340;&#23545;&#40784;&#20063;&#20351;&#24471;&#35757;&#32451;&#30446;&#26631;&#30340;&#26368;&#23567;&#21270;&#21464;&#24471;&#22256;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#19968;&#38454;&#20248;&#21270;&#26041;&#27861;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#26159;&#28145;&#24230;&#23398;&#20064;&#25104;&#21151;&#30340;&#26680;&#24515;&#12290;&#21021;&#22987;&#21270;&#30340;&#35268;&#27169;&#26159;&#19968;&#20010;&#20851;&#38190;&#22240;&#32032;&#65292;&#22240;&#20026;&#23567;&#30340;&#21021;&#22987;&#21270;&#36890;&#24120;&#19982;&#29305;&#24449;&#23398;&#20064;&#27169;&#24335;&#30456;&#20851;&#65292;&#22312;&#36825;&#31181;&#27169;&#24335;&#19979;&#65292;&#26799;&#24230;&#19979;&#38477;&#23545;&#31616;&#21333;&#35299;&#38544;&#21547;&#20559;&#22909;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#26089;&#26399;&#23545;&#40784;&#38454;&#27573;&#30340;&#26222;&#36941;&#21644;&#37327;&#21270;&#25551;&#36848;&#65292;&#26368;&#21021;&#30001;Maennel&#31561;&#20154;&#25552;&#20986;&#12290;&#23545;&#20110;&#23567;&#21021;&#22987;&#21270;&#21644;&#19968;&#20010;&#38544;&#34255;&#30340;ReLU&#23618;&#32593;&#32476;&#65292;&#35757;&#32451;&#21160;&#24577;&#30340;&#26089;&#26399;&#38454;&#27573;&#23548;&#33268;&#31070;&#32463;&#20803;&#21521;&#20851;&#38190;&#26041;&#21521;&#36827;&#34892;&#23545;&#40784;&#12290;&#36825;&#31181;&#23545;&#40784;&#24341;&#21457;&#20102;&#32593;&#32476;&#30340;&#31232;&#30095;&#34920;&#31034;&#65292;&#36825;&#19982;&#26799;&#24230;&#27969;&#22312;&#25910;&#25947;&#26102;&#30340;&#38544;&#21547;&#20559;&#22909;&#30452;&#25509;&#30456;&#20851;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#31232;&#30095;&#35825;&#23548;&#30340;&#23545;&#40784;&#26159;&#20197;&#22312;&#26368;&#23567;&#21270;&#35757;&#32451;&#30446;&#26631;&#26041;&#38754;&#36935;&#21040;&#22256;&#38590;&#20026;&#20195;&#20215;&#30340;&#65306;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#25968;&#25454;&#31034;&#20363;&#65292;&#20854;&#20013;&#36229;&#21442;&#25968;&#32593;&#32476;&#26080;&#27861;&#25910;&#25947;&#21040;&#20840;&#23616;&#26368;&#23567;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Training neural networks with first order optimisation methods is at the core of the empirical success of deep learning. The scale of initialisation is a crucial factor, as small initialisations are generally associated to a feature learning regime, for which gradient descent is implicitly biased towards simple solutions. This work provides a general and quantitative description of the early alignment phase, originally introduced by Maennel et al. (2018) . For small initialisation and one hidden ReLU layer networks, the early stage of the training dynamics leads to an alignment of the neurons towards key directions. This alignment induces a sparse representation of the network, which is directly related to the implicit bias of gradient flow at convergence. This sparsity inducing alignment however comes at the expense of difficulties in minimising the training objective: we also provide a simple data example for which overparameterised networks fail to converge towards global minima and
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#22312;&#33258;&#28982;&#22270;&#20687;&#21644;&#21307;&#23398;&#22270;&#20687;&#39046;&#22495;&#23398;&#20064;&#26102;&#30340;&#24046;&#24322;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#19982;&#35757;&#32451;&#38598;&#32500;&#24230;&#26377;&#20851;&#30340;&#27867;&#21270;&#32553;&#25918;&#23450;&#24459;&#65292;&#24182;&#35748;&#20026;&#21307;&#23398;&#22270;&#20687;&#25968;&#25454;&#38598;&#26356;&#39640;&#30340;&#22266;&#26377;&#8220;&#26631;&#31614;&#38160;&#24230;&#8221;&#21487;&#33021;&#26159;&#20004;&#20010;&#39046;&#22495;&#20043;&#38388;&#26174;&#33879;&#24046;&#24322;&#30340;&#37096;&#20998;&#21407;&#22240;&#12290;</title><link>http://arxiv.org/abs/2401.08865</link><description>&lt;p&gt;
Intrinsic Dataset Properties&#23545;&#27867;&#21270;&#33021;&#21147;&#30340;&#24433;&#21709;&#65306;&#25581;&#31034;&#33258;&#28982;&#22270;&#20687;&#21644;&#21307;&#23398;&#22270;&#20687;&#20043;&#38388;&#30340;&#23398;&#20064;&#24046;&#24322;
&lt;/p&gt;
&lt;p&gt;
The Effect of Intrinsic Dataset Properties on Generalization: Unraveling Learning Differences Between Natural and Medical Images. (arXiv:2401.08865v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.08865
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#22312;&#33258;&#28982;&#22270;&#20687;&#21644;&#21307;&#23398;&#22270;&#20687;&#39046;&#22495;&#23398;&#20064;&#26102;&#30340;&#24046;&#24322;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#19982;&#35757;&#32451;&#38598;&#32500;&#24230;&#26377;&#20851;&#30340;&#27867;&#21270;&#32553;&#25918;&#23450;&#24459;&#65292;&#24182;&#35748;&#20026;&#21307;&#23398;&#22270;&#20687;&#25968;&#25454;&#38598;&#26356;&#39640;&#30340;&#22266;&#26377;&#8220;&#26631;&#31614;&#38160;&#24230;&#8221;&#21487;&#33021;&#26159;&#20004;&#20010;&#39046;&#22495;&#20043;&#38388;&#26174;&#33879;&#24046;&#24322;&#30340;&#37096;&#20998;&#21407;&#22240;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#22312;&#19981;&#21516;&#22270;&#20687;&#39046;&#22495;&#23398;&#20064;&#26102;&#30340;&#24046;&#24322;&#65292;&#36825;&#22312;&#20174;&#33258;&#28982;&#22270;&#20687;&#21040;&#20854;&#20182;&#19987;&#38376;&#39046;&#22495;&#65288;&#22914;&#21307;&#23398;&#22270;&#20687;&#65289;&#37319;&#29992;&#35745;&#31639;&#26426;&#35270;&#35273;&#25216;&#26415;&#26102;&#36890;&#24120;&#34987;&#24573;&#35270;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#35757;&#32451;&#38598;&#30340;&#22266;&#26377;&#32500;&#24230;($d_{data}$)&#19982;&#32593;&#32476;&#30340;&#27867;&#21270;&#38169;&#35823;&#19968;&#33324;&#20250;&#22686;&#21152;&#12290;&#28982;&#32780;&#65292;&#21307;&#23398;&#65288;&#25918;&#23556;&#23398;&#65289;&#21644;&#33258;&#28982;&#22270;&#20687;&#39046;&#22495;&#20043;&#38388;&#30340;&#36825;&#31181;&#20851;&#31995;&#30340;&#38497;&#23789;&#31243;&#24230;&#23384;&#22312;&#26174;&#33879;&#24046;&#24322;&#65292;&#19988;&#26080;&#29616;&#26377;&#30340;&#29702;&#35770;&#35299;&#37322;&#12290;&#25105;&#20204;&#36890;&#36807;&#24314;&#31435;&#24182;&#32463;&#39564;&#35777;&#19968;&#20010;&#19982;$d_{data}$&#30456;&#20851;&#30340;&#27867;&#21270;&#32553;&#25918;&#23450;&#24459;&#26469;&#35299;&#20915;&#36825;&#20010;&#30693;&#35782;&#31354;&#30333;&#65292;&#24182;&#25552;&#20986;&#32771;&#34385;&#21040;&#21307;&#23398;&#22270;&#20687;&#25968;&#25454;&#38598;&#26356;&#39640;&#30340;&#22266;&#26377;&#8220;&#26631;&#31614;&#38160;&#24230;&#8221;($K_F$)&#36825;&#19968;&#24230;&#37327;&#25351;&#26631;&#21487;&#20197;&#37096;&#20998;&#35299;&#37322;&#36825;&#20004;&#20010;&#39046;&#22495;&#20043;&#38388;&#30340;&#26174;&#33879;&#32553;&#25918;&#24046;&#24322;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21033;&#29992;&#27979;&#37327;&#36825;&#19968;&#25351;&#26631;&#21487;&#20197;&#25552;&#20379;&#30340;&#39069;&#22806;&#22909;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates discrepancies in how neural networks learn from different imaging domains, which are commonly overlooked when adopting computer vision techniques from the domain of natural images to other specialized domains such as medical images. Recent works have found that the generalization error of a trained network typically increases with the intrinsic dimension ($d_{data}$) of its training set. Yet, the steepness of this relationship varies significantly between medical (radiological) and natural imaging domains, with no existing theoretical explanation. We address this gap in knowledge by establishing and empirically validating a generalization scaling law with respect to $d_{data}$, and propose that the substantial scaling discrepancy between the two considered domains may be at least partially attributed to the higher intrinsic "label sharpness" ($K_F$) of medical imaging datasets, a metric which we propose. Next, we demonstrate an additional benefit of measuring th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#26469;&#24314;&#27169;&#26102;&#38388;&#24207;&#21015;&#30340;&#21464;&#28857;&#26816;&#27979;&#31639;&#27861;&#65292;&#36890;&#36807;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#23398;&#20064;&#27599;&#20010;&#21464;&#28857;&#23545;&#24212;&#30340;&#31070;&#32463;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#21442;&#25968;&#65292;&#24182;&#36890;&#36807;GAN&#21028;&#21035;&#22120;&#30340;&#36755;&#20986;&#26816;&#27979;&#21464;&#28857;&#12290;&#39564;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#31639;&#27861;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2312.13152</link><description>&lt;p&gt;
&#24102;&#26377;&#21464;&#28857;&#30340;&#31070;&#32463;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65306;&#19968;&#31181;&#29983;&#25104;&#23545;&#25239;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Neural Stochastic Differential Equations with Change Points: A Generative Adversarial Approach. (arXiv:2312.13152v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.13152
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#26469;&#24314;&#27169;&#26102;&#38388;&#24207;&#21015;&#30340;&#21464;&#28857;&#26816;&#27979;&#31639;&#27861;&#65292;&#36890;&#36807;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#23398;&#20064;&#27599;&#20010;&#21464;&#28857;&#23545;&#24212;&#30340;&#31070;&#32463;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#21442;&#25968;&#65292;&#24182;&#36890;&#36807;GAN&#21028;&#21035;&#22120;&#30340;&#36755;&#20986;&#26816;&#27979;&#21464;&#28857;&#12290;&#39564;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#31639;&#27861;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#24191;&#27867;&#29992;&#20110;&#24314;&#27169;&#30495;&#23454;&#19990;&#30028;&#30340;&#38543;&#26426;&#29616;&#35937;&#12290;&#29616;&#26377;&#30340;&#24037;&#20316;&#20027;&#35201;&#38598;&#20013;&#22312;&#26102;&#38388;&#24207;&#21015;&#30001;&#21333;&#20010;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#24314;&#27169;&#30340;&#24773;&#20917;&#65292;&#36825;&#23545;&#20110;&#20855;&#26377;&#20998;&#24067;&#20559;&#31227;&#30340;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#21487;&#33021;&#26159;&#23616;&#38480;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#26102;&#38388;&#24207;&#21015;&#24314;&#27169;&#20026;&#31070;&#32463;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#21464;&#28857;&#26816;&#27979;&#31639;&#27861;&#12290;&#32473;&#23450;&#19968;&#20010;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#32852;&#21512;&#23398;&#20064;&#26410;&#30693;&#30340;&#21464;&#28857;&#21644;&#19982;&#27599;&#20010;&#21464;&#28857;&#23545;&#24212;&#30340;&#19981;&#21516;&#31070;&#32463;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#27169;&#22411;&#30340;&#21442;&#25968;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#31070;&#32463;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#22312;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#30340;&#26694;&#26550;&#19979;&#36827;&#34892;&#23398;&#20064;&#65292;&#24182;&#19988;&#21464;&#28857;&#26159;&#26681;&#25454;GAN&#21028;&#21035;&#22120;&#30340;&#36755;&#20986;&#22312;&#21069;&#21521;&#20256;&#36882;&#20013;&#34987;&#26816;&#27979;&#21040;&#12290;&#22312;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#30340;&#27599;&#19968;&#27493;&#20013;&#65292;&#21464;&#28857;&#21644;SDE&#27169;&#22411;&#21442;&#25968;&#20197;&#20132;&#26367;&#30340;&#26041;&#24335;&#36827;&#34892;&#26356;&#26032;&#12290;&#36890;&#36807;&#23545;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#30340;&#25968;&#20540;&#32467;&#26524;&#36827;&#34892;&#39564;&#35777;&#65292;&#20197;&#39564;&#35777;&#25105;&#20204;&#30340;&#31639;&#27861;&#19982;&#20256;&#32479;&#26041;&#27861;&#30340;&#24615;&#33021;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic differential equations (SDEs) have been widely used to model real world random phenomena. Existing works mainly focus on the case where the time series is modeled by a single SDE, which might be restrictive for modeling time series with distributional shift. In this work, we propose a change point detection algorithm for time series modeled as neural SDEs. Given a time series dataset, the proposed method jointly learns the unknown change points and the parameters of distinct neural SDE models corresponding to each change point. Specifically, the SDEs are learned under the framework of generative adversarial networks (GANs) and the change points are detected based on the output of the GAN discriminator in a forward pass. At each step of the proposed algorithm, the change points and the SDE model parameters are updated in an alternating fashion. Numerical results on both synthetic and real datasets are provided to validate the performance of our algorithm in comparison to clas
&lt;/p&gt;</description></item><item><title>&#36861;&#27714;&#26368;&#20248;&#32479;&#35745;&#27700;&#21360;&#25216;&#26415;&#12290;&#36890;&#36807;&#23558;&#32479;&#35745;&#27700;&#21360;&#25216;&#26415;&#35270;&#20026;&#20551;&#35774;&#26816;&#39564;&#38382;&#39064;&#24182;&#24341;&#20837;&#20266;&#38543;&#26426;&#29983;&#25104;&#22120;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#36755;&#20986;&#20196;&#29260;&#21644;&#25298;&#32477;&#21306;&#22495;&#30340;&#32806;&#21512;&#65292;&#23454;&#29616;&#20102;&#31532;&#19968;&#31867;&#38169;&#35823;&#21644;&#31532;&#20108;&#31867;&#38169;&#35823;&#20043;&#38388;&#30340;&#38750;&#24179;&#20961;&#26435;&#34913;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#26368;&#32479;&#19968;&#26368;&#26377;&#21147;&#30340;&#27700;&#21360;&#21644;&#26368;&#23567;&#21270;&#31532;&#20108;&#31867;&#38169;&#35823;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#29420;&#31435;&#21516;&#20998;&#24067;&#20196;&#29260;&#25968;&#37327;&#30340;&#19978;&#19979;&#30028;&#65292;&#31361;&#26174;&#20102;&#25913;&#36827;&#30340;&#28508;&#21147;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25506;&#35752;&#20102;&#40065;&#26834;&#24615;&#27700;&#21360;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2312.07930</link><description>&lt;p&gt;
&#36861;&#27714;&#26368;&#20248;&#32479;&#35745;&#27700;&#21360;&#25216;&#26415;
&lt;/p&gt;
&lt;p&gt;
Towards Optimal Statistical Watermarking. (arXiv:2312.07930v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.07930
&lt;/p&gt;
&lt;p&gt;
&#36861;&#27714;&#26368;&#20248;&#32479;&#35745;&#27700;&#21360;&#25216;&#26415;&#12290;&#36890;&#36807;&#23558;&#32479;&#35745;&#27700;&#21360;&#25216;&#26415;&#35270;&#20026;&#20551;&#35774;&#26816;&#39564;&#38382;&#39064;&#24182;&#24341;&#20837;&#20266;&#38543;&#26426;&#29983;&#25104;&#22120;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;&#36755;&#20986;&#20196;&#29260;&#21644;&#25298;&#32477;&#21306;&#22495;&#30340;&#32806;&#21512;&#65292;&#23454;&#29616;&#20102;&#31532;&#19968;&#31867;&#38169;&#35823;&#21644;&#31532;&#20108;&#31867;&#38169;&#35823;&#20043;&#38388;&#30340;&#38750;&#24179;&#20961;&#26435;&#34913;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#26368;&#32479;&#19968;&#26368;&#26377;&#21147;&#30340;&#27700;&#21360;&#21644;&#26368;&#23567;&#21270;&#31532;&#20108;&#31867;&#38169;&#35823;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#29420;&#31435;&#21516;&#20998;&#24067;&#20196;&#29260;&#25968;&#37327;&#30340;&#19978;&#19979;&#30028;&#65292;&#31361;&#26174;&#20102;&#25913;&#36827;&#30340;&#28508;&#21147;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25506;&#35752;&#20102;&#40065;&#26834;&#24615;&#27700;&#21360;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23558;&#32479;&#35745;&#27700;&#21360;&#25216;&#26415;&#20316;&#20026;&#19968;&#20010;&#20551;&#35774;&#26816;&#39564;&#38382;&#39064;&#36827;&#34892;&#30740;&#31350;&#65292;&#36825;&#26159;&#19968;&#20010;&#27867;&#21270;&#20102;&#25152;&#26377;&#20043;&#21069;&#32479;&#35745;&#27700;&#21360;&#26041;&#27861;&#30340;&#36890;&#29992;&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#26159;&#36890;&#36807;&#23454;&#36341;&#20013;&#30340;&#20266;&#38543;&#26426;&#29983;&#25104;&#22120;&#23454;&#29616;&#36755;&#20986;&#20196;&#29260;&#21644;&#25298;&#32477;&#21306;&#22495;&#30340;&#32806;&#21512;&#65292;&#20174;&#32780;&#20801;&#35768;&#22312;&#31532;&#19968;&#31867;&#38169;&#35823;&#21644;&#31532;&#20108;&#31867;&#38169;&#35823;&#20043;&#38388;&#36827;&#34892;&#38750;&#24179;&#20961;&#30340;&#26435;&#34913;&#12290;&#25105;&#20204;&#22312;&#19968;&#33324;&#30340;&#20551;&#35774;&#26816;&#39564;&#29615;&#22659;&#19979;&#34920;&#24449;&#20102;&#26368;&#32479;&#19968;&#26368;&#26377;&#21147;&#30340;&#27700;&#21360;&#20197;&#21450;&#22312;&#27169;&#22411;&#26080;&#20851;&#30340;&#29615;&#22659;&#20013;&#26368;&#23567;&#21270;&#31532;&#20108;&#31867;&#38169;&#35823;&#12290;&#22312;&#36755;&#20986;&#26159;$n$&#20010;&#20196;&#29260;&#30340;&#24120;&#35265;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#23545;&#38656;&#35201;&#20445;&#35777;&#23567;&#30340;&#31532;&#19968;&#31867;&#21644;&#31532;&#20108;&#31867;&#38169;&#35823;&#30340;&#29420;&#31435;&#21516;&#20998;&#24067;&#20196;&#29260;&#25968;&#37327;&#24314;&#31435;&#20102;&#36817;&#20046;&#21305;&#37197;&#30340;&#19978;&#19979;&#30028;&#12290;&#19982;&#20043;&#21069;&#30340;&#24037;&#20316;&#20013;&#30340;$ h ^ {-2} $&#36895;&#29575;&#30456;&#27604;&#65292;&#25105;&#20204;&#30456;&#23545;&#20110;&#27599;&#20010;&#20196;&#29260;&#30340;&#24179;&#22343;&#29109;$h$&#30340;&#36895;&#29575;&#20026;$ \Theta(h ^ {-1} \log (1/h)) $&#65292;&#31361;&#26174;&#20102;&#25913;&#36827;&#30340;&#28508;&#21147;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#40065;&#26834;&#24615;&#27700;&#21360;&#38382;&#39064;&#65292;&#20854;&#20013;&#29992;&#25143;&#37117;&#26159;...
&lt;/p&gt;
&lt;p&gt;
We study statistical watermarking by formulating it as a hypothesis testing problem, a general framework which subsumes all previous statistical watermarking methods. Key to our formulation is a coupling of the output tokens and the rejection region, realized by pseudo-random generators in practice, that allows non-trivial trade-off between the Type I error and Type II error. We characterize the Uniformly Most Powerful (UMP) watermark in the general hypothesis testing setting and the minimax Type II error in the model-agnostic setting. In the common scenario where the output is a sequence of $n$ tokens, we establish nearly matching upper and lower bounds on the number of i.i.d. tokens required to guarantee small Type I and Type II errors. Our rate of $\Theta(h^{-1} \log (1/h))$ with respect to the average entropy per token $h$ highlights potentials for improvement from the rate of $h^{-2}$ in the previous works. Moreover, we formulate the robust watermarking problem where users are all
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26368;&#20248;&#21270;&#22810;&#20998;&#24067;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#37319;&#26679;&#26469;&#23454;&#29616;&#25968;&#25454;&#39640;&#25928;&#30340;&#23398;&#20064;&#12290;&#38024;&#23545;Vapnik-Chervonenkis (VC)&#32500;&#25968;&#20026;d&#30340;&#20551;&#35774;&#31867;&#65292;&#31639;&#27861;&#21487;&#20197;&#29983;&#25104;&#19968;&#20010;&#949;-&#26368;&#20248;&#38543;&#26426;&#20551;&#35774;&#65292;&#24182;&#19988;&#26679;&#26412;&#22797;&#26434;&#24230;&#19982;&#26368;&#20339;&#19979;&#30028;&#20445;&#25345;&#19968;&#33268;&#12290;&#21516;&#26102;&#65292;&#35813;&#31639;&#27861;&#30340;&#24605;&#24819;&#21644;&#29702;&#35770;&#36824;&#34987;&#36827;&#19968;&#27493;&#25193;&#23637;&#20197;&#36866;&#24212;Rademacher&#31867;&#12290;&#26368;&#32456;&#25552;&#20986;&#30340;&#31639;&#27861;&#26159;&#22885;&#25289;&#20811;&#23572;&#39640;&#25928;&#30340;&#65292;&#20165;&#35775;&#38382;&#20551;&#35774;&#31867;&#12290;</title><link>http://arxiv.org/abs/2312.05134</link><description>&lt;p&gt;
&#26368;&#20248;&#21270;&#22810;&#20998;&#24067;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Optimal Multi-Distribution Learning. (arXiv:2312.05134v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.05134
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26368;&#20248;&#21270;&#22810;&#20998;&#24067;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#37319;&#26679;&#26469;&#23454;&#29616;&#25968;&#25454;&#39640;&#25928;&#30340;&#23398;&#20064;&#12290;&#38024;&#23545;Vapnik-Chervonenkis (VC)&#32500;&#25968;&#20026;d&#30340;&#20551;&#35774;&#31867;&#65292;&#31639;&#27861;&#21487;&#20197;&#29983;&#25104;&#19968;&#20010;&#949;-&#26368;&#20248;&#38543;&#26426;&#20551;&#35774;&#65292;&#24182;&#19988;&#26679;&#26412;&#22797;&#26434;&#24230;&#19982;&#26368;&#20339;&#19979;&#30028;&#20445;&#25345;&#19968;&#33268;&#12290;&#21516;&#26102;&#65292;&#35813;&#31639;&#27861;&#30340;&#24605;&#24819;&#21644;&#29702;&#35770;&#36824;&#34987;&#36827;&#19968;&#27493;&#25193;&#23637;&#20197;&#36866;&#24212;Rademacher&#31867;&#12290;&#26368;&#32456;&#25552;&#20986;&#30340;&#31639;&#27861;&#26159;&#22885;&#25289;&#20811;&#23572;&#39640;&#25928;&#30340;&#65292;&#20165;&#35775;&#38382;&#20551;&#35774;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20998;&#24067;&#23398;&#20064;&#65288;MDL&#65289;&#26088;&#22312;&#23398;&#20064;&#19968;&#20010;&#20849;&#20139;&#27169;&#22411;&#65292;&#20351;&#24471;&#22312;k&#20010;&#19981;&#21516;&#30340;&#25968;&#25454;&#20998;&#24067;&#19979;&#65292;&#26368;&#23567;&#21270;&#26368;&#22351;&#24773;&#20917;&#39118;&#38505;&#65292;&#24050;&#25104;&#20026;&#36866;&#24212;&#20581;&#22766;&#24615;&#12289;&#20844;&#24179;&#24615;&#12289;&#22810;&#32452;&#21512;&#20316;&#31561;&#38656;&#27714;&#30340;&#32479;&#19968;&#26694;&#26550;&#12290;&#23454;&#29616;&#25968;&#25454;&#39640;&#25928;&#30340;MDL&#38656;&#35201;&#22312;&#23398;&#20064;&#36807;&#31243;&#20013;&#36827;&#34892;&#33258;&#36866;&#24212;&#37319;&#26679;&#65292;&#20063;&#31216;&#20026;&#25353;&#38656;&#37319;&#26679;&#12290;&#28982;&#32780;&#65292;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#19978;&#19979;&#30028;&#20043;&#38388;&#23384;&#22312;&#36739;&#22823;&#24046;&#36317;&#12290;&#38024;&#23545;Vapnik-Chervonenkis&#65288;VC&#65289;&#32500;&#25968;&#20026;d&#30340;&#20551;&#35774;&#31867;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;&#65292;&#21487;&#29983;&#25104;&#19968;&#20010;&#949;-&#26368;&#20248;&#38543;&#26426;&#20551;&#35774;&#65292;&#20854;&#26679;&#26412;&#22797;&#26434;&#24230;&#25509;&#36817;&#20110;&#65288;d+k&#65289;/&#949;^2&#65288;&#22312;&#26576;&#20123;&#23545;&#25968;&#22240;&#23376;&#20013;&#65289;&#65292;&#19982;&#24050;&#30693;&#30340;&#26368;&#20339;&#19979;&#30028;&#21305;&#37197;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#24605;&#24819;&#21644;&#29702;&#35770;&#34987;&#36827;&#19968;&#27493;&#25193;&#23637;&#65292;&#20197;&#36866;&#24212;Rademacher&#31867;&#12290;&#25552;&#20986;&#30340;&#31639;&#27861;&#26159;&#22885;&#25289;&#20811;&#23572;&#39640;&#25928;&#30340;&#65292;&#20165;&#20165;&#35775;&#38382;&#20551;&#35774;&#31867;
&lt;/p&gt;
&lt;p&gt;
Multi-distribution learning (MDL), which seeks to learn a shared model that minimizes the worst-case risk across $k$ distinct data distributions, has emerged as a unified framework in response to the evolving demand for robustness, fairness, multi-group collaboration, etc. Achieving data-efficient MDL necessitates adaptive sampling, also called on-demand sampling, throughout the learning process. However, there exist substantial gaps between the state-of-the-art upper and lower bounds on the optimal sample complexity. Focusing on a hypothesis class of Vapnik-Chervonenkis (VC) dimension $d$, we propose a novel algorithm that yields an $varepsilon$-optimal randomized hypothesis with a sample complexity on the order of $(d+k)/\varepsilon^2$ (modulo some logarithmic factor), matching the best-known lower bound. Our algorithmic ideas and theory have been further extended to accommodate Rademacher classes. The proposed algorithms are oracle-efficient, which access the hypothesis class solely
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;&#26680;&#26426;&#22120;&#39044;&#22788;&#29702;&#20013;&#20351;&#29992;Nystrom&#36924;&#36817;&#30340;&#26435;&#34913;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#20351;&#29992;&#23545;&#25968;&#22823;&#23567;&#30340;&#26679;&#26412;&#33021;&#22815;&#35753;Nystrom&#36924;&#36817;&#30340;&#39044;&#22788;&#29702;&#22120;&#20960;&#20046;&#19982;&#26799;&#24230;&#19979;&#38477;&#21516;&#26679;&#26377;&#25928;&#22320;&#21152;&#36895;&#12290;</title><link>http://arxiv.org/abs/2312.03311</link><description>&lt;p&gt;
&#23545;&#20110;&#26680;&#26426;&#22120;&#22312;&#39044;&#22788;&#29702;&#20013;&#30340;Nystrom&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
On the Nystrom Approximation for Preconditioning in Kernel Machines. (arXiv:2312.03311v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.03311
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#26680;&#26426;&#22120;&#39044;&#22788;&#29702;&#20013;&#20351;&#29992;Nystrom&#36924;&#36817;&#30340;&#26435;&#34913;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#20351;&#29992;&#23545;&#25968;&#22823;&#23567;&#30340;&#26679;&#26412;&#33021;&#22815;&#35753;Nystrom&#36924;&#36817;&#30340;&#39044;&#22788;&#29702;&#22120;&#20960;&#20046;&#19982;&#26799;&#24230;&#19979;&#38477;&#21516;&#26679;&#26377;&#25928;&#22320;&#21152;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26680;&#26041;&#27861;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#19968;&#31867;&#27969;&#34892;&#30340;&#38750;&#32447;&#24615;&#39044;&#27979;&#27169;&#22411;&#12290;&#23398;&#20064;&#26680;&#27169;&#22411;&#30340;&#21487;&#25193;&#23637;&#31639;&#27861;&#38656;&#35201;&#20855;&#26377;&#36845;&#20195;&#24615;&#36136;&#65292;&#20294;&#30001;&#20110;&#31967;&#31957;&#30340;&#26465;&#20214;&#65292;&#25910;&#25947;&#21487;&#33021;&#24456;&#24930;&#12290;&#35889;&#39044;&#22788;&#29702;&#26159;&#21152;&#24555;&#35757;&#32451;&#26680;&#27169;&#22411;&#36845;&#20195;&#31639;&#27861;&#25910;&#25947;&#36895;&#24230;&#30340;&#37325;&#35201;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#35745;&#31639;&#21644;&#23384;&#20648;&#35889;&#39044;&#22788;&#29702;&#22120;&#21487;&#33021;&#20195;&#20215;&#39640;&#26114;&#65292;&#20250;&#23548;&#33268;&#22823;&#37327;&#30340;&#35745;&#31639;&#21644;&#23384;&#20648;&#24320;&#38144;&#65292;&#38480;&#21046;&#20102;&#26680;&#26041;&#27861;&#22312;&#22823;&#22411;&#25968;&#25454;&#38598;&#38382;&#39064;&#19978;&#30340;&#24212;&#29992;&#12290;Nystrom&#36924;&#36817;&#30340;&#35889;&#39044;&#22788;&#29702;&#22120;&#36890;&#24120;&#26356;&#20415;&#23452;&#21644;&#26356;&#23481;&#26131;&#35745;&#31639;&#21644;&#23384;&#20648;&#65292;&#24182;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#25104;&#21151;&#12290;&#26412;&#25991;&#20998;&#26512;&#20102;&#20351;&#29992;&#36825;&#31181;&#36924;&#36817;&#39044;&#22788;&#29702;&#22120;&#30340;&#26435;&#34913;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#34920;&#26126;&#19982;&#25968;&#25454;&#38598;&#22823;&#23567;&#30456;&#20851;&#30340;&#23545;&#25968;&#26679;&#26412;&#25968;&#37327;&#33021;&#22815;&#35753;&#22522;&#20110;Nystrom&#36924;&#36817;&#30340;&#39044;&#22788;&#29702;&#22120;&#20960;&#20046;&#19982;&#26799;&#24230;&#19979;&#38477;&#21516;&#26679;&#26377;&#25928;&#22320;&#21152;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;
Kernel methods are a popular class of nonlinear predictive models in machine learning. Scalable algorithms for learning kernel models need to be iterative in nature, but convergence can be slow due to poor conditioning. Spectral preconditioning is an important tool to speed-up the convergence of such iterative algorithms for training kernel models. However computing and storing a spectral preconditioner can be expensive which can lead to large computational and storage overheads, precluding the application of kernel methods to problems with large datasets. A Nystrom approximation of the spectral preconditioner is often cheaper to compute and store, and has demonstrated success in practical applications. In this paper we analyze the trade-offs of using such an approximated preconditioner. Specifically, we show that a sample of logarithmic size (as a function of the size of the dataset) enables the Nystrom-based approximated preconditioner to accelerate gradient descent nearly as well as
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#21457;&#29616;&#35757;&#32451;&#25968;&#25454;&#25910;&#38598;&#26041;&#27861;&#23545;&#27880;&#37322;&#26412;&#36523;&#21644;&#19979;&#28216;&#27169;&#22411;&#24615;&#33021;&#20135;&#29983;&#24433;&#21709;&#12290;&#22312;&#23545;&#20167;&#24680;&#35328;&#35770;&#21644;&#20882;&#29359;&#24615;&#35821;&#35328;&#36827;&#34892;&#27880;&#37322;&#25910;&#38598;&#30340;&#23454;&#39564;&#20013;&#65292;&#21457;&#29616;&#27880;&#37322;&#24037;&#20855;&#30340;&#35774;&#35745;&#36873;&#25321;&#20250;&#23545;&#27169;&#22411;&#30340;&#24615;&#33021;&#20135;&#29983;&#26126;&#26174;&#24046;&#24322;&#12290;</title><link>http://arxiv.org/abs/2311.14212</link><description>&lt;p&gt;
&#27880;&#37322;&#25935;&#24863;&#24615;&#65306;&#35757;&#32451;&#25968;&#25454;&#25910;&#38598;&#26041;&#27861;&#24433;&#21709;&#27169;&#22411;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;
Annotation Sensitivity: Training Data Collection Methods Affect Model Performance. (arXiv:2311.14212v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.14212
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#21457;&#29616;&#35757;&#32451;&#25968;&#25454;&#25910;&#38598;&#26041;&#27861;&#23545;&#27880;&#37322;&#26412;&#36523;&#21644;&#19979;&#28216;&#27169;&#22411;&#24615;&#33021;&#20135;&#29983;&#24433;&#21709;&#12290;&#22312;&#23545;&#20167;&#24680;&#35328;&#35770;&#21644;&#20882;&#29359;&#24615;&#35821;&#35328;&#36827;&#34892;&#27880;&#37322;&#25910;&#38598;&#30340;&#23454;&#39564;&#20013;&#65292;&#21457;&#29616;&#27880;&#37322;&#24037;&#20855;&#30340;&#35774;&#35745;&#36873;&#25321;&#20250;&#23545;&#27169;&#22411;&#30340;&#24615;&#33021;&#20135;&#29983;&#26126;&#26174;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#35757;&#32451;&#25968;&#25454;&#30001;&#20154;&#24037;&#27880;&#37322;&#32773;&#25910;&#38598;&#26102;&#65292;&#27880;&#37322;&#24037;&#20855;&#30340;&#35774;&#35745;&#12289;&#32473;&#20104;&#27880;&#37322;&#32773;&#30340;&#25351;&#31034;&#12289;&#27880;&#37322;&#32773;&#30340;&#29305;&#24449;&#20197;&#21450;&#20182;&#20204;&#20043;&#38388;&#30340;&#20114;&#21160;&#37117;&#21487;&#33021;&#23545;&#35757;&#32451;&#25968;&#25454;&#20135;&#29983;&#24433;&#21709;&#12290;&#36825;&#39033;&#30740;&#31350;&#35777;&#26126;&#20102;&#21019;&#24314;&#27880;&#37322;&#24037;&#20855;&#26102;&#30340;&#35774;&#35745;&#36873;&#25321;&#20063;&#20250;&#24433;&#21709;&#22522;&#20110;&#24471;&#21040;&#30340;&#27880;&#37322;&#35757;&#32451;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;"&#27880;&#37322;&#25935;&#24863;&#24615;"&#36825;&#20010;&#26415;&#35821;&#65292;&#29992;&#26469;&#25351;&#20195;&#27880;&#37322;&#25968;&#25454;&#25910;&#38598;&#26041;&#27861;&#23545;&#27880;&#37322;&#26412;&#36523;&#20197;&#21450;&#19979;&#28216;&#27169;&#22411;&#24615;&#33021;&#21644;&#39044;&#27979;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#22312;&#20116;&#31181;&#23454;&#39564;&#26465;&#20214;&#19979;&#23545;&#20167;&#24680;&#35328;&#35770;&#21644;&#20882;&#29359;&#24615;&#35821;&#35328;&#36827;&#34892;&#27880;&#37322;&#25910;&#38598;&#65292;&#38543;&#26426;&#23558;&#27880;&#37322;&#32773;&#20998;&#37197;&#21040;&#19981;&#21516;&#26465;&#20214;&#19979;&#12290;&#28982;&#21518;&#65292;&#22312;&#27599;&#20010;&#24471;&#21040;&#30340;&#20116;&#20010;&#25968;&#25454;&#38598;&#19978;&#23545;BERT&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#65292;&#24182;&#22312;&#27599;&#20010;&#26465;&#20214;&#30340;&#20445;&#30041;&#37096;&#20998;&#19978;&#35780;&#20272;&#27169;&#22411;&#24615;&#33021;&#12290;&#25105;&#20204;&#21457;&#29616;&#22312;&#20197;&#19979;&#26041;&#38754;&#26465;&#20214;&#20043;&#38388;&#23384;&#22312;&#26126;&#26174;&#24046;&#24322;&#65306;1&#65289;&#20167;&#24680;&#35328;&#35770;/&#20882;&#29359;&#24615;&#35821;&#35328;&#27880;&#37322;&#30340;&#27604;&#20363;&#65292;2&#65289;&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
When training data are collected from human annotators, the design of the annotation instrument, the instructions given to annotators, the characteristics of the annotators, and their interactions can impact training data. This study demonstrates that design choices made when creating an annotation instrument also impact the models trained on the resulting annotations. We introduce the term annotation sensitivity to refer to the impact of annotation data collection methods on the annotations themselves and on downstream model performance and predictions. We collect annotations of hate speech and offensive language in five experimental conditions of an annotation instrument, randomly assigning annotators to conditions. We then fine-tune BERT models on each of the five resulting datasets and evaluate model performance on a holdout portion of each condition. We find considerable differences between the conditions for 1) the share of hate speech/offensive language annotations, 2) model per
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20026;&#20998;&#24067;&#40065;&#26834;&#24378;&#21270;&#23398;&#20064;&#30340;&#29702;&#35770;&#22522;&#30784;&#20570;&#20986;&#20102;&#36129;&#29486;&#65292;&#36890;&#36807;&#19968;&#20010;&#32508;&#21512;&#30340;&#24314;&#27169;&#26694;&#26550;&#65292;&#20915;&#31574;&#32773;&#22312;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#20998;&#24067;&#36716;&#21464;&#19979;&#36873;&#25321;&#26368;&#20248;&#31574;&#30053;&#65292;&#24182;&#32771;&#34385;&#20102;&#21508;&#31181;&#24314;&#27169;&#23646;&#24615;&#21644;&#23545;&#25163;&#24341;&#36215;&#30340;&#36716;&#21464;&#30340;&#28789;&#27963;&#24615;&#12290;</title><link>http://arxiv.org/abs/2311.09018</link><description>&lt;p&gt;
&#20851;&#20110;&#20998;&#24067;&#40065;&#26834;&#24378;&#21270;&#23398;&#20064;&#30340;&#22522;&#30784;
&lt;/p&gt;
&lt;p&gt;
On the Foundation of Distributionally Robust Reinforcement Learning. (arXiv:2311.09018v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.09018
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20026;&#20998;&#24067;&#40065;&#26834;&#24378;&#21270;&#23398;&#20064;&#30340;&#29702;&#35770;&#22522;&#30784;&#20570;&#20986;&#20102;&#36129;&#29486;&#65292;&#36890;&#36807;&#19968;&#20010;&#32508;&#21512;&#30340;&#24314;&#27169;&#26694;&#26550;&#65292;&#20915;&#31574;&#32773;&#22312;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#20998;&#24067;&#36716;&#21464;&#19979;&#36873;&#25321;&#26368;&#20248;&#31574;&#30053;&#65292;&#24182;&#32771;&#34385;&#20102;&#21508;&#31181;&#24314;&#27169;&#23646;&#24615;&#21644;&#23545;&#25163;&#24341;&#36215;&#30340;&#36716;&#21464;&#30340;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20986;&#20110;&#23545;&#22312;&#35757;&#32451;&#21644;&#37096;&#32626;&#20043;&#38388;&#29615;&#22659;&#21464;&#21270;&#26102;&#40065;&#26834;&#31574;&#30053;&#30340;&#38656;&#27714;&#65292;&#25105;&#20204;&#20026;&#20998;&#24067;&#40065;&#26834;&#24378;&#21270;&#23398;&#20064;&#30340;&#29702;&#35770;&#22522;&#30784;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;&#36890;&#36807;&#19968;&#20010;&#20197;&#20998;&#24067;&#40065;&#26834;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;DRMDPs&#65289;&#20026;&#20013;&#24515;&#30340;&#32508;&#21512;&#24314;&#27169;&#26694;&#26550;&#65292;&#25105;&#20204;&#20351;&#20915;&#31574;&#32773;&#22312;&#19968;&#20010;&#30001;&#23545;&#25163;&#25805;&#32437;&#30340;&#26368;&#22351;&#24773;&#20917;&#20998;&#24067;&#36716;&#21464;&#19979;&#36873;&#25321;&#26368;&#20248;&#31574;&#30053;&#12290;&#36890;&#36807;&#32479;&#19968;&#21644;&#25193;&#23637;&#29616;&#26377;&#30340;&#34920;&#36848;&#65292;&#25105;&#20204;&#20005;&#26684;&#26500;&#24314;&#20102;&#36866;&#29992;&#20110;&#20915;&#31574;&#32773;&#21644;&#23545;&#25163;&#30340;&#21508;&#31181;&#24314;&#27169;&#23646;&#24615;&#30340;DRMDPs&#65292;&#21253;&#25324;&#36866;&#24212;&#24615;&#31890;&#24230;&#12289;&#25506;&#32034;&#21382;&#21490;&#20381;&#36182;&#24615;&#12289;&#39532;&#23572;&#31185;&#22827;&#21644;&#39532;&#23572;&#31185;&#22827;&#26102;&#38388;&#40784;&#27425;&#30340;&#20915;&#31574;&#32773;&#21644;&#23545;&#25163;&#21160;&#24577;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#28145;&#20837;&#30740;&#31350;&#20102;&#23545;&#25163;&#24341;&#36215;&#30340;&#36716;&#21464;&#30340;&#28789;&#27963;&#24615;&#65292;&#30740;&#31350;&#20102;SA&#21644;S-&#30697;&#24418;&#24615;&#12290;&#22312;&#36825;&#20010;DRMDP&#26694;&#26550;&#19979;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#23454;&#29616;&#40065;&#26834;&#24615;&#25152;&#38656;&#30340;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by the need for a robust policy in the face of environment shifts between training and the deployment, we contribute to the theoretical foundation of distributionally robust reinforcement learning (DRRL). This is accomplished through a comprehensive modeling framework centered around distributionally robust Markov decision processes (DRMDPs). This framework obliges the decision maker to choose an optimal policy under the worst-case distributional shift orchestrated by an adversary. By unifying and extending existing formulations, we rigorously construct DRMDPs that embraces various modeling attributes for both the decision maker and the adversary. These attributes include adaptability granularity, exploring history-dependent, Markov, and Markov time-homogeneous decision maker and adversary dynamics. Additionally, we delve into the flexibility of shifts induced by the adversary, examining SA and S-rectangularity. Within this DRMDP framework, we investigate conditions for the e
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31867;&#20284;ResNet&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#26469;&#36817;&#20284;Langevin Monte Carlo&#31639;&#27861;&#65292;&#36890;&#36807;&#23558;&#26469;&#33258;&#31616;&#21333;&#21442;&#32771;&#20998;&#24067;&#30340;&#26679;&#26412;&#26144;&#23556;&#21040;&#30446;&#26631;&#20998;&#24067;&#30340;&#26679;&#26412;&#20013;&#26469;&#36827;&#34892;&#37319;&#26679;&#65292;&#20855;&#26377;&#36739;&#22909;&#30340;&#36924;&#36817;&#36895;&#24230;&#21644;&#34920;&#36798;&#24615;&#12290;</title><link>http://arxiv.org/abs/2311.03242</link><description>&lt;p&gt;
&#20351;&#29992;&#31867;&#20284;ResNet&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#36817;&#20284;Langevin Monte Carlo
&lt;/p&gt;
&lt;p&gt;
Approximating Langevin Monte Carlo with ResNet-like Neural Network architectures. (arXiv:2311.03242v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.03242
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31867;&#20284;ResNet&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#26469;&#36817;&#20284;Langevin Monte Carlo&#31639;&#27861;&#65292;&#36890;&#36807;&#23558;&#26469;&#33258;&#31616;&#21333;&#21442;&#32771;&#20998;&#24067;&#30340;&#26679;&#26412;&#26144;&#23556;&#21040;&#30446;&#26631;&#20998;&#24067;&#30340;&#26679;&#26412;&#20013;&#26469;&#36827;&#34892;&#37319;&#26679;&#65292;&#20855;&#26377;&#36739;&#22909;&#30340;&#36924;&#36817;&#36895;&#24230;&#21644;&#34920;&#36798;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#36890;&#36807;&#26500;&#24314;&#19968;&#20010;&#31070;&#32463;&#32593;&#32476;&#65292;&#23558;&#26469;&#33258;&#31616;&#21333;&#21442;&#32771;&#20998;&#24067;&#65288;&#22914;&#26631;&#20934;&#27491;&#24577;&#20998;&#24067;&#65289;&#30340;&#26679;&#26412;&#26144;&#23556;&#21040;&#30446;&#26631;&#20998;&#24067;&#30340;&#26679;&#26412;&#20013;&#65292;&#20174;&#32780;&#20174;&#32473;&#23450;&#30340;&#30446;&#26631;&#20998;&#24067;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#21463;Langevin Monte Carlo (LMC)&#31639;&#27861;&#21551;&#21457;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#12290;&#22522;&#20110;LMC&#25200;&#21160;&#32467;&#26524;&#65292;&#22312;Wasserstein-2&#36317;&#31163;&#19978;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#26550;&#26500;&#23545;&#20110;&#24179;&#28369;&#30340;&#23545;&#25968;&#20985;&#30446;&#26631;&#20998;&#24067;&#30340;&#36924;&#36817;&#36895;&#24230;&#12290;&#20998;&#26512;&#20005;&#37325;&#20381;&#36182;&#20110;&#25200;&#21160;LMC&#36807;&#31243;&#30340;&#20013;&#38388;&#24230;&#37327;&#30340;&#20122;&#39640;&#26031;&#24615;&#27010;&#24565;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#26681;&#25454;&#19981;&#21516;&#25200;&#21160;&#20551;&#35774;&#25512;&#23548;&#20986;&#20102;&#20013;&#38388;&#26041;&#24046;&#20195;&#29702;&#30340;&#22686;&#38271;&#30028;&#38480;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31867;&#20284;&#20110;&#28145;&#24230;&#27531;&#24046;&#31070;&#32463;&#32593;&#32476;&#30340;&#26550;&#26500;&#65292;&#24182;&#25512;&#23548;&#20986;&#20102;&#36817;&#20284;&#26679;&#26412;&#19982;&#30446;&#26631;&#20998;&#24067;&#26144;&#23556;&#30340;&#34920;&#36798;&#24615;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We sample from a given target distribution by constructing a neural network which maps samples from a simple reference, e.g. the standard normal distribution, to samples from the target. To that end, we propose using a neural network architecture inspired by the Langevin Monte Carlo (LMC) algorithm. Based on LMC perturbation results, we show approximation rates of the proposed architecture for smooth, log-concave target distributions measured in the Wasserstein-$2$ distance. The analysis heavily relies on the notion of sub-Gaussianity of the intermediate measures of the perturbed LMC process. In particular, we derive bounds on the growth of the intermediate variance proxies under different assumptions on the perturbations. Moreover, we propose an architecture similar to deep residual neural networks and derive expressivity results for approximating the sample to target distribution map.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#20174;&#20855;&#26377;&#32473;&#23450;&#21021;&#22987;&#29366;&#24577;&#30340;&#35299;&#36807;&#31243;&#30340;&#20998;&#24067;&#20013;&#35782;&#21035;&#32447;&#24615;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;SDE&#65289;&#30340;&#21457;&#29983;&#22120;&#30340;&#26465;&#20214;&#65292;&#24182;&#19988;&#25552;&#20379;&#20102;&#23545;&#20110;&#20855;&#26377;&#21152;&#24615;&#21644;&#20056;&#24615;&#22122;&#22768;&#30340;SDE&#30340;&#35782;&#21035;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2310.19491</link><description>&lt;p&gt;
&#20855;&#26377;&#21152;&#24615;&#21644;&#20056;&#24615;&#22122;&#22768;&#30340;&#32447;&#24615;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#21457;&#29983;&#22120;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Generator Identification for Linear SDEs with Additive and Multiplicative Noise. (arXiv:2310.19491v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19491
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#20174;&#20855;&#26377;&#32473;&#23450;&#21021;&#22987;&#29366;&#24577;&#30340;&#35299;&#36807;&#31243;&#30340;&#20998;&#24067;&#20013;&#35782;&#21035;&#32447;&#24615;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;SDE&#65289;&#30340;&#21457;&#29983;&#22120;&#30340;&#26465;&#20214;&#65292;&#24182;&#19988;&#25552;&#20379;&#20102;&#23545;&#20110;&#20855;&#26377;&#21152;&#24615;&#21644;&#20056;&#24615;&#22122;&#22768;&#30340;SDE&#30340;&#35782;&#21035;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#20855;&#26377;&#32473;&#23450;&#22266;&#23450;&#21021;&#22987;&#29366;&#24577;&#30340;&#35299;&#36807;&#31243;&#30340;&#20998;&#24067;&#20013;&#35782;&#21035;&#32447;&#24615;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;SDE&#65289;&#30340;&#21457;&#29983;&#22120;&#30340;&#26465;&#20214;&#12290;&#36825;&#20123;&#21487;&#35782;&#21035;&#24615;&#26465;&#20214;&#22312;&#20351;&#29992;&#32447;&#24615;SDE&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#26102;&#33267;&#20851;&#37325;&#35201;&#65292;&#22240;&#20026;&#23427;&#20204;&#20351;&#24471;&#21487;&#20197;&#20174;&#20854;&#35266;&#27979;&#20998;&#24067;&#20013;&#35782;&#21035;&#20986;&#24178;&#39044;&#21518;&#30340;&#20998;&#24067;&#12290;&#25105;&#20204;&#20855;&#20307;&#25512;&#23548;&#20986;&#20102;&#35782;&#21035;&#20855;&#26377;&#21152;&#24615;&#22122;&#22768;&#30340;&#32447;&#24615;SDE&#30340;&#21457;&#29983;&#22120;&#30340;&#20805;&#20998;&#24517;&#35201;&#26465;&#20214;&#65292;&#20197;&#21450;&#35782;&#21035;&#20855;&#26377;&#20056;&#24615;&#22122;&#22768;&#30340;&#32447;&#24615;SDE&#30340;&#21457;&#29983;&#22120;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#20004;&#31181;&#31867;&#22411;&#30340;SDE&#65292;&#24471;&#21040;&#30340;&#26465;&#20214;&#26159;&#19968;&#33324;&#24615;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#24471;&#21040;&#30340;&#21487;&#35782;&#21035;&#24615;&#26465;&#20214;&#30340;&#20960;&#20309;&#35299;&#37322;&#65292;&#20197;&#22686;&#24378;&#23545;&#20854;&#30340;&#29702;&#35299;&#12290;&#20026;&#20102;&#39564;&#35777;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#31995;&#21015;&#30340;&#27169;&#25311;&#23454;&#39564;&#65292;&#36825;&#20123;&#23454;&#39564;&#25903;&#25345;&#24182;&#35777;&#23454;&#20102;&#25105;&#20204;&#25152;&#24471;&#21040;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we present conditions for identifying the generator of a linear stochastic differential equation (SDE) from the distribution of its solution process with a given fixed initial state. These identifiability conditions are crucial in causal inference using linear SDEs as they enable the identification of the post-intervention distributions from its observational distribution. Specifically, we derive a sufficient and necessary condition for identifying the generator of linear SDEs with additive noise, as well as a sufficient condition for identifying the generator of linear SDEs with multiplicative noise. We show that the conditions derived for both types of SDEs are generic. Moreover, we offer geometric interpretations of the derived identifiability conditions to enhance their understanding. To validate our theoretical results, we perform a series of simulations, which support and substantiate the established findings.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35299;&#20915;&#20102;&#23398;&#20064;&#20855;&#26377;&#19968;&#33324;&#24211;&#23384;&#21040;&#36135;&#21160;&#24577;&#19979;&#30340;&#24211;&#23384;&#25511;&#21046;&#31574;&#30053;&#30340;&#38382;&#39064;&#65292;&#21516;&#26102;&#20801;&#35768;&#20462;&#25913;&#35746;&#36141;&#25968;&#37327;&#20197;&#28385;&#36275;&#20379;&#24212;&#21830;&#30340;&#38480;&#21046;&#65292;&#24182;&#23558;&#21608;&#26399;&#24615;&#23457;&#26680;&#24211;&#23384;&#25511;&#21046;&#38382;&#39064;&#23450;&#20041;&#20026;&#22806;&#37096;&#20915;&#31574;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2310.17168</link><description>&lt;p&gt;
&#23398;&#20064;&#22788;&#29702;&#20855;&#26377;&#19968;&#33324;&#24211;&#23384;&#21040;&#36135;&#21160;&#24577;&#30340;&#24211;&#23384;&#25511;&#21046;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Learning an Inventory Control Policy with General Inventory Arrival Dynamics. (arXiv:2310.17168v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17168
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#23398;&#20064;&#20855;&#26377;&#19968;&#33324;&#24211;&#23384;&#21040;&#36135;&#21160;&#24577;&#19979;&#30340;&#24211;&#23384;&#25511;&#21046;&#31574;&#30053;&#30340;&#38382;&#39064;&#65292;&#21516;&#26102;&#20801;&#35768;&#20462;&#25913;&#35746;&#36141;&#25968;&#37327;&#20197;&#28385;&#36275;&#20379;&#24212;&#21830;&#30340;&#38480;&#21046;&#65292;&#24182;&#23558;&#21608;&#26399;&#24615;&#23457;&#26680;&#24211;&#23384;&#25511;&#21046;&#38382;&#39064;&#23450;&#20041;&#20026;&#22806;&#37096;&#20915;&#31574;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#38754;&#23545;&#19968;&#33324;&#21040;&#36135;&#21160;&#24577;&#30340;&#24773;&#20917;&#19979;&#35299;&#20915;&#20102;&#23398;&#20064;&#21644;&#22238;&#27979;&#24211;&#23384;&#25511;&#21046;&#31574;&#30053;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#23558;&#20854;&#31216;&#20026;&#25968;&#37327;&#38543;&#26102;&#38388;&#21040;&#36135;&#27169;&#22411;&#65288;QOT&#65289;&#12290;&#22312;&#23454;&#38469;&#20379;&#24212;&#38142;&#20013;&#65292;&#25105;&#20204;&#36824;&#20801;&#35768;&#20462;&#25913;&#35746;&#36141;&#25968;&#37327;&#20197;&#28385;&#36275;&#20379;&#24212;&#21830;&#30340;&#38480;&#21046;&#65292;&#20363;&#22914;&#35746;&#36141;&#26368;&#20302;&#25968;&#37327;&#21644;&#25209;&#27425;&#22823;&#23567;&#32422;&#26463;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#31532;&#19968;&#31687;&#22788;&#29702;&#20219;&#24847;&#21040;&#36135;&#21160;&#24577;&#25110;&#20219;&#24847;&#21518;&#32493;&#22788;&#29702;&#30340;&#35746;&#36141;&#25968;&#37327;&#30340;&#30740;&#31350;&#12290;&#22312;&#26368;&#36817;&#30340;&#24037;&#20316;&#65288;Madeka&#31561;&#65292;2022&#65289;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#21516;&#26679;&#23558;&#21608;&#26399;&#24615;&#23457;&#26680;&#24211;&#23384;&#25511;&#21046;&#38382;&#39064;&#23450;&#20041;&#20026;&#22806;&#37096;&#20915;&#31574;&#36807;&#31243;&#65292;&#20854;&#20013;&#22823;&#37096;&#20998;&#29366;&#24577;&#19981;&#21463;&#20195;&#29702;&#30340;&#25511;&#21046;&#12290;Madeka&#31561;&#20154;&#65288;2022&#65289;&#23637;&#31034;&#20102;&#22914;&#20309;&#26500;&#24314;&#19968;&#20010;&#27169;&#25311;&#22120;&#26469;&#22238;&#25918;&#21382;&#21490;&#25968;&#25454;&#20197;&#35299;&#20915;&#36825;&#31867;&#38382;&#39064;&#12290;&#22312;&#25105;&#20204;&#30340;&#20363;&#23376;&#20013;&#65292;&#25105;&#20204;&#23558;&#19968;&#20010;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#32435;&#20837;&#21040;&#36135;&#36807;&#31243;&#30340;&#21382;&#21490;&#22238;&#25918;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we address the problem of learning and backtesting inventory control policies in the presence of general arrival dynamics -- which we term as a quantity-over-time arrivals model (QOT). We also allow for order quantities to be modified as a post-processing step to meet vendor constraints such as order minimum and batch size constraints -- a common practice in real supply chains. To the best of our knowledge this is the first work to handle either arbitrary arrival dynamics or an arbitrary downstream post-processing of order quantities. Building upon recent work (Madeka et al., 2022) we similarly formulate the periodic review inventory control problem as an exogenous decision process, where most of the state is outside the control of the agent. Madeka et al. (2022) show how to construct a simulator that replays historic data to solve this class of problem. In our case, we incorporate a deep generative model for the arrivals process as part of the history replay. By formulat
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#23398;&#20064;&#24050;&#30693;&#39592;&#26550;&#30340;&#26377;&#30028;&#24230;&#22810;&#26641;&#30340;&#31639;&#27861;&#65292;&#24182;&#32473;&#20986;&#20102;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#20869;&#30340;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#12290;&#36825;&#23545;&#20110;&#22797;&#26434;&#27010;&#29575;&#20998;&#24067;&#30340;&#23398;&#20064;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2310.06333</link><description>&lt;p&gt;
&#23398;&#20064;&#20855;&#26377;&#24050;&#30693;&#39592;&#26550;&#30340;&#26377;&#30028;&#24230;&#22810;&#26641;
&lt;/p&gt;
&lt;p&gt;
Learning bounded-degree polytrees with known skeleton. (arXiv:2310.06333v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06333
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#23398;&#20064;&#24050;&#30693;&#39592;&#26550;&#30340;&#26377;&#30028;&#24230;&#22810;&#26641;&#30340;&#31639;&#27861;&#65292;&#24182;&#32473;&#20986;&#20102;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#20869;&#30340;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#12290;&#36825;&#23545;&#20110;&#22797;&#26434;&#27010;&#29575;&#20998;&#24067;&#30340;&#23398;&#20064;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20026;&#39640;&#32500;&#27010;&#29575;&#20998;&#24067;&#30340;&#19968;&#31867;&#20016;&#23500;&#30340;&#22810;&#26641;&#65288;polytrees&#65289;&#8212;&#8212;&#26377;&#30028;&#24230;&#22810;&#26641;&#65292;&#24314;&#31435;&#20102;&#39640;&#25928;&#36866;&#24403;&#23398;&#20064;&#30340;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#12290;&#26377;&#30028;&#24230;&#22810;&#26641;&#26159;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#23376;&#31867;&#65292;&#36125;&#21494;&#26031;&#32593;&#32476;&#26159;&#19968;&#31181;&#24191;&#27867;&#30740;&#31350;&#30340;&#22270;&#27169;&#22411;&#31867;&#22411;&#12290;&#26368;&#36817;&#65292;Bhattacharyya&#31561;&#20154;&#65288;2021&#65289;&#36890;&#36807;&#25552;&#20379;&#19968;&#31181;&#39640;&#25928;&#31639;&#27861;&#65292;&#22312;&#24050;&#30693;&#26080;&#21521;&#22270;&#65288;&#39592;&#26550;&#65289;&#30340;&#24773;&#20917;&#19979;&#65292;&#20026;1-&#22810;&#26641;&#24674;&#22797;&#20102;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#12290;&#25105;&#20204;&#36890;&#36807;&#25193;&#23637;&#20182;&#20204;&#30340;&#32467;&#26524;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#39640;&#25928;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#20869;&#23398;&#20064;&#20219;&#20309;&#26377;&#30028;&#24230;&#30340;$d$-&#22810;&#26641;&#12290;&#25105;&#20204;&#23558;&#31639;&#27861;&#19982;&#20449;&#24687;&#35770;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#19979;&#30028;&#32467;&#21512;&#36215;&#26469;&#65292;&#34920;&#26126;&#23545;&#32500;&#24230;&#21644;&#30446;&#26631;&#31934;&#24230;&#21442;&#25968;&#30340;&#20381;&#36182;&#20960;&#20046;&#26159;&#32039;&#33268;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We establish finite-sample guarantees for efficient proper learning of bounded-degree polytrees, a rich class of high-dimensional probability distributions and a subclass of Bayesian networks, a widely-studied type of graphical model. Recently, Bhattacharyya et al. (2021) obtained finite-sample guarantees for recovering tree-structured Bayesian networks, i.e., 1-polytrees. We extend their results by providing an efficient algorithm which learns $d$-polytrees in polynomial time and sample complexity for any bounded $d$ when the underlying undirected graph (skeleton) is known. We complement our algorithm with an information-theoretic sample complexity lower bound, showing that the dependence on the dimension and target accuracy parameters are nearly tight.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#21464;&#37327;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#38750;&#23618;&#27425;&#21270;&#22810;&#20445;&#30495;&#24230;&#33258;&#36866;&#24212;&#37319;&#26679;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#21033;&#29992;&#19981;&#21516;&#20445;&#30495;&#24230;&#27169;&#22411;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#20197;&#26356;&#39640;&#25928;&#22320;&#25506;&#32034;&#21644;&#21033;&#29992;&#35774;&#35745;&#31354;&#38388;&#12290;</title><link>http://arxiv.org/abs/2310.03298</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#38750;&#23618;&#27425;&#21270;&#22810;&#20445;&#30495;&#24230;&#33258;&#36866;&#24212;&#37319;&#26679;&#30340;&#28508;&#21464;&#37327;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Latent Variable Approach for Non-Hierarchical Multi-Fidelity Adaptive Sampling. (arXiv:2310.03298v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03298
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#21464;&#37327;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#38750;&#23618;&#27425;&#21270;&#22810;&#20445;&#30495;&#24230;&#33258;&#36866;&#24212;&#37319;&#26679;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#21033;&#29992;&#19981;&#21516;&#20445;&#30495;&#24230;&#27169;&#22411;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#20197;&#26356;&#39640;&#25928;&#22320;&#25506;&#32034;&#21644;&#21033;&#29992;&#35774;&#35745;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20445;&#30495;&#24230;&#65288;MF&#65289;&#26041;&#27861;&#22312;&#25552;&#39640;&#26367;&#20195;&#27169;&#22411;&#21644;&#35774;&#35745;&#20248;&#21270;&#26041;&#38754;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#65292;&#36890;&#36807;&#25972;&#21512;&#26469;&#33258;&#19981;&#21516;&#20302;&#20445;&#30495;&#24230;&#65288;LF&#65289;&#27169;&#22411;&#30340;&#25968;&#25454;&#12290;&#23613;&#31649;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;MF&#26041;&#27861;&#20551;&#23450;&#20102;&#19968;&#20010;&#22266;&#23450;&#30340;&#25968;&#25454;&#38598;&#65292;&#20294;&#26159;&#21160;&#24577;&#20998;&#37197;&#36164;&#28304;&#22312;&#19981;&#21516;&#20445;&#30495;&#24230;&#27169;&#22411;&#20043;&#38388;&#21487;&#20197;&#23454;&#29616;&#26356;&#39640;&#30340;&#25506;&#32034;&#21644;&#21033;&#29992;&#35774;&#35745;&#31354;&#38388;&#30340;&#25928;&#29575;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;MF&#26041;&#27861;&#20381;&#36182;&#20110;&#20445;&#30495;&#24230;&#32423;&#21035;&#30340;&#23618;&#27425;&#20551;&#35774;&#65292;&#25110;&#32773;&#26080;&#27861;&#25429;&#25417;&#22810;&#20010;&#20445;&#30495;&#24230;&#32423;&#21035;&#20043;&#38388;&#30340;&#30456;&#20114;&#20851;&#31995;&#24182;&#21033;&#29992;&#20854;&#26469;&#37327;&#21270;&#26410;&#26469;&#26679;&#26412;&#30340;&#20215;&#20540;&#21644;&#23548;&#33322;&#33258;&#36866;&#24212;&#37319;&#26679;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38556;&#30861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#19981;&#21516;&#20445;&#30495;&#24230;&#27169;&#22411;&#30340;&#28508;&#21464;&#37327;&#23884;&#20837;&#21644;&#30456;&#20851;&#30340;&#20808;&#39564;-&#21518;&#39564;&#20998;&#26512;&#30340;&#26694;&#26550;&#65292;&#20197;&#26174;&#24335;&#22320;&#21033;&#29992;&#23427;&#20204;&#30340;&#30456;&#20851;&#24615;&#36827;&#34892;&#33258;&#36866;&#24212;&#37319;&#26679;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#20013;&#65292;&#27599;&#20010;&#22635;&#20805;&#37319;&#26679;&#36845;&#20195;&#21253;&#25324;&#20004;&#20010;&#27493;&#39588;&#65306;&#39318;&#20808;&#25105;&#20204;&#30830;&#23450;&#20855;&#26377;&#26368;&#22823;&#28508;&#21147;&#24433;&#21709;&#30340;&#20301;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-fidelity (MF) methods are gaining popularity for enhancing surrogate modeling and design optimization by incorporating data from various low-fidelity (LF) models. While most existing MF methods assume a fixed dataset, adaptive sampling methods that dynamically allocate resources among fidelity models can achieve higher efficiency in the exploring and exploiting the design space. However, most existing MF methods rely on the hierarchical assumption of fidelity levels or fail to capture the intercorrelation between multiple fidelity levels and utilize it to quantify the value of the future samples and navigate the adaptive sampling. To address this hurdle, we propose a framework hinged on a latent embedding for different fidelity models and the associated pre-posterior analysis to explicitly utilize their correlation for adaptive sampling. In this framework, each infill sampling iteration includes two steps: We first identify the location of interest with the greatest potential imp
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#35299;&#20915;&#20102;&#23545;&#20110;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#20013;&#19981;&#21516;&#27169;&#24335;&#30340;&#36861;&#36394;&#21644;&#29702;&#35299;&#30340;&#38382;&#39064;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#30456;&#20301;&#22270;&#26469;&#21306;&#20998;&#22122;&#22768;&#20027;&#23548;&#30340;SGD&#21644;&#22823;&#27493;&#39588;&#20027;&#23548;&#30340;SGD&#12290;</title><link>http://arxiv.org/abs/2309.10688</link><description>&lt;p&gt;
&#20851;&#20110;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#19981;&#21516;&#27169;&#24335;
&lt;/p&gt;
&lt;p&gt;
On the different regimes of Stochastic Gradient Descent. (arXiv:2309.10688v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.10688
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#35299;&#20915;&#20102;&#23545;&#20110;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#20013;&#19981;&#21516;&#27169;&#24335;&#30340;&#36861;&#36394;&#21644;&#29702;&#35299;&#30340;&#38382;&#39064;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#30456;&#20301;&#22270;&#26469;&#21306;&#20998;&#22122;&#22768;&#20027;&#23548;&#30340;SGD&#21644;&#22823;&#27493;&#39588;&#20027;&#23548;&#30340;SGD&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#28145;&#24230;&#32593;&#32476;&#36890;&#36807;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#36827;&#34892;&#35757;&#32451;&#65292;&#20854;&#20851;&#38190;&#21442;&#25968;&#26159;&#27599;&#20010;&#27493;&#39588;&#32771;&#34385;&#30340;&#25968;&#25454;&#37327;&#25110;&#25209;&#37327;&#22823;&#23567;B&#20197;&#21450;&#27493;&#38271;&#25110;&#23398;&#20064;&#29575;&#951;&#12290;&#23545;&#20110;&#23567;&#30340;B&#21644;&#22823;&#30340;&#951;&#65292;SGD&#23545;&#24212;&#20110;&#21442;&#25968;&#30340;&#38543;&#26426;&#28436;&#21270;&#65292;&#20854;&#22122;&#22768;&#24133;&#24230;&#30001;&#8220;&#28201;&#24230;&#8221;T=&#951;/B&#25511;&#21046;&#12290;&#28982;&#32780;&#24403;&#25209;&#37327;&#22823;&#23567;B&#8805;B^*&#36275;&#22815;&#22823;&#26102;&#65292;&#36825;&#31181;&#25551;&#36848;&#34987;&#35266;&#23519;&#21040;&#22833;&#25928;&#65292;&#25110;&#32773;&#22312;&#28201;&#24230;&#36275;&#22815;&#23567;&#26102;&#31616;&#21270;&#20026;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#12290;&#29702;&#35299;&#36825;&#20123;&#20132;&#21449;&#21457;&#29983;&#30340;&#20301;&#32622;&#20173;&#28982;&#26159;&#19968;&#20010;&#20013;&#24515;&#25361;&#25112;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#36825;&#20123;&#38382;&#39064;&#65292;&#22312;&#19968;&#20010;&#25945;&#24072;-&#23398;&#29983;&#24863;&#30693;&#22120;&#20998;&#31867;&#27169;&#22411;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#20851;&#38190;&#39044;&#27979;&#20173;&#36866;&#29992;&#20110;&#28145;&#24230;&#32593;&#32476;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#22312;B-&#951;&#24179;&#38754;&#19978;&#33719;&#24471;&#20102;&#19968;&#20010;&#30456;&#20301;&#22270;&#65292;&#23558;&#19977;&#20010;&#21160;&#24577;&#38454;&#27573;&#20998;&#24320;&#65306;&#65288;i&#65289;&#21463;&#28201;&#24230;&#25511;&#21046;&#30340;&#22122;&#22768;&#20027;&#23548;&#30340;SGD&#65292;&#65288;ii&#65289;&#22823;&#27493;&#39588;&#20027;&#23548;&#30340;SGD&#21644;
&lt;/p&gt;
&lt;p&gt;
Modern deep networks are trained with stochastic gradient descent (SGD) whose key parameters are the number of data considered at each step or batch size $B$, and the step size or learning rate $\eta$. For small $B$ and large $\eta$, SGD corresponds to a stochastic evolution of the parameters, whose noise amplitude is governed by the `temperature' $T\equiv \eta/B$. Yet this description is observed to break down for sufficiently large batches $B\geq B^*$, or simplifies to gradient descent (GD) when the temperature is sufficiently small. Understanding where these cross-overs take place remains a central challenge. Here we resolve these questions for a teacher-student perceptron classification model, and show empirically that our key predictions still apply to deep networks. Specifically, we obtain a phase diagram in the $B$-$\eta$ plane that separates three dynamical phases: $\textit{(i)}$ a noise-dominated SGD governed by temperature, $\textit{(ii)}$ a large-first-step-dominated SGD and
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#21435;&#27542;&#27665;&#21270;&#20154;&#24037;&#26234;&#33021;&#23545;&#40784;&#30340;&#19977;&#20010;&#24314;&#35758;&#65306;&#25913;&#21464;&#22522;&#26412;&#36947;&#24503;&#21746;&#23398;&#20026;&#36798;&#23572;&#29595;&#21746;&#23398;&#65292;&#20801;&#35768;&#22810;&#20803;&#20027;&#20041;&#30340;&#35770;&#35777;&#20256;&#32479;&#23384;&#22312;&#20110;&#23545;&#40784;&#25216;&#26415;&#20013;&#65292;&#20197;&#21450;&#23558;&#20215;&#20540;&#35748;&#35782;&#35770;&#25193;&#23637;&#21040;&#36229;&#36234;&#33258;&#28982;&#35821;&#35328;&#20013;&#30340;&#25351;&#20196;&#12290;</title><link>http://arxiv.org/abs/2309.05030</link><description>&lt;p&gt;
&#21435;&#27542;&#27665;&#21270;&#30340;&#20154;&#24037;&#26234;&#33021;&#23545;&#40784;&#65306;&#23041;&#33394;&#36798;&#23572;&#29595;&#12289;&#35770;&#35777;&#21644;&#33402;&#26415;&#34920;&#36798;
&lt;/p&gt;
&lt;p&gt;
Decolonial AI Alignment: Vi\'{s}esadharma, Argument, and Artistic Expression. (arXiv:2309.05030v1 [cs.CY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05030
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#21435;&#27542;&#27665;&#21270;&#20154;&#24037;&#26234;&#33021;&#23545;&#40784;&#30340;&#19977;&#20010;&#24314;&#35758;&#65306;&#25913;&#21464;&#22522;&#26412;&#36947;&#24503;&#21746;&#23398;&#20026;&#36798;&#23572;&#29595;&#21746;&#23398;&#65292;&#20801;&#35768;&#22810;&#20803;&#20027;&#20041;&#30340;&#35770;&#35777;&#20256;&#32479;&#23384;&#22312;&#20110;&#23545;&#40784;&#25216;&#26415;&#20013;&#65292;&#20197;&#21450;&#23558;&#20215;&#20540;&#35748;&#35782;&#35770;&#25193;&#23637;&#21040;&#36229;&#36234;&#33258;&#28982;&#35821;&#35328;&#20013;&#30340;&#25351;&#20196;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#38416;&#26126;&#20102;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#24320;&#21457;&#21644;&#37096;&#32626;&#30340;&#27542;&#27665;&#24615;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#30740;&#31350;&#24456;&#23569;&#28041;&#21450;&#21040;&#23545;&#40784;&#65306;&#21363;&#22522;&#20110;&#32454;&#33268;&#30340;&#20154;&#31867;&#21453;&#39304;&#65292;&#35843;&#25972;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#34892;&#20026;&#19982;&#26399;&#26395;&#20540;&#19968;&#33268;&#12290;&#38500;&#20102;&#20854;&#20182;&#23454;&#36341;&#65292;&#27542;&#27665;&#20027;&#20041;&#36824;&#26377;&#19968;&#37096;&#20998;&#26159;&#25913;&#21464;&#34987;&#27542;&#27665;&#27665;&#26063;&#30340;&#20449;&#20208;&#21644;&#20215;&#20540;&#35266;&#30340;&#21382;&#21490;&#65307;&#32780;&#24403;&#21069;&#30340;LLM&#23545;&#40784;&#23454;&#36341;&#27491;&#26159;&#36825;&#19968;&#21382;&#21490;&#30340;&#22797;&#21046;&#12290;&#25105;&#20204;&#24314;&#35758;&#36890;&#36807;&#19977;&#20010;&#25552;&#35758;&#23545;AI&#23545;&#40784;&#36827;&#34892;&#21435;&#27542;&#27665;&#21270;&#65306;&#65288;a&#65289;&#23558;&#22522;&#26412;&#36947;&#24503;&#21746;&#23398;&#20174;&#35199;&#26041;&#21746;&#23398;&#36716;&#21464;&#20026;&#36798;&#23572;&#29595;&#21746;&#23398;&#65292;&#65288;b&#65289;&#22312;&#23545;&#40784;&#25216;&#26415;&#20013;&#20801;&#35768;&#35770;&#35777;&#21644;&#22810;&#20803;&#20027;&#20041;&#30340;&#20256;&#32479;&#65292;&#20197;&#21450;&#65288;c&#65289;&#23558;&#20215;&#20540;&#30340;&#35748;&#35782;&#35770;&#25193;&#23637;&#21040;&#36229;&#36234;&#33258;&#28982;&#35821;&#35328;&#20013;&#30340;&#25351;&#20196;&#25110;&#21629;&#20196;&#12290;
&lt;/p&gt;
&lt;p&gt;
Prior work has explicated the coloniality of artificial intelligence (AI) development and deployment. One process that that work has not engaged with much is alignment: the tuning of large language model (LLM) behavior to be in line with desired values based on fine-grained human feedback. In addition to other practices, colonialism has a history of altering the beliefs and values of colonized peoples; this history is recapitulated in current LLM alignment practices. We suggest that AI alignment be decolonialized using three proposals: (a) changing the base moral philosophy from Western philosophy to dharma, (b) permitting traditions of argument and pluralism in alignment technologies, and (c) expanding the epistemology of values beyond instructions or commandments given in natural language.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;MC-CP&#30340;&#26032;&#22411;&#28151;&#21512;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#33258;&#36866;&#24212;&#33945;&#29305;&#21345;&#27931;dropout&#26041;&#27861;&#19982;&#21512;&#35268;&#39044;&#27979;&#30456;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#33410;&#30465;&#36164;&#28304;&#21644;&#20135;&#29983;&#40065;&#26834;&#39044;&#27979;&#38598;/&#21306;&#38388;&#30340;&#30446;&#26631;&#12290;&#23454;&#39564;&#35777;&#26126;MC-CP&#22312;&#20998;&#31867;&#20219;&#21153;&#20013;&#30456;&#27604;&#20854;&#20182;&#20808;&#36827;&#26041;&#27861;&#20855;&#26377;&#26174;&#33879;&#25552;&#21319;</title><link>http://arxiv.org/abs/2308.09647</link><description>&lt;p&gt;
&#20351;&#29992;&#21512;&#35268;&#30340;&#33945;&#29305;&#21345;&#27931;&#39044;&#27979;&#23454;&#29616;&#40065;&#26834;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Robust Uncertainty Quantification using Conformalised Monte Carlo Prediction. (arXiv:2308.09647v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09647
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;MC-CP&#30340;&#26032;&#22411;&#28151;&#21512;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#33258;&#36866;&#24212;&#33945;&#29305;&#21345;&#27931;dropout&#26041;&#27861;&#19982;&#21512;&#35268;&#39044;&#27979;&#30456;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#33410;&#30465;&#36164;&#28304;&#21644;&#20135;&#29983;&#40065;&#26834;&#39044;&#27979;&#38598;/&#21306;&#38388;&#30340;&#30446;&#26631;&#12290;&#23454;&#39564;&#35777;&#26126;MC-CP&#22312;&#20998;&#31867;&#20219;&#21153;&#20013;&#30456;&#27604;&#20854;&#20182;&#20808;&#36827;&#26041;&#27861;&#20855;&#26377;&#26174;&#33879;&#25552;&#21319;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23433;&#20840;&#20851;&#38190;&#24212;&#29992;&#20013;&#37096;&#32626;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#20173;&#28982;&#26159;&#19968;&#39033;&#38750;&#24120;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#38656;&#35201;&#23545;&#36825;&#20123;&#27169;&#22411;&#30340;&#21487;&#38752;&#36816;&#34892;&#25552;&#20379;&#20445;&#35777;&#12290;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65288;UQ&#65289;&#26041;&#27861;&#20272;&#35745;&#27599;&#20010;&#39044;&#27979;&#30340;&#27169;&#22411;&#32622;&#20449;&#24230;&#65292;&#36890;&#36807;&#32771;&#34385;&#38543;&#26426;&#24615;&#21644;&#27169;&#22411;&#38169;&#35823;&#35268;&#33539;&#21270;&#30340;&#24433;&#21709;&#26469;&#25351;&#23548;&#20915;&#31574;&#12290;&#23613;&#31649;&#26368;&#20808;&#36827;&#30340;UQ&#26041;&#27861;&#21462;&#24471;&#20102;&#19968;&#20123;&#36827;&#23637;&#65292;&#20294;&#23427;&#20204;&#22312;&#35745;&#31639;&#19978;&#35201;&#20040;&#38750;&#24120;&#26114;&#36149;&#65292;&#35201;&#20040;&#20135;&#29983;&#20445;&#23432;&#30340;&#39044;&#27979;&#38598;/&#21306;&#38388;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#28151;&#21512;UQ&#26041;&#27861;MC-CP&#65292;&#23427;&#23558;&#19968;&#31181;&#26032;&#30340;&#33258;&#36866;&#24212;&#33945;&#29305;&#21345;&#27931;&#65288;MC&#65289;dropout&#26041;&#27861;&#19982;&#21512;&#35268;&#39044;&#27979;&#65288;CP&#65289;&#30456;&#32467;&#21512;&#12290;MC-CP&#22312;&#36816;&#34892;&#26102;&#33258;&#36866;&#24212;&#35843;&#33410;&#20256;&#32479;&#30340;MC dropout&#20197;&#33410;&#30465;&#20869;&#23384;&#21644;&#35745;&#31639;&#36164;&#28304;&#65292;&#20351;&#24471;&#39044;&#27979;&#21487;&#20197;&#34987;CP&#20351;&#29992;&#65292;&#24471;&#21040;&#40065;&#26834;&#30340;&#39044;&#27979;&#38598;/&#21306;&#38388;&#12290;&#36890;&#36807;&#20840;&#38754;&#30340;&#23454;&#39564;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;MC-CP&#30456;&#27604;MC dropout&#12289;RAPS&#21644;CQR&#31561;&#20808;&#36827;&#30340;UQ&#26041;&#27861;&#33021;&#22815;&#26174;&#33879;&#25913;&#21892;&#20998;&#31867;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;
Deploying deep learning models in safety-critical applications remains a very challenging task, mandating the provision of assurances for the dependable operation of these models. Uncertainty quantification (UQ) methods estimate the model's confidence per prediction, informing decision-making by considering the effect of randomness and model misspecification. Despite the advances of state-of-the-art UQ methods, they are computationally expensive or produce conservative prediction sets/intervals. We introduce MC-CP, a novel hybrid UQ method that combines a new adaptive Monte Carlo (MC) dropout method with conformal prediction (CP). MC-CP adaptively modulates the traditional MC dropout at runtime to save memory and computation resources, enabling predictions to be consumed by CP, yielding robust prediction sets/intervals. Throughout comprehensive experiments, we show that MC-CP delivers significant improvements over advanced UQ methods, like MC dropout, RAPS and CQR, both in classificati
&lt;/p&gt;</description></item><item><title>Bandit&#21453;&#39304;&#19979;&#30340;&#22312;&#32447;&#22810;&#31867;&#23398;&#20064;&#30340;&#20851;&#38190;&#22312;&#20110;Bandit Littlestone&#32500;&#24230;&#30340;&#26377;&#38480;&#24615;&#65292;&#26080;&#35770;&#26631;&#31614;&#31354;&#38388;&#26159;&#21542;&#26080;&#30028;&#12290;</title><link>http://arxiv.org/abs/2308.04620</link><description>&lt;p&gt;
&#22810;&#31867;&#22312;&#32447;&#23398;&#20064;&#22312;Bandit&#21453;&#39304;&#19979;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Multiclass Online Learnability under Bandit Feedback. (arXiv:2308.04620v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04620
&lt;/p&gt;
&lt;p&gt;
Bandit&#21453;&#39304;&#19979;&#30340;&#22312;&#32447;&#22810;&#31867;&#23398;&#20064;&#30340;&#20851;&#38190;&#22312;&#20110;Bandit Littlestone&#32500;&#24230;&#30340;&#26377;&#38480;&#24615;&#65292;&#26080;&#35770;&#26631;&#31614;&#31354;&#38388;&#26159;&#21542;&#26080;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;Bandit&#21453;&#39304;&#19979;&#30340;&#22810;&#31867;&#22312;&#32447;&#20998;&#31867;&#38382;&#39064;&#12290;&#25105;&#20204;&#25193;&#23637;&#20102;(daniely2013price)&#30340;&#32467;&#26524;&#65292;&#36890;&#36807;&#23637;&#31034;Bandit Littlestone&#32500;&#24230;&#30340;&#26377;&#38480;&#24615;&#26159;&#22810;&#31867;&#22312;&#32447;&#23398;&#20064;&#30340;&#24517;&#35201;&#19988;&#20805;&#20998;&#26465;&#20214;&#65292;&#21363;&#20351;&#26631;&#31614;&#31354;&#38388;&#26159;&#26080;&#30028;&#30340;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34917;&#20805;&#20102;(hanneke2023multiclass)&#30340;&#26368;&#36817;&#24037;&#20316;&#65292;&#20182;&#20204;&#22312;&#26631;&#31614;&#31354;&#38388;&#26080;&#30028;&#30340;&#20840;&#20449;&#24687;&#35774;&#32622;&#20013;&#65292;&#23637;&#31034;&#20102;Littlestone&#32500;&#24230;&#21051;&#30011;&#20102;&#22312;&#32447;&#22810;&#31867;&#23398;&#20064;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study online multiclass classification under bandit feedback. We extend the results of (daniely2013price) by showing that the finiteness of the Bandit Littlestone dimension is necessary and sufficient for bandit online multiclass learnability even when the label space is unbounded. Our result complements the recent work by (hanneke2023multiclass) who show that the Littlestone dimension characterizes online multiclass learnability in the full-information setting when the label space is unbounded.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#23545;&#20110;&#36125;&#21494;&#26031;&#36172;&#21338;&#26426;&#30340;&#39318;&#20010;&#26377;&#38480;&#26102;&#38388;&#23545;&#25968;&#36951;&#25022;&#36793;&#30028;&#65292;&#24182;&#29992;&#20110;&#39640;&#26031;&#21644;&#32447;&#24615;&#36172;&#21338;&#26426;&#65292;&#20174;&#32780;&#38416;&#26126;&#20102;&#36125;&#21494;&#26031;&#35774;&#32622;&#20013;&#20808;&#39564;&#20215;&#20540;&#20197;&#21450;&#23545;$\tilde{O}(\sqrt{n})$&#30028;&#38480;&#30340;&#25913;&#21892;&#12290;</title><link>http://arxiv.org/abs/2306.09136</link><description>&lt;p&gt;
&#23545;&#25968;&#36125;&#21494;&#26031;&#36951;&#25022;&#36793;&#30028;
&lt;/p&gt;
&lt;p&gt;
Logarithmic Bayes Regret Bounds. (arXiv:2306.09136v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09136
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#23545;&#20110;&#36125;&#21494;&#26031;&#36172;&#21338;&#26426;&#30340;&#39318;&#20010;&#26377;&#38480;&#26102;&#38388;&#23545;&#25968;&#36951;&#25022;&#36793;&#30028;&#65292;&#24182;&#29992;&#20110;&#39640;&#26031;&#21644;&#32447;&#24615;&#36172;&#21338;&#26426;&#65292;&#20174;&#32780;&#38416;&#26126;&#20102;&#36125;&#21494;&#26031;&#35774;&#32622;&#20013;&#20808;&#39564;&#20215;&#20540;&#20197;&#21450;&#23545;$\tilde{O}(\sqrt{n})$&#30028;&#38480;&#30340;&#25913;&#21892;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20026;&#36125;&#21494;&#26031;&#36172;&#21338;&#26426;&#23548;&#20986;&#20102;&#39318;&#20010;&#26377;&#38480;&#26102;&#38388;&#23545;&#25968;&#36951;&#25022;&#36793;&#30028;&#12290;&#23545;&#20110;&#39640;&#26031;&#36172;&#21338;&#26426;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#19968;&#20010;$O(c_h \log^2 n)$&#30340;&#36793;&#30028;&#65292;&#20854;&#20013;$c_h$&#26159;&#19982;&#20808;&#39564;&#30456;&#20851;&#30340;&#24120;&#37327;&#12290;&#36825;&#19982;Lai&#65288;1987&#65289;&#30340;&#28176;&#36817;&#19979;&#38480;&#30456;&#21305;&#37197;&#12290;&#25105;&#20204;&#30340;&#35777;&#26126;&#19982;&#20808;&#21069;&#30340;&#24037;&#20316;&#26377;&#25152;&#19981;&#21516;&#65292;&#19988;&#31616;&#21333;&#19988;&#26222;&#36941;&#12290;&#20026;&#20102;&#26174;&#31034;&#19968;&#33324;&#24615;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#25216;&#26415;&#24212;&#29992;&#20110;&#32447;&#24615;&#36172;&#21338;&#26426;&#12290;&#25105;&#20204;&#30340;&#30028;&#38480;&#38416;&#26126;&#20102;&#36125;&#21494;&#26031;&#35774;&#32622;&#20013;&#20808;&#39564;&#30340;&#20215;&#20540;&#65292;&#26082;&#21487;&#20197;&#20316;&#20026;&#30446;&#26631;&#65292;&#20063;&#21487;&#20197;&#20316;&#20026;&#20256;&#36882;&#32473;&#23398;&#20064;&#32773;&#30340;&#38468;&#21152;&#20449;&#24687;&#12290;&#23427;&#20204;&#26174;&#30528;&#25913;&#21892;&#20102;&#29616;&#26377;&#30340;$\tilde{O}(\sqrt{n})$&#30028;&#38480;&#65292;&#23613;&#31649;&#23384;&#22312;&#19979;&#38480;&#65292;&#20294;&#24050;&#25104;&#20026;&#25991;&#29486;&#20013;&#30340;&#26631;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;
We derive the first finite-time logarithmic regret bounds for Bayesian bandits. For Gaussian bandits, we obtain a $O(c_h \log^2 n)$ bound, where $c_h$ is a prior-dependent constant. This matches the asymptotic lower bound of Lai (1987). Our proofs mark a technical departure from prior works, and are simple and general. To show generality, we apply our technique to linear bandits. Our bounds shed light on the value of the prior in the Bayesian setting, both in the objective and as a side information given to the learner. They significantly improve the $\tilde{O}(\sqrt{n})$ bounds, that despite the existing lower bounds, have become standard in the literature.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#24230;&#30456;&#20284;&#30340;&#21464;&#20998;&#21518;&#39564;&#20998;&#24067;&#21644;&#20808;&#39564;&#20998;&#24067;&#20043;&#38388;&#30340;&#21518;&#39564;&#23849;&#28291;&#29616;&#35937;&#65292;&#29305;&#21035;&#22320;&#65292;&#36890;&#36807;&#23545;&#32447;&#24615;&#26465;&#20214;VAE&#21644;&#20998;&#23618;VAE&#36827;&#34892;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#36825;&#31181;&#29616;&#35937;&#26159;&#30001;&#20110;&#28508;&#22312;&#21464;&#37327;&#23618;&#27425;&#20851;&#31995;&#19981;&#28165;&#26224;&#32780;&#24341;&#36215;&#30340;&#12290;</title><link>http://arxiv.org/abs/2306.05023</link><description>&lt;p&gt;
&#32447;&#24615;&#26465;&#20214;VAE&#21644;&#20998;&#23618;VAE&#20013;&#30340;&#21518;&#39564;&#23849;&#28291;&#29616;&#35937;
&lt;/p&gt;
&lt;p&gt;
Posterior Collapse in Linear Conditional and Hierarchical Variational Autoencoders. (arXiv:2306.05023v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05023
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#24230;&#30456;&#20284;&#30340;&#21464;&#20998;&#21518;&#39564;&#20998;&#24067;&#21644;&#20808;&#39564;&#20998;&#24067;&#20043;&#38388;&#30340;&#21518;&#39564;&#23849;&#28291;&#29616;&#35937;&#65292;&#29305;&#21035;&#22320;&#65292;&#36890;&#36807;&#23545;&#32447;&#24615;&#26465;&#20214;VAE&#21644;&#20998;&#23618;VAE&#36827;&#34892;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#36825;&#31181;&#29616;&#35937;&#26159;&#30001;&#20110;&#28508;&#22312;&#21464;&#37327;&#23618;&#27425;&#20851;&#31995;&#19981;&#28165;&#26224;&#32780;&#24341;&#36215;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#20013;&#65292;&#21518;&#39564;&#23849;&#28291;&#29616;&#35937;&#25351;&#30340;&#26159;&#21464;&#20998;&#21518;&#39564;&#20998;&#24067;&#19982;&#20808;&#39564;&#20998;&#24067;&#30340;&#30456;&#20284;&#24230;&#36807;&#39640;&#65292;&#23548;&#33268;&#32534;&#30721;&#22120;&#25552;&#21462;&#30340;&#28508;&#22312;&#21464;&#37327;&#20445;&#23384;&#30340;&#36755;&#20837;&#25968;&#25454;&#20449;&#24687;&#36739;&#23569;&#65292;&#26080;&#27861;&#20026;&#35299;&#30721;&#22120;&#30340;&#25968;&#25454;&#37325;&#24314;&#36807;&#31243;&#20135;&#29983;&#26377;&#24847;&#20041;&#30340;&#34920;&#31034;&#12290;&#23613;&#31649;&#35813;&#29616;&#35937;&#19968;&#30452;&#26159;VAEs&#24615;&#33021;&#30340;&#30740;&#31350;&#28909;&#28857;&#65292;&#20294;&#26159;&#23545;&#20110;&#21518;&#39564;&#23849;&#28291;&#30340;&#29702;&#35770;&#21364;&#30456;&#23545;&#34180;&#24369;&#65292;&#29305;&#21035;&#26159;&#22312;&#38750;&#26631;&#20934;&#30340;VAEs&#20013;&#12290;&#26412;&#25991;&#36890;&#36807;&#23545;&#20004;&#31867;&#37325;&#35201;&#32780;&#24120;&#35265;&#21448;&#36739;&#23569;&#30740;&#31350;&#30340;VAEs&#36827;&#34892;&#38750;&#24179;&#20961;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#21363;&#20855;&#26377;&#20004;&#20010;&#28508;&#22312;&#21464;&#37327;&#23618;&#27425;&#30340;&#32447;&#24615;&#26465;&#20214;VAE&#21644;&#20998;&#23618;VAE&#65292;&#25552;&#21319;&#20102;&#23545;&#21518;&#39564;&#23849;&#28291;&#30340;&#29702;&#35770;&#35748;&#35782;&#65292;&#35777;&#26126;&#20102;&#20854;&#25104;&#22240;&#12290;
&lt;/p&gt;
&lt;p&gt;
The posterior collapse phenomenon in variational autoencoders (VAEs), where the variational posterior distribution closely matches the prior distribution, can hinder the quality of the learned latent variables. As a consequence of posterior collapse, the latent variables extracted by the encoder in VAEs preserve less information from the input data and thus fail to produce meaningful representations as input to the reconstruction process in the decoder. While this phenomenon has been an actively addressed topic related to VAEs performance, the theory for posterior collapse remains underdeveloped, especially beyond the standard VAEs. In this work, we advance the theoretical understanding of posterior collapse to two important and prevalent yet less studied classes of VAEs: conditional VAEs and hierarchical VAEs. Specifically, via a non-trivial theoretical analysis of linear conditional VAEs and hierarchical VAEs with two levels of latent, we prove that the cause of posterior collapses i
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#35752;&#35770;&#22312;&#20855;&#26377;&#36172;&#21338;&#21453;&#39304;&#30340;&#38543;&#26426;&#29615;&#22659;&#20013;&#36827;&#34892;&#36873;&#25321;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;&#25968;&#25454;&#30340;&#27169;&#22411;&#36873;&#25321;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#20445;&#35777;&#12290;&#36890;&#36807;&#21033;&#29992;&#23454;&#38469;&#36951;&#25022;&#65292;&#36825;&#20123;&#31639;&#27861;&#22312;&#23454;&#38469;&#20013;&#21462;&#24471;&#20102;&#22909;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.02869</link><description>&lt;p&gt;
&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#36951;&#25022;&#24179;&#34913;&#22312;&#32447;&#27169;&#22411;&#36873;&#25321;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Data-Driven Regret Balancing for Online Model Selection in Bandits. (arXiv:2306.02869v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02869
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#35752;&#35770;&#22312;&#20855;&#26377;&#36172;&#21338;&#21453;&#39304;&#30340;&#38543;&#26426;&#29615;&#22659;&#20013;&#36827;&#34892;&#36873;&#25321;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;&#25968;&#25454;&#30340;&#27169;&#22411;&#36873;&#25321;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#20445;&#35777;&#12290;&#36890;&#36807;&#21033;&#29992;&#23454;&#38469;&#36951;&#25022;&#65292;&#36825;&#20123;&#31639;&#27861;&#22312;&#23454;&#38469;&#20013;&#21462;&#24471;&#20102;&#22909;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#20855;&#26377;&#36172;&#21338;&#21453;&#39304;&#30340;&#38543;&#26426;&#29615;&#22659;&#20013;&#36827;&#34892;&#39034;&#24207;&#20915;&#31574;&#27169;&#22411;&#36873;&#25321;&#65292;&#20854;&#20013;&#20803;&#23398;&#20064;&#22120;&#21487;&#20197;&#20351;&#29992;&#19968;&#32452;&#22522;&#26412;&#23398;&#20064;&#22120;&#65292;&#24182;&#26681;&#25454;&#27599;&#20010;&#22522;&#26412;&#23398;&#20064;&#22120;&#25512;&#33616;&#30340;&#31574;&#30053;&#21160;&#24577;&#20915;&#31574;&#12290;&#25105;&#20204;&#36890;&#36807;&#36951;&#25022;&#24179;&#34913;&#26469;&#25191;&#34892;&#27169;&#22411;&#36873;&#25321;&#65292;&#20294;&#19982;&#27492;&#30456;&#20851;&#30340;&#26368;&#36817;&#25991;&#29486;&#19981;&#21516;&#30340;&#26159;&#65292;&#25105;&#20204;&#27809;&#26377;&#20551;&#35774;&#20219;&#20309;&#20851;&#20110;&#22522;&#26412;&#23398;&#20064;&#22120;&#30340;&#20808;&#39564;&#30693;&#35782;&#65292;&#22914;&#20505;&#36873;&#36951;&#25022;&#20445;&#35777;&#65307;&#30456;&#21453;&#65292;&#25105;&#20204;&#20197;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#24335;&#25581;&#31034;&#36825;&#20123;&#25968;&#37327;&#12290;&#22240;&#27492;&#65292;&#20803;&#23398;&#20064;&#22120;&#33021;&#22815;&#21033;&#29992;&#27599;&#20010;&#22522;&#26412;&#23398;&#20064;&#22120;&#22312;&#32473;&#23450;&#30340;&#23398;&#20064;&#29615;&#22659;&#20013;&#20135;&#29983;&#30340;&#23454;&#38469;&#36951;&#25022;&#65288;&#32780;&#19981;&#26159;&#26399;&#26395;&#36951;&#25022;&#65289;&#65292;&#24182;&#25361;&#36873;&#20986;&#26368;&#20339;&#30340;&#36951;&#25022;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#20004;&#20010;&#27169;&#22411;&#36873;&#25321;&#31639;&#27861;&#65292;&#25805;&#20316;&#26356;&#20026;&#38596;&#24515;&#21187;&#21187;&#30340;&#36951;&#25022;&#27010;&#24565;&#65292;&#24182;&#19988;&#38500;&#20102;&#36890;&#36807;&#36951;&#25022;&#24179;&#34913;&#35777;&#26126;&#27169;&#22411;&#36873;&#25321;&#20445;&#35777;&#22806;&#65292;&#25105;&#20204;&#36824;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#22788;&#29702;&#23454;&#38469;&#36951;&#25022;&#30340;&#20196;&#20154;&#20449;&#26381;&#30340;&#23454;&#38469;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider model selection for sequential decision making in stochastic environments with bandit feedback, where a meta-learner has at its disposal a pool of base learners, and decides on the fly which action to take based on the policies recommended by each base learner. Model selection is performed by regret balancing but, unlike the recent literature on this subject, we do not assume any prior knowledge about the base learners like candidate regret guarantees; instead, we uncover these quantities in a data-driven manner. The meta-learner is therefore able to leverage the realized regret incurred by each base learner for the learning environment at hand (as opposed to the expected regret), and single out the best such regret. We design two model selection algorithms operating with this more ambitious notion of regret and, besides proving model selection guarantees via regret balancing, we experimentally demonstrate the compelling practical benefits of dealing with actual regrets ins
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312; mini-batch &#20013;&#26174;&#24335;&#22320;&#23398;&#20064;&#35823;&#24046;&#30340;&#24207;&#21015;&#30456;&#20851;&#24615;&#65292;&#26469;&#25552;&#39640;&#28145;&#24230;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;</title><link>http://arxiv.org/abs/2305.17028</link><description>&lt;p&gt;
&#28145;&#24230;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#26356;&#22909;Batch&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Better Batch for Deep Probabilistic Time Series Forecasting. (arXiv:2305.17028v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17028
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35757;&#32451;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312; mini-batch &#20013;&#26174;&#24335;&#22320;&#23398;&#20064;&#35823;&#24046;&#30340;&#24207;&#21015;&#30456;&#20851;&#24615;&#65292;&#26469;&#25552;&#39640;&#28145;&#24230;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#22240;&#20854;&#33021;&#22815;&#25552;&#20379;&#26377;&#20215;&#20540;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#32780;&#21463;&#21040;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#29616;&#26377;&#27169;&#22411;&#36807;&#20110;&#31616;&#21333;&#21270;&#38382;&#39064;&#65292;&#20551;&#35774;&#35823;&#24046;&#36807;&#31243;&#26159;&#19982;&#26102;&#38388;&#26080;&#20851;&#30340;&#65292;&#20174;&#32780;&#24573;&#30053;&#20102;&#35823;&#24046;&#36807;&#31243;&#20013;&#30340;&#24207;&#21015;&#30456;&#20851;&#24615;&#12290;&#36825;&#21487;&#33021;&#20250;&#38477;&#20302;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#65292;&#20351;&#36825;&#20123;&#27169;&#22411;&#23545;&#20915;&#31574;&#24615;&#20219;&#21153;&#30340;&#26377;&#25928;&#24615;&#20943;&#24369;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#19968;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#35757;&#32451;&#26041;&#27861;&#65292;&#23558;&#35823;&#24046;&#33258;&#30456;&#20851;&#24615;&#32435;&#20837;&#32771;&#34385;&#65292;&#20197;&#22686;&#24378;&#27010;&#29575;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#28041;&#21450;&#26500;&#36896;&#19968;&#20010;mini-batch&#65292;&#20316;&#20026;$D$&#20010;&#36830;&#32493;&#26102;&#38388;&#24207;&#21015;&#27573;&#36827;&#34892;&#27169;&#22411;&#35757;&#32451;&#65292;&#24182;&#26174;&#24335;&#22320;&#23398;&#20064;&#19968;&#20010;&#21327;&#26041;&#24046;&#30697;&#38453;&#65292;&#35206;&#30422;&#20102;&#30456;&#37051;&#26102;&#38388;&#27493;&#20043;&#38388;&#30340;&#35823;&#24046;&#30456;&#20851;&#24615;&#12290;&#30001;&#27492;&#20135;&#29983;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#21487;&#29992;&#20110;&#25552;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#21644;&#22686;&#24378;&#19981;&#30830;&#23450;&#24615;&#30340;&#37327;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep probabilistic time series forecasting has gained significant attention due to its ability to provide valuable uncertainty quantification for decision-making tasks. However, many existing models oversimplify the problem by assuming the error process is time-independent, thereby overlooking the serial correlation in the error process. This oversight can potentially diminish the accuracy of the forecasts, rendering these models less effective for decision-making purposes. To overcome this limitation, we propose an innovative training method that incorporates error autocorrelation to enhance the accuracy of probabilistic forecasting. Our method involves constructing a mini-batch as a collection of $D$ consecutive time series segments for model training and explicitly learning a covariance matrix over each mini-batch that encodes the error correlation among adjacent time steps. The resulting covariance matrix can be used to improve prediction accuracy and enhance uncertainty quantifica
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#28145;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#20013;&#30340;&#24402;&#32435;&#20559;&#32622;&#65292;&#35777;&#26126;&#20102;$\mathcal{O}(\log d)$&#30340;&#28145;&#24230;&#23601;&#36275;&#20197;&#23454;&#29616;&#26222;&#36866;&#24615;&#65292;&#29992;CNN&#23398;&#20064;&#31232;&#30095;&#20989;&#25968;&#21482;&#38656;&#35201;$\tilde{\mathcal{O}}(\log^2d)$&#20010;&#26679;&#26412;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#23616;&#37096;&#36830;&#25509;&#32593;&#32476;&#65288;LCN&#65289;&#20998;&#26512;&#20102;&#26435;&#37325;&#20849;&#20139;&#21644;&#23616;&#37096;&#24615;&#30340;&#24402;&#32435;&#20559;&#32622;&#30340;&#21306;&#21035;&#65292;&#24471;&#20986;&#20102;&#23427;&#20204;&#22312;&#34920;&#31034;&#38656;&#35201;&#26377;&#38480;&#24179;&#31227;&#31561;&#21464;&#21644;&#39640;&#26041;&#21521;&#36873;&#25321;&#24615;&#30340;&#20989;&#25968;&#26041;&#38754;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.08404</link><description>&lt;p&gt;
&#28145;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#20013;&#24402;&#32435;&#20559;&#32622;&#30340;&#29702;&#35770;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Theoretical Analysis of Inductive Biases in Deep Convolutional Networks. (arXiv:2305.08404v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08404
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#28145;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#20013;&#30340;&#24402;&#32435;&#20559;&#32622;&#65292;&#35777;&#26126;&#20102;$\mathcal{O}(\log d)$&#30340;&#28145;&#24230;&#23601;&#36275;&#20197;&#23454;&#29616;&#26222;&#36866;&#24615;&#65292;&#29992;CNN&#23398;&#20064;&#31232;&#30095;&#20989;&#25968;&#21482;&#38656;&#35201;$\tilde{\mathcal{O}}(\log^2d)$&#20010;&#26679;&#26412;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#23616;&#37096;&#36830;&#25509;&#32593;&#32476;&#65288;LCN&#65289;&#20998;&#26512;&#20102;&#26435;&#37325;&#20849;&#20139;&#21644;&#23616;&#37096;&#24615;&#30340;&#24402;&#32435;&#20559;&#32622;&#30340;&#21306;&#21035;&#65292;&#24471;&#20986;&#20102;&#23427;&#20204;&#22312;&#34920;&#31034;&#38656;&#35201;&#26377;&#38480;&#24179;&#31227;&#31561;&#21464;&#21644;&#39640;&#26041;&#21521;&#36873;&#25321;&#24615;&#30340;&#20989;&#25968;&#26041;&#38754;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#20013;&#30340;&#24402;&#32435;&#20559;&#32622;&#65292;&#36825;&#34987;&#35748;&#20026;&#26159;CNN&#22312;&#35270;&#35273;&#20219;&#21153;&#19978;&#34920;&#29616;&#24322;&#24120;&#20986;&#33394;&#30340;&#37325;&#35201;&#39537;&#21160;&#22240;&#32032;&#12290;&#25105;&#20204;&#39318;&#20808;&#20998;&#26512;&#20102;CNN&#30340;&#26222;&#36866;&#24615;&#65292;&#21363;&#36924;&#36817;&#36830;&#32493;&#20989;&#25968;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;$\mathcal{O}(\log d)$&#30340;&#28145;&#24230;&#23601;&#36275;&#20197;&#23454;&#29616;&#26222;&#36866;&#24615;&#65292;&#20854;&#20013;$d$&#26159;&#36755;&#20837;&#32500;&#24230;&#12290;&#36825;&#30456;&#27604;&#20110;&#29616;&#26377;&#32467;&#26524;&#38656;&#35201;$\Omega(d)$&#30340;&#28145;&#24230;&#26159;&#19968;&#39033;&#37325;&#22823;&#25913;&#36827;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#29992;CNN&#23398;&#20064;&#31232;&#30095;&#20989;&#25968;&#21482;&#38656;&#35201;$\tilde{\mathcal{O}}(\log^2d)$&#20010;&#26679;&#26412;&#65292;&#34920;&#26126;&#28145;&#24230;CNN&#21487;&#20197;&#26377;&#25928;&#22320;&#25429;&#25417;&#38271;&#31243;&#31232;&#30095;&#30456;&#20851;&#24615;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#36824;&#20998;&#26512;&#20102;&#20849;&#20139;&#26435;&#37325;&#21644;&#23616;&#37096;&#24615;&#30340;&#24402;&#32435;&#20559;&#32622;&#65292;&#36890;&#36807;&#23545;&#31216;&#24615;&#24471;&#20986;&#32467;&#35770;&#12290;&#20026;&#20102;&#21306;&#20998;&#36825;&#20004;&#31181;&#20559;&#35265;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#23616;&#37096;&#36830;&#25509;&#32593;&#32476;&#65288;LCN&#65289;&#24182;&#35777;&#26126;&#20102;&#23427;&#20204;&#22312;&#34920;&#31034;&#38656;&#35201;&#26377;&#38480;&#24179;&#31227;&#31561;&#21464;&#21644;&#39640;&#26041;&#21521;&#36873;&#25321;&#24615;&#30340;&#20989;&#25968;&#26041;&#38754;&#30340;&#20248;&#36234;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20026;&#28145;CNN&#30340;&#25104;&#21151;&#25552;&#20379;&#20102;&#29702;&#35770;&#27934;&#23519;&#21147;&#65292;&#21516;&#26102;&#26356;&#22909;&#22320;&#29702;&#35299;&#20102;&#23427;&#20204;&#30340;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study the inductive biases in convolutional neural networks (CNNs), which are believed to be vital drivers behind CNNs' exceptional performance on vision-like tasks. We first analyze the universality of CNNs, i.e., the ability to approximate continuous functions. We prove that a depth of $\mathcal{O}(\log d)$ is sufficient for achieving universality, where $d$ is the input dimension. This is a significant improvement over existing results that required a depth of $\Omega(d)$. We also prove that learning sparse functions with CNNs needs only $\tilde{\mathcal{O}}(\log^2d)$ samples, indicating that deep CNNs can efficiently capture long-range sparse correlations. Note that all these are achieved through a novel combination of increased network depth and the utilization of multichanneling and downsampling.  Lastly, we study the inductive biases of weight sharing and locality through the lens of symmetry. To separate two biases, we introduce locally-connected networks (LCN
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26368;&#22823;&#21270;&#19968;&#31995;&#21015;&#24402;&#19968;&#21270;&#30697;&#26469;&#20351;&#29992;&#23376;&#39640;&#26031;&#20869;&#22312;&#30697;&#33539;&#23454;&#29616;&#32039;&#20945;&#30340;&#38750;&#28176;&#36827;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#23548;&#33268;&#26356;&#32039;&#30340;Hoeffding&#23376;&#39640;&#26031;&#27987;&#24230;&#19981;&#31561;&#24335;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#23376;&#39640;&#26031;&#22270;&#26816;&#26597;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#22823;&#23567;&#30340;&#23376;&#39640;&#26031;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2303.07287</link><description>&lt;p&gt;
&#36890;&#36807;&#23376;&#39640;&#26031;&#20869;&#22312;&#30697;&#33539;&#23454;&#29616;&#32039;&#20945;&#30340;&#38750;&#28176;&#36827;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Tight Non-asymptotic Inference via Sub-Gaussian Intrinsic Moment Norm. (arXiv:2303.07287v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.07287
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26368;&#22823;&#21270;&#19968;&#31995;&#21015;&#24402;&#19968;&#21270;&#30697;&#26469;&#20351;&#29992;&#23376;&#39640;&#26031;&#20869;&#22312;&#30697;&#33539;&#23454;&#29616;&#32039;&#20945;&#30340;&#38750;&#28176;&#36827;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#23548;&#33268;&#26356;&#32039;&#30340;Hoeffding&#23376;&#39640;&#26031;&#27987;&#24230;&#19981;&#31561;&#24335;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#23376;&#39640;&#26031;&#22270;&#26816;&#26597;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#22823;&#23567;&#30340;&#23376;&#39640;&#26031;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a method of achieving tight non-asymptotic inference by using sub-Gaussian intrinsic moment norm through maximizing a series of normalized moments, which can lead to tighter Hoeffding's sub-Gaussian concentration inequalities and can be checked with sub-Gaussian plot for sub-Gaussian data with a finite sample size.
&lt;/p&gt;
&lt;p&gt;
&#22312;&#38750;&#28176;&#36827;&#32479;&#35745;&#25512;&#26029;&#20013;&#65292;&#23376;&#39640;&#26031;&#20998;&#24067;&#30340;&#26041;&#24046;&#31867;&#22411;&#21442;&#25968;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#22522;&#20110;&#32463;&#39564;&#30697;&#29983;&#25104;&#20989;&#25968;&#65288;MGF&#65289;&#30340;&#30452;&#25509;&#20272;&#35745;&#36825;&#20123;&#21442;&#25968;&#26159;&#19981;&#21487;&#34892;&#30340;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24314;&#35758;&#36890;&#36807;&#26368;&#22823;&#21270;&#19968;&#31995;&#21015;&#24402;&#19968;&#21270;&#30697;&#26469;&#20351;&#29992;&#23376;&#39640;&#26031;&#20869;&#22312;&#30697;&#33539;[Buldygin&#21644;Kozachenko&#65288;2000&#65289;&#65292;&#23450;&#29702;1.3]&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#25512;&#33616;&#30340;&#33539;&#25968;&#19981;&#20165;&#21487;&#20197;&#24674;&#22797;&#30456;&#24212;MGF&#30340;&#25351;&#25968;&#30697;&#30028;&#38480;&#65292;&#32780;&#19988;&#36824;&#21487;&#20197;&#23548;&#33268;&#26356;&#32039;&#30340;Hoeffding&#23376;&#39640;&#26031;&#27987;&#24230;&#19981;&#31561;&#24335;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#30452;&#35266;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23376;&#39640;&#26031;&#22270;&#26816;&#26597;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#22823;&#23567;&#30340;&#23376;&#39640;&#26031;&#25968;&#25454;&#12290;&#21487;&#20197;&#36890;&#36807;&#31616;&#21333;&#30340;&#25554;&#20837;&#26041;&#27861;&#40065;&#26834;&#22320;&#20272;&#35745;&#20869;&#22312;&#30697;&#33539;&#25968;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#24212;&#29992;&#20110;&#38750;&#28176;&#36827;&#20998;&#26512;&#65292;&#21253;&#25324;&#22810;&#33218;&#36172;&#21338;&#26426;&#12290;
&lt;/p&gt;
&lt;p&gt;
In non-asymptotic statistical inferences, variance-type parameters of sub-Gaussian distributions play a crucial role. However, direct estimation of these parameters based on the empirical moment generating function (MGF) is infeasible. To this end, we recommend using a sub-Gaussian intrinsic moment norm [Buldygin and Kozachenko (2000), Theorem 1.3] through maximizing a series of normalized moments. Importantly, the recommended norm can not only recover the exponential moment bounds for the corresponding MGFs, but also lead to tighter Hoeffding's sub-Gaussian concentration inequalities. In practice, {\color{black} we propose an intuitive way of checking sub-Gaussian data with a finite sample size by the sub-Gaussian plot}. Intrinsic moment norm can be robustly estimated via a simple plug-in approach. Our theoretical results are applied to non-asymptotic analysis, including the multi-armed bandit.
&lt;/p&gt;</description></item><item><title>OPAA&#26159;&#19968;&#31181;&#21151;&#33021;&#20998;&#26512;&#26041;&#27861;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#25214;&#21040;&#24179;&#28369;&#30340;&#27010;&#29575;&#20998;&#24067;&#20989;&#25968;&#20272;&#35745;&#20540;&#12289;&#35745;&#31639;&#24402;&#19968;&#21270;&#26435;&#37325;&#30340;&#20272;&#35745;&#20540;&#65292;&#24182;&#20351;&#29992;&#29305;&#27530;&#30340;&#20989;&#25968;&#31354;&#38388;&#36716;&#25442;&#26469;&#20272;&#35745;&#35777;&#25454;&#65292;&#23454;&#29616;&#20102;&#24182;&#34892;&#35745;&#31639;&#30340;&#19968;&#27425;&#36890;&#36807;&#12290;&#23427;&#36866;&#29992;&#20110;&#20272;&#35745;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#65292;&#23588;&#20854;&#22312;&#36125;&#21494;&#26031;&#38382;&#39064;&#20013;&#20272;&#35745;&#24402;&#19968;&#21270;&#26435;&#37325;&#12290;</title><link>http://arxiv.org/abs/2211.08594</link><description>&lt;p&gt;
&#27491;&#20132;&#22810;&#39033;&#24335;&#36924;&#36817;&#31639;&#27861;&#65288;OPAA&#65289;&#65306;&#19968;&#31181;&#29992;&#20110;&#20272;&#35745;&#27010;&#29575;&#23494;&#24230;&#30340;&#21151;&#33021;&#20998;&#26512;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Orthogonal Polynomials Approximation Algorithm (OPAA):a functional analytic approach to estimating probability densities. (arXiv:2211.08594v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.08594
&lt;/p&gt;
&lt;p&gt;
OPAA&#26159;&#19968;&#31181;&#21151;&#33021;&#20998;&#26512;&#26041;&#27861;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#25214;&#21040;&#24179;&#28369;&#30340;&#27010;&#29575;&#20998;&#24067;&#20989;&#25968;&#20272;&#35745;&#20540;&#12289;&#35745;&#31639;&#24402;&#19968;&#21270;&#26435;&#37325;&#30340;&#20272;&#35745;&#20540;&#65292;&#24182;&#20351;&#29992;&#29305;&#27530;&#30340;&#20989;&#25968;&#31354;&#38388;&#36716;&#25442;&#26469;&#20272;&#35745;&#35777;&#25454;&#65292;&#23454;&#29616;&#20102;&#24182;&#34892;&#35745;&#31639;&#30340;&#19968;&#27425;&#36890;&#36807;&#12290;&#23427;&#36866;&#29992;&#20110;&#20272;&#35745;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#65292;&#23588;&#20854;&#22312;&#36125;&#21494;&#26031;&#38382;&#39064;&#20013;&#20272;&#35745;&#24402;&#19968;&#21270;&#26435;&#37325;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27491;&#20132;&#22810;&#39033;&#24335;&#36924;&#36817;&#31639;&#27861;&#65288;OPAA&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#21487;&#24182;&#34892;&#21270;&#30340;&#31639;&#27861;&#65292;&#20351;&#29992;&#21151;&#33021;&#20998;&#26512;&#26041;&#27861;&#20272;&#35745;&#27010;&#29575;&#20998;&#24067;&#65306;&#39318;&#20808;&#65292;&#23427;&#25214;&#21040;&#20102;&#27010;&#29575;&#20998;&#24067;&#30340;&#24179;&#28369;&#20989;&#25968;&#20272;&#35745;&#65292;&#26080;&#35770;&#23427;&#26159;&#21542;&#24402;&#19968;&#21270;&#65307;&#20854;&#27425;&#65292;&#31639;&#27861;&#25552;&#20379;&#20102;&#24402;&#19968;&#21270;&#26435;&#37325;&#30340;&#20272;&#35745;&#65307;&#31532;&#19977;&#65292;&#31639;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35745;&#31639;&#26041;&#26696;&#26469;&#35745;&#31639;&#36825;&#20123;&#20272;&#35745;&#20540;&#12290;OPAA&#30340;&#26680;&#24515;&#32452;&#25104;&#37096;&#20998;&#26159;&#23558;&#32852;&#21512;&#20998;&#24067;&#30340;&#24179;&#26041;&#26681;&#36716;&#21270;&#20026;&#25105;&#20204;&#26500;&#36896;&#30340;&#29305;&#27530;&#20989;&#25968;&#31354;&#38388;&#30340;&#29305;&#27530;&#21464;&#25442;&#12290;&#36890;&#36807;&#36825;&#20010;&#21464;&#25442;&#65292;&#35777;&#25454;&#31561;&#20110;&#36716;&#25442;&#20989;&#25968;&#30340;$L^2$&#33539;&#25968;&#30340;&#24179;&#26041;&#12290;&#22240;&#27492;&#65292;&#21487;&#20197;&#36890;&#36807;&#36716;&#25442;&#31995;&#25968;&#30340;&#24179;&#26041;&#21644;&#26469;&#20272;&#35745;&#35777;&#25454;&#12290;&#35745;&#31639;&#21487;&#20197;&#24182;&#34892;&#21270;&#24182;&#22312;&#19968;&#27425;&#36890;&#36807;&#20013;&#23436;&#25104;&#12290;OPAA&#21487;&#20197;&#24191;&#27867;&#24212;&#29992;&#20110;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#30340;&#20272;&#35745;&#12290;&#22312;&#36125;&#21494;&#26031;&#38382;&#39064;&#20013;&#65292;&#23427;&#21487;&#20197;&#29992;&#20110;&#20272;&#35745;&#24402;&#19968;&#21270;&#26435;&#37325;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present the new Orthogonal Polynomials Approximation Algorithm (OPAA), a parallelizable algorithm that estimates probability distributions using functional analytic approach: first, it finds a smooth functional estimate of the probability distribution, whether it is normalized or not; second, the algorithm provides an estimate of the normalizing weight; and third, the algorithm proposes a new computation scheme to compute such estimates.  A core component of OPAA is a special transform of the square root of the joint distribution into a special functional space of our construct. Through this transform, the evidence is equated with the $L^2$ norm of the transformed function, squared. Hence, the evidence can be estimated by the sum of squares of the transform coefficients. Computations can be parallelized and completed in one pass.  OPAA can be applied broadly to the estimation of probability density functions. In Bayesian problems, it can be applied to estimating the normalizing weig
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21483;&#20570;&#20223;&#23556;&#27169;&#22411;&#36716;&#31227;&#30340;&#36801;&#31227;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#26399;&#26395;&#24179;&#26041;&#25439;&#22833;&#65292;&#21487;&#20197;&#36866;&#24212;&#21508;&#31181;&#19981;&#21516;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#22522;&#20110;&#31070;&#32463;&#29305;&#24449;&#25552;&#21462;&#22120;&#30340;&#26041;&#27861;&#12290;&#23545;&#20110;&#36825;&#20010;&#26041;&#27861;&#20063;&#32473;&#20986;&#20102;&#29702;&#35770;&#19978;&#30340;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2210.09745</link><description>&lt;p&gt;
&#21033;&#29992;&#20223;&#23556;&#27169;&#22411;&#21464;&#25442;&#30340;&#36801;&#31227;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Transfer learning with affine model transformation. (arXiv:2210.09745v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.09745
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21483;&#20570;&#20223;&#23556;&#27169;&#22411;&#36716;&#31227;&#30340;&#36801;&#31227;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#26399;&#26395;&#24179;&#26041;&#25439;&#22833;&#65292;&#21487;&#20197;&#36866;&#24212;&#21508;&#31181;&#19981;&#21516;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#22522;&#20110;&#31070;&#32463;&#29305;&#24449;&#25552;&#21462;&#22120;&#30340;&#26041;&#27861;&#12290;&#23545;&#20110;&#36825;&#20010;&#26041;&#27861;&#20063;&#32473;&#20986;&#20102;&#29702;&#35770;&#19978;&#30340;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#22312;&#25968;&#25454;&#31232;&#32570;&#30340;&#24773;&#20917;&#19979;&#33021;&#22815;&#25552;&#39640;&#26426;&#22120;&#23398;&#20064;&#30340;&#39044;&#27979;&#33021;&#21147;&#65292;&#21463;&#21040;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#20256;&#32479;&#19978;&#65292;&#20351;&#29992;&#32473;&#23450;&#30340;&#28304;&#27169;&#22411;&#38598;&#21644;&#26469;&#33258;&#30446;&#26631;&#39046;&#22495;&#30340;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#32479;&#35745;&#23398;&#20064;&#26469;&#36866;&#24212;&#39044;&#35757;&#32451;&#27169;&#22411;&#21040;&#30446;&#26631;&#39046;&#22495;&#65292;&#23398;&#20064;&#39046;&#22495;&#36716;&#31227;&#21644;&#39046;&#22495;&#29305;&#23450;&#22240;&#32032;&#12290;&#34429;&#28982;&#36825;&#31181;&#26041;&#27861;&#22312;&#24191;&#27867;&#30340;&#23454;&#38469;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#25104;&#21151;&#65292;&#20294;&#32570;&#20047;&#29702;&#35770;&#22522;&#30784;&#38459;&#30861;&#20102;&#36827;&#19968;&#27493;&#30340;&#26041;&#27861;&#21457;&#23637;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#20223;&#23556;&#27169;&#22411;&#36716;&#31227;&#30340;&#36890;&#29992;&#31867;&#21035;&#30340;&#36801;&#31227;&#23398;&#20064;&#22238;&#24402;&#26041;&#27861;&#65292;&#36981;&#24490;&#26399;&#26395;&#24179;&#26041;&#25439;&#22833;&#26368;&#23567;&#21270;&#30340;&#21407;&#21017;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#20223;&#23556;&#27169;&#22411;&#36716;&#31227;&#24191;&#27867;&#21253;&#25324;&#21508;&#31181;&#29616;&#26377;&#26041;&#27861;&#65292;&#21253;&#25324;&#22522;&#20110;&#31070;&#32463;&#29305;&#24449;&#25552;&#21462;&#22120;&#30340;&#26368;&#24120;&#35265;&#36807;&#31243;&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#38416;&#26126;&#20102;&#20223;&#23556;&#27169;&#22411;&#36716;&#31227;&#30340;&#29702;&#35770;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Supervised transfer learning has received considerable attention due to its potential to boost the predictive power of machine learning in scenarios where data are scarce. Generally, a given set of source models and a dataset from a target domain are used to adapt the pre-trained models to a target domain by statistically learning domain shift and domain-specific factors. While such procedurally and intuitively plausible methods have achieved great success in a wide range of real-world applications, the lack of a theoretical basis hinders further methodological development. This paper presents a general class of transfer learning regression called affine model transfer, following the principle of expected-square loss minimization. It is shown that the affine model transfer broadly encompasses various existing methods, including the most common procedure based on neural feature extractors. Furthermore, the current paper clarifies theoretical properties of the affine model transfer such 
&lt;/p&gt;</description></item><item><title>&#22810;&#26679;&#24615;&#25955;&#23556;&#21464;&#25442;&#26159;&#19968;&#31181;&#29992;&#20110;&#39640;&#32500;&#28857;&#20113;&#25968;&#25454;&#30340;&#28145;&#24230;&#29305;&#24449;&#25552;&#21462;&#22120;&#65292;&#22312;&#23454;&#29616;&#19978;&#37319;&#29992;&#20102;&#25193;&#25955;&#26144;&#23556;&#29702;&#35770;&#65292;&#26377;&#25928;&#29992;&#20110;&#20449;&#21495;&#20998;&#31867;&#21644;&#27969;&#24418;&#20998;&#31867;&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2206.10078</link><description>&lt;p&gt;
&#39640;&#32500;&#28857;&#20113;&#25968;&#25454;&#30340;&#22810;&#26679;&#24615;&#25955;&#23556;&#21464;&#25442;
&lt;/p&gt;
&lt;p&gt;
The Manifold Scattering Transform for High-Dimensional Point Cloud Data. (arXiv:2206.10078v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.10078
&lt;/p&gt;
&lt;p&gt;
&#22810;&#26679;&#24615;&#25955;&#23556;&#21464;&#25442;&#26159;&#19968;&#31181;&#29992;&#20110;&#39640;&#32500;&#28857;&#20113;&#25968;&#25454;&#30340;&#28145;&#24230;&#29305;&#24449;&#25552;&#21462;&#22120;&#65292;&#22312;&#23454;&#29616;&#19978;&#37319;&#29992;&#20102;&#25193;&#25955;&#26144;&#23556;&#29702;&#35770;&#65292;&#26377;&#25928;&#29992;&#20110;&#20449;&#21495;&#20998;&#31867;&#21644;&#27969;&#24418;&#20998;&#31867;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#26679;&#24615;&#25955;&#23556;&#21464;&#25442;&#26159;&#19968;&#31181;&#29992;&#20110;&#23450;&#20041;&#22312;&#40654;&#26364;&#27969;&#24418;&#19978;&#30340;&#25968;&#25454;&#30340;&#28145;&#24230;&#29305;&#24449;&#25552;&#21462;&#22120;&#12290;&#23427;&#26159;&#23558;&#31867;&#20284;&#20110;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#25805;&#20316;&#25193;&#23637;&#21040;&#19968;&#33324;&#27969;&#24418;&#30340;&#26368;&#26089;&#30340;&#20363;&#23376;&#20043;&#19968;&#12290;&#36825;&#20010;&#27169;&#22411;&#30340;&#26368;&#21021;&#24037;&#20316;&#20027;&#35201;&#20851;&#27880;&#20854;&#29702;&#35770;&#31283;&#23450;&#24615;&#21644;&#19981;&#21464;&#24615;&#29305;&#24615;&#65292;&#20294;&#38500;&#20102;&#22312;&#20855;&#26377;&#39044;&#23450;&#20041;&#32593;&#26684;&#30340;&#20108;&#32500;&#26354;&#38754;&#30340;&#24773;&#20917;&#19979;&#25552;&#20379;&#20854;&#25968;&#20540;&#23454;&#29616;&#30340;&#26041;&#27861;&#22806;&#65292;&#36824;&#27809;&#26377;&#25552;&#20379;&#20854;&#25968;&#20540;&#23454;&#29616;&#30340;&#26041;&#27861;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25193;&#25955;&#26144;&#23556;&#29702;&#35770;&#30340;&#23454;&#29992;&#26041;&#26696;&#65292;&#29992;&#20110;&#23558;&#22810;&#26679;&#24615;&#25955;&#23556;&#21464;&#25442;&#24212;&#29992;&#20110;&#33258;&#28982;&#31995;&#32479;&#20013;&#20135;&#29983;&#30340;&#25968;&#25454;&#38598;&#65292;&#20363;&#22914;&#21333;&#32454;&#32990;&#36951;&#20256;&#23398;&#65292;&#20854;&#20013;&#25968;&#25454;&#26159;&#20316;&#20026;&#20302;&#32500;&#27969;&#24418;&#19978;&#30340;&#39640;&#32500;&#28857;&#20113;&#24314;&#27169;&#30340;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#23545;&#20110;&#20449;&#21495;&#20998;&#31867;&#21644;&#27969;&#24418;&#20998;&#31867;&#20219;&#21153;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The manifold scattering transform is a deep feature extractor for data defined on a Riemannian manifold. It is one of the first examples of extending convolutional neural network-like operators to general manifolds. The initial work on this model focused primarily on its theoretical stability and invariance properties but did not provide methods for its numerical implementation except in the case of two-dimensional surfaces with predefined meshes. In this work, we present practical schemes, based on the theory of diffusion maps, for implementing the manifold scattering transform to datasets arising in naturalistic systems, such as single cell genetics, where the data is a high-dimensional point cloud modeled as lying on a low-dimensional manifold. We show that our methods are effective for signal classification and manifold classification tasks.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#25805;&#20316;&#22120;&#32593;&#32476;&#30340;&#27867;&#21270;&#30028;&#38480;&#38382;&#39064;&#65292;&#22312;&#19968;&#31867;DeepONets&#20013;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;Rademacher&#22797;&#26434;&#24230;&#30340;&#30028;&#38480;&#19981;&#20250;&#38543;&#32593;&#32476;&#23485;&#24230;&#25193;&#23637;&#32780;&#26126;&#30830;&#21464;&#21270;&#65292;&#24182;&#21033;&#29992;&#36825;&#20010;&#32467;&#26524;&#23637;&#31034;&#20102;&#22914;&#20309;&#36873;&#25321;Huber&#25439;&#22833;&#26469;&#33719;&#24471;&#19981;&#26126;&#30830;&#20381;&#36182;&#20110;&#32593;&#32476;&#22823;&#23567;&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2205.11359</link><description>&lt;p&gt;
&#38754;&#21521;&#23610;&#24230;&#26080;&#20851;&#30340;&#28145;&#24230;&#25805;&#20316;&#22120;&#32593;&#32476;&#30340;&#27867;&#21270;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Towards Size-Independent Generalization Bounds for Deep Operator Nets. (arXiv:2205.11359v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.11359
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#25805;&#20316;&#22120;&#32593;&#32476;&#30340;&#27867;&#21270;&#30028;&#38480;&#38382;&#39064;&#65292;&#22312;&#19968;&#31867;DeepONets&#20013;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;Rademacher&#22797;&#26434;&#24230;&#30340;&#30028;&#38480;&#19981;&#20250;&#38543;&#32593;&#32476;&#23485;&#24230;&#25193;&#23637;&#32780;&#26126;&#30830;&#21464;&#21270;&#65292;&#24182;&#21033;&#29992;&#36825;&#20010;&#32467;&#26524;&#23637;&#31034;&#20102;&#22914;&#20309;&#36873;&#25321;Huber&#25439;&#22833;&#26469;&#33719;&#24471;&#19981;&#26126;&#30830;&#20381;&#36182;&#20110;&#32593;&#32476;&#22823;&#23567;&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26368;&#36817;&#30340;&#26102;&#26399;&#65292;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#20998;&#26512;&#29289;&#29702;&#31995;&#32479;&#26041;&#38754;&#21462;&#24471;&#20102;&#37325;&#35201;&#36827;&#23637;&#12290;&#22312;&#36825;&#20010;&#20027;&#39064;&#20013;&#29305;&#21035;&#27963;&#36291;&#30340;&#39046;&#22495;&#26159;"&#29289;&#29702;&#20449;&#24687;&#26426;&#22120;&#23398;&#20064;"&#65292;&#23427;&#19987;&#27880;&#20110;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#26469;&#25968;&#20540;&#27714;&#35299;&#24494;&#20998;&#26041;&#31243;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#25512;&#36827;&#22312;&#35757;&#32451;DeepONets&#26102;&#27979;&#37327;&#26679;&#26412;&#22806;&#35823;&#24046;&#30340;&#29702;&#35770; - &#36825;&#26159;&#35299;&#20915;PDE&#31995;&#32479;&#26368;&#36890;&#29992;&#30340;&#26041;&#27861;&#20043;&#19968;&#12290;&#39318;&#20808;&#65292;&#38024;&#23545;&#19968;&#31867;DeepONets&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;Rademacher&#22797;&#26434;&#24230;&#26377;&#19968;&#20010;&#30028;&#38480;&#65292;&#35813;&#30028;&#38480;&#19981;&#20250;&#26126;&#30830;&#22320;&#38543;&#30528;&#28041;&#21450;&#30340;&#32593;&#32476;&#23485;&#24230;&#25193;&#23637;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#21033;&#29992;&#36825;&#19968;&#32467;&#26524;&#26469;&#23637;&#31034;&#22914;&#20309;&#36873;&#25321;Huber&#25439;&#22833;&#65292;&#20351;&#24471;&#23545;&#20110;&#36825;&#20123;DeepONet&#31867;&#65292;&#33021;&#22815;&#33719;&#24471;&#19981;&#26126;&#30830;&#20381;&#36182;&#20110;&#32593;&#32476;&#22823;&#23567;&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#12290;&#25105;&#20204;&#25351;&#20986;&#65292;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#36866;&#29992;&#20110;&#20219;&#20309;&#30446;&#26631;&#26159;&#30001;DeepONets&#27714;&#35299;&#30340;PDE&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent times machine learning methods have made significant advances in becoming a useful tool for analyzing physical systems. A particularly active area in this theme has been "physics-informed machine learning" which focuses on using neural nets for numerically solving differential equations. In this work, we aim to advance the theory of measuring out-of-sample error while training DeepONets -- which is among the most versatile ways to solve PDE systems in one-shot.  Firstly, for a class of DeepONets, we prove a bound on their Rademacher complexity which does not explicitly scale with the width of the nets involved. Secondly, we use this to show how the Huber loss can be chosen so that for these DeepONet classes generalization error bounds can be obtained that have no explicit dependence on the size of the nets. We note that our theoretical results apply to any PDE being targeted to be solved by DeepONets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#36890;&#20449;&#22797;&#26434;&#24230;&#25512;&#23548;&#20986;&#20102;&#23545;&#20110;&#20869;&#23384;&#21463;&#38480;&#31639;&#27861;&#22312;&#24352;&#37327;&#20027;&#25104;&#20998;&#20998;&#26512;&#20013;&#30340;&#35745;&#31639;&#19979;&#30028;&#65292;&#24182;&#19988;&#25351;&#23450;&#20102;&#35299;&#20915;&#35813;&#38382;&#39064;&#30340;&#31639;&#27861;&#24517;&#39035;&#22312;&#25968;&#25454;&#26679;&#26412;&#32463;&#36807;&#27425;&#25968;&#12289;&#26679;&#26412;&#22823;&#23567;&#21644;&#25152;&#38656;&#20869;&#23384;&#20043;&#38388;&#36827;&#34892;&#26435;&#34913;&#12290;&#36825;&#20123;&#19979;&#30028;&#26263;&#31034;&#20102;&#35768;&#22810;&#24120;&#29992;&#31639;&#27861;&#22312;&#26679;&#26412;&#22823;&#23567;&#19981;&#22815;&#22823;&#26102;&#38656;&#35201;&#26356;&#22810;&#30340;&#36845;&#20195;&#27425;&#25968;&#12290;</title><link>http://arxiv.org/abs/2204.07526</link><description>&lt;p&gt;
&#22312;&#24352;&#37327;&#20027;&#25104;&#20998;&#20998;&#26512;&#21644;&#30456;&#20851;&#38382;&#39064;&#20013;&#30340;&#32479;&#35745;&#35745;&#31639;&#26435;&#34913;&#65306;&#36890;&#36807;&#36890;&#20449;&#22797;&#26434;&#24230;
&lt;/p&gt;
&lt;p&gt;
Statistical-Computational Trade-offs in Tensor PCA and Related Problems via Communication Complexity. (arXiv:2204.07526v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.07526
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#36890;&#20449;&#22797;&#26434;&#24230;&#25512;&#23548;&#20986;&#20102;&#23545;&#20110;&#20869;&#23384;&#21463;&#38480;&#31639;&#27861;&#22312;&#24352;&#37327;&#20027;&#25104;&#20998;&#20998;&#26512;&#20013;&#30340;&#35745;&#31639;&#19979;&#30028;&#65292;&#24182;&#19988;&#25351;&#23450;&#20102;&#35299;&#20915;&#35813;&#38382;&#39064;&#30340;&#31639;&#27861;&#24517;&#39035;&#22312;&#25968;&#25454;&#26679;&#26412;&#32463;&#36807;&#27425;&#25968;&#12289;&#26679;&#26412;&#22823;&#23567;&#21644;&#25152;&#38656;&#20869;&#23384;&#20043;&#38388;&#36827;&#34892;&#26435;&#34913;&#12290;&#36825;&#20123;&#19979;&#30028;&#26263;&#31034;&#20102;&#35768;&#22810;&#24120;&#29992;&#31639;&#27861;&#22312;&#26679;&#26412;&#22823;&#23567;&#19981;&#22815;&#22823;&#26102;&#38656;&#35201;&#26356;&#22810;&#30340;&#36845;&#20195;&#27425;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24352;&#37327;&#20027;&#25104;&#20998;&#20998;&#26512;&#26159;Montanari&#21644;Richard&#24341;&#20837;&#30340;&#19968;&#31181;&#39118;&#26684;&#21270;&#32479;&#35745;&#25512;&#26029;&#38382;&#39064;&#65292;&#29992;&#20110;&#30740;&#31350;&#20174;&#39640;&#38454;&#30697;&#24352;&#37327;&#20013;&#20272;&#35745;&#26410;&#30693;&#21442;&#25968;&#30340;&#35745;&#31639;&#38590;&#24230;&#12290;&#19982;&#20854;&#30697;&#38453;&#23545;&#24212;&#38382;&#39064;&#19981;&#21516;&#65292;&#24352;&#37327;&#20027;&#25104;&#20998;&#20998;&#26512;&#23637;&#29616;&#20102;&#19968;&#31181;&#32479;&#35745;&#35745;&#31639;&#24046;&#36317;&#65292;&#21363;&#22312;&#26679;&#26412;&#22823;&#23567;&#33539;&#22260;&#20869;&#65292;&#38382;&#39064;&#22312;&#20449;&#24687;&#29702;&#35770;&#19978;&#21487;&#35299;&#65292;&#20294;&#34987;&#35748;&#20026;&#22312;&#35745;&#31639;&#19978;&#36739;&#22256;&#38590;&#12290;&#26412;&#25991;&#21033;&#29992;&#36890;&#20449;&#22797;&#26434;&#24230;&#25512;&#23548;&#20986;&#20102;&#20869;&#23384;&#21463;&#38480;&#31639;&#27861;&#22312;&#24352;&#37327;&#20027;&#25104;&#20998;&#20998;&#26512;&#20013;&#30340;&#35745;&#31639;&#19979;&#30028;&#12290;&#36825;&#20123;&#19979;&#30028;&#25351;&#23450;&#20102;&#25104;&#21151;&#35299;&#20915;&#24352;&#37327;&#20027;&#25104;&#20998;&#20998;&#26512;&#30340;&#20219;&#20309;&#31639;&#27861;&#22312;&#25968;&#25454;&#26679;&#26412;&#32463;&#36807;&#27425;&#25968;&#12289;&#26679;&#26412;&#22823;&#23567;&#21644;&#25152;&#38656;&#20869;&#23384;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;&#23613;&#31649;&#19979;&#30028;&#19981;&#33021;&#25490;&#38500;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#65292;&#20294;&#23427;&#20204;&#24847;&#21619;&#30528;&#35768;&#22810;&#24120;&#29992;&#30340;&#31639;&#27861;&#65292;&#22914;&#26799;&#24230;&#19979;&#38477;&#21644;&#24130;&#36845;&#20195;&#26041;&#27861;&#65292;&#22312;&#26679;&#26412;&#22823;&#23567;&#19981;&#22815;&#22823;&#26102;&#24517;&#39035;&#26377;&#26356;&#39640;&#30340;&#36845;&#20195;&#27425;&#25968;&#12290;&#31867;&#20284;&#30340;&#19979;&#30028;&#36824;&#21487;&#20197;&#20351;&#29992;&#36890;&#20449;&#22797;&#26434;&#24230;&#33719;&#24471;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tensor PCA is a stylized statistical inference problem introduced by Montanari and Richard to study the computational difficulty of estimating an unknown parameter from higher-order moment tensors. Unlike its matrix counterpart, Tensor PCA exhibits a statistical-computational gap, i.e., a sample size regime where the problem is information-theoretically solvable but conjectured to be computationally hard. This paper derives computational lower bounds on the run-time of memory bounded algorithms for Tensor PCA using communication complexity. These lower bounds specify a trade-off among the number of passes through the data sample, the sample size, and the memory required by any algorithm that successfully solves Tensor PCA. While the lower bounds do not rule out polynomial-time algorithms, they do imply that many commonly-used algorithms, such as gradient descent and power method, must have a higher iteration count when the sample size is not large enough. Similar lower bounds are obtai
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;Concordance&#25351;&#25968;&#20998;&#35299;&#25104;&#20004;&#20010;&#37096;&#20998;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35780;&#20272;&#29983;&#23384;&#39044;&#27979;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#35813;&#20998;&#35299;&#26041;&#27861;&#21487;&#20197;&#36827;&#34892;&#26356;&#32454;&#31890;&#24230;&#30340;&#20998;&#26512;&#65292;&#25581;&#31034;&#19981;&#21516;&#39044;&#27979;&#26041;&#27861;&#20043;&#38388;&#30340;&#20248;&#21155;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#26356;&#22909;&#22320;&#21033;&#29992;&#20102;&#35266;&#27979;&#20107;&#20214;&#12290;</title><link>http://arxiv.org/abs/2203.00144</link><description>&lt;p&gt;
Concordance&#25351;&#25968;&#30340;&#20998;&#35299;: &#23545;&#29983;&#23384;&#39044;&#27979;&#27169;&#22411;&#28145;&#20837;&#29702;&#35299;&#30340;&#24230;&#37327;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
The Concordance Index decomposition: A measure for a deeper understanding of survival prediction models. (arXiv:2203.00144v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.00144
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;Concordance&#25351;&#25968;&#20998;&#35299;&#25104;&#20004;&#20010;&#37096;&#20998;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35780;&#20272;&#29983;&#23384;&#39044;&#27979;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#35813;&#20998;&#35299;&#26041;&#27861;&#21487;&#20197;&#36827;&#34892;&#26356;&#32454;&#31890;&#24230;&#30340;&#20998;&#26512;&#65292;&#25581;&#31034;&#19981;&#21516;&#39044;&#27979;&#26041;&#27861;&#20043;&#38388;&#30340;&#20248;&#21155;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#26356;&#22909;&#22320;&#21033;&#29992;&#20102;&#35266;&#27979;&#20107;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Concordance&#25351;&#25968;&#65288;C-index&#65289;&#26159;&#29983;&#23384;&#20998;&#26512;&#20013;&#24120;&#29992;&#30340;&#35780;&#20272;&#39044;&#27979;&#27169;&#22411;&#24615;&#33021;&#30340;&#25351;&#26631;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;C-index&#20998;&#35299;&#20026;&#20004;&#20010;&#25968;&#37327;&#30340;&#21152;&#26435;&#35843;&#21644;&#24179;&#22343;&#30340;&#26041;&#27861;&#65306;&#19968;&#20010;&#29992;&#20110;&#27604;&#36739;&#35266;&#27979;&#20107;&#20214;&#19982;&#20854;&#20182;&#35266;&#27979;&#20107;&#20214;&#30340;&#25490;&#24207;&#65292;&#21478;&#19968;&#20010;&#29992;&#20110;&#27604;&#36739;&#35266;&#27979;&#20107;&#20214;&#19982;&#34987;&#21098;&#36753;&#30340;&#24773;&#20917;&#30340;&#25490;&#24207;&#12290;&#36825;&#31181;&#20998;&#35299;&#26041;&#27861;&#21487;&#20197;&#23545;&#19981;&#21516;&#29983;&#23384;&#39044;&#27979;&#26041;&#27861;&#20043;&#38388;&#30340;&#20248;&#21155;&#36827;&#34892;&#26356;&#32454;&#31890;&#24230;&#30340;&#20998;&#26512;&#12290;&#36890;&#36807;&#19982;&#32463;&#20856;&#27169;&#22411;&#21644;&#26368;&#20808;&#36827;&#26041;&#27861;&#30340;&#22522;&#20934;&#27604;&#36739;&#65292;&#20197;&#21450;&#26412;&#25991;&#25552;&#20986;&#30340;&#26032;&#30340;&#21464;&#20998;&#29983;&#25104;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#65288;SurVED&#65289;&#65292;&#23637;&#31034;&#20102;&#35813;&#20998;&#35299;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#12290;&#20351;&#29992;&#22235;&#20010;&#20844;&#24320;&#21487;&#29992;&#30340;&#20855;&#26377;&#19981;&#21516;&#21098;&#36753;&#27700;&#24179;&#30340;&#25968;&#25454;&#38598;&#35780;&#20272;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#36890;&#36807;C-index&#20998;&#35299;&#21644;&#21512;&#25104;&#21098;&#36753;&#65292;&#20998;&#26512;&#32467;&#26524;&#26174;&#31034;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#26356;&#22909;&#22320;&#21033;&#29992;&#20102;&#35266;&#27979;&#20107;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Concordance Index (C-index) is a commonly used metric in Survival Analysis for evaluating the performance of a prediction model. In this paper, we propose a decomposition of the C-index into a weighted harmonic mean of two quantities: one for ranking observed events versus other observed events, and the other for ranking observed events versus censored cases. This decomposition enables a finer-grained analysis of the relative strengths and weaknesses between different survival prediction methods. The usefulness of this decomposition is demonstrated through benchmark comparisons against classical models and state-of-the-art methods, together with the new variational generative neural-network-based method (SurVED) proposed in this paper. The performance of the models is assessed using four publicly available datasets with varying levels of censoring. Using the C-index decomposition and synthetic censoring, the analysis shows that deep learning models utilize the observed events more 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#39640;&#32500;&#32972;&#26223;&#19979;&#36827;&#34892;&#27169;&#25311;&#39532;&#23572;&#21487;&#22827;&#38543;&#26426;&#22330;&#32479;&#35745;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#19968;&#33268;&#24615;&#65292;&#24182;&#26500;&#24314;&#20102;&#20004;&#31181;&#35823;&#21457;&#29616;&#29575;&#25511;&#21046;&#31243;&#24207;&#12290;</title><link>http://arxiv.org/abs/2202.05612</link><description>&lt;p&gt;
&#39640;&#32500;&#25512;&#26029;&#19982;&#27169;&#25311;&#39532;&#23572;&#21487;&#22827;&#38543;&#26426;&#22330;&#30340;FDR&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
High-dimensional Inference and FDR Control for Simulated Markov Random Fields. (arXiv:2202.05612v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.05612
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#39640;&#32500;&#32972;&#26223;&#19979;&#36827;&#34892;&#27169;&#25311;&#39532;&#23572;&#21487;&#22827;&#38543;&#26426;&#22330;&#32479;&#35745;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#19968;&#33268;&#24615;&#65292;&#24182;&#26500;&#24314;&#20102;&#20004;&#31181;&#35823;&#21457;&#29616;&#29575;&#25511;&#21046;&#31243;&#24207;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21508;&#31181;&#31185;&#23398;&#39046;&#22495;&#20013;&#65292;&#30830;&#23450;&#19982;&#21709;&#24212;&#21464;&#37327;&#30456;&#20851;&#30340;&#37325;&#35201;&#29305;&#24449;&#26159;&#19968;&#39033;&#22522;&#26412;&#20219;&#21153;&#12290;&#26412;&#25991;&#25506;&#35752;&#39640;&#32500;&#32972;&#26223;&#19979;&#27169;&#25311;&#39532;&#23572;&#21487;&#22827;&#38543;&#26426;&#22330;&#30340;&#32479;&#35745;&#25512;&#26029;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#26497;&#22823;&#20284;&#28982;&#20272;&#35745;&#65288;MCMC-MLE&#65289;&#19982;&#24377;&#24615;&#32593;&#27491;&#21017;&#21270;&#30340;&#26041;&#27861;&#12290;&#22312;MCMC&#26041;&#27861;&#30340;&#28201;&#21644;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#30340;&#32602;&#27454;MCMC-MLE&#26041;&#27861;&#23454;&#29616;&#20102;$\ell_{1}$&#19968;&#33268;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21435;&#30456;&#20851;&#30340;&#24471;&#20998;&#26816;&#39564;&#65292;&#30830;&#23450;&#20854;&#28176;&#36817;&#27491;&#24577;&#24615;&#21644;&#19968;&#27493;&#20272;&#35745;&#37327;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#65292;&#20197;&#21450;&#30456;&#24212;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22522;&#20110;p&#20540;&#21644;e&#20540;&#30340;&#28176;&#36817;&#34892;&#20026;&#26500;&#24314;&#20102;&#20004;&#31181;&#35823;&#21457;&#29616;&#29575;&#25511;&#21046;&#31243;&#24207;&#12290;&#20840;&#38754;&#30340;&#25968;&#20540;&#27169;&#25311;&#39564;&#35777;&#20102;&#25152;&#25552;&#26041;&#27861;&#30340;&#29702;&#35770;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Identifying important features linked to a response variable is a fundamental task in various scientific domains. This article explores statistical inference for simulated Markov random fields in high-dimensional settings. We introduce a methodology based on Markov Chain Monte Carlo Maximum Likelihood Estimation (MCMC-MLE) with Elastic-net regularization. Under mild conditions on the MCMC method, our penalized MCMC-MLE method achieves $\ell_{1}$-consistency. We propose a decorrelated score test, establishing both its asymptotic normality and that of a one-step estimator, along with the associated confidence interval. Furthermore, we construct two false discovery rate control procedures via the asymptotic behaviors for both p-values and e-values. Comprehensive numerical simulations confirm the theoretical validity of the proposed methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#26102;&#38388;&#24207;&#21015;&#22266;&#26377;&#23545;&#31216;&#24615;&#26500;&#24314;&#30340;&#23567;&#27874;&#32593;&#32476;&#65292;&#20854;&#34920;&#29616;&#20986;&#23884;&#22871;&#30340;&#38750;&#32447;&#24615;&#23567;&#27874;&#26679;&#30340;&#26102;&#39057;&#21464;&#25442;&#65292;&#23454;&#39564;&#35777;&#26126;&#20854;&#22312;&#21407;&#22987;&#27874;&#24418;&#19978;&#20248;&#20110;&#20256;&#32479;&#30340;CNN&#12290;</title><link>http://arxiv.org/abs/2006.05259</link><description>&lt;p&gt;
Wavelet Networks: &#20174;&#21407;&#22987;&#26102;&#38388;&#24207;&#21015;&#23398;&#20064;&#23610;&#24230;&#24179;&#31227;&#31561;&#21464;&#24615;&#30340;&#23398;&#20064;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Wavelet Networks: Scale-Translation Equivariant Learning From Raw Time-Series. (arXiv:2006.05259v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2006.05259
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#26102;&#38388;&#24207;&#21015;&#22266;&#26377;&#23545;&#31216;&#24615;&#26500;&#24314;&#30340;&#23567;&#27874;&#32593;&#32476;&#65292;&#20854;&#34920;&#29616;&#20986;&#23884;&#22871;&#30340;&#38750;&#32447;&#24615;&#23567;&#27874;&#26679;&#30340;&#26102;&#39057;&#21464;&#25442;&#65292;&#23454;&#39564;&#35777;&#26126;&#20854;&#22312;&#21407;&#22987;&#27874;&#24418;&#19978;&#20248;&#20110;&#20256;&#32479;&#30340;CNN&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;&#29305;&#23450;&#25968;&#25454;&#39046;&#22495;&#20013;&#22266;&#26377;&#30340;&#23545;&#31216;&#24615;&#26500;&#24314;&#31561;&#21464;&#24615;&#31070;&#32463;&#32593;&#32476;&#65292;&#21487;&#26174;&#33879;&#25552;&#39640;&#25968;&#25454;&#25928;&#29575;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#30740;&#31350;&#38598;&#20013;&#22312;&#24179;&#38754;&#21644;&#20307;&#31215;&#25968;&#25454;&#20013;&#20135;&#29983;&#30340;&#23545;&#31216;&#24615;&#19978;&#65292;&#32780;&#25226;&#19968;&#20010;&#20851;&#38190;&#30340;&#25968;&#25454;&#28304;&#22522;&#26412;&#26410;&#24320;&#21457;&#65306;&#26102;&#38388;&#24207;&#21015;&#12290;&#26412;&#25991;&#36890;&#36807;&#21033;&#29992;&#26102;&#38388;&#24207;&#21015;&#30340;&#22266;&#26377;&#23545;&#31216;&#24615;&#26469;&#26500;&#24314;&#31561;&#21464;&#24615;&#31070;&#32463;&#32593;&#32476;&#65292;&#22635;&#34917;&#20102;&#36825;&#19968;&#31354;&#30333;&#12290;&#25105;&#20204;&#30830;&#35748;&#20102;&#20004;&#20010;&#26680;&#24515;&#23545;&#31216;&#24615;&#65306;&#23610;&#24230;&#21644;&#24179;&#31227;&#65292;&#24182;&#26500;&#24314;&#20102;&#36866;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#23398;&#20064;&#30340;&#23610;&#24230;&#24179;&#31227;&#31561;&#21464;&#24615;&#31070;&#32463;&#32593;&#32476;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#25105;&#20204;&#21457;&#29616;&#23610;&#24230;&#24179;&#31227;&#31561;&#21464;&#24615;&#26144;&#23556;&#19982;&#23567;&#27874;&#21464;&#25442;&#20855;&#26377;&#24456;&#24378;&#30340;&#30456;&#20284;&#24615;&#12290;&#21463;&#21040;&#36825;&#31181;&#30456;&#20284;&#24615;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#32593;&#32476;&#31216;&#20026;&#23567;&#27874;&#32593;&#32476;&#65292;&#24182;&#23637;&#31034;&#23427;&#20204;&#25191;&#34892;&#23884;&#22871;&#30340;&#38750;&#32447;&#24615;&#23567;&#27874;&#26679;&#30340;&#26102;&#39057;&#21464;&#25442;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#23567;&#27874;&#32593;&#32476;&#22312;&#21407;&#22987;&#27874;&#24418;&#19978;&#20248;&#20110;&#20256;&#32479;&#30340;CNN&#12290;
&lt;/p&gt;
&lt;p&gt;
Leveraging the symmetries inherent to specific data domains for the construction of equivariant neural networks has lead to remarkable improvements in terms of data efficiency and generalization. However, most existing research focuses on symmetries arising from planar and volumetric data, leaving a crucial data source largely underexplored: time-series. In this work, we fill this gap by leveraging the symmetries inherent to time-series for the construction of equivariant neural network. We identify two core symmetries: *scale and translation*, and construct scale-translation equivariant neural networks for time-series learning. Intriguingly, we find that scale-translation equivariant mappings share strong resemblance with the wavelet transform. Inspired by this resemblance, we term our networks Wavelet Networks, and show that they perform nested non-linear wavelet-like time-frequency transforms. Empirical results show that Wavelet Networks outperform conventional CNNs on raw waveforms
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#24555;&#36895;&#36817;&#20284;&#35745;&#31639;&#21516;&#36136; Ising &#27169;&#22411;&#20013;&#37325;&#35201;&#37327;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#30340;&#34920;&#29616;&#22312;&#27169;&#25311;&#30740;&#31350;&#20013;&#34920;&#29616;&#33391;&#22909;&#65292;&#21487;&#29992;&#20110;&#22330;&#26223;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/1712.02195</link><description>&lt;p&gt;
&#29992;&#20110;&#22330;&#26223;&#20998;&#26512;&#30340;&#21516;&#36136; Ising &#27169;&#22411;&#30340;&#24555;&#36895;&#36817;&#20284;&#35745;&#31639;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Fast approximations in the homogeneous Ising model for use in scene analysis. (arXiv:1712.02195v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1712.02195
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#24555;&#36895;&#36817;&#20284;&#35745;&#31639;&#21516;&#36136; Ising &#27169;&#22411;&#20013;&#37325;&#35201;&#37327;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#30340;&#34920;&#29616;&#22312;&#27169;&#25311;&#30740;&#31350;&#20013;&#34920;&#29616;&#33391;&#22909;&#65292;&#21487;&#29992;&#20110;&#22330;&#26223;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Ising &#27169;&#22411;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#37117;&#24456;&#37325;&#35201;&#65292;&#20294;&#20854;&#24402;&#19968;&#21270;&#24120;&#25968;&#12289;&#27963;&#21160;&#39030;&#28857;&#25968;&#30340;&#24179;&#22343;&#20540;&#21644;&#33258;&#26059;&#30456;&#20114;&#20316;&#29992;&#30340;&#22343;&#20540;&#38590;&#20197;&#35745;&#31639;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#20934;&#30830;&#30340;&#36817;&#20284;&#20540;&#65292;&#20351;&#24471;&#22312;&#21516;&#36136;&#24773;&#20917;&#19979;&#21487;&#20197;&#25968;&#20540;&#35745;&#31639;&#36825;&#20123;&#37327;&#12290;&#27169;&#25311;&#30740;&#31350;&#34920;&#26126;&#65292;&#19982;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#24615;&#33021;&#33391;&#22909;&#65292;&#19988;&#25152;&#38656;&#26102;&#38388;&#21482;&#26159;&#37027;&#20123;&#38543;&#26426;&#26041;&#27861;&#30340;&#19968;&#23567;&#37096;&#20998;&#12290;&#25105;&#20204;&#30340;&#36817;&#20284;&#20540;&#22312;&#25191;&#34892;&#21151;&#33021;&#30913;&#20849;&#25391;&#28608;&#27963;&#26816;&#27979;&#23454;&#39564;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#20197;&#21450;&#26893;&#29289;&#29983;&#20135;&#20013;&#24180;&#22686;&#37327;&#31354;&#38388;&#22270;&#26696;&#30340;&#21508;&#21521;&#24322;&#24615;&#30340;&#20284;&#28982;&#27604;&#26816;&#39564;&#20013;&#24471;&#21040;&#20102;&#20307;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Ising model is important in statistical modeling and inference in many applications, however its normalizing constant, mean number of active vertices and mean spin interaction are intractable to compute. We provide accurate approximations that make it possible to numerically calculate these quantities in the homogeneous case. Simulation studies indicate good performance when compared to Markov Chain Monte Carlo methods and at a tiny fraction of the time taken by those stochastic approaches. The value of our approximations is illustrated in performing Bayesian inference in a functional Magnetic Resonance Imaging activation detection experiment, and also in likelihood ratio testing for anisotropy in the spatial patterns of yearly increases in pistachio tree yields.
&lt;/p&gt;</description></item></channel></rss>