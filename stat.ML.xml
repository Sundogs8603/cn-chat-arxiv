<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20351;&#29992;&#31614;&#21517;&#26465;&#30721;&#26469;&#31283;&#23450;&#21521;&#37327;&#21270;&#22810;&#21442;&#25968;&#25345;&#20037;&#21516;&#35843;&#65292;&#23558;&#22810;&#21442;&#25968;&#25345;&#20037;&#21516;&#35843;&#30340;&#20016;&#23500;&#20449;&#24687;&#21644;&#31283;&#23450;&#21521;&#37327;&#21270;&#30340;&#20248;&#21183;&#30456;&#32467;&#21512;&#12290;</title><link>http://arxiv.org/abs/2306.03801</link><description>&lt;p&gt;
&#31614;&#21517;&#26465;&#30721;&#20316;&#20026;&#24230;&#37327;&#30340;&#22810;&#21442;&#25968;&#25345;&#20037;&#21516;&#35843;&#30340;&#31283;&#23450;&#21521;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Stable Vectorization of Multiparameter Persistent Homology using Signed Barcodes as Measures. (arXiv:2306.03801v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03801
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20351;&#29992;&#31614;&#21517;&#26465;&#30721;&#26469;&#31283;&#23450;&#21521;&#37327;&#21270;&#22810;&#21442;&#25968;&#25345;&#20037;&#21516;&#35843;&#65292;&#23558;&#22810;&#21442;&#25968;&#25345;&#20037;&#21516;&#35843;&#30340;&#20016;&#23500;&#20449;&#24687;&#21644;&#31283;&#23450;&#21521;&#37327;&#21270;&#30340;&#20248;&#21183;&#30456;&#32467;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25345;&#20037;&#21516;&#35843;&#65288;PH&#65289;&#25552;&#20379;&#20102;&#20960;&#20309;&#25968;&#25454;&#65288;&#20363;&#22914;&#21152;&#26435;&#22270;&#65289;&#30340;&#25299;&#25169;&#25551;&#36848;&#31526;&#65292;&#23427;&#20204;&#26159;&#21487;&#35299;&#37322;&#30340;&#65292;&#23545;&#25200;&#21160;&#31283;&#23450;&#65292;&#24182;&#20855;&#26377;&#35832;&#22914;&#37325;&#26631;&#35760;&#31561;&#19981;&#21464;&#24615;&#12290;&#22823;&#22810;&#25968;PH&#24212;&#29992;&#20851;&#27880;&#19968;&#21442;&#25968;&#24773;&#20917;&#8212;&#8212;&#25551;&#36848;&#31526;&#24635;&#32467;&#25968;&#25454;&#30340;&#25299;&#25169;&#38543;&#30528;&#21333;&#20010;&#24863;&#20852;&#36259;&#22240;&#32032;&#30340;&#28388;&#27874;&#32780;&#21457;&#29983;&#21464;&#21270;&#65307;&#29616;&#22312;&#65292;&#26377;&#21508;&#31181;&#26041;&#27861;&#20351;&#24471;&#19968;&#21442;&#25968;PH&#25551;&#36848;&#31526;&#22312;&#25968;&#25454;&#31185;&#23398;&#20013;&#24471;&#21040;&#24212;&#29992;&#65292;&#24182;&#19988;&#20381;&#36182;&#20110;&#23558;&#36825;&#20123;&#25551;&#36848;&#31526;&#31283;&#23450;&#21521;&#37327;&#21270;&#20026;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#30340;&#20803;&#32032;&#12290;&#34429;&#28982;&#30001;&#20960;&#20010;&#24863;&#20852;&#36259;&#22240;&#32032;&#36807;&#28388;&#30340;&#25968;&#25454;&#30340;&#22810;&#21442;&#25968;PH&#65288;MPH&#65289;&#32534;&#30721;&#27604;&#20854;&#19968;&#21442;&#25968;&#21516;&#22411;&#30340;&#20449;&#24687;&#26356;&#20016;&#23500;&#65292;&#20294;&#36804;&#20170;&#20026;&#27490;&#65292;MPH&#25551;&#36848;&#31526;&#30340;&#31283;&#23450;&#24615;&#32467;&#26524;&#30340;&#31232;&#32570;&#24615;&#24050;&#32463;&#38480;&#21046;&#20102;MPH&#30340;&#31283;&#23450;&#21521;&#37327;&#21270;&#30340;&#21487;&#29992;&#36873;&#39033;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#36890;&#36807;&#23637;&#31034;&#22914;&#20309;&#35299;&#37322;&#31614;&#21517;&#26465;&#30721;&#26469;&#38598;&#32467;&#20004;&#26041;&#38754;&#30340;&#20248;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Persistent homology (PH) provides topological descriptors for geometric data, such as weighted graphs, which are interpretable, stable to perturbations, and invariant under, e.g., relabeling. Most applications of PH focus on the one-parameter case -- where the descriptors summarize the changes in topology of data as it is filtered by a single quantity of interest -- and there is now a wide array of methods enabling the use of one-parameter PH descriptors in data science, which rely on the stable vectorization of these descriptors as elements of a Hilbert space. Although the multiparameter PH (MPH) of data that is filtered by several quantities of interest encodes much richer information than its one-parameter counterpart, the scarceness of stability results for MPH descriptors has so far limited the available options for the stable vectorization of MPH. In this paper, we aim to bring together the best of both worlds by showing how the interpretation of signed barcodes -- a recent famil
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#27604;&#36739;&#21644;&#23545;&#27604;&#20102;&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;&#21644;&#26368;&#22823;&#21518;&#39564;&#20272;&#35745;&#30340;&#39118;&#38505;&#65292;&#37325;&#28857;&#20851;&#27880;&#20102;&#27169;&#22411;&#32500;&#24230;&#22686;&#38271;&#36895;&#24230;&#22823;&#20110;&#20219;&#20309;&#24120;&#25968;&#20493;&#30340;&#26679;&#26412;&#25968;&#26102;&#23427;&#20204;&#20043;&#38388;&#30340;&#28176;&#36817;&#19968;&#33268;&#24615;&#12290;&#25968;&#20540;&#27169;&#25311;&#34920;&#26126;&#36825;&#20004;&#20010;&#25968;&#37327;&#22312;&#38480;&#23450;&#32500;&#24230;&#19978;&#20855;&#26377;&#39640;&#26031;&#27874;&#21160;&#65292;&#24182;&#34920;&#29616;&#20986;&#30456;&#20284;&#30340;&#23646;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.03783</link><description>&lt;p&gt;
&#38543;&#26426;&#29305;&#24449;&#22238;&#24402;&#20013;&#36125;&#21494;&#26031;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#28176;&#36817;&#24615;
&lt;/p&gt;
&lt;p&gt;
Asymptotics of Bayesian Uncertainty Estimation in Random Features Regression. (arXiv:2306.03783v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03783
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#27604;&#36739;&#21644;&#23545;&#27604;&#20102;&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;&#21644;&#26368;&#22823;&#21518;&#39564;&#20272;&#35745;&#30340;&#39118;&#38505;&#65292;&#37325;&#28857;&#20851;&#27880;&#20102;&#27169;&#22411;&#32500;&#24230;&#22686;&#38271;&#36895;&#24230;&#22823;&#20110;&#20219;&#20309;&#24120;&#25968;&#20493;&#30340;&#26679;&#26412;&#25968;&#26102;&#23427;&#20204;&#20043;&#38388;&#30340;&#28176;&#36817;&#19968;&#33268;&#24615;&#12290;&#25968;&#20540;&#27169;&#25311;&#34920;&#26126;&#36825;&#20004;&#20010;&#25968;&#37327;&#22312;&#38480;&#23450;&#32500;&#24230;&#19978;&#20855;&#26377;&#39640;&#26031;&#27874;&#21160;&#65292;&#24182;&#34920;&#29616;&#20986;&#30456;&#20284;&#30340;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#27604;&#36739;&#21644;&#23545;&#27604;&#20102;&#36125;&#21494;&#26031;&#22238;&#24402;&#27169;&#22411;&#20013;&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;&#21644;&#26368;&#22823;&#21518;&#39564;&#20272;&#35745;&#65288;MAP&#65289;&#39118;&#38505;&#22312;&#36229;&#21442;&#25968;&#21270;&#21306;&#22495;&#20013;&#30340;&#34892;&#20026;&#12290;&#25105;&#20204;&#23558;&#37325;&#28857;&#20851;&#27880;&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;&#65288;&#36125;&#21494;&#26031;&#27169;&#22411;&#24179;&#22343;&#65289;&#30340;&#26041;&#24046;&#65292;&#24182;&#23558;&#20854;&#28176;&#36817;&#24615;&#19982;MAP&#20272;&#35745;&#22120;&#30340;&#39118;&#38505;&#36827;&#34892;&#27604;&#36739;&#12290;&#24403;&#27169;&#22411;&#32500;&#24230;&#22686;&#38271;&#36895;&#24230;&#22823;&#20110;&#20219;&#20309;&#24120;&#25968;&#20493;&#30340;&#26679;&#26412;&#25968;&#26102;&#65292;&#23427;&#20204;&#20043;&#38388;&#30340;&#28176;&#36817;&#19968;&#33268;&#24615;&#21463;&#21040;&#20449;&#22122;&#27604;&#30340;&#30456;&#21464;&#30340;&#25511;&#21046;&#12290;&#24403;&#26679;&#26412;&#25968;&#22686;&#38271;&#36895;&#24230;&#22823;&#20110;&#20219;&#20309;&#24120;&#25968;&#20493;&#30340;&#27169;&#22411;&#32500;&#24230;&#26102;&#65292;&#23427;&#20204;&#20063;&#20250;&#28176;&#36817;&#19968;&#33268;&#12290;&#25968;&#20540;&#27169;&#25311;&#35828;&#26126;&#20102;&#20004;&#20010;&#25968;&#37327;&#30340;&#26377;&#38480;&#32500;&#20998;&#24067;&#24615;&#36136;&#12290;&#25105;&#20204;&#25512;&#27979;&#23427;&#20204;&#20855;&#26377;&#39640;&#26031;&#27874;&#21160;&#65292;&#24182;&#34920;&#29616;&#20986;&#19982;&#20043;&#21069;&#22312;&#39640;&#26031;&#24207;&#21015;&#27169;&#22411;&#20013;&#21457;&#29616;&#30340;&#31867;&#20284;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we compare and contrast the behavior of the posterior predictive distribution to the risk of the maximum a posteriori estimator for the random features regression model in the overparameterized regime. We will focus on the variance of the posterior predictive distribution (Bayesian model average) and compare its asymptotics to that of the risk of the MAP estimator. In the regime where the model dimensions grow faster than any constant multiple of the number of samples, asymptotic agreement between these two quantities is governed by the phase transition in the signal-to-noise ratio. They also asymptotically agree with each other when the number of samples grow faster than any constant multiple of model dimensions. Numerical simulations illustrate finer distributional properties of the two quantities for finite dimensions. We conjecture they have Gaussian fluctuations and exhibit similar properties as found by previous authors in a Gaussian sequence model, which is of inde
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#35889;&#29305;&#24449;&#30340;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#26469;&#35299;&#20915;&#22270;&#20998;&#31867;&#38382;&#39064;&#65292;&#21363;&#20351;&#26159;&#22522;&#20110;&#33410;&#28857;&#29305;&#24449;&#20449;&#21495;&#22312;&#22270;&#35889;&#19978;&#33021;&#37327;&#20998;&#24067;&#36825;&#26679;&#31616;&#21333;&#30340;&#26041;&#27861;&#20063;&#26377;&#31454;&#20105;&#21147;&#30340;&#34920;&#29616;&#12290;&#21516;&#26102;&#65292;&#26356;&#22797;&#26434;&#30340;&#21464;&#20307;&#20351;&#29992;&#35889;&#22270;&#23567;&#27874;&#28388;&#27874;&#22120;&#21487;&#20197;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#33719;&#24471;&#25913;&#36827;&#65292;&#32780;&#20004;&#31181;&#27169;&#22411;&#37117;&#33021;&#22815;&#20135;&#29983;&#35745;&#31639;&#20272;&#35745;&#65292;&#33021;&#22815;&#21487;&#38752;&#22320;&#20570;&#20986;&#20915;&#31574;&#12290;</title><link>http://arxiv.org/abs/2306.03770</link><description>&lt;p&gt;
&#36890;&#36807;&#35889;&#29305;&#24449;&#30340;&#39640;&#26031;&#36807;&#31243;&#36827;&#34892;&#22270;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Graph Classification Gaussian Processes via Spectral Features. (arXiv:2306.03770v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03770
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#35889;&#29305;&#24449;&#30340;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#26469;&#35299;&#20915;&#22270;&#20998;&#31867;&#38382;&#39064;&#65292;&#21363;&#20351;&#26159;&#22522;&#20110;&#33410;&#28857;&#29305;&#24449;&#20449;&#21495;&#22312;&#22270;&#35889;&#19978;&#33021;&#37327;&#20998;&#24067;&#36825;&#26679;&#31616;&#21333;&#30340;&#26041;&#27861;&#20063;&#26377;&#31454;&#20105;&#21147;&#30340;&#34920;&#29616;&#12290;&#21516;&#26102;&#65292;&#26356;&#22797;&#26434;&#30340;&#21464;&#20307;&#20351;&#29992;&#35889;&#22270;&#23567;&#27874;&#28388;&#27874;&#22120;&#21487;&#20197;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#33719;&#24471;&#25913;&#36827;&#65292;&#32780;&#20004;&#31181;&#27169;&#22411;&#37117;&#33021;&#22815;&#20135;&#29983;&#35745;&#31639;&#20272;&#35745;&#65292;&#33021;&#22815;&#21487;&#38752;&#22320;&#20570;&#20986;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#20998;&#31867;&#26088;&#22312;&#26681;&#25454;&#20854;&#32467;&#26500;&#21644;&#33410;&#28857;&#23646;&#24615;&#23545;&#22270;&#36827;&#34892;&#20998;&#31867;&#12290;&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#22270;&#20449;&#21495;&#22788;&#29702;&#24037;&#20855;&#65292;&#36890;&#36807;&#24471;&#20986;&#35889;&#29305;&#24449;&#26469;&#35774;&#35745;&#20004;&#31181;&#21464;&#20307;&#30340;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#31532;&#19968;&#31181;&#21464;&#20307;&#20351;&#29992;&#22522;&#20110;&#33410;&#28857;&#29305;&#24449;&#20449;&#21495;&#22312;&#22270;&#35889;&#19978;&#33021;&#37327;&#20998;&#24067;&#30340;&#35889;&#29305;&#24449;&#12290;&#25105;&#20204;&#23637;&#31034;&#21363;&#20351;&#20351;&#29992;&#27809;&#26377;&#23398;&#20064;&#21442;&#25968;&#30340;&#22914;&#27492;&#31616;&#21333;&#30340;&#26041;&#27861;&#65292;&#20063;&#21487;&#20197;&#19982;&#24378;&#22823;&#30340;&#31070;&#32463;&#32593;&#32476;&#21644;&#22270;&#20869;&#26680;&#22522;&#32447;&#30456;&#27604;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#34920;&#29616;&#12290;&#31532;&#20108;&#31181;&#26356;&#22797;&#26434;&#30340;&#21464;&#20307;&#36890;&#36807;&#23398;&#20064;&#35889;&#22270;&#23567;&#27874;&#28388;&#27874;&#22120;&#26469;&#25429;&#25417;&#22270;&#20013;&#30340;&#22810;&#23610;&#24230;&#21644;&#23616;&#37096;&#27169;&#24335;&#65292;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#19978;&#33719;&#24471;&#20102;&#25913;&#36827;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20004;&#31181;&#27169;&#22411;&#37117;&#21487;&#20197;&#20135;&#29983;&#33391;&#22909;&#30340;&#35745;&#31639;&#20272;&#35745;&#65292;&#20174;&#32780;&#22522;&#20110;&#27169;&#22411;&#39044;&#27979;&#21487;&#38752;&#22320;&#20570;&#20986;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph classification aims to categorise graphs based on their structure and node attributes. In this work, we propose to tackle this task using tools from graph signal processing by deriving spectral features, which we then use to design two variants of Gaussian process models for graph classification. The first variant uses spectral features based on the distribution of energy of a node feature signal over the spectrum of the graph. We show that even such a simple approach, having no learned parameters, can yield competitive performance compared to strong neural network and graph kernel baselines. A second, more sophisticated variant is designed to capture multi-scale and localised patterns in the graph by learning spectral graph wavelet filters, obtaining improved performance on synthetic and real-world data sets. Finally, we show that both models produce well calibrated uncertainty estimates, enabling reliable decision making based on the model predictions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#38544;&#31169;&#20445;&#25252;&#23398;&#20064;&#33539;&#24335;&#65292;&#36890;&#36807;&#21152;&#23494;&#22270;&#20687;&#23454;&#29616;&#20154;&#31867;&#19981;&#21487;&#24863;&#30693;&#20294;&#26426;&#22120;&#21487;&#35782;&#21035;&#65292;&#24182;&#20351;&#29992;&#32463;&#36807;&#26368;&#23567;&#36866;&#37197;&#30340;&#35270;&#35273;&#36716;&#25442;&#22120;&#23436;&#25104;&#35745;&#31639;&#26426;&#35270;&#35273;&#20219;&#21153;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#20934;&#30830;&#24615;&#19982;&#31454;&#20105;&#26041;&#27861;&#30456;&#24403;&#12290;</title><link>http://arxiv.org/abs/2306.03679</link><description>&lt;p&gt;
&#20154;&#31867;&#19981;&#21487;&#24863;&#30693;&#12289;&#26426;&#22120;&#21487;&#35782;&#21035;&#30340;&#22270;&#20687;
&lt;/p&gt;
&lt;p&gt;
Human-imperceptible, Machine-recognizable Images. (arXiv:2306.03679v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03679
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#38544;&#31169;&#20445;&#25252;&#23398;&#20064;&#33539;&#24335;&#65292;&#36890;&#36807;&#21152;&#23494;&#22270;&#20687;&#23454;&#29616;&#20154;&#31867;&#19981;&#21487;&#24863;&#30693;&#20294;&#26426;&#22120;&#21487;&#35782;&#21035;&#65292;&#24182;&#20351;&#29992;&#32463;&#36807;&#26368;&#23567;&#36866;&#37197;&#30340;&#35270;&#35273;&#36716;&#25442;&#22120;&#23436;&#25104;&#35745;&#31639;&#26426;&#35270;&#35273;&#20219;&#21153;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#20934;&#30830;&#24615;&#19982;&#31454;&#20105;&#26041;&#27861;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#37327;&#19982;&#20154;&#31867;&#30456;&#20851;&#30340;&#25968;&#25454;&#34987;&#25910;&#38598;&#29992;&#20110;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#35745;&#31639;&#26426;&#35270;&#35273;&#20219;&#21153;&#12290;&#25105;&#20204;&#21457;&#29616;&#20102;&#19968;&#31181;&#20851;&#20110;&#36719;&#20214;&#24037;&#31243;&#24072;&#30340;&#37325;&#22823;&#20914;&#31361;&#65306;&#22312;&#26356;&#22909;&#22320;&#24320;&#21457;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#19982;&#36828;&#31163;&#25935;&#24863;&#35757;&#32451;&#25968;&#25454;&#20043;&#38388;&#23384;&#22312;&#19968;&#22823;&#30683;&#30462;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#38544;&#31169;&#20445;&#25252;&#23398;&#20064;&#33539;&#24335;&#65292;&#20854;&#20013;&#22270;&#20687;&#34987;&#21152;&#23494;&#25104;&#8220;&#20154;&#31867;&#19981;&#21487;&#24863;&#30693;&#65292;&#26426;&#22120;&#21487;&#35782;&#21035;&#8221;&#29366;&#24577;&#65292;&#36890;&#36807;&#20197;&#19979;&#20004;&#31181;&#21152;&#23494;&#31574;&#30053;&#20043;&#19968;&#26469;&#23454;&#29616;&#65306;(1) &#23558;&#22270;&#20687;&#38543;&#26426;&#27927;&#29260;&#25104;&#19968;&#32452;&#30456;&#31561;&#22823;&#23567;&#30340;&#23567;&#22359;&#65292;(2) &#23545;&#22270;&#20687;&#30340;&#23376;&#22359;&#36827;&#34892;&#28151;&#21512;&#12290;&#28982;&#21518;&#65292;&#23545;&#35270;&#35273;&#36716;&#25442;&#22120;&#36827;&#34892;&#26368;&#23567;&#30340;&#36866;&#37197;&#65292;&#20351;&#20854;&#33021;&#22815;&#23398;&#20064;&#21152;&#23494;&#22270;&#20687;&#30340;&#35745;&#31639;&#26426;&#35270;&#35273;&#20219;&#21153;&#65292;&#21253;&#25324;&#22270;&#20687;&#20998;&#31867;&#21644;&#30446;&#26631;&#26816;&#27979;&#12290;&#22312; ImageNet &#21644; COCO &#19978;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#23454;&#39564;&#65292;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#20934;&#30830;&#24615;&#26041;&#38754;&#19982;&#31454;&#20105;&#26041;&#27861;&#30456;&#24403;&#12290;&#35299;&#23494;&#21152;&#23494;&#22270;&#20687;&#38656;&#35201;&#35299;&#20915; NP &#38590;&#30340;&#25340;&#22270;&#38382;&#39064;&#25110;&#30149;&#24577;&#30340;&#21453;&#38382;&#39064;&#65292;&#36825;&#26159;&#32463;&#39564;&#35777;&#26126;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Massive human-related data is collected to train neural networks for computer vision tasks. A major conflict is exposed relating to software engineers between better developing AI systems and distancing from the sensitive training data. To reconcile this conflict, this paper proposes an efficient privacy-preserving learning paradigm, where images are first encrypted to become ``human-imperceptible, machine-recognizable'' via one of the two encryption strategies: (1) random shuffling to a set of equally-sized patches and (2) mixing-up sub-patches of the images. Then, minimal adaptations are made to vision transformer to enable it to learn on the encrypted images for vision tasks, including image classification and object detection. Extensive experiments on ImageNet and COCO show that the proposed paradigm achieves comparable accuracy with the competitive methods. Decrypting the encrypted images requires solving an NP-hard jigsaw puzzle or an ill-posed inverse problem, which is empirical
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23494;&#38598;&#39640;&#26031;&#21464;&#20998;&#26063;&#30340;&#26799;&#24230;&#20272;&#35745;&#22120;&#65292;&#22312;&#27492;&#22522;&#30784;&#19978;&#20351;&#29992;&#36817;&#31471;&#21644;&#25237;&#24433;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65292;&#25552;&#20379;&#20102;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#25910;&#25947;&#20110;&#36924;&#30495;&#25512;&#26029;&#38382;&#39064;&#30340;&#31532;&#19968;&#20010;&#20005;&#26684;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2306.03638</link><description>&lt;p&gt;
&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#30340;&#25910;&#25947;&#24615;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Provable convergence guarantees for black-box variational inference. (arXiv:2306.03638v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03638
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23494;&#38598;&#39640;&#26031;&#21464;&#20998;&#26063;&#30340;&#26799;&#24230;&#20272;&#35745;&#22120;&#65292;&#22312;&#27492;&#22522;&#30784;&#19978;&#20351;&#29992;&#36817;&#31471;&#21644;&#25237;&#24433;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65292;&#25552;&#20379;&#20102;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#25910;&#25947;&#20110;&#36924;&#30495;&#25512;&#26029;&#38382;&#39064;&#30340;&#31532;&#19968;&#20010;&#20005;&#26684;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#34987;&#24191;&#27867;&#24212;&#29992;&#65292;&#20294;&#27809;&#26377;&#35777;&#26126;&#20854;&#38543;&#26426;&#20248;&#21270;&#25104;&#21151;&#30340;&#35777;&#26126;&#12290;&#25105;&#20204;&#25552;&#20986;&#36825;&#26159;&#29616;&#26377;&#38543;&#26426;&#20248;&#21270;&#35777;&#26126;&#20013;&#30340;&#29702;&#35770;&#24046;&#36317;&#65292;&#21363;&#20855;&#26377;&#24322;&#24120;&#22122;&#22768;&#36793;&#30028;&#21644;&#22797;&#21512;&#38750;&#24179;&#28369;&#30446;&#26631;&#30340;&#26799;&#24230;&#20272;&#35745;&#22120;&#30340;&#25361;&#25112;&#12290;&#23545;&#20110;&#23494;&#38598;&#30340;&#39640;&#26031;&#21464;&#20998;&#26063;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#29616;&#26377;&#30340;&#22522;&#20110;&#20877;&#21442;&#25968;&#21270;&#30340;&#26799;&#24230;&#20272;&#35745;&#22120;&#28385;&#36275;&#20108;&#27425;&#22122;&#22768;&#30028;&#65292;&#24182;&#20026;&#20351;&#29992;&#35813;&#30028;&#38480;&#30340;&#36817;&#31471;&#21644;&#25237;&#24433;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#25552;&#20379;&#26032;&#30340;&#25910;&#25947;&#20445;&#35777;&#12290;&#36825;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#25910;&#25947;&#20110;&#36924;&#30495;&#25512;&#26029;&#38382;&#39064;&#30340;&#20005;&#26684;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
While black-box variational inference is widely used, there is no proof that its stochastic optimization succeeds. We suggest this is due to a theoretical gap in existing stochastic optimization proofs-namely the challenge of gradient estimators with unusual noise bounds, and a composite non-smooth objective. For dense Gaussian variational families, we observe that existing gradient estimators based on reparameterization satisfy a quadratic noise bound and give novel convergence guarantees for proximal and projected stochastic gradient descent using this bound. This provides the first rigorous guarantee that black-box variational inference converges for realistic inference problems.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20844;&#24179;&#19988;&#20581;&#22766;&#30340;&#24322;&#36136;&#27835;&#30103;&#25928;&#26524;&#30340;&#20272;&#35745;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#20844;&#24179;&#32422;&#26463;&#19979;&#38750;&#21442;&#25968;&#22320;&#20272;&#35745;&#65292;&#24182;&#21487;&#29992;&#20110;&#26435;&#34913;&#20844;&#24179;&#21644;&#26368;&#22823;&#31119;&#21033;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2306.03625</link><description>&lt;p&gt;
&#20844;&#24179;&#19988;&#20581;&#22766;&#30340;&#24322;&#36136;&#27835;&#30103;&#25928;&#26524;&#25919;&#31574;&#23398;&#20064;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Fair and Robust Estimation of Heterogeneous Treatment Effects for Policy Learning. (arXiv:2306.03625v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03625
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20844;&#24179;&#19988;&#20581;&#22766;&#30340;&#24322;&#36136;&#27835;&#30103;&#25928;&#26524;&#30340;&#20272;&#35745;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#20844;&#24179;&#32422;&#26463;&#19979;&#38750;&#21442;&#25968;&#22320;&#20272;&#35745;&#65292;&#24182;&#21487;&#29992;&#20110;&#26435;&#34913;&#20844;&#24179;&#21644;&#26368;&#22823;&#31119;&#21033;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#19988;&#36890;&#29992;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#20844;&#24179;&#32422;&#26463;&#26465;&#20214;&#19979;&#38750;&#21442;&#25968;&#20272;&#35745;&#24322;&#36136;&#27835;&#30103;&#25928;&#26524;&#12290;&#22312;&#26631;&#20934;&#27491;&#21017;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#24471;&#21040;&#30340;&#20272;&#35745;&#22120;&#20855;&#26377;&#21452;&#37325;&#20581;&#22766;&#24615;&#12290;&#25105;&#20204;&#21033;&#29992;&#27492;&#26694;&#26550;&#26469;&#34920;&#24449;&#20844;&#24179;&#21644;&#26368;&#20339;&#25919;&#31574;&#21487;&#23454;&#29616;&#30340;&#26368;&#22823;&#31119;&#21033;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;&#25105;&#20204;&#22312;&#27169;&#25311;&#30740;&#31350;&#20013;&#35780;&#20272;&#20102;&#35813;&#26041;&#27861;&#65292;&#24182;&#22312;&#19968;&#20010;&#30495;&#23454;&#19990;&#30028;&#30340;&#26696;&#20363;&#30740;&#31350;&#20013;&#36827;&#34892;&#20102;&#35828;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a simple and general framework for nonparametric estimation of heterogeneous treatment effects under fairness constraints. Under standard regularity conditions, we show that the resulting estimators possess the double robustness property. We use this framework to characterize the trade-off between fairness and the maximum welfare achievable by the optimal policy. We evaluate the methods in a simulation study and illustrate them in a real-world case study.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#32447;&#24615;&#32422;&#26463;&#21327;&#26041;&#24046;&#30697;&#38453;&#21464;&#25442;&#30340;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20272;&#35745;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#19968;&#20010;&#20984;&#38382;&#39064;&#65292;&#20801;&#35768;&#30456;&#23545;&#31616;&#21333;&#30340;&#28176;&#36817;&#24615;&#21644;&#26377;&#38480;&#26679;&#26412;&#20998;&#26512;&#12290;&#30740;&#31350;&#30340;&#37325;&#28857;&#26159;&#20851;&#20110;&#24314;&#27169;&#30456;&#20851;&#30697;&#38453;&#21644;&#31232;&#30095;&#24615;&#26041;&#38754;&#30340;&#20869;&#23481;&#12290;</title><link>http://arxiv.org/abs/2306.03590</link><description>&lt;p&gt;
&#29109;&#21327;&#26041;&#24046;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Entropic covariance models. (arXiv:2306.03590v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03590
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#32447;&#24615;&#32422;&#26463;&#21327;&#26041;&#24046;&#30697;&#38453;&#21464;&#25442;&#30340;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#20272;&#35745;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#19968;&#20010;&#20984;&#38382;&#39064;&#65292;&#20801;&#35768;&#30456;&#23545;&#31616;&#21333;&#30340;&#28176;&#36817;&#24615;&#21644;&#26377;&#38480;&#26679;&#26412;&#20998;&#26512;&#12290;&#30740;&#31350;&#30340;&#37325;&#28857;&#26159;&#20851;&#20110;&#24314;&#27169;&#30456;&#20851;&#30697;&#38453;&#21644;&#31232;&#30095;&#24615;&#26041;&#38754;&#30340;&#20869;&#23481;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#20013;&#65292;&#25214;&#21040;&#21512;&#36866;&#30340;&#27169;&#22411;&#21644;&#26377;&#25928;&#30340;&#20272;&#35745;&#26041;&#27861;&#26159;&#19968;&#39033;&#25361;&#25112;&#12290;&#25991;&#29486;&#20013;&#36890;&#24120;&#37319;&#29992;&#20004;&#31181;&#26041;&#27861;&#65292;&#19968;&#31181;&#26159;&#23545;&#21327;&#26041;&#24046;&#30697;&#38453;&#25110;&#20854;&#36870;&#26045;&#21152;&#32447;&#24615;&#32422;&#26463;&#65292;&#21478;&#19968;&#31181;&#26159;&#32771;&#34385;&#26045;&#21152;&#22312;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#30697;&#38453;&#23545;&#25968;&#19978;&#30340;&#32447;&#24615;&#32422;&#26463;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#32447;&#24615;&#32422;&#26463;&#21327;&#26041;&#24046;&#30697;&#38453;&#21464;&#25442;&#30340;&#26694;&#26550;&#65292;&#21253;&#25324;&#19978;&#36848;&#20363;&#23376;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#20272;&#35745;&#26041;&#27861;&#35299;&#20915;&#20102;&#19968;&#20010;&#20984;&#38382;&#39064;&#65292;&#24182;&#20135;&#29983;&#20102;&#19968;&#20010;M&#20272;&#35745;&#37327;&#65292;&#20801;&#35768;&#30456;&#23545;&#31616;&#21333;&#30340;&#28176;&#36817;&#24615;&#21644;&#26377;&#38480;&#26679;&#26412;&#20998;&#26512;&#12290;&#22312;&#24320;&#21457;&#20102;&#19968;&#33324;&#29702;&#35770;&#20043;&#21518;&#65292;&#25105;&#20204;&#38598;&#20013;&#22312;&#24314;&#27169;&#30456;&#20851;&#30697;&#38453;&#21644;&#31232;&#30095;&#24615;&#26041;&#38754;&#12290;&#25105;&#20204;&#30340;&#20960;&#20309;&#27934;&#23519;&#21147;&#20801;&#35768;&#25105;&#20204;&#25193;&#23637;&#21327;&#26041;&#24046;&#30697;&#38453;&#24314;&#27169;&#20013;&#30340;&#19968;&#20123;&#26368;&#26032;&#32467;&#26524;&#12290;&#36825;&#21253;&#25324;&#25552;&#20379;&#30456;&#20851;&#30697;&#38453;&#31354;&#38388;&#30340;&#26080;&#38480;&#21046;&#21442;&#25968;&#21270;&#65292;&#36825;&#26159;&#19968;&#31181;&#26367;&#20195;&#21033;&#29992;&#21464;&#25442;&#30340;&#26368;&#26032;&#32467;&#26524;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22914;&#20309;&#23545;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;Cholesky&#22240;&#23376;&#26045;&#21152;&#31232;&#30095;&#24615;&#38480;&#21046;&#65292;&#36825;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;
In covariance matrix estimation, one of the challenges lies in finding a suitable model and an efficient estimation method. Two commonly used approaches in the literature involve imposing linear restrictions on the covariance matrix or its inverse. Another approach considers linear restrictions on the matrix logarithm of the covariance matrix. In this paper, we present a general framework for linear restrictions on different transformations of the covariance matrix, including the mentioned examples. Our proposed estimation method solves a convex problem and yields an M-estimator, allowing for relatively straightforward asymptotic and finite sample analysis. After developing the general theory, we focus on modelling correlation matrices and on sparsity. Our geometric insights allow to extend various recent results in covariance matrix modelling. This includes providing unrestricted parametrizations of the space of correlation matrices, which is alternative to a recent result utilizing t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#27979;&#37327;&#33410;&#28857;&#20043;&#38388;&#25104;&#23545;&#20132;&#20114;&#30340;&#27700;&#24179;&#65292;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#20998;&#26512;&#65292;&#20197;&#30830;&#23450;&#20855;&#26377;&#19968;&#23450;&#23481;&#37327;&#30340;MPNN&#21487;&#20197;&#23398;&#20064;&#21738;&#20123;&#33410;&#28857;&#29305;&#24449;&#30340;&#20989;&#25968;&#31867;&#21035;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#20026;&#20102;&#20445;&#35777;&#33410;&#28857;&#23545;&#20043;&#38388;&#30340;&#20805;&#20998;&#36890;&#20449;&#65292;MPNN&#30340;&#23481;&#37327;&#24517;&#39035;&#26159;...</title><link>http://arxiv.org/abs/2306.03589</link><description>&lt;p&gt;
&#36807;&#24230;&#21387;&#32553;&#22914;&#20309;&#24433;&#21709;GNN&#30340;&#33021;&#21147;&#65311;
&lt;/p&gt;
&lt;p&gt;
How does over-squashing affect the power of GNNs?. (arXiv:2306.03589v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03589
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#27979;&#37327;&#33410;&#28857;&#20043;&#38388;&#25104;&#23545;&#20132;&#20114;&#30340;&#27700;&#24179;&#65292;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#20998;&#26512;&#65292;&#20197;&#30830;&#23450;&#20855;&#26377;&#19968;&#23450;&#23481;&#37327;&#30340;MPNN&#21487;&#20197;&#23398;&#20064;&#21738;&#20123;&#33410;&#28857;&#29305;&#24449;&#30340;&#20989;&#25968;&#31867;&#21035;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#20026;&#20102;&#20445;&#35777;&#33410;&#28857;&#23545;&#20043;&#38388;&#30340;&#20805;&#20998;&#36890;&#20449;&#65292;MPNN&#30340;&#23481;&#37327;&#24517;&#39035;&#26159;...
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#26159;&#22788;&#29702;&#22270;&#32467;&#26500;&#25968;&#25454;&#30340;&#26426;&#22120;&#23398;&#20064;&#30340;&#26368;&#20808;&#36827;&#27169;&#22411;&#12290;&#26368;&#27969;&#34892;&#30340;GNN&#31867;&#21035;&#26159;&#36890;&#36807;&#30456;&#37051;&#33410;&#28857;&#38388;&#30340;&#20449;&#24687;&#20132;&#25442;&#26469;&#25805;&#20316;&#30340;&#65292;&#31216;&#20026;&#28040;&#24687;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#65288;MPNN&#65289;&#12290;&#37492;&#20110;&#23427;&#20204;&#30340;&#24191;&#27867;&#24212;&#29992;&#65292;&#20102;&#35299;MPNN&#30340;&#34920;&#36798;&#33021;&#21147;&#26159;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#32467;&#26524;&#36890;&#24120;&#32771;&#34385;&#20855;&#26377;&#26080;&#20449;&#24687;&#33410;&#28857;&#29305;&#24449;&#30340;&#29615;&#22659;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#20005;&#26684;&#30340;&#20998;&#26512;&#26041;&#27861;&#65292;&#20197;&#30830;&#23450;&#20855;&#26377;&#19968;&#23450;&#23481;&#37327;&#30340;MPNN&#21487;&#20197;&#23398;&#20064;&#21738;&#20123;&#33410;&#28857;&#29305;&#24449;&#30340;&#20989;&#25968;&#31867;&#21035;&#12290;&#25105;&#20204;&#36890;&#36807;&#27979;&#37327;MPNN&#20801;&#35768;&#30340;&#33410;&#28857;&#20043;&#38388;&#30340;&#25104;&#23545;&#20132;&#20114;&#27700;&#24179;&#26469;&#23454;&#29616;&#27492;&#30446;&#30340;&#12290;&#35813;&#27979;&#37327;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#37327;&#21270;&#29305;&#24615;&#65292;&#21363;&#25152;&#35859;&#30340;&#36807;&#24230;&#21387;&#32553;&#25928;&#24212;&#65292;&#35813;&#25928;&#24212;&#34987;&#35266;&#23519;&#21040;&#26159;&#24403;&#22823;&#37327;&#30340;&#20449;&#24687;&#32858;&#21512;&#25104;&#22266;&#23450;&#22823;&#23567;&#30340;&#21521;&#37327;&#26102;&#21457;&#29983;&#30340;&#12290;&#20351;&#29992;&#25105;&#20204;&#30340;&#27979;&#37327;&#65292;&#25105;&#20204;&#35777;&#26126;&#65292;&#20026;&#20102;&#20445;&#35777;&#33410;&#28857;&#23545;&#20043;&#38388;&#30340;&#20805;&#20998;&#36890;&#20449;&#65292;MPNN&#30340;&#23481;&#37327;&#24517;&#39035;&#26159;...
&lt;/p&gt;
&lt;p&gt;
Graph Neural Networks (GNNs) are the state-of-the-art model for machine learning on graph-structured data. The most popular class of GNNs operate by exchanging information between adjacent nodes, and are known as Message Passing Neural Networks (MPNNs). Given their widespread use, understanding the expressive power of MPNNs is a key question. However, existing results typically consider settings with uninformative node features. In this paper, we provide a rigorous analysis to determine which function classes of node features can be learned by an MPNN of a given capacity. We do so by measuring the level of pairwise interactions between nodes that MPNNs allow for. This measure provides a novel quantitative characterization of the so-called over-squashing effect, which is observed to occur when a large volume of messages is aggregated into fixed-size vectors. Using our measure, we prove that, to guarantee sufficient communication between pairs of nodes, the capacity of the MPNN must be l
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; L-C2ST &#30340;&#22522;&#20110;&#26412;&#22320;&#35786;&#26029;&#23454;&#29616;&#27169;&#25311;&#25512;&#26029;&#20013;&#21518;&#39564;&#36817;&#20284;&#30340;&#26032;&#26041;&#27861;&#65292;&#20854;&#21487;&#20197;&#22312;&#20219;&#20309;&#32473;&#23450;&#30340;&#35266;&#27979;&#19979;&#26412;&#22320;&#35780;&#20272;&#21518;&#39564;&#20272;&#35745;&#22120;&#65292;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#30446;&#21069;&#35780;&#20272;&#21518;&#39564;&#20272;&#35745;&#22120;&#38480;&#21046;&#35299;&#20915;&#26041;&#27861;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.03580</link><description>&lt;p&gt;
L-C2ST: &#22522;&#20110;&#26412;&#22320;&#35786;&#26029;&#23454;&#29616;&#27169;&#25311;&#25512;&#26029;&#20013;&#21518;&#39564;&#36817;&#20284;
&lt;/p&gt;
&lt;p&gt;
L-C2ST: Local Diagnostics for Posterior Approximations in Simulation-Based Inference. (arXiv:2306.03580v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03580
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; L-C2ST &#30340;&#22522;&#20110;&#26412;&#22320;&#35786;&#26029;&#23454;&#29616;&#27169;&#25311;&#25512;&#26029;&#20013;&#21518;&#39564;&#36817;&#20284;&#30340;&#26032;&#26041;&#27861;&#65292;&#20854;&#21487;&#20197;&#22312;&#20219;&#20309;&#32473;&#23450;&#30340;&#35266;&#27979;&#19979;&#26412;&#22320;&#35780;&#20272;&#21518;&#39564;&#20272;&#35745;&#22120;&#65292;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#30446;&#21069;&#35780;&#20272;&#21518;&#39564;&#20272;&#35745;&#22120;&#38480;&#21046;&#35299;&#20915;&#26041;&#27861;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#35768;&#22810;&#27169;&#25311;&#25512;&#26029;&#65288;SBI&#65289;&#30340;&#24037;&#20316;&#37117;&#20381;&#36182;&#20110;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#26469;&#36817;&#20284;&#22797;&#26434;&#12289;&#39640;&#32500;&#24230;&#30340;&#21518;&#39564;&#20998;&#24067;&#12290;&#28982;&#32780;&#65292;&#35780;&#20272;&#36825;&#20123;&#36817;&#20284;&#26159;&#21542;&#21487;&#20449;&#20173;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;&#22823;&#22810;&#25968;&#26041;&#27861;&#20165;&#22312;&#35266;&#27979;&#31354;&#38388;&#26399;&#26395;&#19979;&#35780;&#20272;&#21518;&#39564;&#20272;&#35745;&#22120;&#12290;&#36825;&#38480;&#21046;&#20102;&#23427;&#20204;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#19981;&#33021;&#36275;&#22815;&#22320;&#30830;&#23450;&#21738;&#20123;&#35266;&#27979;&#32467;&#26524;&#21487;&#20197;&#20449;&#20219;&#36825;&#20123;&#36817;&#20284;&#25110;&#24212;&#35813;&#25913;&#36827;&#12290;&#25105;&#20204;&#22522;&#20110;&#33879;&#21517;&#30340;&#20998;&#31867;&#22120;&#20004;&#26679;&#26412;&#26816;&#39564; (C2ST)&#65292;&#24341;&#20837; L-C2ST&#65292;&#19968;&#20010;&#26032;&#26041;&#27861;&#65292;&#20801;&#35768;&#22312;&#20219;&#20309;&#32473;&#23450;&#30340;&#35266;&#27979;&#19979;&#26412;&#22320;&#35780;&#20272;&#21518;&#39564;&#20272;&#35745;&#22120;&#12290;&#23427;&#25552;&#20379;&#26377;&#29702;&#35770;&#22522;&#30784;&#21644;&#26131;&#20110;&#35299;&#37322;&#30340;&#65292;&#22914;&#22270;&#31034;&#35786;&#26029;&#12290;&#19982; C2ST &#19981;&#21516;&#30340;&#26159;&#65292;L-C2ST &#19981;&#38656;&#35201;&#35775;&#38382;&#30495;&#23454;&#21518;&#39564;&#30340;&#26679;&#26412;&#12290;&#23545;&#20110;&#22522;&#20110;&#24402;&#19968;&#21270;&#27969;&#30340;&#21518;&#39564;&#20272;&#35745;&#22120;&#65292;L-C2ST &#21487;&#20197;&#19987;&#38376;&#25552;&#20379;&#26356;&#22909;&#30340;&#32479;&#35745;&#21151;&#29575;&#65292;&#21516;&#26102;&#35745;&#31639;&#25928;&#29575;&#26356;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many recent works in simulation-based inference (SBI) rely on deep generative models to approximate complex, high-dimensional posterior distributions. However, evaluating whether or not these approximations can be trusted remains a challenge. Most approaches evaluate the posterior estimator only in expectation over the observation space. This limits their interpretability and is not sufficient to identify for which observations the approximation can be trusted or should be improved. Building upon the well-known classifier two-sample test (C2ST), we introduce L-C2ST, a new method that allows for a local evaluation of the posterior estimator at any given observation. It offers theoretically grounded and easy to interpret - e.g. graphical - diagnostics, and unlike C2ST, does not require access to samples from the true posterior. In the case of normalizing flow-based posterior estimators, L-C2ST can be specialized to offer better statistical power, while being computationally more efficien
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35760;&#24518;&#30340;&#21452;&#39640;&#26031;&#36807;&#31243;&#29992;&#20110;&#24207;&#21015;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#25511;&#21046;&#35823;&#24046;&#24182;&#25913;&#21892;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2306.03566</link><description>&lt;p&gt;
&#22522;&#20110;&#35760;&#24518;&#30340;&#21452;&#39640;&#26031;&#36807;&#31243;&#29992;&#20110;&#24207;&#21015;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Memory-Based Dual Gaussian Processes for Sequential Learning. (arXiv:2306.03566v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03566
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35760;&#24518;&#30340;&#21452;&#39640;&#26031;&#36807;&#31243;&#29992;&#20110;&#24207;&#21015;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#25511;&#21046;&#35823;&#24046;&#24182;&#25913;&#21892;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36830;&#32493;&#21644;&#20027;&#21160;&#23398;&#20064;&#20013;&#65292;&#35775;&#38382;&#36807;&#21435;&#25968;&#25454;&#30340;&#33021;&#21147;&#26377;&#38480;&#65292;&#22240;&#27492;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#65288;GPs&#65289;&#36827;&#34892;&#24207;&#21015;&#23398;&#20064;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#22312;&#21518;&#39564;&#12289;&#36229;&#21442;&#25968;&#21644;&#35825;&#23548;&#28857;&#30340;&#19981;&#20934;&#30830;&#24615;&#23548;&#33268;&#38169;&#35823;&#38543;&#26102;&#38388;&#32047;&#31215;&#30340;&#24773;&#20917;&#19979;&#65292;&#20934;&#30830;&#23398;&#20064;&#21464;&#24471;&#22256;&#38590;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#26368;&#36817;&#25552;&#20986;&#30340;&#21452;&#31232;&#30095;&#21464;&#20998;&#39640;&#26031;&#36807;&#31243;&#26469;&#25511;&#21046;&#25152;&#26377;&#36825;&#20123;&#35823;&#24046;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#36827;&#34892;&#36890;&#29992;&#20284;&#28982;&#30340;&#20934;&#30830;&#25512;&#26029;&#65292;&#24182;&#36890;&#36807;&#20027;&#21160;&#24314;&#31435;&#21644;&#26356;&#26032;&#36807;&#21435;&#25968;&#25454;&#30340;&#35760;&#24518;&#26469;&#25913;&#21892;&#23398;&#20064;&#12290;&#25105;&#20204;&#22312;&#28041;&#21450;&#36125;&#21494;&#26031;&#20248;&#21270;&#12289;&#20027;&#21160;&#23398;&#20064;&#21644;&#36830;&#32493;&#23398;&#20064;&#30340;&#20960;&#20010;&#24212;&#29992;&#20013;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sequential learning with Gaussian processes (GPs) is challenging when access to past data is limited, for example, in continual and active learning. In such cases, errors can accumulate over time due to inaccuracies in the posterior, hyperparameters, and inducing points, making accurate learning challenging. Here, we present a method to keep all such errors in check using the recently proposed dual sparse variational GP. Our method enables accurate inference for generic likelihoods and improves learning by actively building and updating a memory of past data. We demonstrate its effectiveness in several applications involving Bayesian optimization, active learning, and continual learning.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32593;&#32476;&#30340;&#20989;&#25968;&#25968;&#25454;&#35270;&#35282;&#30340;&#21407;&#21019;&#26041;&#27861;&#65292;&#21033;&#29992;&#26679;&#26412;&#36890;&#36807;&#21508;&#23618;&#30340;&#36712;&#36857;&#21450;&#20854;&#32479;&#35745;&#19978;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#22810;&#23618;&#27425;&#24102;&#22522;&#20934;&#30340;ODD&#26816;&#27979;&#12290;</title><link>http://arxiv.org/abs/2306.03522</link><description>&lt;p&gt;
&#22810;&#23618;&#27425;&#24102;&#22522;&#20934;&#30340;&#24322;&#24120;&#26816;&#27979;&#30340;&#20989;&#25968;&#25968;&#25454;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
A Functional Data Perspective and Baseline On Multi-Layer Out-of-Distribution Detection. (arXiv:2306.03522v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03522
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32593;&#32476;&#30340;&#20989;&#25968;&#25968;&#25454;&#35270;&#35282;&#30340;&#21407;&#21019;&#26041;&#27861;&#65292;&#21033;&#29992;&#26679;&#26412;&#36890;&#36807;&#21508;&#23618;&#30340;&#36712;&#36857;&#21450;&#20854;&#32479;&#35745;&#19978;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#22810;&#23618;&#27425;&#24102;&#22522;&#20934;&#30340;ODD&#26816;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#29616;&#22806;&#26679;&#26412;&#26816;&#27979;&#30340;&#20851;&#38190;&#29305;&#24449;&#26159;&#36890;&#36807;&#22810;&#23618;&#20998;&#31867;&#22120;&#25552;&#21462;&#32479;&#35745;&#27169;&#24335;&#21644;&#25968;&#25454;&#38388;&#30340;&#20851;&#31995;&#65292;&#20197;&#26816;&#27979;&#39044;&#26399;&#36755;&#20837;&#25968;&#25454;&#20998;&#24067;&#30340;&#21464;&#21270;&#12290;&#20294;&#26159;&#65292;&#29616;&#26377;&#30340;&#19968;&#20123;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#20165;&#20351;&#29992;&#20498;&#25968;&#31532;&#20108;&#23618;&#25110;&#26368;&#21518;&#19968;&#23618;&#30340;&#36755;&#20986;&#65292;&#30041;&#19979;&#20102;&#29992;&#20110;ODD&#26816;&#27979;&#30340;&#26377;&#20215;&#20540;&#30340;&#20449;&#24687;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32593;&#32476;&#30340;&#20989;&#25968;&#35270;&#35282;&#30340;&#21407;&#21019;&#26041;&#27861;&#65292;&#21033;&#29992;&#26679;&#26412;&#36890;&#36807;&#21508;&#23618;&#30340;&#36712;&#36857;&#21450;&#20854;&#32479;&#35745;&#19978;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;&#23427;&#36229;&#36234;&#20102;&#22810;&#20803;&#29305;&#24449;&#32858;&#21512;&#65292;&#24182;&#24341;&#20837;&#20102;&#22522;&#20110;&#20989;&#25968;&#24322;&#24120;&#26816;&#27979;&#30340;&#22522;&#20934;&#12290;&#22312;&#36825;&#20010;&#26032;&#30340;&#26694;&#26550;&#20013;&#65292;ODD&#26816;&#27979;&#36716;&#21270;&#20026;&#26816;&#27979;&#26679;&#26412;&#30340;&#36712;&#36857;&#19982;&#35757;&#32451;&#38598;&#25152;&#34920;&#29616;&#30340;&#20856;&#22411;&#34892;&#20026;&#19981;&#21516;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#22522;&#20934;&#27979;&#35797;&#20013;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#36890;&#36807;&#21033;&#29992;&#32593;&#32476;&#30340;&#25152;&#26377;&#23618;&#30340;&#20449;&#24687;&#65292;&#20854;&#22312;&#24615;&#33021;&#19978;&#20248;&#20110;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
A key feature of out-of-distribution (OOD) detection is to exploit a trained neural network by extracting statistical patterns and relationships through the multi-layer classifier to detect shifts in the expected input data distribution. Despite achieving solid results, several state-of-the-art methods rely on the penultimate or last layer outputs only, leaving behind valuable information for OOD detection. Methods that explore the multiple layers either require a special architecture or a supervised objective to do so. This work adopts an original approach based on a functional view of the network that exploits the sample's trajectories through the various layers and their statistical dependencies. It goes beyond multivariate features aggregation and introduces a baseline rooted in functional anomaly detection. In this new framework, OOD detection translates into detecting samples whose trajectories differ from the typical behavior characterized by the training set. We validate our me
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;Prompt-tuning&#22312;&#27880;&#24847;&#21147;&#26550;&#26500;&#20013;&#30340;&#24212;&#29992;&#65292;&#36890;&#36807;&#25506;&#32034;&#19978;&#19979;&#25991;&#28151;&#21512;&#27169;&#22411;&#65292;&#34920;&#26126;softmax-prompt-attention&#22312;&#34920;&#36798;&#19978;&#20248;&#20110;&#20854;&#20182;&#27169;&#22411;&#65292;&#21516;&#26102;&#20063;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#21487;&#20197;&#39640;&#25928;&#30340;&#20351;&#29992;&#25968;&#25454;&#23398;&#20064;&#25552;&#31034;&#12290;</title><link>http://arxiv.org/abs/2306.03435</link><description>&lt;p&gt;
&#20851;&#27880;&#28857;&#23545;Prompt-tuning&#30340;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
On the Role of Attention in Prompt-tuning. (arXiv:2306.03435v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03435
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;Prompt-tuning&#22312;&#27880;&#24847;&#21147;&#26550;&#26500;&#20013;&#30340;&#24212;&#29992;&#65292;&#36890;&#36807;&#25506;&#32034;&#19978;&#19979;&#25991;&#28151;&#21512;&#27169;&#22411;&#65292;&#34920;&#26126;softmax-prompt-attention&#22312;&#34920;&#36798;&#19978;&#20248;&#20110;&#20854;&#20182;&#27169;&#22411;&#65292;&#21516;&#26102;&#20063;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#21487;&#20197;&#39640;&#25928;&#30340;&#20351;&#29992;&#25968;&#25454;&#23398;&#20064;&#25552;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Prompt-tuning &#26159;&#19968;&#31181;&#26032;&#20852;&#30340;&#31574;&#30053;&#65292;&#36890;&#36807;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064; (&#36719;) &#25552;&#31034;&#21442;&#25968;&#65292;&#20351;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411; (LLM) &#36866;&#24212;&#19979;&#28216;&#20219;&#21153;&#12290;&#23613;&#31649;&#20854;&#22312; LLM &#20013;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#23545;&#20110; Prompt-tuning &#30340;&#33021;&#21147;&#21450;&#20851;&#27880;&#26426;&#21046;&#22312;&#25552;&#31034;&#20013;&#30340;&#20316;&#29992;&#65292;&#29702;&#35770;&#29702;&#35299;&#23578;&#26377;&#38480;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25506;&#32034;&#19968;&#20010;&#27880;&#24847;&#21147;&#26550;&#26500;&#30340; Prompt-tuning&#65292;&#24182;&#30740;&#31350;&#19978;&#19979;&#25991;&#28151;&#21512;&#27169;&#22411;&#65292;&#20854;&#20013;&#27599;&#20010;&#36755;&#20837;&#34920;&#31034;&#23646;&#20110;&#19978;&#19979;&#25991;&#30456;&#20851;&#25110;&#26080;&#20851;&#38598;&#21512;&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#20010;&#33258;&#21253;&#21547;&#30340;&#25552;&#31034;-&#27880;&#24847;&#21147;&#27169;&#22411;&#26469;&#38548;&#31163; Prompt-tuning &#30340;&#20316;&#29992;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#22914;&#19979;&#65306;(1) &#25105;&#20204;&#34920;&#26126;&#22312;&#25105;&#20204;&#30340;&#19978;&#19979;&#25991;&#25968;&#25454;&#27169;&#22411;&#19979;&#65292;softmax-prompt-attention &#22312;&#21487;&#35777;&#26126;&#22320;&#27604;softmax-self-attention &#21644;&#32447;&#24615;&#25552;&#31034;&#27880;&#24847;&#21147;&#26356;&#20855;&#34920;&#36798;&#21147;&#12290;(2) &#25105;&#20204;&#20998;&#26512;&#20102;&#28176;&#21464;&#19979;&#38477;&#30340;&#21021;&#22987;&#36712;&#36857;&#65292;&#24182;&#23637;&#31034;&#21487;&#20197;&#36890;&#36807;&#36817;&#20046;&#26368;&#20248;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#23398;&#20064;&#25552;&#31034;&#21644;&#39044;&#27979;&#22836;&#65292;&#20174;&#32780;&#35777;&#26126;&#20102;&#25552;&#31034;&#21487;&#20197;&#35777;&#26126;&#22320;&#27880;&#24847;&#21040;&#31232;&#30095;&#30340;&#19978;&#19979;&#25991;&#30456;&#20851;&#20449;&#24687;&#12290;(3)
&lt;/p&gt;
&lt;p&gt;
Prompt-tuning is an emerging strategy to adapt large language models (LLM) to downstream tasks by learning a (soft-)prompt parameter from data. Despite its success in LLMs, there is limited theoretical understanding of the power of prompt-tuning and the role of the attention mechanism in prompting. In this work, we explore prompt-tuning for one-layer attention architectures and study contextual mixture-models where each input token belongs to a context-relevant or -irrelevant set. We isolate the role of prompt-tuning through a self-contained prompt-attention model. Our contributions are as follows: (1) We show that softmax-prompt-attention is provably more expressive than softmax-self-attention and linear-prompt-attention under our contextual data model. (2) We analyze the initial trajectory of gradient descent and show that it learns the prompt and prediction head with near-optimal sample complexity and demonstrate how prompt can provably attend to sparse context-relevant tokens. (3) 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#35299;&#20915;&#24102;&#26377;&#23454;&#20363;&#21644;&#26631;&#31614;&#30456;&#20851;&#30340;&#26631;&#31614;&#22122;&#22768;&#23545;&#20110;&#20108;&#20998;&#31867;&#38382;&#39064;&#30340;&#22256;&#38590;&#65292;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#24471;&#21040;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#21487;&#20197;&#23454;&#29616;&#26368;&#20248;&#30340;&#36229;&#39069;&#39118;&#38505;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2306.03402</link><description>&lt;p&gt;
&#24102;&#26377;&#23454;&#20363;&#21644;&#26631;&#31614;&#30456;&#20851;&#30340;&#26631;&#31614;&#22122;&#22768;&#30340;&#20108;&#20998;&#31867;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Binary Classification with Instance and Label Dependent Label Noise. (arXiv:2306.03402v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03402
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#35299;&#20915;&#24102;&#26377;&#23454;&#20363;&#21644;&#26631;&#31614;&#30456;&#20851;&#30340;&#26631;&#31614;&#22122;&#22768;&#23545;&#20110;&#20108;&#20998;&#31867;&#38382;&#39064;&#30340;&#22256;&#38590;&#65292;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#24471;&#21040;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#21487;&#20197;&#23454;&#29616;&#26368;&#20248;&#30340;&#36229;&#39069;&#39118;&#38505;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#24102;&#26377;&#26631;&#31614;&#30456;&#20851;&#30340;&#26631;&#31614;&#22122;&#22768;&#22312;&#29702;&#35770;&#21644;&#23454;&#36341;&#20013;&#24471;&#21040;&#20102;&#24191;&#27867;&#25506;&#35752;&#65292;&#28982;&#32780;&#22788;&#29702;&#24102;&#26377;&#23454;&#20363;&#21644;&#26631;&#31614;&#30456;&#20851;&#30340;&#26631;&#31614;&#22122;&#22768;&#20173;&#28982;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#36825;&#31181;&#22256;&#38590;&#22312;&#20110;&#22122;&#22768;&#29575;&#22240;&#27599;&#20010;&#23454;&#20363;&#32780;&#24322;&#65292;&#20351;&#24471;&#20934;&#30830;&#20272;&#35745;&#22122;&#22768;&#29575;&#25104;&#20026;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#30446;&#21069;&#36824;&#27809;&#26377;&#35299;&#20915;&#33021;&#21542;&#20165;&#20351;&#29992;&#21547;&#26377;&#22122;&#22768;&#26679;&#26412;&#26469;&#23398;&#20064;&#21487;&#38752;&#27169;&#22411;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#36890;&#36807;&#29702;&#35770;&#20998;&#26512;&#22238;&#31572;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#25552;&#20379;&#20102;&#21305;&#37197;&#30340;&#19978;&#30028;&#21644;&#19979;&#30028;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#19981;&#38656;&#35201;&#20219;&#20309;&#39069;&#22806;&#30340;&#20551;&#35774;&#65292;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#21487;&#20197;&#23454;&#29616;&#26368;&#20248;&#30340;&#36229;&#39069;&#39118;&#38505;&#30028;&#38480;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#36890;&#36807;&#27604;&#36739;&#20174;&#24178;&#20928;&#26679;&#26412;&#21644;&#22122;&#22768;&#26679;&#26412;&#20013;&#24471;&#21040;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#22120;&#26469;&#23548;&#20986;&#19968;&#31181;&#19982;&#22122;&#22768;&#27700;&#24179;&#25104;&#27604;&#20363;&#30340;&#26032;&#30340;&#36229;&#39069;&#39118;&#38505;&#30028;&#38480;&#65292;&#22312;&#38750;&#24120;&#19968;&#33324;&#30340;&#24773;&#20917;&#19979;&#37117;&#25104;&#31435;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#34920;&#26126;&#20102;0-1&#25439;&#22833;&#30340;&#26497;&#23567;&#26497;&#22823;&#19979;&#30028;&#26159;&#19968;&#20010;&#19982;&#26631;&#31614;&#25968;&#25104;&#27604;&#20363;&#30340;&#24120;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning with label dependent label noise has been extensively explored in both theory and practice; however, dealing with instance (i.e., feature) and label dependent label noise continues to be a challenging task. The difficulty arises from the fact that the noise rate varies for each instance, making it challenging to estimate accurately. The question of whether it is possible to learn a reliable model using only noisy samples remains unresolved. We answer this question with a theoretical analysis that provides matching upper and lower bounds. Surprisingly, our results show that, without any additional assumptions, empirical risk minimization achieves the optimal excess risk bound. Specifically, we derive a novel excess risk bound proportional to the noise level, which holds in very general settings, by comparing the empirical risk minimizers obtained from clean samples and noisy samples. Second, we show that the minimax lower bound for the 0-1 loss is a constant proportional to the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36731;&#37327;&#32423;&#26041;&#27861;&#26469;&#35843;&#25972;&#32852;&#37030;&#24179;&#22343;&#20013;&#30340;&#32858;&#21512;&#26435;&#37325;&#65292;&#36890;&#36807;&#26681;&#25454;&#27599;&#20010;&#23458;&#25143;&#30340;&#21442;&#19982;&#21382;&#21490;&#26469;&#22788;&#29702;&#20855;&#26377;&#19981;&#21516;&#21442;&#19982;&#29575;&#30340;&#23458;&#25143;&#65292;&#35299;&#20915;&#20102;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#26410;&#30693;&#21442;&#19982;&#27010;&#29575;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.03401</link><description>&lt;p&gt;
&#22788;&#29702;&#32852;&#37030;&#24179;&#22343;&#20013;&#26410;&#30693;&#21442;&#19982;&#27010;&#29575;&#30340;&#36731;&#37327;&#32423;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Lightweight Method for Tackling Unknown Participation Probabilities in Federated Averaging. (arXiv:2306.03401v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03401
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36731;&#37327;&#32423;&#26041;&#27861;&#26469;&#35843;&#25972;&#32852;&#37030;&#24179;&#22343;&#20013;&#30340;&#32858;&#21512;&#26435;&#37325;&#65292;&#36890;&#36807;&#26681;&#25454;&#27599;&#20010;&#23458;&#25143;&#30340;&#21442;&#19982;&#21382;&#21490;&#26469;&#22788;&#29702;&#20855;&#26377;&#19981;&#21516;&#21442;&#19982;&#29575;&#30340;&#23458;&#25143;&#65292;&#35299;&#20915;&#20102;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#26410;&#30693;&#21442;&#19982;&#27010;&#29575;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#65292;&#23458;&#25143;&#31471;&#36890;&#24120;&#20855;&#26377;&#20808;&#39564;&#26410;&#30693;&#30340;&#19981;&#21516;&#21442;&#19982;&#29575;&#65292;&#22914;&#26524;&#19981;&#36866;&#24403;&#22788;&#29702;&#65292;&#21017;&#21487;&#33021;&#20250;&#23545;&#32852;&#37030;&#23398;&#20064;&#30340;&#24615;&#33021;&#36896;&#25104;&#37325;&#22823;&#24433;&#21709;&#12290;&#29616;&#26377;&#30340;&#35299;&#20915;&#26041;&#27861;&#36890;&#24120;&#22522;&#20110;&#20840;&#23616;&#26041;&#24046;&#32553;&#20943;&#65292;&#36825;&#38656;&#35201;&#22823;&#37327;&#39069;&#22806;&#30340;&#20869;&#23384;&#65292;&#20854;&#20056;&#27861;&#22240;&#23376;&#31561;&#20110;&#23458;&#25143;&#24635;&#25968;&#12290;&#19968;&#20010;&#37325;&#35201;&#30340;&#26410;&#35299;&#20915;&#38382;&#39064;&#26159;&#25214;&#21040;&#19968;&#31181;&#36731;&#37327;&#32423;&#26041;&#27861;&#26469;&#22788;&#29702;&#20855;&#22791;&#19981;&#21516;&#21442;&#19982;&#29575;&#23458;&#25143;&#30340;&#32852;&#37030;&#23398;&#20064;&#12290;&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#26681;&#25454;&#27599;&#20010;&#23458;&#25143;&#30340;&#21442;&#19982;&#21382;&#21490;&#26469;&#35843;&#25972;&#32852;&#37030;&#24179;&#22343;&#65288;FedAvg&#65289;&#20013;&#30340;&#32858;&#21512;&#26435;&#37325;&#26469;&#35299;&#20915;&#27492;&#38382;&#39064;&#12290;&#25105;&#20204;&#39318;&#20808;&#23637;&#31034;&#20102;&#22312;&#20855;&#26377;&#24322;&#26500;&#21442;&#19982;&#27010;&#29575;&#30340;&#24773;&#20917;&#19979;&#65292;&#38750;&#26368;&#20248;&#32858;&#21512;&#26435;&#37325;&#30340;FedAvg&#21487;&#33021;&#20250;&#20174;&#21407;&#22987;FL&#30446;&#26631;&#30340;&#26368;&#20248;&#35299;&#20559;&#31163;&#65292;&#36825;&#34920;&#26126;&#38656;&#35201;&#25214;&#21040;&#26368;&#20248;&#32858;&#21512;&#26435;&#37325;&#12290;&#28982;&#32780;&#65292;&#24403;&#21442;&#19982;&#27010;&#29575;&#19981;&#21487;&#30693;&#26102;&#35745;&#31639;&#26368;&#20248;&#26435;&#37325;&#38750;&#24120;&#22256;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;
In federated learning (FL), clients usually have diverse participation probabilities that are unknown a priori, which can significantly harm the performance of FL if not handled properly. Existing works aiming at addressing this problem are usually based on global variance reduction, which requires a substantial amount of additional memory in a multiplicative factor equal to the total number of clients. An important open problem is to find a lightweight method for FL in the presence of clients with unknown participation rates. In this paper, we address this problem by adapting the aggregation weights in federated averaging (FedAvg) based on the participation history of each client. We first show that, with heterogeneous participation probabilities, FedAvg with non-optimal aggregation weights can diverge from the optimal solution of the original FL objective, indicating the need of finding optimal aggregation weights. However, it is difficult to compute the optimal weights when the part
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#32447;&#40654;&#26364;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#22312;&#32447;&#24773;&#20917;&#19979;&#20272;&#35745;&#28508;&#22312;&#30340;&#20302;&#31209;&#24352;&#37327;&#12290;&#20854;&#20013;&#65292;&#25105;&#20204;&#22312;&#22788;&#29702;&#36830;&#32493;&#25110;&#20998;&#31867;&#21464;&#37327;&#26102;&#25552;&#20379;&#20102;&#28789;&#27963;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#22312;&#32447;&#24773;&#20917;&#19979;&#23581;&#35797;&#20102;&#20004;&#20010;&#20855;&#20307;&#30340;&#24212;&#29992;&#65292;&#21363;&#22312;&#32447;&#24352;&#37327;&#34917;&#20840;&#21644;&#22312;&#32447;&#20108;&#20803;&#24352;&#37327;&#23398;&#20064;&#12290;&#25105;&#20204;&#36824;&#24314;&#31435;&#20102;&#36880;&#20010;&#26465;&#30446;&#30340;&#31934;&#30830;&#38169;&#35823;&#30028;&#38480;&#65292;&#36825;&#26159;&#22312;&#22312;&#32447;&#24352;&#37327;&#34917;&#20840;&#20013;&#39318;&#27425;&#32435;&#20837;&#22122;&#22768;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#22312;&#23384;&#22312;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#65292;&#35745;&#31639;&#21644;&#32479;&#35745;&#26041;&#38754;&#23384;&#22312;&#30528;&#20196;&#20154;&#24778;&#35766;&#30340;&#26435;&#34913;&#12290;</title><link>http://arxiv.org/abs/2306.03372</link><description>&lt;p&gt;
&#22312;&#32447;&#24352;&#37327;&#23398;&#20064;&#65306;&#35745;&#31639;&#21644;&#32479;&#35745;&#26435;&#34913;&#65292;&#36866;&#24212;&#24615;&#21644;&#26368;&#20248;&#36951;&#25022;
&lt;/p&gt;
&lt;p&gt;
Online Tensor Learning: Computational and Statistical Trade-offs, Adaptivity and Optimal Regret. (arXiv:2306.03372v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03372
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#32447;&#40654;&#26364;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#22312;&#32447;&#24773;&#20917;&#19979;&#20272;&#35745;&#28508;&#22312;&#30340;&#20302;&#31209;&#24352;&#37327;&#12290;&#20854;&#20013;&#65292;&#25105;&#20204;&#22312;&#22788;&#29702;&#36830;&#32493;&#25110;&#20998;&#31867;&#21464;&#37327;&#26102;&#25552;&#20379;&#20102;&#28789;&#27963;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#22312;&#32447;&#24773;&#20917;&#19979;&#23581;&#35797;&#20102;&#20004;&#20010;&#20855;&#20307;&#30340;&#24212;&#29992;&#65292;&#21363;&#22312;&#32447;&#24352;&#37327;&#34917;&#20840;&#21644;&#22312;&#32447;&#20108;&#20803;&#24352;&#37327;&#23398;&#20064;&#12290;&#25105;&#20204;&#36824;&#24314;&#31435;&#20102;&#36880;&#20010;&#26465;&#30446;&#30340;&#31934;&#30830;&#38169;&#35823;&#30028;&#38480;&#65292;&#36825;&#26159;&#22312;&#22312;&#32447;&#24352;&#37327;&#34917;&#20840;&#20013;&#39318;&#27425;&#32435;&#20837;&#22122;&#22768;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#22312;&#23384;&#22312;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#65292;&#35745;&#31639;&#21644;&#32479;&#35745;&#26041;&#38754;&#23384;&#22312;&#30528;&#20196;&#20154;&#24778;&#35766;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#24191;&#20041;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#32447;&#24773;&#20917;&#19979;&#20272;&#35745;&#28508;&#22312;&#30340;&#20302;&#31209;&#24352;&#37327;&#65292;&#21253;&#25324;&#32447;&#24615;&#21644;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#12290;&#35813;&#26694;&#26550;&#25552;&#20379;&#20102;&#19968;&#31181;&#22788;&#29702;&#36830;&#32493;&#25110;&#20998;&#31867;&#21464;&#37327;&#30340;&#28789;&#27963;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#20010;&#20855;&#20307;&#30340;&#24212;&#29992;&#65306;&#22312;&#32447;&#24352;&#37327;&#34917;&#20840;&#21644;&#22312;&#32447;&#20108;&#20803;&#24352;&#37327;&#23398;&#20064;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22312;&#32447;&#40654;&#26364;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#22312;&#25152;&#26377;&#24212;&#29992;&#31243;&#24207;&#20013;&#37117;&#21487;&#20197;&#26681;&#25454;&#36866;&#24403;&#30340;&#26465;&#20214;&#32447;&#24615;&#25910;&#25947;&#24182;&#24674;&#22797;&#20302;&#31209;&#32452;&#20214;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20026;&#22312;&#32447;&#24352;&#37327;&#34917;&#20840;&#24314;&#31435;&#20102;&#31934;&#30830;&#30340;&#36880;&#20010;&#26465;&#30446;&#38169;&#35823;&#30028;&#38480;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#20195;&#34920;&#20102;&#39318;&#27425;&#23581;&#35797;&#22312;&#22312;&#32447;&#20302;&#31209;&#24352;&#37327;&#24674;&#22797;&#20219;&#21153;&#20013;&#32435;&#20837;&#22122;&#22768;&#30340;&#21162;&#21147;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#22312;&#23384;&#22312;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#65292;&#22312;&#35745;&#31639;&#21644;&#32479;&#35745;&#26041;&#38754;&#23384;&#22312;&#30528;&#20196;&#20154;&#24778;&#35766;&#30340;&#26435;&#34913;&#12290;&#22686;&#21152;&#27493;&#38271;&#21487;&#20197;&#21152;&#24555;&#25910;&#25947;&#65292;&#20294;&#20250;&#23548;&#33268;&#26356;&#39640;&#30340;&#32479;&#35745;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate a generalized framework for estimating latent low-rank tensors in an online setting, encompassing both linear and generalized linear models. This framework offers a flexible approach for handling continuous or categorical variables. Additionally, we investigate two specific applications: online tensor completion and online binary tensor learning. To address these challenges, we propose the online Riemannian gradient descent algorithm, which demonstrates linear convergence and the ability to recover the low-rank component under appropriate conditions in all applications. Furthermore, we establish a precise entry-wise error bound for online tensor completion. Notably, our work represents the first attempt to incorporate noise in the online low-rank tensor recovery task. Intriguingly, we observe a surprising trade-off between computational and statistical aspects in the presence of noise. Increasing the step size accelerates convergence but leads to higher statistical error
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23545;&#27604;&#23398;&#20064;&#20013;&#30340;&#25237;&#24433;&#22836;&#65292;&#22312;&#29702;&#35770;&#21644;&#23454;&#36341;&#20013;&#25214;&#21040;&#20102;&#20004;&#20010;&#20851;&#38190;&#25928;&#24212;&#65306;&#20449;&#21495;&#26041;&#21521;&#30340;&#25193;&#23637;&#21644;&#25910;&#32553;&#65292;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#32447;&#24615;&#21464;&#25442;&#26469;&#25913;&#21892;&#19979;&#28216;&#20998;&#31867;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.03335</link><description>&lt;p&gt;
&#23545;&#27604;&#23398;&#20064;&#20013;&#30340;&#25237;&#24433;&#22836;&#65306;&#25193;&#23637;&#21644;&#25910;&#32553;&#30340;&#21551;&#31034;
&lt;/p&gt;
&lt;p&gt;
Unraveling Projection Heads in Contrastive Learning: Insights from Expansion and Shrinkage. (arXiv:2306.03335v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03335
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23545;&#27604;&#23398;&#20064;&#20013;&#30340;&#25237;&#24433;&#22836;&#65292;&#22312;&#29702;&#35770;&#21644;&#23454;&#36341;&#20013;&#25214;&#21040;&#20102;&#20004;&#20010;&#20851;&#38190;&#25928;&#24212;&#65306;&#20449;&#21495;&#26041;&#21521;&#30340;&#25193;&#23637;&#21644;&#25910;&#32553;&#65292;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#32447;&#24615;&#21464;&#25442;&#26469;&#25913;&#21892;&#19979;&#28216;&#20998;&#31867;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23545;&#27604;&#23398;&#20064;&#20013;&#32534;&#30721;&#22120;-&#25237;&#24433;&#22120;&#26694;&#26550;&#65288;&#20363;&#22914;SimCLR&#65289;&#20013;&#30340;&#25237;&#24433;&#22836;&#65292;&#20063;&#31216;&#20026;&#25237;&#24433;&#20202;&#65292;&#30340;&#20316;&#29992;&#12290;&#25105;&#20204;&#26088;&#22312;&#25581;&#31034;&#19968;&#20010;&#35266;&#23519;&#29616;&#35937;&#30340;&#30495;&#30456;&#65306;&#36890;&#36807;&#19979;&#28216;&#32447;&#24615;&#20998;&#31867;&#20934;&#30830;&#24230;&#30340;&#34913;&#37327;&#65292;&#21363;&#20351;&#22312;&#25237;&#24433;&#22836;&#26412;&#36523;&#26159;&#32447;&#24615;&#30340;&#24773;&#20917;&#19979;&#65292;&#20063;&#21487;&#20197;&#23398;&#20064;&#20986;&#22312;&#25237;&#24433;&#22120;&#20043;&#21069;&#30340;&#34920;&#31034;&#20248;&#20110;&#20043;&#21518;&#12290;&#36890;&#36807;&#23454;&#35777;&#21644;&#29702;&#35770;&#20998;&#26512;&#65292;&#25105;&#20204;&#39318;&#20808;&#30830;&#23450;&#20102;&#20004;&#20010;&#30001;&#23545;&#27604;&#25439;&#22833;&#24341;&#36215;&#30340;&#20851;&#38190;&#25928;&#24212;&#12290;&#26412;&#36136;&#19978;&#65292;&#23545;&#27604;&#25439;&#22833;&#20250;&#25193;&#23637;&#25110;&#25910;&#32553;&#32534;&#30721;&#22120;&#23398;&#20064;&#30340;&#34920;&#31034;&#20013;&#30340;&#20449;&#21495;&#26041;&#21521;&#65292;&#20855;&#20307;&#21462;&#20915;&#20110;&#22914;&#22686;&#24378;&#24378;&#24230;&#65292;&#23545;&#27604;&#25439;&#22833;&#20013;&#20351;&#29992;&#30340;&#28201;&#24230;&#31561;&#22240;&#32032;&#12290;&#20854;&#27425;&#65292;&#21463;&#21040;&#25193;&#23637;&#21644;&#25910;&#32553;&#29616;&#35937;&#30340;&#21551;&#31034;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#32447;&#24615;&#21464;&#25442;&#26469;&#20934;&#30830;&#24314;&#27169;&#25237;&#24433;&#22836;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#21464;&#25442;&#21487;&#20197;&#25552;&#39640;&#19979;&#28216;&#30340;&#20998;&#31867;&#20934;&#30830;&#24230;&#65292;&#32780;&#19988;&#35745;&#31639;&#25104;&#26412;&#20302;&#65292;&#26131;&#20110;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the role of projection heads, also known as projectors, within the encoder-projector framework (e.g., SimCLR) used in contrastive learning. We aim to demystify the observed phenomenon where representations learned before projectors outperform those learned after -- measured using the downstream linear classification accuracy, even when the projectors themselves are linear.  In this paper, we make two significant contributions towards this aim. Firstly, through empirical and theoretical analysis, we identify two crucial effects -- expansion and shrinkage -- induced by the contrastive loss on the projectors. In essence, contrastive loss either expands or shrinks the signal direction in the representations learned by an encoder, depending on factors such as the augmentation strength, the temperature used in contrastive loss, etc. Secondly, drawing inspiration from the expansion and shrinkage phenomenon, we propose a family of linear transformations to accurately model the p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#21151;&#33021;&#24615;&#36755;&#20837;&#31070;&#32463;&#32593;&#32476;&#65292;&#21487;&#20197;&#22312;&#24102;&#26435;&#37325;&#31354;&#38388;&#19978;&#23436;&#25104;&#20840;&#23616;&#20989;&#25968;&#36924;&#36817;&#12290;&#36825;&#19968;&#26041;&#27861;&#36866;&#29992;&#20110;&#36830;&#32493;&#20989;&#25968;&#30340;&#25512;&#24191;&#65292;&#36824;&#21487;&#29992;&#20110;&#36335;&#24452;&#31354;&#38388;&#20989;&#25968;&#30340;&#36924;&#36817;&#65292;&#21516;&#26102;&#20063;&#21487;&#20197;&#36924;&#36817;&#32447;&#24615;&#20989;&#25968;&#31614;&#21517;&#12290;</title><link>http://arxiv.org/abs/2306.03303</link><description>&lt;p&gt;
&#24102;&#26435;&#37325;&#31354;&#38388;&#19978;&#21151;&#33021;&#24615;&#36755;&#20837;&#26144;&#23556;&#30340;&#20840;&#23616;&#26222;&#36866;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
Global universal approximation of functional input maps on weighted spaces. (arXiv:2306.03303v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03303
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#21151;&#33021;&#24615;&#36755;&#20837;&#31070;&#32463;&#32593;&#32476;&#65292;&#21487;&#20197;&#22312;&#24102;&#26435;&#37325;&#31354;&#38388;&#19978;&#23436;&#25104;&#20840;&#23616;&#20989;&#25968;&#36924;&#36817;&#12290;&#36825;&#19968;&#26041;&#27861;&#36866;&#29992;&#20110;&#36830;&#32493;&#20989;&#25968;&#30340;&#25512;&#24191;&#65292;&#36824;&#21487;&#29992;&#20110;&#36335;&#24452;&#31354;&#38388;&#20989;&#25968;&#30340;&#36924;&#36817;&#65292;&#21516;&#26102;&#20063;&#21487;&#20197;&#36924;&#36817;&#32447;&#24615;&#20989;&#25968;&#31614;&#21517;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#25152;&#35859;&#30340;&#21151;&#33021;&#24615;&#36755;&#20837;&#31070;&#32463;&#32593;&#32476;&#65292;&#23450;&#20041;&#22312;&#21487;&#33021;&#26159;&#26080;&#38480;&#32500;&#24102;&#26435;&#37325;&#31354;&#38388;&#19978;&#65292;&#20854;&#20540;&#20063;&#22312;&#21487;&#33021;&#26159;&#26080;&#38480;&#32500;&#30340;&#36755;&#20986;&#31354;&#38388;&#20013;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#21152;&#24615;&#26063;&#20316;&#20026;&#38544;&#34255;&#23618;&#26144;&#23556;&#65292;&#20197;&#21450;&#19968;&#20010;&#38750;&#32447;&#24615;&#28608;&#27963;&#20989;&#25968;&#24212;&#29992;&#20110;&#27599;&#20010;&#38544;&#34255;&#23618;&#12290;&#20381;&#38752;&#24102;&#26435;&#37325;&#31354;&#38388;&#19978;&#30340;Stone-Weierstrass&#23450;&#29702;&#65292;&#25105;&#20204;&#21487;&#20197;&#35777;&#26126;&#36830;&#32493;&#20989;&#25968;&#30340;&#25512;&#24191;&#30340;&#20840;&#23616;&#26222;&#36866;&#36924;&#36817;&#32467;&#26524;&#65292;&#36229;&#36234;&#20102;&#24120;&#35268;&#32039;&#38598;&#36924;&#36817;&#12290;&#36825;&#29305;&#21035;&#36866;&#29992;&#20110;&#36890;&#36807;&#21151;&#33021;&#24615;&#36755;&#20837;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;&#65288;&#38750;&#20808;&#35265;&#20043;&#26126;&#30340;&#65289;&#36335;&#24452;&#31354;&#38388;&#20989;&#25968;&#12290;&#20316;&#20026;&#24102;&#26435;Stone-Weierstrass&#23450;&#29702;&#30340;&#36827;&#19968;&#27493;&#24212;&#29992;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#32447;&#24615;&#20989;&#25968;&#31614;&#21517;&#30340;&#20840;&#23616;&#26222;&#36866;&#36924;&#36817;&#32467;&#26524;&#12290;&#25105;&#20204;&#36824;&#22312;&#36825;&#20010;&#35774;&#32622;&#20013;&#24341;&#20837;&#20102;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#30340;&#35266;&#28857;&#65292;&#24182;&#23637;&#31034;&#20102;&#31614;&#21517;&#20869;&#26680;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#26159;&#26576;&#20123;&#39640;&#26031;&#36807;&#31243;&#30340;Cameron-Martin&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce so-called functional input neural networks defined on a possibly infinite dimensional weighted space with values also in a possibly infinite dimensional output space. To this end, we use an additive family as hidden layer maps and a non-linear activation function applied to each hidden layer. Relying on Stone-Weierstrass theorems on weighted spaces, we can prove a global universal approximation result for generalizations of continuous functions going beyond the usual approximation on compact sets. This then applies in particular to approximation of (non-anticipative) path space functionals via functional input neural networks. As a further application of the weighted Stone-Weierstrass theorem we prove a global universal approximation result for linear functions of the signature. We also introduce the viewpoint of Gaussian process regression in this setting and show that the reproducing kernel Hilbert space of the signature kernels are Cameron-Martin spaces of certain Gauss
&lt;/p&gt;</description></item><item><title>&#35813;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20999;&#25442;&#33258;&#22238;&#24402;&#20302;&#31209;&#24352;&#37327;&#65288;SALT&#65289;&#27169;&#22411;&#65292;&#23427;&#23558;&#33258;&#22238;&#24402;&#38544;Markov&#27169;&#22411;&#65288;ARHMM&#65289;&#21644;&#20999;&#25442;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#65288;SLDS&#65289;&#30340;&#20248;&#28857;&#32467;&#21512;&#36215;&#26469;&#65292;&#36890;&#36807;&#20302;&#31209;&#21442;&#25968;&#21270;&#25552;&#39640;&#20102;&#27169;&#22411;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.03291</link><description>&lt;p&gt;
&#20999;&#25442;&#33258;&#22238;&#24402;&#20302;&#31209;&#24352;&#37327;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Switching Autoregressive Low-rank Tensor Models. (arXiv:2306.03291v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03291
&lt;/p&gt;
&lt;p&gt;
&#35813;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20999;&#25442;&#33258;&#22238;&#24402;&#20302;&#31209;&#24352;&#37327;&#65288;SALT&#65289;&#27169;&#22411;&#65292;&#23427;&#23558;&#33258;&#22238;&#24402;&#38544;Markov&#27169;&#22411;&#65288;ARHMM&#65289;&#21644;&#20999;&#25442;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#65288;SLDS&#65289;&#30340;&#20248;&#28857;&#32467;&#21512;&#36215;&#26469;&#65292;&#36890;&#36807;&#20302;&#31209;&#21442;&#25968;&#21270;&#25552;&#39640;&#20102;&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#24207;&#20998;&#26512;&#20013;&#19968;&#20010;&#37325;&#35201;&#30340;&#38382;&#39064;&#26159;&#23545;&#20855;&#26377;&#26102;&#21464;&#21160;&#21147;&#23398;&#30340;&#31995;&#32479;&#36827;&#34892;&#24314;&#27169;&#12290;&#20849;&#21516;&#36830;&#32493;&#21644;&#31163;&#25955;&#28508;&#24577;&#30340;&#27010;&#29575;&#27169;&#22411;&#20026;&#36825;&#26679;&#30340;&#25968;&#25454;&#25552;&#20379;&#20102;&#21487;&#35299;&#37322;&#12289;&#39640;&#25928;&#21644;&#23454;&#39564;&#24615;&#26377;&#29992;&#30340;&#25551;&#36848;&#12290;&#24120;&#29992;&#30340;&#27169;&#22411;&#21253;&#25324;&#33258;&#22238;&#24402;&#38544;Markov&#27169;&#22411;&#65288;ARHMM&#65289;&#21644;&#20999;&#25442;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#65288;SLDS&#65289;&#65292;&#23427;&#20204;&#21508;&#26377;&#20248;&#32570;&#28857;&#12290;ARHMM&#20801;&#35768;&#31934;&#30830;&#25512;&#29702;&#21644;&#31616;&#21333;&#30340;&#21442;&#25968;&#20272;&#35745;&#65292;&#20294;&#22312;&#23545;&#38271;&#20381;&#36182;&#20851;&#31995;&#24314;&#27169;&#26102;&#20855;&#26377;&#21442;&#25968;&#23494;&#38598;&#24615;&#65292;&#22240;&#27492;&#23481;&#26131;&#20986;&#29616;&#36807;&#25311;&#21512;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#36890;&#36807;&#39532;&#23572;&#21487;&#22827;&#28508;&#24577;&#21160;&#21147;&#23398;&#65292;SLDS&#21487;&#20197;&#20197;&#21442;&#25968;&#39640;&#25928;&#30340;&#26041;&#24335;&#25429;&#25417;&#38271;&#36317;&#31163;&#20381;&#36182;&#24615;&#65292;&#20294;&#22256;&#38590;&#30340;&#21442;&#25968;&#20272;&#35745;&#20219;&#21153;&#21644;&#19968;&#20010;&#38590;&#20197;&#22788;&#29702;&#30340;&#20284;&#28982;&#20989;&#25968;&#21364;&#26159;&#20854;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22320;&#26041;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20999;&#25442;&#33258;&#22238;&#24402;&#20302;&#31209;&#24352;&#37327;&#65288;SALT&#65289;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#20445;&#30041;&#20102;&#20004;&#31181;&#26041;&#27861;&#30340;&#20248;&#28857;&#65292;&#21516;&#26102;&#25913;&#21892;&#20102;&#20854;&#23616;&#38480;&#24615;&#12290;SALT&#23558;ARHMM&#30340;&#24352;&#37327;&#21442;&#25968;&#21270;&#20026;&#20302;&#31209;&#24418;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
An important problem in time-series analysis is modeling systems with time-varying dynamics. Probabilistic models with joint continuous and discrete latent states offer interpretable, efficient, and experimentally useful descriptions of such data. Commonly used models include autoregressive hidden Markov models (ARHMMs) and switching linear dynamical systems (SLDSs), each with its own advantages and disadvantages. ARHMMs permit exact inference and easy parameter estimation, but are parameter intensive when modeling long dependencies, and hence are prone to overfitting. In contrast, SLDSs can capture long-range dependencies in a parameter efficient way through Markovian latent dynamics, but present an intractable likelihood and a challenging parameter estimation task. In this paper, we propose switching autoregressive low-rank tensor (SALT) models, which retain the advantages of both approaches while ameliorating the weaknesses. SALT parameterizes the tensor of an ARHMM with a low-rank 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#20247;&#21253;&#26631;&#31614;&#36827;&#34892;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#32806;&#21512;&#20132;&#21449;&#29109;&#26368;&#23567;&#21270;&#21644;&#27491;&#21017;&#21270;&#20351;&#23398;&#20064;&#36807;&#31243;&#26356;&#21152;&#40065;&#26834;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#24615;&#33021;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2306.03288</link><description>&lt;p&gt;
&#20174;&#20247;&#21253;&#26631;&#31614;&#36827;&#34892;&#28145;&#24230;&#23398;&#20064;&#65306;&#32806;&#21512;&#20132;&#21449;&#29109;&#26368;&#23567;&#21270;&#12289;&#21487;&#35782;&#21035;&#24615;&#21644;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
Deep Learning From Crowdsourced Labels: Coupled Cross-entropy Minimization, Identifiability, and Regularization. (arXiv:2306.03288v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03288
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#20247;&#21253;&#26631;&#31614;&#36827;&#34892;&#28145;&#24230;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#32806;&#21512;&#20132;&#21449;&#29109;&#26368;&#23567;&#21270;&#21644;&#27491;&#21017;&#21270;&#20351;&#23398;&#20064;&#36807;&#31243;&#26356;&#21152;&#40065;&#26834;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#24615;&#33021;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#22810;&#20010;&#27880;&#37322;&#32773;&#25552;&#20379;&#30340;&#26377;&#22122;&#22768;&#30340;&#20247;&#21253;&#26631;&#31614;&#65292;&#19968;&#20010;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#31471;&#21040;&#31471; (E2E) &#31995;&#32479;&#26088;&#22312;&#21516;&#26102;&#23398;&#20064;&#26631;&#31614;&#26657;&#27491;&#26426;&#21046;&#21644;&#31070;&#32463;&#20998;&#31867;&#22120;&#12290;&#32806;&#21512;&#20132;&#21449;&#29109;&#26368;&#23567;&#21270; (CCEM) &#31867;&#22411;&#20934;&#21017;&#30452;&#35266;&#19988;&#22312;&#23454;&#36341;&#20013;&#34920;&#29616;&#33391;&#22909;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#23545; CCEM &#20934;&#21017;&#30340;&#24615;&#33021;&#20445;&#35777;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#20174;&#32780;&#20351;&#23398;&#20064;&#36807;&#31243;&#26356;&#21152;&#40065;&#26834;&#12290;
&lt;/p&gt;
&lt;p&gt;
Using noisy crowdsourced labels from multiple annotators, a deep learning-based end-to-end (E2E) system aims to learn the label correction mechanism and the neural classifier simultaneously. To this end, many E2E systems concatenate the neural classifier with multiple annotator-specific ``label confusion'' layers and co-train the two parts in a parameter-coupled manner. The formulated coupled cross-entropy minimization (CCEM)-type criteria are intuitive and work well in practice. Nonetheless, theoretical understanding of the CCEM criterion has been limited. The contribution of this work is twofold: First, performance guarantees of the CCEM criterion are presented. Our analysis reveals for the first time that the CCEM can indeed correctly identify the annotators' confusion characteristics and the desired ``ground-truth'' neural classifier under realistic conditions, e.g., when only incomplete annotator labeling and finite samples are available. Second, based on the insights learned from
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;$(k, t)$-FWL&#21644;$k$-FWL+&#20004;&#31181;&#26041;&#27861;&#65292;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#23427;&#20204;&#21487;&#20197;&#22312;$O(n^2)$&#30340;&#31354;&#38388;&#22797;&#26434;&#24230;&#19979;&#65292;&#35299;&#20915;&#22270;&#21516;&#26500;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.03266</link><description>&lt;p&gt;
&#36890;&#36807;&#37325;&#26032;&#24605;&#32771;&#27665;&#38388;&#23041;&#26031;&#36153;&#21202;-&#33713;&#26364;&#31639;&#27861;&#65292;&#23454;&#29616;$O(n^2)$&#31354;&#38388;&#20869;&#20219;&#24847;&#34920;&#36798;&#33021;&#21147;&#30340;GNNs
&lt;/p&gt;
&lt;p&gt;
Towards Arbitrarily Expressive GNNs in $O(n^2)$ Space by Rethinking Folklore Weisfeiler-Lehman. (arXiv:2306.03266v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03266
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;$(k, t)$-FWL&#21644;$k$-FWL+&#20004;&#31181;&#26041;&#27861;&#65292;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#23427;&#20204;&#21487;&#20197;&#22312;$O(n^2)$&#30340;&#31354;&#38388;&#22797;&#26434;&#24230;&#19979;&#65292;&#35299;&#20915;&#22270;&#21516;&#26500;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#28040;&#24687;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#65288;MPNNs&#65289;&#24050;&#25104;&#20026;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#20013;&#26368;&#21463;&#27426;&#36814;&#30340;&#26694;&#26550;&#12290;&#28982;&#32780;&#65292;&#20854;&#34920;&#36798;&#33021;&#21147;&#21463;&#21040;&#19968;&#32500;&#23041;&#26031;&#36153;&#21202;-&#33713;&#26364;&#65288;1-WL&#65289;&#27979;&#35797;&#30340;&#38480;&#21046;&#12290;&#19968;&#20123;&#30740;&#31350;&#21463;&#21040;$k$-WL/FWL&#65288;&#27665;&#38388;WL&#65289;&#30340;&#21551;&#21457;&#24182;&#35774;&#35745;&#20854;&#30456;&#24212;&#30340;&#31070;&#32463;&#29256;&#26412;&#12290;&#23613;&#31649;&#20855;&#26377;&#24456;&#39640;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#20294;&#36825;&#19968;&#30740;&#31350;&#26041;&#21521;&#23384;&#22312;&#20005;&#37325;&#23616;&#38480;&#24615;&#12290;&#20026;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#20316;&#32773;&#25552;&#20986;&#20102;$(k, t)$-FWL&#21644;$k$-FWL+&#65292;&#24182;&#22312;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Message passing neural networks (MPNNs) have emerged as the most popular framework of graph neural networks (GNNs) in recent years. However, their expressive power is limited by the 1-dimensional Weisfeiler-Lehman (1-WL) test. Some works are inspired by $k$-WL/FWL (Folklore WL) and design the corresponding neural versions. Despite the high expressive power, there are serious limitations in this line of research. In particular, (1) $k$-WL/FWL requires at least $O(n^k)$ space complexity, which is impractical for large graphs even when $k=3$; (2) The design space of $k$-WL/FWL is rigid, with the only adjustable hyper-parameter being $k$. To tackle the first limitation, we propose an extension, $(k, t)$-FWL. We theoretically prove that even if we fix the space complexity to $O(n^2)$ in $(k, t)$-FWL, we can construct an expressiveness hierarchy up to solving the graph isomorphism problem. To tackle the second problem, we propose $k$-FWL+, which considers any equivariant set as neighbors ins
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#37327;&#21270;&#36755;&#20837;&#29305;&#24449;&#21644;&#36755;&#20986;&#26631;&#31614;&#20043;&#38388;&#30340;&#26465;&#20214;&#20559;&#31227;&#37327;&#65292;&#23545;&#22270;&#31070;&#32463;&#32593;&#32476;&#26131;&#21463;&#20998;&#24067;&#20559;&#31227;&#24433;&#21709;&#30340;&#38382;&#39064;&#36827;&#34892;&#29702;&#35770;&#20998;&#26512;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#22270;&#24418;&#24322;&#36136;&#24615;&#21644;&#27169;&#22411;&#26550;&#26500;&#37117;&#20250;&#23548;&#33268;&#26465;&#20214;&#20559;&#31227;&#65292;&#24433;&#21709;&#24615;&#33021;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#26465;&#20214;&#20559;&#31227;&#30340;&#20272;&#35745;&#21644;&#26368;&#23567;&#21270;&#26469;&#24212;&#23545;&#36825;&#19968;&#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#22312;&#33410;&#28857;&#20998;&#31867;&#21644;&#22270;&#20998;&#31867;&#20219;&#21153;&#19978;&#34920;&#29616;&#26356;&#20248;&#12290;</title><link>http://arxiv.org/abs/2306.03256</link><description>&lt;p&gt;
&#35299;&#37322;&#19982;&#35843;&#25972;&#22270;&#24418;&#26465;&#20214;&#36716;&#31227;
&lt;/p&gt;
&lt;p&gt;
Explaining and Adapting Graph Conditional Shift. (arXiv:2306.03256v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03256
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#37327;&#21270;&#36755;&#20837;&#29305;&#24449;&#21644;&#36755;&#20986;&#26631;&#31614;&#20043;&#38388;&#30340;&#26465;&#20214;&#20559;&#31227;&#37327;&#65292;&#23545;&#22270;&#31070;&#32463;&#32593;&#32476;&#26131;&#21463;&#20998;&#24067;&#20559;&#31227;&#24433;&#21709;&#30340;&#38382;&#39064;&#36827;&#34892;&#29702;&#35770;&#20998;&#26512;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#22270;&#24418;&#24322;&#36136;&#24615;&#21644;&#27169;&#22411;&#26550;&#26500;&#37117;&#20250;&#23548;&#33268;&#26465;&#20214;&#20559;&#31227;&#65292;&#24433;&#21709;&#24615;&#33021;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#26465;&#20214;&#20559;&#31227;&#30340;&#20272;&#35745;&#21644;&#26368;&#23567;&#21270;&#26469;&#24212;&#23545;&#36825;&#19968;&#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#22312;&#33410;&#28857;&#20998;&#31867;&#21644;&#22270;&#20998;&#31867;&#20219;&#21153;&#19978;&#34920;&#29616;&#26356;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#22270;&#32467;&#26500;&#25968;&#25454;&#19978;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#23454;&#35777;&#30740;&#31350;&#34920;&#26126;&#65292;GNN&#38750;&#24120;&#23481;&#26131;&#21463;&#21040;&#20998;&#24067;&#20559;&#31227;&#30340;&#24433;&#21709;&#12290;&#30446;&#21069;&#20851;&#20110;&#20026;&#20160;&#20040;&#22522;&#20110;&#22270;&#24418;&#30340;&#27169;&#22411;&#20284;&#20046;&#26356;&#23481;&#26131;&#21463;&#21040;&#36825;&#20123;&#20559;&#31227;&#24433;&#21709;&#30340;&#38382;&#39064;&#36824;&#23384;&#22312;&#26174;&#33879;&#30340;&#27495;&#20041;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#37327;&#21270;&#36755;&#20837;&#29305;&#24449;&#21644;&#36755;&#20986;&#26631;&#31614;&#20043;&#38388;&#30340;&#26465;&#20214;&#20559;&#31227;&#37327;&#65292;&#23545;&#23427;&#36827;&#34892;&#20102;&#24443;&#24213;&#30340;&#29702;&#35770;&#20998;&#26512;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22270;&#24418;&#24322;&#36136;&#24615;&#21644;&#27169;&#22411;&#26550;&#26500;&#37117;&#21152;&#21095;&#20102;&#26465;&#20214;&#20559;&#31227;&#65292;&#23548;&#33268;&#24615;&#33021;&#19979;&#38477;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#28041;&#21450;&#23545;&#22270;&#24418;&#19978;&#30340;&#26080;&#30417;&#30563;&#22495;&#36866;&#24212;&#24615;&#36827;&#34892;&#26465;&#20214;&#20559;&#31227;&#30340;&#20272;&#35745;&#21644;&#26368;&#23567;&#21270;&#12290;&#22312;&#25105;&#20204;&#30340;&#25511;&#21046;&#24615;&#32508;&#21512;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#34920;&#29616;&#20986;&#23545;&#20998;&#24067;&#20559;&#31227;&#30340;&#40065;&#26834;&#24615;&#65292;&#30456;&#23545;&#31532;&#20108;&#20248;&#31639;&#27861;&#23454;&#29616;&#20102;&#39640;&#36798;10%&#30340;ROC AUC&#32477;&#23545;&#25913;&#21892;&#12290;&#27492;&#22806;&#65292;&#23545;&#33410;&#28857;&#20998;&#31867;&#21644;&#22270;&#20998;&#31867;&#20219;&#21153;&#30340;&#20840;&#38754;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22987;&#32456;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#22495;&#36866;&#24212;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Networks (GNNs) have shown remarkable performance on graph-structured data. However, recent empirical studies suggest that GNNs are very susceptible to distribution shift. There is still significant ambiguity about why graph-based models seem more vulnerable to these shifts. In this work we provide a thorough theoretical analysis on it by quantifying the magnitude of conditional shift between the input features and the output label. Our findings show that both graph heterophily and model architecture exacerbate conditional shifts, leading to performance degradation. To address this, we propose an approach that involves estimating and minimizing the conditional shift for unsupervised domain adaptation on graphs. In our controlled synthetic experiments, our algorithm demonstrates robustness towards distribution shift, resulting in up to 10% absolute ROC AUC improvement versus the second-best algorithm. Furthermore, comprehensive experiments on both node classification and gr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#38750;&#32447;&#24615;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#31639;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#19968;&#31867;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807; Gateaux Derivative &#22788;&#29702;&#19968;&#33324;&#39118;&#38505;&#24230;&#37327;&#12290;&#32463;&#36807;&#23454;&#39564;&#39564;&#35777;&#65292;&#35813;&#26041;&#27861;&#25104;&#21151;&#22788;&#29702;&#20998;&#24067;&#30340;&#38750;&#32447;&#24615;&#30446;&#26631;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2306.03202</link><description>&lt;p&gt;
&#38750;&#32447;&#24615;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Nonlinear Distributionally Robust Optimization. (arXiv:2306.03202v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03202
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#38750;&#32447;&#24615;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#31639;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#19968;&#31867;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807; Gateaux Derivative &#22788;&#29702;&#19968;&#33324;&#39118;&#38505;&#24230;&#37327;&#12290;&#32463;&#36807;&#23454;&#39564;&#39564;&#35777;&#65292;&#35813;&#26041;&#27861;&#25104;&#21151;&#22788;&#29702;&#20998;&#24067;&#30340;&#38750;&#32447;&#24615;&#30446;&#26631;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20851;&#27880;&#19968;&#31867;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#65288;DRO&#65289;&#38382;&#39064;&#65292;&#20854;&#20013;&#30446;&#26631;&#20989;&#25968;&#22312;&#20998;&#24067;&#19978;&#21487;&#33021;&#26159;&#38750;&#32447;&#24615;&#30340;&#65292;&#36825;&#19982;&#29616;&#26377;&#30340;&#25991;&#29486;&#26377;&#25152;&#19981;&#21516;&#12290;&#20026;&#35299;&#20915;&#22312;&#27010;&#29575;&#31354;&#38388;&#20013;&#20248;&#21270;&#38750;&#32447;&#24615;&#20989;&#25968;&#38754;&#20020;&#30340;&#29702;&#35770;&#21644;&#35745;&#31639;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;Derivative&#21644;&#30456;&#24212;&#30340;&#24179;&#28369;&#24230;&#27010;&#24565;&#65292;&#22522;&#20110;Gateaux Derivative&#26469;&#22788;&#29702;&#19968;&#33324;&#39118;&#38505;&#24230;&#37327;&#12290;&#25105;&#20204;&#36890;&#36807;Var&#12289;entropic risk&#21644;&#26377;&#38480;&#25903;&#25345;&#38598;&#19978;&#30340;&#19977;&#20010;&#36816;&#34892;&#39118;&#38505;&#24230;&#37327;&#31034;&#20363;&#26469;&#35299;&#37322;&#36825;&#20123;&#27010;&#24565;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20026;&#27010;&#29575;&#31354;&#38388;&#20013;&#19968;&#33324;&#38750;&#32447;&#24615;&#20248;&#21270;&#38382;&#39064;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;G-derivative&#30340;Frank-Wolfe&#65288;FW&#65289;&#31639;&#27861;&#65292;&#24182;&#20197;&#23436;&#20840;&#29420;&#31435;&#20110;&#33539;&#25968;&#30340;&#26041;&#24335;&#25512;&#23548;&#20986;&#20854;&#25910;&#25947;&#24615;&#22312;&#25552;&#20986;&#30340;&#24179;&#28369;&#24230;&#27010;&#24565;&#19979;&#12290;&#25105;&#20204;&#21033;&#29992;FW&#31639;&#27861;&#30340;&#35774;&#32622;&#26469;&#35774;&#35745;&#19968;&#31181;&#35745;&#31639;&#38750;&#32447;&#24615;DRO&#38382;&#39064;&#38797;&#28857;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#22788;&#29702;&#20998;&#24067;&#30340;&#38750;&#32447;&#24615;&#30446;&#26631;&#20989;&#25968;&#30340;&#25104;&#21151;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article focuses on a class of distributionally robust optimization (DRO) problems where, unlike the growing body of the literature, the objective function is potentially non-linear in the distribution. Existing methods to optimize nonlinear functions in probability space use the Frechet derivatives, which present both theoretical and computational challenges. Motivated by this, we propose an alternative notion for the derivative and corresponding smoothness based on Gateaux (G)-derivative for generic risk measures. These concepts are explained via three running risk measure examples of variance, entropic risk, and risk on finite support sets. We then propose a G-derivative based Frank-Wolfe~(FW) algorithm for generic non-linear optimization problems in probability spaces and establish its convergence under the proposed notion of smoothness in a completely norm-independent manner. We use the set-up of the FW algorithm to devise a methodology to compute a saddle point of the non-lin
&lt;/p&gt;</description></item><item><title>LatFormer&#26159;&#19968;&#31181;&#23558;&#26684;&#28857;&#23545;&#31216;&#20808;&#39564;&#34701;&#20837;&#21040;&#27880;&#24847;&#21147;&#25513;&#30721;&#20013;&#30340;&#27169;&#22411;&#65292;&#33021;&#22815;&#29992;&#21367;&#31215;&#32593;&#32476;&#29983;&#25104;&#36719;&#25513;&#30721;&#26469;&#35843;&#25972;&#27880;&#24847;&#21147;&#26435;&#37325;&#12290;&#35813;&#27169;&#22411;&#22312;&#21512;&#25104;&#20960;&#20309;&#25512;&#29702;&#20013;&#21462;&#24471;&#20102;&#36739;&#22909;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.03175</link><description>&lt;p&gt;
&#22522;&#20110;&#26684;&#28857;&#23545;&#27880;&#24847;&#26426;&#21046;&#36827;&#34892;&#20808;&#39564;&#21152;&#20837;&#65292;&#20197;&#25552;&#39640;&#25277;&#35937;&#20960;&#20309;&#25512;&#29702;&#30340;&#26679;&#26412;&#25928;&#29575;
&lt;/p&gt;
&lt;p&gt;
Infusing Lattice Symmetry Priors in Attention Mechanisms for Sample-Efficient Abstract Geometric Reasoning. (arXiv:2306.03175v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03175
&lt;/p&gt;
&lt;p&gt;
LatFormer&#26159;&#19968;&#31181;&#23558;&#26684;&#28857;&#23545;&#31216;&#20808;&#39564;&#34701;&#20837;&#21040;&#27880;&#24847;&#21147;&#25513;&#30721;&#20013;&#30340;&#27169;&#22411;&#65292;&#33021;&#22815;&#29992;&#21367;&#31215;&#32593;&#32476;&#29983;&#25104;&#36719;&#25513;&#30721;&#26469;&#35843;&#25972;&#27880;&#24847;&#21147;&#26435;&#37325;&#12290;&#35813;&#27169;&#22411;&#22312;&#21512;&#25104;&#20960;&#20309;&#25512;&#29702;&#20013;&#21462;&#24471;&#20102;&#36739;&#22909;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25277;&#35937;&#21644;&#25512;&#29702;&#35821;&#26009;&#24211;&#65288;ARC&#65289;&#21450;&#20854;&#26368;&#36817;&#30340;&#35821;&#35328;&#23436;&#25972;&#23454;&#20363;&#65288;LARC&#65289;&#34987;&#35748;&#20026;&#26159;&#36890;&#24448;&#36890;&#29992;&#20154;&#24037;&#26234;&#33021;&#30340;&#37325;&#35201;&#19968;&#27493;&#12290;&#28982;&#32780;&#65292;&#21363;&#20351;&#26159;&#26368;&#20808;&#36827;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#36825;&#20123;&#38382;&#39064;&#19978;&#20063;&#38590;&#20197;&#23454;&#29616;&#26377;&#24847;&#20041;&#30340;&#24615;&#33021;&#65292;&#33853;&#21518;&#20110;&#38750;&#23398;&#20064;&#26041;&#27861;&#12290;&#25105;&#20204;&#35748;&#20026;&#35299;&#20915;&#36825;&#20123;&#20219;&#21153;&#38656;&#35201;&#26497;&#31471;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#21482;&#26377;&#36890;&#36807;&#36866;&#24403;&#32771;&#34385;&#26680;&#24515;&#30693;&#35782;&#20808;&#39564;&#25165;&#33021;&#23454;&#29616;&#12290;&#20026;&#20102;&#36798;&#21040;&#36825;&#20010;&#30446;&#26631;&#65292;&#25105;&#20204;&#32858;&#28966;&#20110;&#20960;&#20309;&#20808;&#39564;&#65292;&#24182;&#24341;&#20837;LatFormer&#27169;&#22411;&#65292;&#23558;&#26684;&#28857;&#23545;&#31216;&#20808;&#39564;&#34701;&#20837;&#21040;&#27880;&#24847;&#21147;&#25513;&#30721;&#20013;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#36229;&#31435;&#26041;&#26684;&#30340;&#20219;&#20309;&#21464;&#25442;&#65292;&#37117;&#23384;&#22312;&#19968;&#20010;&#20108;&#20540;&#27880;&#24847;&#21147;&#25513;&#30721;&#26469;&#23454;&#29616;&#35813;&#32676;&#20316;&#29992;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#28608;&#21457;&#20102;&#23545;&#26631;&#20934;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#20462;&#25913;&#65292;&#20854;&#20013;&#20351;&#29992;&#21367;&#31215;&#32593;&#32476;&#29983;&#25104;&#30340;&#36719;&#25513;&#30721;&#26469;&#35843;&#25972;&#20851;&#27880;&#26435;&#37325;&#12290;&#22312;&#21512;&#25104;&#20960;&#20309;&#25512;&#29702;&#26041;&#38754;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;LatFormer
&lt;/p&gt;
&lt;p&gt;
The Abstraction and Reasoning Corpus (ARC) (Chollet, 2019) and its most recent language-complete instantiation (LARC) has been postulated as an important step towards general AI. Yet, even state-of-the-art machine learning models struggle to achieve meaningful performance on these problems, falling behind non-learning based approaches. We argue that solving these tasks requires extreme generalization that can only be achieved by proper accounting for core knowledge priors. As a step towards this goal, we focus on geometry priors and introduce LatFormer, a model that incorporates lattice symmetry priors in attention masks. We show that, for any transformation of the hypercubic lattice, there exists a binary attention mask that implements that group action. Hence, our study motivates a modification to the standard attention mechanism, where attention weights are scaled using soft masks generated by a convolutional network. Experiments on synthetic geometric reasoning show that LatFormer 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;BootGen&#31639;&#27861;&#65292;&#20351;&#29992;&#20195;&#29702;&#24471;&#20998;&#20989;&#25968;&#22686;&#24378;&#29983;&#29289;&#24207;&#21015;&#29983;&#25104;&#22120;&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#65292;&#24182;&#20135;&#29983;&#22810;&#26679;&#21270;&#30340;&#35774;&#35745;&#65292;&#23558;&#20854;&#24212;&#29992;&#20110;&#20248;&#21270;&#29983;&#29289;&#24207;&#21015;&#65292;&#21462;&#24471;&#20102;&#27604;&#31454;&#20105;&#23545;&#25163;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.03111</link><description>&lt;p&gt;
&#38024;&#23545;&#31163;&#32447;&#35774;&#35745;&#29983;&#29289;&#24207;&#21015;&#30340;&#24471;&#20998;&#26465;&#20214;&#29983;&#25104;&#22120;&#30340;&#33258;&#21161;&#22686;&#24378;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Bootstrapped Training of Score-Conditioned Generator for Offline Design of Biological Sequences. (arXiv:2306.03111v1 [q-bio.QM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03111
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;BootGen&#31639;&#27861;&#65292;&#20351;&#29992;&#20195;&#29702;&#24471;&#20998;&#20989;&#25968;&#22686;&#24378;&#29983;&#29289;&#24207;&#21015;&#29983;&#25104;&#22120;&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#65292;&#24182;&#20135;&#29983;&#22810;&#26679;&#21270;&#30340;&#35774;&#35745;&#65292;&#23558;&#20854;&#24212;&#29992;&#20110;&#20248;&#21270;&#29983;&#29289;&#24207;&#21015;&#65292;&#21462;&#24471;&#20102;&#27604;&#31454;&#20105;&#23545;&#25163;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20248;&#21270;&#29983;&#29289;&#24207;&#21015;&#65288;&#22914;&#34507;&#30333;&#36136;&#12289;DNA&#21644;RNA&#65289;&#20197;&#26368;&#22823;&#21270;&#20165;&#22312;&#31163;&#32447;&#25968;&#25454;&#38598;&#20013;&#35780;&#20272;&#30340;&#40657;&#21283;&#23376;&#24471;&#20998;&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#35299;&#20915;&#26041;&#26696;&#8212;&#8212;&#24471;&#20998;&#26465;&#20214;&#29983;&#25104;&#22120;&#30340;&#33258;&#21161;&#22686;&#24378;&#35757;&#32451;&#65288;BootGen&#65289;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#37325;&#22797;&#20102;&#19968;&#20010;&#20004;&#38454;&#27573;&#36807;&#31243;&#12290;&#22312;&#31532;&#19968;&#38454;&#27573;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#20351;&#29992;&#25490;&#21517;&#21152;&#26435;&#27861;&#35757;&#32451;&#29983;&#29289;&#24207;&#21015;&#29983;&#25104;&#22120;&#65292;&#20197;&#25552;&#39640;&#22522;&#20110;&#39640;&#20998;&#25968;&#30340;&#24207;&#21015;&#29983;&#25104;&#30340;&#20934;&#30830;&#24615;&#12290;&#25509;&#19979;&#26469;&#30340;&#38454;&#27573;&#28041;&#21450;&#21040;&#33258;&#21161;&#22686;&#24378;&#65292;&#36890;&#36807;&#33258;&#21160;&#29983;&#25104;&#30340;&#25968;&#25454;&#24182;&#26631;&#35760;&#20195;&#29702;&#24471;&#20998;&#20989;&#25968;&#65292;&#26469;&#22686;&#24378;&#35757;&#32451;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#24605;&#24819;&#26159;&#23558;&#22522;&#20110;&#24471;&#20998;&#30340;&#29983;&#25104;&#19982;&#20195;&#29702;&#24471;&#20998;&#20989;&#25968;&#23545;&#40784;&#65292;&#23558;&#20195;&#29702;&#24471;&#20998;&#20989;&#25968;&#30340;&#30693;&#35782;&#20256;&#36882;&#32473;&#29983;&#25104;&#22120;&#12290;&#35757;&#32451;&#21518;&#65292;&#25105;&#20204;&#32858;&#21512;&#26469;&#33258;&#22810;&#20010;&#33258;&#21161;&#22686;&#24378;&#29983;&#25104;&#22120;&#21644;&#20195;&#29702;&#30340;&#26679;&#26412;&#65292;&#20135;&#29983;&#22810;&#26679;&#21270;&#30340;&#35774;&#35745;&#12290;&#22823;&#37327;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#29983;&#29289;&#24207;&#21015;&#20248;&#21270;&#26041;&#38754;&#32988;&#36807;&#31454;&#20105;&#23545;&#25163;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of optimizing biological sequences, e.g., proteins, DNA, and RNA, to maximize a black-box score function that is only evaluated in an offline dataset. We propose a novel solution, bootstrapped training of score-conditioned generator (BootGen) algorithm. Our algorithm repeats a two-stage process. In the first stage, our algorithm trains the biological sequence generator with rank-based weights to enhance the accuracy of sequence generation based on high scores. The subsequent stage involves bootstrapping, which augments the training dataset with self-generated data labeled by a proxy score function. Our key idea is to align the score-based generation with a proxy score function, which distills the knowledge of the proxy score function to the generator. After training, we aggregate samples from multiple bootstrapped generators and proxies to produce a diverse design. Extensive experiments show that our method outperforms competitive baselines on biological sequential
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35777;&#26126;&#20102;&#20351;&#29992;Mixup&#35757;&#32451;&#20855;&#26377;&#21487;&#35777;&#23454;&#30340;&#30410;&#22788;&#65292;&#21487;&#20197;&#26174;&#33879;&#38477;&#20302;&#22312;&#26356;&#21487;&#20998;&#31163;&#25968;&#25454;&#20998;&#24067;&#20013;&#23547;&#25214;&#26368;&#20339;&#20915;&#31574;&#36793;&#30028;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2306.00267</link><description>&lt;p&gt;
Mixup&#22312;&#23547;&#25214;&#26368;&#20339;&#20915;&#31574;&#36793;&#30028;&#20013;&#30340;&#21487;&#35777;&#23454;&#30410;&#22788;
&lt;/p&gt;
&lt;p&gt;
Provable Benefit of Mixup for Finding Optimal Decision Boundaries. (arXiv:2306.00267v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00267
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35777;&#26126;&#20102;&#20351;&#29992;Mixup&#35757;&#32451;&#20855;&#26377;&#21487;&#35777;&#23454;&#30340;&#30410;&#22788;&#65292;&#21487;&#20197;&#26174;&#33879;&#38477;&#20302;&#22312;&#26356;&#21487;&#20998;&#31163;&#25968;&#25454;&#20998;&#24067;&#20013;&#23547;&#25214;&#26368;&#20339;&#20915;&#31574;&#36793;&#30028;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20687;Mixup&#36825;&#26679;&#30340;&#25104;&#23545;&#25968;&#25454;&#22686;&#24378;&#25216;&#26415;&#22914;&#20309;&#24433;&#21709;&#22312;&#20108;&#20803;&#32447;&#24615;&#20998;&#31867;&#38382;&#39064;&#20013;&#23547;&#25214;&#26368;&#20339;&#20915;&#31574;&#36793;&#30028;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#38024;&#23545;&#19968;&#31867;&#20855;&#26377;&#21487;&#20998;&#31163;&#24120;&#25968;$\kappa$&#30340;&#25968;&#25454;&#20998;&#24067;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#35757;&#32451;&#25439;&#22833;&#26368;&#20248;&#20998;&#31867;&#22120;&#19982;&#27979;&#35797;&#20934;&#30830;&#29575;&#26368;&#20248;&#20998;&#31867;&#22120;&#65288;&#21363;&#36125;&#21494;&#26031;&#26368;&#20248;&#20998;&#31867;&#22120;&#65289;&#20043;&#38388;&#30340;&#23545;&#40784;&#31243;&#24230;&#12290;&#23545;&#20110;&#27809;&#26377;&#22686;&#24378;&#30340;&#26222;&#36890;&#35757;&#32451;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#19968;&#31181;&#26377;&#36259;&#30340;&#29616;&#35937;&#65292;&#31216;&#20026;&#21487;&#20998;&#31163;&#24615;&#30340;&#35781;&#21650;&#12290;&#38543;&#30528;&#25105;&#20204;&#22686;&#21152;$\kappa$&#20351;&#25968;&#25454;&#20998;&#24067;&#26356;&#21152;&#21487;&#20998;&#31163;&#65292;&#26222;&#36890;&#35757;&#32451;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20250;&#22312;$\kappa$&#20013;&#21576;&#25351;&#25968;&#22686;&#38271;&#12290;&#20063;&#35768;&#26356;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#23545;&#20110;&#26356;&#21487;&#20998;&#31163;&#30340;&#25968;&#25454;&#20998;&#24067;&#32780;&#35328;&#65292;&#23547;&#25214;&#26368;&#20339;&#20915;&#31574;&#36793;&#30028;&#30340;&#20219;&#21153;&#21464;&#24471;&#26356;&#21152;&#22256;&#38590;&#12290;&#38024;&#23545;Mixup&#35757;&#32451;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;Mixup&#20943;&#36731;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#36890;&#36807;&#26174;&#33879;&#38477;&#20302;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#36866;&#29992;&#20110;Mixup&#32771;&#34385;&#30340;$n^2$&#25104;&#23545;&#22686;&#24378;&#25968;&#25454;&#28857;&#30340;&#26032;&#30340;&#38598;&#20013;&#32467;&#26524;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25552;&#20379;&#20102;&#20851;&#20110;Mixup&#30340;&#27867;&#21270;&#30410;&#22788;&#30340;&#21487;&#35777;&#20445;&#35777;&#65292;&#24182;&#25552;&#20379;&#20102;&#29702;&#35299;Mixup&#20026;&#20160;&#20040;&#22312;&#23454;&#36341;&#20013;&#34920;&#29616;&#33391;&#22909;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate how pair-wise data augmentation techniques like Mixup affect the sample complexity of finding optimal decision boundaries in a binary linear classification problem. For a family of data distributions with a separability constant $\kappa$, we analyze how well the optimal classifier in terms of training loss aligns with the optimal one in test accuracy (i.e., Bayes optimal classifier). For vanilla training without augmentation, we uncover an interesting phenomenon named the curse of separability. As we increase $\kappa$ to make the data distribution more separable, the sample complexity of vanilla training increases exponentially in $\kappa$; perhaps surprisingly, the task of finding optimal decision boundaries becomes harder for more separable distributions. For Mixup training, we show that Mixup mitigates this problem by significantly reducing the sample complexity. To this end, we develop new concentration results applicable to $n^2$ pair-wise augmented data points cons
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#31350;&#20102;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#20559;&#35265;&#65292;&#21457;&#29616;&#22312;ReLU&#32593;&#32476;&#20013;&#28155;&#21152;&#32447;&#24615;&#23618;&#26377;&#21161;&#20110;&#36924;&#36817;&#20855;&#26377;&#20302;&#31209;&#32447;&#24615;&#31639;&#23376;&#21644;&#20302;&#34920;&#31034;&#25104;&#26412;&#20989;&#25968;&#32452;&#25104;&#30340;&#20989;&#25968;&#65292;&#20174;&#32780;&#24471;&#21040;&#19968;&#20010;&#19982;&#20302;&#32500;&#23376;&#31354;&#38388;&#22402;&#30452;&#26041;&#21521;&#36817;&#20046;&#24658;&#23450;&#30340;&#25554;&#20540;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2305.15598</link><description>&lt;p&gt;
&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#23618;&#20419;&#36827;&#23398;&#20064;&#21333;&#25351;&#25968;&#21644;&#22810;&#25351;&#25968;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Linear Neural Network Layers Promote Learning Single- and Multiple-Index Models. (arXiv:2305.15598v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15598
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#31350;&#20102;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#20559;&#35265;&#65292;&#21457;&#29616;&#22312;ReLU&#32593;&#32476;&#20013;&#28155;&#21152;&#32447;&#24615;&#23618;&#26377;&#21161;&#20110;&#36924;&#36817;&#20855;&#26377;&#20302;&#31209;&#32447;&#24615;&#31639;&#23376;&#21644;&#20302;&#34920;&#31034;&#25104;&#26412;&#20989;&#25968;&#32452;&#25104;&#30340;&#20989;&#25968;&#65292;&#20174;&#32780;&#24471;&#21040;&#19968;&#20010;&#19982;&#20302;&#32500;&#23376;&#31354;&#38388;&#22402;&#30452;&#26041;&#21521;&#36817;&#20046;&#24658;&#23450;&#30340;&#25554;&#20540;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#31350;&#20102;&#28145;&#24230;&#22823;&#20110;&#20004;&#23618;&#30340;&#36807;&#24230;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#30340;&#38544;&#21547;&#20559;&#35265;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#32771;&#34385;&#20102;&#19968;&#31867;&#28145;&#24230;&#19981;&#21516;&#20294;&#23481;&#37327;&#30456;&#21516;&#30340;&#32593;&#32476;&#65292;&#23427;&#20204;&#20855;&#26377;&#19981;&#21516;&#30340;&#26174;&#24335;&#23450;&#20041;&#30340;&#34920;&#31034;&#25104;&#26412;&#12290;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#35825;&#23548;&#30340;&#20989;&#25968;&#30340;&#34920;&#31034;&#25104;&#26412;&#26159;&#32593;&#32476;&#34920;&#31034;&#35813;&#20989;&#25968;&#25152;&#38656;&#30340;&#24179;&#26041;&#26435;&#37325;&#20043;&#21644;&#30340;&#26368;&#23567;&#20540;&#65307;&#23427;&#21453;&#26144;&#20102;&#19982;&#35813;&#26550;&#26500;&#30456;&#20851;&#30340;&#20989;&#25968;&#31354;&#38388;&#20559;&#24046;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#23558;&#32447;&#24615;&#23618;&#28155;&#21152;&#21040;ReLU&#32593;&#32476;&#20250;&#20135;&#29983;&#19968;&#20010;&#34920;&#31034;&#25104;&#26412;&#65292;&#36825;&#26377;&#21033;&#20110;&#20351;&#29992;&#20004;&#23618;&#32593;&#32476;&#26469;&#36924;&#36817;&#30001;&#20302;&#31209;&#32447;&#24615;&#31639;&#23376;&#21644;&#20855;&#26377;&#20302;&#34920;&#31034;&#25104;&#26412;&#30340;&#20989;&#25968;&#32452;&#25104;&#30340;&#20989;&#25968;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#20197;&#26368;&#23567;&#30340;&#34920;&#31034;&#25104;&#26412;&#25311;&#21512;&#35757;&#32451;&#25968;&#25454;&#20250;&#24471;&#21040;&#19968;&#20010;&#19982;&#20302;&#32500;&#23376;&#31354;&#38388;&#22402;&#30452;&#26041;&#21521;&#36817;&#20046;&#24658;&#23450;&#30340;&#25554;&#20540;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper explores the implicit bias of overparameterized neural networks of depth greater than two layers. Our framework considers a family of networks of varying depths that all have the same capacity but different implicitly defined representation costs. The representation cost of a function induced by a neural network architecture is the minimum sum of squared weights needed for the network to represent the function; it reflects the function space bias associated with the architecture. Our results show that adding linear layers to a ReLU network yields a representation cost that favors functions that can be approximated by a low-rank linear operator composed with a function with low representation cost using a two-layer network. Specifically, using a neural network to fit training data with minimum representation cost yields an interpolating function that is nearly constant in directions orthogonal to a low-dimensional subspace. This means that the learned network will approximate
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#23454;&#29992;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#20219;&#24847;&#20002;&#22833;&#27169;&#24335;&#19979;&#26377;&#25928;&#22320;&#20445;&#35777;&#35206;&#30422;&#29575;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#37327;&#21270;&#20102;&#32570;&#22833;&#23545;&#39044;&#27979;&#31934;&#24230;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2305.11640</link><description>&lt;p&gt;
&#20219;&#24847;&#32570;&#22833;&#27169;&#24335;&#19979;&#30340;&#26080;&#20998;&#24067;&#30697;&#38453;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Distribution-Free Matrix Prediction Under Arbitrary Missing Pattern. (arXiv:2305.11640v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11640
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#23454;&#29992;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#20219;&#24847;&#20002;&#22833;&#27169;&#24335;&#19979;&#26377;&#25928;&#22320;&#20445;&#35777;&#35206;&#30422;&#29575;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#37327;&#21270;&#20102;&#32570;&#22833;&#23545;&#39044;&#27979;&#31934;&#24230;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#34892;/&#21015;&#21487;&#20132;&#25442;&#30697;&#38453;&#20013;&#39044;&#27979;&#32570;&#22833;&#26465;&#30446;&#30340;&#38382;&#39064;&#12290;&#34429;&#28982;&#30697;&#38453;&#35774;&#32622;&#25552;&#20986;&#20102;&#26032;&#39062;&#21644;&#29420;&#29305;&#30340;&#25361;&#25112;&#65292;&#20294;&#26159;&#22312;&#36825;&#20010;&#26377;&#36259;&#30340;&#20027;&#39064;&#19978;&#23384;&#22312;&#24456;&#23569;&#30340;&#24037;&#20316;&#12290;&#25105;&#20204;&#31934;&#32454;&#22320;&#23450;&#20041;&#20102;&#38382;&#39064;&#65292;&#23558;&#20854;&#19982;&#23494;&#20999;&#30456;&#20851;&#30340;&#38382;&#39064;&#21306;&#20998;&#24320;&#26469;&#65292;&#24182;&#20005;&#26684;&#21010;&#20998;&#20102;&#21487;&#36798;&#25104;&#21644;&#19981;&#21487;&#33021;&#30340;&#30446;&#26631;&#30340;&#36793;&#30028;&#12290;&#28982;&#21518;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#23454;&#29992;&#31639;&#27861;&#12290;&#31532;&#19968;&#31181;&#26041;&#27861;&#25552;&#20379;&#20102;&#20840;&#38754;&#30340;&#39044;&#27979;&#30340;&#24555;&#36895;&#20223;&#30495;&#65292;&#32780;&#31532;&#20108;&#31181;&#26041;&#27861;&#21033;&#29992;&#31639;&#27861;&#31283;&#23450;&#24615;&#25216;&#26415;&#21152;&#36895;&#35745;&#31639;&#12290;&#36825;&#20004;&#31181;&#26041;&#27861;&#35745;&#31639;&#25928;&#29575;&#39640;&#65292;&#33021;&#22815;&#22312;&#20219;&#24847;&#20002;&#22833;&#27169;&#24335;&#19979;&#26377;&#25928;&#22320;&#20445;&#35777;&#35206;&#30422;&#29575;&#30340;&#26377;&#25928;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#37327;&#21270;&#20102;&#32570;&#22833;&#23545;&#39044;&#27979;&#31934;&#24230;&#30340;&#24433;&#21709;&#65292;&#24182;&#24314;&#31435;&#20102;&#22522;&#26412;&#30340;&#26497;&#38480;&#32467;&#26524;&#12290;&#26469;&#33258;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#30340;&#32463;&#39564;&#35777;&#25454;&#35777;&#23454;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#21331;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the open problem of conformalized entry prediction in a row/column-exchangeable matrix. The matrix setting presents novel and unique challenges, but there exists little work on this interesting topic. We meticulously define the problem, differentiate it from closely related problems, and rigorously delineate the boundary between achievable and impossible goals. We then propose two practical algorithms. The first method provides a fast emulation of the full conformal prediction, while the second method leverages the technique of algorithmic stability for acceleration. Both methods are computationally efficient and can effectively safeguard coverage validity in presence of arbitrary missing pattern. Further, we quantify the impact of missingness on prediction accuracy and establish fundamental limit results. Empirical evidence from synthetic and real-world data sets corroborates the superior performance of our proposed methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#38543;&#26426;&#25628;&#32034;&#21450;&#20854;&#24615;&#33021;&#65292;&#24341;&#20837;&#20102;&#8220;&#25955;&#23556;&#32500;&#24230;&#8221;&#30340;&#27010;&#24565;&#65292;&#25551;&#36848;&#20102;&#24213;&#23618;&#20989;&#25968;&#30340;&#29366;&#24577;&#65292;&#37327;&#21270;&#20102;&#38543;&#26426;&#25628;&#32034;&#30340;&#24615;&#33021;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#26080;&#22122;&#22768;&#21644;&#26377;&#30028;&#22122;&#22768;&#24773;&#20917;&#19979;&#30340;&#36755;&#20986;&#20998;&#21035;&#20197;&#19968;&#23450;&#27010;&#29575;&#25910;&#25947;&#21040;&#26368;&#20248;&#20540;&#12290;</title><link>http://arxiv.org/abs/2305.11509</link><description>&lt;p&gt;
&#20174;&#38543;&#26426;&#25628;&#32034;&#21040;&#24230;&#37327;&#27979;&#24230;&#31354;&#38388;&#20013;&#30340;&#36172;&#21338;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
From Random Search to Bandit Learning in Metric Measure Spaces. (arXiv:2305.11509v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11509
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#38543;&#26426;&#25628;&#32034;&#21450;&#20854;&#24615;&#33021;&#65292;&#24341;&#20837;&#20102;&#8220;&#25955;&#23556;&#32500;&#24230;&#8221;&#30340;&#27010;&#24565;&#65292;&#25551;&#36848;&#20102;&#24213;&#23618;&#20989;&#25968;&#30340;&#29366;&#24577;&#65292;&#37327;&#21270;&#20102;&#38543;&#26426;&#25628;&#32034;&#30340;&#24615;&#33021;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#26080;&#22122;&#22768;&#21644;&#26377;&#30028;&#22122;&#22768;&#24773;&#20917;&#19979;&#30340;&#36755;&#20986;&#20998;&#21035;&#20197;&#19968;&#23450;&#27010;&#29575;&#25910;&#25947;&#21040;&#26368;&#20248;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#25628;&#32034;&#26159;&#36229;&#21442;&#25968;&#20248;&#21270;&#20013;&#26368;&#24120;&#29992;&#30340;&#26041;&#27861;&#20043;&#19968;&#65292;&#23545;&#20110;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#25104;&#21151;&#33267;&#20851;&#37325;&#35201;&#12290;&#23613;&#31649;&#20854;&#24615;&#33021;&#20196;&#20154;&#24778;&#21497;&#65292;&#20294;&#24456;&#23569;&#26377;&#38750;&#21551;&#21457;&#24335;&#30340;&#29702;&#35770;&#29992;&#20110;&#25551;&#36848;&#20854;&#24037;&#20316;&#26426;&#21046;&#12290;&#26412;&#25991;&#32473;&#20986;&#20102;&#20851;&#20110;&#38543;&#26426;&#25628;&#32034;&#30340;&#29702;&#35770;&#35299;&#37322;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#8220;&#25955;&#23556;&#32500;&#24230;&#8221;&#30340;&#27010;&#24565;&#65292;&#25551;&#36848;&#20102;&#24213;&#23618;&#20989;&#25968;&#30340;&#29366;&#24577;&#65292;&#24182;&#37327;&#21270;&#20102;&#38543;&#26426;&#25628;&#32034;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#24403;&#29615;&#22659;&#27809;&#26377;&#22122;&#22768;&#26102;&#65292;&#38543;&#26426;&#25628;&#32034;&#30340;&#36755;&#20986;&#20197;&#27010;&#29575;&#25910;&#25947;&#21040;&#26368;&#20248;&#20540;&#65292;&#20854;&#36895;&#29575;&#20026;$ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \right)^{ \frac{1}{d_s} } \right) $&#65292;&#20854;&#20013;$ d_s \ge 0 $&#26159;&#24213;&#23618;&#20989;&#25968;&#30340;&#25955;&#23556;&#32500;&#24230;&#12290;&#24403;&#35266;&#23519;&#21040;&#30340;&#20989;&#25968;&#20540;&#21463;&#21040;&#26377;&#30028;&#30340;&#29420;&#31435;&#21516;&#20998;&#24067;&#22122;&#22768;&#24433;&#21709;&#26102;&#65292;&#38543;&#26426;&#25628;&#32034;&#30340;&#36755;&#20986;&#20197;&#27010;&#29575;&#25910;&#25947;&#21040;&#26368;&#20248;&#20540;&#65292;&#36895;&#29575;&#20026;$ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \right)^{ \frac{2}{2+d_s} } \right) $&#12290;
&lt;/p&gt;
&lt;p&gt;
Random Search is one of the most widely-used method for Hyperparameter Optimization, and is critical to the success of deep learning models. Despite its astonishing performance, little non-heuristic theory has been developed to describe the underlying working mechanism. This paper gives a theoretical accounting of Random Search. We introduce the concept of \emph{scattering dimension} that describes the landscape of the underlying function, and quantifies the performance of random search. We show that, when the environment is noise-free, the output of random search converges to the optimal value in probability at rate $ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \right)^{ \frac{1}{d_s} } \right) $, where $ d_s \ge 0 $ is the scattering dimension of the underlying function. When the observed function values are corrupted by bounded $iid$ noise, the output of random search converges to the optimal value in probability at rate $ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \rig
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#22270;&#33410;&#28857;&#23884;&#20837;&#26694;&#26550;&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#29702;&#35299;&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;GNN&#12290;</title><link>http://arxiv.org/abs/2305.07580</link><description>&lt;p&gt;
&#22522;&#20110;Fisher&#20449;&#24687;&#23884;&#20837;&#30340;&#33410;&#28857;&#21644;&#22270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Fisher Information Embedding for Node and Graph Learning. (arXiv:2305.07580v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07580
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#22270;&#33410;&#28857;&#23884;&#20837;&#26694;&#26550;&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#29702;&#35299;&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;GNN&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#65292;&#20363;&#22914;&#22270;&#27880;&#24847;&#21147;&#32593;&#32476;&#65288;GAT&#65289;&#65292;&#24050;&#25104;&#20026;&#22788;&#29702;&#22270;&#32467;&#26500;&#25968;&#25454;&#21644;&#23398;&#20064;&#33410;&#28857;&#23884;&#20837;&#30340;&#27969;&#34892;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#12290;&#23613;&#31649;&#36825;&#20123;&#27169;&#22411;&#22312;&#32463;&#39564;&#19978;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#23427;&#20204;&#20381;&#36182;&#20110;&#26631;&#27880;&#25968;&#25454;&#65292;&#19988;&#36825;&#20123;&#27169;&#22411;&#30340;&#29702;&#35770;&#23646;&#24615;&#23578;&#26410;&#23436;&#20840;&#29702;&#35299;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;&#22270;&#33410;&#28857;&#23884;&#20837;&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#24314;&#31435;&#22312;&#19968;&#31181;&#22810;&#37325;&#38598;&#21512;&#20869;&#33410;&#28857;&#21608;&#22260;&#23376;&#22270;&#30340;&#20998;&#23618;&#26680;&#20043;&#19978;&#65288;&#20363;&#22914;&#65292;&#37051;&#22495;&#65289;&#65292;&#24182;&#19988;&#27599;&#20010;&#26680;&#21033;&#29992;&#24179;&#28369;&#32479;&#35745;&#27969;&#24418;&#30340;&#20960;&#20309;&#26469;&#27604;&#36739;&#22810;&#37325;&#38598;&#21512;&#30340;&#25104;&#23545;&#24046;&#24322;&#65292;&#36890;&#36807;&#23558;&#22810;&#37325;&#38598;&#21512;&#8220;&#26144;&#23556;&#8221;&#21040;&#27969;&#24418;&#19978;&#12290;&#36890;&#36807;&#26174;&#24335;&#35745;&#31639;&#39640;&#26031;&#28151;&#21512;&#29289;&#27969;&#24418;&#20013;&#30340;&#33410;&#28857;&#23884;&#20837;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#24341;&#23548;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20851;&#27880;&#26426;&#21046;&#36827;&#34892;&#37051;&#22495;&#32858;&#21512;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#26377;&#20851;&#23884;&#20837;&#30340;&#27867;&#21270;&#21644;&#34920;&#36798;&#33021;&#21147;&#30340;&#29702;&#35770;&#35265;&#35299;&#65292;&#20026;&#26356;&#28145;&#20837;&#29702;&#35299;&#22522;&#20110;&#27880;&#24847;&#21147;&#26426;&#21046;&#30340;GNN&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
Attention-based graph neural networks (GNNs), such as graph attention networks (GATs), have become popular neural architectures for processing graph-structured data and learning node embeddings. Despite their empirical success, these models rely on labeled data and the theoretical properties of these models have yet to be fully understood. In this work, we propose a novel attention-based node embedding framework for graphs. Our framework builds upon a hierarchical kernel for multisets of subgraphs around nodes (e.g. neighborhoods) and each kernel leverages the geometry of a smooth statistical manifold to compare pairs of multisets, by "projecting" the multisets onto the manifold. By explicitly computing node embeddings with a manifold of Gaussian mixtures, our method leads to a new attention mechanism for neighborhood aggregation. We provide theoretical insights into genralizability and expressivity of our embeddings, contributing to a deeper understanding of attention-based GNNs. We p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#21463;&#38480;&#36890;&#20449;&#21644;&#21152;&#24615;&#39640;&#26031;&#22122;&#22768;&#19979;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#38454;&#27573;&#36172;&#21338;&#31639;&#27861;&#65292;&#24182;&#32473;&#20986;&#20102;&#20449;&#24687;&#29702;&#35770;&#19979;&#38480;&#12290;</title><link>http://arxiv.org/abs/2304.12680</link><description>&lt;p&gt;
&#21463;&#38480;&#36890;&#20449;&#21152;&#24615;&#39640;&#26031;&#22122;&#22768;&#19979;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Communication-Constrained Bandits under Additive Gaussian Noise. (arXiv:2304.12680v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12680
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#21463;&#38480;&#36890;&#20449;&#21644;&#21152;&#24615;&#39640;&#26031;&#22122;&#22768;&#19979;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#38454;&#27573;&#36172;&#21338;&#31639;&#27861;&#65292;&#24182;&#32473;&#20986;&#20102;&#20449;&#24687;&#29702;&#35770;&#19979;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#20998;&#24067;&#24335;&#38543;&#26426;&#22810;&#33218;&#36172;&#21338;&#26426;,&#20854;&#20013;&#23458;&#25143;&#31471;&#26681;&#25454;&#30456;&#24212;&#30340;&#25289;&#33218;&#22870;&#21169;&#25552;&#20379;&#21463;&#38480;&#36890;&#20449;&#21453;&#39304;&#32473;&#23398;&#20064;&#32773;&#12290;&#22312;&#25105;&#20204;&#30340;&#35774;&#23450;&#19979;,&#23458;&#25143;&#31471;&#24517;&#39035;&#32534;&#30721;&#22870;&#21169;&#65292;&#20351;&#24471;&#32534;&#30721;&#22870;&#21169;&#30340;&#20108;&#38454;&#30697;&#19981;&#36229;&#36807;P&#65292;&#24182;&#19988;&#36825;&#20010;&#32534;&#30721;&#22870;&#21169;&#20250;&#34987;&#26041;&#24046;&#20026;$\sigma^2$&#30340;&#21152;&#24615;&#39640;&#26031;&#22122;&#22768;&#25152;&#27745;&#26579;&#65307;&#23398;&#20064;&#32773;&#21482;&#33021;&#35775;&#38382;&#36825;&#20010;&#34987;&#27745;&#26579;&#30340;&#22870;&#21169;&#12290;&#25105;&#20204;&#22312;&#36825;&#20010;&#35774;&#32622;&#20013;&#23548;&#20986;&#20102;&#20219;&#20309;&#26041;&#26696;&#30340;&#26368;&#23567;&#21270;&#21518;&#24724;&#30340;&#20449;&#24687;&#35770;&#19979;&#38480;$\Omega\left(\sqrt{\frac{KT}{\mathtt{SNR} \wedge1}} \right)$&#65292;&#20854;&#20013; $ \mathtt{SNR} := \frac{P}{\sigma^2}$&#65292;$K$&#21644;$T$&#20998;&#21035;&#26159;&#33218;&#25968;&#21644;&#26102;&#38388;&#38271;&#24230;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#38454;&#27573;&#36172;&#21338;&#31639;&#27861;$\mathtt{UE\text{-}UCB++}$&#65292;&#23427;&#21487;&#20197;&#23558;&#36825;&#20010;&#19979;&#38480;&#30340;&#20540;&#21152;&#19978;&#19968;&#20010;&#24494;&#23567;&#30340;&#21487;&#21152;&#24615;&#22240;&#23376;&#12290;$\mathtt{UE\text{-}UCB++}$&#22312;&#20854;&#21021;&#22987;&#38454;&#27573;&#25191;&#34892;&#22343;&#21248;&#25506;&#32034;&#65292;&#28982;&#21518;&#22312;&#21518;&#32493;&#38454;&#27573;&#20351;&#29992;&#8220;&#19978;&#32622;&#20449;&#30028;&#8221;(UCB)&#31639;&#27861;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#25968;&#20540;&#32467;&#26524;&#65292;&#34920;&#26126;&#22312;&#23454;&#38469;&#24773;&#20917;&#19979;&#38656;&#35201;&#36825;&#26679;&#30340;&#36890;&#20449;&#26377;&#25928;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study a distributed stochastic multi-armed bandit where a client supplies the learner with communication-constrained feedback based on the rewards for the corresponding arm pulls. In our setup, the client must encode the rewards such that the second moment of the encoded rewards is no more than $P$, and this encoded reward is further corrupted by additive Gaussian noise of variance $\sigma^2$; the learner only has access to this corrupted reward. For this setting, we derive an information-theoretic lower bound of $\Omega\left(\sqrt{\frac{KT}{\mathtt{SNR} \wedge1}} \right)$ on the minimax regret of any scheme, where $ \mathtt{SNR} := \frac{P}{\sigma^2}$, and $K$ and $T$ are the number of arms and time horizon, respectively. Furthermore, we propose a multi-phase bandit algorithm, $\mathtt{UE\text{-}UCB++}$, which matches this lower bound to a minor additive factor. $\mathtt{UE\text{-}UCB++}$ performs uniform exploration in its initial phases and then utilizes the {\em upper confidence
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#26377;&#38480;&#26679;&#26412;&#21644;&#21151;&#29575;&#20998;&#26512;&#30830;&#23450;&#20102;&#22810;&#20803;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#35780;&#20998;&#35268;&#21017;&#30340;&#21487;&#38752;&#24615;&#21306;&#22495;&#65292;&#24182;&#22312;&#30005;&#21147;&#29983;&#20135;&#38382;&#39064;&#19978;&#35780;&#20272;&#20102;&#32467;&#26524;&#23545;&#30495;&#23454;&#19990;&#30028;&#20219;&#21153;&#30340;&#26222;&#36866;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.09836</link><description>&lt;p&gt;
&#22810;&#20803;&#27010;&#29575;&#39044;&#27979;&#35780;&#20272;&#20013;&#30340;&#21487;&#38752;&#24615;&#21306;&#22495;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Regions of Reliability in the Evaluation of Multivariate Probabilistic Forecasts. (arXiv:2304.09836v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09836
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#26377;&#38480;&#26679;&#26412;&#21644;&#21151;&#29575;&#20998;&#26512;&#30830;&#23450;&#20102;&#22810;&#20803;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#35780;&#20998;&#35268;&#21017;&#30340;&#21487;&#38752;&#24615;&#21306;&#22495;&#65292;&#24182;&#22312;&#30005;&#21147;&#29983;&#20135;&#38382;&#39064;&#19978;&#35780;&#20272;&#20102;&#32467;&#26524;&#23545;&#30495;&#23454;&#19990;&#30028;&#20219;&#21153;&#30340;&#26222;&#36866;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22810;&#20803;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#35780;&#20272;&#20013;&#65292;&#36890;&#24120;&#20351;&#29992;&#36866;&#24403;&#30340;&#35780;&#20998;&#35268;&#21017;&#36827;&#34892;&#35780;&#20272;&#65292;&#21363;&#23545;&#20110;&#22522;&#20934;&#20998;&#24067;&#26399;&#26395;&#26368;&#23567;&#30340;&#20989;&#25968;&#12290;&#28982;&#32780;&#65292;&#22312;&#38750;&#28176;&#36827;&#24773;&#20917;&#19979;&#65292;&#36825;&#19968;&#23646;&#24615;&#19981;&#33021;&#20445;&#35777;&#20855;&#26377;&#33391;&#22909;&#30340;&#21306;&#20998;&#24230;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#31532;&#19968;&#31687;&#31995;&#32479;&#30340;&#26377;&#38480;&#26679;&#26412;&#36866;&#24403;&#35780;&#20998;&#35268;&#21017;&#30740;&#31350;&#65292;&#36890;&#36807;&#21151;&#29575;&#20998;&#26512;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#19968;&#20010;&#20998;&#25968;&#35268;&#21017;&#30340;&#8220;&#21487;&#38752;&#24615;&#21306;&#22495;&#8221;&#65292;&#21363;&#23427;&#21487;&#20197;&#21487;&#38752;&#22320;&#35782;&#21035;&#39044;&#27979;&#35823;&#24046;&#30340;&#19968;&#32452;&#23454;&#38469;&#26465;&#20214;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#20840;&#38754;&#30340;&#20154;&#36896;&#22522;&#20934;&#27979;&#35797;&#19978;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#35813;&#27979;&#35797;&#19987;&#38376;&#35774;&#35745;&#20197;&#27979;&#35797;&#22522;&#20934;&#20998;&#24067;&#19982;&#39044;&#27979;&#20998;&#24067;&#20043;&#38388;&#30340;&#20960;&#20010;&#20851;&#38190;&#24046;&#24322;&#65292;&#24182;&#36890;&#36807;&#22312;&#30005;&#21147;&#29983;&#20135;&#38382;&#39064;&#19978;&#24212;&#29992;&#26469;&#35780;&#20272;&#25105;&#20204;&#30340;&#32467;&#26524;&#23545;&#30495;&#23454;&#19990;&#30028;&#20219;&#21153;&#30340;&#26222;&#36866;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25581;&#31034;&#20102;&#22312;&#22810;&#20803;&#27010;&#29575;&#39044;&#27979;&#30340;&#35780;&#20272;&#20013;&#30340;&#37325;&#22823;&#32570;&#38519;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multivariate probabilistic time series forecasts are commonly evaluated via proper scoring rules, i.e., functions that are minimal in expectation for the ground-truth distribution. However, this property is not sufficient to guarantee good discrimination in the non-asymptotic regime. In this paper, we provide the first systematic finite-sample study of proper scoring rules for time-series forecasting evaluation. Through a power analysis, we identify the "region of reliability" of a scoring rule, i.e., the set of practical conditions where it can be relied on to identify forecasting errors. We carry out our analysis on a comprehensive synthetic benchmark, specifically designed to test several key discrepancies between ground-truth and forecast distributions, and we gauge the generalizability of our findings to real-world tasks with an application to an electricity production problem. Our results reveal critical shortcomings in the evaluation of multivariate probabilistic forecasts as co
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35299;&#20915;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#31232;&#30095;&#22870;&#21169;&#19979;&#30340;&#26368;&#22823;&#29109;&#25506;&#32034;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#31867;&#22411;&#30340;&#26368;&#22823;&#29109;&#25506;&#32034;&#26041;&#27861;&#65292;&#24182;&#25552;&#39640;&#20102;&#20854;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2303.08059</link><description>&lt;p&gt;
&#24555;&#36895;&#29575;&#30340;&#26368;&#22823;&#29109;&#25506;&#32034;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Fast Rates for Maximum Entropy Exploration. (arXiv:2303.08059v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.08059
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#24378;&#21270;&#23398;&#20064;&#20013;&#31232;&#30095;&#22870;&#21169;&#19979;&#30340;&#26368;&#22823;&#29109;&#25506;&#32034;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#31867;&#22411;&#30340;&#26368;&#22823;&#29109;&#25506;&#32034;&#26041;&#27861;&#65292;&#24182;&#25552;&#39640;&#20102;&#20854;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#26234;&#33021;&#20307;&#22312;&#19968;&#20010;&#26410;&#30693;&#30340;&#12289;&#31232;&#30095;&#25110;&#27809;&#26377;&#22870;&#21169;&#30340;&#29615;&#22659;&#20013;&#25805;&#20316;&#26102;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#20013;&#25506;&#32034;&#30340;&#25361;&#25112;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#31181;&#19981;&#21516;&#31867;&#22411;&#30340;&#26368;&#22823;&#29109;&#25506;&#32034;&#38382;&#39064;&#12290;&#31532;&#19968;&#31181;&#31867;&#22411;&#26159;&#22238;&#35775;&#29109;&#26368;&#22823;&#21270;&#65292;&#36825;&#22312;&#25240;&#25187;&#35774;&#32622;&#20013;&#24050;&#32463;&#30001;Hazan et al.&#65288;2019&#65289;&#32771;&#34385;&#36807;&#12290;&#23545;&#20110;&#36825;&#31181;&#31867;&#22411;&#30340;&#25506;&#32034;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21338;&#24328;&#35770;&#31639;&#27861;&#65292;&#20854;&#26679;&#26412;&#22797;&#26434;&#24615;&#20026;$\widetilde{\mathcal{O}}(H^3S^2A/\varepsilon^2)$&#65292;&#20174;&#32780;&#25913;&#36827;&#20102;&#29616;&#26377;&#32467;&#26524;&#30340;$\varepsilon$&#20381;&#36182;&#20851;&#31995;&#65292;&#20854;&#20013;$S$&#26159;&#29366;&#24577;&#25968;&#65292;$A$&#26159;&#34892;&#21160;&#25968;&#65292;$H$&#26159;&#27599;&#20010;&#22238;&#21512;&#30340;&#38271;&#24230;&#65292;$\varepsilon$&#26159;&#26399;&#26395;&#30340;&#31934;&#24230;&#12290;&#25105;&#20204;&#30740;&#31350;&#30340;&#31532;&#20108;&#31181;&#29109;&#26159;&#36712;&#36857;&#29109;&#12290;&#36825;&#20010;&#30446;&#26631;&#20989;&#25968;&#19982;&#29109;&#27491;&#21017;&#21270;MDPs&#23494;&#20999;&#30456;&#20851;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#31639;&#27861;&#65292;&#20854;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$\widetilde{\mathcal{O}}(\mathrm{poly}(S,A,H)/\varepsilon)$&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#22312;&#20855;&#26377;$\mathrm{poly}(S,A,H)$&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#24773;&#20917;&#19979;&#35299;&#20915;&#36712;&#36857;&#29109;&#26368;&#22823;&#21270;&#38382;&#39064;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We address the challenge of exploration in reinforcement learning (RL) when the agent operates in an unknown environment with sparse or no rewards. In this work, we study the maximum entropy exploration problem of two different types. The first type is visitation entropy maximization previously considered by Hazan et al.(2019) in the discounted setting. For this type of exploration, we propose a game-theoretic algorithm that has $\widetilde{\mathcal{O}}(H^3S^2A/\varepsilon^2)$ sample complexity thus improving the $\varepsilon$-dependence upon existing results, where $S$ is a number of states, $A$ is a number of actions, $H$ is an episode length, and $\varepsilon$ is a desired accuracy. The second type of entropy we study is the trajectory entropy. This objective function is closely related to the entropy-regularized MDPs, and we propose a simple algorithm that has a sample complexity of order $\widetilde{\mathcal{O}}(\mathrm{poly}(S,A,H)/\varepsilon)$. Interestingly, it is the first th
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#8220;&#23433;&#20840;&#21093;&#31163;&#8221;&#26041;&#27861;&#21152;&#36895;&#35299;&#20915;L0&#27491;&#21017;&#21270;&#26368;&#23567;&#20108;&#20056;&#38382;&#39064;&#65292;&#36890;&#36807;&#25910;&#32553;&#26494;&#24347;&#24230;&#20801;&#35768;&#26356;&#28608;&#36827;&#30340;&#21098;&#26525;&#65292;&#26174;&#33879;&#38477;&#20302;&#27714;&#35299;&#26102;&#38388;&#12290;</title><link>http://arxiv.org/abs/2302.14471</link><description>&lt;p&gt;
&#23433;&#20840;&#21093;&#31163;L0&#27491;&#21017;&#21270;&#26368;&#23567;&#20108;&#20056;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Safe Peeling for L0-Regularized Least-Squares with supplementary material. (arXiv:2302.14471v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.14471
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#8220;&#23433;&#20840;&#21093;&#31163;&#8221;&#26041;&#27861;&#21152;&#36895;&#35299;&#20915;L0&#27491;&#21017;&#21270;&#26368;&#23567;&#20108;&#20056;&#38382;&#39064;&#65292;&#36890;&#36807;&#25910;&#32553;&#26494;&#24347;&#24230;&#20801;&#35768;&#26356;&#28608;&#36827;&#30340;&#21098;&#26525;&#65292;&#26174;&#33879;&#38477;&#20302;&#27714;&#35299;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;&#8220;&#23433;&#20840;&#21093;&#31163;&#8221;&#65292;&#36890;&#36807;&#20998;&#25903;&#23450;&#30028;&#31639;&#27861;&#21152;&#36895;&#35299;&#20915;L0&#27491;&#21017;&#21270;&#26368;&#23567;&#20108;&#20056;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#31243;&#24207;&#20351;&#24471;&#22312;BnB&#20915;&#31574;&#26641;&#30340;&#27599;&#20010;&#33410;&#28857;&#22788;&#32771;&#34385;&#21040;&#25910;&#32553;&#26494;&#24347;&#24230;&#65292;&#22240;&#27492;&#21487;&#33021;&#20801;&#35768;&#26356;&#21152;&#28608;&#36827;&#30340;&#21098;&#26525;&#12290;&#25968;&#20540;&#27169;&#25311;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#25506;&#32034;&#33410;&#28857;&#25968;&#37327;&#21644;&#25972;&#20307;&#27714;&#35299;&#26102;&#38388;&#26041;&#38754;&#20855;&#26377;&#26174;&#33879;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a new methodology dubbed ``safe peeling'' to accelerate the resolution of L0-regularized least-squares problems via a Branch-and-Bound (BnB) algorithm. Our procedure enables to tighten the convex relaxation considered at each node of the BnB decision tree and therefore potentially allows for more aggressive pruning. Numerical simulations show that our proposed methodology leads to significant gains in terms of number of nodes explored and overall solving time.s show that our proposed methodology leads to significant gains in terms of number of nodes explored and overall solving time.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#22240;&#26524;&#31561;&#20445;&#26657;&#20934;&#26041;&#27861;&#21450;&#20854;&#25968;&#25454;&#26377;&#25928;&#30340;&#21464;&#20307;&#20132;&#21449;&#26657;&#20934;&#65292;&#36825;&#20004;&#31181;&#26041;&#27861;&#37117;&#33021;&#24555;&#36895;&#31283;&#20581;&#22320;&#26657;&#20934;&#24322;&#36136;&#24615;&#22788;&#29702;&#25928;&#24212;&#30340;&#39044;&#27979;&#22120;&#65292;&#32780;&#19988;&#21487;&#20197;&#24212;&#29992;&#20110;&#20219;&#20309;&#40657;&#30418;&#23398;&#20064;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2302.14011</link><description>&lt;p&gt;
&#24322;&#36136;&#24615;&#22788;&#29702;&#25928;&#24212;&#30340;&#22240;&#26524;&#31561;&#20445;&#26657;&#20934;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Causal isotonic calibration for heterogeneous treatment effects. (arXiv:2302.14011v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.14011
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#22240;&#26524;&#31561;&#20445;&#26657;&#20934;&#26041;&#27861;&#21450;&#20854;&#25968;&#25454;&#26377;&#25928;&#30340;&#21464;&#20307;&#20132;&#21449;&#26657;&#20934;&#65292;&#36825;&#20004;&#31181;&#26041;&#27861;&#37117;&#33021;&#24555;&#36895;&#31283;&#20581;&#22320;&#26657;&#20934;&#24322;&#36136;&#24615;&#22788;&#29702;&#25928;&#24212;&#30340;&#39044;&#27979;&#22120;&#65292;&#32780;&#19988;&#21487;&#20197;&#24212;&#29992;&#20110;&#20219;&#20309;&#40657;&#30418;&#23398;&#20064;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#38750;&#21442;&#25968;&#26041;&#27861;&#8212;&#8212;&#22240;&#26524;&#31561;&#20445;&#26657;&#20934;&#26041;&#27861;&#65292;&#29992;&#20110;&#26657;&#20934;&#24322;&#36136;&#24615;&#22788;&#29702;&#25928;&#24212;&#30340;&#39044;&#27979;&#22120;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#20171;&#32461;&#20102;&#20132;&#21449;&#26657;&#20934;&#65292;&#36825;&#26159;&#19968;&#31181;&#25968;&#25454;&#26377;&#25928;&#30340;&#26657;&#20934;&#21464;&#20307;&#65292;&#28040;&#38500;&#20102;&#20445;&#30041;&#26657;&#20934;&#38598;&#30340;&#38656;&#35201;&#12290;&#20132;&#21449;&#26657;&#20934;&#21033;&#29992;&#20132;&#21449;&#25311;&#21512;&#30340;&#39044;&#27979;&#22120;&#65292;&#24182;&#20351;&#29992;&#25152;&#26377;&#21487;&#29992;&#25968;&#25454;&#29983;&#25104;&#19968;&#20010;&#21333;&#19968;&#30340;&#26657;&#20934;&#39044;&#27979;&#22120;&#12290;&#22312;&#19981;&#35201;&#27714;&#21333;&#35843;&#24615;&#30340;&#24369;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22240;&#26524;&#31561;&#20445;&#26657;&#20934;&#21644;&#20132;&#21449;&#26657;&#20934;&#37117;&#33021;&#23454;&#29616;&#24555;&#36895;&#21452;&#37325;&#31283;&#20581;&#26657;&#20934;&#36895;&#29575;&#65292;&#21482;&#35201;&#21033;&#29992;&#31867;&#20284;&#24847;&#20041;&#19979;&#31934;&#30830;&#20272;&#35745;&#20102;&#20542;&#21521;&#24471;&#20998;&#25110;&#21518;&#26524;&#22238;&#24402;&#12290;&#36825;&#31181;&#22240;&#26524;&#31561;&#20445;&#26657;&#20934;&#22120;&#21487;&#20197;&#21253;&#35013;&#22312;&#20219;&#20309;&#40657;&#30418;&#23398;&#20064;&#31639;&#27861;&#21608;&#22260;&#65292;&#25552;&#20379;&#24378;&#20581;&#21644;&#20998;&#24067;&#33258;&#30001;&#30340;&#26657;&#20934;&#20445;&#35777;&#65292;&#21516;&#26102;&#20445;&#25345;&#39044;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose causal isotonic calibration, a novel nonparametric method for calibrating predictors of heterogeneous treatment effects. Furthermore, we introduce cross-calibration, a data-efficient variant of calibration that eliminates the need for hold-out calibration sets. Cross-calibration leverages cross-fitted predictors and generates a single calibrated predictor using all available data. Under weak conditions that do not assume monotonicity, we establish that both causal isotonic calibration and cross-calibration achieve fast doubly-robust calibration rates, as long as either the propensity score or outcome regression is estimated accurately in a suitable sense. The proposed causal isotonic calibrator can be wrapped around any black-box learning algorithm, providing robust and distribution-free calibration guarantees while preserving predictive performance.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;f-DPG&#65292;&#29992;&#20110;&#23545;&#40784;&#35821;&#35328;&#27169;&#22411;&#21644;&#20559;&#22909;&#65292;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#35780;&#20272;&#20219;&#20309;&#30446;&#26631;&#20998;&#24067;&#65292;&#32479;&#19968;&#20102;&#29616;&#26377;&#30340;&#21508;&#31181;&#26694;&#26550;&#21644;&#36924;&#36817;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2302.08215</link><description>&lt;p&gt;
&#36890;&#36807;f-&#25955;&#24230;&#26368;&#23567;&#21270;&#23545;&#40784;&#35821;&#35328;&#27169;&#22411;&#19982;&#20559;&#22909;
&lt;/p&gt;
&lt;p&gt;
Aligning Language Models with Preferences through f-divergence Minimization. (arXiv:2302.08215v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.08215
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;f-DPG&#65292;&#29992;&#20110;&#23545;&#40784;&#35821;&#35328;&#27169;&#22411;&#21644;&#20559;&#22909;&#65292;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#35780;&#20272;&#20219;&#20309;&#30446;&#26631;&#20998;&#24067;&#65292;&#32479;&#19968;&#20102;&#29616;&#26377;&#30340;&#21508;&#31181;&#26694;&#26550;&#21644;&#36924;&#36817;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#40784;&#35821;&#35328;&#27169;&#22411;&#21644;&#20559;&#22909;&#21487;&#20197;&#34987;&#30475;&#20316;&#26159;&#23545;&#30446;&#26631;&#20998;&#24067;&#36827;&#34892;&#36924;&#36817;&#65292;&#20197;&#26399;&#36798;&#21040;&#26576;&#31181;&#25152;&#38656;&#34892;&#20026;&#12290;&#29616;&#26377;&#30340;&#26041;&#27861;&#22312;&#30446;&#26631;&#20998;&#24067;&#30340;&#20989;&#25968;&#24418;&#24335;&#21644;&#29992;&#20110;&#36924;&#36817;&#30446;&#26631;&#20998;&#24067;&#30340;&#31639;&#27861;&#19978;&#23384;&#22312;&#24046;&#24322;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;f-DPG&#65292;&#35813;&#26041;&#27861;&#20801;&#35768;&#20351;&#29992;&#20219;&#20309;&#21487;&#35780;&#20272;&#30340;f-&#25955;&#24230;&#36924;&#36817;&#20219;&#20309;&#30446;&#26631;&#20998;&#24067;&#65292;&#20174;&#32780;&#32479;&#19968;&#20102;&#29616;&#26377;&#30340;&#21508;&#31181;&#26694;&#26550;&#21644;&#36924;&#36817;&#26041;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#21508;&#31181;&#25955;&#24230;&#30446;&#26631;&#30340;&#23454;&#38469;&#22909;&#22788;&#65292;&#24182;&#35777;&#26126;&#20102;&#27809;&#26377;&#26222;&#36866;&#30340;&#26368;&#20339;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;
Aligning language models with preferences can be posed as approximating a target distribution representing some desired behavior. Existing approaches differ both in the functional form of the target distribution and the algorithm used to approximate it. For instance, Reinforcement Learning from Human Feedback (RLHF) corresponds to minimizing a reverse KL from an implicit target distribution arising from a KL penalty in the objective. On the other hand, Generative Distributional Control (GDC) has an explicit target distribution and minimizes a forward KL from it using the Distributional Policy Gradient (DPG) algorithm. In this paper, we propose a new approach, f-DPG, which allows the use of any f-divergence to approximate any target distribution that can be evaluated. f-DPG unifies both frameworks (RLHF, GDC) and the approximation methods (DPG, RL with KL penalties). We show the practical benefits of various choices of divergence objectives and demonstrate that there is no universally o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#22312;&#20855;&#26377;&#39640;&#39118;&#38505;&#24212;&#29992;&#30340;&#20010;&#24615;&#21270;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#20013;&#65292;&#19981;&#21516;&#27169;&#22411;&#36873;&#25321;&#26631;&#20934;&#30340;&#20248;&#28857;&#21644;&#32570;&#28857;&#65292;&#24182;&#25552;&#20986;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#12290;</title><link>http://arxiv.org/abs/2302.02923</link><description>&lt;p&gt;
&#19981;&#26159;&#31070;&#22855;&#33647;&#20024;&#65292;&#32780;&#26159;&#27934;&#23519;&#21147;&#20043;&#25628;&#23547;&#65306;&#28040;&#38500;&#24322;&#36136;&#24615;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#20013;&#30340;&#27169;&#22411;&#36873;&#25321;&#22256;&#22659;
&lt;/p&gt;
&lt;p&gt;
In Search of Insights, Not Magic Bullets: Towards Demystification of the Model Selection Dilemma in Heterogeneous Treatment Effect Estimation. (arXiv:2302.02923v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.02923
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22312;&#20855;&#26377;&#39640;&#39118;&#38505;&#24212;&#29992;&#30340;&#20010;&#24615;&#21270;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#20013;&#65292;&#19981;&#21516;&#27169;&#22411;&#36873;&#25321;&#26631;&#20934;&#30340;&#20248;&#28857;&#21644;&#32570;&#28857;&#65292;&#24182;&#25552;&#20986;&#26410;&#26469;&#30740;&#31350;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#24615;&#21270;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#22312;&#39640;&#39118;&#38505;&#24212;&#29992;&#20013;&#32463;&#24120;&#22791;&#21463;&#20851;&#27880;&#65292;&#22240;&#27492;&#65292;&#22312;&#23454;&#36341;&#20013;&#37096;&#32626;&#20272;&#35745;&#36825;&#31181;&#25928;&#24212;&#30340;&#27169;&#22411;&#20043;&#21069;&#65292;&#38656;&#35201;&#30830;&#20449;&#24050;&#32463;&#36873;&#25321;&#20102;&#26368;&#22909;&#30340;&#26426;&#22120;&#23398;&#20064;&#24037;&#20855;&#31665;&#20013;&#30340;&#20505;&#36873;&#27169;&#22411;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#30001;&#20110;&#23454;&#36341;&#20013;&#32570;&#20047;&#21453;&#20107;&#23454;&#20449;&#24687;&#65292;&#36890;&#24120;&#26080;&#27861;&#20381;&#38752;&#26631;&#20934;&#39564;&#35777;&#25351;&#26631;&#23436;&#25104;&#27492;&#20219;&#21153;&#65292;&#23548;&#33268;&#20102;&#22788;&#29702;&#25928;&#24212;&#20272;&#35745;&#25991;&#29486;&#20013;&#24050;&#30693;&#30340;&#27169;&#22411;&#36873;&#25321;&#22256;&#22659;&#12290;&#34429;&#28982;&#26368;&#36817;&#24050;&#32463;&#30740;&#31350;&#20102;&#19968;&#20123;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#23545;&#19981;&#21516;&#27169;&#22411;&#36873;&#25321;&#26631;&#20934;&#30340;&#20248;&#32570;&#28857;&#30340;&#31995;&#32479;&#29702;&#35299;&#20173;&#28982;&#32570;&#20047;&#12290;&#22240;&#27492;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24182;&#27809;&#26377;&#35797;&#22270;&#23459;&#24067;&#20840;&#23616;&#8220;&#32988;&#32773;&#8221;&#65292;&#32780;&#26159;&#23545;&#19981;&#21516;&#36873;&#25321;&#26631;&#20934;&#30340;&#25104;&#21151;&#21644;&#22833;&#36133;&#27169;&#24335;&#36827;&#34892;&#20102;&#23454;&#35777;&#30740;&#31350;&#12290;&#25105;&#20204;&#24378;&#35843;&#36873;&#25321;&#31574;&#30053;&#65292;&#20505;&#36873;&#20272;&#35745;&#37327;&#21644;&#29992;&#20110;&#27604;&#36739;&#23427;&#20204;&#30340;&#25968;&#25454;&#20043;&#38388;&#23384;&#22312;&#22797;&#26434;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#24182;&#25552;&#20986;&#20102;&#26410;&#26469;&#30740;&#31350;&#30340;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
Personalized treatment effect estimates are often of interest in high-stakes applications -- thus, before deploying a model estimating such effects in practice, one needs to be sure that the best candidate from the ever-growing machine learning toolbox for this task was chosen. Unfortunately, due to the absence of counterfactual information in practice, it is usually not possible to rely on standard validation metrics for doing so, leading to a well-known model selection dilemma in the treatment effect estimation literature. While some solutions have recently been investigated, systematic understanding of the strengths and weaknesses of different model selection criteria is still lacking. In this paper, instead of attempting to declare a global `winner', we therefore empirically investigate success- and failure modes of different selection criteria. We highlight that there is a complex interplay between selection strategies, candidate estimators and the data used for comparing them, an
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;ScaledGD(&#120582;)&#26041;&#27861;&#65292;&#30456;&#36739;&#20110;&#20256;&#32479;&#26799;&#24230;&#19979;&#38477;&#27861;&#26356;&#21152;&#40065;&#26834;&#65292;&#24182;&#19988;&#22312;&#22788;&#29702;&#20302;&#31209;&#30697;&#38453;&#24863;&#30693;&#38382;&#39064;&#26102;&#20855;&#26377;&#24456;&#22909;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2302.01186</link><description>&lt;p&gt;
&#39044;&#26465;&#20214;&#23545;&#36229;&#21442;&#21270;&#20302;&#31209;&#30697;&#38453;&#24863;&#30693;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
The Power of Preconditioning in Overparameterized Low-Rank Matrix Sensing. (arXiv:2302.01186v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.01186
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;ScaledGD(&#120582;)&#26041;&#27861;&#65292;&#30456;&#36739;&#20110;&#20256;&#32479;&#26799;&#24230;&#19979;&#38477;&#27861;&#26356;&#21152;&#40065;&#26834;&#65292;&#24182;&#19988;&#22312;&#22788;&#29702;&#20302;&#31209;&#30697;&#38453;&#24863;&#30693;&#38382;&#39064;&#26102;&#20855;&#26377;&#24456;&#22909;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;ScaledGD(&#120582;)&#26041;&#27861;&#26469;&#35299;&#20915;&#20302;&#31209;&#30697;&#38453;&#24863;&#30693;&#20013;&#30697;&#38453;&#21487;&#33021;&#30149;&#24577;&#20197;&#21450;&#30495;&#23454;&#31209;&#26410;&#30693;&#30340;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992;&#36229;&#21442;&#24335;&#34920;&#31034;&#65292;&#20174;&#19968;&#20010;&#23567;&#30340;&#38543;&#26426;&#21021;&#22987;&#21270;&#24320;&#22987;&#65292;&#36890;&#36807;&#20351;&#29992;&#29305;&#23450;&#24418;&#24335;&#30340;&#38459;&#23612;&#39044;&#26465;&#20214;&#26799;&#24230;&#19979;&#38477;&#26469;&#23545;&#25239;&#36229;&#21442;&#21270;&#21644;&#30149;&#24577;&#26354;&#29575;&#30340;&#24433;&#21709;&#12290;&#19982;&#22522;&#20934;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#30456;&#27604;&#65292;&#23613;&#31649;&#39044;&#22788;&#29702;&#38656;&#35201;&#36731;&#24494;&#30340;&#35745;&#31639;&#24320;&#38144;&#65292;&#20294;ScaledGD&#65288;&#120582;&#65289;&#22312;&#38754;&#23545;&#30149;&#24577;&#38382;&#39064;&#26102;&#34920;&#29616;&#20986;&#20102;&#20986;&#33394;&#30340;&#40065;&#26834;&#24615;&#12290;&#22312;&#39640;&#26031;&#35774;&#35745;&#19979;&#65292;ScaledGD($\lambda$) &#20250;&#22312;&#20165;&#36845;&#20195;&#25968;&#23545;&#25968;&#32423;&#21035;&#30340;&#24773;&#20917;&#19979;&#65292;&#20197;&#32447;&#24615;&#36895;&#29575;&#25910;&#25947;&#21040;&#30495;&#23454;&#30340;&#20302;&#31209;&#30697;&#38453;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose $\textsf{ScaledGD($\lambda$)}$, a preconditioned gradient descent method to tackle the low-rank matrix sensing problem when the true rank is unknown, and when the matrix is possibly ill-conditioned. Using overparametrized factor representations, $\textsf{ScaledGD($\lambda$)}$ starts from a small random initialization, and proceeds by gradient descent with a specific form of damped preconditioning to combat bad curvatures induced by overparameterization and ill-conditioning. At the expense of light computational overhead incurred by preconditioners, $\textsf{ScaledGD($\lambda$)}$ is remarkably robust to ill-conditioning compared to vanilla gradient descent ($\textsf{GD}$) even with overprameterization. Specifically, we show that, under the Gaussian design, $\textsf{ScaledGD($\lambda$)}$ converges to the true low-rank matrix at a constant linear rate after a small number of iterations that scales only logarithmically with respect to the condition number and the problem dimensi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#37325;&#26032;&#23457;&#35270; Bellman Errors&#65292;&#21457;&#29616;&#20043;&#21069;&#30340;Bellman Errors &#26041;&#27861;&#38656;&#35201;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#25165;&#33021;&#34920;&#29616;&#33391;&#22909;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#26356;&#20934;&#30830;&#30340; MSBE &#20272;&#35745;&#22120;&#65292;&#22312;&#31163;&#25955;&#25511;&#21046;&#20219;&#21153;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;</title><link>http://arxiv.org/abs/2302.00141</link><description>&lt;p&gt;
&#37325;&#26032;&#23457;&#35270; Bellman Errors &#29992;&#20110;&#31163;&#32447;&#27169;&#22411;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Revisiting Bellman Errors for Offline Model Selection. (arXiv:2302.00141v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.00141
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37325;&#26032;&#23457;&#35270; Bellman Errors&#65292;&#21457;&#29616;&#20043;&#21069;&#30340;Bellman Errors &#26041;&#27861;&#38656;&#35201;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#25165;&#33021;&#34920;&#29616;&#33391;&#22909;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#26356;&#20934;&#30830;&#30340; MSBE &#20272;&#35745;&#22120;&#65292;&#22312;&#31163;&#25955;&#25511;&#21046;&#20219;&#21153;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#32447;&#27169;&#22411;&#36873;&#25321;&#65288;OMS&#65289;&#21363;&#22312;&#21482;&#26377;&#24050;&#35760;&#24405;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#20174;&#20247;&#22810;&#31574;&#30053;&#20013;&#36873;&#25321;&#26368;&#20339;&#31574;&#30053;&#65292;&#23545;&#20110;&#22312;&#23454;&#38469;&#29615;&#22659;&#19979;&#24212;&#29992;&#31163;&#32447;RL&#33267;&#20851;&#37325;&#35201;&#12290;&#19968;&#20010;&#32463;&#36807;&#24191;&#27867;&#25506;&#35752;&#30340;&#24819;&#27861;&#26159;&#26681;&#25454;&#30456;&#20851;Q&#20989;&#25968;&#30340;&#22343;&#26041;Bellman&#35823;&#24046;&#65288;MSBE&#65289;&#36873;&#25321;&#31574;&#30053;&#12290;&#28982;&#32780;&#65292;&#20043;&#21069;&#30340;&#30740;&#31350;&#19968;&#30452;&#22312;&#20351;&#29992;Bellman&#35823;&#24046;&#26102;&#26080;&#27861;&#33719;&#24471;&#36275;&#22815;&#30340;OMS&#24615;&#33021;&#65292;&#23548;&#33268;&#35768;&#22810;&#30740;&#31350;&#20154;&#21592;&#25918;&#24323;&#27492;&#24819;&#27861;&#12290;&#20026;&#27492;&#65292;&#26412;&#25991;&#38416;&#36848;&#20102;&#20026;&#20160;&#20040;&#20043;&#21069;&#30340;&#32467;&#26524;&#20351;&#29992;Bellman&#35823;&#24046;&#26102;&#20250;&#30475;&#21040;&#24754;&#35266;&#30340;&#32467;&#26524;&#65292;&#24182;&#30830;&#23450;&#20102;&#22522;&#20110;Bellman&#35823;&#24046;&#30340;OMS&#31639;&#27861;&#23558;&#34920;&#29616;&#33391;&#22909;&#30340;&#26465;&#20214;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#27604;&#20043;&#21069;&#26041;&#27861;&#26356;&#20934;&#30830;&#30340;MSBE&#30340;&#26032;&#30340;&#20272;&#35745;&#22120;&#12290;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#22312;&#19981;&#21516;&#30340;&#31163;&#25955;&#25511;&#21046;&#20219;&#21153;&#65288;&#21253;&#25324; Atari &#28216;&#25103;&#65289;&#19978;&#33719;&#24471;&#20102;&#20986;&#33394;&#30340;OMS&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Offline model selection (OMS), that is, choosing the best policy from a set of many policies given only logged data, is crucial for applying offline RL in real-world settings. One idea that has been extensively explored is to select policies based on the mean squared Bellman error (MSBE) of the associated Q-functions. However, previous work has struggled to obtain adequate OMS performance with Bellman errors, leading many researchers to abandon the idea. To this end, we elucidate why previous work has seen pessimistic results with Bellman errors and identify conditions under which OMS algorithms based on Bellman errors will perform well. Moreover, we develop a new estimator of the MSBE that is more accurate than prior methods. Our estimator obtains impressive OMS performance on diverse discrete control tasks, including Atari games.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#20026;&#26426;&#22120;&#21487;&#34920;&#31034;&#25968;&#23383;&#26102;&#33258;&#21160;&#24494;&#20998;&#30340;&#27491;&#30830;&#24615;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#31070;&#32463;&#32593;&#32476;&#24102;&#20559;&#32622;&#21442;&#25968;&#26102;&#33258;&#21160;&#24494;&#20998;&#22987;&#32456;&#27491;&#30830;&#65292;&#32473;&#20986;&#20102;&#38480;&#21046;&#19981;&#21487;&#24494;&#24615;&#22312;&#28608;&#27963;&#20989;&#25968;&#20013;&#25968;&#30446;&#30340;&#30028;&#65292;&#24182;&#25552;&#20379;&#20102;&#21028;&#26029;&#21442;&#25968;&#26159;&#21542;&#22312;&#19981;&#21487;&#24494;&#21442;&#25968;&#32452;&#20013;&#30340;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2301.13370</link><description>&lt;p&gt;
&#20851;&#20110;&#20855;&#26377;&#26426;&#22120;&#21487;&#34920;&#31034;&#21442;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#33258;&#21160;&#24494;&#20998;&#27491;&#30830;&#24615;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Correctness of Automatic Differentiation for Neural Networks with Machine-Representable Parameters. (arXiv:2301.13370v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.13370
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#20026;&#26426;&#22120;&#21487;&#34920;&#31034;&#25968;&#23383;&#26102;&#33258;&#21160;&#24494;&#20998;&#30340;&#27491;&#30830;&#24615;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#31070;&#32463;&#32593;&#32476;&#24102;&#20559;&#32622;&#21442;&#25968;&#26102;&#33258;&#21160;&#24494;&#20998;&#22987;&#32456;&#27491;&#30830;&#65292;&#32473;&#20986;&#20102;&#38480;&#21046;&#19981;&#21487;&#24494;&#24615;&#22312;&#28608;&#27963;&#20989;&#25968;&#20013;&#25968;&#30446;&#30340;&#30028;&#65292;&#24182;&#25552;&#20379;&#20102;&#21028;&#26029;&#21442;&#25968;&#26159;&#21542;&#22312;&#19981;&#21487;&#24494;&#21442;&#25968;&#32452;&#20013;&#30340;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#23454;&#25968;&#22495;&#19978;&#30340;&#21069;&#21521;&#21644;&#21453;&#21521;&#27169;&#24335;&#33258;&#21160;&#24494;&#20998;&#20960;&#20046;&#22987;&#32456;&#22312;&#25968;&#23398;&#19978;&#26159;&#20934;&#30830;&#30340;&#12290;&#28982;&#32780;&#65292;&#23454;&#38469;&#32534;&#31243;&#20351;&#29992;&#30340;&#26159;&#26426;&#22120;&#21487;&#34920;&#31034;&#30340;&#25968;&#23383;&#65288;&#20363;&#22914;&#28014;&#28857;&#25968;&#65289;&#65292;&#32780;&#19981;&#26159;&#23454;&#25968;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#24403;&#31070;&#32463;&#32593;&#32476;&#30340;&#21442;&#25968;&#31354;&#38388;&#20165;&#30001;&#26426;&#22120;&#21487;&#34920;&#31034;&#30340;&#25968;&#23383;&#32452;&#25104;&#26102;&#65292;&#33258;&#21160;&#24494;&#20998;&#30340;&#27491;&#30830;&#24615;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#20004;&#32452;&#21487;&#33021;&#23548;&#33268;&#33258;&#21160;&#24494;&#20998;&#19981;&#27491;&#30830;&#30340;&#21442;&#25968;&#65306;&#19968;&#32452;&#26159;&#32593;&#32476;&#21487;&#24494;&#20294;&#33258;&#21160;&#24494;&#20998;&#26080;&#27861;&#35745;&#31639;&#20854;&#23548;&#25968;&#30340;&#21442;&#25968;&#32452;&#65292;&#21478;&#19968;&#32452;&#26159;&#32593;&#32476;&#19981;&#21487;&#24494;&#30340;&#21442;&#25968;&#32452;&#12290;&#23545;&#20110;&#24102;&#26377;&#20559;&#32622;&#21442;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#20102;&#31532;&#19968;&#32452;&#21442;&#25968;&#32452;&#22987;&#32456;&#20026;&#31354;&#12290;&#28982;&#21518;&#25105;&#20204;&#32473;&#20986;&#20102;&#19968;&#20010;&#32447;&#24615;&#19978;&#38480;&#26469;&#38480;&#21046;&#31532;&#20108;&#32452;&#21442;&#25968;&#32452;&#20013;&#19981;&#21487;&#24494;&#24615;&#22312;&#28608;&#27963;&#20989;&#25968;&#20013;&#30340;&#25968;&#30446;&#65292;&#24182;&#32473;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#26469;&#21028;&#26029;&#19968;&#20010;&#21442;&#25968;&#26159;&#21542;&#22312;&#36825;&#20010;&#21442;&#25968;&#32452;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent work has shown that forward- and reverse- mode automatic differentiation (AD) over the reals is almost always correct in a mathematically precise sense. However, actual programs work with machine-representable numbers (e.g., floating-point numbers), not reals. In this paper, we study the correctness of AD when the parameter space of a neural network consists solely of machine-representable numbers. In particular, we analyze two sets of parameters on which AD can be incorrect: the incorrect set on which the network is differentiable but AD does not compute its derivative, and the non-differentiable set on which the network is non-differentiable. For a neural network with bias parameters, we first prove that the incorrect set is always empty. We then prove a tight bound on the size of the non-differentiable set, which is linear in the number of non-differentiabilities in activation functions, and give a simple necessary and sufficient condition for a parameter to be in this set. W
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#27491;&#21017;&#21270;&#27969;&#65292;&#19987;&#20026;&#19977;&#32500;&#31354;&#38388;&#20013;&#22810;&#20010;&#29289;&#20307;&#30340;&#20301;&#32622;&#21644;&#26041;&#21521;&#24314;&#27169;&#32780;&#35774;&#35745;&#12290;&#36890;&#36807;&#22312;&#21333;&#20301;&#22235;&#20803;&#25968;&#32676;&#19978;&#23450;&#20041;&#24179;&#28369;&#21644;&#34920;&#29616;&#21147;&#24378;&#30340;&#27969;&#20197;&#21450;&#23450;&#20041;&#36866;&#24403;&#30340;&#23494;&#24230;&#65292;&#22312;&#26059;&#36716;&#32676;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#25105;&#20204;&#21487;&#20197;&#25104;&#21151;&#22320;&#37319;&#26679;&#20998;&#23376;&#26230;&#20307;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2301.11355</link><description>&lt;p&gt;
&#29992;&#20110;&#37319;&#26679;&#20998;&#23376;&#26230;&#20307;&#32467;&#26500;&#30340;&#21018;&#20307;&#27969;
&lt;/p&gt;
&lt;p&gt;
Rigid body flows for sampling molecular crystal structures. (arXiv:2301.11355v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11355
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#27491;&#21017;&#21270;&#27969;&#65292;&#19987;&#20026;&#19977;&#32500;&#31354;&#38388;&#20013;&#22810;&#20010;&#29289;&#20307;&#30340;&#20301;&#32622;&#21644;&#26041;&#21521;&#24314;&#27169;&#32780;&#35774;&#35745;&#12290;&#36890;&#36807;&#22312;&#21333;&#20301;&#22235;&#20803;&#25968;&#32676;&#19978;&#23450;&#20041;&#24179;&#28369;&#21644;&#34920;&#29616;&#21147;&#24378;&#30340;&#27969;&#20197;&#21450;&#23450;&#20041;&#36866;&#24403;&#30340;&#23494;&#24230;&#65292;&#22312;&#26059;&#36716;&#32676;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#25105;&#20204;&#21487;&#20197;&#25104;&#21151;&#22320;&#37319;&#26679;&#20998;&#23376;&#26230;&#20307;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27491;&#21017;&#21270;&#27969;(NF)&#26159;&#19968;&#31867;&#24378;&#22823;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#30001;&#20110;&#20854;&#39640;&#24230;&#28789;&#27963;&#21644;&#34920;&#29616;&#21147;&#65292;&#36817;&#24180;&#26469;&#24191;&#21463;&#27426;&#36814;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#27491;&#21017;&#21270;&#27969;&#65292;&#19987;&#20026;&#19977;&#32500;&#31354;&#38388;&#20013;&#22810;&#20010;&#29289;&#20307;&#30340;&#20301;&#32622;&#21644;&#26041;&#21521;&#24314;&#27169;&#32780;&#35774;&#35745;&#65292;&#20363;&#22914;&#26230;&#20307;&#20013;&#30340;&#20998;&#23376;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#20004;&#20010;&#20851;&#38190;&#24605;&#24819;:&#39318;&#20808;&#65292;&#25105;&#20204;&#22312;&#21333;&#20301;&#22235;&#20803;&#25968;&#32676;&#19978;&#23450;&#20041;&#24179;&#28369;&#21644;&#34920;&#29616;&#21147;&#24378;&#30340;&#27969;&#65292;&#20174;&#32780;&#21487;&#20197;&#25429;&#25417;&#21018;&#20307;&#30340;&#36830;&#32493;&#26059;&#36716;&#36816;&#21160;;&#20854;&#27425;&#65292;&#25105;&#20204;&#21033;&#29992;&#21333;&#20301;&#22235;&#20803;&#25968;&#30340;&#21452;&#35206;&#30422;&#29305;&#24615;&#65292;&#22312;&#26059;&#36716;&#32676;&#19978;&#23450;&#20041;&#19968;&#20010;&#36866;&#24403;&#30340;&#23494;&#24230;&#12290;&#36825;&#30830;&#20445;&#25105;&#20204;&#30340;&#27169;&#22411;&#21487;&#20197;&#20351;&#29992;&#26631;&#20934;&#30340;&#22522;&#20110;&#20284;&#28982;&#26041;&#27861;&#25110;&#22522;&#20110;&#28909;&#21147;&#23398;&#30446;&#26631;&#23494;&#24230;&#30340;&#21464;&#20998;&#25512;&#26029;&#36827;&#34892;&#35757;&#32451;&#12290;&#25105;&#20204;&#36890;&#36807;&#35757;&#32451;&#20004;&#20010;&#20998;&#23376;&#31034;&#20363;&#30340;Boltzmann&#29983;&#25104;&#22120;&#26469;&#35780;&#20272;&#35813;&#26041;&#27861;&#65292;&#21363;&#22235;&#38754;&#20307;&#31995;&#32479;&#30340;&#22810;&#27169;&#24577;&#23494;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Normalizing flows (NF) are a class of powerful generative models that have gained popularity in recent years due to their ability to model complex distributions with high flexibility and expressiveness. In this work, we introduce a new type of normalizing flow that is tailored for modeling positions and orientations of multiple objects in three-dimensional space, such as molecules in a crystal. Our approach is based on two key ideas: first, we define smooth and expressive flows on the group of unit quaternions, which allows us to capture the continuous rotational motion of rigid bodies; second, we use the double cover property of unit quaternions to define a proper density on the rotation group. This ensures that our model can be trained using standard likelihood-based methods or variational inference with respect to a thermodynamic target density. We evaluate the method by training Boltzmann generators for two molecular examples, namely the multi-modal density of a tetrahedral system 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#23618;&#27425;&#24179;&#34913;&#30340;&#27010;&#24565;&#65292;&#35813;&#27010;&#24565;&#25429;&#25417;&#20102;&#26410;&#35266;&#23519;&#21040;&#30340;&#28508;&#22312;&#22240;&#26524;&#22240;&#32032;&#30340;&#24773;&#20917;&#21464;&#21270;&#65292;&#24182;&#25506;&#35752;&#20102;&#21160;&#24577;&#20844;&#24179;&#24615;&#30340;&#23454;&#29616;&#12290;&#22312;&#25351;&#23450;&#30340;&#21160;&#24577;&#19979;&#65292;&#36890;&#24120;&#19981;&#33021;&#36890;&#36807;&#19968;&#27493;&#24178;&#39044;&#26469;&#23454;&#29616;&#38271;&#26399;&#20844;&#24179;&#30446;&#26631;&#12290;</title><link>http://arxiv.org/abs/2301.08987</link><description>&lt;p&gt;
&#23618;&#27425;&#24179;&#34913;&#65306;&#23454;&#29616;&#22522;&#20110;&#28508;&#22312;&#22240;&#26524;&#22240;&#32032;&#30340;&#21160;&#24577;&#20844;&#24179;&#24615;
&lt;/p&gt;
&lt;p&gt;
Tier Balancing: Towards Dynamic Fairness over Underlying Causal Factors. (arXiv:2301.08987v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.08987
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#23618;&#27425;&#24179;&#34913;&#30340;&#27010;&#24565;&#65292;&#35813;&#27010;&#24565;&#25429;&#25417;&#20102;&#26410;&#35266;&#23519;&#21040;&#30340;&#28508;&#22312;&#22240;&#26524;&#22240;&#32032;&#30340;&#24773;&#20917;&#21464;&#21270;&#65292;&#24182;&#25506;&#35752;&#20102;&#21160;&#24577;&#20844;&#24179;&#24615;&#30340;&#23454;&#29616;&#12290;&#22312;&#25351;&#23450;&#30340;&#21160;&#24577;&#19979;&#65292;&#36890;&#24120;&#19981;&#33021;&#36890;&#36807;&#19968;&#27493;&#24178;&#39044;&#26469;&#23454;&#29616;&#38271;&#26399;&#20844;&#24179;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#29616;&#38271;&#26399;&#20844;&#24179;&#24615;&#38656;&#35201;&#20915;&#31574;&#21644;&#24213;&#23618;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#26412;&#25991;&#36890;&#36807;&#22312;&#20915;&#31574;&#21644;&#20998;&#24067;&#20132;&#20114;&#20316;&#29992;&#19978;&#36827;&#34892;&#22240;&#26524;&#24314;&#27169;&#65292;&#24182;&#25552;&#20986;&#23618;&#27425;&#24179;&#34913;&#30340;&#27010;&#24565;&#65292;&#20174;&#21160;&#24577;&#30340;&#35282;&#24230;&#25506;&#35752;&#23454;&#29616;&#38271;&#26399;&#20844;&#24179;&#24615;&#30340;&#21487;&#33021;&#24615;&#12290;&#19982;&#20043;&#21069;&#20165;&#22312;&#35266;&#23519;&#21464;&#37327;&#19978;&#23450;&#20041;&#20844;&#24179;&#27010;&#24565;&#30340;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#36827;&#19968;&#27493;&#25429;&#25417;&#26410;&#35266;&#23519;&#21040;&#30340;&#28508;&#22312;&#22240;&#26524;&#22240;&#32032;&#26041;&#38754;&#26356;&#20026;&#31934;&#30830;&#12290;&#22312;&#25351;&#23450;&#30340;&#21160;&#24577;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#36890;&#24120;&#19981;&#33021;&#36890;&#36807;&#19968;&#27493;&#24178;&#39044;&#26469;&#23454;&#29616;&#38271;&#26399;&#20844;&#24179;&#30446;&#26631;&#12290;&#27492;&#22806;&#65292;&#22312;&#21162;&#21147;&#23454;&#29616;&#38271;&#26399;&#20844;&#24179;&#24615;&#30340;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#35843;&#33410;&#20844;&#24179;&#24230;&#21644;&#24615;&#33021;&#24230;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;
The pursuit of long-term fairness involves the interplay between decision-making and the underlying data generating process. In this paper, through causal modeling with a directed acyclic graph (DAG) on the decision-distribution interplay, we investigate the possibility of achieving long-term fairness from a dynamic perspective. We propose Tier Balancing, a technically more challenging but more natural notion to achieve in the context of long-term, dynamic fairness analysis. Different from previous fairness notions that are defined purely on observed variables, our notion goes one step further, capturing behind-the-scenes situation changes on the unobserved latent causal factors that directly carry out the influence from the current decision to the future data distribution. Under the specified dynamics, we prove that in general one cannot achieve the long-term fairness goal only through one-step interventions. Furthermore, in the effort of approaching long-term fairness, we consider th
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20010;&#20154;&#21487;&#20197;&#36873;&#25321;&#19982;&#20915;&#31574;&#31995;&#32479;&#20849;&#20139;&#21487;&#36873;&#20010;&#20154;&#20449;&#24687;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#20445;&#25252;&#29992;&#25143;&#21516;&#24847;&#30340;PUC&#27010;&#24565;&#65292;&#20026;&#29992;&#25143;&#38544;&#31169;&#20445;&#25252;&#25552;&#20379;&#20102;&#26377;&#21147;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2210.13954</link><description>&lt;p&gt;
&#25105;&#19981;&#24819;&#35828;&#65306;&#22312;&#21487;&#36873;&#20010;&#20154;&#25968;&#25454;&#27169;&#22411;&#20013;&#20445;&#25252;&#29992;&#25143;&#21516;&#24847;
&lt;/p&gt;
&lt;p&gt;
I Prefer not to Say: Protecting User Consent in Models with Optional Personal Data. (arXiv:2210.13954v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.13954
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20010;&#20154;&#21487;&#20197;&#36873;&#25321;&#19982;&#20915;&#31574;&#31995;&#32479;&#20849;&#20139;&#21487;&#36873;&#20010;&#20154;&#20449;&#24687;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#20445;&#25252;&#29992;&#25143;&#21516;&#24847;&#30340;PUC&#27010;&#24565;&#65292;&#20026;&#29992;&#25143;&#38544;&#31169;&#20445;&#25252;&#25552;&#20379;&#20102;&#26377;&#21147;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#20854;&#20013;&#20010;&#20154;&#21487;&#20197;&#36873;&#25321;&#19982;&#20915;&#31574;&#31995;&#32479;&#20849;&#20139;&#21487;&#36873;&#20010;&#20154;&#20449;&#24687;&#65292;&#36825;&#22312;&#29616;&#20195;&#20445;&#38505;&#23450;&#20215;&#27169;&#22411;&#20013;&#24456;&#24120;&#35265;&#12290;&#19968;&#20123;&#29992;&#25143;&#21516;&#24847;&#20351;&#29992;&#20182;&#20204;&#30340;&#25968;&#25454;&#65292;&#32780;&#20854;&#20182;&#20154;&#21017;&#21453;&#23545;&#24182;&#20445;&#25345;&#20854;&#25968;&#25454;&#26410;&#20844;&#24320;&#12290;&#26412;&#25991;&#34920;&#26126;&#65292;&#19981;&#20849;&#20139;&#25968;&#25454;&#30340;&#20915;&#23450;&#26412;&#36523;&#21487;&#20197;&#34987;&#35270;&#20026;&#20449;&#24687;&#65292;&#24212;&#35813;&#21463;&#21040;&#20445;&#25252;&#65292;&#20197;&#23562;&#37325;&#29992;&#25143;&#30340;&#38544;&#31169;&#12290;&#36825;&#19968;&#35266;&#23519;&#32467;&#26524;&#24341;&#21457;&#20102;&#19968;&#20010;&#34987;&#24573;&#35270;&#30340;&#38382;&#39064;&#65292;&#21363;&#22914;&#20309;&#30830;&#20445;&#20445;&#25252;&#20854;&#20010;&#20154;&#25968;&#25454;&#30340;&#29992;&#25143;&#19981;&#20250;&#22240;&#27492;&#21463;&#21040;&#20219;&#20309;&#19981;&#21033;&#24433;&#21709;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#23545;&#20165;&#20351;&#29992;&#33719;&#24471;&#31215;&#26497;&#29992;&#25143;&#21516;&#24847;&#30340;&#20449;&#24687;&#30340;&#27169;&#22411;&#36827;&#34892;&#20102;&#20445;&#25252;&#35201;&#27714;&#30340;&#27491;&#24335;&#21270;&#12290;&#36825;&#25490;&#38500;&#20102;&#20316;&#20986;&#20849;&#20139;&#25968;&#25454;&#19982;&#21542;&#20915;&#23450;&#25152;&#21253;&#21547;&#30340;&#38544;&#21547;&#20449;&#24687;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;Protected User Consent (PUC)&#27010;&#24565;&#65292;&#36825;&#26159;&#25105;&#20204;&#35777;&#26126;&#22312;&#20445;&#25252;&#35201;&#27714;&#19979;&#25439;&#22833;&#26368;&#23567;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
We examine machine learning models in a setup where individuals have the choice to share optional personal information with a decision-making system, as seen in modern insurance pricing models. Some users consent to their data being used whereas others object and keep their data undisclosed. In this work, we show that the decision not to share data can be considered as information in itself that should be protected to respect users' privacy. This observation raises the overlooked problem of how to ensure that users who protect their personal data do not suffer any disadvantages as a result. To address this problem, we formalize protection requirements for models which only use the information for which active user consent was obtained. This excludes implicit information contained in the decision to share data or not. We offer the first solution to this problem by proposing the notion of Protected User Consent (PUC), which we prove to be loss-optimal under our protection requirement. To
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#23558;&#27169;&#22411;&#24615;&#33021;&#21464;&#21270;&#24402;&#22240;&#20110;&#24213;&#23618;&#25968;&#25454;&#29983;&#25104;&#26426;&#21046;&#30340;&#20998;&#24067;&#20559;&#31227;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#25512;&#23548;&#19968;&#31181;&#37325;&#35201;&#24615;&#26435;&#37325;&#26041;&#27861;&#26469;&#35745;&#31639;&#20219;&#24847;&#19968;&#32452;&#20998;&#24067;&#30340;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2210.10769</link><description>&lt;p&gt;
&#20026;&#20160;&#20040;&#27169;&#22411;&#20250;&#22833;&#36133;&#65311;&#23558;&#27169;&#22411;&#24615;&#33021;&#21464;&#21270;&#24402;&#22240;&#20110;&#20998;&#24067;&#20559;&#31227;
&lt;/p&gt;
&lt;p&gt;
"Why did the Model Fail?": Attributing Model Performance Changes to Distribution Shifts. (arXiv:2210.10769v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.10769
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#23558;&#27169;&#22411;&#24615;&#33021;&#21464;&#21270;&#24402;&#22240;&#20110;&#24213;&#23618;&#25968;&#25454;&#29983;&#25104;&#26426;&#21046;&#30340;&#20998;&#24067;&#20559;&#31227;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#25512;&#23548;&#19968;&#31181;&#37325;&#35201;&#24615;&#26435;&#37325;&#26041;&#27861;&#26469;&#35745;&#31639;&#20219;&#24847;&#19968;&#32452;&#20998;&#24067;&#30340;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#20998;&#24067;&#20559;&#31227;&#19979;&#32463;&#24120;&#20250;&#20986;&#29616;&#24615;&#33021;&#19979;&#38477;&#30340;&#24773;&#20917;&#12290;&#36825;&#31181;&#20559;&#31227;&#30340;&#26681;&#26412;&#21407;&#22240;&#21487;&#33021;&#26159;&#22810;&#37325;&#30340;&#22240;&#32032;&#65292;&#27604;&#22914;&#25968;&#25454;&#36136;&#37327;&#30340;&#21464;&#21270;&#12289;&#29305;&#23450;&#21327;&#21464;&#37327;&#20998;&#24067;&#30340;&#24046;&#24322;&#25110;&#32773;&#26631;&#31614;&#19982;&#29305;&#24449;&#20043;&#38388;&#30340;&#20851;&#31995;&#21464;&#21270;&#31561;&#12290;&#24403;&#27169;&#22411;&#22312;&#37096;&#32626;&#26102;&#22833;&#36133;&#26102;&#65292;&#23558;&#24615;&#33021;&#21464;&#21270;&#24402;&#22240;&#20110;&#36825;&#20123;&#22240;&#32032;&#23545;&#20110;&#27169;&#22411;&#24320;&#21457;&#20154;&#21592;&#26469;&#35828;&#33267;&#20851;&#37325;&#35201;&#65292;&#20197;&#35782;&#21035;&#26681;&#26412;&#21407;&#22240;&#24182;&#37319;&#21462;&#32531;&#35299;&#25514;&#26045;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#23558;&#29615;&#22659;&#20043;&#38388;&#30340;&#24615;&#33021;&#24046;&#24322;&#24402;&#22240;&#20110;&#24213;&#23618;&#25968;&#25454;&#29983;&#25104;&#26426;&#21046;&#30340;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#12290;&#25105;&#20204;&#23558;&#35813;&#38382;&#39064;&#26500;&#36896;&#20026;&#19968;&#31181;&#21512;&#20316;&#21338;&#24328;&#30340;&#24418;&#24335;&#65292;&#20854;&#20013;&#29609;&#23478;&#26159;&#20998;&#24067;&#12290;&#25105;&#20204;&#23450;&#20041;&#19968;&#32452;&#20998;&#24067;&#30340;&#20215;&#20540;&#20026;&#24403;&#21482;&#26377;&#36825;&#32452;&#20998;&#24067;&#22312;&#29615;&#22659;&#20043;&#38388;&#21457;&#29983;&#21464;&#21270;&#26102;&#27169;&#22411;&#24615;&#33021;&#30340;&#21464;&#21270;&#65292;&#24182;&#25512;&#23548;&#20986;&#19968;&#31181;&#37325;&#35201;&#24615;&#26435;&#37325;&#26041;&#27861;&#20197;&#35745;&#31639;&#20219;&#24847;&#19968;&#32452;&#20998;&#24067;&#30340;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning models frequently experience performance drops under distribution shifts. The underlying cause of such shifts may be multiple simultaneous factors such as changes in data quality, differences in specific covariate distributions, or changes in the relationship between label and features. When a model does fail during deployment, attributing performance change to these factors is critical for the model developer to identify the root cause and take mitigating actions. In this work, we introduce the problem of attributing performance differences between environments to distribution shifts in the underlying data generating mechanisms. We formulate the problem as a cooperative game where the players are distributions. We define the value of a set of distributions to be the change in model performance when only this set of distributions has changed between environments, and derive an importance weighting method for computing the value of an arbitrary set of distributions. The
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20887;&#20313;&#37325;&#21442;&#25968;&#21270;&#21644;&#31616;&#21333;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26469;&#26368;&#23567;&#21270;&#24102;&#26377;$L_1$&#24809;&#32602;&#30340;&#36890;&#29992;&#21487;&#24494;&#25439;&#22833;&#20989;&#25968;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;\textit{spred}&#65292;&#26159;$L_1$&#30340;&#31934;&#30830;&#27714;&#35299;&#22120;&#65292;&#21487;&#29992;&#20110;&#35757;&#32451;&#31232;&#30095;&#31070;&#32463;&#32593;&#32476;&#20197;&#25191;&#34892;&#22522;&#22240;&#36873;&#25321;&#20219;&#21153;&#21644;&#31070;&#32463;&#32593;&#32476;&#21387;&#32553;&#20219;&#21153;&#65292;&#24357;&#21512;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#31232;&#30095;&#24615;&#21644;&#20256;&#32479;&#32479;&#35745;&#23398;&#20064;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;</title><link>http://arxiv.org/abs/2210.01212</link><description>&lt;p&gt;
&#36890;&#36807;&#20887;&#20313;&#24615;&#23454;&#29616;&#31232;&#30095;&#24615;&#65306;&#29992;SGD&#27714;&#35299;$L_1$
&lt;/p&gt;
&lt;p&gt;
Sparsity by Redundancy: Solving $L_1$ with SGD. (arXiv:2210.01212v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.01212
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20887;&#20313;&#37325;&#21442;&#25968;&#21270;&#21644;&#31616;&#21333;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26469;&#26368;&#23567;&#21270;&#24102;&#26377;$L_1$&#24809;&#32602;&#30340;&#36890;&#29992;&#21487;&#24494;&#25439;&#22833;&#20989;&#25968;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;\textit{spred}&#65292;&#26159;$L_1$&#30340;&#31934;&#30830;&#27714;&#35299;&#22120;&#65292;&#21487;&#29992;&#20110;&#35757;&#32451;&#31232;&#30095;&#31070;&#32463;&#32593;&#32476;&#20197;&#25191;&#34892;&#22522;&#22240;&#36873;&#25321;&#20219;&#21153;&#21644;&#31070;&#32463;&#32593;&#32476;&#21387;&#32553;&#20219;&#21153;&#65292;&#24357;&#21512;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#31232;&#30095;&#24615;&#21644;&#20256;&#32479;&#32479;&#35745;&#23398;&#20064;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a method called "spred" to minimize a generic differentiable loss function with $L_1$ penalty using redundant reparametrization and straightforward stochastic gradient descent. It is an exact solver of $L_1$ and can be used to train sparse neural networks for gene selection tasks and neural network compression tasks, bridging the gap between sparsity in deep learning and conventional statistical learning.
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20887;&#20313;&#37325;&#21442;&#25968;&#21270;&#21644;&#31616;&#21333;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26469;&#26368;&#23567;&#21270;&#24102;&#26377;$L_1$&#24809;&#32602;&#30340;&#36890;&#29992;&#21487;&#24494;&#25439;&#22833;&#20989;&#25968;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#25552;&#35758;&#26159;$L_1$&#24809;&#32602;&#31561;&#20215;&#20110;&#24102;&#26377;&#26435;&#37325;&#34928;&#20943;&#30340;&#21487;&#24494;&#37325;&#21442;&#25968;&#21270;&#30340;&#30452;&#25509;&#25512;&#24191;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#21363;\textit{spred}&#65292;&#26159;$L_1$&#30340;&#31934;&#30830;&#27714;&#35299;&#22120;&#65292;&#24182;&#19988;&#23545;&#20110;&#36890;&#29992;&#30340;&#38750;&#20984;&#20989;&#25968;&#65292;&#37325;&#21442;&#25968;&#21270;&#25216;&#24039;&#26159;&#23436;&#20840;&#8220;&#33391;&#24615;&#8221;&#30340;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#65292;&#21253;&#25324;(1)&#35757;&#32451;&#31232;&#30095;&#31070;&#32463;&#32593;&#32476;&#20197;&#25191;&#34892;&#22522;&#22240;&#36873;&#25321;&#20219;&#21153;&#65292;&#20854;&#20013;&#28041;&#21450;&#22312;&#38750;&#24120;&#39640;&#32500;&#31354;&#38388;&#20013;&#25214;&#21040;&#30456;&#20851;&#29305;&#24449;&#65292;&#20197;&#21450;(2)&#31070;&#32463;&#32593;&#32476;&#21387;&#32553;&#20219;&#21153;&#65292;&#20808;&#21069;&#23581;&#35797;&#24212;&#29992;$L_1$&#24809;&#32602;&#30340;&#26041;&#27861;&#22343;&#26410;&#25104;&#21151;&#12290;&#20174;&#27010;&#24565;&#19978;&#35762;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#24357;&#21512;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#31232;&#30095;&#24615;&#21644;&#20256;&#32479;&#32479;&#35745;&#23398;&#20064;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose to minimize a generic differentiable loss function with $L_1$ penalty with a redundant reparametrization and straightforward stochastic gradient descent. Our proposal is the direct generalization of a series of previous ideas that the $L_1$ penalty may be equivalent to a differentiable reparametrization with weight decay. We prove that the proposed method, \textit{spred}, is an exact solver of $L_1$ and that the reparametrization trick is completely ``benign" for a generic nonconvex function. Practically, we demonstrate the usefulness of the method in (1) training sparse neural networks to perform gene selection tasks, which involves finding relevant features in a very high dimensional space, and (2) neural network compression task, to which previous attempts at applying the $L_1$-penalty have been unsuccessful. Conceptually, our result bridges the gap between the sparsity in deep learning and conventional statistical learning.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25506;&#35752;&#20102;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#20013;&#36801;&#31227;&#22240;&#26524;&#30693;&#35782;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#20351;&#29992;CITA&#24230;&#37327;&#36827;&#34892;ITE&#30693;&#35782;&#36716;&#31227;&#30340;&#26694;&#26550;&#65292;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2210.00380</link><description>&lt;p&gt;
&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#30340;&#36801;&#31227;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Transfer Learning for Individual Treatment Effect Estimation. (arXiv:2210.00380v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.00380
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25506;&#35752;&#20102;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#20013;&#36801;&#31227;&#22240;&#26524;&#30693;&#35782;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#20351;&#29992;CITA&#24230;&#37327;&#36827;&#34892;ITE&#30693;&#35782;&#36716;&#31227;&#30340;&#26694;&#26550;&#65292;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#20013;&#36890;&#36807;&#20219;&#21153;&#20043;&#38388;&#36716;&#31227;&#22240;&#26524;&#30693;&#35782;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#20174;&#29702;&#35770;&#19978;&#35780;&#20272;&#20102;&#36716;&#31227;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#30693;&#35782;&#30340;&#21487;&#34892;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#23454;&#29992;&#30340;&#26694;&#26550;&#26469;&#23454;&#29616;&#26377;&#25928;&#30340;&#36716;&#31227;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#19979;&#30028;&#26469;&#35828;&#26126;&#30446;&#26631;&#20219;&#21153;&#30340;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#35823;&#24046;&#23384;&#22312;&#25361;&#25112;&#65292;&#22240;&#20026;&#32570;&#20047;&#21453;&#20107;&#23454;&#20449;&#24687;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#30446;&#26631;&#20219;&#21153;&#21453;&#20107;&#23454;&#25439;&#22833;&#21644;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#35823;&#24046;&#30340;&#27867;&#21270;&#19978;&#30028;&#65292;&#35777;&#26126;&#20102;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#30693;&#35782;&#36716;&#31227;&#30340;&#21487;&#34892;&#24615;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#20854;&#20013;&#20351;&#29992;&#26032;&#30340;&#22240;&#26524;&#25512;&#26029;&#20219;&#21153;&#20146;&#21644;&#24230;&#65288;CITA&#65289;&#24230;&#37327;&#36827;&#34892;ITE&#30693;&#35782;&#36716;&#31227;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20351;&#29992;CITA&#26469;&#25214;&#21040;&#26368;&#25509;&#36817;&#30446;&#26631;&#20219;&#21153;&#30340;&#28304;&#20219;&#21153;&#65292;&#24182;&#21033;&#29992;&#23427;&#26469;&#36827;&#34892;ITE&#30693;&#35782;&#36716;&#31227;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#23454;&#35777;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;ITE&#30693;&#35782;&#36716;&#31227;&#21487;&#20197;&#26174;&#33879;&#65288;
&lt;/p&gt;
&lt;p&gt;
This work considers the problem of transferring causal knowledge between tasks for Individual Treatment Effect (ITE) estimation. To this end, we theoretically assess the feasibility of transferring ITE knowledge and present a practical framework for efficient transfer. A lower bound is introduced on the ITE error of the target task to demonstrate that ITE knowledge transfer is challenging due to the absence of counterfactual information. Nevertheless, we establish generalization upper bounds on the counterfactual loss and ITE error of the target task, demonstrating the feasibility of ITE knowledge transfer. Subsequently, we introduce a framework with a new Causal Inference Task Affinity (CITA) measure for ITE knowledge transfer. Specifically, we use CITA to find the closest source task to the target task and utilize it for ITE knowledge transfer. Empirical studies are provided, demonstrating the efficacy of the proposed method. We observe that ITE knowledge transfer can significantly (
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21516;&#24577;&#33258;&#32534;&#30721;&#22120;&#26041;&#27861;&#65292;&#20351;&#26426;&#22120;&#33021;&#22815;&#22312;&#34892;&#21160;&#20013;&#23398;&#20064;&#21040;&#19982;&#20854;&#34892;&#20026;&#30456;&#19968;&#33268;&#30340;&#24863;&#30693;&#20449;&#24687;&#30340;&#20869;&#37096;&#34920;&#31034;&#65292;&#24182;&#25429;&#33719;&#29615;&#22659;&#20013;&#30340;&#36716;&#25442;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2207.12067</link><description>&lt;p&gt;
&#21516;&#24577;&#33258;&#32534;&#30721;&#22120; - &#20174;&#35266;&#23519;&#21040;&#36716;&#21270;&#23398;&#20064;&#32676;&#32452;&#32467;&#26500;&#34920;&#29616;
&lt;/p&gt;
&lt;p&gt;
Homomorphism Autoencoder -- Learning Group Structured Representations from Observed Transitions. (arXiv:2207.12067v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.12067
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21516;&#24577;&#33258;&#32534;&#30721;&#22120;&#26041;&#27861;&#65292;&#20351;&#26426;&#22120;&#33021;&#22815;&#22312;&#34892;&#21160;&#20013;&#23398;&#20064;&#21040;&#19982;&#20854;&#34892;&#20026;&#30456;&#19968;&#33268;&#30340;&#24863;&#30693;&#20449;&#24687;&#30340;&#20869;&#37096;&#34920;&#31034;&#65292;&#24182;&#25429;&#33719;&#29615;&#22659;&#20013;&#30340;&#36716;&#25442;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#20309;&#35753;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#23398;&#20064;&#21040;&#20934;&#30830;&#34920;&#31034;&#20854;&#19982;&#30495;&#23454;&#19990;&#30028;&#20132;&#20114;&#30340;&#20869;&#22312;&#27169;&#22411;&#26159;&#19968;&#20010;&#23578;&#24453;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#26500;&#24314;&#19981;&#20165;&#21253;&#21547;&#35266;&#23519;&#24615;&#30693;&#35782;&#65292;&#20063;&#21253;&#21547;&#24178;&#39044;&#24615;&#30693;&#35782;&#30340;&#34920;&#29616;&#23398;&#20064;&#26694;&#26550;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#34920;&#31034;&#23398;&#20064;&#21644;&#32676;&#35770;&#30340;&#26041;&#27861;&#26469;&#30740;&#31350;&#35813;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#26041;&#27861;&#65292;&#20351;&#26426;&#22120;&#33021;&#22815;&#22312;&#34892;&#21160;&#36807;&#31243;&#20013;&#23398;&#20064;&#21040;&#19982;&#20043;&#30456;&#19968;&#33268;&#30340;&#24863;&#30693;&#20449;&#24687;&#30340;&#20869;&#37096;&#34920;&#31034;&#65292;&#32780;&#36825;&#20123;&#34892;&#21160;&#23454;&#38469;&#19978;&#26159;&#21464;&#25442;&#36825;&#20123;&#20449;&#24687;&#30340;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#33258;&#32534;&#30721;&#22120;&#24182;&#22312;&#20854;&#28508;&#22312;&#31354;&#38388;&#19978;&#24212;&#29992;&#32676;&#32452;&#34920;&#31034;&#65292;&#36890;&#36807;&#21033;&#29992;&#31561;&#21464;&#25439;&#22833;&#24378;&#21046;&#23454;&#26045;&#36866;&#24403;&#30340;&#21516;&#24577;&#24615;&#36136;&#20197;&#23436;&#25104;&#35757;&#32451;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#38656;&#35201;&#20808;&#39564;&#32676;&#32452;&#30693;&#35782;&#65292;&#24182;&#19988;&#19981;&#38480;&#21046;&#20195;&#29702;&#21487;&#25191;&#34892;&#30340;&#34892;&#21160;&#38598;&#21512;&#12290;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#33021;&#22815;&#23398;&#20064;&#21040;&#34892;&#21160;&#30340;&#32676;&#32452;&#34920;&#31034;&#65292;&#20174;&#32780;&#25429;&#33719;&#20102;&#29615;&#22659;&#20013;&#30340;&#36716;&#25442;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
How can agents learn internal models that veridically represent interactions with the real world is a largely open question. As machine learning is moving towards representations containing not just observational but also interventional knowledge, we study this problem using tools from representation learning and group theory. We propose methods enabling an agent acting upon the world to learn internal representations of sensory information that are consistent with actions that modify it. We use an autoencoder equipped with a group representation acting on its latent space, trained using an equivariance-derived loss in order to enforce a suitable homomorphism property on the group representation. In contrast to existing work, our approach does not require prior knowledge of the group and does not restrict the set of actions the agent can perform. We motivate our method theoretically, and show empirically that it can learn a group representation of the actions, thereby capturing the str
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#21487;&#35782;&#21035;&#30340;&#27010;&#24565;&#21457;&#29616;&#26041;&#27861;&#65292;&#21487;&#20197;&#24674;&#22797;&#20986;&#22810;&#20010;&#24050;&#30693;&#30340;&#27010;&#24565;&#65292;&#20197;&#30830;&#20445;&#35299;&#37322;&#30340;&#21487;&#38752;&#24615;&#12290;&#23545;&#20110;&#20855;&#26377;&#20381;&#36182;&#20851;&#31995;&#30340;&#27010;&#24565;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#22270;&#20687;&#29983;&#25104;&#36807;&#31243;&#30340;&#21151;&#33021;&#32452;&#21512;&#24615;&#36136;&#12290;&#35813;&#26041;&#27861;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2206.13872</link><description>&lt;p&gt;
&#21518;&#39564;&#27010;&#24565;&#35299;&#37322;&#20309;&#26102;&#21487;&#35782;&#21035;&#65311;
&lt;/p&gt;
&lt;p&gt;
When are Post-hoc Conceptual Explanations Identifiable?. (arXiv:2206.13872v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.13872
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#21487;&#35782;&#21035;&#30340;&#27010;&#24565;&#21457;&#29616;&#26041;&#27861;&#65292;&#21487;&#20197;&#24674;&#22797;&#20986;&#22810;&#20010;&#24050;&#30693;&#30340;&#27010;&#24565;&#65292;&#20197;&#30830;&#20445;&#35299;&#37322;&#30340;&#21487;&#38752;&#24615;&#12290;&#23545;&#20110;&#20855;&#26377;&#20381;&#36182;&#20851;&#31995;&#30340;&#27010;&#24565;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#22270;&#20687;&#29983;&#25104;&#36807;&#31243;&#30340;&#21151;&#33021;&#32452;&#21512;&#24615;&#36136;&#12290;&#35813;&#26041;&#27861;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#23884;&#20837;&#36890;&#24120;&#38656;&#35201;&#36890;&#36807;&#27010;&#24565;&#35299;&#37322;&#26469;&#29702;&#35299;&#21644;&#20998;&#35299;&#65292;&#36825;&#31181;&#38656;&#27714;&#22312;&#35299;&#37322;&#20013;&#19981;&#21253;&#21547;&#26377;&#25928;&#27010;&#24565;&#26631;&#31614;&#30340;&#24773;&#20917;&#19979;&#23588;&#20026;&#26174;&#33879;&#12290;&#20026;&#20102;&#25552;&#20379;&#21518;&#39564;&#35299;&#37322;&#65292;&#27010;&#24565;&#21457;&#29616;&#26041;&#27861;&#20250;&#22312;&#24050;&#35757;&#32451;&#30340;&#23884;&#20837;&#31354;&#38388;&#20013;&#25628;&#32034;&#35299;&#37322;&#24615;&#24378;&#30340;&#27010;&#24565;&#65292;&#20363;&#22914;&#29289;&#20307;&#24418;&#29366;&#25110;&#39068;&#33394;&#12290;&#19982;&#20043;&#21069;&#30340;&#24037;&#20316;&#19981;&#21516;&#65292;&#25105;&#20204;&#35748;&#20026;&#27010;&#24565;&#21457;&#29616;&#24212;&#35813;&#26159;&#21487;&#35782;&#21035;&#30340;&#65292;&#36825;&#24847;&#21619;&#30528;&#21487;&#20197;&#34987;&#35777;&#26126;&#22320;&#24674;&#22797;&#20986;&#22810;&#20010;&#24050;&#30693;&#30340;&#27010;&#24565;&#65292;&#20197;&#30830;&#20445;&#35299;&#37322;&#30340;&#21487;&#38752;&#24615;&#12290;&#20026;&#20102;&#20316;&#20026;&#19968;&#20010;&#36215;&#28857;&#65292;&#25105;&#20204;&#26126;&#30830;&#22320;&#23558;&#27010;&#24565;&#21457;&#29616;&#19982;&#20256;&#32479;&#26041;&#27861;&#65288;&#20363;&#22914;&#20027;&#25104;&#20998;&#20998;&#26512;&#21644;&#29420;&#31435;&#25104;&#20998;&#20998;&#26512;&#65289;&#32852;&#31995;&#36215;&#26469;&#65292;&#24182;&#36890;&#36807;&#34920;&#26126;&#23427;&#20204;&#21487;&#20197;&#24674;&#22797;&#20855;&#26377;&#38750;&#39640;&#26031;&#20998;&#24067;&#30340;&#29420;&#31435;&#27010;&#24565;&#26469;&#38416;&#26126;&#36825;&#19968;&#28857;&#12290;&#23545;&#20110;&#20855;&#26377;&#20381;&#36182;&#20851;&#31995;&#30340;&#27010;&#24565;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#22270;&#20687;&#29983;&#25104;&#36807;&#31243;&#30340;&#21151;&#33021;&#32452;&#21512;&#24615;&#36136;&#12290;&#25105;&#20204;&#30340;&#21487;&#35777;&#26126;&#21487;&#35782;&#21035;&#30340;&#27010;&#24565;&#21457;&#29616;&#26041;&#27861;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Interest in understanding and factorizing learned embedding spaces through conceptual explanations is steadily growing. When no human concept labels are available, concept discovery methods search trained embedding spaces for interpretable concepts like object shape or color that can be used to provide post-hoc explanations for decisions. Unlike previous work, we argue that concept discovery should be identifiable, meaning that a number of known concepts can be provably recovered to guarantee reliability of the explanations. As a starting point, we explicitly make the connection between concept discovery and classical methods like Principal Component Analysis and Independent Component Analysis by showing that they can recover independent concepts with non-Gaussian distributions. For dependent concepts, we propose two novel approaches that exploit functional compositionality properties of image-generating processes. Our provably identifiable concept discovery methods substantially outpe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24046;&#20998;&#38544;&#31169;&#20248;&#21270;&#31639;&#27861;&#26469;&#22788;&#29702;&#20854;&#23427;&#31639;&#27861;&#26080;&#27861;&#22788;&#29702;&#30340;&#38750;&#22343;&#21248;&#26446;&#26222;&#24076;&#33576;&#24773;&#24418;&#65292;&#24182;&#19988;&#22312;&#20855;&#20307;&#24212;&#29992;&#20013;&#25552;&#20379;&#20102;&#30456;&#24212;&#30340;&#21442;&#25968;&#35843;&#25972;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2206.10713</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#20248;&#21270;&#20013;&#36229;&#36234;&#32479;&#19968;&#26446;&#26222;&#24076;&#33576;&#26465;&#20214;
&lt;/p&gt;
&lt;p&gt;
Beyond Uniform Lipschitz Condition in Differentially Private Optimization. (arXiv:2206.10713v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.10713
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24046;&#20998;&#38544;&#31169;&#20248;&#21270;&#31639;&#27861;&#26469;&#22788;&#29702;&#20854;&#23427;&#31639;&#27861;&#26080;&#27861;&#22788;&#29702;&#30340;&#38750;&#22343;&#21248;&#26446;&#26222;&#24076;&#33576;&#24773;&#24418;&#65292;&#24182;&#19988;&#22312;&#20855;&#20307;&#24212;&#29992;&#20013;&#25552;&#20379;&#20102;&#30456;&#24212;&#30340;&#21442;&#25968;&#35843;&#25972;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#20851;&#20110;&#24046;&#20998;&#38544;&#31169;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;DP-SGD&#65289;&#30340;&#20808;&#21069;&#32467;&#26524;&#37117;&#26159;&#22312;&#32479;&#19968;&#26446;&#26222;&#24076;&#33576;&#24615;&#30340;&#31616;&#21270;&#20551;&#35774;&#19979;&#23548;&#20986;&#30340;&#65292;&#21363;&#27599;&#20010;&#26679;&#26412;&#30340;&#26799;&#24230;&#37117;&#26159;&#22343;&#21248;&#26377;&#30028;&#30340;&#12290;&#25105;&#20204;&#36890;&#36807;&#20551;&#23450;&#27599;&#20010;&#26679;&#26412;&#30340;&#26799;&#24230;&#20855;&#26377;&#26679;&#26412;&#30456;&#20851;&#30340;&#19978;&#30028;&#65292;&#21363;&#27599;&#20010;&#26679;&#26412;&#30340;&#26446;&#26222;&#24076;&#33576;&#24120;&#25968;&#65292;&#20174;&#32780;&#25512;&#24191;&#20102;&#32479;&#19968;&#26446;&#26222;&#24076;&#33576;&#24615;&#12290;&#36825;&#20123;&#26412;&#36523;&#21487;&#33021;&#26159;&#26080;&#30028;&#30340;&#12290;&#24403;&#27599;&#20010;&#26679;&#26412;&#30340;&#26446;&#26222;&#24076;&#33576;&#24120;&#25968;&#26159;&#26377;&#30028;&#30340;&#26102;&#65292;&#25105;&#20204;&#20026;DP-SGD&#22312;&#20984;&#36229;&#21442;&#25968;&#21270;&#35774;&#32622;&#20013;&#36873;&#25321;&#21098;&#36753;&#33539;&#25968;&#25552;&#20379;&#20102;&#21407;&#21017;&#24615;&#25351;&#23548;&#65307;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24314;&#35758;&#20165;&#35843;&#25972;&#21098;&#36753;&#33539;&#25968;&#65292;&#30452;&#21040;&#26368;&#23567;&#27599;&#20010;&#26679;&#26412;&#26446;&#26222;&#24076;&#33576;&#24120;&#25968;&#30340;&#20540;&#12290;&#36825;&#22312;&#28145;&#24230;&#32593;&#32476;&#19978;&#39044;&#20808;&#35757;&#32451;&#20844;&#20849;&#25968;&#25454;&#30340; softmax &#23618;&#30340;&#31169;&#20154;&#35757;&#32451;&#20013;&#26377;&#24212;&#29992;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;8&#20010;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#24314;&#35758;&#30340;&#21151;&#25928;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#20026;DP-SGD&#22312;&#20984;&#21644;&#38750;&#20984;&#20989;&#25968;&#19978;&#25552;&#20379;&#20102;&#26032;&#30340;&#25910;&#25947;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most prior results on differentially private stochastic gradient descent (DP-SGD) are derived under the simplistic assumption of uniform Lipschitzness, i.e., the per-sample gradients are uniformly bounded. We generalize uniform Lipschitzness by assuming that the per-sample gradients have sample-dependent upper bounds, i.e., per-sample Lipschitz constants, which themselves may be unbounded. We provide principled guidance on choosing the clip norm in DP-SGD for convex over-parameterized settings satisfying our general version of Lipschitzness when the per-sample Lipschitz constants are bounded; specifically, we recommend tuning the clip norm only till values up to the minimum per-sample Lipschitz constant. This finds application in the private training of a softmax layer on top of a deep network pre-trained on public data. We verify the efficacy of our recommendation via experiments on 8 datasets. Furthermore, we provide new convergence results for DP-SGD on convex and nonconvex function
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;RKHS&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#20013;&#30340;&#21327;&#21464;&#37327;&#36716;&#31227;&#38382;&#39064;&#65292;&#38024;&#23545;&#20004;&#20010;&#19981;&#21516;&#30340;&#20284;&#28982;&#27604;&#26063;&#65292;&#35777;&#26126;&#20102;&#20351;&#29992;KRR&#20272;&#35745;&#37327;&#20855;&#26377;&#26497;&#23567;&#21270;&#29575;&#26368;&#20248;&#30340;&#29305;&#28857;&#65292;&#23588;&#20854;&#26159;&#22312;&#20284;&#28982;&#27604;&#34987;&#22343;&#21248;&#26377;&#30028;&#26102;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#26412;&#25991;&#20063;&#35777;&#26126;&#20102;&#65292;&#22312;&#21327;&#21464;&#37327;&#36716;&#31227;&#19979;&#19968;&#20010;naive&#30340;&#20272;&#35745;&#22120;&#30456;&#27604;&#20110;KRR&#26159;&#20005;&#26684;&#27425;&#20248;&#30340;&#12290;</title><link>http://arxiv.org/abs/2205.02986</link><description>&lt;p&gt;
&#22312;RKHS&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#20013;&#26368;&#20248;&#35299;&#20915;&#21327;&#21464;&#37327;&#36716;&#31227;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Optimally tackling covariate shift in RKHS-based nonparametric regression. (arXiv:2205.02986v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.02986
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;RKHS&#30340;&#38750;&#21442;&#25968;&#22238;&#24402;&#20013;&#30340;&#21327;&#21464;&#37327;&#36716;&#31227;&#38382;&#39064;&#65292;&#38024;&#23545;&#20004;&#20010;&#19981;&#21516;&#30340;&#20284;&#28982;&#27604;&#26063;&#65292;&#35777;&#26126;&#20102;&#20351;&#29992;KRR&#20272;&#35745;&#37327;&#20855;&#26377;&#26497;&#23567;&#21270;&#29575;&#26368;&#20248;&#30340;&#29305;&#28857;&#65292;&#23588;&#20854;&#26159;&#22312;&#20284;&#28982;&#27604;&#34987;&#22343;&#21248;&#26377;&#30028;&#26102;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#26412;&#25991;&#20063;&#35777;&#26126;&#20102;&#65292;&#22312;&#21327;&#21464;&#37327;&#36716;&#31227;&#19979;&#19968;&#20010;naive&#30340;&#20272;&#35745;&#22120;&#30456;&#27604;&#20110;KRR&#26159;&#20005;&#26684;&#27425;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#19978;&#30740;&#31350;&#20102;&#38750;&#21442;&#25968;&#22238;&#24402;&#20013;&#30340;&#21327;&#21464;&#37327;&#36716;&#31227;&#38382;&#39064;&#12290;&#25105;&#20204;&#20851;&#27880;&#20004;&#20010;&#20351;&#29992;&#28304;&#21644;&#30446;&#26631;&#20998;&#24067;&#20043;&#38388;&#30340;&#20284;&#28982;&#27604;&#23450;&#20041;&#30340;&#33258;&#28982;&#21327;&#21464;&#37327;&#36716;&#31227;&#38382;&#39064;&#26063;&#12290;&#24403;&#20284;&#28982;&#27604;&#34987;&#22343;&#21248;&#26377;&#30028;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#24102;&#26377;&#31934;&#24515;&#36873;&#25321;&#30340;&#27491;&#21017;&#21270;&#21442;&#25968;&#30340;&#26680;&#23725;&#22238;&#24402;(KRR)&#20272;&#35745;&#37327;&#26159;&#26497;&#23567;&#21270;&#29575;&#26368;&#20248;&#30340;&#65288;&#26368;&#22810;&#24046;&#19968;&#20010;&#23545;&#25968;&#22240;&#23376;&#65289;&#65292;&#23545;&#20110;&#19968;&#22823;&#31867;&#20855;&#26377;&#27491;&#21017;&#26680;&#29305;&#24449;&#20540;&#30340;RKHS&#32780;&#35328;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#38500;&#20102;&#20284;&#28982;&#27604;&#19978;&#30028;&#20043;&#22806;&#65292;KRR&#19981;&#38656;&#35201;&#23545;&#20284;&#28982;&#27604;&#26377;&#23436;&#20840;&#30340;&#30693;&#35782;&#12290;&#19982;&#27809;&#26377;&#21327;&#21464;&#37327;&#36716;&#31227;&#30340;&#26631;&#20934;&#32479;&#35745;&#35774;&#32622;&#24418;&#25104;&#40092;&#26126;&#23545;&#27604;&#30340;&#26159;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#19968;&#20010;&#31616;&#21333;&#20272;&#35745;&#22120;&#65292;&#21363;&#22312;&#20989;&#25968;&#31867;&#20013;&#26368;&#23567;&#21270;&#32463;&#39564;&#39118;&#38505;&#65292;&#19982;KRR&#30456;&#27604;&#65292;&#22312;&#21327;&#21464;&#37327;&#36716;&#31227;&#19979;&#26159;&#20005;&#26684;&#27425;&#20248;&#30340;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#26356;&#22823;&#30340;&#21327;&#21464;&#37327;&#36716;&#31227;&#38382;&#39064;&#31867;&#65292;&#20854;&#20013;&#20284;&#28982;&#27604;&#21487;&#33021;&#26159;&#26080;&#30028;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the covariate shift problem in the context of nonparametric regression over a reproducing kernel Hilbert space (RKHS). We focus on two natural families of covariate shift problems defined using the likelihood ratios between the source and target distributions. When the likelihood ratios are uniformly bounded, we prove that the kernel ridge regression (KRR) estimator with a carefully chosen regularization parameter is minimax rate-optimal (up to a log factor) for a large family of RKHSs with regular kernel eigenvalues. Interestingly, KRR does not require full knowledge of likelihood ratios apart from an upper bound on them. In striking contrast to the standard statistical setting without covariate shift, we also demonstrate that a naive estimator, which minimizes the empirical risk over the function class, is strictly sub-optimal under covariate shift as compared to KRR. We then address the larger class of covariate shift problems where the likelihood ratio is possibly unbounde
&lt;/p&gt;</description></item><item><title>&#23545;&#31216;&#25439;&#22833;&#26159;&#19968;&#31181;&#26032;&#22411;&#30340;&#20195;&#29702;&#25439;&#22833;&#65292;&#33021;&#22815;&#20351;&#24471;&#23398;&#20064;&#36807;&#31243;&#23545;&#20110;&#21463;&#25439;&#26631;&#31614;&#26356;&#21152;&#40065;&#26834;&#65292;&#20174;&#32780;&#25552;&#39640;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2101.01366</link><description>&lt;p&gt;
&#21487;&#38752;&#26426;&#22120;&#23398;&#20064;&#30340;&#23545;&#31216;&#25439;&#22833;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
A Symmetric Loss Perspective of Reliable Machine Learning. (arXiv:2101.01366v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2101.01366
&lt;/p&gt;
&lt;p&gt;
&#23545;&#31216;&#25439;&#22833;&#26159;&#19968;&#31181;&#26032;&#22411;&#30340;&#20195;&#29702;&#25439;&#22833;&#65292;&#33021;&#22815;&#20351;&#24471;&#23398;&#20064;&#36807;&#31243;&#23545;&#20110;&#21463;&#25439;&#26631;&#31614;&#26356;&#21152;&#40065;&#26834;&#65292;&#20174;&#32780;&#25552;&#39640;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#22312;&#20108;&#20803;&#20998;&#31867;&#20013;&#26368;&#23567;&#21270;&#32463;&#39564;&#39118;&#38505;&#26102;&#65292;&#24120;&#24120;&#23558;&#38646;&#19968;&#25439;&#22833;&#26367;&#25442;&#20026;&#20195;&#29702;&#25439;&#22833;&#65292;&#20197;&#20351;&#23398;&#20064;&#30446;&#26631;&#26131;&#20110;&#20248;&#21270;&#12290;&#20108;&#20803;&#20998;&#31867;&#30340;&#20195;&#29702;&#25439;&#22833;&#20363;&#22914;&#36923;&#36753;&#25439;&#22833;&#65292;hinge&#25439;&#22833;&#21644;sigmoid&#25439;&#22833;&#24191;&#20026;&#20154;&#30693;&#12290;&#24050;&#30693;&#20195;&#29702;&#25439;&#22833;&#30340;&#36873;&#25321;&#20250;&#26497;&#22823;&#22320;&#24433;&#21709;&#35757;&#32451;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#65292;&#22240;&#27492;&#24212;&#35813;&#20180;&#32454;&#36873;&#25321;&#12290;&#26368;&#36817;&#65292;&#28385;&#36275;&#26576;&#20123;&#23545;&#31216;&#26465;&#20214;&#65288;&#31216;&#20026;&#23545;&#31216;&#25439;&#22833;&#65289;&#30340;&#20195;&#29702;&#25439;&#22833;&#24050;&#32463;&#35777;&#26126;&#20102;&#23427;&#20204;&#22312;&#23398;&#20064;&#26469;&#33258;&#25439;&#22351;&#26631;&#31614;&#30340;&#25968;&#25454;&#26041;&#38754;&#30340;&#23454;&#29992;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#23545;&#31216;&#25439;&#22833;&#21450;&#20854;&#24212;&#29992;&#30340;&#27010;&#36848;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#22238;&#39038;&#20102;&#23545;&#31216;&#25439;&#22833;&#22914;&#20309;&#22312;&#24179;&#34913;&#35823;&#24046;&#29575;&#65288;BER&#65289;&#26368;&#23567;&#21270;&#21644;&#25805;&#20316;&#29305;&#24449;&#26354;&#32447;&#19979;&#38754;&#31215;&#65288;AUC&#65289;&#26368;&#22823;&#21270;&#20013;&#20135;&#29983;&#40065;&#26834;&#20998;&#31867;&#30340;&#26041;&#27861;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#28436;&#31034;&#20102;&#40065;&#26834;AUC&#26368;&#22823;&#21270;&#26041;&#27861;&#21487;&#20197;&#21463;&#30410;&#20110;&#21463;&#25439;&#26631;&#31614;&#65292;&#23588;&#20854;&#26159;&#19982;&#20854;&#20182;&#20195;&#29702;&#25439;&#22833;&#30456;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;
When minimizing the empirical risk in binary classification, it is a common practice to replace the zero-one loss with a surrogate loss to make the learning objective feasible to optimize. Examples of well-known surrogate losses for binary classification include the logistic loss, hinge loss, and sigmoid loss. It is known that the choice of a surrogate loss can highly influence the performance of the trained classifier and therefore it should be carefully chosen. Recently, surrogate losses that satisfy a certain symmetric condition (aka., symmetric losses) have demonstrated their usefulness in learning from corrupted labels. In this article, we provide an overview of symmetric losses and their applications. First, we review how a symmetric loss can yield robust classification from corrupted labels in balanced error rate (BER) minimization and area under the receiver operating characteristic curve (AUC) maximization. Then, we demonstrate how the robust AUC maximization method can benefi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#32467;&#26500;&#21270;&#36830;&#32493;&#31232;&#30095;&#21270;&#30340;&#28145;&#24230;&#32593;&#32476;&#32467;&#26500;&#29983;&#38271;&#26041;&#27861;&#65292;&#36890;&#36807;&#36830;&#32493;&#26494;&#24347;&#21644;&#37319;&#26679;&#31232;&#30095;&#23376;&#32593;&#32476;&#65292;&#21487;&#20197;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#36798;&#21040;&#32039;&#20945;&#30340;&#20462;&#21098;&#32593;&#32476;&#32467;&#26500;&#65292;&#21516;&#26102;&#22823;&#24133;&#38477;&#20302;&#35745;&#31639;&#22797;&#26434;&#24230;&#24182;&#20445;&#25345;&#36739;&#39640;&#30340;&#20934;&#30830;&#29575;&#12290;</title><link>http://arxiv.org/abs/2007.15353</link><description>&lt;p&gt;
&#32467;&#26500;&#21270;&#36830;&#32493;&#31232;&#30095;&#21270;&#22686;&#24378;&#28145;&#24230;&#32593;&#32476;&#30340;&#35757;&#32451;&#25928;&#29575;
&lt;/p&gt;
&lt;p&gt;
Growing Efficient Deep Networks by Structured Continuous Sparsification. (arXiv:2007.15353v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2007.15353
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#32467;&#26500;&#21270;&#36830;&#32493;&#31232;&#30095;&#21270;&#30340;&#28145;&#24230;&#32593;&#32476;&#32467;&#26500;&#29983;&#38271;&#26041;&#27861;&#65292;&#36890;&#36807;&#36830;&#32493;&#26494;&#24347;&#21644;&#37319;&#26679;&#31232;&#30095;&#23376;&#32593;&#32476;&#65292;&#21487;&#20197;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#36798;&#21040;&#32039;&#20945;&#30340;&#20462;&#21098;&#32593;&#32476;&#32467;&#26500;&#65292;&#21516;&#26102;&#22823;&#24133;&#38477;&#20302;&#35745;&#31639;&#22797;&#26434;&#24230;&#24182;&#20445;&#25345;&#36739;&#39640;&#30340;&#20934;&#30830;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#20197;&#31934;&#24230;&#21644;&#31232;&#30095;&#24615;&#20026;&#39537;&#21160;&#30340;&#28145;&#24230;&#32593;&#32476;&#32467;&#26500;&#29983;&#38271;&#26041;&#27861;&#12290;&#19982;&#29616;&#26377;&#30340;&#22522;&#20110;&#23436;&#25972;&#27169;&#22411;&#25110;&#36229;&#32593;&#26684;&#26550;&#26500;&#30340;&#21098;&#26525;&#25110;&#26550;&#26500;&#25628;&#32034;&#25216;&#26415;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#20174;&#19968;&#20010;&#23567;&#32780;&#31616;&#21333;&#30340;&#31181;&#23376;&#26550;&#26500;&#24320;&#22987;&#65292;&#21160;&#24577;&#22320;&#22686;&#38271;&#21644;&#20462;&#21098;&#23618;&#21644;&#36807;&#28388;&#22120;&#12290;&#36890;&#36807;&#23558;&#31163;&#25955;&#32593;&#32476;&#32467;&#26500;&#20248;&#21270;&#30340;&#36830;&#32493;&#26494;&#24347;&#19982;&#37319;&#26679;&#31232;&#30095;&#23376;&#32593;&#32476;&#26041;&#26696;&#30456;&#32467;&#21512;&#65292;&#25105;&#20204;&#21487;&#20197;&#20135;&#29983;&#32039;&#20945;&#30340;&#20462;&#21098;&#32593;&#32476;&#65292;&#21516;&#26102;&#26174;&#33879;&#38477;&#20302;&#35757;&#32451;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;&#20363;&#22914;&#65292;&#22312;ImageNet&#19978;&#65292;&#19982;&#22522;&#32447;ResNet-50&#30456;&#27604;&#65292;&#25105;&#20204;&#23454;&#29616;&#20102;49.7&#65285;&#30340;&#25512;&#29702;FLOPs&#21644;47.4&#65285;&#30340;&#35757;&#32451;FLOPs&#33410;&#30465;&#65292;&#21516;&#26102;&#20445;&#25345;75.2&#65285;&#30340;top-1&#31934;&#24230;--&#25152;&#26377;&#36825;&#20123;&#37117;&#27809;&#26377;&#20219;&#20309;&#19987;&#38376;&#30340;&#24494;&#35843;&#38454;&#27573;&#12290;&#22312;CIFAR&#65292;ImageNet&#65292;PASCAL VOC&#21644;Penn Treebank&#19978;&#36827;&#34892;&#23454;&#39564;&#65292;&#20351;&#29992;&#21367;&#31215;&#32593;&#32476;&#36827;&#34892;&#22270;&#20687;&#20998;&#31867;&#21644;&#35821;&#20041;&#20998;&#21106;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop an approach to growing deep network architectures over the course of training, driven by a principled combination of accuracy and sparsity objectives. Unlike existing pruning or architecture search techniques that operate on full-sized models or supernet architectures, our method can start from a small, simple seed architecture and dynamically grow and prune both layers and filters. By combining a continuous relaxation of discrete network structure optimization with a scheme for sampling sparse subnetworks, we produce compact, pruned networks, while also drastically reducing the computational expense of training. For example, we achieve $49.7\%$ inference FLOPs and $47.4\%$ training FLOPs savings compared to a baseline ResNet-50 on ImageNet, while maintaining $75.2\%$ top-1 accuracy -- all without any dedicated fine-tuning stage. Experiments across CIFAR, ImageNet, PASCAL VOC, and Penn Treebank, with convolutional networks for image classification and semantic segmentation, 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27010;&#29575;&#27979;&#24230;&#26465;&#20214;&#37319;&#26679;&#26694;&#26550;&#65292;&#20351;&#29992;&#21333;&#35843;GAN&#23398;&#20064;&#22359;&#29366;&#19977;&#35282;&#24418;&#26144;&#23556;&#65292;&#20165;&#20351;&#29992;&#26469;&#33258;&#24213;&#23618;&#32852;&#21512;&#27010;&#29575;&#27979;&#24230;&#30340;&#26679;&#26412;&#23454;&#29616;&#26080;&#20284;&#28982;&#25512;&#26029;&#12290;</title><link>http://arxiv.org/abs/2006.06755</link><description>&lt;p&gt;
&#22522;&#20110;&#21333;&#35843;GAN&#30340;&#26465;&#20214;&#37319;&#26679;&#65306;&#20174;&#29983;&#25104;&#27169;&#22411;&#21040;&#26080;&#20284;&#28982;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Conditional Sampling with Monotone GANs: from Generative Models to Likelihood-Free Inference. (arXiv:2006.06755v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2006.06755
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27010;&#29575;&#27979;&#24230;&#26465;&#20214;&#37319;&#26679;&#26694;&#26550;&#65292;&#20351;&#29992;&#21333;&#35843;GAN&#23398;&#20064;&#22359;&#29366;&#19977;&#35282;&#24418;&#26144;&#23556;&#65292;&#20165;&#20351;&#29992;&#26469;&#33258;&#24213;&#23618;&#32852;&#21512;&#27010;&#29575;&#27979;&#24230;&#30340;&#26679;&#26412;&#23454;&#29616;&#26080;&#20284;&#28982;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27010;&#29575;&#27979;&#24230;&#26465;&#20214;&#37319;&#26679;&#26694;&#26550;&#65292;&#20351;&#29992;&#20102;&#22359;&#29366;&#19977;&#35282;&#24418;&#20256;&#36755;&#26144;&#23556;&#12290;&#25105;&#20204;&#22312;Banach&#31354;&#38388;&#35774;&#32622;&#19979;&#24320;&#21457;&#20102;&#22359;&#29366;&#19977;&#35282;&#24418;&#20256;&#36755;&#30340;&#29702;&#35770;&#22522;&#30784;&#65292;&#24314;&#31435;&#20102;&#21487;&#20197;&#23454;&#29616;&#26465;&#20214;&#37319;&#26679;&#30340;&#19968;&#33324;&#26465;&#20214;&#65292;&#24182;&#22312;&#21333;&#35843;&#22359;&#29366;&#19977;&#35282;&#24418;&#26144;&#23556;&#19982;&#26368;&#20248;&#20256;&#36755;&#20043;&#38388;&#24314;&#31435;&#32852;&#31995;&#12290;&#22522;&#20110;&#35813;&#29702;&#35770;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#26041;&#27861;&#65292;&#31216;&#20026;&#21333;&#35843;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;M-GAN&#65289;&#65292;&#29992;&#20110;&#23398;&#20064;&#21512;&#36866;&#30340;&#22359;&#29366;&#19977;&#35282;&#24418;&#26144;&#23556;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20165;&#20351;&#29992;&#26469;&#33258;&#24213;&#23618;&#32852;&#21512;&#27010;&#29575;&#27979;&#24230;&#30340;&#26679;&#26412;&#65292;&#22240;&#27492;&#26080;&#38656;&#20284;&#28982;&#12290;M-GAN&#30340;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#22312;&#21512;&#25104;&#31034;&#20363;&#12289;&#28041;&#21450;&#24120;&#24494;&#20998;&#26041;&#31243;&#21644;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#36125;&#21494;&#26031;&#21453;&#38382;&#39064;&#65292;&#20197;&#21450;&#27010;&#29575;&#22270;&#20687;&#20462;&#22797;&#20013;&#20934;&#30830;&#37319;&#26679;&#26465;&#20214;&#27979;&#24230;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a novel framework for conditional sampling of probability measures, using block triangular transport maps. We develop the theoretical foundations of block triangular transport in a Banach space setting, establishing general conditions under which conditional sampling can be achieved and drawing connections between monotone block triangular maps and optimal transport. Based on this theory, we then introduce a computational approach, called monotone generative adversarial networks (M-GANs), to learn suitable block triangular maps. Our algorithm uses only samples from the underlying joint probability measure and is hence likelihood-free. Numerical experiments with M-GAN demonstrate accurate sampling of conditional measures in synthetic examples, Bayesian inverse problems involving ordinary and partial differential equations, and probabilistic image in-painting.
&lt;/p&gt;</description></item><item><title>Denise&#26159;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#23545;&#21327;&#26041;&#24046;&#30697;&#38453;&#36827;&#34892;&#20302;&#31209;&#21152;&#31232;&#30095;&#20998;&#35299;&#65292;&#36798;&#21040;&#20102;&#19982;&#26368;&#20808;&#36827;&#25216;&#26415;&#30456;&#24403;&#30340;&#24615;&#33021;&#32780;&#19988;&#36817;&#20046;&#25509;&#36817;20&#20493;&#30340;&#21152;&#36895;&#12290;</title><link>http://arxiv.org/abs/2004.13612</link><description>&lt;p&gt;
Denise: &#38754;&#21521;&#21322;&#27491;&#23450;&#30697;&#38453;&#30340;&#28145;&#24230;&#20581;&#22766;&#20027;&#25104;&#20998;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Denise: Deep Robust Principal Component Analysis for Positive Semidefinite Matrices. (arXiv:2004.13612v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2004.13612
&lt;/p&gt;
&lt;p&gt;
Denise&#26159;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#23545;&#21327;&#26041;&#24046;&#30697;&#38453;&#36827;&#34892;&#20302;&#31209;&#21152;&#31232;&#30095;&#20998;&#35299;&#65292;&#36798;&#21040;&#20102;&#19982;&#26368;&#20808;&#36827;&#25216;&#26415;&#30456;&#24403;&#30340;&#24615;&#33021;&#32780;&#19988;&#36817;&#20046;&#25509;&#36817;20&#20493;&#30340;&#21152;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#20581;&#22766;&#20027;&#25104;&#20998;&#20998;&#26512;&#22312;&#38548;&#31163;&#20851;&#38190;&#35299;&#37322;&#29305;&#24449;&#26041;&#38754;&#21457;&#25381;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#30446;&#21069;&#21487;&#29992;&#30340;&#25191;&#34892;&#20302;&#31209;&#21152;&#31232;&#30095;&#20998;&#35299;&#30340;&#26041;&#27861;&#26159;&#38024;&#23545;&#29305;&#23450;&#30697;&#38453;&#30340;&#65292;&#20063;&#23601;&#26159;&#35828;&#65292;&#36825;&#20123;&#31639;&#27861;&#24517;&#39035;&#38024;&#23545;&#27599;&#20010;&#26032;&#30340;&#30697;&#38453;&#37325;&#26032;&#36816;&#34892;&#12290;&#30001;&#20110;&#36825;&#20123;&#31639;&#27861;&#30340;&#35745;&#31639;&#25104;&#26412;&#24456;&#39640;&#65292;&#22240;&#27492;&#26368;&#22909;&#23398;&#20064;&#21644;&#23384;&#20648;&#19968;&#20010;&#20989;&#25968;&#65292;&#22312;&#35780;&#20272;&#26102;&#20960;&#20046;&#31435;&#21363;&#25191;&#34892;&#27492;&#20998;&#35299;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102; Denise&#65292;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#20581;&#22766;&#20027;&#25104;&#20998;&#20998;&#26512;&#31639;&#27861;&#65292;&#25110;&#26356;&#19968;&#33324;&#22320;&#35828;&#65292;&#23545;&#31216;&#21322;&#27491;&#23450;&#30697;&#38453;&#65292;&#23427;&#23398;&#20064;&#21040;&#20102;&#36825;&#26679;&#19968;&#20010;&#20989;&#25968;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102; Denise &#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#36825;&#20123;&#21253;&#25324;&#19968;&#20010;&#26032;&#30340;&#36890;&#29992;&#36924;&#36817;&#23450;&#29702;&#65292;&#36866;&#29992;&#20110;&#25105;&#20204;&#30340;&#20960;&#20309;&#28145;&#24230;&#23398;&#20064;&#38382;&#39064;&#65292;&#24182;&#36235;&#20110;&#23398;&#20064;&#38382;&#39064;&#30340;&#26368;&#20248;&#35299;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;Denise &#22312;&#20998;&#35299;&#36136;&#37327;&#26041;&#38754;&#19982;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#30456;&#21305;&#37197;&#65292;&#21516;&#26102;&#36817;&#20046;&#25509;&#36817;20&#20493;&#30340;&#21152;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;
The robust PCA of covariance matrices plays an essential role when isolating key explanatory features. The currently available methods for performing such a low-rank plus sparse decomposition are matrix specific, meaning, those algorithms must re-run for every new matrix. Since these algorithms are computationally expensive, it is preferable to learn and store a function that nearly instantaneously performs this decomposition when evaluated. Therefore, we introduce Denise, a deep learning-based algorithm for robust PCA of covariance matrices, or more generally, of symmetric positive semidefinite matrices, which learns precisely such a function. Theoretical guarantees for Denise are provided. These include a novel universal approximation theorem adapted to our geometric deep learning problem and convergence to an optimal solution to the learning problem. Our experiments show that Denise matches state-of-the-art performance in terms of decomposition quality, while being approximately $20
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#26080;&#20851;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#33021;&#22815;&#20351;&#29992;&#32447;&#24615;&#26102;&#24577;&#36923;&#36753;&#26469;&#21046;&#23450;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#30446;&#26631;&#65292;&#23558;LTL&#23646;&#24615;&#36716;&#21270;&#20026;LDGBA&#33258;&#21160;&#26426;&#65292;&#36890;&#36807;&#35843;&#25972;&#21516;&#27493;&#22870;&#21169;&#20989;&#25968;&#26368;&#22823;&#27010;&#29575;&#33719;&#24471;&#28385;&#36275;LTL&#35268;&#23450;&#35201;&#27714;&#30340;&#25511;&#21046;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/1902.00778</link><description>&lt;p&gt;
&#36890;&#36807;&#36923;&#36753;&#25351;&#23548;&#30340;&#35748;&#35777;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Certified Reinforcement Learning with Logic Guidance. (arXiv:1902.00778v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1902.00778
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27169;&#22411;&#26080;&#20851;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#33021;&#22815;&#20351;&#29992;&#32447;&#24615;&#26102;&#24577;&#36923;&#36753;&#26469;&#21046;&#23450;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#30446;&#26631;&#65292;&#23558;LTL&#23646;&#24615;&#36716;&#21270;&#20026;LDGBA&#33258;&#21160;&#26426;&#65292;&#36890;&#36807;&#35843;&#25972;&#21516;&#27493;&#22870;&#21169;&#20989;&#25968;&#26368;&#22823;&#27010;&#29575;&#33719;&#24471;&#28385;&#36275;LTL&#35268;&#23450;&#35201;&#27714;&#30340;&#25511;&#21046;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#22312;&#21508;&#31181;&#25511;&#21046;&#38382;&#39064;&#19978;&#24471;&#21040;&#20102;&#24191;&#27867;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#22312;&#23433;&#20840;&#20851;&#38190;&#39046;&#22495;&#30340;&#24212;&#29992;&#38656;&#35201;&#19968;&#20010;&#31995;&#32479;&#21644;&#27491;&#24335;&#30340;&#26041;&#27861;&#26469;&#25351;&#23450;&#20219;&#21153;&#25110;&#30446;&#26631;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#27169;&#22411;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#23427;&#33021;&#22815;&#20351;&#29992;&#32447;&#24615;&#26102;&#24577;&#36923;&#36753;&#65288;LTL&#65289;&#26469;&#21046;&#23450;&#26410;&#30693;&#36830;&#32493;&#29366;&#24577;/&#21160;&#20316;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDPs&#65289;&#30340;&#30446;&#26631;&#12290;&#32473;&#23450;&#30340;LTL&#23646;&#24615;&#34987;&#36716;&#21270;&#20026;&#26497;&#38480;&#30830;&#23450;&#21270;&#24191;&#20041;&#24067;&#27663;&#33258;&#21160;&#26426;&#65288;LDGBA&#65289;&#65292;&#36890;&#36807;LDGBA&#22312;&#34892;&#36827;&#36807;&#31243;&#20013;&#19981;&#26029;&#35843;&#25972;&#21516;&#27493;&#22870;&#21169;&#20989;&#25968;&#12290;&#22312;&#26576;&#20123;&#20551;&#35774;&#19979;&#65292;&#35813;&#31639;&#27861;&#23558;&#20445;&#35777;&#21512;&#25104;&#20986;&#19968;&#20010;&#25511;&#21046;&#31574;&#30053;&#65292;&#20854;&#36712;&#36857;&#26368;&#22823;&#27010;&#29575;&#28385;&#36275;LTL&#35268;&#23450;&#30340;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement Learning (RL) is a widely employed machine learning architecture that has been applied to a variety of control problems. However, applications in safety-critical domains require a systematic and formal approach to specifying requirements as tasks or goals. We propose a model-free RL algorithm that enables the use of Linear Temporal Logic (LTL) to formulate a goal for unknown continuous-state/action Markov Decision Processes (MDPs). The given LTL property is translated into a Limit-Deterministic Generalised Buchi Automaton (LDGBA), which is then used to shape a synchronous reward function on-the-fly. Under certain assumptions, the algorithm is guaranteed to synthesise a control policy whose traces satisfy the LTL specification with maximal probability.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#38454;&#27573;&#26679;&#26412;&#25286;&#20998;&#30340;&#20803;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#22312;&#35780;&#20272;&#24635;&#20307;&#39118;&#38505;&#26102;&#32771;&#34385;&#24178;&#25200;&#21442;&#25968;&#65292;&#24182;&#19988;&#23454;&#29616;&#30340;&#36229;&#39069;&#39118;&#38505;&#30028;&#30340;&#24433;&#21709;&#20026;&#20108;&#27425;&#12290;</title><link>http://arxiv.org/abs/1901.09036</link><description>&lt;p&gt;
&#27491;&#20132;&#32479;&#35745;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Orthogonal Statistical Learning. (arXiv:1901.09036v4 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1901.09036
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#38454;&#27573;&#26679;&#26412;&#25286;&#20998;&#30340;&#20803;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#22312;&#35780;&#20272;&#24635;&#20307;&#39118;&#38505;&#26102;&#32771;&#34385;&#24178;&#25200;&#21442;&#25968;&#65292;&#24182;&#19988;&#23454;&#29616;&#30340;&#36229;&#39069;&#39118;&#38505;&#30028;&#30340;&#24433;&#21709;&#20026;&#20108;&#27425;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#19968;&#20010;&#32479;&#35745;&#23398;&#20064;&#30340;&#35774;&#32622;&#19979;&#25552;&#20379;&#20102;&#20851;&#20110;&#38750;&#28176;&#36817;&#36229;&#39069;&#39118;&#38505;&#20445;&#35777;&#65292;&#20854;&#20013;&#30446;&#26631;&#21442;&#25968;&#25152;&#35780;&#20272;&#30340;&#24635;&#20307;&#39118;&#38505;&#21462;&#20915;&#20110;&#24517;&#39035;&#20174;&#25968;&#25454;&#20013;&#20272;&#35745;&#30340;&#26410;&#30693;&#24178;&#25200;&#21442;&#25968;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#19968;&#20010;&#20004;&#38454;&#27573;&#26679;&#26412;&#25286;&#20998;&#30340;&#20803;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#23558;&#20219;&#24847;&#20272;&#35745;&#30446;&#26631;&#21442;&#25968;&#21644;&#24178;&#25200;&#21442;&#25968;&#30340;&#31639;&#27861;&#20316;&#20026;&#36755;&#20837;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#22914;&#26524;&#24635;&#20307;&#39118;&#38505;&#28385;&#36275;&#19968;&#20010;&#31216;&#20026;Neyman&#27491;&#20132;&#24615;&#30340;&#26465;&#20214;&#65292;&#21017;&#24178;&#25200;&#20272;&#35745;&#35823;&#24046;&#23545;&#20803;&#31639;&#27861;&#23454;&#29616;&#30340;&#36229;&#39069;&#39118;&#38505;&#30028;&#30340;&#24433;&#21709;&#20026;&#20108;&#27425;&#12290;&#25105;&#20204;&#30340;&#23450;&#29702;&#19981;&#20851;&#24515;&#29992;&#20110;&#30446;&#26631;&#21644;&#24178;&#25200;&#30340;&#29305;&#23450;&#31639;&#27861;&#65292;&#21482;&#20570;&#20986;&#20102;&#26377;&#20851;&#23427;&#20204;&#21508;&#33258;&#24615;&#33021;&#30340;&#20551;&#35774;&#12290;&#36825;&#26679;&#65292;&#23601;&#21487;&#20197;&#21033;&#29992;&#29616;&#26377;&#26426;&#22120;&#23398;&#20064;&#30340;&#22823;&#37327;&#32467;&#26524;&#65292;&#20026;&#24102;&#26377;&#24178;&#25200;&#32452;&#25104;&#30340;&#23398;&#20064;&#25552;&#20379;&#26032;&#30340;&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#20851;&#27880;&#36229;&#39069;&#39118;&#38505;&#32780;&#19981;&#26159;&#21442;&#25968;&#20272;&#35745;&#65292;&#25105;&#20204;&#21487;&#20197;&#25552;&#20379;&#19968;&#20010;&#24369;&#21270;&#30340;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
We provide non-asymptotic excess risk guarantees for statistical learning in a setting where the population risk with respect to which we evaluate the target parameter depends on an unknown nuisance parameter that must be estimated from data. We analyze a two-stage sample splitting meta-algorithm that takes as input arbitrary estimation algorithms for the target parameter and nuisance parameter. We show that if the population risk satisfies a condition called Neyman orthogonality, the impact of the nuisance estimation error on the excess risk bound achieved by the meta-algorithm is of second order. Our theorem is agnostic to the particular algorithms used for the target and nuisance and only makes an assumption on their individual performance. This enables the use of a plethora of existing results from machine learning to give new guarantees for learning with a nuisance component. Moreover, by focusing on excess risk rather than parameter estimation, we can provide rates under weaker a
&lt;/p&gt;</description></item></channel></rss>