<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#21487;&#22797;&#21046;&#24615;&#21644;&#20840;&#23616;&#31283;&#23450;&#24615;&#65292;&#24182;&#35777;&#26126;&#35768;&#22810;&#23398;&#20064;&#20219;&#21153;&#21482;&#33021;&#24369;&#21270;&#22320;&#23454;&#29616;&#20840;&#23616;&#31283;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.03757</link><description>&lt;p&gt;
&#23398;&#20064;&#20013;&#30340;&#21487;&#22797;&#21046;&#24615;&#21644;&#31283;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
Replicability and stability in learning. (arXiv:2304.03757v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03757
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#21487;&#22797;&#21046;&#24615;&#21644;&#20840;&#23616;&#31283;&#23450;&#24615;&#65292;&#24182;&#35777;&#26126;&#35768;&#22810;&#23398;&#20064;&#20219;&#21153;&#21482;&#33021;&#24369;&#21270;&#22320;&#23454;&#29616;&#20840;&#23616;&#31283;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#22797;&#21046;&#24615;&#26159;&#31185;&#23398;&#20013;&#30340;&#20851;&#38190;&#65292;&#22240;&#20026;&#23427;&#20351;&#25105;&#20204;&#33021;&#22815;&#39564;&#35777;&#21644;&#39564;&#35777;&#30740;&#31350;&#32467;&#26524;&#12290;Impagliazzo&#12289;Lei&#12289;Pitassi&#21644;Sorrell&#65288;'22&#65289;&#26368;&#36817;&#24320;&#22987;&#30740;&#31350;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#21487;&#22797;&#21046;&#24615;&#12290;&#22914;&#26524;&#21516;&#19968;&#31639;&#27861;&#22312;&#20004;&#20010;&#29420;&#31435;&#21516;&#20998;&#24067;&#36755;&#20837;&#19978;&#20351;&#29992;&#30456;&#21516;&#30340;&#20869;&#37096;&#38543;&#26426;&#24615;&#26102;&#36890;&#24120;&#20135;&#29983;&#30456;&#21516;&#30340;&#36755;&#20986;&#65292;&#21017;&#23398;&#20064;&#31639;&#27861;&#26159;&#21487;&#22797;&#21046;&#30340;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#19981;&#28041;&#21450;&#22266;&#23450;&#38543;&#26426;&#24615;&#30340;&#21487;&#22797;&#21046;&#24615;&#21464;&#20307;&#12290;&#22914;&#26524;&#19968;&#20010;&#31639;&#27861;&#22312;&#20004;&#20010;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#36755;&#20837;&#19978;&#65288;&#19981;&#22266;&#23450;&#20869;&#37096;&#38543;&#26426;&#24615;&#65289;&#24212;&#29992;&#26102;&#36890;&#24120;&#20135;&#29983;&#30456;&#21516;&#30340;&#36755;&#20986;&#65292;&#21017;&#31639;&#27861;&#28385;&#36275;&#36825;&#31181;&#24418;&#24335;&#30340;&#21487;&#22797;&#21046;&#24615;&#12290;&#36825;&#20010;&#21464;&#31181;&#34987;&#31216;&#20026;&#20840;&#23616;&#31283;&#23450;&#24615;&#65292;&#24182;&#22312;&#24046;&#20998;&#38544;&#31169;&#30340;&#19978;&#19979;&#25991;&#20013;&#30001;Bun&#12289;Livni&#21644;Moran&#65288;'20&#65289;&#20171;&#32461;&#12290; Impagliazzo&#31561;&#20154;&#23637;&#31034;&#20102;&#22914;&#20309;&#25552;&#39640;&#20219;&#20309;&#21487;&#22797;&#21046;&#31639;&#27861;&#30340;&#25928;&#26524;&#65292;&#20197;&#20351;&#20854;&#20135;&#29983;&#30340;&#36755;&#20986;&#27010;&#29575;&#26080;&#38480;&#25509;&#36817;&#20110;1&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#35768;&#22810;&#23398;&#20064;&#20219;&#21153;&#65292;&#21482;&#33021;&#24369;&#21270;&#22320;&#23454;&#29616;&#20840;&#23616;&#31283;&#23450;&#24615;&#65292;&#36825;&#37324;&#36755;&#20986;&#21482;&#26377;&#30456;&#21516;&#30340;&#37096;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;
Replicability is essential in science as it allows us to validate and verify research findings. Impagliazzo, Lei, Pitassi and Sorrell (`22) recently initiated the study of replicability in machine learning. A learning algorithm is replicable if it typically produces the same output when applied on two i.i.d. inputs using the same internal randomness. We study a variant of replicability that does not involve fixing the randomness. An algorithm satisfies this form of replicability if it typically produces the same output when applied on two i.i.d. inputs (without fixing the internal randomness). This variant is called global stability and was introduced by Bun, Livni and Moran (`20) in the context of differential privacy.  Impagliazzo et al. showed how to boost any replicable algorithm so that it produces the same output with probability arbitrarily close to 1. In contrast, we demonstrate that for numerous learning tasks, global stability can only be accomplished weakly, where the same o
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#24230;&#37327;&#23398;&#20064;&#21644;&#20559;&#22909;&#23398;&#20064;&#30340;&#26032;&#30340;&#34920;&#29616;&#23450;&#29702;&#65292;&#35299;&#20915;&#20102;&#24230;&#37327;&#23398;&#20064;&#20219;&#21153;&#20197;&#19977;&#20803;&#32452;&#27604;&#36739;&#20026;&#22522;&#30784;&#30340;&#34920;&#29616;&#23450;&#29702;&#38382;&#39064;&#12290;&#36825;&#31181;&#34920;&#29616;&#23450;&#29702;&#21487;&#20197;&#29992;&#20869;&#31215;&#35825;&#23548;&#30340;&#33539;&#25968;&#26469;&#34920;&#31034;&#12290;</title><link>http://arxiv.org/abs/2304.03720</link><description>&lt;p&gt;
&#24230;&#37327;&#23398;&#20064;&#19982;&#20559;&#22909;&#23398;&#20064;&#30340;&#34920;&#29616;&#23450;&#29702;&#65306;&#22522;&#20110;&#20960;&#20309;&#30340;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Representer Theorems for Metric and Preference Learning: A Geometric Perspective. (arXiv:2304.03720v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03720
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#24230;&#37327;&#23398;&#20064;&#21644;&#20559;&#22909;&#23398;&#20064;&#30340;&#26032;&#30340;&#34920;&#29616;&#23450;&#29702;&#65292;&#35299;&#20915;&#20102;&#24230;&#37327;&#23398;&#20064;&#20219;&#21153;&#20197;&#19977;&#20803;&#32452;&#27604;&#36739;&#20026;&#22522;&#30784;&#30340;&#34920;&#29616;&#23450;&#29702;&#38382;&#39064;&#12290;&#36825;&#31181;&#34920;&#29616;&#23450;&#29702;&#21487;&#20197;&#29992;&#20869;&#31215;&#35825;&#23548;&#30340;&#33539;&#25968;&#26469;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25506;&#35752;&#20102;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#24230;&#37327;&#23398;&#20064;&#21644;&#20559;&#22909;&#23398;&#20064;&#38382;&#39064;&#65292;&#24182;&#33719;&#24471;&#20102;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#23398;&#20064;&#21644;&#20559;&#22909;&#23398;&#20064;&#30340;&#34920;&#29616;&#23450;&#29702;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#35266;&#23519;&#26159;&#65292;&#34920;&#29616;&#23450;&#29702;&#21487;&#20197;&#26681;&#25454;&#38382;&#39064;&#32467;&#26500;&#20869;&#22312;&#30340;&#20869;&#31215;&#25152;&#35825;&#23548;&#30340;&#33539;&#25968;&#26469;&#34920;&#31034;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#25105;&#20204;&#30340;&#26694;&#26550;&#24212;&#29992;&#20110;&#19977;&#20803;&#32452;&#27604;&#36739;&#30340;&#24230;&#37327;&#23398;&#20064;&#20219;&#21153;&#65292;&#24182;&#23637;&#31034;&#23427;&#23548;&#33268;&#20102;&#19968;&#20010;&#31616;&#21333;&#19988;&#33258;&#21253;&#21547;&#30340;&#35813;&#20219;&#21153;&#30340;&#34920;&#29616;&#23450;&#29702;&#12290;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;(RKHS)&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23398;&#20064;&#38382;&#39064;&#30340;&#35299;&#21487;&#20197;&#20351;&#29992;&#31867;&#20284;&#20110;&#32463;&#20856;&#34920;&#29616;&#23450;&#29702;&#30340;&#26680;&#26415;&#35821;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
We explore the metric and preference learning problem in Hilbert spaces. We obtain a novel representer theorem for the simultaneous task of metric and preference learning. Our key observation is that the representer theorem can be formulated with respect to the norm induced by the inner product inherent in the problem structure. Additionally, we demonstrate how our framework can be applied to the task of metric learning from triplet comparisons and show that it leads to a simple and self-contained representer theorem for this task. In the case of Reproducing Kernel Hilbert Spaces (RKHS), we demonstrate that the solution to the learning problem can be expressed using kernel terms, akin to classical representer theorems.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38416;&#36848;&#20102;&#19968;&#20010;&#20998;&#24067;&#24335;&#26234;&#33021;&#20307;&#30340;&#32593;&#32476;&#22914;&#20309;&#21512;&#20316;&#35299;&#20915;&#22238;&#24402;&#38382;&#39064;&#65292;&#22312;&#36890;&#20449;&#32422;&#26463;&#12289;&#33258;&#36866;&#24212;&#21644;&#21512;&#20316;&#30340;&#24773;&#20917;&#19979;&#33021;&#22815;&#36798;&#21040;&#30340;&#24615;&#33021;&#65292;&#24182;&#25506;&#35752;&#20102;&#20998;&#24067;&#24335;&#22238;&#24402;&#38382;&#39064;&#30340;&#22522;&#26412;&#23646;&#24615;&#19982;&#26368;&#20248;&#20998;&#37197;&#36890;&#20449;&#36164;&#28304;&#20043;&#38388;&#30340;&#23450;&#37327;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2304.03638</link><description>&lt;p&gt;
&#21387;&#32553;&#22238;&#24402;&#19982;&#33258;&#36866;&#24212;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Compressed Regression over Adaptive Networks. (arXiv:2304.03638v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03638
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38416;&#36848;&#20102;&#19968;&#20010;&#20998;&#24067;&#24335;&#26234;&#33021;&#20307;&#30340;&#32593;&#32476;&#22914;&#20309;&#21512;&#20316;&#35299;&#20915;&#22238;&#24402;&#38382;&#39064;&#65292;&#22312;&#36890;&#20449;&#32422;&#26463;&#12289;&#33258;&#36866;&#24212;&#21644;&#21512;&#20316;&#30340;&#24773;&#20917;&#19979;&#33021;&#22815;&#36798;&#21040;&#30340;&#24615;&#33021;&#65292;&#24182;&#25506;&#35752;&#20102;&#20998;&#24067;&#24335;&#22238;&#24402;&#38382;&#39064;&#30340;&#22522;&#26412;&#23646;&#24615;&#19982;&#26368;&#20248;&#20998;&#37197;&#36890;&#20449;&#36164;&#28304;&#20043;&#38388;&#30340;&#23450;&#37327;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#19968;&#20010;&#20998;&#24067;&#24335;&#26234;&#33021;&#20307;&#32593;&#32476;&#22312;&#35299;&#20915;&#22238;&#24402;&#38382;&#39064;&#26102;&#65292;&#22312;&#36890;&#20449;&#32422;&#26463;&#12289;&#33258;&#36866;&#24212;&#21644;&#21512;&#20316;&#30340;&#24773;&#20917;&#19979;&#33021;&#22815;&#36798;&#21040;&#30340;&#24615;&#33021;&#12290;&#26234;&#33021;&#20307;&#20351;&#29992;&#20102;&#26368;&#36817;&#25552;&#20986;&#30340; ACTC (adapt-compress-then-combine) &#25193;&#25955;&#31574;&#30053;&#65292;&#22312;&#36825;&#20010;&#31574;&#30053;&#20013;&#65292;&#37051;&#36817;&#26234;&#33021;&#20307;&#20132;&#25442;&#30340;&#20449;&#21495;&#34987;&#38543;&#26426;&#19981;&#21516;&#21387;&#32553;&#31639;&#23376;&#32534;&#30721;&#12290;&#25105;&#20204;&#35814;&#32454;&#38416;&#36848;&#20102;&#22343;&#26041;&#20272;&#35745;&#35823;&#24046;&#30340;&#29305;&#24449;&#65292;&#20854;&#20013;&#21253;&#25324;&#20102;&#19968;&#39033;&#19982;&#27809;&#26377;&#36890;&#20449;&#32422;&#26463;&#30340;&#24773;&#20917;&#19979;&#26234;&#33021;&#20307;&#23558;&#35201;&#36798;&#21040;&#30340;&#35823;&#24046;&#26377;&#20851;&#30340;&#38169;&#35823;&#39033;&#65292;&#20197;&#21450;&#19968;&#39033;&#30001;&#20110;&#21387;&#32553;&#32780;&#20135;&#29983;&#30340;&#35823;&#24046;&#39033;&#12290;&#20998;&#26512;&#25581;&#31034;&#20102;&#20998;&#24067;&#24335;&#22238;&#24402;&#38382;&#39064;&#30340;&#22522;&#26412;&#23646;&#24615;&#65292;&#23588;&#20854;&#26159;&#36890;&#36807;Perron&#29305;&#24449;&#21521;&#37327;&#24341;&#36215;&#30340;&#26799;&#24230;&#22122;&#22768;&#21644;&#32593;&#32476;&#25299;&#25169;&#32467;&#26500;&#65288;&#65289;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#30693;&#26195;&#36825;&#20123;&#20851;&#31995;&#23545;&#20110;&#26368;&#20248;&#22320;&#20998;&#37197;&#26234;&#33021;&#20307;&#20043;&#38388;&#30340;&#36890;&#20449;&#36164;&#28304;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work we derive the performance achievable by a network of distributed agents that solve, adaptively and in the presence of communication constraints, a regression problem. Agents employ the recently proposed ACTC (adapt-compress-then-combine) diffusion strategy, where the signals exchanged locally by neighboring agents are encoded with randomized differential compression operators. We provide a detailed characterization of the mean-square estimation error, which is shown to comprise a term related to the error that agents would achieve without communication constraints, plus a term arising from compression. The analysis reveals quantitative relationships between the compression loss and fundamental attributes of the distributed regression problem, in particular, the stochastic approximation error caused by the gradient noise and the network topology (through the Perron eigenvector). We show that knowledge of such relationships is critical to allocate optimally the communication
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#26377;&#24322;&#26500;&#30456;&#20284;&#24615;&#30340;&#26032;&#30340;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#65292;&#38450;&#27490;&#36807;&#25311;&#21512;&#24433;&#21709;&#27169;&#22411;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.03440</link><description>&lt;p&gt;
&#24102;&#26377;&#24322;&#26500;&#30456;&#20284;&#24615;&#30340;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;&#29992;&#20110;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Supervised Contrastive Learning with Heterogeneous Similarity for Distribution Shifts. (arXiv:2304.03440v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03440
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#26377;&#24322;&#26500;&#30456;&#20284;&#24615;&#30340;&#26032;&#30340;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#65292;&#38450;&#27490;&#36807;&#25311;&#21512;&#24433;&#21709;&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#30340;&#20998;&#24067;&#22312;&#35757;&#32451;&#21644;&#27979;&#35797;&#26102;&#21457;&#29983;&#21464;&#21270;&#20250;&#23548;&#33268;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#65292;&#36827;&#32780;&#20005;&#37325;&#24433;&#21709;&#27169;&#22411;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;&#36817;&#26399;&#30740;&#31350;&#34920;&#26126;&#65292;&#36807;&#25311;&#21512;&#26159;&#20854;&#21407;&#22240;&#20043;&#19968;&#65292;&#21512;&#36866;&#30340;&#27491;&#21017;&#21270;&#21487;&#20197;&#32531;&#35299;&#36825;&#31181;&#24433;&#21709;&#65292;&#23588;&#20854;&#36866;&#29992;&#20110;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#31561;&#39640;&#24230;&#20855;&#26377;&#20195;&#34920;&#24615;&#30340;&#27169;&#22411;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#35813;&#26041;&#27861;&#21487;&#20197;&#38450;&#27490;&#36807;&#25311;&#21512;&#65292;&#35757;&#32451;&#27169;&#22411;&#36991;&#20813;&#22312;&#20998;&#24067;&#20559;&#31227;&#19979;&#24615;&#33021;&#36864;&#21270;&#12290;&#20316;&#32773;&#23558;&#23545;&#27604;&#25439;&#22833;&#20013;&#30340;&#20313;&#24358;&#30456;&#20284;&#24615;&#25193;&#23637;&#20026;&#26356;&#36890;&#29992;&#30340;&#30456;&#20284;&#24615;&#24230;&#37327;&#65292;&#24182;&#24314;&#35758;&#22312;&#27604;&#36739;&#26679;&#26412;&#19982;&#27491;&#26679;&#26412;&#25110;&#36127;&#26679;&#26412;&#26102;&#20351;&#29992;&#19981;&#21516;&#30340;&#21442;&#25968;&#65292;&#22312;&#29702;&#35770;&#19978;&#36825;&#19968;&#24314;&#35758;&#34987;&#35777;&#26126;&#21487;&#20197;&#20316;&#20026;&#23545;&#27604;&#25439;&#22833;&#20013;&#30340;&#19968;&#31181;&#36793;&#32536;&#25928;&#24212;&#12290;&#23454;&#39564;&#22312;&#27169;&#25311;&#20998;&#24067;&#20559;&#31227;&#30340;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#65292;&#21253;&#25324;&#23376;&#31181;&#32676;&#20559;&#31227;&#21644;...&#65288;&#21407;&#25991;&#26410;&#23436;&#25104;&#65289;
&lt;/p&gt;
&lt;p&gt;
Distribution shifts are problems where the distribution of data changes between training and testing, which can significantly degrade the performance of a model deployed in the real world. Recent studies suggest that one reason for the degradation is a type of overfitting, and that proper regularization can mitigate the degradation, especially when using highly representative models such as neural networks. In this paper, we propose a new regularization using the supervised contrastive learning to prevent such overfitting and to train models that do not degrade their performance under the distribution shifts. We extend the cosine similarity in contrastive loss to a more general similarity measure and propose to use different parameters in the measure when comparing a sample to a positive or negative example, which is analytically shown to act as a kind of margin in contrastive loss. Experiments on benchmark datasets that emulate distribution shifts, including subpopulation shift and do
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#23485;&#20294;&#26377;&#38480;&#30340;&#29305;&#24449;&#23398;&#20064;&#31070;&#32463;&#32593;&#32476;&#20013;&#26377;&#38480;&#23485;&#24230;&#25928;&#24212;&#30340;&#21160;&#21147;&#23398;&#65292;&#25552;&#20379;&#20102;&#23545;&#32593;&#32476;&#26435;&#37325;&#38543;&#26426;&#21021;&#22987;&#21270;&#19979;DMFT&#24207;&#21442;&#25968;&#27874;&#21160;&#30340;&#34920;&#24449;&#20197;&#21450;&#29305;&#24449;&#23398;&#20064;&#22914;&#20309;&#21160;&#24577;&#22320;&#20943;&#23569;&#26368;&#32456;NTK&#21644;&#26368;&#32456;&#32593;&#32476;&#39044;&#27979;&#30340;&#26041;&#24046;&#12290;</title><link>http://arxiv.org/abs/2304.03408</link><description>&lt;p&gt;
&#26377;&#38480;&#23485;&#24230;&#26680;&#21644;&#24179;&#22343;&#22330;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#39044;&#27979;&#27874;&#21160;&#21160;&#21147;&#23398;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Dynamics of Finite Width Kernel and Prediction Fluctuations in Mean Field Neural Networks. (arXiv:2304.03408v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03408
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#23485;&#20294;&#26377;&#38480;&#30340;&#29305;&#24449;&#23398;&#20064;&#31070;&#32463;&#32593;&#32476;&#20013;&#26377;&#38480;&#23485;&#24230;&#25928;&#24212;&#30340;&#21160;&#21147;&#23398;&#65292;&#25552;&#20379;&#20102;&#23545;&#32593;&#32476;&#26435;&#37325;&#38543;&#26426;&#21021;&#22987;&#21270;&#19979;DMFT&#24207;&#21442;&#25968;&#27874;&#21160;&#30340;&#34920;&#24449;&#20197;&#21450;&#29305;&#24449;&#23398;&#20064;&#22914;&#20309;&#21160;&#24577;&#22320;&#20943;&#23569;&#26368;&#32456;NTK&#21644;&#26368;&#32456;&#32593;&#32476;&#39044;&#27979;&#30340;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20998;&#26512;&#20102;&#23485;&#20294;&#26377;&#38480;&#30340;&#29305;&#24449;&#23398;&#20064;&#31070;&#32463;&#32593;&#32476;&#20013;&#26377;&#38480;&#23485;&#24230;&#25928;&#24212;&#30340;&#21160;&#21147;&#23398;&#12290;&#19982;&#35768;&#22810;&#20808;&#21069;&#30340;&#20998;&#26512;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#26159;&#38024;&#23545;&#29305;&#24449;&#23398;&#20064;&#24378;&#24230;&#30340;&#38750;&#24494;&#25200;&#26377;&#38480;&#23485;&#24230;&#30340;&#32467;&#26524;&#12290;&#20174;&#26080;&#38480;&#23485;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26680;&#21644;&#39044;&#27979;&#21160;&#21147;&#23398;&#30340;&#21160;&#21147;&#23398;&#24179;&#22343;&#22330;&#29702;&#35770;&#65288;DMFT&#65289;&#25551;&#36848;&#24320;&#22987;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#32593;&#32476;&#26435;&#37325;&#30340;&#38543;&#26426;&#21021;&#22987;&#21270;&#19979;DMFT&#24207;&#21442;&#25968;$\mathcal{O}(1/\sqrt{\text{width}})$&#27874;&#21160;&#30340;&#34920;&#24449;&#12290;&#22312;&#32593;&#32476;&#35757;&#32451;&#30340;&#25042;&#24816;&#26497;&#38480;&#20013;&#65292;&#25152;&#26377;&#26680;&#37117;&#26159;&#38543;&#26426;&#30340;&#20294;&#22312;&#26102;&#38388;&#19978;&#38745;&#27490;&#30340;&#65292;&#39044;&#27979;&#26041;&#24046;&#20855;&#26377;&#36890;&#29992;&#24418;&#24335;&#12290;&#28982;&#32780;&#65292;&#22312;&#23500;&#26377;&#29305;&#24449;&#23398;&#20064;&#30340;&#21306;&#22495;&#65292;&#26680;&#21644;&#39044;&#27979;&#30340;&#27874;&#21160;&#26159;&#21160;&#24577;&#32806;&#21512;&#19988;&#26041;&#24046;&#21487;&#20197;&#34987;&#33258;&#27965;&#35745;&#31639;&#12290;&#22312;&#20004;&#23618;&#32593;&#32476;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#29305;&#24449;&#23398;&#20064;&#22914;&#20309;&#21160;&#24577;&#22320;&#20943;&#23569;&#26368;&#32456;NTK&#21644;&#26368;&#32456;&#32593;&#32476;&#39044;&#27979;&#30340;&#26041;&#24046;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22914;&#20309;&#36827;&#34892;&#21021;&#22987;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
We analyze the dynamics of finite width effects in wide but finite feature learning neural networks. Unlike many prior analyses, our results, while perturbative in width, are non-perturbative in the strength of feature learning. Starting from a dynamical mean field theory (DMFT) description of infinite width deep neural network kernel and prediction dynamics, we provide a characterization of the $\mathcal{O}(1/\sqrt{\text{width}})$ fluctuations of the DMFT order parameters over random initialization of the network weights. In the lazy limit of network training, all kernels are random but static in time and the prediction variance has a universal form. However, in the rich, feature learning regime, the fluctuations of the kernels and predictions are dynamically coupled with variance that can be computed self-consistently. In two layer networks, we show how feature learning can dynamically reduce the variance of the final NTK and final network predictions. We also show how initialization
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#20998;&#25968;&#21305;&#37197;&#31639;&#27861;&#23454;&#29616;&#21487;&#25193;&#23637;&#22240;&#26524;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#35813;&#31639;&#27861;&#21487;&#20174;&#38750;&#32447;&#24615;&#21487;&#21152;&#24615;&#39640;&#26031;&#22122;&#22768;&#27169;&#22411;&#30340;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#20013;&#21457;&#29616;&#25972;&#20010;&#22240;&#26524;&#22270;&#65292;&#24182;&#36890;&#36807;&#23454;&#29616;&#19982;&#24403;&#21069;&#26368;&#20808;&#36827;&#25216;&#26415;&#30456;&#24403;&#30340;&#20934;&#30830;&#24615;&#26469;&#38477;&#20302;&#20102;&#35745;&#31639;&#38376;&#27099;&#12290;</title><link>http://arxiv.org/abs/2304.03382</link><description>&lt;p&gt;
&#22522;&#20110;&#20998;&#25968;&#21305;&#37197;&#30340;&#21487;&#25193;&#23637;&#22240;&#26524;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Scalable Causal Discovery with Score Matching. (arXiv:2304.03382v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03382
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#20998;&#25968;&#21305;&#37197;&#31639;&#27861;&#23454;&#29616;&#21487;&#25193;&#23637;&#22240;&#26524;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#35813;&#31639;&#27861;&#21487;&#20174;&#38750;&#32447;&#24615;&#21487;&#21152;&#24615;&#39640;&#26031;&#22122;&#22768;&#27169;&#22411;&#30340;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#20013;&#21457;&#29616;&#25972;&#20010;&#22240;&#26524;&#22270;&#65292;&#24182;&#36890;&#36807;&#23454;&#29616;&#19982;&#24403;&#21069;&#26368;&#20808;&#36827;&#25216;&#26415;&#30456;&#24403;&#30340;&#20934;&#30830;&#24615;&#26469;&#38477;&#20302;&#20102;&#35745;&#31639;&#38376;&#27099;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23637;&#31034;&#20102;&#22914;&#20309;&#22312;&#38750;&#32447;&#24615;&#21487;&#21152;&#24615;&#39640;&#26031;&#22122;&#22768;&#27169;&#22411;&#20013;&#21033;&#29992;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#30340;&#20108;&#38454;&#23548;&#25968;&#26469;&#21457;&#29616;&#25972;&#20010;&#22240;&#26524;&#22270;&#12290;&#20511;&#21161;&#20110;&#21487;&#25193;&#23637;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#26469;&#36924;&#36817;&#20998;&#25968;&#20989;&#25968; $\nabla \log p(\mathbf{X})$&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;Rolland&#31561;&#20154;&#65288;2022&#65289;&#30340;&#24037;&#20316;&#65292;&#21518;&#32773;&#20165;&#20174;&#20998;&#25968;&#20013;&#24674;&#22797;&#25299;&#25169;&#39034;&#24207;&#65292;&#24182;&#38656;&#35201;&#19968;&#20010;&#26114;&#36149;&#30340;&#20462;&#21098;&#27493;&#39588;&#26469;&#28040;&#38500;&#30001;&#27492;&#39034;&#24207;&#20801;&#35768;&#30340;&#34394;&#20551;&#36793;&#32536;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#23548;&#33268;&#20102;DAS&#65288;&#21363; Discovery At Scale&#65292;&#35268;&#27169;&#21270;&#21457;&#29616;&#65289;&#31639;&#27861;&#65292;&#23427;&#36890;&#36807;&#19982;&#22270;&#24418;&#22823;&#23567;&#25104;&#27604;&#20363;&#30340;&#22240;&#32032;&#20943;&#23569;&#20462;&#21098;&#30340;&#22797;&#26434;&#24615;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;DAS&#23454;&#29616;&#20102;&#19982;&#24403;&#21069;&#26368;&#20808;&#36827;&#25216;&#26415;&#30456;&#24403;&#30340;&#20934;&#30830;&#24615;&#65292;&#21516;&#26102;&#36895;&#24230;&#25552;&#21319;&#20102;&#19968;&#20010;&#25968;&#37327;&#32423;&#20197;&#19978;&#12290;&#24635;&#30340;&#26469;&#35828;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#23454;&#29616;&#20102;&#21407;&#21017;&#24615;&#21644;&#21487;&#25193;&#23637;&#30340;&#22240;&#26524;&#25512;&#26029;&#65292;&#22823;&#22823;&#38477;&#20302;&#20102;&#35745;&#31639;&#38376;&#27099;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper demonstrates how to discover the whole causal graph from the second derivative of the log-likelihood in observational non-linear additive Gaussian noise models. Leveraging scalable machine learning approaches to approximate the score function $\nabla \log p(\mathbf{X})$, we extend the work of Rolland et al. (2022) that only recovers the topological order from the score and requires an expensive pruning step removing spurious edges among those admitted by the ordering. Our analysis leads to DAS (acronym for Discovery At Scale), a practical algorithm that reduces the complexity of the pruning by a factor proportional to the graph size. In practice, DAS achieves competitive accuracy with current state-of-the-art while being over an order of magnitude faster. Overall, our approach enables principled and scalable causal discovery, significantly lowering the compute bar.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#19968;&#31995;&#21015;&#25490;&#21517;&#25439;&#22833;&#20989;&#25968;&#19979;&#22810;&#26631;&#31614;&#25490;&#21517;&#38382;&#39064;&#22312;&#25209;&#22788;&#29702;&#21644;&#22312;&#32447;&#35774;&#32622;&#19979;&#30340;&#21487;&#23398;&#20064;&#24615;&#65292;&#24182;&#39318;&#27425;&#32473;&#20986;&#22522;&#20110;&#21487;&#23398;&#20064;&#24615;&#30340;&#25490;&#21517;&#25439;&#22833;&#20989;&#25968;&#30340;&#31561;&#20215;&#31867;&#12290;</title><link>http://arxiv.org/abs/2304.03337</link><description>&lt;p&gt;
&#20851;&#20110;&#22810;&#26631;&#31614;&#25490;&#21517;&#30340;&#21487;&#23398;&#20064;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Learnability of Multilabel Ranking. (arXiv:2304.03337v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03337
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#19968;&#31995;&#21015;&#25490;&#21517;&#25439;&#22833;&#20989;&#25968;&#19979;&#22810;&#26631;&#31614;&#25490;&#21517;&#38382;&#39064;&#22312;&#25209;&#22788;&#29702;&#21644;&#22312;&#32447;&#35774;&#32622;&#19979;&#30340;&#21487;&#23398;&#20064;&#24615;&#65292;&#24182;&#39318;&#27425;&#32473;&#20986;&#22522;&#20110;&#21487;&#23398;&#20064;&#24615;&#30340;&#25490;&#21517;&#25439;&#22833;&#20989;&#25968;&#30340;&#31561;&#20215;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#22810;&#26631;&#31614;&#25490;&#21517;&#26159;&#19968;&#39033;&#37325;&#35201;&#20219;&#21153;&#65292;&#24191;&#27867;&#24212;&#29992;&#20110;&#32593;&#32476;&#25628;&#32034;&#12289;&#26032;&#38395;&#25253;&#36947;&#12289;&#25512;&#33616;&#31995;&#32479;&#31561;&#39046;&#22495;&#12290;&#20294;&#26159;&#65292;&#20851;&#20110;&#22810;&#26631;&#31614;&#25490;&#21517;&#35774;&#32622;&#20013;&#21487;&#23398;&#20064;&#24615;&#30340;&#26368;&#22522;&#26412;&#38382;&#39064;&#20173;&#26410;&#35299;&#31572;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31995;&#21015;&#25490;&#21517;&#25439;&#22833;&#20989;&#25968;&#19979;&#22810;&#26631;&#31614;&#25490;&#21517;&#38382;&#39064;&#22312;&#25209;&#22788;&#29702;&#21644;&#22312;&#32447;&#35774;&#32622;&#19979;&#30340;&#21487;&#23398;&#20064;&#24615;&#65292;&#21516;&#26102;&#20063;&#39318;&#27425;&#32473;&#20986;&#20102;&#22522;&#20110;&#21487;&#23398;&#20064;&#24615;&#30340;&#25490;&#21517;&#25439;&#22833;&#20989;&#25968;&#30340;&#31561;&#20215;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multilabel ranking is a central task in machine learning with widespread applications to web search, news stories, recommender systems, etc. However, the most fundamental question of learnability in a multilabel ranking setting remains unanswered. In this paper, we characterize the learnability of multilabel ranking problems in both the batch and online settings for a large family of ranking losses. Along the way, we also give the first equivalence class of ranking losses based on learnability.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#37325;&#23614;&#37096;&#27491;&#21017;&#21270;&#30340;&#25216;&#26415;&#65292;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#36890;&#36807;&#26126;&#30830;&#25552;&#20513;&#26356;&#37325;&#30340;&#37325;&#23614;&#35889;&#26469;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#12290;&#19982;&#26631;&#20934;&#27491;&#21017;&#21270;&#25216;&#26415;&#30456;&#27604;&#65292;&#35813;&#26041;&#27861;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26174;&#30528;&#30340;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2304.02911</link><description>&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#37325;&#23614;&#37096;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
Heavy-Tailed Regularization of Weight Matrices in Deep Neural Networks. (arXiv:2304.02911v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02911
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#37325;&#23614;&#37096;&#27491;&#21017;&#21270;&#30340;&#25216;&#26415;&#65292;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#36890;&#36807;&#26126;&#30830;&#25552;&#20513;&#26356;&#37325;&#30340;&#37325;&#23614;&#35889;&#26469;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#12290;&#19982;&#26631;&#20934;&#27491;&#21017;&#21270;&#25216;&#26415;&#30456;&#27604;&#65292;&#35813;&#26041;&#27861;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#26174;&#30528;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#25104;&#21151;&#21644;&#26174;&#33879;&#30340;&#27867;&#21270;&#33021;&#21147;&#32972;&#21518;&#30340;&#21407;&#22240;&#20173;&#28982;&#26159;&#19968;&#20010;&#24040;&#22823;&#30340;&#25361;&#25112;&#12290;&#20174;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#24471;&#21040;&#30340;&#26368;&#26032;&#20449;&#24687;&#65292;&#29305;&#21035;&#26159;&#28041;&#21450;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#26435;&#37325;&#30697;&#38453;&#30340;&#35889;&#20998;&#26512;&#30340;&#20449;&#24687;&#65292;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#32447;&#32034;&#12290;&#19968;&#20010;&#20851;&#38190;&#21457;&#29616;&#26159;&#65292;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#24615;&#33021;&#19982;&#20854;&#26435;&#37325;&#30697;&#38453;&#30340;&#35889;&#30340;&#37325;&#23614;&#31243;&#24230;&#30456;&#20851;&#12290;&#20026;&#20102;&#21033;&#29992;&#36825;&#19968;&#21457;&#29616;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#27491;&#21017;&#21270;&#25216;&#26415;&#65292;&#31216;&#20026;&#37325;&#23614;&#37096;&#27491;&#21017;&#21270;&#65292;&#36890;&#36807;&#27491;&#21017;&#21270;&#26126;&#30830;&#25552;&#20513;&#26435;&#37325;&#30697;&#38453;&#20013;&#26356;&#37325;&#30340;&#37325;&#23614;&#35889;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#37319;&#29992;&#21152;&#26435;&#38463;&#23572;&#27861;&#21644;&#31283;&#23450;&#31209;&#20316;&#20026;&#24809;&#32602;&#39033;&#65292;&#20004;&#32773;&#37117;&#21487;&#24494;&#20998;&#65292;&#20174;&#32780;&#21487;&#20197;&#30452;&#25509;&#35745;&#31639;&#23427;&#20204;&#30340;&#26799;&#24230;&#12290;&#20026;&#20102;&#36991;&#20813;&#36807;&#24230;&#27491;&#21017;&#21270;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#20004;&#31181;&#24809;&#32602;&#20989;&#25968;&#30340;&#21464;&#20307;&#12290;&#28982;&#21518;&#65292;&#37319;&#29992;&#36125;&#21494;&#26031;&#32479;&#35745;&#35270;&#35282;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#37325;&#23614;&#37096;&#27491;&#21017;&#21270;&#30340;&#27010;&#29575;&#35299;&#37322;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#23558;&#20854;&#25928;&#26524;&#29702;&#35299;&#20026;&#26435;&#37325;&#30697;&#38453;&#30340;&#20808;&#39564;&#12290;&#22312;&#22810;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#35777;&#35780;&#20272;&#34920;&#26126;&#65292;&#19982;&#26631;&#20934;&#27491;&#21017;&#21270;&#25216;&#26415;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26126;&#26174;&#25552;&#39640;&#20102;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Unraveling the reasons behind the remarkable success and exceptional generalization capabilities of deep neural networks presents a formidable challenge. Recent insights from random matrix theory, specifically those concerning the spectral analysis of weight matrices in deep neural networks, offer valuable clues to address this issue. A key finding indicates that the generalization performance of a neural network is associated with the degree of heavy tails in the spectrum of its weight matrices. To capitalize on this discovery, we introduce a novel regularization technique, termed Heavy-Tailed Regularization, which explicitly promotes a more heavy-tailed spectrum in the weight matrix through regularization. Firstly, we employ the Weighted Alpha and Stable Rank as penalty terms, both of which are differentiable, enabling the direct calculation of their gradients. To circumvent over-regularization, we introduce two variations of the penalty function. Then, adopting a Bayesian statistics
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24433;&#21709;&#20989;&#25968;&#30340;&#33030;&#24369;&#24615;&#65292;&#24182;&#25552;&#20986;&#22312;&#38750;&#20984;&#26465;&#20214;&#19979;&#20351;&#29992;&#28145;&#23618;&#27169;&#22411;&#21644;&#26356;&#22797;&#26434;&#25968;&#25454;&#38598;&#26469;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2303.12922</link><description>&lt;p&gt;
&#37325;&#26032;&#23457;&#35270;&#24433;&#21709;&#20989;&#25968;&#30340;&#33030;&#24369;&#24615;
&lt;/p&gt;
&lt;p&gt;
Revisiting the Fragility of Influence Functions. (arXiv:2303.12922v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.12922
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24433;&#21709;&#20989;&#25968;&#30340;&#33030;&#24369;&#24615;&#65292;&#24182;&#25552;&#20986;&#22312;&#38750;&#20984;&#26465;&#20214;&#19979;&#20351;&#29992;&#28145;&#23618;&#27169;&#22411;&#21644;&#26356;&#22797;&#26434;&#25968;&#25454;&#38598;&#26469;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#20960;&#24180;&#26377;&#24456;&#22810;&#35770;&#25991;&#33268;&#21147;&#20110;&#35299;&#37322;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#39044;&#27979;&#12290;&#28982;&#32780;&#65292;&#24456;&#23569;&#26377;&#26041;&#27861;&#34987;&#25552;&#20986;&#26469;&#39564;&#35777;&#36825;&#20123;&#35299;&#37322;&#30340;&#20934;&#30830;&#24615;&#25110;&#21487;&#20449;&#24230;&#12290;&#26368;&#36817;&#65292;&#24433;&#21709;&#20989;&#25968;&#34987;&#35777;&#26126;&#26159;&#19968;&#31181;&#35780;&#20272;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#21333;&#20010;&#26679;&#26412;&#19978;&#30340;&#28789;&#25935;&#24230;&#30340;&#26041;&#27861;&#12290;&#20294;&#26159;&#65292;&#20808;&#21069;&#30340;&#30740;&#31350;&#34920;&#26126;&#24433;&#21709;&#20989;&#25968;&#26131;&#21463;&#22122;&#22768;&#21644;&#25968;&#25454;&#20998;&#24067;&#19981;&#23545;&#31216;&#24615;&#24433;&#21709;&#65292;&#32570;&#20047;&#40065;&#26834;&#24615;&#12290;&#26412;&#25991;&#26088;&#22312;&#30740;&#31350;&#24433;&#21709;&#20989;&#25968;&#30340;&#33030;&#24369;&#24615;&#65292;&#36890;&#36807;&#25506;&#31350;&#24433;&#21709;&#20989;&#25968;&#32972;&#21518;&#30340;&#26426;&#29702;&#65292;&#20174;&#32780;&#20026;&#22686;&#24378;&#24433;&#21709;&#20989;&#25968;&#30340;&#40065;&#26834;&#24615;&#25552;&#20379;&#26032;&#24605;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the last few years, many works have tried to explain the predictions of deep learning models. Few methods, however, have been proposed to verify the accuracy or faithfulness of these explanations. Recently, influence functions, which is a method that approximates the effect that leave-one-out training has on the loss function, has been shown to be fragile. The proposed reason for their fragility remains unclear. Although previous work suggests the use of regularization to increase robustness, this does not hold in all cases. In this work, we seek to investigate the experiments performed in the prior work in an effort to understand the underlying mechanisms of influence function fragility. First, we verify influence functions using procedures from the literature under conditions where the convexity assumptions of influence functions are met. Then, we relax these assumptions and study the effects of non-convexity by using deeper models and more complex datasets. Here, we analyze the k
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#27169;&#24577;&#20559;&#35265;&#30340;&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#21464;&#20998;&#21387;&#32553;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#19981;&#21516;&#30340;&#25968;&#25454;&#27169;&#24577;&#19978;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#21387;&#32553;&#24615;&#33021;&#21644;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2301.09479</link><description>&lt;p&gt;
&#26080;&#27169;&#24577;&#20559;&#35265;&#30340;&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#21464;&#20998;&#21387;&#32553;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Modality-Agnostic Variational Compression of Implicit Neural Representations. (arXiv:2301.09479v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.09479
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#27169;&#24577;&#20559;&#35265;&#30340;&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#21464;&#20998;&#21387;&#32553;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#19981;&#21516;&#30340;&#25968;&#25454;&#27169;&#24577;&#19978;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#21387;&#32553;&#24615;&#33021;&#21644;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25968;&#25454;&#30340;&#20989;&#25968;&#35270;&#22270;&#65292;&#24182;&#29992;&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#65288;INR&#65289;&#21442;&#25968;&#21270;&#30340;&#26080;&#27169;&#24577;&#31070;&#32463;&#21387;&#32553;&#31639;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#36719;&#38376;&#25511;&#26426;&#21046;&#23558;&#38750;&#32447;&#24615;&#26144;&#23556;&#21040;&#32039;&#20945;&#30340;&#28508;&#22312;&#34920;&#31034;&#20013;&#65292;&#20174;&#32780;&#24357;&#21512;&#20102;&#28508;&#22312;&#32534;&#30721;&#21644;&#31232;&#30095;&#24615;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#36825;&#20801;&#35768;&#27599;&#20010;&#25968;&#25454;&#39033;&#36890;&#36807;&#23376;&#32593;&#32476;&#36873;&#25321;&#26469;&#23450;&#21046;&#20849;&#20139;&#30340;INR&#32593;&#32476;&#30340;&#19987;&#19994;&#21270;&#12290;&#22312;&#33719;&#21462;&#36825;&#31181;&#28508;&#22312;&#34920;&#31034;&#30340;&#25968;&#25454;&#38598;&#21518;&#65292;&#25105;&#20204;&#22312;&#26080;&#27169;&#24577;&#31354;&#38388;&#20013;&#30452;&#25509;&#20248;&#21270;&#36895;&#29575;/&#22833;&#30495;&#30340;&#25240;&#34935;&#26041;&#26696;&#65292;&#20351;&#29992;&#31070;&#32463;&#21387;&#32553;&#12290;&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#30340;&#21464;&#20998;&#21387;&#32553;&#65288;VC-INR&#65289;&#22312;&#20855;&#26377;&#30456;&#21516;&#34920;&#31034;&#23481;&#37327;&#30340;&#37327;&#21270;&#20043;&#21069;&#26174;&#31034;&#20986;&#25913;&#36827;&#30340;&#24615;&#33021;&#65292;&#21516;&#26102;&#20248;&#20110;&#20854;&#20182;INR&#25216;&#26415;&#25152;&#20351;&#29992;&#30340;&#20808;&#21069;&#37327;&#21270;&#26041;&#26696;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#20351;&#29992;&#30456;&#21516;&#30340;&#31639;&#27861;&#32780;&#19981;&#38656;&#35201;&#20219;&#20309;&#29305;&#23450;&#20110;&#27169;&#24577;&#30340;&#24402;&#32435;&#20559;&#24046;&#65292;&#21487;&#20197;&#22312;&#21508;&#31181;&#19981;&#21516;&#30340;&#27169;&#24577;&#19978;&#21462;&#24471;&#21331;&#36234;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#22270;&#20687;&#12289;&#27668;&#20505;&#25968;&#25454;&#12289;&#25991;&#26412;&#21644;&#38899;&#39057;&#25968;&#25454;&#19978;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a modality-agnostic neural compression algorithm based on a functional view of data and parameterised as an Implicit Neural Representation (INR). Bridging the gap between latent coding and sparsity, we obtain compact latent representations non-linearly mapped to a soft gating mechanism. This allows the specialisation of a shared INR network to each data item through subnetwork selection. After obtaining a dataset of such latent representations, we directly optimise the rate/distortion trade-off in a modality-agnostic space using neural compression. Variational Compression of Implicit Neural Representations (VC-INR) shows improved performance given the same representational capacity pre quantisation while also outperforming previous quantisation schemes used for other INR techniques. Our experiments demonstrate strong results over a large set of diverse modalities using the same algorithm without any modality-specific inductive biases. We show results on images, climate dat
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#26377;&#21327;&#21464;&#37327;&#30340;&#32593;&#32476;&#36125;&#21494;&#26031;&#31038;&#21306;&#26816;&#27979;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#20855;&#26377;&#28789;&#27963;&#24615;&#65292;&#21487;&#20197;&#24314;&#27169;&#21442;&#25968;&#20272;&#35745;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#21253;&#25324;&#31038;&#21306;&#25104;&#21592;&#36523;&#20221;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2203.02090</link><description>&lt;p&gt;
&#24102;&#26377;&#21327;&#21464;&#37327;&#30340;&#32593;&#32476;&#36125;&#21494;&#26031;&#31038;&#21306;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Bayesian community detection for networks with covariates. (arXiv:2203.02090v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.02090
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#26377;&#21327;&#21464;&#37327;&#30340;&#32593;&#32476;&#36125;&#21494;&#26031;&#31038;&#21306;&#26816;&#27979;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#20855;&#26377;&#28789;&#27963;&#24615;&#65292;&#21487;&#20197;&#24314;&#27169;&#21442;&#25968;&#20272;&#35745;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#21253;&#25324;&#31038;&#21306;&#25104;&#21592;&#36523;&#20221;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21508;&#20010;&#39046;&#22495;&#20013;&#65292;&#32593;&#32476;&#25968;&#25454;&#30340;&#26222;&#36941;&#23384;&#22312;&#21644;&#20174;&#20013;&#25552;&#21462;&#20986;&#26377;&#29992;&#20449;&#24687;&#30340;&#38656;&#27714;&#65292;&#20419;&#36827;&#20102;&#30456;&#20851;&#27169;&#22411;&#21644;&#31639;&#27861;&#30340;&#24555;&#36895;&#21457;&#23637;&#12290;&#22312;&#20247;&#22810;&#38024;&#23545;&#32593;&#32476;&#25968;&#25454;&#30340;&#23398;&#20064;&#20219;&#21153;&#20013;&#65292;&#31038;&#21306;&#21457;&#29616;&#65292;&#21363;&#21457;&#29616;&#33410;&#28857;&#32676;&#38598;&#25110;"&#31038;&#21306;"&#65292;&#21487;&#33021;&#26159;&#23398;&#26415;&#30028;&#26368;&#21463;&#20851;&#27880;&#30340;&#12290;&#22312;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#32593;&#32476;&#25968;&#25454;&#36890;&#24120;&#38468;&#24102;&#26377;&#33410;&#28857;&#25110;&#36793;&#32536;&#21327;&#21464;&#37327;&#31561;&#38468;&#21152;&#20449;&#24687;&#65292;&#29702;&#24819;&#24773;&#20917;&#19979;&#24212;&#35813;&#21033;&#29992;&#36825;&#20123;&#20449;&#24687;&#36827;&#34892;&#25512;&#26029;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#20855;&#26377;&#21327;&#21464;&#37327;&#20381;&#36182;&#38543;&#26426;&#20998;&#21306;&#20808;&#39564;&#30340;&#36125;&#21494;&#26031;&#38543;&#26426;&#22359;&#27169;&#22411;&#65292;&#20026;&#24102;&#26377;&#21327;&#21464;&#37327;&#30340;&#32593;&#32476;&#31038;&#21306;&#26816;&#27979;&#30340;&#26377;&#38480;&#25991;&#29486;&#22686;&#28155;&#20102;&#26032;&#30340;&#20869;&#23481;&#12290;&#22312;&#25105;&#20204;&#30340;&#20808;&#39564;&#19979;&#65292;&#21327;&#21464;&#37327;&#26126;&#30830;&#22320;&#34920;&#29616;&#20026;&#25351;&#23450;&#32858;&#31867;&#25104;&#21592;&#30340;&#20808;&#39564;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#20855;&#26377;&#24314;&#27169;&#25152;&#26377;&#21442;&#25968;&#20272;&#35745;&#65292;&#21253;&#25324;&#31038;&#21306;&#25104;&#21592;&#36523;&#20221;&#30340;&#19981;&#30830;&#23450;&#24615;&#30340;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The increasing prevalence of network data in a vast variety of fields and the need to extract useful information out of them have spurred fast developments in related models and algorithms. Among the various learning tasks with network data, community detection, the discovery of node clusters or "communities," has arguably received the most attention in the scientific community. In many real-world applications, the network data often come with additional information in the form of node or edge covariates that should ideally be leveraged for inference. In this paper, we add to a limited literature on community detection for networks with covariates by proposing a Bayesian stochastic block model with a covariate-dependent random partition prior. Under our prior, the covariates are explicitly expressed in specifying the prior distribution on the cluster membership. Our model has the flexibility of modeling uncertainties of all the parameter estimates including the community membership. Im
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#26080;&#20284;&#28982;&#20551;&#35774;&#19979;&#30340;&#39057;&#29575;&#23398;&#27966;&#25512;&#26029;&#65288;LF2I&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#32467;&#21512;&#32463;&#20856;&#32479;&#35745;&#21644;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#65292;&#23454;&#29616;&#20102;&#26500;&#24314;&#20855;&#26377;&#27491;&#30830;&#26465;&#20214;&#35206;&#30422;&#30340;&#32622;&#20449;&#21306;&#38388;&#30340;&#23454;&#29992;&#31243;&#24207;&#21644;&#35786;&#26029;&#26041;&#27861;&#65292;&#22312;&#21253;&#25324;&#23431;&#23449;&#23398;&#21442;&#25968;&#25512;&#26029;&#22312;&#20869;&#30340;&#22810;&#20010;&#20363;&#23376;&#20013;&#37117;&#23454;&#29616;&#20102;&#35206;&#30422;&#24615;&#36136;&#24471;&#21040;&#22823;&#24133;&#25913;&#21892;&#12290;</title><link>http://arxiv.org/abs/2107.03920</link><description>&lt;p&gt;
&#26080;&#20284;&#28982;&#20551;&#35774;&#19979;&#22522;&#20110;&#39057;&#29575;&#23398;&#27966;&#25512;&#26029;&#65306;&#20855;&#26377;&#27491;&#30830;&#26465;&#20214;&#35206;&#30422;&#30340;&#32622;&#20449;&#21306;&#38388;
&lt;/p&gt;
&lt;p&gt;
Likelihood-Free Frequentist Inference: Confidence Sets with Correct Conditional Coverage. (arXiv:2107.03920v6 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2107.03920
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#26080;&#20284;&#28982;&#20551;&#35774;&#19979;&#30340;&#39057;&#29575;&#23398;&#27966;&#25512;&#26029;&#65288;LF2I&#65289;&#26694;&#26550;&#65292;&#36890;&#36807;&#32467;&#21512;&#32463;&#20856;&#32479;&#35745;&#21644;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#65292;&#23454;&#29616;&#20102;&#26500;&#24314;&#20855;&#26377;&#27491;&#30830;&#26465;&#20214;&#35206;&#30422;&#30340;&#32622;&#20449;&#21306;&#38388;&#30340;&#23454;&#29992;&#31243;&#24207;&#21644;&#35786;&#26029;&#26041;&#27861;&#65292;&#22312;&#21253;&#25324;&#23431;&#23449;&#23398;&#21442;&#25968;&#25512;&#26029;&#22312;&#20869;&#30340;&#22810;&#20010;&#20363;&#23376;&#20013;&#37117;&#23454;&#29616;&#20102;&#35206;&#30422;&#24615;&#36136;&#24471;&#21040;&#22823;&#24133;&#25913;&#21892;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#31185;&#23398;&#39046;&#22495;&#37117;&#24191;&#27867;&#20351;&#29992;&#35745;&#31639;&#26426;&#27169;&#25311;&#22120;&#20197;&#38544;&#21547;&#22797;&#26434;&#31995;&#32479;&#30340;&#20284;&#28982;&#20989;&#25968;&#12290;&#20256;&#32479;&#30340;&#32479;&#35745;&#26041;&#27861;&#24182;&#19981;&#36866;&#29992;&#20110;&#36825;&#20123;&#31216;&#20026;&#26080;&#20284;&#28982;&#20551;&#35774;&#19979;&#25512;&#26029;&#65288;LFI&#65289;&#30340;&#24773;&#20917;&#65292;&#23588;&#20854;&#26159;&#22312;&#28176;&#36817;&#21644;&#20302;&#32500;&#30340;&#26465;&#20214;&#19979;&#12290;&#34429;&#28982;&#26032;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#22914;&#24402;&#19968;&#21270;&#27969;&#65292;&#24050;&#32463;&#38761;&#26032;&#20102;LFI&#26041;&#27861;&#30340;&#26679;&#26412;&#25928;&#29575;&#21644;&#23481;&#37327;&#65292;&#20294;&#23427;&#20204;&#26159;&#21542;&#33021;&#20026;&#23567;&#26679;&#26412;&#22823;&#23567;&#20135;&#29983;&#20855;&#26377;&#27491;&#30830;&#26465;&#20214;&#35206;&#30422;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#20173;&#28982;&#26159;&#19968;&#20010;&#24320;&#25918;&#38382;&#39064;&#12290;&#26412;&#25991;&#23558;&#32463;&#20856;&#32479;&#35745;&#21644;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#30456;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#65288;i&#65289;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#21517;&#20041;&#35206;&#30422;&#30340;&#20869;&#26364;&#21306;&#38388;&#24314;&#35774;&#30340;&#23454;&#29992;&#31243;&#24207;&#65292;&#20197;&#21450;&#65288;ii&#65289;&#20272;&#35745;&#25972;&#20010;&#21442;&#25968;&#31354;&#38388;&#30340;&#26465;&#20214;&#35206;&#30422;&#30340;&#35786;&#26029;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26694;&#26550;&#31216;&#20026;&#26080;&#20284;&#28982;&#20551;&#35774;&#19979;&#30340;&#39057;&#29575;&#23398;&#27966;&#25512;&#26029;&#65288;LF2I&#65289;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#20351;&#29992;&#23450;&#20041;&#27979;&#35797;&#32479;&#35745;&#37327;&#30340;&#20219;&#20309;&#26041;&#27861;&#65292;&#22914;&#20284;&#28982;&#27604;&#65292;&#22240;&#27492;&#20855;&#26377;&#24191;&#27867;&#30340;&#36866;&#29992;&#24615;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#20960;&#20010;&#21512;&#25104;&#21644;&#23454;&#38469;&#30340;&#20363;&#23376;&#65292;&#21253;&#25324;&#23431;&#23449;&#23398;&#21442;&#25968;&#25512;&#26029;&#65292;&#24182;&#35777;&#26126;&#19982;&#29616;&#26377;&#30340;LFI&#26041;&#27861;&#30456;&#27604;&#65292;&#35206;&#30422;&#24615;&#36136;&#24471;&#21040;&#20102;&#22823;&#24133;&#25913;&#21892;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many areas of science make extensive use of computer simulators that implicitly encode likelihood functions of complex systems. Classical statistical methods are poorly suited for these so-called likelihood-free inference (LFI) settings, particularly outside asymptotic and low-dimensional regimes. Although new machine learning methods, such as normalizing flows, have revolutionized the sample efficiency and capacity of LFI methods, it remains an open question whether they produce confidence sets with correct conditional coverage for small sample sizes. This paper unifies classical statistics with modern machine learning to present (i) a practical procedure for the Neyman construction of confidence sets with finite-sample guarantees of nominal coverage, and (ii) diagnostics that estimate conditional coverage over the entire parameter space. We refer to our framework as likelihood-free frequentist inference (LF2I). Any method that defines a test statistic, like the likelihood ratio, can 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#36807;&#39640;&#26031;&#36807;&#31243;&#24314;&#27169;&#28789;&#27963;&#19988;&#26126;&#30830;&#22320;&#23558;&#26679;&#21697;&#29305;&#24449;&#21644;&#23454;&#39564;&#22122;&#22768;&#30340;&#20808;&#39564;&#30693;&#35782;&#32435;&#20837;&#37325;&#24314;&#21644;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#30340;&#26041;&#27861;&#12290;&#36825;&#20010;&#26041;&#27861;&#22312;&#21508;&#31181;&#22270;&#20687;&#20013;&#23637;&#31034;&#20102;&#19982;&#29616;&#26377;&#23454;&#29992;&#37325;&#24314;&#26041;&#27861;&#30456;&#23218;&#32654;&#30340;&#37325;&#24314;&#32467;&#26524;&#65292;&#24182;&#20855;&#22791;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#29420;&#29305;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2103.15864</link><description>&lt;p&gt;
&#21516;&#26102;&#37325;&#24314;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#23618;&#26512;&#25104;&#20687;
&lt;/p&gt;
&lt;p&gt;
Simultaneous Reconstruction and Uncertainty Quantification for Tomography. (arXiv:2103.15864v2 [stat.AP] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2103.15864
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#36807;&#39640;&#26031;&#36807;&#31243;&#24314;&#27169;&#28789;&#27963;&#19988;&#26126;&#30830;&#22320;&#23558;&#26679;&#21697;&#29305;&#24449;&#21644;&#23454;&#39564;&#22122;&#22768;&#30340;&#20808;&#39564;&#30693;&#35782;&#32435;&#20837;&#37325;&#24314;&#21644;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#30340;&#26041;&#27861;&#12290;&#36825;&#20010;&#26041;&#27861;&#22312;&#21508;&#31181;&#22270;&#20687;&#20013;&#23637;&#31034;&#20102;&#19982;&#29616;&#26377;&#23454;&#29992;&#37325;&#24314;&#26041;&#27861;&#30456;&#23218;&#32654;&#30340;&#37325;&#24314;&#32467;&#26524;&#65292;&#24182;&#20855;&#22791;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#29420;&#29305;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23618;&#26512;&#25104;&#20687;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#20855;&#26377;&#38761;&#21629;&#24615;&#30340;&#24433;&#21709;&#65292;&#20294;&#30001;&#20110;&#26377;&#38480;&#21644;&#22122;&#22768;&#27979;&#37327;&#23548;&#33268;&#27809;&#26377;&#21807;&#19968;&#35299;&#65292;&#22240;&#27492;&#20854;&#37325;&#24314;&#20855;&#26377;&#30149;&#24577;&#24615;&#36136;&#12290;&#22240;&#27492;&#65292;&#22312;&#27809;&#26377;&#22522;&#20934;&#30495;&#23454;&#20540;&#30340;&#24773;&#20917;&#19979;&#65292;&#37327;&#21270;&#35299;&#30340;&#36136;&#37327;&#38750;&#24120;&#26377;&#24517;&#35201;&#20294;&#21448;&#26410;&#20805;&#20998;&#25506;&#32034;&#12290;&#26412;&#25991;&#36890;&#36807;&#39640;&#26031;&#36807;&#31243;&#24314;&#27169;&#35299;&#20915;&#20102;&#36825;&#19968;&#25361;&#25112;&#65292;&#36890;&#36807;&#36873;&#25321;&#21367;&#31215;&#26680;&#21644;&#22122;&#22768;&#31867;&#22411;&#28789;&#27963;&#19988;&#26126;&#30830;&#22320;&#23558;&#26679;&#21697;&#29305;&#24449;&#21644;&#23454;&#39564;&#22122;&#22768;&#30340;&#20808;&#39564;&#30693;&#35782;&#32435;&#20837;&#27169;&#22411;&#20013;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#19981;&#20165;&#21487;&#20197;&#24471;&#21040;&#19982;&#29616;&#26377;&#23454;&#29992;&#37325;&#24314;&#26041;&#27861;&#65288;&#20363;&#22914;&#65292;&#21453;&#38382;&#39064;&#30340;&#35268;&#21017;&#36845;&#20195;&#27714;&#35299;&#22120;&#65289;&#30456;&#23218;&#32654;&#30340;&#37325;&#24314;&#32467;&#26524;&#65292;&#32780;&#19988;&#21487;&#20197;&#26377;&#25928;&#22320;&#37327;&#21270;&#35299;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#22312;&#21508;&#31181;&#22270;&#20687;&#20013;&#30340;&#33021;&#21147;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;&#23384;&#22312;&#21508;&#31181;&#22122;&#22768;&#24773;&#20917;&#19979;&#36827;&#34892;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#29420;&#29305;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tomographic reconstruction, despite its revolutionary impact on a wide range of applications, suffers from its ill-posed nature in that there is no unique solution because of limited and noisy measurements. Therefore, in the absence of ground truth, quantifying the solution quality is highly desirable but under-explored. In this work, we address this challenge through Gaussian process modeling to flexibly and explicitly incorporate prior knowledge of sample features and experimental noises through the choices of the kernels and noise models. Our proposed method yields not only comparable reconstruction to existing practical reconstruction methods (e.g., regularized iterative solver for inverse problem) but also an efficient way of quantifying solution uncertainties. We demonstrate the capabilities of the proposed approach on various images and show its unique capability of uncertainty quantification in the presence of various noises.
&lt;/p&gt;</description></item></channel></rss>