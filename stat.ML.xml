<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#30740;&#31350;&#20102;&#27604;&#20363;&#28176;&#36817;&#24773;&#24418;&#19979;&#30340;&#23376;&#37319;&#26679;&#23725;&#22238;&#24402;&#38598;&#25104;&#65292;&#35777;&#26126;&#20102;&#26368;&#20248;&#20840;&#23725;&#22238;&#24402;&#38598;&#25104;&#30340;&#39118;&#38505;&#19982;&#26368;&#20248;&#23725;&#39044;&#27979;&#22120;&#30340;&#39118;&#38505;&#30456;&#21305;&#37197;&#65292;&#24182;&#35777;&#26126;&#20102;GCV&#22312;&#20272;&#35745;&#23725;&#22238;&#24402;&#38598;&#21512;&#30340;&#39044;&#27979;&#39118;&#38505;&#26041;&#38754;&#30340;&#24378;&#19968;&#33268;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.13016</link><description>&lt;p&gt;
&#23376;&#37319;&#26679;&#23725;&#22238;&#24402;&#38598;&#25104;&#65306;&#31561;&#25928;&#24615;&#21644;&#24191;&#20041;&#20132;&#21449;&#39564;&#35777;
&lt;/p&gt;
&lt;p&gt;
Subsample Ridge Ensembles: Equivalences and Generalized Cross-Validation. (arXiv:2304.13016v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13016
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#27604;&#20363;&#28176;&#36817;&#24773;&#24418;&#19979;&#30340;&#23376;&#37319;&#26679;&#23725;&#22238;&#24402;&#38598;&#25104;&#65292;&#35777;&#26126;&#20102;&#26368;&#20248;&#20840;&#23725;&#22238;&#24402;&#38598;&#25104;&#30340;&#39118;&#38505;&#19982;&#26368;&#20248;&#23725;&#39044;&#27979;&#22120;&#30340;&#39118;&#38505;&#30456;&#21305;&#37197;&#65292;&#24182;&#35777;&#26126;&#20102;GCV&#22312;&#20272;&#35745;&#23725;&#22238;&#24402;&#38598;&#21512;&#30340;&#39044;&#27979;&#39118;&#38505;&#26041;&#38754;&#30340;&#24378;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#27604;&#20363;&#28176;&#36817;&#24773;&#24418;&#19979;&#30340;&#23376;&#37319;&#26679;&#23725;&#22238;&#24402;&#38598;&#25104;&#65292;&#20854;&#20013;&#29305;&#24449;&#22823;&#23567;&#19982;&#26679;&#26412;&#22823;&#23567;&#25104;&#27604;&#20363;&#22686;&#38271;&#65292;&#20351;&#24471;&#23427;&#20204;&#30340;&#27604;&#29575;&#25910;&#25947;&#21040;&#19968;&#20010;&#24120;&#25968;&#12290;&#36890;&#36807;&#20998;&#26512;&#23725;&#22238;&#24402;&#38598;&#21512;&#30340;&#24179;&#26041;&#39044;&#27979;&#39118;&#38505;&#20316;&#20026;&#26174;&#24335;&#24809;&#32602;$\lambda$&#21644;&#26497;&#38480;&#23376;&#26679;&#26412;&#26041;&#38754;&#27604;$\phi_s$&#65288;&#29305;&#24449;&#22823;&#23567;&#19982;&#23376;&#26679;&#26412;&#22823;&#23567;&#30340;&#27604;&#29575;&#65289;&#30340;&#20989;&#25968;&#65292;&#25105;&#20204;&#34920;&#24449;&#20102;&#22312;&#20219;&#20309;&#21487;&#36798;&#39118;&#38505;&#19979;&#30340;$(\lambda, \phi_s)$-&#24179;&#38754;&#19978;&#30340;&#36718;&#24275;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#35777;&#26126;&#26368;&#20248;&#20840;&#23725;&#22238;&#24402;&#38598;&#25104;&#65288;&#36866;&#21512;&#20110;&#25152;&#26377;&#21487;&#33021;&#30340;&#23376;&#26679;&#26412;&#65289;&#30340;&#39118;&#38505;&#19982;&#26368;&#20248;&#23725;&#39044;&#27979;&#22120;&#30340;&#39118;&#38505;&#30456;&#21305;&#37197;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#23545;&#20110;&#20272;&#35745;&#23725;&#22238;&#24402;&#38598;&#21512;&#30340;&#39044;&#27979;&#39118;&#38505;&#65292;&#22522;&#20110;&#24191;&#20041;&#20132;&#21449;&#39564;&#35777;&#65288;GCV&#65289;&#30340;&#23376;&#26679;&#26412;&#22823;&#23567;&#24378;&#19968;&#33268;&#24615;&#12290;&#36825;&#20801;&#35768;&#26080;&#38656;&#26679;&#26412;&#25286;&#20998;&#22522;&#20110;GCV&#20248;&#21270;&#20840;&#23616;&#23725;&#22238;&#24402;&#38598;&#25104;&#65292;&#24182;&#20135;&#29983;&#19968;&#20010;&#39118;&#38505;&#19982;&#26368;&#20248;&#23725;&#22238;&#24402;&#39118;&#38505;&#30456;&#21305;&#37197;&#30340;&#39044;&#27979;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study subsampling-based ridge ensembles in the proportional asymptotics regime, where the feature size grows proportionally with the sample size such that their ratio converges to a constant. By analyzing the squared prediction risk of ridge ensembles as a function of the explicit penalty $\lambda$ and the limiting subsample aspect ratio $\phi_s$ (the ratio of the feature size to the subsample size), we characterize contours in the $(\lambda, \phi_s)$-plane at any achievable risk. As a consequence, we prove that the risk of the optimal full ridgeless ensemble (fitted on all possible subsamples) matches that of the optimal ridge predictor. In addition, we prove strong uniform consistency of generalized cross-validation (GCV) over the subsample sizes for estimating the prediction risk of ridge ensembles. This allows for GCV-based tuning of full ridgeless ensembles without sample splitting and yields a predictor whose risk matches optimal ridge risk.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#26080;&#24490;&#29615;&#25237;&#24433;&#38543;&#26426;&#36924;&#36817;(LPSA)&#31639;&#27861;&#65292;&#23427;&#21576;&#29616;&#20986;&#19968;&#31181;&#26377;&#36259;&#30340;&#28176;&#36817;&#20559;&#24046;-&#26041;&#24046;&#26435;&#34913;&#65292;&#24182;&#20135;&#29983;&#30456;&#23545;&#20110;&#27493;&#38271;&#30340;&#25237;&#24433;&#27010;&#29575;&#30340;&#30456;&#21464;&#29616;&#35937;&#65292;&#20174;&#32780;&#20026;&#36873;&#25321;&#36866;&#24403;&#30340;&#21442;&#25968;&#25552;&#20379;&#20102;&#35265;&#35299;&#12290;</title><link>http://arxiv.org/abs/2304.12953</link><description>&lt;p&gt;
&#25237;&#24433;&#38543;&#26426;&#36924;&#36817;&#20013;&#30340;&#28176;&#36817;&#34892;&#20026;&#21644;&#30456;&#21464;&#65306;&#36339;&#36291;&#25193;&#25955;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Asymptotic Behaviors and Phase Transitions in Projected Stochastic Approximation: A Jump Diffusion Approach. (arXiv:2304.12953v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12953
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#26080;&#24490;&#29615;&#25237;&#24433;&#38543;&#26426;&#36924;&#36817;(LPSA)&#31639;&#27861;&#65292;&#23427;&#21576;&#29616;&#20986;&#19968;&#31181;&#26377;&#36259;&#30340;&#28176;&#36817;&#20559;&#24046;-&#26041;&#24046;&#26435;&#34913;&#65292;&#24182;&#20135;&#29983;&#30456;&#23545;&#20110;&#27493;&#38271;&#30340;&#25237;&#24433;&#27010;&#29575;&#30340;&#30456;&#21464;&#29616;&#35937;&#65292;&#20174;&#32780;&#20026;&#36873;&#25321;&#36866;&#24403;&#30340;&#21442;&#25968;&#25552;&#20379;&#20102;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#32447;&#24615;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#26080;&#24490;&#29615;&#25237;&#24433;&#38543;&#26426;&#36924;&#36817;(LPSA)&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#22312;&#31532;n&#27425;&#36845;&#20195;&#26102;&#20197;&#27010;&#29575;$p_n$&#36827;&#34892;&#25237;&#24433;&#65292;&#20197;&#30830;&#20445;&#21487;&#34892;&#24615;&#12290;&#32771;&#34385;&#21040;&#27010;&#29575;$p_n$&#21644;&#27493;&#38271;$\eta_n$&#30340;&#20855;&#20307;&#19968;&#31867;&#65292;&#25105;&#20204;&#20174;&#28176;&#36817;&#21644;&#36830;&#32493;&#35282;&#24230;&#20998;&#26512;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#12290;&#36890;&#36807;&#20351;&#29992;&#26032;&#39062;&#30340;&#36339;&#36291;&#25193;&#25955;&#36924;&#36817;&#26041;&#27861;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36830;&#25509;&#36866;&#24403;&#32553;&#25918;&#30340;&#26368;&#21518;&#36845;&#20195;&#30340;&#36712;&#36857;&#24369;&#25910;&#25947;&#20110;&#29305;&#23450;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;(SDE)&#30340;&#35299;&#12290;&#36890;&#36807;&#20998;&#26512;SDE&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;LPSA&#22312;&#19981;&#21516;&#30340;$(p_n, \eta_n)$&#36873;&#25321;&#19979;&#30340;&#28176;&#36817;&#34892;&#20026;&#12290;&#25105;&#20204;&#21457;&#29616;&#35813;&#31639;&#27861;&#21576;&#29616;&#20986;&#19968;&#31181;&#26377;&#36259;&#30340;&#28176;&#36817;&#20559;&#24046;-&#26041;&#24046;&#26435;&#34913;&#65292;&#24182;&#20135;&#29983;&#30456;&#23545;&#20110;$\eta_n$&#30340;$p_n$&#30340;&#30456;&#21464;&#29616;&#35937;&#12290;&#35813;&#21457;&#29616;&#25581;&#31034;&#20102;&#36873;&#25321;&#36866;&#24403;&#30340; ${(p_n, \eta_n)}_{n \geq 1}$ &#30340;&#35265;&#35299;&#65292;&#20197;&#26368;&#23567;&#21270;&#27010;&#29575;&#30340;&#28385;&#36275;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we consider linearly constrained optimization problems and propose a loopless projection stochastic approximation (LPSA) algorithm. It performs the projection with probability $p_n$ at the $n$-th iteration to ensure feasibility. Considering a specific family of the probability $p_n$ and step size $\eta_n$, we analyze our algorithm from an asymptotic and continuous perspective. Using a novel jump diffusion approximation, we show that the trajectories connecting those properly rescaled last iterates weakly converge to the solution of specific stochastic differential equations (SDEs). By analyzing SDEs, we identify the asymptotic behaviors of LPSA for different choices of $(p_n, \eta_n)$. We find that the algorithm presents an intriguing asymptotic bias-variance trade-off and yields phase transition phenomenons, according to the relative magnitude of $p_n$ w.r.t. $\eta_n$. This finding provides insights on selecting appropriate ${(p_n, \eta_n)}_{n \geq 1}$ to minimize the pr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35780;&#20998;&#24046;&#24322;&#27969;&#27169;&#22411;(SD flow)&#65292;&#23427;&#21487;&#20197;&#26368;&#20248;&#22320;&#20943;&#23569;&#20004;&#20010;&#20998;&#24067;&#20043;&#38388;&#30340;&#25955;&#24230;&#65292;&#21516;&#26102;&#35299;&#20915;Schr&#8203;&#8203;&#246;dinger&#26725;&#38382;&#39064;&#12290;&#19982;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#19981;&#21516;&#65292;&#23427;&#27809;&#26377;&#23545;&#20808;&#39564;&#20998;&#24067;&#26045;&#21152;&#20219;&#20309;&#38480;&#21046;&#65292;&#22312;&#19968;&#20123;&#22522;&#20934;&#25968;&#25454;&#38598;&#20013;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2304.12906</link><description>&lt;p&gt;
&#35780;&#20998;&#24046;&#20540;&#27969;&#27169;&#22411;&#29992;&#20110;&#38544;&#24335;&#29983;&#25104;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
The Score-Difference Flow for Implicit Generative Modeling. (arXiv:2304.12906v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12906
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35780;&#20998;&#24046;&#24322;&#27969;&#27169;&#22411;(SD flow)&#65292;&#23427;&#21487;&#20197;&#26368;&#20248;&#22320;&#20943;&#23569;&#20004;&#20010;&#20998;&#24067;&#20043;&#38388;&#30340;&#25955;&#24230;&#65292;&#21516;&#26102;&#35299;&#20915;Schr&#8203;&#8203;&#246;dinger&#26725;&#38382;&#39064;&#12290;&#19982;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#19981;&#21516;&#65292;&#23427;&#27809;&#26377;&#23545;&#20808;&#39564;&#20998;&#24067;&#26045;&#21152;&#20219;&#20309;&#38480;&#21046;&#65292;&#22312;&#19968;&#20123;&#22522;&#20934;&#25968;&#25454;&#38598;&#20013;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38544;&#24335;&#29983;&#25104;&#24314;&#27169;(IGM)&#26088;&#22312;&#29983;&#25104;&#31526;&#21512;&#30446;&#26631;&#25968;&#25454;&#20998;&#24067;&#29305;&#24449;&#30340;&#21512;&#25104;&#25968;&#25454;&#26679;&#26412;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;(&#20363;&#22914;&#35780;&#20998;&#21305;&#37197;&#32593;&#32476;&#12289;&#25193;&#25955;&#27169;&#22411;)&#20174;&#36890;&#36807;&#29615;&#22659;&#31354;&#38388;&#20013;&#30340;&#21160;&#24577;&#25200;&#21160;&#25110;&#27969;&#23558;&#21512;&#25104;&#28304;&#25968;&#25454;&#25512;&#21521;&#30446;&#26631;&#20998;&#24067;&#30340;&#35282;&#24230;&#35299;&#20915;&#20102;IGM&#38382;&#39064;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#20219;&#24847;&#30446;&#26631;&#21644;&#28304;&#20998;&#24067;&#20043;&#38388;&#30340;&#35780;&#20998;&#24046;&#24322;(SD)&#20316;&#20026;&#27969;&#65292;&#23427;&#21487;&#20197;&#26368;&#20248;&#22320;&#20943;&#23569;&#23427;&#20204;&#20043;&#38388;&#30340;Kullback-Leibler&#25955;&#24230;&#65292;&#21516;&#26102;&#35299;&#20915;Schr&#8203;&#8203;&#246;dinger&#26725;&#38382;&#39064;&#12290;&#25105;&#20204;&#23558;SD&#27969;&#24212;&#29992;&#20110;&#26041;&#20415;&#30340;&#20195;&#29702;&#20998;&#24067;&#65292;&#24403;&#19988;&#20165;&#24403;&#21407;&#22987;&#20998;&#24067;&#23545;&#40784;&#26102;&#65292;&#23427;&#20204;&#26159;&#23545;&#40784;&#30340;&#12290;&#25105;&#20204;&#22312;&#26576;&#20123;&#26465;&#20214;&#19979;&#23637;&#31034;&#20102;&#36825;&#31181;&#20844;&#24335;&#19982;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#30340;&#24418;&#24335;&#19968;&#33268;&#24615;&#12290;&#28982;&#32780;&#65292;&#19982;&#25193;&#25955;&#27169;&#22411;&#19981;&#21516;&#65292;SD&#27969;&#27809;&#26377;&#23545;&#20808;&#39564;&#20998;&#24067;&#26045;&#21152;&#20219;&#20309;&#38480;&#21046;&#12290;&#25105;&#20204;&#36824;&#34920;&#26126;&#65292;&#22312;&#26080;&#38480;&#36776;&#21035;&#22120;&#33021;&#21147;&#30340;&#26497;&#38480;&#19979;&#65292;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#30340;&#35757;&#32451;&#21253;&#21547;SD&#27969;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;SD&#27969;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#20248;&#20110;&#20808;&#21069;&#30340;&#26368;&#26032;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
Implicit generative modeling (IGM) aims to produce samples of synthetic data matching the characteristics of a target data distribution. Recent work (e.g. score-matching networks, diffusion models) has approached the IGM problem from the perspective of pushing synthetic source data toward the target distribution via dynamical perturbations or flows in the ambient space. We introduce the score difference (SD) between arbitrary target and source distributions as a flow that optimally reduces the Kullback-Leibler divergence between them while also solving the Schr\"odinger bridge problem. We apply the SD flow to convenient proxy distributions, which are aligned if and only if the original distributions are aligned. We demonstrate the formal equivalence of this formulation to denoising diffusion models under certain conditions. However, unlike diffusion models, SD flow places no restrictions on the prior distribution. We also show that the training of generative adversarial networks includ
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#32773;&#23545;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19968;&#33324;&#35206;&#30422;&#26465;&#20214;&#65292;&#24182;&#21457;&#29616;&#26356;&#22810;&#30340;&#35206;&#30422;&#26465;&#20214;&#65292;&#25552;&#39640;&#20102;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#26679;&#26412;&#25928;&#29575;&#21644;&#34920;&#29616;&#65292;&#21516;&#26102;&#38416;&#26126;&#33391;&#22909;&#30340;&#35206;&#30422;&#26465;&#20214;&#20173;&#28982;&#26377;&#30410;&#20110;&#33719;&#24471;&#26368;&#20248;&#35299;&#12290;</title><link>http://arxiv.org/abs/2304.12886</link><description>&lt;p&gt;
&#38024;&#23545;&#20989;&#25968;&#36924;&#36817;&#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#19968;&#33324;&#35206;&#30422;&#26465;&#20214;&#30340;&#21487;&#35777;&#26126;&#20248;&#21183;
&lt;/p&gt;
&lt;p&gt;
Provable benefits of general coverage conditions in efficient online RL with function approximation. (arXiv:2304.12886v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12886
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#32773;&#23545;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#19968;&#33324;&#35206;&#30422;&#26465;&#20214;&#65292;&#24182;&#21457;&#29616;&#26356;&#22810;&#30340;&#35206;&#30422;&#26465;&#20214;&#65292;&#25552;&#39640;&#20102;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#26679;&#26412;&#25928;&#29575;&#21644;&#34920;&#29616;&#65292;&#21516;&#26102;&#38416;&#26126;&#33391;&#22909;&#30340;&#35206;&#30422;&#26465;&#20214;&#20173;&#28982;&#26377;&#30410;&#20110;&#33719;&#24471;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#19982;&#20854;&#20351;&#29992;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDPs&#65289;&#30340;&#26631;&#20934;&#32467;&#26500;&#20551;&#35774;&#65292;&#20351;&#29992;&#26576;&#31181;&#35206;&#30422;&#26465;&#20214;&#65288;&#28304;&#33258;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#65289;&#36275;&#20197;&#30830;&#20445;&#26679;&#26412;&#26377;&#25928;&#20445;&#35777;&#65288;Xie&#31561;&#20154;&#65292;2023&#65289;&#12290;&#26412;&#25991;&#20851;&#27880;&#36825;&#20010;&#26032;&#26041;&#21521;&#65292;&#25366;&#25496;&#26356;&#22810;&#21487;&#33021;&#21644;&#26356;&#26222;&#36941;&#30340;&#35206;&#30422;&#26465;&#20214;&#65292;&#24182;&#30740;&#31350;&#23427;&#20204;&#22312;&#39640;&#25928;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#28508;&#21147;&#21644;&#29992;&#36884;&#12290;&#25105;&#20204;&#37492;&#23450;&#20102;&#26356;&#22810;&#27010;&#24565;&#65292;&#21253;&#25324;$L^p$&#21151;&#33021;&#38598;&#20013;&#24230;&#12289;&#23494;&#24230;&#27604;&#23454;&#29616;&#24615;&#20197;&#21450;&#37096;&#20998;/&#20840;&#35206;&#30422;&#26465;&#20214;&#30340;&#26435;&#34913;&#65292;&#36825;&#20123;&#27010;&#24565;&#20063;&#26377;&#30410;&#20110;&#23454;&#29616;&#26679;&#26412;&#26377;&#25928;&#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#65292;&#20174;&#32780;&#23454;&#29616;&#25913;&#36827;&#30340;&#36951;&#25022;&#36793;&#30028;&#12290;&#27492;&#22806;&#65292;&#22914;&#26524;&#21033;&#29992;&#25506;&#32034;&#24615;&#30340;&#31163;&#32447;&#25968;&#25454;&#65292;&#22312;&#25105;&#20204;&#30340;&#35206;&#30422;&#26465;&#20214;&#19979;&#65292;&#21487;&#20197;&#20026;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#23454;&#29616;&#32479;&#35745;&#21644;&#35745;&#31639;&#19978;&#39640;&#25928;&#30340;&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;&#21363;&#20351;MDP&#32467;&#26500;&#24050;&#32463;&#32473;&#20986;&#65292;&#20363;&#22914;&#32447;&#24615;MDP&#65292;&#25105;&#20204;&#20063;&#38416;&#26126;&#20102;&#33391;&#22909;&#30340;&#35206;&#30422;&#26465;&#20214;&#20173;&#28982;&#26377;&#30410;&#20110;&#33719;&#24471;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
In online reinforcement learning (RL), instead of employing standard structural assumptions on Markov decision processes (MDPs), using a certain coverage condition (original from offline RL) is enough to ensure sample-efficient guarantees (Xie et al. 2023). In this work, we focus on this new direction by digging more possible and general coverage conditions, and study the potential and the utility of them in efficient online RL. We identify more concepts, including the $L^p$ variant of concentrability, the density ratio realizability, and trade-off on the partial/rest coverage condition, that can be also beneficial to sample-efficient online RL, achieving improved regret bound. Furthermore, if exploratory offline data are used, under our coverage conditions, both statistically and computationally efficient guarantees can be achieved for online RL. Besides, even though the MDP structure is given, e.g., linear MDP, we elucidate that, good coverage conditions are still beneficial to obtai
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21453;Lipschitz&#32422;&#26463;&#30340;&#35299;&#30721;&#22120;&#32593;&#32476;&#65292;&#21487;&#20197;&#31616;&#21333;&#26126;&#20102;&#22320;&#25511;&#21046;&#24191;&#27867;&#30340;VAE&#27169;&#22411;&#30340;&#21518;&#39564;&#22349;&#22604;&#31243;&#24230;&#65292;&#24182;&#24102;&#26377;&#20855;&#20307;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2304.12770</link><description>&lt;p&gt;
&#22522;&#20110;&#21453;Lipschitz&#32422;&#26463;&#30340;&#35299;&#30721;&#22120;&#32593;&#32476;&#25511;&#21046;&#21518;&#39564;&#22349;&#22604;
&lt;/p&gt;
&lt;p&gt;
Controlling Posterior Collapse by an Inverse Lipschitz Constraint on the Decoder Network. (arXiv:2304.12770v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12770
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21453;Lipschitz&#32422;&#26463;&#30340;&#35299;&#30721;&#22120;&#32593;&#32476;&#65292;&#21487;&#20197;&#31616;&#21333;&#26126;&#20102;&#22320;&#25511;&#21046;&#24191;&#27867;&#30340;VAE&#27169;&#22411;&#30340;&#21518;&#39564;&#22349;&#22604;&#31243;&#24230;&#65292;&#24182;&#24102;&#26377;&#20855;&#20307;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAE&#65289;&#26159;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#20013;&#21462;&#24471;&#24040;&#22823;&#25104;&#21151;&#30340;&#19968;&#31181;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#23427;&#20204;&#23384;&#22312;&#19968;&#20010;&#31216;&#20026;&#21518;&#39564;&#22349;&#22604;&#30340;&#38382;&#39064;&#65292;&#24403;&#32534;&#30721;&#22120;&#19982;&#27809;&#26377;&#32771;&#34385;&#36755;&#20837;&#25968;&#25454;&#30340;&#28508;&#22312;&#32467;&#26500;&#30340;&#20808;&#39564;&#37325;&#21512;&#25110;&#22349;&#22604;&#26102;&#23601;&#20250;&#21457;&#29983;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#21453;Lipschitz&#31070;&#32463;&#32593;&#32476;&#30340;&#35299;&#30721;&#22120;&#65292;&#22522;&#20110;&#36825;&#20010;&#26550;&#26500;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21487;&#20197;&#31616;&#21333;&#26126;&#20102;&#22320;&#25511;&#21046;&#24191;&#27867;&#30340;VAE&#27169;&#22411;&#30340;&#21518;&#39564;&#22349;&#22604;&#31243;&#24230;&#65292;&#24182;&#24102;&#26377;&#20855;&#20307;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#20960;&#20010;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variational autoencoders (VAEs) are one of the deep generative models that have experienced enormous success over the past decades. However, in practice, they suffer from a problem called posterior collapse, which occurs when the encoder coincides, or collapses, with the prior taking no information from the latent structure of the input data into consideration. In this work, we introduce an inverse Lipschitz neural network into the decoder and, based on this architecture, provide a new method that can control in a simple and clear manner the degree of posterior collapse for a wide range of VAE models equipped with a concrete theoretical guarantee. We also illustrate the effectiveness of our method through several numerical experiments.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#20154;&#31995;&#32479;&#30340;&#33021;&#37327;&#27969;&#37327;&#21644;&#33021;&#37327;&#29305;&#24615;&#65292;&#25705;&#25830;&#21147;&#21644;&#34987;&#21160;&#25670;&#21160;&#26159;&#20854;&#20027;&#35201;&#24433;&#21709;&#22240;&#32032;&#65292;&#25552;&#20986;&#20102;&#20851;&#38190;&#21442;&#25968;&#21644;&#33021;&#37327;&#29305;&#24615;&#65292;&#26377;&#21161;&#20110;&#36827;&#19968;&#27493;&#30740;&#31350;&#12290;</title><link>http://arxiv.org/abs/2304.12768</link><description>&lt;p&gt;
&#34987;&#21160;&#25670;&#21160;&#25705;&#25830;&#21147;&#20316;&#29992;&#19979;&#26426;&#22120;&#20154;&#33021;&#37327;&#27969;&#37327;&#30340;&#20851;&#38190;&#21442;&#25968;&#21450;&#20854;&#29305;&#24615;
&lt;/p&gt;
&lt;p&gt;
Towards Characterizing the First-order Query Complexity of Learning (Approximate) Nash Equilibria in Zero-sum Matrix Games. (arXiv:2304.12768v1 [cs.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12768
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#20154;&#31995;&#32479;&#30340;&#33021;&#37327;&#27969;&#37327;&#21644;&#33021;&#37327;&#29305;&#24615;&#65292;&#25705;&#25830;&#21147;&#21644;&#34987;&#21160;&#25670;&#21160;&#26159;&#20854;&#20027;&#35201;&#24433;&#21709;&#22240;&#32032;&#65292;&#25552;&#20986;&#20102;&#20851;&#38190;&#21442;&#25968;&#21644;&#33021;&#37327;&#29305;&#24615;&#65292;&#26377;&#21161;&#20110;&#36827;&#19968;&#27493;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#30740;&#31350;&#26426;&#22120;&#20154;&#31995;&#32479;&#30340;&#33021;&#37327;&#27969;&#37327;&#21644;&#33021;&#37327;&#29305;&#24615;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#26426;&#22120;&#20154;&#20256;&#21160;&#31995;&#32479;&#20013;&#25705;&#25830;&#21147;&#21644;&#34987;&#21160;&#25670;&#21160;&#31561;&#22240;&#32032;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#26469;&#20998;&#26512;&#36825;&#20123;&#22240;&#32032;&#23545;&#33021;&#37327;&#27969;&#37327;&#30340;&#24433;&#21709;&#12290;&#36890;&#36807;&#27169;&#25311;&#21644;&#23454;&#39564;&#65292;&#25105;&#20204;&#21457;&#29616;&#33021;&#37327;&#27969;&#37327;&#20027;&#35201;&#21463;&#21040;&#25705;&#25830;&#21147;&#21644;&#34987;&#21160;&#25670;&#21160;&#30340;&#24433;&#21709;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#20123;&#20851;&#38190;&#21442;&#25968;&#21644;&#33021;&#37327;&#29305;&#24615;&#20197;&#20379;&#36827;&#19968;&#27493;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the first-order query model for zero-sum $K\times K$ matrix games, playersobserve the expected pay-offs for all their possible actions under therandomized action played by their opponent. This is a classical model,which has received renewed interest after the discoveryby Rakhlin and Sridharan that $\epsilon$-approximate Nash equilibria can be computedefficiently from $O(\ln K / \epsilon) $ instead of $O( \ln K / \epsilon^2)$ queries.Surprisingly, the optimal number of such queries, as a function of both$\epsilon$ and $K$, is not known.We make progress on this question on two fronts. First, we fully characterise the query complexity of learning exact equilibria ($\epsilon=0$), by showing that they require a number of queries that is linearin $K$, which means that it is essentially as hard as querying the wholematrix, which can also be done with $K$ queries. Second, for $\epsilon &gt; 0$, the currentquery complexity upper bound stands at $O(\min(\ln(K) / \epsilon , K))$. We argue that, u
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#21463;&#38480;&#36890;&#20449;&#21644;&#21152;&#24615;&#39640;&#26031;&#22122;&#22768;&#19979;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#38454;&#27573;&#36172;&#21338;&#31639;&#27861;&#65292;&#24182;&#32473;&#20986;&#20102;&#20449;&#24687;&#29702;&#35770;&#19979;&#38480;&#12290;</title><link>http://arxiv.org/abs/2304.12680</link><description>&lt;p&gt;
&#21463;&#38480;&#36890;&#20449;&#21152;&#24615;&#39640;&#26031;&#22122;&#22768;&#19979;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Communication-Constrained Bandits under Additive Gaussian Noise. (arXiv:2304.12680v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12680
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#21463;&#38480;&#36890;&#20449;&#21644;&#21152;&#24615;&#39640;&#26031;&#22122;&#22768;&#19979;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#38454;&#27573;&#36172;&#21338;&#31639;&#27861;&#65292;&#24182;&#32473;&#20986;&#20102;&#20449;&#24687;&#29702;&#35770;&#19979;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#20998;&#24067;&#24335;&#38543;&#26426;&#22810;&#33218;&#36172;&#21338;&#26426;,&#20854;&#20013;&#23458;&#25143;&#31471;&#26681;&#25454;&#30456;&#24212;&#30340;&#25289;&#33218;&#22870;&#21169;&#25552;&#20379;&#21463;&#38480;&#36890;&#20449;&#21453;&#39304;&#32473;&#23398;&#20064;&#32773;&#12290;&#22312;&#25105;&#20204;&#30340;&#35774;&#23450;&#19979;,&#23458;&#25143;&#31471;&#24517;&#39035;&#32534;&#30721;&#22870;&#21169;&#65292;&#20351;&#24471;&#32534;&#30721;&#22870;&#21169;&#30340;&#20108;&#38454;&#30697;&#19981;&#36229;&#36807;P&#65292;&#24182;&#19988;&#36825;&#20010;&#32534;&#30721;&#22870;&#21169;&#20250;&#34987;&#26041;&#24046;&#20026;$\sigma^2$&#30340;&#21152;&#24615;&#39640;&#26031;&#22122;&#22768;&#25152;&#27745;&#26579;&#65307;&#23398;&#20064;&#32773;&#21482;&#33021;&#35775;&#38382;&#36825;&#20010;&#34987;&#27745;&#26579;&#30340;&#22870;&#21169;&#12290;&#25105;&#20204;&#22312;&#36825;&#20010;&#35774;&#32622;&#20013;&#23548;&#20986;&#20102;&#20219;&#20309;&#26041;&#26696;&#30340;&#26368;&#23567;&#21270;&#21518;&#24724;&#30340;&#20449;&#24687;&#35770;&#19979;&#38480;$\Omega\left(\sqrt{\frac{KT}{\mathtt{SNR} \wedge1}} \right)$&#65292;&#20854;&#20013; $ \mathtt{SNR} := \frac{P}{\sigma^2}$&#65292;$K$&#21644;$T$&#20998;&#21035;&#26159;&#33218;&#25968;&#21644;&#26102;&#38388;&#38271;&#24230;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#38454;&#27573;&#36172;&#21338;&#31639;&#27861;$\mathtt{UE\text{-}UCB++}$&#65292;&#23427;&#21487;&#20197;&#23558;&#36825;&#20010;&#19979;&#38480;&#30340;&#20540;&#21152;&#19978;&#19968;&#20010;&#24494;&#23567;&#30340;&#21487;&#21152;&#24615;&#22240;&#23376;&#12290;$\mathtt{UE\text{-}UCB++}$&#22312;&#20854;&#21021;&#22987;&#38454;&#27573;&#25191;&#34892;&#22343;&#21248;&#25506;&#32034;&#65292;&#28982;&#21518;&#22312;&#21518;&#32493;&#38454;&#27573;&#20351;&#29992;&#8220;&#19978;&#32622;&#20449;&#30028;&#8221;(UCB)&#31639;&#27861;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#25968;&#20540;&#32467;&#26524;&#65292;&#34920;&#26126;&#22312;&#23454;&#38469;&#24773;&#20917;&#19979;&#38656;&#35201;&#36825;&#26679;&#30340;&#36890;&#20449;&#26377;&#25928;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study a distributed stochastic multi-armed bandit where a client supplies the learner with communication-constrained feedback based on the rewards for the corresponding arm pulls. In our setup, the client must encode the rewards such that the second moment of the encoded rewards is no more than $P$, and this encoded reward is further corrupted by additive Gaussian noise of variance $\sigma^2$; the learner only has access to this corrupted reward. For this setting, we derive an information-theoretic lower bound of $\Omega\left(\sqrt{\frac{KT}{\mathtt{SNR} \wedge1}} \right)$ on the minimax regret of any scheme, where $ \mathtt{SNR} := \frac{P}{\sigma^2}$, and $K$ and $T$ are the number of arms and time horizon, respectively. Furthermore, we propose a multi-phase bandit algorithm, $\mathtt{UE\text{-}UCB++}$, which matches this lower bound to a minor additive factor. $\mathtt{UE\text{-}UCB++}$ performs uniform exploration in its initial phases and then utilizes the {\em upper confidence
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#36951;&#20256;&#31639;&#27861;&#30340;&#23545;&#27969;&#20256;&#28909;&#22686;&#24378;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#33258;&#30001;&#27969;&#30456;&#20132;&#30340;&#20845;&#20010;&#38388;&#38553;&#21943;&#27668;&#23380;&#36827;&#34892;&#25511;&#21046;&#65292;&#20248;&#21270;&#20102;&#25104;&#26412;&#20989;&#25968;&#65292;&#26368;&#32456;&#23454;&#29616;&#20102;&#23545;&#23545;&#27969;&#20256;&#28909;&#36895;&#29575;&#30340;&#25552;&#39640;&#12290;</title><link>http://arxiv.org/abs/2304.12618</link><description>&lt;p&gt;
&#22522;&#20110;&#36951;&#20256;&#31639;&#27861;&#30340;&#23545;&#27969;&#20256;&#28909;&#22686;&#24378;
&lt;/p&gt;
&lt;p&gt;
Genetically-inspired convective heat transfer enhancement. (arXiv:2304.12618v1 [physics.flu-dyn])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12618
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#36951;&#20256;&#31639;&#27861;&#30340;&#23545;&#27969;&#20256;&#28909;&#22686;&#24378;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#33258;&#30001;&#27969;&#30456;&#20132;&#30340;&#20845;&#20010;&#38388;&#38553;&#21943;&#27668;&#23380;&#36827;&#34892;&#25511;&#21046;&#65292;&#20248;&#21270;&#20102;&#25104;&#26412;&#20989;&#25968;&#65292;&#26368;&#32456;&#23454;&#29616;&#20102;&#23545;&#23545;&#27969;&#20256;&#28909;&#36895;&#29575;&#30340;&#25552;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#24179;&#26495;&#19978;&#30340;&#32010;&#27969;&#36793;&#30028;&#23618;(TBL)&#19978;&#65292;&#37319;&#29992;&#22522;&#20110;&#32447;&#24615;&#36951;&#20256;&#31639;&#27861;&#25511;&#21046;(LGAC)&#30340;&#20154;&#24037;&#26234;&#33021;&#26041;&#27861;&#23454;&#29616;&#23545;&#27969;&#20256;&#28909;&#30340;&#22686;&#24378;&#12290;&#35813;&#25511;&#21046;&#26041;&#27861;&#37319;&#29992;&#20102;&#19968;&#32452;&#19982;&#33258;&#30001;&#27969;&#30456;&#20132;&#30340;&#20845;&#20010;&#38388;&#38553;&#21943;&#27668;&#23380;&#12290;&#36890;&#36807;&#23545;&#36733;&#27874;&#39057;&#29575;&#65292;&#21344;&#31354;&#27604;&#21644;&#25191;&#34892;&#22120;&#20043;&#38388;&#30340;&#30456;&#20301;&#24046;&#30340;&#25511;&#21046;&#21442;&#25968;&#23450;&#20041;&#24320;&#29615;&#26368;&#20248;&#21608;&#26399;&#24615;&#28608;&#21169;&#12290;&#26681;&#25454;&#26080;&#25200;&#21160;TBL&#21644;&#31283;&#24577;&#21943;&#27969;&#30340;&#25511;&#21046;&#65292;&#23545;&#25511;&#21046;&#23450;&#24459;&#36827;&#34892;&#20102;&#20248;&#21270;&#12290;&#25104;&#26412;&#20989;&#25968;&#21253;&#25324;&#22721;&#38754;&#23545;&#27969;&#20256;&#28909;&#36895;&#29575;&#21644;&#25191;&#34892;&#25104;&#26412;&#12290;&#37319;&#29992;&#32418;&#22806;&#28909;&#25104;&#20687;&#21644;&#31890;&#23376;&#22270;&#20687;&#27979;&#36895;&#25216;&#26415;&#35780;&#20272;&#20102;&#25511;&#21046;&#22120;&#30340;&#24615;&#33021;&#12290;&#26368;&#20248;&#25511;&#21046;&#22120;&#20135;&#29983;&#20102;&#30053;&#24494;&#19981;&#23545;&#31216;&#30340;&#27969;&#22330;&#12290;LGAC&#31639;&#27861;&#25910;&#25947;&#20110;&#25152;&#26377;&#25191;&#34892;&#22120;&#30340;&#30456;&#21516;&#39057;&#29575;&#21644;&#21344;&#31354;&#27604;&#12290;&#22914;&#27492;&#39057;&#29575;&#38750;&#24120;&#25509;&#36817;&#20110;&#29305;&#24449;&#39057;&#29575;&#30340;&#20498;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
The convective heat transfer in a turbulent boundary layer (TBL) on a flat plate is enhanced using an artificial intelligence approach based on linear genetic algorithms control (LGAC). The actuator is a set of six slot jets in crossflow aligned with the freestream. An open-loop optimal periodic forcing is defined by the carrier frequency, the duty cycle and the phase difference between actuators as control parameters. The control laws are optimised with respect to the unperturbed TBL and to the actuation with a steady jet. The cost function includes the wall convective heat transfer rate and the cost of the actuation. The performance of the controller is assessed by infrared thermography and characterised also with particle image velocimetry measurements. The optimal controller yields a slightly asymmetric flow field. The LGAC algorithm converges to the same frequency and duty cycle for all the actuators. It is noted that such frequency is strikingly equal to the inverse of the charac
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#24314;&#27169;&#19981;&#30830;&#23450;&#21644;&#36864;&#21270;&#28382;&#21518;&#31995;&#32479;&#30340;&#21452;&#20445;&#30495;DeepONet&#26041;&#27861;&#65292;&#22312;&#19981;&#20102;&#35299;&#36864;&#21270;&#25928;&#24212;&#24615;&#36136;&#30340;&#21407;&#22987;&#27169;&#22411;&#25968;&#25454;&#38598;&#30340;&#24773;&#20917;&#19979;&#20351;&#29992;&#20302;&#20445;&#30495;&#24230;&#34920;&#31034;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;&#36864;&#21270;&#28382;&#21518;&#31995;&#32479;&#30340;&#39044;&#27979;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2304.12609</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#24314;&#27169;&#19981;&#30830;&#23450;&#21644;&#34928;&#20943;&#28382;&#21518;&#31995;&#32479;&#30340;&#21452;&#20445;&#30495;DeepONet&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Bi-fidelity DeepONet Approach for Modeling Uncertain and Degrading Hysteretic Systems. (arXiv:2304.12609v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12609
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#24314;&#27169;&#19981;&#30830;&#23450;&#21644;&#36864;&#21270;&#28382;&#21518;&#31995;&#32479;&#30340;&#21452;&#20445;&#30495;DeepONet&#26041;&#27861;&#65292;&#22312;&#19981;&#20102;&#35299;&#36864;&#21270;&#25928;&#24212;&#24615;&#36136;&#30340;&#21407;&#22987;&#27169;&#22411;&#25968;&#25454;&#38598;&#30340;&#24773;&#20917;&#19979;&#20351;&#29992;&#20302;&#20445;&#30495;&#24230;&#34920;&#31034;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;&#36864;&#21270;&#28382;&#21518;&#31995;&#32479;&#30340;&#39044;&#27979;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#19981;&#30830;&#23450;&#24615;&#21518;&#65292;&#38750;&#32447;&#24615;&#31995;&#32479;&#22914;&#28382;&#21518;&#34892;&#20026;&#30340;&#36864;&#21270;&#36890;&#24120;&#20986;&#29616;&#22312;&#24037;&#31243;&#24212;&#29992;&#20013;&#65292;&#32780;&#24314;&#27169;&#36825;&#31181;&#31995;&#32479;&#21464;&#24471;&#36234;&#26469;&#36234;&#22256;&#38590;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#21487;&#20197;&#24456;&#23481;&#26131;&#22320;&#33719;&#21462;&#19981;&#20102;&#35299;&#36864;&#21270;&#25928;&#24212;&#24615;&#36136;&#30340;&#21407;&#22987;&#27169;&#22411;&#25968;&#25454;&#38598;&#12290;&#26412;&#25991;&#20351;&#29992;&#26469;&#33258;&#21407;&#22987;&#27169;&#22411;&#30340;&#25968;&#25454;&#38598;&#20316;&#20026;&#20302;&#20445;&#30495;&#24230;&#34920;&#31034;&#65292;&#20197;&#35757;&#32451;DeepONet&#12290;&#19977;&#20010;&#25968;&#20540;&#23454;&#20363;&#29992;&#20110;&#34920;&#26126;&#25152;&#25552;&#20986;&#30340;DeepONets&#30340;&#20351;&#29992;&#65292;&#20197;&#27169;&#25311;&#20302;&#20445;&#30495;&#24230;&#27169;&#22411;&#21644;&#30495;&#23454;&#31995;&#32479;&#21709;&#24212;&#20043;&#38388;&#30340;&#20559;&#24046;&#65292;&#22312;&#27169;&#22411;&#21442;&#25968;&#23384;&#22312;&#19981;&#30830;&#23450;&#24615;&#26102;&#65292;&#22312;&#36864;&#21270;&#28382;&#21518;&#31995;&#32479;&#20013;&#39044;&#27979;&#35823;&#24046;&#26174;&#33879;&#38477;&#20302;&#12290;
&lt;/p&gt;
&lt;p&gt;
Nonlinear systems, such as with degrading hysteretic behavior, are often encountered in engineering applications. In addition, due to the ubiquitous presence of uncertainty and the modeling of such systems becomes increasingly difficult. On the other hand, datasets from pristine models developed without knowing the nature of the degrading effects can be easily obtained. In this paper, we use datasets from pristine models without considering the degrading effects of hysteretic systems as low-fidelity representations that capture many of the important characteristics of the true system's behavior to train a deep operator network (DeepONet). Three numerical examples are used to show that the proposed use of the DeepONets to model the discrepancies between the low-fidelity model and the true system's response leads to significant improvements in the prediction error in the presence of uncertainty in the model parameters for degrading hysteretic systems.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#36890;&#36807;&#22686;&#21152;&#36741;&#21161;&#20219;&#21153;&#30340;&#25968;&#37327;&#21644;&#20195;&#29702;&#32593;&#32476;&#30340;&#22823;&#23567;&#65292;&#25552;&#39640;&#34920;&#31034;&#23398;&#20064;&#30340;&#25928;&#26524;&#12290;&#21516;&#26102;&#65292;&#26412;&#25991;&#36824;&#25552;&#20986;&#20102;&#22522;&#20110;&#21518;&#32487;&#24230;&#37327;&#30340;&#26032;&#22411;&#36741;&#21161;&#20219;&#21153;&#23478;&#26063; Proto-Value &#32593;&#32476;&#12290;</title><link>http://arxiv.org/abs/2304.12567</link><description>&lt;p&gt;
Proto-Value Networks: &#36890;&#36807;&#36741;&#21161;&#20219;&#21153;&#36827;&#34892;&#34920;&#31034;&#23398;&#20064;&#30340;&#21487;&#25193;&#23637;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Proto-Value Networks: Scaling Representation Learning with Auxiliary Tasks. (arXiv:2304.12567v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12567
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#36890;&#36807;&#22686;&#21152;&#36741;&#21161;&#20219;&#21153;&#30340;&#25968;&#37327;&#21644;&#20195;&#29702;&#32593;&#32476;&#30340;&#22823;&#23567;&#65292;&#25552;&#39640;&#34920;&#31034;&#23398;&#20064;&#30340;&#25928;&#26524;&#12290;&#21516;&#26102;&#65292;&#26412;&#25991;&#36824;&#25552;&#20986;&#20102;&#22522;&#20110;&#21518;&#32487;&#24230;&#37327;&#30340;&#26032;&#22411;&#36741;&#21161;&#20219;&#21153;&#23478;&#26063; Proto-Value &#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36741;&#21161;&#20219;&#21153;&#21487;&#20197;&#25552;&#39640;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#23398;&#21040;&#30340;&#34920;&#31034;&#33021;&#21147;&#12290;&#23613;&#31649;&#20854;&#25928;&#26524;&#24050;&#32463;&#34987;&#30456;&#24403;&#20805;&#20998;&#22320;&#29702;&#35770;&#20998;&#26512;&#65292;&#20294;&#22312;&#23454;&#36341;&#20013;&#65292;&#23427;&#20204;&#20027;&#35201;&#34987;&#29992;&#20316;&#20027;&#35201;&#23398;&#20064;&#30446;&#26631;&#30340;&#25903;&#25345;&#65292;&#32780;&#19981;&#26159;&#20316;&#20026;&#34920;&#31034;&#23398;&#20064;&#30340;&#19968;&#31181;&#26041;&#27861;&#12290;&#22522;&#20110;&#36825;&#19968;&#35266;&#23519;&#65292;&#26412;&#25991;&#30740;&#31350;&#20102;&#36741;&#21161;&#20219;&#21153;&#22312;&#23398;&#20064;&#22797;&#26434;&#34920;&#31034;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#65292;&#37325;&#28857;&#20851;&#27880;&#21516;&#26102;&#22686;&#21152;&#20219;&#21153;&#25968;&#37327;&#21644;&#20195;&#29702;&#32593;&#32476;&#30340;&#22823;&#23567;&#30340;&#35774;&#32622;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21518;&#32487;&#24230;&#37327;&#30340;&#26032;&#22411;&#36741;&#21161;&#20219;&#21153;&#23478;&#26063;&#12290;&#36825;&#20123;&#20219;&#21153;&#26131;&#20110;&#23454;&#29616;&#65292;&#20855;&#26377;&#21560;&#24341;&#20154;&#30340;&#29702;&#35770;&#24615;&#36136;&#12290;&#19982;&#21512;&#36866;&#30340;&#31163;&#32447;&#23398;&#20064;&#35268;&#21017;&#32467;&#21512;&#20351;&#29992;&#65292;&#32467;&#26524;&#26159;&#19968;&#20010;&#34920;&#31034;&#23398;&#20064;&#31639;&#27861;&#65292;&#21487;&#20197;&#34987;&#29702;&#35299;&#20026; Proto-Value &#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
Auxiliary tasks improve the representations learned by deep reinforcement learning agents. Analytically, their effect is reasonably well understood; in practice, however, their primary use remains in support of a main learning objective, rather than as a method for learning representations. This is perhaps surprising given that many auxiliary tasks are defined procedurally, and hence can be treated as an essentially infinite source of information about the environment. Based on this observation, we study the effectiveness of auxiliary tasks for learning rich representations, focusing on the setting where the number of tasks and the size of the agent's network are simultaneously increased. For this purpose, we derive a new family of auxiliary tasks based on the successor measure. These tasks are easy to implement and have appealing theoretical properties. Combined with a suitable off-policy learning rule, the result is a representation learning algorithm that can be understood as extend
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#40065;&#26834;&#30456;&#20301;&#24674;&#22797;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#33258;&#36866;&#24212;&#20572;&#27490;&#20934;&#21017;&#30340;&#38750;&#31934;&#30830;&#36817;&#31471;&#32447;&#24615;&#31639;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#23454;&#39564;&#20013;&#35777;&#26126;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#39640;&#25928;&#12290;</title><link>http://arxiv.org/abs/2304.12522</link><description>&lt;p&gt;
&#19968;&#31181;&#26032;&#30340;&#20855;&#26377;&#33258;&#36866;&#24212;&#20572;&#27490;&#20934;&#21017;&#30340;&#38750;&#31934;&#30830;&#36817;&#31471;&#32447;&#24615;&#31639;&#27861;&#65292;&#29992;&#20110;&#40065;&#26834;&#30456;&#20301;&#24674;&#22797;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
A New Inexact Proximal Linear Algorithm with Adaptive Stopping Criteria for Robust Phase Retrieval. (arXiv:2304.12522v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12522
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#40065;&#26834;&#30456;&#20301;&#24674;&#22797;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#33258;&#36866;&#24212;&#20572;&#27490;&#20934;&#21017;&#30340;&#38750;&#31934;&#30830;&#36817;&#31471;&#32447;&#24615;&#31639;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#23454;&#39564;&#20013;&#35777;&#26126;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#39640;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#40065;&#26834;&#30456;&#20301;&#24674;&#22797;&#38382;&#39064;&#65292;&#35813;&#38382;&#39064;&#21487;&#35270;&#20026;&#19968;&#20010;&#38750;&#20809;&#28369;&#21644;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38750;&#31934;&#30830;&#36817;&#31471;&#32447;&#24615;&#31639;&#27861;&#65292;&#20854;&#20013;&#23376;&#38382;&#39064;&#34987;&#19981;&#31934;&#30830;&#27714;&#35299;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#26159;&#20026;&#23376;&#38382;&#39064;&#25552;&#20986;&#20102;&#20004;&#31181;&#33258;&#36866;&#24212;&#20572;&#27490;&#20934;&#21017;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#33021;&#12290;&#36890;&#36807;&#23545;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#39640;&#25928;&#65292;&#20363;&#22914;&#21407;&#22987;&#36817;&#31471;&#32447;&#24615;&#31639;&#27861;&#21644;&#27425;&#26799;&#24230;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper considers the robust phase retrieval problem, which can be cast as a nonsmooth and nonconvex optimization problem. We propose a new inexact proximal linear algorithm with the subproblem being solved inexactly. Our contributions are two adaptive stopping criteria for the subproblem. The convergence behavior of the proposed methods is analyzed. Through experiments on both synthetic and real datasets, we demonstrate that our methods are much more efficient than existing methods, such as the original proximal linear algorithm and the subgradient method.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#24191;&#20041;&#30340;&#36125;&#21494;&#26031;&#26641;&#21450;&#20854;&#21152;&#24615;&#38598;&#25104;&#30340;&#26694;&#26550;&#65292;&#21253;&#25324;&#22823;&#22810;&#25968;BART&#30340;&#21464;&#20307;&#65292;&#24182;&#25552;&#20986;&#21709;&#24212;&#20998;&#24067;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#23545;BART&#21450;&#20854;&#21464;&#20307;&#30340;&#23454;&#35777;&#25104;&#21151;&#25552;&#20379;&#20102;&#29702;&#35770;&#25903;&#25345;&#12290;</title><link>http://arxiv.org/abs/2304.12505</link><description>&lt;p&gt;
&#24191;&#20041;&#36125;&#21494;&#26031;&#21152;&#24615;&#22238;&#24402;&#26641;&#30340;&#21518;&#39564;&#38598;&#20013;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Theory of Posterior Concentration for Generalized Bayesian Additive Regression Trees. (arXiv:2304.12505v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12505
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#24191;&#20041;&#30340;&#36125;&#21494;&#26031;&#26641;&#21450;&#20854;&#21152;&#24615;&#38598;&#25104;&#30340;&#26694;&#26550;&#65292;&#21253;&#25324;&#22823;&#22810;&#25968;BART&#30340;&#21464;&#20307;&#65292;&#24182;&#25552;&#20986;&#21709;&#24212;&#20998;&#24067;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#23545;BART&#21450;&#20854;&#21464;&#20307;&#30340;&#23454;&#35777;&#25104;&#21151;&#25552;&#20379;&#20102;&#29702;&#35770;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#21152;&#24615;&#22238;&#24402;&#26641;&#65288;BART&#65289;&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#21322;&#21442;&#25968;&#38598;&#25104;&#23398;&#20064;&#25216;&#26415;&#65292;&#29992;&#20110;&#24314;&#27169;&#38750;&#32447;&#24615;&#22238;&#24402;&#20989;&#25968;&#12290;&#34429;&#28982;&#26368;&#21021;BART&#20165;&#29992;&#20110;&#39044;&#27979;&#36830;&#32493;&#21644;&#20108;&#20803;&#21709;&#24212;&#21464;&#37327;&#65292;&#20294;&#22810;&#24180;&#26469;&#24050;&#32463;&#20986;&#29616;&#20102;&#22810;&#31181;&#25193;&#23637;&#65292;&#36866;&#29992;&#20110;&#20272;&#35745;&#26356;&#24191;&#27867;&#30340;&#21709;&#24212;&#21464;&#37327;&#65288;&#20363;&#22914;&#20998;&#31867;&#21644;&#35745;&#25968;&#25968;&#25454;&#65289;&#65292;&#24182;&#19988;&#21487;&#20197;&#24212;&#29992;&#20110;&#24456;&#22810;&#39046;&#22495;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#19968;&#20010;&#24191;&#20041;&#36125;&#21494;&#26031;&#26641;&#21450;&#20854;&#21152;&#24615;&#38598;&#25104;&#30340;&#26694;&#26550;&#65292;&#20854;&#20013;&#21709;&#24212;&#21464;&#37327;&#26469;&#33258;&#25351;&#25968;&#26063;&#20998;&#24067;&#65292;&#22240;&#27492;&#21253;&#25324;BART&#30340;&#22823;&#22810;&#25968;&#21464;&#20307;&#12290; &#25105;&#20204;&#25512;&#23548;&#20986;&#21709;&#24212;&#20998;&#24067;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#22312;&#27492;&#26465;&#20214;&#19979;&#65292;&#21518;&#39564;&#20197;&#26368;&#23567;&#21270;&#36895;&#29575;&#38598;&#20013;&#65292;&#26368;&#22810;&#20197;&#23545;&#25968;&#22240;&#23376;&#20026;&#38480;&#12290;&#22312;&#36825;&#26041;&#38754;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#20026;BART&#21450;&#20854;&#21464;&#20307;&#30340;&#23454;&#35777;&#25104;&#21151;&#25552;&#20379;&#20102;&#29702;&#35770;&#20381;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian Additive Regression Trees (BART) are a powerful semiparametric ensemble learning technique for modeling nonlinear regression functions. Although initially BART was proposed for predicting only continuous and binary response variables, over the years multiple extensions have emerged that are suitable for estimating a wider class of response variables (e.g. categorical and count data) in a multitude of application areas. In this paper we describe a Generalized framework for Bayesian trees and their additive ensembles where the response variable comes from an exponential family distribution and hence encompasses a majority of these variants of BART. We derive sufficient conditions on the response distribution, under which the posterior concentrates at a minimax rate, up to a logarithmic factor. In this regard our results provide theoretical justification for the empirical success of BART and its variants.
&lt;/p&gt;</description></item><item><title>&#38024;&#23545;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;&#65292;&#26412;&#25991;&#24341;&#20837;&#20102;&#20004;&#31181;&#24378;&#20581;&#30340;&#38543;&#26426;&#39044;&#22788;&#29702;&#25216;&#26415;&#65292;&#20998;&#21035;&#35299;&#20915;&#20102;&#20840;&#25968;&#25454;KRR&#38382;&#39064;&#21644;&#38480;&#21046;&#29256;KRR&#38382;&#39064;&#65292;&#20811;&#26381;&#20102;&#20197;&#24448;&#39044;&#22788;&#29702;&#22120;&#30340;&#25925;&#38556;&#27169;&#24335;&#12290;</title><link>http://arxiv.org/abs/2304.12465</link><description>&lt;p&gt;
&#24378;&#20581;&#30340;&#38543;&#26426;&#39044;&#22788;&#29702;&#26041;&#27861;&#35299;&#20915;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Robust, randomized preconditioning for kernel ridge regression. (arXiv:2304.12465v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12465
&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#26680;&#23725;&#22238;&#24402;&#38382;&#39064;&#65292;&#26412;&#25991;&#24341;&#20837;&#20102;&#20004;&#31181;&#24378;&#20581;&#30340;&#38543;&#26426;&#39044;&#22788;&#29702;&#25216;&#26415;&#65292;&#20998;&#21035;&#35299;&#20915;&#20102;&#20840;&#25968;&#25454;KRR&#38382;&#39064;&#21644;&#38480;&#21046;&#29256;KRR&#38382;&#39064;&#65292;&#20811;&#26381;&#20102;&#20197;&#24448;&#39044;&#22788;&#29702;&#22120;&#30340;&#25925;&#38556;&#27169;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#20004;&#31181;&#38543;&#26426;&#39044;&#22788;&#29702;&#25216;&#26415;&#65292;&#29992;&#20110;&#24378;&#20581;&#22320;&#35299;&#20915;&#20855;&#26377;&#20013;&#22823;&#35268;&#27169;&#25968;&#25454;&#28857;&#65288;$10^4 \leq N \leq 10^7$&#65289;&#30340;&#26680;&#23725;&#22238;&#24402;&#65288;KRR&#65289;&#38382;&#39064;&#12290;&#31532;&#19968;&#31181;&#26041;&#27861;&#65292;RPCholesky&#39044;&#22788;&#29702;&#65292;&#33021;&#22815;&#22312;&#20551;&#35774;&#26680;&#30697;&#38453;&#29305;&#24449;&#20540;&#26377;&#36275;&#22815;&#24555;&#36895;&#30340;&#22810;&#39033;&#24335;&#34928;&#20943;&#30340;&#24773;&#20917;&#19979;&#65292;&#20197;$O&#65288;N ^ 2&#65289;$&#31639;&#27861;&#25805;&#20316;&#20934;&#30830;&#22320;&#35299;&#20915;&#20840;&#25968;&#25454;KRR&#38382;&#39064;&#12290;&#31532;&#20108;&#31181;&#26041;&#27861;&#65292;KRILL&#39044;&#22788;&#29702;&#65292;&#20197;$O&#65288;&#65288;N + k ^ 2&#65289;k \ logk&#65289;$&#30340;&#20195;&#20215;&#65292;&#20026;KRR&#38382;&#39064;&#30340;&#38480;&#21046;&#29256;&#26412;&#25552;&#20379;&#20934;&#30830;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#35813;&#29256;&#26412;&#28041;&#21450;$k \ll N$&#36873;&#25321;&#30340;&#25968;&#25454;&#20013;&#24515;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#35299;&#20915;&#20102;&#24191;&#27867;&#30340;KRR&#38382;&#39064;&#65292;&#20811;&#26381;&#20102;&#20197;&#21069;&#30340;KRR&#39044;&#22788;&#29702;&#22120;&#30340;&#25925;&#38556;&#27169;&#24335;&#65292;&#20351;&#23427;&#20204;&#25104;&#20026;&#23454;&#38469;&#24212;&#29992;&#30340;&#29702;&#24819;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces two randomized preconditioning techniques for robustly solving kernel ridge regression (KRR) problems with a medium to large number of data points ($10^4 \leq N \leq 10^7$). The first method, RPCholesky preconditioning, is capable of accurately solving the full-data KRR problem in $O(N^2)$ arithmetic operations, assuming sufficiently rapid polynomial decay of the kernel matrix eigenvalues. The second method, KRILL preconditioning, offers an accurate solution to a restricted version of the KRR problem involving $k \ll N$ selected data centers at a cost of $O((N + k^2) k \log k)$ operations. The proposed methods solve a broad range of KRR problems and overcome the failure modes of previous KRR preconditioners, making them ideal for practical applications.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20351;&#29992;&#20102;&#39640;&#25928;&#30340;&#26679;&#26412;&#38598;&#20248;&#21270;&#21644;&#22522;&#20110;&#20195;&#29702;&#30340;&#26041;&#27861;&#26469;&#35774;&#35745;&#27700;&#19979;&#33322;&#34892;&#22120;&#33337;&#20307;&#65292;&#20854;&#20013;&#20195;&#29702;&#27169;&#22411;&#26174;&#33879;&#25552;&#39640;&#20102;&#35745;&#31639;&#25928;&#29575;&#65292;&#20351;&#20248;&#21270;&#26356;&#21152;&#24555;&#36895;&#20934;&#30830;&#12290;</title><link>http://arxiv.org/abs/2304.12420</link><description>&lt;p&gt;
&#27700;&#19979;&#33322;&#34892;&#22120;&#33337;&#20307;&#30340;&#26679;&#26412;&#39640;&#25928;&#21644;&#22522;&#20110;&#20195;&#29702;&#30340;&#35774;&#35745;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Sample-Efficient and Surrogate-Based Design Optimization of Underwater Vehicle Hulls. (arXiv:2304.12420v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12420
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20351;&#29992;&#20102;&#39640;&#25928;&#30340;&#26679;&#26412;&#38598;&#20248;&#21270;&#21644;&#22522;&#20110;&#20195;&#29702;&#30340;&#26041;&#27861;&#26469;&#35774;&#35745;&#27700;&#19979;&#33322;&#34892;&#22120;&#33337;&#20307;&#65292;&#20854;&#20013;&#20195;&#29702;&#27169;&#22411;&#26174;&#33879;&#25552;&#39640;&#20102;&#35745;&#31639;&#25928;&#29575;&#65292;&#20351;&#20248;&#21270;&#26356;&#21152;&#24555;&#36895;&#20934;&#30830;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29289;&#29702;&#27169;&#25311;&#26159;&#35745;&#31639;&#26426;&#36741;&#21161;&#35774;&#35745;(CAD)&#20248;&#21270;&#36807;&#31243;&#20013;&#30340;&#19968;&#20010;&#35745;&#31639;&#29942;&#39048;&#12290;&#22240;&#27492;&#65292;&#20026;&#20102;&#20351;&#31934;&#30830;(&#35745;&#31639;&#26114;&#36149;)&#30340;&#27169;&#25311;&#21487;&#29992;&#20110;&#35774;&#35745;&#20248;&#21270;&#20013;&#65292;&#38656;&#35201;&#19968;&#20010;&#39640;&#26679;&#26412;&#25928;&#29575;&#30340;&#20248;&#21270;&#26694;&#26550;&#25110;&#24555;&#36895;&#30340;&#25968;&#25454;&#39537;&#21160;&#20195;&#29702;(&#20195;&#29702;&#27169;&#22411;)&#26469;&#20195;&#26367;&#38271;&#26102;&#38388;&#36816;&#34892;&#30340;&#27169;&#25311;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#26368;&#36817;&#20248;&#21270;&#21644;&#20154;&#24037;&#26234;&#33021;(AI)&#30340;&#36827;&#23637;&#26469;&#35299;&#20915;&#36825;&#20004;&#20010;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20197;&#35774;&#35745;&#19968;&#20010;&#26368;&#20339;&#30340;&#26080;&#20154;&#27700;&#19979;&#33322;&#34892;&#22120;(UUV)&#12290;&#25105;&#20204;&#39318;&#20808;&#30740;&#31350;&#24182;&#27604;&#36739;&#20102;&#19981;&#21516;&#20248;&#21270;&#25216;&#26415;&#22312;&#20248;&#21270;&#24490;&#29615;&#20013;&#19982;&#26631;&#20934;&#35745;&#31639;&#27969;&#20307;&#21147;&#23398;(CFD)&#27714;&#35299;&#22120;&#30456;&#32467;&#21512;&#26102;&#30340;&#26679;&#26412;&#25928;&#29575;&#21644;&#25910;&#25947;&#34892;&#20026;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNN)&#30340;&#20195;&#29702;&#27169;&#22411;&#26469;&#36924;&#36817;&#21542;&#21017;&#36890;&#36807;CFD&#27714;&#35299;&#22120;&#36827;&#34892;&#35745;&#31639;&#30340;&#38459;&#21147;&#12290;&#20195;&#29702;&#27169;&#22411;&#36827;&#32780;&#29992;&#20110;&#26679;&#26412;&#39640;&#25928;&#30340;&#20248;&#21270;&#26694;&#26550;&#20013;&#65292;&#35813;&#26694;&#26550;&#22312;&#19981;&#20351;&#29992;&#20195;&#29702;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#20248;&#20110;&#26631;&#20934;&#20248;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Physics simulations are a computational bottleneck in computer-aided design (CAD) optimization processes. Hence, in order to make accurate (computationally expensive) simulations feasible for use in design optimization, one requires either an optimization framework that is highly sample-efficient or fast data-driven proxies (surrogate models) for long running simulations. In this work, we leverage recent advances in optimization and artificial intelligence (AI) to address both of these potential solutions, in the context of designing an optimal unmanned underwater vehicle (UUV). We first investigate and compare the sample efficiency and convergence behavior of different optimization techniques with a standard computational fluid dynamics (CFD) solver in the optimization loop. We then develop a deep neural network (DNN) based surrogate model to approximate drag forces that would otherwise be computed via direct numerical simulation with the CFD solver. The surrogate model is in turn use
&lt;/p&gt;</description></item><item><title>&#35813;&#36719;&#20214;&#21253;&#25552;&#20379;&#20102;&#19968;&#32452;&#26377;&#29992;&#30340;&#24037;&#20855;&#26469;&#20998;&#26512;&#20998;&#31867;&#26102;&#38388;&#24207;&#21015;&#65292;&#20351;&#24471;&#29992;&#25143;&#21487;&#20197;&#29992;&#22270;&#24418;&#25551;&#36848;&#24213;&#23618;&#26102;&#38388;&#27169;&#24335;&#24182;&#21033;&#29992;&#20854;&#36755;&#20986;&#25191;&#34892;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#21253;&#25324;&#32858;&#31867;&#12289;&#20998;&#31867;&#21644;&#24322;&#24120;&#26816;&#27979;&#12290;</title><link>http://arxiv.org/abs/2304.12332</link><description>&lt;p&gt;
&#20351;&#29992;R&#36719;&#20214;&#21253;ctsfeatures&#20998;&#26512;&#20998;&#31867;&#26102;&#38388;&#24207;&#21015;
&lt;/p&gt;
&lt;p&gt;
Analyzing categorical time series with the R package ctsfeatures. (arXiv:2304.12332v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12332
&lt;/p&gt;
&lt;p&gt;
&#35813;&#36719;&#20214;&#21253;&#25552;&#20379;&#20102;&#19968;&#32452;&#26377;&#29992;&#30340;&#24037;&#20855;&#26469;&#20998;&#26512;&#20998;&#31867;&#26102;&#38388;&#24207;&#21015;&#65292;&#20351;&#24471;&#29992;&#25143;&#21487;&#20197;&#29992;&#22270;&#24418;&#25551;&#36848;&#24213;&#23618;&#26102;&#38388;&#27169;&#24335;&#24182;&#21033;&#29992;&#20854;&#36755;&#20986;&#25191;&#34892;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#21253;&#25324;&#32858;&#31867;&#12289;&#20998;&#31867;&#21644;&#24322;&#24120;&#26816;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#22914;&#20170;&#24050;&#26080;&#22788;&#19981;&#22312;&#12290;&#28982;&#32780;&#65292;&#22823;&#37096;&#20998;&#25991;&#29486;&#37117;&#22788;&#29702;&#23454;&#20540;&#26102;&#38388;&#24207;&#21015;&#65292;&#20998;&#31867;&#26102;&#38388;&#24207;&#21015;&#21364;&#21463;&#21040;&#20102;&#36739;&#23569;&#30340;&#20851;&#27880;&#12290;&#36817;&#24180;&#26469;&#65292;&#36825;&#31867;&#25968;&#25454;&#30340;&#25968;&#25454;&#25366;&#25496;&#25216;&#26415;&#24471;&#21040;&#20102;&#23454;&#36136;&#24615;&#30340;&#21457;&#23637;&#12290; R&#36719;&#20214;&#21253;ctsfeatures&#20026;&#29992;&#25143;&#25552;&#20379;&#20102;&#19968;&#32452;&#26377;&#29992;&#30340;&#24037;&#20855;&#26469;&#20998;&#26512;&#20998;&#31867;&#26102;&#38388;&#24207;&#21015;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#35813;&#36719;&#20214;&#21253;&#25552;&#20379;&#20102;&#20960;&#20010;&#20989;&#25968;&#65292;&#20801;&#35768;&#25552;&#21462;&#24050;&#30693;&#30340;&#32479;&#35745;&#29305;&#24449;&#24182;&#26500;&#24314;&#25551;&#36848;&#24213;&#23618;&#26102;&#38388;&#27169;&#24335;&#30340;&#22270;&#24418;&#12290;&#26576;&#20123;&#20989;&#25968;&#30340;&#36755;&#20986;&#21487;&#29992;&#20110;&#25191;&#34892;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#65292;&#21253;&#25324;&#32858;&#31867;&#12289;&#20998;&#31867;&#21644;&#24322;&#24120;&#26816;&#27979;&#12290;&#35813;&#36719;&#20214;&#21253;&#36824;&#21253;&#25324;&#20004;&#20010;&#22312;&#25991;&#29486;&#20013;&#20171;&#32461;&#30340;&#29983;&#29289;&#24207;&#21015;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#32858;&#31867;&#30446;&#30340;&#65292;&#20197;&#21450;&#19977;&#20010;&#26377;&#36259;&#30340;&#21512;&#25104;&#25968;&#25454;&#24211;&#12290;&#26412;&#25991;&#25551;&#36848;&#20102;&#35813;&#36719;&#20214;&#21253;&#30340;&#20027;&#35201;&#29305;&#24449;&#21450;&#20854;&#20351;&#29992;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Time series data are ubiquitous nowadays. Whereas most of the literature on the topic deals with real-valued time series, categorical time series have received much less attention. However, the development of data mining techniques for this kind of data has substantially increased in recent years. The R package ctsfeatures offers users a set of useful tools for analyzing categorical time series. In particular, several functions allowing the extraction of well-known statistical features and the construction of illustrative graphs describing underlying temporal patterns are provided in the package. The output of some functions can be employed to perform traditional machine learning tasks including clustering, classification and outlier detection. The package also includes two datasets of biological sequences introduced in the literature for clustering purposes, as well as three interesting synthetic databases. In this work, the main characteristics of the package are described and its us
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#40654;&#26364;&#23376;&#27969;&#24418;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#20102;&#31616;&#21270;&#65292;&#25552;&#20986;&#20102;&#40654;&#26364;&#27491;&#24120;&#22352;&#26631;&#30340;&#24191;&#20041;&#29256;&#26412;&#65292;&#21487;&#29992;&#20110;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#30340;&#23376;&#27969;&#24418;&#20248;&#21270;&#65292;&#24182;&#20026;&#28145;&#24230;&#23398;&#20064;&#24320;&#21457;&#20102;&#39640;&#25928;&#30340;&#20108;&#38454;&#20248;&#21270;&#22120;&#65292;&#26080;&#38656;&#26174;&#24335;&#30697;&#38453;&#27714;&#36870;&#12290;</title><link>http://arxiv.org/abs/2302.09738</link><description>&lt;p&gt;
&#31616;&#21270;&#22522;&#20110;&#21160;&#37327;&#30340;&#40654;&#26364;&#23376;&#27969;&#24418;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Simplifying Momentum-based Riemannian Submanifold Optimization. (arXiv:2302.09738v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09738
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#40654;&#26364;&#23376;&#27969;&#24418;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#20102;&#31616;&#21270;&#65292;&#25552;&#20986;&#20102;&#40654;&#26364;&#27491;&#24120;&#22352;&#26631;&#30340;&#24191;&#20041;&#29256;&#26412;&#65292;&#21487;&#29992;&#20110;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#30340;&#23376;&#27969;&#24418;&#20248;&#21270;&#65292;&#24182;&#20026;&#28145;&#24230;&#23398;&#20064;&#24320;&#21457;&#20102;&#39640;&#25928;&#30340;&#20108;&#38454;&#20248;&#21270;&#22120;&#65292;&#26080;&#38656;&#26174;&#24335;&#30697;&#38453;&#27714;&#36870;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24102;&#26377;&#21160;&#37327;&#30340;&#40654;&#26364;&#23376;&#27969;&#24418;&#20248;&#21270;&#22312;&#35745;&#31639;&#19978;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#22240;&#20026;&#30830;&#20445;&#36845;&#20195;&#20445;&#25345;&#22312;&#23376;&#27969;&#24418;&#19978;&#36890;&#24120;&#38656;&#35201;&#35299;&#20915;&#22256;&#38590;&#30340;&#24494;&#20998;&#26041;&#31243;&#12290;&#26412;&#25991;&#38024;&#23545;&#20855;&#26377;&#20223;&#23556;&#19981;&#21464;&#24230;&#37327;&#30340;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#30340;&#23376;&#27969;&#24418;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#20102;&#31616;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#40654;&#26364;&#27491;&#24120;&#22352;&#26631;&#30340;&#24191;&#20041;&#29256;&#26412;&#65292;&#21487;&#20197;&#23558;&#38382;&#39064;&#21160;&#24577;&#22320;&#31616;&#21270;&#20026;&#27431;&#20960;&#37324;&#24471;&#26080;&#32422;&#26463;&#38382;&#39064;&#12290;&#25105;&#20204;&#20351;&#29992;&#25105;&#20204;&#30340;&#26041;&#27861;&#26469;&#35299;&#37322;&#21644;&#31616;&#21270;&#29616;&#26377;&#30340;&#32467;&#26500;&#21270;&#21327;&#26041;&#24046;&#26041;&#27861;&#65292;&#24182;&#20026;&#28145;&#24230;&#23398;&#20064;&#24320;&#21457;&#20102;&#39640;&#25928;&#30340;&#20108;&#38454;&#20248;&#21270;&#22120;&#65292;&#32780;&#26080;&#38656;&#26174;&#24335;&#30697;&#38453;&#27714;&#36870;&#12290;
&lt;/p&gt;
&lt;p&gt;
Riemannian submanifold optimization with momentum is computationally challenging because ensuring iterates remain on the submanifold often requires solving difficult differential equations. We simplify such optimization algorithms for the submanifold of symmetric positive-definite matrices with the affine invariant metric. We propose a generalized version of the Riemannian normal coordinates which dynamically trivializes the problem into a Euclidean unconstrained problem. We use our approach to explain and simplify existing approaches for structured covariances and develop efficient second-order optimizers for deep learning without explicit matrix inverses.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#31649;&#36947;&#65288;FavMac&#65289;&#65292;&#21487;&#20197;&#26368;&#22823;&#21270;&#20215;&#20540;&#24182;&#25511;&#21046;&#25104;&#26412;&#12290; FavMac&#21487;&#20197;&#19982;&#20960;&#20046;&#20219;&#20309;&#22810;&#26631;&#31614;&#20998;&#31867;&#22120;&#30456;&#32467;&#21512;&#65292;&#24182;&#36890;&#36807;&#22312;&#32447;&#26356;&#26032;&#26426;&#21046;&#22788;&#29702;&#23454;&#38469;&#30340;&#22823;&#35268;&#27169;&#24212;&#29992;&#65292;&#20026;&#25104;&#26412;&#25511;&#21046;&#25552;&#20379;&#26080;&#20998;&#24067;&#29702;&#35770;&#25285;&#20445;&#12290;</title><link>http://arxiv.org/abs/2302.00839</link><description>&lt;p&gt;
&#24555;&#36895;&#22312;&#32447;&#20540;&#26368;&#22823;&#21270;&#39044;&#27979;&#38598;&#21644;&#31526;&#21512;&#35268;&#33539;&#25104;&#26412;&#25511;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fast Online Value-Maximizing Prediction Sets with Conformal Cost Control. (arXiv:2302.00839v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.00839
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#31649;&#36947;&#65288;FavMac&#65289;&#65292;&#21487;&#20197;&#26368;&#22823;&#21270;&#20215;&#20540;&#24182;&#25511;&#21046;&#25104;&#26412;&#12290; FavMac&#21487;&#20197;&#19982;&#20960;&#20046;&#20219;&#20309;&#22810;&#26631;&#31614;&#20998;&#31867;&#22120;&#30456;&#32467;&#21512;&#65292;&#24182;&#36890;&#36807;&#22312;&#32447;&#26356;&#26032;&#26426;&#21046;&#22788;&#29702;&#23454;&#38469;&#30340;&#22823;&#35268;&#27169;&#24212;&#29992;&#65292;&#20026;&#25104;&#26412;&#25511;&#21046;&#25552;&#20379;&#26080;&#20998;&#24067;&#29702;&#35770;&#25285;&#20445;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#29616;&#23454;&#19990;&#30028;&#30340;&#22810;&#26631;&#31614;&#39044;&#27979;&#38382;&#39064;&#28041;&#21450;&#21040;&#24517;&#39035;&#28385;&#36275;&#19979;&#28216;&#20351;&#29992;&#35268;&#23450;&#30340;&#29305;&#23450;&#35201;&#27714;&#30340;&#38598;&#21512;&#20540;&#39044;&#27979;&#12290;&#25105;&#20204;&#20851;&#27880;&#19968;&#20010;&#20856;&#22411;&#30340;&#24773;&#20917;&#65292;&#20854;&#20013;&#36825;&#20123;&#35201;&#27714;&#20998;&#21035;&#32534;&#30721;&#20215;&#20540;&#21644;&#25104;&#26412;&#65292;&#24182;&#30456;&#20114;&#31454;&#20105;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#34987;&#31216;&#20026;FavMac&#30340;&#36890;&#29992;&#31649;&#36947;&#65292;&#20197;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#26368;&#22823;&#21270;&#20215;&#20540;&#24182;&#25511;&#21046;&#25104;&#26412;&#12290; FavMac&#21487;&#20197;&#19982;&#20960;&#20046;&#20219;&#20309;&#22810;&#26631;&#31614;&#20998;&#31867;&#22120;&#30456;&#32467;&#21512;&#65292;&#20026;&#25104;&#26412;&#25511;&#21046;&#25552;&#20379;&#26080;&#20998;&#24067;&#29702;&#35770;&#25285;&#20445;&#12290;&#27492;&#22806;&#65292;&#19982;&#20043;&#21069;&#30340;&#20316;&#21697;&#19981;&#21516;&#65292;&#23427;&#21487;&#20197;&#36890;&#36807;&#31934;&#24515;&#35774;&#35745;&#30340;&#22312;&#32447;&#26356;&#26032;&#26426;&#21046;&#22788;&#29702;&#23454;&#38469;&#30340;&#22823;&#35268;&#27169;&#24212;&#29992;&#65292;&#36825;&#26159;&#20540;&#24471;&#29420;&#31435;&#20851;&#27880;&#30340;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#35770;&#21644;&#29702;&#35770;&#36129;&#29486;&#24471;&#21040;&#20102;&#23545;&#22810;&#31181;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#22120;&#21644;&#20960;&#31181;&#25968;&#25454;&#38598;&#30340;&#35797;&#39564;&#25903;&#25745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many real-world multi-label prediction problems involve set-valued predictions that must satisfy specific requirements dictated by downstream usage. We focus on a typical scenario where such requirements, separately encoding $\textit{value}$ and $\textit{cost}$, compete with each other. For instance, a hospital might expect a smart diagnosis system to capture as many severe, often co-morbid, diseases as possible (the value), while maintaining strict control over incorrect predictions (the cost). We present a general pipeline, dubbed as FavMac, to maximize the value while controlling the cost in such scenarios. FavMac can be combined with almost any multi-label classifier, affording distribution-free theoretical guarantees on cost control. Moreover, unlike prior works, it can handle real-world large-scale applications via a carefully designed online update mechanism, which is of independent interest. Our methodological and theoretical contributions are supported by experiments on severa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#27491;&#21017;&#21270;&#27969;&#65292;&#19987;&#20026;&#19977;&#32500;&#31354;&#38388;&#20013;&#22810;&#20010;&#29289;&#20307;&#30340;&#20301;&#32622;&#21644;&#26041;&#21521;&#24314;&#27169;&#32780;&#35774;&#35745;&#12290;&#36890;&#36807;&#22312;&#21333;&#20301;&#22235;&#20803;&#25968;&#32676;&#19978;&#23450;&#20041;&#24179;&#28369;&#21644;&#34920;&#29616;&#21147;&#24378;&#30340;&#27969;&#20197;&#21450;&#23450;&#20041;&#36866;&#24403;&#30340;&#23494;&#24230;&#65292;&#22312;&#26059;&#36716;&#32676;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#25105;&#20204;&#21487;&#20197;&#25104;&#21151;&#22320;&#37319;&#26679;&#20998;&#23376;&#26230;&#20307;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2301.11355</link><description>&lt;p&gt;
&#29992;&#20110;&#37319;&#26679;&#20998;&#23376;&#26230;&#20307;&#32467;&#26500;&#30340;&#21018;&#20307;&#27969;
&lt;/p&gt;
&lt;p&gt;
Rigid body flows for sampling molecular crystal structures. (arXiv:2301.11355v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11355
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#27491;&#21017;&#21270;&#27969;&#65292;&#19987;&#20026;&#19977;&#32500;&#31354;&#38388;&#20013;&#22810;&#20010;&#29289;&#20307;&#30340;&#20301;&#32622;&#21644;&#26041;&#21521;&#24314;&#27169;&#32780;&#35774;&#35745;&#12290;&#36890;&#36807;&#22312;&#21333;&#20301;&#22235;&#20803;&#25968;&#32676;&#19978;&#23450;&#20041;&#24179;&#28369;&#21644;&#34920;&#29616;&#21147;&#24378;&#30340;&#27969;&#20197;&#21450;&#23450;&#20041;&#36866;&#24403;&#30340;&#23494;&#24230;&#65292;&#22312;&#26059;&#36716;&#32676;&#19978;&#36827;&#34892;&#35757;&#32451;&#65292;&#25105;&#20204;&#21487;&#20197;&#25104;&#21151;&#22320;&#37319;&#26679;&#20998;&#23376;&#26230;&#20307;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27491;&#21017;&#21270;&#27969;(NF)&#26159;&#19968;&#31867;&#24378;&#22823;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#30001;&#20110;&#20854;&#39640;&#24230;&#28789;&#27963;&#21644;&#34920;&#29616;&#21147;&#65292;&#36817;&#24180;&#26469;&#24191;&#21463;&#27426;&#36814;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#27491;&#21017;&#21270;&#27969;&#65292;&#19987;&#20026;&#19977;&#32500;&#31354;&#38388;&#20013;&#22810;&#20010;&#29289;&#20307;&#30340;&#20301;&#32622;&#21644;&#26041;&#21521;&#24314;&#27169;&#32780;&#35774;&#35745;&#65292;&#20363;&#22914;&#26230;&#20307;&#20013;&#30340;&#20998;&#23376;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#20004;&#20010;&#20851;&#38190;&#24605;&#24819;:&#39318;&#20808;&#65292;&#25105;&#20204;&#22312;&#21333;&#20301;&#22235;&#20803;&#25968;&#32676;&#19978;&#23450;&#20041;&#24179;&#28369;&#21644;&#34920;&#29616;&#21147;&#24378;&#30340;&#27969;&#65292;&#20174;&#32780;&#21487;&#20197;&#25429;&#25417;&#21018;&#20307;&#30340;&#36830;&#32493;&#26059;&#36716;&#36816;&#21160;;&#20854;&#27425;&#65292;&#25105;&#20204;&#21033;&#29992;&#21333;&#20301;&#22235;&#20803;&#25968;&#30340;&#21452;&#35206;&#30422;&#29305;&#24615;&#65292;&#22312;&#26059;&#36716;&#32676;&#19978;&#23450;&#20041;&#19968;&#20010;&#36866;&#24403;&#30340;&#23494;&#24230;&#12290;&#36825;&#30830;&#20445;&#25105;&#20204;&#30340;&#27169;&#22411;&#21487;&#20197;&#20351;&#29992;&#26631;&#20934;&#30340;&#22522;&#20110;&#20284;&#28982;&#26041;&#27861;&#25110;&#22522;&#20110;&#28909;&#21147;&#23398;&#30446;&#26631;&#23494;&#24230;&#30340;&#21464;&#20998;&#25512;&#26029;&#36827;&#34892;&#35757;&#32451;&#12290;&#25105;&#20204;&#36890;&#36807;&#35757;&#32451;&#20004;&#20010;&#20998;&#23376;&#31034;&#20363;&#30340;Boltzmann&#29983;&#25104;&#22120;&#26469;&#35780;&#20272;&#35813;&#26041;&#27861;&#65292;&#21363;&#22235;&#38754;&#20307;&#31995;&#32479;&#30340;&#22810;&#27169;&#24577;&#23494;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Normalizing flows (NF) are a class of powerful generative models that have gained popularity in recent years due to their ability to model complex distributions with high flexibility and expressiveness. In this work, we introduce a new type of normalizing flow that is tailored for modeling positions and orientations of multiple objects in three-dimensional space, such as molecules in a crystal. Our approach is based on two key ideas: first, we define smooth and expressive flows on the group of unit quaternions, which allows us to capture the continuous rotational motion of rigid bodies; second, we use the double cover property of unit quaternions to define a proper density on the rotation group. This ensures that our model can be trained using standard likelihood-based methods or variational inference with respect to a thermodynamic target density. We evaluate the method by training Boltzmann generators for two molecular examples, namely the multi-modal density of a tetrahedral system 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19981;&#21464;Lipschitz&#36172;&#24466;&#35774;&#32622;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;\texttt{UniformMesh-N}&#30340;&#31639;&#27861;&#12290;&#20351;&#29992;&#20391;&#38754;&#35266;&#23519;&#30340;&#26041;&#27861;&#65292;&#35777;&#26126;&#20102;&#25913;&#36827;&#30340;&#36951;&#25022;&#19978;&#30028;&#12290;</title><link>http://arxiv.org/abs/2212.07524</link><description>&lt;p&gt;
&#19981;&#21464;Lipschitz&#36172;&#24466;&#65306;&#19968;&#20010;&#20391;&#35266;&#21457;&#29616;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Invariant Lipschitz Bandits: A Side Observation Approach. (arXiv:2212.07524v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.07524
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19981;&#21464;Lipschitz&#36172;&#24466;&#35774;&#32622;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;\texttt{UniformMesh-N}&#30340;&#31639;&#27861;&#12290;&#20351;&#29992;&#20391;&#38754;&#35266;&#23519;&#30340;&#26041;&#27861;&#65292;&#35777;&#26126;&#20102;&#25913;&#36827;&#30340;&#36951;&#25022;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#31216;&#20986;&#29616;&#22312;&#35768;&#22810;&#20248;&#21270;&#21644;&#20915;&#31574;&#38382;&#39064;&#20013;&#65292;&#24182;&#21560;&#24341;&#20102;&#20248;&#21270;&#30028;&#30340;&#30456;&#24403;&#20851;&#27880;&#65306;&#36890;&#36807;&#21033;&#29992;&#36825;&#26679;&#30340;&#23545;&#31216;&#24615;&#65292;&#21487;&#20197;&#26174;&#33879;&#25913;&#36827;&#23547;&#25214;&#26368;&#20248;&#35299;&#30340;&#36807;&#31243;&#12290;&#23613;&#31649;&#23545;&#31216;&#24615;&#22312;&#65288;&#31163;&#32447;&#65289;&#20248;&#21270;&#20013;&#21462;&#24471;&#25104;&#21151;&#65292;&#20294;&#22312;&#22312;&#32447;&#20248;&#21270;&#35774;&#32622;&#20013;&#65292;&#29305;&#21035;&#26159;&#22312;&#36172;&#24466;&#25991;&#29486;&#20013;&#65292;&#20854;&#21033;&#29992;&#36824;&#26410;&#24471;&#21040;&#20805;&#20998;&#30340;&#30740;&#31350;&#12290;&#22240;&#27492;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19981;&#21464;Lipschitz&#36172;&#24466;&#35774;&#32622;&#65292;&#36825;&#26159;Lipschitz&#36172;&#24466;&#30340;&#19968;&#20010;&#23376;&#31867;&#65292;&#22312;&#35813;&#23376;&#31867;&#20013;&#65292;&#22870;&#21169;&#20989;&#25968;&#21644;&#33218;&#38598;&#22312;&#19968;&#32452;&#21464;&#25442;&#19979;&#20445;&#25345;&#19981;&#21464;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;\texttt{UniformMesh-N}&#30340;&#31639;&#27861;&#65292;&#23427;&#33258;&#28982;&#22320;&#23558;&#20391;&#38754;&#35266;&#23519;&#20351;&#29992;&#32676;&#36712;&#36947;&#25972;&#21512;&#21040;\texttt{UniformMesh}&#31639;&#27861;&#65288;\cite{Kleinberg2005_UniformMesh}&#65289;&#20013;&#65292;&#35813;&#31639;&#27861;&#22343;&#21248;&#22320;&#20998;&#21106;&#20102;&#33218;&#30340;&#38598;&#21512;&#12290;&#36890;&#36807;&#20391;&#38754;&#35266;&#23519;&#26041;&#27861;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25913;&#36827;&#30340;&#36951;&#25022;&#19978;&#30028;&#65292;&#20854;&#21462;&#20915;&#20110;&#22522;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Symmetry arises in many optimization and decision-making problems, and has attracted considerable attention from the optimization community: By utilizing the existence of such symmetries, the process of searching for optimal solutions can be improved significantly. Despite its success in (offline) optimization, the utilization of symmetries has not been well examined within the online optimization settings, especially in the bandit literature. As such, in this paper we study the invariant Lipschitz bandit setting, a subclass of the Lipschitz bandits where the reward function and the set of arms are preserved under a group of transformations. We introduce an algorithm named \texttt{UniformMesh-N}, which naturally integrates side observations using group orbits into the \texttt{UniformMesh} algorithm (\cite{Kleinberg2005_UniformMesh}), which uniformly discretizes the set of arms. Using the side-observation approach, we prove an improved regret upper bound, which depends on the cardinalit
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;GNN&#27169;&#25311;&#39030;&#28857;&#38388;&#30456;&#20114;&#20316;&#29992;&#30340;&#33021;&#21147;&#65292;&#36890;&#36807;&#19968;&#20010;&#34987;&#31216;&#20026;&#20998;&#31163;&#31209;&#30340;&#24230;&#37327;&#26631;&#20934;&#26469;&#37327;&#21270;&#36825;&#31181;&#33021;&#21147;&#65292;&#32467;&#26524;&#34920;&#26126;&#27169;&#25311;&#30456;&#20114;&#20316;&#29992;&#30340;&#33021;&#21147;&#20027;&#35201;&#21462;&#20915;&#20110;&#20998;&#21306;&#30340;&#34892;&#36208;&#25351;&#25968;&#65292;&#21363;&#20174;&#20998;&#30028;&#32447;&#24320;&#22987;&#30340;&#34892;&#36208;&#25968;&#37327;&#65292;&#21516;&#26102;&#35774;&#35745;&#20102;&#19968;&#31181;&#21517;&#20026;WISA&#30340;&#36793;&#31232;&#30095;&#21270;&#31639;&#27861;&#20197;&#25552;&#39640;GNNs&#30340;&#22788;&#29702;&#25928;&#29575;&#21644;&#34920;&#36798;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2211.16494</link><description>&lt;p&gt;
&#20851;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#27169;&#25311;&#39030;&#28857;&#38388;&#30456;&#20114;&#20316;&#29992;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Ability of Graph Neural Networks to Model Interactions Between Vertices. (arXiv:2211.16494v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.16494
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;GNN&#27169;&#25311;&#39030;&#28857;&#38388;&#30456;&#20114;&#20316;&#29992;&#30340;&#33021;&#21147;&#65292;&#36890;&#36807;&#19968;&#20010;&#34987;&#31216;&#20026;&#20998;&#31163;&#31209;&#30340;&#24230;&#37327;&#26631;&#20934;&#26469;&#37327;&#21270;&#36825;&#31181;&#33021;&#21147;&#65292;&#32467;&#26524;&#34920;&#26126;&#27169;&#25311;&#30456;&#20114;&#20316;&#29992;&#30340;&#33021;&#21147;&#20027;&#35201;&#21462;&#20915;&#20110;&#20998;&#21306;&#30340;&#34892;&#36208;&#25351;&#25968;&#65292;&#21363;&#20174;&#20998;&#30028;&#32447;&#24320;&#22987;&#30340;&#34892;&#36208;&#25968;&#37327;&#65292;&#21516;&#26102;&#35774;&#35745;&#20102;&#19968;&#31181;&#21517;&#20026;WISA&#30340;&#36793;&#31232;&#30095;&#21270;&#31639;&#27861;&#20197;&#25552;&#39640;GNNs&#30340;&#22788;&#29702;&#25928;&#29575;&#21644;&#34920;&#36798;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;(GNNs)&#34987;&#24191;&#27867;&#29992;&#20110;&#24314;&#27169;&#30001;&#22270;&#20013;&#39030;&#28857;&#34920;&#31034;&#30340;&#23454;&#20307;&#20043;&#38388;&#30340;&#22797;&#26434;&#20114;&#21160;&#12290;&#23613;&#31649;&#26368;&#36817;&#26377;&#19968;&#20123;&#29702;&#35770;&#20998;&#26512;GNNs&#34920;&#36798;&#33021;&#21147;&#30340;&#21162;&#21147;&#65292;&#20294;&#23545;&#20854;&#27169;&#25311;&#30456;&#20114;&#20316;&#29992;&#30340;&#33021;&#21147;&#32570;&#20047;&#19968;&#20010;&#27491;&#24335;&#30340;&#25551;&#36848;&#12290;&#26412;&#25991;&#26088;&#22312;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#12290;&#36890;&#36807;&#19968;&#20010;&#24050;&#30693;&#30340;&#24230;&#37327;&#26631;&#20934;&#8212;&#8212;&#20998;&#31163;&#31209;(separation rank)&#26469;&#35268;&#33539;&#21270;&#30456;&#20114;&#20316;&#29992;&#30340;&#24378;&#24230;&#65292;&#25105;&#20204;&#37327;&#21270;&#20102;&#26576;&#20123;GNNs&#27169;&#25311;&#32473;&#23450;&#39030;&#28857;&#23376;&#38598;&#21450;&#20854;&#34917;&#38598;&#20043;&#38388;&#20132;&#20114;&#30340;&#33021;&#21147;&#65292;&#21363;&#36755;&#20837;&#39030;&#28857;&#32452;&#25104;&#30340;&#32473;&#23450;&#20998;&#21306;&#30340;&#20004;&#20391;&#20043;&#38388;&#30340;&#20114;&#21160;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#27169;&#25311;&#30456;&#20114;&#20316;&#29992;&#30340;&#33021;&#21147;&#20027;&#35201;&#21462;&#20915;&#20110;&#20998;&#21306;&#30340;&#34892;&#36208;&#25351;&#25968;(walk index)&#8212;&#8212;&#19968;&#20010;&#30001;&#20998;&#30028;&#32447;&#24320;&#22987;&#30340;&#34892;&#36208;&#25968;&#37327;&#23450;&#20041;&#30340;&#22270;&#24418;&#29305;&#24449;&#12290;&#24120;&#35265;GNN&#26550;&#26500;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#19968;&#21457;&#29616;&#12290;&#20316;&#20026;&#25105;&#20204;&#29702;&#35770;&#30340;&#23454;&#38469;&#24212;&#29992;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#21517;&#20026;Walk Indexed Sparsification Algorithm (WISA)&#30340;&#36793;&#31232;&#30095;&#21270;&#31639;&#27861;&#65292;&#21033;&#29992;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#25552;&#39640;&#22788;&#29702;&#22823;&#35268;&#27169;&#22270;&#24418;&#30340;GNNs&#25928;&#29575;&#21516;&#26102;&#20445;&#25345;&#23427;&#20204;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph neural networks (GNNs) are widely used for modeling complex interactions between entities represented as vertices of a graph. Despite recent efforts to theoretically analyze the expressive power of GNNs, a formal characterization of their ability to model interactions is lacking. The current paper aims to address this gap. Formalizing strength of interactions through an established measure known as separation rank, we quantify the ability of certain GNNs to model interaction between a given subset of vertices and its complement, i.e. between the sides of a given partition of input vertices. Our results reveal that the ability to model interaction is primarily determined by the partition's walk index -- a graph-theoretical characteristic defined by the number of walks originating from the boundary of the partition. Experiments with common GNN architectures corroborate this finding. As a practical application of our theory, we design an edge sparsification algorithm named Walk Inde
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32479;&#35745;&#26816;&#39564;&#30340; MMD-B-Fair &#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#20844;&#24179;&#30340;&#25968;&#25454;&#34920;&#31034;&#65292;&#24182;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2211.07907</link><description>&lt;p&gt;
&#22522;&#20110;&#32479;&#35745;&#26816;&#39564;&#30340;MMD-B-Fair&#65306;&#23398;&#20064;&#20844;&#24179;&#30340;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
MMD-B-Fair: Learning Fair Representations with Statistical Testing. (arXiv:2211.07907v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.07907
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32479;&#35745;&#26816;&#39564;&#30340; MMD-B-Fair &#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#20844;&#24179;&#30340;&#25968;&#25454;&#34920;&#31034;&#65292;&#24182;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26680;&#21452;&#26679;&#26412;&#27979;&#35797;&#23398;&#20064;&#25968;&#25454;&#20844;&#24179;&#34920;&#31034;&#30340;&#26041;&#27861;MMD-B-Fair&#12290;&#25105;&#20204;&#25214;&#21040;&#20102;&#25968;&#25454;&#30340;&#31070;&#32463;&#29305;&#24449;&#65292;&#20854;&#20013;&#26368;&#22823;&#24179;&#22343;&#20559;&#24046;&#65288;MMD&#65289;&#27979;&#35797;&#26080;&#27861;&#21306;&#20998;&#19981;&#21516;&#25935;&#24863;&#32452;&#30340;&#34920;&#31034;&#65292;&#21516;&#26102;&#20445;&#30041;&#26377;&#20851;&#30446;&#26631;&#23646;&#24615;&#30340;&#20449;&#24687;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#22359;&#27979;&#35797;&#26041;&#26696;&#30340;&#31616;&#21333;&#28176;&#36817;&#24615;&#33021;&#22815;&#26377;&#25928;&#22320;&#25214;&#21040;&#20844;&#24179;&#34920;&#31034;&#65292;&#32780;&#19981;&#38656;&#35201;&#20351;&#29992;&#29616;&#26377;&#20844;&#24179;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#20013;&#24191;&#27867;&#20351;&#29992;&#30340;&#22797;&#26434;&#23545;&#25239;&#24615;&#20248;&#21270;&#25110;&#29983;&#25104;&#24314;&#27169;&#26041;&#26696;&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#26174;&#31034;&#20854;&#33021;&#22815;&#8220;&#38544;&#34255;&#8221;&#26377;&#20851;&#25935;&#24863;&#23646;&#24615;&#30340;&#20449;&#24687;&#65292;&#24182;&#22312;&#19979;&#28216;&#20256;&#36755;&#20219;&#21153;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a method, MMD-B-Fair, to learn fair representations of data via kernel two-sample testing. We find neural features of our data where a maximum mean discrepancy (MMD) test cannot distinguish between representations of different sensitive groups, while preserving information about the target attributes. Minimizing the power of an MMD test is more difficult than maximizing it (as done in previous work), because the test threshold's complex behavior cannot be simply ignored. Our method exploits the simple asymptotics of block testing schemes to efficiently find fair representations without requiring complex adversarial optimization or generative modelling schemes widely used by existing work on fair representation learning. We evaluate our approach on various datasets, showing its ability to ``hide'' information about sensitive attributes, and its effectiveness in downstream transfer tasks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;StaPLR&#31639;&#27861;&#30340;&#26032;&#30340;&#22810;&#35270;&#35282;&#25968;&#25454;&#25554;&#34917;&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#38477;&#32500;&#31354;&#38388;&#20013;&#25191;&#34892;&#25554;&#34917;&#20197;&#35299;&#20915;&#35745;&#31639;&#25361;&#25112;&#65292;&#24182;&#22312;&#27169;&#25311;&#25968;&#25454;&#38598;&#20013;&#24471;&#21040;&#20102;&#31454;&#20105;&#24615;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2210.14484</link><description>&lt;p&gt;
&#22810;&#35270;&#35282;&#25968;&#25454;&#20013;&#32570;&#22833;&#20540;&#30340;&#25554;&#34917;&#38382;&#39064;&#35299;&#20915;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Imputation of missing values in multi-view data. (arXiv:2210.14484v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.14484
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;StaPLR&#31639;&#27861;&#30340;&#26032;&#30340;&#22810;&#35270;&#35282;&#25968;&#25454;&#25554;&#34917;&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#38477;&#32500;&#31354;&#38388;&#20013;&#25191;&#34892;&#25554;&#34917;&#20197;&#35299;&#20915;&#35745;&#31639;&#25361;&#25112;&#65292;&#24182;&#22312;&#27169;&#25311;&#25968;&#25454;&#38598;&#20013;&#24471;&#21040;&#20102;&#31454;&#20105;&#24615;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#35270;&#35282;&#25968;&#25454;&#26159;&#25351;&#30001;&#22810;&#20010;&#19981;&#21516;&#29305;&#24449;&#38598;&#25551;&#36848;&#30340;&#25968;&#25454;&#12290;&#22312;&#22788;&#29702;&#22810;&#35270;&#35282;&#25968;&#25454;&#26102;&#65292;&#33509;&#20986;&#29616;&#32570;&#22833;&#20540;&#65292;&#21017;&#19968;&#20010;&#35270;&#35282;&#20013;&#30340;&#25152;&#26377;&#29305;&#24449;&#26497;&#26377;&#21487;&#33021;&#21516;&#26102;&#32570;&#22833;&#65292;&#22240;&#32780;&#23548;&#33268;&#38750;&#24120;&#22823;&#37327;&#30340;&#32570;&#22833;&#25968;&#25454;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22810;&#35270;&#35282;&#23398;&#20064;&#31639;&#27861;&#20013;&#30340;&#25554;&#34917;&#26041;&#27861;&#65292;&#23427;&#22522;&#20110;&#22534;&#21472;&#24809;&#32602;&#36923;&#36753;&#22238;&#24402;(StaPLR)&#31639;&#27861;&#65292;&#22312;&#38477;&#32500;&#31354;&#38388;&#20013;&#25191;&#34892;&#25554;&#34917;&#65292;&#20197;&#35299;&#20915;&#22266;&#26377;&#30340;&#22810;&#35270;&#35282;&#35745;&#31639;&#25361;&#25112;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#27169;&#25311;&#25968;&#25454;&#38598;&#19978;&#20855;&#26377;&#31454;&#20105;&#24615;&#32467;&#26524;&#65292;&#32780;&#19988;&#20855;&#26377;&#26356;&#20302;&#30340;&#35745;&#31639;&#25104;&#26412;&#65292;&#20174;&#32780;&#21487;&#20197;&#20351;&#29992;&#20808;&#36827;&#30340;&#25554;&#34917;&#31639;&#27861;&#65292;&#20363;&#22914;missForest&#12290;
&lt;/p&gt;
&lt;p&gt;
Data for which a set of objects is described by multiple distinct feature sets (called views) is known as multi-view data. When missing values occur in multi-view data, all features in a view are likely to be missing simultaneously. This leads to very large quantities of missing data which, especially when combined with high-dimensionality, makes the application of conditional imputation methods computationally infeasible. We introduce a new imputation method based on the existing stacked penalized logistic regression (StaPLR) algorithm for multi-view learning. It performs imputation in a dimension-reduced space to address computational challenges inherent to the multi-view context. We compare the performance of the new imputation method with several existing imputation algorithms in simulated data sets. The results show that the new imputation method leads to competitive results at a much lower computational cost, and makes the use of advanced imputation algorithms such as missForest 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#32467;&#21512;&#27969;&#24418;&#23398;&#20064;&#21644;&#39640;&#26031;&#36807;&#31243;&#65292;&#21033;&#29992;&#27969;&#24418;&#26679;&#26412;&#28857;&#20113;&#23450;&#20041;&#22270;&#39640;&#26031;&#36807;&#31243;&#20195;&#29702;&#27169;&#22411;&#65292;&#36890;&#36807;&#36873;&#25321;&#26597;&#35810;&#28857;&#22312;&#27969;&#24418;&#19978;&#20248;&#21270;&#30446;&#26631;&#20989;&#25968;&#65292;&#20855;&#26377;&#33391;&#22909;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2210.10962</link><description>&lt;p&gt;
&#22522;&#20110;&#22270;&#39640;&#26031;&#36807;&#31243;&#30340;&#27969;&#24418;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Optimization on Manifolds via Graph Gaussian Processes. (arXiv:2210.10962v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.10962
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#32467;&#21512;&#27969;&#24418;&#23398;&#20064;&#21644;&#39640;&#26031;&#36807;&#31243;&#65292;&#21033;&#29992;&#27969;&#24418;&#26679;&#26412;&#28857;&#20113;&#23450;&#20041;&#22270;&#39640;&#26031;&#36807;&#31243;&#20195;&#29702;&#27169;&#22411;&#65292;&#36890;&#36807;&#36873;&#25321;&#26597;&#35810;&#28857;&#22312;&#27969;&#24418;&#19978;&#20248;&#21270;&#30446;&#26631;&#20989;&#25968;&#65292;&#20855;&#26377;&#33391;&#22909;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#27969;&#24418;&#23398;&#20064;&#25216;&#26415;&#19982;&#39640;&#26031;&#36807;&#31243;&#19978;&#38480;&#32622;&#20449;&#24230;&#31639;&#27861;&#30456;&#32467;&#21512;&#65292;&#20197;&#20248;&#21270;&#27969;&#24418;&#19978;&#30340;&#30446;&#26631;&#20989;&#25968;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#38024;&#23545;&#22312;&#26080;&#27861;&#33719;&#24471;&#23436;&#25972;&#27969;&#24418;&#34920;&#31034;&#19988;&#26597;&#35810;&#30446;&#26631;&#26114;&#36149;&#30340;&#24212;&#29992;&#22330;&#26223;&#32780;&#35774;&#35745;&#30340;&#12290;&#25105;&#20204;&#20381;&#38752;&#27969;&#24418;&#26679;&#26412;&#28857;&#20113;&#26469;&#23450;&#20041;&#29992;&#20110;&#30446;&#26631;&#20989;&#25968;&#30340;&#22270;&#39640;&#26031;&#36807;&#31243;&#20195;&#29702;&#27169;&#22411;&#12290;&#20351;&#29992;&#20808;&#21069;&#25152;&#26377;&#26597;&#35810;&#30340;&#21518;&#39564;&#20998;&#24067;&#36880;&#27493;&#36873;&#25321;&#26597;&#35810;&#28857;&#12290;&#25105;&#20204;&#22312;&#26597;&#35810;&#27425;&#25968;&#21644;&#28857;&#20113;&#22823;&#23567;&#26041;&#38754;&#24314;&#31435;&#20102;&#36951;&#25022;&#19978;&#38480;&#12290;&#25968;&#20540;&#23454;&#39564;&#34917;&#20805;&#20102;&#29702;&#35770;&#65292;&#24182;&#35828;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper integrates manifold learning techniques within a \emph{Gaussian process upper confidence bound} algorithm to optimize an objective function on a manifold. Our approach is motivated by applications where a full representation of the manifold is not available and querying the objective is expensive. We rely on a point cloud of manifold samples to define a graph Gaussian process surrogate model for the objective. Query points are sequentially chosen using the posterior distribution of the surrogate model given all previous queries. We establish regret bounds in terms of the number of queries and the size of the point cloud. Several numerical examples complement the theory and illustrate the performance of our method.
&lt;/p&gt;</description></item><item><title>&#22312;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#21517;&#20026;&#24207;&#21015;&#20851;&#27880;&#30340;&#29305;&#24449;&#36873;&#25321;&#31639;&#27861;&#65292;&#23427;&#22312;&#27599;&#20010;&#27493;&#39588;&#20351;&#29992;&#27880;&#24847;&#21147;&#26435;&#37325;&#20316;&#20026;&#29305;&#24449;&#37325;&#35201;&#24615;&#30340;&#20195;&#29702;&#65292;&#23454;&#29616;&#20102;&#26368;&#26032;&#30340;&#23454;&#35777;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2209.14881</link><description>&lt;p&gt;
&#29305;&#24449;&#36873;&#25321;&#30340;&#24207;&#21015;&#20851;&#27880;
&lt;/p&gt;
&lt;p&gt;
Sequential Attention for Feature Selection. (arXiv:2209.14881v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.14881
&lt;/p&gt;
&lt;p&gt;
&#22312;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#21517;&#20026;&#24207;&#21015;&#20851;&#27880;&#30340;&#29305;&#24449;&#36873;&#25321;&#31639;&#27861;&#65292;&#23427;&#22312;&#27599;&#20010;&#27493;&#39588;&#20351;&#29992;&#27880;&#24847;&#21147;&#26435;&#37325;&#20316;&#20026;&#29305;&#24449;&#37325;&#35201;&#24615;&#30340;&#20195;&#29702;&#65292;&#23454;&#29616;&#20102;&#26368;&#26032;&#30340;&#23454;&#35777;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29305;&#24449;&#36873;&#25321;&#26159;&#20026;&#20102;&#36873;&#25321;&#19968;&#20010;&#23376;&#38598;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#32780;&#36825;&#20010;&#23376;&#38598;&#33021;&#26368;&#22823;&#21270;&#27169;&#22411;&#36136;&#37327;&#65292;&#24182;&#19988;&#35201;&#27714;&#22312;&#39044;&#31639;&#33539;&#22260;&#20869;&#12290;&#23545;&#20110;&#31070;&#32463;&#32593;&#32476;&#65292;&#37319;&#29992;&#30340;&#20256;&#32479;&#26041;&#27861;&#21253;&#25324;&#22522;&#20110;$\ell_1$&#27491;&#21017;&#21270;&#12289;&#27880;&#24847;&#21147;&#21644;&#20854;&#20182;&#25216;&#26415;&#30340;&#26041;&#27861;&#65292;&#36890;&#24120;&#22312;&#19968;&#27425;&#35780;&#20272;&#20013;&#36873;&#25321;&#25972;&#20010;&#29305;&#24449;&#23376;&#38598;&#65292;&#24573;&#30053;&#20102;&#22312;&#36873;&#25321;&#26399;&#38388;&#29305;&#24449;&#30340;&#27531;&#30041;&#20215;&#20540;&#65292;&#21363;&#22312;&#36873;&#25321;&#20854;&#20182;&#29305;&#24449;&#21518;&#32473;&#19982;&#29305;&#24449;&#30340;&#36793;&#38469;&#36129;&#29486;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#24207;&#21015;&#20851;&#27880;&#30340;&#29305;&#24449;&#36873;&#25321;&#31639;&#27861;&#65292;&#23427;&#22312;&#31070;&#32463;&#32593;&#32476;&#20013;&#23454;&#29616;&#20102;&#26368;&#26032;&#30340;&#23454;&#35777;&#32467;&#26524;&#12290;&#35813;&#31639;&#27861;&#22522;&#20110;&#19968;&#36941;&#39640;&#25928;&#30340;&#36138;&#24515;&#21069;&#21521;&#36873;&#25321;&#23454;&#29616;&#65292;&#24182;&#22312;&#27599;&#20010;&#27493;&#39588;&#20351;&#29992;&#27880;&#24847;&#21147;&#26435;&#37325;&#20316;&#20026;&#29305;&#24449;&#37325;&#35201;&#24615;&#30340;&#20195;&#29702;&#12290;&#25105;&#20204;&#36890;&#36807;&#23637;&#31034;&#36866;&#29992;&#20110;&#32447;&#24615;&#22238;&#24402;&#30340;&#29702;&#35770;&#24847;&#20041;&#65292;&#35828;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#30456;&#24403;&#20110;&#32463;&#20856;&#30340;&#27491;&#20132;&#21305;&#37197;&#36861;&#36394;&#65288;OMP&#65289;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Feature selection is the problem of selecting a subset of features for a machine learning model that maximizes model quality subject to a budget constraint. For neural networks, prior methods, including those based on $\ell_1$ regularization, attention, and other techniques, typically select the entire feature subset in one evaluation round, ignoring the residual value of features during selection, i.e., the marginal contribution of a feature given that other features have already been selected. We propose a feature selection algorithm called Sequential Attention that achieves state-of-the-art empirical results for neural networks. This algorithm is based on an efficient one-pass implementation of greedy forward selection and uses attention weights at each step as a proxy for feature importance. We give theoretical insights into our algorithm for linear regression by showing that an adaptation to this setting is equivalent to the classical Orthogonal Matching Pursuit (OMP) algorithm, a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38750;&#32447;&#24615;&#38477;&#32500;&#26041;&#27861;&#65292;&#29992;&#20110;&#21516;&#26102;&#22788;&#29702;&#39044;&#27979;&#21464;&#37327;&#21644;&#21709;&#24212;&#21464;&#37327;&#22343;&#20026;&#20998;&#24067;&#25968;&#25454;&#30340;&#24773;&#24418;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992;&#36890;&#29992;&#26680;&#24314;&#31435;&#39044;&#27979;&#21464;&#37327;&#21644;&#21709;&#24212;&#21464;&#37327;&#30340;&#22797;&#29616;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20197;&#25551;&#36848;&#26465;&#20214;&#29420;&#31435;&#24615;&#65292;&#23545;&#20110;&#21333;&#21464;&#37327;&#20998;&#24067;&#21644;&#22810;&#20803;&#20998;&#24067;&#20998;&#21035;&#37319;&#29992;Wasserstein&#36317;&#31163;&#21644;&#20998;&#29255;Wasserstein&#36317;&#31163;&#26500;&#24314;&#36890;&#29992;&#26680;&#65292;&#32463;&#21512;&#25104;&#25968;&#25454;&#27979;&#35797;&#34920;&#29616;&#20248;&#20110;&#31454;&#20105;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2207.04613</link><description>&lt;p&gt;
&#20998;&#24067;&#22238;&#24402;&#30340;&#38750;&#32447;&#24615;&#20805;&#20998;&#38477;&#32500;
&lt;/p&gt;
&lt;p&gt;
Nonlinear Sufficient Dimension Reduction for Distribution-on-Distribution Regression. (arXiv:2207.04613v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.04613
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38750;&#32447;&#24615;&#38477;&#32500;&#26041;&#27861;&#65292;&#29992;&#20110;&#21516;&#26102;&#22788;&#29702;&#39044;&#27979;&#21464;&#37327;&#21644;&#21709;&#24212;&#21464;&#37327;&#22343;&#20026;&#20998;&#24067;&#25968;&#25454;&#30340;&#24773;&#24418;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992;&#36890;&#29992;&#26680;&#24314;&#31435;&#39044;&#27979;&#21464;&#37327;&#21644;&#21709;&#24212;&#21464;&#37327;&#30340;&#22797;&#29616;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20197;&#25551;&#36848;&#26465;&#20214;&#29420;&#31435;&#24615;&#65292;&#23545;&#20110;&#21333;&#21464;&#37327;&#20998;&#24067;&#21644;&#22810;&#20803;&#20998;&#24067;&#20998;&#21035;&#37319;&#29992;Wasserstein&#36317;&#31163;&#21644;&#20998;&#29255;Wasserstein&#36317;&#31163;&#26500;&#24314;&#36890;&#29992;&#26680;&#65292;&#32463;&#21512;&#25104;&#25968;&#25454;&#27979;&#35797;&#34920;&#29616;&#20248;&#20110;&#31454;&#20105;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38750;&#32447;&#24615;&#20805;&#20998;&#38477;&#32500;&#26041;&#27861;&#65292;&#29992;&#20110;&#21516;&#26102;&#22788;&#29702;&#39044;&#27979;&#21464;&#37327;&#21644;&#21709;&#24212;&#21464;&#37327;&#22343;&#20026;&#20998;&#24067;&#25968;&#25454;&#30340;&#24773;&#24418;&#65292;&#36825;&#20004;&#31181;&#25968;&#25454;&#37117;&#34987;&#24314;&#27169;&#20026;&#24230;&#37327;&#31354;&#38388;&#20013;&#30340;&#25104;&#21592;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#27493;&#39588;&#26159;&#22312;&#24230;&#37327;&#31354;&#38388;&#19978;&#26500;&#24314;&#36890;&#29992;&#26680;&#65292;&#20197;&#24314;&#31435;&#21487;&#20197;&#25551;&#36848;&#20915;&#23450;&#20805;&#20998;&#38477;&#32500;&#30340;&#26465;&#20214;&#29420;&#31435;&#24615;&#30340;&#39044;&#27979;&#21464;&#37327;&#21644;&#21709;&#24212;&#21464;&#37327;&#30340;&#22797;&#29616;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#12290;&#23545;&#20110;&#21333;&#21464;&#37327;&#20998;&#24067;&#65292;&#25105;&#20204;&#20351;&#29992;Wasserstein&#36317;&#31163;&#26500;&#24314;&#36890;&#29992;&#26680;&#65292;&#32780;&#23545;&#20110;&#22810;&#20803;&#20998;&#24067;&#65292;&#25105;&#20204;&#21017;&#37319;&#29992;&#20998;&#29255;Wasserstein&#36317;&#31163;&#12290;&#20998;&#29255;Wasserstein&#36317;&#31163;&#30830;&#20445;&#24230;&#37327;&#31354;&#38388;&#20855;&#26377;&#19982;Wasserstein&#31354;&#38388;&#30456;&#20284;&#30340;&#25299;&#25169;&#29305;&#24615;&#65292;&#21516;&#26102;&#36824;&#25552;&#20379;&#20102;&#26174;&#33879;&#30340;&#35745;&#31639;&#20248;&#21183;&#12290;&#22522;&#20110;&#21512;&#25104;&#25968;&#25454;&#30340;&#25968;&#20540;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#21487;&#33021;&#30340;&#31454;&#20105;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#20063;&#34987;&#24212;&#29992;&#20110;&#22810;&#20010;&#25968;&#25454;&#38598;&#65292;&#21253;&#25324;&#29983;&#32946;&#25968;&#25454;&#21644;...
&lt;/p&gt;
&lt;p&gt;
We introduce a new approach to nonlinear sufficient dimension reduction in cases where both the predictor and the response are distributional data, modeled as members of a metric space. Our key step is to build universal kernels (cc-universal) on the metric spaces, which results in reproducing kernel Hilbert spaces for the predictor and response that are rich enough to characterize the conditional independence that determines sufficient dimension reduction. For univariate distributions, we construct the universal kernel using the Wasserstein distance, while for multivariate distributions, we resort to the sliced Wasserstein distance. The sliced Wasserstein distance ensures that the metric space possesses similar topological properties to the Wasserstein space while also offering significant computation benefits. Numerical results based on synthetic data show that our method outperforms possible competing methods. The method is also applied to several data sets, including fertility and 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;DIMPLE&#32593;&#32476;&#27169;&#22411;&#20013;&#30340;&#31232;&#30095;&#23376;&#31354;&#38388;&#32858;&#31867;&#65292;&#36890;&#36807;&#35782;&#21035;&#20855;&#26377;&#30456;&#21516;&#31038;&#21306;&#32467;&#26500;&#30340;&#23618;&#32452;&#65292;&#25214;&#21040;&#20102;&#19968;&#31181;&#24378;&#19968;&#33268;&#24615;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2206.07602</link><description>&lt;p&gt;
&#22810;&#26679;&#22810;&#23618;&#32593;&#32476;&#27169;&#22411;&#20013;&#30340;&#31232;&#30095;&#23376;&#31354;&#38388;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Sparse Subspace Clustering in Diverse Multiplex Network Model. (arXiv:2206.07602v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.07602
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;DIMPLE&#32593;&#32476;&#27169;&#22411;&#20013;&#30340;&#31232;&#30095;&#23376;&#31354;&#38388;&#32858;&#31867;&#65292;&#36890;&#36807;&#35782;&#21035;&#20855;&#26377;&#30456;&#21516;&#31038;&#21306;&#32467;&#26500;&#30340;&#23618;&#32452;&#65292;&#25214;&#21040;&#20102;&#19968;&#31181;&#24378;&#19968;&#33268;&#24615;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;Pensky&#21644;Wang&#65288;2021&#65289;&#24341;&#20837;&#30340;DIverse MultiPLEx&#65288;DIMPLE&#65289;&#32593;&#32476;&#27169;&#22411;&#65292;&#20854;&#20013;&#32593;&#32476;&#30340;&#25152;&#26377;&#23618;&#37117;&#20855;&#26377;&#30456;&#21516;&#30340;&#33410;&#28857;&#38598;&#21512;&#65292;&#24182;&#37197;&#22791;&#26377;&#38543;&#26426;&#22359;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#25152;&#26377;&#23618;&#37117;&#21487;&#20197;&#20998;&#20026;&#20855;&#26377;&#30456;&#21516;&#31038;&#21306;&#32467;&#26500;&#30340;&#32452;&#65292;&#23613;&#31649;&#22312;&#21516;&#19968;&#32452;&#20013;&#30340;&#23618;&#21487;&#33021;&#20855;&#26377;&#19981;&#21516;&#30340;&#22359;&#36830;&#25509;&#27010;&#29575;&#30697;&#38453;&#12290;DIMPLE&#27169;&#22411;&#27010;&#25324;&#20102;&#35768;&#22810;&#30740;&#31350;&#25152;&#26377;&#23618;&#20855;&#26377;&#30456;&#21516;&#31038;&#21306;&#32467;&#26500;&#30340;&#22810;&#23618;&#32593;&#32476;&#30340;&#35770;&#25991;&#65292;&#20197;&#21450;&#28151;&#21512;&#22810;&#23618;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;MMLSBM&#65289;&#65292;&#22312;&#20854;&#20013;&#21516;&#19968;&#32452;&#20013;&#30340;&#23618;&#20855;&#26377;&#30456;&#21516;&#30340;&#22359;&#36830;&#25509;&#27010;&#29575;&#30697;&#38453;&#12290;&#26412;&#25991;&#20351;&#29992;&#31232;&#30095;&#23376;&#31354;&#38388;&#32858;&#31867;&#65288;SSC&#65289;&#26469;&#35782;&#21035;&#20855;&#26377;&#30456;&#21516;&#31038;&#21306;&#32467;&#26500;&#30340;&#23618;&#32452;&#12290;&#22312;&#28201;&#21644;&#30340;&#26465;&#20214;&#19979;&#65292;&#21518;&#32773;&#23548;&#33268;&#20102;&#24378;&#19968;&#33268;&#24615;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
The paper considers the DIverse MultiPLEx (DIMPLE) network model, introduced in Pensky and Wang (2021), where all layers of the network have the same collection of nodes and are equipped with the Stochastic Block Models. In addition, all layers can be partitioned into groups with the same community structures, although the layers in the same group may have different matrices of block connection probabilities. The DIMPLE model generalizes a multitude of papers that study multilayer networks with the same community structures in all layers, as well as the Mixture Multilayer Stochastic Block Model (MMLSBM), where the layers in the same group have identical matrices of block connection probabilities. While Pensky and Wang (2021) applied spectral clustering to the proxy of the adjacency tensor, the present paper uses Sparse Subspace Clustering (SSC) for identifying groups of layers with identical community structures. Under mild conditions, the latter leads to the strongly consistent betwee
&lt;/p&gt;</description></item><item><title>TAD&#26159;&#19968;&#31181;&#26032;&#30340;&#30446;&#26631;&#33258;&#36866;&#24212;&#35774;&#35745;&#31639;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#39640;&#26031;&#36807;&#31243;&#20195;&#29702;&#27169;&#22411;&#22312;&#25351;&#23450;&#20844;&#24046;&#20013;&#30830;&#23450;&#20135;&#29983;&#26399;&#26395;&#35774;&#35745;&#29305;&#24449;&#30340;&#26368;&#20339;&#25511;&#21046;&#35774;&#32622;&#65292;&#30456;&#27604;&#20854;&#20182;&#33258;&#36866;&#24212;&#35774;&#35745;&#31639;&#27861;&#65292;&#20855;&#26377;&#26356;&#39640;&#30340;&#31934;&#24230;&#21644;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2205.14208</link><description>&lt;p&gt;
&#30446;&#26631;&#33258;&#36866;&#24212;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Targeted Adaptive Design. (arXiv:2205.14208v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.14208
&lt;/p&gt;
&lt;p&gt;
TAD&#26159;&#19968;&#31181;&#26032;&#30340;&#30446;&#26631;&#33258;&#36866;&#24212;&#35774;&#35745;&#31639;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#39640;&#26031;&#36807;&#31243;&#20195;&#29702;&#27169;&#22411;&#22312;&#25351;&#23450;&#20844;&#24046;&#20013;&#30830;&#23450;&#20135;&#29983;&#26399;&#26395;&#35774;&#35745;&#29305;&#24449;&#30340;&#26368;&#20339;&#25511;&#21046;&#35774;&#32622;&#65292;&#30456;&#27604;&#20854;&#20182;&#33258;&#36866;&#24212;&#35774;&#35745;&#31639;&#27861;&#65292;&#20855;&#26377;&#26356;&#39640;&#30340;&#31934;&#24230;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#20808;&#36827;&#21046;&#36896;&#21644;&#39640;&#32423;&#26448;&#26009;&#35774;&#35745;&#24448;&#24448;&#38656;&#35201;&#22312;&#36739;&#39640;&#32500;&#24230;&#30340;&#36807;&#31243;&#25511;&#21046;&#21442;&#25968;&#31354;&#38388;&#20013;&#25628;&#32034;&#26368;&#20339;&#32467;&#26500;&#12289;&#24615;&#33021;&#21644;&#24615;&#33021;&#21442;&#25968;&#30340;&#35774;&#32622;&#12290;&#20174;&#21069;&#32773;&#21040;&#21518;&#32773;&#30340;&#26144;&#23556;&#24517;&#39035;&#36890;&#36807;&#22024;&#26434;&#30340;&#23454;&#39564;&#25110;&#26114;&#36149;&#30340;&#27169;&#25311;&#26469;&#30830;&#23450;&#12290;&#25105;&#20204;&#25226;&#36825;&#20010;&#38382;&#39064;&#25277;&#35937;&#25104;&#19968;&#20010;&#25968;&#23398;&#26694;&#26550;&#65292;&#20854;&#20013;&#24517;&#39035;&#36890;&#36807;&#26114;&#36149;&#30340;&#22024;&#26434;&#27979;&#37327;&#26469;&#30830;&#23450;&#20174;&#25511;&#21046;&#31354;&#38388;&#21040;&#35774;&#35745;&#31354;&#38388;&#30340;&#26410;&#30693;&#20989;&#25968;&#65292;&#35813;&#20989;&#25968;&#22312;&#25351;&#23450;&#30340;&#20844;&#24046;&#33539;&#22260;&#20869;&#23450;&#20301;&#20135;&#29983;&#26399;&#26395;&#35774;&#35745;&#29305;&#24449;&#30340;&#26368;&#20339;&#25511;&#21046;&#35774;&#32622;&#65292;&#24182;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;&#30446;&#26631;&#33258;&#36866;&#24212;&#35774;&#35745; (TAD)&#65292;&#36825;&#26159;&#19968;&#31181;&#26377;&#25928;&#25191;&#34892;&#36825;&#20010;&#37319;&#26679;&#20219;&#21153;&#30340;&#26032;&#31639;&#27861;&#12290;TAD &#22312;&#27599;&#20010;&#36845;&#20195;&#38454;&#27573;&#21019;&#24314;&#19968;&#20010;&#26410;&#30693;&#26144;&#23556;&#30340;&#39640;&#26031;&#36807;&#31243;&#20195;&#29702;&#27169;&#22411;&#65292;&#24314;&#35758;&#19968;&#25209;&#26032;&#30340;&#25511;&#21046;&#35774;&#32622;&#36827;&#34892;&#23454;&#39564;&#37319;&#26679;&#65292;&#24182;&#20248;&#21270;&#26356;&#26032;&#30340;&#30446;&#26631;&#35774;&#35745;&#29305;&#24449;&#30340;&#23545;&#25968;&#39044;&#27979;&#20284;&#28982;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern advanced manufacturing and advanced materials design often require searches of relatively high-dimensional process control parameter spaces for settings that result in optimal structure, property, and performance parameters. The mapping from the former to the latter must be determined from noisy experiments or from expensive simulations. We abstract this problem to a mathematical framework in which an unknown function from a control space to a design space must be ascertained by means of expensive noisy measurements, which locate optimal control settings generating desired design features within specified tolerances, with quantified uncertainty. We describe targeted adaptive design (TAD), a new algorithm that performs this sampling task efficiently. TAD creates a Gaussian process surrogate model of the unknown mapping at each iterative stage, proposing a new batch of control settings to sample experimentally and optimizing the updated log-predictive likelihood of the target desi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25351;&#20986;&#20102;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#20013;&#65292;&#20351;&#29992;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#20272;&#35745;&#38271;&#24230;&#23610;&#24230;&#21442;&#25968;&#30340;&#24179;&#31283;&#21327;&#26041;&#24046;&#20989;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#22312;&#26080;&#22122;&#22768;&#25968;&#25454;&#24773;&#20917;&#19979;&#20250;&#23384;&#22312;&#19981;&#36866;&#23450;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2203.09179</link><description>&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#20013;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#23384;&#22312;&#19981;&#36866;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
Maximum Likelihood Estimation in Gaussian Process Regression is Ill-Posed. (arXiv:2203.09179v3 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.09179
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25351;&#20986;&#20102;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#20013;&#65292;&#20351;&#29992;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#20272;&#35745;&#38271;&#24230;&#23610;&#24230;&#21442;&#25968;&#30340;&#24179;&#31283;&#21327;&#26041;&#24046;&#20989;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#22312;&#26080;&#22122;&#22768;&#25968;&#25454;&#24773;&#20917;&#19979;&#20250;&#23384;&#22312;&#19981;&#36866;&#23450;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#26159;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#23398;&#20013;&#26080;&#25968;&#23398;&#26415;&#21644;&#24037;&#19994;&#24212;&#29992;&#30340;&#22522;&#30784;&#65292;&#20854;&#20013;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#36890;&#24120;&#29992;&#20110;&#36873;&#25321;&#36866;&#24403;&#30340;&#21327;&#26041;&#24046;&#26680;&#21442;&#25968;&#12290;&#28982;&#32780;&#65292;&#30830;&#23450;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#20026;&#36866;&#23450;&#38382;&#39064;&#30340;&#24773;&#20917;&#23578;&#26410;&#35299;&#20915;&#65292;&#21363;&#65292;&#22312;&#22238;&#24402;&#27169;&#22411;&#30340;&#39044;&#27979;&#23545;&#25968;&#25454;&#30340;&#24494;&#23567;&#25200;&#21160;&#19981;&#25935;&#24863;&#30340;&#24773;&#20917;&#19979;&#12290;&#26412;&#25991;&#30830;&#23450;&#20102;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#26080;&#27861;&#36866;&#23450;&#30340;&#24773;&#20917;&#65292;&#21363;&#22312;Hellinger&#36317;&#31163;&#24847;&#20041;&#19979;&#65292;&#39044;&#27979;&#20998;&#24067;&#23545;&#25968;&#25454;&#19981;&#20855;&#26377;Lipschitz&#36830;&#32493;&#24615;&#12290;&#36825;&#20123;&#22833;&#36133;&#24773;&#20917;&#21457;&#29983;&#22312;&#26080;&#22122;&#22768;&#25968;&#25454;&#24773;&#20917;&#19979;&#65292;&#23545;&#20110;&#20219;&#20309;&#20351;&#29992;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#20272;&#35745;&#38271;&#24230;&#23610;&#24230;&#21442;&#25968;&#30340;&#24179;&#31283;&#21327;&#26041;&#24046;&#20989;&#25968;&#30340;&#39640;&#26031;&#36807;&#31243;&#12290;&#34429;&#28982;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#22833;&#36133;&#26159;&#39640;&#26031;&#36807;&#31243;&#30340;&#24120;&#35782;&#65292;&#20294;&#36825;&#20123;&#20005;&#26684;&#30340;&#29702;&#35770;&#32467;&#26524;&#20284;&#20046;&#26159;&#31532;&#19968;&#27425;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian process regression underpins countless academic and industrial applications of machine learning and statistics, with maximum likelihood estimation routinely used to select appropriate parameters for the covariance kernel. However, it remains an open problem to establish the circumstances in which maximum likelihood estimation is well-posed, that is, when the predictions of the regression model are insensitive to small perturbations of the data. This article identifies scenarios where the maximum likelihood estimator fails to be well-posed, in that the predictive distributions are not Lipschitz in the data with respect to the Hellinger distance. These failure cases occur in the noiseless data setting, for any Gaussian process with a stationary covariance function whose lengthscale parameter is estimated using maximum likelihood. Although the failure of maximum likelihood estimation is part of Gaussian process folklore, these rigorous theoretical results appear to be the first o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;APEx&#8221;&#30340;&#25216;&#33021;&#21457;&#29616;&#21644;&#36716;&#31227;&#31639;&#27861;&#65292;&#23427;&#20197;&#19968;&#31181;&#21407;&#21017;&#24615;&#21644;&#23398;&#20064;&#30340;&#26041;&#24335;&#21033;&#29992;&#20449;&#24687;&#19981;&#23545;&#31216;&#24615;&#65292;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#37319;&#26679;&#25928;&#29575;&#12289;&#20219;&#21153;&#21487;&#36716;&#31227;&#24615;&#21644;&#27010;&#25324;&#33021;&#21147;&#65292;&#21516;&#26102;&#20445;&#30041;&#20102;&#38750;&#20998;&#23618;&#26041;&#27861;&#30340;&#34920;&#36798;&#33021;&#21147;&#21644;&#28789;&#27963;&#24615;&#12290;</title><link>http://arxiv.org/abs/2201.08115</link><description>&lt;p&gt;
&#20808;&#39564;&#12289;&#23618;&#27425;&#21644;&#20449;&#24687;&#19981;&#23545;&#31216;&#22312;&#24378;&#21270;&#23398;&#20064;&#25216;&#33021;&#36716;&#31227;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Priors, Hierarchy, and Information Asymmetry for Skill Transfer in Reinforcement Learning. (arXiv:2201.08115v2 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.08115
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;APEx&#8221;&#30340;&#25216;&#33021;&#21457;&#29616;&#21644;&#36716;&#31227;&#31639;&#27861;&#65292;&#23427;&#20197;&#19968;&#31181;&#21407;&#21017;&#24615;&#21644;&#23398;&#20064;&#30340;&#26041;&#24335;&#21033;&#29992;&#20449;&#24687;&#19981;&#23545;&#31216;&#24615;&#65292;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#37319;&#26679;&#25928;&#29575;&#12289;&#20219;&#21153;&#21487;&#36716;&#31227;&#24615;&#21644;&#27010;&#25324;&#33021;&#21147;&#65292;&#21516;&#26102;&#20445;&#30041;&#20102;&#38750;&#20998;&#23618;&#26041;&#27861;&#30340;&#34920;&#36798;&#33021;&#21147;&#21644;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#36807;&#21435;&#30340;&#32463;&#39564;&#20013;&#21457;&#29616;&#34892;&#20026;&#65292;&#24182;&#23558;&#20854;&#36716;&#31227;&#21040;&#26032;&#20219;&#21153;&#20013;&#30340;&#33021;&#21147;&#26159;&#26234;&#33021;&#20195;&#29702;&#22312;&#30495;&#23454;&#19990;&#30028;&#20013;&#39640;&#25928;&#37319;&#26679;&#30340;&#26631;&#24535;&#12290;&#20026;&#26234;&#33021;&#24378;&#21270;&#23398;&#20064;&#32773;&#35013;&#22791;&#30456;&#21516;&#30340;&#33021;&#21147;&#21487;&#33021;&#23545;&#23427;&#20204;&#22312;&#26426;&#22120;&#20154;&#25216;&#26415;&#19978;&#30340;&#25104;&#21151;&#37096;&#32626;&#33267;&#20851;&#37325;&#35201;&#12290;&#34429;&#28982;&#20998;&#23618;&#21644;KL-&#27491;&#21017;&#21270;&#24378;&#21270;&#23398;&#20064;&#21508;&#33258;&#22312;&#36825;&#26041;&#38754;&#24456;&#26377;&#24076;&#26395;&#65292;&#20294;&#28151;&#21512;&#26041;&#27861;&#21487;&#33021;&#32467;&#21512;&#23427;&#20204;&#21508;&#33258;&#30340;&#20248;&#28857;&#12290;&#36825;&#20123;&#39046;&#22495;&#30340;&#20851;&#38190;&#22312;&#20110;&#21033;&#29992;&#26550;&#26500;&#27169;&#22359;&#20043;&#38388;&#30340;&#20449;&#24687;&#19981;&#23545;&#31216;&#24615;&#26469;&#20559;&#25191;&#23398;&#20064;&#30340;&#25216;&#33021;&#12290;&#34429;&#28982;&#19981;&#23545;&#31216;&#24615;&#36873;&#25321;&#23545;&#21487;&#36716;&#31227;&#24615;&#26377;&#24456;&#22823;&#24433;&#21709;&#65292;&#20294;&#29616;&#26377;&#26041;&#27861;&#20027;&#35201;&#22522;&#20110;&#30452;&#35273;&#65292;&#20197;&#19968;&#20010;&#19982;&#39046;&#22495;&#26080;&#20851;&#30340;&#21487;&#33021;&#27425;&#20248;&#30340;&#26041;&#24335;&#36827;&#34892;&#36873;&#25321;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20174;&#29702;&#35770;&#21644;&#32463;&#39564;&#19978;&#23637;&#31034;&#20102;&#24207;&#21015;&#20219;&#21153;&#20013;&#25216;&#33021;&#30340;&#20851;&#38190;&#34920;&#36798;&#33021;&#21147;-&#21487;&#36716;&#31227;&#24615;&#30340;&#24179;&#34913;&#65292;&#30001;&#20449;&#24687;&#19981;&#23545;&#31216;&#24615;&#25511;&#21046;&#12290;&#22312;&#33719;&#24471;&#36825;&#19968;&#27934;&#35265;&#21518;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;APEx&#8221;&#30340;&#25216;&#33021;&#21457;&#29616;&#21644;&#36716;&#31227;&#31639;&#27861;&#65292;&#23427;&#20197;&#19968;&#31181;&#21407;&#21017;&#24615;&#21644;&#23398;&#20064;&#30340;&#26041;&#24335;&#21033;&#29992;&#20449;&#24687;&#19981;&#23545;&#31216;&#24615;&#12290;APEx&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#37319;&#26679;&#25928;&#29575;&#12289;&#20219;&#21153;&#21487;&#36716;&#31227;&#24615;&#21644;&#27010;&#25324;&#33021;&#21147;&#65292;&#21516;&#26102;&#20445;&#30041;&#20102;&#38750;&#20998;&#23618;&#26041;&#27861;&#30340;&#34920;&#36798;&#33021;&#21147;&#21644;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The ability to discover behaviours from past experience and transfer them to new tasks is a hallmark of intelligent agents acting sample-efficiently in the real world. Equipping embodied reinforcement learners with the same ability may be crucial for their successful deployment in robotics. While hierarchical and KL-regularized reinforcement learning individually hold promise here, arguably a hybrid approach could combine their respective benefits. Key to these fields is the use of information asymmetry across architectural modules to bias which skills are learnt. While asymmetry choice has a large influence on transferability, existing methods base their choice primarily on intuition in a domain-independent, potentially sub-optimal, manner. In this paper, we theoretically and empirically show the crucial expressivity-transferability trade-off of skills across sequential tasks, controlled by information asymmetry. Given this insight, we introduce Attentive Priors for Expressive and Tra
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#26435;&#22810;&#35270;&#22270; NMF&#31639;&#27861;&#65292;&#26088;&#22312;&#23398;&#20064;&#35270;&#22270;&#29305;&#23450;&#26435;&#37325;&#21644;&#35266;&#27979;&#29305;&#23450;&#37325;&#26500;&#26435;&#37325;&#65292;&#20197;&#37327;&#21270;&#27599;&#20010;&#35270;&#22270;&#30340;&#20449;&#24687;&#20869;&#23481;&#65292;&#36890;&#36807;&#20998;&#37197;&#36739;&#23567;&#21644;&#36739;&#22823;&#30340;&#26435;&#37325;&#26469;&#25193;&#22823;&#37325;&#35201;&#35270;&#22270;&#30340;&#27491;&#38754;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2110.13240</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#21152;&#26435;&#22810;&#35270;&#22270;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Adaptive Weighted Multi-View Clustering. (arXiv:2110.13240v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.13240
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#26435;&#22810;&#35270;&#22270; NMF&#31639;&#27861;&#65292;&#26088;&#22312;&#23398;&#20064;&#35270;&#22270;&#29305;&#23450;&#26435;&#37325;&#21644;&#35266;&#27979;&#29305;&#23450;&#37325;&#26500;&#26435;&#37325;&#65292;&#20197;&#37327;&#21270;&#27599;&#20010;&#35270;&#22270;&#30340;&#20449;&#24687;&#20869;&#23481;&#65292;&#36890;&#36807;&#20998;&#37197;&#36739;&#23567;&#21644;&#36739;&#22823;&#30340;&#26435;&#37325;&#26469;&#25193;&#22823;&#37325;&#35201;&#35270;&#22270;&#30340;&#27491;&#38754;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#22810;&#35270;&#22270;&#25968;&#25454;&#26159;&#26426;&#22120;&#23398;&#20064;&#30740;&#31350;&#20013;&#19968;&#20010;&#26032;&#20852;&#30340;&#38382;&#39064;&#65292;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#65288;NMF&#65289;&#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#38477;&#32500;&#26041;&#27861;&#65292;&#29992;&#20110;&#25972;&#21512;&#26469;&#33258;&#22810;&#20010;&#35270;&#22270;&#30340;&#20449;&#24687;&#12290;&#36825;&#20123;&#35270;&#22270;&#36890;&#24120;&#19981;&#20165;&#25552;&#20379;&#19968;&#33268;&#24615;&#20449;&#24687;&#65292;&#36824;&#25552;&#20379;&#20114;&#34917;&#20449;&#24687;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#22810;&#35270;&#22270;NMF&#31639;&#27861;&#23558;&#27599;&#20010;&#35270;&#22270;&#36171;&#20104;&#30456;&#21516;&#30340;&#26435;&#37325;&#65292;&#25110;&#32773;&#36890;&#36807;&#32463;&#39564;&#24615;&#30340;&#32447;&#24615;&#25628;&#32034;&#35843;&#25972;&#26435;&#37325;&#65292;&#36825;&#22312;&#27809;&#26377;&#35270;&#22270;&#30340;&#20219;&#20309;&#20808;&#39564;&#30693;&#35782;&#25110;&#35745;&#31639;&#19978;&#26159;&#19981;&#21487;&#34892;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#26435;&#22810;&#35270;&#22270;NMF&#65288;WM-NMF&#65289;&#31639;&#27861;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#26088;&#22312;&#35299;&#20915;&#20851;&#38190;&#25216;&#26415;&#24046;&#36317;&#65292;&#21363;&#23398;&#20064;&#35270;&#22270;&#29305;&#23450;&#26435;&#37325;&#21644;&#35266;&#27979;&#29305;&#23450;&#37325;&#26500;&#26435;&#37325;&#65292;&#20197;&#37327;&#21270;&#27599;&#20010;&#35270;&#22270;&#30340;&#20449;&#24687;&#20869;&#23481;&#12290;&#24341;&#20837;&#30340;&#21152;&#26435;&#26041;&#26696;&#21487;&#20197;&#36890;&#36807;&#20998;&#37197;&#36739;&#23567;&#21644;&#36739;&#22823;&#30340;&#26435;&#37325;&#26469;&#20943;&#36731;&#19981;&#24517;&#35201;&#35270;&#22270;&#30340;&#36127;&#38754;&#24433;&#21709;&#24182;&#25193;&#22823;&#37325;&#35201;&#35270;&#22270;&#30340;&#27491;&#38754;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning multi-view data is an emerging problem in machine learning research, and nonnegative matrix factorization (NMF) is a popular dimensionality-reduction method for integrating information from multiple views. These views often provide not only consensus but also complementary information. However, most multi-view NMF algorithms assign equal weight to each view or tune the weight via line search empirically, which can be infeasible without any prior knowledge of the views or computationally expensive. In this paper, we propose a weighted multi-view NMF (WM-NMF) algorithm. In particular, we aim to address the critical technical gap, which is to learn both view-specific weight and observation-specific reconstruction weight to quantify each view's information content. The introduced weighting scheme can alleviate unnecessary views' adverse effects and enlarge the positive effects of the important views by assigning smaller and larger weights, respectively. Experimental results confir
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;&#22312;&#20915;&#31574;&#30456;&#20851;&#20998;&#24067;&#23398;&#20064;&#20013;&#30340;&#39118;&#38505;&#26368;&#23567;&#21270;&#65292;&#24314;&#31435;&#22312;&#25191;&#34892;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#26799;&#24230;&#27969;&#30340;&#25200;&#21160;&#36712;&#36857;&#20043;&#19978;&#65292;&#30740;&#31350;&#20102;&#21487;&#33021;&#23384;&#22312;&#22810;&#20010;&#23616;&#37096;&#26368;&#23567;&#21270;&#22120;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2107.00055</link><description>&lt;p&gt;
&#24102;&#26377;&#20915;&#31574;&#30456;&#20851;&#20998;&#24067;&#30340;&#23398;&#20064;&#20013;&#30340;&#36817;&#20284;&#21560;&#24341;&#23376;&#21306;&#22495;
&lt;/p&gt;
&lt;p&gt;
Approximate Regions of Attraction in Learning with Decision-Dependent Distributions. (arXiv:2107.00055v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2107.00055
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#22312;&#20915;&#31574;&#30456;&#20851;&#20998;&#24067;&#23398;&#20064;&#20013;&#30340;&#39118;&#38505;&#26368;&#23567;&#21270;&#65292;&#24314;&#31435;&#22312;&#25191;&#34892;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#26799;&#24230;&#27969;&#30340;&#25200;&#21160;&#36712;&#36857;&#20043;&#19978;&#65292;&#30740;&#31350;&#20102;&#21487;&#33021;&#23384;&#22312;&#22810;&#20010;&#23616;&#37096;&#26368;&#23567;&#21270;&#22120;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#27861;&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#24212;&#29992;&#65292;&#29983;&#25104;&#35266;&#23519;&#25968;&#25454;&#30340;&#36807;&#31243;&#24448;&#24448;&#20250;&#26681;&#25454;&#23398;&#20064;&#32773;&#30340;&#20915;&#31574;&#20570;&#20986;&#21453;&#24212;&#12290;&#20363;&#22914;&#65292;&#25968;&#25454;&#28304;&#21487;&#33021;&#26377;&#19968;&#20123;&#28608;&#21169;&#35753;&#31639;&#27861;&#25552;&#20379;&#29305;&#23450;&#30340;&#26631;&#31614;&#65288;&#22914;&#25209;&#20934;&#38134;&#34892;&#36151;&#27454;&#65289;&#65292;&#24182;&#30456;&#24212;&#22320;&#25805;&#32437;&#23427;&#20204;&#30340;&#29305;&#24449;&#12290;&#22312;&#25112;&#30053;&#20998;&#31867;&#21644;&#20915;&#31574;&#30456;&#20851;&#20998;&#24067;&#30340;&#24037;&#20316;&#20013;&#65292;&#36890;&#36807;&#26126;&#30830;&#32771;&#34385;&#20998;&#31867;&#22120;&#23545;&#22522;&#30784;&#25968;&#25454;&#20998;&#24067;&#30340;&#24433;&#21709;&#26469;&#34920;&#24449;&#37096;&#32626;&#23398;&#20064;&#31639;&#27861;&#30340;&#38381;&#29615;&#34892;&#20026;&#12290;&#26368;&#36817;&#65292;&#22312;&#25191;&#34892;&#39044;&#27979;&#30340;&#30740;&#31350;&#20013;&#65292;&#32771;&#34385;&#20998;&#31867;&#22120;&#21040;&#25968;&#25454;&#20998;&#24067;&#30340;&#26144;&#23556;&#30340;&#19968;&#33324;&#23646;&#24615;&#65292;&#32780;&#38750;&#26174;&#24335;&#24418;&#24335;&#26469;&#20998;&#31867;&#38381;&#29615;&#34892;&#20026;&#12290;&#22522;&#20110;&#36825;&#20010;&#27010;&#24565;&#65292;&#25105;&#20204;&#23558;&#37325;&#22797;&#30340;&#39118;&#38505;&#26368;&#23567;&#21270;&#20998;&#26512;&#20026;&#25191;&#34892;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#26799;&#24230;&#27969;&#30340;&#25200;&#21160;&#36712;&#36857;&#12290;&#25105;&#20204;&#32771;&#34385;&#21487;&#33021;&#23384;&#22312;&#22810;&#20010;&#23616;&#37096;&#26368;&#23567;&#21270;&#22120;&#30340;&#22330;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
As data-driven methods are deployed in real-world settings, the processes that generate the observed data will often react to the decisions of the learner. For example, a data source may have some incentive for the algorithm to provide a particular label (e.g. approve a bank loan), and manipulate their features accordingly. Work in strategic classification and decision-dependent distributions seeks to characterize the closed-loop behavior of deploying learning algorithms by explicitly considering the effect of the classifier on the underlying data distribution. More recently, works in performative prediction seek to classify the closed-loop behavior by considering general properties of the mapping from classifier to data distribution, rather than an explicit form. Building on this notion, we analyze repeated risk minimization as the perturbed trajectories of the gradient flows of performative risk minimization. We consider the case where there may be multiple local minimizers of perfor
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#23884;&#20837;&#20132;&#20114;&#30340;&#35282;&#24230;&#26469;&#20998;&#26512;&#21644;&#27604;&#36739;&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#26041;&#27861;&#65292;&#30740;&#31350;&#20102;CP&#65292;DistMult&#21644;ComplEx&#31561;&#19977;&#31181;&#27969;&#34892;&#30340;&#26041;&#27861;&#65292;&#25581;&#31034;&#20102;ComplEx&#24615;&#33021;&#26356;&#22909;&#30340;&#21407;&#22240;&#65292;&#24182;&#20026;&#24320;&#21457;&#26032;&#27169;&#22411;&#25552;&#20379;&#20102;&#35265;&#35299;&#12290;</title><link>http://arxiv.org/abs/1903.11406</link><description>&lt;p&gt;
&#20174;&#22810;&#23884;&#20837;&#20132;&#20114;&#30340;&#35282;&#24230;&#20998;&#26512;&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Analyzing Knowledge Graph Embedding Methods from a Multi-Embedding Interaction Perspective. (arXiv:1903.11406v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1903.11406
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#23884;&#20837;&#20132;&#20114;&#30340;&#35282;&#24230;&#26469;&#20998;&#26512;&#21644;&#27604;&#36739;&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#26041;&#27861;&#65292;&#30740;&#31350;&#20102;CP&#65292;DistMult&#21644;ComplEx&#31561;&#19977;&#31181;&#27969;&#34892;&#30340;&#26041;&#27861;&#65292;&#25581;&#31034;&#20102;ComplEx&#24615;&#33021;&#26356;&#22909;&#30340;&#21407;&#22240;&#65292;&#24182;&#20026;&#24320;&#21457;&#26032;&#27169;&#22411;&#25552;&#20379;&#20102;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#35782;&#22270;&#35889;&#26159;&#19968;&#31181;&#24191;&#27867;&#29992;&#20110;&#34920;&#31034;&#30693;&#35782;&#30340;&#26684;&#24335;&#65292;&#19988;&#22312;&#35821;&#20041;&#25628;&#32034;&#24341;&#25806;&#12289;&#38382;&#31572;&#31995;&#32479;&#21644;&#25512;&#33616;&#31995;&#32479;&#20013;&#26377;&#35768;&#22810;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#23454;&#38469;&#30340;&#30693;&#35782;&#22270;&#35889;&#36890;&#24120;&#26159;&#19981;&#23436;&#25972;&#30340;&#65292;&#22240;&#27492;&#25552;&#20986;&#20102;&#22522;&#20110;&#23884;&#20837;&#21521;&#37327;&#26041;&#27861;&#65292;&#22914;CP&#12289;DistMult&#21644;ComplEx&#31561;&#65292;&#20197;&#35299;&#20915;&#27492;&#38382;&#39064;&#12290;&#36825;&#20123;&#26041;&#27861;&#23558;&#23454;&#20307;&#21644;&#20851;&#31995;&#34920;&#31034;&#20026;&#35821;&#20041;&#31354;&#38388;&#20013;&#30340;&#23884;&#20837;&#21521;&#37327;&#65292;&#24182;&#39044;&#27979;&#23427;&#20204;&#20043;&#38388;&#30340;&#38142;&#25509;&#12290;&#23884;&#20837;&#21521;&#37327;&#26412;&#36523;&#21253;&#21547;&#20016;&#23500;&#30340;&#35821;&#20041;&#20449;&#24687;&#65292;&#21487;&#29992;&#20110;&#20854;&#20182;&#24212;&#29992;&#31243;&#24207;&#65292;&#22914;&#25968;&#25454;&#20998;&#26512;&#12290;&#20294;&#26159;&#65292;&#36825;&#20123;&#27169;&#22411;&#20013;&#30340;&#26426;&#21046;&#21644;&#23884;&#20837;&#21521;&#37327;&#26412;&#36523;&#21464;&#21270;&#24456;&#22823;&#65292;&#20351;&#20854;&#38590;&#20197;&#29702;&#35299;&#21644;&#27604;&#36739;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#38656;&#35201;&#20197;&#22810;&#23884;&#20837;&#20132;&#20114;&#30340;&#35282;&#24230;&#26469;&#20998;&#26512;&#21644;&#27604;&#36739;&#30693;&#35782;&#22270;&#35889;&#23884;&#20837;&#26041;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19977;&#31181;&#27969;&#34892;&#30340;&#26041;&#27861;&#65288;CP&#12289;DistMult&#21644;ComplEx&#65289;&#65292;&#24182;&#30740;&#31350;&#23427;&#20204;&#30340;&#19981;&#21516;&#23884;&#20837;&#21521;&#37327;&#22914;&#20309;&#30456;&#20114;&#20316;&#29992;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#25581;&#31034;&#20102;ComplEx&#24615;&#33021;&#26356;&#22909;&#30340;&#21407;&#22240;&#65292;&#24182;&#20026;&#24320;&#21457;&#26032;&#27169;&#22411;&#25552;&#20379;&#20102;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Knowledge graph is a popular format for representing knowledge, with many applications to semantic search engines, question-answering systems, and recommender systems. Real-world knowledge graphs are usually incomplete, so knowledge graph embedding methods, such as Canonical decomposition/Parallel factorization (CP), DistMult, and ComplEx, have been proposed to address this issue. These methods represent entities and relations as embedding vectors in semantic space and predict the links between them. The embedding vectors themselves contain rich semantic information and can be used in other applications such as data analysis. However, mechanisms in these models and the embedding vectors themselves vary greatly, making it difficult to understand and compare them. Given this lack of understanding, we risk using them ineffectively or incorrectly, particularly for complicated models, such as CP, with two role-based embedding vectors, or the state-of-the-art ComplEx model, with complex-valu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#38598;&#25104;&#37319;&#26679;&#65292;&#20197;&#36817;&#20284;Thompson&#37319;&#26679;&#24182;&#22312;&#22797;&#26434;&#27169;&#22411;&#19979;&#20445;&#25345;&#21487;&#34892;&#24615;&#65292;&#23558;&#22823;&#22823;&#25193;&#23637;Thompson&#37319;&#26679;&#30340;&#24212;&#29992;&#33539;&#22260;&#12290;</title><link>http://arxiv.org/abs/1705.07347</link><description>&lt;p&gt;
&#38598;&#25104;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Ensemble Sampling. (arXiv:1705.07347v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1705.07347
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#38598;&#25104;&#37319;&#26679;&#65292;&#20197;&#36817;&#20284;Thompson&#37319;&#26679;&#24182;&#22312;&#22797;&#26434;&#27169;&#22411;&#19979;&#20445;&#25345;&#21487;&#34892;&#24615;&#65292;&#23558;&#22823;&#22823;&#25193;&#23637;Thompson&#37319;&#26679;&#30340;&#24212;&#29992;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Thompson&#37319;&#26679;&#24050;&#32463;&#25104;&#20026;&#19968;&#31181;&#35299;&#20915;&#22810;&#31181;&#22312;&#32447;&#20915;&#31574;&#38382;&#39064;&#30340;&#26377;&#25928;&#21551;&#21457;&#24335;&#31639;&#27861;&#12290;&#22312;&#20854;&#22522;&#26412;&#24418;&#24335;&#20013;&#65292;&#35813;&#31639;&#27861;&#38656;&#35201;&#35745;&#31639;&#24182;&#20174;&#27169;&#22411;&#30340;&#21518;&#39564;&#20998;&#24067;&#20013;&#37319;&#26679;&#65292;&#20165;&#22312;&#31616;&#21333;&#29305;&#27530;&#24773;&#20917;&#19979;&#25165;&#21487;&#34892;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#38598;&#25104;&#37319;&#26679;&#65292;&#26088;&#22312;&#36817;&#20284;Thompson&#37319;&#26679;&#65292;&#21516;&#26102;&#22312;&#22797;&#26434;&#27169;&#22411;&#65288;&#22914;&#31070;&#32463;&#32593;&#32476;&#65289;&#30340;&#38754;&#21069;&#20445;&#25345;&#21487;&#34892;&#24615;&#12290;&#38598;&#25104;&#37319;&#26679;&#22823;&#22823;&#25193;&#23637;&#20102;&#36866;&#29992;Thompson&#37319;&#26679;&#30340;&#24212;&#29992;&#33539;&#22260;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#25903;&#25345;&#35813;&#26041;&#27861;&#30340;&#29702;&#35770;&#22522;&#30784;&#65292;&#24182;&#25552;&#20379;&#20102;&#36827;&#19968;&#27493;&#30340;&#35745;&#31639;&#32467;&#26524;&#26469;&#25552;&#20379;&#26356;&#22810;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Thompson sampling has emerged as an effective heuristic for a broad range of online decision problems. In its basic form, the algorithm requires computing and sampling from a posterior distribution over models, which is tractable only for simple special cases. This paper develops ensemble sampling, which aims to approximate Thompson sampling while maintaining tractability even in the face of complex models such as neural networks. Ensemble sampling dramatically expands on the range of applications for which Thompson sampling is viable. We establish a theoretical basis that supports the approach and present computational results that offer further insight.
&lt;/p&gt;</description></item></channel></rss>