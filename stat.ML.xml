<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#20998;&#26512;&#20102;NHTS&#25968;&#25454;&#65292;&#24320;&#21457;&#20102;&#19968;&#20010;&#33021;&#22815;&#20934;&#30830;&#39044;&#27979;&#20154;&#21592;&#21644;&#36710;&#36742;&#20986;&#34892;&#30340;&#27169;&#22411;&#65292;&#24182;&#21462;&#24471;&#20102;98%&#30340;&#20934;&#30830;&#29575;&#12290;&#36825;&#23545;&#20256;&#32479;&#20132;&#36890;&#35268;&#21010;&#27169;&#22411;&#30340;&#24615;&#33021;&#26469;&#35828;&#26159;&#19968;&#20010;&#26174;&#33879;&#30340;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2308.05665</link><description>&lt;p&gt;
&#25506;&#32034;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#39044;&#27979;&#20154;&#21592;&#21644;&#36710;&#36742;&#20986;&#34892;&#65306;&#23545;NHTS&#25968;&#25454;&#30340;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Exploring Deep Learning Approaches to Predict Person and Vehicle Trips: An Analysis of NHTS Data. (arXiv:2308.05665v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05665
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#20998;&#26512;&#20102;NHTS&#25968;&#25454;&#65292;&#24320;&#21457;&#20102;&#19968;&#20010;&#33021;&#22815;&#20934;&#30830;&#39044;&#27979;&#20154;&#21592;&#21644;&#36710;&#36742;&#20986;&#34892;&#30340;&#27169;&#22411;&#65292;&#24182;&#21462;&#24471;&#20102;98%&#30340;&#20934;&#30830;&#29575;&#12290;&#36825;&#23545;&#20256;&#32479;&#20132;&#36890;&#35268;&#21010;&#27169;&#22411;&#30340;&#24615;&#33021;&#26469;&#35828;&#26159;&#19968;&#20010;&#26174;&#33879;&#30340;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#20132;&#36890;&#35268;&#21010;&#22312;&#20934;&#30830;&#39044;&#27979;&#20154;&#21592;&#21644;&#36710;&#36742;&#20986;&#34892;&#26041;&#38754;&#20381;&#36182;&#36739;&#22810;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#35268;&#21010;&#27169;&#22411;&#24448;&#24448;&#26080;&#27861;&#32771;&#34385;&#20986;&#34892;&#34892;&#20026;&#30340;&#22797;&#26434;&#24615;&#21644;&#21160;&#24577;&#24615;&#65292;&#23548;&#33268;&#39044;&#27979;&#20934;&#30830;&#24615;&#19981;&#20339;&#12290;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#30340;&#28508;&#21147;&#65292;&#20197;&#25913;&#21464;&#25105;&#20204;&#23545;&#20986;&#34892;&#39044;&#27979;&#21644;&#20132;&#36890;&#35268;&#21010;&#30340;&#26041;&#27861;&#12290;&#21033;&#29992;&#20840;&#22269;&#23478;&#24237;&#20986;&#34892;&#35843;&#26597;&#65288;NHTS&#65289;&#30340;&#20840;&#38754;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#24320;&#21457;&#21644;&#35757;&#32451;&#20102;&#19968;&#20010;&#29992;&#20110;&#39044;&#27979;&#20154;&#21592;&#21644;&#36710;&#36742;&#20986;&#34892;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#12290;&#35813;&#27169;&#22411;&#21033;&#29992;NHTS&#25968;&#25454;&#20013;&#30340;&#22823;&#37327;&#20449;&#24687;&#65292;&#25429;&#25417;&#20197;&#21069;&#20256;&#32479;&#27169;&#22411;&#24573;&#35270;&#30340;&#22797;&#26434;&#38750;&#32447;&#24615;&#20851;&#31995;&#12290;&#32467;&#26524;&#65292;&#25105;&#20204;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#22312;&#39044;&#27979;&#20154;&#21592;&#20986;&#34892;&#26041;&#38754;&#36798;&#21040;&#20102;98%&#30340;&#20934;&#30830;&#29575;&#65292;&#22312;&#36710;&#36742;&#20986;&#34892;&#20272;&#35745;&#26041;&#38754;&#36798;&#21040;&#20102;96%&#30340;&#20934;&#30830;&#29575;&#12290;&#30456;&#27604;&#20256;&#32479;&#20132;&#36890;&#27169;&#22411;&#30340;&#34920;&#29616;&#65292;&#36825;&#20195;&#34920;&#20102;&#26174;&#33879;&#30340;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern transportation planning relies heavily on accurate predictions of person and vehicle trips. However, traditional planning models often fail to account for the intricacies and dynamics of travel behavior, leading to less-than-optimal accuracy in these predictions. This study explores the potential of deep learning techniques to transform the way we approach trip predictions, and ultimately, transportation planning. Utilizing a comprehensive dataset from the National Household Travel Survey (NHTS), we developed and trained a deep learning model for predicting person and vehicle trips. The proposed model leverages the vast amount of information in the NHTS data, capturing complex, non-linear relationships that were previously overlooked by traditional models. As a result, our deep learning model achieved an impressive accuracy of 98% for person trip prediction and 96% for vehicle trip estimation. This represents a significant improvement over the performances of traditional transpo
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#36830;&#25509;&#36710;&#36742;&#25968;&#25454;&#21644;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#33258;&#21160;&#25552;&#21462;&#36947;&#36335;&#22522;&#30784;&#35774;&#26045;&#30340;&#26032;&#26041;&#27861;&#12290;&#36890;&#36807;&#23558;&#36710;&#36742;&#36712;&#36857;&#20998;&#27573;&#24182;&#29983;&#25104;&#36947;&#36335;&#27573;&#30340;&#22270;&#20687;&#34920;&#31034;&#65292;&#25105;&#20204;&#21033;&#29992;YOLOv5&#31639;&#27861;&#20934;&#30830;&#20998;&#31867;&#30452;&#32447;&#36947;&#36335;&#27573;&#21644;&#20132;&#21449;&#28857;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#25972;&#20307;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.05658</link><description>&lt;p&gt;
&#20351;&#29992;&#36830;&#25509;&#36710;&#36742;&#25968;&#25454;&#21644;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#33258;&#21160;&#25552;&#21462;&#30456;&#20851;&#36947;&#36335;&#22522;&#30784;&#35774;&#26045;
&lt;/p&gt;
&lt;p&gt;
Automatic Extraction of Relevant Road Infrastructure using Connected vehicle data and Deep Learning Model. (arXiv:2308.05658v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05658
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#36830;&#25509;&#36710;&#36742;&#25968;&#25454;&#21644;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#33258;&#21160;&#25552;&#21462;&#36947;&#36335;&#22522;&#30784;&#35774;&#26045;&#30340;&#26032;&#26041;&#27861;&#12290;&#36890;&#36807;&#23558;&#36710;&#36742;&#36712;&#36857;&#20998;&#27573;&#24182;&#29983;&#25104;&#36947;&#36335;&#27573;&#30340;&#22270;&#20687;&#34920;&#31034;&#65292;&#25105;&#20204;&#21033;&#29992;YOLOv5&#31639;&#27861;&#20934;&#30830;&#20998;&#31867;&#30452;&#32447;&#36947;&#36335;&#27573;&#21644;&#20132;&#21449;&#28857;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#25972;&#20307;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24403;&#20170;&#24555;&#36895;&#21457;&#23637;&#30340;&#22478;&#24066;&#29615;&#22659;&#20013;&#65292;&#39640;&#25928;&#20934;&#30830;&#22320;&#32472;&#21046;&#36947;&#36335;&#22522;&#30784;&#35774;&#26045;&#23545;&#20110;&#20248;&#21270;&#20132;&#36890;&#31995;&#32479;&#12289;&#22686;&#24378;&#36947;&#36335;&#23433;&#20840;&#24182;&#25913;&#21892;&#39550;&#39542;&#21592;&#21644;&#36890;&#21220;&#32773;&#30340;&#25972;&#20307;&#20986;&#34892;&#20307;&#39564;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#19968;&#20010;&#20005;&#23803;&#30340;&#29942;&#39048;&#38459;&#30861;&#20102;&#36827;&#23637;-&#32321;&#29712;&#32791;&#26102;&#30340;&#25163;&#21160;&#20132;&#21449;&#28857;&#35782;&#21035;&#12290;&#32771;&#34385;&#21040;&#38656;&#35201;&#35782;&#21035;&#30340;&#20132;&#21449;&#28857;&#25968;&#37327;&#21644;&#27599;&#20010;&#20132;&#21449;&#28857;&#25152;&#38656;&#30340;&#24037;&#26102;&#65292;&#33258;&#21160;&#21270;&#35299;&#20915;&#26041;&#26696;&#30340;&#38656;&#27714;&#21464;&#24471;&#19981;&#21487;&#24573;&#35270;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#36830;&#25509;&#36710;&#36742;&#25968;&#25454;&#21644;&#20808;&#36827;&#30340;&#28145;&#24230;&#23398;&#20064;&#25216;&#26415;&#12290;&#36890;&#36807;&#20351;&#29992;&#22320;&#29702;&#25955;&#21015;&#23545;&#36710;&#36742;&#36712;&#36857;&#36827;&#34892;&#20998;&#27573;&#65292;&#24182;&#29983;&#25104;&#36947;&#36335;&#27573;&#30340;&#22270;&#20687;&#34920;&#31034;&#65292;&#25105;&#20204;&#21033;&#29992;YOLOv5&#65288;You Only Look Once version 5&#65289;&#31639;&#27861;&#20934;&#30830;&#20998;&#31867;&#20102;&#30452;&#32447;&#36947;&#36335;&#27573;&#21644;&#20132;&#21449;&#28857;&#12290;&#23454;&#39564;&#32467;&#26524;&#23637;&#31034;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#25972;&#20307;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In today's rapidly evolving urban landscapes, efficient and accurate mapping of road infrastructure is critical for optimizing transportation systems, enhancing road safety, and improving the overall mobility experience for drivers and commuters. Yet, a formidable bottleneck obstructs progress - the laborious and time-intensive manual identification of intersections. Simply considering the shear number of intersections that need to be identified, and the labor hours required per intersection, the need for an automated solution becomes undeniable. To address this challenge, we propose a novel approach that leverages connected vehicle data and cutting-edge deep learning techniques. By employing geohashing to segment vehicle trajectories and then generating image representations of road segments, we utilize the YOLOv5 (You Only Look Once version 5) algorithm for accurate classification of both straight road segments and intersections. Experimental results demonstrate an impressive overall
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#26631;&#20934;&#21270;&#26799;&#24230;&#36866;&#24212; H\"{o}lder &#20809;&#28369;&#24615;&#30340;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#23616;&#37096; H\"{o}lder &#20809;&#28369;&#24615;&#30340;&#26032;&#27010;&#24565;&#12290;</title><link>http://arxiv.org/abs/2308.05621</link><description>&lt;p&gt;
&#25152;&#26377;&#24773;&#20917;&#19979;&#30340;&#26631;&#20934;&#21270;&#26799;&#24230;
&lt;/p&gt;
&lt;p&gt;
Normalized Gradients for All. (arXiv:2308.05621v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05621
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#26631;&#20934;&#21270;&#26799;&#24230;&#36866;&#24212; H\"{o}lder &#20809;&#28369;&#24615;&#30340;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#23616;&#37096; H\"{o}lder &#20809;&#28369;&#24615;&#30340;&#26032;&#27010;&#24565;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#31616;&#30701;&#30340;&#35770;&#25991;&#20013;&#65292;&#25105;&#23637;&#31034;&#20102;&#22914;&#20309;&#20197;&#40657;&#30418;&#30340;&#26041;&#24335;&#21033;&#29992;&#26631;&#20934;&#21270;&#26799;&#24230;&#26469;&#36866;&#24212; H\"{o}lder &#20809;&#28369;&#24615;&#12290;&#27492;&#22806;&#65292;&#36825;&#20010;&#30028;&#38480;&#23558;&#20381;&#36182;&#20110;&#23616;&#37096; H\"{o}lder &#20809;&#28369;&#24615;&#30340;&#19968;&#31181;&#26032;&#27010;&#24565;&#12290;&#20027;&#35201;&#24605;&#24819;&#30452;&#25509;&#26469;&#33258;&#20110; Levy [2017]&#12290;
&lt;/p&gt;
&lt;p&gt;
In this short note, I show how to adapt to H\"{o}lder smoothness using normalized gradients in a black-box way. Moreover, the bound will depend on a novel notion of local H\"{o}lder smoothness. The main idea directly comes from Levy [2017].
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25490;&#21517;&#30340;&#20860;&#23481;&#24615;&#24230;&#37327;&#21644;&#19968;&#31181;&#26032;&#30340;&#25439;&#22833;&#20989;&#25968;&#26469;&#26356;&#26032;&#20020;&#24202;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#20197;&#35299;&#20915;&#26356;&#26032;&#27169;&#22411;&#24341;&#20837;&#30340;&#20860;&#23481;&#24615;&#38382;&#39064;&#12290;&#22312;&#20351;&#29992;MIMIC&#25968;&#25454;&#30340;&#30149;&#27515;&#29575;&#39118;&#38505;&#20998;&#23618;&#26696;&#20363;&#30740;&#31350;&#20013;&#65292;&#35813;&#26041;&#27861;&#30456;&#23545;&#20110;&#29616;&#26377;&#25216;&#26415;&#33021;&#20135;&#29983;&#26356;&#20860;&#23481;&#30340;&#27169;&#22411;&#24182;&#20445;&#25345;&#21028;&#21035;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.05619</link><description>&lt;p&gt;
&#20351;&#29992;&#22522;&#20110;&#25490;&#21517;&#30340;&#20860;&#23481;&#24615;&#26356;&#26032;&#20020;&#24202;&#39118;&#38505;&#20998;&#23618;&#27169;&#22411;&#65306;&#35780;&#20272;&#21644;&#20248;&#21270;&#20020;&#24202;&#21307;&#29983;-&#27169;&#22411;&#22242;&#38431;&#24615;&#33021;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Updating Clinical Risk Stratification Models Using Rank-Based Compatibility: Approaches for Evaluating and Optimizing Clinician-Model Team Performance. (arXiv:2308.05619v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05619
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25490;&#21517;&#30340;&#20860;&#23481;&#24615;&#24230;&#37327;&#21644;&#19968;&#31181;&#26032;&#30340;&#25439;&#22833;&#20989;&#25968;&#26469;&#26356;&#26032;&#20020;&#24202;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#20197;&#35299;&#20915;&#26356;&#26032;&#27169;&#22411;&#24341;&#20837;&#30340;&#20860;&#23481;&#24615;&#38382;&#39064;&#12290;&#22312;&#20351;&#29992;MIMIC&#25968;&#25454;&#30340;&#30149;&#27515;&#29575;&#39118;&#38505;&#20998;&#23618;&#26696;&#20363;&#30740;&#31350;&#20013;&#65292;&#35813;&#26041;&#27861;&#30456;&#23545;&#20110;&#29616;&#26377;&#25216;&#26415;&#33021;&#20135;&#29983;&#26356;&#20860;&#23481;&#30340;&#27169;&#22411;&#24182;&#20445;&#25345;&#21028;&#21035;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#25968;&#25454;&#30340;&#21464;&#21270;&#25110;&#26032;&#25968;&#25454;&#30340;&#20986;&#29616;&#65292;&#26356;&#26032;&#20020;&#24202;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21487;&#33021;&#26159;&#24517;&#35201;&#30340;&#65292;&#20197;&#20445;&#25345;&#25110;&#25552;&#39640;&#20854;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#26356;&#26032;&#27169;&#22411;&#21487;&#33021;&#20250;&#24341;&#20837;&#20860;&#23481;&#24615;&#38382;&#39064;&#65292;&#24403;&#26356;&#26032;&#21518;&#30340;&#27169;&#22411;&#30340;&#34892;&#20026;&#19982;&#29992;&#25143;&#30340;&#26399;&#26395;&#19981;&#19968;&#33268;&#26102;&#65292;&#20250;&#23548;&#33268;&#29992;&#25143;-&#27169;&#22411;&#22242;&#38431;&#34920;&#29616;&#19981;&#20339;&#12290;&#29616;&#26377;&#30340;&#20860;&#23481;&#24615;&#24230;&#37327;&#20381;&#36182;&#20110;&#27169;&#22411;&#30340;&#20915;&#31574;&#38408;&#20540;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#22522;&#20110;&#20272;&#35745;&#39118;&#38505;&#30340;&#25490;&#21517;&#29983;&#25104;&#27169;&#22411;&#30340;&#24212;&#29992;&#33021;&#21147;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#25490;&#21517;&#30340;&#20860;&#23481;&#24615;&#24230;&#37327;&#65292;$C^R$&#65292;&#20197;&#21450;&#19968;&#20010;&#26088;&#22312;&#20248;&#21270;&#21028;&#21035;&#24615;&#33021;&#30340;&#26032;&#25439;&#22833;&#20989;&#25968;&#65292;&#21516;&#26102;&#40723;&#21169;&#33391;&#22909;&#30340;&#20860;&#23481;&#24615;&#12290;&#22312;&#21033;&#29992;MIMIC&#25968;&#25454;&#30340;&#30149;&#27515;&#29575;&#39118;&#38505;&#20998;&#23618;&#30340;&#26696;&#20363;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#30456;&#23545;&#20110;&#29616;&#26377;&#30340;&#27169;&#22411;&#36873;&#25321;&#25216;&#26415;&#65292;&#20135;&#29983;&#20102;&#26356;&#20860;&#23481;&#30340;&#27169;&#22411;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#21028;&#21035;&#24615;&#33021;&#65292;$C^R$&#25552;&#39640;&#20102;0.019&#65288;$95\%$&#32622;&#20449;&#21306;&#38388;&#65306;...
&lt;/p&gt;
&lt;p&gt;
As data shift or new data become available, updating clinical machine learning models may be necessary to maintain or improve performance over time. However, updating a model can introduce compatibility issues when the behavior of the updated model does not align with user expectations, resulting in poor user-model team performance. Existing compatibility measures depend on model decision thresholds, limiting their applicability in settings where models are used to generate rankings based on estimated risk. To address this limitation, we propose a novel rank-based compatibility measure, $C^R$, and a new loss function that aims to optimize discriminative performance while encouraging good compatibility. Applied to a case study in mortality risk stratification leveraging data from MIMIC, our approach yields more compatible models while maintaining discriminative performance compared to existing model selection techniques, with an increase in $C^R$ of $0.019$ ($95\%$ confidence interval: 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#20449;&#36947;&#25277;&#26679;&#26041;&#27861;&#65292;&#29992;&#20110;&#24555;&#36895;&#21512;&#25104;&#26377;&#38480;&#25968;&#25454;&#30340;&#20449;&#36947;&#23454;&#29616;&#65292;&#30456;&#27604;&#20110;&#29616;&#26377;&#30340;&#22522;&#20110; GAN &#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#35757;&#32451;&#31283;&#23450;&#19988;&#33021;&#22815;&#29983;&#25104;&#22810;&#26679;&#21270;&#21644;&#39640;&#36136;&#37327;&#30340;&#20449;&#36947;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2308.05583</link><description>&lt;p&gt;
&#26080;&#32447;&#30005;&#26080;&#32447;&#20449;&#36947;&#24314;&#27169;&#21644;&#25277;&#26679;&#30340;&#29983;&#25104;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Generative Diffusion Models for Radio Wireless Channel Modelling and Sampling. (arXiv:2308.05583v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05583
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#20449;&#36947;&#25277;&#26679;&#26041;&#27861;&#65292;&#29992;&#20110;&#24555;&#36895;&#21512;&#25104;&#26377;&#38480;&#25968;&#25454;&#30340;&#20449;&#36947;&#23454;&#29616;&#65292;&#30456;&#27604;&#20110;&#29616;&#26377;&#30340;&#22522;&#20110; GAN &#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#35757;&#32451;&#31283;&#23450;&#19988;&#33021;&#22815;&#29983;&#25104;&#22810;&#26679;&#21270;&#21644;&#39640;&#36136;&#37327;&#30340;&#20449;&#36947;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20449;&#36947;&#24314;&#27169;&#23545;&#20110;&#35774;&#35745;&#29616;&#20195;&#26080;&#32447;&#36890;&#20449;&#31995;&#32479;&#33267;&#20851;&#37325;&#35201;&#12290;&#20449;&#36947;&#24314;&#27169;&#30340;&#22797;&#26434;&#24615;&#21644;&#25910;&#38598;&#39640;&#36136;&#37327;&#26080;&#32447;&#20449;&#36947;&#25968;&#25454;&#30340;&#25104;&#26412;&#26085;&#30410;&#22686;&#21152;&#65292;&#24050;&#25104;&#20026;&#20027;&#35201;&#25361;&#25112;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#20449;&#36947;&#25277;&#26679;&#26041;&#27861;&#65292;&#21487;&#20197;&#24555;&#36895;&#21512;&#25104;&#26377;&#38480;&#25968;&#25454;&#30340;&#20449;&#36947;&#23454;&#29616;&#12290;&#25105;&#20204;&#20351;&#29992;&#22312;&#39057;&#29575;&#31354;&#38388;&#22495;&#20013;&#25805;&#20316;&#30340;&#22522;&#20110; U Net &#30340;&#25193;&#25955;&#27169;&#22411;&#12290;&#20026;&#20102;&#35780;&#20272;&#25152;&#25552;&#27169;&#22411;&#22312;&#35757;&#32451;&#25968;&#25454;&#38598;&#20013;&#22914;&#20309;&#20934;&#30830;&#22320;&#37325;&#29616;&#20449;&#36947;&#30340;&#30495;&#23454;&#20998;&#24067;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#20004;&#20010;&#35780;&#20272;&#25351;&#26631;&#65306;$i)$ &#21453;&#26144;&#22825;&#32447;&#21644;&#39057;&#29575;&#39046;&#22495;&#20013;&#24402;&#19968;&#21270;&#21151;&#29575;&#35889;&#30340;&#23454;&#38469;&#20998;&#24067;&#21644;&#29983;&#25104;&#20998;&#24067;&#20043;&#38388;&#30340;&#36817;&#20284; $2$-Wasserstein &#36317;&#31163;&#65292;&#21644; $ii)$ &#20998;&#24067;&#30340;&#31934;&#30830;&#24230;&#21644;&#21484;&#22238;&#29575;&#24230;&#37327;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#19982;&#29616;&#26377;&#30340;&#22522;&#20110; GAN &#30340;&#26041;&#27861;&#30456;&#27604;&#65292;&#35813;&#25193;&#25955;&#27169;&#22411;&#26041;&#27861;&#35757;&#32451;&#31283;&#23450;&#19988;&#33021;&#22815;&#29983;&#25104;&#22810;&#26679;&#21270;&#21644;&#39640;&#36136;&#37327;&#30340;&#20449;&#36947;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Channel modelling is essential to designing modern wireless communication systems. The increasing complexity of channel modelling and the cost of collecting high-quality wireless channel data have become major challenges. In this paper, we propose a diffusion model based channel sampling approach for rapidly synthesizing channel realizations from limited data. We use a diffusion model with a U Net based architecture operating in the frequency space domain. To evaluate how well the proposed model reproduces the true distribution of channels in the training dataset, two evaluation metrics are used: $i)$ the approximate $2$-Wasserstein distance between real and generated distributions of the normalized power spectrum in the antenna and frequency domains and $ii)$ precision and recall metric for distributions. We show that, compared to existing GAN based approaches which suffer from mode collapse and unstable training, our diffusion based approach trains stably and generates diverse and hi
&lt;/p&gt;</description></item><item><title>TSLiNGAM&#26159;&#19968;&#31181;&#33021;&#22815;&#22312;&#37325;&#23614;&#20998;&#24067;&#19979;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;LiNGAM&#27169;&#22411;&#20013;&#35823;&#24046;&#39033;&#30340;&#38750;&#39640;&#26031;&#24615;&#20551;&#35774;&#65292;&#23454;&#29616;&#20102;&#26356;&#39640;&#25928;&#21644;&#26356;&#31283;&#20581;&#30340;&#22240;&#26524;&#32467;&#26500;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2308.05422</link><description>&lt;p&gt;
TSLiNGAM: &#22312;&#37325;&#23614;&#20998;&#24067;&#19979;&#30340;DirectLiNGAM
&lt;/p&gt;
&lt;p&gt;
TSLiNGAM: DirectLiNGAM under heavy tails. (arXiv:2308.05422v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05422
&lt;/p&gt;
&lt;p&gt;
TSLiNGAM&#26159;&#19968;&#31181;&#33021;&#22815;&#22312;&#37325;&#23614;&#20998;&#24067;&#19979;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;LiNGAM&#27169;&#22411;&#20013;&#35823;&#24046;&#39033;&#30340;&#38750;&#39640;&#26031;&#24615;&#20551;&#35774;&#65292;&#23454;&#29616;&#20102;&#26356;&#39640;&#25928;&#21644;&#26356;&#31283;&#20581;&#30340;&#22240;&#26524;&#32467;&#26500;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#25512;&#26029;&#30340;&#19968;&#31181;&#24050;&#24314;&#31435;&#30340;&#26041;&#27861;&#26159;&#23558;&#26377;&#21521;&#26080;&#29615;&#22270;(DAGs)&#19982;&#32467;&#26500;&#24615;&#22240;&#26524;&#27169;&#22411;(SCMs)&#32467;&#21512;&#36215;&#26469;&#65292;&#20197;&#25551;&#36848;&#25928;&#24212;&#23545;&#20854;&#22240;&#26524;&#30340;&#21151;&#33021;&#20381;&#36182;&#20851;&#31995;&#12290;&#32473;&#23450;&#25968;&#25454;&#19979;SCMs&#30340;&#21487;&#33021;&#21487;&#36776;&#35782;&#24615;&#21462;&#20915;&#20110;&#23545;&#22122;&#22768;&#21464;&#37327;&#21644;SCM&#20013;&#21151;&#33021;&#31867;&#30340;&#20551;&#35774;&#12290;&#20363;&#22914;&#65292;&#22312;LiNGAM&#27169;&#22411;&#20013;&#65292;&#21151;&#33021;&#31867;&#21463;&#38480;&#20110;&#32447;&#24615;&#20989;&#25968;&#65292;&#25200;&#21160;&#24517;&#39035;&#26159;&#38750;&#39640;&#26031;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;TSLiNGAM&#65292;&#19968;&#31181;&#22522;&#20110;&#35266;&#27979;&#25968;&#25454;&#35782;&#21035;&#22240;&#26524;&#27169;&#22411;DAG&#30340;&#26032;&#26041;&#27861;&#12290;TSLiNGAM&#24314;&#31435;&#22312;DirectLiNGAM&#20043;&#19978;&#65292;&#23427;&#26159;&#19968;&#31181;&#20351;&#29992;&#31616;&#21333;&#30340;OLS&#22238;&#24402;&#26469;&#35782;&#21035;&#21464;&#37327;&#38388;&#22240;&#26524;&#26041;&#21521;&#30340;&#27969;&#34892;&#31639;&#27861;&#12290;TSLiNGAM&#21033;&#29992;&#20102;LiNGAM&#27169;&#22411;&#20013;&#35823;&#24046;&#39033;&#30340;&#38750;&#39640;&#26031;&#24615;&#20551;&#35774;&#65292;&#20174;&#32780;&#33719;&#24471;&#26356;&#39640;&#25928;&#21644;&#26356;&#31283;&#20581;&#30340;&#22240;&#26524;&#32467;&#26500;&#20272;&#35745;&#12290;TSLiNGAM&#22312;&#29702;&#35770;&#19978;&#34987;&#35777;&#26126;&#26159;&#21512;&#29702;&#30340;&#65292;&#24182;&#22312;&#24191;&#27867;&#30340;&#27169;&#25311;&#30740;&#31350;&#20013;&#36827;&#34892;&#20102;&#23454;&#35777;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
One of the established approaches to causal discovery consists of combining directed acyclic graphs (DAGs) with structural causal models (SCMs) to describe the functional dependencies of effects on their causes. Possible identifiability of SCMs given data depends on assumptions made on the noise variables and the functional classes in the SCM. For instance, in the LiNGAM model, the functional class is restricted to linear functions and the disturbances have to be non-Gaussian.  In this work, we propose TSLiNGAM, a new method for identifying the DAG of a causal model based on observational data. TSLiNGAM builds on DirectLiNGAM, a popular algorithm which uses simple OLS regression for identifying causal directions between variables. TSLiNGAM leverages the non-Gaussianity assumption of the error terms in the LiNGAM model to obtain more efficient and robust estimation of the causal structure. TSLiNGAM is justified theoretically and is studied empirically in an extensive simulation study. I
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#26368;&#20248;&#36755;&#36816;&#29702;&#35770;&#23558;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#30340;&#25955;&#24230;&#26041;&#27861;&#21644;Wasserstein&#26041;&#27861;&#32479;&#19968;&#21040;&#19968;&#20010;&#26694;&#26550;&#20013;&#65292;&#24182;&#19988;&#25552;&#20986;&#20102;&#21487;&#20197;&#21516;&#26102;&#25200;&#21160;&#20284;&#28982;&#21644;&#32467;&#26524;&#30340;&#26368;&#20248;&#23545;&#25239;&#20998;&#24067;&#12290;&#36825;&#20010;&#32479;&#19968;&#26694;&#26550;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#20855;&#26377;&#36739;&#24378;&#30340;&#21487;&#34892;&#24615;&#21644;&#23454;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.05414</link><description>&lt;p&gt;
&#36890;&#36807;&#26368;&#20248;&#36755;&#36816;&#29702;&#35770;&#32479;&#19968;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Unifying Distributionally Robust Optimization via Optimal Transport Theory. (arXiv:2308.05414v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.05414
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#26368;&#20248;&#36755;&#36816;&#29702;&#35770;&#23558;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#30340;&#25955;&#24230;&#26041;&#27861;&#21644;Wasserstein&#26041;&#27861;&#32479;&#19968;&#21040;&#19968;&#20010;&#26694;&#26550;&#20013;&#65292;&#24182;&#19988;&#25552;&#20986;&#20102;&#21487;&#20197;&#21516;&#26102;&#25200;&#21160;&#20284;&#28982;&#21644;&#32467;&#26524;&#30340;&#26368;&#20248;&#23545;&#25239;&#20998;&#24067;&#12290;&#36825;&#20010;&#32479;&#19968;&#26694;&#26550;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#20855;&#26377;&#36739;&#24378;&#30340;&#21487;&#34892;&#24615;&#21644;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#20960;&#24180;&#20013;&#65292;&#23545;&#20110;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270; (DRO) &#26377;&#20004;&#31181;&#20027;&#35201;&#26041;&#27861;&#24341;&#36215;&#20102;&#30456;&#24403;&#22823;&#30340;&#20851;&#27880;&#65306;&#22522;&#20110;&#25955;&#24230;&#21644;&#22522;&#20110;Wasserstein&#30340;&#26041;&#27861;&#12290;&#25955;&#24230;&#26041;&#27861;&#20351;&#29992;&#20284;&#28982;&#27604;&#26469;&#24314;&#27169;&#38169;&#37197;&#65292;&#32780;&#21518;&#32773;&#20351;&#29992;&#23454;&#38469;&#32467;&#26524;&#30340;&#36317;&#31163;&#25110;&#25104;&#26412;&#26469;&#24314;&#27169;&#38169;&#37197;&#12290;&#22312;&#36825;&#20123;&#36827;&#23637;&#30340;&#22522;&#30784;&#19978;&#65292;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#23558;&#36825;&#20123;&#26041;&#27861;&#32479;&#19968;&#21040;&#19968;&#20010;&#22522;&#20110;&#26368;&#20248;&#36755;&#36816; (OT) &#21644;&#26465;&#20214;&#30697;&#32422;&#26463;&#30340;&#26694;&#26550;&#20013;&#12290;&#20363;&#22914;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#20197;&#20351;&#24471;&#26368;&#20248;&#23545;&#25239;&#20998;&#24067;&#21516;&#26102;&#25200;&#21160;&#20284;&#28982;&#21644;&#32467;&#26524;&#65292;&#24182;&#22312;&#22522;&#32447;&#27169;&#22411;&#21644;&#23545;&#25239;&#27169;&#22411;&#20043;&#38388;&#20135;&#29983;&#19968;&#20010;&#26368;&#20248; (&#20174;&#26368;&#20248;&#36755;&#36816;&#24847;&#20041;&#19978;) &#30340;&#32806;&#21512;&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#36824;&#30740;&#31350;&#20102;&#20960;&#20010;&#23545;&#20598;&#32467;&#26524;&#65292;&#24182;&#25552;&#20986;&#20102;&#21487;&#34892;&#30340;&#25913;&#36827;&#65292;&#22686;&#24378;&#20102;&#36825;&#20010;&#32479;&#19968;&#26694;&#26550;&#30340;&#23454;&#38469;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the past few years, there has been considerable interest in two prominent approaches for Distributionally Robust Optimization (DRO): Divergence-based and Wasserstein-based methods. The divergence approach models misspecification in terms of likelihood ratios, while the latter models it through a measure of distance or cost in actual outcomes. Building upon these advances, this paper introduces a novel approach that unifies these methods into a single framework based on optimal transport (OT) with conditional moment constraints. Our proposed approach, for example, makes it possible for optimal adversarial distributions to simultaneously perturb likelihood and outcomes, while producing an optimal (in an optimal transport sense) coupling between the baseline model and the adversarial model.Additionally, the paper investigates several duality results and presents tractable reformulations that enhance the practical applicability of this unified framework.
&lt;/p&gt;</description></item><item><title>SLEM&#26159;&#19968;&#31181;&#36335;&#24452;&#24314;&#27169;&#25216;&#26415;&#65292;&#36890;&#36807;&#38598;&#25104;&#26426;&#22120;&#23398;&#20064;&#36229;&#32423;&#23398;&#20064;&#32773;&#65292;&#23454;&#29616;&#20102;&#19968;&#33268;&#19988;&#26080;&#20559;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#65292;&#24182;&#22312;&#22788;&#29702;&#38750;&#32447;&#24615;&#20851;&#31995;&#26102;&#36229;&#36807;&#20102;&#20256;&#32479;&#30340;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2308.04365</link><description>&lt;p&gt;
SLEM&#65306;&#26426;&#22120;&#23398;&#20064;&#29992;&#20110;&#36335;&#24452;&#24314;&#27169;&#21644;&#22240;&#26524;&#25512;&#26029;&#30340;&#36229;&#32423;&#23398;&#20064;&#32773;&#26041;&#31243;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
SLEM: Machine Learning for Path Modeling and Causal Inference with Super Learner Equation Modeling. (arXiv:2308.04365v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04365
&lt;/p&gt;
&lt;p&gt;
SLEM&#26159;&#19968;&#31181;&#36335;&#24452;&#24314;&#27169;&#25216;&#26415;&#65292;&#36890;&#36807;&#38598;&#25104;&#26426;&#22120;&#23398;&#20064;&#36229;&#32423;&#23398;&#20064;&#32773;&#65292;&#23454;&#29616;&#20102;&#19968;&#33268;&#19988;&#26080;&#20559;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#65292;&#24182;&#22312;&#22788;&#29702;&#38750;&#32447;&#24615;&#20851;&#31995;&#26102;&#36229;&#36807;&#20102;&#20256;&#32479;&#30340;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#25512;&#26029;&#26159;&#31185;&#23398;&#30340;&#20851;&#38190;&#30446;&#26631;&#65292;&#20351;&#30740;&#31350;&#20154;&#21592;&#33021;&#22815;&#36890;&#36807;&#35266;&#23519;&#25968;&#25454;&#24471;&#20986;&#20851;&#20110;&#23545;&#20551;&#23450;&#24178;&#39044;&#30340;&#39044;&#27979;&#30340;&#26377;&#24847;&#20041;&#30340;&#32467;&#35770;&#12290;&#36335;&#24452;&#27169;&#22411;&#12289;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;(SEMs)&#20197;&#21450;&#26356;&#19968;&#33324;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;(DAGs)&#33021;&#22815;&#26126;&#30830;&#22320;&#25351;&#23450;&#20851;&#20110;&#29616;&#35937;&#32972;&#21518;&#30340;&#22240;&#26524;&#32467;&#26500;&#30340;&#20551;&#35774;&#12290;&#19982;DAGs&#19981;&#21516;&#65292;SEMs&#20551;&#35774;&#32447;&#24615;&#20851;&#31995;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#20989;&#25968;&#38169;&#35823;&#35268;&#33539;&#65292;&#20174;&#32780;&#38459;&#30861;&#30740;&#31350;&#20154;&#21592;&#36827;&#34892;&#21487;&#38752;&#30340;&#25928;&#26524;&#22823;&#23567;&#20272;&#35745;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36229;&#32423;&#23398;&#20064;&#32773;&#26041;&#31243;&#27169;&#22411;&#65288;SLEM&#65289;&#65292;&#19968;&#31181;&#38598;&#25104;&#20102;&#26426;&#22120;&#23398;&#20064;&#36229;&#32423;&#23398;&#20064;&#32773;&#38598;&#25104;&#30340;&#36335;&#24452;&#24314;&#27169;&#25216;&#26415;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;SLEM&#33021;&#22815;&#25552;&#20379;&#19968;&#33268;&#19988;&#26080;&#20559;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#65292;&#22312;&#19982;SEMs&#36827;&#34892;&#32447;&#24615;&#27169;&#22411;&#27604;&#36739;&#26102;&#34920;&#29616;&#20986;&#31454;&#20105;&#21147;&#65292;&#24182;&#19988;&#22312;&#22788;&#29702;&#38750;&#32447;&#24615;&#20851;&#31995;&#26102;&#20248;&#20110;SEMs&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal inference is a crucial goal of science, enabling researchers to arrive at meaningful conclusions regarding the predictions of hypothetical interventions using observational data. Path models, Structural Equation Models (SEMs), and, more generally, Directed Acyclic Graphs (DAGs), provide a means to unambiguously specify assumptions regarding the causal structure underlying a phenomenon. Unlike DAGs, which make very few assumptions about the functional and parametric form, SEM assumes linearity. This can result in functional misspecification which prevents researchers from undertaking reliable effect size estimation. In contrast, we propose Super Learner Equation Modeling, a path modeling technique integrating machine learning Super Learner ensembles. We empirically demonstrate its ability to provide consistent and unbiased estimates of causal effects, its competitive performance for linear models when compared with SEM, and highlight its superiority over SEM when dealing with non
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#19968;&#31181;&#20351;&#29992;&#38543;&#26426;&#20998;&#32452;&#22871;&#32034;&#20272;&#35745;&#22120;&#36827;&#34892;&#24191;&#20041;&#27169;&#22411;&#30340;&#36873;&#25321;&#24615;&#25512;&#26029;&#26041;&#27861;&#65292;&#21487;&#20197;&#32771;&#34385;&#20998;&#31867;&#25110;&#20998;&#32452;&#21327;&#21464;&#37327;&#20197;&#21450;&#36830;&#32493;&#21327;&#21464;&#37327;&#65292;&#24182;&#19988;&#26377;&#35777;&#25454;&#34920;&#26126;&#20854;&#20855;&#26377;&#36866;&#24403;&#24615;&#21644;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.13829</link><description>&lt;p&gt;
&#20351;&#29992;&#38543;&#26426;&#20998;&#32452;&#22871;&#32034;&#20272;&#35745;&#22120;&#36827;&#34892;&#24191;&#20041;&#27169;&#22411;&#30340;&#36873;&#25321;&#24615;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
Selective inference using randomized group lasso estimators for general models. (arXiv:2306.13829v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13829
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#19968;&#31181;&#20351;&#29992;&#38543;&#26426;&#20998;&#32452;&#22871;&#32034;&#20272;&#35745;&#22120;&#36827;&#34892;&#24191;&#20041;&#27169;&#22411;&#30340;&#36873;&#25321;&#24615;&#25512;&#26029;&#26041;&#27861;&#65292;&#21487;&#20197;&#32771;&#34385;&#20998;&#31867;&#25110;&#20998;&#32452;&#21327;&#21464;&#37327;&#20197;&#21450;&#36830;&#32493;&#21327;&#21464;&#37327;&#65292;&#24182;&#19988;&#26377;&#35777;&#25454;&#34920;&#26126;&#20854;&#20855;&#26377;&#36866;&#24403;&#24615;&#21644;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#19982;&#24191;&#27867;&#30340;&#20998;&#24067;&#21644;&#25439;&#22833;&#20989;&#25968;&#19968;&#36215;&#20351;&#29992;&#65292;&#24320;&#21457;&#20102;&#36873;&#25321;&#24615;&#25512;&#29702;&#26041;&#27861;&#65292;&#29992;&#20110;&#32452;&#22871;&#32034;&#20272;&#35745;&#22120;&#12290;&#35813;&#26041;&#27861;&#21253;&#25324;&#20351;&#29992;&#25351;&#25968;&#23478;&#26063;&#20998;&#24067;&#65292;&#20197;&#21450;&#20687;&#36807;&#24230;&#31163;&#25955;&#35745;&#25968;&#25968;&#25454;&#30340;&#25311;&#28982;&#27169;&#22411;&#31561;&#65292;&#20801;&#35768;&#20998;&#31867;&#25110;&#20998;&#32452;&#21327;&#21464;&#37327;&#20197;&#21450;&#36830;&#32493;&#21327;&#21464;&#37327;&#12290;&#30740;&#31350;&#20102;&#19968;&#31181;&#38543;&#26426;&#30340;&#32452;&#27491;&#21017;&#21270;&#20248;&#21270;&#38382;&#39064;&#12290;&#28155;&#21152;&#30340;&#38543;&#26426;&#21270;&#20351;&#25105;&#20204;&#21487;&#20197;&#26500;&#24314;&#21518;&#36873;&#25321;&#20284;&#28982;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#26465;&#20214;&#36873;&#25321;&#20998;&#32452;&#21327;&#21464;&#37327;&#30340;&#20107;&#20214;&#19978;&#36866;&#29992;&#20110;&#36873;&#25321;&#24615;&#25512;&#26029;&#12290;&#36825;&#20010;&#20284;&#28982;&#20063;&#25552;&#20379;&#20102;&#19968;&#20010;&#36873;&#25321;&#24615;&#28857;&#20272;&#35745;&#65292;&#36890;&#36807;&#32452;&#22871;&#32034;&#32771;&#34385;&#20102;&#36873;&#25321;&#12290;&#36873;&#25321;&#30340;&#27169;&#22411;&#20013;&#22238;&#24402;&#21442;&#25968;&#30340;&#32622;&#20449;&#21306;&#38388;&#37319;&#29992;&#27779;&#23572;&#24503;&#31867;&#22411;&#30340;&#21306;&#38388;&#65292;&#24182;&#35777;&#26126;&#20855;&#26377;&#26377;&#30028;&#20307;&#31215;&#12290;&#20197;&#32654;&#22269;&#22269;&#23478;&#20581;&#24247;&#21644;&#33829;&#20859;&#35843;&#26597;&#30340;&#25968;&#25454;&#20026;&#20363;&#23637;&#31034;&#20102;&#32452;&#22871;&#32034;&#30340;&#36873;&#25321;&#24615;&#25512;&#29702;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Selective inference methods are developed for group lasso estimators for use with a wide class of distributions and loss functions. The method includes the use of exponential family distributions, as well as quasi-likelihood modeling for overdispersed count data, for example, and allows for categorical or grouped covariates as well as continuous covariates. A randomized group-regularized optimization problem is studied. The added randomization allows us to construct a post-selection likelihood which we show to be adequate for selective inference when conditioning on the event of the selection of the grouped covariates. This likelihood also provides a selective point estimator, accounting for the selection by the group lasso. Confidence regions for the regression parameters in the selected model take the form of Wald-type regions and are shown to have bounded volume. The selective inference method for grouped lasso is illustrated on data from the national health and nutrition examinatio
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#38543;&#26426;&#25628;&#32034;&#21450;&#20854;&#24615;&#33021;&#65292;&#24341;&#20837;&#20102;&#8220;&#25955;&#23556;&#32500;&#24230;&#8221;&#30340;&#27010;&#24565;&#65292;&#25551;&#36848;&#20102;&#24213;&#23618;&#20989;&#25968;&#30340;&#29366;&#24577;&#65292;&#37327;&#21270;&#20102;&#38543;&#26426;&#25628;&#32034;&#30340;&#24615;&#33021;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#26080;&#22122;&#22768;&#21644;&#26377;&#30028;&#22122;&#22768;&#24773;&#20917;&#19979;&#30340;&#36755;&#20986;&#20998;&#21035;&#20197;&#19968;&#23450;&#27010;&#29575;&#25910;&#25947;&#21040;&#26368;&#20248;&#20540;&#12290;</title><link>http://arxiv.org/abs/2305.11509</link><description>&lt;p&gt;
&#20174;&#38543;&#26426;&#25628;&#32034;&#21040;&#24230;&#37327;&#27979;&#24230;&#31354;&#38388;&#20013;&#30340;&#36172;&#21338;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
From Random Search to Bandit Learning in Metric Measure Spaces. (arXiv:2305.11509v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11509
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#38543;&#26426;&#25628;&#32034;&#21450;&#20854;&#24615;&#33021;&#65292;&#24341;&#20837;&#20102;&#8220;&#25955;&#23556;&#32500;&#24230;&#8221;&#30340;&#27010;&#24565;&#65292;&#25551;&#36848;&#20102;&#24213;&#23618;&#20989;&#25968;&#30340;&#29366;&#24577;&#65292;&#37327;&#21270;&#20102;&#38543;&#26426;&#25628;&#32034;&#30340;&#24615;&#33021;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#26080;&#22122;&#22768;&#21644;&#26377;&#30028;&#22122;&#22768;&#24773;&#20917;&#19979;&#30340;&#36755;&#20986;&#20998;&#21035;&#20197;&#19968;&#23450;&#27010;&#29575;&#25910;&#25947;&#21040;&#26368;&#20248;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#25628;&#32034;&#26159;&#36229;&#21442;&#25968;&#20248;&#21270;&#20013;&#26368;&#24120;&#29992;&#30340;&#26041;&#27861;&#20043;&#19968;&#65292;&#23545;&#20110;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#25104;&#21151;&#33267;&#20851;&#37325;&#35201;&#12290;&#23613;&#31649;&#20854;&#24615;&#33021;&#20196;&#20154;&#24778;&#21497;&#65292;&#20294;&#24456;&#23569;&#26377;&#38750;&#21551;&#21457;&#24335;&#30340;&#29702;&#35770;&#29992;&#20110;&#25551;&#36848;&#20854;&#24037;&#20316;&#26426;&#21046;&#12290;&#26412;&#25991;&#32473;&#20986;&#20102;&#20851;&#20110;&#38543;&#26426;&#25628;&#32034;&#30340;&#29702;&#35770;&#35299;&#37322;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#8220;&#25955;&#23556;&#32500;&#24230;&#8221;&#30340;&#27010;&#24565;&#65292;&#25551;&#36848;&#20102;&#24213;&#23618;&#20989;&#25968;&#30340;&#29366;&#24577;&#65292;&#24182;&#37327;&#21270;&#20102;&#38543;&#26426;&#25628;&#32034;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#24403;&#29615;&#22659;&#27809;&#26377;&#22122;&#22768;&#26102;&#65292;&#38543;&#26426;&#25628;&#32034;&#30340;&#36755;&#20986;&#20197;&#27010;&#29575;&#25910;&#25947;&#21040;&#26368;&#20248;&#20540;&#65292;&#20854;&#36895;&#29575;&#20026;$ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \right)^{ \frac{1}{d_s} } \right) $&#65292;&#20854;&#20013;$ d_s \ge 0 $&#26159;&#24213;&#23618;&#20989;&#25968;&#30340;&#25955;&#23556;&#32500;&#24230;&#12290;&#24403;&#35266;&#23519;&#21040;&#30340;&#20989;&#25968;&#20540;&#21463;&#21040;&#26377;&#30028;&#30340;&#29420;&#31435;&#21516;&#20998;&#24067;&#22122;&#22768;&#24433;&#21709;&#26102;&#65292;&#38543;&#26426;&#25628;&#32034;&#30340;&#36755;&#20986;&#20197;&#27010;&#29575;&#25910;&#25947;&#21040;&#26368;&#20248;&#20540;&#65292;&#36895;&#29575;&#20026;$ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \right)^{ \frac{2}{2+d_s} } \right) $&#12290;
&lt;/p&gt;
&lt;p&gt;
Random Search is one of the most widely-used method for Hyperparameter Optimization, and is critical to the success of deep learning models. Despite its astonishing performance, little non-heuristic theory has been developed to describe the underlying working mechanism. This paper gives a theoretical accounting of Random Search. We introduce the concept of \emph{scattering dimension} that describes the landscape of the underlying function, and quantifies the performance of random search. We show that, when the environment is noise-free, the output of random search converges to the optimal value in probability at rate $ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \right)^{ \frac{1}{d_s} } \right) $, where $ d_s \ge 0 $ is the scattering dimension of the underlying function. When the observed function values are corrupted by bounded $iid$ noise, the output of random search converges to the optimal value in probability at rate $ \widetilde{\mathcal{O}} \left( \left( \frac{1}{T} \rig
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992; kernel &#26041;&#27861;&#23398;&#20064;&#20855;&#26377;&#33021;&#38553;&#30340;&#37327;&#23376;&#21704;&#23494;&#39039;&#37327;&#22522;&#24577;&#30340;&#32479;&#35745;&#23398;&#20064;&#26041;&#27861;&#65292;&#29702;&#35770;&#19978;&#38656;&#35201;&#22810;&#39033;&#24335;&#36164;&#28304;&#23454;&#29616;&#65292;&#36890;&#36807;&#25968;&#20540;&#27169;&#25311;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#26041;&#27861;&#30340;&#28789;&#27963;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.08902</link><description>&lt;p&gt;
&#29992; Kernel &#26041;&#27861;&#23398;&#20064;&#20855;&#26377;&#33021;&#38553;&#30340;&#37327;&#23376;&#21704;&#23494;&#39039;&#37327;&#30340;&#22522;&#24577;
&lt;/p&gt;
&lt;p&gt;
Learning ground states of gapped quantum Hamiltonians with Kernel Methods. (arXiv:2303.08902v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.08902
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992; kernel &#26041;&#27861;&#23398;&#20064;&#20855;&#26377;&#33021;&#38553;&#30340;&#37327;&#23376;&#21704;&#23494;&#39039;&#37327;&#22522;&#24577;&#30340;&#32479;&#35745;&#23398;&#20064;&#26041;&#27861;&#65292;&#29702;&#35770;&#19978;&#38656;&#35201;&#22810;&#39033;&#24335;&#36164;&#28304;&#23454;&#29616;&#65292;&#36890;&#36807;&#25968;&#20540;&#27169;&#25311;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#26041;&#27861;&#30340;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#26469;&#36817;&#20284;&#37327;&#23376;&#21704;&#23494;&#39039;&#37327;&#22522;&#24577;&#30340;&#26041;&#27861;&#38656;&#35201;&#35299;&#20915;&#39640;&#24230;&#38750;&#32447;&#24615;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992; kernel &#26041;&#27861;&#26469;&#20351;&#20248;&#21270;&#21464;&#24471;&#31616;&#21333;&#30340;&#32479;&#35745;&#23398;&#20064;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#26696;&#26159;&#21151;&#29575;&#27861;&#30340;&#19968;&#31181;&#36817;&#20284;&#23454;&#29616;&#65292;&#20854;&#20013;&#36890;&#36807;&#30417;&#30563;&#23398;&#20064;&#26469;&#23398;&#20064;&#21151;&#29575;&#36845;&#20195;&#30340;&#19979;&#19968;&#27493;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#20551;&#35774;&#30417;&#30563;&#23398;&#20064;&#26159;&#26377;&#25928;&#30340;&#65292;&#37027;&#20040;&#21487;&#20197;&#20351;&#29992;&#22810;&#39033;&#24335;&#36164;&#28304;&#23454;&#29616;&#23545;&#20219;&#24847;&#20855;&#26377;&#33021;&#38553;&#30340;&#37327;&#23376;&#21704;&#23494;&#39039;&#37327;&#30340;&#22522;&#24577;&#24615;&#36136;&#30340;&#35745;&#31639;&#12290;&#25105;&#20204;&#20351;&#29992; kernel ridge &#22238;&#24402;&#65292;&#36890;&#36807;&#23545;&#19968;&#32500;&#21644;&#20108;&#32500;&#30340;&#20960;&#20010;&#20856;&#22411;&#30456;&#20114;&#20316;&#29992;&#22810;&#20307;&#37327;&#23376;&#31995;&#32479;&#36827;&#34892;&#22522;&#24577;&#30340;&#23547;&#25214;&#65292;&#25552;&#20379;&#20102;&#22522;&#20110;&#25968;&#20540;&#27169;&#25311;&#30340;&#35777;&#25454;&#65292;&#35777;&#26126;&#20102;&#23398;&#20064;&#20551;&#35774;&#30340;&#26377;&#25928;&#24615;&#65292;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural network approaches to approximate the ground state of quantum hamiltonians require the numerical solution of a highly nonlinear optimization problem. We introduce a statistical learning approach that makes the optimization trivial by using kernel methods. Our scheme is an approximate realization of the power method, where supervised learning is used to learn the next step of the power iteration. We show that the ground state properties of arbitrary gapped quantum hamiltonians can be reached with polynomial resources under the assumption that the supervised learning is efficient. Using kernel ridge regression, we provide numerical evidence that the learning assumption is verified by applying our scheme to find the ground states of several prototypical interacting many-body quantum systems, both in one and two dimensions, showing the flexibility of our approach.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#40654;&#26364;&#23376;&#27969;&#24418;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#20102;&#31616;&#21270;&#65292;&#25552;&#20986;&#20102;&#40654;&#26364;&#27491;&#24120;&#22352;&#26631;&#30340;&#24191;&#20041;&#29256;&#26412;&#65292;&#21487;&#29992;&#20110;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#30340;&#23376;&#27969;&#24418;&#20248;&#21270;&#65292;&#24182;&#20026;&#28145;&#24230;&#23398;&#20064;&#24320;&#21457;&#20102;&#39640;&#25928;&#30340;&#20108;&#38454;&#20248;&#21270;&#22120;&#65292;&#26080;&#38656;&#26174;&#24335;&#30697;&#38453;&#27714;&#36870;&#12290;</title><link>http://arxiv.org/abs/2302.09738</link><description>&lt;p&gt;
&#31616;&#21270;&#22522;&#20110;&#21160;&#37327;&#30340;&#40654;&#26364;&#23376;&#27969;&#24418;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Simplifying Momentum-based Riemannian Submanifold Optimization. (arXiv:2302.09738v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09738
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#40654;&#26364;&#23376;&#27969;&#24418;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#20102;&#31616;&#21270;&#65292;&#25552;&#20986;&#20102;&#40654;&#26364;&#27491;&#24120;&#22352;&#26631;&#30340;&#24191;&#20041;&#29256;&#26412;&#65292;&#21487;&#29992;&#20110;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#30340;&#23376;&#27969;&#24418;&#20248;&#21270;&#65292;&#24182;&#20026;&#28145;&#24230;&#23398;&#20064;&#24320;&#21457;&#20102;&#39640;&#25928;&#30340;&#20108;&#38454;&#20248;&#21270;&#22120;&#65292;&#26080;&#38656;&#26174;&#24335;&#30697;&#38453;&#27714;&#36870;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24102;&#26377;&#21160;&#37327;&#30340;&#40654;&#26364;&#23376;&#27969;&#24418;&#20248;&#21270;&#22312;&#35745;&#31639;&#19978;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#22240;&#20026;&#30830;&#20445;&#36845;&#20195;&#20445;&#25345;&#22312;&#23376;&#27969;&#24418;&#19978;&#36890;&#24120;&#38656;&#35201;&#35299;&#20915;&#22256;&#38590;&#30340;&#24494;&#20998;&#26041;&#31243;&#12290;&#26412;&#25991;&#38024;&#23545;&#20855;&#26377;&#20223;&#23556;&#19981;&#21464;&#24230;&#37327;&#30340;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#30340;&#23376;&#27969;&#24418;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#20102;&#31616;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#40654;&#26364;&#27491;&#24120;&#22352;&#26631;&#30340;&#24191;&#20041;&#29256;&#26412;&#65292;&#21487;&#20197;&#23558;&#38382;&#39064;&#21160;&#24577;&#22320;&#31616;&#21270;&#20026;&#27431;&#20960;&#37324;&#24471;&#26080;&#32422;&#26463;&#38382;&#39064;&#12290;&#25105;&#20204;&#20351;&#29992;&#25105;&#20204;&#30340;&#26041;&#27861;&#26469;&#35299;&#37322;&#21644;&#31616;&#21270;&#29616;&#26377;&#30340;&#32467;&#26500;&#21270;&#21327;&#26041;&#24046;&#26041;&#27861;&#65292;&#24182;&#20026;&#28145;&#24230;&#23398;&#20064;&#24320;&#21457;&#20102;&#39640;&#25928;&#30340;&#20108;&#38454;&#20248;&#21270;&#22120;&#65292;&#32780;&#26080;&#38656;&#26174;&#24335;&#30697;&#38453;&#27714;&#36870;&#12290;
&lt;/p&gt;
&lt;p&gt;
Riemannian submanifold optimization with momentum is computationally challenging because ensuring iterates remain on the submanifold often requires solving difficult differential equations. We simplify such optimization algorithms for the submanifold of symmetric positive-definite matrices with the affine invariant metric. We propose a generalized version of the Riemannian normal coordinates which dynamically trivializes the problem into a Euclidean unconstrained problem. We use our approach to explain and simplify existing approaches for structured covariances and develop efficient second-order optimizers for deep learning without explicit matrix inverses.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#27531;&#24046;&#32593;&#32476;&#20013;&#23485;&#24230;&#21644;&#28145;&#24230;&#30340;&#26497;&#38480;&#24773;&#20917;&#65292;&#21457;&#29616;&#24403;&#26525;&#24178;&#25353;&#27604;&#20363;&#32553;&#25918;&#26102;&#65292;&#24471;&#21040;&#30340;&#21327;&#26041;&#24046;&#32467;&#26500;&#26159;&#30456;&#21516;&#30340;&#12290;&#36825;&#19968;&#21457;&#29616;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#21363;&#20351;&#28145;&#24230;&#21644;&#23485;&#24230;&#22788;&#20110;&#30456;&#21516;&#38454;&#25968;&#30340;&#32593;&#32476;&#65292;&#26631;&#20934;&#30340;&#23485;&#24230;&#26080;&#38480;&#12289;&#28982;&#21518;&#28145;&#24230;&#36235;&#21521;&#26080;&#31351;&#30340;&#26041;&#27861;&#20063;&#33021;&#25552;&#20379;&#23454;&#38469;&#27934;&#35265;&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#36824;&#35777;&#26126;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#39044;&#28608;&#27963;&#20855;&#26377;&#39640;&#26031;&#20998;&#24067;&#65292;&#36825;&#23545;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#20855;&#26377;&#30452;&#25509;&#24212;&#29992;&#12290;&#36890;&#36807;&#22823;&#37327;&#27169;&#25311;&#23454;&#39564;&#35777;&#26126;&#20102;&#29702;&#35770;&#21457;&#29616;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.00453</link><description>&lt;p&gt;
&#28145;&#24230;&#27531;&#24046;&#32593;&#32476;&#20013;&#23485;&#24230;&#21644;&#28145;&#24230;&#26497;&#38480;&#30340;&#36890;&#34892;
&lt;/p&gt;
&lt;p&gt;
Width and Depth Limits Commute in Residual Networks. (arXiv:2302.00453v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.00453
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#27531;&#24046;&#32593;&#32476;&#20013;&#23485;&#24230;&#21644;&#28145;&#24230;&#30340;&#26497;&#38480;&#24773;&#20917;&#65292;&#21457;&#29616;&#24403;&#26525;&#24178;&#25353;&#27604;&#20363;&#32553;&#25918;&#26102;&#65292;&#24471;&#21040;&#30340;&#21327;&#26041;&#24046;&#32467;&#26500;&#26159;&#30456;&#21516;&#30340;&#12290;&#36825;&#19968;&#21457;&#29616;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#21363;&#20351;&#28145;&#24230;&#21644;&#23485;&#24230;&#22788;&#20110;&#30456;&#21516;&#38454;&#25968;&#30340;&#32593;&#32476;&#65292;&#26631;&#20934;&#30340;&#23485;&#24230;&#26080;&#38480;&#12289;&#28982;&#21518;&#28145;&#24230;&#36235;&#21521;&#26080;&#31351;&#30340;&#26041;&#27861;&#20063;&#33021;&#25552;&#20379;&#23454;&#38469;&#27934;&#35265;&#12290;&#27492;&#22806;&#65292;&#26412;&#25991;&#36824;&#35777;&#26126;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#39044;&#28608;&#27963;&#20855;&#26377;&#39640;&#26031;&#20998;&#24067;&#65292;&#36825;&#23545;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#20855;&#26377;&#30452;&#25509;&#24212;&#29992;&#12290;&#36890;&#36807;&#22823;&#37327;&#27169;&#25311;&#23454;&#39564;&#35777;&#26126;&#20102;&#29702;&#35770;&#21457;&#29616;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24102;&#26377;&#36339;&#36291;&#36830;&#25509;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#24403;&#26525;&#24178;&#25353;&#27604;&#20363;$1/\sqrt{depth}$&#32553;&#25918;&#26102;&#65292;&#23558;&#23485;&#24230;&#21644;&#28145;&#24230;&#36235;&#21521;&#26080;&#31351;&#24471;&#21040;&#30340;&#21327;&#26041;&#24046;&#32467;&#26500;&#26159;&#30456;&#21516;&#30340;&#12290;&#36825;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#26631;&#20934;&#30340;&#23485;&#24230;&#26080;&#38480;&#12289;&#28982;&#21518;&#28145;&#24230;&#36235;&#21521;&#26080;&#31351;&#30340;&#26041;&#27861;&#23545;&#20110;&#28145;&#24230;&#21644;&#23485;&#24230;&#22788;&#20110;&#30456;&#21516;&#38454;&#25968;&#30340;&#32593;&#32476;&#20063;&#33021;&#25552;&#20379;&#23454;&#38469;&#27934;&#35265;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#39044;&#28608;&#27963;&#20855;&#26377;&#39640;&#26031;&#20998;&#24067;&#65292;&#36825;&#22312;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#20013;&#20855;&#26377;&#30452;&#25509;&#24212;&#29992;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#22823;&#37327;&#27169;&#25311;&#23454;&#39564;&#65292;&#32467;&#26524;&#19982;&#29702;&#35770;&#21457;&#29616;&#38750;&#24120;&#21563;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
We show that taking the width and depth to infinity in a deep neural network with skip connections, when branches are scaled by $1/\sqrt{depth}$ (the only nontrivial scaling), result in the same covariance structure no matter how that limit is taken. This explains why the standard infinite-width-then-depth approach provides practical insights even for networks with depth of the same order as width. We also demonstrate that the pre-activations, in this case, have Gaussian distributions which has direct applications in Bayesian deep learning. We conduct extensive simulations that show an excellent match with our theoretical findings.
&lt;/p&gt;</description></item><item><title>&#21151;&#33021;&#24615;&#31070;&#32463;&#32593;&#32476;&#65288;FNNs&#65289;&#26159;&#19968;&#31181;&#26032;&#30340;&#31070;&#32463;&#32593;&#32476;&#31867;&#21035;&#65292;&#20855;&#26377;&#20301;&#31227;&#19981;&#21464;&#24615;&#21644;&#20445;&#25345;&#25968;&#25454;&#24179;&#28369;&#24615;&#30340;&#29305;&#28857;&#12290;&#22312;&#33041;&#30005;&#22270;&#20998;&#31867;&#20219;&#21153;&#20013;&#65292;FNNs&#30340;&#27169;&#22411;&#34920;&#29616;&#20248;&#20110;&#22522;&#20934;&#27169;&#22411;&#24182;&#33021;&#25104;&#21151;&#36827;&#34892;&#20998;&#31867;&#12290;</title><link>http://arxiv.org/abs/2301.05869</link><description>&lt;p&gt;
&#21151;&#33021;&#24615;&#31070;&#32463;&#32593;&#32476;&#65306;&#29992;&#20110;&#21151;&#33021;&#25968;&#25454;&#30340;&#20301;&#31227;&#19981;&#21464;&#27169;&#22411;&#21450;&#20854;&#22312;&#33041;&#30005;&#22270;&#20998;&#31867;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Functional Neural Networks: Shift invariant models for functional data with applications to EEG classification. (arXiv:2301.05869v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.05869
&lt;/p&gt;
&lt;p&gt;
&#21151;&#33021;&#24615;&#31070;&#32463;&#32593;&#32476;&#65288;FNNs&#65289;&#26159;&#19968;&#31181;&#26032;&#30340;&#31070;&#32463;&#32593;&#32476;&#31867;&#21035;&#65292;&#20855;&#26377;&#20301;&#31227;&#19981;&#21464;&#24615;&#21644;&#20445;&#25345;&#25968;&#25454;&#24179;&#28369;&#24615;&#30340;&#29305;&#28857;&#12290;&#22312;&#33041;&#30005;&#22270;&#20998;&#31867;&#20219;&#21153;&#20013;&#65292;FNNs&#30340;&#27169;&#22411;&#34920;&#29616;&#20248;&#20110;&#22522;&#20934;&#27169;&#22411;&#24182;&#33021;&#25104;&#21151;&#36827;&#34892;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#32479;&#35745;&#27169;&#22411;&#26469;&#35828;&#65292;&#29420;&#31435;&#20110;&#20301;&#32622;&#22320;&#26816;&#27979;&#24863;&#20852;&#36259;&#30340;&#20449;&#21495;&#26159;&#24456;&#29702;&#24819;&#30340;&#12290;&#22914;&#26524;&#25968;&#25454;&#30001;&#26576;&#20010;&#24179;&#28369;&#36807;&#31243;&#29983;&#25104;&#65292;&#37027;&#20040;&#36825;&#31181;&#38468;&#21152;&#32467;&#26500;&#24212;&#35813;&#34987;&#32771;&#34385;&#36827;&#21435;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#31070;&#32463;&#32593;&#32476;&#31867;&#21035;&#65292;&#23427;&#20204;&#20855;&#26377;&#20301;&#31227;&#19981;&#21464;&#24615;&#24182;&#20445;&#25345;&#25968;&#25454;&#30340;&#24179;&#28369;&#24615;&#65306;&#21151;&#33021;&#24615;&#31070;&#32463;&#32593;&#32476;&#65288;FNNs&#65289;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#20351;&#29992;&#21151;&#33021;&#25968;&#25454;&#20998;&#26512;&#65288;FDA&#65289;&#30340;&#26041;&#27861;&#26469;&#25193;&#23637;&#22810;&#23618;&#24863;&#30693;&#22120;&#21644;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#20197;&#36866;&#24212;&#21151;&#33021;&#25968;&#25454;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19981;&#21516;&#30340;&#27169;&#22411;&#26550;&#26500;&#65292;&#35777;&#26126;&#36825;&#20123;&#27169;&#22411;&#22312;&#20934;&#30830;&#24615;&#19978;&#20248;&#20110;FDA&#30340;&#22522;&#20934;&#27169;&#22411;&#65292;&#24182;&#25104;&#21151;&#22320;&#20351;&#29992;FNNs&#23545;&#33041;&#30005;&#22270;&#25968;&#25454;&#36827;&#34892;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is desirable for statistical models to detect signals of interest independently of their position. If the data is generated by some smooth process, this additional structure should be taken into account. We introduce a new class of neural networks that are shift invariant and preserve smoothness of the data: functional neural networks (FNNs). For this, we use methods from functional data analysis (FDA) to extend multi-layer perceptrons and convolutional neural networks to functional data. We propose different model architectures, show that the models outperform a benchmark model from FDA in terms of accuracy and successfully use FNNs to classify electroencephalography (EEG) data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#19982;&#20316;&#32773;&#24341;&#20837;&#30340;&#19968;&#31181;&#26032;&#30340;&#30456;&#20851;&#31995;&#25968;&#30456;&#20851;&#30340;&#20851;&#32852;&#24230;&#27979;&#37327;&#26041;&#27861;&#30340;&#19968;&#20123;&#26368;&#26032;&#21457;&#23637;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#23545;&#26631;&#20934;Borel&#31354;&#38388;&#30340;&#30452;&#25509;&#25512;&#24191;&#12290;</title><link>http://arxiv.org/abs/2211.04702</link><description>&lt;p&gt;
&#20851;&#32852;&#24230;&#27979;&#37327;&#26041;&#27861;&#30340;&#19968;&#20123;&#26368;&#26032;&#21457;&#23637;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A survey of some recent developments in measures of association. (arXiv:2211.04702v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.04702
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#19982;&#20316;&#32773;&#24341;&#20837;&#30340;&#19968;&#31181;&#26032;&#30340;&#30456;&#20851;&#31995;&#25968;&#30456;&#20851;&#30340;&#20851;&#32852;&#24230;&#27979;&#37327;&#26041;&#27861;&#30340;&#19968;&#20123;&#26368;&#26032;&#21457;&#23637;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#23545;&#26631;&#20934;Borel&#31354;&#38388;&#30340;&#30452;&#25509;&#25512;&#24191;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#19982;&#20316;&#32773;&#24341;&#20837;&#30340;&#19968;&#31181;&#26032;&#30340;&#30456;&#20851;&#31995;&#25968;&#30456;&#20851;&#30340;&#20851;&#32852;&#24230;&#27979;&#37327;&#26041;&#27861;&#30340;&#19968;&#20123;&#26368;&#26032;&#21457;&#23637;&#12290;&#24182;&#22312;&#32508;&#36848;&#30340;&#26368;&#21518;&#25552;&#20986;&#20102;&#19968;&#20010;&#23545;&#26631;&#20934;Borel&#31354;&#38388;&#65288;&#21253;&#25324;&#25152;&#26377;&#27874;&#20848;&#31354;&#38388;&#65289;&#30340;&#30452;&#25509;&#25512;&#24191;&#65292;&#36825;&#19968;&#25512;&#24191;&#22312;&#25991;&#29486;&#20013;&#36804;&#20170;&#34987;&#24573;&#35270;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper surveys some recent developments in measures of association related to a new coefficient of correlation introduced by the author. A straightforward extension of this coefficient to standard Borel spaces (which includes all Polish spaces), overlooked in the literature so far, is proposed at the end of the survey.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#36870;&#25193;&#23637; Kalman &#28388;&#27874;&#22120; (I-EKF) &#26469;&#35299;&#20915;&#38750;&#32447;&#24615;&#31995;&#32479;&#20013;&#30340;&#36870;&#36807;&#28388;&#38382;&#39064;&#65292;&#24182;&#25299;&#23637;&#20102;&#35813;&#29702;&#35770;&#20197;&#24212;&#23545;&#39640;&#24230;&#38750;&#32447;&#24615;&#27169;&#22411;&#12290;&#21516;&#26102;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#26041;&#26696;&#65292;&#35299;&#20915;&#26631;&#20934; I-EKF &#30340;&#23616;&#38480;&#24615;&#12290;</title><link>http://arxiv.org/abs/2208.06683</link><description>&lt;p&gt;
Inverse Extended Kalman Filter -- Part II: Highly Non-Linear and Uncertain Systems.
&lt;/p&gt;
&lt;p&gt;
Inverse Extended Kalman Filter -- Part II: Highly Non-Linear and Uncertain Systems. (arXiv:2208.06683v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.06683
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#36870;&#25193;&#23637; Kalman &#28388;&#27874;&#22120; (I-EKF) &#26469;&#35299;&#20915;&#38750;&#32447;&#24615;&#31995;&#32479;&#20013;&#30340;&#36870;&#36807;&#28388;&#38382;&#39064;&#65292;&#24182;&#25299;&#23637;&#20102;&#35813;&#29702;&#35770;&#20197;&#24212;&#23545;&#39640;&#24230;&#38750;&#32447;&#24615;&#27169;&#22411;&#12290;&#21516;&#26102;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#26041;&#26696;&#65292;&#35299;&#20915;&#26631;&#20934; I-EKF &#30340;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#23545;&#25239;&#24615;&#31995;&#32479;&#35774;&#35745;&#38382;&#39064;&#25512;&#21160;&#20102;&#36870;&#36125;&#21494;&#26031;&#28388;&#27874;&#22120;&#30340;&#21457;&#23637;&#12290;&#20363;&#22914;&#65292;&#26368;&#36817;&#25552;&#20986;&#20102;&#36870; Kalman &#28388;&#27874;&#22120; (I-KF)&#65292;&#29992;&#20110;&#20272;&#35745;&#23545;&#25163;&#30340; Kalman &#28388;&#27874;&#36319;&#36394;&#20272;&#35745;&#65292;&#20174;&#32780;&#39044;&#27979;&#23545;&#25163;&#30340;&#26410;&#26469;&#27493;&#39588;&#12290;&#26412;&#35770;&#25991;&#21450;&#20854;&#20276;&#38543;&#35770;&#25991; (Part I) &#30340;&#30446;&#30340;&#26159;&#36890;&#36807;&#25552;&#20986;&#36870;&#25193;&#23637; Kalman &#28388;&#27874;&#22120; (I-EKF) &#26469;&#35299;&#20915;&#38750;&#32447;&#24615;&#31995;&#32479;&#20013;&#30340;&#36870;&#36807;&#28388;&#38382;&#39064;&#12290;&#20276;&#38543;&#35770;&#25991;&#25552;&#20986;&#20102; I-EKF (&#20855;&#26377;&#21644;&#19981;&#20855;&#26377;&#26410;&#30693;&#36755;&#20837;) &#21644; I-KF (&#20855;&#26377;&#26410;&#30693;&#36755;&#20837;) &#30340;&#29702;&#35770;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23545;&#39640;&#24230;&#38750;&#32447;&#24615;&#27169;&#22411;&#30340;&#35813;&#29702;&#35770;&#36827;&#34892;&#20102;&#25299;&#23637;&#65292;&#35813;&#27169;&#22411;&#37319;&#29992;&#20108;&#38454;&#12289;&#39640;&#26031;&#21644;&#25238;&#21160;&#21069;&#21521; EKF&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#36890;&#36807;&#26377;&#30028;&#38750;&#32447;&#24615;&#26041;&#27861;&#25512;&#23548;&#20102;&#36870;&#20108;&#38454; EKF &#30340;&#29702;&#35770;&#31283;&#23450;&#24615;&#20445;&#35777;&#12290;&#20026;&#20102;&#35299;&#20915;&#26631;&#20934; I-EKF &#30340;&#23616;&#38480;&#24615;&#65292;&#21363;&#31995;&#32479;&#27169;&#22411;&#21644;&#21069;&#21521;&#28388;&#27874;&#22120;&#23545;&#38450;&#24481;&#32773;&#26469;&#35828;&#26159;&#23436;&#20840;&#24050;&#30693;&#30340;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Counter-adversarial system design problems have lately motivated the development of inverse Bayesian filters. For example, inverse Kalman filter (I-KF) has been recently formulated to estimate the adversary's Kalman-filter-tracked estimates and hence, predict the adversary's future steps. The purpose of this paper and the companion paper (Part I) is to address the inverse filtering problem in non-linear systems by proposing an inverse extended Kalman filter (I-EKF). The companion paper proposed the theory of I-EKF (with and without unknown inputs) and I-KF (with unknown inputs). In this paper, we develop this theory for highly non-linear models, which employ second-order, Gaussian sum, and dithered forward EKFs. In particular, we derive theoretical stability guarantees for the inverse second-order EKF using the bounded non-linearity approach. To address the limitation of the standard I-EKFs that the system model and forward filter are perfectly known to the defender, we propose reprodu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#20219;&#21153;&#31232;&#30095;&#22238;&#24402;&#30340;&#36873;&#25321;&#25512;&#26029;&#26694;&#26550;&#65292;&#22312;&#31070;&#32463;&#24433;&#20687;&#23398;&#20013;&#24212;&#29992;&#65292;&#21487;&#20197;&#25552;&#39640;&#24314;&#27169;&#31934;&#24230;&#21644;&#39044;&#27979;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2205.14220</link><description>&lt;p&gt;
&#22810;&#20219;&#21153;&#31232;&#30095;&#22238;&#24402;&#30340;&#36873;&#25321;&#25512;&#26029;&#21450;&#20854;&#22312;&#31070;&#32463;&#24433;&#20687;&#23398;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Selective Inference for Sparse Multitask Regression with Applications in Neuroimaging. (arXiv:2205.14220v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.14220
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#20219;&#21153;&#31232;&#30095;&#22238;&#24402;&#30340;&#36873;&#25321;&#25512;&#26029;&#26694;&#26550;&#65292;&#22312;&#31070;&#32463;&#24433;&#20687;&#23398;&#20013;&#24212;&#29992;&#65292;&#21487;&#20197;&#25552;&#39640;&#24314;&#27169;&#31934;&#24230;&#21644;&#39044;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20219;&#21153;&#23398;&#20064;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#20174;&#21516;&#19968;&#29305;&#24449;&#38598;&#20013;&#27169;&#25311;&#19968;&#32452;&#30456;&#20851;&#21709;&#24212;&#21464;&#37327;&#65292;&#30456;&#27604;&#20110;&#21333;&#29420;&#22788;&#29702;&#27599;&#20010;&#21709;&#24212;&#21464;&#37327;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#25552;&#39640;&#39044;&#27979;&#24615;&#33021;&#21644;&#24314;&#27169;&#31934;&#24230;&#12290;&#20294;&#22810;&#20219;&#21153;&#23398;&#20064;&#22312;&#25512;&#26029;&#19981;&#30830;&#23450;&#24615;&#26041;&#38754;&#30340;&#30740;&#31350;&#36824;&#36739;&#23569;&#12290;&#26412;&#25991;&#36890;&#36807;&#31232;&#30095;&#24615;&#20449;&#21495;&#21152;&#24378;&#26041;&#27861;&#65292;&#38024;&#23545;&#31070;&#32463;&#24433;&#20687;&#23398;&#20013;&#30340;&#24120;&#35265;&#22810;&#20219;&#21153;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36873;&#25321;&#25512;&#26029;&#26694;&#26550;&#65292;&#20855;&#26377;&#28789;&#27963;&#24615;&#65292;&#21487;&#20197;&#21516;&#26102;&#35782;&#21035;&#20986;&#27599;&#20010;&#20219;&#21153;&#30456;&#20851;&#30340;&#21327;&#21464;&#37327;&#65292;&#24182;&#24314;&#31435;&#22522;&#20110;&#31232;&#30095;&#32467;&#26500;&#30340;&#26377;&#25928;&#25512;&#26029;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-task learning is frequently used to model a set of related response variables from the same set of features, improving predictive performance and modeling accuracy relative to methods that handle each response variable separately. Despite the potential of multi-task learning to yield more powerful inference than single-task alternatives, prior work in this area has largely omitted uncertainty quantification. Our focus in this paper is a common multi-task problem in neuroimaging, where the goal is to understand the relationship between multiple cognitive task scores (or other subject-level assessments) and brain connectome data collected from imaging. We propose a framework for selective inference to address this problem, with the flexibility to: (i) jointly identify the relevant covariates for each task through a sparsity-inducing penalty, and (ii) conduct valid inference in a model based on the estimated sparsity structure. Our framework offers a new conditional procedure for in
&lt;/p&gt;</description></item><item><title>InfoNCE&#30446;&#26631;&#22312;&#35782;&#21035;&#21442;&#25968;&#21270;&#27169;&#22411;&#20013;&#31561;&#21516;&#20110;ELBO&#65292;&#22312;&#23398;&#20064;&#26368;&#20248;&#20808;&#39564;&#26102;&#21464;&#20026;&#20114;&#20449;&#24687;&#65292;&#24182;&#19982;&#33258;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#24314;&#31435;&#20102;&#32852;&#31995;&#12290;&#28982;&#32780;&#65292;&#23454;&#38469;&#30340;InfoNCE&#30446;&#26631;&#26159;&#23545;&#20114;&#20449;&#24687;&#30340;&#26494;&#25955;&#19979;&#30028;&#65292;&#20197;&#36991;&#20813;&#39640;&#24230;&#32416;&#32544;&#30340;&#34920;&#31034;&#12290;</title><link>http://arxiv.org/abs/2107.02495</link><description>&lt;p&gt;
InfoNCE&#26159;&#35782;&#21035;&#21442;&#25968;&#21270;&#27169;&#22411;&#20013;&#30340;&#21464;&#20998;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
InfoNCE is variational inference in a recognition parameterised model. (arXiv:2107.02495v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2107.02495
&lt;/p&gt;
&lt;p&gt;
InfoNCE&#30446;&#26631;&#22312;&#35782;&#21035;&#21442;&#25968;&#21270;&#27169;&#22411;&#20013;&#31561;&#21516;&#20110;ELBO&#65292;&#22312;&#23398;&#20064;&#26368;&#20248;&#20808;&#39564;&#26102;&#21464;&#20026;&#20114;&#20449;&#24687;&#65292;&#24182;&#19982;&#33258;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#24314;&#31435;&#20102;&#32852;&#31995;&#12290;&#28982;&#32780;&#65292;&#23454;&#38469;&#30340;InfoNCE&#30446;&#26631;&#26159;&#23545;&#20114;&#20449;&#24687;&#30340;&#26494;&#25955;&#19979;&#30028;&#65292;&#20197;&#36991;&#20813;&#39640;&#24230;&#32416;&#32544;&#30340;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#23637;&#31034;InfoNCE&#30446;&#26631;&#31561;&#21516;&#20110;&#19968;&#31181;&#26032;&#22411;&#27010;&#29575;&#29983;&#25104;&#27169;&#22411;&#8212;&#8212;&#35782;&#21035;&#21442;&#25968;&#21270;&#27169;&#22411;&#65288;RPM&#65289;&#20013;&#30340;ELBO&#12290;&#24403;&#25105;&#20204;&#23398;&#20064;&#26368;&#20248;&#20808;&#39564;&#26102;&#65292;RPM ELBO&#21464;&#25104;&#20102;&#20114;&#20449;&#24687;&#65288;MI&#65307;&#38500;&#20102;&#19968;&#20010;&#24120;&#25968;&#65289;&#65292;&#20174;&#32780;&#19982;&#20043;&#21069;&#23384;&#22312;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#65288;&#22914;InfoNCE&#65289;&#24314;&#31435;&#20102;&#32852;&#31995;&#12290;&#28982;&#32780;&#65292;&#23454;&#38469;&#30340;InfoNCE&#26041;&#27861;&#24182;&#19981;&#20351;&#29992;MI&#20316;&#20026;&#30446;&#26631;&#65307;MI&#23545;&#20110;&#20219;&#24847;&#21487;&#36870;&#21464;&#25442;&#26159;&#19981;&#21464;&#30340;&#65292;&#22240;&#27492;&#20351;&#29992;MI&#30446;&#26631;&#21487;&#33021;&#23548;&#33268;&#39640;&#24230;&#32416;&#32544;&#30340;&#34920;&#31034;&#65288;Tschannen et al.&#65292;2019&#65289;&#12290;&#30456;&#21453;&#65292;&#23454;&#38469;&#30340;InfoNCE&#30446;&#26631;&#26159;&#23545;MI&#30340;&#19968;&#20010;&#31616;&#21270;&#19979;&#30028;&#65292;&#21363;&#20351;&#22312;&#26080;&#38480;&#26679;&#26412;&#26497;&#38480;&#19979;&#20063;&#19981;&#32039;&#23494;&#12290;&#22240;&#27492;&#65292;&#19968;&#20010;&#26377;&#25928;&#30340;&#30446;&#26631;&#65288;&#21363;&#23454;&#38469;&#30340;InfoNCE&#30446;&#26631;&#65289;&#20284;&#20046;&#26159;&#23545;&#19968;&#20010;&#26080;&#25928;&#30340;&#30446;&#26631;&#65288;&#21363;&#32473;&#20986;&#20219;&#24847;&#32416;&#32544;&#34920;&#31034;&#30340;&#30495;&#23454;MI&#65289;&#30340;&#26494;&#25955;&#19979;&#30028;&#30340;&#21160;&#26426;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#23454;&#38469;&#30340;InfoNCE&#30446;&#26631;&#30340;&#21478;&#19968;&#31181;&#21160;&#26426;&#12290;&#22312;&#30446;&#24405;&#20013;
&lt;/p&gt;
&lt;p&gt;
Here, we show that the InfoNCE objective is equivalent to the ELBO in a new class of probabilistic generative model, the recognition parameterised model (RPM). When we learn the optimal prior, the RPM ELBO becomes equal to the mutual information (MI; up to a constant), establishing a connection to pre-existing self-supervised learning methods such as InfoNCE. However, practical InfoNCE methods do not use the MI as an objective; the MI is invariant to arbitrary invertible transformations, so using an MI objective can lead to highly entangled representations (Tschannen et al., 2019). Instead, the actual InfoNCE objective is a simplified lower bound on the MI which is loose even in the infinite sample limit. Thus, an objective that works (i.e. the actual InfoNCE objective) appears to be motivated as a loose bound on an objective that does not work (i.e. the true MI which gives arbitrarily entangled representations). We give an alternative motivation for the actual InfoNCE objective. In pa
&lt;/p&gt;</description></item></channel></rss>