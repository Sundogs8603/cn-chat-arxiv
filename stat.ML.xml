<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#23558;&#21160;&#24577;&#36710;&#36742;&#35843;&#24230;&#38382;&#39064;&#24314;&#27169;&#20026;&#21322;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#22522;&#20110;&#20107;&#20214;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#23454;&#38469;&#22330;&#26223;&#30340;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.07508</link><description>&lt;p&gt;
&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#29992;&#20110;&#21160;&#24577;&#36710;&#36742;&#35843;&#24230;&#38382;&#39064;&#30340;&#22522;&#20110;&#20107;&#20214;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Deep reinforcement learning for the dynamic vehicle dispatching problem: An event-based approach. (arXiv:2307.07508v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07508
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#23558;&#21160;&#24577;&#36710;&#36742;&#35843;&#24230;&#38382;&#39064;&#24314;&#27169;&#20026;&#21322;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#22522;&#20110;&#20107;&#20214;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#23454;&#38469;&#22330;&#26223;&#30340;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21160;&#24577;&#36710;&#36742;&#35843;&#24230;&#38382;&#39064;&#28041;&#21450;&#20915;&#23450;&#23558;&#21738;&#20123;&#36710;&#36742;&#20998;&#37197;&#32473;&#38543;&#26426;&#20135;&#29983;&#30340;&#26102;&#38388;&#21644;&#31354;&#38388;&#35831;&#27714;&#12290;&#35813;&#38382;&#39064;&#20986;&#29616;&#22312;&#21508;&#20010;&#39046;&#22495;&#65292;&#22914;&#23558;&#21345;&#36710;&#20998;&#37197;&#32473;&#35201;&#36816;&#36755;&#30340;&#36135;&#29289;&#12289;&#24212;&#24613;&#31995;&#32479;&#21644;&#39034;&#39118;&#36710;&#26381;&#21153;&#20013;&#12290;&#26412;&#25991;&#23558;&#35813;&#38382;&#39064;&#24314;&#27169;&#20026;&#21322;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65292;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#23558;&#26102;&#38388;&#35270;&#20026;&#36830;&#32493;&#21464;&#37327;&#12290;&#22312;&#27492;&#35774;&#32622;&#20013;&#65292;&#20915;&#31574;&#26102;&#21051;&#19982;&#20107;&#20214;&#19968;&#33268;&#65292;&#20854;&#26102;&#38388;&#38388;&#38548;&#26159;&#38543;&#26426;&#30340;&#12290;&#25105;&#20204;&#35748;&#20026;&#22522;&#20110;&#20107;&#20214;&#30340;&#26041;&#27861;&#22823;&#22823;&#38477;&#20302;&#20102;&#20915;&#31574;&#31354;&#38388;&#30340;&#32452;&#21512;&#22797;&#26434;&#24615;&#65292;&#24182;&#20811;&#26381;&#20102;&#25991;&#29486;&#20013;&#24120;&#25552;&#20986;&#30340;&#31163;&#25955;&#26102;&#38388;&#27169;&#22411;&#30340;&#20854;&#20182;&#23616;&#38480;&#24615;&#12290;&#20026;&#20102;&#27979;&#35797;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#26032;&#30340;&#31163;&#25955;&#20107;&#20214;&#27169;&#25311;&#22120;&#65292;&#24182;&#20351;&#29992;&#21452;&#28145;&#24230;Q&#23398;&#20064;&#35757;&#32451;&#25105;&#20204;&#30340;&#20915;&#31574;&#20195;&#29702;&#12290;&#22312;&#20351;&#29992;&#32445;&#32422;&#24066;&#30340;&#25968;&#25454;&#36827;&#34892;&#23454;&#38469;&#22330;&#26223;&#30340;&#25968;&#20540;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#23558;&#36890;&#36807;&#25105;&#20204;&#30340;&#26041;&#27861;&#33719;&#24471;&#30340;&#31574;&#30053;&#19982;&#21551;&#21457;&#24335;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
The dynamic vehicle dispatching problem corresponds to deciding which vehicles to assign to requests that arise stochastically over time and space. It emerges in diverse areas, such as in the assignment of trucks to loads to be transported; in emergency systems; and in ride-hailing services. In this paper, we model the problem as a semi-Markov decision process, which allows us to treat time as continuous. In this setting, decision epochs coincide with discrete events whose time intervals are random. We argue that an event-based approach substantially reduces the combinatorial complexity of the decision space and overcomes other limitations of discrete-time models often proposed in the literature. In order to test our approach, we develop a new discrete-event simulator and use double deep q-learning to train our decision agents. Numerical experiments are carried out in realistic scenarios using data from New York City. We compare the policies obtained through our approach with heuristic
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#30740;&#31350;&#23545;&#35282;&#32447;&#24615;&#32593;&#32476;&#65288;DLNs&#65289;&#30340;&#26799;&#24230;&#27969;&#25152;&#26045;&#21152;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#65292;&#24847;&#22806;&#22320;&#19982;&#24191;&#20041;&#36817;&#20284;&#38590;&#24230;&#65288;GHA&#65289;&#20013;&#30340;&#30456;&#21464;&#29616;&#35937;&#32852;&#31995;&#36215;&#26469;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#27492;&#30340;&#38160;&#21033;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2307.07410</link><description>&lt;p&gt;
AI&#20013;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#19982;&#20248;&#21270;&#20013;&#30340;&#24191;&#20041;&#36817;&#20284;&#38590;&#24230;&#30456;&#36935;--&#23545;&#23545;&#35282;&#32447;&#24615;&#32593;&#32476;&#30340;&#38160;&#21033;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Implicit regularization in AI meets generalized hardness of approximation in optimization -- Sharp results for diagonal linear networks. (arXiv:2307.07410v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07410
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#30740;&#31350;&#23545;&#35282;&#32447;&#24615;&#32593;&#32476;&#65288;DLNs&#65289;&#30340;&#26799;&#24230;&#27969;&#25152;&#26045;&#21152;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#65292;&#24847;&#22806;&#22320;&#19982;&#24191;&#20041;&#36817;&#20284;&#38590;&#24230;&#65288;GHA&#65289;&#20013;&#30340;&#30456;&#21464;&#29616;&#35937;&#32852;&#31995;&#36215;&#26469;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#27492;&#30340;&#38160;&#21033;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#21644;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#26041;&#27861;&#25152;&#26045;&#21152;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#26159;&#28145;&#24230;&#23398;&#20064;&#21644;&#20154;&#24037;&#26234;&#33021;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#38024;&#23545;&#36229;&#21442;&#25968;&#22238;&#24402;&#35774;&#32622;&#25552;&#20379;&#20102;&#23545;&#20110;&#23545;&#35282;&#32447;&#24615;&#32593;&#32476;&#65288;DLNs&#65289;&#30340;&#26799;&#24230;&#27969;&#25152;&#26045;&#21152;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#30340;&#38160;&#21033;&#32467;&#26524;&#65292;&#24182;&#24847;&#22806;&#22320;&#23558;&#20854;&#19982;&#24191;&#20041;&#36817;&#20284;&#38590;&#24230;&#65288;GHA&#65289;&#20013;&#30340;&#30456;&#21464;&#29616;&#35937;&#32852;&#31995;&#36215;&#26469;&#12290;GHA&#23558;&#36817;&#20284;&#38590;&#24230;&#30340;&#29616;&#35937;&#20174;&#35745;&#31639;&#26426;&#31185;&#23398;&#25512;&#24191;&#21040;&#36830;&#32493;&#21644;&#40065;&#26834;&#20248;&#21270;&#31561;&#39046;&#22495;&#12290;&#20247;&#25152;&#21608;&#30693;&#65292;&#20855;&#26377;&#24494;&#23567;&#21021;&#22987;&#21270;&#30340;DLNs&#30340;&#26799;&#24230;&#27969;&#30340;$\ell^1$-&#33539;&#25968;&#25910;&#25947;&#21040;&#22522;&#30784;&#36861;&#36394;&#30340;&#30446;&#26631;&#20989;&#25968;&#12290;&#25105;&#20204;&#36890;&#36807;&#23637;&#31034;&#20855;&#26377;&#24494;&#23567;&#21021;&#22987;&#21270;&#30340;DLNs&#30340;&#26799;&#24230;&#27969;&#36817;&#20284;&#20110;&#22522;&#30784;&#36861;&#36394;&#20248;&#21270;&#38382;&#39064;&#30340;&#26368;&#23567;&#21270;&#22120;&#65288;&#32780;&#19981;&#20165;&#20165;&#26159;&#30446;&#26631;&#20989;&#25968;&#65289;&#65292;&#36827;&#19968;&#27493;&#25913;&#36827;&#20102;&#36825;&#20123;&#32467;&#26524;&#65292;&#24182;&#33719;&#24471;&#20102;&#26032;&#30340;&#38160;&#21033;&#25910;&#25947;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding the implicit regularization imposed by neural network architectures and gradient based optimization methods is a key challenge in deep learning and AI. In this work we provide sharp results for the implicit regularization imposed by the gradient flow of Diagonal Linear Networks (DLNs) in the over-parameterized regression setting and, potentially surprisingly, link this to the phenomenon of phase transitions in generalized hardness of approximation (GHA). GHA generalizes the phenomenon of hardness of approximation from computer science to, among others, continuous and robust optimization. It is well-known that the $\ell^1$-norm of the gradient flow of DLNs with tiny initialization converges to the objective function of basis pursuit. We improve upon these results by showing that the gradient flow of DLNs with tiny initialization approximates minimizers of the basis pursuit optimization problem (as opposed to just the objective function), and we obtain new and sharp converg
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#31232;&#30095;&#20984;&#20248;&#21270;&#20013;$\ell_1$&#27491;&#21017;&#21270;&#30340;&#24615;&#33021;&#65292;&#32473;&#20986;&#20102;Group LASSO&#30340;&#24674;&#22797;&#20445;&#35777;&#65292;&#24182;&#19988;&#21457;&#29616;&#20102;Group LASSO&#36873;&#25321;&#30456;&#21516;&#29305;&#24449;&#38598;&#30340;&#26426;&#21046;&#12290;</title><link>http://arxiv.org/abs/2307.07405</link><description>&lt;p&gt;
$\ell_1$&#27491;&#21017;&#21270;&#22312;&#31232;&#30095;&#20984;&#20248;&#21270;&#20013;&#30340;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;
Performance of $\ell_1$ Regularization for Sparse Convex Optimization. (arXiv:2307.07405v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07405
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#31232;&#30095;&#20984;&#20248;&#21270;&#20013;$\ell_1$&#27491;&#21017;&#21270;&#30340;&#24615;&#33021;&#65292;&#32473;&#20986;&#20102;Group LASSO&#30340;&#24674;&#22797;&#20445;&#35777;&#65292;&#24182;&#19988;&#21457;&#29616;&#20102;Group LASSO&#36873;&#25321;&#30456;&#21516;&#29305;&#24449;&#38598;&#30340;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;LASSO&#21644;Group LASSO&#22312;&#23454;&#36341;&#20013;&#34987;&#24191;&#27867;&#37319;&#29992;, &#20294;&#26159;&#23545;&#20110;&#38500;&#20102;&#32479;&#35745;&#38382;&#39064;&#20197;&#22806;&#30340;&#20854;&#20182;&#24773;&#20917;, &#36825;&#20123;&#31639;&#27861;&#30340;&#20445;&#35777;&#20196;&#20154;&#38663;&#24778;&#22320;&#32570;&#20047;, &#24182;&#19988;&#22312;&#30830;&#23450;&#24615;&#36755;&#20837;&#30340;&#31232;&#30095;&#20984;&#20248;&#21270;&#32972;&#26223;&#19979;&#36890;&#24120;&#34987;&#35748;&#20026;&#26159;&#19968;&#31181;&#21551;&#21457;&#24335;&#31639;&#27861;&#12290;&#25105;&#20204;&#20026;&#20855;&#26377;&#21521;&#37327;&#20540;&#29305;&#24449;&#30340;&#31232;&#30095;&#20984;&#20248;&#21270;&#30340;Group LASSO&#32473;&#20986;&#20102;&#31532;&#19968;&#20010;&#24674;&#22797;&#20445;&#35777;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#65292;&#22914;&#26524;&#22312;&#26368;&#23567;&#21270;&#20005;&#26684;&#20984;&#20989;&#25968;$l$&#26102;&#24212;&#29992;&#36275;&#22815;&#22823;&#30340;Group LASSO&#27491;&#21017;&#21270;&#65292;&#37027;&#20040;&#26497;&#23567;&#21270;&#22120;&#26159;&#22312;&#20855;&#26377;&#26368;&#22823;&#26799;&#24230;&#30340;$\ell_2$&#33539;&#25968;&#30340;&#21521;&#37327;&#20540;&#29305;&#24449;&#19978;&#25903;&#25345;&#30340;&#31232;&#30095;&#21521;&#37327;&#12290;&#22240;&#27492;&#65292;&#37325;&#22797;&#27492;&#36807;&#31243;&#36873;&#25321;&#19982;&#27491;&#20132;&#21305;&#37197;&#36861;&#36394;&#31639;&#27861;&#30456;&#21516;&#30340;&#29305;&#24449;&#38598;&#65292;&#36890;&#36807;&#24369;&#27425;&#27169;&#24615;&#35777;&#26126;&#20102;&#23545;&#20110;&#20855;&#26377;&#21463;&#38480;&#24378;&#20984;&#24615;&#21644;&#20809;&#28369;&#24615;&#30340;&#20219;&#20309;&#20989;&#25968;$l$&#37117;&#20855;&#26377;&#24674;&#22797;&#20445;&#35777;&#12290;&#36825;&#22238;&#31572;&#20102;Tibshirani&#31561;&#20154;&#21644;Yasuda&#31561;&#20154;&#30340;&#24320;&#25918;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#39318;&#27425;&#22312;&#29702;&#35770;&#19978;&#35299;&#37322;&#20102;
&lt;/p&gt;
&lt;p&gt;
Despite widespread adoption in practice, guarantees for the LASSO and Group LASSO are strikingly lacking in settings beyond statistical problems, and these algorithms are usually considered to be a heuristic in the context of sparse convex optimization on deterministic inputs. We give the first recovery guarantees for the Group LASSO for sparse convex optimization with vector-valued features. We show that if a sufficiently large Group LASSO regularization is applied when minimizing a strictly convex function $l$, then the minimizer is a sparse vector supported on vector-valued features with the largest $\ell_2$ norm of the gradient. Thus, repeating this procedure selects the same set of features as the Orthogonal Matching Pursuit algorithm, which admits recovery guarantees for any function $l$ with restricted strong convexity and smoothness via weak submodularity arguments. This answers open questions of Tibshirani et al. and Yasuda et al. Our result is the first to theoretically expla
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25299;&#23637;&#20102;&#35780;&#20272;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20013;&#21051;&#26495;&#20559;&#35265;&#30340;&#30740;&#31350;&#65292;&#36890;&#36807;&#36328;&#35821;&#35328;&#20998;&#26512;&#21457;&#29616;mGPT-2&#22312;&#19981;&#21516;&#35821;&#35328;&#20013;&#26174;&#31034;&#20986;&#20196;&#20154;&#24778;&#35766;&#30340;&#21453;&#21051;&#26495;&#34892;&#20026;&#65292;&#24182;&#19988;&#33521;&#35821;&#27169;&#22411;&#34920;&#29616;&#20986;&#26368;&#24378;&#30340;&#20559;&#35265;&#65292;&#32780;&#22303;&#32819;&#20854;&#35821;&#21017;&#26368;&#19981;&#26126;&#26174;&#12290;</title><link>http://arxiv.org/abs/2307.07331</link><description>&lt;p&gt;
&#36328;&#35821;&#35328;&#30340;&#21051;&#26495;&#20559;&#35265;&#26377;&#20309;&#19981;&#21516;&#65311;
&lt;/p&gt;
&lt;p&gt;
How Different Is Stereotypical Bias Across Languages?. (arXiv:2307.07331v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07331
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25299;&#23637;&#20102;&#35780;&#20272;&#39044;&#35757;&#32451;&#35821;&#35328;&#27169;&#22411;&#20013;&#21051;&#26495;&#20559;&#35265;&#30340;&#30740;&#31350;&#65292;&#36890;&#36807;&#36328;&#35821;&#35328;&#20998;&#26512;&#21457;&#29616;mGPT-2&#22312;&#19981;&#21516;&#35821;&#35328;&#20013;&#26174;&#31034;&#20986;&#20196;&#20154;&#24778;&#35766;&#30340;&#21453;&#21051;&#26495;&#34892;&#20026;&#65292;&#24182;&#19988;&#33521;&#35821;&#27169;&#22411;&#34920;&#29616;&#20986;&#26368;&#24378;&#30340;&#20559;&#35265;&#65292;&#32780;&#22303;&#32819;&#20854;&#35821;&#21017;&#26368;&#19981;&#26126;&#26174;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#23637;&#31034;&#20102;&#22914;&#20309;&#35780;&#20272;&#39044;&#35757;&#32451;&#30340;&#33521;&#35821;&#35821;&#35328;&#27169;&#22411;&#20013;&#30340;&#21051;&#26495;&#20559;&#35265;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#31995;&#32479;&#22320;&#35843;&#26597;(a)&#22810;&#35821;&#35328;&#27169;&#22411;&#21644;&#21333;&#35821;&#27169;&#22411;&#12289;(b)&#19981;&#21516;&#22522;&#30784;&#26550;&#26500;&#19979;&#30340;&#21051;&#26495;&#20559;&#35265;&#12289;(c)&#22810;&#31181;&#35821;&#35328;&#20013;&#30340;&#20559;&#35265;&#65292;&#25193;&#23637;&#20102;&#35813;&#30740;&#31350;&#39046;&#22495;&#30340;&#22810;&#20010;&#26041;&#38754;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#25105;&#20204;&#21033;&#29992;&#33521;&#35821;&#30340;StereoSet&#25968;&#25454;&#38598;&#23558;&#20854;&#21322;&#33258;&#21160;&#32763;&#35793;&#25104;&#24503;&#35821;&#12289;&#27861;&#35821;&#12289;&#35199;&#29677;&#29273;&#35821;&#21644;&#22303;&#32819;&#20854;&#35821;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#22810;&#35821;&#35328;&#29615;&#22659;&#19979;&#36827;&#34892;&#36825;&#31181;&#31867;&#22411;&#30340;&#20998;&#26512;&#38750;&#24120;&#37325;&#35201;&#65292;&#22240;&#20026;&#25105;&#20204;&#30340;&#23454;&#39564;&#23637;&#31034;&#20102;&#19968;&#20010;&#26356;&#20026;&#32454;&#33268;&#30340;&#30011;&#38754;&#65292;&#20197;&#21450;&#19982;&#20165;&#33521;&#35821;&#20998;&#26512;&#26377;&#26174;&#33879;&#24046;&#24322;&#30340;&#21457;&#29616;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#20027;&#35201;&#24471;&#20986;&#20197;&#19979;&#32467;&#35770;&#65306;mGPT-2&#65288;&#22312;&#26576;&#31181;&#31243;&#24230;&#19978;&#65289;&#22312;&#19981;&#21516;&#35821;&#35328;&#20013;&#26174;&#31034;&#20986;&#20196;&#20154;&#24778;&#35766;&#30340;&#21453;&#21051;&#26495;&#34892;&#20026;&#65292;&#33521;&#35821;&#65288;&#21333;&#35821;&#65289;&#27169;&#22411;&#34920;&#29616;&#20986;&#26368;&#24378;&#30340;&#20559;&#35265;&#65292;&#24182;&#19988;&#25968;&#25454;&#38598;&#20013;&#21453;&#26144;&#30340;&#21051;&#26495;&#21360;&#35937;&#22312;&#22303;&#32819;&#20854;&#35821;&#20013;&#26368;&#19981;&#26126;&#26174;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent studies have demonstrated how to assess the stereotypical bias in pre-trained English language models. In this work, we extend this branch of research in multiple different dimensions by systematically investigating (a) mono- and multilingual models of (b) different underlying architectures with respect to their bias in (c) multiple different languages. To that end, we make use of the English StereoSet data set (Nadeem et al., 2021), which we semi-automatically translate into German, French, Spanish, and Turkish. We find that it is of major importance to conduct this type of analysis in a multilingual setting, as our experiments show a much more nuanced picture as well as notable differences from the English-only analysis. The main takeaways from our analysis are that mGPT-2 (partly) shows surprising anti-stereotypical behavior across languages, English (monolingual) models exhibit the strongest bias, and the stereotypes reflected in the data set are least present in Turkish mod
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#33258;&#36866;&#24212;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#38750;&#27491;&#24577;&#28176;&#36817;&#34892;&#20026;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#33258;&#36866;&#24212;&#32447;&#24615;&#20272;&#35745;&#26041;&#31243;&#26500;&#24314;&#21435;&#20559;&#20272;&#35745;&#37327;&#65292;&#24182;&#22312;&#22810;&#33218;&#32769;&#34382;&#26426;&#30340;&#32972;&#26223;&#19979;&#20445;&#25345;&#20102;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#37327;&#30340;&#38750;&#28176;&#36817;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.07320</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#32447;&#24615;&#20272;&#35745;&#26041;&#31243;
&lt;/p&gt;
&lt;p&gt;
Adaptive Linear Estimating Equations. (arXiv:2307.07320v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07320
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#33258;&#36866;&#24212;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#38750;&#27491;&#24577;&#28176;&#36817;&#34892;&#20026;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#33258;&#36866;&#24212;&#32447;&#24615;&#20272;&#35745;&#26041;&#31243;&#26500;&#24314;&#21435;&#20559;&#20272;&#35745;&#37327;&#65292;&#24182;&#22312;&#22810;&#33218;&#32769;&#34382;&#26426;&#30340;&#32972;&#26223;&#19979;&#20445;&#25345;&#20102;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#37327;&#30340;&#38750;&#28176;&#36817;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39034;&#24207;&#25968;&#25454;&#25910;&#38598;&#24050;&#25104;&#20026;&#22686;&#24378;&#25968;&#25454;&#25910;&#38598;&#36807;&#31243;&#25928;&#29575;&#30340;&#24191;&#27867;&#37319;&#29992;&#30340;&#25216;&#26415;&#12290;&#23613;&#31649;&#20855;&#26377;&#20248;&#21183;&#65292;&#20294;&#36825;&#31181;&#25968;&#25454;&#25910;&#38598;&#26426;&#21046;&#24120;&#24120;&#32473;&#32479;&#35745;&#25512;&#26029;&#36807;&#31243;&#24341;&#20837;&#22797;&#26434;&#24615;&#12290;&#20363;&#22914;&#65292;&#22312;&#33258;&#36866;&#24212;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#65292;&#26222;&#36890;&#26368;&#23567;&#20108;&#20056;&#65288;OLS&#65289;&#20272;&#35745;&#37327;&#21487;&#33021;&#34920;&#29616;&#20986;&#38750;&#27491;&#24577;&#30340;&#28176;&#36817;&#34892;&#20026;&#65292;&#20174;&#32780;&#23545;&#20934;&#30830;&#30340;&#25512;&#26029;&#21644;&#35299;&#37322;&#25552;&#20986;&#25361;&#25112;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26500;&#24314;&#21435;&#20559;&#20272;&#35745;&#37327;&#30340;&#36890;&#29992;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#37319;&#29992;&#33258;&#36866;&#24212;&#32447;&#24615;&#20272;&#35745;&#26041;&#31243;&#30340;&#24605;&#24819;&#65292;&#24182;&#22312;&#29702;&#35770;&#19978;&#20445;&#35777;&#20102;&#28176;&#36817;&#27491;&#24577;&#24615;&#65292;&#24182;&#35752;&#35770;&#20102;&#23454;&#29616;&#36817;&#20284;&#26368;&#20248;&#28176;&#36817;&#26041;&#24046;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#20272;&#35745;&#37327;&#30340;&#19968;&#20010;&#26174;&#33879;&#29305;&#28857;&#26159;&#65292;&#22312;&#22810;&#33218;&#32769;&#34382;&#26426;&#30340;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#30340;&#20272;&#35745;&#37327;&#20445;&#30041;&#20102;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#37327;&#30340;&#38750;&#28176;&#36817;&#24615;&#33021;&#65292;&#21516;&#26102;&#33719;&#24471;&#20102;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;&#22240;&#27492;&#65292;&#26412;&#24037;&#20316;&#35299;&#20915;&#20102;&#33258;&#36866;&#24212;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20013;&#38750;&#27491;&#24577;&#28176;&#36817;&#34892;&#20026;&#30340;&#38382;&#39064;&#65292;&#24182;&#20026;&#32479;&#35745;&#25512;&#26029;&#25552;&#20379;&#20102;&#21487;&#38752;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sequential data collection has emerged as a widely adopted technique for enhancing the efficiency of data gathering processes. Despite its advantages, such data collection mechanism often introduces complexities to the statistical inference procedure. For instance, the ordinary least squares (OLS) estimator in an adaptive linear regression model can exhibit non-normal asymptotic behavior, posing challenges for accurate inference and interpretation. In this paper, we propose a general method for constructing debiased estimator which remedies this issue. It makes use of the idea of adaptive linear estimating equations, and we establish theoretical guarantees of asymptotic normality, supplemented by discussions on achieving near-optimal asymptotic variance. A salient feature of our estimator is that in the context of multi-armed bandits, our estimator retains the non-asymptotic performance of the least square estimator while obtaining asymptotic normality property. Consequently, this work
&lt;/p&gt;</description></item><item><title>&#23398;&#20064;&#19987;&#23478;&#24314;&#35758;&#21644;&#22810;&#33218;&#36172;&#21338;&#26159;&#20004;&#20010;&#32463;&#20856;&#30340;&#22312;&#32447;&#20915;&#31574;&#38382;&#39064;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#32773;&#20043;&#38388;&#30340;&#25554;&#20540;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;$\mathbf{m}$-MAB&#30340;&#26497;&#23567;&#21518;&#24724;&#30028;&#24182;&#35774;&#35745;&#20102;$\mathbf{m}$-BAI&#30340;&#26368;&#20248;PAC&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#26088;&#22312;&#20197;&#23613;&#21487;&#33021;&#23569;&#30340;&#36718;&#25968;&#30830;&#23450;&#25439;&#22833;&#26368;&#23567;&#30340;&#33218;&#12290;</title><link>http://arxiv.org/abs/2307.07264</link><description>&lt;p&gt;
&#20851;&#20110;&#25554;&#20540;&#19987;&#23478;&#21644;&#22810;&#33218;&#36172;&#21338;&#26426;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Interpolating Experts and Multi-Armed Bandits. (arXiv:2307.07264v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07264
&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#19987;&#23478;&#24314;&#35758;&#21644;&#22810;&#33218;&#36172;&#21338;&#26159;&#20004;&#20010;&#32463;&#20856;&#30340;&#22312;&#32447;&#20915;&#31574;&#38382;&#39064;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#32773;&#20043;&#38388;&#30340;&#25554;&#20540;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;$\mathbf{m}$-MAB&#30340;&#26497;&#23567;&#21518;&#24724;&#30028;&#24182;&#35774;&#35745;&#20102;$\mathbf{m}$-BAI&#30340;&#26368;&#20248;PAC&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#26088;&#22312;&#20197;&#23613;&#21487;&#33021;&#23569;&#30340;&#36718;&#25968;&#30830;&#23450;&#25439;&#22833;&#26368;&#23567;&#30340;&#33218;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#19987;&#23478;&#24314;&#35758;&#21644;&#22810;&#33218;&#36172;&#21338;&#26159;&#20004;&#20010;&#32463;&#20856;&#30340;&#22312;&#32447;&#20915;&#31574;&#38382;&#39064;&#65292;&#23427;&#20204;&#22312;&#27599;&#19968;&#36718;&#35266;&#23519;&#20449;&#24687;&#30340;&#26041;&#24335;&#19978;&#26377;&#25152;&#19981;&#21516;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#36825;&#20004;&#32773;&#20043;&#38388;&#30340;&#25554;&#20540;&#38382;&#39064;&#12290;&#23545;&#20110;&#21521;&#37327;$\mathbf{m}=(m_1,\dots,m_K)\in \mathbb{N}^K$&#65292;$\mathbf{m}$-MAB&#30340;&#19968;&#20010;&#23454;&#20363;&#34920;&#31034;&#23558;&#33218;&#20998;&#25104;$K$&#32452;&#65292;&#31532;$i$&#32452;&#21253;&#21547;$m_i$&#20010;&#33218;&#12290;&#19968;&#26086;&#25289;&#21160;&#19968;&#20010;&#33218;&#65292;&#21516;&#19968;&#32452;&#20013;&#25152;&#26377;&#33218;&#30340;&#25439;&#22833;&#37117;&#34987;&#35266;&#23519;&#21040;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;$\mathbf{m}$-MAB&#30340;&#32039;&#33268;&#26497;&#23567;&#21518;&#24724;&#30028;&#65292;&#24182;&#20026;&#20854;&#32431;&#25506;&#32034;&#29256;&#26412;$\mathbf{m}$-BAI&#35774;&#35745;&#20102;&#19968;&#20010;&#26368;&#20248;&#30340;PAC&#31639;&#27861;&#65292;&#20854;&#20013;&#30446;&#26631;&#26159;&#29992;&#23613;&#21487;&#33021;&#23569;&#30340;&#36718;&#25968;&#26469;&#35782;&#21035;&#25439;&#22833;&#26368;&#23567;&#30340;&#33218;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;$\mathbf{m}$-MAB&#30340;&#26497;&#23567;&#21518;&#24724;&#26159;$\Theta\left(\sqrt{T\sum_{k=1}^K\log (m_k+1)}\right)$&#65292;&#23545;&#20110;&#19968;&#20010;$(\epsilon,0.05)$-PAC&#31639;&#27861;&#30340;$\mathbf{m}$-BAI&#65292;&#25289;&#21160;&#33218;&#30340;&#26368;&#23567;&#27425;&#25968;&#26159;$\Theta\left(\frac{1}{\epsilon^2}\cdot \sum_{k=1}^K\log (m_k+1)\right)$&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning with expert advice and multi-armed bandit are two classic online decision problems which differ on how the information is observed in each round of the game. We study a family of problems interpolating the two. For a vector $\mathbf{m}=(m_1,\dots,m_K)\in \mathbb{N}^K$, an instance of $\mathbf{m}$-MAB indicates that the arms are partitioned into $K$ groups and the $i$-th group contains $m_i$ arms. Once an arm is pulled, the losses of all arms in the same group are observed. We prove tight minimax regret bounds for $\mathbf{m}$-MAB and design an optimal PAC algorithm for its pure exploration version, $\mathbf{m}$-BAI, where the goal is to identify the arm with minimum loss with as few rounds as possible. We show that the minimax regret of $\mathbf{m}$-MAB is $\Theta\left(\sqrt{T\sum_{k=1}^K\log (m_k+1)}\right)$ and the minimum number of pulls for an $(\epsilon,0.05)$-PAC algorithm of $\mathbf{m}$-BAI is $\Theta\left(\frac{1}{\epsilon^2}\cdot \sum_{k=1}^K\log (m_k+1)\right)$. Bot
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#30005;&#21147;&#36127;&#33655;&#39044;&#27979;&#23384;&#26723;&#65292;&#21253;&#25324;&#36127;&#33655;&#39046;&#22495;&#29305;&#23450;&#30340;&#29305;&#24449;&#24037;&#31243;&#65292;&#24110;&#21161;&#27169;&#22411;&#26356;&#22909;&#22320;&#27169;&#25311;&#36127;&#33655;&#25968;&#25454;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#25439;&#22833;&#20989;&#25968;&#26469;&#26368;&#23567;&#21270;&#21518;&#32493;&#20219;&#21153;&#30340;&#25104;&#26412;&#12290;</title><link>http://arxiv.org/abs/2307.07191</link><description>&lt;p&gt;
&#29992;&#20110;&#30005;&#21147;&#36127;&#33655;&#39044;&#27979;&#30340;&#22522;&#20934;&#21644;&#33258;&#23450;&#20041;&#21253;
&lt;/p&gt;
&lt;p&gt;
Benchmarks and Custom Package for Electrical Load Forecasting. (arXiv:2307.07191v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07191
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#30005;&#21147;&#36127;&#33655;&#39044;&#27979;&#23384;&#26723;&#65292;&#21253;&#25324;&#36127;&#33655;&#39046;&#22495;&#29305;&#23450;&#30340;&#29305;&#24449;&#24037;&#31243;&#65292;&#24110;&#21161;&#27169;&#22411;&#26356;&#22909;&#22320;&#27169;&#25311;&#36127;&#33655;&#25968;&#25454;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#25439;&#22833;&#20989;&#25968;&#26469;&#26368;&#23567;&#21270;&#21518;&#32493;&#20219;&#21153;&#30340;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36127;&#33655;&#39044;&#27979;&#22312;&#30005;&#21147;&#34892;&#19994;&#20013;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#65292;&#21487;&#20197;&#20026;&#21518;&#32493;&#20219;&#21153;&#22914;&#30005;&#32593;&#35843;&#24230;&#25552;&#20379;&#21442;&#32771;&#65292;&#20174;&#32780;&#24102;&#26469;&#24040;&#22823;&#30340;&#32463;&#27982;&#25928;&#30410;&#12290;&#28982;&#32780;&#65292;&#36127;&#33655;&#39044;&#27979;&#19982;&#20256;&#32479;&#30340;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20043;&#38388;&#23384;&#22312;&#35768;&#22810;&#24046;&#24322;&#12290;&#19968;&#26041;&#38754;&#65292;&#36127;&#33655;&#39044;&#27979;&#30340;&#30446;&#26631;&#26159;&#26368;&#23567;&#21270;&#21518;&#32493;&#20219;&#21153;&#65288;&#22914;&#30005;&#32593;&#35843;&#24230;&#65289;&#30340;&#25104;&#26412;&#65292;&#32780;&#19981;&#20165;&#20165;&#36861;&#27714;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#36127;&#33655;&#21463;&#21040;&#35768;&#22810;&#22806;&#37096;&#22240;&#32032;&#30340;&#24433;&#21709;&#65292;&#22914;&#28201;&#24230;&#25110;&#26085;&#21382;&#21464;&#37327;&#12290;&#27492;&#22806;&#65292;&#39044;&#27979;&#30340;&#35268;&#27169;&#65288;&#22914;&#24314;&#31569;&#32423;&#36127;&#33655;&#21644;&#32858;&#21512;&#32423;&#36127;&#33655;&#65289;&#20063;&#20250;&#23545;&#39044;&#27979;&#32467;&#26524;&#20135;&#29983;&#37325;&#22823;&#24433;&#21709;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#36127;&#33655;&#39044;&#27979;&#23384;&#26723;&#65292;&#20854;&#20013;&#21253;&#25324;&#36127;&#33655;&#39046;&#22495;&#29305;&#23450;&#30340;&#29305;&#24449;&#24037;&#31243;&#65292;&#20197;&#24110;&#21161;&#39044;&#27979;&#27169;&#22411;&#26356;&#22909;&#22320;&#27169;&#25311;&#36127;&#33655;&#25968;&#25454;&#12290;&#27492;&#22806;&#65292;&#19982;&#20256;&#32479;&#30340;&#25439;&#22833;&#20989;&#25968;&#20165;&#36861;&#27714;&#20934;&#30830;&#24615;&#19981;&#21516;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;...
&lt;/p&gt;
&lt;p&gt;
Load forecasting is of great significance in the power industry as it can provide a reference for subsequent tasks such as power grid dispatch, thus bringing huge economic benefits. However, there are many differences between load forecasting and traditional time series forecasting. On the one hand, load forecasting aims to minimize the cost of subsequent tasks such as power grid dispatch, rather than simply pursuing prediction accuracy. On the other hand, the load is largely influenced by many external factors, such as temperature or calendar variables. In addition, the scale of predictions (such as building-level loads and aggregated-level loads) can also significantly impact the predicted results. In this paper, we provide a comprehensive load forecasting archive, which includes load domain-specific feature engineering to help forecasting models better model load data. In addition, different from the traditional loss function which only aims for accuracy, we also provide a method to
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#33258;&#30417;&#30563;&#28145;&#24230;&#23398;&#20064;&#36827;&#34892;&#23450;&#37327;MRI&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#36127;&#23545;&#25968;Rician&#20284;&#28982;&#65288;NLR&#65289;&#25439;&#22833;&#20989;&#25968;&#65292;&#35299;&#20915;&#20102;&#20302;&#20449;&#22122;&#27604;&#26465;&#20214;&#19979;&#21442;&#25968;&#20272;&#35745;&#20559;&#24046;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.07072</link><description>&lt;p&gt;
&#20351;&#29992;&#33258;&#30417;&#30563;&#28145;&#24230;&#23398;&#20064;&#30340;Rician&#20284;&#28982;&#25439;&#22833;&#36827;&#34892;&#23450;&#37327;MRI
&lt;/p&gt;
&lt;p&gt;
Rician likelihood loss for quantitative MRI using self-supervised deep learning. (arXiv:2307.07072v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07072
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#33258;&#30417;&#30563;&#28145;&#24230;&#23398;&#20064;&#36827;&#34892;&#23450;&#37327;MRI&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#36127;&#23545;&#25968;Rician&#20284;&#28982;&#65288;NLR&#65289;&#25439;&#22833;&#20989;&#25968;&#65292;&#35299;&#20915;&#20102;&#20302;&#20449;&#22122;&#27604;&#26465;&#20214;&#19979;&#21442;&#25968;&#20272;&#35745;&#20559;&#24046;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#30340;&#65306;&#20197;&#21069;&#20351;&#29992;&#33258;&#30417;&#30563;&#28145;&#24230;&#23398;&#20064;&#36827;&#34892;&#30340;&#23450;&#37327;MRI&#30740;&#31350;&#25253;&#21578;&#22312;&#20302;&#20449;&#22122;&#27604;&#26465;&#20214;&#19979;&#23384;&#22312;&#21442;&#25968;&#20272;&#35745;&#20559;&#24046;&#30340;&#38382;&#39064;&#12290;&#36825;&#20123;&#31995;&#32479;&#35823;&#24046;&#26469;&#33258;&#20110;&#32593;&#32476;&#35757;&#32451;&#20013;&#36873;&#25321;&#30340;&#22343;&#26041;&#35823;&#24046;&#65288;MSE&#65289;&#25439;&#22833;&#20989;&#25968;&#65292;&#35813;&#20989;&#25968;&#19982;Rician&#20998;&#24067;&#30340;MR&#24133;&#24230;&#20449;&#21495;&#19981;&#20860;&#23481;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#36127;&#23545;&#25968;Rician&#20284;&#28982;&#65288;NLR&#65289;&#25439;&#22833;&#12290;&#26041;&#27861;&#65306;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#25968;&#20540;&#31283;&#23450;&#19988;&#20934;&#30830;&#30340;NLR&#25439;&#22833;&#30340;&#23454;&#29616;&#65292;&#29992;&#20110;&#20272;&#35745;&#34920;&#35266;&#25193;&#25955;&#31995;&#25968;&#65288;ADC&#65289;&#27169;&#22411;&#21644;&#20307;&#32032;&#20869;&#19981;&#30456;&#24178;&#36816;&#21160;&#65288;IVIM&#65289;&#27169;&#22411;&#30340;&#23450;&#37327;&#21442;&#25968;&#12290;&#36890;&#36807;&#22312;&#19968;&#31995;&#21015;&#20449;&#22122;&#27604;&#65288;5-30&#65289;&#19979;&#27604;&#36739;&#20559;&#24046;&#12289;&#26041;&#24046;&#21644;&#22343;&#26041;&#26681;&#35823;&#24046;&#26469;&#35780;&#20272;&#21442;&#25968;&#20272;&#35745;&#30340;&#20934;&#30830;&#24615;&#12289;&#31934;&#24230;&#21644;&#24635;&#20307;&#35823;&#24046;&#65292;&#24182;&#19982;MSE&#25439;&#22833;&#36827;&#34892;&#27604;&#36739;&#12290;&#32467;&#26524;&#65306;&#20351;&#29992;NLR&#25439;&#22833;&#35757;&#32451;&#30340;&#32593;&#32476;&#22312;SNR&#38477;&#20302;&#26102;&#26174;&#31034;&#20986;&#27604;MSE&#26356;&#39640;&#30340;ADC&#21644;IVIM&#25193;&#25955;&#31995;&#25968;&#20272;&#35745;&#20934;&#30830;&#24615;&#65292;&#32780;&#31934;&#24230;&#25110;&#24635;&#35823;&#24046;&#20960;&#20046;&#27809;&#26377;&#25439;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;
Purpose: Previous quantitative MR imaging studies using self-supervised deep learning have reported biased parameter estimates at low SNR. Such systematic errors arise from the choice of Mean Squared Error (MSE) loss function for network training, which is incompatible with Rician-distributed MR magnitude signals. To address this issue, we introduce the negative log Rician likelihood (NLR) loss. Methods: A numerically stable and accurate implementation of the NLR loss was developed to estimate quantitative parameters of the apparent diffusion coefficient (ADC) model and intra-voxel incoherent motion (IVIM) model. Parameter estimation accuracy, precision and overall error were evaluated in terms of bias, variance and root mean squared error and compared against the MSE loss over a range of SNRs (5 - 30). Results: Networks trained with NLR loss show higher estimation accuracy than MSE for the ADC and IVIM diffusion coefficients as SNR decreases, with minimal loss of precision or total er
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#21033;&#29992;&#20998;&#35299;&#30340;&#21160;&#20316;&#31354;&#38388;&#26469;&#20943;&#36731;&#28041;&#21450;&#22823;&#22411;&#32452;&#21512;&#21160;&#20316;&#31354;&#38388;&#38382;&#39064;&#30340;&#38750;&#31574;&#30053;&#35780;&#20272;&#65288;OPE&#65289;&#30340;&#39640;&#20559;&#24046;&#21644;&#39640;&#26041;&#24046;&#38382;&#39064;&#12290;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#20998;&#35299;&#21160;&#20316;&#31354;&#38388;&#30340;&#26032;&#22411;&#8220;&#20998;&#35299;&#8221;&#37325;&#35201;&#24615;&#25277;&#26679;&#65288;IS&#65289;&#20272;&#35745;&#22120;&#31995;&#21015;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20998;&#35299;IS&#20272;&#35745;&#22120;&#20855;&#26377;&#27604;&#38750;&#20998;&#35299;&#29256;&#26412;&#26356;&#23567;&#30340;&#26041;&#24046;&#65292;&#21516;&#26102;&#20855;&#26377;&#38646;&#20559;&#24046;&#30340;&#24615;&#36136;&#65292;&#24182;&#36890;&#36807;&#27169;&#25311;&#23454;&#39564;&#35777;&#23454;&#20102;&#35813;&#29702;&#35770;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2307.07014</link><description>&lt;p&gt;
&#21033;&#29992;&#20998;&#35299;&#30340;&#21160;&#20316;&#31354;&#38388;&#36827;&#34892;&#38750;&#31574;&#30053;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Leveraging Factored Action Spaces for Off-Policy Evaluation. (arXiv:2307.07014v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07014
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#21033;&#29992;&#20998;&#35299;&#30340;&#21160;&#20316;&#31354;&#38388;&#26469;&#20943;&#36731;&#28041;&#21450;&#22823;&#22411;&#32452;&#21512;&#21160;&#20316;&#31354;&#38388;&#38382;&#39064;&#30340;&#38750;&#31574;&#30053;&#35780;&#20272;&#65288;OPE&#65289;&#30340;&#39640;&#20559;&#24046;&#21644;&#39640;&#26041;&#24046;&#38382;&#39064;&#12290;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#20998;&#35299;&#21160;&#20316;&#31354;&#38388;&#30340;&#26032;&#22411;&#8220;&#20998;&#35299;&#8221;&#37325;&#35201;&#24615;&#25277;&#26679;&#65288;IS&#65289;&#20272;&#35745;&#22120;&#31995;&#21015;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20998;&#35299;IS&#20272;&#35745;&#22120;&#20855;&#26377;&#27604;&#38750;&#20998;&#35299;&#29256;&#26412;&#26356;&#23567;&#30340;&#26041;&#24046;&#65292;&#21516;&#26102;&#20855;&#26377;&#38646;&#20559;&#24046;&#30340;&#24615;&#36136;&#65292;&#24182;&#36890;&#36807;&#27169;&#25311;&#23454;&#39564;&#35777;&#23454;&#20102;&#35813;&#29702;&#35770;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#31574;&#30053;&#35780;&#20272;&#65288;OPE&#65289;&#26088;&#22312;&#20272;&#35745;&#26681;&#25454;&#25191;&#34892;&#24207;&#21015;&#25910;&#38598;&#30340;&#25968;&#25454;&#65292;&#36981;&#24490;&#21453;&#20107;&#23454;&#30340;&#19968;&#31995;&#21015;&#21160;&#20316;&#30340;&#25928;&#30410;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;OPE&#20272;&#35745;&#22120;&#22312;&#28041;&#21450;&#22823;&#22411;&#32452;&#21512;&#21160;&#20316;&#31354;&#38388;&#30340;&#38382;&#39064;&#20013;&#32463;&#24120;&#34920;&#29616;&#20986;&#39640;&#20559;&#24046;&#21644;&#39640;&#26041;&#24046;&#12290;&#25105;&#20204;&#30740;&#31350;&#22914;&#20309;&#21033;&#29992;&#20998;&#35299;&#30340;&#21160;&#20316;&#31354;&#38388;&#26469;&#20943;&#36731;&#36825;&#20010;&#38382;&#39064;&#65292;&#21363;&#23558;&#27599;&#20010;&#21160;&#20316;&#34920;&#31034;&#20026;&#26469;&#33258;&#36739;&#23567;&#21160;&#20316;&#31354;&#38388;&#30340;&#29420;&#31435;&#23376;&#21160;&#20316;&#30340;&#32452;&#21512;&#12290;&#36825;&#31181;&#26041;&#27861;&#26377;&#21161;&#20110;&#23545;&#21160;&#20316;&#22312;&#20854;&#25928;&#26524;&#19978;&#30340;&#24046;&#24322;&#36827;&#34892;&#26356;&#31934;&#32454;&#30340;&#20998;&#26512;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#35299;&#21160;&#20316;&#31354;&#38388;&#30340;&#26032;&#22411;&#8220;&#20998;&#35299;&#8221;&#37325;&#35201;&#24615;&#25277;&#26679;&#65288;IS&#65289;&#20272;&#35745;&#22120;&#31995;&#21015;&#12290;&#22312;&#23545;&#24213;&#23618;&#38382;&#39064;&#32467;&#26500;&#36827;&#34892;&#19968;&#23450;&#30340;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20998;&#35299;IS&#20272;&#35745;&#22120;&#30340;&#26041;&#24046;&#27604;&#20854;&#21407;&#22987;&#38750;&#20998;&#35299;&#29256;&#26412;&#23567;&#65292;&#21516;&#26102;&#20445;&#25345;&#38646;&#20559;&#24046;&#30340;&#24615;&#36136;&#12290;&#36890;&#36807;&#27169;&#25311;&#65292;&#25105;&#20204;&#32463;&#39564;&#35777;&#23454;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#65292;&#26816;&#39564;&#20102;&#21508;&#31181;&#20551;&#35774;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Off-policy evaluation (OPE) aims to estimate the benefit of following a counterfactual sequence of actions, given data collected from executed sequences. However, existing OPE estimators often exhibit high bias and high variance in problems involving large, combinatorial action spaces. We investigate how to mitigate this issue using factored action spaces i.e. expressing each action as a combination of independent sub-actions from smaller action spaces. This approach facilitates a finer-grained analysis of how actions differ in their effects. In this work, we propose a new family of "decomposed" importance sampling (IS) estimators based on factored action spaces. Given certain assumptions on the underlying problem structure, we prove that the decomposed IS estimators have less variance than their original non-decomposed versions, while preserving the property of zero bias. Through simulations, we empirically verify our theoretical results, probing the validity of various assumptions. P
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#25968;&#20540;&#19981;&#31283;&#23450;&#24615;&#23545;&#21464;&#20998;&#27969;&#20013;&#37319;&#26679;&#12289;&#23494;&#24230;&#35780;&#20272;&#21644;ELBO&#20272;&#35745;&#30340;&#21487;&#38752;&#24615;&#30340;&#24433;&#21709;&#12290;&#36890;&#36807;&#29702;&#35770;&#20445;&#35777;&#21644;&#23454;&#39564;&#39564;&#35777;&#65292;&#25105;&#20204;&#21457;&#29616;&#23613;&#31649;&#23384;&#22312;&#20005;&#37325;&#30340;&#25968;&#20540;&#19981;&#31283;&#23450;&#24615;&#65292;&#21464;&#20998;&#27969;&#20135;&#29983;&#30340;&#32467;&#26524;&#22312;&#24212;&#29992;&#20013;&#24120;&#24120;&#36275;&#22815;&#20934;&#30830;&#12290;</title><link>http://arxiv.org/abs/2307.06957</link><description>&lt;p&gt;
&#25317;&#25265;&#28151;&#20081;&#65306;&#25968;&#20540;&#19981;&#31283;&#23450;&#24615;&#22312;&#21464;&#20998;&#27969;&#20013;&#30340;&#20998;&#26512;&#21644;&#35786;&#26029;
&lt;/p&gt;
&lt;p&gt;
Embracing the chaos: analysis and diagnosis of numerical instability in variational flows. (arXiv:2307.06957v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06957
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#25968;&#20540;&#19981;&#31283;&#23450;&#24615;&#23545;&#21464;&#20998;&#27969;&#20013;&#37319;&#26679;&#12289;&#23494;&#24230;&#35780;&#20272;&#21644;ELBO&#20272;&#35745;&#30340;&#21487;&#38752;&#24615;&#30340;&#24433;&#21709;&#12290;&#36890;&#36807;&#29702;&#35770;&#20445;&#35777;&#21644;&#23454;&#39564;&#39564;&#35777;&#65292;&#25105;&#20204;&#21457;&#29616;&#23613;&#31649;&#23384;&#22312;&#20005;&#37325;&#30340;&#25968;&#20540;&#19981;&#31283;&#23450;&#24615;&#65292;&#21464;&#20998;&#27969;&#20135;&#29983;&#30340;&#32467;&#26524;&#22312;&#24212;&#29992;&#20013;&#24120;&#24120;&#36275;&#22815;&#20934;&#30830;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#25968;&#20540;&#19981;&#31283;&#23450;&#24615;&#23545;&#21464;&#20998;&#27969;&#20013;&#37319;&#26679;&#12289;&#23494;&#24230;&#35780;&#20272;&#21644;&#35777;&#25454;&#19979;&#30028;&#65288;ELBO&#65289;&#20272;&#35745;&#30340;&#21487;&#38752;&#24615;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#39318;&#20808;&#36890;&#36807;&#23454;&#35777;&#39564;&#35777;&#20102;&#24120;&#35265;&#27969;&#21487;&#33021;&#20986;&#29616;&#20005;&#37325;&#30340;&#38169;&#35823;&#32047;&#31215;&#65306;&#25968;&#20540;&#27969;&#26144;&#23556;&#19982;&#31934;&#30830;&#26144;&#23556;&#30340;&#20559;&#24046;&#26174;&#33879;&#65292;&#24433;&#21709;&#37319;&#26679;&#65307;&#25968;&#20540;&#36870;&#27969;&#26144;&#23556;&#26080;&#27861;&#20934;&#30830;&#24674;&#22797;&#21021;&#22987;&#36755;&#20837;&#65292;&#24433;&#21709;&#23494;&#24230;&#21644;ELBO&#35745;&#31639;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#24778;&#35766;&#22320;&#21457;&#29616;&#65292;&#23613;&#31649;&#23384;&#22312;&#20005;&#37325;&#30340;&#25968;&#20540;&#19981;&#31283;&#23450;&#24615;&#65292;&#27969;&#20135;&#29983;&#30340;&#32467;&#26524;&#24120;&#24120;&#36275;&#22815;&#20934;&#30830;&#24212;&#23545;&#24212;&#29992;&#38656;&#27714;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23558;&#21464;&#20998;&#27969;&#35270;&#20026;&#21160;&#21147;&#31995;&#32479;&#65292;&#24182;&#21033;&#29992;&#38452;&#24433;&#29702;&#35770;&#36890;&#36807;&#29702;&#35770;&#20445;&#35777;&#23545;&#37319;&#26679;&#12289;&#23494;&#24230;&#35780;&#20272;&#21644;ELBO&#20272;&#35745;&#30340;&#38169;&#35823;&#26469;&#38416;&#26126;&#36825;&#31181;&#34892;&#20026;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#24320;&#21457;&#24182;&#32463;&#39564;&#24615;&#22320;&#27979;&#35797;&#20102;&#19968;&#31181;&#21487;&#20197;&#29992;&#20110;&#39564;&#35777;&#25968;&#20540;&#32467;&#26524;&#30340;&#35786;&#26029;&#31243;&#24207;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we investigate the impact of numerical instability on the reliability of sampling, density evaluation, and evidence lower bound (ELBO) estimation in variational flows. We first empirically demonstrate that common flows can exhibit a catastrophic accumulation of error: the numerical flow map deviates significantly from the exact map -- which affects sampling -- and the numerical inverse flow map does not accurately recover the initial input -which affects density and ELBO computations. Surprisingly though, we find that results produced by flows are often accurate enough for applications despite the presence of serious numerical instability. In this work, we treat variational flows as dynamical systems, and leverage shadowing theory to elucidate this behavior via theoretical guarantees on the error of sampling, density evaluation, and ELBO estimation. Finally, we develop and empirically test a diagnostic procedure that can be used to validate results produced by numerica
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#32452;&#21512;&#20998;&#24067;&#20559;&#31227;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#30697;&#38453;&#34917;&#20840;&#30340;&#35299;&#20915;&#26041;&#27861;&#12290;&#36890;&#36807;&#22312;&#29305;&#27530;&#24773;&#20917;&#19979;&#30340;&#21452;&#32447;&#24615;&#23884;&#20837;&#65292;&#23454;&#29616;&#23545;&#35757;&#32451;&#20013;&#26410;&#28085;&#30422;&#30340;&#27979;&#35797;&#20998;&#24067;&#36827;&#34892;&#22806;&#25512;&#12290;&#36825;&#20010;&#35774;&#32622;&#23558;&#32570;&#22833;&#38750;&#38543;&#26426;&#25968;&#25454;&#30340;&#30697;&#38453;&#34917;&#20840;&#38382;&#39064;&#24191;&#20041;&#21270;&#12290;</title><link>http://arxiv.org/abs/2307.06457</link><description>&lt;p&gt;
&#35299;&#20915;&#32452;&#21512;&#20998;&#24067;&#20559;&#31227;&#38382;&#39064;&#65306;&#22522;&#20110;&#30697;&#38453;&#34917;&#20840;&#30340;&#35266;&#28857;
&lt;/p&gt;
&lt;p&gt;
Tackling Combinatorial Distribution Shift: A Matrix Completion Perspective. (arXiv:2307.06457v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06457
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#32452;&#21512;&#20998;&#24067;&#20559;&#31227;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#30697;&#38453;&#34917;&#20840;&#30340;&#35299;&#20915;&#26041;&#27861;&#12290;&#36890;&#36807;&#22312;&#29305;&#27530;&#24773;&#20917;&#19979;&#30340;&#21452;&#32447;&#24615;&#23884;&#20837;&#65292;&#23454;&#29616;&#23545;&#35757;&#32451;&#20013;&#26410;&#28085;&#30422;&#30340;&#27979;&#35797;&#20998;&#24067;&#36827;&#34892;&#22806;&#25512;&#12290;&#36825;&#20010;&#35774;&#32622;&#23558;&#32570;&#22833;&#38750;&#38543;&#26426;&#25968;&#25454;&#30340;&#30697;&#38453;&#34917;&#20840;&#38382;&#39064;&#24191;&#20041;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20998;&#24067;&#20559;&#31227;&#19979;&#33719;&#24471;&#20005;&#26684;&#30340;&#32479;&#35745;&#20445;&#35777;&#20173;&#28982;&#26159;&#19968;&#20010;&#24320;&#25918;&#19988;&#27963;&#36291;&#30340;&#30740;&#31350;&#39046;&#22495;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#31216;&#20026;&#32452;&#21512;&#20998;&#24067;&#20559;&#31227;&#30340;&#35774;&#32622;&#65292;&#20854;&#20013;(a)&#22312;&#27979;&#35797;&#21644;&#35757;&#32451;&#20998;&#24067;&#19979;&#65292;&#26631;&#31614;$z$&#30001;&#29305;&#24449;$(x,y)$&#30340;&#23545;&#20915;&#23450;&#65292;(b)&#35757;&#32451;&#20998;&#24067;&#28085;&#30422;&#20102;$x$&#21644;$y$&#20998;&#21035;&#30340;&#19968;&#23450;&#36793;&#32536;&#20998;&#24067;&#65292;&#20294;&#26159;(c)&#27979;&#35797;&#20998;&#24067;&#28041;&#21450;&#20102;&#19968;&#20010;&#22312;&#35757;&#32451;&#20998;&#24067;&#20013;&#26410;&#28085;&#30422;&#30340;$(x,y)$&#30340;&#20135;&#21697;&#20998;&#24067;&#30340;&#31034;&#20363;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#26631;&#31614;&#30001;&#21452;&#32447;&#24615;&#23884;&#20837;&#21040;Hilbert&#31354;&#38388;$H$&#20013;&#32473;&#20986;&#30340;&#29305;&#27530;&#24773;&#20917;&#65306;$\mathbb{E}[z \mid x,y ]=\langle f_{\star}(x),g_{\star}(y)\rangle_{{H}}$&#65292;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#23545;&#22312;&#35757;&#32451;&#20013;&#26410;&#28085;&#30422;&#30340;&#27979;&#35797;&#20998;&#24067;&#22495;&#36827;&#34892;&#22806;&#25512;&#65292;&#21363;&#23454;&#29616;&#21452;&#32447;&#24615;&#32452;&#21512;&#22806;&#25512;&#12290;&#25105;&#20204;&#30340;&#35774;&#32622;&#23558;&#32570;&#22833;&#38750;&#38543;&#26426;&#25968;&#25454;&#30340;&#30697;&#38453;&#34917;&#20840;&#30340;&#19968;&#20010;&#29305;&#27530;&#24773;&#20917;&#24191;&#20041;&#21270;&#65292;&#23545;&#20110;&#35813;&#24773;&#20917;&#65292;&#25152;&#26377;&#29616;&#26377;&#32467;&#26524;&#37117;&#35201;&#27714;....
&lt;/p&gt;
&lt;p&gt;
Obtaining rigorous statistical guarantees for generalization under distribution shift remains an open and active research area. We study a setting we call combinatorial distribution shift, where (a) under the test- and training-distributions, the labels $z$ are determined by pairs of features $(x,y)$, (b) the training distribution has coverage of certain marginal distributions over $x$ and $y$ separately, but (c) the test distribution involves examples from a product distribution over $(x,y)$ that is {not} covered by the training distribution. Focusing on the special case where the labels are given by bilinear embeddings into a Hilbert space $H$: $\mathbb{E}[z \mid x,y ]=\langle f_{\star}(x),g_{\star}(y)\rangle_{{H}}$, we aim to extrapolate to a test distribution domain that is $not$ covered in training, i.e., achieving bilinear combinatorial extrapolation.  Our setting generalizes a special case of matrix completion from missing-not-at-random data, for which all existing results requi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#36719;&#24178;&#39044;&#20013;&#30830;&#20445;&#22240;&#26524;&#20998;&#35299;&#30340;&#21487;&#35782;&#21035;&#24615;&#12290;&#36890;&#36807;&#24320;&#21457;&#19968;&#31181;&#33258;&#32534;&#30721;&#21464;&#20998;&#36125;&#21494;&#26031;&#31639;&#27861;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#32473;&#23450;&#19968;&#33324;&#21270;&#30340;&#24544;&#35802;&#24615;&#27010;&#24565;&#30340;&#24773;&#20917;&#19979;&#65292;&#21363;&#20351;&#23384;&#22312;&#26410;&#35266;&#27979;&#21040;&#30340;&#22240;&#26524;&#21464;&#37327;&#65292;&#20173;&#28982;&#21487;&#20197;&#24674;&#22797;&#28508;&#22312;&#30340;&#22240;&#26524;&#27169;&#22411;&#65292;&#24182;&#22312;&#26080;&#38480;&#25968;&#25454;&#30340;&#26497;&#38480;&#24773;&#20917;&#19979;&#39044;&#27979;&#26410;&#35265;&#32452;&#21512;&#30340;&#24178;&#39044;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2307.06250</link><description>&lt;p&gt;
&#20174;&#36719;&#24178;&#39044;&#20013;&#30830;&#20445;&#22240;&#26524;&#20998;&#35299;&#30340;&#21487;&#35782;&#21035;&#24615;
&lt;/p&gt;
&lt;p&gt;
Identifiability Guarantees for Causal Disentanglement from Soft Interventions. (arXiv:2307.06250v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06250
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#36719;&#24178;&#39044;&#20013;&#30830;&#20445;&#22240;&#26524;&#20998;&#35299;&#30340;&#21487;&#35782;&#21035;&#24615;&#12290;&#36890;&#36807;&#24320;&#21457;&#19968;&#31181;&#33258;&#32534;&#30721;&#21464;&#20998;&#36125;&#21494;&#26031;&#31639;&#27861;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#32473;&#23450;&#19968;&#33324;&#21270;&#30340;&#24544;&#35802;&#24615;&#27010;&#24565;&#30340;&#24773;&#20917;&#19979;&#65292;&#21363;&#20351;&#23384;&#22312;&#26410;&#35266;&#27979;&#21040;&#30340;&#22240;&#26524;&#21464;&#37327;&#65292;&#20173;&#28982;&#21487;&#20197;&#24674;&#22797;&#28508;&#22312;&#30340;&#22240;&#26524;&#27169;&#22411;&#65292;&#24182;&#22312;&#26080;&#38480;&#25968;&#25454;&#30340;&#26497;&#38480;&#24773;&#20917;&#19979;&#39044;&#27979;&#26410;&#35265;&#32452;&#21512;&#30340;&#24178;&#39044;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#20998;&#35299;&#26088;&#22312;&#36890;&#36807;&#28508;&#22312;&#21464;&#37327;&#30340;&#30456;&#20851;&#24615;&#25581;&#31034;&#25968;&#25454;&#30340;&#34920;&#24449;&#65292;&#20854;&#36890;&#36807;&#22240;&#26524;&#27169;&#22411;&#30456;&#20114;&#20851;&#32852;&#12290;&#22914;&#26524;&#35299;&#37322;&#25968;&#25454;&#30340;&#28508;&#22312;&#27169;&#22411;&#26159;&#21807;&#19968;&#30340;&#65292;&#37027;&#20040;&#36825;&#31181;&#34920;&#31034;&#26159;&#21487;&#35782;&#21035;&#30340;&#12290;&#26412;&#25991;&#20851;&#27880;&#30340;&#26159;&#24403;&#23384;&#22312;&#19981;&#37197;&#23545;&#30340;&#35266;&#27979;&#21644;&#24178;&#39044;&#25968;&#25454;&#26102;&#30340;&#24773;&#20917;&#65292;&#27599;&#20010;&#24178;&#39044;&#37117;&#20250;&#25913;&#21464;&#19968;&#20010;&#28508;&#22312;&#21464;&#37327;&#30340;&#26426;&#21046;&#12290;&#24403;&#22240;&#26524;&#21464;&#37327;&#23436;&#20840;&#35266;&#27979;&#21040;&#26102;&#65292;&#22312;&#35802;&#23454;&#24615;&#20551;&#35774;&#19979;&#65292;&#24050;&#32463;&#24320;&#21457;&#20986;&#20102;&#32479;&#35745;&#19968;&#33268;&#30340;&#31639;&#27861;&#26469;&#35782;&#21035;&#22240;&#26524;&#27169;&#22411;&#12290;&#25105;&#20204;&#22312;&#36825;&#37324;&#23637;&#31034;&#65292;&#21363;&#20351;&#23384;&#22312;&#26410;&#35266;&#27979;&#21040;&#30340;&#22240;&#26524;&#21464;&#37327;&#65292;&#22312;&#32473;&#23450;&#19968;&#33324;&#21270;&#30340;&#24544;&#35802;&#24615;&#27010;&#24565;&#30340;&#24773;&#20917;&#19979;&#20173;&#28982;&#21487;&#20197;&#23454;&#29616;&#21487;&#35782;&#21035;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20445;&#35777;&#20102;&#25105;&#20204;&#21487;&#20197;&#24674;&#22797;&#28508;&#22312;&#30340;&#22240;&#26524;&#27169;&#22411;&#65292;&#39044;&#27979;&#26410;&#35265;&#32452;&#21512;&#30340;&#24178;&#39044;&#25928;&#26524;&#65292;&#22312;&#26080;&#38480;&#25968;&#25454;&#30340;&#26497;&#38480;&#24773;&#20917;&#19979;&#12290;&#25105;&#20204;&#36890;&#36807;&#24320;&#21457;&#19968;&#31181;&#33258;&#32534;&#30721;&#21464;&#20998;&#36125;&#21494;&#26031;&#31639;&#27861;&#21644;ap&#26469;&#23454;&#29616;&#25105;&#20204;&#30340;&#22240;&#26524;&#20998;&#35299;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal disentanglement aims to uncover a representation of data using latent variables that are interrelated through a causal model. Such a representation is identifiable if the latent model that explains the data is unique. In this paper, we focus on the scenario where unpaired observational and interventional data are available, with each intervention changing the mechanism of a latent variable. When the causal variables are fully observed, statistically consistent algorithms have been developed to identify the causal model under faithfulness assumptions. We here show that identifiability can still be achieved with unobserved causal variables, given a generalized notion of faithfulness. Our results guarantee that we can recover the latent causal model up to an equivalence class and predict the effect of unseen combinations of interventions, in the limit of infinite data. We implement our causal disentanglement framework by developing an autoencoding variational Bayes algorithm and ap
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21435;&#22122;&#25193;&#25955;&#38544;&#24335;&#27169;&#22411;&#21644;&#37325;&#37319;&#26679;&#30340;&#22320;&#38663;&#25968;&#25454;&#25554;&#20540;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#21644;&#20313;&#24358;&#22122;&#22768;&#35745;&#21010;&#65292;&#23454;&#29616;&#20102;&#31283;&#23450;&#35757;&#32451;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65292;&#24182;&#25552;&#39640;&#20102;&#24050;&#30693;&#36857;&#32447;&#20449;&#24687;&#30340;&#21033;&#29992;&#29575;&#12290;</title><link>http://arxiv.org/abs/2307.04226</link><description>&lt;p&gt;
&#22522;&#20110;&#21435;&#22122;&#25193;&#25955;&#38544;&#24335;&#27169;&#22411;&#21644;&#37325;&#37319;&#26679;&#30340;&#22320;&#38663;&#25968;&#25454;&#25554;&#20540;
&lt;/p&gt;
&lt;p&gt;
Seismic Data Interpolation based on Denoising Diffusion Implicit Models with Resampling. (arXiv:2307.04226v1 [physics.geo-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.04226
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21435;&#22122;&#25193;&#25955;&#38544;&#24335;&#27169;&#22411;&#21644;&#37325;&#37319;&#26679;&#30340;&#22320;&#38663;&#25968;&#25454;&#25554;&#20540;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#21644;&#20313;&#24358;&#22122;&#22768;&#35745;&#21010;&#65292;&#23454;&#29616;&#20102;&#31283;&#23450;&#35757;&#32451;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65292;&#24182;&#25552;&#39640;&#20102;&#24050;&#30693;&#36857;&#32447;&#20449;&#24687;&#30340;&#21033;&#29992;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22320;&#38663;&#25968;&#25454;&#31354;&#38388;&#25193;&#23637;&#19978;&#32570;&#22833;&#21078;&#38754;&#23548;&#33268;&#22320;&#38663;&#25968;&#25454;&#19981;&#23436;&#25972;&#26159;&#22320;&#38663;&#37319;&#38598;&#20013;&#26222;&#36941;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#30001;&#20110;&#38556;&#30861;&#29289;&#21644;&#32463;&#27982;&#38480;&#21046;&#65292;&#36825;&#20005;&#37325;&#24433;&#21709;&#20102;&#22320;&#19979;&#22320;&#36136;&#32467;&#26500;&#30340;&#25104;&#20687;&#36136;&#37327;&#12290;&#26368;&#36817;&#65292;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#22320;&#38663;&#25554;&#20540;&#26041;&#27861;&#21462;&#24471;&#20102;&#20196;&#20154;&#26399;&#24453;&#30340;&#36827;&#23637;&#65292;&#20294;&#31283;&#23450;&#35757;&#32451;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#24182;&#19981;&#23481;&#26131;&#65292;&#22914;&#26524;&#27979;&#35797;&#21644;&#35757;&#32451;&#20013;&#30340;&#32570;&#22833;&#27169;&#24335;&#19981;&#21305;&#37197;&#65292;&#24615;&#33021;&#36864;&#21270;&#36890;&#24120;&#26159;&#26174;&#33879;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22320;&#38663;&#21435;&#22122;&#25193;&#25955;&#38544;&#24335;&#27169;&#22411;&#21644;&#37325;&#37319;&#26679;&#26041;&#27861;&#12290;&#27169;&#22411;&#35757;&#32451;&#24314;&#31435;&#22312;&#21435;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#30340;&#22522;&#30784;&#19978;&#65292;&#20854;&#20013;U-Net&#37197;&#22791;&#20102;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#20197;&#21305;&#37197;&#27599;&#20010;&#27493;&#39588;&#20013;&#30340;&#22122;&#22768;&#12290;&#20313;&#24358;&#22122;&#22768;&#35745;&#21010;&#20316;&#20026;&#20840;&#23616;&#22122;&#22768;&#37197;&#32622;&#65292;&#36890;&#36807;&#21152;&#36895;&#36807;&#24230;&#20449;&#24687;&#30340;&#20256;&#36882;&#26469;&#20419;&#36827;&#24050;&#30693;&#36857;&#32447;&#20449;&#24687;&#30340;&#39640;&#24230;&#21033;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
The incompleteness of the seismic data caused by missing traces along the spatial extension is a common issue in seismic acquisition due to the existence of obstacles and economic constraints, which severely impairs the imaging quality of subsurface geological structures. Recently, deep learning-based seismic interpolation methods have attained promising progress, while achieving stable training of generative adversarial networks is not easy, and performance degradation is usually notable if the missing patterns in the testing and training do not match. In this paper, we propose a novel seismic denoising diffusion implicit model with resampling. The model training is established on the denoising diffusion probabilistic model, where U-Net is equipped with the multi-head self-attention to match the noise in each step. The cosine noise schedule, serving as the global noise configuration, promotes the high utilization of known trace information by accelerating the passage of the excessive 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#20195;&#29702;&#20998;&#31867;&#25439;&#22833;&#30340;&#20551;&#35774;&#36801;&#31227;&#23398;&#20064;&#30340;&#23398;&#20064;&#29702;&#35770;&#65292;&#36890;&#36807;&#31639;&#27861;&#31283;&#23450;&#24615;&#25552;&#20379;&#20102;&#22312;&#28201;&#21644;&#20551;&#35774;&#19979;&#30340;&#23398;&#20064;&#20445;&#35777;&#65292;&#36866;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.19694</link><description>&lt;p&gt;
&#21033;&#29992;&#20195;&#29702;&#20998;&#31867;&#25439;&#22833;&#30340;&#20551;&#35774;&#36801;&#31227;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Hypothesis Transfer Learning with Surrogate Classification Losses. (arXiv:2305.19694v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19694
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#20195;&#29702;&#20998;&#31867;&#25439;&#22833;&#30340;&#20551;&#35774;&#36801;&#31227;&#23398;&#20064;&#30340;&#23398;&#20064;&#29702;&#35770;&#65292;&#36890;&#36807;&#31639;&#27861;&#31283;&#23450;&#24615;&#25552;&#20379;&#20102;&#22312;&#28201;&#21644;&#20551;&#35774;&#19979;&#30340;&#23398;&#20064;&#20445;&#35777;&#65292;&#36866;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20551;&#35774;&#36801;&#31227;&#23398;&#20064;&#65288;HTL&#65289;&#36890;&#36807;&#20801;&#35768;&#20808;&#21069;&#20219;&#21153;&#65288;&#21363;&#28304;&#20219;&#21153;&#65289;&#21521;&#19968;&#20010;&#26032;&#20219;&#21153;&#65288;&#30446;&#26631;&#20219;&#21153;&#65289;&#36716;&#31227;&#23398;&#20064;&#65292;&#32780;&#26080;&#38656;&#35775;&#38382;&#28304;&#25968;&#25454;&#65292;&#19982;&#39046;&#22495;&#33258;&#36866;&#24212;&#30456;&#23545;&#24212;&#12290;&#20107;&#23454;&#19978;&#65292;HTL&#20165;&#20381;&#36182;&#20110;&#20174;&#28304;&#25968;&#25454;&#23398;&#20064;&#21040;&#30340;&#20551;&#35774;&#65292;&#20813;&#38500;&#20102;&#22823;&#37327;&#25968;&#25454;&#23384;&#20648;&#30340;&#38556;&#30861;&#65292;&#24182;&#25552;&#20379;&#20102;&#24040;&#22823;&#30340;&#23454;&#38469;&#21033;&#30410;&#12290;&#22240;&#27492;&#65292;HTL&#23545;&#20110;&#20381;&#36182;&#20110;&#22823;&#25968;&#25454;&#30340;&#23454;&#38469;&#24212;&#29992;&#38750;&#24120;&#26377;&#21033;&#12290;&#26412;&#25991;&#36890;&#36807;&#31639;&#27861;&#31283;&#23450;&#24615;&#30740;&#31350;HTL&#30340;&#23398;&#20064;&#29702;&#35770;&#65292;&#36825;&#26159;&#19968;&#31181;&#29992;&#20110;&#20998;&#26512;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#26377;&#21560;&#24341;&#21147;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#29305;&#21035;&#26159;&#22312;&#20108;&#20998;&#31867;&#24773;&#20917;&#19979;&#24863;&#20852;&#36259;&#12290;&#25105;&#20204;&#30340;&#31283;&#23450;&#24615;&#20998;&#26512;&#25552;&#20379;&#20102;&#22312;&#28201;&#21644;&#20551;&#35774;&#19979;&#30340;&#23398;&#20064;&#20445;&#35777;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24471;&#20986;&#20102;&#20960;&#20010;&#27604;&#20197;&#21069;&#26356;&#32039;&#23494;&#30340;&#29702;&#35770;&#30028;&#38480;&#65292;&#36825;&#20123;&#30028;&#38480;&#21487;&#20197;&#23454;&#38469;&#24212;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hypothesis transfer learning (HTL) contrasts domain adaptation by allowing for a previous task leverage, named the source, into a new one, the target, without requiring access to the source data. Indeed, HTL relies only on a hypothesis learnt from such source data, relieving the hurdle of expansive data storage and providing great practical benefits. Hence, HTL is highly beneficial for real-world applications relying on big data. The analysis of such a method from a theoretical perspective faces multiple challenges, particularly in classification tasks. This paper deals with this problem by studying the learning theory of HTL through algorithmic stability, an attractive theoretical framework for machine learning algorithms analysis. In particular, we are interested in the statistical behaviour of the regularized empirical risk minimizers in the case of binary classification. Our stability analysis provides learning guarantees under mild assumptions. Consequently, we derive several comp
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;DoCoFL&#65292;&#19968;&#31181;&#29992;&#20110;&#36328;&#35774;&#22791;&#32852;&#21512;&#23398;&#20064;&#30340;&#19979;&#34892;&#21387;&#32553;&#26694;&#26550;&#65292;&#33021;&#22815;&#22312;&#38477;&#20302;&#21452;&#21521;&#24102;&#23485;&#30340;&#21516;&#26102;&#20445;&#25345;&#31454;&#20105;&#21147;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.00543</link><description>&lt;p&gt;
DoCoFL&#65306;&#29992;&#20110;&#36328;&#35774;&#22791;&#32852;&#21512;&#23398;&#20064;&#30340;&#19979;&#34892;&#21387;&#32553;
&lt;/p&gt;
&lt;p&gt;
DoCoFL: Downlink Compression for Cross-Device Federated Learning. (arXiv:2302.00543v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.00543
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;DoCoFL&#65292;&#19968;&#31181;&#29992;&#20110;&#36328;&#35774;&#22791;&#32852;&#21512;&#23398;&#20064;&#30340;&#19979;&#34892;&#21387;&#32553;&#26694;&#26550;&#65292;&#33021;&#22815;&#22312;&#38477;&#20302;&#21452;&#21521;&#24102;&#23485;&#30340;&#21516;&#26102;&#20445;&#25345;&#31454;&#20105;&#21147;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#21387;&#32553;&#25216;&#26415;&#24050;&#34987;&#25552;&#20986;&#29992;&#20110;&#20943;&#23569;&#32852;&#21512;&#23398;&#20064;&#35757;&#32451;&#36807;&#31243;&#20013;&#30340;&#36890;&#20449;&#24320;&#38144;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#25216;&#26415;&#36890;&#24120;&#29992;&#20110;&#21387;&#32553;&#27169;&#22411;&#26356;&#26032;&#65292;&#32780;&#27169;&#22411;&#26356;&#26032;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#20250;&#36880;&#28176;&#20943;&#23569;&#12290;&#22240;&#27492;&#65292;&#36825;&#20123;&#26041;&#27861;&#19981;&#36866;&#29992;&#20110;&#36328;&#35774;&#22791;&#30340;&#19979;&#34892;&#65288;&#21363;&#20174;&#26381;&#21153;&#22120;&#21040;&#23458;&#25143;&#31471;&#65289;&#21387;&#32553;&#65292;&#22312;&#36825;&#31181;&#22330;&#26223;&#19979;&#65292;&#24322;&#26500;&#23458;&#25143;&#31471;&#22312;&#35757;&#32451;&#26399;&#38388;&#21487;&#33021;&#21482;&#20986;&#29616;&#19968;&#27425;&#65292;&#22240;&#27492;&#24517;&#39035;&#19979;&#36733;&#27169;&#22411;&#21442;&#25968;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;DoCoFL&#8212;&#8212;&#19968;&#20010;&#26032;&#30340;&#29992;&#20110;&#36328;&#35774;&#22791;&#19979;&#34892;&#21387;&#32553;&#30340;&#26694;&#26550;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;DoCoFL&#21487;&#20197;&#26080;&#32541;&#22320;&#19982;&#35768;&#22810;&#19978;&#34892;&#21387;&#32553;&#26041;&#26696;&#32467;&#21512;&#20351;&#29992;&#65292;&#20351;&#20854;&#36866;&#29992;&#20110;&#21452;&#21521;&#21387;&#32553;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#35780;&#20272;&#65292;&#25105;&#20204;&#35777;&#26126;DoCoFL&#22312;&#26174;&#33879;&#38477;&#20302;&#21452;&#21521;&#24102;&#23485;&#30340;&#21516;&#26102;&#65292;&#23454;&#29616;&#20102;&#19982;&#27809;&#26377;&#20219;&#20309;&#21387;&#32553;&#30340;&#22522;&#20934;&#27169;&#22411;&#30456;&#24403;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many compression techniques have been proposed to reduce the communication overhead of Federated Learning training procedures. However, these are typically designed for compressing model updates, which are expected to decay throughout training. As a result, such methods are inapplicable to downlink (i.e., from the parameter server to clients) compression in the cross-device setting, where heterogeneous clients $\textit{may appear only once}$ during training and thus must download the model parameters. Accordingly, we propose $\textsf{DoCoFL}$ -- a new framework for downlink compression in the cross-device setting. Importantly, $\textsf{DoCoFL}$ can be seamlessly combined with many uplink compression schemes, rendering it suitable for bi-directional compression. Through extensive evaluation, we show that $\textsf{DoCoFL}$ offers significant bi-directional bandwidth reduction while achieving competitive accuracy to that of a baseline without any compression.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#27963;&#21160;&#30340;&#32479;&#35745;&#21644;&#20960;&#20309;&#23646;&#24615;&#19982;&#24615;&#33021;&#30340;&#20851;&#31995;&#65292;&#24182;&#21457;&#29616;&#20102;&#32447;&#24615;&#21487;&#20998;&#24615;&#30340;&#24230;&#37327;&#19982;&#30446;&#26631;&#34920;&#31034;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#30740;&#31350;&#32467;&#26524;&#25581;&#31034;&#20102;&#20851;&#20110;&#30456;&#20851;&#24615;&#21644;&#20960;&#20309;&#24615;&#36136;&#20043;&#38388;&#30340;&#20108;&#20803;&#24615;&#22312;&#20998;&#31867;&#38382;&#39064;&#19978;&#30340;&#38382;&#39064;&#65292;&#24182;&#36827;&#19968;&#27493;&#24212;&#29992;&#21040;&#28145;&#24230;&#32593;&#32476;&#25968;&#25454;&#20013;&#12290;</title><link>http://arxiv.org/abs/2211.14961</link><description>&lt;p&gt;
&#31070;&#32463;&#27969;&#24418;&#30340;&#30456;&#20851;&#21464;&#24322;&#30340;&#32447;&#24615;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Linear Classification of Neural Manifolds with Correlated Variability. (arXiv:2211.14961v2 [q-bio.NC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.14961
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#27963;&#21160;&#30340;&#32479;&#35745;&#21644;&#20960;&#20309;&#23646;&#24615;&#19982;&#24615;&#33021;&#30340;&#20851;&#31995;&#65292;&#24182;&#21457;&#29616;&#20102;&#32447;&#24615;&#21487;&#20998;&#24615;&#30340;&#24230;&#37327;&#19982;&#30446;&#26631;&#34920;&#31034;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#30740;&#31350;&#32467;&#26524;&#25581;&#31034;&#20102;&#20851;&#20110;&#30456;&#20851;&#24615;&#21644;&#20960;&#20309;&#24615;&#36136;&#20043;&#38388;&#30340;&#20108;&#20803;&#24615;&#22312;&#20998;&#31867;&#38382;&#39064;&#19978;&#30340;&#38382;&#39064;&#65292;&#24182;&#36827;&#19968;&#27493;&#24212;&#29992;&#21040;&#28145;&#24230;&#32593;&#32476;&#25968;&#25454;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#31070;&#32463;&#27963;&#21160;&#30340;&#32479;&#35745;&#21644;&#20960;&#20309;&#23646;&#24615;&#19982;&#24615;&#33021;&#30340;&#20851;&#31995;&#26159;&#29702;&#35770;&#31070;&#32463;&#31185;&#23398;&#21644;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#35745;&#31639;&#30446;&#26631;&#34920;&#31034;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#22914;&#20309;&#24433;&#21709;&#32447;&#24615;&#21487;&#20998;&#24615;&#30340;&#24230;&#37327;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#23545;&#20110;&#29699;&#24418;&#30446;&#26631;&#27969;&#24418;&#65292;&#24341;&#20837;&#36136;&#24515;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#26377;&#25928;&#22320;&#23558;&#29699;&#20307;&#25512;&#21521;&#19968;&#36215;&#65292;&#32780;&#24341;&#20837;&#36724;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#26377;&#25928;&#22320;&#32553;&#23567;&#20102;&#23427;&#20204;&#30340;&#21322;&#24452;&#65292;&#25581;&#31034;&#20102;&#20851;&#20110;&#30456;&#20851;&#24615;&#21644;&#20960;&#20309;&#24615;&#36136;&#20043;&#38388;&#30340;&#20108;&#20803;&#24615;&#22312;&#20998;&#31867;&#38382;&#39064;&#19978;&#30340;&#38382;&#39064;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#32467;&#26524;&#24212;&#29992;&#20110;&#20934;&#30830;&#22320;&#20272;&#35745;&#28145;&#24230;&#32593;&#32476;&#25968;&#25454;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding how the statistical and geometric properties of neural activity relate to performance is a key problem in theoretical neuroscience and deep learning. Here, we calculate how correlations between object representations affect the capacity, a measure of linear separability. We show that for spherical object manifolds, introducing correlations between centroids effectively pushes the spheres closer together, while introducing correlations between the axes effectively shrinks their radii, revealing a duality between correlations and geometry with respect to the problem of classification. We then apply our results to accurately estimate the capacity of deep network data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29289;&#29702;&#25351;&#23548;&#30340;&#21160;&#24577;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120; ($\Phi$-DVAE) &#29992;&#20110;&#23558;&#38750;&#32467;&#26500;&#21270;&#25968;&#25454;&#21516;&#21270;&#21040;&#29289;&#29702;&#27169;&#22411;&#20013;&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;&#26041;&#27861;&#22312;&#26410;&#30693;&#26144;&#23556;&#24773;&#20917;&#19979;&#26080;&#27861;&#23454;&#29616;&#19968;&#33268;&#27169;&#22411;&#19982;&#25968;&#25454;&#32508;&#21512;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2209.15609</link><description>&lt;p&gt;
$\Phi$-DVAE: &#29289;&#29702;&#25351;&#23548;&#30340;&#21160;&#24577;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#29992;&#20110;&#38750;&#32467;&#26500;&#21270;&#25968;&#25454;&#21516;&#21270;
&lt;/p&gt;
&lt;p&gt;
$\Phi$-DVAE: Physics-Informed Dynamical Variational Autoencoders for Unstructured Data Assimilation. (arXiv:2209.15609v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.15609
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29289;&#29702;&#25351;&#23548;&#30340;&#21160;&#24577;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120; ($\Phi$-DVAE) &#29992;&#20110;&#23558;&#38750;&#32467;&#26500;&#21270;&#25968;&#25454;&#21516;&#21270;&#21040;&#29289;&#29702;&#27169;&#22411;&#20013;&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;&#26041;&#27861;&#22312;&#26410;&#30693;&#26144;&#23556;&#24773;&#20917;&#19979;&#26080;&#27861;&#23454;&#29616;&#19968;&#33268;&#27169;&#22411;&#19982;&#25968;&#25454;&#32508;&#21512;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25968;&#25454;&#21516;&#21270;&#20013;&#65292;&#23558;&#38750;&#32467;&#26500;&#21270;&#25968;&#25454;&#32435;&#20837;&#29289;&#29702;&#27169;&#22411;&#26159;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#12290;&#20256;&#32479;&#26041;&#27861;&#36890;&#24120;&#20851;&#27880;&#20855;&#26377;&#26126;&#30830;&#23450;&#20041;&#35266;&#27979;&#31639;&#23376;&#30340;&#24773;&#20917;&#65292;&#20854;&#20989;&#25968;&#24418;&#24335;&#36890;&#24120;&#34987;&#20551;&#23450;&#20026;&#24050;&#30693;&#12290;&#36825;&#38459;&#27490;&#20102;&#36825;&#20123;&#26041;&#27861;&#22312;&#20174;&#25968;&#25454;&#31354;&#38388;&#21040;&#27169;&#22411;&#31354;&#38388;&#30340;&#26144;&#23556;&#26410;&#30693;&#30340;&#37197;&#32622;&#20013;&#23454;&#29616;&#19968;&#33268;&#30340;&#27169;&#22411;&#19982;&#25968;&#25454;&#32508;&#21512;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#22312;&#26412;&#25991;&#20013;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#29289;&#29702;&#25351;&#23548;&#30340;&#21160;&#24577;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;($\Phi$-DVAE)&#65292;&#23558;&#22810;&#26679;&#21270;&#30340;&#25968;&#25454;&#27969;&#23884;&#20837;&#21040;&#30001;&#24494;&#20998;&#26041;&#31243;&#25551;&#36848;&#30340;&#26102;&#21464;&#29289;&#29702;&#31995;&#32479;&#20013;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#32467;&#21512;&#20102;&#19968;&#20010;&#26631;&#20934;&#30340;&#12289;&#21487;&#33021;&#26159;&#38750;&#32447;&#24615;&#30340;&#28508;&#22312;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#28388;&#27874;&#22120;&#21644;&#19968;&#20010;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65292;&#23558;&#38750;&#32467;&#26500;&#21270;&#25968;&#25454;&#21516;&#21270;&#21040;&#28508;&#22312;&#30340;&#21160;&#24577;&#31995;&#32479;&#20013;&#12290;&#22312;&#25105;&#20204;&#30340;&#31034;&#20363;&#31995;&#32479;&#20013;&#65292;&#38750;&#32467;&#26500;&#21270;&#25968;&#25454;&#37319;&#29992;&#35270;&#39057;&#25968;&#25454;&#21644;&#36895;&#24230;&#22330;&#27979;&#37327;&#30340;&#24418;&#24335;&#65292;&#20294;&#35813;&#26041;&#27861;&#30340;&#36866;&#29992;&#24615;&#36275;&#22815;&#36890;&#29992;&#65292;&#21487;&#20197;&#20801;&#35768;&#20219;&#24847;&#26410;&#30693;&#30340;&#35266;&#27979;&#31639;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;
Incorporating unstructured data into physical models is a challenging problem that is emerging in data assimilation. Traditional approaches focus on well-defined observation operators whose functional forms are typically assumed to be known. This prevents these methods from achieving a consistent model-data synthesis in configurations where the mapping from data-space to model-space is unknown. To address these shortcomings, in this paper we develop a physics-informed dynamical variational autoencoder ($\Phi$-DVAE) to embed diverse data streams into time-evolving physical systems described by differential equations. Our approach combines a standard, possibly nonlinear, filter for the latent state-space model and a VAE, to assimilate the unstructured data into the latent dynamical system. Unstructured data, in our example systems, comes in the form of video data and velocity field measurements, however the methodology is suitably generic to allow for arbitrary unknown observation operat
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#20302;&#22122;&#22768;&#30340;&#24046;&#20998;&#38544;&#31169;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#27861;&#22312;&#28857;&#38382;&#39064;&#21644;&#25104;&#23545;&#23398;&#20064;&#20013;&#30340;&#24615;&#33021;&#65292;&#24182;&#25512;&#23548;&#20986;&#26356;&#31934;&#30830;&#30340;&#36807;&#21097;&#39118;&#38505;&#30028;&#38480;&#12290;&#25552;&#20986;&#30340;&#31639;&#27861;&#22522;&#20110;&#26799;&#24230;&#25200;&#21160;&#65292;&#20855;&#26377;&#20248;&#21270;&#36807;&#21097;&#39118;&#38505;&#29575;&#30340;&#26368;&#20339;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2209.04188</link><description>&lt;p&gt;
&#20855;&#26377;&#20302;&#22122;&#22768;&#30340;&#24046;&#20998;&#38544;&#31169;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#27861;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Stochastic Gradient Descent with Low-Noise. (arXiv:2209.04188v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.04188
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#20302;&#22122;&#22768;&#30340;&#24046;&#20998;&#38544;&#31169;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#27861;&#22312;&#28857;&#38382;&#39064;&#21644;&#25104;&#23545;&#23398;&#20064;&#20013;&#30340;&#24615;&#33021;&#65292;&#24182;&#25512;&#23548;&#20986;&#26356;&#31934;&#30830;&#30340;&#36807;&#21097;&#39118;&#38505;&#30028;&#38480;&#12290;&#25552;&#20986;&#30340;&#31639;&#27861;&#22522;&#20110;&#26799;&#24230;&#25200;&#21160;&#65292;&#20855;&#26377;&#20248;&#21270;&#36807;&#21097;&#39118;&#38505;&#29575;&#30340;&#26368;&#20339;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#26088;&#22312;&#20174;&#25968;&#25454;&#20013;&#25552;&#21462;&#32454;&#31890;&#24230;&#20449;&#24687;&#65292;&#20197;&#25552;&#20379;&#20934;&#30830;&#30340;&#39044;&#27979;&#65292;&#20294;&#36825;&#24448;&#24448;&#19982;&#20445;&#25252;&#38544;&#31169;&#30340;&#30446;&#26631;&#30456;&#20914;&#31361;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#24320;&#21457;&#20445;&#25252;&#38544;&#31169;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#22312;&#30830;&#20445;&#33391;&#22909;&#24615;&#33021;&#30340;&#21516;&#26102;&#20445;&#25252;&#38544;&#31169;&#30340;&#23454;&#38469;&#21644;&#29702;&#35770;&#37325;&#35201;&#24615;&#12290;&#25105;&#20204;&#22312;&#38543;&#26426;&#20984;&#20248;&#21270;&#35774;&#32622;&#20013;&#65292;&#20851;&#27880;&#24046;&#20998;&#38544;&#31169;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#31639;&#27861;&#22312;&#38544;&#31169;&#24615;&#21644;&#25928;&#29992;&#24615;&#65288;&#36890;&#36807;&#36807;&#21097;&#39118;&#38505;&#30028;&#38480;&#34913;&#37327;&#65289;&#26041;&#38754;&#30340;&#24615;&#33021;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20302;&#22122;&#22768;&#35774;&#32622;&#19979;&#30340;&#28857;&#38382;&#39064;&#65292;&#24182;&#24471;&#20986;&#20102;&#24046;&#20998;&#38544;&#31169;SGD&#31639;&#27861;&#26356;&#31934;&#30830;&#30340;&#36807;&#21097;&#39118;&#38505;&#30028;&#38480;&#12290;&#22312;&#25104;&#23545;&#23398;&#20064;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26799;&#24230;&#25200;&#21160;&#30340;&#31616;&#21333;&#24046;&#20998;&#38544;&#31169;SGD&#31639;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#25152;&#25552;&#31639;&#27861;&#30340;&#26032;&#22411;&#25928;&#29992;&#30028;&#38480;&#65292;&#35777;&#26126;&#23427;&#21363;&#20351;&#22312;&#38750;&#20809;&#28369;&#24773;&#20917;&#19979;&#20063;&#33021;&#36798;&#21040;&#26368;&#20248;&#30340;&#36807;&#21097;&#39118;&#38505;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern machine learning algorithms aim to extract fine-grained information from data to provide accurate predictions, which often conflicts with the goal of privacy protection. This paper addresses the practical and theoretical importance of developing privacy-preserving machine learning algorithms that ensure good performance while preserving privacy. In this paper, we focus on the privacy and utility (measured by excess risk bounds) performances of differentially private stochastic gradient descent (SGD) algorithms in the setting of stochastic convex optimization. Specifically, we examine the pointwise problem in the low-noise setting for which we derive sharper excess risk bounds for the differentially private SGD algorithm. In the pairwise learning setting, we propose a simple differentially private SGD algorithm based on gradient perturbation. Furthermore, we develop novel utility bounds for the proposed algorithm, proving that it achieves optimal excess risk rates even for non-sm
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#21644;&#27010;&#29575;&#24314;&#27169;&#30340;&#20840;&#27010;&#29575;&#28145;&#24230;&#27169;&#22411;&#65292;&#29992;&#20110;&#23398;&#20064;&#21442;&#25968;&#21270;&#20559;&#24494;&#20998;&#26041;&#31243;&#20013;&#30340;&#21069;&#21521;&#21644;&#21453;&#21521;&#26144;&#23556;&#12290;&#27169;&#22411;&#36890;&#36807;&#26368;&#22823;&#21270;&#35266;&#23519;&#21040;&#30340;&#38646;&#27531;&#24046;&#30340;&#27010;&#29575;&#26469;&#36827;&#34892;&#35757;&#32451;&#65292;&#19981;&#38656;&#35201;&#29420;&#31435;&#30340;&#35757;&#32451;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2208.04856</link><description>&lt;p&gt;
&#21442;&#25968;&#21270;&#20559;&#24494;&#20998;&#26041;&#31243;&#20013;&#21069;&#21521;&#21644;&#21453;&#21521;&#38382;&#39064;&#30340;&#20840;&#27010;&#29575;&#28145;&#24230;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Fully probabilistic deep models for forward and inverse problems in parametric PDEs. (arXiv:2208.04856v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.04856
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#21644;&#27010;&#29575;&#24314;&#27169;&#30340;&#20840;&#27010;&#29575;&#28145;&#24230;&#27169;&#22411;&#65292;&#29992;&#20110;&#23398;&#20064;&#21442;&#25968;&#21270;&#20559;&#24494;&#20998;&#26041;&#31243;&#20013;&#30340;&#21069;&#21521;&#21644;&#21453;&#21521;&#26144;&#23556;&#12290;&#27169;&#22411;&#36890;&#36807;&#26368;&#22823;&#21270;&#35266;&#23519;&#21040;&#30340;&#38646;&#27531;&#24046;&#30340;&#27010;&#29575;&#26469;&#36827;&#34892;&#35757;&#32451;&#65292;&#19981;&#38656;&#35201;&#29420;&#31435;&#30340;&#35757;&#32451;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#29289;&#29702;&#39537;&#21160;&#30340;&#28145;&#24230;&#28508;&#21464;&#37327;&#27169;&#22411;&#65288;PDDLVM&#65289;&#65292;&#29992;&#20110;&#21516;&#26102;&#23398;&#20064;&#21442;&#25968;&#21270;&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;PDEs&#65289;&#30340;&#21442;&#25968;&#21040;&#35299;&#65288;&#21069;&#21521;&#65289;&#21644;&#35299;&#21040;&#21442;&#25968;&#65288;&#21453;&#21521;&#65289;&#26144;&#23556;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#32467;&#21512;&#20102;&#20256;&#32479;&#30340;PDE&#31163;&#25955;&#21270;&#25216;&#26415;&#12289;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#12289;&#27010;&#29575;&#24314;&#27169;&#21644;&#21464;&#20998;&#25512;&#26029;&#65292;&#24418;&#25104;&#20102;&#19968;&#20010;&#23436;&#20840;&#27010;&#29575;&#19968;&#33268;&#30340;&#26694;&#26550;&#12290;&#22312;&#25152;&#20551;&#35774;&#30340;&#27010;&#29575;&#27169;&#22411;&#20013;&#65292;&#21069;&#21521;&#21644;&#21453;&#21521;&#26144;&#23556;&#22343;&#34987;&#36817;&#20284;&#20026;&#30001;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#30340;&#39640;&#26031;&#20998;&#24067;&#12290;&#25105;&#20204;&#20551;&#35774;PDE&#27531;&#24046;&#26159;&#19968;&#20010;&#35266;&#27979;&#21040;&#30340;&#38543;&#26426;&#21521;&#37327;&#65292;&#20540;&#20026;&#38646;&#65292;&#22240;&#27492;&#25105;&#20204;&#23558;&#20854;&#24314;&#27169;&#20026;&#19968;&#20010;&#22343;&#20540;&#20026;&#38646;&#12289;&#29992;&#25143;&#25351;&#23450;&#21327;&#26041;&#24046;&#30340;&#38543;&#26426;&#21521;&#37327;&#12290;&#35813;&#27169;&#22411;&#36890;&#36807;&#26368;&#22823;&#21270;&#35266;&#23519;&#21040;&#38646;&#27531;&#24046;&#30340;&#27010;&#29575;&#65288;&#21363;&#35777;&#25454;&#25110;&#36793;&#38469;&#20284;&#28982;&#65289;&#26469;&#36827;&#34892;&#35757;&#32451;&#65292;&#26368;&#22823;&#21270;&#35777;&#25454;&#19979;&#30028;&#65288;ELBO&#65289;&#12290;&#22240;&#27492;&#65292;&#35813;&#26041;&#27861;&#19981;&#38656;&#35201;&#20219;&#20309;&#29420;&#31435;&#30340;&#35757;&#32451;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a physics-driven deep latent variable model (PDDLVM) to learn simultaneously parameter-to-solution (forward) and solution-to-parameter (inverse) maps of parametric partial differential equations (PDEs). Our formulation leverages conventional PDE discretization techniques, deep neural networks, probabilistic modelling, and variational inference to assemble a fully probabilistic coherent framework. In the posited probabilistic model, both the forward and inverse maps are approximated as Gaussian distributions with a mean and covariance parameterized by deep neural networks. The PDE residual is assumed to be an observed random vector of value zero, hence we model it as a random vector with a zero mean and a user-prescribed covariance. The model is trained by maximizing the probability, that is the evidence or marginal likelihood, of observing a residual of zero by maximizing the evidence lower bound (ELBO). Consequently, the proposed methodology does not require any independe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#22914;&#20309;&#22312;&#20195;&#29702;&#20351;&#29992;&#22797;&#26434;&#30340;&#8220;&#40657;&#30418;&#8221;&#39044;&#27979;&#20989;&#25968;&#36827;&#34892;&#20915;&#31574;&#30340;&#24773;&#20917;&#19979;&#65292;&#23545;&#31639;&#27861;&#20915;&#31574;&#36827;&#34892;&#26368;&#20248;&#35843;&#25511;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#38480;&#21046;&#20195;&#29702;&#20351;&#29992;&#36879;&#26126;&#24230;&#36275;&#22815;&#39640;&#30340;&#39044;&#27979;&#20989;&#25968;&#26159;&#20302;&#25928;&#30340;&#65292;&#32780;&#38024;&#23545;&#28608;&#21169;&#20559;&#24046;&#28304;&#22836;&#30340;&#30446;&#26631;&#21270;&#24037;&#20855;&#21487;&#20197;&#25552;&#20379;&#27425;&#20248;&#35299;&#20915;&#26041;&#26696;&#65292;&#20174;&#32780;&#25913;&#21892;&#31119;&#21033;&#12290;</title><link>http://arxiv.org/abs/2110.03443</link><description>&lt;p&gt;
&#25581;&#24320;&#40657;&#30418;&#23376;&#65306;&#35843;&#25511;&#31639;&#27861;&#20915;&#31574;
&lt;/p&gt;
&lt;p&gt;
Unpacking the Black Box: Regulating Algorithmic Decisions. (arXiv:2110.03443v2 [econ.GN] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.03443
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22914;&#20309;&#22312;&#20195;&#29702;&#20351;&#29992;&#22797;&#26434;&#30340;&#8220;&#40657;&#30418;&#8221;&#39044;&#27979;&#20989;&#25968;&#36827;&#34892;&#20915;&#31574;&#30340;&#24773;&#20917;&#19979;&#65292;&#23545;&#31639;&#27861;&#20915;&#31574;&#36827;&#34892;&#26368;&#20248;&#35843;&#25511;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#38480;&#21046;&#20195;&#29702;&#20351;&#29992;&#36879;&#26126;&#24230;&#36275;&#22815;&#39640;&#30340;&#39044;&#27979;&#20989;&#25968;&#26159;&#20302;&#25928;&#30340;&#65292;&#32780;&#38024;&#23545;&#28608;&#21169;&#20559;&#24046;&#28304;&#22836;&#30340;&#30446;&#26631;&#21270;&#24037;&#20855;&#21487;&#20197;&#25552;&#20379;&#27425;&#20248;&#35299;&#20915;&#26041;&#26696;&#65292;&#20174;&#32780;&#25913;&#21892;&#31119;&#21033;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#22312;&#19968;&#20010;&#20195;&#29702;&#20351;&#29992;&#22797;&#26434;&#30340;&#8220;&#40657;&#30418;&#8221;&#39044;&#27979;&#20989;&#25968;&#36827;&#34892;&#20915;&#31574;&#65288;&#22914;&#36151;&#27454;&#12289;&#21307;&#30103;&#27979;&#35797;&#25110;&#25307;&#32856;&#65289;&#19988;&#22996;&#25176;&#20154;&#22312;&#20102;&#35299;&#20195;&#29702;&#30340;&#40657;&#30418;&#27169;&#22411;&#26041;&#38754;&#26377;&#38480;&#30340;&#24773;&#20917;&#19979;&#65292;&#26368;&#20248;&#22320;&#35843;&#25511;&#39044;&#27979;&#31639;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#21482;&#35201;&#35825;&#23548;&#19981;&#36275;&#65292;&#19988;&#26368;&#20248;&#39044;&#27979;&#20989;&#25968;&#36275;&#22815;&#22797;&#26434;&#65292;&#23558;&#20195;&#29702;&#38480;&#21046;&#22312;&#36275;&#22815;&#36879;&#26126;&#30340;&#39044;&#27979;&#20989;&#25968;&#20013;&#26159;&#20302;&#25928;&#30340;&#12290;&#31639;&#27861;&#23457;&#35745;&#26377;&#21161;&#20110;&#25552;&#39640;&#31119;&#21033;&#65292;&#20294;&#20854;&#25910;&#30410;&#21462;&#20915;&#20110;&#23457;&#35745;&#24037;&#20855;&#30340;&#35774;&#35745;&#12290;&#35768;&#22810;&#35299;&#37322;&#24037;&#20855;&#20542;&#21521;&#20110;&#26368;&#23567;&#21270;&#25972;&#20307;&#20449;&#24687;&#25439;&#22833;&#65292;&#20294;&#36825;&#36890;&#24120;&#26159;&#20302;&#25928;&#30340;&#65292;&#22240;&#20026;&#23427;&#20204;&#38598;&#20013;&#20110;&#35299;&#37322;&#39044;&#27979;&#20989;&#25968;&#30340;&#24179;&#22343;&#34892;&#20026;&#12290;&#38024;&#23545;&#24615;&#30340;&#24037;&#20855;&#65292;&#22914;&#38024;&#23545;&#28608;&#21169;&#20559;&#24046;&#28304;&#22836;&#65288;&#22914;&#36807;&#22810;&#30340;&#20551;&#38451;&#24615;&#25110;&#31181;&#26063;&#24046;&#24322;&#65289;&#30340;&#24037;&#20855;&#65292;&#21487;&#20197;&#25552;&#20379;&#27425;&#20248;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#25105;&#20204;&#29702;&#35770;&#30340;&#23454;&#35777;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;
We show how to optimally regulate prediction algorithms in a world where an agent uses complex 'black-box' prediction functions to make decisions such as lending, medical testing, or hiring, and where a principal is limited in how much she can learn about the agent's black-box model. We show that limiting agents to prediction functions that are simple enough to be fully transparent is inefficient as long as the misalignment is limited and first-best prediction functions are sufficiently complex. Algorithmic audits can improve welfare, but the gains depend on the design of the audit tools. Tools that focus on minimizing overall information loss, the focus of many explainer tools, will generally be inefficient since they focus on explaining the average behavior of the prediction function. Targeted tools that focus on the source of incentive misalignment, e.g., excess false positives or racial disparities, can provide second-best solutions. We provide empirical support for our theoretical
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#20351;&#29992;&#22810;&#33218;&#36172;&#21338;&#26426;&#27169;&#22411;&#20998;&#26512;&#25307;&#32856;&#24066;&#22330;&#20013;&#30340;&#32479;&#35745;&#27495;&#35270;&#65292;&#21457;&#29616;&#33258;&#30001;&#25918;&#20219;&#20250;&#23548;&#33268;&#23545;&#23569;&#25968;&#26063;&#35028;&#24037;&#20154;&#30340;&#25345;&#32493;&#20302;&#20272;&#38382;&#39064;&#12290;&#30740;&#31350;&#25552;&#20986;&#20102;&#20004;&#31181;&#25919;&#31574;&#35299;&#20915;&#26041;&#26696;&#65292;&#21363;&#28151;&#21512;&#26426;&#21046;&#21644;&#32599;&#23612;&#27861;&#21017;&#65292;&#34920;&#26126;&#20020;&#26102;&#32943;&#23450;&#34892;&#21160;&#21487;&#20197;&#26377;&#25928;&#32531;&#35299;&#30001;&#20110;&#25968;&#25454;&#19981;&#36275;&#24341;&#36215;&#30340;&#27495;&#35270;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2010.01079</link><description>&lt;p&gt;
&#23545;&#32479;&#35745;&#27495;&#35270;&#20316;&#20026;&#31038;&#20250;&#23398;&#20064;&#22833;&#36133;&#30340;&#30740;&#31350;&#65306;&#19968;&#20010;&#22810;&#33218;&#36172;&#21338;&#26426;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
On Statistical Discrimination as a Failure of Social Learning: A Multi-Armed Bandit Approach. (arXiv:2010.01079v6 [econ.TH] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2010.01079
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#20351;&#29992;&#22810;&#33218;&#36172;&#21338;&#26426;&#27169;&#22411;&#20998;&#26512;&#25307;&#32856;&#24066;&#22330;&#20013;&#30340;&#32479;&#35745;&#27495;&#35270;&#65292;&#21457;&#29616;&#33258;&#30001;&#25918;&#20219;&#20250;&#23548;&#33268;&#23545;&#23569;&#25968;&#26063;&#35028;&#24037;&#20154;&#30340;&#25345;&#32493;&#20302;&#20272;&#38382;&#39064;&#12290;&#30740;&#31350;&#25552;&#20986;&#20102;&#20004;&#31181;&#25919;&#31574;&#35299;&#20915;&#26041;&#26696;&#65292;&#21363;&#28151;&#21512;&#26426;&#21046;&#21644;&#32599;&#23612;&#27861;&#21017;&#65292;&#34920;&#26126;&#20020;&#26102;&#32943;&#23450;&#34892;&#21160;&#21487;&#20197;&#26377;&#25928;&#32531;&#35299;&#30001;&#20110;&#25968;&#25454;&#19981;&#36275;&#24341;&#36215;&#30340;&#27495;&#35270;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20351;&#29992;&#19968;&#20010;&#22810;&#33218;&#36172;&#21338;&#26426;&#27169;&#22411;&#26469;&#20998;&#26512;&#25307;&#32856;&#24066;&#22330;&#20013;&#30340;&#32479;&#35745;&#27495;&#35270;&#12290;&#30446;&#20809;&#30701;&#27973;&#30340;&#20844;&#21496;&#38754;&#20020;&#30528;&#20855;&#26377;&#19981;&#21516;&#21487;&#35266;&#23519;&#29305;&#24449;&#30340;&#24037;&#20154;&#12290;&#24037;&#20154;&#30340;&#25216;&#33021;&#21644;&#29305;&#24449;&#20043;&#38388;&#30340;&#20851;&#32852;&#22312;&#20808;&#39564;&#26465;&#20214;&#19979;&#26159;&#26410;&#30693;&#30340;&#65292;&#22240;&#27492;&#20844;&#21496;&#38656;&#35201;&#23398;&#20064;&#12290;&#33258;&#30001;&#25918;&#20219;&#20250;&#23548;&#33268;&#25345;&#20037;&#24615;&#20302;&#20272;&#65306;&#23569;&#25968;&#26063;&#35028;&#24037;&#20154;&#24456;&#23569;&#34987;&#38599;&#20323;&#65292;&#22240;&#27492;&#20302;&#20272;&#24448;&#24448;&#25345;&#32493;&#23384;&#22312;&#12290;&#21363;&#20351;&#20154;&#21475;&#27604;&#20363;&#31245;&#24494;&#19981;&#24179;&#34913;&#65292;&#20063;&#32463;&#24120;&#23548;&#33268;&#25345;&#20037;&#24615;&#20302;&#20272;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#25919;&#31574;&#35299;&#20915;&#26041;&#26696;&#65306;&#19968;&#31181;&#26032;&#39062;&#30340;&#34917;&#36148;&#35268;&#21017;&#65288;&#28151;&#21512;&#26426;&#21046;&#65289;&#21644;&#32599;&#23612;&#27861;&#21017;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#20020;&#26102;&#32943;&#23450;&#34892;&#21160;&#21487;&#20197;&#26377;&#25928;&#32531;&#35299;&#30001;&#20110;&#25968;&#25454;&#19981;&#36275;&#32780;&#23548;&#33268;&#30340;&#27495;&#35270;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
We analyze statistical discrimination in hiring markets using a multi-armed bandit model. Myopic firms face workers arriving with heterogeneous observable characteristics. The association between the worker's skill and characteristics is unknown ex ante; thus, firms need to learn it. Laissez-faire causes perpetual underestimation: minority workers are rarely hired, and therefore, the underestimation tends to persist. Even a marginal imbalance in the population ratio frequently results in perpetual underestimation. We propose two policy solutions: a novel subsidy rule (the hybrid mechanism) and the Rooney Rule. Our results indicate that temporary affirmative actions effectively alleviate discrimination stemming from insufficient data.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20132;&#26367;&#20154;&#21475;&#21644;&#20195;&#29702;&#25511;&#21046;&#31070;&#32463;&#32593;&#32476;&#65288;APAC-Net&#65289;&#26469;&#35299;&#20915;&#39640;&#32500;&#24230;&#38543;&#26426;&#22343;&#22330;&#21338;&#24328;&#65288;MFG&#65289;&#38382;&#39064;&#12290;&#36890;&#36807;&#21033;&#29992;&#21464;&#20998;&#21407;&#22987;-&#23545;&#20598;&#32467;&#26500;&#21644;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#20215;&#20540;&#21644;&#23494;&#24230;&#20989;&#25968;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#39640;&#32500;&#24230;MFG&#38382;&#39064;&#20013;&#30340;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2002.10113</link><description>&lt;p&gt;
&#23558;&#20154;&#21475;&#21644;&#25511;&#21046;&#31070;&#32463;&#32593;&#32476;&#20132;&#26367;&#24212;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#24230;&#38543;&#26426;&#22343;&#22330;&#21338;&#24328;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Alternating the Population and Control Neural Networks to Solve High-Dimensional Stochastic Mean-Field Games. (arXiv:2002.10113v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2002.10113
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20132;&#26367;&#20154;&#21475;&#21644;&#20195;&#29702;&#25511;&#21046;&#31070;&#32463;&#32593;&#32476;&#65288;APAC-Net&#65289;&#26469;&#35299;&#20915;&#39640;&#32500;&#24230;&#38543;&#26426;&#22343;&#22330;&#21338;&#24328;&#65288;MFG&#65289;&#38382;&#39064;&#12290;&#36890;&#36807;&#21033;&#29992;&#21464;&#20998;&#21407;&#22987;-&#23545;&#20598;&#32467;&#26500;&#21644;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#20215;&#20540;&#21644;&#23494;&#24230;&#20989;&#25968;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#39640;&#32500;&#24230;MFG&#38382;&#39064;&#20013;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20132;&#26367;&#20154;&#21475;&#21644;&#20195;&#29702;&#25511;&#21046;&#31070;&#32463;&#32593;&#32476;&#65288;APAC-Net&#65289;&#26469;&#35299;&#20915;&#38543;&#26426;&#22343;&#22330;&#21338;&#24328;&#65288;MFG&#65289;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#38024;&#23545;&#39640;&#32500;&#24230;&#30340;MFG&#23454;&#20363;&#65292;&#36825;&#20123;&#23454;&#20363;&#20351;&#29992;&#29616;&#26377;&#35299;&#20915;&#26041;&#27861;&#26080;&#27861;&#35299;&#20915;&#12290;&#25105;&#20204;&#36890;&#36807;&#20004;&#20010;&#27493;&#39588;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#21033;&#29992;MFG&#25152;&#23637;&#31034;&#30340;&#21464;&#20998;&#21407;&#22987;-&#23545;&#20598;&#32467;&#26500;&#65292;&#24182;&#23558;&#20854;&#24418;&#24335;&#21270;&#20026;&#20984;-&#20985;&#38797;&#28857;&#38382;&#39064;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#20998;&#21035;&#36890;&#36807;&#20004;&#20010;&#31070;&#32463;&#32593;&#32476;&#23545;&#20215;&#20540;&#21644;&#23494;&#24230;&#20989;&#25968;&#36827;&#34892;&#21442;&#25968;&#21270;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#24335;&#65292;&#35299;&#20915;MFG&#21487;&#20197;&#34987;&#35299;&#37322;&#20026;&#35757;&#32451;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#30340;&#29305;&#20363;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#39640;&#36798;100&#32500;MFG&#38382;&#39064;&#19978;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present APAC-Net, an alternating population and agent control neural network for solving stochastic mean field games (MFGs). Our algorithm is geared toward high-dimensional instances of MFGs that are beyond reach with existing solution methods. We achieve this in two steps. First, we take advantage of the underlying variational primal-dual structure that MFGs exhibit and phrase it as a convex-concave saddle point problem. Second, we parameterize the value and density functions by two neural networks, respectively. By phrasing the problem in this manner, solving the MFG can be interpreted as a special case of training a generative adversarial network (GAN). We show the potential of our method on up to 100-dimensional MFG problems.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26377;&#31526;&#21495;&#30340;&#36845;&#20195;&#38543;&#26426;&#26862;&#26519;&#65288;siRF&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#25512;&#26029;Drosophila melanogaster&#20013;&#22686;&#24378;&#23376;&#20803;&#32032;&#21608;&#22260;&#30340;&#36716;&#24405;&#22240;&#23376;&#20043;&#38388;&#30340;&#35843;&#25511;&#30456;&#20114;&#20316;&#29992;&#21644;&#21151;&#33021;&#32467;&#21512;&#31614;&#21517;&#12290;</title><link>http://arxiv.org/abs/1810.07287</link><description>&lt;p&gt;
&#29992;&#26377;&#31526;&#21495;&#30340;&#36845;&#20195;&#38543;&#26426;&#26862;&#26519;&#35782;&#21035;&#22686;&#24378;&#23376;&#30456;&#20851;&#30340;&#36716;&#24405;&#22240;&#23376;&#32467;&#21512;
&lt;/p&gt;
&lt;p&gt;
Signed iterative random forests to identify enhancer-associated transcription factor binding. (arXiv:1810.07287v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1810.07287
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26377;&#31526;&#21495;&#30340;&#36845;&#20195;&#38543;&#26426;&#26862;&#26519;&#65288;siRF&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#25512;&#26029;Drosophila melanogaster&#20013;&#22686;&#24378;&#23376;&#20803;&#32032;&#21608;&#22260;&#30340;&#36716;&#24405;&#22240;&#23376;&#20043;&#38388;&#30340;&#35843;&#25511;&#30456;&#20114;&#20316;&#29992;&#21644;&#21151;&#33021;&#32467;&#21512;&#31614;&#21517;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#20934;&#30340;ChIP-seq&#23792;&#20540;&#35843;&#29992;&#27969;&#31243;&#26088;&#22312;&#21306;&#20998;&#21508;&#20010;&#22522;&#22240;&#32452;&#20803;&#32032;&#30340;&#29983;&#21270;&#21487;&#37325;&#22797;&#20449;&#21495;&#21644;&#32972;&#26223;&#22122;&#22768;&#12290;&#28982;&#32780;&#65292;&#20165;&#20973;&#21487;&#37325;&#22797;&#24615;&#24182;&#19981;&#33021;&#26263;&#31034;&#21151;&#33021;&#35843;&#25511;&#65288;&#20363;&#22914;&#22686;&#24378;&#23376;&#27963;&#21270;&#12289;&#21487;&#36873;&#21098;&#25509;&#65289;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#12289;&#21487;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65306;&#26377;&#31526;&#21495;&#30340;&#36845;&#20195;&#38543;&#26426;&#26862;&#26519;&#65288;siRF&#65289;&#65292;&#25105;&#20204;&#29992;&#23427;&#26469;&#25512;&#26029;Drosophila melanogaster&#20013;&#22686;&#24378;&#23376;&#20803;&#32032;&#21608;&#22260;&#30340;&#36716;&#24405;&#22240;&#23376;&#20043;&#38388;&#30340;&#35843;&#25511;&#30456;&#20114;&#20316;&#29992;&#21644;&#21151;&#33021;&#32467;&#21512;&#31614;&#21517;&#12290;
&lt;/p&gt;
&lt;p&gt;
Standard ChIP-seq peak calling pipelines seek to differentiate biochemically reproducible signals of individual genomic elements from background noise. However, reproducibility alone does not imply functional regulation (e.g., enhancer activation, alternative splicing). Here we present a general-purpose, interpretable machine learning method: signed iterative random forests (siRF), which we use to infer regulatory interactions among transcription factors and functional binding signatures surrounding enhancer elements in Drosophila melanogaster.
&lt;/p&gt;</description></item></channel></rss>