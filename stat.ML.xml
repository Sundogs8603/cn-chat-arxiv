<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#23618;&#22240;&#26524;&#27169;&#22411;&#26469;&#35299;&#20915;&#20851;&#20110;&#20998;&#23618;&#25968;&#25454;&#30340;&#22240;&#26524;&#38382;&#39064;&#65292;&#36890;&#36807;&#28155;&#21152;&#20869;&#37096;&#26495;&#26469;&#25193;&#23637;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#21644;&#22240;&#26524;&#22270;&#27169;&#22411;&#12290;&#21457;&#29616;&#20998;&#23618;&#25968;&#25454;&#21487;&#20197;&#23454;&#29616;&#22240;&#26524;&#35782;&#21035;&#65292;&#21363;&#20351;&#20351;&#29992;&#38750;&#20998;&#23618;&#25968;&#25454;&#26159;&#19981;&#21487;&#33021;&#30340;&#12290;&#24320;&#21457;&#20102;&#29992;&#20110;&#20998;&#23618;&#25968;&#25454;&#30340;&#20272;&#35745;&#25216;&#26415;&#12290;</title><link>http://arxiv.org/abs/2401.05330</link><description>&lt;p&gt;
&#20998;&#23618;&#22240;&#26524;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Hierarchical Causal Models. (arXiv:2401.05330v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05330
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#23618;&#22240;&#26524;&#27169;&#22411;&#26469;&#35299;&#20915;&#20851;&#20110;&#20998;&#23618;&#25968;&#25454;&#30340;&#22240;&#26524;&#38382;&#39064;&#65292;&#36890;&#36807;&#28155;&#21152;&#20869;&#37096;&#26495;&#26469;&#25193;&#23637;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#21644;&#22240;&#26524;&#22270;&#27169;&#22411;&#12290;&#21457;&#29616;&#20998;&#23618;&#25968;&#25454;&#21487;&#20197;&#23454;&#29616;&#22240;&#26524;&#35782;&#21035;&#65292;&#21363;&#20351;&#20351;&#29992;&#38750;&#20998;&#23618;&#25968;&#25454;&#26159;&#19981;&#21487;&#33021;&#30340;&#12290;&#24320;&#21457;&#20102;&#29992;&#20110;&#20998;&#23618;&#25968;&#25454;&#30340;&#20272;&#35745;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31185;&#23398;&#23478;&#20204;&#32463;&#24120;&#24819;&#35201;&#20174;&#20998;&#23618;&#25968;&#25454;&#20013;&#23398;&#20064;&#22240;&#26524;&#20851;&#31995;&#65292;&#36825;&#20123;&#25968;&#25454;&#26159;&#20174;&#23884;&#22871;&#22312;&#21333;&#20301;&#20869;&#37096;&#30340;&#23376;&#21333;&#20803;&#25910;&#38598;&#30340;&#12290;&#27604;&#22914;&#23398;&#26657;&#20013;&#30340;&#23398;&#29983;&#12289;&#30149;&#20154;&#30340;&#32454;&#32990;&#25110;&#24030;&#20013;&#30340;&#22478;&#24066;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#21333;&#20301;&#32423;&#21464;&#37327;&#65288;&#20363;&#22914;&#27599;&#20010;&#23398;&#26657;&#30340;&#39044;&#31639;&#65289;&#21487;&#33021;&#20250;&#24433;&#21709;&#23376;&#21333;&#20301;&#32423;&#21464;&#37327;&#65288;&#20363;&#22914;&#27599;&#20010;&#23398;&#26657;&#27599;&#20010;&#23398;&#29983;&#30340;&#32771;&#35797;&#25104;&#32489;&#65289;&#65292;&#21453;&#20043;&#20134;&#28982;&#12290;&#20026;&#20102;&#35299;&#20915;&#20851;&#20110;&#20998;&#23618;&#25968;&#25454;&#30340;&#22240;&#26524;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20998;&#23618;&#22240;&#26524;&#27169;&#22411;&#65292;&#23427;&#36890;&#36807;&#28155;&#21152;&#20869;&#37096;&#26495;&#26469;&#25193;&#23637;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#21644;&#22240;&#26524;&#22270;&#27169;&#22411;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#29992;&#20110;&#20998;&#23618;&#22240;&#26524;&#27169;&#22411;&#30340;&#36890;&#29992;&#22270;&#24418;&#35782;&#21035;&#25216;&#26415;&#65292;&#35813;&#25216;&#26415;&#25193;&#23637;&#20102;do-&#35745;&#31639;&#12290;&#25105;&#20204;&#21457;&#29616;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#21363;&#20351;&#20351;&#29992;&#38750;&#20998;&#23618;&#25968;&#25454;&#26159;&#19981;&#21487;&#33021;&#30340;&#65292;&#20998;&#23618;&#25968;&#25454;&#20063;&#21487;&#20197;&#23454;&#29616;&#22240;&#26524;&#35782;&#21035;&#65292;&#20063;&#23601;&#26159;&#35828;&#65292;&#22914;&#26524;&#25105;&#20204;&#21482;&#26377;&#23376;&#21333;&#20301;&#32423;&#21464;&#37327;&#30340;&#21333;&#20301;&#32423;&#27719;&#24635;&#65288;&#20363;&#22914;&#23398;&#26657;&#30340;&#24179;&#22343;&#32771;&#35797;&#25104;&#32489;&#65292;&#32780;&#19981;&#26159;&#27599;&#20010;&#23398;&#29983;&#30340;&#25104;&#32489;&#65289;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#29992;&#20110;&#20998;&#23618;&#25968;&#25454;&#30340;&#20272;&#35745;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
Scientists often want to learn about cause and effect from hierarchical data, collected from subunits nested inside units. Consider students in schools, cells in patients, or cities in states. In such settings, unit-level variables (e.g. each school's budget) may affect subunit-level variables (e.g. the test scores of each student in each school) and vice versa. To address causal questions with hierarchical data, we propose hierarchical causal models, which extend structural causal models and causal graphical models by adding inner plates. We develop a general graphical identification technique for hierarchical causal models that extends do-calculus. We find many situations in which hierarchical data can enable causal identification even when it would be impossible with non-hierarchical data, that is, if we had only unit-level summaries of subunit-level variables (e.g. the school's average test score, rather than each student's score). We develop estimation techniques for hierarchical 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22522;&#20110;Hamilton&#31070;&#32463;&#32593;&#32476;&#30340;Monte Carlo&#37319;&#26679;&#30340;&#23376;&#38598;&#27169;&#25311;&#26041;&#27861;&#26469;&#36827;&#34892;&#22797;&#26434;&#31995;&#32479;&#21487;&#38752;&#24615;&#20998;&#26512;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#23558;&#20248;&#36234;&#30340;&#37319;&#26679;&#21644;&#39640;&#25928;&#30340;&#26799;&#24230;&#35780;&#20272;&#30456;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#39640;&#25509;&#21463;&#29575;&#21644;&#20302;&#35745;&#31639;&#25104;&#26412;&#12290;&#22312;&#19981;&#21516;&#30340;&#21487;&#38752;&#24615;&#38382;&#39064;&#19978;&#23637;&#31034;&#20102;&#20854;&#26174;&#33879;&#30340;&#20934;&#30830;&#24615;&#65292;&#24182;&#19982;&#20256;&#32479;&#30340;Hamilton Monte Carlo&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#27492;&#26041;&#27861;&#22312;&#26799;&#24230;&#35780;&#20272;&#26041;&#38754;&#23384;&#22312;&#19968;&#23450;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2401.05244</link><description>&lt;p&gt;
&#20351;&#29992;Hamilton&#31070;&#32463;&#32593;&#32476;&#30340;&#23376;&#38598;&#27169;&#25311;&#36827;&#34892;&#22797;&#26434;&#31995;&#32479;&#21487;&#38752;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Reliability Analysis of Complex Systems using Subset Simulations with Hamiltonian Neural Networks. (arXiv:2401.05244v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05244
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22522;&#20110;Hamilton&#31070;&#32463;&#32593;&#32476;&#30340;Monte Carlo&#37319;&#26679;&#30340;&#23376;&#38598;&#27169;&#25311;&#26041;&#27861;&#26469;&#36827;&#34892;&#22797;&#26434;&#31995;&#32479;&#21487;&#38752;&#24615;&#20998;&#26512;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#23558;&#20248;&#36234;&#30340;&#37319;&#26679;&#21644;&#39640;&#25928;&#30340;&#26799;&#24230;&#35780;&#20272;&#30456;&#32467;&#21512;&#65292;&#23454;&#29616;&#20102;&#39640;&#25509;&#21463;&#29575;&#21644;&#20302;&#35745;&#31639;&#25104;&#26412;&#12290;&#22312;&#19981;&#21516;&#30340;&#21487;&#38752;&#24615;&#38382;&#39064;&#19978;&#23637;&#31034;&#20102;&#20854;&#26174;&#33879;&#30340;&#20934;&#30830;&#24615;&#65292;&#24182;&#19982;&#20256;&#32479;&#30340;Hamilton Monte Carlo&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#27492;&#26041;&#27861;&#22312;&#26799;&#24230;&#35780;&#20272;&#26041;&#38754;&#23384;&#22312;&#19968;&#23450;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20351;&#29992;&#22522;&#20110;Hamilton&#31070;&#32463;&#32593;&#32476;&#30340;Monte Carlo&#37319;&#26679;&#30340;&#23376;&#38598;&#27169;&#25311;&#26041;&#27861;&#65292;&#29992;&#20110;&#21487;&#38752;&#24615;&#20998;&#26512;&#12290;&#25152;&#25552;&#20986;&#30340;&#31574;&#30053;&#23558;Hamilton Monte Carlo&#26041;&#27861;&#30340;&#20248;&#36234;&#37319;&#26679;&#19982;&#20351;&#29992;Hamilton&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#35745;&#31639;&#39640;&#25928;&#26799;&#24230;&#35780;&#20272;&#30456;&#32467;&#21512;&#12290;&#36825;&#31181;&#32452;&#21512;&#29305;&#21035;&#26377;&#20248;&#21183;&#65292;&#22240;&#20026;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#20445;&#25345;&#20102;Hamiltonian&#30340;&#29305;&#24615;&#65292;&#32780;Hamiltonian&#23450;&#20041;&#20102;Hamilton Monte Carlo&#37319;&#26679;&#22120;&#30340;&#25509;&#21463;&#20934;&#21017;&#12290;&#22240;&#27492;&#65292;&#36825;&#31181;&#31574;&#30053;&#22312;&#20302;&#35745;&#31639;&#25104;&#26412;&#19979;&#21487;&#20197;&#23454;&#29616;&#39640;&#25509;&#21463;&#29575;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#29992;&#23376;&#38598;&#27169;&#25311;&#26469;&#20272;&#35745;&#23567;&#27010;&#29575;&#22833;&#25928;&#12290;&#28982;&#32780;&#65292;&#22312;&#20302;&#27010;&#29575;&#26679;&#26412;&#21306;&#22495;&#20013;&#65292;&#26799;&#24230;&#35780;&#20272;&#23588;&#20854;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#31574;&#30053;&#30340;&#26174;&#33879;&#20934;&#30830;&#24615;&#65292;&#24182;&#23558;&#20854;&#25928;&#29575;&#19982;&#20256;&#32479;&#30340;Hamilton Monte Carlo&#26041;&#27861;&#36827;&#34892;&#27604;&#36739;&#12290;&#25105;&#20204;&#27880;&#24847;&#21040;&#65292;&#36825;&#31181;&#26041;&#27861;&#22312;&#26799;&#24230;&#35780;&#20272;&#26041;&#38754;&#23384;&#22312;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a new Subset Simulation approach using Hamiltonian neural network-based Monte Carlo sampling for reliability analysis. The proposed strategy combines the superior sampling of the Hamiltonian Monte Carlo method with computationally efficient gradient evaluations using Hamiltonian neural networks. This combination is especially advantageous because the neural network architecture conserves the Hamiltonian, which defines the acceptance criteria of the Hamiltonian Monte Carlo sampler. Hence, this strategy achieves high acceptance rates at low computational cost. Our approach estimates small failure probabilities using Subset Simulations. However, in low-probability sample regions, the gradient evaluation is particularly challenging. The remarkable accuracy of the proposed strategy is demonstrated on different reliability problems, and its efficiency is compared to the traditional Hamiltonian Monte Carlo method. We note that this approach can reach its limitations for gradient es
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#22312;&#36830;&#32493;&#29366;&#24577;-&#21160;&#20316;&#31354;&#38388;&#20013;&#20998;&#26512;&#24378;&#21270;&#23398;&#20064;&#30340;&#26032;&#26694;&#26550;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#31163;&#32447;&#21644;&#22312;&#32447;&#35774;&#32622;&#20013;&#20855;&#26377;&#24555;&#36895;&#25910;&#25947;&#36895;&#24230;&#12290;&#20998;&#26512;&#21457;&#29616;&#20102;&#20004;&#20010;&#31283;&#23450;&#24615;&#23646;&#24615;&#65292;&#19982;&#20540;&#20989;&#25968;&#21644;/&#25110;&#31574;&#30053;&#21464;&#21270;&#22914;&#20309;&#24433;&#21709;&#36125;&#23572;&#26364;&#31639;&#23376;&#21644;&#21344;&#25454;&#24230;&#27979;&#24230;&#30456;&#20851;&#12290;&#36825;&#20123;&#23646;&#24615;&#22312;&#35768;&#22810;&#36830;&#32493;&#29366;&#24577;-&#21160;&#20316;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#25104;&#31435;&#65292;&#24182;&#19988;&#22312;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#26041;&#27861;&#19979;&#33258;&#28982;&#20135;&#29983;&#12290;&#20998;&#26512;&#36824;&#25581;&#31034;&#20102;&#31163;&#32447;&#21644;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#24754;&#35266;&#20027;&#20041;&#21644;&#20048;&#35266;&#20027;&#20041;&#30340;&#35282;&#33394;&#65292;&#20197;&#21450;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#21644;&#36801;&#31227;&#23398;&#20064;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;</title><link>http://arxiv.org/abs/2401.05233</link><description>&lt;p&gt;
&#39535;&#26381;&#8220;&#25968;&#25454;&#39269;&#28212;&#8221;&#30340;&#24378;&#21270;&#23398;&#20064;&#65311;&#22312;&#36830;&#32493;&#29366;&#24577;-&#21160;&#20316;&#31354;&#38388;&#20013;&#30340;&#31283;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
Taming "data-hungry" reinforcement learning? Stability in continuous state-action spaces. (arXiv:2401.05233v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05233
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#22312;&#36830;&#32493;&#29366;&#24577;-&#21160;&#20316;&#31354;&#38388;&#20013;&#20998;&#26512;&#24378;&#21270;&#23398;&#20064;&#30340;&#26032;&#26694;&#26550;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#31163;&#32447;&#21644;&#22312;&#32447;&#35774;&#32622;&#20013;&#20855;&#26377;&#24555;&#36895;&#25910;&#25947;&#36895;&#24230;&#12290;&#20998;&#26512;&#21457;&#29616;&#20102;&#20004;&#20010;&#31283;&#23450;&#24615;&#23646;&#24615;&#65292;&#19982;&#20540;&#20989;&#25968;&#21644;/&#25110;&#31574;&#30053;&#21464;&#21270;&#22914;&#20309;&#24433;&#21709;&#36125;&#23572;&#26364;&#31639;&#23376;&#21644;&#21344;&#25454;&#24230;&#27979;&#24230;&#30456;&#20851;&#12290;&#36825;&#20123;&#23646;&#24615;&#22312;&#35768;&#22810;&#36830;&#32493;&#29366;&#24577;-&#21160;&#20316;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#25104;&#31435;&#65292;&#24182;&#19988;&#22312;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#26041;&#27861;&#19979;&#33258;&#28982;&#20135;&#29983;&#12290;&#20998;&#26512;&#36824;&#25581;&#31034;&#20102;&#31163;&#32447;&#21644;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#24754;&#35266;&#20027;&#20041;&#21644;&#20048;&#35266;&#20027;&#20041;&#30340;&#35282;&#33394;&#65292;&#20197;&#21450;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#21644;&#36801;&#31227;&#23398;&#20064;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#22312;&#36830;&#32493;&#29366;&#24577;-&#21160;&#20316;&#31354;&#38388;&#20013;&#20998;&#26512;&#24378;&#21270;&#23398;&#20064;&#30340;&#26032;&#26694;&#26550;&#65292;&#24182;&#23558;&#20854;&#29992;&#20110;&#35777;&#26126;&#31163;&#32447;&#21644;&#22312;&#32447;&#35774;&#32622;&#20013;&#30340;&#24555;&#36895;&#25910;&#25947;&#36895;&#24230;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#31361;&#20986;&#20102;&#20004;&#20010;&#20851;&#38190;&#30340;&#31283;&#23450;&#24615;&#23646;&#24615;&#65292;&#28041;&#21450;&#20540;&#20989;&#25968;&#21644;/&#25110;&#31574;&#30053;&#21464;&#21270;&#22914;&#20309;&#24433;&#21709;&#36125;&#23572;&#26364;&#31639;&#23376;&#21644;&#21344;&#25454;&#24230;&#27979;&#24230;&#12290;&#25105;&#20204;&#35748;&#20026;&#36825;&#20123;&#23646;&#24615;&#22312;&#35768;&#22810;&#36830;&#32493;&#29366;&#24577;-&#21160;&#20316;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#25104;&#31435;&#65292;&#24182;&#28436;&#31034;&#20102;&#22312;&#20351;&#29992;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#26041;&#27861;&#26102;&#22914;&#20309;&#33258;&#28982;&#22320;&#20135;&#29983;&#36825;&#20123;&#23646;&#24615;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#25552;&#20379;&#20102;&#20851;&#20110;&#31163;&#32447;&#21644;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#24754;&#35266;&#20027;&#20041;&#21644;&#20048;&#35266;&#20027;&#20041;&#30340;&#26032;&#35270;&#35282;&#65292;&#24182;&#24378;&#35843;&#20102;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#21644;&#36801;&#31227;&#23398;&#20064;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a novel framework for analyzing reinforcement learning (RL) in continuous state-action spaces, and use it to prove fast rates of convergence in both off-line and on-line settings. Our analysis highlights two key stability properties, relating to how changes in value functions and/or policies affect the Bellman operator and occupation measures. We argue that these properties are satisfied in many continuous state-action Markov decision processes, and demonstrate how they arise naturally when using linear function approximation methods. Our analysis offers fresh perspectives on the roles of pessimism and optimism in off-line and on-line RL, and highlights the connection between off-line RL and transfer learning.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#19978;&#19979;&#25991;&#20851;&#32852;&#36172;&#21338;&#38382;&#39064;&#20013;&#20351;&#29992;&#20989;&#25968;&#36924;&#36817;&#36827;&#34892;&#23454;&#39564;&#35268;&#21010;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#19982;&#20989;&#25968;&#36924;&#36817;&#20860;&#23481;&#30340;&#23454;&#39564;&#35268;&#21010;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2401.05193</link><description>&lt;p&gt;
&#20351;&#29992;&#20989;&#25968;&#36924;&#36817;&#36827;&#34892;&#23454;&#39564;&#35268;&#21010;
&lt;/p&gt;
&lt;p&gt;
Experiment Planning with Function Approximation. (arXiv:2401.05193v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05193
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#19978;&#19979;&#25991;&#20851;&#32852;&#36172;&#21338;&#38382;&#39064;&#20013;&#20351;&#29992;&#20989;&#25968;&#36924;&#36817;&#36827;&#34892;&#23454;&#39564;&#35268;&#21010;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#19982;&#20989;&#25968;&#36924;&#36817;&#20860;&#23481;&#30340;&#23454;&#39564;&#35268;&#21010;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#19978;&#19979;&#25991;&#20851;&#32852;&#36172;&#21338;&#38382;&#39064;&#20013;&#20351;&#29992;&#20989;&#25968;&#36924;&#36817;&#36827;&#34892;&#23454;&#39564;&#35268;&#21010;&#30340;&#38382;&#39064;&#12290;&#22312;&#23384;&#22312;&#37096;&#32626;&#33258;&#36866;&#24212;&#31639;&#27861;&#30340;&#26174;&#33879;&#24320;&#38144;&#30340;&#24773;&#20917;&#19979;&#65292;&#20363;&#22914;&#24403;&#25191;&#34892;&#25968;&#25454;&#25910;&#38598;&#31574;&#30053;&#38656;&#35201;&#20998;&#24067;&#24335;&#25110;&#38656;&#35201;&#20154;&#24037;&#21442;&#19982;&#26102;&#65292;&#25552;&#21069;&#29983;&#25104;&#19968;&#32452;&#25968;&#25454;&#25910;&#38598;&#31574;&#30053;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#22823;&#22411;&#19978;&#19979;&#25991;&#25968;&#25454;&#38598;&#21487;&#29992;&#20294;&#22870;&#21169;&#25968;&#25454;&#19981;&#21487;&#29992;&#30340;&#24773;&#26223;&#65292;&#23398;&#20064;&#32773;&#21487;&#20197;&#21033;&#29992;&#35813;&#25968;&#25454;&#38598;&#35774;&#35745;&#19968;&#20010;&#26377;&#25928;&#30340;&#25968;&#25454;&#25910;&#38598;&#31574;&#30053;&#12290;&#34429;&#28982;&#24403;&#22870;&#21169;&#26159;&#32447;&#24615;&#30340;&#26102;&#20505;&#65292;&#36825;&#20010;&#38382;&#39064;&#24050;&#32463;&#34987;&#24191;&#27867;&#30740;&#31350;&#65292;&#20294;&#23545;&#20110;&#26356;&#22797;&#26434;&#30340;&#22870;&#21169;&#27169;&#22411;&#65292;&#20173;&#28982;&#32570;&#20047;&#32467;&#26524;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#19982;&#20989;&#25968;&#36924;&#36817;&#20860;&#23481;&#30340;&#23454;&#39564;&#35268;&#21010;&#31574;&#30053;&#12290;&#31532;&#19968;&#31181;&#26159;&#36867;&#36991;&#32773;&#35268;&#21010;&#21644;&#37319;&#26679;&#36807;&#31243;&#65292;&#21487;&#20197;&#26681;&#25454;&#36867;&#36991;&#32773;&#32500;&#24230;&#30340;&#22870;&#21169;&#20989;&#25968;&#31867;&#33719;&#24471;&#26368;&#20248;&#24615;&#20445;&#35777;&#12290;&#23545;&#20110;&#31532;&#20108;&#31181;&#31574;&#30053;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;...
&lt;/p&gt;
&lt;p&gt;
We study the problem of experiment planning with function approximation in contextual bandit problems. In settings where there is a significant overhead to deploying adaptive algorithms -- for example, when the execution of the data collection policies is required to be distributed, or a human in the loop is needed to implement these policies -- producing in advance a set of policies for data collection is paramount. We study the setting where a large dataset of contexts but not rewards is available and may be used by the learner to design an effective data collection strategy. Although when rewards are linear this problem has been well studied, results are still missing for more complex reward models. In this work we propose two experiment planning strategies compatible with function approximation. The first is an eluder planning and sampling procedure that can recover optimality guarantees depending on the eluder dimension of the reward function class. For the second, we show that a 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#20284;&#28982;&#36335;&#24452;&#21407;&#29702;&#21644;&#26032;&#30340;&#29702;&#35770;&#24037;&#20855;&#65292;&#26412;&#30740;&#31350;&#38024;&#23545;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAEs&#65289;&#30340;&#26465;&#20214;&#20284;&#28982;&#24615;&#25552;&#20379;&#20102;&#38750;&#28176;&#36817;&#21487;&#35777;&#26126;&#30340;&#36229;&#20986;&#20998;&#24067;&#65288;OOD&#65289;&#26816;&#27979;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2401.04933</link><description>&lt;p&gt;
&#37325;&#26032;&#24605;&#32771;&#27979;&#35797;&#26102;&#20284;&#28982;&#24615;&#65306;&#20284;&#28982;&#36335;&#24452;&#21407;&#29702;&#21450;&#20854;&#22312;OOD&#26816;&#27979;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Rethinking Test-time Likelihood: The Likelihood Path Principle and Its Application to OOD Detection. (arXiv:2401.04933v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04933
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#20284;&#28982;&#36335;&#24452;&#21407;&#29702;&#21644;&#26032;&#30340;&#29702;&#35770;&#24037;&#20855;&#65292;&#26412;&#30740;&#31350;&#38024;&#23545;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAEs&#65289;&#30340;&#26465;&#20214;&#20284;&#28982;&#24615;&#25552;&#20379;&#20102;&#38750;&#28176;&#36817;&#21487;&#35777;&#26126;&#30340;&#36229;&#20986;&#20998;&#24067;&#65288;OOD&#65289;&#26816;&#27979;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34429;&#28982;&#20284;&#28982;&#24615;&#22312;&#29702;&#35770;&#19978;&#24456;&#26377;&#21560;&#24341;&#21147;&#65292;&#20294;&#26159;&#36890;&#36807;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65288;DGM&#65289;&#20272;&#35745;&#30340;&#20284;&#28982;&#24615;&#22312;&#23454;&#36341;&#20013;&#32463;&#24120;&#20986;&#29616;&#38382;&#39064;&#65292;&#23545;&#20110;&#36229;&#20986;&#20998;&#24067;&#65288;OOD&#65289;&#26816;&#27979;&#34920;&#29616;&#19981;&#20339;&#12290;&#26368;&#36817;&#30340;&#19968;&#20123;&#24037;&#20316;&#24320;&#22987;&#32771;&#34385;&#26367;&#20195;&#24615;&#35780;&#20998;&#65292;&#24182;&#21462;&#24471;&#20102;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#24182;&#27809;&#26377;&#25552;&#20379;&#21487;&#35777;&#26126;&#30340;&#20445;&#35777;&#65292;&#20063;&#19981;&#28165;&#26970;&#23427;&#20204;&#30340;&#36873;&#25321;&#26159;&#21542;&#25552;&#21462;&#20102;&#36275;&#22815;&#30340;&#20449;&#24687;&#12290;&#25105;&#20204;&#23581;&#35797;&#25913;&#21464;&#36825;&#31181;&#24773;&#20917;&#65292;&#36890;&#36807;&#23545;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAEs&#65289;&#36827;&#34892;&#26696;&#20363;&#30740;&#31350;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20284;&#28982;&#36335;&#24452;&#65288;LPath&#65289;&#21407;&#29702;&#65292;&#25512;&#24191;&#20102;&#20284;&#28982;&#24615;&#21407;&#29702;&#12290;&#36825;&#23558;&#25628;&#32034;&#26377;&#29992;&#30340;&#25688;&#35201;&#32479;&#35745;&#37327;&#32553;&#23567;&#21040;VAEs&#26465;&#20214;&#20284;&#28982;&#24615;&#30340;&#26368;&#23567;&#20805;&#20998;&#32479;&#35745;&#37327;&#12290;&#20854;&#27425;&#65292;&#24341;&#20837;&#20102;&#26032;&#30340;&#29702;&#35770;&#24037;&#20855;&#65292;&#22914;&#20960;&#20046;&#26377;&#25928;&#25903;&#25345;&#12289;&#22522;&#26412;&#36317;&#31163;&#21644;&#20849;-Lipschitz&#24615;&#65292;&#25105;&#20204;&#20026;&#26576;&#20123;&#26368;&#23567;&#20805;&#20998;&#32479;&#35745;&#37327;&#30340;&#25688;&#35201;&#25552;&#20379;&#20102;&#38750;&#28176;&#36817;&#21487;&#35777;&#26126;&#30340;OOD&#26816;&#27979;&#20445;&#35777;&#12290;&#30456;&#24212;&#30340;LPath&#31639;&#27861;&#35777;&#26126;&#20102;&#36825;&#19968;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
While likelihood is attractive in theory, its estimates by deep generative models (DGMs) are often broken in practice, and perform poorly for out of distribution (OOD) Detection. Various recent works started to consider alternative scores and achieved better performances. However, such recipes do not come with provable guarantees, nor is it clear that their choices extract sufficient information.  We attempt to change this by conducting a case study on variational autoencoders (VAEs). First, we introduce the likelihood path (LPath) principle, generalizing the likelihood principle. This narrows the search for informative summary statistics down to the minimal sufficient statistics of VAEs' conditional likelihoods. Second, introducing new theoretic tools such as nearly essential support, essential distance and co-Lipschitzness, we obtain non-asymptotic provable OOD detection guarantees for certain distillation of the minimal sufficient statistics. The corresponding LPath algorithm demons
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#21483;&#20570;&#20809;&#35889;&#21464;&#25442;&#22120;&#65288;SPT&#65289;&#30340;&#26694;&#26550;&#26469;&#39044;&#27979;&#32418;&#24040;&#26143;&#30340;&#24180;&#40836;&#21644;&#36136;&#37327;&#65292;&#20854;&#20013;&#20851;&#38190;&#30340;&#32452;&#25104;&#37096;&#20998;&#26159;&#20026;&#20809;&#35889;&#35774;&#35745;&#30340;&#22810;&#22836;&#21704;&#36798;&#29595;&#33258;&#27880;&#24847;&#26426;&#21046;&#65292;&#21516;&#26102;&#36824;&#20351;&#29992;&#20102;&#39532;&#27663;&#36317;&#31163;&#21644;&#33945;&#29305;&#21345;&#27931;Dropout&#26469;&#35299;&#20915;&#38382;&#39064;&#24182;&#20998;&#26512;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.04900</link><description>&lt;p&gt;
SPT: &#20809;&#35889;&#21464;&#25442;&#22120;&#29992;&#20110;&#32418;&#24040;&#26143;&#24180;&#40836;&#21644;&#36136;&#37327;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
SPT: Spectral Transformer for Red Giant Stars Age and Mass Estimation. (arXiv:2401.04900v1 [astro-ph.SR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04900
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#21483;&#20570;&#20809;&#35889;&#21464;&#25442;&#22120;&#65288;SPT&#65289;&#30340;&#26694;&#26550;&#26469;&#39044;&#27979;&#32418;&#24040;&#26143;&#30340;&#24180;&#40836;&#21644;&#36136;&#37327;&#65292;&#20854;&#20013;&#20851;&#38190;&#30340;&#32452;&#25104;&#37096;&#20998;&#26159;&#20026;&#20809;&#35889;&#35774;&#35745;&#30340;&#22810;&#22836;&#21704;&#36798;&#29595;&#33258;&#27880;&#24847;&#26426;&#21046;&#65292;&#21516;&#26102;&#36824;&#20351;&#29992;&#20102;&#39532;&#27663;&#36317;&#31163;&#21644;&#33945;&#29305;&#21345;&#27931;Dropout&#26469;&#35299;&#20915;&#38382;&#39064;&#24182;&#20998;&#26512;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32418;&#24040;&#26143;&#30340;&#24180;&#40836;&#21644;&#36136;&#37327;&#23545;&#20110;&#29702;&#35299;&#38134;&#27827;&#31995;&#30340;&#32467;&#26500;&#21644;&#28436;&#21270;&#33267;&#20851;&#37325;&#35201;&#12290;&#20256;&#32479;&#30340;&#31561;&#26102;&#32447;&#26041;&#27861;&#22312;&#20272;&#31639;&#20013;&#23384;&#22312;&#38480;&#21046;&#65292;&#22240;&#20026;&#22312;&#36203;&#32599;&#22270;&#20013;&#31561;&#26102;&#32447;&#37325;&#21472;&#65292;&#32780;&#22825;&#20307;&#22768;&#23398;&#34429;&#28982;&#26356;&#31934;&#30830;&#65292;&#20294;&#38656;&#35201;&#39640;&#31934;&#24230;&#12289;&#38271;&#26399;&#35266;&#27979;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26694;&#26550;&#8212;&#8212;&#20809;&#35889;&#21464;&#25442;&#22120;&#65288;Spectral Transformer&#65292;SPT&#65289;&#65292;&#36890;&#36807;&#32418;&#24040;&#26143;&#30340;&#20809;&#35889;&#39044;&#27979;&#20854;&#19982;&#22825;&#20307;&#22768;&#23398;&#19968;&#33268;&#30340;&#24180;&#40836;&#21644;&#36136;&#37327;&#12290;SPT&#30340;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#26159;&#20026;&#20809;&#35889;&#29305;&#21035;&#35774;&#35745;&#30340;&#22810;&#22836;&#21704;&#36798;&#29595;&#33258;&#27880;&#24847;&#26426;&#21046;&#65292;&#21487;&#20197;&#25429;&#25417;&#19981;&#21516;&#27874;&#38271;&#19978;&#30340;&#22797;&#26434;&#20851;&#31995;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#22522;&#20110;&#39532;&#27663;&#36317;&#31163;&#30340;&#25439;&#22833;&#20989;&#25968;&#26469;&#35299;&#20915;&#23610;&#24230;&#19981;&#24179;&#34913;&#21644;&#20132;&#20114;&#27169;&#24335;&#25439;&#22833;&#65292;&#24182;&#32467;&#21512;&#20102;&#33945;&#29305;&#21345;&#27931;Dropout&#26469;&#23450;&#37327;&#20998;&#26512;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#22312;&#26469;&#33258;LAMOST&#30340;3,880&#20010;&#32418;&#24040;&#26143;&#20809;&#35889;&#19978;&#36827;&#34892;&#35757;&#32451;&#21644;&#27979;&#35797;&#65292;SPT&#21462;&#24471;&#20102;&#20196;&#20154;&#30633;&#30446;&#30340;&#24180;&#40836;
&lt;/p&gt;
&lt;p&gt;
The age and mass of red giants are essential for understanding the structure and evolution of the Milky Way. Traditional isochrone methods for these estimations are inherently limited due to overlapping isochrones in the Hertzsprung-Russell diagram, while asteroseismology, though more precise, requires high-precision, long-term observations. In response to these challenges, we developed a novel framework, Spectral Transformer (SPT), to predict the age and mass of red giants aligned with asteroseismology from their spectra. A key component of SPT, the Multi-head Hadamard Self-Attention mechanism, designed specifically for spectra, can capture complex relationships across different wavelength. Further, we introduced a Mahalanobis distance-based loss function to address scale imbalance and interaction mode loss, and incorporated Monte Carlo dropout for quantitative analysis of prediction uncertainty.Trained and tested on 3,880 red giant spectra from LAMOST, the SPT achieved remarkable age
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#31216;&#20026;&#26426;&#21046;&#31232;&#30095;&#24615;&#27491;&#21017;&#21270;&#30340;&#35299;&#32544;&#21407;&#21017;&#65292;&#36890;&#36807;&#21516;&#26102;&#23398;&#20064;&#28508;&#22312;&#22240;&#32032;&#21644;&#35299;&#37322;&#23427;&#20204;&#30340;&#31232;&#30095;&#22240;&#26524;&#22270;&#27169;&#22411;&#26469;&#23454;&#29616;&#35299;&#32544;&#12290;&#36825;&#39033;&#24037;&#20316;&#36890;&#36807;&#38750;&#21442;&#25968;&#21270;&#21487;&#36776;&#35782;&#24615;&#29702;&#35770;&#35777;&#26126;&#20102;&#36825;&#19968;&#21407;&#21017;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#22270;&#24418;&#20934;&#21017;&#26469;&#20445;&#35777;&#23436;&#20840;&#35299;&#32544;&#12290;</title><link>http://arxiv.org/abs/2401.04890</link><description>&lt;p&gt;
&#36890;&#36807;&#26426;&#21046;&#31232;&#30095;&#24615;&#36827;&#34892;&#38750;&#21442;&#25968;&#21270;&#37096;&#20998;&#35299;&#32544;: &#31232;&#30095;&#21160;&#20316;, &#24178;&#39044;&#21644;&#31232;&#30095;&#26102;&#38388;&#20381;&#36182;&#24615;
&lt;/p&gt;
&lt;p&gt;
Nonparametric Partial Disentanglement via Mechanism Sparsity: Sparse Actions, Interventions and Sparse Temporal Dependencies. (arXiv:2401.04890v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04890
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#31216;&#20026;&#26426;&#21046;&#31232;&#30095;&#24615;&#27491;&#21017;&#21270;&#30340;&#35299;&#32544;&#21407;&#21017;&#65292;&#36890;&#36807;&#21516;&#26102;&#23398;&#20064;&#28508;&#22312;&#22240;&#32032;&#21644;&#35299;&#37322;&#23427;&#20204;&#30340;&#31232;&#30095;&#22240;&#26524;&#22270;&#27169;&#22411;&#26469;&#23454;&#29616;&#35299;&#32544;&#12290;&#36825;&#39033;&#24037;&#20316;&#36890;&#36807;&#38750;&#21442;&#25968;&#21270;&#21487;&#36776;&#35782;&#24615;&#29702;&#35770;&#35777;&#26126;&#20102;&#36825;&#19968;&#21407;&#21017;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#22270;&#24418;&#20934;&#21017;&#26469;&#20445;&#35777;&#23436;&#20840;&#35299;&#32544;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#24341;&#20837;&#19968;&#31181;&#26032;&#30340;&#35299;&#32544;&#21407;&#21017;&#65292;&#21363;&#26426;&#21046;&#31232;&#30095;&#35268;&#21017;&#65292;&#35813;&#35268;&#21017;&#36866;&#29992;&#20110;&#24863;&#20852;&#36259;&#30340;&#28508;&#22312;&#22240;&#32032;&#22312;&#35266;&#23519;&#36741;&#21161;&#21464;&#37327;&#21644;/&#25110;&#36807;&#21435;&#28508;&#22312;&#22240;&#32032;&#19978;&#31232;&#30095;&#20381;&#36182;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#21516;&#26102;&#23398;&#20064;&#28508;&#22312;&#22240;&#32032;&#21644;&#35299;&#37322;&#23427;&#20204;&#30340;&#31232;&#30095;&#22240;&#26524;&#22270;&#27169;&#22411;&#26469;&#24341;&#23548;&#35299;&#32544;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#38750;&#21442;&#25968;&#21270;&#21487;&#36776;&#35782;&#24615;&#29702;&#35770;&#26469;&#24418;&#24335;&#21270;&#36825;&#19968;&#21407;&#21017;&#65292;&#24182;&#35777;&#26126;&#36890;&#36807;&#23558;&#23398;&#20064;&#21040;&#30340;&#22240;&#26524;&#22270;&#31232;&#30095;&#21270;&#65292;&#21487;&#20197;&#24674;&#22797;&#28508;&#22312;&#22240;&#32032;&#12290;&#26356;&#30830;&#20999;&#22320;&#35828;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#31181;&#26032;&#30340;&#31561;&#20215;&#20851;&#31995;"&#19968;&#33268;&#24615;"&#26469;&#25551;&#36848;&#33021;&#22815;&#20445;&#25345;&#19968;&#20123;&#28508;&#22312;&#22240;&#32032;&#32416;&#32544;&#30340;&#37096;&#20998;&#35299;&#32544;&#36807;&#31243;&#12290;&#20026;&#20102;&#25551;&#36848;&#32416;&#32544;&#30340;&#32467;&#26500;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#32416;&#32544;&#22270;&#21644;&#22270;&#20445;&#25345;&#20989;&#25968;&#30340;&#27010;&#24565;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#20010;&#22270;&#24418;&#20934;&#21017;&#65292;&#29992;&#20110;&#20445;&#35777;&#23436;&#20840;&#35299;&#32544;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work introduces a novel principle for disentanglement we call mechanism sparsity regularization, which applies when the latent factors of interest depend sparsely on observed auxiliary variables and/or past latent factors. We propose a representation learning method that induces disentanglement by simultaneously learning the latent factors and the sparse causal graphical model that explains them. We develop a nonparametric identifiability theory that formalizes this principle and shows that the latent factors can be recovered by regularizing the learned causal graph to be sparse. More precisely, we show identifiablity up to a novel equivalence relation we call "consistency", which allows some latent factors to remain entangled (hence the term partial disentanglement). To describe the structure of this entanglement, we introduce the notions of entanglement graphs and graph preserving functions. We further provide a graphical criterion which guarantees complete disentanglement, that
&lt;/p&gt;</description></item><item><title>&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#29305;&#24449;&#32593;&#32476;&#26041;&#27861;&#21450;&#24212;&#29992;&#26159;&#23558;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#29305;&#24449;&#36830;&#25509;&#25104;&#22270;&#24418;&#32467;&#26500;&#65292;&#24182;&#36890;&#36807;&#20989;&#25968;&#25805;&#20316;&#29983;&#25104;&#26032;&#30340;&#29305;&#24449;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#22270;&#20687;&#22788;&#29702;&#21644;&#35745;&#31639;&#29983;&#29289;&#23398;&#20013;&#20855;&#26377;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2401.04874</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#29305;&#24449;&#32593;&#32476;&#26041;&#27861;&#21450;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Feature Network Methods in Machine Learning and Applications. (arXiv:2401.04874v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04874
&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#29305;&#24449;&#32593;&#32476;&#26041;&#27861;&#21450;&#24212;&#29992;&#26159;&#23558;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#29305;&#24449;&#36830;&#25509;&#25104;&#22270;&#24418;&#32467;&#26500;&#65292;&#24182;&#36890;&#36807;&#20989;&#25968;&#25805;&#20316;&#29983;&#25104;&#26032;&#30340;&#29305;&#24449;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#22270;&#20687;&#22788;&#29702;&#21644;&#35745;&#31639;&#29983;&#29289;&#23398;&#20013;&#20855;&#26377;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#29305;&#24449;&#32593;&#32476;&#26159;&#19968;&#20010;&#23558;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#29305;&#24449;&#22522;&#20110;&#30456;&#20284;&#24615;&#36830;&#25509;&#36215;&#26469;&#30340;&#22270;&#24418;&#34920;&#31034;&#12290;&#36825;&#31181;&#32593;&#32476;&#34920;&#31034;&#20801;&#35768;&#25105;&#20204;&#23558;&#29305;&#24449;&#21521;&#37327;&#35270;&#20026;&#32593;&#32476;&#19978;&#30340;&#20989;&#25968;&#12290;&#36890;&#36807;&#21033;&#29992;&#20613;&#37324;&#21494;&#20998;&#26512;&#21644;&#20989;&#25968;&#20998;&#26512;&#20013;&#30340;&#20989;&#25968;&#25805;&#20316;&#65292;&#25105;&#20204;&#21487;&#20197;&#36731;&#26494;&#22320;&#29983;&#25104;&#26032;&#30340;&#29305;&#24449;&#65292;&#21033;&#29992;&#29305;&#24449;&#21521;&#37327;&#19978;&#25152;&#26045;&#21152;&#30340;&#22270;&#24418;&#32467;&#26500;&#12290;&#36825;&#26679;&#30340;&#32593;&#32476;&#32467;&#26500;&#22312;&#22270;&#20687;&#22788;&#29702;&#21644;&#35745;&#31639;&#29983;&#29289;&#23398;&#20013;&#24050;&#32463;&#34987;&#38544;&#24335;&#30740;&#31350;&#36807;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#23558;&#29305;&#24449;&#32593;&#32476;&#25551;&#36848;&#20026;&#34987;&#26045;&#21152;&#22312;&#29305;&#24449;&#21521;&#37327;&#19978;&#30340;&#22270;&#24418;&#32467;&#26500;&#65292;&#24182;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#25552;&#20379;&#24212;&#29992;&#12290;&#20854;&#20013;&#19968;&#20010;&#24212;&#29992;&#28041;&#21450;&#22522;&#20110;&#22270;&#24418;&#30340;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#25512;&#24191;&#65292;&#28041;&#21450;&#20855;&#26377;&#19981;&#21516;&#28145;&#24230;&#25110;&#22797;&#26434;&#24230;&#30340;&#29305;&#24449;&#30340;&#23618;&#27425;&#21270;&#32467;&#26500;&#21270;&#28145;&#24230;&#23398;&#20064;&#12290;&#36825;&#36824;&#25193;&#23637;&#21040;&#33021;&#22815;&#29983;&#25104;&#26377;&#29992;&#30340;&#26032;&#30340;&#22810;&#23618;&#32423;&#29305;&#24449;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#29305;&#24449;&#30340;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
A machine learning (ML) feature network is a graph that connects ML features in learning tasks based on their similarity. This network representation allows us to view feature vectors as functions on the network. By leveraging function operations from Fourier analysis and from functional analysis, one can easily generate new and novel features, making use of the graph structure imposed on the feature vectors. Such network structures have previously been studied implicitly in image processing and computational biology. We thus describe feature networks as graph structures imposed on feature vectors, and provide applications in machine learning. One application involves graph-based generalizations of convolutional neural networks, involving structured deep learning with hierarchical representations of features that have varying depth or complexity. This extends also to learning algorithms that are able to generate useful new multilevel features. Additionally, we discuss the use of featur
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#21453;&#20363;&#35777;&#26126;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#21363;&#20351;&#35780;&#20998;&#20989;&#25968;&#23398;&#20064;&#33391;&#22909;&#65292;&#22522;&#20110;&#35780;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#65288;SGMs&#65289;&#20173;&#28982;&#26080;&#27861;&#29983;&#25104;&#25509;&#36817;&#30495;&#23454;&#25968;&#25454;&#20998;&#24067;&#30340;&#26679;&#26412;&#65292;&#24182;&#19988;&#21482;&#33021;&#20135;&#29983;&#35757;&#32451;&#25968;&#25454;&#28857;&#30340;&#39640;&#26031;&#27169;&#31946;&#26679;&#26412;&#12290;</title><link>http://arxiv.org/abs/2401.04856</link><description>&lt;p&gt;
&#19968;&#20010;&#22909;&#30340;&#35780;&#20998;&#24182;&#19981;&#20250;&#23548;&#33268;&#19968;&#20010;&#22909;&#30340;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Good Score Does not Lead to A Good Generative Model. (arXiv:2401.04856v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04856
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#21453;&#20363;&#35777;&#26126;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#21363;&#20351;&#35780;&#20998;&#20989;&#25968;&#23398;&#20064;&#33391;&#22909;&#65292;&#22522;&#20110;&#35780;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#65288;SGMs&#65289;&#20173;&#28982;&#26080;&#27861;&#29983;&#25104;&#25509;&#36817;&#30495;&#23454;&#25968;&#25454;&#20998;&#24067;&#30340;&#26679;&#26412;&#65292;&#24182;&#19988;&#21482;&#33021;&#20135;&#29983;&#35757;&#32451;&#25968;&#25454;&#28857;&#30340;&#39640;&#26031;&#27169;&#31946;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#35780;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#65288;SGMs&#65289;&#26159;&#29983;&#25104;&#24314;&#27169;&#20013;&#30340;&#19968;&#31181;&#20027;&#35201;&#26041;&#27861;&#65292;&#20197;&#20854;&#33021;&#22815;&#20174;&#22797;&#26434;&#30340;&#39640;&#32500;&#25968;&#25454;&#20998;&#24067;&#20013;&#29983;&#25104;&#39640;&#36136;&#37327;&#26679;&#26412;&#32780;&#38395;&#21517;&#12290;&#35813;&#26041;&#27861;&#22312;&#32463;&#39564;&#19978;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#24182;&#19988;&#26377;&#30528;&#20005;&#26684;&#30340;&#29702;&#35770;&#25910;&#25947;&#24615;&#36136;&#30340;&#25903;&#25345;&#12290;&#29305;&#21035;&#26159;&#24050;&#32463;&#35777;&#26126;&#65292;&#22914;&#26524;&#23398;&#20064;&#21040;&#30340;&#24213;&#23618;&#35780;&#20998;&#20989;&#25968;&#33391;&#22909;&#65292;SGMs&#33021;&#22815;&#29983;&#25104;&#25509;&#36817;&#30495;&#23454;&#25968;&#25454;&#20998;&#24067;&#30340;&#26679;&#26412;&#65292;&#36825;&#34920;&#26126;&#20102;SGM&#20316;&#20026;&#29983;&#25104;&#27169;&#22411;&#30340;&#25104;&#21151;&#20043;&#22788;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#21453;&#20363;&#12290;&#36890;&#36807;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#20998;&#26512;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#29305;&#23450;&#30340;&#35774;&#32622;&#65292;&#20854;&#20013;&#35780;&#20998;&#20989;&#25968;&#23398;&#20064;&#24471;&#24456;&#22909;&#12290;&#28982;&#32780;&#65292;&#22312;&#36825;&#20010;&#35774;&#32622;&#20013;&#65292;SGMs&#21482;&#33021;&#36755;&#20986;&#35757;&#32451;&#25968;&#25454;&#28857;&#30340;&#39640;&#26031;&#27169;&#31946;&#26679;&#26412;&#65292;&#27169;&#25311;&#26680;&#23494;&#24230;&#20272;&#35745;&#30340;&#25928;&#26524;&#12290;&#36825;&#19968;&#21457;&#29616;&#19982;&#26368;&#36817;&#30340;&#19968;&#31995;&#21015;&#21457;&#29616;&#30456;&#19968;&#33268;&#65292;&#25581;&#31034;&#20102;SGMs&#21487;&#33021;&#34920;&#29616;&#20986;&#24378;&#22823;&#30340;&#35760;&#24518;&#25928;&#24212;&#24182;&#19988;&#26080;&#27861;&#29983;&#25104;&#26679;&#26412;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Score-based Generative Models (SGMs) is one leading method in generative modeling, renowned for their ability to generate high-quality samples from complex, high-dimensional data distributions. The method enjoys empirical success and is supported by rigorous theoretical convergence properties. In particular, it has been shown that SGMs can generate samples from a distribution that is close to the ground-truth if the underlying score function is learned well, suggesting the success of SGM as a generative model. We provide a counter-example in this paper. Through the sample complexity argument, we provide one specific setting where the score function is learned well. Yet, SGMs in this setting can only output samples that are Gaussian blurring of training data points, mimicking the effects of kernel density estimation. The finding resonates a series of recent finding that reveal that SGMs can demonstrate strong memorization effect and fail to generate.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#28145;&#20837;&#20998;&#26512;&#24191;&#20041;&#31561;&#22686;&#36882;&#24402;&#20998;&#21106;&#31639;&#27861;&#65288;GIRP&#65289;&#65292;&#22312;&#21487;&#20998;&#31163;&#20984;&#25439;&#22833;&#21644;&#19981;&#21487;&#24494;&#25439;&#22833;&#30340;&#24773;&#20917;&#19979;&#65292;&#35299;&#20915;&#20102;&#31561;&#22686;&#22238;&#24402;&#38382;&#39064;&#30340;&#23384;&#22312;&#24615;&#21644;&#21807;&#19968;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#36882;&#24402;&#20108;&#20998;&#20998;&#21106;&#30340;&#26041;&#27861;&#26469;&#25214;&#21040;&#35299;&#12290;</title><link>http://arxiv.org/abs/2401.04847</link><description>&lt;p&gt;
&#20851;&#20110;&#24191;&#20041;&#31561;&#22686;&#36882;&#24402;&#20998;&#21106;&#31639;&#27861;&#30340;&#27491;&#30830;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Correctness of the Generalized Isotonic Recursive Partitioning Algorithm. (arXiv:2401.04847v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04847
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#28145;&#20837;&#20998;&#26512;&#24191;&#20041;&#31561;&#22686;&#36882;&#24402;&#20998;&#21106;&#31639;&#27861;&#65288;GIRP&#65289;&#65292;&#22312;&#21487;&#20998;&#31163;&#20984;&#25439;&#22833;&#21644;&#19981;&#21487;&#24494;&#25439;&#22833;&#30340;&#24773;&#20917;&#19979;&#65292;&#35299;&#20915;&#20102;&#31561;&#22686;&#22238;&#24402;&#38382;&#39064;&#30340;&#23384;&#22312;&#24615;&#21644;&#21807;&#19968;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#36882;&#24402;&#20108;&#20998;&#20998;&#21106;&#30340;&#26041;&#27861;&#26469;&#25214;&#21040;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#28145;&#20837;&#20998;&#26512;&#20102;&#24191;&#20041;&#31561;&#22686;&#36882;&#24402;&#20998;&#21106;&#31639;&#27861;&#65288;GIRP&#65289;&#65292;&#35813;&#31639;&#27861;&#29992;&#20110;&#25311;&#21512;&#21487;&#20998;&#31163;&#20984;&#25439;&#22833;&#19979;&#30340;&#31561;&#22686;&#27169;&#22411;&#65292;&#35813;&#31639;&#27861;&#30001;Luss&#21644;Rosset&#25552;&#20986; [J. Comput. Graph. Statist., 23 (2014), pp. 192--201] &#24182;&#30001;Painsky&#21644;Rosset [IEEE Trans. Pattern Anal. Mach. Intell., 38 (2016), pp. 308-321] &#25193;&#23637;&#36866;&#29992;&#20110;&#19981;&#21487;&#24494;&#25439;&#22833;&#12290;GIRP&#31639;&#27861;&#20855;&#26377;&#21560;&#24341;&#20154;&#30340;&#29305;&#28857;&#65292;&#21363;&#22312;&#31639;&#27861;&#30340;&#27599;&#19968;&#27493;&#20013;&#65292;&#20013;&#38388;&#35299;&#28385;&#36275;&#31561;&#22686;&#32422;&#26463;&#12290;&#25991;&#31456;&#20197;&#19968;&#20010;&#20363;&#23376;&#24320;&#22987;&#65292;&#23637;&#31034;&#20102;&#25991;&#29486;&#20013;&#25551;&#36848;&#30340;GIRP&#31639;&#27861;&#21487;&#33021;&#26080;&#27861;&#20135;&#29983;&#31561;&#22686;&#27169;&#22411;&#30340;&#24773;&#20917;&#65292;&#34920;&#26126;&#24517;&#39035;&#20180;&#32454;&#35752;&#35770;&#31561;&#22686;&#22238;&#24402;&#38382;&#39064;&#30340;&#35299;&#30340;&#23384;&#22312;&#24615;&#21644;&#21807;&#19968;&#24615;&#12290;&#25991;&#31456;&#25509;&#30528;&#23637;&#31034;&#65292;&#21487;&#33021;&#23384;&#22312;&#35768;&#22810;&#35299;&#20043;&#19968;&#65292;&#21487;&#20197;&#36890;&#36807;&#23545;&#35266;&#23519;&#25968;&#25454;&#38598;&#36827;&#34892;&#36882;&#24402;&#20108;&#20998;&#20998;&#21106;&#26469;&#25214;&#21040;&#35299;&#12290;&#19968;&#20010;&#23567;&#30340;&#20462;&#25913;
&lt;/p&gt;
&lt;p&gt;
This paper presents an in-depth analysis of the generalized isotonic recursive partitioning (GIRP) algorithm for fitting isotonic models under separable convex losses, proposed by Luss and Rosset [J. Comput. Graph. Statist., 23 (2014), pp. 192--201] for differentiable losses and extended by Painsky and Rosset [IEEE Trans. Pattern Anal. Mach. Intell., 38 (2016), pp. 308-321] for nondifferentiable losses. The GIRP algorithm poseses an attractive feature that in each step of the algorithm, the intermediate solution satisfies the isotonicity constraint. The paper begins with an example showing that the GIRP algorithm as described in the literature may fail to produce an isotonic model, suggesting that the existence and uniqueness of the solution to the isotonic regression problem must be carefully addressed. It proceeds with showing that, among possibly many solutions, there indeed exists a solution that can be found by recursive binary partitioning of the set of observed data. A small mod
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#21033;&#29992;&#29983;&#25104;&#31070;&#32463;&#32593;&#32476;&#27169;&#25311;&#29305;&#24449;&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#26500;&#24314;&#19968;&#20010;&#26222;&#36866;&#19988;&#26080;&#38656;&#20551;&#35774;&#30340;&#29983;&#25104;&#31070;&#32463;&#32593;&#32476;&#26469;&#35299;&#20915;&#12290;&#30740;&#31350;&#22522;&#20110;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#24230;&#37327;&#65292;&#24182;&#25552;&#20986;&#20102;&#26377;&#20851;&#36924;&#36817;&#36136;&#37327;&#30340;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2401.04778</link><description>&lt;p&gt;
&#21033;&#29992;&#29983;&#25104;&#31070;&#32463;&#32593;&#32476;&#27169;&#25311;&#29305;&#24449;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Generative neural networks for characteristic functions. (arXiv:2401.04778v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04778
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#21033;&#29992;&#29983;&#25104;&#31070;&#32463;&#32593;&#32476;&#27169;&#25311;&#29305;&#24449;&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#26500;&#24314;&#19968;&#20010;&#26222;&#36866;&#19988;&#26080;&#38656;&#20551;&#35774;&#30340;&#29983;&#25104;&#31070;&#32463;&#32593;&#32476;&#26469;&#35299;&#20915;&#12290;&#30740;&#31350;&#22522;&#20110;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#24230;&#37327;&#65292;&#24182;&#25552;&#20986;&#20102;&#26377;&#20851;&#36924;&#36817;&#36136;&#37327;&#30340;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#27169;&#25311;&#31639;&#27861;&#26469;&#20174;&#19968;&#20010;&#65288;&#22810;&#20803;&#65289;&#29305;&#24449;&#20989;&#25968;&#20013;&#27169;&#25311;&#65292;&#35813;&#29305;&#24449;&#20989;&#25968;&#20165;&#20197;&#40657;&#30418;&#26684;&#24335;&#21487;&#35775;&#38382;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#29983;&#25104;&#31070;&#32463;&#32593;&#32476;&#65292;&#20854;&#25439;&#22833;&#20989;&#25968;&#21033;&#29992;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#24230;&#37327;&#30340;&#29305;&#23450;&#34920;&#31034;&#65292;&#30452;&#25509;&#32467;&#21512;&#30446;&#26631;&#29305;&#24449;&#20989;&#25968;&#12290;&#36825;&#31181;&#26500;&#36896;&#20855;&#26377;&#26222;&#36941;&#24615;&#65292;&#19981;&#20381;&#36182;&#20110;&#32500;&#24230;&#65292;&#24182;&#19988;&#19981;&#38656;&#35201;&#23545;&#32473;&#23450;&#29305;&#24449;&#20989;&#25968;&#36827;&#34892;&#20219;&#20309;&#20551;&#35774;&#12290;&#27492;&#22806;&#65292;&#36824;&#24471;&#20986;&#20102;&#20851;&#20110;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#24230;&#37327;&#30340;&#36924;&#36817;&#36136;&#37327;&#30340;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#12290;&#35813;&#26041;&#27861;&#22312;&#19968;&#20010;&#30701;&#26399;&#27169;&#25311;&#30740;&#31350;&#20013;&#36827;&#34892;&#20102;&#35828;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we provide a simulation algorithm to simulate from a (multivariate) characteristic function, which is only accessible in a black-box format. We construct a generative neural network, whose loss function exploits a specific representation of the Maximum-Mean-Discrepancy metric to directly incorporate the targeted characteristic function. The construction is universal in the sense that it is independent of the dimension and that it does not require any assumptions on the given characteristic function. Furthermore, finite sample guarantees on the approximation quality in terms of the Maximum-Mean Discrepancy metric are derived. The method is illustrated in a short simulation study.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20010;&#24615;&#21270;&#27835;&#30103;&#25512;&#33616;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#19978;&#19979;&#25991;&#22266;&#23450;&#39044;&#31639;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#27169;&#22411;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#23454;&#39564;&#35774;&#35745;&#21644;&#31574;&#30053;&#23398;&#20064;&#26469;&#25512;&#33616;&#26368;&#20339;&#27835;&#30103;&#26041;&#26696;&#65292;&#24182;&#36890;&#36807;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#26399;&#26395;&#31616;&#21333;&#36951;&#25022;&#26469;&#34913;&#37327;&#25512;&#33616;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.03756</link><description>&lt;p&gt;
&#19978;&#19979;&#25991;&#22266;&#23450;&#39044;&#31639;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#65306;&#36866;&#24212;&#24615;&#23454;&#39564;&#35774;&#35745;&#19982;&#31574;&#30053;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Contextual Fixed-Budget Best Arm Identification: Adaptive Experimental Design with Policy Learning. (arXiv:2401.03756v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03756
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20010;&#24615;&#21270;&#27835;&#30103;&#25512;&#33616;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#19978;&#19979;&#25991;&#22266;&#23450;&#39044;&#31639;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#27169;&#22411;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#23454;&#39564;&#35774;&#35745;&#21644;&#31574;&#30053;&#23398;&#20064;&#26469;&#25512;&#33616;&#26368;&#20339;&#27835;&#30103;&#26041;&#26696;&#65292;&#24182;&#36890;&#36807;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#26399;&#26395;&#31616;&#21333;&#36951;&#25022;&#26469;&#34913;&#37327;&#25512;&#33616;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20010;&#24615;&#21270;&#27835;&#30103;&#25512;&#33616;&#26159;&#22522;&#20110;&#35777;&#25454;&#30340;&#20915;&#31574;&#20013;&#30340;&#20851;&#38190;&#20219;&#21153;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23558;&#36825;&#20010;&#20219;&#21153;&#20316;&#20026;&#19968;&#20010;&#24102;&#26377;&#19978;&#19979;&#25991;&#20449;&#24687;&#30340;&#22266;&#23450;&#39044;&#31639;&#26368;&#20339;&#33218;&#35782;&#21035;&#65288;Best Arm Identification, BAI&#65289;&#38382;&#39064;&#26469;&#36827;&#34892;&#24314;&#27169;&#12290;&#22312;&#36825;&#20010;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#32473;&#23450;&#22810;&#20010;&#27835;&#30103;&#33218;&#30340;&#33258;&#36866;&#24212;&#35797;&#39564;&#12290;&#22312;&#27599;&#19968;&#36718;&#20013;&#65292;&#20915;&#31574;&#32773;&#35266;&#23519;&#19968;&#20010;&#21051;&#30011;&#23454;&#39564;&#21333;&#20301;&#30340;&#19978;&#19979;&#25991;&#65288;&#21327;&#21464;&#37327;&#65289;&#65292;&#24182;&#23558;&#35813;&#21333;&#20301;&#20998;&#37197;&#32473;&#20854;&#20013;&#19968;&#20010;&#27835;&#30103;&#33218;&#12290;&#22312;&#23454;&#39564;&#32467;&#26463;&#26102;&#65292;&#20915;&#31574;&#32773;&#25512;&#33616;&#19968;&#20010;&#22312;&#32473;&#23450;&#19978;&#19979;&#25991;&#26465;&#20214;&#19979;&#39044;&#35745;&#20135;&#29983;&#26368;&#39640;&#26399;&#26395;&#32467;&#26524;&#30340;&#27835;&#30103;&#33218;&#65288;&#26368;&#20339;&#27835;&#30103;&#33218;&#65289;&#12290;&#35813;&#20915;&#31574;&#30340;&#26377;&#25928;&#24615;&#36890;&#36807;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#26399;&#26395;&#31616;&#21333;&#36951;&#25022;&#65288;&#31574;&#30053;&#36951;&#25022;&#65289;&#26469;&#34913;&#37327;&#65292;&#35813;&#36951;&#25022;&#34920;&#31034;&#22312;&#32473;&#23450;&#19978;&#19979;&#25991;&#26465;&#20214;&#19979;&#65292;&#26368;&#20339;&#27835;&#30103;&#33218;&#21644;&#25512;&#33616;&#27835;&#30103;&#33218;&#30340;&#26465;&#20214;&#26399;&#26395;&#32467;&#26524;&#20043;&#38388;&#30340;&#26368;&#22823;&#24046;&#24322;&#12290;&#25105;&#20204;&#30340;&#21021;&#22987;&#27493;&#39588;&#26159;&#25512;&#23548;&#26368;&#22351;&#24773;&#20917;&#19979;&#26399;&#26395;&#31616;&#21333;&#36951;&#25022;&#30340;&#28176;&#36817;&#19979;&#30028;&#65292;&#35813;&#19979;&#30028;&#36824;&#26263;&#31034;&#30528;&#35299;&#20915;&#35813;&#38382;&#39064;&#30340;&#19968;&#20123;&#24605;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Individualized treatment recommendation is a crucial task in evidence-based decision-making. In this study, we formulate this task as a fixed-budget best arm identification (BAI) problem with contextual information. In this setting, we consider an adaptive experiment given multiple treatment arms. At each round, a decision-maker observes a context (covariate) that characterizes an experimental unit and assigns the unit to one of the treatment arms. At the end of the experiment, the decision-maker recommends a treatment arm estimated to yield the highest expected outcome conditioned on a context (best treatment arm). The effectiveness of this decision is measured in terms of the worst-case expected simple regret (policy regret), which represents the largest difference between the conditional expected outcomes of the best and recommended treatment arms given a context. Our initial step is to derive asymptotic lower bounds for the worst-case expected simple regret, which also implies idea
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;$\beta$-Predictive Bayes&#30340;&#36125;&#21494;&#26031;&#32852;&#37030;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#39044;&#27979;&#21518;&#39564;&#30340;&#28151;&#21512;&#21644;&#20056;&#31215;&#20043;&#38388;&#36827;&#34892;&#25554;&#20540;&#65292;&#36890;&#36807;&#35843;&#25972;&#21442;&#25968;$\beta$&#26469;&#35299;&#20915;&#29616;&#26377;&#26041;&#27861;&#20013;&#36807;&#20110;&#33258;&#20449;&#30340;&#39044;&#27979;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2312.09817</link><description>&lt;p&gt;
&#22312;&#39044;&#27979;&#31354;&#38388;&#20013;&#24102;&#26377;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#26657;&#20934;&#19968;&#36718;&#32852;&#37030;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Calibrated One Round Federated Learning with Bayesian Inference in the Predictive Space. (arXiv:2312.09817v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.09817
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;$\beta$-Predictive Bayes&#30340;&#36125;&#21494;&#26031;&#32852;&#37030;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#39044;&#27979;&#21518;&#39564;&#30340;&#28151;&#21512;&#21644;&#20056;&#31215;&#20043;&#38388;&#36827;&#34892;&#25554;&#20540;&#65292;&#36890;&#36807;&#35843;&#25972;&#21442;&#25968;$\beta$&#26469;&#35299;&#20915;&#29616;&#26377;&#26041;&#27861;&#20013;&#36807;&#20110;&#33258;&#20449;&#30340;&#39044;&#27979;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#26159;&#25351;&#22312;&#20998;&#24067;&#22312;&#23458;&#25143;&#31471;&#20013;&#30340;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#27169;&#22411;&#65292;&#27599;&#20010;&#23458;&#25143;&#31471;&#30340;&#25968;&#25454;&#38598;&#26159;&#26412;&#22320;&#21270;&#19988;&#21487;&#33021;&#26159;&#24322;&#36136;&#30340;&#12290;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#65292;&#23567;&#32780;&#22122;&#22768;&#30340;&#25968;&#25454;&#38598;&#24456;&#24120;&#35265;&#65292;&#24378;&#35843;&#20102;&#38656;&#35201;&#33021;&#22815;&#34920;&#31034;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#30340;&#33391;&#22909;&#26657;&#20934;&#27169;&#22411;&#12290;&#26368;&#25509;&#36817;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#30340;&#32852;&#37030;&#23398;&#20064;&#25216;&#26415;&#26159;&#36125;&#21494;&#26031;&#32852;&#37030;&#23398;&#20064;&#26041;&#27861;&#65292;&#23427;&#20174;&#23616;&#37096;&#21518;&#39564;&#20013;&#25910;&#38598;&#21442;&#25968;&#26679;&#26412;&#65292;&#24182;&#23558;&#23427;&#20204;&#32858;&#21512;&#20197;&#36817;&#20284;&#20840;&#23616;&#21518;&#39564;&#12290;&#20026;&#20102;&#25552;&#39640;&#26356;&#22823;&#27169;&#22411;&#30340;&#21487;&#25193;&#23637;&#24615;&#65292;&#36125;&#21494;&#26031;&#26041;&#27861;&#36890;&#24120;&#26159;&#36890;&#36807;&#23558;&#23616;&#37096;&#39044;&#27979;&#21518;&#39564;&#30456;&#20056;&#26469;&#36817;&#20284;&#20840;&#23616;&#39044;&#27979;&#21518;&#39564;&#12290;&#26412;&#30740;&#31350;&#34920;&#26126;&#65292;&#36825;&#31181;&#26041;&#27861;&#20250;&#23548;&#33268;&#31995;&#32479;&#24615;&#30340;&#36807;&#20110;&#33258;&#20449;&#30340;&#39044;&#27979;&#32467;&#26524;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;$\beta$-Predictive Bayes&#30340;&#36125;&#21494;&#26031;&#32852;&#37030;&#23398;&#20064;&#31639;&#27861;&#65292;&#23427;&#22312;&#39044;&#27979;&#21518;&#39564;&#30340;&#28151;&#21512;&#21644;&#20056;&#31215;&#20043;&#38388;&#36827;&#34892;&#25554;&#20540;&#65292;&#20351;&#29992;&#19968;&#20010;&#21487;&#35843;&#21442;&#25968;$\beta$&#26469;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated Learning (FL) involves training a model over a dataset distributed among clients, with the constraint that each client's dataset is localized and possibly heterogeneous. In FL, small and noisy datasets are common, highlighting the need for well-calibrated models that represent the uncertainty of predictions. The closest FL techniques to achieving such goals are the Bayesian FL methods which collect parameter samples from local posteriors, and aggregate them to approximate the global posterior. To improve scalability for larger models, one common Bayesian approach is to approximate the global predictive posterior by multiplying local predictive posteriors. In this work, we demonstrate that this method gives systematically overconfident predictions, and we remedy this by proposing $\beta$-Predictive Bayes, a Bayesian FL algorithm that interpolates between a mixture and product of the predictive posteriors, using a tunable parameter $\beta$. This parameter is tuned to improve th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#24847;&#22806;&#25351;&#25968;&#26469;&#35780;&#20272;&#33258;&#20027;&#20915;&#31574;&#20013;&#33021;&#21147;&#30340;&#26041;&#27861;&#65292;&#35813;&#25351;&#26631;&#21487;&#20197;&#21033;&#29992;&#27979;&#37327;&#25968;&#25454;&#37327;&#21270;&#21160;&#24577;&#31995;&#32479;&#26159;&#21542;&#25353;&#39044;&#26399;&#36816;&#34892;&#12290;&#35813;&#26041;&#27861;&#22312;&#38750;&#32447;&#24615;&#33322;&#22825;&#22120;&#26426;&#21160;&#38382;&#39064;&#20013;&#26377;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2312.09033</link><description>&lt;p&gt;
&#20351;&#29992;&#24847;&#22806;&#25351;&#25968;&#35780;&#20272;&#33258;&#20027;&#20915;&#31574;&#20013;&#30340;&#33021;&#21147;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Using Surprise Index for Competency Assessment in Autonomous Decision-Making. (arXiv:2312.09033v2 [cs.RO] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.09033
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#24847;&#22806;&#25351;&#25968;&#26469;&#35780;&#20272;&#33258;&#20027;&#20915;&#31574;&#20013;&#33021;&#21147;&#30340;&#26041;&#27861;&#65292;&#35813;&#25351;&#26631;&#21487;&#20197;&#21033;&#29992;&#27979;&#37327;&#25968;&#25454;&#37327;&#21270;&#21160;&#24577;&#31995;&#32479;&#26159;&#21542;&#25353;&#39044;&#26399;&#36816;&#34892;&#12290;&#35813;&#26041;&#27861;&#22312;&#38750;&#32447;&#24615;&#33322;&#22825;&#22120;&#26426;&#21160;&#38382;&#39064;&#20013;&#26377;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#22312;&#21160;&#24577;&#21644;&#19981;&#30830;&#23450;&#29615;&#22659;&#20013;&#35780;&#20272;&#33258;&#20027;&#31995;&#32479;&#22312;&#25191;&#34892;&#20219;&#21153;&#26102;&#30340;&#33021;&#21147;&#30340;&#38382;&#39064;&#12290;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#22266;&#26377;&#19981;&#36879;&#26126;&#24615;&#65292;&#20174;&#29992;&#25143;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#36890;&#24120;&#34987;&#25551;&#36848;&#20026;&#8220;&#40657;&#21283;&#23376;&#8221;&#65292;&#36825;&#26159;&#19968;&#20010;&#25361;&#25112;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#19968;&#20010;&#31216;&#20026;&#8220;&#24847;&#22806;&#25351;&#25968;&#8221;&#30340;&#24230;&#37327;&#26469;&#21033;&#29992;&#21487;&#29992;&#30340;&#27979;&#37327;&#25968;&#25454;&#26469;&#37327;&#21270;&#21160;&#24577;&#31995;&#32479;&#26159;&#21542;&#25353;&#39044;&#26399;&#36816;&#34892;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#24403;&#35266;&#27979;&#21040;&#30340;&#35777;&#25454;&#22312;&#27010;&#29575;&#27169;&#22411;&#20013;&#30340;&#32852;&#21512;&#20998;&#24067;&#36981;&#24490;&#22810;&#20803;&#39640;&#26031;&#36793;&#32536;&#20998;&#24067;&#26102;&#65292;&#24847;&#22806;&#25351;&#25968;&#21487;&#20197;&#20197;&#38381;&#21512;&#24418;&#24335;&#35745;&#31639;&#21160;&#24577;&#31995;&#32479;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#20854;&#24212;&#29992;&#20110;&#38750;&#32447;&#24615;&#33322;&#22825;&#22120;&#26426;&#21160;&#38382;&#39064;&#65292;&#22312;&#35813;&#38382;&#39064;&#20013;&#65292;&#21160;&#20316;&#30001;&#24378;&#21270;&#23398;&#20064;&#20195;&#29702;&#36873;&#25321;&#65292;&#24182;&#19988;&#25105;&#20204;&#23637;&#31034;&#23427;&#21487;&#20197;&#25351;&#31034;&#36712;&#36947;&#22914;&#20309;&#36319;&#38543;&#25152;&#38656;&#36712;&#36947;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper considers the problem of evaluating an autonomous system's competency in performing a task, particularly when working in dynamic and uncertain environments. The inherent opacity of machine learning models, from the perspective of the user, often described as a `black box', poses a challenge. To overcome this, we propose using a measure called the Surprise index, which leverages available measurement data to quantify whether the dynamic system performs as expected. We show that the surprise index can be computed in closed form for dynamic systems when observed evidence in a probabilistic model if the joint distribution for that evidence follows a multivariate Gaussian marginal distribution. We then apply it to a nonlinear spacecraft maneuver problem, where actions are chosen by a reinforcement learning agent and show it can indicate how well the trajectory follows the required orbit.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#20984;&#20248;&#21270;&#20013;&#31639;&#27861;&#30340;&#21487;&#37325;&#29616;&#24615;&#21644;&#26799;&#24230;&#22797;&#26434;&#24230;&#38382;&#39064;&#12290;&#20182;&#20204;&#25361;&#25112;&#20102;&#20043;&#21069;&#30340;&#35266;&#28857;&#65292;&#35777;&#26126;&#20102;&#23545;&#20110;&#24179;&#28369;&#20984;&#20248;&#21270;&#21644;&#24179;&#28369;&#20984;&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#21487;&#20197;&#23454;&#29616;&#26368;&#20248;&#30340;&#21487;&#37325;&#29616;&#24615;&#21644;&#25509;&#36817;&#26368;&#20248;&#30340;&#25910;&#25947;&#20445;&#35777;&#12290;&#20182;&#20204;&#36824;&#35777;&#26126;&#20102;&#22312;&#19981;&#21516;&#30340;oracle&#35774;&#32622;&#19979;&#65292;&#19982;&#19981;&#21516;&#31867;&#22411;&#30340;oracle&#30456;&#21305;&#37197;&#30340;&#31639;&#27861;&#36798;&#21040;&#20102;&#26368;&#20248;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.17759</link><description>&lt;p&gt;
&#22312;&#20984;&#20248;&#21270;&#20013;&#30340;&#31639;&#27861;&#21487;&#37325;&#29616;&#24615;&#21644;&#26799;&#24230;&#22797;&#26434;&#24230;&#30340;&#26368;&#20248;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Optimal Guarantees for Algorithmic Reproducibility and Gradient Complexity in Convex Optimization. (arXiv:2310.17759v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17759
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#20984;&#20248;&#21270;&#20013;&#31639;&#27861;&#30340;&#21487;&#37325;&#29616;&#24615;&#21644;&#26799;&#24230;&#22797;&#26434;&#24230;&#38382;&#39064;&#12290;&#20182;&#20204;&#25361;&#25112;&#20102;&#20043;&#21069;&#30340;&#35266;&#28857;&#65292;&#35777;&#26126;&#20102;&#23545;&#20110;&#24179;&#28369;&#20984;&#20248;&#21270;&#21644;&#24179;&#28369;&#20984;&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#21487;&#20197;&#23454;&#29616;&#26368;&#20248;&#30340;&#21487;&#37325;&#29616;&#24615;&#21644;&#25509;&#36817;&#26368;&#20248;&#30340;&#25910;&#25947;&#20445;&#35777;&#12290;&#20182;&#20204;&#36824;&#35777;&#26126;&#20102;&#22312;&#19981;&#21516;&#30340;oracle&#35774;&#32622;&#19979;&#65292;&#19982;&#19981;&#21516;&#31867;&#22411;&#30340;oracle&#30456;&#21305;&#37197;&#30340;&#31639;&#27861;&#36798;&#21040;&#20102;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31639;&#27861;&#21487;&#37325;&#29616;&#24615;&#34913;&#37327;&#20102;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#31245;&#24494;&#25913;&#21464;&#26102;&#36755;&#20986;&#30340;&#20559;&#24046;&#12290;&#20043;&#21069;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#19968;&#38454;&#26041;&#27861;&#38656;&#35201;&#22312;&#25910;&#25947;&#36895;&#24230;&#65288;&#26799;&#24230;&#22797;&#26434;&#24230;&#65289;&#21644;&#26356;&#22909;&#30340;&#21487;&#37325;&#29616;&#24615;&#20043;&#38388;&#20570;&#20986;&#26435;&#34913;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25361;&#25112;&#20102;&#36825;&#31181;&#30475;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#21508;&#31181;&#23481;&#26131;&#20986;&#38169;&#30340;oracle&#35774;&#32622;&#19979;&#65292;&#23545;&#20110;&#24179;&#28369;&#20984;&#20248;&#21270;&#21644;&#24179;&#28369;&#20984;&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#21487;&#20197;&#23454;&#29616;&#26368;&#20248;&#30340;&#21487;&#37325;&#29616;&#24615;&#21644;&#25509;&#36817;&#26368;&#20248;&#30340;&#25910;&#25947;&#20445;&#35777;&#12290;&#23588;&#20854;&#26159;&#65292;&#22312;&#19981;&#31934;&#30830;&#30340;&#21021;&#22987;&#21270;oracle&#32473;&#23450;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#22522;&#20110;&#27491;&#21017;&#21270;&#30340;&#31639;&#27861;&#23454;&#29616;&#20102;&#26368;&#20248;&#30340;&#21487;&#37325;&#29616;&#24615;&#21644;&#25509;&#36817;&#26368;&#20248;&#30340;&#26799;&#24230;&#22797;&#26434;&#24230;-&#23545;&#20110;&#26368;&#23567;&#21270;&#21644;&#26368;&#23567;&#26368;&#22823;&#20248;&#21270;&#12290;&#23545;&#20110;&#19981;&#31934;&#30830;&#30340;&#26799;&#24230;oracle&#65292;&#25509;&#36817;&#26368;&#20248;&#30340;&#20445;&#35777;&#20063;&#36866;&#29992;&#20110;&#26368;&#23567;&#26368;&#22823;&#20248;&#21270;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#38543;&#26426;&#26799;&#24230;oracle&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#19978;&#21319;&#22312;&#21487;&#37325;&#29616;&#24615;&#21644;&#25910;&#25947;&#36895;&#24230;&#26041;&#38754;&#37117;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Algorithmic reproducibility measures the deviation in outputs of machine learning algorithms upon minor changes in the training process. Previous work suggests that first-order methods would need to trade-off convergence rate (gradient complexity) for better reproducibility. In this work, we challenge this perception and demonstrate that both optimal reproducibility and near-optimal convergence guarantees can be achieved for smooth convex minimization and smooth convex-concave minimax problems under various error-prone oracle settings. Particularly, given the inexact initialization oracle, our regularization-based algorithms achieve the best of both worlds optimal reproducibility and near-optimal gradient complexity - for minimization and minimax optimization. With the inexact gradient oracle, the near-optimal guarantees also hold for minimax optimization. Additionally, with the stochastic gradient oracle, we show that stochastic gradient descent ascent is optimal in terms of both re
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;$L^1$&#20445;&#30495;&#24230;&#26465;&#20214;&#19979;&#65292;&#20174;&#22122;&#22768;&#35266;&#27979;&#20013;&#20272;&#35745;&#38543;&#26426;&#21464;&#37327;$X$&#30340;&#38382;&#39064;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#21807;&#19968;&#33021;&#22815;&#24341;&#20837;&#32447;&#24615;&#26465;&#20214;&#20013;&#20301;&#25968;&#30340;&#20808;&#39564;&#20998;&#24067;&#26159;&#39640;&#26031;&#20998;&#24067;&#12290;&#27492;&#22806;&#65292;&#36824;&#30740;&#31350;&#20102;&#20854;&#20182;$L^p$&#25439;&#22833;&#65292;&#24182;&#35266;&#23519;&#21040;&#23545;&#20110;$p \in [1,2]$&#65292;&#39640;&#26031;&#20998;&#24067;&#26159;&#21807;&#19968;&#24341;&#20837;&#32447;&#24615;&#26368;&#20248;&#36125;&#21494;&#26031;&#20272;&#35745;&#22120;&#30340;&#20808;&#39564;&#20998;&#24067;&#12290;&#25193;&#23637;&#36824;&#28085;&#30422;&#20102;&#29305;&#23450;&#25351;&#25968;&#26063;&#26465;&#20214;&#20998;&#24067;&#30340;&#22122;&#22768;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2309.09129</link><description>&lt;p&gt;
$L^1$&#20272;&#35745;&#65306;&#32447;&#24615;&#20272;&#35745;&#22120;&#30340;&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;
$L^1$ Estimation: On the Optimality of Linear Estimators. (arXiv:2309.09129v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09129
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;$L^1$&#20445;&#30495;&#24230;&#26465;&#20214;&#19979;&#65292;&#20174;&#22122;&#22768;&#35266;&#27979;&#20013;&#20272;&#35745;&#38543;&#26426;&#21464;&#37327;$X$&#30340;&#38382;&#39064;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#21807;&#19968;&#33021;&#22815;&#24341;&#20837;&#32447;&#24615;&#26465;&#20214;&#20013;&#20301;&#25968;&#30340;&#20808;&#39564;&#20998;&#24067;&#26159;&#39640;&#26031;&#20998;&#24067;&#12290;&#27492;&#22806;&#65292;&#36824;&#30740;&#31350;&#20102;&#20854;&#20182;$L^p$&#25439;&#22833;&#65292;&#24182;&#35266;&#23519;&#21040;&#23545;&#20110;$p \in [1,2]$&#65292;&#39640;&#26031;&#20998;&#24067;&#26159;&#21807;&#19968;&#24341;&#20837;&#32447;&#24615;&#26368;&#20248;&#36125;&#21494;&#26031;&#20272;&#35745;&#22120;&#30340;&#20808;&#39564;&#20998;&#24067;&#12290;&#25193;&#23637;&#36824;&#28085;&#30422;&#20102;&#29305;&#23450;&#25351;&#25968;&#26063;&#26465;&#20214;&#20998;&#24067;&#30340;&#22122;&#22768;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;$L^1$&#20445;&#30495;&#24230;&#26465;&#20214;&#19979;&#65292;&#32771;&#34385;&#20174;&#22122;&#22768;&#35266;&#27979;$Y=X+Z$&#20013;&#20272;&#35745;&#38543;&#26426;&#21464;&#37327;$X$&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;$Z$&#26159;&#26631;&#20934;&#27491;&#24577;&#20998;&#24067;&#12290;&#20247;&#25152;&#21608;&#30693;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#26368;&#20248;&#30340;&#36125;&#21494;&#26031;&#20272;&#35745;&#22120;&#26159;&#26465;&#20214;&#20013;&#20301;&#25968;&#12290;&#26412;&#25991;&#34920;&#26126;&#65292;&#22312;&#26465;&#20214;&#20013;&#20301;&#25968;&#20013;&#24341;&#20837;&#32447;&#24615;&#30340;&#21807;&#19968;&#20808;&#39564;&#20998;&#24067;&#26159;&#39640;&#26031;&#20998;&#24067;&#12290;&#21516;&#26102;&#65292;&#36824;&#25552;&#20379;&#20102;&#20854;&#20182;&#20960;&#20010;&#32467;&#26524;&#12290;&#29305;&#21035;&#22320;&#65292;&#35777;&#26126;&#20102;&#22914;&#26524;&#23545;&#20110;&#25152;&#26377;$y$&#65292;&#26465;&#20214;&#20998;&#24067;$P_{X|Y=y}$&#37117;&#26159;&#23545;&#31216;&#30340;&#65292;&#21017;$X$&#24517;&#39035;&#26381;&#20174;&#39640;&#26031;&#20998;&#24067;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#20854;&#20182;&#30340;$L^p$&#25439;&#22833;&#65292;&#24182;&#35266;&#23519;&#21040;&#20197;&#19979;&#29616;&#35937;&#65306;&#23545;&#20110;$p \in [1,2]$&#65292;&#39640;&#26031;&#20998;&#24067;&#26159;&#21807;&#19968;&#24341;&#20837;&#32447;&#24615;&#26368;&#20248;&#36125;&#21494;&#26031;&#20272;&#35745;&#22120;&#30340;&#20808;&#39564;&#20998;&#24067;&#65292;&#23545;&#20110;$p \in (2,\infty)$&#65292;&#26377;&#26080;&#31351;&#22810;&#20010;&#20808;&#39564;&#20998;&#24067;&#21487;&#20197;&#24341;&#20837;&#32447;&#24615;&#24615;&#12290;&#26368;&#21518;&#65292;&#36824;&#25552;&#20379;&#20102;&#25193;&#23637;&#65292;&#20197;&#28085;&#30422;&#23548;&#33268;&#29305;&#23450;&#25351;&#25968;&#26063;&#26465;&#20214;&#20998;&#24067;&#30340;&#22122;&#22768;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Consider the problem of estimating a random variable $X$ from noisy observations $Y = X+ Z$, where $Z$ is standard normal, under the $L^1$ fidelity criterion. It is well known that the optimal Bayesian estimator in this setting is the conditional median. This work shows that the only prior distribution on $X$ that induces linearity in the conditional median is Gaussian.  Along the way, several other results are presented. In particular, it is demonstrated that if the conditional distribution $P_{X|Y=y}$ is symmetric for all $y$, then $X$ must follow a Gaussian distribution. Additionally, we consider other $L^p$ losses and observe the following phenomenon: for $p \in [1,2]$, Gaussian is the only prior distribution that induces a linear optimal Bayesian estimator, and for $p \in (2,\infty)$, infinitely many prior distributions on $X$ can induce linearity. Finally, extensions are provided to encompass noise models leading to conditional distributions from certain exponential families.
&lt;/p&gt;</description></item><item><title>&#22810;&#20445;&#30495;&#24230;&#20613;&#37324;&#21494;&#31070;&#32463;&#31639;&#23376;&#29992;&#20110;&#35299;&#20915;&#22823;&#35268;&#27169;&#22320;&#36136;&#30899;&#20648;&#23384;&#38382;&#39064;&#65292;&#36890;&#36807;&#21033;&#29992;&#32463;&#27982;&#24615;&#26356;&#39640;&#30340;&#22810;&#20445;&#30495;&#24230;&#35757;&#32451;&#25968;&#25454;&#38598;&#65292;&#33021;&#22815;&#20197;&#19982;&#39640;&#20445;&#30495;&#24230;&#27169;&#22411;&#30456;&#24403;&#30340;&#20934;&#30830;&#24615;&#36827;&#34892;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2308.09113</link><description>&lt;p&gt;
&#22810;&#20445;&#30495;&#24230;&#20613;&#37324;&#21494;&#31070;&#32463;&#31639;&#23376;&#29992;&#20110;&#24555;&#36895;&#24314;&#27169;&#22823;&#35268;&#27169;&#22320;&#36136;&#30899;&#20648;&#23384;
&lt;/p&gt;
&lt;p&gt;
Multi-fidelity Fourier Neural Operator for Fast Modeling of Large-Scale Geological Carbon Storage. (arXiv:2308.09113v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09113
&lt;/p&gt;
&lt;p&gt;
&#22810;&#20445;&#30495;&#24230;&#20613;&#37324;&#21494;&#31070;&#32463;&#31639;&#23376;&#29992;&#20110;&#35299;&#20915;&#22823;&#35268;&#27169;&#22320;&#36136;&#30899;&#20648;&#23384;&#38382;&#39064;&#65292;&#36890;&#36807;&#21033;&#29992;&#32463;&#27982;&#24615;&#26356;&#39640;&#30340;&#22810;&#20445;&#30495;&#24230;&#35757;&#32451;&#25968;&#25454;&#38598;&#65292;&#33021;&#22815;&#20197;&#19982;&#39640;&#20445;&#30495;&#24230;&#27169;&#22411;&#30456;&#24403;&#30340;&#20934;&#30830;&#24615;&#36827;&#34892;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#30340;&#20195;&#29702;&#27169;&#22411;&#24050;&#24191;&#27867;&#24212;&#29992;&#20110;&#22320;&#36136;&#30899;&#20648;&#23384;&#65288;GCS&#65289;&#38382;&#39064;&#65292;&#20197;&#21152;&#24555;&#39044;&#27979;&#20648;&#21387;&#21644;&#20108;&#27687;&#21270;&#30899;&#20113;&#23618;&#31227;&#21160;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#39640;&#35745;&#31639;&#25104;&#26412;&#65292;&#22823;&#35268;&#27169;&#19977;&#32500;&#38382;&#39064;&#30340;&#21487;&#29992;&#35757;&#32451;&#25968;&#25454;&#22987;&#32456;&#26377;&#38480;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#22810;&#20445;&#30495;&#24230;&#20613;&#37324;&#21494;&#31070;&#32463;&#31639;&#23376;&#26469;&#35299;&#20915;&#22823;&#35268;&#27169;GCS&#38382;&#39064;&#65292;&#21033;&#29992;&#26356;&#20855;&#32463;&#27982;&#24615;&#30340;&#22810;&#20445;&#30495;&#24230;&#35757;&#32451;&#25968;&#25454;&#38598;&#12290;&#20613;&#37324;&#21494;&#31070;&#32463;&#31639;&#23376;&#20855;&#26377;&#33391;&#22909;&#30340;&#32593;&#26684;&#19981;&#21464;&#24615;&#65292;&#31616;&#21270;&#20102;&#19981;&#21516;&#31163;&#25955;&#25968;&#25454;&#38598;&#20043;&#38388;&#30340;&#36801;&#31227;&#23398;&#20064;&#36807;&#31243;&#12290;&#25105;&#20204;&#39318;&#20808;&#22312;&#19968;&#20010;GCS&#20648;&#23618;&#27169;&#22411;&#19978;&#36827;&#34892;&#27169;&#22411;&#26377;&#25928;&#24615;&#27979;&#35797;&#65292;&#35813;&#27169;&#22411;&#34987;&#21010;&#20998;&#20026;110,000&#20010;&#32593;&#26684;&#21333;&#20803;&#12290;&#22810;&#20445;&#30495;&#24230;&#27169;&#22411;&#30340;&#39044;&#27979;&#20934;&#30830;&#24230;&#21487;&#19982;&#39640;&#20445;&#30495;&#24230;&#27169;&#22411;&#30340;&#35757;&#32451;&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning-based surrogate models have been widely applied in geological carbon storage (GCS) problems to accelerate the prediction of reservoir pressure and CO2 plume migration. Large amounts of data from physics-based numerical simulators are required to train a model to accurately predict the complex physical behaviors associated with this process. In practice, the available training data are always limited in large-scale 3D problems due to the high computational cost. Therefore, we propose to use a multi-fidelity Fourier Neural Operator to solve large-scale GCS problems with more affordable multi-fidelity training datasets. The Fourier Neural Operator has a desirable grid-invariant property, which simplifies the transfer learning procedure between datasets with different discretization. We first test the model efficacy on a GCS reservoir model being discretized into 110k grid cells. The multi-fidelity model can predict with accuracy comparable to a high-fidelity model trained wi
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#38750;&#32447;&#24615;&#12289;&#21453;&#39304;&#21644;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#20013;&#30340;&#19968;&#33268;&#24615;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#24369;&#20110;&#24378;&#21487;&#38752;&#24615;&#30340;k-Triangle Faithfulness&#30340;&#26367;&#20195;&#23450;&#20041;&#12290;</title><link>http://arxiv.org/abs/2308.07520</link><description>&lt;p&gt;
&#38750;&#32447;&#24615;&#12289;&#21453;&#39304;&#21644;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#20013;&#30340;&#19968;&#33268;&#24615;&#38382;&#39064;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Nonlinearity, Feedback and Uniform Consistency in Causal Structural Learning. (arXiv:2308.07520v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07520
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#38750;&#32447;&#24615;&#12289;&#21453;&#39304;&#21644;&#22240;&#26524;&#32467;&#26500;&#23398;&#20064;&#20013;&#30340;&#19968;&#33268;&#24615;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#24369;&#20110;&#24378;&#21487;&#38752;&#24615;&#30340;k-Triangle Faithfulness&#30340;&#26367;&#20195;&#23450;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#21457;&#29616;&#30340;&#30446;&#26631;&#26159;&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#25214;&#21040;&#23398;&#20064;&#22240;&#26524;&#32467;&#26500;&#30340;&#33258;&#21160;&#21270;&#25628;&#32034;&#26041;&#27861;&#12290;&#26377;&#20123;&#24773;&#20917;&#19979;&#65292;&#24863;&#20852;&#36259;&#30340;&#22240;&#26524;&#26426;&#21046;&#30340;&#25152;&#26377;&#21464;&#37327;&#37117;&#24050;&#32463;&#34987;&#27979;&#37327;&#65292;&#20219;&#21153;&#26159;&#39044;&#27979;&#19968;&#20010;&#21464;&#37327;&#23545;&#21478;&#19968;&#20010;&#21464;&#37327;&#30340;&#24433;&#21709;&#12290;&#30456;&#21453;&#65292;&#26377;&#26102;&#20027;&#35201;&#20851;&#27880;&#30340;&#21464;&#37327;&#24182;&#38750;&#30452;&#25509;&#21487;&#35266;&#23519;&#65292;&#32780;&#26159;&#36890;&#36807;&#23427;&#20204;&#22312;&#25968;&#25454;&#20013;&#30340;&#34920;&#29616;&#26469;&#25512;&#29702;&#20986;&#26469;&#30340;&#12290;&#36825;&#20123;&#34987;&#31216;&#20026;&#28508;&#22312;&#21464;&#37327;&#12290;&#19968;&#20010;&#24191;&#27867;&#34987;&#30693;&#36947;&#30340;&#20363;&#23376;&#26159;&#24515;&#29702;&#26500;&#36896;&#30340;&#26234;&#21830;&#65292;&#22240;&#20026;&#26080;&#27861;&#30452;&#25509;&#27979;&#37327;&#65292;&#25152;&#20197;&#30740;&#31350;&#20154;&#21592;&#23581;&#35797;&#36890;&#36807;&#21508;&#31181;&#25351;&#26631;&#22914;&#26234;&#21830;&#27979;&#35797;&#26469;&#35780;&#20272;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#21487;&#20197;&#25581;&#31034;&#28508;&#22312;&#21464;&#37327;&#20043;&#38388;&#21644;&#28508;&#22312;&#21464;&#37327;&#19982;&#35266;&#23519;&#21464;&#37327;&#20043;&#38388;&#30340;&#22240;&#26524;&#36830;&#25509;&#65292;&#20174;&#32780;&#21457;&#29616;&#28508;&#22312;&#30340;&#27169;&#24335;&#21644;&#32467;&#26500;&#12290;&#36825;&#31687;&#35770;&#25991;&#20027;&#35201;&#30740;&#31350;&#22240;&#26524;&#21457;&#29616;&#20013;&#30340;&#20004;&#20010;&#38382;&#39064;&#65306;&#25552;&#20379;&#20102;&#19968;&#20010;&#24369;&#20110;&#24378;&#21487;&#38752;&#24615;&#30340;k-Triangle Faithfulness&#30340;&#26367;&#20195;&#23450;&#20041;&#65292;&#24182;&#25552;&#20986;&#20102;&#23545;&#32479;&#35745;&#19968;&#33268;&#24615;&#30340;&#26032;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
The goal of Causal Discovery is to find automated search methods for learning causal structures from observational data. In some cases all variables of the interested causal mechanism are measured, and the task is to predict the effects one measured variable has on another. In contrast, sometimes the variables of primary interest are not directly observable but instead inferred from their manifestations in the data. These are referred to as latent variables. One commonly known example is the psychological construct of intelligence, which cannot directly measured so researchers try to assess through various indicators such as IQ tests. In this case, casual discovery algorithms can uncover underlying patterns and structures to reveal the causal connections between the latent variables and between the latent and observed variables. This thesis focuses on two questions in causal discovery: providing an alternative definition of k-Triangle Faithfulness that (i) is weaker than strong faithfu
&lt;/p&gt;</description></item><item><title>SLEM&#26159;&#19968;&#31181;&#36335;&#24452;&#24314;&#27169;&#25216;&#26415;&#65292;&#36890;&#36807;&#38598;&#25104;&#26426;&#22120;&#23398;&#20064;&#36229;&#32423;&#23398;&#20064;&#32773;&#65292;&#23454;&#29616;&#20102;&#19968;&#33268;&#19988;&#26080;&#20559;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#65292;&#24182;&#22312;&#22788;&#29702;&#38750;&#32447;&#24615;&#20851;&#31995;&#26102;&#36229;&#36807;&#20102;&#20256;&#32479;&#30340;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2308.04365</link><description>&lt;p&gt;
SLEM&#65306;&#26426;&#22120;&#23398;&#20064;&#29992;&#20110;&#36335;&#24452;&#24314;&#27169;&#21644;&#22240;&#26524;&#25512;&#26029;&#30340;&#36229;&#32423;&#23398;&#20064;&#32773;&#26041;&#31243;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
SLEM: Machine Learning for Path Modeling and Causal Inference with Super Learner Equation Modeling. (arXiv:2308.04365v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.04365
&lt;/p&gt;
&lt;p&gt;
SLEM&#26159;&#19968;&#31181;&#36335;&#24452;&#24314;&#27169;&#25216;&#26415;&#65292;&#36890;&#36807;&#38598;&#25104;&#26426;&#22120;&#23398;&#20064;&#36229;&#32423;&#23398;&#20064;&#32773;&#65292;&#23454;&#29616;&#20102;&#19968;&#33268;&#19988;&#26080;&#20559;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#65292;&#24182;&#22312;&#22788;&#29702;&#38750;&#32447;&#24615;&#20851;&#31995;&#26102;&#36229;&#36807;&#20102;&#20256;&#32479;&#30340;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#25512;&#26029;&#26159;&#31185;&#23398;&#30340;&#20851;&#38190;&#30446;&#26631;&#65292;&#20351;&#30740;&#31350;&#20154;&#21592;&#33021;&#22815;&#36890;&#36807;&#35266;&#23519;&#25968;&#25454;&#24471;&#20986;&#20851;&#20110;&#23545;&#20551;&#23450;&#24178;&#39044;&#30340;&#39044;&#27979;&#30340;&#26377;&#24847;&#20041;&#30340;&#32467;&#35770;&#12290;&#36335;&#24452;&#27169;&#22411;&#12289;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;(SEMs)&#20197;&#21450;&#26356;&#19968;&#33324;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;(DAGs)&#33021;&#22815;&#26126;&#30830;&#22320;&#25351;&#23450;&#20851;&#20110;&#29616;&#35937;&#32972;&#21518;&#30340;&#22240;&#26524;&#32467;&#26500;&#30340;&#20551;&#35774;&#12290;&#19982;DAGs&#19981;&#21516;&#65292;SEMs&#20551;&#35774;&#32447;&#24615;&#20851;&#31995;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#20989;&#25968;&#38169;&#35823;&#35268;&#33539;&#65292;&#20174;&#32780;&#38459;&#30861;&#30740;&#31350;&#20154;&#21592;&#36827;&#34892;&#21487;&#38752;&#30340;&#25928;&#26524;&#22823;&#23567;&#20272;&#35745;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36229;&#32423;&#23398;&#20064;&#32773;&#26041;&#31243;&#27169;&#22411;&#65288;SLEM&#65289;&#65292;&#19968;&#31181;&#38598;&#25104;&#20102;&#26426;&#22120;&#23398;&#20064;&#36229;&#32423;&#23398;&#20064;&#32773;&#38598;&#25104;&#30340;&#36335;&#24452;&#24314;&#27169;&#25216;&#26415;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;SLEM&#33021;&#22815;&#25552;&#20379;&#19968;&#33268;&#19988;&#26080;&#20559;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#65292;&#22312;&#19982;SEMs&#36827;&#34892;&#32447;&#24615;&#27169;&#22411;&#27604;&#36739;&#26102;&#34920;&#29616;&#20986;&#31454;&#20105;&#21147;&#65292;&#24182;&#19988;&#22312;&#22788;&#29702;&#38750;&#32447;&#24615;&#20851;&#31995;&#26102;&#20248;&#20110;SEMs&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal inference is a crucial goal of science, enabling researchers to arrive at meaningful conclusions regarding the predictions of hypothetical interventions using observational data. Path models, Structural Equation Models (SEMs), and, more generally, Directed Acyclic Graphs (DAGs), provide a means to unambiguously specify assumptions regarding the causal structure underlying a phenomenon. Unlike DAGs, which make very few assumptions about the functional and parametric form, SEM assumes linearity. This can result in functional misspecification which prevents researchers from undertaking reliable effect size estimation. In contrast, we propose Super Learner Equation Modeling, a path modeling technique integrating machine learning Super Learner ensembles. We empirically demonstrate its ability to provide consistent and unbiased estimates of causal effects, its competitive performance for linear models when compared with SEM, and highlight its superiority over SEM when dealing with non
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#24322;&#26500;&#29305;&#24449;&#38598;&#25104;&#65292;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#24615;&#22238;&#24402;&#35774;&#32622;&#20013;&#26500;&#24314;&#30340;&#23725;&#22238;&#24402;&#38598;&#25104;&#30340;&#23398;&#20064;&#26354;&#32447;&#65292;&#32467;&#26524;&#34920;&#26126;&#24322;&#26500;&#29305;&#24449;&#38598;&#25104;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.03176</link><description>&lt;p&gt;
&#24322;&#26500;&#29305;&#24449;&#23376;&#37319;&#26679;&#30340;Ridge Ensemble&#30340;&#23398;&#20064;&#26354;&#32447;
&lt;/p&gt;
&lt;p&gt;
Learning Curves for Heterogeneous Feature-Subsampled Ridge Ensembles. (arXiv:2307.03176v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03176
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#24322;&#26500;&#29305;&#24449;&#38598;&#25104;&#65292;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#24615;&#22238;&#24402;&#35774;&#32622;&#20013;&#26500;&#24314;&#30340;&#23725;&#22238;&#24402;&#38598;&#25104;&#30340;&#23398;&#20064;&#26354;&#32447;&#65292;&#32467;&#26524;&#34920;&#26126;&#24322;&#26500;&#29305;&#24449;&#38598;&#25104;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29305;&#24449;&#21253;&#35013;&#26159;&#19968;&#31181;&#26088;&#22312;&#36890;&#36807;&#22312;&#38543;&#26426;&#23376;&#26679;&#26412;&#25110;&#29305;&#24449;&#25237;&#24433;&#19978;&#35757;&#32451;&#20272;&#35745;&#22120;&#26469;&#20943;&#23569;&#39044;&#27979;&#26041;&#24046;&#30340;&#25104;&#29087;&#38598;&#25104;&#26041;&#27861;&#12290;&#36890;&#24120;&#65292;&#38598;&#25104;&#36873;&#25321;&#26159;&#21516;&#36136;&#30340;&#65292;&#21363;&#20272;&#35745;&#22120;&#21487;&#29992;&#30340;&#29305;&#24449;&#32500;&#25968;&#22312;&#25972;&#20010;&#38598;&#25104;&#20013;&#26159;&#22343;&#21248;&#30340;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#24322;&#26500;&#29305;&#24449;&#38598;&#25104;&#26041;&#27861;&#65292;&#20854;&#20013;&#30340;&#20272;&#35745;&#22120;&#22522;&#20110;&#21464;&#21160;&#30340;&#29305;&#24449;&#32500;&#25968;&#65292;&#24182;&#30740;&#31350;&#20854;&#22312;&#32447;&#24615;&#22238;&#24402;&#35774;&#32622;&#20013;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#32447;&#24615;&#39044;&#27979;&#22120;&#30340;&#38598;&#25104;&#65292;&#27599;&#20010;&#39044;&#27979;&#22120;&#20351;&#29992;&#37096;&#20998;&#21487;&#29992;&#29305;&#24449;&#36827;&#34892;&#23725;&#22238;&#24402;&#25311;&#21512;&#12290;&#25105;&#20204;&#20801;&#35768;&#36825;&#20123;&#23376;&#38598;&#20013;&#21253;&#21547;&#30340;&#29305;&#24449;&#25968;&#37327;&#26377;&#25152;&#21464;&#21270;&#12290;&#21033;&#29992;&#32479;&#35745;&#29289;&#29702;&#20013;&#30340;&#22797;&#21046;&#25216;&#24039;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#20855;&#26377;&#30830;&#23450;&#24615;&#32447;&#24615;&#25513;&#27169;&#30340;&#23725;&#22238;&#24402;&#38598;&#25104;&#30340;&#23398;&#20064;&#26354;&#32447;&#12290;&#23545;&#20110;&#20855;&#26377;&#21508;&#21521;&#21516;&#24615;&#29305;&#24449;&#22122;&#22768;&#30340;&#31561;&#30456;&#30456;&#20851;&#25968;&#25454;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#23398;&#20064;&#26354;&#32447;&#30340;&#26174;&#24335;&#34920;&#36798;&#24335;&#12290;&#21033;&#29992;&#36825;&#20123;&#25512;&#23548;&#34920;&#36798;&#24335;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#38598;&#25104;&#22312;&#19981;&#21516;&#29305;&#24449;&#32500;&#25968;&#19979;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Feature bagging is a well-established ensembling method which aims to reduce prediction variance by training estimators in an ensemble on random subsamples or projections of features. Typically, ensembles are chosen to be homogeneous, in the sense the the number of feature dimensions available to an estimator is uniform across the ensemble. Here, we introduce heterogeneous feature ensembling, with estimators built on varying number of feature dimensions, and consider its performance in a linear regression setting. We study an ensemble of linear predictors, each fit using ridge regression on a subset of the available features. We allow the number of features included in these subsets to vary. Using the replica trick from statistical physics, we derive learning curves for ridge ensembles with deterministic linear masks. We obtain explicit expressions for the learning curves in the case of equicorrelated data with an isotropic feature noise. Using the derived expressions, we investigate t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#32452;&#21512;&#24615;&#25968;&#25454;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#23545;&#38543;&#26426;&#23618;&#27425;&#27169;&#22411;&#36827;&#34892;&#20998;&#31867;&#20219;&#21153;&#65292;&#21457;&#29616;&#28145;&#24230;CNN&#23398;&#20064;&#36825;&#20010;&#20219;&#21153;&#25152;&#38656;&#30340;&#35757;&#32451;&#25968;&#25454;&#25968;&#37327;&#38543;&#30528;&#31867;&#21035;&#25968;&#12289;&#32452;&#21512;&#25968;&#21644;&#36845;&#20195;&#27425;&#25968;&#30340;&#22686;&#21152;&#32780;&#28176;&#36827;&#22686;&#21152;&#12290;</title><link>http://arxiv.org/abs/2307.02129</link><description>&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22914;&#20309;&#23398;&#20064;&#32452;&#21512;&#24615;&#25968;&#25454;&#65306;&#38543;&#26426;&#23618;&#27425;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
How Deep Neural Networks Learn Compositional Data: The Random Hierarchy Model. (arXiv:2307.02129v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02129
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#32452;&#21512;&#24615;&#25968;&#25454;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#23545;&#38543;&#26426;&#23618;&#27425;&#27169;&#22411;&#36827;&#34892;&#20998;&#31867;&#20219;&#21153;&#65292;&#21457;&#29616;&#28145;&#24230;CNN&#23398;&#20064;&#36825;&#20010;&#20219;&#21153;&#25152;&#38656;&#30340;&#35757;&#32451;&#25968;&#25454;&#25968;&#37327;&#38543;&#30528;&#31867;&#21035;&#25968;&#12289;&#32452;&#21512;&#25968;&#21644;&#36845;&#20195;&#27425;&#25968;&#30340;&#22686;&#21152;&#32780;&#28176;&#36827;&#22686;&#21152;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#19968;&#33324;&#39640;&#32500;&#20219;&#21153;&#26159;&#38750;&#24120;&#22256;&#38590;&#30340;&#65292;&#22240;&#20026;&#23427;&#38656;&#35201;&#19982;&#32500;&#24230;&#25104;&#25351;&#25968;&#22686;&#38271;&#30340;&#35757;&#32451;&#25968;&#25454;&#25968;&#37327;&#12290;&#28982;&#32780;&#65292;&#28145;&#24230;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#22312;&#20811;&#26381;&#36825;&#19968;&#25361;&#25112;&#26041;&#38754;&#26174;&#31034;&#20986;&#20102;&#21331;&#36234;&#30340;&#25104;&#21151;&#12290;&#19968;&#31181;&#26222;&#36941;&#30340;&#20551;&#35774;&#26159;&#21487;&#23398;&#20064;&#20219;&#21153;&#20855;&#26377;&#39640;&#24230;&#32467;&#26500;&#21270;&#65292;CNN&#21033;&#29992;&#36825;&#31181;&#32467;&#26500;&#24314;&#31435;&#20102;&#25968;&#25454;&#30340;&#20302;&#32500;&#34920;&#31034;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#23545;&#23427;&#20204;&#38656;&#35201;&#22810;&#23569;&#35757;&#32451;&#25968;&#25454;&#20197;&#21450;&#36825;&#20010;&#25968;&#23383;&#22914;&#20309;&#21462;&#20915;&#20110;&#25968;&#25454;&#32467;&#26500;&#30693;&#20043;&#29978;&#23569;&#12290;&#26412;&#25991;&#22238;&#31572;&#20102;&#38024;&#23545;&#19968;&#20010;&#31616;&#21333;&#30340;&#20998;&#31867;&#20219;&#21153;&#30340;&#36825;&#20010;&#38382;&#39064;&#65292;&#35813;&#20219;&#21153;&#26088;&#22312;&#25429;&#25417;&#30495;&#23454;&#25968;&#25454;&#30340;&#30456;&#20851;&#26041;&#38754;&#65306;&#38543;&#26426;&#23618;&#27425;&#27169;&#22411;&#12290;&#22312;&#36825;&#20010;&#27169;&#22411;&#20013;&#65292;$n_c$&#20010;&#31867;&#21035;&#20013;&#30340;&#27599;&#19968;&#20010;&#23545;&#24212;&#20110;$m$&#20010;&#21516;&#20041;&#32452;&#21512;&#30340;&#39640;&#23618;&#27425;&#29305;&#24449;&#65292;&#24182;&#19988;&#36825;&#20123;&#29305;&#24449;&#21448;&#36890;&#36807;&#19968;&#20010;&#37325;&#22797;$L$&#27425;&#30340;&#36845;&#20195;&#36807;&#31243;&#30001;&#23376;&#29305;&#24449;&#32452;&#25104;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#38656;&#35201;&#28145;&#24230;CNN&#23398;&#20064;&#36825;&#20010;&#20219;&#21153;&#30340;&#35757;&#32451;&#25968;&#25454;&#25968;&#37327;$P^*$&#65288;i&#65289;&#38543;&#30528;$n_c m^L$&#30340;&#22686;&#38271;&#32780;&#28176;&#36827;&#22320;&#22686;&#38271;&#65292;&#36825;&#21482;&#26377;...
&lt;/p&gt;
&lt;p&gt;
Learning generic high-dimensional tasks is notably hard, as it requires a number of training data exponential in the dimension. Yet, deep convolutional neural networks (CNNs) have shown remarkable success in overcoming this challenge. A popular hypothesis is that learnable tasks are highly structured and that CNNs leverage this structure to build a low-dimensional representation of the data. However, little is known about how much training data they require, and how this number depends on the data structure. This paper answers this question for a simple classification task that seeks to capture relevant aspects of real data: the Random Hierarchy Model. In this model, each of the $n_c$ classes corresponds to $m$ synonymic compositions of high-level features, which are in turn composed of sub-features through an iterative process repeated $L$ times. We find that the number of training data $P^*$ required by deep CNNs to learn this task (i) grows asymptotically as $n_c m^L$, which is only
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;$K$&#26368;&#36817;&#37051;&#37325;&#37319;&#26679;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#31639;&#21382;&#21490;&#25968;&#25454;&#20013;&#30001;&#19981;&#21516;&#31574;&#30053;&#29983;&#25104;&#30340;&#20915;&#31574;&#36807;&#31243;&#30340;&#24615;&#33021;&#65292;&#35299;&#20915;&#20102;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#20013;&#30340;&#21453;&#20107;&#23454;&#20272;&#35745;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.04836</link><description>&lt;p&gt;
$K$&#26368;&#36817;&#37051;&#37325;&#37319;&#26679;&#29992;&#20110;&#38543;&#26426;&#25511;&#21046;&#20013;&#30340;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
$K$-Nearest-Neighbor Resampling for Off-Policy Evaluation in Stochastic Control. (arXiv:2306.04836v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04836
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;$K$&#26368;&#36817;&#37051;&#37325;&#37319;&#26679;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#31639;&#21382;&#21490;&#25968;&#25454;&#20013;&#30001;&#19981;&#21516;&#31574;&#30053;&#29983;&#25104;&#30340;&#20915;&#31574;&#36807;&#31243;&#30340;&#24615;&#33021;&#65292;&#35299;&#20915;&#20102;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#20013;&#30340;&#21453;&#20107;&#23454;&#20272;&#35745;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;$K$&#26368;&#36817;&#37051;&#37325;&#37319;&#26679;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#31639;&#21382;&#21490;&#25968;&#25454;&#20013;&#30001;&#19981;&#21516;&#31574;&#30053;&#29983;&#25104;&#30340;&#20915;&#31574;&#36807;&#31243;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#20381;&#36182;&#20110;&#24403;&#21069;&#29366;&#24577;&#30340;&#21453;&#39304;&#31574;&#30053;&#65292;&#36825;&#31181;&#31574;&#30053;&#36866;&#29992;&#20110;&#20855;&#26377;&#36830;&#32493;&#29366;&#24577;-&#21160;&#20316;&#31354;&#38388;&#21644;&#25152;&#36873;&#21160;&#20316;&#24433;&#21709;&#19979;&#30340;&#31995;&#32479;&#22266;&#26377;&#38543;&#26426;&#24615;&#30340;&#29615;&#22659;&#12290;&#36825;&#20123;&#35774;&#32622;&#22312;&#35768;&#22810;&#39640;&#39118;&#38505;&#24212;&#29992;&#31243;&#24207;&#20013;&#24456;&#24120;&#35265;&#65292;&#24182;&#22312;&#38543;&#26426;&#25511;&#21046;&#30340;&#19978;&#19979;&#25991;&#20013;&#31215;&#26497;&#30740;&#31350;&#12290;&#25105;&#20204;&#30340;&#36807;&#31243;&#21033;&#29992;&#20102;&#31867;&#20284;&#30340;&#29366;&#24577;/&#21160;&#20316;&#23545;&#65288;&#22312;&#24230;&#37327;&#24847;&#20041;&#19979;&#65289;&#19982;&#31867;&#20284;&#30340;&#22870;&#21169;&#21644;&#29366;&#24577;&#36716;&#25442;&#30456;&#20851;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#30340;&#37325;&#37319;&#26679;&#36807;&#31243;&#36890;&#36807;&#31867;&#20284;&#20110;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#30340;&#36712;&#36857;&#27169;&#25311;&#26469;&#35299;&#20915;&#31163;&#32447;&#31574;&#30053;&#35780;&#20272;&#65288;OPE&#65289;&#20013;&#30340;&#21453;&#20107;&#23454;&#20272;&#35745;&#38382;&#39064;&#12290;&#19982;&#20854;&#20182;OPE&#26041;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#19981;&#38656;&#35201;&#20248;&#21270;&#65292;&#21487;&#20197;&#36890;&#36807;&#22522;&#20110;&#26641;&#30340;&#26368;&#36817;&#37051;&#25628;&#32034;&#39640;&#25928;&#23454;&#29616;&#65292;&#24182;&#19988;&#26412;&#36136;&#19978;&#26159;&#21487;&#24182;&#34892;&#21270;&#30340;&#12290;&#25105;&#20204;&#25552;&#20379;&#29702;&#35770;&#24615;&#33021;&#20445;&#35777;&#65292;&#24182;&#22312;&#22522;&#20934;&#29615;&#22659;&#19979;&#23637;&#31034;&#20102;&#25105;&#20204;&#31639;&#27861;&#30340;&#20248;&#36234;&#23454;&#39564;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel $K$-nearest neighbor resampling procedure for estimating the performance of a policy from historical data containing realized episodes of a decision process generated under a different policy. We focus on feedback policies that depend deterministically on the current state in environments with continuous state-action spaces and system-inherent stochasticity effected by chosen actions. Such settings are common in a wide range of high-stake applications and are actively investigated in the context of stochastic control. Our procedure exploits that similar state/action pairs (in a metric sense) are associated with similar rewards and state transitions. This enables our resampling procedure to tackle the counterfactual estimation problem underlying off-policy evaluation (OPE) by simulating trajectories similarly to Monte Carlo methods. Compared to other OPE methods, our algorithm does not require optimization, can be efficiently implemented via tree-based nearest neighbo
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#35777;&#25454;&#32593;&#32476;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#22788;&#29702;&#20284;&#28982;&#20989;&#25968;&#25110;&#20808;&#39564;&#20989;&#25968;&#19982;&#23884;&#22871;&#25277;&#26679;&#26080;&#27861;&#32988;&#20219;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#36125;&#21494;&#26031;&#27169;&#22411;&#27604;&#36739;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#19981;&#21516;&#30340;&#26159;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#20102;&#26032;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#26356;&#24555;&#36895;&#22320;&#12289;&#26356;&#26377;&#25928;&#22320;&#20272;&#31639;&#36125;&#21494;&#26031;&#22240;&#23376;&#12290;</title><link>http://arxiv.org/abs/2305.11241</link><description>&lt;p&gt;
&#35777;&#25454;&#32593;&#32476;&#65306;&#29992;&#31616;&#21333;&#30340;&#25439;&#22833;&#20989;&#25968;&#24555;&#36895;&#12289;&#20998;&#25674;&#24335;&#22320;&#36827;&#34892;&#31070;&#32463;&#36125;&#21494;&#26031;&#27169;&#22411;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
Evidence Networks: simple losses for fast, amortized, neural Bayesian model comparison. (arXiv:2305.11241v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11241
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#35777;&#25454;&#32593;&#32476;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#22788;&#29702;&#20284;&#28982;&#20989;&#25968;&#25110;&#20808;&#39564;&#20989;&#25968;&#19982;&#23884;&#22871;&#25277;&#26679;&#26080;&#27861;&#32988;&#20219;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#36125;&#21494;&#26031;&#27169;&#22411;&#27604;&#36739;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#19981;&#21516;&#30340;&#26159;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#20102;&#26032;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#26356;&#24555;&#36895;&#22320;&#12289;&#26356;&#26377;&#25928;&#22320;&#20272;&#31639;&#36125;&#21494;&#26031;&#22240;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35777;&#25454;&#32593;&#32476;&#21487;&#22312;&#24403;&#29616;&#26377;&#30340;&#26041;&#27861;&#65288;&#22914;&#23884;&#22871;&#25277;&#26679;&#65289;&#22833;&#36133;&#12289;&#20284;&#28982;&#20989;&#25968;&#25110;&#20808;&#39564;&#20989;&#25968;&#38590;&#20197;&#22788;&#29702;&#25110;&#19981;&#30693;&#36947;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#36125;&#21494;&#26031;&#27169;&#22411;&#27604;&#36739;&#12290;&#36125;&#21494;&#26031;&#27169;&#22411;&#27604;&#36739;&#21487;&#30475;&#20316;&#19968;&#20010;&#20248;&#21270;&#38382;&#39064;&#12290;&#34429;&#28982;&#29992;&#36125;&#21494;&#26031;&#27861;&#36827;&#34892;&#26368;&#20248;&#20998;&#31867;&#30340;&#35299;&#37322;&#24050;&#32463;&#20247;&#25152;&#21608;&#30693;&#65292;&#20294;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25913;&#21464;&#20102;&#35270;&#35282;&#65292;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#25439;&#22833;&#20989;&#25968;&#65292;&#20197;&#20135;&#29983;&#24555;&#36895;&#12289;&#20998;&#25674;&#24335;&#30340;&#31070;&#32463;&#20272;&#35745;&#22120;&#65292;&#30452;&#25509;&#20272;&#31639;&#26041;&#20415;&#30340;&#36125;&#21494;&#26031;&#22240;&#23376;&#30340;&#20989;&#25968;&#12290;&#36825;&#20943;&#23569;&#20102;&#20272;&#31639;&#21333;&#20010;&#27169;&#22411;&#27010;&#29575;&#26102;&#30340;&#25968;&#23383;&#19981;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#28183;&#28431;&#22855; parity-odd power&#65288;l-POP&#65289;&#21464;&#25442;&#65292;&#24341;&#23548;&#20102;&#26032;&#30340;&#8220;l-Pop-Exponential&#8221;&#30340;&#25439;&#22833;&#20989;&#25968;&#12290;&#25105;&#20204;&#25506;&#35752;&#20102;&#22312;&#19981;&#21516;&#27169;&#22411;&#20013;&#23545;&#25968;&#25454;&#27010;&#29575;&#36827;&#34892;&#31070;&#32463;&#23494;&#24230;&#20272;&#35745;&#65292;&#32467;&#26524;&#34920;&#26126;&#36825;&#31181;&#26041;&#27861;&#27604;&#35777;&#25454;&#32593;&#32476;&#30340;&#31934;&#24230;&#21644;&#21487;&#25193;&#23637;&#24615;&#37117;&#35201;&#20302;&#12290;&#22810;&#31181;&#23454;&#38469;&#21644;&#20154;&#36896;&#20363;&#23376;&#35777;&#26126;&#20102;&#35777;&#25454;&#32593;&#32476;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Evidence Networks can enable Bayesian model comparison when state-of-the-art methods (e.g. nested sampling) fail and even when likelihoods or priors are intractable or unknown. Bayesian model comparison, i.e. the computation of Bayes factors or evidence ratios, can be cast as an optimization problem. Though the Bayesian interpretation of optimal classification is well-known, here we change perspective and present classes of loss functions that result in fast, amortized neural estimators that directly estimate convenient functions of the Bayes factor. This mitigates numerical inaccuracies associated with estimating individual model probabilities. We introduce the leaky parity-odd power (l-POP) transform, leading to the novel ``l-POP-Exponential'' loss function. We explore neural density estimation for data probability in different models, showing it to be less accurate and scalable than Evidence Networks. Multiple real-world and synthetic examples illustrate that Evidence Networks are e
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#20351;&#29992;&#38543;&#26426;Lp&#33539;&#25968;&#22833;&#30495;&#23545;&#22270;&#20687;&#20998;&#31867;&#22120;&#30340;&#35757;&#32451;&#21644;&#27979;&#35797;&#25968;&#25454;&#36827;&#34892;&#22686;&#24378;&#65292;&#24182;&#35780;&#20272;&#27169;&#22411;&#23545;&#19981;&#21487;&#24863;&#30693;&#38543;&#26426;&#22833;&#30495;&#30340;&#31283;&#20581;&#24615;&#65292;&#21457;&#29616;&#31283;&#20581;&#24615;&#21487;&#33021;&#20250;&#25552;&#39640;&#27169;&#22411;&#22312;&#38543;&#26426;&#22833;&#30495;&#26041;&#38754;&#30340;&#24615;&#33021;&#65292;&#20294;&#20063;&#21487;&#33021;&#20250;&#25439;&#23475;L&#8734;&#33539;&#25968;&#30340;&#31283;&#20581;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.05400</link><description>&lt;p&gt;
&#20351;&#29992;&#38543;&#26426;Lp&#33539;&#25968;&#22833;&#30495;&#25506;&#31350;&#22270;&#20687;&#20998;&#31867;&#22120;&#30340;&#33104;&#36133;&#31283;&#20581;&#24615;
&lt;/p&gt;
&lt;p&gt;
Investigating the Corruption Robustness of Image Classifiers with Random Lp-norm Corruptions. (arXiv:2305.05400v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05400
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#20351;&#29992;&#38543;&#26426;Lp&#33539;&#25968;&#22833;&#30495;&#23545;&#22270;&#20687;&#20998;&#31867;&#22120;&#30340;&#35757;&#32451;&#21644;&#27979;&#35797;&#25968;&#25454;&#36827;&#34892;&#22686;&#24378;&#65292;&#24182;&#35780;&#20272;&#27169;&#22411;&#23545;&#19981;&#21487;&#24863;&#30693;&#38543;&#26426;&#22833;&#30495;&#30340;&#31283;&#20581;&#24615;&#65292;&#21457;&#29616;&#31283;&#20581;&#24615;&#21487;&#33021;&#20250;&#25552;&#39640;&#27169;&#22411;&#22312;&#38543;&#26426;&#22833;&#30495;&#26041;&#38754;&#30340;&#24615;&#33021;&#65292;&#20294;&#20063;&#21487;&#33021;&#20250;&#25439;&#23475;L&#8734;&#33539;&#25968;&#30340;&#31283;&#20581;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31283;&#20581;&#24615;&#26159;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#22120;&#23454;&#29616;&#23433;&#20840;&#21644;&#21487;&#38752;&#30340;&#22522;&#26412;&#23646;&#24615;&#12290;&#22312;&#23545;&#22270;&#20687;&#20998;&#31867;&#27169;&#22411;&#30340;&#23545;&#25239;&#31283;&#20581;&#24615;&#21644;&#24418;&#24335;&#31283;&#20581;&#24615;&#39564;&#35777;&#39046;&#22495;&#20013;&#65292;&#31283;&#20581;&#24615;&#36890;&#24120;&#34987;&#23450;&#20041;&#20026;&#22312;Lp&#33539;&#25968;&#36317;&#31163;&#20869;&#23545;&#25152;&#26377;&#36755;&#20837;&#21464;&#21270;&#30340;&#31283;&#23450;&#24615;&#12290;&#28982;&#32780;&#65292;&#23545;&#38543;&#26426;&#22833;&#30495;&#30340;&#31283;&#20581;&#24615;&#36890;&#24120;&#36890;&#36807;&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#35266;&#23519;&#21040;&#30340;&#21464;&#21270;&#26469;&#25913;&#36827;&#21644;&#35780;&#20272;&#65292;&#32780;&#24456;&#23569;&#32771;&#34385;&#25968;&#23398;&#23450;&#20041;&#30340;Lp&#33539;&#25968;&#22833;&#30495;&#12290;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#20351;&#29992;&#38543;&#26426;Lp&#33539;&#25968;&#22833;&#30495;&#26469;&#22686;&#24378;&#22270;&#20687;&#20998;&#31867;&#22120;&#30340;&#35757;&#32451;&#21644;&#27979;&#35797;&#25968;&#25454;&#12290;&#25105;&#20204;&#20511;&#37492;&#20102;&#23545;&#25239;&#31283;&#20581;&#24615;&#39046;&#22495;&#30340;&#26041;&#27861;&#26469;&#35780;&#20272;&#27169;&#22411;&#23545;&#19981;&#21487;&#24863;&#30693;&#38543;&#26426;&#22833;&#30495;&#30340;&#31283;&#20581;&#24615;&#12290;&#25105;&#20204;&#23454;&#35777;&#21644;&#29702;&#35770;&#19978;&#30740;&#31350;&#20102;&#22312;&#19981;&#21516;Lp&#33539;&#25968;&#20043;&#38388;&#31283;&#20581;&#24615;&#26159;&#21542;&#21487;&#36716;&#31227;&#65292;&#24182;&#24471;&#20986;&#32467;&#35770;&#65292;&#21738;&#20123;Lp&#33539;&#25968;&#30340;&#22833;&#30495;&#24212;&#35813;&#29992;&#26469;&#35757;&#32451;&#21644;&#35780;&#20272;&#27169;&#22411;&#12290;&#25105;&#20204;&#21457;&#29616;&#35757;&#32451;&#25968;&#25454;&#22686;&#24378;&#21487;&#33021;&#20250;&#25552;&#39640;&#27169;&#22411;&#22312;&#38543;&#26426;&#22833;&#30495;&#26041;&#38754;&#30340;&#24615;&#33021;&#65292;&#20294;&#20063;&#21487;&#33021;&#20250;&#25439;&#23475;L&#8734;&#33539;&#25968;&#30340;&#31283;&#20581;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Robustness is a fundamental property of machine learning classifiers to achieve safety and reliability. In the fields of adversarial robustness and formal robustness verification of image classification models, robustness is commonly defined as the stability to all input variations within an Lp-norm distance. However, robustness to random corruptions is usually improved and evaluated using variations observed in the real-world, while mathematically defined Lp-norm corruptions are rarely considered. This study investigates the use of random Lp-norm corruptions to augment the training and test data of image classifiers. We adapt an approach from the field of adversarial robustness to assess the model robustness to imperceptible random corruptions. We empirically and theoretically investigate whether robustness is transferable across different Lp-norms and derive conclusions on which Lp-norm corruptions a model should be trained and evaluated on. We find that training data augmentation wi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#38750;&#32447;&#24615;Ridge Bandits&#20013;&#29420;&#29305;&#30340;&#23398;&#20064;&#29616;&#35937;&#65292;&#25512;&#23548;&#20986;&#20102;&#26368;&#20248;&#28903;&#24405;&#25104;&#26412;&#30340;&#19978;&#19979;&#38480;&#21644;&#25972;&#20010;&#28903;&#24405;&#26399;&#38388;&#30340;&#23398;&#20064;&#36712;&#36857;&#30340;&#32479;&#35745;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;UCB&#21644;&#22522;&#20110;&#22238;&#24402;&#31070;&#32463;&#20803;&#30340;&#31639;&#27861;&#37117;&#26159;&#27425;&#20248;&#35299;&#12290;</title><link>http://arxiv.org/abs/2302.06025</link><description>&lt;p&gt;
&#38750;&#32447;&#24615;Ridge Bandits&#30340;&#32479;&#35745;&#22797;&#26434;&#24230;&#21644;&#26368;&#20248;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Statistical Complexity and Optimal Algorithms for Non-linear Ridge Bandits. (arXiv:2302.06025v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.06025
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#38750;&#32447;&#24615;Ridge Bandits&#20013;&#29420;&#29305;&#30340;&#23398;&#20064;&#29616;&#35937;&#65292;&#25512;&#23548;&#20986;&#20102;&#26368;&#20248;&#28903;&#24405;&#25104;&#26412;&#30340;&#19978;&#19979;&#38480;&#21644;&#25972;&#20010;&#28903;&#24405;&#26399;&#38388;&#30340;&#23398;&#20064;&#36712;&#36857;&#30340;&#32479;&#35745;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;UCB&#21644;&#22522;&#20110;&#22238;&#24402;&#31070;&#32463;&#20803;&#30340;&#31639;&#27861;&#37117;&#26159;&#27425;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#31181;&#39034;&#24207;&#20915;&#31574;&#38382;&#39064;&#65292;&#20854;&#20013;&#24179;&#22343;&#32467;&#26524;&#26159;&#25152;&#36873;&#25321;&#21160;&#20316;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#12290;&#19982;&#32447;&#24615;&#27169;&#22411;&#30456;&#27604;&#65292;&#38750;&#32447;&#24615;&#27169;&#22411;&#26377;&#20004;&#31181;&#22855;&#29305;&#29616;&#35937;&#65306;&#39318;&#20808;&#65292;&#38500;&#20102;&#20855;&#26377;&#26631;&#20934;&#21442;&#25968;&#29575;&#30340;&#8220;&#23398;&#20064;&#38454;&#27573;&#8221;&#20197;&#36827;&#34892;&#20272;&#35745;&#25110;&#21518;&#24724;&#22806;&#65292;&#36824;&#26377;&#19968;&#20010;&#30001;&#38750;&#32447;&#24615;&#20989;&#25968;&#30830;&#23450;&#30340;&#22266;&#23450;&#25104;&#26412;&#30340;&#8220;&#28903;&#24405;&#26399;&#8221;; &#20854;&#27425;&#65292;&#23454;&#29616;&#26368;&#23567;&#28903;&#24405;&#25104;&#26412;&#38656;&#35201;&#26032;&#30340;&#25506;&#32034;&#31639;&#27861;&#12290;&#38024;&#23545;&#19968;&#31867;&#21517;&#20026;ridge&#20989;&#25968;&#30340;&#29305;&#27530;&#38750;&#32447;&#24615;&#20989;&#25968;&#65292;&#25105;&#20204;&#36890;&#36807;&#24494;&#20998;&#26041;&#31243;&#25512;&#23548;&#20102;&#26368;&#20248;&#28903;&#24405;&#25104;&#26412;&#30340;&#19978;&#19979;&#38480;&#65292;&#27492;&#22806;&#36824;&#25512;&#23548;&#20102;&#25972;&#20010;&#28903;&#24405;&#26399;&#38388;&#30340;&#23398;&#20064;&#36712;&#36857;&#30340;&#19978;&#19979;&#38480;&#12290;&#29305;&#21035;&#22320;&#65292;&#19968;&#31181;&#20004;&#38454;&#27573;&#31639;&#27861;&#20808;&#25214;&#21040;&#19968;&#20010;&#22909;&#30340;&#21021;&#22987;&#34892;&#21160;&#65292;&#28982;&#21518;&#23558;&#38382;&#39064;&#35270;&#20026;&#23616;&#37096;&#32447;&#24615;&#65292;&#36825;&#26159;&#32479;&#35745;&#19978;&#26368;&#20248;&#30340;&#12290;&#30456;&#21453;&#65292;&#20960;&#31181;&#32463;&#20856;&#31639;&#27861;&#65292;&#20363;&#22914;UCB&#21644;&#20381;&#36182;&#20110;&#22238;&#24402;&#31070;&#32463;&#20803;&#30340;&#31639;&#27861;&#65292;&#20854;&#21487;&#35777;&#26126;&#26159;&#27425;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the sequential decision-making problem where the mean outcome is a non-linear function of the chosen action. Compared with the linear model, two curious phenomena arise in non-linear models: first, in addition to the "learning phase" with a standard parametric rate for estimation or regret, there is an "burn-in period" with a fixed cost determined by the non-linear function; second, achieving the smallest burn-in cost requires new exploration algorithms. For a special family of non-linear functions named ridge functions in the literature, we derive upper and lower bounds on the optimal burn-in cost, and in addition, on the entire learning trajectory during the burn-in period via differential equations. In particular, a two-stage algorithm that first finds a good initial action and then treats the problem as locally linear is statistically optimal. In contrast, several classical algorithms, such as UCB and algorithms relying on regression oracles, are provably suboptimal.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21457;&#29616;&#22312;&#39640;&#23481;&#37327;&#30340;&#31070;&#32463;&#32593;&#32476;&#38598;&#25104;&#20013;&#65292;&#40723;&#21169;&#39044;&#27979;&#22810;&#26679;&#24615;&#24182;&#19981;&#24635;&#26159;&#26377;&#25928;&#30340;&#65292;&#29978;&#33267;&#21453;&#32780;&#20250;&#25439;&#23475;&#24615;&#33021;&#12290;&#30456;&#21453;&#22320;&#65292;&#38459;&#27490;&#39044;&#27979;&#22810;&#26679;&#24615;&#24448;&#24448;&#26159;&#26080;&#23475;&#30340;&#65292;&#36825;&#19982;&#20808;&#21069;&#30340;&#30452;&#35273;&#30456;&#21453;&#12290;</title><link>http://arxiv.org/abs/2302.00704</link><description>&lt;p&gt;
&#28145;&#24230;&#38598;&#25104;&#20013;&#30340;&#39044;&#27979;&#22810;&#26679;&#24615;&#30149;&#24577;
&lt;/p&gt;
&lt;p&gt;
Pathologies of Predictive Diversity in Deep Ensembles. (arXiv:2302.00704v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.00704
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21457;&#29616;&#22312;&#39640;&#23481;&#37327;&#30340;&#31070;&#32463;&#32593;&#32476;&#38598;&#25104;&#20013;&#65292;&#40723;&#21169;&#39044;&#27979;&#22810;&#26679;&#24615;&#24182;&#19981;&#24635;&#26159;&#26377;&#25928;&#30340;&#65292;&#29978;&#33267;&#21453;&#32780;&#20250;&#25439;&#23475;&#24615;&#33021;&#12290;&#30456;&#21453;&#22320;&#65292;&#38459;&#27490;&#39044;&#27979;&#22810;&#26679;&#24615;&#24448;&#24448;&#26159;&#26080;&#23475;&#30340;&#65292;&#36825;&#19982;&#20808;&#21069;&#30340;&#30452;&#35273;&#30456;&#21453;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#40723;&#21169;&#39044;&#27979;&#22810;&#26679;&#24615;&#21487;&#20197;&#25552;&#39640;&#20302;&#23481;&#37327;&#27169;&#22411;&#30340;&#38598;&#25104;&#24615;&#33021;&#65292;&#20363;&#22914;&#36890;&#36807;Bagging&#25110;Boosting&#12290;&#28982;&#32780;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#36825;&#20123;&#30452;&#35273;&#22312;&#39640;&#23481;&#37327;&#30340;&#31070;&#32463;&#32593;&#32476;&#38598;&#25104;&#65288;&#28145;&#24230;&#38598;&#25104;&#65289;&#20013;&#24182;&#19981;&#36866;&#29992;&#65292;&#20107;&#23454;&#19978;&#65292;&#24448;&#24448;&#30456;&#21453;&#12290;&#36890;&#36807;&#23545;&#36817;600&#20010;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#38598;&#25104;&#30340;&#22823;&#35268;&#27169;&#30740;&#31350;&#65292;&#25105;&#20204;&#32771;&#23519;&#20102;&#19968;&#31995;&#21015;&#24179;&#34913;&#32452;&#20214;&#27169;&#22411;&#24615;&#33021;&#19982;&#39044;&#27979;&#22810;&#26679;&#24615;&#20043;&#38388;&#20851;&#31995;&#30340;&#24178;&#39044;&#25514;&#26045;&#12290;&#34429;&#28982;&#36825;&#26679;&#30340;&#24178;&#39044;&#25514;&#26045;&#21487;&#20197;&#25913;&#21892;&#23567;&#35268;&#27169;&#31070;&#32463;&#32593;&#32476;&#38598;&#25104;&#30340;&#24615;&#33021;&#65288;&#31526;&#21512;&#26631;&#20934;&#30452;&#35273;&#65289;&#65292;&#20294;&#23427;&#20204;&#21364;&#20250;&#25439;&#23475;&#22312;&#23454;&#36341;&#20013;&#26368;&#24120;&#29992;&#30340;&#22823;&#35268;&#27169;&#31070;&#32463;&#32593;&#32476;&#38598;&#25104;&#30340;&#24615;&#33021;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#22312;&#22823;&#22411;&#32593;&#32476;&#38598;&#25104;&#20013;&#65292;&#38459;&#27490;&#39044;&#27979;&#22810;&#26679;&#24615;&#24448;&#24448;&#26159;&#26080;&#23475;&#30340;&#65292;&#23436;&#20840;&#39072;&#35206;&#20102;&#26631;&#20934;&#30340;&#30452;&#35273;&#12290;&#21363;&#20351;&#22810;&#26679;&#24615;&#20419;&#36827;&#30340;&#24178;&#39044;&#25514;&#26045;&#19981;&#29306;&#29298;&#32452;&#20214;&#27169;&#22411;&#30340;&#24615;&#33021;&#65288;&#20363;&#22914;&#20351;&#29992;&#24322;&#26500;&#26550;&#26500;&#21644;&#35757;&#32451;&#31574;&#30053;&#65289;...
&lt;/p&gt;
&lt;p&gt;
Classic results establish that encouraging predictive diversity improves performance in ensembles of low-capacity models, e.g. through bagging or boosting. Here we demonstrate that these intuitions do not apply to high-capacity neural network ensembles (deep ensembles), and in fact the opposite is often true. In a large scale study of nearly 600 neural network classification ensembles, we examine a variety of interventions that trade off component model performance for predictive diversity. While such interventions can improve the performance of small neural network ensembles (in line with standard intuitions), they harm the performance of the large neural network ensembles most often used in practice. Surprisingly, we also find that discouraging predictive diversity is often benign in large-network ensembles, fully inverting standard intuitions. Even when diversity-promoting interventions do not sacrifice component model performance (e.g. using heterogeneous architectures and training
&lt;/p&gt;</description></item><item><title>&#26696;&#20363;&#22522;&#30784;&#31070;&#32463;&#32593;&#32476;&#65288;CBNNs&#65289;&#26159;&#19968;&#31181;&#26032;&#30340;&#29983;&#23384;&#20998;&#26512;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#21516;&#26102;&#27169;&#25311;&#26102;&#38388;&#21464;&#21270;&#30340;&#20132;&#20114;&#21644;&#22797;&#26434;&#30340;&#22522;&#32447;&#39118;&#38505;&#12290;</title><link>http://arxiv.org/abs/2301.06535</link><description>&lt;p&gt;
&#26696;&#20363;&#22522;&#30784;&#31070;&#32463;&#32593;&#32476;&#65306;&#20855;&#26377;&#26102;&#38388;&#21464;&#21270;&#30340;&#39640;&#38454;&#20132;&#20114;&#30340;&#29983;&#23384;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Case-Base Neural Networks: survival analysis with time-varying, higher-order interactions. (arXiv:2301.06535v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.06535
&lt;/p&gt;
&lt;p&gt;
&#26696;&#20363;&#22522;&#30784;&#31070;&#32463;&#32593;&#32476;&#65288;CBNNs&#65289;&#26159;&#19968;&#31181;&#26032;&#30340;&#29983;&#23384;&#20998;&#26512;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#21516;&#26102;&#27169;&#25311;&#26102;&#38388;&#21464;&#21270;&#30340;&#20132;&#20114;&#21644;&#22797;&#26434;&#30340;&#22522;&#32447;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#22522;&#20110;&#29983;&#23384;&#20998;&#26512;&#26041;&#27861;&#21487;&#20197;&#27169;&#25311;&#25968;&#25454;&#39537;&#21160;&#30340;&#21327;&#21464;&#37327;&#20132;&#20114;&#12290;&#34429;&#28982;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#27604;&#22238;&#24402;&#26041;&#27861;&#25552;&#20379;&#26356;&#22909;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#20294;&#24182;&#19981;&#26159;&#25152;&#26377;&#30340;&#26041;&#27861;&#37117;&#21487;&#20197;&#27169;&#25311;&#26102;&#38388;&#21464;&#21270;&#30340;&#20132;&#20114;&#21644;&#22797;&#26434;&#30340;&#22522;&#32447;&#39118;&#38505;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#26696;&#20363;&#22522;&#30784;&#31070;&#32463;&#32593;&#32476;&#65288;CBNNs&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#23558;&#26696;&#20363;&#22522;&#30784;&#25277;&#26679;&#26694;&#26550;&#19982;&#28789;&#27963;&#30340;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#30456;&#32467;&#21512;&#12290;&#36890;&#36807;&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#25277;&#26679;&#26041;&#26696;&#21644;&#25968;&#25454;&#22686;&#24378;&#26469;&#33258;&#28982;&#22320;&#32771;&#34385;&#21040;&#25130;&#23614;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#21487;&#20197;&#25509;&#21463;&#26102;&#38388;&#36755;&#20837;&#30340;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#12290;CBNNs&#36890;&#36807;&#39044;&#27979;&#22312;&#32473;&#23450;&#26102;&#21051;&#20107;&#20214;&#21457;&#29983;&#30340;&#27010;&#29575;&#26469;&#20272;&#35745;&#21361;&#38505;&#20989;&#25968;&#12290;&#25105;&#20204;&#36890;&#36807;&#27169;&#25311;&#21644;&#19977;&#20010;&#26696;&#20363;&#30740;&#31350;&#20351;&#29992;&#20004;&#20010;&#26102;&#38388;&#20381;&#36182;&#25351;&#26631;&#27604;&#36739;CBNNs&#19982;&#22238;&#24402;&#21644;&#31070;&#32463;&#32593;&#32476;&#22522;&#20110;&#29983;&#23384;&#20998;&#26512;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#36890;&#36807;&#28041;&#21450;&#22797;&#26434;&#22522;&#32447;&#39118;&#38505;&#21644;&#26102;&#38388;&#21464;&#21270;&#20132;&#20114;&#30340;&#27169;&#25311;&#26469;&#35780;&#20272;&#25152;&#26377;&#26041;&#27861;&#65292;&#20854;&#20013;&#21253;&#25324;CBNNs&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural network-based survival methods can model data-driven covariate interactions. While these methods can provide better predictive performance than regression-based approaches, not all can model time-varying interactions and complex baseline hazards. To address this, we propose Case-Base Neural Networks (CBNNs) as a new approach that combines the case-base sampling framework with flexible neural network architectures. Using a novel sampling scheme and data augmentation to naturally account for censoring, we construct a feed-forward neural network that may take time as an input. CBNNs predict the probability of an event occurring at a given moment to estimate the hazard function. We compare the performance of CBNNs to regression and neural network-based survival methods in a simulation and three case studies using two time-dependent metrics. First, we examine performance on a simulation involving a complex baseline hazard and time-varying interactions to assess all methods, with CBNN
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#27604;&#36739;&#20102;&#22810;&#31181;&#24120;&#29992;&#30340;&#21452;&#37325;&#31283;&#20581;&#26041;&#27861;&#65292;&#25506;&#35752;&#20102;&#23427;&#20204;&#20351;&#29992;&#27835;&#30103;&#27169;&#22411;&#21644;&#32467;&#26524;&#27169;&#22411;&#30340;&#31574;&#30053;&#24322;&#21516;&#65292;&#24182;&#30740;&#31350;&#20102;&#22914;&#20309;&#32467;&#21512;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#20197;&#25552;&#39640;&#20854;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2204.10969</link><description>&lt;p&gt;
&#24403;&#21452;&#37325;&#31283;&#20581;&#26041;&#27861;&#36935;&#21040;&#26426;&#22120;&#23398;&#20064;&#65306;&#29992;&#20110;&#20174;&#23454;&#38469;&#25968;&#25454;&#20013;&#20272;&#35745;&#27835;&#30103;&#25928;&#26524;&#30340;&#27604;&#36739;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
When Doubly Robust Methods Meet Machine Learning for Estimating Treatment Effects from Real-World Data: A Comparative Study. (arXiv:2204.10969v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.10969
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#27604;&#36739;&#20102;&#22810;&#31181;&#24120;&#29992;&#30340;&#21452;&#37325;&#31283;&#20581;&#26041;&#27861;&#65292;&#25506;&#35752;&#20102;&#23427;&#20204;&#20351;&#29992;&#27835;&#30103;&#27169;&#22411;&#21644;&#32467;&#26524;&#27169;&#22411;&#30340;&#31574;&#30053;&#24322;&#21516;&#65292;&#24182;&#30740;&#31350;&#20102;&#22914;&#20309;&#32467;&#21512;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#20197;&#25552;&#39640;&#20854;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35266;&#23519;&#24615;&#38431;&#21015;&#30740;&#31350;&#36234;&#26469;&#36234;&#24120;&#29992;&#20110;&#27604;&#36739;&#25928;&#26524;&#30740;&#31350;&#65292;&#20197;&#35780;&#20272;&#27835;&#30103;&#26041;&#27861;&#30340;&#23433;&#20840;&#24615;&#12290;&#26368;&#36817;&#65292;&#21508;&#31181;&#21452;&#37325;&#31283;&#20581;&#26041;&#27861;&#24050;&#34987;&#25552;&#20986;&#65292;&#36890;&#36807;&#21305;&#37197;&#12289;&#21152;&#26435;&#21644;&#22238;&#24402;&#31561;&#19981;&#21516;&#26041;&#24335;&#65292;&#36890;&#36807;&#32452;&#21512;&#27835;&#30103;&#27169;&#22411;&#21644;&#32467;&#26524;&#27169;&#22411;&#26469;&#20272;&#35745;&#24179;&#22343;&#27835;&#30103;&#25928;&#24212;&#12290;&#21452;&#37325;&#31283;&#20581;&#20272;&#35745;&#22120;&#30340;&#20851;&#38190;&#20248;&#21183;&#22312;&#20110;&#65292;&#23427;&#20204;&#35201;&#27714;&#27835;&#30103;&#27169;&#22411;&#25110;&#32467;&#26524;&#27169;&#22411;&#20043;&#19968;&#34987;&#27491;&#30830;&#35268;&#23450;&#65292;&#20197;&#33719;&#24471;&#24179;&#22343;&#27835;&#30103;&#25928;&#26524;&#30340;&#19968;&#33268;&#20272;&#35745;&#20540;&#65292;&#20174;&#32780;&#23548;&#33268;&#26356;&#20934;&#30830;&#12289;&#36890;&#24120;&#26356;&#31934;&#30830;&#30340;&#25512;&#26029;&#12290;&#28982;&#32780;&#65292;&#24456;&#23569;&#26377;&#24037;&#20316;&#21435;&#29702;&#35299;&#21452;&#37325;&#31283;&#20581;&#20272;&#35745;&#22120;&#30001;&#20110;&#20351;&#29992;&#27835;&#30103;&#21644;&#32467;&#26524;&#27169;&#22411;&#30340;&#29420;&#29305;&#31574;&#30053;&#22914;&#20309;&#19981;&#21516;&#20197;&#21450;&#22914;&#20309;&#32467;&#21512;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#20197;&#25552;&#39640;&#20854;&#24615;&#33021;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#26816;&#26597;&#20102;&#22810;&#20010;&#21463;&#27426;&#36814;&#30340;&#21452;&#37325;&#31283;&#20581;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;&#19981;&#21516;&#30340;&#27835;&#30103;&#21644;&#32467;&#26524;&#27169;&#22411;&#27604;&#36739;&#23427;&#20204;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Observational cohort studies are increasingly being used for comparative effectiveness research to assess the safety of therapeutics. Recently, various doubly robust methods have been proposed for average treatment effect estimation by combining the treatment model and the outcome model via different vehicles, such as matching, weighting, and regression. The key advantage of doubly robust estimators is that they require either the treatment model or the outcome model to be correctly specified to obtain a consistent estimator of average treatment effects, and therefore lead to a more accurate and often more precise inference. However, little work has been done to understand how doubly robust estimators differ due to their unique strategies of using the treatment and outcome models and how machine learning techniques can be combined to boost their performance. Here we examine multiple popular doubly robust methods and compare their performance using different treatment and outcome modeli
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#23558;&#20048;&#35266;&#26799;&#24230;&#26041;&#27861;&#35299;&#37322;&#20026;&#23545;&#37051;&#36817;&#28857;&#27861;&#30340;&#36817;&#20284;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#24191;&#20041;&#20048;&#35266;&#26041;&#27861;&#65292;&#21487;&#20197;&#22788;&#29702;&#20855;&#26377;&#22797;&#21512;&#30446;&#26631;&#20989;&#25968;&#30340;&#32422;&#26463;&#38797;&#28857;&#38382;&#39064;&#65292;&#24182;&#19988;&#21487;&#20197;&#20351;&#29992;Bregman&#36317;&#31163;&#22788;&#29702;&#20219;&#24847;&#33539;&#25968;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#20010;&#22238;&#28335;&#32447;&#25628;&#32034;&#26041;&#26696;&#65292;&#20197;&#36873;&#25321;&#27493;&#38271;&#65292;&#32780;&#19981;&#38656;&#35201;&#20102;&#35299;&#24179;&#28369;&#31995;&#25968;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20351;&#29992;&#19968;&#38454;&#12289;&#20108;&#38454;&#21644;&#26356;&#39640;&#38454;&#25968;&#23398;&#35268;&#21017;&#26102;&#65292;&#32473;&#20986;&#20102;&#24050;&#30693;&#30340;&#20840;&#23616;&#36845;&#20195;&#22797;&#26434;&#24230;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2202.09674</link><description>&lt;p&gt;
&#24191;&#20041;&#20048;&#35266;&#26041;&#27861;&#29992;&#20110;&#20984;&#20985;&#38797;&#28857;&#38382;&#39064;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generalized Optimistic Methods for Convex-Concave Saddle Point Problems. (arXiv:2202.09674v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.09674
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23558;&#20048;&#35266;&#26799;&#24230;&#26041;&#27861;&#35299;&#37322;&#20026;&#23545;&#37051;&#36817;&#28857;&#27861;&#30340;&#36817;&#20284;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#24191;&#20041;&#20048;&#35266;&#26041;&#27861;&#65292;&#21487;&#20197;&#22788;&#29702;&#20855;&#26377;&#22797;&#21512;&#30446;&#26631;&#20989;&#25968;&#30340;&#32422;&#26463;&#38797;&#28857;&#38382;&#39064;&#65292;&#24182;&#19988;&#21487;&#20197;&#20351;&#29992;Bregman&#36317;&#31163;&#22788;&#29702;&#20219;&#24847;&#33539;&#25968;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#20010;&#22238;&#28335;&#32447;&#25628;&#32034;&#26041;&#26696;&#65292;&#20197;&#36873;&#25321;&#27493;&#38271;&#65292;&#32780;&#19981;&#38656;&#35201;&#20102;&#35299;&#24179;&#28369;&#31995;&#25968;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20351;&#29992;&#19968;&#38454;&#12289;&#20108;&#38454;&#21644;&#26356;&#39640;&#38454;&#25968;&#23398;&#35268;&#21017;&#26102;&#65292;&#32473;&#20986;&#20102;&#24050;&#30693;&#30340;&#20840;&#23616;&#36845;&#20195;&#22797;&#26434;&#24230;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20048;&#35266;&#26799;&#24230;&#26041;&#27861;&#22312;&#35299;&#20915;&#20984;&#20985;&#38797;&#28857;&#38382;&#39064;&#26041;&#38754;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#12290;&#20026;&#20102;&#20998;&#26512;&#20854;&#36845;&#20195;&#22797;&#26434;&#24230;&#65292;&#26368;&#36817;&#30340;&#19968;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#20010;&#26377;&#36259;&#30340;&#35266;&#28857;&#65292;&#23558;&#36825;&#20010;&#26041;&#27861;&#35299;&#37322;&#20026;&#23545;&#37051;&#36817;&#28857;&#27861;&#30340;&#36817;&#20284;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36981;&#24490;&#36825;&#19968;&#26041;&#27861;&#65292;&#24182;&#23558;&#20048;&#35266;&#30340;&#24605;&#24819;&#31934;&#28860;&#20026;&#19968;&#20010;&#24191;&#20041;&#20048;&#35266;&#26041;&#27861;&#65292;&#20854;&#20013;&#21253;&#25324;&#20048;&#35266;&#26799;&#24230;&#26041;&#27861;&#20316;&#20026;&#19968;&#31181;&#29305;&#27530;&#24773;&#20917;&#12290;&#25105;&#20204;&#30340;&#36890;&#29992;&#26694;&#26550;&#21487;&#20197;&#22788;&#29702;&#20855;&#26377;&#22797;&#21512;&#30446;&#26631;&#20989;&#25968;&#30340;&#32422;&#26463;&#38797;&#28857;&#38382;&#39064;&#65292;&#24182;&#19988;&#21487;&#20197;&#20351;&#29992;Bregman&#36317;&#31163;&#22788;&#29702;&#20219;&#24847;&#33539;&#25968;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#22238;&#28335;&#32447;&#25628;&#32034;&#26041;&#26696;&#65292;&#20197;&#36873;&#25321;&#27493;&#38271;&#65292;&#32780;&#19981;&#38656;&#35201;&#20102;&#35299;&#24179;&#28369;&#31995;&#25968;&#12290;&#25105;&#20204;&#21033;&#29992;&#19968;&#38454;&#12289;&#20108;&#38454;&#21644;&#26356;&#39640;&#38454;&#25968;&#23398;&#35268;&#21017;&#26469;&#23454;&#29616;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#24182;&#32473;&#20986;&#20102;&#24050;&#30693;&#30340;&#20840;&#23616;&#36845;&#20195;&#22797;&#26434;&#24230;&#30028;&#38480;&#12290;&#23545;&#20110;&#25105;&#20204;&#30340;&#19968;&#38454;&#26041;&#27861;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#24179;&#22343;&#36845;&#20195;&#22312;$O(1/N)$&#30340;&#36895;&#24230;&#19979;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;
The optimistic gradient method has seen increasing popularity for solving convex-concave saddle point problems. To analyze its iteration complexity, a recent work [arXiv:1906.01115] proposed an interesting perspective that interprets this method as an approximation to the proximal point method. In this paper, we follow this approach and distill the underlying idea of optimism to propose a generalized optimistic method, which includes the optimistic gradient method as a special case. Our general framework can handle constrained saddle point problems with composite objective functions and can work with arbitrary norms using Bregman distances. Moreover, we develop a backtracking line search scheme to select the step sizes without knowledge of the smoothness coefficients. We instantiate our method with first-, second- and higher-order oracles and give best-known global iteration complexity bounds. For our first-order method, we show that the averaged iterates converge at a rate of $O(1/N)$
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#32852;&#21512;&#20998;&#24067;&#23398;&#20064;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#20174;&#22823;&#37327;&#25968;&#25454;&#28857;&#20013;&#20272;&#35745;&#20302;&#32500;&#12289;&#24402;&#19968;&#21270;&#21644;&#27491;&#30340;Radon-Nikodym&#23548;&#25968;&#27169;&#22411;&#65292;&#24182;&#22312;&#19981;&#21516;&#23398;&#20064;&#38382;&#39064;&#19978;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2110.04829</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#32852;&#21512;&#20998;&#24067;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Adaptive joint distribution learning. (arXiv:2110.04829v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.04829
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#32852;&#21512;&#20998;&#24067;&#23398;&#20064;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#20174;&#22823;&#37327;&#25968;&#25454;&#28857;&#20013;&#20272;&#35745;&#20302;&#32500;&#12289;&#24402;&#19968;&#21270;&#21644;&#27491;&#30340;Radon-Nikodym&#23548;&#25968;&#27169;&#22411;&#65292;&#24182;&#22312;&#19981;&#21516;&#23398;&#20064;&#38382;&#39064;&#19978;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#23558;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#23884;&#20837;&#24352;&#37327;&#31215;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#20013;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#23481;&#32435;&#19968;&#20010;&#20302;&#32500;&#12289;&#24402;&#19968;&#21270;&#21644;&#27491;&#30340;Radon-Nikodym&#23548;&#25968;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#20174;&#22810;&#36798;&#25968;&#30334;&#19975;&#20010;&#25968;&#25454;&#28857;&#30340;&#26679;&#26412;&#22823;&#23567;&#20013;&#36827;&#34892;&#20272;&#35745;&#65292;&#20943;&#36731;&#20102;RKHS&#24314;&#27169;&#30340;&#22266;&#26377;&#38480;&#21046;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#33258;&#28982;&#20135;&#29983;&#20102;&#23450;&#20041;&#33391;&#22909;&#30340;&#24402;&#19968;&#21270;&#21644;&#27491;&#30340;&#26465;&#20214;&#20998;&#24067;&#12290;&#23884;&#20837;&#35745;&#31639;&#36895;&#24230;&#24555;&#19988;&#36866;&#29992;&#20110;&#20174;&#39044;&#27979;&#21040;&#20998;&#31867;&#30340;&#21508;&#31181;&#23398;&#20064;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#24471;&#21040;&#20102;&#26377;&#30410;&#30340;&#25968;&#20540;&#32467;&#26524;&#30340;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a new framework for embedding joint probability distributions in tensor product reproducing kernel Hilbert spaces (RKHS). Our framework accommodates a low-dimensional, normalized and positive model of a Radon-Nikodym derivative, which we estimate from sample sizes of up to several million data points, alleviating the inherent limitations of RKHS modeling. Well-defined normalized and positive conditional distributions are natural by-products to our approach. The embedding is fast to compute and accommodates learning problems ranging from prediction to classification. Our theoretical findings are supplemented by favorable numerical results.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#23618;&#30456;&#20851;&#32858;&#31867;&#26041;&#27861;&#65292;&#21487;&#24212;&#29992;&#20110;&#27491;&#36127;&#37197;&#23545;&#19981;&#30456;&#20284;&#24230;&#65292;&#24182;&#30740;&#31350;&#20102;&#20351;&#29992;&#27492;&#26041;&#27861;&#36827;&#34892;&#26080;&#30417;&#30563;&#34920;&#24449;&#23398;&#20064;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2002.07756</link><description>&lt;p&gt;
&#20998;&#23618;&#30456;&#20851;&#32858;&#31867;&#21644;&#32500;&#25345;&#26641;&#32467;&#26500;&#23884;&#20837;
&lt;/p&gt;
&lt;p&gt;
Hierarchical Correlation Clustering and Tree Preserving Embedding. (arXiv:2002.07756v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2002.07756
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#23618;&#30456;&#20851;&#32858;&#31867;&#26041;&#27861;&#65292;&#21487;&#24212;&#29992;&#20110;&#27491;&#36127;&#37197;&#23545;&#19981;&#30456;&#20284;&#24230;&#65292;&#24182;&#30740;&#31350;&#20102;&#20351;&#29992;&#27492;&#26041;&#27861;&#36827;&#34892;&#26080;&#30417;&#30563;&#34920;&#24449;&#23398;&#20064;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#23618;&#30456;&#20851;&#32858;&#31867;&#26041;&#27861;&#65292;&#25193;&#23637;&#20102;&#33879;&#21517;&#30340;&#30456;&#20851;&#32858;&#31867;&#26041;&#27861;&#65292;&#21487;&#20197;&#20135;&#29983;&#36866;&#29992;&#20110;&#27491;&#36127;&#37197;&#23545;&#19981;&#30456;&#20284;&#24230;&#30340;&#20998;&#23618;&#32858;&#31867;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20351;&#29992;&#36825;&#31181;&#20998;&#23618;&#30456;&#20851;&#32858;&#31867;&#30340;&#26080;&#30417;&#30563;&#34920;&#24449;&#23398;&#20064;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#39318;&#20808;&#30740;&#31350;&#23558;&#30456;&#24212;&#30340;&#20998;&#23618;&#23884;&#20837;&#29992;&#20110;&#32500;&#25345;&#26641;&#32467;&#26500;&#23884;&#20837;&#21644;&#29305;&#24449;&#25552;&#21462;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#26368;&#23567;&#26368;&#22823;&#36317;&#31163;&#24230;&#37327;&#25193;&#23637;&#21040;&#30456;&#20851;&#32858;&#31867;&#30340;&#26041;&#27861;&#65292;&#20316;&#20026;&#21478;&#19968;&#31181;&#34920;&#24449;&#23398;&#20064;&#33539;&#24335;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a hierarchical correlation clustering method that extends the well-known correlation clustering to produce hierarchical clusters applicable to both positive and negative pairwise dissimilarities. Then, in the following, we study unsupervised representation learning with such hierarchical correlation clustering. For this purpose, we first investigate embedding the respective hierarchy to be used for tree-preserving embedding and feature extraction. Thereafter, we study the extension of minimax distance measures to correlation clustering, as another representation learning paradigm. Finally, we demonstrate the performance of our methods on several datasets.
&lt;/p&gt;</description></item></channel></rss>