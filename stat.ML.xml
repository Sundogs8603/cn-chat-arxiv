<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#23558;&#38543;&#26426;Polyak&#27493;&#38271;&#26041;&#27861;&#25193;&#23637;&#21040;&#32852;&#37030;&#23398;&#20064;&#65292;&#25552;&#20986;&#20102;&#26032;&#30340;&#23616;&#37096;&#33258;&#36866;&#24212;&#21644;&#20960;&#20046;&#26080;&#38656;&#35843;&#21442;&#30340;FedSPS&#21644;FedDecSPS&#21464;&#20307;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#25554;&#20540;&#26465;&#20214;&#28385;&#36275;&#26102;&#65292;FedSPS&#20197;&#32447;&#24615;&#36895;&#24230;&#25910;&#25947;&#65292;&#19968;&#33324;&#24773;&#20917;&#19979;&#25910;&#25947;&#21040;&#35299;&#30340;&#37051;&#22495;&#12290;</title><link>http://arxiv.org/abs/2307.06306</link><description>&lt;p&gt;
&#36890;&#36807;&#38543;&#26426;Polyak&#27493;&#38271;&#30340;&#23616;&#37096;&#33258;&#36866;&#24212;&#32852;&#37030;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Locally Adaptive Federated Learning via Stochastic Polyak Stepsizes. (arXiv:2307.06306v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06306
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#38543;&#26426;Polyak&#27493;&#38271;&#26041;&#27861;&#25193;&#23637;&#21040;&#32852;&#37030;&#23398;&#20064;&#65292;&#25552;&#20986;&#20102;&#26032;&#30340;&#23616;&#37096;&#33258;&#36866;&#24212;&#21644;&#20960;&#20046;&#26080;&#38656;&#35843;&#21442;&#30340;FedSPS&#21644;FedDecSPS&#21464;&#20307;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#25554;&#20540;&#26465;&#20214;&#28385;&#36275;&#26102;&#65292;FedSPS&#20197;&#32447;&#24615;&#36895;&#24230;&#25910;&#25947;&#65292;&#19968;&#33324;&#24773;&#20917;&#19979;&#25910;&#25947;&#21040;&#35299;&#30340;&#37051;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#20808;&#36827;&#30340;&#32852;&#37030;&#23398;&#20064;&#31639;&#27861;&#65292;&#22914;FedAvg&#65292;&#38656;&#35201;&#31934;&#24515;&#35843;&#25972;&#30340;&#27493;&#38271;&#25165;&#33021;&#36798;&#21040;&#26368;&#20339;&#24615;&#33021;&#12290;&#29616;&#26377;&#33258;&#36866;&#24212;&#32852;&#37030;&#26041;&#27861;&#25552;&#20986;&#30340;&#25913;&#36827;&#20165;&#28041;&#21450;&#39069;&#22806;&#30340;&#36229;&#21442;&#25968;&#35843;&#25972;&#65292;&#22914;&#21160;&#37327;&#21442;&#25968;&#65292;&#24182;&#19988;&#20165;&#32771;&#34385;&#22312;&#26381;&#21153;&#22120;&#32858;&#21512;&#36718;&#27425;&#20013;&#30340;&#36866;&#24212;&#24615;&#65292;&#32780;&#19981;&#26159;&#23616;&#37096;&#30340;&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#35768;&#22810;&#23454;&#38469;&#22330;&#26223;&#19979;&#25928;&#29575;&#20302;&#19979;&#65292;&#22240;&#20026;&#23427;&#20204;&#38656;&#35201;&#36807;&#22810;&#30340;&#36229;&#21442;&#25968;&#35843;&#25972;&#65292;&#24182;&#19988;&#19981;&#33021;&#25429;&#25417;&#23616;&#37096;&#20960;&#20309;&#20449;&#24687;&#12290;&#26412;&#25991;&#23558;&#26368;&#36817;&#25552;&#20986;&#30340;&#38543;&#26426;Polyak&#27493;&#38271;&#26041;&#27861;&#25193;&#23637;&#21040;&#32852;&#37030;&#23398;&#20064;&#29615;&#22659;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#23616;&#37096;&#33258;&#36866;&#24212;&#21644;&#20960;&#20046;&#26080;&#38656;&#35843;&#21442;&#30340;&#20998;&#24067;&#24335;SPS&#21464;&#20307;&#65288;FedSPS&#21644;FedDecSPS&#65289;&#12290;&#25105;&#20204;&#35777;&#26126;&#24403;&#25554;&#20540;&#26465;&#20214;&#65288;&#36807;&#21442;&#25968;&#21270;&#65289;&#28385;&#36275;&#26102;&#65292;FedSPS&#22312;&#24378;&#20984;&#21644;&#20984;&#35774;&#32622;&#20013;&#20197;&#32447;&#24615;&#36895;&#24230;&#25910;&#25947;&#65292;&#19968;&#33324;&#24773;&#20917;&#19979;&#25910;&#25947;&#21040;&#35299;&#30340;&#37051;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
State-of-the-art federated learning algorithms such as FedAvg require carefully tuned stepsizes to achieve their best performance. The improvements proposed by existing adaptive federated methods involve tuning of additional hyperparameters such as momentum parameters, and consider adaptivity only in the server aggregation round, but not locally. These methods can be inefficient in many practical scenarios because they require excessive tuning of hyperparameters and do not capture local geometric information. In this work, we extend the recently proposed stochastic Polyak stepsize (SPS) to the federated learning setting, and propose new locally adaptive and nearly parameter-free distributed SPS variants (FedSPS and FedDecSPS). We prove that FedSPS converges linearly in strongly convex and sublinearly in convex settings when the interpolation condition (overparametrization) is satisfied, and converges to a neighborhood of the solution in the general case. We extend our proposed method t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#36719;&#24178;&#39044;&#20013;&#30830;&#20445;&#22240;&#26524;&#20998;&#35299;&#30340;&#21487;&#35782;&#21035;&#24615;&#12290;&#36890;&#36807;&#24320;&#21457;&#19968;&#31181;&#33258;&#32534;&#30721;&#21464;&#20998;&#36125;&#21494;&#26031;&#31639;&#27861;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#32473;&#23450;&#19968;&#33324;&#21270;&#30340;&#24544;&#35802;&#24615;&#27010;&#24565;&#30340;&#24773;&#20917;&#19979;&#65292;&#21363;&#20351;&#23384;&#22312;&#26410;&#35266;&#27979;&#21040;&#30340;&#22240;&#26524;&#21464;&#37327;&#65292;&#20173;&#28982;&#21487;&#20197;&#24674;&#22797;&#28508;&#22312;&#30340;&#22240;&#26524;&#27169;&#22411;&#65292;&#24182;&#22312;&#26080;&#38480;&#25968;&#25454;&#30340;&#26497;&#38480;&#24773;&#20917;&#19979;&#39044;&#27979;&#26410;&#35265;&#32452;&#21512;&#30340;&#24178;&#39044;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2307.06250</link><description>&lt;p&gt;
&#20174;&#36719;&#24178;&#39044;&#20013;&#30830;&#20445;&#22240;&#26524;&#20998;&#35299;&#30340;&#21487;&#35782;&#21035;&#24615;
&lt;/p&gt;
&lt;p&gt;
Identifiability Guarantees for Causal Disentanglement from Soft Interventions. (arXiv:2307.06250v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06250
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#36719;&#24178;&#39044;&#20013;&#30830;&#20445;&#22240;&#26524;&#20998;&#35299;&#30340;&#21487;&#35782;&#21035;&#24615;&#12290;&#36890;&#36807;&#24320;&#21457;&#19968;&#31181;&#33258;&#32534;&#30721;&#21464;&#20998;&#36125;&#21494;&#26031;&#31639;&#27861;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#32473;&#23450;&#19968;&#33324;&#21270;&#30340;&#24544;&#35802;&#24615;&#27010;&#24565;&#30340;&#24773;&#20917;&#19979;&#65292;&#21363;&#20351;&#23384;&#22312;&#26410;&#35266;&#27979;&#21040;&#30340;&#22240;&#26524;&#21464;&#37327;&#65292;&#20173;&#28982;&#21487;&#20197;&#24674;&#22797;&#28508;&#22312;&#30340;&#22240;&#26524;&#27169;&#22411;&#65292;&#24182;&#22312;&#26080;&#38480;&#25968;&#25454;&#30340;&#26497;&#38480;&#24773;&#20917;&#19979;&#39044;&#27979;&#26410;&#35265;&#32452;&#21512;&#30340;&#24178;&#39044;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#20998;&#35299;&#26088;&#22312;&#36890;&#36807;&#28508;&#22312;&#21464;&#37327;&#30340;&#30456;&#20851;&#24615;&#25581;&#31034;&#25968;&#25454;&#30340;&#34920;&#24449;&#65292;&#20854;&#36890;&#36807;&#22240;&#26524;&#27169;&#22411;&#30456;&#20114;&#20851;&#32852;&#12290;&#22914;&#26524;&#35299;&#37322;&#25968;&#25454;&#30340;&#28508;&#22312;&#27169;&#22411;&#26159;&#21807;&#19968;&#30340;&#65292;&#37027;&#20040;&#36825;&#31181;&#34920;&#31034;&#26159;&#21487;&#35782;&#21035;&#30340;&#12290;&#26412;&#25991;&#20851;&#27880;&#30340;&#26159;&#24403;&#23384;&#22312;&#19981;&#37197;&#23545;&#30340;&#35266;&#27979;&#21644;&#24178;&#39044;&#25968;&#25454;&#26102;&#30340;&#24773;&#20917;&#65292;&#27599;&#20010;&#24178;&#39044;&#37117;&#20250;&#25913;&#21464;&#19968;&#20010;&#28508;&#22312;&#21464;&#37327;&#30340;&#26426;&#21046;&#12290;&#24403;&#22240;&#26524;&#21464;&#37327;&#23436;&#20840;&#35266;&#27979;&#21040;&#26102;&#65292;&#22312;&#35802;&#23454;&#24615;&#20551;&#35774;&#19979;&#65292;&#24050;&#32463;&#24320;&#21457;&#20986;&#20102;&#32479;&#35745;&#19968;&#33268;&#30340;&#31639;&#27861;&#26469;&#35782;&#21035;&#22240;&#26524;&#27169;&#22411;&#12290;&#25105;&#20204;&#22312;&#36825;&#37324;&#23637;&#31034;&#65292;&#21363;&#20351;&#23384;&#22312;&#26410;&#35266;&#27979;&#21040;&#30340;&#22240;&#26524;&#21464;&#37327;&#65292;&#22312;&#32473;&#23450;&#19968;&#33324;&#21270;&#30340;&#24544;&#35802;&#24615;&#27010;&#24565;&#30340;&#24773;&#20917;&#19979;&#20173;&#28982;&#21487;&#20197;&#23454;&#29616;&#21487;&#35782;&#21035;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20445;&#35777;&#20102;&#25105;&#20204;&#21487;&#20197;&#24674;&#22797;&#28508;&#22312;&#30340;&#22240;&#26524;&#27169;&#22411;&#65292;&#39044;&#27979;&#26410;&#35265;&#32452;&#21512;&#30340;&#24178;&#39044;&#25928;&#26524;&#65292;&#22312;&#26080;&#38480;&#25968;&#25454;&#30340;&#26497;&#38480;&#24773;&#20917;&#19979;&#12290;&#25105;&#20204;&#36890;&#36807;&#24320;&#21457;&#19968;&#31181;&#33258;&#32534;&#30721;&#21464;&#20998;&#36125;&#21494;&#26031;&#31639;&#27861;&#21644;ap&#26469;&#23454;&#29616;&#25105;&#20204;&#30340;&#22240;&#26524;&#20998;&#35299;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal disentanglement aims to uncover a representation of data using latent variables that are interrelated through a causal model. Such a representation is identifiable if the latent model that explains the data is unique. In this paper, we focus on the scenario where unpaired observational and interventional data are available, with each intervention changing the mechanism of a latent variable. When the causal variables are fully observed, statistically consistent algorithms have been developed to identify the causal model under faithfulness assumptions. We here show that identifiability can still be achieved with unobserved causal variables, given a generalized notion of faithfulness. Our results guarantee that we can recover the latent causal model up to an equivalence class and predict the effect of unseen combinations of interventions, in the limit of infinite data. We implement our causal disentanglement framework by developing an autoencoding variational Bayes algorithm and ap
&lt;/p&gt;</description></item><item><title>SepVAE&#26159;&#19968;&#31181;&#23545;&#27604;VAE&#26041;&#27861;&#65292;&#21487;&#20197;&#20174;&#20581;&#24247;&#25968;&#25454;&#21644;&#24739;&#32773;&#25968;&#25454;&#20013;&#20998;&#31163;&#20986;&#20849;&#21516;&#30340;&#21644;&#29305;&#23450;&#30340;&#21464;&#21270;&#22240;&#32032;&#12290;&#22312;&#22810;&#20010;&#24212;&#29992;&#20013;&#34920;&#29616;&#20986;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.06206</link><description>&lt;p&gt;
SepVAE: &#19968;&#31181;&#23545;&#27604;VAE&#29992;&#20110;&#20998;&#31163;&#30149;&#29702;&#27169;&#24335;&#21644;&#20581;&#24247;&#27169;&#24335;
&lt;/p&gt;
&lt;p&gt;
SepVAE: a contrastive VAE to separate pathological patterns from healthy ones. (arXiv:2307.06206v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06206
&lt;/p&gt;
&lt;p&gt;
SepVAE&#26159;&#19968;&#31181;&#23545;&#27604;VAE&#26041;&#27861;&#65292;&#21487;&#20197;&#20174;&#20581;&#24247;&#25968;&#25454;&#21644;&#24739;&#32773;&#25968;&#25454;&#20013;&#20998;&#31163;&#20986;&#20849;&#21516;&#30340;&#21644;&#29305;&#23450;&#30340;&#21464;&#21270;&#22240;&#32032;&#12290;&#22312;&#22810;&#20010;&#24212;&#29992;&#20013;&#34920;&#29616;&#20986;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#27604;&#20998;&#26512;VAE&#65288;CA-VAEs&#65289;&#26159;&#19968;&#31867;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAEs&#65289;&#65292;&#26088;&#22312;&#20174;&#32972;&#26223;&#25968;&#25454;&#38598;&#65288;BG&#65289;&#65288;&#21363;&#20581;&#24247;&#20154;&#32676;&#65289;&#21644;&#30446;&#26631;&#25968;&#25454;&#38598;&#65288;TG&#65289;&#65288;&#21363;&#24739;&#32773;&#65289;&#20043;&#38388;&#20998;&#31163;&#20849;&#21516;&#21464;&#21270;&#22240;&#32032;&#21644;&#20165;&#23384;&#22312;&#20110;&#30446;&#26631;&#25968;&#25454;&#38598;&#20013;&#30340;&#22240;&#32032;&#12290;&#20026;&#27492;&#65292;&#36825;&#20123;&#26041;&#27861;&#23558;&#28508;&#22312;&#31354;&#38388;&#20998;&#20026;&#19968;&#32452;&#26174;&#33879;&#29305;&#24449;&#65288;&#21363;&#29305;&#23450;&#20110;&#30446;&#26631;&#25968;&#25454;&#38598;&#65289;&#21644;&#19968;&#32452;&#20849;&#21516;&#29305;&#24449;&#65288;&#21363;&#23384;&#22312;&#20110;&#20004;&#20010;&#25968;&#25454;&#38598;&#20013;&#65289;&#12290;&#30446;&#21069;&#65292;&#25152;&#26377;&#27169;&#22411;&#37117;&#26410;&#33021;&#26377;&#25928;&#38450;&#27490;&#28508;&#22312;&#31354;&#38388;&#20043;&#38388;&#30340;&#20449;&#24687;&#20849;&#20139;&#65292;&#24182;&#25429;&#25417;&#25152;&#26377;&#26174;&#33879;&#30340;&#21464;&#21270;&#22240;&#32032;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#20010;&#20851;&#38190;&#30340;&#27491;&#21017;&#21270;&#25439;&#22833;&#65306;&#20849;&#21516;&#34920;&#31034;&#21644;&#26174;&#33879;&#34920;&#31034;&#20043;&#38388;&#30340;&#35299;&#32544;&#32469;&#39033;&#65292;&#20197;&#21450;&#26174;&#33879;&#31354;&#38388;&#20013;&#32972;&#26223;&#21644;&#30446;&#26631;&#26679;&#26412;&#20043;&#38388;&#30340;&#20998;&#31867;&#39033;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#23545;&#19977;&#20010;&#21307;&#23398;&#24212;&#29992;&#21644;&#19968;&#20010;&#33258;&#28982;&#22270;&#20687;&#25968;&#25454;&#38598;&#65288;CelebA&#65289;&#30340;&#20808;&#21069;CA-VAEs&#26041;&#27861;&#30340;&#26356;&#22909;&#24615;&#33021;&#12290;&#20195;&#30721;&#21644;&#25968;&#25454;&#38598;&#21487;&#22312;GitHub&#19978;&#33719;&#21462;&#12290;
&lt;/p&gt;
&lt;p&gt;
Contrastive Analysis VAE (CA-VAEs) is a family of Variational auto-encoders (VAEs) that aims at separating the common factors of variation between a background dataset (BG) (i.e., healthy subjects) and a target dataset (TG) (i.e., patients) from the ones that only exist in the target dataset. To do so, these methods separate the latent space into a set of salient features (i.e., proper to the target dataset) and a set of common features (i.e., exist in both datasets). Currently, all models fail to prevent the sharing of information between latent spaces effectively and to capture all salient factors of variation. To this end, we introduce two crucial regularization losses: a disentangling term between common and salient representations and a classification term between background and target samples in the salient space. We show a better performance than previous CA-VAEs methods on three medical applications and a natural images dataset (CelebA). Code and datasets are available on GitHu
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#37325;&#26032;&#25512;&#23548;&#20102;&#22312;&#32447; Laplace &#26041;&#27861;&#65292;&#24182;&#23558;&#20854;&#30446;&#26631;&#23450;&#20301;&#20026;&#27169;&#24577;&#20462;&#27491;&#30340;&#21464;&#20998;&#19978;&#30028;&#65292;&#36991;&#20813;&#20102;&#23545;&#24179;&#31283;&#24615;&#30340;&#20551;&#35774;&#12290;&#36890;&#36807;&#20351;&#29992;&#20840;&#25209;&#37327;&#26799;&#24230;&#30340;&#22312;&#32447;&#31639;&#27861;&#65292;&#25105;&#20204;&#28436;&#31034;&#20102;&#22312;&#23454;&#36341;&#20013;&#23454;&#29616;&#20102;&#36825;&#20123;&#26368;&#20248;&#28857;&#65292;&#24182;&#39564;&#35777;&#20102;&#20854;&#36866;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.06093</link><description>&lt;p&gt;
&#22312;&#32447; Laplace &#27169;&#22411;&#36873;&#25321;&#30340;&#20877;&#25506;&#35752;
&lt;/p&gt;
&lt;p&gt;
Online Laplace Model Selection Revisited. (arXiv:2307.06093v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06093
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#37325;&#26032;&#25512;&#23548;&#20102;&#22312;&#32447; Laplace &#26041;&#27861;&#65292;&#24182;&#23558;&#20854;&#30446;&#26631;&#23450;&#20301;&#20026;&#27169;&#24577;&#20462;&#27491;&#30340;&#21464;&#20998;&#19978;&#30028;&#65292;&#36991;&#20813;&#20102;&#23545;&#24179;&#31283;&#24615;&#30340;&#20551;&#35774;&#12290;&#36890;&#36807;&#20351;&#29992;&#20840;&#25209;&#37327;&#26799;&#24230;&#30340;&#22312;&#32447;&#31639;&#27861;&#65292;&#25105;&#20204;&#28436;&#31034;&#20102;&#22312;&#23454;&#36341;&#20013;&#23454;&#29616;&#20102;&#36825;&#20123;&#26368;&#20248;&#28857;&#65292;&#24182;&#39564;&#35777;&#20102;&#20854;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Laplace &#36817;&#20284;&#20026;&#31070;&#32463;&#32593;&#32476;&#25552;&#20379;&#20102;&#19968;&#20010;&#23553;&#38381;&#24418;&#24335;&#30340;&#27169;&#22411;&#36873;&#25321;&#30446;&#26631;&#12290;&#22312;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#39046;&#22495;&#65292;&#23558;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#19982;&#36229;&#21442;&#25968;&#65288;&#22914;&#26435;&#37325;&#34928;&#20943;&#24378;&#24230;&#65289;&#19968;&#36215;&#36827;&#34892;&#20248;&#21270;&#30340;&#22312;&#32447;&#21464;&#20307;&#26041;&#27861;&#20877;&#27425;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#36829;&#21453;&#20102; Laplace &#26041;&#27861;&#30340;&#19968;&#20010;&#20851;&#38190;&#20551;&#35774;&#65292;&#21363;&#36817;&#20284;&#26159;&#22260;&#32469;&#25439;&#22833;&#30340;&#27169;&#24577;&#36827;&#34892;&#30340;&#65292;&#36825;&#23601;&#23545;&#23427;&#20204;&#30340;&#21512;&#29702;&#24615;&#25552;&#20986;&#20102;&#36136;&#30097;&#12290;&#26412;&#30740;&#31350;&#37325;&#26032;&#25512;&#23548;&#20102;&#22312;&#32447; Laplace &#26041;&#27861;&#65292;&#23637;&#31034;&#20102;&#23427;&#20204;&#38024;&#23545; Laplace &#35777;&#25454;&#30340;&#19968;&#20010;&#20462;&#27491;&#27169;&#24577;&#30340;&#21464;&#20998;&#19978;&#30028;&#65292;&#20174;&#32780;&#36991;&#20813;&#20102;&#23545;&#24179;&#31283;&#24615;&#30340;&#20551;&#35774;&#12290;&#22312;&#32447; Laplace &#26041;&#27861;&#21450;&#20854;&#20462;&#27491;&#27169;&#24577;&#30340;&#23545;&#24212;&#28857;&#28385;&#36275;&#20004;&#20010;&#26465;&#20214;&#65306;1. &#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#26159;&#19968;&#20010;&#26368;&#22823;&#21518;&#39564;&#27010;&#29575;&#65292;&#28385;&#36275; Laplace &#26041;&#27861;&#30340;&#20551;&#35774;&#65307;2. &#36229;&#21442;&#25968;&#26368;&#22823;&#21270; Laplace &#35777;&#25454;&#65292;&#20174;&#32780;&#20419;&#20351;&#22312;&#32447;&#26041;&#27861;&#30340;&#24212;&#29992;&#12290;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#20840;&#25209;&#37327;&#26799;&#24230;&#30340;&#22312;&#32447;&#31639;&#27861;&#28436;&#31034;&#20102;&#36825;&#20123;&#26368;&#20248;&#28857;&#22312;&#23454;&#36341;&#20013;&#30340;&#36817;&#20284;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Laplace approximation provides a closed-form model selection objective for neural networks (NN). Online variants, which optimise NN parameters jointly with hyperparameters, like weight decay strength, have seen renewed interest in the Bayesian deep learning community. However, these methods violate Laplace's method's critical assumption that the approximation is performed around a mode of the loss, calling into question their soundness. This work re-derives online Laplace methods, showing them to target a variational bound on a mode-corrected variant of the Laplace evidence which does not make stationarity assumptions. Online Laplace and its mode-corrected counterpart share stationary points where 1. the NN parameters are a maximum a posteriori, satisfying the Laplace method's assumption, and 2. the hyperparameters maximise the Laplace evidence, motivating online methods. We demonstrate that these optima are roughly attained in practise by online algorithms using full-batch gradien
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#38543;&#26426;&#39640;&#26031;&#26435;&#37325;&#21644;&#20559;&#32622;&#30340;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#24067;&#65292;&#24471;&#21040;&#20102;&#22312;&#22823;&#20294;&#26377;&#38480;&#30340; $n$ &#21644;&#20219;&#24847;&#22266;&#23450;&#32593;&#32476;&#28145;&#24230;&#19979;&#25104;&#31435;&#30340;&#27491;&#24577;&#36924;&#36817;&#30340;&#23450;&#37327;&#30028;&#38480;&#65292;&#35777;&#26126;&#20102;&#38543;&#26426;&#20840;&#36830;&#25509;&#32593;&#32476;&#19982;&#30456;&#24212;&#30340;&#26080;&#38480;&#23485;&#39640;&#26031;&#36807;&#31243;&#20043;&#38388;&#30340;&#36317;&#31163;&#25353;&#29031; $n^{-\gamma}$ &#32553;&#25918;&#65292;&#30028;&#38480;&#22312;&#32593;&#32476;&#23485;&#24230;&#30340;&#20381;&#36182;&#24615;&#26041;&#38754;&#20248;&#20110;&#20197;&#21069;&#30340;&#30740;&#31350;&#12290;</title><link>http://arxiv.org/abs/2307.06092</link><description>&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#23450;&#37327;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;
&lt;/p&gt;
&lt;p&gt;
Quantitative CLTs in Deep Neural Networks. (arXiv:2307.06092v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06092
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#38543;&#26426;&#39640;&#26031;&#26435;&#37325;&#21644;&#20559;&#32622;&#30340;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#24067;&#65292;&#24471;&#21040;&#20102;&#22312;&#22823;&#20294;&#26377;&#38480;&#30340; $n$ &#21644;&#20219;&#24847;&#22266;&#23450;&#32593;&#32476;&#28145;&#24230;&#19979;&#25104;&#31435;&#30340;&#27491;&#24577;&#36924;&#36817;&#30340;&#23450;&#37327;&#30028;&#38480;&#65292;&#35777;&#26126;&#20102;&#38543;&#26426;&#20840;&#36830;&#25509;&#32593;&#32476;&#19982;&#30456;&#24212;&#30340;&#26080;&#38480;&#23485;&#39640;&#26031;&#36807;&#31243;&#20043;&#38388;&#30340;&#36317;&#31163;&#25353;&#29031; $n^{-\gamma}$ &#32553;&#25918;&#65292;&#30028;&#38480;&#22312;&#32593;&#32476;&#23485;&#24230;&#30340;&#20381;&#36182;&#24615;&#26041;&#38754;&#20248;&#20110;&#20197;&#21069;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#38543;&#26426;&#39640;&#26031;&#26435;&#37325;&#21644;&#20559;&#32622;&#30340;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#24067;&#65292;&#20854;&#20013;&#38544;&#34255;&#23618;&#23485;&#24230;&#19982;&#22823;&#24120;&#25968; $n$ &#25104;&#27604;&#20363;&#12290;&#22312;&#38750;&#32447;&#24615;&#30340;&#28201;&#21644;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#22312;&#22823;&#20294;&#26377;&#38480;&#30340; $n$ &#21644;&#20219;&#24847;&#22266;&#23450;&#32593;&#32476;&#28145;&#24230;&#19979;&#25104;&#31435;&#30340;&#27491;&#24577;&#36924;&#36817;&#30340;&#23450;&#37327;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#23450;&#29702;&#34920;&#26126;&#65292;&#26080;&#35770;&#26159;&#23545;&#20110;&#26377;&#38480;&#32500;&#20998;&#24067;&#36824;&#26159;&#25972;&#20010;&#36807;&#31243;&#65292;&#38543;&#26426;&#20840;&#36830;&#25509;&#32593;&#32476;&#65288;&#21450;&#20854;&#23548;&#25968;&#65289;&#19982;&#30456;&#24212;&#30340;&#26080;&#38480;&#23485;&#39640;&#26031;&#36807;&#31243;&#20043;&#38388;&#30340;&#36317;&#31163;&#37117;&#20250;&#25353;&#29031; $n^{-\gamma}$ &#32553;&#25918;&#65292;&#20854;&#20013; $\gamma&gt;0$&#65292;&#25351;&#25968;&#21462;&#20915;&#20110;&#29992;&#20110;&#24230;&#37327;&#24046;&#24322;&#30340;&#24230;&#37327;&#26041;&#24335;&#12290;&#25105;&#20204;&#30340;&#30028;&#38480;&#22312;&#32593;&#32476;&#23485;&#24230;&#30340;&#20381;&#36182;&#24615;&#26041;&#38754;&#27604;&#25991;&#29486;&#20013;&#20197;&#21069;&#25552;&#20379;&#30340;&#20219;&#20309;&#30028;&#38480;&#37117;&#35201;&#24378;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the distribution of a fully connected neural network with random Gaussian weights and biases in which the hidden layer widths are proportional to a large constant $n$. Under mild assumptions on the non-linearity, we obtain quantitative bounds on normal approximations valid at large but finite $n$ and any fixed network depth. Our theorems show, both for the finite-dimensional distributions and the entire process, that the distance between a random fully connected network (and its derivatives) to the corresponding infinite width Gaussian process scales like $n^{-\gamma}$ for $\gamma&gt;0,$ with the exponent depending on the metric used to measure discrepancy. Our bounds are stronger in terms of their dependence on network width than any previously available in the literature.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#30142;&#30149;&#36827;&#23637;&#32858;&#31867;&#20013;&#35299;&#35835;&#28145;&#24230;&#23884;&#20837;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#35780;&#20272;2&#22411;&#31958;&#23615;&#30149;&#21442;&#19982;&#32773;&#25968;&#25454;&#38598;&#23637;&#31034;&#20102;&#23545;&#30142;&#30149;&#36827;&#23637;&#27169;&#24335;&#30340;&#20020;&#24202;&#24847;&#20041;&#24615;&#35265;&#35299;&#12290;</title><link>http://arxiv.org/abs/2307.06060</link><description>&lt;p&gt;
&#35299;&#35835;&#30142;&#30149;&#36827;&#23637;&#32858;&#31867;&#20013;&#30340;&#28145;&#24230;&#23884;&#20837;
&lt;/p&gt;
&lt;p&gt;
Interpreting deep embeddings for disease progression clustering. (arXiv:2307.06060v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06060
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#30142;&#30149;&#36827;&#23637;&#32858;&#31867;&#20013;&#35299;&#35835;&#28145;&#24230;&#23884;&#20837;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#35780;&#20272;2&#22411;&#31958;&#23615;&#30149;&#21442;&#19982;&#32773;&#25968;&#25454;&#38598;&#23637;&#31034;&#20102;&#23545;&#30142;&#30149;&#36827;&#23637;&#27169;&#24335;&#30340;&#20020;&#24202;&#24847;&#20041;&#24615;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#24739;&#32773;&#32858;&#31867;&#30340;&#32972;&#26223;&#19979;&#35299;&#35835;&#28145;&#24230;&#23884;&#20837;&#30340;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#22312;&#26469;&#33258;&#33521;&#22269;&#29983;&#29289;&#24211;&#30340;2&#22411;&#31958;&#23615;&#30149;&#21442;&#19982;&#32773;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20986;&#23545;&#30142;&#30149;&#36827;&#23637;&#27169;&#24335;&#30340;&#20020;&#24202;&#24847;&#20041;&#24615;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel approach for interpreting deep embeddings in the context of patient clustering. We evaluate our approach on a dataset of participants with type 2 diabetes from the UK Biobank, and demonstrate clinically meaningful insights into disease progression patterns.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20989;&#25968;&#31354;&#38388;&#27491;&#21017;&#21270;&#26041;&#27861;&#26469;&#22686;&#21152;&#28145;&#24230;&#36125;&#21494;&#26031;&#20998;&#31867;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#23545;&#25239;&#24615;&#40065;&#26834;&#24615;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992;Dirichlet&#20808;&#39564;&#22312;&#39044;&#27979;&#31354;&#38388;&#20013;&#36827;&#34892;&#21464;&#20998;&#25512;&#26029;&#65292;&#24182;&#33021;&#19982;&#19981;&#21516;&#27169;&#22411;&#30456;&#32467;&#21512;&#32780;&#19981;&#24433;&#21709;&#27169;&#22411;&#30340;&#26550;&#26500;&#22823;&#23567;&#12290;</title><link>http://arxiv.org/abs/2307.06055</link><description>&lt;p&gt;
&#28145;&#24230;&#36125;&#21494;&#26031;&#20998;&#31867;&#30340;&#20989;&#25968;&#31354;&#38388;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
Function-Space Regularization for Deep Bayesian Classification. (arXiv:2307.06055v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06055
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20989;&#25968;&#31354;&#38388;&#27491;&#21017;&#21270;&#26041;&#27861;&#26469;&#22686;&#21152;&#28145;&#24230;&#36125;&#21494;&#26031;&#20998;&#31867;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#23545;&#25239;&#24615;&#40065;&#26834;&#24615;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992;Dirichlet&#20808;&#39564;&#22312;&#39044;&#27979;&#31354;&#38388;&#20013;&#36827;&#34892;&#21464;&#20998;&#25512;&#26029;&#65292;&#24182;&#33021;&#19982;&#19981;&#21516;&#27169;&#22411;&#30456;&#32467;&#21512;&#32780;&#19981;&#24433;&#21709;&#27169;&#22411;&#30340;&#26550;&#26500;&#22823;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#20551;&#35774;&#27169;&#22411;&#21442;&#25968;&#20026;&#28508;&#22312;&#38543;&#26426;&#21464;&#37327;&#65292;&#24182;&#25512;&#26029;&#21518;&#39564;&#20998;&#24067;&#20197;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#65292;&#22686;&#21152;&#23433;&#20840;&#24615;&#21644;&#21487;&#20449;&#24230;&#65292;&#24182;&#38450;&#27490;&#36807;&#20110;&#33258;&#20449;&#21644;&#19981;&#21487;&#39044;&#27979;&#30340;&#34892;&#20026;&#12290;&#28982;&#32780;&#65292;&#26435;&#37325;&#31354;&#38388;&#20808;&#39564;&#26159;&#29305;&#23450;&#20110;&#27169;&#22411;&#30340;&#65292;&#21487;&#33021;&#38590;&#20197;&#35299;&#37322;&#21644;&#38590;&#20197;&#25351;&#23450;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#22312;&#39044;&#27979;&#31354;&#38388;&#20013;&#24212;&#29992;Dirichlet&#20808;&#39564;&#65292;&#24182;&#25191;&#34892;&#36817;&#20284;&#20989;&#25968;&#31354;&#38388;&#21464;&#20998;&#25512;&#26029;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#23558;&#38543;&#26426;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#30340;&#20256;&#32479;&#20998;&#31867;&#39044;&#27979;&#35299;&#37322;&#20026;&#26469;&#33258;&#38544;&#24335;Dirichlet&#20998;&#24067;&#30340;&#26679;&#26412;&#12290;&#36890;&#36807;&#35843;&#25972;&#25512;&#26029;&#65292;&#21487;&#20197;&#23558;&#30456;&#21516;&#30340;&#20989;&#25968;&#31354;&#38388;&#20808;&#39564;&#19982;&#19981;&#21516;&#30340;&#27169;&#22411;&#32467;&#21512;&#22312;&#19968;&#36215;&#65292;&#32780;&#19981;&#24433;&#21709;&#27169;&#22411;&#30340;&#26550;&#26500;&#25110;&#22823;&#23567;&#12290;&#25105;&#20204;&#36890;&#36807;&#29609;&#20855;&#23454;&#39564;&#35828;&#26126;&#20102;&#36825;&#31181;&#20808;&#39564;&#30340;&#28789;&#27963;&#24615;&#21644;&#21151;&#25928;&#65292;&#24182;&#36890;&#36807;&#22823;&#35268;&#27169;&#22270;&#20687;&#20998;&#31867;&#23454;&#39564;&#23637;&#31034;&#20102;&#21487;&#25193;&#23637;&#24615;&#12289;&#25913;&#36827;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#23545;&#25239;&#24615;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian deep learning approaches assume model parameters to be latent random variables and infer posterior distributions to quantify uncertainty, increase safety and trust, and prevent overconfident and unpredictable behavior. However, weight-space priors are model-specific, can be difficult to interpret and are hard to specify. Instead, we apply a Dirichlet prior in predictive space and perform approximate function-space variational inference. To this end, we interpret conventional categorical predictions from stochastic neural network classifiers as samples from an implicit Dirichlet distribution. By adapting the inference, the same function-space prior can be combined with different models without affecting model architecture or size. We illustrate the flexibility and efficacy of such a prior with toy experiments and demonstrate scalability, improved uncertainty quantification and adversarial robustness with large-scale image classification experiments.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#35774;&#32622;&#30340;&#22312;&#32447;&#24211;&#23384;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#32447;&#31639;&#27861;MaxCOSD&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#22312;&#32771;&#34385;&#20102;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#38656;&#27714;&#21644;&#26377;&#29366;&#24577;&#21160;&#24577;&#30340;&#24773;&#20917;&#19979;&#30340;&#26377;&#25928;&#24615;</title><link>http://arxiv.org/abs/2307.06048</link><description>&lt;p&gt;
&#22312;&#32447;&#24211;&#23384;&#38382;&#39064;&#65306;&#22312;&#32447;&#20984;&#20248;&#21270;&#20013;&#30340;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#35774;&#32622;
&lt;/p&gt;
&lt;p&gt;
Online Inventory Problems: Beyond the i.i.d. Setting with Online Convex Optimization. (arXiv:2307.06048v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06048
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#35774;&#32622;&#30340;&#22312;&#32447;&#24211;&#23384;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#32447;&#31639;&#27861;MaxCOSD&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#22312;&#32771;&#34385;&#20102;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#38656;&#27714;&#21644;&#26377;&#29366;&#24577;&#21160;&#24577;&#30340;&#24773;&#20917;&#19979;&#30340;&#26377;&#25928;&#24615;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#22810;&#20135;&#21697;&#24211;&#23384;&#25511;&#21046;&#38382;&#39064;&#65292;&#20854;&#20013;&#32463;&#29702;&#26681;&#25454;&#37096;&#20998;&#21382;&#21490;&#20449;&#24687;&#20316;&#20986;&#39034;&#24207;&#34917;&#20805;&#20915;&#31574;&#65292;&#20197;&#26368;&#23567;&#21270;&#20854;&#32047;&#31215;&#25439;&#22833;&#12290;&#25105;&#20204;&#30340;&#21160;&#26426;&#26159;&#32771;&#34385;&#21040;&#19968;&#33324;&#38656;&#27714;&#12289;&#25439;&#22833;&#21644;&#21160;&#24577;&#65292;&#36229;&#36234;&#36890;&#24120;&#20381;&#36182;&#26032;&#38395;&#20379;&#24212;&#21830;&#31867;&#22411;&#25439;&#22833;&#12289;&#22266;&#23450;&#21160;&#24577;&#21644;&#19981;&#29616;&#23454;&#30340;&#29420;&#31435;&#21516;&#20998;&#24067;&#38656;&#27714;&#20551;&#35774;&#30340;&#26631;&#20934;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;MaxCOSD&#65292;&#19968;&#20010;&#22312;&#32447;&#31639;&#27861;&#65292;&#21363;&#20351;&#23545;&#20110;&#38750;&#29420;&#31435;&#21516;&#20998;&#24067;&#38656;&#27714;&#21644;&#26377;&#29366;&#24577;&#21160;&#24577;&#65288;&#21253;&#25324;&#26131;&#33104;&#28866;&#29289;&#21697;&#65289;&#30340;&#38382;&#39064;&#65292;&#20063;&#20855;&#26377;&#21487;&#35777;&#26126;&#30340;&#20445;&#35777;&#24615;&#33021;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#25105;&#20204;&#25152;&#31216;&#30340;&#38656;&#27714;&#36807;&#31243;&#30340;&#38750;&#36864;&#21270;&#24615;&#20551;&#35774;&#65292;&#24182;&#35748;&#20026;&#23427;&#20204;&#26159;&#20801;&#35768;&#23398;&#20064;&#30340;&#24517;&#35201;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study multi-product inventory control problems where a manager makes sequential replenishment decisions based on partial historical information in order to minimize its cumulative losses. Our motivation is to consider general demands, losses and dynamics to go beyond standard models which usually rely on newsvendor-type losses, fixed dynamics, and unrealistic i.i.d. demand assumptions. We propose MaxCOSD, an online algorithm that has provable guarantees even for problems with non-i.i.d. demands and stateful dynamics, including for instance perishability. We consider what we call non-degeneracy assumptions on the demand process, and argue that they are necessary to allow learning.
&lt;/p&gt;</description></item><item><title>balance&#26159;&#19968;&#20010;&#29992;&#20110;&#20998;&#26512;&#21644;&#35843;&#25972;&#26377;&#20559;&#25968;&#25454;&#26679;&#26412;&#30340;Python&#36719;&#20214;&#21253;&#65292;&#36890;&#36807;&#35780;&#20272;&#21021;&#22987;&#20559;&#24046;&#12289;&#26681;&#25454;&#20542;&#21521;&#20998;&#25968;&#20135;&#29983;&#26435;&#37325;&#26657;&#27491;&#25968;&#25454;&#20197;&#21450;&#35780;&#20272;&#25311;&#21512;&#26435;&#37325;&#21518;&#30340;&#20559;&#24046;&#21644;&#26041;&#24046;&#33192;&#32960;&#26469;&#25552;&#20379;&#21151;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.06024</link><description>&lt;p&gt;
balance -- &#19968;&#20010;&#29992;&#20110;&#24179;&#34913;&#26377;&#20559;&#25968;&#25454;&#26679;&#26412;&#30340;Python&#36719;&#20214;&#21253;
&lt;/p&gt;
&lt;p&gt;
balance -- a Python package for balancing biased data samples. (arXiv:2307.06024v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06024
&lt;/p&gt;
&lt;p&gt;
balance&#26159;&#19968;&#20010;&#29992;&#20110;&#20998;&#26512;&#21644;&#35843;&#25972;&#26377;&#20559;&#25968;&#25454;&#26679;&#26412;&#30340;Python&#36719;&#20214;&#21253;&#65292;&#36890;&#36807;&#35780;&#20272;&#21021;&#22987;&#20559;&#24046;&#12289;&#26681;&#25454;&#20542;&#21521;&#20998;&#25968;&#20135;&#29983;&#26435;&#37325;&#26657;&#27491;&#25968;&#25454;&#20197;&#21450;&#35780;&#20272;&#25311;&#21512;&#26435;&#37325;&#21518;&#30340;&#20559;&#24046;&#21644;&#26041;&#24046;&#33192;&#32960;&#26469;&#25552;&#20379;&#21151;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35843;&#26597;&#26159;&#19968;&#31181;&#37325;&#35201;&#30340;&#30740;&#31350;&#24037;&#20855;&#65292;&#21487;&#20197;&#25552;&#20379;&#20851;&#20110;&#24773;&#24863;&#21644;&#24847;&#35265;&#31561;&#20027;&#35266;&#20307;&#39564;&#30340;&#29420;&#29305;&#27979;&#37327;&#65292;&#36825;&#20123;&#27979;&#37327;&#26080;&#27861;&#36890;&#36807;&#20854;&#20182;&#26041;&#24335;&#36827;&#34892;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#35843;&#26597;&#25968;&#25454;&#26159;&#20174;&#33258;&#24895;&#21442;&#19982;&#30340;&#20154;&#32676;&#20013;&#25910;&#38598;&#30340;&#65292;&#30452;&#25509;&#20174;&#20013;&#25512;&#26029;&#20986;&#23545;&#25152;&#20851;&#27880;&#30340;&#20154;&#32676;&#25110;&#32773;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#21487;&#33021;&#20250;&#23548;&#33268;&#38169;&#35823;&#30340;&#20272;&#35745;&#25110;&#32773;&#24615;&#33021;&#19979;&#38477;&#30340;&#27169;&#22411;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#24320;&#28304;&#30340;Python&#36719;&#20214;&#21253;balance&#65292;&#23427;&#30001;Meta&#24320;&#21457;&#65292;&#25552;&#20379;&#19968;&#20010;&#31616;&#21333;&#30340;&#24037;&#20316;&#27969;&#31243;&#26469;&#20998;&#26512;&#21644;&#26657;&#27491;&#26377;&#20559;&#25968;&#25454;&#26679;&#26412;&#65292;&#20351;&#20854;&#30456;&#23545;&#20110;&#25152;&#20851;&#27880;&#30340;&#20154;&#32676;&#20855;&#26377;&#24179;&#34913;&#24615;&#12290;balance&#24037;&#20316;&#27969;&#31243;&#21253;&#25324;&#19977;&#20010;&#27493;&#39588;&#65306;&#20102;&#35299;&#25968;&#25454;&#30340;&#21021;&#22987;&#20559;&#24046;&#65292;&#26681;&#25454;&#20542;&#21521;&#20998;&#25968;&#20026;&#26679;&#26412;&#20013;&#30340;&#27599;&#20010;&#21333;&#20301;&#20135;&#29983;&#26435;&#37325;&#20197;&#26657;&#27491;&#20559;&#24046;&#65292;&#20197;&#21450;&#22312;&#24212;&#29992;&#25311;&#21512;&#26435;&#37325;&#21518;&#35780;&#20272;&#26368;&#32456;&#20559;&#24046;&#21644;&#26041;&#24046;&#33192;&#32960;&#12290;&#35813;&#36719;&#20214;&#21253;&#25552;&#20379;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;API&#65292;&#21487;&#20197;&#29992;&#20110;...
&lt;/p&gt;
&lt;p&gt;
Surveys are an important research tool, providing unique measurements on subjective experiences such as sentiment and opinions that cannot be measured by other means. However, because survey data is collected from a self-selected group of participants, directly inferring insights from it to a population of interest, or training ML models on such data, can lead to erroneous estimates or under-performing models. In this paper we present balance, an open-source Python package by Meta, offering a simple workflow for analyzing and adjusting biased data samples with respect to a population of interest.  The balance workflow includes three steps: understanding the initial bias in the data relative to a target we would like to infer, adjusting the data to correct for the bias by producing weights for each unit in the sample based on propensity scores, and evaluating the final biases and the variance inflation after applying the fitted weights. The package provides a simple API that can be used
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#24635;&#32467;&#20102;&#32844;&#19994;&#20581;&#24247;&#20013;&#25968;&#23383;&#24037;&#20855;&#30340;&#26041;&#27861;&#21644;&#24433;&#21709;&#65292;&#31361;&#20986;&#21049;&#36710;&#21644;&#26464;&#26438;&#20197;&#21450;&#32771;&#34385;&#36741;&#21161;&#25514;&#26045;&#30340;&#21508;&#31181;&#21487;&#33021;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.05998</link><description>&lt;p&gt;
&#32844;&#19994;&#20581;&#24247;&#20013;&#30340;&#25968;&#23383;&#24037;&#20855;&#65306;&#26500;&#24314;&#22810;&#23398;&#31185;&#21160;&#24577;&#30340;&#21049;&#36710;&#36824;&#26159;&#26464;&#26438;&#65311;
&lt;/p&gt;
&lt;p&gt;
Digital tools in occupational health, brakes or levers for building multidisciplinary dynamics?. (arXiv:2307.05998v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05998
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#24635;&#32467;&#20102;&#32844;&#19994;&#20581;&#24247;&#20013;&#25968;&#23383;&#24037;&#20855;&#30340;&#26041;&#27861;&#21644;&#24433;&#21709;&#65292;&#31361;&#20986;&#21049;&#36710;&#21644;&#26464;&#26438;&#20197;&#21450;&#32771;&#34385;&#36741;&#21161;&#25514;&#26045;&#30340;&#21508;&#31181;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#23383;&#24179;&#21488;&#30340;&#20986;&#29616;&#38761;&#21629;&#20102;&#32844;&#19994;&#20581;&#24247;&#65292;&#20351;&#32844;&#19994;&#20581;&#24247;&#26381;&#21153;&#26426;&#26500;&#33021;&#22815;&#33719;&#21462;&#25968;&#25454;&#24211;&#65292;&#20026;&#19987;&#19994;&#20154;&#21592;&#25552;&#20379;&#26032;&#30340;&#34892;&#21160;&#21487;&#33021;&#24615;&#12290;&#28982;&#32780;&#65292;&#22312;&#19968;&#20010;&#25345;&#32493;20&#24180;&#36136;&#30097;&#22810;&#23398;&#31185;&#21457;&#23637;&#30340;&#39046;&#22495;&#20013;&#65292;&#26032;&#24037;&#20855;&#30340;&#21040;&#26469;&#26377;&#26102;&#30475;&#36215;&#26469;&#20687;&#26159;&#19968;&#20010;&#24555;&#36895;&#35299;&#20915;&#26041;&#26696;&#12290;&#36825;&#39033;&#22312;&#25968;&#23383;&#24037;&#20855;&#21457;&#23637;&#26041;&#38754;&#22788;&#20110;&#20808;&#39537;&#22320;&#20301;&#30340;&#32844;&#19994;&#20581;&#24247;&#26381;&#21153;&#26426;&#26500;&#30340;&#30740;&#31350;&#26088;&#22312;&#24635;&#32467;&#24037;&#20855;&#21644;&#32452;&#32455;&#21464;&#38761;&#23545;&#20581;&#24247;&#19987;&#19994;&#20154;&#21592;&#20197;&#21450;&#25216;&#26415;&#22242;&#38431;&#25104;&#21592;&#30340;&#26041;&#27861;&#21644;&#24433;&#21709;&#12290;&#36825;&#28041;&#21450;&#21040;&#31361;&#20986;&#21049;&#36710;&#21644;&#26464;&#26438;&#20197;&#21450;&#32771;&#34385;&#21508;&#31181;&#36741;&#21161;&#25514;&#26045;&#30340;&#21508;&#31181;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The arrival of digital platforms has revolutionized occupational health by giving the possibility to Occupational Health Services (SPSTI) to acquire databases to offer professionals new possibilities for action. However, in a sector of activity that has been questioning the development of multidisciplinarity for 20 years, the arrival of new tools can sometimes seem to be a quick solution. The study, conducted in a precursor SPSTI in terms of the development of digital tools, aims to take stock of the methods and impacts of instrumental and organizational transformations for health professionals as well as for members of the technical teams of the SPSTI. It is a question of highlighting the brakes and the levers as well as the various possibilities of accompaniment to consider.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22238;&#24402;&#20013;&#35299;&#20915;&#24322;&#24120;&#20540;&#26816;&#27979;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#20108;&#27425;&#38181;&#26494;&#24347;&#24418;&#24335;&#32780;&#19981;&#26159;&#20351;&#29992;big-M&#32422;&#26463;&#65292;&#36825;&#31181;&#26041;&#27861;&#27604;&#29616;&#26377;&#30340;big-M&#20844;&#24335;&#24555;&#25968;&#20010;&#25968;&#37327;&#32423;&#12290;</title><link>http://arxiv.org/abs/2307.05975</link><description>&lt;p&gt;
&#22238;&#24402;&#20013;&#30340;&#24322;&#24120;&#20540;&#26816;&#27979;&#65306;&#38181;&#20108;&#27425;&#24418;&#24335;
&lt;/p&gt;
&lt;p&gt;
Outlier detection in regression: conic quadratic formulations. (arXiv:2307.05975v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05975
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22238;&#24402;&#20013;&#35299;&#20915;&#24322;&#24120;&#20540;&#26816;&#27979;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#20108;&#27425;&#38181;&#26494;&#24347;&#24418;&#24335;&#32780;&#19981;&#26159;&#20351;&#29992;big-M&#32422;&#26463;&#65292;&#36825;&#31181;&#26041;&#27861;&#27604;&#29616;&#26377;&#30340;big-M&#20844;&#24335;&#24555;&#25968;&#20010;&#25968;&#37327;&#32423;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#65292;&#24403;&#26500;&#24314;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#26102;&#65292;&#32771;&#34385;&#21040;&#24322;&#24120;&#20540;&#30340;&#23384;&#22312;&#8212;&#8212;&#21363;&#21463;&#25439;&#30340;&#36755;&#20837;&#25968;&#25454;&#28857;&#65292;&#26159;&#24456;&#37325;&#35201;&#30340;&#12290;&#36825;&#31867;&#38382;&#39064;&#21487;&#20197;&#36890;&#36807;&#28151;&#21512;&#25972;&#25968;&#20248;&#21270;&#38382;&#39064;&#26469;&#34920;&#36798;&#65292;&#20854;&#20013;&#27599;&#20010;&#38382;&#39064;&#30001;&#20108;&#36827;&#21046;&#21464;&#37327;&#21644;&#36830;&#32493;&#21464;&#37327;&#30340;&#20108;&#27425;&#39033;&#30340;&#20056;&#31215;&#32473;&#20986;&#65292;&#24418;&#25104;&#19977;&#27425;&#39033;&#12290;&#29616;&#26377;&#30340;&#25991;&#29486;&#26041;&#27861;&#36890;&#24120;&#20381;&#38752;&#20351;&#29992;big-M&#32422;&#26463;&#32447;&#24615;&#21270;&#19977;&#27425;&#39033;&#65292;&#20294;&#22312;&#23454;&#36341;&#20013;&#34920;&#29616;&#20986;&#24369;&#25918;&#26494;&#21644;&#24615;&#33021;&#24046;&#30340;&#32570;&#28857;&#12290;&#26412;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#19981;&#28041;&#21450;big-M&#32422;&#26463;&#30340;&#20108;&#27425;&#38181;&#26494;&#24347;&#24418;&#24335;&#12290;&#25105;&#20204;&#30340;&#35745;&#31639;&#23454;&#39564;&#34920;&#26126;&#65292;&#23545;&#20110;&#36825;&#20010;&#38382;&#39064;&#65292;&#25552;&#35758;&#30340;&#20844;&#24335;&#27604;&#29616;&#26377;&#25991;&#29486;&#20013;&#30340;big-M&#20844;&#24335;&#24555;&#25968;&#20010;&#25968;&#37327;&#32423;&#12290;
&lt;/p&gt;
&lt;p&gt;
In many applications, when building linear regression models, it is important to account for the presence of outliers, i.e., corrupted input data points. Such problems can be formulated as mixed-integer optimization problems involving cubic terms, each given by the product of a binary variable and a quadratic term of the continuous variables. Existing approaches in the literature, typically relying on the linearization of the cubic terms using big-M constraints, suffer from weak relaxation and poor performance in practice. In this work we derive stronger second-order conic relaxations that do not involve big-M constraints. Our computational experiments indicate that the proposed formulations are several orders-of-magnitude faster than existing big-M formulations in the literature for this problem.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Newell&#29702;&#35770;&#30340;&#29305;&#24449;&#36716;&#25442;&#26041;&#27861;&#29992;&#20110;&#26102;&#31354;&#20132;&#36890;&#39044;&#27979;&#65292;&#29992;&#20110;&#25913;&#21892;&#27169;&#22411;&#22312;&#19981;&#21516;&#20301;&#32622;&#30340;&#36801;&#31227;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.05949</link><description>&lt;p&gt;
&#22522;&#20110;Newell&#29702;&#35770;&#30340;&#29305;&#24449;&#36716;&#25442;&#29992;&#20110;&#26102;&#31354;&#20132;&#36890;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Newell's theory based feature transformations for spatio-temporal traffic prediction. (arXiv:2307.05949v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05949
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Newell&#29702;&#35770;&#30340;&#29305;&#24449;&#36716;&#25442;&#26041;&#27861;&#29992;&#20110;&#26102;&#31354;&#20132;&#36890;&#39044;&#27979;&#65292;&#29992;&#20110;&#25913;&#21892;&#27169;&#22411;&#22312;&#19981;&#21516;&#20301;&#32622;&#30340;&#36801;&#31227;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#22312;&#26102;&#31354;&#20132;&#36890;&#27969;&#39044;&#27979;&#20013;&#20351;&#29992;&#21367;&#31215;&#25110;&#22270;&#21367;&#31215;&#36807;&#28388;&#22120;&#20197;&#21450;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#26469;&#25429;&#25417;&#20132;&#36890;&#25968;&#25454;&#30340;&#31354;&#38388;&#21644;&#26102;&#38388;&#20381;&#36182;&#20851;&#31995;&#12290;&#36825;&#20123;&#27169;&#22411;, &#22914;CNN-LSTM, &#21033;&#29992;&#37051;&#36817;&#26816;&#27979;&#31449;&#30340;&#20132;&#36890;&#27969;&#26469;&#39044;&#27979;&#29305;&#23450;&#20301;&#32622;&#30340;&#27969;&#37327;&#12290;&#28982;&#32780;, &#36825;&#20123;&#27169;&#22411;&#22312;&#25429;&#25417;&#20132;&#36890;&#31995;&#32479;&#30340;&#26356;&#24191;&#27867;&#21160;&#24577;&#26041;&#38754;&#20855;&#26377;&#23616;&#38480;&#24615;, &#22240;&#20026;&#23427;&#20204;&#20027;&#35201;&#23398;&#20064;&#29305;&#23450;&#20110;&#26816;&#27979;&#37197;&#32622;&#21644;&#30446;&#26631;&#20301;&#32622;&#20132;&#36890;&#29305;&#24449;&#30340;&#29305;&#24449;&#12290;&#22240;&#27492;, &#24403;&#22312;&#26032;&#30340;&#20301;&#32622;&#32570;&#23569;&#29992;&#20110;&#27169;&#22411;&#35757;&#32451;&#30340;&#25968;&#25454;&#26102;, &#36825;&#20123;&#27169;&#22411;&#30340;&#21487;&#36801;&#31227;&#24615;&#21464;&#24471;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;, &#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#20132;&#36890;&#27969;&#29289;&#29702;&#23398;&#30340;&#29305;&#24449;&#36716;&#25442;&#26041;&#27861;&#29992;&#20110;&#26102;&#31354;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning (DL) models for spatio-temporal traffic flow forecasting employ convolutional or graph-convolutional filters along with recurrent neural networks to capture spatial and temporal dependencies in traffic data. These models, such as CNN-LSTM, utilize traffic flows from neighboring detector stations to predict flows at a specific location of interest. However, these models are limited in their ability to capture the broader dynamics of the traffic system, as they primarily learn features specific to the detector configuration and traffic characteristics at the target location. Hence, the transferability of these models to different locations becomes challenging, particularly when data is unavailable at the new location for model training. To address this limitation, we propose a traffic flow physics-based feature transformation for spatio-temporal DL models. This transformation incorporates Newell's uncongested and congested-state estimators of traffic flows at the target loc
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#24402;&#19968;&#21270;&#22788;&#29702;&#65292;&#23454;&#29616;&#20132;&#36890;&#39044;&#27979;&#27169;&#22411;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#26356;&#39640;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2307.05946</link><description>&lt;p&gt;
&#19968;&#31181;&#36125;&#21494;&#26031;&#26041;&#27861;&#29992;&#20110;&#37327;&#21270;&#20132;&#36890;&#39044;&#27979;&#27169;&#22411;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#21644;&#25913;&#21892;&#27867;&#21270;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
A Bayesian approach to quantifying uncertainties and improving generalizability in traffic prediction models. (arXiv:2307.05946v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05946
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#24402;&#19968;&#21270;&#22788;&#29702;&#65292;&#23454;&#29616;&#20132;&#36890;&#39044;&#27979;&#27169;&#22411;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#26356;&#39640;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20132;&#36890;&#25968;&#25454;&#39044;&#27979;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#22810;&#23618;&#26550;&#26500;&#23545;&#22797;&#26434;&#20989;&#25968;&#36827;&#34892;&#20248;&#21270;&#24314;&#27169;&#65292;&#20294;&#36825;&#20123;&#26041;&#27861;&#30340;&#19968;&#20010;&#20027;&#35201;&#32570;&#28857;&#26159;&#22823;&#22810;&#25968;&#26041;&#27861;&#19981;&#25552;&#20379;&#24102;&#26377;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#39044;&#27979;&#32467;&#26524;&#65292;&#32780;&#36825;&#23545;&#20110;&#20132;&#36890;&#36816;&#33829;&#21644;&#25511;&#21046;&#26159;&#24517;&#38656;&#30340;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#65292;&#36890;&#36807;&#24341;&#20837;&#35889;&#24402;&#19968;&#21270;&#21040;&#20854;&#38544;&#34255;&#23618;&#65292;&#23454;&#29616;&#20132;&#36890;&#39044;&#27979;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#26356;&#39640;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#35770;&#25991;&#34920;&#26126;&#65292;&#24402;&#19968;&#21270;&#36890;&#36807;&#25511;&#21046;&#27169;&#22411;&#30340;&#22797;&#26434;&#24615;&#24182;&#20943;&#23569;&#23545;&#35757;&#32451;&#25968;&#25454;&#30340;&#36807;&#24230;&#25311;&#21512;&#39118;&#38505;&#65292;&#25913;&#21892;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep-learning models for traffic data prediction can have superior performance in modeling complex functions using a multi-layer architecture. However, a major drawback of these approaches is that most of these approaches do not offer forecasts with uncertainty estimates, which are essential for traffic operations and control. Without uncertainty estimates, it is difficult to place any level of trust to the model predictions, and operational strategies relying on overconfident predictions can lead to worsening traffic conditions. In this study, we propose a Bayesian recurrent neural network framework for uncertainty quantification in traffic prediction with higher generalizability by introducing spectral normalization to its hidden layers. In our paper, we have shown that normalization alters the training process of deep neural networks by controlling the model's complexity and reducing the risk of overfitting to the training data. This, in turn, helps improve the generalization perfor
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#20351;&#29992;time-dependent Cox&#27169;&#22411;&#21644;&#31070;&#32463;&#32593;&#32476;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21160;&#24577;&#39044;&#27979;&#27169;&#22411;&#26469;&#39044;&#27979;&#36827;&#34892;&#24615;&#30524;&#37096;&#30142;&#30149;&#24180;&#40836;&#30456;&#20851;&#24615;&#40644;&#26001;&#21464;&#24615;&#65288;AMD&#65289;&#30340;&#36827;&#23637;&#12290;&#36890;&#36807;&#20351;&#29992;&#32437;&#21521;&#30524;&#24213;&#22270;&#20687;&#20316;&#20026;&#36755;&#20837;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#24314;&#31435;&#19968;&#20010;&#20010;&#20307;&#21270;&#30340;&#39118;&#38505;&#39044;&#27979;&#27169;&#22411;&#65292;&#24182;&#19988;&#22312;&#23454;&#35777;&#30740;&#31350;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2307.05881</link><description>&lt;p&gt;
&#21160;&#24577;&#39044;&#27979;&#20351;&#29992;&#26102;&#21464;Cox&#29983;&#23384;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Dynamic Prediction using Time-Dependent Cox Survival Neural Network. (arXiv:2307.05881v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05881
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#20351;&#29992;time-dependent Cox&#27169;&#22411;&#21644;&#31070;&#32463;&#32593;&#32476;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21160;&#24577;&#39044;&#27979;&#27169;&#22411;&#26469;&#39044;&#27979;&#36827;&#34892;&#24615;&#30524;&#37096;&#30142;&#30149;&#24180;&#40836;&#30456;&#20851;&#24615;&#40644;&#26001;&#21464;&#24615;&#65288;AMD&#65289;&#30340;&#36827;&#23637;&#12290;&#36890;&#36807;&#20351;&#29992;&#32437;&#21521;&#30524;&#24213;&#22270;&#20687;&#20316;&#20026;&#36755;&#20837;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#24314;&#31435;&#19968;&#20010;&#20010;&#20307;&#21270;&#30340;&#39118;&#38505;&#39044;&#27979;&#27169;&#22411;&#65292;&#24182;&#19988;&#22312;&#23454;&#35777;&#30740;&#31350;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21160;&#24577;&#39044;&#27979;&#30340;&#30446;&#26631;&#26159;&#22312;&#19981;&#26029;&#26356;&#26032;&#30340;&#26032;&#25968;&#25454;&#21487;&#29992;&#26102;&#25552;&#20379;&#20010;&#20307;&#21270;&#30340;&#39118;&#38505;&#39044;&#27979;&#12290;&#21463;&#21040;&#24314;&#31435;&#19968;&#20010;&#38024;&#23545;&#36827;&#34892;&#24615;&#30524;&#37096;&#30142;&#30149;&#65292;&#24180;&#40836;&#30456;&#20851;&#24615;&#40644;&#26001;&#21464;&#24615;&#65288;AMD&#65289;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26102;&#21464;Cox&#27169;&#22411;&#30340;&#29983;&#23384;&#31070;&#32463;&#32593;&#32476;&#65288;tdCoxSNN&#65289;&#26469;&#39044;&#27979;&#20854;&#22312;&#25345;&#32493;&#26102;&#38388;&#23610;&#24230;&#19978;&#30340;&#36827;&#23637;&#65292;&#20351;&#29992;&#32437;&#21521;&#30524;&#24213;&#22270;&#20687;&#12290;tdCoxSNN&#36890;&#36807;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#26469;&#27169;&#25311;&#26102;&#21464;&#21327;&#21464;&#37327;&#23545;&#29983;&#23384;&#32467;&#26524;&#30340;&#38750;&#32447;&#24615;&#24433;&#21709;&#25193;&#23637;&#20102;&#26102;&#21464;Cox&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#32467;&#21512;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#65292;tdCoxSNN&#21487;&#20197;&#20197;&#32437;&#21521;&#21407;&#22987;&#22270;&#20687;&#20316;&#20026;&#36755;&#20837;&#12290;&#25105;&#20204;&#36890;&#36807;&#20840;&#38754;&#30340;&#27169;&#25311;&#65292;&#20351;&#29992;&#20004;&#20010;&#26102;&#21464;&#31934;&#24230;&#24230;&#37327;&#26631;&#20934;&#65292;Brier&#20998;&#25968;&#21644;&#21160;&#24577;AUC&#27604;&#36739;&#21644;&#35780;&#20272;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#19982;&#32852;&#21512;&#24314;&#27169;&#21644;&#37324;&#31243;&#30865;&#26041;&#27861;&#12290;&#25105;&#20204;&#23558;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#20004;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#12290;&#19968;&#20010;&#26159;&#19968;&#20010;&#22823;&#22411;AMD&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
The target of dynamic prediction is to provide individualized risk predictions over time which can be updated as new data become available. Motivated by establishing a dynamic prediction model for the progressive eye disease, age-related macular degeneration (AMD), we proposed a time-dependent Cox model-based survival neural network (tdCoxSNN) to predict its progression on a continuous time scale using longitudinal fundus images. tdCoxSNN extends the time-dependent Cox model by utilizing a neural network to model the non-linear effect of the time-dependent covariates on the survival outcome. Additionally, by incorporating the convolutional neural network (CNN), tdCoxSNN can take the longitudinal raw images as input. We evaluate and compare our proposed method with joint modeling and landmarking approaches through comprehensive simulations using two time-dependent accuracy metrics, the Brier Score and dynamic AUC. We applied the proposed approach to two real datasets. One is a large AMD
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38544;&#24335;&#27491;&#21017;&#21270;&#22312;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20013;&#30340;&#24212;&#29992;&#65292;&#36890;&#36807;&#21521;&#21518;&#35823;&#24046;&#20998;&#26512;&#26500;&#24314;&#36830;&#32493;&#26102;&#38388;&#27969;&#37327;&#26469;&#37327;&#21270;&#31163;&#25955;&#20248;&#21270;&#22120;&#30340;&#31163;&#25955;&#21270;&#35823;&#24046;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#20351;&#29992;BEA&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.05789</link><description>&lt;p&gt;
&#38544;&#24335;&#27491;&#21017;&#21270;&#22312;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20013;&#30340;&#24212;&#29992;&#65306;&#20174;&#21333;&#30446;&#26631;&#21040;&#21452;&#20154;&#28216;&#25103;
&lt;/p&gt;
&lt;p&gt;
Implicit regularisation in stochastic gradient descent: from single-objective to two-player games. (arXiv:2307.05789v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05789
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38544;&#24335;&#27491;&#21017;&#21270;&#22312;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20013;&#30340;&#24212;&#29992;&#65292;&#36890;&#36807;&#21521;&#21518;&#35823;&#24046;&#20998;&#26512;&#26500;&#24314;&#36830;&#32493;&#26102;&#38388;&#27969;&#37327;&#26469;&#37327;&#21270;&#31163;&#25955;&#20248;&#21270;&#22120;&#30340;&#31163;&#25955;&#21270;&#35823;&#24046;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#20351;&#29992;BEA&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#36890;&#36807;&#21457;&#29616;&#24120;&#29992;&#30340;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#22120;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#25928;&#24212;&#65292;&#20026;&#28145;&#24230;&#23398;&#20064;&#20248;&#21270;&#24102;&#26469;&#20102;&#35768;&#22810;&#26032;&#30340;&#35265;&#35299;&#12290;&#29702;&#35299;&#38544;&#24335;&#27491;&#21017;&#21270;&#19981;&#20165;&#21487;&#20197;&#25581;&#31034;&#20248;&#21270;&#21160;&#24577;&#65292;&#36824;&#21487;&#20197;&#29992;&#20110;&#25913;&#21892;&#24615;&#33021;&#21644;&#31283;&#23450;&#24615;&#65292;&#28041;&#21450;&#21040;&#20174;&#26377;&#30417;&#30563;&#23398;&#20064;&#21040;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#31561;&#38382;&#39064;&#39046;&#22495;&#30340;&#20004;&#20154;&#28216;&#25103;&#12290;&#36890;&#36807;&#21521;&#21518;&#35823;&#24046;&#20998;&#26512;&#65288;BEA&#65289;&#26500;&#24314;&#30340;&#36830;&#32493;&#26102;&#38388;&#27969;&#37327;&#26469;&#37327;&#21270;&#31163;&#25955;&#20248;&#21270;&#22120;&#30340;&#31163;&#25955;&#21270;&#35823;&#24046;&#26159;&#25214;&#21040;&#38544;&#24335;&#27491;&#21017;&#21270;&#25928;&#24212;&#30340;&#19968;&#31181;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;BEA&#30340;&#20351;&#29992;&#23384;&#22312;&#38480;&#21046;&#65292;&#22240;&#20026;&#24182;&#19981;&#26159;&#36890;&#36807;BEA&#33719;&#24471;&#30340;&#25152;&#26377;&#36830;&#32493;&#26102;&#38388;&#27969;&#30340;&#21521;&#37327;&#22330;&#37117;&#21487;&#20197;&#20889;&#25104;&#26799;&#24230;&#65292;&#36825;&#38459;&#30861;&#20102;&#26500;&#24314;&#25581;&#31034;&#38544;&#24335;&#27491;&#21017;&#21270;&#22120;&#30340;&#20462;&#27491;&#25439;&#22833;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#20351;&#29992;BEA&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22914;&#20309;&#29992;&#20110;&#26500;&#24314;&#36830;&#32493;&#26102;&#38388;&#27969;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent years have seen many insights on deep learning optimisation being brought forward by finding implicit regularisation effects of commonly used gradient-based optimisers. Understanding implicit regularisation can not only shed light on optimisation dynamics, but it can also be used to improve performance and stability across problem domains, from supervised learning to two-player games such as Generative Adversarial Networks. An avenue for finding such implicit regularisation effects has been quantifying the discretisation errors of discrete optimisers via continuous-time flows constructed by backward error analysis (BEA). The current usage of BEA is not without limitations, since not all the vector fields of continuous-time flows obtained using BEA can be written as a gradient, hindering the construction of modified losses revealing implicit regularisers. In this work, we provide a novel approach to use BEA, and show how our approach can be used to construct continuous-time flows
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38543;&#26426;&#38598;&#21512;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;RS-CNN&#65289;&#29992;&#20110;&#20998;&#31867;&#65292;&#36890;&#36807;&#39044;&#27979;&#20449;&#24565;&#20989;&#25968;&#32780;&#19981;&#26159;&#27010;&#29575;&#30690;&#37327;&#38598;&#21512;&#65292;&#20197;&#34920;&#31034;&#27169;&#22411;&#30340;&#32622;&#20449;&#24230;&#21644;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#12290;&#22522;&#20110;&#35748;&#35782;&#35770;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#27169;&#22411;&#33021;&#22815;&#20272;&#35745;&#30001;&#26377;&#38480;&#35757;&#32451;&#38598;&#24341;&#36215;&#30340;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.05772</link><description>&lt;p&gt;
&#38543;&#26426;&#38598;&#21512;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;RS-CNN&#65289;&#29992;&#20110;&#35748;&#35782;&#35770;&#28145;&#24230;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Random-Set Convolutional Neural Network (RS-CNN) for Epistemic Deep Learning. (arXiv:2307.05772v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05772
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38543;&#26426;&#38598;&#21512;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;RS-CNN&#65289;&#29992;&#20110;&#20998;&#31867;&#65292;&#36890;&#36807;&#39044;&#27979;&#20449;&#24565;&#20989;&#25968;&#32780;&#19981;&#26159;&#27010;&#29575;&#30690;&#37327;&#38598;&#21512;&#65292;&#20197;&#34920;&#31034;&#27169;&#22411;&#30340;&#32622;&#20449;&#24230;&#21644;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#12290;&#22522;&#20110;&#35748;&#35782;&#35770;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#27169;&#22411;&#33021;&#22815;&#20272;&#35745;&#30001;&#26377;&#38480;&#35757;&#32451;&#38598;&#24341;&#36215;&#30340;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#36234;&#26469;&#36234;&#22810;&#22320;&#24212;&#29992;&#20110;&#23433;&#20840;&#20851;&#38190;&#39046;&#22495;&#65292;&#23545;&#25239;&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#33267;&#20851;&#37325;&#35201;&#65292;&#38169;&#35823;&#30340;&#39044;&#27979;&#21487;&#33021;&#23548;&#33268;&#28508;&#22312;&#30340;&#28798;&#38590;&#24615;&#21518;&#26524;&#12290;&#36825;&#31361;&#20986;&#20102;&#23398;&#20064;&#31995;&#32479;&#38656;&#35201;&#33021;&#22815;&#30830;&#23450;&#27169;&#22411;&#23545;&#20854;&#39044;&#27979;&#30340;&#32622;&#20449;&#24230;&#20197;&#21450;&#19982;&#20043;&#30456;&#20851;&#32852;&#30340;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#30340;&#25163;&#27573;&#65292;&#8220;&#30693;&#36947;&#19968;&#20010;&#27169;&#22411;&#19981;&#30693;&#36947;&#8221;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29992;&#20110;&#20998;&#31867;&#30340;&#38543;&#26426;&#38598;&#21512;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;RS-CNN&#65289;&#65292;&#20854;&#39044;&#27979;&#20449;&#24565;&#20989;&#25968;&#32780;&#19981;&#26159;&#27010;&#29575;&#30690;&#37327;&#38598;&#21512;&#65292;&#20351;&#29992;&#38543;&#26426;&#38598;&#21512;&#30340;&#25968;&#23398;&#65292;&#21363;&#23545;&#26679;&#26412;&#31354;&#38388;&#30340;&#24130;&#38598;&#30340;&#20998;&#24067;&#12290;&#22522;&#20110;&#35748;&#35782;&#35770;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#38543;&#26426;&#38598;&#27169;&#22411;&#33021;&#22815;&#34920;&#31034;&#26426;&#22120;&#23398;&#20064;&#20013;&#30001;&#26377;&#38480;&#35757;&#32451;&#38598;&#24341;&#36215;&#30340;&#8220;&#35748;&#35782;&#24615;&#8221;&#19981;&#30830;&#23450;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#36817;&#20284;&#39044;&#27979;&#20449;&#24565;&#20989;&#25968;&#30456;&#20851;&#32852;&#30340;&#32622;&#20449;&#38598;&#30340;&#22823;&#23567;&#26469;&#20272;&#35745;&#35748;&#35782;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning is increasingly deployed in safety-critical domains where robustness against adversarial attacks is crucial and erroneous predictions could lead to potentially catastrophic consequences. This highlights the need for learning systems to be equipped with the means to determine a model's confidence in its prediction and the epistemic uncertainty associated with it, 'to know when a model does not know'. In this paper, we propose a novel Random-Set Convolutional Neural Network (RS-CNN) for classification which predicts belief functions rather than probability vectors over the set of classes, using the mathematics of random sets, i.e., distributions over the power set of the sample space. Based on the epistemic deep learning approach, random-set models are capable of representing the 'epistemic' uncertainty induced in machine learning by limited training sets. We estimate epistemic uncertainty by approximating the size of credal sets associated with the predicted belief func
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;Fermat&#36317;&#31163;&#30340;&#25910;&#25947;&#24615;&#36136;&#21644;&#20854;&#22312;&#32858;&#31867;&#31639;&#27861;&#20013;&#30340;&#24212;&#29992;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#31163;&#25955;&#37319;&#26679;&#30340;Fermat&#36317;&#31163;&#22312;&#23567;&#37051;&#22495;&#20013;&#25910;&#25947;&#20110;&#23427;&#20204;&#30340;&#36830;&#32493;&#27169;&#25311;&#65292;&#21516;&#26102;&#20063;&#35777;&#26126;&#20102;&#22522;&#20110;&#31163;&#25955;&#37319;&#26679;&#30340;Fermat&#36317;&#31163;&#30340;&#31163;&#25955;&#22270;&#25289;&#26222;&#25289;&#26031;&#31639;&#23376;&#25910;&#25947;&#20110;&#36830;&#32493;&#31639;&#23376;&#12290;</title><link>http://arxiv.org/abs/2307.05750</link><description>&lt;p&gt;
Fermat&#36317;&#31163;&#65306;&#24230;&#37327;&#36924;&#36817;&#12289;&#35889;&#25910;&#25947;&#21644;&#32858;&#31867;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Fermat Distances: Metric Approximation, Spectral Convergence, and Clustering Algorithms. (arXiv:2307.05750v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05750
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;Fermat&#36317;&#31163;&#30340;&#25910;&#25947;&#24615;&#36136;&#21644;&#20854;&#22312;&#32858;&#31867;&#31639;&#27861;&#20013;&#30340;&#24212;&#29992;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#31163;&#25955;&#37319;&#26679;&#30340;Fermat&#36317;&#31163;&#22312;&#23567;&#37051;&#22495;&#20013;&#25910;&#25947;&#20110;&#23427;&#20204;&#30340;&#36830;&#32493;&#27169;&#25311;&#65292;&#21516;&#26102;&#20063;&#35777;&#26126;&#20102;&#22522;&#20110;&#31163;&#25955;&#37319;&#26679;&#30340;Fermat&#36317;&#31163;&#30340;&#31163;&#25955;&#22270;&#25289;&#26222;&#25289;&#26031;&#31639;&#23376;&#25910;&#25947;&#20110;&#36830;&#32493;&#31639;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20998;&#26512;&#20102;Fermat&#36317;&#31163;&#30340;&#25910;&#25947;&#24615;&#36136;&#65292;&#36825;&#26159;&#19968;&#31867;&#22312;&#20855;&#26377;&#20851;&#32852;&#27010;&#29575;&#27979;&#24230;&#30340;Riemann&#27969;&#24418;&#19978;&#23450;&#20041;&#30340;&#23494;&#24230;&#39537;&#21160;&#24230;&#37327;&#12290;Fermat&#36317;&#31163;&#21487;&#20197;&#22312;&#31163;&#25955;&#37319;&#26679;&#19978;&#23450;&#20041;&#65292;&#27492;&#26102;&#23427;&#20204;&#26159;&#38543;&#26426;&#30340;&#65307;&#20063;&#21487;&#20197;&#22312;&#36830;&#32493;&#35774;&#32622;&#20013;&#23450;&#20041;&#65292;&#27492;&#26102;&#23427;&#20204;&#30001;&#23494;&#24230;&#25197;&#26354;&#30340;Riemann&#24230;&#37327;&#19979;&#30340;&#27979;&#22320;&#32447;&#23548;&#20986;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22522;&#20110;&#31163;&#25955;&#37319;&#26679;&#30340;Fermat&#36317;&#31163;&#22312;&#23567;&#37051;&#22495;&#20013;&#25910;&#25947;&#20110;&#23427;&#20204;&#30340;&#36830;&#32493;&#27169;&#25311;&#65292;&#25910;&#25947;&#36895;&#29575;&#21462;&#20915;&#20110;&#25968;&#25454;&#30340;&#20869;&#22312;&#32500;&#24230;&#21644;Fermat&#36317;&#31163;&#20013;&#23494;&#24230;&#21152;&#26435;&#30340;&#21442;&#25968;&#12290;&#36825;&#26159;&#36890;&#36807;&#21033;&#29992;&#26032;&#39062;&#30340;&#20960;&#20309;&#21644;&#32479;&#35745;&#35770;&#35777;&#22312;&#28183;&#27969;&#29702;&#35770;&#20013;&#20801;&#35768;&#38750;&#22343;&#21248;&#23494;&#24230;&#21644;&#26354;&#38754;&#22495;&#30340;&#26041;&#27861;&#23436;&#25104;&#30340;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;&#36825;&#20123;&#32467;&#26524;&#35777;&#26126;&#20102;&#22522;&#20110;&#31163;&#25955;&#65292;&#37319;&#26679;&#39537;&#21160;&#30340;Fermat&#36317;&#31163;&#30340;&#31163;&#25955;&#22270;&#25289;&#26222;&#25289;&#26031;&#31639;&#23376;&#25910;&#25947;&#20110;&#30456;&#24212;&#30340;&#36830;&#32493;&#31639;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;
We analyze the convergence properties of Fermat distances, a family of density-driven metrics defined on Riemannian manifolds with an associated probability measure. Fermat distances may be defined either on discrete samples from the underlying measure, in which case they are random, or in the continuum setting, in which they are induced by geodesics under a density-distorted Riemannian metric. We prove that discrete, sample-based Fermat distances converge to their continuum analogues in small neighborhoods with a precise rate that depends on the intrinsic dimensionality of the data and the parameter governing the extent of density weighting in Fermat distances. This is done by leveraging novel geometric and statistical arguments in percolation theory that allow for non-uniform densities and curved domains. Our results are then used to prove that discrete graph Laplacians based on discrete, sample-driven Fermat distances converge to corresponding continuum operators. In particular, we 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#36890;&#36807;&#20999;&#29255;&#21644;&#37197;&#20934;&#36807;&#31243;&#23450;&#20041;&#30340;&#27979;&#37327;&#36716;&#31227;&#21644;&#36924;&#36817;&#38382;&#39064;&#30340;&#36845;&#20195;&#26041;&#26696;&#65292;&#24182;&#23545;&#38543;&#26426;&#20999;&#29255;&#21644;&#37197;&#20934;&#26041;&#26696;&#25552;&#20379;&#20102;&#20960;&#20046;&#24517;&#28982;&#25910;&#25947;&#30340;&#35777;&#26126;&#12290;</title><link>http://arxiv.org/abs/2307.05705</link><description>&lt;p&gt;
&#36890;&#36807;&#38543;&#26426;&#20999;&#29255;&#21644;&#37197;&#20934;&#36827;&#34892;&#27979;&#37327;&#36716;&#31227;
&lt;/p&gt;
&lt;p&gt;
Measure transfer via stochastic slicing and matching. (arXiv:2307.05705v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05705
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#36890;&#36807;&#20999;&#29255;&#21644;&#37197;&#20934;&#36807;&#31243;&#23450;&#20041;&#30340;&#27979;&#37327;&#36716;&#31227;&#21644;&#36924;&#36817;&#38382;&#39064;&#30340;&#36845;&#20195;&#26041;&#26696;&#65292;&#24182;&#23545;&#38543;&#26426;&#20999;&#29255;&#21644;&#37197;&#20934;&#26041;&#26696;&#25552;&#20379;&#20102;&#20960;&#20046;&#24517;&#28982;&#25910;&#25947;&#30340;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#36890;&#36807;&#20999;&#29255;&#21644;&#37197;&#20934;&#36807;&#31243;&#23450;&#20041;&#30340;&#27979;&#37327;&#36716;&#31227;&#21644;&#36924;&#36817;&#38382;&#39064;&#30340;&#36845;&#20195;&#26041;&#26696;&#12290;&#31867;&#20284;&#20110;&#20999;&#29255;Wasserstein&#36317;&#31163;&#65292;&#36825;&#20123;&#26041;&#26696;&#21463;&#30410;&#20110;&#19968;&#32500;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#30340;&#38381;&#24335;&#35299;&#30340;&#21487;&#29992;&#24615;&#21644;&#30456;&#20851;&#35745;&#31639;&#20248;&#21183;&#12290;&#23613;&#31649;&#36825;&#20123;&#26041;&#26696;&#24050;&#32463;&#22312;&#25968;&#25454;&#31185;&#23398;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#25104;&#21151;&#65292;&#20294;&#20851;&#20110;&#23427;&#20204;&#30340;&#25910;&#25947;&#24615;&#30340;&#32467;&#26524;&#19981;&#22826;&#22810;&#12290;&#26412;&#25991;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#23545;&#38543;&#26426;&#20999;&#29255;&#21644;&#37197;&#20934;&#26041;&#26696;&#25552;&#20379;&#20102;&#20960;&#20046;&#24517;&#28982;&#25910;&#25947;&#30340;&#35777;&#26126;&#12290;&#35813;&#35777;&#26126;&#24314;&#31435;&#22312;&#23558;&#20854;&#35299;&#37322;&#20026;Wasserstein&#31354;&#38388;&#19978;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#26696;&#30340;&#22522;&#30784;&#20043;&#19978;&#12290;&#21516;&#26102;&#36824;&#23637;&#31034;&#20102;&#20851;&#20110;&#36880;&#27493;&#22270;&#20687;&#21464;&#24418;&#30340;&#25968;&#20540;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies iterative schemes for measure transfer and approximation problems, which are defined through a slicing-and-matching procedure. Similar to the sliced Wasserstein distance, these schemes benefit from the availability of closed-form solutions for the one-dimensional optimal transport problem and the associated computational advantages. While such schemes have already been successfully utilized in data science applications, not too many results on their convergence are available. The main contribution of this paper is an almost sure convergence proof for stochastic slicing-and-matching schemes. The proof builds on an interpretation as a stochastic gradient descent scheme on the Wasserstein space. Numerical examples on step-wise image morphing are demonstrated as well.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#25913;&#30340;&#24452;&#21521;&#22522;&#20989;&#25968;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#36890;&#36807;&#23398;&#20064;&#31934;&#24230;&#30697;&#38453;&#65292;&#20174;&#35757;&#32451;&#23436;&#25104;&#21518;&#30340;&#27169;&#22411;&#20013;&#25552;&#21462;&#26377;&#29992;&#20449;&#24687;&#65292;&#21253;&#25324;&#27963;&#36291;&#23376;&#31354;&#38388;&#30340;&#26041;&#21521;&#21644;&#36755;&#20837;&#21464;&#37327;&#37325;&#35201;&#24615;&#30340;&#25490;&#24207;&#12290;</title><link>http://arxiv.org/abs/2307.05639</link><description>&lt;p&gt;
&#20351;&#29992;&#39640;&#26031;&#24452;&#21521;&#22522;&#20989;&#25968;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#27963;&#36291;&#23376;&#31354;&#38388;&#24182;&#21457;&#29616;&#37325;&#35201;&#29305;&#24449;
&lt;/p&gt;
&lt;p&gt;
Learning Active Subspaces and Discovering Important Features with Gaussian Radial Basis Functions Neural Networks. (arXiv:2307.05639v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05639
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#25913;&#30340;&#24452;&#21521;&#22522;&#20989;&#25968;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#36890;&#36807;&#23398;&#20064;&#31934;&#24230;&#30697;&#38453;&#65292;&#20174;&#35757;&#32451;&#23436;&#25104;&#21518;&#30340;&#27169;&#22411;&#20013;&#25552;&#21462;&#26377;&#29992;&#20449;&#24687;&#65292;&#21253;&#25324;&#27963;&#36291;&#23376;&#31354;&#38388;&#30340;&#26041;&#21521;&#21644;&#36755;&#20837;&#21464;&#37327;&#37325;&#35201;&#24615;&#30340;&#25490;&#24207;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25552;&#20379;&#19968;&#20010;&#26082;&#33021;&#36798;&#21040;&#24378;&#22823;&#39044;&#27979;&#24615;&#33021;&#65292;&#21448;&#33021;&#34987;&#20154;&#31867;&#35299;&#37322;&#30340;&#27169;&#22411;&#26159;&#26426;&#22120;&#23398;&#20064;&#30740;&#31350;&#20013;&#26368;&#22256;&#38590;&#30340;&#25361;&#25112;&#20043;&#19968;&#65292;&#30001;&#20110;&#36825;&#20004;&#20010;&#30446;&#26631;&#30340;&#20914;&#31361;&#24615;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#25913;&#30340;&#24452;&#21521;&#22522;&#20989;&#25968;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#36890;&#36807;&#20026;&#20854;&#39640;&#26031;&#26680;&#28155;&#21152;&#21487;&#23398;&#20064;&#30340;&#31934;&#24230;&#30697;&#38453;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#35757;&#32451;&#23436;&#25104;&#21518;&#21487;&#20197;&#20174;&#31934;&#24230;&#30697;&#38453;&#30340;&#35889;&#20013;&#25552;&#21462;&#23453;&#36149;&#30340;&#20449;&#24687;&#12290;&#29305;&#21035;&#26159;&#65292;&#29305;&#24449;&#21521;&#37327;&#35299;&#37322;&#20102;&#27169;&#22411;&#26368;&#25935;&#24863;&#30340;&#26041;&#21521;&#65292;&#25581;&#31034;&#20102;&#27963;&#36291;&#23376;&#31354;&#38388;&#65292;&#24182;&#25552;&#20986;&#20102;&#29992;&#20110;&#30417;&#30563;&#38477;&#32500;&#30340;&#28508;&#22312;&#24212;&#29992;&#12290;&#21516;&#26102;&#65292;&#29305;&#24449;&#21521;&#37327;&#20984;&#26174;&#20102;&#36755;&#20837;&#21644;&#28508;&#22312;&#21464;&#37327;&#20043;&#38388;&#30340;&#32477;&#23545;&#21464;&#21270;&#20851;&#31995;&#65292;&#20174;&#32780;&#20351;&#25105;&#20204;&#33021;&#22815;&#22522;&#20110;&#20854;&#23545;&#39044;&#27979;&#30340;&#37325;&#35201;&#24615;&#25552;&#21462;&#36755;&#20837;&#21464;&#37327;&#30340;&#25490;&#24207;&#12290;
&lt;/p&gt;
&lt;p&gt;
Providing a model that achieves a strong predictive performance and at the same time is interpretable by humans is one of the most difficult challenges in machine learning research due to the conflicting nature of these two objectives. To address this challenge, we propose a modification of the Radial Basis Function Neural Network model by equipping its Gaussian kernel with a learnable precision matrix. We show that precious information is contained in the spectrum of the precision matrix that can be extracted once the training of the model is completed. In particular, the eigenvectors explain the directions of maximum sensitivity of the model revealing the active subspace and suggesting potential applications for supervised dimensionality reduction. At the same time, the eigenvectors highlight the relationship in terms of absolute variation between the input and the latent variables, thereby allowing us to extract a ranking of the input variables based on their importance to the predi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;LS-PIE&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#25552;&#39640;&#32447;&#24615;&#28508;&#22312;&#31354;&#38388;&#30340;&#35299;&#37322;&#33021;&#21147;&#12290;&#35813;&#26694;&#26550;&#36890;&#36807;&#33258;&#21160;&#21270;&#28508;&#22312;&#21521;&#37327;&#30340;&#32858;&#31867;&#21644;&#25490;&#24207;&#65292;&#20174;&#32780;&#25913;&#21892;&#20102;&#20027;&#25104;&#20998;&#20998;&#26512;&#12289;&#29420;&#31435;&#25104;&#20998;&#20998;&#26512;&#31561;&#32447;&#24615;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.05620</link><description>&lt;p&gt;
&#28508;&#22312;&#31354;&#38388;&#27934;&#23519;&#21147;&#21644;&#35299;&#37322;&#22686;&#24378;&#65288;LS-PIE&#65289;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Latent Space Perspicacity and Interpretation Enhancement (LS-PIE) Framework. (arXiv:2307.05620v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05620
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21517;&#20026;LS-PIE&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#25552;&#39640;&#32447;&#24615;&#28508;&#22312;&#31354;&#38388;&#30340;&#35299;&#37322;&#33021;&#21147;&#12290;&#35813;&#26694;&#26550;&#36890;&#36807;&#33258;&#21160;&#21270;&#28508;&#22312;&#21521;&#37327;&#30340;&#32858;&#31867;&#21644;&#25490;&#24207;&#65292;&#20174;&#32780;&#25913;&#21892;&#20102;&#20027;&#25104;&#20998;&#20998;&#26512;&#12289;&#29420;&#31435;&#25104;&#20998;&#20998;&#26512;&#31561;&#32447;&#24615;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32447;&#24615;&#28508;&#21464;&#37327;&#27169;&#22411;&#22914;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#12289;&#29420;&#31435;&#25104;&#20998;&#20998;&#26512;&#65288;ICA&#65289;&#12289;&#20856;&#22411;&#30456;&#20851;&#20998;&#26512;&#65288;CCA&#65289;&#21644;&#22240;&#23376;&#20998;&#26512;&#65288;FA&#65289;&#36890;&#24120;&#20250;&#35782;&#21035;&#26377;&#24207;&#25110;&#26080;&#24207;&#30340;&#28508;&#22312;&#26041;&#21521;&#65288;&#25110;&#36733;&#33655;&#65289;&#12290;&#28982;&#21518;&#23558;&#25968;&#25454;&#25237;&#24433;&#21040;&#28508;&#22312;&#26041;&#21521;&#19978;&#20197;&#33719;&#24471;&#23427;&#20204;&#30340;&#25237;&#24433;&#34920;&#31034;&#65288;&#25110;&#24471;&#20998;&#65289;&#12290;&#28982;&#32780;&#65292;ICA&#27714;&#35299;&#22120;&#36890;&#24120;&#26080;&#24207;&#22320;&#36820;&#22238;&#29420;&#31435;&#26041;&#21521;&#65292;&#24182;&#19988;&#24448;&#24448;&#23558;&#21333;&#19968;&#28304;&#20998;&#24067;&#22312;&#22810;&#20010;&#26041;&#21521;&#19978;&#20316;&#20026;&#22810;&#20010;&#23376;&#28304;&#65292;&#36825;&#23545;&#20110;&#20854;&#21487;&#29992;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#24456;&#19981;&#21033;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#22686;&#24378;&#32447;&#24615;&#28508;&#22312;&#31354;&#38388;&#30340;&#35299;&#37322;&#33021;&#21147;&#12290;&#23613;&#31649;&#26412;&#25991;&#20171;&#32461;&#30340;&#27010;&#24565;&#19982;&#35821;&#35328;&#26080;&#20851;&#65292;&#20294;&#35813;&#26694;&#26550;&#26159;&#29992;Python&#32534;&#20889;&#30340;&#12290;&#35813;&#26694;&#26550;&#33258;&#21160;&#21270;&#20102;&#28508;&#22312;&#21521;&#37327;&#30340;&#32858;&#31867;&#21644;&#25490;&#24207;&#65292;&#20197;&#22686;&#24378;&#35299;&#37322;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Linear latent variable models such as principal component analysis (PCA), independent component analysis (ICA), canonical correlation analysis (CCA), and factor analysis (FA) identify latent directions (or loadings) either ordered or unordered. The data is then projected onto the latent directions to obtain their projected representations (or scores). For example, PCA solvers usually rank the principal directions by explaining the most to least variance, while ICA solvers usually return independent directions unordered and often with single sources spread across multiple directions as multiple sub-sources, which is of severe detriment to their usability and interpretability.  This paper proposes a general framework to enhance latent space representations for improving the interpretability of linear latent spaces. Although the concepts in this paper are language agnostic, the framework is written in Python. This framework automates the clustering and ranking of latent vectors to enhance
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#23558;&#32452;&#21512;&#24615;&#27867;&#21270;&#35270;&#20026;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#30340;&#23646;&#24615;&#65292;&#36890;&#36807;&#23548;&#20986;&#23545;&#35757;&#32451;&#20998;&#24067;&#25903;&#25345;&#21644;&#27169;&#22411;&#26550;&#26500;&#30340;&#26465;&#20214;&#35201;&#27714;&#65292;&#23454;&#29616;&#20102;&#32452;&#21512;&#24615;&#27867;&#21270;&#12290;&#23545;&#20110;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#32452;&#21512;&#24615;&#27867;&#21270;&#38382;&#39064;&#25552;&#20379;&#20102;&#29702;&#35770;&#24615;&#30340;&#30740;&#31350;&#22522;&#30784;&#12290;</title><link>http://arxiv.org/abs/2307.05596</link><description>&lt;p&gt;
&#20174;&#31532;&#19968;&#21407;&#29702;&#20013;&#23454;&#29616;&#32452;&#21512;&#24615;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Compositional Generalization from First Principles. (arXiv:2307.05596v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05596
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#23558;&#32452;&#21512;&#24615;&#27867;&#21270;&#35270;&#20026;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#30340;&#23646;&#24615;&#65292;&#36890;&#36807;&#23548;&#20986;&#23545;&#35757;&#32451;&#20998;&#24067;&#25903;&#25345;&#21644;&#27169;&#22411;&#26550;&#26500;&#30340;&#26465;&#20214;&#35201;&#27714;&#65292;&#23454;&#29616;&#20102;&#32452;&#21512;&#24615;&#27867;&#21270;&#12290;&#23545;&#20110;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#32452;&#21512;&#24615;&#27867;&#21270;&#38382;&#39064;&#25552;&#20379;&#20102;&#29702;&#35770;&#24615;&#30340;&#30740;&#31350;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;&#25105;&#20204;&#19990;&#30028;&#30340;&#32452;&#21512;&#24615;&#36136;&#21152;&#24555;&#23398;&#20064;&#21644;&#20419;&#36827;&#27867;&#21270;&#26159;&#20154;&#31867;&#24863;&#30693;&#30340;&#19968;&#20010;&#29305;&#28857;&#12290;&#28982;&#32780;&#65292;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#21363;&#20351;&#23545;&#20110;&#20855;&#26377;&#26126;&#30830;&#32452;&#21512;&#24615;&#20808;&#39564;&#30340;&#27169;&#22411;&#65292;&#23454;&#29616;&#32452;&#21512;&#24615;&#27867;&#21270;&#20063;&#26159;&#19968;&#20010;&#38590;&#20197;&#23454;&#29616;&#30340;&#30446;&#26631;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#29702;&#35299;&#32452;&#21512;&#24615;&#27867;&#21270;&#65292;&#25105;&#20204;&#20174;&#24213;&#23618;&#24320;&#22987;&#36827;&#34892;&#25506;&#32034;&#65306;&#21463;&#21487;&#35782;&#21035;&#34920;&#31034;&#23398;&#20064;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#30740;&#31350;&#32452;&#21512;&#24615;&#20316;&#20026;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#30340;&#23646;&#24615;&#65292;&#32780;&#19981;&#26159;&#25968;&#25454;&#26412;&#36523;&#12290;&#36825;&#31181;&#25913;&#36827;&#20351;&#25105;&#20204;&#33021;&#22815;&#23548;&#20986;&#20165;&#23545;&#35757;&#32451;&#20998;&#24067;&#30340;&#25903;&#25345;&#21644;&#27169;&#22411;&#26550;&#26500;&#26377;&#36731;&#24494;&#26465;&#20214;&#30340;&#35201;&#27714;&#65292;&#36825;&#20123;&#26465;&#20214;&#36275;&#20197;&#23454;&#29616;&#32452;&#21512;&#24615;&#27867;&#21270;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#26694;&#26550;&#22914;&#20309;&#24212;&#29992;&#20110;&#29616;&#23454;&#22330;&#26223;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#23454;&#20102;&#25105;&#20204;&#30340;&#21457;&#29616;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20026;&#32452;&#21512;&#24615;&#27867;&#21270;&#30340;&#21407;&#21017;&#24615;&#29702;&#35770;&#30740;&#31350;&#22880;&#23450;&#20102;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
Leveraging the compositional nature of our world to expedite learning and facilitate generalization is a hallmark of human perception. In machine learning, on the other hand, achieving compositional generalization has proven to be an elusive goal, even for models with explicit compositional priors. To get a better handle on compositional generalization, we here approach it from the bottom up: Inspired by identifiable representation learning, we investigate compositionality as a property of the data-generating process rather than the data itself. This reformulation enables us to derive mild conditions on only the support of the training distribution and the model architecture, which are sufficient for compositional generalization. We further demonstrate how our theoretical framework applies to real-world scenarios and validate our findings empirically. Our results set the stage for a principled theoretical study of compositional generalization.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21151;&#33021;&#20027;&#25104;&#20998;&#20998;&#26512;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#36870;UQ&#36807;&#31243;&#65292;&#29992;&#20110;&#26102;&#38388;&#30456;&#20851;&#21709;&#24212;&#30340;&#27169;&#22411;&#36755;&#20837;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#24182;&#36890;&#36807;&#21151;&#33021;&#23545;&#40784;&#26041;&#27861;&#35299;&#20915;&#20102;PCT&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#30340;&#28201;&#24230;&#19979;&#38477;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.05592</link><description>&lt;p&gt;
&#22522;&#20110;&#21151;&#33021;&#20027;&#25104;&#20998;&#20998;&#26512;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#22522;&#20110;&#36125;&#21494;&#26031;&#30340;&#36870;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#19982;&#30636;&#24577;&#23454;&#39564;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Functional PCA and Deep Neural Networks-based Bayesian Inverse Uncertainty Quantification with Transient Experimental Data. (arXiv:2307.05592v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05592
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21151;&#33021;&#20027;&#25104;&#20998;&#20998;&#26512;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#36870;UQ&#36807;&#31243;&#65292;&#29992;&#20110;&#26102;&#38388;&#30456;&#20851;&#21709;&#24212;&#30340;&#27169;&#22411;&#36755;&#20837;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#24182;&#36890;&#36807;&#21151;&#33021;&#23545;&#40784;&#26041;&#27861;&#35299;&#20915;&#20102;PCT&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#30340;&#28201;&#24230;&#19979;&#38477;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36870;UQ&#26159;&#22522;&#20110;&#23454;&#39564;&#25968;&#25454;&#23545;&#27169;&#22411;&#36755;&#20837;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#36870;&#21521;&#37327;&#21270;&#30340;&#36807;&#31243;&#12290;&#26412;&#30740;&#31350;&#37325;&#28857;&#21457;&#23637;&#20102;&#19968;&#31181;&#38024;&#23545;&#26102;&#38388;&#30456;&#20851;&#21709;&#24212;&#30340;&#36870;UQ&#36807;&#31243;&#65292;&#21033;&#29992;&#21151;&#33021;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#21644;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#30340;&#20195;&#29702;&#27169;&#22411;&#36827;&#34892;&#38477;&#32500;&#12290;&#35813;&#28436;&#31034;&#22522;&#20110;&#20351;&#29992;FEBA&#30636;&#24577;&#23454;&#39564;&#25968;&#25454;&#26469;&#36870;&#21521;&#37327;&#21270;TRACE&#29289;&#29702;&#27169;&#22411;&#21442;&#25968;&#65292;&#27979;&#37327;&#25968;&#25454;&#26159;&#26102;&#38388;&#30456;&#20851;&#30340;&#26368;&#39640;&#21253;&#35206;&#28201;&#24230;&#65288;PCT&#65289;&#12290;&#30001;&#20110;&#24863;&#20852;&#36259;&#30340;&#25968;&#37327;&#65288;QoI&#65289;&#26159;&#26102;&#38388;&#30456;&#20851;&#30340;&#65292;&#23545;&#24212;&#20110;&#26080;&#38480;&#32500;&#21709;&#24212;&#65292;&#22240;&#27492;&#20351;&#29992;PCA&#23545;QoI&#32500;&#24230;&#36827;&#34892;&#38477;&#20302;&#65292;&#21516;&#26102;&#20445;&#30041;PCT&#30340;&#30636;&#24577;&#29305;&#24449;&#65292;&#20197;&#20351;&#36870;UQ&#36807;&#31243;&#26356;&#21152;&#39640;&#25928;&#12290;&#28982;&#32780;&#65292;&#30452;&#25509;&#24212;&#29992;&#20256;&#32479;PCA&#21040;PCT&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#26080;&#27861;&#20934;&#30830;&#34920;&#31034;&#25968;&#25454;&#65292;&#22240;&#20026;&#22312;&#28140;&#28781;&#26102;&#21051;&#20250;&#20986;&#29616;&#31361;&#28982;&#30340;&#28201;&#24230;&#19979;&#38477;&#12290;&#22240;&#27492;&#65292;&#37319;&#29992;&#20102;&#19968;&#31181;&#21151;&#33021;&#23545;&#40784;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Inverse UQ is the process to inversely quantify the model input uncertainties based on experimental data. This work focuses on developing an inverse UQ process for time-dependent responses, using dimensionality reduction by functional principal component analysis (PCA) and deep neural network (DNN)-based surrogate models. The demonstration is based on the inverse UQ of TRACE physical model parameters using the FEBA transient experimental data. The measurement data is time-dependent peak cladding temperature (PCT). Since the quantity-of-interest (QoI) is time-dependent that corresponds to infinite-dimensional responses, PCA is used to reduce the QoI dimension while preserving the transient profile of the PCT, in order to make the inverse UQ process more efficient. However, conventional PCA applied directly to the PCT time series profiles can hardly represent the data precisely due to the sudden temperature drop at the time of quenching. As a result, a functional alignment method is used
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#21033;&#29992;&#21518;&#39564;&#25910;&#32553;&#24615;&#36136;&#30340;&#39640;&#25928;&#25277;&#26679;&#31639;&#27861;&#65292;&#20854;&#20013;&#30740;&#31350;&#20102;&#20855;&#26377;&#20248;&#21183;&#30340;&#39640;&#26031;Spike-and-Slab&#30340;&#20934;&#20284;&#28982;&#20989;&#25968;&#65292;&#24182;&#36890;&#36807;&#20004;&#31181;&#31639;&#27861;&#23454;&#29616;&#20102;&#23545;&#31232;&#30095;&#20449;&#21495;&#30340;&#26377;&#25928;&#25512;&#26029;&#12290;</title><link>http://arxiv.org/abs/2307.05558</link><description>&lt;p&gt;
&#20174;&#20272;&#35745;&#21040;&#25277;&#26679;&#65306;&#20855;&#26377;Spike-and-Slab&#20808;&#39564;&#30340;&#36125;&#21494;&#26031;&#32447;&#24615;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
From Estimation to Sampling for Bayesian Linear Regression with Spike-and-Slab Prior. (arXiv:2307.05558v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.05558
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#21033;&#29992;&#21518;&#39564;&#25910;&#32553;&#24615;&#36136;&#30340;&#39640;&#25928;&#25277;&#26679;&#31639;&#27861;&#65292;&#20854;&#20013;&#30740;&#31350;&#20102;&#20855;&#26377;&#20248;&#21183;&#30340;&#39640;&#26031;Spike-and-Slab&#30340;&#20934;&#20284;&#28982;&#20989;&#25968;&#65292;&#24182;&#36890;&#36807;&#20004;&#31181;&#31639;&#27861;&#23454;&#29616;&#20102;&#23545;&#31232;&#30095;&#20449;&#21495;&#30340;&#26377;&#25928;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#20855;&#26377;&#31232;&#30095;&#35825;&#23548;&#20808;&#39564;&#30340;&#36125;&#21494;&#26031;&#32447;&#24615;&#22238;&#24402;&#65292;&#24182;&#35774;&#35745;&#20102;&#21033;&#29992;&#21518;&#39564;&#25910;&#32553;&#24615;&#36136;&#30340;&#39640;&#25928;&#25277;&#26679;&#31639;&#27861;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#39640;&#26031;Spike-and-Slab&#65288;&#22312;&#32479;&#35745;&#21644;&#35745;&#31639;&#26041;&#38754;&#37117;&#20855;&#26377;&#20248;&#21183;&#65289;&#30340;&#20934;&#20284;&#28982;&#20989;&#25968;&#65292;&#24182;&#20998;&#26512;&#20102;&#22522;&#20110;Gibbs&#25277;&#26679;&#21644;&#38543;&#26426;&#23450;&#20301;&#30340;&#20004;&#31181;&#31639;&#27861;&#65292;&#20004;&#32773;&#37117;&#22522;&#20110;&#30456;&#21516;&#65288;&#30456;&#24403;&#33258;&#28982;&#65289;&#30340;&#32479;&#35745;&#20551;&#35774;&#65292;&#36824;&#21487;&#20197;&#23545;&#31232;&#30095;&#20449;&#21495;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#12290;&#38543;&#26426;&#23450;&#20301;&#25277;&#26679;&#22120;&#23588;&#20854;&#36866;&#29992;&#20110;&#35774;&#35745;&#19981;&#33391;&#30340;&#25968;&#25454;&#30697;&#38453;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider Bayesian linear regression with sparsity-inducing prior and design efficient sampling algorithms leveraging posterior contraction properties. A quasi-likelihood with Gaussian spike-and-slab (that is favorable both statistically and computationally) is investigated and two algorithms based on Gibbs sampling and Stochastic Localization are analyzed, both under the same (quite natural) statistical assumptions that also enable valid inference on the sparse planted signal. The benefit of the Stochastic Localization sampler is particularly prominent for data matrix that is not well-designed.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#21644;&#36125;&#21494;&#26031;&#26041;&#27861;&#30340;&#32593;&#32476;&#27169;&#22411;&#65292;&#36890;&#36807;&#33945;&#29305;&#21345;&#32599;&#21644;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#37319;&#26679;&#32593;&#32476;&#32467;&#26500;&#30340;&#21518;&#39564;&#20998;&#24067;&#12290;&#35813;&#26041;&#27861;&#22312;&#24674;&#22797;&#32593;&#32476;&#30340;&#22270;&#24418;&#32467;&#26500;&#26041;&#38754;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#21518;&#39564;&#27010;&#29575;&#30340;&#20934;&#30830;&#36817;&#20284;&#12290;</title><link>http://arxiv.org/abs/2306.11380</link><description>&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#32593;&#32476;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Bayesian Take on Gaussian Process Networks. (arXiv:2306.11380v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11380
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#21644;&#36125;&#21494;&#26031;&#26041;&#27861;&#30340;&#32593;&#32476;&#27169;&#22411;&#65292;&#36890;&#36807;&#33945;&#29305;&#21345;&#32599;&#21644;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#37319;&#26679;&#32593;&#32476;&#32467;&#26500;&#30340;&#21518;&#39564;&#20998;&#24067;&#12290;&#35813;&#26041;&#27861;&#22312;&#24674;&#22797;&#32593;&#32476;&#30340;&#22270;&#24418;&#32467;&#26500;&#26041;&#38754;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#21518;&#39564;&#27010;&#29575;&#30340;&#20934;&#30830;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#32593;&#32476;&#65288;GPNs&#65289;&#26159;&#19968;&#31867;&#26377;&#21521;&#22270;&#27169;&#22411;&#65292;&#20854;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#20316;&#20026;&#32593;&#32476;&#20013;&#27599;&#20010;&#21464;&#37327;&#32473;&#23450;&#20854;&#29238;&#21464;&#37327;&#30340;&#26465;&#20214;&#26399;&#26395;&#30340;&#20808;&#39564;&#20998;&#24067;&#12290;&#35813;&#27169;&#22411;&#20801;&#35768;&#20197;&#32039;&#20945;&#20294;&#28789;&#27963;&#30340;&#26041;&#24335;&#25551;&#36848;&#36830;&#32493;&#32852;&#21512;&#20998;&#24067;&#65292;&#23545;&#21464;&#37327;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#20165;&#20570;&#26368;&#23569;&#30340;&#21442;&#25968;&#20551;&#35774;&#12290;GPNs&#30340;&#36125;&#21494;&#26031;&#32467;&#26500;&#23398;&#20064;&#38656;&#35201;&#35745;&#31639;&#32593;&#32476;&#32467;&#26500;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#21363;&#20351;&#22312;&#20302;&#32500;&#24773;&#20917;&#19979;&#65292;&#36825;&#20063;&#26159;&#35745;&#31639;&#19978;&#19981;&#21487;&#34892;&#30340;&#12290;&#26412;&#25991;&#23454;&#29616;&#20102;&#33945;&#29305;&#21345;&#32599;&#21644;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#26469;&#20174;&#32593;&#32476;&#32467;&#26500;&#30340;&#21518;&#39564;&#20998;&#24067;&#20013;&#37319;&#26679;&#12290;&#22240;&#27492;&#65292;&#35813;&#26041;&#27861;&#36981;&#24490;&#36125;&#21494;&#26031;&#33539;&#24335;&#65292;&#36890;&#36807;&#36793;&#32536;&#20284;&#28982;&#27604;&#36739;&#27169;&#22411;&#65292;&#24182;&#35745;&#31639;GPN&#29305;&#24449;&#30340;&#21518;&#39564;&#27010;&#29575;&#12290;&#27169;&#25311;&#30740;&#31350;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#24674;&#22797;&#32593;&#32476;&#30340;&#22270;&#24418;&#32467;&#26500;&#26041;&#38754;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;&#65292;&#24182;&#25552;&#20379;&#20854;&#21518;&#39564;&#30340;&#20934;&#30830;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian Process Networks (GPNs) are a class of directed graphical models which employ Gaussian processes as priors for the conditional expectation of each variable given its parents in the network. The model allows describing continuous joint distributions in a compact but flexible manner with minimal parametric assumptions on the dependencies between variables. Bayesian structure learning of GPNs requires computing the posterior over graphs of the network and is computationally infeasible even in low dimensions. This work implements Monte Carlo and Markov Chain Monte Carlo methods to sample from the posterior distribution of network structures. As such, the approach follows the Bayesian paradigm, comparing models via their marginal likelihood and computing the posterior probability of the GPN features. Simulation studies show that our method outperforms state-of-the-art algorithms in recovering the graphical structure of the network and provides an accurate approximation of its poste
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#32447;&#40654;&#26364;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#22312;&#32447;&#24773;&#20917;&#19979;&#20272;&#35745;&#28508;&#22312;&#30340;&#20302;&#31209;&#24352;&#37327;&#12290;&#20854;&#20013;&#65292;&#25105;&#20204;&#22312;&#22788;&#29702;&#36830;&#32493;&#25110;&#20998;&#31867;&#21464;&#37327;&#26102;&#25552;&#20379;&#20102;&#28789;&#27963;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#22312;&#32447;&#24773;&#20917;&#19979;&#23581;&#35797;&#20102;&#20004;&#20010;&#20855;&#20307;&#30340;&#24212;&#29992;&#65292;&#21363;&#22312;&#32447;&#24352;&#37327;&#34917;&#20840;&#21644;&#22312;&#32447;&#20108;&#20803;&#24352;&#37327;&#23398;&#20064;&#12290;&#25105;&#20204;&#36824;&#24314;&#31435;&#20102;&#36880;&#20010;&#26465;&#30446;&#30340;&#31934;&#30830;&#38169;&#35823;&#30028;&#38480;&#65292;&#36825;&#26159;&#22312;&#22312;&#32447;&#24352;&#37327;&#34917;&#20840;&#20013;&#39318;&#27425;&#32435;&#20837;&#22122;&#22768;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#22312;&#23384;&#22312;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#65292;&#35745;&#31639;&#21644;&#32479;&#35745;&#26041;&#38754;&#23384;&#22312;&#30528;&#20196;&#20154;&#24778;&#35766;&#30340;&#26435;&#34913;&#12290;</title><link>http://arxiv.org/abs/2306.03372</link><description>&lt;p&gt;
&#22312;&#32447;&#24352;&#37327;&#23398;&#20064;&#65306;&#35745;&#31639;&#21644;&#32479;&#35745;&#26435;&#34913;&#65292;&#36866;&#24212;&#24615;&#21644;&#26368;&#20248;&#36951;&#25022;
&lt;/p&gt;
&lt;p&gt;
Online Tensor Learning: Computational and Statistical Trade-offs, Adaptivity and Optimal Regret. (arXiv:2306.03372v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03372
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#32447;&#40654;&#26364;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#22312;&#32447;&#24773;&#20917;&#19979;&#20272;&#35745;&#28508;&#22312;&#30340;&#20302;&#31209;&#24352;&#37327;&#12290;&#20854;&#20013;&#65292;&#25105;&#20204;&#22312;&#22788;&#29702;&#36830;&#32493;&#25110;&#20998;&#31867;&#21464;&#37327;&#26102;&#25552;&#20379;&#20102;&#28789;&#27963;&#30340;&#26041;&#27861;&#65292;&#24182;&#22312;&#22312;&#32447;&#24773;&#20917;&#19979;&#23581;&#35797;&#20102;&#20004;&#20010;&#20855;&#20307;&#30340;&#24212;&#29992;&#65292;&#21363;&#22312;&#32447;&#24352;&#37327;&#34917;&#20840;&#21644;&#22312;&#32447;&#20108;&#20803;&#24352;&#37327;&#23398;&#20064;&#12290;&#25105;&#20204;&#36824;&#24314;&#31435;&#20102;&#36880;&#20010;&#26465;&#30446;&#30340;&#31934;&#30830;&#38169;&#35823;&#30028;&#38480;&#65292;&#36825;&#26159;&#22312;&#22312;&#32447;&#24352;&#37327;&#34917;&#20840;&#20013;&#39318;&#27425;&#32435;&#20837;&#22122;&#22768;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#22312;&#23384;&#22312;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#65292;&#35745;&#31639;&#21644;&#32479;&#35745;&#26041;&#38754;&#23384;&#22312;&#30528;&#20196;&#20154;&#24778;&#35766;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#24191;&#20041;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#32447;&#24773;&#20917;&#19979;&#20272;&#35745;&#28508;&#22312;&#30340;&#20302;&#31209;&#24352;&#37327;&#65292;&#21253;&#25324;&#32447;&#24615;&#21644;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#12290;&#35813;&#26694;&#26550;&#25552;&#20379;&#20102;&#19968;&#31181;&#22788;&#29702;&#36830;&#32493;&#25110;&#20998;&#31867;&#21464;&#37327;&#30340;&#28789;&#27963;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#20010;&#20855;&#20307;&#30340;&#24212;&#29992;&#65306;&#22312;&#32447;&#24352;&#37327;&#34917;&#20840;&#21644;&#22312;&#32447;&#20108;&#20803;&#24352;&#37327;&#23398;&#20064;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22312;&#32447;&#40654;&#26364;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#22312;&#25152;&#26377;&#24212;&#29992;&#31243;&#24207;&#20013;&#37117;&#21487;&#20197;&#26681;&#25454;&#36866;&#24403;&#30340;&#26465;&#20214;&#32447;&#24615;&#25910;&#25947;&#24182;&#24674;&#22797;&#20302;&#31209;&#32452;&#20214;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20026;&#22312;&#32447;&#24352;&#37327;&#34917;&#20840;&#24314;&#31435;&#20102;&#31934;&#30830;&#30340;&#36880;&#20010;&#26465;&#30446;&#38169;&#35823;&#30028;&#38480;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#20195;&#34920;&#20102;&#39318;&#27425;&#23581;&#35797;&#22312;&#22312;&#32447;&#20302;&#31209;&#24352;&#37327;&#24674;&#22797;&#20219;&#21153;&#20013;&#32435;&#20837;&#22122;&#22768;&#30340;&#21162;&#21147;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#22312;&#23384;&#22312;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#65292;&#22312;&#35745;&#31639;&#21644;&#32479;&#35745;&#26041;&#38754;&#23384;&#22312;&#30528;&#20196;&#20154;&#24778;&#35766;&#30340;&#26435;&#34913;&#12290;&#22686;&#21152;&#27493;&#38271;&#21487;&#20197;&#21152;&#24555;&#25910;&#25947;&#65292;&#20294;&#20250;&#23548;&#33268;&#26356;&#39640;&#30340;&#32479;&#35745;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate a generalized framework for estimating latent low-rank tensors in an online setting, encompassing both linear and generalized linear models. This framework offers a flexible approach for handling continuous or categorical variables. Additionally, we investigate two specific applications: online tensor completion and online binary tensor learning. To address these challenges, we propose the online Riemannian gradient descent algorithm, which demonstrates linear convergence and the ability to recover the low-rank component under appropriate conditions in all applications. Furthermore, we establish a precise entry-wise error bound for online tensor completion. Notably, our work represents the first attempt to incorporate noise in the online low-rank tensor recovery task. Intriguingly, we observe a surprising trade-off between computational and statistical aspects in the presence of noise. Increasing the step size accelerates convergence but leads to higher statistical error
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;aggVAE&#36827;&#34892;&#28145;&#24230;&#23398;&#20064;&#21644;MCMC&#22788;&#29702;&#34892;&#25919;&#36793;&#30028;&#21464;&#21270;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#26144;&#23556;&#20197;&#21439;&#20026;&#23618;&#32423;&#30340;&#32858;&#21512;&#32423;&#21035;&#25968;&#25454;&#65292;&#24182;&#22788;&#29702;&#34892;&#25919;&#36793;&#30028;&#30340;&#21464;&#21270;&#65292;&#30456;&#27604;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#34920;&#29616;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2305.19779</link><description>&lt;p&gt;
&#21033;&#29992;aggVAE&#36827;&#34892;&#28145;&#24230;&#23398;&#20064;&#21644;MCMC&#20197;&#22788;&#29702;&#34892;&#25919;&#36793;&#30028;&#21464;&#21270;&#65306;&#20197;&#32943;&#23612;&#20122;&#30340;&#30111;&#30142;&#24739;&#30149;&#29575;&#20026;&#20363;
&lt;/p&gt;
&lt;p&gt;
Deep learning and MCMC with aggVAE for shifting administrative boundaries: mapping malaria prevalence in Kenya. (arXiv:2305.19779v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19779
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;aggVAE&#36827;&#34892;&#28145;&#24230;&#23398;&#20064;&#21644;MCMC&#22788;&#29702;&#34892;&#25919;&#36793;&#30028;&#21464;&#21270;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#26144;&#23556;&#20197;&#21439;&#20026;&#23618;&#32423;&#30340;&#32858;&#21512;&#32423;&#21035;&#25968;&#25454;&#65292;&#24182;&#22788;&#29702;&#34892;&#25919;&#36793;&#30028;&#30340;&#21464;&#21270;&#65292;&#30456;&#27604;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#27169;&#22411;&#30340;&#30142;&#30149;&#26144;&#23556;&#26159;&#20844;&#20849;&#21355;&#29983;&#21644;&#30142;&#30149;&#30417;&#27979;&#20013;&#22522;&#26412;&#30340;&#25919;&#31574;&#20449;&#24687;&#24037;&#20855;&#65292;&#20998;&#23618;&#36125;&#21494;&#26031;&#27169;&#22411;&#26159;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;&#24403;&#22788;&#29702;&#21306;&#22495;&#25968;&#25454;&#65292;&#22914;&#34892;&#25919;&#21306;&#21010;&#21333;&#20301;&#65288;&#20363;&#22914;&#21439;&#25110;&#30465;&#65289;&#30340;&#32858;&#21512;&#25968;&#25454;&#26102;&#65292;&#24120;&#29992;&#30340;&#27169;&#22411;&#20381;&#36182;&#20110;&#21306;&#22495;&#21333;&#20803;&#30340;&#30456;&#37051;&#32467;&#26500;&#20197;&#32771;&#34385;&#31354;&#38388;&#30456;&#20851;&#24615;&#12290;&#30142;&#30149;&#30417;&#27979;&#31995;&#32479;&#30340;&#30446;&#26631;&#26159;&#38543;&#26102;&#38388;&#36319;&#36394;&#30142;&#30149;&#32467;&#26524;&#65292;&#20294;&#22312;&#21361;&#26426;&#24773;&#20917;&#19979;&#65288;&#20363;&#22914;&#25919;&#27835;&#21464;&#21270;&#23548;&#33268;&#34892;&#25919;&#36793;&#30028;&#26356;&#25913;&#65289;&#65292;&#36825;&#23558;&#24102;&#26469;&#25361;&#25112;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#12289;&#23454;&#29992;&#21644;&#26131;&#20110;&#23454;&#26045;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#35813;&#26041;&#26696;&#20381;&#36182;&#20110;&#32452;&#21512;&#28145;&#23618;&#29983;&#25104;&#27169;&#22411;&#21644;&#20840;&#36125;&#21494;&#26031;&#25512;&#26029;&#12290;&#25105;&#20204;&#24314;&#31435;&#22312;&#29616;&#26377;&#30340;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;(VAE) &#24037;&#20316;&#19978;&#65292;&#24182;&#23637;&#31034;&#25105;&#20204;&#25552;&#20986;&#30340;&#32858;&#21512;VAE(aggVAE)&#20307;&#31995;&#32467;&#26500;&#21487;&#29992;&#20110;&#22312;&#20197;&#21439;&#20026;&#23618;&#32423;&#30340;&#32858;&#21512;&#32423;&#21035;&#22788;&#29702;&#25968;&#25454;&#65292;&#20197;&#26144;&#23556;&#32943;&#23612;&#20122;&#30340;&#30111;&#30142;&#24739;&#30149;&#29575;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#21487;&#20197;&#20197;&#36830;&#32493;&#30340;&#26041;&#24335;&#32771;&#34385;&#31354;&#38388;&#30456;&#20851;&#24615;&#65292;&#32780;&#19981;&#20381;&#36182;&#20110;&#30456;&#37051;&#24615;&#20551;&#35774;&#65292;&#24182;&#19988;&#33021;&#22815;&#22788;&#29702;&#34892;&#25919;&#36793;&#30028;&#30340;&#21464;&#21270;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#30456;&#27604;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#21644;&#26356;&#20934;&#30830;&#30340;&#30111;&#30142;&#24739;&#30149;&#29575;&#26144;&#23556;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model-based disease mapping remains a fundamental policy-informing tool in public health and disease surveillance with hierarchical Bayesian models being the current state-of-the-art approach. When working with areal data, e.g. aggregates at the administrative unit level such as district or province, routinely used models rely on the adjacency structure of areal units to account for spatial correlations. The goal of disease surveillance systems is to track disease outcomes over time, but this provides challenging in situations of crises, such as political changes, leading to changes of administrative boundaries. Kenya is an example of such country. Moreover, adjacency-based approach ignores the continuous nature of spatial processes and cannot solve the change-of-support problem, i.e. when administrative boundaries change. We present a novel, practical, and easy to implement solution relying on a methodology combining deep generative modelling and fully Bayesian inference. We build on 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#24615;&#21270;Laplace&#36924;&#36817;(LLA)&#22312;Bayesian optimization&#20013;&#30340;&#24212;&#29992;&#12290;&#34429;&#28982;LLA&#22312;&#26500;&#24314;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#26102;&#24050;&#34987;&#35777;&#26126;&#20855;&#26377;&#25928;&#24615;&#21644;&#39640;&#25928;&#24615;&#65292;&#20294;&#26159;&#22312;&#24207;&#21015;&#20915;&#31574;&#38382;&#39064;&#20013;&#65292;&#38656;&#35201;&#32771;&#34385;&#20854;&#21487;&#33021;&#30340;&#23616;&#38480;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.08309</link><description>&lt;p&gt;
Bayesian Optimization&#20013;&#32447;&#24615;&#21270;Laplace&#30340;&#20248;&#21183;&#21644;&#23616;&#38480;&#24615;
&lt;/p&gt;
&lt;p&gt;
Promises and Pitfalls of the Linearized Laplace in Bayesian Optimization. (arXiv:2304.08309v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.08309
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#24615;&#21270;Laplace&#36924;&#36817;(LLA)&#22312;Bayesian optimization&#20013;&#30340;&#24212;&#29992;&#12290;&#34429;&#28982;LLA&#22312;&#26500;&#24314;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#26102;&#24050;&#34987;&#35777;&#26126;&#20855;&#26377;&#25928;&#24615;&#21644;&#39640;&#25928;&#24615;&#65292;&#20294;&#26159;&#22312;&#24207;&#21015;&#20915;&#31574;&#38382;&#39064;&#20013;&#65292;&#38656;&#35201;&#32771;&#34385;&#20854;&#21487;&#33021;&#30340;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32447;&#24615;&#21270;Laplace&#36924;&#36817;(LLA)&#24050;&#34987;&#35777;&#26126;&#22312;&#26500;&#24314;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#26102;&#26377;&#25928;&#19988;&#39640;&#25928;&#12290;&#23427;&#22312;&#29702;&#35770;&#19978;&#20855;&#26377;&#21560;&#24341;&#21147;&#65292;&#22240;&#20026;&#23427;&#21487;&#20197;&#34987;&#30475;&#20316;&#26159;&#20855;&#26377;&#39640;&#26031;&#36807;&#31243;&#21518;&#39564;&#30340;&#26368;&#22823;&#21518;&#39564;&#39044;&#27979;&#20989;&#25968;&#26368;&#22823;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#24179;&#22343;&#20989;&#25968;&#65292;&#24182;&#19988;&#30001;&#32463;&#39564;&#31070;&#32463;&#26354;&#38754;&#26680;&#35825;&#23548;&#30340;&#21327;&#26041;&#24046;&#20989;&#25968;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#24050;&#32463;&#30740;&#31350;&#36807;&#20854;&#22312;&#22270;&#20687;&#20998;&#31867;&#31561;&#22823;&#35268;&#27169;&#20219;&#21153;&#20013;&#30340;&#25928;&#26524;&#65292;&#20294;&#22312;&#35832;&#22914;Bayesian optimization&#36825;&#26679;&#30340;&#24207;&#21015;&#20915;&#31574;&#38382;&#39064;&#20013;&#23578;&#26410;&#23545;&#20854;&#36827;&#34892;&#30740;&#31350;&#65292;&#20854;&#20013;&#39640;&#26031;&#36807;&#31243;&#26159;&#40664;&#35748;&#30340;&#20195;&#29702;&#27169;&#22411;&#65292;&#20855;&#26377;&#31616;&#21333;&#30340;&#24179;&#22343;&#20989;&#25968;&#21644;&#26680;&#20989;&#25968;&#65292;&#20363;&#22914;&#24452;&#21521;&#22522;&#20989;&#25968;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;LLA&#22312;Bayesian optimization&#20013;&#30340;&#26377;&#29992;&#24615;&#21644;&#28789;&#27963;&#24615;&#65292;&#24182;&#24378;&#35843;&#20854;&#24378;&#22823;&#30340;&#24615;&#33021;&#12290;&#20294;&#26159;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#21487;&#33021;&#20986;&#29616;&#30340;&#19968;&#20123;&#38382;&#39064;&#21644;&#19968;&#20010;LLA&#21487;&#33021;&#23384;&#22312;&#30340;&#38382;&#39064;&#65292;&#21363;&#24403;&#25628;&#32034;&#31354;&#38388;&#26159;&#26080;&#30028;&#30340;&#26102;&#20505;&#12290;
&lt;/p&gt;
&lt;p&gt;
The linearized-Laplace approximation (LLA) has been shown to be effective and efficient in constructing Bayesian neural networks. It is theoretically compelling since it can be seen as a Gaussian process posterior with the mean function given by the neural network's maximum-a-posteriori predictive function and the covariance function induced by the empirical neural tangent kernel. However, while its efficacy has been studied in large-scale tasks like image classification, it has not been studied in sequential decision-making problems like Bayesian optimization where Gaussian processes -- with simple mean functions and kernels such as the radial basis function -- are the de-facto surrogate models. In this work, we study the usefulness of the LLA in Bayesian optimization and highlight its strong performance and flexibility. However, we also present some pitfalls that might arise and a potential problem with the LLA when the search space is unbounded.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20195;&#25968;&#25299;&#25169;&#26694;&#26550;&#65292;&#36890;&#36807;&#20174;MALDI&#25968;&#25454;&#20013;&#33719;&#24471;&#20869;&#22312;&#20449;&#24687;&#24182;&#36716;&#21270;&#20026;&#21453;&#26144;&#25299;&#25169;&#25345;&#20037;&#24615;&#30340;&#24418;&#24335;&#65292;&#23454;&#29616;&#20102;&#22312;&#32954;&#30284;&#20122;&#22411;&#20998;&#31867;&#20013;&#30340;&#22122;&#38899;&#20449;&#21495;&#21306;&#20998;&#21644;&#25968;&#25454;&#21387;&#32553;&#30340;&#21151;&#33021;&#12290;</title><link>http://arxiv.org/abs/2302.13948</link><description>&lt;p&gt;
&#30417;&#30563;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#22312;MALDI&#36136;&#35889;&#25104;&#20687;&#24212;&#29992;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Supervised topological data analysis for MALDI mass spectrometry imaging applications. (arXiv:2302.13948v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.13948
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20195;&#25968;&#25299;&#25169;&#26694;&#26550;&#65292;&#36890;&#36807;&#20174;MALDI&#25968;&#25454;&#20013;&#33719;&#24471;&#20869;&#22312;&#20449;&#24687;&#24182;&#36716;&#21270;&#20026;&#21453;&#26144;&#25299;&#25169;&#25345;&#20037;&#24615;&#30340;&#24418;&#24335;&#65292;&#23454;&#29616;&#20102;&#22312;&#32954;&#30284;&#20122;&#22411;&#20998;&#31867;&#20013;&#30340;&#22122;&#38899;&#20449;&#21495;&#21306;&#20998;&#21644;&#25968;&#25454;&#21387;&#32553;&#30340;&#21151;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32972;&#26223;&#65306;&#22522;&#36136;&#36741;&#21161;&#28608;&#20809;&#35299;&#21560;/&#30005;&#31163;&#36136;&#35889;&#25104;&#20687;&#65288;MALDI MSI&#65289;&#22312;&#30284;&#30151;&#30740;&#31350;&#20013;&#26174;&#31034;&#20986;&#37325;&#35201;&#30340;&#28508;&#21147;&#65292;&#29305;&#21035;&#26159;&#22312;&#32959;&#30244;&#20998;&#22411;&#21644;&#20122;&#22411;&#20998;&#26512;&#20013;&#12290;&#32954;&#30284;&#26159;&#32959;&#30244;&#30456;&#20851;&#27515;&#20129;&#30340;&#20027;&#35201;&#21407;&#22240;&#65292;&#20854;&#20013;&#26368;&#33268;&#21629;&#30340;&#23454;&#20307;&#26159;&#33146;&#30284;&#65288;ADC&#65289;&#21644;&#40158;&#29366;&#32454;&#32990;&#30284;&#65288;SqCC&#65289;&#12290;&#21306;&#20998;&#36825;&#20004;&#31181;&#24120;&#35265;&#20122;&#22411;&#23545;&#20110;&#27835;&#30103;&#20915;&#31574;&#21644;&#24739;&#32773;&#31649;&#29702;&#33267;&#20851;&#37325;&#35201;&#12290;&#32467;&#26524;&#65306;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20195;&#25968;&#25299;&#25169;&#26694;&#26550;&#65292;&#36890;&#36807;&#20174;MALDI&#25968;&#25454;&#20013;&#33719;&#21462;&#20869;&#22312;&#20449;&#24687;&#24182;&#23558;&#20854;&#36716;&#21270;&#20026;&#21453;&#26144;&#25299;&#25169;&#25345;&#20037;&#24615;&#30340;&#24418;&#24335;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#20855;&#26377;&#20004;&#20010;&#20027;&#35201;&#20248;&#28857;&#12290;&#39318;&#20808;&#65292;&#25299;&#25169;&#25345;&#20037;&#24615;&#26377;&#21161;&#20110;&#21306;&#20998;&#20449;&#21495;&#21644;&#22122;&#38899;&#12290;&#20854;&#27425;&#65292;&#23427;&#21387;&#32553;&#20102;MALDI&#25968;&#25454;&#65292;&#33410;&#30465;&#20102;&#23384;&#20648;&#31354;&#38388;&#65292;&#24182;&#20248;&#21270;&#20102;&#21518;&#32493;&#20998;&#31867;&#20219;&#21153;&#30340;&#35745;&#31639;&#26102;&#38388;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#39640;&#25928;&#23454;&#29616;&#25105;&#20204;&#25299;&#25169;&#26694;&#26550;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20381;&#36182;&#20110;&#21333;&#19968;&#35843;&#20248;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Background: Matrix-assisted laser desorption/ionization mass spectrometry imaging (MALDI MSI) displays significant potential for applications in cancer research, especially in tumor typing and subtyping. Lung cancer is the primary cause of tumor-related deaths, where the most lethal entities are adenocarcinoma (ADC) and squamous cell carcinoma (SqCC). Distinguishing between these two common subtypes is crucial for therapy decisions and successful patient management.  Results: We propose a new algebraic topological framework, which obtains intrinsic information from MALDI data and transforms it to reflect topological persistence. Our framework offers two main advantages. Firstly, topological persistence aids in distinguishing the signal from noise. Secondly, it compresses the MALDI data, saving storage space and optimizes computational time for subsequent classification tasks. We present an algorithm that efficiently implements our topological framework, relying on a single tuning param
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23433;&#20840;&#38480;&#21046;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65292;&#24378;&#35843;&#20102;&#36125;&#23572;&#26364;&#26368;&#20248;&#24615;&#21407;&#29702;&#22312;&#20855;&#26377;&#22810;&#38142;&#32467;&#26500;&#30340;&#21463;&#38480;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#38382;&#39064;&#20013;&#21487;&#33021;&#19981;&#25104;&#31435;&#12290;&#36890;&#36807;&#23558;&#22810;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#34920;&#31034;&#20026;&#26032;&#30340;&#20248;&#21270;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#36825;&#20010;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2302.13152</link><description>&lt;p&gt;
&#20851;&#20110;&#36125;&#23572;&#26364;&#26368;&#20248;&#24615;&#21407;&#29702;&#21644;&#23433;&#20840;&#38480;&#21046;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#24378;&#21270;&#23398;&#20064;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Bellman's principle of optimality and Reinforcement learning for safety-constrained Markov decision process. (arXiv:2302.13152v3 [eess.SY] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.13152
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23433;&#20840;&#38480;&#21046;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65292;&#24378;&#35843;&#20102;&#36125;&#23572;&#26364;&#26368;&#20248;&#24615;&#21407;&#29702;&#22312;&#20855;&#26377;&#22810;&#38142;&#32467;&#26500;&#30340;&#21463;&#38480;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#38382;&#39064;&#20013;&#21487;&#33021;&#19981;&#25104;&#31435;&#12290;&#36890;&#36807;&#23558;&#22810;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#34920;&#31034;&#20026;&#26032;&#30340;&#20248;&#21270;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23433;&#20840;&#38480;&#21046;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65292;&#36825;&#26159;&#23433;&#20840;&#24378;&#21270;&#23398;&#20064;&#30340;&#22522;&#26412;&#26694;&#26550;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#26377;&#38480;&#29366;&#24577;&#21644;&#26377;&#38480;&#21160;&#20316;&#30340;&#21463;&#38480;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65292;&#22312;&#36825;&#20010;&#36807;&#31243;&#20013;&#65292;&#20915;&#31574;&#32773;&#30340;&#30446;&#26631;&#26159;&#22312;&#19968;&#23450;&#30340;&#27010;&#29575;&#20445;&#35777;&#19979;&#21040;&#36798;&#30446;&#26631;&#38598;&#21512;&#65292;&#21516;&#26102;&#36991;&#20813;&#36827;&#20837;&#19968;&#20010;&#19981;&#23433;&#20840;&#30340;&#38598;&#21512;&#12290;&#22240;&#27492;&#65292;&#20219;&#20309;&#25511;&#21046;&#31574;&#30053;&#19979;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#37117;&#20250;&#34920;&#29616;&#20026;&#22810;&#38142;&#32467;&#26500;&#65292;&#22240;&#20026;&#26681;&#25454;&#23450;&#20041;&#65292;&#23384;&#22312;&#19968;&#20010;&#30446;&#26631;&#38598;&#21512;&#21644;&#19968;&#20010;&#19981;&#23433;&#20840;&#38598;&#21512;&#12290;&#20915;&#31574;&#32773;&#22312;&#23548;&#33322;&#21040;&#30446;&#26631;&#38598;&#21512;&#26102;&#36824;&#24517;&#39035;&#26159;&#26368;&#20248;&#30340;&#65288;&#22522;&#20110;&#19968;&#20010;&#25104;&#26412;&#20989;&#25968;&#65289;&#12290;&#36825;&#23548;&#33268;&#20102;&#19968;&#20010;&#22810;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#12290;&#25105;&#20204;&#24378;&#35843;&#36125;&#23572;&#26364;&#26368;&#20248;&#24615;&#21407;&#29702;&#22312;&#20855;&#26377;&#22810;&#38142;&#32467;&#26500;&#30340;&#21463;&#38480;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#38382;&#39064;&#20013;&#21487;&#33021;&#19981;&#25104;&#31435;&#65288;&#27491;&#22914;Haviv&#30340;&#21453;&#20363;&#25152;&#31034;&#65289;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#19978;&#36848;&#22810;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#34920;&#31034;&#20026;&#19968;&#20010;&#26032;&#30340;&#20248;&#21270;&#26694;&#26550;&#65292;&#35299;&#20915;&#20102;&#36825;&#20010;&#21453;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study optimality for the safety-constrained Markov decision process which is the underlying framework for safe reinforcement learning. Specifically, we consider a constrained Markov decision process (with finite states and finite actions) where the goal of the decision maker is to reach a target set while avoiding an unsafe set(s) with certain probabilistic guarantees. Therefore the underlying Markov chain for any control policy will be multichain since by definition there exists a target set and an unsafe set. The decision maker also has to be optimal (with respect to a cost function) while navigating to the target set. This gives rise to a multi-objective optimization problem. We highlight the fact that Bellman's principle of optimality may not hold for constrained Markov decision problems with an underlying multichain structure (as shown by the counterexample due to Haviv. We resolve the counterexample by formulating the aforementioned multi-objective optimization problem as a ze
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26368;&#23567;&#21270;&#26399;&#26395;&#31616;&#21333;&#36951;&#25022;&#30340;&#22266;&#23450;&#39044;&#31639;&#26368;&#20248;&#33218;&#35782;&#21035;&#38382;&#39064;&#12290;&#36890;&#36807;&#25512;&#23548;&#26368;&#22351;&#24773;&#20917;&#26399;&#26395;&#31616;&#21333;&#36951;&#25022;&#30340;&#28176;&#36827;&#19979;&#30028;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;HIR&#20272;&#35745;&#30340;TS-HIR&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#22312;&#25512;&#33616;&#26368;&#20248;&#33218;&#26102;&#34920;&#29616;&#20986;&#36817;&#20284;&#26368;&#20248;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.02988</link><description>&lt;p&gt;
&#28176;&#36827;&#26368;&#20248;&#30340;&#22266;&#23450;&#39044;&#31639;&#26368;&#20248;&#33218;&#35782;&#21035;&#26041;&#27861;&#19982;&#26041;&#24046;&#30456;&#20851;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Asymptotically Optimal Fixed-Budget Best Arm Identification with Variance-Dependent Bounds. (arXiv:2302.02988v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.02988
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26368;&#23567;&#21270;&#26399;&#26395;&#31616;&#21333;&#36951;&#25022;&#30340;&#22266;&#23450;&#39044;&#31639;&#26368;&#20248;&#33218;&#35782;&#21035;&#38382;&#39064;&#12290;&#36890;&#36807;&#25512;&#23548;&#26368;&#22351;&#24773;&#20917;&#26399;&#26395;&#31616;&#21333;&#36951;&#25022;&#30340;&#28176;&#36827;&#19979;&#30028;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;HIR&#20272;&#35745;&#30340;TS-HIR&#31574;&#30053;&#65292;&#35813;&#31574;&#30053;&#22312;&#25512;&#33616;&#26368;&#20248;&#33218;&#26102;&#34920;&#29616;&#20986;&#36817;&#20284;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26368;&#23567;&#21270;&#26399;&#26395;&#31616;&#21333;&#36951;&#25022;&#30340;&#22266;&#23450;&#39044;&#31639;&#26368;&#20248;&#33218;&#35782;&#21035;&#38382;&#39064;&#12290;&#22312;&#33258;&#36866;&#24212;&#23454;&#39564;&#20013;&#65292;&#20915;&#31574;&#32773;&#26681;&#25454;&#36807;&#21435;&#30340;&#35266;&#27979;&#32467;&#26524;&#36873;&#25321;&#22810;&#20010;&#22788;&#29702;&#33218;&#20043;&#19968;&#65292;&#24182;&#35266;&#23519;&#25152;&#36873;&#25321;&#30340;&#33218;&#30340;&#32467;&#26524;&#12290;&#23454;&#39564;&#32467;&#26463;&#21518;&#65292;&#20915;&#31574;&#32773;&#25512;&#33616;&#26399;&#26395;&#32467;&#26524;&#26368;&#39640;&#30340;&#22788;&#29702;&#33218;&#12290;&#25105;&#20204;&#22522;&#20110;&#26399;&#26395;&#31616;&#21333;&#36951;&#25022;&#35780;&#20272;&#20915;&#31574;&#30340;&#22909;&#22351;&#65292;&#20854;&#23450;&#20041;&#20026;&#26368;&#20248;&#33218;&#30340;&#26399;&#26395;&#32467;&#26524;&#19982;&#25512;&#33616;&#33218;&#30340;&#26399;&#26395;&#32467;&#26524;&#20043;&#24046;&#12290;&#30001;&#20110;&#22266;&#26377;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#25105;&#20204;&#20351;&#29992;&#26497;&#23567;&#26497;&#22823;&#20934;&#21017;&#35780;&#20272;&#36951;&#25022;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#26368;&#22351;&#24773;&#20917;&#26399;&#26395;&#31616;&#21333;&#36951;&#25022;&#30340;&#28176;&#36827;&#19979;&#30028;&#65292;&#35813;&#19979;&#30028;&#30001;&#28508;&#22312;&#32467;&#26524;&#30340;&#26041;&#24046;&#65288;&#20027;&#23548;&#22240;&#32032;&#65289;&#25152;&#30830;&#23450;&#12290;&#22522;&#20110;&#36825;&#20123;&#19979;&#30028;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Two-Stage (TS)-Hirano-Imbens-Ridder (HIR)&#31574;&#30053;&#65292;&#22312;&#25512;&#33616;&#26368;&#20248;&#33218;&#26102;&#21033;&#29992;HIR&#20272;&#35745;&#65288;Hirano et al., 2003&#65289;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;TS-HIR&#31574;&#30053;&#36817;&#20284;&#26159;&#26368;&#20248;&#30340;&#65292;&#24182;&#19988;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#33021;&#36798;&#21040;&#26497;&#23567;&#26497;&#22823;&#20934;&#21017;&#19979;&#30340;&#28176;&#36827;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the problem of fixed-budget best arm identification (BAI) for minimizing expected simple regret. In an adaptive experiment, a decision maker draws one of multiple treatment arms based on past observations and observes the outcome of the drawn arm. After the experiment, the decision maker recommends the treatment arm with the highest expected outcome. We evaluate the decision based on the expected simple regret, which is the difference between the expected outcomes of the best arm and the recommended arm. Due to inherent uncertainty, we evaluate the regret using the minimax criterion. First, we derive asymptotic lower bounds for the worst-case expected simple regret, which are characterized by the variances of potential outcomes (leading factor). Based on the lower bounds, we propose the Two-Stage (TS)-Hirano-Imbens-Ridder (HIR) strategy, which utilizes the HIR estimator (Hirano et al., 2003) in recommending the best arm. Our theoretical analysis shows that the TS-HIR str
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;GAN&#29983;&#25104;&#24314;&#27169;&#26694;&#26550;MonoFlow&#65292;&#36890;&#36807;Wasserstein&#26799;&#24230;&#27969;&#33719;&#24471;&#29702;&#35770;&#27934;&#35265;&#21644;&#31639;&#27861;&#21551;&#31034;&#12290;&#35813;&#26694;&#26550;&#20351;&#29992;&#23494;&#24230;&#27604;&#20363;&#30340;&#21333;&#35843;&#36882;&#22686;&#26144;&#23556;&#37325;&#26032;&#32553;&#25918;&#31890;&#23376;&#28436;&#21270;&#65292;&#24182;&#36890;&#36807;&#35757;&#32451;&#37492;&#21035;&#22120;&#33719;&#24471;MonoFlow&#30340;&#21521;&#37327;&#22330;&#65292;&#21033;&#29992;&#30456;&#24212;&#30340;&#21521;&#37327;&#22330;&#36827;&#34892;&#31890;&#23376;&#27969;&#30340;&#29983;&#25104;&#12290;</title><link>http://arxiv.org/abs/2302.01075</link><description>&lt;p&gt;
MonoFlow: &#20174;Wasserstein&#26799;&#24230;&#27969;&#30340;&#35282;&#24230;&#37325;&#26032;&#24605;&#32771;Divergence GANs
&lt;/p&gt;
&lt;p&gt;
MonoFlow: Rethinking Divergence GANs via the Perspective of Wasserstein Gradient Flows. (arXiv:2302.01075v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.01075
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;GAN&#29983;&#25104;&#24314;&#27169;&#26694;&#26550;MonoFlow&#65292;&#36890;&#36807;Wasserstein&#26799;&#24230;&#27969;&#33719;&#24471;&#29702;&#35770;&#27934;&#35265;&#21644;&#31639;&#27861;&#21551;&#31034;&#12290;&#35813;&#26694;&#26550;&#20351;&#29992;&#23494;&#24230;&#27604;&#20363;&#30340;&#21333;&#35843;&#36882;&#22686;&#26144;&#23556;&#37325;&#26032;&#32553;&#25918;&#31890;&#23376;&#28436;&#21270;&#65292;&#24182;&#36890;&#36807;&#35757;&#32451;&#37492;&#21035;&#22120;&#33719;&#24471;MonoFlow&#30340;&#21521;&#37327;&#22330;&#65292;&#21033;&#29992;&#30456;&#24212;&#30340;&#21521;&#37327;&#22330;&#36827;&#34892;&#31890;&#23376;&#27969;&#30340;&#29983;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#19978;&#65292;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GANs&#65289;&#30340;&#23545;&#25239;&#35757;&#32451;&#26159;&#36890;&#36807;&#21028;&#21035;&#22120;&#26469;&#20272;&#35745;&#31163;&#25955;&#24230;&#65292;&#29983;&#25104;&#22120;&#23398;&#20064;&#26368;&#23567;&#21270;&#36825;&#20010;&#31163;&#25955;&#24230;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#23613;&#31649;&#35768;&#22810;GANs&#21464;&#20307;&#37117;&#26159;&#25353;&#29031;&#36825;&#20010;&#33539;&#20363;&#24320;&#21457;&#30340;&#65292;&#20294;&#24403;&#21069;GANs&#30340;&#29702;&#35770;&#29702;&#35299;&#21644;&#23454;&#38469;&#31639;&#27861;&#26159;&#19981;&#19968;&#33268;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#36890;&#36807;&#21033;&#29992;&#23637;&#31034;&#20102;&#26679;&#26412;&#31354;&#38388;&#20869;&#31890;&#23376;&#28436;&#21270;&#30340;Wasserstein&#26799;&#24230;&#27969;&#26469;&#33719;&#24471;GANs&#30340;&#29702;&#35770;&#27934;&#35265;&#21644;&#31639;&#27861;&#21551;&#31034;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#29983;&#25104;&#24314;&#27169;&#26694;&#26550;MonoFlow&#65306;&#31890;&#23376;&#28436;&#21270;&#36890;&#36807;&#23494;&#24230;&#27604;&#20363;&#30340;&#21333;&#35843;&#36882;&#22686;&#26144;&#23556;&#36827;&#34892;&#37325;&#26032;&#32553;&#25918;&#12290;&#22312;&#25105;&#20204;&#30340;&#26694;&#26550;&#19979;&#65292;&#23545;&#25239;&#24615;&#35757;&#32451;&#21487;&#20197;&#34987;&#35270;&#20026;&#19968;&#20010;&#36807;&#31243;&#65292;&#39318;&#20808;&#36890;&#36807;&#35757;&#32451;&#37492;&#21035;&#22120;&#33719;&#24471;MonoFlow&#30340;&#21521;&#37327;&#22330;&#65292;&#28982;&#21518;&#29983;&#25104;&#22120;&#23398;&#20064;&#30001;&#30456;&#24212;&#21521;&#37327;&#22330;&#25152;&#23450;&#20041;&#30340;&#31890;&#23376;&#27969;&#12290;
&lt;/p&gt;
&lt;p&gt;
The conventional understanding of adversarial training in generative adversarial networks (GANs) is that the discriminator is trained to estimate a divergence, and the generator learns to minimize this divergence. We argue that despite the fact that many variants of GANs were developed following this paradigm, the current theoretical understanding of GANs and their practical algorithms are inconsistent. In this paper, we leverage Wasserstein gradient flows which characterize the evolution of particles in the sample space, to gain theoretical insights and algorithmic inspiration of GANs. We introduce a unified generative modeling framework - MonoFlow: the particle evolution is rescaled via a monotonically increasing mapping of the log density ratio. Under our framework, adversarial training can be viewed as a procedure first obtaining MonoFlow's vector field via training the discriminator and the generator learns to draw the particle flow defined by the corresponding vector field. We al
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#27604;&#36739;&#36125;&#21494;&#26031;&#23618;&#27425;&#27169;&#22411;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#25903;&#25345;&#20998;&#25674;&#25512;&#26029;&#65292;&#33021;&#22815;&#39640;&#25928;&#22320;&#36827;&#34892;&#27169;&#22411;&#27604;&#36739;&#21644;&#24615;&#33021;&#39564;&#35777;&#12290;&#21516;&#26102;&#65292;&#20316;&#32773;&#36824;&#23545;&#22235;&#20010;&#23618;&#27425;&#35777;&#25454;&#31215;&#32047;&#27169;&#22411;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;</title><link>http://arxiv.org/abs/2301.11873</link><description>&lt;p&gt;
&#27604;&#36739;&#36125;&#21494;&#26031;&#23618;&#27425;&#27169;&#22411;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Deep Learning Method for Comparing Bayesian Hierarchical Models. (arXiv:2301.11873v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11873
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#27604;&#36739;&#36125;&#21494;&#26031;&#23618;&#27425;&#27169;&#22411;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#25903;&#25345;&#20998;&#25674;&#25512;&#26029;&#65292;&#33021;&#22815;&#39640;&#25928;&#22320;&#36827;&#34892;&#27169;&#22411;&#27604;&#36739;&#21644;&#24615;&#33021;&#39564;&#35777;&#12290;&#21516;&#26102;&#65292;&#20316;&#32773;&#36824;&#23545;&#22235;&#20010;&#23618;&#27425;&#35777;&#25454;&#31215;&#32047;&#27169;&#22411;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#27169;&#22411;&#27604;&#36739;&#65288;BMC&#65289;&#25552;&#20379;&#20102;&#19968;&#31181;&#22522;&#20110;&#21407;&#21017;&#30340;&#26041;&#27861;&#26469;&#35780;&#20272;&#31454;&#20105;&#35745;&#31639;&#27169;&#22411;&#30340;&#30456;&#23545;&#20248;&#21183;&#65292;&#24182;&#23558;&#19981;&#30830;&#23450;&#24615;&#20256;&#25773;&#21040;&#27169;&#22411;&#36873;&#25321;&#20915;&#31574;&#20013;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#39640;&#32500;&#23884;&#22871;&#21442;&#25968;&#32467;&#26500;&#65292;BMC&#22312;&#24120;&#35265;&#30340;&#23618;&#27425;&#27169;&#22411;&#20013;&#24120;&#24120;&#38590;&#20197;&#35745;&#31639;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38590;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#23545;&#20219;&#20309;&#21487;&#23454;&#20363;&#21270;&#20026;&#27010;&#29575;&#31243;&#24207;&#30340;&#23618;&#27425;&#27169;&#22411;&#38598;&#36827;&#34892;BMC&#12290;&#30001;&#20110;&#25105;&#20204;&#30340;&#26041;&#27861;&#25903;&#25345;&#20998;&#25674;&#25512;&#26029;&#65292;&#23427;&#21487;&#20197;&#22312;&#20219;&#20309;&#23454;&#38469;&#25968;&#25454;&#24212;&#29992;&#20043;&#21069;&#65292;&#23545;&#21518;&#39564;&#27169;&#22411;&#27010;&#29575;&#36827;&#34892;&#39640;&#25928;&#30340;&#37325;&#26032;&#20272;&#35745;&#21644;&#24555;&#36895;&#24615;&#33021;&#39564;&#35777;&#12290;&#22312;&#19968;&#31995;&#21015;&#24191;&#27867;&#30340;&#39564;&#35777;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23545;&#27604;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#26368;&#20808;&#36827;&#30340;&#26725;&#24335;&#25277;&#26679;&#26041;&#27861;&#30340;&#24615;&#33021;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#25152;&#26377;BMC&#35774;&#32622;&#20013;&#20986;&#33394;&#30340;&#20998;&#25674;&#25512;&#26029;&#33021;&#21147;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#27604;&#36739;&#20808;&#21069;&#34987;&#35748;&#20026;&#26159;&#22235;&#20010;&#23618;&#27425;&#35777;&#25454;&#31215;&#32047;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian model comparison (BMC) offers a principled approach for assessing the relative merits of competing computational models and propagating uncertainty into model selection decisions. However, BMC is often intractable for the popular class of hierarchical models due to their high-dimensional nested parameter structure. To address this intractability, we propose a deep learning method for performing BMC on any set of hierarchical models which can be instantiated as probabilistic programs. Since our method enables amortized inference, it allows efficient re-estimation of posterior model probabilities and fast performance validation prior to any real-data application. In a series of extensive validation studies, we benchmark the performance of our method against the state-of-the-art bridge sampling method and demonstrate excellent amortized inference across all BMC settings. We then showcase our method by comparing four hierarchical evidence accumulation models that have previously b
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20887;&#20313;&#37325;&#21442;&#25968;&#21270;&#21644;&#31616;&#21333;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26469;&#26368;&#23567;&#21270;&#24102;&#26377;$L_1$&#24809;&#32602;&#30340;&#36890;&#29992;&#21487;&#24494;&#25439;&#22833;&#20989;&#25968;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;\textit{spred}&#65292;&#26159;$L_1$&#30340;&#31934;&#30830;&#27714;&#35299;&#22120;&#65292;&#21487;&#29992;&#20110;&#35757;&#32451;&#31232;&#30095;&#31070;&#32463;&#32593;&#32476;&#20197;&#25191;&#34892;&#22522;&#22240;&#36873;&#25321;&#20219;&#21153;&#21644;&#31070;&#32463;&#32593;&#32476;&#21387;&#32553;&#20219;&#21153;&#65292;&#24357;&#21512;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#31232;&#30095;&#24615;&#21644;&#20256;&#32479;&#32479;&#35745;&#23398;&#20064;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;</title><link>http://arxiv.org/abs/2210.01212</link><description>&lt;p&gt;
&#36890;&#36807;&#20887;&#20313;&#24615;&#23454;&#29616;&#31232;&#30095;&#24615;&#65306;&#29992;SGD&#27714;&#35299;$L_1$
&lt;/p&gt;
&lt;p&gt;
Sparsity by Redundancy: Solving $L_1$ with SGD. (arXiv:2210.01212v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.01212
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20887;&#20313;&#37325;&#21442;&#25968;&#21270;&#21644;&#31616;&#21333;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26469;&#26368;&#23567;&#21270;&#24102;&#26377;$L_1$&#24809;&#32602;&#30340;&#36890;&#29992;&#21487;&#24494;&#25439;&#22833;&#20989;&#25968;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;\textit{spred}&#65292;&#26159;$L_1$&#30340;&#31934;&#30830;&#27714;&#35299;&#22120;&#65292;&#21487;&#29992;&#20110;&#35757;&#32451;&#31232;&#30095;&#31070;&#32463;&#32593;&#32476;&#20197;&#25191;&#34892;&#22522;&#22240;&#36873;&#25321;&#20219;&#21153;&#21644;&#31070;&#32463;&#32593;&#32476;&#21387;&#32553;&#20219;&#21153;&#65292;&#24357;&#21512;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#31232;&#30095;&#24615;&#21644;&#20256;&#32479;&#32479;&#35745;&#23398;&#20064;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a method called "spred" to minimize a generic differentiable loss function with $L_1$ penalty using redundant reparametrization and straightforward stochastic gradient descent. It is an exact solver of $L_1$ and can be used to train sparse neural networks for gene selection tasks and neural network compression tasks, bridging the gap between sparsity in deep learning and conventional statistical learning.
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#20887;&#20313;&#37325;&#21442;&#25968;&#21270;&#21644;&#31616;&#21333;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26469;&#26368;&#23567;&#21270;&#24102;&#26377;$L_1$&#24809;&#32602;&#30340;&#36890;&#29992;&#21487;&#24494;&#25439;&#22833;&#20989;&#25968;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#25552;&#35758;&#26159;$L_1$&#24809;&#32602;&#31561;&#20215;&#20110;&#24102;&#26377;&#26435;&#37325;&#34928;&#20943;&#30340;&#21487;&#24494;&#37325;&#21442;&#25968;&#21270;&#30340;&#30452;&#25509;&#25512;&#24191;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#21363;\textit{spred}&#65292;&#26159;$L_1$&#30340;&#31934;&#30830;&#27714;&#35299;&#22120;&#65292;&#24182;&#19988;&#23545;&#20110;&#36890;&#29992;&#30340;&#38750;&#20984;&#20989;&#25968;&#65292;&#37325;&#21442;&#25968;&#21270;&#25216;&#24039;&#26159;&#23436;&#20840;&#8220;&#33391;&#24615;&#8221;&#30340;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#65292;&#21253;&#25324;(1)&#35757;&#32451;&#31232;&#30095;&#31070;&#32463;&#32593;&#32476;&#20197;&#25191;&#34892;&#22522;&#22240;&#36873;&#25321;&#20219;&#21153;&#65292;&#20854;&#20013;&#28041;&#21450;&#22312;&#38750;&#24120;&#39640;&#32500;&#31354;&#38388;&#20013;&#25214;&#21040;&#30456;&#20851;&#29305;&#24449;&#65292;&#20197;&#21450;(2)&#31070;&#32463;&#32593;&#32476;&#21387;&#32553;&#20219;&#21153;&#65292;&#20808;&#21069;&#23581;&#35797;&#24212;&#29992;$L_1$&#24809;&#32602;&#30340;&#26041;&#27861;&#22343;&#26410;&#25104;&#21151;&#12290;&#20174;&#27010;&#24565;&#19978;&#35762;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#24357;&#21512;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#31232;&#30095;&#24615;&#21644;&#20256;&#32479;&#32479;&#35745;&#23398;&#20064;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose to minimize a generic differentiable loss function with $L_1$ penalty with a redundant reparametrization and straightforward stochastic gradient descent. Our proposal is the direct generalization of a series of previous ideas that the $L_1$ penalty may be equivalent to a differentiable reparametrization with weight decay. We prove that the proposed method, \textit{spred}, is an exact solver of $L_1$ and that the reparametrization trick is completely ``benign" for a generic nonconvex function. Practically, we demonstrate the usefulness of the method in (1) training sparse neural networks to perform gene selection tasks, which involves finding relevant features in a very high dimensional space, and (2) neural network compression task, to which previous attempts at applying the $L_1$-penalty have been unsuccessful. Conceptually, our result bridges the gap between the sparsity in deep learning and conventional statistical learning.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#26080;&#31351;&#23567;&#26799;&#24230;&#25552;&#21319;&#22312;&#22823;&#26679;&#26412;&#26497;&#38480;&#19979;&#30340;&#28176;&#36817;&#24615;&#36136;&#65292;&#35777;&#26126;&#20102;&#20854;&#25910;&#25947;&#21040;&#19968;&#20010;&#30830;&#23450;&#24615;&#36807;&#31243;&#65292;&#24182;&#25506;&#35752;&#20102;&#20854;&#20351;&#24471;&#27979;&#35797;&#35823;&#24046;&#20943;&#23567;&#30340;&#21160;&#21147;&#23398;&#20197;&#21450;&#20854;&#38271;&#26102;&#38388;&#34892;&#20026;&#12290;</title><link>http://arxiv.org/abs/2210.00736</link><description>&lt;p&gt;
&#26080;&#31351;&#23567;&#26799;&#24230;&#25552;&#21319;&#30340;&#22823;&#26679;&#26412;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
A large sample theory for infinitesimal gradient boosting. (arXiv:2210.00736v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.00736
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#30740;&#31350;&#20102;&#26080;&#31351;&#23567;&#26799;&#24230;&#25552;&#21319;&#22312;&#22823;&#26679;&#26412;&#26497;&#38480;&#19979;&#30340;&#28176;&#36817;&#24615;&#36136;&#65292;&#35777;&#26126;&#20102;&#20854;&#25910;&#25947;&#21040;&#19968;&#20010;&#30830;&#23450;&#24615;&#36807;&#31243;&#65292;&#24182;&#25506;&#35752;&#20102;&#20854;&#20351;&#24471;&#27979;&#35797;&#35823;&#24046;&#20943;&#23567;&#30340;&#21160;&#21147;&#23398;&#20197;&#21450;&#20854;&#38271;&#26102;&#38388;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#31351;&#23567;&#26799;&#24230;&#25552;&#21319;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#27969;&#34892;&#30340;&#22522;&#20110;&#26641;&#30340;&#26799;&#24230;&#25552;&#21319;&#31639;&#27861;&#30340;&#28040;&#22833;&#23398;&#20064;&#29575;&#26497;&#38480;&#12290;&#23427;&#34987;&#23450;&#20041;&#20026;&#22312;&#26080;&#31351;&#32500;&#20989;&#25968;&#31354;&#38388;&#20013;&#30340;&#38750;&#32447;&#24615;&#24120;&#24494;&#20998;&#26041;&#31243;&#30340;&#35299;&#65292;&#20854;&#20013;&#39537;&#21160;&#21160;&#21147;&#23398;&#30340;&#26080;&#31351;&#23567;&#25552;&#21319;&#31639;&#23376;&#20381;&#36182;&#20110;&#35757;&#32451;&#26679;&#26412;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#27169;&#22411;&#22312;&#22823;&#26679;&#26412;&#26497;&#38480;&#19979;&#30340;&#28176;&#36817;&#24615;&#36136;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#25910;&#25947;&#21040;&#19968;&#20010;&#30830;&#23450;&#24615;&#36807;&#31243;&#12290;&#36825;&#20010;&#31181;&#32676;&#26497;&#38480;&#20877;&#27425;&#34987;&#19968;&#20010;&#20381;&#36182;&#20110;&#31181;&#32676;&#20998;&#24067;&#30340;&#24494;&#20998;&#26041;&#31243;&#25152;&#25551;&#36848;&#12290;&#25105;&#20204;&#25506;&#35752;&#20102;&#36825;&#20010;&#31181;&#32676;&#26497;&#38480;&#30340;&#19968;&#20123;&#24615;&#36136;&#65306;&#25105;&#20204;&#35777;&#26126;&#20102;&#21160;&#21147;&#23398;&#20351;&#24471;&#27979;&#35797;&#35823;&#24046;&#20943;&#23567;&#65292;&#24182;&#32771;&#34385;&#20102;&#23427;&#22312;&#38271;&#26102;&#38388;&#34892;&#20026;&#19978;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Infinitesimal gradient boosting (Dombry and Duchamps, 2021) is defined as the vanishing-learning-rate limit of the popular tree-based gradient boosting algorithm from machine learning. It is characterized as the solution of a nonlinear ordinary differential equation in a infinite-dimensional function space where the infinitesimal boosting operator driving the dynamics depends on the training sample. We consider the asymptotic behavior of the model in the large sample limit and prove its convergence to a deterministic process. This population limit is again characterized by a differential equation that depends on the population distribution. We explore some properties of this population limit: we prove that the dynamics makes the test error decrease and we consider its long time behavior.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21457;&#23637;&#20102;&#19968;&#31181;&#21160;&#24577;&#22343;&#22330;&#35268;&#21010;&#26041;&#27861;&#65292;&#29992;&#20110;&#26377;&#38480;&#29366;&#24577;&#21644;&#34892;&#20026;&#30340;&#36125;&#21494;&#26031;&#24378;&#21270;&#23398;&#20064;&#12290;&#36890;&#36807;&#27169;&#25311;&#32479;&#35745;&#29289;&#29702;&#20013;&#30340;&#27010;&#24565;&#65292;&#30740;&#31350;&#20102;&#36125;&#23572;&#26364;&#26041;&#31243;&#20316;&#20026;&#19968;&#31181;&#26080;&#24207;&#21160;&#21147;&#23398;&#31995;&#32479;&#65292;&#24182;&#36890;&#36807;&#22343;&#22330;&#26041;&#31243;&#35745;&#31639;&#29366;&#24577;&#34892;&#20026;&#20540;&#30340;&#32479;&#35745;&#20449;&#24687;&#12290;</title><link>http://arxiv.org/abs/2206.05200</link><description>&lt;p&gt;
&#21160;&#24577;&#22343;&#22330;&#35268;&#21010;
&lt;/p&gt;
&lt;p&gt;
Dynamic mean field programming. (arXiv:2206.05200v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.05200
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21457;&#23637;&#20102;&#19968;&#31181;&#21160;&#24577;&#22343;&#22330;&#35268;&#21010;&#26041;&#27861;&#65292;&#29992;&#20110;&#26377;&#38480;&#29366;&#24577;&#21644;&#34892;&#20026;&#30340;&#36125;&#21494;&#26031;&#24378;&#21270;&#23398;&#20064;&#12290;&#36890;&#36807;&#27169;&#25311;&#32479;&#35745;&#29289;&#29702;&#20013;&#30340;&#27010;&#24565;&#65292;&#30740;&#31350;&#20102;&#36125;&#23572;&#26364;&#26041;&#31243;&#20316;&#20026;&#19968;&#31181;&#26080;&#24207;&#21160;&#21147;&#23398;&#31995;&#32479;&#65292;&#24182;&#36890;&#36807;&#22343;&#22330;&#26041;&#31243;&#35745;&#31639;&#29366;&#24577;&#34892;&#20026;&#20540;&#30340;&#32479;&#35745;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22823;&#29366;&#24577;&#31354;&#38388;&#38480;&#21046;&#19979;&#65292;&#21457;&#23637;&#20102;&#19968;&#31181;&#21160;&#24577;&#22343;&#22330;&#29702;&#35770;&#65292;&#29992;&#20110;&#26377;&#38480;&#29366;&#24577;&#21644;&#34892;&#20026;&#30340;&#36125;&#21494;&#26031;&#24378;&#21270;&#23398;&#20064;&#12290;&#31867;&#27604;&#20110;&#32479;&#35745;&#29289;&#29702;&#23398;&#65292;&#23545;&#36125;&#23572;&#26364;&#26041;&#31243;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#23558;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#36716;&#31227;&#27010;&#29575;&#35299;&#37322;&#20026;&#32806;&#21512;&#65292;&#23558;&#20540;&#20989;&#25968;&#35299;&#37322;&#20026;&#21160;&#24577;&#28436;&#21270;&#30340;&#30830;&#23450;&#24615;&#33258;&#26059;&#12290;&#22240;&#27492;&#65292;&#24179;&#22343;&#22238;&#25253;&#21644;&#36716;&#31227;&#27010;&#29575;&#34987;&#35748;&#20026;&#26159;&#28140;&#28781;&#38543;&#26426;&#21464;&#37327;&#12290;&#35813;&#29702;&#35770;&#25581;&#31034;&#20102;&#22312;&#26576;&#20123;&#20551;&#35774;&#19979;&#65292;&#22312;&#28176;&#36817;&#29366;&#24577;&#31354;&#38388;&#26497;&#38480;&#19979;&#65292;&#29366;&#24577;&#34892;&#20026;&#20540;&#22312;&#29366;&#24577;&#34892;&#20026;&#23545;&#20043;&#38388;&#20855;&#26377;&#32479;&#35745;&#29420;&#31435;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#30830;&#20999;&#30340;&#20998;&#24067;&#24418;&#24335;&#12290;&#36825;&#20123;&#32467;&#26524;&#36866;&#29992;&#20110;&#26377;&#38480;&#21644;&#26080;&#38480;&#25240;&#29616;&#26102;&#38388;&#35270;&#37326;&#65292;&#22312;&#20215;&#20540;&#36845;&#20195;&#21644;&#31574;&#30053;&#35780;&#20272;&#20013;&#22343;&#25104;&#31435;&#12290;&#29366;&#24577;&#34892;&#20026;&#20540;&#30340;&#32479;&#35745;&#20449;&#24687;&#21487;&#20197;&#20174;&#19968;&#32452;&#22343;&#22330;&#26041;&#31243;&#20013;&#35745;&#31639;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#21160;&#24577;&#22343;&#22330;&#35268;&#21010;&#65288;DMFP&#65289;&#12290;&#23545;&#20110;&#31574;&#30053;&#35780;&#20272;&#65292;&#21487;&#20197;&#20351;&#29992;&#26399;&#26395;&#20540;&#36845;&#20195;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
A dynamic mean field theory is developed for finite state and action Bayesian reinforcement learning in the large state space limit. In an analogy with statistical physics, the Bellman equation is studied as a disordered dynamical system; the Markov decision process transition probabilities are interpreted as couplings and the value functions as deterministic spins that evolve dynamically. Thus, the mean-rewards and transition probabilities are considered to be quenched random variables. The theory reveals that, under certain assumptions, the state-action values are statistically independent across state-action pairs in the asymptotic state space limit, and provides the form of the distribution exactly. The results hold in the finite and discounted infinite horizon settings, for both value iteration and policy evaluation. The state-action value statistics can be computed from a set of mean field equations, which we call dynamic mean field programming (DMFP). For policy evaluation the e
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#32780;&#27835;&#20043;&#30340;&#34701;&#21512;&#26041;&#27861;&#65292;&#22312;&#35299;&#20915;&#20998;&#24067;&#24335;&#8220;&#22823;&#25968;&#25454;&#8221;&#38382;&#39064;&#25110;&#22810;&#26041;&#38544;&#31169;&#32422;&#26463;&#26102;&#65292;&#36890;&#36807;&#31934;&#30830;&#33945;&#29305;&#21345;&#32599;&#36817;&#20284;&#26469;&#25913;&#21892;&#21518;&#39564;&#20998;&#24067;&#30340;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2110.07265</link><description>&lt;p&gt;
&#20998;&#32780;&#27835;&#20043;&#34701;&#21512;
&lt;/p&gt;
&lt;p&gt;
Divide-and-Conquer Fusion. (arXiv:2110.07265v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.07265
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#32780;&#27835;&#20043;&#30340;&#34701;&#21512;&#26041;&#27861;&#65292;&#22312;&#35299;&#20915;&#20998;&#24067;&#24335;&#8220;&#22823;&#25968;&#25454;&#8221;&#38382;&#39064;&#25110;&#22810;&#26041;&#38544;&#31169;&#32422;&#26463;&#26102;&#65292;&#36890;&#36807;&#31934;&#30830;&#33945;&#29305;&#21345;&#32599;&#36817;&#20284;&#26469;&#25913;&#21892;&#21518;&#39564;&#20998;&#24067;&#30340;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23558;&#20960;&#20010;&#65288;&#26679;&#26412;&#36924;&#36817;&#30340;&#65289;&#20998;&#24067;&#65292;&#25105;&#20204;&#31216;&#20026;&#23376;&#21518;&#39564;&#20998;&#24067;&#65292;&#32467;&#21512;&#25104;&#19968;&#20010;&#27604;&#20363;&#20026;&#23427;&#20204;&#20056;&#31215;&#30340;&#21333;&#19968;&#20998;&#24067;&#26159;&#19968;&#20010;&#24120;&#35265;&#30340;&#25361;&#25112;&#12290;&#36825;&#22312;&#20998;&#24067;&#24335;&#8220;&#22823;&#25968;&#25454;&#8221;&#38382;&#39064;&#20013;&#32463;&#24120;&#21457;&#29983;&#65292;&#25110;&#32773;&#22312;&#22810;&#26041;&#38544;&#31169;&#32422;&#26463;&#19979;&#24037;&#20316;&#26102;&#20250;&#36935;&#21040;&#12290;&#35768;&#22810;&#29616;&#26377;&#26041;&#27861;&#37117;&#37319;&#29992;&#36817;&#20284;&#23376;&#21518;&#39564;&#30340;&#26041;&#24335;&#65292;&#28982;&#21518;&#25214;&#21040;&#32467;&#26524;&#65288;&#20135;&#21697;&#27719;&#24635;&#65289;&#21518;&#39564;&#30340;&#35299;&#26512;&#36817;&#20284;&#25110;&#26679;&#26412;&#36817;&#20284;&#12290;&#23545;&#20110;&#36825;&#20123;&#26041;&#27861;&#65292;&#24403;&#23376;&#21518;&#39564;&#20998;&#24067;&#36229;&#20986;&#19968;&#23450;&#33539;&#22260;&#65288;&#27604;&#22914;&#36817;&#20284;&#20026;&#39640;&#26031;&#20998;&#24067;&#65289;&#26102;&#65292;&#21518;&#39564;&#36817;&#20284;&#30340;&#36136;&#37327;&#36739;&#24046;&#12290;&#26368;&#36817;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#34701;&#21512;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#25214;&#21040;&#20102;&#21518;&#39564;&#30340;&#31934;&#30830;&#33945;&#29305;&#21345;&#32599;&#36817;&#20284;&#65292;&#36991;&#20813;&#20102;&#36817;&#20284;&#26041;&#27861;&#30340;&#32570;&#28857;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#29616;&#26377;&#34701;&#21512;&#26041;&#27861;&#23384;&#22312;&#19968;&#20123;&#35745;&#31639;&#38480;&#21046;&#65292;&#29305;&#21035;&#26159;&#24403;&#25972;&#21512;&#22823;&#37327;&#23376;&#21518;&#39564;&#26102;&#12290;
&lt;/p&gt;
&lt;p&gt;
Combining several (sample approximations of) distributions, which we term sub-posteriors, into a single distribution proportional to their product, is a common challenge. Occurring, for instance, in distributed 'big data' problems, or when working under multi-party privacy constraints. Many existing approaches resort to approximating the individual sub-posteriors for practical necessity, then find either an analytical approximation or sample approximation of the resulting (product-pooled) posterior. The quality of the posterior approximation for these approaches is poor when the sub-posteriors fall out-with a narrow range of distributional form, such as being approximately Gaussian. Recently, a Fusion approach has been proposed which finds an exact Monte Carlo approximation of the posterior, circumventing the drawbacks of approximate approaches. Unfortunately, existing Fusion approaches have a number of computational limitations, particularly when unifying a large number of sub-posteri
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#36817;&#37051;&#30340;&#25490;&#21517;&#20013;&#24515;&#24615;&#26041;&#27861;&#65292;&#29992;&#20110;&#21160;&#24577;&#25490;&#21517;&#38382;&#39064;&#65292;&#22312;&#21160;&#24577;&#35774;&#32622;&#20013;&#25193;&#23637;&#20102;&#32463;&#20856;&#30340;BTL&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2109.13743</link><description>&lt;p&gt;
&#20351;&#29992;BTL&#27169;&#22411;&#30340;&#21160;&#24577;&#25490;&#21517;&#65306;&#19968;&#31181;&#22522;&#20110;&#26368;&#36817;&#37051;&#30340;&#25490;&#21517;&#20013;&#24515;&#24615;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Dynamic Ranking with the BTL Model: A Nearest Neighbor based Rank Centrality Method. (arXiv:2109.13743v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.13743
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#36817;&#37051;&#30340;&#25490;&#21517;&#20013;&#24515;&#24615;&#26041;&#27861;&#65292;&#29992;&#20110;&#21160;&#24577;&#25490;&#21517;&#38382;&#39064;&#65292;&#22312;&#21160;&#24577;&#35774;&#32622;&#20013;&#25193;&#23637;&#20102;&#32463;&#20856;&#30340;BTL&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#24212;&#29992;&#20363;&#22914;&#25512;&#33616;&#31995;&#32479;&#25110;&#20307;&#32946;&#27604;&#36187;&#28041;&#21450;&#21040;&#23545;n&#20010;&#29289;&#21697;&#36827;&#34892;&#25104;&#23545;&#27604;&#36739;&#65292;&#20854;&#30446;&#26631;&#26159;&#36890;&#36807;&#32858;&#21512;&#27604;&#36739;&#32467;&#26524;&#26469;&#24674;&#22797;&#29289;&#21697;&#30340;&#28508;&#22312;&#24378;&#24230;&#21644;/&#25110;&#20840;&#23616;&#25490;&#24207;&#12290;&#36817;&#24180;&#26469;&#65292;&#36825;&#20010;&#38382;&#39064;&#20174;&#29702;&#35770;&#35282;&#24230;&#24341;&#36215;&#20102;&#24456;&#22823;&#30340;&#20851;&#27880;&#65292;&#25552;&#20986;&#20102;&#35768;&#22810;&#26041;&#27861;&#65292;&#24182;&#22312;&#36866;&#24403;&#30340;&#29983;&#25104;&#27169;&#22411;&#20551;&#35774;&#19979;&#25552;&#20379;&#20102;&#30456;&#20851;&#30340;&#32479;&#35745;&#20445;&#35777;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#32467;&#26524;&#36890;&#24120;&#23558;&#25104;&#23545;&#27604;&#36739;&#25910;&#38598;&#20026;&#19968;&#20010;&#27604;&#36739;&#22270;G&#65292;&#20294;&#26159;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#65292;&#20363;&#22914;&#38182;&#26631;&#36187;&#26399;&#38388;&#30340;&#36275;&#29699;&#27604;&#36187;&#32467;&#26524;&#65292;&#25104;&#23545;&#27604;&#36739;&#30340;&#24615;&#36136;&#21487;&#33021;&#20250;&#38543;&#26102;&#38388;&#28436;&#21464;&#12290;&#19982;&#21069;&#36848;&#30340;&#38745;&#24577;&#35774;&#32622;&#30456;&#27604;&#65292;&#38024;&#23545;&#36825;&#31181;&#21160;&#24577;&#35774;&#32622;&#30340;&#29702;&#35770;&#32467;&#26524;&#30456;&#23545;&#26377;&#38480;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;&#32463;&#20856;&#30340;BTL&#65288;Bradley-Terry-Luce&#65289;&#27169;&#22411;&#25193;&#23637;&#21040;&#25105;&#20204;&#30340;&#21160;&#24577;&#35774;&#32622;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many applications such as recommendation systems or sports tournaments involve pairwise comparisons within a collection of $n$ items, the goal being to aggregate the binary outcomes of the comparisons in order to recover the latent strength and/or global ranking of the items. In recent years, this problem has received significant interest from a theoretical perspective with a number of methods being proposed, along with associated statistical guarantees under the assumption of a suitable generative model.  While these results typically collect the pairwise comparisons as one comparison graph $G$, however in many applications - such as the outcomes of soccer matches during a tournament - the nature of pairwise outcomes can evolve with time. Theoretical results for such a dynamic setting are relatively limited compared to the aforementioned static setting. We study in this paper an extension of the classic BTL (Bradley-Terry-Luce) model for the static setting to our dynamic setup under t
&lt;/p&gt;</description></item><item><title>&#22810;&#31867;&#20998;&#31867;&#20013;&#30340;&#33391;&#24615;&#36807;&#25311;&#21512;&#38382;&#39064;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#30830;&#23450;&#24615;&#26465;&#20214;&#65292;&#24403;&#21069;&#19977;&#31181;&#31639;&#27861;&#22312;&#28385;&#36275;&#26465;&#20214;&#26102;&#20250;&#24471;&#21040;&#25554;&#20540;&#25968;&#25454;&#24182;&#20855;&#26377;&#30456;&#31561;&#20934;&#30830;&#29575;&#30340;&#20998;&#31867;&#22120;&#12290;</title><link>http://arxiv.org/abs/2106.10865</link><description>&lt;p&gt;
&#22810;&#31867;&#20998;&#31867;&#20013;&#30340;&#33391;&#24615;&#36807;&#25311;&#21512;&#65306;&#25152;&#26377;&#36335;&#24452;&#37117;&#36890;&#24448;&#25554;&#20540;
&lt;/p&gt;
&lt;p&gt;
Benign Overfitting in Multiclass Classification: All Roads Lead to Interpolation. (arXiv:2106.10865v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.10865
&lt;/p&gt;
&lt;p&gt;
&#22810;&#31867;&#20998;&#31867;&#20013;&#30340;&#33391;&#24615;&#36807;&#25311;&#21512;&#38382;&#39064;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#30830;&#23450;&#24615;&#26465;&#20214;&#65292;&#24403;&#21069;&#19977;&#31181;&#31639;&#27861;&#22312;&#28385;&#36275;&#26465;&#20214;&#26102;&#20250;&#24471;&#21040;&#25554;&#20540;&#25968;&#25454;&#24182;&#20855;&#26377;&#30456;&#31561;&#20934;&#30830;&#29575;&#30340;&#20998;&#31867;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36229;&#21442;&#25968;&#21270;&#27169;&#22411;&#20013;&#65292;&#8220;&#33391;&#24615;&#36807;&#25311;&#21512;&#8221;&#30340;&#25991;&#29486;&#22823;&#22810;&#23616;&#38480;&#20110;&#22238;&#24402;&#25110;&#20108;&#20998;&#31867;&#38382;&#39064;&#65307;&#28982;&#32780;&#65292;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#22312;&#22810;&#31867;&#21035;&#35774;&#32622;&#20013;&#36816;&#34892;&#12290;&#21463;&#27492;&#24046;&#24322;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22810;&#31867;&#32447;&#24615;&#20998;&#31867;&#20013;&#30340;&#33391;&#24615;&#36807;&#25311;&#21512;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#32771;&#34385;&#22312;&#21487;&#20998;&#25968;&#25454;&#19978;&#30340;&#20197;&#19979;&#35757;&#32451;&#31639;&#27861;&#65306;&#65288;i&#65289;&#20132;&#21449;&#29109;&#25439;&#22833;&#30340;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;ERM&#65289;&#65292;&#25910;&#25947;&#21040;&#22810;&#31867;&#25903;&#25345;&#21521;&#37327;&#26426;&#65288;SVM&#65289;&#35299;&#65307;&#65288;ii&#65289;&#26368;&#23567;&#20108;&#20056;&#25439;&#22833;&#30340;ERM&#65292;&#25910;&#25947;&#21040;&#26368;&#23567;&#33539;&#25968;&#25554;&#20540;&#65288;MNI&#65289;&#35299;&#65307;&#21450;&#65288;iii&#65289;&#19968;&#23545;&#22810;SVM&#20998;&#31867;&#22120;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#20805;&#20998;&#30830;&#23450;&#24615;&#26465;&#20214;&#65292;&#22312;&#35813;&#26465;&#20214;&#19979;&#65292;&#25152;&#26377;&#19977;&#31181;&#31639;&#27861;&#37117;&#20250;&#23548;&#33268;&#25554;&#20540;&#35757;&#32451;&#25968;&#25454;&#24182;&#20855;&#26377;&#30456;&#31561;&#20934;&#30830;&#29575;&#30340;&#20998;&#31867;&#22120;&#12290;&#24403;&#25968;&#25454;&#26469;&#33258;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#25110;&#22810;&#39033;&#24335;&#36923;&#36753;&#27169;&#22411;&#26102;&#65292;&#22312;&#36275;&#22815;&#39640;&#30340;&#26377;&#25928;&#36229;&#21442;&#25968;&#21270;&#19979;&#65292;&#36825;&#20010;&#26465;&#20214;&#25104;&#31435;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;...
&lt;/p&gt;
&lt;p&gt;
The literature on "benign overfitting" in overparameterized models has been mostly restricted to regression or binary classification; however, modern machine learning operates in the multiclass setting. Motivated by this discrepancy, we study benign overfitting in multiclass linear classification. Specifically, we consider the following training algorithms on separable data: (i) empirical risk minimization (ERM) with cross-entropy loss, which converges to the multiclass support vector machine (SVM) solution; (ii) ERM with least-squares loss, which converges to the min-norm interpolating (MNI) solution; and, (iii) the one-vs-all SVM classifier. First, we provide a simple sufficient deterministic condition under which all three algorithms lead to classifiers that interpolate the training data and have equal accuracy. When the data is generated from Gaussian mixtures or a multinomial logistic model, this condition holds under high enough effective overparameterization. We also show that t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#31163;&#32447;&#25968;&#25454;&#23545;&#24378;&#21270;&#23398;&#20064;&#30340;&#36951;&#25022;&#65292;&#25552;&#20986;&#20102;&#31934;&#32454;&#30340;&#25910;&#25947;&#36895;&#29575;&#20998;&#26512;&#65292;&#25581;&#31034;&#20102;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#25910;&#25947;&#36895;&#24230;&#36739;&#24555;&#30340;&#29616;&#35937;&#65292;&#24182;&#36890;&#36807;&#25351;&#25968;&#24418;&#24335;&#30340;&#21152;&#36895;&#26426;&#21046;&#21152;&#24555;&#20102;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2102.00479</link><description>&lt;p&gt;
&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#36951;&#25022;&#24555;&#36895;&#25910;&#25947;&#36895;&#29575;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Fast Rates for the Regret of Offline Reinforcement Learning. (arXiv:2102.00479v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2102.00479
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31163;&#32447;&#25968;&#25454;&#23545;&#24378;&#21270;&#23398;&#20064;&#30340;&#36951;&#25022;&#65292;&#25552;&#20986;&#20102;&#31934;&#32454;&#30340;&#25910;&#25947;&#36895;&#29575;&#20998;&#26512;&#65292;&#25581;&#31034;&#20102;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#25910;&#25947;&#36895;&#24230;&#36739;&#24555;&#30340;&#29616;&#35937;&#65292;&#24182;&#36890;&#36807;&#25351;&#25968;&#24418;&#24335;&#30340;&#21152;&#36895;&#26426;&#21046;&#21152;&#24555;&#20102;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22266;&#23450;&#34892;&#20026;&#31574;&#30053;&#22312;&#26080;&#38480;&#26102;&#38388;&#25240;&#29616;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDP&#65289;&#20013;&#29983;&#25104;&#30340;&#31163;&#32447;&#25968;&#25454;&#23545;&#24378;&#21270;&#23398;&#20064;&#30340;&#36951;&#25022;&#12290;&#29616;&#26377;&#26041;&#27861;&#65288;&#22914;&#25311;&#21512;Q-&#36845;&#20195;&#65289;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#23545;&#20110;&#36951;&#25022;&#30340;&#25910;&#25947;&#36895;&#29575;&#26159;O(1/&#8730;n)&#65292;&#20294;&#23454;&#35777;&#34892;&#20026;&#34920;&#29616;&#20986;&#38750;&#24120;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;&#26412;&#25991;&#36890;&#36807;&#25552;&#20379;&#36951;&#25022;&#25910;&#25947;&#36895;&#29575;&#30340;&#24555;&#36895;&#25910;&#25947;&#36827;&#34892;&#26356;&#31934;&#32454;&#30340;&#36951;&#25022;&#20998;&#26512;&#65292;&#20934;&#30830;&#22320;&#34920;&#24449;&#20102;&#36825;&#19968;&#29616;&#35937;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#32473;&#23450;&#26368;&#20248;&#36136;&#37327;&#20989;&#25968;Q*&#30340;&#20272;&#35745;&#30340;&#24773;&#20917;&#19979;&#65292;&#20854;&#23545;&#24212;&#30340;&#31574;&#30053;&#36951;&#25022;&#25353;&#29031;Q*&#20272;&#35745;&#30340;&#28857;&#23545;&#28857;&#25910;&#25947;&#36895;&#29575;&#30340;&#25351;&#25968;&#36827;&#34892;&#25910;&#25947;&#65292;&#20174;&#32780;&#21152;&#36895;&#20102;&#25910;&#25947;&#36895;&#24230;&#12290;&#25351;&#25968;&#30340;&#32423;&#21035;&#21462;&#20915;&#20110;&#8220;&#20915;&#31574;&#38382;&#39064;&#8221;&#20013;&#30340;&#22122;&#22768;&#27700;&#24179;&#65292;&#32780;&#19981;&#26159;&#20272;&#35745;&#38382;&#39064;&#12290;&#25105;&#20204;&#20197;&#32447;&#24615;&#21644;&#34920;&#26684;&#22411;MDP&#20316;&#20026;&#31034;&#20363;&#65292;&#24314;&#31435;&#20102;&#36825;&#26679;&#30340;&#22122;&#22768;&#27700;&#24179;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#23545;&#25311;&#21512;Q-&#36845;&#20195;&#21644;Bellman&#27531;&#24046;&#36827;&#34892;&#20102;&#26032;&#30340;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the regret of reinforcement learning from offline data generated by a fixed behavior policy in an infinite-horizon discounted Markov decision process (MDP). While existing analyses of common approaches, such as fitted $Q$-iteration (FQI), suggest a $O(1/\sqrt{n})$ convergence for regret, empirical behavior exhibits \emph{much} faster convergence. In this paper, we present a finer regret analysis that exactly characterizes this phenomenon by providing fast rates for the regret convergence. First, we show that given any estimate for the optimal quality function $Q^*$, the regret of the policy it defines converges at a rate given by the exponentiation of the $Q^*$-estimate's pointwise convergence rate, thus speeding it up. The level of exponentiation depends on the level of noise in the \emph{decision-making} problem, rather than the estimation problem. We establish such noise levels for linear and tabular MDPs as examples. Second, we provide new analyses of FQI and Bellman resid
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20998;&#26512;&#21517;&#23383;&#20013;&#30340;&#23383;&#31526;&#24207;&#21015;&#65292;&#21487;&#20197;&#39044;&#27979;&#31181;&#26063;&#21644;&#27665;&#26063;&#65292;&#24182;&#24212;&#29992;&#20110;&#31454;&#36873;&#36164;&#37329;&#25968;&#25454;&#21644;&#26032;&#38395;&#25253;&#36947;&#20013;&#12290;</title><link>http://arxiv.org/abs/1805.02109</link><description>&lt;p&gt;
&#20174;&#21517;&#23383;&#20013;&#30340;&#23383;&#31526;&#24207;&#21015;&#39044;&#27979;&#31181;&#26063;&#21644;&#27665;&#26063;
&lt;/p&gt;
&lt;p&gt;
Predicting Race and Ethnicity From the Sequence of Characters in a Name. (arXiv:1805.02109v2 [stat.AP] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1805.02109
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20998;&#26512;&#21517;&#23383;&#20013;&#30340;&#23383;&#31526;&#24207;&#21015;&#65292;&#21487;&#20197;&#39044;&#27979;&#31181;&#26063;&#21644;&#27665;&#26063;&#65292;&#24182;&#24212;&#29992;&#20110;&#31454;&#36873;&#36164;&#37329;&#25968;&#25454;&#21644;&#26032;&#38395;&#25253;&#36947;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#22238;&#31572;&#20851;&#20110;&#31181;&#26063;&#19981;&#24179;&#31561;&#21644;&#20844;&#27491;&#24615;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#32463;&#24120;&#38656;&#35201;&#19968;&#31181;&#20174;&#21517;&#23383;&#20013;&#25512;&#26029;&#31181;&#26063;&#21644;&#27665;&#26063;&#30340;&#26041;&#27861;&#12290;&#19968;&#31181;&#20174;&#21517;&#23383;&#20013;&#25512;&#26029;&#31181;&#26063;&#21644;&#27665;&#26063;&#30340;&#26041;&#27861;&#26159;&#20381;&#36182;&#20110;&#20154;&#21475;&#26222;&#26597;&#23616;&#30340;&#28909;&#38376;&#22995;&#27663;&#21015;&#34920;&#12290;&#28982;&#32780;&#65292;&#35813;&#21015;&#34920;&#23384;&#22312;&#33267;&#23569;&#19977;&#20010;&#38480;&#21046;&#65306;1. &#23427;&#21482;&#21253;&#21547;&#22995;&#27663;&#65292;2. &#23427;&#21482;&#21253;&#21547;&#24120;&#35265;&#30340;&#22995;&#27663;&#65292;3. &#23427;&#27599;10&#24180;&#26356;&#26032;&#19968;&#27425;&#12290;&#20026;&#20102;&#25552;&#20379;&#26356;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#24182;&#22312;&#21517;&#23383;&#21487;&#29992;&#26102;&#25552;&#39640;&#20934;&#30830;&#24615;&#65292;&#25105;&#20204;&#20351;&#29992;&#21508;&#31181;&#25216;&#26415;&#24314;&#31435;&#20102;&#21517;&#23383;&#20013;&#30340;&#23383;&#31526;&#19982;&#31181;&#26063;&#21644;&#27665;&#26063;&#20043;&#38388;&#30340;&#20851;&#31995;&#27169;&#22411;&#12290;&#20351;&#29992;&#38271;&#30701;&#26399;&#35760;&#24518;&#30340;&#27169;&#22411;&#20855;&#26377;&#26368;&#20339;&#30340;&#26679;&#26412;&#22806;&#20934;&#30830;&#24615;&#65292;&#20026;0.85&#12290;&#26368;&#20339;&#34920;&#29616;&#30340;&#22995;&#27663;&#27169;&#22411;&#30340;&#26679;&#26412;&#22806;&#20934;&#30830;&#24615;&#20026;0.81&#12290;&#20026;&#20102;&#35828;&#26126;&#27169;&#22411;&#30340;&#23454;&#29992;&#24615;&#65292;&#25105;&#20204;&#23558;&#20854;&#24212;&#29992;&#20110;&#31454;&#36873;&#36164;&#37329;&#25968;&#25454;&#65292;&#20272;&#35745;&#19981;&#21516;&#31181;&#26063;&#32676;&#20307;&#30340;&#25424;&#27454;&#20221;&#39069;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#26032;&#38395;&#25968;&#25454;&#65292;&#20272;&#35745;&#26032;&#38395;&#20013;&#21508;&#31181;&#31181;&#26063;&#21644;&#27665;&#26063;&#30340;&#25253;&#36947;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
To answer questions about racial inequality and fairness, we often need a way to infer race and ethnicity from names. One way to infer race and ethnicity from names is by relying on the Census Bureau's list of popular last names. The list, however, suffers from at least three limitations: 1. it only contains last names, 2. it only includes popular last names, and 3. it is updated once every 10 years. To provide better generalization, and higher accuracy when first names are available, we model the relationship between characters in a name and race and ethnicity using various techniques. A model using Long Short-Term Memory works best with out-of-sample accuracy of .85. The best-performing last-name model achieves out-of-sample accuracy of .81. To illustrate the utility of the models, we apply them to campaign finance data to estimate the share of donations made by people of various racial groups, and to news data to estimate the coverage of various races and ethnicities in the news.
&lt;/p&gt;</description></item></channel></rss>