<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>PPI++&#26159;&#19968;&#31181;&#39640;&#25928;&#30340;&#39044;&#27979;&#39537;&#21160;&#25512;&#29702;&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#21160;&#35843;&#25972;&#39044;&#27979;&#36136;&#37327;&#26469;&#25913;&#21892;&#32463;&#20856;&#21306;&#38388;&#30340;&#35745;&#31639;&#32622;&#20449;&#21306;&#38388;&#30340;&#35745;&#31639;&#25928;&#29575;&#21644;&#32479;&#35745;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2311.01453</link><description>&lt;p&gt;
PPI++:&#39640;&#25928;&#30340;&#39044;&#27979;&#39537;&#21160;&#25512;&#29702;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
PPI++: Efficient Prediction-Powered Inference. (arXiv:2311.01453v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01453
&lt;/p&gt;
&lt;p&gt;
PPI++&#26159;&#19968;&#31181;&#39640;&#25928;&#30340;&#39044;&#27979;&#39537;&#21160;&#25512;&#29702;&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#21160;&#35843;&#25972;&#39044;&#27979;&#36136;&#37327;&#26469;&#25913;&#21892;&#32463;&#20856;&#21306;&#38388;&#30340;&#35745;&#31639;&#32622;&#20449;&#21306;&#38388;&#30340;&#35745;&#31639;&#25928;&#29575;&#21644;&#32479;&#35745;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;PPI++&#65306;&#19968;&#31181;&#22522;&#20110;&#23567;&#22411;&#26631;&#35760;&#25968;&#25454;&#38598;&#21644;&#36890;&#24120;&#27604;&#36739;&#22823;&#30340;&#26426;&#22120;&#23398;&#20064;&#39044;&#27979;&#25968;&#25454;&#38598;&#30340;&#35745;&#31639;&#36731;&#37327;&#32423;&#30340;&#20272;&#35745;&#21644;&#25512;&#29702;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#33258;&#21160;&#36866;&#24212;&#21487;&#29992;&#39044;&#27979;&#30340;&#36136;&#37327;&#65292;&#20135;&#29983;&#26131;&#20110;&#35745;&#31639;&#30340;&#32622;&#20449;&#21306;&#38388; - &#23545;&#20110;&#20219;&#24847;&#32500;&#24230;&#30340;&#21442;&#25968; - &#24635;&#26159;&#33021;&#22815;&#22312;&#21482;&#20351;&#29992;&#26631;&#35760;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#25913;&#21892;&#32463;&#20856;&#21306;&#38388;&#12290;PPI++&#22522;&#20110;&#39044;&#27979;&#39537;&#21160;&#25512;&#29702;&#65288;PPI&#65289;&#65292;&#38024;&#23545;&#30456;&#21516;&#30340;&#38382;&#39064;&#22330;&#26223;&#65292;&#25552;&#39640;&#20102;&#35745;&#31639;&#21644;&#32479;&#35745;&#25928;&#29575;&#12290;&#30495;&#23454;&#21644;&#21512;&#25104;&#23454;&#39564;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#25913;&#36827;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present PPI++: a computationally lightweight methodology for estimation and inference based on a small labeled dataset and a typically much larger dataset of machine-learning predictions. The methods automatically adapt to the quality of available predictions, yielding easy-to-compute confidence sets -for parameters of any dimensionality -- that always improve on classical intervals using only the labeled data. PPI++ builds on prediction-powered inference (PPI), which targets the same problem setting, improving its computational and statistical efficiency. Real and synthetic experiments demonstrate the benefits of the proposed adaptations.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#65292;&#22312;&#26410;&#30693;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#20351;&#29992;&#23545;&#27604;&#30697;&#26469;&#23398;&#20064;&#20855;&#26377;&#36793;&#32536;&#30340;&#39640;&#32500;&#21322;&#31354;&#38388;&#65292;&#32780;&#19981;&#38656;&#35201;&#26631;&#31614;&#65292;&#24182;&#22312;&#36825;&#20010;&#20998;&#24067;&#20551;&#35774;&#19979;&#24314;&#31435;&#20102;&#38544;&#34255;&#21322;&#31354;&#38388;&#30340;&#21807;&#19968;&#24615;&#21644;&#39640;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2311.01435</link><description>&lt;p&gt;
&#23545;&#27604;&#30697;&#65306;&#22810;&#39033;&#24335;&#26102;&#38388;&#26080;&#30417;&#30563;&#21322;&#31354;&#38388;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Contrastive Moments: Unsupervised Halfspace Learning in Polynomial Time. (arXiv:2311.01435v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01435
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#65292;&#22312;&#26410;&#30693;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#20351;&#29992;&#23545;&#27604;&#30697;&#26469;&#23398;&#20064;&#20855;&#26377;&#36793;&#32536;&#30340;&#39640;&#32500;&#21322;&#31354;&#38388;&#65292;&#32780;&#19981;&#38656;&#35201;&#26631;&#31614;&#65292;&#24182;&#22312;&#36825;&#20010;&#20998;&#24067;&#20551;&#35774;&#19979;&#24314;&#31435;&#20102;&#38544;&#34255;&#21322;&#31354;&#38388;&#30340;&#21807;&#19968;&#24615;&#21644;&#39640;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#29615;&#22659;&#20998;&#24067;&#26159;&#26410;&#30693;&#20851;&#20110;d&#32500;&#31354;&#38388;d&#20493;&#23545;&#31216;&#12289;&#23545;&#25968;&#20985;&#30340;&#20998;&#24067;&#30340;&#20854;&#20013;&#19968;&#32452;&#20998;&#24067;&#65292;&#21322;&#31354;&#38388;&#26159;&#36890;&#36807;&#21024;&#38500;&#33267;&#23569;&#19968;&#20010;&#20998;&#37327;&#20998;&#24067;&#20013;&#30340;&#949;&#27604;&#20363;&#30340;&#25968;&#25454;&#24341;&#20837;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#26469;&#23398;&#20064;&#20855;&#26377;&#36793;&#32536;&#30340;&#39640;&#32500;&#21322;&#31354;&#38388;&#65292;&#30446;&#26631;&#26159;&#22312;&#25152;&#38656;&#30340;TV&#36317;&#31163;&#20869;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#19981;&#38656;&#35201;&#26631;&#31614;&#65292;&#24182;&#19988;&#22312;&#36825;&#20010;&#20998;&#24067;&#20551;&#35774;&#19979;&#24314;&#31435;&#20102;&#38544;&#34255;&#21322;&#31354;&#38388;&#30340;&#21807;&#19968;&#24615;&#65288;&#21644;&#39640;&#25928;&#24615;&#65289;&#12290;&#31639;&#27861;&#30340;&#26679;&#26412;&#21644;&#26102;&#38388;&#22797;&#26434;&#24615;&#22312;&#32500;&#24230;&#21644;1/&#949;&#19978;&#37117;&#26159;&#22810;&#39033;&#24335;&#12290;&#35813;&#31639;&#27861;&#21482;&#20351;&#29992;&#32463;&#39564;&#20998;&#24067;&#30340;&#36866;&#24403;&#37325;&#26032;&#21152;&#26435;&#30340;&#21069;&#20004;&#20010;&#30697;&#65292;&#25105;&#20204;&#23558;&#20854;&#31216;&#20026;&#23545;&#27604;&#30697;&#65307;&#20854;&#20998;&#26512;&#20351;&#29992;&#20102;&#20851;&#20110;&#24191;&#20041;Dirichlet&#22810;&#39033;&#24335;&#30340;&#32463;&#20856;&#20107;&#23454;&#65292;&#24182;&#19988;&#20851;&#38190;&#20381;&#36182;&#20110;&#23545;&#23545;&#25968;&#20985;&#25130;&#26029;&#30340;&#30697;&#27604;&#30340;&#19968;&#20010;&#26032;&#21333;&#35843;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
We give a polynomial-time algorithm for learning high-dimensional halfspaces with margins in $d$-dimensional space to within desired TV distance when the ambient distribution is an unknown affine transformation of the $d$-fold product of an (unknown) symmetric one-dimensional logconcave distribution, and the halfspace is introduced by deleting at least an $\epsilon$ fraction of the data in one of the component distributions. Notably, our algorithm does not need labels and establishes the unique (and efficient) identifiability of the hidden halfspace under this distributional assumption. The sample and time complexity of the algorithm are polynomial in the dimension and $1/\epsilon$. The algorithm uses only the first two moments of suitable re-weightings of the empirical distribution, which we call contrastive moments; its analysis uses classical facts about generalized Dirichlet polynomials and relies crucially on a new monotonicity property of the moment ratio of truncations of logcon
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#26680;&#25197;&#26354;&#20989;&#25968;&#23545;Mixup&#25968;&#25454;&#36827;&#34892;&#20010;&#24615;&#21270;&#22788;&#29702;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21160;&#24577;&#25913;&#21464;&#25554;&#20540;&#31995;&#25968;&#30340;&#27010;&#29575;&#20998;&#24067;&#26469;&#23454;&#29616;&#26356;&#39057;&#32321;&#21644;&#26356;&#24378;&#28872;&#30340;&#28151;&#21512;&#30456;&#20284;&#25968;&#25454;&#28857;&#12290;&#23454;&#39564;&#35777;&#26126;&#36825;&#31181;&#26041;&#27861;&#19981;&#20165;&#25552;&#39640;&#20102;&#27169;&#22411;&#24615;&#33021;&#65292;&#36824;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#26657;&#20934;&#24615;&#12290;</title><link>http://arxiv.org/abs/2311.01434</link><description>&lt;p&gt;
&#36890;&#36807;&#26680;&#25197;&#26354;&#20989;&#25968;&#23450;&#21046;Mixup&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Tailoring Mixup to Data using Kernel Warping functions. (arXiv:2311.01434v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01434
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#26680;&#25197;&#26354;&#20989;&#25968;&#23545;Mixup&#25968;&#25454;&#36827;&#34892;&#20010;&#24615;&#21270;&#22788;&#29702;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#21160;&#24577;&#25913;&#21464;&#25554;&#20540;&#31995;&#25968;&#30340;&#27010;&#29575;&#20998;&#24067;&#26469;&#23454;&#29616;&#26356;&#39057;&#32321;&#21644;&#26356;&#24378;&#28872;&#30340;&#28151;&#21512;&#30456;&#20284;&#25968;&#25454;&#28857;&#12290;&#23454;&#39564;&#35777;&#26126;&#36825;&#31181;&#26041;&#27861;&#19981;&#20165;&#25552;&#39640;&#20102;&#27169;&#22411;&#24615;&#33021;&#65292;&#36824;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#26657;&#20934;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#22686;&#24378;&#26159;&#23398;&#20064;&#39640;&#25928;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#37325;&#35201;&#22522;&#30784;&#12290;&#22312;&#25152;&#26377;&#25552;&#20986;&#30340;&#22686;&#24378;&#25216;&#26415;&#20013;&#65292;&#32447;&#24615;&#25554;&#20540;&#35757;&#32451;&#25968;&#25454;&#28857;&#65288;&#20063;&#31216;&#20026;Mixup&#65289;&#24050;&#34987;&#35777;&#26126;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#38750;&#24120;&#26377;&#25928;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#30740;&#31350;&#37117;&#38598;&#20013;&#22312;&#36873;&#25321;&#21512;&#36866;&#30340;&#28857;&#36827;&#34892;&#28151;&#21512;&#65292;&#25110;&#32773;&#24212;&#29992;&#22797;&#26434;&#30340;&#38750;&#32447;&#24615;&#25554;&#20540;&#65292;&#32780;&#25105;&#20204;&#21017;&#23545;&#26356;&#30456;&#20284;&#30340;&#28857;&#36827;&#34892;&#26356;&#39057;&#32321;&#21644;&#26356;&#24378;&#28872;&#30340;&#28151;&#21512;&#24863;&#20852;&#36259;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36890;&#36807;&#25197;&#26354;&#20989;&#25968;&#21160;&#24577;&#25913;&#21464;&#25554;&#20540;&#31995;&#25968;&#30340;&#27010;&#29575;&#20998;&#24067;&#30340;&#26041;&#27861;&#65292;&#21462;&#20915;&#20110;&#35201;&#32452;&#21512;&#30340;&#25968;&#25454;&#28857;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;&#19968;&#20010;&#39640;&#25928;&#32780;&#28789;&#27963;&#30340;&#26694;&#26550;&#26469;&#23454;&#29616;&#36825;&#19968;&#28857;&#65292;&#20197;&#36991;&#20813;&#22810;&#26679;&#24615;&#30340;&#25439;&#22833;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#20998;&#31867;&#21644;&#22238;&#24402;&#20219;&#21153;&#23454;&#39564;&#65292;&#32467;&#26524;&#26174;&#31034;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#26082;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#21448;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#26657;&#20934;&#24615;&#12290;&#20195;&#30721;&#21487;&#22312;https://github.com/ENSTA-U2IS/torch-uncertainty&#19978;&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data augmentation is an essential building block for learning efficient deep learning models. Among all augmentation techniques proposed so far, linear interpolation of training data points, also called mixup, has found to be effective for a large panel of applications. While the majority of works have focused on selecting the right points to mix, or applying complex non-linear interpolation, we are interested in mixing similar points more frequently and strongly than less similar ones. To this end, we propose to dynamically change the underlying distribution of interpolation coefficients through warping functions, depending on the similarity between data points to combine. We define an efficient and flexible framework to do so without losing in diversity. We provide extensive experiments for classification and regression tasks, showing that our proposed method improves both performance and calibration of models. Code available in https://github.com/ENSTA-U2IS/torch-uncertainty
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#24515;&#38598;&#30340;&#12289;&#28201;&#21644;&#21464;&#20998;&#21518;&#39564;&#30340;&#39640;&#26031;&#36807;&#31243;&#25512;&#29702;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#31232;&#30095;&#30340;&#12289;&#21487;&#35299;&#37322;&#30340;&#25968;&#25454;&#34920;&#31034;&#26469;&#38477;&#20302;&#21442;&#25968;&#22823;&#23567;&#65292;&#24182;&#19988;&#20855;&#26377;&#25968;&#20540;&#31283;&#23450;&#24615;&#21644;&#36739;&#20302;&#30340;&#26102;&#38388;&#21644;&#31354;&#38388;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2311.01409</link><description>&lt;p&gt;
&#22522;&#20110;&#26680;&#24515;&#38598;&#30340;&#12289;&#28201;&#21644;&#21464;&#20998;&#21518;&#39564;&#30340;&#31934;&#30830;&#21644;&#21487;&#25193;&#23637;&#38543;&#26426;&#39640;&#26031;&#36807;&#31243;&#25512;&#29702;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Coreset-based, Tempered Variational Posterior for Accurate and Scalable Stochastic Gaussian Process Inference. (arXiv:2311.01409v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01409
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#24515;&#38598;&#30340;&#12289;&#28201;&#21644;&#21464;&#20998;&#21518;&#39564;&#30340;&#39640;&#26031;&#36807;&#31243;&#25512;&#29702;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#31232;&#30095;&#30340;&#12289;&#21487;&#35299;&#37322;&#30340;&#25968;&#25454;&#34920;&#31034;&#26469;&#38477;&#20302;&#21442;&#25968;&#22823;&#23567;&#65292;&#24182;&#19988;&#20855;&#26377;&#25968;&#20540;&#31283;&#23450;&#24615;&#21644;&#36739;&#20302;&#30340;&#26102;&#38388;&#21644;&#31354;&#38388;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38543;&#26426;&#21464;&#20998;&#39640;&#26031;&#36807;&#31243;($\mathcal{GP}$)&#25512;&#29702;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#21487;&#23398;&#20064;&#30340;&#26435;&#37325;&#20266;&#36755;&#20837;&#36755;&#20986;&#28857;&#30340;&#21518;&#39564;&#65288;&#26680;&#24515;&#38598;&#65289;&#12290;&#19982;&#33258;&#30001;&#24418;&#24335;&#30340;&#21464;&#20998;&#26063;&#19981;&#21516;&#65292;&#25552;&#20986;&#30340;&#22522;&#20110;&#26680;&#24515;&#38598;&#30340;&#12289;&#28201;&#21644;&#21464;&#20998;&#30340;$\mathcal{GP}$&#65288;CVTGP&#65289;&#26159;&#22522;&#20110;$\mathcal{GP}$&#20808;&#39564;&#21644;&#25968;&#25454;&#20284;&#28982;&#20989;&#25968;&#26469;&#23450;&#20041;&#30340;&#65292;&#22240;&#27492;&#36866;&#24212;&#20102;&#24314;&#27169;&#30340;&#24402;&#32435;&#20559;&#24046;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#25552;&#20986;&#30340;&#21518;&#39564;&#36827;&#34892;&#28508;&#22312;&#30340;$\mathcal{GP}$&#26680;&#24515;&#38598;&#21464;&#37327;&#30340;&#36793;&#32536;&#21270;&#65292;&#25512;&#23548;&#20986;CVTGP&#30340;&#23545;&#25968;&#36793;&#38469;&#20284;&#28982;&#19979;&#30028;&#65292;&#24182;&#19988;&#35777;&#26126;&#20854;&#36866;&#29992;&#20110;&#38543;&#26426;&#20248;&#21270;&#12290;CVTGP&#36890;&#36807;&#21033;&#29992;&#22522;&#20110;&#26680;&#24515;&#38598;&#30340;&#28201;&#21644;&#21518;&#39564;&#26469;&#20943;&#23567;&#21487;&#23398;&#20064;&#21442;&#25968;&#30340;&#22823;&#23567;&#21040;$\mathcal{O}(M)$&#65292;&#20855;&#26377;&#25968;&#20540;&#31283;&#23450;&#24615;&#65292;&#24182;&#19988;&#36890;&#36807;&#25552;&#20379;&#31232;&#30095;&#19988;&#21487;&#35299;&#37322;&#30340;&#25968;&#25454;&#34920;&#31034;&#26469;&#20445;&#25345;$\mathcal{O}(M^3)$&#26102;&#38388;&#22797;&#26434;&#24230;&#21644;$\mathcal{O}(M^2)$&#31354;&#38388;&#22797;&#26434;&#24230;&#12290;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#22238;&#24402;&#38382;&#39064;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#20102;CVTGP&#30340;&#24615;&#33021;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a novel stochastic variational Gaussian process ($\mathcal{GP}$) inference method, based on a posterior over a learnable set of weighted pseudo input-output points (coresets). Instead of a free-form variational family, the proposed coreset-based, variational tempered family for $\mathcal{GP}$s (CVTGP) is defined in terms of the $\mathcal{GP}$ prior and the data-likelihood; hence, accommodating the modeling inductive biases. We derive CVTGP's lower bound for the log-marginal likelihood via marginalization of the proposed posterior over latent $\mathcal{GP}$ coreset variables, and show it is amenable to stochastic optimization. CVTGP reduces the learnable parameter size to $\mathcal{O}(M)$, enjoys numerical stability, and maintains $\mathcal{O}(M^3)$ time- and $\mathcal{O}(M^2)$ space-complexity, by leveraging a coreset-based tempered posterior that, in turn, provides sparse and explainable representations of the data. Results on simulated and real-world regression problems wi
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#19968;&#31181;&#29983;&#25104;&#26694;&#26550;&#65292;&#26088;&#22312;&#23558;&#33258;&#22238;&#24402;&#27169;&#22411;&#30340;&#26174;&#24335;&#36716;&#25442;&#20998;&#24067;&#21644;&#22522;&#20110;&#23545;&#25239;&#35757;&#32451;&#30340;&#38544;&#24335;&#36716;&#25442;&#30456;&#32467;&#21512;&#65292;&#36890;&#36807;&#23545;&#27604;&#20272;&#35745;&#35757;&#32451;&#20840;&#23616;&#33021;&#37327;&#27169;&#22411;&#65292;&#24182;&#20248;&#21270;&#26412;&#22320;&#36716;&#25442;&#31574;&#30053;&#26469;&#35299;&#20915;&#26102;&#38388;&#24207;&#21015;&#29983;&#25104;&#20013;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2311.01388</link><description>&lt;p&gt;
&#23545;&#27604;&#27169;&#20223;&#30340;&#26102;&#38388;&#24207;&#21015;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Time-series Generation by Contrastive Imitation. (arXiv:2311.01388v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01388
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#19968;&#31181;&#29983;&#25104;&#26694;&#26550;&#65292;&#26088;&#22312;&#23558;&#33258;&#22238;&#24402;&#27169;&#22411;&#30340;&#26174;&#24335;&#36716;&#25442;&#20998;&#24067;&#21644;&#22522;&#20110;&#23545;&#25239;&#35757;&#32451;&#30340;&#38544;&#24335;&#36716;&#25442;&#30456;&#32467;&#21512;&#65292;&#36890;&#36807;&#23545;&#27604;&#20272;&#35745;&#35757;&#32451;&#20840;&#23616;&#33021;&#37327;&#27169;&#22411;&#65292;&#24182;&#20248;&#21270;&#26412;&#22320;&#36716;&#25442;&#31574;&#30053;&#26469;&#35299;&#20915;&#26102;&#38388;&#24207;&#21015;&#29983;&#25104;&#20013;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32771;&#34385;&#23398;&#20064;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#29983;&#25104;&#27169;&#22411;&#12290;&#24207;&#21015;&#35774;&#32622;&#25552;&#20986;&#20102;&#19968;&#20010;&#29420;&#29305;&#30340;&#25361;&#25112;&#65306;&#29983;&#25104;&#22120;&#19981;&#20165;&#24212;&#35813;&#25429;&#25417;&#65288;&#36880;&#27493;&#65289;&#36716;&#25442;&#30340;&#26465;&#20214;&#21160;&#21147;&#23398;&#65292;&#32780;&#19988;&#20854;&#24320;&#29615;&#22238;&#28378;&#24212;&#35813;&#20445;&#25345;&#65288;&#22810;&#27493;&#65289;&#36712;&#36857;&#30340;&#32852;&#21512;&#20998;&#24067;&#12290;&#19968;&#26041;&#38754;&#65292;MLE&#35757;&#32451;&#30340;&#33258;&#22238;&#24402;&#27169;&#22411;&#20801;&#35768;&#23398;&#20064;&#21644;&#35745;&#31639;&#26174;&#24335;&#30340;&#36716;&#25442;&#20998;&#24067;&#65292;&#20294;&#22312;&#22238;&#28378;&#36807;&#31243;&#20013;&#20250;&#21463;&#21040;&#22797;&#21512;&#35823;&#24046;&#30340;&#24433;&#21709;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#22522;&#20110;GAN&#35757;&#32451;&#30340;&#23545;&#25239;&#27169;&#22411;&#20943;&#36731;&#20102;&#36825;&#31181;&#26292;&#38706;&#20559;&#24046;&#65292;&#20294;&#36716;&#25442;&#26159;&#38544;&#24335;&#30340;&#19988;&#38590;&#20197;&#35780;&#20272;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#26088;&#22312;&#32467;&#21512;&#20004;&#32773;&#20248;&#21183;&#30340;&#29983;&#25104;&#26694;&#26550;&#65306;&#21463;&#21040;&#21305;&#37197;&#30697;&#27861;&#30340;&#30446;&#26631;&#28608;&#21457;&#65292;&#25105;&#20204;&#20248;&#21270;&#19968;&#20010;&#26412;&#22320;&#65288;&#20294;&#21069;&#30651;&#24615;&#30340;&#65289;&#36716;&#25442;&#31574;&#30053;&#65292;&#20854;&#20013;&#24378;&#21270;&#20449;&#21495;&#30001;&#20840;&#23616;&#65288;&#20294;&#21487;&#36880;&#27493;&#20998;&#35299;&#65289;&#33021;&#37327;&#27169;&#22411;&#36890;&#36807;&#23545;&#27604;&#20272;&#35745;&#35757;&#32451;&#25552;&#20379;&#12290;&#22312;&#35757;&#32451;&#20013;&#65292;&#20004;&#20010;&#32452;&#20214;&#34987;&#23398;&#20064;&#29983;&#25104;&#23545;&#25239;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Consider learning a generative model for time-series data. The sequential setting poses a unique challenge: Not only should the generator capture the conditional dynamics of (stepwise) transitions, but its open-loop rollouts should also preserve the joint distribution of (multi-step) trajectories. On one hand, autoregressive models trained by MLE allow learning and computing explicit transition distributions, but suffer from compounding error during rollouts. On the other hand, adversarial models based on GAN training alleviate such exposure bias, but transitions are implicit and hard to assess. In this work, we study a generative framework that seeks to combine the strengths of both: Motivated by a moment-matching objective to mitigate compounding error, we optimize a local (but forward-looking) transition policy, where the reinforcement signal is provided by a global (but stepwise-decomposable) energy model trained by contrastive estimation. At training, the two components are learne
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#21160;&#24577;&#27169;&#24577;&#20998;&#35299;&#20998;&#26512;&#30452;&#24067;&#32599;&#38464;&#28023;&#23777;&#30340;&#28526;&#27969;&#65292;&#25581;&#31034;&#20102;&#20854;&#22797;&#26434;&#30340;&#28023;&#27915;&#20122;&#20013;&#23610;&#24230;&#29305;&#24449;&#20197;&#21450;&#29289;&#29702;&#26426;&#21046;&#65292;&#24182;&#25552;&#20986;&#20102;&#25913;&#36827;&#26041;&#27861;&#26469;&#22686;&#24378;&#20998;&#26512;&#30340;&#31283;&#20581;&#24615;&#21644;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2311.01377</link><description>&lt;p&gt;
&#21033;&#29992;&#21160;&#24577;&#27169;&#24577;&#20998;&#35299;&#20998;&#26512;&#30452;&#24067;&#32599;&#38464;&#28023;&#23777;&#30340;&#28526;&#27969;
&lt;/p&gt;
&lt;p&gt;
Analysis of tidal flows through the Strait of Gibraltar using Dynamic Mode Decomposition. (arXiv:2311.01377v1 [math.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01377
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#21160;&#24577;&#27169;&#24577;&#20998;&#35299;&#20998;&#26512;&#30452;&#24067;&#32599;&#38464;&#28023;&#23777;&#30340;&#28526;&#27969;&#65292;&#25581;&#31034;&#20102;&#20854;&#22797;&#26434;&#30340;&#28023;&#27915;&#20122;&#20013;&#23610;&#24230;&#29305;&#24449;&#20197;&#21450;&#29289;&#29702;&#26426;&#21046;&#65292;&#24182;&#25552;&#20986;&#20102;&#25913;&#36827;&#26041;&#27861;&#26469;&#22686;&#24378;&#20998;&#26512;&#30340;&#31283;&#20581;&#24615;&#21644;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30452;&#24067;&#32599;&#38464;&#28023;&#23777;&#26159;&#19968;&#20010;&#30001;&#22320;&#24418;&#12289;&#28526;&#27728;&#21147;&#12289;&#19981;&#31283;&#23450;&#24615;&#21644;&#38750;&#32447;&#24615;&#27700;&#21147;&#36807;&#31243;&#24433;&#21709;&#30340;&#22797;&#26434;&#28023;&#27915;&#20122;&#20013;&#23610;&#24230;&#29305;&#24449;&#21306;&#22495;&#65292;&#25152;&#26377;&#36825;&#20123;&#37117;&#21463;&#38750;&#32447;&#24615;&#27969;&#20307;&#36816;&#21160;&#26041;&#31243;&#31649;&#25511;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#36890;&#36807;3D MIT&#36890;&#29992;&#29615;&#27969;&#27169;&#22411;&#27169;&#25311;&#65292;&#21253;&#25324;&#27874;&#28010;&#12289;&#28065;&#26059;&#21644;&#26059;&#22238;&#65292;&#25581;&#31034;&#36825;&#20123;&#29616;&#35937;&#32972;&#21518;&#30340;&#29289;&#29702;&#26426;&#21046;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#25105;&#20204;&#37319;&#29992;&#21160;&#24577;&#27169;&#24577;&#20998;&#35299;&#65288;DMD&#65289;&#23558;&#27169;&#25311;&#24555;&#29031;&#20998;&#35299;&#25104;Koopman&#27169;&#24577;&#65292;&#20855;&#26377;&#19981;&#21516;&#30340;&#25351;&#25968;&#22686;&#38271;/&#34928;&#20943;&#29575;&#21644;&#25391;&#33633;&#39057;&#29575;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#21253;&#25324;&#35780;&#20272;DMD&#22312;&#25429;&#25417;&#24050;&#30693;&#29305;&#24449;&#12289;&#25581;&#31034;&#26032;&#20803;&#32032;&#12289;&#25490;&#21517;&#27169;&#24577;&#21644;&#25506;&#32034;&#38477;&#38454;&#30340;&#25928;&#26524;&#12290;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#19968;&#20123;&#20462;&#25913;&#26469;&#22686;&#24378;DMD&#30340;&#31283;&#20581;&#24615;&#12289;&#25968;&#20540;&#31934;&#24230;&#21644;&#29305;&#24449;&#20540;&#30340;&#31283;&#20581;&#24615;&#12290;DMD&#20998;&#26512;&#20135;&#29983;&#20102;&#23545;&#27969;&#21160;&#27169;&#24335;&#12289;&#20869;&#27874;&#24418;&#25104;&#21644;&#30452;&#24067;&#32599;&#38464;&#28023;&#23777;&#21160;&#21147;&#23398;&#30340;&#20840;&#38754;&#20102;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Strait of Gibraltar is a region characterized by intricate oceanic sub-mesoscale features, influenced by topography, tidal forces, instabilities, and nonlinear hydraulic processes, all governed by the nonlinear equations of fluid motion. In this study, we aim to uncover the underlying physics of these phenomena within 3D MIT general circulation model simulations, including waves, eddies, and gyres. To achieve this, we employ Dynamic Mode Decomposition (DMD) to break down simulation snapshots into Koopman modes, with distinct exponential growth/decay rates and oscillation frequencies. Our objectives encompass evaluating DMD's efficacy in capturing known features, unveiling new elements, ranking modes, and exploring order reduction. We also introduce modifications to enhance DMD's robustness, numerical accuracy, and robustness of eigenvalues. DMD analysis yields a comprehensive understanding of flow patterns, internal wave formation, and the dynamics of the Strait of Gibraltar, its m
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#24212;&#29992;&#37327;&#23376;&#28151;&#27788;&#21644;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#30340;&#24037;&#20855;&#65292;&#23545;&#28237;&#27969;&#27169;&#25311;&#22270;&#20687;&#25968;&#25454;&#36827;&#34892;&#20102;&#35814;&#32454;&#20998;&#26512;&#65292;&#24182;&#23558;&#20854;&#19982;&#32463;&#20856;&#28151;&#27788;&#12289;&#19981;&#30456;&#20851;&#22122;&#22768;&#21644;&#33258;&#28982;&#22270;&#20687;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#28237;&#27969;&#30340;Gram&#30697;&#38453;&#19982;&#37327;&#23376;&#28151;&#27788;&#31995;&#32479;&#22788;&#20110;&#21516;&#19968;&#26222;&#36866;&#31867;&#21035;&#65292;&#24182;&#19988;&#25968;&#25454;&#30340;&#29305;&#24449;&#20540;&#22312;&#22823;&#37096;&#20998;&#24773;&#20917;&#19979;&#26174;&#31034;&#20986;&#19982;&#19981;&#30456;&#20851;&#31995;&#32479;&#23436;&#20840;&#19981;&#21516;&#30340;&#24130;&#24459;&#32553;&#25918;&#12290;</title><link>http://arxiv.org/abs/2311.01358</link><description>&lt;p&gt;
&#28151;&#27788;&#21644;&#28237;&#27969;&#30340;&#26222;&#36866;&#32479;&#35745;&#32467;&#26500;&#21644;&#23610;&#24230;&#24459;
&lt;/p&gt;
&lt;p&gt;
The Universal Statistical Structure and Scaling Laws of Chaos and Turbulence. (arXiv:2311.01358v1 [cond-mat.stat-mech])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01358
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#24212;&#29992;&#37327;&#23376;&#28151;&#27788;&#21644;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;&#30340;&#24037;&#20855;&#65292;&#23545;&#28237;&#27969;&#27169;&#25311;&#22270;&#20687;&#25968;&#25454;&#36827;&#34892;&#20102;&#35814;&#32454;&#20998;&#26512;&#65292;&#24182;&#23558;&#20854;&#19982;&#32463;&#20856;&#28151;&#27788;&#12289;&#19981;&#30456;&#20851;&#22122;&#22768;&#21644;&#33258;&#28982;&#22270;&#20687;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#28237;&#27969;&#30340;Gram&#30697;&#38453;&#19982;&#37327;&#23376;&#28151;&#27788;&#31995;&#32479;&#22788;&#20110;&#21516;&#19968;&#26222;&#36866;&#31867;&#21035;&#65292;&#24182;&#19988;&#25968;&#25454;&#30340;&#29305;&#24449;&#20540;&#22312;&#22823;&#37096;&#20998;&#24773;&#20917;&#19979;&#26174;&#31034;&#20986;&#19982;&#19981;&#30456;&#20851;&#31995;&#32479;&#23436;&#20840;&#19981;&#21516;&#30340;&#24130;&#24459;&#32553;&#25918;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28237;&#27969;&#26159;&#30001;&#20110;&#39640;&#38647;&#35834;&#25968;&#27969;&#20307;&#27969;&#21160;&#30340;&#24378;&#38750;&#32447;&#24615;&#21160;&#21147;&#23398;&#32780;&#24418;&#25104;&#30340;&#22797;&#26434;&#30340;&#26102;&#31354;&#32467;&#26500;&#12290;&#23613;&#31649;&#28237;&#27969;&#26159;&#19968;&#20010;&#26222;&#36941;&#23384;&#22312;&#30340;&#29616;&#35937;&#65292;&#24182;&#19988;&#24050;&#32463;&#30740;&#31350;&#20102;&#20960;&#20010;&#19990;&#32426;&#65292;&#20294;&#23545;&#28237;&#27969;&#30340;&#23436;&#20840;&#29702;&#35299;&#20173;&#28982;&#26159;&#19968;&#20010;&#24040;&#22823;&#30340;&#25361;&#25112;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#37327;&#23376;&#28151;&#27788;&#21644;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;(RMT)&#30340;&#24037;&#20855;&#65292;&#24182;&#23545;&#30001;&#19981;&#21487;&#21387;&#32553;&#21644;&#21487;&#21387;&#32553;&#27969;&#20307;&#27969;&#21160;&#20135;&#29983;&#30340;&#22270;&#20687;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#35814;&#32454;&#20998;&#26512;&#12290;&#25105;&#20204;&#20851;&#27880;&#20004;&#20010;&#21487;&#35266;&#23519;&#37327;&#65306;&#25968;&#25454;Gram&#30697;&#38453;&#21644;&#21333;&#20010;&#22270;&#20687;&#20998;&#24067;&#65292;&#30740;&#31350;&#20102;&#23616;&#37096;&#21644;&#20840;&#23616;&#29305;&#24449;&#20540;&#32479;&#35745;&#24182;&#23558;&#20854;&#19982;&#32463;&#20856;&#28151;&#27788;&#12289;&#19981;&#30456;&#20851;&#22122;&#22768;&#21644;&#33258;&#28982;&#22270;&#20687;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#20174;RMT&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#28237;&#27969;&#30340;Gram&#30697;&#38453;&#19982;&#37327;&#23376;&#28151;&#27788;&#32780;&#19981;&#26159;&#21487;&#31215;&#31995;&#32479;&#22788;&#20110;&#30456;&#21516;&#30340;&#26222;&#36866;&#31867;&#21035;&#20013;&#65292;&#24182;&#19988;&#25968;&#25454;&#22312;&#20854;&#29305;&#24449;&#20540;&#30340;&#22823;&#37096;&#20998;&#19978;&#34920;&#29616;&#20986;&#19982;&#19981;&#30456;&#20851;&#30340;&#32463;&#20856;&#31867;&#21035;&#23436;&#20840;&#19981;&#21516;&#30340;&#24130;&#24459;&#32553;&#25918;&#12290;
&lt;/p&gt;
&lt;p&gt;
Turbulence is a complex spatial and temporal structure created by the strong non-linear dynamics of fluid flows at high Reynolds numbers. Despite being an ubiquitous phenomenon that has been studied for centuries, a full understanding of turbulence remained a formidable challenge. Here, we introduce tools from the fields of quantum chaos and Random Matrix Theory (RMT) and present a detailed analysis of image datasets generated from turbulence simulations of incompressible and compressible fluid flows. Focusing on two observables: the data Gram matrix and the single image distribution, we study both the local and global eigenvalue statistics and compare them to classical chaos, uncorrelated noise and natural images. We show that from the RMT perspective, the turbulence Gram matrices lie in the same universality class as quantum chaotic rather than integrable systems, and the data exhibits power-law scalings in the bulk of its eigenvalues which are vastly different from uncorrelated clas
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;Lipschitz&#24120;&#25968;&#65292;&#23545;&#20110;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;Lipschitz&#24120;&#25968;&#30340;&#31934;&#30830;&#21051;&#30011;&#65292;&#23545;&#20110;&#36275;&#22815;&#23485;&#24230;&#30340;&#28145;&#23618;&#31070;&#32463;&#32593;&#32476;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#19978;&#19979;&#30028;&#65292;&#24182;&#21305;&#37197;&#19968;&#20010;&#20381;&#36182;&#20110;&#28145;&#24230;&#30340;&#23545;&#25968;&#22240;&#23376;&#12290;</title><link>http://arxiv.org/abs/2311.01356</link><description>&lt;p&gt;
&#20851;&#20110;&#38543;&#26426;&#31070;&#32463;&#32593;&#32476;&#30340;Lipschitz&#24120;&#25968;
&lt;/p&gt;
&lt;p&gt;
On the Lipschitz constant of random neural networks. (arXiv:2311.01356v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01356
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;Lipschitz&#24120;&#25968;&#65292;&#23545;&#20110;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;Lipschitz&#24120;&#25968;&#30340;&#31934;&#30830;&#21051;&#30011;&#65292;&#23545;&#20110;&#36275;&#22815;&#23485;&#24230;&#30340;&#28145;&#23618;&#31070;&#32463;&#32593;&#32476;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#19978;&#19979;&#30028;&#65292;&#24182;&#21305;&#37197;&#19968;&#20010;&#20381;&#36182;&#20110;&#28145;&#24230;&#30340;&#23545;&#25968;&#22240;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23454;&#35777;&#30740;&#31350;&#24191;&#27867;&#35777;&#26126;&#31070;&#32463;&#32593;&#32476;&#23545;&#36755;&#20837;&#30340;&#24494;&#23567;&#23545;&#25239;&#24615;&#25200;&#21160;&#38750;&#24120;&#25935;&#24863;&#12290;&#36825;&#20123;&#25152;&#35859;&#30340;&#23545;&#25239;&#24615;&#31034;&#20363;&#30340;&#26368;&#22351;&#24773;&#20917;&#40065;&#26834;&#24615;&#21487;&#20197;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#30340;Lipschitz&#24120;&#25968;&#26469;&#37327;&#21270;&#12290;&#28982;&#32780;&#65292;&#20851;&#20110;&#36825;&#20010;&#37327;&#30340;&#29702;&#35770;&#32467;&#26524;&#22312;&#25991;&#29486;&#20013;&#20165;&#26377;&#23569;&#25968;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#22987;&#30740;&#31350;&#38543;&#26426;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;Lipschitz&#24120;&#25968;&#65292;&#21363;&#36873;&#25321;&#38543;&#26426;&#26435;&#37325;&#24182;&#37319;&#29992;ReLU&#28608;&#27963;&#20989;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#12290;&#23545;&#20110;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#65292;&#25105;&#20204;&#23558;Lipschitz&#24120;&#25968;&#21051;&#30011;&#21040;&#19968;&#20010;&#32477;&#23545;&#25968;&#20540;&#24120;&#25968;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#20998;&#26512;&#25193;&#23637;&#21040;&#36275;&#22815;&#23485;&#24230;&#30340;&#28145;&#23618;&#31070;&#32463;&#32593;&#32476;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;Lipschitz&#24120;&#25968;&#30340;&#19978;&#19979;&#30028;&#12290;&#36825;&#20123;&#30028;&#21305;&#37197;&#21040;&#19968;&#20010;&#20381;&#36182;&#20110;&#28145;&#24230;&#30340;&#23545;&#25968;&#22240;&#23376;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
Empirical studies have widely demonstrated that neural networks are highly sensitive to small, adversarial perturbations of the input. The worst-case robustness against these so-called adversarial examples can be quantified by the Lipschitz constant of the neural network. However, only few theoretical results regarding this quantity exist in the literature. In this paper, we initiate the study of the Lipschitz constant of random ReLU neural networks, i.e., neural networks whose weights are chosen at random and which employ the ReLU activation function. For shallow neural networks, we characterize the Lipschitz constant up to an absolute numerical constant. Moreover, we extend our analysis to deep neural networks of sufficiently large width where we prove upper and lower bounds for the Lipschitz constant. These bounds match up to a logarithmic factor that depends on the depth.
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#30340;&#30446;&#30340;&#26159;&#21033;&#29992;&#27491;&#20132;&#21270;&#26041;&#27861;&#28040;&#38500;&#33016;&#37096;X&#23556;&#32447;&#23884;&#20837;&#20013;&#30340;&#20445;&#25252;&#29305;&#24449;&#24433;&#21709;&#65292;&#24182;&#35777;&#26126;&#20854;&#26377;&#25928;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#20445;&#25252;&#29305;&#24449;&#23545;&#30149;&#29702;&#39044;&#27979;&#26377;&#26174;&#33879;&#24433;&#21709;&#65292;&#32780;&#24212;&#29992;&#27491;&#20132;&#21270;&#26041;&#27861;&#21487;&#20197;&#28040;&#38500;&#36825;&#20123;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2311.01349</link><description>&lt;p&gt;
&#21462;&#28040;&#20445;&#25252;&#29305;&#24449;&#65306;&#20174;&#33016;&#37096;X&#23556;&#32447;&#23884;&#20837;&#20013;&#28040;&#38500;&#20445;&#25252;&#29305;&#24449;
&lt;/p&gt;
&lt;p&gt;
Unreading Race: Purging Protected Features from Chest X-ray Embeddings. (arXiv:2311.01349v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01349
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#30340;&#30446;&#30340;&#26159;&#21033;&#29992;&#27491;&#20132;&#21270;&#26041;&#27861;&#28040;&#38500;&#33016;&#37096;X&#23556;&#32447;&#23884;&#20837;&#20013;&#30340;&#20445;&#25252;&#29305;&#24449;&#24433;&#21709;&#65292;&#24182;&#35777;&#26126;&#20854;&#26377;&#25928;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#20445;&#25252;&#29305;&#24449;&#23545;&#30149;&#29702;&#39044;&#27979;&#26377;&#26174;&#33879;&#24433;&#21709;&#65292;&#32780;&#24212;&#29992;&#27491;&#20132;&#21270;&#26041;&#27861;&#21487;&#20197;&#28040;&#38500;&#36825;&#20123;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#30340;&#65306;&#20998;&#26512;&#24182;&#28040;&#38500;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#20013;&#33016;&#37096;X&#23556;&#32447;&#23884;&#20837;&#30340;&#20445;&#25252;&#29305;&#24449;&#24433;&#21709;&#12290;&#26041;&#27861;&#65306;&#20351;&#29992;&#27491;&#20132;&#21270;&#26041;&#27861;&#28040;&#38500;&#33016;&#37096;X&#23556;&#32447;&#23884;&#20837;&#20013;&#30340;&#20445;&#25252;&#29305;&#24449;&#65288;&#22914;&#24180;&#40836;&#12289;&#24615;&#21035;&#12289;&#31181;&#26063;&#65289;&#30340;&#24433;&#21709;&#65292;&#30830;&#20445;&#29305;&#24449;&#29420;&#31435;&#30340;&#32467;&#26524;&#12290;&#20026;&#20102;&#39564;&#35777;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#25105;&#20204;&#20351;&#29992;&#19977;&#20010;&#39044;&#35757;&#32451;&#27169;&#22411;&#65288;&#26377;&#30417;&#30563;&#23545;&#27604;&#12289;&#33258;&#30417;&#30563;&#23545;&#27604;&#21644;&#22522;&#32447;&#20998;&#31867;&#22120;&#27169;&#22411;&#65289;&#23545;MIMIC&#21644;CheXpert&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#22238;&#39038;&#24615;&#30740;&#31350;&#12290;&#25105;&#20204;&#30340;&#32479;&#35745;&#20998;&#26512;&#28041;&#21450;&#36890;&#36807;&#20272;&#35745;&#20445;&#25252;&#29305;&#24449;&#24433;&#21709;&#21644;&#35780;&#20272;&#20351;&#29992;&#20004;&#31181;&#31867;&#22411;&#23884;&#20837;&#30340;&#33021;&#21147;&#26469;&#39044;&#27979;&#31181;&#26063;&#12289;&#24180;&#40836;&#25110;&#24615;&#21035;&#30340;&#21407;&#22987;&#19982;&#27491;&#20132;&#23884;&#20837;&#30340;&#27604;&#36739;&#12290;&#32467;&#26524;&#65306;&#25105;&#20204;&#30340;&#23454;&#39564;&#25581;&#31034;&#20102;&#20445;&#25252;&#29305;&#24449;&#23545;&#30149;&#29702;&#39044;&#27979;&#30340;&#26174;&#30528;&#24433;&#21709;&#12290;&#24212;&#29992;&#27491;&#20132;&#21270;&#26041;&#27861;&#21487;&#20197;&#28040;&#38500;&#36825;&#20123;&#29305;&#24449;&#24433;&#21709;&#12290;&#38500;&#20102;&#28040;&#38500;&#23545;&#30149;&#29702;&#20998;&#31867;&#30340;&#24433;&#21709;&#20043;&#22806;&#65292;
&lt;/p&gt;
&lt;p&gt;
Purpose: To analyze and remove protected feature effects in chest radiograph embeddings of deep learning models.  Materials and Methods: An orthogonalization is utilized to remove the influence of protected features (e.g., age, sex, race) in chest radiograph embeddings, ensuring feature-independent results. To validate the efficacy of the approach, we retrospectively study the MIMIC and CheXpert datasets using three pre-trained models, namely a supervised contrastive, a self-supervised contrastive, and a baseline classifier model. Our statistical analysis involves comparing the original versus the orthogonalized embeddings by estimating protected feature influences and evaluating the ability to predict race, age, or sex using the two types of embeddings.  Results: Our experiments reveal a significant influence of protected features on predictions of pathologies. Applying orthogonalization removes these feature effects. Apart from removing any influence on pathology classification, whil
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#32972;&#21253;&#32422;&#26463;&#30340;&#39640;&#32500;&#32447;&#24615;&#36172;&#33218;&#38382;&#39064;&#65292;&#21033;&#29992;&#31232;&#30095;&#32467;&#26500;&#23454;&#29616;&#25913;&#36827;&#36951;&#25022;&#12290;&#36890;&#36807;&#24320;&#21457;&#22312;&#32447;&#30828;&#38408;&#20540;&#31639;&#27861;&#21644;&#21407;&#22987;-&#23545;&#20598;&#26694;&#26550;&#32467;&#21512;&#30340;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#23545;&#29305;&#24449;&#32500;&#24230;&#30340;&#23545;&#25968;&#25913;&#36827;&#30340;&#27425;&#32447;&#24615;&#36951;&#25022;&#12290;</title><link>http://arxiv.org/abs/2311.01327</link><description>&lt;p&gt;
&#20855;&#26377;&#32972;&#21253;&#32422;&#26463;&#30340;&#39640;&#32500;&#32447;&#24615;&#36172;&#33218;&#38382;&#39064;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
High-dimensional Linear Bandits with Knapsacks. (arXiv:2311.01327v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01327
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#32972;&#21253;&#32422;&#26463;&#30340;&#39640;&#32500;&#32447;&#24615;&#36172;&#33218;&#38382;&#39064;&#65292;&#21033;&#29992;&#31232;&#30095;&#32467;&#26500;&#23454;&#29616;&#25913;&#36827;&#36951;&#25022;&#12290;&#36890;&#36807;&#24320;&#21457;&#22312;&#32447;&#30828;&#38408;&#20540;&#31639;&#27861;&#21644;&#21407;&#22987;-&#23545;&#20598;&#26694;&#26550;&#32467;&#21512;&#30340;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#23545;&#29305;&#24449;&#32500;&#24230;&#30340;&#23545;&#25968;&#25913;&#36827;&#30340;&#27425;&#32447;&#24615;&#36951;&#25022;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#29305;&#24449;&#32500;&#24230;&#36739;&#22823;&#30340;&#39640;&#32500;&#35774;&#32622;&#19979;&#30340;&#20855;&#26377;&#32972;&#21253;&#32422;&#26463;&#30340;&#19978;&#19979;&#25991;&#36172;&#33218;&#38382;&#39064;&#12290;&#27599;&#20010;&#25163;&#33218;&#25289;&#21160;&#30340;&#22870;&#21169;&#31561;&#20110;&#31232;&#30095;&#39640;&#32500;&#26435;&#37325;&#21521;&#37327;&#19982;&#24403;&#21069;&#21040;&#36798;&#30340;&#29305;&#24449;&#30340;&#20056;&#31215;&#65292;&#21152;&#19978;&#39069;&#22806;&#30340;&#38543;&#26426;&#22122;&#22768;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#22914;&#20309;&#21033;&#29992;&#36825;&#31181;&#31232;&#30095;&#32467;&#26500;&#26469;&#23454;&#29616;CBwK&#38382;&#39064;&#30340;&#25913;&#36827;&#36951;&#25022;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#39318;&#20808;&#24320;&#21457;&#20102;&#19968;&#31181;&#22312;&#32447;&#30340;&#30828;&#38408;&#20540;&#31639;&#27861;&#30340;&#21464;&#20307;&#65292;&#20197;&#22312;&#32447;&#26041;&#24335;&#36827;&#34892;&#31232;&#30095;&#20272;&#35745;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23558;&#25105;&#20204;&#30340;&#22312;&#32447;&#20272;&#35745;&#22120;&#19982;&#21407;&#22987;-&#23545;&#20598;&#26694;&#26550;&#32467;&#21512;&#36215;&#26469;&#65292;&#22312;&#27599;&#20010;&#32972;&#21253;&#32422;&#26463;&#19978;&#20998;&#37197;&#19968;&#20010;&#23545;&#20598;&#21464;&#37327;&#65292;&#24182;&#21033;&#29992;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#26469;&#26356;&#26032;&#23545;&#20598;&#21464;&#37327;&#65292;&#20174;&#32780;&#25511;&#21046;&#32972;&#21253;&#23481;&#37327;&#30340;&#28040;&#32791;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#38598;&#25104;&#26041;&#27861;&#20351;&#25105;&#20204;&#33021;&#22815;&#23454;&#29616;&#23545;&#29305;&#24449;&#32500;&#24230;&#30340;&#23545;&#25968;&#25913;&#36827;&#30340;&#27425;&#32447;&#24615;&#36951;&#25022;&#65292;&#20174;&#32780;&#25913;&#36827;&#20102;&#22810;&#39033;&#24335;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the contextual bandits with knapsack (CBwK) problem under the high-dimensional setting where the dimension of the feature is large. The reward of pulling each arm equals the multiplication of a sparse high-dimensional weight vector and the feature of the current arrival, with additional random noise. In this paper, we investigate how to exploit this sparsity structure to achieve improved regret for the CBwK problem. To this end, we first develop an online variant of the hard thresholding algorithm that performs the sparse estimation in an online manner. We further combine our online estimator with a primal-dual framework, where we assign a dual variable to each knapsack constraint and utilize an online learning algorithm to update the dual variable, thereby controlling the consumption of the knapsack capacity. We show that this integrated approach allows us to achieve a sublinear regret that depends logarithmically on the feature dimension, thus improving the polynomial depend
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#22312;&#32454;&#32990;&#22797;&#21512;&#29289;&#19978;&#24212;&#29992;&#39640;&#26031;&#36807;&#31243;&#65292;&#25552;&#20986;&#20102;&#20004;&#20010;&#26032;&#30340;&#26680;&#20989;&#25968;&#26469;&#25429;&#25417;&#39640;&#38454;&#32454;&#32990;&#20043;&#38388;&#30340;&#20132;&#20114;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2311.01198</link><description>&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#22312;&#32454;&#32990;&#22797;&#21512;&#29289;&#19978;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Gaussian Processes on Cellular Complexes. (arXiv:2311.01198v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01198
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#22312;&#32454;&#32990;&#22797;&#21512;&#29289;&#19978;&#24212;&#29992;&#39640;&#26031;&#36807;&#31243;&#65292;&#25552;&#20986;&#20102;&#20004;&#20010;&#26032;&#30340;&#26680;&#20989;&#25968;&#26469;&#25429;&#25417;&#39640;&#38454;&#32454;&#32990;&#20043;&#38388;&#30340;&#20132;&#20114;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#20154;&#20204;&#23545;&#22312;&#22270;&#19978;&#24320;&#21457;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26469;&#32771;&#34385;&#25299;&#25169;&#24402;&#32435;&#20559;&#32622;&#20135;&#29983;&#20102;&#30456;&#24403;&#22823;&#30340;&#20852;&#36259;&#12290;&#29305;&#21035;&#26159;&#65292;&#26368;&#36817;&#20851;&#27880;&#30340;&#26159;&#22312;&#36825;&#20123;&#32467;&#26500;&#19978;&#30340;&#39640;&#26031;&#36807;&#31243;&#65292;&#22240;&#20026;&#23427;&#20204;&#33021;&#22815;&#21516;&#26102;&#32771;&#34385;&#19981;&#30830;&#23450;&#24615;&#12290;&#28982;&#32780;&#65292;&#22270;&#20165;&#38480;&#20110;&#23545;&#20004;&#20010;&#39030;&#28857;&#20043;&#38388;&#30340;&#20851;&#31995;&#36827;&#34892;&#24314;&#27169;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36229;&#36234;&#20102;&#36825;&#31181;&#23545;&#31216;&#37197;&#32622;&#65292;&#24182;&#32771;&#34385;&#20102;&#21253;&#25324;&#39030;&#28857;&#12289;&#36793;&#21644;&#23427;&#20204;&#30340;&#19968;&#31181;&#24191;&#20041;&#21270;&#31216;&#20026;&#32454;&#32990;&#30340;&#20132;&#20114;&#20851;&#31995;&#12290;&#20855;&#20307;&#22320;&#35828;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#39640;&#26031;&#36807;&#31243;&#22312;&#32454;&#32990;&#22797;&#21512;&#29289;&#19978;&#30340;&#24212;&#29992;&#65292;&#36825;&#26159;&#23545;&#22270;&#30340;&#19968;&#31181;&#25512;&#24191;&#65292;&#21487;&#20197;&#25429;&#25417;&#36825;&#20123;&#39640;&#38454;&#32454;&#32990;&#20043;&#38388;&#30340;&#20132;&#20114;&#20316;&#29992;&#12290;&#25105;&#20204;&#30340;&#19968;&#20010;&#20851;&#38190;&#36129;&#29486;&#26159;&#25512;&#23548;&#20986;&#20004;&#20010;&#26032;&#22411;&#26680;&#20989;&#25968;&#65292;&#19968;&#20010;&#26159;&#23545;&#22270;Mat\'ern&#26680;&#36827;&#34892;&#25512;&#24191;&#65292;&#21478;&#19968;&#20010;&#26159;&#39069;&#22806;&#22320;&#28151;&#21512;&#20102;&#19981;&#21516;&#32454;&#32990;&#31867;&#22411;&#30340;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, there has been considerable interest in developing machine learning models on graphs in order to account for topological inductive biases. In particular, recent attention was given to Gaussian processes on such structures since they can additionally account for uncertainty. However, graphs are limited to modelling relations between two vertices. In this paper, we go beyond this dyadic setting and consider polyadic relations that include interactions between vertices, edges and one of their generalisations, known as cells. Specifically, we propose Gaussian processes on cellular complexes, a generalisation of graphs that captures interactions between these higher-order cells. One of our key contributions is the derivation of two novel kernels, one that generalises the graph Mat\'ern kernel and one that additionally mixes information of different cell types.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27010;&#29575;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#30340;&#26102;&#38388;&#28857;&#36807;&#31243;&#27169;&#22411;&#65292;&#30456;&#27604;&#20110;&#29616;&#26377;&#30340;&#26041;&#27861;&#65292;&#35813;&#27169;&#22411;&#22312;&#39044;&#27979;&#26041;&#38754;&#21462;&#24471;&#20102;&#36739;&#22909;&#30340;&#24615;&#33021;&#65292;&#23545;&#20855;&#26377;&#31163;&#25955;&#21644;&#36830;&#32493;&#25104;&#20998;&#30340;&#25968;&#25454;&#20855;&#26377;&#22788;&#29702;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2311.01139</link><description>&lt;p&gt;
&#28155;&#21152;&#21644;&#31232;&#30095;&#65306;&#19968;&#31181;&#29992;&#20110;&#26102;&#38388;&#28857;&#36807;&#31243;&#30340;&#25193;&#25955;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Add and Thin: Diffusion for Temporal Point Processes. (arXiv:2311.01139v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01139
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27010;&#29575;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#30340;&#26102;&#38388;&#28857;&#36807;&#31243;&#27169;&#22411;&#65292;&#30456;&#27604;&#20110;&#29616;&#26377;&#30340;&#26041;&#27861;&#65292;&#35813;&#27169;&#22411;&#22312;&#39044;&#27979;&#26041;&#38754;&#21462;&#24471;&#20102;&#36739;&#22909;&#30340;&#24615;&#33021;&#65292;&#23545;&#20855;&#26377;&#31163;&#25955;&#21644;&#36830;&#32493;&#25104;&#20998;&#30340;&#25968;&#25454;&#20855;&#26377;&#22788;&#29702;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26102;&#38388;&#28857;&#36807;&#31243;&#65288;TPP&#65289;&#26694;&#26550;&#20869;&#65292;&#33258;&#22238;&#24402;&#31070;&#32463;&#32593;&#32476;&#24050;&#25104;&#20026;&#24314;&#27169;&#36830;&#32493;&#26102;&#38388;&#20107;&#20214;&#25968;&#25454;&#30340;&#26631;&#20934;&#12290;&#23613;&#31649;&#36825;&#20123;&#27169;&#22411;&#21487;&#20197;&#20197;&#19968;&#27493;&#39044;&#27979;&#30340;&#26041;&#24335;&#31934;&#30830;&#22320;&#25429;&#25417;&#20107;&#20214;&#24207;&#21015;&#65292;&#20294;&#30001;&#20110;&#20854;&#39034;&#24207;&#24615;&#36136;&#24341;&#36215;&#30340;&#35823;&#24046;&#31215;&#32047;&#65292;&#23427;&#20204;&#22312;&#38271;&#26399;&#39044;&#27979;&#24212;&#29992;&#20013;&#20855;&#26377;&#22266;&#26377;&#30340;&#23616;&#38480;&#24615;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;ADD-THIN&#65292;&#19968;&#31181;&#38754;&#21521;&#25972;&#20010;&#20107;&#20214;&#24207;&#21015;&#24037;&#20316;&#30340;&#22522;&#20110;&#27010;&#29575;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#65292;&#23427;&#33258;&#28982;&#22320;&#22788;&#29702;&#20855;&#26377;&#31163;&#25955;&#21644;&#36830;&#32493;&#25104;&#20998;&#30340;&#25968;&#25454;&#12290;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#23494;&#24230;&#20272;&#35745;&#26041;&#38754;&#19982;&#26368;&#20808;&#36827;&#30340;TPP&#27169;&#22411;&#30456;&#21305;&#37197;&#65292;&#24182;&#22312;&#39044;&#27979;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;
Autoregressive neural networks within the temporal point process (TPP) framework have become the standard for modeling continuous-time event data. Even though these models can expressively capture event sequences in a one-step-ahead fashion, they are inherently limited for long-term forecasting applications due to the accumulation of errors caused by their sequential nature. To overcome these limitations, we derive ADD-THIN, a principled probabilistic denoising diffusion model for TPPs that operates on entire event sequences. Unlike existing diffusion approaches, ADD-THIN naturally handles data with discrete and continuous components. In experiments on synthetic and real-world datasets, our model matches the state-of-the-art TPP models in density estimation and strongly outperforms them in forecasting.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#24341;&#20837;&#20102;&#38887;&#24615;&#22810;&#36873;&#23398;&#20064;&#65288;rMCL&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#22522;&#20110;Voronoi tessellations&#30340;&#25968;&#23398;&#26694;&#26550;&#21644;&#23398;&#20064;&#35780;&#20998;&#26041;&#26696;&#65292;&#22312;&#22238;&#24402;&#35774;&#32622;&#20013;&#23454;&#29616;&#20102;&#23545;&#20110;&#27599;&#20010;&#35757;&#32451;&#36755;&#20837;&#21487;&#33021;&#37319;&#26679;&#22810;&#20010;&#30446;&#26631;&#30340;&#26465;&#20214;&#20998;&#24067;&#20272;&#35745;&#12290;&#35813;&#26041;&#27861;&#22312;&#21512;&#25104;&#25968;&#25454;&#21644;&#22768;&#28304;&#23450;&#20301;&#38382;&#39064;&#19978;&#24471;&#21040;&#20102;&#23454;&#35777;&#39564;&#35777;&#21644;&#36827;&#19968;&#27493;&#35780;&#20272;&#65292;&#23637;&#31034;&#20102;&#20854;&#23454;&#38469;&#30340;&#26377;&#29992;&#24615;&#21644;&#35299;&#37322;&#30340;&#30456;&#20851;&#24615;&#12290;</title><link>http://arxiv.org/abs/2311.01052</link><description>&lt;p&gt;
&#38887;&#24615;&#22810;&#36873;&#23398;&#20064;&#65306;&#29992;&#20110;&#38899;&#39057;&#22330;&#26223;&#20998;&#26512;&#30340;&#23398;&#20064;&#35780;&#20998;&#26041;&#26696;&#30340;&#24341;&#20837;
&lt;/p&gt;
&lt;p&gt;
Resilient Multiple Choice Learning: A learned scoring scheme with application to audio scene analysis. (arXiv:2311.01052v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01052
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#24341;&#20837;&#20102;&#38887;&#24615;&#22810;&#36873;&#23398;&#20064;&#65288;rMCL&#65289;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#22522;&#20110;Voronoi tessellations&#30340;&#25968;&#23398;&#26694;&#26550;&#21644;&#23398;&#20064;&#35780;&#20998;&#26041;&#26696;&#65292;&#22312;&#22238;&#24402;&#35774;&#32622;&#20013;&#23454;&#29616;&#20102;&#23545;&#20110;&#27599;&#20010;&#35757;&#32451;&#36755;&#20837;&#21487;&#33021;&#37319;&#26679;&#22810;&#20010;&#30446;&#26631;&#30340;&#26465;&#20214;&#20998;&#24067;&#20272;&#35745;&#12290;&#35813;&#26041;&#27861;&#22312;&#21512;&#25104;&#25968;&#25454;&#21644;&#22768;&#28304;&#23450;&#20301;&#38382;&#39064;&#19978;&#24471;&#21040;&#20102;&#23454;&#35777;&#39564;&#35777;&#21644;&#36827;&#19968;&#27493;&#35780;&#20272;&#65292;&#23637;&#31034;&#20102;&#20854;&#23454;&#38469;&#30340;&#26377;&#29992;&#24615;&#21644;&#35299;&#37322;&#30340;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#38887;&#24615;&#22810;&#36873;&#23398;&#20064;&#65288;rMCL&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#23545;&#20110;&#27599;&#20010;&#35757;&#32451;&#36755;&#20837;&#21487;&#33021;&#37319;&#26679;&#22810;&#20010;&#30446;&#26631;&#30340;&#22238;&#24402;&#35774;&#32622;&#19979;&#26465;&#20214;&#20998;&#24067;&#20272;&#35745;&#30340;MCL&#26041;&#27861;&#30340;&#25193;&#23637;&#12290;&#22810;&#36873;&#23398;&#20064;&#26159;&#19968;&#20010;&#31616;&#21333;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#22788;&#29702;&#22810;&#27169;&#24577;&#23494;&#24230;&#20272;&#35745;&#65292;&#20351;&#29992;&#20102;&#19968;&#32452;&#20551;&#35774;&#30340;&#32988;&#32773;&#20840;&#25343;&#65288;WTA&#65289;&#25439;&#22833;&#12290;&#22312;&#22238;&#24402;&#35774;&#32622;&#20013;&#65292;&#29616;&#26377;&#30340;MCL&#21464;&#20307;&#20027;&#35201;&#38598;&#20013;&#22312;&#21512;&#24182;&#20551;&#35774;&#19978;&#65292;&#20174;&#32780;&#26368;&#32456;&#29306;&#29298;&#20102;&#39044;&#27979;&#30340;&#22810;&#26679;&#24615;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20381;&#36182;&#20110;&#19968;&#20010;&#22522;&#20110;Voronoi tessellations&#30340;&#36755;&#20986;&#31354;&#38388;&#30340;&#25968;&#23398;&#26694;&#26550;&#25903;&#25345;&#30340;&#26032;&#39062;&#30340;&#23398;&#20064;&#35780;&#20998;&#26041;&#26696;&#65292;&#25105;&#20204;&#21487;&#20197;&#20174;&#20013;&#24471;&#20986;&#27010;&#29575;&#35299;&#37322;&#12290;&#22312;&#23545;&#21512;&#25104;&#25968;&#25454;&#36827;&#34892;&#23454;&#35777;&#39564;&#35777;&#21518;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#35780;&#20272;&#20102;rMCL&#22312;&#22768;&#28304;&#23450;&#20301;&#38382;&#39064;&#19978;&#30340;&#20248;&#28857;&#65292;&#23637;&#31034;&#20102;&#20854;&#23454;&#38469;&#30340;&#26377;&#29992;&#24615;&#21644;&#35299;&#37322;&#30340;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce Resilient Multiple Choice Learning (rMCL), an extension of the MCL approach for conditional distribution estimation in regression settings where multiple targets may be sampled for each training input. Multiple Choice Learning is a simple framework to tackle multimodal density estimation, using the Winner-Takes-All (WTA) loss for a set of hypotheses. In regression settings, the existing MCL variants focus on merging the hypotheses, thereby eventually sacrificing the diversity of the predictions. In contrast, our method relies on a novel learned scoring scheme underpinned by a mathematical framework based on Voronoi tessellations of the output space, from which we can derive a probabilistic interpretation. After empirically validating rMCL with experiments on synthetic data, we further assess its merits on the sound source localization problem, demonstrating its practical usefulness and the relevance of its interpretation.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;SGLD&#30340;&#26080;&#26102;&#38388;&#20449;&#24687;&#35770;&#24191;&#20041;&#30028;&#65292;&#23613;&#31649;&#36845;&#20195;&#27425;&#25968;&#21644;&#27493;&#38271;&#21487;&#33021;&#19981;&#22266;&#23450;&#65292;&#20294;&#36825;&#20123;&#30028;&#22312;&#26679;&#26412;&#22823;&#23567;&#22686;&#21152;&#26102;&#20250;&#34928;&#20943;&#20026;&#38646;&#12290;&#21516;&#26102;&#65292;&#36824;&#24314;&#31435;&#20102;&#22312;&#35757;&#32451;&#21644;&#27979;&#35797;&#25439;&#22833;&#30456;&#21516;&#26102;&#30340;&#20449;&#24687;&#35770;&#24191;&#20041;&#30028;&#65292;&#24182;&#35299;&#20915;&#20102;&#29616;&#26377;&#24037;&#20316;&#20013;&#27493;&#38271;&#20381;&#36182;&#30340;&#38382;&#39064;&#65292;&#20174;&#32780;&#24471;&#21040;&#20102;&#25913;&#36827;&#30340;&#36807;&#24230;&#39118;&#38505;&#30028;&#12290;</title><link>http://arxiv.org/abs/2311.01046</link><description>&lt;p&gt;
SGLD&#30340;&#26080;&#26102;&#38388;&#20449;&#24687;&#35770;&#24191;&#20041;&#30028;&#30340;&#32763;&#35793;
&lt;/p&gt;
&lt;p&gt;
Time-Independent Information-Theoretic Generalization Bounds for SGLD. (arXiv:2311.01046v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01046
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;SGLD&#30340;&#26080;&#26102;&#38388;&#20449;&#24687;&#35770;&#24191;&#20041;&#30028;&#65292;&#23613;&#31649;&#36845;&#20195;&#27425;&#25968;&#21644;&#27493;&#38271;&#21487;&#33021;&#19981;&#22266;&#23450;&#65292;&#20294;&#36825;&#20123;&#30028;&#22312;&#26679;&#26412;&#22823;&#23567;&#22686;&#21152;&#26102;&#20250;&#34928;&#20943;&#20026;&#38646;&#12290;&#21516;&#26102;&#65292;&#36824;&#24314;&#31435;&#20102;&#22312;&#35757;&#32451;&#21644;&#27979;&#35797;&#25439;&#22833;&#30456;&#21516;&#26102;&#30340;&#20449;&#24687;&#35770;&#24191;&#20041;&#30028;&#65292;&#24182;&#35299;&#20915;&#20102;&#29616;&#26377;&#24037;&#20316;&#20013;&#27493;&#38271;&#20381;&#36182;&#30340;&#38382;&#39064;&#65292;&#20174;&#32780;&#24471;&#21040;&#20102;&#25913;&#36827;&#30340;&#36807;&#24230;&#39118;&#38505;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20809;&#28369;&#24615;&#21644;&#32791;&#25955;&#24615;&#30340;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#38543;&#26426;&#26799;&#24230; Langevin &#21160;&#21147;&#23398; (SGLD) &#30340;&#26032;&#39062;&#20449;&#24687;&#35770;&#24191;&#20041;&#30028;&#12290;&#25105;&#20204;&#30340;&#30028;&#19981;&#20381;&#36182;&#20110;&#26102;&#38388;&#65292;&#22312;&#26679;&#26412;&#22823;&#23567;&#22686;&#21152;&#26102;&#20250;&#34928;&#20943;&#33267;&#38646;&#65292;&#19981;&#35770;&#36845;&#20195;&#27425;&#25968;&#21644;&#27493;&#38271;&#26159;&#21542;&#22266;&#23450;&#12290;&#19982;&#20197;&#21069;&#30340;&#30740;&#31350;&#19981;&#21516;&#65292;&#25105;&#20204;&#36890;&#36807;&#20851;&#27880; Kullback--Leibler &#25955;&#24230;&#30340;&#26102;&#38388;&#28436;&#21270;&#26469;&#25512;&#23548;&#24191;&#20041;&#35823;&#24046;&#30028;&#65292;&#35813;&#25955;&#24230;&#19982;&#25968;&#25454;&#38598;&#30340;&#31283;&#23450;&#24615;&#26377;&#20851;&#24182;&#19988;&#26159;&#36755;&#20986;&#21442;&#25968;&#19982;&#36755;&#20837;&#25968;&#25454;&#38598;&#20043;&#38388;&#20114;&#20449;&#24687;&#30340;&#19978;&#30028;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#35777;&#26126; SGLD &#30340;&#25439;&#22833;&#20989;&#25968;&#26159;&#27425;&#25351;&#25968;&#30340;&#26469;&#24314;&#31435;&#31532;&#19968;&#20010;&#24403;&#35757;&#32451;&#21644;&#27979;&#35797;&#25439;&#22833;&#30456;&#21516;&#26102;&#30340;&#20449;&#24687;&#35770;&#24191;&#20041;&#30028;&#12290;&#36825;&#20010;&#30028;&#20063;&#26159;&#26080;&#26102;&#38388;&#20851;&#32852;&#30340;&#65292;&#24182;&#19988;&#28040;&#38500;&#20102;&#29616;&#26377;&#24037;&#20316;&#20013;&#27493;&#38271;&#20381;&#36182;&#30340;&#38382;&#39064;&#65292;&#20174;&#32780;&#24471;&#21040;&#20102;&#25913;&#36827;&#30340;&#36807;&#24230;&#39118;&#38505;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
We provide novel information-theoretic generalization bounds for stochastic gradient Langevin dynamics (SGLD) under the assumptions of smoothness and dissipativity, which are widely used in sampling and non-convex optimization studies. Our bounds are time-independent and decay to zero as the sample size increases, regardless of the number of iterations and whether the step size is fixed. Unlike previous studies, we derive the generalization error bounds by focusing on the time evolution of the Kullback--Leibler divergence, which is related to the stability of datasets and is the upper bound of the mutual information between output parameters and an input dataset. Additionally, we establish the first information-theoretic generalization bound when the training and test loss are the same by showing that a loss function of SGLD is sub-exponential. This bound is also time-independent and removes the problematic step size dependence in existing work, leading to an improved excess risk bound
&lt;/p&gt;</description></item><item><title>&#25991;&#31456;&#30740;&#31350;&#20102;&#20855;&#26377;&#26377;&#38480;&#23545;&#25239;&#21160;&#20316;&#30340;&#32852;&#37030;&#32447;&#24615;&#36172;&#21338;&#26426;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;FedSupLinUCB&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;$\tilde{O}(\sqrt{d T})$&#30340;&#24635;&#36951;&#25022;&#65292;&#24182;&#19988;&#36890;&#20449;&#25104;&#26412;&#21487;&#20197;&#34987;&#25511;&#21046;&#22312;$O(d M^2 \log(d)\log(T))$&#21644;$O(\sqrt{d^3 M^3} \log(d))$&#20869;&#12290;</title><link>http://arxiv.org/abs/2311.00973</link><description>&lt;p&gt;
&#20855;&#26377;&#26377;&#38480;&#23545;&#25239;&#21160;&#20316;&#30340;&#32852;&#37030;&#32447;&#24615;&#36172;&#21338;&#26426;
&lt;/p&gt;
&lt;p&gt;
Federated Linear Bandits with Finite Adversarial Actions. (arXiv:2311.00973v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00973
&lt;/p&gt;
&lt;p&gt;
&#25991;&#31456;&#30740;&#31350;&#20102;&#20855;&#26377;&#26377;&#38480;&#23545;&#25239;&#21160;&#20316;&#30340;&#32852;&#37030;&#32447;&#24615;&#36172;&#21338;&#26426;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;FedSupLinUCB&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;$\tilde{O}(\sqrt{d T})$&#30340;&#24635;&#36951;&#25022;&#65292;&#24182;&#19988;&#36890;&#20449;&#25104;&#26412;&#21487;&#20197;&#34987;&#25511;&#21046;&#22312;$O(d M^2 \log(d)\log(T))$&#21644;$O(\sqrt{d^3 M^3} \log(d))$&#20869;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#32852;&#37030;&#32447;&#24615;&#36172;&#21338;&#26426;&#27169;&#22411;&#65292;&#20854;&#20013;$M$&#20010;&#23458;&#25143;&#31471;&#19982;&#20013;&#22830;&#26381;&#21153;&#22120;&#36890;&#20449;&#65292;&#35299;&#20915;&#20855;&#26377;&#19981;&#21516;&#23545;&#25239;&#21160;&#20316;&#38598;&#30340;&#26377;&#38480;&#23545;&#25239;&#21160;&#20316;&#38598;&#30340;&#32447;&#24615;&#19978;&#19979;&#25991;&#36172;&#21338;&#26426;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#23545;&#25239;&#24615;&#26377;&#38480;&#21160;&#20316;&#38598;&#30340;&#29420;&#29305;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;FedSupLinUCB&#31639;&#27861;&#65292;&#23427;&#22312;&#32447;&#24615;&#19978;&#19979;&#25991;&#36172;&#21338;&#26426;&#20013;&#25193;&#23637;&#20102;SupLinUCB&#21644;OFUL&#31639;&#27861;&#30340;&#21407;&#21017;&#12290;&#25105;&#20204;&#35777;&#26126;FedSupLinUCB&#30340;&#24635;&#36951;&#25022;&#20026;$\tilde{O}(\sqrt{d T})$&#65292;&#20854;&#20013;$T$&#26159;&#25152;&#26377;&#23458;&#25143;&#31471;&#30340;&#24635;&#33218;&#25289;&#27425;&#25968;&#65292;$d$&#26159;&#32447;&#24615;&#27169;&#22411;&#30340;&#29615;&#22659;&#32500;&#24230;&#12290;&#36825;&#19982;&#26497;&#23567;&#20540;&#19979;&#30028;&#30456;&#21305;&#37197;&#65292;&#22240;&#27492;&#26159;&#26368;&#20248;&#30340;&#65288;&#22810;&#39033;&#24335;&#23545;&#25968;&#39033;&#65289;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#24322;&#27493;&#21644;&#21516;&#27493;&#20004;&#31181;&#24773;&#20917;&#65292;&#24182;&#23637;&#31034;&#20102;&#36890;&#20449;&#25104;&#26412;&#21487;&#20197;&#20998;&#21035;&#25511;&#21046;&#20026;$O(d M^2 \log(d) \log(T))$&#21644;$O(\sqrt{d^3 M^3} \log(d))$&#12290;FedSupLinUCB&#35774;&#35745;&#36827;&#19968;&#27493;&#25193;&#23637;&#20026;&#20004;&#31181;&#24773;&#26223;&#65306;&#65288;1&#65289;&#26041;&#24046;&#33258;&#36866;&#24212;&#65292;&#24635;&#36951;&#25022;&#20026;$\tilde{O}(\sqrt{
&lt;/p&gt;
&lt;p&gt;
We study a federated linear bandits model, where $M$ clients communicate with a central server to solve a linear contextual bandits problem with finite adversarial action sets that may be different across clients. To address the unique challenges of adversarial finite action sets, we propose the FedSupLinUCB algorithm, which extends the principles of SupLinUCB and OFUL algorithms in linear contextual bandits. We prove that FedSupLinUCB achieves a total regret of $\tilde{O}(\sqrt{d T})$, where $T$ is the total number of arm pulls from all clients, and $d$ is the ambient dimension of the linear model. This matches the minimax lower bound and thus is order-optimal (up to polylog terms). We study both asynchronous and synchronous cases and show that the communication cost can be controlled as $O(d M^2 \log(d)\log(T))$ and $O(\sqrt{d^3 M^3} \log(d))$, respectively. The FedSupLinUCB design is further extended to two scenarios: (1) variance-adaptive, where a total regret of $\tilde{O} (\sqrt{
&lt;/p&gt;</description></item><item><title>ISR&#26159;&#19968;&#31181;&#26032;&#22411;&#30340;&#21487;&#35777;&#26126;&#30340;&#39046;&#22495;&#27867;&#21270;&#31639;&#27861;&#65292;&#23427;&#21487;&#20197;&#36890;&#36807;&#31867;&#26465;&#20214;&#20998;&#24067;&#30340;&#19968;&#38454;&#30697;&#26469;&#35782;&#21035;&#19981;&#21464;&#29305;&#24449;&#25152;&#24352;&#25104;&#30340;&#23376;&#31354;&#38388;&#12290;</title><link>http://arxiv.org/abs/2311.00966</link><description>&lt;p&gt;
&#19981;&#21464;&#29305;&#24449;&#23376;&#31354;&#38388;&#24674;&#22797;&#65306;&#19968;&#31867;&#26032;&#30340;&#21487;&#35777;&#26126;&#30340;&#39046;&#22495;&#27867;&#21270;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Invariant-Feature Subspace Recovery: A New Class of Provable Domain Generalization Algorithms. (arXiv:2311.00966v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00966
&lt;/p&gt;
&lt;p&gt;
ISR&#26159;&#19968;&#31181;&#26032;&#22411;&#30340;&#21487;&#35777;&#26126;&#30340;&#39046;&#22495;&#27867;&#21270;&#31639;&#27861;&#65292;&#23427;&#21487;&#20197;&#36890;&#36807;&#31867;&#26465;&#20214;&#20998;&#24067;&#30340;&#19968;&#38454;&#30697;&#26469;&#35782;&#21035;&#19981;&#21464;&#29305;&#24449;&#25152;&#24352;&#25104;&#30340;&#23376;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39046;&#22495;&#27867;&#21270;&#35201;&#27714;&#22312;&#19968;&#32452;&#35757;&#32451;&#29615;&#22659;&#20013;&#35757;&#32451;&#30340;&#27169;&#22411;&#33021;&#22815;&#22312;&#26410;&#30693;&#30340;&#27979;&#35797;&#29615;&#22659;&#20013;&#33391;&#22909;&#22320;&#27867;&#21270;&#12290;&#26368;&#36817;&#65292;&#19968;&#31995;&#21015;&#31639;&#27861;&#65292;&#22914;&#19981;&#21464;&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;IRM&#65289;&#65292;&#24050;&#34987;&#25552;&#20986;&#29992;&#20110;&#39046;&#22495;&#27867;&#21270;&#12290;&#28982;&#32780;&#65292;Rosenfeld&#31561;&#20154;&#65288;2021&#65289;&#34920;&#26126;&#65292;&#22312;&#19968;&#20010;&#31616;&#21333;&#30340;&#32447;&#24615;&#25968;&#25454;&#27169;&#22411;&#20013;&#65292;&#21363;&#20351;&#24573;&#30053;&#20102;&#38750;&#20984;&#24615;&#38382;&#39064;&#65292;IRM&#21450;&#20854;&#25193;&#23637;&#20063;&#26080;&#27861;&#23545;&#20855;&#26377;&#23569;&#20110;$d_s+1$&#20010;&#35757;&#32451;&#29615;&#22659;&#30340;&#26410;&#30693;&#29615;&#22659;&#36827;&#34892;&#27867;&#21270;&#65292;&#20854;&#20013;$d_s$&#26159;&#34394;&#20551;&#29305;&#24449;&#23376;&#31354;&#38388;&#30340;&#32500;&#24230;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19981;&#21464;&#29305;&#24449;&#23376;&#31354;&#38388;&#24674;&#22797;&#65288;ISR&#65289;&#65306;&#19968;&#31867;&#26032;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#20998;&#31867;&#21644;&#22238;&#24402;&#38382;&#39064;&#35774;&#32622;&#20013;&#23454;&#29616;&#21487;&#35777;&#26126;&#30340;&#39046;&#22495;&#27867;&#21270;&#12290;&#39318;&#20808;&#65292;&#22312;Rosenfeld&#31561;&#20154;&#65288;2021&#65289;&#30340;&#20108;&#20998;&#31867;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#31532;&#19968;&#20010;&#31639;&#27861;ISR-Mean&#65292;&#23427;&#21487;&#20197;&#36890;&#36807;&#31867;&#26465;&#20214;&#20998;&#24067;&#30340;&#19968;&#38454;&#30697;&#26469;&#35782;&#21035;&#19981;&#21464;&#29305;&#24449;&#25152;&#24352;&#25104;&#30340;&#23376;&#31354;&#38388;&#65292;&#24182;&#23454;&#29616;&#21487;&#35777;&#26126;&#30340;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Domain generalization asks for models trained over a set of training environments to generalize well in unseen test environments. Recently, a series of algorithms such as Invariant Risk Minimization (IRM) have been proposed for domain generalization. However, Rosenfeld et al. (2021) shows that in a simple linear data model, even if non-convexity issues are ignored, IRM and its extensions cannot generalize to unseen environments with less than $d_s+1$ training environments, where $d_s$ is the dimension of the spurious-feature subspace. In this work, we propose Invariant-feature Subspace Recovery (ISR): a new class of algorithms to achieve provable domain generalization across the settings of classification and regression problems. First, in the binary classification setup of Rosenfeld et al. (2021), we show that our first algorithm, ISR-Mean, can identify the subspace spanned by invariant features from the first-order moments of the class-conditional distributions, and achieve provable 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;FESS-GDA&#65292;&#21033;&#29992;&#24179;&#28369;&#25216;&#26415;&#36827;&#34892;&#32852;&#37030;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#12290;&#36890;&#36807;&#35299;&#20915;&#19981;&#21516;&#31867;&#22411;&#30340;&#32852;&#37030;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;FESS-GDA&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;&#23454;&#38469;&#32852;&#37030;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#23454;&#38469;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2311.00944</link><description>&lt;p&gt;
&#22522;&#20110;&#38543;&#26426;&#24179;&#28369;&#26799;&#24230;&#19978;&#21319;&#19979;&#38477;&#27861;&#30340;&#32852;&#37030;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Stochastic Smoothed Gradient Descent Ascent for Federated Minimax Optimization. (arXiv:2311.00944v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00944
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;FESS-GDA&#65292;&#21033;&#29992;&#24179;&#28369;&#25216;&#26415;&#36827;&#34892;&#32852;&#37030;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#12290;&#36890;&#36807;&#35299;&#20915;&#19981;&#21516;&#31867;&#22411;&#30340;&#32852;&#37030;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;FESS-GDA&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;&#23454;&#38469;&#32852;&#37030;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#23454;&#38469;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#30001;&#20110;&#20854;&#22312;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#24191;&#27867;&#24212;&#29992;&#65292;&#32852;&#37030;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#34429;&#28982;&#22312;&#38598;&#20013;&#38750;&#20984;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#20013;&#65292;&#24179;&#28369;&#20132;&#26367;&#26799;&#24230;&#19978;&#21319;&#19979;&#38477;&#65288;Smoothed-AGDA&#65289;&#24050;&#32463;&#35777;&#26126;&#20102;&#20854;&#25104;&#21151;&#20043;&#22788;&#65292;&#20294;&#24179;&#28369;&#25216;&#26415;&#22312;&#32852;&#37030;&#35774;&#32622;&#20013;&#30340;&#20316;&#29992;&#21644;&#26159;&#21542;&#26377;&#25152;&#24110;&#21161;&#23578;&#26410;&#34987;&#25506;&#31350;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;&#31216;&#20026;&#32852;&#37030;&#38543;&#26426;&#24179;&#28369;&#26799;&#24230;&#19978;&#21319;&#19979;&#38477;&#65288;FESS-GDA&#65289;&#65292;&#35813;&#31639;&#27861;&#21033;&#29992;&#24179;&#28369;&#25216;&#26415;&#36827;&#34892;&#32852;&#37030;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;FESS-GDA&#21487;&#20197;&#32479;&#19968;&#35299;&#20915;&#20960;&#31867;&#32852;&#37030;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#24182;&#20026;&#36825;&#20123;&#35774;&#32622;&#25552;&#20379;&#20102;&#26032;&#30340;&#25110;&#26356;&#22909;&#30340;&#25910;&#25947;&#32467;&#26524;&#20998;&#26512;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;FESS-GDA&#22312;&#23454;&#38469;&#32852;&#37030;&#23398;&#20064;&#20219;&#21153;&#20013;&#65292;&#22914;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GANs&#65289;&#30340;&#35757;&#32451;&#21644;&#20844;&#24179;&#20998;&#31867;&#20013;&#30340;&#23454;&#38469;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, federated minimax optimization has attracted growing interest due to its extensive applications in various machine learning tasks. While Smoothed Alternative Gradient Descent Ascent (Smoothed-AGDA) has proved its success in centralized nonconvex minimax optimization, how and whether smoothing technique could be helpful in federated setting remains unexplored. In this paper, we propose a new algorithm termed Federated Stochastic Smoothed Gradient Descent Ascent (FESS-GDA), which utilizes the smoothing technique for federated minimax optimization. We prove that FESS-GDA can be uniformly used to solve several classes of federated minimax problems and prove new or better analytical convergence results for these settings. We showcase the practical efficiency of FESS-GDA in practical federated learning tasks of training generative adversarial networks (GANs) and fair classification.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#22810;&#21464;&#37327;&#22240;&#26524;&#27169;&#22411;&#20013;&#20272;&#35745;&#22810;&#20010;&#24863;&#20852;&#36259;&#37327;&#30340;&#21453;&#20107;&#23454;&#32852;&#21512;&#20998;&#24067;&#12290;&#36890;&#36807;&#21033;&#29992;&#21407;&#22987;&#39640;&#32500;&#31354;&#38388;&#20013;&#30340;&#19968;&#32500;&#28508;&#22312;&#23376;&#31354;&#38388;&#21644;&#21333;&#19968;&#21464;&#37327;&#22240;&#26524;&#27169;&#22411;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#21516;&#26102;&#22788;&#29702;&#22810;&#21464;&#37327;&#32467;&#26524;&#30340;&#30456;&#20851;&#32467;&#26500;&#24182;&#20135;&#29983;&#20934;&#30830;&#30340;&#21453;&#20107;&#23454;&#20998;&#24067;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2311.00927</link><description>&lt;p&gt;
&#21487;&#25193;&#23637;&#30340;&#22810;&#21464;&#37327;&#22240;&#26524;&#27169;&#22411;&#20013;&#30340;&#21453;&#20107;&#23454;&#20998;&#24067;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Scalable Counterfactual Distribution Estimation in Multivariate Causal Models. (arXiv:2311.00927v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00927
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#22810;&#21464;&#37327;&#22240;&#26524;&#27169;&#22411;&#20013;&#20272;&#35745;&#22810;&#20010;&#24863;&#20852;&#36259;&#37327;&#30340;&#21453;&#20107;&#23454;&#32852;&#21512;&#20998;&#24067;&#12290;&#36890;&#36807;&#21033;&#29992;&#21407;&#22987;&#39640;&#32500;&#31354;&#38388;&#20013;&#30340;&#19968;&#32500;&#28508;&#22312;&#23376;&#31354;&#38388;&#21644;&#21333;&#19968;&#21464;&#37327;&#22240;&#26524;&#27169;&#22411;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#21516;&#26102;&#22788;&#29702;&#22810;&#21464;&#37327;&#32467;&#26524;&#30340;&#30456;&#20851;&#32467;&#26500;&#24182;&#20135;&#29983;&#20934;&#30830;&#30340;&#21453;&#20107;&#23454;&#20998;&#24067;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#22312;&#32463;&#20856;&#30340;&#24046;&#24322;&#24046;&#24322;&#35774;&#35745;&#30340;&#22522;&#30784;&#19978;&#25193;&#23637;&#30340;&#22810;&#21464;&#37327;&#22240;&#26524;&#27169;&#22411;&#20013;&#20272;&#35745;&#22810;&#20010;&#24863;&#20852;&#36259;&#37327;&#65288;&#20363;&#22914;&#32467;&#26524;&#65289;&#30340;&#21453;&#20107;&#23454;&#32852;&#21512;&#20998;&#24067;&#30340;&#38382;&#39064;&#12290;&#29616;&#26377;&#30340;&#26041;&#27861;&#35201;&#20040;&#24573;&#30053;&#22810;&#21464;&#37327;&#32467;&#26524;&#21508;&#32500;&#24230;&#38388;&#30340;&#30456;&#20851;&#32467;&#26500;&#65292;&#36890;&#36807;&#22312;&#27599;&#20010;&#32500;&#24230;&#19978;&#32771;&#34385;&#21333;&#19968;&#21464;&#37327;&#22240;&#26524;&#27169;&#22411;&#32780;&#20135;&#29983;&#38169;&#35823;&#30340;&#21453;&#20107;&#23454;&#20998;&#24067;&#65307;&#35201;&#20040;&#22312;&#30452;&#25509;&#22788;&#29702;&#36825;&#31181;&#22810;&#21464;&#37327;&#22240;&#26524;&#27169;&#22411;&#26102;&#65292;&#22312;&#20013;&#31561;&#22823;&#23567;&#30340;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#19981;&#20339;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#21516;&#26102;&#20943;&#36731;&#36825;&#20004;&#20010;&#38382;&#39064;&#65292;&#26041;&#27861;&#26159;&#21033;&#29992;&#21407;&#22987;&#39640;&#32500;&#31354;&#38388;&#20013;&#40065;&#26834;&#30340;&#19968;&#32500;&#28508;&#22312;&#23376;&#31354;&#38388;&#65292;&#24182;&#21033;&#29992;&#21333;&#19968;&#21464;&#37327;&#22240;&#26524;&#27169;&#22411;&#22312;&#35813;&#31354;&#38388;&#19978;&#30340;&#39640;&#25928;&#20272;&#35745;&#12290;&#30001;&#20110;&#19968;&#32500;&#23376;&#31354;&#38388;&#30340;&#26500;&#24314;&#20351;&#29992;&#20102;&#26469;&#33258;&#25152;&#26377;&#32500;&#24230;&#30340;&#20449;&#24687;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#25429;&#25417;&#30456;&#20851;&#32467;&#26500;&#24182;&#20135;&#29983;&#21453;&#20107;&#23454;&#20998;&#24067;&#30340;&#33391;&#22909;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of estimating the counterfactual joint distribution of multiple quantities of interests (e.g., outcomes) in a multivariate causal model extended from the classical difference-in-difference design. Existing methods for this task either ignore the correlation structures among dimensions of the multivariate outcome by considering univariate causal models on each dimension separately and hence produce incorrect counterfactual distributions, or poorly scale even for moderate-size datasets when directly dealing with such multivariate causal model. We propose a method that alleviates both issues simultaneously by leveraging a robust latent one-dimensional subspace of the original high-dimension space and exploiting the efficient estimation from the univariate causal model on such space. Since the construction of the one-dimensional subspace uses information from all the dimensions, our method can capture the correlation structures and produce good estimates of the coun
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#39640;&#26031;&#36807;&#31243;&#19982;&#20302;&#32500;&#20132;&#20114;&#32467;&#26500;&#30456;&#32467;&#21512;&#30340;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#20108;&#38454;&#31890;&#23376;&#21160;&#21147;&#23398;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#22788;&#29702;&#30456;&#20114;&#20316;&#29992;&#20195;&#29702;&#30340;&#32858;&#21512;&#21644;&#38598;&#20307;&#34892;&#20026;&#65292;&#20855;&#26377;&#36739;&#39640;&#30340;&#21487;&#25193;&#23637;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2311.00902</link><description>&lt;p&gt;
&#36890;&#36807;&#23558;&#39640;&#26031;&#36807;&#31243;&#19982;&#20302;&#32500;&#20132;&#20114;&#32467;&#26500;&#30456;&#32467;&#21512;&#65292;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#36873;&#25321;&#20108;&#38454;&#31890;&#23376;&#21160;&#21147;&#23398;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Data-Driven Model Selections of Second-Order Particle Dynamics via Integrating Gaussian Processes with Low-Dimensional Interacting Structures. (arXiv:2311.00902v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00902
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#39640;&#26031;&#36807;&#31243;&#19982;&#20302;&#32500;&#20132;&#20114;&#32467;&#26500;&#30456;&#32467;&#21512;&#30340;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#20108;&#38454;&#31890;&#23376;&#21160;&#21147;&#23398;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#22788;&#29702;&#30456;&#20114;&#20316;&#29992;&#20195;&#29702;&#30340;&#32858;&#21512;&#21644;&#38598;&#20307;&#34892;&#20026;&#65292;&#20855;&#26377;&#36739;&#39640;&#30340;&#21487;&#25193;&#23637;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37325;&#28857;&#30740;&#31350;&#20102;&#19968;&#31181;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#36890;&#29992;&#20108;&#38454;&#31890;&#23376;&#27169;&#22411;&#30340;&#21457;&#29616;&#65292;&#35813;&#27169;&#22411;&#21253;&#21547;&#20102;&#35768;&#22810;&#29992;&#20110;&#24314;&#27169;&#30456;&#20284;&#22823;&#23567;&#21644;&#20307;&#22411;&#30340;&#30456;&#20114;&#20316;&#29992;&#20195;&#29702;&#30340;&#32858;&#21512;&#21644;&#38598;&#20307;&#34892;&#20026;&#30340;&#26368;&#26032;&#27169;&#22411;&#12290;&#35813;&#27169;&#22411;&#37319;&#29992;&#20102;&#30001;&#20004;&#20010;&#30456;&#20114;&#20316;&#29992;&#26680;&#21442;&#25968;&#21270;&#30340;&#39640;&#32500;&#24120;&#24494;&#20998;&#26041;&#31243;&#31995;&#32479;&#30340;&#24418;&#24335;&#65292;&#36825;&#20123;&#26680;&#35780;&#20272;&#20102;&#20301;&#32622;&#21644;&#36895;&#24230;&#30340;&#23545;&#40784;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20854;&#20013;&#26410;&#30693;&#30340;&#27169;&#22411;&#21442;&#25968;&#36890;&#36807;&#20351;&#29992;&#20004;&#20010;&#29420;&#31435;&#30340;&#39640;&#26031;&#36807;&#31243;&#20808;&#39564;&#36827;&#34892;&#36793;&#32536;&#21270;&#65292;&#36825;&#20123;&#20808;&#39564;&#32422;&#26463;&#22312;&#21160;&#21147;&#23398;&#21644;&#35266;&#27979;&#25968;&#25454;&#19978;&#12290;&#36825;&#23548;&#33268;&#19968;&#20010;&#38750;&#21442;&#25968;&#27169;&#22411;&#65292;&#29992;&#20110;&#32771;&#34385;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#30456;&#20114;&#20316;&#29992;&#21160;&#21147;&#23398;&#31995;&#32479;&#12290;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#21152;&#36895;&#25216;&#26415;&#26469;&#25552;&#39640;&#21487;&#25193;&#23637;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#26469;&#35299;&#37322;&#26041;&#27861;&#35770;&#24182;&#30740;&#31350;&#26680;&#21487;&#20197;&#28385;&#36275;&#30340;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we focus on the data-driven discovery of a general second-order particle-based model that contains many state-of-the-art models for modeling the aggregation and collective behavior of interacting agents of similar size and body type. This model takes the form of a high-dimensional system of ordinary differential equations parameterized by two interaction kernels that appraise the alignment of positions and velocities. We propose a Gaussian Process-based approach to this problem, where the unknown model parameters are marginalized by using two independent Gaussian Process (GP) priors on latent interaction kernels constrained to dynamics and observational data. This results in a nonparametric model for interacting dynamical systems that accounts for uncertainty quantification. We also develop acceleration techniques to improve scalability. Moreover, we perform a theoretical analysis to interpret the methodology and investigate the conditions under which the kernels can be 
&lt;/p&gt;</description></item><item><title>Transformer&#27169;&#22411;&#36890;&#36807;&#39044;&#35757;&#32451;&#25968;&#25454;&#28151;&#21512;&#23454;&#29616;&#20102;&#29421;&#31364;&#30340;&#27169;&#22411;&#36873;&#25321;&#33021;&#21147;&#65292;&#33021;&#22815;&#22312;&#19978;&#19979;&#25991;&#20013;&#35782;&#21035;&#21644;&#23398;&#20064;&#19981;&#21516;&#30340;&#20219;&#21153;&#65292;&#20294;&#23545;&#20110;&#20219;&#21153;&#25110;&#20989;&#25968;&#30340;&#22788;&#29702;&#30456;&#23545;&#26377;&#38480;&#12290;</title><link>http://arxiv.org/abs/2311.00871</link><description>&lt;p&gt;
&#39044;&#35757;&#32451;&#25968;&#25454;&#28151;&#21512;&#20351;&#24471;Transformer&#27169;&#22411;&#20855;&#22791;&#29421;&#31364;&#30340;&#27169;&#22411;&#36873;&#25321;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Pretraining Data Mixtures Enable Narrow Model Selection Capabilities in Transformer Models. (arXiv:2311.00871v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00871
&lt;/p&gt;
&lt;p&gt;
Transformer&#27169;&#22411;&#36890;&#36807;&#39044;&#35757;&#32451;&#25968;&#25454;&#28151;&#21512;&#23454;&#29616;&#20102;&#29421;&#31364;&#30340;&#27169;&#22411;&#36873;&#25321;&#33021;&#21147;&#65292;&#33021;&#22815;&#22312;&#19978;&#19979;&#25991;&#20013;&#35782;&#21035;&#21644;&#23398;&#20064;&#19981;&#21516;&#30340;&#20219;&#21153;&#65292;&#20294;&#23545;&#20110;&#20219;&#21153;&#25110;&#20989;&#25968;&#30340;&#22788;&#29702;&#30456;&#23545;&#26377;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Transformer&#27169;&#22411;&#65292;&#29305;&#21035;&#26159;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#65292;&#20855;&#26377;&#22312;&#19978;&#19979;&#25991;&#20013;&#23398;&#20064;&#65288;ICL&#65289;&#30340;&#26174;&#33879;&#33021;&#21147;-&#22312;&#26410;&#32463;&#36807;&#20219;&#20309;&#26126;&#30830;&#27169;&#22411;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#65292;&#26681;&#25454;&#26410;&#35265;&#36807;&#30340;&#36755;&#20837;-&#36755;&#20986;&#20363;&#23376;&#25191;&#34892;&#26032;&#30340;&#20219;&#21153;&#12290;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;Transformer&#27169;&#22411;&#22914;&#20309;&#26377;&#25928;&#22320;&#22312;&#20854;&#39044;&#35757;&#32451;&#25968;&#25454;&#28151;&#21512;&#20013;&#24314;&#31435;&#26725;&#26753;&#65292;&#20197;&#22312;&#19978;&#19979;&#25991;&#20013;&#35782;&#21035;&#21644;&#23398;&#20064;&#26082;&#21253;&#25324;&#39044;&#35757;&#32451;&#20998;&#24067;&#20869;&#21448;&#21253;&#25324;&#20854;&#22806;&#30340;&#26032;&#20219;&#21153;&#12290;&#22312;&#20043;&#21069;&#30340;&#30740;&#31350;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#22312;&#19968;&#20010;&#21463;&#25511;&#30340;&#29615;&#22659;&#20013;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22522;&#20110;$(x, f(x))$&#23545;&#24207;&#21015;&#32780;&#19981;&#26159;&#33258;&#28982;&#35821;&#35328;&#36827;&#34892;&#35757;&#32451;&#30340;Transformer&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;Transformer&#27169;&#22411;&#22312;&#26080;&#30417;&#30563;&#27169;&#22411;&#36873;&#25321;&#33021;&#21147;&#26041;&#38754;&#34920;&#29616;&#25509;&#36817;&#26368;&#20248;&#65292;&#22312;&#33021;&#22815;&#39318;&#20808;&#22312;&#19978;&#19979;&#25991;&#20013;&#35782;&#21035;&#19981;&#21516;&#30340;&#20219;&#21153;&#26063;&#32676;&#24182;&#22312;&#20854;&#20013;&#36827;&#34892;&#23398;&#20064;&#26102;&#65288;&#20219;&#21153;&#26063;&#32676;&#22312;&#39044;&#35757;&#32451;&#25968;&#25454;&#20013;&#26377;&#24456;&#22909;&#30340;&#34920;&#31034;&#65289;&#12290;&#28982;&#32780;&#65292;&#24403;&#38754;&#23545;&#20219;&#21153;&#25110;&#20989;&#25968;&#26102;&#65292;&#24773;&#20917;&#20250;&#31245;&#26377;&#19981;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transformer models, notably large language models (LLMs), have the remarkable ability to perform in-context learning (ICL) -- to perform new tasks when prompted with unseen input-output examples without any explicit model training. In this work, we study how effectively transformers can bridge between their pretraining data mixture, comprised of multiple distinct task families, to identify and learn new tasks in-context which are both inside and outside the pretraining distribution. Building on previous work, we investigate this question in a controlled setting, where we study transformer models trained on sequences of $(x, f(x))$ pairs rather than natural language. Our empirical results show transformers demonstrate near-optimal unsupervised model selection capabilities, in their ability to first in-context identify different task families and in-context learn within them when the task families are well-represented in their pretraining data. However when presented with tasks or functi
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#36229;&#36234;&#32467;&#26500;&#31232;&#30095;&#24615;&#30340;&#38750;&#32447;&#24615;ICA&#30340;&#27867;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#32452;&#26032;&#30340;&#22312;&#19981;&#23436;&#22791;&#24615;&#12289;&#37096;&#20998;&#31232;&#30095;&#24615;&#12289;&#28304;&#20381;&#36182;&#24615;&#21644;&#28789;&#27963;&#30340;&#20998;&#32452;&#32467;&#26500;&#19979;&#30340;&#21487;&#36776;&#35782;&#24615;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2311.00866</link><description>&lt;p&gt;
&#36229;&#36234;&#32467;&#26500;&#31232;&#30095;&#24615;&#30340;&#38750;&#32447;&#24615;ICA&#30340;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Generalizing Nonlinear ICA Beyond Structural Sparsity. (arXiv:2311.00866v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.00866
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#36229;&#36234;&#32467;&#26500;&#31232;&#30095;&#24615;&#30340;&#38750;&#32447;&#24615;ICA&#30340;&#27867;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#32452;&#26032;&#30340;&#22312;&#19981;&#23436;&#22791;&#24615;&#12289;&#37096;&#20998;&#31232;&#30095;&#24615;&#12289;&#28304;&#20381;&#36182;&#24615;&#21644;&#28789;&#27963;&#30340;&#20998;&#32452;&#32467;&#26500;&#19979;&#30340;&#21487;&#36776;&#35782;&#24615;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#32447;&#24615;&#29420;&#31435;&#25104;&#20998;&#20998;&#26512;&#65288;ICA&#65289;&#26088;&#22312;&#20174;&#21487;&#35266;&#27979;&#30340;&#38750;&#32447;&#24615;&#28151;&#21512;&#20013;&#25581;&#31034;&#30495;&#27491;&#30340;&#28508;&#22312;&#28304;&#12290;&#23613;&#31649;&#20854;&#37325;&#35201;&#24615;&#65292;&#38750;&#32447;&#24615;ICA&#30340;&#21487;&#36776;&#35782;&#24615;&#22312;&#27809;&#26377;&#38468;&#21152;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#26159;&#19981;&#21487;&#33021;&#30340;&#12290;&#26368;&#36817;&#30340;&#36827;&#23637;&#25552;&#20986;&#20102;&#28304;&#21040;&#35266;&#27979;&#21464;&#37327;&#30340;&#36830;&#25509;&#32467;&#26500;&#30340;&#26465;&#20214;&#65292;&#31216;&#20026;&#32467;&#26500;&#31232;&#30095;&#24615;&#65292;&#20197;&#23454;&#29616;&#26080;&#30417;&#30563;&#30340;&#21487;&#36776;&#35782;&#24615;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#31232;&#30095;&#32422;&#26463;&#21487;&#33021;&#19981;&#36866;&#29992;&#20110;&#25152;&#26377;&#28304;&#12290;&#27492;&#22806;&#65292;&#28304;&#30340;&#28151;&#21512;&#36807;&#31243;&#30340;&#21452;&#23556;&#24615;&#21644;&#25152;&#26377;&#28304;&#20043;&#38388;&#30340;&#29420;&#31435;&#24615;&#30340;&#20551;&#35774;&#65292;&#36825;&#20123;&#20551;&#35774;&#26469;&#33258;ICA&#30340;&#35774;&#23450;&#65292;&#22312;&#35768;&#22810;&#29616;&#23454;&#22330;&#26223;&#20013;&#20063;&#21487;&#33021;&#34987;&#36829;&#32972;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#24182;&#27867;&#21270;&#38750;&#32447;&#24615;ICA&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#32452;&#26032;&#30340;&#21487;&#36776;&#35782;&#24615;&#32467;&#26524;&#65292;&#28085;&#30422;&#19981;&#23436;&#22791;&#24615;&#12289;&#37096;&#20998;&#31232;&#30095;&#24615;&#12289;&#28304;&#20381;&#36182;&#24615;&#21644;&#28789;&#27963;&#30340;&#20998;&#32452;&#32467;&#26500;&#30340;&#19968;&#33324;&#35774;&#32622;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#22312;&#23384;&#22312;&#26356;&#22810;&#28304;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21487;&#36776;&#35782;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Nonlinear independent component analysis (ICA) aims to uncover the true latent sources from their observable nonlinear mixtures. Despite its significance, the identifiability of nonlinear ICA is known to be impossible without additional assumptions. Recent advances have proposed conditions on the connective structure from sources to observed variables, known as Structural Sparsity, to achieve identifiability in an unsupervised manner. However, the sparsity constraint may not hold universally for all sources in practice. Furthermore, the assumptions of bijectivity of the mixing process and independence among all sources, which arise from the setting of ICA, may also be violated in many real-world scenarios. To address these limitations and generalize nonlinear ICA, we propose a set of new identifiability results in the general settings of undercompleteness, partial sparsity and source dependence, and flexible grouping structures. Specifically, we prove identifiability when there are mor
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#39640;&#32500;&#39640;&#26031;&#25968;&#25454;&#30340;&#22810;&#32034;&#24341;&#22238;&#24402;&#38382;&#39064;&#20013;&#65292;&#36890;&#36807;&#26799;&#24230;&#27969;&#23398;&#20064;&#20302;&#31209;&#32447;&#24615;&#25237;&#24433;&#21644;&#20302;&#32500;&#36830;&#25509;&#20989;&#25968;&#65292;&#24314;&#31435;&#20102;&#20840;&#23616;&#25910;&#25947;&#24615;&#21644;&#23450;&#37327;&#25551;&#36848;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.19793</link><description>&lt;p&gt;
&#20851;&#20110;&#20351;&#29992;&#26799;&#24230;&#27969;&#23398;&#20064;&#39640;&#26031;&#22810;&#32034;&#24341;&#27169;&#22411;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Learning Gaussian Multi-index Models with Gradient Flow. (arXiv:2310.19793v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19793
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#39640;&#32500;&#39640;&#26031;&#25968;&#25454;&#30340;&#22810;&#32034;&#24341;&#22238;&#24402;&#38382;&#39064;&#20013;&#65292;&#36890;&#36807;&#26799;&#24230;&#27969;&#23398;&#20064;&#20302;&#31209;&#32447;&#24615;&#25237;&#24433;&#21644;&#20302;&#32500;&#36830;&#25509;&#20989;&#25968;&#65292;&#24314;&#31435;&#20102;&#20840;&#23616;&#25910;&#25947;&#24615;&#21644;&#23450;&#37327;&#25551;&#36848;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#39640;&#32500;&#39640;&#26031;&#25968;&#25454;&#30340;&#22810;&#32034;&#24341;&#22238;&#24402;&#38382;&#39064;&#20013;&#30340;&#26799;&#24230;&#27969;&#12290;&#22810;&#32034;&#24341;&#20989;&#25968;&#30001;&#26410;&#30693;&#30340;&#20302;&#31209;&#32447;&#24615;&#25237;&#24433;&#21644;&#20219;&#24847;&#26410;&#30693;&#30340;&#20302;&#32500;&#36830;&#25509;&#20989;&#25968;&#32452;&#25104;&#12290;&#22240;&#27492;&#65292;&#23427;&#20204;&#26500;&#25104;&#20102;&#31070;&#32463;&#32593;&#32476;&#20013;&#29305;&#24449;&#23398;&#20064;&#30340;&#33258;&#28982;&#27169;&#26495;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#20004;&#26102;&#38388;&#23610;&#24230;&#30340;&#31639;&#27861;&#65292;&#20854;&#20013;&#20302;&#32500;&#36830;&#25509;&#20989;&#25968;&#36890;&#36807;&#38750;&#21442;&#25968;&#27169;&#22411;&#27604;&#21442;&#25968;&#21270;&#20302;&#31209;&#25237;&#24433;&#30340;&#20302;&#32500;&#31354;&#38388;&#26356;&#24555;&#22320;&#23398;&#20064;&#12290;&#36890;&#36807;&#36866;&#24403;&#22320;&#21033;&#29992;&#26694;&#26550;&#30340;&#30456;&#20851;&#30697;&#38453;&#19978;&#30340;&#30697;&#38453;&#21322;&#32676;&#32467;&#26500;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#30001;Grassmannian&#20154;&#21475;&#26799;&#24230;&#27969;&#21160;&#21147;&#23398;&#24341;&#36215;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#65292;&#24182;&#23545;&#20854;&#30456;&#20851;&#30340;&#8220;&#38797;&#28857;&#21040;&#38797;&#28857;&#8221;&#21160;&#21147;&#23398;&#25552;&#20379;&#20102;&#23450;&#37327;&#25551;&#36848;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#27599;&#20010;&#38797;&#30340;&#26102;&#38388;&#23610;&#24230;&#21487;&#20197;&#26126;&#30830;&#22320;&#29992;&#30446;&#26631;&#36830;&#25509;&#20989;&#25968;&#30340;&#36866;&#24403;Hermite&#20998;&#35299;&#26469;&#34920;&#24449;&#12290;&#19982;&#36825;&#20123;&#20301;&#32622;&#30456;&#21453;&#30340;&#26159;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study gradient flow on the multi-index regression problem for high-dimensional Gaussian data. Multi-index functions consist of a composition of an unknown low-rank linear projection and an arbitrary unknown, low-dimensional link function. As such, they constitute a natural template for feature learning in neural networks.  We consider a two-timescale algorithm, whereby the low-dimensional link function is learnt with a non-parametric model infinitely faster than the subspace parametrizing the low-rank projection. By appropriately exploiting the matrix semigroup structure arising over the subspace correlation matrices, we establish global convergence of the resulting Grassmannian population gradient flow dynamics, and provide a quantitative description of its associated `saddle-to-saddle' dynamics. Notably, the timescales associated with each saddle can be explicitly characterized in terms of an appropriate Hermite decomposition of the target link function. In contrast with these pos
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#28145;&#24230;&#36716;&#25442;&#39640;&#26031;&#36807;&#31243;&#65288;DTGPs&#65289;&#30340;&#36716;&#25442;&#39640;&#26031;&#36807;&#31243;&#65288;TGPs&#65289;&#30340;&#25512;&#24191;&#65292;&#35813;&#27169;&#22411;&#37319;&#29992;&#20018;&#32852;&#23618;&#32423;&#30340;&#38543;&#26426;&#36807;&#31243;&#65292;&#24182;&#23454;&#29616;&#20102;&#30456;&#23545;&#20110;TGPs&#21644;DGPs&#30340;&#28789;&#27963;&#24615;&#22686;&#24378;&#12290;&#36890;&#36807;&#20351;&#29992;&#21464;&#20998;&#25512;&#29702;&#65292;&#21487;&#20197;&#36817;&#20284;&#25152;&#38656;&#30340;&#35745;&#31639;&#65292;&#20174;&#32780;&#24471;&#21040;&#20102;&#31616;&#21333;&#30452;&#25509;&#30340;&#25512;&#29702;&#31639;&#27861;&#25193;&#23637;&#12290;</title><link>http://arxiv.org/abs/2310.18230</link><description>&lt;p&gt;
&#28145;&#24230;&#36716;&#25442;&#39640;&#26031;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Deep Transformed Gaussian Processes. (arXiv:2310.18230v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18230
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#28145;&#24230;&#36716;&#25442;&#39640;&#26031;&#36807;&#31243;&#65288;DTGPs&#65289;&#30340;&#36716;&#25442;&#39640;&#26031;&#36807;&#31243;&#65288;TGPs&#65289;&#30340;&#25512;&#24191;&#65292;&#35813;&#27169;&#22411;&#37319;&#29992;&#20018;&#32852;&#23618;&#32423;&#30340;&#38543;&#26426;&#36807;&#31243;&#65292;&#24182;&#23454;&#29616;&#20102;&#30456;&#23545;&#20110;TGPs&#21644;DGPs&#30340;&#28789;&#27963;&#24615;&#22686;&#24378;&#12290;&#36890;&#36807;&#20351;&#29992;&#21464;&#20998;&#25512;&#29702;&#65292;&#21487;&#20197;&#36817;&#20284;&#25152;&#38656;&#30340;&#35745;&#31639;&#65292;&#20174;&#32780;&#24471;&#21040;&#20102;&#31616;&#21333;&#30452;&#25509;&#30340;&#25512;&#29702;&#31639;&#27861;&#25193;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36716;&#25442;&#39640;&#26031;&#36807;&#31243;&#65288;TGPs&#65289;&#26159;&#36890;&#36807;&#20351;&#29992;&#21487;&#36870;&#36716;&#25442;&#20174;&#20808;&#39564;&#36807;&#31243;&#65288;&#36890;&#24120;&#26159;&#39640;&#26031;&#36807;&#31243;&#65289;&#20013;&#36716;&#25442;&#26679;&#26412;&#26469;&#25351;&#23450;&#30340;&#38543;&#26426;&#36807;&#31243;&#65292;&#20174;&#32780;&#22686;&#21152;&#20102;&#22522;&#26412;&#36807;&#31243;&#30340;&#28789;&#27963;&#24615;&#12290;&#27492;&#22806;&#65292;&#19982;&#36890;&#36807;&#39640;&#26031;&#36807;&#31243;&#30340;&#23618;&#32423;&#20018;&#32852;&#26500;&#36896;&#30340;&#28145;&#24230;&#39640;&#26031;&#36807;&#31243;&#65288;DGPs&#65289;&#30456;&#27604;&#65292;TGPs&#23454;&#29616;&#20102;&#31454;&#20105;&#24615;&#32467;&#26524;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#28145;&#24230;&#36716;&#25442;&#39640;&#26031;&#36807;&#31243;&#65288;DTGPs&#65289;&#30340;TGP&#25512;&#24191;&#65292;&#23427;&#36981;&#24490;&#20018;&#32852;&#38543;&#26426;&#36807;&#31243;&#23618;&#30340;&#36235;&#21183;&#12290;&#26356;&#20934;&#30830;&#22320;&#35828;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#19968;&#20010;&#22810;&#23618;&#27169;&#22411;&#65292;&#20854;&#20013;&#27599;&#19968;&#23618;&#37117;&#26159;&#19968;&#20010;TGP&#12290;&#36825;&#31181;&#25512;&#24191;&#24847;&#21619;&#30528;&#30456;&#23545;&#20110;TGPs&#21644;DGPs&#37117;&#25552;&#39640;&#20102;&#28789;&#27963;&#24615;&#12290;&#22312;&#36825;&#26679;&#30340;&#27169;&#22411;&#20013;&#36827;&#34892;&#31934;&#30830;&#25512;&#29702;&#26159;&#22256;&#38590;&#30340;&#12290;&#20294;&#26159;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21487;&#20197;&#20351;&#29992;&#21464;&#20998;&#25512;&#29702;&#26469;&#36817;&#20284;&#25152;&#38656;&#30340;&#35745;&#31639;&#65292;&#20174;&#32780;&#24471;&#21040;&#20102;&#27969;&#34892;&#30340;DSVI&#25512;&#29702;&#31639;&#27861;&#30340;&#30452;&#25509;&#25193;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transformed Gaussian Processes (TGPs) are stochastic processes specified by transforming samples from the joint distribution from a prior process (typically a GP) using an invertible transformation; increasing the flexibility of the base process.  Furthermore, they achieve competitive results compared with Deep Gaussian Processes (DGPs), which are another generalization constructed by a hierarchical concatenation of GPs. In this work, we propose a generalization of TGPs named Deep Transformed Gaussian Processes (DTGPs), which follows the trend of concatenating layers of stochastic processes. More precisely, we obtain a multi-layer model in which each layer is a TGP. This generalization implies an increment of flexibility with respect to both TGPs and DGPs. Exact inference in such a model is intractable. However, we show that one can use variational inference to approximate the required computations yielding a straightforward extension of the popular DSVI inference algorithm Salimbeni e
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#31070;&#32463;&#25193;&#25955;&#27169;&#22411;&#65288;NDMs&#65289;&#65292;&#23427;&#26159;&#20256;&#32479;&#25193;&#25955;&#27169;&#22411;&#30340;&#25512;&#24191;&#65292;&#21487;&#20197;&#23450;&#20041;&#21644;&#23398;&#20064;&#25968;&#25454;&#30340;&#26102;&#38388;&#20381;&#36182;&#38750;&#32447;&#24615;&#21464;&#25442;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#22312;&#26080;&#38656;&#27169;&#25311;&#30340;&#35774;&#32622;&#20013;&#20351;&#29992;&#21464;&#20998;&#30028;&#23545;NDMs&#36827;&#34892;&#20248;&#21270;&#65292;&#24182;&#36890;&#36807;&#22312;&#26631;&#20934;&#22270;&#20687;&#29983;&#25104;&#20219;&#21153;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#21487;&#23398;&#20064;&#21464;&#25442;&#30340;NDMs&#30340;&#23454;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.08337</link><description>&lt;p&gt;
&#31070;&#32463;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Neural Diffusion Models. (arXiv:2310.08337v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.08337
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#31070;&#32463;&#25193;&#25955;&#27169;&#22411;&#65288;NDMs&#65289;&#65292;&#23427;&#26159;&#20256;&#32479;&#25193;&#25955;&#27169;&#22411;&#30340;&#25512;&#24191;&#65292;&#21487;&#20197;&#23450;&#20041;&#21644;&#23398;&#20064;&#25968;&#25454;&#30340;&#26102;&#38388;&#20381;&#36182;&#38750;&#32447;&#24615;&#21464;&#25442;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#22312;&#26080;&#38656;&#27169;&#25311;&#30340;&#35774;&#32622;&#20013;&#20351;&#29992;&#21464;&#20998;&#30028;&#23545;NDMs&#36827;&#34892;&#20248;&#21270;&#65292;&#24182;&#36890;&#36807;&#22312;&#26631;&#20934;&#22270;&#20687;&#29983;&#25104;&#20219;&#21153;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#21487;&#23398;&#20064;&#21464;&#25442;&#30340;NDMs&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#22312;&#35768;&#22810;&#29983;&#25104;&#20219;&#21153;&#19978;&#34920;&#29616;&#20986;&#33394;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#26368;&#36817;&#21462;&#24471;&#20102;&#19968;&#20123;&#25104;&#21151;&#65292;&#22823;&#22810;&#25968;&#25193;&#25955;&#27169;&#22411;&#21482;&#20801;&#35768;&#23545;&#25968;&#25454;&#20998;&#24067;&#36827;&#34892;&#32447;&#24615;&#36716;&#25442;&#65292;&#21463;&#21040;&#20102;&#19968;&#23450;&#30340;&#38480;&#21046;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#26356;&#24191;&#27867;&#30340;&#21464;&#25442;&#23478;&#26063;&#21487;&#33021;&#26377;&#21161;&#20110;&#26356;&#26377;&#25928;&#22320;&#35757;&#32451;&#29983;&#25104;&#20998;&#24067;&#65292;&#31616;&#21270;&#36870;&#36807;&#31243;&#24182;&#32553;&#23567;&#30495;&#23454;&#36127;&#23545;&#25968;&#20284;&#28982;&#21644;&#21464;&#20998;&#36817;&#20284;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#31070;&#32463;&#25193;&#25955;&#27169;&#22411;&#65288;NDMs&#65289;&#65292;&#23427;&#26159;&#20256;&#32479;&#25193;&#25955;&#27169;&#22411;&#30340;&#25512;&#24191;&#65292;&#21487;&#20197;&#23450;&#20041;&#21644;&#23398;&#20064;&#25968;&#25454;&#30340;&#26102;&#38388;&#20381;&#36182;&#38750;&#32447;&#24615;&#21464;&#25442;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#22312;&#19968;&#20010;&#26080;&#38656;&#27169;&#25311;&#30340;&#35774;&#32622;&#20013;&#20351;&#29992;&#21464;&#20998;&#30028;&#23545;NDMs&#36827;&#34892;&#20248;&#21270;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23548;&#20986;&#20102;NDMs&#30340;&#26102;&#38388;&#36830;&#32493;&#24418;&#24335;&#65292;&#36890;&#36807;&#20351;&#29992;&#29616;&#25104;&#30340;&#25968;&#20540;ODE&#21644;SDE&#27714;&#35299;&#22120;&#65292;&#21487;&#20197;&#24555;&#36895;&#21487;&#38752;&#22320;&#36827;&#34892;&#25512;&#29702;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#22312;&#26631;&#20934;&#22270;&#20687;&#29983;&#25104;&#20219;&#21153;&#19978;&#30340;&#23454;&#39564;&#23637;&#31034;&#20102;&#21487;&#23398;&#20064;&#21464;&#25442;&#30340;NDMs&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models have shown remarkable performance on many generative tasks. Despite recent success, most diffusion models are restricted in that they only allow linear transformation of the data distribution. In contrast, broader family of transformations can potentially help train generative distributions more efficiently, simplifying the reverse process and closing the gap between the true negative log-likelihood and the variational approximation. In this paper, we present Neural Diffusion Models (NDMs), a generalization of conventional diffusion models that enables defining and learning time-dependent non-linear transformations of data. We show how to optimise NDMs using a variational bound in a simulation-free setting. Moreover, we derive a time-continuous formulation of NDMs, which allows fast and reliable inference using off-the-shelf numerical ODE and SDE solvers. Finally, we demonstrate the utility of NDMs with learnable transformations through experiments on standard image ge
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#21442;&#25968;&#21270;&#26041;&#27861;&#65292;&#21033;&#29992;&#27979;&#22320;&#32447;&#21644;&#27969;&#21160;&#26469;&#25551;&#36848;&#21487;&#24494;&#27969;&#24418;&#19978;&#30340;&#36317;&#31163;&#21644;&#38271;&#24230;&#26368;&#23567;&#21270;&#26354;&#32447;&#12290;&#36825;&#20026;&#22312;&#19981;&#21516;iable&#27969;&#24418;&#19978;&#36827;&#34892;&#32479;&#35745;&#21644;&#38477;&#38454;&#24314;&#27169;&#25552;&#20379;&#20102;&#26426;&#20250;&#12290;</title><link>http://arxiv.org/abs/2310.06157</link><description>&lt;p&gt;
&#22522;&#20110;&#27969;&#24418;&#30340;Eikonal&#26041;&#31243;&#65306;&#21487;&#24494;&#27969;&#24418;&#19978;&#30340;&#27979;&#22320;&#36317;&#31163;&#21644;&#27969;&#21160;
&lt;/p&gt;
&lt;p&gt;
Manifold-augmented Eikonal Equations: Geodesic Distances and Flows on Differentiable Manifolds. (arXiv:2310.06157v1 [cs.CG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.06157
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#21442;&#25968;&#21270;&#26041;&#27861;&#65292;&#21033;&#29992;&#27979;&#22320;&#32447;&#21644;&#27969;&#21160;&#26469;&#25551;&#36848;&#21487;&#24494;&#27969;&#24418;&#19978;&#30340;&#36317;&#31163;&#21644;&#38271;&#24230;&#26368;&#23567;&#21270;&#26354;&#32447;&#12290;&#36825;&#20026;&#22312;&#19981;&#21516;iable&#27969;&#24418;&#19978;&#36827;&#34892;&#32479;&#35745;&#21644;&#38477;&#38454;&#24314;&#27169;&#25552;&#20379;&#20102;&#26426;&#20250;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21457;&#29616;&#30340;&#27969;&#24418;&#25552;&#20379;&#20102;&#24213;&#23618;&#25968;&#25454;&#30340;&#32039;&#20945;&#34920;&#31034;&#12290;&#36825;&#20123;&#27969;&#24418;&#19978;&#30340;&#27979;&#22320;&#32447;&#23450;&#20041;&#20102;&#23616;&#37096;&#38271;&#24230;&#26368;&#23567;&#21270;&#26354;&#32447;&#65292;&#24182;&#25552;&#20379;&#20102;&#36317;&#31163;&#30340;&#27010;&#24565;&#65292;&#36825;&#23545;&#20110;&#38477;&#38454;&#24314;&#27169;&#12289;&#32479;&#35745;&#25512;&#26029;&#21644;&#25554;&#20540;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#21442;&#25968;&#21270;&#26041;&#27861;&#26469;&#34920;&#31034;&#27969;&#24418;&#19978;&#30340;&#36317;&#31163;&#22330;&#21644;&#27979;&#22320;&#27969;&#21160;&#65292;&#21033;&#29992;&#25193;&#23637;&#30340;Eikonal&#26041;&#31243;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#27969;&#24418;&#30340;&#20960;&#20309;&#29305;&#24615;&#22914;&#20309;&#24433;&#21709;&#36317;&#31163;&#22330;&#65292;&#24182;&#21033;&#29992;&#27979;&#22320;&#27969;&#21160;&#30452;&#25509;&#33719;&#24471;&#20840;&#23616;&#38271;&#24230;&#26368;&#23567;&#21270;&#26354;&#32447;&#12290;&#36825;&#39033;&#24037;&#20316;&#20026;&#22312;&#21487;&#24494;&#27969;&#24418;&#19978;&#36827;&#34892;&#32479;&#35745;&#21644;&#38477;&#38454;&#24314;&#27169;&#25552;&#20379;&#20102;&#26426;&#20250;&#12290;
&lt;/p&gt;
&lt;p&gt;
Manifolds discovered by machine learning models provide a compact representation of the underlying data. Geodesics on these manifolds define locally length-minimising curves and provide a notion of distance, which are key for reduced-order modelling, statistical inference, and interpolation. In this work, we propose a model-based parameterisation for distance fields and geodesic flows on manifolds, exploiting solutions of a manifold-augmented Eikonal equation. We demonstrate how the geometry of the manifold impacts the distance field, and exploit the geodesic flow to obtain globally length-minimising curves directly. This work opens opportunities for statistics and reduced-order modelling on differentiable manifolds.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#31867;&#20284;&#26679;&#26412;&#32858;&#31867;&#8221;&#30340;&#25216;&#26415;&#65292;&#36890;&#36807;&#26367;&#25442;&#20010;&#20307;&#30340;&#25935;&#24863;&#29305;&#24449;&#20026;&#32858;&#31867;&#30340;&#24179;&#22343;&#20540;&#26469;&#22686;&#24378;&#38544;&#31169;&#12290;&#36890;&#36807;&#23545;&#20351;&#29992;&#21311;&#21517;&#32858;&#31867;&#20013;&#24515;&#35757;&#32451;&#27169;&#22411;&#30340;&#31934;&#30830;&#20998;&#26512;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#19981;&#21516;&#27169;&#22411;&#32452;&#25104;&#37096;&#20998;&#23545;&#27867;&#21270;&#35823;&#24046;&#30340;&#24433;&#21709;&#65292;&#24182;&#35777;&#26126;&#22312;&#26576;&#20123;&#39640;&#32500;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#21311;&#21517;&#32858;&#31867;&#20013;&#24515;&#36827;&#34892;&#35757;&#32451;&#21487;&#20197;&#21462;&#24471;&#26356;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.04015</link><description>&lt;p&gt;
&#36890;&#36807;&#31867;&#20284;&#26679;&#26412;&#32858;&#31867;&#23398;&#20064;&#65306;&#23545;&#27169;&#22411;&#27867;&#21270;&#30340;&#31934;&#30830;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Learning via Look-Alike Clustering: A Precise Analysis of Model Generalization. (arXiv:2310.04015v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.04015
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#31867;&#20284;&#26679;&#26412;&#32858;&#31867;&#8221;&#30340;&#25216;&#26415;&#65292;&#36890;&#36807;&#26367;&#25442;&#20010;&#20307;&#30340;&#25935;&#24863;&#29305;&#24449;&#20026;&#32858;&#31867;&#30340;&#24179;&#22343;&#20540;&#26469;&#22686;&#24378;&#38544;&#31169;&#12290;&#36890;&#36807;&#23545;&#20351;&#29992;&#21311;&#21517;&#32858;&#31867;&#20013;&#24515;&#35757;&#32451;&#27169;&#22411;&#30340;&#31934;&#30830;&#20998;&#26512;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#19981;&#21516;&#27169;&#22411;&#32452;&#25104;&#37096;&#20998;&#23545;&#27867;&#21270;&#35823;&#24046;&#30340;&#24433;&#21709;&#65292;&#24182;&#35777;&#26126;&#22312;&#26576;&#20123;&#39640;&#32500;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#21311;&#21517;&#32858;&#31867;&#20013;&#24515;&#36827;&#34892;&#35757;&#32451;&#21487;&#20197;&#21462;&#24471;&#26356;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#20010;&#24615;&#21270;&#25512;&#33616;&#31995;&#32479;&#21464;&#24471;&#36234;&#26469;&#36234;&#27969;&#34892;&#65292;&#20294;&#30830;&#20445;&#29992;&#25143;&#25968;&#25454;&#30340;&#20445;&#25252;&#20173;&#28982;&#26159;&#36825;&#20123;&#23398;&#20064;&#31995;&#32479;&#24320;&#21457;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#20851;&#27880;&#28857;&#12290;&#22686;&#24378;&#38544;&#31169;&#30340;&#24120;&#35265;&#26041;&#27861;&#26159;&#20351;&#29992;&#21311;&#21517;&#25968;&#25454;&#32780;&#19981;&#26159;&#20010;&#20307;&#25968;&#25454;&#26469;&#35757;&#32451;&#27169;&#22411;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#31867;&#20284;&#26679;&#26412;&#32858;&#31867;&#8221;&#30340;&#33258;&#28982;&#25216;&#26415;&#65292;&#23427;&#28041;&#21450;&#23558;&#20010;&#20307;&#30340;&#25935;&#24863;&#29305;&#24449;&#26367;&#25442;&#20026;&#32858;&#31867;&#30340;&#24179;&#22343;&#20540;&#12290;&#25105;&#20204;&#23545;&#20351;&#29992;&#21311;&#21517;&#32858;&#31867;&#20013;&#24515;&#35757;&#32451;&#27169;&#22411;&#22914;&#20309;&#24433;&#21709;&#20854;&#27867;&#21270;&#33021;&#21147;&#36827;&#34892;&#20102;&#31934;&#30830;&#30340;&#20998;&#26512;&#12290;&#25105;&#20204;&#20851;&#27880;&#19968;&#20010;&#28176;&#36817;&#24773;&#20917;&#65292;&#21363;&#35757;&#32451;&#38598;&#30340;&#22823;&#23567;&#19982;&#29305;&#24449;&#32500;&#24230;&#25104;&#27604;&#20363;&#22686;&#38271;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#22522;&#20110;&#20984;&#39640;&#26031;&#26497;&#23567;&#21270;&#26497;&#22823;&#23450;&#29702;&#65288;Convex Gaussian Minimax Theorem&#65292;CGMT&#65289;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#22312;&#29702;&#35770;&#19978;&#29702;&#35299;&#19981;&#21516;&#27169;&#22411;&#32452;&#25104;&#37096;&#20998;&#23545;&#27867;&#21270;&#35823;&#24046;&#30340;&#20316;&#29992;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#26576;&#20123;&#39640;&#32500;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#21311;&#21517;&#32858;&#31867;&#20013;&#24515;&#36827;&#34892;&#35757;&#32451;&#33021;&#22815;&#21462;&#24471;&#26356;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
While personalized recommendations systems have become increasingly popular, ensuring user data protection remains a paramount concern in the development of these learning systems. A common approach to enhancing privacy involves training models using anonymous data rather than individual data. In this paper, we explore a natural technique called \emph{look-alike clustering}, which involves replacing sensitive features of individuals with the cluster's average values. We provide a precise analysis of how training models using anonymous cluster centers affects their generalization capabilities. We focus on an asymptotic regime where the size of the training set grows in proportion to the features dimension. Our analysis is based on the Convex Gaussian Minimax Theorem (CGMT) and allows us to theoretically understand the role of different model components on the generalization error. In addition, we demonstrate that in certain high-dimensional regimes, training over anonymous cluster cente
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#35780;&#20272;&#20102;&#22522;&#20110;&#35780;&#20998;&#30340;&#25968;&#25454;&#21516;&#21270;&#26041;&#27861;&#22312;&#39640;&#32500;&#24230;&#30340;&#22320;&#29699;&#29289;&#29702;&#21160;&#21147;&#31995;&#32479;&#20013;&#30340;&#21487;&#25193;&#23637;&#24615;&#65292;&#24182;&#36890;&#36807;&#22312;&#21452;&#23618;&#25311;&#22320;&#36716;&#21160;&#27169;&#22411;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#33391;&#22909;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.01853</link><description>&lt;p&gt;
&#22522;&#20110;&#35780;&#20998;&#30340;&#25968;&#25454;&#21516;&#21270;&#22312;&#21452;&#23618;&#25311;&#22320;&#36716;&#21160;&#27169;&#22411;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Score-based Data Assimilation for a Two-Layer Quasi-Geostrophic Model. (arXiv:2310.01853v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01853
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#35780;&#20272;&#20102;&#22522;&#20110;&#35780;&#20998;&#30340;&#25968;&#25454;&#21516;&#21270;&#26041;&#27861;&#22312;&#39640;&#32500;&#24230;&#30340;&#22320;&#29699;&#29289;&#29702;&#21160;&#21147;&#31995;&#32479;&#20013;&#30340;&#21487;&#25193;&#23637;&#24615;&#65292;&#24182;&#36890;&#36807;&#22312;&#21452;&#23618;&#25311;&#22320;&#36716;&#21160;&#27169;&#22411;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#33391;&#22909;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#21516;&#21270;&#35299;&#20915;&#20102;&#22312;&#32473;&#23450;&#22024;&#26434;&#25110;&#19981;&#23436;&#25972;&#35266;&#27979;&#24773;&#20917;&#19979;&#65292;&#30830;&#23450;&#21160;&#21147;&#31995;&#32479;&#21487;&#34892;&#29366;&#24577;&#36712;&#36857;&#30340;&#38382;&#39064;&#12290;&#22312;&#22320;&#29699;&#31185;&#23398;&#20013;&#65292;&#30001;&#20110;&#22320;&#29699;&#29289;&#29702;&#21160;&#21147;&#31995;&#32479;&#30340;&#39640;&#32500;&#24230;&#24615;&#65292;&#24448;&#24448;&#36229;&#36807;&#20102;&#25968;&#30334;&#19975;&#32500;&#24230;&#65292;&#22240;&#27492;&#23384;&#22312;&#25361;&#25112;&#12290;&#26412;&#25991;&#35780;&#20272;&#20102;&#22522;&#20110;&#35780;&#20998;&#30340;&#25968;&#25454;&#21516;&#21270;&#65288;SDA&#65289;&#36825;&#19968;&#26032;&#39062;&#30340;&#25968;&#25454;&#21516;&#21270;&#26041;&#27861;&#22312;&#27492;&#31867;&#31995;&#32479;&#20013;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#38024;&#23545;&#35780;&#20998;&#32593;&#32476;&#26550;&#26500;&#30340;&#20462;&#25913;&#65292;&#26088;&#22312;&#26174;&#33879;&#20943;&#23569;&#20869;&#23384;&#28040;&#32791;&#21644;&#25191;&#34892;&#26102;&#38388;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#21452;&#23618;&#25311;&#22320;&#36716;&#21160;&#27169;&#22411;&#20013;&#23637;&#31034;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data assimilation addresses the problem of identifying plausible state trajectories of dynamical systems given noisy or incomplete observations. In geosciences, it presents challenges due to the high-dimensionality of geophysical dynamical systems, often exceeding millions of dimensions. This work assesses the scalability of score-based data assimilation (SDA), a novel data assimilation method, in the context of such systems. We propose modifications to the score network architecture aimed at significantly reducing memory consumption and execution time. We demonstrate promising results for a two-layer quasi-geostrophic model.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#31216;&#20026;&#20108;&#20803;&#24378;&#21270;&#23398;&#20064;&#30340;&#22312;&#32447;&#31639;&#27861;&#65292;&#29992;&#20110;&#26681;&#25454;&#19978;&#19979;&#25991;&#22240;&#32032;&#21644;&#30446;&#26631;&#20154;&#19982;&#20854;&#29031;&#39038;&#20276;&#20387;&#30340;&#36807;&#21435;&#21453;&#39304;&#65292;&#20010;&#24615;&#21270;&#22320;&#25552;&#20379;&#24178;&#39044;&#25514;&#26045;&#12290;&#35813;&#31639;&#27861;&#26159;&#36125;&#21494;&#26031;&#21644;&#23618;&#27425;&#30340;&#65292;&#24182;&#36890;&#36807;&#27169;&#25311;&#23637;&#31034;&#20102;&#33391;&#22909;&#30340;&#23454;&#35777;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2308.07843</link><description>&lt;p&gt;
Dyadic Reinforcement Learning. (arXiv:2308.07843v1 [cs.LG]) &#35813;&#35770;&#25991;&#26631;&#39064;&#24050;&#32763;&#35793;&#65306;&#20108;&#20803;&#24378;&#21270;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dyadic Reinforcement Learning. (arXiv:2308.07843v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07843
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#31216;&#20026;&#20108;&#20803;&#24378;&#21270;&#23398;&#20064;&#30340;&#22312;&#32447;&#31639;&#27861;&#65292;&#29992;&#20110;&#26681;&#25454;&#19978;&#19979;&#25991;&#22240;&#32032;&#21644;&#30446;&#26631;&#20154;&#19982;&#20854;&#29031;&#39038;&#20276;&#20387;&#30340;&#36807;&#21435;&#21453;&#39304;&#65292;&#20010;&#24615;&#21270;&#22320;&#25552;&#20379;&#24178;&#39044;&#25514;&#26045;&#12290;&#35813;&#31639;&#27861;&#26159;&#36125;&#21494;&#26031;&#21644;&#23618;&#27425;&#30340;&#65292;&#24182;&#36890;&#36807;&#27169;&#25311;&#23637;&#31034;&#20102;&#33391;&#22909;&#30340;&#23454;&#35777;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31227;&#21160;&#21307;&#30103;&#26088;&#22312;&#36890;&#36807;&#22312;&#20010;&#20154;&#26085;&#24120;&#29983;&#27963;&#20013;&#25552;&#20379;&#24178;&#39044;&#26469;&#25552;&#39640;&#20581;&#24247;&#32467;&#26524;&#12290;&#29031;&#39038;&#20276;&#20387;&#21644;&#31038;&#20250;&#25903;&#25345;&#32593;&#32476;&#30340;&#21442;&#19982;&#32463;&#24120;&#22312;&#24110;&#21161;&#20010;&#20154;&#31649;&#29702;&#32321;&#37325;&#30340;&#21307;&#30103;&#26465;&#20214;&#26041;&#38754;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#36825;&#20026;&#31227;&#21160;&#21307;&#30103;&#25552;&#20379;&#20102;&#26426;&#20250;&#65292;&#35774;&#35745;&#38024;&#23545;&#20108;&#20803;&#20851;&#31995;&#8212;&#8212;&#30446;&#26631;&#20154;&#21644;&#20854;&#29031;&#39038;&#20276;&#20387;&#20043;&#38388;&#20851;&#31995;&#8212;&#8212;&#20197;&#25552;&#39640;&#31038;&#20250;&#25903;&#25345;&#30340;&#24178;&#39044;&#25514;&#26045;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#20108;&#20803;&#24378;&#21270;&#23398;&#20064;&#65288;Dyadic RL&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#22522;&#20110;&#29615;&#22659;&#22240;&#32032;&#21644;&#30446;&#26631;&#20154;&#21450;&#20854;&#29031;&#39038;&#20276;&#20387;&#30340;&#36807;&#21435;&#21453;&#39304;&#20010;&#24615;&#21270;&#24178;&#39044;&#25514;&#26045;&#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#12290;&#22312;&#36825;&#37324;&#65292;&#22810;&#32452;&#24178;&#39044;&#25514;&#26045;&#24433;&#21709;&#30528;&#20108;&#20803;&#20851;&#31995;&#22312;&#22810;&#20010;&#26102;&#38388;&#38388;&#38548;&#20869;&#12290;&#24320;&#21457;&#30340;&#20108;&#20803;&#24378;&#21270;&#23398;&#20064;&#26159;&#36125;&#21494;&#26031;&#21644;&#23618;&#27425;&#30340;&#12290;&#25105;&#20204;&#27491;&#24335;&#20171;&#32461;&#20102;&#38382;&#39064;&#35774;&#23450;&#65292;&#24320;&#21457;&#20102;&#20108;&#20803;&#24378;&#21270;&#23398;&#20064;&#24182;&#30830;&#23450;&#20102;&#36951;&#25022;&#36793;&#30028;&#12290;&#36890;&#36807;&#27169;&#25311;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20108;&#20803;&#24378;&#21270;&#23398;&#20064;&#30340;&#23454;&#35777;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Mobile health aims to enhance health outcomes by delivering interventions to individuals as they go about their daily life. The involvement of care partners and social support networks often proves crucial in helping individuals managing burdensome medical conditions. This presents opportunities in mobile health to design interventions that target the dyadic relationship -- the relationship between a target person and their care partner -- with the aim of enhancing social support. In this paper, we develop dyadic RL, an online reinforcement learning algorithm designed to personalize intervention delivery based on contextual factors and past responses of a target person and their care partner. Here, multiple sets of interventions impact the dyad across multiple time intervals. The developed dyadic RL is Bayesian and hierarchical. We formally introduce the problem setup, develop dyadic RL and establish a regret bound. We demonstrate dyadic RL's empirical performance through simulation st
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#35299;&#20915;&#20102;&#34920;&#31034;&#23398;&#20064;&#20013;&#30340;&#28508;&#21464;&#37327;&#35782;&#21035;&#21644;"&#25903;&#25345;&#22806;"&#22270;&#20687;&#29983;&#25104;&#38382;&#39064;&#65292;&#23637;&#31034;&#20102;&#21152;&#27861;&#35299;&#30721;&#22120;&#33021;&#22815;&#23545;&#28508;&#21464;&#37327;&#36827;&#34892;&#35782;&#21035;&#65292;&#24182;&#25552;&#20379;&#20102;&#29702;&#35770;&#20381;&#25454;&#25903;&#25345;&#36825;&#31181;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.02598</link><description>&lt;p&gt;
&#28155;&#21152;&#35299;&#30721;&#22120;&#29992;&#20110;&#28508;&#21464;&#37327;&#35782;&#21035;&#21644;&#31515;&#21345;&#23572;&#31215;&#25512;&#31639;
&lt;/p&gt;
&lt;p&gt;
Additive Decoders for Latent Variables Identification and Cartesian-Product Extrapolation. (arXiv:2307.02598v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02598
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#35299;&#20915;&#20102;&#34920;&#31034;&#23398;&#20064;&#20013;&#30340;&#28508;&#21464;&#37327;&#35782;&#21035;&#21644;"&#25903;&#25345;&#22806;"&#22270;&#20687;&#29983;&#25104;&#38382;&#39064;&#65292;&#23637;&#31034;&#20102;&#21152;&#27861;&#35299;&#30721;&#22120;&#33021;&#22815;&#23545;&#28508;&#21464;&#37327;&#36827;&#34892;&#35782;&#21035;&#65292;&#24182;&#25552;&#20379;&#20102;&#29702;&#35770;&#20381;&#25454;&#25903;&#25345;&#36825;&#31181;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35299;&#20915;&#20102;&#34920;&#31034;&#23398;&#20064;&#20013;&#30340;&#28508;&#21464;&#37327;&#35782;&#21035;&#21644;&#8220;&#25903;&#25345;&#22806;&#8221;&#22270;&#20687;&#29983;&#25104;&#38382;&#39064;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#19968;&#31867;&#25105;&#20204;&#31216;&#20026;&#8220;&#21152;&#27861;&#8221;&#30340;&#35299;&#30721;&#22120;&#20013;&#65292;&#36825;&#20004;&#32773;&#26159;&#21487;&#33021;&#30340;&#65292;&#36825;&#20123;&#35299;&#30721;&#22120;&#31867;&#20284;&#20110;&#29992;&#20110;&#38754;&#21521;&#23545;&#35937;&#34920;&#31034;&#23398;&#20064;&#65288;OCRL&#65289;&#30340;&#35299;&#30721;&#22120;&#65292;&#24182;&#19988;&#38750;&#24120;&#36866;&#29992;&#20110;&#21487;&#20197;&#20998;&#35299;&#20026;&#22810;&#20010;&#29305;&#23450;&#23545;&#35937;&#22270;&#20687;&#30340;&#22270;&#20687;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#22312;&#20351;&#29992;&#21152;&#27861;&#35299;&#30721;&#22120;&#23436;&#20840;&#35299;&#20915;&#37325;&#26500;&#38382;&#39064;&#26102;&#65292;&#23545;&#28508;&#21464;&#37327;&#22359;&#36827;&#34892;&#20102;&#32622;&#25442;&#21644;&#22359;&#29366;&#36870;&#21464;&#25442;&#30340;&#35782;&#21035;&#30340;&#26465;&#20214;&#12290;&#36825;&#20010;&#20445;&#35777;&#20165;&#22522;&#20110;&#20851;&#20110;&#28508;&#22240;&#23376;&#20998;&#24067;&#30340;&#38750;&#24120;&#24369;&#30340;&#20551;&#35774;&#65292;&#28508;&#22240;&#23376;&#21487;&#33021;&#23384;&#22312;&#32479;&#35745;&#20381;&#36182;&#24182;&#19988;&#20855;&#26377;&#20960;&#20046;&#20219;&#24847;&#24418;&#29366;&#30340;&#25903;&#25345;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25552;&#20379;&#20102;&#38750;&#32447;&#24615;&#29420;&#31435;&#25104;&#20998;&#20998;&#26512;&#65288;ICA&#65289;&#21487;&#33021;&#24615;&#30340;&#26032;&#35774;&#32622;&#65292;&#24182;&#19988;&#22686;&#21152;&#20102;&#25105;&#20204;&#23545;OCRL&#26041;&#27861;&#30340;&#29702;&#35770;&#29702;&#35299;&#12290;&#25105;&#20204;&#36824;&#20174;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#21152;&#27861;&#35299;&#30721;&#22120;&#21487;&#20197;
&lt;/p&gt;
&lt;p&gt;
We tackle the problems of latent variables identification and "out-of-support" image generation in representation learning. We show that both are possible for a class of decoders that we call additive, which are reminiscent of decoders used for object-centric representation learning (OCRL) and well suited for images that can be decomposed as a sum of object-specific images. We provide conditions under which exactly solving the reconstruction problem using an additive decoder is guaranteed to identify the blocks of latent variables up to permutation and block-wise invertible transformations. This guarantee relies only on very weak assumptions about the distribution of the latent factors, which might present statistical dependencies and have an almost arbitrarily shaped support. Our result provides a new setting where nonlinear independent component analysis (ICA) is possible and adds to our theoretical understanding of OCRL methods. We also show theoretically that additive decoders can 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#21452;&#22240;&#26524;&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;&#30340;&#25311;&#21512;&#20540;&#36845;&#20195;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#20445;&#35777;&#31934;&#24230;&#30340;&#21516;&#26102;&#20855;&#26377;&#33391;&#22909;&#30340;&#21487;&#25193;&#23637;&#24615;&#65292;&#25968;&#20540;&#23454;&#39564;&#32467;&#26524;&#20063;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.12658</link><description>&lt;p&gt;
&#25311;&#21512;&#20540;&#36845;&#20195;&#26041;&#27861;&#27714;&#35299;&#36866;&#24212;&#32467;&#26500;&#21452;&#22240;&#26524;&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Fitted Value Iteration Methods for Bicausal Optimal Transport. (arXiv:2306.12658v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12658
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#21452;&#22240;&#26524;&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;&#30340;&#25311;&#21512;&#20540;&#36845;&#20195;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#20445;&#35777;&#31934;&#24230;&#30340;&#21516;&#26102;&#20855;&#26377;&#33391;&#22909;&#30340;&#21487;&#25193;&#23637;&#24615;&#65292;&#25968;&#20540;&#23454;&#39564;&#32467;&#26524;&#20063;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#25311;&#21512;&#20540;&#36845;&#20195;&#26041;&#27861;(FVI)&#29992;&#20110;&#35745;&#31639;&#20855;&#26377;&#36866;&#24212;&#32467;&#26500;&#30340;&#21452;&#22240;&#26524;&#26368;&#20248;&#20256;&#36755;(OT)&#12290;&#22522;&#20110;&#21160;&#24577;&#35268;&#21010;&#30340;&#24418;&#24335;&#21270;&#34920;&#36848;&#65292;FVI&#37319;&#29992;&#20989;&#25968;&#31867;&#29992;&#20110;&#36817;&#20284;&#21452;&#22240;&#26524;OT&#20013;&#30340;&#20540;&#20989;&#25968;&#12290;&#22312;&#21487;&#38598;&#20013;&#26465;&#20214;&#21644;&#36817;&#20284;&#23436;&#22791;&#24615;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#20351;&#29992;&#65288;&#23616;&#37096;&#65289;Rademacher&#22797;&#26434;&#24230;&#35777;&#26126;&#20102;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#28145;&#24230;&#22810;&#23618;&#31070;&#32463;&#32593;&#32476;&#20855;&#26377;&#36866;&#24403;&#32467;&#26500;&#65292;&#28385;&#36275;&#26679;&#26412;&#22797;&#26434;&#24230;&#35777;&#26126;&#25152;&#38656;&#30340;&#20851;&#38190;&#20551;&#35774;&#26465;&#20214;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;FVI&#22312;&#26102;&#38388;&#36328;&#24230;&#22686;&#21152;&#26102;&#20248;&#20110;&#32447;&#24615;&#35268;&#21010;&#21644;&#36866;&#24212;&#24615;Sinkhorn&#26041;&#27861;&#65292;&#22312;&#20445;&#25345;&#21487;&#25509;&#21463;&#31934;&#24230;&#30340;&#21516;&#26102;&#20855;&#26377;&#24456;&#22909;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a fitted value iteration (FVI) method to compute bicausal optimal transport (OT) where couplings have an adapted structure. Based on the dynamic programming formulation, FVI adopts a function class to approximate the value functions in bicausal OT. Under the concentrability condition and approximate completeness assumption, we prove the sample complexity using (local) Rademacher complexity. Furthermore, we demonstrate that multilayer neural networks with appropriate structures satisfy the crucial assumptions required in sample complexity proofs. Numerical experiments reveal that FVI outperforms linear programming and adapted Sinkhorn methods in scalability as the time horizon increases, while still maintaining acceptable accuracy.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#25311;&#30340;&#21487;&#22788;&#29702;&#21644;&#19981;&#21487;&#22788;&#29702;&#20284;&#28982;&#20989;&#25968;&#30340;&#39057;&#29575;&#27966;&#25512;&#26029;&#26041;&#27861;&#65292;&#24182;&#22312;&#23431;&#23449;&#23398;&#12289;&#39640;&#33021;&#29289;&#29702;&#12289;&#22825;&#25991;&#23398;&#21644;&#27969;&#34892;&#30149;&#23398;&#39046;&#22495;&#36827;&#34892;&#20102;&#28436;&#31034;&#12290;</title><link>http://arxiv.org/abs/2306.07769</link><description>&lt;p&gt;
&#22522;&#20110;&#27169;&#25311;&#30340;&#21487;&#22788;&#29702;&#21644;&#19981;&#21487;&#22788;&#29702;&#20284;&#28982;&#20989;&#25968;&#30340;&#39057;&#29575;&#27966;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Simulation-Based Frequentist Inference with Tractable and Intractable Likelihoods. (arXiv:2306.07769v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.07769
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#27169;&#25311;&#30340;&#21487;&#22788;&#29702;&#21644;&#19981;&#21487;&#22788;&#29702;&#20284;&#28982;&#20989;&#25968;&#30340;&#39057;&#29575;&#27966;&#25512;&#26029;&#26041;&#27861;&#65292;&#24182;&#22312;&#23431;&#23449;&#23398;&#12289;&#39640;&#33021;&#29289;&#29702;&#12289;&#22825;&#25991;&#23398;&#21644;&#27969;&#34892;&#30149;&#23398;&#39046;&#22495;&#36827;&#34892;&#20102;&#28436;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#31185;&#23398;&#39046;&#22495;&#20013;&#65292;&#36830;&#25509;&#29702;&#35770;&#27169;&#22411;&#21644;&#35266;&#23519;&#32467;&#26524;&#30340;&#39640;&#20445;&#30495;&#24230;&#27169;&#25311;&#22120;&#26159;&#19981;&#21487;&#25110;&#32570;&#30340;&#24037;&#20855;&#12290;&#24403;&#19982;&#26426;&#22120;&#23398;&#20064;&#30456;&#32467;&#21512;&#26102;&#65292;&#27169;&#25311;&#22120;&#20351;&#24471;&#30452;&#25509;&#20174;&#30495;&#23454;&#21644;&#27169;&#25311;&#35266;&#23519;&#32467;&#26524;&#20013;&#25512;&#26029;&#29702;&#35770;&#27169;&#22411;&#30340;&#21442;&#25968;&#25104;&#20026;&#21487;&#33021;&#65292;&#32780;&#19981;&#38656;&#35201;&#26126;&#30830;&#20351;&#29992;&#20284;&#28982;&#20989;&#25968;&#65292;&#29305;&#21035;&#26159;&#22312;&#20284;&#28982;&#20989;&#25968;&#19981;&#21487;&#22788;&#29702;&#30340;&#24773;&#20917;&#19979;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#26368;&#36817;&#25552;&#20986;&#30340;&#26080;&#20284;&#28982;&#39057;&#29575;&#23398;&#25512;&#26029;&#65288;LF2I&#65289;&#26041;&#27861;&#30340;&#19968;&#20010;&#31616;&#21333;&#20462;&#25913;&#65292;&#36825;&#20010;&#20462;&#25913;&#20855;&#26377;&#19968;&#20123;&#35745;&#31639;&#19978;&#30340;&#20248;&#21183;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#35813;&#31639;&#27861;&#24212;&#29992;&#20110;&#19977;&#20010;&#25945;&#23398;&#19978;&#26377;&#36259;&#30340;&#20363;&#23376;&#26469;&#35828;&#26126;&#20854;&#23454;&#29992;&#24615;&#65306;&#31532;&#19968;&#20010;&#20363;&#23376;&#26469;&#33258;&#23431;&#23449;&#23398;&#65292;&#31532;&#20108;&#20010;&#20363;&#23376;&#26469;&#33258;&#39640;&#33021;&#29289;&#29702;&#21644;&#22825;&#25991;&#23398;&#65292;&#20004;&#32773;&#37117;&#20855;&#26377;&#21487;&#22788;&#29702;&#30340;&#20284;&#28982;&#20989;&#25968;&#65292;&#32780;&#31532;&#19977;&#20010;&#20855;&#26377;&#19981;&#21487;&#22788;&#29702;&#30340;&#20284;&#28982;&#20989;&#25968;&#65292;&#26469;&#33258;&#20110;&#27969;&#34892;&#30149;&#23398;&#12290;
&lt;/p&gt;
&lt;p&gt;
High-fidelity simulators that connect theoretical models with observations are indispensable tools in many sciences. When coupled with machine learning, a simulator makes it possible to infer the parameters of a theoretical model directly from real and simulated observations without explicit use of the likelihood function. This is of particular interest when the latter is intractable. We introduce a simple modification of the recently proposed likelihood-free frequentist inference (LF2I) approach that has some computational advantages. The utility of our algorithm is illustrated by applying it to three pedagogically interesting examples: the first is from cosmology, the second from high-energy physics and astronomy, both with tractable likelihoods, while the third, with an intractable likelihood, is from epidemiology.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#36125;&#21494;&#26031;&#26412;&#22320;&#20248;&#21270;&#31574;&#30053;&#30340;&#34892;&#20026;&#21644;&#25910;&#25947;&#24615;&#65292;&#24182;&#22312;&#39640;&#32500;&#38382;&#39064;&#19978;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#23454;&#35777;&#24615;&#33021;&#12290;&#32479;&#35745;&#25968;&#25454;&#34920;&#26126;&#65292;&#21333;&#20010;&#39640;&#26031;&#36807;&#31243;&#26679;&#26412;&#36335;&#24452;&#30340;&#26412;&#22320;&#35299;&#27604;&#20840;&#23616;&#26041;&#27861;&#24674;&#22797;&#30340;&#39044;&#26399;&#20540;&#26356;&#22909;&#12290;M&#252;ller&#31561;&#20154;&#25552;&#20986;&#30340;&#36125;&#21494;&#26031;&#26412;&#22320;&#20248;&#21270;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#29575;&#22312;&#26377;&#22122;&#38899;&#21644;&#26080;&#22122;&#38899;&#30340;&#24773;&#20917;&#19979;&#37117;&#26377;&#25512;&#23548;&#12290;</title><link>http://arxiv.org/abs/2305.15572</link><description>&lt;p&gt;
&#26412;&#22320;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#34892;&#20026;&#21644;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
The Behavior and Convergence of Local Bayesian Optimization. (arXiv:2305.15572v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15572
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#36125;&#21494;&#26031;&#26412;&#22320;&#20248;&#21270;&#31574;&#30053;&#30340;&#34892;&#20026;&#21644;&#25910;&#25947;&#24615;&#65292;&#24182;&#22312;&#39640;&#32500;&#38382;&#39064;&#19978;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#23454;&#35777;&#24615;&#33021;&#12290;&#32479;&#35745;&#25968;&#25454;&#34920;&#26126;&#65292;&#21333;&#20010;&#39640;&#26031;&#36807;&#31243;&#26679;&#26412;&#36335;&#24452;&#30340;&#26412;&#22320;&#35299;&#27604;&#20840;&#23616;&#26041;&#27861;&#24674;&#22797;&#30340;&#39044;&#26399;&#20540;&#26356;&#22909;&#12290;M&#252;ller&#31561;&#20154;&#25552;&#20986;&#30340;&#36125;&#21494;&#26031;&#26412;&#22320;&#20248;&#21270;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#29575;&#22312;&#26377;&#22122;&#38899;&#21644;&#26080;&#22122;&#38899;&#30340;&#24773;&#20917;&#19979;&#37117;&#26377;&#25512;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#19968;&#39033;&#26368;&#26032;&#30340;&#21457;&#23637;&#26159;&#20351;&#29992;&#26412;&#22320;&#20248;&#21270;&#31574;&#30053;&#65292;&#19982;&#20256;&#32479;&#30340;&#20840;&#23616;&#31574;&#30053;&#30456;&#27604;&#65292;&#21487;&#20197;&#22312;&#39640;&#32500;&#38382;&#39064;&#19978;&#25552;&#20379;&#24378;&#22823;&#30340;&#23454;&#35777;&#24615;&#33021;&#12290;&#25991;&#29486;&#20013;&#30340;&#8220;&#20256;&#32479;&#26234;&#24935;&#8221;&#26159;&#65292;&#19987;&#27880;&#20110;&#26412;&#22320;&#20248;&#21270;&#35268;&#36991;&#20102;&#32500;&#24230;&#35781;&#21650;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#36125;&#21494;&#26031;&#26412;&#22320;&#20248;&#21270;&#20363;&#31243;&#30340;&#39044;&#26399;&#34892;&#20026;&#25110;&#25910;&#25947;&#24615;&#20102;&#35299;&#29978;&#23569;&#12290;&#25105;&#20204;&#39318;&#20808;&#30740;&#31350;&#20102;&#26412;&#22320;&#26041;&#27861;&#30340;&#34892;&#20026;&#65292;&#24182;&#21457;&#29616;&#39640;&#26031;&#36807;&#31243;&#26679;&#26412;&#36335;&#24452;&#21333;&#20010;&#26412;&#22320;&#35299;&#30340;&#32479;&#35745;&#25968;&#25454;&#19982;&#20174;&#20840;&#23616;&#26041;&#27861;&#24674;&#22797;&#30340;&#39044;&#26399;&#20540;&#30456;&#27604;&#38750;&#24120;&#22909;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26368;&#36817;&#30001;M&#252;ller&#31561;&#20154;&#25552;&#20986;&#30340;&#22522;&#20110;&#36125;&#21494;&#26031;&#26412;&#22320;&#20248;&#21270;&#31639;&#27861;&#30340;&#31532;&#19968;&#27425;&#20005;&#26684;&#20998;&#26512;&#65292;&#24182;&#22312;&#26377;&#22122;&#38899;&#21644;&#26080;&#22122;&#38899;&#30340;&#24773;&#20917;&#19979;&#25512;&#23548;&#20986;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
A recent development in Bayesian optimization is the use of local optimization strategies, which can deliver strong empirical performance on high-dimensional problems compared to traditional global strategies. The "folk wisdom" in the literature is that the focus on local optimization sidesteps the curse of dimensionality; however, little is known concretely about the expected behavior or convergence of Bayesian local optimization routines. We first study the behavior of the local approach, and find that the statistics of individual local solutions of Gaussian process sample paths are surprisingly good compared to what we would expect to recover from global methods. We then present the first rigorous analysis of such a Bayesian local optimization algorithm recently proposed by M\"uller et al. (2021), and derive convergence rates in both the noisy and noiseless settings.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#25674;&#38144;&#25104;&#26412;&#20272;&#35745;&#26041;&#27861;&#65292;&#33021;&#22815;&#35299;&#20915;&#24191;&#20041;&#36125;&#21494;&#26031;&#25512;&#29702;&#26041;&#27861;&#20013;&#22810;&#20010;&#27169;&#25311;&#30340;&#35745;&#31639;&#38382;&#39064;&#65292;&#20174;&#32780;&#20026;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#25552;&#20379;&#20102;&#19968;&#31181;&#22788;&#29702;&#39640;&#32500;&#24230;&#12289;&#22797;&#26434;&#22797;&#29616;&#65292;&#19988;&#36125;&#21494;&#26031;&#21518;&#39564;&#26410;&#24517;&#26159;&#26368;&#20339;&#26041;&#26696;&#30340;&#31185;&#23398;&#27169;&#25311;&#22120;&#30340;&#20248;&#21270;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.15208</link><description>&lt;p&gt;
&#24191;&#20041;&#36125;&#21494;&#26031;&#25512;&#29702;&#26041;&#27861;&#65306;&#36890;&#36807;&#25674;&#38144;&#25104;&#26412;&#35780;&#20272;&#20026;&#31185;&#23398;&#27169;&#25311;&#22120;&#25552;&#20379;&#36125;&#21494;&#26031;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Generalized Bayesian Inference for Scientific Simulators via Amortized Cost Estimation. (arXiv:2305.15208v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15208
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#25674;&#38144;&#25104;&#26412;&#20272;&#35745;&#26041;&#27861;&#65292;&#33021;&#22815;&#35299;&#20915;&#24191;&#20041;&#36125;&#21494;&#26031;&#25512;&#29702;&#26041;&#27861;&#20013;&#22810;&#20010;&#27169;&#25311;&#30340;&#35745;&#31639;&#38382;&#39064;&#65292;&#20174;&#32780;&#20026;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#25552;&#20379;&#20102;&#19968;&#31181;&#22788;&#29702;&#39640;&#32500;&#24230;&#12289;&#22797;&#26434;&#22797;&#29616;&#65292;&#19988;&#36125;&#21494;&#26031;&#21518;&#39564;&#26410;&#24517;&#26159;&#26368;&#20339;&#26041;&#26696;&#30340;&#31185;&#23398;&#27169;&#25311;&#22120;&#30340;&#20248;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#27169;&#25311;&#30340;&#25512;&#29702;&#26041;&#27861;(SBI)&#36890;&#36807;&#20869;&#21547;&#30340;&#21487;&#33021;&#24615;&#65292;&#20026;&#27169;&#25311;&#22120;&#25552;&#20379;&#25674;&#38144;&#24335;&#30340;&#36125;&#21494;&#26031;&#25512;&#29702;&#12290;&#20294;&#26159;&#24403;&#25105;&#20204;&#20027;&#35201;&#20851;&#27880;&#30340;&#26159;&#39044;&#27979;&#27169;&#25311;&#30340;&#36136;&#37327;&#65292;&#25110;&#32773;&#24403;&#27169;&#22411;&#19981;&#33021;&#23436;&#20840;&#37325;&#29616;&#35266;&#27979;&#25968;&#25454;(&#21363;&#23384;&#22312;&#32570;&#38519;)&#65292;&#20197;&#36125;&#21494;&#26031;&#21518;&#39564;&#20026;&#30446;&#26631;&#23601;&#21487;&#33021;&#36807;&#20110;&#20005;&#26684;&#12290;&#24191;&#20041;&#36125;&#21494;&#26031;&#25512;&#29702;(GBI)&#26088;&#22312;&#21152;&#24378;&#23545;(&#26377;&#32570;&#38519;&#30340;)&#27169;&#25311;&#22120;&#27169;&#22411;&#30340;&#25512;&#29702;&#65292;&#29992;&#35780;&#20272;&#21442;&#25968;&#30456;&#23545;&#20110;&#25968;&#25454;&#30340;&#22909;&#22351;&#30340;&#25104;&#26412;&#20989;&#25968;&#26367;&#25442;&#20284;&#28982;&#20989;&#25968;&#12290;&#28982;&#32780;&#65292;GBI&#26041;&#27861;&#36890;&#24120;&#38656;&#35201;&#36816;&#34892;&#22810;&#20010;&#27169;&#25311;&#65292;&#20197;&#22312;&#25512;&#29702;&#26399;&#38388;&#20272;&#35745;&#27599;&#20010;&#21442;&#25968;&#20540;&#30340;&#25104;&#26412;&#20989;&#25968;&#65292;&#20351;&#24471;&#21363;&#20351;&#22312;&#20013;&#31561;&#22797;&#26434;&#30340;&#27169;&#25311;&#31243;&#24207;&#20013;&#20063;&#38590;&#20197;&#35745;&#31639;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#25674;&#38144;&#25104;&#26412;&#35780;&#20272;(ACE)&#30340;&#24191;&#20041;&#36125;&#21494;&#26031;&#25512;&#29702;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65306;&#25105;&#20204;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#26469;&#36817;&#20284;&#25104;&#26412;&#20989;&#25968;&#65292;&#23558;&#25104;&#26412;&#20989;&#25968;&#23450;&#20041;&#20026;&#30001;&#28508;&#22312;&#21442;&#25968;&#29983;&#25104;&#30340;&#27169;&#25311;&#20043;&#38388;&#30340;&#26399;&#26395;&#36317;&#31163;&#12290;
&lt;/p&gt;
&lt;p&gt;
Simulation-based inference (SBI) enables amortized Bayesian inference for simulators with implicit likelihoods. But when we are primarily interested in the quality of predictive simulations, or when the model cannot exactly reproduce the observed data (i.e., is misspecified), targeting the Bayesian posterior may be overly restrictive. Generalized Bayesian Inference (GBI) aims to robustify inference for (misspecified) simulator models, replacing the likelihood-function with a cost function that evaluates the goodness of parameters relative to data. However, GBI methods generally require running multiple simulations to estimate the cost function at each parameter value during inference, making the approach computationally infeasible for even moderately complex simulators. Here, we propose amortized cost estimation (ACE) for GBI to address this challenge: We train a neural network to approximate the cost function, which we define as the expected distance between simulations produced by a 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#30340;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#32852;&#21512;&#29420;&#31435;&#24615;&#32479;&#35745;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#20197;&#29992;&#20110;&#24179;&#31283;&#21644;&#38750;&#24179;&#31283;&#38543;&#26426;&#36807;&#31243;&#65292;&#36890;&#36807;&#38024;&#23545;&#21333;&#20010;&#21644;&#22810;&#20010;&#23454;&#29616;&#26102;&#38388;&#24207;&#21015;&#30340;&#37325;&#37319;&#26679;&#25216;&#26415;&#65292;&#21487;&#20197;&#31283;&#20581;&#22320;&#21457;&#29616;&#37325;&#35201;&#30340;&#39640;&#38454;&#20381;&#36182;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2305.08529</link><description>&lt;p&gt;
&#22522;&#20110;&#26680;&#30340;&#32852;&#21512;&#29420;&#31435;&#24615;&#26816;&#39564;&#29992;&#20110;&#22810;&#20803;&#12289;&#24179;&#31283;&#21644;&#38750;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;
&lt;/p&gt;
&lt;p&gt;
Kernel-based Joint Independence Tests for Multivariate Stationary and Nonstationary Time-Series. (arXiv:2305.08529v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08529
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#30340;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#32852;&#21512;&#29420;&#31435;&#24615;&#32479;&#35745;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#20197;&#29992;&#20110;&#24179;&#31283;&#21644;&#38750;&#24179;&#31283;&#38543;&#26426;&#36807;&#31243;&#65292;&#36890;&#36807;&#38024;&#23545;&#21333;&#20010;&#21644;&#22810;&#20010;&#23454;&#29616;&#26102;&#38388;&#24207;&#21015;&#30340;&#37325;&#37319;&#26679;&#25216;&#26415;&#65292;&#21487;&#20197;&#31283;&#20581;&#22320;&#21457;&#29616;&#37325;&#35201;&#30340;&#39640;&#38454;&#20381;&#36182;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25429;&#25417;&#30456;&#20114;&#36830;&#25509;&#31995;&#32479;&#30340;&#26102;&#38388;&#28436;&#21464;&#30340;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#22312;&#21508;&#20010;&#39046;&#22495;&#20013;&#26222;&#36941;&#23384;&#22312;&#12290;&#20102;&#35299;&#20849;&#21516;&#35266;&#23519;&#21464;&#37327;&#20043;&#38388;&#30340;&#22797;&#26434;&#20851;&#31995;&#21644;&#28508;&#22312;&#20381;&#36182;&#20851;&#31995;&#26159;&#20934;&#30830;&#32479;&#35745;&#24314;&#27169;&#21644;&#20998;&#26512;&#27492;&#31867;&#31995;&#32479;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#36890;&#36807;&#23558; d &#21464;&#37327; Hilbert-Schmidt &#29420;&#31435;&#24615;&#20934;&#21017;&#65288;dHSIC&#65289;&#25193;&#23637;&#21040;&#21253;&#21547;&#24179;&#31283;&#21644;&#38750;&#24179;&#31283;&#38543;&#26426;&#36807;&#31243;&#65292;&#20174;&#32780;&#20801;&#35768;&#26356;&#24191;&#27867;&#30340;&#23454;&#38469;&#24212;&#29992;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#26680;&#30340;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#32852;&#21512;&#29420;&#31435;&#24615;&#32479;&#35745;&#26816;&#39564;&#12290;&#36890;&#36807;&#21033;&#29992;&#38024;&#23545;&#21333;&#20010;&#21644;&#22810;&#20010;&#23454;&#29616;&#26102;&#38388;&#24207;&#21015;&#37327;&#36523;&#23450;&#21046;&#30340;&#37325;&#37319;&#26679;&#25216;&#26415;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#22914;&#20309;&#22312;&#21512;&#25104;&#31034;&#20363;&#65288;&#21253;&#25324;&#39057;&#29575;&#28151;&#21512;&#25968;&#25454;&#65289;&#20197;&#21450;&#23454;&#38469;&#27668;&#20505;&#21644;&#31038;&#20250;&#32463;&#27982;&#25968;&#25454;&#20013;&#31283;&#20581;&#22320;&#21457;&#29616;&#37325;&#35201;&#30340;&#39640;&#38454;&#20381;&#36182;&#20851;&#31995;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20026;&#20998;&#26512;&#22797;&#26434;&#39640;&#32500;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#22686;&#21152;&#20102;&#25968;&#23398;&#24037;&#20855;&#31665;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multivariate time-series data that capture the temporal evolution of interconnected systems are ubiquitous in diverse areas. Understanding the complex relationships and potential dependencies among co-observed variables is crucial for the accurate statistical modelling and analysis of such systems. Here, we introduce kernel-based statistical tests of joint independence in multivariate time-series by extending the d-variable Hilbert-Schmidt independence criterion (dHSIC) to encompass both stationary and nonstationary random processes, thus allowing broader real-world applications. By leveraging resampling techniques tailored for both single- and multiple-realization time series, we show how the method robustly uncovers significant higher-order dependencies in synthetic examples, including frequency mixing data, as well as real-world climate and socioeconomic data. Our method adds to the mathematical toolbox for the analysis of complex high-dimensional time-series datasets.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29992;&#20110;&#24207;&#21015;&#24314;&#27169;&#30340;&#26500;&#24314;&#22359;&#65292;&#31216;&#20026;MultiresLayer&#65292;&#36890;&#36807;&#22810;&#20998;&#36776;&#29575;&#21367;&#31215;&#25429;&#33719;&#36755;&#20837;&#24207;&#21015;&#20013;&#30340;&#22810;&#23610;&#24230;&#36235;&#21183;&#65292;&#26082;&#20855;&#26377;&#21367;&#31215;&#32593;&#32476;&#30340;&#35745;&#31639;&#20248;&#21183;&#65292;&#21448;&#20855;&#26377;&#23567;&#27874;&#20998;&#35299;&#30340;&#26377;&#29702;&#35770;&#22522;&#30784;&#30340;&#21160;&#26426;&#12290;</title><link>http://arxiv.org/abs/2305.01638</link><description>&lt;p&gt;
&#22810;&#20998;&#36776;&#29575;&#21367;&#31215;&#35760;&#24518;&#30340;&#24207;&#21015;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Sequence Modeling with Multiresolution Convolutional Memory. (arXiv:2305.01638v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.01638
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29992;&#20110;&#24207;&#21015;&#24314;&#27169;&#30340;&#26500;&#24314;&#22359;&#65292;&#31216;&#20026;MultiresLayer&#65292;&#36890;&#36807;&#22810;&#20998;&#36776;&#29575;&#21367;&#31215;&#25429;&#33719;&#36755;&#20837;&#24207;&#21015;&#20013;&#30340;&#22810;&#23610;&#24230;&#36235;&#21183;&#65292;&#26082;&#20855;&#26377;&#21367;&#31215;&#32593;&#32476;&#30340;&#35745;&#31639;&#20248;&#21183;&#65292;&#21448;&#20855;&#26377;&#23567;&#27874;&#20998;&#35299;&#30340;&#26377;&#29702;&#35770;&#22522;&#30784;&#30340;&#21160;&#26426;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26377;&#25928;&#22320;&#25429;&#25417;&#23545;&#20110;&#26576;&#20010;&#20219;&#21153;&#65288;&#22914;&#20998;&#31867;&#21644;&#29983;&#25104;&#24314;&#27169;&#65289;&#26174;&#33879;&#30340;&#39034;&#24207;&#25968;&#25454;&#28304;&#20013;&#30340;&#38271;&#31243;&#27169;&#24335;&#26159;&#19968;&#20010;&#22522;&#26412;&#25361;&#25112;&#12290;&#25105;&#20204;&#20174;&#22522;&#20110;&#23567;&#27874;&#30340;&#22810;&#20998;&#36776;&#29575;&#20998;&#26512;&#20013;&#33719;&#24471;&#28789;&#24863;&#65292;&#23450;&#20041;&#20102;&#19968;&#20010;&#26032;&#30340;&#29992;&#20110;&#24207;&#21015;&#24314;&#27169;&#30340;&#26500;&#24314;&#22359;&#65292;&#31216;&#20026;MultiresLayer&#12290;&#25105;&#20204;&#27169;&#22411;&#30340;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#26159;&#22810;&#20998;&#36776;&#29575;&#21367;&#31215;&#65292;&#20197;&#25429;&#33719;&#36755;&#20837;&#24207;&#21015;&#20013;&#30340;&#22810;&#23610;&#24230;&#36235;&#21183;&#12290;&#25105;&#20204;&#30340;MultiresConv&#21487;&#20197;&#36890;&#36807;&#22312;&#25193;&#24352;&#30340;&#22240;&#26524;&#21367;&#31215;&#26641;&#19978;&#20351;&#29992;&#20849;&#20139;&#36807;&#28388;&#22120;&#26469;&#23454;&#29616;&#12290;&#22240;&#27492;&#65292;&#23427;&#26082;&#20855;&#26377;&#21367;&#31215;&#32593;&#32476;&#30340;&#35745;&#31639;&#20248;&#21183;&#65292;&#21448;&#20855;&#26377;&#23567;&#27874;&#20998;&#35299;&#30340;&#26377;&#29702;&#35770;&#22522;&#30784;&#30340;&#21160;&#26426;&#12290;
&lt;/p&gt;
&lt;p&gt;
Efficiently capturing the long-range patterns in sequential data sources salient to a given task -- such as classification and generative modeling -poses a fundamental challenge. Popular approaches in the space tradeoff between the memory burden of brute-force enumeration and comparison, as in transformers, the computational burden of complicated sequential dependencies, as in recurrent neural networks, or the parameter burden of convolutional networks with many or large filters. We instead take inspiration from wavelet-based multiresolution analysis to define a new building block for sequence modeling, which we call a MultiresLayer. The key component of our model is the multiresolution convolution, capturing multiscale trends in the input sequence. Our MultiresConv can be implemented with shared filters across a dilated causal convolution tree. Thus it garners the computational advantages of convolutional networks and the principled theoretical motivation of wavelet decompositions. 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#20154;&#31995;&#32479;&#30340;&#33021;&#37327;&#27969;&#37327;&#21644;&#33021;&#37327;&#29305;&#24615;&#65292;&#25705;&#25830;&#21147;&#21644;&#34987;&#21160;&#25670;&#21160;&#26159;&#20854;&#20027;&#35201;&#24433;&#21709;&#22240;&#32032;&#65292;&#25552;&#20986;&#20102;&#20851;&#38190;&#21442;&#25968;&#21644;&#33021;&#37327;&#29305;&#24615;&#65292;&#26377;&#21161;&#20110;&#36827;&#19968;&#27493;&#30740;&#31350;&#12290;</title><link>http://arxiv.org/abs/2304.12768</link><description>&lt;p&gt;
&#34987;&#21160;&#25670;&#21160;&#25705;&#25830;&#21147;&#20316;&#29992;&#19979;&#26426;&#22120;&#20154;&#33021;&#37327;&#27969;&#37327;&#30340;&#20851;&#38190;&#21442;&#25968;&#21450;&#20854;&#29305;&#24615;
&lt;/p&gt;
&lt;p&gt;
Towards Characterizing the First-order Query Complexity of Learning (Approximate) Nash Equilibria in Zero-sum Matrix Games. (arXiv:2304.12768v1 [cs.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.12768
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#20154;&#31995;&#32479;&#30340;&#33021;&#37327;&#27969;&#37327;&#21644;&#33021;&#37327;&#29305;&#24615;&#65292;&#25705;&#25830;&#21147;&#21644;&#34987;&#21160;&#25670;&#21160;&#26159;&#20854;&#20027;&#35201;&#24433;&#21709;&#22240;&#32032;&#65292;&#25552;&#20986;&#20102;&#20851;&#38190;&#21442;&#25968;&#21644;&#33021;&#37327;&#29305;&#24615;&#65292;&#26377;&#21161;&#20110;&#36827;&#19968;&#27493;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#30740;&#31350;&#26426;&#22120;&#20154;&#31995;&#32479;&#30340;&#33021;&#37327;&#27969;&#37327;&#21644;&#33021;&#37327;&#29305;&#24615;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#26426;&#22120;&#20154;&#20256;&#21160;&#31995;&#32479;&#20013;&#25705;&#25830;&#21147;&#21644;&#34987;&#21160;&#25670;&#21160;&#31561;&#22240;&#32032;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#27169;&#22411;&#26469;&#20998;&#26512;&#36825;&#20123;&#22240;&#32032;&#23545;&#33021;&#37327;&#27969;&#37327;&#30340;&#24433;&#21709;&#12290;&#36890;&#36807;&#27169;&#25311;&#21644;&#23454;&#39564;&#65292;&#25105;&#20204;&#21457;&#29616;&#33021;&#37327;&#27969;&#37327;&#20027;&#35201;&#21463;&#21040;&#25705;&#25830;&#21147;&#21644;&#34987;&#21160;&#25670;&#21160;&#30340;&#24433;&#21709;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#20123;&#20851;&#38190;&#21442;&#25968;&#21644;&#33021;&#37327;&#29305;&#24615;&#20197;&#20379;&#36827;&#19968;&#27493;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the first-order query model for zero-sum $K\times K$ matrix games, playersobserve the expected pay-offs for all their possible actions under therandomized action played by their opponent. This is a classical model,which has received renewed interest after the discoveryby Rakhlin and Sridharan that $\epsilon$-approximate Nash equilibria can be computedefficiently from $O(\ln K / \epsilon) $ instead of $O( \ln K / \epsilon^2)$ queries.Surprisingly, the optimal number of such queries, as a function of both$\epsilon$ and $K$, is not known.We make progress on this question on two fronts. First, we fully characterise the query complexity of learning exact equilibria ($\epsilon=0$), by showing that they require a number of queries that is linearin $K$, which means that it is essentially as hard as querying the wholematrix, which can also be done with $K$ queries. Second, for $\epsilon &gt; 0$, the currentquery complexity upper bound stands at $O(\min(\ln(K) / \epsilon , K))$. We argue that, u
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; HopCPT &#30340;&#26032;&#19968;&#33268;&#24615;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#26041;&#27861;&#65292;&#19981;&#20165;&#33021;&#22815;&#22788;&#29702;&#26102;&#38388;&#32467;&#26500;&#65292;&#32780;&#19988;&#33021;&#22815;&#21033;&#29992;&#20854;&#20248;&#21183;&#65292;&#24050;&#22312;&#22810;&#31181;&#30495;&#23454;&#19990;&#30028;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#19978;&#35777;&#26126;&#20102;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2303.12783</link><description>&lt;p&gt;
&#22522;&#20110;&#29616;&#20195; Hopfield &#32593;&#32476;&#30340;&#26102;&#38388;&#24207;&#21015;&#19968;&#33268;&#24615;&#39044;&#27979;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Conformal Prediction for Time Series with Modern Hopfield Networks. (arXiv:2303.12783v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.12783
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; HopCPT &#30340;&#26032;&#19968;&#33268;&#24615;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#26041;&#27861;&#65292;&#19981;&#20165;&#33021;&#22815;&#22788;&#29702;&#26102;&#38388;&#32467;&#26500;&#65292;&#32780;&#19988;&#33021;&#22815;&#21033;&#29992;&#20854;&#20248;&#21183;&#65292;&#24050;&#22312;&#22810;&#31181;&#30495;&#23454;&#19990;&#30028;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#19978;&#35777;&#26126;&#20102;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#65292;&#19968;&#33268;&#24615;&#39044;&#27979;&#26041;&#27861;&#21463;&#21040;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#65292;&#24182;&#24050;&#25104;&#21151;&#24212;&#29992;&#20110;&#21508;&#20010;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#38590;&#20197;&#24212;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#65292;&#22240;&#20026;&#26102;&#38388;&#24207;&#21015;&#30340;&#33258;&#30456;&#20851;&#32467;&#26500;&#36829;&#21453;&#20102;&#19968;&#33268;&#24615;&#39044;&#27979;&#25152;&#38656;&#30340;&#22522;&#26412;&#20551;&#35774;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102; HopCPT&#65292;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110; Hopfield &#32593;&#32476;&#30340;&#26102;&#38388;&#24207;&#21015;&#19968;&#33268;&#24615;&#39044;&#27979;&#26041;&#27861;&#65292;&#19981;&#20165;&#33021;&#22815;&#24212;&#23545;&#26102;&#38388;&#32467;&#26500;&#65292;&#32780;&#19988;&#33021;&#22815;&#21033;&#29992;&#23427;&#20204;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#23384;&#22312;&#26102;&#38388;&#20381;&#36182;&#24615;&#30340;&#26102;&#38388;&#24207;&#21015;&#20013;&#22312;&#29702;&#35770;&#19978;&#26159;&#26377;&#24456;&#22909;&#30340;&#29702;&#35770;&#22522;&#30784;&#30340;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26032;&#26041;&#27861;&#22312;&#22235;&#20010;&#19981;&#21516;&#39046;&#22495;&#30340;&#22810;&#20010;&#30495;&#23454;&#19990;&#30028;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#19978;&#20248;&#20110;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#30340;&#19968;&#33268;&#24615;&#39044;&#27979;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
To quantify uncertainty, conformal prediction methods are gaining continuously more interest and have already been successfully applied to various domains. However, they are difficult to apply to time series as the autocorrelative structure of time series violates basic assumptions required by conformal prediction. We propose HopCPT, a novel conformal prediction approach for time series that not only copes with temporal structures but leverages them. We show that our approach is theoretically well justified for time series where temporal dependencies are present. In experiments, we demonstrate that our new approach outperforms state-of-the-art conformal prediction methods on multiple real-world time series datasets from four different domains.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;GFlowNets&#30340;&#39640;&#25928;&#22810;&#30446;&#26631;&#20998;&#23376;&#20248;&#21270;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#20351;&#29992;&#36229;&#32593;&#32476;&#26469;&#20248;&#21270;&#25910;&#30410;&#20989;&#25968;&#65292;&#20174;&#32780;&#22312;&#32771;&#34385;&#22810;&#26679;&#24615;&#30340;&#21516;&#26102;&#23454;&#29616;&#20102;&#20174;&#36817;&#20284;&#24085;&#32047;&#25176;&#21069;&#27839;&#20013;&#37319;&#26679;&#20986;&#22810;&#26679;&#21270;&#30340;&#20505;&#36873;&#20998;&#23376;&#22270;&#12290;&#21516;&#26102;&#36824;&#20351;&#29992;&#20102;&#19968;&#31181;&#31867;&#20284;&#20110;&#20107;&#21518;&#35748;&#35782;&#30340;&#31163;&#32447;&#31574;&#30053;&#26469;&#21152;&#24555;&#20248;&#21270;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2302.04040</link><description>&lt;p&gt;
&#29992;GFlowNets&#23454;&#29616;&#39640;&#25928;&#30340;&#22810;&#30446;&#26631;&#20998;&#23376;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Sample-efficient Multi-objective Molecular Optimization with GFlowNets. (arXiv:2302.04040v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.04040
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;GFlowNets&#30340;&#39640;&#25928;&#22810;&#30446;&#26631;&#20998;&#23376;&#20248;&#21270;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#20351;&#29992;&#36229;&#32593;&#32476;&#26469;&#20248;&#21270;&#25910;&#30410;&#20989;&#25968;&#65292;&#20174;&#32780;&#22312;&#32771;&#34385;&#22810;&#26679;&#24615;&#30340;&#21516;&#26102;&#23454;&#29616;&#20102;&#20174;&#36817;&#20284;&#24085;&#32047;&#25176;&#21069;&#27839;&#20013;&#37319;&#26679;&#20986;&#22810;&#26679;&#21270;&#30340;&#20505;&#36873;&#20998;&#23376;&#22270;&#12290;&#21516;&#26102;&#36824;&#20351;&#29992;&#20102;&#19968;&#31181;&#31867;&#20284;&#20110;&#20107;&#21518;&#35748;&#35782;&#30340;&#31163;&#32447;&#31574;&#30053;&#26469;&#21152;&#24555;&#20248;&#21270;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#20851;&#38190;&#30340;&#31185;&#23398;&#38382;&#39064;&#28041;&#21450;&#35774;&#35745;&#20855;&#26377;&#25152;&#38656;&#23646;&#24615;&#30340;&#26032;&#22411;&#20998;&#23376;&#65292;&#36825;&#21487;&#20197;&#34987;&#24418;&#24335;&#21270;&#20026;&#22312;&#31163;&#25955;&#21270;&#30340;&#21270;&#23398;&#31354;&#38388;&#19978;&#30340;&#40657;&#30418;&#20248;&#21270;&#38382;&#39064;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#22810;&#20010;&#20914;&#31361;&#30340;&#30446;&#26631;&#21644;&#26114;&#36149;&#30340;&#35780;&#20272;&#65288;&#20363;&#22914;&#28287;&#23454;&#39564;&#65289;&#20351;&#24471;&#20505;&#36873;&#20154;&#30340;&#22810;&#26679;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#35745;&#31639;&#26041;&#27861;&#24050;&#32463;&#21462;&#24471;&#20102;&#21021;&#27493;&#30340;&#25104;&#21151;&#65292;&#20294;&#20173;&#28982;&#22312;&#21516;&#26102;&#32771;&#34385;&#30446;&#26631;&#21644;&#25628;&#32034;&#31354;&#38388;&#30340;&#22810;&#26679;&#24615;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#20010;&#31354;&#30333;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#30446;&#26631;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;MOBO&#65289;&#31639;&#27861;&#65292;&#21033;&#29992;&#22522;&#20110;&#36229;&#32593;&#32476;&#30340;GFlowNets&#65288;HN-GFN&#65289;&#20316;&#20026;&#25910;&#30410;&#20989;&#25968;&#20248;&#21270;&#22120;&#65292;&#30446;&#30340;&#26159;&#20174;&#36817;&#20284;&#24085;&#32047;&#25176;&#21069;&#27839;&#20013;&#37319;&#26679;&#20986;&#22810;&#26679;&#21270;&#30340;&#20505;&#36873;&#20998;&#23376;&#22270;&#12290;&#20351;&#29992;&#21333;&#19968;&#30340;&#26465;&#20214;&#21270;&#36229;&#32593;&#32476;&#65292;HN-GFN&#23398;&#20064;&#25506;&#32034;&#21508;&#20010;&#30446;&#26631;&#20043;&#38388;&#30340;&#21508;&#31181;&#25240;&#20013;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#31181;&#31867;&#20284;&#20110;&#20107;&#21518;&#35748;&#35782;&#30340;&#31163;&#32447;&#31574;&#30053;&#65292;&#20197;&#20415;&#22312;&#19981;&#21516;&#20559;&#22909;&#20043;&#38388;&#20849;&#20139;&#39640;&#24615;&#33021;&#20998;&#23376;&#65292;&#20197;&#21152;&#24555;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many crucial scientific problems involve designing novel molecules with desired properties, which can be formulated as a black-box optimization problem over the discrete chemical space. In practice, multiple conflicting objectives and costly evaluations (e.g., wet-lab experiments) make the diversity of candidates paramount. Computational methods have achieved initial success but still struggle with considering diversity in both objective and search space. To fill this gap, we propose a multi-objective Bayesian optimization (MOBO) algorithm leveraging the hypernetwork-based GFlowNets (HN-GFN) as an acquisition function optimizer, with the purpose of sampling a diverse batch of candidate molecular graphs from an approximate Pareto front. Using a single preference-conditioned hypernetwork, HN-GFN learns to explore various trade-offs between objectives. We further propose a hindsight-like off-policy strategy to share high-performing molecules among different preferences in order to speed u
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;EPGP&#30340;&#39640;&#26031;&#36807;&#31243;&#20808;&#39564;&#65292;&#29992;&#20110;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#31995;&#32479;&#65292;&#24182;&#19988;&#26500;&#36896;&#20102;&#21453;&#26144;&#26631;&#20934;&#35889;&#26041;&#27861;&#30340;GP&#26680;&#20989;&#25968;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#25512;&#26029;&#32447;&#24615;PDE&#31995;&#32479;&#30340;&#21487;&#33021;&#35299;&#65292;&#24182;&#20855;&#26377;&#31639;&#27861;&#24615;&#24378;&#12289;&#26222;&#36866;&#24615;&#24191;&#12289;&#36866;&#29992;&#20110;&#22823;&#25968;&#25454;&#38598;&#30340;&#31232;&#30095;&#29256;&#26412;&#12290;</title><link>http://arxiv.org/abs/2212.14319</link><description>&lt;p&gt;
&#31995;&#32479;&#30340;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#39640;&#26031;&#36807;&#31243;&#20808;&#39564;&#19982;&#24120;&#31995;&#25968;&#65288;&#32763;&#35793;&#33258;arXiv:2212.14319v3 [stat.ML] &#26356;&#26032;&#65289;
&lt;/p&gt;
&lt;p&gt;
Gaussian Process Priors for Systems of Linear Partial Differential Equations with Constant Coefficients. (arXiv:2212.14319v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.14319
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;EPGP&#30340;&#39640;&#26031;&#36807;&#31243;&#20808;&#39564;&#65292;&#29992;&#20110;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#31995;&#32479;&#65292;&#24182;&#19988;&#26500;&#36896;&#20102;&#21453;&#26144;&#26631;&#20934;&#35889;&#26041;&#27861;&#30340;GP&#26680;&#20989;&#25968;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#25512;&#26029;&#32447;&#24615;PDE&#31995;&#32479;&#30340;&#21487;&#33021;&#35299;&#65292;&#24182;&#20855;&#26377;&#31639;&#27861;&#24615;&#24378;&#12289;&#26222;&#36866;&#24615;&#24191;&#12289;&#36866;&#29992;&#20110;&#22823;&#25968;&#25454;&#38598;&#30340;&#31232;&#30095;&#29256;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;PDE&#65289;&#26159;&#24314;&#27169;&#29289;&#29702;&#31995;&#32479;&#30340;&#37325;&#35201;&#24037;&#20855;&#65292;&#23558;&#23427;&#20204;&#32435;&#20837;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26159;&#23558;&#29289;&#29702;&#30693;&#35782;&#32435;&#20837;&#30340;&#37325;&#35201;&#26041;&#24335;&#12290;&#23545;&#20110;&#20219;&#20309;&#20855;&#26377;&#24120;&#31995;&#25968;&#30340;&#32447;&#24615;PDE&#31995;&#32479;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#26063;&#31216;&#20026;EPGP&#30340;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#20808;&#39564;&#65292;&#20351;&#24471;&#25152;&#26377;&#23454;&#29616;&#37117;&#26159;&#35813;&#31995;&#32479;&#30340;&#31934;&#30830;&#35299;&#12290;&#25105;&#20204;&#24212;&#29992;Ehrenpreis-Palamodov&#22522;&#26412;&#21407;&#29702;&#65292;&#23427;&#20316;&#20026;&#19968;&#31181;&#38750;&#32447;&#24615;&#20613;&#37324;&#21494;&#21464;&#25442;&#65292;&#26500;&#24314;&#20102;GP&#26680;&#20989;&#25968;&#65292;&#21453;&#26144;&#20102;&#26631;&#20934;&#30340;&#35889;&#26041;&#27861;&#29992;&#20110;GP&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#20174;&#20219;&#20309;&#25968;&#25454;&#65288;&#22914;&#26377;&#22122;&#22768;&#30340;&#27979;&#37327;&#25968;&#25454;&#25110;&#28857;&#23450;&#20041;&#30340;&#21021;&#22987;&#21644;&#36793;&#30028;&#26465;&#20214;&#65289;&#25512;&#26029;&#32447;&#24615;PDE&#31995;&#32479;&#30340;&#21487;&#33021;&#35299;&#12290;&#26500;&#36896;EPGP&#20808;&#39564;&#30340;&#31639;&#27861;&#24615;&#24378;&#65292;&#26222;&#36866;&#24615;&#24191;&#65292;&#24182;&#19988;&#26377;&#19968;&#20010;&#31232;&#30095;&#29256;&#26412;&#65288;S-EPGP&#65289;&#65292;&#21487;&#20197;&#23398;&#20064;&#30456;&#20851;&#30340;&#35889;&#39057;&#29575;&#65292;&#24182;&#22312;&#22823;&#25968;&#25454;&#38598;&#19978;&#36816;&#34892;&#25928;&#26524;&#26356;&#22909;&#12290;&#25105;&#20204;&#22312;&#19977;&#31867;PDE&#31995;&#32479;&#19978;&#28436;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#28909;&#26041;&#31243;&#21644;&#27874;&#26041;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Partial differential equations (PDEs) are important tools to model physical systems and including them into machine learning models is an important way of incorporating physical knowledge. Given any system of linear PDEs with constant coefficients, we propose a family of Gaussian process (GP) priors, which we call EPGP, such that all realizations are exact solutions of this system. We apply the Ehrenpreis-Palamodov fundamental principle, which works as a non-linear Fourier transform, to construct GP kernels mirroring standard spectral methods for GPs. Our approach can infer probable solutions of linear PDE systems from any data such as noisy measurements, or pointwise defined initial and boundary conditions. Constructing EPGP-priors is algorithmic, generally applicable, and comes with a sparse version (S-EPGP) that learns the relevant spectral frequencies and works better for big data sets. We demonstrate our approach on three families of systems of PDEs, the heat equation, wave equati
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#35782;&#21035;&#32593;&#32476;&#22914;&#20309;&#27169;&#25311;&#30495;&#23454;&#21518;&#39564;&#20998;&#24067;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#65292;&#36890;&#36807;&#23548;&#20986;&#20840;&#23616;&#26465;&#20214;&#21644;&#23616;&#37096;&#26465;&#20214;&#65292;&#21457;&#29616;&#23436;&#32654;&#24615;&#20026;&#20854;&#20855;&#22791;&#26399;&#26395;&#24615;&#36136;&#36215;&#21040;&#20102;&#37325;&#35201;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2212.10649</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#36870;&#25512;
&lt;/p&gt;
&lt;p&gt;
Inversion of Bayesian Networks. (arXiv:2212.10649v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.10649
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#35782;&#21035;&#32593;&#32476;&#22914;&#20309;&#27169;&#25311;&#30495;&#23454;&#21518;&#39564;&#20998;&#24067;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#65292;&#36890;&#36807;&#23548;&#20986;&#20840;&#23616;&#26465;&#20214;&#21644;&#23616;&#37096;&#26465;&#20214;&#65292;&#21457;&#29616;&#23436;&#32654;&#24615;&#20026;&#20854;&#20855;&#22791;&#26399;&#26395;&#24615;&#36136;&#36215;&#21040;&#20102;&#37325;&#35201;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#21644;Helmholtz&#26426;&#20351;&#29992;&#19968;&#20010;&#35782;&#21035;&#32593;&#32476;&#65288;&#32534;&#30721;&#22120;&#65289;&#26469;&#36817;&#20284;&#29983;&#25104;&#27169;&#22411;&#65288;&#35299;&#30721;&#22120;&#65289;&#30340;&#21518;&#39564;&#20998;&#24067;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#35782;&#21035;&#32593;&#32476;&#20855;&#22791;&#27169;&#25311;&#30495;&#23454;&#21518;&#39564;&#20998;&#24067;&#30340;&#24517;&#35201;&#21644;&#20805;&#20998;&#26465;&#20214;&#12290;&#36825;&#20123;&#32467;&#26524;&#22522;&#20110;&#27010;&#29575;&#22270;&#27169;&#22411;&#65295;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#19968;&#33324;&#32972;&#26223;&#65292;&#20854;&#20013;&#32593;&#32476;&#20195;&#34920;&#20102;&#19968;&#32452;&#26465;&#20214;&#29420;&#31435;&#24615;&#35821;&#21477;&#12290;&#25105;&#20204;&#23548;&#20986;&#20102;&#20840;&#23616;&#26465;&#20214;&#65288;&#36890;&#36807;d-&#20998;&#31163;&#65289;&#21644;&#23616;&#37096;&#26465;&#20214;&#65292;&#20351;&#24471;&#35782;&#21035;&#32593;&#32476;&#20855;&#22791;&#26399;&#26395;&#30340;&#24615;&#36136;&#12290;&#23616;&#37096;&#26465;&#20214;&#20013;&#65292;&#23436;&#32654;&#24615;&#65288;&#27599;&#20010;&#33410;&#28857;&#21482;&#19982;&#20854;&#29238;&#33410;&#28857;&#30456;&#36830;&#65289;&#21457;&#25381;&#20102;&#37325;&#35201;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variational autoencoders and Helmholtz machines use a recognition network (encoder) to approximate the posterior distribution of a generative model (decoder). In this paper we study the necessary and sufficient properties of a recognition network so that it can model the true posterior distribution exactly. These results are derived in the general context of probabilistic graphical modelling / Bayesian networks, for which the network represents a set of conditional independence statements. We derive both global conditions, in terms of d-separation, and local conditions for the recognition network to have the desired qualities. It turns out that for the local conditions the property perfectness (for every node, all parents are joined) plays an important role.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;Stein&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#26377;&#38480;&#31890;&#23376;&#25910;&#25947;&#36895;&#24230;&#65292;&#35777;&#26126;&#20102;&#24403;&#30446;&#26631;&#20998;&#24067;&#20026;&#27425;&#39640;&#26031;&#19988;&#20855;&#26377;Lipschitz&#31215;&#20998;&#26680;&#26102;&#65292;&#20351;&#29992;&#36866;&#24403;&#30340;&#27493;&#38271;&#24207;&#21015;&#21644;&#31890;&#23376;&#25968;&#37327;&#65292;&#21487;&#20197;&#20197;1/&#8730;(log log n)&#30340;&#36895;&#24230;&#23558;&#26680;Stein&#24046;&#24322;&#36924;&#36817;&#38646;&#12290;</title><link>http://arxiv.org/abs/2211.09721</link><description>&lt;p&gt;
&#12298;Stein&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#30340;&#26377;&#38480;&#31890;&#23376;&#25910;&#25947;&#36895;&#24230;&#12299;
&lt;/p&gt;
&lt;p&gt;
A Finite-Particle Convergence Rate for Stein Variational Gradient Descent. (arXiv:2211.09721v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.09721
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;Stein&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#26377;&#38480;&#31890;&#23376;&#25910;&#25947;&#36895;&#24230;&#65292;&#35777;&#26126;&#20102;&#24403;&#30446;&#26631;&#20998;&#24067;&#20026;&#27425;&#39640;&#26031;&#19988;&#20855;&#26377;Lipschitz&#31215;&#20998;&#26680;&#26102;&#65292;&#20351;&#29992;&#36866;&#24403;&#30340;&#27493;&#38271;&#24207;&#21015;&#21644;&#31890;&#23376;&#25968;&#37327;&#65292;&#21487;&#20197;&#20197;1/&#8730;(log log n)&#30340;&#36895;&#24230;&#23558;&#26680;Stein&#24046;&#24322;&#36924;&#36817;&#38646;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#39318;&#27425;&#25552;&#20379;&#20102;Stein&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#65288;SVGD&#65289;&#30340;&#26377;&#38480;&#31890;&#23376;&#25910;&#25947;&#36895;&#24230;&#65292;&#36825;&#26159;&#19968;&#31181;&#29992;&#19968;&#32452;&#31890;&#23376;&#36924;&#36817;&#27010;&#29575;&#20998;&#24067;&#30340;&#27969;&#34892;&#31639;&#27861;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#21482;&#35201;&#30446;&#26631;&#20998;&#24067;&#26159;&#27425;&#39640;&#26031;&#30340;&#65292;&#24182;&#19988;&#20855;&#26377;Lipschitz&#31215;&#20998;&#26680;&#65292;&#20351;&#29992;n&#20010;&#31890;&#23376;&#21644;&#36866;&#24403;&#30340;&#27493;&#38271;&#24207;&#21015;&#36827;&#34892;SVGD&#65292;&#26680;Stein&#24046;&#24322;&#23558;&#20197;1/&#8730;(log log n)&#30340;&#36895;&#24230;&#36235;&#20110;&#38646;&#12290;&#25105;&#20204;&#24576;&#30097;n&#30340;&#20381;&#36182;&#24615;&#21487;&#20197;&#25913;&#36827;&#65292;&#24076;&#26395;&#25105;&#20204;&#30340;&#26126;&#30830;&#30340;&#38750;&#28176;&#36817;&#35777;&#26126;&#31574;&#30053;&#33021;&#20026;&#26410;&#26469;&#30340;&#25913;&#36827;&#25552;&#20379;&#27169;&#26495;&#12290;
&lt;/p&gt;
&lt;p&gt;
We provide the first finite-particle convergence rate for Stein variational gradient descent (SVGD), a popular algorithm for approximating a probability distribution with a collection of particles. Specifically, whenever the target distribution is sub-Gaussian with a Lipschitz score, SVGD with n particles and an appropriate step size sequence drives the kernel Stein discrepancy to zero at an order 1/sqrt(log log n) rate. We suspect that the dependence on n can be improved, and we hope that our explicit, non-asymptotic proof strategy will serve as a template for future refinements.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#26426;&#22120;&#23398;&#20064;&#22312;&#31185;&#23398;&#39046;&#22495;&#30340;&#24212;&#29992;&#65292;&#23588;&#20854;&#26159;&#22312;&#31163;&#32676;&#26679;&#26412;&#26816;&#27979;&#26041;&#38754;&#21462;&#24471;&#20102;&#37325;&#35201;&#36827;&#23637;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#25968;&#25454;&#26222;&#36866;&#24615;&#12289;&#23454;&#39564;&#21327;&#35758;&#21644;&#27169;&#22411;&#40065;&#26834;&#24615;&#31561;&#26041;&#38754;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2210.13441</link><description>&lt;p&gt;
&#25645;&#24314;&#26426;&#22120;&#23398;&#20064;&#19982;&#31185;&#23398;&#30340;&#26725;&#26753;&#65306;&#26426;&#36935;&#19982;&#25361;&#25112;
&lt;/p&gt;
&lt;p&gt;
Bridging Machine Learning and Sciences: Opportunities and Challenges. (arXiv:2210.13441v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.13441
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#26426;&#22120;&#23398;&#20064;&#22312;&#31185;&#23398;&#39046;&#22495;&#30340;&#24212;&#29992;&#65292;&#23588;&#20854;&#26159;&#22312;&#31163;&#32676;&#26679;&#26412;&#26816;&#27979;&#26041;&#38754;&#21462;&#24471;&#20102;&#37325;&#35201;&#36827;&#23637;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#25968;&#25454;&#26222;&#36866;&#24615;&#12289;&#23454;&#39564;&#21327;&#35758;&#21644;&#27169;&#22411;&#40065;&#26834;&#24615;&#31561;&#26041;&#38754;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#22312;&#31185;&#23398;&#39046;&#22495;&#30340;&#24212;&#29992;&#36817;&#24180;&#26469;&#21462;&#24471;&#20102;&#20196;&#20154;&#25391;&#22859;&#30340;&#36827;&#23637;&#12290;&#20316;&#20026;&#19968;&#31181;&#24191;&#27867;&#36866;&#29992;&#30340;&#25216;&#26415;&#65292;&#24322;&#24120;&#26816;&#27979;&#22312;&#26426;&#22120;&#23398;&#20064;&#31038;&#21306;&#20013;&#19968;&#30452;&#21463;&#21040;&#20851;&#27880;&#12290;&#29305;&#21035;&#26159;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#31163;&#32676;&#26679;&#26412;&#26816;&#27979;&#22312;&#39640;&#32500;&#25968;&#25454;&#26041;&#38754;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#36827;&#27493;&#12290;&#26368;&#36817;&#65292;&#36825;&#20123;&#25216;&#26415;&#23637;&#31034;&#20102;&#22312;&#31185;&#23398;&#23398;&#31185;&#20013;&#30340;&#28508;&#21147;&#12290;&#25105;&#20204;&#23545;&#23427;&#20204;&#22312;&#25968;&#25454;&#26222;&#36866;&#24615;&#12289;&#23454;&#39564;&#21327;&#35758;&#12289;&#27169;&#22411;&#40065;&#26834;&#24615;&#31561;&#26041;&#38754;&#36827;&#34892;&#20102;&#25209;&#21028;&#24615;&#25506;&#35752;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#21516;&#26102;&#23637;&#31034;&#20102;&#21487;&#36716;&#31227;&#23454;&#36341;&#21644;&#39046;&#22495;&#29305;&#23450;&#25361;&#25112;&#30340;&#31034;&#20363;&#65292;&#20026;&#22312;&#36817;&#26399;&#24314;&#31435;&#19968;&#20010;&#26032;&#30340;&#36328;&#23398;&#31185;&#30740;&#31350;&#33539;&#24335;&#25552;&#20379;&#20102;&#19968;&#20010;&#36215;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
The application of machine learning in sciences has seen exciting advances in recent years. As a widely applicable technique, anomaly detection has been long studied in the machine learning community. Especially, deep neural nets-based out-of-distribution detection has made great progress for high-dimensional data. Recently, these techniques have been showing their potential in scientific disciplines. We take a critical look at their applicative prospects including data universality, experimental protocols, model robustness, etc. We discuss examples that display transferable practices and domain-specific challenges simultaneously, providing a starting point for establishing a novel interdisciplinary research paradigm in the near future.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#26680;&#24046;&#24322;&#24230;&#37327;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#26032;&#30340;&#20805;&#20998;&#24517;&#35201;&#26465;&#20214;&#65292;&#23454;&#29616;&#20102;&#23558;&#30446;&#26631;&#20998;&#31163;&#20986;&#26469;&#65292;&#20197;&#21450;&#25511;&#21046;&#23545;&#30446;&#26631;&#30340;&#24369;&#25910;&#25947;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22312;$\mathbb{R}^d$&#19978;&#20351;&#29992;&#20102;&#36825;&#20123;&#32467;&#26524;&#26469;&#25193;&#23637;&#20102;&#26680;Stein&#24046;&#24322;&#20998;&#31163;&#21644;&#25910;&#25947;&#25511;&#21046;&#30340;&#24050;&#30693;&#26465;&#20214;&#65292;&#24182;&#24320;&#21457;&#20102;&#33021;&#22815;&#31934;&#30830;&#24230;&#37327;&#30446;&#26631;&#30340;&#24369;&#25910;&#25947;&#24615;&#30340;&#26680;&#24046;&#24322;&#24230;&#37327;&#12290;</title><link>http://arxiv.org/abs/2209.12835</link><description>&lt;p&gt;
&#36890;&#36807;&#26680;&#24046;&#24322;&#23454;&#29616;&#26377;&#38024;&#23545;&#24615;&#30340;&#20998;&#31163;&#19982;&#25910;&#25947;
&lt;/p&gt;
&lt;p&gt;
Targeted Separation and Convergence with Kernel Discrepancies. (arXiv:2209.12835v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.12835
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26680;&#24046;&#24322;&#24230;&#37327;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#26032;&#30340;&#20805;&#20998;&#24517;&#35201;&#26465;&#20214;&#65292;&#23454;&#29616;&#20102;&#23558;&#30446;&#26631;&#20998;&#31163;&#20986;&#26469;&#65292;&#20197;&#21450;&#25511;&#21046;&#23545;&#30446;&#26631;&#30340;&#24369;&#25910;&#25947;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22312;$\mathbb{R}^d$&#19978;&#20351;&#29992;&#20102;&#36825;&#20123;&#32467;&#26524;&#26469;&#25193;&#23637;&#20102;&#26680;Stein&#24046;&#24322;&#20998;&#31163;&#21644;&#25910;&#25947;&#25511;&#21046;&#30340;&#24050;&#30693;&#26465;&#20214;&#65292;&#24182;&#24320;&#21457;&#20102;&#33021;&#22815;&#31934;&#30830;&#24230;&#37327;&#30446;&#26631;&#30340;&#24369;&#25910;&#25947;&#24615;&#30340;&#26680;&#24046;&#24322;&#24230;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#65288;MMDs&#65289;&#22914;&#26680;Stein&#24046;&#24322;&#65288;KSD&#65289;&#24050;&#32463;&#25104;&#20026;&#24191;&#27867;&#24212;&#29992;&#30340;&#20013;&#24515;&#65292;&#21253;&#25324;&#20551;&#35774;&#26816;&#39564;&#12289;&#37319;&#26679;&#22120;&#36873;&#25321;&#12289;&#20998;&#24067;&#36817;&#20284;&#21644;&#21464;&#20998;&#25512;&#26029;&#12290;&#22312;&#27599;&#20010;&#35774;&#32622;&#20013;&#65292;&#36825;&#20123;&#22522;&#20110;&#26680;&#30340;&#24046;&#24322;&#24230;&#37327;&#38656;&#35201;&#23454;&#29616;&#65288;i&#65289;&#23558;&#30446;&#26631;P&#19982;&#20854;&#20182;&#27010;&#29575;&#27979;&#24230;&#20998;&#31163;&#65292;&#29978;&#33267;&#65288;ii&#65289;&#25511;&#21046;&#23545;P&#30340;&#24369;&#25910;&#25947;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#30830;&#20445;&#65288;i&#65289;&#21644;&#65288;ii&#65289;&#30340;&#26032;&#30340;&#20805;&#20998;&#24517;&#35201;&#26465;&#20214;&#12290;&#23545;&#20110;&#21487;&#20998;&#30340;&#24230;&#37327;&#31354;&#38388;&#19978;&#30340;MMDs&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#20998;&#31163;Bochner&#21487;&#23884;&#20837;&#27979;&#24230;&#30340;&#26680;&#65292;&#24182;&#24341;&#20837;&#31616;&#21333;&#30340;&#26465;&#20214;&#26469;&#20998;&#31163;&#25152;&#26377;&#20855;&#26377;&#26080;&#30028;&#26680;&#30340;&#27979;&#24230;&#21644;&#29992;&#26377;&#30028;&#26680;&#26469;&#25511;&#21046;&#25910;&#25947;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#20123;&#32467;&#26524;&#22312;$\mathbb{R}^d$&#19978;&#22823;&#22823;&#25193;&#23637;&#20102;KSD&#20998;&#31163;&#21644;&#25910;&#25947;&#25511;&#21046;&#30340;&#24050;&#30693;&#26465;&#20214;&#65292;&#24182;&#24320;&#21457;&#20102;&#39318;&#20010;&#33021;&#22815;&#31934;&#30830;&#24230;&#37327;&#23545;P&#30340;&#24369;&#25910;&#25947;&#30340;KSDs&#12290;&#22312;&#36825;&#20010;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#24378;&#35843;&#20102;&#25105;&#20204;&#30340;&#32467;&#26524;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Maximum mean discrepancies (MMDs) like the kernel Stein discrepancy (KSD) have grown central to a wide range of applications, including hypothesis testing, sampler selection, distribution approximation, and variational inference. In each setting, these kernel-based discrepancy measures are required to (i) separate a target P from other probability measures or even (ii) control weak convergence to P. In this article we derive new sufficient and necessary conditions to ensure (i) and (ii). For MMDs on separable metric spaces, we characterize those kernels that separate Bochner embeddable measures and introduce simple conditions for separating all measures with unbounded kernels and for controlling convergence with bounded kernels. We use these results on $\mathbb{R}^d$ to substantially broaden the known conditions for KSD separation and convergence control and to develop the first KSDs known to exactly metrize weak convergence to P. Along the way, we highlight the implications of our res
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#36827;&#34892;&#26377;&#25439;&#22270;&#20687;&#21387;&#32553;&#30340;&#20248;&#21270;&#26694;&#26550;&#12290;&#36890;&#36807;&#24341;&#20837;&#39069;&#22806;&#30340;&#20869;&#23481;&#28508;&#21464;&#37327;&#20197;&#21450;&#21512;&#25104;&#32441;&#29702;&#21464;&#37327;&#65292;&#35813;&#26041;&#27861;&#22312;&#22270;&#20687;&#36136;&#37327;&#35780;&#20272;&#25351;&#26631;&#19978;&#34920;&#29616;&#20986;&#26356;&#24378;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2209.06950</link><description>&lt;p&gt;
&#22522;&#20110;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#30340;&#26377;&#25439;&#22270;&#20687;&#21387;&#32553;
&lt;/p&gt;
&lt;p&gt;
Lossy Image Compression with Conditional Diffusion Models. (arXiv:2209.06950v5 [eess.IV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.06950
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#36827;&#34892;&#26377;&#25439;&#22270;&#20687;&#21387;&#32553;&#30340;&#20248;&#21270;&#26694;&#26550;&#12290;&#36890;&#36807;&#24341;&#20837;&#39069;&#22806;&#30340;&#20869;&#23481;&#28508;&#21464;&#37327;&#20197;&#21450;&#21512;&#25104;&#32441;&#29702;&#21464;&#37327;&#65292;&#35813;&#26041;&#27861;&#22312;&#22270;&#20687;&#36136;&#37327;&#35780;&#20272;&#25351;&#26631;&#19978;&#34920;&#29616;&#20986;&#26356;&#24378;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#25193;&#25955;&#29983;&#25104;&#27169;&#22411;&#30340;&#31471;&#21040;&#31471;&#20248;&#21270;&#30340;&#26377;&#25439;&#22270;&#20687;&#21387;&#32553;&#26694;&#26550;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#21464;&#25442;&#32534;&#30721;&#33539;&#24335;&#65292;&#23558;&#22270;&#20687;&#26144;&#23556;&#21040;&#28508;&#22312;&#31354;&#38388;&#36827;&#34892;&#20449;&#24687;&#29109;&#32534;&#30721;&#65292;&#28982;&#21518;&#20877;&#26144;&#23556;&#22238;&#25968;&#25454;&#31354;&#38388;&#36827;&#34892;&#37325;&#26500;&#12290;&#19982;&#22522;&#20110;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;(VAE)&#30340;&#31070;&#32463;&#21387;&#32553;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#35299;&#30721;&#22120;&#26159;&#19968;&#20010;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#24341;&#20837;&#20102;&#19968;&#20010;&#39069;&#22806;&#30340;&#8220;&#20869;&#23481;&#8221;&#28508;&#21464;&#37327;&#65292;&#21453;&#21521;&#25193;&#25955;&#36807;&#31243;&#20250;&#23545;&#20854;&#36827;&#34892;&#26465;&#20214;&#21270;&#65292;&#24182;&#21033;&#29992;&#35813;&#21464;&#37327;&#23384;&#20648;&#22270;&#20687;&#20449;&#24687;&#12290;&#20915;&#23450;&#25193;&#25955;&#36807;&#31243;&#30340;&#21097;&#20313;&#8220;&#32441;&#29702;&#8221;&#21464;&#37327;&#20250;&#22312;&#35299;&#30721;&#26102;&#21512;&#25104;&#12290;&#36890;&#36807;&#23454;&#39564;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#27169;&#22411;&#30340;&#24615;&#33021;&#21487;&#20197;&#26681;&#25454;&#24863;&#30693;&#24230;&#37327;&#36827;&#34892;&#35843;&#25972;&#12290;&#25105;&#20204;&#24191;&#27867;&#30340;&#23454;&#39564;&#28041;&#21450;&#20102;&#22810;&#20010;&#25968;&#25454;&#38598;&#21644;&#22270;&#20687;&#36136;&#37327;&#35780;&#20272;&#25351;&#26631;&#65292;&#32467;&#26524;&#34920;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#30456;&#36739;&#20110;&#22522;&#20110;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#30340;&#26041;&#27861;&#33021;&#22815;&#24471;&#21040;&#26356;&#22909;&#30340;FID&#20998;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper outlines an end-to-end optimized lossy image compression framework using diffusion generative models. The approach relies on the transform coding paradigm, where an image is mapped into a latent space for entropy coding and, from there, mapped back to the data space for reconstruction. In contrast to VAE-based neural compression, where the (mean) decoder is a deterministic neural network, our decoder is a conditional diffusion model. Our approach thus introduces an additional "content" latent variable on which the reverse diffusion process is conditioned and uses this variable to store information about the image. The remaining "texture" variables characterizing the diffusion process are synthesized at decoding time. We show that the model's performance can be tuned toward perceptual metrics of interest. Our extensive experiments involving multiple datasets and image quality assessment metrics show that our approach yields stronger reported FID scores than the GAN-based mode
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#32570;&#22833;&#29289;&#29702;&#24314;&#27169;&#26694;&#26550;&#65292;&#36890;&#36807;&#23398;&#20064;&#31995;&#32479;&#27531;&#24046;&#28436;&#21270;&#30340;&#27169;&#22411;&#21644;&#21457;&#29616;&#30830;&#23450;&#24615;&#21160;&#21147;&#35823;&#24046;&#30340;&#27169;&#22411;&#65292;&#26469;&#35299;&#20915;&#27169;&#22411;&#19982;&#27979;&#37327;&#19981;&#21305;&#37197;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2203.05164</link><description>&lt;p&gt;
&#32570;&#22833;&#29289;&#29702;&#24314;&#27169;&#26694;&#26550;&#65306;&#23398;&#20064;&#32570;&#22833;&#30340;&#29289;&#29702;&#12289;&#24314;&#27169;&#31995;&#32479;&#27531;&#24046;&#21644;&#21306;&#20998;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#25928;&#24212;
&lt;/p&gt;
&lt;p&gt;
Discrepancy Modeling Framework: Learning missing physics, modeling systematic residuals, and disambiguating between deterministic and random effects. (arXiv:2203.05164v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.05164
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#32570;&#22833;&#29289;&#29702;&#24314;&#27169;&#26694;&#26550;&#65292;&#36890;&#36807;&#23398;&#20064;&#31995;&#32479;&#27531;&#24046;&#28436;&#21270;&#30340;&#27169;&#22411;&#21644;&#21457;&#29616;&#30830;&#23450;&#24615;&#21160;&#21147;&#35823;&#24046;&#30340;&#27169;&#22411;&#65292;&#26469;&#35299;&#20915;&#27169;&#22411;&#19982;&#27979;&#37327;&#19981;&#21305;&#37197;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#29289;&#29702;&#21644;&#31532;&#19968;&#21407;&#29702;&#30340;&#27169;&#22411;&#22312;&#24037;&#31243;&#21644;&#29289;&#29702;&#31185;&#23398;&#20013;&#24471;&#21040;&#24191;&#27867;&#24212;&#29992;&#65292;&#21487;&#20197;&#20197;&#25351;&#23450;&#30340;&#31934;&#24230;&#23545;&#22797;&#26434;&#31995;&#32479;&#30340;&#21160;&#24577;&#36827;&#34892;&#24314;&#27169;&#12290;&#22312;&#25512;&#23548;&#25511;&#21046;&#26041;&#31243;&#26102;&#20351;&#29992;&#30340;&#36817;&#20284;&#26041;&#27861;&#36890;&#24120;&#20250;&#23548;&#33268;&#27169;&#22411;&#19982;&#22522;&#20110;&#20256;&#24863;&#22120;&#30340;&#31995;&#32479;&#27979;&#37327;&#32467;&#26524;&#20043;&#38388;&#23384;&#22312;&#24046;&#24322;&#65292;&#25581;&#31034;&#20102;&#26041;&#31243;&#30340;&#36817;&#20284;&#24615;&#36136;&#21644;/&#25110;&#20256;&#24863;&#22120;&#26412;&#36523;&#30340;&#20449;&#22122;&#27604;&#12290;&#22312;&#29616;&#20195;&#21160;&#21147;&#31995;&#32479;&#20013;&#65292;&#27169;&#22411;&#19982;&#27979;&#37327;&#20043;&#38388;&#30340;&#36825;&#31181;&#24046;&#24322;&#21487;&#33021;&#23548;&#33268;&#26080;&#27861;&#20934;&#30830;&#37327;&#21270;&#65292;&#24120;&#24120;&#21066;&#24369;&#20102;&#20135;&#29983;&#31934;&#30830;&#21644;&#20934;&#30830;&#25511;&#21046;&#31639;&#27861;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#32570;&#22833;&#29289;&#29702;&#24314;&#27169;&#26694;&#26550;&#65292;&#36890;&#36807;&#20004;&#31181;&#19981;&#21516;&#30340;&#26041;&#27861;&#26469;&#35782;&#21035;&#32570;&#22833;&#30340;&#29289;&#29702;&#24182;&#35299;&#20915;&#27169;&#22411;&#19982;&#27979;&#37327;&#19981;&#21305;&#37197;&#30340;&#38382;&#39064;&#65306;&#65288;i&#65289;&#36890;&#36807;&#23398;&#20064;&#31995;&#32479;&#29366;&#24577;&#31354;&#38388;&#27531;&#24046;&#28436;&#21270;&#30340;&#27169;&#22411;&#65292;&#20197;&#21450;&#65288;ii&#65289;&#36890;&#36807;&#21457;&#29616;&#30830;&#23450;&#24615;&#21160;&#21147;&#35823;&#24046;&#30340;&#27169;&#22411;&#12290;&#26080;&#35770;&#37319;&#29992;&#21738;&#31181;&#26041;&#27861;&#65292;&#37117;&#20351;&#29992;&#20102;&#19968;&#22871;&#24120;&#35265;&#30340;&#25968;&#25454;&#39537;&#21160;&#27169;&#22411;&#21457;&#29616;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
Physics-based and first-principles models pervade the engineering and physical sciences, allowing for the ability to model the dynamics of complex systems with a prescribed accuracy. The approximations used in deriving governing equations often result in discrepancies between the model and sensor-based measurements of the system, revealing the approximate nature of the equations and/or the signal-to-noise ratio of the sensor itself. In modern dynamical systems, such discrepancies between model and measurement can lead to poor quantification, often undermining the ability to produce accurate and precise control algorithms. We introduce a discrepancy modeling framework to identify the missing physics and resolve the model-measurement mismatch with two distinct approaches: (i) by learning a model for the evolution of systematic state-space residual, and (ii) by discovering a model for the deterministic dynamical error. Regardless of approach, a common suite of data-driven model discovery 
&lt;/p&gt;</description></item><item><title>&#22312;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#25512;&#23548;&#20986;&#36951;&#28431;&#21464;&#37327;&#20559;&#24046;&#30340;&#23574;&#38160;&#19978;&#30028;&#65292;&#20026;&#24191;&#27867;&#30340;&#32447;&#24615;&#27867;&#20989;&#22240;&#26524;&#21442;&#25968;&#25552;&#20379;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#36890;&#29992;&#30340;&#26041;&#27861;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#35768;&#22810;&#20256;&#32479;&#30340;&#22240;&#26524;&#25512;&#26029;&#30740;&#31350;&#30446;&#26631;&#65292;&#24182;&#19988;&#20165;&#21462;&#20915;&#20110;&#28508;&#21464;&#37327;&#22312;&#32467;&#26524;&#21644;&#21442;&#25968;&#30340;Riesz&#34920;&#31034;&#22120;&#20013;&#25152;&#23548;&#33268;&#30340;&#39069;&#22806;&#21464;&#24322;&#12290;</title><link>http://arxiv.org/abs/2112.13398</link><description>&lt;p&gt;
&#12298;&#38271;&#35805;&#30701;&#35828;&#65306;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#36951;&#28431;&#21464;&#37327;&#20559;&#24046;&#12299;
&lt;/p&gt;
&lt;p&gt;
Long Story Short: Omitted Variable Bias in Causal Machine Learning. (arXiv:2112.13398v4 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.13398
&lt;/p&gt;
&lt;p&gt;
&#22312;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#25512;&#23548;&#20986;&#36951;&#28431;&#21464;&#37327;&#20559;&#24046;&#30340;&#23574;&#38160;&#19978;&#30028;&#65292;&#20026;&#24191;&#27867;&#30340;&#32447;&#24615;&#27867;&#20989;&#22240;&#26524;&#21442;&#25968;&#25552;&#20379;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#36890;&#29992;&#30340;&#26041;&#27861;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#35768;&#22810;&#20256;&#32479;&#30340;&#22240;&#26524;&#25512;&#26029;&#30740;&#31350;&#30446;&#26631;&#65292;&#24182;&#19988;&#20165;&#21462;&#20915;&#20110;&#28508;&#21464;&#37327;&#22312;&#32467;&#26524;&#21644;&#21442;&#25968;&#30340;Riesz&#34920;&#31034;&#22120;&#20013;&#25152;&#23548;&#33268;&#30340;&#39069;&#22806;&#21464;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25512;&#23548;&#20102;&#19968;&#31867;&#24191;&#27867;&#30340;&#22240;&#26524;&#21442;&#25968;&#30340;&#36951;&#28431;&#21464;&#37327;&#20559;&#24046;&#30340;&#19968;&#33324;&#20294;&#31616;&#21333;&#30340;&#23574;&#38160;&#19978;&#30028;&#65292;&#36825;&#20123;&#21442;&#25968;&#21487;&#20197;&#34987;&#35748;&#23450;&#20026;&#32467;&#26524;&#30340;&#26465;&#20214;&#26399;&#26395;&#20989;&#25968;&#30340;&#32447;&#24615;&#27867;&#20989;&#12290;&#36825;&#26679;&#30340;&#27867;&#20989;&#21253;&#25324;&#35768;&#22810;&#22240;&#26524;&#25512;&#26029;&#30740;&#31350;&#20013;&#30340;&#20256;&#32479;&#35843;&#26597;&#30446;&#26631;&#65292;&#20363;&#22914;&#65288;&#21152;&#26435;&#65289;&#28508;&#22312;&#32467;&#26524;&#30340;&#24179;&#22343;&#20540;&#12289;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;&#21253;&#25324;&#23376;&#32452;&#25928;&#24212;&#65292;&#22914;&#23545;&#24453;&#22788;&#29702;&#23545;&#35937;&#30340;&#24433;&#21709;&#65289;&#12289;&#65288;&#21152;&#26435;&#65289;&#24179;&#22343;&#23548;&#25968;&#21644;&#26469;&#33258;&#21327;&#21464;&#37327;&#20998;&#24067;&#21464;&#21270;&#30340;&#31574;&#30053;&#25928;&#24212; - &#20840;&#37096;&#36866;&#29992;&#20110;&#19968;&#33324;&#30340;&#38750;&#21442;&#25968;&#22240;&#26524;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#26500;&#36896;&#20381;&#36182;&#20110;&#30446;&#26631;&#27867;&#20989;&#30340;Riesz-Fr&#233;chet&#34920;&#31034;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20559;&#24046;&#19978;&#30028;&#20165;&#21462;&#20915;&#20110;&#28508;&#21464;&#37327;&#22312;&#32467;&#26524;&#21644;&#24863;&#20852;&#36259;&#21442;&#25968;&#30340;Riesz&#34920;&#31034;&#22120;&#20013;&#25152;&#21019;&#24314;&#30340;&#38468;&#21152;&#21464;&#21270;&#12290;&#27492;&#22806;&#65292;&#22312;&#35768;&#22810;&#37325;&#35201;&#24773;&#20917;&#19979;&#65288;&#20363;&#22914;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#21644;&#24179;&#22343;&#23548;&#25968;&#65289;
&lt;/p&gt;
&lt;p&gt;
We derive general, yet simple, sharp bounds on the size of the omitted variable bias for a broad class of causal parameters that can be identified as linear functionals of the conditional expectation function of the outcome. Such functionals encompass many of the traditional targets of investigation in causal inference studies, such as, for example, (weighted) average of potential outcomes, average treatment effects (including subgroup effects, such as the effect on the treated), (weighted) average derivatives, and policy effects from shifts in covariate distribution -- all for general, nonparametric causal models. Our construction relies on the Riesz-Frechet representation of the target functional. Specifically, we show how the bound on the bias depends only on the additional variation that the latent variables create both in the outcome and in the Riesz representer for the parameter of interest. Moreover, in many important cases (e.g, average treatment effects and avearage derivative
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#39532;&#23572;&#21487;&#22827;&#38142;&#32806;&#21512;&#30340;&#20272;&#35745;&#22120;&#65292;&#29992;&#20110;&#35780;&#20272;&#28176;&#36817;&#26377;&#20559;&#37319;&#26679;&#26041;&#27861;&#30340;&#36136;&#37327;&#65292;&#24182;&#32473;&#20986;&#20102;&#28176;&#36817;&#26377;&#20559;&#37319;&#26679;&#26041;&#27861;&#30340;&#26497;&#38480;&#20998;&#24067;&#19982;&#21407;&#22987;&#30446;&#26631;&#20998;&#24067;&#20043;&#38388;&#30340;Wasserstein&#36317;&#31163;&#30340;&#32463;&#39564;&#19978;&#30028;&#12290;</title><link>http://arxiv.org/abs/2112.03152</link><description>&lt;p&gt;
&#20351;&#29992;&#32806;&#21512;&#26041;&#27861;&#30028;&#23450;Wasserstein&#36317;&#31163;
&lt;/p&gt;
&lt;p&gt;
Bounding Wasserstein distance with couplings. (arXiv:2112.03152v3 [stat.CO] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.03152
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#39532;&#23572;&#21487;&#22827;&#38142;&#32806;&#21512;&#30340;&#20272;&#35745;&#22120;&#65292;&#29992;&#20110;&#35780;&#20272;&#28176;&#36817;&#26377;&#20559;&#37319;&#26679;&#26041;&#27861;&#30340;&#36136;&#37327;&#65292;&#24182;&#32473;&#20986;&#20102;&#28176;&#36817;&#26377;&#20559;&#37319;&#26679;&#26041;&#27861;&#30340;&#26497;&#38480;&#20998;&#24067;&#19982;&#21407;&#22987;&#30446;&#26631;&#20998;&#24067;&#20043;&#38388;&#30340;Wasserstein&#36317;&#31163;&#30340;&#32463;&#39564;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#65288;MCMC&#65289;&#22312;&#36845;&#20195;&#27425;&#25968;&#36235;&#20110;&#26080;&#31351;&#26102;&#25552;&#20379;&#20102;&#23545;&#38590;&#20197;&#35745;&#31639;&#30340;&#21518;&#39564;&#26399;&#26395;&#30340;&#28176;&#36817;&#19968;&#33268;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#22312;&#22823;&#22411;&#25968;&#25454;&#24212;&#29992;&#20013;&#65292;MCMC&#27599;&#27425;&#36845;&#20195;&#30340;&#35745;&#31639;&#25104;&#26412;&#24456;&#39640;&#12290;&#36825;&#20419;&#20351;&#20154;&#20204;&#23545;&#20197;&#25552;&#39640;&#27599;&#27425;&#36845;&#20195;&#30340;&#35745;&#31639;&#36895;&#24230;&#20026;&#30446;&#26631;&#30340;MCMC&#36817;&#20284;&#26041;&#27861;&#20135;&#29983;&#20102;&#20852;&#36259;&#65292;&#20294;&#36825;&#20123;&#26041;&#27861;&#19981;&#20250;&#20135;&#29983;&#28176;&#36817;&#19968;&#33268;&#20272;&#35745;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#39532;&#23572;&#21487;&#22827;&#38142;&#32806;&#21512;&#30340;&#20272;&#35745;&#22120;&#65292;&#29992;&#20110;&#35780;&#20272;&#36825;&#31181;&#28176;&#36817;&#26377;&#20559;&#37319;&#26679;&#26041;&#27861;&#30340;&#36136;&#37327;&#12290;&#36825;&#20123;&#20272;&#35745;&#22120;&#32473;&#20986;&#20102;&#28176;&#36817;&#26377;&#20559;&#37319;&#26679;&#26041;&#27861;&#30340;&#26497;&#38480;&#20998;&#24067;&#19982;&#21407;&#22987;&#30446;&#26631;&#20998;&#24067;&#20043;&#38388;&#30340;Wasserstein&#36317;&#31163;&#30340;&#32463;&#39564;&#19978;&#30028;&#12290;&#25105;&#20204;&#20026;&#25105;&#20204;&#30340;&#19978;&#30028;&#24314;&#31435;&#20102;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#34920;&#26126;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#20173;&#28982;&#26377;&#25928;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#36136;&#37327;&#24230;&#37327;&#24212;&#29992;&#20110;&#38543;&#26426;&#26799;&#24230;MCMC&#12289;&#21464;&#20998;&#36125;&#21494;&#26031;&#21644;&#25289;&#26222;&#25289;&#26031;&#36817;&#20284;&#31561;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Markov chain Monte Carlo (MCMC) provides asymptotically consistent estimates of intractable posterior expectations as the number of iterations tends to infinity. However, in large data applications, MCMC can be computationally expensive per iteration. This has catalyzed interest in approximating MCMC in a manner that improves computational speed per iteration but does not produce asymptotically consistent estimates. In this article, we propose estimators based on couplings of Markov chains to assess the quality of such asymptotically biased sampling methods. The estimators give empirical upper bounds of the Wasserstein distance between the limiting distribution of the asymptotically biased sampling method and the original target distribution of interest. We establish theoretical guarantees for our upper bounds and show that our estimators can remain effective in high dimensions. We apply our quality measures to stochastic gradient MCMC, variational Bayes, and Laplace approximations for
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21407;&#23376;&#33539;&#25968;&#30340;&#29420;&#21344;&#32676;&#32452;&#22871;&#32034;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#32467;&#26500;&#21464;&#37327;&#36873;&#25321;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#36866;&#24403;&#35774;&#35745;&#30340;&#22797;&#21512;&#33539;&#25968;&#20419;&#36827;&#29420;&#21344;&#32676;&#32452;&#31232;&#30095;&#27169;&#24335;&#65292;&#24182;&#20351;&#29992;&#39640;&#25928;&#28789;&#27963;&#30340;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#25903;&#25345;&#24674;&#22797;&#12290;&#36890;&#36807;&#36880;&#27493;&#23558;&#32467;&#26500;&#21407;&#23376;&#21253;&#21547;&#21040;&#20272;&#35745;&#30340;&#25903;&#25345;&#20013;&#26500;&#24314;&#35299;&#65292;&#24182;&#22312;&#19968;&#23450;&#20551;&#35774;&#19979;&#35777;&#26126;&#20102;&#35299;&#20915;&#26041;&#26696;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2108.10284</link><description>&lt;p&gt;
&#32467;&#26500;&#21464;&#37327;&#36873;&#25321;&#30340;&#29420;&#21344;&#32676;&#32452;&#22871;&#32034;
&lt;/p&gt;
&lt;p&gt;
Exclusive Group Lasso for Structured Variable Selection. (arXiv:2108.10284v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2108.10284
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21407;&#23376;&#33539;&#25968;&#30340;&#29420;&#21344;&#32676;&#32452;&#22871;&#32034;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#32467;&#26500;&#21464;&#37327;&#36873;&#25321;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#36866;&#24403;&#35774;&#35745;&#30340;&#22797;&#21512;&#33539;&#25968;&#20419;&#36827;&#29420;&#21344;&#32676;&#32452;&#31232;&#30095;&#27169;&#24335;&#65292;&#24182;&#20351;&#29992;&#39640;&#25928;&#28789;&#27963;&#30340;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#25903;&#25345;&#24674;&#22797;&#12290;&#36890;&#36807;&#36880;&#27493;&#23558;&#32467;&#26500;&#21407;&#23376;&#21253;&#21547;&#21040;&#20272;&#35745;&#30340;&#25903;&#25345;&#20013;&#26500;&#24314;&#35299;&#65292;&#24182;&#22312;&#19968;&#23450;&#20551;&#35774;&#19979;&#35777;&#26126;&#20102;&#35299;&#20915;&#26041;&#26696;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#31181;&#32467;&#26500;&#21464;&#37327;&#36873;&#25321;&#38382;&#39064;&#65292;&#22312;&#36825;&#20010;&#38382;&#39064;&#20013;&#65292;&#21327;&#21464;&#37327;&#34987;&#39044;&#23450;&#20041;&#30340;&#32676;&#32452;&#21010;&#20998;&#65292;&#24182;&#19988;&#26681;&#25454;&#27599;&#20010;&#32676;&#32452;&#20013;&#30340;&#31232;&#30095;&#27169;&#24335;&#28608;&#27963;&#65292;&#27599;&#20010;&#32676;&#32452;&#20165;&#26377;&#23569;&#25968;&#38750;&#38646;&#26465;&#30446;&#12290;&#21033;&#29992;&#21407;&#23376;&#33539;&#25968;&#30340;&#27010;&#24565;&#65292;&#21487;&#20197;&#35774;&#35745;&#20986;&#21512;&#36866;&#30340;&#22797;&#21512;&#33539;&#25968;&#20197;&#20419;&#36827;&#36825;&#31181;&#29420;&#21344;&#32676;&#32452;&#31232;&#30095;&#27169;&#24335;&#12290;&#30001;&#27492;&#20135;&#29983;&#30340;&#33539;&#25968;&#36866;&#29992;&#20110;&#39640;&#25928;&#21644;&#28789;&#27963;&#30340;&#25903;&#25345;&#24674;&#22797;&#27491;&#21017;&#21270;&#20248;&#21270;&#31639;&#27861;&#65292;&#22914;&#36817;&#31471;&#31639;&#27861;&#12290;&#27492;&#22806;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20027;&#21160;&#38598;&#31639;&#27861;&#65292;&#36890;&#36807;&#36880;&#27493;&#23558;&#32467;&#26500;&#21407;&#23376;&#21253;&#21547;&#21040;&#20272;&#35745;&#30340;&#25903;&#25345;&#20013;&#26469;&#26500;&#24314;&#35299;&#12290;&#36824;&#34920;&#26126;&#65292;&#36825;&#31181;&#31639;&#27861;&#21487;&#20197;&#38024;&#23545;&#27604;&#32431;&#31929;&#30340;&#29420;&#21344;&#32676;&#32452;&#31232;&#30095;&#24615;&#26356;&#20005;&#26684;&#30340;&#32467;&#26500;&#36827;&#34892;&#23450;&#21046;&#12290;&#28176;&#36817;&#19968;&#33268;&#24615;&#20998;&#26512;&#65288;&#21442;&#25968;&#25968;&#37327;&#21644;&#32676;&#32452;&#25968;&#37327;&#38543;&#35266;&#23519;&#22823;&#23567;&#22686;&#38271;&#65289;&#22312;&#20256;&#32479;&#20551;&#35774;&#19979;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#35299;&#20915;&#26041;&#26696;&#22312;&#26377;&#31526;&#21495;&#25903;&#25345;&#24674;&#22797;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;&#26368;&#21518;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#20248;&#21270;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
A structured variable selection problem is considered in which the covariates, divided into predefined groups, activate according to sparse patterns with few nonzero entries per group. Capitalizing on the concept of atomic norm, a composite norm can be properly designed to promote such exclusive group sparsity patterns. The resulting norm lends itself to efficient and flexible regularized optimization algorithms for support recovery, like the proximal algorithm. Moreover, an active set algorithm is proposed that builds the solution by successively including structure atoms into the estimated support. It is also shown that such an algorithm can be tailored to match more rigid structures than plain exclusive group sparsity. Asymptotic consistency analysis (with both the number of parameters as well as the number of groups growing with the observation size) establishes the effectiveness of the proposed solution in terms of signed support recovery under conventional assumptions. Finally, a
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24320;&#21457;&#20102;&#19968;&#31181;&#21033;&#29992;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#33258;&#21160;&#33719;&#21462;&#30149;&#24773;&#21464;&#37327;&#30340;&#35745;&#31639;&#34920;&#22411;&#65292;&#24182;&#25551;&#36848;&#20102;&#37325;&#30151;&#30417;&#25252;&#23460;&#30149;&#20154;&#30340;&#30149;&#24773;&#36716;&#25442;&#12290;&#36890;&#36807;&#36830;&#32493;&#30340;&#30149;&#24773;&#29366;&#24577;&#21644;&#32858;&#31867;&#26041;&#27861;&#65292;&#25552;&#20379;&#20102;&#23545;ICU&#30149;&#20154;&#20020;&#24202;&#36827;&#23637;&#30340;&#23637;&#31034;&#12290;</title><link>http://arxiv.org/abs/2005.05163</link><description>&lt;p&gt;
&#22312;&#37325;&#30151;&#30417;&#25252;&#23460;&#20013;&#30340;&#30149;&#20154;&#30149;&#24773;&#21487;&#35745;&#31639;&#30340;&#34920;&#22411;
&lt;/p&gt;
&lt;p&gt;
Computable Phenotypes of Patient Acuity in the Intensive Care Unit. (arXiv:2005.05163v2 [q-bio.QM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2005.05163
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24320;&#21457;&#20102;&#19968;&#31181;&#21033;&#29992;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#33258;&#21160;&#33719;&#21462;&#30149;&#24773;&#21464;&#37327;&#30340;&#35745;&#31639;&#34920;&#22411;&#65292;&#24182;&#25551;&#36848;&#20102;&#37325;&#30151;&#30417;&#25252;&#23460;&#30149;&#20154;&#30340;&#30149;&#24773;&#36716;&#25442;&#12290;&#36890;&#36807;&#36830;&#32493;&#30340;&#30149;&#24773;&#29366;&#24577;&#21644;&#32858;&#31867;&#26041;&#27861;&#65292;&#25552;&#20379;&#20102;&#23545;ICU&#30149;&#20154;&#20020;&#24202;&#36827;&#23637;&#30340;&#23637;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36830;&#32493;&#30417;&#27979;&#21644;&#30149;&#20154;&#30149;&#24773;&#35780;&#20272;&#26159;&#37325;&#30151;&#30417;&#25252;&#23460;&#23454;&#36341;&#30340;&#20851;&#38190;&#65292;&#20294;&#37117;&#21463;&#21040;&#21307;&#25252;&#20154;&#21592;&#26102;&#38388;&#38480;&#21046;&#30340;&#38480;&#21046;&#12290;&#27492;&#22806;&#65292;&#39044;&#27979;&#20020;&#24202;&#36827;&#23637;&#20173;&#28982;&#19981;&#31934;&#30830;&#12290;&#26412;&#30740;&#31350;&#30340;&#30446;&#26631;&#26159;&#65288;1&#65289;&#21033;&#29992;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#20013;&#30340;&#33258;&#21160;&#21464;&#37327;&#33719;&#21462;&#24320;&#21457;&#19968;&#20010;&#30149;&#24773;&#34920;&#22411;&#21644;&#65288;2&#65289;&#25551;&#36848;&#37325;&#30151;&#30417;&#25252;&#23460;&#30149;&#20154;&#30340;&#30149;&#24773;&#36716;&#25442;&#65292;&#20197;&#23637;&#31034;&#20020;&#24202;&#36827;&#23637;&#12290;&#25105;&#20204;&#25910;&#38598;&#20102;51,372&#21517;&#20837;&#20303;&#20315;&#32599;&#37324;&#36798;&#22823;&#23398;&#20581;&#24247;&#21307;&#38498;&#65288;UFH&#65289;&#30422;&#24681;&#26031;&#32500;&#23572;&#65288;GNV&#65289;&#21644;&#26480;&#20811;&#36874;&#32500;&#23572;&#65288;JAX&#65289;&#37325;&#30151;&#30417;&#25252;&#23460;&#30340;&#25104;&#24180;&#30149;&#20154;&#30340;&#20004;&#20010;&#21333;&#20013;&#24515;&#12289;&#32437;&#21521;&#30340;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#31639;&#27861;&#65292;&#20197;&#27599;&#22235;&#23567;&#26102;&#20026;&#38388;&#38548;&#35745;&#31639;&#27599;&#27425;&#37325;&#30151;&#30417;&#25252;&#23460;&#20837;&#38498;&#30340;&#30149;&#24773;&#29366;&#20917;&#65292;&#24182;&#21033;&#29992;&#36830;&#32493;&#30340;&#30149;&#24773;&#29366;&#20917;&#21644;k-means&#32858;&#31867;&#26041;&#27861;&#35782;&#21035;&#30149;&#24773;&#34920;&#22411;&#12290;UFH GNV&#25968;&#25454;&#38598;&#20013;&#26377;38,749&#21517;&#30149;&#20154;&#30340;51,073&#27425;&#20837;&#38498;&#65292;JAX&#25968;&#25454;&#38598;&#20013;&#26377;12,623&#21517;&#30149;&#20154;&#30340;22,219&#27425;&#20837;&#38498;&#12290;
&lt;/p&gt;
&lt;p&gt;
Continuous monitoring and patient acuity assessments are key aspects of Intensive Care Unit (ICU) practice, but both are limited by time constraints imposed on healthcare providers. Moreover, anticipating clinical trajectories remains imprecise. The objectives of this study are to (1) develop an electronic phenotype of acuity using automated variable retrieval within the electronic health records and (2) describe transitions between acuity states that illustrate the clinical trajectories of ICU patients. We gathered two single-center, longitudinal electronic health record datasets for 51,372 adult ICU patients admitted to the University of Florida Health (UFH) Gainesville (GNV) and Jacksonville (JAX). We developed algorithms to quantify acuity status at four-hour intervals for each ICU admission and identify acuity phenotypes using continuous acuity status and k-means clustering approach. 51,073 admissions for 38,749 patients in the UFH GNV dataset and 22,219 admissions for 12,623 pati
&lt;/p&gt;</description></item></channel></rss>