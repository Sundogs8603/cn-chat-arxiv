<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#38024;&#23545;&#38543;&#26426;&#38646;&#38454;&#20248;&#21270;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20108;&#27425;&#22411;&#30446;&#26631;&#20989;&#25968;&#21450;&#20854;&#23616;&#37096;&#20960;&#20309;&#32467;&#26500;&#30340;&#26368;&#20248;Hessian&#30456;&#20851;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#20174;&#20449;&#24687;&#35770;&#35282;&#24230;&#25552;&#20379;Hessian&#30456;&#20851;&#22797;&#26434;&#24230;&#30340;&#19979;&#30028;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;Hessian&#26080;&#20851;&#30340;&#31639;&#27861;&#21487;&#26222;&#36941;&#23454;&#29616;&#25152;&#26377;Hessian&#23454;&#20363;&#30340;&#28176;&#36817;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2306.12383</link><description>&lt;p&gt;
&#20108;&#27425;&#22411;&#36172;&#33218;&#26426;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65306;Hessian&#30456;&#20851;&#24615;&#30028;&#38480;&#21644;&#26368;&#20248;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Sample Complexity for Quadratic Bandits: Hessian Dependent Bounds and Optimal Algorithms. (arXiv:2306.12383v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12383
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#38543;&#26426;&#38646;&#38454;&#20248;&#21270;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20108;&#27425;&#22411;&#30446;&#26631;&#20989;&#25968;&#21450;&#20854;&#23616;&#37096;&#20960;&#20309;&#32467;&#26500;&#30340;&#26368;&#20248;Hessian&#30456;&#20851;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#20174;&#20449;&#24687;&#35770;&#35282;&#24230;&#25552;&#20379;Hessian&#30456;&#20851;&#22797;&#26434;&#24230;&#30340;&#19979;&#30028;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;Hessian&#26080;&#20851;&#30340;&#31639;&#27861;&#21487;&#26222;&#36941;&#23454;&#29616;&#25152;&#26377;Hessian&#23454;&#20363;&#30340;&#28176;&#36817;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#38543;&#26426;&#38646;&#38454;&#20248;&#21270;&#20013;&#65292;&#20102;&#35299;&#22914;&#20309;&#20805;&#20998;&#21033;&#29992;&#24213;&#23618;&#30446;&#26631;&#20989;&#25968;&#30340;&#23616;&#37096;&#20960;&#20309;&#32467;&#26500;&#26159;&#19968;&#20010;&#23454;&#38469;&#30456;&#20851;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#32771;&#34385;&#19968;&#31181;&#22522;&#26412;&#24773;&#20917;&#65292;&#21363;&#30446;&#26631;&#20989;&#25968;&#26159;&#20108;&#27425;&#22411;&#30340;&#65292;&#24182;&#19988;&#25552;&#20379;&#20102;&#26368;&#20248;Hessian&#30456;&#20851;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#31532;&#19968;&#20010;&#32039;&#23494;&#21051;&#30011;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#20855;&#26377;&#21452;&#37325;&#24615;&#36136;&#12290;&#39318;&#20808;&#65292;&#20174;&#20449;&#24687;&#35770;&#30340;&#35282;&#24230;&#20986;&#21457;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#31181;&#31216;&#20026;&#33021;&#37327;&#20998;&#37197;&#30340;&#27010;&#24565;&#26469;&#25429;&#25417;&#25628;&#32034;&#31639;&#27861;&#21644;&#30446;&#26631;&#20989;&#25968;&#20960;&#20309;&#32467;&#26500;&#20043;&#38388;&#30340;&#20132;&#20114;&#65292;&#35777;&#26126;&#20102;Hessian&#30456;&#20851;&#22797;&#26434;&#24230;&#30340;&#32039;&#23494;&#19979;&#30028;&#12290;&#36890;&#36807;&#35299;&#20915;&#26368;&#20248;&#33021;&#37327;&#35889;&#65292;&#24471;&#21040;&#20102;&#37197;&#22871;&#30340;&#19978;&#38480;&#12290;&#20854;&#27425;&#65292;&#31639;&#27861;&#26041;&#38754;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#23384;&#22312;&#19968;&#31181;Hessian&#26080;&#20851;&#30340;&#31639;&#27861;&#65292;&#33021;&#22815;&#26222;&#36941;&#23454;&#29616;&#25152;&#26377;Hessian&#23454;&#20363;&#30340;&#28176;&#36817;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#31639;&#27861;&#33021;&#22815;&#23454;&#29616;&#30340;&#28176;&#36817;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#23545;&#20110;&#37325;&#23614;&#22122;&#22768;&#20998;&#24067;&#20173;&#28982;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;
In stochastic zeroth-order optimization, a problem of practical relevance is understanding how to fully exploit the local geometry of the underlying objective function. We consider a fundamental setting in which the objective function is quadratic, and provide the first tight characterization of the optimal Hessian-dependent sample complexity. Our contribution is twofold. First, from an information-theoretic point of view, we prove tight lower bounds on Hessian-dependent complexities by introducing a concept called energy allocation, which captures the interaction between the searching algorithm and the geometry of objective functions. A matching upper bound is obtained by solving the optimal energy spectrum. Then, algorithmically, we show the existence of a Hessian-independent algorithm that universally achieves the asymptotic optimal sample complexities for all Hessian instances. The optimal sample complexities achieved by our algorithm remain valid for heavy-tailed noise distributio
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#35814;&#32454;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#22686;&#37327;&#21333;&#20803;&#26522;&#20030;&#65288;ICE&#65289;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21487;&#20197;&#31934;&#30830;&#35299;&#20915;&#23450;&#32500;&#24230;0-1&#25439;&#22833;&#32447;&#24615;&#20998;&#31867;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.12344</link><description>&lt;p&gt;
&#19968;&#31181;&#26377;&#25928;&#19988;&#21487;&#35777;&#26126;&#31934;&#30830;&#30340;0-1&#25439;&#22833;&#32447;&#24615;&#20998;&#31867;&#38382;&#39064;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
An efficient, provably exact algorithm for the 0-1 loss linear classification problem. (arXiv:2306.12344v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12344
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#35814;&#32454;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;&#22686;&#37327;&#21333;&#20803;&#26522;&#20030;&#65288;ICE&#65289;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21487;&#20197;&#31934;&#30830;&#35299;&#20915;&#23450;&#32500;&#24230;0-1&#25439;&#22833;&#32447;&#24615;&#20998;&#31867;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35299;&#20915;&#32447;&#24615;&#20998;&#31867;&#38382;&#39064;&#30340;&#31639;&#27861;&#20855;&#26377;&#24736;&#20037;&#30340;&#21382;&#21490;&#65292;&#33267;&#23569;&#21487;&#20197;&#36861;&#28335;&#21040;1936&#24180;&#30340;&#32447;&#24615;&#21028;&#21035;&#20998;&#26512;&#12290;&#23545;&#20110;&#32447;&#24615;&#21487;&#20998;&#25968;&#25454;&#65292;&#35768;&#22810;&#31639;&#27861;&#21487;&#20197;&#26377;&#25928;&#22320;&#24471;&#21040;&#30456;&#24212;&#30340;0-1&#25439;&#22833;&#20998;&#31867;&#38382;&#39064;&#30340;&#31934;&#30830;&#35299;&#65292;&#20294;&#23545;&#20110;&#38750;&#32447;&#24615;&#21487;&#20998;&#25968;&#25454;&#65292;&#24050;&#32463;&#35777;&#26126;&#36825;&#20010;&#38382;&#39064;&#22312;&#23436;&#20840;&#33539;&#22260;&#20869;&#26159;NP&#38590;&#30340;&#12290;&#25152;&#26377;&#26367;&#20195;&#26041;&#27861;&#37117;&#28041;&#21450;&#26576;&#31181;&#24418;&#24335;&#30340;&#36817;&#20284;&#65292;&#21253;&#25324;&#20351;&#29992;0-1&#25439;&#22833;&#30340;&#20195;&#29702;&#65288;&#20363;&#22914;hinge&#25110;logistic&#25439;&#22833;&#65289;&#25110;&#36817;&#20284;&#30340;&#32452;&#21512;&#25628;&#32034;&#65292;&#36825;&#20123;&#37117;&#19981;&#33021;&#20445;&#35777;&#23436;&#20840;&#35299;&#20915;&#38382;&#39064;&#12290;&#25214;&#21040;&#35299;&#20915;&#23450;&#32500;&#24230;0-1&#25439;&#22833;&#32447;&#24615;&#20998;&#31867;&#38382;&#39064;&#30340;&#20840;&#23616;&#26368;&#20248;&#35299;&#30340;&#26377;&#25928;&#31639;&#27861;&#20173;&#28982;&#26159;&#19968;&#20010;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#35814;&#32454;&#20171;&#32461;&#20102;&#19968;&#20010;&#26032;&#31639;&#27861;&#30340;&#26500;&#24314;&#36807;&#31243;&#65292;&#22686;&#37327;&#21333;&#20803;&#26522;&#20030;&#65288;ICE&#65289;&#65292;&#23427;&#21487;&#20197;&#31934;&#30830;&#35299;&#20915;0-1&#25439;&#22833;&#20998;&#31867;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Algorithms for solving the linear classification problem have a long history, dating back at least to 1936 with linear discriminant analysis. For linearly separable data, many algorithms can obtain the exact solution to the corresponding 0-1 loss classification problem efficiently, but for data which is not linearly separable, it has been shown that this problem, in full generality, is NP-hard. Alternative approaches all involve approximations of some kind, including the use of surrogates for the 0-1 loss (for example, the hinge or logistic loss) or approximate combinatorial search, none of which can be guaranteed to solve the problem exactly. Finding efficient algorithms to obtain an exact i.e. globally optimal solution for the 0-1 loss linear classification problem with fixed dimension, remains an open problem. In research we report here, we detail the construction of a new algorithm, incremental cell enumeration (ICE), that can solve the 0-1 loss classification problem exactly in po
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#23545;&#21160;&#24577;&#31232;&#30095;&#35757;&#32451;&#20013;&#30340;&#21098;&#26525;&#20301;&#32622;&#36827;&#34892;&#20102;&#23454;&#35777;&#20998;&#26512;&#65292;&#21457;&#29616;&#22312;&#20302;&#23494;&#24230;&#33539;&#22260;&#20869;&#65292;&#26368;&#31616;&#21333;&#30340;&#22823;&#23567;&#26041;&#27861;&#25552;&#20379;&#20102;&#26368;&#20339;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.12230</link><description>&lt;p&gt;
&#22855;&#22937;&#30340;&#26435;&#37325;&#21450;&#20854;&#26597;&#25214;&#26041;&#27861;&#65306;&#21160;&#24577;&#31232;&#30095;&#35757;&#32451;&#20013;&#30340;&#21098;&#26525;&#20301;&#32622;
&lt;/p&gt;
&lt;p&gt;
Fantastic Weights and How to Find Them: Where to Prune in Dynamic Sparse Training. (arXiv:2306.12230v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12230
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#23545;&#21160;&#24577;&#31232;&#30095;&#35757;&#32451;&#20013;&#30340;&#21098;&#26525;&#20301;&#32622;&#36827;&#34892;&#20102;&#23454;&#35777;&#20998;&#26512;&#65292;&#21457;&#29616;&#22312;&#20302;&#23494;&#24230;&#33539;&#22260;&#20869;&#65292;&#26368;&#31616;&#21333;&#30340;&#22823;&#23567;&#26041;&#27861;&#25552;&#20379;&#20102;&#26368;&#20339;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21160;&#24577;&#31232;&#30095;&#35757;&#32451;&#65288;DST&#65289;&#26159;&#19968;&#20010;&#24555;&#36895;&#21457;&#23637;&#30340;&#30740;&#31350;&#39046;&#22495;&#65292;&#26088;&#22312;&#36890;&#36807;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#35843;&#25972;&#31070;&#32463;&#32593;&#32476;&#30340;&#25299;&#25169;&#32467;&#26500;&#26469;&#20248;&#21270;&#20854;&#31232;&#30095;&#21021;&#22987;&#21270;&#12290;&#24050;&#32463;&#35777;&#26126;&#65292;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#65292;DST&#33021;&#22815;&#32988;&#36807;&#23494;&#38598;&#27169;&#22411;&#12290;&#35813;&#26694;&#26550;&#30340;&#20851;&#38190;&#32452;&#25104;&#37096;&#20998;&#26159;&#21098;&#26525;&#21644;&#29983;&#38271;&#26631;&#20934;&#65292;&#36825;&#20123;&#26631;&#20934;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#34987;&#21453;&#22797;&#24212;&#29992;&#20197;&#35843;&#25972;&#32593;&#32476;&#30340;&#31232;&#30095;&#36830;&#25509;&#12290;&#34429;&#28982;&#29983;&#38271;&#26631;&#20934;&#23545;DST&#24615;&#33021;&#30340;&#24433;&#21709;&#30456;&#23545;&#36739;&#22909;&#22320;&#30740;&#31350;&#20102;&#65292;&#20294;&#21098;&#26525;&#26631;&#20934;&#30340;&#24433;&#21709;&#20173;&#28982;&#34987;&#24573;&#35270;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#35774;&#35745;&#24182;&#36827;&#34892;&#20102;&#23545;&#21508;&#31181;&#21098;&#26525;&#26631;&#20934;&#30340;&#24191;&#27867;&#23454;&#35777;&#20998;&#26512;&#65292;&#20197;&#26356;&#22909;&#22320;&#20102;&#35299;&#23427;&#20204;&#23545; DST &#35299;&#20915;&#26041;&#26696;&#21160;&#24577;&#30340;&#24433;&#21709;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#25105;&#20204;&#21457;&#29616;&#22823;&#22810;&#25968;&#30740;&#31350;&#26041;&#27861;&#37117;&#20135;&#29983;&#31867;&#20284;&#30340;&#32467;&#26524;&#12290;&#22312;&#20302;&#23494;&#24230;&#33539;&#22260;&#20869;&#65292;&#26368;&#31616;&#21333;&#30340;&#25216;&#26415;&#8212;&#8212;&#22522;&#20110;&#22823;&#23567;&#30340;&#26041;&#27861;&#65292;&#25552;&#20379;&#20102;&#26368;&#20339;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dynamic Sparse Training (DST) is a rapidly evolving area of research that seeks to optimize the sparse initialization of a neural network by adapting its topology during training. It has been shown that under specific conditions, DST is able to outperform dense models. The key components of this framework are the pruning and growing criteria, which are repeatedly applied during the training process to adjust the network's sparse connectivity. While the growing criterion's impact on DST performance is relatively well studied, the influence of the pruning criterion remains overlooked. To address this issue, we design and perform an extensive empirical analysis of various pruning criteria to better understand their effect on the dynamics of DST solutions. Surprisingly, we find that most of the studied methods yield similar results. The differences become more significant in the low-density regime, where the best performance is predominantly given by the simplest technique: magnitude-based
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#39640;&#27010;&#29575;PAC-Bayes&#30028;&#38480;&#65292;&#22312;&#26377;&#30028;&#21644;&#19968;&#33324;&#23614;&#37096;&#34892;&#20026;&#30340;&#25439;&#22833;&#20013;&#22343;&#36866;&#29992;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#30028;&#38480;&#36824;&#33021;&#22815;&#20445;&#25345;&#38543;&#26102;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.12214</link><description>&lt;p&gt;
&#26356;&#22810;&#30340;PAC-Bayes Bounds&#65306;&#20174;&#26377;&#30028;&#25439;&#22833;&#21040;&#20855;&#26377;&#19968;&#33324;&#24615;&#23614;&#37096;&#34892;&#20026;&#30340;&#25439;&#22833;&#65292;&#21040;&#20219;&#20309;&#26102;&#38388;&#22343;&#26377;&#25928;&#30340;&#25439;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;
More PAC-Bayes bounds: From bounded losses, to losses with general tail behaviors, to anytime-validity. (arXiv:2306.12214v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12214
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#39640;&#27010;&#29575;PAC-Bayes&#30028;&#38480;&#65292;&#22312;&#26377;&#30028;&#21644;&#19968;&#33324;&#23614;&#37096;&#34892;&#20026;&#30340;&#25439;&#22833;&#20013;&#22343;&#36866;&#29992;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#30028;&#38480;&#36824;&#33021;&#22815;&#20445;&#25345;&#38543;&#26102;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#19981;&#21516;&#31867;&#22411;&#30340;&#25439;&#22833;&#25552;&#20986;&#20102;&#26032;&#30340;&#39640;&#27010;&#29575;PAC-Bayes&#30028;&#38480;&#12290;&#39318;&#20808;&#65292;&#38024;&#23545;&#26377;&#30028;&#33539;&#22260;&#30340;&#25439;&#22833;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Catoni&#30028;&#30340;&#21152;&#24378;&#29256;&#26412;&#65292;&#36866;&#29992;&#20110;&#25152;&#26377;&#21442;&#25968;&#20540;&#30340;&#32479;&#19968;&#30028;&#12290;&#36825;&#23548;&#33268;&#20102;&#26032;&#30340;&#24555;&#36895;&#36895;&#29575;&#21644;&#28151;&#21512;&#36895;&#29575;&#19978;&#38480;&#65292;&#36825;&#20123;&#19978;&#38480;&#21487;&#35299;&#37322;&#24615;&#24378;&#19988;&#27604;&#25991;&#29486;&#20013;&#20808;&#21069;&#30028;&#38480;&#26356;&#32039;&#12290;&#20854;&#27425;&#65292;&#38024;&#23545;&#26356;&#19968;&#33324;&#30340;&#23614;&#37096;&#34892;&#20026;&#30340;&#25439;&#22833;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#20010;&#26032;&#30340;&#26080;&#21442;&#25968;&#19978;&#38480;&#65306;&#24403;&#25439;&#22833;&#30340;&#32047;&#31215;&#29983;&#25104;&#20989;&#25968;&#26377;&#30028;&#26102;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;PAC-Bayes Chernoff&#31867;&#27604;&#65292;&#21478;&#19968;&#20010;&#19978;&#38480;&#26159;&#25439;&#22833;&#30340;&#20108;&#38454;&#30697;&#26377;&#30028;&#12290;&#36825;&#20004;&#20010;&#19978;&#38480;&#26159;&#21033;&#29992;&#19968;&#31181;&#22522;&#20110;&#21487;&#33021;&#20107;&#20214;&#31354;&#38388;&#30340;&#31163;&#25955;&#21270;&#30340;&#26032;&#25216;&#26415;&#33719;&#24471;&#30340;&#65292;&#8220;&#22312;&#27010;&#29575;&#8221;&#21442;&#25968;&#20248;&#21270;&#38382;&#39064;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#19968;&#31181;&#36866;&#29992;&#20110;&#20219;&#20309;&#29616;&#26377;&#30028;&#38480;&#30340;&#31616;&#21333;&#25216;&#26415;&#23558;&#25152;&#26377;&#20808;&#21069;&#32467;&#26524;&#25193;&#23637;&#21040;&#20219;&#20309;&#26102;&#38388;&#26377;&#25928;&#30340;&#19978;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we present new high-probability PAC-Bayes bounds for different types of losses. Firstly, for losses with a bounded range, we present a strengthened version of Catoni's bound that holds uniformly for all parameter values. This leads to new fast rate and mixed rate bounds that are interpretable and tighter than previous bounds in the literature. Secondly, for losses with more general tail behaviors, we introduce two new parameter-free bounds: a PAC-Bayes Chernoff analogue when the loss' cumulative generating function is bounded, and a bound when the loss' second moment is bounded. These two bounds are obtained using a new technique based on a discretization of the space of possible events for the "in probability" parameter optimization problem. Finally, we extend all previous results to anytime-valid bounds using a simple technique applicable to any existing bound.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20154;&#20307;&#24418;&#24577;&#12289;&#29983;&#29289;&#24615;&#21035;&#21644;&#23039;&#21183;&#23545;&#20110;&#24179;&#31227;&#25391;&#21160;&#20013;&#20154;&#20307;&#21160;&#21147;&#23398;&#21709;&#24212;&#30340;&#24433;&#21709;&#65292;&#24182;&#21019;&#24314;&#20102;&#22810;&#20010;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20197;&#30830;&#23450;&#26368;&#20855;&#24433;&#21709;&#30340;&#39044;&#27979;&#22240;&#23376;&#12290;</title><link>http://arxiv.org/abs/2306.12115</link><description>&lt;p&gt;
&#38543;&#26426;&#25391;&#21160;&#20013;&#20154;&#20307;&#21453;&#24212;&#30340;&#35299;&#37322;&#65306;&#36816;&#21160;&#26041;&#21521;&#12289;&#22352;&#23039;&#21644;&#20154;&#20307;&#27979;&#37327;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Explaining human body responses in random vibration: Effect of motion direction, sitting posture, and anthropometry. (arXiv:2306.12115v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12115
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20154;&#20307;&#24418;&#24577;&#12289;&#29983;&#29289;&#24615;&#21035;&#21644;&#23039;&#21183;&#23545;&#20110;&#24179;&#31227;&#25391;&#21160;&#20013;&#20154;&#20307;&#21160;&#21147;&#23398;&#21709;&#24212;&#30340;&#24433;&#21709;&#65292;&#24182;&#21019;&#24314;&#20102;&#22810;&#20010;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#20197;&#30830;&#23450;&#26368;&#20855;&#24433;&#21709;&#30340;&#39044;&#27979;&#22240;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35843;&#26597;&#20102;&#20154;&#20307;&#24418;&#24577;&#12289;&#29983;&#29289;&#24615;&#21035;&#21644;&#23039;&#21183;&#23545;&#20110;&#24179;&#31227;&#25391;&#21160;&#20013;&#20154;&#20307;&#21160;&#21147;&#23398;&#21709;&#24212;&#30340;&#24433;&#21709;&#12290;35&#21517;&#21442;&#19982;&#32773;&#22352;&#22312;&#26631;&#20934;&#27773;&#36710;&#24231;&#26885;&#19978;&#65292;&#20351;&#29992;&#22522;&#20110;&#36816;&#21160;&#30340;&#24179;&#21488;&#26045;&#21152;0.1&#33267;12.0&#36203;&#20857;&#30340;&#38543;&#26426;&#20449;&#21495;&#25391;&#21160;&#65292;RMS&#21152;&#36895;&#24230;&#20026;0.3 m / s2&#65292;&#25345;&#32493;60&#31186;&#12290;&#21019;&#24314;&#20102;&#22810;&#20010;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#65292;&#20197;&#30830;&#23450;&#39057;&#22495;&#20869;&#27599;&#20010;&#36523;&#20307;&#27573;&#65288;&#39592;&#30406;&#12289;&#36527;&#24178;&#21644;&#22836;&#37096;&#65289;&#30340;&#23792;&#20540;&#24179;&#31227;&#22686;&#30410;&#26368;&#26377;&#24433;&#21709;&#30340;&#39044;&#27979;&#22240;&#23376;&#12290;&#27169;&#22411;&#23558;&#23454;&#39564;&#25805;&#20316;&#22240;&#23376;&#65288;&#36816;&#21160;&#26041;&#21521;&#12289;&#23039;&#21183;&#12289;&#27979;&#37327;&#30340;&#20154;&#20307;&#27979;&#37327;&#23646;&#24615;&#21644;&#29983;&#29289;&#24615;&#21035;&#65289;&#20316;&#20026;&#39044;&#27979;&#22240;&#23376;&#12290;&#35780;&#20272;&#20102;&#21253;&#25324;&#39044;&#27979;&#22240;&#23376;&#23545;&#27169;&#22411;&#25311;&#21512;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
This study investigates the effects of anthropometric attributes, biological sex, and posture on translational body kinematic responses in translational vibrations. In total, 35 participants were recruited. Perturbations were applied on a standard car seat using a motion-based platform with 0.1 to 12.0 Hz random noise signals, with 0.3 m/s2 rms acceleration, for 60 seconds. Multiple linear regression models (three basic models and one advanced model, including interactions between predictors) were created to determine the most influential predictors of peak translational gains in the frequency domain per body segment (pelvis, trunk, and head). The models introduced experimentally manipulated factors (motion direction, posture, measured anthropometric attributes, and biological sex) as predictors. Effects of included predictors on the model fit were estimated. Basic linear regression models could explain over 70% of peak body segments' kinematic body response (where the R2 adjusted was 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#38543;&#26426;&#21452;&#23618;&#20248;&#21270;&#30340;&#26368;&#20248;&#31639;&#27861;&#65292;&#36991;&#20813;&#20102;&#20351;&#29992;&#39640;&#38454;&#20809;&#28369;&#24615;&#20551;&#35774;&#65292;&#33021;&#22815;&#26356;&#22909;&#22320;&#36866;&#24212;&#38750;&#20984;&#35774;&#32622;&#12290;</title><link>http://arxiv.org/abs/2306.12067</link><description>&lt;p&gt;
&#26494;&#24347;&#20809;&#28369;&#26465;&#20214;&#19979;&#38543;&#26426;&#21452;&#23618;&#20248;&#21270;&#30340;&#26368;&#20248;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Optimal Algorithms for Stochastic Bilevel Optimization under Relaxed Smoothness Conditions. (arXiv:2306.12067v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12067
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#38543;&#26426;&#21452;&#23618;&#20248;&#21270;&#30340;&#26368;&#20248;&#31639;&#27861;&#65292;&#36991;&#20813;&#20102;&#20351;&#29992;&#39640;&#38454;&#20809;&#28369;&#24615;&#20551;&#35774;&#65292;&#33021;&#22815;&#26356;&#22909;&#22320;&#36866;&#24212;&#38750;&#20984;&#35774;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#21452;&#23618;&#20248;&#21270;&#36890;&#24120;&#28041;&#21450;&#26368;&#23567;&#21270;&#20381;&#36182;&#20110;&#24378;&#20984;&#19979;&#23618;&#20989;&#25968;&#30340;&#19979;&#23618;&#20989;&#25968;&#65288;LL&#65289;&#26368;&#23567;&#20540;&#30340;&#19978;&#23618;&#65288;UL&#65289;&#20989;&#25968;&#12290;&#20960;&#31181;&#31639;&#27861;&#21033;&#29992;Neumann&#32423;&#25968;&#26469;&#36817;&#20284;&#20272;&#35745;&#38544;&#24335;&#26799;&#24230;&#65288;&#36229;&#26799;&#24230;&#65289;&#30340;&#30697;&#38453;&#36870;&#12290;&#26368;&#20808;&#36827;&#30340;&#38543;&#26426;&#21452;&#23618;&#31639;&#27861;&#65288;SOBA&#65289;[16]&#25913;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#26469;&#35299;&#20915;&#19982;&#26174;&#24335;&#30697;&#38453;&#21453;&#28436;&#30456;&#20851;&#30340;&#32447;&#24615;&#31995;&#32479;&#12290;&#35813;&#20462;&#25913;&#20351;SOBA&#33021;&#22815;&#22312;&#38750;&#20984;&#35774;&#32622;&#20013;&#21305;&#37197;&#21333;&#23618;&#23545;&#24212;&#39033;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#19979;&#38480;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#24403;&#21069;SOBA&#30340;&#20998;&#26512;&#20381;&#36182;&#20110;UL&#21644;LL&#20989;&#25968;&#30340;&#39640;&#38454;&#20809;&#28369;&#24615;&#20551;&#35774;&#20197;&#23454;&#29616;&#26368;&#20248;&#24615;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#38543;&#26426;&#21452;&#23618;&#20248;&#21270;&#30340;&#19968;&#31181;&#26032;&#22411;&#23436;&#20840;&#21333;&#24490;&#29615;&#19988;&#26080;Hessian&#21453;&#28436;&#31639;&#27861;&#26694;&#26550;&#65292;&#24182;&#22312;&#26631;&#20934;&#20809;&#28369;&#24615;&#20551;&#35774;&#19979;&#25552;&#20379;&#20102;&#26356;&#32039;&#23494;&#30340;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic Bilevel optimization usually involves minimizing an upper-level (UL) function that is dependent on the arg-min of a strongly-convex lower-level (LL) function. Several algorithms utilize Neumann series to approximate certain matrix inverses involved in estimating the implicit gradient of the UL function (hypergradient). The state-of-the-art StOchastic Bilevel Algorithm (SOBA) [16] instead uses stochastic gradient descent steps to solve the linear system associated with the explicit matrix inversion. This modification enables SOBA to match the lower bound of sample complexity for the single-level counterpart in non-convex settings. Unfortunately, the current analysis of SOBA relies on the assumption of higher-order smoothness for the UL and LL functions to achieve optimality. In this paper, we introduce a novel fully single-loop and Hessian-inversion-free algorithmic framework for stochastic bilevel optimization and present a tighter analysis under standard smoothness assumpti
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#31639;&#27861;&#65292;&#20174;&#20010;&#20307;&#20844;&#24179;&#20998;&#24067;&#20013;&#37319;&#26679;&#25490;&#21517;&#65292;&#21516;&#26102;&#30830;&#20445;&#27599;&#20010;&#36755;&#20986;&#30340;&#25490;&#21517;&#37117;&#28385;&#36275;&#32676;&#20307;&#20844;&#24179;&#24615;&#32422;&#26463;&#12290;&#36755;&#20986;&#25490;&#21517;&#30340;&#26399;&#26395;&#25928;&#29992;&#33267;&#23569;&#26159;&#26368;&#20248;&#20844;&#24179;&#35299;&#30340;&#25928;&#29992;&#30340;$\alpha$&#20493;&#65292;&#20854;&#20013;$\alpha$&#26159;&#19968;&#20010;&#37327;&#21270;&#20844;&#24179;&#32422;&#26463;&#32039;&#24230;&#30340;&#21442;&#25968;&#12290;</title><link>http://arxiv.org/abs/2306.11964</link><description>&lt;p&gt;
&#37319;&#26679;&#20010;&#20307;&#20844;&#24179;&#19988;&#28385;&#36275;&#32676;&#20307;&#20844;&#24179;&#30340;&#25490;&#21517;
&lt;/p&gt;
&lt;p&gt;
Sampling Individually-Fair Rankings that are Always Group Fair. (arXiv:2306.11964v1 [cs.CY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11964
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#31639;&#27861;&#65292;&#20174;&#20010;&#20307;&#20844;&#24179;&#20998;&#24067;&#20013;&#37319;&#26679;&#25490;&#21517;&#65292;&#21516;&#26102;&#30830;&#20445;&#27599;&#20010;&#36755;&#20986;&#30340;&#25490;&#21517;&#37117;&#28385;&#36275;&#32676;&#20307;&#20844;&#24179;&#24615;&#32422;&#26463;&#12290;&#36755;&#20986;&#25490;&#21517;&#30340;&#26399;&#26395;&#25928;&#29992;&#33267;&#23569;&#26159;&#26368;&#20248;&#20844;&#24179;&#35299;&#30340;&#25928;&#29992;&#30340;$\alpha$&#20493;&#65292;&#20854;&#20013;$\alpha$&#26159;&#19968;&#20010;&#37327;&#21270;&#20844;&#24179;&#32422;&#26463;&#32039;&#24230;&#30340;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#24179;&#21488;&#19978;&#30340;&#25490;&#21517;&#21487;&#20197;&#24110;&#21161;&#29992;&#25143;&#24555;&#36895;&#25214;&#21040;&#30456;&#20851;&#20449;&#24687;&#65292;&#22914;&#20154;&#29289;&#12289;&#26032;&#38395;&#12289;&#23186;&#20307;&#21644;&#20135;&#21697;&#12290;&#20844;&#24179;&#25490;&#21517;&#26159;&#19968;&#31181;&#20026;&#20102;&#28385;&#36275;&#32676;&#20307;&#20844;&#24179;&#24615;&#32422;&#26463;&#32780;&#20248;&#21270;&#19968;&#32452;&#39033;&#30446;&#25490;&#21517;&#30340;&#20219;&#21153;&#65292;&#24050;&#32463;&#22312;&#31639;&#27861;&#20844;&#24179;&#24615;&#12289;&#20449;&#24687;&#26816;&#32034;&#21644;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#36817;&#26399;&#30340;&#30740;&#31350;&#34920;&#26126;&#39033;&#30446;&#25928;&#29992;&#30340;&#19981;&#30830;&#23450;&#24615;&#26159;&#19981;&#20844;&#24179;&#30340;&#20027;&#35201;&#21407;&#22240;&#65292;&#24182;&#24314;&#35758;&#22312;&#36755;&#20986;&#20013;&#24341;&#20837;&#38543;&#26426;&#24615;&#12290;&#36825;&#31181;&#38543;&#26426;&#24615;&#32463;&#36807;&#20180;&#32454;&#36873;&#25321;&#65292;&#20197;&#30830;&#20445;&#23545;&#27599;&#20010;&#39033;&#30446;&#36827;&#34892;&#20805;&#20998;&#19988;&#21512;&#29702;&#30340;&#20195;&#34920;&#65288;&#21516;&#26102;&#32771;&#34385;&#19981;&#30830;&#23450;&#24615;&#65289;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#36825;&#31181;&#38543;&#26426;&#24615;&#65292;&#36755;&#20986;&#30340;&#25490;&#21517;&#21487;&#33021;&#20250;&#36829;&#21453;&#32676;&#20307;&#20844;&#24179;&#24615;&#32422;&#26463;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26377;&#25928;&#30340;&#31639;&#27861;&#65292;&#20174;&#19968;&#20010;&#20010;&#20307;&#20844;&#24179;&#20998;&#24067;&#20013;&#25277;&#26679;&#25490;&#21517;&#65292;&#21516;&#26102;&#30830;&#20445;&#27599;&#20010;&#36755;&#20986;&#30340;&#25490;&#21517;&#37117;&#28385;&#36275;&#32676;&#20307;&#20844;&#24179;&#24615;&#32422;&#26463;&#12290;&#36755;&#20986;&#25490;&#21517;&#30340;&#26399;&#26395;&#25928;&#29992;&#33267;&#23569;&#26159;&#26368;&#20248;&#20844;&#24179;&#35299;&#30340;&#25928;&#29992;&#30340; $\alpha$ &#20493;&#65292;&#20854;&#20013; $\alpha$ &#26159;&#19968;&#20010;&#37327;&#21270;&#20844;&#24179;&#32422;&#26463;&#32039;&#24230;&#30340;&#21442;&#25968;&#12290;&#25105;&#20204;&#22312;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#31639;&#27861;&#30340;&#39640;&#25928;&#24615;&#21644;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Rankings on online platforms help their end-users find the relevant information -- people, news, media, and products -- quickly. Fair ranking tasks, which ask to rank a set of items to maximize utility subject to satisfying group-fairness constraints, have gained significant interest in the Algorithmic Fairness, Information Retrieval, and Machine Learning literature. Recent works, however, identify uncertainty in the utilities of items as a primary cause of unfairness and propose introducing randomness in the output. This randomness is carefully chosen to guarantee an adequate representation of each item (while accounting for the uncertainty). However, due to this randomness, the output rankings may violate group fairness constraints. We give an efficient algorithm that samples rankings from an individually-fair distribution while ensuring that every output ranking is group fair. The expected utility of the output ranking is at least $\alpha$ times the utility of the optimal fair solut
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#27979;&#24230;&#19978;&#32534;&#20889;&#21464;&#20998;&#30446;&#26631;&#30340;&#21160;&#26426;&#65292;&#25552;&#20986;&#36890;&#36807;&#27492;&#31867;&#30446;&#26631;&#25512;&#23548;&#23454;&#29992;&#31639;&#27861;&#65292;&#20197;&#35299;&#20915;&#36229;&#20986;&#20998;&#24067;&#30340;&#27867;&#21270;&#21644;&#24369;&#30417;&#30563;&#23398;&#20064;&#31561;&#38382;&#39064;&#30340;&#24320;&#25918;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.11928</link><description>&lt;p&gt;
&#24320;&#25918;&#38382;&#39064;&#65306;&#22522;&#20110;&#21464;&#20998;&#30446;&#26631;&#30340;&#27979;&#24230;&#23398;&#20064; (arXiv:2306.11928v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
Open Problem: Learning with Variational Objectives on Measures. (arXiv:2306.11928v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11928
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#27979;&#24230;&#19978;&#32534;&#20889;&#21464;&#20998;&#30446;&#26631;&#30340;&#21160;&#26426;&#65292;&#25552;&#20986;&#36890;&#36807;&#27492;&#31867;&#30446;&#26631;&#25512;&#23548;&#23454;&#29992;&#31639;&#27861;&#65292;&#20197;&#35299;&#20915;&#36229;&#20986;&#20998;&#24067;&#30340;&#27867;&#21270;&#21644;&#24369;&#30417;&#30563;&#23398;&#20064;&#31561;&#38382;&#39064;&#30340;&#24320;&#25918;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#20851;&#27880;&#30340;&#26159;&#22522;&#20110;&#20989;&#25968;&#30340;&#21464;&#20998;&#30446;&#26631;&#12290;&#26412;&#25991;&#35752;&#35770;&#20102;&#22312;&#27979;&#24230;&#19978;&#32534;&#20889;&#31867;&#20284;&#30446;&#26631;&#30340;&#21160;&#26426;&#65292;&#29305;&#21035;&#26159;&#35752;&#35770;&#20102;&#36229;&#20986;&#20998;&#24067;&#30340;&#27867;&#21270;&#21644;&#24369;&#30417;&#30563;&#23398;&#20064;&#12290;&#36825;&#24341;&#21457;&#20102;&#19968;&#20010;&#33258;&#28982;&#30340;&#38382;&#39064;&#65306;&#33021;&#21542;&#23558;&#36890;&#24120;&#30340;&#32479;&#35745;&#23398;&#20064;&#32467;&#26524;&#36716;&#21270;&#20026;&#22522;&#20110;&#27979;&#37327;&#34920;&#36798;&#30340;&#30446;&#26631;&#65311;&#32467;&#26524;&#26500;&#24314;&#26159;&#21542;&#20250;&#23548;&#33268;&#26032;&#30340;&#23454;&#29992;&#31639;&#27861;&#65311;
&lt;/p&gt;
&lt;p&gt;
The theory of statistical learning has focused on variational objectives expressed on functions. In this note, we discuss motivations to write similar objectives on measures, in particular to discuss out-of-distribution generalization and weakly-supervised learning. It raises a natural question: can one cast usual statistical learning results to objectives expressed on measures? Does the resulting construction lead to new algorithms of practical interest?
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38543;&#26426;&#24179;&#28369;&#26041;&#27861;&#65292;&#21487;&#20197;&#26681;&#25454;&#22270;&#30340;&#19981;&#21516;&#39044;&#23450;&#20041;&#32467;&#26500;&#29983;&#25104;&#23545;&#24212;&#30340;&#40065;&#26834;&#24615;&#35777;&#20070;&#65292;&#20174;&#32780;&#22312;&#22810;&#20010;&#22522;&#20934;&#22270;&#20998;&#31867;&#20219;&#21153;&#20013;&#21462;&#24471;&#39046;&#20808;&#30340;&#23545;&#25239;&#24615;&#25915;&#20987;&#19979;&#40065;&#26834;&#24615;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.11915</link><description>&lt;p&gt;
&#22270;&#20998;&#31867;&#38382;&#39064;&#20013;&#32467;&#26500;&#24863;&#30693;&#30340;&#40065;&#26834;&#24615;&#35748;&#35777;
&lt;/p&gt;
&lt;p&gt;
Structure-Aware Robustness Certificates for Graph Classification. (arXiv:2306.11915v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11915
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38543;&#26426;&#24179;&#28369;&#26041;&#27861;&#65292;&#21487;&#20197;&#26681;&#25454;&#22270;&#30340;&#19981;&#21516;&#39044;&#23450;&#20041;&#32467;&#26500;&#29983;&#25104;&#23545;&#24212;&#30340;&#40065;&#26834;&#24615;&#35777;&#20070;&#65292;&#20174;&#32780;&#22312;&#22810;&#20010;&#22522;&#20934;&#22270;&#20998;&#31867;&#20219;&#21153;&#20013;&#21462;&#24471;&#39046;&#20808;&#30340;&#23545;&#25239;&#24615;&#25915;&#20987;&#19979;&#40065;&#26834;&#24615;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#22522;&#20110;&#22270;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#36827;&#34892;&#40065;&#26834;&#24615;&#35748;&#35777;&#26159;&#20445;&#35777;&#23433;&#20840;&#24615;&#30340;&#19968;&#20010;&#33267;&#20851;&#37325;&#35201;&#30340;&#25361;&#25112;&#12290;&#30446;&#21069;&#29992;&#20110;&#22270;&#20998;&#31867;&#22120;&#30340;&#40065;&#26834;&#24615;&#35777;&#26126;&#20445;&#35777;&#19982;&#33410;&#28857;&#23545;&#32763;&#36716;&#65288;&#28155;&#21152;&#25110;&#21024;&#38500;&#36793;&#32536;&#65289;&#30340;&#24635;&#25968;&#26377;&#20851;&#65292;&#36825;&#30456;&#24403;&#20110;&#20197;&#37051;&#25509;&#30697;&#38453;&#20026;&#20013;&#24515;&#30340;l0&#29699;&#12290;&#23613;&#31649;&#20174;&#29702;&#35770;&#19978;&#30475;&#24456;&#26377;&#21560;&#24341;&#21147;&#65292;&#20294;&#36825;&#31181;&#21508;&#21521;&#21516;&#24615;&#30340;&#32467;&#26500;&#22122;&#22768;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#21487;&#33021;&#36807;&#20110;&#20005;&#26684;&#65292;&#22240;&#20026;&#26377;&#20123;&#33410;&#28857;&#23545;&#20110;&#30830;&#23450;&#20998;&#31867;&#22120;&#30340;&#36755;&#20986;&#26356;&#20026;&#20851;&#38190;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#35777;&#20070;&#32473;&#20986;&#20102;&#23545;&#22270;&#27169;&#22411;&#40065;&#26834;&#24615;&#30340;&#24754;&#35266;&#25551;&#36848;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#24179;&#28369;&#30340;&#26041;&#27861;&#65292;&#23558;&#38750;&#21508;&#21521;&#21516;&#24615;&#30340;&#22122;&#22768;&#20998;&#24067;&#28155;&#21152;&#21040;&#36755;&#20837;&#22270;&#32467;&#26500;&#20013;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#36807;&#31243;&#20026;&#20998;&#31867;&#22120;&#29983;&#25104;&#20102;&#32467;&#26500;&#24863;&#30693;&#30340;&#35777;&#20070;&#65292;&#22240;&#27492;&#40065;&#26834;&#24615;&#35777;&#20070;&#30340;&#22823;&#23567;&#21487;&#20197;&#22312;&#22270;&#30340;&#19981;&#21516;&#39044;&#23450;&#20041;&#32467;&#26500;&#20043;&#38388;&#21464;&#21270;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#22522;&#20934;&#22270;&#20998;&#31867;&#20219;&#21153;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#20248;&#21183;&#65292;&#22312;&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#40065;&#26834;&#24615;&#26041;&#38754;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Certifying the robustness of a graph-based machine learning model poses a critical challenge for safety. Current robustness certificates for graph classifiers guarantee output invariance with respect to the total number of node pair flips (edge addition or edge deletion), which amounts to an $l_{0}$ ball centred on the adjacency matrix. Although theoretically attractive, this type of isotropic structural noise can be too restrictive in practical scenarios where some node pairs are more critical than others in determining the classifier's output. The certificate, in this case, gives a pessimistic depiction of the robustness of the graph model. To tackle this issue, we develop a randomised smoothing method based on adding an anisotropic noise distribution to the input graph structure. We show that our process generates structural-aware certificates for our classifiers, whereby the magnitude of robustness certificates can vary across different pre-defined structures of the graph. We demon
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#26641;&#29983;&#38271;&#35268;&#21017;&#65292;&#20351;&#24191;&#20041;&#38543;&#26426;&#26862;&#26519;&#22312;&#26080;&#26799;&#24230;&#20248;&#21270;&#30340;&#24773;&#20917;&#19979;&#22823;&#22823;&#33410;&#30465;&#20102;&#26102;&#38388;&#12290;</title><link>http://arxiv.org/abs/2306.11908</link><description>&lt;p&gt;
&#22522;&#20110;&#23450;&#28857;&#26641;&#30340;&#24191;&#20041;&#38543;&#26426;&#26862;&#26519;&#21152;&#36895;
&lt;/p&gt;
&lt;p&gt;
Accelerating Generalized Random Forests with Fixed-Point Trees. (arXiv:2306.11908v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11908
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#26641;&#29983;&#38271;&#35268;&#21017;&#65292;&#20351;&#24191;&#20041;&#38543;&#26426;&#26862;&#26519;&#22312;&#26080;&#26799;&#24230;&#20248;&#21270;&#30340;&#24773;&#20917;&#19979;&#22823;&#22823;&#33410;&#30465;&#20102;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24191;&#20041;&#38543;&#26426;&#26862;&#26519;&#24314;&#31435;&#22312;&#20256;&#32479;&#38543;&#26426;&#26862;&#26519;&#30340;&#22522;&#30784;&#19978;&#65292;&#36890;&#36807;&#23558;&#20854;&#20316;&#20026;&#33258;&#36866;&#24212;&#26680;&#21152;&#26435;&#31639;&#27861;&#26469;&#26500;&#24314;&#20272;&#31639;&#22120;&#65292;&#24182;&#36890;&#36807;&#22522;&#20110;&#26799;&#24230;&#30340;&#26641;&#29983;&#38271;&#36807;&#31243;&#26469;&#23454;&#29616;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26641;&#29983;&#38271;&#35268;&#21017;&#65292;&#22522;&#20110;&#23450;&#28857;&#36845;&#20195;&#36817;&#20284;&#34920;&#31034;&#26799;&#24230;&#36817;&#20284;&#65292;&#23454;&#29616;&#20102;&#26080;&#26799;&#24230;&#20248;&#21270;&#65292;&#24182;&#20026;&#27492;&#24320;&#21457;&#20102;&#28176;&#36817;&#29702;&#35770;&#12290;&#36825;&#26377;&#25928;&#22320;&#33410;&#30465;&#20102;&#26102;&#38388;&#65292;&#23588;&#20854;&#26159;&#22312;&#30446;&#26631;&#37327;&#30340;&#32500;&#24230;&#36866;&#20013;&#26102;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generalized random forests arXiv:1610.01271 build upon the well-established success of conventional forests (Breiman, 2001) to offer a flexible and powerful non-parametric method for estimating local solutions of heterogeneous estimating equations. Estimators are constructed by leveraging random forests as an adaptive kernel weighting algorithm and implemented through a gradient-based tree-growing procedure. By expressing this gradient-based approximation as being induced from a single Newton-Raphson root-finding iteration, and drawing upon the connection between estimating equations and fixed-point problems arXiv:2110.11074, we propose a new tree-growing rule for generalized random forests induced from a fixed-point iteration type of approximation, enabling gradient-free optimization, and yielding substantial time savings for tasks involving even modest dimensionality of the target quantity (e.g. multiple/multi-level treatment effects). We develop an asymptotic theory for estimators o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21363;&#23398;&#20064;&#21512;&#36866;&#30340;&#25104;&#26412;&#32467;&#26500;&#26469;&#40723;&#21169;&#26144;&#23556;&#27839;&#30528;&#29305;&#23450;&#30340;&#24037;&#31243;&#29305;&#24449;&#26469;&#20256;&#36865;&#28857;&#65292;&#20854;&#22312;&#25193;&#23637; Monge-Bregman-Occam &#31649;&#36947;&#26041;&#38754;&#20570;&#20986;&#20102;&#37325;&#22823;&#36129;&#29486;&#65292;&#24182;&#22312;&#21305;&#37197;&#30452;&#26041;&#22270;&#26041;&#38754;&#34920;&#29616;&#20986;&#20102;&#20248;&#24322;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.11895</link><description>&lt;p&gt;
&#23398;&#20064;&#32467;&#26500;&#33945;&#26085;&#20301;&#31227;&#30340;&#25104;&#26412;
&lt;/p&gt;
&lt;p&gt;
Learning Costs for Structured Monge Displacements. (arXiv:2306.11895v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11895
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21363;&#23398;&#20064;&#21512;&#36866;&#30340;&#25104;&#26412;&#32467;&#26500;&#26469;&#40723;&#21169;&#26144;&#23556;&#27839;&#30528;&#29305;&#23450;&#30340;&#24037;&#31243;&#29305;&#24449;&#26469;&#20256;&#36865;&#28857;&#65292;&#20854;&#22312;&#25193;&#23637; Monge-Bregman-Occam &#31649;&#36947;&#26041;&#38754;&#20570;&#20986;&#20102;&#37325;&#22823;&#36129;&#29486;&#65292;&#24182;&#22312;&#21305;&#37197;&#30452;&#26041;&#22270;&#26041;&#38754;&#34920;&#29616;&#20986;&#20102;&#20248;&#24322;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#20248;&#36755;&#36816;&#29702;&#35770;&#20026;&#26426;&#22120;&#23398;&#20064;&#25552;&#20379;&#20102;&#22810;&#31181;&#25512;&#26029;&#26679;&#26412;&#38388;&#23494;&#24230;&#21069;&#21521;&#26144;&#23556;&#30340;&#24037;&#20855;&#12290;&#23613;&#31649;&#26368;&#36817;&#22312;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#20013;&#35813;&#29702;&#35770;&#24050;&#32463;&#35265;&#35777;&#20102;&#35768;&#22810;&#26041;&#27861;&#30340;&#21457;&#23637;&#65292;&#20294;&#20854;&#23454;&#38469;&#23454;&#29616;&#20173;&#28982;&#26497;&#20854;&#22256;&#38590;&#65292;&#22240;&#20026;&#23427;&#21516;&#26102;&#38754;&#20020;&#35745;&#31639;&#21644;&#32479;&#35745;&#19978;&#30340;&#25361;&#25112;&#12290;&#29616;&#26377;&#26041;&#27861;&#24456;&#23569;&#26377;&#19981;&#20351;&#29992;&#40664;&#35748;&#36873;&#25321;&#26469;&#20272;&#35745;&#36825;&#20123;&#26144;&#23556;&#30340;&#24773;&#20917;&#65292;&#20854;&#20013;&#31616;&#21333;&#30340;&#24179;&#26041;&#27431;&#27663;&#36317;&#31163;&#20316;&#20026;&#22320;&#38754;&#36153;&#29992;$c(x,y)=\|x-y\|^2_2$&#12290;&#25105;&#20204;&#22312;&#26412;&#25991;&#20013;&#37319;&#21462;&#19981;&#21516;&#30340;&#26041;&#27861;&#65292;&#20197;\emph{&#23398;&#20064;}&#21512;&#36866;&#30340;&#25104;&#26412;&#32467;&#26500;&#65292;&#40723;&#21169;&#26144;&#23556;&#27839;&#30528;&#29305;&#23450;&#30340;&#24037;&#31243;&#29305;&#24449;&#26469;&#20256;&#36865;&#28857;&#12290;&#25105;&#20204;&#23558;&#26368;&#36817;&#25552;&#20986;&#30340; Monge-Bregman-Occam &#31649;&#36947;~\citep{cuturi2023monge} &#30340;&#33539;&#24335;&#36827;&#34892;&#20102;&#25193;&#23637;&#65292;&#35813;&#33539;&#24335;&#22522;&#20110;&#26367;&#20195;&#30340;&#25104;&#26412;&#20844;&#24335;$c(x,y)=h(x-y)$ &#65292;&#23427;&#20063;&#26159;&#25104;&#26412;&#19981;&#21464;&#30340;&#65292;&#20294;&#37319;&#29992;&#26356;&#19968;&#33324;&#30340;&#24418;&#24335;$h=\tfrac12 \ell_2^2+\tau$&#65292;&#20854;&#20013;$\tau$&#26159;&#36866;&#24403;&#30340;&#20984;&#35268;&#21017;&#39033;&#12290;
&lt;/p&gt;
&lt;p&gt;
Optimal transport theory has provided machine learning with several tools to infer a push-forward map between densities from samples. While this theory has recently seen tremendous methodological developments in machine learning, its practical implementation remains notoriously difficult, because it is plagued by both computational and statistical challenges. Because of such difficulties, existing approaches rarely depart from the default choice of estimating such maps with the simple squared-Euclidean distance as the ground cost, $c(x,y)=\|x-y\|^2_2$. We follow a different path in this work, with the motivation of \emph{learning} a suitable cost structure to encourage maps to transport points along engineered features. We extend the recently proposed Monge-Bregman-Occam pipeline~\citep{cuturi2023monge}, that rests on an alternative cost formulation that is also cost-invariant $c(x,y)=h(x-y)$, but which adopts a more general form as $h=\tfrac12 \ell_2^2+\tau$, where $\tau$ is an approp
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#20110;&#24322;&#36136;&#31181;&#32676;&#26377;&#23475;&#23454;&#39564;&#30340;&#26089;&#26399;&#20572;&#27490;&#26041;&#27861;CLASH&#65292;&#20351;&#29992;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#21487;&#20197;&#26377;&#25928;&#25552;&#21069;&#20572;&#27490;&#20020;&#24202;&#35797;&#39564;&#21644;A/B&#27979;&#35797;&#12290;</title><link>http://arxiv.org/abs/2306.11839</link><description>&lt;p&gt;
&#26159;&#21542;&#24212;&#35813;&#20572;&#27490;&#65306;&#20855;&#26377;&#24322;&#36136;&#31181;&#32676;&#30340;&#26089;&#26399;&#20572;&#27490;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Should I Stop or Should I Go: Early Stopping with Heterogeneous Populations. (arXiv:2306.11839v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11839
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#20110;&#24322;&#36136;&#31181;&#32676;&#26377;&#23475;&#23454;&#39564;&#30340;&#26089;&#26399;&#20572;&#27490;&#26041;&#27861;CLASH&#65292;&#20351;&#29992;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#21487;&#20197;&#26377;&#25928;&#25552;&#21069;&#20572;&#27490;&#20020;&#24202;&#35797;&#39564;&#21644;A/B&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#23454;&#39564;&#30001;&#20110;&#27835;&#30103;&#36896;&#25104;&#24847;&#22806;&#30340;&#26377;&#23475;&#24433;&#21709;&#65292;&#22240;&#27492;&#24448;&#24448;&#38656;&#35201;&#25552;&#21069;&#20572;&#27490;&#12290;&#30446;&#21069;&#30830;&#23450;&#20309;&#26102;&#25552;&#21069;&#32456;&#27490;&#23454;&#39564;&#30340;&#29616;&#26377;&#26041;&#27861;&#36890;&#24120;&#36866;&#29992;&#20110;&#24635;&#20307;&#25968;&#25454;&#65292;&#19981;&#32771;&#34385;&#27835;&#30103;&#25928;&#24212;&#30340;&#24322;&#36136;&#24615;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#38024;&#23545;&#24322;&#36136;&#31181;&#32676;&#26377;&#23475;&#23454;&#39564;&#30340;&#26089;&#26399;&#20572;&#27490;&#26041;&#27861;&#12290;&#25105;&#20204;&#39318;&#20808;&#30830;&#23450;&#29616;&#26377;&#26041;&#27861;&#22312;&#27835;&#30103;&#23545;&#23569;&#25968;&#21442;&#19982;&#32773;&#36896;&#25104;&#20260;&#23475;&#26102;&#24448;&#24448;&#26080;&#27861;&#20572;&#27490;&#23454;&#39564;&#12290;&#28982;&#21518;&#20351;&#29992;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#24320;&#21457;&#20102;CLASH&#65292;&#36825;&#26159;&#39318;&#20010;&#24191;&#27867;&#36866;&#29992;&#20110;&#24322;&#36136;&#26089;&#26399;&#20572;&#27490;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#22312;&#27169;&#25311;&#21644;&#23454;&#38469;&#25968;&#25454;&#19978;&#23637;&#31034;&#20102;CLASH&#30340;&#34920;&#29616;&#65292;&#24182;&#35777;&#26126;&#23427;&#22312;&#20020;&#24202;&#35797;&#39564;&#21644;A/B&#27979;&#35797;&#20013;&#37117;&#33021;&#26377;&#25928;&#25552;&#21069;&#20572;&#27490;&#12290;
&lt;/p&gt;
&lt;p&gt;
Randomized experiments often need to be stopped prematurely due to the treatment having an unintended harmful effect. Existing methods that determine when to stop an experiment early are typically applied to the data in aggregate and do not account for treatment effect heterogeneity. In this paper, we study the early stopping of experiments for harm on heterogeneous populations. We first establish that current methods often fail to stop experiments when the treatment harms a minority group of participants. We then use causal machine learning to develop CLASH, the first broadly-applicable method for heterogeneous early stopping. We demonstrate CLASH's performance on simulated and real data and show that it yields effective early stopping for both clinical trials and A/B tests.
&lt;/p&gt;</description></item><item><title>&#25299;&#25169;&#35270;&#24046;&#26159;&#19968;&#31181;&#27604;&#36739;&#35757;&#32451;&#27169;&#22411;&#21644;&#21442;&#32771;&#25968;&#25454;&#38598;&#22810;&#23610;&#24230;&#20960;&#20309;&#32467;&#26500;&#30456;&#20284;&#24615;&#30340;&#29702;&#35770;&#21644;&#35745;&#31639;&#24037;&#20855;&#65292;&#23427;&#21487;&#20197;&#20272;&#35745;&#27169;&#22411;&#20013;&#30340;&#25299;&#25169;&#29305;&#24449;&#65292;&#26377;&#21161;&#20110;&#29702;&#35299;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#34892;&#20026;&#21644;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.11835</link><description>&lt;p&gt;
&#25299;&#25169;&#35270;&#24046;&#65306;&#28145;&#24230;&#24863;&#30693;&#27169;&#22411;&#30340;&#20960;&#20309;&#35268;&#33539;&#35828;&#26126;
&lt;/p&gt;
&lt;p&gt;
Topological Parallax: A Geometric Specification for Deep Perception Models. (arXiv:2306.11835v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11835
&lt;/p&gt;
&lt;p&gt;
&#25299;&#25169;&#35270;&#24046;&#26159;&#19968;&#31181;&#27604;&#36739;&#35757;&#32451;&#27169;&#22411;&#21644;&#21442;&#32771;&#25968;&#25454;&#38598;&#22810;&#23610;&#24230;&#20960;&#20309;&#32467;&#26500;&#30456;&#20284;&#24615;&#30340;&#29702;&#35770;&#21644;&#35745;&#31639;&#24037;&#20855;&#65292;&#23427;&#21487;&#20197;&#20272;&#35745;&#27169;&#22411;&#20013;&#30340;&#25299;&#25169;&#29305;&#24449;&#65292;&#26377;&#21161;&#20110;&#29702;&#35299;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#34892;&#20026;&#21644;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#20445;&#35777;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#30340;&#23433;&#20840;&#24615;&#21644;&#40065;&#26834;&#24615;&#65292;&#25105;&#20204;&#24341;&#20837;&#25299;&#25169;&#35270;&#24046;&#20316;&#20026;&#27604;&#36739;&#24050;&#35757;&#32451;&#27169;&#22411;&#21644;&#21442;&#32771;&#25968;&#25454;&#38598;&#30340;&#22810;&#23610;&#24230;&#20960;&#20309;&#32467;&#26500;&#30456;&#20284;&#24615;&#30340;&#29702;&#35770;&#21644;&#35745;&#31639;&#24037;&#20855;&#12290;&#25105;&#20204;&#30340;&#35777;&#26126;&#21644;&#20363;&#23376;&#34920;&#26126;&#65292;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#20043;&#38388;&#30340;&#36825;&#31181;&#20960;&#20309;&#30456;&#20284;&#24615;&#23545;&#20110;&#21487;&#20449;&#30340;&#25554;&#20540;&#21644;&#25200;&#21160;&#33267;&#20851;&#37325;&#35201;&#65292;&#24182;&#19988;&#25105;&#20204;&#29468;&#27979;&#65292;&#36825;&#20010;&#26032;&#27010;&#24565;&#23558;&#20026;&#28145;&#24230;&#23398;&#20064;&#24212;&#29992;&#20013;&#36807;&#25311;&#21512;&#21644;&#27867;&#21270;&#20043;&#38388;&#19981;&#26126;&#30830;&#30340;&#20851;&#31995;&#30340;&#24403;&#21069;&#35752;&#35770;&#22686;&#28155;&#20215;&#20540;&#12290;&#22312;&#20856;&#22411;&#30340;DNN&#24212;&#29992;&#20013;&#65292;&#27169;&#22411;&#30340;&#26174;&#24335;&#20960;&#20309;&#25551;&#36848;&#26159;&#19981;&#21487;&#33021;&#30340;&#65292;&#20294;&#35270;&#24046;&#21487;&#20197;&#36890;&#36807;&#26816;&#26597;&#20351;&#29992;&#21442;&#32771;&#25968;&#25454;&#38598;&#30340;&#27979;&#22320;&#30072;&#21464;&#23545;Rips&#22797;&#21512;&#20307;&#30340;&#24433;&#21709;&#26469;&#20272;&#35745;&#27169;&#22411;&#20013;&#30340;&#25299;&#25169;&#29305;&#24449;&#65288;&#32452;&#20214;&#12289;&#21608;&#26399;&#12289;&#31354;&#27934;&#31561;&#65289;&#12290;&#22240;&#27492;&#65292;&#35270;&#24046;&#25351;&#31034;&#27169;&#22411;&#19982;&#25968;&#25454;&#38598;&#26159;&#21542;&#20849;&#20139;&#31867;&#20284;&#30340;&#22810;&#23610;&#24230;&#20960;&#20309;&#29305;&#24449;&#12290;&#35270;&#24046;&#36890;&#36807;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#29702;&#35770;&#65292;&#25552;&#20379;&#20102;&#20174;&#19981;&#21516;&#35282;&#24230;&#35266;&#23519;&#25968;&#25454;&#30340;&#30452;&#35266;&#27010;&#24565;&#65292;&#24182;&#20026;&#29702;&#35299;&#28145;&#24230;&#24863;&#30693;&#27169;&#22411;&#30340;&#34892;&#20026;&#21644;&#24615;&#33021;&#25552;&#20379;&#20102;&#26032;&#30340;&#35270;&#35282;&#12290;
&lt;/p&gt;
&lt;p&gt;
For safety and robustness of AI systems, we introduce topological parallax as a theoretical and computational tool that compares a trained model to a reference dataset to determine whether they have similar multiscale geometric structure. Our proofs and examples show that this geometric similarity between dataset and model is essential to trustworthy interpolation and perturbation, and we conjecture that this new concept will add value to the current debate regarding the unclear relationship between overfitting and generalization in applications of deep-learning. In typical DNN applications, an explicit geometric description of the model is impossible, but parallax can estimate topological features (components, cycles, voids, etc.) in the model by examining the effect on the Rips complex of geodesic distortions using the reference dataset. Thus, parallax indicates whether the model shares similar multiscale geometric features with the dataset. Parallax presents theoretically via topolo
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#35777;&#26126;&#20102;&#20219;&#20309;&#28145;&#24230;&#30340;ReLU&#32593;&#32476;&#37117;&#21487;&#20197;&#34987;&#37325;&#20889;&#20026;&#19968;&#20010;&#20855;&#26377;&#36879;&#26126;&#24615;&#30340;&#27973;&#23618;&#32593;&#32476;&#12290;&#36825;&#19968;&#32467;&#35770;&#26377;&#21161;&#20110;&#35299;&#37322;&#27169;&#22411;&#34892;&#20026;&#12290;</title><link>http://arxiv.org/abs/2306.11827</link><description>&lt;p&gt;
&#20219;&#20309;&#28145;&#24230;ReLU&#32593;&#32476;&#37117;&#26159;&#27973;&#23618;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Any Deep ReLU Network is Shallow. (arXiv:2306.11827v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11827
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#35777;&#26126;&#20102;&#20219;&#20309;&#28145;&#24230;&#30340;ReLU&#32593;&#32476;&#37117;&#21487;&#20197;&#34987;&#37325;&#20889;&#20026;&#19968;&#20010;&#20855;&#26377;&#36879;&#26126;&#24615;&#30340;&#27973;&#23618;&#32593;&#32476;&#12290;&#36825;&#19968;&#32467;&#35770;&#26377;&#21161;&#20110;&#35299;&#37322;&#27169;&#22411;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#26500;&#36896;&#24615;&#22320;&#35777;&#26126;&#20102;&#27599;&#20010;&#28145;&#24230;&#30340;ReLU&#32593;&#32476;&#21487;&#20197;&#34987;&#37325;&#20889;&#20026;&#19968;&#20010;&#20989;&#25968;&#19978;&#31561;&#20215;&#30340;&#19977;&#23618;&#32593;&#32476;&#65292;&#20854;&#20013;&#26435;&#37325;&#20540;&#20026;&#24310;&#36831;&#23454;&#25968;&#12290;&#22522;&#20110;&#27492;&#35777;&#26126;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#31639;&#27861;&#65292;&#21487;&#20197;&#32473;&#20986;&#19968;&#20010;&#28145;&#24230;ReLU&#32593;&#32476;&#23545;&#24212;&#30340;&#26174;&#24335;&#26435;&#37325;&#12290;&#30001;&#27492;&#24471;&#21040;&#30340;&#27973;&#23618;&#32593;&#32476;&#26159;&#36879;&#26126;&#30340;&#65292;&#24182;&#29992;&#20110;&#29983;&#25104;&#27169;&#22411;&#34892;&#20026;&#30340;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
We constructively prove that every deep ReLU network can be rewritten as a functionally identical three-layer network with weights valued in the extended reals. Based on this proof, we provide an algorithm that, given a deep ReLU network, finds the explicit weights of the corresponding shallow network. The resulting shallow network is transparent and used to generate explanations of the model s behaviour.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#30340;&#22810;&#20219;&#21153;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#65292;&#29992;&#20110;&#36924;&#36817;&#20010;&#20307;&#30340;&#31227;&#21160;&#29366;&#24577;&#30340;&#28508;&#22312;&#20989;&#25968;&#65292;&#24182;&#32771;&#34385;&#20102;&#36716;&#31227;&#27010;&#29575;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#21644;&#26102;&#38388;&#21487;&#21464;&#24615;&#65292;&#36890;&#36807;&#24378;&#21046;&#25191;&#34892;&#38543;&#26426;&#24615;&#21644;&#38750;&#36127;&#24615;&#32422;&#26463;&#26469;&#23454;&#29616;&#30740;&#31350;&#30446;&#26631;&#12290;</title><link>http://arxiv.org/abs/2306.11772</link><description>&lt;p&gt;
&#22810;&#20219;&#21153;&#39640;&#26031;&#36807;&#31243;&#20013;&#30340;&#26102;&#38388;&#21464;&#21270;&#36716;&#31227;&#30697;&#38453;
&lt;/p&gt;
&lt;p&gt;
Time-Varying Transition Matrices with Multi-task Gaussian Processes. (arXiv:2306.11772v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11772
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#30340;&#22810;&#20219;&#21153;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#65292;&#29992;&#20110;&#36924;&#36817;&#20010;&#20307;&#30340;&#31227;&#21160;&#29366;&#24577;&#30340;&#28508;&#22312;&#20989;&#25968;&#65292;&#24182;&#32771;&#34385;&#20102;&#36716;&#31227;&#27010;&#29575;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#21644;&#26102;&#38388;&#21487;&#21464;&#24615;&#65292;&#36890;&#36807;&#24378;&#21046;&#25191;&#34892;&#38543;&#26426;&#24615;&#21644;&#38750;&#36127;&#24615;&#32422;&#26463;&#26469;&#23454;&#29616;&#30740;&#31350;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#30340;&#22810;&#20219;&#21153;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#65292;&#29992;&#20110;&#36924;&#36817;&#20010;&#20307;&#30340;&#31227;&#21160;&#29366;&#24577;&#30340;&#28508;&#22312;&#20989;&#25968;&#65292;&#35813;&#27169;&#22411;&#20351;&#29992;&#20855;&#26377;&#20004;&#20010;&#29366;&#24577;&#65288;&#31227;&#21160;&#21644;&#20572;&#30041;&#65289;&#30340;&#26102;&#38388;&#19981;&#22343;&#21248;&#39532;&#23572;&#31185;&#22827;&#36807;&#31243;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#21019;&#24314;&#20219;&#21153;&#20043;&#38388;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#26469;&#32771;&#34385;&#36716;&#31227;&#27010;&#29575;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#12290;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;&#26102;&#38388;&#21487;&#21464;&#24615;&#65292;&#20551;&#35774;&#20010;&#20307;&#30340;&#36716;&#31227;&#27010;&#29575;&#38543;&#30528;&#22806;&#37096;&#21464;&#37327;&#32780;&#38543;&#26102;&#38388;&#21464;&#21270;&#12290;&#36890;&#36807;&#23558;&#32422;&#26463;&#28857;&#38598;&#25104;&#21040;&#39640;&#26031;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#24378;&#21046;&#25191;&#34892;&#39532;&#23572;&#31185;&#22827;&#36807;&#31243;&#20013;&#27010;&#29575;&#30340;&#38543;&#26426;&#24615;&#21644;&#38750;&#36127;&#24615;&#32422;&#26463;&#12290;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#21033;&#29992;Toeplitz&#21644;Kronecker&#20056;&#31215;&#32467;&#26500;&#22312;&#27492;&#19978;&#19979;&#25991;&#20013;&#21152;&#36895;GP&#20272;&#35745;&#21644;&#25512;&#26029;&#30340;&#26426;&#20250;&#12290;&#25105;&#20204;&#30340;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#20844;&#24335;&#21487;&#20197;&#24378;&#21046;&#25191;&#34892;&#25152;&#38656;&#30340;&#32422;&#26463;&#26465;&#20214;&#65292;&#21516;&#26102;&#23398;&#20064;&#36716;&#31227;&#27010;&#29575;&#30340;&#20989;&#25968;&#24418;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we present a kernel-based, multi-task Gaussian Process (GP) model for approximating the underlying function of an individual's mobility state using a time-inhomogeneous Markov Process with two states: moves and pauses. Our approach accounts for the correlations between the transition probabilities by creating a covariance matrix over the tasks. We also introduce time-variability by assuming that an individual's transition probabilities vary over time in response to exogenous variables. We enforce the stochasticity and non-negativity constraints of probabilities in a Markov process through the incorporation of a set of constraint points in the GP. We also discuss opportunities to speed up GP estimation and inference in this context by exploiting Toeplitz and Kronecker product structures. Our numerical experiments demonstrate the ability of our formulation to enforce the desired constraints while learning the functional form of transition probabilities.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;Samplet&#22352;&#26631;&#19979;&#26680;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;&#24341;&#20837;l1&#27491;&#21017;&#21270;&#39033;&#21487;&#20197;&#22686;&#21152;&#31995;&#25968;&#30340;&#31232;&#30095;&#24615;&#12290;&#30456;&#27604;&#20110;&#21333;&#23610;&#24230;&#22522;&#65292;Samplet&#22522;&#21487;&#20197;&#26356;&#22909;&#22320;&#34920;&#31034;&#26356;&#22810;&#31867;&#22411;&#30340;&#20449;&#21495;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#20351;&#29992;&#36719;&#38408;&#20540;&#21644;&#21322;&#20809;&#28369;&#29275;&#39039;&#27861;&#35299;&#20915;&#35813;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.10180</link><description>&lt;p&gt;
&#22522;&#20110;Samplet&#22522; Pursuit &#30340;&#26680;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Samplet basis pursuit. (arXiv:2306.10180v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10180
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;Samplet&#22352;&#26631;&#19979;&#26680;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;&#24341;&#20837;l1&#27491;&#21017;&#21270;&#39033;&#21487;&#20197;&#22686;&#21152;&#31995;&#25968;&#30340;&#31232;&#30095;&#24615;&#12290;&#30456;&#27604;&#20110;&#21333;&#23610;&#24230;&#22522;&#65292;Samplet&#22522;&#21487;&#20197;&#26356;&#22909;&#22320;&#34920;&#31034;&#26356;&#22810;&#31867;&#22411;&#30340;&#20449;&#21495;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#20351;&#29992;&#36719;&#38408;&#20540;&#21644;&#21322;&#20809;&#28369;&#29275;&#39039;&#27861;&#35299;&#20915;&#35813;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#22522;&#20110;l1&#27491;&#21017;&#21270;&#30340;Samplet&#22352;&#26631;&#19979;&#30340;&#26680;&#23398;&#20064;&#38382;&#39064;&#12290;&#22312;Samplet&#22522;&#30340;&#31995;&#25968;&#19978;&#65292;&#24212;&#29992;l1&#27491;&#21017;&#21270;&#39033;&#21487;&#20197;&#24378;&#21046;&#22686;&#21152;&#31232;&#30095;&#24615;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#31216;&#36825;&#31181;&#26041;&#27861;&#20026;Samplet&#22522; Pursuit&#12290;Samplet&#22522;&#26159;&#27874;&#24418;&#31867;&#22411;&#30340;&#26377;&#31526;&#21495;&#27979;&#24230;&#65292;&#19987;&#38376;&#29992;&#20110;&#25955;&#20081;&#25968;&#25454;&#12290;&#23427;&#20204;&#20855;&#26377;&#19982;&#23567;&#27874;&#30456;&#20284;&#30340;&#26412;&#22320;&#21270;&#12289;&#22810;&#20998;&#36776;&#29575;&#20998;&#26512;&#21644;&#25968;&#25454;&#21387;&#32553;&#24615;&#36136;&#12290;&#21487;&#20197;&#22312;Samplet&#22522;&#19978;&#31232;&#30095;&#22320;&#34920;&#31034;&#30340;&#20449;&#21495;&#31867;&#27604;&#21333;&#23610;&#24230;&#22522;&#19978;&#33021;&#22815;&#34920;&#31034;&#31232;&#30095;&#30340;&#20449;&#21495;&#31867;&#21035;&#35201;&#22823;&#24471;&#22810;&#12290;&#29305;&#21035;&#22320;&#65292;&#20165;&#29992;&#22522;&#20989;&#25968;&#26144;&#23556;&#30340;&#20960;&#20010;&#29305;&#24449;&#21472;&#21152;&#21363;&#21487;&#34920;&#31034;&#30340;&#25152;&#26377;&#20449;&#21495;&#20063;&#21487;&#20197;&#22312;Samplet&#22352;&#26631;&#19979;&#23454;&#29616;&#31232;&#30095;&#34920;&#31034;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#35299;&#20915;&#35813;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#23558;&#36719;&#38408;&#20540;&#21644;&#21322;&#20809;&#28369;&#29275;&#39039;&#27861;&#30456;&#32467;&#21512;&#65292;&#24182;&#23558;&#35813;&#26041;&#27861;&#19982;&#24555;&#36895;&#36845;&#20195;&#25910;&#32553;&#38408;&#20540;&#31639;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#31232;&#30095;&#24615;&#21644;&#39044;&#27979;&#31934;&#24230;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider kernel-based learning in samplet coordinates with l1-regularization. The application of an l1-regularization term enforces sparsity of the coefficients with respect to the samplet basis. Therefore, we call this approach samplet basis pursuit. Samplets are wavelet-type signed measures, which are tailored to scattered data. They provide similar properties as wavelets in terms of localization, multiresolution analysis, and data compression. The class of signals that can sparsely be represented in a samplet basis is considerably larger than the class of signals which exhibit a sparse representation in the single-scale basis. In particular, every signal that can be represented by the superposition of only a few features of the canonical feature map is also sparse in samplet coordinates. We propose the efficient solution of the problem under consideration by combining soft-shrinkage with the semi-smooth Newton method and compare the approach to the fast iterative shrinkage thresh
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#28436;&#36827;&#21464;&#21270;&#26469;&#25913;&#21892;&#36719;&#20214;&#24320;&#21457;&#36807;&#31243;&#36136;&#37327;&#30340;&#26041;&#27861;&#65292;&#20854;&#21253;&#25324;&#20351;&#29992;&#32479;&#35745;&#36807;&#31243;&#25511;&#21046;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#26469;&#20998;&#26512;&#24212;&#29992;&#31243;&#24207;&#29983;&#21629;&#21608;&#26399;&#31649;&#29702;&#25152;&#25429;&#33719;&#30340;&#21464;&#26356;&#25968;&#25454;&#65292;&#23454;&#39564;&#34920;&#26126;&#35813;&#26041;&#27861;&#26159;&#26377;&#25928;&#30340;&#12290;</title><link>http://arxiv.org/abs/2305.18061</link><description>&lt;p&gt;
&#21033;&#29992;&#28436;&#36827;&#21464;&#21270;&#25552;&#39640;&#36719;&#20214;&#36807;&#31243;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Leveraging Evolutionary Changes for Software Process Quality. (arXiv:2305.18061v1 [cs.SE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18061
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#28436;&#36827;&#21464;&#21270;&#26469;&#25913;&#21892;&#36719;&#20214;&#24320;&#21457;&#36807;&#31243;&#36136;&#37327;&#30340;&#26041;&#27861;&#65292;&#20854;&#21253;&#25324;&#20351;&#29992;&#32479;&#35745;&#36807;&#31243;&#25511;&#21046;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#26469;&#20998;&#26512;&#24212;&#29992;&#31243;&#24207;&#29983;&#21629;&#21608;&#26399;&#31649;&#29702;&#25152;&#25429;&#33719;&#30340;&#21464;&#26356;&#25968;&#25454;&#65292;&#23454;&#39564;&#34920;&#26126;&#35813;&#26041;&#27861;&#26159;&#26377;&#25928;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#36719;&#20214;&#24212;&#29992;&#24517;&#39035;&#19981;&#26029;&#28436;&#36827;&#25165;&#33021;&#20445;&#25345;&#30456;&#20851;&#24615;&#12290;&#20256;&#32479;&#30340;&#36719;&#20214;&#36136;&#37327;&#25511;&#21046;&#26041;&#27861;&#28041;&#21450;&#36719;&#20214;&#36136;&#37327;&#27169;&#22411;&#21644;&#25345;&#32493;&#30340;&#20195;&#30721;&#26816;&#26597;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#36719;&#20214;&#24320;&#21457;&#36807;&#31243;&#30340;&#36136;&#37327;&#19982;&#26368;&#32456;&#36719;&#20214;&#20135;&#21697;&#30340;&#36136;&#37327;&#20043;&#38388;&#23384;&#22312;&#24378;&#20851;&#32852;&#21644;&#22240;&#26524;&#20851;&#31995;&#12290;&#22240;&#27492;&#65292;&#38388;&#25509;&#25552;&#39640;&#36719;&#20214;&#20135;&#21697;&#30340;&#36136;&#37327;&#38656;&#35201;&#25913;&#21892;&#36719;&#20214;&#24320;&#21457;&#36807;&#31243;&#30340;&#36136;&#37327;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#24320;&#21457;&#36807;&#31243;&#30340;&#28436;&#36827;&#21464;&#21270;&#26469;&#25552;&#39640;&#36719;&#20214;&#36136;&#37327;&#30340;&#26032;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#21253;&#25324;&#20351;&#29992;&#32479;&#35745;&#36807;&#31243;&#25511;&#21046;&#21644;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#26469;&#20998;&#26512;&#24212;&#29992;&#31243;&#24207;&#29983;&#21629;&#21608;&#26399;&#31649;&#29702;&#25152;&#25429;&#33719;&#30340;&#21464;&#26356;&#25968;&#25454;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Real-world software applications must constantly evolve to remain relevant. This evolution occurs when developing new applications or adapting existing ones to meet new requirements, make corrections, or incorporate future functionality. Traditional methods of software quality control involve software quality models and continuous code inspection tools. These measures focus on directly assessing the quality of the software. However, there is a strong correlation and causation between the quality of the development process and the resulting software product. Therefore, improving the development process indirectly improves the software product, too. To achieve this, effective learning from past processes is necessary, often embraced through post mortem organizational learning. While qualitative evaluation of large artifacts is common, smaller quantitative changes captured by application lifecycle management are often overlooked. In addition to software metrics, these smaller changes can 
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20302;&#31209;&#35889;&#26368;&#20248;&#21270;&#38382;&#39064;&#30340;&#37096;&#20998;&#20984;&#21270;&#30340;&#23454;&#21147;&#65292;&#25552;&#20986;&#20102;&#27966;&#29983;&#20219;&#20309;&#26497;&#31471;&#28857;&#30340;&#31209;&#30028;&#65292;&#24182;&#35777;&#26126;&#20102;&#23545;&#20110;&#19981;&#21516;&#30697;&#38453;&#31354;&#38388;&#30340;&#22495;&#38598;&#21512;&#30340;&#32039;&#33268;&#24615;&#65292;&#21516;&#26102;&#24320;&#21457;&#20102;&#19968;&#20010;&#21253;&#21547;&#30690;&#37327;&#20984;&#23450;&#20215;&#31070;&#35861;&#30340;&#21015;&#29983;&#25104;&#31639;&#27861;&#20197;&#26377;&#25928;&#35299;&#20915;&#27492;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.07638</link><description>&lt;p&gt;
&#20851;&#20110;&#20302;&#31209;&#35889;&#26368;&#20248;&#21270;&#30340;&#37096;&#20998;&#20984;&#21270;&#65306;&#31209;&#30028;&#19982;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
On the Partial Convexification for Low-Rank Spectral Optimization: Rank Bounds and Algorithms. (arXiv:2305.07638v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.07638
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20302;&#31209;&#35889;&#26368;&#20248;&#21270;&#38382;&#39064;&#30340;&#37096;&#20998;&#20984;&#21270;&#30340;&#23454;&#21147;&#65292;&#25552;&#20986;&#20102;&#27966;&#29983;&#20219;&#20309;&#26497;&#31471;&#28857;&#30340;&#31209;&#30028;&#65292;&#24182;&#35777;&#26126;&#20102;&#23545;&#20110;&#19981;&#21516;&#30697;&#38453;&#31354;&#38388;&#30340;&#22495;&#38598;&#21512;&#30340;&#32039;&#33268;&#24615;&#65292;&#21516;&#26102;&#24320;&#21457;&#20102;&#19968;&#20010;&#21253;&#21547;&#30690;&#37327;&#20984;&#23450;&#20215;&#31070;&#35861;&#30340;&#21015;&#29983;&#25104;&#31639;&#27861;&#20197;&#26377;&#25928;&#35299;&#20915;&#27492;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20302;&#31209;&#35889;&#26368;&#20248;&#21270;&#38382;&#39064;&#65288;LSOP&#65289;&#30340;&#30446;&#26631;&#26159;&#22312;&#20302;&#31209;&#21644;&#35889;&#32422;&#26463;&#30340;&#21487;&#34892;&#22495;&#20869;&#65292;&#26368;&#23567;&#21270;&#19968;&#20010;&#32447;&#24615;&#30446;&#26631;&#65292;&#28385;&#36275;&#22810;&#20010;&#21452;&#38754;&#32447;&#24615;&#30697;&#38453;&#19981;&#31561;&#24335;&#30340;&#20132;&#38598;&#12290;&#34429;&#28982;&#35299;&#20915;LSOP&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#26159;NP&#38590;&#30340;&#65292;&#20294;&#23427;&#30340;&#37096;&#20998;&#20984;&#21270;&#65288;&#21363;&#29992;&#20984;&#22771;&#20195;&#26367;&#22495;&#38598;&#21512;&#65289;&#65292;&#31216;&#20026;&#8220;LSOP-R&#8221;&#65292;&#36890;&#24120;&#26159;&#21487;&#22788;&#29702;&#30340;&#24182;&#20135;&#29983;&#39640;&#36136;&#37327;&#30340;&#35299;&#12290;&#36825;&#28608;&#21169;&#25105;&#20204;&#30740;&#31350;LSOP-R&#30340;&#23454;&#21147;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20026;LSOP-R&#21487;&#34892;&#38598;&#30340;&#20219;&#20309;&#26497;&#31471;&#28857;&#27966;&#29983;&#31209;&#30028;&#65292;&#24182;&#35777;&#26126;&#23545;&#20110;&#19981;&#21516;&#30697;&#38453;&#31354;&#38388;&#30340;&#22495;&#38598;&#21512;&#65292;&#23427;&#20204;&#30340;&#32039;&#33268;&#24615;&#12290;&#25152;&#25552;&#20986;&#30340;&#31209;&#30028;&#20174;&#26032;&#30340;&#35282;&#24230;&#24674;&#22797;&#20102;&#25991;&#29486;&#20013;&#30340;&#20004;&#20010;&#20247;&#25152;&#21608;&#30693;&#30340;&#32467;&#26524;&#65292;&#24182;&#20801;&#35768;&#25105;&#20204;&#23548;&#20986;&#24403;&#26494;&#24347;LSOP-R&#31561;&#20215;&#20110;&#21407;&#22987;LSOP&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#20026;&#20102;&#26377;&#25928;&#22320;&#35299;&#20915;LSOP-R&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#21253;&#21547;&#30690;&#37327;&#20984;&#23450;&#20215;&#31070;&#35861;&#30340;&#21015;&#29983;&#25104;&#31639;&#27861;&#65292;&#37197;&#21512;&#19968;&#20010;&#31209;&#38477;&#31639;&#27861;&#65292;&#23427;&#30830;&#20445;&#36755;&#20986;&#19968;&#20010;LSOP-R&#30340;&#20934;&#30830;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
A Low-rank Spectral Optimization Problem (LSOP) minimizes a linear objective subject to multiple two-sided linear matrix inequalities intersected with a low-rank and spectral constrained domain set. Although solving LSOP is, in general, NP-hard, its partial convexification (i.e., replacing the domain set by its convex hull) termed "LSOP-R," is often tractable and yields a high-quality solution. This motivates us to study the strength of LSOP-R. Specifically, we derive rank bounds for any extreme point of the feasible set of LSOP-R and prove their tightness for the domain sets with different matrix spaces. The proposed rank bounds recover two well-known results in the literature from a fresh angle and also allow us to derive sufficient conditions under which the relaxation LSOP-R is equivalent to the original LSOP. To effectively solve LSOP-R, we develop a column generation algorithm with a vector-based convex pricing oracle, coupled with a rank-reduction algorithm, which ensures the ou
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;NNCI&#65292;&#29992;&#20110;&#23558;&#26368;&#36817;&#37051;&#23621;&#20449;&#24687;&#38598;&#25104;&#21040;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#20013;&#65292;&#20197;&#26356;&#20934;&#30830;&#22320;&#20272;&#35745;&#27835;&#30103;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2305.06789</link><description>&lt;p&gt;
&#22312;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#20013;&#38598;&#25104;&#26368;&#36817;&#37051;&#23621;&#20197;&#20272;&#35745;&#27835;&#30103;&#25928;&#26524;
&lt;/p&gt;
&lt;p&gt;
Integrating nearest neighbors on neural network models for treatment effect estimation. (arXiv:2305.06789v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06789
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;NNCI&#65292;&#29992;&#20110;&#23558;&#26368;&#36817;&#37051;&#23621;&#20449;&#24687;&#38598;&#25104;&#21040;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#20013;&#65292;&#20197;&#26356;&#20934;&#30830;&#22320;&#20272;&#35745;&#27835;&#30103;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#23545;&#20110;&#35768;&#22810;&#31185;&#23398;&#21644;&#24037;&#19994;&#39046;&#22495;&#30340;&#30740;&#31350;&#20154;&#21592;&#21644;&#20174;&#19994;&#32773;&#26469;&#35828;&#20855;&#26377;&#39640;&#24230;&#37325;&#35201;&#24615;&#12290;&#35266;&#23519;&#25968;&#25454;&#30340;&#20016;&#23500;&#24615;&#20351;&#23427;&#20204;&#36234;&#26469;&#36234;&#21463;&#21040;&#30740;&#31350;&#20154;&#21592;&#29992;&#20110;&#22240;&#26524;&#25928;&#24212;&#30340;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#25968;&#25454;&#23384;&#22312;&#20559;&#24046;&#21644;&#20854;&#20182;&#24369;&#28857;&#65292;&#23548;&#33268;&#22914;&#26524;&#19981;&#27491;&#30830;&#22788;&#29702;&#65292;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#20250;&#19981;&#20934;&#30830;&#12290;&#22240;&#27492;&#65292;&#25552;&#20986;&#20102;&#20960;&#31181;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#65292;&#20854;&#20013;&#22823;&#37096;&#20998;&#37117;&#19987;&#27880;&#20110;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#30340;&#39044;&#27979;&#33021;&#21147;&#65292;&#20197;&#36798;&#21040;&#26356;&#31934;&#30830;&#30340;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#26368;&#36817;&#37051;&#23621;&#20449;&#24687;&#29992;&#20110;&#22240;&#26524;&#25512;&#26029;&#65288;NNCI&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#29992;&#20110;&#23558;&#26377;&#20215;&#20540;&#30340;&#26368;&#36817;&#37051;&#23621;&#20449;&#24687;&#38598;&#25104;&#21040;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#27169;&#22411;&#20013;&#65292;&#20197;&#20272;&#35745;&#27835;&#30103;&#25928;&#26524;&#12290;&#25552;&#20986;&#30340;NNCI&#26041;&#27861;&#34987;&#24212;&#29992;&#20110;&#19968;&#20123;&#26368;&#24191;&#27867;&#20351;&#29992;&#30340;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#27169;&#22411;&#65292;&#20854;&#20351;&#29992;&#35266;&#23519;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Treatment effect estimation is of high-importance for both researchers and practitioners across many scientific and industrial domains. The abundance of observational data makes them increasingly used by researchers for the estimation of causal effects. However, these data suffer from biases, from several weaknesses, leading to inaccurate causal effect estimations, if not handled properly. Therefore, several machine learning techniques have been proposed, most of them focusing on leveraging the predictive power of neural network models to attain more precise estimation of causal effects. In this work, we propose a new methodology, named Nearest Neighboring Information for Causal Inference (NNCI), for integrating valuable nearest neighboring information on neural network-based models for estimating treatment effects. The proposed NNCI methodology is applied to some of the most well established neural network-based models for treatment effect estimation with the use of observational data
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#25968;&#20540;&#31163;&#25955;&#21270;&#21442;&#25968;&#23545;&#20809;&#23398;&#32435;&#31859;&#35745;&#37327;&#39046;&#22495;&#21442;&#25968;&#37325;&#24314;&#21644;&#27169;&#22411;&#21442;&#25968;&#20998;&#24067;&#30340;&#24433;&#21709;&#65292;&#30830;&#23450;&#20102;&#25968;&#20540;&#21442;&#25968;&#21487;&#20197;&#20801;&#35768;&#39640;&#31934;&#24230;&#37325;&#24314;&#12290;</title><link>http://arxiv.org/abs/2305.02663</link><description>&lt;p&gt;
&#25968;&#20540;&#31163;&#25955;&#21270;&#31934;&#24230;&#23545;&#21442;&#25968;&#37325;&#24314;&#21644;&#27169;&#22411;&#21442;&#25968;&#20998;&#24067;&#30340;&#24433;&#21709;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Impact Study of Numerical Discretization Accuracy on Parameter Reconstructions and Model Parameter Distributions. (arXiv:2305.02663v1 [physics.comp-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02663
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#25968;&#20540;&#31163;&#25955;&#21270;&#21442;&#25968;&#23545;&#20809;&#23398;&#32435;&#31859;&#35745;&#37327;&#39046;&#22495;&#21442;&#25968;&#37325;&#24314;&#21644;&#27169;&#22411;&#21442;&#25968;&#20998;&#24067;&#30340;&#24433;&#21709;&#65292;&#30830;&#23450;&#20102;&#25968;&#20540;&#21442;&#25968;&#21487;&#20197;&#20801;&#35768;&#39640;&#31934;&#24230;&#37325;&#24314;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#20540;&#27169;&#22411;&#22312;&#20809;&#23398;&#32435;&#31859;&#35745;&#37327;&#39046;&#22495;&#30340;&#21442;&#25968;&#37325;&#24314;&#20013;&#24471;&#21040;&#24191;&#27867;&#24212;&#29992;&#12290;&#36890;&#36807;&#20351;&#29992;&#36125;&#21494;&#26031;&#30446;&#26631;&#21521;&#37327;&#20248;&#21270;&#26041;&#27861;&#23558;&#26377;&#38480;&#20803;&#25968;&#20540;&#27169;&#22411;&#25311;&#21512;&#21040;&#23454;&#39564;&#25968;&#25454;&#38598;&#65292;&#21487;&#20197;&#33719;&#24471;&#32435;&#31859;&#32467;&#26500;&#32447;&#20809;&#26629;&#30340;&#20960;&#20309;&#21442;&#25968;&#12290;&#22312;&#37325;&#24314;&#36807;&#31243;&#20013;&#65292;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#20195;&#29702;&#27169;&#22411;&#36827;&#34892;&#35757;&#32451;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#25277;&#26679;&#22120;&#23545;&#20195;&#29702;&#27169;&#22411;&#36827;&#34892;&#25277;&#26679;&#65292;&#20197;&#30830;&#23450;&#37325;&#24314;&#27169;&#22411;&#21442;&#25968;&#30340;&#23436;&#25972;&#27169;&#22411;&#21442;&#25968;&#20998;&#24067;&#12290;&#25968;&#20540;&#31163;&#25955;&#21270;&#21442;&#25968;&#30340;&#36873;&#25321;&#65292;&#22914;&#26377;&#38480;&#20803;&#35299;&#31572;&#20989;&#25968;&#30340;&#22810;&#39033;&#24335;&#38454;&#25968;&#65292;&#24433;&#21709;&#27491;&#28436;&#27169;&#22411;&#30340;&#25968;&#20540;&#31163;&#25955;&#21270;&#35823;&#24046;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#27491;&#28436;&#38382;&#39064;&#30340;&#25968;&#20540;&#31163;&#25955;&#21270;&#21442;&#25968;&#23545;&#37325;&#26500;&#21442;&#25968;&#20197;&#21450;&#27169;&#22411;&#21442;&#25968;&#20998;&#24067;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#34920;&#26126;&#36825;&#26679;&#30340;&#25910;&#25947;&#30740;&#31350;&#21487;&#20197;&#30830;&#23450;&#20801;&#35768;&#39640;&#31934;&#24230;&#37325;&#24314;&#30340;&#25968;&#20540;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Numerical models are used widely for parameter reconstructions in the field of optical nano metrology. To obtain geometrical parameters of a nano structured line grating, we fit a finite element numerical model to an experimental data set by using the Bayesian target vector optimization method. Gaussian process surrogate models are trained during the reconstruction. Afterwards, we employ a Markov chain Monte Carlo sampler on the surrogate models to determine the full model parameter distribution for the reconstructed model parameters. The choice of numerical discretization parameters, like the polynomial order of the finite element ansatz functions, impacts the numerical discretization error of the forward model. In this study we investigate the impact of numerical discretization parameters of the forward problem on the reconstructed parameters as well as on the model parameter distributions. We show that such a convergence study allows to determine numerical parameters which allow for
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;ChemCrow&#65292;&#19968;&#31181;LLM&#21270;&#23398;&#20195;&#29702;&#65292;&#36890;&#36807;&#25972;&#21512;13&#20010;&#19987;&#23478;&#35774;&#35745;&#30340;&#24037;&#20855;&#20174;&#32780;&#22686;&#24378;LLM&#22312;&#21270;&#23398;&#39046;&#22495;&#30340;&#24615;&#33021;&#65292;&#22312;&#21270;&#23398;&#20219;&#21153;&#20013;&#23454;&#29616;&#33258;&#21160;&#21270;&#65292;&#25552;&#39640;&#20102;&#25928;&#29575;&#21644;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2304.05376</link><description>&lt;p&gt;
ChemCrow:&#29992;&#21270;&#23398;&#24037;&#20855;&#22686;&#24378;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
ChemCrow: Augmenting large-language models with chemistry tools. (arXiv:2304.05376v1 [physics.chem-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05376
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;ChemCrow&#65292;&#19968;&#31181;LLM&#21270;&#23398;&#20195;&#29702;&#65292;&#36890;&#36807;&#25972;&#21512;13&#20010;&#19987;&#23478;&#35774;&#35745;&#30340;&#24037;&#20855;&#20174;&#32780;&#22686;&#24378;LLM&#22312;&#21270;&#23398;&#39046;&#22495;&#30340;&#24615;&#33021;&#65292;&#22312;&#21270;&#23398;&#20219;&#21153;&#20013;&#23454;&#29616;&#33258;&#21160;&#21270;&#65292;&#25552;&#39640;&#20102;&#25928;&#29575;&#21644;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;(LLMs)&#22312;&#36328;&#39046;&#22495;&#30340;&#20219;&#21153;&#34920;&#29616;&#20986;&#19968;&#23450;&#30340;&#20248;&#21183;&#65292;&#20294;&#22312;&#21270;&#23398;&#30456;&#20851;&#38382;&#39064;&#19978;&#21364;&#34920;&#29616;&#19981;&#20339;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#27169;&#22411;&#32570;&#20047;&#35775;&#38382;&#22806;&#37096;&#30693;&#35782;&#28304;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#31185;&#23398;&#24212;&#29992;&#20013;&#30340;&#26377;&#29992;&#24615;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;ChemCrow&#65292;&#19968;&#31181;LLM&#21270;&#23398;&#20195;&#29702;&#65292;&#26088;&#22312;&#23436;&#25104;&#26377;&#26426;&#21512;&#25104;&#12289;&#33647;&#29289;&#21457;&#29616;&#21644;&#26448;&#26009;&#35774;&#35745;&#31561;&#20219;&#21153;&#12290;&#36890;&#36807;&#25972;&#21512;13&#20010;&#19987;&#23478;&#35774;&#35745;&#30340;&#24037;&#20855;&#65292;ChemCrow&#25552;&#39640;&#20102;LLM&#22312;&#21270;&#23398;&#20013;&#30340;&#24615;&#33021;&#65292;&#24182;&#20135;&#29983;&#20102;&#26032;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#35780;&#20272;&#65292;&#21253;&#25324;LLM&#21644;&#20154;&#31867;&#19987;&#23478;&#35780;&#20272;&#65292;&#35777;&#26126;&#20102;ChemCrow&#22312;&#33258;&#21160;&#21270;&#21508;&#31181;&#21270;&#23398;&#20219;&#21153;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#25105;&#20204;&#21457;&#29616;GPT-4&#20316;&#20026;&#35780;&#20272;&#22120;&#26080;&#27861;&#21306;&#20998;&#26126;&#26174;&#38169;&#35823;&#30340;GPT-4&#23436;&#25104;&#21644;GPT-4 + ChemCrow&#24615;&#33021;&#12290;&#36825;&#31181;&#24037;&#20855;&#30340;&#28389;&#29992;&#26377;&#24456;&#22823;&#30340;&#39118;&#38505;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#23427;&#20204;&#30340;&#28508;&#22312;&#21361;&#23475;&#12290;&#22312;&#36127;&#36131;&#20219;&#30340;&#24773;&#20917;&#19979;&#65292;ChemCrow&#19981;&#20165;&#21487;&#20197;&#24110;&#21161;&#19987;&#19994;&#21270;&#23398;&#23478;&#24182;&#38477;&#20302;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large-language models (LLMs) have recently shown strong performance in tasks across domains, but struggle with chemistry-related problems. Moreover, these models lack access to external knowledge sources, limiting their usefulness in scientific applications. In this study, we introduce ChemCrow, an LLM chemistry agent designed to accomplish tasks across organic synthesis, drug discovery, and materials design. By integrating 13 expert-designed tools, ChemCrow augments the LLM performance in chemistry, and new capabilities emerge. Our evaluation, including both LLM and expert human assessments, demonstrates ChemCrow's effectiveness in automating a diverse set of chemical tasks. Surprisingly, we find that GPT-4 as an evaluator cannot distinguish between clearly wrong GPT-4 completions and GPT-4 + ChemCrow performance. There is a significant risk of misuse of tools like ChemCrow and we discuss their potential harms. Employed responsibly, ChemCrow not only aids expert chemists and lowers ba
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;Shallow ReLU$^k$&#31070;&#32463;&#32593;&#32476;&#30340;&#36924;&#36817;&#23481;&#37327;&#65292;&#35777;&#26126;&#20102;&#20854;&#26368;&#20248;&#36924;&#36817;&#36895;&#29575;&#12290;&#24212;&#29992;&#21040;&#38750;&#21442;&#25968;&#22238;&#24402;&#19978;&#65292;&#35777;&#26126;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#23454;&#29616;&#23398;&#20064;H\"older&#20989;&#25968;&#30340;&#26368;&#20248;&#28176;&#36827;&#36895;&#29575;&#65292;&#34917;&#20805;&#20102;&#28145;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#36817;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2304.01561</link><description>&lt;p&gt;
Shallow ReLU$^k$&#31070;&#32463;&#32593;&#32476;&#30340;&#36924;&#36817;&#36895;&#29575;&#21450;&#20854;&#22312;&#38750;&#21442;&#25968;&#22238;&#24402;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Optimal rates of approximation by shallow ReLU$^k$ neural networks and applications to nonparametric regression. (arXiv:2304.01561v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01561
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;Shallow ReLU$^k$&#31070;&#32463;&#32593;&#32476;&#30340;&#36924;&#36817;&#23481;&#37327;&#65292;&#35777;&#26126;&#20102;&#20854;&#26368;&#20248;&#36924;&#36817;&#36895;&#29575;&#12290;&#24212;&#29992;&#21040;&#38750;&#21442;&#25968;&#22238;&#24402;&#19978;&#65292;&#35777;&#26126;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#23454;&#29616;&#23398;&#20064;H\"older&#20989;&#25968;&#30340;&#26368;&#20248;&#28176;&#36827;&#36895;&#29575;&#65292;&#34917;&#20805;&#20102;&#28145;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#36817;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#19982;Shallow ReLU$^k$&#31070;&#32463;&#32593;&#32476;&#30456;&#20851;&#30340;&#21464;&#24322;&#31354;&#38388;&#30340;&#36924;&#36817;&#23481;&#37327;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#26377;&#38480;&#21464;&#24322;&#33539;&#25968;&#19979;&#65292;&#23481;&#32435;&#20102;&#36275;&#22815;&#24179;&#28369;&#30340;&#20989;&#25968;&#12290;&#23545;&#20110;&#36739;&#23569;&#24179;&#28369;&#30340;&#20989;&#25968;&#65292;&#26681;&#25454;&#21464;&#24322;&#33539;&#25968;&#24314;&#31435;&#20102;&#36924;&#36817;&#36895;&#29575;&#12290;&#36816;&#29992;&#36825;&#20123;&#32467;&#26524;&#65292;&#25105;&#20204;&#21487;&#20197;&#35777;&#26126;Shallow ReLU$^k$&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#20248;&#36924;&#36817;&#36895;&#29575;&#12290;&#21516;&#26102;&#38416;&#26126;&#20102;&#36825;&#20123;&#32467;&#26524;&#22914;&#20309;&#29992;&#20110;&#25512;&#23548;&#28145;&#23618;&#31070;&#32463;&#32593;&#32476;&#21644;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;(CNNs)&#30340;&#36924;&#36817;&#30028;&#38480;&#12290;&#20026;&#24212;&#29992;&#30740;&#31350;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#19977;&#31181;ReLU&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65306;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#65292;&#36229;&#21442;&#25968;&#31070;&#32463;&#32593;&#32476;&#21644;CNN&#36827;&#34892;&#38750;&#21442;&#25968;&#22238;&#24402;&#25910;&#25947;&#36895;&#29575;&#30740;&#31350;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#23454;&#29616;&#23398;&#20064;H\"older&#20989;&#25968;&#30340;&#26368;&#20248;&#28176;&#36827;&#36895;&#29575;&#65292;&#36825;&#34917;&#20805;&#20102;&#28145;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#36817;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the approximation capacity of some variation spaces corresponding to shallow ReLU$^k$ neural networks. It is shown that sufficiently smooth functions are contained in these spaces with finite variation norms. For functions with less smoothness, the approximation rates in terms of the variation norm are established. Using these results, we are able to prove the optimal approximation rates in terms of the number of neurons for shallow ReLU$^k$ neural networks. It is also shown how these results can be used to derive approximation bounds for deep neural networks and convolutional neural networks (CNNs). As applications, we study convergence rates for nonparametric regression using three ReLU neural network models: shallow neural network, over-parameterized neural network, and CNN. In particular, we show that shallow neural networks can achieve the minimax optimal rates for learning H\"older functions, which complements recent results for deep neural networks. It is also proven th
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#8220;&#23398;&#20064;&#25298;&#32477;&#8221;&#26694;&#26550;&#26469;&#35299;&#20915;&#39046;&#22495;&#27867;&#21270;&#20013;&#30340;&#40664;&#40664;&#22833;&#36133;&#38382;&#39064;&#12290;&#36890;&#36807;&#39044;&#27979;&#21487;&#20449;&#24230;&#65292;&#35813;&#26041;&#27861;&#22312;&#27979;&#35797;&#20998;&#24067;&#19982;&#35757;&#32451;&#20998;&#24067;&#19981;&#21516;&#30340;&#24773;&#20917;&#19979;&#25509;&#21463;&#36229;&#20986;&#20998;&#24067;&#30340;&#25968;&#25454;&#65292;&#20197;&#35782;&#21035;&#33021;&#21147;&#21306;&#22495;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#36890;&#36807;&#19981;&#21516;&#30340;&#23398;&#20064;&#34920;&#31034;&#34913;&#37327;&#26080;&#33021;&#65292;&#22686;&#21152;&#26080;&#33021;&#24471;&#20998;&#20250;&#39044;&#31034;&#30528;&#38477;&#20302;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.09989</link><description>&lt;p&gt;
&#22312;&#39046;&#22495;&#27867;&#21270;&#20013;&#25214;&#21040;&#33021;&#21147;&#21306;&#22495;
&lt;/p&gt;
&lt;p&gt;
Finding Competence Regions in Domain Generalization. (arXiv:2303.09989v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.09989
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#8220;&#23398;&#20064;&#25298;&#32477;&#8221;&#26694;&#26550;&#26469;&#35299;&#20915;&#39046;&#22495;&#27867;&#21270;&#20013;&#30340;&#40664;&#40664;&#22833;&#36133;&#38382;&#39064;&#12290;&#36890;&#36807;&#39044;&#27979;&#21487;&#20449;&#24230;&#65292;&#35813;&#26041;&#27861;&#22312;&#27979;&#35797;&#20998;&#24067;&#19982;&#35757;&#32451;&#20998;&#24067;&#19981;&#21516;&#30340;&#24773;&#20917;&#19979;&#25509;&#21463;&#36229;&#20986;&#20998;&#24067;&#30340;&#25968;&#25454;&#65292;&#20197;&#35782;&#21035;&#33021;&#21147;&#21306;&#22495;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#36890;&#36807;&#19981;&#21516;&#30340;&#23398;&#20064;&#34920;&#31034;&#34913;&#37327;&#26080;&#33021;&#65292;&#22686;&#21152;&#26080;&#33021;&#24471;&#20998;&#20250;&#39044;&#31034;&#30528;&#38477;&#20302;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#8220;&#23398;&#20064;&#25298;&#32477;&#8221;&#26694;&#26550;&#26469;&#35299;&#20915;&#39046;&#22495;&#27867;&#21270;&#20013;&#40664;&#40664;&#22833;&#36133;&#30340;&#38382;&#39064;&#65292;&#21363;&#27979;&#35797;&#20998;&#24067;&#19982;&#35757;&#32451;&#20998;&#24067;&#19981;&#21516;&#30340;&#24773;&#20917;&#12290;&#20551;&#35774;&#26377;&#19968;&#20010;&#28201;&#21644;&#30340;&#20998;&#24067;&#20559;&#31227;&#65292;&#25105;&#20204;&#24076;&#26395;&#22312;&#27169;&#22411;&#20272;&#35745;&#30340;&#33021;&#21147;&#39044;&#31034;&#30528;&#21487;&#20449;&#21709;&#24212;&#26102;&#25509;&#21463;&#36229;&#20986;&#20998;&#24067;&#30340;&#25968;&#25454;&#65292;&#32780;&#19981;&#26159;&#30452;&#25509;&#25298;&#32477;&#36229;&#20986;&#20998;&#24067;&#30340;&#25968;&#25454;&#12290;&#21487;&#20449;&#24230;&#36890;&#36807;&#19982;&#20998;&#31867;&#22120;&#24615;&#33021;&#23494;&#20999;&#30456;&#20851;&#30340;&#20195;&#29702;&#26080;&#33021;&#20998;&#25968;&#36827;&#34892;&#39044;&#27979;&#12290;&#25105;&#20204;&#23545;&#20998;&#31867;&#30340;&#26080;&#33021;&#24471;&#20998;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#23454;&#39564;&#35780;&#20272;&#65292;&#24182;&#24378;&#35843;&#20102;&#25298;&#32477;&#29575;&#19982;&#20934;&#30830;&#29575;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;&#20026;&#20102;&#19982;&#20808;&#21069;&#30340;&#24037;&#20316;&#36827;&#34892;&#27604;&#36739;&#65292;&#25105;&#20204;&#32858;&#28966;&#20110;&#26631;&#20934;&#39046;&#22495;&#27867;&#21270;&#22522;&#20934;&#65292;&#24182;&#32771;&#34385;&#22312;&#38381;&#21512;&#21644;&#24320;&#25918;&#19990;&#30028;&#29615;&#22659;&#19979;&#36890;&#36807;&#19981;&#21516;&#30340;&#23398;&#20064;&#34920;&#31034;&#26469;&#34913;&#37327;&#26080;&#33021;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#22686;&#21152;&#26080;&#33021;&#20998;&#25968;&#30830;&#23454;&#39044;&#31034;&#30528;&#38477;&#20302;&#20934;&#30830;&#24615;&#65292;&#20174;&#32780;&#23548;&#33268;&#26174;&#30528;&#30340;...
&lt;/p&gt;
&lt;p&gt;
We propose a "learning to reject" framework to address the problem of silent failures in Domain Generalization (DG), where the test distribution differs from the training distribution. Assuming a mild distribution shift, we wish to accept out-of-distribution (OOD) data whenever a model's estimated competence foresees trustworthy responses, instead of rejecting OOD data outright. Trustworthiness is then predicted via a proxy incompetence score that is tightly linked to the performance of a classifier. We present a comprehensive experimental evaluation of incompetence scores for classification and highlight the resulting trade-offs between rejection rate and accuracy gain. For comparability with prior work, we focus on standard DG benchmarks and consider the effect of measuring incompetence via different learned representations in a closed versus an open world setting. Our results suggest that increasing incompetence scores are indeed predictive of reduced accuracy, leading to significan
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;Erd&#337;s-R&#233;nyi&#22270;&#20013;&#31181;&#26893;&#19968;&#20010;&#20855;&#26377;&#26399;&#26395;&#24102;&#23485;n*tau&#21644;&#36793;&#23494;&#24230;p&#30340;&#31264;&#23494;&#29615;&#65292;&#23545;&#24212;&#30340;&#26816;&#27979;&#21644;&#24674;&#22797;&#38382;&#39064;&#22312;&#20302;&#27425;&#22810;&#39033;&#24335;&#31639;&#27861;&#31867;&#30340;&#35745;&#31639;&#38408;&#20540;&#23384;&#22312;&#24046;&#36317;&#12290;</title><link>http://arxiv.org/abs/2302.06737</link><description>&lt;p&gt;
&#25581;&#31034;&#31181;&#26893;&#31264;&#23494;&#29615;&#30340;&#26816;&#27979;&#21644;&#24674;&#22797;&#24046;&#36317;
&lt;/p&gt;
&lt;p&gt;
Detection-Recovery Gap for Planted Dense Cycles. (arXiv:2302.06737v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.06737
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;Erd&#337;s-R&#233;nyi&#22270;&#20013;&#31181;&#26893;&#19968;&#20010;&#20855;&#26377;&#26399;&#26395;&#24102;&#23485;n*tau&#21644;&#36793;&#23494;&#24230;p&#30340;&#31264;&#23494;&#29615;&#65292;&#23545;&#24212;&#30340;&#26816;&#27979;&#21644;&#24674;&#22797;&#38382;&#39064;&#22312;&#20302;&#27425;&#22810;&#39033;&#24335;&#31639;&#27861;&#31867;&#30340;&#35745;&#31639;&#38408;&#20540;&#23384;&#22312;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31181;&#26893;&#31264;&#23494;&#29615;&#26159;&#35768;&#22810;&#24212;&#29992;&#31243;&#24207;&#20013;&#20986;&#29616;&#30340;&#19968;&#31181;&#28508;&#22312;&#32467;&#26500;&#65292;&#20363;&#22914;&#31038;&#20250;&#31185;&#23398;&#20013;&#30340;&#23567;&#19990;&#30028;&#32593;&#32476;&#21644;&#35745;&#31639;&#29983;&#29289;&#23398;&#20013;&#30340;&#24207;&#21015;&#32452;&#35013;&#12290;&#26412;&#25991;&#32771;&#34385;&#22312;Erd&#337;s-R&#233;nyi&#22270;G(n&#65292;q)&#20013;&#31181;&#26893;&#19968;&#20010;&#20855;&#26377;&#26399;&#26395;&#24102;&#23485;n*tau&#21644;&#36793;&#23494;&#24230;p&#30340;&#31264;&#23494;&#29615;&#12290;&#25105;&#20204;&#34920;&#24449;&#20102;&#20302;&#27425;&#22810;&#39033;&#24335;&#31639;&#27861;&#31867;&#30340;&#30456;&#20851;&#26816;&#27979;&#21644;&#24674;&#22797;&#38382;&#39064;&#30340;&#35745;&#31639;&#38408;&#20540;&#12290;&#29305;&#21035;&#22320;&#65292;&#22312;&#26576;&#20123;&#21442;&#25968;&#33539;&#22260;&#20869;&#23384;&#22312;&#20004;&#20010;&#38408;&#20540;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#20363;&#22914;&#65292;&#22914;&#26524;n^(-3/4)&#8810;tau&#8810;n^(-1/2)&#19988;p=Cq=&#920;(1)&#65292;&#20854;&#20013;C&gt;1&#26159;&#19968;&#20010;&#24120;&#25968;&#65292;&#21017;&#26816;&#27979;&#38382;&#39064;&#23545;&#20110;&#20302;&#27425;&#31639;&#27861;&#26159;&#35745;&#31639;&#23481;&#26131;&#30340;&#65292;&#32780;&#24674;&#22797;&#38382;&#39064;&#23545;&#20110;&#20302;&#27425;&#31639;&#27861;&#26159;&#22256;&#38590;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Planted dense cycles are a type of latent structure that appears in many applications, such as small-world networks in social sciences and sequence assembly in computational biology. We consider a model where a dense cycle with expected bandwidth $n \tau$ and edge density $p$ is planted in an Erd\H{o}s-R\'enyi graph $G(n,q)$. We characterize the computational thresholds for the associated detection and recovery problems for the class of low-degree polynomial algorithms. In particular, a gap exists between the two thresholds in a certain regime of parameters. For example, if $n^{-3/4} \ll \tau \ll n^{-1/2}$ and $p = C q = \Theta(1)$ for a constant $C&gt;1$, the detection problem is computationally easy while the recovery problem is hard for low-degree algorithms.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#31639;&#27861;&#38598;&#20307;&#34892;&#21160;&#30340;&#29702;&#35770;&#27169;&#22411;&#65292;&#24182;&#22312;&#22823;&#37327;&#23454;&#39564;&#20013;&#39564;&#35777;&#20102;&#35813;&#31639;&#27861;&#21487;&#20197;&#22823;&#22823;&#25552;&#39640;&#20998;&#31867;&#20934;&#30830;&#24615;&#65292;&#29305;&#21035;&#26159;&#22312;&#25968;&#25454;&#32467;&#26500;&#22797;&#26434;&#21644;&#38598;&#20307;&#35268;&#27169;&#22823;&#30340;&#24773;&#20917;&#19979;&#12290;</title><link>http://arxiv.org/abs/2302.04262</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#31639;&#27861;&#38598;&#20307;&#34892;&#21160;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Algorithmic Collective Action in Machine Learning. (arXiv:2302.04262v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.04262
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#31639;&#27861;&#38598;&#20307;&#34892;&#21160;&#30340;&#29702;&#35770;&#27169;&#22411;&#65292;&#24182;&#22312;&#22823;&#37327;&#23454;&#39564;&#20013;&#39564;&#35777;&#20102;&#35813;&#31639;&#27861;&#21487;&#20197;&#22823;&#22823;&#25552;&#39640;&#20998;&#31867;&#20934;&#30830;&#24615;&#65292;&#29305;&#21035;&#26159;&#22312;&#25968;&#25454;&#32467;&#26500;&#22797;&#26434;&#21644;&#38598;&#20307;&#35268;&#27169;&#22823;&#30340;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23545;&#22312;&#37319;&#29992;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#25968;&#23383;&#24179;&#21488;&#19978;&#36827;&#34892;&#31639;&#27861;&#38598;&#20307;&#34892;&#21160;&#36827;&#34892;&#20102;&#21407;&#21017;&#24615;&#30740;&#31350;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#29702;&#35770;&#27169;&#22411;&#65292;&#25551;&#36848;&#20102;&#19968;&#32676;&#20154;&#19982;&#20844;&#21496;&#30340;&#23398;&#20064;&#31639;&#27861;&#36827;&#34892;&#20132;&#20114;&#30340;&#24773;&#20917;&#12290;&#38598;&#20307;&#27719;&#32858;&#21442;&#19982;&#20010;&#20307;&#30340;&#25968;&#25454;&#24182;&#36890;&#36807;&#19968;&#31181;&#31639;&#27861;&#31574;&#30053;&#25351;&#23548;&#21442;&#19982;&#32773;&#20462;&#25913;&#33258;&#24049;&#30340;&#25968;&#25454;&#20197;&#23454;&#29616;&#38598;&#20307;&#30446;&#26631;&#12290;&#25105;&#20204;&#22312;&#19977;&#31181;&#22522;&#26412;&#30340;&#23398;&#20064;&#29702;&#35770;&#35774;&#32622;&#19979;&#30740;&#31350;&#20102;&#36825;&#31181;&#27169;&#22411;&#30340;&#32467;&#26524;&#65306;&#38750;&#21442;&#25968;&#26368;&#20248;&#23398;&#20064;&#31639;&#27861;&#65292;&#21442;&#25968;&#39118;&#38505;&#26368;&#23567;&#21270;&#21644;&#26799;&#24230;&#19979;&#38477;&#20248;&#21270;&#12290;&#22312;&#27599;&#20010;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21327;&#35843;&#30340;&#31639;&#27861;&#31574;&#30053;&#65292;&#24182;&#26681;&#25454;&#38598;&#20307;&#35268;&#27169;&#30340;&#22823;&#23567;&#26469;&#34920;&#24449;&#33258;&#28982;&#30340;&#25104;&#21151;&#26631;&#20934;&#12290;&#20026;&#20102;&#34917;&#20805;&#25105;&#20204;&#30340;&#29702;&#35770;&#65292;&#25105;&#20204;&#23545;&#28041;&#21450;&#25968;&#20197;&#19975;&#35745;&#33258;&#30001;&#32844;&#19994;&#24179;&#21488;&#31616;&#21382;&#30340;&#25216;&#33021;&#20998;&#31867;&#20219;&#21153;&#36827;&#34892;&#20102;&#31995;&#32479;&#23454;&#39564;&#12290;&#36890;&#36807; BERT &#27169;&#22411;&#30340;&#20004;&#21315;&#22810;&#27425;&#35757;&#32451;&#36816;&#34892;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#38598;&#20307;&#34892;&#21160;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#20998;&#31867;&#20934;&#30830;&#24615;&#65292;&#27604;&#38598;&#20013;&#24335;&#23398;&#20064;&#31639;&#27861;&#21644;&#29420;&#31435;&#20462;&#25913;&#25968;&#25454;&#30340;&#38750;&#21327;&#35843;&#26041;&#27861;&#35201;&#22909;&#24471;&#22810;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#31639;&#27861;&#38598;&#20307;&#34892;&#21160;&#30340;&#26377;&#25928;&#24615;&#33267;&#20851;&#37325;&#35201;&#30340;&#20381;&#36182;&#20110;&#38598;&#20307;&#30340;&#35268;&#27169;&#21644;&#25968;&#25454;&#30340;&#22522;&#26412;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
We initiate a principled study of algorithmic collective action on digital platforms that deploy machine learning algorithms. We propose a simple theoretical model of a collective interacting with a firm's learning algorithm. The collective pools the data of participating individuals and executes an algorithmic strategy by instructing participants how to modify their own data to achieve a collective goal. We investigate the consequences of this model in three fundamental learning-theoretic settings: the case of a nonparametric optimal learning algorithm, a parametric risk minimizer, and gradient-based optimization. In each setting, we come up with coordinated algorithmic strategies and characterize natural success criteria as a function of the collective's size. Complementing our theory, we conduct systematic experiments on a skill classification task involving tens of thousands of resumes from a gig platform for freelancers. Through more than two thousand model training runs of a BERT
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#38543;&#26426;&#32593;&#32476;&#30340;&#23398;&#20064;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102; Bayes &#26368;&#20248;&#27979;&#35797;&#35823;&#24046;&#30340;&#38381;&#24335;&#34920;&#36798;&#24335;&#12290;&#23725;&#22238;&#24402;&#21644;&#26680;&#22238;&#24402;&#33021;&#22815;&#36798;&#21040;&#26368;&#20248;&#34920;&#29616;&#65292;&#32780;&#31070;&#32463;&#32593;&#32476;&#30340;&#27979;&#35797;&#35823;&#24046;&#20063;&#21487;&#20197;&#20174;&#24179;&#26041;&#32423;&#30340;&#26679;&#26412;&#25968;&#37327;&#20013;&#33719;&#24471;&#25509;&#36817;&#20110;&#38646;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2302.00375</link><description>&lt;p&gt;
&#28145;&#24230;&#38543;&#26426;&#32593;&#32476;&#30340; Bayes &#26368;&#20248;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Bayes-optimal Learning of Deep Random Networks of Extensive-width. (arXiv:2302.00375v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.00375
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#38543;&#26426;&#32593;&#32476;&#30340;&#23398;&#20064;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102; Bayes &#26368;&#20248;&#27979;&#35797;&#35823;&#24046;&#30340;&#38381;&#24335;&#34920;&#36798;&#24335;&#12290;&#23725;&#22238;&#24402;&#21644;&#26680;&#22238;&#24402;&#33021;&#22815;&#36798;&#21040;&#26368;&#20248;&#34920;&#29616;&#65292;&#32780;&#31070;&#32463;&#32593;&#32476;&#30340;&#27979;&#35797;&#35823;&#24046;&#20063;&#21487;&#20197;&#20174;&#24179;&#26041;&#32423;&#30340;&#26679;&#26412;&#25968;&#37327;&#20013;&#33719;&#24471;&#25509;&#36817;&#20110;&#38646;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#23398;&#20064;&#19968;&#20010;&#28145;&#24230;&#24191;&#24230;&#38750;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#20854;&#20855;&#26377;&#38543;&#26426;&#39640;&#26031;&#26435;&#37325;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#26679;&#26412;&#25968;&#37327;&#12289;&#36755;&#20837;&#32500;&#25968;&#21644;&#32593;&#32476;&#23485;&#24230;&#25104;&#27604;&#20363;&#22686;&#21152;&#26102;&#30340;&#28176;&#36817;&#24773;&#20917;&#65292;&#24182;&#20026;&#22238;&#24402;&#21644;&#20998;&#31867;&#20219;&#21153;&#25552;&#20986;&#20102; Bayes &#26368;&#20248;&#27979;&#35797;&#35823;&#24046;&#30340;&#38381;&#24335;&#34920;&#36798;&#24335;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35745;&#31639;&#20102;&#23725;&#22238;&#24402;&#12289;&#26680;&#20989;&#25968;&#21644;&#38543;&#26426;&#29305;&#24449;&#22238;&#24402;&#30340;&#27979;&#35797;&#35823;&#24046;&#30340;&#38381;&#24335;&#34920;&#36798;&#24335;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#26368;&#20248;&#27491;&#21017;&#21270;&#30340;&#23725;&#22238;&#24402;&#20197;&#21450;&#26680;&#22238;&#24402;&#21487;&#20197;&#36798;&#21040; Bayes &#26368;&#20248;&#34920;&#29616;&#65292;&#32780;&#36923;&#36753;&#25439;&#22833;&#20989;&#25968;&#23545;&#20110;&#20998;&#31867;&#38382;&#39064;&#20960;&#20046;&#33021;&#36798;&#21040;&#26368;&#20248;&#30340;&#27979;&#35797;&#35823;&#24046;&#12290;&#25105;&#20204;&#36890;&#36807;&#25968;&#23383;&#23454;&#39564;&#35777;&#26126;&#65292;&#24403;&#26679;&#26412;&#25968;&#37327;&#22686;&#38271;&#36895;&#24230;&#24555;&#20110;&#32500;&#25968;&#26102;&#65292;&#23725;&#22238;&#24402;&#21644;&#26680;&#26041;&#27861;&#21464;&#24471;&#27425;&#20248;&#65292;&#32780;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#20174;&#24179;&#26041;&#32423;&#30340;&#26679;&#26412;&#25968;&#37327;&#20013;&#33719;&#24471;&#25509;&#36817;&#20110;&#38646;&#30340;&#27979;&#35797;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of learning a target function corresponding to a deep, extensive-width, non-linear neural network with random Gaussian weights. We consider the asymptotic limit where the number of samples, the input dimension and the network width are proportionally large. We propose a closed-form expression for the Bayes-optimal test error, for regression and classification tasks. We further compute closed-form expressions for the test errors of ridge regression, kernel and random features regression. We find, in particular, that optimally regularized ridge regression, as well as kernel regression, achieve Bayes-optimal performances, while the logistic loss yields a near-optimal test error for classification. We further show numerically that when the number of samples grows faster than the dimension, ridge and kernel methods become suboptimal, while neural networks achieve test error close to zero from quadratically many samples.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#23558;&#26377;&#21521;&#26080;&#29615;&#22270;&#20013;&#30340;&#27010;&#29575;&#22240;&#26524;&#30693;&#35782;&#24212;&#29992;&#20110;&#22238;&#24402;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#30896;&#25758;&#22238;&#24402;&#26694;&#26550;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#22312;&#20551;&#35774;&#31354;&#38388;&#20026;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#26102;&#20855;&#26377;&#20005;&#26684;&#27491;&#30340;&#24191;&#20041;&#25910;&#30410;&#65292;&#22312;&#21512;&#25104;&#21644;&#27668;&#20505;&#27169;&#22411;&#25968;&#25454;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20854;&#21487;&#20197;&#25552;&#39640;&#39044;&#27979;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2301.11214</link><description>&lt;p&gt;
&#22238;&#25253;&#24681;&#24800;&#65306;&#22238;&#24402;&#22914;&#20309;&#20174;&#27010;&#29575;&#22240;&#26524;&#30693;&#35782;&#20013;&#21463;&#30410;
&lt;/p&gt;
&lt;p&gt;
Returning The Favour: When Regression Benefits From Probabilistic Causal Knowledge. (arXiv:2301.11214v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11214
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#23558;&#26377;&#21521;&#26080;&#29615;&#22270;&#20013;&#30340;&#27010;&#29575;&#22240;&#26524;&#30693;&#35782;&#24212;&#29992;&#20110;&#22238;&#24402;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#30896;&#25758;&#22238;&#24402;&#26694;&#26550;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#22312;&#20551;&#35774;&#31354;&#38388;&#20026;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#26102;&#20855;&#26377;&#20005;&#26684;&#27491;&#30340;&#24191;&#20041;&#25910;&#30410;&#65292;&#22312;&#21512;&#25104;&#21644;&#27668;&#20505;&#27169;&#22411;&#25968;&#25454;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20854;&#21487;&#20197;&#25552;&#39640;&#39044;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26377;&#21521;&#26080;&#29615;&#22270;(DAG)&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#20808;&#39564;&#30693;&#35782;&#65292;&#20294;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#22238;&#24402;&#20219;&#21153;&#20013;&#32463;&#24120;&#34987;&#24573;&#30053;&#12290;&#26412;&#25991;&#34920;&#26126;&#65292;&#22312;DAG&#20013;&#30001;&#30896;&#25758;&#32467;&#26500;&#24341;&#36215;&#30340;&#29420;&#31435;&#24615;&#25552;&#20379;&#20102;&#26377;&#24847;&#20041;&#30340;&#24402;&#32435;&#20559;&#24046;&#65292;&#36825;&#21487;&#20197;&#38480;&#21046;&#22238;&#24402;&#20551;&#35774;&#31354;&#38388;&#24182;&#25552;&#39640;&#39044;&#27979;&#24615;&#33021;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#30896;&#25758;&#22238;&#24402;&#65292;&#19968;&#31181;&#23558;&#19968;&#20010;&#30896;&#25758;&#20013;&#30340;&#27010;&#29575;&#22240;&#26524;&#30693;&#35782;&#32435;&#20837;&#22238;&#24402;&#38382;&#39064;&#30340;&#26694;&#26550;&#12290;&#24403;&#20551;&#35774;&#31354;&#38388;&#20026;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#65292;&#20855;&#26377;&#20005;&#26684;&#27491;&#30340;&#24191;&#20041;&#25910;&#30410;&#65292;&#24182;&#25552;&#20379;&#20102;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#38381;&#21512;&#24418;&#24335;&#20272;&#35745;&#37327;&#12290;&#22312;&#21512;&#25104;&#21644;&#27668;&#20505;&#27169;&#22411;&#25968;&#25454;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#25216;&#26415;&#21487;&#20197;&#25552;&#39640;&#39044;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
A directed acyclic graph (DAG) provides valuable prior knowledge that is often discarded in regression tasks in machine learning. We show that the independences arising from the presence of collider structures in DAGs provide meaningful inductive biases, which constrain the regression hypothesis space and improve predictive performance. We introduce collider regression, a framework to incorporate probabilistic causal knowledge from a collider in a regression problem. When the hypothesis space is a reproducing kernel Hilbert space, we prove a strictly positive generalisation benefit under mild assumptions and provide closed-form estimators of the empirical risk minimiser. Experiments on synthetic and climate model data demonstrate performance gains of the proposed methodology.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#28789;&#27963;&#36125;&#21494;&#26031;&#22238;&#24402;&#26641;&#27169;&#22411;flexBART&#65292;&#21487;&#20197;&#22312;&#21010;&#20998;&#20998;&#31867;&#27700;&#24179;&#30340;&#31163;&#25955;&#38598;&#26102;&#65292;&#23558;&#22810;&#20010;&#27700;&#24179;&#20998;&#37197;&#32473;&#20915;&#31574;&#26641;&#33410;&#28857;&#30340;&#20004;&#20010;&#20998;&#25903;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#23545;&#20998;&#31867;&#39044;&#27979;&#21464;&#37327;&#30340;&#28789;&#27963;&#24314;&#27169;&#65292;&#36328;&#32423;&#21035;&#30340;&#25968;&#25454;&#37096;&#20998;&#27719;&#24635;&#33021;&#21147;&#20063;&#24471;&#21040;&#20102;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2211.04459</link><description>&lt;p&gt;
flexBART:&#20855;&#26377;&#20998;&#31867;&#39044;&#27979;&#21464;&#37327;&#30340;&#28789;&#27963;&#36125;&#21494;&#26031;&#22238;&#24402;&#26641;
&lt;/p&gt;
&lt;p&gt;
flexBART: Flexible Bayesian regression trees with categorical predictors. (arXiv:2211.04459v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.04459
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#28789;&#27963;&#36125;&#21494;&#26031;&#22238;&#24402;&#26641;&#27169;&#22411;flexBART&#65292;&#21487;&#20197;&#22312;&#21010;&#20998;&#20998;&#31867;&#27700;&#24179;&#30340;&#31163;&#25955;&#38598;&#26102;&#65292;&#23558;&#22810;&#20010;&#27700;&#24179;&#20998;&#37197;&#32473;&#20915;&#31574;&#26641;&#33410;&#28857;&#30340;&#20004;&#20010;&#20998;&#25903;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#23545;&#20998;&#31867;&#39044;&#27979;&#21464;&#37327;&#30340;&#28789;&#27963;&#24314;&#27169;&#65292;&#36328;&#32423;&#21035;&#30340;&#25968;&#25454;&#37096;&#20998;&#27719;&#24635;&#33021;&#21147;&#20063;&#24471;&#21040;&#20102;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22810;&#25968;&#36125;&#21494;&#26031;&#21152;&#27861;&#22238;&#24402;&#26641;&#65288;BART&#65289;&#30340;&#23454;&#29616;&#26041;&#27861;&#37319;&#29992;&#29420;&#28909;&#32534;&#30721;&#23558;&#20998;&#31867;&#39044;&#27979;&#21464;&#37327;&#26367;&#25442;&#20026;&#22810;&#20010;&#20108;&#36827;&#21046;&#25351;&#26631;&#65292;&#27599;&#20010;&#25351;&#26631;&#23545;&#24212;&#20110;&#27599;&#20010;&#32423;&#21035;&#25110;&#31867;&#21035;&#12290;&#29992;&#36825;&#20123;&#25351;&#26631;&#26500;&#24314;&#30340;&#22238;&#24402;&#26641;&#36890;&#36807;&#21453;&#22797;&#21024;&#38500;&#19968;&#20010;&#32423;&#21035;&#26469;&#21010;&#20998;&#20998;&#31867;&#27700;&#24179;&#30340;&#31163;&#25955;&#38598;&#12290;&#28982;&#32780;&#65292;&#32477;&#22823;&#22810;&#25968;&#20998;&#21106;&#19981;&#33021;&#20351;&#29992;&#27492;&#31574;&#30053;&#26500;&#24314;&#65292;&#20005;&#37325;&#38480;&#21046;&#20102;BART&#22312;&#36328;&#32423;&#21035;&#30340;&#25968;&#25454;&#37096;&#20998;&#27719;&#24635;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;&#21463;&#23545;&#26834;&#29699;&#25968;&#25454;&#21644;&#37051;&#37324;&#29359;&#32618;&#21160;&#24577;&#20998;&#26512;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#36890;&#36807;&#37325;&#26032;&#23454;&#29616;&#20197;&#33021;&#22815;&#23558;&#22810;&#20010;&#27700;&#24179;&#20998;&#37197;&#32473;&#20915;&#31574;&#26641;&#33410;&#28857;&#30340;&#20004;&#20010;&#20998;&#25903;&#30340;&#22238;&#24402;&#26641;&#26469;&#20811;&#26381;&#20102;&#36825;&#20010;&#38480;&#21046;&#12290;&#20026;&#20102;&#23545;&#32858;&#21512;&#20026;&#23567;&#21306;&#22495;&#30340;&#31354;&#38388;&#25968;&#25454;&#24314;&#27169;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20915;&#31574;&#35268;&#21017;&#20808;&#39564;&#65292;&#36890;&#36807;&#20174;&#36866;&#24403;&#23450;&#20041;&#30340;&#32593;&#32476;&#30340;&#38543;&#26426;&#29983;&#25104;&#26641;&#20013;&#21024;&#38500;&#19968;&#20010;&#38543;&#26426;&#36793;&#26469;&#21019;&#24314;&#31354;&#38388;&#36830;&#32493;&#30340;&#21306;&#22495;&#12290;&#25105;&#20204;&#30340;&#37325;&#26032;&#23454;&#29616;&#65292;&#21487;&#22312;R&#30340;flexBART&#36719;&#20214;&#21253;&#20013;&#20351;&#29992;&#65292;&#20801;&#35768;&#28789;&#27963;&#22320;&#24314;&#27169;&#20998;&#31867;&#39044;&#27979;&#21464;&#37327;&#24182;&#25913;&#36827;&#36328;&#19981;&#21516;&#32423;&#21035;&#30340;&#25968;&#25454;&#37096;&#20998;&#27719;&#24635;&#12290;
&lt;/p&gt;
&lt;p&gt;
Most implementations of Bayesian additive regression trees (BART) one-hot encode categorical predictors, replacing each one with several binary indicators, one for every level or category. Regression trees built with these indicators partition the discrete set of categorical levels by repeatedly removing one level at a time. Unfortunately, the vast majority of partitions cannot be built with this strategy, severely limiting BART's ability to partially pool data across groups of levels. Motivated by analyses of baseball data and neighborhood-level crime dynamics, we overcame this limitation by re-implementing BART with regression trees that can assign multiple levels to both branches of a decision tree node. To model spatial data aggregated into small regions, we further proposed a new decision rule prior that creates spatially contiguous regions by deleting a random edge from a random spanning tree of a suitably defined network. Our re-implementation, which is available in the flexBART
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#30528;&#27491;&#21017;&#21270;&#21442;&#25968;&#28040;&#22833;&#65292;&#21457;&#25955;-&#27491;&#21017;&#21270;&#26368;&#20248;&#36755;&#36816;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#36890;&#36807;&#37327;&#21270;&#21644;&#38789;&#32806;&#21512;&#25216;&#26415;&#24471;&#21040;&#20102;&#19968;&#20123;&#19968;&#33324;&#21457;&#25955;&#24615;&#12289;&#21253;&#25324;&#30456;&#23545;&#29109;&#25110; $L^{p}$ &#27491;&#21017;&#21270;&#12289;&#19968;&#33324;&#36816;&#36755;&#25104;&#26412;&#21644;&#22810;&#36793;&#38382;&#39064;&#30340;&#23574;&#38160;&#36895;&#29575;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2208.14391</link><description>&lt;p&gt;
&#36890;&#36807;&#37327;&#21270;&#23454;&#29616;&#27491;&#21017;&#21270;&#26368;&#20248;&#36755;&#36816;&#30340;&#25910;&#25947;&#36895;&#29575;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Convergence Rates for Regularized Optimal Transport via Quantization. (arXiv:2208.14391v3 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.14391
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#30528;&#27491;&#21017;&#21270;&#21442;&#25968;&#28040;&#22833;&#65292;&#21457;&#25955;-&#27491;&#21017;&#21270;&#26368;&#20248;&#36755;&#36816;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#36890;&#36807;&#37327;&#21270;&#21644;&#38789;&#32806;&#21512;&#25216;&#26415;&#24471;&#21040;&#20102;&#19968;&#20123;&#19968;&#33324;&#21457;&#25955;&#24615;&#12289;&#21253;&#25324;&#30456;&#23545;&#29109;&#25110; $L^{p}$ &#27491;&#21017;&#21270;&#12289;&#19968;&#33324;&#36816;&#36755;&#25104;&#26412;&#21644;&#22810;&#36793;&#38382;&#39064;&#30340;&#23574;&#38160;&#36895;&#29575;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#30528;&#27491;&#21017;&#21270;&#21442;&#25968;&#28040;&#22833;&#65292;&#21457;&#25955;-&#27491;&#21017;&#21270;&#26368;&#20248;&#36755;&#36816;&#30340;&#25910;&#25947;&#24615;&#12290;&#24471;&#21040;&#20102;&#19968;&#20123;&#19968;&#33324;&#21457;&#25955;&#24615;&#12289;&#21253;&#25324;&#30456;&#23545;&#29109;&#25110; $L^{p}$ &#27491;&#21017;&#21270;&#12289;&#19968;&#33324;&#36816;&#36755;&#25104;&#26412;&#21644;&#22810;&#36793;&#38382;&#39064;&#30340;&#23574;&#38160;&#36895;&#29575;&#32467;&#26524;&#12290;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#37327;&#21270;&#21644;&#38789;&#32806;&#21512;&#25216;&#26415;&#65292;&#36866;&#29992;&#20110;&#38750;&#32039;&#33268;&#36793;&#32536;&#65292;&#24182;&#23454;&#29616;&#20102;&#25152;&#26377;&#26377;&#38480; $(2+\delta)$-&#30697;&#30340;&#36793;&#32536;&#19978;&#30340;&#29109;&#27491;&#21017;&#21270; 2-Wasserstein &#36317;&#31163;&#30340;&#23574;&#38160;&#39046;&#20808;&#38454;&#39033;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the convergence of divergence-regularized optimal transport as the regularization parameter vanishes. Sharp rates for general divergences including relative entropy or $L^{p}$ regularization, general transport costs and multi-marginal problems are obtained. A novel methodology using quantization and martingale couplings is suitable for non-compact marginals and achieves, in particular, the sharp leading-order term of entropically regularized 2-Wasserstein distance for all marginals with finite $(2+\delta)$-moment.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#21435;&#20559;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#36882;&#24402;Riesz&#34920;&#24449;&#23884;&#22871;&#22343;&#20540;&#22238;&#24402;&#65292;&#36991;&#20813;&#20102;&#22312;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;&#20013;&#38656;&#35201;&#35299;&#20915;&#36741;&#21161;&#20542;&#21521;&#27169;&#22411;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2203.13887</link><description>&lt;p&gt;
&#21160;&#24577;&#27835;&#30103;&#25928;&#24212;&#21644;&#19968;&#33324;&#23884;&#22871;&#20989;&#25968;&#30340;&#33258;&#21160;&#21435;&#20559;&#26426;&#22120;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Automatic Debiased Machine Learning for Dynamic Treatment Effects and General Nested Functionals. (arXiv:2203.13887v5 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.13887
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#21160;&#21435;&#20559;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#36882;&#24402;Riesz&#34920;&#24449;&#23884;&#22871;&#22343;&#20540;&#22238;&#24402;&#65292;&#36991;&#20813;&#20102;&#22312;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;&#20013;&#38656;&#35201;&#35299;&#20915;&#36741;&#21161;&#20542;&#21521;&#27169;&#22411;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23558;&#33258;&#21160;&#21435;&#20559;&#26426;&#22120;&#23398;&#20064;&#30340;&#24605;&#24819;&#25193;&#23637;&#21040;&#20102;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;&#21644;&#26356;&#19968;&#33324;&#30340;&#23884;&#22871;&#20989;&#25968;&#19978;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#21160;&#24577;&#27835;&#30103;&#26041;&#26696;&#31163;&#25955;&#22788;&#29702;&#30340;&#22810;&#37325;&#31283;&#20581;&#20844;&#24335;&#21487;&#20197;&#29992;&#23884;&#22871;&#22343;&#20540;&#22238;&#24402;&#30340;&#36882;&#24402; Riesz &#34920;&#31034;&#26469;&#37325;&#26032;&#34920;&#36848;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24212;&#29992;&#19968;&#31181;&#36882;&#24402; Riesz &#34920;&#31034;&#20272;&#35745;&#23398;&#20064;&#31639;&#27861;&#65292;&#20272;&#35745;&#21435;&#20559;&#36716;&#21270;&#30340;&#20462;&#27491;&#65292;&#32780;&#26080;&#38656;&#25551;&#36848;&#26657;&#27491;&#39033;&#30340;&#24418;&#24335;&#65292;&#20363;&#22914;&#20498;&#25968;&#27010;&#29575;&#21152;&#26435;&#39033;&#30340;&#20056;&#31215;&#65292;&#22914;&#22312;&#21160;&#24577;&#26426;&#21046;&#20013;&#36827;&#34892;&#30340;&#21452;&#37325;&#31283;&#20581;&#20272;&#35745;&#20013;&#25152;&#20570;&#30340;&#37027;&#26679;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23450;&#20041;&#20102;&#19968;&#31995;&#21015;&#25439;&#22833;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#20854;&#26368;&#23567;&#21270;&#22120;&#26159;&#21435;&#20559;&#36716;&#21270;&#30340;&#20462;&#27491;&#30340;&#20056;&#25968;&#65292;&#20174;&#32780;&#36991;&#20813;&#20102;&#38656;&#35201;&#35299;&#20915;&#36741;&#21161;&#20542;&#21521;&#27169;&#22411;&#65292;&#24182;&#30452;&#25509;&#20248;&#21270;&#30446;&#26631;&#21435;&#20559;&#24615;&#20462;&#27491;&#30340;&#22343;&#26041;&#35823;&#24046;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#19968;&#20123;&#23454;&#38469;&#38382;&#39064;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
We extend the idea of automated debiased machine learning to the dynamic treatment regime and more generally to nested functionals. We show that the multiply robust formula for the dynamic treatment regime with discrete treatments can be re-stated in terms of a recursive Riesz representer characterization of nested mean regressions. We then apply a recursive Riesz representer estimation learning algorithm that estimates de-biasing corrections without the need to characterize how the correction terms look like, such as for instance, products of inverse probability weighting terms, as is done in prior work on doubly robust estimation in the dynamic regime. Our approach defines a sequence of loss minimization problems, whose minimizers are the mulitpliers of the de-biasing correction, hence circumventing the need for solving auxiliary propensity models and directly optimizing for the mean squared error of the target de-biasing correction. We provide further applications of our approach to
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;GNN&#31639;&#27861;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#36890;&#20449;&#32593;&#32476;&#20013;&#22788;&#29702;&#36830;&#25509;&#25925;&#38556;&#24341;&#36215;&#30340;&#32602;&#27454;&#20998;&#24067;&#65292;&#24182;&#21487;&#20197;&#20934;&#30830;&#22320;&#27169;&#25311;&#21508;&#31181;&#29616;&#26377;&#25299;&#25169;&#32467;&#26500;&#20013;&#30340;&#24809;&#32602;&#65292;&#22312;&#23454;&#36341;&#20013;&#36824;&#33719;&#24471;&#20102;&#36229;&#36807;12,000&#20493;&#30340;&#36895;&#24230;&#25552;&#39640;&#12290;</title><link>http://arxiv.org/abs/2201.12263</link><description>&lt;p&gt;
RiskNet:&#19981;&#21487;&#38752;&#36164;&#28304;&#32593;&#32476;&#30340;&#31070;&#32463;&#39118;&#38505;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
RiskNet: Neural Risk Assessment in Networks of Unreliable Resources. (arXiv:2201.12263v2 [cs.NI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.12263
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;GNN&#31639;&#27861;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#36890;&#20449;&#32593;&#32476;&#20013;&#22788;&#29702;&#36830;&#25509;&#25925;&#38556;&#24341;&#36215;&#30340;&#32602;&#27454;&#20998;&#24067;&#65292;&#24182;&#21487;&#20197;&#20934;&#30830;&#22320;&#27169;&#25311;&#21508;&#31181;&#29616;&#26377;&#25299;&#25169;&#32467;&#26500;&#20013;&#30340;&#24809;&#32602;&#65292;&#22312;&#23454;&#36341;&#20013;&#36824;&#33719;&#24471;&#20102;&#36229;&#36807;12,000&#20493;&#30340;&#36895;&#24230;&#25552;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#39044;&#27979;&#36890;&#20449;&#32593;&#32476;&#20013;&#30340;&#25925;&#38556;&#24341;&#36215;&#30340;&#32602;&#27454;&#20998;&#24067;&#65292;&#20854;&#20013;&#36830;&#25509;&#21463;&#20849;&#20139;&#20110;&#24037;&#20316;&#36335;&#24452;&#21644;&#22791;&#29992;&#36335;&#24452;&#20043;&#38388;&#30340;&#36164;&#28304;&#20445;&#25252;&#12290;&#35813;GNN&#31639;&#27861;&#20165;&#20351;&#29992;&#36890;&#36807;Barab\'asi-Albert&#27169;&#22411;&#29983;&#25104;&#30340;&#38543;&#26426;&#22270;&#36827;&#34892;&#35757;&#32451;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#25152;&#24471;&#30340;&#27979;&#35797;&#32467;&#26524;&#34920;&#26126;&#25105;&#20204;&#21487;&#20197;&#20934;&#30830;&#22320;&#27169;&#25311;&#21508;&#31181;&#29616;&#26377;&#25299;&#25169;&#32467;&#26500;&#20013;&#30340;&#24809;&#32602;&#12290;GNN&#28040;&#38500;&#20102;&#22312;&#30740;&#31350;&#32593;&#32476;&#25299;&#25169;&#26102;&#27169;&#25311;&#22797;&#26434;&#25925;&#38556;&#22330;&#26223;&#30340;&#38656;&#35201;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#25972;&#20010;&#35774;&#35745;&#25805;&#20316;&#20165;&#21463;&#29616;&#20195;&#30828;&#20214;&#30340;4ms&#30340;&#38480;&#21046;&#12290;&#36825;&#26679;&#65292;&#25105;&#20204;&#21487;&#20197;&#33719;&#24471;&#36229;&#36807;12,000&#20493;&#30340;&#36895;&#24230;&#25552;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a graph neural network (GNN)-based method to predict the distribution of penalties induced by outages in communication networks, where connections are protected by resources shared between working and backup paths. The GNN-based algorithm is trained only with random graphs generated with the Barab\'asi-Albert model. Even though, the obtained test results show that we can precisely model the penalties in a wide range of various existing topologies. GNNs eliminate the need to simulate complex outage scenarios for the network topologies under study. In practice, the whole design operation is limited by 4ms on modern hardware. This way, we can gain as much as over 12,000 times in the speed improvement.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23884;&#22871;&#27169;&#25311;&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#33021;&#22815;&#22312;&#20445;&#25345;&#26465;&#20214;&#26399;&#26395;&#36275;&#22815;&#24179;&#28369;&#30340;&#24773;&#20917;&#19979;&#65292;&#26377;&#25928;&#22320;&#32531;&#35299;&#39640;&#32500;&#24230;&#20013;&#30340;&#32500;&#24230;&#28798;&#38590;&#65292;&#20197;&#26725;&#25509;&#26631;&#20934;&#23884;&#22871;&#27169;&#25311;&#30340;&#31435;&#26041;&#26681;&#25910;&#25947;&#29575;&#21644;&#26631;&#20934;&#33945;&#29305;&#21345;&#27931;&#27169;&#25311;&#30340;&#24179;&#26041;&#26681;&#25910;&#25947;&#29575;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;</title><link>http://arxiv.org/abs/2201.02958</link><description>&lt;p&gt;
&#24179;&#28369;&#30340;&#23884;&#22871;&#27169;&#25311;&#26041;&#27861;&#65306;&#22312;&#39640;&#32500;&#24230;&#20013;&#26725;&#25509;&#31435;&#26041;&#21644;&#24179;&#26041;&#26681;&#25910;&#25947;&#29575;
&lt;/p&gt;
&lt;p&gt;
Smooth Nested Simulation: Bridging Cubic and Square Root Convergence Rates in High Dimensions. (arXiv:2201.02958v4 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.02958
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23884;&#22871;&#27169;&#25311;&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#33021;&#22815;&#22312;&#20445;&#25345;&#26465;&#20214;&#26399;&#26395;&#36275;&#22815;&#24179;&#28369;&#30340;&#24773;&#20917;&#19979;&#65292;&#26377;&#25928;&#22320;&#32531;&#35299;&#39640;&#32500;&#24230;&#20013;&#30340;&#32500;&#24230;&#28798;&#38590;&#65292;&#20197;&#26725;&#25509;&#26631;&#20934;&#23884;&#22871;&#27169;&#25311;&#30340;&#31435;&#26041;&#26681;&#25910;&#25947;&#29575;&#21644;&#26631;&#20934;&#33945;&#29305;&#21345;&#27931;&#27169;&#25311;&#30340;&#24179;&#26041;&#26681;&#25910;&#25947;&#29575;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23884;&#22871;&#27169;&#25311;&#26159;&#36890;&#36807;&#27169;&#25311;&#26469;&#20272;&#35745;&#26465;&#20214;&#26399;&#26395;&#30340;&#21151;&#33021;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#23725;&#22238;&#24402;&#30340;&#26032;&#26041;&#27861;&#65292;&#20197;&#21033;&#29992;&#26465;&#20214;&#26399;&#26395;&#20316;&#20026;&#22810;&#32500;&#35843;&#33410;&#21464;&#37327;&#30340;&#24179;&#28369;&#20989;&#25968;&#12290;&#28176;&#36817;&#20998;&#26512;&#34920;&#26126;&#65292;&#21482;&#35201;&#26465;&#20214;&#26399;&#26395;&#36275;&#22815;&#24179;&#28369;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#33021;&#22815;&#22312;&#27169;&#25311;&#27425;&#25968;&#22686;&#21152;&#26102;&#26377;&#25928;&#22320;&#20943;&#23569;&#32500;&#24230;&#28798;&#38590;&#30340;&#24433;&#21709;&#12290;&#24179;&#28369;&#24615;&#26725;&#25509;&#20102;&#31435;&#26041;&#26681;&#25910;&#25947;&#29575;&#65288;&#21363;&#26631;&#20934;&#23884;&#22871;&#27169;&#25311;&#30340;&#26368;&#20248;&#25910;&#25947;&#29575;&#65289;&#21644;&#24179;&#26041;&#26681;&#25910;&#25947;&#29575;&#65288;&#21363;&#26631;&#20934;&#33945;&#29305;&#21345;&#27931;&#27169;&#25311;&#30340;&#35268;&#33539;&#25910;&#25947;&#29575;&#65289;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#25105;&#20204;&#36890;&#36807;&#32452;&#21512;&#39118;&#38505;&#31649;&#29702;&#21644;&#36755;&#20837;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#25968;&#20540;&#31034;&#20363;&#65292;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Nested simulation concerns estimating functionals of a conditional expectation via simulation. In this paper, we propose a new method based on kernel ridge regression to exploit the smoothness of the conditional expectation as a function of the multidimensional conditioning variable. Asymptotic analysis shows that the proposed method can effectively alleviate the curse of dimensionality on the convergence rate as the simulation budget increases, provided that the conditional expectation is sufficiently smooth. The smoothness bridges the gap between the cubic root convergence rate (that is, the optimal rate for the standard nested simulation) and the square root convergence rate (that is, the canonical rate for the standard Monte Carlo simulation). We demonstrate the performance of the proposed method via numerical examples from portfolio risk management and input uncertainty quantification.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;GraphDINO&#65292;&#19968;&#31181;&#33258;&#30417;&#30563;&#30340;&#22270;&#24418;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#20174;&#26410;&#26631;&#35760;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#20013;&#23398;&#20064;&#19977;&#32500;&#31070;&#32463;&#20803;&#24418;&#24577;&#30340;&#20302;&#32500;&#34920;&#31034;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992;&#20102;&#19968;&#31995;&#21015;&#25968;&#25454;&#22686;&#24378;&#31574;&#30053;&#21644;&#26032;&#22411;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;AC-Attention&#65292;&#22312;&#22810;&#20010;&#22823;&#33041;&#21306;&#22495;&#20869;&#65292;GraphDINO &#26174;&#31034;&#20986;&#20102;&#20248;&#20110;&#20854;&#23427;&#26368;&#20808;&#36827;&#26041;&#27861;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2112.12482</link><description>&lt;p&gt;
&#33258;&#30417;&#30563;&#30340;&#22270;&#24418;&#34920;&#31034;&#23398;&#20064;&#22312;&#31070;&#32463;&#20803;&#24418;&#24577;&#23398;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Self-Supervised Graph Representation Learning for Neuronal Morphologies. (arXiv:2112.12482v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.12482
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;GraphDINO&#65292;&#19968;&#31181;&#33258;&#30417;&#30563;&#30340;&#22270;&#24418;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#20174;&#26410;&#26631;&#35760;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#20013;&#23398;&#20064;&#19977;&#32500;&#31070;&#32463;&#20803;&#24418;&#24577;&#30340;&#20302;&#32500;&#34920;&#31034;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992;&#20102;&#19968;&#31995;&#21015;&#25968;&#25454;&#22686;&#24378;&#31574;&#30053;&#21644;&#26032;&#22411;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;AC-Attention&#65292;&#22312;&#22810;&#20010;&#22823;&#33041;&#21306;&#22495;&#20869;&#65292;GraphDINO &#26174;&#31034;&#20986;&#20102;&#20248;&#20110;&#20854;&#23427;&#26368;&#20808;&#36827;&#26041;&#27861;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#30340;&#22270;&#24418;&#34920;&#31034;&#23398;&#20064;&#22312;&#22810;&#20010;&#24212;&#29992;&#39046;&#22495;&#22914;&#31070;&#32463;&#31185;&#23398;&#20013;&#21560;&#24341;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#65292;&#20854;&#20013;&#23545;&#22823;&#33041;&#20013;&#32454;&#32990;&#31867;&#22411;&#30340;&#22810;&#26679;&#24418;&#24577;&#36827;&#34892;&#24314;&#27169;&#26159;&#20854;&#20013;&#30340;&#20851;&#38190;&#25361;&#25112;&#20043;&#19968;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;GraphDINO&#65292;&#19968;&#31181;&#29992;&#20110;&#20174;&#26410;&#26631;&#35760;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#20013;&#23398;&#20064;&#19977;&#32500;&#31070;&#32463;&#20803;&#24418;&#24577;&#30340;&#20302;&#32500;&#34920;&#31034;&#30340;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#12290;GraphDINO &#26159;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;Transformer&#27169;&#22411;&#30340;&#29992;&#20110;&#31354;&#38388;&#23884;&#20837;&#24335;&#22270;&#24418;&#34920;&#31034;&#23398;&#20064;&#30340;&#26041;&#27861;&#12290;&#20026;&#20102;&#20351;Transformer&#27169;&#22411;&#33021;&#22815;&#36827;&#34892;&#33258;&#30417;&#30563;&#23398;&#20064;&#65292;&#25105;&#20204; (1)&#24320;&#21457;&#20102;&#38024;&#23545;&#31354;&#38388;&#23884;&#20837;&#24335;&#22270;&#24418;&#30340;&#25968;&#25454;&#22686;&#24378;&#31574;&#30053;&#65292; (2) &#23545;&#20301;&#32622;&#32534;&#30721;&#36827;&#34892;&#20102;&#20462;&#25913;&#65292; (3)&#24341;&#20837;&#20102;&#26032;&#22411;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;AC-Attention&#65292;&#23427;&#32467;&#21512;&#20102;&#33410;&#28857;&#38388;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#20840;&#23616;&#20132;&#20114;&#21644;&#20256;&#32479;&#30340;&#22270;&#24418;&#21367;&#31215;&#22788;&#29702;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#19981;&#21516;&#31181;&#31867;&#30340;&#12289;&#36328;&#36234;&#22810;&#20010;&#22823;&#33041;&#21306;&#22495;&#30340;&#31070;&#32463;&#20803;&#25968;&#25454;&#19978;&#27979;&#35797;&#65292;&#32467;&#26524;&#34920;&#26126;&#65292;GraphDINO &#22312;&#31070;&#32463;&#20803;&#24418;&#24577;&#23398;&#34920;&#31034;&#23398;&#20064;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20248;&#20110;&#30446;&#21069;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#33258;&#30417;&#30563;&#26041;&#27861;&#21487;&#20197;&#23398;&#20064;&#21040;&#25429;&#25417;&#31070;&#32463;&#20803;&#24418;&#24577;&#23398;&#30456;&#20851;&#29305;&#24449;&#30340;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Unsupervised graph representation learning has recently gained interest in several application domains such as neuroscience, where modeling the diverse morphology of cell types in the brain is one of the key challenges. It is currently unknown how many excitatory cortical cell types exist and what their defining morphological features are. Here we present GraphDINO, a purely data-driven approach to learn low-dimensional representations of 3D neuronal morphologies from unlabeled large-scale datasets. GraphDINO is a novel transformer-based representation learning method for spatially-embedded graphs. To enable self-supervised learning on transformers, we (1) developed data augmentation strategies for spatially-embedded graphs, (2) adapted the positional encoding and (3) introduced a novel attention mechanism, AC-Attention, which combines attention-based global interaction between nodes and classic graph convolutional processing. We show, in two different species and across multiple brain
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#38754;&#23545;&#33258;&#36866;&#24212;&#36873;&#25321;&#25968;&#25454;&#26679;&#26412;&#24341;&#36215;&#30340;&#36807;&#24230;&#25311;&#21512;&#38382;&#39064;&#65292;&#20351;&#29992;&#22122;&#22768;&#21152;&#31639;&#27861;&#21487;&#20197;&#25552;&#20379;&#19981;&#20381;&#36182;&#20110;&#26597;&#35810;&#35268;&#27169;&#30340;&#35823;&#24046;&#20445;&#35777;&#65292;&#36825;&#19968;&#32467;&#26524;&#34920;&#26126;&#36866;&#24212;&#25968;&#25454;&#20998;&#26512;&#30340;&#38382;&#39064;&#22312;&#20110;&#26032;&#26597;&#35810;&#19982;&#36807;&#21435;&#26597;&#35810;&#30340;&#21327;&#26041;&#24046;&#12290;</title><link>http://arxiv.org/abs/2106.10761</link><description>&lt;p&gt;
&#38754;&#23545;&#36866;&#24212;&#24615;&#27867;&#21270;&#65306;&#36125;&#21494;&#26031;&#35270;&#35282;&#19979;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Generalization in the Face of Adaptivity: A Bayesian Perspective. (arXiv:2106.10761v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.10761
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#38754;&#23545;&#33258;&#36866;&#24212;&#36873;&#25321;&#25968;&#25454;&#26679;&#26412;&#24341;&#36215;&#30340;&#36807;&#24230;&#25311;&#21512;&#38382;&#39064;&#65292;&#20351;&#29992;&#22122;&#22768;&#21152;&#31639;&#27861;&#21487;&#20197;&#25552;&#20379;&#19981;&#20381;&#36182;&#20110;&#26597;&#35810;&#35268;&#27169;&#30340;&#35823;&#24046;&#20445;&#35777;&#65292;&#36825;&#19968;&#32467;&#26524;&#34920;&#26126;&#36866;&#24212;&#25968;&#25454;&#20998;&#26512;&#30340;&#38382;&#39064;&#22312;&#20110;&#26032;&#26597;&#35810;&#19982;&#36807;&#21435;&#26597;&#35810;&#30340;&#21327;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#36866;&#24212;&#36873;&#25321;&#26679;&#26412;&#21487;&#33021;&#23548;&#33268;&#36807;&#24230;&#25311;&#21512;&#65292;&#31616;&#21333;&#30340;&#22122;&#22768;&#21152;&#31639;&#27861;&#21487;&#20197;&#36991;&#20813;&#36825;&#19968;&#38382;&#39064;&#12290;&#26412;&#25991;&#35777;&#26126;&#20102;&#22122;&#22768;&#21152;&#31639;&#27861;&#21487;&#20197;&#25552;&#20379;&#19981;&#20381;&#36182;&#20110;&#26597;&#35810;&#35268;&#27169;&#30340;&#35823;&#24046;&#20445;&#35777;&#65292;&#36825;&#19968;&#32467;&#26524;&#26469;&#28304;&#20110;&#26356;&#22909;&#22320;&#29702;&#35299;&#33258;&#36866;&#24212;&#25968;&#25454;&#20998;&#26512;&#30340;&#26680;&#24515;&#38382;&#39064;&#12290;&#25105;&#20204;&#34920;&#26126;&#36866;&#24212;&#25968;&#25454;&#20998;&#26512;&#30340;&#38382;&#39064;&#22312;&#20110;&#26032;&#26597;&#35810;&#19982;&#36807;&#21435;&#26597;&#35810;&#30340;&#21327;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Repeated use of a data sample via adaptively chosen queries can rapidly lead to overfitting, wherein the empirical evaluation of queries on the sample significantly deviates from their mean with respect to the underlying data distribution. It turns out that simple noise addition algorithms suffice to prevent this issue, and differential privacy-based analysis of these algorithms shows that they can handle an asymptotically optimal number of queries. However, differential privacy's worst-case nature entails scaling such noise to the range of the queries even for highly-concentrated queries, or introducing more complex algorithms.  In this paper, we prove that straightforward noise-addition algorithms already provide variance-dependent guarantees that also extend to unbounded queries. This improvement stems from a novel characterization that illuminates the core problem of adaptive data analysis. We show that the harm of adaptivity results from the covariance between the new query and a 
&lt;/p&gt;</description></item></channel></rss>