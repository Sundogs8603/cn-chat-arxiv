<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#30740;&#31350;&#24314;&#31435;&#20102;&#39318;&#20010;&#22312;&#23545;&#25239;&#24615;&#22810;&#33218;&#32769;&#34382;&#26426;&#20013;&#20248;&#21270;&#19988;&#33258;&#36866;&#24212;&#30340;&#27874;&#36798;&#21160;&#24577;&#36951;&#25022;&#19978;&#30028;&#65292;&#25581;&#31034;&#20102;&#22312;Condorcet&#21644;Borda&#20043;&#38388;&#20005;&#37325;&#38750;&#24179;&#31283;&#24615;&#21487;&#23398;&#20064;&#24615;&#30340;&#22522;&#26412;&#24046;&#24322;</title><link>https://arxiv.org/abs/2403.12950</link><description>&lt;p&gt;
&#20248;&#21270;&#30340;&#33258;&#36866;&#24212;&#38750;&#24179;&#31283;&#23545;&#25239;&#24615;&#22810;&#33218;&#32769;&#34382;&#26426;&#22312;&#24191;&#20041;&#27874;&#36798;&#20934;&#21017;&#19979;
&lt;/p&gt;
&lt;p&gt;
Optimal and Adaptive Non-Stationary Dueling Bandits Under a Generalized Borda Criterion
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12950
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#24314;&#31435;&#20102;&#39318;&#20010;&#22312;&#23545;&#25239;&#24615;&#22810;&#33218;&#32769;&#34382;&#26426;&#20013;&#20248;&#21270;&#19988;&#33258;&#36866;&#24212;&#30340;&#27874;&#36798;&#21160;&#24577;&#36951;&#25022;&#19978;&#30028;&#65292;&#25581;&#31034;&#20102;&#22312;Condorcet&#21644;Borda&#20043;&#38388;&#20005;&#37325;&#38750;&#24179;&#31283;&#24615;&#21487;&#23398;&#20064;&#24615;&#30340;&#22522;&#26412;&#24046;&#24322;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23545;&#25239;&#24615;&#22810;&#33218;&#32769;&#34382;&#26426;&#20013;&#65292;&#23398;&#20064;&#32773;&#25509;&#25910;&#33218;&#20043;&#38388;&#30340;&#20559;&#22909;&#21453;&#39304;&#65292;&#24182;&#23558;&#26576;&#20010;&#33218;&#30340;&#36951;&#25022;&#23450;&#20041;&#20026;&#20854;&#30456;&#23545;&#20110;&#20248;&#32988;&#33218;&#30340;&#27425;&#20248;&#24615;&#12290;&#26356;&#20855;&#25361;&#25112;&#24615;&#21644;&#23454;&#36341;&#21160;&#26426;&#30340;&#38750;&#24179;&#31283;&#23545;&#25239;&#24615;&#22810;&#33218;&#32769;&#34382;&#26426;&#21464;&#20307;&#65292;&#22312;&#36825;&#31181;&#21464;&#20307;&#20013;&#65292;&#20559;&#22909;&#38543;&#26102;&#38388;&#21464;&#21270;&#65292;&#24050;&#32463;&#25104;&#20026;&#36817;&#26399;&#22810;&#39033;&#24037;&#20316;&#30340;&#28966;&#28857;&#12290;&#30446;&#26631;&#26159;&#35774;&#35745;&#20986;&#31639;&#27861;&#65292;&#32780;&#26080;&#38656;&#25552;&#21069;&#20102;&#35299;&#21464;&#21270;&#37327;&#12290;&#24050;&#30693;&#32467;&#26524;&#30340;&#22823;&#37096;&#20998;&#30740;&#31350;&#20102;&#23380;&#22810;&#22622;&#20248;&#32988;&#32773;&#35774;&#32622;&#65292;&#20854;&#20013;&#20248;&#20808;&#20110;&#20854;&#20182;&#20219;&#20309;&#33218;&#30340;&#33218;&#22312;&#20219;&#20309;&#26102;&#20505;&#37117;&#23384;&#22312;&#12290;&#28982;&#32780;&#65292;&#36825;&#26679;&#30340;&#20248;&#32988;&#32773;&#21487;&#33021;&#24182;&#19981;&#23384;&#22312;&#65292;&#20026;&#20102;&#23545;&#27604;&#65292;&#27492;&#38382;&#39064;&#30340;&#27874;&#36798;&#29256;&#26412;&#65288;&#22987;&#32456;&#26377;&#26126;&#30830;&#23450;&#20041;&#65289;&#21364;&#21463;&#21040;&#20102;&#24456;&#23569;&#20851;&#27880;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#31532;&#19968;&#20010;&#26368;&#20248;&#21644;&#33258;&#36866;&#24212;&#30340;&#27874;&#36798;&#21160;&#24577;&#36951;&#25022;&#19978;&#30028;&#65292;&#31361;&#26174;&#20102;&#22312;&#23380;&#22810;&#22622;&#21644;&#27874;&#36798;&#20043;&#38388;&#30340;&#20005;&#37325;&#38750;&#24179;&#31283;&#24615;&#21487;&#23398;&#20064;&#24615;&#30340;&#22522;&#26412;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12950v1 Announce Type: new  Abstract: In dueling bandits, the learner receives preference feedback between arms, and the regret of an arm is defined in terms of its suboptimality to a winner arm. The more challenging and practically motivated non-stationary variant of dueling bandits, where preferences change over time, has been the focus of several recent works (Saha and Gupta, 2022; Buening and Saha, 2023; Suk and Agarwal, 2023). The goal is to design algorithms without foreknowledge of the amount of change.   The bulk of known results here studies the Condorcet winner setting, where an arm preferred over any other exists at all times. Yet, such a winner may not exist and, to contrast, the Borda version of this problem (which is always well-defined) has received little attention. In this work, we establish the first optimal and adaptive Borda dynamic regret upper bound, which highlights fundamental differences in the learnability of severe non-stationarity between Condorce
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#23433;&#20840;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#23433;&#20840;&#24615;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;Real-\b{eta}-SafeOpt&#31639;&#27861;&#65292;&#26377;&#25928;&#20445;&#30041;&#20102;&#25152;&#26377;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2403.12948</link><description>&lt;p&gt;
&#20851;&#20110;&#23433;&#20840;&#30340;&#23433;&#20840;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
On Safety in Safe Bayesian Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12948
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#23433;&#20840;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#23433;&#20840;&#24615;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;Real-\b{eta}-SafeOpt&#31639;&#27861;&#65292;&#26377;&#25928;&#20445;&#30041;&#20102;&#25152;&#26377;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20248;&#21270;&#26410;&#30693;&#20989;&#25968;&#22312;&#23433;&#20840;&#32422;&#26463;&#19979;&#26159;&#26426;&#22120;&#20154;&#23398;&#12289;&#29983;&#29289;&#21307;&#23398;&#24037;&#31243;&#21644;&#35768;&#22810;&#20854;&#20182;&#23398;&#31185;&#20013;&#30340;&#20013;&#24515;&#20219;&#21153;&#65292;&#23433;&#20840;&#36125;&#21494;&#26031;&#20248;&#21270;(Safe Bayesian Optimization, BO)&#22312;&#36825;&#26041;&#38754;&#34987;&#36234;&#26469;&#36234;&#24191;&#27867;&#22320;&#24212;&#29992;&#12290;&#30001;&#20110;&#36825;&#20123;&#24212;&#29992;&#30340;&#23433;&#20840;&#20851;&#38190;&#24615;&#36136;&#65292;&#20445;&#35777;&#36825;&#20123;&#31639;&#27861;&#30340;&#29702;&#35770;&#23433;&#20840;&#24615;&#33021;&#33021;&#22815;&#26144;&#23556;&#21040;&#29616;&#23454;&#19990;&#30028;&#20013;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#27969;&#34892;&#31867;&#21035;SafeOpt&#31867;&#22411;&#31639;&#27861;&#30340;&#19977;&#20010;&#19982;&#23433;&#20840;&#30456;&#20851;&#30340;&#38382;&#39064;&#12290;&#39318;&#20808;&#65292;&#36825;&#20123;&#31639;&#27861;&#20851;&#38190;&#20381;&#36182;&#20110;&#39640;&#26031;&#36807;&#31243; (Gaussian Process, GP) &#22238;&#24402;&#30340;&#39057;&#29575;&#19981;&#30830;&#23450;&#24615;&#30028;&#38480;&#65292;&#20294;&#20855;&#20307;&#23454;&#29616;&#36890;&#24120;&#20351;&#29992;&#20351;&#25152;&#26377;&#23433;&#20840;&#20445;&#35777;&#26080;&#25928;&#30340;&#21551;&#21457;&#24335;&#26041;&#27861;&#12290;&#25105;&#20204;&#23545;&#36825;&#20010;&#38382;&#39064;&#36827;&#34892;&#20102;&#35814;&#32454;&#20998;&#26512;&#65292;&#24182;&#24341;&#20837;&#20102;Real-\b{eta}-SafeOpt&#65292;&#36825;&#26159;SafeOpt&#31639;&#27861;&#30340;&#19968;&#31181;&#21464;&#20307;&#65292;&#21033;&#29992;&#26368;&#36817;&#30340;GP&#19978;&#30028;&#65292;&#22240;&#27492;&#20445;&#30041;&#20102;&#25152;&#26377;&#29702;&#35770;&#20445;&#35777;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#22312;&#22797;&#21046;.
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12948v1 Announce Type: new  Abstract: Optimizing an unknown function under safety constraints is a central task in robotics, biomedical engineering, and many other disciplines, and increasingly safe Bayesian Optimization (BO) is used for this. Due to the safety critical nature of these applications, it is of utmost importance that theoretical safety guarantees for these algorithms translate into the real world. In this work, we investigate three safety-related issues of the popular class of SafeOpt-type algorithms. First, these algorithms critically rely on frequentist uncertainty bounds for Gaussian Process (GP) regression, but concrete implementations typically utilize heuristics that invalidate all safety guarantees. We provide a detailed analysis of this problem and introduce Real-\b{eta}-SafeOpt, a variant of the SafeOpt algorithm that leverages recent GP bounds and thus retains all theoretical guarantees. Second, we identify assuming an upper bound on the reproducing k
&lt;/p&gt;</description></item><item><title>&#25193;&#23637;&#20102;&#33879;&#21517;&#30340;Mallows&#27169;&#22411;&#20197;&#36866;&#24212;&#39033;&#30446;&#30340;&#26080;&#24046;&#24322;&#22788;&#29702;&#65292;&#35299;&#20915;&#20102;&#20005;&#26684;&#20559;&#22909;&#19981;&#20999;&#23454;&#38469;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.12880</link><description>&lt;p&gt;
&#32858;&#31867;Mallows&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Clustered Mallows Model
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12880
&lt;/p&gt;
&lt;p&gt;
&#25193;&#23637;&#20102;&#33879;&#21517;&#30340;Mallows&#27169;&#22411;&#20197;&#36866;&#24212;&#39033;&#30446;&#30340;&#26080;&#24046;&#24322;&#22788;&#29702;&#65292;&#35299;&#20915;&#20102;&#20005;&#26684;&#20559;&#22909;&#19981;&#20999;&#23454;&#38469;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25490;&#21517;&#26159;&#19968;&#31181;&#20174;&#23454;&#39564;&#20013;&#33719;&#24471;&#30340;&#20559;&#22909;&#34920;&#36798;&#65292;&#35780;&#20272;&#32773;&#22312;&#23454;&#39564;&#20013;&#23545;&#39033;&#30446;&#36827;&#34892;&#25490;&#24207;&#65292;&#20363;&#22914;&#25353;&#25928;&#29992;&#38477;&#24207;&#25490;&#21015;&#12290;&#26631;&#35760;&#20026;{1,...,n}&#30340;n&#20010;&#29289;&#21697;&#30340;&#25490;&#24207;&#31216;&#20026;&#25490;&#21015;&#65292;&#21453;&#26144;&#20102;&#20005;&#26684;&#30340;&#20559;&#22909;&#12290;&#30001;&#20110;&#22810;&#31181;&#21407;&#22240;&#65292;&#23545;&#20110;&#30495;&#23454;&#25968;&#25454;&#20005;&#26684;&#30340;&#20559;&#22909;&#21487;&#33021;&#26159;&#19981;&#20999;&#23454;&#38469;&#30340;&#20551;&#35774;&#12290;&#20363;&#22914;&#65292;&#24403;&#29289;&#21697;&#20849;&#20139;&#20849;&#21516;&#29305;&#24449;&#26102;&#65292;&#23558;&#23427;&#20204;&#23646;&#24615;&#20026;&#30456;&#21516;&#31561;&#32423;&#21487;&#33021;&#26159;&#21512;&#29702;&#30340;&#12290;&#27492;&#22806;&#65292;&#23545;&#24418;&#25104;&#25490;&#21517;&#30340;&#20915;&#31574;&#21487;&#33021;&#26377;&#19981;&#21516;&#30340;&#37325;&#35201;&#24615;&#24402;&#22240;&#12290;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#20363;&#22914;&#26377;&#22823;&#37327;&#29289;&#21697;&#30340;&#24773;&#20917;&#19979;&#65292;&#35780;&#20272;&#32773;&#21487;&#33021;&#24076;&#26395;&#23558;&#26576;&#20123;&#29289;&#21697;&#25490;&#22312;&#21069;&#20960;&#21517;&#65292;&#23558;&#20854;&#20182;&#29289;&#21697;&#25490;&#22312;&#26411;&#20301;&#65292;&#24182;&#23545;&#20854;&#20182;&#25152;&#26377;&#29289;&#21697;&#34920;&#31034;&#19981;&#30830;&#23450;&#12290;&#27492;&#22806;&#65292;&#22312;&#27719;&#24635;&#24847;&#35265;&#26102;&#65292;&#35780;&#21028;&#26426;&#26500;&#21487;&#33021;&#23545;&#25490;&#21517;&#30340;&#26576;&#20123;&#37096;&#20998;&#26126;&#30830;&#65292;&#32780;&#23545;&#20854;&#20182;&#37096;&#20998;&#27169;&#31946;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;&#33879;&#21517;&#30340;Mallows&#65288;Mallows, 1957&#65289;&#27169;&#22411;&#65288;MM&#65289;&#20197;&#36866;&#24212;&#39033;&#30446;&#30340;&#26080;&#24046;&#24322;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12880v1 Announce Type: cross  Abstract: Rankings are a type of preference elicitation that arise in experiments where assessors arrange items, for example, in decreasing order of utility. Orderings of n items labelled {1,...,n} denoted are permutations that reflect strict preferences. For a number of reasons, strict preferences can be unrealistic assumptions for real data. For example, when items share common traits it may be reasonable to attribute them equal ranks. Also, there can be different importance attributions to decisions that form the ranking. In a situation with, for example, a large number of items, an assessor may wish to rank at top a certain number items; to rank other items at the bottom and to express indifference to all others. In addition, when aggregating opinions, a judging body might be decisive about some parts of the rank but ambiguous for others. In this paper we extend the well-known Mallows (Mallows, 1957) model (MM) to accommodate item indifferen
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#21407;&#22987;&#26041;&#27861;&#65292;&#31216;&#20026;&#32422;&#26463;&#26799;&#24230;&#26041;&#27861;&#65288;CGM&#65289;&#65292;&#29992;&#20110;&#35299;&#20915;&#20855;&#26377;&#22810;&#20010;&#21151;&#33021;&#32422;&#26463;&#30340;&#21464;&#20998;&#19981;&#31561;&#24335;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.12859</link><description>&lt;p&gt;
&#20855;&#26377;&#20989;&#25968;&#32422;&#26463;&#30340;&#21464;&#20998;&#19981;&#31561;&#24335;&#38382;&#39064;&#30340;&#21407;&#22987;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Primal Methods for Variational Inequality Problems with Functional Constraints
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12859
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#21407;&#22987;&#26041;&#27861;&#65292;&#31216;&#20026;&#32422;&#26463;&#26799;&#24230;&#26041;&#27861;&#65288;CGM&#65289;&#65292;&#29992;&#20110;&#35299;&#20915;&#20855;&#26377;&#22810;&#20010;&#21151;&#33021;&#32422;&#26463;&#30340;&#21464;&#20998;&#19981;&#31561;&#24335;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32422;&#26463;&#21464;&#20998;&#19981;&#31561;&#24335;&#38382;&#39064;&#22240;&#20854;&#22312;&#21253;&#25324;&#26426;&#22120;&#23398;&#20064;&#21644;&#36816;&#31609;&#23398;&#22312;&#20869;&#30340;&#21508;&#20010;&#39046;&#22495;&#30340;&#24191;&#27867;&#24212;&#29992;&#32780;&#22791;&#21463;&#35748;&#21487;&#12290; &#39318;&#27425;&#26041;&#27861;&#24050;&#25104;&#20026;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#30340;&#26631;&#20934;&#26041;&#27861;&#65292;&#22240;&#20854;&#31616;&#21333;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#32780;&#21463;&#21040;&#37325;&#35270;&#12290; &#20256;&#32479;&#19978;&#65292;&#23427;&#20204;&#36890;&#24120;&#20381;&#36182;&#20110;&#25237;&#24433;&#25110;&#32447;&#24615;&#26368;&#23567;&#21270;&#23637;&#24320;&#22120;&#26469;&#23548;&#33322;&#21487;&#34892;&#38598;&#65292;&#20294;&#22312;&#23454;&#36341;&#20013;&#65292;&#36825;&#20250;&#22312;&#20855;&#26377;&#22810;&#20010;&#21151;&#33021;&#32422;&#26463;&#30340;&#24773;&#20917;&#19979;&#21464;&#24471;&#35745;&#31639;&#26114;&#36149;&#12290; &#35299;&#20915;&#36825;&#20123;&#21151;&#33021;&#32422;&#26463;&#21464;&#20998;&#19981;&#31561;&#24335;&#38382;&#39064;&#30340;&#29616;&#26377;&#21162;&#21147;&#20027;&#35201;&#38598;&#20013;&#22312;&#22522;&#20110;Lagrange&#20989;&#25968;&#30340;&#21407;&#22987;-&#23545;&#20598;&#31639;&#27861;&#19978;&#12290; &#36825;&#20123;&#31639;&#27861;&#21450;&#20854;&#29702;&#35770;&#20998;&#26512;&#36890;&#24120;&#38656;&#35201;&#23384;&#22312;&#24182;&#19988;&#20107;&#20808;&#20102;&#35299;&#26368;&#20339;&#25289;&#26684;&#26391;&#26085;&#20056;&#25968;&#12290; &#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#21407;&#22987;&#26041;&#27861;&#65292;&#31216;&#20026;&#32422;&#26463;&#26799;&#24230;&#26041;&#27861;&#65288;CGM&#65289;&#65292;&#29992;&#20110;&#22788;&#29702;&#21151;&#33021;&#32422;&#26463;&#30340;&#21464;&#20998;&#19981;&#31561;&#24335;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12859v1 Announce Type: cross  Abstract: Constrained variational inequality problems are recognized for their broad applications across various fields including machine learning and operations research. First-order methods have emerged as the standard approach for solving these problems due to their simplicity and scalability. However, they typically rely on projection or linear minimization oracles to navigate the feasible set, which becomes computationally expensive in practical scenarios featuring multiple functional constraints. Existing efforts to tackle such functional constrained variational inequality problems have centered on primal-dual algorithms grounded in the Lagrangian function. These algorithms along with their theoretical analysis often require the existence and prior knowledge of the optimal Lagrange multipliers. In this work, we propose a simple primal method, termed Constrained Gradient Method (CGM), for addressing functional constrained variational inequa
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20351;&#29992;&#38789;&#23614;&#24052;&#30028;&#38480;&#21644;&#26080;&#38480;&#32500;&#20984;&#35268;&#21010;&#30340;&#26377;&#38480;&#32500;&#37325;&#26500;&#65292;&#24314;&#31435;&#20102;&#24207;&#36143;&#26680;&#22238;&#24402;&#30340;&#26032;&#32622;&#20449;&#21306;&#38388;&#65292;&#35777;&#26126;&#20854;&#22987;&#32456;&#27604;&#29616;&#26377;&#30340;&#32622;&#20449;&#21306;&#38388;&#26356;&#32039;&#20945;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#26680;&#36172;&#21338;&#38382;&#39064;&#65292;&#25552;&#39640;&#20102;&#31639;&#27861;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;</title><link>https://arxiv.org/abs/2403.12732</link><description>&lt;p&gt;
&#23545;&#20110;&#24207;&#36143;&#26680;&#22238;&#24402;&#30340;&#26356;&#32039;&#20945;&#32622;&#20449;&#21306;&#38388;
&lt;/p&gt;
&lt;p&gt;
Tighter Confidence Bounds for Sequential Kernel Regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12732
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;&#38789;&#23614;&#24052;&#30028;&#38480;&#21644;&#26080;&#38480;&#32500;&#20984;&#35268;&#21010;&#30340;&#26377;&#38480;&#32500;&#37325;&#26500;&#65292;&#24314;&#31435;&#20102;&#24207;&#36143;&#26680;&#22238;&#24402;&#30340;&#26032;&#32622;&#20449;&#21306;&#38388;&#65292;&#35777;&#26126;&#20854;&#22987;&#32456;&#27604;&#29616;&#26377;&#30340;&#32622;&#20449;&#21306;&#38388;&#26356;&#32039;&#20945;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#26680;&#36172;&#21338;&#38382;&#39064;&#65292;&#25552;&#39640;&#20102;&#31639;&#27861;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32622;&#20449;&#21306;&#38388;&#26159;&#20005;&#26684;&#37327;&#21270;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#37325;&#35201;&#24037;&#20855;&#12290;&#23427;&#20204;&#21487;&#20197;&#25351;&#23548;&#25506;&#32034;&#19982;&#24320;&#21457;&#30340;&#26435;&#34913;&#65292;&#24182;&#26500;&#25104;&#35768;&#22810;&#24207;&#36143;&#23398;&#20064;&#21644;&#20915;&#31574;&#31639;&#27861;&#30340;&#26680;&#24515;&#32452;&#25104;&#37096;&#20998;&#12290;&#26356;&#32039;&#20945;&#30340;&#32622;&#20449;&#21306;&#38388;&#24102;&#26469;&#20102;&#20855;&#26377;&#26356;&#22909;&#32463;&#39564;&#24615;&#33021;&#21644;&#26356;&#22909;&#24615;&#33021;&#20445;&#35777;&#30340;&#31639;&#27861;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#38789;&#23614;&#24052;&#30028;&#38480;&#21644;&#26080;&#38480;&#32500;&#20984;&#35268;&#21010;&#30340;&#26377;&#38480;&#32500;&#37325;&#26500;&#26469;&#24314;&#31435;&#24207;&#36143;&#26680;&#22238;&#24402;&#30340;&#26032;&#32622;&#20449;&#21306;&#38388;&#12290;&#25105;&#20204;&#35777;&#26126;&#22312;&#36825;&#19968;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#30340;&#26032;&#32622;&#20449;&#21306;&#38388;&#22987;&#32456;&#27604;&#29616;&#26377;&#30340;&#26356;&#32039;&#20945;&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#32622;&#20449;&#21306;&#38388;&#24212;&#29992;&#20110;&#26680;&#36172;&#21338;&#38382;&#39064;&#65292;&#20854;&#20013;&#26410;&#26469;&#30340;&#34892;&#21160;&#21462;&#20915;&#20110;&#20808;&#21069;&#30340;&#21382;&#21490;&#12290;&#24403;&#25105;&#20204;&#30340;&#32622;&#20449;&#21306;&#38388;&#21462;&#20195;&#29616;&#26377;&#30340;&#32622;&#20449;&#21306;&#38388;&#26102;&#65292;KernelUCB&#65288;GP-UCB&#65289;&#31639;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#32463;&#39564;&#24615;&#33021;&#65292;&#21305;&#37197;&#30340;&#26368;&#22351;&#24773;&#20917;&#24615;&#33021;&#20445;&#35777;&#21644;&#21487;&#27604;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12732v1 Announce Type: cross  Abstract: Confidence bounds are an essential tool for rigorously quantifying the uncertainty of predictions. In this capacity, they can inform the exploration-exploitation trade-off and form a core component in many sequential learning and decision-making algorithms. Tighter confidence bounds give rise to algorithms with better empirical performance and better performance guarantees. In this work, we use martingale tail bounds and finite-dimensional reformulations of infinite-dimensional convex programs to establish new confidence bounds for sequential kernel regression. We prove that our new confidence bounds are always tighter than existing ones in this setting. We apply our confidence bounds to the kernel bandit problem, where future actions depend on the previous history. When our confidence bounds replace existing ones, the KernelUCB (GP-UCB) algorithm has better empirical performance, a matching worst-case performance guarantee and compara
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#25552;&#20986;MixupMP&#26041;&#27861;&#65292;&#20351;&#29992;&#25968;&#25454;&#22686;&#24378;&#26500;&#24314;&#26356;&#29616;&#23454;&#30340;&#39044;&#27979;&#20998;&#24067;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#22312;&#31070;&#32463;&#32593;&#32476;&#20013;&#23545;&#21518;&#39564;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#37327;&#21270;&#26102;&#30340;&#22522;&#26412;&#27169;&#22411;&#31867;&#38169;&#35823;&#35268;&#33539;&#21270;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.12729</link><description>&lt;p&gt;
&#20351;&#29992;&#25968;&#25454;&#22686;&#24378;&#22312;&#31070;&#32463;&#32593;&#32476;&#20013;&#23545;&#21518;&#39564;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Posterior Uncertainty Quantification in Neural Networks using Data Augmentation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12729
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25552;&#20986;MixupMP&#26041;&#27861;&#65292;&#20351;&#29992;&#25968;&#25454;&#22686;&#24378;&#26500;&#24314;&#26356;&#29616;&#23454;&#30340;&#39044;&#27979;&#20998;&#24067;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#22312;&#31070;&#32463;&#32593;&#32476;&#20013;&#23545;&#21518;&#39564;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#37327;&#21270;&#26102;&#30340;&#22522;&#26412;&#27169;&#22411;&#31867;&#38169;&#35823;&#35268;&#33539;&#21270;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#19968;&#20010;&#39044;&#27979;&#26694;&#26550;&#26469;&#22788;&#29702;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#38382;&#39064;&#65292;&#35813;&#26694;&#26550;&#36890;&#36807;&#25351;&#23450;&#26377;&#20851;&#26410;&#26469;&#26410;&#35265;&#25968;&#25454;&#30340;&#39044;&#27979;&#20998;&#24067;&#30340;&#20551;&#35774;&#26469;&#25429;&#25417;&#27169;&#22411;&#21442;&#25968;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#22312;&#36825;&#20010;&#35266;&#28857;&#19979;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#28145;&#24230;&#38598;&#25104;&#65288;Lakshminarayanan&#31561;&#65292;2017&#65289;&#26159;&#19968;&#20010;&#22522;&#26412;&#19978;&#38169;&#35823;&#35268;&#33539;&#21270;&#30340;&#27169;&#22411;&#31867;&#65292;&#22240;&#20026;&#23427;&#20551;&#35774;&#26410;&#26469;&#25968;&#25454;&#20165;&#25903;&#25345;&#29616;&#26377;&#35266;&#23519;&#32467;&#26524; -- &#36825;&#31181;&#24773;&#20917;&#22312;&#23454;&#36341;&#20013;&#24456;&#23569;&#36935;&#21040;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#23616;&#38480;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;MixupMP&#65292;&#19968;&#31181;&#20351;&#29992;&#27969;&#34892;&#30340;&#25968;&#25454;&#22686;&#24378;&#25216;&#26415;&#26500;&#24314;&#26356;&#29616;&#23454;&#30340;&#39044;&#27979;&#20998;&#24067;&#30340;&#26041;&#27861;&#12290;MixupMP&#20316;&#20026;&#28145;&#24230;&#38598;&#25104;&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#20854;&#20013;&#27599;&#20010;&#38598;&#25104;&#25104;&#21592;&#37117;&#26159;&#22312;&#36825;&#20010;&#39044;&#27979;&#20998;&#24067;&#30340;&#38543;&#26426;&#27169;&#25311;&#19978;&#35757;&#32451;&#30340;&#12290;&#22522;&#20110;&#26368;&#36817;&#25552;&#20986;&#30340;&#39532;&#19969;&#26684;&#23572;&#21518;&#39564;&#26694;&#26550;&#65288;Fong&#31561;&#65292;2023&#65289;&#65292;MixupMP&#36820;&#22238;&#38544;&#24335;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12729v1 Announce Type: cross  Abstract: In this paper, we approach the problem of uncertainty quantification in deep learning through a predictive framework, which captures uncertainty in model parameters by specifying our assumptions about the predictive distribution of unseen future data. Under this view, we show that deep ensembling (Lakshminarayanan et al., 2017) is a fundamentally mis-specified model class, since it assumes that future data are supported on existing observations only -- a situation rarely encountered in practice. To address this limitation, we propose MixupMP, a method that constructs a more realistic predictive distribution using popular data augmentation techniques. MixupMP operates as a drop-in replacement for deep ensembles, where each ensemble member is trained on a random simulation from this predictive distribution. Grounded in the recently-proposed framework of Martingale posteriors (Fong et al., 2023), MixupMP returns samples from an implicitly
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32047;&#31215;&#20998;&#24067;&#25913;&#36827;&#35780;&#20998;&#21487;&#35299;&#37322;&#24615;&#30340;&#24230;&#37327;&#65292;&#24314;&#31435;&#20102;&#20351;&#29992;&#21487;&#35299;&#37322;&#24230;&#37327;&#35774;&#32622;&#38408;&#20540;&#30340;&#20934;&#21017;&#65292;&#24182;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20854;&#21512;&#29702;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.12672</link><description>&lt;p&gt;
&#22522;&#20110;&#39640;&#26031;&#20271;&#21162;&#21033;&#21463;&#38480;&#29627;&#23572;&#20857;&#26364;&#26426;&#30340;&#24322;&#24120;&#26816;&#27979;&#35780;&#20998;&#21487;&#35299;&#37322;&#24615;&#25913;&#36827;
&lt;/p&gt;
&lt;p&gt;
Improving Interpretability of Scores in Anomaly Detection Based on Gaussian-Bernoulli Restricted Boltzmann Machine
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12672
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32047;&#31215;&#20998;&#24067;&#25913;&#36827;&#35780;&#20998;&#21487;&#35299;&#37322;&#24615;&#30340;&#24230;&#37327;&#65292;&#24314;&#31435;&#20102;&#20351;&#29992;&#21487;&#35299;&#37322;&#24230;&#37327;&#35774;&#32622;&#38408;&#20540;&#30340;&#20934;&#21017;&#65292;&#24182;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20854;&#21512;&#29702;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#20271;&#21162;&#21033;&#21463;&#38480;&#29627;&#23572;&#20857;&#26364;&#26426;&#65288;GBRBM&#65289;&#24120;&#29992;&#20110;&#21322;&#30417;&#30563;&#24322;&#24120;&#26816;&#27979;&#65292;&#20165;&#20351;&#29992;&#27491;&#24120;&#25968;&#25454;&#28857;&#36827;&#34892;&#35757;&#32451;&#12290;&#22312;&#22522;&#20110;GBRBM&#30340;&#24322;&#24120;&#26816;&#27979;&#20013;&#65292;&#26681;&#25454;&#36793;&#32536;GBRBM&#30340;&#33021;&#37327;&#20989;&#25968;&#30456;&#21516;&#30340;&#35780;&#20998;&#26469;&#23545;&#27491;&#24120;&#21644;&#24322;&#24120;&#25968;&#25454;&#36827;&#34892;&#20998;&#31867;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#26080;&#27861;&#35299;&#37322;&#35813;&#35780;&#20998;&#65292;&#24456;&#38590;&#35774;&#32622;&#36866;&#24403;&#30340;&#20998;&#31867;&#38408;&#20540;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32047;&#31215;&#20998;&#24067;&#25913;&#36827;&#35780;&#20998;&#21487;&#35299;&#37322;&#24615;&#30340;&#24230;&#37327;&#65292;&#24182;&#24314;&#31435;&#20102;&#20351;&#29992;&#21487;&#35299;&#37322;&#24230;&#37327;&#35774;&#32622;&#38408;&#20540;&#30340;&#20934;&#21017;&#12290;&#25968;&#20540;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#20165;&#20351;&#29992;&#27491;&#24120;&#25968;&#25454;&#28857;&#35774;&#32622;&#38408;&#20540;&#26102;&#65292;&#35813;&#20934;&#21017;&#26159;&#21512;&#29702;&#30340;&#12290;&#27492;&#22806;&#65292;&#30001;&#20110;&#35782;&#21035;&#24230;&#37327;&#28041;&#21450;&#35745;&#31639;&#19981;&#21487;&#34892;&#30340;&#26368;&#23567;&#35780;&#20998;&#20540;&#30340;&#35780;&#20272;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26368;&#23567;&#35780;&#20998;&#30340;&#35780;&#20272;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12672v1 Announce Type: cross  Abstract: Gaussian-Bernoulli restricted Boltzmann machines (GBRBMs) are often used for semi-supervised anomaly detection, where they are trained using only normal data points. In GBRBM-based anomaly detection, normal and anomalous data are classified based on a score that is identical to an energy function of the marginal GBRBM. However, the classification threshold is difficult to set to an appropriate value, as this score cannot be interpreted. In this study, we propose a measure that improves score's interpretability based on its cumulative distribution, and establish a guideline for setting the threshold using the interpretable measure. The results of numerical experiments show that the guideline is reasonable when setting the threshold solely using normal data points. Moreover, because identifying the measure involves computationally infeasible evaluation of the minimum score value, we also propose an evaluation method for the minimum score
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#23454;&#29992;&#25351;&#21335;&#65292;&#20171;&#32461;&#20102;&#22235;&#31181;&#24120;&#29992;&#32479;&#35745;&#36317;&#31163;&#30340;&#27010;&#24565;&#65292;&#20197;&#24110;&#21161;&#35780;&#20272;&#29983;&#25104;&#27169;&#22411;&#65292;&#26080;&#38656;&#39640;&#28145;&#30340;&#25968;&#23398;&#21644;&#32479;&#35745;&#30693;&#35782;&#12290;</title><link>https://arxiv.org/abs/2403.12636</link><description>&lt;p&gt;
&#29992;&#20110;&#31185;&#23398;&#20013;&#35780;&#20272;&#29983;&#25104;&#27169;&#22411;&#30340;&#32479;&#35745;&#36317;&#31163;&#30340;&#23454;&#29992;&#25351;&#21335;
&lt;/p&gt;
&lt;p&gt;
A Practical Guide to Statistical Distances for Evaluating Generative Models in Science
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12636
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#23454;&#29992;&#25351;&#21335;&#65292;&#20171;&#32461;&#20102;&#22235;&#31181;&#24120;&#29992;&#32479;&#35745;&#36317;&#31163;&#30340;&#27010;&#24565;&#65292;&#20197;&#24110;&#21161;&#35780;&#20272;&#29983;&#25104;&#27169;&#22411;&#65292;&#26080;&#38656;&#39640;&#28145;&#30340;&#25968;&#23398;&#21644;&#32479;&#35745;&#30693;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#27169;&#22411;&#22312;&#35768;&#22810;&#31185;&#23398;&#39046;&#22495;&#20013;&#26159;&#38750;&#24120;&#23453;&#36149;&#30340;&#65292;&#22240;&#20026;&#23427;&#20204;&#33021;&#22815;&#25429;&#25417;&#39640;&#32500;&#21644;&#22797;&#26434;&#30340;&#20998;&#24067;&#65292;&#20363;&#22914;&#36924;&#30495;&#30340;&#22270;&#20687;&#12289;&#34507;&#30333;&#36136;&#32467;&#26500;&#21644;&#36830;&#25509;&#32452;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#20026;&#29702;&#35299;&#27969;&#34892;&#30340;&#32479;&#35745;&#36317;&#31163;&#27010;&#24565;&#25552;&#20379;&#19968;&#20010;&#26131;&#20110;&#29702;&#35299;&#30340;&#20837;&#21475;&#28857;&#65292;&#21482;&#38656;&#35201;&#25968;&#23398;&#21644;&#32479;&#35745;&#23398;&#30340;&#22522;&#30784;&#30693;&#35782;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#20195;&#34920;&#19981;&#21516;&#26041;&#27861;&#35770;&#30340;&#22235;&#31181;&#24120;&#29992;&#32479;&#35745;&#36317;&#31163;&#27010;&#24565;&#65306;&#20351;&#29992;&#20302;&#32500;&#25237;&#24433;&#65288;Sliced-Wasserstein; SW)&#12289;&#20351;&#29992;&#20998;&#31867;&#22120;&#33719;&#21462;&#36317;&#31163;&#65288;Classifier Two-Sample Tests; C2ST)&#12289;&#36890;&#36807;&#26680;&#36827;&#34892;&#23884;&#20837;&#65288;Maximum Mean Discrepancy; MMD) &#25110;&#31070;&#32463;&#32593;&#32476;&#65288;Fr\'echet Inception Distance; FID)&#12290;&#25105;&#20204;&#24378;&#35843;&#27599;&#20010;&#36317;&#31163;&#32972;&#21518;&#30340;&#30452;&#35273;&#65292;&#24182;&#35299;&#37322;&#23427;&#20204;&#30340;&#20248;&#28857;&#12289;&#21487;&#20280;&#32553;&#24615;&#12289;&#22797;&#26434;&#24615;&#21644;&#32570;&#38519;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12636v1 Announce Type: new  Abstract: Generative models are invaluable in many fields of science because of their ability to capture high-dimensional and complicated distributions, such as photo-realistic images, protein structures, and connectomes. How do we evaluate the samples these models generate? This work aims to provide an accessible entry point to understanding popular notions of statistical distances, requiring only foundational knowledge in mathematics and statistics. We focus on four commonly used notions of statistical distances representing different methodologies: Using low-dimensional projections (Sliced-Wasserstein; SW), obtaining a distance using classifiers (Classifier Two-Sample Tests; C2ST), using embeddings through kernels (Maximum Mean Discrepancy; MMD), or neural networks (Fr\'echet Inception Distance; FID). We highlight the intuition behind each distance and explain their merits, scalability, complexity, and pitfalls. To demonstrate how these distanc
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;PePR&#20998;&#25968;&#65292;&#30740;&#31350;&#20154;&#21592;&#23637;&#31034;&#20102;&#22312;&#36164;&#28304;&#26377;&#38480;&#30340;&#24773;&#20917;&#19979;&#65292;&#21033;&#29992;131&#31181;&#29420;&#29305;&#30340;DL&#26550;&#26500;&#22312;&#21307;&#23398;&#22270;&#20687;&#20219;&#21153;&#20013;&#30340;&#21487;&#34892;&#24615;&#12290;</title><link>https://arxiv.org/abs/2403.12562</link><description>&lt;p&gt;
&#36890;&#36807;&#33719;&#21462;&#36171;&#26435;&#65306;&#25903;&#25345;&#23567;&#35268;&#27169;&#28145;&#24230;&#23398;&#20064;&#30340;&#26696;&#20363;
&lt;/p&gt;
&lt;p&gt;
Equity through Access: A Case for Small-scale Deep Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12562
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;PePR&#20998;&#25968;&#65292;&#30740;&#31350;&#20154;&#21592;&#23637;&#31034;&#20102;&#22312;&#36164;&#28304;&#26377;&#38480;&#30340;&#24773;&#20917;&#19979;&#65292;&#21033;&#29992;131&#31181;&#29420;&#29305;&#30340;DL&#26550;&#26500;&#22312;&#21307;&#23398;&#22270;&#20687;&#20219;&#21153;&#20013;&#30340;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#65288;DL&#65289;&#30340;&#26368;&#26032;&#36827;&#23637;&#24471;&#30410;&#20110;&#22823;&#35268;&#27169;&#25968;&#25454;&#21644;&#35745;&#31639;&#21147;&#30340;&#25552;&#21319;&#12290;&#36825;&#20123;&#22823;&#35268;&#27169;&#36164;&#28304;&#34987;&#29992;&#20110;&#35757;&#32451;&#26085;&#30410;&#24222;&#22823;&#30340;&#27169;&#22411;&#65292;&#32780;&#36825;&#20123;&#27169;&#22411;&#22312;&#35745;&#31639;&#12289;&#25968;&#25454;&#12289;&#33021;&#28304;&#21644;&#30899;&#25490;&#25918;&#26041;&#38754;&#28040;&#32791;&#24040;&#22823;&#12290;&#36825;&#20123;&#25104;&#26412;&#27491;&#22312;&#25104;&#20026;&#30740;&#31350;&#20154;&#21592;&#21644;&#20174;&#19994;&#32773;&#38754;&#20020;&#30340;&#26032;&#22411;&#20934;&#20837;&#38556;&#30861;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#37027;&#20123;&#22312;&#20840;&#29699;&#21335;&#26041;&#22320;&#21306;&#36164;&#28304;&#26377;&#38480;&#30340;&#20154;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20840;&#38754;&#23457;&#35270;&#20102;&#29616;&#26377;&#35270;&#35273;&#20219;&#21153;&#30340;DL&#27169;&#22411;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#20204;&#22312;&#36164;&#28304;&#26377;&#38480;&#30340;&#29615;&#22659;&#20013;&#30340;&#23454;&#29992;&#24615;&#12290;&#20026;&#20102;&#32771;&#34385;DL&#27169;&#22411;&#30340;&#36164;&#28304;&#28040;&#32791;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#34913;&#37327;&#24615;&#33021;&#19982;&#36164;&#28304;&#21333;&#20803;&#30340;&#26032;&#25351;&#26631;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;PePR&#20998;&#25968;&#12290;&#36890;&#36807;&#20351;&#29992;131&#31181;&#29420;&#29305;&#30340;DL&#26550;&#26500;&#65288;&#36328;&#24230;&#20174;1M&#21040;130M&#20010;&#21487;&#35757;&#32451;&#21442;&#25968;&#65289;&#21644;&#19977;&#20010;&#21307;&#23398;&#22270;&#20687;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#33719;&#21462;&#20102;&#26377;&#20851;&#24615;&#33021;&#21644;&#36164;&#28304;&#20043;&#38388;&#20851;&#31995;&#30340;&#36235;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12562v1 Announce Type: cross  Abstract: The recent advances in deep learning (DL) have been accelerated by access to large-scale data and compute. These large-scale resources have been used to train progressively larger models which are resource intensive in terms of compute, data, energy, and carbon emissions. These costs are becoming a new type of entry barrier to researchers and practitioners with limited access to resources at such scale, particularly in the Global South. In this work, we take a comprehensive look at the landscape of existing DL models for vision tasks and demonstrate their usefulness in settings where resources are limited. To account for the resource consumption of DL models, we introduce a novel measure to estimate the performance per resource unit, which we call the PePR score. Using a diverse family of 131 unique DL architectures (spanning 1M to 130M trainable parameters) and three medical image datasets, we capture trends about the performance-reso
&lt;/p&gt;</description></item><item><title>&#25913;&#36827;&#30340;&#35889;&#32858;&#31867;&#31639;&#27861;&#22312;&#22810;&#23618;&#32593;&#32476;&#20013;&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#31038;&#21306;&#26816;&#27979;&#24615;&#33021;&#65292;&#24182;&#35777;&#26126;&#22810;&#23618;&#32593;&#32476;&#23545;&#31038;&#21306;&#26816;&#27979;&#26377;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2403.12540</link><description>&lt;p&gt;
&#22810;&#23618;&#32593;&#32476;&#20013;&#22522;&#20110;&#35889;&#26041;&#27861;&#30340;&#31038;&#21306;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Community detection by spectral methods in multi-layer networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12540
&lt;/p&gt;
&lt;p&gt;
&#25913;&#36827;&#30340;&#35889;&#32858;&#31867;&#31639;&#27861;&#22312;&#22810;&#23618;&#32593;&#32476;&#20013;&#23454;&#29616;&#20102;&#26356;&#22909;&#30340;&#31038;&#21306;&#26816;&#27979;&#24615;&#33021;&#65292;&#24182;&#35777;&#26126;&#22810;&#23618;&#32593;&#32476;&#23545;&#31038;&#21306;&#26816;&#27979;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#23618;&#32593;&#32476;&#20013;&#30340;&#31038;&#21306;&#26816;&#27979;&#26159;&#32593;&#32476;&#20998;&#26512;&#20013;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#12290;&#26412;&#25991;&#20998;&#26512;&#20102;&#20004;&#31181;&#35889;&#32858;&#31867;&#31639;&#27861;&#22312;&#22810;&#23618;&#24230;&#26657;&#27491;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;MLDCSBM&#65289;&#26694;&#26550;&#19979;&#36827;&#34892;&#31038;&#21306;&#26816;&#27979;&#30340;&#24615;&#33021;&#12290;&#19968;&#31181;&#31639;&#27861;&#22522;&#20110;&#37051;&#25509;&#30697;&#38453;&#30340;&#21644;&#65292;&#21478;&#19968;&#31181;&#21033;&#29992;&#20102;&#21435;&#20559;&#21644;&#30340;&#24179;&#26041;&#37051;&#25509;&#30697;&#38453;&#30340;&#21644;&#12290;&#25105;&#20204;&#22312;&#32593;&#32476;&#35268;&#27169;&#21644;/&#25110;&#23618;&#25968;&#22686;&#21152;&#26102;&#24314;&#31435;&#20102;&#36825;&#20123;&#26041;&#27861;&#22312;MLDCSBM&#19979;&#36827;&#34892;&#31038;&#21306;&#26816;&#27979;&#30340;&#19968;&#33268;&#24615;&#32467;&#26524;&#12290;&#25105;&#20204;&#30340;&#23450;&#29702;&#23637;&#31034;&#20102;&#21033;&#29992;&#22810;&#23618;&#36827;&#34892;&#31038;&#21306;&#26816;&#27979;&#30340;&#20248;&#21183;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#21033;&#29992;&#21435;&#20559;&#21644;&#30340;&#24179;&#26041;&#37051;&#25509;&#30697;&#38453;&#30340;&#35889;&#32858;&#31867;&#36890;&#24120;&#20248;&#20110;&#21033;&#29992;&#37051;&#25509;&#30697;&#38453;&#30340;&#35889;&#32858;&#31867;&#12290;&#25968;&#20540;&#27169;&#25311;&#35777;&#23454;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#65292;&#37319;&#29992;&#20102;&#21435;&#20559;&#21644;&#30340;&#24179;&#26041;&#37051;&#25509;&#30697;&#38453;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12540v1 Announce Type: cross  Abstract: Community detection in multi-layer networks is a crucial problem in network analysis. In this paper, we analyze the performance of two spectral clustering algorithms for community detection within the multi-layer degree-corrected stochastic block model (MLDCSBM) framework. One algorithm is based on the sum of adjacency matrices, while the other utilizes the debiased sum of squared adjacency matrices. We establish consistency results for community detection using these methods under MLDCSBM as the size of the network and/or the number of layers increases. Our theorems demonstrate the advantages of utilizing multiple layers for community detection. Moreover, our analysis indicates that spectral clustering with the debiased sum of squared adjacency matrices is generally superior to spectral clustering with the sum of adjacency matrices. Numerical simulations confirm that our algorithm, employing the debiased sum of squared adjacency matri
&lt;/p&gt;</description></item><item><title>&#38750;&#36127;&#23545;&#27604;&#23398;&#20064;(NCL)&#26159;&#23545;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;(NMF)&#30340;&#37325;&#26032;&#28436;&#32462;&#65292;&#36890;&#36807;&#23545;&#29305;&#24449;&#26045;&#21152;&#38750;&#36127;&#32422;&#26463;&#26469;&#33719;&#24471;&#21487;&#35299;&#37322;&#30340;&#29305;&#24449;&#65292;&#20445;&#30041;&#20102;NMF&#30340;&#21487;&#35299;&#37322;&#23646;&#24615;&#65292;&#20174;&#32780;&#24471;&#21040;&#27604;&#26631;&#20934;&#23545;&#27604;&#23398;&#20064;(CL)&#26356;&#31232;&#30095;&#21644;&#35299;&#32806;&#30340;&#34920;&#31034;</title><link>https://arxiv.org/abs/2403.12459</link><description>&lt;p&gt;
&#38750;&#36127;&#23545;&#27604;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Non-negative Contrastive Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12459
&lt;/p&gt;
&lt;p&gt;
&#38750;&#36127;&#23545;&#27604;&#23398;&#20064;(NCL)&#26159;&#23545;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;(NMF)&#30340;&#37325;&#26032;&#28436;&#32462;&#65292;&#36890;&#36807;&#23545;&#29305;&#24449;&#26045;&#21152;&#38750;&#36127;&#32422;&#26463;&#26469;&#33719;&#24471;&#21487;&#35299;&#37322;&#30340;&#29305;&#24449;&#65292;&#20445;&#30041;&#20102;NMF&#30340;&#21487;&#35299;&#37322;&#23646;&#24615;&#65292;&#20174;&#32780;&#24471;&#21040;&#27604;&#26631;&#20934;&#23545;&#27604;&#23398;&#20064;(CL)&#26356;&#31232;&#30095;&#21644;&#35299;&#32806;&#30340;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#34920;&#31034;&#22312;&#20197;&#40657;&#30418;&#26041;&#24335;&#36716;&#31227;&#21040;&#19979;&#28216;&#20219;&#21153;&#26102;&#34920;&#29616;&#20986;&#20102;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#22266;&#26377;&#30340;&#19981;&#21487;&#35299;&#37322;&#24615;&#20173;&#28982;&#26159;&#19968;&#20010;&#37325;&#22823;&#25361;&#25112;&#65292;&#22240;&#20026;&#36825;&#20123;&#29305;&#24449;&#36890;&#24120;&#23545;&#20154;&#31867;&#29702;&#35299;&#32780;&#35328;&#26159;&#19981;&#36879;&#26126;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#38750;&#36127;&#23545;&#27604;&#23398;&#20064;&#65288;NCL&#65289;&#65292;&#36825;&#26159;&#23545;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#65288;NMF&#65289;&#30340;&#22797;&#20852;&#65292;&#26088;&#22312;&#24471;&#20986;&#21487;&#35299;&#37322;&#30340;&#29305;&#24449;&#12290;NCL&#30340;&#21147;&#37327;&#22312;&#20110;&#24378;&#21046;&#23558;&#38750;&#36127;&#32422;&#26463;&#24212;&#29992;&#20110;&#29305;&#24449;&#65292;&#36825;&#35753;&#20154;&#24819;&#36215;NMF&#33021;&#22815;&#25552;&#21462;&#19982;&#26679;&#26412;&#38598;&#32676;&#32039;&#23494;&#23545;&#40784;&#30340;&#29305;&#24449;&#30340;&#33021;&#21147;&#12290;NCL&#19981;&#20165;&#22312;&#25968;&#23398;&#19978;&#19982;NMF&#30446;&#26631;&#24456;&#22909;&#22320;&#23545;&#40784;&#65292;&#32780;&#19988;&#20445;&#30041;&#20102;NMF&#30340;&#21487;&#35299;&#37322;&#23646;&#24615;&#65292;&#20351;&#24471;&#19982;&#26631;&#20934;&#23545;&#27604;&#23398;&#20064;&#65288;CL&#65289;&#30456;&#27604;&#65292;&#24471;&#21040;&#20102;&#26356;&#21152;&#31232;&#30095;&#21644;&#35299;&#32806;&#30340;&#34920;&#31034;&#12290;&#20174;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#20026;NCL&#30340;&#21487;&#35782;&#21035;&#24615;&#21644;&#19979;&#28216;&#27867;&#21270;&#24615;&#33021;&#25552;&#20379;&#20102;&#20445;&#35777;&#12290;&#20174;&#32463;&#39564;&#19978;&#30475;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20123;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12459v1 Announce Type: cross  Abstract: Deep representations have shown promising performance when transferred to downstream tasks in a black-box manner. Yet, their inherent lack of interpretability remains a significant challenge, as these features are often opaque to human understanding. In this paper, we propose Non-negative Contrastive Learning (NCL), a renaissance of Non-negative Matrix Factorization (NMF) aimed at deriving interpretable features. The power of NCL lies in its enforcement of non-negativity constraints on features, reminiscent of NMF's capability to extract features that align closely with sample clusters. NCL not only aligns mathematically well with an NMF objective but also preserves NMF's interpretability attributes, resulting in a more sparse and disentangled representation compared to standard contrastive learning (CL). Theoretically, we establish guarantees on the identifiability and downstream generalization of NCL. Empirically, we show that these 
&lt;/p&gt;</description></item><item><title>&#29983;&#25104;&#30340;&#39640;&#36136;&#37327;&#22270;&#20687;&#24050;&#25104;&#21151;&#24212;&#29992;&#20110;&#22686;&#24378;&#23545;&#27604;&#34920;&#31034;&#23398;&#20064;&#65292;&#20294;&#25105;&#20204;&#21457;&#29616;&#26377;&#26102;&#29983;&#25104;&#30340;&#25968;&#25454;&#29978;&#33267;&#20250;&#23545;&#23545;&#27604;&#23398;&#20064;&#36896;&#25104;&#20260;&#23475;&#65292;&#36890;&#36807;&#30740;&#31350;&#21457;&#29616;&#26356;&#24378;&#30340;&#25968;&#25454;&#33192;&#32960;&#24212;&#35813;&#20276;&#38543;&#30528;&#26356;&#24369;&#30340;&#22686;&#24378;&#12290;</title><link>https://arxiv.org/abs/2403.12448</link><description>&lt;p&gt;
&#29983;&#25104;&#30340;&#25968;&#25454;&#24635;&#26159;&#26377;&#21161;&#20110;&#23545;&#27604;&#23398;&#20064;&#21527;&#65311;
&lt;/p&gt;
&lt;p&gt;
Do Generated Data Always Help Contrastive Learning?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12448
&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#30340;&#39640;&#36136;&#37327;&#22270;&#20687;&#24050;&#25104;&#21151;&#24212;&#29992;&#20110;&#22686;&#24378;&#23545;&#27604;&#34920;&#31034;&#23398;&#20064;&#65292;&#20294;&#25105;&#20204;&#21457;&#29616;&#26377;&#26102;&#29983;&#25104;&#30340;&#25968;&#25454;&#29978;&#33267;&#20250;&#23545;&#23545;&#27604;&#23398;&#20064;&#36896;&#25104;&#20260;&#23475;&#65292;&#36890;&#36807;&#30740;&#31350;&#21457;&#29616;&#26356;&#24378;&#30340;&#25968;&#25454;&#33192;&#32960;&#24212;&#35813;&#20276;&#38543;&#30528;&#26356;&#24369;&#30340;&#22686;&#24378;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#27604;&#23398;&#20064;&#65288;CL&#65289;&#24050;&#32463;&#25104;&#20026;&#26080;&#30417;&#30563;&#35270;&#35273;&#34920;&#31034;&#23398;&#20064;&#20013;&#26368;&#25104;&#21151;&#30340;&#33539;&#24335;&#20043;&#19968;&#65292;&#28982;&#32780;&#23427;&#24448;&#24448;&#20381;&#36182;&#22823;&#37327;&#25163;&#24037;&#25968;&#25454;&#22686;&#24378;&#12290;&#38543;&#30528;&#29983;&#25104;&#27169;&#22411;&#30340;&#20852;&#36215;&#65292;&#29305;&#21035;&#26159;&#25193;&#25955;&#27169;&#22411;&#65292;&#29983;&#25104;&#25509;&#36817;&#30495;&#23454;&#25968;&#25454;&#20998;&#24067;&#30340;&#36924;&#30495;&#22270;&#20687;&#30340;&#33021;&#21147;&#24471;&#21040;&#20102;&#24456;&#22909;&#30340;&#35748;&#21487;&#12290;&#36825;&#20123;&#29983;&#25104;&#30340;&#39640;&#36136;&#37327;&#22270;&#20687;&#24050;&#25104;&#21151;&#24212;&#29992;&#20110;&#22686;&#24378;&#23545;&#27604;&#34920;&#31034;&#23398;&#20064;&#65292;&#19968;&#31181;&#31216;&#20026;&#8220;&#25968;&#25454;&#33192;&#32960;&#8221;&#30340;&#25216;&#26415;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#21457;&#29616;&#29983;&#25104;&#30340;&#25968;&#25454;&#65288;&#29978;&#33267;&#26469;&#33258;&#20687;DDPM&#36825;&#26679;&#30340;&#22909;&#25193;&#25955;&#27169;&#22411;&#65289;&#26377;&#26102;&#29978;&#33267;&#20250;&#23545;&#23545;&#27604;&#23398;&#20064;&#36896;&#25104;&#20260;&#23475;&#12290;&#25105;&#20204;&#20174;&#25968;&#25454;&#33192;&#32960;&#21644;&#25968;&#25454;&#22686;&#24378;&#30340;&#35282;&#24230;&#25506;&#35752;&#20102;&#36825;&#31181;&#22833;&#36133;&#30340;&#21407;&#22240;&#12290;&#25105;&#20204;&#39318;&#27425;&#25581;&#31034;&#20102;&#26356;&#24378;&#30340;&#25968;&#25454;&#33192;&#32960;&#24212;&#35813;&#20276;&#38543;&#30528;&#26356;&#24369;&#30340;&#22686;&#24378;&#65292;&#21453;&#20043;&#20134;&#28982;&#30340;&#20114;&#34917;&#20316;&#29992;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#29702;&#35770;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12448v1 Announce Type: cross  Abstract: Contrastive Learning (CL) has emerged as one of the most successful paradigms for unsupervised visual representation learning, yet it often depends on intensive manual data augmentations. With the rise of generative models, especially diffusion models, the ability to generate realistic images close to the real data distribution has been well recognized. These generated high-equality images have been successfully applied to enhance contrastive representation learning, a technique termed ``data inflation''. However, we find that the generated data (even from a good diffusion model like DDPM) may sometimes even harm contrastive learning. We investigate the causes behind this failure from the perspective of both data inflation and data augmentation. For the first time, we reveal the complementary roles that stronger data inflation should be accompanied by weaker augmentations, and vice versa. We also provide rigorous theoretical explanatio
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22870;&#21169;&#26679;&#26412;&#36716;&#31227;&#30340;&#31639;&#27861;&#65292;&#22312;&#39034;&#24207;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#20013;&#26174;&#33879;&#25913;&#36827;&#20102;&#32047;&#31215;&#36951;&#25022;&#24615;&#33021;</title><link>https://arxiv.org/abs/2403.12428</link><description>&lt;p&gt;
&#22522;&#20110;&#22870;&#21169;&#26679;&#26412;&#30340;&#39034;&#24207;&#22810;&#33218;&#32769;&#34382;&#26426;&#20013;&#30340;&#36716;&#31227;
&lt;/p&gt;
&lt;p&gt;
Transfer in Sequential Multi-armed Bandits via Reward Samples
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12428
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22870;&#21169;&#26679;&#26412;&#36716;&#31227;&#30340;&#31639;&#27861;&#65292;&#22312;&#39034;&#24207;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#20013;&#26174;&#33879;&#25913;&#36827;&#20102;&#32047;&#31215;&#36951;&#25022;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#39034;&#24207;&#38543;&#26426;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#65292;&#22312;&#36825;&#20010;&#38382;&#39064;&#20013;&#65292;&#20195;&#29702;&#19982;&#32769;&#34382;&#26426;&#22312;&#22810;&#20010;&#36718;&#27425;&#20013;&#36827;&#34892;&#20132;&#20114;&#12290;&#33218;&#30340;&#22870;&#21169;&#20998;&#24067;&#22312;&#19968;&#20010;&#36718;&#27425;&#20013;&#20445;&#25345;&#19981;&#21464;&#65292;&#20294;&#22312;&#19981;&#21516;&#36718;&#27425;&#20043;&#38388;&#21487;&#33021;&#20250;&#21457;&#29983;&#21464;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;UCB&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#20174;&#20808;&#21069;&#36718;&#27425;&#20013;&#36716;&#31227;&#22870;&#21169;&#26679;&#26412;&#65292;&#24182;&#25913;&#21892;&#25152;&#26377;&#36718;&#27425;&#20013;&#30340;&#32047;&#31215;&#36951;&#25022;&#24615;&#33021;&#12290;&#25105;&#20204;&#20026;&#25105;&#20204;&#30340;&#31639;&#27861;&#25552;&#20379;&#20102;&#36951;&#25022;&#24615;&#33021;&#20998;&#26512;&#21644;&#23454;&#35777;&#32467;&#26524;&#65292;&#34920;&#26126;&#30456;&#27604;&#27809;&#26377;&#36716;&#31227;&#30340;&#26631;&#20934;UCB&#31639;&#27861;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#26377;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12428v1 Announce Type: new  Abstract: We consider a sequential stochastic multi-armed bandit problem where the agent interacts with bandit over multiple episodes. The reward distribution of the arms remain constant throughout an episode but can change over different episodes. We propose an algorithm based on UCB to transfer the reward samples from the previous episodes and improve the cumulative regret performance over all the episodes. We provide regret analysis and empirical results for our algorithm, which show significant improvement over the standard UCB algorithm without transfer.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20108;&#27425;&#35780;&#20998;&#20989;&#25968;&#30340;&#19968;&#23545;&#19968;&#21305;&#37197;&#31639;&#27861;&#65292;&#36890;&#36807;&#35774;&#35745;&#26435;&#37325;&#26368;&#23567;&#21270;&#37197;&#23545;&#35757;&#32451;&#21333;&#20803;&#20043;&#38388;&#30340;&#24471;&#20998;&#24046;&#24322;&#65292;&#21516;&#26102;&#26368;&#22823;&#21270;&#26410;&#37197;&#23545;&#35757;&#32451;&#21333;&#20803;&#20043;&#38388;&#30340;&#24471;&#20998;&#24046;&#24322;</title><link>https://arxiv.org/abs/2403.12367</link><description>&lt;p&gt;
&#21322;&#30417;&#30563;&#35745;&#20998;&#21305;&#37197;&#31639;&#27861;&#35780;&#20272;&#20844;&#20849;&#21355;&#29983;&#24178;&#39044;&#25928;&#26524;
&lt;/p&gt;
&lt;p&gt;
Semisupervised score based matching algorithm to evaluate the effect of public health interventions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12367
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20108;&#27425;&#35780;&#20998;&#20989;&#25968;&#30340;&#19968;&#23545;&#19968;&#21305;&#37197;&#31639;&#27861;&#65292;&#36890;&#36807;&#35774;&#35745;&#26435;&#37325;&#26368;&#23567;&#21270;&#37197;&#23545;&#35757;&#32451;&#21333;&#20803;&#20043;&#38388;&#30340;&#24471;&#20998;&#24046;&#24322;&#65292;&#21516;&#26102;&#26368;&#22823;&#21270;&#26410;&#37197;&#23545;&#35757;&#32451;&#21333;&#20803;&#20043;&#38388;&#30340;&#24471;&#20998;&#24046;&#24322;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20803;&#21305;&#37197;&#31639;&#27861;&#22312;&#35266;&#23519;&#24615;&#30740;&#31350;&#20013;&#8220;&#37197;&#23545;&#8221;&#30456;&#20284;&#30340;&#30740;&#31350;&#21333;&#20803;&#65292;&#20197;&#28040;&#38500;&#30001;&#20110;&#32570;&#20047;&#38543;&#26426;&#24615;&#32780;&#24341;&#36215;&#30340;&#28508;&#22312;&#20559;&#20506;&#21644;&#28151;&#26434;&#25928;&#24212;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20108;&#27425;&#35780;&#20998;&#20989;&#25968;&#30340;&#26032;&#22411;&#19968;&#23545;&#19968;&#21305;&#37197;&#31639;&#27861;&#65292;&#26435;&#37325;$\beta$&#34987;&#35774;&#35745;&#20026;&#26368;&#23567;&#21270;&#37197;&#23545;&#35757;&#32451;&#21333;&#20803;&#20043;&#38388;&#30340;&#24471;&#20998;&#24046;&#24322;&#65292;&#21516;&#26102;&#26368;&#22823;&#21270;&#26410;&#37197;&#23545;&#35757;&#32451;&#21333;&#20803;&#20043;&#38388;&#30340;&#24471;&#20998;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12367v1 Announce Type: cross  Abstract: Multivariate matching algorithms "pair" similar study units in an observational study to remove potential bias and confounding effects caused by the absence of randomizations. In one-to-one multivariate matching algorithms, a large number of "pairs" to be matched could mean both the information from a large sample and a large number of tasks, and therefore, to best match the pairs, such a matching algorithm with efficiency and comparatively limited auxiliary matching knowledge provided through a "training" set of paired units by domain experts, is practically intriguing.   We proposed a novel one-to-one matching algorithm based on a quadratic score function $S_{\beta}(x_i,x_j)= \beta^T (x_i-x_j)(x_i-x_j)^T \beta$. The weights $\beta$, which can be interpreted as a variable importance measure, are designed to minimize the score difference between paired training units while maximizing the score difference between unpaired training units
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#37325;&#26032;&#21442;&#25968;&#21270;&#31934;&#20934;&#30697;&#38453;&#26368;&#21518;&#19968;&#21015;&#65292;&#23558;&#27491;&#21017;&#21270;&#27491;&#24577;&#23545;&#25968;&#20284;&#28982;&#20998;&#35299;&#20026;&#20004;&#20010;&#26131;&#20110;&#26368;&#23567;&#21270;&#30340;&#20984;&#20989;&#25968;&#65292;&#20854;&#20013;&#19968;&#20010;&#26159;Lasso&#22238;&#24402;&#38382;&#39064;&#65292;&#20174;&#32780;&#24320;&#21457;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#22359;&#22352;&#26631;&#19979;&#38477;&#31639;&#27861;&#26469;&#35745;&#31639;GLasso&#26356;&#26032;&#65292;&#24615;&#33021;&#21487;&#19982;DP-GLas&#30456;&#23218;&#32654;&#12290;</title><link>https://arxiv.org/abs/2403.12357</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#31934;&#20934;&#30697;&#38453;&#30340;&#26367;&#20195;&#22270;&#24418;Lasso&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
An Alternative Graphical Lasso Algorithm for Precision Matrices
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12357
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#37325;&#26032;&#21442;&#25968;&#21270;&#31934;&#20934;&#30697;&#38453;&#26368;&#21518;&#19968;&#21015;&#65292;&#23558;&#27491;&#21017;&#21270;&#27491;&#24577;&#23545;&#25968;&#20284;&#28982;&#20998;&#35299;&#20026;&#20004;&#20010;&#26131;&#20110;&#26368;&#23567;&#21270;&#30340;&#20984;&#20989;&#25968;&#65292;&#20854;&#20013;&#19968;&#20010;&#26159;Lasso&#22238;&#24402;&#38382;&#39064;&#65292;&#20174;&#32780;&#24320;&#21457;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#22359;&#22352;&#26631;&#19979;&#38477;&#31639;&#27861;&#26469;&#35745;&#31639;GLasso&#26356;&#26032;&#65292;&#24615;&#33021;&#21487;&#19982;DP-GLas&#30456;&#23218;&#32654;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Graphical Lasso (GLasso)&#31639;&#27861;&#26159;&#19968;&#31181;&#24555;&#36895;&#19988;&#24191;&#27867;&#29992;&#20110;&#20272;&#35745;&#31232;&#30095;&#31934;&#20934;&#30697;&#38453;&#30340;&#26041;&#27861;&#12290;&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#26032;&#30340;&#24182;&#30053;&#24494;&#19981;&#21516;&#30340;&#31934;&#20934;&#30697;&#38453;&#26368;&#21518;&#19968;&#21015;&#30340;&#37325;&#26032;&#21442;&#25968;&#21270;&#65292;&#23637;&#31034;&#20102;&#27491;&#21017;&#21270;&#27491;&#24577;&#23545;&#25968;&#20284;&#28982;&#33258;&#28982;&#22320;&#20998;&#35299;&#25104;&#20004;&#20010;&#26131;&#20110;&#26368;&#23567;&#21270;&#30340;&#20984;&#20989;&#25968;&#20043;&#21644;&#65292;&#20854;&#20013;&#20043;&#19968;&#26159;Lasso&#22238;&#24402;&#38382;&#39064;&#12290;&#36825;&#31181;&#20998;&#35299;&#26159;&#24320;&#21457;&#36879;&#26126;&#12289;&#31616;&#21333;&#30340;&#36845;&#20195;&#22359;&#22352;&#26631;&#19979;&#38477;&#31639;&#27861;&#30340;&#20851;&#38190;&#65292;&#29992;&#20110;&#35745;&#31639;GLasso&#26356;&#26032;&#65292;&#20854;&#24615;&#33021;&#19982;DP-GLas&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12357v1 Announce Type: cross  Abstract: The Graphical Lasso (GLasso) algorithm is fast and widely used for estimating sparse precision matrices (Friedman et al., 2008). Its central role in the literature of high-dimensional covariance estimation rivals that of Lasso regression for sparse estimation of the mean vector. Some mysteries regarding its optimization target, convergence, positive-definiteness and performance have been unearthed, resolved and presented in Mazumder and Hastie (2011), leading to a new/improved (dual-primal) DP-GLasso. Using a new and slightly different reparametriztion of the last column of a precision matrix we show that the regularized normal log-likelihood naturally decouples into a sum of two easy to minimize convex functions one of which is a Lasso regression problem. This decomposition is the key in developing a transparent, simple iterative block coordinate descent algorithm for computing the GLasso updates with performance comparable to DP-GLas
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;&#38543;&#26426;Halpern&#36845;&#20195;&#22312;&#36171;&#33539;&#31354;&#38388;&#20013;&#30340;Oracle&#22797;&#26434;&#24230;&#65292;&#25552;&#20986;&#20102;&#25913;&#36827;&#30340;&#31639;&#27861;&#22797;&#26434;&#24230;&#65292;&#36827;&#32780;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#25552;&#20986;&#20102;&#26032;&#30340;&#21516;&#27493;&#31639;&#27861;&#24212;&#29992;&#12290;</title><link>https://arxiv.org/abs/2403.12338</link><description>&lt;p&gt;
&#38543;&#26426;Halpern&#36845;&#20195;&#22312;&#36171;&#33539;&#31354;&#38388;&#20013;&#30340;&#24212;&#29992;&#21450;&#20854;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Stochastic Halpern iteration in normed spaces and applications to reinforcement learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12338
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20998;&#26512;&#20102;&#38543;&#26426;Halpern&#36845;&#20195;&#22312;&#36171;&#33539;&#31354;&#38388;&#20013;&#30340;Oracle&#22797;&#26434;&#24230;&#65292;&#25552;&#20986;&#20102;&#25913;&#36827;&#30340;&#31639;&#27861;&#22797;&#26434;&#24230;&#65292;&#36827;&#32780;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#25552;&#20986;&#20102;&#26032;&#30340;&#21516;&#27493;&#31639;&#27861;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20998;&#26512;&#20102;&#20855;&#26377;&#26041;&#24046;&#20943;&#23569;&#30340;&#38543;&#26426;Halpern&#36845;&#20195;&#30340;Oracle&#22797;&#26434;&#24230;&#65292;&#26088;&#22312;&#36817;&#20284;&#26377;&#30028;&#21644;&#25910;&#32553;&#31639;&#23376;&#30340;&#19981;&#21160;&#28857;&#22312;&#19968;&#20010;&#26377;&#38480;&#32500;&#36171;&#33539;&#31354;&#38388;&#20013;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#22914;&#26524;&#24213;&#23618;&#30340;&#38543;&#26426;Oracle&#20855;&#26377;&#19968;&#33268;&#26377;&#30028;&#30340;&#26041;&#24046;&#65292;&#21017;&#25105;&#20204;&#30340;&#26041;&#27861;&#23637;&#29616;&#20986;&#24635;&#30340;Oracle&#22797;&#26434;&#24230;&#20026;$ \tilde{O} (\varepsilon^{-5})$&#65292;&#25913;&#36827;&#20102;&#26368;&#36817;&#20026;&#38543;&#26426;Krasnoselskii-Mann&#36845;&#20195;&#24314;&#31435;&#30340;&#36895;&#29575;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102; $\Omega (\varepsilon^{-3})$&#30340;&#19979;&#30028;&#65292;&#36866;&#29992;&#20110;&#24191;&#27867;&#33539;&#22260;&#30340;&#31639;&#27861;&#65292;&#21253;&#25324;&#25152;&#26377;&#24102;&#26377;&#23567;&#25209;&#22788;&#29702;&#30340;&#24179;&#22343;&#36845;&#20195;&#12290;&#36890;&#36807;&#36866;&#24403;&#20462;&#25913;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#22312;&#31639;&#23376;&#20026; $\gamma$-&#25910;&#32553;&#30340;&#24773;&#20917;&#19979;&#19968;&#20010; $O(\varepsilon^{-2}(1-\gamma)^{-3})$&#22797;&#26434;&#24230;&#19978;&#30028;&#12290;&#20316;&#20026;&#19968;&#20010;&#24212;&#29992;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26032;&#30340;&#29992;&#20110;&#24179;&#22343;&#22870;&#21169;&#21644;&#25240;&#25187;&#22870;&#21169;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#30340;&#21516;&#27493;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12338v1 Announce Type: cross  Abstract: We analyze the oracle complexity of the stochastic Halpern iteration with variance reduction, where we aim to approximate fixed-points of nonexpansive and contractive operators in a normed finite-dimensional space. We show that if the underlying stochastic oracle is with uniformly bounded variance, our method exhibits an overall oracle complexity of $\tilde{O}(\varepsilon^{-5})$, improving recent rates established for the stochastic Krasnoselskii-Mann iteration. Also, we establish a lower bound of $\Omega(\varepsilon^{-3})$, which applies to a wide range of algorithms, including all averaged iterations even with minibatching. Using a suitable modification of our approach, we derive a $O(\varepsilon^{-2}(1-\gamma)^{-3})$ complexity bound in the case in which the operator is a $\gamma$-contraction. As an application, we propose new synchronous algorithms for average reward and discounted reward Markov decision processes. In particular, f
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;FedFisher&#31639;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;Fisher&#20449;&#24687;&#30697;&#38453;&#36827;&#34892;&#19968;&#27425;&#24615;&#32852;&#37030;&#23398;&#20064;&#65292;&#33021;&#22815;&#22312;&#19968;&#27425;&#36890;&#20449;&#20013;&#35757;&#32451;&#20986;&#20840;&#23616;&#27169;&#22411;&#65292;&#24182;&#22312;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#38543;&#30528;&#31070;&#32463;&#32593;&#32476;&#23485;&#24230;&#21644;&#23458;&#25143;&#31471;&#26412;&#22320;&#35757;&#32451;&#37327;&#30340;&#22686;&#21152;&#65292;FedFisher&#20840;&#23616;&#27169;&#22411;&#30340;&#35823;&#24046;&#20250;&#21464;&#24471;&#38750;&#24120;&#23567;&#12290;</title><link>https://arxiv.org/abs/2403.12329</link><description>&lt;p&gt;
FedFisher&#65306;&#21033;&#29992;Fisher&#20449;&#24687;&#36827;&#34892;&#19968;&#27425;&#24615;&#32852;&#37030;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
FedFisher: Leveraging Fisher Information for One-Shot Federated Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12329
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;FedFisher&#31639;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;Fisher&#20449;&#24687;&#30697;&#38453;&#36827;&#34892;&#19968;&#27425;&#24615;&#32852;&#37030;&#23398;&#20064;&#65292;&#33021;&#22815;&#22312;&#19968;&#27425;&#36890;&#20449;&#20013;&#35757;&#32451;&#20986;&#20840;&#23616;&#27169;&#22411;&#65292;&#24182;&#22312;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#38543;&#30528;&#31070;&#32463;&#32593;&#32476;&#23485;&#24230;&#21644;&#23458;&#25143;&#31471;&#26412;&#22320;&#35757;&#32451;&#37327;&#30340;&#22686;&#21152;&#65292;FedFisher&#20840;&#23616;&#27169;&#22411;&#30340;&#35823;&#24046;&#20250;&#21464;&#24471;&#38750;&#24120;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#20934;&#30340;&#32852;&#37030;&#23398;&#20064;(FL)&#31639;&#27861;&#36890;&#24120;&#38656;&#35201;&#26381;&#21153;&#22120;&#21644;&#23458;&#25143;&#31471;&#20043;&#38388;&#30340;&#22810;&#36718;&#36890;&#20449;&#65292;&#36825;&#20855;&#26377;&#20960;&#20010;&#32570;&#28857;&#65292;&#21253;&#25324;&#38656;&#35201;&#24658;&#23450;&#30340;&#32593;&#32476;&#36830;&#36890;&#24615;&#65292;&#37325;&#22797;&#25237;&#20837;&#35745;&#31639;&#36164;&#28304;&#65292;&#20197;&#21450;&#23481;&#26131;&#21463;&#21040;&#38544;&#31169;&#25915;&#20987;&#30340;&#24433;&#21709;&#12290;&#19968;&#27425;&#24615;FL&#26159;&#19968;&#31181;&#26032;&#30340;&#33539;&#20363;&#65292;&#26088;&#22312;&#36890;&#36807;&#20351;&#26381;&#21153;&#22120;&#22312;&#19968;&#36718;&#36890;&#20449;&#20013;&#35757;&#32451;&#20840;&#23616;&#27169;&#22411;&#26469;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;FedFisher&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#29992;&#20110;&#19968;&#27425;&#24615;FL&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21033;&#29992;&#22312;&#26412;&#22320;&#23458;&#25143;&#31471;&#27169;&#22411;&#19978;&#35745;&#31639;&#30340;Fisher&#20449;&#24687;&#30697;&#38453;&#65292;&#21463;&#21040;FL&#30340;&#36125;&#21494;&#26031;&#35270;&#35282;&#30340;&#21551;&#21457;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#20174;&#20004;&#23618;&#36807;&#21442;&#25968;&#21270;&#30340;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#29702;&#35770;&#35282;&#24230;&#23545;FedFisher&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#19968;&#27425;&#24615;FedFisher&#20840;&#23616;&#27169;&#22411;&#30340;&#35823;&#24046;&#20250;&#22312;&#31070;&#32463;&#32593;&#32476;&#30340;&#23485;&#24230;&#21644;&#23458;&#25143;&#31471;&#26412;&#22320;&#35757;&#32451;&#37327;&#22686;&#21152;&#26102;&#21464;&#24471;&#26080;&#38480;&#23567;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23454;&#29992;&#30340;F&#30340;&#21464;&#31181;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12329v1 Announce Type: new  Abstract: Standard federated learning (FL) algorithms typically require multiple rounds of communication between the server and the clients, which has several drawbacks, including requiring constant network connectivity, repeated investment of computational resources, and susceptibility to privacy attacks. One-Shot FL is a new paradigm that aims to address this challenge by enabling the server to train a global model in a single round of communication. In this work, we present FedFisher, a novel algorithm for one-shot FL that makes use of Fisher information matrices computed on local client models, motivated by a Bayesian perspective of FL. First, we theoretically analyze FedFisher for two-layer over-parameterized ReLU neural networks and show that the error of our one-shot FedFisher global model becomes vanishingly small as the width of the neural networks and amount of local training at clients increases. Next, we propose practical variants of F
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32479;&#19968;&#26694;&#26550;&#65292;&#29992;&#20110;&#26500;&#24314;&#20449;&#24687;&#20016;&#23500;&#30340;&#31526;&#21512;&#39044;&#27979;&#38598;&#65292;&#21516;&#26102;&#25511;&#21046;&#25152;&#36873;&#26679;&#26412;&#30340;&#34394;&#35686;&#35206;&#30422;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.12295</link><description>&lt;p&gt;
&#36890;&#36807;&#25511;&#21046;&#34394;&#35686;&#35206;&#30422;&#29575;&#36873;&#25321;&#20449;&#24687;&#37327;&#20016;&#23500;&#30340;&#31526;&#21512;&#39044;&#27979;&#38598;
&lt;/p&gt;
&lt;p&gt;
Selecting informative conformal prediction sets with false coverage rate control
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12295
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32479;&#19968;&#26694;&#26550;&#65292;&#29992;&#20110;&#26500;&#24314;&#20449;&#24687;&#20016;&#23500;&#30340;&#31526;&#21512;&#39044;&#27979;&#38598;&#65292;&#21516;&#26102;&#25511;&#21046;&#25152;&#36873;&#26679;&#26412;&#30340;&#34394;&#35686;&#35206;&#30422;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#30417;&#30563;&#23398;&#20064;&#20013;&#65292;&#21253;&#25324;&#22238;&#24402;&#21644;&#20998;&#31867;&#65292;&#31526;&#21512;&#26041;&#27861;&#20026;&#20219;&#20309;&#26426;&#22120;&#23398;&#20064;&#39044;&#27979;&#22120;&#25552;&#20379;&#39044;&#27979;&#32467;&#26524;/&#26631;&#31614;&#30340;&#39044;&#27979;&#38598;&#21512;&#65292;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#35206;&#30422;&#29575;&#12290;&#22312;&#36825;&#37324;&#25105;&#20204;&#32771;&#34385;&#20102;&#36825;&#26679;&#19968;&#31181;&#24773;&#20917;&#65292;&#21363;&#36825;&#31181;&#39044;&#27979;&#38598;&#21512;&#26159;&#32463;&#36807;&#36873;&#25321;&#36807;&#31243;&#24471;&#21040;&#30340;&#12290;&#35813;&#36873;&#25321;&#36807;&#31243;&#35201;&#27714;&#36873;&#25321;&#30340;&#39044;&#27979;&#38598;&#22312;&#26576;&#31181;&#26126;&#30830;&#23450;&#20041;&#30340;&#24847;&#20041;&#19978;&#26159;&#8220;&#20449;&#24687;&#37327;&#20016;&#23500;&#30340;&#8221;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#20998;&#31867;&#21644;&#22238;&#24402;&#35774;&#32622;&#65292;&#22312;&#36825;&#20123;&#35774;&#32622;&#20013;&#65292;&#20998;&#26512;&#20154;&#21592;&#21487;&#33021;&#21482;&#32771;&#34385;&#20855;&#26377;&#39044;&#27979;&#26631;&#31614;&#38598;&#25110;&#39044;&#27979;&#21306;&#38388;&#36275;&#22815;&#23567;&#12289;&#19981;&#21253;&#25324;&#31354;&#20540;&#25110;&#36981;&#23432;&#20854;&#20182;&#36866;&#24403;&#30340;&#8220;&#21333;&#35843;&#8221;&#32422;&#26463;&#30340;&#26679;&#26412;&#20026;&#20855;&#26377;&#20449;&#24687;&#37327;&#20016;&#23500;&#30340;&#12290;&#34429;&#28982;&#36825;&#28085;&#30422;&#20102;&#21508;&#31181;&#24212;&#29992;&#20013;&#21487;&#33021;&#24863;&#20852;&#36259;&#30340;&#35768;&#22810;&#35774;&#32622;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#65292;&#29992;&#26469;&#26500;&#24314;&#36825;&#26679;&#30340;&#20449;&#24687;&#37327;&#20016;&#23500;&#30340;&#31526;&#21512;&#39044;&#27979;&#38598;&#65292;&#21516;&#26102;&#25511;&#21046;&#25152;&#36873;&#26679;&#26412;&#19978;&#30340;&#34394;&#35686;&#35206;&#30422;&#29575;&#65288;FCR&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12295v1 Announce Type: cross  Abstract: In supervised learning, including regression and classification, conformal methods provide prediction sets for the outcome/label with finite sample coverage for any machine learning predictors. We consider here the case where such prediction sets come after a selection process. The selection process requires that the selected prediction sets be `informative' in a well defined sense. We consider both the classification and regression settings where the analyst may consider as informative only the sample with prediction label sets or prediction intervals small enough, excluding null values, or obeying other appropriate `monotone' constraints. While this covers many settings of possible interest in various applications, we develop a unified framework for building such informative conformal prediction sets while controlling the false coverage rate (FCR) on the selected sample. While conformal prediction sets after selection have been the f
&lt;/p&gt;</description></item><item><title>&#22522;&#20110;&#21644;&#24179;&#26041;&#27861;&#30340;&#31169;&#26377;&#22270;&#20272;&#35745;&#31639;&#27861;&#39318;&#27425;&#23454;&#29616;&#20102;&#23398;&#20064;&#38543;&#26426;&#22359;&#27169;&#22411;&#21644;&#22270;&#20272;&#35745;&#30340;&#32431;&#33410;&#28857;&#24046;&#20998;&#38544;&#31169;&#31639;&#27861;&#65292;&#20855;&#26377;&#22810;&#39033;&#24335;&#36816;&#34892;&#26102;&#38388;&#65292;&#19982;&#20043;&#21069;&#26368;&#20339;&#30340;&#20449;&#24687;&#35770;&#33410;&#28857;&#31169;&#26377;&#26426;&#21046;&#20855;&#26377;&#30456;&#21305;&#37197;&#30340;&#32479;&#35745;&#25928;&#29992;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2403.12213</link><description>&lt;p&gt;
&#36890;&#36807;&#20108;&#27425;&#21644;&#26041;&#27861;&#36827;&#34892;&#31169;&#26377;&#22270;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Private graphon estimation via sum-of-squares
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12213
&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#21644;&#24179;&#26041;&#27861;&#30340;&#31169;&#26377;&#22270;&#20272;&#35745;&#31639;&#27861;&#39318;&#27425;&#23454;&#29616;&#20102;&#23398;&#20064;&#38543;&#26426;&#22359;&#27169;&#22411;&#21644;&#22270;&#20272;&#35745;&#30340;&#32431;&#33410;&#28857;&#24046;&#20998;&#38544;&#31169;&#31639;&#27861;&#65292;&#20855;&#26377;&#22810;&#39033;&#24335;&#36816;&#34892;&#26102;&#38388;&#65292;&#19982;&#20043;&#21069;&#26368;&#20339;&#30340;&#20449;&#24687;&#35770;&#33410;&#28857;&#31169;&#26377;&#26426;&#21046;&#20855;&#26377;&#30456;&#21305;&#37197;&#30340;&#32479;&#35745;&#25928;&#29992;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24320;&#21457;&#20102;&#29992;&#20110;&#23398;&#20064;&#38543;&#26426;&#22359;&#27169;&#22411;&#21644;&#22270;&#20272;&#35745;&#30340;&#31532;&#19968;&#20010;&#32431;&#33410;&#28857;&#24046;&#20998;&#38544;&#31169;&#31639;&#27861;&#65292;&#23545;&#20110;&#20219;&#24847;&#24120;&#25968;&#20010;&#22359;&#65292;&#20855;&#26377;&#22810;&#39033;&#24335;&#36816;&#34892;&#26102;&#38388;&#12290;&#32479;&#35745;&#25928;&#29992;&#20445;&#35777;&#19982;&#20808;&#21069;&#26368;&#20339;&#30340;&#20449;&#24687;&#35770;&#65288;&#25351;&#25968;&#26102;&#38388;&#65289;&#33410;&#28857;&#31169;&#26377;&#26426;&#21046;&#30456;&#21305;&#37197;&#12290;&#35813;&#31639;&#27861;&#22522;&#20110;&#19968;&#20010;&#22522;&#20110;&#25351;&#25968;&#26426;&#21046;&#30340;&#24471;&#20998;&#20989;&#25968;&#65292;&#35813;&#20989;&#25968;&#23450;&#20041;&#20026;&#20381;&#36182;&#20110;&#22359;&#25968;&#37327;&#30340;&#20108;&#27425;&#21644;&#26494;&#24347;&#12290;&#25105;&#20204;&#32467;&#26524;&#30340;&#20851;&#38190;&#35201;&#32032;&#26159;&#65306;(1) &#22312;&#24418;&#24335;&#19978;&#23450;&#20041;&#20026;&#20108;&#27425;&#20248;&#21270;&#22312;&#21452;&#37325;&#38543;&#26426;&#30697;&#38453;&#30340;&#22810;&#32990;&#20307;&#19978;&#30340;&#36317;&#31163;&#30340;&#29305;&#24449;&#21270;&#22359;&#22270;&#23450;&#20041;&#65292;(2) &#19968;&#33324;&#30340;&#22810;&#39033;&#24335;&#20248;&#21270;&#30340;&#21644;&#24179;&#26041;&#27861;&#22312;&#20219;&#24847;&#22810;&#32990;&#20307;&#19978;&#30340;&#25910;&#25947;&#32467;&#26524;&#65292;&#20197;&#21450;(3) &#25191;&#34892;&#21033;&#26222;&#24076;&#33576;&#25193;&#23637;&#30340;&#24471;&#20998;&#20989;&#25968;&#20316;&#20026;&#20108;&#27425;&#21644;&#31639;&#27861;&#33539;&#20363;&#30340;&#19968;&#33324;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12213v1 Announce Type: cross  Abstract: We develop the first pure node-differentially-private algorithms for learning stochastic block models and for graphon estimation with polynomial running time for any constant number of blocks. The statistical utility guarantees match those of the previous best information-theoretic (exponential-time) node-private mechanisms for these problems. The algorithm is based on an exponential mechanism for a score function defined in terms of a sum-of-squares relaxation whose level depends on the number of blocks. The key ingredients of our results are (1) a characterization of the distance between the block graphons in terms of a quadratic optimization over the polytope of doubly stochastic matrices, (2) a general sum-of-squares convergence result for polynomial optimization over arbitrary polytopes, and (3) a general approach to perform Lipschitz extensions of score functions as part of the sum-of-squares algorithmic paradigm.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#19978;&#30340;&#20989;&#25968;&#22411;&#65292;&#24182;&#24314;&#31435;&#20102;&#36924;&#36817;&#30340;&#26222;&#36866;&#24615;&#65292;&#25512;&#23548;&#20102;&#36870;&#22810;&#37325;&#20108;&#27425;&#12289;&#39640;&#26031;&#21644;Sobolev&#26680;&#24341;&#36215;&#30340;&#35823;&#24046;&#30028;&#38480;&#65292;&#35777;&#26126;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#20934;&#30830;&#36924;&#36817;&#24191;&#20041;&#20989;&#25968;&#32447;&#24615;&#27169;&#22411;&#20013;&#30340;&#22238;&#24402;&#26144;&#23556;&#12290;</title><link>https://arxiv.org/abs/2403.12187</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;RKHS&#20989;&#25968;&#22411;
&lt;/p&gt;
&lt;p&gt;
Approximation of RKHS Functionals by Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12187
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#19978;&#30340;&#20989;&#25968;&#22411;&#65292;&#24182;&#24314;&#31435;&#20102;&#36924;&#36817;&#30340;&#26222;&#36866;&#24615;&#65292;&#25512;&#23548;&#20102;&#36870;&#22810;&#37325;&#20108;&#27425;&#12289;&#39640;&#26031;&#21644;Sobolev&#26680;&#24341;&#36215;&#30340;&#35823;&#24046;&#30028;&#38480;&#65292;&#35777;&#26126;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#20934;&#30830;&#36924;&#36817;&#24191;&#20041;&#20989;&#25968;&#32447;&#24615;&#27169;&#22411;&#20013;&#30340;&#22238;&#24402;&#26144;&#23556;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#21040;&#26102;&#38388;&#24207;&#21015;&#21644;&#22270;&#20687;&#31561;&#20016;&#23500;&#21151;&#33021;&#24615;&#25968;&#25454;&#30340;&#21551;&#21457;&#65292;&#20154;&#20204;&#36234;&#26469;&#36234;&#24863;&#20852;&#36259;&#23558;&#36825;&#20123;&#25968;&#25454;&#25972;&#21512;&#21040;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#24182;&#20174;&#20989;&#25968;&#31354;&#38388;&#21040;R&#65288;&#21363;&#20989;&#25968;&#22411;&#65289;&#23398;&#20064;&#26144;&#23556;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#36924;&#36817;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#19978;&#30340;&#20989;&#25968;&#22411;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#23545;RKHS&#19978;&#20989;&#25968;&#22411;&#36924;&#36817;&#30340;&#26222;&#36866;&#24615;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#36890;&#36807;&#36870;&#22810;&#37325;&#20108;&#27425;&#12289;&#39640;&#26031;&#21644;Sobolev&#26680;&#24341;&#36215;&#30340;&#26126;&#30830;&#35823;&#24046;&#30028;&#38480;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#30740;&#31350;&#24212;&#29992;&#20110;&#20989;&#25968;&#22238;&#24402;&#65292;&#35777;&#26126;&#20102;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#20934;&#30830;&#36924;&#36817;&#24191;&#20041;&#20989;&#25968;&#32447;&#24615;&#27169;&#22411;&#20013;&#30340;&#22238;&#24402;&#26144;&#23556;&#12290;&#29616;&#26377;&#30340;&#21151;&#33021;&#24615;&#23398;&#20064;&#20316;&#21697;&#38656;&#35201;&#31215;&#20998;&#22411;&#22522;&#20989;&#25968;&#23637;&#24320;&#19982;&#19968;&#32452;&#39044;&#23450;&#20041;&#30340;&#22522;&#20989;&#25968;&#12290;&#36890;&#36807;&#22312;RKHS&#20013;&#21033;&#29992;&#25554;&#20540;&#27491;&#20132;&#25237;&#24433;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#32593;&#32476;&#26159;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12187v1 Announce Type: cross  Abstract: Motivated by the abundance of functional data such as time series and images, there has been a growing interest in integrating such data into neural networks and learning maps from function spaces to R (i.e., functionals). In this paper, we study the approximation of functionals on reproducing kernel Hilbert spaces (RKHS's) using neural networks. We establish the universality of the approximation of functionals on the RKHS's. Specifically, we derive explicit error bounds for those induced by inverse multiquadric, Gaussian, and Sobolev kernels. Moreover, we apply our findings to functional regression, proving that neural networks can accurately approximate the regression maps in generalized functional linear models. Existing works on functional learning require integration-type basis function expansions with a set of pre-specified basis functions. By leveraging the interpolating orthogonal projections in RKHS's, our proposed network is 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#21033;&#29992;&#26680;&#24515;&#23376;&#38598;&#36873;&#25321;&#36827;&#34892;&#25968;&#25454;&#37325;&#26032;&#21152;&#26435;&#30340;&#26041;&#27861;&#65292;&#26377;&#25928;&#20248;&#21270;&#20102;&#35745;&#31639;&#26102;&#38388;&#21644;&#27169;&#22411;&#24615;&#33021;&#65292;&#31361;&#26174;&#20854;&#20316;&#20026;&#27169;&#22411;&#35757;&#32451;&#30340;&#21487;&#25193;&#23637;&#21644;&#31934;&#30830;&#35299;&#20915;&#26041;&#26696;&#30340;&#28508;&#21147;&#12290;</title><link>https://arxiv.org/abs/2403.12166</link><description>&lt;p&gt;
&#23569;&#25968;&#20010;&#20307;&#30340;&#21147;&#37327;&#65306;&#21033;&#29992;&#26680;&#24515;&#23376;&#38598;&#36873;&#25321;&#21152;&#36895;&#21644;&#20248;&#21270;&#25968;&#25454;&#37325;&#26032;&#21152;&#26435;
&lt;/p&gt;
&lt;p&gt;
The Power of Few: Accelerating and Enhancing Data Reweighting with Coreset Selection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12166
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#21033;&#29992;&#26680;&#24515;&#23376;&#38598;&#36873;&#25321;&#36827;&#34892;&#25968;&#25454;&#37325;&#26032;&#21152;&#26435;&#30340;&#26041;&#27861;&#65292;&#26377;&#25928;&#20248;&#21270;&#20102;&#35745;&#31639;&#26102;&#38388;&#21644;&#27169;&#22411;&#24615;&#33021;&#65292;&#31361;&#26174;&#20854;&#20316;&#20026;&#27169;&#22411;&#35757;&#32451;&#30340;&#21487;&#25193;&#23637;&#21644;&#31934;&#30830;&#35299;&#20915;&#26041;&#26696;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#19981;&#26029;&#21457;&#23637;&#65292;&#36235;&#21183;&#26159;&#25910;&#38598;&#26356;&#22823;&#30340;&#25968;&#25454;&#38598;&#24182;&#35757;&#32451;&#35268;&#27169;&#36234;&#26469;&#36234;&#22823;&#30340;&#27169;&#22411;&#12290;&#34429;&#28982;&#36825;&#25552;&#39640;&#20102;&#20934;&#30830;&#24615;&#65292;&#20294;&#20063;&#23558;&#35745;&#31639;&#25104;&#26412;&#25552;&#39640;&#21040;&#19981;&#21487;&#25345;&#32493;&#30340;&#27700;&#24179;&#12290;&#38024;&#23545;&#36825;&#19968;&#38382;&#39064;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#26088;&#22312;&#22312;&#35745;&#31639;&#25928;&#29575;&#21644;&#27169;&#22411;&#20934;&#30830;&#24615;&#20043;&#38388;&#21462;&#24471;&#24494;&#22937;&#30340;&#24179;&#34913;&#65292;&#36825;&#26159;&#35813;&#39046;&#22495;&#20013;&#19968;&#30452;&#23384;&#22312;&#30340;&#25361;&#25112;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21033;&#29992;&#26680;&#24515;&#23376;&#38598;&#36873;&#25321;&#36827;&#34892;&#37325;&#26032;&#21152;&#26435;&#30340;&#26032;&#26041;&#27861;&#65292;&#26377;&#25928;&#20248;&#21270;&#20102;&#35745;&#31639;&#26102;&#38388;&#21644;&#27169;&#22411;&#24615;&#33021;&#12290;&#36890;&#36807;&#19987;&#27880;&#20110; strategically selected coreset&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;&#19968;&#20010;&#31283;&#20581;&#30340;&#34920;&#31034;&#65292;&#22240;&#20026;&#23427;&#26377;&#25928;&#22320;&#26368;&#23567;&#21270;&#20102;&#24322;&#24120;&#20540;&#30340;&#24433;&#21709;&#12290;&#28982;&#21518;&#65292;&#37325;&#26032;&#26657;&#20934;&#30340;&#26435;&#37325;&#34987;&#26144;&#23556;&#22238;&#24182;&#20256;&#25773;&#21040;&#25972;&#20010;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#35777;&#23454;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#31361;&#26174;&#20102;&#23427;&#20316;&#20026;&#27169;&#22411;&#35757;&#32451;&#30340;&#21487;&#25193;&#23637;&#21644;&#31934;&#30830;&#35299;&#20915;&#26041;&#26696;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12166v1 Announce Type: new  Abstract: As machine learning tasks continue to evolve, the trend has been to gather larger datasets and train increasingly larger models. While this has led to advancements in accuracy, it has also escalated computational costs to unsustainable levels. Addressing this, our work aims to strike a delicate balance between computational efficiency and model accuracy, a persisting challenge in the field. We introduce a novel method that employs core subset selection for reweighting, effectively optimizing both computational time and model performance. By focusing on a strategically selected coreset, our approach offers a robust representation, as it efficiently minimizes the influence of outliers. The re-calibrated weights are then mapped back to and propagated across the entire dataset. Our experimental results substantiate the effectiveness of this approach, underscoring its potential as a scalable and precise solution for model training.
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#21464;&#20998;&#26041;&#27861;&#22312;Dirichlet&#28151;&#21512;&#27169;&#22411;&#20013;&#25552;&#20379;&#20102;&#23553;&#38381;&#24418;&#24335;&#30340;&#35299;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;&#35745;&#31639;&#25928;&#29575;&#65292;&#21487;&#29992;&#20110;&#24555;&#36895;&#27169;&#22411;&#27604;&#36739;&#21644;&#31283;&#20581;&#20272;&#35745;&#35780;&#20272;&#12290;</title><link>https://arxiv.org/abs/2403.12158</link><description>&lt;p&gt;
&#21464;&#20998;&#26041;&#27861;&#29992;&#20110;Dirichlet&#28151;&#21512;&#27169;&#22411;&#20013;KL&#25955;&#24230;&#30340;&#39640;&#25928;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Variational Approach for Efficient KL Divergence Estimation in Dirichlet Mixture Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12158
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#21464;&#20998;&#26041;&#27861;&#22312;Dirichlet&#28151;&#21512;&#27169;&#22411;&#20013;&#25552;&#20379;&#20102;&#23553;&#38381;&#24418;&#24335;&#30340;&#35299;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;&#35745;&#31639;&#25928;&#29575;&#65292;&#21487;&#29992;&#20110;&#24555;&#36895;&#27169;&#22411;&#27604;&#36739;&#21644;&#31283;&#20581;&#20272;&#35745;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#33268;&#21147;&#20110;&#22312;Dirichlet&#28151;&#21512;&#27169;&#22411;&#65288;DMM&#65289;&#20013;&#39640;&#25928;&#20272;&#35745;Kullback-Leibler&#65288;KL&#65289;&#25955;&#24230;&#65292;&#36825;&#23545;&#20110;&#23545;&#25104;&#20998;&#25968;&#25454;&#36827;&#34892;&#32858;&#31867;&#33267;&#20851;&#37325;&#35201;&#12290;&#23613;&#31649;DMM&#30340;&#37325;&#35201;&#24615;&#65292;&#20294;&#33719;&#24471;KL&#25955;&#24230;&#30340;&#35299;&#26512;&#35299;&#20173;&#28982;&#26159;&#22256;&#38590;&#30340;&#12290;&#36807;&#21435;&#30340;&#26041;&#27861;&#20381;&#36182;&#20110;&#35745;&#31639;&#23494;&#38598;&#22411;&#30340;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#65292;&#36825;&#20419;&#20351;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21464;&#20998;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;&#19968;&#20010;&#23553;&#38381;&#24418;&#24335;&#30340;&#35299;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;&#35745;&#31639;&#25928;&#29575;&#65292;&#21487;&#20197;&#24555;&#36895;&#36827;&#34892;&#27169;&#22411;&#27604;&#36739;&#21644;&#31283;&#20581;&#30340;&#20272;&#35745;&#35780;&#20272;&#12290;&#23454;&#38469;&#25968;&#25454;&#21644;&#27169;&#25311;&#25968;&#25454;&#30340;&#39564;&#35777;&#26174;&#31034;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#27604;&#20256;&#32479;&#30340;&#22522;&#20110;&#33945;&#29305;&#21345;&#27931;&#30340;&#26041;&#27861;&#26356;&#21152;&#39640;&#25928;&#20934;&#30830;&#65292;&#20026;&#24555;&#36895;&#25506;&#32034;&#19981;&#21516;DMM&#27169;&#22411;&#21644;&#25512;&#36827;&#25104;&#20998;&#25968;&#25454;&#30340;&#32479;&#35745;&#20998;&#26512;&#24320;&#36767;&#20102;&#26032;&#36884;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12158v1 Announce Type: cross  Abstract: This study tackles the efficient estimation of Kullback-Leibler (KL) Divergence in Dirichlet Mixture Models (DMM), crucial for clustering compositional data. Despite the significance of DMMs, obtaining an analytically tractable solution for KL Divergence has proven elusive. Past approaches relied on computationally demanding Monte Carlo methods, motivating our introduction of a novel variational approach. Our method offers a closed-form solution, significantly enhancing computational efficiency for swift model comparisons and robust estimation evaluations. Validation using real and simulated data showcases its superior efficiency and accuracy over traditional Monte Carlo-based methods, opening new avenues for rapid exploration of diverse DMM models and advancing statistical analyses of compositional data.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#23558;&#31070;&#32463;&#32593;&#32476;&#34920;&#31034;&#20026;&#21442;&#25968;&#30340;&#35745;&#31639;&#22270;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#21644;&#21464;&#21387;&#22120;&#26469;&#23454;&#29616;&#32622;&#25442;&#23545;&#31216;&#24615;&#65292;&#20351;&#24471;&#21333;&#20010;&#27169;&#22411;&#33021;&#22815;&#22788;&#29702;&#20855;&#26377;&#22810;&#31181;&#26550;&#26500;&#30340;&#31070;&#32463;&#35745;&#31639;&#22270;&#12290;</title><link>https://arxiv.org/abs/2403.12143</link><description>&lt;p&gt;
&#29992;&#20110;&#23398;&#20064;&#31070;&#32463;&#32593;&#32476;&#31561;&#21464;&#34920;&#31034;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Networks for Learning Equivariant Representations of Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12143
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#23558;&#31070;&#32463;&#32593;&#32476;&#34920;&#31034;&#20026;&#21442;&#25968;&#30340;&#35745;&#31639;&#22270;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#21644;&#21464;&#21387;&#22120;&#26469;&#23454;&#29616;&#32622;&#25442;&#23545;&#31216;&#24615;&#65292;&#20351;&#24471;&#21333;&#20010;&#27169;&#22411;&#33021;&#22815;&#22788;&#29702;&#20855;&#26377;&#22810;&#31181;&#26550;&#26500;&#30340;&#31070;&#32463;&#35745;&#31639;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22788;&#29702;&#20854;&#20182;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#22312;&#35832;&#22914;&#20998;&#31867;&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#12289;&#29983;&#25104;&#31070;&#32463;&#32593;&#32476;&#26435;&#37325;&#21644;&#39044;&#27979;&#27867;&#21270;&#38169;&#35823;&#31561;&#39046;&#22495;&#20013;&#24471;&#21040;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#35201;&#20040;&#24573;&#35270;&#31070;&#32463;&#32593;&#32476;&#20013;&#22266;&#26377;&#30340;&#32622;&#25442;&#23545;&#31216;&#24615;&#65292;&#35201;&#20040;&#20381;&#36182;&#22797;&#26434;&#30340;&#26435;&#37325;&#20849;&#20139;&#27169;&#24335;&#26469;&#23454;&#29616;&#31561;&#21464;&#24615;&#65292;&#21516;&#26102;&#24573;&#30053;&#32593;&#32476;&#26550;&#26500;&#26412;&#36523;&#30340;&#24433;&#21709;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#23558;&#31070;&#32463;&#32593;&#32476;&#34920;&#31034;&#20026;&#21442;&#25968;&#30340;&#35745;&#31639;&#22270;&#65292;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#21033;&#29992;&#24378;&#22823;&#30340;&#20445;&#30041;&#32622;&#25442;&#23545;&#31216;&#24615;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#21644;&#21464;&#21387;&#22120;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#24471;&#21333;&#20010;&#27169;&#22411;&#33021;&#22815;&#23545;&#20855;&#26377;&#22810;&#26679;&#26550;&#26500;&#30340;&#31070;&#32463;&#35745;&#31639;&#22270;&#36827;&#34892;&#32534;&#30721;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21253;&#25324;&#20998;&#31867;&#21644;&#32534;&#36753;&#38544;&#24335;&#31070;&#32463;&#34920;&#31034;&#12289;&#39044;&#27979;&#27867;&#21270;&#38169;&#35823;&#31561;&#22810;&#31181;&#20219;&#21153;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12143v1 Announce Type: cross  Abstract: Neural networks that process the parameters of other neural networks find applications in domains as diverse as classifying implicit neural representations, generating neural network weights, and predicting generalization errors. However, existing approaches either overlook the inherent permutation symmetry in the neural network or rely on intricate weight-sharing patterns to achieve equivariance, while ignoring the impact of the network architecture itself. In this work, we propose to represent neural networks as computational graphs of parameters, which allows us to harness powerful graph neural networks and transformers that preserve permutation symmetry. Consequently, our approach enables a single model to encode neural computational graphs with diverse architectures. We showcase the effectiveness of our method on a wide range of tasks, including classification and editing of implicit neural representations, predicting generalizati
&lt;/p&gt;</description></item><item><title>DTOR&#26159;&#19968;&#31181;&#20915;&#31574;&#26641;&#24322;&#24120;&#20540;&#22238;&#24402;&#22120;&#65292;&#36890;&#36807;&#20272;&#35745;&#24322;&#24120;&#26816;&#27979;&#27169;&#22411;&#29983;&#25104;&#30340;&#24322;&#24120;&#20998;&#25968;&#26469;&#20135;&#29983;&#22522;&#20110;&#35268;&#21017;&#30340;&#35299;&#37322;&#65292;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#22823;&#37327;&#29305;&#24449;&#25968;&#25454;&#38598;&#12290;</title><link>https://arxiv.org/abs/2403.10903</link><description>&lt;p&gt;
DTOR&#65306;&#20915;&#31574;&#26641;&#24322;&#24120;&#20540;&#22238;&#24402;&#22120;&#29992;&#20110;&#35299;&#37322;&#24322;&#24120;
&lt;/p&gt;
&lt;p&gt;
DTOR: Decision Tree Outlier Regressor to explain anomalies
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10903
&lt;/p&gt;
&lt;p&gt;
DTOR&#26159;&#19968;&#31181;&#20915;&#31574;&#26641;&#24322;&#24120;&#20540;&#22238;&#24402;&#22120;&#65292;&#36890;&#36807;&#20272;&#35745;&#24322;&#24120;&#26816;&#27979;&#27169;&#22411;&#29983;&#25104;&#30340;&#24322;&#24120;&#20998;&#25968;&#26469;&#20135;&#29983;&#22522;&#20110;&#35268;&#21017;&#30340;&#35299;&#37322;&#65292;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#22823;&#37327;&#29305;&#24449;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35299;&#37322;&#24322;&#24120;&#20540;&#30340;&#20986;&#29616;&#20197;&#21450;&#20854;&#20135;&#29983;&#26426;&#21046;&#22312;&#21508;&#31181;&#39046;&#22495;&#20013;&#21487;&#33021;&#38750;&#24120;&#37325;&#35201;&#12290;&#25925;&#38556;&#12289;&#27450;&#35784;&#12289;&#23041;&#32961;&#31561;&#38382;&#39064;&#65292;&#38500;&#20102;&#34987;&#27491;&#30830;&#35782;&#21035;&#20043;&#22806;&#65292;&#36890;&#24120;&#38656;&#35201;&#26377;&#25928;&#30340;&#35299;&#37322;&#20197;&#26377;&#25928;&#25191;&#34892;&#21487;&#25805;&#20316;&#30340;&#23545;&#25239;&#25514;&#26045;&#12290;&#36234;&#26469;&#36234;&#24191;&#27867;&#22320;&#20351;&#29992;&#22797;&#26434;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#26469;&#35782;&#21035;&#24322;&#24120;&#20540;&#65292;&#20351;&#24471;&#36825;&#26679;&#30340;&#35299;&#37322;&#26356;&#20855;&#25361;&#25112;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20915;&#31574;&#26641;&#24322;&#24120;&#20540;&#22238;&#24402;&#22120;&#65288;DTOR&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#36890;&#36807;&#20272;&#35745;&#24322;&#24120;&#26816;&#27979;&#27169;&#22411;&#29983;&#25104;&#30340;&#24322;&#24120;&#20998;&#25968;&#26469;&#20026;&#21333;&#20010;&#25968;&#25454;&#28857;&#29983;&#25104;&#22522;&#20110;&#35268;&#21017;&#30340;&#35299;&#37322;&#30340;&#25216;&#26415;&#12290;&#36825;&#26159;&#36890;&#36807;&#39318;&#20808;&#24212;&#29992;&#20915;&#31574;&#26641;&#22238;&#24402;&#22120;&#26469;&#35745;&#31639;&#20272;&#35745;&#20998;&#25968;&#65292;&#28982;&#21518;&#25552;&#21462;&#19982;&#25968;&#25454;&#28857;&#20998;&#25968;&#30456;&#20851;&#32852;&#30340;&#30456;&#23545;&#36335;&#24452;&#26469;&#23454;&#29616;&#30340;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#21363;&#20351;&#22312;&#20855;&#26377;&#22823;&#37327;&#29305;&#24449;&#30340;&#25968;&#25454;&#38598;&#20013;&#65292;DTOR&#30340;&#40065;&#26834;&#24615;&#20063;&#24471;&#21040;&#20102;&#35777;&#23454;&#12290;&#27492;&#22806;&#65292;&#19982;&#20854;&#20182;&#22522;&#20110;&#35268;&#21017;&#30340;&#26041;&#27861;&#30456;&#27604;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10903v1 Announce Type: cross  Abstract: Explaining outliers occurrence and mechanism of their occurrence can be extremely important in a variety of domains. Malfunctions, frauds, threats, in addition to being correctly identified, oftentimes need a valid explanation in order to effectively perform actionable counteracts. The ever more widespread use of sophisticated Machine Learning approach to identify anomalies make such explanations more challenging. We present the Decision Tree Outlier Regressor (DTOR), a technique for producing rule-based explanations for individual data points by estimating anomaly scores generated by an anomaly detection model. This is accomplished by first applying a Decision Tree Regressor, which computes the estimation score, and then extracting the relative path associated with the data point score. Our results demonstrate the robustness of DTOR even in datasets with a large number of features. Additionally, in contrast to other rule-based approac
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#37327;&#21270;&#20102;&#32676;&#20307;&#19981;&#24179;&#34913;&#23545;&#26679;&#26412;&#22797;&#26434;&#24615;&#12289;&#25910;&#25947;&#36895;&#29575;&#21644;&#24179;&#22343;&#20197;&#21450;&#32676;&#20307;&#32423;&#27979;&#35797;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#39318;&#27425;&#25552;&#20379;&#20102;ERM&#22312;&#32676;&#20307;&#32423;&#27867;&#21270;&#30340;&#29702;&#35770;&#20998;&#26512;&#12290;</title><link>https://arxiv.org/abs/2403.07310</link><description>&lt;p&gt;
&#25512;&#21160;&#23569;&#25968;&#32676;&#20307;&#20221;&#39069;&#22914;&#20309;&#24433;&#21709;&#27867;&#21270;&#65311;&#20851;&#20110;&#19968;&#23618;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#22312;&#32676;&#20307;&#19981;&#24179;&#34913;&#19978;&#30340;&#29702;&#35770;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
How does promoting the minority fraction affect generalization? A theoretical study of the one-hidden-layer neural network on group imbalance
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07310
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#37327;&#21270;&#20102;&#32676;&#20307;&#19981;&#24179;&#34913;&#23545;&#26679;&#26412;&#22797;&#26434;&#24615;&#12289;&#25910;&#25947;&#36895;&#29575;&#21644;&#24179;&#22343;&#20197;&#21450;&#32676;&#20307;&#32423;&#27979;&#35797;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#39318;&#27425;&#25552;&#20379;&#20102;ERM&#22312;&#32676;&#20307;&#32423;&#27867;&#21270;&#30340;&#29702;&#35770;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32676;&#20307;&#19981;&#24179;&#34913;&#19968;&#30452;&#26159;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;ERM&#65289;&#20013;&#24050;&#30693;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#21462;&#24471;&#30340;&#39640;&#24179;&#22343;&#20934;&#30830;&#29575;&#20276;&#38543;&#30528;&#23569;&#25968;&#32676;&#20307;&#30340;&#20302;&#20934;&#30830;&#29575;&#12290;&#23613;&#31649;&#26377;&#31639;&#27861;&#21162;&#21147;&#25913;&#21892;&#23569;&#25968;&#32676;&#20307;&#30340;&#20934;&#30830;&#24615;&#65292;&#20294;&#20851;&#20110;ERM&#22312;&#21508;&#20010;&#32676;&#20307;&#19978;&#30340;&#29702;&#35770;&#27867;&#21270;&#20998;&#26512;&#20173;&#28982;&#38590;&#20197;&#23454;&#29616;&#12290;&#36890;&#36807;&#29992;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#34920;&#36798;&#32676;&#20307;&#19981;&#24179;&#34913;&#38382;&#39064;&#65292;&#26412;&#25991;&#37327;&#21270;&#20102;&#21508;&#20010;&#32676;&#20307;&#23545;&#26679;&#26412;&#22797;&#26434;&#24615;&#12289;&#25910;&#25947;&#36895;&#29575;&#20197;&#21450;&#24179;&#22343;&#21644;&#32676;&#20307;&#32423;&#27979;&#35797;&#24615;&#33021;&#30340;&#24433;&#21709;&#12290;&#34429;&#28982;&#25105;&#20204;&#30340;&#29702;&#35770;&#26694;&#26550;&#38598;&#20013;&#22312;&#20351;&#29992;&#19968;&#23618;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#20108;&#20998;&#31867;&#65292;&#20294;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#25105;&#20204;&#39318;&#27425;&#25552;&#20379;&#20102;ERM&#22312;&#32676;&#20307;&#32423;&#27867;&#21270;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#38500;&#20102;&#36890;&#24120;&#30740;&#31350;&#30340;&#24179;&#22343;&#27867;&#21270;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#30340;&#19968;&#20123;&#35265;&#35299;&#21253;&#25324;&#24403;&#25152;&#26377;&#32676;&#20307;&#32423;&#21327;&#26041;&#24046;&#37117;&#22312;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07310v1 Announce Type: cross  Abstract: Group imbalance has been a known problem in empirical risk minimization (ERM), where the achieved high average accuracy is accompanied by low accuracy in a minority group. Despite algorithmic efforts to improve the minority group accuracy, a theoretical generalization analysis of ERM on individual groups remains elusive. By formulating the group imbalance problem with the Gaussian Mixture Model, this paper quantifies the impact of individual groups on the sample complexity, the convergence rate, and the average and group-level testing performance. Although our theoretical framework is centered on binary classification using a one-hidden-layer neural network, to the best of our knowledge, we provide the first theoretical analysis of the group-level generalization of ERM in addition to the commonly studied average generalization performance. Sample insights of our theoretical results include that when all group-level co-variance is in th
&lt;/p&gt;</description></item><item><title>&#35777;&#26126;&#22312;1-D&#25968;&#25454;&#19978;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#31561;&#20215;&#20110;&#35299;&#20915;&#19968;&#20010;&#20855;&#26377;&#22266;&#23450;&#29305;&#24449;&#23383;&#20856;&#30697;&#38453;&#30340;&#20984;Lasso&#38382;&#39064;&#65292;&#20026;&#20840;&#23616;&#26368;&#20248;&#32593;&#32476;&#21644;&#35299;&#31354;&#38388;&#25552;&#20379;&#20102;&#27934;&#23519;&#12290;</title><link>https://arxiv.org/abs/2403.01046</link><description>&lt;p&gt;
&#19968;&#20010;&#38236;&#23376;&#30340;&#24211;&#65306;&#20302;&#32500;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26159;&#20855;&#26377;&#21453;&#23556;&#29305;&#24449;&#30340;&#20984;Lasso&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Library of Mirrors: Deep Neural Nets in Low Dimensions are Convex Lasso Models with Reflection Features
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.01046
&lt;/p&gt;
&lt;p&gt;
&#35777;&#26126;&#22312;1-D&#25968;&#25454;&#19978;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#31561;&#20215;&#20110;&#35299;&#20915;&#19968;&#20010;&#20855;&#26377;&#22266;&#23450;&#29305;&#24449;&#23383;&#20856;&#30697;&#38453;&#30340;&#20984;Lasso&#38382;&#39064;&#65292;&#20026;&#20840;&#23616;&#26368;&#20248;&#32593;&#32476;&#21644;&#35299;&#31354;&#38388;&#25552;&#20379;&#20102;&#27934;&#23519;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35777;&#26126;&#22312;1-D&#25968;&#25454;&#19978;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#31561;&#20215;&#20110;&#35299;&#20915;&#19968;&#20010;&#24102;&#26377;&#22266;&#23450;&#12289;&#26126;&#30830;&#23450;&#20041;&#30340;&#29305;&#24449;&#23383;&#20856;&#30697;&#38453;&#30340;&#20984;Lasso&#38382;&#39064;&#12290;&#20855;&#20307;&#30340;&#23383;&#20856;&#21462;&#20915;&#20110;&#28608;&#27963;&#20989;&#25968;&#21644;&#28145;&#24230;&#12290;&#25105;&#20204;&#32771;&#34385;&#20855;&#26377;&#20998;&#27573;&#32447;&#24615;&#28608;&#27963;&#20989;&#25968;&#30340;&#20004;&#23618;&#32593;&#32476;&#65292;&#28145;&#31364;&#30340;ReLU&#32593;&#32476;&#26368;&#22810;&#26377;4&#23618;&#65292;&#20197;&#21450;&#20855;&#26377;&#31526;&#21495;&#28608;&#27963;&#21644;&#20219;&#24847;&#28145;&#24230;&#30340;&#30697;&#24418;&#21644;&#26641;&#32593;&#32476;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#22312;ReLU&#32593;&#32476;&#20013;&#65292;&#31532;&#22235;&#23618;&#21019;&#24314;&#20195;&#34920;&#35757;&#32451;&#25968;&#25454;&#20851;&#20110;&#33258;&#36523;&#30340;&#21453;&#23556;&#30340;&#29305;&#24449;&#12290;Lasso&#34920;&#31034;&#27861;&#25581;&#31034;&#20102;&#20840;&#23616;&#26368;&#20248;&#32593;&#32476;&#21644;&#35299;&#31354;&#38388;&#30340;&#27934;&#23519;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.01046v1 Announce Type: cross  Abstract: We prove that training neural networks on 1-D data is equivalent to solving a convex Lasso problem with a fixed, explicitly defined dictionary matrix of features. The specific dictionary depends on the activation and depth. We consider 2-layer networks with piecewise linear activations, deep narrow ReLU networks with up to 4 layers, and rectangular and tree networks with sign activation and arbitrary depth. Interestingly in ReLU networks, a fourth layer creates features that represent reflections of training data about themselves. The Lasso representation sheds insight to globally optimal networks and the solution landscape.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#35843;&#21442;&#30340;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#21482;&#32473;&#20986;&#38382;&#39064;&#21442;&#25968;&#30340;&#31895;&#30053;&#25552;&#31034;&#30340;&#24773;&#20917;&#19979;&#65292;&#19982;&#26368;&#20248;&#35843;&#21442;&#20248;&#21270;&#31639;&#27861;&#30340;&#24615;&#33021;&#30456;&#21305;&#37197;&#12290;&#24182;&#19988;&#22312;&#26377;&#30028;&#30340;&#20248;&#21270;&#39046;&#22495;&#20013;&#35777;&#26126;&#20102;&#27492;&#31639;&#27861;&#30340;&#21487;&#34892;&#24615;&#65292;&#24182;&#25506;&#35752;&#20102;&#22312;&#26080;&#30028;&#22495;&#20013;&#30340;&#26465;&#20214;&#12290;</title><link>https://arxiv.org/abs/2402.07793</link><description>&lt;p&gt;
&#26080;&#35843;&#21442;&#30340;&#38543;&#26426;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Tuning-Free Stochastic Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07793
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#35843;&#21442;&#30340;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#21482;&#32473;&#20986;&#38382;&#39064;&#21442;&#25968;&#30340;&#31895;&#30053;&#25552;&#31034;&#30340;&#24773;&#20917;&#19979;&#65292;&#19982;&#26368;&#20248;&#35843;&#21442;&#20248;&#21270;&#31639;&#27861;&#30340;&#24615;&#33021;&#30456;&#21305;&#37197;&#12290;&#24182;&#19988;&#22312;&#26377;&#30028;&#30340;&#20248;&#21270;&#39046;&#22495;&#20013;&#35777;&#26126;&#20102;&#27492;&#31639;&#27861;&#30340;&#21487;&#34892;&#24615;&#65292;&#24182;&#25506;&#35752;&#20102;&#22312;&#26080;&#30028;&#22495;&#20013;&#30340;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20351;&#24471;&#35843;&#21442;&#30340;&#25104;&#26412;&#36234;&#26469;&#36234;&#39640;&#26114;&#12290;&#36825;&#23548;&#33268;&#20102;&#38656;&#35201;&#33021;&#22815;&#21363;&#26102;&#33258;&#25105;&#35843;&#25972;&#30340;&#31639;&#27861;&#30340;&#38656;&#27714;&#12290;&#25105;&#20204;&#23558;&#8220;&#26080;&#35843;&#21442;&#8221;&#31639;&#27861;&#30340;&#27010;&#24565;&#24418;&#24335;&#21270;&#65292;&#21363;&#21482;&#32473;&#20986;&#38382;&#39064;&#21442;&#25968;&#30340;&#31895;&#30053;&#25552;&#31034;&#21363;&#21487;&#19982;&#26368;&#20248;&#35843;&#21442;&#20248;&#21270;&#31639;&#27861;&#30340;&#24615;&#33021;&#30456;&#21305;&#37197;&#65292;&#35823;&#24046;&#20026;&#23545;&#25968;&#22810;&#39033;&#24335;&#22240;&#23376;&#12290;&#25105;&#20204;&#29305;&#21035;&#32771;&#34385;&#33021;&#22815;&#19982;&#26368;&#20248;&#35843;&#21442;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;(SGD)&#30456;&#21305;&#37197;&#30340;&#31639;&#27861;&#12290;&#24403;&#20248;&#21270;&#30340;&#22495;&#26159;&#26377;&#30028;&#30340;&#26102;&#20505;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#35843;&#21442;&#33258;&#30001;&#19982;SGD&#30340;&#21305;&#37197;&#26159;&#21487;&#33021;&#30340;&#65292;&#24182;&#19988;&#36890;&#36807;&#20960;&#20010;&#29616;&#26377;&#31639;&#27861;&#23454;&#29616;&#20102;&#36825;&#19968;&#28857;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#20248;&#21270;&#30340;&#22495;&#26159;&#26080;&#30028;&#30340;&#26102;&#20505;&#65292;&#23545;&#20110;&#26368;&#23567;&#21270;&#20984;&#24179;&#28369;&#25110;&#32773;Lipschitz&#20989;&#25968;&#30340;&#20219;&#21153;&#65292;&#26080;&#35843;&#21442;&#20248;&#21270;&#26159;&#19981;&#21487;&#33021;&#30340;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#22312;&#26080;&#30028;&#22495;&#20013;&#65292;&#20309;&#31181;&#24773;&#20917;&#19979;&#21487;&#20197;&#23454;&#29616;&#26080;&#35843;&#21442;&#20248;&#21270;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26368;&#36817;&#25552;&#20986;&#30340; DoG &#21644; DoWG &#31639;&#27861;&#22312;&#22122;&#22768;&#20998;&#24067;&#36275;&#22815;&#26102;&#26159;&#26080;&#35843;&#21442;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large-scale machine learning problems make the cost of hyperparameter tuning ever more prohibitive. This creates a need for algorithms that can tune themselves on-the-fly. We formalize the notion of "tuning-free" algorithms that can match the performance of optimally-tuned optimization algorithms up to polylogarithmic factors given only loose hints on the relevant problem parameters. We consider in particular algorithms that can match optimally-tuned Stochastic Gradient Descent (SGD). When the domain of optimization is bounded, we show tuning-free matching of SGD is possible and achieved by several existing algorithms. We prove that for the task of minimizing a convex and smooth or Lipschitz function over an unbounded domain, tuning-free optimization is impossible. We discuss conditions under which tuning-free optimization is possible even over unbounded domains. In particular, we show that the recently proposed DoG and DoWG algorithms are tuning-free when the noise distribution is suf
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21363;&#19968;&#33268;&#24615;&#33945;&#29305;&#21345;&#27931;&#20803;&#23398;&#20064;&#27169;&#22411;&#65292;&#29992;&#20110;&#39044;&#27979;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#12290;&#36890;&#36807;&#21033;&#29992;&#19968;&#33268;&#24615;&#39044;&#27979;&#31995;&#32479;&#12289;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#21644;CATE&#20803;&#23398;&#20064;&#27169;&#22411;&#65292;&#35813;&#26041;&#27861;&#29983;&#25104;&#21487;&#29992;&#20110;&#20010;&#24615;&#21270;&#20915;&#31574;&#30340;&#39044;&#27979;&#20998;&#24067;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#35813;&#26041;&#27861;&#22312;&#20445;&#25345;&#36739;&#23567;&#21306;&#38388;&#23485;&#24230;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#24378;&#22823;&#30340;&#23454;&#39564;&#35206;&#30422;&#33539;&#22260;&#65292;&#21487;&#20197;&#25552;&#20379;&#30495;&#23454;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#30340;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2402.04906</link><description>&lt;p&gt;
&#39044;&#27979;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#30340;&#19968;&#33268;&#24615;&#33945;&#29305;&#21345;&#27931;&#20803;&#23398;&#20064;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Conformal Monte Carlo Meta-learners for Predictive Inference of Individual Treatment Effects
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04906
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21363;&#19968;&#33268;&#24615;&#33945;&#29305;&#21345;&#27931;&#20803;&#23398;&#20064;&#27169;&#22411;&#65292;&#29992;&#20110;&#39044;&#27979;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#12290;&#36890;&#36807;&#21033;&#29992;&#19968;&#33268;&#24615;&#39044;&#27979;&#31995;&#32479;&#12289;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#21644;CATE&#20803;&#23398;&#20064;&#27169;&#22411;&#65292;&#35813;&#26041;&#27861;&#29983;&#25104;&#21487;&#29992;&#20110;&#20010;&#24615;&#21270;&#20915;&#31574;&#30340;&#39044;&#27979;&#20998;&#24067;&#12290;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;&#35813;&#26041;&#27861;&#22312;&#20445;&#25345;&#36739;&#23567;&#21306;&#38388;&#23485;&#24230;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#24378;&#22823;&#30340;&#23454;&#39564;&#35206;&#30422;&#33539;&#22260;&#65292;&#21487;&#20197;&#25552;&#20379;&#30495;&#23454;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#30340;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35748;&#35782;&#24178;&#39044;&#25928;&#26524;&#65292;&#21363;&#27835;&#30103;&#25928;&#26524;&#65292;&#23545;&#20110;&#20915;&#31574;&#33267;&#20851;&#37325;&#35201;&#12290;&#29992;&#26465;&#20214;&#24179;&#22343;&#27835;&#30103;&#25928;&#26524; (CATE) &#20272;&#35745;&#31561;&#26041;&#27861;&#36890;&#24120;&#21482;&#25552;&#20379;&#27835;&#30103;&#25928;&#26524;&#30340;&#28857;&#20272;&#35745;&#65292;&#32780;&#24120;&#24120;&#38656;&#35201;&#39069;&#22806;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#26041;&#27861;&#65292;&#21363;&#19968;&#33268;&#24615;&#33945;&#29305;&#21345;&#27931; (CMC) &#20803;&#23398;&#20064;&#27169;&#22411;&#65292;&#21033;&#29992;&#19968;&#33268;&#24615;&#39044;&#27979;&#31995;&#32479;&#12289;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#21644; CATE &#20803;&#23398;&#20064;&#27169;&#22411;&#65292;&#26469;&#20135;&#29983;&#21487;&#29992;&#20110;&#20010;&#24615;&#21270;&#20915;&#31574;&#30340;&#39044;&#27979;&#20998;&#24067;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#32467;&#26524;&#22122;&#22768;&#20998;&#24067;&#30340;&#29305;&#23450;&#20551;&#35774;&#22914;&#20309;&#20005;&#37325;&#24433;&#21709;&#36825;&#20123;&#19981;&#30830;&#23450;&#24615;&#39044;&#27979;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;CMC&#26694;&#26550;&#23637;&#31034;&#20102;&#24378;&#22823;&#30340;&#23454;&#39564;&#35206;&#30422;&#33539;&#22260;&#65292;&#21516;&#26102;&#20445;&#25345;&#36739;&#23567;&#30340;&#21306;&#38388;&#23485;&#24230;&#65292;&#20197;&#25552;&#20379;&#30495;&#23454;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#30340;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Knowledge of the effect of interventions, called the treatment effect, is paramount for decision-making. Approaches to estimating this treatment effect, e.g. by using Conditional Average Treatment Effect (CATE) estimators, often only provide a point estimate of this treatment effect, while additional uncertainty quantification is frequently desired instead. Therefore, we present a novel method, the Conformal Monte Carlo (CMC) meta-learners, leveraging conformal predictive systems, Monte Carlo sampling, and CATE meta-learners, to instead produce a predictive distribution usable in individualized decision-making. Furthermore, we show how specific assumptions on the noise distribution of the outcome heavily affect these uncertainty predictions. Nonetheless, the CMC framework shows strong experimental coverage while retaining small interval widths to provide estimates of the true individual treatment effect.
&lt;/p&gt;</description></item><item><title>GeoShapley&#26159;&#19968;&#31181;&#34913;&#37327;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#31354;&#38388;&#25928;&#24212;&#30340;&#21338;&#24328;&#35770;&#26041;&#27861;&#65292;&#23558;&#20301;&#32622;&#35270;&#20026;&#27169;&#22411;&#39044;&#27979;&#21338;&#24328;&#20013;&#30340;&#19968;&#21517;&#29609;&#23478;&#65292;&#33021;&#22815;&#37327;&#21270;&#20301;&#32622;&#30340;&#37325;&#35201;&#24615;&#24182;&#19982;&#20854;&#20182;&#29305;&#24449;&#20043;&#38388;&#30340;&#21327;&#21516;&#20316;&#29992;&#36827;&#34892;&#37327;&#21270;&#12290;</title><link>https://arxiv.org/abs/2312.03675</link><description>&lt;p&gt;
GeoShapley&#65306;&#19968;&#31181;&#34913;&#37327;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#31354;&#38388;&#25928;&#24212;&#30340;&#21338;&#24328;&#35770;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
GeoShapley: A Game Theory Approach to Measuring Spatial Effects in Machine Learning Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.03675
&lt;/p&gt;
&lt;p&gt;
GeoShapley&#26159;&#19968;&#31181;&#34913;&#37327;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#31354;&#38388;&#25928;&#24212;&#30340;&#21338;&#24328;&#35770;&#26041;&#27861;&#65292;&#23558;&#20301;&#32622;&#35270;&#20026;&#27169;&#22411;&#39044;&#27979;&#21338;&#24328;&#20013;&#30340;&#19968;&#21517;&#29609;&#23478;&#65292;&#33021;&#22815;&#37327;&#21270;&#20301;&#32622;&#30340;&#37325;&#35201;&#24615;&#24182;&#19982;&#20854;&#20182;&#29305;&#24449;&#20043;&#38388;&#30340;&#21327;&#21516;&#20316;&#29992;&#36827;&#34892;&#37327;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;GeoShapley&#65292;&#36825;&#26159;&#19968;&#31181;&#34913;&#37327;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#31354;&#38388;&#25928;&#24212;&#30340;&#21338;&#24328;&#35770;&#26041;&#27861;&#12290;GeoShapley&#36890;&#36807;&#23558;&#20301;&#32622;&#27010;&#24565;&#21270;&#20026;&#27169;&#22411;&#39044;&#27979;&#21338;&#24328;&#20013;&#30340;&#19968;&#21517;&#29609;&#23478;&#65292;&#25193;&#23637;&#20102;&#21338;&#24328;&#35770;&#20013;&#30340;Nobel Prize-winning Shapley&#20540;&#26694;&#26550;&#65292;&#20174;&#32780;&#20351;&#24471;&#21487;&#20197;&#37327;&#21270;&#20301;&#32622;&#30340;&#37325;&#35201;&#24615;&#20197;&#21450;&#20301;&#32622;&#19982;&#27169;&#22411;&#20013;&#20854;&#20182;&#29305;&#24449;&#20043;&#38388;&#30340;&#21327;&#21516;&#20316;&#29992;&#12290;GeoShapley&#26159;&#19968;&#31181;&#19982;&#27169;&#22411;&#26080;&#20851;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#19981;&#21516;&#32467;&#26500;&#30340;&#32479;&#35745;&#23398;&#25110;&#40657;&#30418;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#12290;GeoShapley&#30340;&#35299;&#37322;&#30452;&#25509;&#19982;&#29992;&#20110;&#35299;&#37322;&#31354;&#38388;&#25928;&#24212;&#30340;&#31354;&#38388;&#21464;&#21270;&#31995;&#25968;&#27169;&#22411;&#20197;&#21450;&#29992;&#20110;&#35299;&#37322;&#38750;&#31354;&#38388;&#25928;&#24212;&#30340;&#21152;&#27861;&#27169;&#22411;&#30456;&#36830;&#12290;&#21033;&#29992;&#27169;&#25311;&#25968;&#25454;&#65292;&#39564;&#35777;&#20102;GeoShapley&#20540;&#19982;&#24050;&#30693;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#29992;&#20110;&#23545;&#27604;&#19971;&#31181;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#12290;&#36890;&#36807;&#25151;&#20215;&#24314;&#27169;&#30340;&#23454;&#35777;&#31034;&#20363;&#26469;&#35828;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.03675v2 Announce Type: replace  Abstract: This paper introduces GeoShapley, a game theory approach to measuring spatial effects in machine learning models. GeoShapley extends the Nobel Prize-winning Shapley value framework in game theory by conceptualizing location as a player in a model prediction game, which enables the quantification of the importance of location and the synergies between location and other features in a model. GeoShapley is a model-agnostic approach and can be applied to statistical or black-box machine learning models in various structures. The interpretation of GeoShapley is directly linked with spatially varying coefficient models for explaining spatial effects and additive models for explaining non-spatial effects. Using simulated data, GeoShapley values are validated against known data-generating processes and are used for cross-comparison of seven statistical and machine learning models. An empirical example of house price modeling is used to illus
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#21151;&#33021;&#36125;&#21494;&#26031; Tucker &#20998;&#35299;&#65288;FunBaT&#65289;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#23558; Tucker &#20998;&#35299;&#25512;&#24191;&#21040;&#36830;&#32493;&#32034;&#24341;&#30340;&#24352;&#37327;&#25968;&#25454;&#65292;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#28508;&#22312;&#20989;&#25968;&#12290;</title><link>https://arxiv.org/abs/2311.04829</link><description>&lt;p&gt;
&#36830;&#32493;&#32034;&#24341;&#24352;&#37327;&#25968;&#25454;&#30340;&#21151;&#33021;&#36125;&#21494;&#26031; Tucker &#20998;&#35299;
&lt;/p&gt;
&lt;p&gt;
Functional Bayesian Tucker Decomposition for Continuous-indexed Tensor Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.04829
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#21151;&#33021;&#36125;&#21494;&#26031; Tucker &#20998;&#35299;&#65288;FunBaT&#65289;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#23558; Tucker &#20998;&#35299;&#25512;&#24191;&#21040;&#36830;&#32493;&#32034;&#24341;&#30340;&#24352;&#37327;&#25968;&#25454;&#65292;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#28508;&#22312;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Tucker &#20998;&#35299;&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#24352;&#37327;&#27169;&#22411;&#65292;&#29992;&#20110;&#22788;&#29702;&#22810;&#26041;&#38754;&#25968;&#25454;&#12290;&#23427;&#36890;&#36807;&#23558;&#32593;&#26684;&#32467;&#26500;&#25968;&#25454;&#20998;&#35299;&#20026;&#26680;&#24352;&#37327;&#21644;&#19968;&#32452;&#23545;&#35937;&#34920;&#31034;&#65288;&#22240;&#23376;&#65289;&#20043;&#38388;&#30340;&#20132;&#20114;&#26469;&#23637;&#31034;&#20302;&#31209;&#29305;&#24615;&#12290;&#36825;&#31181;&#20998;&#35299;&#30340;&#19968;&#20010;&#22522;&#26412;&#20551;&#35774;&#26159;&#27599;&#20010;&#26041;&#38754;&#25110;&#27169;&#24335;&#20013;&#37117;&#26377;&#26377;&#38480;&#30340;&#23545;&#35937;&#65292;&#23545;&#24212;&#20110;&#25968;&#25454;&#26465;&#30446;&#30340;&#31163;&#25955;&#32034;&#24341;&#12290;&#28982;&#32780;&#65292;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#25968;&#25454;&#24448;&#24448;&#24182;&#38750;&#33258;&#28982;&#22320;&#21576;&#29616;&#22312;&#36825;&#31181;&#35774;&#32622;&#20013;&#12290;&#20363;&#22914;&#65292;&#22320;&#29702;&#25968;&#25454;&#20197;&#32428;&#24230;&#21644;&#32463;&#24230;&#22352;&#26631;&#30340;&#36830;&#32493;&#32034;&#24341;&#34920;&#31034;&#65292;&#26080;&#27861;&#30452;&#25509;&#36866;&#24212;&#24352;&#37327;&#27169;&#22411;&#12290;&#20026;&#20102;&#23558; Tucker &#20998;&#35299;&#25512;&#24191;&#21040;&#36825;&#31181;&#22330;&#26223;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21151;&#33021;&#36125;&#21494;&#26031; Tucker &#20998;&#35299;&#65288;FunBaT&#65289;&#12290;&#25105;&#20204;&#23558;&#36830;&#32493;&#32034;&#24341;&#25968;&#25454;&#35270;&#20026; Tucker &#26680;&#24515;&#21644;&#19968;&#32452;&#28508;&#22312;&#20989;&#25968;&#20043;&#38388;&#30340;&#20132;&#20114;&#12290;&#25105;&#20204;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#20316;&#20026;&#21151;&#33021;&#20808;&#39564;&#26469;&#24314;&#27169;&#28508;&#22312;&#20989;&#25968;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#27599;&#20010;&#39640;&#26031;&#36807;&#31243;&#36716;&#25442;&#20026;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.04829v2 Announce Type: replace  Abstract: Tucker decomposition is a powerful tensor model to handle multi-aspect data. It demonstrates the low-rank property by decomposing the grid-structured data as interactions between a core tensor and a set of object representations (factors). A fundamental assumption of such decomposition is that there are finite objects in each aspect or mode, corresponding to discrete indexes of data entries. However, real-world data is often not naturally posed in this setting. For example, geographic data is represented as continuous indexes of latitude and longitude coordinates, and cannot fit tensor models directly. To generalize Tucker decomposition to such scenarios, we propose Functional Bayesian Tucker Decomposition (FunBaT). We treat the continuous-indexed data as the interaction between the Tucker core and a group of latent functions. We use Gaussian processes (GP) as functional priors to model the latent functions. Then, we convert each GP 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#39318;&#27425;&#30740;&#31350;&#20102;&#22312;&#26410;&#30693;&#21709;&#24212;&#19979;&#19968;&#27425;&#24615;&#31574;&#30053;&#20998;&#31867;&#30340;&#24773;&#26223;&#65292;&#38024;&#23545;&#29992;&#25143;&#25104;&#26412;&#20989;&#25968;&#19981;&#30830;&#23450;&#24615;&#65292;&#25552;&#20986;&#35299;&#20915;&#26041;&#26696;&#24182;&#23558;&#20219;&#21153;&#23450;&#20041;&#20026;&#26497;&#23567;-&#26497;&#22823;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2311.02761</link><description>&lt;p&gt;
&#19968;&#27425;&#24615;&#31574;&#30053;&#20998;&#31867;&#22312;&#26410;&#30693;&#25104;&#26412;&#19979;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
One-Shot Strategic Classification Under Unknown Costs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.02761
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#39318;&#27425;&#30740;&#31350;&#20102;&#22312;&#26410;&#30693;&#21709;&#24212;&#19979;&#19968;&#27425;&#24615;&#31574;&#30053;&#20998;&#31867;&#30340;&#24773;&#26223;&#65292;&#38024;&#23545;&#29992;&#25143;&#25104;&#26412;&#20989;&#25968;&#19981;&#30830;&#23450;&#24615;&#65292;&#25552;&#20986;&#35299;&#20915;&#26041;&#26696;&#24182;&#23558;&#20219;&#21153;&#23450;&#20041;&#20026;&#26497;&#23567;-&#26497;&#22823;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31574;&#30053;&#20998;&#31867;&#30340;&#30446;&#26631;&#26159;&#23398;&#20064;&#23545;&#31574;&#30053;&#36755;&#20837;&#25805;&#32437;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#20915;&#31574;&#35268;&#21017;&#12290;&#20043;&#21069;&#30340;&#30740;&#31350;&#20551;&#35774;&#36825;&#20123;&#21709;&#24212;&#26159;&#24050;&#30693;&#30340;&#65307;&#32780;&#26368;&#36817;&#30340;&#19968;&#20123;&#30740;&#31350;&#22788;&#29702;&#26410;&#30693;&#21709;&#24212;&#65292;&#20294;&#23427;&#20204;&#19987;&#38376;&#30740;&#31350;&#37325;&#22797;&#27169;&#22411;&#37096;&#32626;&#30340;&#22312;&#32447;&#35774;&#32622;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#39046;&#22495;&#65292;&#29305;&#21035;&#26159;&#22312;&#20844;&#20849;&#25919;&#31574;&#20013;&#65292;&#19968;&#20010;&#24120;&#35265;&#30340;&#28608;&#21169;&#29992;&#20363;&#20013;&#65292;&#22810;&#27425;&#37096;&#32626;&#26159;&#19981;&#21487;&#34892;&#30340;&#65292;&#29978;&#33267;&#19968;&#20010;&#31967;&#31957;&#30340;&#36718;&#27425;&#37117;&#26159;&#19981;&#21487;&#25509;&#21463;&#30340;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#39318;&#27425;&#24341;&#20837;&#20102;&#22312;&#26410;&#30693;&#21709;&#24212;&#19979;&#30340;&#19968;&#27425;&#24615;&#31574;&#30053;&#20998;&#31867;&#30340;&#27491;&#24335;&#30740;&#31350;&#65292;&#36825;&#38656;&#35201;&#22312;&#19968;&#27425;&#24615;&#36873;&#25321;&#19968;&#20010;&#20998;&#31867;&#22120;&#12290;&#30528;&#37325;&#20851;&#27880;&#29992;&#25143;&#25104;&#26412;&#20989;&#25968;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#23545;&#20110;&#19968;&#31867;&#24191;&#27867;&#30340;&#25104;&#26412;&#65292;&#21363;&#20351;&#23545;&#30495;&#23454;&#25104;&#26412;&#30340;&#23567;&#35823;&#24046;&#20063;&#21487;&#33021;&#22312;&#26368;&#22351;&#24773;&#20917;&#19979;&#23548;&#33268;&#20934;&#30830;&#24615;&#38477;&#33267;&#26497;&#20302;&#27700;&#24179;&#12290;&#37492;&#20110;&#27492;&#65292;&#25105;&#20204;&#23558;&#20219;&#21153;&#26694;&#23450;&#20026;&#26497;&#23567;-&#26497;&#22823;&#38382;&#39064;&#65292;&#30446;&#26631;&#26159;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.02761v2 Announce Type: replace  Abstract: The goal of strategic classification is to learn decision rules which are robust to strategic input manipulation. Earlier works assume that these responses are known; while some recent works handle unknown responses, they exclusively study online settings with repeated model deployments. But there are many domains$\unicode{x2014}$particularly in public policy, a common motivating use case$\unicode{x2014}$where multiple deployments are infeasible, or where even one bad round is unacceptable. To address this gap, we initiate the formal study of one-shot strategic classification under unknown responses, which requires committing to a single classifier once. Focusing on uncertainty in the users' cost function, we begin by proving that for a broad class of costs, even a small mis-estimation of the true cost can entail trivial accuracy in the worst case. In light of this, we frame the task as a minimax problem, with the goal of identifying
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#24191;&#20041;&#25324;&#21495;&#25968;&#30340;&#27010;&#24565;&#65292;&#32467;&#21512;&#23545;&#25163;&#30340;&#32422;&#26463;&#19982;&#31354;&#38388;&#22823;&#23567;&#65292;&#36890;&#36807;Follow-the-Perturbed-Leader&#31639;&#27861;&#23454;&#29616;&#20302;&#36951;&#25022;&#65292;&#20248;&#21270;&#35843;&#29992;&#20248;&#21270;Oracle&#30340;&#27425;&#25968;&#20197;&#23454;&#29616;&#36951;&#25022;&#22312;&#22810;&#20010;&#38382;&#39064;&#20013;&#30340;&#26377;&#25928;&#24212;&#29992;&#12290;</title><link>https://arxiv.org/abs/2302.05430</link><description>&lt;p&gt;
&#38024;&#23545;&#20998;&#27573;&#36830;&#32493;&#20915;&#31574;&#21046;&#23450;&#30340;Oracle&#39640;&#25928;&#24179;&#28369;&#22312;&#32447;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Oracle-Efficient Smoothed Online Learning for Piecewise Continuous Decision Making
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2302.05430
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#24191;&#20041;&#25324;&#21495;&#25968;&#30340;&#27010;&#24565;&#65292;&#32467;&#21512;&#23545;&#25163;&#30340;&#32422;&#26463;&#19982;&#31354;&#38388;&#22823;&#23567;&#65292;&#36890;&#36807;Follow-the-Perturbed-Leader&#31639;&#27861;&#23454;&#29616;&#20302;&#36951;&#25022;&#65292;&#20248;&#21270;&#35843;&#29992;&#20248;&#21270;Oracle&#30340;&#27425;&#25968;&#20197;&#23454;&#29616;&#36951;&#25022;&#22312;&#22810;&#20010;&#38382;&#39064;&#20013;&#30340;&#26377;&#25928;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24179;&#28369;&#22312;&#32447;&#23398;&#20064;&#24050;&#32463;&#25104;&#20026;&#19968;&#31181;&#27969;&#34892;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#32531;&#35299;&#22312;&#20174;&#32463;&#20856;&#23398;&#20064;&#36716;&#21521;&#23545;&#25239;&#24615;&#23398;&#20064;&#26102;&#20135;&#29983;&#30340;&#32479;&#35745;&#21644;&#35745;&#31639;&#22797;&#26434;&#24615;&#30340;&#26174;&#33879;&#25439;&#22833;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#22797;&#26434;&#24615;&#27010;&#24565;&#65292;&#21363;&#24191;&#20041;&#25324;&#21495;&#25968;&#65292;&#23558;&#23545;&#25163;&#30340;&#32422;&#26463;&#19982;&#31354;&#38388;&#22823;&#23567;&#30456;&#32467;&#21512;&#65292;&#24182;&#23637;&#31034;&#20102;&#19968;&#20010;Follow-the-Perturbed-Leader&#23454;&#20363;&#21487;&#20197;&#23454;&#29616;&#20302;&#36951;&#25022;&#65292;&#24182;&#19988;&#20248;&#21270;&#35843;&#29992;&#20248;&#21270;Oracle&#30340;&#27425;&#25968;&#20197;&#23454;&#29616;&#24179;&#22343;&#36951;&#25022;&#30340;&#26368;&#20339;&#32553;&#25918;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2302.05430v2 Announce Type: replace-cross  Abstract: Smoothed online learning has emerged as a popular framework to mitigate the substantial loss in statistical and computational complexity that arises when one moves from classical to adversarial learning. Unfortunately, for some spaces, it has been shown that efficient algorithms suffer an exponentially worse regret than that which is minimax optimal, even when the learner has access to an optimization oracle over the space. To mitigate that exponential dependence, this work introduces a new notion of complexity, the generalized bracketing numbers, which marries constraints on the adversary to the size of the space, and shows that an instantiation of Follow-the-Perturbed-Leader can attain low regret with the number of calls to the optimization oracle scaling optimally with respect to average regret. We then instantiate our bounds in several problems of interest, including online prediction and planning of piecewise continuous fu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#24179;&#28369;&#22312;&#32447;&#23398;&#20064;&#26694;&#26550;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#22788;&#29702;&#20998;&#27573;&#20223;&#23556;&#31995;&#32479;&#20013;&#30340;&#39044;&#27979;&#21644;&#27169;&#25311;&#38382;&#39064;&#65292;&#22312;&#24369;&#20809;&#28369;&#24615;&#20551;&#35774;&#19979;&#20855;&#26377;&#22810;&#39033;&#24335;&#36951;&#25022;&#24230;&#65292;&#24182;&#19988;&#22312;&#35843;&#29992;&#20248;&#21270;&#39044;&#27979;&#27425;&#25968;&#26041;&#38754;&#26159;&#39640;&#25928;&#30340;&#12290;</title><link>https://arxiv.org/abs/2301.11187</link><description>&lt;p&gt;
&#24179;&#28369;&#22312;&#32447;&#23398;&#20064;&#29992;&#20110;&#20998;&#27573;&#20223;&#23556;&#31995;&#32479;&#20013;&#30340;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Smoothed Online Learning for Prediction in Piecewise Affine Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2301.11187
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#24179;&#28369;&#22312;&#32447;&#23398;&#20064;&#26694;&#26550;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#22788;&#29702;&#20998;&#27573;&#20223;&#23556;&#31995;&#32479;&#20013;&#30340;&#39044;&#27979;&#21644;&#27169;&#25311;&#38382;&#39064;&#65292;&#22312;&#24369;&#20809;&#28369;&#24615;&#20551;&#35774;&#19979;&#20855;&#26377;&#22810;&#39033;&#24335;&#36951;&#25022;&#24230;&#65292;&#24182;&#19988;&#22312;&#35843;&#29992;&#20248;&#21270;&#39044;&#27979;&#27425;&#25968;&#26041;&#38754;&#26159;&#39640;&#25928;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#27573;&#20223;&#23556;&#65288;PWA&#65289;&#22238;&#24402;&#21644;&#35268;&#21010;&#38382;&#39064;&#23545;&#20110;&#22312;&#32447;&#23398;&#20064;&#12289;&#25511;&#21046;&#21644;&#26426;&#22120;&#20154;&#23398;&#30340;&#30740;&#31350;&#20855;&#26377;&#22522;&#30784;&#37325;&#35201;&#24615;&#65292;&#23427;&#20026;&#30740;&#31350;&#31995;&#32479;&#21160;&#24577;&#21457;&#29983;&#24613;&#21095;&#21464;&#21270;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#19978;&#21644;&#23454;&#35777;&#19978;&#21487;&#22788;&#29702;&#30340;&#35774;&#32622;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#31359;&#36234;&#19981;&#21516;&#8220;&#29255;&#27573;&#8221;&#26102;&#20986;&#29616;&#30340;&#19981;&#36830;&#32493;&#24615;&#65292;&#23398;&#20064;&#22312;&#19968;&#33324;&#30340;&#39034;&#24207;&#35774;&#32622;&#20013;&#26159;&#19981;&#21487;&#33021;&#30340;&#65292;&#23454;&#38469;&#31639;&#27861;&#34987;&#36843;&#37319;&#29992;&#21551;&#21457;&#24335;&#26041;&#27861;&#12290;&#26412;&#25991;&#22312;&#26368;&#36817;&#24320;&#21457;&#30340;&#24179;&#28369;&#22312;&#32447;&#23398;&#20064;&#26694;&#26550;&#22522;&#30784;&#19978;&#26500;&#24314;&#65292;&#24182;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#22312;&#24369;&#20809;&#28369;&#24615;&#20551;&#35774;&#19979;&#65292;&#20855;&#26377;&#22810;&#39033;&#24335;&#36951;&#25022;&#24230;&#24182;&#19988;&#22312;&#20248;&#21270;&#39044;&#27979;&#20013;&#39640;&#25928;&#30340;PWA&#31995;&#32479;&#39044;&#27979;&#21644;&#27169;&#25311;&#31639;&#27861;&#65307;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#32467;&#26524;&#24212;&#29992;&#21040;&#19968;&#27493;&#39044;&#27979;&#21644;&#22810;&#27493;&#27169;&#25311;&#36951;&#25022;&#38382;&#39064;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2301.11187v2 Announce Type: replace-cross  Abstract: The problem of piecewise affine (PWA) regression and planning is of foundational importance to the study of online learning, control, and robotics, where it provides a theoretically and empirically tractable setting to study systems undergoing sharp changes in the dynamics. Unfortunately, due to the discontinuities that arise when crossing into different ``pieces,'' learning in general sequential settings is impossible and practical algorithms are forced to resort to heuristic approaches. This paper builds on the recently developed smoothed online learning framework and provides the first algorithms for prediction and simulation in PWA systems whose regret is polynomial in all relevant problem parameters under a weak smoothness assumption; moreover, our algorithms are efficient in the number of calls to an optimization oracle. We further apply our results to the problems of one-step prediction and multi-step simulation regret i
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#21033;&#29992;&#22343;&#22330;&#31070;&#32463;&#32593;&#32476;&#31867;&#35299;&#20915;McKean-Vlasov&#25511;&#21046;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#22810;&#31181;&#31639;&#27861;&#65292;&#24182;&#22312;&#19981;&#21516;&#31034;&#20363;&#19978;&#23637;&#31034;&#20102;&#25968;&#20540;&#32467;&#26524;&#65292;&#35752;&#35770;&#27604;&#36739;&#20102;&#21508;&#31181;&#26041;&#27861;&#30340;&#20248;&#32570;&#28857;&#12290;</title><link>https://arxiv.org/abs/2212.11518</link><description>&lt;p&gt;
&#22522;&#20110;&#22343;&#22330;&#31070;&#32463;&#32593;&#32476;&#30340;McKean-Vlasov&#25511;&#21046;&#38382;&#39064;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Mean-field neural networks-based algorithms for McKean-Vlasov control problems *
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2212.11518
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#21033;&#29992;&#22343;&#22330;&#31070;&#32463;&#32593;&#32476;&#31867;&#35299;&#20915;McKean-Vlasov&#25511;&#21046;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#22810;&#31181;&#31639;&#27861;&#65292;&#24182;&#22312;&#19981;&#21516;&#31034;&#20363;&#19978;&#23637;&#31034;&#20102;&#25968;&#20540;&#32467;&#26524;&#65292;&#35752;&#35770;&#27604;&#36739;&#20102;&#21508;&#31181;&#26041;&#27861;&#30340;&#20248;&#32570;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#33268;&#21147;&#20110;&#36890;&#36807;&#25105;&#20204;&#22312;&#20276;&#38543;&#35770;&#25991;[25]&#20013;&#24341;&#20837;&#30340;&#22343;&#22330;&#31070;&#32463;&#32593;&#32476;&#31867;&#65292;&#23545;McKean-Vlasov&#25511;&#21046;&#38382;&#39064;&#36827;&#34892;&#25968;&#20540;&#35299;&#26512;&#65292;&#20197;&#20415;&#22312;Wasserstein&#31354;&#38388;&#19978;&#23398;&#20064;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20960;&#31181;&#31639;&#27861;&#65292;&#22522;&#20110;&#25511;&#21046;&#23398;&#20064;&#31574;&#30053;&#25110;&#20540;&#36845;&#20195;&#30340;&#21160;&#24577;&#35268;&#21010;&#65292;&#25110;&#32773;&#22522;&#20110;&#38543;&#26426;&#26368;&#22823;&#21407;&#29702;&#21644;&#20840;&#23616;&#25110;&#23616;&#37096;&#25439;&#22833;&#20989;&#25968;&#30340;&#21453;&#21521;SDE&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#23545;&#19981;&#21516;&#31034;&#20363;&#30340;&#22823;&#37327;&#25968;&#20540;&#32467;&#26524;&#65292;&#20197;&#35828;&#26126;&#25105;&#20204;&#30340;&#20843;&#31181;&#31639;&#27861;&#27599;&#19968;&#31181;&#30340;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#35752;&#35770;&#24182;&#27604;&#36739;&#20102;&#25152;&#26377;&#27979;&#35797;&#26041;&#27861;&#30340;&#20248;&#32570;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2212.11518v2 Announce Type: replace-cross  Abstract: This paper is devoted to the numerical resolution of McKean-Vlasov control problems via the class of mean-field neural networks introduced in our companion paper [25] in order to learn the solution on the Wasserstein space. We propose several algorithms either based on dynamic programming with control learning by policy or value iteration, or backward SDE from stochastic maximum principle with global or local loss functions. Extensive numerical results on different examples are presented to illustrate the accuracy of each of our eight algorithms. We discuss and compare the pros and cons of all the tested methods.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#22810;&#30446;&#26631;&#26799;&#24230;&#26657;&#27491;&#65288;MoCo&#65289;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#19981;&#22686;&#21152;&#25209;&#37327;&#22823;&#23567;&#30340;&#24773;&#20917;&#19979;&#20445;&#35777;&#25910;&#25947;&#65292;&#35299;&#20915;&#20102;&#22810;&#30446;&#26631;&#23398;&#20064;&#20013;&#26799;&#24230;&#20559;&#24046;&#23548;&#33268;&#24615;&#33021;&#19979;&#38477;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2210.12624</link><description>&lt;p&gt;
&#32531;&#35299;&#22810;&#30446;&#26631;&#23398;&#20064;&#20013;&#30340;&#26799;&#24230;&#20559;&#24046;&#65306;&#19968;&#31181;&#21487;&#35777;&#26126;&#25910;&#25947;&#30340;&#38543;&#26426;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Mitigating Gradient Bias in Multi-objective Learning: A Provably Convergent Stochastic Approach
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2210.12624
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#22810;&#30446;&#26631;&#26799;&#24230;&#26657;&#27491;&#65288;MoCo&#65289;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#19981;&#22686;&#21152;&#25209;&#37327;&#22823;&#23567;&#30340;&#24773;&#20917;&#19979;&#20445;&#35777;&#25910;&#25947;&#65292;&#35299;&#20915;&#20102;&#22810;&#30446;&#26631;&#23398;&#20064;&#20013;&#26799;&#24230;&#20559;&#24046;&#23548;&#33268;&#24615;&#33021;&#19979;&#38477;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20855;&#26377;&#22810;&#20010;&#30446;&#26631;&#20989;&#25968;&#30340;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#36890;&#24120;&#20986;&#29616;&#22312;&#38656;&#35201;&#22312;&#22810;&#20010;&#24615;&#33021;&#25351;&#26631;&#65288;&#22914;&#20844;&#24179;&#24615;&#65292;&#23433;&#20840;&#24615;&#21644;&#20934;&#30830;&#24615;&#65289;&#20043;&#38388;&#36827;&#34892;&#26435;&#34913;&#30340;&#22810;&#30446;&#26631;&#23398;&#20064;&#20013;&#65307;&#25110;&#32773;&#22312;&#22810;&#20219;&#21153;&#23398;&#20064;&#20013;&#65292;&#22810;&#20010;&#20219;&#21153;&#32852;&#21512;&#20248;&#21270;&#65292;&#20849;&#20139;&#23427;&#20204;&#20043;&#38388;&#30340;&#24402;&#32435;&#20559;&#24046;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#38543;&#26426;&#22810;&#30446;&#26631;&#26799;&#24230;&#26041;&#27861;&#21450;&#20854;&#21464;&#20307;&#65288;&#20363;&#22914;&#65292;MGDA&#65292;PCGrad&#65292;CAGrad&#31561;&#65289;&#37117;&#37319;&#29992;&#24102;&#20559;&#24046;&#30340;&#22122;&#22768;&#26799;&#24230;&#26041;&#21521;&#65292;&#23548;&#33268;&#32463;&#39564;&#24615;&#33021;&#19979;&#38477;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#29992;&#20110;&#22810;&#30446;&#26631;&#20248;&#21270;&#30340;&#38543;&#26426;&#22810;&#30446;&#26631;&#26799;&#24230;&#26657;&#27491;&#65288;MoCo&#65289;&#26041;&#27861;&#12290;&#25105;&#20204;&#26041;&#27861;&#30340;&#29420;&#29305;&#20043;&#22788;&#22312;&#20110;&#65292;&#21363;&#20351;&#22312;&#38750;&#20984;&#35774;&#32622;&#20013;&#20063;&#33021;&#20445;&#35777;&#25910;&#25947;&#32780;&#19981;&#22686;&#21152;&#25209;&#37327;&#22823;&#23567;&#12290;&#23545;&#22810;&#20219;&#21153;&#30417;&#30563;&#23398;&#20064;&#21644;&#24378;&#21270;&#23398;&#20064;&#36827;&#34892;&#20102;&#27169;&#25311;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2210.12624v2 Announce Type: replace  Abstract: Machine learning problems with multiple objective functions appear either in learning with multiple criteria where learning has to make a trade-off between multiple performance metrics such as fairness, safety and accuracy; or, in multi-task learning where multiple tasks are optimized jointly, sharing inductive bias between them. This problems are often tackled by the multi-objective optimization framework. However, existing stochastic multi-objective gradient methods and its variants (e.g., MGDA, PCGrad, CAGrad, etc.) all adopt a biased noisy gradient direction, which leads to degraded empirical performance. To this end, we develop a stochastic Multi-objective gradient Correction (MoCo) method for multi-objective optimization. The unique feature of our method is that it can guarantee convergence without increasing the batch size even in the non-convex setting. Simulations on multi-task supervised and reinforcement learning demonstra
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#19982;&#26368;&#26032;&#30340;&#20915;&#31574;&#29702;&#35770;&#27169;&#22411;&#30456;&#32467;&#21512;&#30340;&#40065;&#26834;&#20248;&#21270;&#20934;&#21017;&#65292;&#36890;&#36807;&#36825;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#20013;&#33719;&#24471;&#26377;&#31283;&#23450;&#24615;&#21644;&#20248;&#36234;&#24615;&#33021;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2401.15771</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#19982;&#25968;&#25454;&#39537;&#21160;&#40065;&#26834;&#20248;&#21270;&#30340;&#32467;&#21512;
&lt;/p&gt;
&lt;p&gt;
Bayesian Nonparametrics meets Data-Driven Robust Optimization. (arXiv:2401.15771v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.15771
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#19982;&#26368;&#26032;&#30340;&#20915;&#31574;&#29702;&#35770;&#27169;&#22411;&#30456;&#32467;&#21512;&#30340;&#40065;&#26834;&#20248;&#21270;&#20934;&#21017;&#65292;&#36890;&#36807;&#36825;&#31181;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#20013;&#33719;&#24471;&#26377;&#31283;&#23450;&#24615;&#21644;&#20248;&#36234;&#24615;&#33021;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#27169;&#22411;&#36890;&#24120;&#28041;&#21450;&#20248;&#21270;&#25968;&#25454;&#39537;&#21160;&#30340;&#39118;&#38505;&#20934;&#21017;&#12290;&#39118;&#38505;&#36890;&#24120;&#26159;&#26681;&#25454;&#32463;&#39564;&#25968;&#25454;&#20998;&#24067;&#35745;&#31639;&#30340;&#65292;&#20294;&#30001;&#20110;&#20998;&#24067;&#19981;&#30830;&#23450;&#24615;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#24615;&#33021;&#19981;&#31283;&#23450;&#21644;&#19981;&#22909;&#30340;&#26679;&#26412;&#22806;&#34920;&#29616;&#12290;&#22312;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#30340;&#31934;&#31070;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#40065;&#26834;&#20934;&#21017;&#65292;&#23558;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#65288;&#21363;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#65289;&#29702;&#35770;&#21644;&#26368;&#36817;&#30340;&#24179;&#28369;&#27169;&#31946;&#35268;&#36991;&#20559;&#22909;&#30340;&#20915;&#31574;&#29702;&#35770;&#27169;&#22411;&#30340;&#35265;&#35299;&#30456;&#32467;&#21512;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#24378;&#35843;&#20102;&#19982;&#26631;&#20934;&#27491;&#21017;&#21270;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#25216;&#26415;&#30340;&#26032;&#36830;&#25509;&#65292;&#20854;&#20013;&#21253;&#25324;&#23725;&#22238;&#24402;&#21644;&#22871;&#32034;&#22238;&#24402;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20174;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#40065;&#26834;&#20248;&#21270;&#36807;&#31243;&#22312;&#26377;&#38480;&#26679;&#26412;&#21644;&#28176;&#36817;&#32479;&#35745;&#20445;&#35777;&#26041;&#38754;&#30340;&#26377;&#21033;&#24615;&#23384;&#22312;&#12290;&#23545;&#20110;&#23454;&#38469;&#23454;&#26045;&#65292;&#25105;&#20204;&#25552;&#20986;&#24182;&#30740;&#31350;&#20102;&#22522;&#20110;&#20247;&#25152;&#21608;&#30693;&#30340;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#34920;&#31034;&#30340;&#21487;&#34892;&#36817;&#20284;&#20934;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;
Training machine learning and statistical models often involves optimizing a data-driven risk criterion. The risk is usually computed with respect to the empirical data distribution, but this may result in poor and unstable out-of-sample performance due to distributional uncertainty. In the spirit of distributionally robust optimization, we propose a novel robust criterion by combining insights from Bayesian nonparametric (i.e., Dirichlet Process) theory and recent decision-theoretic models of smooth ambiguity-averse preferences. First, we highlight novel connections with standard regularized empirical risk minimization techniques, among which Ridge and LASSO regressions. Then, we theoretically demonstrate the existence of favorable finite-sample and asymptotic statistical guarantees on the performance of the robust optimization procedure. For practical implementation, we propose and study tractable approximations of the criterion based on well-known Dirichlet Process representations. 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#36830;&#32493;&#26102;&#38388;&#24207;&#21015;&#38598;&#21512;&#30340;&#27010;&#29575;&#24314;&#27169;&#26694;&#26550;&#65292;&#36866;&#29992;&#20110;&#22788;&#29702;&#27599;&#20010;&#20107;&#20214;&#19982;&#19968;&#32452;&#39033;&#30446;&#30456;&#20851;&#32852;&#30340;&#24773;&#20917;&#12290;&#24341;&#20837;&#20102;&#36866;&#29992;&#20110;&#20219;&#20309;&#24378;&#24230;&#20026;&#22522;&#30784;&#30340;&#36882;&#24402;&#31070;&#32463;&#28857;&#36807;&#31243;&#27169;&#22411;&#30340;&#25512;&#29702;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#22238;&#31572;&#20851;&#20110;&#24207;&#21015;&#21382;&#21490;&#26465;&#20214;&#19979;&#30340;&#27010;&#29575;&#26597;&#35810;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2312.15045</link><description>&lt;p&gt;
&#36830;&#32493;&#26102;&#38388;&#24207;&#21015;&#38598;&#21512;&#30340;&#27010;&#29575;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Probabilistic Modeling for Sequences of Sets in Continuous-Time. (arXiv:2312.15045v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.15045
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#36830;&#32493;&#26102;&#38388;&#24207;&#21015;&#38598;&#21512;&#30340;&#27010;&#29575;&#24314;&#27169;&#26694;&#26550;&#65292;&#36866;&#29992;&#20110;&#22788;&#29702;&#27599;&#20010;&#20107;&#20214;&#19982;&#19968;&#32452;&#39033;&#30446;&#30456;&#20851;&#32852;&#30340;&#24773;&#20917;&#12290;&#24341;&#20837;&#20102;&#36866;&#29992;&#20110;&#20219;&#20309;&#24378;&#24230;&#20026;&#22522;&#30784;&#30340;&#36882;&#24402;&#31070;&#32463;&#28857;&#36807;&#31243;&#27169;&#22411;&#30340;&#25512;&#29702;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#22238;&#31572;&#20851;&#20110;&#24207;&#21015;&#21382;&#21490;&#26465;&#20214;&#19979;&#30340;&#27010;&#29575;&#26597;&#35810;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36830;&#32493;&#26102;&#38388;&#20107;&#20214;&#25968;&#25454;&#30340;&#32479;&#35745;&#21442;&#25968;&#27169;&#22411;&#24037;&#20855;&#31665;&#20013;&#65292;&#31070;&#32463;&#26631;&#35760;&#26102;&#38388;&#28857;&#36807;&#31243;&#26159;&#19968;&#20010;&#26377;&#20215;&#20540;&#30340;&#34917;&#20805;&#12290;&#36825;&#20123;&#27169;&#22411;&#36866;&#29992;&#20110;&#27599;&#20010;&#20107;&#20214;&#19982;&#21333;&#20010;&#39033;&#30446;&#65288;&#21333;&#20010;&#20107;&#20214;&#31867;&#22411;&#25110;&#8220;&#26631;&#35760;&#8221;&#65289;&#30456;&#20851;&#32852;&#30340;&#24207;&#21015;&#65292;&#20294;&#19981;&#36866;&#29992;&#20110;&#27599;&#20010;&#20107;&#20214;&#19982;&#19968;&#32452;&#39033;&#30446;&#30456;&#20851;&#32852;&#30340;&#23454;&#38469;&#24773;&#20917;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#36830;&#32493;&#26102;&#38388;&#38598;&#21512;&#25968;&#20540;&#25968;&#25454;&#24314;&#27169;&#26694;&#26550;&#65292;&#19982;&#20219;&#20309;&#22522;&#20110;&#24378;&#24230;&#30340;&#36882;&#24402;&#31070;&#32463;&#28857;&#36807;&#31243;&#27169;&#22411;&#20860;&#23481;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#25512;&#29702;&#26041;&#27861;&#65292;&#21487;&#20351;&#29992;&#36825;&#20123;&#27169;&#22411;&#22238;&#31572;&#35832;&#22914;&#8220;&#22312;&#32771;&#34385;&#24207;&#21015;&#21382;&#21490;&#30340;&#26465;&#20214;&#19979;&#65292;&#39033;&#30446;A&#22312;&#39033;&#30446;B&#20043;&#21069;&#35266;&#23519;&#21040;&#30340;&#27010;&#29575;&#8221;&#31561;&#27010;&#29575;&#26597;&#35810;&#38382;&#39064;&#12290;&#30001;&#20110;&#38382;&#39064;&#35774;&#32622;&#30340;&#36830;&#32493;&#26102;&#38388;&#24615;&#36136;&#21644;&#27599;&#20010;&#20107;&#20214;&#30340;&#28508;&#22312;&#32467;&#26524;&#31354;&#38388;&#30340;&#32452;&#21512;&#26497;&#22823;&#65292;&#23545;&#20110;&#31070;&#32463;&#27169;&#22411;&#26469;&#35828;&#65292;&#35745;&#31639;&#36825;&#20123;&#26597;&#35810;&#30340;&#31934;&#30830;&#31572;&#26696;&#36890;&#24120;&#26159;&#19981;&#21487;&#34892;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural marked temporal point processes have been a valuable addition to the existing toolbox of statistical parametric models for continuous-time event data. These models are useful for sequences where each event is associated with a single item (a single type of event or a "mark") -- but such models are not suited for the practical situation where each event is associated with a set of items. In this work, we develop a general framework for modeling set-valued data in continuous-time, compatible with any intensity-based recurrent neural point process model. In addition, we develop inference methods that can use such models to answer probabilistic queries such as "the probability of item $A$ being observed before item $B$," conditioned on sequence history. Computing exact answers for such queries is generally intractable for neural models due to both the continuous-time nature of the problem setting and the combinatorially-large space of potential outcomes for each event. To address th
&lt;/p&gt;</description></item><item><title>MCRAGE&#26159;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#26469;&#22686;&#24378;&#19981;&#24179;&#34913;&#30340;&#21307;&#30103;&#25968;&#25454;&#38598;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#23569;&#25968;&#32676;&#20307;&#22312;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#30340;&#19981;&#20844;&#24179;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.18430</link><description>&lt;p&gt;
MCRAGE: &#20844;&#24179;&#24615;&#30340;&#21512;&#25104;&#21307;&#30103;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
MCRAGE: Synthetic Healthcare Data for Fairness. (arXiv:2310.18430v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18430
&lt;/p&gt;
&lt;p&gt;
MCRAGE&#26159;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#26469;&#22686;&#24378;&#19981;&#24179;&#34913;&#30340;&#21307;&#30103;&#25968;&#25454;&#38598;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#23569;&#25968;&#32676;&#20307;&#22312;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#30340;&#19981;&#20844;&#24179;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21307;&#30103;&#39046;&#22495;&#65292;&#30005;&#23376;&#20581;&#24247;&#35760;&#24405;&#65288;EHR&#65289;&#26159;&#24320;&#21457;&#35786;&#26029;&#12289;&#27835;&#30103;&#21644;&#31649;&#29702;&#21307;&#30103;&#36164;&#28304;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#20851;&#38190;&#35757;&#32451;&#25968;&#25454;&#12290;&#28982;&#32780;&#65292;&#21307;&#30103;&#25968;&#25454;&#38598;&#22312;&#31181;&#26063;/&#27665;&#26063;&#12289;&#24615;&#21035;&#21644;&#24180;&#40836;&#31561;&#25935;&#24863;&#23646;&#24615;&#26041;&#38754;&#24448;&#24448;&#23384;&#22312;&#19981;&#24179;&#34913;&#12290;&#22312;&#31867;&#19981;&#24179;&#34913;&#30340;EHR&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#37096;&#32626;&#26102;&#65292;&#23545;&#20110;&#23569;&#25968;&#32676;&#20307;&#30340;&#20010;&#20307;&#32780;&#35328;&#65292;&#34920;&#29616;&#26174;&#33879;&#19981;&#22914;&#22810;&#25968;&#32676;&#20307;&#30340;&#26679;&#26412;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#23569;&#25968;&#32676;&#20307;&#30340;&#19981;&#20844;&#24179;&#21307;&#30103;&#32467;&#26524;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Minority Class Rebalancing through Augmentation by Generative modeling (MCRAGE)&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#30001;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#29983;&#25104;&#30340;&#26679;&#26412;&#26469;&#22686;&#24378;&#19981;&#24179;&#34913;&#30340;&#25968;&#25454;&#38598;&#12290;MCRAGE&#36807;&#31243;&#21253;&#25324;&#35757;&#32451;&#19968;&#20010;&#33021;&#22815;&#20174;&#23569;&#25968;&#32676;&#20307;&#20013;&#20135;&#29983;&#39640;&#36136;&#37327;&#21512;&#25104;EHR&#26679;&#26412;&#30340;&#26465;&#20214;&#21435;&#22122;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#65288;CDDPM&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the field of healthcare, electronic health records (EHR) serve as crucial training data for developing machine learning models for diagnosis, treatment, and the management of healthcare resources. However, medical datasets are often imbalanced in terms of sensitive attributes such as race/ethnicity, gender, and age. Machine learning models trained on class-imbalanced EHR datasets perform significantly worse in deployment for individuals of the minority classes compared to samples from majority classes, which may lead to inequitable healthcare outcomes for minority groups. To address this challenge, we propose Minority Class Rebalancing through Augmentation by Generative modeling (MCRAGE), a novel approach to augment imbalanced datasets using samples generated by a deep generative model. The MCRAGE process involves training a Conditional Denoising Diffusion Probabilistic Model (CDDPM) capable of generating high-quality synthetic EHR samples from underrepresented classes. We use this 
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#25197;&#26354;&#20960;&#20309;&#23398;&#30340;&#27010;&#24565;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#39640;&#32500;&#27431;&#20960;&#37324;&#24503;&#31354;&#38388;&#20013;&#20248;&#21270;&#20989;&#25968;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#22312;&#37325;&#26032;&#23450;&#20041;&#30340;&#40654;&#26364;&#27969;&#24418;&#19978;&#36827;&#34892;&#35745;&#31639;&#65292;&#25214;&#21040;&#20102;&#20989;&#25968;&#30340;&#26368;&#20248;&#35299;&#12290;</title><link>http://arxiv.org/abs/2308.08305</link><description>&lt;p&gt;
&#22312;&#27431;&#20960;&#37324;&#24503;&#20989;&#25968;&#20248;&#21270;&#20013;&#30340;&#25197;&#26354;&#20960;&#20309;&#20449;&#24687;
&lt;/p&gt;
&lt;p&gt;
Warped geometric information on the optimisation of Euclidean functions. (arXiv:2308.08305v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.08305
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#25197;&#26354;&#20960;&#20309;&#23398;&#30340;&#27010;&#24565;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#39640;&#32500;&#27431;&#20960;&#37324;&#24503;&#31354;&#38388;&#20013;&#20248;&#21270;&#20989;&#25968;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#22312;&#37325;&#26032;&#23450;&#20041;&#30340;&#40654;&#26364;&#27969;&#24418;&#19978;&#36827;&#34892;&#35745;&#31639;&#65292;&#25214;&#21040;&#20102;&#20989;&#25968;&#30340;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#22312;&#28508;&#22312;&#39640;&#32500;&#27431;&#20960;&#37324;&#24503;&#31354;&#38388;&#20013;&#20248;&#21270;&#23454;&#20540;&#20989;&#25968;&#30340;&#22522;&#26412;&#20219;&#21153;&#65292;&#20363;&#22914;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#25439;&#22833;&#20989;&#25968;&#25110;&#32479;&#35745;&#25512;&#26029;&#20013;&#30340;&#27010;&#29575;&#20998;&#24067;&#30340;&#23545;&#25968;&#12290;&#25105;&#20204;&#20351;&#29992;&#25197;&#26354;&#40654;&#26364;&#20960;&#20309;&#27010;&#24565;&#65292;&#23558;&#27431;&#20960;&#37324;&#24503;&#31354;&#38388;&#19978;&#30340;&#20989;&#25968;&#20248;&#21270;&#38382;&#39064;&#37325;&#26032;&#23450;&#20041;&#20026;&#19968;&#20010;&#24102;&#26377;&#25197;&#26354;&#24230;&#37327;&#30340;&#40654;&#26364;&#27969;&#24418;&#65292;&#24182;&#22312;&#35813;&#27969;&#24418;&#19978;&#25214;&#21040;&#20989;&#25968;&#30340;&#26368;&#20248;&#35299;&#12290;&#36873;&#25321;&#29992;&#20110;&#25628;&#32034;&#22495;&#30340;&#25197;&#26354;&#24230;&#37327;&#24341;&#20837;&#20102;&#19968;&#20010;&#35745;&#31639;&#21451;&#22909;&#30340;&#24230;&#37327;&#24352;&#37327;&#65292;&#20351;&#24471;&#22312;&#27969;&#24418;&#19978;&#25214;&#21040;&#26368;&#20248;&#25628;&#32034;&#26041;&#21521;&#19982;&#27979;&#22320;&#32447;&#21464;&#24471;&#26356;&#23481;&#26131;&#35745;&#31639;&#12290;&#27839;&#27979;&#22320;&#32447;&#36827;&#34892;&#20248;&#21270;&#36890;&#24120;&#26159;&#19981;&#21487;&#34892;&#30340;&#65292;&#20294;&#25105;&#20204;&#34920;&#26126;&#22312;&#36825;&#20010;&#29305;&#23450;&#30340;&#27969;&#24418;&#20013;&#65292;&#25105;&#20204;&#21487;&#20197;&#35299;&#26512;&#22320;&#24471;&#21040;&#39640;&#36798;&#19977;&#38454;&#30340;&#27888;&#21202;&#36817;&#20284;&#12290;&#19968;&#33324;&#24773;&#20917;&#19979;&#65292;&#36825;&#20123;&#23545;&#27979;&#22320;&#32447;&#30340;&#36817;&#20284;&#19981;&#20250;&#20301;&#20110;&#27969;&#24418;&#19978;&#65292;&#20294;&#25105;&#20204;&#26500;&#36896;&#20102;&#21512;&#36866;&#30340;&#22238;&#32553;&#26041;&#31243;&#23558;&#36825;&#20123;&#36817;&#20284;&#37325;&#26032;&#26144;&#23556;&#21040;&#27969;&#24418;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the fundamental task of optimizing a real-valued function defined in a potentially high-dimensional Euclidean space, such as the loss function in many machine-learning tasks or the logarithm of the probability distribution in statistical inference. We use the warped Riemannian geometry notions to redefine the optimisation problem of a function on Euclidean space to a Riemannian manifold with a warped metric, and then find the function's optimum along this manifold. The warped metric chosen for the search domain induces a computational friendly metric-tensor for which optimal search directions associate with geodesic curves on the manifold becomes easier to compute. Performing optimization along geodesics is known to be generally infeasible, yet we show that in this specific manifold we can analytically derive Taylor approximations up to third-order. In general these approximations to the geodesic curve will not lie on the manifold, however we construct suitable retraction m
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38024;&#23545;&#23545;&#25239;&#24615;&#35757;&#32451;&#30340;&#38750;&#38646;&#21644;&#21452;&#23618;&#20844;&#24335;&#65292;&#23454;&#29616;&#20102;&#19982;&#26368;&#20808;&#36827;&#25915;&#20987;&#30456;&#21305;&#37197;&#24182;&#19988;&#33021;&#22815;&#36798;&#21040;&#19982;&#26631;&#20934;&#23545;&#25239;&#24615;&#35757;&#32451;&#30456;&#21516;&#30340;&#40065;&#26834;&#24615;&#27700;&#24179;&#12290;</title><link>http://arxiv.org/abs/2306.11035</link><description>&lt;p&gt;
&#23545;&#25239;&#35757;&#32451;&#24212;&#34987;&#35270;&#20026;&#19968;&#20010;&#38750;&#38646;&#21644;&#21338;&#24328;
&lt;/p&gt;
&lt;p&gt;
Adversarial Training Should Be Cast as a Non-Zero-Sum Game. (arXiv:2306.11035v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11035
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38024;&#23545;&#23545;&#25239;&#24615;&#35757;&#32451;&#30340;&#38750;&#38646;&#21644;&#21452;&#23618;&#20844;&#24335;&#65292;&#23454;&#29616;&#20102;&#19982;&#26368;&#20808;&#36827;&#25915;&#20987;&#30456;&#21305;&#37197;&#24182;&#19988;&#33021;&#22815;&#36798;&#21040;&#19982;&#26631;&#20934;&#23545;&#25239;&#24615;&#35757;&#32451;&#30456;&#21516;&#30340;&#40065;&#26834;&#24615;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35299;&#20915;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23545;&#25239;&#24615;&#33030;&#24369;&#24615;&#30340;&#19968;&#20010;&#31361;&#20986;&#26041;&#27861;&#26159;&#37319;&#29992;&#23545;&#25239;&#24615;&#35757;&#32451;&#30340;&#20004;&#20010;&#29609;&#23478;&#38646;&#21644;&#33539;&#24335;&#65292;&#20854;&#20013;&#39044;&#27979;&#22120;&#34987;&#35757;&#32451;&#20197;&#23545;&#25239;&#24615;&#36873;&#25321;&#30340;&#25968;&#25454;&#25200;&#21160;&#12290;&#34429;&#28982;&#36825;&#31181;&#26041;&#27861;&#24456;&#26377;&#21069;&#36884;&#65292;&#20294;&#26159;&#22522;&#20110;&#36825;&#31181;&#33539;&#24335;&#30340;&#31639;&#27861;&#24182;&#27809;&#26377;&#20135;&#29983;&#36275;&#22815;&#30340;&#40065;&#26834;&#24615;&#65292;&#24182;&#19988;&#36973;&#21463;&#30149;&#24577;&#34892;&#20026;&#65292;&#22914;&#24378;&#20581;&#30340;&#36807;&#25311;&#21512;&#12290;&#20026;&#20102;&#29702;&#35299;&#36825;&#31181;&#32570;&#38519;&#65292;&#25105;&#20204;&#39318;&#20808;&#23637;&#31034;&#20102;&#22312;&#23545;&#25239;&#35757;&#32451;&#31639;&#27861;&#20013;&#20351;&#29992;&#30340;&#24120;&#35265;&#22522;&#20110;&#20195;&#29702;&#30340;&#26494;&#24347;&#26041;&#27861;&#20351;&#25152;&#35757;&#32451;&#20998;&#31867;&#22120;&#30340;&#31283;&#20581;&#24615;&#27809;&#26377;&#20219;&#20309;&#20445;&#35777;&#12290;&#25105;&#20204;&#21457;&#29616;&#36825;&#20010;&#38382;&#39064;&#21518;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#38750;&#38646;&#21644;&#21452;&#23618;&#23545;&#25239;&#35757;&#32451;&#20844;&#24335;&#65292;&#20854;&#20013;&#27599;&#20010;&#29609;&#23478;&#20248;&#21270;&#19981;&#21516;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#25105;&#20204;&#30340;&#20844;&#24335;&#33258;&#28982;&#22320;&#20135;&#29983;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#31639;&#27861;&#26694;&#26550;&#65292;&#21487;&#20197;&#19982;&#26368;&#20808;&#36827;&#30340;&#25915;&#20987;&#30456;&#21305;&#37197;&#65292;&#24182;&#19988;&#22312;&#19968;&#20123;&#24773;&#20917;&#19979;&#65292;&#33021;&#22815;&#36798;&#21040;&#19982;&#26631;&#20934;&#23545;&#25239;&#24615;&#35757;&#32451;&#30456;&#24403;&#30340;&#40065;&#26834;&#24615;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
One prominent approach toward resolving the adversarial vulnerability of deep neural networks is the two-player zero-sum paradigm of adversarial training, in which predictors are trained against adversarially-chosen perturbations of data. Despite the promise of this approach, algorithms based on this paradigm have not engendered sufficient levels of robustness, and suffer from pathological behavior like robust overfitting. To understand this shortcoming, we first show that the commonly used surrogate-based relaxation used in adversarial training algorithms voids all guarantees on the robustness of trained classifiers. The identification of this pitfall informs a novel non-zero-sum bilevel formulation of adversarial training, wherein each player optimizes a different objective function. Our formulation naturally yields a simple algorithmic framework that matches and in some cases outperforms state-of-the-art attacks, attains comparable levels of robustness to standard adversarial traini
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;&#21487;&#20197;&#23646;&#24615;&#39640;&#25928;&#30340;&#23398;&#20064;&#20302;&#27425;&#22810;&#39033;&#24335;&#38408;&#20540;&#20989;&#25968;&#65292;&#24182;&#33021;&#22815;&#22312;&#22122;&#22768;&#19979;&#36827;&#34892;PAC&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2306.00673</link><description>&lt;p&gt;
&#23646;&#24615;&#39640;&#25928;&#30340;&#20302;&#27425;&#22810;&#39033;&#24335;&#38408;&#20540;&#20989;&#25968;&#24102;&#22122;&#22768;PAC&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Attribute-Efficient PAC Learning of Low-Degree Polynomial Threshold Functions with Nasty Noise. (arXiv:2306.00673v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00673
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;&#21487;&#20197;&#23646;&#24615;&#39640;&#25928;&#30340;&#23398;&#20064;&#20302;&#27425;&#22810;&#39033;&#24335;&#38408;&#20540;&#20989;&#25968;&#65292;&#24182;&#33021;&#22815;&#22312;&#22122;&#22768;&#19979;&#36827;&#34892;PAC&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20302;&#27425;&#22810;&#39033;&#24335;&#38408;&#20540;&#20989;&#25968;&#65288;PTFs&#65289;&#30340;&#27010;&#24565;&#31867;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#36215;&#30528;&#22522;&#30784;&#20316;&#29992;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;$\mathbb{R}^n$&#19978;$K$&#31232;&#30095;&#24230;-$d$ PTFs&#30340;&#23646;&#24615;&#39640;&#25928;PAC&#23398;&#20064;&#65292;&#20854;&#20013;&#20219;&#20309;&#36825;&#26679;&#30340;&#27010;&#24565;&#20165;&#20381;&#36182;&#20110;&#36755;&#20837;&#30340;$K$&#20010;&#23646;&#24615;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#65306;&#25552;&#20986;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;&#22312;&#39640;&#26031;&#36793;&#32536;&#20998;&#24067;&#19979;&#65292;&#21363;&#20351;&#26377;$O(\epsilon^d)$&#30340;$\eta$&#34987;&#24694;&#24847;&#22122;&#22768;Bshouty et al. (2002)&#30772;&#22351;&#65292;&#20063;&#21487;&#20197;&#22312;&#38169;&#35823;&#29575;$\epsilon$&#19979;&#20197;$O(\frac{K^{{4d}}}{\epsilon^{2d}}\cdot \log^{5d} n)$&#30340;&#26679;&#26412;PAC&#23398;&#20064;&#35813;&#31867;&#65292;&#31639;&#27861;&#36816;&#34892;&#26102;&#38388;&#20026;$({nd}/{\epsilon})^{O(d)}$&#12290;&#22312;&#27492;&#20043;&#21069;&#65292;&#20165;&#20026;&#31232;&#30095;&#40784;&#27425;&#36229;&#24179;&#38754;&#30340;&#29305;&#27530;&#24773;&#20917;&#24314;&#31435;&#20102;&#23646;&#24615;&#39640;&#25928;&#30340;&#40065;&#26834;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#22240;&#32032;&#26159;&#65306;1&#65289;&#23558;&#23646;&#24615;&#31232;&#30095;&#24615;&#36716;&#21270;&#20026;Hermite&#22810;&#39033;&#24335;&#22522;&#19979;chow&#21521;&#37327;&#30340;&#31232;&#30095;&#27169;&#24335;&#30340;&#32467;&#26500;&#32467;&#26524;&#65307;2&#65289;&#19968;&#31181;&#26032;&#30340;&#35268;&#33539;&#21270;&#26041;&#27861;&#65292;&#20197;&#21450;&#21033;&#29992;&#22810;&#39033;&#24335;&#36817;&#20284;&#30340;&#38408;&#20540;&#20989;&#25968;&#30340;&#30452;&#25509;&#21028;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;
The concept class of low-degree polynomial threshold functions (PTFs) plays a fundamental role in machine learning. In this paper, we study PAC learning of $K$-sparse degree-$d$ PTFs on $\mathbb{R}^n$, where any such concept depends only on $K$ out of $n$ attributes of the input. Our main contribution is a new algorithm that runs in time $({nd}/{\epsilon})^{O(d)}$ and under the Gaussian marginal distribution, PAC learns the class up to error rate $\epsilon$ with $O(\frac{K^{4d}}{\epsilon^{2d}} \cdot \log^{5d} n)$ samples even when an $\eta \leq O(\epsilon^d)$ fraction of them are corrupted by the nasty noise of Bshouty et al. (2002), possibly the strongest corruption model. Prior to this work, attribute-efficient robust algorithms are established only for the special case of sparse homogeneous halfspaces. Our key ingredients are: 1) a structural result that translates the attribute sparsity to a sparsity pattern of the Chow vector under the basis of Hermite polynomials, and 2) a novel 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23454;&#39564;&#21644;&#29702;&#35770;&#20998;&#26512;&#65292;&#26412;&#35770;&#25991;&#21457;&#29616;&#22312;&#30693;&#35782;&#33976;&#39311;&#20013;&#65292;&#23398;&#29983;&#32593;&#32476;&#23545;&#25945;&#24072;&#32593;&#32476;&#30340;&#27010;&#29575;&#20559;&#31163;&#26159;&#31995;&#32479;&#24615;&#22840;&#22823;&#30340;&#65292;&#21516;&#26102;&#20063;&#24471;&#21040;&#20102;&#26356;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2301.12923</link><description>&lt;p&gt;
&#20851;&#20110;&#30693;&#35782;&#33976;&#39311;&#20013;&#30340;&#23398;&#29983;-&#25945;&#24072;&#20559;&#24046;&#65306;&#36829;&#21453;&#35268;&#21017;&#26159;&#21542;&#26377;&#30410;&#65311;
&lt;/p&gt;
&lt;p&gt;
On student-teacher deviations in distillation: does it pay to disobey?. (arXiv:2301.12923v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.12923
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23454;&#39564;&#21644;&#29702;&#35770;&#20998;&#26512;&#65292;&#26412;&#35770;&#25991;&#21457;&#29616;&#22312;&#30693;&#35782;&#33976;&#39311;&#20013;&#65292;&#23398;&#29983;&#32593;&#32476;&#23545;&#25945;&#24072;&#32593;&#32476;&#30340;&#27010;&#29575;&#20559;&#31163;&#26159;&#31995;&#32479;&#24615;&#22840;&#22823;&#30340;&#65292;&#21516;&#26102;&#20063;&#24471;&#21040;&#20102;&#26356;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#35782;&#33976;&#39311;&#65288;KD&#65289;&#34987;&#24191;&#27867;&#29992;&#20110;&#36890;&#36807;&#35757;&#32451;&#23398;&#29983;&#27169;&#20223;&#32463;&#36807;&#35757;&#32451;&#30340;&#8220;&#25945;&#24072;&#8221;&#32593;&#32476;&#30340;&#36719;&#27010;&#29575;&#26469;&#25552;&#39640;&#8220;&#23398;&#29983;&#8221;&#32593;&#32476;&#30340;&#27979;&#35797;&#20934;&#30830;&#24615;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#23613;&#31649;&#34987;&#35757;&#32451;&#25104;&#36866;&#24212;&#25945;&#24072;&#30340;&#27010;&#29575;&#65292;&#23398;&#29983;&#19981;&#20165;&#26126;&#26174;&#20559;&#31163;&#36825;&#20123;&#27010;&#29575;&#65292;&#32780;&#19988;&#34920;&#29616;&#27604;&#25945;&#24072;&#26356;&#22909;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#26088;&#22312;&#36890;&#36807;&#30830;&#23450;&#23398;&#29983;-&#25945;&#24072;&#20559;&#24046;&#30340;&#30830;&#20999;&#24615;&#36136;&#65292;&#24182;&#35770;&#35777;&#23427;&#20204;&#19982;&#26356;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#22914;&#20309;&#20849;&#23384;&#26469;&#35299;&#20915;&#36825;&#19968;&#30475;&#20284;&#30683;&#30462;&#30340;&#35266;&#23519;&#12290;&#39318;&#20808;&#65292;&#36890;&#36807;&#23545;&#22270;&#20687;&#21644;&#35821;&#35328;&#25968;&#25454;&#36827;&#34892;&#23454;&#39564;&#65292;&#25105;&#20204;&#30830;&#23450;&#36825;&#20123;&#20559;&#24046;&#23545;&#24212;&#20110;&#23398;&#29983;&#31995;&#32479;&#24615;&#22320;&#22840;&#22823;&#25945;&#24072;&#30340;&#33258;&#20449;&#27700;&#24179;&#12290;&#25509;&#19979;&#26469;&#65292;&#22312;&#19968;&#20123;&#31616;&#21333;&#30340;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#20174;&#29702;&#35770;&#21644;&#23454;&#35777;&#19978;&#24314;&#31435;&#20102;KD&#22312;&#25910;&#25947;&#26356;&#24555;&#30340;&#36807;&#31243;&#20013;&#22840;&#22823;&#20102;&#26799;&#24230;&#19979;&#38477;&#30340;&#38544;&#21547;&#20559;&#24046;&#30340;&#35777;&#25454;&#12290;&#26368;&#21518;&#65292;
&lt;/p&gt;
&lt;p&gt;
Knowledge distillation (KD) has been widely-used to improve the test accuracy of a ``student'' network by training the student to mimic soft probabilities of a trained "teacher" network. Yet, it has been shown in recent work that, despite being trained to fit the teacher's probabilities, the student not only significantly deviates from these probabilities, but also performs even better than the teacher. Our work aims to reconcile this seemingly paradoxical observation by characterizing the precise nature of the student-teacher deviations, and by arguing how they can co-occur with better generalization. First, through experiments on image and language data, we identify that these deviations correspond to the student systematically exaggerating the confidence levels of the teacher. Next, we theoretically and empirically establish in some simple settings that KD also exaggerates the implicit bias of gradient descent in converging faster along the top eigendirections of the data. Finally, 
&lt;/p&gt;</description></item></channel></rss>