<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#24341;&#20837;&#31867;&#37327;&#23376; Hamilton Monte Carlo &#26041;&#27861;&#21040;&#19981;&#31561;&#24335;&#21644;&#21333;&#35843;&#24615;&#32422;&#26463;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#20013;&#65292;&#22312;&#27010;&#29575;&#24847;&#20041;&#19978;&#25552;&#39640;&#20102;&#27169;&#22411;&#20934;&#30830;&#24615;&#24182;&#20943;&#23569;&#20102;&#26041;&#24046;</title><link>https://arxiv.org/abs/2404.02873</link><description>&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#19982;&#36719;&#19981;&#31561;&#24335;&#21644;&#21333;&#35843;&#24615;&#32422;&#26463;
&lt;/p&gt;
&lt;p&gt;
Gaussian Process Regression with Soft Inequality and Monotonicity Constraints
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02873
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#31867;&#37327;&#23376; Hamilton Monte Carlo &#26041;&#27861;&#21040;&#19981;&#31561;&#24335;&#21644;&#21333;&#35843;&#24615;&#32422;&#26463;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#20013;&#65292;&#22312;&#27010;&#29575;&#24847;&#20041;&#19978;&#25552;&#39640;&#20102;&#27169;&#22411;&#20934;&#30830;&#24615;&#24182;&#20943;&#23569;&#20102;&#26041;&#24046;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Gaussian process&#65288;GP&#65289;&#22238;&#24402;&#26159;&#19968;&#31181;&#38750;&#21442;&#25968;&#12289;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#29992;&#20110;&#36924;&#36817;&#22797;&#26434;&#27169;&#22411;&#12290;&#26631;&#20934;&#30340;GP&#22238;&#24402;&#21487;&#33021;&#23548;&#33268;&#27169;&#22411;&#26080;&#30028;&#65292;&#23548;&#33268;&#26576;&#20123;&#28857;&#37319;&#29992;&#19981;&#21487;&#34892;&#30340;&#20540;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;GP&#26041;&#27861;&#65292;&#20197;&#27010;&#29575;&#26041;&#24335;&#24378;&#21046;&#25191;&#34892;&#29289;&#29702;&#32422;&#26463;&#12290;&#35813;GP&#27169;&#22411;&#36890;&#36807;&#31867;&#37327;&#23376;&#21551;&#21457;&#30340; Hamilton Monte Carlo&#65288;QHMC&#65289;&#36827;&#34892;&#35757;&#32451;&#12290;QHMC&#26159;&#20174;&#21508;&#31181;&#20998;&#24067;&#20013;&#39640;&#25928;&#25277;&#26679;&#30340;&#26041;&#27861;&#12290;&#19982;&#26631;&#20934;&#30340; Hamilton Monte Carlo &#31639;&#27861;&#19981;&#21516;&#65292;&#20854;&#20013;&#31890;&#23376;&#20855;&#26377;&#22266;&#23450;&#36136;&#37327;&#65292;QHMC&#20801;&#35768;&#31890;&#23376;&#20855;&#26377;&#38543;&#26426;&#36136;&#37327;&#30697;&#38453;&#24182;&#24102;&#26377;&#27010;&#29575;&#20998;&#24067;&#12290;&#23558; QHMC &#26041;&#27861;&#24341;&#20837;&#27010;&#29575;&#24847;&#20041;&#19978;&#30340;&#19981;&#31561;&#24335;&#21644;&#21333;&#35843;&#24615;&#32422;&#26463;&#30340; GP &#22238;&#24402;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#25552;&#39640;&#20102;&#32467;&#26524; GP &#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#24182;&#20943;&#23569;&#20102;&#26041;&#24046;&#12290;&#26681;&#25454;&#25105;&#20204;&#22312;&#20960;&#20010;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20316;&#20026;&#19968;&#31181;&#39640;&#25928;&#26041;&#27861;&#21487;&#20197;&#21152;&#36895;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02873v1 Announce Type: cross  Abstract: Gaussian process (GP) regression is a non-parametric, Bayesian framework to approximate complex models. Standard GP regression can lead to an unbounded model in which some points can take infeasible values. We introduce a new GP method that enforces the physical constraints in a probabilistic manner. This GP model is trained by the quantum-inspired Hamiltonian Monte Carlo (QHMC). QHMC is an efficient way to sample from a broad class of distributions. Unlike the standard Hamiltonian Monte Carlo algorithm in which a particle has a fixed mass, QHMC allows a particle to have a random mass matrix with a probability distribution. Introducing the QHMC method to the inequality and monotonicity constrained GP regression in the probabilistic sense, our approach improves the accuracy and reduces the variance in the resulting GP model. According to our experiments on several datasets, the proposed approach serves as an efficient method as it accel
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#28155;&#21152;&#22122;&#22768;&#21040;&#26368;&#21518;&#23618;&#30340;&#28608;&#27963;&#26469;&#20445;&#25252;&#38544;&#31169;&#65292;&#20351;&#29992;HCR&#30028;&#38480;&#21487;&#37327;&#21270;&#20445;&#25252;&#26426;&#23494;&#24615;&#30340;&#21487;&#20449;&#24230;</title><link>https://arxiv.org/abs/2404.02866</link><description>&lt;p&gt;
&#36890;&#36807;Hammersley-Chapman-Robbins&#30028;&#38480;&#20445;&#35777;&#26426;&#23494;&#24615;
&lt;/p&gt;
&lt;p&gt;
Guarantees of confidentiality via Hammersley-Chapman-Robbins bounds
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02866
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#28155;&#21152;&#22122;&#22768;&#21040;&#26368;&#21518;&#23618;&#30340;&#28608;&#27963;&#26469;&#20445;&#25252;&#38544;&#31169;&#65292;&#20351;&#29992;HCR&#30028;&#38480;&#21487;&#37327;&#21270;&#20445;&#25252;&#26426;&#23494;&#24615;&#30340;&#21487;&#20449;&#24230;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#25512;&#26029;&#36807;&#31243;&#20013;&#36890;&#36807;&#21521;&#26368;&#21518;&#20960;&#23618;&#30340;&#28608;&#27963;&#28155;&#21152;&#22122;&#22768;&#26469;&#20445;&#25252;&#38544;&#31169;&#26159;&#21487;&#33021;&#30340;&#12290;&#36825;&#20123;&#23618;&#20013;&#30340;&#28608;&#27963;&#34987;&#31216;&#20026;&#8220;&#29305;&#24449;&#8221;&#65288;&#23569;&#35265;&#30340;&#31216;&#20026;&#8220;&#23884;&#20837;&#8221;&#25110;&#8220;&#29305;&#24449;&#23884;&#20837;&#8221;&#65289;&#12290;&#28155;&#21152;&#30340;&#22122;&#22768;&#26377;&#21161;&#20110;&#38450;&#27490;&#20174;&#22024;&#26434;&#30340;&#29305;&#24449;&#20013;&#37325;&#24314;&#36755;&#20837;&#12290;&#36890;&#36807;&#23545;&#25152;&#26377;&#21487;&#33021;&#30340;&#26080;&#20559;&#20272;&#35745;&#37327;&#30340;&#26041;&#24046;&#36827;&#34892;&#19979;&#38480;&#20272;&#35745;&#65292;&#37327;&#21270;&#20102;&#30001;&#27492;&#28155;&#21152;&#30340;&#22122;&#22768;&#20135;&#29983;&#30340;&#26426;&#23494;&#24615;&#12290;&#32463;&#20856;&#19981;&#31561;&#24335;Hammersley&#21644;Chapman&#20197;&#21450;Robbins&#25552;&#20379;&#20415;&#21033;&#30340;&#12289;&#21487;&#35745;&#31639;&#30340;&#30028;&#38480;-- HCR&#30028;&#38480;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#23545;&#20110;&#21253;&#21547;10&#20010;&#31867;&#21035;&#30340;&#22270;&#20687;&#20998;&#31867;&#25968;&#25454;&#38598;&#8220;MNIST&#8221;&#21644;&#8220;CIFAR-10&#8221;&#65292;HCR&#30028;&#38480;&#22312;&#23567;&#22411;&#31070;&#32463;&#32593;&#32476;&#19978;&#34920;&#29616;&#33391;&#22909;&#12290;HCR&#30028;&#38480;&#20284;&#20046;&#21333;&#29420;&#26080;&#27861;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02866v1 Announce Type: new  Abstract: Protecting privacy during inference with deep neural networks is possible by adding noise to the activations in the last layers prior to the final classifiers or other task-specific layers. The activations in such layers are known as "features" (or, less commonly, as "embeddings" or "feature embeddings"). The added noise helps prevent reconstruction of the inputs from the noisy features. Lower bounding the variance of every possible unbiased estimator of the inputs quantifies the confidentiality arising from such added noise. Convenient, computationally tractable bounds are available from classic inequalities of Hammersley and of Chapman and Robbins -- the HCR bounds. Numerical experiments indicate that the HCR bounds are on the precipice of being effectual for small neural nets with the data sets, "MNIST" and "CIFAR-10," which contain 10 classes each for image classification. The HCR bounds appear to be insufficient on their own to guar
&lt;/p&gt;</description></item><item><title>&#23398;&#20064;&#32773;&#20542;&#21521;&#20110;&#20272;&#35745;&#20540;&#20026;&#27491;&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#36991;&#24320;&#20272;&#35745;&#20540;&#20026;&#36127;&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#23548;&#33268;&#39640;&#20272;&#35823;&#24046;&#32416;&#27491;&#20294;&#20302;&#20272;&#35823;&#24046;&#26080;&#27861;&#32416;&#27491;&#65292;&#21516;&#26102;&#30740;&#31350;&#21457;&#29616;&#22312;&#19968;&#20123;&#24773;&#20917;&#19979;&#36127;&#20272;&#35745;&#20250;&#23548;&#33268;&#36873;&#25321;&#36739;&#23569;&#30340;&#26679;&#26412;&#37327;&#65292;&#36825;&#31181;&#28040;&#26497;&#20559;&#35265;&#21516;&#26679;&#23384;&#22312;&#20110;&#36125;&#21494;&#26031;&#23398;&#20064;&#32773;&#20013;&#12290;</title><link>https://arxiv.org/abs/2404.02591</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#37319;&#26679;&#25919;&#31574;&#24847;&#21619;&#30528;&#23384;&#22312;&#20559;&#35265;&#20449;&#24565;: &#19968;&#33324;&#21270;&#30340;&#28909;&#28809;&#25928;&#24212;
&lt;/p&gt;
&lt;p&gt;
Adaptive Sampling Policies Imply Biased Beliefs: A Generalization of the Hot Stove Effect
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02591
&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#32773;&#20542;&#21521;&#20110;&#20272;&#35745;&#20540;&#20026;&#27491;&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#36991;&#24320;&#20272;&#35745;&#20540;&#20026;&#36127;&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#23548;&#33268;&#39640;&#20272;&#35823;&#24046;&#32416;&#27491;&#20294;&#20302;&#20272;&#35823;&#24046;&#26080;&#27861;&#32416;&#27491;&#65292;&#21516;&#26102;&#30740;&#31350;&#21457;&#29616;&#22312;&#19968;&#20123;&#24773;&#20917;&#19979;&#36127;&#20272;&#35745;&#20250;&#23548;&#33268;&#36873;&#25321;&#36739;&#23569;&#30340;&#26679;&#26412;&#37327;&#65292;&#36825;&#31181;&#28040;&#26497;&#20559;&#35265;&#21516;&#26679;&#23384;&#22312;&#20110;&#36125;&#21494;&#26031;&#23398;&#20064;&#32773;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28909;&#28809;&#25928;&#24212;&#26159;&#30001;&#20110;&#23398;&#20064;&#30340;&#36866;&#24212;&#24615;&#29305;&#24615;&#25152;&#23548;&#33268;&#30340;&#19968;&#31181;&#28040;&#26497;&#20559;&#35265;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#36861;&#27714;&#20272;&#35745;&#20540;&#20026;&#27491;&#30340;&#26367;&#20195;&#26041;&#26696;&#65292;&#36991;&#24320;&#20272;&#35745;&#20540;&#20026;&#36127;&#30340;&#26367;&#20195;&#26041;&#26696;&#30340;&#23398;&#20064;&#31639;&#27861;&#23558;&#32416;&#27491;&#39640;&#20272;&#35823;&#24046;&#65292;&#20294;&#26080;&#27861;&#32416;&#27491;&#20302;&#20272;&#35823;&#24046;&#12290;&#26412;&#25991;&#23558;&#28909;&#28809;&#25928;&#24212;&#30340;&#29702;&#35770;&#25512;&#24191;&#21040;&#36127;&#20272;&#35745;&#19981;&#19968;&#23450;&#23548;&#33268;&#36991;&#20813;&#32780;&#26159;&#23548;&#33268;&#26679;&#26412;&#37327;&#36739;&#23567;&#30340;&#24773;&#20917;&#65288;&#21363;&#65292;&#22914;&#26524;B&#34987;&#35748;&#20026;&#26159;&#27425;&#20248;&#30340;&#65292;&#23398;&#20064;&#32773;&#20250;&#36873;&#25321;&#26356;&#23569;&#30340;&#26367;&#20195;&#26041;&#26696;B&#32780;&#38750;&#23436;&#20840;&#36991;&#20813;B&#65289;&#12290;&#25105;&#20204;&#24418;&#24335;&#19978;&#35777;&#26126;&#20102;&#22312;&#36825;&#31181;&#35774;&#32622;&#20013;&#28040;&#26497;&#20559;&#35265;&#20173;&#28982;&#23384;&#22312;&#12290;&#25105;&#20204;&#36824;&#34920;&#26126;&#65292;&#36125;&#21494;&#26031;&#23398;&#20064;&#32773;&#23384;&#22312;&#28040;&#26497;&#20559;&#35265;&#65292;&#21363;&#22823;&#22810;&#25968;&#36825;&#26679;&#30340;&#23398;&#20064;&#32773;&#20302;&#20272;&#26367;&#20195;&#26041;&#26696;&#30340;&#39044;&#26399;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02591v1 Announce Type: new  Abstract: The Hot Stove Effect is a negativity bias resulting from the adaptive character of learning. The mechanism is that learning algorithms that pursue alternatives with positive estimated values, but avoid alternatives with negative estimated values, will correct errors of overestimation but fail to correct errors of underestimation. Here, we generalize the theory behind the Hot Stove Effect to settings in which negative estimates do not necessarily lead to avoidance but to a smaller sample size (i.e., a learner selects fewer of alternative B if B is believed to be inferior but does not entirely avoid B). We formally demonstrate that the negativity bias remains in this set-up. We also show there is a negativity bias for Bayesian learners in the sense that most such learners underestimate the expected value of an alternative.
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;ODE&#30340;&#29983;&#25104;&#27169;&#22411;&#20013;&#65292;&#20351;&#29992;Transformer&#23454;&#29616;&#27969;&#21305;&#37197;&#22312;&#28508;&#31354;&#38388;&#20013;&#30340;&#29702;&#35770;&#25910;&#25947;&#24615;&#20445;&#35777;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;&#20272;&#35745;ODE&#27969;&#29983;&#25104;&#26679;&#26412;&#20998;&#24067;&#26102;&#30340;&#26377;&#25928;&#24615;&#65292;&#21516;&#26102;&#36824;&#35777;&#26126;&#20102;&#20855;&#26377;&#21033;&#26222;&#24076;&#33576;&#36830;&#32493;&#24615;&#30340;Transformer&#32593;&#32476;&#21487;&#20197;&#26377;&#25928;&#36924;&#36817;&#20219;&#24847;&#20809;&#28369;&#20989;&#25968;&#12290;</title><link>https://arxiv.org/abs/2404.02538</link><description>&lt;p&gt;
&#27969;&#21305;&#37197;&#22312;&#28508;&#31354;&#38388;&#20013;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#19982;Transformer
&lt;/p&gt;
&lt;p&gt;
Convergence Analysis of Flow Matching in Latent Space with Transformers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02538
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;ODE&#30340;&#29983;&#25104;&#27169;&#22411;&#20013;&#65292;&#20351;&#29992;Transformer&#23454;&#29616;&#27969;&#21305;&#37197;&#22312;&#28508;&#31354;&#38388;&#20013;&#30340;&#29702;&#35770;&#25910;&#25947;&#24615;&#20445;&#35777;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;&#20272;&#35745;ODE&#27969;&#29983;&#25104;&#26679;&#26412;&#20998;&#24067;&#26102;&#30340;&#26377;&#25928;&#24615;&#65292;&#21516;&#26102;&#36824;&#35777;&#26126;&#20102;&#20855;&#26377;&#21033;&#26222;&#24076;&#33576;&#36830;&#32493;&#24615;&#30340;Transformer&#32593;&#32476;&#21487;&#20197;&#26377;&#25928;&#36924;&#36817;&#20219;&#24847;&#20809;&#28369;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;ODE-based&#29983;&#25104;&#27169;&#22411;&#65292;&#29305;&#21035;&#26159;&#27969;&#21305;&#37197;&#30340;&#29702;&#35770;&#25910;&#25947;&#24615;&#20445;&#35777;&#12290;&#25105;&#20204;&#20351;&#29992;&#39044;&#35757;&#32451;&#30340;&#33258;&#32534;&#30721;&#22120;&#32593;&#32476;&#23558;&#39640;&#32500;&#21407;&#22987;&#36755;&#20837;&#26144;&#23556;&#21040;&#20302;&#32500;&#28508;&#31354;&#38388;&#65292;&#20854;&#20013;&#19968;&#20010;Transformer&#32593;&#32476;&#34987;&#35757;&#32451;&#26469;&#39044;&#27979;&#20174;&#26631;&#20934;&#27491;&#24577;&#20998;&#24067;&#21040;&#30446;&#26631;&#28508;&#31354;&#38388;&#20998;&#24067;&#30340;&#21464;&#25442;&#36895;&#24230;&#22330;&#12290;&#25105;&#20204;&#30340;&#35823;&#24046;&#20998;&#26512;&#23637;&#31034;&#20102;&#36825;&#31181;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#34920;&#26126;&#36890;&#36807;&#20272;&#35745;&#30340;ODE&#27969;&#29983;&#25104;&#26679;&#26412;&#30340;&#20998;&#24067;&#22312;&#28201;&#26031;&#22374;-2&#36317;&#31163;&#19979;&#25910;&#25947;&#21040;&#30446;&#26631;&#20998;&#24067;&#65292;&#36825;&#22312;&#28201;&#21644;&#19988;&#23454;&#38469;&#30340;&#20551;&#35774;&#19979;&#25104;&#31435;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20855;&#26377;&#21033;&#26222;&#24076;&#33576;&#36830;&#32493;&#24615;&#30340;Transformer&#32593;&#32476;&#21487;&#20197;&#26377;&#25928;&#22320;&#36924;&#36817;&#20219;&#24847;&#20809;&#28369;&#20989;&#25968;&#65292;&#36825;&#21487;&#33021;&#26159;&#29420;&#31435;&#24863;&#20852;&#36259;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02538v1 Announce Type: cross  Abstract: We present theoretical convergence guarantees for ODE-based generative models, specifically flow matching. We use a pre-trained autoencoder network to map high-dimensional original inputs to a low-dimensional latent space, where a transformer network is trained to predict the velocity field of the transformation from a standard normal distribution to the target latent distribution. Our error analysis demonstrates the effectiveness of this approach, showing that the distribution of samples generated via estimated ODE flow converges to the target distribution in the Wasserstein-2 distance under mild and practical assumptions. Furthermore, we show that arbitrary smooth functions can be effectively approximated by transformer networks with Lipschitz continuity, which may be of independent interest.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20197;&#24212;&#29992;&#20110;&#22823;&#35268;&#27169;&#26080;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#30340;&#30333;&#30418;&#35774;&#35745;&#33539;&#20363;&#12290;</title><link>https://arxiv.org/abs/2404.02446</link><description>&lt;p&gt;
&#36890;&#36807;&#24102;&#26377;&#30333;&#30418;&#21464;&#25442;&#22120;&#30340;&#32467;&#26500;&#25193;&#25955;&#36827;&#34892;&#33945;&#38754;&#34917;&#20840;
&lt;/p&gt;
&lt;p&gt;
Masked Completion via Structured Diffusion with White-Box Transformers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02446
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20197;&#24212;&#29992;&#20110;&#22823;&#35268;&#27169;&#26080;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#30340;&#30333;&#30418;&#35774;&#35745;&#33539;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#23398;&#20064;&#26694;&#26550;&#36890;&#24120;&#20351;&#29992;&#22823;&#37327;&#26080;&#26631;&#31614;&#25968;&#25454;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#35299;&#20915;&#31616;&#21333;&#30340;&#21069;&#32622;&#20219;&#21153;&#23398;&#20064;&#34920;&#31034;&#65292;&#28982;&#21518;&#23558;&#36825;&#20123;&#34920;&#31034;&#29992;&#20316;&#19979;&#28216;&#20219;&#21153;&#30340;&#22522;&#30784;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#30333;&#30418;&#35774;&#35745;&#33539;&#20363;&#30340;&#23454;&#20363;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#22823;&#35268;&#27169;&#26080;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02446v1 Announce Type: new  Abstract: Modern learning frameworks often train deep neural networks with massive amounts of unlabeled data to learn representations by solving simple pretext tasks, then use the representations as foundations for downstream tasks. These networks are empirically designed; as such, they are usually not interpretable, their representations are not structured, and their designs are potentially redundant. White-box deep networks, in which each layer explicitly identifies and transforms structures in the data, present a promising alternative. However, existing white-box architectures have only been shown to work at scale in supervised settings with labeled data, such as classification. In this work, we provide the first instantiation of the white-box design paradigm that can be applied to large-scale unsupervised representation learning. We do this by exploiting a fundamental connection between diffusion, compression, and (masked) completion, deriving
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#26368;&#20808;&#36827;&#30340;NLP&#25216;&#26415;&#20174;&#21475;&#36848;&#39564;&#23608;&#25991;&#26412;&#20013;&#39044;&#27979;&#27515;&#22240;&#24182;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#30340;&#26041;&#27861;&#12290;</title><link>https://arxiv.org/abs/2404.02438</link><description>&lt;p&gt;
&#20174;&#21465;&#36848;&#21040;&#25968;&#23383;&#65306;&#21033;&#29992;&#21475;&#36848;&#39564;&#23608;&#21465;&#36848;&#30340;&#35821;&#35328;&#27169;&#22411;&#39044;&#27979;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
From Narratives to Numbers: Valid Inference Using Language Model Predictions from Verbal Autopsy Narratives
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02438
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#26368;&#20808;&#36827;&#30340;NLP&#25216;&#26415;&#20174;&#21475;&#36848;&#39564;&#23608;&#25991;&#26412;&#20013;&#39044;&#27979;&#27515;&#22240;&#24182;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22823;&#37096;&#20998;&#27515;&#20129;&#20107;&#20214;&#21457;&#29983;&#22312;&#21307;&#30103;&#31995;&#32479;&#22806;&#30340;&#22330;&#26223;&#20013;&#65292;&#21475;&#36848;&#39564;&#23608;&#65288;VAs&#65289;&#26159;&#30417;&#27979;&#27515;&#22240;&#36235;&#21183;&#30340;&#24120;&#29992;&#24037;&#20855;&#12290;VAs&#26159;&#19982;&#24184;&#23384;&#30340;&#29031;&#26009;&#32773;&#25110;&#20146;&#23646;&#36827;&#34892;&#30340;&#35775;&#35848;&#65292;&#29992;&#20110;&#39044;&#27979;&#36893;&#32773;&#30340;&#27515;&#22240;&#12290;&#23558;VAs&#36716;&#21270;&#20026;&#30740;&#31350;&#20154;&#21592;&#21644;&#20915;&#31574;&#32773;&#21487;&#34892;&#30340;&#35265;&#35299;&#38656;&#35201;&#20004;&#20010;&#27493;&#39588;&#65306;&#65288;i&#65289;&#20351;&#29992;VA&#35775;&#35848;&#39044;&#27979;&#21487;&#33021;&#30340;&#27515;&#22240;&#65292;&#65288;ii&#65289;&#20351;&#29992;&#39044;&#27979;&#30340;&#27515;&#22240;&#36827;&#34892;&#25512;&#26029;&#65288;&#20363;&#22914;&#65292;&#20351;&#29992;&#27515;&#20129;&#26679;&#26412;&#23545;&#27515;&#22240;&#25353;&#20154;&#21475;&#32479;&#35745;&#22240;&#32032;&#20998;&#35299;&#30340;&#24314;&#27169;&#65289;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#21033;&#29992;&#26368;&#20808;&#36827;&#30340;NLP&#25216;&#26415;&#20174;&#33258;&#30001;&#25991;&#26412;&#39044;&#27979;&#32467;&#26524;&#65288;&#22312;&#25105;&#20204;&#30340;&#26696;&#20363;&#20013;&#20026;&#27515;&#22240;&#65289;&#36827;&#34892;&#26377;&#25928;&#25512;&#26029;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#23558;&#36825;&#31181;&#26041;&#27861;&#31216;&#20026;multiPPI++&#65292;&#23558;&#26368;&#36817;&#30340;&#8220;&#39044;&#27979;&#39537;&#21160;&#25512;&#26029;&#8221;&#24037;&#20316;&#25193;&#23637;&#21040;&#22810;&#39033;&#20998;&#31867;&#12290;&#25105;&#20204;&#21033;&#29992;&#19968;&#31995;&#21015;NLP&#25216;&#26415;&#36827;&#34892;COD&#39044;&#27979;&#65292;&#24182;&#36890;&#36807;&#23545;VA&#25968;&#25454;&#30340;&#23454;&#35777;&#20998;&#26512;&#65292;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02438v1 Announce Type: new  Abstract: In settings where most deaths occur outside the healthcare system, verbal autopsies (VAs) are a common tool to monitor trends in causes of death (COD). VAs are interviews with a surviving caregiver or relative that are used to predict the decedent's COD. Turning VAs into actionable insights for researchers and policymakers requires two steps (i) predicting likely COD using the VA interview and (ii) performing inference with predicted CODs (e.g. modeling the breakdown of causes by demographic factors using a sample of deaths). In this paper, we develop a method for valid inference using outcomes (in our case COD) predicted from free-form text using state-of-the-art NLP techniques. This method, which we call multiPPI++, extends recent work in "prediction-powered inference" to multinomial classification. We leverage a suite of NLP techniques for COD prediction and, through empirical analysis of VA data, demonstrate the effectiveness of our 
&lt;/p&gt;</description></item><item><title>&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#21644;&#26399;&#26435;&#38544;&#21547;&#20449;&#24687;&#25913;&#36827;&#22810;&#36164;&#20135;&#26399;&#26435;&#30340;&#26080;&#27169;&#22411;&#19978;&#30028;&#35745;&#31639;&#26041;&#27861;</title><link>https://arxiv.org/abs/2404.02343</link><description>&lt;p&gt;
&#21033;&#29992;&#26399;&#26435;&#38544;&#21547;&#20449;&#24687;&#21644;&#28145;&#24230;&#23398;&#20064;&#25913;&#36827;&#22810;&#36164;&#20135;&#26399;&#26435;&#30340;&#26080;&#27169;&#22411;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Improved model-free bounds for multi-asset options using option-implied information and deep learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02343
&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#21644;&#26399;&#26435;&#38544;&#21547;&#20449;&#24687;&#25913;&#36827;&#22810;&#36164;&#20135;&#26399;&#26435;&#30340;&#26080;&#27169;&#22411;&#19978;&#30028;&#35745;&#31639;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#23558;&#20381;&#36182;&#24615;&#19981;&#30830;&#23450;&#24615;&#19982;&#26377;&#20851;&#20381;&#36182;&#32467;&#26500;&#30340;&#39069;&#22806;&#20449;&#24687;&#30456;&#32467;&#21512;&#30340;&#24773;&#20917;&#19979;&#35745;&#31639;&#22810;&#36164;&#20135;&#26399;&#26435;&#30340;&#26080;&#27169;&#22411;&#30028;&#38480;&#12290; &#26356;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#36793;&#38469;&#20998;&#24067;&#24050;&#30693;&#19988;&#24066;&#22330;&#19978;&#20063;&#26377;&#22810;&#36164;&#20135;&#26399;&#26435;&#20215;&#26684;&#30340;&#37096;&#20998;&#20449;&#24687;&#30340;&#24773;&#24418;&#12290; &#25105;&#20204;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#32473;&#20986;&#20102;&#36164;&#20135;&#23450;&#20215;&#30340;&#22522;&#26412;&#23450;&#29702;&#65292;&#20197;&#21450;&#19968;&#31181;&#36229;&#23545;&#20914;&#23545;&#20598;&#65292;&#33021;&#22815;&#23558;&#22312;&#27010;&#29575;&#24230;&#37327;&#19978;&#30340;&#26368;&#22823;&#21270;&#38382;&#39064;&#36716;&#21270;&#20026;&#22312;&#20132;&#26131;&#31574;&#30053;&#19978;&#30340;&#26356;&#26131;&#22788;&#29702;&#30340;&#26368;&#23567;&#21270;&#38382;&#39064;&#12290; &#21518;&#32773;&#26159;&#36890;&#36807;&#32467;&#21512;&#32602;&#27454;&#26041;&#27861;&#21644;&#20511;&#21161;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#30340;&#28145;&#24230;&#23398;&#20064;&#36924;&#36817;&#26469;&#35299;&#20915;&#30340;&#12290; &#25968;&#20540;&#26041;&#27861;&#24555;&#36895;&#65292;&#24182;&#19988;&#35745;&#31639;&#26102;&#38388;&#19982;&#20132;&#26131;&#36164;&#20135;&#25968;&#37327;&#25104;&#32447;&#24615;&#27604;&#20363;&#12290; &#26368;&#21518;&#65292;&#25105;&#20204;&#26816;&#39564;&#20102;&#21508;&#31181;&#39069;&#22806;&#20449;&#24687;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02343v1 Announce Type: cross  Abstract: We consider the computation of model-free bounds for multi-asset options in a setting that combines dependence uncertainty with additional information on the dependence structure. More specifically, we consider the setting where the marginal distributions are known and partial information, in the form of known prices for multi-asset options, is also available in the market. We provide a fundamental theorem of asset pricing in this setting, as well as a superhedging duality that allows to transform the maximization problem over probability measures in a more tractable minimization problem over trading strategies. The latter is solved using a penalization approach combined with a deep learning approximation using artificial neural networks. The numerical method is fast and the computational time scales linearly with respect to the number of traded assets. We finally examine the significance of various pieces of additional information. Em
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#26356;&#24378;&#30340;&#24179;&#22343;&#24773;&#20917;&#35745;&#31639;&#20998;&#31163;&#65292;&#23545;&#20110;&#8220;&#20856;&#22411;&#8221;&#24773;&#20917;&#19979;&#30340;&#23398;&#20064;&#20219;&#21153;&#23454;&#20363;&#65292;&#21333;&#27169;&#24577;&#23398;&#20064;&#22312;&#35745;&#31639;&#19978;&#26159;&#22256;&#38590;&#30340;&#65292;&#20294;&#22810;&#27169;&#24577;&#23398;&#20064;&#21364;&#24456;&#23481;&#26131;&#12290;</title><link>https://arxiv.org/abs/2404.02254</link><description>&lt;p&gt;
&#20851;&#20110;&#22810;&#27169;&#24577;&#19982;&#21333;&#27169;&#24577;&#26426;&#22120;&#23398;&#20064;&#20043;&#38388;&#26356;&#24378;&#30340;&#35745;&#31639;&#20998;&#31163;
&lt;/p&gt;
&lt;p&gt;
On Stronger Computational Separations Between Multimodal and Unimodal Machine Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02254
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#26356;&#24378;&#30340;&#24179;&#22343;&#24773;&#20917;&#35745;&#31639;&#20998;&#31163;&#65292;&#23545;&#20110;&#8220;&#20856;&#22411;&#8221;&#24773;&#20917;&#19979;&#30340;&#23398;&#20064;&#20219;&#21153;&#23454;&#20363;&#65292;&#21333;&#27169;&#24577;&#23398;&#20064;&#22312;&#35745;&#31639;&#19978;&#26159;&#22256;&#38590;&#30340;&#65292;&#20294;&#22810;&#27169;&#24577;&#23398;&#20064;&#21364;&#24456;&#23481;&#26131;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22810;&#27169;&#24577;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#23558;&#22810;&#31181;&#25968;&#25454;&#27169;&#24577;&#65288;&#20363;&#22914;&#25991;&#26412;&#21644;&#22270;&#20687;&#65289;&#32467;&#21512;&#36215;&#26469;&#20197;&#20419;&#36827;&#26356;&#22909;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#23398;&#20064;&#65292;&#36825;&#20173;&#28982;&#36866;&#29992;&#20110;&#30456;&#24212;&#30340;&#21333;&#27169;&#24577;&#20219;&#21153;&#65288;&#20363;&#22914;&#25991;&#26412;&#29983;&#25104;&#65289;&#12290;&#26368;&#36817;&#65292;&#22810;&#27169;&#24577;&#26426;&#22120;&#23398;&#20064;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#32463;&#39564;&#25104;&#21151;&#65288;&#20363;&#22914;GPT-4&#65289;&#12290;&#21463;&#21040;&#20026;&#36825;&#31181;&#32463;&#39564;&#25104;&#21151;&#24320;&#21457;&#29702;&#35770;&#22522;&#30784;&#30340;&#21160;&#26426;&#65292;Lu&#65288;NeurIPS '23&#65292;ALT '24&#65289;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#27169;&#24577;&#23398;&#20064;&#29702;&#35770;&#65292;&#24182;&#32771;&#34385;&#20102;&#22810;&#27169;&#24577;&#21644;&#21333;&#27169;&#24577;&#23398;&#20064;&#30340;&#29702;&#35770;&#27169;&#22411;&#20043;&#38388;&#21487;&#33021;&#30340;&#20998;&#31163;&#12290;&#29305;&#21035;&#26159;Lu&#65288;ALT '24&#65289;&#23637;&#31034;&#20102;&#19968;&#31181;&#35745;&#31639;&#20998;&#31163;&#65292;&#36825;&#23545;&#23398;&#20064;&#20219;&#21153;&#30340;&#26368;&#22351;&#24773;&#20917;&#23454;&#20363;&#26159;&#30456;&#20851;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02254v1 Announce Type: cross  Abstract: In multimodal machine learning, multiple modalities of data (e.g., text and images) are combined to facilitate the learning of a better machine learning model, which remains applicable to a corresponding unimodal task (e.g., text generation). Recently, multimodal machine learning has enjoyed huge empirical success (e.g. GPT-4). Motivated to develop theoretical justification for this empirical success, Lu (NeurIPS '23, ALT '24) introduces a theory of multimodal learning, and considers possible separations between theoretical models of multimodal and unimodal learning. In particular, Lu (ALT '24) shows a computational separation, which is relevant to worst-case instances of the learning task.   In this paper, we give a stronger average-case computational separation, where for "typical" instances of the learning task, unimodal learning is computationally hard, but multimodal learning is easy. We then question how "organic" the average-cas
&lt;/p&gt;</description></item><item><title>&#35774;&#35745;&#19968;&#31181;&#36866;&#24212;&#19981;&#26029;&#21464;&#21270;&#30340;&#36890;&#20449;&#32422;&#26463;&#30340;&#29305;&#24449;&#21387;&#32553;&#26041;&#26696;&#65292;&#21516;&#26102;&#26368;&#22823;&#21270;&#34701;&#21512;&#20013;&#24515;&#30340;&#25512;&#26029;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2404.02179</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#21644;&#36895;&#29575;&#33258;&#36866;&#24212;&#29305;&#24449;&#21387;&#32553;
&lt;/p&gt;
&lt;p&gt;
Distributed and Rate-Adaptive Feature Compression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02179
&lt;/p&gt;
&lt;p&gt;
&#35774;&#35745;&#19968;&#31181;&#36866;&#24212;&#19981;&#26029;&#21464;&#21270;&#30340;&#36890;&#20449;&#32422;&#26463;&#30340;&#29305;&#24449;&#21387;&#32553;&#26041;&#26696;&#65292;&#21516;&#26102;&#26368;&#22823;&#21270;&#34701;&#21512;&#20013;&#24515;&#30340;&#25512;&#26029;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20998;&#24067;&#24335;&#21644;&#36895;&#29575;&#33258;&#36866;&#24212;&#29305;&#24449;&#21387;&#32553;&#38382;&#39064;&#65292;&#38024;&#23545;&#32447;&#24615;&#22238;&#24402;&#12290;&#19968;&#32452;&#20998;&#24067;&#24335;&#20256;&#24863;&#22120;&#25910;&#38598;&#22238;&#24402;&#22120;&#25968;&#25454;&#30340;&#19981;&#30456;&#20132;&#29305;&#24449;&#12290;&#20551;&#23450;&#34701;&#21512;&#20013;&#24515;&#21253;&#21547;&#19968;&#20010;&#22312;&#25972;&#20010;&#26410;&#21387;&#32553;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#39044;&#35757;&#32451;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#12290;&#22312;&#25512;&#26029;&#26102;&#65292;&#20256;&#24863;&#22120;&#21387;&#32553;&#20854;&#35266;&#27979;&#32467;&#26524;&#65292;&#24182;&#36890;&#36807;&#36890;&#20449;&#21463;&#38480;&#30340;&#20449;&#36947;&#23558;&#20854;&#21457;&#36865;&#21040;&#34701;&#21512;&#20013;&#24515;&#65292;&#36825;&#20123;&#20449;&#36947;&#30340;&#36895;&#29575;&#21487;&#20197;&#38543;&#26102;&#38388;&#21464;&#21270;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#35774;&#35745;&#19968;&#31181;&#33021;&#22815;&#36866;&#24212;&#19981;&#26029;&#21464;&#21270;&#30340;&#36890;&#20449;&#32422;&#26463;&#30340;&#29305;&#24449;&#21387;&#32553;&#26041;&#26696;&#65292;&#21516;&#26102;&#22312;&#34701;&#21512;&#20013;&#24515;&#26368;&#22823;&#21270;&#25512;&#26029;&#24615;&#33021;&#12290;&#25105;&#20204;&#39318;&#20808;&#33719;&#24471;&#20102;&#20551;&#23450;&#20102;&#23545;&#24213;&#23618;&#22238;&#24402;&#22120;&#25968;&#25454;&#20998;&#24067;&#30693;&#35782;&#30340;&#26368;&#20248;&#37327;&#21270;&#22120;&#30340;&#24418;&#24335;&#12290;&#22312;&#19968;&#20010;&#23454;&#38469;&#21512;&#29702;&#30340;&#36817;&#20284;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#23545;&#20256;&#24863;&#22120;&#25968;&#25454;&#30340;&#19968;&#32500;&#25237;&#24433;&#36827;&#34892;&#37327;&#21270;&#24037;&#20316;&#30340;&#20998;&#24067;&#24335;&#21387;&#32553;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02179v1 Announce Type: cross  Abstract: We study the problem of distributed and rate-adaptive feature compression for linear regression. A set of distributed sensors collect disjoint features of regressor data. A fusion center is assumed to contain a pretrained linear regression model, trained on a dataset of the entire uncompressed data. At inference time, the sensors compress their observations and send them to the fusion center through communication-constrained channels, whose rates can change with time. Our goal is to design a feature compression {scheme} that can adapt to the varying communication constraints, while maximizing the inference performance at the fusion center. We first obtain the form of optimal quantizers assuming knowledge of underlying regressor data distribution. Under a practically reasonable approximation, we then propose a distributed compression scheme which works by quantizing a one-dimensional projection of the sensor data. We also propose a simp
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Systemic Quantum Score (SQS)&#30340;&#26032;&#26041;&#27861;&#65292;&#23637;&#31034;&#22312;&#37329;&#34701;&#39046;&#22495;&#29983;&#20135;&#32423;&#24212;&#29992;&#26696;&#20363;&#20013;&#30456;&#27604;&#32431;&#32463;&#20856;&#27169;&#22411;&#26356;&#26377;&#20248;&#21183;&#65292;&#33021;&#22815;&#20174;&#36739;&#23569;&#25968;&#25454;&#28857;&#20013;&#25552;&#21462;&#27169;&#24335;&#24182;&#34920;&#29616;&#20986;&#26356;&#22909;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2404.00015</link><description>&lt;p&gt;
&#21033;&#29992;&#37327;&#23376;&#22686;&#24378;&#26426;&#22120;&#23398;&#20064;&#36171;&#33021;&#20449;&#29992;&#35780;&#20998;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Empowering Credit Scoring Systems with Quantum-Enhanced Machine Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.00015
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Systemic Quantum Score (SQS)&#30340;&#26032;&#26041;&#27861;&#65292;&#23637;&#31034;&#22312;&#37329;&#34701;&#39046;&#22495;&#29983;&#20135;&#32423;&#24212;&#29992;&#26696;&#20363;&#20013;&#30456;&#27604;&#32431;&#32463;&#20856;&#27169;&#22411;&#26356;&#26377;&#20248;&#21183;&#65292;&#33021;&#22815;&#20174;&#36739;&#23569;&#25968;&#25454;&#28857;&#20013;&#25552;&#21462;&#27169;&#24335;&#24182;&#34920;&#29616;&#20986;&#26356;&#22909;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Quantum Kernels&#34987;&#35748;&#20026;&#22312;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#30340;&#26089;&#26399;&#38454;&#27573;&#25552;&#20379;&#20102;&#26377;&#29992;&#24615;&#12290;&#28982;&#32780;&#65292;&#22312;&#21033;&#29992;&#24222;&#22823;&#25968;&#25454;&#38598;&#26102;&#65292;&#39640;&#24230;&#22797;&#26434;&#30340;&#32463;&#20856;&#27169;&#22411;&#24456;&#38590;&#36229;&#36234;&#65292;&#29305;&#21035;&#26159;&#22312;&#29702;&#35299;&#21147;&#26041;&#38754;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#19968;&#26086;&#25968;&#25454;&#31232;&#32570;&#19988;&#20542;&#26012;&#65292;&#32463;&#20856;&#27169;&#22411;&#23601;&#20250;&#36935;&#21040;&#22256;&#38590;&#12290;&#37327;&#23376;&#29305;&#24449;&#31354;&#38388;&#34987;&#39044;&#35745;&#22312;&#36825;&#26679;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#24773;&#26223;&#20013;&#33021;&#22815;&#25214;&#21040;&#26356;&#22909;&#30340;&#25968;&#25454;&#29305;&#24449;&#21644;&#30446;&#26631;&#31867;&#21035;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#26368;&#37325;&#35201;&#30340;&#26159;&#22686;&#24378;&#20102;&#27867;&#21270;&#33021;&#21147;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Systemic Quantum Score (SQS)&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#21021;&#27493;&#32467;&#26524;&#65292;&#34920;&#26126;&#22312;&#37329;&#34701;&#34892;&#19994;&#29983;&#20135;&#32423;&#24212;&#29992;&#26696;&#20363;&#20013;&#65292;SQS&#21487;&#33021;&#27604;&#32431;&#32463;&#20856;&#27169;&#22411;&#20855;&#26377;&#20248;&#21183;&#12290;&#25105;&#20204;&#30340;&#20855;&#20307;&#30740;&#31350;&#34920;&#26126;&#65292;SQS&#33021;&#22815;&#20174;&#36739;&#23569;&#30340;&#25968;&#25454;&#28857;&#20013;&#25552;&#21462;&#20986;&#27169;&#24335;&#65292;&#24182;&#19988;&#22312;&#25968;&#25454;&#38656;&#27714;&#37327;&#22823;&#30340;&#31639;&#27861;&#65288;&#22914;XGBoost&#65289;&#19978;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#24102;&#26469;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.00015v1 Announce Type: cross  Abstract: Quantum Kernels are projected to provide early-stage usefulness for quantum machine learning. However, highly sophisticated classical models are hard to surpass without losing interpretability, particularly when vast datasets can be exploited. Nonetheless, classical models struggle once data is scarce and skewed. Quantum feature spaces are projected to find better links between data features and the target class to be predicted even in such challenging scenarios and most importantly, enhanced generalization capabilities. In this work, we propose a novel approach called Systemic Quantum Score (SQS) and provide preliminary results indicating potential advantage over purely classical models in a production grade use case for the Finance sector. SQS shows in our specific study an increased capacity to extract patterns out of fewer data points as well as improved performance over data-hungry algorithms such as XGBoost, providing advantage i
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340; tamed interactive particle Langevin algorithms&#65288;tIPLA&#65289;&#31867;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#22810;&#39033;&#24335;&#22686;&#38271;&#24773;&#20917;&#19979;&#33719;&#24471;&#31283;&#23450;&#19988;&#20855;&#26377;&#26368;&#20339;&#36895;&#29575;&#30340;&#38750;&#28176;&#36817;&#25910;&#25947;&#35823;&#24046;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2403.19587</link><description>&lt;p&gt;
&#39535;&#26381;&#20132;&#20114;&#24335;&#31890;&#23376; Langevin &#31639;&#27861; -- &#36229;&#32447;&#24615;&#24773;&#20917;
&lt;/p&gt;
&lt;p&gt;
Taming the Interactive Particle Langevin Algorithm -- the superlinear case
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19587
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340; tamed interactive particle Langevin algorithms&#65288;tIPLA&#65289;&#31867;&#31639;&#27861;&#65292;&#33021;&#22815;&#22312;&#22810;&#39033;&#24335;&#22686;&#38271;&#24773;&#20917;&#19979;&#33719;&#24471;&#31283;&#23450;&#19988;&#20855;&#26377;&#26368;&#20339;&#36895;&#29575;&#30340;&#38750;&#28176;&#36817;&#25910;&#25947;&#35823;&#24046;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#22312;&#38543;&#26426;&#20248;&#21270;&#26041;&#38754;&#30340;&#36827;&#23637;&#20135;&#29983;&#20102;&#20132;&#20114;&#24335;&#31890;&#23376; Langevin &#31639;&#27861;&#65288;IPLA&#65289;&#65292;&#35813;&#31639;&#27861;&#21033;&#29992;&#20132;&#20114;&#31890;&#23376;&#31995;&#32479;&#65288;IPS&#65289;&#30340;&#27010;&#24565;&#26469;&#39640;&#25928;&#22320;&#20174;&#36817;&#20284;&#21518;&#39564;&#23494;&#24230;&#20013;&#25277;&#26679;&#12290;&#36825;&#22312;&#26399;&#26395;&#26368;&#22823;&#21270;&#65288;EM&#65289;&#26694;&#26550;&#20013;&#21464;&#24471;&#23588;&#20026;&#20851;&#38190;&#65292;&#20854;&#20013; E &#27493;&#39588;&#22312;&#35745;&#31639;&#19978;&#20855;&#26377;&#25361;&#25112;&#24615;&#29978;&#33267;&#26159;&#38590;&#20197;&#22788;&#29702;&#30340;&#12290;&#23613;&#31649;&#20808;&#21069;&#30340;&#30740;&#31350;&#20391;&#37325;&#20110;&#26799;&#24230;&#26368;&#22810;&#32447;&#24615;&#22686;&#38271;&#30340;&#20984;&#24773;&#20917;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#23558;&#27492;&#26694;&#26550;&#25193;&#23637;&#21040;&#21253;&#25324;&#22810;&#39033;&#24335;&#22686;&#38271;&#12290;&#37319;&#29992;&#39535;&#26381;&#25216;&#26415;&#29983;&#25104;&#26126;&#30830;&#30340;&#31163;&#25955;&#21270;&#26041;&#26696;&#65292;&#20174;&#32780;&#20135;&#29983;&#19968;&#31867;&#31283;&#23450;&#30340;&#12289;&#22312;&#36825;&#31181;&#38750;&#32447;&#24615;&#24773;&#20917;&#19979;&#65292;&#31216;&#20026;&#39535;&#26381;&#20132;&#20114;&#24335;&#31890;&#23376; Langevin &#31639;&#27861;&#65288;tIPLA&#65289;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#33719;&#24471;&#20102;&#26032;&#31867;&#22312; Wasserstein-2 &#36317;&#31163;&#19979;&#30340;&#38750;&#28176;&#36817;&#25910;&#25947;&#35823;&#24046;&#20272;&#35745;&#65292;&#20855;&#26377;&#26368;&#20339;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19587v1 Announce Type: cross  Abstract: Recent advances in stochastic optimization have yielded the interactive particle Langevin algorithm (IPLA), which leverages the notion of interacting particle systems (IPS) to efficiently sample from approximate posterior densities. This becomes particularly crucial within the framework of Expectation-Maximization (EM), where the E-step is computationally challenging or even intractable. Although prior research has focused on scenarios involving convex cases with gradients of log densities that grow at most linearly, our work extends this framework to include polynomial growth. Taming techniques are employed to produce an explicit discretization scheme that yields a new class of stable, under such non-linearities, algorithms which are called tamed interactive particle Langevin algorithms (tIPLA). We obtain non-asymptotic convergence error estimates in Wasserstein-2 distance for the new class under an optimal rate.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#20351;&#29992;&#23545;&#35282;&#36153;&#33293;&#23572;&#20449;&#24687;&#30697;&#38453;&#20272;&#35745;&#22120;&#30340;&#26435;&#34913;&#12290;&#36890;&#36807;&#20998;&#26512;&#21644;&#25968;&#20540;&#30740;&#31350;&#65292;&#21457;&#29616;&#26041;&#24046;&#37327;&#21462;&#20915;&#20110;&#38750;&#32447;&#24615;&#19982;&#19981;&#21516;&#21442;&#25968;&#32452;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24212;&#35813;&#22312;&#20272;&#35745;&#36153;&#33293;&#23572;&#20449;&#24687;&#26102;&#20104;&#20197;&#37325;&#35270;&#12290;</title><link>https://arxiv.org/abs/2402.05379</link><description>&lt;p&gt;
&#23545;&#35282;&#36153;&#33293;&#23572;&#20449;&#24687;&#30697;&#38453;&#20272;&#35745;&#22120;&#30340;&#26435;&#34913;
&lt;/p&gt;
&lt;p&gt;
Tradeoffs of Diagonal Fisher Information Matrix Estimators
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05379
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#20351;&#29992;&#23545;&#35282;&#36153;&#33293;&#23572;&#20449;&#24687;&#30697;&#38453;&#20272;&#35745;&#22120;&#30340;&#26435;&#34913;&#12290;&#36890;&#36807;&#20998;&#26512;&#21644;&#25968;&#20540;&#30740;&#31350;&#65292;&#21457;&#29616;&#26041;&#24046;&#37327;&#21462;&#20915;&#20110;&#38750;&#32447;&#24615;&#19982;&#19981;&#21516;&#21442;&#25968;&#32452;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24212;&#35813;&#22312;&#20272;&#35745;&#36153;&#33293;&#23572;&#20449;&#24687;&#26102;&#20104;&#20197;&#37325;&#35270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36153;&#33293;&#23572;&#20449;&#24687;&#30697;&#38453;&#25551;&#36848;&#20102;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#31354;&#38388;&#20013;&#30340;&#23616;&#37096;&#20960;&#20309;&#24615;&#36136;&#65292;&#23427;&#25552;&#20379;&#20102;&#29702;&#35770;&#21644;&#24037;&#20855;&#26469;&#29702;&#35299;&#21644;&#20248;&#21270;&#31070;&#32463;&#32593;&#32476;&#12290;&#37492;&#20110;&#20854;&#35745;&#31639;&#25104;&#26412;&#39640;&#65292;&#23454;&#36341;&#32773;&#36890;&#24120;&#20351;&#29992;&#38543;&#26426;&#20272;&#35745;&#22120;&#65292;&#24182;&#20165;&#35780;&#20272;&#23545;&#35282;&#32447;&#26465;&#30446;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#31181;&#36825;&#26679;&#30340;&#20272;&#35745;&#22120;&#65292;&#20854;&#20934;&#30830;&#24615;&#21644;&#26679;&#26412;&#22797;&#26434;&#24615;&#21462;&#20915;&#20110;&#23427;&#20204;&#20851;&#32852;&#30340;&#26041;&#24046;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#26041;&#24046;&#30340;&#30028;&#38480;&#65292;&#24182;&#22312;&#22238;&#24402;&#21644;&#20998;&#31867;&#32593;&#32476;&#20013;&#23454;&#20363;&#21270;&#23427;&#20204;&#12290;&#25105;&#20204;&#36890;&#36807;&#20998;&#26512;&#21644;&#25968;&#20540;&#30740;&#31350;&#26469;&#26435;&#34913;&#36825;&#20004;&#20010;&#20272;&#35745;&#22120;&#12290;&#25105;&#20204;&#21457;&#29616;&#26041;&#24046;&#37327;&#21462;&#20915;&#20110;&#20851;&#20110;&#19981;&#21516;&#21442;&#25968;&#32452;&#30340;&#38750;&#32447;&#24615;&#65292;&#24403;&#20272;&#35745;&#36153;&#33293;&#23572;&#20449;&#24687;&#26102;&#19981;&#33021;&#24573;&#35270;&#23427;&#20204;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Fisher information matrix characterizes the local geometry in the parameter space of neural networks. It elucidates insightful theories and useful tools to understand and optimize neural networks. Given its high computational cost, practitioners often use random estimators and evaluate only the diagonal entries. We examine two such estimators, whose accuracy and sample complexity depend on their associated variances. We derive bounds of the variances and instantiate them in regression and classification networks. We navigate trade-offs of both estimators based on analytical and numerical studies. We find that the variance quantities depend on the non-linearity with respect to different parameter groups and should not be neglected when estimating the Fisher information.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#27491;&#21017;&#21270;&#23545;&#27604;&#24230;&#34920;&#31034;&#23398;&#20064;&#19990;&#30028;&#27169;&#22411;&#65292;&#35813;&#26041;&#27861;&#25552;&#39640;&#20102;&#26679;&#26412;&#25928;&#29575;&#21644;&#27867;&#21270;&#24615;&#33021;&#65292;&#35299;&#20915;&#20102;&#22312;&#35270;&#35273;&#23548;&#33322;&#31561;&#26085;&#24120;&#20219;&#21153;&#20013;&#20986;&#29616;&#22806;&#35266;&#21464;&#21270;&#26102;&#30340;&#25361;&#25112;&#12290;</title><link>https://arxiv.org/abs/2312.09056</link><description>&lt;p&gt;
ReCoRe: &#27491;&#21017;&#21270;&#23545;&#27604;&#24230;&#34920;&#31034;&#23398;&#20064;&#30340;&#19990;&#30028;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
ReCoRe: Regularized Contrastive Representation Learning of World Model
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.09056
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#27491;&#21017;&#21270;&#23545;&#27604;&#24230;&#34920;&#31034;&#23398;&#20064;&#19990;&#30028;&#27169;&#22411;&#65292;&#35813;&#26041;&#27861;&#25552;&#39640;&#20102;&#26679;&#26412;&#25928;&#29575;&#21644;&#27867;&#21270;&#24615;&#33021;&#65292;&#35299;&#20915;&#20102;&#22312;&#35270;&#35273;&#23548;&#33322;&#31561;&#26085;&#24120;&#20219;&#21153;&#20013;&#20986;&#29616;&#22806;&#35266;&#21464;&#21270;&#26102;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#30340;&#26080;&#27169;&#22411;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#26041;&#27861;&#22312;&#28216;&#25103;&#29615;&#22659;&#20013;&#24050;&#32463;&#23637;&#31034;&#20986;&#19982;&#20154;&#31867;&#27700;&#24179;&#30456;&#24403;&#30340;&#26377;&#25928;&#24615;&#65292;&#20294;&#22312;&#35270;&#35273;&#23548;&#33322;&#31561;&#26085;&#24120;&#20219;&#21153;&#20013;&#30340;&#25104;&#21151;&#21463;&#21040;&#38480;&#21046;&#65292;&#29305;&#21035;&#26159;&#22312;&#20986;&#29616;&#26174;&#33879;&#22806;&#35266;&#21464;&#21270;&#30340;&#24773;&#20917;&#19979;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#19990;&#30028;&#27169;&#22411;&#65292;&#36890;&#36807;&#65288;i&#65289;&#23545;&#27604;&#24230;&#26080;&#30417;&#30563;&#23398;&#20064;&#21644;&#65288;ii&#65289;&#20171;&#20837;&#19981;&#21464;&#27491;&#21017;&#21270;&#26469;&#23398;&#20064;&#19981;&#21464;&#29305;&#24449;&#12290;&#23398;&#20064;&#19990;&#30028;&#21160;&#21147;&#23398;&#30340;&#26174;&#24335;&#34920;&#31034;&#65292;&#21363;&#19990;&#30028;&#27169;&#22411;&#65292;&#25552;&#39640;&#20102;&#26679;&#26412;&#25928;&#29575;&#65292;&#32780;&#23545;&#27604;&#24230;&#23398;&#20064;&#38544;&#21547;&#22320;&#24378;&#21270;&#20102;&#23398;&#20064;&#19981;&#21464;&#29305;&#24449;&#65292;&#25913;&#21892;&#20102;&#27867;&#21270;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#31616;&#21333;&#22320;&#23558;&#23545;&#27604;&#24230;&#25439;&#22833;&#38598;&#25104;&#21040;&#19990;&#30028;&#27169;&#22411;&#20013;&#26159;&#19981;&#22815;&#30340;&#65292;&#22240;&#20026;&#22522;&#20110;&#19990;&#30028;&#27169;&#22411;&#30340;RL&#26041;&#27861;&#29420;&#31435;&#20248;&#21270;&#34920;&#31034;&#23398;&#20064;&#21644;&#26234;&#33021;&#20307;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.09056v2 Announce Type: replace-cross  Abstract: While recent model-free Reinforcement Learning (RL) methods have demonstrated human-level effectiveness in gaming environments, their success in everyday tasks like visual navigation has been limited, particularly under significant appearance variations. This limitation arises from (i) poor sample efficiency and (ii) over-fitting to training scenarios. To address these challenges, we present a world model that learns invariant features using (i) contrastive unsupervised learning and (ii) an intervention-invariant regularizer. Learning an explicit representation of the world dynamics i.e. a world model, improves sample efficiency while contrastive learning implicitly enforces learning of invariant features, which improves generalization. However, the na\"ive integration of contrastive loss to world models is not good enough, as world-model-based RL methods independently optimize representation learning and agent policy. To overc
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;KL&#26465;&#20214;&#19979;&#20855;&#26377;&#26368;&#20248;&#36895;&#29575;&#30340;&#24046;&#20998;&#31169;&#26377;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#38024;&#23545;&#19981;&#21516;&#24773;&#20917;&#30340;&#26032;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#25509;&#36817;&#26368;&#20248;&#30340;&#36895;&#29575;&#12290;</title><link>https://arxiv.org/abs/2311.13447</link><description>&lt;p&gt;
&#22312;KL&#26465;&#20214;&#19979;&#20855;&#26377;&#26368;&#20248;&#36895;&#29575;&#30340;&#24046;&#20998;&#31169;&#26377;&#38750;&#20984;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Non-Convex Optimization under the KL Condition with Optimal Rates
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.13447
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;KL&#26465;&#20214;&#19979;&#20855;&#26377;&#26368;&#20248;&#36895;&#29575;&#30340;&#24046;&#20998;&#31169;&#26377;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#38024;&#23545;&#19981;&#21516;&#24773;&#20917;&#30340;&#26032;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#25509;&#36817;&#26368;&#20248;&#30340;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#28385;&#36275;$(\gamma,\kappa)$-Kurdyka-Lojasiewicz (KL)&#26465;&#20214;&#30340;&#25439;&#22833;&#20989;&#25968;&#30340;&#31169;&#26377;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;ERM&#65289;&#38382;&#39064;&#12290;Polyak-Lojasiewicz (PL)&#26465;&#20214;&#26159;&#36825;&#20010;&#26465;&#20214;&#30340;&#29305;&#20363;&#65292;&#24403;$\kappa=2$&#26102;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;$\rho$&#38646;&#38598;&#20013;&#24046;&#20998;&#38544;&#31169;&#65288;zCDP&#65289;&#32422;&#26463;&#19979;&#30340;&#38382;&#39064;&#12290;&#24403;$\kappa\in[1,2]$&#19988;&#25439;&#22833;&#20989;&#25968;&#22312;&#36275;&#22815;&#22823;&#30340;&#21306;&#22495;&#20869;&#26159;Lipschitz&#21644;&#20809;&#28369;&#30340;&#26102;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26041;&#24046;&#20943;&#23569;&#26799;&#24230;&#19979;&#38477;&#30340;&#26032;&#31639;&#27861;&#65292;&#20854;&#22312;&#36229;&#39069;&#32463;&#39564;&#39118;&#38505;&#19978;&#23454;&#29616;&#20102;&#36895;&#29575;$\tilde{O}\big(\big(\frac{\sqrt{d}}{n\sqrt{\rho}}\big)^\kappa\big)$&#65292;&#20854;&#20013;$n$&#26159;&#25968;&#25454;&#38598;&#22823;&#23567;&#65292;$d$&#26159;&#32500;&#24230;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23637;&#31034;&#20102;&#36825;&#20010;&#36895;&#29575;&#20960;&#20046;&#26159;&#26368;&#20248;&#30340;&#12290;&#24403;$\kappa \geq 2$&#19988;&#25439;&#22833;&#20989;&#25968;&#20195;&#26367;&#26159;Lipschitz&#21644;&#24369;&#20984;&#26102;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#36807;&#31169;&#26377;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;&#36895;&#29575;$\tilde{O}\big(\big(\frac{\sqrt{d}}{n\sqrt{\rho}}\big)^\kappa\big)$&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.13447v2 Announce Type: replace  Abstract: We study private empirical risk minimization (ERM) problem for losses satisfying the $(\gamma,\kappa)$-Kurdyka-{\L}ojasiewicz (KL) condition. The Polyak-{\L}ojasiewicz (PL) condition is a special case of this condition when $\kappa=2$. Specifically, we study this problem under the constraint of $\rho$ zero-concentrated differential privacy (zCDP). When $\kappa\in[1,2]$ and the loss function is Lipschitz and smooth over a sufficiently large region, we provide a new algorithm based on variance reduced gradient descent that achieves the rate $\tilde{O}\big(\big(\frac{\sqrt{d}}{n\sqrt{\rho}}\big)^\kappa\big)$ on the excess empirical risk, where $n$ is the dataset size and $d$ is the dimension. We further show that this rate is nearly optimal. When $\kappa \geq 2$ and the loss is instead Lipschitz and weakly convex, we show it is possible to achieve the rate $\tilde{O}\big(\big(\frac{\sqrt{d}}{n\sqrt{\rho}}\big)^\kappa\big)$ with a privat
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#39044;&#27979;MDP&#31574;&#30053;&#36798;&#21040;&#29992;&#25143;&#25351;&#23450;&#34892;&#20026;&#30446;&#26631;&#27010;&#29575;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#23545;&#31526;&#21512;&#39044;&#27979;&#36827;&#34892;&#21453;&#36716;&#26469;&#35745;&#31639;&#27010;&#29575;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2211.16462</link><description>&lt;p&gt;
&#25105;&#30340;&#26426;&#22120;&#20154;&#20250;&#23454;&#29616;&#25105;&#30340;&#30446;&#26631;&#21527;&#65311;&#39044;&#27979;MDP&#31574;&#30053;&#36798;&#21040;&#29992;&#25143;&#25351;&#23450;&#34892;&#20026;&#30446;&#26631;&#30340;&#27010;&#29575;
&lt;/p&gt;
&lt;p&gt;
Will My Robot Achieve My Goals? Predicting the Probability that an MDP Policy Reaches a User-Specified Behavior Target
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2211.16462
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#39044;&#27979;MDP&#31574;&#30053;&#36798;&#21040;&#29992;&#25143;&#25351;&#23450;&#34892;&#20026;&#30446;&#26631;&#27010;&#29575;&#30340;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#23545;&#31526;&#21512;&#39044;&#27979;&#36827;&#34892;&#21453;&#36716;&#26469;&#35745;&#31639;&#27010;&#29575;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#33258;&#20027;&#31995;&#32479;&#25191;&#34892;&#20219;&#21153;&#26102;&#65292;&#24212;&#20445;&#25345;&#23545;&#23454;&#29616;&#29992;&#25143;&#30446;&#26631;&#27010;&#29575;&#30340;&#26657;&#20934;&#20272;&#35745;&#12290;&#22914;&#26524;&#35813;&#27010;&#29575;&#20302;&#20110;&#26576;&#20010;&#26399;&#26395;&#27700;&#24179;&#65292;&#24212;&#21521;&#29992;&#25143;&#21457;&#20986;&#35686;&#25253;&#65292;&#20197;&#20415;&#37319;&#21462;&#36866;&#24403;&#24178;&#39044;&#12290;&#26412;&#25991;&#32771;&#34385;&#20102;&#29992;&#25143;&#23558;&#30446;&#26631;&#35268;&#23450;&#20026;&#23454;&#20540;&#24615;&#33021;&#25688;&#35201;&#30340;&#30446;&#26631;&#21306;&#38388;&#30340;&#35774;&#32622;&#65292;&#20363;&#22914;&#22312;&#22266;&#23450;&#26102;&#38388;&#27573;$H$&#20869;&#27979;&#37327;&#30340;&#32047;&#31215;&#22870;&#21169;&#12290;&#22312;&#27599;&#20010;&#26102;&#38388;$t \in \{0, \ldots, H-1\}$&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20250;&#20135;&#29983;&#19968;&#20010;&#26657;&#20934;&#27010;&#29575;&#20272;&#35745;&#65292;&#21363;&#26368;&#32456;&#32047;&#31215;&#22870;&#21169;&#33853;&#22312;&#29992;&#25143;&#25351;&#23450;&#30446;&#26631;&#21306;&#38388;$[y^-,y^+]$&#20869;&#30340;&#27010;&#29575;&#12290;&#21033;&#29992;&#36825;&#19968;&#20272;&#35745;&#65292;&#33258;&#20027;&#31995;&#32479;&#21487;&#20197;&#22312;&#27010;&#29575;&#20302;&#20110;&#25351;&#23450;&#38408;&#20540;&#26102;&#21457;&#20986;&#35686;&#25253;&#12290;&#25105;&#20204;&#36890;&#36807;&#21453;&#36716;&#31526;&#21512;&#39044;&#27979;&#26469;&#35745;&#31639;&#27010;&#29575;&#20272;&#35745;&#12290;&#25105;&#20204;&#30340;&#20986;&#21457;&#28857;&#26159;Romano&#31561;&#20154;&#30340;Quantile Regression (CQR)&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#24212;&#29992;&#20102;spli
&lt;/p&gt;
&lt;p&gt;
arXiv:2211.16462v2 Announce Type: replace  Abstract: As an autonomous system performs a task, it should maintain a calibrated estimate of the probability that it will achieve the user's goal. If that probability falls below some desired level, it should alert the user so that appropriate interventions can be made. This paper considers settings where the user's goal is specified as a target interval for a real-valued performance summary, such as the cumulative reward, measured at a fixed horizon $H$. At each time $t \in \{0, \ldots, H-1\}$, our method produces a calibrated estimate of the probability that the final cumulative reward will fall within a user-specified target interval $[y^-,y^+].$ Using this estimate, the autonomous system can raise an alarm if the probability drops below a specified threshold. We compute the probability estimates by inverting conformal prediction. Our starting point is the Conformalized Quantile Regression (CQR) method of Romano et al., which applies spli
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26799;&#24230;&#30340;&#24178;&#39044;&#30446;&#26631;&#23450;&#20301;&#26041;&#27861;&#65292;GIT&#65292;&#22312;&#22240;&#26524;&#21457;&#29616;&#20013;&#33021;&#22815;&#36890;&#36807;&#20449;&#21495;&#26799;&#24230;&#20272;&#35745;&#22120;&#38477;&#20302;&#24178;&#39044;&#27425;&#25968;&#65292;&#22312;&#20302;&#25968;&#25454;&#37327;&#24773;&#20917;&#19979;&#20248;&#20110;&#31454;&#20105;&#22522;&#32447;&#12290;</title><link>https://arxiv.org/abs/2211.13715</link><description>&lt;p&gt;
&#30456;&#20449;&#24744;&#30340; $\nabla$: &#22522;&#20110;&#26799;&#24230;&#30340;&#24178;&#39044;&#30446;&#26631;&#23450;&#20301;&#29992;&#20110;&#22240;&#26524;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Trust Your $\nabla$: Gradient-based Intervention Targeting for Causal Discovery
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2211.13715
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26799;&#24230;&#30340;&#24178;&#39044;&#30446;&#26631;&#23450;&#20301;&#26041;&#27861;&#65292;GIT&#65292;&#22312;&#22240;&#26524;&#21457;&#29616;&#20013;&#33021;&#22815;&#36890;&#36807;&#20449;&#21495;&#26799;&#24230;&#20272;&#35745;&#22120;&#38477;&#20302;&#24178;&#39044;&#27425;&#25968;&#65292;&#22312;&#20302;&#25968;&#25454;&#37327;&#24773;&#20917;&#19979;&#20248;&#20110;&#31454;&#20105;&#22522;&#32447;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#25968;&#25454;&#20013;&#25512;&#26029;&#22240;&#26524;&#32467;&#26500;&#26159;&#31185;&#23398;&#20013;&#19968;&#39033;&#20855;&#26377;&#22522;&#30784;&#37325;&#35201;&#24615;&#30340;&#25361;&#25112;&#24615;&#20219;&#21153;&#12290;&#35266;&#27979;&#25968;&#25454;&#36890;&#24120;&#19981;&#36275;&#20197;&#21807;&#19968;&#30830;&#23450;&#31995;&#32479;&#30340;&#22240;&#26524;&#32467;&#26500;&#12290;&#34429;&#28982;&#36827;&#34892;&#24178;&#39044;&#65288;&#21363;&#23454;&#39564;&#65289;&#21487;&#20197;&#25913;&#21892;&#21487;&#35782;&#21035;&#24615;&#65292;&#20294;&#36825;&#20123;&#26679;&#26412;&#36890;&#24120;&#38590;&#20197;&#33719;&#24471;&#19988;&#25104;&#26412;&#39640;&#26114;&#12290;&#22240;&#27492;&#65292;&#22240;&#26524;&#21457;&#29616;&#30340;&#23454;&#39564;&#35774;&#35745;&#26041;&#27861;&#26088;&#22312;&#36890;&#36807;&#20272;&#35745;&#26368;&#20855;&#20449;&#24687;&#24615;&#30340;&#24178;&#39044;&#30446;&#26631;&#26469;&#26368;&#23567;&#21270;&#24178;&#39044;&#27425;&#25968;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#26799;&#24230;&#30340;&#24178;&#39044;&#30446;&#26631;&#23450;&#20301;&#26041;&#27861;&#65292;&#31616;&#31216;&#20026;GIT&#65292;&#23427;&#8216;&#30456;&#20449;&#8217;&#20102;&#22522;&#20110;&#26799;&#24230;&#30340;&#22240;&#26524;&#21457;&#29616;&#26694;&#26550;&#30340;&#26799;&#24230;&#20272;&#35745;&#22120;&#65292;&#20197;&#25552;&#20379;&#24178;&#39044;&#37319;&#38598;&#20989;&#25968;&#30340;&#20449;&#21495;&#12290;&#25105;&#20204;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#65292;&#24182;&#35777;&#26126;GIT&#22312;&#20302;&#25968;&#25454;&#37327;&#24773;&#20917;&#19979;&#34920;&#29616;&#19982;&#31454;&#20105;&#22522;&#32447;&#30456;&#24403;&#65292;&#29978;&#33267;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#36229;&#36234;&#23427;&#20204;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2211.13715v4 Announce Type: replace-cross  Abstract: Inferring causal structure from data is a challenging task of fundamental importance in science. Observational data are often insufficient to identify a system's causal structure uniquely. While conducting interventions (i.e., experiments) can improve the identifiability, such samples are usually challenging and expensive to obtain. Hence, experimental design approaches for causal discovery aim to minimize the number of interventions by estimating the most informative intervention target. In this work, we propose a novel Gradient-based Intervention Targeting method, abbreviated GIT, that 'trusts' the gradient estimator of a gradient-based causal discovery framework to provide signals for the intervention acquisition function. We provide extensive experiments in simulated and real-world datasets and demonstrate that GIT performs on par with competitive baselines, surpassing them in the low-data regime.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20840;&#23616;&#21160;&#37327;&#21387;&#32553;&#65288;GMC&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#31232;&#30095;&#36890;&#20449;&#65292;&#19982;&#29616;&#26377;&#30340;&#23616;&#37096;&#21160;&#37327;&#26041;&#27861;&#19981;&#21516;&#65292;GMC&#21033;&#29992;&#20840;&#23616;&#21160;&#37327;&#26469;&#25552;&#39640;&#20998;&#24067;&#24335;&#23398;&#20064;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/1905.12948</link><description>&lt;p&gt;
&#20840;&#23616;&#21160;&#37327;&#21387;&#32553;&#29992;&#20110;&#20998;&#24067;&#24335;&#23398;&#20064;&#20013;&#30340;&#31232;&#30095;&#36890;&#20449;
&lt;/p&gt;
&lt;p&gt;
Global Momentum Compression for Sparse Communication in Distributed Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/1905.12948
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20840;&#23616;&#21160;&#37327;&#21387;&#32553;&#65288;GMC&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#31232;&#30095;&#36890;&#20449;&#65292;&#19982;&#29616;&#26377;&#30340;&#23616;&#37096;&#21160;&#37327;&#26041;&#27861;&#19981;&#21516;&#65292;GMC&#21033;&#29992;&#20840;&#23616;&#21160;&#37327;&#26469;&#25552;&#39640;&#20998;&#24067;&#24335;&#23398;&#20064;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#25968;&#25454;&#30340;&#24555;&#36895;&#22686;&#38271;&#65292;&#20998;&#24067;&#24335;&#21160;&#37327;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;DMSGD&#65289;&#22312;&#20998;&#24067;&#24335;&#23398;&#20064;&#20013;&#24471;&#21040;&#20102;&#24191;&#27867;&#24212;&#29992;&#65292;&#29305;&#21035;&#26159;&#29992;&#20110;&#35757;&#32451;&#22823;&#35268;&#27169;&#28145;&#24230;&#27169;&#22411;&#12290;&#30001;&#20110;&#32593;&#32476;&#30340;&#24310;&#36831;&#21644;&#24102;&#23485;&#26377;&#38480;&#65292;&#36890;&#20449;&#25104;&#20026;&#20998;&#24067;&#24335;&#23398;&#20064;&#30340;&#29942;&#39048;&#12290;&#20351;&#29992;&#31232;&#30095;&#26799;&#24230;&#36827;&#34892;&#36890;&#20449;&#21387;&#32553;&#65292;&#31616;&#31216;&#20026;&#8220;&#31232;&#30095;&#36890;&#20449;&#8221;&#65292;&#24050;&#34987;&#24191;&#27867;&#24212;&#29992;&#20197;&#38477;&#20302;&#36890;&#20449;&#25104;&#26412;&#12290;&#25152;&#26377;&#20851;&#20110;DMSGD&#20013;&#31232;&#30095;&#36890;&#20449;&#30340;&#29616;&#26377;&#24037;&#20316;&#37117;&#20351;&#29992;&#26412;&#22320;&#21160;&#37327;&#65292;&#20854;&#20013;&#21160;&#37327;&#20165;&#32047;&#31215;&#27599;&#20010;&#24037;&#20316;&#32773;&#22312;&#26412;&#22320;&#35745;&#31639;&#30340;&#38543;&#26426;&#26799;&#24230;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#31216;&#20026;\emph{&#20840;&#23616;&#21160;&#37327;&#21387;&#32553;}&#65288;GMC&#65289;&#65292;&#29992;&#20110;&#31232;&#30095;&#36890;&#20449;&#12290;&#19981;&#21516;&#20110;&#29616;&#26377;&#24037;&#20316;&#20013;&#20351;&#29992;&#30340;&#23616;&#37096;&#21160;&#37327;&#65292;GMC&#20351;&#29992;&#20840;&#23616;&#21160;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:1905.12948v3 Announce Type: replace-cross  Abstract: With the rapid growth of data, distributed momentum stochastic gradient descent~(DMSGD) has been widely used in distributed learning, especially for training large-scale deep models. Due to the latency and limited bandwidth of the network, communication has become the bottleneck of distributed learning. Communication compression with sparsified gradient, abbreviated as \emph{sparse communication}, has been widely employed to reduce communication cost. All existing works about sparse communication in DMSGD employ local momentum, in which the momentum only accumulates stochastic gradients computed by each worker locally. In this paper, we propose a novel method, called \emph{\underline{g}}lobal \emph{\underline{m}}omentum \emph{\underline{c}}ompression~(GMC), for sparse communication. Different from existing works that utilize local momentum, GMC utilizes global momentum. Furthermore, to enhance the convergence performance when u
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#22914;&#20309;&#21033;&#29992;&#35270;&#39057;&#39044;&#27979;&#27169;&#22411;&#23454;&#29616;&#22522;&#20110;&#27169;&#22411;&#30340;&#28145;&#24230;RL&#31639;&#27861;SimPLe&#65292;&#22312;Atari&#28216;&#25103;&#20013;&#27604;&#26080;&#27169;&#22411;&#26041;&#27861;&#26356;&#26377;&#25928;&#22320;&#35299;&#20915;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#39564;&#35777;&#20102;&#26032;&#39062;&#27169;&#22411;&#20307;&#31995;&#32467;&#26500;&#22312;&#36825;&#19968;&#32972;&#26223;&#19979;&#21462;&#24471;&#26368;&#20339;&#32467;&#26524;&#12290;</title><link>https://arxiv.org/abs/1903.00374</link><description>&lt;p&gt;
&#22522;&#20110;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#22312;Atari&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Model-Based Reinforcement Learning for Atari
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/1903.00374
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#22914;&#20309;&#21033;&#29992;&#35270;&#39057;&#39044;&#27979;&#27169;&#22411;&#23454;&#29616;&#22522;&#20110;&#27169;&#22411;&#30340;&#28145;&#24230;RL&#31639;&#27861;SimPLe&#65292;&#22312;Atari&#28216;&#25103;&#20013;&#27604;&#26080;&#27169;&#22411;&#26041;&#27861;&#26356;&#26377;&#25928;&#22320;&#35299;&#20915;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#39564;&#35777;&#20102;&#26032;&#39062;&#27169;&#22411;&#20307;&#31995;&#32467;&#26500;&#22312;&#36825;&#19968;&#32972;&#26223;&#19979;&#21462;&#24471;&#26368;&#20339;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#21487;&#20197;&#29992;&#20110;&#20174;&#22270;&#20687;&#35266;&#23519;&#20013;&#23398;&#20064;&#26377;&#25928;&#30340;&#31574;&#30053;&#65292;&#20363;&#22914;Atari&#28216;&#25103;&#65292;&#20294;&#36890;&#24120;&#38656;&#35201;&#38750;&#24120;&#22823;&#37327;&#30340;&#20132;&#20114;&#8212;&#8212;&#23454;&#38469;&#19978;&#65292;&#36828;&#36828;&#36229;&#36807;&#20154;&#31867;&#23398;&#20064;&#30456;&#21516;&#28216;&#25103;&#25152;&#38656;&#30340;&#25968;&#37327;&#12290;&#20154;&#20204;&#26159;&#22914;&#20309;&#22914;&#27492;&#24555;&#36895;&#23398;&#20064;&#30340;&#65311;&#31572;&#26696;&#30340;&#19968;&#37096;&#20998;&#21487;&#33021;&#26159;&#20154;&#20204;&#21487;&#20197;&#23398;&#20064;&#28216;&#25103;&#36816;&#34892;&#30340;&#26041;&#24335;&#65292;&#24182;&#39044;&#27979;&#21738;&#20123;&#21160;&#20316;&#20250;&#20135;&#29983;&#26399;&#26395;&#30340;&#32467;&#26524;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#35270;&#39057;&#39044;&#27979;&#27169;&#22411;&#22914;&#20309;&#20351;&#20195;&#29702;&#33021;&#22815;&#22312;&#27604;&#26080;&#27169;&#22411;&#26041;&#27861;&#20132;&#20114;&#26356;&#23569;&#30340;&#24773;&#20917;&#19979;&#35299;&#20915;Atari&#28216;&#25103;&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;Simulated Policy Learning&#65288;SimPLe&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#22522;&#20110;&#35270;&#39057;&#39044;&#27979;&#27169;&#22411;&#30340;&#23436;&#25972;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#28145;&#24230;RL&#31639;&#27861;&#65292;&#24182;&#23545;&#20960;&#31181;&#27169;&#22411;&#20307;&#31995;&#32467;&#26500;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#21253;&#25324;&#19968;&#20010;&#22312;&#25105;&#20204;&#30340;&#24773;&#22659;&#20013;&#21462;&#24471;&#26368;&#20339;&#32467;&#26524;&#30340;&#26032;&#39062;&#32467;&#26500;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35780;&#20272;&#20102;SimPLe&#22312;100k&#20302;&#25968;&#25454;&#26465;&#20214;&#19979;&#30340;&#19968;&#31995;&#21015;Atari&#28216;&#25103;&#20013;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:1903.00374v5 Announce Type: replace  Abstract: Model-free reinforcement learning (RL) can be used to learn effective policies for complex tasks, such as Atari games, even from image observations. However, this typically requires very large amounts of interaction -- substantially more, in fact, than a human would need to learn the same games. How can people learn so quickly? Part of the answer may be that people can learn how the game works and predict which actions will lead to desirable outcomes. In this paper, we explore how video prediction models can similarly enable agents to solve Atari games with fewer interactions than model-free methods. We describe Simulated Policy Learning (SimPLe), a complete model-based deep RL algorithm based on video prediction models and present a comparison of several model architectures, including a novel architecture that yields the best results in our setting. Our experiments evaluate SimPLe on a range of Atari games in low data regime of 100k
&lt;/p&gt;</description></item><item><title>&#21033;&#29992;&#29616;&#20195;&#25968;&#25454;&#38598;&#20013;&#22823;&#37327;&#20013;&#38388;&#32467;&#26524;&#30340;&#20107;&#23454;&#65292;&#21363;&#20351;&#27809;&#26377;&#21333;&#20010;&#26367;&#20195;&#25351;&#26631;&#28385;&#36275;&#32479;&#35745;&#26367;&#20195;&#26465;&#20214;&#65292;&#20351;&#29992;&#22810;&#20010;&#26367;&#20195;&#25351;&#26631;&#20063;&#21487;&#33021;&#26159;&#26377;&#25928;&#30340;&#12290;</title><link>https://arxiv.org/abs/1603.09326</link><description>&lt;p&gt;
&#21033;&#29992;&#22810;&#20010;&#26367;&#20195;&#25351;&#26631;&#20272;&#35745;&#27835;&#30103;&#25928;&#26524;&#65306;&#26367;&#20195;&#20998;&#25968;&#21644;&#26367;&#20195;&#25351;&#25968;&#30340;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
Estimating Treatment Effects using Multiple Surrogates: The Role of the Surrogate Score and the Surrogate Index
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/1603.09326
&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;&#29616;&#20195;&#25968;&#25454;&#38598;&#20013;&#22823;&#37327;&#20013;&#38388;&#32467;&#26524;&#30340;&#20107;&#23454;&#65292;&#21363;&#20351;&#27809;&#26377;&#21333;&#20010;&#26367;&#20195;&#25351;&#26631;&#28385;&#36275;&#32479;&#35745;&#26367;&#20195;&#26465;&#20214;&#65292;&#20351;&#29992;&#22810;&#20010;&#26367;&#20195;&#25351;&#26631;&#20063;&#21487;&#33021;&#26159;&#26377;&#25928;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20272;&#35745;&#27835;&#30103;&#25928;&#26524;&#38271;&#26399;&#20316;&#29992;&#26159;&#35768;&#22810;&#39046;&#22495;&#24863;&#20852;&#36259;&#30340;&#38382;&#39064;&#12290; &#20272;&#35745;&#27492;&#31867;&#27835;&#30103;&#25928;&#26524;&#30340;&#19968;&#20010;&#24120;&#35265;&#25361;&#25112;&#22312;&#20110;&#38271;&#26399;&#32467;&#26524;&#22312;&#38656;&#35201;&#20570;&#20986;&#25919;&#31574;&#20915;&#31574;&#30340;&#26102;&#38388;&#33539;&#22260;&#20869;&#26159;&#26410;&#35266;&#23519;&#21040;&#30340;&#12290; &#20811;&#26381;&#36825;&#31181;&#32570;&#22833;&#25968;&#25454;&#38382;&#39064;&#30340;&#19968;&#31181;&#26041;&#27861;&#26159;&#20998;&#26512;&#27835;&#30103;&#25928;&#26524;&#23545;&#20013;&#38388;&#32467;&#26524;&#30340;&#24433;&#21709;&#65292;&#36890;&#24120;&#31216;&#20026;&#32479;&#35745;&#26367;&#20195;&#25351;&#26631;&#65292;&#22914;&#26524;&#28385;&#36275;&#26465;&#20214;&#65306;&#22312;&#32479;&#35745;&#26367;&#20195;&#25351;&#26631;&#30340;&#26465;&#20214;&#19979;&#65292;&#27835;&#30103;&#21644;&#32467;&#26524;&#26159;&#29420;&#31435;&#30340;&#12290;  &#26367;&#20195;&#26465;&#20214;&#30340;&#26377;&#25928;&#24615;&#32463;&#24120;&#26159;&#26377;&#20105;&#35758;&#30340;&#12290; &#22312;&#29616;&#20195;&#25968;&#25454;&#38598;&#20013;&#65292;&#30740;&#31350;&#20154;&#21592;&#36890;&#24120;&#35266;&#23519;&#21040;&#22823;&#37327;&#20013;&#38388;&#32467;&#26524;&#65292;&#21487;&#33021;&#26159;&#25968;&#30334;&#20010;&#25110;&#25968;&#21315;&#20010;&#65292;&#34987;&#35748;&#20026;&#20301;&#20110;&#27835;&#30103;&#21644;&#38271;&#26399;&#24863;&#20852;&#36259;&#30340;&#32467;&#26524;&#20043;&#38388;&#30340;&#22240;&#26524;&#38142;&#19978;&#25110;&#38468;&#36817;&#12290; &#21363;&#20351;&#27809;&#26377;&#20010;&#21035;&#20195;&#29702;&#28385;&#36275;&#32479;&#35745;&#26367;&#20195;&#26465;&#20214;&#65292;&#20351;&#29992;&#22810;&#20010;&#20195;&#29702;&#20063;&#21487;&#20197;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:1603.09326v4 Announce Type: replace-cross  Abstract: Estimating the long-term effects of treatments is of interest in many fields. A common challenge in estimating such treatment effects is that long-term outcomes are unobserved in the time frame needed to make policy decisions. One approach to overcome this missing data problem is to analyze treatments effects on an intermediate outcome, often called a statistical surrogate, if it satisfies the condition that treatment and outcome are independent conditional on the statistical surrogate. The validity of the surrogacy condition is often controversial. Here we exploit that fact that in modern datasets, researchers often observe a large number, possibly hundreds or thousands, of intermediate outcomes, thought to lie on or close to the causal chain between the treatment and the long-term outcome of interest. Even if none of the individual proxies satisfies the statistical surrogacy criterion by itself, using multiple proxies can be 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#26679;&#26412;&#36873;&#25321;&#20559;&#24046;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#21033;&#29992;&#38598;&#25104;&#22810;&#26679;&#24615;&#36827;&#34892;&#40065;&#26834;&#30340;&#33258;&#35757;&#32451;&#30340;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#20449;&#24230;&#24230;&#37327;&#26041;&#27861;-$\mathcal{T}$-&#30456;&#20284;&#24230;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#19977;&#31181;&#19981;&#21516;&#20266;&#26631;&#31614;&#31574;&#30053;&#19979;&#20855;&#26377;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.14814</link><description>&lt;p&gt;
&#22312;&#26679;&#26412;&#36873;&#25321;&#20559;&#24046;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#21033;&#29992;&#38598;&#25104;&#22810;&#26679;&#24615;&#36827;&#34892;&#40065;&#26834;&#30340;&#33258;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Leveraging Ensemble Diversity for Robust Self-Training in the Presence of Sample Selection Bias. (arXiv:2310.14814v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14814
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#26679;&#26412;&#36873;&#25321;&#20559;&#24046;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#21033;&#29992;&#38598;&#25104;&#22810;&#26679;&#24615;&#36827;&#34892;&#40065;&#26834;&#30340;&#33258;&#35757;&#32451;&#30340;&#26041;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#20449;&#24230;&#24230;&#37327;&#26041;&#27861;-$\mathcal{T}$-&#30456;&#20284;&#24230;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#19977;&#31181;&#19981;&#21516;&#20266;&#26631;&#31614;&#31574;&#30053;&#19979;&#20855;&#26377;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#35757;&#32451;&#26159;&#21322;&#30417;&#30563;&#23398;&#20064;&#20013;&#19968;&#31181;&#20247;&#25152;&#21608;&#30693;&#30340;&#26041;&#27861;&#12290;&#23427;&#21253;&#25324;&#23545;&#27169;&#22411;&#33258;&#20449;&#24230;&#39640;&#30340;&#26410;&#26631;&#35760;&#25968;&#25454;&#36827;&#34892;&#20266;&#26631;&#31614;&#20998;&#37197;&#65292;&#24182;&#23558;&#20854;&#35270;&#20026;&#26631;&#35760;&#26679;&#26412;&#36827;&#34892;&#22788;&#29702;&#12290;&#23545;&#20110;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#24120;&#20351;&#29992;softmax&#39044;&#27979;&#27010;&#29575;&#20316;&#20026;&#33258;&#20449;&#24230;&#24230;&#37327;&#65292;&#23613;&#31649;&#24050;&#30693;&#23427;&#20204;&#23545;&#38169;&#35823;&#39044;&#27979;&#20063;&#36807;&#20110;&#33258;&#20449;&#12290;&#24403;&#25968;&#25454;&#26631;&#27880;&#21463;&#21040;&#26576;&#31181;&#32422;&#26463;&#26102;&#65292;&#36825;&#31181;&#29616;&#35937;&#23588;&#20026;&#26126;&#26174;&#65292;&#21363;&#26679;&#26412;&#36873;&#25321;&#20559;&#24046;&#23384;&#22312;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33258;&#20449;&#24230;&#24230;&#37327;&#26041;&#27861;&#65292;&#31216;&#20026;$\mathcal{T}$-&#30456;&#20284;&#24230;&#65292;&#23427;&#22522;&#20110;&#32447;&#24615;&#20998;&#31867;&#22120;&#30340;&#38598;&#25104;&#39044;&#27979;&#22810;&#26679;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#30740;&#31350;&#31283;&#23450;&#28857;&#24182;&#25551;&#36848;&#21333;&#20010;&#25104;&#21592;&#30340;&#22810;&#26679;&#24615;&#19982;&#20854;&#24615;&#33021;&#20043;&#38388;&#30340;&#20851;&#31995;&#26469;&#25552;&#20379;&#25105;&#20204;&#26041;&#27861;&#30340;&#29702;&#35770;&#20998;&#26512;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#19977;&#31181;&#19981;&#21516;&#20266;&#26631;&#31614;&#31574;&#30053;&#30340;&#23454;&#39564;&#39564;&#35777;&#20102;&#25105;&#20204;&#33258;&#20449;&#24230;&#24230;&#37327;&#30340;&#22909;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
Self-training is a well-known approach for semi-supervised learning. It consists of iteratively assigning pseudo-labels to unlabeled data for which the model is confident and treating them as labeled examples. For neural networks, softmax prediction probabilities are often used as a confidence measure, despite the fact that they are known to be overconfident, even for wrong predictions. This phenomenon is particularly intensified in the presence of sample selection bias, i.e., when data labeling is subject to some constraint. To address this issue, we propose a novel confidence measure, called $\mathcal{T}$-similarity, built upon the prediction diversity of an ensemble of linear classifiers. We provide the theoretical analysis of our approach by studying stationary points and describing the relationship between the diversity of the individual members and their performance. We empirically demonstrate the benefit of our confidence measure for three different pseudo-labeling policies on c
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29289;&#29702;&#20449;&#24687;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#26694;&#26550;GraPhyR&#65292;&#29992;&#20110;&#35299;&#20915;&#30005;&#21147;&#31995;&#32479;&#30340;&#21160;&#24577;&#37325;&#26500;&#65288;DyR&#65289;&#38382;&#39064;&#12290;&#35813;&#26694;&#26550;&#23558;&#36816;&#33829;&#21644;&#36830;&#25509;&#32422;&#26463;&#30452;&#25509;&#34701;&#20837;GNN&#26694;&#26550;&#20013;&#65292;&#24182;&#36827;&#34892;&#31471;&#21040;&#31471;&#30340;&#35757;&#32451;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#20248;&#21270;DyR&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2310.00728</link><description>&lt;p&gt;
&#22522;&#20110;&#29289;&#29702;&#20449;&#24687;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#30005;&#21147;&#31995;&#32479;&#30340;&#21160;&#24577;&#37325;&#26500;
&lt;/p&gt;
&lt;p&gt;
Physics-Informed Graph Neural Network for Dynamic Reconfiguration of Power Systems. (arXiv:2310.00728v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00728
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29289;&#29702;&#20449;&#24687;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#26694;&#26550;GraPhyR&#65292;&#29992;&#20110;&#35299;&#20915;&#30005;&#21147;&#31995;&#32479;&#30340;&#21160;&#24577;&#37325;&#26500;&#65288;DyR&#65289;&#38382;&#39064;&#12290;&#35813;&#26694;&#26550;&#23558;&#36816;&#33829;&#21644;&#36830;&#25509;&#32422;&#26463;&#30452;&#25509;&#34701;&#20837;GNN&#26694;&#26550;&#20013;&#65292;&#24182;&#36827;&#34892;&#31471;&#21040;&#31471;&#30340;&#35757;&#32451;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#20248;&#21270;DyR&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#20445;&#25345;&#21487;&#38752;&#30340;&#30005;&#32593;&#65292;&#25105;&#20204;&#38656;&#35201;&#24555;&#36895;&#30340;&#20915;&#31574;&#31639;&#27861;&#26469;&#35299;&#20915;&#21160;&#24577;&#37325;&#26500;&#65288;DyR&#65289;&#31561;&#22797;&#26434;&#38382;&#39064;&#12290;DyR&#23454;&#26102;&#20248;&#21270;&#37197;&#30005;&#32593;&#24320;&#20851;&#35774;&#32622;&#65292;&#20197;&#26368;&#23567;&#21270;&#30005;&#32593;&#25439;&#32791;&#65292;&#24182;&#20998;&#27966;&#36164;&#28304;&#20197;&#28385;&#36275;&#21487;&#29992;&#21457;&#30005;&#37327;&#30340;&#36127;&#36733;&#38656;&#27714;&#12290;DyR&#26159;&#19968;&#20010;&#28151;&#21512;&#25972;&#25968;&#38382;&#39064;&#65292;&#23545;&#20110;&#22823;&#35268;&#27169;&#30005;&#32593;&#21644;&#24555;&#36895;&#26102;&#38388;&#23610;&#24230;&#26469;&#35828;&#65292;&#21487;&#33021;&#35745;&#31639;&#38590;&#20197;&#35299;&#20915;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;GraPhyR&#65292;&#19968;&#31181;&#19987;&#20026;DyR&#32780;&#35774;&#35745;&#30340;&#22522;&#20110;&#29289;&#29702;&#20449;&#24687;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#26694;&#26550;&#12290;&#25105;&#20204;&#30452;&#25509;&#23558;&#22522;&#26412;&#30340;&#36816;&#33829;&#21644;&#36830;&#25509;&#32422;&#26463;&#34701;&#20837;&#21040;GNN&#26694;&#26550;&#20013;&#65292;&#24182;&#36827;&#34892;&#31471;&#21040;&#31471;&#30340;&#35757;&#32451;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;GraPhyR&#33021;&#22815;&#23398;&#20064;&#20248;&#21270;DyR&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
To maintain a reliable grid we need fast decision-making algorithms for complex problems like Dynamic Reconfiguration (DyR). DyR optimizes distribution grid switch settings in real-time to minimize grid losses and dispatches resources to supply loads with available generation. DyR is a mixed-integer problem and can be computationally intractable to solve for large grids and at fast timescales. We propose GraPhyR, a Physics-Informed Graph Neural Network (GNNs) framework tailored for DyR. We incorporate essential operational and connectivity constraints directly within the GNN framework and train it end-to-end. Our results show that GraPhyR is able to learn to optimize the DyR task.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#38754;&#21521;&#38543;&#26426;&#32593;&#32476;&#36164;&#28304;&#20998;&#37197;&#30340;&#22312;&#32447;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#20046;&#26368;&#20248;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#35813;&#26041;&#26696;&#22312;&#25968;&#23383;&#27169;&#25311;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>http://arxiv.org/abs/2305.15558</link><description>&lt;p&gt;
&#38754;&#21521;&#24102;&#26377;&#38271;&#26399;&#32422;&#26463;&#30340;&#38543;&#26426;&#32593;&#32476;&#36164;&#28304;&#20998;&#37197;&#30340;&#22312;&#32447;&#20248;&#21270;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Online Optimization for Randomized Network Resource Allocation with Long-Term Constraints. (arXiv:2305.15558v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15558
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#38754;&#21521;&#38543;&#26426;&#32593;&#32476;&#36164;&#28304;&#20998;&#37197;&#30340;&#22312;&#32447;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#20046;&#26368;&#20248;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#35813;&#26041;&#26696;&#22312;&#25968;&#23383;&#27169;&#25311;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#31616;&#21333;&#36890;&#20449;&#32593;&#32476;&#20013;&#30340;&#22312;&#32447;&#36164;&#28304;&#39044;&#30041;&#38382;&#39064;&#12290;&#32593;&#32476;&#30001;&#20004;&#20010;&#35745;&#31639;&#33410;&#28857;&#32452;&#25104;&#65292;&#36890;&#36807;&#26412;&#22320;&#36890;&#20449;&#38142;&#36335;&#36830;&#25509;&#12290;&#31995;&#32479;&#22312;&#31163;&#25955;&#26102;&#38388;&#20869;&#36816;&#34892;&#65307;&#22312;&#27599;&#20010;&#26102;&#38388;&#27573;&#65292;&#31649;&#29702;&#21592;&#20250;&#22312;&#23454;&#38469;&#20316;&#19994;&#35831;&#27714;&#20043;&#21069;&#20026;&#26381;&#21153;&#22120;&#39044;&#30041;&#36164;&#28304;&#65292;&#36825;&#20123;&#39044;&#30041;&#20250;&#20135;&#29983;&#25104;&#26412;&#12290;&#28982;&#21518;&#65292;&#22312;&#35266;&#23519;&#21040;&#23458;&#25143;&#31471;&#35831;&#27714;&#20043;&#21518;&#65292;&#20316;&#19994;&#21487;&#33021;&#20250;&#20174;&#19968;&#20010;&#26381;&#21153;&#22120;&#36716;&#31227;&#21040;&#21478;&#19968;&#20010;&#26381;&#21153;&#22120;&#65292;&#20197;&#26368;&#22909;&#22320;&#36866;&#24212;&#38656;&#27714;&#65292;&#20294;&#36825;&#20250;&#20135;&#29983;&#39069;&#22806;&#30340;&#20256;&#36755;&#25104;&#26412;&#12290;&#22914;&#26524;&#26080;&#27861;&#28385;&#36275;&#26576;&#20123;&#20316;&#19994;&#35831;&#27714;&#65292;&#21017;&#20250;&#20135;&#29983;&#36829;&#35268;&#25104;&#26412;&#65292;&#38656;&#35201;&#20026;&#27599;&#20010;&#34987;&#38459;&#27490;&#30340;&#20316;&#19994;&#25903;&#20184;&#25104;&#26412;&#12290;&#30446;&#26631;&#26159;&#22312;&#26377;&#38480;&#30340;&#26102;&#38388;&#20869;&#26368;&#23567;&#21270;&#24635;&#39044;&#35746;&#25104;&#26412;&#65292;&#21516;&#26102;&#22312;&#19968;&#23450;&#39044;&#31639;&#38480;&#21046;&#19979;&#32500;&#25252;&#32047;&#31215;&#36829;&#35268;&#21644;&#20256;&#36755;&#25104;&#26412;&#12290;&#20026;&#20102;&#30740;&#31350;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#23558;&#20854;&#24418;&#24335;&#21270;&#20026;&#19968;&#20010;&#21453;&#22797;&#21338;&#24328;&#38382;&#39064;&#65292;&#38024;&#23545;&#19968;&#31995;&#21015;&#25552;&#35758;&#30340;&#31574;&#30053;&#25353;&#38543;&#26426;&#39034;&#24207;&#36827;&#34892;&#39044;&#35746;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#22312;&#32447;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21487;&#20197;&#23454;&#29616;&#25509;&#36817;&#26368;&#20248;&#30340;&#24615;&#33021;&#20445;&#35777;&#65292;&#20197;&#26399;&#26395;&#30340;&#24635;&#25104;&#26412;&#20026;&#22522;&#30784;&#65292;&#20026;&#20219;&#20309;&#26377;&#38480;&#30340;T&#26102;&#38388;&#27573;&#12290;&#25968;&#23383;&#27169;&#25311;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#20248;&#20110;&#20960;&#31181;&#22522;&#32447;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study an optimal online resource reservation problem in a simple communication network. The network is composed of two compute nodes linked by a local communication link. The system operates in discrete time; at each time slot, the administrator reserves resources for servers before the actual job requests are known. A cost is incurred for the reservations made. Then, after the client requests are observed, jobs may be transferred from one server to the other to best accommodate the demands by incurring an additional transport cost. If certain job requests cannot be satisfied, there is a violation that engenders a cost to pay for each of the blocked jobs. The goal is to minimize the overall reservation cost over finite horizons while maintaining the cumulative violation and transport costs under a certain budget limit. To study this problem, we first formalize it as a repeated game against nature where the reservations are drawn randomly according to a sequence of pro
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20197;&#24179;&#28369;&#30340;&#35282;&#24230;&#24341;&#20837;&#20102;Shapley&#26354;&#32447;&#20316;&#20026;&#23616;&#37096;&#21464;&#37327;&#37325;&#35201;&#24615;&#30340;&#24230;&#37327;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#20272;&#35745;&#31574;&#30053;&#65292;&#24182;&#22312;&#29305;&#24449;&#30340;&#29420;&#31435;&#21644;&#20381;&#36182;&#24773;&#20917;&#19979;&#24471;&#21040;&#20102;&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24577;&#24615;&#65292;&#20026;&#20272;&#35745;&#30340;Shapley&#26354;&#32447;&#26500;&#24314;&#20102;&#32622;&#20449;&#21306;&#38388;&#24182;&#36827;&#34892;&#20102;&#25512;&#26029;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#23454;&#20102;&#28176;&#36817;&#32467;&#26524;&#12290;&#24212;&#29992;&#20013;&#20998;&#26512;&#20102;&#21738;&#20123;&#23646;&#24615;&#39537;&#21160;&#36710;&#36742;&#20215;&#26684;&#12290;</title><link>http://arxiv.org/abs/2211.13289</link><description>&lt;p&gt;
Shapley&#26354;&#32447;&#65306;&#19968;&#31181;&#24179;&#28369;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Shapley Curves: A Smoothing Perspective. (arXiv:2211.13289v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.13289
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20197;&#24179;&#28369;&#30340;&#35282;&#24230;&#24341;&#20837;&#20102;Shapley&#26354;&#32447;&#20316;&#20026;&#23616;&#37096;&#21464;&#37327;&#37325;&#35201;&#24615;&#30340;&#24230;&#37327;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#20272;&#35745;&#31574;&#30053;&#65292;&#24182;&#22312;&#29305;&#24449;&#30340;&#29420;&#31435;&#21644;&#20381;&#36182;&#24773;&#20917;&#19979;&#24471;&#21040;&#20102;&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24577;&#24615;&#65292;&#20026;&#20272;&#35745;&#30340;Shapley&#26354;&#32447;&#26500;&#24314;&#20102;&#32622;&#20449;&#21306;&#38388;&#24182;&#36827;&#34892;&#20102;&#25512;&#26029;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#23454;&#20102;&#28176;&#36817;&#32467;&#26524;&#12290;&#24212;&#29992;&#20013;&#20998;&#26512;&#20102;&#21738;&#20123;&#23646;&#24615;&#39537;&#21160;&#36710;&#36742;&#20215;&#26684;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28304;&#33258;&#21512;&#20316;&#21338;&#24328;&#29702;&#35770;&#65292;Shapley&#20540;&#24050;&#25104;&#20026;&#24212;&#29992;&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#24191;&#27867;&#20351;&#29992;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#24230;&#37327;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#23545;Shapley&#20540;&#30340;&#32479;&#35745;&#29702;&#35299;&#20173;&#28982;&#26377;&#38480;&#12290;&#26412;&#25991;&#20197;&#38750;&#21442;&#25968;(&#25110;&#24179;&#28369;)&#30340;&#35282;&#24230;&#65292;&#24341;&#20837;Shapley&#26354;&#32447;&#20316;&#20026;&#23616;&#37096;&#21464;&#37327;&#37325;&#35201;&#24615;&#30340;&#24230;&#37327;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#20272;&#35745;&#31574;&#30053;&#65292;&#24182;&#22312;&#29305;&#24449;&#29420;&#31435;&#21644;&#20381;&#36182;&#30340;&#24773;&#20917;&#19979;&#37117;&#24471;&#20986;&#20102;&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;&#36825;&#26679;&#65292;&#25105;&#20204;&#21487;&#20197;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#24182;&#23545;&#20272;&#35745;&#30340;Shapley&#26354;&#32447;&#36827;&#34892;&#25512;&#26029;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#37326;&#34542;&#24341;&#23548;&#31243;&#24207;&#29256;&#26412;&#65292;&#19987;&#38376;&#35843;&#25972;&#20197;&#33719;&#24471;Shapley&#26354;&#32447;&#30340;&#33391;&#22909;&#26377;&#38480;&#26679;&#26412;&#35206;&#30422;&#12290;&#28176;&#36817;&#32467;&#26524;&#22312;&#22823;&#37327;&#23454;&#39564;&#35777;&#23454;&#20102;&#12290;&#22312;&#23454;&#35777;&#24212;&#29992;&#20013;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#21738;&#20123;&#23646;&#24615;&#39537;&#21160;&#20102;&#36710;&#36742;&#30340;&#20215;&#26684;&#12290;
&lt;/p&gt;
&lt;p&gt;
Originating from cooperative game theory, Shapley values have become one of the most widely used measures for variable importance in applied Machine Learning. However, the statistical understanding of Shapley values is still limited. In this paper, we take a nonparametric (or smoothing) perspective by introducing Shapley curves as a local measure of variable importance. We propose two estimation strategies and derive the consistency and asymptotic normality both under independence and dependence among the features. This allows us to construct confidence intervals and conduct inference on the estimated Shapley curves. We propose a novel version of the wild bootstrap procedure, specifically adjusted to give good finite sample coverage of the Shapley curves. The asymptotic results are validated in extensive experiments. In an empirical application, we analyze which attributes drive the prices of vehicles.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#30340;&#22686;&#24378;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#33021;&#22815;&#27169;&#25311;&#22823;&#37327;&#23439;&#35266;&#32463;&#27982;&#21644;&#37329;&#34701;&#21464;&#37327;&#30340;&#36890;&#29992;&#38750;&#32447;&#24615;&#21644;&#26102;&#38388;&#21464;&#21270;&#65292;&#20855;&#26377;&#28508;&#22312;&#30340;&#25919;&#31574;&#20915;&#31574;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2211.04752</link><description>&lt;p&gt;
&#22686;&#24378;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#22312;&#23439;&#35266;&#32463;&#27982;&#21644;&#37329;&#34701;&#39046;&#22495;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Enhanced Bayesian Neural Networks for Macroeconomics and Finance. (arXiv:2211.04752v3 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.04752
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#30340;&#22686;&#24378;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#33021;&#22815;&#27169;&#25311;&#22823;&#37327;&#23439;&#35266;&#32463;&#27982;&#21644;&#37329;&#34701;&#21464;&#37327;&#30340;&#36890;&#29992;&#38750;&#32447;&#24615;&#21644;&#26102;&#38388;&#21464;&#21270;&#65292;&#20855;&#26377;&#28508;&#22312;&#30340;&#25919;&#31574;&#20915;&#31574;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24320;&#21457;&#20102;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476; (BNNs)&#65292;&#23427;&#20204;&#33021;&#22815;&#27169;&#25311;&#21487;&#33021;&#21253;&#21547;&#22823;&#37327;&#23439;&#35266;&#32463;&#27982;&#21644;&#37329;&#34701;&#21464;&#37327;&#30340;&#36890;&#29992;&#38750;&#32447;&#24615;&#21644;&#26102;&#38388;&#21464;&#21270;&#12290;&#20174;&#26041;&#27861;&#35770;&#19978;&#35762;&#65292;&#25105;&#20204;&#20801;&#35768;&#23545;&#32593;&#32476;&#36827;&#34892;&#19968;&#33324;&#35268;&#26684;&#30340;&#35828;&#26126;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#23494;&#38598;&#25110;&#31232;&#30095;&#25968;&#25454;&#38598;&#65292;&#24182;&#32467;&#21512;&#21508;&#31181;&#28608;&#27963;&#21151;&#33021;&#12289;&#21487;&#33021;&#38750;&#24120;&#22810;&#30340;&#31070;&#32463;&#20803;&#21644;&#35823;&#24046;&#39033;&#30340;&#38543;&#26426;&#27874;&#21160;&#12290;&#20174;&#35745;&#31639;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#25105;&#20204;&#20026;&#24341;&#20837;&#30340;&#36890;&#29992;BNNs&#24320;&#21457;&#20102;&#24555;&#36895;&#39640;&#25928;&#30340;&#20272;&#35745;&#31639;&#27861;&#12290;&#20174;&#23454;&#35777;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#25105;&#20204;&#29992;&#27169;&#25311;&#25968;&#25454;&#21644;&#19968;&#32452;&#24120;&#35265;&#30340;&#23439;&#35266;&#37329;&#34701;&#24212;&#29992;&#26469;&#23637;&#31034;&#25105;&#20204;&#30340;BNNs&#21487;&#20197;&#23454;&#38469;&#20351;&#29992;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#35266;&#27979;&#30446;&#26631;&#21464;&#37327;&#30340;&#27178;&#25130;&#38754;&#25110;&#26102;&#38388;&#24207;&#21015;&#20998;&#24067;&#30340;&#23614;&#37096;&#65292;&#35813;&#26041;&#27861;&#29305;&#21035;&#36866;&#29992;&#20110;&#22312;&#19981;&#23547;&#24120;&#30340;&#26102;&#38388;&#20570;&#20986;&#20915;&#31574;&#26041;&#38754;&#20855;&#26377;&#20449;&#24687;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop Bayesian neural networks (BNNs) that permit to model generic nonlinearities and time variation for (possibly large sets of) macroeconomic and financial variables. From a methodological point of view, we allow for a general specification of networks that can be applied to either dense or sparse datasets, and combines various activation functions, a possibly very large number of neurons, and stochastic volatility (SV) for the error term. From a computational point of view, we develop fast and efficient estimation algorithms for the general BNNs we introduce. From an empirical point of view, we show both with simulated data and with a set of common macro and financial applications that our BNNs can be of practical use, particularly so for observations in the tails of the cross-sectional or time series distributions of the target variables, which makes the method particularly informative for policy making in uncommon times.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;Kriging&#29702;&#35770;&#30340;&#22810;&#23618;&#27425;&#38543;&#26426;&#20248;&#21270;&#22635;&#34917;&#26041;&#27861;&#65292;&#33021;&#22815;&#26356;&#20934;&#30830;&#12289;&#26356;&#24555;&#36895;&#21644;&#26356;&#31283;&#23450;&#22320;&#22788;&#29702;&#22823;&#35268;&#27169;&#21307;&#30103;&#25968;&#25454;&#35760;&#24405;&#20013;&#30340;&#32570;&#22833;&#25968;&#20540;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2110.09680</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#21307;&#30103;&#25968;&#25454;&#35760;&#24405;&#20013;&#30340;&#22810;&#23618;&#27425;&#38543;&#26426;&#20248;&#21270;&#22635;&#34917;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Multilevel Stochastic Optimization for Imputation in Massive Medical Data Records. (arXiv:2110.09680v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.09680
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;Kriging&#29702;&#35770;&#30340;&#22810;&#23618;&#27425;&#38543;&#26426;&#20248;&#21270;&#22635;&#34917;&#26041;&#27861;&#65292;&#33021;&#22815;&#26356;&#20934;&#30830;&#12289;&#26356;&#24555;&#36895;&#21644;&#26356;&#31283;&#23450;&#22320;&#22788;&#29702;&#22823;&#35268;&#27169;&#21307;&#30103;&#25968;&#25454;&#35760;&#24405;&#20013;&#30340;&#32570;&#22833;&#25968;&#20540;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25506;&#32034;&#21644;&#20998;&#26512;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#26368;&#36817;&#22312;&#30740;&#31350;&#21644;&#21457;&#23637;&#31038;&#21306;&#20013;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#38271;&#26399;&#20197;&#26469;&#65292;&#20154;&#20204;&#19968;&#30452;&#35748;&#35782;&#21040;&#35768;&#22810;&#25968;&#25454;&#38598;&#20013;&#21253;&#21547;&#22823;&#37327;&#32570;&#22833;&#30340;&#25968;&#20540;&#25968;&#25454;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;Kriging&#29702;&#35770;&#30340;&#25968;&#23398;&#21407;&#21017;&#38543;&#26426;&#20248;&#21270;&#22635;&#34917;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#34987;&#35777;&#26126;&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#22635;&#34917;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#20854;&#35745;&#31639;&#25104;&#26412;&#21644;&#28508;&#22312;&#30340;&#25968;&#20540;&#19981;&#31283;&#23450;&#24615;&#20250;&#23548;&#33268;&#26114;&#36149;&#21644;/&#25110;&#19981;&#21487;&#38752;&#30340;&#39044;&#27979;&#65292;&#21487;&#33021;&#38480;&#21046;&#20854;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#30340;&#20351;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#26368;&#36817;&#24320;&#21457;&#30340;&#22810;&#23618;&#27425;&#38543;&#26426;&#20248;&#21270;&#26041;&#27861;&#24212;&#29992;&#20110;&#22823;&#35268;&#27169;&#21307;&#30103;&#35760;&#24405;&#20013;&#30340;&#22635;&#34917;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#35745;&#31639;&#24212;&#29992;&#25968;&#23398;&#25216;&#26415;&#65292;&#24182;&#20855;&#26377;&#39640;&#31934;&#24230;&#12290;&#29305;&#21035;&#22320;&#65292;&#23545;&#20110;&#26368;&#20339;&#32447;&#24615;&#26080;&#20559;&#39044;&#27979;&#22120;&#65288;BLUP&#65289;&#65292;&#35813;&#22810;&#23618;&#27425;&#24418;&#24335;&#21270;&#26159;&#31934;&#30830;&#30340;&#65292;&#32780;&#19988;&#35745;&#31639;&#36895;&#24230;&#26356;&#24555;&#65292;&#25968;&#20540;&#31283;&#23450;&#24615;&#26356;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
Exploration and analysis of massive datasets has recently generated increasing interest in the research and development communities. It has long been a recognized problem that many datasets contain significant levels of missing numerical data. We introduce a mathematically principled stochastic optimization imputation method based on the theory of Kriging. This is shown to be a powerful method for imputation. However, its computational effort and potential numerical instabilities produce costly and/or unreliable predictions, potentially limiting its use on large scale datasets. In this paper, we apply a recently developed multi-level stochastic optimization approach to the problem of imputation in massive medical records. The approach is based on computational applied mathematics techniques and is highly accurate. In particular, for the Best Linear Unbiased Predictor (BLUP) this multi-level formulation is exact, and is also significantly faster and more numerically stable. This permits
&lt;/p&gt;</description></item></channel></rss>