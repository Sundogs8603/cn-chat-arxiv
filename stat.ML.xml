<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#20381;&#36182;&#25968;&#25454;&#30340;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#22122;&#22768;&#27700;&#24179;&#65292;&#25552;&#20986;&#20102;&#19978;&#38480;&#30028;&#38480;&#65292;&#24182;&#22312;&#35823;&#24046;&#35268;&#33539;&#19979;&#34920;&#29616;&#20986;&#20248;&#38597;&#30340;&#38477;&#20302;&#12290;</title><link>http://arxiv.org/abs/2305.11165</link><description>&lt;p&gt;
&#32447;&#24615;&#22238;&#24402;&#20013;&#20381;&#36182;&#25968;&#25454;&#30340;&#22122;&#22768;&#27700;&#24179;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
The noise level in linear regression with dependent data. (arXiv:2305.11165v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11165
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#20381;&#36182;&#25968;&#25454;&#30340;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#22122;&#22768;&#27700;&#24179;&#65292;&#25552;&#20986;&#20102;&#19978;&#38480;&#30028;&#38480;&#65292;&#24182;&#22312;&#35823;&#24046;&#35268;&#33539;&#19979;&#34920;&#29616;&#20986;&#20248;&#38597;&#30340;&#38477;&#20302;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20174;&#26410;&#20570;&#20219;&#20309;&#23454;&#29616;&#20551;&#35774;&#20986;&#21457;&#65292;&#23545;&#20110;&#20855;&#26377;&#20381;&#36182;($\beta$-mixing)&#25968;&#25454;&#30340;&#38543;&#26426;&#35774;&#35745;&#32447;&#24615;&#22238;&#24402;&#65292;&#25512;&#23548;&#20102;&#20854;&#19978;&#38480;&#30028;&#38480;&#12290;&#19982;&#20165;&#22312;&#21487;&#23454;&#29616;&#30340;&#38789;&#22122;&#22768;&#33539;&#22260;&#20869;&#19981;&#21487;&#29992;&#23574;&#38160;&#30340;&#23454;&#20363;&#26368;&#20248;&#38750;&#28176;&#36817;&#24615;&#30456;&#27604;&#65292;&#25991;&#29486;&#20013;&#27809;&#26377;&#21487;&#29992;&#30340;&#19978;&#38480;&#30028;&#38480;&#12290;&#22312;&#24688;&#24403;&#30340;&#24120;&#25968;&#22240;&#32032;&#19979;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#27491;&#30830;&#22320;&#22238;&#24402;&#20102;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#39044;&#27979;&#30340;&#26041;&#24046;&#39033; - &#38382;&#39064;&#30340;&#22122;&#22768;&#27700;&#24179; - &#24182;&#22240;&#27492;&#22312;&#24341;&#20837;&#38169;&#35823;&#35268;&#33539;&#26102;&#34920;&#29616;&#20986;&#36880;&#28176;&#38477;&#20302;&#30340;&#20248;&#38597;&#24615;&#12290;&#22312;&#39044;&#29123;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#22312;&#20013;&#24230;&#20559;&#24046;&#33539;&#22260;&#20869;&#26159;&#23574;&#38160;&#30340;&#65292;&#29305;&#21035;&#26159;&#19981;&#20250;&#33192;&#32960;&#24341;&#39046;&#39033;&#26399;&#38480;&#19982;&#28151;&#21512;&#26102;&#38388;&#22240;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;
We derive upper bounds for random design linear regression with dependent ($\beta$-mixing) data absent any realizability assumptions. In contrast to the strictly realizable martingale noise regime, no sharp instance-optimal non-asymptotics are available in the literature. Up to constant factors, our analysis correctly recovers the variance term predicted by the Central Limit Theorem -- the noise level of the problem -- and thus exhibits graceful degradation as we introduce misspecification. Past a burn-in, our result is sharp in the moderate deviations regime, and in particular does not inflate the leading order term by mixing time factors.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#20998;&#26512;Hugging Face&#19978;1,417&#20010;ML&#27169;&#22411;&#21450;&#30456;&#20851;&#25968;&#25454;&#38598;&#30340;&#30899;&#36275;&#36857;&#27979;&#37327;&#24773;&#20917;&#65292;&#25552;&#20986;&#20102;&#26377;&#20851;&#22914;&#20309;&#25253;&#21578;&#21644;&#20248;&#21270;ML&#27169;&#22411;&#30340;&#30899;&#25928;&#29575;&#30340;&#35265;&#35299;&#21644;&#24314;&#35758;&#12290;</title><link>http://arxiv.org/abs/2305.11164</link><description>&lt;p&gt;
&#25506;&#32034;&#25265;&#25265;&#33080;ML&#27169;&#22411;&#30340;&#30899;&#36275;&#36857;&#65306;&#19968;&#39033;&#23384;&#20648;&#24211;&#25366;&#25496;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Exploring the Carbon Footprint of Hugging Face's ML Models: A Repository Mining Study. (arXiv:2305.11164v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11164
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#20998;&#26512;Hugging Face&#19978;1,417&#20010;ML&#27169;&#22411;&#21450;&#30456;&#20851;&#25968;&#25454;&#38598;&#30340;&#30899;&#36275;&#36857;&#27979;&#37327;&#24773;&#20917;&#65292;&#25552;&#20986;&#20102;&#26377;&#20851;&#22914;&#20309;&#25253;&#21578;&#21644;&#20248;&#21270;ML&#27169;&#22411;&#30340;&#30899;&#25928;&#29575;&#30340;&#35265;&#35299;&#21644;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;(ML)&#31995;&#32479;&#30340;&#23835;&#36215;&#21152;&#21095;&#20102;&#23427;&#20204;&#30340;&#30899;&#36275;&#36857;&#65292;&#36825;&#26159;&#30001;&#20110;&#20854;&#22686;&#21152;&#30340;&#33021;&#21147;&#21644;&#27169;&#22411;&#22823;&#23567;&#25152;&#33268;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#23545;ML&#27169;&#22411;&#30340;&#30899;&#36275;&#36857;&#22914;&#20309;&#23454;&#38469;&#27979;&#37327;&#12289;&#25253;&#21578;&#21644;&#35780;&#20272;&#30340;&#35748;&#35782;&#30456;&#23545;&#36739;&#23569;&#12290;&#22240;&#27492;&#65292;&#26412;&#35770;&#25991;&#26088;&#22312;&#20998;&#26512;&#22312;Hugging Face&#19978;1,417&#20010;ML&#27169;&#22411;&#21644;&#30456;&#20851;&#25968;&#25454;&#38598;&#30340;&#30899;&#36275;&#36857;&#27979;&#37327;&#24773;&#20917;&#65292;Hugging Face&#26159;&#26368;&#21463;&#27426;&#36814;&#30340;&#39044;&#35757;&#32451;ML&#27169;&#22411;&#30340;&#23384;&#20648;&#24211;&#12290;&#30446;&#26631;&#26159;&#25552;&#20379;&#26377;&#20851;&#22914;&#20309;&#25253;&#21578;&#21644;&#20248;&#21270;ML&#27169;&#22411;&#30340;&#30899;&#25928;&#29575;&#30340;&#35265;&#35299;&#21644;&#24314;&#35758;&#12290;&#35813;&#30740;&#31350;&#21253;&#25324;Hugging Face Hub API&#19978;&#26377;&#20851;&#30899;&#25490;&#25918;&#30340;&#31532;&#19968;&#39033;&#23384;&#20648;&#24211;&#25366;&#25496;&#30740;&#31350;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#22238;&#31572;&#20004;&#20010;&#30740;&#31350;&#38382;&#39064;&#65306;(1) ML&#27169;&#22411;&#30340;&#21019;&#24314;&#32773;&#22914;&#20309;&#22312;Hugging Face Hub&#19978;&#27979;&#37327;&#21644;&#25253;&#21578;&#30899;&#25490;&#25918;&#65311;(2) &#21738;&#20123;&#26041;&#38754;&#24433;&#21709;&#20102;&#35757;&#32451;ML&#27169;&#22411;&#30340;&#30899;&#25490;&#25918;&#65311;&#35813;&#30740;&#31350;&#24471;&#20986;&#20102;&#20960;&#20010;&#20851;&#38190;&#21457;&#29616;&#12290;&#20854;&#20013;&#21253;&#25324;&#30899;&#25490;&#25918;&#25253;&#21578;&#27169;&#24335;&#27604;&#20363;&#30340;&#36880;&#27493;&#19979;&#38477;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;
The rise of machine learning (ML) systems has exacerbated their carbon footprint due to increased capabilities and model sizes. However, there is scarce knowledge on how the carbon footprint of ML models is actually measured, reported, and evaluated. In light of this, the paper aims to analyze the measurement of the carbon footprint of 1,417 ML models and associated datasets on Hugging Face, which is the most popular repository for pretrained ML models. The goal is to provide insights and recommendations on how to report and optimize the carbon efficiency of ML models. The study includes the first repository mining study on the Hugging Face Hub API on carbon emissions. This study seeks to answer two research questions: (1) how do ML model creators measure and report carbon emissions on Hugging Face Hub?, and (2) what aspects impact the carbon emissions of training ML models? The study yielded several key findings. These include a decreasing proportion of carbon emissions-reporting mode
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#25511;&#21046;&#29702;&#35770;&#30340;&#35270;&#35282;&#30740;&#31350;&#20102;&#22312;&#32447;&#23398;&#20064;&#29615;&#22659;&#19979;&#21487;&#33021;&#36973;&#21463;&#21040;&#30340;&#26631;&#31614;&#25200;&#21160;&#25915;&#20987;&#24773;&#20917;&#65292;&#24471;&#20986;&#25915;&#20987;&#24378;&#24230;&#36229;&#36807;&#20020;&#30028;&#38408;&#20540;&#26102;&#23398;&#20064;&#20934;&#30830;&#29575;&#23558;&#20986;&#29616;&#19981;&#36830;&#32493;&#36716;&#21464;&#30340;&#32467;&#35770;&#65292;&#24182;&#39564;&#35777;&#20102;&#29702;&#35770;&#22312;&#22797;&#26434;&#32467;&#26500;&#23398;&#20064;&#22120;&#19978;&#30340;&#36866;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.11132</link><description>&lt;p&gt;
&#22312;&#32447;&#23398;&#20064;&#32773;&#30340;&#25915;&#20987;&#65306;&#19968;&#39033;&#25945;&#24072;-&#23398;&#29983;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Attacks on Online Learners: a Teacher-Student Analysis. (arXiv:2305.11132v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11132
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#25511;&#21046;&#29702;&#35770;&#30340;&#35270;&#35282;&#30740;&#31350;&#20102;&#22312;&#32447;&#23398;&#20064;&#29615;&#22659;&#19979;&#21487;&#33021;&#36973;&#21463;&#21040;&#30340;&#26631;&#31614;&#25200;&#21160;&#25915;&#20987;&#24773;&#20917;&#65292;&#24471;&#20986;&#25915;&#20987;&#24378;&#24230;&#36229;&#36807;&#20020;&#30028;&#38408;&#20540;&#26102;&#23398;&#20064;&#20934;&#30830;&#29575;&#23558;&#20986;&#29616;&#19981;&#36830;&#32493;&#36716;&#21464;&#30340;&#32467;&#35770;&#65292;&#24182;&#39564;&#35777;&#20102;&#29702;&#35770;&#22312;&#22797;&#26434;&#32467;&#26500;&#23398;&#20064;&#22120;&#19978;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#36890;&#24120;&#23481;&#26131;&#21463;&#21040;&#23545;&#25239;&#24615;&#25915;&#20987;&#65306;&#25968;&#25454;&#30340;&#24494;&#23567;&#25200;&#21160;&#21487;&#33021;&#20250;&#20351;&#27169;&#22411;&#30340;&#39044;&#27979;&#32467;&#26524;&#20135;&#29983;&#28798;&#38590;&#24615;&#30340;&#24433;&#21709;&#12290;&#34429;&#28982;&#22823;&#37327;&#30340;&#25991;&#29486;&#30740;&#31350;&#20102;&#23545;&#24050;&#32463;&#39044;&#20808;&#35757;&#32451;&#30340;&#27169;&#22411;&#36827;&#34892;&#27979;&#35797;&#26102;&#30340;&#25915;&#20987;&#24773;&#20917;&#65292;&#20294;&#22312;&#32447;&#23398;&#20064;&#29615;&#22659;&#19979;&#30340;&#25915;&#20987;&#24773;&#20917;&#21364;&#40092;&#26377;&#30740;&#31350;&#12290;&#26412;&#25991;&#20351;&#29992;&#25511;&#21046;&#29702;&#35770;&#30340;&#35270;&#35282;&#30740;&#31350;&#20102;&#22312;&#32447;&#23398;&#20064;&#32773;&#21487;&#33021;&#23384;&#22312;&#30340;&#26631;&#31614;&#25200;&#21160;&#25915;&#20987;&#24773;&#20917;&#65292;&#32771;&#34385;&#20102;&#19981;&#21516;&#30340;&#25915;&#20987;&#31574;&#30053;&#65292;&#24182;&#38024;&#23545;&#31616;&#21333;&#32447;&#24615;&#23398;&#20064;&#22120;&#30340;&#31283;&#24577;&#33719;&#24471;&#20102;&#20998;&#26512;&#32467;&#26524;&#12290;&#36825;&#20123;&#32467;&#26524;&#21487;&#20197;&#35777;&#26126;&#65292;&#24403;&#25915;&#20987;&#24378;&#24230;&#36229;&#36807;&#20020;&#30028;&#38408;&#20540;&#26102;&#65292;&#23398;&#20064;&#22120;&#30340;&#20934;&#30830;&#29575;&#20250;&#20986;&#29616;&#19981;&#36830;&#32493;&#30340;&#36716;&#21464;&#12290;&#28982;&#21518;&#25105;&#20204;&#20351;&#29992;&#30495;&#23454;&#25968;&#25454;&#23545;&#22797;&#26434;&#32467;&#26500;&#30340;&#23398;&#20064;&#22120;&#36827;&#34892;&#20102;&#23454;&#35777;&#20998;&#26512;&#65292;&#39564;&#35777;&#20102;&#29702;&#35770;&#20998;&#26512;&#30340;&#27934;&#35265;&#24182;&#25581;&#31034;&#20102;&#36973;&#21463;&#25915;&#20987;&#30340;&#23398;&#20064;&#22120;&#30340;&#26032;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning models are famously vulnerable to adversarial attacks: small ad-hoc perturbations of the data that can catastrophically alter the model predictions. While a large literature has studied the case of test-time attacks on pre-trained models, the important case of attacks in an online learning setting has received little attention so far. In this work, we use a control-theoretical perspective to study the scenario where an attacker may perturb data labels to manipulate the learning dynamics of an online learner. We perform a theoretical analysis of the problem in a teacher-student setup, considering different attack strategies, and obtaining analytical results for the steady state of simple linear learners. These results enable us to prove that a discontinuous transition in the learner's accuracy occurs when the attack strength exceeds a critical threshold. We then study empirically attacks on learners with complex architectures using real data, confirming the insights of 
&lt;/p&gt;</description></item><item><title>&#20808;&#39564;-&#25968;&#25454;&#25311;&#21512;&#32593;&#32476;&#26159;&#19968;&#31181;&#26032;&#30340;&#26426;&#22120;&#23398;&#20064;&#33539;&#20363;&#65292;&#36890;&#36807;&#31163;&#32447;&#39044;&#35757;&#32451;&#22266;&#23450;&#30340;&#27169;&#22411;&#65292;&#28982;&#21518;&#22312;&#20219;&#24847;&#22823;&#23567;&#21644;&#20998;&#24067;&#30340;&#26032;&#35757;&#32451;&#38598;&#19978;&#25512;&#26029;&#31867;&#27010;&#29575;&#65292;&#24182;&#22312;&#19982;&#39044;&#35757;&#32451;&#25152;&#29992;&#22823;&#23567;&#30456;&#20284;&#30340;&#20219;&#21153;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;, &#19988;&#20934;&#30830;&#24615;&#22312;&#25512;&#26029;&#36807;&#31243;&#20013;&#36827;&#19968;&#27493;&#25552;&#39640;&#12290;</title><link>http://arxiv.org/abs/2305.11097</link><description>&lt;p&gt;
&#20808;&#39564;-&#25968;&#25454;&#25311;&#21512;&#32593;&#32476;&#30340;&#32479;&#35745;&#23398;&#22522;&#30784;
&lt;/p&gt;
&lt;p&gt;
Statistical Foundations of Prior-Data Fitted Networks. (arXiv:2305.11097v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11097
&lt;/p&gt;
&lt;p&gt;
&#20808;&#39564;-&#25968;&#25454;&#25311;&#21512;&#32593;&#32476;&#26159;&#19968;&#31181;&#26032;&#30340;&#26426;&#22120;&#23398;&#20064;&#33539;&#20363;&#65292;&#36890;&#36807;&#31163;&#32447;&#39044;&#35757;&#32451;&#22266;&#23450;&#30340;&#27169;&#22411;&#65292;&#28982;&#21518;&#22312;&#20219;&#24847;&#22823;&#23567;&#21644;&#20998;&#24067;&#30340;&#26032;&#35757;&#32451;&#38598;&#19978;&#25512;&#26029;&#31867;&#27010;&#29575;&#65292;&#24182;&#22312;&#19982;&#39044;&#35757;&#32451;&#25152;&#29992;&#22823;&#23567;&#30456;&#20284;&#30340;&#20219;&#21153;&#19978;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;, &#19988;&#20934;&#30830;&#24615;&#22312;&#25512;&#26029;&#36807;&#31243;&#20013;&#36827;&#19968;&#27493;&#25552;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#39564;-&#25968;&#25454;&#25311;&#21512;&#32593;&#32476; (PFNs) &#26368;&#36817;&#34987;&#25552;&#20986;&#20316;&#20026;&#19968;&#31181;&#26032;&#30340;&#26426;&#22120;&#23398;&#20064;&#33539;&#20363;&#12290;&#19982;&#23558;&#32593;&#32476;&#35757;&#32451;&#21040;&#35266;&#23519;&#21040;&#30340;&#35757;&#32451;&#38598;&#19981;&#21516;&#65292;&#19968;&#20010;&#22266;&#23450;&#30340;&#27169;&#22411;&#22312;&#21508;&#31181;&#20219;&#21153;&#30340;&#23567;&#22411;&#27169;&#25311;&#35757;&#32451;&#38598;&#19978;&#36827;&#34892;&#31163;&#32447;&#39044;&#35757;&#32451;&#12290;&#28982;&#21518;&#65292;&#39044;&#35757;&#32451;&#30340;&#27169;&#22411;&#29992;&#20110;&#22312;&#20219;&#24847;&#22823;&#23567;&#21644;&#20998;&#24067;&#30340;&#26032;&#35757;&#32451;&#38598;&#19978;&#25512;&#26029;&#31867;&#27010;&#29575;&#12290;&#20174;&#32463;&#39564;&#19978;&#26469;&#30475;&#65292;&#24403;&#29992;&#20110;&#19982;&#39044;&#35757;&#32451;&#25152;&#29992;&#22823;&#23567;&#30456;&#20284;&#30340;&#20219;&#21153;&#26102;&#65292;PFNs &#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#22312;&#25512;&#26029;&#36807;&#31243;&#20013;&#65292;&#24403;&#20256;&#36882;&#36739;&#22823;&#30340;&#25968;&#25454;&#38598;&#26102;&#65292;&#20854;&#20934;&#30830;&#24615;&#36827;&#19968;&#27493;&#25552;&#39640;&#12290;&#26412;&#25991;&#20026; PFNs &#24314;&#31435;&#20102;&#19968;&#20010;&#29702;&#35770;&#22522;&#30784;&#24182;&#38416;&#26126;&#20102;&#25511;&#21046;&#23427;&#20204;&#34892;&#20026;&#30340;&#32479;&#35745;&#26426;&#21046;&#12290;&#34429;&#28982; PFNs &#21463;&#36125;&#21494;&#26031;&#24605;&#24819;&#30340;&#21551;&#21457;&#65292;&#20294;&#23558; PFNs &#23436;&#20840;&#35299;&#37322;&#20026;&#39044;&#35843;&#30340;&#26410;&#32463;&#35757;&#32451;&#30340;&#39044;&#27979;&#22120;&#30340;&#39057;&#29575;&#35299;&#37322;&#21487;&#20197;&#35299;&#37322;&#23427;&#20204;&#30340;&#34892;&#20026;&#12290;&#22914;&#26524;&#39044;&#27979;&#22120;&#23545;&#21333;&#20010;&#35757;&#32451;&#26679;&#26412;&#25935;&#24863;&#24615;&#38477;&#20302;&#65292;&#37027;&#20040;&#20854;&#26041;&#24046;&#20063;&#20250;&#38477;&#20026;&#38646;&#65292;&#32780;&#20559;&#24046;&#21482;&#26377;&#24403;&#35823;&#24046;&#21644;&#23548;&#33268;&#20989;&#25968;&#24402;&#20110;&#24120;&#25968;&#26102;&#25165;&#20250;&#28040;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;
Prior-data fitted networks (PFNs) were recently proposed as a new paradigm for machine learning. Instead of training the network to an observed training set, a fixed model is pre-trained offline on small, simulated training sets from a variety of tasks. The pre-trained model is then used to infer class probabilities in-context on fresh training sets with arbitrary size and distribution. Empirically, PFNs achieve state-of-the-art performance on tasks with similar size to the ones used in pre-training. Surprisingly, their accuracy further improves when passed larger data sets during inference. This article establishes a theoretical foundation for PFNs and illuminates the statistical mechanisms governing their behavior. While PFNs are motivated by Bayesian ideas, a purely frequentistic interpretation of PFNs as pre-tuned, but untrained predictors explains their behavior. A predictor's variance vanishes if its sensitivity to individual training samples does and the bias vanishes only if it
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#24314;&#31435;&#20102;&#19968;&#20010;&#23567;&#22122;&#22768;&#20998;&#26512;&#26694;&#26550;&#65292;&#25581;&#31034;&#20102;&#20256;&#32479;L2&#27491;&#21017;&#21270;&#33539;&#25968;&#30340;&#28508;&#22312;&#19981;&#31283;&#23450;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#20998;&#25968;&#38454;RKHS&#27491;&#21017;&#21270;&#22120;&#31867;&#26469;&#35299;&#20915;&#19981;&#31283;&#23450;&#24615;&#65292;&#36825;&#20123;&#27491;&#21017;&#21270;&#22120;&#22987;&#32456;&#20135;&#29983;&#26368;&#20339;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2305.11055</link><description>&lt;p&gt;
Tikhonov&#21644;RKHS&#27491;&#21017;&#21270;&#30340;&#23567;&#22122;&#22768;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Small noise analysis for Tikhonov and RKHS regularizations. (arXiv:2305.11055v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11055
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#24314;&#31435;&#20102;&#19968;&#20010;&#23567;&#22122;&#22768;&#20998;&#26512;&#26694;&#26550;&#65292;&#25581;&#31034;&#20102;&#20256;&#32479;L2&#27491;&#21017;&#21270;&#33539;&#25968;&#30340;&#28508;&#22312;&#19981;&#31283;&#23450;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#20998;&#25968;&#38454;RKHS&#27491;&#21017;&#21270;&#22120;&#31867;&#26469;&#35299;&#20915;&#19981;&#31283;&#23450;&#24615;&#65292;&#36825;&#20123;&#27491;&#21017;&#21270;&#22120;&#22987;&#32456;&#20135;&#29983;&#26368;&#20339;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27491;&#21017;&#21270;&#22312;&#26426;&#22120;&#23398;&#20064;&#21644;&#21453;&#38382;&#39064;&#20013;&#36215;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#21508;&#31181;&#27491;&#21017;&#21270;&#33539;&#25968;&#30340;&#22522;&#26412;&#27604;&#36739;&#20998;&#26512;&#20173;&#28982;&#26410;&#35299;&#20915;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#23567;&#22122;&#22768;&#20998;&#26512;&#26694;&#26550;&#65292;&#20197;&#35780;&#20272;Tikhonov&#21644;RKHS&#27491;&#21017;&#21270;&#33539;&#25968;&#22312;&#39640;&#26031;&#22122;&#22768;&#30340;&#19981;&#36866;&#23450;&#32447;&#24615;&#21453;&#38382;&#39064;&#20013;&#30340;&#25928;&#26524;&#12290;&#35813;&#26694;&#26550;&#30740;&#31350;&#20102;&#27491;&#21017;&#21270;&#20272;&#35745;&#22120;&#22312;&#23567;&#22122;&#22768;&#26497;&#38480;&#19979;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#24182;&#25581;&#31034;&#20102;&#20256;&#32479;L2&#27491;&#21017;&#21270;&#30340;&#28508;&#22312;&#19981;&#31283;&#23450;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#21019;&#26032;&#30340;&#33258;&#36866;&#24212;&#20998;&#25968;&#38454;RKHS&#27491;&#21017;&#21270;&#22120;&#31867;&#26469;&#35299;&#20915;&#36825;&#31181;&#19981;&#31283;&#23450;&#24615;&#65292;&#36890;&#36807;&#35843;&#25972;&#20998;&#25968;&#20809;&#28369;&#24230;&#21442;&#25968;&#65292;&#35813;&#31867;&#35206;&#30422;&#20102;L2 Tikhonov&#21644;RKHS&#27491;&#21017;&#21270;&#22120;&#12290;&#19968;&#20010;&#20196;&#20154;&#24778;&#22855;&#30340;&#35266;&#28857;&#26159;&#65292;&#36890;&#36807;&#36825;&#20123;&#20998;&#25968;&#38454;RKHS&#36827;&#34892;&#36807;&#24230;&#24179;&#28369;&#22987;&#32456;&#20135;&#29983;&#26368;&#20339;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#20294;&#26368;&#20339;&#30340;&#36229;&#21442;&#25968;&#21487;&#33021;&#34928;&#20943;&#24471;&#22826;&#24555;&#32780;&#26080;&#27861;&#22312;&#23454;&#36341;&#20013;&#36827;&#34892;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;
Regularization plays a pivotal role in ill-posed machine learning and inverse problems. However, the fundamental comparative analysis of various regularization norms remains open. We establish a small noise analysis framework to assess the effects of norms in Tikhonov and RKHS regularizations, in the context of ill-posed linear inverse problems with Gaussian noise. This framework studies the convergence rates of regularized estimators in the small noise limit and reveals the potential instability of the conventional L2-regularizer. We solve such instability by proposing an innovative class of adaptive fractional RKHS regularizers, which covers the L2 Tikhonov and RKHS regularizations by adjusting the fractional smoothness parameter. A surprising insight is that over-smoothing via these fractional RKHSs consistently yields optimal convergence rates, but the optimal hyper-parameter may decay too fast to be selected in practice.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#21033;&#29992;DC&#35268;&#21010;&#31639;&#27861;&#26469;&#35299;&#20915;&#23376;&#27169;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#25910;&#25947;&#24615;&#36136;&#27604;&#29616;&#26377;&#31639;&#27861;&#26356;&#20840;&#38754;&#65292;&#21516;&#26102;&#22312;&#35821;&#38899;&#29305;&#24449;&#36873;&#25321;&#21644;&#25991;&#26723;&#25688;&#35201;&#31561;&#24212;&#29992;&#20013;&#21462;&#24471;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.11046</link><description>&lt;p&gt;
DC&#35268;&#21010;&#31639;&#27861;&#22312;&#23376;&#27169;&#26368;&#23567;&#21270;&#38382;&#39064;&#19978;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Difference of Submodular Minimization via DC Programming. (arXiv:2305.11046v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11046
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#21033;&#29992;DC&#35268;&#21010;&#31639;&#27861;&#26469;&#35299;&#20915;&#23376;&#27169;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#25910;&#25947;&#24615;&#36136;&#27604;&#29616;&#26377;&#31639;&#27861;&#26356;&#20840;&#38754;&#65292;&#21516;&#26102;&#22312;&#35821;&#38899;&#29305;&#24449;&#36873;&#25321;&#21644;&#25991;&#26723;&#25688;&#35201;&#31561;&#24212;&#29992;&#20013;&#21462;&#24471;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20013;&#65292;&#26368;&#23567;&#21270;&#20004;&#20010;&#23376;&#27169;&#65288;DS&#65289;&#20989;&#25968;&#30340;&#24046;&#24322;&#26159;&#19968;&#20010;&#33258;&#28982;&#20135;&#29983;&#30340;&#38382;&#39064;&#12290;&#34429;&#28982;&#24050;&#32463;&#26377;&#20154;&#30693;&#36947;DS&#38382;&#39064;&#21487;&#20197;&#31561;&#20215;&#22320;&#36716;&#21270;&#20026;&#20004;&#20010;&#20984;&#65288;DC&#65289;&#20989;&#25968;&#30340;&#24046;&#24322;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#20294;&#29616;&#26377;&#31639;&#27861;&#24182;&#27809;&#26377;&#20805;&#20998;&#21033;&#29992;&#36825;&#31181;&#32852;&#31995;&#12290;&#23545;&#20110;DC&#38382;&#39064;&#65292;&#19968;&#20010;&#32463;&#20856;&#30340;&#31639;&#27861;&#21483;&#20570;DC&#31639;&#27861;&#65288;DCA&#65289;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;DCA&#21450;&#20854;&#23436;&#25972;&#24418;&#24335;&#65288;CDCA&#65289;&#30340;&#21464;&#20307;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#23545;&#24212;&#20110;DS&#26368;&#23567;&#21270;&#30340;DC&#31243;&#24207;&#20013;&#12290;&#25105;&#20204;&#25193;&#23637;&#20102;DCA&#30340;&#29616;&#26377;&#25910;&#25947;&#24615;&#36136;&#65292;&#24182;&#23558;&#23427;&#20204;&#19982;DS&#38382;&#39064;&#30340;&#25910;&#25947;&#24615;&#36136;&#32852;&#31995;&#36215;&#26469;&#12290;&#25105;&#20204;&#30340;DCA&#32467;&#26524;&#19982;&#29616;&#26377;&#30340;DS&#31639;&#27861;&#28385;&#36275;&#30456;&#21516;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#26356;&#23436;&#25972;&#30340;&#25910;&#25947;&#24615;&#36136;&#25551;&#36848;&#12290;&#23545;&#20110;CDCA&#30340;&#24773;&#20917;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#26356;&#24378;&#30340;&#23616;&#37096;&#26368;&#23567;&#20445;&#35777;&#12290;&#25105;&#20204;&#30340;&#25968;&#23383;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#22312;&#20004;&#20010;&#24212;&#29992;&#8212;&#8212;&#35821;&#38899;&#35821;&#26009;&#24211;&#36873;&#25321;&#29305;&#24449;&#20248;&#21270;&#21644;&#25991;&#26723;&#25688;&#35201;&#20013;&#22343;&#20248;&#20110;&#29616;&#26377;&#30340;&#22522;&#32447;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Minimizing the difference of two submodular (DS) functions is a problem that naturally occurs in various machine learning problems. Although it is well known that a DS problem can be equivalently formulated as the minimization of the difference of two convex (DC) functions, existing algorithms do not fully exploit this connection. A classical algorithm for DC problems is called the DC algorithm (DCA). We introduce variants of DCA and its complete form (CDCA) that we apply to the DC program corresponding to DS minimization. We extend existing convergence properties of DCA, and connect them to convergence properties on the DS problem. Our results on DCA match the theoretical guarantees satisfied by existing DS algorithms, while providing a more complete characterization of convergence properties. In the case of CDCA, we obtain a stronger local minimality guarantee. Our numerical results show that our proposed algorithms outperform existing baselines on two applications: speech corpus sel
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27010;&#29575;&#21435;&#30456;&#20851;&#24341;&#29702;&#21644;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#20013;&#19968;&#20123;&#20854;&#20182;&#25216;&#26415;&#30340;&#36890;&#29992;&#26041;&#27861;&#65292;&#21487;&#20197;&#24471;&#21040;&#26032;&#30340;&#23398;&#20064;&#31639;&#27861;&#30340;&#20449;&#24687;&#35770;&#27867;&#21270;&#19978;&#38480;&#65292;&#24182;&#19988;&#33021;&#22815;&#24674;&#22797;&#35768;&#22810;&#29616;&#26377;&#30340;&#27867;&#21270;&#30028;&#65292;&#22914;&#22522;&#20110;&#20114;&#20449;&#24687;&#12289;&#26465;&#20214;&#20114;&#20449;&#24687;&#12289;&#38543;&#26426;chaining&#21644;PAC-Bayes&#19981;&#31561;&#24335;&#30340;&#30028;&#12290;</title><link>http://arxiv.org/abs/2305.11042</link><description>&lt;p&gt;
&#19968;&#31181;&#20449;&#24687;&#35770;&#36890;&#29992;&#27867;&#21270;&#30028;&#32479;&#19968;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A unified framework for information-theoretic generalization bounds. (arXiv:2305.11042v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11042
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27010;&#29575;&#21435;&#30456;&#20851;&#24341;&#29702;&#21644;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#20013;&#19968;&#20123;&#20854;&#20182;&#25216;&#26415;&#30340;&#36890;&#29992;&#26041;&#27861;&#65292;&#21487;&#20197;&#24471;&#21040;&#26032;&#30340;&#23398;&#20064;&#31639;&#27861;&#30340;&#20449;&#24687;&#35770;&#27867;&#21270;&#19978;&#38480;&#65292;&#24182;&#19988;&#33021;&#22815;&#24674;&#22797;&#35768;&#22810;&#29616;&#26377;&#30340;&#27867;&#21270;&#30028;&#65292;&#22914;&#22522;&#20110;&#20114;&#20449;&#24687;&#12289;&#26465;&#20214;&#20114;&#20449;&#24687;&#12289;&#38543;&#26426;chaining&#21644;PAC-Bayes&#19981;&#31561;&#24335;&#30340;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#26041;&#27861;&#26469;&#23548;&#20986;&#23398;&#20064;&#31639;&#27861;&#30340;&#20449;&#24687;&#35770;&#27867;&#21270;&#30028;&#12290;&#20027;&#35201;&#30340;&#25216;&#26415;&#24037;&#20855;&#26159;&#22522;&#20110;&#25913;&#21464;&#27979;&#24230;&#21644;&#26494;&#24347;Young&#19981;&#31561;&#24335;&#22312;$L_{\psi_p}$Orlicz&#31354;&#38388;&#20013;&#30340;&#27010;&#29575;&#21435;&#30456;&#20851;&#24615;&#24341;&#29702;&#12290;&#37319;&#29992;&#21435;&#30456;&#20851;&#24615;&#24341;&#29702;&#19982;&#20854;&#20182;&#25216;&#26415;&#65292;&#22914;&#23545;&#31216;&#21270;&#12289;&#32806;&#21512;&#21644;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#20013;&#30340;chaining&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#26032;&#30340;&#27867;&#21270;&#35823;&#24046;&#19978;&#38480;&#65292;&#21253;&#25324;&#26399;&#26395;&#21644;&#39640;&#27010;&#29575;&#65292;&#21516;&#26102;&#65292;&#25105;&#20204;&#20063;&#24674;&#22797;&#20102;&#35768;&#22810;&#29616;&#26377;&#30340;&#27867;&#21270;&#30028;&#65292;&#21253;&#25324;&#22522;&#20110;&#20114;&#20449;&#24687;&#12289;&#26465;&#20214;&#20114;&#20449;&#24687;&#12289;&#38543;&#26426;chaining&#21644;PAC-Bayes&#19981;&#31561;&#24335;&#30340;&#30028;&#12290;&#27492;&#22806;&#65292;Fernique-Talagrand&#19978;&#30028;&#20063;&#20316;&#20026;&#19968;&#31181;&#29305;&#27530;&#24773;&#20917;&#21576;&#29616;&#20986;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a general methodology for deriving information-theoretic generalization bounds for learning algorithms. The main technical tool is a probabilistic decorrelation lemma based on a change of measure and a relaxation of Young's inequality in $L_{\psi_p}$ Orlicz spaces. Using the decorrelation lemma in combination with other techniques, such as symmetrization, couplings, and chaining in the space of probability measures, we obtain new upper bounds on the generalization error, both in expectation and in high probability, and recover as special cases many of the existing generalization bounds, including the ones based on mutual information, conditional mutual information, stochastic chaining, and PAC-Bayes inequalities. In addition, the Fernique-Talagrand upper bound on the expected supremum of a subgaussian process emerges as a special case.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21435;&#22122;&#33258;&#32534;&#30721;&#22120;&#22312;&#39640;&#32500;&#26497;&#38480;&#19979;&#30340;&#24615;&#33021;&#34920;&#29616;&#65292;&#24471;&#20986;&#20102;&#21435;&#22122;&#22343;&#26041;&#27979;&#35797;&#35823;&#24046;&#30340;&#38381;&#24335;&#34920;&#36798;&#24335;&#65292;&#24182;&#25581;&#31034;&#20102;&#26377;&#36339;&#36291;&#36830;&#25509;&#30340;&#33258;&#32534;&#30721;&#22120;&#30456;&#36739;&#20110;&#20256;&#32479;&#33258;&#32534;&#30721;&#22120;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.11041</link><description>&lt;p&gt;
&#21435;&#22122;&#33258;&#32534;&#30721;&#22120;&#30340;&#39640;&#32500;&#28176;&#36817;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
High-dimensional Asymptotics of Denoising Autoencoders. (arXiv:2305.11041v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11041
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21435;&#22122;&#33258;&#32534;&#30721;&#22120;&#22312;&#39640;&#32500;&#26497;&#38480;&#19979;&#30340;&#24615;&#33021;&#34920;&#29616;&#65292;&#24471;&#20986;&#20102;&#21435;&#22122;&#22343;&#26041;&#27979;&#35797;&#35823;&#24046;&#30340;&#38381;&#24335;&#34920;&#36798;&#24335;&#65292;&#24182;&#25581;&#31034;&#20102;&#26377;&#36339;&#36291;&#36830;&#25509;&#30340;&#33258;&#32534;&#30721;&#22120;&#30456;&#36739;&#20110;&#20256;&#32479;&#33258;&#32534;&#30721;&#22120;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#24212;&#29992;&#24102;&#26377;&#32465;&#23450;&#26435;&#37325;&#21644;&#36339;&#36291;&#36830;&#25509;&#30340;&#20108;&#23618;&#38750;&#32447;&#24615;&#33258;&#32534;&#30721;&#22120;&#26469;&#21435;&#22122;&#39640;&#26031;&#28151;&#21512;&#25968;&#25454;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#22312;&#39640;&#32500;&#26497;&#38480;&#19979;&#32771;&#34385;&#65292;&#20854;&#20013;&#35757;&#32451;&#26679;&#26412;&#25968;&#21644;&#36755;&#20837;&#32500;&#25968;&#20849;&#21516;&#36235;&#21521;&#20110;&#26080;&#31351;&#22823;&#65292;&#32780;&#38544;&#34255;&#21333;&#20803;&#25968;&#20445;&#25345;&#26377;&#38480;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#21435;&#22122;&#22343;&#26041;&#27979;&#35797;&#35823;&#24046;&#30340;&#38381;&#24335;&#34920;&#36798;&#24335;&#12290;&#22522;&#20110;&#36825;&#20010;&#32467;&#26524;&#65292;&#25105;&#20204;&#23450;&#37327;&#22320;&#34920;&#24449;&#20102;&#25152;&#32771;&#34385;&#30340;&#26550;&#26500;&#22312;&#33258;&#32534;&#30721;&#22120;&#65288;&#27809;&#26377;&#20851;&#32852;&#21040;&#20027;&#25104;&#20998;&#20998;&#26512;&#65289;&#30340;&#36339;&#36291;&#36830;&#25509;&#30456;&#20851;&#24615;&#20043;&#19978;&#30340;&#20248;&#21183;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#32467;&#26524;&#20934;&#30830;&#22320;&#25429;&#25417;&#20102;&#19968;&#31995;&#21015;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#23398;&#20064;&#26354;&#32447;&#12290;
&lt;/p&gt;
&lt;p&gt;
We address the problem of denoising data from a Gaussian mixture using a two-layer non-linear autoencoder with tied weights and a skip connection. We consider the high-dimensional limit where the number of training samples and the input dimension jointly tend to infinity while the number of hidden units remains bounded. We provide closed-form expressions for the denoising mean-squared test error. Building on this result, we quantitatively characterize the advantage of the considered architecture over the autoencoder without the skip connection that relates closely to principal component analysis. We further show that our results accurately capture the learning curves on a range of real data sets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20048;&#35266;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#20248;&#21270;&#26694;&#26550;&#65292;&#37319;&#29992;&#20048;&#35266;&#31574;&#30053;&#35780;&#20272;&#23376;&#31243;&#24207;&#20197;&#40723;&#21169;&#25506;&#32034;&#65292;&#36866;&#29992;&#20110;&#32447;&#24615;MDP&#65292;&#26679;&#26412;&#22797;&#26434;&#24230;&#20855;&#26377;&#26368;&#20248;&#32500;&#24230;&#20381;&#36182;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2305.11032</link><description>&lt;p&gt;
&#20048;&#35266;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#65306;&#19968;&#31181;&#31616;&#21333;&#39640;&#25928;&#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#20248;&#21270;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Optimistic Natural Policy Gradient: a Simple Efficient Policy Optimization Framework for Online RL. (arXiv:2305.11032v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11032
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20048;&#35266;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#20248;&#21270;&#26694;&#26550;&#65292;&#37319;&#29992;&#20048;&#35266;&#31574;&#30053;&#35780;&#20272;&#23376;&#31243;&#24207;&#20197;&#40723;&#21169;&#25506;&#32034;&#65292;&#36866;&#29992;&#20110;&#32447;&#24615;MDP&#65292;&#26679;&#26412;&#22797;&#26434;&#24230;&#20855;&#26377;&#26368;&#20248;&#32500;&#24230;&#20381;&#36182;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#31574;&#30053;&#20248;&#21270;&#31639;&#27861;&#23545;&#20110;&#36817;&#26399;&#24378;&#21270;&#23398;&#20064;&#30340;&#23454;&#35777;&#25104;&#21151;&#21457;&#25381;&#20102;&#37325;&#35201;&#20316;&#29992;&#65292;&#20294;&#31574;&#30053;&#20248;&#21270;&#30340;&#29616;&#26377;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#30456;&#24403;&#26377;&#38480; - &#23427;&#20204;&#35201;&#20040;&#23616;&#38480;&#20110;&#34920;&#26684;MDP&#65292;&#35201;&#20040;&#22312;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#23384;&#22312;&#39640;&#24230;&#20122;&#26368;&#20248;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#39640;&#25928;&#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#31574;&#30053;&#20248;&#21270;&#26694;&#26550; - &#20048;&#35266;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#12290;&#20048;&#35266;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#21487;&#20197;&#30475;&#20316;&#26159;&#23558;&#32463;&#20856;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#31639;&#27861;[Kakade&#65292;2001]&#19982;&#20048;&#35266;&#31574;&#30053;&#35780;&#20272;&#23376;&#31243;&#24207;&#31616;&#21333;&#32452;&#21512;&#20197;&#40723;&#21169;&#25506;&#32034;&#12290;&#23545;&#20110;$d$-&#32500;&#32447;&#24615;MDP&#65292;&#20048;&#35266;&#33258;&#28982;&#31574;&#30053;&#26799;&#24230;&#20855;&#26377;&#35745;&#31639;&#25928;&#29575;&#65292;&#24182;&#19988;&#22312;$\tilde{O}(d^2/\varepsilon^3)$ &#27425;&#37319;&#26679;&#20869;&#23398;&#20064; $\varepsilon$ -&#26368;&#20248;&#31574;&#30053;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#20855;&#26377;&#26368;&#20248;&#32500;&#24230;&#20381;&#36182;&#20851;&#31995;$\tilde {\Theta}(d^2)$&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#35745;&#31639;&#39640;&#25928;&#31639;&#27861;&#12290;&#23427;&#20063;&#36229;&#36234;&#20102;&#30446;&#21069;&#39046;&#20808;&#30340;&#19968;&#20123;&#29366;&#24577;of-the-art&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
While policy optimization algorithms have played an important role in recent empirical success of Reinforcement Learning (RL), the existing theoretical understanding of policy optimization remains rather limited -- they are either restricted to tabular MDPs or suffer from highly suboptimal sample complexity, especial in online RL where exploration is necessary. This paper proposes a simple efficient policy optimization framework -- Optimistic NPG for online RL. Optimistic NPG can be viewed as simply combining of the classic natural policy gradient (NPG) algorithm [Kakade, 2001] with optimistic policy evaluation subroutines to encourage exploration. For $d$-dimensional linear MDPs, Optimistic NPG is computationally efficient, and learns an $\varepsilon$-optimal policy within $\tilde{O}(d^2/\varepsilon^3)$ samples, which is the first computationally efficient algorithm whose sample complexity has the optimal dimension dependence $\tilde{\Theta}(d^2)$. It also improves over state-of-the-a
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#25293;&#21334;&#35774;&#35745;&#39046;&#22495;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#65292;&#21363;&#26368;&#20248;&#25293;&#21334;&#35774;&#35745;&#12290;&#22312;&#30740;&#31350;&#20013;&#65292;&#20316;&#32773;&#35777;&#26126;&#20102;&#31070;&#32463;&#32593;&#32476;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#21487;&#20197;&#36890;&#36807;&#31616;&#21333;&#30340;&#20998;&#27573;&#32447;&#24615;&#36335;&#24452;&#36830;&#25509;&#19981;&#21516;&#30340;&#23616;&#37096;&#26368;&#20248;&#35299;&#65292;&#24182;&#21462;&#24471;&#20102;&#25104;&#21151;&#12290;</title><link>http://arxiv.org/abs/2305.11005</link><description>&lt;p&gt;
&#25293;&#21334;&#35774;&#35745;&#20013;&#30340;&#27169;&#24335;&#36830;&#36890;&#24615;
&lt;/p&gt;
&lt;p&gt;
Mode Connectivity in Auction Design. (arXiv:2305.11005v1 [cs.GT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11005
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#25293;&#21334;&#35774;&#35745;&#39046;&#22495;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#65292;&#21363;&#26368;&#20248;&#25293;&#21334;&#35774;&#35745;&#12290;&#22312;&#30740;&#31350;&#20013;&#65292;&#20316;&#32773;&#35777;&#26126;&#20102;&#31070;&#32463;&#32593;&#32476;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#21487;&#20197;&#36890;&#36807;&#31616;&#21333;&#30340;&#20998;&#27573;&#32447;&#24615;&#36335;&#24452;&#36830;&#25509;&#19981;&#21516;&#30340;&#23616;&#37096;&#26368;&#20248;&#35299;&#65292;&#24182;&#21462;&#24471;&#20102;&#25104;&#21151;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#20248;&#25293;&#21334;&#35774;&#35745;&#26159;&#31639;&#27861;&#21338;&#24328;&#35770;&#20013;&#30340;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#65292;&#21363;&#20351;&#22312;&#38750;&#24120;&#31616;&#21333;&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#20010;&#38382;&#39064;&#20063;&#24456;&#38590;&#12290;&#26368;&#36817;&#19981;&#21516;&#30340;&#32463;&#27982;&#23398;&#21487;&#24494;&#20998;&#29702;&#35770;&#34920;&#26126;&#65292;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#26377;&#25928;&#22320;&#23398;&#20064;&#24050;&#30693;&#30340;&#26368;&#20248;&#25293;&#21334;&#26426;&#21046;&#65292;&#21457;&#29616;&#26377;&#36259;&#30340;&#26032;&#26426;&#21046;&#12290;&#20026;&#20102;&#29702;&#35770;&#19978;&#35777;&#26126;&#23427;&#20204;&#30340;&#23454;&#35777;&#25104;&#21151;&#65292;&#25105;&#20204;&#32858;&#28966;&#20110;&#31532;&#19968;&#20010;&#36825;&#26679;&#30340;&#32593;&#32476;&#65292;RochetNet&#65292;&#24182;&#30740;&#31350;&#25152;&#35859;&#30340;&#20223;&#23556;&#26497;&#22823;&#21270;&#25293;&#21334;&#30340;&#24191;&#20041;&#29256;&#26412;&#12290;&#25105;&#20204;&#35777;&#26126;&#23427;&#20204;&#28385;&#36275;&#27169;&#24335;&#36830;&#36890;&#24615;&#65292;&#21363;&#23616;&#37096;&#26368;&#20248;&#35299;&#36890;&#36807;&#19968;&#20010;&#31616;&#21333;&#30340;&#20998;&#27573;&#32447;&#24615;&#36335;&#24452;&#36830;&#25509;&#65292;&#36335;&#24452;&#19978;&#30340;&#27599;&#20010;&#35299;&#37117;&#20960;&#20046;&#21644;&#20004;&#20010;&#23616;&#37096;&#26368;&#20248;&#35299;&#20043;&#19968;&#19968;&#26679;&#22909;&#12290;&#27169;&#24335;&#36830;&#36890;&#24615;&#26368;&#36817;&#34987;&#35777;&#26126;&#26159;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#39044;&#27979;&#38382;&#39064;&#30340;&#19968;&#20010;&#26377;&#36259;&#30340;&#32463;&#39564;&#21644;&#29702;&#35770;&#30340;&#23646;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26159;&#23545;&#21487;&#24494;&#20998;&#32463;&#27982;&#23398;&#39046;&#22495;&#20013;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110;&#35299;&#20915;&#38750;&#32447;&#24615;&#35774;&#35745;&#38382;&#39064;&#30340;&#31532;&#19968;&#20010;&#36825;&#26679;&#30340;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Optimal auction design is a fundamental problem in algorithmic game theory. This problem is notoriously difficult already in very simple settings. Recent work in differentiable economics showed that neural networks can efficiently learn known optimal auction mechanisms and discover interesting new ones. In an attempt to theoretically justify their empirical success, we focus on one of the first such networks, RochetNet, and a generalized version for affine maximizer auctions. We prove that they satisfy mode connectivity, i.e., locally optimal solutions are connected by a simple, piecewise linear path such that every solution on the path is almost as good as one of the two local optima. Mode connectivity has been recently investigated as an intriguing empirical and theoretically justifiable property of neural networks used for prediction problems. Our results give the first such analysis in the context of differentiable economics, where neural networks are used directly for solving non-
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24191;&#20041;&#24314;&#27169;&#26041;&#27861;&#65292;&#22312;&#21160;&#24577;&#26399;&#38480;&#32467;&#26500;&#27169;&#22411;&#20013;&#24341;&#20837;&#20102;&#39640;&#26031;&#36807;&#31243;&#20808;&#39564;&#26469;&#24314;&#27169;&#38750;&#32447;&#24615;&#20851;&#32852;&#65292;&#20197;&#27492;&#36827;&#34892;&#39044;&#27979;&#21644;&#21160;&#24577;&#25237;&#36164;&#32452;&#21512;&#20248;&#21270;&#65292;&#30456;&#27604;&#36807;&#21435;&#20165;&#32771;&#34385;&#32447;&#24615;&#30456;&#20114;&#20316;&#29992;&#65292;&#21453;&#26144;&#20102;&#26356;&#21152;&#30495;&#23454;&#30340;&#32463;&#27982;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2305.11001</link><description>&lt;p&gt;
&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#30340;&#38750;&#32447;&#24615;&#21160;&#24577;&#26399;&#38480;&#32467;&#26500;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Dynamic Term Structure Models with Nonlinearities using Gaussian Processes. (arXiv:2305.11001v1 [stat.AP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11001
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24191;&#20041;&#24314;&#27169;&#26041;&#27861;&#65292;&#22312;&#21160;&#24577;&#26399;&#38480;&#32467;&#26500;&#27169;&#22411;&#20013;&#24341;&#20837;&#20102;&#39640;&#26031;&#36807;&#31243;&#20808;&#39564;&#26469;&#24314;&#27169;&#38750;&#32447;&#24615;&#20851;&#32852;&#65292;&#20197;&#27492;&#36827;&#34892;&#39044;&#27979;&#21644;&#21160;&#24577;&#25237;&#36164;&#32452;&#21512;&#20248;&#21270;&#65292;&#30456;&#27604;&#36807;&#21435;&#20165;&#32771;&#34385;&#32447;&#24615;&#30456;&#20114;&#20316;&#29992;&#65292;&#21453;&#26144;&#20102;&#26356;&#21152;&#30495;&#23454;&#30340;&#32463;&#27982;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25991;&#29486;&#20013;&#24191;&#27867;&#35752;&#35770;&#20102;&#23439;&#35266;&#32463;&#27982;&#21464;&#37327;&#23545;&#21160;&#24577;&#26399;&#38480;&#32467;&#26500;&#27169;&#22411;&#30340;&#37325;&#35201;&#24615;&#12290;&#21040;&#30446;&#21069;&#20026;&#27490;&#65292;&#20197;&#24448;&#30340;&#30740;&#31350;&#20165;&#32771;&#34385;&#20102;DTSM&#20013;&#32463;&#27982;&#21644;&#21033;&#29575;&#23454;&#38469;&#21160;&#24577;&#20043;&#38388;&#30340;&#32447;&#24615;&#30456;&#20114;&#20316;&#29992;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24191;&#20041;&#24314;&#27169;&#26041;&#27861;&#65292;&#21033;&#29992;&#39640;&#26031;DTSM&#65292;&#20801;&#35768;&#20004;&#32773;&#20043;&#38388;&#30340;&#38750;&#32447;&#24615;&#20851;&#32852;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#31181;&#24314;&#27169;&#26041;&#24335;&#36827;&#34892;&#39044;&#27979;&#65292;&#24182;&#26500;&#24314;&#33258;&#23450;&#20041;&#30340;&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;&#20272;&#35745;&#21644;&#39044;&#27979;&#26041;&#26696;&#65292;&#24341;&#20837;&#39640;&#26031;&#36807;&#31243;&#20808;&#39564;&#26469;&#24314;&#27169;&#38750;&#32447;&#24615;&#20851;&#32852;&#12290;&#24314;&#35758;&#30340;&#39034;&#24207;&#26041;&#26696;&#20063;&#21487;&#29992;&#20110;&#21160;&#24577;&#25237;&#36164;&#32452;&#21512;&#20248;&#21270;&#65292;&#20197;&#35780;&#20272;&#20026;&#25237;&#36164;&#32773;&#21019;&#36896;&#30340;&#32463;&#27982;&#20215;&#20540;&#28508;&#21147;&#12290;&#25105;&#20204;&#20351;&#29992;&#32654;&#22269;&#22269;&#20538;&#25968;&#25454;&#21644;&#36873;&#23450;&#30340;&#23439;&#35266;&#32463;&#27982;&#25351;&#26631;&#65292;&#29305;&#21035;&#26159;&#26680;&#24515;&#36890;&#32960;&#21644;&#30495;&#23454;&#32463;&#27982;&#27963;&#21160;&#26469;&#23637;&#31034;&#36825;&#31181;&#26041;&#27861;&#12290;&#25105;&#20204;&#23558;&#38750;&#32447;&#24615;&#27169;&#22411;&#30340;&#32467;&#26524;&#19982;&#20165;&#32771;&#34385;&#32447;&#24615;&#30456;&#20114;&#20316;&#29992;&#30340;&#27169;&#22411;&#30340;&#32467;&#26524;&#36827;&#34892;&#23545;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;
The importance of unspanned macroeconomic variables for Dynamic Term Structure Models has been intensively discussed in the literature. To our best knowledge the earlier studies considered only linear interactions between the economy and the real-world dynamics of interest rates in DTSMs. We propose a generalized modelling setup for Gaussian DTSMs which allows for unspanned nonlinear associations between the two and we exploit it in forecasting. Specifically, we construct a custom sequential Monte Carlo estimation and forecasting scheme where we introduce Gaussian Process priors to model nonlinearities. Sequential scheme we propose can also be used with dynamic portfolio optimization to assess the potential of generated economic value to investors. The methodology is presented using US Treasury data and selected macroeconomic indices. Namely, we look at core inflation and real economic activity. We contrast the results obtained from the nonlinear model with those stemming from an appli
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26680;&#30697;&#27861;&#20272;&#35745;&#22120;&#65292;&#31216;&#20026;KMM&#65292;&#20854;&#29992;&#20110;&#36229;&#36234;&#25968;&#25454;&#37325;&#26032;&#21152;&#26435;&#30340;&#30697;&#26041;&#27861;&#27169;&#22411;&#65292;&#35299;&#38500;&#20102;&#20851;&#20110;&#20351;&#29992; $\varphi$-&#25955;&#24230;&#30456;&#20851;&#30340;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2305.10898</link><description>&lt;p&gt;
&#36229;&#36234;&#25968;&#25454;&#37325;&#26032;&#21152;&#26435;&#65306;&#26680;&#30697;&#27861;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Estimation Beyond Data Reweighting: Kernel Method of Moments. (arXiv:2305.10898v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10898
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26680;&#30697;&#27861;&#20272;&#35745;&#22120;&#65292;&#31216;&#20026;KMM&#65292;&#20854;&#29992;&#20110;&#36229;&#36234;&#25968;&#25454;&#37325;&#26032;&#21152;&#26435;&#30340;&#30697;&#26041;&#27861;&#27169;&#22411;&#65292;&#35299;&#38500;&#20102;&#20851;&#20110;&#20351;&#29992; $\varphi$-&#25955;&#24230;&#30456;&#20851;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#19982;&#32479;&#35745;&#23398;&#31561;&#22810;&#20010;&#39046;&#22495;&#20013;&#37117;&#20250;&#20986;&#29616;&#30697;&#32422;&#26463;&#21644;&#26465;&#20214;&#23545;&#24212;&#65292;&#20854;&#20013;&#65292;&#24191;&#20041;&#30697;&#27861;&#65288;GMM&#65289;&#20316;&#20026;&#19968;&#20010;&#20272;&#35745;&#27169;&#22411;&#24050;&#32463;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#24448;&#24448;&#30001;&#20110;&#20351;&#29992; $\varphi$-&#25955;&#24230;&#30340;&#30456;&#20851;&#38480;&#21046;&#23558;&#20505;&#36873;&#20998;&#24067;&#38480;&#21046;&#20026;&#25968;&#25454;&#26679;&#26412;&#30340;&#37325;&#26032;&#21152;&#26435;&#12290;&#32780;&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#30697;&#20272;&#35745;&#26041;&#27861;&#8212;&#8212;&#22522;&#20110;&#26368;&#22823;&#22343;&#20540;&#20559;&#24046;&#30340;&#32463;&#39564;&#20284;&#28982;&#20272;&#35745;&#22120;&#65292;&#21363;&#26680;&#30697;&#27861;(KMM)&#65292;&#20854;&#23454;&#29616;&#36229;&#36234;&#20102;&#23545;&#25968;&#25454;&#30340;&#37325;&#26032;&#21152;&#26435;&#12290;
&lt;/p&gt;
&lt;p&gt;
Moment restrictions and their conditional counterparts emerge in many areas of machine learning and statistics ranging from causal inference to reinforcement learning. Estimators for these tasks, generally called methods of moments, include the prominent generalized method of moments (GMM) which has recently gained attention in causal inference. GMM is a special case of the broader family of empirical likelihood estimators which are based on approximating a population distribution by means of minimizing a $\varphi$-divergence to an empirical distribution. However, the use of $\varphi$-divergences effectively limits the candidate distributions to reweightings of the data samples. We lift this long-standing limitation and provide a method of moments that goes beyond data reweighting. This is achieved by defining an empirical likelihood estimator based on maximum mean discrepancy which we term the kernel method of moments (KMM). We provide a variant of our estimator for conditional moment
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#26368;&#23567;&#39118;&#38505;&#37325;&#26032;&#26657;&#20934;&#30340;&#27010;&#24565;&#65292;&#22312;&#22343;&#26041;&#35823;&#24046;&#20998;&#35299;&#26694;&#26550;&#20869;&#25552;&#20379;&#20102;&#19968;&#31181;&#21407;&#21017;&#24615;&#26041;&#27861;&#65292;&#29992;&#20110;&#35780;&#20272;&#21644;&#37325;&#26032;&#26657;&#20934;&#27010;&#29575;&#20998;&#31867;&#22120;&#65292;&#24182;&#36890;&#36807;&#24179;&#34913;&#26657;&#20934;&#21644;&#38160;&#24230;&#30830;&#23450;&#20102;&#26368;&#20248;&#30340;&#26742;&#25968;&#65292;&#20174;&#32780;&#20135;&#29983;&#20102;&#22823;&#32422;$O(n^{-2/3})$&#30340;&#39118;&#38505;&#19978;&#30028;&#12290;</title><link>http://arxiv.org/abs/2305.10886</link><description>&lt;p&gt;
&#20998;&#31867;&#22120;&#26368;&#23567;&#39118;&#38505;&#37325;&#26032;&#26657;&#20934;
&lt;/p&gt;
&lt;p&gt;
Minimum-Risk Recalibration of Classifiers. (arXiv:2305.10886v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10886
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#26368;&#23567;&#39118;&#38505;&#37325;&#26032;&#26657;&#20934;&#30340;&#27010;&#24565;&#65292;&#22312;&#22343;&#26041;&#35823;&#24046;&#20998;&#35299;&#26694;&#26550;&#20869;&#25552;&#20379;&#20102;&#19968;&#31181;&#21407;&#21017;&#24615;&#26041;&#27861;&#65292;&#29992;&#20110;&#35780;&#20272;&#21644;&#37325;&#26032;&#26657;&#20934;&#27010;&#29575;&#20998;&#31867;&#22120;&#65292;&#24182;&#36890;&#36807;&#24179;&#34913;&#26657;&#20934;&#21644;&#38160;&#24230;&#30830;&#23450;&#20102;&#26368;&#20248;&#30340;&#26742;&#25968;&#65292;&#20174;&#32780;&#20135;&#29983;&#20102;&#22823;&#32422;$O(n^{-2/3})$&#30340;&#39118;&#38505;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37325;&#26032;&#26657;&#20934;&#27010;&#29575;&#20998;&#31867;&#22120;&#23545;&#20110;&#25552;&#39640;&#39044;&#27979;&#27169;&#22411;&#30340;&#21487;&#38752;&#24615;&#21644;&#20934;&#30830;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#23613;&#31649;&#24050;&#32463;&#24320;&#21457;&#20102;&#35768;&#22810;&#37325;&#26032;&#26657;&#20934;&#31639;&#27861;&#65292;&#20294;&#20173;&#32570;&#20047;&#19968;&#20010;&#32508;&#21512;&#30340;&#29702;&#35770;&#26469;&#25972;&#21512;&#26657;&#20934;&#21644;&#38160;&#24230;&#65288;&#36825;&#23545;&#20110;&#20445;&#25345;&#39044;&#27979;&#21147;&#33267;&#20851;&#37325;&#35201;&#65289;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#22312;&#22343;&#26041;&#35823;&#24046;&#65288;MSE&#65289;&#20998;&#35299;&#26694;&#26550;&#20869;&#20171;&#32461;&#20102;&#26368;&#23567;&#39118;&#38505;&#37325;&#26032;&#26657;&#20934;&#30340;&#27010;&#24565;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#35780;&#20272;&#21644;&#37325;&#26032;&#26657;&#20934;&#27010;&#29575;&#20998;&#31867;&#22120;&#30340;&#21407;&#21017;&#24615;&#26041;&#27861;&#12290;&#21033;&#29992;&#36825;&#20010;&#26694;&#26550;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#22343;&#21248;&#36136;&#37327;&#20998;&#26742;&#65288;UMB&#65289;&#37325;&#26032;&#26657;&#20934;&#26041;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#19968;&#20010;&#26377;&#38480;&#26679;&#26412;&#39118;&#38505;&#19978;&#30028;&#65292;&#20854;&#39034;&#24207;&#20026;$\tilde{O}(B/n+1/B^2)$&#65292;&#20854;&#20013;$B$&#26159;&#26742;&#30340;&#25968;&#37327;&#65292;$n$&#26159;&#26679;&#26412;&#22823;&#23567;&#12290;&#36890;&#36807;&#24179;&#34913;&#26657;&#20934;&#21644;&#38160;&#24230;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#30830;&#23450;&#20102;UMB&#30340;&#26368;&#20248;&#26742;&#25968;&#19982;$n^{1/3}$&#25104;&#27604;&#20363;&#65292;&#20174;&#32780;&#20135;&#29983;&#20102;&#22823;&#32422;$O(n^{-2/3})$&#30340;&#39118;&#38505;&#30028;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24212;&#23545;&#20102;&#26631;&#31614;&#31232;&#23569;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recalibrating probabilistic classifiers is vital for enhancing the reliability and accuracy of predictive models. Despite the development of numerous recalibration algorithms, there is still a lack of a comprehensive theory that integrates calibration and sharpness (which is essential for maintaining predictive power). In this paper, we introduce the concept of minimum-risk recalibration within the framework of mean-squared-error (MSE) decomposition, offering a principled approach for evaluating and recalibrating probabilistic classifiers. Using this framework, we analyze the uniform-mass binning (UMB) recalibration method and establish a finite-sample risk upper bound of order $\tilde{O}(B/n + 1/B^2)$ where $B$ is the number of bins and $n$ is the sample size. By balancing calibration and sharpness, we further determine that the optimal number of bins for UMB scales with $n^{1/3}$, resulting in a risk bound of approximately $O(n^{-2/3})$. Additionally, we tackle the challenge of label
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#38750;&#31283;&#24577;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#25240;&#25187;&#27748;&#26222;&#26862;&#25277;&#26679;&#31639;&#27861;&#65288;DS-TS&#65289;&#65292;&#21487;&#20197;&#35299;&#20915;&#31361;&#28982;&#24615;&#21464;&#21270;&#21644;&#24179;&#28369;&#24615;&#21464;&#21270;&#30340;&#38382;&#39064;&#65292;&#24182;&#19988;&#22312;&#20004;&#31181;&#24773;&#20917;&#19979;&#20855;&#26377;&#36817;&#20046;&#26368;&#20248;&#30340;&#36951;&#25022;&#19978;&#38480;&#12290;</title><link>http://arxiv.org/abs/2305.10718</link><description>&lt;p&gt;
&#38024;&#23545;&#38750;&#31283;&#24577;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#25240;&#25187;&#27748;&#26222;&#26862;&#25277;&#26679;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Discounted Thompson Sampling for Non-Stationary Bandit Problems. (arXiv:2305.10718v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10718
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#38750;&#31283;&#24577;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#25240;&#25187;&#27748;&#26222;&#26862;&#25277;&#26679;&#31639;&#27861;&#65288;DS-TS&#65289;&#65292;&#21487;&#20197;&#35299;&#20915;&#31361;&#28982;&#24615;&#21464;&#21270;&#21644;&#24179;&#28369;&#24615;&#21464;&#21270;&#30340;&#38382;&#39064;&#65292;&#24182;&#19988;&#22312;&#20004;&#31181;&#24773;&#20917;&#19979;&#20855;&#26377;&#36817;&#20046;&#26368;&#20248;&#30340;&#36951;&#25022;&#19978;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#38750;&#31283;&#24577;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#21463;&#21040;&#20102;&#26174;&#33879;&#20851;&#27880;&#12290;NS-MAB&#36890;&#24120;&#22312;&#20004;&#31181;&#24773;&#20917;&#19979;&#36827;&#34892;&#24314;&#27169;&#65306;&#31361;&#28982;&#24615;&#21464;&#21270;&#21644;&#24179;&#28369;&#24615;&#21464;&#21270;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#24102;&#26377;&#39640;&#26031;&#20808;&#39564;&#30340;&#25240;&#25187;&#27748;&#26222;&#26862;&#37319;&#26679;&#31639;&#27861;&#65288;DS-TS&#65289;&#20197;&#35299;&#20915;&#36825;&#20004;&#20010;&#38750;&#31283;&#24577;&#35774;&#32622;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#36890;&#36807;&#23558;&#25240;&#25187;&#22240;&#23376;&#32435;&#20837;&#27748;&#26222;&#26862;&#37319;&#26679;&#26469;&#34987;&#21160;&#36866;&#24212;&#21464;&#21270;&#12290;DS-TS&#26041;&#27861;&#32463;&#36807;&#23454;&#39564;&#39564;&#35777;&#65292;&#20294;&#32570;&#20047;&#23545;&#36951;&#25022;&#19978;&#38480;&#30340;&#20998;&#26512;&#12290;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#24102;&#26377;&#39640;&#26031;&#20808;&#39564;&#30340;DS-TS&#21487;&#20197;&#22312;&#31361;&#28982;&#24615;&#21464;&#21270;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#36817;&#20046;&#26368;&#20248;&#30340;&#36951;&#25022;&#19978;&#38480;&#65288;$\tilde{O} (\sqrt {TB_T})$&#65289;&#65292;&#22312;&#24179;&#28369;&#24615;&#21464;&#21270;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616; $\tilde{O}(T^{\beta})$ &#30340;&#36817;&#20046;&#26368;&#20248;&#36951;&#25022;&#19978;&#38480;&#65292;&#20854;&#20013; $T$ &#26159;&#26102;&#38388;&#27493;&#25968;&#65292;$B_T$ &#26159;&#26029;&#28857;&#25968;&#65292;$\beta$ &#19982;&#25910;&#30410;&#20998;&#24067;&#30340;&#24179;&#28369;&#24615;&#26377;&#20851;&#65292;$\tilde{O}$ &#26159;&#23545;&#25968;&#36951;&#25022;&#19978;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
Non-stationary multi-armed bandit (NS-MAB) problems have recently received significant attention. NS-MAB are typically modelled in two scenarios: abruptly changing, where reward distributions remain constant for a certain period and change at unknown time steps, and smoothly changing, where reward distributions evolve smoothly based on unknown dynamics. In this paper, we propose Discounted Thompson Sampling (DS-TS) with Gaussian priors to address both non-stationary settings. Our algorithm passively adapts to changes by incorporating a discounted factor into Thompson Sampling. DS-TS method has been experimentally validated, but analysis of the regret upper bound is currently lacking. Under mild assumptions, we show that DS-TS with Gaussian priors can achieve nearly optimal regret bound on the order of $\tilde{O}(\sqrt{TB_T})$ for abruptly changing and $\tilde{O}(T^{\beta})$ for smoothly changing, where $T$ is the number of time steps, $B_T$ is the number of breakpoints, $\beta$ is asso
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#24322;&#26500;&#32676;&#20307;&#24378;&#21270;&#23398;&#20064;&#20013;&#32852;&#37030;Q&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20445;&#35777;&#65292;&#35752;&#35770;&#20102;&#21516;&#27493;&#21644;&#24322;&#27493;&#29256;&#26412;&#30340;&#32447;&#24615;&#21152;&#36895;&#65292;&#21516;&#26102;&#25506;&#31350;&#20102;&#31561;&#26435;&#37325;&#24179;&#22343;&#26412;&#22320;Q&#20272;&#35745;&#30340;&#32570;&#38519;&#12290;</title><link>http://arxiv.org/abs/2305.10697</link><description>&lt;p&gt;
&#24322;&#26500;&#32676;&#20307;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#31119;&#38899;&#65306;&#32447;&#24615;&#21152;&#36895;&#21644;&#26356;&#22810;&#21487;&#33021;
&lt;/p&gt;
&lt;p&gt;
The Blessing of Heterogeneity in Federated Q-learning: Linear Speedup and Beyond. (arXiv:2305.10697v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10697
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#24322;&#26500;&#32676;&#20307;&#24378;&#21270;&#23398;&#20064;&#20013;&#32852;&#37030;Q&#23398;&#20064;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20445;&#35777;&#65292;&#35752;&#35770;&#20102;&#21516;&#27493;&#21644;&#24322;&#27493;&#29256;&#26412;&#30340;&#32447;&#24615;&#21152;&#36895;&#65292;&#21516;&#26102;&#25506;&#31350;&#20102;&#31561;&#26435;&#37325;&#24179;&#22343;&#26412;&#22320;Q&#20272;&#35745;&#30340;&#32570;&#38519;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#30340;&#25968;&#25454;&#30001;&#22810;&#20010;&#20195;&#29702;&#20197;&#20998;&#24067;&#24335;&#26041;&#24335;&#25910;&#38598;&#26102;&#65292;&#32852;&#37030;RL&#31639;&#27861;&#20801;&#35768;&#21327;&#20316;&#23398;&#20064;&#65292;&#26080;&#38656;&#20849;&#20139;&#26412;&#22320;&#25968;&#25454;&#12290;&#26412;&#25991;&#32771;&#34385;&#32852;&#37030;Q&#23398;&#20064;&#65292;&#20854;&#30446;&#30340;&#26159;&#36890;&#36807;&#23450;&#26399;&#32858;&#21512;&#20165;&#22312;&#26412;&#22320;&#25968;&#25454;&#19978;&#35757;&#32451;&#30340;&#26412;&#22320;Q&#20272;&#35745;&#26469;&#23398;&#20064;&#26368;&#20248;Q&#20989;&#25968;&#12290;&#38024;&#23545;&#26080;&#38480;&#26102;&#38388;&#33976;&#39311;&#26631;&#35760;&#20915;&#31574;&#36807;&#31243;&#65292;&#25105;&#20204;&#20026;&#21516;&#27493;&#21644;&#24322;&#27493;&#29256;&#26412;&#30340;&#32852;&#37030;Q&#23398;&#20064;&#25552;&#20379;&#20102;&#26679;&#26412;&#22797;&#26434;&#24230;&#20445;&#35777;&#12290;&#22312;&#20004;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#30028;&#38480;&#23637;&#31034;&#20102;&#19982;&#20195;&#29702;&#25968;&#37327;&#25104;&#32447;&#24615;&#21152;&#36895;&#20197;&#21450;&#20854;&#20182;&#26174;&#33879;&#38382;&#39064;&#21442;&#25968;&#30340;&#26356;&#23574;&#38160;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;&#27492;&#22806;&#65292;&#29616;&#26377;&#30340;&#32852;&#37030;Q&#23398;&#20064;&#26041;&#27861;&#37319;&#29992;&#31561;&#26435;&#37325;&#24179;&#22343;&#26412;&#22320;Q&#20272;&#35745;&#65292;&#36825;&#22312;&#24322;&#27493;&#35774;&#32622;&#20013;&#21487;&#33021;&#20250;&#39640;&#24230;&#27425;&#20248;&#65292;&#22240;&#20026;&#30001;&#20110;&#19981;&#21516;&#30340;&#26412;&#22320;&#34892;&#20026;&#31574;&#30053;&#65292;&#26412;&#22320;&#36712;&#36857;&#21487;&#33021;&#39640;&#24230;&#24322;&#26500;&#12290;&#29616;&#26377;&#30340;&#26679;&#26412;&#26368;&#20248;&#21270;&#31574;&#30053;&#22312;&#24322;&#27493;&#35774;&#32622;&#20013;&#23384;&#22312;&#24040;&#22823;&#32570;&#38519;&#12290;
&lt;/p&gt;
&lt;p&gt;
When the data used for reinforcement learning (RL) are collected by multiple agents in a distributed manner, federated versions of RL algorithms allow collaborative learning without the need of sharing local data. In this paper, we consider federated Q-learning, which aims to learn an optimal Q-function by periodically aggregating local Q-estimates trained on local data alone. Focusing on infinite-horizon tabular Markov decision processes, we provide sample complexity guarantees for both the synchronous and asynchronous variants of federated Q-learning. In both cases, our bounds exhibit a linear speedup with respect to the number of agents and sharper dependencies on other salient problem parameters. Moreover, existing approaches to federated Q-learning adopt an equally-weighted averaging of local Q-estimates, which can be highly sub-optimal in the asynchronous setting since the local trajectories can be highly heterogeneous due to different local behavior policies. Existing sample com
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#36827;&#34892;&#20851;&#20110;&#20855;&#26377;&#26080;&#30028;&#26041;&#24046;&#26435;&#37325;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;&#21518;&#39564;&#25512;&#26029;&#65292;&#24182;&#34920;&#26126;&#21518;&#39564;&#20998;&#24067;&#38598;&#20013;&#22312;&#20855;&#26377;&#38750;&#26631;&#20934;&#36229;&#21442;&#25968;&#20381;&#36182;&#24615;&#30340;&#31232;&#30095;&#20419;&#36827;&#21644;&#22343;&#20540;&#25910;&#32553;&#20808;&#39564;&#21608;&#22260;&#12290;</title><link>http://arxiv.org/abs/2305.10664</link><description>&lt;p&gt;
&#26435;&#37325;&#20855;&#26377;&#26080;&#30028;&#26041;&#24046;&#30340;&#26080;&#38480;&#23485;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#21518;&#39564;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Posterior Inference on Infinitely Wide Bayesian Neural Networks under Weights with Unbounded Variance. (arXiv:2305.10664v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10664
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#36827;&#34892;&#20851;&#20110;&#20855;&#26377;&#26080;&#30028;&#26041;&#24046;&#26435;&#37325;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;&#21518;&#39564;&#25512;&#26029;&#65292;&#24182;&#34920;&#26126;&#21518;&#39564;&#20998;&#24067;&#38598;&#20013;&#22312;&#20855;&#26377;&#38750;&#26631;&#20934;&#36229;&#21442;&#25968;&#20381;&#36182;&#24615;&#30340;&#31232;&#30095;&#20419;&#36827;&#21644;&#22343;&#20540;&#25910;&#32553;&#20808;&#39564;&#21608;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;Neal&#65288;1996&#65289;&#30340;&#32463;&#20856;&#32780;&#26377;&#24433;&#21709;&#21147;&#30340;&#20316;&#21697;&#24050;&#30693;&#65292;&#20855;&#26377;&#19968;&#23618;&#38544;&#34255;&#23618;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;&#26080;&#38480;&#23485;&#24230;&#26631;&#24230;&#26497;&#38480;&#26159;&#19968;&#20010;&#39640;&#26031;&#36807;&#31243;&#65292;&#24403;&#32593;&#32476;&#26435;&#37325;&#20855;&#26377;&#26377;&#30028;&#20808;&#39564;&#26041;&#24046;&#26102;&#12290;Neal&#30340;&#32467;&#26524;&#24050;&#25193;&#23637;&#21040;&#20855;&#26377;&#22810;&#20010;&#38544;&#34255;&#23618;&#21644;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#32593;&#32476;&#65292;&#20063;&#20855;&#26377;&#39640;&#26031;&#36807;&#31243;&#26631;&#24230;&#26497;&#38480;&#12290;&#39640;&#26031;&#36807;&#31243;&#30340;&#26131;&#22788;&#29702;&#23646;&#24615;&#20801;&#35768;&#30452;&#25509;&#30340;&#21518;&#39564;&#25512;&#26029;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#30456;&#27604;&#26377;&#38480;&#23485;&#24230;&#30340;&#32593;&#32476;&#65292;&#26497;&#22823;&#22320;&#31616;&#21270;&#20102;&#26497;&#38480;&#36807;&#31243;&#30340;&#30740;&#31350;&#12290;&#28982;&#32780;&#65292;&#20855;&#26377;&#26080;&#30028;&#26041;&#24046;&#30340;&#31070;&#32463;&#32593;&#32476;&#26435;&#37325;&#38754;&#20020;&#30528;&#29420;&#29305;&#30340;&#25361;&#25112;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#32463;&#20856;&#30340;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#22833;&#25928;&#65292;&#25454;&#36866;&#24403;&#26465;&#20214;&#19979;&#30340;&#31283;&#23450;$\alpha$&#36807;&#31243;&#30340;&#26631;&#24230;&#26497;&#38480;&#30340;&#25991;&#29486;&#36739;&#22810;&#30340;&#26159;&#21069;&#21521;&#27169;&#25311;&#65292;&#32780;&#22312;&#36825;&#20123;&#26435;&#37325;&#19979;&#30340;&#21518;&#39564;&#25512;&#26029;&#38382;&#39064;&#20173;&#28982;&#26159;&#19968;&#20010;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20851;&#20110;&#20855;&#26377;&#26080;&#30028;&#26041;&#24046;&#26435;&#37325;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#21518;&#39564;&#25512;&#26029;&#30340;&#26032;&#29702;&#35770;&#27934;&#23519;&#21147;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#31181;&#26032;&#30340;&#21518;&#39564;&#25910;&#32553;&#36895;&#29575;&#32467;&#26524;&#65292;&#24182;&#34920;&#26126;&#21518;&#39564;&#20998;&#24067;&#38598;&#20013;&#22312;&#20855;&#26377;&#38750;&#26631;&#20934;&#36229;&#21442;&#25968;&#20381;&#36182;&#24615;&#30340;&#31232;&#30095;&#20419;&#36827;&#21644;&#22343;&#20540;&#25910;&#32553;&#20808;&#39564;&#21608;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;
From the classical and influential works of Neal (1996), it is known that the infinite width scaling limit of a Bayesian neural network with one hidden layer is a Gaussian process, \emph{when the network weights have bounded prior variance}. Neal's result has been extended to networks with multiple hidden layers and to convolutional neural networks, also with Gaussian process scaling limits. The tractable properties of Gaussian processes then allow straightforward posterior inference and uncertainty quantification, considerably simplifying the study of the limit process compared to a network of finite width. Neural network weights with unbounded variance, however, pose unique challenges. In this case, the classical central limit theorem breaks down and it is well known that the scaling limit is an $\alpha$-stable process under suitable conditions. However, current literature is primarily limited to forward simulations under these processes and the problem of posterior inference under s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22686;&#24378;&#30340;&#28040;&#24687;&#20256;&#36882;&#26031;&#22374;&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#27861;(AUMP-SVGD)&#26469;&#24212;&#23545; Stein Variational Gradient Descent (SVGD)&#26041;&#27861;&#30340;&#26041;&#24046;&#23849;&#28291;&#38382;&#39064;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#33021;&#22815;&#25552;&#39640;SVGD&#22312;&#39640;&#32500;&#38382;&#39064;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.10636</link><description>&lt;p&gt;
&#22686;&#24378;&#30340;&#28040;&#24687;&#20256;&#36882;&#26031;&#22374;&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#27861;
&lt;/p&gt;
&lt;p&gt;
Augmented Message Passing Stein Variational Gradient Descent. (arXiv:2305.10636v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10636
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22686;&#24378;&#30340;&#28040;&#24687;&#20256;&#36882;&#26031;&#22374;&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#27861;(AUMP-SVGD)&#26469;&#24212;&#23545; Stein Variational Gradient Descent (SVGD)&#26041;&#27861;&#30340;&#26041;&#24046;&#23849;&#28291;&#38382;&#39064;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#33021;&#22815;&#25552;&#39640;SVGD&#22312;&#39640;&#32500;&#38382;&#39064;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Stein Variational Gradient Descent (SVGD)&#26159;&#19968;&#31181;&#29992;&#20110;&#36125;&#21494;&#26031;&#25512;&#29702;&#30340;&#22522;&#20110;&#31890;&#23376;&#30340;&#27969;&#34892;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#23427;&#30340;&#25910;&#25947;&#24615;&#36973;&#21463;&#26041;&#24046;&#23849;&#28291;&#30340;&#24433;&#21709;&#65292;&#36825;&#20250;&#38477;&#20302;&#20272;&#35745;&#30340;&#20934;&#30830;&#24615;&#21644;&#22810;&#26679;&#24615;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#25910;&#25947;&#36807;&#31243;&#20013;&#26377;&#38480;&#31890;&#23376;&#30340;&#31561;&#21521;&#24615;&#23646;&#24615;&#65292;&#34920;&#26126;&#26377;&#38480;&#31890;&#23376;&#30340;SVGD&#26080;&#27861;&#22312;&#25972;&#20010;&#26679;&#26412;&#31354;&#38388;&#20013;&#20256;&#25773;&#12290;&#30456;&#21453;&#65292;&#25152;&#26377;&#31890;&#23376;&#20542;&#21521;&#20110;&#22312;&#19968;&#23450;&#33539;&#22260;&#20869;&#32858;&#38598;&#22312;&#31890;&#23376;&#20013;&#24515;&#21608;&#22260;&#65292;&#24182;&#19988;&#25105;&#20204;&#25552;&#20379;&#20102;&#27492;&#32858;&#31867;&#30340;&#20998;&#26512;&#30028;&#38480;&#12290;&#20026;&#36827;&#19968;&#27493;&#25913;&#21892;SVGD&#22312;&#39640;&#32500;&#38382;&#39064;&#20013;&#30340;&#26377;&#25928;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22686;&#24378;&#28040;&#24687;&#20256;&#36882;&#26031;&#22374;&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#27861;(AUMP-SVGD)&#26041;&#27861;&#65292;&#36825;&#26159;&#19968;&#31181;&#20004;&#38454;&#27573;&#20248;&#21270;&#36807;&#31243;&#65292;&#19981;&#38656;&#35201;&#30446;&#26631;&#20998;&#24067;&#30340;&#31232;&#30095;&#24615;&#65292;&#19981;&#20687;MP-SVGD&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#21508;&#31181;&#22522;&#20934;&#38382;&#39064;&#20013;&#23454;&#29616;&#20102;&#20196;&#20154;&#28385;&#24847;&#30340;&#20934;&#30830;&#24615;&#65292;&#24182;&#20811;&#26381;&#20102;&#26041;&#24046;&#23849;&#28291;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stein Variational Gradient Descent (SVGD) is a popular particle-based method for Bayesian inference. However, its convergence suffers from the variance collapse, which reduces the accuracy and diversity of the estimation. In this paper, we study the isotropy property of finite particles during the convergence process and show that SVGD of finite particles cannot spread across the entire sample space. Instead, all particles tend to cluster around the particle center within a certain range and we provide an analytical bound for this cluster. To further improve the effectiveness of SVGD for high-dimensional problems, we propose the Augmented Message Passing SVGD (AUMP-SVGD) method, which is a two-stage optimization procedure that does not require sparsity of the target distribution, unlike the MP-SVGD method. Our algorithm achieves satisfactory accuracy and overcomes the variance collapse problem in various benchmark problems.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#24179;&#28369;&#21270;&#30340;&#25439;&#22833;&#26469;&#20248;&#21270;&#22312;&#32447;SGD&#30340;&#20449;&#21495;&#65292;&#21487;&#20197;&#20351;&#29992;$n \gtrsim d^{k^\star/2}$&#20010;&#26679;&#26412;&#23398;&#20064;&#21333;&#25351;&#25968;&#27169;&#22411;$w^\star$&#65292;&#24182;&#19982;&#24352;&#37327;PCA&#21644;&#23567;&#25209;&#37327;SGD&#30340;&#27491;&#21017;&#21270;&#25928;&#24212;&#26377;&#20851;&#12290;</title><link>http://arxiv.org/abs/2305.10633</link><description>&lt;p&gt;
&#24179;&#28369;&#21270;&#39118;&#26223;&#21487;&#25552;&#21319;SGD&#20449;&#21495;&#65306;&#23398;&#20064;&#21333;&#25351;&#25968;&#27169;&#22411;&#30340;&#26368;&#20248;&#26679;&#26412;&#22797;&#26434;&#24230;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Smoothing the Landscape Boosts the Signal for SGD: Optimal Sample Complexity for Learning Single Index Models. (arXiv:2305.10633v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10633
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#24179;&#28369;&#21270;&#30340;&#25439;&#22833;&#26469;&#20248;&#21270;&#22312;&#32447;SGD&#30340;&#20449;&#21495;&#65292;&#21487;&#20197;&#20351;&#29992;$n \gtrsim d^{k^\star/2}$&#20010;&#26679;&#26412;&#23398;&#20064;&#21333;&#25351;&#25968;&#27169;&#22411;$w^\star$&#65292;&#24182;&#19982;&#24352;&#37327;PCA&#21644;&#23567;&#25209;&#37327;SGD&#30340;&#27491;&#21017;&#21270;&#25928;&#24212;&#26377;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;$d$&#32500;&#24230;&#19978;&#20351;&#29992;&#21508;&#21521;&#21516;&#24615;&#39640;&#26031;&#20998;&#24067;&#26469;&#23398;&#20064;&#21333;&#25351;&#25968;&#27169;&#22411;$\sigma(w^\star \cdot x)$&#30340;&#20219;&#21153;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#23398;&#20064;$w^\star$&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#26159;&#30001;&#38142;&#25509;&#20989;&#25968;$\sigma$&#30340;&#20449;&#24687;&#25351;&#25968;$k^\star$&#25152;&#20915;&#23450;&#30340;&#65292;&#23427;&#34987;&#23450;&#20041;&#20026;$\sigma$&#30340;&#31532;&#19968;&#20010;&#38750;&#38646;Hermite&#31995;&#25968;&#30340;&#25351;&#25968;&#12290;&#26412;&#25991;&#36890;&#36807;&#23637;&#31034;&#22522;&#20110;&#24179;&#28369;&#25439;&#22833;&#30340;&#22312;&#32447;SGD&#20351;&#29992;$n \gtrsim d^{k^\star/2}$&#20010;&#26679;&#26412;&#21487;&#20197;&#23398;&#20064;$w^\star$&#65292;&#24357;&#34917;&#20102;&#19978;&#19979;&#30028;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#20316;&#32773;&#36824;&#23558;&#20854;&#19982;&#24352;&#37327;PCA&#30340;&#32479;&#35745;&#20998;&#26512;&#21644;&#23567;&#25209;&#37327;SGD&#22312;&#32463;&#39564;&#25439;&#22833;&#19978;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#25928;&#24212;&#32852;&#31995;&#36215;&#26469;&#12290;
&lt;/p&gt;
&lt;p&gt;
We focus on the task of learning a single index model $\sigma(w^\star \cdot x)$ with respect to the isotropic Gaussian distribution in $d$ dimensions. Prior work has shown that the sample complexity of learning $w^\star$ is governed by the information exponent $k^\star$ of the link function $\sigma$, which is defined as the index of the first nonzero Hermite coefficient of $\sigma$. Ben Arous et al. (2021) showed that $n \gtrsim d^{k^\star-1}$ samples suffice for learning $w^\star$ and that this is tight for online SGD. However, the CSQ lower bound for gradient based methods only shows that $n \gtrsim d^{k^\star/2}$ samples are necessary. In this work, we close the gap between the upper and lower bounds by showing that online SGD on a smoothed loss learns $w^\star$ with $n \gtrsim d^{k^\star/2}$ samples. We also draw connections to statistical analyses of tensor PCA and to the implicit regularization effects of minibatch SGD on empirical losses.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#32034;&#20102;&#24352;&#37327;&#31215;&#22312;&#36229;&#32500;&#35745;&#31639;&#20013;&#30340;&#25968;&#23398;&#20851;&#31995;&#65292;&#23558;&#20854;&#30830;&#23450;&#20026;&#20013;&#24515;&#34920;&#31034;&#65292;&#24182;&#21457;&#29616;&#23427;&#26159;&#26368;&#36890;&#29992;&#12289;&#26368;&#20855;&#34920;&#29616;&#21147;&#21644;&#26368;&#21387;&#32553;&#30340;&#34920;&#31034;&#65292;&#21516;&#26102;&#20855;&#26377;&#26080;&#35823;&#24046;&#35299;&#32465;&#21644;&#26816;&#27979;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2305.10572</link><description>&lt;p&gt;
&#24352;&#37327;&#31215;&#19982;&#36229;&#32500;&#35745;&#31639;
&lt;/p&gt;
&lt;p&gt;
Tensor Products and Hyperdimensional Computing. (arXiv:2305.10572v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10572
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#32034;&#20102;&#24352;&#37327;&#31215;&#22312;&#36229;&#32500;&#35745;&#31639;&#20013;&#30340;&#25968;&#23398;&#20851;&#31995;&#65292;&#23558;&#20854;&#30830;&#23450;&#20026;&#20013;&#24515;&#34920;&#31034;&#65292;&#24182;&#21457;&#29616;&#23427;&#26159;&#26368;&#36890;&#29992;&#12289;&#26368;&#20855;&#34920;&#29616;&#21147;&#21644;&#26368;&#21387;&#32553;&#30340;&#34920;&#31034;&#65292;&#21516;&#26102;&#20855;&#26377;&#26080;&#35823;&#24046;&#35299;&#32465;&#21644;&#26816;&#27979;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20043;&#21069;&#23545;&#22270;&#23884;&#20837;&#30340;&#20998;&#26512;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#23558;&#19968;&#20123;&#32467;&#26524;&#25512;&#24191;&#21644;&#25299;&#23637;&#21040;&#21521;&#37327;&#31526;&#21495;&#32467;&#26500; (VSA) &#21644;&#36229;&#32500;&#35745;&#31639; (HDC) &#30340;&#19968;&#33324;&#35774;&#32622;&#20013;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#25506;&#32034;&#36229;&#21472;&#21152;&#12289;&#27491;&#20132;&#21644;&#24352;&#37327;&#31215;&#20043;&#38388;&#30340;&#25968;&#23398;&#20851;&#31995;&#12290;&#25105;&#20204;&#23558;&#24352;&#37327;&#31215;&#34920;&#31034;&#30830;&#23450;&#20026;&#20013;&#24515;&#34920;&#31034;&#65292;&#24182;&#20855;&#26377;&#19968;&#22871;&#29420;&#29305;&#30340;&#23646;&#24615;&#12290;&#36825;&#21253;&#25324;&#23427;&#26159;&#26368;&#36890;&#29992;&#21644;&#26368;&#20855;&#34920;&#29616;&#21147;&#30340;&#34920;&#31034;&#65292;&#20063;&#26159;&#26368;&#21387;&#32553;&#30340;&#34920;&#31034;&#65292;&#20855;&#26377;&#26080;&#35823;&#24046;&#35299;&#32465;&#21644;&#26816;&#27979;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Following up on a previous analysis of graph embeddings, we generalize and expand some results to the general setting of vector symbolic architectures (VSA) and hyperdimensional computing (HDC). Importantly, we explore the mathematical relationship between superposition, orthogonality, and tensor product. We establish the tensor product representation as the central representation, with a suite of unique properties. These include it being the most general and expressive representation, as well as being the most compressed representation that has errorrless unbinding and detection.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#21644;&#35270;&#35282;&#26469;&#35780;&#20272;&#21644;&#27604;&#36739;&#25918;&#24323;&#20998;&#31867;&#22120;&#65292;&#23558;&#25918;&#24323;&#39044;&#27979;&#35270;&#20026;&#32570;&#22833;&#25968;&#25454;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;&#25918;&#24323;&#20998;&#31867;&#22120;&#30340;&#21453;&#20107;&#23454;&#24471;&#20998;&#65292;&#25351;&#30340;&#26159;&#20998;&#31867;&#22120;&#27809;&#26377;&#25918;&#24323;&#39044;&#27979;&#26102;&#30340;&#39044;&#27979;&#24615;&#33021;&#26399;&#26395;&#12290;</title><link>http://arxiv.org/abs/2305.10564</link><description>&lt;p&gt;
&#23545;&#25918;&#24323;&#20998;&#31867;&#22120;&#36827;&#34892;&#21453;&#20107;&#23454;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
Counterfactually Comparing Abstaining Classifiers. (arXiv:2305.10564v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10564
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#21644;&#35270;&#35282;&#26469;&#35780;&#20272;&#21644;&#27604;&#36739;&#25918;&#24323;&#20998;&#31867;&#22120;&#65292;&#23558;&#25918;&#24323;&#39044;&#27979;&#35270;&#20026;&#32570;&#22833;&#25968;&#25454;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;&#25918;&#24323;&#20998;&#31867;&#22120;&#30340;&#21453;&#20107;&#23454;&#24471;&#20998;&#65292;&#25351;&#30340;&#26159;&#20998;&#31867;&#22120;&#27809;&#26377;&#25918;&#24323;&#39044;&#27979;&#26102;&#30340;&#39044;&#27979;&#24615;&#33021;&#26399;&#26395;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25918;&#24323;&#20998;&#31867;&#22120;&#21487;&#20197;&#36873;&#25321;&#22312;&#19981;&#30830;&#23450;&#26102;&#25918;&#24323;&#23545;&#36755;&#20837;&#30340;&#39044;&#27979;&#12290;&#36825;&#20123;&#20998;&#31867;&#22120;&#22312;&#39640;&#39118;&#38505;&#20915;&#31574;&#38382;&#39064;&#20013;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#65292;&#22240;&#20026;&#23427;&#20204;&#21487;&#20197;&#20445;&#30041;&#19981;&#30830;&#23450;&#30340;&#39044;&#27979;&#65292;&#20197;&#25552;&#39640;&#20854;&#21487;&#38752;&#24615;&#21644;&#23433;&#20840;&#24615;&#12290;&#28982;&#32780;&#65292;&#22312;&#35780;&#20272;&#40657;&#30418;&#25918;&#24323;&#20998;&#31867;&#22120;&#26102;&#65292;&#25105;&#20204;&#32570;&#20047;&#19968;&#20010;&#21407;&#21017;&#24615;&#30340;&#26041;&#27861;&#26469;&#32771;&#34385;&#20998;&#31867;&#22120;&#22312;&#23427;&#30340;&#25918;&#24323;&#39044;&#27979;&#19978;&#30340;&#39044;&#27979;&#32467;&#26524;&#12290;&#24403;&#25918;&#23556;&#31185;&#21307;&#29983;&#19981;&#30830;&#23450;&#20854;&#35786;&#26029;&#25110;&#24403;&#39550;&#39542;&#21592;&#22312;&#33258;&#21160;&#39550;&#39542;&#27773;&#36710;&#20013;&#19981;&#27880;&#24847;&#26102;&#65292;&#36825;&#20123;&#32570;&#22833;&#30340;&#39044;&#27979;&#32467;&#26524;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#21644;&#35270;&#35282;&#26469;&#35780;&#20272;&#21644;&#27604;&#36739;&#25918;&#24323;&#20998;&#31867;&#22120;&#65292;&#23558;&#25918;&#24323;&#39044;&#27979;&#35270;&#20026;&#32570;&#22833;&#25968;&#25454;&#12290;&#25105;&#20204;&#30340;&#35780;&#20272;&#26041;&#27861;&#22260;&#32469;&#30528;&#23450;&#20041;&#19968;&#20010;&#25918;&#24323;&#20998;&#31867;&#22120;&#30340;&#21453;&#20107;&#23454;&#24471;&#20998;&#65292;&#21363;&#20998;&#31867;&#22120;&#27809;&#26377;&#25918;&#24323;&#30340;&#24773;&#20917;&#19979;&#30340;&#39044;&#27979;&#24615;&#33021;&#30340;&#26399;&#26395;&#12290;&#25105;&#20204;&#25351;&#23450;&#20102;&#26465;&#20214;... (&#27492;&#22788;&#30465;&#30053;)
&lt;/p&gt;
&lt;p&gt;
Abstaining classifiers have the option to abstain from making predictions on inputs that they are unsure about. These classifiers are becoming increasingly popular in high-stake decision-making problems, as they can withhold uncertain predictions to improve their reliability and safety. When evaluating black-box abstaining classifier(s), however, we lack a principled approach that accounts for what the classifier would have predicted on its abstentions. These missing predictions are crucial when, e.g., a radiologist is unsure of their diagnosis or when a driver is inattentive in a self-driving car. In this paper, we introduce a novel approach and perspective to the problem of evaluating and comparing abstaining classifiers by treating abstentions as missing data. Our evaluation approach is centered around defining the counterfactual score of an abstaining classifier, defined as the expected performance of the classifier had it not been allowed to abstain. We specify the conditions unde
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#21442;&#25968;&#21270;&#35745;&#31639;&#20284;&#28982;&#27604;&#30340;&#25216;&#24039;&#65292;&#24182;&#35814;&#32454;&#27604;&#36739;&#20102;&#19981;&#21516;&#35774;&#32622;&#30340;&#24615;&#33021;&#12290;&#36825;&#23545;&#20110;&#35768;&#22810;&#25968;&#25454;&#25110;&#22522;&#20110;&#27169;&#25311;&#30340;&#31185;&#23398;&#24212;&#29992;&#38750;&#24120;&#26377;&#29992;&#12290;</title><link>http://arxiv.org/abs/2305.10500</link><description>&lt;p&gt;
&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#23398;&#20064;&#20284;&#28982;&#27604;
&lt;/p&gt;
&lt;p&gt;
Learning Likelihood Ratios with Neural Network Classifiers. (arXiv:2305.10500v1 [hep-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10500
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#21442;&#25968;&#21270;&#35745;&#31639;&#20284;&#28982;&#27604;&#30340;&#25216;&#24039;&#65292;&#24182;&#35814;&#32454;&#27604;&#36739;&#20102;&#19981;&#21516;&#35774;&#32622;&#30340;&#24615;&#33021;&#12290;&#36825;&#23545;&#20110;&#35768;&#22810;&#25968;&#25454;&#25110;&#22522;&#20110;&#27169;&#25311;&#30340;&#31185;&#23398;&#24212;&#29992;&#38750;&#24120;&#26377;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31185;&#23398;&#20013;&#65292;&#20284;&#28982;&#27604;&#26159;&#32479;&#35745;&#25512;&#26029;&#30340;&#20851;&#38190;&#24615;&#37327;&#65292;&#23427;&#20351;&#24471;&#20551;&#35774;&#26816;&#39564;&#12289;&#32622;&#20449;&#21306;&#38388;&#26500;&#24314;&#12289;&#20998;&#24067;&#21152;&#26435;&#31561;&#25104;&#20026;&#21487;&#33021;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#29616;&#20195;&#31185;&#23398;&#24212;&#29992;&#20351;&#29992;&#22522;&#20110;&#25968;&#25454;&#25110;&#22522;&#20110;&#27169;&#25311;&#30340;&#27169;&#22411;&#65292;&#32780;&#35745;&#31639;&#20284;&#28982;&#27604;&#21487;&#33021;&#38750;&#24120;&#22256;&#38590;&#29978;&#33267;&#19981;&#21487;&#33021;&#12290;&#36890;&#36807;&#24212;&#29992;&#25152;&#35859;&#30340;&#8220;&#20284;&#28982;&#27604;&#25216;&#24039;&#8221;&#65292;&#21487;&#20197;&#20351;&#29992;&#32874;&#26126;&#30340;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#21442;&#25968;&#21270;&#26469;&#35745;&#31639;&#20284;&#28982;&#27604;&#30340;&#36817;&#20284;&#20540;&#12290;&#21487;&#20197;&#23450;&#20041;&#35768;&#22810;&#19981;&#21516;&#30340;&#31070;&#32463;&#32593;&#32476;&#35774;&#32622;&#26469;&#28385;&#36275;&#27492;&#36807;&#31243;&#65292;&#27599;&#20010;&#35774;&#32622;&#22312;&#20351;&#29992;&#26377;&#38480;&#35757;&#32451;&#25968;&#25454;&#26102;&#36817;&#20284;&#20284;&#28982;&#27604;&#30340;&#24615;&#33021;&#21508;&#24322;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#32463;&#39564;&#30740;&#31350;&#65292;&#35814;&#32454;&#20171;&#32461;&#20102;&#20960;&#31181;&#24120;&#35265;&#25439;&#22833;&#20989;&#25968;&#21644;&#20998;&#31867;&#22120;&#36755;&#20986;&#21442;&#25968;&#21270;&#22312;&#36817;&#20284;&#20004;&#20010;&#19968;&#20803;&#21644;&#22810;&#20803;&#39640;&#26031;&#20998;&#24067;&#30340;&#20284;&#28982;&#27604;&#26041;&#38754;&#30340;&#34920;&#29616;&#20197;&#21450;&#27169;&#25311;&#39640;&#33021;&#29289;&#29702;&#30340;&#20449;&#21495;&#21644;&#32972;&#26223;&#20107;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
The likelihood ratio is a crucial quantity for statistical inference in science that enables hypothesis testing, construction of confidence intervals, reweighting of distributions, and more. Many modern scientific applications, however, make use of data- or simulation-driven models for which computing the likelihood ratio can be very difficult or even impossible. By applying the so-called ``likelihood ratio trick,'' approximations of the likelihood ratio may be computed using clever parametrizations of neural network-based classifiers. A number of different neural network setups can be defined to satisfy this procedure, each with varying performance in approximating the likelihood ratio when using finite training data. We present a series of empirical studies detailing the performance of several common loss functionals and parametrizations of the classifier output in approximating the likelihood ratio of two univariate and multivariate Gaussian distributions as well as simulated high-e
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;Wasserstein&#21453;&#21521;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#36866;&#29992;&#20110;&#22810;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#65292;&#21487;&#35753;&#23398;&#20064;&#32773;&#30340;&#22870;&#21169;&#20540;&#21644;&#26368;&#20248;&#35299;&#27169;&#20223;&#19987;&#23478;&#65292;&#20855;&#26377;&#19968;&#23450;&#30340;&#23454;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2305.10089</link><description>&lt;p&gt;
&#19968;&#31181;&#22810;&#30446;&#26631;&#20248;&#21270;&#30340;Wasserstein&#21453;&#21521;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#30340;&#35777;&#26126;
&lt;/p&gt;
&lt;p&gt;
A proof of imitation of Wasserstein inverse reinforcement learning for multi-objective optimization. (arXiv:2305.10089v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10089
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;Wasserstein&#21453;&#21521;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#36866;&#29992;&#20110;&#22810;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#65292;&#21487;&#35753;&#23398;&#20064;&#32773;&#30340;&#22870;&#21169;&#20540;&#21644;&#26368;&#20248;&#35299;&#27169;&#20223;&#19987;&#23478;&#65292;&#20855;&#26377;&#19968;&#23450;&#30340;&#23454;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;Wasserstein&#21453;&#21521;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#21487;&#20197;&#22312;&#26377;&#38480;&#27425;&#36845;&#20195;&#20013;&#35753;&#23398;&#20064;&#32773;&#30340;&#22870;&#21169;&#20540;&#27169;&#20223;&#19987;&#23478;&#30340;&#22870;&#21169;&#20540;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#35789;&#20856;&#24207;&#30340;&#22810;&#30446;&#26631;&#20248;&#21270;&#20013;&#65292;Wasserstein&#21453;&#21521;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#21487;&#20197;&#35753;&#23398;&#20064;&#32773;&#30340;&#26368;&#20248;&#35299;&#27169;&#20223;&#19987;&#23478;&#30340;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
We prove Wasserstein inverse reinforcement learning enables the learner's reward values to imitate the expert's reward values in a finite iteration for multi-objective optimizations. Moreover, we prove Wasserstein inverse reinforcement learning enables the learner's optimal solutions to imitate the expert's optimal solutions for multi-objective optimizations with lexicographic order.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#31181;&#33258;&#28982;&#30340;&#32858;&#21512;&#26041;&#27861;&#65306;&#22522;&#20110;&#20849;&#21516;&#29305;&#24449;&#23558;&#25968;&#25454;&#28857;&#20998;&#32452;&#30340;&#31934;&#36873;&#21253;&#21644;&#23558;&#25968;&#25454;&#28857;&#38543;&#26426;&#20998;&#32452;&#30340;&#38543;&#26426;&#21253;&#65292;&#23545;&#20110;&#31934;&#36873;&#21253;&#35774;&#32622;&#21644;&#24191;&#27867;&#30340;&#25439;&#22833;&#20989;&#25968;&#33539;&#22260;&#20869;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21487;&#20197;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#32780;&#19981;&#20250;&#23548;&#33268;&#25968;&#25454;&#32858;&#21512;&#23548;&#33268;&#24615;&#33021;&#19979;&#38477;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2305.09557</link><description>&lt;p&gt;
&#22823;&#25968;&#25454;&#23398;&#20064;&#65306;&#31934;&#36873;&#21253;&#19982;&#38543;&#26426;&#21253;&#30340;&#23545;&#27604;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Learning from Aggregated Data: Curated Bags versus Random Bags. (arXiv:2305.09557v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.09557
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#31181;&#33258;&#28982;&#30340;&#32858;&#21512;&#26041;&#27861;&#65306;&#22522;&#20110;&#20849;&#21516;&#29305;&#24449;&#23558;&#25968;&#25454;&#28857;&#20998;&#32452;&#30340;&#31934;&#36873;&#21253;&#21644;&#23558;&#25968;&#25454;&#28857;&#38543;&#26426;&#20998;&#32452;&#30340;&#38543;&#26426;&#21253;&#65292;&#23545;&#20110;&#31934;&#36873;&#21253;&#35774;&#32622;&#21644;&#24191;&#27867;&#30340;&#25439;&#22833;&#20989;&#25968;&#33539;&#22260;&#20869;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21487;&#20197;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#32780;&#19981;&#20250;&#23548;&#33268;&#25968;&#25454;&#32858;&#21512;&#23548;&#33268;&#24615;&#33021;&#19979;&#38477;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20445;&#25252;&#29992;&#25143;&#38544;&#31169;&#26159;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#37096;&#32626;&#30340;&#19968;&#20010;&#20027;&#35201;&#20851;&#27880;&#28857;&#65292;&#36825;&#20123;&#31995;&#32479;&#25910;&#38598;&#26469;&#33258;&#21508;&#31181;&#32676;&#20307;&#30340;&#25968;&#25454;&#12290;&#20026;&#20102;&#24212;&#23545;&#36825;&#31181;&#38382;&#39064;&#65292;&#19968;&#31181;&#26041;&#27861;&#26159;&#20197;&#32858;&#21512;&#30340;&#24418;&#24335;&#25910;&#38598;&#21644;&#21457;&#24067;&#25968;&#25454;&#26631;&#31614;&#65292;&#20174;&#32780;&#21487;&#20197;&#23558;&#21333;&#20010;&#29992;&#25143;&#30340;&#20449;&#24687;&#19982;&#20854;&#20182;&#29992;&#25143;&#30340;&#20449;&#24687;&#32452;&#21512;&#36215;&#26469;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#20351;&#29992;&#32858;&#21512;&#25968;&#25454;&#26631;&#31614;&#32780;&#38750;&#21333;&#20010;&#26631;&#31614;&#26469;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#21487;&#33021;&#24615;&#65292;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#20004;&#31181;&#33258;&#28982;&#30340;&#32858;&#21512;&#26041;&#27861;&#65306;&#22522;&#20110;&#20849;&#21516;&#29305;&#24449;&#23558;&#25968;&#25454;&#28857;&#20998;&#32452;&#30340;&#31934;&#36873;&#21253;&#21644;&#23558;&#25968;&#25454;&#28857;&#38543;&#26426;&#20998;&#32452;&#30340;&#38543;&#26426;&#21253;&#12290;&#23545;&#20110;&#31934;&#36873;&#21253;&#35774;&#32622;&#21644;&#24191;&#27867;&#30340;&#25439;&#22833;&#20989;&#25968;&#33539;&#22260;&#20869;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21487;&#20197;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#23398;&#20064;&#32780;&#19981;&#20250;&#23548;&#33268;&#25968;&#25454;&#32858;&#21512;&#23548;&#33268;&#24615;&#33021;&#19979;&#38477;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#20197;&#19979;&#35266;&#23519;&#65306;&#25439;&#22833;&#20989;&#25968;&#30340;&#26799;&#24230;&#20043;&#21644;&#21487;&#20197;&#34920;&#31034;&#20026;&#27599;&#20010;&#21253;&#30340;&#26799;&#24230;&#30340;&#21152;&#26435;&#21644;&#65292;&#20854;&#20013;&#26435;&#37325;&#26159;&#21253;&#30340;&#22823;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;
Protecting user privacy is a major concern for many machine learning systems that are deployed at scale and collect from a diverse set of population. One way to address this concern is by collecting and releasing data labels in an aggregated manner so that the information about a single user is potentially combined with others. In this paper, we explore the possibility of training machine learning models with aggregated data labels, rather than individual labels. Specifically, we consider two natural aggregation procedures suggested by practitioners: curated bags where the data points are grouped based on common features and random bags where the data points are grouped randomly in bag of similar sizes. For the curated bag setting and for a broad range of loss functions, we show that we can perform gradient-based learning without any degradation in performance that may result from aggregating data. Our method is based on the observation that the sum of the gradients of the loss functio
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#24212;&#29992;&#20110;&#20219;&#20309;MPNN&#32467;&#26500;&#30340;&#26694;&#26550;&#65292;&#25191;&#34892;&#22522;&#20110;&#23618;&#30340;&#21160;&#24577;&#37325;&#36830;&#26469;&#30830;&#20445;&#36880;&#28176;&#23494;&#38598;&#21270;&#30340;&#22270;&#24418;&#12290;&#21516;&#26102;&#24341;&#20837;&#20102;&#19968;&#31181;&#24310;&#36831;&#26426;&#21046;&#65292;&#20801;&#35768;&#36328;&#23618;&#33410;&#28857;&#20043;&#38388;&#30340;&#36339;&#36291;&#36830;&#25509;&#12290;</title><link>http://arxiv.org/abs/2305.08018</link><description>&lt;p&gt;
DRew&#65306;&#24102;&#24310;&#36831;&#30340;&#21160;&#24577;&#37325;&#36830;&#28040;&#24687;&#20256;&#36882;
&lt;/p&gt;
&lt;p&gt;
DRew: Dynamically Rewired Message Passing with Delay. (arXiv:2305.08018v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08018
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#24212;&#29992;&#20110;&#20219;&#20309;MPNN&#32467;&#26500;&#30340;&#26694;&#26550;&#65292;&#25191;&#34892;&#22522;&#20110;&#23618;&#30340;&#21160;&#24577;&#37325;&#36830;&#26469;&#30830;&#20445;&#36880;&#28176;&#23494;&#38598;&#21270;&#30340;&#22270;&#24418;&#12290;&#21516;&#26102;&#24341;&#20837;&#20102;&#19968;&#31181;&#24310;&#36831;&#26426;&#21046;&#65292;&#20801;&#35768;&#36328;&#23618;&#33410;&#28857;&#20043;&#38388;&#30340;&#36339;&#36291;&#36830;&#25509;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24050;&#32463;&#35777;&#26126;&#65292;&#28040;&#24687;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#65288;MPNN&#65289;&#23384;&#22312;&#36807;&#24230;&#21387;&#32553;&#29616;&#35937;&#65292;&#23548;&#33268;&#38271;&#31243;&#30456;&#20114;&#20316;&#29992;&#20219;&#21153;&#34920;&#29616;&#19981;&#20339;&#12290;&#36825;&#20027;&#35201;&#24402;&#22240;&#20110;&#21482;&#22312;&#33410;&#28857;&#30340;&#30456;&#37051;&#23621;&#20043;&#38388;&#36827;&#34892;&#23616;&#37096;&#28040;&#24687;&#20256;&#36882;&#12290;&#35797;&#22270;&#20351;&#22270;&#24418;&#8220;&#26356;&#36830;&#36890;&#8221;&#24182;&#19988;&#26356;&#36866;&#21512;&#38271;&#31243;&#20219;&#21153;&#30340;&#37325;&#36830;&#26041;&#27861;&#36890;&#24120;&#20250;&#22833;&#21435;&#22522;&#20110;&#22270;&#24418;&#36317;&#31163;&#25552;&#20379;&#30340;&#24402;&#32435;&#20559;&#24046;&#65292;&#22240;&#20026;&#23427;&#20204;&#20250;&#20351;&#36828;&#31243;&#33410;&#28857;&#22312;&#27599;&#19968;&#23618;&#20013;&#31435;&#21363;&#36890;&#20449;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#21487;&#24212;&#29992;&#20110;&#20219;&#20309;MPNN&#26550;&#26500;&#65292;&#20197;&#25191;&#34892;&#22522;&#20110;&#23618;&#30340;&#37325;&#36830;&#65292;&#20197;&#30830;&#20445;&#36880;&#28176;&#21152;&#23494;&#22270;&#24418;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#24310;&#36831;&#26426;&#21046;&#65292;&#23427;&#20801;&#35768;&#26681;&#25454;&#23618;&#21644;&#23427;&#20204;&#30340;&#30456;&#20114;&#36317;&#31163;&#22312;&#33410;&#28857;&#20043;&#38388;&#36827;&#34892;&#36339;&#36291;&#36830;&#25509;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#38271;&#31243;&#20219;&#21153;&#19978;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#24182;&#34920;&#26126;&#20854;&#20248;&#20110;&#22270;&#24418;&#21464;&#25442;&#22120;&#21644;&#22810;&#36339;MPNN&#12290;
&lt;/p&gt;
&lt;p&gt;
Message passing neural networks (MPNNs) have been shown to suffer from the phenomenon of over-squashing that causes poor performance for tasks relying on long-range interactions. This can be largely attributed to message passing only occurring locally, over a node's immediate neighbours. Rewiring approaches attempting to make graphs `more connected', and supposedly better suited to long-range tasks, often lose the inductive bias provided by distance on the graph since they make distant nodes communicate instantly at every layer. In this paper we propose a framework, applicable to any MPNN architecture, that performs a layer-dependent rewiring to ensure gradual densification of the graph. We also propose a delay mechanism that permits skip connections between nodes depending on the layer and their mutual distance. We validate our approach on several long-range tasks and show that it outperforms graph Transformers and multi-hop MPNNs.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#35777;&#26126;&#20102;&#22810;&#30446;&#26631;&#20248;&#21270;&#30340;&#36870;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#22312;&#29702;&#35770;&#23618;&#38754;&#19978;&#30340;&#25910;&#25947;&#24615;&#65292;&#21253;&#25324;Wasserstein&#36870;&#24378;&#21270;&#23398;&#20064;&#21644;&#24120;&#35268;&#36870;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.06137</link><description>&lt;p&gt;
&#22810;&#30446;&#26631;&#20248;&#21270;&#30340;&#36870;&#24378;&#21270;&#23398;&#20064;&#30340;&#25910;&#25947;&#24615;&#35777;&#26126;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A proof of convergence of inverse reinforcement learning for multi-objective optimization. (arXiv:2305.06137v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06137
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#35777;&#26126;&#20102;&#22810;&#30446;&#26631;&#20248;&#21270;&#30340;&#36870;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#22312;&#29702;&#35770;&#23618;&#38754;&#19978;&#30340;&#25910;&#25947;&#24615;&#65292;&#21253;&#25324;Wasserstein&#36870;&#24378;&#21270;&#23398;&#20064;&#21644;&#24120;&#35268;&#36870;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23558;&#31561;&#25928;&#20110;&#22810;&#30446;&#26631;&#20248;&#21270;&#30340;WIRL&#38382;&#39064;&#30340;&#36870;&#38382;&#39064;&#19982;&#25237;&#24433;&#27425;&#26799;&#24230;&#27861;&#30456;&#32467;&#21512;&#65292;&#35777;&#26126;&#20102;Wasserstein&#36870;&#24378;&#21270;&#23398;&#20064;&#65288;WIRL&#65289;&#22312;&#22810;&#30446;&#26631;&#20248;&#21270;&#20013;&#30340;&#25910;&#25947;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#36870;&#24378;&#21270;&#23398;&#20064;&#65288;&#26368;&#22823;&#29109;&#36870;&#24378;&#21270;&#23398;&#20064;&#65292;&#23548;&#24341;&#25104;&#26412;&#23398;&#20064;&#65289;&#22312;&#22810;&#30446;&#26631;&#20248;&#21270;&#20013;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We show the convergence of Wasserstein inverse reinforcement learning (WIRL) for multi-objective optimizations with the projective subgradient method by formulating an inverse problem of the optimization problem that is equivalent to WIRL for multi-objective optimizations.  In addition, we prove convergence of inverse reinforcement learning (maximum entropy inverse reinforcement learning, guid cost learning) for multi-objective optimization with the projective subgradient method.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#22312;&#26679;&#26412;&#20013;&#24341;&#20837;&#25200;&#21160;&#65292;&#25913;&#36827;&#22522;&#20110;&#26680;&#21270;&#26031;&#22374;&#36317;&#30340;&#25311;&#21512;&#20248;&#24230;&#26816;&#39564;&#26041;&#27861;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#22312;&#21516;&#36136;&#20294;&#28151;&#21512;&#27604;&#20363;&#19981;&#21516;&#30340;&#24773;&#20917;&#19979;&#20302;&#21151;&#29575;&#30340;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#23454;&#39564;&#35777;&#25454;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#21151;&#25928;&#12290;</title><link>http://arxiv.org/abs/2304.14762</link><description>&lt;p&gt;
&#21033;&#29992;&#25200;&#21160;&#26469;&#25913;&#21892;&#22522;&#20110;&#26680;&#21270;&#26031;&#22374;&#36317;&#30340;&#25311;&#21512;&#20248;&#24230;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Using Perturbation to Improve Goodness-of-Fit Tests based on Kernelized Stein Discrepancy. (arXiv:2304.14762v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14762
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#22312;&#26679;&#26412;&#20013;&#24341;&#20837;&#25200;&#21160;&#65292;&#25913;&#36827;&#22522;&#20110;&#26680;&#21270;&#26031;&#22374;&#36317;&#30340;&#25311;&#21512;&#20248;&#24230;&#26816;&#39564;&#26041;&#27861;&#30340;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#22312;&#21516;&#36136;&#20294;&#28151;&#21512;&#27604;&#20363;&#19981;&#21516;&#30340;&#24773;&#20917;&#19979;&#20302;&#21151;&#29575;&#30340;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#23454;&#39564;&#35777;&#25454;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#21151;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26680;&#21270;&#26031;&#22374;&#36317;&#65288;KSD&#65289;&#26159;&#19968;&#31181;&#24191;&#27867;&#29992;&#20110;&#25311;&#21512;&#20248;&#24230;&#26816;&#39564;&#30340;&#22522;&#20110;&#24471;&#20998;&#30340;&#24046;&#24322;&#24230;&#37327;&#12290;&#21363;&#20351;&#30446;&#26631;&#20998;&#24067;&#20855;&#26377;&#26410;&#30693;&#30340;&#26631;&#20934;&#21270;&#22240;&#23376;&#65292;&#20363;&#22914;&#22312;&#36125;&#21494;&#26031;&#20998;&#26512;&#20013;&#65292;&#20063;&#21487;&#20197;&#24212;&#29992;&#23427;&#12290;&#25105;&#20204;&#29702;&#35770;&#19978;&#21644;&#23454;&#39564;&#35777;&#26126;&#65292;&#24403;&#30446;&#26631;&#20998;&#24067;&#21644;&#26367;&#20195;&#20998;&#24067;&#20855;&#26377;&#30456;&#21516;&#19988;&#30456;&#36317;&#36739;&#36828;&#30340;&#27169;&#24335;&#20294;&#22312;&#28151;&#21512;&#27604;&#20363;&#19978;&#26377;&#25152;&#19981;&#21516;&#26102;&#65292;KSD&#26816;&#39564;&#21487;&#33021;&#20250;&#20986;&#29616;&#20302;&#21151;&#29575;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#39532;&#23572;&#31185;&#22827;&#36716;&#31227;&#26680;&#23545;&#35266;&#27979;&#26679;&#26412;&#36827;&#34892;&#25200;&#21160;&#65292;&#20351;&#20854;&#30456;&#23545;&#20110;&#30446;&#26631;&#20998;&#24067;&#19981;&#21464;&#12290;&#36825;&#20351;&#25105;&#20204;&#21487;&#20197;&#22312;&#25200;&#21160;&#26679;&#26412;&#19978;&#20351;&#29992;KSD&#26816;&#39564;&#12290;&#25105;&#20204;&#25552;&#20379;&#30340;&#25968;&#20540;&#35777;&#25454;&#34920;&#26126;&#65292;&#20351;&#29992;&#36866;&#24403;&#36873;&#25321;&#30340;&#26680;&#26102;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#20197;&#27604;KSD&#26816;&#39564;&#20855;&#26377;&#26356;&#39640;&#30340;&#21151;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Kernelized Stein discrepancy (KSD) is a score-based discrepancy widely used in goodness-of-fit tests. It can be applied even when the target distribution has an unknown normalising factor, such as in Bayesian analysis. We show theoretically and empirically that the KSD test can suffer from low power when the target and the alternative distribution have the same well-separated modes but differ in mixing proportions. We propose to perturb the observed sample via Markov transition kernels, with respect to which the target distribution is invariant. This allows us to then employ the KSD test on the perturbed sample. We provide numerical evidence that with suitably chosen kernels the proposed approach can lead to a substantially higher power than the KSD test.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31232;&#30095;&#32852;&#21512;&#20559;&#31227;&#27169;&#22411;&#65292;&#29992;&#20110;&#35299;&#20915;&#25972;&#20307;&#25968;&#25454;&#38598;&#20559;&#31227;&#38382;&#39064;&#65292;&#25552;&#20379;&#20102;&#20256;&#36882;SJS&#12289;&#20462;&#27491;&#31867;&#21518;&#39564;&#27010;&#29575;&#12289;SJS&#30340;&#21487;&#36776;&#35748;&#24615;&#12289;SJS&#19982;&#21327;&#21464;&#37327;&#36716;&#31227;&#20851;&#31995;&#31561;&#26032;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2303.16971</link><description>&lt;p&gt;
&#22810;&#39033;&#24335;&#20998;&#31867;&#20013;&#30340;&#31232;&#30095;&#32852;&#21512;&#20559;&#31227;
&lt;/p&gt;
&lt;p&gt;
Sparse joint shift in multinomial classification. (arXiv:2303.16971v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16971
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31232;&#30095;&#32852;&#21512;&#20559;&#31227;&#27169;&#22411;&#65292;&#29992;&#20110;&#35299;&#20915;&#25972;&#20307;&#25968;&#25454;&#38598;&#20559;&#31227;&#38382;&#39064;&#65292;&#25552;&#20379;&#20102;&#20256;&#36882;SJS&#12289;&#20462;&#27491;&#31867;&#21518;&#39564;&#27010;&#29575;&#12289;SJS&#30340;&#21487;&#36776;&#35748;&#24615;&#12289;SJS&#19982;&#21327;&#21464;&#37327;&#36716;&#31227;&#20851;&#31995;&#31561;&#26032;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31232;&#30095;&#32852;&#21512;&#20559;&#31227;&#65288;SJS&#65289;&#26159;&#19968;&#31181;&#38024;&#23545;&#25968;&#25454;&#38598;&#25972;&#20307;&#20559;&#31227;&#30340;&#21487;&#22788;&#29702;&#27169;&#22411;&#65292;&#21487;&#33021;&#20250;&#23548;&#33268;&#29305;&#24449;&#21644;&#26631;&#31614;&#30340;&#36793;&#38469;&#20998;&#24067;&#20197;&#21450;&#21518;&#39564;&#27010;&#29575;&#21644;&#31867;&#26465;&#20214;&#29305;&#24449;&#20998;&#24067;&#30340;&#21464;&#21270;&#12290;&#22312;&#27809;&#26377;&#26631;&#31614;&#35266;&#27979;&#30340;&#24773;&#20917;&#19979;&#65292;&#20026;&#30446;&#26631;&#25968;&#25454;&#38598;&#25311;&#21512;SJS&#21487;&#33021;&#20250;&#20135;&#29983;&#26631;&#31614;&#30340;&#26377;&#25928;&#39044;&#27979;&#21644;&#31867;&#20808;&#39564;&#27010;&#29575;&#30340;&#20272;&#35745;&#12290;&#25105;&#20204;&#22312;&#29305;&#24449;&#38598;&#20043;&#38388;&#20256;&#36882;SJS&#26041;&#38754;&#25552;&#20379;&#20102;&#26032;&#30340;&#32467;&#26524;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#30446;&#26631;&#20998;&#24067;&#30340;&#31867;&#21518;&#39564;&#27010;&#29575;&#30340;&#26465;&#20214;&#20462;&#27491;&#20844;&#24335;&#65292;&#30830;&#23450;&#24615;SJS&#30340;&#21487;&#36776;&#35748;&#24615;&#20197;&#21450;SJS&#21644;&#21327;&#21464;&#37327;&#36716;&#31227;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25351;&#20986;&#20102;&#29992;&#20110;&#20272;&#35745;SJS&#29305;&#24449;&#30340;&#31639;&#27861;&#20013;&#30340;&#19981;&#19968;&#33268;&#24615;&#65292;&#22240;&#20026;&#23427;&#20204;&#21487;&#33021;&#20250;&#22952;&#30861;&#23547;&#25214;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sparse joint shift (SJS) was recently proposed as a tractable model for general dataset shift which may cause changes to the marginal distributions of features and labels as well as the posterior probabilities and the class-conditional feature distributions. Fitting SJS for a target dataset without label observations may produce valid predictions of labels and estimates of class prior probabilities. We present new results on the transmission of SJS from sets of features to larger sets of features, a conditional correction formula for the class posterior probabilities under the target distribution, identifiability of SJS, and the relationship between SJS and covariate shift. In addition, we point out inconsistencies in the algorithms which were proposed for estimating the characteristics of SJS, as they could hamper the search for optimal solutions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#26631;&#31614;&#21015;&#34920;&#30340;&#22312;&#32447;&#39044;&#27979;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102; $b$-ary Littlestone &#32500;&#24230;&#21487;&#23398;&#20064;&#27169;&#22411;&#65292;&#24182;&#19988;&#22312;&#25077;&#25026;&#30340;&#24773;&#20917;&#19979;&#25506;&#32034;&#19981;&#21516;&#30340;&#24773;&#20917;&#12290;&#21487;&#20197;&#20351;&#29992;&#25913;&#32534;&#33258; Littlestone &#30340; SOA &#21644; Rosenblatt &#30340;&#24863;&#30693;&#22120;&#31561;&#31639;&#27861;&#36827;&#34892;&#39044;&#27979;&#65292;&#21516;&#26102;&#36824;&#24314;&#31435;&#20102;&#21015;&#34920;&#21487;&#23398;&#20064;&#30340;&#32452;&#21512;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2303.15383</link><description>&lt;p&gt;
&#22522;&#20110;&#21015;&#34920;&#30340;&#22312;&#32447;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
List Online Classification. (arXiv:2303.15383v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15383
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#26631;&#31614;&#21015;&#34920;&#30340;&#22312;&#32447;&#39044;&#27979;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102; $b$-ary Littlestone &#32500;&#24230;&#21487;&#23398;&#20064;&#27169;&#22411;&#65292;&#24182;&#19988;&#22312;&#25077;&#25026;&#30340;&#24773;&#20917;&#19979;&#25506;&#32034;&#19981;&#21516;&#30340;&#24773;&#20917;&#12290;&#21487;&#20197;&#20351;&#29992;&#25913;&#32534;&#33258; Littlestone &#30340; SOA &#21644; Rosenblatt &#30340;&#24863;&#30693;&#22120;&#31561;&#31639;&#27861;&#36827;&#34892;&#39044;&#27979;&#65292;&#21516;&#26102;&#36824;&#24314;&#31435;&#20102;&#21015;&#34920;&#21487;&#23398;&#20064;&#30340;&#32452;&#21512;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#22810;&#20998;&#31867;&#22312;&#32447;&#39044;&#27979;&#65292;&#20854;&#20013;&#23398;&#20064;&#32773;&#21487;&#20197;&#20351;&#29992;&#22810;&#20010;&#26631;&#31614;&#30340;&#21015;&#34920;&#36827;&#34892;&#39044;&#27979;&#65288;&#19982;&#20256;&#32479;&#35774;&#32622;&#20013;&#20165;&#20351;&#29992;&#19968;&#31181;&#26631;&#31614;&#19981;&#21516;&#65289;&#12290;&#25105;&#20204;&#20351;&#29992; $b$-ary Littlestone &#32500;&#24230;&#34920;&#24449;&#20102;&#35813;&#27169;&#22411;&#20013;&#30340;&#21487;&#23398;&#20064;&#24615;&#12290;&#35813;&#32500;&#24230;&#26159;&#32463;&#20856; Littlestone &#32500;&#24230;&#30340;&#21464;&#20307;&#65292;&#20854;&#20013;&#20108;&#36827;&#21046;&#38169;&#35823;&#26641;&#34987;&#26367;&#25442;&#20026; $(k+1)$-ary &#38169;&#35823;&#26641;&#65292;&#20854;&#20013; k &#26159;&#21015;&#34920;&#20013;&#26631;&#31614;&#30340;&#25968;&#37327;&#12290;&#22312;&#25077;&#25026;&#30340;&#22330;&#26223;&#20013;&#65292;&#25105;&#20204;&#26681;&#25454;&#27604;&#36739;&#31867;&#20013;&#26159;&#21542;&#21253;&#21547;&#21333;&#26631;&#31614;&#25110;&#22810;&#26631;&#31614;&#20989;&#25968;&#20197;&#21450;&#23427;&#19982;&#31639;&#27861;&#20351;&#29992;&#30340;&#21015;&#34920;&#22823;&#23567;&#20043;&#38388;&#30340;&#26435;&#34913;&#26469;&#25506;&#32034;&#19981;&#21516;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#21457;&#29616;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#21487;&#20197;&#23454;&#29616;&#36127;&#24724;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#20160;&#20040;&#24773;&#20917;&#19979;&#23454;&#29616;&#36127;&#24724;&#30340;&#23436;&#25972;&#29305;&#24615;&#21270;&#12290;&#20316;&#20026;&#25105;&#20204;&#24037;&#20316;&#30340;&#19968;&#37096;&#20998;&#65292;&#25105;&#20204;&#25913;&#32534;&#20102;&#32463;&#20856;&#31639;&#27861;&#65292;&#22914; Littlestone &#30340; SOA &#21644; Rosenblatt &#30340;&#24863;&#30693;&#22120;&#65292;&#20197;&#20351;&#29992;&#26631;&#31614;&#21015;&#34920;&#36827;&#34892;&#39044;&#27979;&#12290;&#25105;&#20204;&#36824;&#20026;&#21487;&#20197;&#36827;&#34892;&#21015;&#34920;&#23398;&#20064;&#30340;&#32452;&#21512;&#32467;&#26524;&#24314;&#31435;&#20102;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study multiclass online prediction where the learner can predict using a list of multiple labels (as opposed to just one label in the traditional setting). We characterize learnability in this model using the $b$-ary Littlestone dimension. This dimension is a variation of the classical Littlestone dimension with the difference that binary mistake trees are replaced with $(k+1)$-ary mistake trees, where $k$ is the number of labels in the list. In the agnostic setting, we explore different scenarios depending on whether the comparator class consists of single-labeled or multi-labeled functions and its tradeoff with the size of the lists the algorithm uses. We find that it is possible to achieve negative regret in some cases and provide a complete characterization of when this is possible. As part of our work, we adapt classical algorithms such as Littlestone's SOA and Rosenblatt's Perceptron to predict using lists of labels. We also establish combinatorial results for list-learnable c
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#24067;&#40065;&#26834;&#25439;&#22833;&#20989;&#25968;&#65292;&#35813;&#20989;&#25968;&#36890;&#36807;&#35748;&#35777;&#32423;&#21035;&#30340;&#40065;&#26834;&#24615;&#23545;&#20004;&#31181;&#24120;&#35265;&#30340;&#27745;&#26579;&#31867;&#22411;&#36827;&#34892;&#25269;&#25239;&#65292;&#24182;&#30830;&#20445;&#27867;&#21270;&#20445;&#35777;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#40065;&#26834;&#24615;&#21644;&#27867;&#21270;&#20043;&#38388;&#30340;&#30683;&#30462;&#65292;&#20855;&#26377;&#26497;&#39640;&#30340;&#23454;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.02251</link><description>&lt;p&gt;
&#35770;&#25991;&#26631;&#39064;&#65306;&#35748;&#35777;&#40065;&#26834;&#31070;&#32463;&#32593;&#32476;&#65306;&#27867;&#21270;&#21644;&#25239;&#27745;&#26579;&#24615;
&lt;/p&gt;
&lt;p&gt;
Certified Robust Neural Networks: Generalization and Corruption Resistance. (arXiv:2303.02251v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.02251
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#24067;&#40065;&#26834;&#25439;&#22833;&#20989;&#25968;&#65292;&#35813;&#20989;&#25968;&#36890;&#36807;&#35748;&#35777;&#32423;&#21035;&#30340;&#40065;&#26834;&#24615;&#23545;&#20004;&#31181;&#24120;&#35265;&#30340;&#27745;&#26579;&#31867;&#22411;&#36827;&#34892;&#25269;&#25239;&#65292;&#24182;&#30830;&#20445;&#27867;&#21270;&#20445;&#35777;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#40065;&#26834;&#24615;&#21644;&#27867;&#21270;&#20043;&#38388;&#30340;&#30683;&#30462;&#65292;&#20855;&#26377;&#26497;&#39640;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#40065;&#26834;&#24615;&#65288;&#23545;&#8220;&#27745;&#26579;&#8221;&#30340;&#25269;&#25239;&#33021;&#21147;&#65289;&#21487;&#33021;&#19982;&#27867;&#21270;&#23384;&#22312;&#30683;&#30462;&#12290;&#20363;&#22914;&#65292;&#23545;&#25239;&#24615;&#35757;&#32451;&#26088;&#22312;&#20943;&#23569;&#29616;&#20195;&#31070;&#32463;&#32593;&#32476;&#23545;&#23567;&#25968;&#25454;&#25200;&#21160;&#30340;&#25935;&#24863;&#24615;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#22312;&#23545;&#25239;&#35757;&#32451;&#20013;&#65292;&#36807;&#25311;&#21512;&#26159;&#19968;&#20010;&#20027;&#35201;&#38382;&#39064;&#65292;&#23613;&#31649;&#22312;&#26631;&#20934;&#35757;&#32451;&#20013;&#20960;&#20046;&#19981;&#23384;&#22312;&#12290;&#25105;&#20204;&#22312;&#36825;&#37324;&#25552;&#20379;&#20102;&#20851;&#20110;&#36825;&#31181;&#22855;&#29305;&#30340;&#8220;&#40065;&#26834;&#36807;&#25311;&#21512;&#8221;&#29616;&#35937;&#30340;&#29702;&#35770;&#35777;&#25454;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#24067;&#40065;&#26834;&#25439;&#22833;&#20989;&#25968;&#65292;&#23558;&#40065;&#26834;&#24615;&#21644;&#27867;&#21270;&#30456;&#32467;&#21512;&#12290;&#25105;&#20204;&#29702;&#35770;&#19978;&#21644;&#23454;&#35777;&#22320;&#35777;&#26126;&#20102;&#35813;&#25439;&#22833;&#20855;&#26377;&#35748;&#35777;&#32423;&#21035;&#30340;&#40065;&#26834;&#24615;&#65292;&#21487;&#20197;&#25269;&#25239;&#20004;&#31181;&#24120;&#35265;&#30340;&#27745;&#26579;&#31867;&#22411;&#8212;&#8212;&#25968;&#25454;&#36867;&#36991;&#21644;&#25915;&#20987;&#8212;&#8212;&#21516;&#26102;&#30830;&#20445;&#27867;&#21270;&#20445;&#35777;&#12290;&#36890;&#36807;&#31934;&#24515;&#35774;&#35745;&#30340;&#25968;&#23383;&#23454;&#39564;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#24471;&#21040;&#30340;&#23436;&#25972;&#40065;&#26834;&#65288;HR&#65289;&#35757;&#32451;&#31243;&#24207;&#20855;&#26377;SOTA&#30340;&#24615;&#33021;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25351;&#20986;HR&#35757;&#32451;&#21487;&#20197;&#34987;&#35299;&#37322;&#20026;&#23545;&#25239;&#24615;&#35757;&#32451;&#30340;&#30452;&#25509;&#25193;&#23637;&#65292;&#24182;&#21487;&#20197;&#33258;&#28982;&#22320;&#24212;&#29992;&#20110;GAN&#21644;RL&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent work have demonstrated that robustness (to "corruption") can be at odds with generalization. Adversarial training, for instance, aims to reduce the problematic susceptibility of modern neural networks to small data perturbations. Surprisingly, overfitting is a major concern in adversarial training despite being mostly absent in standard training. We provide here theoretical evidence for this peculiar "robust overfitting" phenomenon. Subsequently, we advance a novel distributionally robust loss function bridging robustness and generalization. We demonstrate both theoretically as well as empirically the loss to enjoy a certified level of robustness against two common types of corruption--data evasion and poisoning attacks--while ensuring guaranteed generalization. We show through careful numerical experiments that our resulting holistic robust (HR) training procedure yields SOTA performance. Finally, we indicate that HR training can be interpreted as a direct extension of adversar
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#28145;&#24230;&#22686;&#24378;&#20915;&#31574;&#26641;&#30340;&#26041;&#27861;&#26469;&#36827;&#34892;&#27450;&#35784;&#26816;&#27979;&#65292;&#26082;&#21487;&#20197;&#21033;&#29992;&#20915;&#31574;&#26641;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#21448;&#21487;&#20197;&#25552;&#39640;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#31034;&#23398;&#20064;&#33021;&#21147;&#12290;&#21516;&#26102;&#65292;&#37319;&#29992;&#26032;&#30340;&#36807;&#37319;&#26679;&#31574;&#30053;&#26469;&#32531;&#35299;&#25968;&#25454;&#19981;&#24179;&#34913;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2302.05918</link><description>&lt;p&gt;
&#21033;&#29992;&#28145;&#24230;&#22686;&#24378;&#20915;&#31574;&#26641;&#36827;&#34892;&#39640;&#25928;&#27450;&#35784;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Efficient Fraud Detection Using Deep Boosting Decision Trees. (arXiv:2302.05918v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.05918
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#28145;&#24230;&#22686;&#24378;&#20915;&#31574;&#26641;&#30340;&#26041;&#27861;&#26469;&#36827;&#34892;&#27450;&#35784;&#26816;&#27979;&#65292;&#26082;&#21487;&#20197;&#21033;&#29992;&#20915;&#31574;&#26641;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#21448;&#21487;&#20197;&#25552;&#39640;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#31034;&#23398;&#20064;&#33021;&#21147;&#12290;&#21516;&#26102;&#65292;&#37319;&#29992;&#26032;&#30340;&#36807;&#37319;&#26679;&#31574;&#30053;&#26469;&#32531;&#35299;&#25968;&#25454;&#19981;&#24179;&#34913;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27450;&#35784;&#26816;&#27979;&#26159;&#35782;&#21035;&#12289;&#30417;&#25511;&#21644;&#39044;&#38450;&#22797;&#26434;&#25968;&#25454;&#20013;&#30340;&#28508;&#22312;&#27450;&#35784;&#27963;&#21160;&#12290;&#26426;&#22120;&#23398;&#20064;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#39537;&#21160;&#26041;&#27861;&#26469;&#22788;&#29702;&#27450;&#35784;&#34892;&#20026;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26799;&#24230;&#22686;&#24378;&#21644;&#31070;&#32463;&#32593;&#32476;&#30340;&#28145;&#24230;&#22686;&#24378;&#20915;&#31574;&#26641;&#65288;DBDT&#65289;&#26041;&#27861;&#65292;&#23427;&#39318;&#20808;&#26500;&#24314;&#20102;&#36719;&#20915;&#31574;&#26641;&#65292;&#28982;&#21518;&#23558;&#20854;&#23884;&#20837;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#29992;&#20110;&#26368;&#32456;&#20998;&#31867;&#65292;&#26082;&#21487;&#20197;&#21033;&#29992;&#20915;&#31574;&#26641;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#21448;&#21487;&#20197;&#25552;&#39640;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#31034;&#23398;&#20064;&#33021;&#21147;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#36807;&#37319;&#26679;&#31574;&#30053;&#26469;&#32531;&#35299;&#25968;&#25454;&#19981;&#24179;&#34913;&#24102;&#26469;&#30340;&#24433;&#21709;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20934;&#30830;&#24615;&#12289;&#21487;&#35299;&#37322;&#24615;&#21644;&#25928;&#29575;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Fraud detection is to identify, monitor, and prevent potentially fraudulent activities from complex data. The recent development and success in AI, especially machine learning, provides a new data-driven way to deal with fraud. From a methodological point of view, machine learning based fraud detection can be divided into two categories, i.e., conventional methods (decision tree, boosting...) and deep learning, both of which have significant limitations in terms of the lack of representation learning ability for the former and interpretability for the latter. Furthermore, due to the rarity of detected fraud cases, the associated data is usually imbalanced, which seriously degrades the performance of classification algorithms. In this paper, we propose deep boosting decision trees (DBDT), a novel approach for fraud detection based on gradient boosting and neural networks. In order to combine the advantages of both conventional methods and deep learning, we first construct soft decision 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26694;&#26550;GCDTC&#65292;&#21033;&#29992;&#25968;&#20540;&#20808;&#39564;&#21644;&#24191;&#20041;CP&#20998;&#35299;&#23454;&#29616;&#20102;&#26356;&#39640;&#30340;&#20302;&#31209;&#24352;&#37327;&#34917;&#20840;&#31934;&#24230;&#65307;&#21516;&#26102;&#20171;&#32461;&#20102;&#19968;&#20010;&#31639;&#27861;SPTC&#65292;&#20316;&#20026;&#35813;&#26694;&#26550;&#30340;&#19968;&#20010;&#23454;&#29616;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#35813;&#26041;&#27861;&#34920;&#29616;&#20986;&#27604;&#29616;&#26377;&#25216;&#26415;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2302.05881</link><description>&lt;p&gt;
&#25506;&#32034;&#22522;&#20110;&#25968;&#20540;&#20808;&#39564;&#30340;&#24191;&#20041;CP&#20998;&#35299;&#20302;&#31209;&#24352;&#37327;&#34917;&#20840;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Exploring Numerical Priors for Low-Rank Tensor Completion with Generalized CP Decomposition. (arXiv:2302.05881v3 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.05881
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26694;&#26550;GCDTC&#65292;&#21033;&#29992;&#25968;&#20540;&#20808;&#39564;&#21644;&#24191;&#20041;CP&#20998;&#35299;&#23454;&#29616;&#20102;&#26356;&#39640;&#30340;&#20302;&#31209;&#24352;&#37327;&#34917;&#20840;&#31934;&#24230;&#65307;&#21516;&#26102;&#20171;&#32461;&#20102;&#19968;&#20010;&#31639;&#27861;SPTC&#65292;&#20316;&#20026;&#35813;&#26694;&#26550;&#30340;&#19968;&#20010;&#23454;&#29616;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#35813;&#26041;&#27861;&#34920;&#29616;&#20986;&#27604;&#29616;&#26377;&#25216;&#26415;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24352;&#37327;&#34917;&#20840;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#25968;&#25454;&#20998;&#26512;&#21644;&#20449;&#21495;&#22788;&#29702;&#31561;&#39046;&#22495;&#20013;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;&#26368;&#36817;&#65292;&#20302;&#31209;&#24352;&#37327;&#34917;&#20840;&#36825;&#19968;&#31867;&#21035;&#30340;&#26041;&#27861;&#24471;&#21040;&#20102;&#24191;&#27867;&#30740;&#31350;&#65292;&#23545;&#34917;&#20840;&#24352;&#37327;&#26045;&#21152;&#20302;&#31209;&#32467;&#26500;&#12290;&#34429;&#28982;&#36825;&#20123;&#26041;&#27861;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#65292;&#20294;&#23578;&#26410;&#32771;&#34385;&#21040;&#24352;&#37327;&#20803;&#32032;&#30340;&#25968;&#20540;&#20808;&#39564;&#20449;&#24687;&#12290;&#24573;&#30053;&#25968;&#20540;&#20808;&#39564;&#23558;&#23548;&#33268;&#20002;&#22833;&#20851;&#20110;&#25968;&#25454;&#30340;&#37325;&#35201;&#20449;&#24687;&#65292;&#22240;&#27492;&#38459;&#27490;&#31639;&#27861;&#36798;&#21040;&#26368;&#20248;&#31934;&#24230;&#12290;&#26412;&#30740;&#31350;&#35797;&#22270;&#26500;&#24314;&#19968;&#20010;&#26032;&#30340;&#26041;&#27861;&#26694;&#26550;&#65292;&#21517;&#20026;GCDTC&#65288;&#24191;&#20041;CP&#20998;&#35299;&#24352;&#37327;&#34917;&#20840;&#65289;&#65292;&#20197;&#21033;&#29992;&#25968;&#20540;&#20808;&#39564;&#24182;&#23454;&#29616;&#26356;&#39640;&#30340;&#24352;&#37327;&#34917;&#20840;&#31934;&#24230;&#12290;&#22312;&#36825;&#20010;&#26032;&#24341;&#20837;&#30340;&#26694;&#26550;&#20013;&#65292;&#23558;&#24191;&#20041;&#30340;CP&#20998;&#35299;&#24212;&#29992;&#20110;&#20302;&#31209;&#24352;&#37327;&#34917;&#20840;&#12290;&#26412;&#25991;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SPTC&#65288;&#24179;&#28369;&#27850;&#26494;&#24352;&#37327;&#34917;&#20840;&#65289;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#38750;&#36127;&#25972;&#25968;&#24352;&#37327;&#34917;&#20840;&#65292;&#20316;&#20026;GCDTC&#26694;&#26550;&#30340;&#19968;&#20010;&#23454;&#29616;&#12290;&#36890;&#36807;&#23545;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#30340;&#22823;&#37327;&#23454;&#39564;&#65292;&#35777;&#26126;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#30456;&#27604;&#20110;&#29616;&#26377;&#25216;&#26415;&#20855;&#26377;&#26356;&#20248;&#30340;&#24352;&#37327;&#34917;&#20840;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tensor completion is important to many areas such as computer vision, data analysis, and signal processing. Enforcing low-rank structures on completed tensors, a category of methods known as low-rank tensor completion has recently been studied extensively. While such methods attained great success, none considered exploiting numerical priors of tensor elements. Ignoring numerical priors causes loss of important information regarding the data, and therefore prevents the algorithms from reaching optimal accuracy. This work attempts to construct a new methodological framework called GCDTC (Generalized CP Decomposition Tensor Completion) for leveraging numerical priors and achieving higher accuracy in tensor completion. In this newly introduced framework, a generalized form of CP Decomposition is applied to low-rank tensor completion. This paper also proposes an algorithm known as SPTC (Smooth Poisson Tensor Completion) for nonnegative integer tensor completion as an instantiation of the G
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;DCMDPs&#30340;&#26032;&#22411;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#22788;&#29702;&#20381;&#36182;&#21382;&#21490;&#29615;&#22659;&#30340;&#24773;&#20917;&#12290;&#20854;&#20013;&#30340;&#36923;&#36753;DCMDPs&#36890;&#36807;&#21033;&#29992;&#32858;&#21512;&#20989;&#25968;&#30830;&#23450;&#19978;&#19979;&#25991;&#36716;&#25442;&#65292;&#25171;&#30772;&#20102;&#23545;&#21382;&#21490;&#38271;&#24230;&#30340;&#25351;&#25968;&#20381;&#36182;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#23454;&#29992;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#31639;&#27861;&#12290;&#22312;&#25512;&#33616;&#20219;&#21153;&#20013;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.02061</link><description>&lt;p&gt;
&#21382;&#21490;&#20381;&#36182;&#21160;&#24577;&#29615;&#22659;&#19979;&#30340;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Reinforcement Learning with History-Dependent Dynamic Contexts. (arXiv:2302.02061v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.02061
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;DCMDPs&#30340;&#26032;&#22411;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#22788;&#29702;&#20381;&#36182;&#21382;&#21490;&#29615;&#22659;&#30340;&#24773;&#20917;&#12290;&#20854;&#20013;&#30340;&#36923;&#36753;DCMDPs&#36890;&#36807;&#21033;&#29992;&#32858;&#21512;&#20989;&#25968;&#30830;&#23450;&#19978;&#19979;&#25991;&#36716;&#25442;&#65292;&#25171;&#30772;&#20102;&#23545;&#21382;&#21490;&#38271;&#24230;&#30340;&#25351;&#25968;&#20381;&#36182;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31181;&#23454;&#29992;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#31639;&#27861;&#12290;&#22312;&#25512;&#33616;&#20219;&#21153;&#20013;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#21160;&#24577;&#19978;&#19979;&#25991;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;DCMDPs&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#30340;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#29992;&#20110;&#22788;&#29702;&#20381;&#36182;&#21382;&#21490;&#29615;&#22659;&#30340;&#24773;&#20917;&#12290;&#23427;&#25512;&#24191;&#20102;&#19978;&#19979;&#25991;MDP&#26694;&#26550;&#65292;&#20197;&#22788;&#29702;&#38750;&#39532;&#23572;&#21487;&#22827;&#29615;&#22659;&#65292;&#20854;&#20013;&#19978;&#19979;&#25991;&#38543;&#26102;&#38388;&#21464;&#21270;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#36825;&#20010;&#27169;&#22411;&#30340;&#29305;&#27530;&#24773;&#20917;&#65292;&#30528;&#37325;&#20110;&#36923;&#36753;DCMDPs&#65292;&#23427;&#36890;&#36807;&#21033;&#29992;&#32858;&#21512;&#20989;&#25968;&#30830;&#23450;&#19978;&#19979;&#25991;&#36716;&#25442;&#26469;&#25171;&#30772;&#23545;&#21382;&#21490;&#38271;&#24230;&#30340;&#25351;&#25968;&#20381;&#36182;&#12290;&#36825;&#31181;&#29305;&#27530;&#32467;&#26500;&#20351;&#25105;&#20204;&#33021;&#22815;&#25512;&#23548;&#20986;&#19968;&#31181;&#31867;&#20284;&#20110;&#19978;&#38480;&#32622;&#20449;&#30028;&#31639;&#27861;&#30340;&#31639;&#27861;&#65292;&#24182;&#24314;&#31435;&#20102;&#36951;&#25022;&#30028;&#12290;&#21463;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#23454;&#29992;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#36923;&#36753;DCMDPs&#65292;&#36825;&#20010;&#31639;&#27861;&#22312;&#19968;&#20010;&#28508;&#22312;&#31354;&#38388;&#20013;&#36827;&#34892;&#35268;&#21010;&#65292;&#24182;&#20351;&#29992;&#21382;&#21490;&#20381;&#36182;&#29305;&#24449;&#19978;&#30340;&#20048;&#35266;&#20027;&#20041;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#25512;&#33616;&#20219;&#21153;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65288;&#20351;&#29992;MovieLens&#25968;&#25454;&#38598;&#65289;&#65292;&#20854;&#20013;&#29992;&#25143;&#34892;&#20026;&#21160;&#24577;&#22320;&#38543;&#30528;&#25512;&#33616;&#30340;&#21464;&#21270;&#32780;&#28436;&#21464;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce Dynamic Contextual Markov Decision Processes (DCMDPs), a novel reinforcement learning framework for history-dependent environments that generalizes the contextual MDP framework to handle non-Markov environments, where contexts change over time. We consider special cases of the model, with a focus on logistic DCMDPs, which break the exponential dependence on history length by leveraging aggregation functions to determine context transitions. This special structure allows us to derive an upper-confidence-bound style algorithm for which we establish regret bounds. Motivated by our theoretical results, we introduce a practical model-based algorithm for logistic DCMDPs that plans in a latent space and uses optimism over history-dependent features. We demonstrate the efficacy of our approach on a recommendation task (using MovieLens data) where user behavior dynamics evolve in response to recommendations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;Maxout&#32593;&#32476;&#20851;&#20110;&#36755;&#20837;&#21644;&#21442;&#25968;&#30340;&#26799;&#24230;&#65292;&#25552;&#20986;&#20102;&#36991;&#20813;&#26799;&#24230;&#28040;&#22833;&#21644;&#29190;&#28856;&#30340;&#21442;&#25968;&#21021;&#22987;&#21270;&#31574;&#30053;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2301.06956</link><description>&lt;p&gt;
Maxout&#32593;&#32476;&#30340;&#26399;&#26395;&#26799;&#24230;&#21450;&#20854;&#23545;&#21442;&#25968;&#21021;&#22987;&#21270;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Expected Gradients of Maxout Networks and Consequences to Parameter Initialization. (arXiv:2301.06956v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.06956
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;Maxout&#32593;&#32476;&#20851;&#20110;&#36755;&#20837;&#21644;&#21442;&#25968;&#30340;&#26799;&#24230;&#65292;&#25552;&#20986;&#20102;&#36991;&#20813;&#26799;&#24230;&#28040;&#22833;&#21644;&#29190;&#28856;&#30340;&#21442;&#25968;&#21021;&#22987;&#21270;&#31574;&#30053;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;Maxout&#32593;&#32476;&#30456;&#23545;&#20110;&#36755;&#20837;&#21644;&#21442;&#25968;&#30340;&#26799;&#24230;&#65292;&#24182;&#26681;&#25454;&#32593;&#32476;&#32467;&#26500;&#21644;&#21442;&#25968;&#20998;&#24067;&#24471;&#20986;&#26799;&#24230;&#30340;&#30697;&#19978;&#30028;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#36755;&#20837;&#36755;&#20986;Jacobian&#30340;&#20998;&#24067;&#21462;&#20915;&#20110;&#36755;&#20837;&#65292;&#36825;&#20351;&#24471;&#31283;&#23450;&#30340;&#21442;&#25968;&#21021;&#22987;&#21270;&#21464;&#24471;&#22797;&#26434;&#12290;&#22522;&#20110;&#26799;&#24230;&#30697;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36991;&#20813;&#22312;&#23485;&#32593;&#32476;&#20013;&#26799;&#24230;&#28040;&#22833;&#21644;&#29190;&#28856;&#30340;&#21442;&#25968;&#21021;&#22987;&#21270;&#31574;&#30053;&#12290;&#22312;&#28145;&#24230;&#20840;&#36830;&#25509;&#21644;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#36825;&#31181;&#31574;&#30053;&#25913;&#21892;&#20102;Maxout&#32593;&#32476;&#30340;SGD&#21644;Adam&#35757;&#32451;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24471;&#21040;&#20102;&#20851;&#20110;&#26399;&#26395;&#32447;&#24615;&#21306;&#22495;&#25968;&#37327;&#12289;&#26399;&#26395;&#26354;&#32447;&#38271;&#24230;&#22833;&#30495;&#21644;NTK&#30340;&#31934;&#32454;&#30028;&#38480;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the gradients of a maxout network with respect to inputs and parameters and obtain bounds for the moments depending on the architecture and the parameter distribution. We observe that the distribution of the input-output Jacobian depends on the input, which complicates a stable parameter initialization. Based on the moments of the gradients, we formulate parameter initialization strategies that avoid vanishing and exploding gradients in wide networks. Experiments with deep fully-connected and convolutional networks show that this strategy improves SGD and Adam training of deep maxout networks. In addition, we obtain refined bounds on the expected number of linear regions, results on the expected curve length distortion, and results on the NTK.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#32858;&#31867;&#21644;&#23884;&#20837;&#30340;&#31616;&#21333;&#39640;&#25928;&#26041;&#27861;&#65292;&#29992;&#20110;&#20811;&#26381;&#31934;&#20934;&#21307;&#30103;&#20013;&#30340;&#39640;&#32500;&#38382;&#39064;&#21644;&#32858;&#31867;&#38382;&#39064;&#65292;&#32463;&#39564;&#35777;&#35813;&#26041;&#27861;&#36739;&#24403;&#21069;&#26041;&#27861;&#20855;&#26377;&#26356;&#39640;&#30340;&#26377;&#25928;&#24615;&#21644;&#21487;&#34892;&#24615;&#12290;</title><link>http://arxiv.org/abs/2211.16553</link><description>&lt;p&gt;
&#31616;&#21333;&#39640;&#25928;&#30340;&#22522;&#20110;&#32858;&#31867;&#30340;&#31934;&#20934;&#21307;&#30103;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Simple and Scalable Algorithms for Cluster-Aware Precision Medicine. (arXiv:2211.16553v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.16553
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#32858;&#31867;&#21644;&#23884;&#20837;&#30340;&#31616;&#21333;&#39640;&#25928;&#26041;&#27861;&#65292;&#29992;&#20110;&#20811;&#26381;&#31934;&#20934;&#21307;&#30103;&#20013;&#30340;&#39640;&#32500;&#38382;&#39064;&#21644;&#32858;&#31867;&#38382;&#39064;&#65292;&#32463;&#39564;&#35777;&#35813;&#26041;&#27861;&#36739;&#24403;&#21069;&#26041;&#27861;&#20855;&#26377;&#26356;&#39640;&#30340;&#26377;&#25928;&#24615;&#21644;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;&#20154;&#24037;&#26234;&#33021;&#23454;&#29616;&#25968;&#25454;&#39537;&#21160;&#30340;&#20010;&#24615;&#21270;&#35786;&#26029;&#12289;&#39044;&#21518;&#21644;&#27835;&#30103;&#65292;&#20026;&#31934;&#20934;&#21307;&#30103;&#24102;&#26469;&#20102;&#21069;&#25152;&#26410;&#26377;&#30340;&#21464;&#38761;&#12290;&#28982;&#32780;&#65292;&#29983;&#29289;&#21307;&#23398;&#25968;&#25454;&#30340;&#39640;&#32500;&#24230;&#21644;&#32858;&#31867;&#32467;&#26500;&#20351;&#24471;&#22312;&#39640;&#32500;&#24230;&#12289;&#38480;&#21046;&#24615;&#35266;&#27979;&#30340;&#31934;&#20934;&#21307;&#30103;&#39046;&#22495;&#20013;&#20250;&#36935;&#21040;&#25361;&#25112;&#12290;&#20026;&#20102;&#21516;&#26102;&#20811;&#26381;&#36825;&#20004;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#39640;&#25928;&#30340;&#32852;&#21512;&#32858;&#31867;&#21644;&#23884;&#20837;&#26041;&#27861;&#65292;&#23558;&#26631;&#20934;&#23884;&#20837;&#26041;&#27861;&#19982;&#20984;&#32858;&#31867;&#24809;&#32602;&#20197;&#27169;&#22359;&#21270;&#30340;&#26041;&#24335;&#32467;&#21512;&#12290;&#36825;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#32858;&#31867;&#30340;&#23884;&#20837;&#26041;&#27861;&#20811;&#26381;&#20102;&#24403;&#21069;&#32852;&#21512;&#23884;&#20837;&#21644;&#32858;&#31867;&#26041;&#27861;&#30340;&#22797;&#26434;&#24615;&#21644;&#23616;&#38480;&#24615;&#65292;&#25105;&#20204;&#36890;&#36807;&#23618;&#27425;&#32858;&#31867;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#12289;&#23616;&#37096;&#32447;&#24615;&#23884;&#20837;&#65288;LLE&#65289;&#21644;&#35268;&#33539;&#30456;&#20851;&#20998;&#26512;&#65288;CCA&#65289;&#30340;&#31616;&#21333;&#23454;&#29616;&#36827;&#34892;&#20102;&#35777;&#26126;&#12290;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#21644;&#30495;&#23454;&#19990;&#30028;&#30340;&#26696;&#20363;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
AI-enabled precision medicine promises a transformational improvement in healthcare outcomes by enabling data-driven personalized diagnosis, prognosis, and treatment. However, the well-known "curse of dimensionality" and the clustered structure of biomedical data together interact to present a joint challenge in the high dimensional, limited observation precision medicine regime. To overcome both issues simultaneously we propose a simple and scalable approach to joint clustering and embedding that combines standard embedding methods with a convex clustering penalty in a modular way. This novel, cluster-aware embedding approach overcomes the complexity and limitations of current joint embedding and clustering methods, which we show with straightforward implementations of hierarchically clustered principal component analysis (PCA), locally linear embedding (LLE), and canonical correlation analysis (CCA). Through both numerical experiments and real-world examples, we demonstrate that our 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#33021;&#32791;&#24863;&#30693;&#30340;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#34920;&#26684;&#22522;&#20934; EC-NAS&#65292;&#35813;&#22522;&#20934;&#36890;&#36807;&#28155;&#21152;&#33021;&#32791;&#21644;&#30899;&#36275;&#36857;&#20449;&#24687;&#65292;&#25903;&#25345;&#35774;&#35745;&#33021;&#25928;&#39640;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#24182;&#38477;&#20302;&#24635;&#33021;&#32791;&#12290;</title><link>http://arxiv.org/abs/2210.06015</link><description>&lt;p&gt;
EC-NAS: &#38754;&#21521;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#30340;&#33021;&#32791;&#24863;&#30693;&#34920;&#26684;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
EC-NAS: Energy Consumption Aware Tabular Benchmarks for Neural Architecture Search. (arXiv:2210.06015v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.06015
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#33021;&#32791;&#24863;&#30693;&#30340;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034;&#34920;&#26684;&#22522;&#20934; EC-NAS&#65292;&#35813;&#22522;&#20934;&#36890;&#36807;&#28155;&#21152;&#33021;&#32791;&#21644;&#30899;&#36275;&#36857;&#20449;&#24687;&#65292;&#25903;&#25345;&#35774;&#35745;&#33021;&#25928;&#39640;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#24182;&#38477;&#20302;&#24635;&#33021;&#32791;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#36873;&#25321;&#12289;&#35757;&#32451;&#21644;&#37096;&#32626;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#25152;&#38656;&#30340;&#33021;&#37327;&#28040;&#32791;&#19981;&#26029;&#22686;&#21152;&#12290;&#26412;&#25991;&#26088;&#22312;&#25903;&#25345;&#35774;&#35745;&#33021;&#25928;&#39640;&#12289;&#35757;&#32451;&#36164;&#28304;&#28040;&#32791;&#36739;&#20302;&#12289;&#36866;&#29992;&#20110;&#23454;&#38469;&#36793;&#32536;/&#31227;&#21160;&#35745;&#31639;&#29615;&#22659;&#24182;&#20855;&#26377;&#29615;&#22659;&#21487;&#25345;&#32493;&#24615;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20986;&#23558;&#33021;&#25928;&#20316;&#20026;&#31070;&#32463;&#26550;&#26500;&#25628;&#32034; (NAS) &#30340;&#19968;&#39033;&#39069;&#22806;&#24615;&#33021;&#25351;&#26631;&#65292;&#24182;&#36890;&#36807;&#28155;&#21152;&#19981;&#21516;&#26550;&#26500;&#30340;&#33021;&#32791;&#21644;&#30899;&#36275;&#36857;&#20449;&#24687;&#65292;&#25552;&#20379;&#26356;&#26032;&#30340;&#34920;&#26684;&#22522;&#20934; EC-NAS &#20197;&#22312;&#36739;&#20302;&#35745;&#31639;&#25104;&#26412;&#19979;&#35780;&#20272; NAS &#31574;&#30053;&#12290;EC-NAS &#36824;&#21253;&#25324;&#29992;&#20110;&#39044;&#27979;&#33021;&#32791;&#30340;&#20195;&#29702;&#27169;&#22411;&#65292;&#24182;&#26377;&#21161;&#20110;&#38477;&#20302;&#24635;&#33021;&#32791;&#12290;
&lt;/p&gt;
&lt;p&gt;
Energy consumption from selecting, training and deploying deep learning models has continued to increase over the past few years. Our goal in this work is to support the design of energy-efficient deep learning models that are easier to train with lower compute resources, practical to deploy in real-world edge/mobile computing settings and environmentally sustainable. Tabular benchmarks for neural architecture search (NAS) allow the evaluation of NAS strategies at lower computational cost by providing pre-computed performance statistics. In this work, we suggest including energy efficiency as an additional performance criterion to NAS and present an updated tabular benchmark by including information on energy consumption and carbon footprint for different architectures. The benchmark called EC-NAS is made available open-source to support energy consumption-aware NAS research. EC-NAS also includes a surrogate model for predicting energy consumption, and helps us reduce the overall energ
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#37096;&#20998;&#20449;&#24687;&#20998;&#35299;&#30340;&#8220;&#34920;&#31034;&#22797;&#26434;&#24230;&#8221;&#24230;&#37327;&#65292;&#29992;&#20110;&#37327;&#21270;&#36328;&#22810;&#20010;&#31070;&#32463;&#20803;&#25193;&#25955;&#30340;&#20449;&#24687;&#35775;&#38382;&#38590;&#24230;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#23454;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2209.10438</link><description>&lt;p&gt;
&#22522;&#20110;&#37096;&#20998;&#20449;&#24687;&#20998;&#35299;&#30340;&#31070;&#32463;&#34920;&#31034;&#22797;&#26434;&#24230;&#24230;&#37327;
&lt;/p&gt;
&lt;p&gt;
A Measure of the Complexity of Neural Representations based on Partial Information Decomposition. (arXiv:2209.10438v2 [cs.IT] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.10438
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#37096;&#20998;&#20449;&#24687;&#20998;&#35299;&#30340;&#8220;&#34920;&#31034;&#22797;&#26434;&#24230;&#8221;&#24230;&#37327;&#65292;&#29992;&#20110;&#37327;&#21270;&#36328;&#22810;&#20010;&#31070;&#32463;&#20803;&#25193;&#25955;&#30340;&#20449;&#24687;&#35775;&#38382;&#38590;&#24230;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#19982;&#20219;&#21153;&#30456;&#20851;&#30340;&#20449;&#24687;&#36890;&#24120;&#26159;&#30001;&#31070;&#32463;&#20803;&#32676;&#32852;&#21512;&#34920;&#31034;&#30340;&#12290;&#28982;&#32780;&#65292;&#20851;&#20110;&#36825;&#31181;&#20998;&#31867;&#26631;&#31614;&#30340;&#20114;&#20449;&#24687;&#22914;&#20309;&#22312;&#21333;&#20010;&#31070;&#32463;&#20803;&#20043;&#38388;&#20998;&#37197;&#30340;&#32454;&#33410;&#23578;&#19981;&#28165;&#26970;&#65306;&#34429;&#28982;&#37096;&#20998;&#20114;&#20449;&#24687;&#21482;&#33021;&#20174;&#29305;&#23450;&#30340;&#21333;&#20010;&#31070;&#32463;&#20803;&#20013;&#33719;&#24471;&#65292;&#20294;&#20854;&#20182;&#37096;&#20998;&#21017;&#30001;&#22810;&#20010;&#31070;&#32463;&#20803;&#20887;&#20313;&#25110;&#21327;&#21516;&#25215;&#36733;&#12290;&#26412;&#25991;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#20449;&#24687;&#35770;&#30340;&#37096;&#20998;&#20449;&#24687;&#20998;&#35299;&#26469;&#20998;&#31163;&#36825;&#20123;&#19981;&#21516;&#30340;&#36129;&#29486;&#65292;&#24182;&#25552;&#20986;&#20102;&#8220;&#34920;&#31034;&#22797;&#26434;&#24230;&#8221;&#24230;&#37327;&#65292;&#29992;&#20110;&#37327;&#21270;&#36328;&#22810;&#20010;&#31070;&#32463;&#20803;&#25193;&#25955;&#30340;&#20449;&#24687;&#35775;&#38382;&#38590;&#24230;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22914;&#20309;&#30452;&#25509;&#35745;&#31639;&#36739;&#23567;&#23618;&#30340;&#22797;&#26434;&#24230;&#65292;&#24182;&#38024;&#23545;&#36739;&#22823;&#23618;&#25552;&#20986;&#20102;&#23376;&#25277;&#26679;&#21644;&#31895;&#31890;&#21270;&#36807;&#31243;&#65292;&#24182;&#35777;&#26126;&#20102;&#23545;&#24212;&#30340;&#19978;&#38480;&#12290;&#22312;MNIST&#21644;CIFAR10&#20219;&#21153;&#19978;&#65292;&#25105;&#20204;&#22312;&#37327;&#21270;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#35266;&#23519;&#21040;&#34920;&#31034;&#22797;&#26434;&#24230;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In neural networks, task-relevant information is represented jointly by groups of neurons. However, the specific way in which this mutual information about the classification label is distributed among the individual neurons is not well understood: While parts of it may only be obtainable from specific single neurons, other parts are carried redundantly or synergistically by multiple neurons. We show how Partial Information Decomposition (PID), a recent extension of information theory, can disentangle these different contributions. From this, we introduce the measure of "Representational Complexity", which quantifies the difficulty of accessing information spread across multiple neurons. We show how this complexity is directly computable for smaller layers. For larger layers, we propose subsampling and coarse-graining procedures and prove corresponding bounds on the latter. Empirically, for quantized deep neural networks solving the MNIST and CIFAR10 tasks, we observe that representati
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#8212;&#8212;Selectively Adaptive Lasso&#65288;SAL&#65289;&#65292;&#23427;&#22522;&#20110;HAL&#30340;&#29702;&#35770;&#26500;&#24314;&#65292;&#20445;&#30041;&#20102;&#26080;&#32500;&#24230;&#12289;&#38750;&#21442;&#25968;&#25910;&#25947;&#36895;&#29575;&#30340;&#20248;&#28857;&#65292;&#21516;&#26102;&#20063;&#20855;&#26377;&#21487;&#25193;&#23637;&#21040;&#22823;&#35268;&#27169;&#39640;&#32500;&#25968;&#25454;&#38598;&#30340;&#33021;&#21147;&#12290;&#36825;&#31181;&#31639;&#27861;&#23558;&#35768;&#22810;&#22238;&#24402;&#31995;&#25968;&#33258;&#21160;&#35774;&#32622;&#20026;&#38646;&#12290;</title><link>http://arxiv.org/abs/2205.10697</link><description>&lt;p&gt;
Selectively Adaptive Lasso&#36873;&#36866;&#24212;Lasso
&lt;/p&gt;
&lt;p&gt;
The Selectively Adaptive Lasso. (arXiv:2205.10697v5 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.10697
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#8212;&#8212;Selectively Adaptive Lasso&#65288;SAL&#65289;&#65292;&#23427;&#22522;&#20110;HAL&#30340;&#29702;&#35770;&#26500;&#24314;&#65292;&#20445;&#30041;&#20102;&#26080;&#32500;&#24230;&#12289;&#38750;&#21442;&#25968;&#25910;&#25947;&#36895;&#29575;&#30340;&#20248;&#28857;&#65292;&#21516;&#26102;&#20063;&#20855;&#26377;&#21487;&#25193;&#23637;&#21040;&#22823;&#35268;&#27169;&#39640;&#32500;&#25968;&#25454;&#38598;&#30340;&#33021;&#21147;&#12290;&#36825;&#31181;&#31639;&#27861;&#23558;&#35768;&#22810;&#22238;&#24402;&#31995;&#25968;&#33258;&#21160;&#35774;&#32622;&#20026;&#38646;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#22238;&#24402;&#26041;&#27861;&#33021;&#22815;&#36827;&#34892;&#26080;&#38656;&#36807;&#22810;&#30340;&#21442;&#25968;&#20551;&#35774;&#30340;&#20989;&#25968;&#20272;&#35745;&#12290;&#34429;&#28982;&#23427;&#20204;&#21487;&#20197;&#22312;&#39044;&#27979;&#35823;&#24046;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#22823;&#22810;&#25968;&#32570;&#20047;&#31867;&#21322;&#21442;&#25968;&#26377;&#25928;&#20272;&#35745;&#65288;&#20363;&#22914;&#65292;TMLE&#65292;AIPW&#65289;&#25152;&#38656;&#30340;&#29702;&#35770;&#25910;&#25947;&#36895;&#24230;&#12290;&#39640;&#24230;&#33258;&#36866;&#24212;Lasso&#65288;HAL&#65289;&#26159;&#21807;&#19968;&#32463;&#35777;&#26126;&#33021;&#22815;&#24555;&#36895;&#25910;&#25947;&#21040;&#24847;&#20041;&#19978;&#30340;&#22823;&#31867;&#20989;&#25968;&#30340;&#22238;&#24402;&#26041;&#27861;&#65292;&#19982;&#39044;&#27979;&#21464;&#37327;&#30340;&#32500;&#24230;&#26080;&#20851;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;HAL&#26080;&#27861;&#25193;&#23637;&#35745;&#31639;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#22312;HAL&#29702;&#35770;&#30340;&#22522;&#30784;&#19978;&#26500;&#24314;&#36873;&#25321;&#33258;&#36866;&#24212;Lasso&#65288;SAL&#65289;&#65292;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#20445;&#30041;HAL&#30340;&#26080;&#32500;&#24230;&#12289;&#38750;&#21442;&#25968;&#25910;&#25947;&#29575;&#65292;&#20294;&#20063;&#33021;&#25193;&#23637;&#21040;&#22823;&#35268;&#27169;&#30340;&#39640;&#32500;&#25968;&#25454;&#38598;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20123;&#19982;&#23884;&#22871;Donsker&#31867;&#20013;&#30340;&#32463;&#39564;&#25439;&#22833;&#26368;&#23567;&#21270;&#26377;&#20851;&#30340;&#19968;&#33324;&#29702;&#35770;&#32467;&#26524;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#26159;&#19968;&#31181;&#26799;&#24230;&#19979;&#38477;&#24418;&#24335;&#65292;&#20855;&#26377;&#31616;&#21333;&#30340;&#20998;&#32452;&#35268;&#21017;&#65292;&#33258;&#21160;&#23558;&#35768;&#22810;&#22238;&#24402;&#31995;&#25968;&#35774;&#20026;&#38646;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning regression methods allow estimation of functions without unrealistic parametric assumptions. Although they can perform exceptionally in prediction error, most lack theoretical convergence rates necessary for semi-parametric efficient estimation (e.g. TMLE, AIPW) of parameters like average treatment effects. The Highly Adaptive Lasso (HAL) is the only regression method proven to converge quickly enough for a meaningfully large class of functions, independent of the dimensionality of the predictors. Unfortunately, HAL is not computationally scalable. In this paper we build upon the theory of HAL to construct the Selectively Adaptive Lasso (SAL), a new algorithm which retains HAL's dimension-free, nonparametric convergence rate but which also scales computationally to large high-dimensional datasets. To accomplish this, we prove some general theoretical results pertaining to empirical loss minimization in nested Donsker classes. Our resulting algorithm is a form of gradie
&lt;/p&gt;</description></item><item><title>PyDTS&#26159;&#19968;&#20010;&#29992;&#20110;&#31163;&#25955;&#26102;&#38388;&#29983;&#23384;&#25968;&#25454;&#21322;&#21442;&#25968;&#31454;&#20105;&#39118;&#38505;&#27169;&#22411;&#30340;Python&#21253;&#65292;&#25903;&#25345;&#21253;&#25324;LASSO&#21644;&#24377;&#24615;&#32593;&#31561;&#27491;&#21017;&#21270;&#22238;&#24402;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2204.05731</link><description>&lt;p&gt;
PyDTS&#65306;&#29992;&#20110;&#31163;&#25955;&#26102;&#38388;&#31454;&#20105;&#39118;&#38505;&#65288;&#27491;&#21017;&#21270;&#65289;&#22238;&#24402;&#30340; Python &#21253;
&lt;/p&gt;
&lt;p&gt;
PyDTS: A Python Package for Discrete-Time Survival (Regularized) Regression with Competing Risks. (arXiv:2204.05731v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.05731
&lt;/p&gt;
&lt;p&gt;
PyDTS&#26159;&#19968;&#20010;&#29992;&#20110;&#31163;&#25955;&#26102;&#38388;&#29983;&#23384;&#25968;&#25454;&#21322;&#21442;&#25968;&#31454;&#20105;&#39118;&#38505;&#27169;&#22411;&#30340;Python&#21253;&#65292;&#25903;&#25345;&#21253;&#25324;LASSO&#21644;&#24377;&#24615;&#32593;&#31561;&#27491;&#21017;&#21270;&#22238;&#24402;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#33267;&#20107;&#20214;&#20998;&#26512;&#65288;&#29983;&#23384;&#20998;&#26512;&#65289;&#29992;&#20110;&#21709;&#24212;&#26102;&#38388;&#26159;&#25351;&#39044;&#23450;&#20107;&#20214;&#21457;&#29983;&#30340;&#26102;&#38388;&#12290;&#30001;&#20110;&#26102;&#38388;&#26412;&#36523;&#26159;&#31163;&#25955;&#30340;&#25110;&#30001;&#20110;&#23558;&#22833;&#36133;&#26102;&#38388;&#20998;&#32452;&#20026;&#38388;&#38548;&#25110;&#33293;&#20837;&#27979;&#37327;&#65292;&#22240;&#27492;&#26102;&#38388;&#33267;&#20107;&#20214;&#25968;&#25454;&#26377;&#26102;&#26159;&#31163;&#25955;&#30340;&#12290;&#27492;&#22806;&#65292;&#20010;&#20307;&#30340;&#22833;&#36133;&#21487;&#33021;&#26159;&#20960;&#31181;&#19981;&#21516;&#30340;&#22833;&#36133;&#31867;&#22411;&#20043;&#19968;&#65292;&#31216;&#20026;&#31454;&#20105;&#39118;&#38505;&#65288;&#20107;&#20214;&#65289;&#12290;&#22823;&#22810;&#25968;&#29983;&#23384;&#22238;&#24402;&#20998;&#26512;&#30340;&#26041;&#27861;&#21644;&#36719;&#20214;&#21253;&#20551;&#23450;&#26102;&#38388;&#26159;&#22312;&#36830;&#32493;&#23610;&#24230;&#19978;&#27979;&#37327;&#30340;&#12290;&#20247;&#25152;&#21608;&#30693;&#65292;&#23558;&#26631;&#20934;&#30340;&#36830;&#32493;&#26102;&#38388;&#27169;&#22411;&#24212;&#29992;&#20110;&#31163;&#25955;&#26102;&#38388;&#25968;&#25454;&#21487;&#33021;&#23548;&#33268;&#31163;&#25955;&#26102;&#38388;&#27169;&#22411;&#30340;&#20272;&#35745;&#22120;&#23384;&#22312;&#20559;&#24046;&#12290;&#20171;&#32461;&#20102; Python &#21253; PyDTS&#65292;&#29992;&#20110;&#27169;&#25311;&#65292;&#20272;&#35745;&#21644;&#35780;&#20272;&#31163;&#25955;&#26102;&#38388;&#29983;&#23384;&#25968;&#25454;&#30340;&#21322;&#21442;&#25968;&#31454;&#20105;&#39118;&#38505;&#27169;&#22411;&#12290;&#35813;&#21253;&#23454;&#29616;&#20102;&#24555;&#36895;&#36807;&#31243;&#65292;&#20351;&#26377;&#25928;&#22320;&#21253;&#25324;&#27491;&#21017;&#21270;&#22238;&#24402;&#26041;&#27861;&#65292;&#22914; LASSO &#21644;&#24377;&#24615;&#32593;&#32476;&#31561;&#12290;&#19968;&#20010;&#27169;&#25311;
&lt;/p&gt;
&lt;p&gt;
Time-to-event analysis (survival analysis) is used when the response of interest is the time until a pre-specified event occurs. Time-to-event data are sometimes discrete either because time itself is discrete or due to grouping of failure times into intervals or rounding off measurements. In addition, the failure of an individual could be one of several distinct failure types, known as competing risks (events). Most methods and software packages for survival regression analysis assume that time is measured on a continuous scale. It is well-known that naively applying standard continuous-time models with discrete-time data may result in biased estimators of the discrete-time models. The Python package PyDTS, for simulating, estimating and evaluating semi-parametric competing-risks models for discrete-time survival data, is introduced. The package implements a fast procedure that enables including regularized regression methods, such as LASSO and elastic net, among others. A simulation 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#32452;&#20302;&#22797;&#26434;&#24230;&#20998;&#31867;&#22120;&#65292;&#35813;&#20998;&#31867;&#22120;&#21487;&#20197;&#36817;&#20284;&#20110;&#20219;&#24847;&#36830;&#32493;&#20989;&#25968;&#21644;&#24067;&#23572;&#20989;&#25968;&#65292;&#19988;&#22312;&#32473;&#23450;&#31867;&#26465;&#20214;&#23494;&#24230;&#30340;&#24773;&#20917;&#19979;&#65292;&#20854;&#35823;&#24046;&#19982;&#26368;&#20248;&#35823;&#24046;&#30456;&#21516;&#12290;</title><link>http://arxiv.org/abs/2108.06339</link><description>&lt;p&gt;
&#38543;&#26426;&#25237;&#24433;&#20998;&#31867;&#30340;&#26368;&#20248;&#24615;&#21644;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Optimality and complexity of classification by random projection. (arXiv:2108.06339v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2108.06339
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#32452;&#20302;&#22797;&#26434;&#24230;&#20998;&#31867;&#22120;&#65292;&#35813;&#20998;&#31867;&#22120;&#21487;&#20197;&#36817;&#20284;&#20110;&#20219;&#24847;&#36830;&#32493;&#20989;&#25968;&#21644;&#24067;&#23572;&#20989;&#25968;&#65292;&#19988;&#22312;&#32473;&#23450;&#31867;&#26465;&#20214;&#23494;&#24230;&#30340;&#24773;&#20917;&#19979;&#65292;&#20854;&#35823;&#24046;&#19982;&#26368;&#20248;&#35823;&#24046;&#30456;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#31867;&#22120;&#30340;&#27867;&#21270;&#35823;&#24046;&#19982;&#36873;&#25321;&#20998;&#31867;&#22120;&#30340;&#20989;&#25968;&#38598;&#30340;&#22797;&#26434;&#24230;&#26377;&#20851;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#32452;&#20302;&#22797;&#26434;&#24230;&#20998;&#31867;&#22120;&#65292;&#21253;&#25324;&#36890;&#36807;&#38543;&#26426;&#19968;&#32500;&#29305;&#24449;&#20570;&#38408;&#20540;&#22788;&#29702;&#12290;&#35813;&#29305;&#24449;&#36890;&#36807;&#23558;&#25968;&#25454;&#23884;&#20837;&#21040;&#30001;&#39640;&#27425;&#21333;&#39033;&#24335;&#21442;&#25968;&#21270;&#30340;&#26356;&#39640;&#32500;&#31354;&#38388;&#20013;&#21518;&#22312;&#38543;&#26426;&#30452;&#32447;&#19978;&#36827;&#34892;&#25237;&#24433;&#32780;&#24471;&#21040;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25193;&#23637;&#30340;&#25968;&#25454;&#34987;&#25237;&#24433;n&#27425;&#65292;&#24182;&#20174;&#36825;n&#20010;&#20013;&#36873;&#20986;&#34920;&#29616;&#22312;&#35757;&#32451;&#25968;&#25454;&#19978;&#26368;&#22909;&#30340;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#31867;&#22411;&#30340;&#20998;&#31867;&#22120;&#26159;&#26497;&#20854;&#28789;&#27963;&#30340;&#65292;&#22240;&#20026;&#23427;&#26377;&#21487;&#33021;&#36817;&#20284;&#20110;&#20219;&#20309;&#22312;&#32039;&#33268;&#38598;&#19978;&#30340;&#36830;&#32493;&#20989;&#25968;&#65292;&#20197;&#21450;&#23558;&#25903;&#25745;&#38598;&#25286;&#20998;&#20026;&#21487;&#27979;&#23376;&#38598;&#30340;&#20219;&#20309;&#24067;&#23572;&#20989;&#25968;&#12290;&#29305;&#21035;&#22320;&#65292;&#22914;&#26524;&#32473;&#23450;&#31867;&#26465;&#20214;&#23494;&#24230;&#30340;&#23436;&#20840;&#30693;&#35782;&#65292;&#21017;&#36825;&#20123;&#20302;&#22797;&#26434;&#24230;&#20998;&#31867;&#22120;&#30340;&#35823;&#24046;&#23558;&#22312;k&#21644;n&#36235;&#36817;&#20110;&#26080;&#31351;&#22823;&#26102;&#25910;&#25947;&#21040;&#26368;&#20248;&#65288;&#36125;&#21494;&#26031;&#65289;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
The generalization error of a classifier is related to the complexity of the set of functions among which the classifier is chosen. We study a family of low-complexity classifiers consisting of thresholding a random one-dimensional feature. The feature is obtained by projecting the data on a random line after embedding it into a higher-dimensional space parametrized by monomials of order up to k. More specifically, the extended data is projected n-times and the best classifier among those n, based on its performance on training data, is chosen. We show that this type of classifier is extremely flexible, as it is likely to approximate, to an arbitrary precision, any continuous function on a compact set as well as any boolean function on a compact set that splits the support into measurable subsets. In particular, given full knowledge of the class conditional densities, the error of these low-complexity classifiers would converge to the optimal (Bayes) error as k and n go to infinity. On
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#36890;&#36807;&#36866;&#37327;&#32423;&#21035;&#30340;&#36882;&#22686;&#35745;&#31639;&#26469;&#20272;&#35745;&#31070;&#32463;&#32593;&#32476;&#19981;&#30830;&#23450;&#24615;&#30340;Epistemic&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#65292;&#20351;&#24471;&#20256;&#32479;&#31070;&#32463;&#32593;&#32476;&#33021;&#22815;&#22312;&#35745;&#31639;&#25104;&#26412;&#22823;&#24133;&#19979;&#38477;&#30340;&#24773;&#20917;&#19979;&#36229;&#36234;&#22823;&#22411;&#38598;&#25104;&#27169;&#22411;&#65292;&#20026;&#27169;&#22411;&#32852;&#21512;&#39044;&#27979;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#25509;&#21475;&#12290;</title><link>http://arxiv.org/abs/2107.08924</link><description>&lt;p&gt;
&#35748;&#30693;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Epistemic Neural Networks. (arXiv:2107.08924v8 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2107.08924
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#36890;&#36807;&#36866;&#37327;&#32423;&#21035;&#30340;&#36882;&#22686;&#35745;&#31639;&#26469;&#20272;&#35745;&#31070;&#32463;&#32593;&#32476;&#19981;&#30830;&#23450;&#24615;&#30340;Epistemic&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#65292;&#20351;&#24471;&#20256;&#32479;&#31070;&#32463;&#32593;&#32476;&#33021;&#22815;&#22312;&#35745;&#31639;&#25104;&#26412;&#22823;&#24133;&#19979;&#38477;&#30340;&#24773;&#20917;&#19979;&#36229;&#36234;&#22823;&#22411;&#38598;&#25104;&#27169;&#22411;&#65292;&#20026;&#27169;&#22411;&#32852;&#21512;&#39044;&#27979;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#25509;&#21475;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26234;&#33021;&#20381;&#36182;&#20110;&#26234;&#33021;&#20307;&#23545;&#20854;&#19981;&#30693;&#36947;&#30340;&#20107;&#29289;&#30340;&#20102;&#35299;&#12290;&#26234;&#33021;&#20307;&#39044;&#27979;&#22810;&#20010;&#36755;&#20837;&#26631;&#31614;&#30340;&#36136;&#37327;&#21487;&#20197;&#35780;&#20272;&#20854;&#23545;&#36825;&#31181;&#33021;&#21147;&#30340;&#25484;&#25569;&#31243;&#24230;&#12290;&#38598;&#25104;&#24335;&#26041;&#27861;&#22312;&#21407;&#21017;&#19978;&#21487;&#20197;&#20135;&#29983;&#26377;&#25928;&#30340;&#39044;&#27979;&#65292;&#20294;&#35757;&#32451;&#22823;&#35268;&#27169;&#30340;&#38598;&#25104;&#27169;&#22411;&#30340;&#35745;&#31639;&#25104;&#26412;&#24456;&#39640;&#65292;&#20174;&#32780;&#21487;&#33021;&#20250;&#21464;&#24471;&#31105;&#27490;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;Epinet&#65306;&#19968;&#31181;&#21487;&#20197;&#21152;&#24378;&#20219;&#20309;&#20256;&#32479;&#31070;&#32463;&#32593;&#32476;&#65288;&#21253;&#25324;&#22823;&#22411;&#39044;&#35757;&#32451;&#27169;&#22411;&#65289;&#30340;&#26550;&#26500;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#36866;&#37327;&#32423;&#21035;&#30340;&#36882;&#22686;&#35745;&#31639;&#35757;&#32451;&#26469;&#20272;&#35745;&#19981;&#30830;&#23450;&#24615;&#12290;&#29992;Epinet&#65292;&#20256;&#32479;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#22312;&#35745;&#31639;&#25104;&#26412;&#22823;&#24133;&#19979;&#38477;&#30340;&#24773;&#20917;&#19979;&#32988;&#36807;&#30001;&#25968;&#30334;&#20010;&#25110;&#26356;&#22810;&#31890;&#23376;&#32452;&#25104;&#30340;&#22823;&#22411;&#38598;&#25104;&#65292;&#21516;&#26102;&#19981;&#38656;&#35201;&#31526;&#21512;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;&#20256;&#32479;&#26694;&#26550;&#12290;&#20026;&#20102;&#36866;&#24212;&#36229;&#36234;BNN&#30340;&#26041;&#27861;&#30340;&#21457;&#23637;&#65292;&#20363;&#22914;Epinet&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#20316;&#20026;&#20135;&#29983;&#32852;&#21512;&#39044;&#27979;&#27169;&#22411;&#30340;&#25509;&#21475;&#30340;&#30693;&#35782;&#31070;&#32463;&#32593;&#32476;&#65288;ENN&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Intelligence relies on an agent's knowledge of what it does not know. This capability can be assessed based on the quality of joint predictions of labels across multiple inputs. In principle, ensemble-based approaches produce effective joint predictions, but the computational costs of training large ensembles can become prohibitive. We introduce the epinet: an architecture that can supplement any conventional neural network, including large pretrained models, and can be trained with modest incremental computation to estimate uncertainty. With an epinet, conventional neural networks outperform very large ensembles, consisting of hundreds or more particles, with orders of magnitude less computation. The epinet does not fit the traditional framework of Bayesian neural networks. To accommodate development of approaches beyond BNNs, such as the epinet, we introduce the epistemic neural network (ENN) as an interface for models that produce joint predictions.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#35777;&#26126;&#20102;&#23545;&#20110;&#19968;&#31867;ODENet&#21644;&#19968;&#31867;ResNet&#65292;&#8220;&#23485;&#24230;&#20026;n+m&#30340;ODENet&#21487;&#20197;&#36924;&#36817;${\rm \mathbb{R}^n}$&#19978;&#32039;&#33268;&#23376;&#38598;&#19978;&#30340;&#20219;&#20309;&#36830;&#32493;&#20989;&#25968;&#8221;&#65292;&#21516;&#26102;&#25512;&#23548;&#20102;&#25439;&#22833;&#20989;&#25968;&#23545;&#26576;&#20010;&#35843;&#25972;&#21464;&#37327;&#30340;&#26799;&#24230;&#24182;&#29992;&#20110;&#26500;&#24314;ODENet&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#22312;MNIST&#19978;&#36827;&#34892;&#23454;&#39564;&#12290;</title><link>http://arxiv.org/abs/2101.10229</link><description>&lt;p&gt;
&#19968;&#20010;ODENet&#21644;ResNet&#30340;&#36890;&#29992;&#36924;&#36817;&#24615;&#36136;&#65306;&#25968;&#23398;&#20998;&#26512;&#19982;&#25968;&#20540;&#23454;&#39564;
&lt;/p&gt;
&lt;p&gt;
Universal Approximation Properties for an ODENet and a ResNet: Mathematical Analysis and Numerical Experiments. (arXiv:2101.10229v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2101.10229
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#35777;&#26126;&#20102;&#23545;&#20110;&#19968;&#31867;ODENet&#21644;&#19968;&#31867;ResNet&#65292;&#8220;&#23485;&#24230;&#20026;n+m&#30340;ODENet&#21487;&#20197;&#36924;&#36817;${\rm \mathbb{R}^n}$&#19978;&#32039;&#33268;&#23376;&#38598;&#19978;&#30340;&#20219;&#20309;&#36830;&#32493;&#20989;&#25968;&#8221;&#65292;&#21516;&#26102;&#25512;&#23548;&#20102;&#25439;&#22833;&#20989;&#25968;&#23545;&#26576;&#20010;&#35843;&#25972;&#21464;&#37327;&#30340;&#26799;&#24230;&#24182;&#29992;&#20110;&#26500;&#24314;ODENet&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#22312;MNIST&#19978;&#36827;&#34892;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#31867;ODENet&#21644;&#19968;&#31867;ResNet&#30340;&#36890;&#29992;&#36924;&#36817;&#24615;&#36136;(UAP)&#65292;&#23427;&#20204;&#26159;&#20855;&#26377;&#36339;&#36291;&#36830;&#25509;&#30340;&#28145;&#24230;&#23398;&#20064;&#31995;&#32479;&#30340;&#31616;&#21270;&#25968;&#23398;&#27169;&#22411;&#12290; UAP&#21487;&#20197;&#38472;&#36848;&#22914;&#19979;:&#35774;$n$&#21644;$m$&#20998;&#21035;&#20026;&#36755;&#20837;&#25968;&#25454;&#21644;&#36755;&#20986;&#25968;&#25454;&#30340;&#32500;&#25968;&#65292;&#24182;&#20551;&#35774;$m\leq n$&#12290;&#28982;&#21518;&#25105;&#20204;&#35777;&#26126;&#20102;&#24102;&#26377;&#38750;&#22810;&#39033;&#24335;&#36830;&#32493;&#28608;&#27963;&#20989;&#25968;&#30340;&#23485;&#24230;&#20026;$n+m$&#30340;ODENet&#21487;&#20197;&#36924;&#36817;$\mathbb {R} ^ n$&#19978;&#32039;&#33268;&#23376;&#38598;&#19978;&#30340;&#20219;&#20309;&#36830;&#32493;&#20989;&#25968;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#24403;&#28145;&#24230;&#36235;&#20110;&#26080;&#38480;&#26102;&#65292;ResNet&#20855;&#26377;&#30456;&#21516;&#30340;&#24615;&#36136;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#26126;&#30830;&#25512;&#23548;&#20102;&#25439;&#22833;&#20989;&#25968;&#23545;&#26576;&#20010;&#35843;&#25972;&#21464;&#37327;&#30340;&#26799;&#24230;&#12290; &#25105;&#20204;&#23558;&#20854;&#29992;&#20110;&#26500;&#24314;ODENet&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;&#20026;&#20102;&#23637;&#31034;&#27492;&#31639;&#27861;&#30340;&#23454;&#29992;&#24615;&#65292;&#25105;&#20204;&#23558;&#20854;&#24212;&#29992;&#20110;MNIST&#19978;&#30340;&#22238;&#24402;&#38382;&#39064;&#12289;&#20108;&#20998;&#31867;&#21644;&#22810;&#39033;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
We prove a universal approximation property (UAP) for a class of ODENet and a class of ResNet, which are simplified mathematical models for deep learning systems with skip connections. The UAP can be stated as follows. Let $n$ and $m$ be the dimension of input and output data, and assume $m\leq n$. Then we show that ODENet of width $n+m$ with any non-polynomial continuous activation function can approximate any continuous function on a compact subset on $\mathbb{R}^n$. We also show that ResNet has the same property as the depth tends to infinity. Furthermore, we derive the gradient of a loss function explicitly with respect to a certain tuning variable. We use this to construct a learning algorithm for ODENet. To demonstrate the usefulness of this algorithm, we apply it to a regression problem, a binary classification, and a multinomial classification in MNIST.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#37325;&#22797;&#39318;&#20215;&#25293;&#21334;&#30340;&#26368;&#20248;&#26080;&#24724;&#23398;&#20064;&#31639;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#29305;&#23450;&#30340;&#21453;&#39304;&#32467;&#26500;&#21644;&#25903;&#20184;&#20989;&#25968;&#65292;&#23454;&#29616;&#20102;&#25509;&#36817;&#26368;&#20248;&#30340;&#36951;&#25022;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2003.09795</link><description>&lt;p&gt;
&#37325;&#22797;&#39318;&#20215;&#25293;&#21334;&#20013;&#30340;&#26368;&#20248;&#26080;&#24724;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Optimal No-regret Learning in Repeated First-price Auctions. (arXiv:2003.09795v6 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2003.09795
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#37325;&#22797;&#39318;&#20215;&#25293;&#21334;&#30340;&#26368;&#20248;&#26080;&#24724;&#23398;&#20064;&#31639;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#29305;&#23450;&#30340;&#21453;&#39304;&#32467;&#26500;&#21644;&#25903;&#20184;&#20989;&#25968;&#65292;&#23454;&#29616;&#20102;&#25509;&#36817;&#26368;&#20248;&#30340;&#36951;&#25022;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#37325;&#22797;&#39318;&#20215;&#25293;&#21334;&#20013;&#30340;&#22312;&#32447;&#23398;&#20064;&#38382;&#39064;&#65292;&#25293;&#21334;&#32773;&#21482;&#22312;&#27599;&#27425;&#25293;&#21334;&#32467;&#26463;&#21518;&#30475;&#21040;&#26368;&#39640;&#30340;&#20986;&#20215;&#65292;&#20026;&#20102;&#26368;&#22823;&#21270;&#25910;&#30410;&#65292;&#22905;&#24517;&#39035;&#36827;&#34892;&#36866;&#24212;&#24615;&#20986;&#20215;&#12290;&#28982;&#32780;&#65292;&#25293;&#21334;&#32773;&#21482;&#33021;&#38754;&#23545;&#34987;&#23457;&#26597;&#30340;&#21453;&#39304;&#65292;&#22914;&#26524;&#22905;&#36194;&#24471;&#20986;&#20215;&#65292;&#23601;&#26080;&#27861;&#35266;&#23519;&#21040;&#20854;&#20182;&#31454;&#26631;&#32773;&#30340;&#26368;&#39640;&#20986;&#20215;&#65292;&#32780;&#20854;&#20182;&#31454;&#26631;&#32773;&#30340;&#26368;&#39640;&#20986;&#20215;&#26159;&#20174;&#26410;&#30693;&#30340;&#20998;&#24067;&#20013;\textit{iid}&#25277;&#21462;&#30340;&#12290;&#26412;&#25991;&#24320;&#21457;&#20102;&#31532;&#19968;&#20010;&#23398;&#20064;&#31639;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#39318;&#20215;&#25293;&#21334;&#30340;&#20004;&#20010;&#32467;&#26500;&#24615;&#36136;&#65292;&#21363;&#29305;&#23450;&#30340;&#21453;&#39304;&#32467;&#26500;&#21644;&#25903;&#20184;&#20989;&#25968;&#65292;&#23454;&#29616;&#20102;&#25509;&#36817;&#26368;&#20248;&#30340;$\widetilde{O}(\sqrt{T})$&#36951;&#25022;&#30028;&#38480;&#12290;&#39318;&#20215;&#25293;&#21334;&#20013;&#30340;&#21453;&#39304;&#26426;&#21046;&#32467;&#21512;&#20102;&#36328;&#34892;&#21160;(&#20986;&#20215;)&#30340;&#22270;&#24418;&#21453;&#39304;&#12289;&#36328;&#19978;&#19979;&#25991;(&#31169;&#20154;&#20215;&#20540;)&#30340;&#20132;&#21449;&#23398;&#20064;&#20197;&#21450;&#23545;&#19978;&#19979;&#25991;&#30340;&#37096;&#20998;&#25490;&#24207;&#65292;&#25105;&#20204;&#23558;&#20854;&#25512;&#24191;&#20026;&#37096;&#20998;&#25490;&#24207;&#24773;&#22659;&#36172;&#21338;&#26426;&#12290;&#36890;&#36807;&#23637;&#31034;&#25439;&#22833;&#20989;&#25968;&#19982;&#20248;&#21270;&#32467;&#26500;&#20043;&#38388;&#30340;&#22855;&#24618;&#20998;&#31163;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#27492;&#26694;&#26550;&#30340;&#20248;&#28857;&#21644;&#32570;&#28857;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20351;&#29992;&#21518;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#26377;&#25928;&#21464;&#20307;&#65292;&#31216;&#20026;&#8220;&#24102;&#26377;&#22522;&#20110;&#26041;&#24046;&#30340;&#27491;&#21017;&#21270;&#30340;&#36830;&#32493;&#35843;&#29992;&#27491;&#21017;&#21270;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#22120;&#8221;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#21033;&#29992;&#20102;&#23545;&#38382;&#39064;&#26412;&#36136;&#32467;&#26500;&#21644;Kwon-Singer&#23450;&#29702;&#30340;&#20180;&#32454;&#25506;&#32034;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study online learning in repeated first-price auctions where a bidder, only observing the winning bid at the end of each auction, learns to adaptively bid in order to maximize her cumulative payoff. To achieve this goal, the bidder faces a censored feedback: if she wins the bid, then she is not able to observe the highest bid of the other bidders, which we assume is \textit{iid} drawn from an unknown distribution. In this paper, we develop the first learning algorithm that achieves a near-optimal $\widetilde{O}(\sqrt{T})$ regret bound, by exploiting two structural properties of first-price auctions, i.e. the specific feedback structure and payoff function.  The feedback in first-price auctions combines the graph feedback across actions (bids), the cross learning across contexts (private values), and a partial order over the contexts; we generalize it as the partially ordered contextual bandits. We establish both strengths and weaknesses of this framework, by showing a curious separa
&lt;/p&gt;</description></item><item><title>Open-LACU&#26159;&#19968;&#31181;&#26032;&#30340;&#24320;&#25918;&#24335;&#23398;&#20064;&#31574;&#30053;&#65292;&#23427;&#21487;&#20197;&#23558;&#20998;&#31867;&#22120;&#25512;&#24191;&#21040;&#35266;&#23519;&#21040;&#30340;&#21644;&#26410;&#35266;&#23519;&#21040;&#30340;&#26032;&#39062;&#31867;&#21035;&#20043;&#38388;&#65292;&#24182;&#36890;&#36807;&#23450;&#20041;&#19981;&#21516;&#30340;&#32972;&#26223;&#21644;&#26410;&#30693;&#31867;&#21035;&#26469;&#25552;&#39640;&#35757;&#32451;&#25104;&#26412;&#25928;&#30410;&#24615;&#65292;&#30830;&#20445;&#22312;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#26032;&#39062;&#31867;&#21035;&#26102;&#36827;&#34892;&#23433;&#20840;&#20998;&#31867;&#12290;</title><link>http://arxiv.org/abs/2002.01368</link><description>&lt;p&gt;
&#21033;&#29992;&#26410;&#26631;&#35760;&#25968;&#25454;&#25193;&#23637;&#31867;&#21035;&#30340;&#24320;&#25918;&#38598;&#23398;&#20064;&#65288;Open-LACU&#65289;
&lt;/p&gt;
&lt;p&gt;
Open-set learning with augmented category by exploiting unlabeled data (Open-LACU). (arXiv:2002.01368v5 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2002.01368
&lt;/p&gt;
&lt;p&gt;
Open-LACU&#26159;&#19968;&#31181;&#26032;&#30340;&#24320;&#25918;&#24335;&#23398;&#20064;&#31574;&#30053;&#65292;&#23427;&#21487;&#20197;&#23558;&#20998;&#31867;&#22120;&#25512;&#24191;&#21040;&#35266;&#23519;&#21040;&#30340;&#21644;&#26410;&#35266;&#23519;&#21040;&#30340;&#26032;&#39062;&#31867;&#21035;&#20043;&#38388;&#65292;&#24182;&#36890;&#36807;&#23450;&#20041;&#19981;&#21516;&#30340;&#32972;&#26223;&#21644;&#26410;&#30693;&#31867;&#21035;&#26469;&#25552;&#39640;&#35757;&#32451;&#25104;&#26412;&#25928;&#30410;&#24615;&#65292;&#30830;&#20445;&#22312;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#26032;&#39062;&#31867;&#21035;&#26102;&#36827;&#34892;&#23433;&#20840;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#21322;&#30417;&#30563;&#23398;&#20064;&#65288;SSL&#65289;&#21644;&#24320;&#25918;&#24335;&#35782;&#21035;&#65288;OSR&#65289;&#65292;&#24050;&#32463;&#36827;&#34892;&#20102;&#35768;&#22810;&#23581;&#35797;&#20197;&#21512;&#25104;&#21333;&#20010;&#35757;&#32451;&#31574;&#30053;&#12290;&#28982;&#32780;&#65292;&#27599;&#27425;&#23581;&#35797;&#37117;&#36829;&#21453;&#20102;&#24320;&#25918;&#38598;&#23450;&#20041;&#65292;&#22240;&#20026;&#36825;&#20123;&#26041;&#27861;&#22312;&#26410;&#26631;&#35760;&#30340;&#35757;&#32451;&#38598;&#20013;&#21253;&#21547;&#26032;&#39062;&#30340;&#31867;&#21035;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23398;&#20064;&#31574;&#30053;&#65292;&#20854;&#20013;&#20998;&#31867;&#22120;&#33021;&#22815;&#22312;&#35266;&#23519;&#21040;&#30340;&#21644;&#26410;&#35266;&#23519;&#21040;&#30340;&#26032;&#39062;&#31867;&#21035;&#20043;&#38388;&#36827;&#34892;&#25512;&#24191;&#65292;&#20174;&#32780;&#23450;&#20041;&#20102;&#35266;&#23519;&#21040;&#26032;&#39062;&#31867;&#21035;&#30340;&#32972;&#26223;&#31867;&#21035;&#21644;&#26410;&#35266;&#23519;&#21040;&#26032;&#39062;&#31867;&#21035;&#30340;&#26410;&#30693;&#31867;&#21035;&#12290;&#36890;&#36807;&#20998;&#31867;&#36825;&#20004;&#31181;&#26032;&#39062;&#31867;&#21035;&#30340;&#26041;&#24335;&#65292;Open-LACU&#33021;&#22815;&#25552;&#39640;&#35757;&#32451;&#30340;&#25104;&#26412;&#25928;&#30410;&#24615;&#65292;&#24182;&#30830;&#20445;&#22312;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#26032;&#39062;&#31867;&#21035;&#26102;&#36827;&#34892;&#23433;&#20840;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;
Several efforts have been made to synthesize semi-supervised learning (SSL) and open set recognition (OSR) within a single training policy. However, each attempt violated the definition of an open set by incorporating novel categories within the unlabeled training set. Although such \textit{observed} novel categories are undoubtedly prevalent in application-grade datasets, they should not be conflated with the OSR-defined \textit{unobserved} novel categories, which only emerge during testing. This study proposes a new learning policy wherein classifiers generalize between observed and unobserved novel categories. Specifically, our open-set learning with augmented category by exploiting unlabeled data (Open-LACU) policy defines a background category for observed novel categories and an unknown category for unobserved novel categories. By separating these novel category types, Open-LACU promotes cost-efficient training by eliminating the need to label every category and ensures safe clas
&lt;/p&gt;</description></item></channel></rss>