<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#22312;&#26680;&#22238;&#24402;&#30340;&#31616;&#21270;&#29615;&#22659;&#20013;&#35299;&#26512;&#20102;&#27169;&#22411;&#23849;&#28291;&#29616;&#35937;&#65292;&#24182;&#21457;&#29616;&#20102;&#27169;&#22411;&#33021;&#22815;&#22788;&#29702;&#34394;&#20551;&#25968;&#25454;&#19982;&#24615;&#33021;&#23436;&#20840;&#23849;&#28291;&#20043;&#38388;&#30340;&#20132;&#21449;&#28857;&#12290;&#36890;&#36807;&#25552;&#20986;&#22522;&#20110;&#33258;&#36866;&#24212;&#27491;&#21017;&#21270;&#30340;&#31574;&#30053;&#65292;&#25104;&#21151;&#32531;&#35299;&#20102;&#27169;&#22411;&#23849;&#28291;&#38382;&#39064;&#12290;&#36825;&#20123;&#21457;&#29616;&#36890;&#36807;&#23454;&#39564;&#35777;&#23454;&#12290;</title><link>https://arxiv.org/abs/2402.07712</link><description>&lt;p&gt;
&#27169;&#22411;&#23849;&#28291;&#35299;&#23494;&#65306;&#22238;&#24402;&#26696;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Model Collapse Demystified: The Case of Regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07712
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22312;&#26680;&#22238;&#24402;&#30340;&#31616;&#21270;&#29615;&#22659;&#20013;&#35299;&#26512;&#20102;&#27169;&#22411;&#23849;&#28291;&#29616;&#35937;&#65292;&#24182;&#21457;&#29616;&#20102;&#27169;&#22411;&#33021;&#22815;&#22788;&#29702;&#34394;&#20551;&#25968;&#25454;&#19982;&#24615;&#33021;&#23436;&#20840;&#23849;&#28291;&#20043;&#38388;&#30340;&#20132;&#21449;&#28857;&#12290;&#36890;&#36807;&#25552;&#20986;&#22522;&#20110;&#33258;&#36866;&#24212;&#27491;&#21017;&#21270;&#30340;&#31574;&#30053;&#65292;&#25104;&#21151;&#32531;&#35299;&#20102;&#27169;&#22411;&#23849;&#28291;&#38382;&#39064;&#12290;&#36825;&#20123;&#21457;&#29616;&#36890;&#36807;&#23454;&#39564;&#35777;&#23454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20687;ChatGPT&#36825;&#26679;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26102;&#20195;&#65292;"&#27169;&#22411;&#23849;&#28291;"&#29616;&#35937;&#25351;&#30340;&#26159;&#27169;&#22411;&#22312;&#36882;&#24402;&#22320;&#35757;&#32451;&#33258;&#36523;&#19978;&#19968;&#20195;&#21448;&#19968;&#20195;&#29983;&#25104;&#30340;&#25968;&#25454;&#26102;&#65292;&#20854;&#24615;&#33021;&#36880;&#28176;&#38477;&#20302;&#65292;&#26368;&#32456;&#21464;&#24471;&#23436;&#20840;&#26080;&#29992;&#65292;&#21363;&#27169;&#22411;&#23849;&#28291;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#22312;&#26680;&#22238;&#24402;&#30340;&#31616;&#21270;&#29615;&#22659;&#20013;&#30740;&#31350;&#20102;&#36825;&#19968;&#29616;&#35937;&#65292;&#24182;&#33719;&#24471;&#20102;&#32467;&#26524;&#65292;&#26174;&#31034;&#27169;&#22411;&#33021;&#22815;&#22788;&#29702;&#34394;&#20551;&#25968;&#25454;&#19982;&#27169;&#22411;&#24615;&#33021;&#23436;&#20840;&#23849;&#28291;&#20043;&#38388;&#23384;&#22312;&#26126;&#26174;&#30340;&#20132;&#21449;&#28857;&#12290;&#22312;&#22810;&#39033;&#24335;&#34928;&#20943;&#30340;&#20809;&#35889;&#21644;&#28304;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#20462;&#25913;&#21518;&#30340;&#32553;&#25918;&#23450;&#24459;&#65292;&#23637;&#31034;&#20102;&#20174;&#24555;&#36895;&#21040;&#32531;&#24930;&#36895;&#29575;&#30340;&#26032;&#20132;&#21449;&#29616;&#35937;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#22522;&#20110;&#33258;&#36866;&#24212;&#27491;&#21017;&#21270;&#30340;&#31616;&#21333;&#31574;&#30053;&#26469;&#32531;&#35299;&#27169;&#22411;&#23849;&#28291;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#36890;&#36807;&#23454;&#39564;&#35777;&#23454;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the era of large language models like ChatGPT, the phenomenon of "model collapse" refers to the situation whereby as a model is trained recursively on data generated from previous generations of itself over time, its performance degrades until the model eventually becomes completely useless, i.e the model collapses. In this work, we study this phenomenon in the simplified setting of kernel regression and obtain results which show a clear crossover between where the model can cope with fake data, and a regime where the model's performance completely collapses. Under polynomial decaying spectral and source conditions, we obtain modified scaling laws which exhibit new crossover phenomena from fast to slow rates. We also propose a simple strategy based on adaptive regularization to mitigate model collapse. Our theoretical results are validated with experiments.
&lt;/p&gt;</description></item><item><title>&#21033;&#29992;&#38543;&#26426;&#35797;&#39564;&#35774;&#35745;&#20102;&#19968;&#31181;&#32479;&#35745;&#26816;&#39564;&#65292;&#33021;&#22815;&#37327;&#21270;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#24378;&#24230;&#65292;&#24182;&#20272;&#35745;&#20854;&#19979;&#30028;&#65292;&#26377;&#25928;&#24212;&#29992;&#20110;&#29616;&#23454;&#19990;&#30028;&#20013;&#35782;&#21035;&#28151;&#28102;&#12290;</title><link>https://arxiv.org/abs/2312.03871</link><description>&lt;p&gt;
&#38544;&#34109;&#32780;&#21487;&#37327;&#21270;&#65306;&#20351;&#29992;&#38543;&#26426;&#35797;&#39564;&#30340;&#28151;&#28102;&#24378;&#24230;&#19979;&#30028;
&lt;/p&gt;
&lt;p&gt;
Hidden yet quantifiable: A lower bound for confounding strength using randomized trials
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.03871
&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;&#38543;&#26426;&#35797;&#39564;&#35774;&#35745;&#20102;&#19968;&#31181;&#32479;&#35745;&#26816;&#39564;&#65292;&#33021;&#22815;&#37327;&#21270;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#24378;&#24230;&#65292;&#24182;&#20272;&#35745;&#20854;&#19979;&#30028;&#65292;&#26377;&#25928;&#24212;&#29992;&#20110;&#29616;&#23454;&#19990;&#30028;&#20013;&#35782;&#21035;&#28151;&#28102;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24555;&#33410;&#22863;&#31934;&#20934;&#21307;&#23398;&#26102;&#20195;&#65292;&#35266;&#23519;&#24615;&#30740;&#31350;&#22312;&#27491;&#30830;&#35780;&#20272;&#20020;&#24202;&#23454;&#36341;&#20013;&#26032;&#30103;&#27861;&#26041;&#38754;&#21457;&#25381;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#21487;&#33021;&#20005;&#37325;&#25439;&#23475;&#20174;&#38750;&#38543;&#26426;&#25968;&#25454;&#20013;&#24471;&#20986;&#30340;&#22240;&#26524;&#32467;&#35770;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#38543;&#26426;&#35797;&#39564;&#26469;&#37327;&#21270;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#30340;&#26032;&#31574;&#30053;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#32479;&#35745;&#26816;&#39564;&#26469;&#26816;&#27979;&#24378;&#24230;&#36229;&#36807;&#32473;&#23450;&#38408;&#20540;&#30340;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#35813;&#26816;&#39564;&#26469;&#20272;&#35745;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#24378;&#24230;&#30340;&#28176;&#36817;&#26377;&#25928;&#19979;&#30028;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#21512;&#25104;&#21644;&#21322;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#32479;&#35745;&#26816;&#39564;&#30340;&#21151;&#25928;&#21644;&#26377;&#25928;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#19979;&#30028;&#22914;&#20309;&#33021;&#22815;&#22312;&#30495;&#23454;&#29615;&#22659;&#20013;&#27491;&#30830;&#35782;&#21035;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#30340;&#23384;&#22312;&#21644;&#19981;&#23384;&#22312;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.03871v2 Announce Type: replace-cross  Abstract: In the era of fast-paced precision medicine, observational studies play a major role in properly evaluating new treatments in clinical practice. Yet, unobserved confounding can significantly compromise causal conclusions drawn from non-randomized data. We propose a novel strategy that leverages randomized trials to quantify unobserved confounding. First, we design a statistical test to detect unobserved confounding with strength above a given threshold. Then, we use the test to estimate an asymptotically valid lower bound on the unobserved confounding strength. We evaluate the power and validity of our statistical test on several synthetic and semi-synthetic datasets. Further, we show how our lower bound can correctly identify the absence and presence of unobserved confounding in a real-world setting.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20132;&#21449;&#39564;&#35777;&#30340;&#26032;&#22411;&#21512;&#35268;&#39118;&#38505;&#25511;&#21046;&#26041;&#27861;(CV-CRC)&#65292;&#23427;&#25193;&#23637;&#20102;&#19968;&#33268;&#24615;&#39044;&#27979;&#30340;&#27010;&#24565;&#65292;&#33021;&#22815;&#25511;&#21046;&#26356;&#24191;&#27867;&#30340;&#39118;&#38505;&#20989;&#25968;&#65292;&#24182;&#22312;&#39044;&#27979;&#22120;&#38598;&#21512;&#30340;&#24179;&#22343;&#39118;&#38505;&#19978;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2401.11974</link><description>&lt;p&gt;
&#20132;&#21449;&#39564;&#35777;&#21512;&#35268;&#39118;&#38505;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Cross-Validation Conformal Risk Control. (arXiv:2401.11974v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.11974
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20132;&#21449;&#39564;&#35777;&#30340;&#26032;&#22411;&#21512;&#35268;&#39118;&#38505;&#25511;&#21046;&#26041;&#27861;(CV-CRC)&#65292;&#23427;&#25193;&#23637;&#20102;&#19968;&#33268;&#24615;&#39044;&#27979;&#30340;&#27010;&#24565;&#65292;&#33021;&#22815;&#25511;&#21046;&#26356;&#24191;&#27867;&#30340;&#39118;&#38505;&#20989;&#25968;&#65292;&#24182;&#22312;&#39044;&#27979;&#22120;&#38598;&#21512;&#30340;&#24179;&#22343;&#39118;&#38505;&#19978;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21512;&#35268;&#39118;&#38505;&#25511;&#21046;&#65288;CRC&#65289;&#26159;&#19968;&#31181;&#26368;&#36817;&#25552;&#20986;&#30340;&#25216;&#26415;&#65292;&#23427;&#24212;&#29992;&#20110;&#20256;&#32479;&#30340;&#28857;&#39044;&#27979;&#22120;&#19978;&#65292;&#20197;&#25552;&#20379;&#26657;&#20934;&#20445;&#35777;&#12290;&#22312;CRC&#20013;&#25512;&#24191;&#19968;&#33268;&#24615;&#39044;&#27979;&#65288;CP&#65289;&#65292;&#36890;&#36807;&#20174;&#28857;&#39044;&#27979;&#22120;&#20013;&#25552;&#21462;&#19968;&#20010;&#39044;&#27979;&#22120;&#38598;&#21512;&#26469;&#25511;&#21046;&#39118;&#38505;&#20989;&#25968;&#65288;&#22914;&#35823;&#35206;&#30422;&#27010;&#29575;&#25110;&#38169;&#35823;&#36127;&#20363;&#29575;&#65289;&#65292;&#20174;&#32780;&#30830;&#20445;&#26657;&#20934;&#24615;&#12290;&#21407;&#22987;&#30340;CRC&#38656;&#35201;&#23558;&#21487;&#29992;&#25968;&#25454;&#38598;&#20998;&#20026;&#35757;&#32451;&#21644;&#39564;&#35777;&#25968;&#25454;&#38598;&#12290;&#24403;&#25968;&#25454;&#21487;&#29992;&#24615;&#26377;&#38480;&#26102;&#65292;&#36825;&#21487;&#33021;&#23548;&#33268;&#39044;&#27979;&#22120;&#38598;&#21512;&#25928;&#29575;&#20302;&#19979;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#20132;&#21449;&#39564;&#35777;&#32780;&#19981;&#26159;&#21407;&#22987;CRC&#30340;&#26032;&#22411;CRC&#26041;&#27861;&#12290;&#25152;&#25552;&#20986;&#30340;&#20132;&#21449;&#39564;&#35777;CRC&#65288;CV-CRC&#65289;&#23558;CP&#30340;&#19968;&#31181;&#29256;&#26412;&#25193;&#23637;&#21040;CRC&#65292;&#21487;&#20197;&#25511;&#21046;&#26356;&#24191;&#27867;&#30340;&#39118;&#38505;&#20989;&#25968;&#12290;CV-CRC&#34987;&#35777;&#26126;&#22312;&#39044;&#27979;&#22120;&#38598;&#21512;&#30340;&#24179;&#22343;&#39118;&#38505;&#19978;&#20855;&#26377;&#29702;&#35770;&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;CV-CRC&#22312;&#23454;&#36341;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conformal risk control (CRC) is a recently proposed technique that applies post-hoc to a conventional point predictor to provide calibration guarantees. Generalizing conformal prediction (CP), with CRC, calibration is ensured for a set predictor that is extracted from the point predictor to control a risk function such as the probability of miscoverage or the false negative rate. The original CRC requires the available data set to be split between training and validation data sets. This can be problematic when data availability is limited, resulting in inefficient set predictors. In this paper, a novel CRC method is introduced that is based on cross-validation, rather than on validation as the original CRC. The proposed cross-validation CRC (CV-CRC) extends a version of the jackknife-minmax from CP to CRC, allowing for the control of a broader range of risk functions. CV-CRC is proved to offer theoretical guarantees on the average risk of the set predictor. Furthermore, numerical exper
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;KL&#32422;&#26463;&#19979;&#30340;&#21453;&#39304;&#24378;&#21270;&#23398;&#20064;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#26377;&#25928;&#30340;&#31639;&#27861;&#21644;&#23454;&#36341;&#12290;&#23454;&#35777;&#35780;&#20272;&#34920;&#26126;&#65292;&#35813;&#26694;&#26550;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23545;&#40784;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2312.11456</link><description>&lt;p&gt;
&#20154;&#31867;&#21453;&#39304;&#30340;&#36845;&#20195;&#20559;&#22909;&#23398;&#20064;&#65306;&#22312;KL&#32422;&#26463;&#19979;&#23558;&#29702;&#35770;&#19982;&#23454;&#36341;&#32852;&#31995;&#36215;&#26469;&#30340;RLHF
&lt;/p&gt;
&lt;p&gt;
Iterative Preference Learning from Human Feedback: Bridging Theory and Practice for RLHF under KL-Constraint. (arXiv:2312.11456v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.11456
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;KL&#32422;&#26463;&#19979;&#30340;&#21453;&#39304;&#24378;&#21270;&#23398;&#20064;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#26377;&#25928;&#30340;&#31639;&#27861;&#21644;&#23454;&#36341;&#12290;&#23454;&#35777;&#35780;&#20272;&#34920;&#26126;&#65292;&#35813;&#26694;&#26550;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#23545;&#40784;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#29983;&#25104;&#27169;&#22411;&#19982;&#24378;&#21270;&#23398;&#20064;&#20174;&#20154;&#31867;&#21453;&#39304;&#20013;&#30340;&#23545;&#40784;&#36807;&#31243;&#30340;&#29702;&#35770;&#26694;&#26550;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#26631;&#20934;&#30340;&#25968;&#23398;&#34920;&#36798;&#24335;&#65292;&#21363;&#21453;&#21521;KL&#27491;&#21017;&#21270;&#30340;&#19978;&#19979;&#25991;&#22810;&#33218;&#36172;&#21338;&#26426;&#29992;&#20110;RLHF&#12290;&#23613;&#31649;&#23427;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#23454;&#38469;&#24212;&#29992;&#65292;&#20294;&#23545;&#36825;&#20010;&#20844;&#24335;&#30340;&#20005;&#26684;&#29702;&#35770;&#20998;&#26512;&#20173;&#28982;&#24456;&#24320;&#25918;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#23427;&#22312;&#31163;&#32447;&#12289;&#22312;&#32447;&#21644;&#28151;&#21512;&#19977;&#31181;&#19981;&#21516;&#22330;&#26223;&#19979;&#30340;&#34892;&#20026;&#65292;&#24182;&#25552;&#20986;&#20102;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#29702;&#35770;&#20445;&#35777;&#30340;&#39640;&#25928;&#31639;&#27861;&#12290;&#26397;&#30528;&#23454;&#38469;&#24212;&#29992;&#30340;&#26041;&#21521;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#36890;&#36807;&#23545;&#20449;&#24687;&#29702;&#35770;&#31574;&#30053;&#25913;&#36827;&#39044;&#35328;&#30340;&#31283;&#20581;&#36817;&#20284;&#65292;&#33258;&#28982;&#22320;&#20135;&#29983;&#20102;&#20960;&#31181;&#26032;&#39062;&#30340;RLHF&#31639;&#27861;&#12290;&#36825;&#21253;&#25324;&#22312;&#32447;&#22330;&#26223;&#20013;&#30340;&#36845;&#20195;&#29256;&#26412;&#30340;&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;(DPO)&#31639;&#27861;&#65292;&#20197;&#21450;&#31163;&#32447;&#24773;&#26223;&#19979;&#30340;&#22810;&#27493;&#25298;&#32477;&#25277;&#26679;&#31574;&#30053;&#12290;&#25105;&#20204;&#23545;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#30495;&#23454;&#23545;&#40784;&#23454;&#39564;&#36827;&#34892;&#20102;&#23454;&#35777;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the theoretical framework of the alignment process of generative models with Reinforcement Learning from Human Feedback (RLHF). We consider a standard mathematical formulation, the reverse-KL regularized contextual bandit for RLHF. Despite its widespread practical application, a rigorous theoretical analysis of this formulation remains open. We investigate its behavior in three distinct settings -- offline, online, and hybrid -- and propose efficient algorithms with finite-sample theoretical guarantees.  Moving towards practical applications, our framework, with a robust approximation of the information-theoretical policy improvement oracle, naturally gives rise to several novel RLHF algorithms. This includes an iterative version of the Direct Preference Optimization (DPO) algorithm for online settings, and a multi-step rejection sampling strategy for offline scenarios. Our empirical evaluations on real-world alignment experiment of large language model demonstrate t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#32431;&#24046;&#20998;&#38544;&#31169;&#21644;&#39640;&#26031;&#24046;&#20998;&#38544;&#31169;&#30340;&#21487;&#35745;&#31639;MCMC&#31169;&#26377;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#36817;&#20284;&#37319;&#26679;&#25200;&#21160;&#31639;&#27861;&#65292;&#32467;&#21512;Metropolis-Hastings&#31639;&#27861;&#21644;&#23616;&#37096;&#21270;&#27493;&#39588;&#65292;&#23454;&#29616;&#20102;&#23545;&#38544;&#31169;&#30340;&#20445;&#25252;&#24182;&#33719;&#24471;&#20102;&#36739;&#22909;&#30340;&#25910;&#25947;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.14661</link><description>&lt;p&gt;
&#22522;&#20110;&#32431;&#24046;&#20998;&#38544;&#31169;&#21644;&#39640;&#26031;&#24046;&#20998;&#38544;&#31169;&#30340;&#21487;&#35745;&#31639;MCMC&#31169;&#26377;&#23398;&#20064;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tractable MCMC for Private Learning with Pure and Gaussian Differential Privacy. (arXiv:2310.14661v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.14661
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#32431;&#24046;&#20998;&#38544;&#31169;&#21644;&#39640;&#26031;&#24046;&#20998;&#38544;&#31169;&#30340;&#21487;&#35745;&#31639;MCMC&#31169;&#26377;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#36817;&#20284;&#37319;&#26679;&#25200;&#21160;&#31639;&#27861;&#65292;&#32467;&#21512;Metropolis-Hastings&#31639;&#27861;&#21644;&#23616;&#37096;&#21270;&#27493;&#39588;&#65292;&#23454;&#29616;&#20102;&#23545;&#38544;&#31169;&#30340;&#20445;&#25252;&#24182;&#33719;&#24471;&#20102;&#36739;&#22909;&#30340;&#25910;&#25947;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21518;&#39564;&#37319;&#26679;&#21363;&#20174;&#21518;&#39564;&#20998;&#24067;&#20013;&#37319;&#26679;&#30340;&#25351;&#25968;&#26426;&#21046;&#65292;&#25552;&#20379;&#949;-&#32431;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#20445;&#35777;&#65292;&#24182;&#19981;&#21463;&#65288;&#949;&#65292;&#948;&#65289;-&#36817;&#20284;DP&#24341;&#20837;&#30340;&#28508;&#22312;&#26080;&#30028;&#38544;&#31169;&#27844;&#28431;&#30340;&#24433;&#21709;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#38656;&#35201;&#24212;&#29992;&#36817;&#20284;&#37319;&#26679;&#26041;&#27861;&#65292;&#22914;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#65288;MCMC&#65289;&#65292;&#20174;&#32780;&#37325;&#26032;&#24341;&#20837;&#20102;&#23545;&#38544;&#31169;&#20445;&#35777;&#30340;&#948;-&#36817;&#20284;&#35823;&#24046;&#12290;&#20026;&#20102;&#24357;&#21512;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#36817;&#20284;&#37319;&#26679;&#25200;&#21160;&#65288;&#21363;ASAP&#65289;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#19982;&#28385;&#36275;&#32431;DP&#25110;&#32431;&#39640;&#26031;DP&#65288;&#21363;&#948;=0&#65289;&#30340;&#21442;&#32771;&#20998;&#24067;&#26377;&#30028;Wasserstein&#26080;&#31351;&#36317;&#31163;&#30340;MCMC&#26679;&#26412;&#21152;&#22122;&#22768;&#12290;&#28982;&#21518;&#21033;&#29992;Metropolis-Hastings&#31639;&#27861;&#29983;&#25104;&#26679;&#26412;&#24182;&#35777;&#26126;&#31639;&#27861;&#22312;W$_\infty$&#36317;&#31163;&#19978;&#25910;&#25947;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#36807;&#23558;&#25105;&#20204;&#30340;&#26032;&#25216;&#26415;&#19982;&#32454;&#33268;&#30340;&#23616;&#37096;&#21270;&#27493;&#39588;&#30456;&#32467;&#21512;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#31532;&#19968;&#20010;&#21487;&#35745;&#31639;MCMC&#31169;&#26377;&#23398;&#20064;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Posterior sampling, i.e., exponential mechanism to sample from the posterior distribution, provides $\varepsilon$-pure differential privacy (DP) guarantees and does not suffer from potentially unbounded privacy breach introduced by $(\varepsilon,\delta)$-approximate DP. In practice, however, one needs to apply approximate sampling methods such as Markov chain Monte Carlo (MCMC), thus re-introducing the unappealing $\delta$-approximation error into the privacy guarantees. To bridge this gap, we propose the Approximate SAample Perturbation (abbr. ASAP) algorithm which perturbs an MCMC sample with noise proportional to its Wasserstein-infinity ($W_\infty$) distance from a reference distribution that satisfies pure DP or pure Gaussian DP (i.e., $\delta=0$). We then leverage a Metropolis-Hastings algorithm to generate the sample and prove that the algorithm converges in W$_\infty$ distance. We show that by combining our new techniques with a careful localization step, we obtain the first ne
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#26080;&#32422;&#26463;&#30446;&#26631;&#65292;&#36890;&#36807;&#24212;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#21040;CCA&#30446;&#26631;&#65292;&#23454;&#29616;&#20102;&#19968;&#31995;&#21015;&#24555;&#36895;&#31639;&#27861;&#65292;&#21253;&#25324;&#38543;&#26426;PLS&#12289;&#38543;&#26426;CCA&#21644;&#28145;&#24230;CCA&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#21508;&#31181;&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#27604;&#20808;&#21069;&#26368;&#20808;&#36827;&#26041;&#27861;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#21644;&#26356;&#39640;&#30340;&#30456;&#20851;&#24615;&#24674;&#22797;&#12290;</title><link>http://arxiv.org/abs/2310.01012</link><description>&lt;p&gt;
CCA&#23478;&#26063;&#30340;&#39640;&#25928;&#31639;&#27861;&#65306;&#26080;&#32422;&#26463;&#30446;&#26631;&#19982;&#26080;&#20559;&#26799;&#24230;
&lt;/p&gt;
&lt;p&gt;
Efficient Algorithms for the CCA Family: Unconstrained Objectives with Unbiased Gradients. (arXiv:2310.01012v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.01012
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#26080;&#32422;&#26463;&#30446;&#26631;&#65292;&#36890;&#36807;&#24212;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#21040;CCA&#30446;&#26631;&#65292;&#23454;&#29616;&#20102;&#19968;&#31995;&#21015;&#24555;&#36895;&#31639;&#27861;&#65292;&#21253;&#25324;&#38543;&#26426;PLS&#12289;&#38543;&#26426;CCA&#21644;&#28145;&#24230;CCA&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#21508;&#31181;&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20986;&#27604;&#20808;&#21069;&#26368;&#20808;&#36827;&#26041;&#27861;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#21644;&#26356;&#39640;&#30340;&#30456;&#20851;&#24615;&#24674;&#22797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20856;&#22411;&#30456;&#20851;&#20998;&#26512;&#65288;CCA&#65289;&#26041;&#27861;&#22312;&#22810;&#35270;&#35282;&#23398;&#20064;&#20013;&#20855;&#26377;&#22522;&#30784;&#24615;&#20316;&#29992;&#12290;&#27491;&#21017;&#21270;&#32447;&#24615;CCA&#26041;&#27861;&#21487;&#20197;&#30475;&#20316;&#26159;&#20559;&#26368;&#23567;&#20108;&#20056;&#65288;PLS&#65289;&#30340;&#25512;&#24191;&#65292;&#24182;&#19982;&#24191;&#20041;&#29305;&#24449;&#20540;&#38382;&#39064;&#65288;GEP&#65289;&#26694;&#26550;&#32479;&#19968;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#32447;&#24615;&#26041;&#27861;&#30340;&#20256;&#32479;&#31639;&#27861;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#19978;&#35745;&#31639;&#19978;&#26159;&#19981;&#21487;&#34892;&#30340;&#12290;&#28145;&#24230;CCA&#30340;&#25193;&#23637;&#26174;&#31034;&#20986;&#24456;&#22823;&#30340;&#28508;&#21147;&#65292;&#20294;&#30446;&#21069;&#30340;&#35757;&#32451;&#36807;&#31243;&#32531;&#24930;&#19988;&#22797;&#26434;&#12290;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;&#19968;&#20010;&#25551;&#36848;GEPs&#30340;&#39030;&#32423;&#23376;&#31354;&#38388;&#30340;&#26032;&#39062;&#26080;&#32422;&#26463;&#30446;&#26631;&#12290;&#25105;&#20204;&#30340;&#26680;&#24515;&#36129;&#29486;&#26159;&#19968;&#31995;&#21015;&#24555;&#36895;&#31639;&#27861;&#65292;&#29992;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#24212;&#29992;&#20110;&#30456;&#24212;&#30340;CCA&#30446;&#26631;&#65292;&#20174;&#32780;&#33719;&#24471;&#38543;&#26426;PLS&#12289;&#38543;&#26426;CCA&#21644;&#28145;&#24230;CCA&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#25152;&#26377;&#26631;&#20934;CCA&#21644;&#28145;&#24230;CCA&#22522;&#20934;&#27979;&#35797;&#20013;&#26174;&#31034;&#20986;&#27604;&#20808;&#21069;&#26368;&#20808;&#36827;&#26041;&#27861;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#21644;&#26356;&#39640;&#30340;&#30456;&#20851;&#24615;&#24674;&#22797;&#12290;&#36825;&#26679;&#30340;&#36895;&#24230;&#20351;&#25105;&#20204;&#33021;&#22815;&#39318;&#27425;&#36827;&#34892;&#22823;&#35268;&#27169;&#29983;&#29289;&#25968;&#25454;&#30340;PLS&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Canonical Correlation Analysis (CCA) family of methods is foundational in multi-view learning. Regularised linear CCA methods can be seen to generalise Partial Least Squares (PLS) and unified with a Generalized Eigenvalue Problem (GEP) framework. However, classical algorithms for these linear methods are computationally infeasible for large-scale data. Extensions to Deep CCA show great promise, but current training procedures are slow and complicated. First we propose a novel unconstrained objective that characterizes the top subspace of GEPs. Our core contribution is a family of fast algorithms for stochastic PLS, stochastic CCA, and Deep CCA, simply obtained by applying stochastic gradient descent (SGD) to the corresponding CCA objectives. These methods show far faster convergence and recover higher correlations than the previous state-of-the-art on all standard CCA and Deep CCA benchmarks. This speed allows us to perform a first-of-its-kind PLS analysis of an extremely large bio
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#31216;&#20026;&#21518;&#32493;&#39564;&#35777;&#30340;&#27491;&#24335;&#27979;&#35797;&#31243;&#24207;&#65292;&#29992;&#20110;&#26816;&#27979;&#27169;&#22411;&#20998;&#37197;&#22266;&#23450;&#39044;&#27979;&#30340;&#24773;&#20917;&#12290;&#36890;&#36807;&#24320;&#21457;&#21487;&#38752;&#30340;&#26426;&#21046;&#65292;&#21487;&#20197;&#30830;&#23450;&#32473;&#23450;&#27169;&#22411;&#26159;&#21542;&#33021;&#20026;&#20915;&#31574;&#23545;&#35937;&#25552;&#20379;&#21518;&#32493;&#25514;&#26045;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#27169;&#22411;&#20998;&#37197;&#22266;&#23450;&#39044;&#27979;&#21487;&#33021;&#24102;&#26469;&#30340;&#38382;&#39064;&#12290;&#35813;&#30740;&#31350;&#36824;&#23637;&#31034;&#20102;&#22914;&#20309;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#20013;&#30830;&#20445;&#21518;&#32493;&#25514;&#26045;&#21644;&#23545;&#25239;&#40065;&#26834;&#24615;&#65292;&#24182;&#25506;&#35752;&#20102;&#22312;&#36151;&#27454;&#25968;&#25454;&#38598;&#20013;&#23454;&#29616;&#21518;&#32493;&#25514;&#26045;&#30340;&#19981;&#21487;&#34892;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.12820</link><description>&lt;p&gt;
&#19981;&#25490;&#38500;&#39044;&#27979;&#65306;&#22522;&#20110;&#21487;&#36798;&#38598;&#30340;&#21518;&#32493;&#39564;&#35777;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Prediction without Preclusion: Recourse Verification with Reachable Sets. (arXiv:2308.12820v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12820
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#31216;&#20026;&#21518;&#32493;&#39564;&#35777;&#30340;&#27491;&#24335;&#27979;&#35797;&#31243;&#24207;&#65292;&#29992;&#20110;&#26816;&#27979;&#27169;&#22411;&#20998;&#37197;&#22266;&#23450;&#39044;&#27979;&#30340;&#24773;&#20917;&#12290;&#36890;&#36807;&#24320;&#21457;&#21487;&#38752;&#30340;&#26426;&#21046;&#65292;&#21487;&#20197;&#30830;&#23450;&#32473;&#23450;&#27169;&#22411;&#26159;&#21542;&#33021;&#20026;&#20915;&#31574;&#23545;&#35937;&#25552;&#20379;&#21518;&#32493;&#25514;&#26045;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#27169;&#22411;&#20998;&#37197;&#22266;&#23450;&#39044;&#27979;&#21487;&#33021;&#24102;&#26469;&#30340;&#38382;&#39064;&#12290;&#35813;&#30740;&#31350;&#36824;&#23637;&#31034;&#20102;&#22914;&#20309;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#20013;&#30830;&#20445;&#21518;&#32493;&#25514;&#26045;&#21644;&#23545;&#25239;&#40065;&#26834;&#24615;&#65292;&#24182;&#25506;&#35752;&#20102;&#22312;&#36151;&#27454;&#25968;&#25454;&#38598;&#20013;&#23454;&#29616;&#21518;&#32493;&#25514;&#26045;&#30340;&#19981;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#24120;&#34987;&#29992;&#20110;&#20915;&#23450;&#35841;&#26377;&#36164;&#26684;&#24471;&#21040;&#36151;&#27454;&#12289;&#38754;&#35797;&#25110;&#20844;&#20849;&#31119;&#21033;&#12290;&#26631;&#20934;&#25216;&#26415;&#29992;&#20110;&#26500;&#24314;&#36825;&#20123;&#27169;&#22411;&#26102;&#65292;&#20250;&#20351;&#29992;&#20851;&#20110;&#20154;&#30340;&#29305;&#24449;&#65292;&#20294;&#24573;&#35270;&#20182;&#20204;&#30340;&#21487;&#25805;&#20316;&#24615;&#12290;&#22240;&#27492;&#65292;&#27169;&#22411;&#21487;&#33021;&#20250;&#20998;&#37197;&#22266;&#23450;&#30340;&#39044;&#27979;&#65292;&#36825;&#24847;&#21619;&#30528;&#34987;&#25298;&#32477;&#36151;&#27454;&#12289;&#38754;&#35797;&#25110;&#31119;&#21033;&#30340;&#28040;&#36153;&#32773;&#21487;&#33021;&#27704;&#20037;&#34987;&#25490;&#38500;&#22312;&#33719;&#24471;&#20449;&#36151;&#12289;&#23601;&#19994;&#25110;&#25588;&#21161;&#30340;&#26426;&#20250;&#20043;&#22806;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#27491;&#24335;&#30340;&#27979;&#35797;&#31243;&#24207;&#26469;&#26816;&#27979;&#20998;&#37197;&#22266;&#23450;&#39044;&#27979;&#30340;&#27169;&#22411;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#21518;&#32493;&#39564;&#35777;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#22871;&#26426;&#21046;&#21487;&#38752;&#22320;&#30830;&#23450;&#32473;&#23450;&#27169;&#22411;&#26159;&#21542;&#33021;&#25552;&#20379;&#23545;&#20915;&#31574;&#23545;&#35937;&#30340;&#21518;&#32493;&#25163;&#27573;&#65292;&#36825;&#20123;&#25163;&#27573;&#30001;&#29992;&#25143;&#25351;&#23450;&#30340;&#21487;&#25805;&#20316;&#24615;&#32422;&#26463;&#30830;&#23450;&#12290;&#25105;&#20204;&#28436;&#31034;&#20102;&#25105;&#20204;&#30340;&#24037;&#20855;&#22914;&#20309;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#38598;&#20013;&#30830;&#20445;&#21518;&#32493;&#25514;&#26045;&#21644;&#23545;&#25239;&#40065;&#26834;&#24615;&#65292;&#24182;&#21033;&#29992;&#23427;&#20204;&#30740;&#31350;&#20102;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#36151;&#27454;&#25968;&#25454;&#38598;&#20013;&#23454;&#29616;&#21518;&#32493;&#25514;&#26045;&#30340;&#19981;&#21487;&#34892;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#20984;&#26174;&#20102;&#27169;&#22411;&#22914;&#20309;&#26080;&#24847;&#20013;&#20998;&#37197;&#22266;&#23450;&#39044;&#27979;&#65292;&#20174;&#32780;&#27704;&#20037;&#31105;&#27490;&#20351;&#29992;&#32773;&#33719;&#24471;&#30456;&#20851;&#26435;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;
Machine learning models are often used to decide who will receive a loan, a job interview, or a public benefit. Standard techniques to build these models use features about people but overlook their actionability. In turn, models can assign predictions that are fixed, meaning that consumers who are denied loans, interviews, or benefits may be permanently locked out from access to credit, employment, or assistance. In this work, we introduce a formal testing procedure to flag models that assign fixed predictions that we call recourse verification. We develop machinery to reliably determine if a given model can provide recourse to its decision subjects from a set of user-specified actionability constraints. We demonstrate how our tools can ensure recourse and adversarial robustness in real-world datasets and use them to study the infeasibility of recourse in real-world lending datasets. Our results highlight how models can inadvertently assign fixed predictions that permanently bar acces
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;Stein&#26041;&#27861;&#25512;&#23548;&#20986;Wasserstein&#36317;&#31163;&#30340;&#19978;&#30028;&#65292;&#36890;&#36807;&#39640;&#26031;&#24179;&#28369;&#25216;&#26415;&#23558;&#24179;&#28369;&#24230;&#37327;&#36716;&#21270;&#20026;Wasserstein&#36317;&#31163;&#12290;&#36890;&#36807;&#29305;&#27530;&#21270;&#32467;&#26524;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#24191;&#20041;&#38543;&#26426;&#31070;&#32463;&#32593;&#32476;&#20013;&#23545;&#39640;&#26031;&#38543;&#26426;&#22330;&#36924;&#36817;&#30340;&#39318;&#20010;&#19978;&#30028;&#12290;</title><link>http://arxiv.org/abs/2306.16308</link><description>&lt;p&gt;
&#36890;&#36807;Stein&#26041;&#27861;&#23545;&#39640;&#26031;&#38543;&#26426;&#22330;&#36827;&#34892;&#36924;&#36817;&#21450;&#20854;&#22312;&#24191;&#20041;&#38543;&#26426;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Gaussian random field approximation via Stein's method with applications to wide random neural networks. (arXiv:2306.16308v1 [math.PR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16308
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;Stein&#26041;&#27861;&#25512;&#23548;&#20986;Wasserstein&#36317;&#31163;&#30340;&#19978;&#30028;&#65292;&#36890;&#36807;&#39640;&#26031;&#24179;&#28369;&#25216;&#26415;&#23558;&#24179;&#28369;&#24230;&#37327;&#36716;&#21270;&#20026;Wasserstein&#36317;&#31163;&#12290;&#36890;&#36807;&#29305;&#27530;&#21270;&#32467;&#26524;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#24191;&#20041;&#38543;&#26426;&#31070;&#32463;&#32593;&#32476;&#20013;&#23545;&#39640;&#26031;&#38543;&#26426;&#22330;&#36924;&#36817;&#30340;&#39318;&#20010;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#21033;&#29992;Stein&#26041;&#27861;&#25512;&#23548;&#20986;&#20102;&#22522;&#20110;Wasserstein&#36317;&#31163;&#65288;$W_1$&#65289;&#30340;&#19978;&#30028;&#65292;&#35813;&#36317;&#31163;&#26159;&#36830;&#32493;&#38543;&#26426;&#22330;&#19982;&#39640;&#26031;&#20998;&#24067;&#20043;&#38388;&#30340;&#36317;&#31163;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#39640;&#26031;&#24179;&#28369;&#25216;&#26415;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#23558;&#24179;&#28369;&#24230;&#37327;&#20013;&#30340;&#19978;&#30028;&#36716;&#21270;&#20026;$W_1$&#36317;&#31163;&#12290;&#24179;&#28369;&#24615;&#26159;&#22522;&#20110;&#20351;&#29992;Laplacian&#31639;&#23376;&#30340;&#24130;&#26500;&#24314;&#30340;&#21327;&#26041;&#24046;&#20989;&#25968;&#65292;&#35774;&#35745;&#25104;&#19982;Cameron-Martin&#25110;Reproducing Kernel Hilbert Space&#30456;&#20851;&#32852;&#30340;&#39640;&#26031;&#36807;&#31243;&#20855;&#26377;&#26131;&#25805;&#20316;&#30340;&#29305;&#24449;&#12290;&#36825;&#20010;&#29305;&#24449;&#20351;&#25105;&#20204;&#33021;&#22815;&#36229;&#36234;&#20043;&#21069;&#25991;&#29486;&#20013;&#32771;&#34385;&#30340;&#19968;&#32500;&#21306;&#38388;&#22411;&#25351;&#26631;&#38598;&#12290;&#36890;&#36807;&#29305;&#21270;&#25105;&#20204;&#30340;&#19968;&#33324;&#32467;&#26524;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#22312;&#20219;&#24847;&#28145;&#24230;&#21644;Lipschitz&#28608;&#27963;&#20989;&#25968;&#30340;&#24191;&#20041;&#38543;&#26426;&#31070;&#32463;&#32593;&#32476;&#20013;&#23545;&#39640;&#26031;&#38543;&#26426;&#22330;&#36924;&#36817;&#30340;&#39318;&#20010;&#19978;&#30028;&#12290;&#25105;&#20204;&#30340;&#19978;&#30028;&#26126;&#30830;&#22320;&#29992;&#32593;&#32476;&#23485;&#24230;&#21644;&#38543;&#26426;&#26435;&#37325;&#30340;&#30697;&#26469;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
We derive upper bounds on the Wasserstein distance ($W_1$), with respect to $\sup$-norm, between any continuous $\mathbb{R}^d$ valued random field indexed by the $n$-sphere and the Gaussian, based on Stein's method. We develop a novel Gaussian smoothing technique that allows us to transfer a bound in a smoother metric to the $W_1$ distance. The smoothing is based on covariance functions constructed using powers of Laplacian operators, designed so that the associated Gaussian process has a tractable Cameron-Martin or Reproducing Kernel Hilbert Space. This feature enables us to move beyond one dimensional interval-based index sets that were previously considered in the literature. Specializing our general result, we obtain the first bounds on the Gaussian random field approximation of wide random neural networks of any depth and Lipschitz activation functions at the random field level. Our bounds are explicitly expressed in terms of the widths of the network and moments of the random wei
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#23558;&#22810;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#36716;&#21270;&#20026;&#19968;&#32452;&#21333;&#30446;&#26631;&#38382;&#39064;&#36827;&#34892;&#35299;&#20915;&#65292;&#24182;&#20171;&#32461;&#20102;R2&#25928;&#29992;&#20989;&#25968;&#20316;&#20026;&#36866;&#24403;&#30340;&#30446;&#26631;&#20989;&#25968;&#12290;&#35813;&#25928;&#29992;&#20989;&#25968;&#21333;&#35843;&#19988;&#27425;&#27169;&#65292;&#21487;&#20197;&#20351;&#29992;&#36138;&#24515;&#20248;&#21270;&#31639;&#27861;&#35745;&#31639;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;</title><link>http://arxiv.org/abs/2305.11774</link><description>&lt;p&gt;
&#20351;&#29992;R2&#25928;&#29992;&#30340;&#22810;&#30446;&#26631;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Multi-Objective Optimization Using the R2 Utility. (arXiv:2305.11774v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11774
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#23558;&#22810;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#36716;&#21270;&#20026;&#19968;&#32452;&#21333;&#30446;&#26631;&#38382;&#39064;&#36827;&#34892;&#35299;&#20915;&#65292;&#24182;&#20171;&#32461;&#20102;R2&#25928;&#29992;&#20989;&#25968;&#20316;&#20026;&#36866;&#24403;&#30340;&#30446;&#26631;&#20989;&#25968;&#12290;&#35813;&#25928;&#29992;&#20989;&#25968;&#21333;&#35843;&#19988;&#27425;&#27169;&#65292;&#21487;&#20197;&#20351;&#29992;&#36138;&#24515;&#20248;&#21270;&#31639;&#27861;&#35745;&#31639;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#30446;&#26631;&#20248;&#21270;&#30340;&#30446;&#26631;&#26159;&#30830;&#23450;&#25551;&#36848;&#22810;&#30446;&#26631;&#20043;&#38388;&#26368;&#20339;&#26435;&#34913;&#30340;&#28857;&#38598;&#21512;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#30690;&#37327;&#20540;&#20248;&#21270;&#38382;&#39064;&#65292;&#20174;&#19994;&#32773;&#24120;&#24120;&#20351;&#29992;&#26631;&#37327;&#21270;&#20989;&#25968;&#23558;&#22810;&#30446;&#26631;&#38382;&#39064;&#36716;&#21270;&#20026;&#19968;&#32452;&#21333;&#30446;&#26631;&#38382;&#39064;&#12290;&#36825;&#32452;&#26631;&#37327;&#21270;&#38382;&#39064;&#21487;&#20197;&#20351;&#29992;&#20256;&#32479;&#30340;&#21333;&#30446;&#26631;&#20248;&#21270;&#25216;&#26415;&#26469;&#35299;&#20915;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23558;&#36825;&#20010;&#32422;&#23450;&#24418;&#24335;&#21270;&#20026;&#19968;&#20010;&#36890;&#29992;&#30340;&#25968;&#23398;&#26694;&#26550;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#31574;&#30053;&#22914;&#20309;&#26377;&#25928;&#22320;&#23558;&#21407;&#22987;&#30340;&#22810;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#37325;&#26032;&#36716;&#21270;&#20026;&#23450;&#20041;&#22312;&#38598;&#21512;&#19978;&#30340;&#21333;&#30446;&#26631;&#20248;&#21270;&#38382;&#39064;&#12290;&#38024;&#23545;&#36825;&#20010;&#26032;&#38382;&#39064;&#30340;&#36866;&#24403;&#31867;&#21035;&#30340;&#30446;&#26631;&#20989;&#25968;&#26159;R2&#25928;&#29992;&#20989;&#25968;&#65292;&#23427;&#34987;&#23450;&#20041;&#20026;&#26631;&#37327;&#21270;&#20248;&#21270;&#38382;&#39064;&#30340;&#21152;&#26435;&#31215;&#20998;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20010;&#25928;&#29992;&#20989;&#25968;&#26159;&#21333;&#35843;&#30340;&#21644;&#27425;&#27169;&#30340;&#38598;&#21512;&#20989;&#25968;&#65292;&#21487;&#20197;&#36890;&#36807;&#36138;&#24515;&#20248;&#21270;&#31639;&#27861;&#26377;&#25928;&#22320;&#35745;&#31639;&#20986;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
The goal of multi-objective optimization is to identify a collection of points which describe the best possible trade-offs between the multiple objectives. In order to solve this vector-valued optimization problem, practitioners often appeal to the use of scalarization functions in order to transform the multi-objective problem into a collection of single-objective problems. This set of scalarized problems can then be solved using traditional single-objective optimization techniques. In this work, we formalise this convention into a general mathematical framework. We show how this strategy effectively recasts the original multi-objective optimization problem into a single-objective optimization problem defined over sets. An appropriate class of objective functions for this new problem is the R2 utility function, which is defined as a weighted integral over the scalarized optimization problems. We show that this utility function is a monotone and submodular set function, which can be op
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#38750;&#32447;&#24615;&#31995;&#32479;&#21160;&#24577;&#30340;&#21453;&#21521;&#26080;&#21619;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;I-UKF&#65289;&#20197;&#21450;&#22522;&#20110;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#30340;UKF&#65288;RKHS-UKF&#65289;&#65292;&#29992;&#20110;&#23398;&#20064;&#26410;&#30693;&#30340;&#31995;&#32479;&#27169;&#22411;&#24182;&#20272;&#35745;&#29366;&#24577;&#12290;</title><link>http://arxiv.org/abs/2304.01698</link><description>&lt;p&gt;
&#21453;&#21521;&#26080;&#21619;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;
&lt;/p&gt;
&lt;p&gt;
Inverse Unscented Kalman Filter. (arXiv:2304.01698v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01698
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#38750;&#32447;&#24615;&#31995;&#32479;&#21160;&#24577;&#30340;&#21453;&#21521;&#26080;&#21619;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;I-UKF&#65289;&#20197;&#21450;&#22522;&#20110;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#30340;UKF&#65288;RKHS-UKF&#65289;&#65292;&#29992;&#20110;&#23398;&#20064;&#26410;&#30693;&#30340;&#31995;&#32479;&#27169;&#22411;&#24182;&#20272;&#35745;&#29366;&#24577;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35774;&#35745;&#35748;&#30693;&#21644;&#21453;&#23545;&#25163;&#31995;&#32479;&#30340;&#24555;&#36895;&#36827;&#27493;&#20419;&#36827;&#20102;&#21453;&#36125;&#21494;&#26031;&#28388;&#27874;&#22120;&#30340;&#21457;&#23637;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#35748;&#30693;&#8220;&#23545;&#25163;&#8221;&#36890;&#36807;&#38543;&#26426;&#26694;&#26550;&#65288;&#22914;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;KF&#65289;&#65289;&#36319;&#36394;&#20854;&#24863;&#20852;&#36259;&#30340;&#30446;&#26631;&#12290;&#28982;&#21518;&#65292;&#30446;&#26631;&#25110;&#8220;&#38450;&#24481;&#32773;&#8221;&#20351;&#29992;&#21478;&#19968;&#20010;&#36870;&#38543;&#26426;&#28388;&#27874;&#22120;&#26469;&#25512;&#26029;&#36890;&#36807;&#23545;&#25163;&#35745;&#31639;&#30340;&#38450;&#24481;&#32773;&#30340;&#21069;&#21521;&#28388;&#27874;&#22120;&#20272;&#35745;&#12290;&#23545;&#20110;&#32447;&#24615;&#31995;&#32479;&#65292;&#26368;&#36817;&#24050;&#32463;&#35777;&#26126;&#20102;&#36870;Kalman&#28388;&#27874;&#22120;&#65288;I-KF&#65289;&#22312;&#36825;&#20123;&#21453;&#23545;&#25239;&#24212;&#29992;&#20013;&#26159;&#26377;&#25928;&#30340;&#12290;&#26412;&#25991;&#19982;&#20043;&#21069;&#30340;&#24037;&#20316;&#30456;&#21453;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#38750;&#32447;&#24615;&#31995;&#32479;&#21160;&#24577;&#24182;&#21046;&#23450;&#36870;&#38750;&#32447;&#24615;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#65288;I-UKF&#65289;&#65292;&#20197;&#20272;&#35745;&#38450;&#24481;&#32773;&#30340;&#29366;&#24577;&#24182;&#20943;&#23567;&#32447;&#24615;&#21270;&#35823;&#24046;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#36825;&#19968;&#26694;&#26550;&#25512;&#24191;&#21040;&#26410;&#30693;&#31995;&#32479;&#27169;&#22411;&#65292;&#36890;&#36807;&#25552;&#20986;&#22522;&#20110;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#30340;UKF&#65288;RKHS-UKF&#65289;&#26469;&#23398;&#20064;&#31995;&#32479;&#21160;&#24577;&#24182;&#22522;&#20110;&#20854;&#35266;&#27979;&#26469;&#20272;&#35745;&#29366;&#24577;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#26088;&#22312;&#20445;&#35777;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#38543;&#26426;&#31283;&#23450;&#24615;&#65292;&#24182;&#36827;&#34892;&#25968;&#20540;&#27169;&#25311;&#20197;&#35777;&#23454;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Rapid advances in designing cognitive and counter-adversarial systems have motivated the development of inverse Bayesian filters. In this setting, a cognitive `adversary' tracks its target of interest via a stochastic framework such as a Kalman filter (KF). The target or `defender' then employs another inverse stochastic filter to infer the forward filter estimates of the defender computed by the adversary. For linear systems, inverse Kalman filter (I-KF) has been recently shown to be effective in these counter-adversarial applications. In the paper, contrary to prior works, we focus on non-linear system dynamics and formulate the inverse unscented KF (I-UKF) to estimate the defender's state with reduced linearization errors. We then generalize this framework to an unknown system model by proposing reproducing kernel Hilbert space-based UKF (RKHS-UKF) to learn the system dynamics and estimate the state based on its observations. Our theoretical analyses to guarantee the stochastic stab
&lt;/p&gt;</description></item></channel></rss>