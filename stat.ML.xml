<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#12289;&#28789;&#27963;&#30340;&#20998;&#26512;&#26694;&#26550;&#65292;&#29992;&#20110;&#35777;&#26126;&#22312;&#20219;&#24847;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#29305;&#24449;&#30340;SVP&#26465;&#20214;</title><link>http://arxiv.org/abs/2305.02304</link><description>&lt;p&gt;
&#25581;&#31034;&#25554;&#20540;&#21644;&#25903;&#25345;&#21521;&#37327;&#26426;&#20043;&#38388;&#30340;&#26032;&#31561;&#20215;&#24615;&#65306;&#26680;&#20989;&#25968;&#21644;&#32467;&#26500;&#21270;&#29305;&#24449;
&lt;/p&gt;
&lt;p&gt;
New Equivalences Between Interpolation and SVMs: Kernels and Structured Features. (arXiv:2305.02304v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02304
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#12289;&#28789;&#27963;&#30340;&#20998;&#26512;&#26694;&#26550;&#65292;&#29992;&#20110;&#35777;&#26126;&#22312;&#20219;&#24847;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#29305;&#24449;&#30340;SVP&#26465;&#20214;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25903;&#25345;&#21521;&#37327;&#26426;&#65288;SVM&#65289;&#26159;&#19968;&#31181;&#30417;&#30563;&#23398;&#20064;&#31639;&#27861;&#65292;&#23427;&#36890;&#36807;&#26680;&#25216;&#24039;&#23558;&#25968;&#25454;&#26144;&#23556;&#21040;&#39640;&#32500;&#29305;&#24449;&#31354;&#38388;&#65292;&#25214;&#21040;&#26368;&#22823;&#38388;&#38548;&#32447;&#24615;&#20998;&#31867;&#22120;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#26576;&#20123;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#24773;&#20917;&#19979;&#65292;SVM&#30340;&#20915;&#31574;&#20989;&#25968;&#19982;&#26368;&#23567;&#33539;&#25968;&#26631;&#31614;&#25554;&#20540;&#23436;&#20840;&#37325;&#21512;&#12290;&#36825;&#31181;&#25903;&#25345;&#21521;&#37327;&#22686;&#27542;&#65288;SVP&#65289;&#29616;&#35937;&#29305;&#21035;&#26377;&#36259;&#65292;&#22240;&#20026;&#23427;&#20351;&#25105;&#20204;&#33021;&#22815;&#36890;&#36807;&#21033;&#29992;&#32447;&#24615;&#21644;&#26680;&#27169;&#22411;&#20013;&#26080;&#23475;&#25554;&#20540;&#30340;&#26368;&#36817;&#20998;&#26512;&#26469;&#29702;&#35299;SVM&#30340;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#20808;&#21069;&#20851;&#20110;SVP&#30340;&#24037;&#20316;&#23545;&#25968;&#25454;/&#29305;&#24449;&#20998;&#24067;&#21644;&#39057;&#35889;&#20570;&#20986;&#20102;&#38480;&#21046;&#24615;&#20551;&#35774;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#12289;&#28789;&#27963;&#30340;&#20998;&#26512;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#20219;&#24847;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#65292;&#23545;&#26631;&#31614;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#19968;&#31867;&#28789;&#27963;&#24615;&#29305;&#24449;&#36827;&#34892;SVP&#35777;&#26126;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#23616;&#38480;&#20110;&#19968;&#33324;&#26377;&#30028;&#27491;&#20132;&#31995;&#32479;&#26063;&#65288;&#20363;&#22914;Fourier&#20989;&#25968;&#26063;&#65289;&#29305;&#24449;&#30340;SVP&#26465;&#20214;
&lt;/p&gt;
&lt;p&gt;
The support vector machine (SVM) is a supervised learning algorithm that finds a maximum-margin linear classifier, often after mapping the data to a high-dimensional feature space via the kernel trick. Recent work has demonstrated that in certain sufficiently overparameterized settings, the SVM decision function coincides exactly with the minimum-norm label interpolant. This phenomenon of support vector proliferation (SVP) is especially interesting because it allows us to understand SVM performance by leveraging recent analyses of harmless interpolation in linear and kernel models. However, previous work on SVP has made restrictive assumptions on the data/feature distribution and spectrum. In this paper, we present a new and flexible analysis framework for proving SVP in an arbitrary reproducing kernel Hilbert space with a flexible class of generative models for the labels. We present conditions for SVP for features in the families of general bounded orthonormal systems (e.g. Fourier f
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#23545;&#20110;&#25968;&#25454;&#29420;&#31435;&#30340;&#25209;&#22788;&#29702;&#26041;&#26696;&#65292;&#20960;&#20046;&#25152;&#26377;&#23567;&#25209;&#37327;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#37117;&#33021;&#22815;&#20248;&#21270;&#65292;&#20854;&#20013;&#21253;&#25324;&#25152;&#26377;&#30340;&#30830;&#23450;&#24615;&#26041;&#26696;&#21644;&#38543;&#26426;&#26041;&#26696;&#12290;&#27492;&#22806;&#65292;&#25152;&#26377;&#36825;&#26679;&#30340;&#25209;&#37327;&#35843;&#24230;&#37117;&#33021;&#36798;&#21040;&#26368;&#20248;&#30340;&#19968;&#33324;&#21270;&#35823;&#24046;&#19979;&#38480;&#12290;</title><link>http://arxiv.org/abs/2305.02247</link><description>&lt;p&gt;
&#27627;&#19981;&#30031;&#24807;&#22320;&#36873;&#25321;&#65306;&#20960;&#20046;&#25152;&#26377;&#30340;&#23567;&#25209;&#37327;&#35757;&#32451;&#26041;&#26696;&#37117;&#33021;&#22815;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Select without Fear: Almost All Mini-Batch Schedules Generalize Optimally. (arXiv:2305.02247v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02247
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#23545;&#20110;&#25968;&#25454;&#29420;&#31435;&#30340;&#25209;&#22788;&#29702;&#26041;&#26696;&#65292;&#20960;&#20046;&#25152;&#26377;&#23567;&#25209;&#37327;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#37117;&#33021;&#22815;&#20248;&#21270;&#65292;&#20854;&#20013;&#21253;&#25324;&#25152;&#26377;&#30340;&#30830;&#23450;&#24615;&#26041;&#26696;&#21644;&#38543;&#26426;&#26041;&#26696;&#12290;&#27492;&#22806;&#65292;&#25152;&#26377;&#36825;&#26679;&#30340;&#25209;&#37327;&#35843;&#24230;&#37117;&#33021;&#36798;&#21040;&#26368;&#20248;&#30340;&#19968;&#33324;&#21270;&#35823;&#24046;&#19979;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35777;&#26126;&#20102;&#24102;&#26377;&#30830;&#23450;&#24615;&#25110;&#38543;&#26426;&#24615;&#12289;&#25968;&#25454;&#29420;&#31435;&#30340;&#23567;&#25209;&#37327;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#21305;&#37197;&#19978;&#19979;&#19968;&#33324;&#21270;&#35823;&#24046;&#30028;&#38480;&#65292;&#20294;&#25209;&#37327;&#36873;&#25321;&#35268;&#21017;&#26159;&#20219;&#24847;&#30340;&#12290;&#25105;&#20204;&#32771;&#34385;&#20809;&#28369;&#30340;Lipschitz-&#20984;&#24615;/&#38750;&#20984;&#24615;/&#24378;&#20984;&#24615;&#25439;&#22833;&#20989;&#25968;&#65292;&#24182;&#35777;&#26126;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#32463;&#20856;&#19978;&#38480;&#30028;&#38480;&#20063;&#36866;&#29992;&#20110;&#36825;&#26679;&#20219;&#24847;&#30340;&#38750;&#33258;&#36866;&#24212;&#25209;&#37327;&#35843;&#24230;&#65292;&#21253;&#25324;&#25152;&#26377;&#30830;&#23450;&#24615;&#30340;&#35843;&#24230;&#26041;&#26696;&#12290;&#36827;&#19968;&#27493;&#22320;&#65292;&#23545;&#20110;&#20984;&#21644;&#24378;&#20984;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#25105;&#20204;&#30452;&#25509;&#35777;&#26126;&#20102;&#22312;&#19978;&#36848;&#25209;&#37327;&#35843;&#24230;&#31867;&#19978;&#19968;&#33268;&#30340;&#19968;&#33324;&#21270;&#35823;&#24046;&#19979;&#30340;&#21305;&#37197;&#19979;&#38480;&#30028;&#38480;&#65292;&#34920;&#26126;&#25152;&#26377;&#36825;&#26679;&#30340;&#25209;&#37327;&#35843;&#24230;&#37117;&#33021;&#36798;&#21040;&#26368;&#20248;&#30340;&#19968;&#33324;&#21270;&#12290;&#26368;&#21518;&#65292;&#23545;&#20110;&#20809;&#28369;&#30340;&#65288;&#38750;Lipschitz&#65289;&#38750;&#20984;&#24615;&#25439;&#22833;&#20989;&#25968;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#25152;&#32771;&#34385;&#30340;&#31867;&#21035;&#20869;&#65292;&#21253;&#25324;&#25152;&#26377;&#38543;&#26426;&#25209;&#22788;&#29702;&#26041;&#26696;&#65292;&#20840;&#25209;&#37327;&#65288;&#30830;&#23450;&#24615;&#65289;&#26799;&#24230;&#19979;&#38477;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We establish matching upper and lower generalization error bounds for mini-batch Gradient Descent (GD) training with either deterministic or stochastic, data-independent, but otherwise arbitrary batch selection rules. We consider smooth Lipschitz-convex/nonconvex/strongly-convex loss functions, and show that classical upper bounds for Stochastic GD (SGD) also hold verbatim for such arbitrary nonadaptive batch schedules, including all deterministic ones. Further, for convex and strongly-convex losses we prove matching lower bounds directly on the generalization error uniform over the aforementioned class of batch schedules, showing that all such batch schedules generalize optimally. Lastly, for smooth (non-Lipschitz) nonconvex losses, we show that full-batch (deterministic) GD is essentially optimal, among all possible batch schedules within the considered class, including all stochastic ones.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#22810;&#20010;&#32467;&#26500;&#39044;&#27979;&#26631;&#20934;&#27979;&#35797;&#20013;&#31934;&#30830;&#35782;&#21035;&#21547;&#26377;100&#20010;&#20197;&#19978;&#21407;&#23376;&#30340;&#35768;&#22810;&#26448;&#26009;&#30340;&#20840;&#23616;&#26368;&#23567;&#32467;&#26500;&#65292;&#24182;&#20197;&#21333;&#27425;&#33021;&#37327;&#35780;&#20272;&#20026;&#22522;&#30784;&#65292;&#21462;&#20195;&#20102;&#37325;&#22797;&#30340;&#31532;&#19968;&#21407;&#29702;&#33021;&#37327;&#35745;&#31639;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2305.02158</link><description>&lt;p&gt;
&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#30340;&#24418;&#25104;&#33021;&#37327;&#39044;&#27979;&#26041;&#27861;&#36827;&#34892;&#29454;&#26538;&#26230;&#20307;&#32467;&#26500;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Shotgun crystal structure prediction using machine-learned formation energies. (arXiv:2305.02158v1 [physics.comp-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02158
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#22810;&#20010;&#32467;&#26500;&#39044;&#27979;&#26631;&#20934;&#27979;&#35797;&#20013;&#31934;&#30830;&#35782;&#21035;&#21547;&#26377;100&#20010;&#20197;&#19978;&#21407;&#23376;&#30340;&#35768;&#22810;&#26448;&#26009;&#30340;&#20840;&#23616;&#26368;&#23567;&#32467;&#26500;&#65292;&#24182;&#20197;&#21333;&#27425;&#33021;&#37327;&#35780;&#20272;&#20026;&#22522;&#30784;&#65292;&#21462;&#20195;&#20102;&#37325;&#22797;&#30340;&#31532;&#19968;&#21407;&#29702;&#33021;&#37327;&#35745;&#31639;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#20197;&#36890;&#36807;&#25214;&#21040;&#21407;&#23376;&#26500;&#22411;&#33021;&#37327;&#26354;&#38754;&#30340;&#20840;&#23616;&#25110;&#23616;&#37096;&#26497;&#23567;&#20540;&#26469;&#39044;&#27979;&#32452;&#35013;&#21407;&#23376;&#30340;&#31283;&#23450;&#25110;&#20122;&#31283;&#23450;&#26230;&#20307;&#32467;&#26500;&#12290;&#36890;&#24120;&#65292;&#36825;&#38656;&#35201;&#37325;&#22797;&#30340;&#31532;&#19968;&#21407;&#29702;&#33021;&#37327;&#35745;&#31639;&#65292;&#36825;&#22312;&#21253;&#21547;30&#20010;&#20197;&#19978;&#21407;&#23376;&#30340;&#22823;&#22411;&#31995;&#32479;&#20013;&#26159;&#19981;&#23454;&#38469;&#30340;&#12290;&#26412;&#30740;&#31350;&#20351;&#29992;&#31616;&#21333;&#20294;&#21151;&#33021;&#24378;&#22823;&#30340;&#26426;&#22120;&#23398;&#20064;&#24037;&#20316;&#27969;&#65292;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#36741;&#21161;&#31532;&#19968;&#21407;&#29702;&#33021;&#37327;&#35745;&#31639;&#65292;&#23545;&#22823;&#37327;&#34394;&#25311;&#21019;&#24314;&#30340;&#26230;&#20307;&#32467;&#26500;&#36827;&#34892;&#38750;&#36845;&#20195;&#24335;&#21333;&#27425;&#31579;&#36873;&#65292;&#20174;&#32780;&#22312;&#35299;&#20915;&#26230;&#20307;&#32467;&#26500;&#39044;&#27979;&#38382;&#39064;&#26041;&#38754;&#21462;&#24471;&#20102;&#37325;&#22823;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stable or metastable crystal structures of assembled atoms can be predicted by finding the global or local minima of the energy surface with respect to the atomic configurations. Generally, this requires repeated first-principles energy calculations that are impractical for large systems, such as those containing more than 30 atoms in the unit cell. Here, we have made significant progress in solving the crystal structure prediction problem with a simple but powerful machine-learning workflow; using a machine-learning surrogate for first-principles energy calculations, we performed non-iterative, single-shot screening using a large library of virtually created crystal structures. The present method relies on two key technical components: transfer learning, which enables a highly accurate energy prediction of pre-relaxed crystalline states given only a small set of training samples from first-principles calculations, and generative models to create promising and diverse crystal structure
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#40654;&#26364;&#23376;&#31354;&#38388;&#19979;&#38477;&#31639;&#27861;&#30340;&#23545;&#31216;&#27491;&#23450;&#27969;&#24418;&#19978;&#30340;&#20989;&#25968;&#26368;&#23567;&#21270;&#26041;&#27861;&#65292;&#20854;&#20855;&#26377;&#20302;&#22797;&#26434;&#24230;&#21644;&#36991;&#20813;&#26114;&#36149;&#30697;&#38453;&#25805;&#20316;&#21644;&#35745;&#31639;&#40654;&#26364;&#26799;&#24230;&#30340;&#20248;&#28857;&#12290;</title><link>http://arxiv.org/abs/2305.02041</link><description>&lt;p&gt;
&#23545;&#31216;&#27491;&#23450;&#27969;&#24418;&#19978;&#20302;&#22797;&#26434;&#24230;&#30340;&#23376;&#31354;&#38388;&#19979;&#38477;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Low-complexity subspace-descent over symmetric positive definite manifold. (arXiv:2305.02041v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02041
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#40654;&#26364;&#23376;&#31354;&#38388;&#19979;&#38477;&#31639;&#27861;&#30340;&#23545;&#31216;&#27491;&#23450;&#27969;&#24418;&#19978;&#30340;&#20989;&#25968;&#26368;&#23567;&#21270;&#26041;&#27861;&#65292;&#20854;&#20855;&#26377;&#20302;&#22797;&#26434;&#24230;&#21644;&#36991;&#20813;&#26114;&#36149;&#30697;&#38453;&#25805;&#20316;&#21644;&#35745;&#31639;&#40654;&#26364;&#26799;&#24230;&#30340;&#20248;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20302;&#22797;&#26434;&#24230;&#30340;&#40654;&#26364;&#23376;&#31354;&#38388;&#19979;&#38477;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#23545;&#31216;&#27491;&#23450;&#65288;SPD&#65289;&#27969;&#24418;&#19978;&#23545;&#20989;&#25968;&#36827;&#34892;&#26368;&#23567;&#21270;&#12290;&#19982;&#29616;&#26377;&#30340;&#40654;&#26364;&#26799;&#24230;&#19979;&#38477;&#21464;&#20307;&#19981;&#21516;&#30340;&#26159;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21033;&#29992; carefully chosen &#30340;&#23376;&#31354;&#38388;&#65292;&#20351;&#24471;&#26356;&#26032;&#21487;&#20197;&#20889;&#25104;&#36845;&#20195;&#30340; Cholesky &#22240;&#23376;&#21644;&#19968;&#20010;&#31232;&#30095;&#30697;&#38453;&#30340;&#20056;&#31215;&#24418;&#24335;&#12290;&#30001;&#27492;&#20135;&#29983;&#30340;&#26356;&#26032;&#36991;&#20813;&#20102;&#26114;&#36149;&#30340;&#30697;&#38453;&#25805;&#20316;&#65292;&#22914;&#30697;&#38453;&#25351;&#25968;&#21644;&#23494;&#38598;&#30697;&#38453;&#20056;&#27861;&#65292;&#36825;&#20123;&#25805;&#20316;&#36890;&#24120;&#22312;&#20960;&#20046;&#25152;&#26377;&#20854;&#20182; Riemannian &#20248;&#21270;&#31639;&#27861;&#20013;&#37117;&#26159;&#24517;&#38656;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work puts forth low-complexity Riemannian subspace descent algorithms for the minimization of functions over the symmetric positive definite (SPD) manifold. Different from the existing Riemannian gradient descent variants, the proposed approach utilizes carefully chosen subspaces that allow the update to be written as a product of the Cholesky factor of the iterate and a sparse matrix. The resulting updates avoid the costly matrix operations like matrix exponentiation and dense matrix multiplication, which are generally required in almost all other Riemannian optimization algorithms on SPD manifold. We further identify a broad class of functions, arising in diverse applications, such as kernel matrix learning, covariance estimation of Gaussian distributions, maximum likelihood parameter estimation of elliptically contoured distributions, and parameter estimation in Gaussian mixture model problems, over which the Riemannian gradients can be calculated efficiently. The proposed uni-
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35780;&#35770;&#23545;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#26041;&#27861; SHAP &#21644; LIME &#36827;&#34892;&#20102;&#35780;&#36848;&#21644;&#27604;&#36739;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#19988;&#31361;&#20986;&#20102;&#23427;&#20204;&#30340;&#20248;&#32570;&#28857;&#12290;</title><link>http://arxiv.org/abs/2305.02012</link><description>&lt;p&gt;
&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#26041;&#27861;&#35780;&#36848;&#65306;SHAP &#21644; LIME
&lt;/p&gt;
&lt;p&gt;
Commentary on explainable artificial intelligence methods: SHAP and LIME. (arXiv:2305.02012v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02012
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35780;&#35770;&#23545;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#26041;&#27861; SHAP &#21644; LIME &#36827;&#34892;&#20102;&#35780;&#36848;&#21644;&#27604;&#36739;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#19988;&#31361;&#20986;&#20102;&#23427;&#20204;&#30340;&#20248;&#32570;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#26041;&#27861;&#24050;&#32463;&#21457;&#23637;&#20986;&#26469;&#65292;&#23558;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#40657;&#21283;&#23376;&#36716;&#21270;&#20026;&#26356;&#26131;&#29702;&#35299;&#30340;&#24418;&#24335;&#12290;&#36825;&#20123;&#26041;&#27861;&#26377;&#21161;&#20110;&#20256;&#36798;&#27169;&#22411;&#30340;&#24037;&#20316;&#21407;&#29702;&#65292;&#26088;&#22312;&#20351;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26356;&#36879;&#26126;&#65292;&#24182;&#22686;&#21152;&#26368;&#32456;&#29992;&#25143;&#23545;&#20854;&#36755;&#20986;&#30340;&#20449;&#20219;&#12290; SHapley Additive exPlanations&#65288;SHAP&#65289;&#21644;Local Interpretable Model Agnostic Explanation&#65288;LIME&#65289;&#26159;&#20004;&#31181;&#22312;&#34920;&#26684;&#25968;&#25454;&#20013;&#24191;&#27867;&#20351;&#29992;&#30340;XAI&#26041;&#27861;&#12290;&#22312;&#36825;&#31687;&#35780;&#35770;&#20013;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#20004;&#31181;&#26041;&#27861;&#30340;&#21487;&#35299;&#37322;&#24615;&#24230;&#37327;&#26159;&#22914;&#20309;&#29983;&#25104;&#30340;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#35299;&#37322;&#23427;&#20204;&#36755;&#20986;&#30340;&#26694;&#26550;&#65292;&#31361;&#20986;&#20102;&#23427;&#20204;&#30340;&#20248;&#32570;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
eXplainable artificial intelligence (XAI) methods have emerged to convert the black box of machine learning models into a more digestible form. These methods help to communicate how the model works with the aim of making machine learning models more transparent and increasing the trust of end-users into their output. SHapley Additive exPlanations (SHAP) and Local Interpretable Model Agnostic Explanation (LIME) are two widely used XAI methods particularly with tabular data. In this commentary piece, we discuss the way the explainability metrics of these two methods are generated and propose a framework for interpretation of their outputs, highlighting their weaknesses and strengths.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#22522;&#20110;&#32479;&#35745;&#26041;&#27861;&#30340;&#20844;&#24179;&#26426;&#22120;&#23398;&#20064;&#24314;&#27169;&#21253;fairml&#65292;&#35813;&#21253;&#23454;&#29616;&#20102;&#20998;&#31867;&#12289;&#22238;&#24402;&#21644;&#26680;&#20272;&#35745;&#31561;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#20445;&#38556;&#20844;&#24179;&#21644;&#38382;&#36131;&#26041;&#38754;&#25552;&#20379;&#24110;&#21161;&#12290;</title><link>http://arxiv.org/abs/2305.02009</link><description>&lt;p&gt;
&#20844;&#24179;&#26426;&#22120;&#23398;&#20064;&#24314;&#27169;&#30340;&#32479;&#35745;&#23398;&#35266;&#28857;
&lt;/p&gt;
&lt;p&gt;
fairml: A Statistician's Take on Fair Machine Learning Modelling. (arXiv:2305.02009v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02009
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#20010;&#22522;&#20110;&#32479;&#35745;&#26041;&#27861;&#30340;&#20844;&#24179;&#26426;&#22120;&#23398;&#20064;&#24314;&#27169;&#21253;fairml&#65292;&#35813;&#21253;&#23454;&#29616;&#20102;&#20998;&#31867;&#12289;&#22238;&#24402;&#21644;&#26680;&#20272;&#35745;&#31561;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#20445;&#38556;&#20844;&#24179;&#21644;&#38382;&#36131;&#26041;&#38754;&#25552;&#20379;&#24110;&#21161;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#22312;&#20851;&#38190;&#20445;&#38556;&#20844;&#24179;&#21644;&#38382;&#36131;&#30340;&#24212;&#29992;&#20013;&#30340;&#37319;&#29992;&#65292;&#23548;&#33268;&#25991;&#29486;&#20013;&#20986;&#29616;&#20102;&#22823;&#37327;&#27169;&#22411;&#24314;&#35758;&#65292;&#20027;&#35201;&#20197;&#32422;&#26463;&#26465;&#20214;&#30340;&#20248;&#21270;&#38382;&#39064;&#24418;&#24335;&#20943;&#23569;&#25110;&#28040;&#38500;&#25935;&#24863;&#23646;&#24615;&#23545;&#21709;&#24212;&#30340;&#24433;&#21709;&#12290;&#34429;&#28982;&#36825;&#31181;&#26041;&#27861;&#20174;&#29702;&#35770;&#19978;&#26469;&#30475;&#38750;&#24120;&#28789;&#27963;&#65292;&#20294;&#25152;&#24471;&#30340;&#27169;&#22411;&#26377;&#20123;&#40657;&#30418;&#24615;&#36136;&#65306;&#24456;&#23569;&#26377;&#20851;&#20110;&#20854;&#32479;&#35745;&#23646;&#24615;&#30340;&#34920;&#36848;&#65292;&#20851;&#20110;&#20854;&#24212;&#29992;&#26368;&#20339;&#23454;&#36341;&#30340;&#35752;&#35770;&#65292;&#20197;&#21450;&#22914;&#20309;&#23558;&#20854;&#25193;&#23637;&#21040;&#20854;&#20182;&#38382;&#39064;&#32780;&#19981;&#26159;&#20854;&#26368;&#21021;&#35774;&#35745;&#29992;&#36884;&#30340;&#30740;&#31350;&#12290;&#27492;&#22806;&#65292;&#20272;&#35745;&#27599;&#20010;&#27169;&#22411;&#38656;&#35201;&#29305;&#23450;&#30340;&#23454;&#29616;&#65292;&#28041;&#21450;&#36866;&#24403;&#30340;&#27714;&#35299;&#22120;&#65292;&#20174;&#36719;&#20214;&#24037;&#31243;&#35282;&#24230;&#26469;&#30475;&#26159;&#19981;&#22826;&#29702;&#24819;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;fairml R&#36719;&#20214;&#21253;&#65292;&#35813;&#36719;&#20214;&#21253;&#23454;&#29616;&#20102;&#25105;&#20204;&#20043;&#21069;&#30340;&#24037;&#20316;&#65288;Scutari&#65292;Panero&#21644;Proissl 2022&#65289;&#20197;&#21450;&#25991;&#29486;&#20013;&#30340;&#30456;&#20851;&#27169;&#22411;&#12290;fairml&#26159;&#22260;&#32469;&#20998;&#31867;&#12289;&#22238;&#24402;&#21644;&#26680;&#20272;&#35745;&#30340;&#32479;&#35745;&#26041;&#27861;&#35774;&#35745;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
The adoption of machine learning in applications where it is crucial to ensure fairness and accountability has led to a large number of model proposals in the literature, largely formulated as optimisation problems with constraints reducing or eliminating the effect of sensitive attributes on the response. While this approach is very flexible from a theoretical perspective, the resulting models are somewhat black-box in nature: very little can be said about their statistical properties, what are the best practices in their applied use, and how they can be extended to problems other than those they were originally designed for. Furthermore, the estimation of each model requires a bespoke implementation involving an appropriate solver which is less than desirable from a software engineering perspective.  In this paper, we describe the fairml R package which implements our previous work (Scutari, Panero, and Proissl 2022) and related models in the literature. fairml is designed around cla
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;$p$-&#33539;&#25968;&#30446;&#26631;&#23454;&#39564;&#35774;&#35745;&#38382;&#39064;&#30340;&#35299;&#20915;&#31639;&#27861;&#65292;&#21487;&#36866;&#29992;&#20110;&#21508;&#31181;&#29305;&#27530;&#24773;&#20917;&#65292;&#24182;&#19988;&#26159;&#24050;&#30693;&#26368;&#22909;&#30340;&#30028;&#30340;&#25554;&#20540;&#12290;</title><link>http://arxiv.org/abs/2305.01942</link><description>&lt;p&gt;
&#20219;&#24847;$p$-&#33539;&#25968;&#30340;&#23454;&#39564;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
Experimental Design for Any $p$-Norm. (arXiv:2305.01942v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.01942
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;$p$-&#33539;&#25968;&#30446;&#26631;&#23454;&#39564;&#35774;&#35745;&#38382;&#39064;&#30340;&#35299;&#20915;&#31639;&#27861;&#65292;&#21487;&#36866;&#29992;&#20110;&#21508;&#31181;&#29305;&#27530;&#24773;&#20917;&#65292;&#24182;&#19988;&#26159;&#24050;&#30693;&#26368;&#22909;&#30340;&#30028;&#30340;&#25554;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;$p$-&#33539;&#25968;&#30446;&#26631;&#65292;&#29992;&#20110;&#23454;&#39564;&#35774;&#35745;&#38382;&#39064;&#65292;&#24182;&#23558;&#19968;&#20123;&#32463;&#20856;&#30446;&#26631;&#65288;D/A/E-&#35774;&#35745;&#65289;&#20316;&#20026;&#29305;&#27530;&#24773;&#20917;&#36827;&#34892;&#20102;&#27010;&#25324;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#31181;&#38543;&#26426;&#23616;&#37096;&#25628;&#32034;&#26041;&#27861;&#25552;&#20379;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#25152;&#26377;&#30340;$p$-&#33539;&#25968;&#38382;&#39064;&#12290;&#36825;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#36866;&#29992;&#20110;&#26222;&#36941;$p$-&#33539;&#25968;&#30446;&#26631;&#30340;&#36817;&#20284;&#31639;&#27861;&#65292;&#24182;&#19988;&#26159;&#29305;&#27530;&#24773;&#20917;&#19979;&#24050;&#30693;&#26368;&#20248;&#30028;&#30340;&#19968;&#20010;&#24456;&#22909;&#30340;&#25554;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a general $p$-norm objective for experimental design problems that captures some well-studied objectives (D/A/E-design) as special cases. We prove that a randomized local search approach provides a unified algorithm to solve this problem for all $p$. This provides the first approximation algorithm for the general $p$-norm objective, and a nice interpolation of the best known bounds of the special cases.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#26512;&#19981;&#30830;&#23450;&#22810;&#21464;&#37327;&#31995;&#32479;&#34892;&#20026;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#25512;&#26029;&#30697;&#25551;&#36848;&#20998;&#24067;&#39044;&#35745;&#22914;&#20309;&#21709;&#24212;&#26032;&#20449;&#24687;&#65292;&#29305;&#21035;&#20851;&#27880;&#25512;&#26029;&#20559;&#24046;&#65292;&#20197;&#25913;&#21892;&#24773;&#22659;&#24863;&#30693;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2305.01841</link><description>&lt;p&gt;
&#19981;&#30830;&#23450;&#22810;&#21464;&#37327;&#31995;&#32479;&#30340;&#25512;&#26029;&#30697;
&lt;/p&gt;
&lt;p&gt;
Inferential Moments of Uncertain Multivariable Systems. (arXiv:2305.01841v1 [physics.data-an])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.01841
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#26512;&#19981;&#30830;&#23450;&#22810;&#21464;&#37327;&#31995;&#32479;&#34892;&#20026;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#25512;&#26029;&#30697;&#25551;&#36848;&#20998;&#24067;&#39044;&#35745;&#22914;&#20309;&#21709;&#24212;&#26032;&#20449;&#24687;&#65292;&#29305;&#21035;&#20851;&#27880;&#25512;&#26029;&#20559;&#24046;&#65292;&#20197;&#25913;&#21892;&#24773;&#22659;&#24863;&#30693;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#31216;&#20026;&#8220;&#25512;&#26029;&#30697;&#8221;&#30340;&#19968;&#32452;&#37327;&#26469;&#20998;&#26512;&#19981;&#30830;&#23450;&#22810;&#21464;&#37327;&#31995;&#32479;&#34892;&#20026;&#30340;&#26032;&#33539;&#24335;&#12290;&#36793;&#32536;&#21270;&#26159;&#19968;&#31181;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#36807;&#31243;&#65292;&#23427;&#36890;&#36807;&#24179;&#22343;&#26465;&#20214;&#27010;&#29575;&#26469;&#37327;&#21270;&#25152;&#20851;&#27880;&#27010;&#29575;&#30340;&#26399;&#26395;&#20540;&#12290;&#25512;&#26029;&#30697;&#26159;&#25551;&#36848;&#20998;&#24067;&#39044;&#35745;&#22914;&#20309;&#21709;&#24212;&#26032;&#20449;&#24687;&#30340;&#39640;&#38454;&#26465;&#20214;&#27010;&#29575;&#30697;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#25512;&#26029;&#20559;&#24046;&#65292;&#23427;&#26159;&#26399;&#26395;&#30340;&#27010;&#29575;&#27874;&#21160;&#65292;&#38543;&#30528;&#25512;&#26029;&#26356;&#26032;&#21478;&#19968;&#20010;&#21464;&#37327;&#32780;&#21457;&#29983;&#21464;&#21270;&#12290;&#25105;&#20204;&#20197;&#25512;&#26029;&#30697;&#30340;&#24418;&#24335;&#25214;&#21040;&#20102;&#20114;&#20449;&#24687;&#30340;&#24130;&#32423;&#25968;&#23637;&#24320;&#24335;&#65292;&#36825;&#24847;&#21619;&#30528;&#25512;&#26029;&#30697;&#36923;&#36753;&#21487;&#33021;&#23545;&#36890;&#24120;&#20351;&#29992;&#20449;&#24687;&#35770;&#24037;&#20855;&#25191;&#34892;&#30340;&#20219;&#21153;&#26377;&#29992;&#12290;&#25105;&#20204;&#22312;&#20004;&#20010;&#24212;&#29992;&#20013;&#25506;&#35752;&#20102;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#25512;&#26029;&#20559;&#24046;&#65292;&#20197;&#25913;&#21892;&#24773;&#22659;&#24863;&#30693;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article offers a new paradigm for analyzing the behavior of uncertain multivariable systems using a set of quantities we call \emph{inferential moments}. Marginalization is an uncertainty quantification process that averages conditional probabilities to quantify the \emph{expected value} of a probability of interest. Inferential moments are higher order conditional probability moments that describe how a distribution is expected to respond to new information. Of particular interest in this article is the \emph{inferential deviation}, which is the expected fluctuation of the probability of one variable in response to an inferential update of another. We find a power series expansion of the Mutual Information in terms of inferential moments, which implies that inferential moment logic may be useful for tasks typically performed with information theoretic tools. We explore this in two applications that analyze the inferential deviations of a Bayesian Network to improve situational aw
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#39318;&#27425;&#20174;&#29702;&#35770;&#19978;&#30740;&#31350;&#20102;&#22522;&#20110;&#21327;&#26041;&#24046;&#31070;&#32463;&#32593;&#32476;&#30340;&#21487;&#36716;&#31227;&#24615;&#65292;&#35777;&#26126;&#20102;&#24403;&#25968;&#25454;&#38598;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#25910;&#25947;&#21040;&#19968;&#20010;&#26497;&#38480;&#23545;&#35937;&#26102;&#65292;VNN&#33021;&#22815;&#23637;&#29616;&#20986;&#24615;&#33021;&#21487;&#36716;&#31227;&#24615;&#12290;&#22810;&#23610;&#24230;&#31070;&#32463;&#24433;&#20687;&#25968;&#25454;&#38598;&#21487;&#20197;&#22312;&#22810;&#20010;&#23610;&#24230;&#19978;&#30740;&#31350;&#33041;&#37096;&#65292;&#24182;&#19988;&#21487;&#20197;&#39564;&#35777;VNN&#30340;&#21487;&#36716;&#31227;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.01807</link><description>&lt;p&gt;
&#22522;&#20110;&#21327;&#26041;&#24046;&#31070;&#32463;&#32593;&#32476;&#30340;&#21487;&#36716;&#31227;&#23398;&#20064;&#21644;&#24212;&#29992;&#20110;&#35299;&#37322;&#24615;&#33041;&#40836;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Transferablility of coVariance Neural Networks and Application to Interpretable Brain Age Prediction using Anatomical Features. (arXiv:2305.01807v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.01807
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#39318;&#27425;&#20174;&#29702;&#35770;&#19978;&#30740;&#31350;&#20102;&#22522;&#20110;&#21327;&#26041;&#24046;&#31070;&#32463;&#32593;&#32476;&#30340;&#21487;&#36716;&#31227;&#24615;&#65292;&#35777;&#26126;&#20102;&#24403;&#25968;&#25454;&#38598;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#25910;&#25947;&#21040;&#19968;&#20010;&#26497;&#38480;&#23545;&#35937;&#26102;&#65292;VNN&#33021;&#22815;&#23637;&#29616;&#20986;&#24615;&#33021;&#21487;&#36716;&#31227;&#24615;&#12290;&#22810;&#23610;&#24230;&#31070;&#32463;&#24433;&#20687;&#25968;&#25454;&#38598;&#21487;&#20197;&#22312;&#22810;&#20010;&#23610;&#24230;&#19978;&#30740;&#31350;&#33041;&#37096;&#65292;&#24182;&#19988;&#21487;&#20197;&#39564;&#35777;VNN&#30340;&#21487;&#36716;&#31227;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#21367;&#31215;&#32593;&#32476;&#65288;GCN&#65289;&#21033;&#29992;&#22522;&#20110;&#25299;&#25169;&#22270;&#30340;&#21367;&#31215;&#25805;&#20316;&#26469;&#32452;&#21512;&#22270;&#19978;&#30340;&#20449;&#24687;&#36827;&#34892;&#25512;&#29702;&#20219;&#21153;&#12290;&#25105;&#20204;&#26368;&#36817;&#30340;&#24037;&#20316;&#20013;&#65292;&#36890;&#36807;&#20351;&#29992;&#21327;&#26041;&#24046;&#30697;&#38453;&#20316;&#20026;&#22270;&#26469;&#35774;&#35745;&#20102;&#19968;&#31181;&#31867;&#20284;&#20110;&#20256;&#32479;PCA&#25968;&#25454;&#20998;&#26512;&#26041;&#27861;&#30340;&#21327;&#26041;&#24046;&#31070;&#32463;&#32593;&#32476;&#65288;VNN&#65289;&#65292;&#24182;&#20855;&#26377;&#26174;&#33879;&#30340;&#20248;&#21183;&#12290;&#26412;&#25991;&#39318;&#20808;&#20174;&#29702;&#35770;&#19978;&#30740;&#31350;&#20102;VNN&#30340;&#21487;&#36716;&#31227;&#24615;&#12290;&#21487;&#36716;&#31227;&#24615;&#30340;&#27010;&#24565;&#26159;&#20174;&#23398;&#20064;&#27169;&#22411;&#21487;&#20197;&#22312;&#8220;&#20860;&#23481;&#8221;&#30340;&#25968;&#25454;&#38598;&#19978;&#27867;&#21270;&#30340;&#30452;&#35266;&#26399;&#26395;&#20013;&#20135;&#29983;&#30340;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;VNN&#20174;GCN&#32487;&#25215;&#30340;&#26080;&#26631;&#24230;&#25968;&#25454;&#22788;&#29702;&#26550;&#26500;&#65292;&#24182;&#35777;&#26126;&#24403;&#25968;&#25454;&#38598;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#25910;&#25947;&#21040;&#19968;&#20010;&#26497;&#38480;&#23545;&#35937;&#26102;&#65292;VNN&#33021;&#22815;&#23637;&#29616;&#20986;&#24615;&#33021;&#21487;&#36716;&#31227;&#24615;&#12290;&#22810;&#23610;&#24230;&#31070;&#32463;&#24433;&#20687;&#25968;&#25454;&#38598;&#21487;&#20197;&#22312;&#22810;&#20010;&#23610;&#24230;&#19978;&#30740;&#31350;&#33041;&#37096;&#65292;&#24182;&#19988;&#21487;&#20197;&#39564;&#35777;VNN&#30340;&#21487;&#36716;&#31227;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph convolutional networks (GCN) leverage topology-driven graph convolutional operations to combine information across the graph for inference tasks. In our recent work, we have studied GCNs with covariance matrices as graphs in the form of coVariance neural networks (VNNs) that draw similarities with traditional PCA-driven data analysis approaches while offering significant advantages over them. In this paper, we first focus on theoretically characterizing the transferability of VNNs. The notion of transferability is motivated from the intuitive expectation that learning models could generalize to "compatible" datasets (possibly of different dimensionalities) with minimal effort. VNNs inherit the scale-free data processing architecture from GCNs and here, we show that VNNs exhibit transferability of performance over datasets whose covariance matrices converge to a limit object. Multi-scale neuroimaging datasets enable the study of the brain at multiple scales and hence, can validate
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#24314;&#27169;&#22823;&#35268;&#27169;&#21160;&#24577;&#31995;&#32479;&#30340;&#28145;&#24230;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65292;&#22312;&#20445;&#25345;&#22810;&#23792;&#39044;&#27979;&#20998;&#24067;&#30340;&#20934;&#30830;&#24615;&#30340;&#21516;&#26102;&#65292;&#36890;&#36807;&#30830;&#23450;&#24615;&#30697;&#21305;&#37197;&#35268;&#21017;&#23454;&#29616;&#20102;&#26080;&#26679;&#26412;&#25512;&#26029;&#65292;&#25552;&#39640;&#20102;&#39044;&#27979;&#30340;&#25928;&#29575;&#21644;&#31283;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.01773</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#21160;&#24577;&#31995;&#32479;&#30340;&#28145;&#24230;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#30340;&#24265;&#20215;&#21644;&#30830;&#23450;&#24615;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Cheap and Deterministic Inference for Deep State-Space Models of Interacting Dynamical Systems. (arXiv:2305.01773v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.01773
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#24314;&#27169;&#22823;&#35268;&#27169;&#21160;&#24577;&#31995;&#32479;&#30340;&#28145;&#24230;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65292;&#22312;&#20445;&#25345;&#22810;&#23792;&#39044;&#27979;&#20998;&#24067;&#30340;&#20934;&#30830;&#24615;&#30340;&#21516;&#26102;&#65292;&#36890;&#36807;&#30830;&#23450;&#24615;&#30697;&#21305;&#37197;&#35268;&#21017;&#23454;&#29616;&#20102;&#26080;&#26679;&#26412;&#25512;&#26029;&#65292;&#25552;&#39640;&#20102;&#39044;&#27979;&#30340;&#25928;&#29575;&#21644;&#31283;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#36890;&#24120;&#34987;&#29992;&#20110;&#24314;&#27169;&#30456;&#20114;&#20316;&#29992;&#30340;&#21160;&#24577;&#31995;&#32479;&#65292;&#22240;&#20026;&#23427;&#20204;&#20248;&#38597;&#22320;&#36866;&#24212;&#20110;&#20855;&#26377;&#21464;&#21270;&#21644;&#22823;&#37327;&#20195;&#29702;&#30340;&#31995;&#32479;&#12290;&#34429;&#28982;&#22312;&#30830;&#23450;&#24615;&#30456;&#20114;&#20316;&#29992;&#31995;&#32479;&#26041;&#38754;&#21462;&#24471;&#20102;&#24456;&#22810;&#36827;&#23637;&#65292;&#20294;&#23545;&#20110;&#26377;&#20852;&#36259;&#33719;&#24471;&#26410;&#26469;&#36712;&#36857;&#30340;&#39044;&#27979;&#20998;&#24067;&#30340;&#38543;&#26426;&#31995;&#32479;&#65292;&#27169;&#22411;&#26356;&#20855;&#25361;&#25112;&#24615;&#12290;&#29616;&#26377;&#26041;&#27861;&#35201;&#20040;&#35745;&#31639;&#36895;&#24230;&#24930;&#65292;&#22240;&#20026;&#23427;&#20204;&#20381;&#36182;&#20110;&#33945;&#29305;&#21345;&#32599;&#25277;&#26679;&#65292;&#35201;&#20040;&#20570;&#20986;&#31616;&#21270;&#20551;&#35774;&#65292;&#20351;&#24471;&#39044;&#27979;&#20998;&#24067;&#26159;&#21333;&#23792;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#28145;&#24230;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65292;&#23427;&#37319;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#26469;&#24314;&#27169;&#24213;&#23618;&#30340;&#30456;&#20114;&#20316;&#29992;&#21160;&#24577;&#31995;&#32479;&#12290;&#39044;&#27979;&#20998;&#24067;&#26159;&#22810;&#23792;&#30340;&#65292;&#24182;&#19988;&#20855;&#26377;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#30340;&#24418;&#24335;&#65292;&#20854;&#20013;&#39640;&#26031;&#20998;&#37327;&#30340;&#30697;&#21487;&#20197;&#36890;&#36807;&#30830;&#23450;&#24615;&#30697;&#21305;&#37197;&#35268;&#21017;&#35745;&#31639;&#12290;&#25105;&#20204;&#30340;&#30697;&#21305;&#37197;&#26041;&#26696;&#21487;&#20197;&#29992;&#20110;&#26080;&#26679;&#26412;&#25512;&#26029;&#65292;&#20174;&#32780;&#23454;&#29616;&#26356;&#26377;&#25928;&#21644;&#31283;&#23450;&#30340;&#39044;&#27979;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#26377;&#25928;&#22320;&#24314;&#27169;&#21644;&#39044;&#27979;&#38543;&#26426;&#31995;&#32479;&#30340;&#36712;&#36857;&#65292;&#21363;&#20351;&#23384;&#22312;&#24040;&#22823;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph neural networks are often used to model interacting dynamical systems since they gracefully scale to systems with a varying and high number of agents. While there has been much progress made for deterministic interacting systems, modeling is much more challenging for stochastic systems in which one is interested in obtaining a predictive distribution over future trajectories. Existing methods are either computationally slow since they rely on Monte Carlo sampling or make simplifying assumptions such that the predictive distribution is unimodal. In this work, we present a deep state-space model which employs graph neural networks in order to model the underlying interacting dynamical system. The predictive distribution is multimodal and has the form of a Gaussian mixture model, where the moments of the Gaussian components can be computed via deterministic moment matching rules. Our moment matching scheme can be exploited for sample-free inference, leading to more efficient and sta
&lt;/p&gt;</description></item><item><title>DeCom&#26159;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#32806;&#21512;&#22240;&#23376;&#20998;&#35299;&#26426;&#30340;RSV&#39044;&#27979;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#32467;&#21512;&#20102;&#27491;&#24120;&#30340;&#23395;&#33410;&#24615;RSV&#20256;&#25773;&#27169;&#24335;&#21644;COVID-19&#31526;&#21512;NPI&#25514;&#26045;&#19979;RSV&#20256;&#25773;&#30340;&#19981;&#31283;&#23450;&#24615;&#65292;&#39044;&#27979;&#25928;&#26524;&#26356;&#21152;&#20934;&#30830;&#12290;</title><link>http://arxiv.org/abs/2305.01770</link><description>&lt;p&gt;
DeCom&#65306;&#22522;&#20110;&#28145;&#24230;&#32806;&#21512;&#22240;&#23376;&#20998;&#35299;&#26426;&#30340;&#38750;&#33647;&#29289;&#24178;&#39044;&#24863;&#30693;&#30340;COVID-19&#21518;RSV&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
DeCom: Deep Coupled-Factorization Machine for Post COVID-19 Respiratory Syncytial Virus Prediction with Nonpharmaceutical Interventions Awareness. (arXiv:2305.01770v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.01770
&lt;/p&gt;
&lt;p&gt;
DeCom&#26159;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#32806;&#21512;&#22240;&#23376;&#20998;&#35299;&#26426;&#30340;RSV&#39044;&#27979;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#32467;&#21512;&#20102;&#27491;&#24120;&#30340;&#23395;&#33410;&#24615;RSV&#20256;&#25773;&#27169;&#24335;&#21644;COVID-19&#31526;&#21512;NPI&#25514;&#26045;&#19979;RSV&#20256;&#25773;&#30340;&#19981;&#31283;&#23450;&#24615;&#65292;&#39044;&#27979;&#25928;&#26524;&#26356;&#21152;&#20934;&#30830;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21628;&#21560;&#36947;&#21512;&#32990;&#30149;&#27602;&#65288;RSV&#65289;&#26159;&#23156;&#24188;&#20799;&#26368;&#21361;&#38505;&#30340;&#21628;&#21560;&#31995;&#32479;&#30142;&#30149;&#20043;&#19968;&#12290;&#30001;&#20110;COVID-19&#30340;&#38750;&#33647;&#29289;&#24178;&#39044;&#65288;NPI&#65289;&#25514;&#26045;&#65292;RSV&#30340;&#23395;&#33410;&#24615;&#20256;&#25773;&#27169;&#24335;&#22312;2020&#24180;&#24050;&#32463;&#20013;&#26029;&#65292;&#24182;&#22312;2021&#24180;&#21271;&#21322;&#29699;&#25552;&#21069;&#25968;&#26376;&#20986;&#29616;&#36716;&#21464;&#12290;&#22240;&#27492;&#65292;&#29702;&#35299;COVID-19&#22914;&#20309;&#24433;&#21709;RSV&#24182;&#26500;&#24314;&#39044;&#27979;&#31639;&#27861;&#20197;&#39044;&#27979;COVID-19&#21518;RSV&#20877;&#20986;&#29616;&#30340;&#26102;&#38388;&#21644;&#24378;&#24230;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DeCom&#30340;&#28145;&#24230;&#32806;&#21512;&#24352;&#37327;&#20998;&#35299;&#26426;&#65292;&#29992;&#20110;COVID-19&#21518;RSV&#39044;&#27979;&#12290;DeCom&#21033;&#29992;&#24352;&#37327;&#20998;&#35299;&#21644;&#27531;&#24046;&#24314;&#27169;&#65292;&#33021;&#21487;&#38752;&#22320;&#23398;&#20064;&#21463;COVID-19&#24433;&#21709;&#19979;&#30340;RSV&#20256;&#25773;&#65292;&#21516;&#26102;&#32771;&#34385;&#27491;&#24120;&#23395;&#33410;&#24615;RSV&#20256;&#25773;&#27169;&#24335;&#21644;NPI&#12290;&#22312;&#30495;&#23454;&#30340;RSV&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;DeCom&#27604;&#29616;&#26377;RSV&#39044;&#27979;&#31639;&#27861;&#26356;&#20934;&#30830;&#65292;&#24182;&#21487;&#26368;&#22823;&#31243;&#24230;&#22320;&#25552;&#39640;&#39044;&#27979;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Respiratory syncytial virus (RSV) is one of the most dangerous respiratory diseases for infants and young children. Due to the nonpharmaceutical intervention (NPI) imposed in the COVID-19 outbreak, the seasonal transmission pattern of RSV has been discontinued in 2020 and then shifted months ahead in 2021 in the northern hemisphere. It is critical to understand how COVID-19 impacts RSV and build predictive algorithms to forecast the timing and intensity of RSV reemergence in post-COVID-19 seasons. In this paper, we propose a deep coupled tensor factorization machine, dubbed as DeCom, for post COVID-19 RSV prediction. DeCom leverages tensor factorization and residual modeling. It enables us to learn the disrupted RSV transmission reliably under COVID-19 by taking both the regular seasonal RSV transmission pattern and the NPI into consideration. Experimental results on a real RSV dataset show that DeCom is more accurate than the state-of-the-art RSV prediction algorithms and achieves up 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23545;&#25239;&#29983;&#25104;&#30340;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#21333;&#22768;&#36947;&#28304;&#20998;&#31163;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#25239;&#35757;&#32451;NMF&#22522;&#65292;&#23454;&#29616;&#20102;&#22312;&#27809;&#26377;&#24378;&#30417;&#30563;&#25968;&#25454;&#21487;&#29992;&#30340;&#24773;&#20917;&#19979;&#25552;&#39640;&#37325;&#26500;&#20449;&#21495;&#36136;&#37327;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2305.01758</link><description>&lt;p&gt;
&#22522;&#20110;&#23545;&#25239;&#29983;&#25104;&#30340;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#21333;&#22768;&#36947;&#28304;&#20998;&#31163;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Adversarial Generative NMF for Single Channel Source Separation. (arXiv:2305.01758v1 [eess.AS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.01758
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23545;&#25239;&#29983;&#25104;&#30340;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#21333;&#22768;&#36947;&#28304;&#20998;&#31163;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#25239;&#35757;&#32451;NMF&#22522;&#65292;&#23454;&#29616;&#20102;&#22312;&#27809;&#26377;&#24378;&#30417;&#30563;&#25968;&#25454;&#21487;&#29992;&#30340;&#24773;&#20917;&#19979;&#25552;&#39640;&#37325;&#26500;&#20449;&#21495;&#36136;&#37327;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#23398;&#20064;&#27491;&#21017;&#21270;&#20989;&#25968;&#30340;&#24605;&#24819;&#26368;&#36817;&#34987;&#24341;&#20837;&#20102;&#26356;&#24191;&#27867;&#30340;&#21453;&#38382;&#39064;&#32972;&#26223;&#19979;&#12290;&#35813;&#26041;&#27861;&#30340;&#28789;&#24863;&#22312;&#20110;&#24847;&#35782;&#21040;&#19981;&#20165;&#38656;&#35201;&#23398;&#20064;&#32452;&#25104;&#25152;&#38656;&#20449;&#21495;&#30340;&#22522;&#26412;&#29305;&#24449;&#65292;&#32780;&#19988;&#25110;&#32773;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#38656;&#35201;&#23398;&#20064;&#36991;&#20813;&#34920;&#31034;&#20013;&#30340;&#21738;&#20123;&#29305;&#24449;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#24212;&#29992;&#36825;&#31181;&#26041;&#27861;&#26469;&#35299;&#20915;&#36890;&#36807;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#36827;&#34892;&#28304;&#20998;&#31163;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#23545;&#25239;&#35757;&#32451;NMF&#22522;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#26080;&#35770;&#26159;&#22270;&#20687;&#36824;&#26159;&#38899;&#39057;&#20998;&#31163;&#65292;&#22312;&#27809;&#26377;&#24378;&#30417;&#30563;&#25968;&#25454;&#21487;&#29992;&#30340;&#24773;&#20917;&#19979;&#65292;&#37117;&#20250;&#26126;&#26174;&#25552;&#39640;&#37325;&#26500;&#20449;&#21495;&#30340;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
The idea of adversarial learning of regularization functionals has recently been introduced in the wider context of inverse problems. The intuition behind this method is the realization that it is not only necessary to learn the basic features that make up a class of signals one wants to represent, but also, or even more so, which features to avoid in the representation. In this paper, we will apply this approach to the problem of source separation by means of non-negative matrix factorization (NMF) and present a new method for the adversarial training of NMF bases. We show in numerical experiments, both for image and audio separation, that this leads to a clear improvement of the reconstructed signals, in particular in the case where little or no strong supervision data is available.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#26694;&#26550;&#65292;&#21033;&#29992;&#26680;&#20989;&#25968;&#30340;&#21152;&#27861;&#21644;&#20056;&#27861;&#32467;&#26500;&#35774;&#35745;&#20102;&#19968;&#20010;&#36951;&#20256;&#32534;&#31243;&#31639;&#27861;&#65292;&#33021;&#22815;&#23398;&#20064;&#29305;&#23450;&#20154;&#32676;&#30340;&#24180;&#40836;&#21644;&#24180;&#20221;&#29305;&#23450;&#30340;&#27515;&#20129;&#29575;&#26354;&#38754;&#65292;&#20026;&#19981;&#21516;&#20154;&#32676;&#20013;&#38431;&#21015;&#25928;&#24212;&#30340;&#23384;&#22312;&#24615;&#24102;&#26469;&#20102;&#26032;&#30340;&#35265;&#35299;&#65292;&#24182;&#25552;&#20379;&#20102;&#30456;&#23545;&#24179;&#28369;&#31243;&#24230;&#30340;&#20998;&#26512;&#24037;&#20316;&#12290;</title><link>http://arxiv.org/abs/2305.01728</link><description>&lt;p&gt;
&#36890;&#36807;&#39640;&#26031;&#36807;&#31243;&#26680;&#34920;&#36798;&#23551;&#21629;&#27169;&#22411;&#30340;&#28789;&#27963;&#24615;
&lt;/p&gt;
&lt;p&gt;
Expressive Mortality Models through Gaussian Process Kernels. (arXiv:2305.01728v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.01728
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#26694;&#26550;&#65292;&#21033;&#29992;&#26680;&#20989;&#25968;&#30340;&#21152;&#27861;&#21644;&#20056;&#27861;&#32467;&#26500;&#35774;&#35745;&#20102;&#19968;&#20010;&#36951;&#20256;&#32534;&#31243;&#31639;&#27861;&#65292;&#33021;&#22815;&#23398;&#20064;&#29305;&#23450;&#20154;&#32676;&#30340;&#24180;&#40836;&#21644;&#24180;&#20221;&#29305;&#23450;&#30340;&#27515;&#20129;&#29575;&#26354;&#38754;&#65292;&#20026;&#19981;&#21516;&#20154;&#32676;&#20013;&#38431;&#21015;&#25928;&#24212;&#30340;&#23384;&#22312;&#24615;&#24102;&#26469;&#20102;&#26032;&#30340;&#35265;&#35299;&#65292;&#24182;&#25552;&#20379;&#20102;&#30456;&#23545;&#24179;&#28369;&#31243;&#24230;&#30340;&#20998;&#26512;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#28789;&#27963;&#30340;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#26694;&#26550;&#65292;&#29992;&#20110;&#23398;&#20064;&#24180;&#40836;&#21644;&#24180;&#20221;&#29305;&#23450;&#30340;&#27515;&#20129;&#29575;&#26354;&#38754;&#30340;&#21327;&#26041;&#24046;&#32467;&#26500;&#12290;&#21033;&#29992;GP&#26680;&#30340;&#21152;&#27861;&#21644;&#20056;&#27861;&#32467;&#26500;&#65292;&#25105;&#20204;&#35774;&#35745;&#19968;&#20010;&#36951;&#20256;&#32534;&#31243;&#31639;&#27861;&#26469;&#25628;&#32034;&#38024;&#23545;&#32473;&#23450;&#20154;&#32676;&#30340;&#26368;&#20855;&#34920;&#29616;&#21147;&#30340;&#26680;&#12290;&#25105;&#20204;&#30340;&#32452;&#21512;&#25628;&#32034;&#22522;&#20110;&#24180;&#40836;-&#26399;&#38388;-&#38431;&#21015;&#65288;APC&#65289;&#33539;&#20363;&#65292;&#20197;&#26500;&#24314;&#26368;&#33021;&#21305;&#37197;&#27515;&#20129;&#29575;&#25968;&#25454;&#38598;&#30340;&#26102;&#31354;&#21160;&#24577;&#30340;&#21327;&#26041;&#24046;&#20808;&#39564;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#26696;&#20363;&#30740;&#31350;&#20013;&#24212;&#29992;&#24471;&#21040;&#30340;&#36951;&#20256;&#31639;&#27861;&#65288;GA&#65289;&#26469;&#39564;&#35777;GA&#24674;&#22797;APC&#32467;&#26500;&#30340;&#33021;&#21147;&#65292;&#24182;&#22312;&#20154;&#31867;&#27515;&#20129;&#25968;&#25454;&#24211;&#30340;&#23454;&#38469;&#22269;&#23478;&#32423;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20998;&#26512;&#12290;&#25105;&#20204;&#30340;&#26426;&#22120;&#23398;&#20064;&#20998;&#26512;&#25552;&#20379;&#20102;&#26377;&#20851;&#19981;&#21516;&#20154;&#32676;&#20013;&#38431;&#21015;&#25928;&#24212;&#23384;&#22312;&#25110;&#19981;&#23384;&#22312;&#30340;&#26032;&#35265;&#35299;&#65292;&#20197;&#21450;&#27839;&#24180;&#40836;&#21644;&#24180;&#20221;&#32500;&#24230;&#30340;&#27515;&#20129;&#29575;&#26354;&#38754;&#30340;&#30456;&#23545;&#24179;&#28369;&#31243;&#24230;&#12290;&#25105;&#20204;&#30340;&#24314;&#27169;&#24037;&#20316;&#26159;&#22312;Python&#30340;PyTorch&#24211;&#20013;&#23436;&#25104;&#30340;&#65292;&#25552;&#20379;&#20102;&#28145;&#20837;&#30340;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a flexible Gaussian Process (GP) framework for learning the covariance structure of Age- and Year-specific mortality surfaces. Utilizing the additive and multiplicative structure of GP kernels, we design a genetic programming algorithm to search for the most expressive kernel for a given population. Our compositional search builds off the Age-Period-Cohort (APC) paradigm to construct a covariance prior best matching the spatio-temporal dynamics of a mortality dataset. We apply the resulting genetic algorithm (GA) on synthetic case studies to validate the ability of the GA to recover APC structure, and on real-life national-level datasets from the Human Mortality Database. Our machine-learning based analysis provides novel insight into the presence/absence of Cohort effects in different populations, and into the relative smoothness of mortality surfaces along the Age and Year dimensions. Our modelling work is done with the PyTorch libraries in Python and provides an in-depth 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#8220;&#24930;&#26432;&#8221;&#30340;&#25216;&#26415;&#65292;&#23427;&#21033;&#29992;&#38750;&#20984;&#32422;&#26463;&#20248;&#21270;&#12289;&#33258;&#36866;&#24212;$\ell_2$&#25910;&#32553;&#21644;&#36880;&#27493;&#22686;&#21152;&#30340;&#23398;&#20064;&#29575;&#65292;&#21487;&#20197;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#19978;&#23454;&#29616;&#39640;&#25928;&#21464;&#37327;&#31579;&#36873;&#21644;&#32479;&#35745;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2305.01726</link><description>&lt;p&gt;
&#22823;&#25968;&#25454;&#23398;&#20064;&#30340;&#24930;&#26432;&#25216;&#24039;
&lt;/p&gt;
&lt;p&gt;
Slow Kill for Big Data Learning. (arXiv:2305.01726v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.01726
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#8220;&#24930;&#26432;&#8221;&#30340;&#25216;&#26415;&#65292;&#23427;&#21033;&#29992;&#38750;&#20984;&#32422;&#26463;&#20248;&#21270;&#12289;&#33258;&#36866;&#24212;$\ell_2$&#25910;&#32553;&#21644;&#36880;&#27493;&#22686;&#21152;&#30340;&#23398;&#20064;&#29575;&#65292;&#21487;&#20197;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#19978;&#23454;&#29616;&#39640;&#25928;&#21464;&#37327;&#31579;&#36873;&#21644;&#32479;&#35745;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#25968;&#25454;&#24212;&#29992;&#36890;&#24120;&#28041;&#21450;&#22823;&#37327;&#30340;&#35266;&#23519;&#21644;&#29305;&#24449;&#65292;&#36825;&#20026;&#21464;&#37327;&#36873;&#25321;&#21644;&#21442;&#25968;&#20272;&#35745;&#24102;&#26469;&#20102;&#26032;&#30340;&#25361;&#25112;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#8220;&#24930;&#26432;&#8221;&#30340;&#26032;&#25216;&#26415;&#65292;&#23427;&#21033;&#29992;&#38750;&#20984;&#32422;&#26463;&#20248;&#21270;&#12289;&#33258;&#36866;&#24212;$\ell_2$&#25910;&#32553;&#21644;&#36880;&#27493;&#22686;&#21152;&#30340;&#23398;&#20064;&#29575;&#12290;&#22312;&#24930;&#26432;&#36845;&#20195;&#36807;&#31243;&#20013;&#65292;&#38382;&#39064;&#35268;&#27169;&#21487;&#20197;&#20943;&#23567;&#65292;&#36825;&#20351;&#20854;&#29305;&#21035;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#21464;&#37327;&#31579;&#36873;&#12290;&#32479;&#35745;&#21644;&#20248;&#21270;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#25552;&#20379;&#20102;&#26377;&#20851;&#25511;&#21046;&#20998;&#20301;&#25968;&#12289;&#27493;&#38271;&#21644;&#25910;&#32553;&#21442;&#25968;&#20197;&#25918;&#26494;&#25152;&#38656;&#30340;&#27491;&#21017;&#24615;&#26465;&#20214;&#20197;&#23454;&#29616;&#25152;&#38656;&#32479;&#35745;&#31934;&#24230;&#30340;&#26377;&#20215;&#20540;&#30340;&#35265;&#35299;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#24930;&#26432;&#22312;&#21508;&#31181;&#24773;&#20917;&#19979;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#65292;&#24182;&#19988;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#19978;&#20855;&#26377;&#39640;&#25928;&#30340;&#35745;&#31639;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
Big-data applications often involve a vast number of observations and features, creating new challenges for variable selection and parameter estimation. This paper presents a novel technique called ``slow kill,'' which utilizes nonconvex constrained optimization, adaptive $\ell_2$-shrinkage, and increasing learning rates. The fact that the problem size can decrease during the slow kill iterations makes it particularly effective for large-scale variable screening. The interaction between statistics and optimization provides valuable insights into controlling quantiles, stepsize, and shrinkage parameters in order to relax the regularity conditions required to achieve the desired level of statistical accuracy. Experimental results on real and synthetic data show that slow kill outperforms state-of-the-art algorithms in various situations while being computationally efficient for large-scale data.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#23457;&#35745;&#26694;&#26550;&#65292;&#33021;&#22815;&#20197;&#20840;&#38754;&#30340;&#26041;&#24335;&#35780;&#20272;&#21512;&#25104;&#25968;&#25454;&#21644;AI&#27169;&#22411;&#30340;&#20855;&#20307;&#25928;&#26524;&#65292;&#21253;&#25324;&#20559;&#35265;&#21644;&#27495;&#35270;&#39044;&#38450;&#12289;&#23545;&#30495;&#23454;&#25968;&#25454;&#30340;&#24544;&#23454;&#31243;&#24230;&#12289;&#25928;&#29992;&#12289;&#40065;&#26834;&#24615;&#21644;&#38544;&#31169;&#20445;&#25252;&#12290;&#22312;&#22810;&#20010;&#29992;&#20363;&#20013;&#65292;&#23457;&#35745;&#26694;&#26550;&#24179;&#34913;&#20102;&#20449;&#20219;&#21644;&#25928;&#29992;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;</title><link>http://arxiv.org/abs/2304.10819</link><description>&lt;p&gt;
&#21487;&#25511;&#30340;&#20449;&#20219;&#26435;&#34913;&#19979;&#30340;&#21512;&#25104;&#25968;&#25454;&#23457;&#35745;&#19982;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Auditing and Generating Synthetic Data with Controllable Trust Trade-offs. (arXiv:2304.10819v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10819
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#23457;&#35745;&#26694;&#26550;&#65292;&#33021;&#22815;&#20197;&#20840;&#38754;&#30340;&#26041;&#24335;&#35780;&#20272;&#21512;&#25104;&#25968;&#25454;&#21644;AI&#27169;&#22411;&#30340;&#20855;&#20307;&#25928;&#26524;&#65292;&#21253;&#25324;&#20559;&#35265;&#21644;&#27495;&#35270;&#39044;&#38450;&#12289;&#23545;&#30495;&#23454;&#25968;&#25454;&#30340;&#24544;&#23454;&#31243;&#24230;&#12289;&#25928;&#29992;&#12289;&#40065;&#26834;&#24615;&#21644;&#38544;&#31169;&#20445;&#25252;&#12290;&#22312;&#22810;&#20010;&#29992;&#20363;&#20013;&#65292;&#23457;&#35745;&#26694;&#26550;&#24179;&#34913;&#20102;&#20449;&#20219;&#21644;&#25928;&#29992;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#23454;&#20013;&#25910;&#38598;&#30340;&#25968;&#25454;&#24448;&#24448;&#23384;&#22312;&#20559;&#24046;&#12289;&#19981;&#24179;&#34913;&#65292;&#24182;&#19988;&#26377;&#27844;&#38706;&#25935;&#24863;&#21644;&#38544;&#31169;&#20449;&#24687;&#30340;&#39118;&#38505;&#12290;&#36825;&#19968;&#20107;&#23454;&#24341;&#21457;&#20102;&#21019;&#24314;&#21512;&#25104;&#25968;&#25454;&#38598;&#30340;&#24819;&#27861;&#65292;&#20197;&#20943;&#36731;&#30495;&#23454;&#25968;&#25454;&#20013;&#22266;&#26377;&#30340;&#39118;&#38505;&#12289;&#20559;&#35265;&#12289;&#20260;&#23475;&#21644;&#38544;&#31169;&#38382;&#39064;&#12290;&#36825;&#20010;&#27010;&#24565;&#20381;&#36182;&#20110;&#29983;&#25104;AI&#27169;&#22411;&#65292;&#20197;&#20135;&#29983;&#19981;&#20559;&#25191;&#12289;&#20445;&#25252;&#38544;&#31169;&#30340;&#21512;&#25104;&#25968;&#25454;&#65292;&#21516;&#26102;&#24544;&#23454;&#20110;&#30495;&#23454;&#25968;&#25454;&#12290;&#22312;&#36825;&#31181;&#26032;&#33539;&#24335;&#20013;&#65292;&#25105;&#20204;&#22914;&#20309;&#30693;&#36947;&#36825;&#31181;&#26041;&#27861;&#26159;&#21542;&#20817;&#29616;&#20102;&#20854;&#25215;&#35834;&#65311;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23457;&#35745;&#26694;&#26550;&#65292;&#25552;&#20379;&#20102;&#23545;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#22522;&#20110;&#23427;&#20204;&#35757;&#32451;&#30340;AI&#27169;&#22411;&#30340;&#20840;&#38754;&#35780;&#20272;&#65292;&#22260;&#32469;&#20559;&#35265;&#21644;&#27495;&#35270;&#30340;&#39044;&#38450;&#12289;&#23545;&#30495;&#23454;&#25968;&#25454;&#30340;&#24544;&#23454;&#31243;&#24230;&#12289;&#25928;&#29992;&#12289;&#40065;&#26834;&#24615;&#21644;&#38544;&#31169;&#20445;&#25252;&#12290;&#25105;&#20204;&#36890;&#36807;&#23457;&#35745;&#22810;&#20010;&#29983;&#25104;&#27169;&#22411;&#22312;&#19981;&#21516;&#29992;&#20363;&#20013;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26694;&#26550;&#65292;&#21253;&#25324;&#25945;&#32946;&#12289;&#21307;&#30103;&#20445;&#20581;&#12289;&#38134;&#34892;&#12289;&#20154;&#21147;&#36164;&#28304;&#65292;&#20197;&#21450;&#20174;&#34920;&#26684;&#65292;&#26102;&#38388;&#24207;&#21015;&#21040;&#33258;&#28982;&#35821;&#35328;&#30340;&#19981;&#21516;&#27169;&#24577;&#12290;&#25105;&#20204;&#30340;&#29992;&#20363;&#23637;&#31034;&#20102;&#22312;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#20013;&#24179;&#34913;&#20449;&#20219;&#21644;&#25928;&#29992;&#30340;&#26435;&#34913;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data collected from the real world tends to be biased, unbalanced, and at risk of exposing sensitive and private information. This reality has given rise to the idea of creating synthetic datasets to alleviate risk, bias, harm, and privacy concerns inherent in the real data. This concept relies on Generative AI models to produce unbiased, privacy-preserving synthetic data while being true to the real data. In this new paradigm, how can we tell if this approach delivers on its promises? We present an auditing framework that offers a holistic assessment of synthetic datasets and AI models trained on them, centered around bias and discrimination prevention, fidelity to the real data, utility, robustness, and privacy preservation. We showcase our framework by auditing multiple generative models on diverse use cases, including education, healthcare, banking, human resources, and across different modalities, from tabular, to time-series, to natural language. Our use cases demonstrate the imp
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21452;&#37325;&#30446;&#26631;GAN&#65292;&#36890;&#36807;&#20351;&#29992;&#21487;&#35843;&#30340;$\alpha$-loss&#26469;&#24314;&#27169;&#27599;&#20010;&#30446;&#26631;&#12290;&#22312;&#36275;&#22815;&#22823;&#30340;&#26679;&#26412;&#25968;&#21644;&#23481;&#37327;&#19979;&#65292;&#36825;&#31867;GAN&#30340;&#38750;&#38646;&#21644;&#28216;&#25103;&#31616;&#21270;&#20026;&#26368;&#23567;&#21270;$f$-&#25955;&#24230;&#12290;&#26368;&#21518;&#65292;&#35843;&#25972;$(\alpha_D,\alpha_G)$&#21487;&#20197;&#32531;&#35299;&#35757;&#32451;&#19981;&#31283;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.14320</link><description>&lt;p&gt;
$(\alpha_D,\alpha_G)$-GANs&#65306;&#36890;&#36807;&#21452;&#37325;&#30446;&#26631;&#26469;&#35299;&#20915;GAN&#35757;&#32451;&#19981;&#31283;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
$(\alpha_D,\alpha_G)$-GANs: Addressing GAN Training Instabilities via Dual Objectives. (arXiv:2302.14320v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.14320
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21452;&#37325;&#30446;&#26631;GAN&#65292;&#36890;&#36807;&#20351;&#29992;&#21487;&#35843;&#30340;$\alpha$-loss&#26469;&#24314;&#27169;&#27599;&#20010;&#30446;&#26631;&#12290;&#22312;&#36275;&#22815;&#22823;&#30340;&#26679;&#26412;&#25968;&#21644;&#23481;&#37327;&#19979;&#65292;&#36825;&#31867;GAN&#30340;&#38750;&#38646;&#21644;&#28216;&#25103;&#31616;&#21270;&#20026;&#26368;&#23567;&#21270;$f$-&#25955;&#24230;&#12290;&#26368;&#21518;&#65292;&#35843;&#25972;$(\alpha_D,\alpha_G)$&#21487;&#20197;&#32531;&#35299;&#35757;&#32451;&#19981;&#31283;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#35299;&#20915;GAN&#30340;&#35757;&#32451;&#19981;&#31283;&#23450;&#24615;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31867;&#20855;&#26377;&#19981;&#21516;&#20215;&#20540;&#20989;&#25968;&#65288;&#30446;&#26631;&#65289;&#30340;&#21452;&#37325;&#30446;&#26631;GAN&#65292;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#20351;&#29992;&#21487;&#35843;&#30340;&#20998;&#31867;&#25439;&#22833;&#8212;&#8212;$\alpha$-loss&#26469;&#24314;&#27169;&#27599;&#20010;&#30446;&#26631;&#65292;&#20197;&#24471;&#21040;&#30001;$(\alpha_D,\alpha_G)\in(0,\infty]^2$&#21442;&#25968;&#21270;&#30340;$(\alpha_D,\alpha_G)$-GAN&#12290;&#23545;&#20110;&#36275;&#22815;&#22823;&#30340;&#26679;&#26412;&#25968;&#21644;G&#12289;D&#30340;&#23481;&#37327;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;$(\alpha_D,\alpha_G)$&#30340;&#36866;&#24403;&#26465;&#20214;&#19979;&#65292;&#23548;&#33268;&#30340;&#38750;&#38646;&#21644;&#28216;&#25103;&#31616;&#21270;&#20026;&#26368;&#23567;&#21270;$f$-&#25955;&#24230;&#12290;&#22312;&#26377;&#38480;&#30340;&#26679;&#26412;&#25968;&#21644;&#23481;&#37327;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#23450;&#20041;&#20272;&#35745;&#35823;&#24046;&#65292;&#20197;&#37327;&#21270;&#30456;&#23545;&#20110;&#26080;&#38480;&#26679;&#26412;&#19979;&#30340;&#26368;&#20248;&#35774;&#23450;&#32780;&#35328;&#29983;&#25104;&#22120;&#24615;&#33021;&#30340;&#24046;&#36317;&#65292;&#24182;&#24471;&#21040;&#20102;&#36825;&#20010;&#35823;&#24046;&#30340;&#19978;&#30028;&#65292;&#35777;&#26126;&#20102;&#22312;&#26576;&#20123;&#26465;&#20214;&#19979;&#23427;&#30340;&#38454;&#26377;&#25928;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#24378;&#35843;&#20102;&#35843;&#25972;$(\alpha_D,\alpha_G)$&#22312;&#32531;&#35299;&#21512;&#25104;2D&#39640;&#26031;&#28151;&#21512;&#38382;&#39064;&#30340;&#35757;&#32451;&#19981;&#31283;&#23450;&#24615;&#26041;&#38754;&#30340;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
In an effort to address the training instabilities of GANs, we introduce a class of dual-objective GANs with different value functions (objectives) for the generator (G) and discriminator (D). In particular, we model each objective using $\alpha$-loss, a tunable classification loss, to obtain $(\alpha_D,\alpha_G)$-GANs, parameterized by $(\alpha_D,\alpha_G)\in (0,\infty]^2$. For sufficiently large number of samples and capacities for G and D, we show that the resulting non-zero sum game simplifies to minimizing an $f$-divergence under appropriate conditions on $(\alpha_D,\alpha_G)$. In the finite sample and capacity setting, we define estimation error to quantify the gap in the generator's performance relative to the optimal setting with infinite samples and obtain upper bounds on this error, showing it to be order optimal under certain conditions. Finally, we highlight the value of tuning $(\alpha_D,\alpha_G)$ in alleviating training instabilities for the synthetic 2D Gaussian mixture
&lt;/p&gt;</description></item><item><title>&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#26159;&#19968;&#31181;&#26426;&#22120;&#23398;&#20064;&#33539;&#24335;&#65292;&#26088;&#22312;&#20174;&#25968;&#25454;&#27969;&#20013;&#36873;&#25321;&#26368;&#20855;&#20449;&#24687;&#37327;&#30340;&#25968;&#25454;&#28857;&#36827;&#34892;&#26631;&#27880;&#12290;&#26412;&#25991;&#32508;&#36848;&#20102;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#30340;&#26368;&#26032;&#36827;&#23637;&#12289;&#22522;&#20110;&#27969;&#30340;&#20027;&#21160;&#23398;&#20064;&#30340;&#20027;&#35201;&#25361;&#25112;&#21644;&#26426;&#36935;&#12289;&#29992;&#20110;&#36873;&#25321;&#20449;&#24687;&#26679;&#26412;&#30340;&#31574;&#30053;&#20197;&#21450;&#35813;&#33539;&#24335;&#20013;&#19981;&#21516;&#30340;&#35780;&#20272;&#25351;&#26631;&#12290;</title><link>http://arxiv.org/abs/2302.08893</link><description>&lt;p&gt;
&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
A survey on online active learning. (arXiv:2302.08893v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.08893
&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#26159;&#19968;&#31181;&#26426;&#22120;&#23398;&#20064;&#33539;&#24335;&#65292;&#26088;&#22312;&#20174;&#25968;&#25454;&#27969;&#20013;&#36873;&#25321;&#26368;&#20855;&#20449;&#24687;&#37327;&#30340;&#25968;&#25454;&#28857;&#36827;&#34892;&#26631;&#27880;&#12290;&#26412;&#25991;&#32508;&#36848;&#20102;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#30340;&#26368;&#26032;&#36827;&#23637;&#12289;&#22522;&#20110;&#27969;&#30340;&#20027;&#21160;&#23398;&#20064;&#30340;&#20027;&#35201;&#25361;&#25112;&#21644;&#26426;&#36935;&#12289;&#29992;&#20110;&#36873;&#25321;&#20449;&#24687;&#26679;&#26412;&#30340;&#31574;&#30053;&#20197;&#21450;&#35813;&#33539;&#24335;&#20013;&#19981;&#21516;&#30340;&#35780;&#20272;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#26159;&#19968;&#31181;&#26426;&#22120;&#23398;&#20064;&#33539;&#24335;&#65292;&#26088;&#22312;&#20174;&#25968;&#25454;&#27969;&#20013;&#36873;&#25321;&#26368;&#20855;&#20449;&#24687;&#37327;&#30340;&#25968;&#25454;&#28857;&#36827;&#34892;&#26631;&#27880;&#12290;&#36817;&#24180;&#26469;&#65292;&#38543;&#30528;&#25968;&#25454;&#20165;&#20197;&#26410;&#26631;&#35760;&#24418;&#24335;&#21487;&#29992;&#30340;&#23454;&#38469;&#24212;&#29992;&#26085;&#30410;&#22686;&#22810;&#65292;&#26368;&#23567;&#21270;&#19982;&#25910;&#38598;&#26631;&#35760;&#35266;&#27979;&#30456;&#20851;&#30340;&#25104;&#26412;&#38382;&#39064;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#26631;&#27880;&#27599;&#20010;&#35266;&#27979;&#21487;&#20197;&#32791;&#36153;&#22823;&#37327;&#30340;&#26102;&#38388;&#21644;&#25104;&#26412;&#65292;&#20351;&#24471;&#33719;&#21462;&#22823;&#37327;&#26631;&#35760;&#25968;&#25454;&#21464;&#24471;&#22256;&#38590;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#38382;&#39064;&#65292;&#35768;&#22810;&#20027;&#21160;&#23398;&#20064;&#31574;&#30053;&#24050;&#32463;&#25552;&#20986;&#65292;&#26088;&#22312;&#36873;&#25321;&#26368;&#20855;&#20449;&#24687;&#37327;&#30340;&#35266;&#27979;&#36827;&#34892;&#26631;&#35760;&#65292;&#20197;&#25552;&#39640;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#24191;&#27867;&#22320;&#20998;&#20026;&#20004;&#31867;&#65306;&#38745;&#24577;&#22522;&#20110;&#27744;&#30340;&#21644;&#22522;&#20110;&#27969;&#30340;&#20027;&#21160;&#23398;&#20064;&#12290;&#22522;&#20110;&#27744;&#30340;&#20027;&#21160;&#23398;&#20064;&#28041;&#21450;&#20174;&#23553;&#38381;&#30340;&#26410;&#26631;&#35760;&#25968;&#25454;&#27744;&#20013;&#36873;&#25321;&#19968;&#37096;&#20998;&#35266;&#27979;&#65292;&#24050;&#25104;&#20026;&#35768;&#22810;&#35843;&#26597;&#21644;&#25991;&#29486;&#32508;&#36848;&#30340;&#37325;&#28857;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#22312;&#32447;&#25968;&#25454;&#27969;&#30340;&#19981;&#26029;&#22686;&#21152;&#65292;&#22522;&#20110;&#27969;&#30340;&#20027;&#21160;&#23398;&#20064;&#31574;&#30053;&#21464;&#24471;&#26356;&#21152;&#21560;&#24341;&#20154;&#65292;&#22240;&#20026;&#23427;&#20204;&#20801;&#35768;&#27169;&#22411;&#36866;&#24212;&#26032;&#36827;&#25968;&#25454;&#12290;&#22312;&#26412;&#32508;&#36848;&#20013;&#65292;&#25105;&#20204;&#32508;&#36848;&#20102;&#22312;&#32447;&#20027;&#21160;&#23398;&#20064;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#35752;&#35770;&#20102;&#22522;&#20110;&#27969;&#30340;&#20027;&#21160;&#23398;&#20064;&#30340;&#20027;&#35201;&#25361;&#25112;&#21644;&#26426;&#36935;&#12289;&#29992;&#20110;&#36873;&#25321;&#20449;&#24687;&#26679;&#26412;&#30340;&#31574;&#30053;&#20197;&#21450;&#35813;&#33539;&#20363;&#20013;&#19981;&#21516;&#30340;&#35780;&#20272;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
Online active learning is a paradigm in machine learning that aims to select the most informative data points to label from a data stream. The problem of minimizing the cost associated with collecting labeled observations has gained a lot of attention in recent years, particularly in real-world applications where data is only available in an unlabeled form. Annotating each observation can be time-consuming and costly, making it difficult to obtain large amounts of labeled data. To overcome this issue, many active learning strategies have been proposed in the last decades, aiming to select the most informative observations for labeling in order to improve the performance of machine learning models. These approaches can be broadly divided into two categories: static pool-based and stream-based active learning. Pool-based active learning involves selecting a subset of observations from a closed pool of unlabeled data, and it has been the focus of many surveys and literature reviews. Howev
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#21033;&#29992;&#27010;&#29575;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#21487;&#20197;&#24674;&#22797;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#36755;&#20837;&#30340;&#27491;&#30830;&#20272;&#35745;&#65292;&#36890;&#36807;&#25193;&#23637;InfoNCE&#30446;&#26631;&#21644;&#32534;&#30721;&#22120;&#20197;&#39044;&#27979;&#28508;&#21464;&#37327;&#20998;&#24067;&#26469;&#23454;&#29616;&#65292;&#22312;&#35745;&#31639;&#24050;&#30693;&#26597;&#35810;&#22270;&#20687;&#30340;&#21487;&#20449;&#21306;&#38388;&#26041;&#38754;&#20855;&#26377;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2302.02865</link><description>&lt;p&gt;
&#27010;&#29575;&#23545;&#27604;&#23398;&#20064;&#24674;&#22797;&#20102;&#19981;&#30830;&#23450;&#24615;&#36755;&#20837;&#30340;&#27491;&#30830;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Probabilistic Contrastive Learning Recovers the Correct Aleatoric Uncertainty of Ambiguous Inputs. (arXiv:2302.02865v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.02865
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#21033;&#29992;&#27010;&#29575;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#21487;&#20197;&#24674;&#22797;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#36755;&#20837;&#30340;&#27491;&#30830;&#20272;&#35745;&#65292;&#36890;&#36807;&#25193;&#23637;InfoNCE&#30446;&#26631;&#21644;&#32534;&#30721;&#22120;&#20197;&#39044;&#27979;&#28508;&#21464;&#37327;&#20998;&#24067;&#26469;&#23454;&#29616;&#65292;&#22312;&#35745;&#31639;&#24050;&#30693;&#26597;&#35810;&#22270;&#20687;&#30340;&#21487;&#20449;&#21306;&#38388;&#26041;&#38754;&#20855;&#26377;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#23545;&#27604;&#23398;&#20064;&#32534;&#30721;&#22120;&#34987;&#35777;&#26126;&#21487;&#20197;&#32763;&#36716;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#65306;&#23427;&#20204;&#21487;&#20197;&#23558;&#27599;&#20010;&#36755;&#20837;&#65288;&#22914;&#22270;&#20687;&#65289;&#32534;&#30721;&#25104;&#29983;&#25104;&#35813;&#22270;&#20687;&#30340;&#30495;&#23454;&#28508;&#21464;&#37327;&#65288;Zimmermann&#31561;&#20154;&#65292;2021&#65289;&#12290;&#28982;&#32780;&#65292;&#29616;&#23454;&#19990;&#30028;&#30340;&#35266;&#23519;&#32467;&#26524;&#36890;&#24120;&#23384;&#22312;&#20869;&#22312;&#30340;&#27169;&#31946;&#24615;&#12290;&#20363;&#22914;&#65292;&#22270;&#20687;&#21487;&#33021;&#27169;&#31946;&#25110;&#21482;&#26174;&#31034;3D&#29289;&#20307;&#30340;2D&#35270;&#22270;&#65292;&#22240;&#27492;&#21487;&#33021;&#26377;&#22810;&#20010;&#28508;&#21464;&#37327;&#29983;&#25104;&#23427;&#20204;&#12290;&#36825;&#20351;&#24471;&#28508;&#21464;&#37327;&#30340;&#30495;&#23454;&#21518;&#39564;&#27010;&#29575;&#20855;&#26377;&#24322;&#26041;&#24046;&#19981;&#30830;&#23450;&#24615;&#12290;&#22312;&#36825;&#31181;&#35774;&#32622;&#19979;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;&#24120;&#35265;&#30340;InfoNCE&#30446;&#26631;&#21644;&#32534;&#30721;&#22120;&#65292;&#20197;&#39044;&#27979;&#28508;&#21464;&#37327;&#20998;&#24067;&#32780;&#19981;&#26159;&#28857;&#12290;&#25105;&#20204;&#35777;&#26126;&#36825;&#20123;&#20998;&#24067;&#24674;&#22797;&#20102;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#30340;&#27491;&#30830;&#21518;&#39564;&#20998;&#24067;&#65292;&#21253;&#25324;&#20854;&#19981;&#30830;&#23450;&#24615;&#27700;&#24179;&#30340;&#20272;&#35745;&#65292;&#35813;&#20272;&#35745;&#23384;&#22312;&#28508;&#21464;&#37327;&#31354;&#38388;&#30340;&#26059;&#36716;&#12290;&#38500;&#20102;&#25552;&#20379;&#26657;&#20934;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#20043;&#22806;&#65292;&#36825;&#20123;&#21518;&#39564;&#20998;&#24067;&#36824;&#20801;&#35768;&#22312;&#22270;&#20687;&#26816;&#32034;&#20013;&#35745;&#31639;&#21487;&#20449;&#21306;&#38388;&#12290;&#23427;&#20204;&#21253;&#25324;&#20855;&#26377;&#19982;&#32473;&#23450;&#26597;&#35810;&#30456;&#21516;&#30340;&#28508;&#21464;&#37327;&#30340;&#22270;&#20687;&#12290;
&lt;/p&gt;
&lt;p&gt;
Contrastively trained encoders have recently been proven to invert the data-generating process: they encode each input, e.g., an image, into the true latent vector that generated the image (Zimmermann et al., 2021). However, real-world observations often have inherent ambiguities. For instance, images may be blurred or only show a 2D view of a 3D object, so multiple latents could have generated them. This makes the true posterior for the latent vector probabilistic with heteroscedastic uncertainty. In this setup, we extend the common InfoNCE objective and encoders to predict latent distributions instead of points. We prove that these distributions recover the correct posteriors of the data-generating process, including its level of aleatoric uncertainty, up to a rotation of the latent space. In addition to providing calibrated uncertainty estimates, these posteriors allow the computation of credible intervals in image retrieval. They comprise images with the same latent as a given quer
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28508;&#21464;&#37327;&#21644;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#30340;&#21487;&#36776;&#35782;&#24615;&#38382;&#39064;&#65292;&#23637;&#31034;&#20102;&#22914;&#20309;&#25512;&#24191;&#29616;&#26377;&#30340;&#27169;&#22411;&#65292;&#20351;&#20854;&#21487;&#20197;&#29992;&#20110;&#38750;&#32447;&#24615;&#38382;&#39064;&#65292;&#24182;&#19988;&#20173;&#28982;&#20445;&#25345;&#21487;&#36776;&#35782;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.02672</link><description>&lt;p&gt;
&#28508;&#21464;&#37327;&#21644;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#30340;&#21487;&#36776;&#35782;&#24615;&#65306;&#20174;&#32447;&#24615;&#21040;&#38750;&#32447;&#24615;
&lt;/p&gt;
&lt;p&gt;
Identifiability of latent-variable and structural-equation models: from linear to nonlinear. (arXiv:2302.02672v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.02672
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28508;&#21464;&#37327;&#21644;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#30340;&#21487;&#36776;&#35782;&#24615;&#38382;&#39064;&#65292;&#23637;&#31034;&#20102;&#22914;&#20309;&#25512;&#24191;&#29616;&#26377;&#30340;&#27169;&#22411;&#65292;&#20351;&#20854;&#21487;&#20197;&#29992;&#20110;&#38750;&#32447;&#24615;&#38382;&#39064;&#65292;&#24182;&#19988;&#20173;&#28982;&#20445;&#25345;&#21487;&#36776;&#35782;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22810;&#21464;&#37327;&#32479;&#35745;&#23398;&#20013;&#65292;&#32447;&#24615;&#39640;&#26031;&#27169;&#22411;&#36890;&#24120;&#26159;&#19981;&#21487;&#36776;&#35782;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#25512;&#24191;&#29616;&#26377;&#30340;&#27169;&#22411;&#65292;&#20351;&#20854;&#21487;&#20197;&#29992;&#20110;&#38750;&#32447;&#24615;&#38382;&#39064;&#65292;&#24182;&#19988;&#20173;&#28982;&#20445;&#25345;&#21487;&#36776;&#35782;&#24615;&#12290;&#36890;&#36807;&#24341;&#20837;&#26102;&#38388;&#24207;&#21015;&#25110;&#35266;&#27979;&#21040;&#30340;&#36741;&#21161;&#21464;&#37327;&#65292;&#25105;&#20204;&#21487;&#20197;&#20811;&#26381;&#38750;&#39640;&#26031;&#24615;&#26159;&#21542;&#36275;&#22815;&#30340;&#38480;&#21046;&#65292;&#26469;&#23454;&#29616;&#36825;&#26679;&#30340;&#21487;&#36776;&#35782;&#24615;&#12290;&#26412;&#25991;&#22238;&#39038;&#20102;&#32447;&#24615;&#21644;&#38750;&#32447;&#24615;&#21487;&#36776;&#35782;&#24615;&#29702;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
An old problem in multivariate statistics is that linear Gaussian models are often unidentifiable, i.e. some parameters cannot be uniquely estimated. In factor (component) analysis, an orthogonal rotation of the factors is unidentifiable, while in linear regression, the direction of effect cannot be identified. For such linear models, non-Gaussianity of the (latent) variables has been shown to provide identifiability. In the case of factor analysis, this leads to independent component analysis, while in the case of the direction of effect, non-Gaussian versions of structural equation modelling solve the problem. More recently, we have shown how even general nonparametric nonlinear versions of such models can be estimated. Non-Gaussianity is not enough in this case, but assuming we have time series, or that the distributions are suitably modulated by some observed auxiliary variables, the models are identifiable. This paper reviews the identifiability theory for the linear and nonlinear
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#23545;&#20110;&#24471;&#20998;&#27169;&#22411;&#32780;&#35328;&#65292;&#20174;&#19968;&#20010;&#27010;&#29575;&#20998;&#24067;&#20013;&#25277;&#26679;&#30340;&#26680;&#24515;&#26426;&#21046;&#65292;&#22312;$L^2(p)$&#20934;&#30830;&#20272;&#35745;$\nabla \ln p$&#21518;&#21487;&#20197;&#22810;&#39033;&#24335;&#25910;&#25947;&#12290;&#21516;&#26102;&#25552;&#20379;&#20102;&#23545;&#22522;&#20110;&#24471;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#20026;&#20351;&#29992;&#36864;&#28779;&#31243;&#24207;&#29983;&#25104;&#26679;&#26412;&#25552;&#20379;&#20102;&#29702;&#35770;&#22522;&#30784;&#12290;</title><link>http://arxiv.org/abs/2206.06227</link><description>&lt;p&gt;
&#24471;&#20998;&#27169;&#22411;&#30340;&#22810;&#39033;&#24335;&#22797;&#26434;&#24230;&#30340;&#37325;&#35201;&#24615;&#35777;&#26126;
&lt;/p&gt;
&lt;p&gt;
Convergence for score-based generative modeling with polynomial complexity. (arXiv:2206.06227v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.06227
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#23545;&#20110;&#24471;&#20998;&#27169;&#22411;&#32780;&#35328;&#65292;&#20174;&#19968;&#20010;&#27010;&#29575;&#20998;&#24067;&#20013;&#25277;&#26679;&#30340;&#26680;&#24515;&#26426;&#21046;&#65292;&#22312;$L^2(p)$&#20934;&#30830;&#20272;&#35745;$\nabla \ln p$&#21518;&#21487;&#20197;&#22810;&#39033;&#24335;&#25910;&#25947;&#12290;&#21516;&#26102;&#25552;&#20379;&#20102;&#23545;&#22522;&#20110;&#24471;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#20026;&#20351;&#29992;&#36864;&#28779;&#31243;&#24207;&#29983;&#25104;&#26679;&#26412;&#25552;&#20379;&#20102;&#29702;&#35770;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24471;&#20998;&#27169;&#22411;&#65288;SGM&#65289;&#26159;&#19968;&#31181;&#23398;&#20064;&#27010;&#29575;&#20998;&#24067;&#24182;&#29983;&#25104;&#26356;&#22810;&#26679;&#26412;&#30340;&#39640;&#25928;&#26041;&#27861;&#12290;&#26412;&#25991;&#35777;&#26126;&#20102;SGM&#32972;&#21518;&#30340;&#26680;&#24515;&#26426;&#21046;&#21363;&#22312;$L^2(p)$&#20934;&#30830;&#20272;&#35745;$\nabla \ln p$&#21518;&#20174;&#27010;&#29575;&#23494;&#24230;$p$&#20013;&#25277;&#26679;&#30340;&#22810;&#39033;&#24335;&#25910;&#25947;&#20445;&#35777;&#12290;&#19982;&#20043;&#21069;&#30340;&#24037;&#20316;&#30456;&#27604;&#65292;&#25105;&#20204;&#19981;&#20250;&#20135;&#29983;&#38543;&#26102;&#38388;&#25351;&#25968;&#22686;&#38271;&#25110;&#36973;&#21463;&#32500;&#25968;&#28798;&#38590;&#30340;&#35823;&#24046;&#12290;&#25105;&#20204;&#30340;&#20445;&#35777;&#36866;&#29992;&#20110;&#20219;&#20309;&#24179;&#28369;&#20998;&#24067;&#65292;&#19988;&#19982;&#20854;&#23545;&#25968;Sobolev&#24120;&#25968;&#22810;&#39033;&#24335;&#30456;&#20851;&#12290;&#20351;&#29992;&#25105;&#20204;&#30340;&#20445;&#35777;&#65292;&#25105;&#20204;&#23545;&#22522;&#20110;&#24471;&#20998;&#30340;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#23558;&#30333;&#22122;&#22768;&#36755;&#20837;&#36716;&#25442;&#20026;&#20174;&#19981;&#21516;&#22122;&#22768;&#23610;&#24230;&#32473;&#23450;&#24471;&#20998;&#20272;&#35745;&#30340;&#23398;&#20064;&#25968;&#25454;&#20998;&#24067;&#30340;&#26679;&#26412;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#20026;&#20351;&#29992;&#36864;&#28779;&#31243;&#24207;&#29983;&#25104;&#22909;&#30340;&#26679;&#26412;&#25552;&#20379;&#20102;&#29702;&#35770;&#22522;&#30784;&#65292;&#22240;&#20026;&#25105;&#20204;&#30340;&#35777;&#26126;&#22522;&#26412;&#19978;&#26159;&#20381;&#36182;&#20110;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Score-based generative modeling (SGM) is a highly successful approach for learning a probability distribution from data and generating further samples. We prove the first polynomial convergence guarantees for the core mechanic behind SGM: drawing samples from a probability density $p$ given a score estimate (an estimate of $\nabla \ln p$) that is accurate in $L^2(p)$. Compared to previous works, we do not incur error that grows exponentially in time or that suffers from a curse of dimensionality. Our guarantee works for any smooth distribution and depends polynomially on its log-Sobolev constant. Using our guarantee, we give a theoretical analysis of score-based generative modeling, which transforms white-noise input into samples from a learned data distribution given score estimates at different noise scales. Our analysis gives theoretical grounding to the observation that an annealed procedure is required in practice to generate good samples, as our proof depends essentially on using
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#39318;&#20010;&#39640;&#32500;&#20581;&#22766;&#32479;&#35745;&#23398;&#27969;&#31639;&#27861;&#65292;&#20855;&#26377;&#20960;&#20046;&#26368;&#20248;&#30340;&#23384;&#20648;&#38656;&#27714;&#65292;&#29305;&#21035;&#26159;&#22312;Huber&#27745;&#26579;&#27169;&#22411;&#19979;&#30340;&#39640;&#32500;&#20581;&#22766;&#22343;&#20540;&#20272;&#35745;&#20219;&#21153;&#20013;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#39640;&#25928;&#30340;&#21333;&#36941;&#27969;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2204.12399</link><description>&lt;p&gt;
&#38754;&#21521;&#39640;&#32500;&#20581;&#22766;&#32479;&#35745;&#23398;&#30340;&#27969;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Streaming Algorithms for High-Dimensional Robust Statistics. (arXiv:2204.12399v2 [cs.DS] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.12399
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#39318;&#20010;&#39640;&#32500;&#20581;&#22766;&#32479;&#35745;&#23398;&#27969;&#31639;&#27861;&#65292;&#20855;&#26377;&#20960;&#20046;&#26368;&#20248;&#30340;&#23384;&#20648;&#38656;&#27714;&#65292;&#29305;&#21035;&#26159;&#22312;Huber&#27745;&#26579;&#27169;&#22411;&#19979;&#30340;&#39640;&#32500;&#20581;&#22766;&#22343;&#20540;&#20272;&#35745;&#20219;&#21153;&#20013;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;&#39640;&#25928;&#30340;&#21333;&#36941;&#27969;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#27969;&#27169;&#22411;&#19979;&#30340;&#39640;&#32500;&#20581;&#22766;&#32479;&#35745;&#23398;&#38382;&#39064;&#12290;&#26368;&#36817;&#30340;&#19968;&#20123;&#24037;&#20316;&#38024;&#23545;&#19968;&#31995;&#21015;&#39640;&#32500;&#20581;&#22766;&#20272;&#35745;&#20219;&#21153;&#25552;&#20986;&#20102;&#35745;&#31639;&#26377;&#25928;&#29575;&#30340;&#31639;&#27861;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#25152;&#26377;&#20043;&#21069;&#30340;&#31639;&#27861;&#37117;&#38656;&#35201;&#23384;&#20648;&#25972;&#20010;&#25968;&#25454;&#38598;&#65292;&#20351;&#24471;&#20869;&#23384;&#33267;&#23569;&#21576;&#20108;&#27425;&#26041;&#19982;&#32500;&#24230;&#21516;&#38454;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#39318;&#20010;&#39640;&#32500;&#20581;&#22766;&#32479;&#35745;&#23398;&#27969;&#31639;&#27861;&#65292;&#20854;&#20855;&#26377;&#20960;&#20046;&#26368;&#20248;&#30340;&#23384;&#20648;&#38656;&#27714;&#65288;&#20197;&#23545;&#25968;&#22240;&#23376;&#34920;&#31034;&#65289;&#12290;&#26412;&#25991;&#20027;&#35201;&#32467;&#26524;&#26159;&#22312;Huber&#27745;&#26579;&#27169;&#22411;&#19979;&#30340;&#39640;&#32500;&#20581;&#22766;&#22343;&#20540;&#20272;&#35745;&#20219;&#21153;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#19968;&#20010;&#39640;&#25928;&#30340;&#21333;&#36941;&#27969;&#31639;&#27861;&#65292;&#20855;&#26377;&#20960;&#20046;&#26368;&#20248;&#30340;&#35823;&#24046;&#20445;&#35777;&#21644;&#31354;&#38388;&#22797;&#26434;&#24230;&#20960;&#20046;&#32447;&#24615;&#20110;&#32500;&#24230;&#12290;&#20316;&#20026;&#25512;&#35770;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#20960;&#20010;&#26356;&#22797;&#26434;&#30340;&#20219;&#21153;&#30340;&#20960;&#20046;&#26368;&#20248;&#31354;&#38388;&#22797;&#26434;&#24230;&#30340;&#27969;&#31639;&#27861;&#65292;&#21253;&#25324;&#20581;&#22766;&#21327;&#26041;&#24046;&#20272;&#35745;&#65292;&#20581;&#22766;&#22238;&#24402;&#65292;&#26356;&#26222;&#36941;&#30340;&#20581;&#22766;&#38543;&#26426;&#20248;&#21270;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study high-dimensional robust statistics tasks in the streaming model. A recent line of work obtained computationally efficient algorithms for a range of high-dimensional robust estimation tasks. Unfortunately, all previous algorithms require storing the entire dataset, incurring memory at least quadratic in the dimension. In this work, we develop the first efficient streaming algorithms for high-dimensional robust statistics with near-optimal memory requirements (up to logarithmic factors). Our main result is for the task of high-dimensional robust mean estimation in (a strengthening of) Huber's contamination model. We give an efficient single-pass streaming algorithm for this task with near-optimal error guarantees and space complexity nearly-linear in the dimension. As a corollary, we obtain streaming algorithms with near-optimal space complexity for several more complex tasks, including robust covariance estimation, robust regression, and more generally robust stochastic optimiz
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#39640;&#32500;&#31232;&#30095;&#21487;&#21152;&#20989;&#25968;&#30340;&#30828;&#23725;&#38543;&#26426;&#29305;&#24449;&#25193;&#23637;&#26041;&#27861;&#65288;HARFE&#65289;&#27169;&#22411;&#65292;&#23427;&#21487;&#20197;&#36890;&#36807;&#24212;&#29992;&#22522;&#20110;&#30828;&#38408;&#20540;&#36861;&#36394;&#30340;&#31639;&#27861;&#26469;&#36827;&#34892;&#36817;&#20284;&#35745;&#31639;&#65292;&#21516;&#26102;&#21033;&#29992;&#31232;&#30095;&#23725;&#22238;&#24402;&#65288;SRR&#65289;&#34920;&#36798;&#24335;&#26469;&#21462;&#24471;&#31232;&#30095;&#27169;&#22411;&#36873;&#25321;&#21644;&#23725;&#22238;&#24402;&#24179;&#28369;&#20043;&#38388;&#30340;&#24179;&#34913;&#65292;&#30456;&#27604;&#20854;&#20182;&#31639;&#27861;&#65292;HARFE&#26041;&#27861;&#22312;&#21512;&#25104;&#25968;&#25454;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#20855;&#26377;&#26356;&#20302;&#30340;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2202.02877</link><description>&lt;p&gt;
HARFE: &#30828;&#23725;&#38543;&#26426;&#29305;&#24449;&#25193;&#23637;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
HARFE: Hard-Ridge Random Feature Expansion. (arXiv:2202.02877v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.02877
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#39640;&#32500;&#31232;&#30095;&#21487;&#21152;&#20989;&#25968;&#30340;&#30828;&#23725;&#38543;&#26426;&#29305;&#24449;&#25193;&#23637;&#26041;&#27861;&#65288;HARFE&#65289;&#27169;&#22411;&#65292;&#23427;&#21487;&#20197;&#36890;&#36807;&#24212;&#29992;&#22522;&#20110;&#30828;&#38408;&#20540;&#36861;&#36394;&#30340;&#31639;&#27861;&#26469;&#36827;&#34892;&#36817;&#20284;&#35745;&#31639;&#65292;&#21516;&#26102;&#21033;&#29992;&#31232;&#30095;&#23725;&#22238;&#24402;&#65288;SRR&#65289;&#34920;&#36798;&#24335;&#26469;&#21462;&#24471;&#31232;&#30095;&#27169;&#22411;&#36873;&#25321;&#21644;&#23725;&#22238;&#24402;&#24179;&#28369;&#20043;&#38388;&#30340;&#24179;&#34913;&#65292;&#30456;&#27604;&#20854;&#20182;&#31639;&#27861;&#65292;HARFE&#26041;&#27861;&#22312;&#21512;&#25104;&#25968;&#25454;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#20855;&#26377;&#26356;&#20302;&#30340;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#38024;&#23545;&#39640;&#32500;&#31232;&#30095;&#21487;&#21152;&#20989;&#25968;&#65292;&#25552;&#20986;&#19968;&#31181;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#8212;&#8212;&#30828;&#23725;&#38543;&#26426;&#29305;&#24449;&#25193;&#23637;&#26041;&#27861;&#65288;HARFE&#65289;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#22522;&#20110;&#30828;&#38408;&#20540;&#36861;&#36394;&#30340;&#31639;&#27861;&#65292;&#24212;&#29992;&#20110;&#31232;&#30095;&#23725;&#22238;&#24402;&#65288;SRR&#65289;&#38382;&#39064;&#65292;&#26469;&#36817;&#20284;&#35745;&#31639;&#30456;&#23545;&#20110;&#38543;&#26426;&#29305;&#24449;&#30697;&#38453;&#30340;&#31995;&#25968;&#12290;&#35813;SRR&#34920;&#36798;&#24335;&#22312;&#31232;&#30095;&#27169;&#22411;&#36873;&#25321;&#21644;&#23725;&#22238;&#24402;&#24179;&#28369;&#20043;&#38388;&#21462;&#24471;&#24179;&#34913;&#65292;&#20174;&#32780;&#26377;&#21033;&#20110;&#22788;&#29702;&#22122;&#22768;&#21644;&#24322;&#24120;&#20540;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#21305;&#37197;&#21152;&#24615;&#20989;&#25968;&#20551;&#35774;&#65292;&#25105;&#20204;&#22312;&#38543;&#26426;&#29305;&#24449;&#30697;&#38453;&#20013;&#37319;&#29992;&#20102;&#38543;&#26426;&#31232;&#30095;&#36830;&#25509;&#27169;&#24335;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;HARFE&#26041;&#27861;&#20250;&#25910;&#25947;&#33267;&#32473;&#23450;&#35823;&#24046;&#30028;&#38480;&#65292;&#20855;&#20307;&#21462;&#20915;&#20110;&#22122;&#22768;&#21644;&#31232;&#30095;&#23725;&#22238;&#24402;&#27169;&#22411;&#21442;&#25968;&#12290;&#22522;&#20110;&#21512;&#25104;&#25968;&#25454;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#30340;&#25968;&#20540;&#32467;&#26524;&#34920;&#26126;&#65292;HARFE&#26041;&#27861;&#30340;&#35823;&#24046;&#20302;&#20110;&#65288;&#25110;&#19982;&#65289;&#20854;&#20182;&#26368;&#20808;&#36827;&#31639;&#27861;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a random feature model for approximating high-dimensional sparse additive functions called the hard-ridge random feature expansion method (HARFE). This method utilizes a hard-thresholding pursuit-based algorithm applied to the sparse ridge regression (SRR) problem to approximate the coefficients with respect to the random feature matrix. The SRR formulation balances between obtaining sparse models that use fewer terms in their representation and ridge-based smoothing that tend to be robust to noise and outliers. In addition, we use a random sparse connectivity pattern in the random feature matrix to match the additive function assumption. We prove that the HARFE method is guaranteed to converge with a given error bound depending on the noise and the parameters of the sparse ridge regression model. Based on numerical results on synthetic data as well as on real datasets, the HARFE approach obtains lower (or comparable) error than other state-of-the-art algorithms.
&lt;/p&gt;</description></item></channel></rss>