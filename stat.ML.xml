<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#27979;&#35797;&#26102;&#30340;&#23545;&#25239;&#25915;&#20987;&#23545;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#30340;&#24433;&#21709;&#65292;&#24182;&#30830;&#23450;&#20102;&#22312;&#20445;&#25345;&#39044;&#27979;&#24615;&#33021;&#30340;&#24773;&#20917;&#19979;&#21487;&#20197;&#36798;&#21040;&#30340;&#26368;&#20339;&#40065;&#26834;&#24615;&#27700;&#24179;&#12290;&#35813;&#30740;&#31350;&#25581;&#31034;&#20102;&#40065;&#26834;&#24615;&#21644;&#20934;&#30830;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#24182;&#22312;&#19981;&#25439;&#23475;&#20934;&#30830;&#24615;&#30340;&#24773;&#20917;&#19979;&#25214;&#21040;&#20102;&#40065;&#26834;&#24615;&#30340;&#23454;&#29616;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2308.00556</link><description>&lt;p&gt;
&#22362;&#24378;&#30340;&#32447;&#24615;&#22238;&#24402;&#65306;&#30456;&#21464;&#21644;&#23545;&#19968;&#33324;&#33539;&#25968;&#30340;&#31934;&#30830;&#26435;&#34913;
&lt;/p&gt;
&lt;p&gt;
Robust Linear Regression: Phase-Transitions and Precise Tradeoffs for General Norms. (arXiv:2308.00556v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.00556
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#27979;&#35797;&#26102;&#30340;&#23545;&#25239;&#25915;&#20987;&#23545;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#30340;&#24433;&#21709;&#65292;&#24182;&#30830;&#23450;&#20102;&#22312;&#20445;&#25345;&#39044;&#27979;&#24615;&#33021;&#30340;&#24773;&#20917;&#19979;&#21487;&#20197;&#36798;&#21040;&#30340;&#26368;&#20339;&#40065;&#26834;&#24615;&#27700;&#24179;&#12290;&#35813;&#30740;&#31350;&#25581;&#31034;&#20102;&#40065;&#26834;&#24615;&#21644;&#20934;&#30830;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#24182;&#22312;&#19981;&#25439;&#23475;&#20934;&#30830;&#24615;&#30340;&#24773;&#20917;&#19979;&#25214;&#21040;&#20102;&#40065;&#26834;&#24615;&#30340;&#23454;&#29616;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#27979;&#35797;&#26102;&#23545;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#30340;&#23545;&#25239;&#25915;&#20987;&#23545;&#20854;&#24433;&#21709;&#65292;&#24182;&#30830;&#23450;&#20102;&#20219;&#20309;&#27169;&#22411;&#22312;&#20445;&#25345;&#32473;&#23450;&#27700;&#24179;&#30340;&#39044;&#27979;&#24615;&#33021;&#65288;&#20934;&#30830;&#24230;&#65289;&#30340;&#21516;&#26102;&#21487;&#20197;&#36798;&#21040;&#30340;&#26368;&#20339;&#40065;&#26834;&#24615;&#27700;&#24179;&#12290;&#36890;&#36807;&#23450;&#37327;&#20272;&#35745;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#22312;&#19981;&#21516;&#39046;&#22495;&#20013;&#40065;&#26834;&#24615;&#21644;&#20934;&#30830;&#24615;&#20043;&#38388;&#30340;&#22522;&#26412;&#26435;&#34913;&#12290;&#25105;&#20204;&#33719;&#24471;&#20102;&#19968;&#20010;&#26126;&#30830;&#30340;&#25551;&#36848;&#65292;&#21306;&#20998;&#20102;&#22312;&#19981;&#25439;&#23475;&#26631;&#20934;&#20934;&#30830;&#24615;&#30340;&#24773;&#20917;&#19979;&#21487;&#20197;&#23454;&#29616;&#40065;&#26834;&#24615;&#30340;&#24773;&#20917;&#19982;&#19981;&#21487;&#36991;&#20813;&#22320;&#38656;&#35201;&#26435;&#34913;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#22312;&#22810;&#31181;&#35774;&#32622;&#19979;&#36890;&#36807;&#31616;&#21333;&#30340;&#23454;&#39564;&#24471;&#21040;&#20102;&#32463;&#39564;&#35777;&#23454;&#12290;&#36825;&#39033;&#24037;&#20316;&#36866;&#29992;&#20110;&#29305;&#24449;&#21327;&#26041;&#24046;&#30697;&#38453;&#21644;&#20219;&#20309;&#24615;&#36136;&#30340;&#25915;&#20987;&#33539;&#25968;&#65292;&#24182;&#36229;&#36234;&#20102;&#20043;&#21069;&#22312;&#35813;&#39046;&#22495;&#30340;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we investigate the impact of test-time adversarial attacks on linear regression models and determine the optimal level of robustness that any model can reach while maintaining a given level of standard predictive performance (accuracy). Through quantitative estimates, we uncover fundamental tradeoffs between adversarial robustness and accuracy in different regimes. We obtain a precise characterization which distinguishes between regimes where robustness is achievable without hurting standard accuracy and regimes where a tradeoff might be unavoidable. Our findings are empirically confirmed with simple experiments that represent a variety of settings. This work applies to feature covariance matrices and attack norms of any nature, and extends beyond previous works in this area.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21452;&#37325;&#31283;&#20581;&#30340;&#23454;&#20363;&#37325;&#26032;&#21152;&#26435;&#23545;&#25239;&#35757;&#32451;&#26694;&#26550;&#65292;&#36890;&#36807;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#65288;DRO&#65289;&#25216;&#26415;&#33719;&#24471;&#37325;&#35201;&#24615;&#26435;&#37325;&#65292;&#24182;&#22312;&#26368;&#33030;&#24369;&#30340;&#31034;&#20363;&#19978;&#25552;&#39640;&#31283;&#20581;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.00311</link><description>&lt;p&gt;
&#21452;&#37325;&#31283;&#20581;&#30340;&#23454;&#20363;&#37325;&#26032;&#21152;&#26435;&#23545;&#25239;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Doubly Robust Instance-Reweighted Adversarial Training. (arXiv:2308.00311v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.00311
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21452;&#37325;&#31283;&#20581;&#30340;&#23454;&#20363;&#37325;&#26032;&#21152;&#26435;&#23545;&#25239;&#35757;&#32451;&#26694;&#26550;&#65292;&#36890;&#36807;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#65288;DRO&#65289;&#25216;&#26415;&#33719;&#24471;&#37325;&#35201;&#24615;&#26435;&#37325;&#65292;&#24182;&#22312;&#26368;&#33030;&#24369;&#30340;&#31034;&#20363;&#19978;&#25552;&#39640;&#31283;&#20581;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26377;&#38480;&#30340;&#27169;&#22411;&#23481;&#37327;&#19979;&#65292;&#20026;&#23545;&#25239;&#24615;&#25968;&#25454;&#20998;&#37197;&#37325;&#35201;&#24615;&#26435;&#37325;&#22312;&#35757;&#32451;&#23545;&#25239;&#24615;&#31283;&#20581;&#32593;&#32476;&#26041;&#38754;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#23454;&#20363;&#37325;&#26032;&#21152;&#26435;&#23545;&#25239;&#35757;&#32451;&#26041;&#27861;&#20005;&#37325;&#20381;&#36182;&#20110;&#21551;&#21457;&#24335;&#31639;&#27861;&#21644;/&#25110;&#20960;&#20309;&#35299;&#37322;&#26469;&#30830;&#23450;&#36825;&#20123;&#37325;&#35201;&#24615;&#26435;&#37325;&#65292;&#20351;&#24471;&#36825;&#20123;&#31639;&#27861;&#32570;&#20047;&#20005;&#26684;&#30340;&#29702;&#35770;&#35299;&#37322;/&#20445;&#35777;&#12290;&#27492;&#22806;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#23545;&#25239;&#35757;&#32451;&#22312;&#35757;&#32451;&#20998;&#24067;&#20013;&#30340;&#31283;&#20581;&#24615;&#34920;&#29616;&#38750;&#22343;&#21248;&#65292;&#20363;&#22914;&#65292;&#26576;&#20123;&#31867;&#21035;&#30340;&#25968;&#25454;&#28857;&#27604;&#20854;&#20182;&#31867;&#21035;&#26356;&#23481;&#26131;&#21463;&#21040;&#23545;&#25239;&#24615;&#25915;&#20987;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20004;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21452;&#37325;&#31283;&#20581;&#30340;&#23454;&#20363;&#37325;&#26032;&#21152;&#26435;&#23545;&#25239;&#35757;&#32451;&#26694;&#26550;&#65292;&#36890;&#36807;&#25506;&#32034;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#65288;DRO&#65289;&#25216;&#26415;&#26469;&#33719;&#24471;&#37325;&#35201;&#24615;&#26435;&#37325;&#65292;&#24182;&#22312;&#26368;&#33030;&#24369;&#30340;&#31034;&#20363;&#19978;&#25552;&#39640;&#31283;&#20581;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Assigning importance weights to adversarial data has achieved great success in training adversarially robust networks under limited model capacity. However, existing instance-reweighted adversarial training (AT) methods heavily depend on heuristics and/or geometric interpretations to determine those importance weights, making these algorithms lack rigorous theoretical justification/guarantee. Moreover, recent research has shown that adversarial training suffers from a severe non-uniform robust performance across the training distribution, e.g., data points belonging to some classes can be much more vulnerable to adversarial attacks than others. To address both issues, in this paper, we propose a novel doubly-robust instance reweighted AT framework, which allows to obtain the importance weights via exploring distributionally robust optimization (DRO) techniques, and at the same time boosts the robustness on the most vulnerable examples. In particular, our importance weights are obtained
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#27169;&#22411;&#36873;&#25321;&#21644;&#36125;&#21494;&#26031;&#20248;&#21270;&#30456;&#32467;&#21512;&#30340;&#26041;&#27861;&#65292;&#20197;&#26356;&#24555;&#22320;&#36798;&#21040;&#20989;&#25968;&#30340;&#26368;&#20248;&#35299;&#12290;</title><link>http://arxiv.org/abs/2308.00285</link><description>&lt;p&gt;
&#36890;&#36807;&#36229;&#36125;&#21494;&#26031;&#20248;&#21270;&#36827;&#34892;&#39044;&#27979;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Predictive Modeling through Hyper-Bayesian Optimization. (arXiv:2308.00285v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.00285
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#27169;&#22411;&#36873;&#25321;&#21644;&#36125;&#21494;&#26031;&#20248;&#21270;&#30456;&#32467;&#21512;&#30340;&#26041;&#27861;&#65292;&#20197;&#26356;&#24555;&#22320;&#36798;&#21040;&#20989;&#25968;&#30340;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#22411;&#36873;&#25321;&#26159;&#22522;&#20110;&#27169;&#22411;&#30340;&#20248;&#21270;&#25216;&#26415;&#65288;&#22914;&#36125;&#21494;&#26031;&#20248;&#21270;&#65289;&#26368;&#20851;&#38190;&#30340;&#38382;&#39064;&#20043;&#19968;&#12290;&#24403;&#21069;&#30340;&#26041;&#27861;&#36890;&#24120;&#23558;&#27169;&#22411;&#36873;&#25321;&#35270;&#20026;&#19968;&#20010;&#20272;&#35745;&#38382;&#39064;&#65292;&#38656;&#35201;&#23450;&#26399;&#26356;&#26032;&#26469;&#36866;&#24212;&#20248;&#21270;&#36845;&#20195;&#20013;&#24471;&#21040;&#30340;&#35266;&#27979;&#32467;&#26524;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#21516;&#26102;&#23454;&#29616;&#39640;&#25928;&#24615;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#27169;&#22411;&#36873;&#25321;&#21644;&#36125;&#21494;&#26031;&#20248;&#21270;&#30456;&#32467;&#21512;&#30340;&#26041;&#27861;&#65292;&#20197;&#36798;&#21040;&#26356;&#24555;&#22320;&#36798;&#21040;&#20989;&#25968;&#30340;&#26368;&#20248;&#35299;&#12290;&#31639;&#27861;&#22312;&#27169;&#22411;&#31354;&#38388;&#21644;&#20989;&#25968;&#31354;&#38388;&#20043;&#38388;&#26469;&#22238;&#31227;&#21160;&#65292;&#20854;&#20013;&#25512;&#33616;&#27169;&#22411;&#30340;&#22909;&#22351;&#30001;&#19968;&#20010;&#35780;&#20998;&#20989;&#25968;&#26469;&#34913;&#37327;&#24182;&#21453;&#39304;&#65292;&#36825;&#20010;&#20989;&#25968;&#25429;&#25417;&#20102;&#27169;&#22411;&#22312;&#20989;&#25968;&#31354;&#38388;&#20013;&#23545;&#25910;&#25947;&#30340;&#24110;&#21161;&#31243;&#24230;&#12290;&#35780;&#20998;&#20989;&#25968;&#30340;&#25512;&#23548;&#26041;&#24335;&#20351;&#20854;&#25269;&#28040;&#20102;&#36125;&#21494;&#26031;&#20248;&#21270;&#22312;&#20989;&#25968;&#31354;&#38388;&#20013;&#30340;&#21160;&#24577;&#24615;&#36136;&#30340;&#24433;&#21709;&#65292;&#20174;&#32780;&#20351;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#20445;&#25345;&#31283;&#23450;&#12290;&#36825;&#31181;&#26469;&#22238;&#36845;&#20195;&#23548;&#33268;&#27169;&#22411;&#36873;&#25321;&#21644;&#36125;&#21494;&#26031;&#20248;&#21270;&#37117;&#33021;&#24555;&#36895;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model selection is an integral problem of model based optimization techniques such as Bayesian optimization (BO). Current approaches often treat model selection as an estimation problem, to be periodically updated with observations coming from the optimization iterations. In this paper, we propose an alternative way to achieve both efficiently. Specifically, we propose a novel way of integrating model selection and BO for the single goal of reaching the function optima faster. The algorithm moves back and forth between BO in the model space and BO in the function space, where the goodness of the recommended model is captured by a score function and fed back, capturing how well the model helped convergence in the function space. The score function is derived in such a way that it neutralizes the effect of the moving nature of the BO in the function space, thus keeping the model selection problem stationary. This back and forth leads to quick convergence for both model selection and BO i
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#39640;&#32500;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#20013;&#36827;&#34892;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;&#30340;&#24555;&#36895;&#19988;&#19968;&#33268;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#25340;&#25509;&#25216;&#26415;&#23454;&#29616;&#20102;&#39640;&#30830;&#23450;&#24615;&#30340;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;&#65292;&#24182;&#22312;&#21464;&#37327;&#36873;&#25321;&#21644;&#31995;&#25968;&#20272;&#35745;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2308.00251</link><description>&lt;p&gt;
&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#20013;&#30340;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;&#65306;&#19968;&#31181;&#36890;&#36807;&#25340;&#25509;&#25216;&#26415;&#30340;&#24555;&#36895;&#19988;&#19968;&#33268;&#30340;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Best-Subset Selection in Generalized Linear Models: A Fast and Consistent Algorithm via Splicing Technique. (arXiv:2308.00251v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.00251
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#39640;&#32500;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#20013;&#36827;&#34892;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;&#30340;&#24555;&#36895;&#19988;&#19968;&#33268;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#25340;&#25509;&#25216;&#26415;&#23454;&#29616;&#20102;&#39640;&#30830;&#23450;&#24615;&#30340;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;&#65292;&#24182;&#22312;&#21464;&#37327;&#36873;&#25321;&#21644;&#31995;&#25968;&#20272;&#35745;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39640;&#32500;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#20013;&#65292;&#24456;&#37325;&#35201;&#30340;&#26159;&#30830;&#23450;&#19968;&#20010;&#33021;&#20805;&#20998;&#35299;&#37322;&#21709;&#24212;&#21464;&#21270;&#30340;&#31232;&#30095;&#27169;&#22411;&#12290;&#34429;&#28982;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;&#19968;&#30452;&#34987;&#35748;&#20026;&#26159;&#36825;&#31867;&#38382;&#39064;&#30340;&#32456;&#26497;&#30446;&#26631;&#65292;&#20294;&#35201;&#21516;&#26102;&#23454;&#29616;&#35745;&#31639;&#25928;&#29575;&#21644;&#32479;&#35745;&#20445;&#35777;&#21364;&#38750;&#24120;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#30446;&#30340;&#22312;&#20110;&#21033;&#29992;&#24555;&#36895;&#31639;&#27861;&#65292;&#20197;&#39640;&#30830;&#23450;&#24615;&#36873;&#25321;&#26368;&#20339;&#23376;&#38598;&#65292;&#35299;&#20915;&#36825;&#19968;&#38590;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#24182;&#28436;&#31034;&#20102;&#19968;&#31181;&#22312;&#27491;&#21017;&#26465;&#20214;&#19979;&#23454;&#29616;&#26368;&#20339;&#23376;&#38598;&#24674;&#22797;&#30340;&#31639;&#27861;&#12290;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#19982;&#26679;&#26412;&#22823;&#23567;&#21644;&#32500;&#25968;&#30340;&#22810;&#39033;&#24335;&#32423;&#21035;&#30456;&#20851;&#12290;&#38500;&#20102;&#23637;&#31034;&#25105;&#20204;&#26041;&#27861;&#30340;&#32479;&#35745;&#29305;&#24615;&#65292;&#24191;&#27867;&#30340;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#23427;&#22312;&#21464;&#37327;&#36873;&#25321;&#21644;&#31995;&#25968;&#20272;&#35745;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;&#36816;&#34892;&#26102;&#38388;&#20998;&#26512;&#26174;&#31034;&#65292;&#19982;&#27969;&#34892;&#30340;&#21464;&#37327;&#36873;&#25321;&#24037;&#20855;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#23454;&#29616;&#23454;&#29616;&#20102;&#36817;4&#20493;&#30340;&#21152;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;
In high-dimensional generalized linear models, it is crucial to identify a sparse model that adequately accounts for response variation. Although the best subset section has been widely regarded as the Holy Grail of problems of this type, achieving either computational efficiency or statistical guarantees is challenging. In this article, we intend to surmount this obstacle by utilizing a fast algorithm to select the best subset with high certainty. We proposed and illustrated an algorithm for best subset recovery in regularity conditions. Under mild conditions, the computational complexity of our algorithm scales polynomially with sample size and dimension. In addition to demonstrating the statistical properties of our method, extensive numerical experiments reveal that it outperforms existing methods for variable selection and coefficient estimation. The runtime analysis shows that our implementation achieves approximately a fourfold speedup compared to popular variable selection tool
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25216;&#26415;&#21644;&#26041;&#27861;&#65292;&#26088;&#22312;&#36890;&#36807;&#25968;&#25454;&#39537;&#21160;&#30340;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#25552;&#21319;&#20154;&#32676;&#31649;&#29702;&#30340;&#35268;&#21010;&#21644;&#25805;&#20316;&#38454;&#27573;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#21019;&#26032;&#30340;&#25968;&#25454;&#25910;&#38598;&#25216;&#26415;&#12289;&#25968;&#25454;&#38598;&#25104;&#21644;3D&#25968;&#23383;&#23402;&#29983;&#25216;&#26415;&#65292;&#32467;&#21512;&#20154;&#24037;&#26234;&#33021;&#24037;&#20855;&#36827;&#34892;&#39118;&#38505;&#35782;&#21035;&#65292;&#24182;&#24341;&#20837;&#20102;&#34676;&#34678;&#32467;&#27169;&#22411;&#26469;&#35780;&#20272;&#21644;&#39044;&#27979;&#39118;&#38505;&#27700;&#24179;&#12290;</title><link>http://arxiv.org/abs/2308.00076</link><description>&lt;p&gt;
&#20154;&#32676;&#23433;&#20840;&#31649;&#29702;&#31995;&#32479;&#65306;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#27963;&#21160;&#20915;&#31574;&#25903;&#25345;&#30340;&#35268;&#21010;&#21644;&#25511;&#21046;
&lt;/p&gt;
&lt;p&gt;
Crowd Safety Manager: Towards Data-Driven Active Decision Support for Planning and Control of Crowd Events. (arXiv:2308.00076v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.00076
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25216;&#26415;&#21644;&#26041;&#27861;&#65292;&#26088;&#22312;&#36890;&#36807;&#25968;&#25454;&#39537;&#21160;&#30340;&#20915;&#31574;&#25903;&#25345;&#31995;&#32479;&#25552;&#21319;&#20154;&#32676;&#31649;&#29702;&#30340;&#35268;&#21010;&#21644;&#25805;&#20316;&#38454;&#27573;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#21019;&#26032;&#30340;&#25968;&#25454;&#25910;&#38598;&#25216;&#26415;&#12289;&#25968;&#25454;&#38598;&#25104;&#21644;3D&#25968;&#23383;&#23402;&#29983;&#25216;&#26415;&#65292;&#32467;&#21512;&#20154;&#24037;&#26234;&#33021;&#24037;&#20855;&#36827;&#34892;&#39118;&#38505;&#35782;&#21035;&#65292;&#24182;&#24341;&#20837;&#20102;&#34676;&#34678;&#32467;&#27169;&#22411;&#26469;&#35780;&#20272;&#21644;&#39044;&#27979;&#39118;&#38505;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25216;&#26415;&#21644;&#26041;&#27861;&#65292;&#26088;&#22312;&#22686;&#24378;&#35268;&#21010;&#21644;&#25805;&#20316;&#38454;&#27573;&#30340;&#20154;&#32676;&#31649;&#29702;&#12290;&#35813;&#26041;&#27861;&#21253;&#25324;&#21019;&#26032;&#30340;&#25968;&#25454;&#25910;&#38598;&#25216;&#26415;&#12289;&#25968;&#25454;&#38598;&#25104;&#21644;&#21487;&#35270;&#21270;&#65292;&#20351;&#29992;3D&#25968;&#23383;&#23402;&#29983;&#25216;&#26415;&#65292;&#24182;&#32467;&#21512;&#20154;&#24037;&#26234;&#33021;&#24037;&#20855;&#36827;&#34892;&#39118;&#38505;&#35782;&#21035;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#8220;&#34676;&#34678;&#32467;&#8221;&#27169;&#22411;&#65292;&#36825;&#26159;&#19968;&#20010;&#32508;&#21512;&#24615;&#26694;&#26550;&#65292;&#26088;&#22312;&#35780;&#20272;&#21644;&#39044;&#27979;&#39118;&#38505;&#27700;&#24179;&#12290;&#35813;&#27169;&#22411;&#32467;&#21512;&#20102;&#23458;&#35266;&#20272;&#35745;&#21644;&#39044;&#27979;&#65292;&#22914;&#20132;&#36890;&#27969;&#37327;&#36816;&#33829;&#21644;&#25317;&#25380;&#31243;&#24230;&#65292;&#20197;&#21450;&#21508;&#31181;&#24694;&#21270;&#22240;&#32032;&#65292;&#22914;&#22825;&#27668;&#26465;&#20214;&#12289;&#24773;&#32490;&#21644;&#28216;&#23458;&#30340;&#30446;&#30340;&#65292;&#20197;&#35780;&#20272;&#28508;&#22312;&#20107;&#20214;&#39118;&#38505;&#12290;&#25552;&#20986;&#30340;&#26694;&#26550;&#24212;&#29992;&#20110;Scheveningen&#30340;&#20154;&#32676;&#23433;&#20840;&#31649;&#29702;&#39033;&#30446;&#65292;&#20854;&#20013;DigiTwin&#22522;&#20110;&#20016;&#23500;&#30340;&#23454;&#26102;&#25968;&#25454;&#26469;&#28304;&#36827;&#34892;&#24320;&#21457;&#12290;&#19968;&#20010;&#20540;&#24471;&#27880;&#24847;&#30340;&#25968;&#25454;&#26469;&#28304;&#26159;Resono&#65292;&#25552;&#20379;&#35775;&#23458;&#25968;&#37327;&#21644;&#21160;&#21521;&#30340;&#35265;&#35299;&#65292;&#20805;&#20998;&#21033;&#29992;&#20102;&#19968;&#32452;
&lt;/p&gt;
&lt;p&gt;
This paper presents novel technology and methodology aimed at enhancing crowd management in both the planning and operational phases. The approach encompasses innovative data collection techniques, data integration, and visualization using a 3D Digital Twin, along with the incorporation of artificial intelligence (AI) tools for risk identification. The paper introduces the Bowtie model, a comprehensive framework designed to assess and predict risk levels. The model combines objective estimations and predictions, such as traffic flow operations and crowdedness levels, with various aggravating factors like weather conditions, sentiments, and the purpose of visitors, to evaluate the expected risk of incidents. The proposed framework is applied to the Crowd Safety Manager project in Scheveningen, where the DigiTwin is developed based on a wealth of real-time data sources. One noteworthy data source is Resono, offering insights into the number of visitors and their movements, leveraging a m
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23494;&#38598;&#39640;&#26031;&#21464;&#20998;&#26063;&#30340;&#26799;&#24230;&#20272;&#35745;&#22120;&#65292;&#22312;&#27492;&#22522;&#30784;&#19978;&#20351;&#29992;&#36817;&#31471;&#21644;&#25237;&#24433;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65292;&#25552;&#20379;&#20102;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#25910;&#25947;&#20110;&#36924;&#30495;&#25512;&#26029;&#38382;&#39064;&#30340;&#31532;&#19968;&#20010;&#20005;&#26684;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2306.03638</link><description>&lt;p&gt;
&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#30340;&#25910;&#25947;&#24615;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Provable convergence guarantees for black-box variational inference. (arXiv:2306.03638v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.03638
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23494;&#38598;&#39640;&#26031;&#21464;&#20998;&#26063;&#30340;&#26799;&#24230;&#20272;&#35745;&#22120;&#65292;&#22312;&#27492;&#22522;&#30784;&#19978;&#20351;&#29992;&#36817;&#31471;&#21644;&#25237;&#24433;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65292;&#25552;&#20379;&#20102;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#25910;&#25947;&#20110;&#36924;&#30495;&#25512;&#26029;&#38382;&#39064;&#30340;&#31532;&#19968;&#20010;&#20005;&#26684;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#34987;&#24191;&#27867;&#24212;&#29992;&#65292;&#20294;&#27809;&#26377;&#35777;&#26126;&#20854;&#38543;&#26426;&#20248;&#21270;&#25104;&#21151;&#30340;&#35777;&#26126;&#12290;&#25105;&#20204;&#25552;&#20986;&#36825;&#26159;&#29616;&#26377;&#38543;&#26426;&#20248;&#21270;&#35777;&#26126;&#20013;&#30340;&#29702;&#35770;&#24046;&#36317;&#65292;&#21363;&#20855;&#26377;&#24322;&#24120;&#22122;&#22768;&#36793;&#30028;&#21644;&#22797;&#21512;&#38750;&#24179;&#28369;&#30446;&#26631;&#30340;&#26799;&#24230;&#20272;&#35745;&#22120;&#30340;&#25361;&#25112;&#12290;&#23545;&#20110;&#23494;&#38598;&#30340;&#39640;&#26031;&#21464;&#20998;&#26063;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#29616;&#26377;&#30340;&#22522;&#20110;&#20877;&#21442;&#25968;&#21270;&#30340;&#26799;&#24230;&#20272;&#35745;&#22120;&#28385;&#36275;&#20108;&#27425;&#22122;&#22768;&#30028;&#65292;&#24182;&#20026;&#20351;&#29992;&#35813;&#30028;&#38480;&#30340;&#36817;&#31471;&#21644;&#25237;&#24433;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#25552;&#20379;&#26032;&#30340;&#25910;&#25947;&#20445;&#35777;&#12290;&#36825;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#25910;&#25947;&#20110;&#36924;&#30495;&#25512;&#26029;&#38382;&#39064;&#30340;&#20005;&#26684;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
While black-box variational inference is widely used, there is no proof that its stochastic optimization succeeds. We suggest this is due to a theoretical gap in existing stochastic optimization proofs-namely the challenge of gradient estimators with unusual noise bounds, and a composite non-smooth objective. For dense Gaussian variational families, we observe that existing gradient estimators based on reparameterization satisfy a quadratic noise bound and give novel convergence guarantees for proximal and projected stochastic gradient descent using this bound. This provides the first rigorous guarantee that black-box variational inference converges for realistic inference problems.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992;GAN&#26469;&#23398;&#20064;&#19968;&#20010;&#21407;&#22411;&#26230;&#26684;&#19978;&#30340;&#38543;&#26426;&#36807;&#31243;&#65292;&#24182;&#25552;&#20986;&#19968;&#31181;&#21512;&#36866;&#30340;&#22810;&#27169;&#22411;&#31243;&#24207;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#31934;&#24230;&#12290;GAN&#20284;&#20046;&#26159;&#22788;&#29702;&#22797;&#26434;&#32479;&#35745;&#21160;&#21147;&#23398;&#38382;&#39064;&#30340;&#26377;&#21069;&#36884;&#30340;&#24037;&#20855;&#12290;</title><link>http://arxiv.org/abs/2305.15920</link><description>&lt;p&gt;
&#22522;&#20110;&#22810;&#27169;&#22411;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#30340;&#38543;&#26426;&#21160;&#21147;&#23398;&#23398;&#20064;&#21644;&#31934;&#30830;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Learning and accurate generation of stochastic dynamics based on multi-model Generative Adversarial Networks. (arXiv:2305.15920v1 [cond-mat.stat-mech])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15920
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;GAN&#26469;&#23398;&#20064;&#19968;&#20010;&#21407;&#22411;&#26230;&#26684;&#19978;&#30340;&#38543;&#26426;&#36807;&#31243;&#65292;&#24182;&#25552;&#20986;&#19968;&#31181;&#21512;&#36866;&#30340;&#22810;&#27169;&#22411;&#31243;&#24207;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#31934;&#24230;&#12290;GAN&#20284;&#20046;&#26159;&#22788;&#29702;&#22797;&#26434;&#32479;&#35745;&#21160;&#21147;&#23398;&#38382;&#39064;&#30340;&#26377;&#21069;&#36884;&#30340;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#24050;&#32463;&#22312;&#36828;&#31163;&#29289;&#29702;&#39046;&#22495;&#65292;&#22914;&#25991;&#26412;&#21644;&#22270;&#20687;&#29983;&#25104;&#26041;&#38754;&#23637;&#31034;&#20986;&#20102;&#24040;&#22823;&#30340;&#28508;&#21147;&#12290;&#26412;&#25991;&#20351;&#29992;GAN&#26469;&#23398;&#20064;&#19968;&#20010;&#21407;&#22411;&#26230;&#26684;&#19978;&#30340;&#38543;&#26426;&#36807;&#31243;&#12290;&#36890;&#36807;&#21512;&#29702;&#22320;&#21521;&#21407;&#22987;&#25968;&#25454;&#28155;&#21152;&#22122;&#22768;&#65292;&#25105;&#20204;&#25104;&#21151;&#22320;&#23558;&#29983;&#25104;&#22120;&#21644;&#37492;&#21035;&#22120;&#25439;&#22833;&#20989;&#25968;&#30340;&#20540;&#24102;&#21040;&#20102;&#23427;&#20204;&#30340;&#29702;&#24819;&#20540;&#38468;&#36817;&#12290;&#28982;&#32780;&#65292;&#20687;&#23545;&#25239;&#24615;&#26041;&#27861;&#19968;&#26679;&#65292;&#38663;&#33633;&#20173;&#28982;&#23384;&#22312;&#12290;&#36825;&#20250;&#30772;&#22351;&#27169;&#22411;&#36873;&#25321;&#21644;&#29983;&#25104;&#36712;&#36857;&#30340;&#36136;&#37327;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#65292;&#19968;&#31181;&#21512;&#36866;&#30340;&#22810;&#27169;&#22411;&#31243;&#24207;&#65292;&#22312;&#27599;&#19968;&#27493;&#38543;&#26426;&#36873;&#25321;&#29983;&#25104;&#22120;&#25512;&#36827;&#38543;&#26426;&#36712;&#36857;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#31934;&#24230;&#12290;&#22522;&#20110;&#20197;&#19978;&#21457;&#29616;&#65292;GAN&#20284;&#20046;&#26159;&#22788;&#29702;&#22797;&#26434;&#32479;&#35745;&#21160;&#21147;&#23398;&#38382;&#39064;&#30340;&#26377;&#21069;&#36884;&#30340;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative Adversarial Networks (GANs) have shown immense potential in fields far from physics, such as in text and image generation. Here we use GANs to learn a prototypical stochastic process on a lattice. By suitably adding noise to the original data we succeed in bringing both the Generator and the Discriminator loss functions close to their ideal value. However, as typical for adversarial approaches, oscillations persist. This undermines model selection and the quality of the generated trajectory. We demonstrate that a suitable multi-model procedure where stochastic trajectories are advanced at each step upon randomly selecting a Generator leads to a remarkable increase in accuracy. Based on the reported findings GANs appears as a promising tool to tackle complex statistical dynamics.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32771;&#34385;&#22312;&#32473;&#23450;&#20984;&#32422;&#26463;&#19979;&#23398;&#20064;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#65292;&#36890;&#36807;&#35299;&#20986;&#21463;&#32422;&#26463;&#30340;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#65292;&#25552;&#20986;&#26032;&#30340;&#38750;&#28176;&#36827;&#35823;&#24046;&#30028;&#65292;&#24182;&#24212;&#29992;&#20110;&#31232;&#30095;&#30697;&#38453;&#31561;&#24773;&#22659;&#65292;&#25913;&#36827;&#20102;&#29616;&#26377;&#32479;&#35745;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2303.15121</link><description>&lt;p&gt;
&#22312;&#20984;&#32422;&#26463;&#19979;&#23398;&#20064;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
Learning linear dynamical systems under convex constraints. (arXiv:2303.15121v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15121
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#22312;&#32473;&#23450;&#20984;&#32422;&#26463;&#19979;&#23398;&#20064;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#65292;&#36890;&#36807;&#35299;&#20986;&#21463;&#32422;&#26463;&#30340;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#65292;&#25552;&#20986;&#26032;&#30340;&#38750;&#28176;&#36827;&#35823;&#24046;&#30028;&#65292;&#24182;&#24212;&#29992;&#20110;&#31232;&#30095;&#30697;&#38453;&#31561;&#24773;&#22659;&#65292;&#25913;&#36827;&#20102;&#29616;&#26377;&#32479;&#35745;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20174;&#21333;&#20010;&#36712;&#36857;&#20013;&#35782;&#21035;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#30340;&#38382;&#39064;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#20027;&#35201;&#20851;&#27880;&#26410;&#23545;&#31995;&#32479;&#30697;&#38453; $A^* \in \mathbb{R}^{n \times n}$ &#36827;&#34892;&#32467;&#26500;&#20551;&#35774;&#30340;&#24773;&#20917;&#65292;&#24182;&#23545;&#26222;&#36890;&#26368;&#23567;&#20108;&#20056; (OLS) &#20272;&#35745;&#22120;&#36827;&#34892;&#20102;&#35814;&#32454;&#20998;&#26512;&#12290;&#25105;&#20204;&#20551;&#35774;&#21487;&#29992;&#20808;&#21069;&#30340; $A^*$ &#30340;&#32467;&#26500;&#20449;&#24687;&#65292;&#21487;&#20197;&#22312;&#21253;&#21547; $A^*$ &#30340;&#20984;&#38598; $\mathcal{K}$ &#20013;&#25429;&#33719;&#12290;&#23545;&#20110;&#38543;&#21518;&#30340;&#21463;&#32422;&#26463;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#30340;&#35299;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986; Frobenius &#33539;&#25968;&#19979;&#20381;&#36182;&#20110; $\mathcal{K}$ &#22312; $A^*$ &#22788;&#20999;&#38181;&#30340;&#23616;&#37096;&#22823;&#23567;&#30340;&#38750;&#28176;&#36827;&#35823;&#24046;&#30028;&#12290;&#20026;&#20102;&#35828;&#26126;&#36825;&#19968;&#32467;&#26524;&#30340;&#26377;&#29992;&#24615;&#65292;&#25105;&#20204;&#23558;&#20854;&#23454;&#20363;&#21270;&#20026;&#20197;&#19979;&#35774;&#32622;&#65306;(i) $\mathcal{K}$ &#26159; $\mathbb{R}^{n \times n}$ &#20013;&#30340; $d$ &#32500;&#23376;&#31354;&#38388;&#65292;&#25110;&#32773; (ii) $A^*$ &#26159; $k$ &#31232;&#30095;&#30340;&#65292;$\mathcal{K}$ &#26159;&#36866;&#24403;&#32553;&#25918;&#30340; $\ell_1$ &#29699;&#12290;&#22312; $d, k \ll n^2$ &#30340;&#21306;&#22495;&#20013;&#65292;&#25105;&#20204;&#30340;&#35823;&#24046;&#30028;&#23545;&#20110;&#30456;&#21516;&#30340;&#32479;&#35745;&#21644;&#22122;&#22768;&#20551;&#35774;&#27604; OLS &#20272;&#35745;&#22120;&#33719;&#24471;&#20102;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of identification of linear dynamical systems from a single trajectory. Recent results have predominantly focused on the setup where no structural assumption is made on the system matrix $A^* \in \mathbb{R}^{n \times n}$, and have consequently analyzed the ordinary least squares (OLS) estimator in detail. We assume prior structural information on $A^*$ is available, which can be captured in the form of a convex set $\mathcal{K}$ containing $A^*$. For the solution of the ensuing constrained least squares estimator, we derive non-asymptotic error bounds in the Frobenius norm which depend on the local size of the tangent cone of $\mathcal{K}$ at $A^*$. To illustrate the usefulness of this result, we instantiate it for the settings where, (i) $\mathcal{K}$ is a $d$ dimensional subspace of $\mathbb{R}^{n \times n}$, or (ii) $A^*$ is $k$-sparse and $\mathcal{K}$ is a suitably scaled $\ell_1$ ball. In the regimes where $d, k \ll n^2$, our bounds improve upon those obta
&lt;/p&gt;</description></item><item><title>&#38750;&#23545;&#25968;&#20985;&#21183;V&#30340;&#39640;&#32500;&#37319;&#26679;&#36895;&#29575;&#21487;&#20197;&#22312;&#19968;&#20123;&#26465;&#20214;&#19979;&#23454;&#29616;&#19982;&#20984;&#20989;&#25968;&#30456;&#21516;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2303.03237</link><description>&lt;p&gt;
&#38750;&#23545;&#25968;&#20985;&#37319;&#26679;&#21644;&#23545;&#25968;&#20998;&#21306;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#29575;
&lt;/p&gt;
&lt;p&gt;
Convergence Rates for Non-Log-Concave Sampling and Log-Partition Estimation. (arXiv:2303.03237v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.03237
&lt;/p&gt;
&lt;p&gt;
&#38750;&#23545;&#25968;&#20985;&#21183;V&#30340;&#39640;&#32500;&#37319;&#26679;&#36895;&#29575;&#21487;&#20197;&#22312;&#19968;&#20123;&#26465;&#20214;&#19979;&#23454;&#29616;&#19982;&#20984;&#20989;&#25968;&#30456;&#21516;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#21513;&#24067;&#26031;&#20998;&#24067;$p(x)\propto\exp(-V(x)/\epsilon)$&#20013;&#37319;&#26679;&#24182;&#35745;&#31639;&#20854;&#23545;&#25968;&#20998;&#21306;&#20989;&#25968;&#26159;&#32479;&#35745;&#23398;&#12289;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#29289;&#29702;&#20013;&#30340;&#22522;&#26412;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#34429;&#28982;&#26377;&#25928;&#30340;&#31639;&#27861;&#24050;&#30693;&#20110;&#20984;&#21183;&#20989;&#25968;$V$&#65292;&#20294;&#38750;&#20984;&#24773;&#20917;&#19979;&#30340;&#24773;&#20917;&#35201;&#22256;&#38590;&#24471;&#22810;&#65292;&#31639;&#27861;&#24517;&#28982;&#22312;&#26368;&#22351;&#24773;&#20917;&#19979;&#21463;&#21040;&#32500;&#24230;&#28798;&#38590;&#30340;&#22256;&#25200;&#12290;&#26368;&#36817;&#65292;&#24050;&#32463;&#35777;&#26126;&#22312;&#36866;&#24403;&#30340;&#26465;&#20214;&#19979;&#65292;&#39640;&#32500;&#37319;&#26679;&#38750;&#23545;&#25968;&#20985;&#21183;V&#30340;&#36895;&#29575;&#20063;&#21487;&#20197;&#36798;&#21040;&#21516;&#26679;&#24555;&#30340;&#36895;&#24230;&#12290;&#26412;&#25991;&#23545;&#36825;&#20123;&#32467;&#26524;&#36827;&#34892;&#20102;&#22238;&#39038;&#65292;&#24182;&#24378;&#35843;&#20102;&#39046;&#22495;&#20013;&#30340;&#19968;&#20123;&#24320;&#25918;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sampling from Gibbs distributions $p(x) \propto \exp(-V(x)/\varepsilon)$ and computing their log-partition function are fundamental tasks in statistics, machine learning, and statistical physics. However, while efficient algorithms are known for convex potentials $V$, the situation is much more difficult in the non-convex case, where algorithms necessarily suffer from the curse of dimensionality in the worst case. For optimization, which can be seen as a low-temperature limit of sampling, it is known that smooth functions $V$ allow faster convergence rates. Specifically, for $m$-times differentiable functions in $d$ dimensions, the optimal rate for algorithms with $n$ function evaluations is known to be $O(n^{-m/d})$, where the constant can potentially depend on $m, d$ and the function to be optimized. Hence, the curse of dimensionality can be alleviated for smooth functions at least in terms of the convergence rate. Recently, it has been shown that similarly fast rates can also be ach
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#28145;&#20837;&#29702;&#35299;&#20102;&#25193;&#25955;&#30446;&#26631;&#65292;&#24182;&#25581;&#31034;&#20102;&#21152;&#26435;&#25439;&#22833;&#21644;ELBO&#30446;&#26631;&#20043;&#38388;&#30340;&#30452;&#25509;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2303.00848</link><description>&lt;p&gt;
&#20197;ELBOs&#30340;&#21152;&#26435;&#31215;&#20998;&#29702;&#35299;&#25193;&#25955;&#30446;&#26631;
&lt;/p&gt;
&lt;p&gt;
Understanding the Diffusion Objective as a Weighted Integral of ELBOs. (arXiv:2303.00848v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.00848
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#28145;&#20837;&#29702;&#35299;&#20102;&#25193;&#25955;&#30446;&#26631;&#65292;&#24182;&#25581;&#31034;&#20102;&#21152;&#26435;&#25439;&#22833;&#21644;ELBO&#30446;&#26631;&#20043;&#38388;&#30340;&#30452;&#25509;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25991;&#29486;&#20013;&#30340;&#25193;&#25955;&#27169;&#22411;&#37319;&#29992;&#19981;&#21516;&#30340;&#30446;&#26631;&#36827;&#34892;&#20248;&#21270;&#65292;&#24182;&#19988;&#36825;&#20123;&#30446;&#26631;&#37117;&#26159;&#21152;&#26435;&#25439;&#22833;&#30340;&#29305;&#20363;&#65292;&#20854;&#20013;&#21152;&#26435;&#20989;&#25968;&#25351;&#23450;&#27599;&#20010;&#22122;&#22768;&#32423;&#21035;&#30340;&#26435;&#37325;&#12290;&#22343;&#21248;&#21152;&#26435;&#23545;&#24212;&#20110;&#26368;&#22823;&#20284;&#28982;&#30340;&#21407;&#21017;&#24615;&#36817;&#20284;ELBO&#30340;&#26368;&#22823;&#21270;&#12290;&#20294;&#26159;&#23454;&#38469;&#19978;&#65292;&#30001;&#20110;&#26356;&#22909;&#30340;&#26679;&#26412;&#36136;&#37327;&#65292;&#30446;&#21069;&#30340;&#25193;&#25955;&#27169;&#22411;&#20351;&#29992;&#38750;&#22343;&#21248;&#21152;&#26435;&#12290;&#26412;&#25991;&#25581;&#31034;&#20102;&#21152;&#26435;&#25439;&#22833;&#65288;&#24102;&#26377;&#20219;&#20309;&#21152;&#26435;&#65289;&#21644;ELBO&#30446;&#26631;&#20043;&#38388;&#30340;&#30452;&#25509;&#20851;&#31995;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#21152;&#26435;&#25439;&#22833;&#21487;&#20197;&#34987;&#20889;&#25104;&#19968;&#31181;ELBOs&#30340;&#21152;&#26435;&#31215;&#20998;&#24418;&#24335;&#65292;&#20854;&#20013;&#27599;&#20010;&#22122;&#22768;&#32423;&#21035;&#37117;&#26377;&#19968;&#20010;ELBO&#12290;&#22914;&#26524;&#26435;&#37325;&#20989;&#25968;&#26159;&#21333;&#35843;&#30340;&#65292;&#37027;&#20040;&#21152;&#26435;&#25439;&#22833;&#26159;&#19968;&#31181;&#22522;&#20110;&#20284;&#28982;&#30340;&#30446;&#26631;&#65306;&#23427;&#22312;&#31616;&#21333;&#30340;&#25968;&#25454;&#22686;&#24378;&#19979;&#65288;&#21363;&#39640;&#26031;&#22122;&#22768;&#25200;&#21160;&#65289;&#19979;&#26368;&#22823;&#21270;ELBO&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#26356;&#28145;&#20837;&#22320;&#29702;&#35299;&#20102;&#25193;&#25955;&#30446;&#26631;&#65292;&#20294;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#19968;&#20123;&#27604;&#36739;&#21333;&#35843;&#21644;&#38750;&#21333;&#35843;&#26435;&#37325;&#30340;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models in the literature are optimized with various objectives that are special cases of a weighted loss, where the weighting function specifies the weight per noise level. Uniform weighting corresponds to maximizing the ELBO, a principled approximation of maximum likelihood. In current practice diffusion models are optimized with non-uniform weighting due to better results in terms of sample quality. In this work we expose a direct relationship between the weighted loss (with any weighting) and the ELBO objective.  We show that the weighted loss can be written as a weighted integral of ELBOs, with one ELBO per noise level. If the weighting function is monotonic, then the weighted loss is a likelihood-based objective: it maximizes the ELBO under simple data augmentation, namely Gaussian noise perturbation. Our main contribution is a deeper theoretical understanding of the diffusion objective, but we also performed some experiments comparing monotonic with non-monotonic weight
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20379;&#20102;&#20851;&#20110;&#22914;&#20309;&#23558;&#24046;&#20998;&#38544;&#31169;&#24212;&#29992;&#20110;&#22797;&#26434;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#23454;&#29992;&#25351;&#21335;&#65292;&#22635;&#34917;&#20102;&#29616;&#26377;&#23454;&#36341;&#20013;&#30340;&#31354;&#30333;&#65292;&#20026;&#23454;&#29616;&#26426;&#22120;&#23398;&#20064;&#19982;&#24046;&#20998;&#38544;&#31169;&#30340;&#32467;&#21512;&#25552;&#20379;&#20102;&#23454;&#38469;&#25351;&#23548;&#12290;</title><link>http://arxiv.org/abs/2303.00654</link><description>&lt;p&gt;
&#22914;&#20309;&#29992;&#24046;&#20998;&#38544;&#31169;&#23454;&#29616;&#26426;&#22120;&#23398;&#20064;&#65306;&#26426;&#22120;&#23398;&#20064;&#19982;&#24046;&#20998;&#38544;&#31169;&#23454;&#29992;&#25351;&#21335;
&lt;/p&gt;
&lt;p&gt;
How to DP-fy ML: A Practical Guide to Machine Learning with Differential Privacy. (arXiv:2303.00654v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.00654
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20379;&#20102;&#20851;&#20110;&#22914;&#20309;&#23558;&#24046;&#20998;&#38544;&#31169;&#24212;&#29992;&#20110;&#22797;&#26434;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#23454;&#29992;&#25351;&#21335;&#65292;&#22635;&#34917;&#20102;&#29616;&#26377;&#23454;&#36341;&#20013;&#30340;&#31354;&#30333;&#65292;&#20026;&#23454;&#29616;&#26426;&#22120;&#23398;&#20064;&#19982;&#24046;&#20998;&#38544;&#31169;&#30340;&#32467;&#21512;&#25552;&#20379;&#20102;&#23454;&#38469;&#25351;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#29616;&#23454;&#19990;&#30028;&#24212;&#29992;&#24191;&#27867;&#65292;&#24182;&#19988;&#26159;&#30740;&#31350;&#30340;&#37325;&#28857;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#31038;&#21306;&#24320;&#22987;&#24847;&#35782;&#21040;&#20445;&#25252;&#26426;&#22120;&#23398;&#20064;&#35757;&#32451;&#25968;&#25454;&#30340;&#38544;&#31169;&#30340;&#37325;&#35201;&#24615;&#12290;&#24046;&#20998;&#38544;&#31169;&#24050;&#32463;&#25104;&#20026;&#23545;&#25968;&#25454;&#21311;&#21517;&#21270;&#20570;&#20986;&#27491;&#24335;&#38472;&#36848;&#30340;&#40644;&#37329;&#26631;&#20934;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#22312;&#24037;&#19994;&#30028;&#24050;&#32463;&#26377;&#19968;&#20123;&#24212;&#29992;&#24046;&#20998;&#38544;&#31169;&#30340;&#23581;&#35797;&#65292;&#20294;&#23558;&#24046;&#20998;&#38544;&#31169;&#24212;&#29992;&#20110;&#29616;&#23454;&#19990;&#30028;&#20013;&#30340;&#22797;&#26434;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20173;&#28982;&#24456;&#23569;&#12290;&#24046;&#20998;&#38544;&#31169;&#30340;&#24212;&#29992;&#21463;&#38480;&#20110;&#32570;&#20047;&#23454;&#38469;&#25351;&#23548;&#65292;&#19981;&#28165;&#26970;&#38656;&#35201;&#20160;&#20040;&#26679;&#30340;&#38544;&#31169;&#20445;&#35777;&#65292;&#24182;&#19988;&#22312;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#38544;&#31169;&#20445;&#25252;&#12289;&#25928;&#29992;&#21644;&#35745;&#31639;&#20043;&#38388;&#23384;&#22312;&#33391;&#22909;&#30340;&#24179;&#34913;&#12290;&#35843;&#25972;&#21644;&#20248;&#21270;&#24615;&#33021;&#30340;&#25216;&#24039;&#25955;&#24067;&#22312;&#35770;&#25991;&#20013;&#25110;&#32773;&#23384;&#22312;&#20110;&#20174;&#19994;&#32773;&#30340;&#22836;&#33041;&#20013;&#12290;&#27492;&#22806;&#65292;&#25991;&#29486;&#20284;&#20046;&#23545;&#20110;&#22914;&#20309;&#20197;&#21450;&#26159;&#21542;&#24212;&#29992;&#26550;&#26500;&#35843;&#25972;&#20197;&#21450;&#21738;&#20123;&#32452;&#20214;&#22312;&#24212;&#29992;&#24046;&#20998;&#38544;&#31169;&#26102;&#26159;&#8220;&#23433;&#20840;&#8221;&#30340;&#38382;&#39064;&#23384;&#22312;&#30528;&#30456;&#20114;&#30683;&#30462;&#30340;&#35777;&#25454;&#12290;&#26412;&#24037;&#20316;&#26159;&#19968;&#20221;&#33258;&#21253;&#21547;&#30340;&#25351;&#21335;&#65292;&#26088;&#22312;&#22635;&#34917;&#36825;&#20123;&#31354;&#30333;&#24182;&#25552;&#20379;&#23454;&#38469;&#25351;&#23548;&#65292;&#24110;&#21161;&#23454;&#29616;&#26426;&#22120;&#23398;&#20064;&#19982;&#24046;&#20998;&#38544;&#31169;&#30340;&#32467;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
ML models are ubiquitous in real world applications and are a constant focus of research. At the same time, the community has started to realize the importance of protecting the privacy of ML training data.  Differential Privacy (DP) has become a gold standard for making formal statements about data anonymization. However, while some adoption of DP has happened in industry, attempts to apply DP to real world complex ML models are still few and far between. The adoption of DP is hindered by limited practical guidance of what DP protection entails, what privacy guarantees to aim for, and the difficulty of achieving good privacy-utility-computation trade-offs for ML models. Tricks for tuning and maximizing performance are scattered among papers or stored in the heads of practitioners. Furthermore, the literature seems to present conflicting evidence on how and whether to apply architectural adjustments and which components are "safe" to use with DP.  This work is a self-contained guide th
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;Nystr\"om $M$-Hilbert-Schmidt&#29420;&#31435;&#20934;&#21017;&#65292;&#38024;&#23545;&#22823;&#35268;&#27169;&#24212;&#29992;&#30340;&#20108;&#27425;&#35745;&#31639;&#29942;&#39048;&#38382;&#39064;&#36827;&#34892;&#20102;&#35299;&#20915;&#65292;&#24182;&#20860;&#39038;&#20102;&#22810;&#20010;&#38543;&#26426;&#21464;&#37327;&#30340;&#25512;&#24191;&#24773;&#20917;&#21644;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2302.09930</link><description>&lt;p&gt;
Nystr\"om $M$-Hilbert-Schmidt&#29420;&#31435;&#20934;&#21017;
&lt;/p&gt;
&lt;p&gt;
Nystr\"om $M$-Hilbert-Schmidt Independence Criterion. (arXiv:2302.09930v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09930
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;Nystr\"om $M$-Hilbert-Schmidt&#29420;&#31435;&#20934;&#21017;&#65292;&#38024;&#23545;&#22823;&#35268;&#27169;&#24212;&#29992;&#30340;&#20108;&#27425;&#35745;&#31639;&#29942;&#39048;&#38382;&#39064;&#36827;&#34892;&#20102;&#35299;&#20915;&#65292;&#24182;&#20860;&#39038;&#20102;&#22810;&#20010;&#38543;&#26426;&#21464;&#37327;&#30340;&#25512;&#24191;&#24773;&#20917;&#21644;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26680;&#25216;&#26415;&#26159;&#25968;&#25454;&#31185;&#23398;&#20013;&#26368;&#21463;&#27426;&#36814;&#21644;&#24378;&#22823;&#30340;&#26041;&#27861;&#20043;&#19968;&#12290;&#26680;&#30340;&#24191;&#27867;&#24212;&#29992;&#30340;&#20851;&#38190;&#29305;&#24615;&#21253;&#25324;&#65306;(i) &#23427;&#20204;&#38024;&#23545;&#30340;&#39046;&#22495;&#25968;&#37327;&#22810;&#65292;(ii) &#19982;&#26680;&#30456;&#20851;&#30340;&#20989;&#25968;&#31867;&#20855;&#26377;Hilbert&#32467;&#26500;&#65292;&#20415;&#20110;&#32479;&#35745;&#20998;&#26512;&#65292;&#20197;&#21450;(iii) &#23427;&#20204;&#33021;&#22815;&#20197;&#19981;&#20002;&#22833;&#20449;&#24687;&#30340;&#26041;&#24335;&#34920;&#31034;&#27010;&#29575;&#20998;&#24067;&#12290;&#36825;&#20123;&#29305;&#24615;&#23548;&#33268;&#20102;Hilbert-Schmidt&#29420;&#31435;&#20934;&#21017;(HSIC)&#30340;&#24040;&#22823;&#25104;&#21151;&#65292;&#35813;&#20934;&#21017;&#33021;&#22815;&#22312;&#28201;&#21644;&#26465;&#20214;&#19979;&#25429;&#25417;&#38543;&#26426;&#21464;&#37327;&#30340;&#32852;&#21512;&#29420;&#31435;&#24615;&#65292;&#24182;&#20801;&#35768;&#20855;&#26377;&#20108;&#27425;&#35745;&#31639;&#22797;&#26434;&#24615;&#30340;&#38381;&#24335;&#20272;&#35745;&#22120;(&#30456;&#23545;&#20110;&#26679;&#26412;&#22823;&#23567;)&#12290;&#20026;&#20102;&#35299;&#20915;&#22823;&#35268;&#27169;&#24212;&#29992;&#20013;&#30340;&#20108;&#27425;&#35745;&#31639;&#29942;&#39048;&#38382;&#39064;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#22810;&#20010;HSIC&#36817;&#20284;&#20272;&#35745;&#22120;&#65292;&#28982;&#32780;&#36825;&#20123;&#20272;&#35745;&#22120;&#38480;&#21046;&#20110;$M=2$&#20010;&#38543;&#26426;&#21464;&#37327;&#65292;&#19981;&#33021;&#33258;&#28982;&#22320;&#25512;&#24191;&#21040;$M \geq 2$&#30340;&#24773;&#20917;&#65292;&#24182;&#19988;&#32570;&#20047;&#29702;&#35770;&#20445;&#35777;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;Nystr\"om $M$-Hilbert-Schmidt&#29420;&#31435;&#20934;&#21017;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Kernel techniques are among the most popular and powerful approaches of data science. Among the key features that make kernels ubiquitous are (i) the number of domains they have been designed for, (ii) the Hilbert structure of the function class associated to kernels facilitating their statistical analysis, and (iii) their ability to represent probability distributions without loss of information. These properties give rise to the immense success of Hilbert-Schmidt independence criterion (HSIC) which is able to capture joint independence of random variables under mild conditions, and permits closed-form estimators with quadratic computational complexity (w.r.t. the sample size). In order to alleviate the quadratic computational bottleneck in large-scale applications, multiple HSIC approximations have been proposed, however these estimators are restricted to $M=2$ random variables, do not extend naturally to the $M\ge 2$ case, and lack theoretical guarantees. In this work, we propose an
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#40654;&#26364;&#23376;&#27969;&#24418;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#20102;&#31616;&#21270;&#65292;&#25552;&#20986;&#20102;&#40654;&#26364;&#27491;&#24120;&#22352;&#26631;&#30340;&#24191;&#20041;&#29256;&#26412;&#65292;&#21487;&#29992;&#20110;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#30340;&#23376;&#27969;&#24418;&#20248;&#21270;&#65292;&#24182;&#20026;&#28145;&#24230;&#23398;&#20064;&#24320;&#21457;&#20102;&#39640;&#25928;&#30340;&#20108;&#38454;&#20248;&#21270;&#22120;&#65292;&#26080;&#38656;&#26174;&#24335;&#30697;&#38453;&#27714;&#36870;&#12290;</title><link>http://arxiv.org/abs/2302.09738</link><description>&lt;p&gt;
&#31616;&#21270;&#22522;&#20110;&#21160;&#37327;&#30340;&#40654;&#26364;&#23376;&#27969;&#24418;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Simplifying Momentum-based Riemannian Submanifold Optimization. (arXiv:2302.09738v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09738
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#40654;&#26364;&#23376;&#27969;&#24418;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#20102;&#31616;&#21270;&#65292;&#25552;&#20986;&#20102;&#40654;&#26364;&#27491;&#24120;&#22352;&#26631;&#30340;&#24191;&#20041;&#29256;&#26412;&#65292;&#21487;&#29992;&#20110;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#30340;&#23376;&#27969;&#24418;&#20248;&#21270;&#65292;&#24182;&#20026;&#28145;&#24230;&#23398;&#20064;&#24320;&#21457;&#20102;&#39640;&#25928;&#30340;&#20108;&#38454;&#20248;&#21270;&#22120;&#65292;&#26080;&#38656;&#26174;&#24335;&#30697;&#38453;&#27714;&#36870;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24102;&#26377;&#21160;&#37327;&#30340;&#40654;&#26364;&#23376;&#27969;&#24418;&#20248;&#21270;&#22312;&#35745;&#31639;&#19978;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#22240;&#20026;&#30830;&#20445;&#36845;&#20195;&#20445;&#25345;&#22312;&#23376;&#27969;&#24418;&#19978;&#36890;&#24120;&#38656;&#35201;&#35299;&#20915;&#22256;&#38590;&#30340;&#24494;&#20998;&#26041;&#31243;&#12290;&#26412;&#25991;&#38024;&#23545;&#20855;&#26377;&#20223;&#23556;&#19981;&#21464;&#24230;&#37327;&#30340;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#30340;&#23376;&#27969;&#24418;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#20102;&#31616;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#40654;&#26364;&#27491;&#24120;&#22352;&#26631;&#30340;&#24191;&#20041;&#29256;&#26412;&#65292;&#21487;&#20197;&#23558;&#38382;&#39064;&#21160;&#24577;&#22320;&#31616;&#21270;&#20026;&#27431;&#20960;&#37324;&#24471;&#26080;&#32422;&#26463;&#38382;&#39064;&#12290;&#25105;&#20204;&#20351;&#29992;&#25105;&#20204;&#30340;&#26041;&#27861;&#26469;&#35299;&#37322;&#21644;&#31616;&#21270;&#29616;&#26377;&#30340;&#32467;&#26500;&#21270;&#21327;&#26041;&#24046;&#26041;&#27861;&#65292;&#24182;&#20026;&#28145;&#24230;&#23398;&#20064;&#24320;&#21457;&#20102;&#39640;&#25928;&#30340;&#20108;&#38454;&#20248;&#21270;&#22120;&#65292;&#32780;&#26080;&#38656;&#26174;&#24335;&#30697;&#38453;&#27714;&#36870;&#12290;
&lt;/p&gt;
&lt;p&gt;
Riemannian submanifold optimization with momentum is computationally challenging because ensuring iterates remain on the submanifold often requires solving difficult differential equations. We simplify such optimization algorithms for the submanifold of symmetric positive-definite matrices with the affine invariant metric. We propose a generalized version of the Riemannian normal coordinates which dynamically trivializes the problem into a Euclidean unconstrained problem. We use our approach to explain and simplify existing approaches for structured covariances and develop efficient second-order optimizers for deep learning without explicit matrix inverses.
&lt;/p&gt;</description></item><item><title>&#22270;&#24418;&#21270;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#29992;&#20110;&#32858;&#31867;&#38750;&#20132;&#25442;&#20998;&#32452;&#25968;&#25454;&#65292;&#22312;&#32852;&#21512;&#27169;&#22411;&#20013;&#20849;&#20139;&#32858;&#31867;&#65292;&#20351;&#29992;&#36229;&#22270;&#12289;&#26029;&#26829;&#27861;&#12289;&#39184;&#39302;&#27169;&#22411;&#21644;&#26377;&#38480;&#28151;&#21512;&#27169;&#22411;&#26497;&#38480;&#36827;&#34892;&#25551;&#36848;&#65292;&#24320;&#21457;&#20102;&#39640;&#25928;&#30340;&#21518;&#39564;&#25512;&#26029;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2302.09111</link><description>&lt;p&gt;
&#22270;&#24418;&#21270;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#29992;&#20110;&#32858;&#31867;&#38750;&#20132;&#25442;&#20998;&#32452;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Graphical Dirichlet Process for Clustering Non-Exchangeable Grouped Data. (arXiv:2302.09111v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09111
&lt;/p&gt;
&lt;p&gt;
&#22270;&#24418;&#21270;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#29992;&#20110;&#32858;&#31867;&#38750;&#20132;&#25442;&#20998;&#32452;&#25968;&#25454;&#65292;&#22312;&#32852;&#21512;&#27169;&#22411;&#20013;&#20849;&#20139;&#32858;&#31867;&#65292;&#20351;&#29992;&#36229;&#22270;&#12289;&#26029;&#26829;&#27861;&#12289;&#39184;&#39302;&#27169;&#22411;&#21644;&#26377;&#38480;&#28151;&#21512;&#27169;&#22411;&#26497;&#38480;&#36827;&#34892;&#25551;&#36848;&#65292;&#24320;&#21457;&#20102;&#39640;&#25928;&#30340;&#21518;&#39564;&#25512;&#26029;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#32858;&#31867;&#21487;&#33021;&#20855;&#26377;&#38750;&#20132;&#25442;&#32452;&#24182;&#19988;&#20854;&#20381;&#36182;&#20851;&#31995;&#21487;&#20197;&#36890;&#36807;&#24050;&#30693;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;&#26469;&#25551;&#36848;&#30340;&#20998;&#32452;&#25968;&#25454;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#20801;&#35768;&#22312;&#38750;&#20132;&#25442;&#32452;&#20043;&#38388;&#20849;&#20139;&#32858;&#31867;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#26041;&#27861;&#65292;&#31216;&#20026;&#22270;&#24418;&#21270;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#65292;&#23427;&#36890;&#36807;&#20551;&#35774;&#27599;&#20010;&#38543;&#26426;&#27979;&#24230;&#20998;&#24067;&#22914;&#21516;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#65292;&#20854;&#20013;&#27987;&#24230;&#21442;&#25968;&#21644;&#22522;&#26412;&#27010;&#29575;&#27979;&#24230;&#21462;&#20915;&#20110;&#20854;&#29238;&#32452;&#30340;&#27987;&#24230;&#21442;&#25968;&#21644;&#22522;&#26412;&#27010;&#29575;&#27979;&#24230;&#65292;&#26469;&#20849;&#21516;&#23545;&#20381;&#36182;&#20110;&#32452;&#30340;&#29305;&#23450;&#38543;&#26426;&#27979;&#24230;&#36827;&#34892;&#24314;&#27169;&#12290;&#25152;&#24471;&#21040;&#30340;&#32852;&#21512;&#38543;&#26426;&#36807;&#31243;&#23562;&#37325;&#36830;&#25509;&#32452;&#30340;&#26377;&#21521;&#26080;&#29615;&#22270;&#30340;&#39532;&#23572;&#21487;&#22827;&#24615;&#36136;&#12290;&#25105;&#20204;&#20351;&#29992;&#26032;&#26041;&#27861;&#30340;&#36229;&#22270;&#34920;&#31034;&#20197;&#21450;&#26029;&#26829;&#27861;&#34920;&#31034;&#12289;&#39184;&#39302;&#31867;&#22411;&#34920;&#31034;&#21644;&#20316;&#20026;&#26377;&#38480;&#28151;&#21512;&#27169;&#22411;&#26497;&#38480;&#30340;&#34920;&#31034;&#26469;&#25551;&#36848;&#22270;&#24418;&#21270;&#29380;&#21033;&#20811;&#38647;&#36807;&#31243;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#39640;&#25928;&#30340;&#21518;&#39564;&#25512;&#26029;&#31639;&#27861;&#65292;&#24182;&#29992;&#27169;&#25311;&#21644;&#23454;&#20363;&#35828;&#26126;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of clustering grouped data with possibly non-exchangeable groups whose dependencies can be characterized by a known directed acyclic graph. To allow the sharing of clusters among the non-exchangeable groups, we propose a Bayesian nonparametric approach, termed graphical Dirichlet process, that jointly models the dependent group-specific random measures by assuming each random measure to be distributed as a Dirichlet process whose concentration parameter and base probability measure depend on those of its parent groups. The resulting joint stochastic process respects the Markov property of the directed acyclic graph that links the groups. We characterize the graphical Dirichlet process using a novel hypergraph representation as well as the stick-breaking representation, the restaurant-type representation, and the representation as a limit of a finite mixture model. We develop an efficient posterior inference algorithm and illustrate our model with simulations and
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23454;&#39564;&#21644;&#29702;&#35770;&#20998;&#26512;&#65292;&#26412;&#35770;&#25991;&#21457;&#29616;&#22312;&#30693;&#35782;&#33976;&#39311;&#20013;&#65292;&#23398;&#29983;&#32593;&#32476;&#23545;&#25945;&#24072;&#32593;&#32476;&#30340;&#27010;&#29575;&#20559;&#31163;&#26159;&#31995;&#32479;&#24615;&#22840;&#22823;&#30340;&#65292;&#21516;&#26102;&#20063;&#24471;&#21040;&#20102;&#26356;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2301.12923</link><description>&lt;p&gt;
&#20851;&#20110;&#30693;&#35782;&#33976;&#39311;&#20013;&#30340;&#23398;&#29983;-&#25945;&#24072;&#20559;&#24046;&#65306;&#36829;&#21453;&#35268;&#21017;&#26159;&#21542;&#26377;&#30410;&#65311;
&lt;/p&gt;
&lt;p&gt;
On student-teacher deviations in distillation: does it pay to disobey?. (arXiv:2301.12923v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.12923
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23454;&#39564;&#21644;&#29702;&#35770;&#20998;&#26512;&#65292;&#26412;&#35770;&#25991;&#21457;&#29616;&#22312;&#30693;&#35782;&#33976;&#39311;&#20013;&#65292;&#23398;&#29983;&#32593;&#32476;&#23545;&#25945;&#24072;&#32593;&#32476;&#30340;&#27010;&#29575;&#20559;&#31163;&#26159;&#31995;&#32479;&#24615;&#22840;&#22823;&#30340;&#65292;&#21516;&#26102;&#20063;&#24471;&#21040;&#20102;&#26356;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30693;&#35782;&#33976;&#39311;&#65288;KD&#65289;&#34987;&#24191;&#27867;&#29992;&#20110;&#36890;&#36807;&#35757;&#32451;&#23398;&#29983;&#27169;&#20223;&#32463;&#36807;&#35757;&#32451;&#30340;&#8220;&#25945;&#24072;&#8221;&#32593;&#32476;&#30340;&#36719;&#27010;&#29575;&#26469;&#25552;&#39640;&#8220;&#23398;&#29983;&#8221;&#32593;&#32476;&#30340;&#27979;&#35797;&#20934;&#30830;&#24615;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#23613;&#31649;&#34987;&#35757;&#32451;&#25104;&#36866;&#24212;&#25945;&#24072;&#30340;&#27010;&#29575;&#65292;&#23398;&#29983;&#19981;&#20165;&#26126;&#26174;&#20559;&#31163;&#36825;&#20123;&#27010;&#29575;&#65292;&#32780;&#19988;&#34920;&#29616;&#27604;&#25945;&#24072;&#26356;&#22909;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#26088;&#22312;&#36890;&#36807;&#30830;&#23450;&#23398;&#29983;-&#25945;&#24072;&#20559;&#24046;&#30340;&#30830;&#20999;&#24615;&#36136;&#65292;&#24182;&#35770;&#35777;&#23427;&#20204;&#19982;&#26356;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#22914;&#20309;&#20849;&#23384;&#26469;&#35299;&#20915;&#36825;&#19968;&#30475;&#20284;&#30683;&#30462;&#30340;&#35266;&#23519;&#12290;&#39318;&#20808;&#65292;&#36890;&#36807;&#23545;&#22270;&#20687;&#21644;&#35821;&#35328;&#25968;&#25454;&#36827;&#34892;&#23454;&#39564;&#65292;&#25105;&#20204;&#30830;&#23450;&#36825;&#20123;&#20559;&#24046;&#23545;&#24212;&#20110;&#23398;&#29983;&#31995;&#32479;&#24615;&#22320;&#22840;&#22823;&#25945;&#24072;&#30340;&#33258;&#20449;&#27700;&#24179;&#12290;&#25509;&#19979;&#26469;&#65292;&#22312;&#19968;&#20123;&#31616;&#21333;&#30340;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#20174;&#29702;&#35770;&#21644;&#23454;&#35777;&#19978;&#24314;&#31435;&#20102;KD&#22312;&#25910;&#25947;&#26356;&#24555;&#30340;&#36807;&#31243;&#20013;&#22840;&#22823;&#20102;&#26799;&#24230;&#19979;&#38477;&#30340;&#38544;&#21547;&#20559;&#24046;&#30340;&#35777;&#25454;&#12290;&#26368;&#21518;&#65292;
&lt;/p&gt;
&lt;p&gt;
Knowledge distillation (KD) has been widely-used to improve the test accuracy of a ``student'' network by training the student to mimic soft probabilities of a trained "teacher" network. Yet, it has been shown in recent work that, despite being trained to fit the teacher's probabilities, the student not only significantly deviates from these probabilities, but also performs even better than the teacher. Our work aims to reconcile this seemingly paradoxical observation by characterizing the precise nature of the student-teacher deviations, and by arguing how they can co-occur with better generalization. First, through experiments on image and language data, we identify that these deviations correspond to the student systematically exaggerating the confidence levels of the teacher. Next, we theoretically and empirically establish in some simple settings that KD also exaggerates the implicit bias of gradient descent in converging faster along the top eigendirections of the data. Finally, 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#32456;&#36523;&#24378;&#21270;&#23398;&#20064;&#20013;&#20351;&#29992;&#35843;&#25972;&#25513;&#30721;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#35843;&#25972;&#25513;&#30721;&#24212;&#29992;&#20110;PPO&#21644;IMPALA&#20195;&#29702;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;&#22312;&#31163;&#25955;&#21644;&#36830;&#32493;&#24378;&#21270;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2212.11110</link><description>&lt;p&gt;
&#20351;&#29992;&#35843;&#25972;&#25513;&#30721;&#30340;&#32456;&#36523;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Lifelong Reinforcement Learning with Modulating Masks. (arXiv:2212.11110v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.11110
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#32456;&#36523;&#24378;&#21270;&#23398;&#20064;&#20013;&#20351;&#29992;&#35843;&#25972;&#25513;&#30721;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#35843;&#25972;&#25513;&#30721;&#24212;&#29992;&#20110;PPO&#21644;IMPALA&#20195;&#29702;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;&#22312;&#31163;&#25955;&#21644;&#36830;&#32493;&#24378;&#21270;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32456;&#36523;&#23398;&#20064;&#26088;&#22312;&#21019;&#24314;&#22312;&#20854;&#29983;&#21629;&#21608;&#26399;&#20013;&#25345;&#32493;&#21644;&#36880;&#27493;&#23398;&#20064;&#30340;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#65292;&#31867;&#20284;&#29983;&#29289;&#23398;&#20064;&#12290;&#21040;&#30446;&#21069;&#20026;&#27490;&#65292;&#36825;&#26041;&#38754;&#30340;&#23581;&#35797;&#36935;&#21040;&#20102;&#38382;&#39064;&#65292;&#21253;&#25324;&#28798;&#38590;&#24615;&#36951;&#24536;&#12289;&#20219;&#21153;&#20043;&#38388;&#30340;&#24178;&#25200;&#65292;&#20197;&#21450;&#26080;&#27861;&#21033;&#29992;&#20808;&#21069;&#30340;&#30693;&#35782;&#12290;&#34429;&#28982;&#24050;&#32463;&#26377;&#30456;&#24403;&#22810;&#30340;&#30740;&#31350;&#38598;&#20013;&#22312;&#23398;&#20064;&#28041;&#21450;&#36755;&#20837;&#20998;&#24067;&#21464;&#21270;&#30340;&#22810;&#20010;&#30417;&#30563;&#20998;&#31867;&#20219;&#21153;&#19978;&#65292;&#20294;&#26159;&#32456;&#36523;&#24378;&#21270;&#23398;&#20064;&#24517;&#39035;&#22788;&#29702;&#29366;&#24577;&#21644;&#36716;&#25442;&#20998;&#24067;&#20197;&#21450;&#22870;&#21169;&#20989;&#25968;&#30340;&#21464;&#21270;&#12290;&#26368;&#36817;&#38024;&#23545;&#20998;&#31867;&#38382;&#39064;&#24320;&#21457;&#30340;&#20351;&#29992;&#22266;&#23450;&#39592;&#24178;&#32593;&#32476;&#30340;&#35843;&#25972;&#25513;&#30721;&#23545;&#20110;&#22788;&#29702;&#22914;&#27492;&#22823;&#33539;&#22260;&#30340;&#20219;&#21153;&#21464;&#21270;&#29305;&#21035;&#36866;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#35843;&#25972;&#25513;&#30721;&#24212;&#29992;&#20110;&#28145;&#23618;&#27425;&#30340;&#32456;&#36523;&#24378;&#21270;&#23398;&#20064;&#65292;&#20855;&#20307;&#21253;&#25324;PPO&#21644;IMPALA&#20195;&#29702;&#12290;&#22312;&#31163;&#25955;&#21644;&#36830;&#32493;&#24378;&#21270;&#23398;&#20064;&#20219;&#21153;&#20013;&#19982;&#32456;&#36523;&#24378;&#21270;&#23398;&#20064;&#22522;&#32447;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#32467;&#26524;&#26174;&#31034;&#20986;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#30740;&#31350;&#20102;&#20808;&#21069;&#20219;&#21153;&#30340;&#32447;&#24615;&#32452;&#21512;&#30340;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Lifelong learning aims to create AI systems that continuously and incrementally learn during a lifetime, similar to biological learning. Attempts so far have met problems, including catastrophic forgetting, interference among tasks, and the inability to exploit previous knowledge. While considerable research has focused on learning multiple supervised classification tasks that involve changes in the input distribution, lifelong reinforcement learning (LRL) must deal with variations in the state and transition distributions, and in the reward functions. Modulating masks with a fixed backbone network, recently developed for classification, are particularly suitable to deal with such a large spectrum of task variations. In this paper, we adapted modulating masks to work with deep LRL, specifically PPO and IMPALA agents. The comparison with LRL baselines in both discrete and continuous RL tasks shows superior performance. We further investigated the use of a linear combination of previousl
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#28145;&#24230;&#40654;&#26364;&#32593;&#32476;&#23545;EEG&#30340;&#24212;&#29992;&#65292;&#25506;&#35752;&#20102;&#32593;&#32476;&#22823;&#23567;&#12289;&#31471;&#21040;&#31471;&#33021;&#21147;&#12289;&#27169;&#22411;&#35757;&#32451;&#23545;&#27169;&#22411;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#24182;&#27604;&#36739;&#20102;&#20854;&#19982;&#22522;&#20110;&#40654;&#26364;&#20960;&#20309;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2212.10426</link><description>&lt;p&gt;
EEG&#35299;&#30721;&#30340;&#28145;&#24230;&#40654;&#26364;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Deep Riemannian Networks for EEG Decoding. (arXiv:2212.10426v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.10426
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#28145;&#24230;&#40654;&#26364;&#32593;&#32476;&#23545;EEG&#30340;&#24212;&#29992;&#65292;&#25506;&#35752;&#20102;&#32593;&#32476;&#22823;&#23567;&#12289;&#31471;&#21040;&#31471;&#33021;&#21147;&#12289;&#27169;&#22411;&#35757;&#32451;&#23545;&#27169;&#22411;&#24615;&#33021;&#30340;&#24433;&#21709;&#65292;&#24182;&#27604;&#36739;&#20102;&#20854;&#19982;&#22522;&#20110;&#40654;&#26364;&#20960;&#20309;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#22312;&#30005;&#33041;&#33041;&#30005;&#22270;&#65288;EEG&#65289;&#35299;&#30721;&#20219;&#21153;&#20013;&#65292;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#36890;&#24120;&#26159;&#30001;&#28145;&#24230;&#23398;&#20064;&#25110;&#22522;&#20110;&#40654;&#26364;&#20960;&#20309;&#30340;&#35299;&#30721;&#22120;&#23454;&#29616;&#30340;&#12290;&#26368;&#36817;&#65292;&#36234;&#26469;&#36234;&#22810;&#30340;&#20154;&#23545;&#28145;&#24230;&#40654;&#26364;&#32593;&#32476;&#65288;DRNs&#65289;&#20135;&#29983;&#20102;&#20852;&#36259;&#65292;&#21487;&#33021;&#32467;&#21512;&#20102;&#20043;&#21069;&#20004;&#31867;&#26041;&#27861;&#30340;&#20248;&#28857;&#12290;&#28982;&#32780;&#65292;&#36824;&#26377;&#19968;&#31995;&#21015;&#38382;&#39064;&#38656;&#35201;&#36827;&#19968;&#27493;&#27934;&#23519;&#65292;&#20197;&#38138;&#24179;DRNs&#22312;EEG&#20013;&#26356;&#24191;&#27867;&#24212;&#29992;&#30340;&#36947;&#36335;&#12290;&#36825;&#20123;&#38382;&#39064;&#21253;&#25324;&#26550;&#26500;&#35774;&#35745;&#38382;&#39064;&#65292;&#22914;&#32593;&#32476;&#22823;&#23567;&#21644;&#31471;&#21040;&#31471;&#33021;&#21147;&#65292;&#20197;&#21450;&#27169;&#22411;&#35757;&#32451;&#38382;&#39064;&#12290;&#36825;&#20123;&#22240;&#32032;&#22914;&#20309;&#24433;&#21709;&#27169;&#22411;&#24615;&#33021;&#23578;&#26410;&#34987;&#25506;&#32034;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#32593;&#32476;&#20013;&#30340;&#25968;&#25454;&#22914;&#20309;&#36716;&#25442;&#65292;&#20197;&#21450;&#26159;&#21542;&#19982;&#20256;&#32479;&#30340;EEG&#35299;&#30721;&#30456;&#20851;&#20063;&#19981;&#28165;&#26970;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#36890;&#36807;&#20998;&#26512;&#20855;&#26377;&#24191;&#27867;&#36229;&#21442;&#25968;&#30340;DRNs&#26469;&#22880;&#23450;&#36825;&#20123;&#20027;&#39064;&#39046;&#22495;&#30340;&#22522;&#30784;&#12290;&#20351;&#29992;&#20004;&#20010;&#20844;&#20849;EEG&#25968;&#25454;&#38598;&#27979;&#35797;&#20102;&#32593;&#32476;&#65292;&#24182;&#19982;&#26368;&#20808;&#36827;&#30340;&#22522;&#20110;&#40654;&#26364;&#20960;&#20309;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
State-of-the-art performance in electroencephalography (EEG) decoding tasks is currently often achieved with either Deep-Learning or Riemannian-Geometry-based decoders. Recently, there is growing interest in Deep Riemannian Networks (DRNs) possibly combining the advantages of both previous classes of methods. However, there are still a range of topics where additional insight is needed to pave the way for a more widespread application of DRNs in EEG. These include architecture design questions such as network size and end-to-end ability as well as model training questions. How these factors affect model performance has not been explored. Additionally, it is not clear how the data within these networks is transformed, and whether this would correlate with traditional EEG decoding. Our study aims to lay the groundwork in the area of these topics through the analysis of DRNs for EEG with a wide range of hyperparameters. Networks were tested on two public EEG datasets and compared with sta
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#24102;&#26377;&#27969;&#24418;&#32422;&#26463;&#21644;&#22797;&#21512;&#20108;&#27425;&#24809;&#32602;&#30340;&#22810;&#20219;&#21153;&#20989;&#25968;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;&#23545;&#26679;&#26465;&#31995;&#25968;&#30697;&#38453;&#36827;&#34892;&#21452;&#37325;&#27491;&#21017;&#21270;&#26469;&#23454;&#29616;&#26012;&#29575;&#20989;&#25968;&#30340;&#20272;&#35745;&#65292;&#36827;&#19968;&#27493;&#32467;&#21512;&#20102;&#22810;&#20219;&#21153;&#23398;&#20064;&#30340;&#20248;&#21183;&#12290;&#35813;&#27169;&#22411;&#21487;&#20197;&#34987;&#35270;&#20026;&#35768;&#22810;&#22810;&#20219;&#21153;&#23398;&#20064;&#26041;&#27861;&#30340;&#29305;&#20363;&#65292;&#21516;&#26102;&#22797;&#21512;&#24809;&#32602;&#24341;&#20837;&#20102;&#29305;&#23450;&#30340;&#33539;&#25968;&#65292;&#24110;&#21161;&#37327;&#21270;&#27969;&#24418;&#30340;&#26354;&#29575;&#24182;&#30830;&#23450;&#36866;&#24403;&#30340;&#23376;&#38598;&#12290;</title><link>http://arxiv.org/abs/2211.04874</link><description>&lt;p&gt;
&#24102;&#26377;&#27969;&#24418;&#32422;&#26463;&#21644;&#22797;&#21512;&#20108;&#27425;&#24809;&#32602;&#30340;&#22810;&#20219;&#21153;&#20989;&#25968;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#30340;&#32479;&#19968;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
A Unified Analysis of Multi-task Functional Linear Regression Models with Manifold Constraint and Composite Quadratic Penalty. (arXiv:2211.04874v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.04874
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#24102;&#26377;&#27969;&#24418;&#32422;&#26463;&#21644;&#22797;&#21512;&#20108;&#27425;&#24809;&#32602;&#30340;&#22810;&#20219;&#21153;&#20989;&#25968;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;&#23545;&#26679;&#26465;&#31995;&#25968;&#30697;&#38453;&#36827;&#34892;&#21452;&#37325;&#27491;&#21017;&#21270;&#26469;&#23454;&#29616;&#26012;&#29575;&#20989;&#25968;&#30340;&#20272;&#35745;&#65292;&#36827;&#19968;&#27493;&#32467;&#21512;&#20102;&#22810;&#20219;&#21153;&#23398;&#20064;&#30340;&#20248;&#21183;&#12290;&#35813;&#27169;&#22411;&#21487;&#20197;&#34987;&#35270;&#20026;&#35768;&#22810;&#22810;&#20219;&#21153;&#23398;&#20064;&#26041;&#27861;&#30340;&#29305;&#20363;&#65292;&#21516;&#26102;&#22797;&#21512;&#24809;&#32602;&#24341;&#20837;&#20102;&#29305;&#23450;&#30340;&#33539;&#25968;&#65292;&#24110;&#21161;&#37327;&#21270;&#27969;&#24418;&#30340;&#26354;&#29575;&#24182;&#30830;&#23450;&#36866;&#24403;&#30340;&#23376;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22810;&#20219;&#21153;&#20989;&#25968;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#65292;&#20854;&#20013;&#21327;&#21464;&#37327;&#21644;&#26410;&#30693;&#22238;&#24402;&#31995;&#25968;&#65288;&#31216;&#20026;&#26012;&#29575;&#20989;&#25968;&#65289;&#22343;&#20026;&#26354;&#32447;&#12290;&#20026;&#20102;&#26012;&#29575;&#20989;&#25968;&#20272;&#35745;&#65292;&#25105;&#20204;&#37319;&#29992;&#32602;&#21270;&#26679;&#26465;&#26469;&#24179;&#34913;&#20559;&#24046;&#12289;&#26041;&#24046;&#21644;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;&#22810;&#20219;&#21153;&#23398;&#20064;&#30340;&#20248;&#21183;&#22312;&#20110;&#36890;&#36807;&#23545;&#26012;&#29575;&#20989;&#25968;&#26045;&#21152;&#39069;&#22806;&#30340;&#32467;&#26500;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#27169;&#22411;&#65292;&#36890;&#36807;&#23545;&#26679;&#26465;&#31995;&#25968;&#30697;&#38453;&#36827;&#34892;&#21452;&#37325;&#27491;&#21017;&#21270;&#65306;i&#65289;&#30697;&#38453;&#27969;&#24418;&#32422;&#26463;&#65292;&#21644;ii&#65289;&#19968;&#20010;&#30001;&#20108;&#27425;&#39033;&#27714;&#21644;&#26500;&#25104;&#30340;&#22797;&#21512;&#24809;&#32602;&#12290;&#35768;&#22810;&#22810;&#20219;&#21153;&#23398;&#20064;&#26041;&#27861;&#37117;&#21487;&#20197;&#34987;&#35270;&#20026;&#35813;&#25552;&#20986;&#27169;&#22411;&#30340;&#29305;&#20363;&#65292;&#20363;&#22914;&#38477;&#31209;&#27169;&#22411;&#21644;&#22270;&#25289;&#26222;&#25289;&#26031;&#27491;&#21017;&#21270;&#27169;&#22411;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22797;&#21512;&#24809;&#32602;&#24341;&#20837;&#20102;&#19968;&#31181;&#29305;&#23450;&#30340;&#33539;&#25968;&#65292;&#26377;&#21161;&#20110;&#37327;&#21270;&#27969;&#24418;&#30340;&#26354;&#29575;&#65292;&#24182;&#30830;&#23450;&#27969;&#24418;&#20999;&#31354;&#38388;&#20013;&#30456;&#24212;&#30340;&#36866;&#24403;&#23376;&#38598;&#12290;&#28982;&#21518;&#65292;&#20999;&#31354;&#38388;&#23376;&#38598;&#30340;&#22797;&#26434;&#24230;&#19982;&#20960;&#20309;&#27969;&#24418;&#30340;&#22797;&#26434;&#24230;&#30456;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work studies the multi-task functional linear regression models where both the covariates and the unknown regression coefficients (called slope functions) are curves. For slope function estimation, we employ penalized splines to balance bias, variance, and computational complexity. The power of multi-task learning is brought in by imposing additional structures over the slope functions. We propose a general model with double regularization over the spline coefficient matrix: i) a matrix manifold constraint, and ii) a composite penalty as a summation of quadratic terms. Many multi-task learning approaches can be treated as special cases of this proposed model, such as a reduced-rank model and a graph Laplacian regularized model. We show the composite penalty induces a specific norm, which helps to quantify the manifold curvature and determine the corresponding proper subset in the manifold tangent space. The complexity of tangent space subset is then bridged to the complexity of ge
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#31867;&#20998;&#31867;&#22120;&#21644;&#24191;&#20041;&#20284;&#28982;&#27604;&#26816;&#39564;&#30340;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#22810;&#23618;&#24863;&#30693;&#22120;&#31070;&#32463;&#32593;&#32476;&#21644;&#25903;&#25345;&#21521;&#37327;&#26426;&#27169;&#22411;&#22312;&#25910;&#25947;&#26102;&#20250;&#34920;&#29616;&#20026;&#24191;&#20041;&#20284;&#28982;&#27604;&#26816;&#39564;&#12290;&#21516;&#26102;&#65292;&#20316;&#32773;&#36824;&#23637;&#31034;&#20102;&#19968;&#31867;&#26368;&#23567;&#20108;&#20056;SVM&#22312;&#25910;&#25947;&#26102;&#20063;&#33021;&#36798;&#21040;&#24191;&#20041;&#20284;&#28982;&#27604;&#26816;&#39564;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2210.12494</link><description>&lt;p&gt;
&#20851;&#20110;&#24191;&#20041;&#20284;&#28982;&#27604;&#26816;&#39564;&#21644;&#19968;&#31867;&#20998;&#31867;&#22120;
&lt;/p&gt;
&lt;p&gt;
On the Generalized Likelihood Ratio Test and One-Class Classifiers. (arXiv:2210.12494v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.12494
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#31867;&#20998;&#31867;&#22120;&#21644;&#24191;&#20041;&#20284;&#28982;&#27604;&#26816;&#39564;&#30340;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#22810;&#23618;&#24863;&#30693;&#22120;&#31070;&#32463;&#32593;&#32476;&#21644;&#25903;&#25345;&#21521;&#37327;&#26426;&#27169;&#22411;&#22312;&#25910;&#25947;&#26102;&#20250;&#34920;&#29616;&#20026;&#24191;&#20041;&#20284;&#28982;&#27604;&#26816;&#39564;&#12290;&#21516;&#26102;&#65292;&#20316;&#32773;&#36824;&#23637;&#31034;&#20102;&#19968;&#31867;&#26368;&#23567;&#20108;&#20056;SVM&#22312;&#25910;&#25947;&#26102;&#20063;&#33021;&#36798;&#21040;&#24191;&#20041;&#20284;&#28982;&#27604;&#26816;&#39564;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#31867;&#20998;&#31867;&#65288;OCC&#65289;&#26159;&#20915;&#23450;&#35266;&#23519;&#26679;&#26412;&#26159;&#21542;&#23646;&#20110;&#30446;&#26631;&#31867;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#32771;&#34385;&#22312;&#21253;&#21547;&#30446;&#26631;&#31867;&#26679;&#26412;&#30340;&#25968;&#25454;&#38598;&#19978;&#23398;&#20064;&#19968;&#20010;&#34920;&#29616;&#20026;&#24191;&#20041;&#20284;&#28982;&#27604;&#26816;&#39564;&#65288;GLRT&#65289;&#30340;OCC&#27169;&#22411;&#30340;&#38382;&#39064;&#12290;&#24403;&#30446;&#26631;&#31867;&#30340;&#32479;&#35745;&#20449;&#24687;&#21487;&#29992;&#26102;&#65292;GLRT&#35299;&#20915;&#20102;&#30456;&#21516;&#30340;&#38382;&#39064;&#12290;GLRT&#26159;&#19968;&#20010;&#20247;&#25152;&#21608;&#30693;&#19988;&#22312;&#29305;&#23450;&#26465;&#20214;&#19979;&#21487;&#35777;&#26126;&#26368;&#20339;&#30340;&#20998;&#31867;&#22120;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#22810;&#23618;&#24863;&#30693;&#22120;&#31070;&#32463;&#32593;&#32476;&#65288;NN&#65289;&#21644;&#25903;&#25345;&#21521;&#37327;&#26426;&#65288;SVM&#65289;&#27169;&#22411;&#12290;&#23427;&#20204;&#20351;&#29992;&#20154;&#24037;&#25968;&#25454;&#38598;&#35757;&#32451;&#20026;&#20004;&#31867;&#20998;&#31867;&#22120;&#65292;&#20854;&#20013;&#26367;&#20195;&#31867;&#20351;&#29992;&#22312;&#30446;&#26631;&#31867;&#25968;&#25454;&#38598;&#30340;&#23450;&#20041;&#22495;&#19978;&#22343;&#21248;&#29983;&#25104;&#30340;&#38543;&#26426;&#26679;&#26412;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#36866;&#24403;&#30340;&#20551;&#35774;&#19979;&#65292;&#27169;&#22411;&#22312;&#22823;&#25968;&#25454;&#38598;&#19978;&#25910;&#25947;&#21040;&#20102;GLRT&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#20855;&#26377;&#36866;&#24403;&#26680;&#20989;&#25968;&#30340;&#19968;&#31867;&#26368;&#23567;&#20108;&#20056;SVM&#65288;OCLSSVM&#65289;&#22312;&#25910;&#25947;&#26102;&#34920;&#29616;&#20026;GLRT&#12290;
&lt;/p&gt;
&lt;p&gt;
One-class classification (OCC) is the problem of deciding whether an observed sample belongs to a target class. We consider the problem of learning an OCC model that performs as the generalized likelihood ratio test (GLRT), given a dataset containing samples of the target class. The GLRT solves the same problem when the statistics of the target class are available. The GLRT is a well-known and provably optimal (under specific assumptions) classifier. To this end, we consider both the multilayer perceptron neural network (NN) and the support vector machine (SVM) models. They are trained as two-class classifiers using an artificial dataset for the alternative class, obtained by generating random samples, uniformly over the domain of the target-class dataset. We prove that, under suitable assumptions, the models converge (with a large dataset) to the GLRT. Moreover, we show that the one-class least squares SVM (OCLSSVM) with suitable kernels at convergence performs as the GLRT. Lastly, we
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28789;&#27963;&#30340;&#31639;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#21327;&#26041;&#24046;&#30697;&#38453;&#19978;&#20855;&#26377;&#20302;&#31209;&#32467;&#26500;&#32422;&#26463;&#30340;&#22270;&#23398;&#20064;&#12290;&#36890;&#36807;&#20351;&#29992;Riemannian&#20248;&#21270;&#65292;&#21033;&#29992;&#27491;&#23450;&#30697;&#38453;&#21644;&#22266;&#23450;&#31209;&#27491;&#21322;&#23450;&#30697;&#38453;&#30340;&#20960;&#20309;&#29305;&#24615;&#65292;&#35299;&#20915;&#20102;&#36825;&#31867;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2210.11950</link><description>&lt;p&gt;
&#29992;Riemannian&#20248;&#21270;&#23398;&#20064;&#22270;&#24418;&#22240;&#23376;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Learning Graphical Factor Models with Riemannian Optimization. (arXiv:2210.11950v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.11950
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28789;&#27963;&#30340;&#31639;&#27861;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#21327;&#26041;&#24046;&#30697;&#38453;&#19978;&#20855;&#26377;&#20302;&#31209;&#32467;&#26500;&#32422;&#26463;&#30340;&#22270;&#23398;&#20064;&#12290;&#36890;&#36807;&#20351;&#29992;Riemannian&#20248;&#21270;&#65292;&#21033;&#29992;&#27491;&#23450;&#30697;&#38453;&#21644;&#22266;&#23450;&#31209;&#27491;&#21322;&#23450;&#30697;&#38453;&#30340;&#20960;&#20309;&#29305;&#24615;&#65292;&#35299;&#20915;&#20102;&#36825;&#31867;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#24418;&#27169;&#22411;&#21644;&#22240;&#23376;&#20998;&#26512;&#26159;&#22810;&#20803;&#32479;&#35745;&#23398;&#20013;&#25104;&#29087;&#30340;&#24037;&#20855;&#12290;&#23613;&#31649;&#36825;&#20123;&#27169;&#22411;&#37117;&#21487;&#20197;&#19982;&#21327;&#26041;&#24046;&#21644;&#31934;&#24230;&#30697;&#38453;&#30340;&#32467;&#26500;&#32852;&#31995;&#36215;&#26469;&#65292;&#20294;&#23427;&#20204;&#36890;&#24120;&#22312;&#22270;&#30340;&#23398;&#20064;&#36807;&#31243;&#20013;&#27809;&#26377;&#34987;&#20849;&#21516;&#21033;&#29992;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#36890;&#36807;&#25552;&#20986;&#19968;&#31181;&#22312;&#21327;&#26041;&#24046;&#30697;&#38453;&#19978;&#20855;&#26377;&#20302;&#31209;&#32467;&#26500;&#32422;&#26463;&#30340;&#22270;&#23398;&#20064;&#30340;&#28789;&#27963;&#31639;&#27861;&#26694;&#26550;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#35813;&#38382;&#39064;&#34987;&#34920;&#36798;&#20026;&#22522;&#20110;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#32602;&#20989;&#25968;&#26041;&#27861;&#65292;&#20854;&#20013;&#21327;&#26041;&#24046;&#30697;&#38453;&#21487;&#20197;&#36873;&#25321;&#24615;&#22320;&#34987;&#32422;&#26463;&#20026;&#20302;&#31209;&#21152;&#23545;&#35282;&#32447;&#32467;&#26500;&#65288;&#20302;&#31209;&#22240;&#23376;&#27169;&#22411;&#65289;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;&#27491;&#23450;&#30697;&#38453;&#21644;&#22266;&#23450;&#31209;&#27491;&#21322;&#23450;&#30697;&#38453;&#30340;&#20960;&#20309;&#29305;&#24615;&#65288;&#36825;&#20123;&#29305;&#24615;&#38750;&#24120;&#36866;&#29992;&#20110;&#26925;&#22278;&#27169;&#22411;&#65289;&#26469;&#35299;&#20915;&#36825;&#31867;&#38382;&#39064;&#20013;&#30340;&#26368;&#20248;&#21270;&#38382;&#39064;&#12290;&#25968;&#20540;&#23454;&#39564;
&lt;/p&gt;
&lt;p&gt;
Graphical models and factor analysis are well-established tools in multivariate statistics. While these models can be both linked to structures exhibited by covariance and precision matrices, they are generally not jointly leveraged within graph learning processes. This paper therefore addresses this issue by proposing a flexible algorithmic framework for graph learning under low-rank structural constraints on the covariance matrix. The problem is expressed as penalized maximum likelihood estimation of an elliptical distribution (a generalization of Gaussian graphical models to possibly heavy-tailed distributions), where the covariance matrix is optionally constrained to be structured as low-rank plus diagonal (low-rank factor model). The resolution of this class of problems is then tackled with Riemannian optimization, where we leverage geometries of positive definite matrices and positive semi-definite matrices of fixed rank that are well suited to elliptical models. Numerical experi
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20197;&#36827;&#34892;&#21452;&#21521;&#20114;&#21160;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20801;&#35768;&#31070;&#32463;&#32593;&#32476;&#23637;&#31034;&#20854;&#25152;&#23398;&#22240;&#26524;&#22270;&#65292;&#24182;&#20801;&#35768;&#20154;&#31867;&#20462;&#25913;&#22240;&#26524;&#22270;&#21518;&#37325;&#26032;&#27880;&#20837;&#26426;&#22120;&#20013;&#65292;&#20174;&#32780;&#25552;&#20379;&#20102;&#19968;&#31181;&#35843;&#35797;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#24335;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#35813;&#26041;&#27861;&#21487;&#20197;&#26174;&#33879;&#25913;&#21892;&#39044;&#27979;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2205.09787</link><description>&lt;p&gt;
&#21487;&#20105;&#35758;&#31070;&#32463;&#32593;&#32476;&#30340;&#22240;&#26524;&#21457;&#29616;&#19982;&#30693;&#35782;&#27880;&#20837;
&lt;/p&gt;
&lt;p&gt;
Causal Discovery and Knowledge Injection for Contestable Neural Networks. (arXiv:2205.09787v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.09787
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#20197;&#36827;&#34892;&#21452;&#21521;&#20114;&#21160;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20801;&#35768;&#31070;&#32463;&#32593;&#32476;&#23637;&#31034;&#20854;&#25152;&#23398;&#22240;&#26524;&#22270;&#65292;&#24182;&#20801;&#35768;&#20154;&#31867;&#20462;&#25913;&#22240;&#26524;&#22270;&#21518;&#37325;&#26032;&#27880;&#20837;&#26426;&#22120;&#20013;&#65292;&#20174;&#32780;&#25552;&#20379;&#20102;&#19968;&#31181;&#35843;&#35797;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#24335;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#35813;&#26041;&#27861;&#21487;&#20197;&#26174;&#33879;&#25913;&#21892;&#39044;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#22312;&#35299;&#20915;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#23427;&#20204;&#26159;&#21542;&#23398;&#20064;&#21040;&#20102;&#30456;&#20851;&#30340;&#22240;&#26524;&#20851;&#31995;&#23578;&#19981;&#28165;&#26970;&#65292;&#32780;&#23427;&#20204;&#30340;&#40657;&#31665;&#29305;&#24615;&#20351;&#24471;&#27169;&#22411;&#26500;&#24314;&#32773;&#38590;&#20197;&#29702;&#35299;&#21644;&#35843;&#35797;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#36890;&#36807;&#20801;&#35768;&#31070;&#32463;&#32593;&#32476;&#39537;&#21160;&#30340;&#26426;&#22120;&#23637;&#31034;&#20854;&#25152;&#23398;&#22240;&#26524;&#22270;&#65292;&#24182;&#20801;&#35768;&#20154;&#31867;&#20462;&#25913;&#22240;&#26524;&#22270;&#21518;&#37325;&#26032;&#27880;&#20837;&#26426;&#22120;&#20013;&#65292;&#23454;&#29616;&#21452;&#21521;&#20114;&#21160;&#12290;&#25152;&#23398;&#27169;&#22411;&#20445;&#35777;&#31526;&#21512;&#22240;&#26524;&#22270;&#24182;&#36981;&#24490;&#19987;&#23478;&#30693;&#35782;&#65292;&#20854;&#20013;&#37096;&#20998;&#30693;&#35782;&#20063;&#21487;&#20197;&#20107;&#20808;&#32473;&#23450;&#12290;&#36890;&#36807;&#23545;&#27169;&#22411;&#34892;&#20026;&#36827;&#34892;&#21487;&#35270;&#21270;&#24182;&#23454;&#29616;&#30693;&#35782;&#27880;&#20837;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20801;&#35768;&#20174;&#25968;&#25454;&#20013;&#21457;&#29616;&#22240;&#26524;&#32467;&#26500;&#24182;&#25903;&#25745;&#39044;&#27979;&#30340;&#20174;&#19994;&#32773;&#36827;&#34892;&#35843;&#35797;&#12290;&#22312;&#30495;&#23454;&#21644;&#21512;&#25104;&#34920;&#26684;&#25968;&#25454;&#19978;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#25913;&#36827;&#39044;&#27979;&#24615;&#33021;&#39640;&#36798;2.4&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural networks have proven to be effective at solving machine learning tasks but it is unclear whether they learn any relevant causal relationships, while their black-box nature makes it difficult for modellers to understand and debug them. We propose a novel method overcoming these issues by allowing a two-way interaction whereby neural-network-empowered machines can expose the underpinning learnt causal graphs and humans can contest the machines by modifying the causal graphs before re-injecting them into the machines. The learnt models are guaranteed to conform to the graphs and adhere to expert knowledge, some of which can also be given up-front. By building a window into the model behaviour and enabling knowledge injection, our method allows practitioners to debug networks based on the causal structure discovered from the data and underpinning the predictions. Experiments with real and synthetic tabular data show that our method improves predictive performance up to 2.4x while pr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#30456;&#20851;&#32500;&#26684;&#32435;&#27169;&#22411;&#19979;&#30340;&#26377;&#31181;&#23376;&#22270;&#21305;&#37197;&#38382;&#39064;&#65292;&#36890;&#36807;&#20998;&#26512;&#34920;&#26126;&#65292;&#20351;&#29992;&#25237;&#24433;&#21151;&#29575;&#26041;&#27861;&#65288;PPM&#65289;&#20316;&#20026;&#22270;&#21305;&#37197;&#31639;&#27861;&#21487;&#20197;&#22312;&#32473;&#23450;&#25509;&#36817;&#30495;&#23454;&#21305;&#37197;&#30340;&#31181;&#23376;&#30340;&#24773;&#20917;&#19979;&#39640;&#27010;&#29575;&#22320;&#25913;&#36827;&#31181;&#23376;&#24182;&#24674;&#22797;&#30495;&#23454;&#21305;&#37197;&#12290;</title><link>http://arxiv.org/abs/2204.04099</link><description>&lt;p&gt;
&#36890;&#36807;&#25237;&#24433;&#21151;&#29575;&#26041;&#27861;&#36827;&#34892;&#30456;&#20851;&#32500;&#26684;&#32435;&#27169;&#22411;&#30340;&#26377;&#31181;&#23376;&#22270;&#21305;&#37197;
&lt;/p&gt;
&lt;p&gt;
Seeded graph matching for the correlated Wigner model via the projected power method. (arXiv:2204.04099v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.04099
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#30456;&#20851;&#32500;&#26684;&#32435;&#27169;&#22411;&#19979;&#30340;&#26377;&#31181;&#23376;&#22270;&#21305;&#37197;&#38382;&#39064;&#65292;&#36890;&#36807;&#20998;&#26512;&#34920;&#26126;&#65292;&#20351;&#29992;&#25237;&#24433;&#21151;&#29575;&#26041;&#27861;&#65288;PPM&#65289;&#20316;&#20026;&#22270;&#21305;&#37197;&#31639;&#27861;&#21487;&#20197;&#22312;&#32473;&#23450;&#25509;&#36817;&#30495;&#23454;&#21305;&#37197;&#30340;&#31181;&#23376;&#30340;&#24773;&#20917;&#19979;&#39640;&#27010;&#29575;&#22320;&#25913;&#36827;&#31181;&#23376;&#24182;&#24674;&#22797;&#30495;&#23454;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22270;&#21305;&#37197;&#38382;&#39064;&#20013;&#65292;&#25105;&#20204;&#35266;&#23519;&#20004;&#20010;&#22270;G&#21644;H&#65292;&#24182;&#36890;&#36807;&#26368;&#22823;&#21270;&#36793;&#21327;&#35758;&#30340;&#19968;&#20123;&#24230;&#37327;&#26469;&#25214;&#21040;&#23427;&#20204;&#39030;&#28857;&#20043;&#38388;&#30340;&#36171;&#20540;&#65288;&#25110;&#21305;&#37197;&#65289;&#12290;&#25105;&#20204;&#20551;&#35774;&#35266;&#23519;&#21040;&#30340;&#22270;&#23545;G&#21644;H&#26159;&#20174;&#30456;&#20851;&#32500;&#26684;&#32435;&#27169;&#22411;&#20013;&#25277;&#21462;&#30340;&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20110;&#30456;&#20851;&#21152;&#26435;&#22270;&#30340;&#27969;&#34892;&#27169;&#22411;&#65292;&#20854;&#20013;G&#21644;H&#30340;&#37051;&#25509;&#30697;&#38453;&#30340;&#20803;&#32032;&#26159;&#29420;&#31435;&#30340;&#39640;&#26031;&#20998;&#24067;&#65292;&#24182;&#19988;G&#30340;&#27599;&#26465;&#36793;&#19982;H&#30340;&#20854;&#20013;&#19968;&#26465;&#36793;&#65288;&#30001;&#26410;&#30693;&#30340;&#21305;&#37197;&#30830;&#23450;&#65289;&#30456;&#20851;&#32852;&#65292;&#36793;&#30456;&#20851;&#24615;&#30001;&#21442;&#25968;&#963;&#8712;[0,1)&#25551;&#36848;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#20316;&#20026;&#8220;&#26377;&#31181;&#23376;&#8221;&#30340;&#22270;&#21305;&#37197;&#31639;&#27861;&#30340;&#8220;&#25237;&#24433;&#21151;&#29575;&#26041;&#27861;&#8221;&#65288;PPM&#65289;&#30340;&#24615;&#33021;&#65292;&#20854;&#20013;&#25105;&#20204;&#25552;&#20379;&#19968;&#20010;&#37096;&#20998;&#27491;&#30830;&#30340;&#21021;&#22987;&#21305;&#37197;&#65288;&#31216;&#20026;&#31181;&#23376;&#65289;&#20316;&#20026;&#38468;&#21152;&#20449;&#24687;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22914;&#26524;&#31181;&#23376;&#36275;&#22815;&#25509;&#36817;&#30495;&#23454;&#21305;&#37197;&#65292;&#21017;PPM&#22312;&#39640;&#27010;&#29575;&#19979;&#20250;&#36845;&#20195;&#25913;&#36827;&#31181;&#23376;&#24182;&#24674;&#22797;&#30495;&#23454;&#21305;&#37197;&#65288;&#25110;&#24674;&#22797;&#26368;&#22823;&#21270;&#36793;&#21327;&#35758;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the \emph{graph matching} problem we observe two graphs $G,H$ and the goal is to find an assignment (or matching) between their vertices such that some measure of edge agreement is maximized. We assume in this work that the observed pair $G,H$ has been drawn from the correlated Wigner model -- a popular model for correlated weighted graphs -- where the entries of the adjacency matrices of $G$ and $H$ are independent Gaussians and each edge of $G$ is correlated with one edge of $H$ (determined by the unknown matching) with the edge correlation described by a parameter $\sigma\in [0,1)$. In this paper, we analyse the performance of the \emph{projected power method} (PPM) as a \emph{seeded} graph matching algorithm where we are given an initial partially correct matching (called the seed) as side information. We prove that if the seed is close enough to the ground-truth matching, then with high probability, PPM iteratively improves the seed and recovers the ground-truth matching (eithe
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#28145;&#24230;&#25209;&#37327;&#20027;&#21160;&#23398;&#20064;&#22238;&#24402;&#30340;&#26694;&#26550;&#21644;&#22522;&#20934;&#27979;&#35797;&#65292;&#20854;&#20013;&#21253;&#25324;&#35768;&#22810;&#29616;&#26377;&#30340;&#36125;&#21494;&#26031;&#21644;&#38750;&#36125;&#21494;&#26031;&#26041;&#27861;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#26367;&#25442;&#24120;&#29992;&#26368;&#21518;&#19968;&#23618;&#29305;&#24449;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#32467;&#21512;&#19968;&#31181;&#26032;&#39062;&#30340;&#32858;&#31867;&#26041;&#27861;&#12290;&#22312;15&#20010;&#22823;&#22411;&#34920;&#26684;&#22238;&#24402;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#27979;&#35797;&#65292;&#35813;&#26041;&#27861;&#22312;&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20248;&#24322;&#65292;&#36866;&#29992;&#20110;&#22823;&#22411;&#25968;&#25454;&#38598;&#19988;&#26131;&#20110;&#20351;&#29992;&#12290;</title><link>http://arxiv.org/abs/2203.09410</link><description>&lt;p&gt;
&#28145;&#24230;&#25209;&#37327;&#20027;&#21160;&#23398;&#20064;&#22238;&#24402;&#30340;&#26694;&#26550;&#21644;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
A Framework and Benchmark for Deep Batch Active Learning for Regression. (arXiv:2203.09410v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.09410
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#28145;&#24230;&#25209;&#37327;&#20027;&#21160;&#23398;&#20064;&#22238;&#24402;&#30340;&#26694;&#26550;&#21644;&#22522;&#20934;&#27979;&#35797;&#65292;&#20854;&#20013;&#21253;&#25324;&#35768;&#22810;&#29616;&#26377;&#30340;&#36125;&#21494;&#26031;&#21644;&#38750;&#36125;&#21494;&#26031;&#26041;&#27861;&#12290;&#25552;&#20986;&#20102;&#19968;&#31181;&#26367;&#25442;&#24120;&#29992;&#26368;&#21518;&#19968;&#23618;&#29305;&#24449;&#30340;&#26032;&#26041;&#27861;&#65292;&#24182;&#32467;&#21512;&#19968;&#31181;&#26032;&#39062;&#30340;&#32858;&#31867;&#26041;&#27861;&#12290;&#22312;15&#20010;&#22823;&#22411;&#34920;&#26684;&#22238;&#24402;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#27979;&#35797;&#65292;&#35813;&#26041;&#27861;&#22312;&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20248;&#24322;&#65292;&#36866;&#29992;&#20110;&#22823;&#22411;&#25968;&#25454;&#38598;&#19988;&#26131;&#20110;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#27880;&#30417;&#30563;&#23398;&#20064;&#25968;&#25454;&#30340;&#33719;&#21462;&#25104;&#26412;&#36739;&#39640;&#12290;&#20026;&#20102;&#25552;&#39640;&#31070;&#32463;&#32593;&#32476;&#22238;&#24402;&#30340;&#26679;&#26412;&#25928;&#29575;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#33258;&#36866;&#24212;&#36873;&#25321;&#26080;&#26631;&#31614;&#25968;&#25454;&#25209;&#27425;&#36827;&#34892;&#26631;&#27880;&#30340;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#29992;&#20110;&#26500;&#24314;&#36825;&#26679;&#30340;&#26041;&#27861;&#65292;&#22522;&#20110;(&#32593;&#32476;&#30456;&#20851;&#30340;)&#22522;&#30784;&#26680;&#12289;&#26680;&#21464;&#25442;&#21644;&#36873;&#25321;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21253;&#25324;&#35768;&#22810;&#29616;&#26377;&#30340;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#36924;&#36817;&#31070;&#32463;&#32593;&#32476;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#20197;&#21450;&#38750;&#36125;&#21494;&#26031;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24314;&#35758;&#29992;&#25551;&#32472;&#26377;&#38480;&#23485;&#24230;&#31070;&#32463;&#27491;&#20999;&#26680;&#26367;&#25442;&#24120;&#29992;&#30340;&#26368;&#21518;&#19968;&#23618;&#29305;&#24449;&#65292;&#24182;&#23558;&#23427;&#20204;&#19982;&#19968;&#31181;&#26032;&#39062;&#30340;&#32858;&#31867;&#26041;&#27861;&#30456;&#32467;&#21512;&#12290;&#20026;&#20102;&#35780;&#20272;&#19981;&#21516;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#30001;15&#20010;&#22823;&#22411;&#34920;&#26684;&#22238;&#24402;&#25968;&#25454;&#38598;&#32452;&#25104;&#30340;&#24320;&#25918;&#28304;&#20195;&#30721;&#30340;&#22522;&#20934;&#27979;&#35797;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#22522;&#20934;&#27979;&#35797;&#20013;&#20248;&#20110;&#29616;&#26377;&#25216;&#26415;&#27700;&#24179;&#65292;&#36866;&#29992;&#20110;&#22823;&#22411;&#25968;&#25454;&#38598;&#65292;&#24182;&#19988;&#21487;&#20197;&#30452;&#25509;&#20351;&#29992;&#65292;&#26080;&#38656;&#35843;&#25972;&#32593;&#32476;&#26550;&#26500;&#25110;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
The acquisition of labels for supervised learning can be expensive. In order to improve the sample-efficiency of neural network regression, we study active learning methods that adaptively select batches of unlabeled data for labeling. We present a framework for constructing such methods out of (network-dependent) base kernels, kernel transformations and selection methods. Our framework encompasses many existing Bayesian methods based on Gaussian Process approximations of neural networks as well as non-Bayesian methods. Additionally, we propose to replace the commonly used last-layer features with sketched finite-width Neural Tangent Kernels, and to combine them with a novel clustering method. To evaluate different methods, we introduce an open-source benchmark consisting of 15 large tabular regression data sets. Our proposed method outperforms the state-of-the-art on our benchmark, scales to large data sets, and works out-of-the-box without adjusting the network architecture or traini
&lt;/p&gt;</description></item><item><title>AgraSSt&#26159;&#19968;&#31181;&#29992;&#20110;&#35780;&#20272;&#38544;&#24335;&#22270;&#29983;&#25104;&#22120;&#36136;&#37327;&#30340;&#32479;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#22522;&#20110;&#26680;&#30340;&#24046;&#24322;&#24230;&#37327;&#65292;&#23427;&#33021;&#22815;&#30830;&#23450;&#23398;&#20064;&#21040;&#30340;&#22270;&#29983;&#25104;&#36807;&#31243;&#26159;&#21542;&#33021;&#29983;&#25104;&#31867;&#20284;&#32473;&#23450;&#36755;&#20837;&#22270;&#30340;&#22270;&#24418;&#65292;&#24182;&#25552;&#20379;&#26377;&#20851;&#22270;&#29983;&#25104;&#22120;&#35757;&#32451;&#36807;&#31243;&#30340;&#21487;&#35299;&#37322;&#24615;&#38382;&#39064;&#21644;&#21487;&#38752;&#26679;&#26412;&#25209;&#27425;&#30340;&#20449;&#24687;&#12290;</title><link>http://arxiv.org/abs/2203.03673</link><description>&lt;p&gt;
AgraSSt: &#36866;&#29992;&#20110;&#35299;&#37322;&#24615;&#35780;&#20272;&#38544;&#24335;&#22270;&#29983;&#25104;&#22120;&#30340;&#36817;&#20284;&#22270;&#26031;&#22374;&#32479;&#35745;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
AgraSSt: Approximate Graph Stein Statistics for Interpretable Assessment of Implicit Graph Generators. (arXiv:2203.03673v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.03673
&lt;/p&gt;
&lt;p&gt;
AgraSSt&#26159;&#19968;&#31181;&#29992;&#20110;&#35780;&#20272;&#38544;&#24335;&#22270;&#29983;&#25104;&#22120;&#36136;&#37327;&#30340;&#32479;&#35745;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#22522;&#20110;&#26680;&#30340;&#24046;&#24322;&#24230;&#37327;&#65292;&#23427;&#33021;&#22815;&#30830;&#23450;&#23398;&#20064;&#21040;&#30340;&#22270;&#29983;&#25104;&#36807;&#31243;&#26159;&#21542;&#33021;&#29983;&#25104;&#31867;&#20284;&#32473;&#23450;&#36755;&#20837;&#22270;&#30340;&#22270;&#24418;&#65292;&#24182;&#25552;&#20379;&#26377;&#20851;&#22270;&#29983;&#25104;&#22120;&#35757;&#32451;&#36807;&#31243;&#30340;&#21487;&#35299;&#37322;&#24615;&#38382;&#39064;&#21644;&#21487;&#38752;&#26679;&#26412;&#25209;&#27425;&#30340;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#24182;&#20998;&#26512;&#20102;&#19968;&#31181;&#26032;&#30340;&#32479;&#35745;&#26041;&#27861;&#65292;&#31216;&#20026;AgraSSt&#65292;&#29992;&#20110;&#35780;&#20272;&#21487;&#33021;&#19981;&#23384;&#22312;&#26174;&#24335;&#24418;&#24335;&#30340;&#22270;&#29983;&#25104;&#22120;&#30340;&#36136;&#37327;&#12290;&#29305;&#21035;&#22320;&#65292;AgraSSt&#21487;&#29992;&#20110;&#30830;&#23450;&#23398;&#20064;&#21040;&#30340;&#22270;&#29983;&#25104;&#36807;&#31243;&#33021;&#21542;&#29983;&#25104;&#31867;&#20284;&#32473;&#23450;&#36755;&#20837;&#22270;&#30340;&#22270;&#24418;&#12290;&#21463;&#38543;&#26426;&#22270;&#30340;&#26031;&#22374;&#25805;&#32437;&#31526;&#21551;&#21457;&#65292;AgraSSt&#30340;&#20851;&#38190;&#24605;&#24819;&#26159;&#22522;&#20110;&#20174;&#22270;&#29983;&#25104;&#22120;&#33719;&#24471;&#30340;&#25805;&#20316;&#31526;&#26500;&#24314;&#22522;&#20110;&#26680;&#30340;&#24046;&#24322;&#24230;&#37327;&#12290;AgraSSt&#21487;&#20197;&#20026;&#22270;&#29983;&#25104;&#22120;&#35757;&#32451;&#36807;&#31243;&#25552;&#20379;&#21487;&#35299;&#37322;&#30340;&#38382;&#39064;&#65292;&#24182;&#24110;&#21161;&#35782;&#21035;&#21487;&#38752;&#30340;&#26679;&#26412;&#25209;&#27425;&#29992;&#20110;&#19979;&#28216;&#20219;&#21153;&#12290;&#21033;&#29992;&#26031;&#22374;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#23545;&#24191;&#27867;&#30340;&#38543;&#26426;&#22270;&#27169;&#22411;&#32473;&#20986;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;&#25105;&#20204;&#22312;&#24050;&#30693;&#22270;&#29983;&#25104;&#36807;&#31243;&#30340;&#21512;&#25104;&#36755;&#20837;&#22270;&#21644;&#26368;&#20808;&#36827;&#30340;&#65288;&#28145;&#24230;&#65289;&#22270;&#29983;&#25104;&#27169;&#22411;&#35757;&#32451;&#30340;&#30495;&#23454;&#19990;&#30028;&#36755;&#20837;&#22270;&#19978;&#25552;&#20379;&#20102;&#23454;&#35777;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose and analyse a novel statistical procedure, coined AgraSSt, to assess the quality of graph generators that may not be available in explicit form. In particular, AgraSSt can be used to determine whether a learnt graph generating process is capable of generating graphs that resemble a given input graph. Inspired by Stein operators for random graphs, the key idea of AgraSSt is the construction of a kernel discrepancy based on an operator obtained from the graph generator. AgraSSt can provide interpretable criticisms for a graph generator training procedure and help identify reliable sample batches for downstream tasks. Using Stein`s method we give theoretical guarantees for a broad class of random graph models. We provide empirical results on both synthetic input graphs with known graph generation procedures, and real-world input graphs that the state-of-the-art (deep) generative models for graphs are trained on.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#32447;&#24615;&#22238;&#24402;&#24773;&#20917;&#30340;&#36801;&#31227;&#23398;&#20064;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#23558;&#26032;&#25968;&#25454;&#19982;&#21382;&#21490;&#25968;&#25454;&#30456;&#32467;&#21512;&#65292;&#29305;&#21035;&#22312;&#26032;&#25968;&#25454;&#31232;&#32570;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#30410;&#22788;&#65292;&#24182;&#19988;&#22312;&#23454;&#39564;&#39564;&#35777;&#20013;&#34920;&#29616;&#20986;&#23545;&#36127;&#36801;&#31227;&#23398;&#20064;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2202.05069</link><description>&lt;p&gt;
&#19981;&#21516;&#36755;&#20837;&#32500;&#24230;&#25968;&#25454;&#38598;&#20043;&#38388;&#30340;&#36801;&#31227;&#23398;&#20064;&#65306;&#32447;&#24615;&#22238;&#24402;&#24773;&#20917;&#19979;&#30340;&#31639;&#27861;&#21644;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Transfer-Learning Across Datasets with Different Input Dimensions: An Algorithm and Analysis for the Linear Regression Case. (arXiv:2202.05069v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.05069
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#32447;&#24615;&#22238;&#24402;&#24773;&#20917;&#30340;&#36801;&#31227;&#23398;&#20064;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#23558;&#26032;&#25968;&#25454;&#19982;&#21382;&#21490;&#25968;&#25454;&#30456;&#32467;&#21512;&#65292;&#29305;&#21035;&#22312;&#26032;&#25968;&#25454;&#31232;&#32570;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#30410;&#22788;&#65292;&#24182;&#19988;&#22312;&#23454;&#39564;&#39564;&#35777;&#20013;&#34920;&#29616;&#20986;&#23545;&#36127;&#36801;&#31227;&#23398;&#20064;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#26032;&#20256;&#24863;&#22120;&#21644;&#30417;&#27979;&#35774;&#22791;&#30340;&#21457;&#23637;&#65292;&#36234;&#26469;&#36234;&#22810;&#30340;&#25968;&#25454;&#28304;&#21487;&#20197;&#20316;&#20026;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#36755;&#20837;&#12290;&#36825;&#20123;&#25968;&#25454;&#26082;&#21487;&#20197;&#24110;&#21161;&#25552;&#39640;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#65292;&#20294;&#23558;&#36825;&#20123;&#26032;&#36755;&#20837;&#19982;&#21382;&#21490;&#25968;&#25454;&#30456;&#32467;&#21512;&#20173;&#28982;&#26159;&#19968;&#20010;&#23578;&#26410;&#35814;&#32454;&#30740;&#31350;&#30340;&#25361;&#25112;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36801;&#31227;&#23398;&#20064;&#31639;&#27861;&#65292;&#23558;&#26032;&#25968;&#25454;&#21644;&#21382;&#21490;&#25968;&#25454;&#32467;&#21512;&#36215;&#26469;&#65292;&#29305;&#21035;&#22312;&#26032;&#25968;&#25454;&#31232;&#32570;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#30410;&#22788;&#12290;&#25105;&#20204;&#23558;&#37325;&#28857;&#25918;&#22312;&#32447;&#24615;&#22238;&#24402;&#24773;&#20917;&#19979;&#65292;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#23545;&#35813;&#26041;&#27861;&#30340;&#30410;&#22788;&#36827;&#34892;&#20005;&#26684;&#30340;&#29702;&#35770;&#30740;&#31350;&#12290;&#25105;&#20204;&#34920;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#23545;&#36127;&#36801;&#31227;&#23398;&#20064;&#26159;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#65292;&#24182;&#36890;&#36807;&#30495;&#23454;&#21644;&#27169;&#25311;&#25968;&#25454;&#36827;&#34892;&#20102;&#23454;&#35777;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the development of new sensors and monitoring devices, more sources of data become available to be used as inputs for machine learning models. These can on the one hand help to improve the accuracy of a model. On the other hand however, combining these new inputs with historical data remains a challenge that has not yet been studied in enough detail. In this work, we propose a transfer-learning algorithm that combines the new and the historical data, that is especially beneficial when the new data is scarce. We focus the approach on the linear regression case, which allows us to conduct a rigorous theoretical study on the benefits of the approach. We show that our approach is robust against negative transfer-learning, and we confirm this result empirically with real and simulated data.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20998;&#26512;&#22810;&#20803;&#26497;&#20540;&#30340;&#35889;&#32858;&#31867;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#21644;&#25968;&#20540;&#23454;&#39564;&#23637;&#31034;&#20102;&#20854;&#22312;&#23398;&#20064;&#35282;&#24230;&#27979;&#24230;&#26041;&#38754;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2111.07799</link><description>&lt;p&gt;
&#22810;&#20803;&#26497;&#20540;&#30340;&#35889;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Spectral learning of multivariate extremes. (arXiv:2111.07799v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.07799
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20998;&#26512;&#22810;&#20803;&#26497;&#20540;&#30340;&#35889;&#32858;&#31867;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#21644;&#25968;&#20540;&#23454;&#39564;&#23637;&#31034;&#20102;&#20854;&#22312;&#23398;&#20064;&#35282;&#24230;&#27979;&#24230;&#26041;&#38754;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#20998;&#26512;&#22810;&#20803;&#26497;&#20540;&#30340;&#35889;&#32858;&#31867;&#31639;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20851;&#27880;&#26497;&#20540;&#29702;&#35770;&#20013;&#30001;&#35282;&#24230;&#25110;&#35889;&#27979;&#24230;&#34920;&#24449;&#30340;&#22810;&#20803;&#26497;&#20540;&#30340;&#28176;&#36817;&#20381;&#36182;&#24615;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#30740;&#31350;&#20102;&#35889;&#32858;&#31867;&#30340;&#29702;&#35770;&#24615;&#33021;&#65292;&#35813;&#32858;&#31867;&#22522;&#20110;&#20174;&#26497;&#20540;&#26679;&#26412;&#20013;&#26500;&#24314;&#30340;&#38543;&#26426;k&#26368;&#36817;&#37051;&#22270;&#65292;&#21363;&#23545;&#20110;&#21322;&#24452;&#36229;&#36807;&#19968;&#20010;&#36739;&#22823;&#38408;&#20540;&#30340;&#38543;&#26426;&#21521;&#37327;&#30340;&#35282;&#24230;&#37096;&#20998;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#32447;&#24615;&#22240;&#23376;&#27169;&#22411;&#20135;&#29983;&#30340;&#26497;&#20540;&#30340;&#28176;&#36817;&#20998;&#24067;&#65292;&#24182;&#35777;&#26126;&#65292;&#22312;&#26576;&#20123;&#26465;&#20214;&#19979;&#65292;&#35889;&#32858;&#31867;&#21487;&#20197;&#19968;&#33268;&#22320;&#35782;&#21035;&#20986;&#22312;&#35813;&#27169;&#22411;&#20013;&#20135;&#29983;&#30340;&#26497;&#20540;&#30340;&#32858;&#31867;&#12290;&#22522;&#20110;&#36825;&#20010;&#32467;&#26524;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#19968;&#33268;&#24615;&#20272;&#35745;&#31574;&#30053;&#26469;&#23398;&#20064;&#35282;&#24230;&#27979;&#24230;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#19982;&#25968;&#20540;&#23454;&#39564;&#30456;&#32467;&#21512;&#65292;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#22312;&#26377;&#38480;&#26679;&#26412;&#24773;&#20917;&#19979;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a spectral clustering algorithm for analyzing the dependence structure of multivariate extremes. More specifically, we focus on the asymptotic dependence of multivariate extremes characterized by the angular or spectral measure in extreme value theory. Our work studies the theoretical performance of spectral clustering based on a random $k$-nearest neighbor graph constructed from an extremal sample, i.e., the angular part of random vectors for which the radius exceeds a large threshold. In particular, we derive the asymptotic distribution of extremes arising from a linear factor model and prove that, under certain conditions, spectral clustering can consistently identify the clusters of extremes arising in this model. Leveraging this result we propose a simple consistent estimation strategy for learning the angular measure. Our theoretical findings are complemented with numerical experiments illustrating the finite sample performance of our methods.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32508;&#21512;&#26465;&#20214;&#20272;&#35745;-&#20248;&#21270;&#65288;ICEO&#65289;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#32771;&#34385;&#20248;&#21270;&#38382;&#39064;&#32467;&#26500;&#30340;&#21516;&#26102;&#20272;&#35745;&#38543;&#26426;&#21442;&#25968;&#30340;&#26465;&#20214;&#20998;&#24067;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20123;&#24615;&#33021;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2110.12351</link><description>&lt;p&gt;
&#32508;&#21512;&#26465;&#20214;&#20272;&#35745;-&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Integrated Conditional Estimation-Optimization. (arXiv:2110.12351v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.12351
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#32508;&#21512;&#26465;&#20214;&#20272;&#35745;-&#20248;&#21270;&#65288;ICEO&#65289;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#32771;&#34385;&#20248;&#21270;&#38382;&#39064;&#32467;&#26500;&#30340;&#21516;&#26102;&#20272;&#35745;&#38543;&#26426;&#21442;&#25968;&#30340;&#26465;&#20214;&#20998;&#24067;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20123;&#24615;&#33021;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#23454;&#38469;&#20248;&#21270;&#38382;&#39064;&#28041;&#21450;&#20855;&#26377;&#27010;&#29575;&#20998;&#24067;&#30340;&#19981;&#30830;&#23450;&#21442;&#25968;&#65292;&#21487;&#20197;&#20351;&#29992;&#19978;&#19979;&#25991;&#29305;&#24449;&#20449;&#24687;&#36827;&#34892;&#20272;&#35745;&#12290;&#19982;&#20808;&#20272;&#35745;&#19981;&#30830;&#23450;&#21442;&#25968;&#30340;&#20998;&#24067;&#28982;&#21518;&#22522;&#20110;&#20272;&#35745;&#20248;&#21270;&#30446;&#26631;&#30340;&#26631;&#20934;&#26041;&#27861;&#30456;&#21453;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#32508;&#21512;&#26465;&#20214;&#20272;&#35745;-&#20248;&#21270;&#65288;ICEO&#65289;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#22312;&#32771;&#34385;&#20248;&#21270;&#38382;&#39064;&#32467;&#26500;&#30340;&#21516;&#26102;&#20272;&#35745;&#38543;&#26426;&#21442;&#25968;&#30340;&#26465;&#20214;&#20998;&#24067;&#12290;&#25105;&#20204;&#30452;&#25509;&#24314;&#27169;&#38543;&#26426;&#21442;&#25968;&#30340;&#26465;&#20214;&#20998;&#24067;&#19982;&#19978;&#19979;&#25991;&#29305;&#24449;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#28982;&#21518;&#29992;&#19982;&#19979;&#28216;&#20248;&#21270;&#38382;&#39064;&#19968;&#33268;&#30340;&#30446;&#26631;&#20272;&#35745;&#27010;&#29575;&#27169;&#22411;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;ICEO&#26041;&#27861;&#22312;&#36866;&#24230;&#35268;&#21017;&#26465;&#20214;&#19979;&#26159;&#28176;&#36827;&#19968;&#33268;&#30340;&#65292;&#24182;&#36827;&#19968;&#27493;&#25552;&#20379;&#20102;&#19968;&#20123;&#25512;&#24191;&#30028;&#38480;&#24418;&#24335;&#30340;&#26377;&#38480;&#24615;&#33021;&#20445;&#35777;&#12290;&#35745;&#31639;&#19978;&#65292;&#20351;&#29992;
&lt;/p&gt;
&lt;p&gt;
Many real-world optimization problems involve uncertain parameters with probability distributions that can be estimated using contextual feature information. In contrast to the standard approach of first estimating the distribution of uncertain parameters and then optimizing the objective based on the estimation, we propose an integrated conditional estimation-optimization (ICEO) framework that estimates the underlying conditional distribution of the random parameter while considering the structure of the optimization problem. We directly model the relationship between the conditional distribution of the random parameter and the contextual features, and then estimate the probabilistic model with an objective that aligns with the downstream optimization problem. We show that our ICEO approach is asymptotically consistent under moderate regularity conditions and further provide finite performance guarantees in the form of generalization bounds. Computationally, performing estimation with
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#26080;&#23725;&#32447;&#24615;&#22238;&#24402;&#20013;&#23384;&#22312;&#19968;&#20010;&#21452;&#19979;&#38477;&#23792;&#65292;&#26080;&#35770;&#36755;&#20837;&#20998;&#24067;&#30340;&#29305;&#24449;&#26144;&#23556;&#26159;&#30830;&#23450;&#24615;&#30340;&#36824;&#26159;&#38543;&#26426;&#30340;&#65292;&#37117;&#20250;&#23548;&#33268;&#26399;&#26395;&#22343;&#26041;&#27867;&#21270;&#35823;&#24046;&#22686;&#21152;&#12290;&#24182;&#19988;&#25105;&#20204;&#30340;&#32467;&#26524;&#36866;&#29992;&#20110;&#24191;&#27867;&#30340;&#36755;&#20837;&#20998;&#24067;&#31867;&#12290;</title><link>http://arxiv.org/abs/2010.01851</link><description>&lt;p&gt;
&#26080;&#23725;&#22238;&#24402;&#20013;&#21452;&#19979;&#38477;&#23792;&#30340;&#26222;&#36941;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Universality of the Double Descent Peak in Ridgeless Regression. (arXiv:2010.01851v8 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2010.01851
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#26080;&#23725;&#32447;&#24615;&#22238;&#24402;&#20013;&#23384;&#22312;&#19968;&#20010;&#21452;&#19979;&#38477;&#23792;&#65292;&#26080;&#35770;&#36755;&#20837;&#20998;&#24067;&#30340;&#29305;&#24449;&#26144;&#23556;&#26159;&#30830;&#23450;&#24615;&#30340;&#36824;&#26159;&#38543;&#26426;&#30340;&#65292;&#37117;&#20250;&#23548;&#33268;&#26399;&#26395;&#22343;&#26041;&#27867;&#21270;&#35823;&#24046;&#22686;&#21152;&#12290;&#24182;&#19988;&#25105;&#20204;&#30340;&#32467;&#26524;&#36866;&#29992;&#20110;&#24191;&#27867;&#30340;&#36755;&#20837;&#20998;&#24067;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#26080;&#23725;&#32447;&#24615;&#22238;&#24402;&#20013;&#30001;&#26631;&#31614;&#22122;&#22768;&#24341;&#36215;&#30340;&#26399;&#26395;&#22343;&#26041;&#27867;&#21270;&#35823;&#24046;&#30340;&#38750;&#28176;&#36817;&#38750;&#20998;&#24067;&#30456;&#20851;&#19979;&#30028;&#12290;&#25105;&#20204;&#30340;&#19979;&#30028;&#23558;&#31867;&#20284;&#30340;&#24050;&#30693;&#32467;&#26524;&#25512;&#24191;&#21040;&#36229;&#21442;&#25968;&#21270;&#65288;&#25554;&#20540;&#65289;&#21306;&#22495;&#12290;&#19982;&#22823;&#22810;&#25968;&#21069;&#26399;&#24037;&#20316;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#36866;&#29992;&#20110;&#20855;&#26377;&#20960;&#20046;&#24517;&#28982;&#23436;&#20840;&#31209;&#29305;&#24449;&#30697;&#38453;&#30340;&#24191;&#27867;&#36755;&#20837;&#20998;&#24067;&#31867;&#65292;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#35206;&#30422;&#21508;&#31181;&#30830;&#23450;&#24615;&#25110;&#38543;&#26426;&#29305;&#24449;&#26144;&#23556;&#31867;&#22411;&#12290;&#25105;&#20204;&#30340;&#19979;&#30028;&#26159;&#28176;&#36817;&#23574;&#38160;&#30340;&#65292;&#24182;&#19988;&#24847;&#21619;&#30528;&#22312;&#23384;&#22312;&#26631;&#31614;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#65292;&#26080;&#23725;&#32447;&#24615;&#22238;&#24402;&#22312;&#20219;&#20309;&#36825;&#20123;&#29305;&#24449;&#26144;&#23556;&#30340;&#25554;&#20540;&#38408;&#20540;&#21608;&#22260;&#34920;&#29616;&#19981;&#20339;&#12290;&#25105;&#20204;&#35814;&#32454;&#20998;&#26512;&#20102;&#25152;&#26045;&#21152;&#30340;&#20551;&#35774;&#65292;&#24182;&#20026;&#35299;&#26512;&#65288;&#38543;&#26426;&#65289;&#29305;&#24449;&#26144;&#23556;&#25552;&#20379;&#20102;&#29702;&#35770;&#12290;&#21033;&#29992;&#36825;&#20010;&#29702;&#35770;&#65292;&#25105;&#20204;&#21487;&#20197;&#35777;&#26126;&#25105;&#20204;&#30340;&#20551;&#35774;&#23545;&#20855;&#26377;&#65288;&#21202;&#36125;&#26684;&#65289;&#23494;&#24230;&#30340;&#36755;&#20837;&#20998;&#24067;&#20197;&#21450;&#30001;&#20998;&#26512;&#28608;&#27963;&#20989;&#25968;&#32473;&#20986;&#30340;&#38543;&#26426;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#29305;&#24449;&#26144;&#23556;&#25104;&#31435;&#12290;
&lt;/p&gt;
&lt;p&gt;
We prove a non-asymptotic distribution-independent lower bound for the expected mean squared generalization error caused by label noise in ridgeless linear regression. Our lower bound generalizes a similar known result to the overparameterized (interpolating) regime. In contrast to most previous works, our analysis applies to a broad class of input distributions with almost surely full-rank feature matrices, which allows us to cover various types of deterministic or random feature maps. Our lower bound is asymptotically sharp and implies that in the presence of label noise, ridgeless linear regression does not perform well around the interpolation threshold for any of these feature maps. We analyze the imposed assumptions in detail and provide a theory for analytic (random) feature maps. Using this theory, we can show that our assumptions are satisfied for input distributions with a (Lebesgue) density and feature maps given by random deep neural networks with analytic activation functi
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#22826;&#38451;&#36752;&#29031;&#24230;&#39044;&#27979;&#30340;&#32479;&#19968;&#26550;&#26500;&#65292;&#33021;&#22815;&#22312;&#19981;&#21516;&#26102;&#38388;&#23610;&#24230;&#19978;&#36827;&#34892;&#39044;&#27979;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#26469;&#23558;&#36825;&#31181;&#26041;&#27861;&#25193;&#23637;&#21040;&#27599;&#23567;&#26102;&#39044;&#27979;&#33539;&#22260;&#12290;</title><link>http://arxiv.org/abs/1905.02616</link><description>&lt;p&gt;
&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#30340;&#38598;&#25104;&#22810;&#26102;&#38388;&#23610;&#24230;&#24314;&#27169;&#36827;&#34892;&#22826;&#38451;&#36752;&#29031;&#24230;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
An Integrated Multi-Time-Scale Modeling for Solar Irradiance Forecasting Using Deep Learning. (arXiv:1905.02616v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1905.02616
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#22826;&#38451;&#36752;&#29031;&#24230;&#39044;&#27979;&#30340;&#32479;&#19968;&#26550;&#26500;&#65292;&#33021;&#22815;&#22312;&#19981;&#21516;&#26102;&#38388;&#23610;&#24230;&#19978;&#36827;&#34892;&#39044;&#27979;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#26469;&#23558;&#36825;&#31181;&#26041;&#27861;&#25193;&#23637;&#21040;&#27599;&#23567;&#26102;&#39044;&#27979;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#30701;&#26399;&#22826;&#38451;&#36752;&#29031;&#24230;&#39044;&#27979;&#65292;&#20256;&#32479;&#30340;&#28857;&#39044;&#27979;&#26041;&#27861;&#30001;&#20110;&#22826;&#38451;&#33021;&#21151;&#29575;&#30340;&#38750;&#24179;&#31283;&#29305;&#24615;&#32780;&#21464;&#24471;&#19981;&#22826;&#26377;&#29992;&#12290;&#30001;&#20110;&#22826;&#38451;&#33021;&#30340;&#21464;&#21160;&#24615;&#65292;&#38656;&#35201;&#26356;&#22810;&#30340;&#36816;&#34892;&#22791;&#29992;&#26469;&#30830;&#20445;&#30005;&#32593;&#30340;&#21487;&#38752;&#36816;&#34892;&#12290;&#21457;&#30005;&#19981;&#30830;&#23450;&#24615;&#36234;&#22823;&#65292;&#36816;&#34892;&#22791;&#29992;&#38656;&#27714;&#36234;&#22823;&#65292;&#36825;&#23558;&#23548;&#33268;&#36816;&#34892;&#25104;&#26412;&#30340;&#22686;&#21152;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#65288;RNN&#65289;&#21644;&#38271;&#30701;&#26102;&#35760;&#24518;&#32593;&#32476;&#65288;LSTM&#65289;&#36827;&#34892;&#22810;&#26102;&#38388;&#23610;&#24230;&#39044;&#27979;&#30340;&#32479;&#19968;&#26550;&#26500;&#65292;&#29992;&#20110;&#39044;&#27979;&#27599;&#22825;&#20869;&#30340;&#22826;&#38451;&#36752;&#29031;&#24230;&#12290;&#26412;&#25991;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#23558;&#36825;&#31181;&#24314;&#27169;&#26041;&#27861;&#25193;&#23637;&#21040;&#27599;&#23567;&#26102;&#39044;&#27979;&#33539;&#22260;&#65292;&#20174;&#32780;&#23454;&#29616;&#22810;&#26102;&#38388;&#33539;&#22260;&#30340;&#39044;&#27979;&#65292;&#33021;&#22815;&#39044;&#27979;&#27599;&#23567;&#26102;&#21644;&#27599;&#22825;&#30340;&#22826;&#38451;&#36752;&#29031;&#24230;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#31471;&#21040;&#31471;&#30340;&#27969;&#31243;&#26469;&#23454;&#26045;&#25552;&#20986;&#30340;&#26550;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
For short-term solar irradiance forecasting, the traditional point forecasting methods are rendered less useful due to the non-stationary characteristic of solar power. The amount of operating reserves required to maintain reliable operation of the electric grid rises due to the variability of solar energy. The higher the uncertainty in the generation, the greater the operating-reserve requirements, which translates to an increased cost of operation. In this research work, we propose a unified architecture for multi-time-scale predictions for intra-day solar irradiance forecasting using recurrent neural networks (RNN) and long-short-term memory networks (LSTMs). This paper also lays out a framework for extending this modeling approach to intra-hour forecasting horizons thus, making it a multi-time-horizon forecasting approach, capable of predicting intra-hour as well as intra-day solar irradiance. We develop an end-to-end pipeline to effectuate the proposed architecture. The performanc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38750;&#22686;&#21152;&#22411;&#27169;&#22411;&#30340;&#20840;&#23616;&#22686;&#21152;&#24615;&#35299;&#37322;&#26041;&#27861;&#65292;&#21457;&#29616;&#19981;&#21516;&#30340;&#35299;&#37322;&#26041;&#27861;&#20197;&#19981;&#21516;&#30340;&#26041;&#24335;&#21051;&#30011;&#20102;&#40657;&#30418;&#27169;&#22411;&#39044;&#27979;&#20989;&#25968;&#20013;&#30340;&#38750;&#22686;&#21152;&#24615;&#25104;&#20998;&#12290;&#23613;&#31649;&#31934;&#31616;&#30340;&#35299;&#37322;&#19968;&#33324;&#26159;&#26368;&#20934;&#30830;&#30340;&#22686;&#21152;&#24615;&#35299;&#37322;&#65292;&#20294;&#26174;&#24335;&#24314;&#27169;&#38750;&#22686;&#21152;&#24615;&#25104;&#20998;&#30340;&#26641;&#24418;&#35299;&#37322;&#24448;&#24448;&#26356;&#20934;&#30830;&#12290;&#26426;&#22120;&#23398;&#20064;&#20174;&#19994;&#32773;&#33021;&#22815;&#26356;&#22909;&#22320;&#21033;&#29992;&#22686;&#21152;&#24615;&#35299;&#37322;&#26469;&#23436;&#25104;&#21508;&#31181;&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/1801.08640</link><description>&lt;p&gt;
&#22312;&#23398;&#20064;&#40657;&#30418;&#27169;&#22411;&#30340;&#22686;&#21152;&#24615;&#35299;&#37322;&#26102;&#38656;&#35201;&#32771;&#34385;&#30340;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Considerations When Learning Additive Explanations for Black-Box Models. (arXiv:1801.08640v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1801.08640
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38750;&#22686;&#21152;&#22411;&#27169;&#22411;&#30340;&#20840;&#23616;&#22686;&#21152;&#24615;&#35299;&#37322;&#26041;&#27861;&#65292;&#21457;&#29616;&#19981;&#21516;&#30340;&#35299;&#37322;&#26041;&#27861;&#20197;&#19981;&#21516;&#30340;&#26041;&#24335;&#21051;&#30011;&#20102;&#40657;&#30418;&#27169;&#22411;&#39044;&#27979;&#20989;&#25968;&#20013;&#30340;&#38750;&#22686;&#21152;&#24615;&#25104;&#20998;&#12290;&#23613;&#31649;&#31934;&#31616;&#30340;&#35299;&#37322;&#19968;&#33324;&#26159;&#26368;&#20934;&#30830;&#30340;&#22686;&#21152;&#24615;&#35299;&#37322;&#65292;&#20294;&#26174;&#24335;&#24314;&#27169;&#38750;&#22686;&#21152;&#24615;&#25104;&#20998;&#30340;&#26641;&#24418;&#35299;&#37322;&#24448;&#24448;&#26356;&#20934;&#30830;&#12290;&#26426;&#22120;&#23398;&#20064;&#20174;&#19994;&#32773;&#33021;&#22815;&#26356;&#22909;&#22320;&#21033;&#29992;&#22686;&#21152;&#24615;&#35299;&#37322;&#26469;&#23436;&#25104;&#21508;&#31181;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#35299;&#37322;&#40657;&#30418;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#26080;&#35770;&#26159;&#23616;&#37096;&#36824;&#26159;&#20840;&#23616;&#30340;&#65292;&#37117;&#26159;&#22686;&#21152;&#22411;&#30340;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#38750;&#22686;&#21152;&#22411;&#27169;&#22411;&#30340;&#20840;&#23616;&#22686;&#21152;&#24615;&#35299;&#37322;&#65292;&#37325;&#28857;&#20851;&#27880;&#22235;&#31181;&#35299;&#37322;&#26041;&#27861;&#65306;&#23616;&#37096;&#20381;&#36182;&#12289;&#36866;&#24212;&#20840;&#23616;&#29615;&#22659;&#30340;Shapley&#35299;&#37322;&#12289;&#31934;&#31616;&#30340;&#22686;&#21152;&#24615;&#35299;&#37322;&#21644;&#22522;&#20110;&#26799;&#24230;&#30340;&#35299;&#37322;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#19981;&#21516;&#30340;&#35299;&#37322;&#26041;&#27861;&#20197;&#19981;&#21516;&#30340;&#26041;&#24335;&#21051;&#30011;&#20102;&#40657;&#30418;&#27169;&#22411;&#39044;&#27979;&#20989;&#25968;&#20013;&#30340;&#38750;&#22686;&#21152;&#24615;&#25104;&#20998;&#12290;&#25105;&#20204;&#20351;&#29992;&#20027;&#25928;&#24212;&#21644;&#24635;&#25928;&#24212;&#30340;&#27010;&#24565;&#26469;&#38170;&#23450;&#22686;&#21152;&#24615;&#35299;&#37322;&#65292;&#24182;&#23450;&#37327;&#35780;&#20272;&#22686;&#21152;&#24615;&#21644;&#38750;&#22686;&#21152;&#24615;&#35299;&#37322;&#12290;&#23613;&#31649;&#31934;&#31616;&#30340;&#35299;&#37322;&#19968;&#33324;&#26159;&#26368;&#20934;&#30830;&#30340;&#22686;&#21152;&#24615;&#35299;&#37322;&#65292;&#20294;&#26174;&#24335;&#24314;&#27169;&#38750;&#22686;&#21152;&#24615;&#25104;&#20998;&#30340;&#26641;&#24418;&#35299;&#37322;&#24448;&#24448;&#26356;&#20934;&#30830;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#25105;&#20204;&#30340;&#29992;&#25143;&#30740;&#31350;&#34920;&#26126;&#65292;&#26426;&#22120;&#23398;&#20064;&#20174;&#19994;&#32773;&#33021;&#22815;&#26356;&#22909;&#22320;&#21033;&#29992;&#22686;&#21152;&#24615;&#35299;&#37322;&#26469;&#23436;&#25104;&#21508;&#31181;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many methods to explain black-box models, whether local or global, are additive. In this paper, we study global additive explanations for non-additive models, focusing on four explanation methods: partial dependence, Shapley explanations adapted to a global setting, distilled additive explanations, and gradient-based explanations. We show that different explanation methods characterize non-additive components in a black-box model's prediction function in different ways. We use the concepts of main and total effects to anchor additive explanations, and quantitatively evaluate additive and non-additive explanations. Even though distilled explanations are generally the most accurate additive explanations, non-additive explanations such as tree explanations that explicitly model non-additive components tend to be even more accurate. Despite this, our user study showed that machine learning practitioners were better able to leverage additive explanations for various tasks. These considerati
&lt;/p&gt;</description></item></channel></rss>