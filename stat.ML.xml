<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#35752;&#35770;&#20102;&#22312;&#21327;&#20316;&#31185;&#23398;&#20013;&#20351;&#29992;&#28608;&#21169;&#29702;&#35770;&#30340;&#36125;&#21494;&#26031;&#25512;&#29702;&#26041;&#27861;&#65292;&#36890;&#36807;&#32771;&#34385;&#30740;&#31350;&#32773;&#21644;&#20915;&#31574;&#32773;&#30340;&#19981;&#21516;&#28608;&#21169;&#26426;&#21046;&#65292;&#21033;&#29992;&#20195;&#29702;&#20154;&#30340;&#25112;&#30053;&#34892;&#20026;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#12290;</title><link>http://arxiv.org/abs/2307.03748</link><description>&lt;p&gt;
&#28608;&#21169;&#29702;&#35770;&#30340;&#36125;&#21494;&#26031;&#25512;&#29702;&#22312;&#21327;&#20316;&#31185;&#23398;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Incentive-Theoretic Bayesian Inference for Collaborative Science. (arXiv:2307.03748v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03748
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35752;&#35770;&#20102;&#22312;&#21327;&#20316;&#31185;&#23398;&#20013;&#20351;&#29992;&#28608;&#21169;&#29702;&#35770;&#30340;&#36125;&#21494;&#26031;&#25512;&#29702;&#26041;&#27861;&#65292;&#36890;&#36807;&#32771;&#34385;&#30740;&#31350;&#32773;&#21644;&#20915;&#31574;&#32773;&#30340;&#19981;&#21516;&#28608;&#21169;&#26426;&#21046;&#65292;&#21033;&#29992;&#20195;&#29702;&#20154;&#30340;&#25112;&#30053;&#34892;&#20026;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#20195;&#31185;&#23398;&#30740;&#31350;&#26159;&#19968;&#39033;&#20998;&#24067;&#24335;&#30340;&#12289;&#21327;&#20316;&#30340;&#24037;&#20316;&#65292;&#30001;&#30740;&#31350;&#22242;&#38431;&#12289;&#30417;&#31649;&#26426;&#26500;&#12289;&#36164;&#21161;&#26426;&#26500;&#12289;&#21830;&#19994;&#21512;&#20316;&#20249;&#20276;&#21644;&#31185;&#23398;&#26426;&#26500;&#32452;&#25104;&#65292;&#24444;&#27492;&#20114;&#21160;&#24182;&#38754;&#23545;&#19981;&#21516;&#30340;&#28608;&#21169;&#12290;&#20026;&#20102;&#20445;&#25345;&#31185;&#23398;&#20005;&#35880;&#24615;&#65292;&#32479;&#35745;&#26041;&#27861;&#24212;&#35813;&#35748;&#35782;&#21040;&#36825;&#31181;&#24773;&#20917;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20551;&#35774;&#26816;&#39564;&#30340;&#24773;&#20917;&#65292;&#20854;&#20013;&#26377;&#19968;&#20010;&#20195;&#29702;&#20154;&#65288;&#20363;&#22914;&#30740;&#31350;&#20154;&#21592;&#25110;&#21046;&#33647;&#20844;&#21496;&#65289;&#23545;&#26410;&#30693;&#21442;&#25968;&#25317;&#26377;&#31169;&#20154;&#20808;&#39564;&#30693;&#35782;&#65292;&#36824;&#26377;&#19968;&#20010;&#22996;&#25176;&#20154;&#65288;&#22914;&#25919;&#31574;&#21046;&#23450;&#32773;&#25110;&#30417;&#31649;&#26426;&#26500;&#65289;&#24076;&#26395;&#26681;&#25454;&#21442;&#25968;&#20540;&#20570;&#20986;&#20915;&#31574;&#12290;&#20195;&#29702;&#20154;&#26681;&#25454;&#20182;&#20204;&#30340;&#31169;&#20154;&#20808;&#39564;&#36873;&#25321;&#26159;&#21542;&#36827;&#34892;&#32479;&#35745;&#35797;&#39564;&#65292;&#28982;&#21518;&#35797;&#39564;&#30340;&#32467;&#26524;&#30001;&#22996;&#25176;&#20154;&#29992;&#26469;&#20570;&#20986;&#20915;&#31574;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22996;&#25176;&#20154;&#22914;&#20309;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#65292;&#21033;&#29992;&#20195;&#29702;&#20154;&#30340;&#25112;&#30053;&#34892;&#20026;&#25152;&#36879;&#38706;&#30340;&#20449;&#24687;&#65292;&#20063;&#23601;&#26159;&#20182;&#20204;&#36873;&#25321;&#26159;&#21542;&#36827;&#34892;&#35797;&#39564;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#35745;&#31639;p&#20540;&#65292;&#20174;&#32780;&#32508;&#21512;&#21033;&#29992;&#20195;&#29702;&#20154;&#30340;&#34892;&#20026;&#21644;&#35797;&#39564;&#30340;&#32467;&#26524;&#36827;&#34892;&#25512;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
Contemporary scientific research is a distributed, collaborative endeavor, carried out by teams of researchers, regulatory institutions, funding agencies, commercial partners, and scientific bodies, all interacting with each other and facing different incentives. To maintain scientific rigor, statistical methods should acknowledge this state of affairs. To this end, we study hypothesis testing when there is an agent (e.g., a researcher or a pharmaceutical company) with a private prior about an unknown parameter and a principal (e.g., a policymaker or regulator) who wishes to make decisions based on the parameter value. The agent chooses whether to run a statistical trial based on their private prior and then the result of the trial is used by the principal to reach a decision. We show how the principal can conduct statistical inference that leverages the information that is revealed by an agent's strategic behavior -- their choice to run a trial or not. In particular, we show how the p
&lt;/p&gt;</description></item><item><title>GeoPhy&#26159;&#19968;&#31181;&#21019;&#26032;&#30340;&#12289;&#23436;&#20840;&#21487;&#24494;&#30340;&#31995;&#32479;&#21457;&#32946;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#36830;&#32493;&#20960;&#20309;&#31354;&#38388;&#20013;&#34920;&#31034;&#25299;&#25169;&#20998;&#24067;&#65292;&#23454;&#29616;&#20102;&#21487;&#25193;&#23637;&#30340;&#21464;&#20998;&#25512;&#26029;&#65292;&#20811;&#26381;&#20102;&#19981;&#38480;&#21046;&#25299;&#25169;&#32467;&#26500;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2307.03675</link><description>&lt;p&gt;
GeoPhy: &#21033;&#29992;&#20960;&#20309;&#26799;&#24230;&#23454;&#29616;&#21487;&#24494;&#20998;&#30340;&#31995;&#32479;&#21457;&#32946;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
GeoPhy: Differentiable Phylogenetic Inference via Geometric Gradients of Tree Topologies. (arXiv:2307.03675v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03675
&lt;/p&gt;
&lt;p&gt;
GeoPhy&#26159;&#19968;&#31181;&#21019;&#26032;&#30340;&#12289;&#23436;&#20840;&#21487;&#24494;&#30340;&#31995;&#32479;&#21457;&#32946;&#25512;&#26029;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#36830;&#32493;&#20960;&#20309;&#31354;&#38388;&#20013;&#34920;&#31034;&#25299;&#25169;&#20998;&#24067;&#65292;&#23454;&#29616;&#20102;&#21487;&#25193;&#23637;&#30340;&#21464;&#20998;&#25512;&#26029;&#65292;&#20811;&#26381;&#20102;&#19981;&#38480;&#21046;&#25299;&#25169;&#32467;&#26500;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31995;&#32479;&#21457;&#32946;&#25512;&#26029;&#26159;&#22312;&#20998;&#23376;&#36827;&#21270;&#27169;&#22411;&#22522;&#30784;&#19978;&#36827;&#34892;&#30340;&#65292;&#23427;&#23545;&#20110;&#29702;&#35299;&#29983;&#29289;&#25968;&#25454;&#20013;&#30340;&#36827;&#21270;&#20851;&#31995;&#33267;&#20851;&#37325;&#35201;&#12290;&#32771;&#34385;&#21040;&#36827;&#21270;&#26641;&#21464;&#37327;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#21253;&#25324;&#26641;&#25299;&#25169;&#32467;&#26500;&#21644;&#20998;&#25903;&#19978;&#30340;&#36827;&#21270;&#36317;&#31163;&#65292;&#23545;&#20110;&#20934;&#30830;&#22320;&#20174;&#20998;&#23376;&#25968;&#25454;&#20013;&#25512;&#26029;&#29289;&#31181;&#20851;&#31995;&#20197;&#21450;&#38656;&#35201;&#36827;&#34892;&#21464;&#37327;&#36793;&#32536;&#21270;&#30340;&#20219;&#21153;&#26469;&#35828;&#33267;&#20851;&#37325;&#35201;&#12290;&#21464;&#20998;&#36125;&#21494;&#26031;&#26041;&#27861;&#26159;&#24320;&#21457;&#21487;&#25193;&#23637;&#12289;&#23454;&#29992;&#27169;&#22411;&#30340;&#20851;&#38190;&#65292;&#28982;&#32780;&#65292;&#22312;&#19981;&#38480;&#21046;&#21487;&#33021;&#30340;&#26641;&#25299;&#25169;&#32467;&#26500;&#30340;&#32452;&#21512;&#25968;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#31995;&#32479;&#21457;&#32946;&#25512;&#26029;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#12289;&#23436;&#20840;&#21487;&#24494;&#30340;&#31995;&#32479;&#21457;&#32946;&#25512;&#26029;&#20844;&#24335;&#65292;&#21033;&#29992;&#36830;&#32493;&#20960;&#20309;&#31354;&#38388;&#20013;&#30340;&#25299;&#25169;&#20998;&#24067;&#26469;&#34920;&#31034;&#12290;&#36890;&#36807;&#23545;&#35774;&#35745;&#31354;&#38388;&#21644;&#28176;&#36817;&#30697;&#30340;&#23454;&#38469;&#32771;&#34385;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;GeoPhy&#21487;&#20197;&#23454;&#29616;&#21464;&#20998;&#25512;&#26029;&#32780;&#19981;&#38480;&#21046;&#25299;&#25169;&#32467;&#26500;&#30340;&#22810;&#26679;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Phylogenetic inference, grounded in molecular evolution models, is essential for understanding the evolutionary relationships in biological data. Accounting for the uncertainty of phylogenetic tree variables, which include tree topologies and evolutionary distances on branches, is crucial for accurately inferring species relationships from molecular data and tasks requiring variable marginalization. Variational Bayesian methods are key to developing scalable, practical models; however, it remains challenging to conduct phylogenetic inference without restricting the combinatorially vast number of possible tree topologies. In this work, we introduce a novel, fully differentiable formulation of phylogenetic inference that leverages a unique representation of topological distributions in continuous geometric spaces. Through practical considerations on design spaces and control variates for gradient estimations, our approach, GeoPhy, enables variational inference without limiting the topolo
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;Grab-UCB&#31639;&#27861;&#29992;&#20110;&#22312;&#32447;&#23398;&#20064;&#22823;&#35268;&#27169;&#32593;&#32476;&#20013;&#26368;&#20248;&#30340;&#28304;&#25918;&#32622;&#20301;&#32622;&#65292;&#36890;&#36807;&#20351;&#29992;&#33258;&#36866;&#24212;&#30340;&#22270;&#35789;&#20856;&#27169;&#22411;&#26469;&#25551;&#36848;&#32593;&#32476;&#36807;&#31243;&#65292;&#24182;&#21033;&#29992;&#31232;&#30095;&#35889;&#34920;&#31034;&#23454;&#29616;&#20102;&#25968;&#25454;&#39640;&#25928;&#30340;&#23398;&#20064;&#26694;&#26550;&#12290;</title><link>http://arxiv.org/abs/2307.03641</link><description>&lt;p&gt;
&#22312;&#32447;&#32593;&#32476;&#28304;&#20248;&#21270;&#19982;&#22270;&#20869;&#26680;MAB
&lt;/p&gt;
&lt;p&gt;
Online Network Source Optimization with Graph-Kernel MAB. (arXiv:2307.03641v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03641
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;Grab-UCB&#31639;&#27861;&#29992;&#20110;&#22312;&#32447;&#23398;&#20064;&#22823;&#35268;&#27169;&#32593;&#32476;&#20013;&#26368;&#20248;&#30340;&#28304;&#25918;&#32622;&#20301;&#32622;&#65292;&#36890;&#36807;&#20351;&#29992;&#33258;&#36866;&#24212;&#30340;&#22270;&#35789;&#20856;&#27169;&#22411;&#26469;&#25551;&#36848;&#32593;&#32476;&#36807;&#31243;&#65292;&#24182;&#21033;&#29992;&#31232;&#30095;&#35889;&#34920;&#31034;&#23454;&#29616;&#20102;&#25968;&#25454;&#39640;&#25928;&#30340;&#23398;&#20064;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;Grab-UCB&#65292;&#19968;&#31181;&#22522;&#20110;&#22270;&#20869;&#26680;&#30340;&#22810;&#33218;&#36172;&#21338;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#32447;&#23398;&#20064;&#22312;&#22823;&#35268;&#27169;&#32593;&#32476;&#20013;&#26368;&#20248;&#30340;&#28304;&#25918;&#32622;&#20301;&#32622;&#65292;&#20197;&#26368;&#22823;&#21270;&#20808;&#39564;&#26410;&#30693;&#32593;&#32476;&#36807;&#31243;&#25152;&#33719;&#24471;&#30340;&#22870;&#21169;&#12290;&#30001;&#20110;&#19981;&#30830;&#23450;&#24615;&#65292;&#38656;&#35201;&#22312;&#32447;&#23398;&#20064;&#65292;&#28982;&#32780;&#36825;&#22312;&#32500;&#24230;&#28798;&#38590;&#20013;&#21463;&#21040;&#20102;&#24433;&#21709;&#12290;&#20026;&#20102;&#23454;&#29616;&#26679;&#26412;&#25928;&#29575;&#65292;&#25105;&#20204;&#20351;&#29992;&#33258;&#36866;&#24212;&#30340;&#22270;&#35789;&#20856;&#27169;&#22411;&#26469;&#25551;&#36848;&#32593;&#32476;&#36807;&#31243;&#65292;&#36825;&#36890;&#24120;&#23548;&#33268;&#31232;&#30095;&#30340;&#35889;&#34920;&#31034;&#12290;&#36825;&#20351;&#24471;&#25968;&#25454;&#39640;&#25928;&#30340;&#23398;&#20064;&#26694;&#26550;&#25104;&#20026;&#21487;&#33021;&#65292;&#20854;&#23398;&#20064;&#29575;&#19982;&#35889;&#34920;&#31034;&#27169;&#22411;&#30340;&#32500;&#24230;&#30456;&#20851;&#65292;&#32780;&#19981;&#26159;&#32593;&#32476;&#30340;&#32500;&#24230;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Grab-UCB&#65292;&#19968;&#31181;&#22312;&#32447;&#39034;&#24207;&#20915;&#31574;&#31574;&#30053;&#65292;&#23427;&#22312;&#20248;&#21270;&#34892;&#21160;&#31574;&#30053;&#30340;&#21516;&#26102;&#23398;&#20064;&#35889;&#34920;&#31034;&#30340;&#21442;&#25968;&#12290;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#19982;&#32593;&#32476;&#21442;&#25968;&#30456;&#20851;&#30340;&#24615;&#33021;&#20445;&#35777;&#65292;&#36825;&#36827;&#19968;&#27493;&#24433;&#21709;&#39034;&#24207;&#20915;&#31574;&#31574;&#30053;&#30340;&#23398;&#20064;&#26354;&#32447;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose Grab-UCB, a graph-kernel multi-arms bandit algorithm to learn online the optimal source placement in large scale networks, such that the reward obtained from a priori unknown network processes is maximized. The uncertainty calls for online learning, which suffers however from the curse of dimensionality. To achieve sample efficiency, we describe the network processes with an adaptive graph dictionary model, which typically leads to sparse spectral representations. This enables a data-efficient learning framework, whose learning rate scales with the dimension of the spectral representation model instead of the one of the network. We then propose Grab-UCB, an online sequential decision strategy that learns the parameters of the spectral representation while optimizing the action strategy. We derive the performance guarantees that depend on network parameters, which further influence the learning curve of the sequential decision strategy We introduce a computationally simplifie
&lt;/p&gt;</description></item><item><title>BOF-UCB&#26159;&#19968;&#31181;&#29992;&#20110;&#38750;&#24179;&#31283;&#29615;&#22659;&#19979;&#30340;&#32972;&#26223;&#32447;&#24615;&#36172;&#21338;&#26426;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#39057;&#29575;&#31639;&#27861;&#65292;&#20854;&#32467;&#21512;&#20102;&#36125;&#21494;&#26031;&#21644;&#39057;&#29575;&#23398;&#27966;&#21407;&#21017;&#65292;&#25552;&#39640;&#20102;&#22312;&#21160;&#24577;&#29615;&#22659;&#20013;&#30340;&#24615;&#33021;&#12290;&#23427;&#21033;&#29992;&#36125;&#21494;&#26031;&#26356;&#26032;&#25512;&#26029;&#21518;&#39564;&#20998;&#24067;&#65292;&#24182;&#20351;&#29992;&#39057;&#29575;&#23398;&#27966;&#26041;&#27861;&#35745;&#31639;&#19978;&#30028;&#20449;&#24515;&#30028;&#20197;&#24179;&#34913;&#25506;&#32034;&#21644;&#24320;&#21457;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;BOF-UCB&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#26159;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#39034;&#24207;&#20915;&#31574;&#30340;&#26377;&#21069;&#36884;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2307.03587</link><description>&lt;p&gt;
BOF-UCB: &#19968;&#31181;&#29992;&#20110;&#38750;&#24179;&#31283;&#29615;&#22659;&#19979;&#30340;&#19978;&#19979;&#30028;&#20449;&#24515;&#31639;&#27861;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#39057;&#29575;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
BOF-UCB: A Bayesian-Optimistic Frequentist Algorithm for Non-Stationary Contextual Bandits. (arXiv:2307.03587v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03587
&lt;/p&gt;
&lt;p&gt;
BOF-UCB&#26159;&#19968;&#31181;&#29992;&#20110;&#38750;&#24179;&#31283;&#29615;&#22659;&#19979;&#30340;&#32972;&#26223;&#32447;&#24615;&#36172;&#21338;&#26426;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#39057;&#29575;&#31639;&#27861;&#65292;&#20854;&#32467;&#21512;&#20102;&#36125;&#21494;&#26031;&#21644;&#39057;&#29575;&#23398;&#27966;&#21407;&#21017;&#65292;&#25552;&#39640;&#20102;&#22312;&#21160;&#24577;&#29615;&#22659;&#20013;&#30340;&#24615;&#33021;&#12290;&#23427;&#21033;&#29992;&#36125;&#21494;&#26031;&#26356;&#26032;&#25512;&#26029;&#21518;&#39564;&#20998;&#24067;&#65292;&#24182;&#20351;&#29992;&#39057;&#29575;&#23398;&#27966;&#26041;&#27861;&#35745;&#31639;&#19978;&#30028;&#20449;&#24515;&#30028;&#20197;&#24179;&#34913;&#25506;&#32034;&#21644;&#24320;&#21457;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;BOF-UCB&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65292;&#26159;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#39034;&#24207;&#20915;&#31574;&#30340;&#26377;&#21069;&#36884;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#39057;&#29575;&#19978;&#19979;&#30028;&#20449;&#24515;&#31639;&#27861;&#65288;BOF-UCB&#65289;&#65292;&#29992;&#20110;&#38750;&#24179;&#31283;&#29615;&#22659;&#19979;&#30340;&#38543;&#26426;&#32972;&#26223;&#32447;&#24615;&#36172;&#21338;&#26426;&#12290;&#36125;&#21494;&#26031;&#21644;&#39057;&#29575;&#23398;&#27966;&#21407;&#21017;&#30340;&#29420;&#29305;&#32467;&#21512;&#22686;&#24378;&#20102;&#31639;&#27861;&#22312;&#21160;&#24577;&#29615;&#22659;&#20013;&#30340;&#36866;&#24212;&#24615;&#21644;&#24615;&#33021;&#12290;BOF-UCB&#31639;&#27861;&#21033;&#29992;&#39034;&#24207;&#36125;&#21494;&#26031;&#26356;&#26032;&#25512;&#26029;&#26410;&#30693;&#22238;&#24402;&#21442;&#25968;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#24182;&#38543;&#21518;&#37319;&#29992;&#39057;&#29575;&#23398;&#27966;&#26041;&#27861;&#36890;&#36807;&#26368;&#22823;&#21270;&#21518;&#39564;&#20998;&#24067;&#19978;&#30340;&#26399;&#26395;&#25910;&#30410;&#26469;&#35745;&#31639;&#19978;&#30028;&#20449;&#24515;&#30028;&#65288;UCB&#65289;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;BOF-UCB&#24615;&#33021;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#24378;&#21270;&#23398;&#20064;&#29615;&#22659;&#20013;&#30340;&#32463;&#20856;&#25511;&#21046;&#20219;&#21153;&#20013;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;BOF-UCB&#20248;&#20110;&#29616;&#26377;&#30340;&#26041;&#27861;&#65292;&#22312;&#38750;&#24179;&#31283;&#29615;&#22659;&#20013;&#36827;&#34892;&#39034;&#24207;&#20915;&#31574;&#26159;&#19968;&#20010;&#26377;&#21069;&#36884;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel Bayesian-Optimistic Frequentist Upper Confidence Bound (BOF-UCB) algorithm for stochastic contextual linear bandits in non-stationary environments. This unique combination of Bayesian and frequentist principles enhances adaptability and performance in dynamic settings. The BOF-UCB algorithm utilizes sequential Bayesian updates to infer the posterior distribution of the unknown regression parameter, and subsequently employs a frequentist approach to compute the Upper Confidence Bound (UCB) by maximizing the expected reward over the posterior distribution. We provide theoretical guarantees of BOF-UCB's performance and demonstrate its effectiveness in balancing exploration and exploitation on synthetic datasets and classical control tasks in a reinforcement learning setting. Our results show that BOF-UCB outperforms existing methods, making it a promising solution for sequential decision-making in non-stationary environments.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#29992;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#31232;&#30095;&#27491;&#21017;&#21270;&#20013;&#36827;&#34892;&#24179;&#28369;&#20248;&#21270;&#65292;&#19982;&#20027;&#27969;&#30340;&#19968;&#38454;&#20248;&#21270;&#26041;&#27861;&#20860;&#23481;&#65292;&#24182;&#19988;&#33021;&#22815;&#24471;&#21040;&#21305;&#37197;&#30340;&#20840;&#23616;&#26368;&#23567;&#20540;&#21644;&#31561;&#20215;&#30340;&#23616;&#37096;&#26368;&#23567;&#20540;&#12290;</title><link>http://arxiv.org/abs/2307.03571</link><description>&lt;p&gt;
&#24179;&#28369;&#36793;&#32536;&#65306;&#21033;&#29992;Hadamard&#36229;&#21442;&#25968;&#21270;&#22312;&#31232;&#30095;&#27491;&#21017;&#21270;&#30340;&#24179;&#28369;&#20248;&#21270;&#20013;&#30340;&#19968;&#33324;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
Smoothing the Edges: A General Framework for Smooth Optimization in Sparse Regularization using Hadamard Overparametrization. (arXiv:2307.03571v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03571
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#29992;&#26694;&#26550;&#65292;&#21487;&#20197;&#22312;&#31232;&#30095;&#27491;&#21017;&#21270;&#20013;&#36827;&#34892;&#24179;&#28369;&#20248;&#21270;&#65292;&#19982;&#20027;&#27969;&#30340;&#19968;&#38454;&#20248;&#21270;&#26041;&#27861;&#20860;&#23481;&#65292;&#24182;&#19988;&#33021;&#22815;&#24471;&#21040;&#21305;&#37197;&#30340;&#20840;&#23616;&#26368;&#23567;&#20540;&#21644;&#31561;&#20215;&#30340;&#23616;&#37096;&#26368;&#23567;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#65288;&#32467;&#26500;&#21270;&#65289;&#31232;&#30095;&#27491;&#21017;&#21270;&#38382;&#39064;&#20013;&#30340;$\ell_q$&#21644;$\ell_{p,q}$&#27491;&#21017;&#21270;&#30340;&#24179;&#28369;&#26041;&#27861;&#12290;&#36825;&#20123;&#38750;&#24179;&#28369;&#19988;&#21487;&#33021;&#38750;&#20984;&#30340;&#38382;&#39064;&#30340;&#20248;&#21270;&#36890;&#24120;&#20381;&#36182;&#20110;&#19987;&#38376;&#30340;&#36807;&#31243;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#25105;&#20204;&#30340;&#19968;&#33324;&#26694;&#26550;&#19982;&#20027;&#27969;&#30340;&#19968;&#38454;&#20248;&#21270;&#26041;&#27861;&#65288;&#22914;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#21644;&#21152;&#36895;&#21464;&#20307;&#65289;&#20860;&#23481;&#65292;&#26080;&#38656;&#20219;&#20309;&#20462;&#25913;&#12290;&#36825;&#26159;&#36890;&#36807;&#24179;&#28369;&#20248;&#21270;&#36716;&#31227;&#23454;&#29616;&#30340;&#65292;&#20854;&#20013;&#36873;&#23450;&#27169;&#22411;&#21442;&#25968;&#30340;&#36229;&#21442;&#25968;&#21270;&#20351;&#29992;Hadamard&#20056;&#31215;&#21644;&#24809;&#32602;&#30340;&#25913;&#21464;&#12290;&#22312;&#36229;&#21442;&#25968;&#38382;&#39064;&#20013;&#65292;&#36890;&#36807;&#29992;&#26367;&#20195;&#21442;&#25968;&#36827;&#34892;&#24179;&#28369;&#21644;&#20984;&#24615;&#30340;$\ell_2$&#27491;&#21017;&#21270;&#65292;&#33021;&#22815;&#22312;&#21407;&#22987;&#21442;&#25968;&#21270;&#20013;&#24341;&#20837;&#38750;&#24179;&#28369;&#21644;&#38750;&#20984;&#24615;&#30340;$\ell_q$&#25110;$\ell_{p,q}$&#27491;&#21017;&#21270;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#19981;&#20165;&#33021;&#22815;&#24471;&#21040;&#21305;&#37197;&#30340;&#20840;&#23616;&#26368;&#23567;&#20540;&#65292;&#36824;&#33021;&#24471;&#21040;&#31561;&#20215;&#30340;&#23616;&#37096;&#26368;&#23567;&#20540;&#12290;&#36825;&#22312;&#38750;&#20984;&#31232;&#30095;&#27491;&#21017;&#21270;&#20013;&#23588;&#20854;&#26377;&#29992;&#65292;&#22240;&#20026;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#25214;&#21040;&#20840;&#23616;&#26368;&#23567;&#20540;&#38750;&#24120;&#22256;&#38590;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces a smooth method for (structured) sparsity in $\ell_q$ and $\ell_{p,q}$ regularized optimization problems. Optimization of these non-smooth and possibly non-convex problems typically relies on specialized procedures. In contrast, our general framework is compatible with prevalent first-order optimization methods like Stochastic Gradient Descent and accelerated variants without any required modifications. This is accomplished through a smooth optimization transfer, comprising an overparametrization of selected model parameters using Hadamard products and a change of penalties. In the overparametrized problem, smooth and convex $\ell_2$ regularization of the surrogate parameters induces non-smooth and non-convex $\ell_q$ or $\ell_{p,q}$ regularization in the original parametrization. We show that our approach yields not only matching global minima but also equivalent local minima. This is particularly useful in non-convex sparse regularization, where finding global m
&lt;/p&gt;</description></item><item><title>MALIBO&#26159;&#19968;&#31181;&#20803;&#23398;&#20064;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#30452;&#25509;&#23398;&#20064;&#36328;&#20219;&#21153;&#30340;&#26597;&#35810;&#25928;&#29992;&#65292;&#24182;&#24341;&#20837;&#36741;&#21161;&#27169;&#22411;&#20197;&#23454;&#29616;&#23545;&#26032;&#20219;&#21153;&#30340;&#31283;&#20581;&#36866;&#24212;&#65292;&#20811;&#26381;&#20102;&#29616;&#26377;&#26041;&#27861;&#30340;&#21487;&#20280;&#32553;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#30340;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2307.03565</link><description>&lt;p&gt;
MALIBO: &#20803;&#23398;&#20064;&#24212;&#29992;&#20110;&#26080;&#20284;&#28982;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
MALIBO: Meta-learning for Likelihood-free Bayesian Optimization. (arXiv:2307.03565v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03565
&lt;/p&gt;
&lt;p&gt;
MALIBO&#26159;&#19968;&#31181;&#20803;&#23398;&#20064;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#30452;&#25509;&#23398;&#20064;&#36328;&#20219;&#21153;&#30340;&#26597;&#35810;&#25928;&#29992;&#65292;&#24182;&#24341;&#20837;&#36741;&#21161;&#27169;&#22411;&#20197;&#23454;&#29616;&#23545;&#26032;&#20219;&#21153;&#30340;&#31283;&#20581;&#36866;&#24212;&#65292;&#20811;&#26381;&#20102;&#29616;&#26377;&#26041;&#27861;&#30340;&#21487;&#20280;&#32553;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#26159;&#19968;&#31181;&#20248;&#21270;&#26114;&#36149;&#40657;&#30418;&#20989;&#25968;&#30340;&#27969;&#34892;&#26041;&#27861;&#12290;&#20256;&#32479;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#20250;&#20174;&#22836;&#24320;&#22987;&#20248;&#21270;&#27599;&#20010;&#26032;&#30340;&#30446;&#26631;&#20219;&#21153;&#65292;&#32780;&#20803;&#23398;&#20064;&#21017;&#26159;&#21033;&#29992;&#30456;&#20851;&#20219;&#21153;&#30340;&#30693;&#35782;&#26469;&#26356;&#24555;&#22320;&#20248;&#21270;&#26032;&#20219;&#21153;&#30340;&#19968;&#31181;&#26041;&#24335;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#20803;&#23398;&#20064;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#20381;&#36182;&#20110;&#26631;&#20934;&#27169;&#22411;&#65292;&#36825;&#20123;&#27169;&#22411;&#23384;&#22312;&#21487;&#20280;&#32553;&#24615;&#38382;&#39064;&#65292;&#24182;&#19988;&#23545;&#19981;&#21516;&#20219;&#21153;&#20043;&#38388;&#35266;&#23519;&#25968;&#25454;&#30340;&#23610;&#24230;&#21644;&#22122;&#22768;&#31867;&#22411;&#38750;&#24120;&#25935;&#24863;&#12290;&#27492;&#22806;&#65292;&#23427;&#20204;&#24120;&#24120;&#24573;&#35270;&#19982;&#20219;&#21153;&#30456;&#20284;&#24615;&#30456;&#20851;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#36825;&#23548;&#33268;&#22312;&#20165;&#26377;&#26377;&#38480;&#35266;&#23519;&#25968;&#25454;&#25110;&#26032;&#20219;&#21153;&#19982;&#30456;&#20851;&#20219;&#21153;&#24046;&#24322;&#26174;&#33879;&#26102;&#65292;&#20219;&#21153;&#36866;&#24212;&#24615;&#19981;&#21487;&#38752;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20803;&#23398;&#20064;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#26088;&#22312;&#32469;&#24320;&#26631;&#20934;&#27169;&#22411;&#65292;&#30452;&#25509;&#23398;&#20064;&#36328;&#20219;&#21153;&#30340;&#26597;&#35810;&#25928;&#29992;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26126;&#30830;&#24314;&#27169;&#20219;&#21153;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#36741;&#21161;&#27169;&#22411;&#65292;&#20351;&#20854;&#33021;&#22815;&#23545;&#26032;&#20219;&#21153;&#36827;&#34892;&#31283;&#20581;&#36866;&#24212;&#12290;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian optimization (BO) is a popular method to optimize costly black-box functions. While traditional BO optimizes each new target task from scratch, meta-learning has emerged as a way to leverage knowledge from related tasks to optimize new tasks faster. However, existing meta-learning BO methods rely on surrogate models that suffer from scalability issues and are sensitive to observations with different scales and noise types across tasks. Moreover, they often overlook the uncertainty associated with task similarity. This leads to unreliable task adaptation when only limited observations are obtained or when the new tasks differ significantly from the related tasks. To address these limitations, we propose a novel meta-learning BO approach that bypasses the surrogate model and directly learns the utility of queries across tasks. Our method explicitly models task uncertainty and includes an auxiliary model to enable robust adaptation to new tasks. Extensive experiments show that ou
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#29992;&#20110;&#20998;&#24067;&#22238;&#24402;&#38382;&#39064;&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;&#31070;&#32463;&#32593;&#32476;&#26080;&#27861;&#30452;&#25509;&#22788;&#29702;&#27010;&#29575;&#20998;&#24067;&#36755;&#20837;&#30340;&#22256;&#38590;&#65292;&#24182;&#24314;&#31435;&#20102;&#36924;&#36817;&#29702;&#35770;&#21644;&#23398;&#20064;&#29702;&#35770;&#12290;</title><link>http://arxiv.org/abs/2307.03487</link><description>&lt;p&gt;
&#20998;&#24067;&#22238;&#24402;&#30340;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Learning Theory of Distribution Regression with Neural Networks. (arXiv:2307.03487v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03487
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#29992;&#20110;&#20998;&#24067;&#22238;&#24402;&#38382;&#39064;&#65292;&#35299;&#20915;&#20102;&#20256;&#32479;&#31070;&#32463;&#32593;&#32476;&#26080;&#27861;&#30452;&#25509;&#22788;&#29702;&#27010;&#29575;&#20998;&#24067;&#36755;&#20837;&#30340;&#22256;&#38590;&#65292;&#24182;&#24314;&#31435;&#20102;&#36924;&#36817;&#29702;&#35770;&#21644;&#23398;&#20064;&#29702;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#65288;FNN&#65289;&#24314;&#31435;&#20998;&#24067;&#22238;&#24402;&#30340;&#36924;&#36817;&#29702;&#35770;&#21644;&#23398;&#20064;&#29702;&#35770;&#12290;&#19982;&#20256;&#32479;&#22238;&#24402;&#26041;&#27861;&#19981;&#21516;&#30340;&#26159;&#65292;&#20998;&#24067;&#22238;&#24402;&#30340;&#36755;&#20837;&#21464;&#37327;&#26159;&#27010;&#29575;&#27979;&#24230;&#12290;&#28982;&#21518;&#25105;&#20204;&#24120;&#24120;&#38656;&#35201;&#36827;&#34892;&#20108;&#38454;&#27573;&#25277;&#26679;&#36807;&#31243;&#26469;&#36817;&#20284;&#20998;&#24067;&#30340;&#23454;&#38469;&#20449;&#24687;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#20256;&#32479;&#30340;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#35201;&#27714;&#36755;&#20837;&#21464;&#37327;&#20026;&#21521;&#37327;&#12290;&#24403;&#36755;&#20837;&#26679;&#26412;&#26159;&#27010;&#29575;&#20998;&#24067;&#26102;&#65292;&#20256;&#32479;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#26080;&#27861;&#30452;&#25509;&#20351;&#29992;&#65292;&#20998;&#24067;&#22238;&#24402;&#38382;&#39064;&#21464;&#24471;&#22256;&#38590;&#12290;&#22240;&#27492;&#65292;&#19968;&#20010;&#23545;&#20110;&#20998;&#24067;&#36755;&#20837;&#36827;&#34892;&#26126;&#30830;&#23450;&#20041;&#30340;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#26159;&#38750;&#24120;&#38656;&#27714;&#30340;&#12290;&#20851;&#20110;&#20998;&#24067;&#22238;&#24402;&#30340;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#27809;&#26377;&#25968;&#23398;&#27169;&#22411;&#21644;&#29702;&#35770;&#20998;&#26512;&#12290;&#20026;&#20102;&#20811;&#26381;&#25216;&#26415;&#38590;&#39064;&#24182;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we aim at establishing an approximation theory and a learning theory of distribution regression via a fully connected neural network (FNN). In contrast to the classical regression methods, the input variables of distribution regression are probability measures. Then we often need to perform a second-stage sampling process to approximate the actual information of the distribution. On the other hand, the classical neural network structure requires the input variable to be a vector. When the input samples are probability distributions, the traditional deep neural network method cannot be directly used and the difficulty arises for distribution regression. A well-defined neural network structure for distribution inputs is intensively desirable. There is no mathematical model and theoretical analysis on neural network realization of distribution regression. To overcome technical difficulties and address this issue, we establish a novel fully connected neural network framework
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21160;&#24577;&#23454;&#29616;&#30340;Hamiltonian Monte Carlo (HMC)&#31639;&#27861;&#21644;No U-Turn Sampler (NUTS) &#30340;&#25910;&#25947;&#24615;&#65292;&#35777;&#26126;&#20102;NUTS&#20316;&#20026;&#21160;&#24577;HMC&#30340;&#29305;&#20363;&#65292;&#24182;&#19988;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#20855;&#26377;&#36941;&#21382;&#24615;&#21644;&#20960;&#20309;&#36941;&#21382;&#24615;&#12290;&#21516;&#26102;&#25913;&#36827;&#20102;HMC&#30340;&#25910;&#25947;&#24615;&#32467;&#26524;&#65292;&#35777;&#26126;&#20102;&#22312;&#30446;&#26631;&#20998;&#24067;&#20026;&#39640;&#26031;&#20998;&#24067;&#30340;&#24494;&#25200;&#24773;&#20917;&#19979;&#65292;&#26080;&#38656;&#20219;&#20309;&#26377;&#30028;&#26465;&#20214;&#65292;HMC&#20063;&#26159;&#36941;&#21382;&#30340;&#12290;</title><link>http://arxiv.org/abs/2307.03460</link><description>&lt;p&gt;
&#21160;&#24577;&#23454;&#29616;&#30340;Hamiltonian Monte Carlo&#21644;No U-Turn Samplers&#30340;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the convergence of dynamic implementations of Hamiltonian Monte Carlo and No U-Turn Samplers. (arXiv:2307.03460v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03460
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21160;&#24577;&#23454;&#29616;&#30340;Hamiltonian Monte Carlo (HMC)&#31639;&#27861;&#21644;No U-Turn Sampler (NUTS) &#30340;&#25910;&#25947;&#24615;&#65292;&#35777;&#26126;&#20102;NUTS&#20316;&#20026;&#21160;&#24577;HMC&#30340;&#29305;&#20363;&#65292;&#24182;&#19988;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#20855;&#26377;&#36941;&#21382;&#24615;&#21644;&#20960;&#20309;&#36941;&#21382;&#24615;&#12290;&#21516;&#26102;&#25913;&#36827;&#20102;HMC&#30340;&#25910;&#25947;&#24615;&#32467;&#26524;&#65292;&#35777;&#26126;&#20102;&#22312;&#30446;&#26631;&#20998;&#24067;&#20026;&#39640;&#26031;&#20998;&#24067;&#30340;&#24494;&#25200;&#24773;&#20917;&#19979;&#65292;&#26080;&#38656;&#20219;&#20309;&#26377;&#30028;&#26465;&#20214;&#65292;HMC&#20063;&#26159;&#36941;&#21382;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#21160;&#24577;&#23454;&#29616;&#30340;Hamiltonian Monte Carlo (HMC)&#31639;&#27861;&#65292;&#20363;&#22914;No U-Turn Sampler (NUTS)&#65292;&#22312;&#35768;&#22810;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#25512;&#29702;&#38382;&#39064;&#20013;&#20855;&#26377;&#25104;&#21151;&#30340;&#32463;&#39564;&#35777;&#25454;&#65292;&#20294;&#20851;&#20110;&#23427;&#20204;&#34892;&#20026;&#30340;&#29702;&#35770;&#32467;&#26524;&#36824;&#19981;&#36275;&#12290;&#26412;&#25991;&#26088;&#22312;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#31216;&#20026;&#21160;&#24577;HMC&#30340;&#36890;&#29992;MCMC&#31639;&#27861;&#31867;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20010;&#36890;&#29992;&#26694;&#26550;&#28085;&#30422;&#20102;NUTS&#20316;&#20026;&#19968;&#20010;&#29305;&#20363;&#65292;&#24182;&#19988;&#20316;&#20026;&#19968;&#20010;&#38468;&#24102;&#32467;&#26524;&#65292;&#35777;&#26126;&#20102;&#30446;&#26631;&#20998;&#24067;&#30340;&#19981;&#21464;&#24615;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#20351;NUTS&#19981;&#21487;&#32422;&#21644;&#38750;&#21608;&#26399;&#30340;&#26465;&#20214;&#65292;&#24182;&#20316;&#20026;&#25512;&#35770;&#32780;&#35777;&#26126;&#20102;&#36941;&#21382;&#24615;&#12290;&#22312;&#31867;&#20284;&#20110;HMC&#30340;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;NUTS&#20855;&#26377;&#20960;&#20309;&#36941;&#21382;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25913;&#36827;&#20102;&#29616;&#26377;&#30340;HMC&#25910;&#25947;&#24615;&#32467;&#26524;&#65292;&#35777;&#26126;&#20102;&#36825;&#20010;&#26041;&#27861;&#22312;&#30446;&#26631;&#20998;&#24067;&#26159;&#39640;&#26031;&#20998;&#24067;&#30340;&#24494;&#25200;&#30340;&#24773;&#20917;&#19979;&#65292;&#26080;&#38656;&#23545;&#27493;&#38271;&#21644;leapfrog&#27493;&#25968;&#36827;&#34892;&#20219;&#20309;&#26377;&#30028;&#26465;&#20214;&#65292;&#20063;&#26159;&#36941;&#21382;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
There is substantial empirical evidence about the success of dynamic implementations of Hamiltonian Monte Carlo (HMC), such as the No U-Turn Sampler (NUTS), in many challenging inference problems but theoretical results about their behavior are scarce. The aim of this paper is to fill this gap. More precisely, we consider a general class of MCMC algorithms we call dynamic HMC. We show that this general framework encompasses NUTS as a particular case, implying the invariance of the target distribution as a by-product. Second, we establish conditions under which NUTS is irreducible and aperiodic and as a corrolary ergodic. Under conditions similar to the ones existing for HMC, we also show that NUTS is geometrically ergodic. Finally, we improve existing convergence results for HMC showing that this method is ergodic without any boundedness condition on the stepsize and the number of leapfrog steps, in the case where the target is a perturbation of a Gaussian distribution.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#29305;&#24449;&#20998;&#24067;&#24335;&#25968;&#25454;&#30340;&#21487;&#25193;&#23637;&#39640;&#32500;&#22810;&#21464;&#37327;&#32447;&#24615;&#22238;&#24402;&#31639;&#27861;&#65292;&#20855;&#26377;&#36890;&#20449;&#22797;&#26434;&#24230;&#19981;&#20381;&#36182;&#20110;&#29305;&#24449;&#32500;&#24230;&#21644;&#24555;&#36895;&#25910;&#25947;&#24615;&#30340;&#20248;&#21183;&#65292;&#21487;&#24212;&#29992;&#20110;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#21644;&#20855;&#26377;&#22810;&#21464;&#37327;&#21709;&#24212;&#21464;&#37327;&#30340;&#22330;&#26223;&#12290;</title><link>http://arxiv.org/abs/2307.03410</link><description>&lt;p&gt;
&#21487;&#25193;&#23637;&#39640;&#32500;&#22810;&#21464;&#37327;&#32447;&#24615;&#22238;&#24402;&#29992;&#20110;&#29305;&#24449;&#20998;&#24067;&#24335;&#25968;&#25454;&#32763;&#35793;&#26631;&#39064;
&lt;/p&gt;
&lt;p&gt;
Scalable High-Dimensional Multivariate Linear Regression for Feature-Distributed Data. (arXiv:2307.03410v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03410
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#29305;&#24449;&#20998;&#24067;&#24335;&#25968;&#25454;&#30340;&#21487;&#25193;&#23637;&#39640;&#32500;&#22810;&#21464;&#37327;&#32447;&#24615;&#22238;&#24402;&#31639;&#27861;&#65292;&#20855;&#26377;&#36890;&#20449;&#22797;&#26434;&#24230;&#19981;&#20381;&#36182;&#20110;&#29305;&#24449;&#32500;&#24230;&#21644;&#24555;&#36895;&#25910;&#25947;&#24615;&#30340;&#20248;&#21183;&#65292;&#21487;&#24212;&#29992;&#20110;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#21644;&#20855;&#26377;&#22810;&#21464;&#37327;&#21709;&#24212;&#21464;&#37327;&#30340;&#22330;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29305;&#24449;&#20998;&#24067;&#24335;&#25968;&#25454;&#26159;&#25351;&#26681;&#25454;&#29305;&#24449;&#21010;&#20998;&#24182;&#23384;&#20648;&#22312;&#22810;&#20010;&#35745;&#31639;&#33410;&#28857;&#19978;&#30340;&#25968;&#25454;&#65292;&#22312;&#20855;&#26377;&#22823;&#37327;&#29305;&#24449;&#30340;&#24212;&#29992;&#20013;&#36234;&#26469;&#36234;&#24120;&#35265;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#36825;&#31181;&#25968;&#25454;&#30340;&#20004;&#38454;&#27573;&#25918;&#26494;&#36138;&#23146;&#31639;&#27861; (TSRGA)&#65292;&#29992;&#20110;&#24212;&#29992;&#22810;&#21464;&#37327;&#32447;&#24615;&#22238;&#24402;&#12290;TSRGA &#30340;&#20027;&#35201;&#20248;&#21183;&#22312;&#20110;&#20854;&#36890;&#20449;&#22797;&#26434;&#24230;&#19981;&#20381;&#36182;&#20110;&#29305;&#24449;&#32500;&#24230;&#65292;&#20351;&#20854;&#33021;&#22815;&#39640;&#24230;&#25193;&#23637;&#21040;&#38750;&#24120;&#22823;&#30340;&#25968;&#25454;&#38598;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#22810;&#21464;&#37327;&#21709;&#24212;&#21464;&#37327;&#65292;TSRGA &#21487;&#29992;&#20110;&#20135;&#29983;&#20302;&#31209;&#31995;&#25968;&#20272;&#35745;&#12290;&#36890;&#36807;&#27169;&#25311;&#23454;&#39564;&#35777;&#26126;&#20102;TSRGA &#30340;&#24555;&#36895;&#25910;&#25947;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#25552;&#20986;&#30340;TSRGA &#24212;&#29992;&#20110;&#19968;&#31181;&#37329;&#34701;&#24212;&#29992;&#20013;&#65292;&#21033;&#29992;&#26469;&#33258; 10-K &#25253;&#21578;&#30340;&#38750;&#32467;&#26500;&#21270;&#25968;&#25454;&#65292;&#35777;&#26126;&#20102;&#20854;&#22312;&#20855;&#26377;&#35768;&#22810;&#23494;&#38598;&#22823;&#32500;&#30697;&#38453;&#30340;&#24212;&#29992;&#20013;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Feature-distributed data, referred to data partitioned by features and stored across multiple computing nodes, are increasingly common in applications with a large number of features. This paper proposes a two-stage relaxed greedy algorithm (TSRGA) for applying multivariate linear regression to such data. The main advantage of TSRGA is that its communication complexity does not depend on the feature dimension, making it highly scalable to very large data sets. In addition, for multivariate response variables, TSRGA can be used to yield low-rank coefficient estimates. The fast convergence of TSRGA is validated by simulation experiments. Finally, we apply the proposed TSRGA in a financial application that leverages unstructured data from the 10-K reports, demonstrating its usefulness in applications with many dense large-dimensional matrices.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#30340;&#31639;&#27861;&#31283;&#23450;&#24615;&#65292;&#20998;&#26512;&#20102;&#38543;&#26426;&#32452;&#21512;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#31283;&#23450;&#24615;&#21644;&#27867;&#21270;&#24615;&#65292;&#24341;&#20837;&#20102;&#32452;&#21512;&#19968;&#33268;&#31283;&#23450;&#24615;&#27010;&#24565;&#24182;&#19982;SCO&#38382;&#39064;&#30340;&#27867;&#21270;&#24615;&#24314;&#31435;&#20102;&#23450;&#37327;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2307.03357</link><description>&lt;p&gt;
&#38543;&#26426;&#32452;&#21512;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#31283;&#23450;&#24615;&#21644;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Stability and Generalization of Stochastic Compositional Gradient Descent Algorithms. (arXiv:2307.03357v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03357
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#30340;&#31639;&#27861;&#31283;&#23450;&#24615;&#65292;&#20998;&#26512;&#20102;&#38543;&#26426;&#32452;&#21512;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#31283;&#23450;&#24615;&#21644;&#27867;&#21270;&#24615;&#65292;&#24341;&#20837;&#20102;&#32452;&#21512;&#19968;&#33268;&#31283;&#23450;&#24615;&#27010;&#24565;&#24182;&#19982;SCO&#38382;&#39064;&#30340;&#27867;&#21270;&#24615;&#24314;&#31435;&#20102;&#23450;&#37327;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#21487;&#20197;&#34987;&#24418;&#24335;&#21270;&#20026;&#38543;&#26426;&#32452;&#21512;&#20248;&#21270;&#65288;SCO&#65289;&#38382;&#39064;&#65292;&#20363;&#22914;&#24378;&#21270;&#23398;&#20064;&#12289;AUC&#26368;&#22823;&#21270;&#21644;&#20803;&#23398;&#20064;&#65292;&#20854;&#20013;&#30446;&#26631;&#20989;&#25968;&#28041;&#21450;&#19982;&#26399;&#26395;&#30456;&#20851;&#30340;&#23884;&#22871;&#32452;&#21512;&#12290;&#34429;&#28982;&#24050;&#32463;&#26377;&#22823;&#37327;&#30740;&#31350;&#33268;&#21147;&#20110;&#30740;&#31350;SCO&#31639;&#27861;&#30340;&#25910;&#25947;&#34892;&#20026;&#65292;&#20294;&#23545;&#20110;&#23427;&#20204;&#30340;&#27867;&#21270;&#24615;&#33021;&#22914;&#20309;&#65292;&#21363;&#20174;&#35757;&#32451;&#31034;&#20363;&#26500;&#24314;&#30340;&#23398;&#20064;&#31639;&#27861;&#22312;&#26410;&#26469;&#30340;&#27979;&#35797;&#31034;&#20363;&#19978;&#30340;&#34892;&#20026;&#22914;&#20309;&#65292;&#21364;&#24456;&#23569;&#26377;&#30740;&#31350;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#26694;&#26550;&#19979;&#30340;&#31639;&#27861;&#31283;&#23450;&#24615;&#65292;&#25552;&#20379;&#20102;&#38543;&#26426;&#32452;&#21512;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#31283;&#23450;&#24615;&#21644;&#27867;&#21270;&#24615;&#20998;&#26512;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#31283;&#23450;&#24615;&#27010;&#24565;&#65292;&#31216;&#20026;&#32452;&#21512;&#19968;&#33268;&#31283;&#23450;&#24615;&#65292;&#24182;&#24314;&#31435;&#20102;&#23427;&#19982;SCO&#38382;&#39064;&#30340;&#27867;&#21270;&#24615;&#20043;&#38388;&#30340;&#23450;&#37327;&#20851;&#31995;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20026;&#20004;&#31181;&#27969;&#34892;&#30340;&#38543;&#26426;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#24314;&#31435;&#20102;&#32452;&#21512;&#19968;&#33268;&#31283;&#23450;&#24615;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many machine learning tasks can be formulated as a stochastic compositional optimization (SCO) problem such as reinforcement learning, AUC maximization, and meta-learning, where the objective function involves a nested composition associated with an expectation. While a significant amount of studies has been devoted to studying the convergence behavior of SCO algorithms, there is little work on understanding their generalization, i.e., how these learning algorithms built from training examples would behave on future test examples. In this paper, we provide the stability and generalization analysis of stochastic compositional gradient descent algorithms through the lens of algorithmic stability in the framework of statistical learning theory. Firstly, we introduce a stability concept called compositional uniform stability and establish its quantitative relation with generalization for SCO problems. Then, we establish the compositional uniform stability results for two popular stochastic
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#23545;&#25239;&#27169;&#22411;&#65288;QUAM&#65289;&#26469;&#26356;&#22909;&#22320;&#20272;&#35745;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#12290;QUAM&#35782;&#21035;&#25972;&#20010;&#31215;&#20998;&#19979;&#20056;&#31215;&#36739;&#22823;&#30340;&#21306;&#22495;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#21518;&#39564;&#12290;&#19982;&#20808;&#21069;&#30340;&#26041;&#27861;&#30456;&#27604;&#65292;QUAM&#23545;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#30340;&#36817;&#20284;&#35823;&#24046;&#26356;&#23567;&#12290;</title><link>http://arxiv.org/abs/2307.03217</link><description>&lt;p&gt;
&#20351;&#29992;&#23545;&#25239;&#27169;&#22411;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
Quantification of Uncertainty with Adversarial Models. (arXiv:2307.03217v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03217
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#23545;&#25239;&#27169;&#22411;&#65288;QUAM&#65289;&#26469;&#26356;&#22909;&#22320;&#20272;&#35745;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#12290;QUAM&#35782;&#21035;&#25972;&#20010;&#31215;&#20998;&#19979;&#20056;&#31215;&#36739;&#22823;&#30340;&#21306;&#22495;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#21518;&#39564;&#12290;&#19982;&#20808;&#21069;&#30340;&#26041;&#27861;&#30456;&#27604;&#65292;QUAM&#23545;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#30340;&#36817;&#20284;&#35823;&#24046;&#26356;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#23545;&#20110;&#21487;&#25805;&#20316;&#30340;&#39044;&#27979;&#38750;&#24120;&#37325;&#35201;&#12290;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#20851;&#38190;&#22312;&#20110;&#20272;&#35745;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#65292;&#23427;&#34987;&#23450;&#20041;&#20026;&#19968;&#20010;&#25955;&#24230;&#20989;&#25968;&#21644;&#21518;&#39564;&#30340;&#20056;&#31215;&#30340;&#31215;&#20998;&#12290;&#24403;&#21069;&#30340;&#26041;&#27861;&#22914;Deep Ensembles&#25110;MC dropout&#22312;&#20272;&#35745;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#26041;&#38754;&#34920;&#29616;&#19981;&#20339;&#65292;&#22240;&#20026;&#23427;&#20204;&#20027;&#35201;&#32771;&#34385;&#21518;&#39564;&#22312;&#37319;&#26679;&#27169;&#22411;&#26102;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20351;&#29992;&#23545;&#25239;&#27169;&#22411;&#65288;QUAM&#65289;&#26469;&#26356;&#22909;&#22320;&#20272;&#35745;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#12290;QUAM&#35782;&#21035;&#25972;&#20010;&#31215;&#20998;&#19979;&#20056;&#31215;&#36739;&#22823;&#30340;&#21306;&#22495;&#65292;&#32780;&#19981;&#20165;&#20165;&#26159;&#21518;&#39564;&#12290;&#22240;&#27492;&#65292;&#19982;&#20808;&#21069;&#30340;&#26041;&#27861;&#30456;&#27604;&#65292;QUAM&#23545;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#30340;&#36817;&#20284;&#35823;&#24046;&#26356;&#23567;&#12290;&#20056;&#31215;&#36739;&#22823;&#30340;&#27169;&#22411;&#23545;&#24212;&#20110;&#23545;&#25239;&#27169;&#22411;&#65288;&#19981;&#26159;&#23545;&#25239;&#24615;&#31034;&#20363;&#65281;&#65289;&#12290;&#23545;&#25239;&#27169;&#22411;&#26082;&#26377;&#36739;&#39640;&#30340;&#21518;&#39564;&#65292;&#20063;&#26377;&#20854;&#39044;&#27979;&#19982;&#20854;&#20182;&#27169;&#22411;&#20043;&#38388;&#30340;&#36739;&#39640;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantifying uncertainty is important for actionable predictions in real-world applications. A crucial part of predictive uncertainty quantification is the estimation of epistemic uncertainty, which is defined as an integral of the product between a divergence function and the posterior. Current methods such as Deep Ensembles or MC dropout underperform at estimating the epistemic uncertainty, since they primarily consider the posterior when sampling models. We suggest Quantification of Uncertainty with Adversarial Models (QUAM) to better estimate the epistemic uncertainty. QUAM identifies regions where the whole product under the integral is large, not just the posterior. Consequently, QUAM has lower approximation error of the epistemic uncertainty compared to previous methods. Models for which the product is large correspond to adversarial models (not adversarial examples!). Adversarial models have both a high posterior as well as a high divergence between their predictions and that of
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#20855;&#26377;&#22810;&#23618;&#30340;&#36229;&#22270;&#946;&#27169;&#22411;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#25512;&#23548;&#20102;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#29575;&#21644;&#26497;&#38480;&#20998;&#24067;&#65292;&#24182;&#26500;&#24314;&#20102;&#27169;&#22411;&#21442;&#25968;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#24314;&#31435;&#20102;&#36229;&#22270;&#946;&#27169;&#22411;&#20013;&#20284;&#28982;&#27604;&#26816;&#39564;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.02818</link><description>&lt;p&gt;
&#39640;&#38454;&#32593;&#32476;&#20013;&#30340;&#24230;&#24322;&#36136;&#24615;&#65306;&#36229;&#22270;&#946;&#27169;&#22411;&#30340;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Degree Heterogeneity in Higher-Order Networks: Inference in the Hypergraph $\boldsymbol{\beta}$-Model. (arXiv:2307.02818v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02818
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#20855;&#26377;&#22810;&#23618;&#30340;&#36229;&#22270;&#946;&#27169;&#22411;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#25512;&#23548;&#20102;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#29575;&#21644;&#26497;&#38480;&#20998;&#24067;&#65292;&#24182;&#26500;&#24314;&#20102;&#27169;&#22411;&#21442;&#25968;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#24314;&#31435;&#20102;&#36229;&#22270;&#946;&#27169;&#22411;&#20013;&#20284;&#28982;&#27604;&#26816;&#39564;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#22270;&#20013;&#30340;&#946;&#27169;&#22411;&#36890;&#24120;&#29992;&#20110;&#34920;&#31034;&#20855;&#26377;&#24230;&#24322;&#36136;&#24615;&#30340;&#32593;&#32476;&#20013;&#30340;&#37197;&#23545;&#20132;&#20114;&#12290;&#36229;&#22270;&#946;&#27169;&#22411;&#36229;&#36234;&#20102;&#37197;&#23545;&#20132;&#20114;&#65292;Stasi&#31561;&#20154;&#20110;2014&#24180;&#24341;&#20837;&#20102;&#36229;&#22270;&#946;&#27169;&#22411;&#65292;&#29992;&#20110;&#25429;&#25417;&#20855;&#26377;&#39640;&#38454;&#65288;&#22810;&#21521;&#65289;&#20132;&#20114;&#30340;&#32593;&#32476;&#20013;&#30340;&#24230;&#24322;&#36136;&#24615;&#12290;&#26412;&#25991;&#39318;&#27425;&#23545;&#20855;&#26377;&#22810;&#23618;&#30340;&#36229;&#22270;&#946;&#27169;&#22411;&#36827;&#34892;&#20102;&#20005;&#26684;&#30740;&#31350;&#65292;&#23427;&#20801;&#35768;&#22312;&#19981;&#21516;&#23618;&#27425;&#20013;&#23384;&#22312;&#19981;&#21516;&#22823;&#23567;&#30340;&#36229;&#36793;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#26368;&#22823;&#20284;&#28982;&#65288;ML&#65289;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#29575;&#65292;&#24182;&#30830;&#23450;&#20102;&#23427;&#20204;&#30340;&#26368;&#23567;&#26497;&#23567;&#36895;&#29575;&#12290;&#25105;&#20204;&#36824;&#25512;&#23548;&#20102;ML&#20272;&#35745;&#30340;&#26497;&#38480;&#20998;&#24067;&#65292;&#24182;&#26500;&#24314;&#20102;&#27169;&#22411;&#21442;&#25968;&#30340;&#28176;&#36817;&#26377;&#25928;&#32622;&#20449;&#21306;&#38388;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#36229;&#22270;&#946;&#27169;&#22411;&#20013;&#30340;&#25311;&#21512;&#20248;&#24230;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#22312;&#38646;&#20551;&#35774;&#19979;&#24314;&#31435;&#20102;&#20284;&#28982;&#27604;&#65288;LR&#65289;&#26816;&#39564;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The $\boldsymbol{\beta}$-model for random graphs is commonly used for representing pairwise interactions in a network with degree heterogeneity. Going beyond pairwise interactions, Stasi et al. (2014) introduced the hypergraph $\boldsymbol{\beta}$-model for capturing degree heterogeneity in networks with higher-order (multi-way) interactions. In this paper we initiate the rigorous study of the hypergraph $\boldsymbol{\beta}$-model with multiple layers, which allows for hyperedges of different sizes across the layers. To begin with, we derive the rates of convergence of the maximum likelihood (ML) estimate and establish their minimax rate optimality. We also derive the limiting distribution of the ML estimate and construct asymptotically valid confidence intervals for the model parameters. Next, we consider the goodness-of-fit problem in the hypergraph $\boldsymbol{\beta}$-model. Specifically, we establish the asymptotic normality of the likelihood ratio (LR) test under the null hypothe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#24212;&#29992;&#20110;&#38543;&#26426;&#20248;&#21270;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#20013;&#30340;&#33258;&#36866;&#24212;&#31639;&#27861;&#12290;&#31639;&#27861;&#21487;&#20197;&#33258;&#21160;&#36866;&#24212;&#19981;&#21516;&#30340;&#22122;&#22768;&#27700;&#24179;&#21644;&#26799;&#24230;&#27604;&#20363;&#33539;&#22260;&#65292;&#20174;&#32780;&#36798;&#21040;&#65288;&#36817;&#20284;&#65289;&#26368;&#20248;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2306.10278</link><description>&lt;p&gt;
&#38750;&#20984;&#20248;&#21270;&#20013;&#30340;&#33258;&#36866;&#24212;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Adaptive Strategies in Non-convex Optimization. (arXiv:2306.10278v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10278
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#24212;&#29992;&#20110;&#38543;&#26426;&#20248;&#21270;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#20013;&#30340;&#33258;&#36866;&#24212;&#31639;&#27861;&#12290;&#31639;&#27861;&#21487;&#20197;&#33258;&#21160;&#36866;&#24212;&#19981;&#21516;&#30340;&#22122;&#22768;&#27700;&#24179;&#21644;&#26799;&#24230;&#27604;&#20363;&#33539;&#22260;&#65292;&#20174;&#32780;&#36798;&#21040;&#65288;&#36817;&#20284;&#65289;&#26368;&#20248;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#26524;&#31639;&#27861;&#19981;&#38656;&#35201;&#20808;&#39564;&#30693;&#35782;&#23601;&#21487;&#20197;&#34920;&#29616;&#24471;&#19982;&#30693;&#36947;&#36825;&#20010;&#38382;&#39064;&#29305;&#23450;&#21442;&#25968;&#30340;&#31639;&#27861;&#30456;&#31454;&#20105;&#65292;&#37027;&#20040;&#23601;&#35828;&#31639;&#27861;&#23545;&#26576;&#20010;&#21442;&#25968;&#26159;&#33258;&#36866;&#24212;&#30340;&#12290;&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#25105;&#20204;&#22312;&#20197;&#19979;&#22330;&#26223;&#20013;&#24320;&#21457;&#33258;&#36866;&#24212;&#31639;&#27861;&#30340;&#24037;&#20316;&#65306;1. &#22312;&#38543;&#26426;&#20248;&#21270;&#29615;&#22659;&#20013;&#65292;&#25105;&#20204;&#21482;&#25910;&#21040;&#38543;&#26426;&#26799;&#24230;&#65292;&#24182;&#19988;&#35780;&#20272;&#36825;&#20123;&#26799;&#24230;&#30340;&#22122;&#22768;&#27700;&#24179;&#26497;&#22823;&#22320;&#24433;&#21709;&#20102;&#25910;&#25947;&#36895;&#24230;&#12290;&#36890;&#24120;&#38656;&#35201;&#35843;&#25972;&#22122;&#22768;&#27700;&#24179;&#25165;&#33021;&#23454;&#29616;&#26368;&#20248;&#36895;&#29575;&#65292;&#32780;&#25105;&#20204;&#24320;&#21457;&#20102;&#33258;&#36866;&#24212;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#19981;&#30693;&#36947;&#22122;&#22768;&#33539;&#22260;&#30340;&#24773;&#20917;&#19979;&#33258;&#21160;&#20445;&#35777;&#65288;&#36817;&#20284;&#65289;&#26368;&#20248;&#36895;&#29575;&#12290;2. &#22312;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26102;&#65292;&#27599;&#20010;&#22352;&#26631;&#36724;&#19978;&#30340;&#26799;&#24230;&#22823;&#23567;&#27604;&#20363;&#21487;&#20197;&#25955;&#24067;&#22312;&#38750;&#24120;&#24191;&#30340;&#33539;&#22260;&#20869;&#65292;&#38500;&#38750;&#37319;&#29992;&#20687;BatchNorm&#36825;&#26679;&#30340;&#24402;&#19968;&#21270;&#25216;&#26415;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#19981;&#32771;&#34385;&#26799;&#24230;&#27604;&#20363;&#38382;&#39064;&#30340;&#31639;&#27861;&#21487;&#33021;&#34920;&#29616;&#38750;&#24120;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
An algorithm is said to be adaptive to a certain parameter (of the problem) if it does not need a priori knowledge of such a parameter but performs competitively to those that know it. This dissertation presents our work on adaptive algorithms in following scenarios: 1. In the stochastic optimization setting, we only receive stochastic gradients and the level of noise in evaluating them greatly affects the convergence rate. Tuning is typically required when without prior knowledge of the noise scale in order to achieve the optimal rate. Considering this, we designed and analyzed noise-adaptive algorithms that can automatically ensure (near)-optimal rates under different noise scales without knowing it. 2. In training deep neural networks, the scales of gradient magnitudes in each coordinate can scatter across a very wide range unless normalization techniques, like BatchNorm, are employed. In such situations, algorithms not addressing this problem of gradient scales can behave very poor
&lt;/p&gt;</description></item><item><title>&#22312;&#32447;&#22810;&#31867;&#23398;&#20064;&#38382;&#39064;&#20013;&#65292;&#20351;&#29992;Multiclass Littlestone&#32500;&#24230;&#21487;&#20197;&#21051;&#30011;&#26631;&#31614;&#25968;&#30446;&#20026;&#26080;&#30028;&#24773;&#20917;&#19979;&#30340;&#21487;&#23398;&#20064;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.17716</link><description>&lt;p&gt;
&#22312;&#32447;&#22810;&#31867;&#21487;&#23398;&#20064;&#24615;&#30340;&#21051;&#30011;&#12290;
&lt;/p&gt;
&lt;p&gt;
A Characterization of Online Multiclass Learnability. (arXiv:2303.17716v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.17716
&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#22810;&#31867;&#23398;&#20064;&#38382;&#39064;&#20013;&#65292;&#20351;&#29992;Multiclass Littlestone&#32500;&#24230;&#21487;&#20197;&#21051;&#30011;&#26631;&#31614;&#25968;&#30446;&#20026;&#26080;&#30028;&#24773;&#20917;&#19979;&#30340;&#21487;&#23398;&#20064;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#24403;&#26631;&#31614;&#25968;&#30446;&#26159;&#26080;&#30028;&#30340;&#26102;&#20505;&#22312;&#32447;&#22810;&#31867;&#23398;&#20064;&#38382;&#39064;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;Multiclass Littlestone&#32500;&#24230;&#65292;&#36825;&#20010;&#27010;&#24565;&#39318;&#27425;&#20986;&#29616;&#22312;\cite{DanielyERMprinciple}&#20013;&#65292;&#32487;&#32493;&#21051;&#30011;&#20102;&#35813;&#22330;&#26223;&#19979;&#30340;&#22312;&#32447;&#21487;&#23398;&#20064;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34917;&#20805;&#20102;&#26368;&#36817;&#30340;&#24037;&#20316;&#65292;\cite{Brukhimetal2022}&#32473;&#20986;&#20102;&#24403;&#26631;&#31614;&#31354;&#38388;&#26159;&#26080;&#30028;&#30340;&#24773;&#20917;&#19979;&#25209;&#22788;&#29702;&#22810;&#31867;&#21487;&#23398;&#20064;&#24615;&#30340;&#21051;&#30011;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of online multiclass learning when the number of labels is unbounded. We show that the Multiclass Littlestone dimension, first introduced in \cite{DanielyERMprinciple}, continues to characterize online learnability in this setting. Our result complements the recent work by \cite{Brukhimetal2022} who give a characterization of batch multiclass learnability when the label space is unbounded.
&lt;/p&gt;</description></item><item><title>&#36830;&#32493;&#26102;&#38388;&#21151;&#33021;&#25193;&#25955;&#36807;&#31243;&#24341;&#20837;&#20102;&#21151;&#33021;&#25193;&#25955;&#36807;&#31243;&#65288;FDPs&#65289;&#65292;&#23558;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#25512;&#24191;&#21040;&#26080;&#38480;&#32500;&#20989;&#25968;&#31354;&#38388;&#12290;&#36890;&#36807;&#20351;&#29992;&#26032;&#30340;&#25968;&#23398;&#26694;&#26550;&#21644;&#25193;&#23637;&#65292;FDPs&#21487;&#20197;&#22312;&#20989;&#25968;&#31354;&#38388;&#20013;&#26500;&#24314;&#26032;&#22411;&#29983;&#25104;&#27169;&#22411;&#65292;&#22312;&#22788;&#29702;&#36830;&#32493;&#25968;&#25454;&#26102;&#33021;&#22815;&#23454;&#29616;&#39640;&#36136;&#37327;&#30340;&#22270;&#20687;&#29983;&#25104;&#65292;&#25152;&#38656;&#21442;&#25968;&#25968;&#37327;&#27604;&#29616;&#26377;&#27169;&#22411;&#20302;&#20960;&#20010;&#25968;&#37327;&#32423;&#12290;</title><link>http://arxiv.org/abs/2303.00800</link><description>&lt;p&gt;
&#36830;&#32493;&#26102;&#38388;&#21151;&#33021;&#25193;&#25955;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Continuous-Time Functional Diffusion Processes. (arXiv:2303.00800v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.00800
&lt;/p&gt;
&lt;p&gt;
&#36830;&#32493;&#26102;&#38388;&#21151;&#33021;&#25193;&#25955;&#36807;&#31243;&#24341;&#20837;&#20102;&#21151;&#33021;&#25193;&#25955;&#36807;&#31243;&#65288;FDPs&#65289;&#65292;&#23558;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#25512;&#24191;&#21040;&#26080;&#38480;&#32500;&#20989;&#25968;&#31354;&#38388;&#12290;&#36890;&#36807;&#20351;&#29992;&#26032;&#30340;&#25968;&#23398;&#26694;&#26550;&#21644;&#25193;&#23637;&#65292;FDPs&#21487;&#20197;&#22312;&#20989;&#25968;&#31354;&#38388;&#20013;&#26500;&#24314;&#26032;&#22411;&#29983;&#25104;&#27169;&#22411;&#65292;&#22312;&#22788;&#29702;&#36830;&#32493;&#25968;&#25454;&#26102;&#33021;&#22815;&#23454;&#29616;&#39640;&#36136;&#37327;&#30340;&#22270;&#20687;&#29983;&#25104;&#65292;&#25152;&#38656;&#21442;&#25968;&#25968;&#37327;&#27604;&#29616;&#26377;&#27169;&#22411;&#20302;&#20960;&#20010;&#25968;&#37327;&#32423;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#21151;&#33021;&#25193;&#25955;&#36807;&#31243;&#65288;FDPs&#65289;&#65292;&#23558;&#22522;&#20110;&#24471;&#20998;&#30340;&#25193;&#25955;&#27169;&#22411;&#25512;&#24191;&#21040;&#26080;&#38480;&#32500;&#20989;&#25968;&#31354;&#38388;&#12290; FDPs&#38656;&#35201;&#19968;&#31181;&#26032;&#30340;&#25968;&#23398;&#26694;&#26550;&#26469;&#25551;&#36848;&#21069;&#21521;&#21644;&#21453;&#21521;&#21160;&#21147;&#23398;&#65292;&#24182;&#36827;&#34892;&#22810;&#20010;&#25193;&#23637;&#20197;&#24471;&#20986;&#23454;&#38469;&#30340;&#35757;&#32451;&#30446;&#26631;&#12290;&#36825;&#20123;&#25193;&#23637;&#21253;&#25324;Girsanov&#23450;&#29702;&#30340;&#26080;&#38480;&#32500;&#29256;&#26412;&#65292;&#20197;&#20415;&#33021;&#22815;&#35745;&#31639;ELBO&#65292;&#20197;&#21450;&#37319;&#26679;&#23450;&#29702;&#30340;&#26080;&#38480;&#32500;&#29256;&#26412;&#65292;&#20197;&#30830;&#20445;&#21487;&#25968;&#20010;&#28857;&#19978;&#30340;&#20989;&#25968;&#35780;&#20272;&#31561;&#20215;&#20110;&#26080;&#38480;&#32500;&#20989;&#25968;&#12290;&#25105;&#20204;&#20351;&#29992;FDPs&#22312;&#20989;&#25968;&#31354;&#38388;&#20013;&#26500;&#24314;&#20102;&#19968;&#31181;&#26032;&#22411;&#29983;&#25104;&#27169;&#22411;&#65292;&#19981;&#38656;&#35201;&#19987;&#38376;&#30340;&#32593;&#32476;&#26550;&#26500;&#65292;&#24182;&#19988;&#21487;&#20197;&#22788;&#29702;&#20219;&#20309;&#31867;&#22411;&#30340;&#36830;&#32493;&#25968;&#25454;&#12290;&#25105;&#20204;&#22312;&#30495;&#23454;&#25968;&#25454;&#19978;&#30340;&#32467;&#26524;&#26174;&#31034;&#65292;&#20351;&#29992;&#31616;&#21333;&#30340;&#22810;&#23618;&#24863;&#30693;&#26426;&#65288;MLP&#65289;&#32467;&#26500;&#65292;FDPs&#23454;&#29616;&#20102;&#39640;&#36136;&#37327;&#30340;&#22270;&#20687;&#29983;&#25104;&#65292;&#25152;&#38656;&#30340;&#21442;&#25968;&#25968;&#37327;&#27604;&#29616;&#26377;&#30340;&#25193;&#25955;&#27169;&#22411;&#20302;&#20960;&#20010;&#25968;&#37327;&#32423;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce Functional Diffusion Processes (FDPs), which generalize score-based diffusion models to infinite-dimensional function spaces. FDPs require a new mathematical framework to describe the forward and backward dynamics, and several extensions to derive practical training objectives. These include infinite-dimensional versions of Girsanov theorem, in order to be able to compute an ELBO, and of the sampling theorem, in order to guarantee that functional evaluations in a countable set of points are equivalent to infinite-dimensional functions. We use FDPs to build a new breed of generative models in function spaces, which do not require specialized network architectures, and that can work with any kind of continuous data. Our results on real data show that FDPs achieve high-quality image generation, using a simple MLP architecture with orders of magnitude fewer parameters than existing diffusion models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#40657;&#30418;&#25209;&#37327;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20165;&#21033;&#29992;&#27169;&#22411;&#39044;&#27979;&#36827;&#34892;&#35780;&#20272;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#24182;&#25193;&#23637;&#20102;&#19968;&#31995;&#21015;&#30333;&#30418;&#25209;&#37327;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2302.08981</link><description>&lt;p&gt;
&#40657;&#30418;&#25209;&#37327;&#20027;&#21160;&#23398;&#20064;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Black-Box Batch Active Learning for Regression. (arXiv:2302.08981v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.08981
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#40657;&#30418;&#25209;&#37327;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20165;&#21033;&#29992;&#27169;&#22411;&#39044;&#27979;&#36827;&#34892;&#35780;&#20272;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#24182;&#25193;&#23637;&#20102;&#19968;&#31995;&#21015;&#30333;&#30418;&#25209;&#37327;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25209;&#37327;&#20027;&#21160;&#23398;&#20064;&#26159;&#19968;&#31181;&#24120;&#29992;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#37325;&#22797;&#33719;&#21462;&#25968;&#25454;&#28857;&#30340;&#26631;&#31614;&#26469;&#39640;&#25928;&#22320;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#23588;&#20854;&#26159;&#23545;&#20110;&#22823;&#35268;&#27169;&#30340;&#21021;&#22987;&#26410;&#26631;&#35760;&#25968;&#25454;&#38598;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#26368;&#36817;&#30340;&#25209;&#37327;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#37117;&#26159;&#30333;&#30418;&#26041;&#27861;&#65292;&#24182;&#19988;&#36890;&#24120;&#20165;&#38480;&#20110;&#21487;&#24494;&#20998;&#30340;&#21442;&#25968;&#27169;&#22411;&#65306;&#23427;&#20204;&#20351;&#29992;&#22522;&#20110;&#27169;&#22411;&#23884;&#20837;&#25110;&#19968;&#38454;&#21644;&#20108;&#38454;&#23548;&#25968;&#30340;&#33719;&#21462;&#20989;&#25968;&#23545;&#26410;&#26631;&#35760;&#30340;&#25968;&#25454;&#28857;&#36827;&#34892;&#35780;&#20998;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#40657;&#30418;&#25209;&#37327;&#20027;&#21160;&#23398;&#20064;&#22238;&#24402;&#20219;&#21153;&#30340;&#26041;&#27861;&#65292;&#20316;&#20026;&#30333;&#30418;&#26041;&#27861;&#30340;&#25193;&#23637;&#12290;&#20851;&#38190;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20165;&#20381;&#36182;&#20110;&#27169;&#22411;&#30340;&#39044;&#27979;&#12290;&#36825;&#31181;&#26041;&#27861;&#36866;&#29992;&#20110;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#21253;&#25324;&#24120;&#35268;&#30340;&#21644;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#20197;&#21450;&#38750;&#21487;&#24494;&#20998;&#27169;&#22411;&#65292;&#22914;&#38543;&#26426;&#26862;&#26519;&#12290;&#23427;&#22522;&#20110;&#36125;&#21494;&#26031;&#21407;&#21017;&#65292;&#24182;&#21033;&#29992;&#26368;&#36817;&#30340;&#22522;&#20110;&#26680;&#30340;&#26041;&#27861;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#25193;&#23637;&#19968;&#31995;&#21015;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#30340;&#30333;&#30418;&#25209;&#37327;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#65288;BADGE&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Batch active learning is a popular approach for efficiently training machine learning models on large, initially unlabelled datasets by repeatedly acquiring labels for batches of data points. However, many recent batch active learning methods are white-box approaches and are often limited to differentiable parametric models: they score unlabeled points using acquisition functions based on model embeddings or first- and second-order derivatives. In this paper, we propose black-box batch active learning for regression tasks as an extension of white-box approaches. Crucially, our method only relies on model predictions. This approach is compatible with a wide range of machine learning models, including regular and Bayesian deep learning models and non-differentiable models such as random forests. It is rooted in Bayesian principles and utilizes recent kernel-based approaches. This allows us to extend a wide range of existing state-of-the-art white-box batch active learning methods (BADGE,
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32467;&#26500;&#21270;&#21464;&#20998;&#25512;&#26029;&#30340;&#32852;&#21512;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#21508;&#31181;&#32467;&#26500;&#21270;&#27010;&#29575;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#36824;&#25552;&#20379;&#20102;&#19968;&#31181;&#36890;&#20449;&#39640;&#25928;&#30340;&#21464;&#20307;&#31639;&#27861;&#65292;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2302.03314</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#32852;&#21512;&#21464;&#20998;&#25512;&#26029;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Federated Variational Inference Methods for Structured Latent Variable Models. (arXiv:2302.03314v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.03314
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32467;&#26500;&#21270;&#21464;&#20998;&#25512;&#26029;&#30340;&#32852;&#21512;&#23398;&#20064;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#21508;&#31181;&#32467;&#26500;&#21270;&#27010;&#29575;&#27169;&#22411;&#12290;&#27492;&#22806;&#65292;&#36824;&#25552;&#20379;&#20102;&#19968;&#31181;&#36890;&#20449;&#39640;&#25928;&#30340;&#21464;&#20307;&#31639;&#27861;&#65292;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#26041;&#27861;&#20351;&#24471;&#22312;&#25968;&#25454;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#27169;&#22411;&#35757;&#32451;&#25104;&#20026;&#21487;&#33021;&#65292;&#32780;&#26080;&#38656;&#25968;&#25454;&#31163;&#24320;&#20854;&#21407;&#22987;&#20301;&#32622;&#65292;&#24182;&#19988;&#22312;&#21508;&#20010;&#39046;&#22495;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#23384;&#22312;&#23616;&#38480;&#24615;&#65292;&#26080;&#27861;&#24212;&#29992;&#20110;&#35768;&#22810;&#32467;&#26500;&#21270;&#27010;&#29575;&#27169;&#22411;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32467;&#26500;&#21270;&#21464;&#20998;&#25512;&#26029;&#30340;&#36890;&#29992;&#32780;&#20248;&#38597;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#38024;&#23545;&#32852;&#37030;&#23398;&#20064;&#29615;&#22659;&#36827;&#34892;&#20102;&#36866;&#24212;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#31867;&#20284;&#20110;&#32463;&#20856;FedAvg&#31639;&#27861;&#30340;&#36890;&#20449;&#39640;&#25928;&#22411;&#21464;&#20307;&#12290;&#36890;&#36807;&#19982;&#20998;&#23618;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#21644;&#20027;&#39064;&#27169;&#22411;&#36827;&#34892;&#27604;&#36739;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated learning methods enable model training across distributed data sources without data leaving their original locations and have gained increasing interest in various fields. However, existing approaches are limited, excluding many structured probabilistic models. We present a general and elegant solution based on structured variational inference, widely used in Bayesian machine learning, adapted for the federated setting. Additionally, we provide a communication-efficient variant analogous to the canonical FedAvg algorithm. The proposed algorithms' effectiveness is demonstrated, and their performance is compared with hierarchical Bayesian neural networks and topic models.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20351;&#29992;&#24322;&#26041;&#24046;&#22122;&#22768;&#27169;&#22411;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#21517;&#20026;&#24191;&#20041;&#26681;&#22240;&#22240;&#26524;&#25512;&#26029;&#65288;GRCI&#65289;&#30340;&#31639;&#27861;&#65292;&#33021;&#22815;&#26356;&#20934;&#30830;&#22320;&#35782;&#21035;&#30142;&#30149;&#30340;&#24739;&#32773;&#29305;&#23450;&#26681;&#26412;&#21407;&#22240;&#12290;</title><link>http://arxiv.org/abs/2205.13085</link><description>&lt;p&gt;
&#20351;&#29992;&#24322;&#26041;&#24046;&#22122;&#22768;&#27169;&#22411;&#35782;&#21035;&#29305;&#23450;&#24739;&#32773;&#30340;&#26681;&#26412;&#21407;&#22240;
&lt;/p&gt;
&lt;p&gt;
Identifying Patient-Specific Root Causes with the Heteroscedastic Noise Model. (arXiv:2205.13085v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.13085
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20351;&#29992;&#24322;&#26041;&#24046;&#22122;&#22768;&#27169;&#22411;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#21517;&#20026;&#24191;&#20041;&#26681;&#22240;&#22240;&#26524;&#25512;&#26029;&#65288;GRCI&#65289;&#30340;&#31639;&#27861;&#65292;&#33021;&#22815;&#26356;&#20934;&#30830;&#22320;&#35782;&#21035;&#30142;&#30149;&#30340;&#24739;&#32773;&#29305;&#23450;&#26681;&#26412;&#21407;&#22240;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22797;&#26434;&#30142;&#30149;&#30001;&#35768;&#22810;&#22240;&#32032;&#24341;&#36215;&#65292;&#21363;&#20351;&#22312;&#30456;&#21516;&#30340;&#35786;&#26029;&#31867;&#21035;&#20013;&#65292;&#36825;&#20123;&#22240;&#32032;&#21487;&#33021;&#22312;&#24739;&#32773;&#20043;&#38388;&#20063;&#20250;&#26377;&#25152;&#19981;&#21516;&#12290;&#28982;&#32780;&#65292;&#19968;&#20123;&#28508;&#22312;&#30340;&#26681;&#26412;&#21407;&#22240;&#20173;&#28982;&#21487;&#33021;&#22312;&#27599;&#20010;&#24739;&#32773;&#20013;&#24341;&#21457;&#30142;&#30149;&#30340;&#21457;&#23637;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#19987;&#27880;&#20110;&#35782;&#21035;&#30142;&#30149;&#30340;&#24739;&#32773;&#29305;&#23450;&#26681;&#26412;&#21407;&#22240;&#65292;&#21363;&#22312;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#20013;&#22806;&#29983;&#35823;&#24046;&#39033;&#30340;&#26679;&#26412;&#29305;&#23450;&#39044;&#27979;&#33021;&#21147;&#12290;&#25105;&#20204;&#20174;&#32447;&#24615;&#35774;&#32622;&#25512;&#24191;&#21040;&#24322;&#26041;&#24046;&#22122;&#22768;&#27169;&#22411;&#65292;&#20854;&#20013;$ Y = m&#65288;X&#65289;+ \varepsilon\sigma&#65288;X&#65289;$&#65292;&#20854;&#20013;$m&#65288;X&#65289;$&#21644;$\sigma&#65288;X&#65289;$&#20998;&#21035;&#20195;&#34920;&#26465;&#20214;&#22343;&#20540;&#21644;&#22343;&#20540;&#32477;&#23545;&#20559;&#24046;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#12290;&#35813;&#27169;&#22411;&#20445;&#25345;&#21487;&#35782;&#21035;&#24615;&#65292;&#20294;&#24341;&#20837;&#20102;&#19968;&#20123;&#38750;&#24179;&#20961;&#30340;&#25361;&#25112;&#65292;&#38656;&#35201;&#19968;&#31181;&#21517;&#20026;&#24191;&#20041;&#26681;&#22240;&#22240;&#26524;&#25512;&#26029;&#65288;GRCI&#65289;&#30340;&#23450;&#21046;&#31639;&#27861;&#26469;&#27491;&#30830;&#25552;&#21462;&#35823;&#24046;&#39033;&#12290;&#19982;&#29616;&#26377;&#30340;&#26367;&#20195;&#26041;&#27861;&#30456;&#27604;&#65292;GRCI&#26356;&#20934;&#30830;&#22320;&#24674;&#22797;&#20102;&#29305;&#23450;&#24739;&#32773;&#30340;&#26681;&#26412;&#21407;&#22240;&#12290;
&lt;/p&gt;
&lt;p&gt;
Complex diseases are caused by a multitude of factors that may differ between patients even within the same diagnostic category. A few underlying root causes may nevertheless initiate the development of disease within each patient. We therefore focus on identifying patient-specific root causes of disease, which we equate to the sample-specific predictivity of the exogenous error terms in a structural equation model. We generalize from the linear setting to the heteroscedastic noise model where $Y = m(X) + \varepsilon\sigma(X)$ with non-linear functions $m(X)$ and $\sigma(X)$ representing the conditional mean and mean absolute deviation, respectively. This model preserves identifiability but introduces non-trivial challenges that require a customized algorithm called Generalized Root Causal Inference (GRCI) to extract the error terms correctly. GRCI recovers patient-specific root causes more accurately than existing alternatives.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#30340;&#26041;&#24335;&#65292;&#22312;&#20449;&#21495;&#19982;&#32972;&#26223;&#39640;&#24230;&#37325;&#21472;&#30340;&#24773;&#20917;&#19979;&#22686;&#24378;LHC&#26032;&#29289;&#29702;&#25506;&#27979;&#30340;&#28789;&#25935;&#24230;&#12290;&#20351;&#29992;XGBoost&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#26469;&#21033;&#29992;&#21487;&#35266;&#27979;&#37327;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#27604;&#20256;&#32479;&#30340;&#21066;&#20943;-&#35745;&#25968;&#26041;&#27861;&#26356;&#26377;&#25928;&#65292;&#24182;&#37319;&#29992;&#27169;&#26495;&#25311;&#21512;&#26041;&#27861;&#20998;&#26512;&#27169;&#22411;&#36755;&#20986;&#12290;</title><link>http://arxiv.org/abs/2108.03125</link><description>&lt;p&gt;
&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#25552;&#39640;Sneutrino&#25506;&#27979;&#25928;&#29575;&#8212;&#8212;&#22312;&#23567;&#20449;&#21495;&#22330;&#26223;&#20013;&#36229;&#36234;&#21066;&#20943;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Beyond Cuts in Small Signal Scenarios -- Enhanced Sneutrino Detectability Using Machine Learning. (arXiv:2108.03125v3 [hep-ph] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2108.03125
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#30340;&#26041;&#24335;&#65292;&#22312;&#20449;&#21495;&#19982;&#32972;&#26223;&#39640;&#24230;&#37325;&#21472;&#30340;&#24773;&#20917;&#19979;&#22686;&#24378;LHC&#26032;&#29289;&#29702;&#25506;&#27979;&#30340;&#28789;&#25935;&#24230;&#12290;&#20351;&#29992;XGBoost&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#26469;&#21033;&#29992;&#21487;&#35266;&#27979;&#37327;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#27604;&#20256;&#32479;&#30340;&#21066;&#20943;-&#35745;&#25968;&#26041;&#27861;&#26356;&#26377;&#25928;&#65292;&#24182;&#37319;&#29992;&#27169;&#26495;&#25311;&#21512;&#26041;&#27861;&#20998;&#26512;&#27169;&#22411;&#36755;&#20986;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#22686;&#24378;LHC&#26032;&#29289;&#29702;&#25628;&#32034;&#28789;&#25935;&#24230;&#30340;&#26041;&#27861;&#65292;&#29305;&#21035;&#26159;&#22312;&#32972;&#26223;&#25903;&#37197;&#21644;&#20449;&#21495;&#19982;&#32972;&#26223;&#22312;&#21487;&#35266;&#27979;&#37327;&#19978;&#23384;&#22312;&#39640;&#24230;&#37325;&#21472;&#30340;&#24773;&#20917;&#19979;&#12290;&#25105;&#20204;&#20351;&#29992;&#20102;&#20004;&#31181;&#19981;&#21516;&#30340;&#27169;&#22411;&#65292;XGBoost&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#21033;&#29992;&#21487;&#35266;&#27979;&#37327;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#65292;&#24182;&#23558;&#36825;&#31181;&#26041;&#27861;&#19982;&#20256;&#32479;&#30340;&#21066;&#20943;-&#35745;&#25968;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19981;&#21516;&#30340;&#26041;&#27861;&#26469;&#20998;&#26512;&#27169;&#22411;&#30340;&#36755;&#20986;&#65292;&#24182;&#21457;&#29616;&#27169;&#26495;&#25311;&#21512;&#36890;&#24120;&#27604;&#31616;&#21333;&#30340;&#21066;&#20943;&#26041;&#27861;&#34920;&#29616;&#26356;&#22909;&#12290;&#36890;&#36807;Shapley&#20998;&#35299;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#23545;&#20107;&#20214;&#36816;&#21160;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#36755;&#20986;&#20043;&#38388;&#20851;&#31995;&#30340;&#39069;&#22806;&#27934;&#23519;&#12290;&#25105;&#20204;&#20197;&#20855;&#20307;&#30340;&#20122;&#31283;Sneutrino&#36229;&#23545;&#31216;&#24773;&#26223;&#20026;&#20363;&#65292;&#20294;&#35813;&#26041;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#26356;&#24191;&#27867;&#30340;&#27169;&#22411;&#31867;&#21035;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate enhancing the sensitivity of new physics searches at the LHC by machine learning in the case of background dominance and a high degree of overlap between the observables for signal and background. We use two different models, XGBoost and a deep neural network, to exploit correlations between observables and compare this approach to the traditional cut-and-count method. We consider different methods to analyze the models' output, finding that a template fit generally performs better than a simple cut. By means of a Shapley decomposition, we gain additional insight into the relationship between event kinematics and the machine learning model output. We consider a supersymmetric scenario with a metastable sneutrino as a concrete example, but the methodology can be applied to a much wider class of models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#28789;&#27963;&#23436;&#20840;&#20998;&#25955;&#21270;&#30340;&#28436;&#21592;-&#35780;&#35770;&#23478;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#22312;&#22823;&#35268;&#27169;&#21512;&#20316;&#22810;&#26234;&#33021;&#20307;&#29615;&#22659;&#20013;&#65292;&#36890;&#36807;&#35774;&#35745;&#19968;&#20010;&#22522;&#20110;&#21407;&#22987;-&#23545;&#20598;&#28151;&#21512;&#26799;&#24230;&#19979;&#38477;&#30340;&#31639;&#27861;&#26694;&#26550;&#65292;&#21487;&#20197;&#20998;&#21035;&#23398;&#20064;&#27599;&#20010;&#26234;&#33021;&#20307;&#65292;&#24182;&#23454;&#29616;&#31574;&#30053;&#25913;&#36827;&#21644;&#20215;&#20540;&#35780;&#20215;&#12290;</title><link>http://arxiv.org/abs/2004.11145</link><description>&lt;p&gt;
F2A2: &#28789;&#27963;&#23436;&#20840;&#21435;&#20013;&#24515;&#21270;&#30340;&#21512;&#20316;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#30340;&#36817;&#20284;&#28436;&#21592;-&#35780;&#35770;&#23478;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
F2A2: Flexible Fully-decentralized Approximate Actor-critic for Cooperative Multi-agent Reinforcement Learning. (arXiv:2004.11145v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2004.11145
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#28789;&#27963;&#23436;&#20840;&#20998;&#25955;&#21270;&#30340;&#28436;&#21592;-&#35780;&#35770;&#23478;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#22312;&#22823;&#35268;&#27169;&#21512;&#20316;&#22810;&#26234;&#33021;&#20307;&#29615;&#22659;&#20013;&#65292;&#36890;&#36807;&#35774;&#35745;&#19968;&#20010;&#22522;&#20110;&#21407;&#22987;-&#23545;&#20598;&#28151;&#21512;&#26799;&#24230;&#19979;&#38477;&#30340;&#31639;&#27861;&#26694;&#26550;&#65292;&#21487;&#20197;&#20998;&#21035;&#23398;&#20064;&#27599;&#20010;&#26234;&#33021;&#20307;&#65292;&#24182;&#23454;&#29616;&#31574;&#30053;&#25913;&#36827;&#21644;&#20215;&#20540;&#35780;&#20215;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#30340;&#20013;&#22830;&#38598;&#26435;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#22312;&#22797;&#26434;&#24212;&#29992;&#20013;&#26377;&#26102;&#19981;&#23454;&#29992;&#65292;&#22240;&#20026;&#26234;&#33021;&#20307;&#20043;&#38388;&#32570;&#20047;&#20114;&#21160;&#65292;&#23384;&#22312;&#32500;&#24230;&#28798;&#38590;&#21644;&#35745;&#31639;&#22797;&#26434;&#24615;&#12290;&#22240;&#27492;&#65292;&#20986;&#29616;&#20102;&#19968;&#20123;&#20998;&#25955;&#21270;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#20998;&#25955;&#21270;&#26041;&#27861;&#21482;&#33021;&#22788;&#29702;&#23436;&#20840;&#21512;&#20316;&#30340;&#35774;&#32622;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#38656;&#35201;&#20256;&#36755;&#22823;&#37327;&#20449;&#24687;&#12290;&#20256;&#32479;&#30340;&#22359;&#22352;&#26631;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#21487;&#20197;&#31616;&#21270;&#35745;&#31639;&#65292;&#20294;&#20250;&#24341;&#36215;&#20005;&#37325;&#30340;&#20559;&#24046;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#28789;&#27963;&#30340;&#23436;&#20840;&#20998;&#25955;&#21270;&#30340;&#28436;&#21592;-&#35780;&#35770;&#23478;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#21487;&#20197;&#32452;&#21512;&#22823;&#22810;&#25968;&#28436;&#21592;-&#35780;&#35770;&#23478;&#26041;&#27861;&#65292;&#24182;&#22788;&#29702;&#22823;&#35268;&#27169;&#19968;&#33324;&#21512;&#20316;&#22810;&#26234;&#33021;&#20307;&#29615;&#22659;&#12290;&#35774;&#35745;&#20102;&#19968;&#31181;&#22522;&#20110;&#21407;&#22987;-&#23545;&#20598;&#28151;&#21512;&#26799;&#24230;&#19979;&#38477;&#30340;&#31639;&#27861;&#26694;&#26550;&#65292;&#20998;&#21035;&#23398;&#20064;&#27599;&#20010;&#26234;&#33021;&#20307;&#26469;&#23454;&#29616;&#20998;&#25955;&#21270;&#12290;&#20174;&#27599;&#20010;&#26234;&#33021;&#20307;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#23454;&#29616;&#20102;&#31574;&#30053;&#25913;&#36827;&#21644;&#20215;&#20540;&#35780;&#20215;&#12290;
&lt;/p&gt;
&lt;p&gt;
Traditional centralized multi-agent reinforcement learning (MARL) algorithms are sometimes unpractical in complicated applications, due to non-interactivity between agents, curse of dimensionality and computation complexity. Hence, several decentralized MARL algorithms are motivated. However, existing decentralized methods only handle the fully cooperative setting where massive information needs to be transmitted in training. The block coordinate gradient descent scheme they used for successive independent actor and critic steps can simplify the calculation, but it causes serious bias. In this paper, we propose a flexible fully decentralized actor-critic MARL framework, which can combine most of actor-critic methods, and handle large-scale general cooperative multi-agent setting. A primal-dual hybrid gradient descent type algorithm framework is designed to learn individual agents separately for decentralization. From the perspective of each agent, policy improvement and value evaluatio
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21407;&#21017; "&#21521;&#21518;&#29305;&#24449;&#20462;&#27491;"&#65292;&#36890;&#36807;&#35757;&#32451;&#36807;&#31243;&#20013;&#33258;&#21160;&#20462;&#27491;&#36739;&#20302;&#23618;&#27425;&#29305;&#24449;&#30340;&#38169;&#35823;&#65292;&#20351;&#24471;&#28145;&#24230;&#23398;&#20064;&#33021;&#22815;&#36827;&#34892;&#28145;&#24230;&#65288;&#20998;&#23618;&#65289;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2001.04413</link><description>&lt;p&gt;
&#12298;&#21521;&#21518;&#29305;&#24449;&#20462;&#27491;&#65306;&#28145;&#24230;&#23398;&#20064;&#22914;&#20309;&#36827;&#34892;&#28145;&#24230;&#65288;&#20998;&#23618;&#65289;&#23398;&#20064;&#12299;
&lt;/p&gt;
&lt;p&gt;
Backward Feature Correction: How Deep Learning Performs Deep (Hierarchical) Learning. (arXiv:2001.04413v6 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2001.04413
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21407;&#21017; "&#21521;&#21518;&#29305;&#24449;&#20462;&#27491;"&#65292;&#36890;&#36807;&#35757;&#32451;&#36807;&#31243;&#20013;&#33258;&#21160;&#20462;&#27491;&#36739;&#20302;&#23618;&#27425;&#29305;&#24449;&#30340;&#38169;&#35823;&#65292;&#20351;&#24471;&#28145;&#24230;&#23398;&#20064;&#33021;&#22815;&#36827;&#34892;&#28145;&#24230;&#65288;&#20998;&#23618;&#65289;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#20063;&#34987;&#31216;&#20026;&#20998;&#23618;&#23398;&#20064;&#65292;&#23398;&#20064;&#32773;&#36890;&#36807;&#23558;&#22797;&#26434;&#30340;&#30446;&#26631;&#20989;&#25968;&#20998;&#35299;&#20026;&#19968;&#31995;&#21015;&#26356;&#31616;&#21333;&#30340;&#20989;&#25968;&#26469;&#38477;&#20302;&#26679;&#26412;&#21644;&#26102;&#38388;&#22797;&#26434;&#24230;&#12290;&#26412;&#25991;&#36890;&#36807;&#23545;&#35757;&#32451;&#30446;&#26631;&#36827;&#34892;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65292;&#20174;&#29702;&#35770;&#19978;&#20998;&#26512;&#20102;&#22810;&#23618;&#31070;&#32463;&#32593;&#32476;&#22914;&#20309;&#26377;&#25928;&#21644;&#33258;&#21160;&#22320;&#36827;&#34892;&#36825;&#31181;&#20998;&#23618;&#23398;&#20064;&#12290;&#22312;&#27010;&#24565;&#19978;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29702;&#35770;&#29305;&#24449;&#65292;&#21363;&#26576;&#20123;&#31867;&#22411;&#30340;&#28145;&#24230;&#65288;&#21363;&#36229;&#24120;&#23618;&#65289;&#31070;&#32463;&#32593;&#32476;&#22312;&#26576;&#20123;&#20998;&#23618;&#20219;&#21153;&#19978;&#20173;&#28982;&#21487;&#20197;&#20197;&#39640;&#25928;&#29575;&#30340;&#26679;&#26412;&#21644;&#26102;&#38388;&#36827;&#34892;&#35757;&#32451;&#65292;&#32780;&#29616;&#26377;&#30340;&#31639;&#27861;&#65288;&#21253;&#25324;&#36880;&#23618;&#35757;&#32451;&#12289;&#26680;&#26041;&#27861;&#31561;&#65289;&#22343;&#26080;&#27861;&#39640;&#25928;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#21521;&#21518;&#29305;&#24449;&#20462;&#27491;&#8221;&#30340;&#26032;&#21407;&#21017;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#65292;&#36739;&#20302;&#23618;&#27425;&#29305;&#24449;&#30340;&#38169;&#35823;&#21487;&#20197;&#33258;&#21160;&#20462;&#27491;&#12290;&#25105;&#20204;&#35748;&#20026;&#36825;&#26159;&#28145;&#24230;&#23398;&#20064;&#22914;&#20309;&#36827;&#34892;&#28145;&#24230;&#65288;&#20998;&#23618;&#65289;&#23398;&#20064;&#30340;&#20851;&#38190;&#25152;&#22312;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning is also known as hierarchical learning, where the learner _learns_ to represent a complicated target function by decomposing it into a sequence of simpler functions to reduce sample and time complexity. This paper formally analyzes how multi-layer neural networks can perform such hierarchical learning _efficiently_ and _automatically_ by SGD on the training objective.  On the conceptual side, we present a theoretical characterizations of how certain types of deep (i.e. super-constant layer) neural networks can still be sample and time efficiently trained on some hierarchical tasks, when no existing algorithm (including layerwise training, kernel method, etc) is known to be efficient. We establish a new principle called "backward feature correction", where the errors in the lower-level features can be automatically corrected when training together with the higher-level layers. We believe this is a key behind how deep learning is performing deep (hierarchical) learning, as 
&lt;/p&gt;</description></item></channel></rss>