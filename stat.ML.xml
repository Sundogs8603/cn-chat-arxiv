<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#20174;&#29702;&#35770;&#23618;&#38754;&#25506;&#31350;&#20102;&#24102;&#26377;&#8220;&#24605;&#32500;&#38142;&#8221;&#25552;&#31034;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#35299;&#20915;&#22522;&#26412;&#25968;&#23398;&#21644;&#20915;&#31574;&#38382;&#39064;&#20013;&#30340;&#33021;&#21147;&#65292;&#21457;&#29616;&#33258;&#22238;&#24402;Transformer&#22823;&#23567;&#24658;&#23450;&#21363;&#21487;&#35299;&#20915;&#20219;&#21153;&#65292;&#25581;&#31034;&#20102;&#8220;&#24605;&#32500;&#38142;&#8221;&#25552;&#31034;&#30340;&#32972;&#21518;&#26426;&#21046;&#12290;</title><link>http://arxiv.org/abs/2305.15408</link><description>&lt;p&gt;
&#20174;&#29702;&#35770;&#35282;&#24230;&#25581;&#31034;&#8220;&#24605;&#32500;&#38142;&#8221;&#32972;&#21518;&#30340;&#22885;&#31192;
&lt;/p&gt;
&lt;p&gt;
Towards Revealing the Mystery behind Chain of Thought: a Theoretical Perspective. (arXiv:2305.15408v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15408
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#29702;&#35770;&#23618;&#38754;&#25506;&#31350;&#20102;&#24102;&#26377;&#8220;&#24605;&#32500;&#38142;&#8221;&#25552;&#31034;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#35299;&#20915;&#22522;&#26412;&#25968;&#23398;&#21644;&#20915;&#31574;&#38382;&#39064;&#20013;&#30340;&#33021;&#21147;&#65292;&#21457;&#29616;&#33258;&#22238;&#24402;Transformer&#22823;&#23567;&#24658;&#23450;&#21363;&#21487;&#35299;&#20915;&#20219;&#21153;&#65292;&#25581;&#31034;&#20102;&#8220;&#24605;&#32500;&#38142;&#8221;&#25552;&#31034;&#30340;&#32972;&#21518;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;"&#24605;&#32500;&#38142;"&#25552;&#31034;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#24615;&#33021;&#65292;&#29305;&#21035;&#26159;&#22312;&#28041;&#21450;&#25968;&#23398;&#25110;&#25512;&#29702;&#30340;&#22797;&#26434;&#20219;&#21153;&#20013;&#12290;&#23613;&#31649;&#33719;&#24471;&#20102;&#24040;&#22823;&#30340;&#23454;&#35777;&#25104;&#21151;&#65292;&#20294;&#8220;&#24605;&#32500;&#38142;&#8221;&#32972;&#21518;&#30340;&#26426;&#21046;&#20197;&#21450;&#23427;&#22914;&#20309;&#37322;&#25918;LLMs&#30340;&#28508;&#21147;&#20173;&#28982;&#26159;&#31070;&#31192;&#30340;&#12290;&#26412;&#25991;&#39318;&#27425;&#20174;&#29702;&#35770;&#19978;&#22238;&#31572;&#20102;&#36825;&#20123;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;LLMs&#24102;&#26377;&#8220;&#24605;&#32500;&#38142;&#8221;&#22312;&#35299;&#20915;&#22522;&#26412;&#25968;&#23398;&#21644;&#20915;&#31574;&#38382;&#39064;&#20013;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#39318;&#20808;&#32473;&#20986;&#19968;&#20010;&#19981;&#21487;&#33021;&#30340;&#32467;&#26524;&#65292;&#34920;&#26126;&#20219;&#20309;&#26377;&#38480;&#28145;&#24230;&#30340;Transformer&#37117;&#19981;&#33021;&#30452;&#25509;&#36755;&#20986;&#27491;&#30830;&#30340;&#22522;&#26412;&#31639;&#26415;/&#26041;&#31243;&#20219;&#21153;&#30340;&#31572;&#26696;&#65292;&#38500;&#38750;&#27169;&#22411;&#22823;&#23567;&#38543;&#30528;&#36755;&#20837;&#38271;&#24230;&#30340;&#22686;&#21152;&#21576;&#36229;&#22810;&#39033;&#24335;&#22686;&#38271;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#36890;&#36807;&#26500;&#36896;&#35777;&#26126;&#65292;&#22823;&#23567;&#24658;&#23450;&#30340;&#33258;&#22238;&#24402;Transformer&#36275;&#20197;&#36890;&#36807;&#20351;&#29992;&#24120;&#29992;&#30340;&#25968;&#23398;&#35821;&#35328;&#24418;&#24335;&#29983;&#25104;&#8220;&#24605;&#32500;&#38142;&#8221;&#25512;&#23548;&#26469;&#35299;&#20915;&#36825;&#20004;&#20010;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent studies have discovered that Chain-of-Thought prompting (CoT) can dramatically improve the performance of Large Language Models (LLMs), particularly when dealing with complex tasks involving mathematics or reasoning. Despite the enormous empirical success, the underlying mechanisms behind CoT and how it unlocks the potential of LLMs remain elusive. In this paper, we take a first step towards theoretically answering these questions. Specifically, we examine the capacity of LLMs with CoT in solving fundamental mathematical and decision-making problems. We start by giving an impossibility result showing that any bounded-depth Transformer cannot directly output correct answers for basic arithmetic/equation tasks unless the model size grows super-polynomially with respect to the input length. In contrast, we then prove by construction that autoregressive Transformers of a constant size suffice to solve both tasks by generating CoT derivations using a commonly-used math language forma
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23545;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#65288;BBVI&#65289;&#30340;&#20998;&#26512;&#65292;&#21457;&#29616;&#19968;&#20123;&#24120;&#35265;&#30340;&#31639;&#27861;&#35774;&#35745;&#36873;&#25321;&#21487;&#33021;&#20250;&#23548;&#33268;&#27425;&#20248;&#25910;&#25947;&#36895;&#29575;&#65292;&#20294;&#20351;&#29992;&#24102;&#26377;&#36817;&#31471;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;BBVI&#21487;&#20197;&#23454;&#29616;&#26368;&#24378;&#25910;&#25947;&#29575;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2305.15349</link><description>&lt;p&gt;
&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#25910;&#25947;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Black-Box Variational Inference Converges. (arXiv:2305.15349v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15349
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#65288;BBVI&#65289;&#30340;&#20998;&#26512;&#65292;&#21457;&#29616;&#19968;&#20123;&#24120;&#35265;&#30340;&#31639;&#27861;&#35774;&#35745;&#36873;&#25321;&#21487;&#33021;&#20250;&#23548;&#33268;&#27425;&#20248;&#25910;&#25947;&#36895;&#29575;&#65292;&#20294;&#20351;&#29992;&#24102;&#26377;&#36817;&#31471;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;BBVI&#21487;&#20197;&#23454;&#29616;&#26368;&#24378;&#25910;&#25947;&#29575;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#23436;&#25972;&#30340;&#40657;&#30418;&#21464;&#20998;&#25512;&#26029;&#65288;BBVI&#65289;&#30340;&#25910;&#25947;&#20445;&#35777;&#65292;&#20063;&#31216;&#20026;&#33945;&#29305;&#21345;&#32599;&#21464;&#20998;&#25512;&#26029;&#12290;&#23613;&#31649;&#26089;&#26399;&#30340;&#30740;&#31350;&#21482;&#38024;&#23545;&#31616;&#21270;&#29256;&#26412;&#30340;BBVI&#36827;&#34892;&#20102;&#30740;&#31350;&#65288;&#20363;&#22914;&#65292;&#26377;&#30028;&#22495;&#12289;&#26377;&#30028;&#25903;&#25345;&#12289;&#20165;&#38024;&#23545;&#23610;&#24230;&#36827;&#34892;&#20248;&#21270;&#31561;&#65289;&#65292;&#20294;&#25105;&#20204;&#30340;&#35774;&#32622;&#19981;&#38656;&#35201;&#20219;&#20309;&#36825;&#26679;&#30340;&#31639;&#27861;&#20462;&#25913;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#36866;&#29992;&#20110;&#23545;&#25968;&#24179;&#28369;&#21518;&#39564;&#23494;&#24230;&#65292;&#26080;&#35770;&#26159;&#21542;&#24378;&#23545;&#25968;&#20985;&#24615;&#20197;&#21450;&#20301;&#32622;-&#23610;&#24230;&#21464;&#20998;&#26063;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#25581;&#31034;&#20986;&#20102;&#19968;&#20123;&#24120;&#35265;&#30340;&#31639;&#27861;&#35774;&#35745;&#36873;&#25321;&#65292;&#29305;&#21035;&#26159;&#21464;&#20998;&#36817;&#20284;&#23610;&#24230;&#30340;&#38750;&#32447;&#24615;&#21442;&#25968;&#21270;&#65292;&#21487;&#33021;&#20250;&#23548;&#33268;&#27425;&#20248;&#25910;&#25947;&#36895;&#29575;&#12290;&#24184;&#36816;&#30340;&#26159;&#65292;&#36816;&#34892;&#24102;&#26377;&#36817;&#31471;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;BBVI&#21487;&#20197;&#32416;&#27491;&#36825;&#20123;&#38480;&#21046;&#65292;&#20174;&#32780;&#23454;&#29616;&#24050;&#30693;&#30340;&#26368;&#24378;&#25910;&#25947;&#29575;&#20445;&#35777;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#36817;&#31471;SGD&#19982;&#20854;&#20182;&#26631;&#20934;&#30340;BBVI&#23454;&#29616;&#36827;&#34892;&#27604;&#36739;&#65292;&#39564;&#35777;&#20102;&#36825;&#19968;&#29702;&#35770;&#32467;&#35770;&#22312;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We provide the first convergence guarantee for full black-box variational inference (BBVI), also known as Monte Carlo variational inference. While preliminary investigations worked on simplified versions of BBVI (e.g., bounded domain, bounded support, only optimizing for the scale, and such), our setup does not need any such algorithmic modifications. Our results hold for log-smooth posterior densities with and without strong log-concavity and the location-scale variational family. Also, our analysis reveals that certain algorithm design choices commonly employed in practice, particularly, nonlinear parameterizations of the scale of the variational approximation, can result in suboptimal convergence rates. Fortunately, running BBVI with proximal stochastic gradient descent fixes these limitations, and thus achieves the strongest known convergence rate guarantees. We evaluate this theoretical insight by comparing proximal SGD against other standard implementations of BBVI on large-scale
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#26631;&#20934;&#65292;&#21363;MADD&#65292;&#21487;&#20197;&#29420;&#31435;&#20110;&#39044;&#27979;&#24615;&#33021;&#20998;&#26512;&#27169;&#22411;&#30340;&#27495;&#35270;&#34892;&#20026;&#12290;&#30740;&#31350;&#32773;&#36824;&#25552;&#20379;&#20102;&#21487;&#35270;&#21270;&#20998;&#26512;&#30340;&#34917;&#20805;&#26469;&#24110;&#21161;&#36827;&#34892;&#20154;&#31867;&#35780;&#20272;&#12290;</title><link>http://arxiv.org/abs/2305.15342</link><description>&lt;p&gt;
&#20320;&#30340;&#27169;&#22411;&#8220;MADD&#8221;&#20102;&#21527;&#65311;&#19968;&#31181;&#29992;&#20110;&#35780;&#20272;&#39044;&#27979;&#24615;&#23398;&#29983;&#27169;&#22411;&#31639;&#27861;&#20844;&#24179;&#24615;&#30340;&#26032;&#25351;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
Is Your Model "MADD"? A Novel Metric to Evaluate Algorithmic Fairness for Predictive Student Models. (arXiv:2305.15342v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15342
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#26631;&#20934;&#65292;&#21363;MADD&#65292;&#21487;&#20197;&#29420;&#31435;&#20110;&#39044;&#27979;&#24615;&#33021;&#20998;&#26512;&#27169;&#22411;&#30340;&#27495;&#35270;&#34892;&#20026;&#12290;&#30740;&#31350;&#32773;&#36824;&#25552;&#20379;&#20102;&#21487;&#35270;&#21270;&#20998;&#26512;&#30340;&#34917;&#20805;&#26469;&#24110;&#21161;&#36827;&#34892;&#20154;&#31867;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#20854;&#22686;&#24378;&#25945;&#32946;&#25104;&#26524;&#21644;&#25903;&#25345;&#21033;&#30410;&#30456;&#20851;&#32773;&#20570;&#20986;&#26126;&#26234;&#20915;&#31574;&#30340;&#33021;&#21147;&#65292;&#39044;&#27979;&#24615;&#23398;&#29983;&#27169;&#22411;&#22312;&#23398;&#20064;&#29615;&#22659;&#20013;&#36234;&#26469;&#36234;&#26222;&#36941;&#12290;&#28982;&#32780;&#65292;&#39044;&#27979;&#27169;&#22411;&#21487;&#33021;&#23384;&#22312;&#20559;&#35265;&#65292;&#23548;&#33268;&#23545;&#26576;&#20123;&#23398;&#29983;&#30340;&#28508;&#22312;&#27495;&#35270;&#21644;&#21487;&#33021;&#30340;&#26377;&#23475;&#38271;&#26399;&#24433;&#21709;&#12290;&#36825;&#20419;&#20351;&#20102;&#23545;&#20844;&#24179;&#24615;&#24230;&#37327;&#26631;&#20934;&#30340;&#30740;&#31350;&#65292;&#26088;&#22312;&#25429;&#25417;&#21644;&#37327;&#21270;&#27492;&#31867;&#20559;&#35265;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#30446;&#21069;&#22312;&#25945;&#32946;&#39046;&#22495;&#20351;&#29992;&#30340;&#29616;&#26377;&#20844;&#24179;&#24230;&#37327;&#26631;&#20934;&#26159;&#38754;&#21521;&#39044;&#27979;&#24615;&#33021;&#30340;&#65292;&#37325;&#28857;&#26159;&#35780;&#20272;&#32452;&#38388;&#23384;&#22312;&#30340;&#26377;&#20559;&#32467;&#26524;&#65292;&#32780;&#19981;&#32771;&#34385;&#27169;&#22411;&#30340;&#34892;&#20026;&#20197;&#21450;&#32467;&#26524;&#20013;&#30340;&#20559;&#35265;&#31243;&#24230;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#24230;&#37327;&#26631;&#20934;&#65292;&#21363;&#8220;&#27169;&#22411;&#32477;&#23545;&#23494;&#24230;&#36317;&#31163;&#8221;&#65288;MADD&#65289;&#65292;&#20197;&#20998;&#26512;&#27169;&#22411;&#30340;&#27495;&#35270;&#34892;&#20026;&#65292;&#29420;&#31435;&#20110;&#20854;&#39044;&#27979;&#24615;&#33021;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#22522;&#20110;&#21487;&#35270;&#21270;&#20998;&#26512;&#30340;&#34917;&#20805;&#65292;&#20197;&#23454;&#29616;&#23545;&#27169;&#22411;&#34892;&#20026;&#30340;&#32454;&#31890;&#24230;&#20154;&#31867;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Predictive student models are increasingly used in learning environments due to their ability to enhance educational outcomes and support stakeholders in making informed decisions. However, predictive models can be biased and produce unfair outcomes, leading to potential discrimination against some students and possible harmful long-term implications. This has prompted research on fairness metrics meant to capture and quantify such biases. Nonetheless, so far, existing fairness metrics used in education are predictive performance-oriented, focusing on assessing biased outcomes across groups of students, without considering the behaviors of the models nor the severity of the biases in the outcomes. Therefore, we propose a novel metric, the Model Absolute Density Distance (MADD), to analyze models' discriminatory behaviors independently from their predictive performance. We also provide a complementary visualization-based analysis to enable fine-grained human assessment of how the models
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#21487;&#24494;&#20998;Agent-Based Model&#30340;&#36125;&#21494;&#26031;&#26657;&#20934;&#26041;&#27861;&#65292;&#21487;&#20197;&#25552;&#20379;&#40065;&#26834;&#24615;&#30340;&#21442;&#25968;&#25512;&#26029;&#12290;&#36890;&#36807;COVID-19&#22823;&#27969;&#34892;&#30340;&#21487;&#24494;&#20998;Agent-Based Model&#23454;&#39564;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.15340</link><description>&lt;p&gt;
&#21487;&#24494;&#20998;Agent-Based Model&#30340;&#36125;&#21494;&#26031;&#26657;&#20934;
&lt;/p&gt;
&lt;p&gt;
Bayesian calibration of differentiable agent-based models. (arXiv:2305.15340v1 [cs.MA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15340
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#21487;&#24494;&#20998;Agent-Based Model&#30340;&#36125;&#21494;&#26031;&#26657;&#20934;&#26041;&#27861;&#65292;&#21487;&#20197;&#25552;&#20379;&#40065;&#26834;&#24615;&#30340;&#21442;&#25968;&#25512;&#26029;&#12290;&#36890;&#36807;COVID-19&#22823;&#27969;&#34892;&#30340;&#21487;&#24494;&#20998;Agent-Based Model&#23454;&#39564;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Agent-Based Model&#26159;&#19968;&#31181;&#24378;&#22823;&#32780;&#30452;&#35266;&#30340;&#22797;&#26434;&#31995;&#32479;&#24314;&#27169;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#30340;&#20284;&#28982;&#20989;&#25968;&#38590;&#20197;&#35745;&#31639;&#65292;&#20854;&#20013;&#30340;&#25968;&#23398;&#36816;&#31639;&#20063;&#19981;&#21487;&#24494;&#20998;&#65292;&#36825;&#26412;&#36136;&#19978;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#20351;&#29992;&#12290;&#20026;&#27492;&#65292;&#20154;&#20204;&#25552;&#20986;&#20102;&#36924;&#36817;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#21644;&#26500;&#24314;&#21487;&#24494;&#20998;&#36924;&#36817;&#20219;&#24847;Agent-Based Model&#30340;&#30740;&#31350;&#65292;&#20294;&#23545;&#20110;&#21487;&#24494;&#20998;Agent-Based Model&#30340;&#36817;&#20284;&#36125;&#21494;&#26031;&#25512;&#26029;&#25216;&#26415;&#30340;&#35774;&#35745;&#21364;&#40092;&#26377;&#30740;&#31350;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#35752;&#35770;&#22914;&#20309;&#37319;&#29992;&#24191;&#20041;&#21464;&#20998;&#25512;&#26029;&#31243;&#24207;&#26469;&#25552;&#20379;&#23545;&#21487;&#24494;&#20998;Agent-Based Model&#36827;&#34892;&#40065;&#26834;&#24615;&#36125;&#21494;&#26031;&#21442;&#25968;&#25512;&#26029;&#12290;&#25105;&#20204;&#20197;COVID-19&#22823;&#27969;&#34892;&#30340;&#21487;&#24494;&#20998;Agent-Based Model&#20026;&#20363;&#36827;&#34892;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#24471;&#20986;&#20934;&#30830;&#30340;&#25512;&#26029;&#65292;&#24182;&#35752;&#35770;&#20102;&#26410;&#26469;&#24037;&#20316;&#30340;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
Agent-based modelling (ABMing) is a powerful and intuitive approach to modelling complex systems; however, the intractability of ABMs' likelihood functions and the non-differentiability of the mathematical operations comprising these models present a challenge to their use in the real world. These difficulties have in turn generated research on approximate Bayesian inference methods for ABMs and on constructing differentiable approximations to arbitrary ABMs, but little work has been directed towards designing approximate Bayesian inference techniques for the specific case of differentiable ABMs. In this work, we aim to address this gap and discuss how generalised variational inference procedures may be employed to provide misspecification-robust Bayesian parameter inferences for differentiable ABMs. We demonstrate with experiments on a differentiable ABM of the COVID-19 pandemic that our approach can result in accurate inferences, and discuss avenues for future work.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#21518;&#22788;&#29702;&#33021;&#35265;&#24230;&#38598;&#21512;&#39044;&#27979;&#30340;&#19981;&#21516;&#26041;&#27861;&#65292;&#21457;&#29616;&#38750;&#21442;&#25968;&#23494;&#24230;&#20272;&#35745;&#21644;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#26041;&#27861;&#34920;&#29616;&#33391;&#22909;&#65292;&#24182;&#19988;&#21487;&#20197;&#26174;&#30528;&#25552;&#39640;&#38598;&#21512;&#39044;&#27979;&#30340;&#25216;&#33021;&#21644;&#21487;&#38752;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.15325</link><description>&lt;p&gt;
&#33021;&#35265;&#24230;&#38598;&#21512;&#39044;&#27979;&#30340;&#32479;&#35745;&#21518;&#22788;&#29702;
&lt;/p&gt;
&lt;p&gt;
Statistical post-processing of visibility ensemble forecasts. (arXiv:2305.15325v1 [stat.AP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15325
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#21518;&#22788;&#29702;&#33021;&#35265;&#24230;&#38598;&#21512;&#39044;&#27979;&#30340;&#19981;&#21516;&#26041;&#27861;&#65292;&#21457;&#29616;&#38750;&#21442;&#25968;&#23494;&#24230;&#20272;&#35745;&#21644;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#26041;&#27861;&#34920;&#29616;&#33391;&#22909;&#65292;&#24182;&#19988;&#21487;&#20197;&#26174;&#30528;&#25552;&#39640;&#38598;&#21512;&#39044;&#27979;&#30340;&#25216;&#33021;&#21644;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33021;&#22815;&#20934;&#30830;&#21487;&#38752;&#22320;&#39044;&#27979;&#33021;&#35265;&#24230;&#23545;&#20110;&#39134;&#34892;&#27668;&#35937;&#65292;&#27700;&#36335;&#21644;&#36947;&#36335;&#36816;&#36755;&#20855;&#26377;&#33267;&#20851;&#37325;&#35201;&#30340;&#24847;&#20041;&#12290;&#29616;&#20170;&#65292;&#19968;&#20123;&#27668;&#35937;&#26381;&#21153;&#25552;&#20379;&#33021;&#35265;&#24230;&#30340;&#38598;&#21512;&#39044;&#27979;; &#28982;&#32780;&#65292;&#30456;&#27604;&#20110;&#20854;&#20182;&#21464;&#37327;&#65288;&#22914;&#28201;&#24230;&#25110;&#39118;&#36895;&#65289;&#65292;&#33021;&#35265;&#24230;&#39044;&#27979;&#30340;&#25216;&#33021;&#21644;&#21487;&#38752;&#24615;&#38477;&#20302;&#24456;&#22810;&#12290;&#22240;&#27492;&#65292;&#24378;&#28872;&#24314;&#35758;&#37319;&#29992;&#26576;&#31181;&#24418;&#24335;&#30340;&#26657;&#20934;&#65292;&#36890;&#24120;&#24847;&#21619;&#30528;&#36890;&#36807;&#21442;&#25968;&#25110;&#38750;&#21442;&#25968;&#26041;&#27861;&#65288;&#21253;&#25324;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#25216;&#26415;&#65289;&#20272;&#35745;&#25152;&#28041;&#21450;&#30340;&#22825;&#27668;&#25968;&#37327;&#30340;&#39044;&#27979;&#20998;&#24067;&#12290;&#30001;&#20110;&#26681;&#25454;&#19990;&#30028;&#27668;&#35937;&#32452;&#32455;&#30340;&#24314;&#35758;&#65292;&#36890;&#24120;&#20197;&#31163;&#25955;&#20540;&#25253;&#21578;&#33021;&#35265;&#24230;&#35266;&#27979;&#20540;&#65292;&#22240;&#27492;&#35813;&#29305;&#23450;&#21464;&#37327;&#30340;&#39044;&#27979;&#20998;&#24067;&#26159;&#31163;&#25955;&#27010;&#29575;&#20998;&#24067;&#65292;&#22240;&#27492;&#26657;&#20934;&#21487;&#20197;&#31616;&#21270;&#20026;&#20998;&#31867;&#38382;&#39064;&#12290;&#22522;&#20110;&#27431;&#27954;&#20013;&#26399;&#22825;&#27668;&#39044;&#25253;&#20013;&#24515;&#30340;&#33021;&#35265;&#24230;&#38598;&#21512;&#39044;&#27979;&#65288;ECMWF&#65289;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19981;&#21516;&#30340;&#26041;&#27861;&#29992;&#20110;&#21518;&#22788;&#29702;&#33021;&#35265;&#24230;&#27010;&#29575;&#39044;&#27979;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#34920;&#26126;&#65292;&#38750;&#21442;&#25968;&#23494;&#24230;&#20272;&#35745;&#21644;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#26041;&#27861;&#34920;&#29616;&#33391;&#22909;&#65292;&#24182;&#19988;&#21487;&#20197;&#26174;&#30528;&#25552;&#39640;&#38598;&#21512;&#39044;&#27979;&#30340;&#25216;&#33021;&#21644;&#21487;&#38752;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
To be able to produce accurate and reliable predictions of visibility has crucial importance in aviation meteorology, as well as in water- and road transportation. Nowadays, several meteorological services provide ensemble forecasts of visibility; however, the skill, and reliability of visibility predictions are far reduced compared to other variables, such as temperature or wind speed. Hence, some form of calibration is strongly advised, which usually means estimation of the predictive distribution of the weather quantity at hand either by parametric or non-parametric approaches, including also machine learning-based techniques. As visibility observations - according to the suggestion of the World Meteorological Organization - are usually reported in discrete values, the predictive distribution for this particular variable is a discrete probability law, hence calibration can be reduced to a classification problem. Based on visibility ensemble forecasts of the European Centre for Mediu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#32447;&#24615;&#22238;&#24402;&#28151;&#21512;&#27169;&#22411;&#30340;&#40065;&#26834;&#23398;&#20064;&#31639;&#27861;&#65292;&#30456;&#27604;&#20197;&#21069;&#30340;&#32467;&#26524;&#20855;&#26377;&#26356;&#22909;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.15317</link><description>&lt;p&gt;
&#20851;&#20110;&#32447;&#24615;&#22238;&#24402;&#28151;&#21512;&#27169;&#22411;&#30340;&#40065;&#26834;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
On the robust learning mixtures of linear regressions. (arXiv:2305.15317v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15317
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#32447;&#24615;&#22238;&#24402;&#28151;&#21512;&#27169;&#22411;&#30340;&#40065;&#26834;&#23398;&#20064;&#31639;&#27861;&#65292;&#30456;&#27604;&#20197;&#21069;&#30340;&#32467;&#26524;&#20855;&#26377;&#26356;&#22909;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#40065;&#26834;&#23398;&#20064;&#32447;&#24615;&#22238;&#24402;&#28151;&#21512;&#27169;&#22411;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#23558;&#32447;&#24615;&#22238;&#24402;&#21644;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#36890;&#36807;&#31616;&#21333;&#30340;&#38408;&#20540;&#36830;&#25509;&#36215;&#26469;&#65292;&#22240;&#27492;&#22312;&#26576;&#20123;&#28201;&#21644;&#30340;&#20998;&#31163;&#26465;&#20214;&#19979;&#21487;&#20197;&#33719;&#24471;&#20934;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#12290;&#19982;&#20197;&#21069;&#30340;&#32467;&#26524;&#30456;&#27604;&#65292;&#35813;&#31639;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this note, we consider the problem of robust learning mixtures of linear regressions. We connect mixtures of linear regressions and mixtures of Gaussians with a simple thresholding, so that a quasi-polynomial time algorithm can be obtained under some mild separation condition. This algorithm has significantly better robustness than the previous result.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#30340;Sharpness-Aware Minimization&#31639;&#27861;&#22823;&#22823;&#25552;&#39640;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#32780;&#20854;&#20013;&#35268;&#33539;&#21270;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#65292;&#36890;&#36807;&#31283;&#23450;&#31639;&#27861;&#21644;&#20351;&#20854;&#28418;&#31227;&#27839;&#30528;&#19968;&#31995;&#21015;&#26497;&#23567;&#20540;&#25552;&#21319;&#24615;&#33021;&#65292;&#24182;&#20351;&#31639;&#27861;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.15287</link><description>&lt;p&gt;
&#35268;&#33539;&#21270;&#22312;Sharpness-Aware Minimization&#20013;&#30340;&#20851;&#38190;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
The Crucial Role of Normalization in Sharpness-Aware Minimization. (arXiv:2305.15287v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15287
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#30340;Sharpness-Aware Minimization&#31639;&#27861;&#22823;&#22823;&#25552;&#39640;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#32780;&#20854;&#20013;&#35268;&#33539;&#21270;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#65292;&#36890;&#36807;&#31283;&#23450;&#31639;&#27861;&#21644;&#20351;&#20854;&#28418;&#31227;&#27839;&#30528;&#19968;&#31995;&#21015;&#26497;&#23567;&#20540;&#25552;&#21319;&#24615;&#33021;&#65292;&#24182;&#20351;&#31639;&#27861;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Sharpness-Aware Minimization&#65288;SAM&#65289;&#26159;&#19968;&#31181;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#22120;&#65292;&#26497;&#22823;&#22320;&#25552;&#39640;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;SAM&#26356;&#26032;&#20013;&#35268;&#33539;&#21270;&#36825;&#19968;&#20851;&#38190;&#32452;&#20214;&#30340;&#20316;&#29992;&#65292;&#20174;&#29702;&#35770;&#21644;&#23454;&#39564;&#20004;&#26041;&#38754;&#20998;&#26512;&#20102;&#35268;&#33539;&#21270;&#22312;SAM&#20013;&#23545;&#20984;&#20989;&#25968;&#21644;&#38750;&#20984;&#20989;&#25968;&#30340;&#24433;&#21709;&#65292;&#25581;&#31034;&#20102;&#35268;&#33539;&#21270;&#21457;&#25381;&#30340;&#20004;&#20010;&#20851;&#38190;&#20316;&#29992;&#65306;i&#65289;&#23427;&#26377;&#21161;&#20110;&#31283;&#23450;&#31639;&#27861;&#65307;ii&#65289;&#23427;&#20351;&#31639;&#27861;&#33021;&#22815;&#27839;&#30528;&#19968;&#31995;&#21015;&#26497;&#23567;&#20540;&#65288;&#27969;&#24418;&#65289;&#28418;&#31227;&#65292;&#36825;&#26159;&#26368;&#36817;&#19968;&#20123;&#29702;&#35770;&#24037;&#20316;&#30830;&#23450;&#30340;&#24615;&#33021;&#25552;&#21319;&#20851;&#38190;&#24615;&#36136;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35748;&#20026;&#65292;&#36825;&#20004;&#20010;&#27491;&#24120;&#21270;&#30340;&#23646;&#24615;&#20351;SAM&#23545;&#36229;&#21442;&#25968;&#30340;&#36873;&#25321;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#35777;&#23454;&#20102;SAM&#30340;&#23454;&#29992;&#24615;&#12290;&#21508;&#31181;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sharpness-Aware Minimization (SAM) is a recently proposed gradient-based optimizer (Foret et al., ICLR 2021) that greatly improves the prediction performance of deep neural networks. Consequently, there has been a surge of interest in explaining its empirical success. We focus, in particular, on understanding the role played by normalization, a key component of the SAM updates. We theoretically and empirically study the effect of normalization in SAM for both convex and non-convex functions, revealing two key roles played by normalization: i) it helps in stabilizing the algorithm; and ii) it enables the algorithm to drift along a continuum (manifold) of minima -- a property identified by recent theoretical works that is the key to better performance. We further argue that these two properties of normalization make SAM robust against the choice of hyper-parameters, supporting the practicality of SAM. Our conclusions are backed by various experiments.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#22686;&#37327;&#23398;&#20064;&#26041;&#27861;&#65292;&#20165;&#38656;&#35201;&#36739;&#23569;&#30340;&#26679;&#26412;&#21363;&#21487;&#22312;&#36817;&#32447;&#24615;&#26102;&#38388;&#20869;&#20272;&#35745;&#31232;&#30095;&#22343;&#20540;&#65292;&#20811;&#26381;&#20102;&#29616;&#26377;&#20272;&#35745;&#22120;&#30340;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2305.15276</link><description>&lt;p&gt;
&#22686;&#37327;&#23398;&#20064;&#19979;&#30340;&#31232;&#30095;&#22343;&#20540;&#40065;&#26834;&#24615;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Robust Sparse Mean Estimation via Incremental Learning. (arXiv:2305.15276v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15276
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#22686;&#37327;&#23398;&#20064;&#26041;&#27861;&#65292;&#20165;&#38656;&#35201;&#36739;&#23569;&#30340;&#26679;&#26412;&#21363;&#21487;&#22312;&#36817;&#32447;&#24615;&#26102;&#38388;&#20869;&#20272;&#35745;&#31232;&#30095;&#22343;&#20540;&#65292;&#20811;&#26381;&#20102;&#29616;&#26377;&#20272;&#35745;&#22120;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31232;&#30095;&#22343;&#20540;&#30340;&#40065;&#26834;&#24615;&#20272;&#35745;&#38382;&#39064;&#65292;&#26088;&#22312;&#20272;&#35745;&#20174;&#37325;&#23614;&#20998;&#24067;&#20013;&#25277;&#21462;&#30340;&#37096;&#20998;&#25439;&#22351;&#26679;&#26412;&#30340;$k$-&#31232;&#30095;&#22343;&#20540;&#12290;&#29616;&#26377;&#20272;&#35745;&#22120;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#38754;&#20020;&#20004;&#20010;&#20851;&#38190;&#25361;&#25112;&#65306;&#39318;&#20808;&#65292;&#23427;&#20204;&#21463;&#21040;&#19968;&#20010;&#34987;&#25512;&#27979;&#30340;&#35745;&#31639;&#32479;&#35745;&#26435;&#34913;&#30340;&#38480;&#21046;&#65292;&#36825;&#24847;&#21619;&#30528;&#20219;&#20309;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#31639;&#27861;&#38656;&#35201;$\tilde\Omega(k^2)$&#20010;&#26679;&#26412;&#65292;&#32780;&#20854;&#22312;&#32479;&#35745;&#19978;&#26368;&#20248;&#30340;&#23545;&#24212;&#29289;&#21482;&#38656;&#35201;$\tilde O(k)$&#20010;&#26679;&#26412;&#12290;&#20854;&#27425;&#65292;&#29616;&#26377;&#30340;&#20272;&#35745;&#22120;&#35268;&#27169;&#38543;&#30528;&#29615;&#22659;&#30340;&#32500;&#24230;&#22686;&#21152;&#32780;&#24613;&#21095;&#19978;&#21319;&#65292;&#38590;&#20197;&#22312;&#23454;&#36341;&#20013;&#20351;&#29992;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#22343;&#20540;&#20272;&#35745;&#22120;&#65292;&#22312;&#36866;&#24230;&#30340;&#26465;&#20214;&#19979;&#20811;&#26381;&#20102;&#36825;&#20004;&#20010;&#25361;&#25112;&#65306;&#23427;&#22312;&#20960;&#20046;&#32447;&#24615;&#30340;&#26102;&#38388;&#21644;&#20869;&#23384;&#20013;&#36816;&#34892;&#65288;&#30456;&#23545;&#20110;&#29615;&#22659;&#32500;&#24230;&#65289;&#65292;&#21516;&#26102;&#21482;&#38656;&#35201;$\tilde O(k)$&#20010;&#26679;&#26412;&#26469;&#24674;&#22797;&#30495;&#23454;&#30340;&#22343;&#20540;&#12290;&#25105;&#20204;&#26041;&#27861;&#30340;&#26680;&#24515;&#26159;&#22686;&#37327;&#23398;&#20064;&#29616;&#35937;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#38750;&#20984;&#26694;&#26550;&#65292;&#23427;&#21487;&#20197;&#23558;&#22343;&#20540;&#20272;&#35745;&#38382;&#39064;&#36716;&#21270;&#20026;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#65292;&#24182;&#21033;&#29992;&#22522;&#20110;&#22686;&#37327;&#23398;&#20064;&#30340;&#31639;&#27861;&#22823;&#22823;&#25552;&#39640;&#20102;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study the problem of robust sparse mean estimation, where the goal is to estimate a $k$-sparse mean from a collection of partially corrupted samples drawn from a heavy-tailed distribution. Existing estimators face two critical challenges in this setting. First, they are limited by a conjectured computational-statistical tradeoff, implying that any computationally efficient algorithm needs $\tilde\Omega(k^2)$ samples, while its statistically-optimal counterpart only requires $\tilde O(k)$ samples. Second, the existing estimators fall short of practical use as they scale poorly with the ambient dimension. This paper presents a simple mean estimator that overcomes both challenges under moderate conditions: it runs in near-linear time and memory (both with respect to the ambient dimension) while requiring only $\tilde O(k)$ samples to recover the true mean. At the core of our method lies an incremental learning phenomenon: we introduce a simple nonconvex framework that ca
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#33021;&#37327;&#30340;&#24402;&#19968;&#21270;&#27969;&#27169;&#22411;&#65288;EBFlow&#65289;&#65292;&#36890;&#36807;&#24471;&#20998;&#21305;&#37197;&#30446;&#26631;&#20248;&#21270;&#20351;&#20854;&#35757;&#32451;&#26356;&#39640;&#25928;&#65292;&#21516;&#26102;&#24320;&#21457;&#19968;&#20123;&#25216;&#26415;&#22686;&#24378;EBFlow&#30340;&#35757;&#32451;&#31283;&#23450;&#24615;&#21644;&#23454;&#35777;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2305.15267</link><description>&lt;p&gt;
&#35757;&#32451;&#22522;&#20110;&#33021;&#37327;&#30340;&#24402;&#19968;&#21270;&#27969;&#27169;&#22411;&#30340;&#24471;&#20998;&#21305;&#37197;&#30446;&#26631;
&lt;/p&gt;
&lt;p&gt;
Training Energy-Based Normalizing Flow with Score-Matching Objectives. (arXiv:2305.15267v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15267
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#33021;&#37327;&#30340;&#24402;&#19968;&#21270;&#27969;&#27169;&#22411;&#65288;EBFlow&#65289;&#65292;&#36890;&#36807;&#24471;&#20998;&#21305;&#37197;&#30446;&#26631;&#20248;&#21270;&#20351;&#20854;&#35757;&#32451;&#26356;&#39640;&#25928;&#65292;&#21516;&#26102;&#24320;&#21457;&#19968;&#20123;&#25216;&#26415;&#22686;&#24378;EBFlow&#30340;&#35757;&#32451;&#31283;&#23450;&#24615;&#21644;&#23454;&#35777;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24314;&#31435;&#20102;&#27969;&#27169;&#22411;&#21644;&#33021;&#37327;&#27169;&#22411;&#21442;&#25968;&#21270;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#33021;&#37327;&#30340;&#24402;&#19968;&#21270;&#27969;&#24314;&#27169;&#26041;&#27861;&#65288;EBFlow&#65289;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#36807;&#24471;&#20998;&#21305;&#37197;&#30446;&#26631;&#20248;&#21270;EBFlow&#65292;&#21487;&#20197;&#23436;&#20840;&#36991;&#24320;&#32447;&#24615;&#21464;&#25442;&#30340;&#38597;&#21487;&#27604;&#34892;&#21015;&#24335;&#35745;&#31639;&#12290;&#36825;&#20351;&#24471;EBFlow&#22312;&#26500;&#24314;&#22522;&#20110;&#27969;&#30340;&#27169;&#22411;&#26102;&#20351;&#29992;&#20219;&#24847;&#32447;&#24615;&#23618;&#65292;&#32780;&#19981;&#20250;&#20351;&#27599;&#20010;&#35757;&#32451;&#36845;&#20195;&#30340;&#35745;&#31639;&#26102;&#38388;&#22797;&#26434;&#24230;&#20174;$\mathcal{O}(D^2L)$&#22686;&#21152;&#21040;$\mathcal{O}(D^3L)$&#65292;&#20854;&#20013;$L$&#20026;&#23618;&#25968;&#65292;$D$&#20026;&#36755;&#20837;&#32500;&#24230;&#12290;&#36825;&#20351;&#24471;EBFlow&#30340;&#35757;&#32451;&#27604;&#24120;&#29992;&#30340;&#26368;&#22823;&#20284;&#28982;&#35757;&#32451;&#26041;&#27861;&#26356;&#39640;&#25928;&#12290;&#38500;&#20102;&#20943;&#23569;&#36816;&#34892;&#26102;&#38388;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#22522;&#20110;&#20998;&#20540;&#21305;&#37197;&#26041;&#27861;&#30340;&#20998;&#26512;&#24320;&#21457;&#20102;&#19968;&#20123;&#25216;&#26415;&#65292;&#20197;&#22686;&#24378;EBFlow&#30340;&#35757;&#32451;&#31283;&#23450;&#24615;&#21644;&#23454;&#35777;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we establish a connection between the parameterization of flow-based and energy-based generative models, and present a new flow-based modeling approach called energy-based normalizing flow (EBFlow). We demonstrate that by optimizing EBFlow with score-matching objectives, the computation of Jacobian determinants for linear transformations can be entirely bypassed. This feature enables the use of arbitrary linear layers in the construction of flow-based models without increasing the computational time complexity of each training iteration from $\mathcal{O}(D^2L)$ to $\mathcal{O}(D^3L)$ for an $L$-layered model that accepts $D$-dimensional inputs. This makes the training of EBFlow more efficient than the commonly-adopted maximum likelihood training method. In addition to the reduction in runtime, we enhance the training stability and empirical performance of EBFlow through a number of techniques developed based on our analysis on the score-matching methods. The experimental
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#35823;&#24046;&#21453;&#39304;&#31639;&#27861;&#22312;&#20998;&#24067;&#24335;&#20248;&#21270;&#38382;&#39064;&#20013;&#24403;&#29305;&#24449;&#31232;&#23569;&#26102;&#26356;&#20026;&#20986;&#33394;&#12290;</title><link>http://arxiv.org/abs/2305.15264</link><description>&lt;p&gt;
&#24403;&#29305;&#24449;&#31232;&#23569;&#26102;&#65292;&#35823;&#24046;&#21453;&#39304;&#26356;&#20026;&#20986;&#33394;
&lt;/p&gt;
&lt;p&gt;
Error Feedback Shines when Features are Rare. (arXiv:2305.15264v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15264
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#35823;&#24046;&#21453;&#39304;&#31639;&#27861;&#22312;&#20998;&#24067;&#24335;&#20248;&#21270;&#38382;&#39064;&#20013;&#24403;&#29305;&#24449;&#31232;&#23569;&#26102;&#26356;&#20026;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#24067;&#24335;&#20248;&#21270;&#38382;&#39064;&#20013;&#65292;&#24403;&#29305;&#24449;&#31232;&#23569;&#26102;&#65292;&#21033;&#29992;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#19982;&#36138;&#24515;&#30340;&#31232;&#30095;&#31639;&#27861;&#65288;TopK&#65289;&#65292;&#32467;&#21512;&#35823;&#24046;&#21453;&#39304;&#65288;EF&#65289;&#21487;&#20197;&#27604;&#32431;GD&#26356;&#22909;&#22320;&#35299;&#20915;&#38382;&#39064;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;EF&#22312;&#29305;&#24449;&#31232;&#23569;&#30340;&#24773;&#20917;&#19979;&#26356;&#20026;&#20986;&#33394;&#12290;&#26412;&#25991;&#39318;&#27425;&#35777;&#26126;&#20102;&#36825;&#19968;&#38382;&#39064;&#12290;&#25105;&#20204;&#36824;&#38416;&#36848;&#20102;&#23547;&#25214;&#20351;&#26799;&#24230;&#30340;&#20108;&#33539;&#25968;&#30340;&#26399;&#26395;&#23567;&#20110;&#19968;&#20010;&#32473;&#23450;&#20540;$\varepsilon$ &#30340;&#38543;&#26426;&#21521;&#37327;&#30340;&#23454;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
We provide the first proof that gradient descent $\left({\color{green}\sf GD}\right)$ with greedy sparsification $\left({\color{green}\sf TopK}\right)$ and error feedback $\left({\color{green}\sf EF}\right)$ can obtain better communication complexity than vanilla ${\color{green}\sf GD}$ when solving the distributed optimization problem $\min_{x\in \mathbb{R}^d} {f(x)=\frac{1}{n}\sum_{i=1}^n f_i(x)}$, where $n$ = # of clients, $d$ = # of features, and $f_1,\dots,f_n$ are smooth nonconvex functions. Despite intensive research since 2014 when ${\color{green}\sf EF}$ was first proposed by Seide et al., this problem remained open until now. We show that ${\color{green}\sf EF}$ shines in the regime when features are rare, i.e., when each feature is present in the data owned by a small number of clients only. To illustrate our main result, we show that in order to find a random vector $\hat{x}$ such that $\lVert {\nabla f(\hat{x})} \rVert^2 \leq \varepsilon$ in expectation, ${\color{green}\sf
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#25674;&#38144;&#25104;&#26412;&#20272;&#35745;&#26041;&#27861;&#65292;&#33021;&#22815;&#35299;&#20915;&#24191;&#20041;&#36125;&#21494;&#26031;&#25512;&#29702;&#26041;&#27861;&#20013;&#22810;&#20010;&#27169;&#25311;&#30340;&#35745;&#31639;&#38382;&#39064;&#65292;&#20174;&#32780;&#20026;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#25552;&#20379;&#20102;&#19968;&#31181;&#22788;&#29702;&#39640;&#32500;&#24230;&#12289;&#22797;&#26434;&#22797;&#29616;&#65292;&#19988;&#36125;&#21494;&#26031;&#21518;&#39564;&#26410;&#24517;&#26159;&#26368;&#20339;&#26041;&#26696;&#30340;&#31185;&#23398;&#27169;&#25311;&#22120;&#30340;&#20248;&#21270;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.15208</link><description>&lt;p&gt;
&#24191;&#20041;&#36125;&#21494;&#26031;&#25512;&#29702;&#26041;&#27861;&#65306;&#36890;&#36807;&#25674;&#38144;&#25104;&#26412;&#35780;&#20272;&#20026;&#31185;&#23398;&#27169;&#25311;&#22120;&#25552;&#20379;&#36125;&#21494;&#26031;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Generalized Bayesian Inference for Scientific Simulators via Amortized Cost Estimation. (arXiv:2305.15208v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15208
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#25674;&#38144;&#25104;&#26412;&#20272;&#35745;&#26041;&#27861;&#65292;&#33021;&#22815;&#35299;&#20915;&#24191;&#20041;&#36125;&#21494;&#26031;&#25512;&#29702;&#26041;&#27861;&#20013;&#22810;&#20010;&#27169;&#25311;&#30340;&#35745;&#31639;&#38382;&#39064;&#65292;&#20174;&#32780;&#20026;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#25552;&#20379;&#20102;&#19968;&#31181;&#22788;&#29702;&#39640;&#32500;&#24230;&#12289;&#22797;&#26434;&#22797;&#29616;&#65292;&#19988;&#36125;&#21494;&#26031;&#21518;&#39564;&#26410;&#24517;&#26159;&#26368;&#20339;&#26041;&#26696;&#30340;&#31185;&#23398;&#27169;&#25311;&#22120;&#30340;&#20248;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#27169;&#25311;&#30340;&#25512;&#29702;&#26041;&#27861;(SBI)&#36890;&#36807;&#20869;&#21547;&#30340;&#21487;&#33021;&#24615;&#65292;&#20026;&#27169;&#25311;&#22120;&#25552;&#20379;&#25674;&#38144;&#24335;&#30340;&#36125;&#21494;&#26031;&#25512;&#29702;&#12290;&#20294;&#26159;&#24403;&#25105;&#20204;&#20027;&#35201;&#20851;&#27880;&#30340;&#26159;&#39044;&#27979;&#27169;&#25311;&#30340;&#36136;&#37327;&#65292;&#25110;&#32773;&#24403;&#27169;&#22411;&#19981;&#33021;&#23436;&#20840;&#37325;&#29616;&#35266;&#27979;&#25968;&#25454;(&#21363;&#23384;&#22312;&#32570;&#38519;)&#65292;&#20197;&#36125;&#21494;&#26031;&#21518;&#39564;&#20026;&#30446;&#26631;&#23601;&#21487;&#33021;&#36807;&#20110;&#20005;&#26684;&#12290;&#24191;&#20041;&#36125;&#21494;&#26031;&#25512;&#29702;(GBI)&#26088;&#22312;&#21152;&#24378;&#23545;(&#26377;&#32570;&#38519;&#30340;)&#27169;&#25311;&#22120;&#27169;&#22411;&#30340;&#25512;&#29702;&#65292;&#29992;&#35780;&#20272;&#21442;&#25968;&#30456;&#23545;&#20110;&#25968;&#25454;&#30340;&#22909;&#22351;&#30340;&#25104;&#26412;&#20989;&#25968;&#26367;&#25442;&#20284;&#28982;&#20989;&#25968;&#12290;&#28982;&#32780;&#65292;GBI&#26041;&#27861;&#36890;&#24120;&#38656;&#35201;&#36816;&#34892;&#22810;&#20010;&#27169;&#25311;&#65292;&#20197;&#22312;&#25512;&#29702;&#26399;&#38388;&#20272;&#35745;&#27599;&#20010;&#21442;&#25968;&#20540;&#30340;&#25104;&#26412;&#20989;&#25968;&#65292;&#20351;&#24471;&#21363;&#20351;&#22312;&#20013;&#31561;&#22797;&#26434;&#30340;&#27169;&#25311;&#31243;&#24207;&#20013;&#20063;&#38590;&#20197;&#35745;&#31639;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#25674;&#38144;&#25104;&#26412;&#35780;&#20272;(ACE)&#30340;&#24191;&#20041;&#36125;&#21494;&#26031;&#25512;&#29702;&#26041;&#27861;&#65292;&#20197;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65306;&#25105;&#20204;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#26469;&#36817;&#20284;&#25104;&#26412;&#20989;&#25968;&#65292;&#23558;&#25104;&#26412;&#20989;&#25968;&#23450;&#20041;&#20026;&#30001;&#28508;&#22312;&#21442;&#25968;&#29983;&#25104;&#30340;&#27169;&#25311;&#20043;&#38388;&#30340;&#26399;&#26395;&#36317;&#31163;&#12290;
&lt;/p&gt;
&lt;p&gt;
Simulation-based inference (SBI) enables amortized Bayesian inference for simulators with implicit likelihoods. But when we are primarily interested in the quality of predictive simulations, or when the model cannot exactly reproduce the observed data (i.e., is misspecified), targeting the Bayesian posterior may be overly restrictive. Generalized Bayesian Inference (GBI) aims to robustify inference for (misspecified) simulator models, replacing the likelihood-function with a cost function that evaluates the goodness of parameters relative to data. However, GBI methods generally require running multiple simulations to estimate the cost function at each parameter value during inference, making the approach computationally infeasible for even moderately complex simulators. Here, we propose amortized cost estimation (ACE) for GBI to address this challenge: We train a neural network to approximate the cost function, which we define as the expected distance between simulations produced by a 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#31070;&#32463;&#32593;&#32476;&#30340;&#38544;&#24615;&#20559;&#24046;&#65292;&#30528;&#30524;&#20110;&#20854;&#20013;&#28041;&#21450;&#30340;&#20613;&#37324;&#21494;&#39057;&#29575;&#19982;&#22270;&#20687;&#20998;&#31867;&#21644;&#23545;&#25239;&#24615;&#25915;&#20987;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21487;&#20197;&#21457;&#29616;&#36825;&#20123;&#39057;&#29575;&#20043;&#38388;&#30340;&#38750;&#32447;&#24615;&#30456;&#20851;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.15203</link><description>&lt;p&gt;
&#36890;&#36807;&#20869;&#22312;&#32500;&#24230;&#23558;&#38544;&#24615;&#20559;&#35265;&#21644;&#23545;&#25239;&#24615;&#25915;&#20987;&#30456;&#20851;&#32852;
&lt;/p&gt;
&lt;p&gt;
Relating Implicit Bias and Adversarial Attacks through Intrinsic Dimension. (arXiv:2305.15203v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15203
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#31070;&#32463;&#32593;&#32476;&#30340;&#38544;&#24615;&#20559;&#24046;&#65292;&#30528;&#30524;&#20110;&#20854;&#20013;&#28041;&#21450;&#30340;&#20613;&#37324;&#21494;&#39057;&#29575;&#19982;&#22270;&#20687;&#20998;&#31867;&#21644;&#23545;&#25239;&#24615;&#25915;&#20987;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21487;&#20197;&#21457;&#29616;&#36825;&#20123;&#39057;&#29575;&#20043;&#38388;&#30340;&#38750;&#32447;&#24615;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#31070;&#32463;&#32593;&#32476;&#22312;&#20998;&#31867;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#20247;&#25152;&#21608;&#30693;&#23427;&#20204;&#26131;&#21463;&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#24433;&#21709;&#12290;&#36825;&#20123;&#25915;&#20987;&#26159;&#38024;&#23545;&#27169;&#22411;&#30340;&#36755;&#20837;&#25968;&#25454;&#36827;&#34892;&#30340;&#23567;&#24178;&#25200;&#65292;&#26088;&#22312;&#27450;&#39575;&#27169;&#22411;&#12290;&#33258;&#28982;&#32780;&#28982;&#30340;&#38382;&#39064;&#26159;&#65292;&#27169;&#22411;&#30340;&#32467;&#26500;&#12289;&#35774;&#32622;&#25110;&#23646;&#24615;&#19982;&#25915;&#20987;&#30340;&#24615;&#36136;&#20043;&#38388;&#21487;&#33021;&#23384;&#22312;&#28508;&#22312;&#32852;&#31995;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#36890;&#36807;&#20851;&#27880;&#31070;&#32463;&#32593;&#32476;&#30340;&#38544;&#24615;&#20559;&#24046;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#36825;&#25351;&#30340;&#26159;&#20854;&#22266;&#26377;&#20542;&#21521;&#20110;&#25903;&#25345;&#29305;&#23450;&#27169;&#24335;&#25110;&#32467;&#26524;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#38544;&#24615;&#20559;&#24046;&#30340;&#19968;&#20010;&#26041;&#38754;&#65292;&#20854;&#20013;&#21253;&#25324;&#36827;&#34892;&#20934;&#30830;&#22270;&#20687;&#20998;&#31867;&#25152;&#38656;&#30340;&#22522;&#26412;&#20613;&#37324;&#21494;&#39057;&#29575;&#12290;&#25105;&#20204;&#36827;&#34892;&#27979;&#35797;&#20197;&#35780;&#20272;&#36825;&#20123;&#39057;&#29575;&#19982;&#25104;&#21151;&#25915;&#20987;&#25152;&#38656;&#30340;&#39057;&#29575;&#20043;&#38388;&#30340;&#32479;&#35745;&#20851;&#31995;&#12290;&#20026;&#20102;&#28145;&#20837;&#25506;&#35752;&#36825;&#31181;&#20851;&#31995;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#25581;&#31034;&#22352;&#26631;&#38598;&#20043;&#38388;&#30340;&#38750;&#32447;&#24615;&#30456;&#20851;&#24615;&#65292;&#22312;&#25105;&#20204;&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#20123;&#22352;&#26631;&#38598;&#23601;&#26159;&#21069;&#36848;&#30340;&#20613;&#37324;&#21494;&#39057;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite their impressive performance in classification, neural networks are known to be vulnerable to adversarial attacks. These attacks are small perturbations of the input data designed to fool the model. Naturally, a question arises regarding the potential connection between the architecture, settings, or properties of the model and the nature of the attack. In this work, we aim to shed light on this problem by focusing on the implicit bias of the neural network, which refers to its inherent inclination to favor specific patterns or outcomes. Specifically, we investigate one aspect of the implicit bias, which involves the essential Fourier frequencies required for accurate image classification. We conduct tests to assess the statistical relationship between these frequencies and those necessary for a successful attack. To delve into this relationship, we propose a new method that can uncover non-linear correlations between sets of coordinates, which, in our case, are the aforementio
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#20998;&#26512;&#21327;&#26041;&#24046;&#32467;&#26500;&#30340;&#38543;&#26426; Shapley &#20540;&#35299;&#37322;&#26041;&#27861;&#65292;&#20854;&#35299;&#37322;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#36136;&#65292;&#21487;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#65292;&#30740;&#31350;&#35299;&#37322;&#20043;&#38388;&#30340;&#32479;&#35745;&#20381;&#36182;&#20851;&#31995;&#65292;&#24182;&#25193;&#23637;&#21040;&#20102;&#39044;&#27979;&#35299;&#37322;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.15167</link><description>&lt;p&gt;
&#35299;&#37322;&#19981;&#30830;&#23450;&#24615;&#65306;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#30340;&#38543;&#26426; Shapley &#20540;
&lt;/p&gt;
&lt;p&gt;
Explaining the Uncertain: Stochastic Shapley Values for Gaussian Process Models. (arXiv:2305.15167v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15167
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#20998;&#26512;&#21327;&#26041;&#24046;&#32467;&#26500;&#30340;&#38543;&#26426; Shapley &#20540;&#35299;&#37322;&#26041;&#27861;&#65292;&#20854;&#35299;&#37322;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#36136;&#65292;&#21487;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#65292;&#30740;&#31350;&#35299;&#37322;&#20043;&#38388;&#30340;&#32479;&#35745;&#20381;&#36182;&#20851;&#31995;&#65292;&#24182;&#25193;&#23637;&#21040;&#20102;&#39044;&#27979;&#35299;&#37322;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#37322;&#21487;&#20197;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;(GP)&#20013;&#23436;&#25972;&#20998;&#26512;&#21327;&#26041;&#24046;&#32467;&#26500;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#24191;&#21463;&#27426;&#36814;&#30340; Shapley &#20540;&#35299;&#20915;&#26041;&#26696;&#27010;&#24565;&#65292;&#25193;&#23637;&#20026;&#38543;&#26426;&#21512;&#20316;&#28216;&#25103;&#65292;&#20174;&#32780;&#20135;&#29983;&#38543;&#26426;&#21464;&#37327;&#30340;&#35299;&#37322;&#12290;&#20351;&#29992;&#25105;&#20204;&#26041;&#27861;&#20135;&#29983;&#30340; GP &#35299;&#37322;&#28385;&#36275;&#19982;&#26631;&#20934; Shapley &#20540;&#31867;&#20284;&#30340;&#26377;&#21033;&#20844;&#29702;&#65292;&#24182;&#19988;&#20855;&#26377;&#36328;&#29305;&#24449;&#21644;&#25968;&#25454;&#35266;&#23519;&#20540;&#30340;&#21487;&#22788;&#29702;&#21327;&#26041;&#24046;&#20989;&#25968;&#12290;&#36825;&#31181;&#21327;&#26041;&#24046;&#20989;&#25968;&#21487;&#20197;&#37327;&#21270;&#35299;&#37322;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#30740;&#31350;&#35299;&#37322;&#20043;&#38388;&#30340;&#32479;&#35745;&#20381;&#36182;&#20851;&#31995;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23558;&#25105;&#20204;&#30340;&#26694;&#26550;&#25193;&#23637;&#21040;&#39044;&#27979;&#35299;&#37322;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#19968;&#20010; Shapley &#20808;&#39564;&#27010;&#29575;&#65292;&#29992;&#20110;&#39044;&#27979;&#22522;&#20110;&#20808;&#21069;&#35745;&#31639;&#30340; Shapley &#20540;&#30340;&#26032;&#25968;&#25454;&#30340; Shapley &#20540;&#12290;&#25105;&#20204;&#24191;&#27867;&#30340;&#35828;&#26126;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a novel approach for explaining Gaussian processes (GPs) that can utilize the full analytical covariance structure present in GPs. Our method is based on the popular solution concept of Shapley values extended to stochastic cooperative games, resulting in explanations that are random variables. The GP explanations generated using our approach satisfy similar favorable axioms to standard Shapley values and possess a tractable covariance function across features and data observations. This covariance allows for quantifying explanation uncertainties and studying the statistical dependencies between explanations. We further extend our framework to the problem of predictive explanation, and propose a Shapley prior over the explanation function to predict Shapley values for new data based on previously computed ones. Our extensive illustrations demonstrate the effectiveness of the proposed approach.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#23545;&#20108;&#23618;ReLU&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#21508;&#31181;&#20551;&#35774;&#19979;&#36807;&#25311;&#21512;&#30340;&#31867;&#22411;&#20250;&#20174;&#19968;&#32500;&#25968;&#25454;&#30340;&#26497;&#31471;&#24773;&#20917;&#19979;&#32531;&#21644;&#21040;&#39640;&#32500;&#30340;&#33391;&#24615;&#65292;&#25581;&#31034;&#20102;&#36755;&#20837;&#32500;&#24230;&#22312;&#31070;&#32463;&#32593;&#32476;&#36807;&#25311;&#21512;&#20013;&#30340;&#20851;&#38190;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2305.15141</link><description>&lt;p&gt;
&#20174;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#32531;&#21644;&#36807;&#25311;&#21512;&#21040;&#33391;&#24615;&#36807;&#25311;&#21512;
&lt;/p&gt;
&lt;p&gt;
From Tempered to Benign Overfitting in ReLU Neural Networks. (arXiv:2305.15141v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15141
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#23545;&#20108;&#23618;ReLU&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#21508;&#31181;&#20551;&#35774;&#19979;&#36807;&#25311;&#21512;&#30340;&#31867;&#22411;&#20250;&#20174;&#19968;&#32500;&#25968;&#25454;&#30340;&#26497;&#31471;&#24773;&#20917;&#19979;&#32531;&#21644;&#21040;&#39640;&#32500;&#30340;&#33391;&#24615;&#65292;&#25581;&#31034;&#20102;&#36755;&#20837;&#32500;&#24230;&#22312;&#31070;&#32463;&#32593;&#32476;&#36807;&#25311;&#21512;&#20013;&#30340;&#20851;&#38190;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#34987;&#35266;&#23519;&#21040;&#21363;&#20351;&#35757;&#32451;&#27169;&#22411;&#26469;&#23436;&#32654;&#22320;&#36866;&#24212;&#22024;&#26434;&#30340;&#25968;&#25454;&#20063;&#33021;&#24456;&#22909;&#22320;&#25512;&#24191;&#12290;&#36825;&#19968;&#29616;&#35937;&#24341;&#21457;&#20102;&#22823;&#37327;&#20851;&#20110;&#8220;&#33391;&#24615;&#36807;&#25311;&#21512;&#8221;&#30340;&#24037;&#20316;&#65292;&#20854;&#20013;&#20869;&#25554;&#39044;&#27979;&#22120;&#23454;&#29616;&#25509;&#36817;&#26368;&#20248;&#24615;&#33021;&#12290;&#26368;&#36817;&#65292;&#26377;&#20154;&#29468;&#27979;&#24182;&#32463;&#39564;&#24615;&#22320;&#35266;&#23519;&#21040;&#31070;&#32463;&#32593;&#32476;&#30340;&#34892;&#20026;&#36890;&#24120;&#26356;&#22909;&#22320;&#25551;&#36848;&#20026;&#8220;&#32531;&#21644;&#36807;&#25311;&#21512;&#8221;&#65292;&#20854;&#20013;&#24615;&#33021;&#26082;&#38750;&#26368;&#20248;&#65292;&#20063;&#38750;&#24494;&#19981;&#36275;&#36947;&#65292;&#24182;&#38543;&#22122;&#22768;&#27700;&#24179;&#30340;&#21464;&#21270;&#32780;&#38477;&#20302;&#12290;&#28982;&#32780;&#65292;&#36804;&#20170;&#20026;&#27490;&#65292;&#36825;&#19968;&#20027;&#24352;&#23578;&#32570;&#20047;&#20851;&#20110;&#38750;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#29702;&#35770;&#30340;&#35777;&#26126;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20960;&#20010;&#32467;&#26524;&#65292;&#26088;&#22312;&#24357;&#21512;&#36825;&#20123;&#20114;&#34917;&#30340;&#35266;&#28857;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#20998;&#31867;&#35774;&#32622;&#65292;&#20351;&#29992;&#20108;&#23618;ReLU&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#35777;&#26126;&#22312;&#21508;&#31181;&#20551;&#35774;&#19979;&#65292;&#36807;&#25311;&#21512;&#30340;&#31867;&#22411;&#20174;&#19968;&#32500;&#25968;&#25454;&#30340;&#26497;&#31471;&#24773;&#20917;&#19979;&#32531;&#21644;&#21040;&#39640;&#32500;&#30340;&#33391;&#24615;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#35777;&#26126;&#36755;&#20837;&#32500;&#24230;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#26377;&#20851;&#38190;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Overparameterized neural networks (NNs) are observed to generalize well even when trained to perfectly fit noisy data. This phenomenon motivated a large body of work on "benign overfitting", where interpolating predictors achieve near-optimal performance. Recently, it was conjectured and empirically observed that the behavior of NNs is often better described as "tempered overfitting", where the performance is non-optimal yet also non-trivial, and degrades as a function of the noise level. However, a theoretical justification of this claim for non-linear NNs has been lacking so far. In this work, we provide several results that aim at bridging these complementing views. We study a simple classification setting with 2-layer ReLU NNs, and prove that under various assumptions, the type of overfitting transitions from tempered in the extreme case of one-dimensional data, to benign in high dimensions. Thus, we show that the input dimension has a crucial role on the type of overfitting in thi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#8212;&#8212;&#38750;&#37197;&#23545;&#31070;&#32463;&#34203;&#23450;&#35860;&#26725; (UNSB)&#65292;&#23427;&#32467;&#21512;&#20102;&#34203;&#23450;&#35860;&#26725;&#12289;&#23545;&#25239;&#35757;&#32451;&#21644;&#27491;&#21017;&#21270;&#65292;&#29992;&#20110;&#22312;&#38750;&#37197;&#23545;&#25968;&#25454;&#20043;&#38388;&#23398;&#20064; SDE&#65292;&#24182;&#25104;&#21151;&#35299;&#20915;&#20102;&#35768;&#22810;&#38750;&#37197;&#23545;&#22270;&#20687;&#36716;&#25442;&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2305.15086</link><description>&lt;p&gt;
&#20351;&#29992;&#31070;&#32463;&#34203;&#23450;&#35860;&#26725;&#23454;&#29616;&#38750;&#37197;&#23545;&#22270;&#20687;&#36716;&#25442;
&lt;/p&gt;
&lt;p&gt;
Unpaired Image-to-Image Translation via Neural Schr\"odinger Bridge. (arXiv:2305.15086v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15086
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#8212;&#8212;&#38750;&#37197;&#23545;&#31070;&#32463;&#34203;&#23450;&#35860;&#26725; (UNSB)&#65292;&#23427;&#32467;&#21512;&#20102;&#34203;&#23450;&#35860;&#26725;&#12289;&#23545;&#25239;&#35757;&#32451;&#21644;&#27491;&#21017;&#21270;&#65292;&#29992;&#20110;&#22312;&#38750;&#37197;&#23545;&#25968;&#25454;&#20043;&#38388;&#23398;&#20064; SDE&#65292;&#24182;&#25104;&#21151;&#35299;&#20915;&#20102;&#35768;&#22810;&#38750;&#37197;&#23545;&#22270;&#20687;&#36716;&#25442;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#26159;&#19968;&#31867;&#29983;&#25104;&#27169;&#22411;&#65292;&#23427;&#36890;&#36807;&#27169;&#25311;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;SDE&#65289;&#20174;&#22122;&#22768;&#29983;&#25104;&#25968;&#25454;&#12290;&#23613;&#31649;&#25193;&#25955;&#27169;&#22411;&#22312;&#26368;&#36817;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#20294;&#30001;&#20110;&#39640;&#26031;&#20808;&#39564;&#20551;&#35774;&#65292;&#23427;&#20204;&#22312;&#38750;&#37197;&#23545;&#30340;&#22270;&#20687;&#36716;&#25442;&#20219;&#21153;&#20013;&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;&#34203;&#23450;&#35860;&#26725;&#26159;&#19968;&#31181;&#23398;&#20064; SDE &#20197;&#22312;&#20004;&#20010;&#20219;&#24847;&#20998;&#24067;&#20043;&#38388;&#36716;&#25442;&#30340;&#26041;&#27861;&#65292;&#34987;&#35270;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#19968;&#31181;&#26377;&#21560;&#24341;&#21147;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#36804;&#20170;&#20026;&#27490;&#65292;&#34203;&#23450;&#35860;&#26725;&#27169;&#22411;&#22312;&#39640;&#20998;&#36776;&#29575;&#22270;&#20687;&#20043;&#38388;&#30340;&#38750;&#37197;&#23545;&#36716;&#25442;&#26041;&#38754;&#24182;&#19981;&#25104;&#21151;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#38750;&#37197;&#23545;&#31070;&#32463;&#34203;&#23450;&#35860;&#26725;&#65288;UNSB&#65289;&#65292;&#23427;&#23558;&#34203;&#23450;&#35860;&#26725;&#19982;&#23545;&#25239;&#24615;&#35757;&#32451;&#21644;&#27491;&#21017;&#21270;&#30456;&#32467;&#21512;&#65292;&#20197;&#23398;&#20064;&#38750;&#37197;&#23545;&#25968;&#25454;&#20043;&#38388;&#30340; SDE&#12290;&#25105;&#20204;&#35777;&#26126;&#20102; UNSB &#26159;&#21487;&#20280;&#32553;&#30340;&#65292;&#24182;&#19988;&#25104;&#21151;&#35299;&#20915;&#20102;&#21508;&#31181;&#38750;&#37197;&#23545;&#22270;&#20687;&#36716;&#25442;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models are a powerful class of generative models which simulate stochastic differential equations (SDEs) to generate data from noise. Although diffusion models have achieved remarkable progress in recent years, they have limitations in the unpaired image-to-image translation tasks due to the Gaussian prior assumption. Schr\"odinger Bridge (SB), which learns an SDE to translate between two arbitrary distributions, have risen as an attractive solution to this problem. However, none of SB models so far have been successful at unpaired translation between high-resolution images. In this work, we propose the Unpaired Neural Schr\"odinger Bridge (UNSB), which combines SB with adversarial training and regularization to learn a SB between unpaired data. We demonstrate that UNSB is scalable, and that it successfully solves various unpaired image-to-image translation tasks. Code: \url{https://github.com/cyclomon/UNSB}
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38544;&#24335;&#28145;&#24230;&#23398;&#20064;&#20013;&#27979;&#35797;&#26102;&#38388;&#20869;&#37096;&#36845;&#20195;&#27425;&#25968;&#30340;&#24433;&#21709;&#65292;&#25552;&#20986;&#36807;&#24230;&#21442;&#25968;&#21270;&#26102;&#22686;&#21152;&#36845;&#20195;&#27425;&#25968;&#26080;&#27861;&#25552;&#39640;&#24615;&#33021;&#30340;&#29702;&#35770;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#36827;&#34892;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2305.15042</link><description>&lt;p&gt;
&#38544;&#24335;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#20687;&#35757;&#32451;&#19968;&#26679;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
Test like you Train in Implicit Deep Learning. (arXiv:2305.15042v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15042
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38544;&#24335;&#28145;&#24230;&#23398;&#20064;&#20013;&#27979;&#35797;&#26102;&#38388;&#20869;&#37096;&#36845;&#20195;&#27425;&#25968;&#30340;&#24433;&#21709;&#65292;&#25552;&#20986;&#36807;&#24230;&#21442;&#25968;&#21270;&#26102;&#22686;&#21152;&#36845;&#20195;&#27425;&#25968;&#26080;&#27861;&#25552;&#39640;&#24615;&#33021;&#30340;&#29702;&#35770;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#36827;&#34892;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38544;&#24335;&#28145;&#24230;&#23398;&#20064;&#26368;&#36817;&#22312;&#20803;&#23398;&#20064;&#21644;Deep Equilibrium Networks&#65288;DEQs&#65289;&#31561;&#24212;&#29992;&#20013;&#21464;&#24471;&#27969;&#34892;&#12290;&#22312;&#20854;&#19968;&#33324;&#24418;&#24335;&#20013;&#65292;&#23427;&#20381;&#36182;&#20110;&#36890;&#36807;&#19968;&#20010;&#31216;&#20026;&#20869;&#37096;&#38382;&#39064;&#30340;&#26681;&#26041;&#31243;&#38544;&#21547;&#22320;&#34920;&#36798;&#28145;&#24230;&#23398;&#20064;&#27969;&#31243;&#30340;&#19968;&#20123;&#32452;&#20214;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#20869;&#37096;&#38382;&#39064;&#30340;&#35299;&#20915;&#26041;&#26696;&#36890;&#24120;&#36890;&#36807;&#36845;&#20195;&#36807;&#31243;&#22312;&#35757;&#32451;&#26399;&#38388;&#36827;&#34892;&#36817;&#20284;&#35745;&#31639;&#65292;&#36890;&#24120;&#20351;&#29992;&#22266;&#23450;&#25968;&#37327;&#30340;&#20869;&#37096;&#36845;&#20195;&#12290;&#22312;&#25512;&#26029;&#26399;&#38388;&#65292;&#20869;&#37096;&#38382;&#39064;&#38656;&#35201;&#20351;&#29992;&#26032;&#25968;&#25454;&#36827;&#34892;&#27714;&#35299;&#12290;&#19968;&#31181;&#26222;&#36941;&#30340;&#20449;&#24565;&#26159;&#65292;&#19982;&#35757;&#32451;&#26399;&#38388;&#20351;&#29992;&#30340;&#20869;&#37096;&#36845;&#20195;&#27425;&#25968;&#30456;&#27604;&#65292;&#22686;&#21152;&#27979;&#35797;&#26102;&#38388;&#30340;&#20869;&#37096;&#36845;&#20195;&#27425;&#25968;&#21487;&#20197;&#25552;&#39640;&#24615;&#33021;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36136;&#30097;&#36825;&#31181;&#20551;&#35774;&#65292;&#24182;&#22312;&#31616;&#21333;&#30340;&#35774;&#32622;&#20013;&#25552;&#20379;&#20102;&#35814;&#32454;&#30340;&#29702;&#35770;&#20998;&#26512;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36807;&#24230;&#21442;&#25968;&#21270;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#65306;&#23545;&#20110;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#32593;&#32476;&#65292;&#22686;&#21152;&#27979;&#35797;&#26102;&#38388;&#30340;&#36845;&#20195;&#27425;&#25968;&#19981;&#33021;&#25913;&#21892;&#24615;&#33021;&#12290;&#25105;&#20204;&#22312;&#19968;&#31995;&#21015;&#38544;&#24335;&#28145;&#24230;&#23398;&#20064;&#38382;&#39064;&#19978;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
Implicit deep learning has recently gained popularity with applications ranging from meta-learning to Deep Equilibrium Networks (DEQs). In its general formulation, it relies on expressing some components of deep learning pipelines implicitly, typically via a root equation called the inner problem. In practice, the solution of the inner problem is approximated during training with an iterative procedure, usually with a fixed number of inner iterations. During inference, the inner problem needs to be solved with new data. A popular belief is that increasing the number of inner iterations compared to the one used during training yields better performance. In this paper, we question such an assumption and provide a detailed theoretical analysis in a simple setting. We demonstrate that overparametrization plays a key role: increasing the number of iterations at test time cannot improve performance for overparametrized networks. We validate our theory on an array of implicit deep-learning pr
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#24314;&#31435;&#20102;&#28145;&#24230;&#23398;&#20064;&#22312;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#20013;&#25152;&#20351;&#29992;&#30340;&#28145;&#24230;&#38598;&#25104;&#21644;&#65288;&#21464;&#20998;&#65289;&#36125;&#21494;&#26031;&#26041;&#27861;&#30340;&#32479;&#19968;&#29702;&#35770;&#65292;&#36890;&#36807;&#23558;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#36716;&#21270;&#20026;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#19978;&#30340;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#19968;&#26063;&#20132;&#20114;&#24335;&#28145;&#24230;&#38598;&#25104;&#26041;&#26696;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#39564;&#35777;&#20102;&#29702;&#35770;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2305.15027</link><description>&lt;p&gt;
&#28145;&#24230;&#38598;&#25104;&#19982;&#65288;&#21464;&#20998;&#65289;&#36125;&#21494;&#26031;&#26041;&#27861;&#20043;&#38388;&#30340;&#20005;&#26684;&#32852;&#31995;
&lt;/p&gt;
&lt;p&gt;
A Rigorous Link between Deep Ensembles and (Variational) Bayesian Methods. (arXiv:2305.15027v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15027
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#24314;&#31435;&#20102;&#28145;&#24230;&#23398;&#20064;&#22312;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#20013;&#25152;&#20351;&#29992;&#30340;&#28145;&#24230;&#38598;&#25104;&#21644;&#65288;&#21464;&#20998;&#65289;&#36125;&#21494;&#26031;&#26041;&#27861;&#30340;&#32479;&#19968;&#29702;&#35770;&#65292;&#36890;&#36807;&#23558;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#36716;&#21270;&#20026;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#19978;&#30340;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#19968;&#26063;&#20132;&#20114;&#24335;&#28145;&#24230;&#38598;&#25104;&#26041;&#26696;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#39564;&#35777;&#20102;&#29702;&#35770;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#39318;&#27425;&#22312;&#25968;&#23398;&#19978;&#24314;&#31435;&#20102;&#36125;&#21494;&#26031;&#12289;&#21464;&#20998;&#36125;&#21494;&#26031;&#21644;&#38598;&#25104;&#26041;&#27861;&#20043;&#38388;&#30340;&#20005;&#26684;&#32852;&#31995;&#12290;&#20854;&#20851;&#38190;&#27493;&#39588;&#26159;&#23558;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#36890;&#24120;&#36935;&#21040;&#30340;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#37325;&#26032;&#34920;&#36848;&#20026;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#20013;&#30340;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#22312;&#25216;&#26415;&#23618;&#38754;&#19978;&#65292;&#25105;&#20204;&#30340;&#36129;&#29486;&#26159;&#36890;&#36807;Wasserstein&#26799;&#24230;&#27969;&#30340;&#36879;&#38236;&#30740;&#31350;&#24191;&#20041;&#21464;&#20998;&#25512;&#26029;&#12290;&#32467;&#26524;&#26159;&#19968;&#20010;&#32479;&#19968;&#30340;&#29702;&#35770;&#65292;&#28085;&#30422;&#22810;&#31181;&#30475;&#20284;&#26080;&#20851;&#30340;&#26041;&#27861;&#65292;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#29992;&#20110;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#21253;&#25324;&#28145;&#24230;&#38598;&#25104;&#21644;&#65288;&#21464;&#20998;&#65289;&#36125;&#21494;&#26031;&#26041;&#27861;&#12290;&#36825;&#20026;&#28145;&#24230;&#38598;&#25104;&#32988;&#36807;&#22522;&#20110;&#21442;&#25968;&#21270;&#21464;&#20998;&#25512;&#26029;&#30340;&#31243;&#24207;&#32972;&#21518;&#30340;&#21407;&#22240;&#25552;&#20379;&#20102;&#26032;&#30340;&#35270;&#35282;&#65292;&#24182;&#20801;&#35768;&#25512;&#23548;&#20855;&#26377;&#25910;&#25947;&#20445;&#35777;&#30340;&#26032;&#38598;&#25104;&#26041;&#26696;&#12290;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#19968;&#26063;&#20855;&#26377;&#30452;&#25509;&#31867;&#27604;&#20110;&#29289;&#29702;&#23398;&#20013;&#31890;&#23376;&#31995;&#32479;&#20132;&#20114;&#30340;&#20132;&#20114;&#24335;&#28145;&#24230;&#38598;&#25104;&#26469;&#23637;&#31034;&#36825;&#19968;&#28857;&#65292;&#24182;&#25552;&#20379;&#19968;&#31995;&#21015;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We establish the first mathematically rigorous link between Bayesian, variational Bayesian, and ensemble methods. A key step towards this it to reformulate the non-convex optimisation problem typically encountered in deep learning as a convex optimisation in the space of probability measures. On a technical level, our contribution amounts to studying generalised variational inference through the lense of Wasserstein gradient flows. The result is a unified theory of various seemingly disconnected approaches that are commonly used for uncertainty quantification in deep learning -- including deep ensembles and (variational) Bayesian methods. This offers a fresh perspective on the reasons behind the success of deep ensembles over procedures based on parameterised variational inference, and allows the derivation of new ensembling schemes with convergence guarantees. We showcase this by proposing a family of interacting deep ensembles with direct parallels to the interactions of particle sys
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21457;&#29616;&#19968;&#31181;&#22522;&#20110;&#28857;&#31215;&#30340;&#23618;&#27425;&#32858;&#31867;&#31639;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#26368;&#22823;&#24179;&#22343;&#28857;&#31215;&#21512;&#24182;&#32858;&#31867;&#65292;&#24182;&#19988;&#36755;&#20986;&#30340;&#26641;&#32467;&#26500;&#21487;&#29992;&#20110;&#20934;&#30830;&#20272;&#35745;&#25968;&#25454;&#30340;&#29983;&#25104;&#23618;&#27425;&#32467;&#26500;&#65292;&#26641;&#24418;&#24674;&#22797;&#24615;&#33021;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.15022</link><description>&lt;p&gt;
&#22522;&#20110;&#28857;&#31215;&#30340;&#23618;&#27425;&#32858;&#31867;&#21487;&#20197;&#24674;&#22797;&#38544;&#34255;&#30340;&#26641;&#24418;&#32467;&#26500;
&lt;/p&gt;
&lt;p&gt;
Hierarchical clustering with dot products recovers hidden tree structure. (arXiv:2305.15022v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15022
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21457;&#29616;&#19968;&#31181;&#22522;&#20110;&#28857;&#31215;&#30340;&#23618;&#27425;&#32858;&#31867;&#31639;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#26368;&#22823;&#24179;&#22343;&#28857;&#31215;&#21512;&#24182;&#32858;&#31867;&#65292;&#24182;&#19988;&#36755;&#20986;&#30340;&#26641;&#32467;&#26500;&#21487;&#29992;&#20110;&#20934;&#30830;&#20272;&#35745;&#25968;&#25454;&#30340;&#29983;&#25104;&#23618;&#27425;&#32467;&#26500;&#65292;&#26641;&#24418;&#24674;&#22797;&#24615;&#33021;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#23545;&#20110;&#24050;&#26377;&#20957;&#32858;&#32858;&#31867;&#31639;&#27861;&#30340;&#26032;&#35270;&#35282;&#65292;&#19987;&#27880;&#20110;&#23618;&#27425;&#32467;&#26500;&#30340;&#24674;&#22797;&#12290;&#25105;&#20204;&#24314;&#35758;&#19968;&#31181;&#31616;&#21333;&#30340;&#26631;&#20934;&#31639;&#27861;&#21464;&#20307;&#65292;&#20854;&#20013;&#32858;&#31867;&#26159;&#36890;&#36807;&#26368;&#22823;&#24179;&#22343;&#28857;&#31215;&#32780;&#19981;&#26159;&#26368;&#23567;&#36317;&#31163;&#25110;&#31751;&#20869;&#26041;&#24046;&#26469;&#21512;&#24182;&#30340;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#27492;&#31639;&#27861;&#36755;&#20986;&#30340;&#26641;&#21487;&#20197;&#20316;&#20026;&#25968;&#25454;&#29983;&#25104;&#23618;&#27425;&#32467;&#26500;&#30340;&#21487;&#38752;&#20272;&#35745;&#12290;&#20851;&#38190;&#25216;&#26415;&#21019;&#26032;&#22312;&#20110;&#29702;&#35299;&#27169;&#22411;&#20013;&#30340;&#23618;&#27425;&#20449;&#24687;&#22914;&#20309;&#36716;&#21270;&#20026;&#21487;&#20174;&#25968;&#25454;&#20013;&#24674;&#22797;&#30340;&#26641;&#24418;&#20960;&#20309;&#20449;&#24687;&#65292;&#24182;&#21516;&#26102;&#22686;&#38271;&#26679;&#26412;&#22823;&#23567;&#21644;&#25968;&#25454;&#32500;&#25968;&#30340;&#22909;&#22788;&#12290;&#25105;&#20204;&#22312;&#30495;&#23454;&#25968;&#25454;&#19978;&#23637;&#31034;&#20102;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#65288;&#22914;UPGMA&#12289;Ward's&#26041;&#27861;&#21644;HDBSCAN&#65289;&#30340;&#26641;&#24418;&#24674;&#22797;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we offer a new perspective on the well established agglomerative clustering algorithm, focusing on recovery of hierarchical structure. We recommend a simple variant of the standard algorithm, in which clusters are merged by maximum average dot product and not, for example, by minimum distance or within-cluster variance. We demonstrate that the tree output by this algorithm provides a bona fide estimate of generative hierarchical structure in data, under a generic probabilistic graphical model. The key technical innovations are to understand how hierarchical information in this model translates into tree geometry which can be recovered from data, and to characterise the benefits of simultaneously growing sample size and data dimension. We demonstrate superior tree recovery performance with real data over existing approaches such as UPGMA, Ward's method, and HDBSCAN.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#25674;&#20313;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#23545;&#25239;&#24615;&#31283;&#20581;&#24615;&#65292;&#21457;&#29616;&#20960;&#20046;&#19981;&#21487;&#35782;&#21035;&#30340;&#26377;&#38024;&#23545;&#24615;&#30340;&#35266;&#23519;&#25200;&#21160;&#20250;&#23548;&#33268;&#21518;&#39564;&#39044;&#27979;&#24040;&#22823;&#21464;&#21270;&#21644;&#19981;&#29616;&#23454;&#30340;&#21518;&#39564;&#39044;&#27979;&#26679;&#26412;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#26469;&#25552;&#39640;&#20854;&#31283;&#20581;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.14984</link><description>&lt;p&gt;
&#35745;&#31639;&#20195;&#20215;&#19982;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#23545;&#25239;&#24615;&#31283;&#20581;&#24615;
&lt;/p&gt;
&lt;p&gt;
Adversarial robustness of amortized Bayesian inference. (arXiv:2305.14984v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14984
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#25674;&#20313;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#23545;&#25239;&#24615;&#31283;&#20581;&#24615;&#65292;&#21457;&#29616;&#20960;&#20046;&#19981;&#21487;&#35782;&#21035;&#30340;&#26377;&#38024;&#23545;&#24615;&#30340;&#35266;&#23519;&#25200;&#21160;&#20250;&#23548;&#33268;&#21518;&#39564;&#39044;&#27979;&#24040;&#22823;&#21464;&#21270;&#21644;&#19981;&#29616;&#23454;&#30340;&#21518;&#39564;&#39044;&#27979;&#26679;&#26412;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#26469;&#25552;&#39640;&#20854;&#31283;&#20581;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#25512;&#26029;&#36890;&#24120;&#38656;&#35201;&#21333;&#29420;&#36816;&#34892;&#21487;&#33021;&#26114;&#36149;&#30340;&#25512;&#29702;&#36807;&#31243;&#20197;&#33719;&#21462;&#27599;&#20010;&#26032;&#35266;&#27979;&#32467;&#26524;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#25674;&#20313;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#24605;&#24819;&#26159;&#26368;&#21021;&#22312;&#27169;&#25311;&#25968;&#25454;&#19978;&#25237;&#36164;&#35745;&#31639;&#25104;&#26412;&#65292;&#28982;&#21518;&#21487;&#20197;&#29992;&#20110;&#24555;&#36895;&#25191;&#34892;&#25512;&#26029;&#65288;&#21363;&#36820;&#22238;&#21518;&#39564;&#20998;&#24067;&#20272;&#35745;&#65289;&#20197;&#33719;&#21462;&#26032;&#35266;&#27979;&#30340;&#32467;&#26524;&#12290;&#34429;&#28982;&#22312;&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#24050;&#32463;&#23558;&#36825;&#31181;&#26041;&#27861;&#24212;&#29992;&#20110;&#35768;&#22810;&#29616;&#23454;&#19990;&#30028;&#30340;&#27169;&#22411;&#65292;&#20294;&#20854;&#23545;&#20110;&#35266;&#27979;&#25968;&#25454;&#30340;&#23545;&#25239;&#24615;&#25200;&#21160;&#30340;&#31283;&#20581;&#24615;&#23578;&#19981;&#28165;&#26970;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#25674;&#20313;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#23545;&#25239;&#24615;&#31283;&#20581;&#24615;&#65292;&#37325;&#28857;&#20851;&#27880;&#22810;&#32500;&#21518;&#39564;&#20998;&#24067;&#30340;&#22522;&#20110;&#27169;&#25311;&#30340;&#20272;&#35745;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20960;&#20010;&#22522;&#20934;&#20219;&#21153;&#21644;&#19968;&#20010;&#26469;&#33258;&#21307;&#23398;&#25104;&#20687;&#30340;&#30495;&#23454;&#19990;&#30028;&#20363;&#23376;&#65292;&#34920;&#26126;&#20960;&#20046;&#26080;&#27861;&#35782;&#21035;&#30340;&#26377;&#38024;&#23545;&#24615;&#30340;&#35266;&#23519;&#25200;&#21160;&#20250;&#23548;&#33268;&#39044;&#27979;&#21518;&#39564;&#30340;&#24040;&#22823;&#21464;&#21270;&#21644;&#39640;&#24230;&#19981;&#29616;&#23454;&#30340;&#21518;&#39564;&#39044;&#27979;&#26679;&#26412;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#25674;&#20313;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#21487;&#33021;&#23481;&#26131;&#21463;&#21040;&#23545;&#25239;&#24615;&#25200;&#21160;&#30340;&#25915;&#20987;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#31283;&#20581;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian inference usually requires running potentially costly inference procedures separately for every new observation. In contrast, the idea of amortized Bayesian inference is to initially invest computational cost in training an inference network on simulated data, which can subsequently be used to rapidly perform inference (i.e., to return estimates of posterior distributions) for new observations. This approach has been applied to many real-world models in the sciences and engineering, but it is unclear how robust the approach is to adversarial perturbations in the observed data. Here, we study the adversarial robustness of amortized Bayesian inference, focusing on simulation-based estimation of multi-dimensional posterior distributions. We show that almost unrecognizable, targeted perturbations of the observations can lead to drastic changes in the predicted posterior and highly unrealistic posterior predictive samples, across several benchmark tasks and a real-world example fro
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#23567;&#27874;&#22495;&#30340;&#23646;&#24615;&#26041;&#27861;WCAM&#65292;&#33021;&#22815;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#23545;&#22270;&#20687;&#25439;&#22351;&#30340;&#25935;&#24863;&#24615;&#65292;&#30830;&#23450;&#39044;&#27979;&#30340;&#36275;&#22815;&#20449;&#24687;&#65292;&#24182;&#38416;&#26126;&#32553;&#25918;&#22914;&#20309;&#22686;&#21152;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.14979</link><description>&lt;p&gt;
&#23610;&#24230;&#24456;&#37325;&#35201;&#65306;&#22522;&#20110;&#23567;&#27874;&#22495;&#30340;&#23646;&#24615;&#26041;&#27861;&#35299;&#37322;&#27169;&#22411;&#23545;&#22270;&#20687;&#25439;&#22351;&#30340;&#25935;&#24863;&#24615;
&lt;/p&gt;
&lt;p&gt;
Scale Matters: Attribution Meets the Wavelet Domain to Explain Model Sensitivity to Image Corruptions. (arXiv:2305.14979v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14979
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#23567;&#27874;&#22495;&#30340;&#23646;&#24615;&#26041;&#27861;WCAM&#65292;&#33021;&#22815;&#35299;&#37322;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#23545;&#22270;&#20687;&#25439;&#22351;&#30340;&#25935;&#24863;&#24615;&#65292;&#30830;&#23450;&#39044;&#27979;&#30340;&#36275;&#22815;&#20449;&#24687;&#65292;&#24182;&#38416;&#26126;&#32553;&#25918;&#22914;&#20309;&#22686;&#21152;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#26041;&#38754;&#34920;&#29616;&#20986;&#20102;&#20986;&#33394;&#30340;&#24615;&#33021;&#65292;&#20294;&#23427;&#20204;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#30340;&#37096;&#32626;&#30001;&#20110;&#23545;&#22270;&#20687;&#25439;&#22351;&#30340;&#25935;&#24863;&#24615;&#32780;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#29616;&#26377;&#30340;&#23646;&#24615;&#26041;&#27861;&#23545;&#20110;&#35299;&#37322;&#23545;&#22270;&#20687;&#25439;&#22351;&#30340;&#25935;&#24863;&#24615;&#26159;&#26080;&#25928;&#30340;&#65292;&#32780;&#24378;&#20581;&#24615;&#39046;&#22495;&#30340;&#25991;&#29486;&#20165;&#25552;&#20379;&#22522;&#20110;&#27169;&#22411;&#30340;&#35299;&#37322;&#12290;&#28982;&#32780;&#65292;&#22312;&#22270;&#20687;&#25439;&#22351;&#30340;&#24773;&#20917;&#19979;&#65292;&#23457;&#26597;&#27169;&#22411;&#30340;&#34892;&#20026;&#33021;&#21147;&#23545;&#20110;&#25552;&#39640;&#29992;&#25143;&#20449;&#20219;&#33267;&#20851;&#37325;&#35201;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;Wavelet sCale Attribution Method (WCAM)&#65292;&#23427;&#26159;&#20174;&#20687;&#32032;&#22495;&#21040;&#31354;&#38388;&#23610;&#24230;&#22495;&#30340;&#23646;&#24615;&#26041;&#27861;&#30340;&#27010;&#25324;&#12290;&#22312;&#31354;&#38388;&#23610;&#24230;&#22495;&#20013;&#36827;&#34892;&#23646;&#24615;&#25581;&#31034;&#20102;&#27169;&#22411;&#30340;&#20851;&#27880;&#28857;&#21644;&#23610;&#24230;&#12290;&#25105;&#20204;&#23637;&#31034;WCAM&#35299;&#37322;&#20102;&#27169;&#22411;&#22312;&#22270;&#20687;&#30772;&#22351;&#19979;&#30340;&#22833;&#25928;&#65292;&#30830;&#23450;&#20102;&#39044;&#27979;&#30340;&#36275;&#22815;&#20449;&#24687;&#65292;&#24182;&#35299;&#37322;&#20102;&#22914;&#20309;&#36890;&#36807;&#32553;&#25918;&#22686;&#21152;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural networks have shown remarkable performance in computer vision, but their deployment in real-world scenarios is challenging due to their sensitivity to image corruptions. Existing attribution methods are uninformative for explaining the sensitivity to image corruptions, while the literature on robustness only provides model-based explanations. However, the ability to scrutinize models' behavior under image corruptions is crucial to increase the user's trust. Towards this end, we introduce the Wavelet sCale Attribution Method (WCAM), a generalization of attribution from the pixel domain to the space-scale domain. Attribution in the space-scale domain reveals where and on what scales the model focuses. We show that the WCAM explains models' failures under image corruptions, identifies sufficient information for prediction, and explains how zoom-in increases accuracy.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27010;&#29575;&#25351;&#25968;&#31215;&#20998;&#22120;&#65292;&#23427;&#22312;&#22788;&#29702;&#21018;&#24615;&#31995;&#32479;&#26102;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#33021;&#22815;&#25552;&#20379;&#25968;&#20540;&#35823;&#24046;&#30340;&#27010;&#29575;&#35299;&#37322;&#65292;&#24182;&#19988;&#33021;&#22815;&#34987;&#24212;&#29992;&#20110;&#24191;&#27867;&#30340;&#38750;&#32447;&#24615;&#31995;&#32479;&#20013;&#12290;</title><link>http://arxiv.org/abs/2305.14978</link><description>&lt;p&gt;
&#27010;&#29575;&#25351;&#25968;&#31215;&#20998;&#22120;
&lt;/p&gt;
&lt;p&gt;
Probabilistic Exponential Integrators. (arXiv:2305.14978v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14978
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27010;&#29575;&#25351;&#25968;&#31215;&#20998;&#22120;&#65292;&#23427;&#22312;&#22788;&#29702;&#21018;&#24615;&#31995;&#32479;&#26102;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#33021;&#22815;&#25552;&#20379;&#25968;&#20540;&#35823;&#24046;&#30340;&#27010;&#29575;&#35299;&#37322;&#65292;&#24182;&#19988;&#33021;&#22815;&#34987;&#24212;&#29992;&#20110;&#24191;&#27867;&#30340;&#38750;&#32447;&#24615;&#31995;&#32479;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27010;&#29575;&#27714;&#35299;&#22120;&#20026;&#21160;&#24577;&#31995;&#32479;&#30340;&#27169;&#25311;&#12289;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#25512;&#26029;&#25552;&#20379;&#20102;&#28789;&#27963;&#21644;&#39640;&#25928;&#30340;&#26694;&#26550;&#12290;&#28982;&#32780;&#65292;&#22312;&#26576;&#20123;&#21018;&#24615;&#31995;&#32479;&#20013;&#65292;&#23427;&#20204;&#20687;&#26631;&#20934;&#27714;&#35299;&#22120;&#19968;&#26679;&#20250;&#36935;&#21040;&#24615;&#33021;&#24809;&#32602;&#65292;&#22240;&#20026;&#38656;&#35201;&#37319;&#21462;&#23567;&#27493;&#38271;&#19981;&#26159;&#20026;&#20102;&#25968;&#20540;&#31934;&#24230;&#65292;&#32780;&#26159;&#20026;&#20102;&#31283;&#23450;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#30340;&#27010;&#29575;&#25351;&#25968;&#31215;&#20998;&#22120;&#26497;&#22823;&#22320;&#32531;&#35299;&#20102;&#36825;&#20010;&#38382;&#39064;&#12290;&#36890;&#36807;&#23558;&#24555;&#36895;&#12289;&#32447;&#24615;&#21160;&#24577;&#21152;&#20837;&#20808;&#39564;&#20013;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#19968;&#31867;&#20855;&#26377;&#26377;&#21033;&#24615;&#36136;&#30340;&#27010;&#29575;&#31215;&#20998;&#22120;&#12290;&#21363;&#23427;&#20204;&#34987;&#35777;&#26126;&#26159;L-&#31283;&#23450;&#30340;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#23427;&#20204;&#20250;&#38477;&#20302;&#21040;&#32463;&#20856;&#30340;&#25351;&#25968;&#31215;&#20998;&#22120;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#25968;&#20540;&#35823;&#24046;&#30340;&#27010;&#29575;&#35299;&#37322;&#12290;&#36890;&#36807;&#22312;&#20808;&#21069;&#20272;&#35745;&#20540;&#30340;&#21521;&#37327;&#22330;&#38597;&#21487;&#27604;&#19978;&#24378;&#21152;&#20998;&#27573;&#21322;&#32447;&#24615;&#65292;&#35813;&#26041;&#27861;&#36824;&#25512;&#24191;&#21040;&#20219;&#24847;&#38750;&#32447;&#24615;&#31995;&#32479;&#65292;&#20174;&#32780;&#20135;&#29983;&#20102;&#33021;&#22815;&#22312;&#24191;&#27867;&#30340;&#21018;&#24615;&#38382;&#39064;&#20013;&#20445;&#25345;&#31283;&#23450;&#24615;&#21644;&#20934;&#30830;&#24615;&#30340;&#27010;&#29575;&#25351;&#25968;&#31215;&#20998;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Probabilistic solvers provide a flexible and efficient framework for simulation, uncertainty quantification, and inference in dynamical systems. However, like standard solvers, they suffer performance penalties for certain stiff systems, where small steps are required not for reasons of numerical accuracy but for the sake of stability. This issue is greatly alleviated in semi-linear problems by the probabilistic exponential integrators developed in this paper. By including the fast, linear dynamics in the prior, we arrive at a class of probabilistic integrators with favorable properties. Namely, they are proven to be L-stable, and in a certain case reduce to a classic exponential integrator -- with the added benefit of providing a probabilistic account of the numerical error. The method is also generalized to arbitrary non-linear systems by imposing piece-wise semi-linearity on the prior via Jacobians of the vector field at the previous estimates, resulting in probabilistic exponential
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#30340;&#31639;&#27861;&#26159;&#23398;&#20064;&#29575;&#26080;&#20851;&#30340;&#32422;&#26463;&#22495;&#37319;&#26679;&#31639;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#26694;&#26550;&#65292;&#33021;&#22815;&#22788;&#29702;&#22810;&#31181;&#32422;&#26463;&#37319;&#26679;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#19982;&#29616;&#26377;&#31639;&#27861;&#30456;&#31454;&#20105;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.14943</link><description>&lt;p&gt;
&#23398;&#20064;&#29575;&#26080;&#20851;&#30340;&#32422;&#26463;&#22495;Bayesian&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Learning Rate Free Bayesian Inference in Constrained Domains. (arXiv:2305.14943v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14943
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30340;&#31639;&#27861;&#26159;&#23398;&#20064;&#29575;&#26080;&#20851;&#30340;&#32422;&#26463;&#22495;&#37319;&#26679;&#31639;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#26694;&#26550;&#65292;&#33021;&#22815;&#22788;&#29702;&#22810;&#31181;&#32422;&#26463;&#37319;&#26679;&#38382;&#39064;&#65292;&#23454;&#29616;&#20102;&#19982;&#29616;&#26377;&#31639;&#27861;&#30456;&#31454;&#20105;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#22871;&#26032;&#30340;&#22522;&#20110;&#31890;&#23376;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#22312;&#32422;&#26463;&#22495;&#20869;&#36827;&#34892;&#37319;&#26679;&#65292;&#36825;&#26159;&#23436;&#20840;&#19982;&#23398;&#20064;&#29575;&#26080;&#20851;&#30340;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21033;&#29992;&#20102;&#20984;&#20248;&#21270;&#20013;&#30340;&#30828;&#24065;&#25237;&#27880;&#24605;&#24819;&#65292;&#20197;&#21450;&#32422;&#26463;&#37319;&#26679;&#20316;&#20026;&#27010;&#29575;&#27979;&#24230;&#31354;&#38388;&#19978;&#38236;&#20687;&#20248;&#21270;&#38382;&#39064;&#30340;&#35266;&#28857;&#12290;&#22522;&#20110;&#36825;&#20010;&#35266;&#28857;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#26694;&#26550;&#65292;&#29992;&#20110;&#20960;&#31181;&#29616;&#26377;&#30340;&#32422;&#26463;&#37319;&#26679;&#31639;&#27861;&#65292;&#21253;&#25324;&#38236;&#20687;Langevin&#21160;&#21147;&#23398;&#21644;&#38236;&#20687;Stein&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#12290;&#25105;&#20204;&#22312;&#19968;&#31995;&#21015;&#30340;&#25968;&#20540;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#31639;&#27861;&#30340;&#24615;&#33021;&#65292;&#21253;&#25324;&#20174;&#21333;&#32431;&#24418;&#30446;&#26631;&#36827;&#34892;&#37319;&#26679;&#12289;&#24102;&#20844;&#24179;&#24615;&#32422;&#26463;&#36827;&#34892;&#37319;&#26679;&#20197;&#21450;&#21518;&#36873;&#25321;&#25512;&#26029;&#20013;&#30340;&#32422;&#26463;&#37319;&#26679;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#19981;&#38656;&#35201;&#35843;&#25972;&#20219;&#20309;&#36229;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#23454;&#29616;&#20102;&#19982;&#29616;&#26377;&#32422;&#26463;&#37319;&#26679;&#26041;&#27861;&#30456;&#31454;&#20105;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a suite of new particle-based algorithms for sampling on constrained domains which are entirely learning rate free. Our approach leverages coin betting ideas from convex optimisation, and the viewpoint of constrained sampling as a mirrored optimisation problem on the space of probability measures. Based on this viewpoint, we also introduce a unifying framework for several existing constrained sampling algorithms, including mirrored Langevin dynamics and mirrored Stein variational gradient descent. We demonstrate the performance of our algorithms on a range of numerical examples, including sampling from targets on the simplex, sampling with fairness constraints, and constrained sampling problems in post-selection inference. Our results indicate that our algorithms achieve competitive performance with existing constrained sampling methods, without the need to tune any hyperparameters.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26080;&#38656;&#35843;&#21442;&#30340;&#22522;&#20110;&#31890;&#23376;&#30340;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#65292;&#20854;&#20013;&#19968;&#31181;&#26159;&#36890;&#36807;&#32771;&#34385;&#36793;&#32536;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#20026;&#33258;&#30001;&#33021;&#27867;&#20989;&#26368;&#23567;&#21270;&#24471;&#21040;&#30340;&#65292;&#21478;&#19968;&#31181;&#26159;&#29992;&#20110;&#20248;&#21270;&#35813;&#38382;&#39064;&#30340;&#31639;&#27861;&#65292;&#23436;&#20840;&#26080;&#38656;&#35843;&#21442;&#12290;</title><link>http://arxiv.org/abs/2305.14916</link><description>&lt;p&gt;
CoinEM&#65306;&#26080;&#38656;&#35843;&#21442;&#30340;&#22522;&#20110;&#31890;&#23376;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#21464;&#20998;&#25512;&#26029;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
CoinEM: Tuning-Free Particle-Based Variational Inference for Latent Variable Models. (arXiv:2305.14916v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14916
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#26080;&#38656;&#35843;&#21442;&#30340;&#22522;&#20110;&#31890;&#23376;&#30340;&#21464;&#20998;&#25512;&#26029;&#31639;&#27861;&#65292;&#20854;&#20013;&#19968;&#31181;&#26159;&#36890;&#36807;&#32771;&#34385;&#36793;&#32536;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#20026;&#33258;&#30001;&#33021;&#27867;&#20989;&#26368;&#23567;&#21270;&#24471;&#21040;&#30340;&#65292;&#21478;&#19968;&#31181;&#26159;&#29992;&#20110;&#20248;&#21270;&#35813;&#38382;&#39064;&#30340;&#31639;&#27861;&#65292;&#23436;&#20840;&#26080;&#38656;&#35843;&#21442;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20004;&#31181;&#22522;&#20110;&#31890;&#23376;&#30340;&#26032;&#22411;&#31639;&#27861;&#65292;&#29992;&#20110;&#36890;&#36807;&#36793;&#38469;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#23398;&#20064;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#20854;&#20013;&#19968;&#31181;&#23436;&#20840;&#26080;&#38656;&#35843;&#21442;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#23558;&#36793;&#38469;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#35270;&#20026;&#20248;&#21270;&#38382;&#39064;&#30340;&#35282;&#24230;&#65306;&#21363;&#23558;&#20854;&#35270;&#20026;&#33258;&#30001;&#33021;&#27867;&#20989;&#30340;&#26368;&#23567;&#21270;&#12290;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#19968;&#31181;&#26041;&#27861;&#26159;&#32771;&#34385;&#33258;&#30001;&#33021;&#20851;&#32852;&#30340;&#26799;&#24230;&#27969;&#30340;&#31163;&#25955;&#21270;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#31867;&#20284;&#20110;&#27969;&#34892;&#30340; Stein &#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#26041;&#27861;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#20026;&#27492;&#31639;&#27861;&#24314;&#31435;&#20102;&#19979;&#38477;&#24341;&#29702;&#65292;&#20445;&#35777;&#20102;&#33258;&#30001;&#33021;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#19979;&#38477;&#12290;&#20294;&#27492;&#26041;&#27861;&#21644;&#20854;&#20182;&#30001;&#26799;&#24230;&#27969;&#30340;&#31163;&#25955;&#21270;&#24471;&#21040;&#30340;&#26041;&#27861;&#37117;&#24517;&#39035;&#20381;&#36182;&#20110;&#23398;&#20064;&#29575;&#65292;&#35813;&#23398;&#20064;&#29575;&#24517;&#39035;&#30001;&#20174;&#19994;&#32773;&#20180;&#32454;&#35843;&#25972;&#65292;&#20197;&#30830;&#20445;&#20197;&#21512;&#36866;&#30340;&#36895;&#29575;&#25910;&#25947;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#21478;&#19968;&#31181;&#31639;&#27861;&#29992;&#20110;&#20248;&#21270;&#36825;&#20010;&#38382;&#39064;&#65292;&#35813;&#31639;&#27861;&#26159;&#23436;&#20840;&#26080;&#38656;&#35843;&#21442;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce two new particle-based algorithms for learning latent variable models via marginal maximum likelihood estimation, including one which is entirely tuning-free. Our methods are based on the perspective of marginal maximum likelihood estimation as an optimization problem: namely, as the minimization of a free energy functional. One way to solve this problem is to consider the discretization of a gradient flow associated with the free energy. We study one such approach, which resembles an extension of the popular Stein variational gradient descent algorithm. In particular, we establish a descent lemma for this algorithm, which guarantees that the free energy decreases at each iteration. This method, and any other obtained as the discretization of the gradient flow, will necessarily depend on a learning rate which must be carefully tuned by the practitioner in order to ensure convergence at a suitable rate. With this in mind, we also propose another algorithm for optimizing the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#20154;&#31867;&#21453;&#39304;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#22914;&#20309;&#20272;&#35745;&#38544;&#24335;&#22870;&#21169;&#20197;&#21450;&#22312;&#32622;&#20449;&#38598;&#21608;&#22260;&#35299;&#20915;&#35268;&#21010;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#20010;&#33021;&#22815;&#20351;&#29992;&#22810;&#39033;&#24335;&#25968;&#37327;&#30340;&#26679;&#26412;&#23398;&#20064;&#20219;&#20309;&#30446;&#26631;&#31574;&#30053;&#30340;&#26032;&#20445;&#35777;&#65292;&#21516;&#26102;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#21333;&#31574;&#30053;&#38598;&#20013;&#31995;&#25968;&#26469;&#34913;&#37327;&#30446;&#26631;&#31574;&#30053;&#30340;&#35206;&#30422;&#33539;&#22260;&#12290;</title><link>http://arxiv.org/abs/2305.14816</link><description>&lt;p&gt;
&#20855;&#26377;&#20154;&#31867;&#21453;&#39304;&#30340;&#21487;&#35777;&#26126;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Provable Offline Reinforcement Learning with Human Feedback. (arXiv:2305.14816v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14816
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#20154;&#31867;&#21453;&#39304;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#22914;&#20309;&#20272;&#35745;&#38544;&#24335;&#22870;&#21169;&#20197;&#21450;&#22312;&#32622;&#20449;&#38598;&#21608;&#22260;&#35299;&#20915;&#35268;&#21010;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#20010;&#33021;&#22815;&#20351;&#29992;&#22810;&#39033;&#24335;&#25968;&#37327;&#30340;&#26679;&#26412;&#23398;&#20064;&#20219;&#20309;&#30446;&#26631;&#31574;&#30053;&#30340;&#26032;&#20445;&#35777;&#65292;&#21516;&#26102;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#21333;&#31574;&#30053;&#38598;&#20013;&#31995;&#25968;&#26469;&#34913;&#37327;&#30446;&#26631;&#31574;&#30053;&#30340;&#35206;&#30422;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#21453;&#39304;&#26159;&#20197;&#36712;&#36857;&#23545;&#20043;&#38388;&#30340;&#20559;&#22909;&#24418;&#24335;&#25552;&#20379;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#21253;&#25324;&#20004;&#20010;&#20027;&#35201;&#27493;&#39588;&#65306;&#65288;1&#65289;&#20351;&#29992;&#36890;&#29992;&#20989;&#25968;&#36924;&#36817;&#20174;&#31163;&#32447;&#25968;&#25454;&#20272;&#35745;&#38544;&#24335;&#22870;&#21169;&#65292;&#21644;&#65288;2&#65289;&#22312;MLE&#21608;&#22260;&#30340;&#32622;&#20449;&#38598;&#19978;&#35299;&#20915;&#20998;&#24067;&#40065;&#26834;&#30340;&#35268;&#21010;&#38382;&#39064;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#36890;&#29992;&#30340;&#22870;&#21169;&#35774;&#32622;&#65292;&#20854;&#20013;&#22870;&#21169;&#21487;&#20197;&#22312;&#25972;&#20010;&#36712;&#36857;&#19978;&#23450;&#20041;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#30340;&#20445;&#35777;&#65292;&#21482;&#35201;&#30446;&#26631;&#31574;&#30053;&#34987;&#31163;&#32447;&#25968;&#25454;&#35206;&#30422;&#65292;&#25105;&#20204;&#23601;&#21487;&#20197;&#20351;&#29992;&#22810;&#39033;&#24335;&#25968;&#37327;&#30340;&#26679;&#26412;&#26469;&#23398;&#20064;&#20219;&#20309;&#30446;&#26631;&#31574;&#30053;&#12290;&#20026;&#20102;&#34913;&#37327;&#30446;&#26631;&#31574;&#30053;&#30340;&#35206;&#30422;&#33539;&#22260;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#21333;&#31574;&#30053;&#38598;&#20013;&#31995;&#25968;&#65292;&#21487;&#20197;&#36890;&#36807;&#27599;&#20010;&#36712;&#36857;&#30340;&#38598;&#20013;&#31995;&#25968;&#19978;&#30028;&#26469;&#19978;&#30028;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we investigate the problem of offline reinforcement learning with human feedback where feedback is available in the form of preference between trajectory pairs rather than explicit rewards. Our proposed algorithm consists of two main steps: (1) estimate the implicit reward using Maximum Likelihood Estimation (MLE) with general function approximation from offline data and (2) solve a distributionally robust planning problem over a confidence set around the MLE. We consider the general reward setting where the reward can be defined over the whole trajectory and provide a novel guarantee that allows us to learn any target policy with a polynomial number of samples, as long as the target policy is covered by the offline data. This guarantee is the first of its kind with general function approximation. To measure the coverage of the target policy, we introduce a new single-policy concentrability coefficient, which can be upper bounded by the per-trajectory concentrability coe
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#38543;&#26426;&#22270;&#19978;&#31561;&#21464;GNN&#35745;&#31639;&#33410;&#28857;&#20219;&#21153;&#25152;&#29983;&#25104;&#30340;&#20989;&#25968;&#31354;&#38388;&#65292;&#24378;&#35843;&#20102;&#36755;&#20837;&#33410;&#28857;&#29305;&#24449;&#30340;&#20316;&#29992;&#21644;&#33410;&#28857;&#20301;&#32622;&#32534;&#30721;&#65288;PE&#65289;&#23545;&#34920;&#29616;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2305.14814</link><description>&lt;p&gt;
&#38543;&#26426;&#22270;&#19978;&#22270;&#31070;&#32463;&#32593;&#32476;&#33021;&#35745;&#31639;&#21738;&#20123;&#20989;&#25968;&#65311;&#20301;&#32622;&#32534;&#30721;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
What functions can Graph Neural Networks compute on random graphs? The role of Positional Encoding. (arXiv:2305.14814v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14814
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22411;&#38543;&#26426;&#22270;&#19978;&#31561;&#21464;GNN&#35745;&#31639;&#33410;&#28857;&#20219;&#21153;&#25152;&#29983;&#25104;&#30340;&#20989;&#25968;&#31354;&#38388;&#65292;&#24378;&#35843;&#20102;&#36755;&#20837;&#33410;&#28857;&#29305;&#24449;&#30340;&#20316;&#29992;&#21644;&#33410;&#28857;&#20301;&#32622;&#32534;&#30721;&#65288;PE&#65289;&#23545;&#34920;&#29616;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#28145;&#20837;&#29702;&#35299;&#22823;&#35268;&#27169;&#22270;&#20013;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#30340;&#34920;&#36798;&#33021;&#21147;&#12290;&#29616;&#26377;&#30340;&#20998;&#26512;&#23558;&#36825;&#20010;&#27010;&#24565;&#19982;&#22270;&#21516;&#26500;&#38382;&#39064;&#32852;&#31995;&#36215;&#26469;&#65292;&#36825;&#23545;&#20110;&#23567;&#35268;&#27169;&#30340;&#22270;&#26368;&#20026;&#30456;&#20851;&#65292;&#25110;&#32773;&#26159;&#30740;&#31350;&#20102;&#22270;&#20998;&#31867;&#25110;&#22238;&#24402;&#20219;&#21153;&#65292;&#32780;&#33410;&#28857;&#19978;&#30340;&#39044;&#27979;&#20219;&#21153;&#21017;&#26356;&#21152;&#30456;&#20851;&#12290;&#26368;&#36817;&#65292;&#20960;&#20010;&#20316;&#21697;&#34920;&#26126;&#65292;&#22312;&#38750;&#24120;&#36890;&#29992;&#30340;&#38543;&#26426;&#22270;&#27169;&#22411;&#19978;&#65292;&#38543;&#30528;&#33410;&#28857;&#25968;&#37327;&#30340;&#22686;&#21152;&#65292;GNN&#20250;&#25910;&#25947;&#20110;&#26576;&#20123;&#20989;&#25968;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#26356;&#21152;&#23436;&#25972;&#21644;&#30452;&#35266;&#30340;&#25910;&#25947;&#29702;&#35770;&#25551;&#36848;&#20102;&#29992;&#20110;&#33410;&#28857;&#20219;&#21153;&#30340;&#31561;&#21464;GNN&#29983;&#25104;&#30340;&#20989;&#25968;&#31354;&#38388;&#65292;&#35813;&#29702;&#35770;&#21253;&#25324;&#20102;&#20197;&#21069;&#30340;&#20960;&#20010;&#20363;&#23376;&#12290;&#25105;&#20204;&#24378;&#35843;&#20102;&#36755;&#20837;&#33410;&#28857;&#29305;&#24449;&#30340;&#20316;&#29992;&#65292;&#24182;&#30740;&#31350;&#20102;&#33410;&#28857;&#20301;&#32622;&#32534;&#30721;&#65288;PEs&#65289;&#30340;&#24433;&#21709;&#65292;&#36825;&#26159;&#19968;&#31181;&#26368;&#36817;&#30340;&#30740;&#31350;&#26041;&#21521;&#65292;&#24050;&#32463;&#22312;&#23454;&#36341;&#20013;&#35777;&#26126;&#20102;&#20854;&#22312;&#34920;&#29616;&#19978;&#30340;&#26368;&#20339;&#32467;&#26524;&#12290;&#36890;&#36807;&#23545;&#22823;&#22411;&#38543;&#26426;&#22270;&#19978;&#22810;&#20010;PE&#31034;&#20363;&#30340;&#30740;&#31350;&#65292;
&lt;/p&gt;
&lt;p&gt;
We aim to deepen the theoretical understanding of Graph Neural Networks (GNNs) on large graphs, with a focus on their expressive power. Existing analyses relate this notion to the graph isomorphism problem, which is mostly relevant for graphs of small sizes, or studied graph classification or regression tasks, while prediction tasks on nodes are far more relevant on large graphs. Recently, several works showed that, on very general random graphs models, GNNs converge to certains functions as the number of nodes grows. In this paper, we provide a more complete and intuitive description of the function space generated by equivariant GNNs for node-tasks, through general notions of convergence that encompass several previous examples. We emphasize the role of input node features, and study the impact of node Positional Encodings (PEs), a recent line of work that has been shown to yield state-of-the-art results in practice. Through the study of several examples of PEs on large random graphs
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33410;&#28857;&#31232;&#30095;BNN&#27169;&#22411;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#21518;&#39564;&#27987;&#24230;&#36895;&#29575;&#25509;&#36817;&#26368;&#23567;&#21270;&#26368;&#20248;&#12290;&#21516;&#26102;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;MCMC&#31639;&#27861;&#65292;&#20351;&#33410;&#28857;&#31232;&#30095;BNN&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#22312;&#23454;&#36341;&#20013;&#21464;&#24471;&#21487;&#34892;&#12290;</title><link>http://arxiv.org/abs/2305.14765</link><description>&lt;p&gt;
&#25513;&#30721;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;: &#29702;&#35770;&#20445;&#35777;&#21450;&#21518;&#39564;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Masked Bayesian Neural Networks : Theoretical Guarantee and its Posterior Inference. (arXiv:2305.14765v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14765
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33410;&#28857;&#31232;&#30095;BNN&#27169;&#22411;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#21518;&#39564;&#27987;&#24230;&#36895;&#29575;&#25509;&#36817;&#26368;&#23567;&#21270;&#26368;&#20248;&#12290;&#21516;&#26102;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;MCMC&#31639;&#27861;&#65292;&#20351;&#33410;&#28857;&#31232;&#30095;BNN&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#22312;&#23454;&#36341;&#20013;&#21464;&#24471;&#21487;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#26041;&#27861;&#22312;&#23398;&#20064;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;BNN&#65289;&#26041;&#38754;&#22791;&#21463;&#20851;&#27880;&#24182;&#25104;&#21151;&#24212;&#29992;&#20110;&#21508;&#31181;&#24212;&#29992;&#20013;&#12290;&#29305;&#21035;&#22320;&#65292;BNN&#20855;&#26377;&#26356;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#21644;&#26356;&#22909;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#20026;&#20102;BNN&#30340;&#25104;&#21151;&#65292;&#23547;&#25214;&#36866;&#24403;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#26159;&#19968;&#39033;&#37325;&#35201;&#20219;&#21153;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#21508;&#31181;&#31639;&#27861;&#26469;&#25214;&#21040;&#22909;&#30340;&#31232;&#30095;&#31070;&#32463;&#32593;&#32476;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33410;&#28857;&#31232;&#30095;BNN&#27169;&#22411;&#65292;&#20855;&#26377;&#33391;&#22909;&#30340;&#29702;&#35770;&#24615;&#36136;&#21644;&#35745;&#31639;&#21487;&#34892;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#30495;&#23454;&#27169;&#22411;&#30340;&#21518;&#39564;&#27987;&#24230;&#36895;&#29575;&#25509;&#36817;&#26368;&#23567;&#21270;&#26368;&#20248;&#65292;&#24182;&#19988;&#36866;&#24212;&#30495;&#23454;&#27169;&#22411;&#30340;&#24179;&#28369;&#24230;&#12290;&#29305;&#21035;&#26159;&#65292;&#35813;&#36866;&#24212;&#24615;&#26159;&#33410;&#28857;&#31232;&#30095;BNN&#30340;&#39318;&#20010;&#36866;&#24212;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;MCMC&#31639;&#27861;&#65292;&#20351;&#33410;&#28857;&#31232;&#30095;BNN&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#22312;&#23454;&#36341;&#20013;&#21464;&#24471;&#21487;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian approaches for learning deep neural networks (BNN) have been received much attention and successfully applied to various applications. Particularly, BNNs have the merit of having better generalization ability as well as better uncertainty quantification. For the success of BNN, search an appropriate architecture of the neural networks is an important task, and various algorithms to find good sparse neural networks have been proposed. In this paper, we propose a new node-sparse BNN model which has good theoretical properties and is computationally feasible. We prove that the posterior concentration rate to the true model is near minimax optimal and adaptive to the smoothness of the true model. In particular the adaptiveness is the first of its kind for node-sparse BNNs. In addition, we develop a novel MCMC algorithm which makes the Bayesian inference of the node-sparse BNN model feasible in practice.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;Wasserstein&#39640;&#26031;&#21270;&#36716;&#25442;&#30340;&#36716;&#25442;&#26041;&#27861;&#65292;&#29992;&#20110;&#38024;&#23545;&#36125;&#21494;&#26031;&#21512;&#25104;&#20284;&#28982;(BSL)&#20013;&#27719;&#24635;&#32479;&#35745;&#37327;&#30340;&#20998;&#24067;&#38382;&#39064;&#12290;&#23558;Wasserstein&#39640;&#26031;&#21270;&#36716;&#25442;&#19982;&#40065;&#26834;BSL&#21644;&#39640;&#25928;&#30340;&#21464;&#20998;&#36125;&#21494;&#26031;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#39640;&#25928;&#21487;&#38752;&#30340;&#36866;&#29992;&#20110;&#26080;&#20284;&#28982;&#38382;&#39064;&#30340;&#36817;&#20284;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.14746</link><description>&lt;p&gt;
Wasserstein&#39640;&#26031;&#36716;&#25442;&#21644;&#40065;&#26834;&#36125;&#21494;&#26031;&#21512;&#25104;&#20284;&#28982;&#30340;&#39640;&#25928;&#21464;&#20998;&#36125;&#21494;&#26031;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Wasserstein Gaussianization and Efficient Variational Bayes for Robust Bayesian Synthetic Likelihood. (arXiv:2305.14746v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14746
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;Wasserstein&#39640;&#26031;&#21270;&#36716;&#25442;&#30340;&#36716;&#25442;&#26041;&#27861;&#65292;&#29992;&#20110;&#38024;&#23545;&#36125;&#21494;&#26031;&#21512;&#25104;&#20284;&#28982;(BSL)&#20013;&#27719;&#24635;&#32479;&#35745;&#37327;&#30340;&#20998;&#24067;&#38382;&#39064;&#12290;&#23558;Wasserstein&#39640;&#26031;&#21270;&#36716;&#25442;&#19982;&#40065;&#26834;BSL&#21644;&#39640;&#25928;&#30340;&#21464;&#20998;&#36125;&#21494;&#26031;&#26041;&#27861;&#30456;&#32467;&#21512;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#39640;&#25928;&#21487;&#38752;&#30340;&#36866;&#29992;&#20110;&#26080;&#20284;&#28982;&#38382;&#39064;&#30340;&#36817;&#20284;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#21512;&#25104;&#20284;&#28982;(BSL)&#26041;&#27861;&#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#26080;&#20284;&#28982;&#36125;&#21494;&#26031;&#25512;&#26029;&#24037;&#20855;&#12290;&#35813;&#26041;&#27861;&#20551;&#23450;&#26576;&#20123;&#27719;&#24635;&#32479;&#35745;&#37327;&#26381;&#20174;&#27491;&#24577;&#20998;&#24067;&#65292;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#21487;&#33021;&#26159;&#19981;&#27491;&#30830;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;Wasserstein&#39640;&#26031;&#21270;&#36716;&#25442;&#30340;&#36716;&#25442;&#26041;&#27861;&#65292;&#20351;&#29992;Wasserstein&#26799;&#24230;&#27969;&#23558;&#27719;&#24635;&#32479;&#35745;&#37327;&#30340;&#20998;&#24067;&#36817;&#20284;&#36716;&#25442;&#20026;&#27491;&#24577;&#20998;&#24067;&#12290;BSL&#38544;&#21547;&#22320;&#35201;&#27714;&#27169;&#25311;&#27719;&#24635;&#32479;&#35745;&#37327;&#22312;&#24037;&#20316;&#27169;&#22411;&#19979;&#19982;&#35266;&#23519;&#21040;&#30340;&#27719;&#24635;&#32479;&#35745;&#37327;&#20860;&#23481;&#12290;&#36817;&#26399;&#24050;&#24320;&#21457;&#20102;&#19968;&#31181;&#40065;&#26834;&#30340;BSL&#21464;&#20307;&#26469;&#23454;&#29616;&#36825;&#19968;&#28857;&#12290;&#25105;&#20204;&#23558;Wasserstein&#39640;&#26031;&#21270;&#36716;&#25442;&#19982;&#40065;&#26834;BSL&#20197;&#21450;&#39640;&#25928;&#30340;&#21464;&#20998;&#36125;&#21494;&#26031;&#36807;&#31243;&#32467;&#21512;&#36215;&#26469;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#39640;&#25928;&#21487;&#38752;&#30340;&#36866;&#29992;&#20110;&#26080;&#20284;&#28982;&#38382;&#39064;&#30340;&#36817;&#20284;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Bayesian Synthetic Likelihood (BSL) method is a widely-used tool for likelihood-free Bayesian inference. This method assumes that some summary statistics are normally distributed, which can be incorrect in many applications. We propose a transformation, called the Wasserstein Gaussianization transformation, that uses a Wasserstein gradient flow to approximately transform the distribution of the summary statistics into a Gaussian distribution. BSL also implicitly requires compatibility between simulated summary statistics under the working model and the observed summary statistics. A robust BSL variant which achieves this has been developed in the recent literature. We combine the Wasserstein Gaussianization transformation with robust BSL, and an efficient Variational Bayes procedure for posterior approximation, to develop a highly efficient and reliable approximate Bayesian inference method for likelihood-free problems.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#32447;&#24615;&#25968;&#25454;&#26368;&#23567;&#20108;&#20056;&#23725;&#27491;&#21017;&#21270;&#30340;&#21435;&#22122;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#22312;&#27424;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#20250;&#20986;&#29616;&#21452;&#23792;&#35895;&#29616;&#35937;&#12290;</title><link>http://arxiv.org/abs/2305.14689</link><description>&lt;p&gt;
&#22522;&#20110;&#23725;&#27491;&#21017;&#21270;&#30340;&#32447;&#24615;&#25968;&#25454;&#26368;&#23567;&#20108;&#20056;&#21435;&#22122;&#38382;&#39064;&#30340;&#27424;&#21442;&#25968;&#21270;&#21452;&#35895;&#25928;&#24212;
&lt;/p&gt;
&lt;p&gt;
Under-Parameterized Double Descent for Ridge Regularized Least Squares Denoising of Data on a Line. (arXiv:2305.14689v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14689
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#32447;&#24615;&#25968;&#25454;&#26368;&#23567;&#20108;&#20056;&#23725;&#27491;&#21017;&#21270;&#30340;&#21435;&#22122;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#22312;&#27424;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#20250;&#20986;&#29616;&#21452;&#23792;&#35895;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#35757;&#32451;&#25968;&#25454;&#28857;&#25968;&#12289;&#32479;&#35745;&#27169;&#22411;&#21442;&#25968;&#25968;&#21644;&#27169;&#22411;&#30340;&#27867;&#21270;&#33021;&#21147;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#24050;&#26377;&#30340;&#24037;&#20316;&#34920;&#26126;&#65292;&#36807;&#24230;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#21487;&#33021;&#20986;&#29616;&#21452;&#23792;&#35895;&#29616;&#35937;&#65292;&#32780;&#22312;&#27424;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#21017;&#26222;&#36941;&#23384;&#22312;&#26631;&#20934;&#20559;&#24046;-&#26041;&#24046;&#26435;&#34913;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#20363;&#23376;&#65292;&#21487;&#20197;&#35777;&#26126;&#27424;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#21487;&#20197;&#21457;&#29983;&#21452;&#23792;&#35895;&#29616;&#35937;&#12290;&#32771;&#34385;&#23884;&#20837;&#39640;&#32500;&#31354;&#38388;&#20013;&#30340;&#32447;&#24615;&#25968;&#25454;&#26368;&#23567;&#20108;&#20056;&#21435;&#22122;&#38382;&#39064;&#20013;&#30340;&#23725;&#27491;&#21017;&#21270;&#65292;&#36890;&#36807;&#25512;&#23548;&#20986;&#19968;&#31181;&#28176;&#36817;&#20934;&#30830;&#30340;&#24191;&#20041;&#35823;&#24046;&#20844;&#24335;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#26679;&#26412;&#21644;&#21442;&#25968;&#30340;&#21452;&#35895;&#25928;&#24212;&#65292;&#21452;&#23792;&#35895;&#20301;&#20110;&#25554;&#20540;&#28857;&#21644;&#36807;&#24230;&#21442;&#25968;&#21270;&#21306;&#22495;&#20043;&#38388;&#12290;&#27492;&#22806;&#65292;&#26679;&#26412;&#21452;&#35895;&#26354;&#32447;&#30340;&#39640;&#23792;&#23545;&#24212;&#20110;&#20272;&#35745;&#37327;&#30340;&#33539;&#25968;&#26354;&#32447;&#30340;&#39640;&#23792;&#12290;
&lt;/p&gt;
&lt;p&gt;
The relationship between the number of training data points, the number of parameters in a statistical model, and the generalization capabilities of the model has been widely studied. Previous work has shown that double descent can occur in the over-parameterized regime, and believe that the standard bias-variance trade-off holds in the under-parameterized regime. In this paper, we present a simple example that provably exhibits double descent in the under-parameterized regime. For simplicity, we look at the ridge regularized least squares denoising problem with data on a line embedded in high-dimension space. By deriving an asymptotically accurate formula for the generalization error, we observe sample-wise and parameter-wise double descent with the peak in the under-parameterized regime rather than at the interpolation point or in the over-parameterized regime.  Further, the peak of the sample-wise double descent curve corresponds to a peak in the curve for the norm of the estimator,
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#25439;&#22833;&#40657;&#22622;&#30697;&#38453;&#21644;&#36755;&#20837;-&#36755;&#20986;&#38597;&#20811;&#27604;&#30697;&#38453;&#32852;&#31995;&#36215;&#26469;&#30340;&#20551;&#35774;&#65292;&#37327;&#21270;&#20102;&#27169;&#22411;&#30340;&#36755;&#20837;-&#36755;&#20986;&#38597;&#20811;&#27604;&#30697;&#38453;&#36817;&#20284;&#20854;&#22312;&#25968;&#25454;&#20998;&#24067;&#19978;&#30340;&#21033;&#26222;&#35199;&#33576;&#33539;&#25968;&#30340;&#31243;&#24230;&#65292;&#24182;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#32463;&#39564;&#38597;&#20811;&#27604;&#30697;&#38453;&#30340;&#26032;&#30340;&#27867;&#21270;&#30028;&#65292;&#32473;&#20986;&#20102;&#20851;&#20110;&#36827;&#21270;&#30952;&#38155;&#21644;&#24179;&#22374;&#26497;&#23567;&#30340;&#27867;&#21270;&#24615;&#36136;&#30340;&#26032;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2305.14683</link><description>&lt;p&gt;
&#35770;&#36827;&#21270;&#30952;&#38155;&#12289;&#24179;&#22374;&#26497;&#23567;&#21644;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
On progressive sharpening, flat minima and generalisation. (arXiv:2305.14683v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14683
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#25439;&#22833;&#40657;&#22622;&#30697;&#38453;&#21644;&#36755;&#20837;-&#36755;&#20986;&#38597;&#20811;&#27604;&#30697;&#38453;&#32852;&#31995;&#36215;&#26469;&#30340;&#20551;&#35774;&#65292;&#37327;&#21270;&#20102;&#27169;&#22411;&#30340;&#36755;&#20837;-&#36755;&#20986;&#38597;&#20811;&#27604;&#30697;&#38453;&#36817;&#20284;&#20854;&#22312;&#25968;&#25454;&#20998;&#24067;&#19978;&#30340;&#21033;&#26222;&#35199;&#33576;&#33539;&#25968;&#30340;&#31243;&#24230;&#65292;&#24182;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#32463;&#39564;&#38597;&#20811;&#27604;&#30697;&#38453;&#30340;&#26032;&#30340;&#27867;&#21270;&#30028;&#65292;&#32473;&#20986;&#20102;&#20851;&#20110;&#36827;&#21270;&#30952;&#38155;&#21644;&#24179;&#22374;&#26497;&#23567;&#30340;&#27867;&#21270;&#24615;&#36136;&#30340;&#26032;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#29702;&#35299;&#28145;&#24230;&#23398;&#20064;&#20013;&#25439;&#22833;&#26354;&#29575;&#19982;&#27867;&#21270;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#21033;&#29992;&#29616;&#26377;&#30340;&#28145;&#24230;&#32593;&#32476;&#25439;&#22833;&#40657;&#22622;&#30697;&#38453;&#39057;&#35889;&#32463;&#39564;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#23558;&#25439;&#22833;&#40657;&#22622;&#30697;&#38453;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#36755;&#20837;-&#36755;&#20986;&#38597;&#20811;&#27604;&#30697;&#38453;&#32852;&#31995;&#36215;&#26469;&#30340;&#20551;&#35774;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#31995;&#21015;&#29702;&#35770;&#32467;&#26524;&#65292;&#37327;&#21270;&#20102;&#27169;&#22411;&#30340;&#36755;&#20837;-&#36755;&#20986;&#38597;&#20811;&#27604;&#30697;&#38453;&#36817;&#20284;&#20854;&#22312;&#25968;&#25454;&#20998;&#24067;&#19978;&#30340;&#21033;&#26222;&#35199;&#33576;&#33539;&#25968;&#30340;&#31243;&#24230;&#65292;&#24182;&#25512;&#23548;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#32463;&#39564;&#38597;&#20811;&#27604;&#30697;&#38453;&#30340;&#26032;&#30340;&#27867;&#21270;&#30028;&#12290;&#25105;&#20204;&#21033;&#29992;&#25105;&#20204;&#30340;&#20551;&#35774;&#21644;&#29702;&#35770;&#32467;&#26524;&#65292;&#32473;&#20986;&#20102;&#20851;&#20110;&#26368;&#36817;&#35266;&#23519;&#21040;&#30340;&#36827;&#21270;&#30952;&#38155;&#29616;&#35937;&#20197;&#21450;&#24179;&#22374;&#26497;&#23567;&#30340;&#27867;&#21270;&#24615;&#36136;&#30340;&#26032;&#25551;&#36848;&#12290;&#23454;&#39564;&#35777;&#25454;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#20027;&#24352;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a new approach to understanding the relationship between loss curvature and generalisation in deep learning. Specifically, we use existing empirical analyses of the spectrum of deep network loss Hessians to ground an ansatz tying together the loss Hessian and the input-output Jacobian of a deep neural network. We then prove a series of theoretical results which quantify the degree to which the input-output Jacobian of a model approximates its Lipschitz norm over a data distribution, and deduce a novel generalisation bound in terms of the empirical Jacobian. We use our ansatz, together with our theoretical results, to give a new account of the recently observed progressive sharpening phenomenon, as well as the generalisation properties of flat minima. Experimental evidence is provided to validate our claims.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24403;&#21069;&#25968;&#25454;&#19982;&#21382;&#21490;&#25968;&#25454;&#30456;&#20284;&#24615;&#30340;&#21160;&#24577;&#20449;&#24687;&#20511;&#29992;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#20020;&#24202;&#35797;&#39564;&#20013;&#30830;&#23450;&#26159;&#21542;&#24212;&#35813;&#20511;&#29992;&#21382;&#21490;&#25968;&#25454;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#35797;&#39564;&#30340;&#26816;&#39564;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.14679</link><description>&lt;p&gt;
&#22522;&#20110;&#39057;&#29575;&#23398;&#27966;&#26041;&#27861;&#30340;&#21382;&#21490;&#20449;&#24687;&#21160;&#24577;&#20511;&#29992;&#31574;&#30053;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Dynamic Borrowing Method for Historical Information Using a Frequentist Approach for Hybrid Control Design. (arXiv:2305.14679v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14679
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24403;&#21069;&#25968;&#25454;&#19982;&#21382;&#21490;&#25968;&#25454;&#30456;&#20284;&#24615;&#30340;&#21160;&#24577;&#20449;&#24687;&#20511;&#29992;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#20020;&#24202;&#35797;&#39564;&#20013;&#30830;&#23450;&#26159;&#21542;&#24212;&#35813;&#20511;&#29992;&#21382;&#21490;&#25968;&#25454;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#35797;&#39564;&#30340;&#26816;&#39564;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20511;&#29992;&#21382;&#21490;&#25968;&#25454;&#26469;&#36827;&#34892;&#20020;&#24202;&#35797;&#39564;&#36234;&#26469;&#36234;&#21463;&#21040;&#20851;&#27880;&#65292;&#23588;&#20854;&#22312;&#32597;&#35265;&#30142;&#30149;&#21644;&#20799;&#31185;&#30142;&#30149;&#30340;&#35797;&#39564;&#20013;&#12290;&#34429;&#28982;&#36125;&#21494;&#26031;&#24335;&#30340;&#20511;&#29992;&#26041;&#27861;&#24050;&#32463;&#24471;&#21040;&#20102;&#24191;&#27867;&#24212;&#29992;&#65292;&#20294;&#26368;&#36817;&#25552;&#20986;&#20102;&#22522;&#20110;&#26816;&#39564;&#21644;&#31561;&#25928;&#26816;&#39564;&#27744;&#21270;&#30340;&#39057;&#29575;&#23398;&#27966;&#26041;&#27861;&#26469;&#30830;&#23450;&#26159;&#21542;&#24212;&#35813;&#20351;&#29992;&#21382;&#21490;&#25968;&#25454;&#36827;&#34892;&#32479;&#35745;&#20551;&#35774;&#26816;&#39564;&#12290;&#26681;&#25454;&#20551;&#35774;&#26816;&#39564;&#30340;&#32467;&#26524;&#65292;&#21382;&#21490;&#25968;&#25454;&#21487;&#33021;&#26080;&#27861;&#20351;&#29992;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24403;&#21069;&#25968;&#25454;&#19982;&#21382;&#21490;&#25968;&#25454;&#30456;&#20284;&#24615;&#30340;&#21160;&#24577;&#20449;&#24687;&#20511;&#29992;&#26041;&#27861;&#12290;&#22312;&#25105;&#20204;&#25552;&#20986;&#30340;&#21160;&#24577;&#20449;&#24687;&#20511;&#29992;&#26041;&#27861;&#20013;&#65292;&#20511;&#29992;&#30340;&#25968;&#37327;&#33539;&#22260;&#20174;0&#65285;&#21040;100&#65285;&#65292;&#19982;&#36125;&#21494;&#26031;&#21160;&#24577;&#20511;&#29992;&#30456;&#20284;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26041;&#27861;&#65292;&#20351;&#29992;t&#20998;&#24067;&#30340;&#23494;&#24230;&#20989;&#25968;&#21644;&#36923;&#36753;&#20989;&#25968;&#20316;&#20026;&#30456;&#20284;&#24230;&#30340;&#24230;&#37327;&#26041;&#24335;&#12290;&#25105;&#20204;&#35780;&#20272;&#20102;&#20351;&#29992;&#19981;&#21516;&#26041;&#27861;&#30340;T-test&#30340;&#24615;&#33021;&#65292;&#32467;&#26524;&#34920;&#26126;&#65292;&#20004;&#31181;&#26041;&#27861;&#37117;&#25552;&#39640;&#20102;&#26816;&#39564;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Information borrowing from historical data is gaining attention in clinical trials of rare and pediatric diseases, where statistical power may be insufficient for confirmation of efficacy if the sample size is small. Although Bayesian information borrowing methods are well established, test-then-pool and equivalence-based test-then-pool methods have recently been proposed as frequentist methods to determine whether historical data should be used for statistical hypothesis testing. Depending on the results of the hypothesis testing, historical data may not be usable. This paper proposes a dynamic borrowing method for historical information based on the similarity between current and historical data. In our proposed method of dynamic information borrowing, as in Bayesian dynamic borrowing, the amount of borrowing ranges from 0% to 100%. We propose two methods using the density function of the t-distribution and a logistic function as a similarity measure. We evaluate the performance of t
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#19968;&#31181;&#29992;&#20110;&#26500;&#24314;&#23454;&#35299;&#26512;&#20989;&#25968;&#27169;&#22411;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#23427;&#19981;&#20381;&#36182;&#26799;&#24230;&#19979;&#38477;&#25110;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#65292;&#24182;&#19988;&#36890;&#36807;&#29087;&#24713;&#30340;&#27888;&#21202;&#36924;&#36817;&#26041;&#27861;&#20174;&#23616;&#37096;&#20449;&#24687;&#20013;&#25277;&#26679;&#25968;&#25454;&#65292;&#23454;&#29616;&#20102;&#19968;&#31181;&#38750;&#22343;&#21248;&#23398;&#20064;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2305.14606</link><description>&lt;p&gt;
Taylor&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Taylor Learning. (arXiv:2305.14606v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14606
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#19968;&#31181;&#29992;&#20110;&#26500;&#24314;&#23454;&#35299;&#26512;&#20989;&#25968;&#27169;&#22411;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#23427;&#19981;&#20381;&#36182;&#26799;&#24230;&#19979;&#38477;&#25110;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#65292;&#24182;&#19988;&#36890;&#36807;&#29087;&#24713;&#30340;&#27888;&#21202;&#36924;&#36817;&#26041;&#27861;&#20174;&#23616;&#37096;&#20449;&#24687;&#20013;&#25277;&#26679;&#25968;&#25454;&#65292;&#23454;&#29616;&#20102;&#19968;&#31181;&#38750;&#22343;&#21248;&#23398;&#20064;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#26159;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#20013;&#22823;&#37096;&#20998;&#20248;&#21270;&#30340;&#22522;&#30784;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#20351;&#29992;&#26631;&#35760;&#25968;&#25454;&#26469;&#36924;&#36817;&#26399;&#26395;&#25104;&#26412;&#65288;&#39118;&#38505;&#65289;&#65292;&#23398;&#20064;&#31639;&#27861;&#36890;&#36807;&#25628;&#23547;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#22120;&#26356;&#26032;&#27169;&#22411;&#23450;&#20041;&#21442;&#25968;&#30340;&#20540;&#65292;&#26469;&#36817;&#20284;&#22320;&#26368;&#23567;&#21270;&#26399;&#26395;&#25104;&#26412;&#12290;&#36890;&#24120;&#24773;&#20917;&#19979;&#65292;&#21442;&#25968;&#26356;&#26032;&#37319;&#29992;&#26576;&#31181;&#24418;&#24335;&#30340;&#26799;&#24230;&#19979;&#38477;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#31639;&#27861;&#65292;&#29992;&#20110;&#26500;&#24314;&#23454;&#35299;&#26512;&#20989;&#25968;&#30340;&#27169;&#22411;&#65292;&#26082;&#19981;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#20063;&#19981;&#20351;&#29992;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#36825;&#31867;&#20989;&#25968;&#30001;&#23616;&#37096;&#20449;&#24687;&#23450;&#20041;&#65292;&#23558;&#29087;&#24713;&#30340;&#27888;&#21202;&#36924;&#36817;&#26041;&#27861;&#32622;&#20110;&#20174;&#20998;&#24067;&#20013;&#25277;&#26679;&#25968;&#25454;&#30340;&#32972;&#26223;&#20013;&#65292;&#24182;&#35777;&#26126;&#20102;&#19968;&#31181;&#38750;&#22343;&#21248;&#23398;&#20064;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Empirical risk minimization stands behind most optimization in supervised machine learning. Under this scheme, labeled data is used to approximate an expected cost (risk), and a learning algorithm updates model-defining parameters in search of an empirical risk minimizer, with the aim of thereby approximately minimizing expected cost. Parameter update is often done by some sort of gradient descent. In this paper, we introduce a learning algorithm to construct models for real analytic functions using neither gradient descent nor empirical risk minimization. Observing that such functions are defined by local information, we situate familiar Taylor approximation methods in the context of sampling data from a distribution, and prove a nonuniform learning result.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26367;&#20195;&#22522;&#20110;&#25490;&#24207;&#30340;&#27169;&#25311;&#26657;&#20934;&#65288;SBC&#65289;&#30340;&#28789;&#27963;&#20998;&#31867;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#27979;&#35797;&#32479;&#35745;&#37327;&#65292;&#24182;&#35745;&#31639;&#20986;&#20174;&#20998;&#31867;&#20934;&#30830;&#24230;&#20013;&#35745;&#31639;&#20986;&#30340;&#35823;&#26657;&#20934;&#21457;&#25955;&#24230;&#24230;&#37327;&#65292;&#20855;&#26377;&#26356;&#39640;&#30340;&#32479;&#35745;&#21151;&#25928;&#65292;&#21487;&#20197;&#35299;&#20915;&#22810;&#37325;&#26816;&#39564;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2305.14593</link><description>&lt;p&gt;
&#21028;&#21035;&#26657;&#20934;
&lt;/p&gt;
&lt;p&gt;
Discriminative calibration. (arXiv:2305.14593v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14593
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26367;&#20195;&#22522;&#20110;&#25490;&#24207;&#30340;&#27169;&#25311;&#26657;&#20934;&#65288;SBC&#65289;&#30340;&#28789;&#27963;&#20998;&#31867;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#27979;&#35797;&#32479;&#35745;&#37327;&#65292;&#24182;&#35745;&#31639;&#20986;&#20174;&#20998;&#31867;&#20934;&#30830;&#24230;&#20013;&#35745;&#31639;&#20986;&#30340;&#35823;&#26657;&#20934;&#21457;&#25955;&#24230;&#24230;&#37327;&#65292;&#20855;&#26377;&#26356;&#39640;&#30340;&#32479;&#35745;&#21151;&#25928;&#65292;&#21487;&#20197;&#35299;&#20915;&#22810;&#37325;&#26816;&#39564;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#26816;&#39564;&#36125;&#21494;&#26031;&#35745;&#31639;&#30340;&#20934;&#30830;&#24615;&#65292;&#24120;&#24120;&#20351;&#29992;&#22522;&#20110;&#25490;&#24207;&#30340;&#27169;&#25311;&#26657;&#20934;&#65288;SBC&#65289;&#12290;&#28982;&#32780;&#65292;SBC &#23384;&#22312;&#19968;&#20123;&#32570;&#28857;&#65306;&#27979;&#35797;&#32479;&#35745;&#37327;&#30053;&#26174;&#38543;&#24847;&#65292;&#20132;&#20114;&#24615;&#38590;&#20197;&#26816;&#26597;&#65292;&#22810;&#37325;&#26816;&#39564;&#26159;&#19968;&#20010;&#25361;&#25112;&#65292;&#24182;&#19988;&#24471;&#21040;&#30340; P &#20540;&#19981;&#26159;&#19968;&#31181;&#21457;&#25955;&#24230;&#24230;&#37327;&#12290;&#25105;&#20204;&#25552;&#20986;&#29992;&#19968;&#31181;&#28789;&#27963;&#30340;&#20998;&#31867;&#26041;&#27861;&#26367;&#25442;&#36793;&#32536;&#25490;&#24207;&#26816;&#39564;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#27979;&#35797;&#32479;&#35745;&#37327;&#12290;&#35813;&#24230;&#37327;&#36890;&#24120;&#20855;&#26377;&#27604; SBC &#25490;&#21517;&#26816;&#39564;&#26356;&#39640;&#30340;&#32479;&#35745;&#21151;&#25928;&#65292;&#24182;&#36820;&#22238;&#20174;&#20998;&#31867;&#20934;&#30830;&#24230;&#35745;&#31639;&#20986;&#30340;&#21487;&#35299;&#37322;&#30340;&#35823;&#26657;&#20934;&#21457;&#25955;&#24230;&#24230;&#37327;&#12290;&#27492;&#26041;&#27861;&#21487;&#20197;&#19982;&#19981;&#21516;&#30340;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#19968;&#36215;&#20351;&#29992;&#65292;&#20197;&#24212;&#23545;&#26080;&#38656;&#20284;&#28982;&#25512;&#26029;&#25110;&#20256;&#32479;&#25512;&#26029;&#26041;&#27861;&#65288;&#22914;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#25110;&#21464;&#20998;&#25512;&#26029;&#65289;&#12290;&#25105;&#20204;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#21644;&#32479;&#35745;&#23398;&#21551;&#21457;&#24335;&#29305;&#24449;&#28436;&#31034;&#20102;&#19968;&#31181;&#33258;&#21160;&#21270;&#23454;&#29616;&#65292;&#24182;&#29992;&#25968;&#20540;&#21644;&#30495;&#23454;&#25968;&#25454;&#23454;&#39564;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
To check the accuracy of Bayesian computations, it is common to use rank-based simulation-based calibration (SBC). However, SBC has drawbacks: The test statistic is somewhat ad-hoc, interactions are difficult to examine, multiple testing is a challenge, and the resulting p-value is not a divergence metric. We propose to replace the marginal rank test with a flexible classification approach that learns test statistics from data. This measure typically has a higher statistical power than the SBC rank test and returns an interpretable divergence measure of miscalibration, computed from classification accuracy. This approach can be used with different data generating processes to address likelihood-free inference or traditional inference methods like Markov chain Monte Carlo or variational inference. We illustrate an automated implementation using neural networks and statistically-inspired features, and validate the method with numerical and real data experiments.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#21517;&#20026;DF2M&#30340;&#27169;&#22411;&#65292;&#29992;&#20110;&#20998;&#26512;&#39640;&#32500;&#20989;&#25968;&#26102;&#38388;&#24207;&#21015;&#12290;&#35813;&#27169;&#22411;&#37319;&#29992;&#21360;&#24230;&#33258;&#21161;&#39184;&#36807;&#31243;&#21644;&#28145;&#24230;&#26680;&#20989;&#25968;&#30340;&#22810;&#20219;&#21153;&#39640;&#26031;&#36807;&#31243;&#25429;&#25417;&#26102;&#38388;&#21160;&#24577;&#65292;&#19982;&#20256;&#32479;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30456;&#27604;&#65292;DF2M&#25552;&#20379;&#20102;&#26356;&#22909;&#30340;&#21487;&#35299;&#37322;&#24615;&#21644;&#21331;&#36234;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.14543</link><description>&lt;p&gt;
DF2M&#65306;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#29992;&#20110;&#39640;&#32500;&#20989;&#25968;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#30340;&#28145;&#24230;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
DF2M: An Explainable Deep Bayesian Nonparametric Model for High-Dimensional Functional Time Series. (arXiv:2305.14543v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14543
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#21517;&#20026;DF2M&#30340;&#27169;&#22411;&#65292;&#29992;&#20110;&#20998;&#26512;&#39640;&#32500;&#20989;&#25968;&#26102;&#38388;&#24207;&#21015;&#12290;&#35813;&#27169;&#22411;&#37319;&#29992;&#21360;&#24230;&#33258;&#21161;&#39184;&#36807;&#31243;&#21644;&#28145;&#24230;&#26680;&#20989;&#25968;&#30340;&#22810;&#20219;&#21153;&#39640;&#26031;&#36807;&#31243;&#25429;&#25417;&#26102;&#38388;&#21160;&#24577;&#65292;&#19982;&#20256;&#32479;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30456;&#27604;&#65292;DF2M&#25552;&#20379;&#20102;&#26356;&#22909;&#30340;&#21487;&#35299;&#37322;&#24615;&#21644;&#21331;&#36234;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;Deep Functional Factor Model(DF2M)&#65292;&#19968;&#31181;&#29992;&#20110;&#20998;&#26512;&#39640;&#32500;&#20989;&#25968;&#26102;&#38388;&#24207;&#21015;&#30340;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#27169;&#22411;&#12290;DF2M&#21033;&#29992;&#21360;&#24230;&#33258;&#21161;&#39184;&#36807;&#31243;&#21644;&#28145;&#24230;&#26680;&#20989;&#25968;&#30340;&#22810;&#20219;&#21153;&#39640;&#26031;&#36807;&#31243;&#26469;&#25429;&#25417;&#38750;&#39532;&#23572;&#31185;&#22827;&#21644;&#38750;&#32447;&#24615;&#26102;&#38388;&#21160;&#24577;&#12290;&#19982;&#35768;&#22810;&#40657;&#21283;&#23376;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#19981;&#21516;&#65292;DF2M&#36890;&#36807;&#26500;&#24314;&#22240;&#23376;&#27169;&#22411;&#24182;&#23558;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#34701;&#20837;&#26680;&#20989;&#25968;&#20013;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#21487;&#35299;&#37322;&#30340;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#30340;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#35745;&#31639;&#39640;&#25928;&#30340;&#21464;&#20998;&#25512;&#29702;&#31639;&#27861;&#26469;&#25512;&#26029;DF2M&#12290;&#22235;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#30340;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#20256;&#32479;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30456;&#27604;&#65292;DF2M&#25552;&#20379;&#20102;&#26356;&#22909;&#30340;&#21487;&#35299;&#37322;&#24615;&#21644;&#21331;&#36234;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we present Deep Functional Factor Model (DF2M), a Bayesian nonparametric model for analyzing high-dimensional functional time series. The DF2M makes use of the Indian Buffet Process and the multi-task Gaussian Process with a deep kernel function to capture non-Markovian and nonlinear temporal dynamics. Unlike many black-box deep learning models, the DF2M provides an explainable way to use neural networks by constructing a factor model and incorporating deep neural networks within the kernel function. Additionally, we develop a computationally efficient variational inference algorithm for inferring the DF2M. Empirical results from four real-world datasets demonstrate that the DF2M offers better explainability and superior predictive accuracy compared to conventional deep learning models for high-dimensional functional time series.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31526;&#21512;&#24615;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65288;CF-GNN&#65289;&#65292;&#36890;&#36807;&#23558;&#31526;&#21512;&#24615;&#39044;&#27979;&#65288;CP&#65289;&#25193;&#23637;&#21040;&#22522;&#20110;&#22270;&#30340;&#27169;&#22411;&#20013;&#65292;&#23545;GNN&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#20102;&#26377;&#25928;&#20272;&#35745;&#12290;CF-GNN&#29983;&#25104;&#30340;&#39044;&#27979;&#38598;/&#21306;&#38388;&#21487;&#26681;&#25454;&#39044;&#23450;&#20041;&#30340;&#35206;&#30422;&#27010;&#29575;&#20445;&#35777;&#21253;&#21547;&#30495;&#23454;&#26631;&#31614;&#65292;&#24182;&#19988;&#25552;&#20379;&#20102;&#19968;&#31181;&#20943;&#23569;&#39044;&#27979;&#38598;&#22823;&#23567;/&#21306;&#38388;&#38271;&#24230;&#30340;&#25299;&#25169;&#24847;&#35782;&#36755;&#20986;&#26657;&#27491;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.14535</link><description>&lt;p&gt;
&#29992;&#22522;&#20110;&#31526;&#21512;&#24615;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#23545;&#22270;&#19978;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Uncertainty Quantification over Graph with Conformalized Graph Neural Networks. (arXiv:2305.14535v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14535
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31526;&#21512;&#24615;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65288;CF-GNN&#65289;&#65292;&#36890;&#36807;&#23558;&#31526;&#21512;&#24615;&#39044;&#27979;&#65288;CP&#65289;&#25193;&#23637;&#21040;&#22522;&#20110;&#22270;&#30340;&#27169;&#22411;&#20013;&#65292;&#23545;GNN&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#20102;&#26377;&#25928;&#20272;&#35745;&#12290;CF-GNN&#29983;&#25104;&#30340;&#39044;&#27979;&#38598;/&#21306;&#38388;&#21487;&#26681;&#25454;&#39044;&#23450;&#20041;&#30340;&#35206;&#30422;&#27010;&#29575;&#20445;&#35777;&#21253;&#21547;&#30495;&#23454;&#26631;&#31614;&#65292;&#24182;&#19988;&#25552;&#20379;&#20102;&#19968;&#31181;&#20943;&#23569;&#39044;&#27979;&#38598;&#22823;&#23567;/&#21306;&#38388;&#38271;&#24230;&#30340;&#25299;&#25169;&#24847;&#35782;&#36755;&#20986;&#26657;&#27491;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#29992;&#20110;&#22270;&#32467;&#26500;&#25968;&#25454;&#39044;&#27979;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;GNN&#32570;&#20047;&#20005;&#26684;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#38169;&#35823;&#25104;&#26412;&#26174;&#33879;&#30340;&#29615;&#22659;&#20013;&#30340;&#21487;&#38752;&#37096;&#32626;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31526;&#21512;&#24615;GNN&#65288;CF-GNN&#65289;&#65292;&#23558;&#31526;&#21512;&#24615;&#39044;&#27979;&#65288;CP&#65289;&#25193;&#23637;&#21040;&#22522;&#20110;&#22270;&#30340;&#27169;&#22411;&#20013;&#65292;&#20197;&#33719;&#24471;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#32473;&#23450;&#22270;&#20013;&#30340;&#23454;&#20307;&#65292;CF-GNN&#29983;&#25104;&#19968;&#20010;&#39044;&#27979;&#38598;/&#21306;&#38388;&#65292;&#20197;&#20808;&#39564;&#35206;&#30422;&#27010;&#29575;&#65288;&#20363;&#22914;90%&#65289;&#30340;&#26041;&#24335;&#20445;&#35777;&#21253;&#21547;&#30495;&#23454;&#26631;&#31614;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#25490;&#21015;&#19981;&#21464;&#26465;&#20214;&#65292;&#20351;&#24471;CP&#22312;&#22270;&#25968;&#25454;&#19978;&#25104;&#31435;&#65292;&#24182;&#25552;&#20379;&#20102;&#27979;&#35797;&#26102;&#38388;&#35206;&#30422;&#29575;&#30340;&#31934;&#30830;&#29305;&#24449;&#12290;&#27492;&#22806;&#65292;&#38500;&#20102;&#26377;&#25928;&#30340;&#35206;&#30422;&#65292;&#20943;&#23569;&#39044;&#27979;&#38598;&#22823;&#23567;/&#21306;&#38388;&#38271;&#24230;&#23545;&#20110;&#23454;&#38469;&#20351;&#29992;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#21457;&#29616;&#38750;&#31526;&#21512;&#24615;&#24471;&#20998;&#21644;&#32593;&#32476;&#32467;&#26500;&#20043;&#38388;&#23384;&#22312;&#20851;&#38190;&#32852;&#31995;&#65292;&#36825;&#20419;&#20351;&#25105;&#20204;&#24320;&#21457;&#20855;&#26377;&#25299;&#25169;&#24847;&#35782;&#30340;&#36755;&#20986;&#26657;&#27491;&#27169;&#22411;&#26469;&#23398;&#20064;&#26356;&#26032;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Networks (GNNs) are powerful machine learning prediction models on graph-structured data. However, GNNs lack rigorous uncertainty estimates, limiting their reliable deployment in settings where the cost of errors is significant. We propose conformalized GNN (CF-GNN), extending conformal prediction (CP) to graph-based models for guaranteed uncertainty estimates. Given an entity in the graph, CF-GNN produces a prediction set/interval that provably contains the true label with pre-defined coverage probability (e.g. 90%). We establish a permutation invariance condition that enables the validity of CP on graph data and provide an exact characterization of the test-time coverage. Moreover, besides valid coverage, it is crucial to reduce the prediction set size/interval length for practical use. We observe a key connection between non-conformity scores and network structures, which motivates us to develop a topology-aware output correction model that learns to update the predicti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#33021;&#22815;&#23558;&#25968;&#23383;&#29305;&#24449;&#32534;&#30721;&#20026;&#22522;&#20989;&#25968;&#21521;&#37327;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#22240;&#23376;&#26426;&#20013;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;&#22240;&#23376;&#26426;&#20013;&#65292;&#21487;&#20197;&#25913;&#21892;&#25512;&#33616;&#31995;&#32479;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.14528</link><description>&lt;p&gt;
&#22522;&#20989;&#25968;&#32534;&#30721;&#25913;&#21892;&#22240;&#23376;&#26426;&#20013;&#25968;&#23383;&#29305;&#24449;&#30340;&#20934;&#30830;&#24615;
&lt;/p&gt;
&lt;p&gt;
Basis Function Encoding of Numerical Features in Factorization Machines for Improved Accuracy. (arXiv:2305.14528v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14528
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#33021;&#22815;&#23558;&#25968;&#23383;&#29305;&#24449;&#32534;&#30721;&#20026;&#22522;&#20989;&#25968;&#21521;&#37327;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#22240;&#23376;&#26426;&#20013;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;&#22240;&#23376;&#26426;&#20013;&#65292;&#21487;&#20197;&#25913;&#21892;&#25512;&#33616;&#31995;&#32479;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#23376;&#26426;(FM)&#21464;&#20307;&#34987;&#24191;&#27867;&#29992;&#20110;&#22823;&#35268;&#27169;&#23454;&#26102;&#20869;&#23481;&#25512;&#33616;&#31995;&#32479;&#65292;&#22240;&#20026;&#23427;&#20204;&#22312;&#27169;&#22411;&#20934;&#30830;&#24615;&#21644;&#35757;&#32451;&#25512;&#29702;&#30340;&#20302;&#35745;&#31639;&#25104;&#26412;&#20043;&#38388;&#25552;&#20379;&#20102;&#20986;&#33394;&#30340;&#24179;&#34913;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#31995;&#32479;&#12289;&#29702;&#35770;&#19978;&#21512;&#29702;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#25968;&#20540;&#29305;&#24449;&#32534;&#30721;&#20026;&#25152;&#36873;&#20989;&#25968;&#38598;&#30340;&#20989;&#25968;&#20540;&#21521;&#37327;&#23558;&#25968;&#20540;&#29305;&#24449;&#32435;&#20837;FM&#21464;&#20307;&#12290;
&lt;/p&gt;
&lt;p&gt;
Factorization machine (FM) variants are widely used for large scale real-time content recommendation systems, since they offer an excellent balance between model accuracy and low computational costs for training and inference. These systems are trained on tabular data with both numerical and categorical columns. Incorporating numerical columns poses a challenge, and they are typically incorporated using a scalar transformation or binning, which can be either learned or chosen a-priori. In this work, we provide a systematic and theoretically-justified way to incorporate numerical features into FM variants by encoding them into a vector of function values for a set of functions of one's choice.  We view factorization machines as approximators of segmentized functions, namely, functions from a field's value to the real numbers, assuming the remaining fields are assigned some given constants, which we refer to as the segment. From this perspective, we show that our technique yields a model
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#22312;&#24191;&#27867;&#27169;&#22411;&#20013;&#36827;&#34892;&#26368;&#20248;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#20013;&#24230;&#20559;&#24046;&#21407;&#29702;&#26500;&#24314;&#39640;&#24230;&#20934;&#30830;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#28385;&#36275;&#25351;&#25968;&#31934;&#24230;&#12289;&#19968;&#33268;&#24615;&#21644;&#26368;&#22823;&#31934;&#24230;&#31561;&#26631;&#20934;&#65292;&#20026;&#35813;&#26041;&#27861;&#25552;&#20379;&#20102;&#29702;&#35770;&#20381;&#25454;&#12290;</title><link>http://arxiv.org/abs/2305.14496</link><description>&lt;p&gt;
&#36890;&#36807;&#20013;&#24230;&#20559;&#24046;&#29702;&#35770;&#36827;&#34892;&#26368;&#20248;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Optimal Learning via Moderate Deviations Theory. (arXiv:2305.14496v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14496
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#22312;&#24191;&#27867;&#27169;&#22411;&#20013;&#36827;&#34892;&#26368;&#20248;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#20013;&#24230;&#20559;&#24046;&#21407;&#29702;&#26500;&#24314;&#39640;&#24230;&#20934;&#30830;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#28385;&#36275;&#25351;&#25968;&#31934;&#24230;&#12289;&#19968;&#33268;&#24615;&#21644;&#26368;&#22823;&#31934;&#24230;&#31561;&#26631;&#20934;&#65292;&#20026;&#35813;&#26041;&#27861;&#25552;&#20379;&#20102;&#29702;&#35770;&#20381;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#24191;&#27867;&#27169;&#22411;&#20013;&#20351;&#29992;&#32622;&#20449;&#21306;&#38388;&#23398;&#20064;&#20989;&#25968;&#20540;&#30340;&#32479;&#35745;&#26368;&#20248;&#26041;&#27861;&#65292;&#21253;&#25324;&#25551;&#36848;&#20026;&#38543;&#26426;&#35268;&#21010;&#38382;&#39064;&#25110;&#21508;&#31181;SDE&#27169;&#22411;&#30340;&#26399;&#26395;&#25439;&#22833;&#30340;&#19968;&#33324;&#38750;&#21442;&#25968;&#20272;&#35745;&#12290;&#26356;&#20934;&#30830;&#22320;&#35828;&#65292;&#25105;&#20204;&#36890;&#36807;&#37319;&#29992;&#22522;&#20110;&#20013;&#24230;&#20559;&#24046;&#21407;&#29702;&#30340;&#26041;&#27861;&#31995;&#32479;&#22320;&#26500;&#24314;&#39640;&#24230;&#20934;&#30830;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#32622;&#20449;&#21306;&#38388;&#22312;&#32479;&#35745;&#24847;&#20041;&#19978;&#26159;&#26368;&#20248;&#30340;&#65292;&#22240;&#20026;&#23427;&#20204;&#28385;&#36275;&#20197;&#25351;&#25968;&#31934;&#24230;&#12289;&#26368;&#23567;&#24615;&#12289;&#19968;&#33268;&#24615;&#12289;&#35823;&#21028;&#27010;&#29575;&#20197;&#21450;&#26368;&#32456;&#30340;&#19968;&#33268;&#26368;&#22823;&#31934;&#24230;&#20026;&#26631;&#20934;&#30340;&#35201;&#27714;&#12290;&#35813;&#26041;&#27861;&#25552;&#20986;&#30340;&#32622;&#20449;&#21306;&#38388;&#26159;&#36890;&#36807;&#24378;&#21270;&#20248;&#21270;&#38382;&#39064;&#30340;&#35299;&#26469;&#34920;&#36798;&#30340;&#65292;&#20854;&#20013;&#19981;&#30830;&#23450;&#24615;&#36890;&#36807;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#24341;&#21457;&#30340;&#20013;&#24230;&#20559;&#24046;&#29575;&#20989;&#25968;&#26469;&#34920;&#31034;&#12290;&#25105;&#20204;&#28436;&#31034;&#20102;&#23545;&#20110;&#35768;&#22810;&#27169;&#22411;&#65292;&#36825;&#20123;&#20248;&#21270;&#38382;&#39064;&#20855;&#26377;&#26131;&#20110;&#35299;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a statistically optimal approach for learning a function value using a confidence interval in a wide range of models, including general non-parametric estimation of an expected loss described as a stochastic programming problem or various SDE models. More precisely, we develop a systematic construction of highly accurate confidence intervals by using a moderate deviation principle-based approach. It is shown that the proposed confidence intervals are statistically optimal in the sense that they satisfy criteria regarding exponential accuracy, minimality, consistency, mischaracterization probability, and eventual uniformly most accurate (UMA) property. The confidence intervals suggested by this approach are expressed as solutions to robust optimization problems, where the uncertainty is expressed via the underlying moderate deviation rate function induced by the data-generating process. We demonstrate that for many models these optimization problems admit tractable r
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#23545;DWP&#21464;&#20998;&#36817;&#20284;&#21518;&#39564;&#30340;&#25913;&#36827;&#31639;&#27861;&#65292;&#24182;&#20998;&#26512;&#20102;&#35813;&#26041;&#27861;&#22312;&#39044;&#27979;&#24615;&#33021;&#19978;&#30340;&#19981;&#36275;&#12290;</title><link>http://arxiv.org/abs/2305.14454</link><description>&lt;p&gt;
&#25913;&#36827;&#30340;&#21464;&#20998;&#36817;&#20284;&#21518;&#39564;&#29992;&#20110;&#28145;&#24230;Wishart&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
An Improved Variational Approximate Posterior for the Deep Wishart Process. (arXiv:2305.14454v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14454
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#23545;DWP&#21464;&#20998;&#36817;&#20284;&#21518;&#39564;&#30340;&#25913;&#36827;&#31639;&#27861;&#65292;&#24182;&#20998;&#26512;&#20102;&#35813;&#26041;&#27861;&#22312;&#39044;&#27979;&#24615;&#33021;&#19978;&#30340;&#19981;&#36275;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#26680;&#36807;&#31243;&#26159;&#19968;&#31867;&#26368;&#36817;&#24341;&#20837;&#30340;&#28145;&#24230;&#36125;&#21494;&#26031;&#27169;&#22411;&#65292;&#20855;&#26377;&#31070;&#32463;&#32593;&#32476;&#30340;&#28789;&#27963;&#24615;&#65292;&#20294;&#23436;&#20840;&#20351;&#29992;Gram&#30697;&#38453;&#12290;&#23427;&#20204;&#36890;&#36807;&#20132;&#26367;&#20174;&#27491;&#21322;&#23450;&#30697;&#38453;&#20998;&#24067;&#20013;&#21462;&#26679;Gram&#30697;&#38453;&#24182;&#24212;&#29992;&#30830;&#23450;&#24615;&#36716;&#25442;&#26469;&#25805;&#20316;&#12290;&#24403;&#20998;&#24067;&#34987;&#36873;&#25321;&#20026;Wishart&#20998;&#24067;&#26102;&#65292;&#27169;&#22411;&#34987;&#31216;&#20026;&#28145;&#24230;Wishart&#36807;&#31243;(DWP)&#12290;&#36825;&#20010;&#29305;&#23450;&#30340;&#27169;&#22411;&#24456;&#26377;&#36259;&#65292;&#22240;&#20026;&#23427;&#30340;&#20808;&#39564;&#31561;&#20215;&#20110;&#28145;&#24230;&#39640;&#26031;&#36807;&#31243;(DGP)&#30340;&#20808;&#39564;&#65292;&#20294;&#21516;&#26102;&#23427;&#23545;&#26059;&#36716;&#23545;&#31216;&#24615;&#19981;&#21464;&#65292;&#23548;&#33268;&#21518;&#39564;&#20998;&#24067;&#26356;&#31616;&#21333;&#12290;&#26368;&#36817;&#30340;&#24037;&#20316;&#65288;&#8220;&#28145;&#24230;Wishart&#36807;&#31243;&#30340;&#21464;&#20998;&#21518;&#39564;&#36817;&#20284;&#8221;Ober and Aitchison 2021a&#65289;&#23454;&#29616;&#20102;&#23545;DWP&#30340;&#23454;&#38469;&#25512;&#26029;&#65292;&#20854;&#20013;&#20316;&#32773;&#20351;&#29992;Wishart&#20998;&#24067;&#30340;Bartlett&#20998;&#35299;&#30340;&#25512;&#24191;&#20316;&#20026;&#21464;&#20998;&#21518;&#39564;&#36817;&#20284;&#12290;&#28982;&#32780;&#65292;&#35813;&#35770;&#25991;&#20013;&#30340;&#39044;&#27979;&#24615;&#33021;&#19981;&#22914;&#20854;&#20182;&#23545;&#27604;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep kernel processes are a recently introduced class of deep Bayesian models that have the flexibility of neural networks, but work entirely with Gram matrices. They operate by alternately sampling a Gram matrix from a distribution over positive semi-definite matrices, and applying a deterministic transformation. When the distribution is chosen to be Wishart, the model is called a deep Wishart process (DWP). This particular model is of interest because its prior is equivalent to a deep Gaussian process (DGP) prior, but at the same time it is invariant to rotational symmetries, leading to a simpler posterior distribution. Practical inference in the DWP was made possible in recent work ("A variational approximate posterior for the deep Wishart process" Ober and Aitchison 2021a) where the authors used a generalisation of the Bartlett decomposition of the Wishart distribution as the variational approximate posterior. However, predictive performance in that paper was less impressive than o
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#26368;&#20248;&#39044;&#26465;&#20214;&#21644;&#36153;&#33293;&#23572;&#33258;&#36866;&#24212; Langevin &#37319;&#26679;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#26377;&#25928;&#19988;&#22312;&#39640;&#32500;&#20013;&#38750;&#24120;&#24378;&#20581;&#30340;&#33258;&#36866;&#24212; MCMC &#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2305.14442</link><description>&lt;p&gt;
&#26368;&#20248;&#39044;&#26465;&#20214;&#21644;&#36153;&#33293;&#23572;&#33258;&#36866;&#24212; Langevin &#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Optimal Preconditioning and Fisher Adaptive Langevin Sampling. (arXiv:2305.14442v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14442
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26368;&#20248;&#39044;&#26465;&#20214;&#21644;&#36153;&#33293;&#23572;&#33258;&#36866;&#24212; Langevin &#37319;&#26679;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#26377;&#25928;&#19988;&#22312;&#39640;&#32500;&#20013;&#38750;&#24120;&#24378;&#20581;&#30340;&#33258;&#36866;&#24212; MCMC &#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#36890;&#36807;&#20998;&#26512;&#26368;&#22823;&#21270;&#39044;&#26399;&#24179;&#26041;&#36339;&#36291;&#36317;&#31163;&#65292;&#20026; Langevin &#25193;&#25955;&#23450;&#20041;&#20102;&#26368;&#20248;&#39044;&#26465;&#20214;&#12290;&#36825;&#23548;&#33268;&#26368;&#20248;&#39044;&#26465;&#20214;&#20026;&#21453;&#36153;&#33293;&#23572;&#20449;&#24687;&#21327;&#26041;&#24046;&#30697;&#38453;&#65292;&#20854;&#20013;&#21327;&#26041;&#24046;&#30697;&#38453;&#26159;&#22312;&#30446;&#26631;&#19979;&#24179;&#22343;&#23545;&#25968;&#30446;&#26631;&#26799;&#24230;&#30340;&#22806;&#31215;&#12290;&#25105;&#20204;&#23558;&#27492;&#32467;&#26524;&#24212;&#29992;&#20110; Metropolis &#35843;&#25972; Langevin &#31639;&#27861; (MALA)&#65292;&#24182;&#25512;&#23548;&#20986;&#19968;&#31181;&#20174;&#31639;&#27861;&#36816;&#34892;&#20135;&#29983;&#30340;&#26799;&#24230;&#21382;&#21490;&#20013;&#23398;&#20064;&#39044;&#26465;&#20214;&#30340;&#35745;&#31639;&#26377;&#25928;&#30340;&#33258;&#36866;&#24212; MCMC &#26041;&#26696;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#22312;&#39640;&#32500;&#20013;&#38750;&#24120;&#24378;&#20581;&#65292;&#24182;&#19988;&#26126;&#26174;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#65292;&#21253;&#25324;&#20351;&#29992;&#26631;&#20934;&#33258;&#36866;&#24212; MCMC &#23398;&#20064;&#39044;&#26465;&#20214;&#21644;&#20301;&#32622;&#30456;&#20851;&#30340; Riemann &#27969;&#24418; MALA &#37319;&#26679;&#22120;&#30340;&#23494;&#20999;&#30456;&#20851;&#30340;&#33258;&#36866;&#24212; MALA &#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
We define an optimal preconditioning for the Langevin diffusion by analytically maximizing the expected squared jumped distance. This yields as the optimal preconditioning an inverse Fisher information covariance matrix, where the covariance matrix is computed as the outer product of log target gradients averaged under the target. We apply this result to the Metropolis adjusted Langevin algorithm (MALA) and derive a computationally efficient adaptive MCMC scheme that learns the preconditioning from the history of gradients produced as the algorithm runs. We show in several experiments that the proposed algorithm is very robust in high dimensions and significantly outperforms other methods, including a closely related adaptive MALA scheme that learns the preconditioning with standard adaptive MCMC as well as the position-dependent Riemannian manifold MALA sampler.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#20195;&#20215;&#24863;&#30693;&#30340;&#27169;&#22411;&#36873;&#25321;BO&#26041;&#27861;SADCBO&#65292;&#36890;&#36807;&#23545;&#21518;&#39564;&#20195;&#29702;&#27169;&#22411;&#30340;&#25935;&#24863;&#24615;&#20998;&#26512;&#26469;&#23398;&#20064;&#20851;&#20110;&#29615;&#22659;&#30340;&#30456;&#20851;&#24773;&#22659;&#20449;&#24687;&#65292;&#24182;&#36890;&#36807;&#24179;&#22343;&#27169;&#22411;&#39044;&#27979;&#26469;&#26368;&#23567;&#21270;&#20248;&#21270;&#20195;&#20215;&#65292;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.14120</link><description>&lt;p&gt;
&#22522;&#20110;&#20195;&#20215;&#24863;&#30693;&#30340;&#24773;&#22659;&#21464;&#37327;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Cost-aware learning of relevant contextual variables within Bayesian optimization. (arXiv:2305.14120v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14120
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#22522;&#20110;&#20195;&#20215;&#24863;&#30693;&#30340;&#27169;&#22411;&#36873;&#25321;BO&#26041;&#27861;SADCBO&#65292;&#36890;&#36807;&#23545;&#21518;&#39564;&#20195;&#29702;&#27169;&#22411;&#30340;&#25935;&#24863;&#24615;&#20998;&#26512;&#26469;&#23398;&#20064;&#20851;&#20110;&#29615;&#22659;&#30340;&#30456;&#20851;&#24773;&#22659;&#20449;&#24687;&#65292;&#24182;&#36890;&#36807;&#24179;&#22343;&#27169;&#22411;&#39044;&#27979;&#26469;&#26368;&#23567;&#21270;&#20248;&#21270;&#20195;&#20215;&#65292;&#22312;&#23454;&#39564;&#20013;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24773;&#22659;&#36125;&#21494;&#26031;&#20248;&#21270;(CBO)&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#26694;&#26550;&#65292;&#21487;&#38024;&#23545;&#35774;&#35745;&#21464;&#37327;&#20248;&#21270;&#40657;&#30418;&#26114;&#36149;&#30340;&#35780;&#20272;&#20989;&#25968;&#65292;&#24182;&#21516;&#26102;&#26377;&#25928;&#22320;&#25972;&#21512;&#20851;&#20110;&#29615;&#22659;&#30340;&#30456;&#20851;&#24773;&#22659;&#20449;&#24687;&#65292;&#22914;&#23454;&#39564;&#26465;&#20214;&#12290;&#28982;&#32780;&#65292;&#22312;&#35768;&#22810;&#23454;&#38469;&#22330;&#26223;&#20013;&#65292;&#24773;&#22659;&#21464;&#37327;&#30340;&#30456;&#20851;&#24615;&#19981;&#19968;&#23450;&#26159;&#39044;&#20808;&#24050;&#30693;&#30340;&#12290;&#27492;&#22806;&#65292;&#26377;&#26102;&#36824;&#21487;&#20197;&#26368;&#20248;&#21270;&#24773;&#22659;&#21464;&#37327;&#26412;&#36523;&#65292;&#36825;&#26159;&#24403;&#21069;CBO&#31639;&#27861;&#26410;&#32771;&#34385;&#30340;&#35774;&#32622;&#12290;&#20248;&#21270;&#24773;&#22659;&#21464;&#37327;&#21487;&#33021;&#26159;&#26114;&#36149;&#30340;&#65292;&#36825;&#24341;&#20986;&#20102;&#30830;&#23450;&#19968;&#20010;&#26368;&#23567;&#30456;&#20851;&#23376;&#38598;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#36825;&#20010;&#38382;&#39064;&#20316;&#20026;&#19968;&#20010;&#20195;&#20215;&#24863;&#30693;&#30340;&#27169;&#22411;&#36873;&#25321;BO&#20219;&#21153;&#26469;&#26500;&#26550;&#65292;&#37319;&#29992;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21363;&#22522;&#20110;&#25935;&#24863;&#24615;&#20998;&#26512;&#30340;&#24773;&#22659;BO (SADCBO) &#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#29305;&#23450;&#36755;&#20837;&#28857;&#21518;&#39564;&#20195;&#29702;&#27169;&#22411;&#30340;&#25935;&#24863;&#24615;&#20998;&#26512;&#26469;&#23398;&#20064;&#24773;&#22659;&#21464;&#37327;&#30340;&#30456;&#20851;&#24615;&#65292;&#21516;&#26102;&#36890;&#36807;&#24179;&#22343;&#27169;&#22411;&#39044;&#27979;&#26469;&#26368;&#23567;&#21270;&#20248;&#21270;&#30340;&#20195;&#20215;&#12290;SADCBO&#22312;&#22810;&#20010;&#21512;&#25104;&#21644;&#30495;&#23454;&#22522;&#20934;&#38382;&#39064;&#19978;&#36827;&#34892;&#20102;&#23454;&#35777;&#35780;&#20272;&#65292;&#26174;&#31034;&#20986;&#20248;&#20110;&#29616;&#26377;&#31639;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Contextual Bayesian Optimization (CBO) is a powerful framework for optimizing black-box, expensive-to-evaluate functions with respect to design variables, while simultaneously efficiently integrating relevant contextual information regarding the environment, such as experimental conditions. However, in many practical scenarios, the relevance of contextual variables is not necessarily known beforehand. Moreover, the contextual variables can sometimes be optimized themselves, a setting that current CBO algorithms do not take into account. Optimizing contextual variables may be costly, which raises the question of determining a minimal relevant subset. In this paper, we frame this problem as a cost-aware model selection BO task and address it using a novel method, Sensitivity-Analysis-Driven Contextual BO (SADCBO). We learn the relevance of context variables by sensitivity analysis of the posterior surrogate model at specific input points, whilst minimizing the cost of optimization by lev
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#23427;&#22312;&#21482;&#26377;&#37096;&#20998;&#35206;&#30422;&#25968;&#25454;&#38598;&#21644;&#24369;&#21487;&#23454;&#29616;&#20989;&#25968;&#31867;&#30340;&#24773;&#20917;&#19979;&#65292;&#21033;&#29992;&#35206;&#30422;&#20998;&#24067;&#30340;&#38468;&#21152;&#20391;&#20449;&#24687;&#23454;&#29616;&#20102;&#26679;&#26412;&#26377;&#25928;&#31163;&#32447;RL&#65292;&#24182;&#23637;&#31034;&#20102;&#35206;&#30422;&#20998;&#24067;&#22312;&#20808;&#39564;&#30693;&#35782;&#21644;&#25152;&#38656;&#38468;&#21152;&#25968;&#25454;&#37327;&#20043;&#38388;&#36827;&#34892;&#26435;&#34913;&#26469;&#33719;&#24471;&#26356;&#22909;&#30340;&#23398;&#20064;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2305.12679</link><description>&lt;p&gt;
&#24102;&#26377;&#38468;&#21152;&#35206;&#30422;&#20998;&#24067;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Offline Reinforcement Learning with Additional Covering Distributions. (arXiv:2305.12679v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12679
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#23427;&#22312;&#21482;&#26377;&#37096;&#20998;&#35206;&#30422;&#25968;&#25454;&#38598;&#21644;&#24369;&#21487;&#23454;&#29616;&#20989;&#25968;&#31867;&#30340;&#24773;&#20917;&#19979;&#65292;&#21033;&#29992;&#35206;&#30422;&#20998;&#24067;&#30340;&#38468;&#21152;&#20391;&#20449;&#24687;&#23454;&#29616;&#20102;&#26679;&#26412;&#26377;&#25928;&#31163;&#32447;RL&#65292;&#24182;&#23637;&#31034;&#20102;&#35206;&#30422;&#20998;&#24067;&#22312;&#20808;&#39564;&#30693;&#35782;&#21644;&#25152;&#38656;&#38468;&#21152;&#25968;&#25454;&#37327;&#20043;&#38388;&#36827;&#34892;&#26435;&#34913;&#26469;&#33719;&#24471;&#26356;&#22909;&#30340;&#23398;&#20064;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#20351;&#29992;&#20989;&#25968;&#36924;&#36817;&#20174;&#26085;&#24535;&#25968;&#25454;&#38598;&#20013;&#23398;&#20064;&#26368;&#20248;&#31574;&#30053;&#65292;&#21363;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#12290;&#23613;&#31649;&#24050;&#32463;&#20184;&#20986;&#20102;&#24456;&#22810;&#21162;&#21147;&#65292;&#22312;&#20855;&#26377;&#29702;&#35770;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#30340;&#29616;&#26377;&#31639;&#27861;&#20013;&#65292;&#36890;&#24120;&#20551;&#35774;&#20855;&#26377;&#25506;&#32034;&#24615;&#25968;&#25454;&#35206;&#30422;&#25110;&#24378;&#21487;&#23454;&#29616;&#30340;&#20989;&#25968;&#31867;&#65292;&#36825;&#22312;&#29616;&#23454;&#20013;&#24456;&#38590;&#28385;&#36275;&#12290;&#34429;&#28982;&#26368;&#36817;&#26377;&#19968;&#20123;&#25104;&#21151;&#35299;&#20915;&#36825;&#20123;&#24378;&#20551;&#35774;&#30340;&#20316;&#21697;&#65292;&#20294;&#23427;&#20204;&#35201;&#20040;&#38656;&#35201;&#21482;&#33021;&#30001;&#19968;&#37096;&#20998;MDP&#28385;&#36275;&#30340;&#38388;&#38553;&#20551;&#35774;&#65292;&#35201;&#20040;&#20351;&#29992;&#34892;&#20026;&#27491;&#21017;&#21270;&#65292;&#20351;&#24471;&#23398;&#20064;&#31574;&#30053;&#30340;&#26368;&#20248;&#24615;&#21464;&#24471;&#19981;&#21487;&#34892;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#22522;&#20110;&#36793;&#38469;&#37325;&#35201;&#24615;&#25277;&#26679;(MIS)&#30340;&#31616;&#21333;&#31639;&#27861;&#30340;&#26679;&#26412;&#26377;&#38480;&#20445;&#35777;&#65292;&#35777;&#26126;&#20102;&#22312;&#32473;&#23450;&#35206;&#30422;&#20998;&#24067;&#30340;&#38468;&#21152;&#20391;&#20449;&#24687;&#19979;&#20165;&#20855;&#26377;&#37096;&#20998;&#35206;&#30422;&#25968;&#25454;&#38598;&#21644;&#24369;&#21487;&#23454;&#29616;&#20989;&#25968;&#31867;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#29992;MDP&#30340;&#26679;&#26412;&#26377;&#25928;&#31163;&#32447;RL&#26159;&#21487;&#33021;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#35206;&#30422;&#20998;&#24067;&#22312;&#20808;&#39564;&#30693;&#35782;&#21644;&#25152;&#38656;&#38468;&#21152;&#25968;&#25454;&#37327;&#20043;&#38388;&#36827;&#34892;&#26435;&#34913;&#65292;&#21516;&#26102;&#23637;&#31034;&#20102;&#23427;&#33021;&#22815;&#26377;&#30410;&#20110;&#23398;&#20064;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study learning optimal policies from a logged dataset, i.e., offline RL, with function approximation. Despite the efforts devoted, existing algorithms with theoretic finite-sample guarantees typically assume exploratory data coverage or strong realizable function classes, which is hard to be satisfied in reality. While there are recent works that successfully tackle these strong assumptions, they either require the gap assumptions that only could be satisfied by part of MDPs or use the behavior regularization that makes the optimality of learned policy even intractable. To solve this challenge, we provide finite-sample guarantees for a simple algorithm based on marginalized importance sampling (MIS), showing that sample-efficient offline RL for general MDPs is possible with only a partial coverage dataset and weak realizable function classes given additional side information of a covering distribution. Furthermore, we demonstrate that the covering distribution trades off prior knowl
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;Lasso&#22238;&#24402;&#23545;&#20110;&#31614;&#21517;&#21464;&#25442;&#30340;&#19968;&#33268;&#24615;&#38382;&#39064;&#65292;&#24182;&#21457;&#29616;&#23545;&#20110;&#19981;&#21516;&#30340;&#36807;&#31243;&#21644;&#26102;&#38388;&#24207;&#21015;&#65292;&#36873;&#25321;&#36866;&#24403;&#30340;&#31614;&#21517;&#23450;&#20041;&#21644;&#38543;&#26426;&#27169;&#22411;&#21487;&#20197;&#25552;&#39640;Lasso&#22238;&#24402;&#30340;&#19968;&#33268;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.10413</link><description>&lt;p&gt;
&#20351;&#29992;Lasso&#30340;&#31614;&#21517;&#19968;&#33268;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Consistency of Signatures Using Lasso. (arXiv:2305.10413v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10413
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;Lasso&#22238;&#24402;&#23545;&#20110;&#31614;&#21517;&#21464;&#25442;&#30340;&#19968;&#33268;&#24615;&#38382;&#39064;&#65292;&#24182;&#21457;&#29616;&#23545;&#20110;&#19981;&#21516;&#30340;&#36807;&#31243;&#21644;&#26102;&#38388;&#24207;&#21015;&#65292;&#36873;&#25321;&#36866;&#24403;&#30340;&#31614;&#21517;&#23450;&#20041;&#21644;&#38543;&#26426;&#27169;&#22411;&#21487;&#20197;&#25552;&#39640;Lasso&#22238;&#24402;&#30340;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31614;&#21517;&#21464;&#25442;&#26159;&#36830;&#32493;&#21644;&#31163;&#25955;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#30340;&#36845;&#20195;&#36335;&#24452;&#31215;&#20998;&#65292;&#23427;&#20204;&#30340;&#26222;&#36941;&#38750;&#32447;&#24615;&#36890;&#36807;&#32447;&#24615;&#21270;&#29305;&#24449;&#36873;&#25321;&#38382;&#39064;&#12290;&#26412;&#25991;&#22312;&#29702;&#35770;&#21644;&#25968;&#20540;&#19978;&#37325;&#26032;&#23457;&#35270;&#20102;Lasso&#22238;&#24402;&#23545;&#20110;&#31614;&#21517;&#21464;&#25442;&#30340;&#19968;&#33268;&#24615;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#23545;&#20110;&#26356;&#25509;&#36817;&#24067;&#26391;&#36816;&#21160;&#25110;&#20855;&#26377;&#36739;&#24369;&#36328;&#32500;&#24230;&#30456;&#20851;&#24615;&#30340;&#36807;&#31243;&#21644;&#26102;&#38388;&#24207;&#21015;&#65292;&#31614;&#21517;&#23450;&#20041;&#20026;It\^o&#31215;&#20998;&#30340;Lasso&#22238;&#24402;&#26356;&#20855;&#19968;&#33268;&#24615;&#65307;&#23545;&#20110;&#22343;&#20540;&#22238;&#24402;&#36807;&#31243;&#21644;&#26102;&#38388;&#24207;&#21015;&#65292;&#20854;&#31614;&#21517;&#23450;&#20041;&#20026;Stratonovich&#31215;&#20998;&#22312;Lasso&#22238;&#24402;&#20013;&#20855;&#26377;&#26356;&#39640;&#30340;&#19968;&#33268;&#24615;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#24378;&#35843;&#20102;&#22312;&#32479;&#35745;&#25512;&#26029;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#36873;&#25321;&#36866;&#24403;&#30340;&#31614;&#21517;&#21644;&#38543;&#26426;&#27169;&#22411;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Signature transforms are iterated path integrals of continuous and discrete-time time series data, and their universal nonlinearity linearizes the problem of feature selection. This paper revisits the consistency issue of Lasso regression for the signature transform, both theoretically and numerically. Our study shows that, for processes and time series that are closer to Brownian motion or random walk with weaker inter-dimensional correlations, the Lasso regression is more consistent for their signatures defined by It\^o integrals; for mean reverting processes and time series, their signatures defined by Stratonovich integrals have more consistency in the Lasso regression. Our findings highlight the importance of choosing appropriate definitions of signatures and stochastic models in statistical inference and machine learning.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#26031;Copula&#28151;&#21512;&#27169;&#22411;&#65288;GCMM&#65289;&#30340;&#24615;&#36136;&#65292;&#24320;&#21457;&#20102;&#22522;&#20110;&#25193;&#23637;&#26399;&#26395;&#26368;&#22823;&#31639;&#27861;&#30340;&#21442;&#25968;&#20272;&#35745;&#26041;&#27861;&#65292;&#24182;&#34920;&#26126;GCMM&#30456;&#27604;&#20110;GMM&#21487;&#20197;&#26356;&#22909;&#22320;&#25311;&#21512;&#25968;&#25454;&#24182;&#23454;&#29616;&#26356;&#28145;&#20837;&#30340;&#25968;&#25454;&#25366;&#25496;&#12290;</title><link>http://arxiv.org/abs/2305.01479</link><description>&lt;p&gt;
&#39640;&#26031;Copula&#28151;&#21512;&#27169;&#22411;&#30340;&#24615;&#36136;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the properties of Gaussian Copula Mixture Models. (arXiv:2305.01479v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.01479
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#39640;&#26031;Copula&#28151;&#21512;&#27169;&#22411;&#65288;GCMM&#65289;&#30340;&#24615;&#36136;&#65292;&#24320;&#21457;&#20102;&#22522;&#20110;&#25193;&#23637;&#26399;&#26395;&#26368;&#22823;&#31639;&#27861;&#30340;&#21442;&#25968;&#20272;&#35745;&#26041;&#27861;&#65292;&#24182;&#34920;&#26126;GCMM&#30456;&#27604;&#20110;GMM&#21487;&#20197;&#26356;&#22909;&#22320;&#25311;&#21512;&#25968;&#25454;&#24182;&#23454;&#29616;&#26356;&#28145;&#20837;&#30340;&#25968;&#25454;&#25366;&#25496;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;Copula&#28151;&#21512;&#27169;&#22411;&#65288;GCMM&#65289;&#26159;&#20351;&#29992;Copula&#27010;&#24565;&#30340;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#30340;&#25512;&#24191;&#12290;&#26412;&#25991;&#32473;&#20986;&#20102;&#20854;&#25968;&#23398;&#23450;&#20041;&#65292;&#24182;&#30740;&#31350;&#20102;&#20284;&#28982;&#20989;&#25968;&#30340;&#24615;&#36136;&#12290;&#22522;&#20110;&#36825;&#20123;&#23646;&#24615;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#25193;&#23637;&#26399;&#26395;&#26368;&#22823;&#31639;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#28151;&#21512;Copula&#30340;&#21442;&#25968;&#65292;&#32780;&#27599;&#20010;&#32452;&#20214;&#23545;&#24212;&#30340;&#36793;&#38469;&#20998;&#24067;&#21017;&#20351;&#29992;&#21333;&#29420;&#30340;&#38750;&#21442;&#25968;&#32479;&#35745;&#26041;&#27861;&#36827;&#34892;&#20272;&#35745;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#30456;&#27604;&#20110;GMM&#65292;GCMM&#22312;&#30456;&#21516;&#25968;&#37327;&#30340;&#32858;&#31867;&#24773;&#20917;&#19979;&#21487;&#20197;&#23454;&#29616;&#26356;&#22909;&#30340;&#25311;&#21512;&#65307;&#27492;&#22806;&#65292;GCMM&#21487;&#20197;&#21033;&#29992;&#27599;&#20010;&#32500;&#24230;&#19978;&#30340;&#19981;&#21516;&#27493;&#25968;&#25454;&#23454;&#29616;&#26356;&#28145;&#20837;&#30340;&#25968;&#25454;&#25366;&#25496;&#12290;
&lt;/p&gt;
&lt;p&gt;
Gaussian copula mixture models (GCMM) are the generalization of Gaussian Mixture models using the concept of copula. Its mathematical definition is given and the properties of likelihood function are studied in this paper. Based on these properties, extended Expectation Maximum algorithms are developed for estimating parameters for the mixture of copulas while marginal distributions corresponding to each component is estimated using separate nonparametric statistical methods. In the experiment, GCMM can achieve better goodness-of-fitting given the same number of clusters as GMM; furthermore, GCMM can utilize unsynchronized data on each dimension to achieve deeper mining of data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20801;&#35768;$k$&#20010;&#33218;&#30340;&#25439;&#22833;&#20989;&#25968;&#38543;&#26102;&#38388;&#32780;&#33258;&#30001;&#21464;&#21270;&#30340;&#23545;&#25239;&#24615;&#32447;&#24615;&#19978;&#19979;&#25991;&#36172;&#21338;&#24773;&#22659;&#12290;&#22312;&#20551;&#35774;&#29615;&#22659;&#36739;&#20026;&#28201;&#21644;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#19968;&#20010;&#20851;&#20110;Learner's Losses $V_T$&#30340;&#20108;&#38454;&#25439;&#22833;&#20540;&#37327;&#32423;&#20026;$\tilde O(K\sqrt{d V_T})$&#21644;&#20851;&#20110;&#26368;&#20339;&#31574;&#30053;$L_T^*$&#30340;&#19968;&#38454;&#25439;&#22833;&#20540;&#37327;&#32423;&#20026;$\tilde O(K\sqrt{d L_T^*})$&#30340;&#30028;&#12290;</title><link>http://arxiv.org/abs/2305.00832</link><description>&lt;p&gt;
&#23545;&#25239;&#24615;&#32447;&#24615;&#19978;&#19979;&#25991;&#36172;&#21338;&#30340;&#19968;&#38454;&#21644;&#20108;&#38454;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
First- and Second-Order Bounds for Adversarial Linear Contextual Bandits. (arXiv:2305.00832v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.00832
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20801;&#35768;$k$&#20010;&#33218;&#30340;&#25439;&#22833;&#20989;&#25968;&#38543;&#26102;&#38388;&#32780;&#33258;&#30001;&#21464;&#21270;&#30340;&#23545;&#25239;&#24615;&#32447;&#24615;&#19978;&#19979;&#25991;&#36172;&#21338;&#24773;&#22659;&#12290;&#22312;&#20551;&#35774;&#29615;&#22659;&#36739;&#20026;&#28201;&#21644;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#19968;&#20010;&#20851;&#20110;Learner's Losses $V_T$&#30340;&#20108;&#38454;&#25439;&#22833;&#20540;&#37327;&#32423;&#20026;$\tilde O(K\sqrt{d V_T})$&#21644;&#20851;&#20110;&#26368;&#20339;&#31574;&#30053;$L_T^*$&#30340;&#19968;&#38454;&#25439;&#22833;&#20540;&#37327;&#32423;&#20026;$\tilde O(K\sqrt{d L_T^*})$&#30340;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23545;&#25239;&#24615;&#32447;&#24615;&#19978;&#19979;&#25991;&#36172;&#21338;&#30340;&#24773;&#22659;&#65292;&#35813;&#24773;&#22659;&#20801;&#35768;&#19982;K&#20010;&#33218;&#30456;&#20851;&#32852;&#30340;&#25439;&#22833;&#20989;&#25968;&#38543;&#26102;&#38388;&#32780;&#33258;&#30001;&#21464;&#21270;&#12290; &#20551;&#35774;d&#32500;&#19978;&#19979;&#25991;&#20174;&#24050;&#30693;&#20998;&#24067;&#20013;&#32472;&#21046;&#65292;&#37027;&#20040;&#22312;T&#36718;&#28216;&#25103;&#26399;&#38388;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#39044;&#26399;&#36951;&#25022;&#23558;&#20197;$\tilde O(\sqrt{Kd T})$&#30340;&#36895;&#24230;&#22686;&#38271;&#12290;&#22312;&#20551;&#35774;&#19978;&#19979;&#25991;&#30340;&#23494;&#24230;&#26159;&#23545;&#25968;&#20985;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#19968;&#20010;&#20108;&#38454;&#30028;&#65292;&#20854;&#22312;&#32047;&#31215;&#25439;&#22833;&#30340;&#20108;&#27425;&#30697;$V_T$&#26041;&#38754;&#30340;&#37327;&#32423;&#20026;$\tilde O(K\sqrt{d V_T})$&#65292;&#20197;&#21450;&#19968;&#20010;&#19982;&#20043;&#23494;&#20999;&#30456;&#20851;&#30340;&#19968;&#38454;&#30028;&#65292;&#20854;&#22312;&#26368;&#20339;&#31574;&#30053;&#30340;&#32047;&#31215;&#25439;&#22833;$L_T^*$&#26041;&#38754;&#30340;&#37327;&#32423;&#20026;$\tilde O(K\sqrt{d L_T^*})$&#12290;&#30001;&#20110;$V_T$&#25110;$L_T^*$&#21487;&#33021;&#26126;&#26174;&#23567;&#20110;$T$&#65292;&#22240;&#27492;&#27599;&#24403;&#29615;&#22659;&#30456;&#23545;&#28201;&#21644;&#26102;&#65292;&#20415;&#20250;&#25913;&#21892;&#26368;&#22351;&#24773;&#20917;&#30340;&#36951;&#25022;&#12290;&#26412;&#25991;&#20351;&#29992;&#27010;&#29575;&#21333;&#32431;&#24418;&#19978;&#30340;&#36830;&#32493;&#25351;&#25968;&#26435;&#37325;&#31639;&#27861;&#30340;&#25130;&#26029;&#29256;&#26412;&#26469;&#33719;&#24471;&#32467;&#26524;
&lt;/p&gt;
&lt;p&gt;
We consider the adversarial linear contextual bandit setting, which allows for the loss functions associated with each of $K$ arms to change over time without restriction. Assuming the $d$-dimensional contexts are drawn from a fixed known distribution, the worst-case expected regret over the course of $T$ rounds is known to scale as $\tilde O(\sqrt{Kd T})$. Under the additional assumption that the density of the contexts is log-concave, we obtain a second-order bound of order $\tilde O(K\sqrt{d V_T})$ in terms of the cumulative second moment of the learner's losses $V_T$, and a closely related first-order bound of order $\tilde O(K\sqrt{d L_T^*})$ in terms of the cumulative loss of the best policy $L_T^*$. Since $V_T$ or $L_T^*$ may be significantly smaller than $T$, these improve over the worst-case regret whenever the environment is relatively benign. Our results are obtained using a truncated version of the continuous exponential weights algorithm over the probability simplex, which
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20174;&#27491;&#21322;&#23450;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#20013;&#39640;&#25928;&#37319;&#26679;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#21033;&#29992;&#27491;&#21322;&#23450;-PSD&#27169;&#22411;&#22312;&#31934;&#24230;$\varepsilon$&#19979;&#29983;&#25104;iid&#26679;&#26412;&#12290;&#31639;&#27861;&#22797;&#26434;&#24230;&#20026;$O(T d \log(1/\varepsilon) m^2 + d m^{\beta+1} \log(T)/\varepsilon^2)$&#65292;&#20854;&#20013;$T$&#26159;&#26102;&#38388;&#27493;&#25968;&#65292;$\beta$&#26159;Fokker-Planck&#35299;&#30340;&#27491;&#21017;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.17109</link><description>&lt;p&gt;
&#27491;&#21322;&#23450;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#39640;&#25928;&#37319;&#26679;
&lt;/p&gt;
&lt;p&gt;
Efficient Sampling of Stochastic Differential Equations with Positive Semi-Definite Models. (arXiv:2303.17109v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.17109
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20174;&#27491;&#21322;&#23450;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#20013;&#39640;&#25928;&#37319;&#26679;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#21033;&#29992;&#27491;&#21322;&#23450;-PSD&#27169;&#22411;&#22312;&#31934;&#24230;$\varepsilon$&#19979;&#29983;&#25104;iid&#26679;&#26412;&#12290;&#31639;&#27861;&#22797;&#26434;&#24230;&#20026;$O(T d \log(1/\varepsilon) m^2 + d m^{\beta+1} \log(T)/\varepsilon^2)$&#65292;&#20854;&#20013;$T$&#26159;&#26102;&#38388;&#27493;&#25968;&#65292;$\beta$&#26159;Fokker-Planck&#35299;&#30340;&#27491;&#21017;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#22312;&#24050;&#30693;&#28418;&#31227;&#20989;&#25968;&#21644;&#25193;&#25955;&#30697;&#38453;&#30340;&#24773;&#20917;&#19979;&#65292;&#20174;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#20013;&#39640;&#25928;&#37319;&#26679;&#30340;&#38382;&#39064;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21033;&#29992;&#20102;&#19968;&#20010;&#26368;&#36817;&#30340;&#27010;&#29575;&#27169;&#22411;&#65288;&#27491;&#21322;&#23450;-PSD&#27169;&#22411;&#65289;\citep{rudi2021psd}&#65292;&#20174;&#20013;&#21487;&#20197;&#33719;&#24471;&#31934;&#24230;&#20026;$\varepsilon$&#30340;&#29420;&#31435;&#21516;&#20998;&#24067;&#65288;iid&#65289;&#26679;&#26412;&#65292;&#20854;&#25104;&#26412;&#20026;$m^2 d \log(1/\varepsilon)$&#65292;&#20854;&#20013;$m$&#26159;&#27169;&#22411;&#30340;&#32500;&#24230;&#65292;$d$&#26159;&#31354;&#38388;&#30340;&#32500;&#24230;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21253;&#25324;&#65306;&#39318;&#20808;&#35745;&#31639;&#28385;&#36275;&#19982;SDE&#30456;&#20851;&#32852;&#30340;Fokker-Planck&#26041;&#31243;&#65288;&#25110;&#20854;&#20998;&#25968;&#21464;&#20307;&#65289;&#30340;PSD&#27169;&#22411;&#65292;&#35823;&#24046;&#20026;$\varepsilon$&#65292;&#28982;&#21518;&#20174;&#29983;&#25104;&#30340;PSD&#27169;&#22411;&#20013;&#37319;&#26679;&#12290;&#20551;&#35774;Fokker-Planck&#35299;&#20855;&#26377;&#19968;&#23450;&#30340;&#27491;&#21017;&#24615;&#65288;&#21363;$\beta$&#38454;&#21487;&#24494;&#24615;&#20197;&#21450;&#20854;&#38646;&#28857;&#30340;&#19968;&#20123;&#20960;&#20309;&#26465;&#20214;&#65289;&#65292;&#25105;&#20204;&#24471;&#21040;&#19968;&#20010;&#31639;&#27861;&#65306;&#65288;a&#65289;&#22312;&#20934;&#22791;&#38454;&#27573;&#65292;&#33719;&#24471;&#20855;&#26377;L2&#36317;&#31163;$\varepsilon$&#30340;PSD&#27169;&#22411;&#20316;&#20026;&#30495;&#23454;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#30340;&#20272;&#35745;&#65307;&#65288;b&#65289;&#22312;&#37319;&#26679;&#38454;&#27573;&#65292;&#20197;&#31934;&#24230;$\varepsilon$&#29983;&#25104;SDE&#35299;&#30340;iid&#26679;&#26412;&#12290;&#25152;&#24471;&#21040;&#30340;&#22797;&#26434;&#24230;&#20026;$O(T d \log(1/\varepsilon) m^2 + d m^{\beta+1} \log(T)/\varepsilon^2)$&#65292;&#20854;&#20013;$T$&#26159;SDE&#30340;&#26102;&#38388;&#27493;&#25968;&#65292;$\beta$&#26159;Fokker-Planck&#35299;&#30340;&#27491;&#21017;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper deals with the problem of efficient sampling from a stochastic differential equation, given the drift function and the diffusion matrix. The proposed approach leverages a recent model for probabilities \citep{rudi2021psd} (the positive semi-definite -- PSD model) from which it is possible to obtain independent and identically distributed (i.i.d.) samples at precision $\varepsilon$ with a cost that is $m^2 d \log(1/\varepsilon)$ where $m$ is the dimension of the model, $d$ the dimension of the space. The proposed approach consists in: first, computing the PSD model that satisfies the Fokker-Planck equation (or its fractional variant) associated with the SDE, up to error $\varepsilon$, and then sampling from the resulting PSD model. Assuming some regularity of the Fokker-Planck solution (i.e. $\beta$-times differentiability plus some geometric condition on its zeros) We obtain an algorithm that: (a) in the preparatory phase obtains a PSD model with L2 distance $\varepsilon$ fr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#34920;&#26126;&#40657;&#30418;&#21464;&#20998;&#25512;&#29702;&#65288;BBVI&#65289;&#28385;&#36275;SGD&#25991;&#29486;&#20013;&#30340;ABC&#26465;&#20214;&#65292;&#35813;&#32467;&#26524;&#36866;&#29992;&#20110;&#24179;&#28369;&#21644;&#20108;&#27425;&#22686;&#38271;&#30340;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#65292;&#21516;&#26102;&#25105;&#20204;&#30340;&#32467;&#26524;&#25512;&#24191;&#21040;&#24191;&#27867;&#24212;&#29992;&#20110;BBVI&#23454;&#36341;&#20013;&#30340;&#38750;&#32447;&#24615;&#21327;&#26041;&#24046;&#21442;&#25968;&#21270;&#12290;</title><link>http://arxiv.org/abs/2303.10472</link><description>&lt;p&gt;
&#40657;&#30418;&#21464;&#20998;&#36125;&#21494;&#26031;&#25512;&#29702;&#30340;&#23454;&#29992;&#21305;&#37197;&#26799;&#24230;&#26041;&#24046;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Practical and Matching Gradient Variance Bounds for Black-Box Variational Bayesian Inference. (arXiv:2303.10472v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.10472
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#34920;&#26126;&#40657;&#30418;&#21464;&#20998;&#25512;&#29702;&#65288;BBVI&#65289;&#28385;&#36275;SGD&#25991;&#29486;&#20013;&#30340;ABC&#26465;&#20214;&#65292;&#35813;&#32467;&#26524;&#36866;&#29992;&#20110;&#24179;&#28369;&#21644;&#20108;&#27425;&#22686;&#38271;&#30340;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#65292;&#21516;&#26102;&#25105;&#20204;&#30340;&#32467;&#26524;&#25512;&#24191;&#21040;&#24191;&#27867;&#24212;&#29992;&#20110;BBVI&#23454;&#36341;&#20013;&#30340;&#38750;&#32447;&#24615;&#21327;&#26041;&#24046;&#21442;&#25968;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#40657;&#30418;&#21464;&#20998;&#25512;&#29702;&#65288;BBVI&#65289;&#30340;&#26799;&#24230;&#26041;&#24046;&#26159;&#24314;&#31435;&#20854;&#25910;&#25947;&#24615;&#21644;&#31639;&#27861;&#25913;&#36827;&#30340;&#20851;&#38190;&#19968;&#27493;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30740;&#31350;&#23578;&#26410;&#34920;&#26126;BBVI&#30340;&#26799;&#24230;&#26041;&#24046;&#28385;&#36275;&#29992;&#20110;&#30740;&#31350;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#25910;&#25947;&#30340;&#26465;&#20214;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#24403;&#24212;&#29992;&#20110;&#24179;&#28369;&#21644;&#20108;&#27425;&#22686;&#38271;&#30340;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#26102;&#65292;BBVI&#28385;&#36275;&#19982;SGD&#25991;&#29486;&#20013;&#20351;&#29992;&#30340;ABC&#26465;&#20214;&#30456;&#21305;&#37197;&#30340;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25512;&#24191;&#21040;&#24191;&#27867;&#24212;&#29992;&#20110;BBVI&#23454;&#36341;&#20013;&#30340;&#38750;&#32447;&#24615;&#21327;&#26041;&#24046;&#21442;&#25968;&#21270;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#34920;&#26126;&#65292;&#24179;&#22343;&#22330;&#21442;&#25968;&#21270;&#30340;&#26041;&#24046;&#20855;&#26377;&#32463;&#36807;&#39564;&#35777;&#30340;&#20248;&#36234;&#32500;&#24230;&#20381;&#36182;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding the gradient variance of black-box variational inference (BBVI) is a crucial step for establishing its convergence and developing algorithmic improvements. However, existing studies have yet to show that the gradient variance of BBVI satisfies the conditions used to study the convergence of stochastic gradient descent (SGD), the workhorse of BBVI. In this work, we show that BBVI satisfies a matching bound corresponding to the $ABC$ condition used in the SGD literature when applied to smooth and quadratically-growing log-likelihoods. Our results generalize to nonlinear covariance parameterizations widely used in the practice of BBVI. Furthermore, we show that the variance of the mean-field parameterization has provably superior dimensional dependence.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#22788;&#29702;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#20998;&#24067;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;M/EEG&#20449;&#21495;&#19978;&#30340;&#33041;&#40836;&#39044;&#27979;&#12290;&#36825;&#31181;&#26041;&#27861;&#20351;&#29992;&#20102;&#20999;&#29255;Wasserstein&#36317;&#31163;&#24182;&#35777;&#26126;&#20855;&#26377;&#24378;&#22823;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#22312;&#39046;&#22495;&#36866;&#24212;&#30340;&#22823;&#33041;&#35745;&#31639;&#26426;&#30028;&#38754;&#24212;&#29992;&#20013;&#65292;&#36825;&#31181;&#26041;&#27861;&#20063;&#35777;&#26126;&#20102;&#20854;&#25928;&#29575;&#21644;&#21487;&#34892;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.05798</link><description>&lt;p&gt;
&#23545;M/EEG&#20449;&#21495;&#19978;&#30340;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#36827;&#34892;&#20999;&#29255;Wasserstein&#36317;&#31163;&#30340;&#35745;&#31639;
&lt;/p&gt;
&lt;p&gt;
Sliced-Wasserstein on Symmetric Positive Definite Matrices for M/EEG Signals. (arXiv:2303.05798v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.05798
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#22788;&#29702;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#20998;&#24067;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;M/EEG&#20449;&#21495;&#19978;&#30340;&#33041;&#40836;&#39044;&#27979;&#12290;&#36825;&#31181;&#26041;&#27861;&#20351;&#29992;&#20102;&#20999;&#29255;Wasserstein&#36317;&#31163;&#24182;&#35777;&#26126;&#20855;&#26377;&#24378;&#22823;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#22312;&#39046;&#22495;&#36866;&#24212;&#30340;&#22823;&#33041;&#35745;&#31639;&#26426;&#30028;&#38754;&#24212;&#29992;&#20013;&#65292;&#36825;&#31181;&#26041;&#27861;&#20063;&#35777;&#26126;&#20102;&#20854;&#25928;&#29575;&#21644;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22788;&#29702;&#30005;&#25110;&#32773;&#30913;&#24615;&#33041;&#30005;&#22270;&#35760;&#24405;&#26102;&#65292;&#35768;&#22810;&#30417;&#30563;&#24335;&#39044;&#27979;&#20219;&#21153;&#36890;&#36807;&#20351;&#29992;&#21327;&#26041;&#24046;&#30697;&#38453;&#26469;&#27719;&#24635;&#20449;&#21495;&#36827;&#34892;&#35299;&#20915;&#12290;&#20351;&#29992;&#36825;&#20123;&#30697;&#38453;&#36827;&#34892;&#23398;&#20064;&#38656;&#35201;&#20351;&#29992;&#20285;&#39532;&#23612;&#20960;&#20309;&#26469;&#35828;&#26126;&#23427;&#20204;&#30340;&#32467;&#26500;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#22788;&#29702;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#20998;&#24067;&#65292;&#24182;&#19988;&#22312;M / EEG&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#19978;&#23637;&#31034;&#20102;&#20854;&#35745;&#31639;&#25928;&#29575;&#12290;&#26356;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#23450;&#20041;&#20102;&#27979;&#37327;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#20043;&#38388;&#30340;&#20999;&#29255;Wasserstein&#36317;&#31163;&#65292;&#24182;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;&#20854;&#23646;&#24615;&#21644;&#20869;&#26680;&#26041;&#27861;&#23558;&#27492;&#36317;&#31163;&#24212;&#29992;&#20110;&#20174;MEG&#25968;&#25454;&#39044;&#27979;&#33041;&#40836;&#65292;&#24182;&#23558;&#20854;&#19982;&#22522;&#20110;Riemannian&#20960;&#20309;&#30340;&#26368;&#26032;&#31639;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#22312;&#39046;&#22495;&#36866;&#24212;&#30340;&#22823;&#33041;&#35745;&#31639;&#26426;&#30028;&#38754;&#24212;&#29992;&#20013;&#65292;&#23427;&#21487;&#20197;&#26159;Wasserstein&#36317;&#31163;&#30340;&#26377;&#25928;&#26367;&#20195;&#21697;&#12290;
&lt;/p&gt;
&lt;p&gt;
When dealing with electro or magnetoencephalography records, many supervised prediction tasks are solved by working with covariance matrices to summarize the signals. Learning with these matrices requires using Riemanian geometry to account for their structure. In this paper, we propose a new method to deal with distributions of covariance matrices and demonstrate its computational efficiency on M/EEG multivariate time series. More specifically, we define a Sliced-Wasserstein distance between measures of symmetric positive definite matrices that comes with strong theoretical guarantees. Then, we take advantage of its properties and kernel methods to apply this distance to brain-age prediction from MEG data and compare it to state-of-the-art algorithms based on Riemannian geometry. Finally, we show that it is an efficient surrogate to the Wasserstein distance in domain adaptation for Brain Computer Interface applications.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#24179;&#22343;&#22330; Langevin &#21160;&#21147;&#23398;&#65292;&#35777;&#26126;&#20102;&#36793;&#32536;&#20998;&#24067; $L^p$ &#25910;&#25947;&#24615;&#21644;&#28151;&#27788;&#29616;&#35937;&#30340;&#22343;&#21248;&#26102;&#38388;&#20256;&#25773;&#12290;</title><link>http://arxiv.org/abs/2212.03050</link><description>&lt;p&gt;
&#22343;&#21248;&#26102;&#38388;&#20256;&#25773;&#28151;&#27788;&#30340;&#24179;&#22343;&#22330; Langevin &#21160;&#21147;&#23398;
&lt;/p&gt;
&lt;p&gt;
Uniform-in-time propagation of chaos for mean field Langevin dynamics. (arXiv:2212.03050v2 [math.PR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.03050
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#24179;&#22343;&#22330; Langevin &#21160;&#21147;&#23398;&#65292;&#35777;&#26126;&#20102;&#36793;&#32536;&#20998;&#24067; $L^p$ &#25910;&#25947;&#24615;&#21644;&#28151;&#27788;&#29616;&#35937;&#30340;&#22343;&#21248;&#26102;&#38388;&#20256;&#25773;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24179;&#22343;&#22330; Langevin &#21160;&#21147;&#23398;&#21450;&#20854;&#30456;&#20851;&#31890;&#23376;&#31995;&#32479;&#12290;&#36890;&#36807;&#20551;&#35774;&#33021;&#37327;&#20989;&#25968;&#30340;&#20984;&#24615;&#65292;&#25105;&#20204;&#24471;&#20986;&#20102;&#36793;&#32536;&#20998;&#24067;&#25910;&#25947;&#21040;&#24179;&#22343;&#22330;&#21160;&#21147;&#23398;&#21807;&#19968;&#19981;&#21464;&#27979;&#24230;&#30340; $L^p$ &#25910;&#25947;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312; $L^2$ Wasserstein &#36317;&#31163;&#21644;&#30456;&#23545;&#29109;&#20004;&#26041;&#38754;&#65292;&#28151;&#27788;&#29616;&#35937;&#30340;&#22343;&#21248;&#26102;&#38388;&#20256;&#25773;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the mean field Langevin dynamics and the associated particle system. By assuming the functional convexity of the energy, we obtain the $L^p$-convergence of the marginal distributions towards the unique invariant measure for the mean field dynamics. Furthermore, we prove the uniform-in-time propagation of chaos in both the $L^2$-Wasserstein metric and relative entropy.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27979;&#35797;&#26102;&#26631;&#31614;&#36716;&#31227;&#26657;&#27491;&#26041;&#27861;&#65292;&#36890;&#36807;&#36866;&#24212;&#20998;&#24067;&#30340;&#21464;&#21270;&#26469;&#25552;&#21319;&#39044;&#27979;&#27169;&#22411;&#24615;&#33021;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#22788;&#29702;&#31867;&#21035;&#26631;&#31614;&#21644;&#22122;&#22768;&#22240;&#32032;&#30340;&#20381;&#36182;&#20851;&#31995;&#38543;&#22495;&#21464;&#21270;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2211.15646</link><description>&lt;p&gt;
&#36229;&#36234;&#19981;&#21464;&#24615;&#65306;&#38024;&#23545;&#20855;&#26377;&#8220;&#34394;&#20551;&#8221;&#30456;&#20851;&#24615;&#30340;&#20998;&#24067;&#30340;&#27979;&#35797;&#26102;&#26631;&#31614;&#36716;&#31227;&#36866;&#24212;&#24615;
&lt;/p&gt;
&lt;p&gt;
Beyond Invariance: Test-Time Label-Shift Adaptation for Distributions with "Spurious" Correlations. (arXiv:2211.15646v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.15646
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27979;&#35797;&#26102;&#26631;&#31614;&#36716;&#31227;&#26657;&#27491;&#26041;&#27861;&#65292;&#36890;&#36807;&#36866;&#24212;&#20998;&#24067;&#30340;&#21464;&#21270;&#26469;&#25552;&#21319;&#39044;&#27979;&#27169;&#22411;&#24615;&#33021;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#22788;&#29702;&#31867;&#21035;&#26631;&#31614;&#21644;&#22122;&#22768;&#22240;&#32032;&#30340;&#20381;&#36182;&#20851;&#31995;&#38543;&#22495;&#21464;&#21270;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27979;&#35797;&#26102;&#25968;&#25454;&#20998;&#24067;&#30340;&#21464;&#21270;&#21487;&#33021;&#23545;&#39044;&#27979;&#27169;&#22411;p(y|x)&#30340;&#24615;&#33021;&#20135;&#29983;&#19981;&#33391;&#24433;&#21709;&#12290;&#25105;&#20204;&#32771;&#34385;&#23384;&#22312;&#38468;&#21152;&#20803;&#25968;&#25454;&#26631;&#31614;&#65288;&#20363;&#22914;&#32452;&#26631;&#31614;&#65289;z&#30340;&#24773;&#20917;&#65292;&#35813;&#26631;&#31614;&#21487;&#20197;&#35828;&#26126;&#20998;&#24067;&#30340;&#21464;&#21270;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#20551;&#35774;&#25551;&#36848;&#31867;&#21035;&#26631;&#31614;y&#21644;&#8220;&#22122;&#22768;&#8221;&#22240;&#32032;z&#20043;&#38388;&#20381;&#36182;&#20851;&#31995;&#30340;&#20808;&#39564;&#20998;&#24067;p(y, z)&#21487;&#33021;&#20250;&#38543;&#30528;&#22495;&#30340;&#21464;&#21270;&#32780;&#25913;&#21464;&#65292;&#35201;&#20040;&#26159;&#30001;&#20110;&#36825;&#20123;&#39033;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#30340;&#21464;&#21270;&#65292;&#35201;&#20040;&#26159;&#30001;&#20110;&#20854;&#20013;&#19968;&#20010;&#21464;&#37327;&#30340;&#36793;&#38469;&#20998;&#24067;&#30340;&#21464;&#21270;&#12290;&#20294;&#26159;&#65292;&#25105;&#20204;&#20551;&#35774;&#29305;&#24449;&#30340;&#29983;&#25104;&#27169;&#22411;p(x|y, z)&#22312;&#22495;&#38388;&#26159;&#19981;&#21464;&#30340;&#12290;&#25105;&#20204;&#27880;&#24847;&#21040;&#36825;&#30456;&#24403;&#20110;&#24191;&#27867;&#20351;&#29992;&#30340;&#8220;&#26631;&#31614;&#36716;&#31227;&#8221;&#20551;&#35774;&#30340;&#25193;&#23637;&#29256;&#26412;&#65292;&#20854;&#20013;&#26631;&#31614;&#29616;&#22312;&#20063;&#21253;&#25324;&#22122;&#22768;&#22240;&#32032;z&#12290;&#22522;&#20110;&#27492;&#35266;&#23519;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#27979;&#35797;&#26102;&#26631;&#31614;&#36716;&#31227;&#26657;&#27491;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#26410;&#26631;&#35760;&#26679;&#26412;&#24212;&#29992;&#26399;&#26395;&#26368;&#22823;&#21270;&#31639;&#27861;&#26469;&#36866;&#24212;p(y, z)&#30340;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Changes in the data distribution at test time can have deleterious effects on the performance of predictive models $p(y|x)$. We consider situations where there are additional meta-data labels (such as group labels), denoted by $z$, that can account for such changes in the distribution. In particular, we assume that the prior distribution $p(y, z)$, which models the dependence between the class label $y$ and the "nuisance" factors $z$, may change across domains, either due to a change in the correlation between these terms, or a change in one of their marginals. However, we assume that the generative model for features $p(x|y, z)$ is invariant across domains. We note that this corresponds to an expanded version of the widely used "label shift" assumption, where the labels now also include the nuisance factors $z$. Based on this observation, we propose a test-time label shift correction that adapts to changes in the joint distribution $p(y, z)$ using EM applied to unlabeled samples from 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#19968;&#33268;&#25490;&#24207;&#26694;&#26550;&#65292;&#21363;RankDice/RankIoU&#65292;&#29992;&#20110;&#35299;&#20915;&#30001;&#20110;&#29616;&#26377;&#30340;&#20998;&#21106;&#26694;&#26550;&#23545;&#20110;Dice/IoU&#25351;&#26631;&#32570;&#20047;&#19968;&#33268;&#24615;&#32780;&#21487;&#33021;&#23548;&#33268;&#30340;&#27425;&#20248;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2206.13086</link><description>&lt;p&gt;
RankSEG:&#19968;&#31181;&#22522;&#20110;&#19968;&#33268;&#25490;&#24207;&#30340;&#20998;&#21106;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
RankSEG: A Consistent Ranking-based Framework for Segmentation. (arXiv:2206.13086v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.13086
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#19968;&#33268;&#25490;&#24207;&#26694;&#26550;&#65292;&#21363;RankDice/RankIoU&#65292;&#29992;&#20110;&#35299;&#20915;&#30001;&#20110;&#29616;&#26377;&#30340;&#20998;&#21106;&#26694;&#26550;&#23545;&#20110;Dice/IoU&#25351;&#26631;&#32570;&#20047;&#19968;&#33268;&#24615;&#32780;&#21487;&#33021;&#23548;&#33268;&#30340;&#27425;&#20248;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#21106;&#24050;&#25104;&#20026;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#22522;&#26412;&#39046;&#22495;&#65292;&#23427;&#23558;&#26631;&#31614;&#20998;&#37197;&#32473;&#27599;&#20010;&#20687;&#32032;/&#29305;&#24449;&#65292;&#20197;&#20174;&#22270;&#20687;/&#25991;&#26412;&#20013;&#25552;&#21462;&#24863;&#20852;&#36259;&#30340;&#21306;&#22495;&#12290;&#20026;&#20102;&#35780;&#20272;&#20998;&#21106;&#24615;&#33021;&#65292;&#20351;&#29992;Dice&#21644;IoU&#25351;&#26631;&#26469;&#34913;&#37327;&#23454;&#38469;&#20540;&#21644;&#39044;&#27979;&#20998;&#21106;&#20043;&#38388;&#30340;&#37325;&#21472;&#31243;&#24230;&#12290;&#26412;&#25991;&#24314;&#31435;&#20102;&#19982;Dice/IoU&#25351;&#26631;&#30456;&#20851;&#30340;&#20998;&#21106;&#29702;&#35770;&#22522;&#30784;&#65292;&#21253;&#25324;&#31867;&#27604;&#20110;&#20998;&#31867;&#30340;&#36125;&#21494;&#26031;&#35268;&#21017;&#21644;Dice-/IoU-&#26657;&#20934;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#29616;&#26377;&#30340;&#22522;&#20110;&#38408;&#20540;&#30340;&#26694;&#26550;&#23545;&#20110;Dice/IoU&#25351;&#26631;&#32570;&#20047;&#19968;&#33268;&#24615;&#65292;&#22240;&#27492;&#21487;&#33021;&#23548;&#33268;&#27425;&#20248;&#35299;&#20915;&#26041;&#26696;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#19968;&#33268;&#25490;&#24207;&#26694;&#26550;&#65292;&#21363;RankDice/RankIoU&#65292;&#21463;&#36125;&#21494;&#26031;&#20998;&#21106;&#35268;&#21017;&#30340;&#25554;&#20837;&#27861;&#21017;&#30340;&#21551;&#21457;&#12290;&#26412;&#25991;&#25552;&#20379;&#20102;&#19977;&#20010;&#20351;&#29992;GPU&#24182;&#34892;&#25191;&#34892;&#30340;&#25968;&#23383;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Segmentation has emerged as a fundamental field of computer vision and natural language processing, which assigns a label to every pixel/feature to extract regions of interest from an image/text. To evaluate the performance of segmentation, the Dice and IoU metrics are used to measure the degree of overlap between the ground truth and the predicted segmentation. In this paper, we establish a theoretical foundation of segmentation with respect to the Dice/IoU metrics, including the Bayes rule and Dice-/IoU-calibration, analogous to classification-calibration or Fisher consistency in classification. We prove that the existing thresholding-based framework with most operating losses are not consistent with respect to the Dice/IoU metrics, and thus may lead to a suboptimal solution. To address this pitfall, we propose a novel consistent ranking-based framework, namely RankDice/RankIoU, inspired by plug-in rules of the Bayes segmentation rule. Three numerical algorithms with GPU parallel exe
&lt;/p&gt;</description></item><item><title>Fenrir&#26159;&#19968;&#31181;&#36890;&#36807;&#27010;&#29575;&#25968;&#20540;&#26041;&#27861;&#23558;&#21021;&#22987;&#20540;&#38382;&#39064;&#36716;&#21270;&#20026;&#39640;&#26031;-&#39532;&#23572;&#31185;&#22827;&#22238;&#24402;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#20351;&#24494;&#20998;&#26041;&#31243;&#21442;&#25968;&#20272;&#35745;&#20219;&#21153;&#26356;&#23481;&#26131;&#35299;&#20915;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#22788;&#29702;&#37096;&#20998;&#35266;&#27979;&#25968;&#25454;&#65292;&#24182;&#20855;&#26377;&#26576;&#20123;&#36867;&#33073;&#23616;&#37096;&#26368;&#20248;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2202.01287</link><description>&lt;p&gt;
Fenrir: &#29289;&#29702;&#22686;&#24378;&#21021;&#22987;&#21270;&#38382;&#39064;&#22238;&#24402;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Fenrir: Physics-Enhanced Regression for Initial Value Problems. (arXiv:2202.01287v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.01287
&lt;/p&gt;
&lt;p&gt;
Fenrir&#26159;&#19968;&#31181;&#36890;&#36807;&#27010;&#29575;&#25968;&#20540;&#26041;&#27861;&#23558;&#21021;&#22987;&#20540;&#38382;&#39064;&#36716;&#21270;&#20026;&#39640;&#26031;-&#39532;&#23572;&#31185;&#22827;&#22238;&#24402;&#38382;&#39064;&#30340;&#26041;&#27861;&#65292;&#20351;&#24494;&#20998;&#26041;&#31243;&#21442;&#25968;&#20272;&#35745;&#20219;&#21153;&#26356;&#23481;&#26131;&#35299;&#20915;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#22788;&#29702;&#37096;&#20998;&#35266;&#27979;&#25968;&#25454;&#65292;&#24182;&#20855;&#26377;&#26576;&#20123;&#36867;&#33073;&#23616;&#37096;&#26368;&#20248;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#27010;&#29575;&#25968;&#20540;&#26041;&#27861;&#23558;&#21021;&#22987;&#20540;&#38382;&#39064;&#36716;&#21270;&#20026;&#30001;&#21021;&#22987;&#20540;&#38382;&#39064;&#21160;&#21147;&#23398;&#21442;&#25968;&#21270;&#30340;&#39640;&#26031;-&#39532;&#23572;&#31185;&#22827;&#36807;&#31243;&#12290;&#22240;&#27492;&#65292;&#24120;&#35265;&#30340;&#24494;&#20998;&#26041;&#31243;&#21442;&#25968;&#20272;&#35745;&#38382;&#39064;&#34987;&#31616;&#21270;&#20026;&#39640;&#26031;-&#39532;&#23572;&#31185;&#22827;&#22238;&#24402;&#30340;&#36229;&#21442;&#25968;&#20272;&#35745;&#65292;&#36825;&#24448;&#24448;&#26356;&#23481;&#26131;&#35299;&#20915;&#12290;&#25105;&#20204;&#38416;&#36848;&#20102;&#35813;&#26041;&#27861;&#19982;&#32463;&#20856;&#25968;&#20540;&#31215;&#20998;&#21644;&#26799;&#24230;&#21305;&#37197;&#26041;&#27861;&#30340;&#20851;&#31995;&#21644;&#20248;&#21183;&#12290;&#29305;&#21035;&#22320;&#65292;&#19982;&#26799;&#24230;&#21305;&#37197;&#30456;&#27604;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#22788;&#29702;&#37096;&#20998;&#35266;&#27979;&#65292;&#24182;&#20855;&#26377;&#26576;&#20123;&#21487;&#36867;&#33073;&#32463;&#20856;&#25968;&#20540;&#31215;&#20998;&#23616;&#37096;&#26368;&#20248;&#30340;&#26041;&#27861;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#19982;&#31454;&#20105;&#26041;&#27861;&#30456;&#24403;&#25110;&#31245;&#24494;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
We show how probabilistic numerics can be used to convert an initial value problem into a Gauss--Markov process parametrised by the dynamics of the initial value problem. Consequently, the often difficult problem of parameter estimation in ordinary differential equations is reduced to hyperparameter estimation in Gauss--Markov regression, which tends to be considerably easier. The method's relation and benefits in comparison to classical numerical integration and gradient matching approaches is elucidated. In particular, the method can, in contrast to gradient matching, handle partial observations, and has certain routes for escaping local optima not available to classical numerical integration. Experimental results demonstrate that the method is on par or moderately better than competing approaches.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20174;&#22240;&#26524;&#30340;&#35282;&#24230;&#25552;&#20986;&#20102;&#19968;&#31181;&#20840;&#38754;&#30340;&#26497;&#23567;&#21270;&#20998;&#26512;&#65292;&#26088;&#22312;&#22238;&#31572;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#36716;&#31227;&#31283;&#23450;&#20449;&#24687;&#26102;&#24212;&#35813;&#36716;&#31227;&#21738;&#20010;&#23376;&#38598;&#20174;&#32780;&#36798;&#21040;&#26368;&#20339;&#30340;&#27867;&#21270;&#33021;&#21147;&#36825;&#19968;&#38382;&#39064;</title><link>http://arxiv.org/abs/2107.01876</link><description>&lt;p&gt;
&#25105;&#20204;&#24212;&#35813;&#36716;&#31227;&#21738;&#31181;&#19981;&#21464;&#24615;&#65311;&#19968;&#31181;&#22240;&#26524;&#26497;&#23567;&#21270;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Which Invariance Should We Transfer? A Causal Minimax Learning Approach. (arXiv:2107.01876v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2107.01876
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20174;&#22240;&#26524;&#30340;&#35282;&#24230;&#25552;&#20986;&#20102;&#19968;&#31181;&#20840;&#38754;&#30340;&#26497;&#23567;&#21270;&#20998;&#26512;&#65292;&#26088;&#22312;&#22238;&#31572;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#36716;&#31227;&#31283;&#23450;&#20449;&#24687;&#26102;&#24212;&#35813;&#36716;&#31227;&#21738;&#20010;&#23376;&#38598;&#20174;&#32780;&#36798;&#21040;&#26368;&#20339;&#30340;&#27867;&#21270;&#33021;&#21147;&#36825;&#19968;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26080;&#27861;&#21487;&#38752;&#24212;&#23545;&#25968;&#25454;&#38598;&#21464;&#21270;&#65292;&#22240;&#27492;&#22823;&#22810;&#25968;&#29616;&#26377;&#30740;&#31350;&#35797;&#22270;&#23558;&#31283;&#23450;&#20449;&#24687;&#36716;&#31227;&#21040;&#30475;&#19981;&#35265;&#30340;&#29615;&#22659;&#20013;&#12290;&#29305;&#21035;&#22320;&#65292;&#22522;&#20110;&#29420;&#31435;&#22240;&#26524;&#26426;&#21046;&#30340;&#26041;&#27861;&#36890;&#36807;do-operator&#28040;&#38500;&#21487;&#21464;&#30340;&#22240;&#26524;&#26426;&#21046;&#12290;&#19982;&#20043;&#21069;&#30340;&#26041;&#27861;&#30456;&#27604;&#65292;&#25152;&#24471;&#21040;&#30340;&#31283;&#23450;&#39044;&#27979;&#22240;&#20026;&#33021;&#22815;&#26356;&#26377;&#25928;&#22320;&#35782;&#21035;&#31283;&#23450;&#20449;&#24687;&#32780;&#26356;&#21152;&#26377;&#25928;&#12290;&#28982;&#32780;&#65292;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#20173;&#28982;&#23384;&#22312;&#65306;&#20026;&#20102;&#36798;&#21040;&#26368;&#20339;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#24212;&#35813;&#36716;&#31227;&#36825;&#25972;&#20010;&#31283;&#23450;&#20449;&#24687;&#20013;&#30340;&#21738;&#20010;&#23376;&#38598;&#65311;&#20026;&#20102;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#20174;&#22240;&#26524;&#30340;&#35282;&#24230;&#25552;&#20986;&#20102;&#19968;&#31181;&#20840;&#38754;&#30340;&#26497;&#23567;&#21270;&#20998;&#26512;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#39318;&#20808;&#25552;&#20379;&#20102;&#19968;&#20010;&#29992;&#20110;&#21028;&#26029;&#25972;&#20010;&#31283;&#23450;&#38598;&#26159;&#21542;&#26368;&#20248;&#30340;&#22270;&#24418;&#26465;&#20214;&#12290;&#24403;&#36825;&#20010;&#26465;&#20214;&#22833;&#36133;&#26102;&#65292;&#25105;&#20204;&#24778;&#35766;&#22320;&#21457;&#29616;&#65292;&#36890;&#36807;&#19968;&#20010;&#20363;&#23376;&#65292;&#36825;&#20010;&#25972;&#20010;&#31283;&#23450;&#38598;&#34429;&#28982;&#33021;&#22815;&#20805;&#20998;&#21033;&#29992;&#31283;&#23450;&#20449;&#24687;&#65292;&#20294;&#24182;&#19981;&#26159;&#26368;&#20248;&#30340;&#36716;&#31227;&#38598;&#12290;&#20026;&#20102;&#30830;&#23450;&#26368;&#20248;&#38598;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22240;&#26524;&#26368;&#23567;&#21547;&#20041;&#30340;&#26041;&#27861;&#65292;&#24182;&#32473;&#20986;&#20102;&#20223;&#30495;&#21644;&#23454;&#38469;&#25968;&#25454;&#20013;&#30340;&#23454;&#39564;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
A major barrier to deploying current machine learning models lies in their non-reliability to dataset shifts. To resolve this problem, most existing studies attempted to transfer stable information to unseen environments. Particularly, independent causal mechanisms-based methods proposed to remove mutable causal mechanisms via the do-operator. Compared to previous methods, the obtained stable predictors are more effective in identifying stable information. However, a key question remains: which subset of this whole stable information should the model transfer, in order to achieve optimal generalization ability? To answer this question, we present a comprehensive minimax analysis from a causal perspective. Specifically, we first provide a graphical condition for the whole stable set to be optimal. When this condition fails, we surprisingly find with an example that this whole stable set, although can fully exploit stable information, is not the optimal one to transfer. To identify the o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#22120;&#30340;&#26032;&#30340;DAG&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#20351;&#20851;&#32852;&#38750;&#32447;&#24615;&#19988;&#25968;&#25454;&#26102;&#21464;&#21487;&#34892;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;&#27169;&#25311;&#21644;&#33041;&#36830;&#25509;&#32593;&#32476;&#20998;&#26512;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2106.01474</link><description>&lt;p&gt;
&#36890;&#36807;&#32467;&#26500;&#21270;&#12289;&#30417;&#30563;&#21644;&#29983;&#25104;&#23545;&#25239;&#23398;&#20064;&#27979;&#35797;&#26377;&#21521;&#26080;&#29615;&#22270;
&lt;/p&gt;
&lt;p&gt;
Testing Directed Acyclic Graph via Structural, Supervised and Generative Adversarial Learning. (arXiv:2106.01474v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.01474
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#22120;&#30340;&#26032;&#30340;DAG&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#20351;&#20851;&#32852;&#38750;&#32447;&#24615;&#19988;&#25968;&#25454;&#26102;&#21464;&#21487;&#34892;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;&#27169;&#25311;&#21644;&#33041;&#36830;&#25509;&#32593;&#32476;&#20998;&#26512;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;DAG&#65289;&#12290;&#34429;&#28982;&#26377;&#19968;&#22823;&#31867;DAG&#20272;&#35745;&#26041;&#27861;&#65292;&#20294;DAG&#25512;&#26029;&#35299;&#20915;&#26041;&#26696;&#30456;&#23545;&#36739;&#23569;&#12290;&#27492;&#22806;&#65292;&#29616;&#26377;&#26041;&#27861;&#36890;&#24120;&#24378;&#21152;&#19968;&#20123;&#29305;&#23450;&#30340;&#27169;&#22411;&#32467;&#26500;&#65292;&#22914;&#32447;&#24615;&#27169;&#22411;&#25110;&#21487;&#21152;&#27169;&#22411;&#65292;&#24182;&#20551;&#35774;&#25968;&#25454;&#35266;&#27979;&#29420;&#31435;&#12290;&#25105;&#20204;&#30340;&#27979;&#35797;&#26041;&#27861;&#20801;&#35768;&#38543;&#26426;&#21464;&#37327;&#20043;&#38388;&#30340;&#20851;&#32852;&#26159;&#38750;&#32447;&#24615;&#30340;&#65292;&#25968;&#25454;&#26159;&#26102;&#21464;&#30340;&#12290;&#25105;&#20204;&#22522;&#20110;&#19968;&#20123;&#39640;&#24230;&#28789;&#27963;&#30340;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#22120;&#26500;&#24314;&#20102;&#36825;&#20010;&#27979;&#35797;&#12290;&#22312;&#20801;&#35768;&#27599;&#20010;&#21463;&#35797;&#32773;&#30340;&#21463;&#35797;&#20154;&#25968;&#25110;&#26102;&#38388;&#28857;&#25968;&#21457;&#25955;&#20026;&#26080;&#31351;&#22823;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#27979;&#35797;&#30340;&#28176;&#36817;&#20445;&#35777;&#12290;&#25105;&#20204;&#36890;&#36807;&#27169;&#25311;&#21644;&#33041;&#36830;&#25509;&#32593;&#32476;&#20998;&#26512;&#23637;&#31034;&#20102;&#27979;&#35797;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this article, we propose a new hypothesis testing method for directed acyclic graph (DAG). While there is a rich class of DAG estimation methods, there is a relative paucity of DAG inference solutions. Moreover, the existing methods often impose some specific model structures such as linear models or additive models, and assume independent data observations. Our proposed test instead allows the associations among the random variables to be nonlinear and the data to be time-dependent. We build the test based on some highly flexible neural networks learners. We establish the asymptotic guarantees of the test, while allowing either the number of subjects or the number of time points for each subject to diverge to infinity. We demonstrate the efficacy of the test through simulations and a brain connectivity network analysis.
&lt;/p&gt;</description></item></channel></rss>