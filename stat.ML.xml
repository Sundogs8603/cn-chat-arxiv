<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#22312;&#32599;&#32455;&#38598;&#20013;&#20351;&#29992;SHAP&#23558;&#26679;&#26412;&#22823;&#23567;&#19982;&#27169;&#22411;&#30340;&#35299;&#37322;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#21457;&#29616;&#38543;&#30528;&#26679;&#26412;&#22823;&#23567;&#30340;&#22686;&#21152;&#65292;&#35299;&#37322;&#36880;&#28176;&#36235;&#20110;&#19968;&#33268;&#12290;&#28982;&#32780;&#65292;&#23569;&#20110;128&#20010;&#26679;&#26412;&#30340;&#35299;&#37322;&#21464;&#24322;&#24615;&#39640;&#65292;&#38480;&#21046;&#20102;&#21487;&#38752;&#30693;&#35782;&#30340;&#25552;&#21462;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#20026;&#20449;&#20219;&#35299;&#37322;&#25152;&#38656;&#30340;&#20805;&#36275;&#25968;&#25454;&#25552;&#20379;&#20102;&#25351;&#23548;&#12290;</title><link>http://arxiv.org/abs/2308.07247</link><description>&lt;p&gt;
&#33021;&#21542;&#36798;&#25104;&#19968;&#33268;&#65311;&#32599;&#32455;&#25928;&#24212;&#21644;&#20107;&#21518;&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#30340;&#21487;&#38752;&#24615;
&lt;/p&gt;
&lt;p&gt;
Can we Agree? On the Rash\=omon Effect and the Reliability of Post-Hoc Explainable AI. (arXiv:2308.07247v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07247
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#22312;&#32599;&#32455;&#38598;&#20013;&#20351;&#29992;SHAP&#23558;&#26679;&#26412;&#22823;&#23567;&#19982;&#27169;&#22411;&#30340;&#35299;&#37322;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#21457;&#29616;&#38543;&#30528;&#26679;&#26412;&#22823;&#23567;&#30340;&#22686;&#21152;&#65292;&#35299;&#37322;&#36880;&#28176;&#36235;&#20110;&#19968;&#33268;&#12290;&#28982;&#32780;&#65292;&#23569;&#20110;128&#20010;&#26679;&#26412;&#30340;&#35299;&#37322;&#21464;&#24322;&#24615;&#39640;&#65292;&#38480;&#21046;&#20102;&#21487;&#38752;&#30693;&#35782;&#30340;&#25552;&#21462;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#20026;&#20449;&#20219;&#35299;&#37322;&#25152;&#38656;&#30340;&#20805;&#36275;&#25968;&#25454;&#25552;&#20379;&#20102;&#25351;&#23548;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32599;&#32455;&#25928;&#24212;&#32473;&#20174;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#33719;&#24471;&#21487;&#38752;&#30693;&#35782;&#24102;&#26469;&#20102;&#25361;&#25112;&#12290;&#26412;&#30740;&#31350;&#20351;&#29992;SHAP&#22312;&#19968;&#20010;&#32599;&#32455;&#38598;&#20013;&#32771;&#23519;&#20102;&#26679;&#26412;&#22823;&#23567;&#23545;&#27169;&#22411;&#35299;&#37322;&#30340;&#24433;&#21709;&#12290;&#22312;5&#20010;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#38543;&#30528;&#26679;&#26412;&#22823;&#23567;&#30340;&#22686;&#21152;&#65292;&#35299;&#37322;&#36880;&#28176;&#36235;&#20110;&#19968;&#33268;&#12290;&#23569;&#20110;128&#20010;&#26679;&#26412;&#30340;&#35299;&#37322;&#21464;&#24322;&#24615;&#39640;&#65292;&#38480;&#21046;&#20102;&#21487;&#38752;&#30693;&#35782;&#30340;&#25552;&#21462;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#26356;&#22810;&#25968;&#25454;&#30340;&#22686;&#21152;&#65292;&#27169;&#22411;&#20043;&#38388;&#30340;&#19968;&#33268;&#24615;&#20063;&#24471;&#21040;&#20102;&#25913;&#21892;&#65292;&#20801;&#35768;&#24418;&#25104;&#20849;&#35782;&#12290;&#38598;&#25104;&#27169;&#22411;&#24120;&#24120;&#20855;&#26377;&#26356;&#39640;&#30340;&#19968;&#33268;&#24615;&#12290;&#36825;&#20123;&#32467;&#26524;&#20026;&#20449;&#20219;&#35299;&#37322;&#25152;&#38656;&#30340;&#20805;&#36275;&#25968;&#25454;&#25552;&#20379;&#20102;&#25351;&#23548;&#12290;&#26679;&#26412;&#25968;&#37327;&#36739;&#23569;&#26102;&#30340;&#21464;&#24322;&#24615;&#34920;&#26126;&#65292;&#27809;&#26377;&#32463;&#36807;&#39564;&#35777;&#30340;&#32467;&#35770;&#21487;&#33021;&#26159;&#19981;&#21487;&#38752;&#30340;&#12290;&#36824;&#38656;&#35201;&#36827;&#19968;&#27493;&#30740;&#31350;&#26356;&#22810;&#30340;&#27169;&#22411;&#31867;&#22411;&#12289;&#25968;&#25454;&#39046;&#22495;&#21644;&#35299;&#37322;&#26041;&#27861;&#12290;&#22312;&#31070;&#32463;&#32593;&#32476;&#21644;&#29305;&#23450;&#27169;&#22411;&#35299;&#37322;&#26041;&#27861;&#20013;&#27979;&#35797;&#25910;&#25947;&#24615;&#23558;&#26159;&#26377;&#24433;&#21709;&#21147;&#30340;&#12290;&#36825;&#37324;&#25506;&#32034;&#30340;&#26041;&#27861;&#20026;&#20174;&#27169;&#31946;&#30340;&#24773;&#20917;&#20013;&#33719;&#21462;&#30693;&#35782;&#25552;&#20379;&#20102;&#26377;&#21407;&#21017;&#30340;&#25216;&#26415;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Rash\=omon effect poses challenges for deriving reliable knowledge from machine learning models. This study examined the influence of sample size on explanations from models in a Rash\=omon set using SHAP. Experiments on 5 public datasets showed that explanations gradually converged as the sample size increased. Explanations from &lt;128 samples exhibited high variability, limiting reliable knowledge extraction. However, agreement between models improved with more data, allowing for consensus. Bagging ensembles often had higher agreement. The results provide guidance on sufficient data to trust explanations. Variability at low samples suggests that conclusions may be unreliable without validation. Further work is needed with more model types, data domains, and explanation methods. Testing convergence in neural networks and with model-specific explanation methods would be impactful. The approaches explored here point towards principled techniques for eliciting knowledge from ambiguous 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#36319;&#36394;&#28436;&#21464;&#27169;&#24335;&#30340;&#26102;&#31354;&#24352;&#37327;&#20998;&#35299;&#26041;&#27861;tPARAFAC2&#65292;&#36890;&#36807;&#26102;&#38388;&#27491;&#21017;&#21270;&#22120;&#20174;&#26102;&#38388;&#25968;&#25454;&#20013;&#25552;&#21462;&#36880;&#28176;&#28436;&#21464;&#30340;&#27169;&#24335;&#12290;</title><link>http://arxiv.org/abs/2308.07126</link><description>&lt;p&gt;
&#19968;&#31181;&#36866;&#29992;&#20110;&#36319;&#36394;&#28436;&#21464;&#27169;&#24335;&#30340;&#26102;&#31354;&#24352;&#37327;&#20998;&#35299;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Time-aware tensor decomposition for tracking evolving patterns. (arXiv:2308.07126v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07126
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#36319;&#36394;&#28436;&#21464;&#27169;&#24335;&#30340;&#26102;&#31354;&#24352;&#37327;&#20998;&#35299;&#26041;&#27861;tPARAFAC2&#65292;&#36890;&#36807;&#26102;&#38388;&#27491;&#21017;&#21270;&#22120;&#20174;&#26102;&#38388;&#25968;&#25454;&#20013;&#25552;&#21462;&#36880;&#28176;&#28436;&#21464;&#30340;&#27169;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#28436;&#21464;&#30340;&#25968;&#25454;&#38598;&#36890;&#24120;&#21487;&#20197;&#32452;&#32455;&#25104;&#19968;&#20010;&#39640;&#38454;&#24352;&#37327;&#65292;&#20854;&#20013;&#30340;&#19968;&#20010;&#27169;&#24335;&#26159;&#26102;&#38388;&#27169;&#24335;&#12290;&#34429;&#28982;&#24352;&#37327;&#20998;&#35299;&#24050;&#32463;&#25104;&#21151;&#22320;&#29992;&#20110;&#25429;&#25417;&#36825;&#31867;&#39640;&#38454;&#25968;&#25454;&#38598;&#20013;&#30340;&#28508;&#22312;&#27169;&#24335;&#65292;&#20294;&#24448;&#24448;&#24573;&#30053;&#20102;&#26102;&#38388;&#30340;&#22240;&#32032;&#65292;&#20801;&#35768;&#26102;&#38388;&#28857;&#30340;&#37325;&#26032;&#25490;&#24207;&#12290;&#22312;&#26368;&#36817;&#30340;&#30740;&#31350;&#20013;&#65292;&#24341;&#20837;&#20102;&#26102;&#38388;&#27491;&#21017;&#21270;&#22120;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#26041;&#27861;&#20173;&#28982;&#19981;&#20801;&#35768;&#28508;&#22312;&#27169;&#24335;&#22312;&#26102;&#38388;&#19978;&#21457;&#29983;&#21464;&#21270;&#65288;&#20363;&#22914;&#65292;&#22823;&#33041;&#20013;&#30340;&#31354;&#38388;&#21464;&#21270;&#65292;&#20027;&#39064;&#20013;&#30340;&#19978;&#19979;&#25991;&#21464;&#21270;&#65289;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;PARAFAC2&#30340;&#26102;&#31354;&#24352;&#37327;&#20998;&#35299;&#26041;&#27861;tPARAFAC2&#65292;&#36890;&#36807;&#26102;&#38388;&#27491;&#21017;&#21270;&#22120;&#20174;&#26102;&#38388;&#25968;&#25454;&#20013;&#25552;&#21462;&#36880;&#28176;&#28436;&#21464;&#30340;&#27169;&#24335;&#12290;&#36890;&#36807;&#23545;&#21512;&#25104;&#25968;&#25454;&#30340;&#22823;&#37327;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;tPARAFAC2&#33021;&#22815;&#20934;&#30830;&#22320;&#25429;&#25417;&#21040;&#28436;&#21464;&#20013;&#30340;&#28508;&#22312;&#27169;&#24335;&#65292;&#34920;&#29616;&#20248;&#20110;PARAFAC2&#21644;&#24102;&#26377;&#26102;&#38388;&#24179;&#28369;&#27491;&#21017;&#21270;&#30340;&#32806;&#21512;&#30697;&#38453;&#20998;&#35299;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Time-evolving data sets can often be arranged as a higher-order tensor with one of the modes being the time mode. While tensor factorizations have been successfully used to capture the underlying patterns in such higher-order data sets, the temporal aspect is often ignored, allowing for the reordering of time points. In recent studies, temporal regularizers are incorporated in the time mode to tackle this issue. Nevertheless, existing approaches still do not allow underlying patterns to change in time (e.g., spatial changes in the brain, contextual changes in topics). In this paper, we propose temporal PARAFAC2 (tPARAFAC2): a PARAFAC2-based tensor factorization method with temporal regularization to extract gradually evolving patterns from temporal data. Through extensive experiments on synthetic data, we demonstrate that tPARAFAC2 can capture the underlying evolving patterns accurately performing better than PARAFAC2 and coupled matrix factorization with temporal smoothness regulariza
&lt;/p&gt;</description></item><item><title>iSTFTNet2&#26159;&#19968;&#20010;&#25913;&#36827;&#30340;&#22522;&#20110;iSTFT&#30340;&#22768;&#30721;&#22120;&#65292;&#20351;&#29992;1D-2D CNN&#26469;&#27169;&#25311;&#26102;&#38388;&#21644;&#35889;&#22270;&#32467;&#26500;&#65292;&#20174;&#32780;&#22312;&#20445;&#25345;&#35821;&#38899;&#36136;&#37327;&#30340;&#21516;&#26102;&#25552;&#39640;&#20102;&#36895;&#24230;&#21644;&#36731;&#37327;&#32423;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.07117</link><description>&lt;p&gt;
iSTFTNet2&#65306;&#20351;&#29992;1D-2D CNN&#26356;&#24555;&#12289;&#26356;&#36731;&#37327;&#32423;&#30340;&#22522;&#20110;iSTFT&#30340;&#31070;&#32463;&#22768;&#30721;&#22120;
&lt;/p&gt;
&lt;p&gt;
iSTFTNet2: Faster and More Lightweight iSTFT-Based Neural Vocoder Using 1D-2D CNN. (arXiv:2308.07117v1 [cs.SD])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07117
&lt;/p&gt;
&lt;p&gt;
iSTFTNet2&#26159;&#19968;&#20010;&#25913;&#36827;&#30340;&#22522;&#20110;iSTFT&#30340;&#22768;&#30721;&#22120;&#65292;&#20351;&#29992;1D-2D CNN&#26469;&#27169;&#25311;&#26102;&#38388;&#21644;&#35889;&#22270;&#32467;&#26500;&#65292;&#20174;&#32780;&#22312;&#20445;&#25345;&#35821;&#38899;&#36136;&#37327;&#30340;&#21516;&#26102;&#25552;&#39640;&#20102;&#36895;&#24230;&#21644;&#36731;&#37327;&#32423;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36870;&#30701;&#26102;&#20613;&#37324;&#21494;&#21464;&#25442;&#32593;&#32476;&#65288;iSTFTNet&#65289;&#36890;&#36807;&#20351;&#29992;&#24555;&#36895;&#12289;&#36731;&#37327;&#32423;&#30340;1D CNN&#20316;&#20026;&#20027;&#24178;&#65292;&#24182;&#23558;&#19968;&#20123;&#31070;&#32463;&#36807;&#31243;&#26367;&#25442;&#20026;iSTFT&#65292;&#20197;&#33719;&#24471;&#24555;&#36895;&#12289;&#36731;&#37327;&#32423;&#21644;&#39640;&#20445;&#30495;&#24230;&#30340;&#35821;&#38899;&#21512;&#25104;&#12290;&#30001;&#20110;1D CNN&#24456;&#38590;&#27169;&#25311;&#39640;&#32500;&#35889;&#22270;&#65292;&#39057;&#29575;&#32500;&#24230;&#36890;&#36807;&#26102;&#38388;&#19978;&#37319;&#26679;&#36827;&#34892;&#38477;&#32500;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#31574;&#30053;&#20250;&#25439;&#23475;&#22686;&#24378;&#36895;&#24230;&#30340;&#28508;&#21147;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;iSTFTNet2&#65292;&#23427;&#26159;iSTFTNet&#30340;&#25913;&#36827;&#29256;&#26412;&#65292;&#37319;&#29992;1D-2D CNN&#65292;&#20351;&#29992;1D&#21644;2D CNN&#20998;&#21035;&#24314;&#27169;&#26102;&#38388;&#21644;&#35889;&#22270;&#32467;&#26500;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;2D CNN&#65292;&#22312;&#36716;&#25442;&#21040;&#23569;&#37327;&#39057;&#29575;&#31354;&#38388;&#21518;&#25191;&#34892;&#39057;&#29575;&#19978;&#37319;&#26679;&#12290;&#36825;&#31181;&#35774;&#35745;&#20351;&#24471;&#33021;&#22815;&#27169;&#25311;&#39640;&#32500;&#35889;&#22270;&#32780;&#19981;&#25439;&#23475;&#36895;&#24230;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;iSTFTNet2&#20351;&#24471;iSTFTNet&#26356;&#24555;&#12289;&#26356;&#36731;&#37327;&#32423;&#65292;&#21516;&#26102;&#20445;&#25345;&#21487;&#27604;&#36739;&#30340;&#35821;&#38899;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
The inverse short-time Fourier transform network (iSTFTNet) has garnered attention owing to its fast, lightweight, and high-fidelity speech synthesis. It obtains these characteristics using a fast and lightweight 1D CNN as the backbone and replacing some neural processes with iSTFT. Owing to the difficulty of a 1D CNN to model high-dimensional spectrograms, the frequency dimension is reduced via temporal upsampling. However, this strategy compromises the potential to enhance the speed. Therefore, we propose iSTFTNet2, an improved variant of iSTFTNet with a 1D-2D CNN that employs 1D and 2D CNNs to model temporal and spectrogram structures, respectively. We designed a 2D CNN that performs frequency upsampling after conversion in a few-frequency space. This design facilitates the modeling of high-dimensional spectrograms without compromising the speed. The results demonstrated that iSTFTNet2 made iSTFTNet faster and more lightweight with comparable speech quality. Audio samples are availa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#27491;&#21017;&#21270;&#30340;&#39640;&#25928;&#19988;&#26377;&#25928;&#30340;&#27169;&#22411;&#65292;&#29992;&#20110;&#35299;&#20915;&#19981;&#23436;&#25972;&#26631;&#31614;&#20998;&#24067;&#23398;&#20064;&#38382;&#39064;&#12290;&#36890;&#36807;&#27491;&#30830;&#22788;&#29702;&#35266;&#23519;&#21040;&#30340;&#23567;&#24230;&#37327;&#24182;&#36880;&#28176;&#22686;&#21152;&#32570;&#22833;&#24230;&#37327;&#30340;&#26435;&#37325;&#65292;&#21487;&#20197;&#23398;&#20064;&#21040;&#20934;&#30830;&#30340;&#26631;&#31614;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2308.07047</link><description>&lt;p&gt;
&#26080;&#38656;&#27491;&#21017;&#21270;&#65306;&#19968;&#31181;&#29992;&#20110;&#19981;&#23436;&#25972;&#26631;&#31614;&#20998;&#24067;&#23398;&#20064;&#30340;&#39640;&#25928;&#19988;&#26377;&#25928;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
No Regularization is Needed: An Efficient and Effective Model for Incomplete Label Distribution Learning. (arXiv:2308.07047v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07047
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#38656;&#27491;&#21017;&#21270;&#30340;&#39640;&#25928;&#19988;&#26377;&#25928;&#30340;&#27169;&#22411;&#65292;&#29992;&#20110;&#35299;&#20915;&#19981;&#23436;&#25972;&#26631;&#31614;&#20998;&#24067;&#23398;&#20064;&#38382;&#39064;&#12290;&#36890;&#36807;&#27491;&#30830;&#22788;&#29702;&#35266;&#23519;&#21040;&#30340;&#23567;&#24230;&#37327;&#24182;&#36880;&#28176;&#22686;&#21152;&#32570;&#22833;&#24230;&#37327;&#30340;&#26435;&#37325;&#65292;&#21487;&#20197;&#23398;&#20064;&#21040;&#20934;&#30830;&#30340;&#26631;&#31614;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#31614;&#20998;&#24067;&#23398;&#20064;&#65288;LDL&#65289;&#20026;&#26679;&#26412;&#20998;&#37197;&#36719;&#26631;&#31614;&#65292;&#21363;&#24230;&#37327;&#12290;&#29616;&#23454;&#20013;&#65292;&#33719;&#24471;&#23436;&#25972;&#24230;&#37327;&#36890;&#24120;&#26159;&#36153;&#21147;&#30340;&#65292;&#20174;&#32780;&#24341;&#21457;&#20102;&#19981;&#23436;&#25972;LDL&#65288;InLDL&#65289;&#12290;&#28982;&#32780;&#65292;InLDL&#32463;&#24120;&#36973;&#21463;&#24615;&#33021;&#36864;&#21270;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#29616;&#26377;&#26041;&#27861;&#38656;&#35201;&#19968;&#20010;&#25110;&#22810;&#20010;&#26174;&#24335;&#27491;&#21017;&#21270;&#65292;&#23548;&#33268;&#32321;&#29712;&#30340;&#21442;&#25968;&#35843;&#25972;&#21644;&#39069;&#22806;&#30340;&#35745;&#31639;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#26631;&#31614;&#20998;&#24067;&#26412;&#36523;&#21487;&#33021;&#25552;&#20379;&#26377;&#29992;&#30340;&#20808;&#39564;&#20449;&#24687;&#65292;&#24403;&#36866;&#24403;&#20351;&#29992;&#26102;&#65292;&#21487;&#20197;&#22312;&#19981;&#38656;&#35201;&#20219;&#20309;&#26174;&#24335;&#27491;&#21017;&#21270;&#30340;&#24773;&#20917;&#19979;&#35299;&#20915;InLDL&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#21512;&#29702;&#30340;&#26367;&#20195;&#26041;&#27861;&#26469;&#21033;&#29992;&#36825;&#26679;&#30340;&#20808;&#39564;&#20449;&#24687;&#12290;&#25105;&#20204;&#30340;&#35266;&#28857;&#26159;&#22823;&#24230;&#37327;&#24456;&#21487;&#33021;&#26356;&#21463;&#20851;&#27880;&#65292;&#23567;&#24230;&#37327;&#24456;&#23481;&#26131;&#34987;&#24573;&#35270;&#65292;&#32780;&#32570;&#22833;&#30340;&#24230;&#37327;&#22312;InLDL&#20013;&#23436;&#20840;&#34987;&#24573;&#30053;&#12290;&#20026;&#20102;&#23398;&#20064;&#20934;&#30830;&#30340;&#26631;&#31614;&#20998;&#24067;&#65292;&#37325;&#35201;&#30340;&#26159;&#19981;&#24573;&#35270;&#35266;&#23519;&#21040;&#30340;&#23567;&#24230;&#37327;&#65292;&#32780;&#26159;&#32473;&#23427;&#20204;&#36866;&#24403;&#30340;&#22823;&#26435;&#37325;&#65292;&#21516;&#26102;&#36880;&#28176;&#22686;&#21152;&#32570;&#22833;&#24230;&#37327;&#30340;&#26435;&#37325;&#12290;
&lt;/p&gt;
&lt;p&gt;
Label Distribution Learning (LDL) assigns soft labels, a.k.a. degrees, to a sample. In reality, it is always laborious to obtain complete degrees, giving birth to the Incomplete LDL (InLDL). However, InLDL often suffers from performance degeneration. To remedy it, existing methods need one or more explicit regularizations, leading to burdensome parameter tuning and extra computation. We argue that label distribution itself may provide useful prior, when used appropriately, the InLDL problem can be solved without any explicit regularization. In this paper, we offer a rational alternative to use such a prior. Our intuition is that large degrees are likely to get more concern, the small ones are easily overlooked, whereas the missing degrees are completely neglected in InLDL. To learn an accurate label distribution, it is crucial not to ignore the small observed degrees but to give them properly large weights, while gradually increasing the weights of the missing degrees. To this end, we 
&lt;/p&gt;</description></item><item><title>GOCPD&#26159;&#19968;&#31181;&#36138;&#24515;&#31639;&#27861;&#65292;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;&#25968;&#25454;&#26469;&#33258;&#20004;&#20010;&#29420;&#31435;&#27169;&#22411;&#30340;&#27010;&#29575;&#26469;&#25214;&#21040;&#21464;&#28857;&#65292;&#20855;&#26377;&#36739;&#39640;&#30340;&#20934;&#30830;&#24615;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#19977;&#20998;&#25628;&#32034;&#36827;&#34892;&#21152;&#36895;&#12290;</title><link>http://arxiv.org/abs/2308.07012</link><description>&lt;p&gt;
&#36138;&#24515;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Greedy online change point detection. (arXiv:2308.07012v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07012
&lt;/p&gt;
&lt;p&gt;
GOCPD&#26159;&#19968;&#31181;&#36138;&#24515;&#31639;&#27861;&#65292;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;&#25968;&#25454;&#26469;&#33258;&#20004;&#20010;&#29420;&#31435;&#27169;&#22411;&#30340;&#27010;&#29575;&#26469;&#25214;&#21040;&#21464;&#28857;&#65292;&#20855;&#26377;&#36739;&#39640;&#30340;&#20934;&#30830;&#24615;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#19977;&#20998;&#25628;&#32034;&#36827;&#34892;&#21152;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#20934;&#30340;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#26041;&#27861;&#23545;&#24322;&#24120;&#20540;&#25935;&#24863;&#65292;&#23481;&#26131;&#20135;&#29983;&#36739;&#39640;&#30340;&#35823;&#25253;&#29575;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#32570;&#28857;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#19978;&#20855;&#26377;&#21560;&#24341;&#21147;&#30340;&#26041;&#27861;&#8212;&#8212;&#36138;&#24515;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#65288;GOCPD&#65289;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#26368;&#22823;&#21270;&#25968;&#25454;&#26469;&#33258;&#20004;&#20010;&#29420;&#31435;&#27169;&#22411;&#65288;&#26102;&#38388;&#19978;&#30340;&#65289;&#32423;&#32852;&#30340;&#27010;&#29575;&#26469;&#25214;&#21040;&#21464;&#28857;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#20855;&#26377;&#21333;&#20010;&#21464;&#28857;&#30340;&#26102;&#38388;&#24207;&#21015;&#20013;&#65292;&#36825;&#20010;&#30446;&#26631;&#26159;&#21333;&#23792;&#30340;&#65292;&#22240;&#27492;&#21464;&#28857;&#26816;&#27979;&#21487;&#20197;&#36890;&#36807;&#20855;&#26377;&#23545;&#25968;&#22797;&#26434;&#24230;&#30340;&#19977;&#20998;&#25628;&#32034;&#36827;&#34892;&#21152;&#36895;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#25968;&#25454;&#19978;&#39564;&#35777;&#20102;GOCPD&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#22312;&#23454;&#38469;&#30340;&#21333;&#21464;&#37327;&#21644;&#22810;&#21464;&#37327;&#35774;&#32622;&#20013;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Standard online change point detection (CPD) methods tend to have large false discovery rates as their detections are sensitive to outliers. To overcome this drawback, we propose Greedy Online Change Point Detection (GOCPD), a computationally appealing method which finds change points by maximizing the probability of the data coming from the (temporal) concatenation of two independent models. We show that, for time series with a single change point, this objective is unimodal and thus CPD can be accelerated via ternary search with logarithmic complexity. We demonstrate the effectiveness of GOCPD on synthetic data and validate our findings on real-world univariate and multivariate settings.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#26032;&#39062;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#21644;&#26080;&#30417;&#30563;&#25439;&#22833;&#20989;&#25968;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#32479;&#35745;&#24418;&#29366;&#20998;&#26512;&#20013;&#24418;&#29366;&#22270;&#21305;&#37197;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#21305;&#37197;&#24615;&#33021;&#21644;&#35745;&#31639;&#25104;&#26412;&#26041;&#38754;&#23454;&#29616;&#20102;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2308.06869</link><description>&lt;p&gt;
&#24418;&#29366;-&#22270;&#21305;&#37197;&#32593;&#32476;&#65288;SGM-net&#65289;&#65306;&#32479;&#35745;&#24418;&#29366;&#20998;&#26512;&#30340;&#27880;&#20876;
&lt;/p&gt;
&lt;p&gt;
Shape-Graph Matching Network (SGM-net): Registration for Statistical Shape Analysis. (arXiv:2308.06869v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06869
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#26032;&#39062;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#21644;&#26080;&#30417;&#30563;&#25439;&#22833;&#20989;&#25968;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#32479;&#35745;&#24418;&#29366;&#20998;&#26512;&#20013;&#24418;&#29366;&#22270;&#21305;&#37197;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#21305;&#37197;&#24615;&#33021;&#21644;&#35745;&#31639;&#25104;&#26412;&#26041;&#38754;&#23454;&#29616;&#20102;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20027;&#35201;&#30740;&#31350;&#25968;&#25454;&#23545;&#35937;&#24418;&#29366;&#22270;&#30340;&#32479;&#35745;&#20998;&#26512;&#65292;&#21363;&#30001;&#36830;&#25509;&#30528;&#20219;&#24847;&#24418;&#29366;&#30340;&#26354;&#32447;&#30340;&#33410;&#28857;&#38598;&#21512;&#12290;&#36825;&#37324;&#30340;&#20851;&#38190;&#38656;&#27714;&#26159;&#36328;&#23545;&#35937;&#36827;&#34892;&#28857;&#65288;&#33410;&#28857;&#21040;&#33410;&#28857;&#65292;&#36793;&#21040;&#36793;&#65289;&#30340;&#21463;&#38480;&#21046;&#27880;&#20876;&#12290;&#36825;&#21448;&#38656;&#35201;&#22312;&#25490;&#21015;&#32676;&#19978;&#36827;&#34892;&#20248;&#21270;&#65292;&#32473;&#23450;&#33410;&#28857;&#65288;&#25968;&#37327;&#12289;&#20301;&#32622;&#65289;&#21644;&#36793;&#65288;&#24418;&#29366;&#12289;&#25918;&#32622;&#12289;&#22823;&#23567;&#65289;&#22312;&#23545;&#35937;&#20043;&#38388;&#23384;&#22312;&#24046;&#24322;&#30340;&#25361;&#25112;&#12290;&#26412;&#25991;&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#35299;&#20915;&#20102;&#36825;&#20010;&#27880;&#20876;&#38382;&#39064;&#65292;&#24182;&#37319;&#29992;&#24377;&#24615;&#24418;&#29366;&#24230;&#37327;&#26354;&#32447;&#24320;&#21457;&#20102;&#26080;&#30417;&#30563;&#25439;&#22833;&#20989;&#25968;&#12290;&#35813;&#26550;&#26500;&#22312;&#21305;&#37197;&#24615;&#33021;&#26041;&#38754;&#25928;&#26524;&#26174;&#33879;&#65292;&#32780;&#19988;&#30456;&#23545;&#20110;&#22522;&#20934;&#26041;&#27861;&#65292;&#22312;&#35745;&#31639;&#25104;&#26412;&#19978;&#38477;&#20302;&#20102;&#19968;&#20010;&#25968;&#37327;&#32423;&#12290;&#25105;&#20204;&#20351;&#29992;&#27169;&#25311;&#25968;&#25454;&#21644;&#30495;&#23454;&#30340;2D&#21644;3D&#24418;&#29366;&#22270;&#39564;&#35777;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#20195;&#30721;&#21644;&#25968;&#25454;&#23558;&#20844;&#24320;&#25552;&#20379;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper focuses on the statistical analysis of shapes of data objects called shape graphs, a set of nodes connected by articulated curves with arbitrary shapes. A critical need here is a constrained registration of points (nodes to nodes, edges to edges) across objects. This, in turn, requires optimization over the permutation group, made challenging by differences in nodes (in terms of numbers, locations) and edges (in terms of shapes, placements, and sizes) across objects. This paper tackles this registration problem using a novel neural-network architecture and involves an unsupervised loss function developed using the elastic shape metric for curves. This architecture results in (1) state-of-the-art matching performance and (2) an order of magnitude reduction in the computational cost relative to baseline approaches. We demonstrate the effectiveness of the proposed approach using both simulated data and real-world 2D and 3D shape graphs. Code and data will be made publicly avail
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Frechet&#32479;&#35745;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#22810;&#21464;&#37327;Hawkes&#36807;&#31243;&#20013;&#26816;&#27979;&#21464;&#28857;&#12290;&#36890;&#36807;&#23558;&#28857;&#36807;&#31243;&#20998;&#25104;&#31383;&#21475;&#65292;&#24182;&#21033;&#29992;&#26680;&#30697;&#38453;&#26469;&#37325;&#26500;&#26377;&#31526;&#21495;&#30340;&#25289;&#26222;&#25289;&#26031;&#30697;&#38453;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#20934;&#30830;&#22320;&#26816;&#27979;&#21644;&#25551;&#36848;&#22810;&#21464;&#37327;Hawkes&#36807;&#31243;&#22240;&#26524;&#32467;&#26500;&#20013;&#30340;&#21464;&#21270;&#65292;&#20855;&#26377;&#28508;&#22312;&#30340;&#37329;&#34701;&#21644;&#31070;&#32463;&#31185;&#23398;&#31561;&#39046;&#22495;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2308.06769</link><description>&lt;p&gt;
&#22522;&#20110;Frechet&#32479;&#35745;&#30340;&#22810;&#21464;&#37327;Hawkes&#36807;&#31243;&#20013;&#30340;&#21464;&#28857;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Fr\'echet Statistics Based Change Point Detection in Multivariate Hawkes Process. (arXiv:2308.06769v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06769
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Frechet&#32479;&#35745;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#22810;&#21464;&#37327;Hawkes&#36807;&#31243;&#20013;&#26816;&#27979;&#21464;&#28857;&#12290;&#36890;&#36807;&#23558;&#28857;&#36807;&#31243;&#20998;&#25104;&#31383;&#21475;&#65292;&#24182;&#21033;&#29992;&#26680;&#30697;&#38453;&#26469;&#37325;&#26500;&#26377;&#31526;&#21495;&#30340;&#25289;&#26222;&#25289;&#26031;&#30697;&#38453;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#20934;&#30830;&#22320;&#26816;&#27979;&#21644;&#25551;&#36848;&#22810;&#21464;&#37327;Hawkes&#36807;&#31243;&#22240;&#26524;&#32467;&#26500;&#20013;&#30340;&#21464;&#21270;&#65292;&#20855;&#26377;&#28508;&#22312;&#30340;&#37329;&#34701;&#21644;&#31070;&#32463;&#31185;&#23398;&#31561;&#39046;&#22495;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;Frechet&#32479;&#35745;&#26041;&#27861;&#23545;&#22810;&#21464;&#37327;Hawkes&#36807;&#31243;&#20013;&#30340;&#22240;&#26524;&#32593;&#32476;&#36827;&#34892;&#21464;&#28857;&#26816;&#27979;&#30340;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#28857;&#36807;&#31243;&#20998;&#25104;&#37325;&#21472;&#30340;&#31383;&#21475;&#65292;&#22312;&#27599;&#20010;&#31383;&#21475;&#20013;&#20272;&#35745;&#26680;&#30697;&#38453;&#65292;&#24182;&#36890;&#36807;&#23558;&#26680;&#30697;&#38453;&#35270;&#20026;&#22240;&#26524;&#32593;&#32476;&#30340;&#37051;&#25509;&#30697;&#38453;&#26469;&#37325;&#26500;&#26377;&#31526;&#21495;&#30340;&#25289;&#26222;&#25289;&#26031;&#30697;&#38453;&#12290;&#36890;&#36807;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#21152;&#23494;&#36135;&#24065;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26174;&#31034;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#20934;&#30830;&#22320;&#26816;&#27979;&#21644;&#25551;&#36848;&#22810;&#21464;&#37327;Hawkes&#36807;&#31243;&#22240;&#26524;&#32467;&#26500;&#20013;&#30340;&#21464;&#21270;&#65292;&#24182;&#22312;&#37329;&#34701;&#21644;&#31070;&#32463;&#31185;&#23398;&#31561;&#39046;&#22495;&#20855;&#26377;&#28508;&#22312;&#30340;&#24212;&#29992;&#20215;&#20540;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#26159;&#23545;&#28857;&#36807;&#31243;&#35774;&#32622;&#20013;Frechet&#32479;&#35745;&#20043;&#21069;&#24037;&#20316;&#30340;&#25193;&#23637;&#65292;&#24182;&#23545;&#22810;&#21464;&#37327;&#28857;&#36807;&#31243;&#30340;&#21464;&#28857;&#26816;&#27979;&#39046;&#22495;&#20570;&#20986;&#20102;&#37325;&#35201;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a new approach for change point detection in causal networks of multivariate Hawkes processes using Frechet statistics. Our method splits the point process into overlapping windows, estimates kernel matrices in each window, and reconstructs the signed Laplacians by treating the kernel matrices as the adjacency matrices of the causal network. We demonstrate the effectiveness of our method through experiments on both simulated and real-world cryptocurrency datasets. Our results show that our method is capable of accurately detecting and characterizing changes in the causal structure of multivariate Hawkes processes, and may have potential applications in fields such as finance and neuroscience. The proposed method is an extension of previous work on Frechet statistics in point process settings and represents an important contribution to the field of change point detection in multivariate point processes.
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#26435;&#31232;&#30095;&#20559;&#26368;&#23567;&#20108;&#20056;&#65288;wsPLS&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#32852;&#21512;&#26679;&#26412;&#21644;&#29305;&#24449;&#36873;&#25321;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#24341;&#20837;$\ell_\infty/\ell_0$-&#33539;&#25968;&#32422;&#26463;&#26469;&#36873;&#25321;&#29305;&#23450;&#23376;&#38598;&#30340;&#26679;&#26412;&#65292;&#24182;&#35777;&#26126;&#20102;&#32422;&#26463;&#20855;&#26377;&#20840;&#23616;&#25910;&#25947;&#24615;&#36136;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25193;&#23637;&#20102;&#26041;&#27861;&#20197;&#36866;&#29992;&#20110;&#22810;&#35270;&#35282;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2308.06740</link><description>&lt;p&gt;
&#21152;&#26435;&#31232;&#30095;&#20559;&#26368;&#23567;&#20108;&#20056;&#29992;&#20110;&#32852;&#21512;&#26679;&#26412;&#21644;&#29305;&#24449;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Weighted Sparse Partial Least Squares for Joint Sample and Feature Selection. (arXiv:2308.06740v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06740
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21152;&#26435;&#31232;&#30095;&#20559;&#26368;&#23567;&#20108;&#20056;&#65288;wsPLS&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#32852;&#21512;&#26679;&#26412;&#21644;&#29305;&#24449;&#36873;&#25321;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#24341;&#20837;$\ell_\infty/\ell_0$-&#33539;&#25968;&#32422;&#26463;&#26469;&#36873;&#25321;&#29305;&#23450;&#23376;&#38598;&#30340;&#26679;&#26412;&#65292;&#24182;&#35777;&#26126;&#20102;&#32422;&#26463;&#20855;&#26377;&#20840;&#23616;&#25910;&#25947;&#24615;&#36136;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25193;&#23637;&#20102;&#26041;&#27861;&#20197;&#36866;&#29992;&#20110;&#22810;&#35270;&#35282;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31232;&#30095;&#20559;&#26368;&#23567;&#20108;&#20056;&#65288;sPLS&#65289;&#26159;&#19968;&#31181;&#24120;&#35265;&#30340;&#25968;&#25454;&#34701;&#21512;&#38477;&#32500;&#25216;&#26415;&#65292;&#36890;&#36807;&#23547;&#25214;&#20855;&#26377;&#26368;&#22823;&#26041;&#24046;&#30340;&#23569;&#25968;&#21464;&#37327;&#30340;&#32447;&#24615;&#32452;&#21512;&#26469;&#23558;&#25968;&#25454;&#26679;&#26412;&#20174;&#20004;&#20010;&#35270;&#22270;&#25237;&#24433;&#20986;&#26469;&#12290;&#28982;&#32780;&#65292;sPLS&#25552;&#21462;&#30340;&#26159;&#20004;&#20010;&#25968;&#25454;&#38598;&#20043;&#38388;&#30340;&#25152;&#26377;&#25968;&#25454;&#26679;&#26412;&#20043;&#38388;&#30340;&#32452;&#21512;&#65292;&#22240;&#27492;&#26080;&#27861;&#26816;&#27979;&#26679;&#26412;&#30340;&#28508;&#22312;&#23376;&#38598;&#12290;&#20026;&#20102;&#36890;&#36807;&#35782;&#21035;&#29305;&#23450;&#30340;&#26679;&#26412;&#23376;&#38598;&#24182;&#21435;&#38500;&#24322;&#24120;&#20540;&#26469;&#25193;&#23637;sPLS&#30340;&#24212;&#29992;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;$\ell_\infty/\ell_0$-&#33539;&#25968;&#32422;&#26463;&#21152;&#26435;&#31232;&#30095;PLS&#65288;$\ell_\infty/\ell_0$-wsPLS&#65289;&#26041;&#27861;&#65292;&#29992;&#20110;&#32852;&#21512;&#26679;&#26412;&#21644;&#29305;&#24449;&#36873;&#25321;&#65292;&#20854;&#20013;$\ell_\infty/\ell_0$-&#33539;&#25968;&#32422;&#26463;&#29992;&#20110;&#36873;&#25321;&#26679;&#26412;&#23376;&#38598;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;$\ell_\infty/\ell_0$-&#33539;&#25968;&#32422;&#26463;&#20855;&#26377;Kurdyka-\L{ojasiewicz}&#24615;&#36136;&#65292;&#20174;&#32780;&#24320;&#21457;&#20102;&#19968;&#31181;&#20840;&#23616;&#25910;&#25947;&#31639;&#27861;&#26469;&#35299;&#20915;&#23427;&#12290;&#27492;&#22806;&#65292;&#22312;&#21508;&#31181;&#23454;&#38469;&#38382;&#39064;&#20013;&#65292;&#22810;&#35270;&#35282;&#25968;&#25454;&#21487;&#20197;&#20855;&#26377;&#30456;&#21516;&#30340;&#26679;&#26412;&#38598;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;$\ell_\infty$-norm-wsPLS&#26041;&#27861;&#20197;&#36866;&#29992;&#20110;&#22810;&#35270;&#35282;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sparse Partial Least Squares (sPLS) is a common dimensionality reduction technique for data fusion, which projects data samples from two views by seeking linear combinations with a small number of variables with the maximum variance. However, sPLS extracts the combinations between two data sets with all data samples so that it cannot detect latent subsets of samples. To extend the application of sPLS by identifying a specific subset of samples and remove outliers, we propose an $\ell_\infty/\ell_0$-norm constrained weighted sparse PLS ($\ell_\infty/\ell_0$-wsPLS) method for joint sample and feature selection, where the $\ell_\infty/\ell_0$-norm constrains are used to select a subset of samples. We prove that the $\ell_\infty/\ell_0$-norm constrains have the Kurdyka-\L{ojasiewicz}~property so that a globally convergent algorithm is developed to solve it. Moreover, multi-view data with a same set of samples can be available in various real problems. To this end, we extend the $\ell_\inft
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#33258;&#31169;&#23398;&#20064;&#20195;&#29702;&#21644;&#23398;&#20064;&#22996;&#25176;&#20154;&#20043;&#38388;&#30340;&#37325;&#22797;&#23545;&#33258;&#36873;&#28216;&#25103;&#65292;&#25506;&#32034;&#22914;&#20309;&#20272;&#35745;&#21644;&#28608;&#21169;&#20855;&#26377;&#38544;&#34255;&#22870;&#21169;&#30340;&#19981;&#23436;&#20840;&#30693;&#35782;&#20195;&#29702;&#12290;</title><link>http://arxiv.org/abs/2308.06717</link><description>&lt;p&gt;
&#20272;&#35745;&#21644;&#28608;&#21169;&#20855;&#26377;&#38544;&#34255;&#22870;&#21169;&#30340;&#19981;&#23436;&#20840;&#30693;&#35782;&#20195;&#29702;
&lt;/p&gt;
&lt;p&gt;
Estimating and Incentivizing Imperfect-Knowledge Agents with Hidden Rewards. (arXiv:2308.06717v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06717
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#33258;&#31169;&#23398;&#20064;&#20195;&#29702;&#21644;&#23398;&#20064;&#22996;&#25176;&#20154;&#20043;&#38388;&#30340;&#37325;&#22797;&#23545;&#33258;&#36873;&#28216;&#25103;&#65292;&#25506;&#32034;&#22914;&#20309;&#20272;&#35745;&#21644;&#28608;&#21169;&#20855;&#26377;&#38544;&#34255;&#22870;&#21169;&#30340;&#19981;&#23436;&#20840;&#30693;&#35782;&#20195;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#36341;&#20013;&#65292;&#28608;&#21169;&#25552;&#20379;&#32773;&#65288;&#21363;&#22996;&#25176;&#20154;&#65289;&#36890;&#24120;&#26080;&#27861;&#35266;&#23519;&#21463;&#21040;&#28608;&#21169;&#30340;&#20195;&#29702;&#30340;&#22870;&#21169;&#23454;&#29616;&#24773;&#20917;&#65292;&#36825;&#19982;&#35768;&#22810;&#20808;&#21069;&#30740;&#31350;&#36807;&#30340;&#22996;&#25176;&#20154;-&#20195;&#29702;&#27169;&#22411;&#24418;&#25104;&#20102;&#23545;&#27604;&#12290;&#36825;&#31181;&#20449;&#24687;&#19981;&#23545;&#31216;&#24615;&#20351;&#22996;&#25176;&#20154;&#20165;&#36890;&#36807;&#35266;&#23519;&#20195;&#29702;&#30340;&#20915;&#31574;&#23601;&#35201;&#22987;&#32456;&#20272;&#35745;&#20195;&#29702;&#30340;&#26410;&#30693;&#22870;&#21169;&#21464;&#24471;&#26356;&#21152;&#22256;&#38590;&#65292;&#24403;&#20195;&#29702;&#38656;&#35201;&#23398;&#20064;&#33258;&#24049;&#30340;&#22870;&#21169;&#26102;&#65292;&#36825;&#20010;&#25361;&#25112;&#21464;&#24471;&#26356;&#21152;&#22256;&#38590;&#12290;&#36825;&#31181;&#22797;&#26434;&#24773;&#20917;&#22312;&#21508;&#31181;&#29616;&#23454;&#22330;&#26223;&#20013;&#34987;&#35266;&#23519;&#21040;&#65292;&#20174;&#21487;&#20877;&#29983;&#33021;&#28304;&#20648;&#23384;&#21512;&#21516;&#21040;&#20010;&#24615;&#21270;&#21307;&#30103;&#20445;&#20581;&#28608;&#21169;&#12290;&#22240;&#27492;&#65292;&#23427;&#19981;&#20165;&#25552;&#20379;&#20102;&#26377;&#36259;&#30340;&#29702;&#35770;&#38382;&#39064;&#65292;&#32780;&#19988;&#20855;&#26377;&#24191;&#27867;&#30340;&#23454;&#38469;&#30456;&#20851;&#24615;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#19968;&#20010;&#33258;&#31169;&#23398;&#20064;&#20195;&#29702;&#21644;&#23398;&#20064;&#22996;&#25176;&#20154;&#20043;&#38388;&#30340;&#37325;&#22797;&#23545;&#33258;&#36873;&#28216;&#25103;&#12290;&#20195;&#29702;&#35299;&#20915;&#22810;&#33218;&#32769;&#34382;&#26426;&#65288;MAB&#65289;&#38382;&#39064;&#65292;&#20197;&#26368;&#22823;&#21270;&#20182;&#20204;&#39044;&#26399;&#30340;&#22870;&#21169;&#21644;&#28608;&#21169;&#12290;&#38500;&#20195;&#29702;&#30340;&#23398;&#20064;&#22806;&#65292;&#22996;&#25176;&#20154;&#36824;&#35757;&#32451;&#20102;&#19968;&#20010;&#24182;&#34892;&#31639;&#27861;&#65292;&#24182;&#38754;&#20020;&#19968;&#20010;&#25240;&#20013;&#24773;&#20917;
&lt;/p&gt;
&lt;p&gt;
In practice, incentive providers (i.e., principals) often cannot observe the reward realizations of incentivized agents, which is in contrast to many principal-agent models that have been previously studied. This information asymmetry challenges the principal to consistently estimate the agent's unknown rewards by solely watching the agent's decisions, which becomes even more challenging when the agent has to learn its own rewards. This complex setting is observed in various real-life scenarios ranging from renewable energy storage contracts to personalized healthcare incentives. Hence, it offers not only interesting theoretical questions but also wide practical relevance. This paper explores a repeated adverse selection game between a self-interested learning agent and a learning principal. The agent tackles a multi-armed bandit (MAB) problem to maximize their expected reward plus incentive. On top of the agent's learning, the principal trains a parallel algorithm and faces a trade-of
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#20013;&#30340;&#23567;&#25209;&#37327;&#22122;&#38899;&#20250;&#20351;&#35299;&#20915;&#26041;&#26696;&#21521;&#24179;&#34913;&#35299;&#38752;&#36817;&#65292;&#21482;&#35201;&#25439;&#22833;&#20989;&#25968;&#21253;&#21547;&#37325;&#26032;&#32553;&#25918;&#23545;&#31216;&#24615;&#12290;&#21033;&#29992;&#36825;&#20010;&#32467;&#26524;&#65292;&#25105;&#20204;&#23548;&#20986;&#20102;&#23545;&#35282;&#32447;&#24615;&#32593;&#32476;&#30340;&#38543;&#26426;&#26799;&#24230;&#27969;&#31283;&#24577;&#20998;&#24067;&#65292;&#35813;&#20998;&#24067;&#23637;&#31034;&#20102;&#22797;&#26434;&#30340;&#38750;&#32447;&#24615;&#29616;&#35937;&#12290;&#36825;&#20123;&#21457;&#29616;&#25581;&#31034;&#20102;&#21160;&#24577;&#26799;&#24230;&#19979;&#38477;&#27861;&#22312;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#24037;&#20316;&#21407;&#29702;&#12290;</title><link>http://arxiv.org/abs/2308.06671</link><description>&lt;p&gt;
&#21160;&#24577;&#26799;&#24230;&#19979;&#38477;&#27861;&#30340;&#24179;&#34913;&#27861;&#21017;&#19982;&#31283;&#24577;&#20998;&#24067;
&lt;/p&gt;
&lt;p&gt;
Law of Balance and Stationary Distribution of Stochastic Gradient Descent. (arXiv:2308.06671v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06671
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#20013;&#30340;&#23567;&#25209;&#37327;&#22122;&#38899;&#20250;&#20351;&#35299;&#20915;&#26041;&#26696;&#21521;&#24179;&#34913;&#35299;&#38752;&#36817;&#65292;&#21482;&#35201;&#25439;&#22833;&#20989;&#25968;&#21253;&#21547;&#37325;&#26032;&#32553;&#25918;&#23545;&#31216;&#24615;&#12290;&#21033;&#29992;&#36825;&#20010;&#32467;&#26524;&#65292;&#25105;&#20204;&#23548;&#20986;&#20102;&#23545;&#35282;&#32447;&#24615;&#32593;&#32476;&#30340;&#38543;&#26426;&#26799;&#24230;&#27969;&#31283;&#24577;&#20998;&#24067;&#65292;&#35813;&#20998;&#24067;&#23637;&#31034;&#20102;&#22797;&#26434;&#30340;&#38750;&#32447;&#24615;&#29616;&#35937;&#12290;&#36825;&#20123;&#21457;&#29616;&#25581;&#31034;&#20102;&#21160;&#24577;&#26799;&#24230;&#19979;&#38477;&#27861;&#22312;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#24037;&#20316;&#21407;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#31639;&#27861;&#26159;&#25105;&#20204;&#29992;&#20110;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#30340;&#31639;&#27861;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#24456;&#38590;&#29702;&#35299;SGD&#22914;&#20309;&#22312;&#31070;&#32463;&#32593;&#32476;&#30340;&#38750;&#32447;&#24615;&#21644;&#36864;&#21270;&#30340;&#25439;&#22833;&#26354;&#38754;&#20013;&#36827;&#34892;&#23548;&#33322;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;SGD&#30340;&#23567;&#25209;&#37327;&#22122;&#38899;&#21487;&#20197;&#20351;&#35299;&#20915;&#26041;&#26696;&#21521;&#24179;&#34913;&#35299;&#38752;&#36817;&#65292;&#21482;&#35201;&#25439;&#22833;&#20989;&#25968;&#21253;&#21547;&#19968;&#20010;&#37325;&#26032;&#32553;&#25918;&#23545;&#31216;&#24615;&#12290;&#30001;&#20110;&#31616;&#21333;&#25193;&#25955;&#36807;&#31243;&#21644;SGD&#21160;&#21147;&#23398;&#30340;&#24046;&#24322;&#22312;&#23545;&#31216;&#24615;&#23384;&#22312;&#26102;&#26368;&#37325;&#35201;&#65292;&#25105;&#20204;&#30340;&#29702;&#35770;&#34920;&#26126;&#65292;&#25439;&#22833;&#20989;&#25968;&#30340;&#23545;&#31216;&#24615;&#26159;&#20102;&#35299;SGD&#24037;&#20316;&#26041;&#24335;&#30340;&#37325;&#35201;&#32447;&#32034;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#36825;&#20010;&#32467;&#26524;&#24212;&#29992;&#20110;&#23548;&#20986;&#20855;&#26377;&#20219;&#24847;&#28145;&#24230;&#21644;&#23485;&#24230;&#30340;&#23545;&#35282;&#32447;&#24615;&#32593;&#32476;&#30340;&#38543;&#26426;&#26799;&#24230;&#27969;&#30340;&#31283;&#24577;&#20998;&#24067;&#12290;&#31283;&#24577;&#20998;&#24067;&#23637;&#29616;&#20102;&#22797;&#26434;&#30340;&#38750;&#32447;&#24615;&#29616;&#35937;&#65292;&#22914;&#30456;&#21464;&#12289;&#30772;&#22351;&#30340;&#36941;&#21382;&#24615;&#21644;&#27874;&#21160;&#21453;&#36716;&#12290;&#36825;&#20123;&#29616;&#35937;&#20165;&#22312;&#28145;&#23618;&#32593;&#32476;&#20013;&#23384;&#22312;&#65292;&#34920;&#26126;&#20102;&#19968;&#31181;&#22522;&#26412;&#30340;&#26032;&#30340;&#21152;&#28145;&#35757;&#32451;&#29702;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
The stochastic gradient descent (SGD) algorithm is the algorithm we use to train neural networks. However, it remains poorly understood how the SGD navigates the highly nonlinear and degenerate loss landscape of a neural network. In this work, we prove that the minibatch noise of SGD regularizes the solution towards a balanced solution whenever the loss function contains a rescaling symmetry. Because the difference between a simple diffusion process and SGD dynamics is the most significant when symmetries are present, our theory implies that the loss function symmetries constitute an essential probe of how SGD works. We then apply this result to derive the stationary distribution of stochastic gradient flow for a diagonal linear network with arbitrary depth and width. The stationary distribution exhibits complicated nonlinear phenomena such as phase transitions, broken ergodicity, and fluctuation inversion. These phenomena are shown to exist uniquely in deep networks, implying a fundam
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#21160;&#36873;&#25321;&#26368;&#20339;&#30340;&#20301;&#23485;&#21644;&#23618;&#23485;&#26469;&#25552;&#39640;&#32593;&#32476;&#25928;&#29575;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#21098;&#26525;&#21644;&#32858;&#31867;&#25216;&#26415;&#65292;&#20248;&#21270;&#20102;&#25628;&#32034;&#36807;&#31243;&#65292;&#24182;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#20005;&#26684;&#27979;&#35797;&#65292;&#32467;&#26524;&#26174;&#31034;&#35813;&#26041;&#27861;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2308.06422</link><description>&lt;p&gt;
&#20351;&#29992;&#22522;&#20110;&#32858;&#31867;&#30340;&#26641;&#29366;Parzen&#20272;&#35745;&#30340;&#25935;&#24863;&#24615;&#24863;&#30693;&#28151;&#21512;&#31934;&#24230;&#37327;&#21270;&#21644;&#23485;&#24230;&#20248;&#21270;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Sensitivity-Aware Mixed-Precision Quantization and Width Optimization of Deep Neural Networks Through Cluster-Based Tree-Structured Parzen Estimation. (arXiv:2308.06422v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06422
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#21160;&#36873;&#25321;&#26368;&#20339;&#30340;&#20301;&#23485;&#21644;&#23618;&#23485;&#26469;&#25552;&#39640;&#32593;&#32476;&#25928;&#29575;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#21098;&#26525;&#21644;&#32858;&#31867;&#25216;&#26415;&#65292;&#20248;&#21270;&#20102;&#25628;&#32034;&#36807;&#31243;&#65292;&#24182;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#20005;&#26684;&#27979;&#35797;&#65292;&#32467;&#26524;&#26174;&#31034;&#35813;&#26041;&#27861;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#22797;&#26434;&#24615;&#21644;&#35745;&#31639;&#38656;&#27714;&#30340;&#25552;&#39640;&#65292;&#23545;&#31070;&#32463;&#32593;&#32476;&#35774;&#35745;&#30340;&#26377;&#25928;&#20248;&#21270;&#26041;&#27861;&#30340;&#38656;&#27714;&#21464;&#24471;&#33267;&#20851;&#37325;&#35201;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#25628;&#32034;&#26426;&#21046;&#65292;&#29992;&#20110;&#33258;&#21160;&#36873;&#25321;&#21333;&#20010;&#31070;&#32463;&#32593;&#32476;&#23618;&#30340;&#26368;&#20339;&#20301;&#23485;&#21644;&#23618;&#23485;&#12290;&#36825;&#23548;&#33268;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#25928;&#29575;&#30340;&#26126;&#26174;&#25552;&#39640;&#12290;&#36890;&#36807;&#21033;&#29992;&#22522;&#20110;Hessian&#30340;&#21098;&#26525;&#31574;&#30053;&#65292;&#26377;&#36873;&#25321;&#22320;&#20943;&#23569;&#25628;&#32034;&#22495;&#65292;&#30830;&#20445;&#31227;&#38500;&#38750;&#20851;&#38190;&#21442;&#25968;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#22522;&#20110;&#32858;&#31867;&#30340;&#26641;&#29366;Parzen&#20272;&#35745;&#22120;&#24320;&#21457;&#26377;&#21033;&#21644;&#19981;&#21033;&#32467;&#26524;&#30340;&#26367;&#20195;&#27169;&#22411;&#12290;&#36825;&#31181;&#31574;&#30053;&#20801;&#35768;&#23545;&#26550;&#26500;&#21487;&#33021;&#24615;&#36827;&#34892;&#31616;&#21270;&#30340;&#25506;&#32034;&#65292;&#24182;&#36805;&#36895;&#30830;&#23450;&#34920;&#29616;&#26368;&#22909;&#30340;&#35774;&#35745;&#12290;&#36890;&#36807;&#23545;&#30693;&#21517;&#25968;&#25454;&#38598;&#36827;&#34892;&#20005;&#26684;&#27979;&#35797;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#35777;&#26126;&#20102;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#30340;&#26126;&#26174;&#20248;&#21183;&#12290;&#19982;&#39046;&#20808;&#30340;&#21387;&#32553;&#31574;&#30053;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21462;&#24471;&#20102;&#20196;&#20154;&#30633;&#30446;&#30340;&#25104;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
As the complexity and computational demands of deep learning models rise, the need for effective optimization methods for neural network designs becomes paramount. This work introduces an innovative search mechanism for automatically selecting the best bit-width and layer-width for individual neural network layers. This leads to a marked enhancement in deep neural network efficiency. The search domain is strategically reduced by leveraging Hessian-based pruning, ensuring the removal of non-crucial parameters. Subsequently, we detail the development of surrogate models for favorable and unfavorable outcomes by employing a cluster-based tree-structured Parzen estimator. This strategy allows for a streamlined exploration of architectural possibilities and swift pinpointing of top-performing designs. Through rigorous testing on well-known datasets, our method proves its distinct advantage over existing methods. Compared to leading compression strategies, our approach records an impressive 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#23558;&#28151;&#21512;&#25928;&#24212;&#27169;&#22411;&#21644;&#23618;&#27425;&#32858;&#31867;&#24212;&#29992;&#20110;&#36125;&#21494;&#26031;&#32593;&#32476;&#23398;&#20064;&#30340;&#26032;&#26041;&#27861;&#65292;&#22312;&#20892;&#23398;&#30740;&#31350;&#20013;&#24191;&#27867;&#24212;&#29992;&#12290;&#36890;&#36807;&#25972;&#21512;&#38543;&#26426;&#25928;&#24212;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#32467;&#26500;&#23398;&#20064;&#33021;&#21147;&#65292;&#23454;&#29616;&#22240;&#26524;&#20851;&#31995;&#32593;&#32476;&#30340;&#21457;&#29616;&#12290;</title><link>http://arxiv.org/abs/2308.06399</link><description>&lt;p&gt;
&#36890;&#36807;&#28151;&#21512;&#25928;&#24212;&#27169;&#22411;&#21644;&#23618;&#27425;&#32858;&#31867;&#23398;&#20064;&#20855;&#26377;&#24322;&#26500;&#20892;&#19994;&#25968;&#25454;&#38598;&#30340;&#36125;&#21494;&#26031;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Learning Bayesian Networks with Heterogeneous Agronomic Data Sets via Mixed-Effect Models and Hierarchical Clustering. (arXiv:2308.06399v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.06399
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#23558;&#28151;&#21512;&#25928;&#24212;&#27169;&#22411;&#21644;&#23618;&#27425;&#32858;&#31867;&#24212;&#29992;&#20110;&#36125;&#21494;&#26031;&#32593;&#32476;&#23398;&#20064;&#30340;&#26032;&#26041;&#27861;&#65292;&#22312;&#20892;&#23398;&#30740;&#31350;&#20013;&#24191;&#27867;&#24212;&#29992;&#12290;&#36890;&#36807;&#25972;&#21512;&#38543;&#26426;&#25928;&#24212;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#36125;&#21494;&#26031;&#32593;&#32476;&#30340;&#32467;&#26500;&#23398;&#20064;&#33021;&#21147;&#65292;&#23454;&#29616;&#22240;&#26524;&#20851;&#31995;&#32593;&#32476;&#30340;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#28041;&#21450;&#22810;&#26679;&#20294;&#30456;&#20851;&#25968;&#25454;&#38598;&#30340;&#30740;&#31350;&#20013;&#65292;&#20854;&#20013;&#21327;&#21464;&#37327;&#19982;&#32467;&#26524;&#20043;&#38388;&#30340;&#20851;&#32852;&#21487;&#33021;&#20250;&#26377;&#25152;&#19981;&#21516;&#65292;&#22312;&#21253;&#25324;&#20892;&#23398;&#30740;&#31350;&#22312;&#20869;&#30340;&#21508;&#20010;&#39046;&#22495;&#37117;&#24456;&#26222;&#36941;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#24120;&#24120;&#20351;&#29992;&#23618;&#27425;&#27169;&#22411;&#65292;&#20063;&#34987;&#31216;&#20026;&#22810;&#23618;&#27169;&#22411;&#65292;&#26469;&#34701;&#21512;&#26469;&#33258;&#19981;&#21516;&#25968;&#25454;&#38598;&#30340;&#20449;&#24687;&#65292;&#24182;&#36866;&#24212;&#23427;&#20204;&#30340;&#19981;&#21516;&#29305;&#28857;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#32467;&#26500;&#36229;&#20986;&#20102;&#31616;&#21333;&#30340;&#24322;&#36136;&#24615;&#65292;&#22240;&#20026;&#21464;&#37327;&#36890;&#24120;&#24418;&#25104;&#22797;&#26434;&#30340;&#22240;&#26524;&#20851;&#31995;&#32593;&#32476;&#12290;&#36125;&#21494;&#26031;&#32593;&#32476;&#65288;BNs&#65289;&#20351;&#29992;&#26377;&#21521;&#26080;&#29615;&#22270;&#26469;&#27169;&#25311;&#36825;&#31181;&#20851;&#31995;&#30340;&#24378;&#22823;&#26694;&#26550;&#12290;&#26412;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#23558;&#38543;&#26426;&#25928;&#24212;&#25972;&#21512;&#21040;BN&#23398;&#20064;&#20013;&#30340;&#26032;&#26041;&#27861;&#12290;&#36825;&#31181;&#26041;&#27861;&#22522;&#20110;&#32447;&#24615;&#28151;&#21512;&#25928;&#24212;&#27169;&#22411;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#22788;&#29702;&#23618;&#27425;&#25968;&#25454;&#12290;&#26469;&#33258;&#30495;&#23454;&#20892;&#23398;&#35797;&#39564;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#37319;&#29992;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#22686;&#24378;&#32467;&#26500;&#23398;&#20064;&#65292;&#20174;&#32780;&#23454;&#29616;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Research involving diverse but related data sets, where associations between covariates and outcomes may vary, is prevalent in various fields including agronomic studies. In these scenarios, hierarchical models, also known as multilevel models, are frequently employed to assimilate information from different data sets while accommodating their distinct characteristics. However, their structure extend beyond simple heterogeneity, as variables often form complex networks of causal relationships.  Bayesian networks (BNs) provide a powerful framework for modelling such relationships using directed acyclic graphs to illustrate the connections between variables. This study introduces a novel approach that integrates random effects into BN learning. Rooted in linear mixed-effects models, this approach is particularly well-suited for handling hierarchical data. Results from a real-world agronomic trial suggest that employing this approach enhances structural learning, leading to the discovery 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25193;&#23637;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#20351;&#29992;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;BDCM&#65292;&#21487;&#20197;&#22312;&#23384;&#22312;&#26080;&#27861;&#27979;&#37327;&#30340;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#20917;&#19979;&#26356;&#20934;&#30830;&#22320;&#22238;&#31572;&#22240;&#26524;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.03669</link><description>&lt;p&gt;
&#26080;&#27861;&#27979;&#37327;&#28151;&#28102;&#22240;&#32032;&#19979;&#22240;&#26524;&#25512;&#26029;&#20013;&#30340;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Diffusion Model in Causal Inference with Unmeasured Confounders. (arXiv:2308.03669v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03669
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25193;&#23637;&#20102;&#25193;&#25955;&#27169;&#22411;&#30340;&#20351;&#29992;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;BDCM&#65292;&#21487;&#20197;&#22312;&#23384;&#22312;&#26080;&#27861;&#27979;&#37327;&#30340;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#20917;&#19979;&#26356;&#20934;&#30830;&#22320;&#22238;&#31572;&#22240;&#26524;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22914;&#20309;&#22312;&#26080;&#27861;&#27979;&#37327;&#30340;&#28151;&#28102;&#22240;&#32032;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#25193;&#23637;&#25193;&#25955;&#27169;&#22411;&#30340;&#20351;&#29992;&#65292;&#20197;&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#22238;&#31572;&#22240;&#26524;&#38382;&#39064;&#12290;&#22312;Pearl&#30340;&#20351;&#29992;&#26377;&#21521;&#26080;&#29615;&#22270;&#65288;DAG&#65289;&#25429;&#25417;&#22240;&#26524;&#24178;&#39044;&#30340;&#26694;&#26550;&#20013;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#22240;&#26524;&#27169;&#22411;&#65288;DCM&#65289;&#65292;&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#22238;&#31572;&#22240;&#26524;&#38382;&#39064;&#65292;&#20551;&#35774;&#25152;&#26377;&#28151;&#28102;&#22240;&#32032;&#37117;&#26159;&#21487;&#20197;&#35266;&#23519;&#21040;&#30340;&#12290;&#28982;&#32780;&#65292;&#23454;&#38469;&#20013;&#23384;&#22312;&#26080;&#27861;&#27979;&#37327;&#30340;&#28151;&#28102;&#22240;&#32032;&#65292;&#36825;&#20351;&#24471;DCM&#26080;&#27861;&#24212;&#29992;&#12290;&#20026;&#20102;&#32531;&#35299;DCM&#30340;&#36825;&#19968;&#23616;&#38480;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#25193;&#23637;&#27169;&#22411;&#65292;&#31216;&#20026;&#22522;&#20110;&#21453;&#38376;&#20934;&#21017;&#30340;DCM&#65288;BDCM&#65289;&#65292;&#20854;&#24605;&#24819;&#26681;&#26893;&#20110;&#22312;DAG&#20013;&#25214;&#21040;&#35201;&#21253;&#25324;&#22312;&#25193;&#25955;&#27169;&#22411;&#35299;&#30721;&#36807;&#31243;&#20013;&#30340;&#21464;&#37327;&#30340;&#21453;&#38376;&#20934;&#21017;&#65292;&#36825;&#26679;&#25105;&#20204;&#21487;&#20197;&#23558;DCM&#25193;&#23637;&#21040;&#23384;&#22312;&#26080;&#27861;&#27979;&#37327;&#30340;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#20917;&#12290;&#21512;&#25104;&#25968;&#25454;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#27169;&#22411;&#22312;&#26080;&#27861;&#27979;&#37327;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#20917;&#19979;&#26356;&#31934;&#30830;&#22320;&#25429;&#25417;&#21040;&#20102;&#21453;&#20107;&#23454;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study how to extend the use of the diffusion model to answer the causal question from the observational data under the existence of unmeasured confounders. In Pearl's framework of using a Directed Acyclic Graph (DAG) to capture the causal intervention, a Diffusion-based Causal Model (DCM) was proposed incorporating the diffusion model to answer the causal questions more accurately, assuming that all of the confounders are observed. However, unmeasured confounders in practice exist, which hinders DCM from being applicable. To alleviate this limitation of DCM, we propose an extended model called Backdoor Criterion based DCM (BDCM), whose idea is rooted in the Backdoor criterion to find the variables in DAG to be included in the decoding process of the diffusion model so that we can extend DCM to the case with unmeasured confounders. Synthetic data experiment demonstrates that our proposed model captures the counterfactual distribution more precisely than DCM under the unmeasured confo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#20809;&#35889;&#26041;&#27861;&#22312;&#24191;&#20041;&#22810;&#32500;&#27604;&#36739;&#20013;&#20272;&#35745;&#21644;&#37327;&#21270;&#26410;&#35266;&#23519;&#21040;&#30340;&#27604;&#36739;&#23454;&#20307;&#30340;&#20559;&#22909;&#20998;&#25968;&#30340;&#24615;&#33021;&#65292;&#24182;&#25581;&#31034;&#20102;&#20809;&#35889;&#20272;&#35745;&#37327;&#19982;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#37327;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2308.02918</link><description>&lt;p&gt;
&#22522;&#20110;&#24191;&#20041;&#22810;&#32500;&#27604;&#36739;&#30340;&#20809;&#35889;&#25490;&#21517;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Spectral Ranking Inferences based on General Multiway Comparisons. (arXiv:2308.02918v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02918
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#20809;&#35889;&#26041;&#27861;&#22312;&#24191;&#20041;&#22810;&#32500;&#27604;&#36739;&#20013;&#20272;&#35745;&#21644;&#37327;&#21270;&#26410;&#35266;&#23519;&#21040;&#30340;&#27604;&#36739;&#23454;&#20307;&#30340;&#20559;&#22909;&#20998;&#25968;&#30340;&#24615;&#33021;&#65292;&#24182;&#25581;&#31034;&#20102;&#20809;&#35889;&#20272;&#35745;&#37327;&#19982;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#37327;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#19968;&#20010;&#38750;&#24120;&#26222;&#36941;&#21644;&#26356;&#21152;&#30495;&#23454;&#30340;&#24773;&#26223;&#20013;&#65292;&#20351;&#29992;&#20809;&#35889;&#26041;&#27861;&#23545;&#26410;&#35266;&#23519;&#21040;&#30340;&#27604;&#36739;&#23454;&#20307;&#30340;&#20559;&#22909;&#20998;&#25968;&#36827;&#34892;&#20272;&#35745;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#24615;&#33021;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#27604;&#36739;&#22270;&#30001;&#21487;&#33021;&#20855;&#26377;&#24322;&#26500;&#22823;&#23567;&#30340;&#36229;&#36793;&#32452;&#25104;&#65292;&#23545;&#20110;&#32473;&#23450;&#30340;&#36229;&#36793;&#65292;&#27604;&#36739;&#25968;&#37327;&#21487;&#33021;&#20165;&#20026;1&#12290;&#36825;&#31181;&#35774;&#32622;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#26222;&#36941;&#23384;&#22312;&#65292;&#36991;&#20813;&#20102;&#38656;&#35201;&#25351;&#23450;&#22270;&#30340;&#38543;&#26426;&#24615;&#20197;&#21450;&#22312;&#24120;&#29992;&#30340;Bradley-Terry-Luce (BTL)&#25110;Plackett-Luce (PL)&#27169;&#22411;&#20013;&#26045;&#21152;&#30340;&#38480;&#21046;&#24615;&#22343;&#21248;&#37319;&#26679;&#20551;&#35774;&#12290;&#27492;&#22806;&#65292;&#22312;&#36866;&#29992;BTL&#25110;PL&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#20809;&#35889;&#20272;&#35745;&#37327;&#19982;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#37327;&#65288;MLE&#65289;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#36890;&#36807;&#24212;&#29992;&#20174;&#31561;&#26435;&#37325;&#20256;&#32479;&#20809;&#35889;&#26041;&#27861;&#20272;&#35745;&#24471;&#21040;&#30340;&#26368;&#20339;&#21152;&#26435;&#65292;&#21487;&#20197;&#23454;&#29616;&#19982;MLE&#30456;&#21516;&#30340;&#28176;&#36817;&#25928;&#29575;&#30340;&#21452;&#27493;&#20809;&#35889;&#26041;&#27861;&#12290;&#32771;&#34385;&#21040;&#28176;&#36817;&#24773;&#20917;&#65292;
&lt;/p&gt;
&lt;p&gt;
This paper studies the performance of the spectral method in the estimation and uncertainty quantification of the unobserved preference scores of compared entities in a very general and more realistic setup in which the comparison graph consists of hyper-edges of possible heterogeneous sizes and the number of comparisons can be as low as one for a given hyper-edge. Such a setting is pervasive in real applications, circumventing the need to specify the graph randomness and the restrictive homogeneous sampling assumption imposed in the commonly-used Bradley-Terry-Luce (BTL) or Plackett-Luce (PL) models. Furthermore, in the scenarios when the BTL or PL models are appropriate, we unravel the relationship between the spectral estimator and the Maximum Likelihood Estimator (MLE). We discover that a two-step spectral method, where we apply the optimal weighting estimated from the equal weighting vanilla spectral method, can achieve the same asymptotic efficiency as the MLE. Given the asymptot
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#24341;&#20837;&#39640;&#38454;&#24635;&#21464;&#24046;&#27491;&#21017;&#21270;&#30340;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#35757;&#32451;&#38750;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#65292;&#36991;&#20813;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.02293</link><description>&lt;p&gt;
&#29992;&#27491;&#21017;&#21270;&#39640;&#38454;&#24635;&#21464;&#24046;&#30340;&#38543;&#26426;&#20248;&#21270;&#26041;&#27861;&#35757;&#32451;&#38750;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
A stochastic optimization approach to train non-linear neural networks with regularization of higher-order total variation. (arXiv:2308.02293v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.02293
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#24341;&#20837;&#39640;&#38454;&#24635;&#21464;&#24046;&#27491;&#21017;&#21270;&#30340;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#35757;&#32451;&#38750;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#65292;&#36991;&#20813;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#21253;&#25324;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#20869;&#30340;&#39640;&#24230;&#34920;&#36798;&#30340;&#21442;&#25968;&#27169;&#22411;&#21487;&#20197;&#26356;&#22909;&#22320;&#24314;&#27169;&#22797;&#26434;&#27010;&#24565;&#65292;&#20294;&#35757;&#32451;&#36825;&#31181;&#39640;&#24230;&#38750;&#32447;&#24615;&#27169;&#22411;&#24050;&#30693;&#20250;&#23548;&#33268;&#20005;&#37325;&#30340;&#36807;&#25311;&#21512;&#39118;&#38505;&#12290;&#38024;&#23545;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#30740;&#31350;&#32771;&#34385;&#20102;&#19968;&#31181;k&#38454;&#24635;&#21464;&#24046;&#65288;k-TV&#65289;&#27491;&#21017;&#21270;&#65292;&#23427;&#34987;&#23450;&#20041;&#20026;&#35201;&#35757;&#32451;&#30340;&#21442;&#25968;&#27169;&#22411;&#30340;k&#38454;&#23548;&#25968;&#30340;&#24179;&#26041;&#31215;&#20998;&#65292;&#36890;&#36807;&#24809;&#32602;k-TV&#26469;&#20135;&#29983;&#19968;&#20010;&#26356;&#24179;&#28369;&#30340;&#20989;&#25968;&#65292;&#20174;&#32780;&#36991;&#20813;&#36807;&#25311;&#21512;&#12290;&#23613;&#31649;&#23558;k-TV&#39033;&#24212;&#29992;&#20110;&#19968;&#33324;&#30340;&#21442;&#25968;&#27169;&#22411;&#30001;&#20110;&#31215;&#20998;&#32780;&#23548;&#33268;&#35745;&#31639;&#22797;&#26434;&#65292;&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#31181;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#35757;&#32451;&#24102;&#26377;k-TV&#27491;&#21017;&#21270;&#30340;&#19968;&#33324;&#27169;&#22411;&#65292;&#32780;&#26080;&#38656;&#36827;&#34892;&#26174;&#24335;&#30340;&#25968;&#20540;&#31215;&#20998;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#32467;&#26500;&#20219;&#24847;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#65292;&#22240;&#20026;&#23427;&#21482;&#38656;&#35201;&#36827;&#34892;&#31616;&#21333;&#30340;&#38543;&#26426;&#26799;&#24230;&#20248;&#21270;&#21363;&#21487;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
While highly expressive parametric models including deep neural networks have an advantage to model complicated concepts, training such highly non-linear models is known to yield a high risk of notorious overfitting. To address this issue, this study considers a $k$th order total variation ($k$-TV) regularization, which is defined as the squared integral of the $k$th order derivative of the parametric models to be trained; penalizing the $k$-TV is expected to yield a smoother function, which is expected to avoid overfitting. While the $k$-TV terms applied to general parametric models are computationally intractable due to the integration, this study provides a stochastic optimization algorithm, that can efficiently train general models with the $k$-TV regularization without conducting explicit numerical integration. The proposed approach can be applied to the training of even deep neural networks whose structure is arbitrary, as it can be implemented by only a simple stochastic gradien
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#21644;&#40065;&#26834;&#30340;&#26041;&#27861;&#26469;&#36817;&#20284;&#35745;&#31639;&#22810;&#20803;&#27491;&#24577;&#20998;&#24067;&#20043;&#38388;&#30340;Fisher-Rao&#36317;&#31163;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31867;&#22522;&#20110;&#27491;&#24577;&#27969;&#24418;&#23884;&#20837;&#21040;&#39640;&#32500;&#23545;&#31216;&#27491;&#23450;&#38181;&#23376;&#27969;&#24418;&#30340;&#36317;&#31163;&#12290;</title><link>http://arxiv.org/abs/2307.10644</link><description>&lt;p&gt;
Fisher-Rao&#36317;&#31163;&#21644;&#36870;&#25512;&#21040;SPD&#38181;&#36317;&#31163;&#22312;&#22810;&#20803;&#27491;&#24577;&#20998;&#24067;&#20043;&#38388;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Fisher-Rao distance and pullback SPD cone distances between multivariate normal distributions. (arXiv:2307.10644v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10644
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#21644;&#40065;&#26834;&#30340;&#26041;&#27861;&#26469;&#36817;&#20284;&#35745;&#31639;&#22810;&#20803;&#27491;&#24577;&#20998;&#24067;&#20043;&#38388;&#30340;Fisher-Rao&#36317;&#31163;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#31867;&#22522;&#20110;&#27491;&#24577;&#27969;&#24418;&#23884;&#20837;&#21040;&#39640;&#32500;&#23545;&#31216;&#27491;&#23450;&#38181;&#23376;&#27969;&#24418;&#30340;&#36317;&#31163;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#31185;&#23398;&#39046;&#22495;&#65292;&#22914;&#25193;&#25955;&#24352;&#37327;&#25104;&#20687;&#12289;&#32467;&#26500;&#24352;&#37327;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#38647;&#36798;&#20449;&#21495;&#22788;&#29702;&#21644;&#26426;&#22120;&#23398;&#20064;&#31561;&#65292;&#37117;&#23384;&#22312;&#30528;&#22810;&#20803;&#27491;&#24577;&#20998;&#24067;&#30340;&#25968;&#25454;&#38598;&#12290;&#20026;&#20102;&#22788;&#29702;&#36825;&#20123;&#27491;&#24577;&#25968;&#25454;&#38598;&#20197;&#36827;&#34892;&#36807;&#28388;&#12289;&#20998;&#31867;&#25110;&#32858;&#31867;&#31561;&#19979;&#28216;&#20219;&#21153;&#65292;&#38656;&#35201;&#23450;&#20041;&#21512;&#36866;&#30340;&#27491;&#24577;&#21644;&#23427;&#20204;&#20043;&#38388;&#30340;&#36335;&#24452;&#20043;&#38388;&#30340;&#24046;&#24322;&#24230;&#37327;&#12290;Fisher-Rao&#36317;&#31163;&#65292;&#20316;&#20026;Fisher&#20449;&#24687;&#24230;&#37327;&#24341;&#36215;&#30340;Riemann&#20960;&#20309;&#36317;&#31163;&#65292;&#26159;&#19968;&#31181;&#21512;&#29702;&#30340;&#24230;&#37327;&#36317;&#31163;&#65292;&#20294;&#38500;&#20102;&#19968;&#20123;&#29305;&#27530;&#24773;&#20917;&#22806;&#65292;&#24182;&#27809;&#26377;&#38381;&#24335;&#27714;&#35299;&#12290;&#26412;&#25991;&#39318;&#20808;&#25253;&#21578;&#20102;&#19968;&#31181;&#24555;&#36895;&#19988;&#40065;&#26834;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#31934;&#30830;&#22320;&#36817;&#20284;&#35745;&#31639;&#22810;&#20803;&#27491;&#24577;&#20998;&#24067;&#20043;&#38388;&#30340;Fisher-Rao&#36317;&#31163;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31867;&#22522;&#20110;&#27491;&#24577;&#27969;&#24418;&#21040;&#39640;&#32500;&#23545;&#31216;&#27491;&#23450;&#38181;&#30340;&#23376;&#27969;&#24418;&#30340;&#24494;&#20998;&#21516;&#32986;&#23884;&#20837;&#30340;&#36317;&#31163;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data sets of multivariate normal distributions abound in many scientific areas like diffusion tensor imaging, structure tensor computer vision, radar signal processing, machine learning, just to name a few. In order to process those normal data sets for downstream tasks like filtering, classification or clustering, one needs to define proper notions of dissimilarities between normals and paths joining them. The Fisher-Rao distance defined as the Riemannian geodesic distance induced by the Fisher information metric is such a principled metric distance which however is not known in closed-form excepts for a few particular cases. In this work, we first report a fast and robust method to approximate arbitrarily finely the Fisher-Rao distance between multivariate normal distributions. Second, we introduce a class of distances based on diffeomorphic embeddings of the normal manifold into a submanifold of the higher-dimensional symmetric positive-definite cone corresponding to the manifold of
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#23545;GP-UCB&#31639;&#27861;&#36827;&#34892;&#25913;&#36827;&#65292;&#20351;&#20854;&#20855;&#26377;&#20960;&#20046;&#26368;&#20248;&#30340;&#27425;&#32447;&#24615;&#36951;&#25022;&#65292;&#24182;&#35299;&#20915;&#20102;&#20851;&#20110;&#36951;&#25022;&#20998;&#26512;&#30340;&#24320;&#25918;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.07539</link><description>&lt;p&gt;
&#22312;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#25913;&#36827;&#33258;&#26631;&#20934;&#21270;&#27987;&#24230;&#65306;&#23545;GP-UCB&#31639;&#27861;&#30340;&#27425;&#32447;&#24615;&#36951;&#25022;
&lt;/p&gt;
&lt;p&gt;
Improved Self-Normalized Concentration in Hilbert Spaces: Sublinear Regret for GP-UCB. (arXiv:2307.07539v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.07539
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#23545;GP-UCB&#31639;&#27861;&#36827;&#34892;&#25913;&#36827;&#65292;&#20351;&#20854;&#20855;&#26377;&#20960;&#20046;&#26368;&#20248;&#30340;&#27425;&#32447;&#24615;&#36951;&#25022;&#65292;&#24182;&#35299;&#20915;&#20102;&#20851;&#20110;&#36951;&#25022;&#20998;&#26512;&#30340;&#24320;&#25918;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26680;&#21270;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#65292;&#23398;&#20064;&#22120;&#26088;&#22312;&#36890;&#36807;&#20165;&#22312;&#39034;&#24207;&#36873;&#25321;&#30340;&#28857;&#22788;&#36827;&#34892;&#22122;&#22768;&#35780;&#20272;&#65292;&#39034;&#24207;&#35745;&#31639;&#20301;&#20110;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#20989;&#25968;&#30340;&#26368;&#20248;&#35299;&#12290;&#29305;&#21035;&#22320;&#65292;&#23398;&#20064;&#22120;&#26088;&#22312;&#26368;&#23567;&#21270;&#36951;&#25022;&#65292;&#36951;&#25022;&#26159;&#25152;&#20570;&#36873;&#25321;&#30340;&#27425;&#20248;&#24615;&#24230;&#37327;&#12290;&#21487;&#20197;&#35828;&#26368;&#21463;&#27426;&#36814;&#30340;&#31639;&#27861;&#26159;&#39640;&#26031;&#36807;&#31243;&#19978;&#30028;&#32622;&#20449;&#21306;&#38388;&#65288;GP-UCB&#65289;&#31639;&#27861;&#65292;&#23427;&#28041;&#21450;&#26681;&#25454;&#26410;&#30693;&#20989;&#25968;&#30340;&#31616;&#21333;&#32447;&#24615;&#20272;&#35745;&#22120;&#36827;&#34892;&#34892;&#21160;&#12290;&#23613;&#31649;&#23427;&#24456;&#21463;&#27426;&#36814;&#65292;&#20294;&#29616;&#26377;&#30340;GP-UCB&#36951;&#25022;&#20998;&#26512;&#32473;&#20986;&#20102;&#27425;&#20248;&#36951;&#25022;&#29575;&#65292;&#23545;&#20110;&#35768;&#22810;&#24120;&#29992;&#30340;&#20869;&#26680;&#65288;&#22914;Mat&#233;rn&#20869;&#26680;&#65289;&#32780;&#35328;&#65292;&#36951;&#25022;&#29575;&#24182;&#19981;&#27425;&#32447;&#24615;&#12290;&#36825;&#24341;&#21457;&#20102;&#19968;&#20010;&#38271;&#26399;&#23384;&#22312;&#30340;&#38382;&#39064;&#65306;&#29616;&#26377;&#30340;GP-UCB&#36951;&#25022;&#20998;&#26512;&#26159;&#21542;&#32039;&#23494;&#65292;&#25110;&#32773;&#26159;&#21542;&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;&#26356;&#22797;&#26434;&#30340;&#20998;&#26512;&#25216;&#26415;&#25913;&#36827;&#30028;&#38480;&#65311;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#36825;&#20010;&#24320;&#25918;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;GP-UCB&#20855;&#26377;&#20960;&#20046;&#26368;&#20248;&#30340;&#36951;&#25022;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#30452;&#25509;&#26263;&#31034;&#20102;&#27425;&#32447;&#24615;&#36951;&#25022;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the kernelized bandit problem, a learner aims to sequentially compute the optimum of a function lying in a reproducing kernel Hilbert space given only noisy evaluations at sequentially chosen points. In particular, the learner aims to minimize regret, which is a measure of the suboptimality of the choices made. Arguably the most popular algorithm is the Gaussian Process Upper Confidence Bound (GP-UCB) algorithm, which involves acting based on a simple linear estimator of the unknown function. Despite its popularity, existing analyses of GP-UCB give a suboptimal regret rate, which fails to be sublinear for many commonly used kernels such as the Mat\'ern kernel. This has led to a longstanding open question: are existing regret analyses for GP-UCB tight, or can bounds be improved by using more sophisticated analytical techniques? In this work, we resolve this open question and show that GP-UCB enjoys nearly optimal regret. In particular, our results directly imply sublinear regret rate
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26368;&#20248;&#36816;&#36755;&#21644;&#21464;&#20998;&#25512;&#26029;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36335;&#24452;&#31354;&#38388;&#25955;&#24230;&#30340;&#37319;&#26679;&#21644;&#29983;&#25104;&#24314;&#27169;&#26694;&#26550;&#12290;&#36890;&#36807;&#24320;&#21457;&#26032;&#39062;&#30340;&#22522;&#20110;&#24471;&#20998;&#30340;&#22238;&#28779;&#27969;&#25216;&#26415;&#21644;&#27491;&#21017;&#21270;&#30340;&#36845;&#20195;&#27604;&#20363;&#25311;&#21512;&#30446;&#26631;&#65292;&#26412;&#25991;&#23637;&#31034;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2307.01050</link><description>&lt;p&gt;
&#36816;&#36755;&#12289;&#21464;&#20998;&#25512;&#26029;&#21644;&#25193;&#25955;&#65306;&#24212;&#29992;&#20110;&#22238;&#28779;&#27969;&#21644;&#34203;&#23450;&#35860;&#26725;&#30340;&#35770;&#25991;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Transport, Variational Inference and Diffusions: with Applications to Annealed Flows and Schr\"odinger Bridges. (arXiv:2307.01050v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01050
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26368;&#20248;&#36816;&#36755;&#21644;&#21464;&#20998;&#25512;&#26029;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36335;&#24452;&#31354;&#38388;&#25955;&#24230;&#30340;&#37319;&#26679;&#21644;&#29983;&#25104;&#24314;&#27169;&#26694;&#26550;&#12290;&#36890;&#36807;&#24320;&#21457;&#26032;&#39062;&#30340;&#22522;&#20110;&#24471;&#20998;&#30340;&#22238;&#28779;&#27969;&#25216;&#26415;&#21644;&#27491;&#21017;&#21270;&#30340;&#36845;&#20195;&#27604;&#20363;&#25311;&#21512;&#30446;&#26631;&#65292;&#26412;&#25991;&#23637;&#31034;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#26368;&#20248;&#36816;&#36755;&#19982;&#21464;&#20998;&#25512;&#26029;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#37325;&#28857;&#30740;&#31350;&#20102;&#27491;&#21521;&#21644;&#21453;&#21521;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#20197;&#21450;Girsanov&#21464;&#25442;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#36335;&#24452;&#31354;&#38388;&#25955;&#24230;&#30340;&#37319;&#26679;&#21644;&#29983;&#25104;&#24314;&#27169;&#30340;&#21407;&#21017;&#24615;&#21644;&#31995;&#32479;&#24615;&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#26368;&#32456;&#21457;&#23637;&#20986;&#19968;&#20010;&#26032;&#39062;&#30340;&#22522;&#20110;&#24471;&#20998;&#30340;&#22238;&#28779;&#27969;&#25216;&#26415;&#65288;&#19982;&#32479;&#35745;&#29289;&#29702;&#20013;&#30340;Jarzynski&#21644;Crooks&#24658;&#31561;&#24335;&#26377;&#20851;&#65289;&#21644;&#19968;&#20010;&#27491;&#21017;&#21270;&#30340;&#36845;&#20195;&#27604;&#20363;&#25311;&#21512;&#65288;IPF&#65289;&#22411;&#30446;&#26631;&#65292;&#19981;&#21516;&#20110;&#26631;&#20934;IPF&#30340;&#39034;&#24207;&#24615;&#12290;&#36890;&#36807;&#19968;&#31995;&#21015;&#30340;&#29983;&#25104;&#24314;&#27169;&#31034;&#20363;&#21644;&#22522;&#20110;&#21452;&#20117;&#30340;&#31232;&#26377;&#20107;&#20214;&#20219;&#21153;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#25552;&#26041;&#27861;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper explores the connections between optimal transport and variational inference, with a focus on forward and reverse time stochastic differential equations and Girsanov transformations.We present a principled and systematic framework for sampling and generative modelling centred around divergences on path space. Our work culminates in the development of a novel score-based annealed flow technique (with connections to Jarzynski and Crooks identities from statistical physics) and a regularised iterative proportional fitting (IPF)-type objective, departing from the sequential nature of standard IPF. Through a series of generative modelling examples and a double-well-based rare event task, we showcase the potential of the proposed methods.
&lt;/p&gt;</description></item><item><title>&#20998;&#25955;SGD&#21644;&#24179;&#22343;&#26041;&#21521;SAM&#22312;&#28176;&#36817;&#24847;&#20041;&#19979;&#26159;&#31561;&#20215;&#30340;&#65292;D-SGD&#34920;&#29616;&#20986;&#26799;&#24230;&#24179;&#28369;&#25928;&#24212;&#21644;&#38160;&#24230;&#27491;&#21017;&#21270;&#25928;&#24212;&#65292;&#32780;&#19988;&#21487;&#20197;&#25552;&#39640;&#21518;&#39564;&#35780;&#20272;&#65292;&#24182;&#35777;&#26126;&#20102;&#28508;&#22312;&#30340;&#27867;&#21270;&#33021;&#21147;</title><link>http://arxiv.org/abs/2306.02913</link><description>&lt;p&gt;
&#20998;&#25955;&#21270;SGD&#21644;&#24179;&#22343;&#26041;&#21521;SAM&#22312;&#28176;&#36817;&#24847;&#20041;&#19979;&#26159;&#31561;&#20215;&#30340;
&lt;/p&gt;
&lt;p&gt;
Decentralized SGD and Average-direction SAM are Asymptotically Equivalent. (arXiv:2306.02913v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02913
&lt;/p&gt;
&lt;p&gt;
&#20998;&#25955;SGD&#21644;&#24179;&#22343;&#26041;&#21521;SAM&#22312;&#28176;&#36817;&#24847;&#20041;&#19979;&#26159;&#31561;&#20215;&#30340;&#65292;D-SGD&#34920;&#29616;&#20986;&#26799;&#24230;&#24179;&#28369;&#25928;&#24212;&#21644;&#38160;&#24230;&#27491;&#21017;&#21270;&#25928;&#24212;&#65292;&#32780;&#19988;&#21487;&#20197;&#25552;&#39640;&#21518;&#39564;&#35780;&#20272;&#65292;&#24182;&#35777;&#26126;&#20102;&#28508;&#22312;&#30340;&#27867;&#21270;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#25955;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;D-SGD&#65289;&#20801;&#35768;&#22312;&#27809;&#26377;&#20013;&#22830;&#26381;&#21153;&#22120;&#30340;&#25511;&#21046;&#19979;&#65292;&#22823;&#37327;&#35774;&#22791;&#21516;&#26102;&#36827;&#34892;&#21327;&#20316;&#23398;&#20064;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#29702;&#35770;&#35748;&#20026;&#65292;&#20998;&#25955;&#21270;&#19981;&#21487;&#36991;&#20813;&#22320;&#21066;&#24369;&#20102;&#27867;&#21270;&#33021;&#21147;&#12290;&#26412;&#25991;&#25361;&#25112;&#20256;&#32479;&#20449;&#24565;&#65292;&#25552;&#20986;&#20102;&#23436;&#20840;&#26032;&#30340;&#35282;&#24230;&#26469;&#29702;&#35299;&#20998;&#25955;&#23398;&#20064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#19968;&#33324;&#38750;&#20984;&#38750;-$\beta$-&#24179;&#28369;&#35774;&#32622;&#19979;&#65292;D-SGD&#38544;&#24335;&#22320;&#26368;&#23567;&#21270;&#20102;&#24179;&#22343;&#26041;&#21521;&#38160;&#24230;&#24863;&#30693;&#26368;&#23567;&#21270;&#65288;SAM&#65289;&#31639;&#27861;&#30340;&#25439;&#22833;&#20989;&#25968;&#12290;&#36825;&#31181;&#24778;&#20154;&#30340;&#28176;&#36817;&#31561;&#20215;&#25581;&#31034;&#20102;&#20869;&#22312;&#30340;&#27491;&#21017;&#21270;-&#20248;&#21270;&#26435;&#34913;&#20197;&#21450;&#20998;&#25955;&#21270;&#30340;&#19977;&#20010;&#20248;&#28857;&#65306;&#65288;1&#65289;D-SGD&#20013;&#23384;&#22312;&#19968;&#20010;&#33258;&#30001;&#30340;&#19981;&#30830;&#23450;&#24615;&#35780;&#20272;&#26426;&#21046;&#65292;&#21487;&#20197;&#25552;&#39640;&#21518;&#39564;&#20272;&#35745;&#65307;&#65288;2&#65289;D-SGD&#34920;&#29616;&#20986;&#26799;&#24230;&#24179;&#28369;&#25928;&#24212;&#65307;&#65288;3&#65289;D-SGD&#30340;&#38160;&#24230;&#27491;&#21017;&#21270;&#25928;&#24212;&#19981;&#20250;&#38543;&#30528;&#24635;&#25209;&#22788;&#29702;&#22823;&#23567;&#30340;&#22686;&#21152;&#32780;&#20943;&#23569;&#65292;&#36825;&#35777;&#26126;&#20102;&#28508;&#22312;&#30340;&#27867;&#21270;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Decentralized stochastic gradient descent (D-SGD) allows collaborative learning on massive devices simultaneously without the control of a central server. However, existing theories claim that decentralization invariably undermines generalization. In this paper, we challenge the conventional belief and present a completely new perspective for understanding decentralized learning. We prove that D-SGD implicitly minimizes the loss function of an average-direction Sharpness-aware minimization (SAM) algorithm under general non-convex non-$\beta$-smooth settings. This surprising asymptotic equivalence reveals an intrinsic regularization-optimization trade-off and three advantages of decentralization: (1) there exists a free uncertainty evaluation mechanism in D-SGD to improve posterior estimation; (2) D-SGD exhibits a gradient smoothing effect; and (3) the sharpness regularization effect of D-SGD does not decrease as total batch size increases, which justifies the potential generalization b
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#27867;&#21270;&#35823;&#24046;&#30340;&#26032;&#19979;&#30028;&#65292;&#25506;&#35752;&#20102;&#23398;&#20064;&#24179;&#28369;&#20989;&#25968;&#26102;&#38656;&#35201;&#30340;&#26679;&#26412;&#25968;&#37327;&#21450;&#20854;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20013;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2305.16014</link><description>&lt;p&gt;
&#24403;&#21069;&#26426;&#22120;&#23398;&#20064;&#38656;&#35201;&#22810;&#23569;&#26679;&#26412;&#25165;&#33021;&#21033;&#29992;&#24179;&#28369;&#24615;&#65311;
&lt;/p&gt;
&lt;p&gt;
How many samples are needed to leverage smoothness?. (arXiv:2305.16014v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16014
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#27867;&#21270;&#35823;&#24046;&#30340;&#26032;&#19979;&#30028;&#65292;&#25506;&#35752;&#20102;&#23398;&#20064;&#24179;&#28369;&#20989;&#25968;&#26102;&#38656;&#35201;&#30340;&#26679;&#26412;&#25968;&#37327;&#21450;&#20854;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20013;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32479;&#35745;&#23398;&#20064;&#30340;&#26680;&#24515;&#21407;&#21017;&#20043;&#19968;&#26159;&#65292;&#30446;&#26631;&#20989;&#25968;&#30340;&#24179;&#28369;&#24615;&#21487;&#20197;&#25171;&#30772;&#32500;&#24230;&#28798;&#38590;&#12290;&#28982;&#32780;&#65292;&#36890;&#36807;&#27888;&#21202;&#23637;&#24320;&#23398;&#20064;&#24179;&#28369;&#20989;&#25968;&#38656;&#35201;&#36275;&#22815;&#25509;&#36817;&#19968;&#36215;&#30340;&#26679;&#26412;&#26469;&#33719;&#24471;&#39640;&#38454;&#23548;&#25968;&#30340;&#26377;&#24847;&#20041;&#20272;&#35745;&#65292;&#36825;&#22312;&#25968;&#25454;&#37327;&#30456;&#23545;&#36739;&#23567;&#30340;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#20013;&#20284;&#20046;&#24456;&#22256;&#38590;&#12290;&#26412;&#25991;&#36890;&#36807;&#25512;&#23548;&#24191;&#20041;&#27867;&#21270;&#35823;&#24046;&#30340;&#26032;&#30340;&#19979;&#30028;&#65292;&#30740;&#31350;&#20102;&#24120;&#25968;&#21644;&#30636;&#24577;&#21306;&#22495;&#22312;&#23454;&#36341;&#20013;&#36890;&#24120;&#34987;&#24573;&#30053;&#21364;&#21457;&#25381;&#20102;&#20027;&#23548;&#20316;&#29992;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
A core principle in statistical learning is that smoothness of target functions allows to break the curse of dimensionality. However, learning a smooth function through Taylor expansions requires enough samples close to one another to get meaningful estimate of high-order derivatives, which seems hard in machine learning problems where the ratio between number of data and input dimension is relatively small. Should we really hope to break the curse of dimensionality based on Taylor expansion estimation? What happens if Taylor expansions are replaced by Fourier or wavelet expansions? By deriving a new lower bound on the generalization error, this paper investigates the role of constants and transitory regimes which are usually not depicted beyond classical learning theory statements while that play a dominant role in practice.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#35757;&#32451;&#21644;&#26223;&#35266;&#35821;&#20041;&#20998;&#21106;&#20013;&#30340;&#25968;&#25454;&#20934;&#22791;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#20998;&#23618;&#38543;&#26426;&#25277;&#26679;&#26041;&#27861;&#21644;&#36739;&#23569;&#30340;&#22823;&#34917;&#19969;&#33021;&#25913;&#21892;&#27169;&#22411;&#20934;&#30830;&#24615;&#65292;&#32780;&#25968;&#25454;&#22686;&#24378;&#21644;&#32553;&#25918;&#23545;&#21019;&#24314;&#19968;&#33324;&#21270;&#27169;&#22411;&#38750;&#24120;&#37325;&#35201;&#12290;</title><link>http://arxiv.org/abs/2304.14625</link><description>&lt;p&gt;
&#39044;&#22788;&#29702;&#35757;&#32451;&#25968;&#25454;&#25913;&#21892;&#20102;&#22522;&#20110;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#26223;&#35266;&#35821;&#20041;&#20998;&#21106;&#30340;&#20934;&#30830;&#24615;&#21644;&#21487;&#27867;&#21270;&#24615;
&lt;/p&gt;
&lt;p&gt;
Pre-processing training data improves accuracy and generalisability of convolutional neural network based landscape semantic segmentation. (arXiv:2304.14625v1 [cs.CV] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14625
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#35757;&#32451;&#21644;&#26223;&#35266;&#35821;&#20041;&#20998;&#21106;&#20013;&#30340;&#25968;&#25454;&#20934;&#22791;&#26041;&#27861;&#65292;&#24182;&#21457;&#29616;&#20998;&#23618;&#38543;&#26426;&#25277;&#26679;&#26041;&#27861;&#21644;&#36739;&#23569;&#30340;&#22823;&#34917;&#19969;&#33021;&#25913;&#21892;&#27169;&#22411;&#20934;&#30830;&#24615;&#65292;&#32780;&#25968;&#25454;&#22686;&#24378;&#21644;&#32553;&#25918;&#23545;&#21019;&#24314;&#19968;&#33324;&#21270;&#27169;&#22411;&#38750;&#24120;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#28595;&#22823;&#21033;&#20122;&#26118;&#22763;&#20848;&#24030;&#28287;&#28909;&#24102;&#21644;&#38463;&#29791;&#39039;&#39640;&#21407;&#22320;&#21306;&#30340;&#33322;&#31354;&#25668;&#24433;&#20013;&#65292;&#35797;&#39564;&#20102;&#19981;&#21516;&#30340;&#25968;&#25454;&#20934;&#22791;&#26041;&#27861;&#65292;&#29992;&#20110;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#35757;&#32451;&#21644;&#22303;&#22320;&#21033;&#29992;&#22303;&#22320;&#35206;&#30422;&#65288;LULC&#65289;&#29305;&#24449;&#30340;&#35821;&#20041;&#20998;&#21106;&#12290;&#36890;&#36807;&#35797;&#39564;&#21644;&#25490;&#21517;&#19981;&#21516;&#30340;&#35757;&#32451;&#34917;&#19969;&#36873;&#25321;&#37319;&#26679;&#31574;&#30053;&#65292;&#34917;&#19969;&#21644;&#25209;&#27425;&#22823;&#23567;&#20197;&#21450;&#25968;&#25454;&#22686;&#24378;&#21644;&#32553;&#25918;&#65292;&#25105;&#20204;&#27604;&#36739;&#20102;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#12290;&#36890;&#36807;&#29983;&#25104;LULC&#20998;&#31867;&#65292;&#25105;&#20204;&#36824;&#27604;&#36739;&#20102;&#20351;&#29992;&#19968;&#20010;&#32593;&#26684;&#34917;&#19969;&#30340;&#21333;&#27425;&#20256;&#36882;&#21644;&#22810;&#27425;&#20256;&#36882;&#20197;&#21450;&#27599;&#20010;&#34917;&#19969;&#30340;&#19977;&#20010;&#26059;&#36716;&#29256;&#26412;&#30340;&#27169;&#22411;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65306;&#23545;&#20110;&#20135;&#29983;&#35757;&#32451;&#34917;&#19969;&#65292;&#20998;&#23618;&#38543;&#26426;&#25277;&#26679;&#26041;&#27861;&#25913;&#21892;&#20102;&#38754;&#31215;&#36739;&#23567;&#30340;&#31867;&#21035;&#30340;&#20934;&#30830;&#24615;&#65292;&#23545;&#36739;&#22823;&#31867;&#21035;&#30340;&#24433;&#21709;&#24456;&#23567;&#65307;&#30456;&#36739;&#20110;&#36739;&#22810;&#30340;&#23567;&#34917;&#19969;&#65292;&#36739;&#23569;&#30340;&#22823;&#34917;&#19969;&#33021;&#25552;&#39640;&#27169;&#22411;&#20934;&#30830;&#24615;&#65307;&#24212;&#29992;&#25968;&#25454;&#22686;&#24378;&#21644;&#32553;&#25918;&#23545;&#21019;&#24314;&#19968;&#33324;&#21270;&#27169;&#22411;&#33267;&#20851;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we trialled different methods of data preparation for Convolutional Neural Network (CNN) training and semantic segmentation of land use land cover (LULC) features within aerial photography over the Wet Tropics and Atherton Tablelands, Queensland, Australia. This was conducted through trialling and ranking various training patch selection sampling strategies, patch and batch sizes and data augmentations and scaling. We also compared model accuracy through producing the LULC classification using a single pass of a grid of patches and averaging multiple grid passes and three rotated version of each patch. Our results showed: a stratified random sampling approach for producing training patches improved the accuracy of classes with a smaller area while having minimal effect on larger classes; a smaller number of larger patches compared to a larger number of smaller patches improves model accuracy; applying data augmentations and scaling are imperative in creating a generalise
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#32034;&#20102;&#33258;&#21160;&#21435;&#20559;&#37325;&#37325;&#37197;&#30340;&#26032;&#39062;&#29305;&#24449;&#25551;&#36848;&#65292;&#24182;&#23558;&#20854;&#31561;&#21516;&#20110;&#22522;&#20110;&#20869;&#26680;&#23725;&#22238;&#24402;&#30340;&#21333;&#20010;&#27424;&#24179;&#28369;&#23725;&#22238;&#24402;&#65292;&#36827;&#19968;&#27493;&#23558;&#36825;&#31181;&#26041;&#27861;&#25512;&#24191;&#21040;&#29305;&#23450;&#30340;&#32467;&#26524;&#21644;&#37325;&#37197;&#27169;&#22411;&#36873;&#25321;&#19978;&#12290;</title><link>http://arxiv.org/abs/2304.14545</link><description>&lt;p&gt;
&#33258;&#21160;&#21435;&#20559;&#37325;&#37325;&#37197;&#20316;&#20026;&#32447;&#24615;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Augmented balancing weights as linear regression. (arXiv:2304.14545v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.14545
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#32034;&#20102;&#33258;&#21160;&#21435;&#20559;&#37325;&#37325;&#37197;&#30340;&#26032;&#39062;&#29305;&#24449;&#25551;&#36848;&#65292;&#24182;&#23558;&#20854;&#31561;&#21516;&#20110;&#22522;&#20110;&#20869;&#26680;&#23725;&#22238;&#24402;&#30340;&#21333;&#20010;&#27424;&#24179;&#28369;&#23725;&#22238;&#24402;&#65292;&#36827;&#19968;&#27493;&#23558;&#36825;&#31181;&#26041;&#27861;&#25512;&#24191;&#21040;&#29305;&#23450;&#30340;&#32467;&#26524;&#21644;&#37325;&#37197;&#27169;&#22411;&#36873;&#25321;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20379;&#20102;&#23545;&#20110;&#33258;&#21160;&#21435;&#20559;&#37325;&#37325;&#37197;(AutoDML)&#30340;&#26032;&#39062;&#29305;&#24449;&#25551;&#36848;&#12290;&#36825;&#20123;&#20272;&#31639;&#22120;&#23558;&#32467;&#26524;&#24314;&#27169;&#19982;&#37325;&#37197;&#30456;&#32467;&#21512;&#65292;&#30452;&#25509;&#20272;&#35745;&#21453;&#21521;&#20542;&#21521;&#31215;&#20998;&#26435;&#37325;&#12290;&#24403;&#32467;&#26524;&#19982;&#26435;&#37325;&#27169;&#22411;&#37117;&#26159;&#26576;&#20123;&#65288;&#21487;&#33021;&#26159;&#26080;&#38480;&#30340;&#65289;&#22522;&#30784;&#20013;&#30340;&#32447;&#24615;&#26102;&#65292;&#25105;&#20204;&#34920;&#26126;&#22686;&#24378;&#30340;&#20272;&#31639;&#22120;&#31561;&#21516;&#20110;&#20855;&#26377;&#23558;&#21407;&#22987;&#32467;&#26524;&#27169;&#22411;&#31995;&#25968;&#21644;OLS&#30456;&#32467;&#21512;&#30340;&#31995;&#25968;&#30340;&#21333;&#20010;&#32447;&#24615;&#27169;&#22411;&#65307;&#22312;&#35768;&#22810;&#35774;&#32622;&#20013;&#65292;&#22686;&#24378;&#20272;&#31639;&#22120;&#21512;&#24182;&#20026;&#20165;&#20351;&#29992;OLS. &#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#36825;&#20123;&#32467;&#26524;&#25193;&#23637;&#21040;&#29305;&#23450;&#30340;&#32467;&#26524;&#21644;&#37325;&#37197;&#27169;&#22411;&#36873;&#25321;&#19978;&#12290;&#25105;&#20204;&#39318;&#20808;&#34920;&#26126;&#65292;&#20351;&#29992;(&#20869;&#26680;)&#23725;&#22238;&#24402;&#20316;&#20026;&#32467;&#26524;&#21644;&#37325;&#37197;&#27169;&#22411;&#30340;&#32852;&#21512;&#20272;&#31639;&#22120;&#31561;&#21516;&#20110;&#21333;&#20010;&#12289;&#27424;&#24179;&#28369;(&#20869;&#26680;)&#23725;&#22238;&#24402;&#65307;&#24403;&#32771;&#34385;&#21040;&#28176;&#36817;&#36895;&#29575;&#26102;&#65292;&#36825;&#19968;&#32467;&#26524;&#20063;&#25104;&#31435;&#12290;&#24403;&#20195;&#26367;&#26435;&#37325;&#27169;&#22411;&#20026;&#22871;&#32034;&#22238;&#24402;&#26102;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#29305;&#27530;&#24773;&#20917;&#30340;&#35299;&#26512;&#34920;&#36798;&#24335;&#24182;&#19988;&#28436;&#31034;&#20102;&#8230;
&lt;/p&gt;
&lt;p&gt;
We provide a novel characterization of augmented balancing weights, also known as Automatic Debiased Machine Learning (AutoDML). These estimators combine outcome modeling with balancing weights, which estimate inverse propensity score weights directly. When the outcome and weighting models are both linear in some (possibly infinite) basis, we show that the augmented estimator is equivalent to a single linear model with coefficients that combine the original outcome model coefficients and OLS; in many settings, the augmented estimator collapses to OLS alone. We then extend these results to specific choices of outcome and weighting models. We first show that the combined estimator that uses (kernel) ridge regression for both outcome and weighting models is equivalent to a single, undersmoothed (kernel) ridge regression; this also holds when considering asymptotic rates. When the weighting model is instead lasso regression, we give closed-form expressions for special cases and demonstrate
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#31867;&#26041;&#27861;&#65292;&#29992;&#20110;&#25552;&#39640;&#40065;&#26834;&#24615;&#65292;&#20943;&#23569;&#26631;&#31614;&#22122;&#22768;&#30340;&#24433;&#21709;&#65292;&#20854;&#22522;&#20110;&#27491;&#24577;&#20998;&#24067;&#65292;&#24182;&#21487;&#36890;&#36807;&#26368;&#23567;&#21270;&#36127;&#23545;&#25968;&#20284;&#28982;&#26469;&#23398;&#20064;&#21442;&#25968;&#12290;</title><link>http://arxiv.org/abs/2304.02849</link><description>&lt;p&gt;
&#20998;&#31867;&#20013;&#24322;&#26041;&#24046;&#26631;&#31614;&#22122;&#22768;&#30340;&#36923;&#36753;&#27491;&#24577;&#20284;&#28982;
&lt;/p&gt;
&lt;p&gt;
Logistic-Normal Likelihoods for Heteroscedastic Label Noise in Classification. (arXiv:2304.02849v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.02849
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#31867;&#26041;&#27861;&#65292;&#29992;&#20110;&#25552;&#39640;&#40065;&#26834;&#24615;&#65292;&#20943;&#23569;&#26631;&#31614;&#22122;&#22768;&#30340;&#24433;&#21709;&#65292;&#20854;&#22522;&#20110;&#27491;&#24577;&#20998;&#24067;&#65292;&#24182;&#21487;&#36890;&#36807;&#26368;&#23567;&#21270;&#36127;&#23545;&#25968;&#20284;&#28982;&#26469;&#23398;&#20064;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22238;&#24402;&#20013;&#20272;&#35745;&#24322;&#26041;&#24046;&#26631;&#31614;&#22122;&#22768;&#30340;&#19968;&#31181;&#33258;&#28982;&#26041;&#27861;&#26159;&#23558;&#35266;&#27979;&#21040;&#30340;&#65288;&#21487;&#33021;&#24102;&#26377;&#22122;&#22768;&#30340;&#65289;&#30446;&#26631;&#24314;&#27169;&#20026;&#19968;&#20010;&#27491;&#24577;&#20998;&#24067;&#30340;&#26679;&#26412;&#65292;&#20854;&#21442;&#25968;&#21487;&#20197;&#36890;&#36807;&#26368;&#23567;&#21270;&#36127;&#23545;&#25968;&#20284;&#28982;&#26469;&#23398;&#20064;&#12290;&#35813;&#25439;&#22833;&#20855;&#26377;&#26399;&#26395;&#30340;&#25439;&#22833;&#34928;&#20943;&#29305;&#24615;&#65292;&#22240;&#20026;&#23427;&#21487;&#20197;&#38477;&#20302;&#39640;&#35823;&#24046;&#31034;&#20363;&#30340;&#36129;&#29486;&#12290;&#30452;&#35266;&#22320;&#35828;&#65292;&#36825;&#31181;&#34892;&#20026;&#21487;&#20197;&#36890;&#36807;&#20943;&#23569;&#36807;&#25311;&#21512;&#26469;&#25552;&#39640;&#23545;&#26631;&#31614;&#22122;&#22768;&#30340;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#36825;&#31181;&#31616;&#21333;&#19988;&#27010;&#29575;&#21270;&#26041;&#27861;&#22312;&#20998;&#31867;&#20013;&#30340;&#25193;&#23637;&#65292;&#20855;&#26377;&#30456;&#21516;&#30340;&#26399;&#26395;&#25439;&#22833;&#34928;&#20943;&#29305;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#27979;&#37327;&#20854;&#23545;&#20998;&#31867;&#20013;&#26631;&#31614;&#22122;&#22768;&#30340;&#40065;&#26834;&#24615;&#26469;&#35780;&#20272;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#21551;&#21457;&#24615;&#30340;&#23454;&#39564;&#65292;&#25506;&#32034;&#20102;&#35813;&#26041;&#27861;&#30340;&#20869;&#37096;&#24037;&#20316;&#21407;&#29702;&#65292;&#21253;&#25324;&#23545;&#36229;&#21442;&#25968;&#30340;&#25935;&#24863;&#24615;&#65292;&#28040;&#34701;&#30740;&#31350;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;
A natural way of estimating heteroscedastic label noise in regression is to model the observed (potentially noisy) target as a sample from a normal distribution, whose parameters can be learned by minimizing the negative log-likelihood. This loss has desirable loss attenuation properties, as it can reduce the contribution of high-error examples. Intuitively, this behavior can improve robustness against label noise by reducing overfitting. We propose an extension of this simple and probabilistic approach to classification that has the same desirable loss attenuation properties. We evaluate the effectiveness of the method by measuring its robustness against label noise in classification. We perform enlightening experiments exploring the inner workings of the method, including sensitivity to hyperparameters, ablation studies, and more.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#20915;&#31574;&#20272;&#35745;&#31995;&#25968;&#21644;Estimation-to-Decisions&#20803;&#31639;&#27861;&#65292;&#22312;&#26080;&#27169;&#22411;&#24378;&#21270;&#23398;&#20064;&#20013;&#32467;&#21512;&#20048;&#35266;&#20272;&#35745;&#65292;&#25552;&#20379;&#20102;&#26356;&#23485;&#26494;&#30340;&#20272;&#35745;&#35823;&#24046;&#27010;&#24565;&#30340;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2211.14250</link><description>&lt;p&gt;
&#26080;&#27169;&#22411;&#24378;&#21270;&#23398;&#20064;&#19982;&#20915;&#31574;&#20272;&#35745;&#31995;&#25968;
&lt;/p&gt;
&lt;p&gt;
Model-Free Reinforcement Learning with the Decision-Estimation Coefficient. (arXiv:2211.14250v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.14250
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#20915;&#31574;&#20272;&#35745;&#31995;&#25968;&#21644;Estimation-to-Decisions&#20803;&#31639;&#27861;&#65292;&#22312;&#26080;&#27169;&#22411;&#24378;&#21270;&#23398;&#20064;&#20013;&#32467;&#21512;&#20048;&#35266;&#20272;&#35745;&#65292;&#25552;&#20379;&#20102;&#26356;&#23485;&#26494;&#30340;&#20272;&#35745;&#35823;&#24046;&#27010;&#24565;&#30340;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20132;&#20114;&#24335;&#20915;&#31574;&#38382;&#39064;&#65292;&#28085;&#30422;&#32467;&#26500;&#21270;&#36172;&#21338;&#26426;&#21644;&#20855;&#26377;&#36890;&#29992;&#20989;&#25968;&#36924;&#36817;&#30340;&#24378;&#21270;&#23398;&#20064;&#12290;&#26368;&#36817;&#65292;Foster&#31561;&#20154;&#65288;2021&#65289;&#24341;&#20837;&#20102;&#20915;&#31574;&#20272;&#35745;&#31995;&#25968;&#65292;&#36825;&#26159;&#19968;&#31181;&#32479;&#35745;&#22797;&#26434;&#24230;&#30340;&#24230;&#37327;&#65292;&#20854;&#20026;&#20132;&#20114;&#24335;&#20915;&#31574;&#21046;&#23450;&#20102;&#19968;&#20010;&#26368;&#20248;&#36951;&#25022;&#30340;&#19979;&#30028;&#65292;&#24182;&#24341;&#20837;&#20102;Estimation-to-Decisions&#20803;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20197;&#30456;&#21516;&#25968;&#37327;&#20026;&#19978;&#30028;&#12290;Estimation-to-Decisions&#26159;&#19968;&#31181;&#32422;&#31616;&#65292;&#23558;&#65288;&#30417;&#30563;&#65289;&#22312;&#32447;&#20272;&#35745;&#30340;&#31639;&#27861;&#25552;&#21319;&#20026;&#20915;&#31574;&#21046;&#23450;&#30340;&#31639;&#27861;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#36807;&#23558;Estimation-to-Decisions&#19982;Zhang&#65288;2022&#65289;&#24341;&#20837;&#30340;&#19968;&#31181;&#19987;&#38376;&#30340;&#20048;&#35266;&#20272;&#35745;&#24418;&#24335;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#24471;&#21040;&#27604;Foster&#31561;&#20154;&#65288;2021&#65289;&#26356;&#20026;&#23485;&#26494;&#30340;&#20272;&#35745;&#35823;&#24046;&#27010;&#24565;&#30340;&#20445;&#35777;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#31181;&#26041;&#27861;&#23548;&#20986;&#20102;&#19982;&#20540;&#20989;&#25968;&#36924;&#36817;&#30456;&#32467;&#21512;&#30340;&#26080;&#27169;&#22411;&#24378;&#21270;&#23398;&#20064;&#30340;&#36951;&#25022;&#30028;&#65292;&#24182;&#32473;&#20986;&#20102;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of interactive decision making, encompassing structured bandits and reinforcement learning with general function approximation. Recently, Foster et al. (2021) introduced the Decision-Estimation Coefficient, a measure of statistical complexity that lower bounds the optimal regret for interactive decision making, as well as a meta-algorithm, Estimation-to-Decisions, which achieves upper bounds in terms of the same quantity. Estimation-to-Decisions is a reduction, which lifts algorithms for (supervised) online estimation into algorithms for decision making. In this paper, we show that by combining Estimation-to-Decisions with a specialized form of optimistic estimation introduced by Zhang (2022), it is possible to obtain guarantees that improve upon those of Foster et al. (2021) by accommodating more lenient notions of estimation error. We use this approach to derive regret bounds for model-free reinforcement learning with value function approximation, and give str
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#38543;&#26426;&#29305;&#24449;&#22238;&#24402;(RFRR)&#22312;&#20960;&#20046;&#27491;&#20132;&#25968;&#25454;&#19978;&#30340;&#34892;&#20026;&#65292;&#35777;&#26126;&#20102;&#22312;&#31532;&#19968;&#23618;&#23485;&#24230;&#22823;&#20110;&#26679;&#26412;&#22823;&#23567;&#30340;&#24773;&#20917;&#19979;&#65292;RFRR&#30340;&#35757;&#32451;&#35823;&#24046;&#12289;&#20132;&#21449;&#39564;&#35777;&#21644;&#27867;&#21270;&#35823;&#24046;&#21487;&#20197;&#39640;&#27010;&#29575;&#38598;&#20013;&#22312;&#26680;&#23725;&#22238;&#24402;(KRR)&#30340;&#30456;&#24212;&#20540;&#21608;&#22260;&#65292;&#21516;&#26102;&#32473;&#20986;&#20102;&#29992;&#22810;&#39033;&#24335;&#26680;&#36817;&#20284;KRR&#24615;&#33021;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2211.06077</link><description>&lt;p&gt;
&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#38543;&#26426;&#29305;&#24449;&#22238;&#24402;&#19982;&#20960;&#20046;&#27491;&#20132;&#25968;&#25454;
&lt;/p&gt;
&lt;p&gt;
Overparameterized random feature regression with nearly orthogonal data. (arXiv:2211.06077v3 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.06077
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#38543;&#26426;&#29305;&#24449;&#22238;&#24402;(RFRR)&#22312;&#20960;&#20046;&#27491;&#20132;&#25968;&#25454;&#19978;&#30340;&#34892;&#20026;&#65292;&#35777;&#26126;&#20102;&#22312;&#31532;&#19968;&#23618;&#23485;&#24230;&#22823;&#20110;&#26679;&#26412;&#22823;&#23567;&#30340;&#24773;&#20917;&#19979;&#65292;RFRR&#30340;&#35757;&#32451;&#35823;&#24046;&#12289;&#20132;&#21449;&#39564;&#35777;&#21644;&#27867;&#21270;&#35823;&#24046;&#21487;&#20197;&#39640;&#27010;&#29575;&#38598;&#20013;&#22312;&#26680;&#23725;&#22238;&#24402;(KRR)&#30340;&#30456;&#24212;&#20540;&#21608;&#22260;&#65292;&#21516;&#26102;&#32473;&#20986;&#20102;&#29992;&#22810;&#39033;&#24335;&#26680;&#36817;&#20284;KRR&#24615;&#33021;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;&#29305;&#24449;&#23725;&#22238;&#24402; (RFRR)&#65292;&#20854;&#20013;&#21253;&#25324;&#19968;&#20010;&#20855;&#26377;&#38543;&#26426;&#39640;&#26031;&#21021;&#22987;&#21270;&#30340;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#36807;&#24230;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#65292;&#31532;&#19968;&#23618;&#30340;&#23485;&#24230;&#36828;&#22823;&#20110;&#26679;&#26412;&#22823;&#23567;&#30340;&#26465;&#20214;&#19979;&#65292;&#37319;&#29992;&#20960;&#20046;&#27491;&#20132;&#30830;&#23450;&#24615;&#21333;&#20301;&#38271;&#24230;&#36755;&#20837;&#25968;&#25454;&#21521;&#37327;&#36827;&#34892; RFRR &#30340;&#38750;&#28176;&#36817;&#34892;&#20026;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#26174;&#31034;&#20102; RFRR &#35757;&#32451;&#35823;&#24046;&#12289;&#20132;&#21449;&#39564;&#35777;&#21644;&#27867;&#21270;&#35823;&#24046;&#30340;&#38750;&#28176;&#36817;&#38598;&#20013;&#32467;&#26524;&#65292;&#22312;&#26680;&#23725;&#22238;&#24402; (KRR) &#30340;&#30456;&#24212;&#20540;&#21608;&#22260;&#26377;&#39640;&#27010;&#29575;&#20986;&#29616;&#12290;&#35813; KRR &#26159;&#30001;&#38750;&#32447;&#24615;&#38543;&#26426;&#29305;&#24449;&#26144;&#23556;&#29983;&#25104;&#30340;&#26399;&#26395;&#26680;&#23548;&#20986;&#30340;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#28608;&#27963;&#20989;&#25968;&#30340; Hermite &#22810;&#39033;&#24335;&#23637;&#24320;&#33719;&#24471;&#30340;&#22810;&#39033;&#24335;&#26680;&#30697;&#38453;&#26469;&#36817;&#20284; KRR &#30340;&#24615;&#33021;&#65292;&#20854;&#27425;&#25968;&#20165;&#21462;&#20915;&#20110;&#19981;&#21516;&#25968;&#25454;&#28857;&#20043;&#38388;&#30340;&#27491;&#20132;&#24615;&#12290;&#36825;&#20010;&#22810;&#39033;&#24335;&#26680;&#30830;&#23450;&#20102; RFRR &#21644; KRR &#30340;&#28176;&#36817;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the properties of random feature ridge regression (RFRR) given by a two-layer neural network with random Gaussian initialization. We study the non-asymptotic behaviors of the RFRR with nearly orthogonal deterministic unit-length input data vectors in the overparameterized regime, where the width of the first layer is much larger than the sample size. Our analysis shows high-probability non-asymptotic concentration results for the training errors, cross-validations, and generalization errors of RFRR centered around their respective values for a kernel ridge regression (KRR). This KRR is derived from an expected kernel generated by a nonlinear random feature map. We then approximate the performance of the KRR by a polynomial kernel matrix obtained from the Hermite polynomial expansion of the activation function, whose degree only depends on the orthogonality among different data points. This polynomial kernel determines the asymptotic behavior of the RFRR and the KRR. Our 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#39640;&#26031;&#36807;&#31243;&#25554;&#20540;&#20013;&#20809;&#28369;&#21442;&#25968;&#20272;&#35745;&#30340;&#28176;&#36817;&#30028;&#38480;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#20809;&#28369;&#21442;&#25968;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#19981;&#33021;&#22312;&#28176;&#36817;&#24847;&#20041;&#19979;&#27424;&#24179;&#28369;&#30495;&#20540;&#65292;&#24182;&#19988;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#33021;&#24674;&#22797;&#19968;&#31867;&#20998;&#27573;&#25903;&#25345;&#33258;&#30456;&#20284;&#20989;&#25968;&#30340;&#30495;&#23454;&#20809;&#28369;&#24230;&#12290;</title><link>http://arxiv.org/abs/2203.05400</link><description>&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#25554;&#20540;&#20013;&#20809;&#28369;&#21442;&#25968;&#20272;&#35745;&#30340;&#28176;&#36817;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Asymptotic Bounds for Smoothness Parameter Estimates in Gaussian Process Interpolation. (arXiv:2203.05400v4 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.05400
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#39640;&#26031;&#36807;&#31243;&#25554;&#20540;&#20013;&#20809;&#28369;&#21442;&#25968;&#20272;&#35745;&#30340;&#28176;&#36817;&#30028;&#38480;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#20809;&#28369;&#21442;&#25968;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#19981;&#33021;&#22312;&#28176;&#36817;&#24847;&#20041;&#19979;&#27424;&#24179;&#28369;&#30495;&#20540;&#65292;&#24182;&#19988;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#33021;&#24674;&#22797;&#19968;&#31867;&#20998;&#27573;&#25903;&#25345;&#33258;&#30456;&#20284;&#20989;&#25968;&#30340;&#30495;&#23454;&#20809;&#28369;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24120;&#35265;&#30340;&#26041;&#27861;&#26159;&#29992;Matern&#21327;&#26041;&#24046;&#26680;&#23558;&#30830;&#23450;&#24615;&#21709;&#24212;&#20989;&#25968;&#65288;&#22914;&#35745;&#31639;&#26426;&#23454;&#39564;&#30340;&#36755;&#20986;&#65289;&#24314;&#27169;&#20026;&#39640;&#26031;&#36807;&#31243;&#12290;Matern&#26680;&#30340;&#20809;&#28369;&#21442;&#25968;&#20915;&#23450;&#20102;&#27169;&#22411;&#22312;&#22823;&#25968;&#25454;&#26497;&#38480;&#19979;&#30340;&#35768;&#22810;&#37325;&#35201;&#23646;&#24615;&#65292;&#21253;&#25324;&#26465;&#20214;&#22343;&#20540;&#25910;&#25947;&#21040;&#21709;&#24212;&#20989;&#25968;&#30340;&#36895;&#29575;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#24403;&#25968;&#25454;&#22312;&#22266;&#23450;&#26377;&#30028;&#23376;&#38598;$\mathbb{R}^d$&#19978;&#33719;&#24471;&#26102;&#65292;&#20809;&#28369;&#21442;&#25968;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#19981;&#33021;&#22312;&#28176;&#36817;&#24847;&#20041;&#19979;&#27424;&#24179;&#28369;&#30495;&#20540;&#12290;&#25442;&#21477;&#35805;&#35828;&#65292;&#22914;&#26524;&#25968;&#25454;&#29983;&#25104;&#30340;&#21709;&#24212;&#20989;&#25968;&#20855;&#26377;Sobolev&#20809;&#28369;&#24230;$\nu_0 &gt; d/2$&#65292;&#37027;&#20040;&#20809;&#28369;&#21442;&#25968;&#20272;&#35745;&#19981;&#33021;&#22312;&#28176;&#36817;&#24847;&#20041;&#19979;&#23567;&#20110;$\nu_0$&#12290;&#36825;&#19968;&#19979;&#30028;&#26159;&#31934;&#20934;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22312;&#19968;&#31867;&#20998;&#27573;&#25903;&#25345;&#33258;&#30456;&#20284;&#20989;&#25968;&#20013;&#33021;&#24674;&#22797;&#30495;&#23454;&#30340;&#20809;&#28369;&#24230;&#12290;&#23545;&#20110;&#20132;&#21449;&#39564;&#35777;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;&#28176;&#36817;&#19979;&#30028;$\nu_0-d/2$&#65292;&#20294;&#36825;&#24456;&#19981;&#21487;&#33021;&#25104;&#31435;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is common to model a deterministic response function, such as the output of a computer experiment, as a Gaussian process with a Mat\'ern covariance kernel. The smoothness parameter of a Mat\'ern kernel determines many important properties of the model in the large data limit, including the rate of convergence of the conditional mean to the response function. We prove that the maximum likelihood estimate of the smoothness parameter cannot asymptotically undersmooth the truth when the data are obtained on a fixed bounded subset of $\mathbb{R}^d$. That is, if the data-generating response function has Sobolev smoothness $\nu_0 &gt; d/2$, then the smoothness parameter estimate cannot be asymptotically less than $\nu_0$. The lower bound is sharp. Additionally, we show that maximum likelihood estimation recovers the true smoothness for a class of compactly supported self-similar functions. For cross-validation we prove an asymptotic lower bound $\nu_0 - d/2$, which however is unlikely to be s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#26377;&#22122;&#22768;&#30340;&#26080;&#24207;&#30697;&#38453;&#27169;&#22411;&#30340;&#30697;&#38453;&#37325;&#25490;&#24207;&#38382;&#39064;&#65292;&#24314;&#31435;&#20102;&#26368;&#20248;&#35299;&#30340;&#32479;&#35745;&#26497;&#38480;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#25928;&#29575;&#36739;&#39640;&#30340;&#31639;&#27861;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#31639;&#27861;&#22312;&#22788;&#29702;&#21333;&#32454;&#32990;RNA&#27979;&#24207;&#25968;&#25454;&#26102;&#20855;&#26377;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2201.06438</link><description>&lt;p&gt;
&#22522;&#20110;&#26377;&#22122;&#22768;&#30340;&#26080;&#24207;&#30697;&#38453;&#30340;&#30697;&#38453;&#37325;&#25490;&#24207;&#65306;&#26368;&#20248;&#24615;&#21644;&#35745;&#31639;&#25928;&#29575;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Matrix Reordering for Noisy Disordered Matrices: Optimality and Computationally Efficient Algorithms. (arXiv:2201.06438v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.06438
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#26377;&#22122;&#22768;&#30340;&#26080;&#24207;&#30697;&#38453;&#27169;&#22411;&#30340;&#30697;&#38453;&#37325;&#25490;&#24207;&#38382;&#39064;&#65292;&#24314;&#31435;&#20102;&#26368;&#20248;&#35299;&#30340;&#32479;&#35745;&#26497;&#38480;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#25928;&#29575;&#36739;&#39640;&#30340;&#31639;&#27861;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#31639;&#27861;&#22312;&#22788;&#29702;&#21333;&#32454;&#32990;RNA&#27979;&#24207;&#25968;&#25454;&#26102;&#20855;&#26377;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#21333;&#32454;&#32990;&#29983;&#29289;&#23398;&#21644;&#23439;&#22522;&#22240;&#32452;&#23398;&#24212;&#29992;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22522;&#20110;&#26377;&#22122;&#22768;&#12289;&#26080;&#24207;&#21333;&#35843;Toeplitz&#30697;&#38453;&#27169;&#22411;&#30340;&#30697;&#38453;&#37325;&#25490;&#24207;&#38382;&#39064;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#20915;&#31574;&#29702;&#35770;&#26694;&#26550;&#19979;&#24314;&#31435;&#20102;&#36825;&#20010;&#38382;&#39064;&#30340;&#22522;&#26412;&#32479;&#35745;&#26497;&#38480;&#65292;&#24182;&#35777;&#26126;&#20102;&#19968;&#20010;&#32422;&#26463;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#37327;&#33021;&#22815;&#36798;&#21040;&#26368;&#20248;&#36895;&#29575;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#35745;&#31639;&#22797;&#26434;&#24615;&#30340;&#21407;&#22240;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#19968;&#31181;&#27969;&#34892;&#30340;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#8212;&#8212;&#20809;&#35889;&#25490;&#24207;&#65292;&#24182;&#34920;&#26126;&#23427;&#26159;&#27425;&#20248;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22810;&#39033;&#24335;&#26102;&#38388;&#33258;&#36866;&#24212;&#25490;&#24207;&#31639;&#27861;&#65292;&#24182;&#20445;&#35777;&#20102;&#24615;&#33021;&#30340;&#25552;&#21319;&#12290;&#23545;&#20004;&#20010;&#30495;&#23454;&#21333;&#32454;&#32990;RNA&#27979;&#24207;&#25968;&#25454;&#38598;&#30340;&#27169;&#25311;&#21644;&#20998;&#26512;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by applications in single-cell biology and metagenomics, we investigate the problem of matrix reordering based on a noisy disordered monotone Toeplitz matrix model. We establish the fundamental statistical limit for this problem in a decision-theoretic framework and demonstrate that a constrained least squares estimator achieves the optimal rate. However, due to its computational complexity, we analyze a popular polynomial-time algorithm, spectral seriation, and show that it is suboptimal. To address this, we propose a novel polynomial-time adaptive sorting algorithm with guaranteed performance improvement. Simulations and analyses of two real single-cell RNA sequencing datasets demonstrate the superiority of our algorithm over existing methods.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#36870;&#25193;&#23637;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;(I-EKF)&#22312;&#38750;&#32447;&#24615;&#36807;&#31243;&#21160;&#21147;&#23398;&#21644;&#26410;&#30693;&#36755;&#20837;&#26041;&#38754;&#30340;&#20851;&#38190;&#25361;&#25112;&#65292;&#24182;&#25552;&#20379;&#20102;&#20855;&#26377;&#37325;&#35201;&#29702;&#35770;&#31283;&#23450;&#24615;&#20445;&#35777;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2201.01539</link><description>&lt;p&gt;
&#36870;&#25193;&#23637;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;--&#31532;&#19968;&#37096;&#20998;: &#22522;&#30784;
&lt;/p&gt;
&lt;p&gt;
Inverse Extended Kalman Filter -- Part I: Fundamentals. (arXiv:2201.01539v3 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.01539
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#36870;&#25193;&#23637;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;(I-EKF)&#22312;&#38750;&#32447;&#24615;&#36807;&#31243;&#21160;&#21147;&#23398;&#21644;&#26410;&#30693;&#36755;&#20837;&#26041;&#38754;&#30340;&#20851;&#38190;&#25361;&#25112;&#65292;&#24182;&#25552;&#20379;&#20102;&#20855;&#26377;&#37325;&#35201;&#29702;&#35770;&#31283;&#23450;&#24615;&#20445;&#35777;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#21453;&#23545;&#25239;&#31995;&#32479;&#30340;&#36827;&#23637;&#24341;&#36215;&#20102;&#23545;&#36125;&#21494;&#26031;&#36870;&#28388;&#27874;&#30340;&#30740;&#31350;&#30340;&#37325;&#35270;&#12290;&#20363;&#22914;&#65292;&#23545;&#20110;&#20197;&#39044;&#27979;&#23545;&#25163;&#26410;&#26469;&#27493;&#39588;&#20026;&#30446;&#30340;&#65292;&#20272;&#35745;&#23545;&#25163;&#30340;&#21345;&#23572;&#26364;&#28388;&#27874;&#36319;&#36394;&#20272;&#35745;&#65292;&#24341;&#21457;&#20102;&#36870;&#21345;&#23572;&#26364;&#28388;&#27874;(I-KF)&#30340;&#26368;&#36817;&#24418;&#24335;&#12290;&#22312;&#36870;&#28388;&#27874;&#30340;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#36870;&#25193;&#23637;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;(I-EKF)&#26469;&#35299;&#20915;&#38750;&#32447;&#24615;&#36807;&#31243;&#21160;&#21147;&#23398;&#21644;&#21069;&#21521;&#28388;&#27874;&#22120;&#30340;&#19981;&#26126;&#36755;&#20837;&#30340;&#20851;&#38190;&#25361;&#25112;&#12290;&#26412;&#25991;&#21450;&#20854;&#38468;&#23646;&#25991;(Part II)&#30340;&#30446;&#30340;&#26159;&#35814;&#32454;&#38416;&#36848;I-EKF&#30340;&#29702;&#35770;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20551;&#35774;&#20855;&#22791;&#23436;&#32654;&#30340;&#31995;&#32479;&#27169;&#22411;&#20449;&#24687;&#65292;&#24182;&#25512;&#23548;&#20102;&#21069;&#21521;&#21644;&#36870;&#21521;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#22343;&#20026;&#38750;&#32447;&#24615;&#26102;&#30340;I-EKF,&#21516;&#26102;&#33719;&#24471;&#20102;&#24102;&#26410;&#30693;&#36755;&#20837;&#30340;I-KF&#12290;&#25105;&#20204;&#36824;&#21033;&#29992;&#26377;&#30028;&#38750;&#32447;&#24615;&#24615;&#21644;&#26410;&#30693;&#30697;&#38453;&#26041;&#27861;&#25552;&#20379;&#20102;&#29702;&#35770;&#31283;&#23450;&#24615;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advances in counter-adversarial systems have garnered significant research attention to inverse filtering from a Bayesian perspective. For example, interest in estimating the adversary's Kalman filter tracked estimate with the purpose of predicting the adversary's future steps has led to recent formulations of inverse Kalman filter (I-KF). In this context of inverse filtering, we address the key challenges of non-linear process dynamics and unknown input to the forward filter by proposing an inverse extended Kalman filter (I-EKF). The purpose of this paper and the companion paper (Part II) is to develop the theory of I-EKF in detail. In this paper, we assume perfect system model information and derive I-EKF with and without an unknown input when both forward and inverse state-space models are non-linear. In the process, I-KF-with-unknown-input is also obtained. We then provide theoretical stability guarantees using both bounded non-linearity and unknown matrix approaches and pro
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#25104;&#23545;&#20851;&#32852;&#20013;&#30340;&#38750;&#21442;&#25968;&#21270;&#28508;&#22312;&#31354;&#38388;&#27169;&#22411;&#20013;&#36827;&#34892;&#19968;&#32500;&#23450;&#20301;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20272;&#35745;&#36807;&#31243;&#65292;&#33021;&#22815;&#20197;&#39640;&#27010;&#29575;&#30340;&#26041;&#24335;&#23558;&#25152;&#26377;&#28508;&#22312;&#20301;&#32622;&#23450;&#20301;&#21040;&#26368;&#22823;&#35823;&#24046;&#20026;$\sqrt{\log(n)/n}$&#30340;&#33539;&#22260;&#20869;&#65292;&#35813;&#36895;&#29575;&#34987;&#35777;&#26126;&#26159;&#26368;&#23567;&#21270;&#30340;&#12290;</title><link>http://arxiv.org/abs/2108.03098</link><description>&lt;p&gt;
&#20174;&#25104;&#23545;&#20851;&#32852;&#20013;&#30340;&#38750;&#21442;&#25968;&#21270;&#28508;&#22312;&#31354;&#38388;&#27169;&#22411;&#20013;&#36827;&#34892;1D&#23450;&#20301;
&lt;/p&gt;
&lt;p&gt;
Localization in 1D non-parametric latent space models from pairwise affinities. (arXiv:2108.03098v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2108.03098
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#25104;&#23545;&#20851;&#32852;&#20013;&#30340;&#38750;&#21442;&#25968;&#21270;&#28508;&#22312;&#31354;&#38388;&#27169;&#22411;&#20013;&#36827;&#34892;&#19968;&#32500;&#23450;&#20301;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20272;&#35745;&#36807;&#31243;&#65292;&#33021;&#22815;&#20197;&#39640;&#27010;&#29575;&#30340;&#26041;&#24335;&#23558;&#25152;&#26377;&#28508;&#22312;&#20301;&#32622;&#23450;&#20301;&#21040;&#26368;&#22823;&#35823;&#24046;&#20026;$\sqrt{\log(n)/n}$&#30340;&#33539;&#22260;&#20869;&#65292;&#35813;&#36895;&#29575;&#34987;&#35777;&#26126;&#26159;&#26368;&#23567;&#21270;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20174;&#25104;&#23545;&#20851;&#32852;&#20013;&#20272;&#35745;&#19968;&#32500;&#29615;&#38754;&#19978;&#30340;&#28508;&#22312;&#20301;&#32622;&#30340;&#38382;&#39064;&#12290;&#23545;&#20110;&#19968;&#23545;&#39033;&#20043;&#38388;&#30340;&#20851;&#32852;&#35266;&#27979;&#34987;&#24314;&#27169;&#20026;&#23545;&#28508;&#22312;&#20301;&#32622;$x^*_{i},x^*_{j}$&#30340;&#20989;&#25968;$f(x^*_{i},x^*_{j})$&#30340;&#22122;&#22768;&#35266;&#27979;&#12290;&#20851;&#32852;&#20989;&#25968;$f$&#26159;&#26410;&#30693;&#30340;&#65292;&#20165;&#20551;&#35774;&#20854;&#28385;&#36275;&#19968;&#20123;&#24418;&#29366;&#32422;&#26463;&#65292;&#30830;&#20445;&#24403;$x$&#21644;$y$&#20043;&#38388;&#30340;&#36317;&#31163;&#36739;&#23567;&#26102;&#65292;$f(x,y)$&#36739;&#22823;&#65292;&#21453;&#20043;&#20134;&#28982;&#12290;&#36825;&#31181;&#38750;&#21442;&#25968;&#21270;&#24314;&#27169;&#25552;&#20379;&#20102;&#36866;&#24212;&#25968;&#25454;&#30340;&#33391;&#22909;&#28789;&#27963;&#24615;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#20272;&#35745;&#36807;&#31243;&#65292;&#33021;&#22815;&#20197;&#39640;&#27010;&#29575;&#30340;&#26041;&#24335;&#23558;&#25152;&#26377;&#28508;&#22312;&#20301;&#32622;&#23450;&#20301;&#21040;&#26368;&#22823;&#35823;&#24046;&#20026;$\sqrt{\log(n)/n}$&#30340;&#33539;&#22260;&#20869;&#12290;&#36825;&#20010;&#36895;&#29575;&#34987;&#35777;&#26126;&#26159;&#26368;&#23567;&#21270;&#30340;&#12290;&#25105;&#20204;&#36824;&#23545;&#19968;&#31181;&#35745;&#31639;&#25928;&#29575;&#26356;&#39640;&#30340;&#21464;&#20307;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#35813;&#21464;&#20307;&#22312;&#19968;&#20123;&#26356;&#20005;&#26684;&#30340;&#20551;&#35774;&#19979;&#25104;&#31435;&#12290;&#25105;&#20204;&#30340;&#24635;&#20307;&#32467;&#26524;&#21487;&#20197;&#24212;&#29992;&#20110;&#32479;&#35745;&#25490;&#24207;&#38382;&#39064;&#65292;&#20174;&#32780;&#24471;&#21040;&#26368;&#22823;&#35823;&#24046;&#30340;&#26032;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of estimating latent positions in a one-dimensional torus from pairwise affinities. The observed affinity between a pair of items is modeled as a noisy observation of a function $f(x^*_{i},x^*_{j})$ of the latent positions $x^*_{i},x^*_{j}$ of the two items on the torus. The affinity function $f$ is unknown, and it is only assumed to fulfill some shape constraints ensuring that $f(x,y)$ is large when the distance between $x$ and $y$ is small, and vice-versa. This non-parametric modeling offers a good flexibility to fit data. We introduce an estimation procedure that provably localizes all the latent positions with a maximum error of the order of $\sqrt{\log(n)/n}$, with high-probability. This rate is proven to be minimax optimal. A computationally efficient variant of the procedure is also analyzed under some more restrictive assumptions. Our general results can be instantiated to the problem of statistical seriation, leading to new bounds for the maximum error 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#23616;&#37096;&#24046;&#20998;&#38544;&#31169;&#32972;&#26223;&#19979;&#20272;&#35745;&#31163;&#25955;&#20998;&#24067;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#20114;&#21160;&#21644;&#38750;&#20114;&#21160;&#30340;&#38544;&#31169;&#26426;&#21046;&#12290;&#36890;&#36807;&#23545;&#24130;&#21644;&#20989;&#25968;&#30340;&#20108;&#27425;&#39118;&#38505;&#34892;&#20026;&#30340;&#30740;&#31350;&#65292;&#22312;&#38750;&#20114;&#21160;&#24773;&#20917;&#19979;&#25552;&#20986;&#20102;&#20004;&#31181;&#25554;&#34917;&#31867;&#22411;&#30340;&#20272;&#35745;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2107.03940</link><description>&lt;p&gt;
&#38750;&#32447;&#24615;&#31163;&#25955;&#20998;&#24067;&#30340;&#23616;&#37096;&#24046;&#20998;&#38544;&#31169;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Locally differentially private estimation of nonlinear functionals of discrete distributions. (arXiv:2107.03940v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2107.03940
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#23616;&#37096;&#24046;&#20998;&#38544;&#31169;&#32972;&#26223;&#19979;&#20272;&#35745;&#31163;&#25955;&#20998;&#24067;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#20114;&#21160;&#21644;&#38750;&#20114;&#21160;&#30340;&#38544;&#31169;&#26426;&#21046;&#12290;&#36890;&#36807;&#23545;&#24130;&#21644;&#20989;&#25968;&#30340;&#20108;&#27425;&#39118;&#38505;&#34892;&#20026;&#30340;&#30740;&#31350;&#65292;&#22312;&#38750;&#20114;&#21160;&#24773;&#20917;&#19979;&#25552;&#20986;&#20102;&#20004;&#31181;&#25554;&#34917;&#31867;&#22411;&#30340;&#20272;&#35745;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#23616;&#37096;&#24046;&#20998;&#38544;&#31169;&#30340;&#32972;&#26223;&#19979;&#20272;&#35745;&#31163;&#25955;&#20998;&#24067;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#30340;&#38382;&#39064;&#12290;&#21021;&#22987;&#25968;&#25454;$x_1,\ldots,x_n \in [K]$&#34987;&#20551;&#35774;&#20026;i.i.d.&#24182;&#26681;&#25454;&#26410;&#30693;&#30340;&#31163;&#25955;&#20998;&#24067;$p = (p_1,\ldots,p_K)$&#36827;&#34892;&#20998;&#24067;&#12290;&#21482;&#26377;$\alpha$-&#23616;&#37096;&#24046;&#20998;&#38544;&#31169;(LDP)&#26679;&#26412;$z_1,...,z_n$&#26159;&#20844;&#24320;&#21487;&#29992;&#30340;&#65292;&#20854;&#20013;&#26415;&#35821;&#8220;&#23616;&#37096;&#8221;&#34920;&#31034;&#27599;&#20010;$z_i$&#37117;&#26159;&#20351;&#29992;&#19968;&#20010;&#20010;&#20154;&#23646;&#24615;$x_i$&#29983;&#25104;&#30340;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#21487;&#20197;&#20351;&#29992;&#20114;&#21160;&#30340;&#38544;&#31169;&#26426;&#21046;&#65288;PM&#65289;&#25110;&#38750;&#20114;&#21160;&#30340;&#38544;&#31169;&#26426;&#21046;&#26469;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;&#20316;&#20026;$K, \, n$&#21644;$\alpha$&#30340;&#20989;&#25968;&#30340;&#24130;&#21644;&#20989;&#25968;$F_{\gamma} = \sum_{k=1}^K p_k^{\gamma}$&#30340;&#20108;&#27425;&#39118;&#38505;&#30340;&#34892;&#20026;&#12290;&#22312;&#38750;&#20114;&#21160;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#31181;&#25554;&#34917;&#31867;&#22411;&#30340;&#20272;&#35745;$F_{\gamma}$&#30340;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#25152;&#26377;$\gamma &gt;0$&#65292;&#20854;&#31867;&#20284;&#20110;Jiao&#31561;(2017)&#22312;&#22810;&#39033;&#24335;&#27169;&#22411;&#20013;&#20998;&#26512;&#30340;MLE&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of estimating non-linear functionals of discrete distributions in the context of local differential privacy. The initial data $x_1,\ldots,x_n \in [K]$ are supposed i.i.d. and distributed according to an unknown discrete distribution $p = (p_1,\ldots,p_K)$. Only $\alpha$-locally differentially private (LDP) samples $z_1,...,z_n$ are publicly available, where the term 'local' means that each $z_i$ is produced using one individual attribute $x_i$. We exhibit privacy mechanisms (PM) that are interactive (i.e. they are allowed to use already published confidential data) or non-interactive. We describe the behavior of the quadratic risk for estimating the power sum functional $F_{\gamma} = \sum_{k=1}^K p_k^{\gamma}$, $\gamma &gt;0$ as a function of $K, \, n$ and $\alpha$. In the non-interactive case, we study two plug-in type estimators of $F_{\gamma}$, for all $\gamma &gt;0$, that are similar to the MLE analyzed by Jiao et al. (2017) in the multinomial model. However, due to 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#23545;&#27604;&#23398;&#20064;&#31574;&#30053;&#65292;&#36890;&#36807;&#20998;&#21035;&#27604;&#36739;&#27491;&#26679;&#26412;&#21644;&#36127;&#26679;&#26412;&#22312;&#21508;&#33258;&#32676;&#32452;&#20869;&#30340;&#20851;&#31995;&#65292;&#24182;&#23545;&#27491;&#36127;&#32676;&#32452;&#20043;&#38388;&#36827;&#34892;&#23545;&#27604;&#65292;&#20197;&#36827;&#19968;&#27493;&#25552;&#39640;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#30340;&#24615;&#33021;&#21644;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2105.03746</link><description>&lt;p&gt;
&#23545;&#27604;&#21560;&#24341;&#21644;&#23545;&#27604;&#25490;&#26021;&#22312;&#34920;&#31034;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Contrastive Attraction and Contrastive Repulsion for Representation Learning. (arXiv:2105.03746v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2105.03746
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#23545;&#27604;&#23398;&#20064;&#31574;&#30053;&#65292;&#36890;&#36807;&#20998;&#21035;&#27604;&#36739;&#27491;&#26679;&#26412;&#21644;&#36127;&#26679;&#26412;&#22312;&#21508;&#33258;&#32676;&#32452;&#20869;&#30340;&#20851;&#31995;&#65292;&#24182;&#23545;&#27491;&#36127;&#32676;&#32452;&#20043;&#38388;&#36827;&#34892;&#23545;&#27604;&#65292;&#20197;&#36827;&#19968;&#27493;&#25552;&#39640;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#30340;&#24615;&#33021;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#20197;&#33258;&#25105;&#30417;&#30563;&#26041;&#24335;&#26377;&#25928;&#22320;&#23398;&#20064;&#25968;&#25454;&#34920;&#31034;&#65292;&#20854;&#20013;&#32534;&#30721;&#22120;&#36890;&#36807;&#19968;&#23545;&#22810;&#30340;softmax&#20132;&#21449;&#29109;&#25439;&#22833;&#23558;&#27599;&#20010;&#27491;&#26679;&#26412;&#19982;&#22810;&#20010;&#36127;&#26679;&#26412;&#36827;&#34892;&#23545;&#27604;&#12290;&#26368;&#36817;&#30340;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#36890;&#36807;&#21033;&#29992;&#22823;&#37327;&#26410;&#26631;&#35760;&#30340;&#22270;&#20687;&#25968;&#25454;&#65292;&#22312;&#39044;&#35757;&#32451;&#27169;&#22411;&#19978;&#21462;&#24471;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#65292;&#22914;ImageNet&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#26041;&#27861;&#35748;&#20026;&#26469;&#33258;&#21516;&#19968;&#23454;&#20363;&#30340;&#22686;&#24378;&#35270;&#22270;&#26159;&#27491;&#26679;&#26412;&#23545;&#65292;&#32780;&#26469;&#33258;&#20854;&#20182;&#23454;&#20363;&#30340;&#35270;&#22270;&#21017;&#26159;&#36127;&#26679;&#26412;&#23545;&#12290;&#36825;&#31181;&#20108;&#20998;&#27861;&#19981;&#20805;&#20998;&#22320;&#32771;&#34385;&#26679;&#26412;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#24182;&#19988;&#22312;&#24212;&#29992;&#21040;&#37326;&#22806;&#22270;&#20687;&#26102;&#24448;&#24448;&#20250;&#20135;&#29983;&#36739;&#24046;&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#36827;&#19968;&#27493;&#25552;&#39640;&#23545;&#27604;&#23398;&#20064;&#30340;&#24615;&#33021;&#65292;&#24182;&#22686;&#24378;&#20854;&#22312;&#21508;&#31181;&#25968;&#25454;&#38598;&#19978;&#30340;&#40065;&#26834;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#23545;&#27604;&#23398;&#20064;&#31574;&#30053;&#65292;&#20998;&#21035;&#22312;&#21508;&#33258;&#30340;&#32676;&#32452;&#20869;&#27604;&#36739;&#27491;&#26679;&#26412;&#21644;&#36127;&#26679;&#26412;&#65292;&#28982;&#21518;&#36827;&#34892;&#27491;&#36127;&#32676;&#32452;&#20043;&#38388;&#30340;&#23545;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;
Contrastive learning (CL) methods effectively learn data representations in a self-supervision manner, where the encoder contrasts each positive sample over multiple negative samples via a one-vs-many softmax cross-entropy loss. By leveraging large amounts of unlabeled image data, recent CL methods have achieved promising results when pretrained on large-scale datasets, such as ImageNet. However, most of them consider the augmented views from the same instance are positive pairs, while views from other instances are negative ones. Such binary partition insufficiently considers the relation between samples and tends to yield worse performance when generalized on images in the wild. In this paper, to further improve the performance of CL and enhance its robustness on various datasets, {we propose a doubly CL strategy that separately compares positive and negative samples within their own groups, and then proceeds with a contrast between positive and negative groups}. We realize this stra
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#24102;&#22122;&#22768;&#30340;&#20302;&#31209;&#30697;&#38453;&#34917;&#20840;&#38382;&#39064;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#36890;&#36807;&#20351;&#29992;&#26464;&#26438;&#24471;&#20998;&#26469;&#37327;&#21270;&#27599;&#20010;&#20803;&#32032;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#31181;&#38750;&#22343;&#21248;&#37319;&#26679;&#36807;&#31243;&#26469;&#26356;&#20934;&#30830;&#22320;&#23436;&#25104;&#34917;&#20840;&#12290;</title><link>http://arxiv.org/abs/2011.05885</link><description>&lt;p&gt;
&#24102;&#22122;&#22768;&#30340;&#26464;&#26438;&#30697;&#38453;&#34917;&#20840;
&lt;/p&gt;
&lt;p&gt;
Leveraged Matrix Completion with Noise. (arXiv:2011.05885v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2011.05885
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#24102;&#22122;&#22768;&#30340;&#20302;&#31209;&#30697;&#38453;&#34917;&#20840;&#38382;&#39064;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#36890;&#36807;&#20351;&#29992;&#26464;&#26438;&#24471;&#20998;&#26469;&#37327;&#21270;&#27599;&#20010;&#20803;&#32032;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#31181;&#38750;&#22343;&#21248;&#37319;&#26679;&#36807;&#31243;&#26469;&#26356;&#20934;&#30830;&#22320;&#23436;&#25104;&#34917;&#20840;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#21313;&#24180;&#20013;&#65292;&#20174;&#23376;&#37319;&#26679;&#27979;&#37327;&#20013;&#23436;&#25104;&#20302;&#31209;&#30697;&#38453;&#24341;&#36215;&#20102;&#24456;&#22810;&#20851;&#27880;&#12290;&#29616;&#26377;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#20026;&#20102;&#22312;&#19968;&#23450;&#30340;&#27010;&#29575;&#19979;&#29702;&#35770;&#19978;&#30830;&#20445;&#23436;&#25104;&#19968;&#20010;$n \times n$&#30340;&#31209;&#20026;$r$&#30340;&#24102;&#22122;&#22768;&#30697;&#38453;&#65292;&#38656;&#35201;$\mathcal{O}(nr\log^2(n))$&#20010;&#25968;&#25454;&#65292;&#20294;&#26159;&#38656;&#35201;&#19968;&#20123;&#30456;&#24403;&#33499;&#21051;&#30340;&#20551;&#35774;&#65306;(1)&#25152;&#21547;&#30340;&#30697;&#38453;&#24517;&#39035;&#26159;&#19981;&#30456;&#20851;&#30340;&#65307;(2)&#35266;&#27979;&#20540;&#26381;&#20174;&#22343;&#21248;&#20998;&#24067;&#12290;&#36825;&#31181;&#38480;&#21046;&#24615;&#37096;&#20998;&#26159;&#30001;&#20110;&#24573;&#30053;&#20102;&#26464;&#26438;&#24471;&#20998;&#21644;&#27599;&#20010;&#20803;&#32032;&#30340;&#39044;&#27979;&#20449;&#24687;&#30340;&#20316;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#26464;&#26438;&#24471;&#20998;&#26469;&#25551;&#36848;&#27599;&#20010;&#20803;&#32032;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#26174;&#33879;&#25918;&#23485;&#20102;&#20551;&#35774;&#65306;(1)&#23545;&#24213;&#23618;&#20302;&#31209;&#30697;&#38453;&#19981;&#26045;&#21152;&#20219;&#20309;&#20854;&#20182;&#32467;&#26500;&#20551;&#35774;&#65307;(2)&#34987;&#35266;&#27979;&#21040;&#30340;&#20803;&#32032;&#36890;&#36807;&#26464;&#26438;&#24471;&#20998;&#36866;&#24403;&#22320;&#20381;&#36182;&#20110;&#23427;&#20204;&#30340;&#37325;&#35201;&#24615;&#12290;&#22312;&#36825;&#20123;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#38750;&#22343;&#21248;/&#20559;&#20506;&#30340;&#37319;&#26679;&#36807;&#31243;&#65292;&#21487;&#20197;&#25581;&#31034;&#8220;&#37325;&#35201;&#8221;&#30340;&#20803;&#32032;&#12290;
&lt;/p&gt;
&lt;p&gt;
Completing low-rank matrices from subsampled measurements has received much attention in the past decade. Existing works indicate that $\mathcal{O}(nr\log^2(n))$ datums are required to theoretically secure the completion of an $n \times n$ noisy matrix of rank $r$ with high probability, under some quite restrictive assumptions: (1) the underlying matrix must be incoherent; (2) observations follow the uniform distribution. The restrictiveness is partially due to ignoring the roles of the leverage score and the oracle information of each element. In this paper, we employ the leverage scores to characterize the importance of each element and significantly relax assumptions to: (1) not any other structure assumptions are imposed on the underlying low-rank matrix; (2) elements being observed are appropriately dependent on their importance via the leverage score. Under these assumptions, instead of uniform sampling, we devise an ununiform/biased sampling procedure that can reveal the ``impor
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#32034;&#20102;&#20351;&#29992;&#23398;&#20064;&#31639;&#27861;&#36817;&#20046;&#26368;&#20248;&#22320;&#35299;&#20915;&#20855;&#26377;&#26102;&#38388;&#30456;&#20851;&#22870;&#21169;&#30340;&#22810;&#26234;&#33021;&#20307;&#12289;&#22810;&#20219;&#21153;&#30340;NP-hard&#35268;&#21010;&#38382;&#39064;&#30340;&#21487;&#33021;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#23637;&#31034;&#20102;&#25552;&#20986;&#26041;&#27861;&#22312;&#35299;&#20915;&#26426;&#22120;&#20154;/&#26426;&#22120;&#35843;&#24230;&#38382;&#39064;&#19978;&#30340;&#36817;&#20046;&#26368;&#20248;&#24615;&#12290;</title><link>http://arxiv.org/abs/1905.12204</link><description>&lt;p&gt;
&#20351;&#29992;GNN&#23398;&#20064;NP-Hard&#22810;&#26234;&#33021;&#20307;&#20998;&#37197;&#35268;&#21010;&#65306;&#22312;&#38543;&#26426;&#22270;&#19978;&#30340;&#25512;&#29702;&#21644;&#21487;&#35777;&#26126;&#30340;&#25293;&#21334;&#36866;&#37197;Q&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Learning NP-Hard Multi-Agent Assignment Planning using GNN: Inference on a Random Graph and Provable Auction-Fitted Q-learning. (arXiv:1905.12204v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1905.12204
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#32034;&#20102;&#20351;&#29992;&#23398;&#20064;&#31639;&#27861;&#36817;&#20046;&#26368;&#20248;&#22320;&#35299;&#20915;&#20855;&#26377;&#26102;&#38388;&#30456;&#20851;&#22870;&#21169;&#30340;&#22810;&#26234;&#33021;&#20307;&#12289;&#22810;&#20219;&#21153;&#30340;NP-hard&#35268;&#21010;&#38382;&#39064;&#30340;&#21487;&#33021;&#24615;&#12290;&#30740;&#31350;&#32467;&#26524;&#23637;&#31034;&#20102;&#25552;&#20986;&#26041;&#27861;&#22312;&#35299;&#20915;&#26426;&#22120;&#20154;/&#26426;&#22120;&#35843;&#24230;&#38382;&#39064;&#19978;&#30340;&#36817;&#20046;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#20351;&#29992;&#22522;&#20110;&#23398;&#20064;&#30340;&#31639;&#27861;&#26469;&#36817;&#20046;&#26368;&#20248;&#22320;&#35299;&#20915;&#20855;&#26377;&#26102;&#38388;&#30456;&#20851;&#22870;&#21169;&#30340;&#22810;&#26234;&#33021;&#20307;&#12289;&#22810;&#20219;&#21153;&#30340;NP-hard&#35268;&#21010;&#38382;&#39064;&#30340;&#21487;&#33021;&#24615;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#31867;&#31216;&#20026;&#22810;&#26426;&#22120;&#20154;&#22870;&#21169;&#25910;&#38598;&#38382;&#39064;&#65288;MRRC&#65289;&#30340;&#26426;&#22120;&#20154;/&#26426;&#22120;&#35843;&#24230;&#38382;&#39064;&#12290;&#36825;&#20123;MRRC&#38382;&#39064;&#24456;&#22909;&#22320;&#27169;&#25311;&#20102;&#20849;&#20056;&#12289;&#21462;&#36865;&#21644;&#20854;&#20182;&#30456;&#20851;&#38382;&#39064;&#12290;&#22312;&#23558;MRRC&#38382;&#39064;&#34920;&#31034;&#20026;&#39034;&#24207;&#20915;&#31574;&#38382;&#39064;&#26102;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#27599;&#20010;&#29366;&#24577;&#21487;&#20197;&#34987;&#34920;&#31034;&#20026;&#27010;&#29575;&#22270;&#27169;&#22411;&#65288;PGM&#65289;&#30340;&#25193;&#23637;&#65292;&#25105;&#20204;&#23558;&#20854;&#31216;&#20026;&#38543;&#26426;PGMs&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20026;&#38543;&#26426;PGMs&#24320;&#21457;&#20102;&#19968;&#31181;&#22343;&#22330;&#25512;&#29702;&#26041;&#27861;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#65288;1&#65289;&#19968;&#20010;&#21487;&#36827;&#34892;&#39034;&#24207;&#36716;&#31227;&#30340;Q&#20989;&#25968;&#20272;&#35745;&#22120;&#21644;&#65288;2&#65289;&#19968;&#20010;&#25903;&#25345;&#39034;&#24207;&#36716;&#31227;&#30340;&#25293;&#21334;&#26041;&#27861;&#65292;&#20197;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#36873;&#25321;&#32852;&#21512;&#20998;&#37197;&#12290;&#36825;&#20123;&#26041;&#27861;&#23548;&#33268;&#20102;&#19968;&#20010;&#20855;&#26377;&#33267;&#23569;$1-1/e$&#26368;&#20248;&#24615;&#30340;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#12290;&#22312;&#35299;&#20915;MRRC&#38382;&#39064;&#30340;&#23454;&#39564;&#32467;&#26524;&#20013;&#31361;&#20986;&#20102;&#36817;&#20046;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper explores the possibility of near-optimally solving multi-agent, multi-task NP-hard planning problems with time-dependent rewards using a learning-based algorithm. In particular, we consider a class of robot/machine scheduling problems called the multi-robot reward collection problem (MRRC). Such MRRC problems well model ride-sharing, pickup-and-delivery, and a variety of related problems. In representing the MRRC problem as a sequential decision-making problem, we observe that each state can be represented as an extension of probabilistic graphical models (PGMs), which we refer to as random PGMs. We then develop a mean-field inference method for random PGMs. We then propose (1) an order-transferable Q-function estimator and (2) an order-transferability-enabled auction to select a joint assignment in polynomial time. These result in a reinforcement learning framework with at least $1-1/e$ optimality. Experimental results on solving MRRC problems highlight the near-optimality 
&lt;/p&gt;</description></item><item><title>&#22312;&#26356;&#21487;&#20449;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;ResNet&#31867;&#22411;&#30340;CNN&#21487;&#20197;&#22312;&#19968;&#20123;&#37325;&#35201;&#30340;&#20989;&#25968;&#31867;&#20013;&#23454;&#29616;&#26497;&#23567;&#20540;&#26368;&#20248;&#35823;&#24046;&#29575;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#22797;&#21046;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#30340;&#23398;&#20064;&#33021;&#21147;&#26469;&#23454;&#29616;&#12290;</title><link>http://arxiv.org/abs/1903.10047</link><description>&lt;p&gt;
&#36817;&#20284;&#21644;&#38750;&#21442;&#25968;&#20272;&#35745;&#30340;ResNet&#31867;&#22411;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Approximation and Non-parametric Estimation of ResNet-type Convolutional Neural Networks. (arXiv:1903.10047v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1903.10047
&lt;/p&gt;
&lt;p&gt;
&#22312;&#26356;&#21487;&#20449;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;ResNet&#31867;&#22411;&#30340;CNN&#21487;&#20197;&#22312;&#19968;&#20123;&#37325;&#35201;&#30340;&#20989;&#25968;&#31867;&#20013;&#23454;&#29616;&#26497;&#23567;&#20540;&#26368;&#20248;&#35823;&#24046;&#29575;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#22797;&#21046;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#30340;&#23398;&#20064;&#33021;&#21147;&#26469;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;(CNNs)&#24050;&#32463;&#22312;&#22810;&#31181;&#20989;&#25968;&#31867;&#20013;&#26174;&#31034;&#20986;&#20102;&#22312;&#36817;&#20284;&#21644;&#20272;&#35745;&#35823;&#24046;&#29575;&#26041;&#38754;&#30340;&#26368;&#20248;&#24615;(&#22312;&#26497;&#23567;&#20540;&#26368;&#22823;&#21270;&#24847;&#20041;&#19978;)&#12290;&#28982;&#32780;&#65292;&#20197;&#21069;&#20998;&#26512;&#30340;&#26368;&#20248;CNN&#26159;&#19981;&#29616;&#23454;&#30340;&#23485;&#24230;&#65292;&#24182;&#19988;&#24456;&#38590;&#36890;&#36807;&#20248;&#21270;&#33719;&#24471;&#65292;&#22240;&#20026;&#22312;&#37325;&#35201;&#30340;&#20989;&#25968;&#31867;&#20013;&#20855;&#26377;&#31232;&#30095;&#32422;&#26463;&#65292;&#21253;&#25324;Holder&#31867;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;ResNet&#31867;&#22411;&#30340;CNN&#21487;&#20197;&#22312;&#26356;&#21487;&#20449;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#36825;&#20123;&#31867;&#30340;&#26497;&#23567;&#20540;&#26368;&#20248;&#35823;&#24046;&#29575;--&#23427;&#21487;&#20197;&#26159;&#23494;&#38598;&#30340;&#65292;&#24182;&#19988;&#20854;&#23485;&#24230;&#12289;&#36890;&#36947;&#22823;&#23567;&#21644;&#28388;&#27874;&#22120;&#22823;&#23567;&#19982;&#26679;&#26412;&#22823;&#23567;&#26080;&#20851;&#12290;&#20851;&#38190;&#24605;&#24819;&#26159;&#65292;&#25105;&#20204;&#21487;&#20197;&#36890;&#36807;&#23450;&#21046;&#30340;CNN&#22797;&#21046;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;(FNNs)&#30340;&#23398;&#20064;&#33021;&#21147;&#65292;&#21482;&#35201;FNNs&#20855;&#26377;&#22359;&#31232;&#30095;&#32467;&#26500;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#22312;&#26576;&#31181;&#24847;&#20041;&#19978;&#26159;&#36890;&#29992;&#30340;&#65292;&#25105;&#20204;&#21487;&#20197;&#33258;&#21160;&#23558;&#22359;&#31232;&#30095;FNNs&#23454;&#29616;&#30340;&#20219;&#20309;&#36817;&#20284;&#29575;&#36716;&#21270;&#20026;CNNs&#23454;&#29616;&#30340;&#36817;&#20284;&#29575;&#12290;&#20316;&#20026;&#19968;&#20010;&#24212;&#29992;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#21069;&#36848;&#31867;&#22411;CNN&#30340;&#36817;&#20284;&#21644;&#20272;&#35745;&#35823;&#24046;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Convolutional neural networks (CNNs) have been shown to achieve optimal approximation and estimation error rates (in minimax sense) in several function classes. However, previous analyzed optimal CNNs are unrealistically wide and difficult to obtain via optimization due to sparse constraints in important function classes, including the H\"older class. We show a ResNet-type CNN can attain the minimax optimal error rates in these classes in more plausible situations -- it can be dense, and its width, channel size, and filter size are constant with respect to sample size. The key idea is that we can replicate the learning ability of Fully-connected neural networks (FNNs) by tailored CNNs, as long as the FNNs have \textit{block-sparse} structures. Our theory is general in a sense that we can automatically translate any approximation rate achieved by block-sparse FNNs into that by CNNs. As an application, we derive approximation and estimation error rates of the aformentioned type of CNNs f
&lt;/p&gt;</description></item></channel></rss>