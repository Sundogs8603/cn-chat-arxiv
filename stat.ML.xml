<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36890;&#36807;&#28155;&#21152;&#22122;&#22768;&#21040;&#26368;&#21518;&#23618;&#30340;&#28608;&#27963;&#26469;&#20445;&#25252;&#38544;&#31169;&#65292;&#20351;&#29992;HCR&#30028;&#38480;&#21487;&#37327;&#21270;&#20445;&#25252;&#26426;&#23494;&#24615;&#30340;&#21487;&#20449;&#24230;</title><link>https://arxiv.org/abs/2404.02866</link><description>&lt;p&gt;
&#36890;&#36807;Hammersley-Chapman-Robbins&#30028;&#38480;&#20445;&#35777;&#26426;&#23494;&#24615;
&lt;/p&gt;
&lt;p&gt;
Guarantees of confidentiality via Hammersley-Chapman-Robbins bounds
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.02866
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#28155;&#21152;&#22122;&#22768;&#21040;&#26368;&#21518;&#23618;&#30340;&#28608;&#27963;&#26469;&#20445;&#25252;&#38544;&#31169;&#65292;&#20351;&#29992;HCR&#30028;&#38480;&#21487;&#37327;&#21270;&#20445;&#25252;&#26426;&#23494;&#24615;&#30340;&#21487;&#20449;&#24230;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#25512;&#26029;&#36807;&#31243;&#20013;&#36890;&#36807;&#21521;&#26368;&#21518;&#20960;&#23618;&#30340;&#28608;&#27963;&#28155;&#21152;&#22122;&#22768;&#26469;&#20445;&#25252;&#38544;&#31169;&#26159;&#21487;&#33021;&#30340;&#12290;&#36825;&#20123;&#23618;&#20013;&#30340;&#28608;&#27963;&#34987;&#31216;&#20026;&#8220;&#29305;&#24449;&#8221;&#65288;&#23569;&#35265;&#30340;&#31216;&#20026;&#8220;&#23884;&#20837;&#8221;&#25110;&#8220;&#29305;&#24449;&#23884;&#20837;&#8221;&#65289;&#12290;&#28155;&#21152;&#30340;&#22122;&#22768;&#26377;&#21161;&#20110;&#38450;&#27490;&#20174;&#22024;&#26434;&#30340;&#29305;&#24449;&#20013;&#37325;&#24314;&#36755;&#20837;&#12290;&#36890;&#36807;&#23545;&#25152;&#26377;&#21487;&#33021;&#30340;&#26080;&#20559;&#20272;&#35745;&#37327;&#30340;&#26041;&#24046;&#36827;&#34892;&#19979;&#38480;&#20272;&#35745;&#65292;&#37327;&#21270;&#20102;&#30001;&#27492;&#28155;&#21152;&#30340;&#22122;&#22768;&#20135;&#29983;&#30340;&#26426;&#23494;&#24615;&#12290;&#32463;&#20856;&#19981;&#31561;&#24335;Hammersley&#21644;Chapman&#20197;&#21450;Robbins&#25552;&#20379;&#20415;&#21033;&#30340;&#12289;&#21487;&#35745;&#31639;&#30340;&#30028;&#38480;-- HCR&#30028;&#38480;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#23545;&#20110;&#21253;&#21547;10&#20010;&#31867;&#21035;&#30340;&#22270;&#20687;&#20998;&#31867;&#25968;&#25454;&#38598;&#8220;MNIST&#8221;&#21644;&#8220;CIFAR-10&#8221;&#65292;HCR&#30028;&#38480;&#22312;&#23567;&#22411;&#31070;&#32463;&#32593;&#32476;&#19978;&#34920;&#29616;&#33391;&#22909;&#12290;HCR&#30028;&#38480;&#20284;&#20046;&#21333;&#29420;&#26080;&#27861;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.02866v1 Announce Type: new  Abstract: Protecting privacy during inference with deep neural networks is possible by adding noise to the activations in the last layers prior to the final classifiers or other task-specific layers. The activations in such layers are known as "features" (or, less commonly, as "embeddings" or "feature embeddings"). The added noise helps prevent reconstruction of the inputs from the noisy features. Lower bounding the variance of every possible unbiased estimator of the inputs quantifies the confidentiality arising from such added noise. Convenient, computationally tractable bounds are available from classic inequalities of Hammersley and of Chapman and Robbins -- the HCR bounds. Numerical experiments indicate that the HCR bounds are on the precipice of being effectual for small neural nets with the data sets, "MNIST" and "CIFAR-10," which contain 10 classes each for image classification. The HCR bounds appear to be insufficient on their own to guar
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20989;&#25968;&#21487;&#24494;&#26041;&#27861;&#26469;&#35299;&#20915;&#32479;&#35745;&#26368;&#20248;&#20998;&#37197;&#38382;&#39064;&#65292;&#36890;&#36807;&#23545;&#25490;&#24207;&#36816;&#31639;&#31526;&#30340;&#19968;&#33324;&#23646;&#24615;&#36827;&#34892;&#35814;&#32454;&#20998;&#26512;&#65292;&#25512;&#23548;&#20986;&#20540;&#20989;&#25968;&#30340;Hadamard&#21487;&#24494;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#20989;&#25968;&#20559;&#24494;&#20998;&#27861;&#30452;&#25509;&#25512;&#23548;&#20986;&#20540;&#20989;&#25968;&#36807;&#31243;&#30340;&#28176;&#36817;&#24615;&#36136;&#12290;</title><link>https://arxiv.org/abs/2403.18248</link><description>&lt;p&gt;
&#32479;&#35745;&#25512;&#26029;&#20013;&#30340;&#26368;&#20248;&#20998;&#37197;I&#65306;&#35268;&#24459;&#24615;&#21450;&#20854;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Statistical Inference of Optimal Allocations I: Regularities and their Implications
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18248
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20989;&#25968;&#21487;&#24494;&#26041;&#27861;&#26469;&#35299;&#20915;&#32479;&#35745;&#26368;&#20248;&#20998;&#37197;&#38382;&#39064;&#65292;&#36890;&#36807;&#23545;&#25490;&#24207;&#36816;&#31639;&#31526;&#30340;&#19968;&#33324;&#23646;&#24615;&#36827;&#34892;&#35814;&#32454;&#20998;&#26512;&#65292;&#25512;&#23548;&#20986;&#20540;&#20989;&#25968;&#30340;Hadamard&#21487;&#24494;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#20989;&#25968;&#20559;&#24494;&#20998;&#27861;&#30452;&#25509;&#25512;&#23548;&#20986;&#20540;&#20989;&#25968;&#36807;&#31243;&#30340;&#28176;&#36817;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#32479;&#35745;&#26368;&#20248;&#20998;&#37197;&#38382;&#39064;&#30340;&#20989;&#25968;&#21487;&#24494;&#26041;&#27861;&#12290;&#36890;&#36807;&#23545;&#25490;&#24207;&#36816;&#31639;&#31526;&#30340;&#19968;&#33324;&#23646;&#24615;&#36827;&#34892;&#35814;&#32454;&#20998;&#26512;&#65292;&#25105;&#20204;&#39318;&#20808;&#25512;&#23548;&#20986;&#20102;&#20540;&#20989;&#25968;&#30340;Hadamard&#21487;&#24494;&#24615;&#12290;&#22312;&#25105;&#20204;&#30340;&#26694;&#26550;&#20013;&#65292;Hausdorff&#27979;&#24230;&#30340;&#27010;&#24565;&#20197;&#21450;&#20960;&#20309;&#27979;&#24230;&#35770;&#20013;&#30340;&#38754;&#31215;&#21644;&#20849;&#38754;&#31215;&#31215;&#20998;&#20844;&#24335;&#26159;&#26680;&#24515;&#12290;&#22522;&#20110;&#25105;&#20204;&#30340;Hadamard&#21487;&#24494;&#24615;&#32467;&#26524;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#20989;&#25968;&#20559;&#24494;&#20998;&#27861;&#30452;&#25509;&#25512;&#23548;&#20986;&#20108;&#20803;&#32422;&#26463;&#26368;&#20248;&#20998;&#37197;&#38382;&#39064;&#30340;&#20540;&#20989;&#25968;&#36807;&#31243;&#20197;&#21450;&#20004;&#27493;ROC&#26354;&#32447;&#20272;&#35745;&#37327;&#30340;&#28176;&#36817;&#24615;&#36136;&#12290;&#27492;&#22806;&#65292;&#21033;&#29992;&#23545;&#20984;&#21644;&#23616;&#37096;Lipschitz&#27867;&#20989;&#30340;&#28145;&#21051;&#35265;&#35299;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#26368;&#20248;&#20998;&#37197;&#38382;&#39064;&#30340;&#20540;&#20989;&#25968;&#30340;&#39069;&#22806;&#19968;&#33324;Frechet&#21487;&#24494;&#24615;&#32467;&#26524;&#12290;&#36825;&#20123;&#24341;&#20154;&#20837;&#32988;&#30340;&#21457;&#29616;&#28608;&#21169;&#20102;&#25105;&#20204;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18248v1 Announce Type: new  Abstract: In this paper, we develp a functional differentiability approach for solving statistical optimal allocation problems. We first derive Hadamard differentiability of the value function through a detailed analysis of the general properties of the sorting operator. Central to our framework are the concept of Hausdorff measure and the area and coarea integration formulas from geometric measure theory. Building on our Hadamard differentiability results, we demonstrate how the functional delta method can be used to directly derive the asymptotic properties of the value function process for binary constrained optimal allocation problems, as well as the two-step ROC curve estimator. Moreover, leveraging profound insights from geometric functional analysis on convex and local Lipschitz functionals, we obtain additional generic Fr\'echet differentiability results for the value functions of optimal allocation problems. These compelling findings moti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#26680;&#26041;&#27861;&#30340;&#35270;&#35282;&#30740;&#31350;&#20102;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#22312;&#24179;&#22343;&#22330;&#26497;&#38480;&#19979;&#30340;&#29305;&#24449;&#23398;&#20064;&#33021;&#21147;&#65292;&#23637;&#31034;&#20102;&#23427;&#20204;&#27604;&#20219;&#20309;&#26680;&#26041;&#27861;&#26356;&#26377;&#25928;&#22320;&#23398;&#20064;&#22810;&#20010;&#20877;&#29616;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#30340;&#24182;&#38598;&#65292;&#24182;&#19988;&#31070;&#32463;&#32593;&#32476;&#20250;&#33719;&#24471;&#19982;&#30446;&#26631;&#20989;&#25968;&#23545;&#40784;&#30340;&#25968;&#25454;&#30456;&#20851;&#26680;&#12290;</title><link>https://arxiv.org/abs/2403.14917</link><description>&lt;p&gt;
&#20174;&#26680;&#26041;&#27861;&#30340;&#35282;&#24230;&#23545;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#24179;&#22343;&#22330;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Mean-field Analysis on Two-layer Neural Networks from a Kernel Perspective
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.14917
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#26680;&#26041;&#27861;&#30340;&#35270;&#35282;&#30740;&#31350;&#20102;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#22312;&#24179;&#22343;&#22330;&#26497;&#38480;&#19979;&#30340;&#29305;&#24449;&#23398;&#20064;&#33021;&#21147;&#65292;&#23637;&#31034;&#20102;&#23427;&#20204;&#27604;&#20219;&#20309;&#26680;&#26041;&#27861;&#26356;&#26377;&#25928;&#22320;&#23398;&#20064;&#22810;&#20010;&#20877;&#29616;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#30340;&#24182;&#38598;&#65292;&#24182;&#19988;&#31070;&#32463;&#32593;&#32476;&#20250;&#33719;&#24471;&#19982;&#30446;&#26631;&#20989;&#25968;&#23545;&#40784;&#30340;&#25968;&#25454;&#30456;&#20851;&#26680;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#26680;&#26041;&#27861;&#30340;&#35270;&#35282;&#30740;&#31350;&#20102;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#22312;&#24179;&#22343;&#22330;&#26497;&#38480;&#19979;&#30340;&#29305;&#24449;&#23398;&#20064;&#33021;&#21147;&#12290;&#20026;&#20102;&#32858;&#28966;&#20110;&#31532;&#19968;&#23618;&#35825;&#23548;&#30340;&#26680;&#30340;&#21160;&#24577;&#65292;&#25105;&#20204;&#21033;&#29992;&#20102;&#20004;&#20010;&#26102;&#38388;&#23610;&#24230;&#30340;&#26497;&#38480;&#65292;&#20854;&#20013;&#31532;&#20108;&#23618;&#27604;&#31532;&#19968;&#23618;&#31227;&#21160;&#24471;&#24555;&#24471;&#22810;&#12290;&#22312;&#36825;&#20010;&#26497;&#38480;&#19979;&#65292;&#23398;&#20064;&#38382;&#39064;&#34987;&#31616;&#21270;&#20026;&#22312;&#20869;&#22312;&#26680;&#19978;&#30340;&#26368;&#23567;&#21270;&#38382;&#39064;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#24179;&#22343;&#22330; Langevin &#21160;&#21147;&#23398;&#30340;&#20840;&#23616;&#25910;&#25947;&#24615;&#65292;&#24182;&#25512;&#23548;&#20102;&#26102;&#38388;&#21644;&#31890;&#23376;&#31163;&#25955;&#21270;&#35823;&#24046;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#27604;&#20219;&#20309;&#26680;&#26041;&#27861;&#26356;&#26377;&#25928;&#22320;&#23398;&#20064;&#22810;&#20010;&#20877;&#29616;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#30340;&#24182;&#38598;&#65292;&#24182;&#19988;&#31070;&#32463;&#32593;&#32476;&#20250;&#33719;&#24471;&#19982;&#30446;&#26631;&#20989;&#25968;&#23545;&#40784;&#30340;&#25968;&#25454;&#30456;&#20851;&#26680;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#20010;&#25910;&#25947;&#21040;&#20840;&#23616;&#26368;&#20248;&#30340;&#26631;&#31614;&#22122;&#22768;&#36807;&#31243;&#65292;&#24182;&#23637;&#31034;&#33258;&#30001;&#24230;&#20986;&#29616;&#20316;&#20026;&#19968;&#31181;&#38544;&#24335;&#27491;&#21017;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.14917v1 Announce Type: new  Abstract: In this paper, we study the feature learning ability of two-layer neural networks in the mean-field regime through the lens of kernel methods. To focus on the dynamics of the kernel induced by the first layer, we utilize a two-timescale limit, where the second layer moves much faster than the first layer. In this limit, the learning problem is reduced to the minimization problem over the intrinsic kernel. Then, we show the global convergence of the mean-field Langevin dynamics and derive time and particle discretization error. We also demonstrate that two-layer neural networks can learn a union of multiple reproducing kernel Hilbert spaces more efficiently than any kernel methods, and neural networks acquire data-dependent kernel which aligns with the target function. In addition, we develop a label noise procedure, which converges to the global optimum and show that the degrees of freedom appears as an implicit regularization.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#33021;&#22815;&#35780;&#20272;&#38750;&#31169;&#23494;&#25968;&#25454;&#30456;&#20851;&#39044;&#22788;&#29702;&#31639;&#27861;&#24341;&#36215;&#30340;&#39069;&#22806;&#38544;&#31169;&#25104;&#26412;&#65292;&#24182;&#21033;&#29992;&#24179;&#28369;DP&#21644;&#39044;&#22788;&#29702;&#31639;&#27861;&#30340;&#26377;&#30028;&#25935;&#24863;&#24615;&#24314;&#31435;&#25972;&#20307;&#38544;&#31169;&#20445;&#35777;&#30340;&#19978;&#38480;</title><link>https://arxiv.org/abs/2403.13041</link><description>&lt;p&gt;
&#20855;&#26377;&#38750;&#31169;&#23494;&#39044;&#22788;&#29702;&#30340;&#21487;&#35777;&#26126;&#38544;&#31169;
&lt;/p&gt;
&lt;p&gt;
Provable Privacy with Non-Private Pre-Processing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13041
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#33021;&#22815;&#35780;&#20272;&#38750;&#31169;&#23494;&#25968;&#25454;&#30456;&#20851;&#39044;&#22788;&#29702;&#31639;&#27861;&#24341;&#36215;&#30340;&#39069;&#22806;&#38544;&#31169;&#25104;&#26412;&#65292;&#24182;&#21033;&#29992;&#24179;&#28369;DP&#21644;&#39044;&#22788;&#29702;&#31639;&#27861;&#30340;&#26377;&#30028;&#25935;&#24863;&#24615;&#24314;&#31435;&#25972;&#20307;&#38544;&#31169;&#20445;&#35777;&#30340;&#19978;&#38480;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#20998;&#26512;&#24046;&#20998;&#31169;&#23494;&#65288;DP&#65289;&#26426;&#22120;&#23398;&#20064;&#31649;&#36947;&#26102;&#65292;&#36890;&#24120;&#20250;&#24573;&#30053;&#25968;&#25454;&#30456;&#20851;&#30340;&#39044;&#22788;&#29702;&#30340;&#28508;&#22312;&#38544;&#31169;&#25104;&#26412;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#35780;&#20272;&#30001;&#38750;&#31169;&#23494;&#25968;&#25454;&#30456;&#20851;&#39044;&#22788;&#29702;&#31639;&#27861;&#24341;&#36215;&#30340;&#39069;&#22806;&#38544;&#31169;&#25104;&#26412;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#36890;&#36807;&#21033;&#29992;&#20004;&#20010;&#26032;&#30340;&#25216;&#26415;&#27010;&#24565;&#24314;&#31435;&#20102;&#25972;&#20307;&#38544;&#31169;&#20445;&#35777;&#30340;&#19978;&#38480;&#65306;&#19968;&#31181;&#31216;&#20026;&#24179;&#28369;DP&#30340;DP&#21464;&#20307;&#20197;&#21450;&#39044;&#22788;&#29702;&#31639;&#27861;&#30340;&#26377;&#30028;&#25935;&#24863;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13041v1 Announce Type: cross  Abstract: When analysing Differentially Private (DP) machine learning pipelines, the potential privacy cost of data-dependent pre-processing is frequently overlooked in privacy accounting. In this work, we propose a general framework to evaluate the additional privacy cost incurred by non-private data-dependent pre-processing algorithms. Our framework establishes upper bounds on the overall privacy guarantees by utilising two new technical notions: a variant of DP termed Smooth DP and the bounded sensitivity of the pre-processing algorithms. In addition to the generic framework, we provide explicit overall privacy guarantees for multiple data-dependent pre-processing algorithms, such as data imputation, quantization, deduplication and PCA, when used in combination with several DP algorithms. Notably, this framework is also simple to implement, allowing direct integration into existing DP pipelines.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#22806;&#28304;&#21464;&#37327;&#30340;&#20998;&#24067;&#65292;&#25552;&#39640;&#20102;&#32467;&#26500;&#21270;&#22240;&#26524;&#27169;&#22411;&#30340;&#36817;&#20284;&#31934;&#24230;&#65292;&#24182;&#23558;&#22240;&#26524;&#36125;&#21494;&#26031;&#20248;&#21270;&#25193;&#23637;&#21040;&#26356;&#19968;&#33324;&#30340;&#22240;&#26524;&#26041;&#26696;&#12290;</title><link>https://arxiv.org/abs/2402.02277</link><description>&lt;p&gt;
&#22240;&#26524;&#36125;&#21494;&#26031;&#20248;&#21270;&#36890;&#36807;&#22806;&#28304;&#20998;&#24067;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Causal Bayesian Optimization via Exogenous Distribution Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02277
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#22806;&#28304;&#21464;&#37327;&#30340;&#20998;&#24067;&#65292;&#25552;&#39640;&#20102;&#32467;&#26500;&#21270;&#22240;&#26524;&#27169;&#22411;&#30340;&#36817;&#20284;&#31934;&#24230;&#65292;&#24182;&#23558;&#22240;&#26524;&#36125;&#21494;&#26031;&#20248;&#21270;&#25193;&#23637;&#21040;&#26356;&#19968;&#33324;&#30340;&#22240;&#26524;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32467;&#26500;&#21270;&#22240;&#26524;&#27169;&#22411;&#20013;&#65292;&#23558;&#30446;&#26631;&#21464;&#37327;&#26368;&#22823;&#21270;&#20316;&#20026;&#25805;&#20316;&#30446;&#26631;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#38382;&#39064;&#12290;&#29616;&#26377;&#30340;&#22240;&#26524;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;CBO&#65289;&#26041;&#27861;&#35201;&#20040;&#20381;&#36182;&#20110;&#25913;&#21464;&#22240;&#26524;&#32467;&#26500;&#20197;&#26368;&#22823;&#21270;&#22870;&#21169;&#30340;&#30828;&#24178;&#39044;&#65292;&#35201;&#20040;&#24341;&#20837;&#21160;&#20316;&#33410;&#28857;&#21040;&#20869;&#29983;&#21464;&#37327;&#20013;&#65292;&#20197;&#35843;&#25972;&#25968;&#25454;&#29983;&#25104;&#26426;&#21046;&#20197;&#23454;&#29616;&#30446;&#26631;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#23398;&#20064;&#22806;&#28304;&#21464;&#37327;&#30340;&#20998;&#24067;&#65292;&#36825;&#22312;&#29616;&#26377;&#26041;&#27861;&#20013;&#36890;&#24120;&#34987;&#24573;&#30053;&#25110;&#36890;&#36807;&#26399;&#26395;&#36827;&#34892;&#36793;&#32536;&#21270;&#12290;&#22806;&#28304;&#20998;&#24067;&#23398;&#20064;&#25552;&#39640;&#20102;&#36890;&#24120;&#36890;&#36807;&#26377;&#38480;&#35266;&#27979;&#25968;&#25454;&#35757;&#32451;&#30340;&#20195;&#29702;&#27169;&#22411;&#20013;&#30340;&#32467;&#26500;&#21270;&#22240;&#26524;&#27169;&#22411;&#30340;&#36817;&#20284;&#31934;&#24230;&#12290;&#27492;&#22806;&#65292;&#23398;&#20064;&#21040;&#30340;&#22806;&#28304;&#20998;&#24067;&#23558;&#29616;&#26377;&#30340;CBO&#25193;&#23637;&#21040;&#36229;&#20986;&#21152;&#24615;&#22122;&#22768;&#27169;&#22411;&#65288;ANM&#65289;&#30340;&#19968;&#33324;&#22240;&#26524;&#26041;&#26696;&#12290;&#24674;&#22797;&#22806;&#28304;&#21464;&#37327;&#20351;&#25105;&#20204;&#33021;&#22815;&#20026;&#22122;&#22768;&#25110;&#26410;&#35266;&#27979;&#21040;&#30340;&#38544;&#34255;&#21464;&#37327;&#20351;&#29992;&#26356;&#28789;&#27963;&#30340;&#20808;&#39564;&#12290;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;CBO&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Maximizing a target variable as an operational objective in a structured causal model is an important problem. Existing Causal Bayesian Optimization (CBO) methods either rely on hard interventions that alter the causal structure to maximize the reward; or introduce action nodes to endogenous variables so that the data generation mechanisms are adjusted to achieve the objective. In this paper, a novel method is introduced to learn the distribution of exogenous variables, which is typically ignored or marginalized through expectation by existing methods.   Exogenous distribution learning improves the approximation accuracy of structured causal models in a surrogate model that is usually trained with limited observational data. Moreover, the learned exogenous distribution extends existing CBO to general causal schemes beyond Additive Noise Models (ANM). The recovery of exogenous variables allows us to use a more flexible prior for noise or unobserved hidden variables. A new CBO method is 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#29992;&#20110;&#22788;&#29702;&#20855;&#26377;&#22810;&#39033;&#24335;&#35745;&#25968;&#25968;&#25454;&#30340;&#20998;&#26512;&#38656;&#27714;&#65292;&#24182;&#33021;&#22815;&#20174;&#25968;&#25454;&#20013;&#23436;&#20840;&#33258;&#21160;&#25552;&#21462;&#20986;&#29983;&#29289;&#24847;&#20041;&#30340;&#20803;&#31614;&#21517;&#12290;</title><link>https://arxiv.org/abs/2311.16909</link><description>&lt;p&gt;
&#22810;&#39033;&#24335;&#20449;&#24565;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Multinomial belief networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.16909
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#29992;&#20110;&#22788;&#29702;&#20855;&#26377;&#22810;&#39033;&#24335;&#35745;&#25968;&#25968;&#25454;&#30340;&#20998;&#26512;&#38656;&#27714;&#65292;&#24182;&#33021;&#22815;&#20174;&#25968;&#25454;&#20013;&#23436;&#20840;&#33258;&#21160;&#25552;&#21462;&#20986;&#29983;&#29289;&#24847;&#20041;&#30340;&#20803;&#31614;&#21517;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#36125;&#21494;&#26031;&#26041;&#27861;&#22312;&#38656;&#35201;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#12289;&#22788;&#29702;&#32570;&#22833;&#35266;&#27979;&#12289;&#26679;&#26412;&#31232;&#32570;&#25110;&#25968;&#25454;&#31232;&#30095;&#26102;&#26159;&#20855;&#26377;&#21560;&#24341;&#21147;&#30340;&#12290;&#20026;&#20102;&#28385;&#36275;&#36825;&#20123;&#20998;&#26512;&#38656;&#27714;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22810;&#39033;&#24335;&#35745;&#25968;&#25968;&#25454;&#30340;&#28145;&#23618;&#29983;&#25104;&#27169;&#22411;&#65292;&#20854;&#20013;&#32593;&#32476;&#30340;&#26435;&#37325;&#21644;&#38544;&#34255;&#21333;&#20803;&#22343;&#26381;&#20174;&#29380;&#21033;&#20811;&#38647;&#20998;&#24067;&#12290;&#25105;&#20204;&#21046;&#23450;&#20102;&#19968;&#20010;&#21033;&#29992;&#19968;&#31995;&#21015;&#22686;&#24191;&#20851;&#31995;&#30340;&#21513;&#24067;&#26031;&#25277;&#26679;&#36807;&#31243;&#65292;&#31867;&#20284;&#20110;&#21608;-&#19995;-&#38472;&#27169;&#22411;&#12290;&#25105;&#20204;&#23558;&#35813;&#27169;&#22411;&#24212;&#29992;&#20110;&#23567;&#35268;&#27169;&#25163;&#20889;&#25968;&#23383;&#21644;&#19968;&#20010;&#22823;&#22411;&#30340;DNA&#31361;&#21464;&#30284;&#30151;&#23454;&#39564;&#25968;&#25454;&#38598;&#65292;&#24182;&#23637;&#31034;&#20102;&#35813;&#27169;&#22411;&#22914;&#20309;&#33021;&#22815;&#23436;&#20840;&#25968;&#25454;&#39537;&#21160;&#22320;&#25552;&#21462;&#20986;&#29983;&#29289;&#24847;&#20041;&#30340;&#20803;&#31614;&#21517;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.16909v2 Announce Type: replace-cross  Abstract: A Bayesian approach to machine learning is attractive when we need to quantify uncertainty, deal with missing observations, when samples are scarce, or when the data is sparse. All of these commonly apply when analysing healthcare data. To address these analytical requirements, we propose a deep generative model for multinomial count data where both the weights and hidden units of the network are Dirichlet distributed. A Gibbs sampling procedure is formulated that takes advantage of a series of augmentation relations, analogous to the Zhou--Cong--Chen model. We apply the model on small handwritten digits, and a large experimental dataset of DNA mutations in cancer, and we show how the model is able to extract biologically meaningful meta-signatures in a fully data-driven way.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FRED&#30340;&#26032;&#39062;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#37322;&#25991;&#26412;&#39044;&#27979;&#12290;FRED&#21487;&#20197;&#35782;&#21035;&#25991;&#26723;&#20013;&#30340;&#20851;&#38190;&#35789;&#65292;&#24182;&#19988;&#36890;&#36807;&#19982;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#36827;&#34892;&#30340;&#23454;&#35777;&#35780;&#20272;&#35777;&#26126;&#20102;&#20854;&#22312;&#25552;&#20379;&#23545;&#25991;&#26412;&#27169;&#22411;&#30340;&#28145;&#20837;&#35265;&#35299;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2311.01605</link><description>&lt;p&gt;
&#23545;&#20110;&#25991;&#26412;&#39044;&#27979;&#30340;&#24544;&#23454;&#21644;&#31283;&#20581;&#30340;&#26412;&#22320;&#21487;&#35299;&#37322;&#24615;
&lt;/p&gt;
&lt;p&gt;
Faithful and Robust Local Interpretability for Textual Predictions. (arXiv:2311.01605v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01605
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FRED&#30340;&#26032;&#39062;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#37322;&#25991;&#26412;&#39044;&#27979;&#12290;FRED&#21487;&#20197;&#35782;&#21035;&#25991;&#26723;&#20013;&#30340;&#20851;&#38190;&#35789;&#65292;&#24182;&#19988;&#36890;&#36807;&#19982;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#36827;&#34892;&#30340;&#23454;&#35777;&#35780;&#20272;&#35777;&#26126;&#20102;&#20854;&#22312;&#25552;&#20379;&#23545;&#25991;&#26412;&#27169;&#22411;&#30340;&#28145;&#20837;&#35265;&#35299;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#35299;&#37322;&#24615;&#23545;&#20110;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#20851;&#38190;&#39046;&#22495;&#20013;&#24471;&#21040;&#20449;&#20219;&#21644;&#37096;&#32626;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#29992;&#20110;&#35299;&#37322;&#25991;&#26412;&#27169;&#22411;&#30340;&#26041;&#27861;&#36890;&#24120;&#22797;&#26434;&#65292;&#24182;&#19988;&#32570;&#20047;&#22362;&#23454;&#30340;&#25968;&#23398;&#22522;&#30784;&#65292;&#23427;&#20204;&#30340;&#24615;&#33021;&#20063;&#19981;&#33021;&#20445;&#35777;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;FRED&#65288;Faithful and Robust Explainer for textual Documents&#65289;&#65292;&#29992;&#20110;&#35299;&#37322;&#25991;&#26412;&#39044;&#27979;&#12290;FRED&#21487;&#20197;&#35782;&#21035;&#25991;&#26723;&#20013;&#30340;&#20851;&#38190;&#35789;&#65292;&#24403;&#36825;&#20123;&#35789;&#34987;&#31227;&#38500;&#26102;&#23545;&#39044;&#27979;&#32467;&#26524;&#20135;&#29983;&#37325;&#22823;&#24433;&#21709;&#12290;&#25105;&#20204;&#36890;&#36807;&#27491;&#24335;&#30340;&#23450;&#20041;&#21644;&#23545;&#21487;&#35299;&#37322;&#20998;&#31867;&#22120;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#30830;&#31435;&#20102;FRED&#30340;&#21487;&#38752;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#36890;&#36807;&#19982;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#36827;&#34892;&#30340;&#23454;&#35777;&#35780;&#20272;&#65292;&#35777;&#26126;&#20102;FRED&#22312;&#25552;&#20379;&#23545;&#25991;&#26412;&#27169;&#22411;&#30340;&#28145;&#20837;&#35265;&#35299;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Interpretability is essential for machine learning models to be trusted and deployed in critical domains. However, existing methods for interpreting text models are often complex, lack solid mathematical foundations, and their performance is not guaranteed. In this paper, we propose FRED (Faithful and Robust Explainer for textual Documents), a novel method for interpreting predictions over text. FRED identifies key words in a document that significantly impact the prediction when removed. We establish the reliability of FRED through formal definitions and theoretical analyses on interpretable classifiers. Additionally, our empirical evaluation against state-of-the-art methods demonstrates the effectiveness of FRED in providing insights into text models.
&lt;/p&gt;</description></item><item><title>SepVAE&#26159;&#19968;&#31181;&#23545;&#27604;VAE&#26041;&#27861;&#65292;&#21487;&#20197;&#20174;&#20581;&#24247;&#25968;&#25454;&#21644;&#24739;&#32773;&#25968;&#25454;&#20013;&#20998;&#31163;&#20986;&#20849;&#21516;&#30340;&#21644;&#29305;&#23450;&#30340;&#21464;&#21270;&#22240;&#32032;&#12290;&#22312;&#22810;&#20010;&#24212;&#29992;&#20013;&#34920;&#29616;&#20986;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.06206</link><description>&lt;p&gt;
SepVAE: &#19968;&#31181;&#23545;&#27604;VAE&#29992;&#20110;&#20998;&#31163;&#30149;&#29702;&#27169;&#24335;&#21644;&#20581;&#24247;&#27169;&#24335;
&lt;/p&gt;
&lt;p&gt;
SepVAE: a contrastive VAE to separate pathological patterns from healthy ones. (arXiv:2307.06206v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06206
&lt;/p&gt;
&lt;p&gt;
SepVAE&#26159;&#19968;&#31181;&#23545;&#27604;VAE&#26041;&#27861;&#65292;&#21487;&#20197;&#20174;&#20581;&#24247;&#25968;&#25454;&#21644;&#24739;&#32773;&#25968;&#25454;&#20013;&#20998;&#31163;&#20986;&#20849;&#21516;&#30340;&#21644;&#29305;&#23450;&#30340;&#21464;&#21270;&#22240;&#32032;&#12290;&#22312;&#22810;&#20010;&#24212;&#29992;&#20013;&#34920;&#29616;&#20986;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#27604;&#20998;&#26512;VAE&#65288;CA-VAEs&#65289;&#26159;&#19968;&#31867;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAEs&#65289;&#65292;&#26088;&#22312;&#20174;&#32972;&#26223;&#25968;&#25454;&#38598;&#65288;BG&#65289;&#65288;&#21363;&#20581;&#24247;&#20154;&#32676;&#65289;&#21644;&#30446;&#26631;&#25968;&#25454;&#38598;&#65288;TG&#65289;&#65288;&#21363;&#24739;&#32773;&#65289;&#20043;&#38388;&#20998;&#31163;&#20849;&#21516;&#21464;&#21270;&#22240;&#32032;&#21644;&#20165;&#23384;&#22312;&#20110;&#30446;&#26631;&#25968;&#25454;&#38598;&#20013;&#30340;&#22240;&#32032;&#12290;&#20026;&#27492;&#65292;&#36825;&#20123;&#26041;&#27861;&#23558;&#28508;&#22312;&#31354;&#38388;&#20998;&#20026;&#19968;&#32452;&#26174;&#33879;&#29305;&#24449;&#65288;&#21363;&#29305;&#23450;&#20110;&#30446;&#26631;&#25968;&#25454;&#38598;&#65289;&#21644;&#19968;&#32452;&#20849;&#21516;&#29305;&#24449;&#65288;&#21363;&#23384;&#22312;&#20110;&#20004;&#20010;&#25968;&#25454;&#38598;&#20013;&#65289;&#12290;&#30446;&#21069;&#65292;&#25152;&#26377;&#27169;&#22411;&#37117;&#26410;&#33021;&#26377;&#25928;&#38450;&#27490;&#28508;&#22312;&#31354;&#38388;&#20043;&#38388;&#30340;&#20449;&#24687;&#20849;&#20139;&#65292;&#24182;&#25429;&#25417;&#25152;&#26377;&#26174;&#33879;&#30340;&#21464;&#21270;&#22240;&#32032;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#20010;&#20851;&#38190;&#30340;&#27491;&#21017;&#21270;&#25439;&#22833;&#65306;&#20849;&#21516;&#34920;&#31034;&#21644;&#26174;&#33879;&#34920;&#31034;&#20043;&#38388;&#30340;&#35299;&#32544;&#32469;&#39033;&#65292;&#20197;&#21450;&#26174;&#33879;&#31354;&#38388;&#20013;&#32972;&#26223;&#21644;&#30446;&#26631;&#26679;&#26412;&#20043;&#38388;&#30340;&#20998;&#31867;&#39033;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#23545;&#19977;&#20010;&#21307;&#23398;&#24212;&#29992;&#21644;&#19968;&#20010;&#33258;&#28982;&#22270;&#20687;&#25968;&#25454;&#38598;&#65288;CelebA&#65289;&#30340;&#20808;&#21069;CA-VAEs&#26041;&#27861;&#30340;&#26356;&#22909;&#24615;&#33021;&#12290;&#20195;&#30721;&#21644;&#25968;&#25454;&#38598;&#21487;&#22312;GitHub&#19978;&#33719;&#21462;&#12290;
&lt;/p&gt;
&lt;p&gt;
Contrastive Analysis VAE (CA-VAEs) is a family of Variational auto-encoders (VAEs) that aims at separating the common factors of variation between a background dataset (BG) (i.e., healthy subjects) and a target dataset (TG) (i.e., patients) from the ones that only exist in the target dataset. To do so, these methods separate the latent space into a set of salient features (i.e., proper to the target dataset) and a set of common features (i.e., exist in both datasets). Currently, all models fail to prevent the sharing of information between latent spaces effectively and to capture all salient factors of variation. To this end, we introduce two crucial regularization losses: a disentangling term between common and salient representations and a classification term between background and target samples in the salient space. We show a better performance than previous CA-VAEs methods on three medical applications and a natural images dataset (CelebA). Code and datasets are available on GitHu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#19982;NMF&#31639;&#27861;&#19968;&#26679;&#31616;&#21333;&#19988;&#21487;&#25193;&#23637;&#30340;K&#22343;&#20540;&#32858;&#31867;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#35299;&#20915;&#38750;&#36127;&#20302;&#31209;&#21322;&#23450;&#35268;&#21010;&#38382;&#39064;&#33719;&#24471;&#20102;&#24378;&#22823;&#30340;&#32479;&#35745;&#26368;&#20248;&#24615;&#20445;&#35777;&#65292;&#23454;&#39564;&#35777;&#26126;&#35813;&#31639;&#27861;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>http://arxiv.org/abs/2305.18436</link><description>&lt;p&gt;
&#36890;&#36807;&#38750;&#36127;&#20302;&#31209;&#21322;&#23450;&#35268;&#21010;&#23454;&#29616;&#26368;&#20248;K&#22343;&#20540;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Statistically Optimal K-means Clustering via Nonnegative Low-rank Semidefinite Programming. (arXiv:2305.18436v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18436
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#19982;NMF&#31639;&#27861;&#19968;&#26679;&#31616;&#21333;&#19988;&#21487;&#25193;&#23637;&#30340;K&#22343;&#20540;&#32858;&#31867;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#36890;&#36807;&#35299;&#20915;&#38750;&#36127;&#20302;&#31209;&#21322;&#23450;&#35268;&#21010;&#38382;&#39064;&#33719;&#24471;&#20102;&#24378;&#22823;&#30340;&#32479;&#35745;&#26368;&#20248;&#24615;&#20445;&#35777;&#65292;&#23454;&#39564;&#35777;&#26126;&#35813;&#31639;&#27861;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
K&#22343;&#20540;&#32858;&#31867;&#26159;&#19968;&#31181;&#24191;&#27867;&#24212;&#29992;&#20110;&#22823;&#25968;&#25454;&#38598;&#20013;&#21457;&#29616;&#27169;&#24335;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#12290;&#21322;&#23450;&#35268;&#21010;&#65288;SDP&#65289;&#26494;&#24347;&#26368;&#36817;&#34987;&#25552;&#20986;&#29992;&#20110;&#35299;&#20915;K&#22343;&#20540;&#20248;&#21270;&#38382;&#39064;&#65292;&#20855;&#26377;&#24456;&#24378;&#30340;&#32479;&#35745;&#26368;&#20248;&#24615;&#20445;&#35777;&#12290;&#20294;&#23454;&#29616;SDP&#27714;&#35299;&#22120;&#30340;&#24040;&#22823;&#25104;&#26412;&#20351;&#24471;&#36825;&#20123;&#20445;&#35777;&#26080;&#27861;&#24212;&#29992;&#20110;&#23454;&#38469;&#25968;&#25454;&#38598;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#38750;&#36127;&#30697;&#38453;&#20998;&#35299;&#65288;NMF&#65289;&#26159;&#19968;&#31181;&#31616;&#21333;&#30340;&#32858;&#31867;&#31639;&#27861;&#65292;&#34987;&#26426;&#22120;&#23398;&#20064;&#20174;&#19994;&#32773;&#24191;&#27867;&#20351;&#29992;&#65292;&#20294;&#32570;&#20047;&#22362;&#23454;&#30340;&#32479;&#35745;&#22522;&#30784;&#25110;&#20005;&#26684;&#30340;&#20445;&#35777;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25551;&#36848;&#20102;&#19968;&#31181;&#31867;&#20284;&#20110;NMF&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#38750;&#20984;Burer-Monteiro&#20998;&#35299;&#26041;&#27861;&#35299;&#20915;&#21322;&#23450;&#35268;&#21010;&#26494;&#24347;&#30340;K&#22343;&#20540;&#20844;&#24335;&#30340;&#38750;&#36127;&#20302;&#31209;&#38480;&#21046;&#12290;&#25152;&#24471;&#21040;&#30340;&#31639;&#27861;&#19982;&#26368;&#20808;&#36827;&#30340;NMF&#31639;&#27861;&#19968;&#26679;&#31616;&#21333;&#21644;&#21487;&#25193;&#23637;&#65292;&#21516;&#26102;&#20063;&#20139;&#26377;&#19982;SDP&#30456;&#21516;&#30340;&#24378;&#22823;&#30340;&#32479;&#35745;&#26368;&#20248;&#24615;&#20445;&#35777;&#12290;&#22312;&#25105;&#20204;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#20248;&#20110;&#29616;&#26377;&#30340;NMF&#31639;&#27861;&#65292;&#24182;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#19982;&#26368;&#20808;&#36827;&#30340;SDP&#27714;&#35299;&#22120;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;
$K$-means clustering is a widely used machine learning method for identifying patterns in large datasets. Semidefinite programming (SDP) relaxations have recently been proposed for solving the $K$-means optimization problem that enjoy strong statistical optimality guarantees, but the prohibitive cost of implementing an SDP solver renders these guarantees inaccessible to practical datasets. By contrast, nonnegative matrix factorization (NMF) is a simple clustering algorithm that is widely used by machine learning practitioners, but without a solid statistical underpinning nor rigorous guarantees. In this paper, we describe an NMF-like algorithm that works by solving a nonnegative low-rank restriction of the SDP relaxed $K$-means formulation using a nonconvex Burer--Monteiro factorization approach. The resulting algorithm is just as simple and scalable as state-of-the-art NMF algorithms, while also enjoying the same strong statistical optimality guarantees as the SDP. In our experiments,
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#25506;&#31350;&#20102;&#23458;&#25143;&#22312;&#32852;&#31995;&#20013;&#24515;&#26080;&#22768;&#25918;&#24323;&#30340;&#29616;&#35937;&#65292;&#36890;&#36807;&#19981;&#30830;&#23450;&#25968;&#25454;&#20272;&#35745;&#23458;&#25143;&#31561;&#24453;&#30340;&#32784;&#24515;&#65292;&#25581;&#31034;&#20102;&#36825;&#31181;&#29616;&#35937;&#23545;&#20195;&#29702;&#20154;&#26102;&#38388;&#21644;&#33021;&#21147;&#30340;&#28010;&#36153;&#12290;</title><link>http://arxiv.org/abs/2304.11754</link><description>&lt;p&gt;
&#26080;&#22768;&#25918;&#24323;&#65306;&#22914;&#20309;&#20174;&#19981;&#30830;&#23450;&#25968;&#25454;&#20013;&#20272;&#35745;&#23458;&#25143;&#31561;&#24453;&#30340;&#32784;&#24515;
&lt;/p&gt;
&lt;p&gt;
Silent Abandonment in Contact Centers: Estimating Customer Patience from Uncertain Data. (arXiv:2304.11754v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.11754
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#25506;&#31350;&#20102;&#23458;&#25143;&#22312;&#32852;&#31995;&#20013;&#24515;&#26080;&#22768;&#25918;&#24323;&#30340;&#29616;&#35937;&#65292;&#36890;&#36807;&#19981;&#30830;&#23450;&#25968;&#25454;&#20272;&#35745;&#23458;&#25143;&#31561;&#24453;&#30340;&#32784;&#24515;&#65292;&#25581;&#31034;&#20102;&#36825;&#31181;&#29616;&#35937;&#23545;&#20195;&#29702;&#20154;&#26102;&#38388;&#21644;&#33021;&#21147;&#30340;&#28010;&#36153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#25552;&#39640;&#26381;&#21153;&#36136;&#37327;&#65292;&#20844;&#21496;&#20026;&#23458;&#25143;&#25552;&#20379;&#19982;&#20195;&#29702;&#20154;&#36827;&#34892;&#20132;&#20114;&#30340;&#26426;&#20250;&#65292;&#20854;&#20013;&#22823;&#37096;&#20998;&#20132;&#27969;&#26159;&#22522;&#20110;&#25991;&#26412;&#30340;&#12290;&#36825;&#24050;&#25104;&#20026;&#36817;&#24180;&#26469;&#23458;&#25143;&#19982;&#20844;&#21496;&#20132;&#27969;&#30340;&#26368;&#21463;&#27426;&#36814;&#30340;&#28192;&#36947;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#32852;&#31995;&#20013;&#24515;&#38754;&#20020;&#36816;&#33829;&#25361;&#25112;&#65292;&#22240;&#20026;&#23458;&#25143;&#20307;&#39564;&#30340;&#24120;&#35265;&#20195;&#29702;&#65292;&#20363;&#22914;&#26159;&#21542;&#30693;&#36947;&#23458;&#25143;&#24050;&#25918;&#24323;&#25490;&#38431;&#21644;&#20182;&#20204;&#31561;&#24453;&#26381;&#21153;&#30340;&#24847;&#24895;&#65288;&#32784;&#24515;&#65289;&#65292;&#21463;&#21040;&#20449;&#24687;&#19981;&#30830;&#23450;&#24615;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32858;&#28966;&#20110;&#20027;&#35201;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#30340;&#24433;&#21709;&#65306;&#23458;&#25143;&#30340;&#26080;&#22768;&#25918;&#24323;&#12290;&#36825;&#20123;&#23458;&#25143;&#22312;&#31561;&#24453;&#22238;&#31572;&#20182;&#20204;&#30340;&#26597;&#35810;&#26102;&#31163;&#24320;&#31995;&#32479;&#65292;&#20294;&#27809;&#26377;&#32473;&#20986;&#20219;&#20309;&#25351;&#31034;&#65292;&#20363;&#22914;&#20851;&#38381;&#20114;&#21160;&#30340;&#31227;&#21160;&#24212;&#29992;&#31243;&#24207;&#12290;&#22240;&#27492;&#65292;&#31995;&#32479;&#19981;&#30693;&#36947;&#20182;&#20204;&#24050;&#32463;&#31163;&#24320;&#65292;&#24182;&#28010;&#36153;&#20195;&#29702;&#20154;&#30340;&#26102;&#38388;&#21644;&#33021;&#21147;&#65292;&#30452;&#21040;&#24847;&#35782;&#21040;&#36825;&#19968;&#20107;&#23454;&#12290;&#26412;&#25991;&#34920;&#26126;&#65292;&#25918;&#24323;&#23458;&#25143;&#20013;&#30340;30&#65285;-67&#65285;&#25918;&#24323;&#26102;&#20250;&#37319;&#21462;&#26080;&#22768;&#25918;&#24323;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the quest to improve services, companies offer customers the opportunity to interact with agents through contact centers, where the communication is mainly text-based. This has become one of the favorite channels of communication with companies in recent years. However, contact centers face operational challenges, since the measurement of common proxies for customer experience, such as knowledge of whether customers have abandoned the queue and their willingness to wait for service (patience), are subject to information uncertainty. We focus this research on the impact of a main source of such uncertainty: silent abandonment by customers. These customers leave the system while waiting for a reply to their inquiry, but give no indication of doing so, such as closing the mobile app of the interaction. As a result, the system is unaware that they have left and waste agent time and capacity until this fact is realized. In this paper, we show that 30%-67% of the abandoning customers aban
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#38754;&#21521;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#30340;&#22312;&#32447;&#36830;&#32493;&#36229;&#21442;&#25968;&#35843;&#25972;&#26694;&#26550;CDT&#65292;&#33021;&#22815;&#21160;&#24577;&#22320;&#22312;&#25628;&#32034;&#31354;&#38388;&#20869;&#23398;&#20064;&#26368;&#20248;&#21442;&#25968;&#37197;&#32622;&#12290;</title><link>http://arxiv.org/abs/2302.09440</link><description>&lt;p&gt;
&#22312;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#39046;&#22495;&#36827;&#34892;&#22312;&#32447;&#36830;&#32493;&#36229;&#21442;&#25968;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Online Continuous Hyperparameter Optimization for Contextual Bandits. (arXiv:2302.09440v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09440
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#38754;&#21521;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#30340;&#22312;&#32447;&#36830;&#32493;&#36229;&#21442;&#25968;&#35843;&#25972;&#26694;&#26550;CDT&#65292;&#33021;&#22815;&#21160;&#24577;&#22320;&#22312;&#25628;&#32034;&#31354;&#38388;&#20869;&#23398;&#20064;&#26368;&#20248;&#21442;&#25968;&#37197;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#38543;&#26426;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#20013;&#65292;&#20195;&#29702;&#26681;&#25454;&#36807;&#21435;&#30340;&#32463;&#39564;&#20174;&#26102;&#38388;&#30456;&#20851;&#34892;&#21160;&#38598;&#20013;&#20381;&#27425;&#37319;&#21462;&#34892;&#21160;&#65292;&#20197;&#26368;&#23567;&#21270;&#24635;&#21518;&#24724;&#12290;&#19982;&#35768;&#22810;&#20854;&#20182;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#19968;&#26679;&#65292;&#24378;&#21270;&#23398;&#20064;&#30340;&#24615;&#33021;&#20005;&#37325;&#20381;&#36182;&#20110;&#20854;&#22810;&#20010;&#36229;&#21442;&#25968;&#65292;&#24182;&#19988;&#29702;&#35770;&#25512;&#23548;&#20986;&#30340;&#21442;&#25968;&#20540;&#21487;&#33021;&#23548;&#33268;&#23454;&#38469;&#19978;&#19981;&#20196;&#20154;&#28385;&#24847;&#30340;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#22312;&#24378;&#21270;&#23398;&#20064;&#29615;&#22659;&#19979;&#20351;&#29992;&#31163;&#32447;&#20248;&#21270;&#26041;&#27861;&#65288;&#22914;&#20132;&#21449;&#39564;&#35777;&#65289;&#36873;&#25321;&#36229;&#21442;&#25968;&#26159;&#19981;&#21487;&#34892;&#30340;&#65292;&#22240;&#20026;&#20915;&#31574;&#24517;&#39035;&#23454;&#26102;&#36827;&#34892;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#38754;&#21521;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#30340;&#22312;&#32447;&#36830;&#32493;&#36229;&#21442;&#25968;&#35843;&#25972;&#26694;&#26550;&#65292;&#20197;&#23398;&#20064;&#39134;&#34892;&#20013;&#30340;&#26368;&#20339;&#21442;&#25968;&#37197;&#32622;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#19968;&#20010;&#21517;&#20026;CDT&#65288;Continuous Dynamic Tuning&#65289;&#30340;&#21452;&#23618;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#24182;&#23558;&#36229;&#21442;&#25968;&#20248;&#21270;&#24418;&#24335;&#21270;&#20026;&#38750;&#24179;&#31283;&#36830;&#32493;&#27494;&#22120;&#24378;&#21270;&#23398;&#20064;&#65292;&#22312;&#20854;&#20013;&#27599;&#20010;&#27494;&#22120;&#20195;&#34920;&#19968;&#31181;&#36229;&#21442;&#25968;&#32452;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
In stochastic contextual bandits, an agent sequentially makes actions from a time-dependent action set based on past experience to minimize the cumulative regret. Like many other machine learning algorithms, the performance of bandits heavily depends on their multiple hyperparameters, and theoretically derived parameter values may lead to unsatisfactory results in practice. Moreover, it is infeasible to use offline tuning methods like cross-validation to choose hyperparameters under the bandit environment, as the decisions should be made in real time. To address this challenge, we propose the first online continuous hyperparameter tuning framework for contextual bandits to learn the optimal parameter configuration within a search space on the fly. Specifically, we use a double-layer bandit framework named CDT (Continuous Dynamic Tuning) and formulate the hyperparameter optimization as a non-stationary continuum-armed bandit, where each arm represents a combination of hyperparameters, a
&lt;/p&gt;</description></item></channel></rss>