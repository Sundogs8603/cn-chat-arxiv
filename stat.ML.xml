<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31232;&#30095;&#24809;&#32602;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#23398;&#20064;&#24369;&#30456;&#20851;&#24615;&#36807;&#31243;&#65292;&#24182;&#22312;&#29305;&#23450;&#24773;&#20917;&#19979;&#20351;&#29992;$\theta_\infty$&#31995;&#25968;&#12290;&#25991;&#20013;&#36824;&#25552;&#20379;&#20102;&#30456;&#24212;&#30340;&#31070;&#35861;&#19981;&#31561;&#24335;&#21644;&#25910;&#25947;&#36895;&#24230;&#65292;&#23545;&#20110;&#30446;&#26631;&#20989;&#25968;&#36275;&#22815;&#20809;&#28369;&#30340;&#24773;&#20917;&#65292;&#36229;&#39069;&#39118;&#38505;&#30340;&#25910;&#25947;&#36895;&#24230;&#25509;&#36817;&#20110;$\mathcal{O}(n^{-1/3})$&#12290;&#20854;&#20013;&#25552;&#20379;&#20102;&#27169;&#25311;&#32467;&#26524;&#21644;&#24212;&#29992;&#20110;&#39044;&#27979;Vit&#243;ria&#39063;&#31890;&#29289;&#30340;&#26696;&#20363;&#12290;</title><link>http://arxiv.org/abs/2305.06230</link><description>&lt;p&gt;
&#24102;&#26377;&#19968;&#33324;&#25439;&#22833;&#20989;&#25968;&#30340;&#24809;&#32602;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20272;&#35745;&#22120;&#22312;&#24369;&#30456;&#20851;&#24615;&#19979;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Penalized deep neural networks estimator with general loss functions under weak dependence. (arXiv:2305.06230v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06230
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31232;&#30095;&#24809;&#32602;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#23398;&#20064;&#24369;&#30456;&#20851;&#24615;&#36807;&#31243;&#65292;&#24182;&#22312;&#29305;&#23450;&#24773;&#20917;&#19979;&#20351;&#29992;$\theta_\infty$&#31995;&#25968;&#12290;&#25991;&#20013;&#36824;&#25552;&#20379;&#20102;&#30456;&#24212;&#30340;&#31070;&#35861;&#19981;&#31561;&#24335;&#21644;&#25910;&#25947;&#36895;&#24230;&#65292;&#23545;&#20110;&#30446;&#26631;&#20989;&#25968;&#36275;&#22815;&#20809;&#28369;&#30340;&#24773;&#20917;&#65292;&#36229;&#39069;&#39118;&#38505;&#30340;&#25910;&#25947;&#36895;&#24230;&#25509;&#36817;&#20110;$\mathcal{O}(n^{-1/3})$&#12290;&#20854;&#20013;&#25552;&#20379;&#20102;&#27169;&#25311;&#32467;&#26524;&#21644;&#24212;&#29992;&#20110;&#39044;&#27979;Vit&#243;ria&#39063;&#31890;&#29289;&#30340;&#26696;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#24191;&#27867;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#23545;&#20110;&#23398;&#20064;&#24369;&#30456;&#20851;&#24615;&#36807;&#31243;&#36827;&#34892;&#20102;&#31232;&#30095;&#24809;&#32602;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#12290;&#25105;&#20204;&#22788;&#29702;&#21253;&#25324;&#22238;&#24402;&#20272;&#35745;&#12289;&#20998;&#31867;&#12289;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#22312;&#20869;&#30340;&#19968;&#33324;&#26694;&#26550;&#65292;&#32771;&#34385;&#20102;$\psi$&#24369;&#30456;&#20851;&#32467;&#26500;&#65292;&#24182;&#38024;&#23545;&#26377;&#30028;&#35266;&#27979;&#30340;&#29305;&#23450;&#24773;&#20917;&#65292;&#20063;&#20351;&#29992;&#20102;$\theta_\infty$&#31995;&#25968;&#12290;&#22312;&#36825;&#31181;$\theta_\infty$&#24369;&#30456;&#20381;&#30340;&#24773;&#20917;&#19979;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#22120;&#31867;&#20013;&#25552;&#20379;&#38750;&#28176;&#36817;&#27867;&#21270;&#30028;&#38480;&#12290;&#23545;&#20110;&#23398;&#20064;$\psi$&#21644;$\theta_\infty$&#24369;&#30456;&#20851;&#30340;&#36807;&#31243;&#65292;&#30830;&#23450;&#20102;&#31232;&#30095;&#24809;&#32602;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20272;&#35745;&#22120;&#36229;&#39069;&#39118;&#38505;&#30340;&#31070;&#35861;&#19981;&#31561;&#24335;&#12290;&#24403;&#30446;&#26631;&#20989;&#25968;&#36275;&#22815;&#20809;&#28369;&#26102;&#65292;&#36825;&#20123;&#36229;&#39069;&#39118;&#38505;&#30340;&#25910;&#25947;&#36895;&#24230;&#25509;&#36817;&#20110;$\mathcal{O}(n^{-1/3})$&#12290;&#25552;&#20379;&#20102;&#19968;&#20123;&#27169;&#25311;&#32467;&#26524;&#65292;&#24182;&#24212;&#29992;&#20110;Vit&#243;ria&#39063;&#31890;&#29289;&#30340;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper carries out sparse-penalized deep neural networks predictors for learning weakly dependent processes, with a broad class of loss functions. We deal with a general framework that includes, regression estimation, classification, times series prediction, $\cdots$ The $\psi$-weak dependence structure is considered, and for the specific case of bounded observations, $\theta_\infty$-coefficients are also used. In this case of $\theta_\infty$-weakly dependent, a non asymptotic generalization bound within the class of deep neural networks predictors is provided. For learning both $\psi$ and $\theta_\infty$-weakly dependent processes, oracle inequalities for the excess risk of the sparse-penalized deep neural networks estimators are established. When the target function is sufficiently smooth, the convergence rate of these excess risk is close to $\mathcal{O}(n^{-1/3})$. Some simulation results are provided, and application to the forecast of the particulate matter in the Vit\'{o}ria
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#35745;&#31639;&#39640;&#25928;&#19988;&#32479;&#35745;&#20248;&#21270;&#30340;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#21644;&#20302;&#31209;&#32447;&#24615;&#22238;&#24402;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#39640;&#32500;&#25968;&#25454;&#19979;&#30340;&#24322;&#24120;&#22122;&#22768;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2305.06199</link><description>&lt;p&gt;
&#39640;&#32500;&#31283;&#20581;&#32447;&#24615;&#22238;&#24402;&#30340;&#35745;&#31639;&#39640;&#25928;&#21644;&#32479;&#35745;&#20248;&#21270;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Computationally Efficient and Statistically Optimal Robust High-Dimensional Linear Regression. (arXiv:2305.06199v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06199
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#35745;&#31639;&#39640;&#25928;&#19988;&#32479;&#35745;&#20248;&#21270;&#30340;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#21644;&#20302;&#31209;&#32447;&#24615;&#22238;&#24402;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#39640;&#32500;&#25968;&#25454;&#19979;&#30340;&#24322;&#24120;&#22122;&#22768;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#37325;&#23614;&#22122;&#22768;&#25110;&#24322;&#24120;&#20540;&#27745;&#26579;&#19979;&#36827;&#34892;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#26080;&#35770;&#26159;&#35745;&#31639;&#19978;&#36824;&#26159;&#32479;&#35745;&#19978;&#12290;&#20984;&#20248;&#21270;&#26041;&#27861;&#24050;&#34987;&#35777;&#26126;&#22312;&#32479;&#35745;&#19978;&#26159;&#26368;&#20248;&#30340;&#65292;&#20294;&#36890;&#24120;&#30001;&#20110;&#40065;&#26834;&#25439;&#22833;&#20989;&#25968;&#26159;&#38750;&#20809;&#28369;&#30340;&#32780;&#20135;&#29983;&#39640;&#35745;&#31639;&#25104;&#26412;&#12290;&#26368;&#36817;&#65292;&#36890;&#36807;&#23376;&#26799;&#24230;&#19979;&#38477;&#25552;&#20986;&#20102;&#35745;&#31639;&#36895;&#24230;&#24555;&#30340;&#38750;&#20984;&#20248;&#21270;&#26041;&#27861;&#65292;&#20294;&#21363;&#20351;&#22312;&#23376;&#39640;&#26031;&#22122;&#22768;&#19979;&#65292;&#36825;&#20123;&#26041;&#27861;&#20063;&#26080;&#27861;&#25552;&#20379;&#32479;&#35745;&#19968;&#33268;&#20272;&#35745;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#21644;&#20302;&#31209;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#30340;&#25237;&#24433;&#23376;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#19981;&#20165;&#20855;&#26377;&#32447;&#24615;&#25910;&#25947;&#30340;&#35745;&#31639;&#25928;&#29575;&#65292;&#32780;&#19988;&#22312;&#22122;&#22768;&#20026;&#39640;&#26031;&#22122;&#22768;&#65292;&#25110;&#20855;&#26377;&#26377;&#38480;1 + epsilon&#30697;&#30340;&#37325;&#23614;&#22122;&#22768;&#19979;&#65292;&#20063;&#20855;&#26377;&#32479;&#35745;&#20248;&#21270;&#30340;&#24615;&#36136;&#12290;&#25910;&#25947;&#29702;&#35770;&#36866;&#29992;&#20110;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#24182;&#30740;&#31350;&#20102;&#20854;&#23545;&#32477;&#23545;&#20540;&#25439;&#22833;&#12289;Huber&#25439;&#22833;&#21644;&#20998;&#20301;&#25968;&#25439;&#22833;&#30340;&#20855;&#20307;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
High-dimensional linear regression under heavy-tailed noise or outlier corruption is challenging, both computationally and statistically. Convex approaches have been proven statistically optimal but suffer from high computational costs, especially since the robust loss functions are usually non-smooth. More recently, computationally fast non-convex approaches via sub-gradient descent are proposed, which, unfortunately, fail to deliver a statistically consistent estimator even under sub-Gaussian noise. In this paper, we introduce a projected sub-gradient descent algorithm for both the sparse linear regression and low-rank linear regression problems. The algorithm is not only computationally efficient with linear convergence but also statistically optimal, be the noise Gaussian or heavy-tailed with a finite 1 + epsilon moment. The convergence theory is established for a general framework and its specific applications to absolute loss, Huber loss and quantile loss are investigated. Compar
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#35777;&#26126;&#20102;&#22810;&#30446;&#26631;&#20248;&#21270;&#30340;&#36870;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#22312;&#29702;&#35770;&#23618;&#38754;&#19978;&#30340;&#25910;&#25947;&#24615;&#65292;&#21253;&#25324;Wasserstein&#36870;&#24378;&#21270;&#23398;&#20064;&#21644;&#24120;&#35268;&#36870;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.06137</link><description>&lt;p&gt;
&#22810;&#30446;&#26631;&#20248;&#21270;&#30340;&#36870;&#24378;&#21270;&#23398;&#20064;&#30340;&#25910;&#25947;&#24615;&#35777;&#26126;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
A proof of convergence of inverse reinforcement learning for multi-objective optimization. (arXiv:2305.06137v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06137
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#35777;&#26126;&#20102;&#22810;&#30446;&#26631;&#20248;&#21270;&#30340;&#36870;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#22312;&#29702;&#35770;&#23618;&#38754;&#19978;&#30340;&#25910;&#25947;&#24615;&#65292;&#21253;&#25324;Wasserstein&#36870;&#24378;&#21270;&#23398;&#20064;&#21644;&#24120;&#35268;&#36870;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23558;&#31561;&#25928;&#20110;&#22810;&#30446;&#26631;&#20248;&#21270;&#30340;WIRL&#38382;&#39064;&#30340;&#36870;&#38382;&#39064;&#19982;&#25237;&#24433;&#27425;&#26799;&#24230;&#27861;&#30456;&#32467;&#21512;&#65292;&#35777;&#26126;&#20102;Wasserstein&#36870;&#24378;&#21270;&#23398;&#20064;&#65288;WIRL&#65289;&#22312;&#22810;&#30446;&#26631;&#20248;&#21270;&#20013;&#30340;&#25910;&#25947;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#36870;&#24378;&#21270;&#23398;&#20064;&#65288;&#26368;&#22823;&#29109;&#36870;&#24378;&#21270;&#23398;&#20064;&#65292;&#23548;&#24341;&#25104;&#26412;&#23398;&#20064;&#65289;&#22312;&#22810;&#30446;&#26631;&#20248;&#21270;&#20013;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We show the convergence of Wasserstein inverse reinforcement learning (WIRL) for multi-objective optimizations with the projective subgradient method by formulating an inverse problem of the optimization problem that is equivalent to WIRL for multi-objective optimizations.  In addition, we prove convergence of inverse reinforcement learning (maximum entropy inverse reinforcement learning, guid cost learning) for multi-objective optimization with the projective subgradient method.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#38480;&#31934;&#24230;&#19979;&#37319;&#26679;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#25913;&#30340;&#36319;&#36394;&#31639;&#27861;&#26469;&#22788;&#29702;&#26368;&#20248;&#20998;&#37197;&#30340;&#38750;&#21807;&#19968;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#28176;&#36827;&#26368;&#20248;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.06082</link><description>&lt;p&gt;
&#26377;&#38480;&#31934;&#24230;&#37319;&#26679;&#19979;&#30340;&#36172;&#21338;&#26426;&#26368;&#20248;&#33218;&#35782;&#21035;&#38382;&#39064;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Best Arm Identification in Bandits with Limited Precision Sampling. (arXiv:2305.06082v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06082
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#38480;&#31934;&#24230;&#19979;&#37319;&#26679;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20462;&#25913;&#30340;&#36319;&#36394;&#31639;&#27861;&#26469;&#22788;&#29702;&#26368;&#20248;&#20998;&#37197;&#30340;&#38750;&#21807;&#19968;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#28176;&#36827;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#21464;&#20307;&#65292;&#22312;&#35813;&#38382;&#39064;&#20013;&#65292;&#23398;&#20064;&#32773;&#22312;&#36873;&#25321;&#33218;&#26102;&#26377;&#38480;&#30340;&#31934;&#24230;&#12290;&#23398;&#20064;&#32773;&#21482;&#33021;&#36890;&#36807;&#29305;&#23450;&#30340;&#25506;&#32034;&#32452;&#21512;&#65288;&#21363;&#25152;&#35859;&#30340;&#31665;&#23376;&#65289;&#37319;&#26679;&#33218;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#22312;&#27599;&#20010;&#37319;&#26679;&#26102;&#21051;&#65292;&#23398;&#20064;&#32773;&#36873;&#25321;&#19968;&#20010;&#31665;&#23376;&#65292;&#28982;&#21518;&#26681;&#25454;&#31665;&#23376;&#29305;&#23450;&#30340;&#27010;&#29575;&#20998;&#24067;&#25289;&#21160;&#33218;&#65292;&#25581;&#31034;&#34987;&#25289;&#21160;&#30340;&#33218;&#21450;&#20854;&#30636;&#26102;&#25910;&#30410;&#65292;&#20854;&#30446;&#26631;&#26159;&#36890;&#36807;&#26368;&#23567;&#21270;&#26399;&#26395;&#20572;&#27490;&#26102;&#38388;&#26469;&#25214;&#21040;&#26368;&#20339;&#33218;&#65292;&#32780;&#35823;&#24046;&#27010;&#29575;&#21463;&#21040;&#19978;&#38480;&#32422;&#26463;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study best arm identification in a variant of the multi-armed bandit problem where the learner has limited precision in arm selection. The learner can only sample arms via certain exploration bundles, which we refer to as boxes. In particular, at each sampling epoch, the learner selects a box, which in turn causes an arm to get pulled as per a box-specific probability distribution. The pulled arm and its instantaneous reward are revealed to the learner, whose goal is to find the best arm by minimising the expected stopping time, subject to an upper bound on the error probability. We present an asymptotic lower bound on the expected stopping time, which holds as the error probability vanishes. We show that the optimal allocation suggested by the lower bound is, in general, non-unique and therefore challenging to track. We propose a modified tracking-based algorithm to handle non-unique optimal allocations, and demonstrate that it is asymptotically optimal. We also present non-asympto
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#27604;&#36739;&#20102;&#19981;&#21516;&#30340;&#32570;&#22833;&#25968;&#25454;&#22788;&#29702;&#26041;&#27861;&#23545;&#30456;&#20851;&#22270;&#30340;&#24433;&#21709;&#65292;&#24314;&#35758;&#20351;&#29992;&#30452;&#25509;&#21442;&#25968;&#20272;&#35745;&#27861;(DPER)&#26469;&#32472;&#21046;&#30456;&#20851;&#22270;</title><link>http://arxiv.org/abs/2305.06044</link><description>&lt;p&gt;
&#32570;&#22833;&#20540;&#19979;&#30340;&#30456;&#20851;&#24615;&#21487;&#35270;&#21270;&#65306;&#22635;&#20805;&#27861;&#21644;&#30452;&#25509;&#21442;&#25968;&#20272;&#35745;&#27861;&#30340;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
Correlation visualization under missing values: a comparison between imputation and direct parameter estimation methods. (arXiv:2305.06044v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.06044
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#27604;&#36739;&#20102;&#19981;&#21516;&#30340;&#32570;&#22833;&#25968;&#25454;&#22788;&#29702;&#26041;&#27861;&#23545;&#30456;&#20851;&#22270;&#30340;&#24433;&#21709;&#65292;&#24314;&#35758;&#20351;&#29992;&#30452;&#25509;&#21442;&#25968;&#20272;&#35745;&#27861;(DPER)&#26469;&#32472;&#21046;&#30456;&#20851;&#22270;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30456;&#20851;&#30697;&#38453;&#21487;&#35270;&#21270;&#23545;&#20110;&#29702;&#35299;&#25968;&#25454;&#38598;&#20013;&#21464;&#37327;&#20043;&#38388;&#30340;&#20851;&#31995;&#33267;&#20851;&#37325;&#35201;&#65292;&#20294;&#26159;&#32570;&#22833;&#25968;&#25454;&#20250;&#23545;&#30456;&#20851;&#31995;&#25968;&#30340;&#20272;&#35745;&#20135;&#29983;&#26174;&#33879;&#25361;&#25112;&#12290;&#26412;&#25991;&#27604;&#36739;&#20102;&#19981;&#21516;&#30340;&#32570;&#22833;&#25968;&#25454;&#22788;&#29702;&#26041;&#27861;&#23545;&#30456;&#20851;&#22270;&#30340;&#24433;&#21709;&#65292;&#37325;&#28857;&#20851;&#27880;&#20004;&#31181;&#24120;&#35265;&#30340;&#32570;&#22833;&#27169;&#24335;&#65306;&#38543;&#26426;&#21644;&#21333;&#35843;&#12290;&#25105;&#20204;&#26088;&#22312;&#20026;&#30740;&#31350;&#20154;&#21592;&#21644;&#23454;&#36341;&#32773;&#25552;&#20379;&#23454;&#29992;&#30340;&#31574;&#30053;&#21644;&#24314;&#35758;&#65292;&#20197;&#21019;&#24314;&#21644;&#20998;&#26512;&#30456;&#20851;&#22270;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#34429;&#28982;&#22635;&#20805;&#27861;&#36890;&#24120;&#29992;&#20110;&#32570;&#22833;&#25968;&#25454;&#65292;&#20294;&#20351;&#29992;&#22635;&#20805;&#30340;&#25968;&#25454;&#26469;&#29983;&#25104;&#30456;&#20851;&#30697;&#38453;&#22270;&#21487;&#33021;&#20250;&#23548;&#33268;&#23545;&#29305;&#24449;&#20043;&#38388;&#20851;&#31995;&#30340;&#35823;&#23548;&#24615;&#25512;&#26029;&#12290;&#25105;&#20204;&#24314;&#35758;&#22522;&#20110;&#20854;&#22312;&#23454;&#39564;&#20013;&#30340;&#34920;&#29616;&#65292;&#20351;&#29992;DPER&#65292;&#19968;&#31181;&#30452;&#25509;&#21442;&#25968;&#20272;&#35745;&#26041;&#27861;&#65292;&#32472;&#21046;&#30456;&#20851;&#30697;&#38453;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Correlation matrix visualization is essential for understanding the relationships between variables in a dataset, but missing data can pose a significant challenge in estimating correlation coefficients. In this paper, we compare the effects of various missing data methods on the correlation plot, focusing on two common missing patterns: random and monotone. We aim to provide practical strategies and recommendations for researchers and practitioners in creating and analyzing the correlation plot. Our experimental results suggest that while imputation is commonly used for missing data, using imputed data for plotting the correlation matrix may lead to a significantly misleading inference of the relation between the features. We recommend using DPER, a direct parameter estimation approach, for plotting the correlation matrix based on its performance in the experiments.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;Pearson-Matthews&#30456;&#20851;&#31995;&#25968;&#65288;MCC&#65289;&#21450;&#20854;&#25193;&#23637;&#29992;&#20110;&#22810;&#20803;&#20998;&#31867;&#30340;&#25351;&#26631;&#65292;&#21253;&#25324;$\text{R}_{\text{K}}$&#12289;$\text{MCC}_k$&#21644;$\text{Q}_k$&#12290;&#27492;&#22806;&#65292;&#36824;&#25552;&#20379;&#20102;&#35745;&#31639;&#36825;&#20123;&#31995;&#25968;&#30340;&#23454;&#29992;&#24314;&#35758;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#20204;&#30340;&#24615;&#33021;&#21644;&#36866;&#29992;&#24615;&#20316;&#20026;&#20551;&#35774;&#26816;&#39564;&#12290;</title><link>http://arxiv.org/abs/2305.05974</link><description>&lt;p&gt;
&#20108;&#20998;&#31867;&#21644;&#22810;&#20998;&#31867;&#21450;&#20551;&#35774;&#26816;&#39564;&#20013;&#30340;Pearson-Matthews&#30456;&#20851;&#31995;&#25968;
&lt;/p&gt;
&lt;p&gt;
Pearson-Matthews correlation coefficients for binary and multinary classification and hypothesis testing. (arXiv:2305.05974v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05974
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;Pearson-Matthews&#30456;&#20851;&#31995;&#25968;&#65288;MCC&#65289;&#21450;&#20854;&#25193;&#23637;&#29992;&#20110;&#22810;&#20803;&#20998;&#31867;&#30340;&#25351;&#26631;&#65292;&#21253;&#25324;$\text{R}_{\text{K}}$&#12289;$\text{MCC}_k$&#21644;$\text{Q}_k$&#12290;&#27492;&#22806;&#65292;&#36824;&#25552;&#20379;&#20102;&#35745;&#31639;&#36825;&#20123;&#31995;&#25968;&#30340;&#23454;&#29992;&#24314;&#35758;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#20204;&#30340;&#24615;&#33021;&#21644;&#36866;&#29992;&#24615;&#20316;&#20026;&#20551;&#35774;&#26816;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Pearson-Matthews&#30456;&#20851;&#31995;&#25968;&#65288;&#36890;&#24120;&#32553;&#20889;&#20026;MCC&#65289;&#34987;&#35748;&#20026;&#26159;&#29992;&#20110;&#20108;&#20803;&#20998;&#31867;&#25110;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#24615;&#33021;&#30340;&#26368;&#26377;&#29992;&#30340;&#25351;&#26631;&#20043;&#19968;&#65288;&#20026;&#20102;&#31616;&#27905;&#65292;&#25105;&#20204;&#23558;&#22987;&#32456;&#20351;&#29992;&#20998;&#31867;&#26415;&#35821;&#65292;&#20294;&#26412;&#25991;&#20013;&#35752;&#35770;&#30340;&#27010;&#24565;&#21644;&#26041;&#27861;&#23436;&#20840;&#36866;&#29992;&#20110;&#20551;&#35774;&#26816;&#39564;&#65289;&#12290;&#23545;&#20110;&#22810;&#20803;&#20998;&#31867;&#20219;&#21153;&#65288;&#20855;&#26377;&#20004;&#20010;&#20197;&#19978;&#30340;&#31867;&#65289;&#65292;&#29616;&#26377;&#30340;MCC&#25193;&#23637;&#36890;&#24120;&#31216;&#20026;$\text{R}_{\text{K}}$&#25351;&#26631;&#65292;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#20063;&#24050;&#32463;&#25104;&#21151;&#20351;&#29992;&#12290;&#26412;&#25991;&#39318;&#20808;&#20171;&#32461;&#20102;MCC&#30340;&#26576;&#20123;&#26041;&#38754;&#65292;&#28982;&#21518;&#32487;&#32493;&#35752;&#35770;&#26412;&#25991;&#30340;&#20027;&#35201;&#28966;&#28857;&#8212;&#8212;&#22810;&#20803;&#20998;&#31867;&#8212;&#8212;&#23613;&#31649;&#20854;&#22312;&#23454;&#36341;&#21644;&#29702;&#35770;&#19978;&#38750;&#24120;&#37325;&#35201;&#65292;&#20294;&#30475;&#36215;&#26469;&#27809;&#26377;&#20108;&#20803;&#20998;&#31867;&#20027;&#39064;&#37027;&#20040;&#21457;&#36798;&#12290;&#25105;&#20204;&#30340;$\text{R}_{\text{K}}$&#35752;&#35770;&#21518;&#26159;&#24341;&#20837;&#21478;&#22806;&#20004;&#31181;&#29992;&#20110;&#22810;&#20803;&#20998;&#31867;&#30340;&#24230;&#37327;&#65292;&#20998;&#21035;&#20026;$\text{MCC}_k$&#21644;$\text{Q}_k$&#12290;&#35813;&#35770;&#25991;&#36824;&#25552;&#20379;&#20102;&#35745;&#31639;&#36825;&#20123;&#31995;&#25968;&#30340;&#23454;&#29992;&#24314;&#35758;&#65292;&#24182;&#25552;&#20379;&#20102;&#27169;&#25311;&#32467;&#26524;&#65292;&#20197;&#35828;&#26126;&#23427;&#20204;&#30340;&#24615;&#33021;&#21450;&#20854;&#20316;&#20026;&#20551;&#35774;&#26816;&#39564;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Pearson-Matthews correlation coefficient (usually abbreviated MCC) is considered to be one of the most useful metrics for the performance of a binary classification or hypothesis testing method (for the sake of conciseness we will use the classification terminology throughout, but the concepts and methods discussed in the paper apply verbatim to hypothesis testing as well). For multinary classification tasks (with more than two classes) the existing extension of MCC, commonly called the $\text{R}_{\text{K}}$ metric, has also been successfully used in many applications. The present paper begins with an introductory discussion on certain aspects of MCC. Then we go on to discuss the topic of multinary classification that is the main focus of this paper and which, despite its practical and theoretical importance, appears to be less developed than the topic of binary classification. Our discussion of the $\text{R}_{\text{K}}$ is followed by the introduction of two other metrics for mult
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#21487;&#20197;&#35299;&#20915;&#20844;&#24179;&#20027;&#25104;&#20998;&#20998;&#26512;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#22788;&#29702;&#25968;&#25454;&#20013;&#30340;&#31163;&#32676;&#20540;&#21644;&#32422;&#26463;&#20272;&#35745;&#30340;&#20844;&#24179;&#20027;&#25104;&#20998;&#31232;&#30095;&#24230;&#30340;&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#39640;&#25928;&#19988;&#27599;&#27425;&#36845;&#20195;&#37117;&#20250;&#22686;&#21152;&#21508;&#33258;&#30340;&#35774;&#35745;&#30446;&#26631;&#12290;</title><link>http://arxiv.org/abs/2305.05963</link><description>&lt;p&gt;
&#20844;&#24179;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#65306;&#20844;&#24179;PCA&#65292;&#20844;&#24179;&#40065;&#26834;PCA&#21644;&#20844;&#24179;&#31232;&#30095;PCA&#30340;&#26368;&#23567;&#21270;-&#26368;&#22823;&#21270;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Fair principal component analysis (PCA): minorization-maximization algorithms for Fair PCA, Fair Robust PCA and Fair Sparse PCA. (arXiv:2305.05963v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05963
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#21487;&#20197;&#35299;&#20915;&#20844;&#24179;&#20027;&#25104;&#20998;&#20998;&#26512;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#22788;&#29702;&#25968;&#25454;&#20013;&#30340;&#31163;&#32676;&#20540;&#21644;&#32422;&#26463;&#20272;&#35745;&#30340;&#20844;&#24179;&#20027;&#25104;&#20998;&#31232;&#30095;&#24230;&#30340;&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#39640;&#25928;&#19988;&#27599;&#27425;&#36845;&#20195;&#37117;&#20250;&#22686;&#21152;&#21508;&#33258;&#30340;&#35774;&#35745;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#20844;&#24179;PCA&#65288;FPCA&#65289;&#38382;&#39064;&#30340;&#26032;&#36845;&#20195;&#31639;&#27861;&#12290;&#25105;&#20204;&#20174;[1]&#25552;&#20986;&#30340;&#26368;&#22823;&#26368;&#23567;&#20844;&#24179;PCA&#20844;&#24335;&#24320;&#22987;&#65292;&#25512;&#23548;&#20986;&#19968;&#20010;&#31616;&#21333;&#32780;&#39640;&#25928;&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#23427;&#22522;&#20110;&#26368;&#23567;&#21270;&#26368;&#22823;&#21270;&#65288;MM&#65289;&#26041;&#27861;&#12290;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#20381;&#36182;&#20110;&#21322;&#27491;&#20132;&#32422;&#26463;&#30340;&#26494;&#24347;&#65292;&#35777;&#26126;&#20102;&#31639;&#27861;&#30340;&#27599;&#27425;&#36845;&#20195;&#37117;&#24456;&#32039;&#23494;&#12290;&#25152;&#25552;&#35758;&#30340;&#31639;&#27861;&#30340;&#39321;&#33609;&#29256;&#38656;&#35201;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#35299;&#20915;&#19968;&#20010;&#21322;&#27491;&#23450;&#35268;&#21010;&#65288;SDP&#65289;&#65292;&#21487;&#20197;&#36890;&#36807;&#26500;&#36896;&#20195;&#29702;&#26368;&#22823;&#21270;&#38382;&#39064;&#30340;&#23545;&#20598;&#38382;&#39064;&#23558;&#20854;&#36827;&#19968;&#27493;&#31616;&#21270;&#20026;&#19968;&#20010;&#20108;&#27425;&#35268;&#21010;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#20844;&#24179;PCA&#38382;&#39064;&#30340;&#20004;&#20010;&#37325;&#35201;&#37325;&#26500;&#65306;a&#65289;&#20844;&#24179;&#40065;&#26834;PCA&#8212;&#8212;&#21487;&#20197;&#22788;&#29702;&#25968;&#25454;&#20013;&#30340;&#31163;&#32676;&#20540;&#65307;b&#65289;&#20844;&#24179;&#31232;&#30095;PCA&#8212;&#8212;&#21487;&#20197;&#23545;&#20272;&#35745;&#30340;&#20844;&#24179;&#20027;&#25104;&#20998;&#36827;&#34892;&#31232;&#30095;&#32422;&#26463;&#12290;&#25152;&#25552;&#35758;&#30340;&#31639;&#27861;&#22312;&#35745;&#31639;&#19978;&#38750;&#24120;&#39640;&#25928;&#65292;&#24182;&#19988;&#20250;&#21333;&#35843;&#22686;&#21152;&#21508;&#33258;&#30340;&#35774;&#35745;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we propose a new iterative algorithm to solve the fair PCA (FPCA) problem. We start with the max-min fair PCA formulation originally proposed in [1] and derive a simple and efficient iterative algorithm which is based on the minorization-maximization (MM) approach. The proposed algorithm relies on the relaxation of a semi-orthogonality constraint which is proved to be tight at every iteration of the algorithm. The vanilla version of the proposed algorithm requires solving a semi-definite program (SDP) at every iteration, which can be further simplified to a quadratic program by formulating the dual of the surrogate maximization problem. We also propose two important reformulations of the fair PCA problem: a) fair robust PCA -- which can handle outliers in the data, and b) fair sparse PCA -- which can enforce sparsity on the estimated fair principal components. The proposed algorithms are computationally efficient and monotonically increase their respective design objectiv
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#26368;&#20339;&#21162;&#21147;&#36866;&#24212;&#24615;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#24046;&#24322;&#30340;&#29702;&#35770;&#20998;&#26512;&#26041;&#27861;&#20197;&#21450;&#29992;&#20110;&#26631;&#20934;&#22495;&#36866;&#24212;&#24615;&#38382;&#39064;&#30340;&#25913;&#36827;&#23398;&#20064;&#31639;&#27861;&#65292;&#34920;&#29616;&#20986;&#24456;&#22909;&#30340;&#23454;&#39564;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2305.05816</link><description>&lt;p&gt;
&#26368;&#20339;&#21162;&#21147;&#36866;&#24212;&#24615;
&lt;/p&gt;
&lt;p&gt;
Best-Effort Adaptation. (arXiv:2305.05816v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05816
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#26368;&#20339;&#21162;&#21147;&#36866;&#24212;&#24615;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#24046;&#24322;&#30340;&#29702;&#35770;&#20998;&#26512;&#26041;&#27861;&#20197;&#21450;&#29992;&#20110;&#26631;&#20934;&#22495;&#36866;&#24212;&#24615;&#38382;&#39064;&#30340;&#25913;&#36827;&#23398;&#20064;&#31639;&#27861;&#65292;&#34920;&#29616;&#20986;&#24456;&#22909;&#30340;&#23454;&#39564;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#30001;&#22810;&#20010;&#24212;&#29992;&#21644;&#32771;&#34385;&#22240;&#32032;&#28608;&#21457;&#20986;&#30340;&#26368;&#20339;&#21162;&#21147;&#36866;&#24212;&#24615;&#38382;&#39064;&#65292;&#20854;&#20013;&#21253;&#25324;&#30830;&#23450;&#19968;&#20010;&#31934;&#30830;&#30340;&#39044;&#27979;&#22120;&#20197;&#29992;&#20110;&#30446;&#26631;&#22495;&#65292;&#34429;&#28982;&#21482;&#26377;&#36866;&#37327;&#30340;&#24050;&#26631;&#35760;&#26679;&#26412;&#21487;&#29992;&#65292;&#20294;&#21033;&#29992;&#26469;&#33258;&#21478;&#19968;&#20010;&#25317;&#26377;&#22823;&#37327;&#24050;&#26631;&#35760;&#26679;&#26412;&#30340;&#22495;&#30340;&#20449;&#24687;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#21644;&#36890;&#29992;&#30340;&#22522;&#20110;&#24046;&#24322;&#30340;&#29702;&#35770;&#20998;&#26512;&#26679;&#26412;&#37325;&#26032;&#21152;&#26435;&#26041;&#27861;&#65292;&#21253;&#25324;&#22312;&#26435;&#37325;&#19978;&#22343;&#21248;&#20445;&#25345;&#30340;&#30028;&#38480;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20123;&#36793;&#30028;&#22914;&#20309;&#25351;&#23548;&#25105;&#20204;&#35814;&#32454;&#35752;&#35770;&#30340;&#23398;&#20064;&#31639;&#27861;&#30340;&#35774;&#35745;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#23398;&#20064;&#20445;&#35777;&#21644;&#31639;&#27861;&#20026;&#26631;&#20934;&#22495;&#36866;&#24212;&#24615;&#38382;&#39064;&#25552;&#20379;&#20102;&#25913;&#36827;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20854;&#20013;&#30446;&#26631;&#22495;&#21482;&#26377;&#23569;&#37327;&#26631;&#35760;&#25968;&#25454;&#25110;&#27809;&#26377;&#26631;&#35760;&#25968;&#25454;&#21487;&#29992;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25253;&#21578;&#20102;&#19968;&#31995;&#21015;&#23454;&#39564;&#30340;&#32467;&#26524;&#65292;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26368;&#20339;&#21162;&#21147;&#36866;&#24212;&#24615;&#21644;&#22495;&#36866;&#24212;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#20197;&#21450;&#19982;&#20960;&#20010;&#22522;&#32447;&#30340;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study a problem of best-effort adaptation motivated by several applications and considerations, which consists of determining an accurate predictor for a target domain, for which a moderate amount of labeled samples are available, while leveraging information from another domain for which substantially more labeled samples are at one's disposal. We present a new and general discrepancy-based theoretical analysis of sample reweighting methods, including bounds holding uniformly over the weights. We show how these bounds can guide the design of learning algorithms that we discuss in detail. We further show that our learning guarantees and algorithms provide improved solutions for standard domain adaptation problems, for which few labeled data or none are available from the target domain. We finally report the results of a series of experiments demonstrating the effectiveness of our best-effort adaptation and domain adaptation algorithms, as well as comparisons with several baselines. 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#20351;&#29992;&#35757;&#32451;&#25968;&#25454;&#36827;&#34892;&#35780;&#20272;&#27169;&#22411;&#24615;&#33021;&#30340;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#20197;&#20934;&#30830;&#22320;&#23450;&#20041;&#21644;&#26816;&#27979;&#36807;&#25311;&#21512;&#12290;</title><link>http://arxiv.org/abs/2305.05792</link><description>&lt;p&gt;
&#36807;&#25311;&#21512;&#30340;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
Testing for Overfitting. (arXiv:2305.05792v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05792
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#20351;&#29992;&#35757;&#32451;&#25968;&#25454;&#36827;&#34892;&#35780;&#20272;&#27169;&#22411;&#24615;&#33021;&#30340;&#20551;&#35774;&#26816;&#39564;&#26041;&#27861;&#65292;&#21487;&#20197;&#20934;&#30830;&#22320;&#23450;&#20041;&#21644;&#26816;&#27979;&#36807;&#25311;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#39640;&#22797;&#26434;&#24230;&#30340;&#27169;&#22411;&#24120;&#35265;&#36807;&#25311;&#21512;&#29616;&#35937;&#65292;&#21363;&#27169;&#22411;&#33021;&#22815;&#24456;&#22909;&#22320;&#20195;&#34920;&#25968;&#25454;&#65292;&#20294;&#26080;&#27861;&#25512;&#24191;&#21040;&#22522;&#30784;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#12290;&#35299;&#20915;&#36807;&#25311;&#21512;&#30340;&#20856;&#22411;&#26041;&#27861;&#26159;&#22312;&#30041;&#32622;&#38598;&#19978;&#35745;&#31639;&#32463;&#39564;&#39118;&#38505;&#65292;&#19968;&#26086;&#39118;&#38505;&#24320;&#22987;&#22686;&#21152;&#65292;&#23601;&#20572;&#27490;&#65288;&#25110;&#26631;&#35760;&#20309;&#26102;&#20572;&#27490;&#65289;&#12290;&#34429;&#28982;&#36825;&#31181;&#26041;&#27861;&#36755;&#20986;&#20102;&#33391;&#22909;&#27867;&#21270;&#30340;&#27169;&#22411;&#65292;&#20294;&#20854;&#23454;&#29616;&#21407;&#29702;&#20027;&#35201;&#26159;&#21551;&#21457;&#24335;&#30340;&#12290;&#26412;&#25991;&#35752;&#35770;&#36807;&#25311;&#21512;&#38382;&#39064;&#65292;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#20351;&#29992;&#35757;&#32451;&#25968;&#25454;&#36827;&#34892;&#35780;&#20272;&#26102;&#65292;&#26631;&#20934;&#28176;&#36817;&#21644;&#27987;&#24230;&#32467;&#26524;&#19981;&#25104;&#31435;&#12290;&#25105;&#20204;&#38543;&#21518;&#25552;&#20986;&#24182;&#38416;&#36848;&#20102;&#19968;&#20010;&#20551;&#35774;&#26816;&#39564;&#65292;&#36890;&#36807;&#35813;&#26816;&#39564;&#21487;&#20197;&#23545;&#20351;&#29992;&#35757;&#32451;&#25968;&#25454;&#35780;&#20272;&#27169;&#22411;&#24615;&#33021;&#65292;&#24182;&#37327;&#21270;&#22320;&#23450;&#20041;&#21644;&#26816;&#27979;&#36807;&#25311;&#21512;&#12290;&#25105;&#20204;&#20381;&#38752;&#30830;&#20445;&#32463;&#39564;&#22343;&#20540;&#24212;&#35813;&#39640;&#27010;&#29575;&#22320;&#36817;&#20284;&#20854;&#30495;&#23454;&#22343;&#20540;&#30340;&#27987;&#24230;&#30028;&#38480;&#65292;&#20197;&#24471;&#20986;&#20182;&#20204;&#24212;&#35813;&#30456;&#20114;&#25509;&#36817;&#30340;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
High complexity models are notorious in machine learning for overfitting, a phenomenon in which models well represent data but fail to generalize an underlying data generating process. A typical procedure for circumventing overfitting computes empirical risk on a holdout set and halts once (or flags that/when) it begins to increase. Such practice often helps in outputting a well-generalizing model, but justification for why it works is primarily heuristic.  We discuss the overfitting problem and explain why standard asymptotic and concentration results do not hold for evaluation with training data. We then proceed to introduce and argue for a hypothesis test by means of which both model performance may be evaluated using training data, and overfitting quantitatively defined and detected. We rely on said concentration bounds which guarantee that empirical means should, with high probability, approximate their true mean to conclude that they should approximate each other. We stipulate co
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#30742;&#22681;&#38543;&#26426;&#37327;&#23376;&#30005;&#36335;&#36755;&#20986;&#20998;&#24067;&#23398;&#20064;&#26159;&#19968;&#20010;&#24179;&#22343;&#22797;&#26434;&#24230;&#22256;&#38590;&#30340;&#38382;&#39064;&#65292;&#38656;&#35201;&#36827;&#34892;&#36229;&#22810;&#39033;&#24335;&#27425;&#25968;&#30340;&#26597;&#35810;&#25165;&#33021;&#26377;&#25928;&#35299;&#20915;&#12290;</title><link>http://arxiv.org/abs/2305.05765</link><description>&lt;p&gt;
&#20851;&#20110;&#37327;&#23376;&#30005;&#36335;&#36755;&#20986;&#20998;&#24067;&#23398;&#20064;&#30340;&#24179;&#22343;&#22797;&#26434;&#24230;
&lt;/p&gt;
&lt;p&gt;
On the average-case complexity of learning output distributions of quantum circuits. (arXiv:2305.05765v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05765
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#30742;&#22681;&#38543;&#26426;&#37327;&#23376;&#30005;&#36335;&#36755;&#20986;&#20998;&#24067;&#23398;&#20064;&#26159;&#19968;&#20010;&#24179;&#22343;&#22797;&#26434;&#24230;&#22256;&#38590;&#30340;&#38382;&#39064;&#65292;&#38656;&#35201;&#36827;&#34892;&#36229;&#22810;&#39033;&#24335;&#27425;&#25968;&#30340;&#26597;&#35810;&#25165;&#33021;&#26377;&#25928;&#35299;&#20915;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#30742;&#22681;&#38543;&#26426;&#37327;&#23376;&#30005;&#36335;&#30340;&#36755;&#20986;&#20998;&#24067;&#23398;&#20064;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#22312;&#32479;&#35745;&#26597;&#35810;&#27169;&#22411;&#19979;&#65292;&#35813;&#38382;&#39064;&#30340;&#24179;&#22343;&#22797;&#26434;&#24230;&#26159;&#22256;&#38590;&#30340;&#12290;&#20855;&#20307;&#22320;&#65292;&#23545;&#20110;&#28145;&#24230;&#20026;$d$&#12289;&#30001;$n$&#20010;&#37327;&#23376;&#27604;&#29305;&#26500;&#25104;&#30340;&#30742;&#22681;&#38543;&#26426;&#37327;&#23376;&#30005;&#36335;&#65292;&#25105;&#20204;&#24471;&#20986;&#20102;&#19977;&#20010;&#20027;&#35201;&#32467;&#35770;&#65306;&#22312;&#36229;&#23545;&#25968;&#30005;&#36335;&#28145;&#24230;$d=\omega(\log(n))$&#26102;&#65292;&#20219;&#20309;&#23398;&#20064;&#31639;&#27861;&#37117;&#38656;&#35201;&#36827;&#34892;&#36229;&#22810;&#39033;&#24335;&#27425;&#25968;&#30340;&#26597;&#35810;&#25165;&#33021;&#22312;&#38543;&#26426;&#23454;&#20363;&#19978;&#23454;&#29616;&#24658;&#23450;&#30340;&#25104;&#21151;&#27010;&#29575;&#12290;&#23384;&#22312;&#19968;&#20010;$d=O(n)$&#65292;&#36825;&#24847;&#21619;&#30528;&#20219;&#20309;&#23398;&#20064;&#31639;&#27861;&#38656;&#35201;&#36827;&#34892;$\Omega(2^n)$&#27425;&#26597;&#35810;&#25165;&#33021;&#22312;&#38543;&#26426;&#23454;&#20363;&#19978;&#23454;&#29616;$O(2^{-n})$&#30340;&#25104;&#21151;&#27010;&#29575;&#12290;&#22312;&#26080;&#38480;&#30005;&#36335;&#28145;&#24230;$d\to\infty$&#26102;&#65292;&#20219;&#20309;&#23398;&#20064;&#31639;&#27861;&#37117;&#38656;&#35201;&#36827;&#34892;$2^{2^{\Omega(n)}}$&#27425;&#26597;&#35810;&#25165;&#33021;&#22312;&#38543;&#26426;&#23454;&#20363;&#19978;&#23454;&#29616;$2^{-2^{\Omega(n)}}$&#30340;&#25104;&#21151;&#27010;&#29575;&#12290;&#20316;&#20026;&#19968;&#20010;&#29420;&#31435;&#30340;&#36741;&#21161;&#32467;&#26524;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;......&#65288;&#25991;&#31456;&#20869;&#23481;&#25130;&#26029;&#65289;
&lt;/p&gt;
&lt;p&gt;
In this work, we show that learning the output distributions of brickwork random quantum circuits is average-case hard in the statistical query model. This learning model is widely used as an abstract computational model for most generic learning algorithms. In particular, for brickwork random quantum circuits on $n$ qubits of depth $d$, we show three main results:  - At super logarithmic circuit depth $d=\omega(\log(n))$, any learning algorithm requires super polynomially many queries to achieve a constant probability of success over the randomly drawn instance.  - There exists a $d=O(n)$, such that any learning algorithm requires $\Omega(2^n)$ queries to achieve a $O(2^{-n})$ probability of success over the randomly drawn instance.  - At infinite circuit depth $d\to\infty$, any learning algorithm requires $2^{2^{\Omega(n)}}$ many queries to achieve a $2^{-2^{\Omega(n)}}$ probability of success over the randomly drawn instance.  As an auxiliary result of independent interest, we show 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#25240;&#25187;&#32047;&#31215;&#22686;&#30410;&#65288;DCG&#65289;&#25490;&#24207;&#24182;&#21152;&#26435;&#22788;&#29702;&#35757;&#32451;&#25968;&#25454;&#20197;&#25552;&#39640;&#27169;&#22411;&#23545;&#20302;&#20195;&#34920;&#24615;&#32452;&#30340;&#40065;&#26834;&#24615;&#30340;&#26041;&#27861;&#65292;&#23454;&#39564;&#35777;&#26126;&#20854;&#20248;&#20110;&#20808;&#21069;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2305.05759</link><description>&lt;p&gt;
&#25490;&#21517;&#21644;&#37325;&#26032;&#21152;&#26435;&#25552;&#39640;&#20102;&#32452;&#30340;&#20998;&#24067;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Ranking &amp; Reweighting Improves Group Distributional Robustness. (arXiv:2305.05759v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05759
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#25240;&#25187;&#32047;&#31215;&#22686;&#30410;&#65288;DCG&#65289;&#25490;&#24207;&#24182;&#21152;&#26435;&#22788;&#29702;&#35757;&#32451;&#25968;&#25454;&#20197;&#25552;&#39640;&#27169;&#22411;&#23545;&#20302;&#20195;&#34920;&#24615;&#32452;&#30340;&#40065;&#26834;&#24615;&#30340;&#26041;&#27861;&#65292;&#23454;&#39564;&#35777;&#26126;&#20854;&#20248;&#20110;&#20808;&#21069;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#36890;&#36807;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;ERM&#65289;&#36827;&#34892;&#26631;&#20934;&#35757;&#32451;&#21487;&#33021;&#20250;&#20135;&#29983;&#22312;&#24179;&#22343;&#31934;&#24230;&#19978;&#34920;&#29616;&#20986;&#33394;&#20294;&#22312;&#20302;&#20195;&#34920;&#24615;&#32452;&#19978;&#20934;&#30830;&#24615;&#36739;&#20302;&#30340;&#27169;&#22411;&#65292;&#36825;&#26159;&#30001;&#20110;&#34920;&#24449;&#20013;&#34394;&#20551;&#29305;&#24449;&#30340;&#26222;&#36941;&#23384;&#22312;&#25152;&#33268;&#12290;&#35299;&#20915;&#36825;&#20010;&#32452;&#40065;&#26834;&#24615;&#38382;&#39064;&#30340;&#20027;&#35201;&#26041;&#27861;&#26159;&#22312;&#35757;&#32451;&#25968;&#25454;&#19978;&#26368;&#23567;&#21270;&#26368;&#22351;&#30340;&#32452;&#35823;&#24046;&#65288;&#31867;&#20284;&#20110;&#26497;&#23567;&#20540;&#31574;&#30053;&#65289;&#65292;&#24076;&#26395;&#23427;&#20250;&#22312;&#27979;&#35797;&#25968;&#25454;&#19978;&#26377;&#33391;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#24448;&#24448;&#26159;&#27425;&#20248;&#30340;&#65292;&#23588;&#20854;&#26159;&#24403;&#27979;&#35797;&#25968;&#25454;&#38598;&#20013;&#21253;&#21547;&#20197;&#21069;&#26410;&#35265;&#36807;&#30340;&#32452;&#26102;&#12290;&#26412;&#25991;&#21463;&#20449;&#24687;&#26816;&#32034;&#21644;Learning-to-Rank&#25991;&#29486;&#30340;&#21551;&#21457;&#65292;&#39318;&#20808;&#25552;&#20986;&#20351;&#29992;&#25240;&#25187;&#32047;&#31215;&#22686;&#30410;&#65288;DCG&#65289;&#20316;&#20026;&#27169;&#22411;&#36136;&#37327;&#24230;&#37327;&#26631;&#20934;&#65292;&#20197;&#20419;&#36827;&#26356;&#22909;&#30340;&#36229;&#21442;&#25968;&#35843;&#25972;&#21644;&#27169;&#22411;&#36873;&#25321;&#12290;&#20316;&#20026;&#19968;&#31181;&#22522;&#20110;&#25490;&#24207;&#30340;&#24230;&#37327;&#26631;&#20934;&#65292;DCG&#21152;&#26435;&#22810;&#20010;&#24615;&#33021;&#36739;&#24046;&#30340;&#32452;&#65288;&#32780;&#19981;&#20165;&#20165;&#26159;&#32771;&#34385;&#24615;&#33021;&#26368;&#24046;&#30340;&#32452;&#65289;&#12290;&#20316;&#20026;&#33258;&#28982;&#30340;&#19979;&#19968;&#27493;&#65292;&#25105;&#20204;&#22522;&#20110;&#36825;&#20123;&#32467;&#26524;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32452;&#37325;&#26032;&#21152;&#26435;&#26041;&#27861;&#65292;&#22312;&#35757;&#32451;&#26399;&#38388;&#40723;&#21169;&#27169;&#22411;&#38598;&#20013;&#20110;&#20302;&#20195;&#34920;&#24615;&#30340;&#32452;&#12290;&#22312;&#20960;&#20010;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#20248;&#20110;&#20808;&#21069;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#65292;&#24182;&#26174;&#33879;&#25552;&#39640;&#20102;&#23545;&#32452;&#19981;&#24179;&#34913;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent work has shown that standard training via empirical risk minimization (ERM) can produce models that achieve high accuracy on average but low accuracy on underrepresented groups due to the prevalence of spurious features. A predominant approach to tackle this group robustness problem minimizes the worst group error (akin to a minimax strategy) on the training data, hoping it will generalize well on the testing data. However, this is often suboptimal, especially when the out-of-distribution (OOD) test data contains previously unseen groups. Inspired by ideas from the information retrieval and learning-to-rank literature, this paper first proposes to use Discounted Cumulative Gain (DCG) as a metric of model quality for facilitating better hyperparameter tuning and model selection. Being a ranking-based metric, DCG weights multiple poorly-performing groups (instead of considering just the group with the worst performance). As a natural next step, we build on our results to propose a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#38598;&#25104;&#20102;&#19977;&#31181;&#22522;&#20110;&#21367;&#31215;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#25391;&#21160;&#20449;&#21495;&#30340;&#25925;&#38556;&#26816;&#27979;&#38382;&#39064;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#20934;&#30830;&#29575;&#19978;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#65292;&#36798;&#21040;&#20102;&#36229;&#36807;98.8\%&#30340;&#20934;&#30830;&#29575;&#12290;</title><link>http://arxiv.org/abs/2305.05532</link><description>&lt;p&gt;
&#22522;&#20110;&#21367;&#31215;&#30340;&#26041;&#27861;&#38598;&#21512;&#29992;&#20110;&#25391;&#21160;&#20449;&#21495;&#30340;&#25925;&#38556;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
An ensemble of convolution-based methods for fault detection using vibration signals. (arXiv:2305.05532v1 [eess.SP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.05532
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#38598;&#25104;&#20102;&#19977;&#31181;&#22522;&#20110;&#21367;&#31215;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#25391;&#21160;&#20449;&#21495;&#30340;&#25925;&#38556;&#26816;&#27979;&#38382;&#39064;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#20934;&#30830;&#29575;&#19978;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#65292;&#36798;&#21040;&#20102;&#36229;&#36807;98.8\%&#30340;&#20934;&#30830;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#27979;&#35797;&#24179;&#21488;&#19978;&#34892;&#26143;&#40831;&#36718;&#31665;&#25391;&#21160;&#20449;&#21495;&#30340;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#35299;&#20915;&#25925;&#38556;&#26816;&#27979;&#38382;&#39064;&#12290;&#23545;&#20110;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#20998;&#31867;&#38382;&#39064;&#65292;&#24120;&#35265;&#30340;&#26426;&#22120;&#23398;&#20064;&#21644;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#21253;&#25324;&#22522;&#20110;&#36317;&#31163;&#12289;&#22522;&#20110;&#21151;&#33021;&#25968;&#25454;&#12289;&#22522;&#20110;&#29305;&#24449;&#21644;&#22522;&#20110;&#21367;&#31215;&#26680;&#30340;&#26041;&#27861;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#20351;&#29992;ROCKET&#12289;ResNet&#21644;FCN&#31561;&#22522;&#20110;&#21367;&#31215;&#26680;&#30340;&#26041;&#27861;&#23545;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20998;&#31867;&#20855;&#26377;&#24378;&#22823;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19977;&#31181;&#22522;&#20110;&#21367;&#31215;&#26680;&#30340;&#26041;&#27861;&#30340;&#38598;&#21512;&#65292;&#24182;&#36890;&#36807;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#24182;&#23454;&#29616;&#36229;&#36807;98.8\%&#20934;&#30830;&#29575;&#30340;&#23454;&#39564;&#32467;&#26524;&#65292;&#35777;&#26126;&#20102;&#20854;&#22312;&#35299;&#20915;&#25925;&#38556;&#26816;&#27979;&#38382;&#39064;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper focuses on solving a fault detection problem using multivariate time series of vibration signals collected from planetary gearboxes in a test rig. Various traditional machine learning and deep learning methods have been proposed for multivariate time-series classification, including distance-based, functional data-oriented, feature-driven, and convolution kernel-based methods. Recent studies have shown using convolution kernel-based methods like ROCKET, and 1D convolutional neural networks with ResNet and FCN, have robust performance for multivariate time-series data classification. We propose an ensemble of three convolution kernel-based methods and show its efficacy on this fault detection problem by outperforming other approaches and achieving an accuracy of more than 98.8\%.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#35777;&#26126;&#20102;&#22312;&#24179;&#31283;&#38543;&#26426;&#20984;&#20248;&#21270;&#20013;&#65292;GD&#21644;SGD&#30340;&#27867;&#21270;&#19979;&#30028;&#21487;&#20197;&#38477;&#20302;&#65292;&#24182;&#19988;&#38271;&#26102;&#38388;&#30340;&#35757;&#32451;&#21487;&#33021;&#23548;&#33268;&#26356;&#24046;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#36825;&#19982;&#20854;&#20182;&#30740;&#31350;&#25104;&#26524;&#19981;&#21516;&#12290;</title><link>http://arxiv.org/abs/2303.10758</link><description>&lt;p&gt;
&#24179;&#31283;&#38543;&#26426;&#20984;&#20248;&#21270;&#20013;GD&#21644;SGD&#30340;&#27867;&#21270;&#19979;&#30028;&#38477;&#20302;
&lt;/p&gt;
&lt;p&gt;
Lower Generalization Bounds for GD and SGD in Smooth Stochastic Convex Optimization. (arXiv:2303.10758v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.10758
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#35777;&#26126;&#20102;&#22312;&#24179;&#31283;&#38543;&#26426;&#20984;&#20248;&#21270;&#20013;&#65292;GD&#21644;SGD&#30340;&#27867;&#21270;&#19979;&#30028;&#21487;&#20197;&#38477;&#20302;&#65292;&#24182;&#19988;&#38271;&#26102;&#38388;&#30340;&#35757;&#32451;&#21487;&#33021;&#23548;&#33268;&#26356;&#24046;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#36825;&#19982;&#20854;&#20182;&#30740;&#31350;&#25104;&#26524;&#19981;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#23398;&#20064;&#29702;&#35770;&#30028;&#22312;&#21051;&#30011;&#19968;&#33324;&#20984;&#25439;&#22833;&#26799;&#24230;&#26041;&#27861;&#30340;&#27867;&#21270;&#35823;&#24046;&#26041;&#38754;&#21462;&#24471;&#20102;&#36827;&#23637;&#12290;&#26412;&#25991;&#20391;&#37325;&#20110;&#35752;&#35770;&#22312;&#27867;&#21270;&#20809;&#28369;&#38543;&#26426;&#20984;&#20248;&#21270;&#65288;SCO&#65289;&#38382;&#39064;&#20013;&#35757;&#32451;&#26102;&#38388;&#22914;&#20309;&#24433;&#21709;&#27867;&#21270;&#33021;&#21147;&#12290;&#25105;&#20204;&#39318;&#20808;&#20026;&#19968;&#33324;&#30340;&#19981;&#21487;&#23454;&#29616;SCO&#38382;&#39064;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#19979;&#30028;&#12290;&#27492;&#22806;&#65292;&#29616;&#26377;&#30340;&#19978;&#30028;&#32467;&#26524;&#34920;&#26126;&#65292;&#20551;&#35774;&#25439;&#22833;&#21487;&#23454;&#29616;&#65288;&#21363;&#26368;&#20248;&#35299;&#21516;&#26102;&#26368;&#23567;&#21270;&#25152;&#26377;&#25968;&#25454;&#28857;&#65289;&#21487;&#20197;&#25552;&#39640;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#20294;&#26159;&#65292;&#24403;&#35757;&#32451;&#26102;&#38388;&#38271;&#19988;&#32570;&#20047;&#19979;&#30028;&#26102;&#65292;&#36825;&#31181;&#25913;&#36827;&#20250;&#21463;&#21040;&#25439;&#23475;&#12290;&#25105;&#20204;&#23545;&#27492;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#25552;&#20379;&#20102;&#23545;&#20110;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#21644;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#22312;&#20004;&#31181;&#21487;&#23454;&#29616;&#24773;&#20917;&#19979;&#30340;&#36807;&#37327;&#39118;&#38505;&#19979;&#30028;&#65306;1&#65289;&#23454;&#29616;&#38656;$T = O(n)$&#65292;&#21644;&#65288;2&#65289;&#23454;&#29616;&#38656;$T = \Omega(n)$&#65292;&#20854;&#20013;$T$&#34920;&#31034;&#35757;&#32451;&#36845;&#20195;&#27425;&#25968;&#65292;$n$&#20026;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#22823;&#23567;&#12290;&#36825;&#20123;&#19979;&#30028;&#30340;&#35777;&#26126;&#20351;&#29992;&#20102;&#26469;&#33258;&#20248;&#21270;&#30340;&#29616;&#20195;&#24037;&#20855;&#65292;&#21253;&#25324;&#23545;&#20598;&#29702;&#35770;&#21644;&#38236;&#20687;&#19979;&#38477;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#21487;&#23454;&#29616;&#30340;SCO&#20013;&#65292;&#26356;&#38271;&#30340;&#35757;&#32451;&#26102;&#38388;&#21487;&#33021;&#20250;&#23548;&#33268;&#26356;&#24046;&#30340;&#27867;&#21270;&#65292;&#36825;&#19982;&#25991;&#29486;&#20013;&#30340;&#20808;&#21069;&#21457;&#29616;&#24418;&#25104;&#40092;&#26126;&#23545;&#27604;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#25903;&#25345;&#25105;&#20204;&#32467;&#26524;&#30340;&#25968;&#20540;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent progress was made in characterizing the generalization error of gradient methods for general convex loss by the learning theory community. In this work, we focus on how training longer might affect generalization in smooth stochastic convex optimization (SCO) problems. We first provide tight lower bounds for general non-realizable SCO problems. Furthermore, existing upper bound results suggest that sample complexity can be improved by assuming the loss is realizable, i.e. an optimal solution simultaneously minimizes all the data points. However, this improvement is compromised when training time is long and lower bounds are lacking. Our paper examines this observation by providing excess risk lower bounds for gradient descent (GD) and stochastic gradient descent (SGD) in two realizable settings: 1) realizable with $T = O(n)$, and (2) realizable with $T = \Omega(n)$, where $T$ denotes the number of training iterations and $n$ is the size of the training dataset. These bounds are 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20869;&#31215;&#20851;&#27880;&#35745;&#31639;&#30340;&#24555;&#36895;&#31639;&#27861;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20004;&#20010;&#32467;&#26524;&#65292;&#35777;&#26126;&#20102;&#22312;B = O(sqrt(log n))&#26102;&#23384;&#22312;&#19968;&#31181;n ^&#65288;1 + O&#65288;1&#65289;&#65289;&#26102;&#38388;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2302.13214</link><description>&lt;p&gt;
&#24555;&#36895;&#27880;&#24847;&#21147;&#38656;&#35201;&#26377;&#30028;&#26465;&#30446;
&lt;/p&gt;
&lt;p&gt;
Fast Attention Requires Bounded Entries. (arXiv:2302.13214v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.13214
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20869;&#31215;&#20851;&#27880;&#35745;&#31639;&#30340;&#24555;&#36895;&#31639;&#27861;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#20004;&#20010;&#32467;&#26524;&#65292;&#35777;&#26126;&#20102;&#22312;B = O(sqrt(log n))&#26102;&#23384;&#22312;&#19968;&#31181;n ^&#65288;1 + O&#65288;1&#65289;&#65289;&#26102;&#38388;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#20869;&#31215;&#20851;&#27880;&#35745;&#31639;&#26159;&#35757;&#32451;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;&#22914;Transformer&#65292;GPT-1&#65292;BERT&#65292;GPT-2&#65292;GPT-3&#21644;ChatGPT&#65289;&#30340;&#22522;&#26412;&#20219;&#21153;&#12290;&#24418;&#24335;&#19978;&#65292;&#22312;&#36825;&#20010;&#38382;&#39064;&#20013;&#65292;&#36755;&#20837;&#19977;&#20010;&#30697;&#38453;$Q&#65292;K&#65292;V \in [-B&#65292;B]^{n \times d}$&#65292;&#30446;&#26631;&#26159;&#26500;&#36896;&#30697;&#38453;$\mathrm{Att}(Q,K,V) := \mathrm{diag}(A {\bf 1}_n)^{-1} A V \in \mathbb{R}^{n \times d}$&#65292;&#20854;&#20013; $A = \exp(QK^\top/d)$ &#26159;&#8220;&#27880;&#24847;&#21147;&#30697;&#38453;&#8221;&#65292;$\exp$&#26159;&#20998;&#37327;&#24212;&#29992;&#12290;&#26412;&#25991;&#30740;&#31350;&#26159;&#21542;&#21487;&#20197;&#36890;&#36807;&#38544;&#24335;&#21033;&#29992;&#30697;&#38453; $A$ &#26469;&#23454;&#29616;&#26356;&#24555;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#20010;&#32467;&#26524;&#65292;&#35777;&#26126;&#20102;&#22312; $B = \Theta(\sqrt{\log n})$&#22788;&#23384;&#22312;&#19968;&#20010;&#23574;&#38160;&#30340;&#36716;&#25442;&#12290;$\bullet$ &#22914;&#26524; $d = O(\log n)$&#65292;$B = o(\sqrt{\log n})$&#65292;&#21017;&#23384;&#22312;&#19968;&#20010;$n^{1+o(1)}$&#26102;&#38388;&#31639;&#27861;&#26469;&#36817;&#20284;$\mathbb{R}^{n \times d}$&#20013;&#30340; $\mathrm{Att}(Q,K,V)$&#12290;
&lt;/p&gt;
&lt;p&gt;
In modern machine learning, inner product attention computation is a fundamental task for training large language models such as Transformer, GPT-1, BERT, GPT-2, GPT-3 and ChatGPT. Formally, in this problem, one is given as input three matrices $Q, K, V \in [-B,B]^{n \times d}$, and the goal is to construct the matrix $\mathrm{Att}(Q,K,V) := \mathrm{diag}(A {\bf 1}_n)^{-1} A V \in \mathbb{R}^{n \times d}$, where $A = \exp(QK^\top/d)$ is the `attention matrix', and $\exp$ is applied entry-wise. Straightforward methods for this problem explicitly compute the $n \times n$ attention matrix $A$, and hence require time $\Omega(n^2)$ even when $d = n^{o(1)}$ is small.  In this paper, we investigate whether faster algorithms are possible by implicitly making use of the matrix $A$. We present two results, showing that there is a sharp transition at $B = \Theta(\sqrt{\log n})$.  $\bullet$ If $d = O(\log n)$ and $B = o(\sqrt{\log n})$, there is an $n^{1+o(1)}$ time algorithm to approximate $\math
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;BPLS&#65292;&#19968;&#31181;&#29992;&#20110;PLS&#30340;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#36890;&#36807;&#35299;&#26512;&#36924;&#36817;&#36873;&#25321;&#26631;&#31614;&#23454;&#20363;&#30340;&#26631;&#20934;&#65292;&#20197;&#36991;&#20813;&#30001;&#36807;&#24230;&#33258;&#20449;&#20294;&#38169;&#35823;&#39044;&#27979;&#30340;&#23454;&#20363;&#36873;&#25321;&#32780;&#23548;&#33268;&#30340;&#30830;&#35748;&#20559;&#24046;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2302.08883</link><description>&lt;p&gt;
&#36817;&#20046;&#36125;&#21494;&#26031;&#26368;&#20248;&#30340;&#20266;&#26631;&#31614;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Approximately Bayes-Optimal Pseudo Label Selection. (arXiv:2302.08883v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.08883
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;BPLS&#65292;&#19968;&#31181;&#29992;&#20110;PLS&#30340;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#36890;&#36807;&#35299;&#26512;&#36924;&#36817;&#36873;&#25321;&#26631;&#31614;&#23454;&#20363;&#30340;&#26631;&#20934;&#65292;&#20197;&#36991;&#20813;&#30001;&#36807;&#24230;&#33258;&#20449;&#20294;&#38169;&#35823;&#39044;&#27979;&#30340;&#23454;&#20363;&#36873;&#25321;&#32780;&#23548;&#33268;&#30340;&#30830;&#35748;&#20559;&#24046;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#35757;&#32451;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#20005;&#37325;&#20381;&#36182;&#20110;&#20266;&#26631;&#31614;&#36873;&#25321;&#65288;PLS&#65289;&#12290;&#36873;&#25321;&#36890;&#24120;&#21462;&#20915;&#20110;&#21021;&#22987;&#27169;&#22411;&#25311;&#21512;&#26631;&#35760;&#25968;&#25454;&#30340;&#31243;&#24230;&#12290;&#36807;&#26089;&#30340;&#36807;&#25311;&#21512;&#21487;&#33021;&#36890;&#36807;&#36873;&#25321;&#20855;&#26377;&#36807;&#24230;&#33258;&#20449;&#20294;&#38169;&#35823;&#30340;&#39044;&#27979;&#30340;&#23454;&#20363;&#65288;&#36890;&#24120;&#31216;&#20026;&#30830;&#35748;&#20559;&#24046;&#65289;&#32780;&#20256;&#25773;&#21040;&#26368;&#32456;&#27169;&#22411;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;BPLS&#65292;&#36825;&#26159;&#19968;&#31181;&#29992;&#20110;PLS&#30340;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#26088;&#22312;&#20943;&#36731;&#36825;&#20010;&#38382;&#39064;&#12290;&#20854;&#26680;&#24515;&#26159;&#36873;&#25321;&#26631;&#31614;&#23454;&#20363;&#30340;&#26631;&#20934;&#65306;&#20266;&#26679;&#26412;&#30340;&#21518;&#39564;&#39044;&#27979;&#30340;&#20998;&#26512;&#36817;&#20284;&#12290;&#25105;&#20204;&#36890;&#36807;&#35777;&#26126;&#20266;&#26679;&#26412;&#30340;&#21518;&#39564;&#39044;&#27979;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#24615;&#33719;&#24471;&#20102;&#36825;&#31181;&#36873;&#25321;&#26631;&#20934;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#36890;&#36807;&#35299;&#26512;&#36924;&#36817;&#20811;&#26381;&#35745;&#31639;&#38590;&#39064;&#12290;&#23427;&#19982;&#36793;&#38469;&#20284;&#28982;&#30340;&#20851;&#31995;&#20351;&#25105;&#20204;&#33021;&#22815;&#25552;&#20986;&#22522;&#20110;&#25289;&#26222;&#25289;&#26031;&#26041;&#27861;&#21644;&#39640;&#26031;&#31215;&#20998;&#30340;&#36924;&#36817;&#12290;&#25105;&#20204;&#38024;&#23545;&#21442;&#25968;&#24191;&#20041;&#32447;&#24615;&#21644;&#38750;&#21442;&#25968;&#24191;&#20041;&#21152;&#24615;&#27169;&#22411;&#23545;BPLS&#36827;&#34892;&#20102;&#23454;&#35777;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
Semi-supervised learning by self-training heavily relies on pseudo-label selection (PLS). The selection often depends on the initial model fit on labeled data. Early overfitting might thus be propagated to the final model by selecting instances with overconfident but erroneous predictions, often referred to as confirmation bias. This paper introduces BPLS, a Bayesian framework for PLS that aims to mitigate this issue. At its core lies a criterion for selecting instances to label: an analytical approximation of the posterior predictive of pseudo-samples. We derive this selection criterion by proving Bayes optimality of the posterior predictive of pseudo-samples. We further overcome computational hurdles by approximating the criterion analytically. Its relation to the marginal likelihood allows us to come up with an approximation based on Laplace's method and the Gaussian integral. We empirically assess BPLS for parametric generalized linear and non-parametric generalized additive models
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;MMD&#20272;&#35745;&#26041;&#27861;&#65292;&#20854;&#26679;&#26412;&#22797;&#26434;&#24230;&#26174;&#30528;&#25552;&#39640;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#35745;&#31639;&#25104;&#26412;&#26114;&#36149;&#12289;&#24179;&#28369;&#30340;&#27169;&#25311;&#22120;&#21644;&#20302;&#32500;&#21040;&#20013;&#32500;&#30340;&#36755;&#20837;&#12290;</title><link>http://arxiv.org/abs/2301.11674</link><description>&lt;p&gt;
&#26080;&#20284;&#28982;&#25512;&#26029;&#30340;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#30340;&#26368;&#20248;&#21152;&#26435;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Optimally-Weighted Estimators of the Maximum Mean Discrepancy for Likelihood-Free Inference. (arXiv:2301.11674v4 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11674
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;MMD&#20272;&#35745;&#26041;&#27861;&#65292;&#20854;&#26679;&#26412;&#22797;&#26434;&#24230;&#26174;&#30528;&#25552;&#39640;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#35745;&#31639;&#25104;&#26412;&#26114;&#36149;&#12289;&#24179;&#28369;&#30340;&#27169;&#25311;&#22120;&#21644;&#20302;&#32500;&#21040;&#20013;&#32500;&#30340;&#36755;&#20837;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#20284;&#28982;&#25512;&#26029;&#26041;&#27861;&#36890;&#24120;&#20351;&#29992;&#27169;&#25311;&#25968;&#25454;&#21644;&#30495;&#23454;&#25968;&#25454;&#20043;&#38388;&#30340;&#36317;&#31163;&#12290;&#20854;&#20013;&#19968;&#31181;&#24120;&#35265;&#26041;&#27861;&#26159;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#65288;MMD&#65289;&#65292;&#20854;&#20808;&#21069;&#24050;&#29992;&#20110;&#36817;&#20284;&#36125;&#21494;&#26031;&#35745;&#31639;&#12289;&#26368;&#23567;&#36317;&#31163;&#20272;&#35745;&#12289;&#24191;&#20041;&#36125;&#21494;&#26031;&#25512;&#26029;&#21644;&#38750;&#21442;&#25968;&#23398;&#20064;&#26694;&#26550;&#20013;&#12290; MMD&#36890;&#24120;&#20197;&#26681;- $m$&#36895;&#29575;&#36827;&#34892;&#20272;&#35745;&#65292;&#20854;&#20013;$ m $&#26159;&#27169;&#25311;&#26679;&#26412;&#25968;&#12290;&#36825;&#21487;&#33021;&#20250;&#23548;&#33268;&#37325;&#22823;&#30340;&#35745;&#31639;&#25361;&#25112;&#65292;&#22240;&#20026;&#38656;&#35201;&#22823;&#37327;&#30340;$ m $&#25165;&#33021;&#33719;&#24471;&#20934;&#30830;&#30340;&#20272;&#35745;&#32467;&#26524;&#65292;&#36825;&#23545;&#20110;&#21442;&#25968;&#20272;&#35745;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;MMD&#20272;&#35745;&#26041;&#27861;&#65292;&#20854;&#26679;&#26412;&#22797;&#26434;&#24230;&#26174;&#30528;&#25552;&#39640;&#12290; &#36825;&#20010;&#20272;&#35745;&#22120;&#29305;&#21035;&#36866;&#29992;&#20110;&#35745;&#31639;&#26114;&#36149;&#65292;&#24179;&#28369;&#30340;&#27169;&#25311;&#22120;&#21644;&#20302;&#32500;&#21040;&#20013;&#32500;&#30340;&#36755;&#20837;&#12290;&#35813;&#35770;&#25991;&#36890;&#36807;&#29702;&#35770;&#32467;&#26524;&#21644;&#23545;&#22522;&#20934;&#27169;&#25311;&#22120;&#30340;&#24191;&#27867;&#27169;&#25311;&#30740;&#31350;&#25903;&#25345;&#35813;&#20027;&#24352;&#12290;
&lt;/p&gt;
&lt;p&gt;
Likelihood-free inference methods typically make use of a distance between simulated and real data. A common example is the maximum mean discrepancy (MMD), which has previously been used for approximate Bayesian computation, minimum distance estimation, generalised Bayesian inference, and within the nonparametric learning framework. The MMD is commonly estimated at a root-$m$ rate, where $m$ is the number of simulated samples. This can lead to significant computational challenges since a large $m$ is required to obtain an accurate estimate, which is crucial for parameter estimation. In this paper, we propose a novel estimator for the MMD with significantly improved sample complexity. The estimator is particularly well suited for computationally expensive smooth simulators with low- to mid-dimensional inputs. This claim is supported through both theoretical results and an extensive simulation study on benchmark simulators.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30830;&#23450;&#24182;&#34920;&#24449;&#20102;&#28145;&#24230;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#29305;&#24449;&#30340;&#26426;&#21046;&#65292;&#25552;&#20986;&#20102;&#28145;&#24230;&#31070;&#32463;&#29305;&#24449;&#20551;&#35774;&#24182;&#35299;&#37322;&#20102;&#28145;&#24230;&#23398;&#20064;&#29616;&#35937;&#65292;&#21516;&#26102;&#20063;&#24341;&#39046;&#20102;&#23545;&#36882;&#24402;&#23398;&#20064;&#29305;&#24449;&#30340;&#26680;&#26041;&#27861;&#20013;&#29305;&#24449;&#23398;&#20064;&#30340;&#26356;&#24191;&#27867;&#30340;&#29702;&#35299;&#12290;</title><link>http://arxiv.org/abs/2212.13881</link><description>&lt;p&gt;
&#28145;&#24230;&#20840;&#36830;&#25509;&#32593;&#32476;&#21644;&#36882;&#24402;&#23398;&#20064;&#29305;&#24449;&#30340;&#26680;&#26426;&#22120;&#30340;&#29305;&#24449;&#23398;&#20064;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
Mechanism of feature learning in deep fully connected networks and kernel machines that recursively learn features. (arXiv:2212.13881v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.13881
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30830;&#23450;&#24182;&#34920;&#24449;&#20102;&#28145;&#24230;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#29305;&#24449;&#30340;&#26426;&#21046;&#65292;&#25552;&#20986;&#20102;&#28145;&#24230;&#31070;&#32463;&#29305;&#24449;&#20551;&#35774;&#24182;&#35299;&#37322;&#20102;&#28145;&#24230;&#23398;&#20064;&#29616;&#35937;&#65292;&#21516;&#26102;&#20063;&#24341;&#39046;&#20102;&#23545;&#36882;&#24402;&#23398;&#20064;&#29305;&#24449;&#30340;&#26680;&#26041;&#27861;&#20013;&#29305;&#24449;&#23398;&#20064;&#30340;&#26356;&#24191;&#27867;&#30340;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#31070;&#32463;&#32593;&#32476;&#22312;&#35768;&#22810;&#25216;&#26415;&#21644;&#31185;&#23398;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#20196;&#20154;&#30633;&#30446;&#30340;&#25104;&#26524;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#27169;&#22411;&#33258;&#21160;&#36873;&#25321;&#29992;&#20110;&#39044;&#27979;&#30340;&#29305;&#24449;&#25110;&#25968;&#25454;&#27169;&#24335;&#30340;&#26426;&#21046;&#20173;&#19981;&#28165;&#26970;&#12290;&#30830;&#23450;&#36825;&#26679;&#30340;&#26426;&#21046;&#26159;&#25512;&#21160;&#31070;&#32463;&#32593;&#32476;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#20197;&#21450;&#20419;&#36827;&#36825;&#20123;&#27169;&#22411;&#22312;&#31185;&#23398;&#24212;&#29992;&#20013;&#21487;&#38752;&#37319;&#29992;&#30340;&#20851;&#38190;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30830;&#23450;&#24182;&#34920;&#24449;&#20102;&#28145;&#24230;&#20840;&#36830;&#25509;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#29305;&#24449;&#30340;&#26426;&#21046;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#28145;&#24230;&#31070;&#32463;&#29305;&#24449;&#20551;&#35774;&#65292;&#35813;&#20551;&#35774;&#34920;&#26126;&#31070;&#32463;&#29305;&#24449;&#23398;&#20064;&#26159;&#36890;&#36807;&#23454;&#29616;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#26469;&#21152;&#24378;&#19982;&#27169;&#22411;&#36755;&#20986;&#23494;&#20999;&#30456;&#20851;&#30340;&#29305;&#24449;&#12290;&#25105;&#20204;&#30340;&#20551;&#35774;&#25581;&#31034;&#20102;&#21508;&#31181;&#28145;&#24230;&#23398;&#20064;&#29616;&#35937;&#65292;&#21253;&#25324;&#20551;&#29305;&#24449;&#30340;&#20986;&#29616;&#21644;&#31616;&#21333;&#24615;&#20559;&#24046;&#20197;&#21450;&#22914;&#20309;&#20462;&#21098;&#32593;&#32476;&#21487;&#20197;&#25552;&#39640;&#24615;&#33021;&#65292;&#12298;&#24425;&#31080;&#20551;&#35774;&#12299;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#24037;&#20316;&#20013;&#30830;&#23450;&#30340;&#26426;&#21046;&#20063;&#24341;&#39046;&#20102;&#23545;&#36882;&#24402;&#23398;&#20064;&#29305;&#24449;&#30340;&#26680;&#26041;&#27861;&#20013;&#29305;&#24449;&#23398;&#20064;&#30340;&#26356;&#24191;&#27867;&#30340;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years neural networks have achieved impressive results on many technological and scientific tasks. Yet, the mechanism through which these models automatically select features, or patterns in data, for prediction remains unclear. Identifying such a mechanism is key to advancing performance and interpretability of neural networks and promoting reliable adoption of these models in scientific applications. In this paper, we identify and characterize the mechanism through which deep fully connected neural networks learn features. We posit the Deep Neural Feature Ansatz, which states that neural feature learning occurs by implementing the average gradient outer product to up-weight features strongly related to model output. Our ansatz sheds light on various deep learning phenomena including emergence of spurious features and simplicity biases and how pruning networks can increase performance, the "lottery ticket hypothesis." Moreover, the mechanism identified in our work leads to a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21452;&#37325;&#40065;&#26834;&#36125;&#21494;&#26031;&#25512;&#26029;&#31243;&#24207;&#65292;&#23454;&#29616;&#20102;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#30340;&#20559;&#24046;&#26657;&#27491;&#24182;&#24418;&#25104;&#20102;&#21487;&#20449;&#21306;&#38388;&#12290;</title><link>http://arxiv.org/abs/2211.16298</link><description>&lt;p&gt;
&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#30340;&#21452;&#37325;&#40065;&#26834;&#36125;&#21494;&#26031;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Double Robust Bayesian Inference on Average Treatment Effects. (arXiv:2211.16298v3 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.16298
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21452;&#37325;&#40065;&#26834;&#36125;&#21494;&#26031;&#25512;&#26029;&#31243;&#24207;&#65292;&#23454;&#29616;&#20102;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#30340;&#20559;&#24046;&#26657;&#27491;&#24182;&#24418;&#25104;&#20102;&#21487;&#20449;&#21306;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#26080;&#20559;&#24615;&#19979;&#30340;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;ATE&#65289;&#30340;&#21452;&#37325;&#40065;&#26834;&#36125;&#21494;&#26031;&#25512;&#26029;&#31243;&#24207;&#12290;&#25105;&#20204;&#30340;&#40065;&#26834;&#36125;&#21494;&#26031;&#26041;&#27861;&#21253;&#25324;&#20004;&#20010;&#35843;&#25972;&#27493;&#39588;&#65306;&#39318;&#20808;&#65292;&#25105;&#20204;&#23545;&#26465;&#20214;&#22343;&#20540;&#20989;&#25968;&#30340;&#20808;&#39564;&#20998;&#24067;&#36827;&#34892;&#26657;&#27491;&#65307;&#20854;&#27425;&#65292;&#25105;&#20204;&#22312;&#20135;&#29983;&#30340;ATE&#30340;&#21518;&#39564;&#20998;&#24067;&#19978;&#24341;&#20837;&#19968;&#20010;&#37325;&#26032;&#23621;&#20013;&#26415;&#35821;&#12290;&#25105;&#20204;&#36890;&#36807;&#24314;&#31435;&#21452;&#37325;&#40065;&#26834;&#24615;&#19979;&#30340;&#21322;&#21442;&#25968;Bernstein-von Mises&#23450;&#29702;&#65292;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#36125;&#21494;&#26031;&#20272;&#35745;&#37327;&#21644;&#21452;&#37325;&#40065;&#26834;&#39057;&#29575;&#20272;&#35745;&#37327;&#30340;&#28176;&#36817;&#31561;&#20215;&#24615;&#65307;&#21363;&#65292;&#26465;&#20214;&#22343;&#20540;&#20989;&#25968;&#30340;&#32570;&#20047;&#24179;&#28369;&#24615;&#21487;&#20197;&#36890;&#36807;&#27010;&#29575;&#24471;&#20998;&#30340;&#39640;&#35268;&#21017;&#24615;&#36827;&#34892;&#34917;&#20607;&#65292;&#21453;&#20043;&#20134;&#28982;&#12290;&#22240;&#27492;&#65292;&#20135;&#29983;&#30340;&#36125;&#21494;&#26031;&#28857;&#20272;&#35745;&#20869;&#22312;&#21270;&#20102;&#39057;&#29575;&#22411;&#21452;&#37325;&#40065;&#26834;&#20272;&#35745;&#37327;&#30340;&#20559;&#24046;&#26657;&#27491;&#65292;&#32780;&#36125;&#21494;&#26031;&#21487;&#20449;&#38598;&#24418;&#25104;&#30340;&#32622;&#20449;&#21306;&#38388;&#20855;&#26377;&#28176;&#36817;&#31934;&#30830;&#30340;&#35206;&#30422;&#27010;&#29575;&#12290;&#22312;&#27169;&#25311;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#36825;&#31181;&#40065;&#26834;&#30340;&#36125;&#21494;&#26031;&#31243;&#24207;&#23548;&#33268;&#20102;&#26174;&#30528;&#30340;...
&lt;/p&gt;
&lt;p&gt;
We study a double robust Bayesian inference procedure on the average treatment effect (ATE) under unconfoundedness. Our robust Bayesian approach involves two adjustment steps: first, we make a correction for prior distributions of the conditional mean function; second, we introduce a recentering term on the posterior distribution of the resulting ATE. We prove asymptotic equivalence of our Bayesian estimator and double robust frequentist estimators by establishing a new semiparametric Bernstein-von Mises theorem under double robustness; i.e., the lack of smoothness of conditional mean functions can be compensated by high regularity of the propensity score and vice versa. Consequently, the resulting Bayesian point estimator internalizes the bias correction as the frequentist-type doubly robust estimator, and the Bayesian credible sets form confidence intervals with asymptotically exact coverage probability. In simulations, we find that this robust Bayesian procedure leads to significant
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24102;&#25215;&#35834;&#21644;&#22122;&#22768;&#35266;&#27979;&#30340;$2\times 2$&#38646;&#21644;&#21338;&#24328;&#65292;&#21457;&#29616;&#24179;&#34913;&#28857;&#24635;&#26159;&#23384;&#22312;&#30340;&#65307;&#39046;&#23548;&#32773;&#30340;&#21160;&#20316;&#35266;&#27979;&#32467;&#26524;&#23545;&#20110;&#36861;&#38543;&#32773;&#26469;&#35828;&#35201;&#20040;&#26159;&#26377;&#30410;&#30340;&#65292;&#35201;&#20040;&#26159;&#26080;&#20851;&#32039;&#35201;&#30340;&#65307;&#35813;&#21338;&#24328;&#30340;&#25910;&#30410;&#22312;&#22343;&#34913;&#28857;&#19978;&#34987;&#19978;&#30028;&#38480;&#21046;&#20026;&#32431;&#31574;&#30053;&#19979;&#30340;SE&#30340;&#25910;&#30410;&#65292;&#19979;&#30028;&#20026;&#28151;&#21512;&#31574;&#30053;&#19979;&#30340;&#32435;&#20160;&#22343;&#34913;&#30340;&#25910;&#30410;&#12290;</title><link>http://arxiv.org/abs/2211.01703</link><description>&lt;p&gt;
&#24102;&#25215;&#35834;&#21644;&#22122;&#22768;&#35266;&#27979;&#30340;$2\times 2$&#38646;&#21644;&#21338;&#24328;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
$2 \times 2$ Zero-Sum Games with Commitments and Noisy Observations. (arXiv:2211.01703v2 [cs.GT] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.01703
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24102;&#25215;&#35834;&#21644;&#22122;&#22768;&#35266;&#27979;&#30340;$2\times 2$&#38646;&#21644;&#21338;&#24328;&#65292;&#21457;&#29616;&#24179;&#34913;&#28857;&#24635;&#26159;&#23384;&#22312;&#30340;&#65307;&#39046;&#23548;&#32773;&#30340;&#21160;&#20316;&#35266;&#27979;&#32467;&#26524;&#23545;&#20110;&#36861;&#38543;&#32773;&#26469;&#35828;&#35201;&#20040;&#26159;&#26377;&#30410;&#30340;&#65292;&#35201;&#20040;&#26159;&#26080;&#20851;&#32039;&#35201;&#30340;&#65307;&#35813;&#21338;&#24328;&#30340;&#25910;&#30410;&#22312;&#22343;&#34913;&#28857;&#19978;&#34987;&#19978;&#30028;&#38480;&#21046;&#20026;&#32431;&#31574;&#30053;&#19979;&#30340;SE&#30340;&#25910;&#30410;&#65292;&#19979;&#30028;&#20026;&#28151;&#21512;&#31574;&#30053;&#19979;&#30340;&#32435;&#20160;&#22343;&#34913;&#30340;&#25910;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20197;&#19979;&#20551;&#35774;&#19979;&#30340;$2\times 2$&#38646;&#21644;&#21338;&#24328;&#65306;$(1)$&#20854;&#20013;&#19968;&#20301;&#29609;&#23478;&#65288;&#39046;&#23548;&#32773;&#65289;&#25215;&#35834;&#36890;&#36807;&#37319;&#26679;&#32473;&#23450;&#30340;&#27010;&#29575;&#20998;&#24067;&#65288;&#31574;&#30053;&#65289;&#26469;&#36873;&#25321;&#20182;&#30340;&#21160;&#20316;;$(2)$&#39046;&#23548;&#32773;&#23459;&#24067;&#20182;&#30340;&#21160;&#20316;&#65292;&#36825;&#20010;&#21160;&#20316;&#36890;&#36807;&#20108;&#36827;&#21046;&#20449;&#36947;&#34987;&#23545;&#25163;&#65288;&#36861;&#38543;&#32773;&#65289;&#35266;&#23519;&#21040;;$(3)$&#36861;&#38543;&#32773;&#22522;&#20110;&#39046;&#23548;&#32773;&#30340;&#31574;&#30053;&#21644;&#39046;&#23548;&#32773;&#21160;&#20316;&#30340;&#22122;&#22768;&#35266;&#27979;&#26469;&#36873;&#25321;&#22905;&#30340;&#31574;&#30053;&#12290;&#22312;&#36825;&#20123;&#26465;&#20214;&#19979;&#65292;&#24179;&#34913;&#28857;&#34987;&#35777;&#26126;&#24635;&#26159;&#23384;&#22312;&#30340;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#21363;&#20351;&#21463;&#21040;&#22122;&#22768;&#30340;&#24433;&#21709;&#65292;&#35266;&#23519;&#39046;&#23548;&#32773;&#30340;&#34892;&#21160;&#23545;&#36861;&#38543;&#32773;&#26469;&#35828;&#23454;&#36136;&#19978;&#35201;&#20040;&#26159;&#26377;&#30410;&#30340;&#65292;&#35201;&#20040;&#26159;&#26080;&#20851;&#32039;&#35201;&#30340;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#22312;&#36825;&#20010;&#21338;&#24328;&#30340;&#22343;&#34913;&#28857;&#19978;&#65292;&#25910;&#30410;&#34987;&#19978;&#30028;&#38480;&#21046;&#20026;&#32431;&#31574;&#30053;&#19979;SE&#30340;&#25910;&#30410;&#65307;&#24182;&#19988;&#19979;&#30028;&#20026;&#32435;&#20160;&#22343;&#34913;&#30340;&#25910;&#30410;&#65292;&#36825;&#31561;&#20215;&#20110;&#28151;&#21512;&#31574;&#30053;&#19979;&#30340;SE&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#24517;&#35201;&#21644;&#20805;&#20998;&#30340;&#26465;&#20214;&#26469;&#35266;&#23519;&#22343;&#34913;&#28857;&#30340;&#25910;&#30410;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, $2\times2$ zero-sum games are studied under the following assumptions: $(1)$ One of the players (the leader) commits to choose its actions by sampling a given probability measure (strategy); $(2)$ The leader announces its action, which is observed by its opponent (the follower) through a binary channel; and $(3)$ the follower chooses its strategy based on the knowledge of the leader's strategy and the noisy observation of the leader's action. Under these conditions, the equilibrium is shown to always exist. Interestingly, even subject to noise, observing the actions of the leader is shown to be either beneficial or immaterial for the follower. More specifically, the payoff at the equilibrium of this game is upper bounded by the payoff at the Stackelberg equilibrium (SE) in pure strategies; and lower bounded by the payoff at the Nash equilibrium, which is equivalent to the SE in mixed strategies.Finally, necessary and sufficient conditions for observing the payoff at equi
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21452;&#26426;&#22120;&#23398;&#20064;&#36235;&#21183;&#27169;&#22411;&#65292;&#33021;&#22815;&#22312;&#25511;&#21046;&#20844;&#27665;&#31185;&#23398;&#25968;&#25454;&#20013;&#30340;&#24180;&#38469;&#28151;&#28102;&#30340;&#21516;&#26102;&#65292;&#20272;&#35745;&#29289;&#31181;&#31181;&#32676;&#36235;&#21183;&#65292;&#20855;&#26377;&#36739;&#39640;&#30340;&#23454;&#29992;&#24615;&#21644;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2210.15524</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#20844;&#27665;&#31185;&#23398;&#25968;&#25454;&#30340;&#21452;&#26426;&#22120;&#23398;&#20064;&#36235;&#21183;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Double Machine Learning Trend Model for Citizen Science Data. (arXiv:2210.15524v2 [q-bio.QM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.15524
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21452;&#26426;&#22120;&#23398;&#20064;&#36235;&#21183;&#27169;&#22411;&#65292;&#33021;&#22815;&#22312;&#25511;&#21046;&#20844;&#27665;&#31185;&#23398;&#25968;&#25454;&#20013;&#30340;&#24180;&#38469;&#28151;&#28102;&#30340;&#21516;&#26102;&#65292;&#20272;&#35745;&#29289;&#31181;&#31181;&#32676;&#36235;&#21183;&#65292;&#20855;&#26377;&#36739;&#39640;&#30340;&#23454;&#29992;&#24615;&#21644;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20844;&#27665;&#21644;&#31038;&#21306;&#31185;&#23398;(CS)&#25968;&#25454;&#38598;&#22240;&#20026;&#27599;&#24180;&#20840;&#29699;&#25910;&#38598;&#30340;&#22823;&#37327;&#25968;&#25454;&#20855;&#26377;&#20272;&#35745;&#31181;&#32676;&#21464;&#21270;&#30340;&#24180;&#38469;&#27169;&#24335;&#30340;&#24040;&#22823;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#20801;&#35768;&#35768;&#22810; CS &#39033;&#30446;&#25910;&#38598;&#22823;&#37327;&#25968;&#25454;&#30340;&#28789;&#27963;&#21327;&#35758;&#36890;&#24120;&#32570;&#20047;&#20445;&#25345;&#19968;&#33268;&#30340;&#37319;&#26679;&#32467;&#26500;&#25152;&#24517;&#38656;&#30340;&#32467;&#26500;&#12290;&#36825;&#23548;&#33268;&#20102;&#24180;&#38469;&#28151;&#28102;&#65292;&#22240;&#20026;&#35266;&#27979;&#36807;&#31243;&#38543;&#26102;&#38388;&#30340;&#25913;&#21464;&#19982;&#29289;&#31181;&#31181;&#32676;&#22823;&#23567;&#30340;&#25913;&#21464;&#28151;&#28102;&#22312;&#19968;&#36215;&#12290;&#36825;&#31687;&#35770;&#25991;&#25551;&#36848;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24314;&#27169;&#26041;&#27861;&#65292;&#26088;&#22312;&#20272;&#35745;&#29289;&#31181;&#31181;&#32676;&#36235;&#21183;&#65292;&#21516;&#26102;&#25511;&#21046;&#20844;&#27665;&#31185;&#23398;&#25968;&#25454;&#20013;&#26222;&#36941;&#23384;&#22312;&#30340;&#24180;&#38469;&#28151;&#28102;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#21452;&#26426;&#22120;&#23398;&#20064;&#65292;&#36825;&#26159;&#19968;&#20010;&#20351;&#29992;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#20272;&#35745;&#31181;&#32676;&#21464;&#21270;&#21644;&#29992;&#20110;&#35843;&#25972;&#25968;&#25454;&#20013;&#21457;&#29616;&#30340;&#28151;&#28102;&#30340;&#20542;&#21521;&#24471;&#20998;&#30340;&#32479;&#35745;&#26694;&#26550;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#27169;&#25311;&#26041;&#27861;&#65292;&#20197;&#35782;&#21035;&#21644;&#35843;&#25972;&#26410;&#33021;&#21457;&#29616;&#30340;&#27531;&#20313;&#28151;&#28102;&#12290;
&lt;/p&gt;
&lt;p&gt;
1. Citizen and community-science (CS) datasets have great potential for estimating interannual patterns of population change given the large volumes of data collected globally every year. Yet, the flexible protocols that enable many CS projects to collect large volumes of data typically lack the structure necessary to keep consistent sampling across years. This leads to interannual confounding, as changes to the observation process over time are confounded with changes in species population sizes.  2. Here we describe a novel modeling approach designed to estimate species population trends while controlling for the interannual confounding common in citizen science data. The approach is based on Double Machine Learning, a statistical framework that uses machine learning methods to estimate population change and the propensity scores used to adjust for confounding discovered in the data. Additionally, we develop a simulation method to identify and adjust for residual confounding missed b
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32463;&#39564;&#36807;&#31243;&#30340;&#32479;&#19968;&#23614;&#37096;&#30028;&#65292;&#35813;&#23614;&#37096;&#30028;&#20197;&#20989;&#25968;&#30340;&#20010;&#20307;&#20559;&#24046;&#32780;&#19981;&#26159;&#22312;&#32771;&#34385;&#30340;&#31867;&#20013;&#30340;&#26368;&#22351;&#24773;&#20917;&#20559;&#24046;&#20026;&#22522;&#30784;&#12290;</title><link>http://arxiv.org/abs/2209.10053</link><description>&lt;p&gt;
&#32463;&#39564;&#36807;&#31243;&#30340;&#23454;&#20363;&#30456;&#20851;&#30340;&#19968;&#33268;&#23614;&#37096;&#30028;
&lt;/p&gt;
&lt;p&gt;
Instance-dependent uniform tail bounds for empirical processes. (arXiv:2209.10053v3 [math.PR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.10053
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32463;&#39564;&#36807;&#31243;&#30340;&#32479;&#19968;&#23614;&#37096;&#30028;&#65292;&#35813;&#23614;&#37096;&#30028;&#20197;&#20989;&#25968;&#30340;&#20010;&#20307;&#20559;&#24046;&#32780;&#19981;&#26159;&#22312;&#32771;&#34385;&#30340;&#31867;&#20013;&#30340;&#26368;&#22351;&#24773;&#20917;&#20559;&#24046;&#20026;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32463;&#39564;&#36807;&#31243;&#30340;&#32479;&#19968;&#23614;&#37096;&#30028;&#65292;&#35813;&#23614;&#37096;&#30028;&#20197;&#20989;&#25968;&#31867;&#20026;&#25351;&#26631;&#65292;&#20197;&#20989;&#25968;&#30340;&#20010;&#20307;&#20559;&#24046;&#32780;&#19981;&#26159;&#22312;&#32771;&#34385;&#30340;&#31867;&#20013;&#30340;&#26368;&#22351;&#24773;&#20917;&#20559;&#24046;&#20026;&#22522;&#30784;&#12290;&#36890;&#36807;&#23558;&#26631;&#20934;&#36890;&#29992;&#38142;&#25509;&#35770;&#35777;&#24341;&#20837;&#19968;&#20010;&#26368;&#21021;&#30340;&#8220;&#27844;&#27668;&#8221;&#27493;&#39588;&#26469;&#24314;&#31435;&#23614;&#37096;&#30028;&#12290;&#29983;&#25104;&#30340;&#23614;&#37096;&#30028;&#26377;&#19968;&#20010;&#20027;&#35201;&#30340;&#22797;&#26434;&#24230;&#32452;&#25104;&#37096;&#20998;&#65292;&#21363;&#19968;&#20010;&#20851;&#20110;&#27844;&#27668;&#20989;&#25968;&#31867;&#30340; Talagrand $\gamma$ &#20989;&#25968;&#30340;&#21464;&#20307;&#65292;&#20197;&#21450;&#19968;&#20010;&#23454;&#20363;&#30456;&#20851;&#30340;&#20559;&#24046;&#39033;&#65292;&#36890;&#36807;&#19968;&#20010;&#36866;&#24403;&#32553;&#25918;&#30340;&#36866;&#24403;&#33539;&#25968;&#30340;&#29256;&#26412;&#26469;&#34913;&#37327;&#12290;&#36825;&#20123;&#39033;&#37117;&#20351;&#29992;&#22522;&#20110;&#30456;&#20851;&#30340;&#27597;&#20989;&#25968;&#30340;&#26576;&#20123;&#31995;&#25968;&#26469;&#34920;&#36798;&#12290;&#24403;&#20989;&#25968;&#31867;&#22312;&#32473;&#23450;&#30340;&#65288;&#25351;&#25968;&#22411;&#65289;Orlicz&#31354;&#38388;&#20013;&#26102;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#26356;&#26126;&#30830;&#30340;&#36817;&#20284;&#20540;&#26469;&#25551;&#36848;&#25152;&#25552;&#21040;&#30340;&#31995;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
We formulate a uniform tail bound for empirical processes indexed by a class of functions, in terms of the individual deviations of the functions rather than the worst-case deviation in the considered class. The tail bound is established by introducing an initial "deflation" step to the standard generic chaining argument. The resulting tail bound has a main complexity component, a variant of Talagrand's $\gamma$ functional for the deflated function class, as well as an instance-dependent deviation term, measured by an appropriately scaled version of a suitable norm. Both of these terms are expressed using certain coefficients formulated based on the relevant cumulant generating functions. We also provide more explicit approximations for the mentioned coefficients, when the function class lies in a given (exponential type) Orlicz space.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35780;&#20272;&#20102;&#29616;&#20195;CNN&#21644;&#35270;&#35273;Transformer&#27169;&#22411;&#22312;&#32452;&#32455;&#30149;&#29702;&#23398;&#20013;&#30340;&#24615;&#33021;&#12289;&#40065;&#26834;&#24615;&#21644;&#20998;&#31867;&#31574;&#30053;&#12290;&#22312;&#20083;&#33146;&#30284;&#12289;&#32963;&#30284;&#21644;&#32467;&#30452;&#32928;&#30284;&#20840;&#20999;&#29255;&#22270;&#20687;&#31561;&#20116;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#24191;&#27867;&#27979;&#35797;&#65292;&#32467;&#26524;&#34920;&#26126;ViT&#27169;&#22411;&#22312;&#20998;&#31867;&#20934;&#30830;&#24615;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;CNN&#65292;&#32780;Swin Transformer&#27169;&#22411;&#22312;&#23545;&#25239;&#26579;&#33394;&#21464;&#21270;&#30340;&#40065;&#26834;&#24615;&#26041;&#38754;&#34920;&#29616;&#26368;&#20339;&#12290;</title><link>http://arxiv.org/abs/2204.05044</link><description>&lt;p&gt;
&#20174;&#29616;&#20195;CNN&#21040;&#35270;&#35273;Transformer&#65306;&#35780;&#20272;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#22312;&#32452;&#32455;&#30149;&#29702;&#23398;&#20013;&#30340;&#24615;&#33021;&#12289;&#40065;&#26834;&#24615;&#21644;&#20998;&#31867;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
From Modern CNNs to Vision Transformers: Assessing the Performance, Robustness, and Classification Strategies of Deep Learning Models in Histopathology. (arXiv:2204.05044v2 [eess.IV] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.05044
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35780;&#20272;&#20102;&#29616;&#20195;CNN&#21644;&#35270;&#35273;Transformer&#27169;&#22411;&#22312;&#32452;&#32455;&#30149;&#29702;&#23398;&#20013;&#30340;&#24615;&#33021;&#12289;&#40065;&#26834;&#24615;&#21644;&#20998;&#31867;&#31574;&#30053;&#12290;&#22312;&#20083;&#33146;&#30284;&#12289;&#32963;&#30284;&#21644;&#32467;&#30452;&#32928;&#30284;&#20840;&#20999;&#29255;&#22270;&#20687;&#31561;&#20116;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#24191;&#27867;&#27979;&#35797;&#65292;&#32467;&#26524;&#34920;&#26126;ViT&#27169;&#22411;&#22312;&#20998;&#31867;&#20934;&#30830;&#24615;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;CNN&#65292;&#32780;Swin Transformer&#27169;&#22411;&#22312;&#23545;&#25239;&#26579;&#33394;&#21464;&#21270;&#30340;&#40065;&#26834;&#24615;&#26041;&#38754;&#34920;&#29616;&#26368;&#20339;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#27491;&#22312;&#25913;&#21464;&#32452;&#32455;&#30149;&#29702;&#23398;&#39046;&#22495;&#65292;&#20294;&#35813;&#39046;&#22495;&#32570;&#20047;&#20840;&#38754;&#35780;&#20272;&#26368;&#26032;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#19981;&#20165;&#35201;&#32771;&#34385;&#31616;&#21333;&#30340;&#20998;&#31867;&#20934;&#30830;&#24615;&#65292;&#36824;&#35201;&#32771;&#34385;&#20854;&#20182;&#36136;&#37327;&#35201;&#27714;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#23545;&#19968;&#31995;&#21015;&#20998;&#31867;&#27169;&#22411;&#36827;&#34892;&#20102;&#24191;&#27867;&#35780;&#20272;&#65292;&#21253;&#25324;&#26368;&#26032;&#30340;&#35270;&#35273;Transformer&#21644;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65292;&#22914;ConvNeXt&#12289;ResNet&#65288;BiT&#65289;&#12289;Inception&#12289;ViT&#21644;Swin Transformer&#65292;&#24182;&#22312;&#26377;&#30417;&#30563;&#25110;&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#20102;&#27979;&#35797;&#12290;&#25105;&#20204;&#23545;&#21253;&#21547;&#20083;&#33146;&#30284;&#12289;&#32963;&#30284;&#21644;&#32467;&#30452;&#32928;&#30284;&#20840;&#20999;&#29255;&#22270;&#20687;&#30340;&#20116;&#20010;&#24191;&#27867;&#20351;&#29992;&#30340;&#32452;&#32455;&#30149;&#29702;&#23398;&#25968;&#25454;&#38598;&#36827;&#34892;&#20102;&#20840;&#38754;&#27979;&#35797;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#20351;&#29992;&#22270;&#20687;&#36716;&#25442;&#27169;&#22411;&#26469;&#35780;&#20272;&#30284;&#30151;&#20998;&#31867;&#27169;&#22411;&#23545;&#26579;&#33394;&#21464;&#21270;&#30340;&#40065;&#26834;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;&#29616;&#26377;&#30340;&#21487;&#35299;&#37322;&#24615;&#26041;&#27861;&#65292;&#31995;&#32479;&#22320;&#25581;&#31034;&#20102;&#23427;&#20204;&#23398;&#21040;&#30340;&#29305;&#24449;&#12290;&#25105;&#20204;&#30340;&#35780;&#20272;&#34920;&#26126;&#65292;ViT&#27169;&#22411;&#22312;&#20998;&#31867;&#20934;&#30830;&#24615;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;CNN&#65292;&#32780;Swin Transformer&#27169;&#22411;&#22312;&#23545;&#25239;&#26579;&#33394;&#21464;&#21270;&#30340;&#40065;&#26834;&#24615;&#26041;&#38754;&#34920;&#29616;&#26368;&#20339;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#39044;&#35757;&#32451;&#21487;&#20197;&#25552;&#39640;&#22823;&#22810;&#25968;&#27169;&#22411;&#30340;&#20998;&#31867;&#24615;&#33021;&#21644;&#40065;&#26834;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#25581;&#31034;&#20102;&#36825;&#20123;&#27169;&#22411;&#23398;&#21040;&#30340;&#29305;&#24449;&#65292;&#21253;&#25324;&#31354;&#38388;&#39057;&#29575;&#20449;&#24687;&#21644;&#32959;&#30244;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
While machine learning is currently transforming the field of histopathology, the domain lacks a comprehensive evaluation of state-of-the-art models based on essential but complementary quality requirements beyond a mere classification accuracy. In order to fill this gap, we developed a new methodology to extensively evaluate a wide range of classification models, including recent vision transformers, and convolutional neural networks such as: ConvNeXt, ResNet (BiT), Inception, ViT and Swin transformer, with and without supervised or self-supervised pretraining. We thoroughly tested the models on five widely used histopathology datasets containing whole slide images of breast, gastric, and colorectal cancer and developed a novel approach using an image-to-image translation model to assess the robustness of a cancer classification model against stain variations. Further, we extended existing interpretability methods to previously unstudied models and systematically reveal insights of th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Wasserstein&#36317;&#31163;&#38480;&#21046;&#30340;&#26356;&#22909;&#30340;&#23041;&#32961;&#27169;&#22411;&#65292;&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#38480;&#21046;&#22270;&#20687;&#25200;&#21160;&#12290;&#20316;&#32773;&#25351;&#20986;&#24182;&#32416;&#27491;&#20102;&#20808;&#21069;Wasserstein&#23041;&#32961;&#27169;&#22411;&#23450;&#20041;&#20013;&#30340;&#32570;&#38519;&#65292;&#24182;&#23637;&#31034;&#20102;&#26356;&#24378;&#30340;&#25915;&#20987;&#21644;&#38450;&#24481;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;Wasserstein-&#40065;&#26834;&#27169;&#22411;&#22312;&#38450;&#24481;&#29616;&#23454;&#19990;&#30028;&#20013;&#20986;&#29616;&#30340;&#25200;&#21160;&#26041;&#38754;&#21487;&#33021;&#21463;&#21040;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2004.12478</link><description>&lt;p&gt;
&#25552;&#39640;&#22270;&#20687;Wasserstein&#25915;&#20987;&#21644;&#38450;&#24481;&#30340;&#25928;&#26524;
&lt;/p&gt;
&lt;p&gt;
Improved Image Wasserstein Attacks and Defenses. (arXiv:2004.12478v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2004.12478
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Wasserstein&#36317;&#31163;&#38480;&#21046;&#30340;&#26356;&#22909;&#30340;&#23041;&#32961;&#27169;&#22411;&#65292;&#21487;&#20197;&#26356;&#20934;&#30830;&#22320;&#38480;&#21046;&#22270;&#20687;&#25200;&#21160;&#12290;&#20316;&#32773;&#25351;&#20986;&#24182;&#32416;&#27491;&#20102;&#20808;&#21069;Wasserstein&#23041;&#32961;&#27169;&#22411;&#23450;&#20041;&#20013;&#30340;&#32570;&#38519;&#65292;&#24182;&#23637;&#31034;&#20102;&#26356;&#24378;&#30340;&#25915;&#20987;&#21644;&#38450;&#24481;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;Wasserstein-&#40065;&#26834;&#27169;&#22411;&#22312;&#38450;&#24481;&#29616;&#23454;&#19990;&#30028;&#20013;&#20986;&#29616;&#30340;&#25200;&#21160;&#26041;&#38754;&#21487;&#33021;&#21463;&#21040;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#26399;&#25991;&#29486;&#20013;&#24050;&#32463;&#24191;&#27867;&#30740;&#31350;&#20102;&#23545;&#20110;$\ell_p$&#38480;&#21046;&#19979;&#21463;&#21040;&#22270;&#20687;&#25200;&#21160;&#30340;&#40065;&#26834;&#24615;&#12290;&#20294;&#26159;&#65292;&#29616;&#23454;&#20013;&#30340;&#25200;&#21160;&#24456;&#23569;&#34920;&#29616;&#20986;$\ell_p$&#23041;&#32961;&#27169;&#22411;&#25152;&#20551;&#23450;&#30340;&#20687;&#32032;&#29420;&#31435;&#24615;&#12290;&#26368;&#36817;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;Wasserstein&#36317;&#31163;&#38480;&#21046;&#30340;&#23041;&#32961;&#27169;&#22411;&#65292;&#23427;&#38480;&#21046;&#25200;&#21160;&#20026;&#20687;&#32032;&#36136;&#37327;&#31227;&#21160;&#12290;&#25105;&#20204;&#25351;&#20986;&#24182;&#32416;&#27491;&#20102;&#20808;&#21069;Wasserstein&#23041;&#32961;&#27169;&#22411;&#23450;&#20041;&#20013;&#30340;&#32570;&#38519;&#65292;&#24182;&#22312;&#25105;&#20204;&#26356;&#22909;&#22320;&#23450;&#20041;&#30340;&#26694;&#26550;&#19979;&#25506;&#32034;&#20102;&#26356;&#24378;&#30340;&#25915;&#20987;&#21644;&#38450;&#24481;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#24403;&#21069;Wasserstein-&#40065;&#26834;&#27169;&#22411;&#22312;&#38450;&#24481;&#29616;&#23454;&#19990;&#30028;&#20013;&#20986;&#29616;&#30340;&#25200;&#21160;&#26041;&#38754;&#30340;&#26080;&#33021;&#20026;&#21147;&#12290;&#25105;&#20204;&#30340;&#20195;&#30721;&#21644;&#35757;&#32451;&#27169;&#22411;&#21487;&#22312;https://github.com/edwardjhu/improved_wasserstein&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
Robustness against image perturbations bounded by a $\ell_p$ ball have been well-studied in recent literature. Perturbations in the real-world, however, rarely exhibit the pixel independence that $\ell_p$ threat models assume. A recently proposed Wasserstein distance-bounded threat model is a promising alternative that limits the perturbation to pixel mass movements. We point out and rectify flaws in previous definition of the Wasserstein threat model and explore stronger attacks and defenses under our better-defined framework. Lastly, we discuss the inability of current Wasserstein-robust models in defending against perturbations seen in the real world. Our code and trained models are available at https://github.com/edwardjhu/improved_wasserstein .
&lt;/p&gt;</description></item></channel></rss>