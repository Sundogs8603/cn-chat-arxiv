<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#39640;&#26031;&#25968;&#25454;&#24211;&#23545;&#40784;&#21644;&#39640;&#26031;&#26893;&#20837;&#21305;&#37197;&#38382;&#39064;&#20855;&#26377;&#23494;&#20999;&#32852;&#31995;&#65292;&#24403;&#25968;&#25454;&#24211;&#29305;&#24449;&#30340;&#32500;&#24230;&#36739;&#39640;&#19988;&#27809;&#26377;&#36807;&#24378;&#30340;&#29305;&#24449;&#26102;&#65292;&#25968;&#25454;&#24211;&#23545;&#40784;&#30340;&#24615;&#33021;&#38408;&#20540;&#25910;&#25947;&#21040;&#26893;&#20837;&#21305;&#37197;&#30340;&#24615;&#33021;&#38408;&#20540;&#12290;</title><link>http://arxiv.org/abs/2307.02459</link><description>&lt;p&gt;
&#39640;&#26031;&#25968;&#25454;&#24211;&#23545;&#40784;&#21644;&#39640;&#26031;&#26893;&#20837;&#21305;&#37197;
&lt;/p&gt;
&lt;p&gt;
Gaussian Database Alignment and Gaussian Planted Matching. (arXiv:2307.02459v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02459
&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#25968;&#25454;&#24211;&#23545;&#40784;&#21644;&#39640;&#26031;&#26893;&#20837;&#21305;&#37197;&#38382;&#39064;&#20855;&#26377;&#23494;&#20999;&#32852;&#31995;&#65292;&#24403;&#25968;&#25454;&#24211;&#29305;&#24449;&#30340;&#32500;&#24230;&#36739;&#39640;&#19988;&#27809;&#26377;&#36807;&#24378;&#30340;&#29305;&#24449;&#26102;&#65292;&#25968;&#25454;&#24211;&#23545;&#40784;&#30340;&#24615;&#33021;&#38408;&#20540;&#25910;&#25947;&#21040;&#26893;&#20837;&#21305;&#37197;&#30340;&#24615;&#33021;&#38408;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#24211;&#23545;&#40784;&#26159;&#22270;&#23545;&#40784;&#38382;&#39064;&#30340;&#19968;&#31181;&#21464;&#20307;&#65306;&#32473;&#23450;&#19968;&#23545;&#21253;&#21547;&#29420;&#31435;&#20294;&#30456;&#20851;&#29305;&#24449;&#30340;&#21311;&#21517;&#25968;&#25454;&#24211;&#65292;&#38382;&#39064;&#26159;&#20165;&#26681;&#25454;&#30456;&#20851;&#24615;&#35782;&#21035;&#29305;&#24449;&#20043;&#38388;&#30340;&#23545;&#24212;&#20851;&#31995;&#65292;&#24182;&#23545;&#40784;&#21311;&#21517;&#29992;&#25143;&#38598;&#12290;&#36825;&#19982;&#26893;&#20837;&#21305;&#37197;&#23494;&#20999;&#30456;&#20851;&#65292;&#20854;&#20013;&#32473;&#23450;&#19968;&#20010;&#24102;&#26377;&#38543;&#26426;&#26435;&#37325;&#30340;&#20108;&#20998;&#22270;&#65292;&#30446;&#26631;&#26159;&#35782;&#21035;&#29983;&#25104;&#32473;&#23450;&#26435;&#37325;&#30340;&#28508;&#22312;&#21305;&#37197;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#20855;&#26377;&#22810;&#21464;&#37327;&#39640;&#26031;&#29305;&#24449;&#30340;&#25968;&#25454;&#24211;&#23545;&#40784;&#38382;&#39064;&#23454;&#20363;&#65292;&#24182;&#25512;&#23548;&#20986;&#36866;&#29992;&#20110;&#25968;&#25454;&#24211;&#23545;&#40784;&#21644;&#26893;&#20837;&#21305;&#37197;&#30340;&#32467;&#26524;&#65292;&#23637;&#31034;&#20102;&#23427;&#20204;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;&#24403;&#25968;&#25454;&#24211;&#29305;&#24449;&#30340;&#32500;&#24230;&#26159;\(\omega(\log n)\)&#65288;&#20854;&#20013;\(n\)&#26159;&#23545;&#40784;&#30340;&#22823;&#23567;&#65289;&#26102;&#65292;&#25968;&#25454;&#24211;&#23545;&#40784;&#30340;&#24615;&#33021;&#38408;&#20540;&#20250;&#25910;&#25947;&#21040;&#26893;&#20837;&#21305;&#37197;&#30340;&#24615;&#33021;&#38408;&#20540;&#65292;&#24182;&#19988;&#27809;&#26377;&#20010;&#21035;&#29305;&#24449;&#36807;&#24378;&#12290;&#23545;&#20110;&#26893;&#20837;&#21305;&#37197;&#21644;&#25968;&#25454;&#24211;&#23545;&#40784;&#26469;&#35828;&#65292;&#26368;&#22823;&#20284;&#28982;&#31639;&#27861;&#37117;&#36866;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Database alignment is a variant of the graph alignment problem: Given a pair of anonymized databases containing separate yet correlated features for a set of users, the problem is to identify the correspondence between the features and align the anonymized user sets based on correlation alone. This closely relates to planted matching, where given a bigraph with random weights, the goal is to identify the underlying matching that generated the given weights. We study an instance of the database alignment problem with multivariate Gaussian features and derive results that apply both for database alignment and for planted matching, demonstrating the connection between them. The performance thresholds for database alignment converge to that for planted matching when the dimensionality of the database features is \(\omega(\log n)\), where \(n\) is the size of the alignment, and no individual feature is too strong. The maximum likelihood algorithms for both planted matching and database alig
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27010;&#29575;&#21644;&#25968;&#25454;&#39537;&#21160;&#30340;&#38381;&#21512;&#27169;&#22411;&#65292;&#29992;&#20110;RANS&#27169;&#25311;&#20013;&#32771;&#34385;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#35813;&#27169;&#22411;&#21253;&#25324;&#21442;&#25968;&#21270;&#37096;&#20998;&#21644;&#38543;&#26426;&#21464;&#37327;&#37096;&#20998;&#65292;&#24182;&#36890;&#36807;&#36125;&#21494;&#26031;&#20844;&#24335;&#21644;&#31232;&#30095;&#20808;&#39564;&#26469;&#35782;&#21035;&#27169;&#22411;&#19981;&#36275;&#30340;&#21306;&#22495;&#65292;&#20197;&#36827;&#34892;&#20462;&#27491;&#12290;&#35757;&#32451;&#20351;&#29992;&#38388;&#25509;&#31232;&#30095;&#25968;&#25454;&#65292;&#25512;&#26029;&#21644;&#23398;&#20064;&#20351;&#29992;&#38543;&#26426;&#21464;&#20998;&#25512;&#26029;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2307.02432</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#27010;&#29575;&#21644;&#25968;&#25454;&#39537;&#21160;&#30340;RANS&#27169;&#25311;&#30340;&#38381;&#21512;&#27169;&#22411;&#65292;&#32771;&#34385;&#21040;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
A probabilistic, data-driven closure model for RANS simulations with aleatoric, model uncertainty. (arXiv:2307.02432v1 [physics.flu-dyn])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02432
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27010;&#29575;&#21644;&#25968;&#25454;&#39537;&#21160;&#30340;&#38381;&#21512;&#27169;&#22411;&#65292;&#29992;&#20110;RANS&#27169;&#25311;&#20013;&#32771;&#34385;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#35813;&#27169;&#22411;&#21253;&#25324;&#21442;&#25968;&#21270;&#37096;&#20998;&#21644;&#38543;&#26426;&#21464;&#37327;&#37096;&#20998;&#65292;&#24182;&#36890;&#36807;&#36125;&#21494;&#26031;&#20844;&#24335;&#21644;&#31232;&#30095;&#20808;&#39564;&#26469;&#35782;&#21035;&#27169;&#22411;&#19981;&#36275;&#30340;&#21306;&#22495;&#65292;&#20197;&#36827;&#34892;&#20462;&#27491;&#12290;&#35757;&#32451;&#20351;&#29992;&#38388;&#25509;&#31232;&#30095;&#25968;&#25454;&#65292;&#25512;&#26029;&#21644;&#23398;&#20064;&#20351;&#29992;&#38543;&#26426;&#21464;&#20998;&#25512;&#26029;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27010;&#29575;&#21644;&#25968;&#25454;&#39537;&#21160;&#30340;&#38381;&#21512;&#27169;&#22411;&#65292;&#29992;&#20110;Reynolds&#24179;&#22343;Navier-Stokes (RANS)&#27169;&#25311;&#20013;&#32771;&#34385;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#35813;&#38381;&#21512;&#27169;&#22411;&#21253;&#25324;&#20004;&#37096;&#20998;&#12290;&#31532;&#19968;&#37096;&#20998;&#26159;&#21442;&#25968;&#21270;&#30340;&#65292;&#21033;&#29992;&#20102;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#24352;&#37327;&#22522;&#20989;&#25968;&#65292;&#36825;&#20123;&#20989;&#25968;&#20381;&#36182;&#20110;&#24212;&#21464;&#29575;&#21644;&#26059;&#36716;&#24352;&#37327;&#30340;&#19981;&#21464;&#37327;&#12290;&#31532;&#20108;&#37096;&#20998;&#21017;&#26159;&#38543;&#26426;&#21464;&#37327;&#65292;&#29992;&#20110;&#32771;&#34385;&#27169;&#22411;&#35823;&#24046;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23436;&#20840;&#36125;&#21494;&#26031;&#30340;&#20844;&#24335;&#65292;&#24182;&#32467;&#21512;&#20102;&#19968;&#31181;&#31232;&#30095;&#20808;&#39564;&#65292;&#20197;&#35782;&#21035;&#38382;&#39064;&#39046;&#22495;&#20013;&#21442;&#25968;&#21270;&#38381;&#21512;&#27169;&#22411;&#19981;&#36275;&#30340;&#22320;&#26041;&#65292;&#36827;&#32780;&#38656;&#35201;&#23545;&#38647;&#35834;&#24212;&#21147;&#24352;&#37327;&#36827;&#34892;&#38543;&#26426;&#20462;&#27491;&#12290;&#35757;&#32451;&#20351;&#29992;&#38388;&#25509;&#31232;&#30095;&#25968;&#25454;&#65292;&#22914;&#24179;&#22343;&#36895;&#24230;&#21644;&#21387;&#21147;&#65292;&#32780;&#19981;&#38656;&#35201;&#30452;&#25509;&#30340;&#38647;&#35834;&#24212;&#21147;&#25968;&#25454;&#65292;&#19982;&#22823;&#22810;&#25968;&#20854;&#20182;&#26041;&#27861;&#19981;&#21516;&#12290;&#20026;&#20102;&#25512;&#26029;&#21644;&#23398;&#20064;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#19968;&#31181;&#22522;&#20110;&#33945;&#29305;&#21345;&#27931;&#20272;&#35745;&#30340;&#38543;&#26426;&#21464;&#20998;&#25512;&#26029;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a data-driven, closure model for Reynolds-averaged Navier-Stokes (RANS) simulations that incorporates aleatoric, model uncertainty. The proposed closure consists of two parts. A parametric one, which utilizes previously proposed, neural-network-based tensor basis functions dependent on the rate of strain and rotation tensor invariants. This is complemented by latent, random variables which account for aleatoric model errors. A fully Bayesian formulation is proposed, combined with a sparsity-inducing prior in order to identify regions in the problem domain where the parametric closure is insufficient and where stochastic corrections to the Reynolds stress tensor are needed. Training is performed using sparse, indirect data, such as mean velocities and pressures, in contrast to the majority of alternatives that require direct Reynolds stress data. For inference and learning, a Stochastic Variational Inference scheme is employed, which is based on Monte Carlo estimates of the p
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#27719;&#24635;&#32479;&#35745;&#25968;&#25454;&#30340;&#28789;&#27963;&#22810;&#20219;&#21153;&#23398;&#20064;&#26694;&#26550;&#65292;&#21487;&#35299;&#20915;&#22312;&#30495;&#23454;&#19990;&#30028;&#35774;&#32622;&#20013;&#25968;&#25454;&#20849;&#20139;&#38480;&#21046;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#33258;&#36866;&#24212;&#21442;&#25968;&#36873;&#25321;&#26041;&#27861;&#21644;&#31995;&#32479;&#38750;&#28176;&#36817;&#20998;&#26512;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#24615;&#33021;&#12290;&#36890;&#36807;&#22823;&#37327;&#27169;&#25311;&#23454;&#39564;&#35777;&#26126;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.02388</link><description>&lt;p&gt;
&#20351;&#29992;&#27719;&#24635;&#32479;&#35745;&#25968;&#25454;&#30340;&#22810;&#20219;&#21153;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Multi-Task Learning with Summary Statistics. (arXiv:2307.02388v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02388
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#27719;&#24635;&#32479;&#35745;&#25968;&#25454;&#30340;&#28789;&#27963;&#22810;&#20219;&#21153;&#23398;&#20064;&#26694;&#26550;&#65292;&#21487;&#35299;&#20915;&#22312;&#30495;&#23454;&#19990;&#30028;&#35774;&#32622;&#20013;&#25968;&#25454;&#20849;&#20139;&#38480;&#21046;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#33258;&#36866;&#24212;&#21442;&#25968;&#36873;&#25321;&#26041;&#27861;&#21644;&#31995;&#32479;&#38750;&#28176;&#36817;&#20998;&#26512;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#24615;&#33021;&#12290;&#36890;&#36807;&#22823;&#37327;&#27169;&#25311;&#23454;&#39564;&#35777;&#26126;&#20102;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20219;&#21153;&#23398;&#20064;&#24050;&#32463;&#25104;&#20026;&#19968;&#20010;&#24378;&#22823;&#30340;&#26426;&#22120;&#23398;&#20064;&#33539;&#24335;&#65292;&#21487;&#20197;&#25972;&#21512;&#26469;&#33258;&#22810;&#20010;&#26469;&#28304;&#30340;&#25968;&#25454;&#65292;&#21033;&#29992;&#20219;&#21153;&#20043;&#38388;&#30340;&#30456;&#20284;&#24615;&#25552;&#39640;&#25972;&#20307;&#27169;&#22411;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#35774;&#32622;&#20013;&#65292;&#22810;&#20219;&#21153;&#23398;&#20064;&#30340;&#24212;&#29992;&#21463;&#21040;&#25968;&#25454;&#20849;&#20139;&#38480;&#21046;&#30340;&#24433;&#21709;&#65292;&#29305;&#21035;&#26159;&#22312;&#21307;&#30103;&#39046;&#22495;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#28789;&#27963;&#30340;&#22810;&#20219;&#21153;&#23398;&#20064;&#26694;&#26550;&#65292;&#21033;&#29992;&#26469;&#33258;&#21508;&#31181;&#26469;&#28304;&#30340;&#27719;&#24635;&#32479;&#35745;&#25968;&#25454;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#21442;&#25968;&#36873;&#25321;&#26041;&#27861;&#65292;&#22522;&#20110;Lepski&#26041;&#27861;&#30340;&#19968;&#31181;&#21464;&#20307;&#65292;&#22312;&#20165;&#26377;&#27719;&#24635;&#32479;&#35745;&#25968;&#25454;&#26102;&#20801;&#35768;&#25968;&#25454;&#39537;&#21160;&#30340;&#35843;&#21442;&#36873;&#25321;&#12290;&#25105;&#20204;&#30340;&#31995;&#32479;&#38750;&#28176;&#36817;&#20998;&#26512;&#25551;&#36848;&#20102;&#25152;&#25552;&#26041;&#27861;&#22312;&#26679;&#26412;&#22797;&#26434;&#24230;&#21644;&#37325;&#21472;&#24230;&#30340;&#21508;&#31181;&#24773;&#20917;&#19979;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#36890;&#36807;&#22823;&#37327;&#27169;&#25311;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#21457;&#29616;&#21644;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;&#36825;&#39033;&#24037;&#20316;&#20026;&#36328;&#20998;&#26512;&#32437;&#21521;&#25968;&#25454;&#25552;&#20379;&#20102;&#19968;&#31181;&#26356;&#28789;&#27963;&#30340;&#35757;&#32451;&#30456;&#20851;&#27169;&#22411;&#30340;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multi-task learning has emerged as a powerful machine learning paradigm for integrating data from multiple sources, leveraging similarities between tasks to improve overall model performance. However, the application of multi-task learning to real-world settings is hindered by data-sharing constraints, especially in healthcare settings. To address this challenge, we propose a flexible multi-task learning framework utilizing summary statistics from various sources. Additionally, we present an adaptive parameter selection approach based on a variant of Lepski's method, allowing for data-driven tuning parameter selection when only summary statistics are available. Our systematic non-asymptotic analysis characterizes the performance of the proposed methods under various regimes of the sample complexity and overlap. We demonstrate our theoretical findings and the performance of the method through extensive simulations. This work offers a more flexible tool for training related models across
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20174;&#25968;&#25454;&#20113;&#20013;&#26500;&#24314;&#30340;&#38543;&#26426;&#20960;&#20309;&#22270;&#19982;&#27969;&#24418;&#20043;&#38388;&#30340;&#26354;&#29575;&#20851;&#31995;&#65292;&#24182;&#36890;&#36807;&#27010;&#29575;&#20998;&#26512;&#35777;&#26126;&#20102;&#28857;&#24577;&#19968;&#33268;&#24615;&#20197;&#21450;&#20840;&#23616;&#32467;&#26500;&#29305;&#24615;&#20256;&#25215;&#12290;&#30740;&#31350;&#32467;&#26524;&#23545;&#22270;&#19978;&#28909;&#26680;&#30340;&#25910;&#25947;&#24615;&#21644;&#20174;&#25968;&#25454;&#20113;&#20013;&#23398;&#20064;&#27969;&#24418;&#20855;&#26377;&#37325;&#35201;&#30340;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2307.02378</link><description>&lt;p&gt;
&#22312;&#25968;&#25454;&#20113;&#20013;Ollivier&#30340;Ricci&#26354;&#29575;&#30340;&#36830;&#32493;&#26497;&#38480;&#65306;&#28857;&#24577;&#19968;&#33268;&#24615;&#21644;&#20840;&#23616;&#19979;&#30028;
&lt;/p&gt;
&lt;p&gt;
Continuum Limits of Ollivier's Ricci Curvature on data clouds: pointwise consistency and global lower bounds. (arXiv:2307.02378v1 [math.DG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02378
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20174;&#25968;&#25454;&#20113;&#20013;&#26500;&#24314;&#30340;&#38543;&#26426;&#20960;&#20309;&#22270;&#19982;&#27969;&#24418;&#20043;&#38388;&#30340;&#26354;&#29575;&#20851;&#31995;&#65292;&#24182;&#36890;&#36807;&#27010;&#29575;&#20998;&#26512;&#35777;&#26126;&#20102;&#28857;&#24577;&#19968;&#33268;&#24615;&#20197;&#21450;&#20840;&#23616;&#32467;&#26500;&#29305;&#24615;&#20256;&#25215;&#12290;&#30740;&#31350;&#32467;&#26524;&#23545;&#22270;&#19978;&#28909;&#26680;&#30340;&#25910;&#25947;&#24615;&#21644;&#20174;&#25968;&#25454;&#20113;&#20013;&#23398;&#20064;&#27969;&#24418;&#20855;&#26377;&#37325;&#35201;&#30340;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35753;$\mathcal{M} \subseteq \mathbb{R}^d$&#34920;&#31034;&#19968;&#20010;&#20302;&#32500;&#27969;&#24418;&#65292;$\mathcal{X}= \{ x_1, \dots, x_n \}$&#34920;&#31034;&#20174;$\mathcal{M}$&#22343;&#21248;&#37319;&#26679;&#24471;&#21040;&#30340;&#19968;&#32452;&#28857;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#20174;$\mathcal{X}$&#26500;&#24314;&#30340;&#38543;&#26426;&#20960;&#20309;&#22270;&#19982;&#27969;&#24418;$\mathcal{M}$&#30340;&#26354;&#29575;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#36890;&#36807;Ollivier&#30340;&#31163;&#25955;Ricci&#26354;&#29575;&#30340;&#36830;&#32493;&#26497;&#38480;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#28857;&#24577;&#12289;&#38750;&#28176;&#36817;&#19968;&#33268;&#24615;&#32467;&#26524;&#65292;&#24182;&#19988;&#36824;&#34920;&#26126;&#65292;&#22914;&#26524;$\mathcal{M}$&#30340;Ricci&#26354;&#29575;&#20174;&#19979;&#38754;&#20005;&#26684;&#22320;&#34987;&#19968;&#20010;&#27491;&#24120;&#25968;&#30028;&#20303;&#65292;&#37027;&#20040;&#38543;&#26426;&#20960;&#20309;&#22270;&#23558;&#20197;&#39640;&#27010;&#29575;&#32487;&#25215;&#27492;&#20840;&#23616;&#32467;&#26500;&#29305;&#24615;&#12290;&#25105;&#20204;&#35752;&#35770;&#20840;&#23616;&#31163;&#25955;&#26354;&#29575;&#30028;&#38480;&#22312;&#22270;&#19978;&#28909;&#26680;&#30340;&#25910;&#25947;&#24615;&#36136;&#20197;&#21450;&#23545;&#25968;&#25454;&#20113;&#19978;&#27969;&#24418;&#23398;&#20064;&#30340;&#24433;&#21709;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#33268;&#24615;&#32467;&#26524;&#20801;&#35768;&#36890;&#36807;&#22806;&#31104;&#26354;&#29575;&#34920;&#24449;&#27969;&#24418;&#30340;&#20869;&#22312;&#26354;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Let $\mathcal{M} \subseteq \mathbb{R}^d$ denote a low-dimensional manifold and let $\mathcal{X}= \{ x_1, \dots, x_n \}$ be a collection of points uniformly sampled from $\mathcal{M}$. We study the relationship between the curvature of a random geometric graph built from $\mathcal{X}$ and the curvature of the manifold $\mathcal{M}$ via continuum limits of Ollivier's discrete Ricci curvature. We prove pointwise, non-asymptotic consistency results and also show that if $\mathcal{M}$ has Ricci curvature bounded from below by a positive constant, then the random geometric graph will inherit this global structural property with high probability. We discuss applications of the global discrete curvature bounds to contraction properties of heat kernels on graphs, as well as implications for manifold learning from data clouds. In particular, we show that the consistency results allow for characterizing the intrinsic curvature of a manifold from extrinsic curvature.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#31867;&#31639;&#27861;&#22312;&#20915;&#31574;&#20013;&#30340;&#24212;&#29992;&#21644;&#24433;&#21709;&#65292;&#37325;&#28857;&#32771;&#23519;&#20102;&#31639;&#27861;&#35774;&#35745;&#23545;&#20154;&#32676;&#34892;&#20026;&#20998;&#24067;&#30340;&#24433;&#21709;&#65292;&#20197;&#21450;&#20998;&#31867;&#22870;&#24809;&#30340;&#27665;&#20027;&#21270;&#23545;&#31038;&#20250;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2307.02319</link><description>&lt;p&gt;
&#31639;&#27861;&#12289;&#28608;&#21169;&#21644;&#27665;&#20027;
&lt;/p&gt;
&lt;p&gt;
Algorithms, Incentives, and Democracy. (arXiv:2307.02319v1 [econ.TH])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02319
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#31867;&#31639;&#27861;&#22312;&#20915;&#31574;&#20013;&#30340;&#24212;&#29992;&#21644;&#24433;&#21709;&#65292;&#37325;&#28857;&#32771;&#23519;&#20102;&#31639;&#27861;&#35774;&#35745;&#23545;&#20154;&#32676;&#34892;&#20026;&#20998;&#24067;&#30340;&#24433;&#21709;&#65292;&#20197;&#21450;&#20998;&#31867;&#22870;&#24809;&#30340;&#27665;&#20027;&#21270;&#23545;&#31038;&#20250;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#31867;&#31639;&#27861;&#22312;&#25151;&#23627;&#12289;&#20449;&#36151;&#21644;&#25191;&#27861;&#31561;&#39046;&#22495;&#36234;&#26469;&#36234;&#24191;&#27867;&#22320;&#34987;&#29992;&#20110;&#20915;&#31574;&#65292;&#24433;&#21709;&#20154;&#20204;&#30340;&#29983;&#27963;&#12290;&#36825;&#20123;&#31639;&#27861;&#21487;&#20197;&#26377;&#24847;&#22320;&#25913;&#21464;&#20010;&#20307;&#34892;&#20026;&#65288;&#36890;&#36807;&#27450;&#35784;&#39044;&#27979;&#31639;&#27861;&#39044;&#38450;&#27450;&#35784;&#34892;&#20026;&#65289;&#65292;&#20063;&#21487;&#20197;&#26080;&#24847;&#20013;&#25913;&#21464;&#34892;&#20026;&#65288;&#36890;&#36807;&#20869;&#23481;&#25490;&#24207;&#31639;&#27861;&#20256;&#25773;&#34394;&#20551;&#20449;&#24687;&#65289;&#65292;&#23427;&#20204;&#36234;&#26469;&#36234;&#38754;&#20020;&#20844;&#20247;&#23457;&#26597;&#21644;&#30417;&#31649;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#31639;&#27861;&#35774;&#35745;&#32773;&#36890;&#36807;&#26368;&#20248;&#20998;&#31867;&#22914;&#20309;&#24433;&#21709;&#20154;&#32676;&#34892;&#20026;&#30340;&#20998;&#24067;&#65292;&#26377;&#26102;&#20250;&#20135;&#29983;&#24847;&#24819;&#19981;&#21040;&#30340;&#32467;&#26524;&#12290;&#28982;&#21518;&#25105;&#20204;&#30740;&#31350;&#20102;&#23545;&#31639;&#27861;&#20998;&#31867;&#30340;&#22870;&#24809;&#25110;&#21033;&#23475;&#20851;&#31995;&#36827;&#34892;&#27665;&#20027;&#21270;&#30340;&#24433;&#21709;&#65292;&#20197;&#25506;&#35752;&#31038;&#20250;&#22914;&#20309;&#28508;&#22312;&#22320;&#38450;&#27490;&#65288;&#25110;&#20419;&#36827;&#65289;&#25504;&#22842;&#24615;&#20998;&#31867;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#28041;&#21450;&#31639;&#27861;&#20844;&#24179;&#24615;&#30340;&#38382;&#39064;&#65292;&#22312;&#29305;&#23450;&#20998;&#31867;&#30340;&#24773;&#22659;&#20013;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;
Classification algorithms are increasingly used in areas such as housing, credit, and law enforcement in order to make decisions affecting peoples' lives. These algorithms can change individual behavior deliberately (a fraud prediction algorithm deterring fraud) or inadvertently (content sorting algorithms spreading misinformation), and they are increasingly facing public scrutiny and regulation. Some of these regulations, like the elimination of cash bail in some states, have focused on \textit{lowering the stakes of certain classifications}. In this paper we characterize how optimal classification by an algorithm designer can affect the distribution of behavior in a population -- sometimes in surprising ways. We then look at the effect of democratizing the rewards and punishments, or stakes, to algorithmic classification to consider how a society can potentially stem (or facilitate!) predatory classification. Our results speak to questions of algorithmic fairness in settings where be
&lt;/p&gt;</description></item><item><title>Sumformer&#26159;&#19968;&#31181;&#26032;&#39062;&#19988;&#31616;&#21333;&#30340;&#26550;&#26500;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#36924;&#36817;Transformer&#12290;&#36890;&#36807;Sumformer&#65292;&#25105;&#20204;&#39318;&#27425;&#32473;&#20986;&#20102;Linformer&#21644;Performer&#30340;&#36890;&#29992;&#36924;&#36817;&#32467;&#26524;&#65292;&#24182;&#25512;&#23548;&#20986;&#19968;&#20010;&#26032;&#30340;&#35777;&#26126;&#65292;&#35777;&#26126;&#21482;&#38656;&#35201;&#19968;&#20010;&#27880;&#24847;&#21147;&#23618;&#23601;&#36275;&#20197;&#36827;&#34892;Transformer&#30340;&#36890;&#29992;&#36924;&#36817;&#12290;</title><link>http://arxiv.org/abs/2307.02301</link><description>&lt;p&gt;
Sumformer:&#39640;&#25928;Transformer&#30340;&#36890;&#29992;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
Sumformer: Universal Approximation for Efficient Transformers. (arXiv:2307.02301v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02301
&lt;/p&gt;
&lt;p&gt;
Sumformer&#26159;&#19968;&#31181;&#26032;&#39062;&#19988;&#31616;&#21333;&#30340;&#26550;&#26500;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#36924;&#36817;Transformer&#12290;&#36890;&#36807;Sumformer&#65292;&#25105;&#20204;&#39318;&#27425;&#32473;&#20986;&#20102;Linformer&#21644;Performer&#30340;&#36890;&#29992;&#36924;&#36817;&#32467;&#26524;&#65292;&#24182;&#25512;&#23548;&#20986;&#19968;&#20010;&#26032;&#30340;&#35777;&#26126;&#65292;&#35777;&#26126;&#21482;&#38656;&#35201;&#19968;&#20010;&#27880;&#24847;&#21147;&#23618;&#23601;&#36275;&#20197;&#36827;&#34892;Transformer&#30340;&#36890;&#29992;&#36924;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;Transformer&#30340;&#24341;&#20837;&#65292;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#12290;ChatGPT&#26159;&#20854;&#20013;&#26368;&#33879;&#21517;&#30340;&#20363;&#23376;&#65292;&#21363;&#20351;&#22312;&#30740;&#31350;&#31038;&#21306;&#20043;&#22806;&#65292;&#20063;&#25913;&#21464;&#20102;&#20154;&#20204;&#23545;AI&#21487;&#33021;&#24615;&#30340;&#30475;&#27861;&#12290;&#28982;&#32780;&#65292;&#38500;&#20102;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#24615;&#33021;&#20043;&#22806;&#65292;Transformer&#30456;&#23545;&#20110;&#24207;&#21015;&#38271;&#24230;&#30340;&#20108;&#27425;&#26102;&#38388;&#21644;&#31354;&#38388;&#22797;&#26434;&#24230;&#38480;&#21046;&#20102;&#22788;&#29702;&#38271;&#24207;&#21015;&#30340;&#33021;&#21147;&#12290;&#23613;&#31649;&#39640;&#25928;Transformer&#26550;&#26500;&#65288;&#22914;Linformer&#21644;Performer&#65289;&#20197;&#32447;&#24615;&#22797;&#26434;&#24230;&#20986;&#29616;&#20316;&#20026;&#26377;&#24076;&#26395;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#23427;&#20204;&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#26377;&#38480;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;Sumformer&#65292;&#19968;&#31181;&#26032;&#39062;&#19988;&#31616;&#21333;&#30340;&#26550;&#26500;&#65292;&#33021;&#22815;&#36890;&#29992;&#36924;&#36817;&#31561;&#21464;&#24207;&#21015;&#21040;&#24207;&#21015;&#30340;&#20989;&#25968;&#12290;&#25105;&#20204;&#20351;&#29992;Sumformer&#32473;&#20986;&#20102;Linformer&#21644;Performer&#30340;&#31532;&#19968;&#20010;&#36890;&#29992;&#36924;&#36817;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25512;&#23548;&#20102;&#19968;&#20010;&#26032;&#30340;Transformer&#35777;&#26126;&#65292;&#26174;&#31034;&#21482;&#38656;&#35201;&#19968;&#20010;&#27880;&#24847;&#21147;&#23618;&#23601;&#36275;&#20197;&#36827;&#34892;&#36890;&#29992;&#36924;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;
Natural language processing (NLP) made an impressive jump with the introduction of Transformers. ChatGPT is one of the most famous examples, changing the perception of the possibilities of AI even outside the research community. However, besides the impressive performance, the quadratic time and space complexity of Transformers with respect to sequence length pose significant limitations for handling long sequences. While efficient Transformer architectures like Linformer and Performer with linear complexity have emerged as promising solutions, their theoretical understanding remains limited. In this paper, we introduce Sumformer, a novel and simple architecture capable of universally approximating equivariant sequence-to-sequence functions. We use Sumformer to give the first universal approximation results for Linformer and Performer. Moreover, we derive a new proof for Transformers, showing that just one attention layer is sufficient for universal approximation.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#27874;&#27573;&#21453;&#39304;&#30340;&#22312;&#32447;&#20803;&#23398;&#20064;&#65292;&#24182;&#35774;&#35745;&#20102;&#29992;&#20110;&#22810;&#33218;&#36172;&#21338;&#26426;&#21644;&#36172;&#21338;&#32447;&#24615;&#20248;&#21270;&#30340;&#20803;&#31639;&#27861;&#12290;&#23545;&#20110;&#22810;&#33218;&#36172;&#21338;&#26426;&#65292;&#31639;&#27861;&#20351;&#29992;&#20102;Tsallis-&#29109;&#30340;&#27867;&#21270;Exp3&#65292;&#24182;&#19988;&#20219;&#21153;&#24179;&#22343;&#36951;&#25022;&#20250;&#38543;&#30528;&#26368;&#20248;&#35299;&#30340;&#29109;&#30340;&#20943;&#23567;&#32780;&#25913;&#21892;&#12290;&#23545;&#20110;&#36172;&#21338;&#32447;&#24615;&#20248;&#21270;&#65292;&#31639;&#27861;&#20351;&#29992;&#20102;&#33258;&#21327;&#35843;&#38556;&#30861;&#27491;&#21017;&#21270;&#22120;&#21021;&#22987;&#21270;&#21644;&#35843;&#25972;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#65292;&#24182;&#19988;&#20219;&#21153;&#24179;&#22343;&#36951;&#25022;&#19982;&#21160;&#20316;&#31354;&#38388;&#30456;&#20851;&#30340;&#24230;&#37327;&#30452;&#25509;&#21464;&#21270;&#12290;</title><link>http://arxiv.org/abs/2307.02295</link><description>&lt;p&gt;
&#20803;&#23398;&#20064;&#23545;&#25239;&#27874;&#27573;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Meta-Learning Adversarial Bandit Algorithms. (arXiv:2307.02295v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02295
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#27874;&#27573;&#21453;&#39304;&#30340;&#22312;&#32447;&#20803;&#23398;&#20064;&#65292;&#24182;&#35774;&#35745;&#20102;&#29992;&#20110;&#22810;&#33218;&#36172;&#21338;&#26426;&#21644;&#36172;&#21338;&#32447;&#24615;&#20248;&#21270;&#30340;&#20803;&#31639;&#27861;&#12290;&#23545;&#20110;&#22810;&#33218;&#36172;&#21338;&#26426;&#65292;&#31639;&#27861;&#20351;&#29992;&#20102;Tsallis-&#29109;&#30340;&#27867;&#21270;Exp3&#65292;&#24182;&#19988;&#20219;&#21153;&#24179;&#22343;&#36951;&#25022;&#20250;&#38543;&#30528;&#26368;&#20248;&#35299;&#30340;&#29109;&#30340;&#20943;&#23567;&#32780;&#25913;&#21892;&#12290;&#23545;&#20110;&#36172;&#21338;&#32447;&#24615;&#20248;&#21270;&#65292;&#31639;&#27861;&#20351;&#29992;&#20102;&#33258;&#21327;&#35843;&#38556;&#30861;&#27491;&#21017;&#21270;&#22120;&#21021;&#22987;&#21270;&#21644;&#35843;&#25972;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#65292;&#24182;&#19988;&#20219;&#21153;&#24179;&#22343;&#36951;&#25022;&#19982;&#21160;&#20316;&#31354;&#38388;&#30456;&#20851;&#30340;&#24230;&#37327;&#30452;&#25509;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20855;&#26377;&#27874;&#27573;&#21453;&#39304;&#30340;&#22312;&#32447;&#20803;&#23398;&#20064;&#65292;&#30446;&#26631;&#26159;&#22312;&#22810;&#20010;&#20219;&#21153;&#20043;&#38388;&#25913;&#21892;&#24615;&#33021;&#65292;&#22914;&#26524;&#23427;&#20204;&#26681;&#25454;&#26576;&#20010;&#33258;&#28982;&#30340;&#30456;&#20284;&#24615;&#24230;&#37327;&#26159;&#30456;&#20284;&#30340;&#12290;&#20316;&#20026;&#38024;&#23545;&#25932;&#23545;&#30340;&#22312;&#32447;&#37096;&#20998;&#20449;&#24687;&#35774;&#32622;&#30340;&#39318;&#20010;&#30446;&#26631;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#20803;&#31639;&#27861;&#65292;&#23558;&#22806;&#23618;&#23398;&#20064;&#22120;&#32467;&#21512;&#22312;&#19968;&#36215;&#65292;&#21516;&#26102;&#20026;&#20004;&#31181;&#37325;&#35201;&#24773;&#20917;&#35843;&#25972;&#20869;&#37096;&#23398;&#20064;&#22120;&#30340;&#21021;&#22987;&#21270;&#21644;&#20854;&#20182;&#36229;&#21442;&#25968;&#65306;&#22810;&#33218;&#36172;&#21338;&#26426;&#65288;MAB&#65289;&#21644;&#36172;&#21338;&#32447;&#24615;&#20248;&#21270;&#65288;BLO&#65289;&#12290;&#23545;&#20110;MAB&#65292;&#20803;&#23398;&#20064;&#22120;&#20351;&#29992;Tsallis-&#29109;&#30340;&#27867;&#21270;Exp3&#30340;&#21021;&#22987;&#21270;&#21644;&#35774;&#32622;&#36229;&#21442;&#25968;&#65292;&#22914;&#26524;&#21518;&#35265;&#20043;&#39640;&#23792;&#30340;&#29109;&#23567;&#65292;&#21017;&#20219;&#21153;&#24179;&#22343;&#36951;&#25022;&#25913;&#21892;&#12290;&#23545;&#20110;BLO&#65292;&#25105;&#20204;&#23398;&#20250;&#20102;&#20351;&#29992;&#33258;&#21327;&#35843;&#38556;&#30861;&#27491;&#21017;&#21270;&#22120;&#21021;&#22987;&#21270;&#21644;&#35843;&#25972;&#22312;&#32447;&#38236;&#20687;&#19979;&#38477;&#65288;OMD&#65289;&#65292;&#34920;&#26126;&#20219;&#21153;&#24179;&#22343;&#36951;&#25022;&#19982;&#20854;&#24341;&#36215;&#30340;&#21160;&#20316;&#31354;&#38388;&#30456;&#20851;&#30340;&#24230;&#37327;&#30452;&#25509;&#21464;&#21270;&#12290;&#25105;&#20204;&#30340;&#20445;&#35777;&#22522;&#20110;&#35777;&#26126;&#26080;&#27491;&#35268;&#21270;&#36319;&#38543;&#32773;&#19982;&#20004;&#20010;&#8230;
&lt;/p&gt;
&lt;p&gt;
We study online meta-learning with bandit feedback, with the goal of improving performance across multiple tasks if they are similar according to some natural similarity measure. As the first to target the adversarial online-within-online partial-information setting, we design meta-algorithms that combine outer learners to simultaneously tune the initialization and other hyperparameters of an inner learner for two important cases: multi-armed bandits (MAB) and bandit linear optimization (BLO). For MAB, the meta-learners initialize and set hyperparameters of the Tsallis-entropy generalization of Exp3, with the task-averaged regret improving if the entropy of the optima-in-hindsight is small. For BLO, we learn to initialize and tune online mirror descent (OMD) with self-concordant barrier regularizers, showing that task-averaged regret varies directly with an action space-dependent measure they induce. Our guarantees rely on proving that unregularized follow-the-leader combined with two 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#36866;&#24403;&#21021;&#22987;&#21270;&#30340;&#26377;&#38480;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#21560;&#25910;&#30456;&#21464;&#21450;&#20854;&#26222;&#36866;&#24615;&#65292;&#35777;&#26126;&#20102;&#21363;&#20351;&#22312;&#26377;&#38480;&#32593;&#32476;&#20013;&#20173;&#28982;&#23384;&#22312;&#30528;&#20174;&#26377;&#24207;&#29366;&#24577;&#21040;&#28151;&#27788;&#29366;&#24577;&#30340;&#36807;&#28193;&#65292;&#24182;&#19988;&#19981;&#21516;&#30340;&#32593;&#32476;&#26550;&#26500;&#20250;&#21453;&#26144;&#22312;&#36807;&#28193;&#30340;&#26222;&#36866;&#31867;&#19978;&#12290;</title><link>http://arxiv.org/abs/2307.02284</link><description>&lt;p&gt;
&#20154;&#24037;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#21560;&#25910;&#30456;&#21464;
&lt;/p&gt;
&lt;p&gt;
Absorbing Phase Transitions in Artificial Deep Neural Networks. (arXiv:2307.02284v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02284
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#36866;&#24403;&#21021;&#22987;&#21270;&#30340;&#26377;&#38480;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#21560;&#25910;&#30456;&#21464;&#21450;&#20854;&#26222;&#36866;&#24615;&#65292;&#35777;&#26126;&#20102;&#21363;&#20351;&#22312;&#26377;&#38480;&#32593;&#32476;&#20013;&#20173;&#28982;&#23384;&#22312;&#30528;&#20174;&#26377;&#24207;&#29366;&#24577;&#21040;&#28151;&#27788;&#29366;&#24577;&#30340;&#36807;&#28193;&#65292;&#24182;&#19988;&#19981;&#21516;&#30340;&#32593;&#32476;&#26550;&#26500;&#20250;&#21453;&#26144;&#22312;&#36807;&#28193;&#30340;&#26222;&#36866;&#31867;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#33879;&#21517;&#30340;&#24179;&#22343;&#22330;&#29702;&#35770;&#65292;&#23545;&#20110;&#21508;&#31181;&#20307;&#31995;&#30340;&#26080;&#38480;&#23485;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#34892;&#20026;&#30340;&#29702;&#35770;&#29702;&#35299;&#24050;&#32463;&#36805;&#36895;&#21457;&#23637;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#26356;&#23454;&#38469;&#21644;&#29616;&#23454;&#37325;&#35201;&#24615;&#26356;&#24378;&#30340;&#26377;&#38480;&#32593;&#32476;&#65292;&#32570;&#20047;&#28165;&#26224;&#30452;&#35266;&#30340;&#26694;&#26550;&#26469;&#24310;&#20280;&#25105;&#20204;&#30340;&#29702;&#35299;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36866;&#24403;&#21021;&#22987;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#34892;&#20026;&#21487;&#20197;&#29992;&#21560;&#25910;&#30456;&#21464;&#20013;&#30340;&#26222;&#36941;&#20020;&#30028;&#29616;&#35937;&#26469;&#29702;&#35299;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20840;&#36830;&#25509;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#21644;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#20013;&#20174;&#26377;&#24207;&#29366;&#24577;&#21040;&#28151;&#27788;&#29366;&#24577;&#30340;&#30456;&#21464;&#65292;&#24182;&#24378;&#35843;&#20102;&#20307;&#31995;&#26550;&#26500;&#30340;&#24046;&#24322;&#19982;&#30456;&#21464;&#30340;&#26222;&#36866;&#31867;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#36824;&#25104;&#21151;&#22320;&#24212;&#29992;&#20102;&#26377;&#38480;&#23610;&#24230;&#25193;&#23637;&#30340;&#26041;&#27861;&#65292;&#36825;&#34920;&#26126;&#20102;&#30452;&#35266;&#30340;&#29616;&#35937;&#23398;&#12290;
&lt;/p&gt;
&lt;p&gt;
Theoretical understanding of the behavior of infinitely-wide neural networks has been rapidly developed for various architectures due to the celebrated mean-field theory. However, there is a lack of a clear, intuitive framework for extending our understanding to finite networks that are of more practical and realistic importance. In the present contribution, we demonstrate that the behavior of properly initialized neural networks can be understood in terms of universal critical phenomena in absorbing phase transitions. More specifically, we study the order-to-chaos transition in the fully-connected feedforward neural networks and the convolutional ones to show that (i) there is a well-defined transition from the ordered state to the chaotics state even for the finite networks, and (ii) difference in architecture is reflected in that of the universality class of the transition. Remarkably, the finite-size scaling can also be successfully applied, indicating that intuitive phenomenologic
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#36890;&#36807;&#24352;&#37327;&#32593;&#32476;&#29702;&#35299;&#21644;&#28436;&#21270;&#21367;&#31215;&#30340;&#26032;&#35270;&#35282;&#65292;&#21487;&#20197;&#36890;&#36807;&#32472;&#21046;&#21644;&#25805;&#20316;&#24352;&#37327;&#32593;&#32476;&#26469;&#36827;&#34892;&#20989;&#25968;&#36716;&#25442;&#12289;&#23376;&#24352;&#37327;&#35775;&#38382;&#21644;&#34701;&#21512;&#12290;&#30740;&#31350;&#20154;&#21592;&#36824;&#28436;&#31034;&#20102;&#21367;&#31215;&#22270;&#34920;&#30340;&#23548;&#20986;&#20197;&#21450;&#21508;&#31181;&#33258;&#21160;&#24494;&#20998;&#25805;&#20316;&#21644;&#20108;&#38454;&#20449;&#24687;&#36924;&#36817;&#22270;&#34920;&#30340;&#29983;&#25104;&#65292;&#21516;&#26102;&#36824;&#25552;&#20379;&#20102;&#29305;&#23450;&#20110;&#21367;&#31215;&#30340;&#22270;&#34920;&#36716;&#25442;&#65292;&#20197;&#20248;&#21270;&#35745;&#31639;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.02275</link><description>&lt;p&gt;
&#36879;&#36807;&#24352;&#37327;&#32593;&#32476;&#30340;&#35270;&#35282;&#35299;&#26512;&#21367;&#31215;
&lt;/p&gt;
&lt;p&gt;
Convolutions Through the Lens of Tensor Networks. (arXiv:2307.02275v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02275
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20379;&#20102;&#19968;&#31181;&#36890;&#36807;&#24352;&#37327;&#32593;&#32476;&#29702;&#35299;&#21644;&#28436;&#21270;&#21367;&#31215;&#30340;&#26032;&#35270;&#35282;&#65292;&#21487;&#20197;&#36890;&#36807;&#32472;&#21046;&#21644;&#25805;&#20316;&#24352;&#37327;&#32593;&#32476;&#26469;&#36827;&#34892;&#20989;&#25968;&#36716;&#25442;&#12289;&#23376;&#24352;&#37327;&#35775;&#38382;&#21644;&#34701;&#21512;&#12290;&#30740;&#31350;&#20154;&#21592;&#36824;&#28436;&#31034;&#20102;&#21367;&#31215;&#22270;&#34920;&#30340;&#23548;&#20986;&#20197;&#21450;&#21508;&#31181;&#33258;&#21160;&#24494;&#20998;&#25805;&#20316;&#21644;&#20108;&#38454;&#20449;&#24687;&#36924;&#36817;&#22270;&#34920;&#30340;&#29983;&#25104;&#65292;&#21516;&#26102;&#36824;&#25552;&#20379;&#20102;&#29305;&#23450;&#20110;&#21367;&#31215;&#30340;&#22270;&#34920;&#36716;&#25442;&#65292;&#20197;&#20248;&#21270;&#35745;&#31639;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#21367;&#31215;&#30340;&#30452;&#35266;&#27010;&#24565;&#31616;&#21333;&#65292;&#20294;&#20854;&#20998;&#26512;&#27604;&#31264;&#23494;&#23618;&#26356;&#21152;&#22797;&#26434;&#65292;&#36825;&#20351;&#24471;&#29702;&#35770;&#21644;&#31639;&#27861;&#30340;&#25512;&#24191;&#21464;&#24471;&#22256;&#38590;&#12290;&#25105;&#20204;&#36890;&#36807;&#24352;&#37327;&#32593;&#32476;&#65288;TN&#65289;&#25552;&#20379;&#20102;&#23545;&#21367;&#31215;&#30340;&#26032;&#35270;&#35282;&#65292;&#36890;&#36807;&#32472;&#21046;&#22270;&#34920;&#12289;&#25805;&#20316;&#22270;&#34920;&#36827;&#34892;&#20989;&#25968;&#36716;&#25442;&#12289;&#23376;&#24352;&#37327;&#35775;&#38382;&#21644;&#34701;&#21512;&#26469;&#25512;&#29702;&#24213;&#23618;&#24352;&#37327;&#20056;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#25512;&#23548;&#21508;&#31181;&#33258;&#21160;&#24494;&#20998;&#25805;&#20316;&#30340;&#22270;&#34920;&#20197;&#21450;&#20855;&#26377;&#23436;&#25972;&#36229;&#21442;&#25968;&#25903;&#25345;&#12289;&#25209;&#22788;&#29702;&#12289;&#36890;&#36947;&#32452;&#21644;&#20219;&#24847;&#21367;&#31215;&#32500;&#24230;&#27867;&#21270;&#30340;&#27969;&#34892;&#30340;&#20108;&#38454;&#20449;&#24687;&#36924;&#36817;&#30340;&#22270;&#34920;&#26469;&#23637;&#31034;&#36825;&#31181;&#34920;&#36798;&#33021;&#21147;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22522;&#20110;&#36830;&#25509;&#27169;&#24335;&#25552;&#20379;&#20102;&#29305;&#23450;&#20110;&#21367;&#31215;&#30340;&#36716;&#25442;&#65292;&#20801;&#35768;&#22312;&#35780;&#20272;&#20043;&#21069;&#37325;&#26032;&#36830;&#25509;&#21644;&#31616;&#21270;&#22270;&#34920;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#36890;&#36807;&#20381;&#36182;&#20110;&#39640;&#25928;TN&#32553;&#24182;&#30340;&#24050;&#24314;&#31435;&#26426;&#21046;&#26469;&#25506;&#31350;&#35745;&#31639;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;TN&#23454;&#29616;&#21152;&#36895;&#20102;&#26368;&#36817;&#25552;&#20986;&#30340;
&lt;/p&gt;
&lt;p&gt;
Despite their simple intuition, convolutions are more tedious to analyze than dense layers, which complicates the generalization of theoretical and algorithmic ideas. We provide a new perspective onto convolutions through tensor networks (TNs) which allow reasoning about the underlying tensor multiplications by drawing diagrams, and manipulating them to perform function transformations, sub-tensor access, and fusion. We demonstrate this expressive power by deriving the diagrams of various autodiff operations and popular approximations of second-order information with full hyper-parameter support, batching, channel groups, and generalization to arbitrary convolution dimensions. Further, we provide convolution-specific transformations based on the connectivity pattern which allow to re-wire and simplify diagrams before evaluation. Finally, we probe computational performance, relying on established machinery for efficient TN contraction. Our TN implementation speeds up a recently-proposed
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#24635;&#32467;&#20102;&#22312;&#20581;&#24247;&#39046;&#22495;&#20013;&#35780;&#20272;AI&#31995;&#32479;&#26102;&#30340;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#65306;&#22522;&#20934;&#20107;&#23454;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#29616;&#26377;&#30340;&#26041;&#27861;&#36890;&#24120;&#24573;&#35270;&#20102;&#36825;&#19968;&#28857;&#65292;&#32780;&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#32479;&#35745;&#27169;&#22411;&#32858;&#21512;&#27880;&#37322;&#30340;&#26694;&#26550;&#65292;&#20197;&#26356;&#20934;&#30830;&#22320;&#35780;&#20272;AI&#31995;&#32479;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.02191</link><description>&lt;p&gt;
&#22312;&#19981;&#30830;&#23450;&#30340;&#22522;&#20934;&#20107;&#23454;&#19979;&#35780;&#20272;AI&#31995;&#32479;&#65306;&#30382;&#32932;&#30149;&#20363;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Evaluating AI systems under uncertain ground truth: a case study in dermatology. (arXiv:2307.02191v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02191
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#24635;&#32467;&#20102;&#22312;&#20581;&#24247;&#39046;&#22495;&#20013;&#35780;&#20272;AI&#31995;&#32479;&#26102;&#30340;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#65306;&#22522;&#20934;&#20107;&#23454;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#29616;&#26377;&#30340;&#26041;&#27861;&#36890;&#24120;&#24573;&#35270;&#20102;&#36825;&#19968;&#28857;&#65292;&#32780;&#35813;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#32479;&#35745;&#27169;&#22411;&#32858;&#21512;&#27880;&#37322;&#30340;&#26694;&#26550;&#65292;&#20197;&#26356;&#20934;&#30830;&#22320;&#35780;&#20272;AI&#31995;&#32479;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#23433;&#20840;&#36215;&#35265;&#65292;&#22312;&#37096;&#32626;&#20043;&#21069;&#65292;&#21355;&#29983;&#39046;&#22495;&#30340;AI&#31995;&#32479;&#38656;&#35201;&#32463;&#36807;&#20840;&#38754;&#30340;&#35780;&#20272;&#65292;&#23558;&#20854;&#39044;&#27979;&#32467;&#26524;&#19982;&#20551;&#23450;&#20026;&#30830;&#23450;&#30340;&#22522;&#20934;&#20107;&#23454;&#36827;&#34892;&#39564;&#35777;&#12290;&#28982;&#32780;&#65292;&#23454;&#38469;&#24773;&#20917;&#24182;&#38750;&#22914;&#27492;&#65292;&#22522;&#20934;&#20107;&#23454;&#21487;&#33021;&#26159;&#19981;&#30830;&#23450;&#30340;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#22312;&#26631;&#20934;&#30340;AI&#27169;&#22411;&#35780;&#20272;&#20013;&#65292;&#36825;&#19968;&#28857;&#34987;&#22823;&#37096;&#20998;&#24573;&#35270;&#20102;&#65292;&#20294;&#26159;&#23427;&#21487;&#33021;&#20250;&#20135;&#29983;&#20005;&#37325;&#21518;&#26524;&#65292;&#22914;&#39640;&#20272;&#26410;&#26469;&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#36991;&#20813;&#36825;&#31181;&#24773;&#20917;&#65292;&#25105;&#20204;&#27979;&#37327;&#20102;&#22522;&#20934;&#20107;&#23454;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#25105;&#20204;&#20551;&#35774;&#23427;&#21487;&#20197;&#20998;&#35299;&#20026;&#20004;&#20010;&#20027;&#35201;&#37096;&#20998;&#65306;&#27880;&#37322;&#19981;&#30830;&#23450;&#24615;&#26159;&#30001;&#20110;&#32570;&#20047;&#21487;&#38752;&#27880;&#37322;&#65292;&#20197;&#21450;&#30001;&#20110;&#26377;&#38480;&#30340;&#35266;&#27979;&#20449;&#24687;&#32780;&#23548;&#33268;&#30340;&#22266;&#26377;&#19981;&#30830;&#23450;&#24615;&#12290;&#22312;&#30830;&#23450;&#22320;&#32858;&#21512;&#27880;&#37322;&#26102;&#65292;&#36890;&#24120;&#20250;&#24573;&#35270;&#36825;&#31181;&#22522;&#20934;&#20107;&#23454;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#20363;&#22914;&#36890;&#36807;&#22810;&#25968;&#25237;&#31080;&#25110;&#24179;&#22343;&#20540;&#26469;&#32858;&#21512;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#22312;&#35813;&#26694;&#26550;&#20013;&#20351;&#29992;&#32479;&#35745;&#27169;&#22411;&#36827;&#34892;&#27880;&#37322;&#30340;&#32858;&#21512;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23558;&#27880;&#37322;&#30340;&#32858;&#21512;&#26694;&#26550;&#35299;&#37322;&#20026;&#25152;&#35859;&#21487;&#33021;&#24615;&#30340;&#21518;&#39564;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
For safety, AI systems in health undergo thorough evaluations before deployment, validating their predictions against a ground truth that is assumed certain. However, this is actually not the case and the ground truth may be uncertain. Unfortunately, this is largely ignored in standard evaluation of AI models but can have severe consequences such as overestimating the future performance. To avoid this, we measure the effects of ground truth uncertainty, which we assume decomposes into two main components: annotation uncertainty which stems from the lack of reliable annotations, and inherent uncertainty due to limited observational information. This ground truth uncertainty is ignored when estimating the ground truth by deterministically aggregating annotations, e.g., by majority voting or averaging. In contrast, we propose a framework where aggregation is done using a statistical model. Specifically, we frame aggregation of annotations as posterior inference of so-called plausibilities
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DiffFlow&#30340;&#32479;&#19968;SDE&#26694;&#26550;&#65292;&#29992;&#20110;&#22788;&#29702;&#22522;&#20110;&#20998;&#25968;&#30340;&#25193;&#25955;&#27169;&#22411;&#21644;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#12290;&#36890;&#36807;&#35843;&#25972;&#26435;&#37325;&#65292;&#21487;&#20197;&#23454;&#29616;&#24555;&#36895;&#37319;&#26679;&#21644;&#39640;&#36136;&#37327;&#26679;&#26412;&#20043;&#38388;&#30340;&#24179;&#28369;&#36807;&#28193;&#12290;</title><link>http://arxiv.org/abs/2307.02159</link><description>&lt;p&gt;
DiffFlow:&#19968;&#31181;&#29992;&#20110;&#22522;&#20110;&#20998;&#25968;&#30340;&#25193;&#25955;&#27169;&#22411;&#21644;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#30340;&#32479;&#19968;SDE&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
DiffFlow: A Unified SDE Framework for Score-Based Diffusion Models and Generative Adversarial Networks. (arXiv:2307.02159v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02159
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DiffFlow&#30340;&#32479;&#19968;SDE&#26694;&#26550;&#65292;&#29992;&#20110;&#22788;&#29702;&#22522;&#20110;&#20998;&#25968;&#30340;&#25193;&#25955;&#27169;&#22411;&#21644;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#12290;&#36890;&#36807;&#35843;&#25972;&#26435;&#37325;&#65292;&#21487;&#20197;&#23454;&#29616;&#24555;&#36895;&#37319;&#26679;&#21644;&#39640;&#36136;&#37327;&#26679;&#26412;&#20043;&#38388;&#30340;&#24179;&#28369;&#36807;&#28193;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#27169;&#22411;&#21487;&#20197;&#20998;&#20026;&#20004;&#31181;&#31867;&#22411;&#65306;&#26174;&#24335;&#29983;&#25104;&#27169;&#22411;&#65288;&#22914;&#22522;&#20110;&#20998;&#25968;&#30340;&#25193;&#25955;&#27169;&#22411;&#21644;&#24402;&#19968;&#21270;&#27969;&#65289;&#21644;&#38544;&#24335;&#29983;&#25104;&#27169;&#22411;&#65288;&#22914;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65289;&#12290;&#23613;&#31649;&#36825;&#20004;&#31181;&#27169;&#22411;&#37117;&#21462;&#24471;&#20102;&#24456;&#22823;&#30340;&#25104;&#21151;&#65292;&#20294;&#23427;&#20204;&#21508;&#33258;&#23384;&#22312;&#38480;&#21046;&#65292;&#26080;&#27861;&#21516;&#26102;&#23454;&#29616;&#24555;&#36895;&#37319;&#26679;&#21644;&#39640;&#36136;&#37327;&#26679;&#26412;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#29992;&#20110;&#22788;&#29702;&#22522;&#20110;&#20998;&#25968;&#30340;&#25193;&#25955;&#27169;&#22411;&#21644;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20197;&#19979;&#20004;&#28857;&#65306;i&#65289;SDM&#21644;GAN&#30340;&#23398;&#20064;&#21160;&#24577;&#21487;&#20197;&#24402;&#32467;&#20026;&#19968;&#20010;&#31216;&#20026;&#37492;&#21035;&#22120;&#38477;&#22122;&#25193;&#25955;&#27969;&#65288;DiffFlow&#65289;&#30340;&#26032;&#22411;SDE&#65292;&#20854;&#20013;&#28418;&#31227;&#21487;&#20197;&#36890;&#36807;&#30495;&#23454;&#25968;&#25454;&#21644;&#29983;&#25104;&#25968;&#25454;&#30340;&#20998;&#25968;&#30340;&#21152;&#26435;&#32452;&#21512;&#26469;&#30830;&#23450;&#65307;ii&#65289;&#36890;&#36807;&#35843;&#25972;&#19981;&#21516;&#20998;&#25968;&#39033;&#20043;&#38388;&#30340;&#26435;&#37325;&#65292;&#25105;&#20204;&#21487;&#20197;&#23454;&#29616;&#24179;&#28369;&#36807;&#28193;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative models can be categorized into two types: explicit generative models that define explicit density forms and allow exact likelihood inference, such as score-based diffusion models (SDMs) and normalizing flows; implicit generative models that directly learn a transformation from the prior to the data distribution, such as generative adversarial nets (GANs). While these two types of models have shown great success, they suffer from respective limitations that hinder them from achieving fast sampling and high sample quality simultaneously. In this paper, we propose a unified theoretic framework for SDMs and GANs. We shown that: i) the learning dynamics of both SDMs and GANs can be described as a novel SDE named Discriminator Denoising Diffusion Flow (DiffFlow) where the drift can be determined by some weighted combinations of scores of the real data and the generated data; ii) By adjusting the relative weights between different score terms, we can obtain a smooth transition betw
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38544;&#24335;&#24494;&#20998;&#30340;&#26041;&#27861;&#29992;&#20110;&#36229;&#21442;&#25968;&#35843;&#20248;&#30340;&#22270;&#24418;Lasso&#65292;&#36890;&#36807;&#27714;&#35299;&#19968;&#38454;&#26041;&#27861;&#19979;&#30340;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#26469;&#23454;&#29616;&#12290;&#26368;&#32456;&#24471;&#21040;&#20102;&#22270;&#24418;Lasso&#35299;&#23545;&#20854;&#27491;&#21017;&#21270;&#36229;&#21442;&#25968;&#30340;&#38597;&#21487;&#27604;&#30697;&#38453;&#12290;</title><link>http://arxiv.org/abs/2307.02130</link><description>&lt;p&gt;
&#38024;&#23545;&#21152;&#26435;&#22270;&#24418;Lasso&#30340;&#38544;&#24335;&#24494;&#20998;&#29992;&#20110;&#36229;&#21442;&#25968;&#35843;&#20248;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Implicit Differentiation for Hyperparameter Tuning the Weighted Graphical Lasso. (arXiv:2307.02130v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02130
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38544;&#24335;&#24494;&#20998;&#30340;&#26041;&#27861;&#29992;&#20110;&#36229;&#21442;&#25968;&#35843;&#20248;&#30340;&#22270;&#24418;Lasso&#65292;&#36890;&#36807;&#27714;&#35299;&#19968;&#38454;&#26041;&#27861;&#19979;&#30340;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#26469;&#23454;&#29616;&#12290;&#26368;&#32456;&#24471;&#21040;&#20102;&#22270;&#24418;Lasso&#35299;&#23545;&#20854;&#27491;&#21017;&#21270;&#36229;&#21442;&#25968;&#30340;&#38597;&#21487;&#27604;&#30697;&#38453;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#26694;&#26550;&#21644;&#31639;&#27861;&#65292;&#29992;&#20110;&#36890;&#36807;&#19968;&#38454;&#26041;&#27861;&#35299;&#20915;&#19968;&#20010;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#26469;&#35843;&#20248;&#22270;&#24418;Lasso&#30340;&#36229;&#21442;&#25968;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23548;&#20986;&#20102;&#22270;&#24418;Lasso&#35299;&#23545;&#20854;&#27491;&#21017;&#21270;&#36229;&#21442;&#25968;&#30340;&#38597;&#21487;&#27604;&#30697;&#38453;&#12290;
&lt;/p&gt;
&lt;p&gt;
We provide a framework and algorithm for tuning the hyperparameters of the Graphical Lasso via a bilevel optimization problem solved with a first-order method. In particular, we derive the Jacobian of the Graphical Lasso solution with respect to its regularization hyperparameters.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#32452;&#21512;&#24615;&#25968;&#25454;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#23545;&#38543;&#26426;&#23618;&#27425;&#27169;&#22411;&#36827;&#34892;&#20998;&#31867;&#20219;&#21153;&#65292;&#21457;&#29616;&#28145;&#24230;CNN&#23398;&#20064;&#36825;&#20010;&#20219;&#21153;&#25152;&#38656;&#30340;&#35757;&#32451;&#25968;&#25454;&#25968;&#37327;&#38543;&#30528;&#31867;&#21035;&#25968;&#12289;&#32452;&#21512;&#25968;&#21644;&#36845;&#20195;&#27425;&#25968;&#30340;&#22686;&#21152;&#32780;&#28176;&#36827;&#22686;&#21152;&#12290;</title><link>http://arxiv.org/abs/2307.02129</link><description>&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22914;&#20309;&#23398;&#20064;&#32452;&#21512;&#24615;&#25968;&#25454;&#65306;&#38543;&#26426;&#23618;&#27425;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
How Deep Neural Networks Learn Compositional Data: The Random Hierarchy Model. (arXiv:2307.02129v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02129
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#32452;&#21512;&#24615;&#25968;&#25454;&#30340;&#38382;&#39064;&#65292;&#36890;&#36807;&#23545;&#38543;&#26426;&#23618;&#27425;&#27169;&#22411;&#36827;&#34892;&#20998;&#31867;&#20219;&#21153;&#65292;&#21457;&#29616;&#28145;&#24230;CNN&#23398;&#20064;&#36825;&#20010;&#20219;&#21153;&#25152;&#38656;&#30340;&#35757;&#32451;&#25968;&#25454;&#25968;&#37327;&#38543;&#30528;&#31867;&#21035;&#25968;&#12289;&#32452;&#21512;&#25968;&#21644;&#36845;&#20195;&#27425;&#25968;&#30340;&#22686;&#21152;&#32780;&#28176;&#36827;&#22686;&#21152;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#19968;&#33324;&#39640;&#32500;&#20219;&#21153;&#26159;&#38750;&#24120;&#22256;&#38590;&#30340;&#65292;&#22240;&#20026;&#23427;&#38656;&#35201;&#19982;&#32500;&#24230;&#25104;&#25351;&#25968;&#22686;&#38271;&#30340;&#35757;&#32451;&#25968;&#25454;&#25968;&#37327;&#12290;&#28982;&#32780;&#65292;&#28145;&#24230;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#22312;&#20811;&#26381;&#36825;&#19968;&#25361;&#25112;&#26041;&#38754;&#26174;&#31034;&#20986;&#20102;&#21331;&#36234;&#30340;&#25104;&#21151;&#12290;&#19968;&#31181;&#26222;&#36941;&#30340;&#20551;&#35774;&#26159;&#21487;&#23398;&#20064;&#20219;&#21153;&#20855;&#26377;&#39640;&#24230;&#32467;&#26500;&#21270;&#65292;CNN&#21033;&#29992;&#36825;&#31181;&#32467;&#26500;&#24314;&#31435;&#20102;&#25968;&#25454;&#30340;&#20302;&#32500;&#34920;&#31034;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#23545;&#23427;&#20204;&#38656;&#35201;&#22810;&#23569;&#35757;&#32451;&#25968;&#25454;&#20197;&#21450;&#36825;&#20010;&#25968;&#23383;&#22914;&#20309;&#21462;&#20915;&#20110;&#25968;&#25454;&#32467;&#26500;&#30693;&#20043;&#29978;&#23569;&#12290;&#26412;&#25991;&#22238;&#31572;&#20102;&#38024;&#23545;&#19968;&#20010;&#31616;&#21333;&#30340;&#20998;&#31867;&#20219;&#21153;&#30340;&#36825;&#20010;&#38382;&#39064;&#65292;&#35813;&#20219;&#21153;&#26088;&#22312;&#25429;&#25417;&#30495;&#23454;&#25968;&#25454;&#30340;&#30456;&#20851;&#26041;&#38754;&#65306;&#38543;&#26426;&#23618;&#27425;&#27169;&#22411;&#12290;&#22312;&#36825;&#20010;&#27169;&#22411;&#20013;&#65292;$n_c$&#20010;&#31867;&#21035;&#20013;&#30340;&#27599;&#19968;&#20010;&#23545;&#24212;&#20110;$m$&#20010;&#21516;&#20041;&#32452;&#21512;&#30340;&#39640;&#23618;&#27425;&#29305;&#24449;&#65292;&#24182;&#19988;&#36825;&#20123;&#29305;&#24449;&#21448;&#36890;&#36807;&#19968;&#20010;&#37325;&#22797;$L$&#27425;&#30340;&#36845;&#20195;&#36807;&#31243;&#30001;&#23376;&#29305;&#24449;&#32452;&#25104;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#38656;&#35201;&#28145;&#24230;CNN&#23398;&#20064;&#36825;&#20010;&#20219;&#21153;&#30340;&#35757;&#32451;&#25968;&#25454;&#25968;&#37327;$P^*$&#65288;i&#65289;&#38543;&#30528;$n_c m^L$&#30340;&#22686;&#38271;&#32780;&#28176;&#36827;&#22320;&#22686;&#38271;&#65292;&#36825;&#21482;&#26377;...
&lt;/p&gt;
&lt;p&gt;
Learning generic high-dimensional tasks is notably hard, as it requires a number of training data exponential in the dimension. Yet, deep convolutional neural networks (CNNs) have shown remarkable success in overcoming this challenge. A popular hypothesis is that learnable tasks are highly structured and that CNNs leverage this structure to build a low-dimensional representation of the data. However, little is known about how much training data they require, and how this number depends on the data structure. This paper answers this question for a simple classification task that seeks to capture relevant aspects of real data: the Random Hierarchy Model. In this model, each of the $n_c$ classes corresponds to $m$ synonymic compositions of high-level features, which are in turn composed of sub-features through an iterative process repeated $L$ times. We find that the number of training data $P^*$ required by deep CNNs to learn this task (i) grows asymptotically as $n_c m^L$, which is only
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27491;&#21017;&#21270;&#30340;&#40065;&#26834;&#22270;&#32467;&#26500;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#40784;&#29305;&#24449;&#20449;&#24687;&#21644;&#22270;&#20449;&#24687;&#65292;&#32467;&#21512;&#31232;&#30095;&#38477;&#32500;&#65292;&#25552;&#39640;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#40065;&#26834;&#24615;&#65292;&#29305;&#21035;&#26159;&#22312;&#21463;&#22122;&#22768;&#24433;&#21709;&#36739;&#22823;&#30340;&#24773;&#20917;&#19979;&#12290;</title><link>http://arxiv.org/abs/2307.02126</link><description>&lt;p&gt;
&#24102;&#26377;&#29305;&#24449;&#21644;&#37051;&#25509;&#30697;&#38453;&#23545;&#40784;&#30340;&#40065;&#26834;&#22270;&#32467;&#26500;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Robust Graph Structure Learning with the Alignment of Features and Adjacency Matrix. (arXiv:2307.02126v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02126
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27491;&#21017;&#21270;&#30340;&#40065;&#26834;&#22270;&#32467;&#26500;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#40784;&#29305;&#24449;&#20449;&#24687;&#21644;&#22270;&#20449;&#24687;&#65292;&#32467;&#21512;&#31232;&#30095;&#38477;&#32500;&#65292;&#25552;&#39640;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#40065;&#26834;&#24615;&#65292;&#29305;&#21035;&#26159;&#22312;&#21463;&#22122;&#22768;&#24433;&#21709;&#36739;&#22823;&#30340;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#25913;&#36827;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#30340;&#40065;&#26834;&#24615;&#65292;&#22270;&#32467;&#26500;&#23398;&#20064;&#65288;GSL&#65289;&#22240;&#22270;&#25968;&#25454;&#20013;&#30340;&#22122;&#22768;&#24191;&#27867;&#23384;&#22312;&#32780;&#21463;&#21040;&#20102;&#26497;&#22823;&#20851;&#27880;&#12290;&#35768;&#22810;&#26041;&#27861;&#24050;&#32463;&#25552;&#20986;&#29992;&#20110;GSL&#65292;&#20197;&#20849;&#21516;&#23398;&#20064;&#28165;&#27905;&#30340;&#22270;&#32467;&#26500;&#21644;&#30456;&#24212;&#30340;&#34920;&#31034;&#12290;&#20026;&#20102;&#25193;&#23637;&#20043;&#21069;&#30340;&#24037;&#20316;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27491;&#21017;&#21270;&#30340;GSL&#26041;&#27861;&#65292;&#29305;&#21035;&#26159;&#36890;&#36807;&#29305;&#24449;&#20449;&#24687;&#21644;&#22270;&#20449;&#24687;&#30340;&#23545;&#40784;&#65292;&#36825;&#20027;&#35201;&#21463;&#21040;&#25105;&#20204;&#25512;&#23548;&#30340;GNNs&#33410;&#28857;&#32423;Rademacher&#22797;&#26434;&#24615;&#30340;&#19979;&#30028;&#30340;&#28608;&#21169;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#25552;&#20986;&#30340;&#26041;&#27861;&#32467;&#21512;&#20102;&#31232;&#30095;&#38477;&#32500;&#65292;&#20197;&#21033;&#29992;&#19982;&#22270;&#32467;&#26500;&#30456;&#20851;&#30340;&#20302;&#32500;&#33410;&#28857;&#29305;&#24449;&#12290;&#20026;&#20102;&#35780;&#20272;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#25105;&#20204;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#22270;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;GSL&#26041;&#27861;&#22312;&#22810;&#20010;&#31454;&#20105;&#22522;&#32447;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#29305;&#21035;&#26159;&#22312;&#22270;&#32467;&#26500;&#21463;&#22122;&#22768;&#20005;&#37325;&#24433;&#21709;&#30340;&#24773;&#20917;&#19979;&#12290;&#24635;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
To improve the robustness of graph neural networks (GNN), graph structure learning (GSL) has attracted great interest due to the pervasiveness of noise in graph data. Many approaches have been proposed for GSL to jointly learn a clean graph structure and corresponding representations. To extend the previous work, this paper proposes a novel regularized GSL approach, particularly with an alignment of feature information and graph information, which is motivated mainly by our derived lower bound of node-level Rademacher complexity for GNNs. Additionally, our proposed approach incorporates sparse dimensional reduction to leverage low-dimensional node features that are relevant to the graph structure. To evaluate the effectiveness of our approach, we conduct experiments on real-world graphs. The results demonstrate that our proposed GSL method outperforms several competitive baselines, especially in scenarios where the graph structures are heavily affected by noise. Overall, our research h
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#24773;&#22659;&#36172;&#21338;&#35774;&#32622;&#30340;&#26032;&#22411;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#36172;&#21338;&#31639;&#27861;&#65292;&#20855;&#26377;&#31616;&#21333;&#21644;&#32047;&#31215;&#36951;&#25022;&#26368;&#23567;&#21270;&#30340;&#20248;&#21183;&#65292;&#24182;&#21487;&#33258;&#36866;&#24212;&#27169;&#22411;&#38169;&#35823;&#35268;&#33539;&#21644;&#36830;&#32493;&#33218;&#35774;&#32622;&#12290;&#35813;&#31639;&#27861;&#21033;&#29992;"&#19968;&#33268;&#33218;&#38598;"&#65288;CAS&#65289;&#26469;&#25552;&#20379;&#22312;&#27599;&#20010;&#24773;&#22659;&#19979;&#22218;&#25324;&#24773;&#22659;&#29305;&#23450;&#30340;&#26368;&#20339;&#33218;&#30340;&#19968;&#32452;&#33218;&#65292;&#36328;&#36234;&#24773;&#22659;&#20998;&#24067;&#12290;&#36825;&#31687;&#35770;&#25991;&#23545;&#31616;&#21333;&#21644;&#32047;&#31215;&#36951;&#25022;&#20445;&#35777;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#27491;&#38754;&#32467;&#26524;&#65292;&#21516;&#26102;&#20063;&#25581;&#31034;&#20102;&#26080;&#27861;&#23454;&#29616;&#23454;&#20363;&#20381;&#36182;&#24615;&#30340;&#31616;&#21333;&#36951;&#25022;&#20445;&#35777;&#30340;&#28040;&#26497;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2307.02108</link><description>&lt;p&gt;
&#27604;&#20363;&#21709;&#24212;&#65306;&#29992;&#20110;&#31616;&#21333;&#21644;&#32047;&#31215;&#36951;&#25022;&#26368;&#23567;&#21270;&#30340;&#24773;&#22659;&#36172;&#21338;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Proportional Response: Contextual Bandits for Simple and Cumulative Regret Minimization. (arXiv:2307.02108v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02108
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#24773;&#22659;&#36172;&#21338;&#35774;&#32622;&#30340;&#26032;&#22411;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#36172;&#21338;&#31639;&#27861;&#65292;&#20855;&#26377;&#31616;&#21333;&#21644;&#32047;&#31215;&#36951;&#25022;&#26368;&#23567;&#21270;&#30340;&#20248;&#21183;&#65292;&#24182;&#21487;&#33258;&#36866;&#24212;&#27169;&#22411;&#38169;&#35823;&#35268;&#33539;&#21644;&#36830;&#32493;&#33218;&#35774;&#32622;&#12290;&#35813;&#31639;&#27861;&#21033;&#29992;"&#19968;&#33268;&#33218;&#38598;"&#65288;CAS&#65289;&#26469;&#25552;&#20379;&#22312;&#27599;&#20010;&#24773;&#22659;&#19979;&#22218;&#25324;&#24773;&#22659;&#29305;&#23450;&#30340;&#26368;&#20339;&#33218;&#30340;&#19968;&#32452;&#33218;&#65292;&#36328;&#36234;&#24773;&#22659;&#20998;&#24067;&#12290;&#36825;&#31687;&#35770;&#25991;&#23545;&#31616;&#21333;&#21644;&#32047;&#31215;&#36951;&#25022;&#20445;&#35777;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#27491;&#38754;&#32467;&#26524;&#65292;&#21516;&#26102;&#20063;&#25581;&#31034;&#20102;&#26080;&#27861;&#23454;&#29616;&#23454;&#20363;&#20381;&#36182;&#24615;&#30340;&#31616;&#21333;&#36951;&#25022;&#20445;&#35777;&#30340;&#28040;&#26497;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21307;&#30103;&#20445;&#20581;&#21644;&#30005;&#23376;&#21830;&#21153;&#31561;&#39046;&#22495;&#65292;&#31616;&#21333;&#36951;&#25022;&#26368;&#23567;&#21270;&#26159;&#23398;&#20064;&#26368;&#20339;&#27835;&#30103;&#20998;&#37197;&#31574;&#30053;&#30340;&#20851;&#38190;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#24773;&#22659;&#36172;&#21338;&#35774;&#32622;&#20013;&#30340;&#31616;&#21333;&#36951;&#25022;&#26368;&#23567;&#21270;&#38382;&#39064;&#20173;&#26410;&#20805;&#20998;&#30740;&#31350;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#36172;&#21338;&#31639;&#27861;&#26063;&#65292;&#38024;&#23545;&#38543;&#26426;&#24773;&#22659;&#36172;&#21338;&#35774;&#32622;&#65292;&#22312;&#32047;&#31215;&#36951;&#25022;&#26368;&#23567;&#21270;&#65288;&#20855;&#26377;&#36817;&#20046;&#26368;&#20248;&#30340;&#26497;&#23567;&#26497;&#22823;&#20445;&#35777;&#65289;&#21644;&#31616;&#21333;&#36951;&#25022;&#26368;&#23567;&#21270;&#65288;&#20855;&#26377;SOTA&#20445;&#35777;&#65289;&#26041;&#38754;&#20855;&#26377;&#28789;&#27963;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#23545;&#27169;&#22411;&#38169;&#35823;&#35268;&#33539;&#36827;&#34892;&#33258;&#36866;&#24212;&#65292;&#24182;&#25193;&#23637;&#21040;&#36830;&#32493;&#33218;&#35774;&#32622;&#12290;&#36825;&#20123;&#20248;&#21183;&#26469;&#33258;&#20110;&#26500;&#24314;&#21644;&#20381;&#36182;&#20110;&#8220;&#19968;&#33268;&#33218;&#38598;&#8221;&#65288;CAS&#65289;&#65292;CAS&#22312;&#27599;&#20010;&#24773;&#22659;&#19979;&#25552;&#20379;&#19968;&#32452;&#33218;&#65292;&#36825;&#20123;&#33218;&#20197;&#19968;&#23450;&#30340;&#27010;&#29575;&#22218;&#25324;&#20102;&#24773;&#22659;&#29305;&#23450;&#30340;&#26368;&#20339;&#33218;&#65292;&#36328;&#36234;&#20102;&#24773;&#22659;&#20998;&#24067;&#12290;&#25105;&#20204;&#20851;&#20110;&#31616;&#21333;&#21644;&#32047;&#31215;&#36951;&#25022;&#20445;&#35777;&#30340;&#31215;&#26497;&#32467;&#26524;&#19982;&#19968;&#20010;&#28040;&#26497;&#32467;&#26524;&#24418;&#25104;&#23545;&#27604;&#65292;&#21518;&#32773;&#34920;&#26126;&#19968;&#20010;&#31639;&#27861;&#26080;&#27861;&#23454;&#29616;&#23454;&#20363;&#20381;&#36182;&#24615;&#30340;&#31616;&#21333;&#36951;&#25022;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Simple regret minimization is a critical problem in learning optimal treatment assignment policies across various domains, including healthcare and e-commerce. However, it remains understudied in the contextual bandit setting. We propose a new family of computationally efficient bandit algorithms for the stochastic contextual bandit settings, with the flexibility to be adapted for cumulative regret minimization (with near-optimal minimax guarantees) and simple regret minimization (with SOTA guarantees). Furthermore, our algorithms adapt to model misspecification and extend to the continuous arm settings. These advantages come from constructing and relying on "conformal arm sets" (CASs), which provide a set of arms at every context that encompass the context-specific optimal arm with some probability across the context distribution. Our positive results on simple and cumulative regret guarantees are contrasted by a negative result, which shows that an algorithm can't achieve instance-de
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#23545;&#22810;&#20010;&#21253;&#21547;&#39640;&#22522;&#25968;&#20998;&#31867;&#21464;&#37327;&#30340;&#34920;&#26684;&#25968;&#25454;&#38598;&#36827;&#34892;&#23454;&#35777;&#27604;&#36739;&#65292;&#21457;&#29616;&#24102;&#38543;&#26426;&#25928;&#24212;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#39640;&#20110;&#19981;&#24102;&#38543;&#26426;&#25928;&#24212;&#30340;&#32463;&#20856;&#27169;&#22411;&#65292;&#21516;&#26102;&#24102;&#38543;&#26426;&#25928;&#24212;&#30340;&#26641;&#25552;&#21319;&#26041;&#27861;&#20248;&#20110;&#24102;&#38543;&#26426;&#25928;&#24212;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#12290;</title><link>http://arxiv.org/abs/2307.02071</link><description>&lt;p&gt;
&#39640;&#22522;&#25968;&#20998;&#31867;&#21464;&#37327;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
A Comparison of Machine Learning Methods for Data with High-Cardinality Categorical Variables. (arXiv:2307.02071v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02071
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23545;&#22810;&#20010;&#21253;&#21547;&#39640;&#22522;&#25968;&#20998;&#31867;&#21464;&#37327;&#30340;&#34920;&#26684;&#25968;&#25454;&#38598;&#36827;&#34892;&#23454;&#35777;&#27604;&#36739;&#65292;&#21457;&#29616;&#24102;&#38543;&#26426;&#25928;&#24212;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#39640;&#20110;&#19981;&#24102;&#38543;&#26426;&#25928;&#24212;&#30340;&#32463;&#20856;&#27169;&#22411;&#65292;&#21516;&#26102;&#24102;&#38543;&#26426;&#25928;&#24212;&#30340;&#26641;&#25552;&#21319;&#26041;&#27861;&#20248;&#20110;&#24102;&#38543;&#26426;&#25928;&#24212;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#22522;&#25968;&#20998;&#31867;&#21464;&#37327;&#26159;&#25351;&#19981;&#21516;&#32423;&#21035;&#25968;&#37327;&#30456;&#23545;&#20110;&#25968;&#25454;&#38598;&#26679;&#26412;&#37327;&#36739;&#22823;&#30340;&#21464;&#37327;&#65292;&#20063;&#23601;&#26159;&#35828;&#65292;&#27599;&#20010;&#32423;&#21035;&#30340;&#25968;&#25454;&#28857;&#36739;&#23569;&#12290;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#22788;&#29702;&#39640;&#22522;&#25968;&#21464;&#37327;&#26102;&#21487;&#33021;&#20250;&#36935;&#21040;&#22256;&#38590;&#12290;&#26412;&#25991;&#36890;&#36807;&#23545;&#22810;&#20010;&#21253;&#21547;&#39640;&#22522;&#25968;&#20998;&#31867;&#21464;&#37327;&#30340;&#34920;&#26684;&#25968;&#25454;&#38598;&#36827;&#34892;&#23454;&#35777;&#27604;&#36739;&#65292;&#23545;&#20004;&#31181;&#26368;&#25104;&#21151;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65288;&#26641;&#25552;&#21319;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65289;&#20197;&#21450;&#32447;&#24615;&#28151;&#21512;&#25928;&#24212;&#27169;&#22411;&#30340;&#20960;&#20010;&#29256;&#26412;&#36827;&#34892;&#27604;&#36739;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#39318;&#20808;&#65292;&#24102;&#38543;&#26426;&#25928;&#24212;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#39640;&#20110;&#19981;&#24102;&#38543;&#26426;&#25928;&#24212;&#30340;&#32463;&#20856;&#27169;&#22411;&#65307;&#20854;&#27425;&#65292;&#24102;&#38543;&#26426;&#25928;&#24212;&#30340;&#26641;&#25552;&#21319;&#20248;&#20110;&#24102;&#38543;&#26426;&#25928;&#24212;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
High-cardinality categorical variables are variables for which the number of different levels is large relative to the sample size of a data set, or in other words, there are few data points per level. Machine learning methods can have difficulties with high-cardinality variables. In this article, we empirically compare several versions of two of the most successful machine learning methods, tree-boosting and deep neural networks, and linear mixed effects models using multiple tabular data sets with high-cardinality categorical variables. We find that, first, machine learning models with random effects have higher prediction accuracy than their classical counterparts without random effects, and, second, tree-boosting with random effects outperforms deep neural networks with random effects.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22810;&#31867;&#23398;&#20064;&#30340;&#36890;&#29992;&#36895;&#29575;&#65292;&#25512;&#24191;&#20102;&#20108;&#20803;&#20998;&#31867;&#30340;&#32467;&#26524;&#65292;&#24182;&#35299;&#20915;&#20102;&#22312;&#22810;&#31867;&#35774;&#32622;&#20013;&#30340;&#19968;&#20010;&#24320;&#25918;&#38382;&#39064;&#12290;&#35770;&#25991;&#36890;&#36807;&#24341;&#20837;DSL&#26641;&#30340;&#27010;&#24565;&#65292;&#32473;&#20986;&#20102;&#31867;&#21035;&#30340;&#25351;&#25968;&#21644;&#32447;&#24615;&#36895;&#29575;&#30340;&#21028;&#21035;&#26465;&#20214;&#65292;&#24182;&#35777;&#26126;&#20102;&#24403;&#26631;&#31614;&#25968;&#26080;&#38480;&#26102;&#65292;&#36895;&#29575;&#23558;&#21464;&#24930;&#12290;</title><link>http://arxiv.org/abs/2307.02066</link><description>&lt;p&gt;
&#22810;&#31867;&#23398;&#20064;&#30340;&#36890;&#29992;&#36895;&#29575;
&lt;/p&gt;
&lt;p&gt;
Universal Rates for Multiclass Learning. (arXiv:2307.02066v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02066
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22810;&#31867;&#23398;&#20064;&#30340;&#36890;&#29992;&#36895;&#29575;&#65292;&#25512;&#24191;&#20102;&#20108;&#20803;&#20998;&#31867;&#30340;&#32467;&#26524;&#65292;&#24182;&#35299;&#20915;&#20102;&#22312;&#22810;&#31867;&#35774;&#32622;&#20013;&#30340;&#19968;&#20010;&#24320;&#25918;&#38382;&#39064;&#12290;&#35770;&#25991;&#36890;&#36807;&#24341;&#20837;DSL&#26641;&#30340;&#27010;&#24565;&#65292;&#32473;&#20986;&#20102;&#31867;&#21035;&#30340;&#25351;&#25968;&#21644;&#32447;&#24615;&#36895;&#29575;&#30340;&#21028;&#21035;&#26465;&#20214;&#65292;&#24182;&#35777;&#26126;&#20102;&#24403;&#26631;&#31614;&#25968;&#26080;&#38480;&#26102;&#65292;&#36895;&#29575;&#23558;&#21464;&#24930;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22810;&#31867;&#20998;&#31867;&#30340;&#36890;&#29992;&#36895;&#29575;&#65292;&#30830;&#23450;&#20102;&#25152;&#26377;&#20551;&#35774;&#31867;&#30340;&#26368;&#20248;&#36895;&#29575;&#65288;&#26368;&#22810;&#23545;&#25968;&#22240;&#23376;&#65289;&#12290;&#36825;&#25512;&#24191;&#20102;&#20043;&#21069;&#20851;&#20110;&#20108;&#20803;&#20998;&#31867;&#30340;&#32467;&#26524;&#65292;&#24182;&#35299;&#20915;&#20102;&#30001;Kalavasis&#12289;Velegkas&#21644;Karbasi&#65288;2022&#24180;&#65289;&#30740;&#31350;&#30340;&#20855;&#26377;&#26377;&#38480;&#26631;&#31614;&#25968;&#30340;&#22810;&#31867;&#35774;&#32622;&#20013;&#30340;&#19968;&#20010;&#24320;&#25918;&#38382;&#39064;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#36866;&#29992;&#20110;&#20219;&#20309;&#21487;&#25968;&#30340;&#26631;&#31614;&#31354;&#38388;&#12290;&#21363;&#20351;&#23545;&#20110;&#26377;&#38480;&#30340;&#26631;&#31614;&#31354;&#38388;&#65292;&#25105;&#20204;&#30340;&#35777;&#26126;&#20063;&#33021;&#25552;&#20379;&#26356;&#31934;&#30830;&#30340;&#23398;&#20064;&#26354;&#32447;&#19978;&#30028;&#65292;&#22240;&#20026;&#23427;&#20204;&#19981;&#20381;&#36182;&#20110;&#26631;&#31614;&#25968;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#35777;&#26126;&#20219;&#20309;&#31867;&#21035;&#21482;&#26377;&#24403;&#23427;&#27809;&#26377;&#26080;&#38480;&#30340;Littlestone&#26641;&#26102;&#25165;&#20855;&#26377;&#25351;&#25968;&#36895;&#29575;&#65292;&#32780;&#21482;&#26377;&#24403;&#23427;&#27809;&#26377;&#26080;&#38480;&#30340;Daniely-Shalev-Shwartz-Littleston&#65288;DSL&#65289;&#26641;&#26102;&#25165;&#20855;&#26377;&#65288;&#36817;&#20284;&#65289;&#32447;&#24615;&#36895;&#29575;&#65292;&#21542;&#21017;&#23601;&#38656;&#35201;&#20219;&#24847;&#24930;&#30340;&#36895;&#29575;&#12290;DSL&#26641;&#26159;&#25105;&#20204;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#23450;&#20041;&#30340;&#19968;&#31181;&#26032;&#32467;&#26500;&#65292;&#20854;&#20013;&#26641;&#30340;&#27599;&#20010;&#33410;&#28857;&#30001;&#19968;&#20010;&#20266;&#31435;&#26041;&#20307;&#32473;&#20986;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study universal rates for multiclass classification, establishing the optimal rates (up to log factors) for all hypothesis classes. This generalizes previous results on binary classification (Bousquet, Hanneke, Moran, van Handel, and Yehudayoff, 2021), and resolves an open question studied by Kalavasis, Velegkas, and Karbasi (2022) who handled the multiclass setting with a bounded number of class labels. In contrast, our result applies for any countable label space. Even for finite label space, our proofs provide a more precise bounds on the learning curves, as they do not depend on the number of labels. Specifically, we show that any class admits exponential rates if and only if it has no infinite Littlestone tree, and admits (near-)linear rates if and only if it has no infinite Daniely-Shalev-Shwartz-Littleston (DSL) tree, and otherwise requires arbitrarily slow rates. DSL trees are a new structure we define in this work, in which each node of the tree is given by a pseudo-cube of
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#31561;&#28183;&#24615;&#30340;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#26041;&#27861;&#65292;&#36890;&#36807;&#36870;&#25193;&#25955;&#36807;&#31243;&#23454;&#29616;&#20102;&#26032;&#39062;&#30340;&#21518;&#39564;&#37319;&#26679;&#31639;&#27861;&#65292;&#22312;&#39640;&#32500;&#37319;&#26679;&#20013;&#34920;&#29616;&#20986;&#26356;&#20248;&#36234;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.02037</link><description>&lt;p&gt;
&#26080;&#31561;&#28183;&#24615;&#30340;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#65306;&#19968;&#31181;&#36870;&#25193;&#25955;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Monte Carlo Sampling without Isoperimetry: A Reverse Diffusion Approach. (arXiv:2307.02037v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02037
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#31561;&#28183;&#24615;&#30340;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#26041;&#27861;&#65292;&#36890;&#36807;&#36870;&#25193;&#25955;&#36807;&#31243;&#23454;&#29616;&#20102;&#26032;&#39062;&#30340;&#21518;&#39564;&#37319;&#26679;&#31639;&#27861;&#65292;&#22312;&#39640;&#32500;&#37319;&#26679;&#20013;&#34920;&#29616;&#20986;&#26356;&#20248;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#29983;&#25104;&#27169;&#22411;&#30340;&#26377;&#25928;&#24615;&#36890;&#24120;&#21462;&#20915;&#20110;&#25193;&#25955;&#36335;&#24452;&#19978;&#24471;&#20998;&#20272;&#35745;&#30340;&#31934;&#24230;&#65292;&#37325;&#28857;&#20851;&#27880;&#25193;&#25955;&#27169;&#22411;&#21450;&#20854;&#29983;&#25104;&#39640;&#36136;&#37327;&#25968;&#25454;&#26679;&#26412;&#30340;&#33021;&#21147;&#12290;&#26412;&#30740;&#31350;&#28145;&#20837;&#25506;&#35752;&#20102;&#36890;&#36807;&#36870;&#25193;&#25955;&#36827;&#34892;&#21518;&#39564;&#37319;&#26679;&#30340;&#28508;&#21147;&#12290;&#36890;&#36807;&#23545;&#37319;&#26679;&#25991;&#29486;&#36827;&#34892;&#30740;&#31350;&#65292;&#21457;&#29616;&#21487;&#20197;&#36890;&#36807;&#36716;&#31227;&#26680;&#30340;&#20998;&#35299;&#23558;&#24471;&#20998;&#20272;&#35745;&#36716;&#21270;&#20026;&#22343;&#20540;&#20272;&#35745;&#38382;&#39064;&#12290;&#36890;&#36807;&#20272;&#35745;&#36741;&#21161;&#20998;&#24067;&#30340;&#22343;&#20540;&#65292;&#36870;&#25193;&#25955;&#36807;&#31243;&#21487;&#20197;&#20135;&#29983;&#19968;&#31181;&#26032;&#39062;&#30340;&#21518;&#39564;&#37319;&#26679;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#19982;&#20256;&#32479;&#30340;&#22522;&#20110;&#26799;&#24230;&#30340;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#65288;MCMC&#65289;&#26041;&#27861;&#19981;&#21516;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#24635;&#21464;&#24046;&#36317;&#31163;&#19979;&#30340;&#25910;&#25947;&#20998;&#26512;&#65292;&#24182;&#35777;&#26126;&#20102;&#25152;&#25552;&#31639;&#27861;&#30340;&#31561;&#28183;&#24615;&#20381;&#36182;&#24615;&#30456;&#23545;&#36739;&#20302;&#65292;&#27604;&#20256;&#32479;&#30340;MCMC&#25216;&#26415;&#34920;&#29616;&#20986;&#26356;&#39640;&#30340;&#39640;&#32500;&#37319;&#26679;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
The efficacy of modern generative models is commonly contingent upon the precision of score estimation along the diffusion path, with a focus on diffusion models and their ability to generate high-quality data samples. This study delves into the potentialities of posterior sampling through reverse diffusion. An examination of the sampling literature reveals that score estimation can be transformed into a mean estimation problem via the decomposition of the transition kernel. By estimating the mean of the auxiliary distribution, the reverse diffusion process can give rise to a novel posterior sampling algorithm, which diverges from traditional gradient-based Markov Chain Monte Carlo (MCMC) methods. We provide the convergence analysis in total variation distance and demonstrate that the isoperimetric dependency of the proposed algorithm is comparatively lower than that observed in conventional MCMC techniques, which justifies the superior performance for high dimensional sampling with er
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#24323;&#26435;&#36827;&#34892;&#25490;&#21517;&#30340;&#26032;&#26694;&#26550;&#65292;&#24182;&#23545;&#35813;&#26694;&#26550;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#29702;&#35770;&#20998;&#26512;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#25991;&#29486;&#20013;&#32473;&#20986;&#20102;&#26368;&#20808;&#36827;&#30340;&#19968;&#33268;&#24615;&#20445;&#35777;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#20272;&#35745;&#30446;&#26631;&#25439;&#22833;&#65292;&#24182;&#22312;&#20351;&#29992;&#31561;&#36830;&#32493;&#20551;&#35774;&#38598;&#26102;&#20855;&#26377;&#37325;&#35201;&#30340;&#24212;&#29992;&#20215;&#20540;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#24323;&#26435;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.02035</link><description>&lt;p&gt;
&#20351;&#29992;&#24323;&#26435;&#36827;&#34892;&#25490;&#21517;
&lt;/p&gt;
&lt;p&gt;
Ranking with Abstention. (arXiv:2307.02035v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02035
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#24323;&#26435;&#36827;&#34892;&#25490;&#21517;&#30340;&#26032;&#26694;&#26550;&#65292;&#24182;&#23545;&#35813;&#26694;&#26550;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#29702;&#35770;&#20998;&#26512;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#25991;&#29486;&#20013;&#32473;&#20986;&#20102;&#26368;&#20808;&#36827;&#30340;&#19968;&#33268;&#24615;&#20445;&#35777;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#20272;&#35745;&#30446;&#26631;&#25439;&#22833;&#65292;&#24182;&#22312;&#20351;&#29992;&#31561;&#36830;&#32493;&#20551;&#35774;&#38598;&#26102;&#20855;&#26377;&#37325;&#35201;&#30340;&#24212;&#29992;&#20215;&#20540;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#24323;&#26435;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#24323;&#26435;&#25490;&#21517;&#26694;&#26550;&#65292;&#23398;&#20064;&#32773;&#21487;&#20197;&#20197;&#26377;&#38480;&#25104;&#26412;$c$&#25918;&#24323;&#23545;&#26576;&#20123;&#25968;&#25454;&#36827;&#34892;&#39044;&#27979;&#12290;&#25105;&#20204;&#23545;&#36825;&#20010;&#26694;&#26550;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#21253;&#25324;&#32447;&#24615;&#20989;&#25968;&#26063;&#21644;&#20855;&#26377;&#19968;&#23618;&#38544;&#34255;&#23618;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#19968;&#31995;&#21015;$H$-&#19968;&#33268;&#24615;&#30028;&#38480;&#12290;&#36825;&#20123;&#29702;&#35770;&#20445;&#35777;&#26159;&#25991;&#29486;&#20013;&#26368;&#20808;&#36827;&#30340;&#19968;&#33268;&#24615;&#20445;&#35777;&#65292;&#23427;&#20204;&#26159;&#39044;&#27979;&#22120;&#22312;&#20551;&#35774;&#38598;$H$&#20013;&#30340;&#30446;&#26631;&#25439;&#22833;&#20272;&#35745;&#35823;&#24046;&#30340;&#19978;&#30028;&#65292;&#20197;&#39044;&#27979;&#22120;&#30340;&#26367;&#20195;&#25439;&#22833;&#20272;&#35745;&#35823;&#24046;&#20026;&#34920;&#36798;&#24418;&#24335;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25351;&#20986;&#65292;&#22312;&#23454;&#36341;&#20013;&#20351;&#29992;&#24120;&#35265;&#31561;&#36830;&#32493;&#20551;&#35774;&#38598;&#26102;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#24323;&#26435;&#26041;&#27861;&#26159;&#37325;&#35201;&#30340;&#12290;&#25105;&#20204;&#25253;&#21578;&#20102;&#19968;&#31995;&#21015;&#23454;&#39564;&#32467;&#26524;&#65292;&#23637;&#31034;&#20102;&#20351;&#29992;&#24323;&#26435;&#36827;&#34892;&#25490;&#21517;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a novel framework of ranking with abstention, where the learner can abstain from making prediction at some limited cost $c$. We present a extensive theoretical analysis of this framework including a series of $H$-consistency bounds for both the family of linear functions and that of neural networks with one hidden-layer. These theoretical guarantees are the state-of-the-art consistency guarantees in the literature, which are upper bounds on the target loss estimation error of a predictor in a hypothesis set $H$, expressed in terms of the surrogate loss estimation error of that predictor. We further argue that our proposed abstention methods are important when using common equicontinuous hypothesis sets in practice. We report the results of experiments illustrating the effectiveness of ranking with abstention.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20351;&#29992;&#38543;&#26426;&#25928;&#24212;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#25104;&#21151;&#35782;&#21035;&#20986;&#22312;&#25233;&#37057;&#39118;&#38505;&#26368;&#22823;&#30340;&#20122;&#32452;&#20013;&#20855;&#26377;&#26368;&#22823;&#25928;&#29992;&#30340;&#21464;&#37327;&#65292;&#24182;&#25552;&#20986;&#20102;&#30456;&#20851;&#30340;&#39044;&#27979;&#27169;&#22411;&#65292;&#21487;&#20197;&#25913;&#21892;&#25233;&#37057;&#30151;&#30340;&#20020;&#24202;&#39044;&#27979;&#21644;&#27835;&#30103;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2307.02023</link><description>&lt;p&gt;
&#20351;&#29992;&#38543;&#26426;&#25928;&#24212;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#35782;&#21035;&#25233;&#37057;&#30340;&#26131;&#24863;&#24615;
&lt;/p&gt;
&lt;p&gt;
Using Random Effects Machine Learning Algorithms to Identify Vulnerability to Depression. (arXiv:2307.02023v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02023
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20351;&#29992;&#38543;&#26426;&#25928;&#24212;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#25104;&#21151;&#35782;&#21035;&#20986;&#22312;&#25233;&#37057;&#39118;&#38505;&#26368;&#22823;&#30340;&#20122;&#32452;&#20013;&#20855;&#26377;&#26368;&#22823;&#25928;&#29992;&#30340;&#21464;&#37327;&#65292;&#24182;&#25552;&#20986;&#20102;&#30456;&#20851;&#30340;&#39044;&#27979;&#27169;&#22411;&#65292;&#21487;&#20197;&#25913;&#21892;&#25233;&#37057;&#30151;&#30340;&#20020;&#24202;&#39044;&#27979;&#21644;&#27835;&#30103;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32972;&#26223;&#65306;&#21487;&#38752;&#22320;&#39044;&#27979;&#25233;&#37057;&#30151;&#30340;&#20020;&#24202;&#36827;&#23637;&#21487;&#20197;&#25913;&#21892;&#27835;&#30103;&#25928;&#26524;&#12290;&#30446;&#21069;&#24456;&#23569;&#26377;&#30740;&#31350;&#23558;&#19981;&#21516;&#30340;&#25233;&#37057;&#30151;&#39118;&#38505;&#22240;&#32032;&#25972;&#21512;&#36215;&#26469;&#65292;&#20197;&#30830;&#23450;&#21738;&#20123;&#22240;&#32032;&#30340;&#32452;&#21512;&#23545;&#20110;&#30830;&#23450;&#21738;&#20123;&#20010;&#20307;&#26368;&#20855;&#39118;&#38505;&#20855;&#26377;&#26368;&#22823;&#25928;&#29992;&#12290;&#26041;&#27861;&#65306;&#26412;&#30740;&#31350;&#35777;&#26126;&#20102;&#25968;&#25454;&#39537;&#21160;&#30340;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#26041;&#27861;&#65292;&#22914;RE-EM&#65288;&#38543;&#26426;&#25928;&#24212;/&#26368;&#22823;&#26399;&#26395;&#65289;&#26641;&#21644;MERF&#65288;&#28151;&#21512;&#25928;&#24212;&#38543;&#26426;&#26862;&#26519;&#65289;&#21487;&#20197;&#24212;&#29992;&#20110;&#21487;&#38752;&#22320;&#35782;&#21035;&#22312;&#25233;&#37057;&#39118;&#38505;&#26368;&#22823;&#30340;&#20122;&#32452;&#20013;&#20855;&#26377;&#26368;&#22823;&#25928;&#29992;&#30340;&#21464;&#37327;&#12290;185&#21517;&#24180;&#36731;&#25104;&#20154;&#21442;&#19982;&#20102;&#20851;&#20110;&#25233;&#37057;&#39118;&#38505;&#30340;&#27979;&#37327;&#65292;&#21253;&#25324;&#21453;&#21005;&#12289;&#25285;&#24551;&#12289;&#28040;&#26497;&#35748;&#30693;&#39118;&#26684;&#12289;&#35748;&#30693;&#21644;&#24212;&#23545;&#28789;&#27963;&#24615;&#20197;&#21450;&#28040;&#26497;&#29983;&#27963;&#20107;&#20214;&#65292;&#20197;&#21450;&#25233;&#37057;&#30151;&#29366;&#12290;&#25105;&#20204;&#35757;&#32451;&#20102;RE-EM&#26641;&#21644;MERF&#31639;&#27861;&#65292;&#24182;&#23558;&#23427;&#20204;&#19982;&#20256;&#32479;&#30340;&#32447;&#24615;&#28151;&#21512;&#27169;&#22411;&#65288;LMMs&#65289;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#29992;&#20110;&#39044;&#27979;&#25233;&#37057;&#30151;&#29366;&#30340;&#21069;&#30651;&#24615;&#21644;&#21516;&#26102;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Background: Reliable prediction of clinical progression over time can improve the outcomes of depression. Little work has been done integrating various risk factors for depression, to determine the combinations of factors with the greatest utility for identifying which individuals are at the greatest risk. Method: This study demonstrates that data-driven machine learning (ML) methods such as RE-EM (Random Effects/Expectation Maximization) trees and MERF (Mixed Effects Random Forest) can be applied to reliably identify variables that have the greatest utility for classifying subgroups at greatest risk for depression. 185 young adults completed measures of depression risk, including rumination, worry, negative cognitive styles, cognitive and coping flexibilities, and negative life events, along with symptoms of depression. We trained RE-EM trees and MERF algorithms and compared them to traditional linear mixed models (LMMs) predicting depressive symptoms prospectively and concurrently wi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27491;&#21017;&#21270;&#30340;EM&#31639;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#23567;&#26679;&#26412;&#37327;&#19979;&#35745;&#31639;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#32553;&#23567;&#20272;&#35745;&#20540;&#21521;&#30446;&#26631;&#21327;&#26041;&#24046;&#30697;&#38453;&#25910;&#32553;&#30340;&#26041;&#24335;&#26469;&#35299;&#20915;&#21327;&#26041;&#24046;&#30697;&#38453;&#22855;&#24322;&#25110;&#26465;&#20214;&#36739;&#24046;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.01955</link><description>&lt;p&gt;
&#27491;&#21017;&#21270;&#30340;EM&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Algorithme EM r\'egularis\'e. (arXiv:2307.01955v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01955
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27491;&#21017;&#21270;&#30340;EM&#31639;&#27861;&#65292;&#29992;&#20110;&#22788;&#29702;&#23567;&#26679;&#26412;&#37327;&#19979;&#35745;&#31639;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#32553;&#23567;&#20272;&#35745;&#20540;&#21521;&#30446;&#26631;&#21327;&#26041;&#24046;&#30697;&#38453;&#25910;&#32553;&#30340;&#26041;&#24335;&#26469;&#35299;&#20915;&#21327;&#26041;&#24046;&#30697;&#38453;&#22855;&#24322;&#25110;&#26465;&#20214;&#36739;&#24046;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26399;&#26395;&#26368;&#22823;&#21270;(EM)&#31639;&#27861;&#26159;&#19968;&#31181;&#24191;&#27867;&#29992;&#20110;&#35745;&#31639;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;(GMM)&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#36845;&#20195;&#31639;&#27861;&#12290;&#24403;&#26679;&#26412;&#37327;&#23567;&#20110;&#25968;&#25454;&#32500;&#24230;&#26102;&#65292;&#21487;&#33021;&#23548;&#33268;&#22855;&#24322;&#25110;&#26465;&#20214;&#36739;&#24046;&#30340;&#21327;&#26041;&#24046;&#30697;&#38453;&#65292;&#20174;&#32780;&#38477;&#20302;&#24615;&#33021;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#27491;&#21017;&#21270;&#30340;EM&#31639;&#27861;&#65292;&#23427;&#26377;&#25928;&#22320;&#21033;&#29992;&#20808;&#39564;&#30693;&#35782;&#26469;&#22788;&#29702;&#23567;&#26679;&#26412;&#37327;&#12290;&#35813;&#26041;&#27861;&#26088;&#22312;&#36890;&#36807;&#32553;&#23567;&#20272;&#35745;&#20540;&#21521;&#26576;&#20123;&#32467;&#26500;&#21270;&#30446;&#26631;&#21327;&#26041;&#24046;&#30697;&#38453;&#25910;&#32553;&#30340;&#26041;&#24335;&#26469;&#26368;&#22823;&#21270;&#32602;&#20989;&#25968;GMM&#20284;&#28982;&#24230;&#65292;&#20197;&#30830;&#20445;&#21327;&#26041;&#24046;&#30697;&#38453;&#26356;&#26032;&#30340;&#27491;&#23450;&#24615;&#12290;&#26368;&#21518;&#65292;&#23545;&#30495;&#23454;&#25968;&#25454;&#30340;&#23454;&#39564;&#32467;&#26524;&#31361;&#20986;&#20102;&#25152;&#25552;&#31639;&#27861;&#22312;&#32858;&#31867;&#30446;&#30340;&#19979;&#30340;&#33391;&#22909;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Expectation-Maximization (EM) algorithm is a widely used iterative algorithm for computing maximum likelihood estimate when dealing with Gaussian Mixture Model (GMM). When the sample size is smaller than the data dimension, this could lead to a singular or poorly conditioned covariance matrix and, thus, to performance reduction. This paper presents a regularized version of the EM algorithm that efficiently uses prior knowledge to cope with a small sample size. This method aims to maximize a penalized GMM likelihood where regularized estimation may ensure positive definiteness of covariance matrix updates by shrinking the estimators towards some structured target covariance matrices. Finally, experiments on real data highlight the good performance of the proposed algorithm for clustering purposes
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#31283;&#20581;&#19988;&#28789;&#27963;&#30340;&#20998;&#31867;&#26041;&#27861;FEMDA&#65292;&#33021;&#22815;&#22788;&#29702;&#38750;&#39640;&#26031;&#20998;&#24067;&#21644;/&#25110;&#21463;&#27745;&#26579;&#30340;&#25968;&#25454;&#38598;&#65292;&#24182;&#33021;&#22815;&#31283;&#20581;&#22320;&#23545;&#25968;&#25454;&#20013;&#30340;&#23610;&#24230;&#21464;&#21270;&#36827;&#34892;&#20998;&#31867;&#12290;</title><link>http://arxiv.org/abs/2307.01954</link><description>&lt;p&gt;
FEMDA: &#19968;&#31181;&#31283;&#20581;&#19988;&#28789;&#27963;&#30340;&#20998;&#31867;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
FEMDA: Une m\'ethode de classification robuste et flexible. (arXiv:2307.01954v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01954
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#31283;&#20581;&#19988;&#28789;&#27963;&#30340;&#20998;&#31867;&#26041;&#27861;FEMDA&#65292;&#33021;&#22815;&#22788;&#29702;&#38750;&#39640;&#26031;&#20998;&#24067;&#21644;/&#25110;&#21463;&#27745;&#26579;&#30340;&#25968;&#25454;&#38598;&#65292;&#24182;&#33021;&#22815;&#31283;&#20581;&#22320;&#23545;&#25968;&#25454;&#20013;&#30340;&#23610;&#24230;&#21464;&#21270;&#36827;&#34892;&#20998;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32447;&#24615;&#21028;&#21035;&#20998;&#26512;(LDA)&#21644;&#20108;&#27425;&#21028;&#21035;&#20998;&#26512;(QDA)&#26159;&#20247;&#25152;&#21608;&#30693;&#30340;&#32463;&#20856;&#26041;&#27861;&#65292;&#20294;&#22312;&#38750;&#39640;&#26031;&#20998;&#24067;&#21644;/&#25110;&#21463;&#27745;&#26579;&#30340;&#25968;&#25454;&#38598;&#20013;&#21487;&#33021;&#21463;&#21040;&#20005;&#37325;&#24433;&#21709;&#65292;&#20027;&#35201;&#26159;&#22240;&#20026;&#24213;&#23618;&#39640;&#26031;&#20551;&#35774;&#19981;&#20855;&#22791;&#31283;&#20581;&#24615;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#26032;&#30340;&#21028;&#21035;&#20998;&#26512;&#25216;&#26415;&#23545;&#25968;&#25454;&#23610;&#24230;&#21464;&#21270;&#30340;&#31283;&#20581;&#24615;&#65292;&#20854;&#20013;&#27599;&#20010;&#25968;&#25454;&#28857;&#30001;&#33258;&#24049;&#30340;&#20219;&#24847;&#26925;&#29699;&#23545;&#31216;(ES)&#20998;&#24067;&#21644;&#33258;&#24049;&#30340;&#20219;&#24847;&#23610;&#24230;&#21442;&#25968;&#32472;&#21046;&#12290;&#36825;&#31181;&#27169;&#22411;&#20801;&#35768;&#21487;&#33021;&#38750;&#24120;&#24322;&#36136;&#12289;&#29420;&#31435;&#20294;&#19981;&#21516;&#20998;&#24067;&#30340;&#26679;&#26412;&#12290;&#19982;&#20854;&#20182;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#30456;&#27604;&#65292;&#25152;&#24471;&#21040;&#30340;&#26032;&#30340;&#20915;&#31574;&#35268;&#21017;&#31616;&#21333;&#12289;&#24555;&#36895;&#19988;&#23545;&#25968;&#25454;&#20013;&#30340;&#23610;&#24230;&#21464;&#21270;&#20855;&#26377;&#31283;&#20581;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Linear and Quadratic Discriminant Analysis (LDA and QDA) are well-known classical methods but can heavily suffer from non-Gaussian distributions and/or contaminated datasets, mainly because of the underlying Gaussian assumption that is not robust. This paper studies the robustness to scale changes in the data of a new discriminant analysis technique where each data point is drawn by its own arbitrary Elliptically Symmetrical (ES) distribution and its own arbitrary scale parameter. Such a model allows for possibly very heterogeneous, independent but non-identically distributed samples. The new decision rule derived is simple, fast, and robust to scale changes in the data compared to other state-of-the-art method
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20197;&#33410;&#28857;&#20998;&#31867;&#20026;&#20363;&#65292;&#36890;&#36807;&#8220;&#31070;&#32463;&#22604;&#38519;&#8221;&#29616;&#35937;&#25506;&#32034;&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#29305;&#24449;&#28436;&#21270;&#30340;&#26426;&#21046;&#65292;&#24182;&#21457;&#29616;&#21363;&#20351;&#22312;&#33410;&#28857;&#20998;&#31867;&#24773;&#20917;&#19979;&#65292;&#29305;&#24449;&#30340;&#31867;&#20869;&#21464;&#24322;&#24615;&#20063;&#20250;&#20943;&#23569;&#65292;&#20294;&#19981;&#21450;&#22522;&#20110;&#23454;&#20363;&#30340;&#24773;&#20917;&#37027;&#20040;&#26174;&#33879;&#12290;</title><link>http://arxiv.org/abs/2307.01951</link><description>&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#29305;&#24449;&#28436;&#21270;&#30340;&#31070;&#32463;&#22604;&#38519;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
A Neural Collapse Perspective on Feature Evolution in Graph Neural Networks. (arXiv:2307.01951v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01951
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20197;&#33410;&#28857;&#20998;&#31867;&#20026;&#20363;&#65292;&#36890;&#36807;&#8220;&#31070;&#32463;&#22604;&#38519;&#8221;&#29616;&#35937;&#25506;&#32034;&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#29305;&#24449;&#28436;&#21270;&#30340;&#26426;&#21046;&#65292;&#24182;&#21457;&#29616;&#21363;&#20351;&#22312;&#33410;&#28857;&#20998;&#31867;&#24773;&#20917;&#19979;&#65292;&#29305;&#24449;&#30340;&#31867;&#20869;&#21464;&#24322;&#24615;&#20063;&#20250;&#20943;&#23569;&#65292;&#20294;&#19981;&#21450;&#22522;&#20110;&#23454;&#20363;&#30340;&#24773;&#20917;&#37027;&#20040;&#26174;&#33879;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#22312;&#22270;&#32467;&#26500;&#25968;&#25454;&#30340;&#20998;&#31867;&#20219;&#21153;&#20013;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#12290;&#28982;&#32780;&#65292;GNNs&#20013;&#22270;&#25299;&#25169;&#21644;&#29305;&#24449;&#28436;&#21270;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#23578;&#19981;&#28165;&#26970;&#12290;&#26412;&#25991;&#20197;&#22522;&#20110;&#33410;&#28857;&#30340;&#20998;&#31867;&#20026;&#20027;&#39064;&#65292;&#20197;&#38543;&#26426;&#22359;&#27169;&#22411;&#22270;&#19978;&#30340;&#31038;&#21306;&#26816;&#27979;&#20026;&#20363;&#65292;&#36890;&#36807;&#8220;&#31070;&#32463;&#22604;&#38519;&#8221;&#29616;&#35937;&#26469;&#25506;&#32034;&#29305;&#24449;&#28436;&#21270;&#12290;&#24403;&#35757;&#32451;&#22522;&#20110;&#23454;&#20363;&#30340;&#28145;&#24230;&#20998;&#31867;&#22120;&#65288;&#20363;&#22914;&#22270;&#20687;&#20998;&#31867;&#65289;&#36229;&#36807;&#38646;&#35757;&#32451;&#35823;&#24046;&#28857;&#26102;&#65292;&#31070;&#32463;&#22604;&#38519;&#34920;&#29616;&#20026;&#26368;&#28145;&#23618;&#29305;&#24449;&#30340;&#31867;&#20869;&#21464;&#24322;&#24615;&#20943;&#23569;&#65292;&#24182;&#19988;&#31867;&#22343;&#20540;&#19982;&#29305;&#23450;&#30340;&#23545;&#31216;&#32467;&#26500;&#26356;&#21152;&#23545;&#40784;&#12290;&#25105;&#20204;&#20808;&#20174;&#23454;&#35777;&#30740;&#31350;&#24320;&#22987;&#65292;&#26174;&#31034;&#31867;&#20869;&#21464;&#24322;&#24615;&#30340;&#20943;&#23569;&#22312;&#22522;&#20110;&#33410;&#28857;&#30340;&#20998;&#31867;&#29615;&#22659;&#20013;&#20063;&#26222;&#36941;&#23384;&#22312;&#65292;&#20294;&#19981;&#21450;&#22522;&#20110;&#23454;&#20363;&#30340;&#26696;&#20363;&#37027;&#20040;&#26126;&#26174;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#20174;&#29702;&#35770;&#19978;&#30740;&#31350;&#20102;&#36825;&#31181;&#21306;&#21035;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21363;&#20351;&#22312;&#19981;&#32771;&#34385;&#28608;&#27963;&#65292;&#22270;&#25299;&#25169;&#20449;&#24687;&#20063;&#33021;&#23548;&#33268;&#29305;&#24449;&#23849;&#28291;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph neural networks (GNNs) have become increasingly popular for classification tasks on graph-structured data. Yet, the interplay between graph topology and feature evolution in GNNs is not well understood. In this paper, we focus on node-wise classification, illustrated with community detection on stochastic block model graphs, and explore the feature evolution through the lens of the "Neural Collapse" (NC) phenomenon. When training instance-wise deep classifiers (e.g. for image classification) beyond the zero training error point, NC demonstrates a reduction in the deepest features' within-class variability and an increased alignment of their class means to certain symmetric structures. We start with an empirical study that shows that a decrease in within-class variability is also prevalent in the node-wise classification setting, however, not to the extent observed in the instance-wise case. Then, we theoretically study this distinction. Specifically, we show that even an "optimis
&lt;/p&gt;</description></item><item><title>MDI+&#26159;&#19968;&#31181;&#28789;&#27963;&#30340;&#22522;&#20110;&#38543;&#26426;&#26862;&#26519;&#30340;&#29305;&#24449;&#37325;&#35201;&#24615;&#26694;&#26550;&#65292;&#36890;&#36807;&#26367;&#25442;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#21644;&#24230;&#37327;&#65292;&#21033;&#29992;&#27491;&#21017;&#21270;&#30340;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#21644;&#26356;&#36866;&#21512;&#25968;&#25454;&#32467;&#26500;&#30340;&#24230;&#37327;&#26469;&#25512;&#24191;MDI&#12290;&#27492;&#22806;&#65292;MDI+&#36824;&#24341;&#20837;&#20102;&#20854;&#20182;&#29305;&#24449;&#26469;&#20943;&#36731;&#20915;&#31574;&#26641;&#23545;&#21152;&#27861;&#25110;&#24179;&#28369;&#27169;&#22411;&#30340;&#24050;&#30693;&#20559;&#24046;&#12290;</title><link>http://arxiv.org/abs/2307.01932</link><description>&lt;p&gt;
MDI+:&#19968;&#31181;&#28789;&#27963;&#30340;&#22522;&#20110;&#38543;&#26426;&#26862;&#26519;&#30340;&#29305;&#24449;&#37325;&#35201;&#24615;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
MDI+: A Flexible Random Forest-Based Feature Importance Framework. (arXiv:2307.01932v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01932
&lt;/p&gt;
&lt;p&gt;
MDI+&#26159;&#19968;&#31181;&#28789;&#27963;&#30340;&#22522;&#20110;&#38543;&#26426;&#26862;&#26519;&#30340;&#29305;&#24449;&#37325;&#35201;&#24615;&#26694;&#26550;&#65292;&#36890;&#36807;&#26367;&#25442;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#21644;&#24230;&#37327;&#65292;&#21033;&#29992;&#27491;&#21017;&#21270;&#30340;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#21644;&#26356;&#36866;&#21512;&#25968;&#25454;&#32467;&#26500;&#30340;&#24230;&#37327;&#26469;&#25512;&#24191;MDI&#12290;&#27492;&#22806;&#65292;MDI+&#36824;&#24341;&#20837;&#20102;&#20854;&#20182;&#29305;&#24449;&#26469;&#20943;&#36731;&#20915;&#31574;&#26641;&#23545;&#21152;&#27861;&#25110;&#24179;&#28369;&#27169;&#22411;&#30340;&#24050;&#30693;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20197;&#19981;&#32431;&#24230;&#20943;&#23569;&#30340;&#24179;&#22343;&#20540;(MDI)&#26159;&#38543;&#26426;&#26862;&#26519;(RF)&#20013;&#19968;&#31181;&#27969;&#34892;&#30340;&#29305;&#24449;&#37325;&#35201;&#24615;&#35780;&#20272;&#26041;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;RF&#20013;&#27599;&#20010;&#26641;&#30340;&#29305;&#24449;$X_k$&#30340;MDI&#31561;&#20215;&#20110;&#21709;&#24212;&#21464;&#37327;&#22312;&#20915;&#31574;&#26641;&#38598;&#21512;&#19978;&#30340;&#32447;&#24615;&#22238;&#24402;&#30340;&#26410;&#24402;&#19968;&#21270;$R^2$&#20540;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#31181;&#35299;&#37322;&#25552;&#20986;&#20102;&#19968;&#31181;&#28789;&#27963;&#30340;&#29305;&#24449;&#37325;&#35201;&#24615;&#26694;&#26550;MDI+&#65292;MDI+&#36890;&#36807;&#20801;&#35768;&#20998;&#26512;&#20154;&#21592;&#23558;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#21644;$R^2$&#24230;&#37327;&#26367;&#25442;&#20026;&#27491;&#21017;&#21270;&#30340;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;(GLM)&#21644;&#26356;&#36866;&#21512;&#32473;&#23450;&#25968;&#25454;&#32467;&#26500;&#30340;&#24230;&#37327;&#26469;&#25512;&#24191;MDI&#12290;&#27492;&#22806;&#65292;MDI+&#36824;&#24341;&#20837;&#20102;&#20854;&#20182;&#29305;&#24449;&#26469;&#20943;&#36731;&#20915;&#31574;&#26641;&#23545;&#21152;&#27861;&#25110;&#24179;&#28369;&#27169;&#22411;&#30340;&#24050;&#30693;&#20559;&#24046;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20379;&#20102;&#20851;&#20110;&#22914;&#20309;&#22522;&#20110;&#21487;&#39044;&#27979;&#24615;&#12289;&#21487;&#35745;&#31639;&#24615;&#21644;&#31283;&#23450;&#24615;&#26694;&#26550;&#36873;&#25321;&#36866;&#24403;&#30340;GLM&#21644;&#24230;&#37327;&#30340;&#25351;&#23548;&#65292;&#20197;&#36827;&#34892;&#30495;&#23454;&#25968;&#25454;&#31185;&#23398;&#30740;&#31350;&#12290;&#22823;&#37327;&#22522;&#20110;&#25968;&#25454;&#30340;&#27169;&#25311;&#32467;&#26524;&#26174;&#31034;&#65292;MDI+&#22312;&#24615;&#33021;&#19978;&#26174;&#33879;&#20248;&#20110;&#20256;&#32479;&#30340;MDI&#12290;
&lt;/p&gt;
&lt;p&gt;
Mean decrease in impurity (MDI) is a popular feature importance measure for random forests (RFs). We show that the MDI for a feature $X_k$ in each tree in an RF is equivalent to the unnormalized $R^2$ value in a linear regression of the response on the collection of decision stumps that split on $X_k$. We use this interpretation to propose a flexible feature importance framework called MDI+. Specifically, MDI+ generalizes MDI by allowing the analyst to replace the linear regression model and $R^2$ metric with regularized generalized linear models (GLMs) and metrics better suited for the given data structure. Moreover, MDI+ incorporates additional features to mitigate known biases of decision trees against additive or smooth models. We further provide guidance on how practitioners can choose an appropriate GLM and metric based upon the Predictability, Computability, Stability framework for veridical data science. Extensive data-inspired simulations show that MDI+ significantly outperfor
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#29983;&#25104;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#34920;&#31034;&#30340;&#26032;&#26041;&#27861;&#65292;&#20381;&#38752;&#29702;&#35770;&#29289;&#29702;&#30340;&#24605;&#24819;&#20197;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#24335;&#26500;&#24314;&#32039;&#20945;&#30340;&#34920;&#31034;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#25429;&#25417;&#25968;&#25454;&#30340;&#22522;&#26412;&#32467;&#26500;&#21644;&#20219;&#21153;&#29305;&#23450;&#20449;&#24687;&#65292;&#21516;&#26102;&#20445;&#25345;&#30452;&#35266;&#12289;&#21487;&#35299;&#37322;&#21644;&#21487;&#39564;&#35777;&#24615;&#65292;&#24182;&#21487;&#20197;&#22312;&#24191;&#20041;&#35774;&#32622;&#20013;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2307.01930</link><description>&lt;p&gt;
&#23398;&#20064;ECG&#20449;&#21495;&#29305;&#24449;&#30340;&#38750;&#21453;&#21521;&#20256;&#25773;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Learning ECG signal features without backpropagation. (arXiv:2307.01930v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01930
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#29983;&#25104;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#34920;&#31034;&#30340;&#26032;&#26041;&#27861;&#65292;&#20381;&#38752;&#29702;&#35770;&#29289;&#29702;&#30340;&#24605;&#24819;&#20197;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#24335;&#26500;&#24314;&#32039;&#20945;&#30340;&#34920;&#31034;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#25429;&#25417;&#25968;&#25454;&#30340;&#22522;&#26412;&#32467;&#26500;&#21644;&#20219;&#21153;&#29305;&#23450;&#20449;&#24687;&#65292;&#21516;&#26102;&#20445;&#25345;&#30452;&#35266;&#12289;&#21487;&#35299;&#37322;&#21644;&#21487;&#39564;&#35777;&#24615;&#65292;&#24182;&#21487;&#20197;&#22312;&#24191;&#20041;&#35774;&#32622;&#20013;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34920;&#31034;&#23398;&#20064;&#24050;&#32463;&#25104;&#20026;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#30340;&#19968;&#20010;&#20851;&#38190;&#30740;&#31350;&#39046;&#22495;&#65292;&#23427;&#26088;&#22312;&#21457;&#29616;&#29992;&#20110;&#25552;&#39640;&#20998;&#31867;&#21644;&#39044;&#27979;&#31561;&#19979;&#28216;&#20219;&#21153;&#30340;&#21407;&#22987;&#25968;&#25454;&#30340;&#26377;&#25928;&#29305;&#24449;&#30340;&#26377;&#25928;&#26041;&#27861;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#29983;&#25104;&#26102;&#38388;&#24207;&#21015;&#31867;&#22411;&#25968;&#25454;&#34920;&#31034;&#30340;&#26032;&#26041;&#27861;&#12290;&#36825;&#31181;&#26041;&#27861;&#20381;&#38752;&#29702;&#35770;&#29289;&#29702;&#30340;&#24605;&#24819;&#20197;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#24335;&#26500;&#24314;&#32039;&#20945;&#30340;&#34920;&#31034;&#65292;&#24182;&#21487;&#20197;&#25429;&#25417;&#21040;&#25968;&#25454;&#30340;&#22522;&#26412;&#32467;&#26500;&#21644;&#20219;&#21153;&#29305;&#23450;&#20449;&#24687;&#65292;&#21516;&#26102;&#20445;&#25345;&#30452;&#35266;&#12289;&#21487;&#35299;&#37322;&#21644;&#21487;&#39564;&#35777;&#24615;&#12290;&#36825;&#20010;&#26032;&#26041;&#27861;&#26088;&#22312;&#35782;&#21035;&#33021;&#22815;&#26377;&#25928;&#25429;&#25417;&#23646;&#20110;&#29305;&#23450;&#31867;&#21035;&#30340;&#26679;&#26412;&#20043;&#38388;&#20849;&#20139;&#29305;&#24449;&#30340;&#32447;&#24615;&#35268;&#24459;&#12290;&#36890;&#36807;&#38543;&#21518;&#21033;&#29992;&#36825;&#20123;&#35268;&#24459;&#22312;&#21069;&#21521;&#26041;&#24335;&#19979;&#29983;&#25104;&#19968;&#20010;&#19982;&#20998;&#31867;&#22120;&#26080;&#20851;&#30340;&#34920;&#31034;&#65292;&#23427;&#20204;&#21487;&#20197;&#22312;&#24191;&#20041;&#35774;&#32622;&#20013;&#24212;&#29992;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Representation learning has become a crucial area of research in machine learning, as it aims to discover efficient ways of representing raw data with useful features to increase the effectiveness, scope and applicability of downstream tasks such as classification and prediction. In this paper, we propose a novel method to generate representations for time series-type data. This method relies on ideas from theoretical physics to construct a compact representation in a data-driven way, and it can capture both the underlying structure of the data and task-specific information while still remaining intuitive, interpretable and verifiable. This novel methodology aims to identify linear laws that can effectively capture a shared characteristic among samples belonging to a specific class. By subsequently utilizing these laws to generate a classifier-agnostic representation in a forward manner, they become applicable in a generalized setting. We demonstrate the effectiveness of our approach o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#35745;&#31639;&#26368;&#20248;&#36755;&#36816;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20999;&#29255;Wasserstein&#24191;&#20041;&#27979;&#22320;&#32447;&#36827;&#34892;&#36817;&#20284;&#65292;&#24471;&#21040;&#20102;&#19968;&#20010;&#22522;&#20110;&#19968;&#32500;&#26368;&#20248;&#25237;&#24433;&#30340;&#20195;&#29702;&#36317;&#31163;min-SWGG&#65292;&#24182;&#25552;&#20379;&#20102;&#30456;&#20851;&#30340;&#20256;&#36755;&#35745;&#21010;&#12290;&#36825;&#31181;&#26041;&#27861;&#20855;&#26377;&#36739;&#20302;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#36866;&#29992;&#20110;&#20248;&#21270;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.01770</link><description>&lt;p&gt;
&#24555;&#36895;&#36890;&#36807;&#20999;&#29255;Wasserstein&#24191;&#20041;&#27979;&#22320;&#32447;&#23454;&#29616;&#26368;&#20248;&#36755;&#36816;
&lt;/p&gt;
&lt;p&gt;
Fast Optimal Transport through Sliced Wasserstein Generalized Geodesics. (arXiv:2307.01770v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01770
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#35745;&#31639;&#26368;&#20248;&#36755;&#36816;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20999;&#29255;Wasserstein&#24191;&#20041;&#27979;&#22320;&#32447;&#36827;&#34892;&#36817;&#20284;&#65292;&#24471;&#21040;&#20102;&#19968;&#20010;&#22522;&#20110;&#19968;&#32500;&#26368;&#20248;&#25237;&#24433;&#30340;&#20195;&#29702;&#36317;&#31163;min-SWGG&#65292;&#24182;&#25552;&#20379;&#20102;&#30456;&#20851;&#30340;&#20256;&#36755;&#35745;&#21010;&#12290;&#36825;&#31181;&#26041;&#27861;&#20855;&#26377;&#36739;&#20302;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#36866;&#29992;&#20110;&#20248;&#21270;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Wassserstein&#36317;&#31163;&#21644;&#30456;&#20851;&#30340;&#26368;&#20248;&#36755;&#36816;&#35745;&#21010;&#22312;&#35768;&#22810;&#28041;&#21450;&#27010;&#29575;&#24230;&#37327;&#30340;&#24212;&#29992;&#20013;&#34987;&#35777;&#26126;&#26159;&#26377;&#29992;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#24179;&#26041;Wasserstein&#36317;&#31163;&#30340;&#20195;&#29702;&#65292;&#31216;&#20026;min-SWGG&#65292;&#23427;&#22522;&#20110;&#20004;&#20010;&#36755;&#20837;&#20998;&#24067;&#30340;&#19968;&#32500;&#26368;&#20248;&#25237;&#24433;&#24341;&#23548;&#30340;&#36816;&#36755;&#26144;&#23556;&#12290;&#25105;&#20204;&#22312;min-SWGG&#21644;Wasserstein&#24191;&#20041;&#27979;&#22320;&#32447;&#20043;&#38388;&#24314;&#31435;&#20102;&#32852;&#31995;&#65292;&#20854;&#20013;&#26530;&#32445;&#27979;&#24230;&#22312;&#19968;&#26465;&#30452;&#32447;&#19978;&#24471;&#21040;&#25903;&#25345;&#12290;&#25105;&#20204;&#29305;&#21035;&#25552;&#20379;&#20102;&#19968;&#20010;&#26032;&#30340;&#38381;&#21512;&#24418;&#24335;&#30340;&#31934;&#30830;Wasserstein&#36317;&#31163;&#65292;&#22312;&#20854;&#20013;&#19968;&#20010;&#20998;&#24067;&#25903;&#25345;&#22312;&#19968;&#26465;&#30452;&#32447;&#19978;&#30340;&#29305;&#27530;&#24773;&#20917;&#19979;&#65292;&#20351;&#25105;&#20204;&#33021;&#22815;&#25512;&#23548;&#20986;&#19968;&#31181;&#36866;&#29992;&#20110;&#26799;&#24230;&#19979;&#38477;&#20248;&#21270;&#30340;&#24555;&#36895;&#35745;&#31639;&#26041;&#26696;&#12290;&#25105;&#20204;&#34920;&#26126;min-SWGG&#26159;WD&#30340;&#19978;&#30028;&#65292;&#24182;&#19988;&#23427;&#20855;&#26377;&#19982;Sliced-Wasserstein&#31867;&#20284;&#30340;&#22797;&#26434;&#24230;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#19968;&#20010;&#30456;&#20851;&#30340;&#36755;&#36816;&#35745;&#21010;&#12290;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#19968;&#20123;&#29702;&#35770;&#24615;&#36136;&#65292;&#22914;&#36317;&#31163;&#24615;&#12289;&#24369;&#25910;&#25947;&#12289;&#35745;&#31639;&#21644;&#25299;&#25169;&#24615;&#36136;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;
Wasserstein distance (WD) and the associated optimal transport plan have been proven useful in many applications where probability measures are at stake. In this paper, we propose a new proxy of the squared WD, coined min-SWGG, that is based on the transport map induced by an optimal one-dimensional projection of the two input distributions. We draw connections between min-SWGG and Wasserstein generalized geodesics in which the pivot measure is supported on a line. We notably provide a new closed form for the exact Wasserstein distance in the particular case of one of the distributions supported on a line allowing us to derive a fast computational scheme that is amenable to gradient descent optimization. We show that min-SWGG is an upper bound of WD and that it has a complexity similar to as Sliced-Wasserstein, with the additional feature of providing an associated transport plan. We also investigate some theoretical properties such as metricity, weak convergence, computational and top
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#20165;&#20381;&#36182;ERM&#39044;&#35328;&#26426;&#35843;&#29992;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#21487;&#23454;&#29616;&#24773;&#20917;&#19979;&#20855;&#26377;&#26377;&#38480;&#30340;&#36951;&#25022;&#65292;&#24182;&#22312;&#19981;&#21487;&#30693;&#24773;&#20917;&#19979;&#20855;&#26377;&#20122;&#32447;&#24615;&#22686;&#38271;&#30340;&#36951;&#25022;&#12290;&#21516;&#26102;&#65292;&#36824;&#25552;&#20379;&#20102;&#31867;&#20284;&#30340;&#32467;&#26524;&#29992;&#20110;&#38750;&#21442;&#25968;&#21338;&#24328;&#29615;&#22659;&#20013;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#21363;&#20165;&#20381;&#36182;&#26368;&#20339;&#21709;&#24212;&#39044;&#35328;&#26426;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#25910;&#25947;&#21040;&#36817;&#20284;&#26497;&#23567;-&#26497;&#22823;&#22343;&#34913;&#28857;&#12290;</title><link>http://arxiv.org/abs/2307.01689</link><description>&lt;p&gt;
&#22312;&#32447;&#23398;&#20064;&#21644;&#20351;&#29992;ERM&#39044;&#35328;&#26426;&#35299;&#20915;&#26080;&#31351;&#21338;&#24328;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Online Learning and Solving Infinite Games with an ERM Oracle. (arXiv:2307.01689v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01689
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#20165;&#20381;&#36182;ERM&#39044;&#35328;&#26426;&#35843;&#29992;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#21487;&#23454;&#29616;&#24773;&#20917;&#19979;&#20855;&#26377;&#26377;&#38480;&#30340;&#36951;&#25022;&#65292;&#24182;&#22312;&#19981;&#21487;&#30693;&#24773;&#20917;&#19979;&#20855;&#26377;&#20122;&#32447;&#24615;&#22686;&#38271;&#30340;&#36951;&#25022;&#12290;&#21516;&#26102;&#65292;&#36824;&#25552;&#20379;&#20102;&#31867;&#20284;&#30340;&#32467;&#26524;&#29992;&#20110;&#38750;&#21442;&#25968;&#21338;&#24328;&#29615;&#22659;&#20013;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#21363;&#20165;&#20381;&#36182;&#26368;&#20339;&#21709;&#24212;&#39044;&#35328;&#26426;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#25910;&#25947;&#21040;&#36817;&#20284;&#26497;&#23567;-&#26497;&#22823;&#22343;&#34913;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22522;&#20110;&#22312;&#32447;&#23398;&#20064;&#30340;&#24773;&#20917;&#19979;&#65292;ERM&#36275;&#20197;&#36798;&#21040;&#25509;&#36817;&#26368;&#20248;&#27867;&#21270;&#35823;&#24046;&#30340;&#30446;&#26631;&#65292;&#20294;&#22312;&#22312;&#32447;&#23398;&#20064;&#29615;&#22659;&#19979;&#24182;&#38750;&#22914;&#27492;&#65292;&#36890;&#24120;&#30340;&#27010;&#24565;&#31867;&#31639;&#27861;&#20381;&#36182;&#35745;&#31639;&#25928;&#29575;&#36739;&#20302;&#30340;&#39044;&#35328;&#26426;&#65292;&#22914;&#26631;&#20934;&#26368;&#20248;&#31639;&#27861;(SOA)&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20165;&#20381;&#36182;ERM&#39044;&#35328;&#26426;&#35843;&#29992;&#30340;&#22312;&#32447;&#20108;&#20998;&#31867;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#22312;&#21487;&#23454;&#29616;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#26377;&#38480;&#30340;&#36951;&#25022;(regret)&#65292;&#22312;&#19981;&#21487;&#30693;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#20122;&#32447;&#24615;&#22686;&#38271;&#30340;&#36951;&#25022;&#12290;&#25105;&#20204;&#36890;&#36807;&#24213;&#23618;&#27010;&#24565;&#31867;&#30340;Littlestone&#21644;&#38408;&#20540;&#32500;&#24230;&#26469;&#38480;&#21046;&#36951;&#25022;&#12290;&#25105;&#20204;&#33719;&#24471;&#20102;&#31867;&#20284;&#30340;&#32467;&#26524;&#29992;&#20110;&#38750;&#21442;&#25968;&#21338;&#24328;&#65292;&#20854;&#20013;ERM&#39044;&#35328;&#26426;&#21487;&#20197;&#34987;&#29702;&#35299;&#20026;&#26368;&#20339;&#21709;&#24212;&#39044;&#35328;&#26426;&#65292;&#26681;&#25454;&#20854;&#20182;&#29609;&#23478;&#30340;&#28216;&#25103;&#21382;&#21490;&#25214;&#21040;&#19968;&#20010;&#29609;&#23478;&#30340;&#26368;&#20339;&#21709;&#24212;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20165;&#20381;&#36182;&#26368;&#20339;&#21709;&#24212;&#39044;&#35328;&#26426;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#24182;&#25910;&#25947;&#21040;&#20004;&#20154;&#38646;&#21644;&#21338;&#24328;&#30340;&#36817;&#20284;&#26497;&#23567;-&#26497;&#22823;&#22343;&#34913;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
While ERM suffices to attain near-optimal generalization error in the stochastic learning setting, this is not known to be the case in the online learning setting, where algorithms for general concept classes rely on computationally inefficient oracles such as the Standard Optimal Algorithm (SOA). In this work, we propose an algorithm for online binary classification setting that relies solely on ERM oracle calls, and show that it has finite regret in the realizable setting and sublinearly growing regret in the agnostic setting. We bound the regret in terms of the Littlestone and threshold dimensions of the underlying concept class.  We obtain similar results for nonparametric games, where the ERM oracle can be interpreted as a best response oracle, finding the best response of a player to a given history of play of the other players. In this setting, we provide learning algorithms that only rely on best response oracles and converge to approximate-minimax equilibria in two-player zero
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#25193;&#25955;&#23545;&#27604;&#21457;&#25955;&#65288;DCD&#65289;&#35757;&#32451;&#33021;&#37327;&#27169;&#22411;&#65288;EBM&#65289;&#30340;&#26041;&#27861;&#65292;&#30456;&#36739;&#20110;&#20256;&#32479;&#30340;&#23545;&#27604;&#21457;&#25955;&#65288;CD&#65289;&#65292;DCD&#22312;&#35745;&#31639;&#25928;&#29575;&#19978;&#26356;&#39640;&#65292;&#24182;&#19988;&#19981;&#21463;&#38750;&#21487;&#24573;&#30053;&#26799;&#24230;&#39033;&#30340;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2307.01668</link><description>&lt;p&gt;
&#20351;&#29992;&#25193;&#25955;&#23545;&#27604;&#21457;&#25955;&#35757;&#32451;&#33021;&#37327;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Training Energy-Based Models with Diffusion Contrastive Divergences. (arXiv:2307.01668v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01668
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#25193;&#25955;&#23545;&#27604;&#21457;&#25955;&#65288;DCD&#65289;&#35757;&#32451;&#33021;&#37327;&#27169;&#22411;&#65288;EBM&#65289;&#30340;&#26041;&#27861;&#65292;&#30456;&#36739;&#20110;&#20256;&#32479;&#30340;&#23545;&#27604;&#21457;&#25955;&#65288;CD&#65289;&#65292;DCD&#22312;&#35745;&#31639;&#25928;&#29575;&#19978;&#26356;&#39640;&#65292;&#24182;&#19988;&#19981;&#21463;&#38750;&#21487;&#24573;&#30053;&#26799;&#24230;&#39033;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33021;&#37327;&#27169;&#22411;&#65288;EBM&#65289;&#24191;&#27867;&#24212;&#29992;&#20110;&#29983;&#25104;&#24314;&#27169;&#12290;&#20256;&#32479;&#30340;&#23545;&#27604;&#21457;&#25955;&#65288;CD&#65289;&#35757;&#32451;&#30446;&#26631;&#38656;&#35201;&#20351;&#29992;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#65288;MCMCs&#65289;&#20174;EBM&#20013;&#37319;&#26679;&#65292;&#36825;&#23548;&#33268;&#20102;&#35745;&#31639;&#36127;&#25285;&#21644;CD&#26377;&#25928;&#24615;&#20043;&#38388;&#30340;&#19981;&#21487;&#35843;&#21644;&#30340;&#25240;&#34935;&#12290;MCMCs&#30340;&#25910;&#25947;&#38656;&#35201;&#22823;&#37327;&#35745;&#31639;&#36164;&#28304;&#65292;&#32780;&#30701;&#26399;&#36816;&#34892;&#30340;MCMC&#20250;&#24341;&#20837;&#38590;&#20197;&#22788;&#29702;&#30340;&#39069;&#22806;&#21442;&#25968;&#26799;&#24230;&#39033;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#25193;&#25955;&#23545;&#27604;&#21457;&#25955;&#65288;DCD&#65289;&#31995;&#21015;&#30340;&#19968;&#33324;&#35299;&#37322;&#65292;&#23558;CD&#35270;&#20026;DCD&#30340;&#19968;&#31181;&#29305;&#27530;&#24773;&#20917;&#65292;&#24182;&#36890;&#36807;&#22312;CD&#20013;&#20351;&#29992;&#19981;&#21516;&#20110;Langevin&#21160;&#21147;&#23398;&#30340;EBM&#21442;&#25968;&#33258;&#30001;&#25193;&#25955;&#36807;&#31243;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#26377;&#25928;&#30340;&#21457;&#25955;&#26041;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;DCD&#27604;CD&#26356;&#21152;&#35745;&#31639;&#39640;&#25928;&#65292;&#24182;&#19988;&#19981;&#21463;&#38750;&#21487;&#24573;&#30053;&#26799;&#24230;&#39033;&#30340;&#38480;&#21046;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#65292;&#21253;&#25324;&#21512;&#25104;&#25968;&#25454;&#21644;&#23454;&#38469;&#24212;&#29992;&#22330;&#26223;&#30340;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Energy-Based Models (EBMs) have been widely used for generative modeling. Contrastive Divergence (CD), a prevailing training objective for EBMs, requires sampling from the EBM with Markov Chain Monte Carlo methods (MCMCs), which leads to an irreconcilable trade-off between the computational burden and the validity of the CD. Running MCMCs till convergence is computationally intensive. On the other hand, short-run MCMC brings in an extra non-negligible parameter gradient term that is difficult to handle. In this paper, we provide a general interpretation of CD, viewing it as a special instance of our proposed Diffusion Contrastive Divergence (DCD) family. By replacing the Langevin dynamic used in CD with other EBM-parameter-free diffusion processes, we propose a more efficient divergence. We show that the proposed DCDs are both more computationally efficient than the CD and are not limited to a non-negligible gradient term. We conduct intensive experiments, including both synthesis data
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;AIM&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#20915;&#31574;&#20013;&#30340;&#25506;&#32034;-&#21033;&#29992;&#22256;&#22659;&#65292;&#29305;&#21035;&#38024;&#23545;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#12290;AIM&#31639;&#27861;&#21033;&#29992;&#36817;&#20284;&#29109;&#26799;&#24230;&#26469;&#36873;&#25321;&#27599;&#20010;&#26102;&#38388;&#28857;&#35201;&#25289;&#21160;&#30340;&#25163;&#33218;&#65292;&#19982;Infomax&#21644;Thompson&#25277;&#26679;&#30456;&#27604;&#65292;&#22312;&#24615;&#33021;&#19978;&#33021;&#22815;&#21305;&#37197;&#65292;&#21516;&#26102;&#20855;&#26377;&#26356;&#22909;&#30340;&#35745;&#31639;&#36895;&#24230;&#12289;&#30830;&#23450;&#24615;&#21644;&#21487;&#35745;&#31639;&#24615;&#12290;&#32463;&#23454;&#35777;&#35780;&#20272;&#34920;&#26126;&#65292;AIM&#31639;&#27861;&#31526;&#21512;Lai-Robbins&#28176;&#36827;&#30028;&#65292;&#23545;&#20110;&#19981;&#21516;&#30340;&#20808;&#39564;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.01563</link><description>&lt;p&gt;
&#29992;&#20110;&#39640;&#25928;&#25506;&#32034;-&#21033;&#29992;&#31574;&#30053;&#30340;&#36817;&#20284;&#20449;&#24687;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Approximate information for efficient exploration-exploitation strategies. (arXiv:2307.01563v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01563
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;AIM&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#20915;&#31574;&#20013;&#30340;&#25506;&#32034;-&#21033;&#29992;&#22256;&#22659;&#65292;&#29305;&#21035;&#38024;&#23545;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#12290;AIM&#31639;&#27861;&#21033;&#29992;&#36817;&#20284;&#29109;&#26799;&#24230;&#26469;&#36873;&#25321;&#27599;&#20010;&#26102;&#38388;&#28857;&#35201;&#25289;&#21160;&#30340;&#25163;&#33218;&#65292;&#19982;Infomax&#21644;Thompson&#25277;&#26679;&#30456;&#27604;&#65292;&#22312;&#24615;&#33021;&#19978;&#33021;&#22815;&#21305;&#37197;&#65292;&#21516;&#26102;&#20855;&#26377;&#26356;&#22909;&#30340;&#35745;&#31639;&#36895;&#24230;&#12289;&#30830;&#23450;&#24615;&#21644;&#21487;&#35745;&#31639;&#24615;&#12290;&#32463;&#23454;&#35777;&#35780;&#20272;&#34920;&#26126;&#65292;AIM&#31639;&#27861;&#31526;&#21512;Lai-Robbins&#28176;&#36827;&#30028;&#65292;&#23545;&#20110;&#19981;&#21516;&#30340;&#20808;&#39564;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#20915;&#31574;&#20013;&#28508;&#22312;&#30340;&#25506;&#32034;-&#21033;&#29992;&#22256;&#22659;&#65292;&#37325;&#28857;&#30740;&#31350;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#12290;&#35813;&#38382;&#39064;&#28041;&#21450;&#19968;&#20010;&#20195;&#29702;&#20915;&#23450;&#26159;&#21542;&#21033;&#29992;&#24403;&#21069;&#30340;&#30693;&#35782;&#20197;&#33719;&#21462;&#21363;&#26102;&#25910;&#30410;&#65292;&#36824;&#26159;&#25506;&#32034;&#26032;&#30340;&#36884;&#24452;&#20197;&#33719;&#24471;&#28508;&#22312;&#30340;&#38271;&#26399;&#22238;&#25253;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;&#65292;&#21363;&#36817;&#20284;&#20449;&#24687;&#26368;&#22823;&#21270;&#65288;AIM&#65289;&#65292;&#23427;&#21033;&#29992;&#29109;&#26799;&#24230;&#30340;&#35299;&#26512;&#36817;&#20284;&#26469;&#36873;&#25321;&#27599;&#20010;&#26102;&#38388;&#28857;&#35201;&#25289;&#21160;&#30340;&#25163;&#33218;&#12290;AIM&#22312;&#24615;&#33021;&#19978;&#19982;Infomax&#21644;Thompson&#25277;&#26679;&#30456;&#21305;&#37197;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#22686;&#24378;&#30340;&#35745;&#31639;&#36895;&#24230;&#12289;&#30830;&#23450;&#24615;&#21644;&#21487;&#35745;&#31639;&#24615;&#12290;&#23545;AIM&#30340;&#23454;&#35777;&#35780;&#20272;&#34920;&#26126;&#20854;&#31526;&#21512;Lai-Robbins&#28176;&#36827;&#30028;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#23545;&#19968;&#31995;&#21015;&#20808;&#39564;&#30340;&#40065;&#26834;&#24615;&#12290;&#20854;&#34920;&#36798;&#24335;&#21487;&#35843;&#33410;&#65292;&#21487;&#20197;&#22312;&#19981;&#21516;&#22330;&#26223;&#19979;&#36827;&#34892;&#20855;&#20307;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper addresses the exploration-exploitation dilemma inherent in decision-making, focusing on multi-armed bandit problems. The problems involve an agent deciding whether to exploit current knowledge for immediate gains or explore new avenues for potential long-term rewards. We here introduce a novel algorithm, approximate information maximization (AIM), which employs an analytical approximation of the entropy gradient to choose which arm to pull at each point in time. AIM matches the performance of Infomax and Thompson sampling while also offering enhanced computational speed, determinism, and tractability. Empirical evaluation of AIM indicates its compliance with the Lai-Robbins asymptotic bound and demonstrates its robustness for a range of priors. Its expression is tunable, which allows for specific optimization in various settings.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#20855;&#26377;&#29366;&#24577;&#30456;&#20851;&#22122;&#22768;&#30340;&#38543;&#26426;&#24179;&#28369;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#36890;&#36807;&#24341;&#20837;&#20004;&#31181;&#38750;&#27431;&#20960;&#37324;&#24471;&#21152;&#36895;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#22312;&#31934;&#24230;&#12289;&#38382;&#39064;&#21442;&#25968;&#21644;&#23567;&#25209;&#37327;&#22823;&#23567;&#26041;&#38754;&#30340;&#26368;&#20248;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.01497</link><description>&lt;p&gt;
&#20855;&#26377;&#29366;&#24577;&#30456;&#20851;&#22122;&#22768;&#30340;&#21152;&#36895;&#38543;&#26426;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
Accelerated stochastic approximation with state-dependent noise. (arXiv:2307.01497v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01497
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#20855;&#26377;&#29366;&#24577;&#30456;&#20851;&#22122;&#22768;&#30340;&#38543;&#26426;&#24179;&#28369;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#36890;&#36807;&#24341;&#20837;&#20004;&#31181;&#38750;&#27431;&#20960;&#37324;&#24471;&#21152;&#36895;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#22312;&#31934;&#24230;&#12289;&#38382;&#39064;&#21442;&#25968;&#21644;&#23567;&#25209;&#37327;&#22823;&#23567;&#26041;&#38754;&#30340;&#26368;&#20248;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20855;&#26377;&#19968;&#33324;&#22122;&#22768;&#20551;&#35774;&#30340;&#38543;&#26426;&#24179;&#28369;&#20984;&#20248;&#21270;&#38382;&#39064;&#30340;&#19968;&#31867;&#38382;&#39064;&#65292;&#22312;&#36825;&#20123;&#38382;&#39064;&#20013;&#65292;&#38543;&#26426;&#26799;&#24230;&#35266;&#27979;&#30340;&#22122;&#22768;&#30340;&#26041;&#24046;&#19982;&#31639;&#27861;&#20135;&#29983;&#30340;&#36817;&#20284;&#35299;&#30340;"&#20122;&#26368;&#20248;&#24615;" &#30456;&#20851;&#12290;&#36825;&#31867;&#38382;&#39064;&#22312;&#22810;&#31181;&#24212;&#29992;&#20013;&#33258;&#28982;&#32780;&#28982;&#22320;&#20986;&#29616;&#65292;&#29305;&#21035;&#26159;&#22312;&#32479;&#35745;&#23398;&#20013;&#30340;&#24191;&#20041;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#20013;&#12290;&#28982;&#32780;&#65292;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#29616;&#26377;&#30340;&#35299;&#20915;&#36825;&#31867;&#38382;&#39064;&#30340;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#22312;&#31934;&#24230;&#12289;&#38382;&#39064;&#21442;&#25968;&#21644;&#23567;&#25209;&#37327;&#22823;&#23567;&#30340;&#20381;&#36182;&#24615;&#26041;&#38754;&#37117;&#26410;&#36798;&#21040;&#26368;&#20248;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#20004;&#31181;&#38750;&#27431;&#20960;&#37324;&#24471;&#21152;&#36895;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#8212;&#8212;&#38543;&#26426;&#21152;&#36895;&#26799;&#24230;&#19979;&#38477;&#65288;SAGD&#65289;&#21644;&#38543;&#26426;&#26799;&#24230;&#22806;&#25512;&#65288;SGE&#65289;&#8212;&#8212;&#23427;&#20204;&#20855;&#26377;&#19968;&#31181;&#29305;&#27530;&#30340;&#23545;&#20598;&#20851;&#31995;
&lt;/p&gt;
&lt;p&gt;
We consider a class of stochastic smooth convex optimization problems under rather general assumptions on the noise in the stochastic gradient observation. As opposed to the classical problem setting in which the variance of noise is assumed to be uniformly bounded, herein we assume that the variance of stochastic gradients is related to the "sub-optimality" of the approximate solutions delivered by the algorithm. Such problems naturally arise in a variety of applications, in particular, in the well-known generalized linear regression problem in statistics. However, to the best of our knowledge, none of the existing stochastic approximation algorithms for solving this class of problems attain optimality in terms of the dependence on accuracy, problem parameters, and mini-batch size.  We discuss two non-Euclidean accelerated stochastic approximation routines--stochastic accelerated gradient descent (SAGD) and stochastic gradient extrapolation (SGE)--which carry a particular duality rela
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#36339;&#36830;&#25509;&#30340;&#36125;&#21494;&#26031;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#33258;&#30001;&#33021;&#65292;&#25581;&#31034;&#20102;&#20854;&#19981;&#20381;&#36182;&#20110;&#36807;&#24230;&#21442;&#25968;&#21270;&#65292;&#24182;&#19988;&#20855;&#26377;&#31867;&#20284;&#30340;&#27867;&#21270;&#35823;&#24046;&#24615;&#36136;&#12290;</title><link>http://arxiv.org/abs/2307.01417</link><description>&lt;p&gt;
&#20855;&#26377;&#36339;&#36830;&#25509;&#30340;&#36125;&#21494;&#26031;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#33258;&#30001;&#33021;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Free energy of Bayesian Convolutional Neural Network with Skip Connection. (arXiv:2307.01417v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01417
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#36339;&#36830;&#25509;&#30340;&#36125;&#21494;&#26031;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#33258;&#30001;&#33021;&#65292;&#25581;&#31034;&#20102;&#20854;&#19981;&#20381;&#36182;&#20110;&#36807;&#24230;&#21442;&#25968;&#21270;&#65292;&#24182;&#19988;&#20855;&#26377;&#31867;&#20284;&#30340;&#27867;&#21270;&#35823;&#24046;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#20174;Residual Network(ResNet)&#30340;&#25104;&#21151;&#20043;&#21518;&#65292;&#35768;&#22810;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;(CNNs)&#30340;&#26550;&#26500;&#37117;&#37319;&#29992;&#20102;&#36339;&#36830;&#25509;&#12290;&#34429;&#28982;&#36339;&#36830;&#25509;&#30340;CNN&#30340;&#27867;&#21270;&#24615;&#33021;&#24050;&#22312;&#38598;&#25104;&#23398;&#20064;&#26694;&#26550;&#19979;&#24471;&#21040;&#35299;&#37322;&#65292;&#20294;&#21442;&#25968;&#25968;&#37327;&#30340;&#20381;&#36182;&#24615;&#23578;&#26410;&#25581;&#31034;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#36125;&#21494;&#26031;&#23398;&#20064;&#20013;&#65292;&#26377;&#36339;&#36830;&#25509;&#21644;&#26080;&#36339;&#36830;&#25509;&#30340;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#36125;&#21494;&#26031;&#33258;&#30001;&#33021;&#12290;&#20855;&#26377;&#36339;&#36830;&#25509;&#30340;&#36125;&#21494;&#26031;CNN&#30340;&#33258;&#30001;&#33021;&#19978;&#30028;&#19981;&#20381;&#36182;&#20110;&#36807;&#24230;&#21442;&#25968;&#21270;&#65292;&#32780;&#36125;&#21494;&#26031;CNN&#30340;&#27867;&#21270;&#35823;&#24046;&#20063;&#20855;&#26377;&#30456;&#20284;&#30340;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
Since the success of Residual Network(ResNet), many of architectures of Convolutional Neural Networks(CNNs) have adopted skip connection. While the generalization performance of CNN with skip connection has been explained within the framework of Ensemble Learning, the dependency on the number of parameters have not been revealed. In this paper, we show that Bayesian free energy of Convolutional Neural Network both with and without skip connection in Bayesian learning. The upper bound of free energy of Bayesian CNN with skip connection does not depend on the oveparametrization and, the generalization error of Bayesian CNN has similar property.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#33258;&#36866;&#24212;&#20027;&#25104;&#20998;&#22238;&#24402;&#26041;&#27861;&#65292;&#24182;&#22312;&#38754;&#26495;&#25968;&#25454;&#20013;&#30340;&#24212;&#29992;&#20013;&#33719;&#24471;&#20102;&#22343;&#21248;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#29992;&#20110;&#38754;&#26495;&#25968;&#25454;&#20013;&#30340;&#23454;&#39564;&#35774;&#35745;&#65292;&#29305;&#21035;&#26159;&#24403;&#24178;&#39044;&#26041;&#26696;&#26159;&#33258;&#36866;&#24212;&#20998;&#37197;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2307.01357</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#20027;&#25104;&#20998;&#22238;&#24402;&#22312;&#38754;&#26495;&#25968;&#25454;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Adaptive Principal Component Regression with Applications to Panel Data. (arXiv:2307.01357v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01357
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#33258;&#36866;&#24212;&#20027;&#25104;&#20998;&#22238;&#24402;&#26041;&#27861;&#65292;&#24182;&#22312;&#38754;&#26495;&#25968;&#25454;&#20013;&#30340;&#24212;&#29992;&#20013;&#33719;&#24471;&#20102;&#22343;&#21248;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#29992;&#20110;&#38754;&#26495;&#25968;&#25454;&#20013;&#30340;&#23454;&#39564;&#35774;&#35745;&#65292;&#29305;&#21035;&#26159;&#24403;&#24178;&#39044;&#26041;&#26696;&#26159;&#33258;&#36866;&#24212;&#20998;&#37197;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20027;&#25104;&#20998;&#22238;&#24402;(PCR)&#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#22266;&#23450;&#35774;&#35745;&#35823;&#24046;&#21464;&#37327;&#22238;&#24402;&#25216;&#26415;&#65292;&#23427;&#26159;&#32447;&#24615;&#22238;&#24402;&#30340;&#25512;&#24191;&#65292;&#35266;&#27979;&#30340;&#21327;&#21464;&#37327;&#21463;&#21040;&#38543;&#26426;&#22122;&#22768;&#30340;&#27745;&#26579;&#12290;&#25105;&#20204;&#22312;&#25968;&#25454;&#25910;&#38598;&#26102;&#25552;&#20379;&#20102;&#22312;&#32447;&#65288;&#27491;&#21017;&#21270;&#65289;PCR&#30340;&#31532;&#19968;&#27425;&#22343;&#21248;&#26377;&#38480;&#26679;&#26412;&#20445;&#35777;&#12290;&#30001;&#20110;&#20998;&#26512;&#22266;&#23450;&#35774;&#35745;&#20013;PCR&#30340;&#35777;&#26126;&#25216;&#26415;&#26080;&#27861;&#24456;&#23481;&#26131;&#22320;&#25193;&#23637;&#21040;&#22312;&#32447;&#35774;&#32622;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#20381;&#36182;&#20110;&#23558;&#29616;&#20195;&#38789;&#27987;&#24230;&#30340;&#24037;&#20855;&#36866;&#24212;&#21040;&#35823;&#24046;&#21464;&#37327;&#35774;&#32622;&#20013;&#12290;&#20316;&#20026;&#25105;&#20204;&#30028;&#38480;&#30340;&#24212;&#29992;&#65292;&#25105;&#20204;&#22312;&#38754;&#26495;&#25968;&#25454;&#35774;&#32622;&#20013;&#25552;&#20379;&#20102;&#23454;&#39564;&#35774;&#35745;&#26694;&#26550;&#65292;&#24403;&#24178;&#39044;&#34987;&#33258;&#36866;&#24212;&#22320;&#20998;&#37197;&#26102;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#34987;&#35748;&#20026;&#26159;&#21512;&#25104;&#25511;&#21046;&#21644;&#21512;&#25104;&#24178;&#39044;&#26694;&#26550;&#30340;&#27867;&#21270;&#65292;&#20854;&#20013;&#25968;&#25454;&#26159;&#36890;&#36807;&#33258;&#36866;&#24212;&#24178;&#39044;&#20998;&#37197;&#31574;&#30053;&#25910;&#38598;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Principal component regression (PCR) is a popular technique for fixed-design error-in-variables regression, a generalization of the linear regression setting in which the observed covariates are corrupted with random noise. We provide the first time-uniform finite sample guarantees for online (regularized) PCR whenever data is collected adaptively. Since the proof techniques for analyzing PCR in the fixed design setting do not readily extend to the online setting, our results rely on adapting tools from modern martingale concentration to the error-in-variables setting. As an application of our bounds, we provide a framework for experiment design in panel data settings when interventions are assigned adaptively. Our framework may be thought of as a generalization of the synthetic control and synthetic interventions frameworks, where data is collected via an adaptive intervention assignment policy.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20197;&#39063;&#31890;&#29699;&#20026;&#26041;&#21521;&#30340;&#30693;&#24773;&#38750;&#32447;&#24615;&#36807;&#37319;&#26679;&#26694;&#26550;INGB&#65292;&#36890;&#36807;&#27169;&#25311;&#25968;&#25454;&#38598;&#30340;&#31354;&#38388;&#20998;&#24067;&#29305;&#24449;&#24182;&#20248;&#21270;&#39063;&#31890;&#29699;&#31354;&#38388;&#65292;&#21033;&#29992;&#39640;&#32500;&#31232;&#30095;&#24615;&#21644;&#21508;&#21521;&#21516;&#24615;&#39640;&#26031;&#20998;&#24067;&#36827;&#34892;&#38750;&#32447;&#24615;&#36807;&#37319;&#26679;&#65292;&#20197;&#25913;&#21892;&#19981;&#22343;&#34913;&#20998;&#31867;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2307.01224</link><description>&lt;p&gt;
INGB: &#29992;&#20110;&#22024;&#26434;&#30340;&#19981;&#22343;&#34913;&#20998;&#31867;&#30340;&#30693;&#24773;&#38750;&#32447;&#24615;&#39063;&#31890;&#29699;&#36807;&#37319;&#26679;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
INGB: Informed Nonlinear Granular Ball Oversampling Framework for Noisy Imbalanced Classification. (arXiv:2307.01224v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01224
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20197;&#39063;&#31890;&#29699;&#20026;&#26041;&#21521;&#30340;&#30693;&#24773;&#38750;&#32447;&#24615;&#36807;&#37319;&#26679;&#26694;&#26550;INGB&#65292;&#36890;&#36807;&#27169;&#25311;&#25968;&#25454;&#38598;&#30340;&#31354;&#38388;&#20998;&#24067;&#29305;&#24449;&#24182;&#20248;&#21270;&#39063;&#31890;&#29699;&#31354;&#38388;&#65292;&#21033;&#29992;&#39640;&#32500;&#31232;&#30095;&#24615;&#21644;&#21508;&#21521;&#21516;&#24615;&#39640;&#26031;&#20998;&#24067;&#36827;&#34892;&#38750;&#32447;&#24615;&#36807;&#37319;&#26679;&#65292;&#20197;&#25913;&#21892;&#19981;&#22343;&#34913;&#20998;&#31867;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20998;&#31867;&#38382;&#39064;&#20013;&#65292;&#25968;&#25454;&#38598;&#36890;&#24120;&#26159;&#19981;&#22343;&#34913;&#12289;&#22024;&#26434;&#25110;&#22797;&#26434;&#30340;&#12290;&#22823;&#22810;&#25968;&#37319;&#26679;&#31639;&#27861;&#21482;&#23545;&#21512;&#25104;&#23569;&#25968;&#31867;&#36807;&#37319;&#26679;&#25216;&#26415;&#65288;SMOTE&#65289;&#30340;&#32447;&#24615;&#37319;&#26679;&#26426;&#21046;&#36827;&#34892;&#20102;&#19968;&#20123;&#25913;&#36827;&#12290;&#28982;&#32780;&#65292;&#32447;&#24615;&#36807;&#37319;&#26679;&#23384;&#22312;&#19968;&#20123;&#19981;&#21487;&#36991;&#20813;&#30340;&#32570;&#28857;&#12290;&#32447;&#24615;&#36807;&#37319;&#26679;&#23481;&#26131;&#36807;&#25311;&#21512;&#65292;&#24182;&#19988;&#21512;&#25104;&#26679;&#26412;&#32570;&#20047;&#22810;&#26679;&#24615;&#65292;&#24456;&#23569;&#32771;&#34385;&#21407;&#22987;&#20998;&#24067;&#29305;&#24449;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20197;&#39063;&#31890;&#29699;&#20026;&#26041;&#21521;&#30340;&#30693;&#24773;&#38750;&#32447;&#24615;&#36807;&#37319;&#26679;&#26694;&#26550;INGB&#12290;&#23427;&#21033;&#29992;&#39063;&#31890;&#29699;&#26469;&#27169;&#25311;&#25968;&#25454;&#38598;&#30340;&#31354;&#38388;&#20998;&#24067;&#29305;&#24449;&#65292;&#24182;&#21033;&#29992;&#30693;&#24773;&#29109;&#36827;&#19968;&#27493;&#20248;&#21270;&#39063;&#31890;&#29699;&#31354;&#38388;&#12290;&#28982;&#21518;&#65292;&#25353;&#29031;&#39640;&#32500;&#31232;&#30095;&#24615;&#21644;&#21508;&#21521;&#21516;&#24615;&#39640;&#26031;&#20998;&#24067;&#36827;&#34892;&#38750;&#32447;&#24615;&#36807;&#37319;&#26679;&#12290;&#27492;&#22806;&#65292;INGB&#20855;&#26377;&#33391;&#22909;&#30340;&#20860;&#23481;&#24615;&#65292;&#23427;&#19981;&#20165;&#21487;&#20197;&#19982;&#22823;&#22810;&#25968;&#22522;&#20110;SMOTE&#30340;&#37319;&#26679;&#31639;&#27861;&#30456;&#32467;&#21512;&#65292;&#20197;&#25913;&#21892;&#20998;&#31867;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In classification problems, the datasets are usually imbalanced, noisy or complex. Most sampling algorithms only make some improvements to the linear sampling mechanism of the synthetic minority oversampling technique (SMOTE). Nevertheless, linear oversampling has several unavoidable drawbacks. Linear oversampling is susceptible to overfitting, and the synthetic samples lack diversity and rarely account for the original distribution characteristics. An informed nonlinear oversampling framework with the granular ball (INGB) as a new direction of oversampling is proposed in this paper. It uses granular balls to simulate the spatial distribution characteristics of datasets, and informed entropy is utilized to further optimize the granular-ball space. Then, nonlinear oversampling is performed by following high-dimensional sparsity and the isotropic Gaussian distribution. Furthermore, INGB has good compatibility. Not only can it be combined with most SMOTE-based sampling algorithms to impro
&lt;/p&gt;</description></item><item><title>CardiGraphormer&#26159;&#19968;&#31181;&#38761;&#21629;&#24615;&#30340;&#26041;&#27861;&#65292;&#32467;&#21512;&#20102;&#33258;&#30417;&#30563;&#23398;&#20064;&#12289;&#22270;&#31070;&#32463;&#32593;&#32476;&#21644;&#20445;&#25345;&#22522;&#25968;&#27880;&#24847;&#21147;&#65292;&#39072;&#35206;&#20102;&#33647;&#29289;&#21457;&#29616;&#30340;&#26041;&#24335;&#12290;&#23427;&#21033;&#29992;&#33258;&#30417;&#30563;&#23398;&#20064;&#23398;&#20064;&#20998;&#23376;&#34920;&#31034;&#24182;&#21033;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#25552;&#21462;&#20998;&#23376;&#25351;&#32441;&#65292;&#25552;&#39640;&#20102;&#39044;&#27979;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#21516;&#26102;&#20943;&#23569;&#20102;&#35745;&#31639;&#26102;&#38388;&#65292;&#24182;&#22312;&#22788;&#29702;&#22797;&#26434;&#25968;&#25454;&#21644;&#25191;&#34892;&#21508;&#31181;&#19982;&#22270;&#32467;&#26500;&#30456;&#20851;&#30340;&#20219;&#21153;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;</title><link>http://arxiv.org/abs/2307.00859</link><description>&lt;p&gt;
CardiGraphormer: &#25581;&#31034;&#33258;&#30417;&#30563;&#23398;&#20064;&#22312;&#39072;&#35206;&#33647;&#29289;&#21457;&#29616;&#20013;&#30340;&#21147;&#37327;
&lt;/p&gt;
&lt;p&gt;
CardiGraphormer: Unveiling the Power of Self-Supervised Learning in Revolutionizing Drug Discovery. (arXiv:2307.00859v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00859
&lt;/p&gt;
&lt;p&gt;
CardiGraphormer&#26159;&#19968;&#31181;&#38761;&#21629;&#24615;&#30340;&#26041;&#27861;&#65292;&#32467;&#21512;&#20102;&#33258;&#30417;&#30563;&#23398;&#20064;&#12289;&#22270;&#31070;&#32463;&#32593;&#32476;&#21644;&#20445;&#25345;&#22522;&#25968;&#27880;&#24847;&#21147;&#65292;&#39072;&#35206;&#20102;&#33647;&#29289;&#21457;&#29616;&#30340;&#26041;&#24335;&#12290;&#23427;&#21033;&#29992;&#33258;&#30417;&#30563;&#23398;&#20064;&#23398;&#20064;&#20998;&#23376;&#34920;&#31034;&#24182;&#21033;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#25552;&#21462;&#20998;&#23376;&#25351;&#32441;&#65292;&#25552;&#39640;&#20102;&#39044;&#27979;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#21516;&#26102;&#20943;&#23569;&#20102;&#35745;&#31639;&#26102;&#38388;&#65292;&#24182;&#22312;&#22788;&#29702;&#22797;&#26434;&#25968;&#25454;&#21644;&#25191;&#34892;&#21508;&#31181;&#19982;&#22270;&#32467;&#26500;&#30456;&#20851;&#30340;&#20219;&#21153;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24191;&#38420;&#30340;&#33647;&#29289;&#21457;&#29616;&#39046;&#22495;&#20013;&#65292;&#24050;&#30693;&#33647;&#29289;&#32422;&#26377;15,000&#31181;&#65292;&#20294;&#21482;&#26377;&#22823;&#32422;4,200&#31181;&#24471;&#21040;&#20102;&#25209;&#20934;&#65292;&#21270;&#23398;&#31354;&#38388;&#30340;&#32452;&#21512;&#24615;&#36136;&#25552;&#20379;&#20102;&#19968;&#39033;&#33392;&#24040;&#30340;&#25361;&#25112;&#12290;&#23613;&#31649;&#20154;&#24037;&#26234;&#33021;&#25104;&#20026;&#20102;&#26377;&#21147;&#30340;&#20249;&#20276;&#65292;&#20256;&#32479;&#30340;&#20154;&#24037;&#26234;&#33021;&#26694;&#26550;&#20173;&#38754;&#20020;&#37325;&#22823;&#38556;&#30861;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;CardiGraphormer&#65292;&#36825;&#26159;&#19968;&#31181;&#21010;&#26102;&#20195;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#33258;&#30417;&#30563;&#23398;&#20064;&#65288;SSL&#65289;&#12289;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#21644;&#20445;&#25345;&#22522;&#25968;&#27880;&#24847;&#21147;&#65292;&#20174;&#32780;&#39072;&#35206;&#33647;&#29289;&#21457;&#29616;&#12290;CardiGraphormer&#26159;Graphormer&#21644;&#20445;&#25345;&#22522;&#25968;&#27880;&#24847;&#21147;&#30340;&#26032;&#39062;&#32452;&#21512;&#65292;&#21033;&#29992;SSL&#23398;&#20064;&#26377;&#25928;&#30340;&#20998;&#23376;&#34920;&#31034;&#65292;&#24182;&#21033;&#29992;GNN&#25552;&#21462;&#20998;&#23376;&#25351;&#32441;&#65292;&#25552;&#39640;&#20102;&#39044;&#27979;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#20943;&#23569;&#20102;&#35745;&#31639;&#26102;&#38388;&#12290;&#23427;&#22312;&#22788;&#29702;&#20998;&#23376;&#32467;&#26500;&#31561;&#22797;&#26434;&#25968;&#25454;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#24182;&#33021;&#25191;&#34892;&#19982;&#33410;&#28857;&#12289;&#33410;&#28857;&#23545;&#12289;&#23376;&#22270;&#25110;&#25972;&#20010;&#22270;&#32467;&#26500;&#30456;&#20851;&#30340;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the expansive realm of drug discovery, with approximately 15,000 known drugs and only around 4,200 approved, the combinatorial nature of the chemical space presents a formidable challenge. While Artificial Intelligence (AI) has emerged as a powerful ally, traditional AI frameworks face significant hurdles. This manuscript introduces CardiGraphormer, a groundbreaking approach that synergizes self-supervised learning (SSL), Graph Neural Networks (GNNs), and Cardinality Preserving Attention to revolutionize drug discovery. CardiGraphormer, a novel combination of Graphormer and Cardinality Preserving Attention, leverages SSL to learn potent molecular representations and employs GNNs to extract molecular fingerprints, enhancing predictive performance and interpretability while reducing computation time. It excels in handling complex data like molecular structures and performs tasks associated with nodes, pairs of nodes, subgraphs, or entire graph structures. CardiGraphormer's potential a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#20855;&#26377;&#36890;&#29992;&#28608;&#27963;&#20989;&#25968;&#30340;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#23450;&#37327;&#20989;&#25968;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#65292;&#25910;&#25947;&#36895;&#24230;&#21462;&#20915;&#20110;&#28608;&#27963;&#20989;&#25968;&#30340;&#24179;&#28369;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.16932</link><description>&lt;p&gt;
&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#23450;&#37327;&#20989;&#25968;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;
&lt;/p&gt;
&lt;p&gt;
A Quantitative Functional Central Limit Theorem for Shallow Neural Networks. (arXiv:2306.16932v1 [math.PR] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16932
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#20855;&#26377;&#36890;&#29992;&#28608;&#27963;&#20989;&#25968;&#30340;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#23450;&#37327;&#20989;&#25968;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#65292;&#25910;&#25947;&#36895;&#24230;&#21462;&#20915;&#20110;&#28608;&#27963;&#20989;&#25968;&#30340;&#24179;&#28369;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#20855;&#26377;&#36890;&#29992;&#28608;&#27963;&#20989;&#25968;&#30340;&#21333;&#38544;&#34255;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#23450;&#37327;&#20989;&#25968;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#12290;&#25105;&#20204;&#24314;&#31435;&#30340;&#25910;&#25947;&#36895;&#24230;&#20005;&#37325;&#20381;&#36182;&#20110;&#28608;&#27963;&#20989;&#25968;&#30340;&#24179;&#28369;&#24615;&#65292;&#20174;&#38750;&#21487;&#24494;&#30340;&#24773;&#20917;&#65288;&#22914;Relu&#65289;&#30340;&#23545;&#25968;&#32423;&#21035;&#21040;&#38750;&#24120;&#35268;&#21017;&#28608;&#27963;&#20989;&#25968;&#30340;$\sqrt{n}$&#32423;&#21035;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#24037;&#20855;&#26159;Stein-Malliavin&#26041;&#27861;&#30340;&#20989;&#25968;&#29256;&#26412;&#65307;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#22823;&#37327;&#21033;&#29992;&#20102;Bourguin&#21644;Campese&#65288;2020&#65289;&#26368;&#36817;&#24314;&#31435;&#30340;&#23450;&#37327;&#20989;&#25968;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
We prove a Quantitative Functional Central Limit Theorem for one-hidden-layer neural networks with generic activation function. The rates of convergence that we establish depend heavily on the smoothness of the activation function, and they range from logarithmic in non-differentiable cases such as the Relu to $\sqrt{n}$ for very regular activations. Our main tools are functional versions of the Stein-Malliavin approach; in particular, we exploit heavily a quantitative functional central limit theorem which has been recently established by Bourguin and Campese (2020).
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#39532;&#23572;&#31185;&#22827;&#38142;&#30740;&#31350;&#20102;&#24120;&#27493;&#38271;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#24615;&#36136;&#65292;&#35777;&#26126;&#20102;&#36845;&#20195;&#25910;&#25947;&#20110;&#19968;&#20010;&#19981;&#21464;&#20998;&#24067;&#65292;&#24182;&#33719;&#24471;&#20102;&#39640;&#32622;&#20449;&#24230;&#36793;&#30028;&#12290;</title><link>http://arxiv.org/abs/2306.11497</link><description>&lt;p&gt;
&#22522;&#20110;&#39532;&#23572;&#31185;&#22827;&#38142;&#30340;&#24120;&#27493;&#38271;SGD&#30340;&#25910;&#25947;&#21644;&#38598;&#20013;&#24615;&#36136;
&lt;/p&gt;
&lt;p&gt;
Convergence and concentration properties of constant step-size SGD through Markov chains. (arXiv:2306.11497v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11497
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#39532;&#23572;&#31185;&#22827;&#38142;&#30740;&#31350;&#20102;&#24120;&#27493;&#38271;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#24615;&#36136;&#65292;&#35777;&#26126;&#20102;&#36845;&#20195;&#25910;&#25947;&#20110;&#19968;&#20010;&#19981;&#21464;&#20998;&#24067;&#65292;&#24182;&#33719;&#24471;&#20102;&#39640;&#32622;&#20449;&#24230;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20351;&#29992;&#24120;&#27493;&#38271;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#20248;&#21270;&#24179;&#28369;&#19988;&#24378;&#20984;&#30340;&#30446;&#26631;&#65292;&#24182;&#36890;&#36807;&#39532;&#23572;&#31185;&#22827;&#38142;&#30740;&#31350;&#20854;&#24615;&#36136;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#23545;&#20110;&#20855;&#26377;&#36731;&#24494;&#21463;&#25511;&#26041;&#24046;&#30340;&#26080;&#20559;&#26799;&#24230;&#20272;&#35745;&#65292;&#36845;&#20195;&#20197;&#24635;&#21464;&#24046;&#36317;&#31163;&#25910;&#25947;&#20110;&#19968;&#20010;&#19981;&#21464;&#20998;&#24067;&#12290;&#25105;&#20204;&#36824;&#22312;&#19982;&#20197;&#21069;&#24037;&#20316;&#30456;&#27604;&#26799;&#24230;&#22122;&#22768;&#20998;&#24067;&#30340;&#25918;&#23485;&#20551;&#35774;&#19979;&#65292;&#22312;Wasserstein-2&#36317;&#31163;&#19979;&#24314;&#31435;&#20102;&#36825;&#31181;&#25910;&#25947;&#24615;&#12290;&#30001;&#20110;&#26497;&#38480;&#20998;&#24067;&#30340;&#19981;&#21464;&#24615;&#36136;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#24403;&#36825;&#20123;&#23545;&#20110;&#26799;&#24230;&#25104;&#31435;&#26102;&#65292;&#21518;&#32773;&#32487;&#25215;&#20102;&#20122;&#39640;&#26031;&#25110;&#20122;&#25351;&#25968;&#27987;&#24230;&#29305;&#24615;&#12290;&#36825;&#20801;&#35768;&#25512;&#23548;&#20986;&#23545;&#20110;&#26368;&#32456;&#20272;&#35745;&#30340;&#39640;&#32622;&#20449;&#24230;&#36793;&#30028;&#12290;&#26368;&#21518;&#65292;&#22312;&#36825;&#31181;&#26465;&#20214;&#19979;&#65292;&#22312;&#32447;&#24615;&#24773;&#20917;&#19979;&#65292;&#23545;&#20110;Polyak-Ruppert&#24207;&#21015;&#30340;&#23614;&#37096;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#19968;&#20010;&#26080;&#32500;&#24230;&#20559;&#24046;&#38480;&#21046;&#12290;&#25152;&#26377;&#32467;&#26524;&#22343;&#20026;&#38750;&#28176;&#36817;&#24615;&#36136;&#65292;&#24182;&#35752;&#35770;&#20102;&#20854;&#21518;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the optimization of a smooth and strongly convex objective using constant step-size stochastic gradient descent (SGD) and study its properties through the prism of Markov chains. We show that, for unbiased gradient estimates with mildly controlled variance, the iteration converges to an invariant distribution in total variation distance. We also establish this convergence in Wasserstein-2 distance under a relaxed assumption on the gradient noise distribution compared to previous work. Thanks to the invariance property of the limit distribution, our analysis shows that the latter inherits sub-Gaussian or sub-exponential concentration properties when these hold true for the gradient. This allows the derivation of high-confidence bounds for the final estimate. Finally, under such conditions in the linear case, we obtain a dimension-free deviation bound for the Polyak-Ruppert average of a tail sequence. All our results are non-asymptotic and their consequences are discussed thr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#39318;&#27425;&#30740;&#31350;&#20102;&#20855;&#26377;&#32593;&#32476;&#36741;&#21161;&#20449;&#24687;&#30340;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#23398;&#20064;&#38382;&#39064;&#65292;&#24341;&#20837;&#20102;Reg-Graph&#27169;&#22411;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;AMP&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#22312;&#23454;&#39564;&#20013;&#20248;&#20110;&#29616;&#26377;&#30340;&#20960;&#31181;&#32593;&#32476;&#36741;&#21161;&#22238;&#24402;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.05679</link><description>&lt;p&gt;
&#20855;&#26377;&#32593;&#32476;&#36741;&#21161;&#20449;&#24687;&#30340;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Bayes optimal learning in high-dimensional linear regression with network side information. (arXiv:2306.05679v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05679
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#39318;&#27425;&#30740;&#31350;&#20102;&#20855;&#26377;&#32593;&#32476;&#36741;&#21161;&#20449;&#24687;&#30340;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#23398;&#20064;&#38382;&#39064;&#65292;&#24341;&#20837;&#20102;Reg-Graph&#27169;&#22411;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;AMP&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#22312;&#23454;&#39564;&#20013;&#20248;&#20110;&#29616;&#26377;&#30340;&#20960;&#31181;&#32593;&#32476;&#36741;&#21161;&#22238;&#24402;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22522;&#22240;&#32452;&#23398;&#12289;&#34507;&#30333;&#36136;&#32452;&#23398;&#21644;&#31070;&#32463;&#31185;&#23398;&#31561;&#24212;&#29992;&#20013;&#65292;&#20855;&#26377;&#32593;&#32476;&#36741;&#21161;&#20449;&#24687;&#30340;&#30417;&#30563;&#23398;&#20064;&#38382;&#39064;&#32463;&#24120;&#20986;&#29616;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#30740;&#31350;&#20102;&#20855;&#26377;&#32593;&#32476;&#36741;&#21161;&#20449;&#24687;&#30340;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#23398;&#20064;&#38382;&#39064;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#39318;&#20808;&#24341;&#20837;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#29983;&#25104;&#27169;&#22411;&#65288;&#31216;&#20026;Reg-Graph&#27169;&#22411;&#65289;&#65292;&#36890;&#36807;&#19968;&#32452;&#20849;&#21516;&#30340;&#28508;&#22312;&#21442;&#25968;&#20026;&#30417;&#30563;&#25968;&#25454;&#21644;&#35266;&#27979;&#21040;&#30340;&#32593;&#32476;&#35774;&#23450;&#20102;&#19968;&#20010;&#32852;&#21512;&#20998;&#24067;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#36817;&#20284;&#28040;&#24687;&#20256;&#36882;&#65288;AMP&#65289;&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#22312;&#38750;&#24120;&#19968;&#33324;&#30340;&#26465;&#20214;&#19979;&#21487;&#35777;&#26126;&#26159;&#36125;&#21494;&#26031;&#26368;&#20248;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23545;&#28508;&#22312;&#20449;&#21495;&#21644;&#35266;&#27979;&#21040;&#30340;&#25968;&#25454;&#20043;&#38388;&#30340;&#26497;&#38480;&#20114;&#20449;&#24687;&#36827;&#34892;&#20102;&#34920;&#24449;&#65292;&#20174;&#32780;&#31934;&#30830;&#37327;&#21270;&#20102;&#32593;&#32476;&#36741;&#21161;&#20449;&#24687;&#22312;&#22238;&#24402;&#38382;&#39064;&#20013;&#30340;&#32479;&#35745;&#24433;&#21709;&#12290;&#25105;&#20204;&#23545;&#27169;&#25311;&#25968;&#25454;&#21644;&#23454;&#38469;&#25968;&#25454;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#30340;&#20960;&#31181;&#32593;&#32476;&#36741;&#21161;&#22238;&#24402;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Supervised learning problems with side information in the form of a network arise frequently in applications in genomics, proteomics and neuroscience. For example, in genetic applications, the network side information can accurately capture background biological information on the intricate relations among the relevant genes. In this paper, we initiate a study of Bayes optimal learning in high-dimensional linear regression with network side information. To this end, we first introduce a simple generative model (called the Reg-Graph model) which posits a joint distribution for the supervised data and the observed network through a common set of latent parameters. Next, we introduce an iterative algorithm based on Approximate Message Passing (AMP) which is provably Bayes optimal under very general conditions. In addition, we characterize the limiting mutual information between the latent signal and the data observed, and thus precisely quantify the statistical impact of the network side 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#23485;&#26494;&#24347;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#35777;&#26126;&#36866;&#24403;&#26089;&#20572;&#30340;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#22810;&#23618;&#23485;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#23454;&#29616;&#26368;&#23567;&#26497;&#22823;&#29575;&#65292;&#21069;&#25552;&#26159;&#22238;&#24402;&#20989;&#25968;&#22312;&#23545;&#24212;&#30340;NTK&#30456;&#20851;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#65292;&#20294;&#36807;&#24230;&#25311;&#21512;&#30340;&#22810;&#23618;&#23485;&#31070;&#32463;&#32593;&#32476;&#22312;$\mathbb S^{d}$&#19978;&#19981;&#33021;&#24456;&#22909;&#22320;&#27867;&#21270;&#12290;</title><link>http://arxiv.org/abs/2305.02657</link><description>&lt;p&gt;
&#28145;&#24230;&#23485;&#26494;&#24347;&#31070;&#32463;&#32593;&#32476;&#30340;&#32479;&#35745;&#20248;&#21270;&#24615;
&lt;/p&gt;
&lt;p&gt;
Statistical Optimality of Deep Wide Neural Networks. (arXiv:2305.02657v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.02657
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28145;&#24230;&#23485;&#26494;&#24347;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#35777;&#26126;&#36866;&#24403;&#26089;&#20572;&#30340;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#22810;&#23618;&#23485;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#23454;&#29616;&#26368;&#23567;&#26497;&#22823;&#29575;&#65292;&#21069;&#25552;&#26159;&#22238;&#24402;&#20989;&#25968;&#22312;&#23545;&#24212;&#30340;NTK&#30456;&#20851;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#65292;&#20294;&#36807;&#24230;&#25311;&#21512;&#30340;&#22810;&#23618;&#23485;&#31070;&#32463;&#32593;&#32476;&#22312;$\mathbb S^{d}$&#19978;&#19981;&#33021;&#24456;&#22909;&#22320;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23450;&#20041;&#22312;&#26377;&#30028;&#22495;$\mathcal X \subset \mathbb R^{d}$&#19978;&#30340;&#28145;&#24230;&#23485;&#26494;&#24347;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#39318;&#20808;&#35777;&#26126;&#20102;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#33021;&#21147;&#21487;&#20197;&#34987;&#30456;&#24212;&#30340;&#28145;&#24230;&#31070;&#32463;&#20999;&#21521;&#26680;&#22238;&#24402;&#25152;&#23436;&#20840;&#25551;&#32472;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#28145;&#24230;&#31070;&#32463;&#20999;&#21521;&#26680;&#30340;&#35889;&#29305;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#28145;&#24230;&#31070;&#32463;&#20999;&#21521;&#26680;&#22312;$\mathcal{X}$&#19978;&#20026;&#27491;&#23450;&#65292;&#20854;&#29305;&#24449;&#20540;&#34928;&#20943;&#29575;&#20026;$(d+1)/d$&#12290;&#30001;&#20110;&#26680;&#22238;&#24402;&#20013;&#24050;&#32463;&#24314;&#31435;&#30340;&#29702;&#35770;&#65292;&#25105;&#20204;&#24471;&#20986;&#32467;&#35770;&#65292;&#36866;&#24403;&#26089;&#20572;&#30340;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#22810;&#23618;&#23485;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#23454;&#29616;&#26368;&#23567;&#26497;&#22823;&#29575;&#65292;&#21069;&#25552;&#26159;&#22238;&#24402;&#20989;&#25968;&#22312;&#23545;&#24212;&#30340;NTK&#30456;&#20851;&#30340;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#36807;&#24230;&#25311;&#21512;&#30340;&#22810;&#23618;&#23485;&#31070;&#32463;&#32593;&#32476;&#22312;$\mathbb S^{d}$&#19978;&#19981;&#33021;&#24456;&#22909;&#22320;&#27867;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we consider the generalization ability of deep wide feedforward ReLU neural networks defined on a bounded domain $\mathcal X \subset \mathbb R^{d}$. We first demonstrate that the generalization ability of the neural network can be fully characterized by that of the corresponding deep neural tangent kernel (NTK) regression. We then investigate on the spectral properties of the deep NTK and show that the deep NTK is positive definite on $\mathcal{X}$ and its eigenvalue decay rate is $(d+1)/d$. Thanks to the well established theories in kernel regression, we then conclude that multilayer wide neural networks trained by gradient descent with proper early stopping achieve the minimax rate, provided that the regression function lies in the reproducing kernel Hilbert space (RKHS) associated with the corresponding NTK. Finally, we illustrate that the overfitted multilayer wide neural networks can not generalize well on $\mathbb S^{d}$.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#27969;&#24335;&#25968;&#25454;&#20013;&#30340;&#20027;&#21160;&#35745;&#36153;&#26631;&#27880;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#36890;&#36807;&#36873;&#25321;&#26631;&#35760;&#28857;&#24182;&#32500;&#25252;&#26102;&#38388;&#21644;&#25104;&#26412;&#30456;&#20851;&#38408;&#20540;&#65292;&#22312;$T$&#36718;&#20043;&#21518;&#23454;&#29616;&#20102;$O(B^{\frac { 1 }{ 3 }}K^{\frac { 1 }{ 3 }}T^{\frac { 2 }{ 3 }})$&#30340;&#26368;&#22351;&#24773;&#20917;&#19978;&#30028;&#12290;</title><link>http://arxiv.org/abs/2304.06808</link><description>&lt;p&gt;
&#27969;&#24335;&#25968;&#25454;&#20027;&#21160;&#35745;&#36153;&#26631;&#27880;
&lt;/p&gt;
&lt;p&gt;
Active Cost-aware Labeling of Streaming Data. (arXiv:2304.06808v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06808
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#27969;&#24335;&#25968;&#25454;&#20013;&#30340;&#20027;&#21160;&#35745;&#36153;&#26631;&#27880;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#27861;&#65292;&#36890;&#36807;&#36873;&#25321;&#26631;&#35760;&#28857;&#24182;&#32500;&#25252;&#26102;&#38388;&#21644;&#25104;&#26412;&#30456;&#20851;&#38408;&#20540;&#65292;&#22312;$T$&#36718;&#20043;&#21518;&#23454;&#29616;&#20102;$O(B^{\frac { 1 }{ 3 }}K^{\frac { 1 }{ 3 }}T^{\frac { 2 }{ 3 }})$&#30340;&#26368;&#22351;&#24773;&#20917;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20027;&#21160;&#26631;&#35760;&#27969;&#25968;&#25454;&#38382;&#39064;&#65292;&#20854;&#20013;&#20027;&#21160;&#23398;&#20064;&#32773;&#38754;&#20020;&#19968;&#31995;&#21015;&#25968;&#25454;&#28857;&#65292;&#24182;&#24517;&#39035;&#36890;&#36807;&#26114;&#36149;&#30340;&#23454;&#39564;&#31934;&#24515;&#36873;&#25321;&#21738;&#20123;&#28857;&#36827;&#34892;&#26631;&#35760;&#65292;&#27492;&#31867;&#38382;&#39064;&#24120;&#24120;&#20986;&#29616;&#22312;&#21307;&#30103;&#21644;&#22825;&#25991;&#23398;&#31561;&#39046;&#22495;&#12290;&#25105;&#20204;&#39318;&#20808;&#30740;&#31350;&#30340;&#26159;&#25968;&#25454;&#36755;&#20837;&#23646;&#20110;$K$&#20010;&#31163;&#25955;&#20998;&#24067;&#20043;&#19968;&#30340;&#24773;&#20917;&#65292;&#24182;&#36890;&#36807;&#25439;&#22833;&#20989;&#25968;&#24418;&#24335;&#21270;&#25551;&#36848;&#27492;&#38382;&#39064;&#65292;&#35813;&#25439;&#22833;&#20989;&#25968;&#25429;&#25417;&#20102;&#26631;&#35760;&#25104;&#26412;&#21644;&#39044;&#27979;&#35823;&#24046;&#12290;&#24403;&#26631;&#35760;&#25104;&#26412;&#20026;$B$&#26102;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#36890;&#36807;&#36873;&#25321;&#26631;&#35760;&#28857;&#65292;&#20165;&#22312;&#19981;&#30830;&#23450;&#24615;&#22823;&#20110;&#26102;&#38388;&#21644;&#25104;&#26412;&#30456;&#20851;&#38408;&#20540;&#26102;&#36827;&#34892;&#65292;&#21487;&#20197;&#22312;$T$&#36718;&#20043;&#21518;&#23454;&#29616;$O(B^{\frac { 1 }{ 3 }}K^{\frac { 1 }{ 3 }}T^{\frac { 2 }{ 3 }})$&#30340;&#26368;&#22351;&#24773;&#20917;&#19978;&#30028;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#26356;&#32454;&#33268;&#30340;&#19978;&#30028;&#65292;&#35777;&#26126;&#20102;&#22312;&#21040;&#36798;&#27169;&#24335;&#26356;&#26377;&#21033;&#26102;&#65292;&#31639;&#27861;&#21487;&#20197;&#36866;&#24212;&#21040;&#36798;&#27169;&#24335;&#65292;&#24182;&#23454;&#29616;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#36824;&#34917;&#20805;&#20102;&#20004;&#20010;&#19978;&#30028;&#30340;&#21305;&#37197;&#19979;&#30028;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#27969;&#25968;&#25454;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#26631;&#35760;&#27969;&#25968;&#25454;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#19982;&#21069;&#38754;&#24773;&#20917;&#31867;&#20284;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study actively labeling streaming data, where an active learner is faced with a stream of data points and must carefully choose which of these points to label via an expensive experiment. Such problems frequently arise in applications such as healthcare and astronomy. We first study a setting when the data's inputs belong to one of $K$ discrete distributions and formalize this problem via a loss that captures the labeling cost and the prediction error. When the labeling cost is $B$, our algorithm, which chooses to label a point if the uncertainty is larger than a time and cost dependent threshold, achieves a worst-case upper bound of $O(B^{\frac{1}{3}} K^{\frac{1}{3}} T^{\frac{2}{3}})$ on the loss after $T$ rounds. We also provide a more nuanced upper bound which demonstrates that the algorithm can adapt to the arrival pattern, and achieves better performance when the arrival pattern is more favorable. We complement both upper bounds with matching lower bounds. We next study this pr
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22240;&#26524;&#20381;&#36182;&#22270;&#65288;CDPs&#65289;&#26469;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#25110;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#22240;&#26524;&#20381;&#36182;&#20851;&#31995;&#12290;CDPs&#19982;&#20256;&#32479;&#26041;&#27861;&#19981;&#21516;&#65292;&#21487;&#20197;&#27169;&#22359;&#21270;&#22320;&#32467;&#21512;&#22240;&#26524;&#23398;&#20064;&#25110;&#25935;&#24863;&#24230;&#20998;&#26512;&#26041;&#27861;&#12290;&#36825;&#20123;&#22270;&#34920;&#21487;&#20197;&#25104;&#20026;&#21487;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#24037;&#20855;&#21253;&#20013;&#30340;&#24378;&#22823;&#24037;&#20855;&#65292;&#24182;&#23545;&#30456;&#20851;&#24212;&#29992;&#20570;&#20986;&#36129;&#29486;&#12290;</title><link>http://arxiv.org/abs/2303.04209</link><description>&lt;p&gt;
&#22240;&#26524;&#20381;&#36182;&#22270;
&lt;/p&gt;
&lt;p&gt;
Causal Dependence Plots. (arXiv:2303.04209v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.04209
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22240;&#26524;&#20381;&#36182;&#22270;&#65288;CDPs&#65289;&#26469;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#25110;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#22240;&#26524;&#20381;&#36182;&#20851;&#31995;&#12290;CDPs&#19982;&#20256;&#32479;&#26041;&#27861;&#19981;&#21516;&#65292;&#21487;&#20197;&#27169;&#22359;&#21270;&#22320;&#32467;&#21512;&#22240;&#26524;&#23398;&#20064;&#25110;&#25935;&#24863;&#24230;&#20998;&#26512;&#26041;&#27861;&#12290;&#36825;&#20123;&#22270;&#34920;&#21487;&#20197;&#25104;&#20026;&#21487;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#24037;&#20855;&#21253;&#20013;&#30340;&#24378;&#22823;&#24037;&#20855;&#65292;&#24182;&#23545;&#30456;&#20851;&#24212;&#29992;&#20570;&#20986;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#25110;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#37325;&#35201;&#24615;&#36234;&#26469;&#36234;&#22823;&#12290;&#20026;&#20102;&#26126;&#26234;&#22320;&#20351;&#29992;&#36825;&#20123;&#25968;&#25454;&#39537;&#21160;&#30340;&#31995;&#32479;&#65292;&#25105;&#20204;&#24517;&#39035;&#20102;&#35299;&#23427;&#20204;&#22914;&#20309;&#19982;&#19990;&#30028;&#20114;&#21160;&#65292;&#21253;&#25324;&#23427;&#20204;&#22312;&#25968;&#25454;&#36755;&#20837;&#19978;&#30340;&#22240;&#26524;&#20381;&#36182;&#20851;&#31995;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#22240;&#26524;&#20381;&#36182;&#22270; (CDPs)&#65292;&#29992;&#20110;&#21487;&#35270;&#21270;&#19968;&#20010;&#21464;&#37327;&#65288;&#32467;&#26524;&#65289;&#22914;&#20309;&#38543;&#21478;&#19968;&#20010;&#21464;&#37327;&#65288;&#39044;&#27979;&#22120;&#65289;&#30340;&#21464;&#21270;&#32780;&#21464;&#21270;&#65292;&#20197;&#21450;&#20854;&#20182;&#39044;&#27979;&#22120;&#21464;&#37327;&#30340;&#22240;&#26524;&#21464;&#21270;&#12290;&#20851;&#38190;&#26159;&#65292;CDPs&#19982;&#22522;&#20110;&#20445;&#25345;&#20854;&#20182;&#39044;&#27979;&#22120;&#24658;&#23450;&#25110;&#20551;&#35774;&#23427;&#20204;&#29420;&#31435;&#30340;&#26631;&#20934;&#26041;&#27861;&#19981;&#21516;&#12290;CDPs&#21033;&#29992;&#36741;&#21161;&#22240;&#26524;&#27169;&#22411;&#65292;&#22240;&#20026;&#22240;&#26524;&#32467;&#35770;&#38656;&#35201;&#22240;&#26524;&#20551;&#35774;&#12290;&#36890;&#36807;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#23454;&#39564;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;CDPs&#21487;&#20197;&#19982;&#22240;&#26524;&#23398;&#20064;&#25110;&#25935;&#24863;&#24615;&#20998;&#26512;&#26041;&#27861;&#20197;&#27169;&#22359;&#21270;&#30340;&#26041;&#24335;&#32467;&#21512;&#20351;&#29992;&#12290;&#30001;&#20110;&#20154;&#20204;&#32463;&#24120;&#22312;&#36755;&#20837;-&#36755;&#20986;&#20381;&#36182;&#24615;&#26041;&#38754;&#36827;&#34892;&#22240;&#26524;&#24605;&#32771;&#65292;CDPs&#21487;&#20197;&#25104;&#20026;xAI&#25110;&#21487;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#24037;&#20855;&#21253;&#20013;&#24378;&#26377;&#21147;&#30340;&#24037;&#20855;&#65292;&#24182;&#23545;&#24212;&#29992;&#26377;&#25152;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
Explaining artificial intelligence or machine learning models is increasingly important. To use such data-driven systems wisely we must understand how they interact with the world, including how they depend causally on data inputs. In this work we develop Causal Dependence Plots (CDPs) to visualize how one variable--an outcome--depends on changes in another variable--a predictor--$\textit{along with any consequent causal changes in other predictor variables}$. Crucially, CDPs differ from standard methods based on holding other predictors constant or assuming they are independent. CDPs make use of an auxiliary causal model because causal conclusions require causal assumptions. With simulations and real data experiments, we show CDPs can be combined in a modular way with methods for causal learning or sensitivity analysis. Since people often think causally about input-output dependence, CDPs can be powerful tools in the xAI or interpretable machine learning toolkit and contribute to appl
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312; exp-concave &#32479;&#35745;&#23398;&#20064;&#20013;&#20351;&#29992;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#36866;&#29992;&#20110;&#24191;&#27867;&#31867;&#21035;&#30340;&#26377;&#30028; exp-concave &#25439;&#22833;&#30340;&#36807;&#37327;&#39118;&#38505;&#30028;&#65292;&#32500;&#24230;&#21644;&#26679;&#26412;&#22823;&#23567;&#23545;&#32467;&#26524;&#26377;&#24433;&#21709;&#65292;&#24182;&#19988;&#22522;&#20110;&#32479;&#19968;&#20960;&#20309;&#20551;&#35774;&#21644;&#26412;&#22320;&#35268;&#33539;&#30340;&#27010;&#24565;&#12290;</title><link>http://arxiv.org/abs/2302.10726</link><description>&lt;p&gt;
&#22312; exp-concave &#32479;&#35745;&#23398;&#20064;&#20013;&#25506;&#32034;&#26412;&#22320;&#35268;&#33539;
&lt;/p&gt;
&lt;p&gt;
Exploring Local Norms in Exp-concave Statistical Learning. (arXiv:2302.10726v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.10726
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312; exp-concave &#32479;&#35745;&#23398;&#20064;&#20013;&#20351;&#29992;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#36866;&#29992;&#20110;&#24191;&#27867;&#31867;&#21035;&#30340;&#26377;&#30028; exp-concave &#25439;&#22833;&#30340;&#36807;&#37327;&#39118;&#38505;&#30028;&#65292;&#32500;&#24230;&#21644;&#26679;&#26412;&#22823;&#23567;&#23545;&#32467;&#26524;&#26377;&#24433;&#21709;&#65292;&#24182;&#19988;&#22522;&#20110;&#32479;&#19968;&#20960;&#20309;&#20551;&#35774;&#21644;&#26412;&#22320;&#35268;&#33539;&#30340;&#27010;&#24565;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#22312;&#19968;&#20010;&#20984;&#31867;&#20013;&#22788;&#29702;&#24102;&#26377; exp-concave &#25439;&#22833;&#30340;&#38543;&#26426;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#22238;&#31572;&#20102;&#19968;&#20123;&#20043;&#21069;&#30740;&#31350;&#20013;&#25552;&#20986;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#19968;&#20010;&#23545;&#20110;&#19968;&#31867;&#24191;&#27867;&#30340;&#26377;&#30028; exp-concave &#25439;&#22833;&#30340; $O(d/n + \log(1/\delta)/n)$ &#36807;&#37327;&#39118;&#38505;&#30028;&#65292;&#20854;&#20013; $d$ &#26159;&#20984;&#21442;&#32771;&#38598;&#30340;&#32500;&#24230;&#65292;$n$ &#26159;&#26679;&#26412;&#22823;&#23567;&#65292;$\delta$ &#26159;&#32622;&#20449;&#27700;&#24179;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#22522;&#20110;&#23545;&#25439;&#22833;&#26799;&#24230;&#30340;&#32479;&#19968;&#20960;&#20309;&#20551;&#35774;&#21644;&#26412;&#22320;&#35268;&#33539;&#30340;&#27010;&#24565;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of stochastic convex optimization with exp-concave losses using Empirical Risk Minimization in a convex class. Answering a question raised in several prior works, we provide a $O( d / n + \log( 1 / \delta) / n )$ excess risk bound valid for a wide class of bounded exp-concave losses, where $d$ is the dimension of the convex reference set, $n$ is the sample size, and $\delta$ is the confidence level. Our result is based on a unified geometric assumption on the gradient of losses and the notion of local norms.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21457;&#29616;&#65292;&#20165;&#35843;&#25972;&#31070;&#32463;&#32593;&#32476;&#30340;&#24402;&#19968;&#21270;&#23618;&#21442;&#25968;&#23601;&#21487;&#20197;&#36798;&#21040;&#39640;&#20934;&#30830;&#24615;&#65292;&#29978;&#33267;&#21487;&#20197;&#37325;&#24314;&#27604;&#21407;&#32593;&#32476;&#23567;O(&#26681;&#21495;&#23485;&#24230;)&#20493;&#30340;&#30446;&#26631;&#32593;&#32476;&#12290;</title><link>http://arxiv.org/abs/2302.07937</link><description>&lt;p&gt;
&#20165;&#35843;&#25972;&#24402;&#19968;&#21270;&#23618;&#30340;&#34920;&#36798;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
The Expressive Power of Tuning Only the Normalization Layers. (arXiv:2302.07937v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.07937
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21457;&#29616;&#65292;&#20165;&#35843;&#25972;&#31070;&#32463;&#32593;&#32476;&#30340;&#24402;&#19968;&#21270;&#23618;&#21442;&#25968;&#23601;&#21487;&#20197;&#36798;&#21040;&#39640;&#20934;&#30830;&#24615;&#65292;&#29978;&#33267;&#21487;&#20197;&#37325;&#24314;&#27604;&#21407;&#32593;&#32476;&#23567;O(&#26681;&#21495;&#23485;&#24230;)&#20493;&#30340;&#30446;&#26631;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29305;&#24449;&#24402;&#19968;&#21270;&#36716;&#25442;&#65292;&#22914;&#25209;&#37327;&#24402;&#19968;&#21270;&#21644;&#23618;&#24402;&#19968;&#21270;&#65292;&#24050;&#25104;&#20026;&#24403;&#20170;&#20808;&#36827;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#19981;&#21487;&#25110;&#32570;&#30340;&#32452;&#25104;&#37096;&#20998;&#12290;&#20851;&#20110;&#24494;&#35843;&#22823;&#22411;&#39044;&#35757;&#32451;&#27169;&#22411;&#30340;&#26368;&#36817;&#30740;&#31350;&#34920;&#26126;&#65292;&#20165;&#35843;&#25972;&#36825;&#20123;&#20223;&#23556;&#21464;&#25442;&#30340;&#21442;&#25968;&#23601;&#21487;&#20197;&#22312;&#19979;&#28216;&#20219;&#21153;&#20013;&#33719;&#24471;&#39640;&#20934;&#30830;&#24615;&#12290;&#36825;&#20123;&#30740;&#31350;&#32467;&#26524;&#24341;&#21457;&#20102;&#23545;&#35843;&#25972;&#20923;&#32467;&#32593;&#32476;&#30340;&#24402;&#19968;&#21270;&#23618;&#30340;&#34920;&#36798;&#33021;&#21147;&#30340;&#38382;&#39064;&#12290;&#26412;&#25991;&#39318;&#27425;&#25506;&#35752;&#36825;&#20010;&#38382;&#39064;&#65292;&#24182;&#26174;&#31034;&#23545;&#20110;&#38543;&#26426;ReLU&#32593;&#32476;&#65292;&#20165;&#24494;&#35843;&#20854;&#24402;&#19968;&#21270;&#23618;&#21487;&#20197;&#37325;&#24314;&#20219;&#20309;&#22823;&#23567;&#20026;O(&#26681;&#21495;&#23485;&#24230;)&#20493;&#23567;&#30340;&#30446;&#26631;&#32593;&#32476;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#21363;&#20351;&#22312;&#38543;&#26426;&#31232;&#30095;&#32593;&#32476;&#20013;&#65292;&#22312;&#36275;&#22815;&#36229;&#21442;&#25968;&#21270;&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#20010;&#32467;&#35770;&#20063;&#25104;&#31435;&#65292;&#19982;&#20808;&#21069;&#30340;&#23454;&#35777;&#24037;&#20316;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;
Feature normalization transforms such as Batch and Layer-Normalization have become indispensable ingredients of state-of-the-art deep neural networks. Recent studies on fine-tuning large pretrained models indicate that just tuning the parameters of these affine transforms can achieve high accuracy for downstream tasks. These findings open the questions about the expressive power of tuning the normalization layers of frozen networks. In this work, we take the first step towards this question and show that for random ReLU networks, fine-tuning only its normalization layers can reconstruct any target network that is $O(\sqrt{\text{width}})$ times smaller. We show that this holds even for randomly sparsified networks, under sufficient overparameterization, in agreement with prior empirical work.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25913;&#36827;&#20102;&#22810;&#20803;&#33258;&#36866;&#24212;&#22238;&#24402;&#26679;&#26465;&#65288;MARS&#65289;&#30340;&#24615;&#33021;&#65292;&#36890;&#36807;&#20351;&#29992;&#21327;&#21464;&#37327;&#30340;&#32447;&#24615;&#32452;&#21512;&#26469;&#23454;&#29616;&#36275;&#22815;&#30340;&#32500;&#24230;&#32422;&#20943;&#65292;&#25552;&#39640;&#20102;&#20272;&#35745;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2302.05790</link><description>&lt;p&gt;
&#32500;&#24230;&#32422;&#20943;&#19982;MARS
&lt;/p&gt;
&lt;p&gt;
Dimension Reduction and MARS. (arXiv:2302.05790v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.05790
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25913;&#36827;&#20102;&#22810;&#20803;&#33258;&#36866;&#24212;&#22238;&#24402;&#26679;&#26465;&#65288;MARS&#65289;&#30340;&#24615;&#33021;&#65292;&#36890;&#36807;&#20351;&#29992;&#21327;&#21464;&#37327;&#30340;&#32447;&#24615;&#32452;&#21512;&#26469;&#23454;&#29616;&#36275;&#22815;&#30340;&#32500;&#24230;&#32422;&#20943;&#65292;&#25552;&#39640;&#20102;&#20272;&#35745;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20803;&#33258;&#36866;&#24212;&#22238;&#24402;&#26679;&#26465;&#65288;MARS&#65289;&#26159;&#38750;&#21442;&#25968;&#22810;&#20803;&#22238;&#24402;&#20272;&#35745;&#26041;&#27861;&#20013;&#30340;&#24120;&#29992;&#26041;&#27861;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;MARS&#22522;&#20110;&#36793;&#38469;&#26679;&#26465;&#65292;&#20026;&#20102;&#32771;&#34385;&#21327;&#21464;&#37327;&#20043;&#38388;&#30340;&#20132;&#20114;&#20316;&#29992;&#65292;&#24517;&#39035;&#20351;&#29992;&#36793;&#38469;&#26679;&#26465;&#30340;&#20056;&#31215;&#65292;&#36825;&#20250;&#23548;&#33268;&#22522;&#20989;&#25968;&#25968;&#37327;&#36807;&#22810;&#65292;&#24403;&#20132;&#20114;&#20316;&#29992;&#38454;&#25968;&#24456;&#39640;&#26102;&#65292;&#20272;&#35745;&#25928;&#29575;&#20250;&#38477;&#20302;&#12290;&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#21327;&#21464;&#37327;&#30340;&#32447;&#24615;&#32452;&#21512;&#26469;&#25913;&#36827;MARS&#30340;&#24615;&#33021;&#65292;&#23454;&#29616;&#20102;&#36275;&#22815;&#30340;&#32500;&#24230;&#32422;&#20943;&#12290;MARS&#30340;&#29305;&#27530;&#22522;&#20989;&#25968;&#26377;&#21161;&#20110;&#35745;&#31639;&#22238;&#24402;&#20989;&#25968;&#30340;&#26799;&#24230;&#65292;&#24182;&#19988;&#36890;&#36807;&#23545;&#26799;&#24230;&#30340;&#22806;&#31215;&#36827;&#34892;&#29305;&#24449;&#20998;&#26512;&#26469;&#20272;&#35745;&#32447;&#24615;&#32452;&#21512;&#12290;&#22312;&#19968;&#20123;&#25216;&#26415;&#26465;&#20214;&#19979;&#65292;&#23545;&#25152;&#25552;&#20986;&#30340;&#20272;&#35745;&#26041;&#27861;&#24314;&#31435;&#20102;&#28176;&#36817;&#29702;&#35770;&#12290;&#21253;&#25324;&#27169;&#25311;&#21644;&#23454;&#35777;&#24212;&#29992;&#30340;&#25968;&#20540;&#30740;&#31350;&#34920;&#26126;&#20102;&#20854;&#22312;&#32500;&#24230;&#32422;&#20943;&#21644;&#25913;&#36827;&#20272;&#35745;&#25928;&#26524;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The multivariate adaptive regression spline (MARS) is one of the popular estimation methods for nonparametric multivariate regressions. However, as MARS is based on marginal splines, to incorporate interactions of covariates, products of the marginal splines must be used, which leads to an unmanageable number of basis functions when the order of interaction is high and results in low estimation efficiency. In this paper, we improve the performance of MARS by using linear combinations of the covariates which achieve sufficient dimension reduction. The special basis functions of MARS facilitate calculation of gradients of the regression function, and estimation of the linear combinations is obtained via eigen-analysis of the outer-product of the gradients. Under some technical conditions, the asymptotic theory is established for the proposed estimation method. Numerical studies including both simulation and empirical applications show its effectiveness in dimension reduction and improvem
&lt;/p&gt;</description></item><item><title>SOBER&#31639;&#27861;&#26159;&#19968;&#31181;&#22312;&#31163;&#25955;&#21644;&#28151;&#21512;&#31354;&#38388;&#19978;&#36827;&#34892;&#39640;&#24182;&#34892;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#36827;&#34892;&#21487;&#25193;&#23637;&#21644;&#22810;&#26679;&#21270;&#30340;&#25209;&#37327;&#20840;&#23616;&#20248;&#21270;&#21644;&#31215;&#20998;&#65292;&#19988;&#20248;&#20110;11&#20010;&#31454;&#20105;&#22522;&#32447;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2301.11832</link><description>&lt;p&gt;
SOBER&#65306;&#31163;&#25955;&#21644;&#28151;&#21512;&#31354;&#38388;&#19978;&#39640;&#24182;&#34892;&#36125;&#21494;&#26031;&#20248;&#21270;&#21644;&#36125;&#21494;&#26031;&#31215;&#20998;
&lt;/p&gt;
&lt;p&gt;
SOBER: Highly Parallel Bayesian Optimization and Bayesian Quadrature over Discrete and Mixed Spaces. (arXiv:2301.11832v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11832
&lt;/p&gt;
&lt;p&gt;
SOBER&#31639;&#27861;&#26159;&#19968;&#31181;&#22312;&#31163;&#25955;&#21644;&#28151;&#21512;&#31354;&#38388;&#19978;&#36827;&#34892;&#39640;&#24182;&#34892;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#36827;&#34892;&#21487;&#25193;&#23637;&#21644;&#22810;&#26679;&#21270;&#30340;&#25209;&#37327;&#20840;&#23616;&#20248;&#21270;&#21644;&#31215;&#20998;&#65292;&#19988;&#20248;&#20110;11&#20010;&#31454;&#20105;&#22522;&#32447;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25209;&#22788;&#29702;&#36125;&#21494;&#26031;&#20248;&#21270;&#21644;&#36125;&#21494;&#26031;&#31215;&#20998;&#24050;&#34987;&#35777;&#26126;&#26159;&#22312;&#38656;&#24182;&#34892;&#26597;&#35810;&#26114;&#36149;&#30340;&#30446;&#26631;&#20989;&#25968;&#26102;&#25191;&#34892;&#20248;&#21270;&#21644;&#31215;&#20998;&#30340;&#39640;&#25928;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#26041;&#27861;&#19981;&#36866;&#29992;&#20110;&#22823;&#25209;&#37327;&#25805;&#20316;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#8212;&#8212;SOBER&#65292;&#23427;&#20801;&#35768;&#22312;&#31163;&#25955;&#21644;&#28151;&#21512;&#31354;&#38388;&#19978;&#20351;&#29992;&#20219;&#24847;&#37319;&#38598;&#20989;&#25968;&#21644;&#20869;&#26680;&#36827;&#34892;&#21487;&#25193;&#23637;&#21644;&#22810;&#26679;&#21270;&#30340;&#25209;&#37327;&#20840;&#23616;&#20248;&#21270;&#21644;&#31215;&#20998;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#20851;&#38190;&#22312;&#20110;&#23558;&#20840;&#23616;&#20248;&#21270;&#30340;&#25209;&#37327;&#36873;&#25321;&#37325;&#26032;&#23450;&#20041;&#20026;&#31215;&#20998;&#38382;&#39064;&#65292;&#24182;&#23558;&#37319;&#38598;&#20989;&#25968;&#30340;&#26368;&#22823;&#21270;&#65288;&#38750;&#20984;&#65289;&#26494;&#24347;&#20026;&#20869;&#26680;&#37325;&#32452;&#65288;&#20984;&#65289;&#65292;&#20174;&#32780;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#20004;&#20010;&#20219;&#21153;&#12290;&#25105;&#20204;&#23637;&#31034;SOBER&#20248;&#20110;11&#20010;&#31454;&#20105;&#22522;&#32447;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Batch Bayesian optimisation and Bayesian quadrature have been shown to be sample-efficient methods of performing optimisation and quadrature where expensive-to-evaluate objective functions can be queried in parallel. However, current methods do not scale to large batch sizes -- a frequent desideratum in practice (e.g. drug discovery or simulation-based inference). We present a novel algorithm, SOBER, which permits scalable and diversified batch global optimisation and quadrature with arbitrary acquisition functions and kernels over discrete and mixed spaces. The key to our approach is to reformulate batch selection for global optimisation as a quadrature problem, which relaxes acquisition function maximisation (non-convex) to kernel recombination (convex). Bridging global optimisation and quadrature can efficiently solve both tasks by balancing the merits of exploitative Bayesian optimisation and explorative Bayesian quadrature. We show that SOBER outperforms 11 competitive baselines o
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20840;&#38754;&#20998;&#26512;&#20102;&#31070;&#32463;&#31639;&#31526;&#21450;&#20854;&#34893;&#29983;&#32467;&#26500;&#30340;&#27867;&#21270;&#29305;&#24615;&#24182;&#25552;&#20986;&#20102;&#25913;&#36827;&#26041;&#27861;&#65292;&#21253;&#25324;&#24341;&#20837;&#26680;&#31215;&#20998;&#31639;&#31526;&#26469;&#20195;&#26367;&#33258;&#20851;&#27880;&#26426;&#21046;&#21644;&#36880;&#28176;&#22686;&#21152;&#27169;&#22411;&#23481;&#37327;&#30340;&#35757;&#32451;&#35838;&#31243;&#65292;&#32467;&#26524;&#26174;&#33879;&#25552;&#39640;&#20102;&#24615;&#33021;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2301.11509</link><description>&lt;p&gt;
&#32454;&#35843;&#31070;&#32463;&#31639;&#31526;&#32467;&#26500;&#20197;&#25552;&#39640;&#35757;&#32451;&#21644;&#27867;&#21270;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Fine-tuning Neural-Operator architectures for training and generalization. (arXiv:2301.11509v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11509
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20840;&#38754;&#20998;&#26512;&#20102;&#31070;&#32463;&#31639;&#31526;&#21450;&#20854;&#34893;&#29983;&#32467;&#26500;&#30340;&#27867;&#21270;&#29305;&#24615;&#24182;&#25552;&#20986;&#20102;&#25913;&#36827;&#26041;&#27861;&#65292;&#21253;&#25324;&#24341;&#20837;&#26680;&#31215;&#20998;&#31639;&#31526;&#26469;&#20195;&#26367;&#33258;&#20851;&#27880;&#26426;&#21046;&#21644;&#36880;&#28176;&#22686;&#21152;&#27169;&#22411;&#23481;&#37327;&#30340;&#35757;&#32451;&#35838;&#31243;&#65292;&#32467;&#26524;&#26174;&#33879;&#25552;&#39640;&#20102;&#24615;&#33021;&#21644;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#31687;&#35770;&#25991;&#20840;&#38754;&#20998;&#26512;&#20102;&#31070;&#32463;&#31639;&#31526;&#65288;NOs&#65289;&#21450;&#20854;&#34893;&#29983;&#32467;&#26500;&#30340;&#27867;&#21270;&#29305;&#24615;&#12290;&#36890;&#36807;&#23545;&#27979;&#35797;&#25439;&#22833;&#30340;&#32463;&#39564;&#35780;&#20272;&#12289;&#22522;&#20110;&#22797;&#26434;&#24615;&#30340;&#27867;&#21270;&#30028;&#38480;&#30340;&#20998;&#26512;&#20197;&#21450;&#23545;&#25439;&#22833;&#26223;&#35266;&#21487;&#35270;&#21270;&#30340;&#23450;&#24615;&#35780;&#20272;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#26088;&#22312;&#25552;&#39640;NOs&#27867;&#21270;&#33021;&#21147;&#30340;&#20462;&#25913;&#12290;&#21463;Transformer&#30340;&#25104;&#21151;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;${\textit{s}}{\text{NO}}+\varepsilon$&#65292;&#35813;&#26041;&#27861;&#24341;&#20837;&#20102;&#19968;&#20010;&#26680;&#31215;&#20998;&#31639;&#31526;&#26469;&#20195;&#26367;&#33258;&#20851;&#27880;&#26426;&#21046;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26174;&#31034;&#65292;&#20276;&#38543;&#30528;&#25439;&#22833;&#26223;&#35266;&#21487;&#35270;&#21270;&#30340;&#23450;&#24615;&#21464;&#21270;&#65292;&#24615;&#33021;&#26174;&#33879;&#25552;&#39640;&#20102;&#65292;&#36866;&#29992;&#20110;&#21508;&#31181;&#25968;&#25454;&#38598;&#21644;&#21021;&#22987;&#21270;&#12290;&#25105;&#20204;&#29468;&#27979;&#65292;Transformer&#30340;&#24067;&#23616;&#20351;&#20248;&#21270;&#31639;&#27861;&#33021;&#22815;&#25214;&#21040;&#26356;&#22909;&#30340;&#26497;&#23567;&#20540;&#65292;&#24182;&#19988;&#38543;&#26426;&#28145;&#24230;&#21487;&#20197;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#12290;&#30001;&#20110;&#35757;&#32451;&#21160;&#24577;&#30340;&#20005;&#26684;&#20998;&#26512;&#26159;&#28145;&#24230;&#23398;&#20064;&#26368;&#31361;&#20986;&#30340;&#26410;&#35299;&#20915;&#38382;&#39064;&#20043;&#19968;&#65292;&#22240;&#27492;&#25105;&#20204;&#36824;&#25512;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#35757;&#32451;&#35838;&#31243;&#65292;&#37325;&#28857;&#26159;&#36880;&#28176;&#22686;&#21152;&#27169;&#22411;&#23481;&#37327;&#65292;&#20174;&#32780;&#26174;&#33879;&#25552;&#39640;&#20102;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work provides a comprehensive analysis of the generalization properties of Neural Operators (NOs) and their derived architectures. Through empirical evaluation of the test loss, analysis of the complexity-based generalization bounds, and qualitative assessments of the visualization of the loss landscape, we investigate modifications aimed at enhancing the generalization capabilities of NOs. Inspired by the success of Transformers, we propose ${\textit{s}}{\text{NO}}+\varepsilon$, which introduces a kernel integral operator in lieu of self-Attention. Our results reveal significantly improved performance across datasets and initializations, accompanied by qualitative changes in the visualization of the loss landscape. We conjecture that the layout of Transformers enables the optimization algorithm to find better minima, and stochastic depth, improve the generalization performance. As a rigorous analysis of training dynamics is one of the most prominent unsolved problems in deep lear
&lt;/p&gt;</description></item><item><title>&#26696;&#20363;&#22522;&#30784;&#31070;&#32463;&#32593;&#32476;&#65288;CBNNs&#65289;&#26159;&#19968;&#31181;&#26032;&#30340;&#29983;&#23384;&#20998;&#26512;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#21516;&#26102;&#27169;&#25311;&#26102;&#38388;&#21464;&#21270;&#30340;&#20132;&#20114;&#21644;&#22797;&#26434;&#30340;&#22522;&#32447;&#39118;&#38505;&#12290;</title><link>http://arxiv.org/abs/2301.06535</link><description>&lt;p&gt;
&#26696;&#20363;&#22522;&#30784;&#31070;&#32463;&#32593;&#32476;&#65306;&#20855;&#26377;&#26102;&#38388;&#21464;&#21270;&#30340;&#39640;&#38454;&#20132;&#20114;&#30340;&#29983;&#23384;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Case-Base Neural Networks: survival analysis with time-varying, higher-order interactions. (arXiv:2301.06535v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.06535
&lt;/p&gt;
&lt;p&gt;
&#26696;&#20363;&#22522;&#30784;&#31070;&#32463;&#32593;&#32476;&#65288;CBNNs&#65289;&#26159;&#19968;&#31181;&#26032;&#30340;&#29983;&#23384;&#20998;&#26512;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#21516;&#26102;&#27169;&#25311;&#26102;&#38388;&#21464;&#21270;&#30340;&#20132;&#20114;&#21644;&#22797;&#26434;&#30340;&#22522;&#32447;&#39118;&#38505;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#22522;&#20110;&#29983;&#23384;&#20998;&#26512;&#26041;&#27861;&#21487;&#20197;&#27169;&#25311;&#25968;&#25454;&#39537;&#21160;&#30340;&#21327;&#21464;&#37327;&#20132;&#20114;&#12290;&#34429;&#28982;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#27604;&#22238;&#24402;&#26041;&#27861;&#25552;&#20379;&#26356;&#22909;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#20294;&#24182;&#19981;&#26159;&#25152;&#26377;&#30340;&#26041;&#27861;&#37117;&#21487;&#20197;&#27169;&#25311;&#26102;&#38388;&#21464;&#21270;&#30340;&#20132;&#20114;&#21644;&#22797;&#26434;&#30340;&#22522;&#32447;&#39118;&#38505;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#26696;&#20363;&#22522;&#30784;&#31070;&#32463;&#32593;&#32476;&#65288;CBNNs&#65289;&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#23558;&#26696;&#20363;&#22522;&#30784;&#25277;&#26679;&#26694;&#26550;&#19982;&#28789;&#27963;&#30340;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#30456;&#32467;&#21512;&#12290;&#36890;&#36807;&#20351;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#25277;&#26679;&#26041;&#26696;&#21644;&#25968;&#25454;&#22686;&#24378;&#26469;&#33258;&#28982;&#22320;&#32771;&#34385;&#21040;&#25130;&#23614;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#21487;&#20197;&#25509;&#21463;&#26102;&#38388;&#36755;&#20837;&#30340;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#12290;CBNNs&#36890;&#36807;&#39044;&#27979;&#22312;&#32473;&#23450;&#26102;&#21051;&#20107;&#20214;&#21457;&#29983;&#30340;&#27010;&#29575;&#26469;&#20272;&#35745;&#21361;&#38505;&#20989;&#25968;&#12290;&#25105;&#20204;&#36890;&#36807;&#27169;&#25311;&#21644;&#19977;&#20010;&#26696;&#20363;&#30740;&#31350;&#20351;&#29992;&#20004;&#20010;&#26102;&#38388;&#20381;&#36182;&#25351;&#26631;&#27604;&#36739;CBNNs&#19982;&#22238;&#24402;&#21644;&#31070;&#32463;&#32593;&#32476;&#22522;&#20110;&#29983;&#23384;&#20998;&#26512;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#36890;&#36807;&#28041;&#21450;&#22797;&#26434;&#22522;&#32447;&#39118;&#38505;&#21644;&#26102;&#38388;&#21464;&#21270;&#20132;&#20114;&#30340;&#27169;&#25311;&#26469;&#35780;&#20272;&#25152;&#26377;&#26041;&#27861;&#65292;&#20854;&#20013;&#21253;&#25324;CBNNs&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural network-based survival methods can model data-driven covariate interactions. While these methods can provide better predictive performance than regression-based approaches, not all can model time-varying interactions and complex baseline hazards. To address this, we propose Case-Base Neural Networks (CBNNs) as a new approach that combines the case-base sampling framework with flexible neural network architectures. Using a novel sampling scheme and data augmentation to naturally account for censoring, we construct a feed-forward neural network that may take time as an input. CBNNs predict the probability of an event occurring at a given moment to estimate the hazard function. We compare the performance of CBNNs to regression and neural network-based survival methods in a simulation and three case studies using two time-dependent metrics. First, we examine performance on a simulation involving a complex baseline hazard and time-varying interactions to assess all methods, with CBNN
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#36890;&#36807;&#37319;&#29992;&#20915;&#31574;&#29702;&#35770;&#30340;&#26368;&#26032;&#21457;&#23637;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24191;&#20041;&#38543;&#26426;&#20248;&#21183;&#30340;&#20998;&#31867;&#22120;&#27604;&#36739;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#36890;&#36807;&#35299;&#20915;&#26131;&#22788;&#29702;&#30340;&#32447;&#24615;&#35268;&#21010;&#38382;&#39064;&#36827;&#34892;&#25805;&#20316;&#65292;&#24182;&#36890;&#36807;&#36866;&#24212;&#30340;&#20004;&#26679;&#26412;&#35266;&#23519;&#38543;&#26426;&#21270;&#27979;&#35797;&#36827;&#34892;&#32479;&#35745;&#27979;&#35797;&#12290;</title><link>http://arxiv.org/abs/2209.01857</link><description>&lt;p&gt;
&#36890;&#36807;&#24191;&#20041;&#38543;&#26426;&#20248;&#21183;&#32479;&#35745;&#27604;&#36739;&#20998;&#31867;&#22120;
&lt;/p&gt;
&lt;p&gt;
Statistical Comparisons of Classifiers by Generalized Stochastic Dominance. (arXiv:2209.01857v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.01857
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#36890;&#36807;&#37319;&#29992;&#20915;&#31574;&#29702;&#35770;&#30340;&#26368;&#26032;&#21457;&#23637;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24191;&#20041;&#38543;&#26426;&#20248;&#21183;&#30340;&#20998;&#31867;&#22120;&#27604;&#36739;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#36890;&#36807;&#35299;&#20915;&#26131;&#22788;&#29702;&#30340;&#32447;&#24615;&#35268;&#21010;&#38382;&#39064;&#36827;&#34892;&#25805;&#20316;&#65292;&#24182;&#36890;&#36807;&#36866;&#24212;&#30340;&#20004;&#26679;&#26412;&#35266;&#23519;&#38543;&#26426;&#21270;&#27979;&#35797;&#36827;&#34892;&#32479;&#35745;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#25104;&#20026;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#21457;&#23637;&#30340;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#65292;&#20294;&#22914;&#20309;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#19978;&#26681;&#25454;&#22810;&#20010;&#26631;&#20934;&#27604;&#36739;&#20998;&#31867;&#22120;&#20173;&#28982;&#27809;&#26377;&#20849;&#35782;&#12290;&#27599;&#20010;&#27604;&#36739;&#26694;&#26550;&#37117;&#38754;&#20020;&#33267;&#23569;&#19977;&#20010;&#22522;&#26412;&#25361;&#25112;&#65306;&#36136;&#37327;&#26631;&#20934;&#30340;&#22810;&#26679;&#24615;&#65292;&#25968;&#25454;&#38598;&#30340;&#22810;&#26679;&#24615;&#20197;&#21450;&#25968;&#25454;&#38598;&#30340;&#38543;&#26426;&#36873;&#25321;&#12290;&#26412;&#25991;&#36890;&#36807;&#37319;&#29992;&#26368;&#36817;&#22312;&#20915;&#31574;&#29702;&#35770;&#20013;&#30340;&#21457;&#23637;&#65292;&#20026;&#36825;&#22330;&#28608;&#28872;&#30340;&#36777;&#35770;&#22686;&#28155;&#20102;&#26032;&#30340;&#35270;&#35282;&#12290;&#22522;&#20110;&#25152;&#35859;&#30340;&#20559;&#22909;&#31995;&#32479;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#36890;&#36807;&#24191;&#20041;&#38543;&#26426;&#20248;&#21183;&#30340;&#27010;&#24565;&#23545;&#20998;&#31867;&#22120;&#36827;&#34892;&#25490;&#21517;&#65292;&#24378;&#22823;&#22320;&#32469;&#36807;&#20102;&#32321;&#29712;&#19988;&#24448;&#24448;&#33258;&#30456;&#30683;&#30462;&#30340;&#32858;&#21512;&#20381;&#36182;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#24191;&#20041;&#38543;&#26426;&#20248;&#21183;&#21487;&#20197;&#36890;&#36807;&#35299;&#20915;&#26131;&#22788;&#29702;&#30340;&#32447;&#24615;&#35268;&#21010;&#38382;&#39064;&#36827;&#34892;&#25805;&#20316;&#65292;&#24182;&#36890;&#36807;&#36866;&#24212;&#30340;&#20004;&#26679;&#26412;&#35266;&#23519;&#38543;&#26426;&#21270;&#27979;&#35797;&#36827;&#34892;&#32479;&#35745;&#27979;&#35797;&#12290;&#36825;&#30830;&#23454;&#20026;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#24378;&#22823;&#30340;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
Although being a crucial question for the development of machine learning algorithms, there is still no consensus on how to compare classifiers over multiple data sets with respect to several criteria. Every comparison framework is confronted with (at least) three fundamental challenges: the multiplicity of quality criteria, the multiplicity of data sets and the randomness of the selection of data sets. In this paper, we add a fresh view to the vivid debate by adopting recent developments in decision theory. Based on so-called preference systems, our framework ranks classifiers by a generalized concept of stochastic dominance, which powerfully circumvents the cumbersome, and often even self-contradictory, reliance on aggregates. Moreover, we show that generalized stochastic dominance can be operationalized by solving easy-to-handle linear programs and moreover statistically tested employing an adapted two-sample observation-randomization test. This yields indeed a powerful framework fo
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#21160;&#24577;&#25490;&#21517;&#21644;&#32763;&#35793;&#21516;&#27493;&#38382;&#39064;&#65292;&#20027;&#35201;&#20851;&#27880;&#25104;&#23545;&#27604;&#36739;&#25968;&#25454;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#24773;&#20917;&#65292;&#24182;&#32473;&#20986;&#20102;&#30456;&#24212;&#30340;&#29702;&#35770;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2207.01455</link><description>&lt;p&gt;
&#21160;&#24577;&#25490;&#21517;&#21644;&#32763;&#35793;&#21516;&#27493;
&lt;/p&gt;
&lt;p&gt;
Dynamic Ranking and Translation Synchronization. (arXiv:2207.01455v3 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.01455
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#21160;&#24577;&#25490;&#21517;&#21644;&#32763;&#35793;&#21516;&#27493;&#38382;&#39064;&#65292;&#20027;&#35201;&#20851;&#27880;&#25104;&#23545;&#27604;&#36739;&#25968;&#25454;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#24773;&#20917;&#65292;&#24182;&#32473;&#20986;&#20102;&#30456;&#24212;&#30340;&#29702;&#35770;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#65292;&#22914;&#20307;&#32946;&#27604;&#36187;&#25110;&#25512;&#33616;&#31995;&#32479;&#65292;&#25105;&#20204;&#21487;&#20197;&#33719;&#24471;&#30001;&#19968;&#32452;$n$&#20010;&#39033;&#30446;&#65288;&#25110;&#36873;&#25163;&#65289;&#20043;&#38388;&#30340;&#25104;&#23545;&#27604;&#36739;&#32452;&#25104;&#30340;&#25968;&#25454;&#12290;&#30446;&#26631;&#26159;&#21033;&#29992;&#36825;&#20123;&#25968;&#25454;&#25512;&#26029;&#27599;&#20010;&#39033;&#30446;&#21644;/&#25110;&#23427;&#20204;&#30340;&#25490;&#21517;&#30340;&#28508;&#22312;&#23454;&#21147;&#12290;&#29616;&#26377;&#32467;&#26524;&#20027;&#35201;&#20851;&#27880;&#21333;&#20010;&#27604;&#36739;&#22270;$G$&#30340;&#35774;&#32622;&#12290;&#28982;&#32780;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65288;&#22914;&#20307;&#32946;&#27604;&#36187;&#65289;&#65292;&#25104;&#23545;&#27604;&#36739;&#25968;&#25454;&#20250;&#38543;&#26102;&#38388;&#21464;&#21270;&#12290;&#23545;&#20110;&#36825;&#31181;&#21160;&#24577;&#35774;&#32622;&#65292;&#29702;&#35770;&#32467;&#26524;&#30456;&#23545;&#26377;&#38480;&#65292;&#26159;&#26412;&#25991;&#30340;&#37325;&#28857;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#32763;&#35793;&#21516;&#27493;&#38382;&#39064;&#22312;&#21160;&#24577;&#35774;&#32622;&#19979;&#30340;&#25193;&#23637;&#12290;&#22312;&#36825;&#20010;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#32473;&#23450;&#20102;&#19968;&#20010;&#27604;&#36739;&#22270;&#24207;&#21015;$(G_t)_{t\in \mathcal{T}}$&#65292;&#20854;&#20013;$\mathcal{T} \subset [0,1]$&#26159;&#34920;&#31034;&#26102;&#38388;&#22495;&#30340;&#26684;&#28857;&#65292;&#23545;&#20110;&#27599;&#20010;&#39033;&#30446;$i$&#21644;&#26102;&#38388;$t\in \mathcal{T}$&#65292;&#23384;&#22312;&#19968;&#20010;&#20851;&#32852;&#30340;&#26410;&#30693;&#23454;&#21147;&#21442;&#25968;$z^*_{t,i}\in \mathbb{R}$&#12290;
&lt;/p&gt;
&lt;p&gt;
In many applications, such as sport tournaments or recommendation systems, we have at our disposal data consisting of pairwise comparisons between a set of $n$ items (or players). The objective is to use this data to infer the latent strength of each item and/or their ranking. Existing results for this problem predominantly focus on the setting consisting of a single comparison graph $G$. However, there exist scenarios (e.g., sports tournaments) where the the pairwise comparison data evolves with time. Theoretical results for this dynamic setting are relatively limited and is the focus of this paper.  We study an extension of the \emph{translation synchronization} problem, to the dynamic setting. In this setup, we are given a sequence of comparison graphs $(G_t)_{t\in \mathcal{T}}$, where $\mathcal{T} \subset [0,1]$ is a grid representing the time domain, and for each item $i$ and time $t\in \mathcal{T}$ there is an associated unknown strength parameter $z^*_{t,i}\in \mathbb{R}$. We ai
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#30740;&#31350;&#20102;&#23398;&#20064;&#38750;&#21442;&#25968;&#28151;&#21512;&#27169;&#22411;&#20013;&#32452;&#20214;&#20998;&#24067;&#30340;&#38590;&#24230;&#65292;&#24182;&#24314;&#31435;&#20102;&#23398;&#20064;&#27599;&#20010;&#32452;&#20214;&#20998;&#24067;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#30340;&#20005;&#26684;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;&#38656;&#35201;$(\frac{1}{\varepsilon})^{\Omega(\log\log \frac{1}{\varepsilon})}$&#20010;&#26679;&#26412;&#26469;&#20272;&#35745;&#27599;&#20010;&#32452;&#20214;&#20998;&#24067;&#12290;</title><link>http://arxiv.org/abs/2203.15150</link><description>&lt;p&gt;
&#23398;&#20064;&#31616;&#21333;&#38750;&#21442;&#25968;&#28151;&#21512;&#27169;&#22411;&#30340;&#38590;&#24230;&#30340;&#20005;&#26684;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Tight Bounds on the Hardness of Learning Simple Nonparametric Mixtures. (arXiv:2203.15150v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.15150
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#23398;&#20064;&#38750;&#21442;&#25968;&#28151;&#21512;&#27169;&#22411;&#20013;&#32452;&#20214;&#20998;&#24067;&#30340;&#38590;&#24230;&#65292;&#24182;&#24314;&#31435;&#20102;&#23398;&#20064;&#27599;&#20010;&#32452;&#20214;&#20998;&#24067;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#30340;&#20005;&#26684;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;&#38656;&#35201;$(\frac{1}{\varepsilon})^{\Omega(\log\log \frac{1}{\varepsilon})}$&#20010;&#26679;&#26412;&#26469;&#20272;&#35745;&#27599;&#20010;&#32452;&#20214;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#26377;&#38480;&#28151;&#21512;&#27169;&#22411;&#20013;&#23398;&#20064;&#38750;&#21442;&#25968;&#20998;&#24067;&#30340;&#38382;&#39064;&#65292;&#24182;&#23545;&#23398;&#20064;&#36825;&#20123;&#27169;&#22411;&#20013;&#30340;&#32452;&#20214;&#20998;&#24067;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#24314;&#31435;&#20102;&#20005;&#26684;&#30028;&#38480;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#32473;&#23450;&#20102;&#26469;&#33258;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;$f$&#30340;i.i.d.&#26679;&#26412;&#65292;&#20854;&#20013;$$ f=w_1f_1+w_2f_2&#65292;\quad w_1+w_2=1&#65292;\quad w_1,w_2&gt;0 $$&#25105;&#20204;&#24863;&#20852;&#36259;&#30340;&#26159;&#23398;&#20064;&#27599;&#20010;&#32452;&#20214;$f_i$&#12290;&#22312;&#23545;$f_i$&#27809;&#26377;&#20219;&#20309;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#20010;&#38382;&#39064;&#26159;&#26080;&#27861;&#35299;&#20915;&#30340;&#12290;&#20026;&#20102;&#35782;&#21035;&#32452;&#20214;$f_i$&#65292;&#25105;&#20204;&#20551;&#35774;&#27599;&#20010;$f_i$&#21487;&#20197;&#20889;&#25104;&#19968;&#20010;&#39640;&#26031;&#20989;&#25968;&#21644;&#19968;&#20010;&#32039;&#25903;&#25745;&#23494;&#24230;$\nu_i$&#30340;&#21367;&#31215;&#24418;&#24335;&#65292;&#20854;&#20013;$\text{supp}(\nu_1)\cap \text{supp}(\nu_2)=\emptyset$&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#34920;&#26126;&#65292;&#20026;&#20102;&#20272;&#35745;&#27599;&#20010;$f_i$&#65292;&#38656;&#35201;$(\frac{1}{\varepsilon})^{\Omega(\log\log \frac{1}{\varepsilon})}$&#20010;&#26679;&#26412;&#12290;&#35777;&#26126;&#20381;&#36182;&#20110;&#19968;&#20010;&#37327;&#21270;&#30340;&#22612;&#20271;&#21033;&#23433;&#23450;&#29702;&#65292;&#35813;&#23450;&#29702;&#25552;&#20379;&#20102;&#19982;&#39640;&#26031;&#20989;&#25968;&#30340;&#24555;&#36895;&#36924;&#36817;&#36895;&#24230;&#65292;&#36825;&#21487;&#33021;&#26159;&#29420;&#31435;&#24863;&#20852;&#36259;&#30340;&#12290;&#20026;&#20102;&#35777;&#26126;&#36825;&#26159;&#32039;&#30830;&#30340;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;$(\frac{1
&lt;/p&gt;
&lt;p&gt;
We study the problem of learning nonparametric distributions in a finite mixture, and establish tight bounds on the sample complexity for learning the component distributions in such models. Namely, we are given i.i.d. samples from a pdf $f$ where $$ f=w_1f_1+w_2f_2, \quad w_1+w_2=1, \quad w_1,w_2&gt;0 $$ and we are interested in learning each component $f_i$. Without any assumptions on $f_i$, this problem is ill-posed. In order to identify the components $f_i$, we assume that each $f_i$ can be written as a convolution of a Gaussian and a compactly supported density $\nu_i$ with $\text{supp}(\nu_1)\cap \text{supp}(\nu_2)=\emptyset$.  Our main result shows that $(\frac{1}{\varepsilon})^{\Omega(\log\log \frac{1}{\varepsilon})}$ samples are required for estimating each $f_i$. The proof relies on a quantitative Tauberian theorem that yields a fast rate of approximation with Gaussians, which may be of independent interest. To show this is tight, we also propose an algorithm that uses $(\frac{1
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#29992;&#20110;&#22312;&#36172;&#21338;&#26426;&#20013;&#36827;&#34892;&#31616;&#21333;&#36951;&#25022;&#26368;&#23567;&#21270;&#30340;&#20803;&#23398;&#20064;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#39318;&#20010;&#36125;&#21494;&#26031;&#21644;&#39057;&#29575;&#27966;&#20803;&#23398;&#20064;&#31639;&#27861;&#12290;&#36125;&#21494;&#26031;&#31639;&#27861;&#20855;&#26377;&#20808;&#39564;&#20998;&#24067;&#24182;&#19988;&#20855;&#26377;&#36739;&#23567;&#30340;&#20803;&#31616;&#21333;&#36951;&#25022;&#65292;&#32780;&#39057;&#29575;&#27966;&#31639;&#27861;&#26356;&#36890;&#29992;&#19988;&#21487;&#20197;&#22312;&#26356;&#22810;&#30340;&#35774;&#32622;&#20013;&#36827;&#34892;&#20998;&#26512;&#12290;&#36890;&#36807;&#23558;&#31639;&#27861;&#24212;&#29992;&#20110;&#19981;&#21516;&#30340;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#29702;&#35770;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2202.12888</link><description>&lt;p&gt;
&#29992;&#20110;&#31616;&#21333;&#36951;&#25022;&#26368;&#23567;&#21270;&#30340;&#20803;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Meta-Learning for Simple Regret Minimization. (arXiv:2202.12888v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.12888
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#29992;&#20110;&#22312;&#36172;&#21338;&#26426;&#20013;&#36827;&#34892;&#31616;&#21333;&#36951;&#25022;&#26368;&#23567;&#21270;&#30340;&#20803;&#23398;&#20064;&#26694;&#26550;&#65292;&#24182;&#25552;&#20986;&#20102;&#39318;&#20010;&#36125;&#21494;&#26031;&#21644;&#39057;&#29575;&#27966;&#20803;&#23398;&#20064;&#31639;&#27861;&#12290;&#36125;&#21494;&#26031;&#31639;&#27861;&#20855;&#26377;&#20808;&#39564;&#20998;&#24067;&#24182;&#19988;&#20855;&#26377;&#36739;&#23567;&#30340;&#20803;&#31616;&#21333;&#36951;&#25022;&#65292;&#32780;&#39057;&#29575;&#27966;&#31639;&#27861;&#26356;&#36890;&#29992;&#19988;&#21487;&#20197;&#22312;&#26356;&#22810;&#30340;&#35774;&#32622;&#20013;&#36827;&#34892;&#20998;&#26512;&#12290;&#36890;&#36807;&#23558;&#31639;&#27861;&#24212;&#29992;&#20110;&#19981;&#21516;&#30340;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#29702;&#35770;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#22312;&#36172;&#21338;&#26426;&#20013;&#31616;&#21333;&#36951;&#25022;&#26368;&#23567;&#21270;&#30340;&#20803;&#23398;&#20064;&#26694;&#26550;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#20013;&#65292;&#23398;&#20064;&#20195;&#29702;&#19982;&#19968;&#31995;&#21015;&#36172;&#21338;&#26426;&#20219;&#21153;&#36827;&#34892;&#20132;&#20114;&#65292;&#36825;&#20123;&#20219;&#21153;&#26159;&#20174;&#19968;&#20010;&#26410;&#30693;&#30340;&#20808;&#39564;&#20998;&#24067;&#20013;&#29420;&#31435;&#37319;&#26679;&#30340;&#65292;&#24182;&#23398;&#20064;&#20854;&#20803;&#21442;&#25968;&#20197;&#22312;&#26410;&#26469;&#20219;&#21153;&#20013;&#34920;&#29616;&#26356;&#22909;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#36825;&#20010;&#35774;&#32622;&#30340;&#31532;&#19968;&#20010;&#36125;&#21494;&#26031;&#21644;&#39057;&#29575;&#27966;&#20803;&#23398;&#20064;&#31639;&#27861;&#12290;&#36125;&#21494;&#26031;&#31639;&#27861;&#21487;&#20197;&#35775;&#38382;&#20803;&#21442;&#25968;&#30340;&#20808;&#39564;&#20998;&#24067;&#65292;&#24182;&#19988;&#20854;&#22312;$m$&#20010;&#36172;&#21338;&#26426;&#20219;&#21153;&#20013;&#65292;&#26102;&#38388;&#30028;&#20026;$n$&#30340;&#20803;&#31616;&#21333;&#36951;&#25022;&#20165;&#20026;$\tilde{O}(m / \sqrt{n})$&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#39057;&#29575;&#27966;&#31639;&#27861;&#30340;&#20803;&#31616;&#21333;&#36951;&#25022;&#20026;$\tilde{O}(\sqrt{m} n + m/ \sqrt{n})$&#12290;&#23613;&#31649;&#36951;&#25022;&#26356;&#22823;&#65292;&#20294;&#39057;&#29575;&#27966;&#31639;&#27861;&#26356;&#36890;&#29992;&#65292;&#22240;&#20026;&#23427;&#19981;&#38656;&#35201;&#20803;&#21442;&#25968;&#30340;&#20808;&#39564;&#20998;&#24067;&#65292;&#24182;&#19988;&#21487;&#20197;&#22312;&#26356;&#22810;&#30340;&#35774;&#32622;&#20013;&#36827;&#34892;&#20998;&#26512;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#31639;&#27861;&#24212;&#29992;&#20110;&#20960;&#31867;&#36172;&#21338;&#26426;&#38382;&#39064;&#26469;&#39564;&#35777;&#25105;&#20204;&#30340;&#29702;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a meta-learning framework for simple regret minimization in bandits. In this framework, a learning agent interacts with a sequence of bandit tasks, which are sampled i.i.d.\ from an unknown prior distribution, and learns its meta-parameters to perform better on future tasks. We propose the first Bayesian and frequentist meta-learning algorithms for this setting. The Bayesian algorithm has access to a prior distribution over the meta-parameters and its meta simple regret over $m$ bandit tasks with horizon $n$ is mere $\tilde{O}(m / \sqrt{n})$. On the other hand, the meta simple regret of the frequentist algorithm is $\tilde{O}(\sqrt{m} n + m/ \sqrt{n})$. While its regret is worse, the frequentist algorithm is more general because it does not need a prior distribution over the meta-parameters. It can also be analyzed in more settings. We instantiate our algorithms for several classes of bandit problems. Our algorithms are general and we complement our theory by evaluating them
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#26679;&#26412;&#30697;&#26041;&#27861;&#36827;&#34892;&#38750;&#20256;&#32479;&#21442;&#25968;&#21270;&#23494;&#24230;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24179;&#26041;Hellinger&#36317;&#31163;&#36827;&#34892;&#21442;&#25968;&#21270;&#65292;&#24182;&#36890;&#36807;&#20984;&#20248;&#21270;&#24471;&#21040;&#21807;&#19968;&#35299;&#12290;&#36890;&#36807;&#24130;&#30697;&#20272;&#35745;&#25552;&#20986;&#20102;&#20272;&#35745;&#22120;&#30340;&#32479;&#35745;&#24615;&#36136;&#21644;&#28176;&#36817;&#35823;&#24046;&#19978;&#30028;&#65292;&#27169;&#25311;&#32467;&#26524;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2201.04786</link><description>&lt;p&gt;
&#19968;&#31181;&#20351;&#29992;&#26679;&#26412;&#30697;&#26041;&#27861;&#30340;&#38750;&#20256;&#32479;&#21442;&#25968;&#21270;&#23494;&#24230;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
A Non-Classical Parameterization for Density Estimation Using Sample Moments. (arXiv:2201.04786v5 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.04786
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#26679;&#26412;&#30697;&#26041;&#27861;&#36827;&#34892;&#38750;&#20256;&#32479;&#21442;&#25968;&#21270;&#23494;&#24230;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24179;&#26041;Hellinger&#36317;&#31163;&#36827;&#34892;&#21442;&#25968;&#21270;&#65292;&#24182;&#36890;&#36807;&#20984;&#20248;&#21270;&#24471;&#21040;&#21807;&#19968;&#35299;&#12290;&#36890;&#36807;&#24130;&#30697;&#20272;&#35745;&#25552;&#20986;&#20102;&#20272;&#35745;&#22120;&#30340;&#32479;&#35745;&#24615;&#36136;&#21644;&#28176;&#36817;&#35823;&#24046;&#19978;&#30028;&#65292;&#27169;&#25311;&#32467;&#26524;&#39564;&#35777;&#20102;&#35813;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27010;&#29575;&#23494;&#24230;&#20272;&#35745;&#26159;&#32479;&#35745;&#23398;&#21644;&#20449;&#21495;&#22788;&#29702;&#30340;&#26680;&#24515;&#38382;&#39064;&#12290;&#30697;&#26041;&#27861;&#26159;&#23494;&#24230;&#20272;&#35745;&#30340;&#37325;&#35201;&#26041;&#27861;&#65292;&#20294;&#36890;&#24120;&#24378;&#28872;&#20381;&#36182;&#20110;&#21487;&#34892;&#20989;&#25968;&#30340;&#36873;&#25321;&#65292;&#36825;&#20005;&#37325;&#24433;&#21709;&#20102;&#24615;&#33021;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#26679;&#26412;&#30697;&#26041;&#27861;&#36827;&#34892;&#23494;&#24230;&#20272;&#35745;&#30340;&#38750;&#20256;&#32479;&#21442;&#25968;&#21270;&#26041;&#27861;&#65292;&#19981;&#38656;&#35201;&#36873;&#25321;&#36825;&#26679;&#30340;&#20989;&#25968;&#12290;&#35813;&#21442;&#25968;&#21270;&#26159;&#30001;&#24179;&#26041;Hellinger&#36317;&#31163;&#24341;&#36215;&#30340;&#65292;&#24182;&#19988;&#23427;&#30340;&#35299;&#34987;&#35777;&#26126;&#22312;&#19981;&#20381;&#36182;&#20110;&#25968;&#25454;&#30340;&#31616;&#21333;&#20808;&#39564;&#26465;&#20214;&#19979;&#23384;&#22312;&#24182;&#19988;&#26159;&#21807;&#19968;&#30340;&#65292;&#24182;&#19988;&#21487;&#20197;&#36890;&#36807;&#20984;&#20248;&#21270;&#24471;&#21040;&#12290;&#36890;&#36807;&#24130;&#30697;&#20272;&#35745;&#25552;&#20986;&#20102;&#23494;&#24230;&#20272;&#35745;&#22120;&#30340;&#32479;&#35745;&#24615;&#36136;&#65292;&#20197;&#21450;&#20272;&#35745;&#22120;&#30340;&#28176;&#36817;&#35823;&#24046;&#19978;&#30028;&#12290;&#32473;&#20986;&#20102;&#25152;&#25552;&#20986;&#30340;&#23494;&#24230;&#20272;&#35745;&#22120;&#22312;&#20449;&#21495;&#22788;&#29702;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#12290;&#36890;&#36807;&#19982;&#20960;&#31181;&#27969;&#34892;&#26041;&#27861;&#30340;&#27604;&#36739;&#65292;&#27169;&#25311;&#32467;&#26524;&#39564;&#35777;&#20102;&#20272;&#35745;&#22120;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Probability density estimation is a core problem of statistics and signal processing. Moment methods are an important means of density estimation, but they are generally strongly dependent on the choice of feasible functions, which severely affects the performance. In this paper, we propose a non-classical parametrization for density estimation using sample moments, which does not require the choice of such functions. The parametrization is induced by the squared Hellinger distance, and the solution of it, which is proved to exist and be unique subject to a simple prior that does not depend on data, and can be obtained by convex optimization. Statistical properties of the density estimator, together with an asymptotic error upper bound are proposed for the estimator by power moments. Applications of the proposed density estimator in signal processing tasks are given. Simulation results validate the performance of the estimator by a comparison to several prevailing methods. To the best 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35777;&#26126;&#20102;&#22312;&#29305;&#23450;&#36873;&#25321;&#30340;&#920;&#21644;&#957;&#19979;&#65292;&#33539;&#25968;&#27979;&#35797;&#21644;&#20869;&#31215;/&#27491;&#20132;&#24615;&#27979;&#35797;&#22312;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#26041;&#38754;&#26159;&#31561;&#20215;&#30340;&#65292;&#21516;&#26102;&#25351;&#20986;&#22312;&#26368;&#29702;&#24819;&#24773;&#20917;&#19979;&#65292;&#20869;&#31215;/&#27491;&#20132;&#24615;&#27979;&#35797;&#21487;&#20197;&#20687;&#33539;&#25968;&#27979;&#35797;&#19968;&#26679;&#24265;&#20215;&#12290;</title><link>http://arxiv.org/abs/2109.10933</link><description>&lt;p&gt;
&#20851;&#20110;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#30340;&#19981;&#21516;&#33258;&#36866;&#24212;&#25209;&#37327;&#22823;&#23567;&#36873;&#25321;&#31574;&#30053;&#30340;&#31561;&#20215;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the equivalence of different adaptive batch size selection strategies for stochastic gradient descent methods. (arXiv:2109.10933v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.10933
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35777;&#26126;&#20102;&#22312;&#29305;&#23450;&#36873;&#25321;&#30340;&#920;&#21644;&#957;&#19979;&#65292;&#33539;&#25968;&#27979;&#35797;&#21644;&#20869;&#31215;/&#27491;&#20132;&#24615;&#27979;&#35797;&#22312;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#26041;&#38754;&#26159;&#31561;&#20215;&#30340;&#65292;&#21516;&#26102;&#25351;&#20986;&#22312;&#26368;&#29702;&#24819;&#24773;&#20917;&#19979;&#65292;&#20869;&#31215;/&#27491;&#20132;&#24615;&#27979;&#35797;&#21487;&#20197;&#20687;&#33539;&#25968;&#27979;&#35797;&#19968;&#26679;&#24265;&#20215;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35777;&#26126;&#20102;&#22312;&#29305;&#23450;&#36873;&#25321;&#30340;&#920;&#21644;&#957;&#19979;&#65292;\cite{Bol18}&#20013;&#25552;&#20986;&#30340;&#33539;&#25968;&#27979;&#35797;&#21644;&#20869;&#31215;/&#27491;&#20132;&#24615;&#27979;&#35797;&#22312;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#26041;&#38754;&#26159;&#31561;&#20215;&#30340;&#65292;&#20854;&#20013;&#1013;&#178;=&#952;&#178;+&#957;&#178;&#12290;&#36825;&#37324;&#65292;&#1013;&#25511;&#21046;&#26799;&#24230;&#33539;&#25968;&#30340;&#30456;&#23545;&#32479;&#35745;&#35823;&#24046;&#65292;&#32780;&#952;&#21644;&#957;&#20998;&#21035;&#25511;&#21046;&#26799;&#24230;&#22312;&#26799;&#24230;&#26041;&#21521;&#21644;&#26799;&#24230;&#27491;&#20132;&#26041;&#21521;&#19978;&#30340;&#30456;&#23545;&#32479;&#35745;&#35823;&#24046;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#26368;&#29702;&#24819;&#24773;&#20917;&#19979;&#65292;&#20869;&#31215;/&#27491;&#20132;&#24615;&#27979;&#35797;&#21487;&#20197;&#20687;&#33539;&#25968;&#27979;&#35797;&#19968;&#26679;&#24265;&#20215;&#65292;&#22914;&#26524;&#952;&#21644;&#957;&#34987;&#26368;&#20248;&#36873;&#25321;&#65292;&#20294;&#26159;&#22914;&#26524;&#1013;&#178;=&#952;&#178;+&#957;&#178;&#65292;&#20869;&#31215;/&#27491;&#20132;&#24615;&#27979;&#35797;&#27704;&#36828;&#19981;&#20250;&#27604;&#33539;&#25968;&#27979;&#35797;&#26356;&#20855;&#35745;&#31639;&#21487;&#25215;&#21463;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20004;&#20010;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#26469;&#35828;&#26126;&#25105;&#20204;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this study, we demonstrate that the norm test and inner product/orthogonality test presented in \cite{Bol18} are equivalent in terms of the convergence rates associated with Stochastic Gradient Descent (SGD) methods if $\epsilon^2=\theta^2+\nu^2$ with specific choices of $\theta$ and $\nu$. Here, $\epsilon$ controls the relative statistical error of the norm of the gradient while $\theta$ and $\nu$ control the relative statistical error of the gradient in the direction of the gradient and in the direction orthogonal to the gradient, respectively. Furthermore, we demonstrate that the inner product/orthogonality test can be as inexpensive as the norm test in the best case scenario if $\theta$ and $\nu$ are optimally selected, but the inner product/orthogonality test will never be more computationally affordable than the norm test if $\epsilon^2=\theta^2+\nu^2$. Finally, we present two stochastic optimization problems to illustrate our results.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#24179;&#28369;&#27969;&#24418;&#19978;&#35299;&#20915;&#20248;&#21270;&#38382;&#39064;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#21033;&#29992;&#27969;&#24418;&#19978;&#30340;&#36763;&#31639;&#27861;&#36827;&#34892;&#21152;&#36895;&#65292;&#21487;&#20197;&#22788;&#29702;&#20855;&#26377;&#38750;&#32447;&#24615;&#32422;&#26463;&#30340;&#38382;&#39064;&#65292;&#24182;&#20855;&#26377;&#33391;&#22909;&#30340;&#25910;&#25947;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2107.11231</link><description>&lt;p&gt;
&#27969;&#24418;&#19978;&#30340;&#20248;&#21270;&#65306;&#19968;&#31181;&#36763;&#31639;&#27861;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Optimization on manifolds: A symplectic approach. (arXiv:2107.11231v2 [cond-mat.stat-mech] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2107.11231
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#24179;&#28369;&#27969;&#24418;&#19978;&#35299;&#20915;&#20248;&#21270;&#38382;&#39064;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#21033;&#29992;&#27969;&#24418;&#19978;&#30340;&#36763;&#31639;&#27861;&#36827;&#34892;&#21152;&#36895;&#65292;&#21487;&#20197;&#22788;&#29702;&#20855;&#26377;&#38750;&#32447;&#24615;&#32422;&#26463;&#30340;&#38382;&#39064;&#65292;&#24182;&#20855;&#26377;&#33391;&#22909;&#30340;&#25910;&#25947;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32479;&#35745;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#20248;&#21270;&#20219;&#21153;&#33267;&#20851;&#37325;&#35201;&#12290;&#36817;&#24180;&#26469;&#65292;&#20154;&#20204;&#24191;&#27867;&#21033;&#29992;&#21160;&#21147;&#31995;&#32479;&#30340;&#24037;&#20855;&#65292;&#36890;&#36807;&#36830;&#32493;&#26102;&#38388;&#31995;&#32479;&#30340;&#36866;&#24403;&#31163;&#25955;&#21270;&#65292;&#23548;&#20986;&#21152;&#36895;&#21644;&#40065;&#26834;&#24615;&#20248;&#21270;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#24605;&#24819;&#22823;&#22810;&#23616;&#38480;&#20110;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#21644;&#26080;&#32422;&#26463;&#30340;&#35774;&#32622;&#65292;&#25110;&#32773;Riemannian&#26799;&#24230;&#27969;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#32791;&#25955;&#22411;&#30340;Dirac&#32422;&#26463;&#21704;&#23494;&#39039;&#31995;&#32479;&#25193;&#23637;&#65292;&#20316;&#20026;&#35299;&#20915;&#24179;&#28369;&#27969;&#24418;&#19978;&#30340;&#20248;&#21270;&#38382;&#39064;&#30340;&#36890;&#29992;&#26694;&#26550;&#65292;&#21253;&#25324;&#20855;&#26377;&#38750;&#32447;&#24615;&#32422;&#26463;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#22312;&#27969;&#24418;&#19978;&#24320;&#21457;&#20102;&#20960;&#20309;/&#36763;&#25968;&#20540;&#31215;&#20998;&#22120;&#65292;&#23427;&#20204;&#26159;"&#36895;&#29575;&#21305;&#37197;"&#30340;&#65292;&#21363;&#20445;&#25345;&#36830;&#32493;&#26102;&#38388;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#32791;&#25955;&#22411;&#30340;RATTLE&#31215;&#20998;&#22120;&#65292;&#33021;&#22815;&#22312;&#23616;&#37096;&#23454;&#29616;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#12290;&#25105;&#20204;&#30340;&#31867;&#21035;&#65288;&#21152;&#36895;&#30340;&#65289;&#31639;&#27861;&#19981;&#20165;&#31616;&#21333;&#39640;&#25928;&#65292;&#32780;&#19988;&#36866;&#29992;&#20110;&#24191;&#27867;&#30340;&#29615;&#22659;&#12290;
&lt;/p&gt;
&lt;p&gt;
Optimization tasks are crucial in statistical machine learning. Recently, there has been great interest in leveraging tools from dynamical systems to derive accelerated and robust optimization methods via suitable discretizations of continuous-time systems. However, these ideas have mostly been limited to Euclidean spaces and unconstrained settings, or to Riemannian gradient flows. In this work, we propose a dissipative extension of Dirac's theory of constrained Hamiltonian systems as a general framework for solving optimization problems over smooth manifolds, including problems with nonlinear constraints. We develop geometric/symplectic numerical integrators on manifolds that are "rate-matching," i.e., preserve the continuous-time rates of convergence. In particular, we introduce a dissipative RATTLE integrator able to achieve optimal convergence rate locally. Our class of (accelerated) algorithms are not only simple and efficient but also applicable to a broad range of contexts.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#32508;&#36848;&#35843;&#26597;&#20102;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#39046;&#22495;&#20013;&#30340;&#36801;&#31227;&#23398;&#20064;&#26041;&#27861;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#23545;&#36825;&#20123;&#26041;&#27861;&#36827;&#34892;&#20998;&#31867;&#30340;&#26694;&#26550;&#12290;&#20998;&#26512;&#20102;&#23427;&#20204;&#30340;&#30446;&#26631;&#12289;&#26041;&#27861;&#23398;&#12289;&#20860;&#23481;&#30340;&#24378;&#21270;&#23398;&#20064;&#32972;&#26223;&#20197;&#21450;&#23454;&#38469;&#24212;&#29992;&#65292;&#24182;&#25506;&#35752;&#20102;&#36801;&#31227;&#23398;&#20064;&#19982;&#20854;&#20182;&#30456;&#20851;&#20027;&#39064;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;</title><link>http://arxiv.org/abs/2009.07888</link><description>&lt;p&gt;
&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#36801;&#31227;&#23398;&#20064;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Transfer Learning in Deep Reinforcement Learning: A Survey. (arXiv:2009.07888v6 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2009.07888
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#32508;&#36848;&#35843;&#26597;&#20102;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#39046;&#22495;&#20013;&#30340;&#36801;&#31227;&#23398;&#20064;&#26041;&#27861;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#23545;&#36825;&#20123;&#26041;&#27861;&#36827;&#34892;&#20998;&#31867;&#30340;&#26694;&#26550;&#12290;&#20998;&#26512;&#20102;&#23427;&#20204;&#30340;&#30446;&#26631;&#12289;&#26041;&#27861;&#23398;&#12289;&#20860;&#23481;&#30340;&#24378;&#21270;&#23398;&#20064;&#32972;&#26223;&#20197;&#21450;&#23454;&#38469;&#24212;&#29992;&#65292;&#24182;&#25506;&#35752;&#20102;&#36801;&#31227;&#23398;&#20064;&#19982;&#20854;&#20182;&#30456;&#20851;&#20027;&#39064;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#26159;&#35299;&#20915;&#24207;&#21015;&#20915;&#31574;&#38382;&#39064;&#30340;&#23398;&#20064;&#33539;&#24335;&#12290;&#36817;&#24180;&#26469;&#65292;&#38543;&#30528;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#24555;&#36895;&#21457;&#23637;&#65292;&#24378;&#21270;&#23398;&#20064;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#36827;&#23637;&#12290;&#38500;&#20102;&#22312;&#26426;&#22120;&#20154;&#21644;&#28216;&#25103;&#31561;&#35832;&#22810;&#39046;&#22495;&#20013;&#20855;&#26377;&#33391;&#22909;&#21069;&#26223;&#30340;&#24378;&#21270;&#23398;&#20064;&#65292;&#36801;&#31227;&#23398;&#20064;&#20316;&#20026;&#19968;&#31181;&#35299;&#20915;&#24378;&#21270;&#23398;&#20064;&#38754;&#20020;&#30340;&#21508;&#31181;&#25361;&#25112;&#30340;&#26041;&#27861;&#24050;&#32463;&#20986;&#29616;&#65292;&#36890;&#36807;&#20174;&#22806;&#37096;&#19987;&#19994;&#30693;&#35782;&#20013;&#36716;&#31227;&#30693;&#35782;&#65292;&#20197;&#25552;&#39640;&#23398;&#20064;&#36807;&#31243;&#30340;&#25928;&#29575;&#21644;&#25928;&#26524;&#12290;&#22312;&#36825;&#39033;&#32508;&#36848;&#20013;&#65292;&#25105;&#20204;&#31995;&#32479;&#22320;&#35843;&#26597;&#20102;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#39046;&#22495;&#20013;&#30340;&#36801;&#31227;&#23398;&#20064;&#26041;&#27861;&#30340;&#26368;&#26032;&#36827;&#23637;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#23545;&#26368;&#20808;&#36827;&#30340;&#36801;&#31227;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#20998;&#31867;&#30340;&#26694;&#26550;&#65292;&#22312;&#27492;&#26694;&#26550;&#19979;&#20998;&#26512;&#20102;&#23427;&#20204;&#30340;&#30446;&#26631;&#12289;&#26041;&#27861;&#23398;&#12289;&#20860;&#23481;&#30340;&#24378;&#21270;&#23398;&#20064;&#32972;&#26223;&#20197;&#21450;&#23454;&#38469;&#24212;&#29992;&#12290;&#25105;&#20204;&#36824;&#25506;&#35752;&#20102;&#36801;&#31227;&#23398;&#20064;&#19982;&#20854;&#20182;&#30456;&#20851;&#20027;&#39064;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reinforcement learning is a learning paradigm for solving sequential decision-making problems. Recent years have witnessed remarkable progress in reinforcement learning upon the fast development of deep neural networks. Along with the promising prospects of reinforcement learning in numerous domains such as robotics and game-playing, transfer learning has arisen to tackle various challenges faced by reinforcement learning, by transferring knowledge from external expertise to facilitate the efficiency and effectiveness of the learning process. In this survey, we systematically investigate the recent progress of transfer learning approaches in the context of deep reinforcement learning. Specifically, we provide a framework for categorizing the state-of-the-art transfer learning approaches, under which we analyze their goals, methodologies, compatible reinforcement learning backbones, and practical applications. We also draw connections between transfer learning and other relevant topics 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#26469;&#38450;&#24481;&#23545;&#25239;&#25200;&#21160;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#20132;&#26367;&#35757;&#32451;&#20998;&#31867;&#22120;&#21644;&#29983;&#25104;&#22120;&#32593;&#32476;&#65292;&#29983;&#25104;&#22120;&#32593;&#32476;&#29983;&#25104;&#23545;&#25239;&#25200;&#21160;&#20197;&#27450;&#39575;&#20998;&#31867;&#22120;&#32593;&#32476;&#65292;&#21516;&#26102;&#20998;&#31867;&#22120;&#32593;&#32476;&#34987;&#35757;&#32451;&#20197;&#27491;&#30830;&#20998;&#31867;&#21407;&#22987;&#21644;&#23545;&#25239;&#22270;&#20687;&#65292;&#36825;&#19968;&#36807;&#31243;&#20351;&#20998;&#31867;&#22120;&#32593;&#32476;&#23545;&#23545;&#25239;&#25200;&#21160;&#26356;&#21152;&#40065;&#26834;&#65292;&#21516;&#26102;&#36824;&#33021;&#26377;&#25928;&#22320;&#38477;&#20302;&#32593;&#32476;&#30340;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/1705.03387</link><description>&lt;p&gt;
&#29983;&#25104;&#23545;&#25239;&#24615;&#35757;&#32451;&#22120;&#65306;&#20351;&#29992;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#38450;&#24481;&#23545;&#25239;&#25200;&#21160;
&lt;/p&gt;
&lt;p&gt;
Generative Adversarial Trainer: Defense to Adversarial Perturbations with GAN. (arXiv:1705.03387v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1705.03387
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#26469;&#38450;&#24481;&#23545;&#25239;&#25200;&#21160;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#20132;&#26367;&#35757;&#32451;&#20998;&#31867;&#22120;&#21644;&#29983;&#25104;&#22120;&#32593;&#32476;&#65292;&#29983;&#25104;&#22120;&#32593;&#32476;&#29983;&#25104;&#23545;&#25239;&#25200;&#21160;&#20197;&#27450;&#39575;&#20998;&#31867;&#22120;&#32593;&#32476;&#65292;&#21516;&#26102;&#20998;&#31867;&#22120;&#32593;&#32476;&#34987;&#35757;&#32451;&#20197;&#27491;&#30830;&#20998;&#31867;&#21407;&#22987;&#21644;&#23545;&#25239;&#22270;&#20687;&#65292;&#36825;&#19968;&#36807;&#31243;&#20351;&#20998;&#31867;&#22120;&#32593;&#32476;&#23545;&#23545;&#25239;&#25200;&#21160;&#26356;&#21152;&#40065;&#26834;&#65292;&#21516;&#26102;&#36824;&#33021;&#26377;&#25928;&#22320;&#38477;&#20302;&#32593;&#32476;&#30340;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25216;&#26415;&#65292;&#20351;&#29992;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#20351;&#31070;&#32463;&#32593;&#32476;&#23545;&#23545;&#25239;&#24615;&#31034;&#20363;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#20132;&#26367;&#35757;&#32451;&#20998;&#31867;&#22120;&#21644;&#29983;&#25104;&#22120;&#32593;&#32476;&#12290;&#29983;&#25104;&#22120;&#32593;&#32476;&#36890;&#36807;&#20351;&#29992;&#27599;&#20010;&#22270;&#20687;&#30340;&#26799;&#24230;&#29983;&#25104;&#23545;&#25239;&#25200;&#21160;&#65292;&#20174;&#32780;&#36731;&#26494;&#27450;&#39575;&#20998;&#31867;&#22120;&#32593;&#32476;&#12290;&#21516;&#26102;&#65292;&#20998;&#31867;&#22120;&#32593;&#32476;&#34987;&#35757;&#32451;&#20197;&#27491;&#30830;&#20998;&#31867;&#30001;&#29983;&#25104;&#22120;&#29983;&#25104;&#30340;&#21407;&#22987;&#21644;&#23545;&#25239;&#22270;&#20687;&#12290;&#36825;&#20123;&#36807;&#31243;&#26377;&#21161;&#20110;&#20351;&#20998;&#31867;&#22120;&#32593;&#32476;&#23545;&#23545;&#25239;&#25200;&#21160;&#26356;&#21152;&#40065;&#26834;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#23545;&#25239;&#35757;&#32451;&#26694;&#26550;&#26377;&#25928;&#22320;&#20943;&#23569;&#20102;&#36807;&#25311;&#21512;&#65292;&#24182;&#19988;&#20248;&#20110;&#20854;&#20182;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#22914;Dropout&#12290;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;CIFAR&#25968;&#25454;&#38598;&#30340;&#26377;&#30417;&#30563;&#23398;&#20064;&#20013;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#26174;&#33879;&#38477;&#20302;&#20102;&#32593;&#32476;&#30340;&#27867;&#21270;&#35823;&#24046;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#20351;&#29992;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#26469;&#25913;&#36827;&#30417;&#30563;&#23398;&#20064;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel technique to make neural network robust to adversarial examples using a generative adversarial network. We alternately train both classifier and generator networks. The generator network generates an adversarial perturbation that can easily fool the classifier network by using a gradient of each image. Simultaneously, the classifier network is trained to classify correctly both original and adversarial images generated by the generator. These procedures help the classifier network to become more robust to adversarial perturbations. Furthermore, our adversarial training framework efficiently reduces overfitting and outperforms other regularization methods such as Dropout. We applied our method to supervised learning for CIFAR datasets, and experimantal results show that our method significantly lowers the generalization error of the network. To the best of our knowledge, this is the first method which uses GAN to improve supervised learning.
&lt;/p&gt;</description></item></channel></rss>