<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#27531;&#24046;&#20998;&#25903;&#23610;&#24230;&#21644;$\mu$P&#21442;&#25968;&#21270;&#30340;&#27531;&#24046;&#32593;&#32476;&#65292;&#23454;&#29616;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#36229;&#21442;&#25968;&#30340;&#36328;&#23485;&#24230;&#21644;&#28145;&#24230;&#30340;&#36716;&#31227;&#12290;</title><link>http://arxiv.org/abs/2309.16620</link><description>&lt;p&gt;
&#27531;&#24046;&#32593;&#32476;&#20013;&#30340;&#28145;&#24230;&#36229;&#21442;&#25968;&#36716;&#31227;&#65306;&#21160;&#24577;&#21644;&#32553;&#25918;&#38480;&#21046;
&lt;/p&gt;
&lt;p&gt;
Depthwise Hyperparameter Transfer in Residual Networks: Dynamics and Scaling Limit. (arXiv:2309.16620v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16620
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#36890;&#36807;&#27531;&#24046;&#20998;&#25903;&#23610;&#24230;&#21644;$\mu$P&#21442;&#25968;&#21270;&#30340;&#27531;&#24046;&#32593;&#32476;&#65292;&#23454;&#29616;&#20102;&#28145;&#24230;&#23398;&#20064;&#20013;&#36229;&#21442;&#25968;&#30340;&#36328;&#23485;&#24230;&#21644;&#28145;&#24230;&#30340;&#36716;&#31227;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#27169;&#22411;&#22823;&#23567;&#30340;&#22686;&#21152;&#65292;&#28145;&#24230;&#23398;&#20064;&#20013;&#36229;&#21442;&#25968;&#35843;&#25972;&#30340;&#25104;&#26412;&#19981;&#26029;&#19978;&#21319;&#65292;&#20419;&#20351;&#20174;&#19994;&#32773;&#23547;&#25214;&#20351;&#29992;&#36739;&#23567;&#32593;&#32476;&#30340;&#20195;&#29702;&#26041;&#27861;&#36827;&#34892;&#35843;&#25972;&#12290;&#20854;&#20013;&#19968;&#20010;&#24314;&#35758;&#20351;&#29992;$\mu$P&#21442;&#25968;&#21270;&#32593;&#32476;&#65292;&#20854;&#20013;&#23567;&#23485;&#24230;&#32593;&#32476;&#30340;&#26368;&#20339;&#36229;&#21442;&#25968;&#36716;&#31227;&#21040;&#20219;&#24847;&#23485;&#24230;&#30340;&#32593;&#32476;&#20013;&#12290;&#28982;&#32780;&#65292;&#22312;&#36825;&#20010;&#26041;&#26696;&#20013;&#65292;&#36229;&#21442;&#25968;&#19981;&#20250;&#22312;&#19981;&#21516;&#28145;&#24230;&#20043;&#38388;&#36716;&#31227;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;$1/\sqrt{\text{depth}}$&#30340;&#27531;&#24046;&#20998;&#25903;&#23610;&#24230;&#21644;$\mu$P&#21442;&#25968;&#21270;&#30340;&#27531;&#24046;&#32593;&#32476;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#20351;&#29992;&#36825;&#31181;&#21442;&#25968;&#21270;&#35757;&#32451;&#30340;&#27531;&#24046;&#32467;&#26500;&#65292;&#21253;&#25324;&#21367;&#31215;ResNet&#21644;Vision Transformer&#65292;&#22312;CIFAR-10&#21644;ImageNet&#19978;&#23637;&#31034;&#20102;&#36328;&#23485;&#24230;&#21644;&#28145;&#24230;&#30340;&#26368;&#20339;&#36229;&#21442;&#25968;&#36716;&#31227;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#32463;&#39564;&#21457;&#29616;&#24471;&#21040;&#20102;&#29702;&#35770;&#30340;&#25903;&#25345;&#21644;&#21160;&#26426;&#12290;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#21160;&#21147;&#23398;&#30340;&#21160;&#24577;&#22343;&#22330;&#29702;&#35770;&#65288;DMFT&#65289;&#25551;&#36848;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;
&lt;/p&gt;
&lt;p&gt;
The cost of hyperparameter tuning in deep learning has been rising with model sizes, prompting practitioners to find new tuning methods using a proxy of smaller networks. One such proposal uses $\mu$P parameterized networks, where the optimal hyperparameters for small width networks transfer to networks with arbitrarily large width. However, in this scheme, hyperparameters do not transfer across depths. As a remedy, we study residual networks with a residual branch scale of $1/\sqrt{\text{depth}}$ in combination with the $\mu$P parameterization. We provide experiments demonstrating that residual architectures including convolutional ResNets and Vision Transformers trained with this parameterization exhibit transfer of optimal hyperparameters across width and depth on CIFAR-10 and ImageNet. Furthermore, our empirical findings are supported and motivated by theory. Using recent developments in the dynamical mean field theory (DMFT) description of neural network learning dynamics, we show
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#27604;&#36739;&#20855;&#26377;&#33410;&#28857;&#21644;&#36793;&#29305;&#24449;&#30340;&#22270;&#30340;&#25193;&#23637;Gromov-Wasserstein&#36317;&#31163;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#31639;&#27861;&#26469;&#35745;&#31639;&#36317;&#31163;&#21644;&#37325;&#24515;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#22270;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.16604</link><description>&lt;p&gt;
&#21033;&#29992;&#34701;&#21512;&#32593;&#32476;Gromov-Wasserstein&#36317;&#31163;&#20013;&#30340;&#36793;&#29305;&#24449;&#23545;&#22270;&#36827;&#34892;&#25366;&#25496;
&lt;/p&gt;
&lt;p&gt;
Exploiting Edge Features in Graphs with Fused Network Gromov-Wasserstein Distance. (arXiv:2309.16604v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16604
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#27604;&#36739;&#20855;&#26377;&#33410;&#28857;&#21644;&#36793;&#29305;&#24449;&#30340;&#22270;&#30340;&#25193;&#23637;Gromov-Wasserstein&#36317;&#31163;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#30340;&#31639;&#27861;&#26469;&#35745;&#31639;&#36317;&#31163;&#21644;&#37325;&#24515;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#22312;&#22270;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#30340;&#25104;&#23545;&#27604;&#36739;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#35768;&#22810;&#24212;&#29992;&#20013;&#33267;&#20851;&#37325;&#35201;&#65292;&#21253;&#25324;&#32858;&#31867;&#12289;&#22522;&#20110;&#26680;&#30340;&#20998;&#31867;/&#22238;&#24402;&#20197;&#21450;&#26368;&#36817;&#30340;&#30417;&#30563;&#22270;&#39044;&#27979;&#12290;&#22270;&#20043;&#38388;&#30340;&#36317;&#31163;&#36890;&#24120;&#20381;&#36182;&#20110;&#36825;&#20123;&#32467;&#26500;&#21270;&#23545;&#35937;&#30340;&#20449;&#24687;&#34920;&#36798;&#65292;&#22914;&#23376;&#32467;&#26500;&#21253;&#25110;&#20854;&#20182;&#22270;&#23884;&#20837;&#12290;&#19968;&#31181;&#26368;&#36817;&#27969;&#34892;&#30340;&#35299;&#20915;&#26041;&#26696;&#26159;&#23558;&#22270;&#34920;&#31034;&#20026;&#24230;&#37327;&#27979;&#24230;&#31354;&#38388;&#65292;&#36825;&#26679;&#21487;&#20197;&#25104;&#21151;&#22320;&#21033;&#29992;&#26368;&#20248;&#36755;&#36816;&#65292;&#23427;&#25552;&#20379;&#20102;&#26377;&#24847;&#20041;&#30340;&#36317;&#31163;&#26469;&#27604;&#36739;&#23427;&#20204;&#65306;Gromov-Wasserstein&#36317;&#31163;&#12290;&#28982;&#32780;&#65292;&#36825;&#31867;&#36317;&#31163;&#24573;&#30053;&#20102;&#36793;&#23646;&#24615;&#65292;&#32780;&#36825;&#23545;&#20110;&#35768;&#22810;&#32467;&#26500;&#21270;&#23545;&#35937;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#25193;&#23637;Gromov-Wasserstein&#36317;&#31163;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#27604;&#36739;&#20855;&#26377;&#33410;&#28857;&#21644;&#36793;&#29305;&#24449;&#30340;&#22270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#36317;&#31163;&#21644;&#37325;&#24515;&#35745;&#31639;&#30340;&#26032;&#31639;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;&#26032;&#36317;&#31163;&#22312;&#22270;&#20986;&#29616;&#22312;&#36755;&#20837;&#21644;&#36755;&#20986;&#30340;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#26377;&#25928;&#24615;
&lt;/p&gt;
&lt;p&gt;
Pairwise comparison of graphs is key to many applications in Machine learning ranging from clustering, kernel-based classification/regression and more recently supervised graph prediction. Distances between graphs usually rely on informative representations of these structured objects such as bag of substructures or other graph embeddings. A recently popular solution consists in representing graphs as metric measure spaces, allowing to successfully leverage Optimal Transport, which provides meaningful distances allowing to compare them: the Gromov-Wasserstein distances. However, this family of distances overlooks edge attributes, which are essential for many structured objects. In this work, we introduce an extension of Gromov-Wasserstein distance for comparing graphs whose both nodes and edges have features. We propose novel algorithms for distance and barycenter computation. We empirically show the effectiveness of the novel distance in learning tasks where graphs occur in either inp
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#20132;&#21449;&#39044;&#27979;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#36827;&#34892;&#25512;&#29702;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#20351;&#29992;&#19968;&#20010;&#23567;&#22411;&#26631;&#35760;&#25968;&#25454;&#38598;&#21644;&#19968;&#20010;&#22823;&#22411;&#26410;&#26631;&#35760;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#22635;&#34917;&#32570;&#22833;&#30340;&#26631;&#31614;&#65292;&#24182;&#37319;&#29992;&#21435;&#20559;&#24046;&#26041;&#27861;&#32416;&#27491;&#39044;&#27979;&#30340;&#19981;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.16598</link><description>&lt;p&gt;
&#22522;&#20110;&#20132;&#21449;&#39044;&#27979;&#30340;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Cross-Prediction-Powered Inference. (arXiv:2309.16598v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16598
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#20132;&#21449;&#39044;&#27979;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#36827;&#34892;&#25512;&#29702;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#20351;&#29992;&#19968;&#20010;&#23567;&#22411;&#26631;&#35760;&#25968;&#25454;&#38598;&#21644;&#19968;&#20010;&#22823;&#22411;&#26410;&#26631;&#35760;&#25968;&#25454;&#38598;&#65292;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#22635;&#34917;&#32570;&#22833;&#30340;&#26631;&#31614;&#65292;&#24182;&#37319;&#29992;&#21435;&#20559;&#24046;&#26041;&#27861;&#32416;&#27491;&#39044;&#27979;&#30340;&#19981;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#38752;&#30340;&#25968;&#25454;&#39537;&#21160;&#20915;&#31574;&#20381;&#36182;&#20110;&#39640;&#36136;&#37327;&#30340;&#26631;&#27880;&#25968;&#25454;&#65292;&#28982;&#32780;&#33719;&#21462;&#39640;&#36136;&#37327;&#30340;&#26631;&#27880;&#25968;&#25454;&#32463;&#24120;&#38656;&#35201;&#32321;&#29712;&#30340;&#20154;&#24037;&#26631;&#27880;&#25110;&#32773;&#32531;&#24930;&#26114;&#36149;&#30340;&#31185;&#23398;&#27979;&#37327;&#12290;&#26426;&#22120;&#23398;&#20064;&#20316;&#20026;&#19968;&#31181;&#26367;&#20195;&#26041;&#26696;&#27491;&#21464;&#24471;&#36234;&#26469;&#36234;&#26377;&#21560;&#24341;&#21147;&#65292;&#22240;&#20026;&#31934;&#23494;&#30340;&#39044;&#27979;&#25216;&#26415;&#21487;&#20197;&#24555;&#36895;&#12289;&#24265;&#20215;&#22320;&#20135;&#29983;&#22823;&#37327;&#39044;&#27979;&#26631;&#31614;&#65307;&#20363;&#22914;&#65292;&#39044;&#27979;&#30340;&#34507;&#30333;&#36136;&#32467;&#26500;&#34987;&#29992;&#26469;&#34917;&#20805;&#23454;&#39564;&#24471;&#21040;&#30340;&#32467;&#26500;&#65292;&#21355;&#26143;&#22270;&#20687;&#39044;&#27979;&#30340;&#31038;&#20250;&#32463;&#27982;&#25351;&#26631;&#34987;&#29992;&#26469;&#34917;&#20805;&#20934;&#30830;&#30340;&#35843;&#26597;&#25968;&#25454;&#31561;&#12290;&#30001;&#20110;&#39044;&#27979;&#20855;&#26377;&#19981;&#23436;&#32654;&#21644;&#28508;&#22312;&#20559;&#24046;&#30340;&#29305;&#28857;&#65292;&#36825;&#31181;&#20570;&#27861;&#23545;&#19979;&#28216;&#25512;&#29702;&#30340;&#26377;&#25928;&#24615;&#20135;&#29983;&#20102;&#36136;&#30097;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#20132;&#21449;&#39044;&#27979;&#26041;&#27861;&#65292;&#29992;&#20110;&#26377;&#25928;&#30340;&#25512;&#29702;&#12290;&#36890;&#36807;&#19968;&#20010;&#23567;&#30340;&#26631;&#35760;&#25968;&#25454;&#38598;&#21644;&#19968;&#20010;&#22823;&#30340;&#26410;&#26631;&#35760;&#25968;&#25454;&#38598;&#65292;&#20132;&#21449;&#39044;&#27979;&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#22635;&#34917;&#32570;&#22833;&#30340;&#26631;&#31614;&#65292;&#24182;&#24212;&#29992;&#19968;&#31181;&#21435;&#20559;&#24046;&#30340;&#26041;&#27861;&#26469;&#32416;&#27491;&#39044;&#27979;&#19981;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
While reliable data-driven decision-making hinges on high-quality labeled data, the acquisition of quality labels often involves laborious human annotations or slow and expensive scientific measurements. Machine learning is becoming an appealing alternative as sophisticated predictive techniques are being used to quickly and cheaply produce large amounts of predicted labels; e.g., predicted protein structures are used to supplement experimentally derived structures, predictions of socioeconomic indicators from satellite imagery are used to supplement accurate survey data, and so on. Since predictions are imperfect and potentially biased, this practice brings into question the validity of downstream inferences. We introduce cross-prediction: a method for valid inference powered by machine learning. With a small labeled dataset and a large unlabeled dataset, cross-prediction imputes the missing labels via machine learning and applies a form of debiasing to remedy the prediction inaccurac
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;MPHD&#26041;&#27861;&#65292;&#36890;&#36807;&#27169;&#22411;&#39044;&#35757;&#32451;&#21644;&#31070;&#32463;&#32593;&#32476;&#22312;&#24322;&#36136;&#25628;&#32034;&#31354;&#38388;&#19978;&#23454;&#29616;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#36801;&#31227;&#23398;&#20064;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;MPHD&#30340;&#26377;&#25928;&#24615;&#21644;&#22312;&#40657;&#30418;&#20989;&#25968;&#20248;&#21270;&#20219;&#21153;&#20013;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.16597</link><description>&lt;p&gt;
&#24322;&#36136;&#25628;&#32034;&#31354;&#38388;&#19978;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#36801;&#31227;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Transfer Learning for Bayesian Optimization on Heterogeneous Search Spaces. (arXiv:2309.16597v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16597
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;MPHD&#26041;&#27861;&#65292;&#36890;&#36807;&#27169;&#22411;&#39044;&#35757;&#32451;&#21644;&#31070;&#32463;&#32593;&#32476;&#22312;&#24322;&#36136;&#25628;&#32034;&#31354;&#38388;&#19978;&#23454;&#29616;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#36801;&#31227;&#23398;&#20064;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;MPHD&#30340;&#26377;&#25928;&#24615;&#21644;&#22312;&#40657;&#30418;&#20989;&#25968;&#20248;&#21270;&#20219;&#21153;&#20013;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#40657;&#30418;&#20989;&#25968;&#20248;&#21270;&#26041;&#27861;&#65292;&#23427;&#22522;&#20110;&#36125;&#21494;&#26031;&#27169;&#22411;&#65288;&#36890;&#24120;&#26159;&#39640;&#26031;&#36807;&#31243;&#65289;&#36827;&#34892;&#39034;&#24207;&#20915;&#31574;&#12290;&#20026;&#20102;&#30830;&#20445;&#27169;&#22411;&#30340;&#36136;&#37327;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#36801;&#31227;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#23398;&#20064;&#26469;&#33258;&#8220;&#35757;&#32451;&#8221;&#20989;&#25968;&#30340;&#35266;&#23519;&#32467;&#26524;&#26469;&#33258;&#21160;&#35774;&#35745;&#39640;&#26031;&#36807;&#31243;&#20808;&#39564;&#12290;&#36825;&#20123;&#35757;&#32451;&#20989;&#25968;&#36890;&#24120;&#38656;&#35201;&#19982;&#8220;&#27979;&#35797;&#8221;&#20989;&#25968;&#65288;&#24453;&#20248;&#21270;&#30340;&#40657;&#30418;&#20989;&#25968;&#65289;&#20855;&#26377;&#30456;&#21516;&#30340;&#23450;&#20041;&#22495;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#21517;&#20026;MPHD&#30340;&#27169;&#22411;&#39044;&#35757;&#32451;&#26041;&#27861;&#65292;&#23427;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#23558;&#29305;&#23450;&#20110;&#39046;&#22495;&#30340;&#19978;&#19979;&#25991;&#26144;&#23556;&#21040;&#20998;&#23618;&#39640;&#26031;&#36807;&#31243;&#30340;&#35268;&#33539;&#12290;MPHD&#21487;&#20197;&#19982;&#36125;&#21494;&#26031;&#20248;&#21270;&#26080;&#32541;&#38598;&#25104;&#65292;&#23454;&#29616;&#24322;&#36136;&#25628;&#32034;&#31354;&#38388;&#30340;&#30693;&#35782;&#36801;&#31227;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#21644;&#23454;&#35777;&#32467;&#26524;&#35777;&#26126;&#20102;MPHD&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#23427;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#40657;&#30418;&#20989;&#25968;&#20248;&#21270;&#20219;&#21153;&#20013;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian optimization (BO) is a popular black-box function optimization method, which makes sequential decisions based on a Bayesian model, typically a Gaussian process (GP), of the function. To ensure the quality of the model, transfer learning approaches have been developed to automatically design GP priors by learning from observations on "training" functions. These training functions are typically required to have the same domain as the "test" function (black-box function to be optimized). In this paper, we introduce MPHD, a model pre-training method on heterogeneous domains, which uses a neural net mapping from domain-specific contexts to specifications of hierarchical GPs. MPHD can be seamlessly integrated with BO to transfer knowledge across heterogeneous search spaces. Our theoretical and empirical results demonstrate the validity of MPHD and its superior performance on challenging black-box function optimization tasks.
&lt;/p&gt;</description></item><item><title>M-OFDFT&#26159;&#19968;&#31181;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#35299;&#20915;&#20998;&#23376;&#31995;&#32479;&#38382;&#39064;&#30340;OFDFT&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#38750;&#23616;&#22495;&#24615;&#24314;&#31435;&#22312;&#27169;&#22411;&#20013;&#24182;&#20351;&#29992;&#32039;&#20945;&#30340;&#23494;&#24230;&#34920;&#31034;&#65292;&#23454;&#29616;&#20102;&#19982;Kohn-Sham DFT&#30456;&#36817;&#30340;&#31934;&#30830;&#24230;&#65292;&#24182;&#19988;&#20855;&#26377;&#33391;&#22909;&#30340;&#22806;&#25512;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2309.16578</link><description>&lt;p&gt;
M-OFDFT&#65306;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#20811;&#26381;&#20998;&#23376;&#31995;&#32479;&#20013;&#30340;&#26080;&#36712;&#36947;&#23494;&#24230;&#27867;&#20989;&#29702;&#35770;&#30340;&#38556;&#30861;
&lt;/p&gt;
&lt;p&gt;
M-OFDFT: Overcoming the Barrier of Orbital-Free Density Functional Theory for Molecular Systems Using Deep Learning. (arXiv:2309.16578v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16578
&lt;/p&gt;
&lt;p&gt;
M-OFDFT&#26159;&#19968;&#31181;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#35299;&#20915;&#20998;&#23376;&#31995;&#32479;&#38382;&#39064;&#30340;OFDFT&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#38750;&#23616;&#22495;&#24615;&#24314;&#31435;&#22312;&#27169;&#22411;&#20013;&#24182;&#20351;&#29992;&#32039;&#20945;&#30340;&#23494;&#24230;&#34920;&#31034;&#65292;&#23454;&#29616;&#20102;&#19982;Kohn-Sham DFT&#30456;&#36817;&#30340;&#31934;&#30830;&#24230;&#65292;&#24182;&#19988;&#20855;&#26377;&#33391;&#22909;&#30340;&#22806;&#25512;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#36712;&#36947;&#23494;&#24230;&#27867;&#20989;&#29702;&#35770;&#65288;OFDFT&#65289;&#26159;&#19968;&#31181;&#20855;&#26377;&#36739;&#20302;&#36816;&#31639;&#25104;&#26412;&#30340;&#37327;&#23376;&#21270;&#23398;&#35745;&#31639;&#26041;&#27861;&#65292;&#27604;&#36215;&#24120;&#29992;&#30340;Kohn-Sham&#23494;&#24230;&#27867;&#20989;&#29702;&#35770;&#26356;&#21152;&#36866;&#29992;&#20110;&#24403;&#20195;&#20998;&#23376;&#30740;&#31350;&#12290;&#28982;&#32780;&#65292;OFDFT&#30340;&#31934;&#30830;&#24615;&#21463;&#21040;&#20102;&#21160;&#33021;&#23494;&#24230;&#27867;&#20989;&#30340;&#38480;&#21046;&#65292;&#23545;&#20110;&#38750;&#21608;&#26399;&#24615;&#20998;&#23376;&#31995;&#32479;&#30340;&#36817;&#20284;&#27714;&#35299;&#38750;&#24120;&#22256;&#38590;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#21517;&#20026;M-OFDFT&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#30340;&#20989;&#25968;&#27169;&#22411;&#35299;&#20915;&#20102;&#20998;&#23376;&#31995;&#32479;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#23558;&#24517;&#35201;&#30340;&#38750;&#23616;&#22495;&#24615;&#24314;&#31435;&#22312;&#36825;&#20010;&#27169;&#22411;&#20013;&#65292;&#36890;&#36807;&#21407;&#23376;&#22522;&#19979;&#30340;&#23637;&#24320;&#31995;&#25968;&#20316;&#20026;&#32039;&#20945;&#30340;&#23494;&#24230;&#34920;&#31034;&#26469;&#38477;&#20302;&#25104;&#26412;&#12290;&#36890;&#36807;&#35299;&#20915;&#20854;&#20013;&#30340;&#38750;&#20256;&#32479;&#23398;&#20064;&#25361;&#25112;&#30340;&#25216;&#26415;&#65292;M-OFDFT&#22312;&#19968;&#31995;&#21015;OFDFT&#26080;&#27861;&#35302;&#21450;&#30340;&#20998;&#23376;&#19978;&#23454;&#29616;&#20102;&#19982;Kohn-Sham DFT&#30456;&#24403;&#30340;&#31934;&#30830;&#24230;&#12290;&#26356;&#26377;&#21560;&#24341;&#21147;&#30340;&#26159;&#65292;M-OFDFT&#22312;&#35757;&#32451;&#26102;&#23646;&#20110;&#26356;&#22823;&#30340;&#20998;&#23376;&#20013;&#26377;&#30528;&#33391;&#22909;&#30340;&#22806;&#25512;&#33021;&#21147;&#65292;&#20026;&#30740;&#31350;&#22823;&#20998;&#23376;&#25552;&#20379;&#20102;&#26377;&#21560;&#24341;&#21147;&#30340;&#35268;&#27169;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
Orbital-free density functional theory (OFDFT) is a quantum chemistry formulation that has a lower cost scaling than the prevailing Kohn-Sham DFT, which is increasingly desired for contemporary molecular research. However, its accuracy is limited by the kinetic energy density functional, which is notoriously hard to approximate for non-periodic molecular systems. In this work, we propose M-OFDFT, an OFDFT approach capable of solving molecular systems using a deep-learning functional model. We build the essential nonlocality into the model, which is made affordable by the concise density representation as expansion coefficients under an atomic basis. With techniques to address unconventional learning challenges therein, M-OFDFT achieves a comparable accuracy with Kohn-Sham DFT on a wide range of molecules untouched by OFDFT before. More attractively, M-OFDFT extrapolates well to molecules much larger than those in training, which unleashes the appealing scaling for studying large molecu
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#20219;&#24847;&#30772;&#22351;&#30340;&#22810;&#33218;&#36172;&#24466;&#38382;&#39064;&#65292;&#24182;&#24314;&#31435;&#20102;&#19968;&#20010;&#19982;&#38382;&#39064;&#30456;&#20851;&#30340;&#36951;&#25022;&#19979;&#30028;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;CRIMED&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#20855;&#26377;&#24050;&#30693;&#26041;&#24046;&#30340;&#39640;&#26031;&#20998;&#24067;&#36172;&#24466;&#38382;&#39064;&#19978;&#23454;&#29616;&#20102;&#36951;&#25022;&#19979;&#30028;&#12290;</title><link>http://arxiv.org/abs/2309.16563</link><description>&lt;p&gt;
CRIMED&#65306;&#20855;&#26377;&#26080;&#30028;&#38543;&#26426;&#30772;&#22351;&#30340;&#36172;&#24466;&#38382;&#39064;&#30340;&#36951;&#25022;&#19979;&#30028;&#21644;&#19978;&#30028;
&lt;/p&gt;
&lt;p&gt;
CRIMED: Lower and Upper Bounds on Regret for Bandits with Unbounded Stochastic Corruption. (arXiv:2309.16563v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16563
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#20219;&#24847;&#30772;&#22351;&#30340;&#22810;&#33218;&#36172;&#24466;&#38382;&#39064;&#65292;&#24182;&#24314;&#31435;&#20102;&#19968;&#20010;&#19982;&#38382;&#39064;&#30456;&#20851;&#30340;&#36951;&#25022;&#19979;&#30028;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;CRIMED&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;&#20855;&#26377;&#24050;&#30693;&#26041;&#24046;&#30340;&#39640;&#26031;&#20998;&#24067;&#36172;&#24466;&#38382;&#39064;&#19978;&#23454;&#29616;&#20102;&#36951;&#25022;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#22810;&#33218;&#36172;&#24466;&#38382;&#39064;&#20013;&#20855;&#26377;&#20219;&#24847;&#30772;&#22351;&#30340;&#36951;&#25022;&#26368;&#23567;&#21270;&#38382;&#39064;&#12290;&#19982;&#32463;&#20856;&#35774;&#23450;&#31867;&#20284;&#65292;&#20195;&#29702;&#25509;&#25910;&#21040;&#30340;&#22870;&#21169;&#26159;&#20174;&#27599;&#20010;&#26102;&#38388;&#28857;&#36873;&#25321;&#30340;&#33218;&#30340;&#20998;&#24067;&#29420;&#31435;&#29983;&#25104;&#30340;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#22870;&#21169;&#24182;&#19981;&#30452;&#25509;&#35266;&#23519;&#21040;&#12290;&#30456;&#21453;&#65292;&#23545;&#20110;&#22266;&#23450;&#30340;&#949;&#8712;(0,12)&#65292;&#20195;&#29702;&#20197;&#27010;&#29575;1-&#949;&#20174;&#36873;&#25321;&#30340;&#33218;&#30340;&#20998;&#24067;&#20013;&#35266;&#27979;&#19968;&#20010;&#26679;&#26412;&#65292;&#25110;&#20197;&#27010;&#29575;&#949;&#20174;&#20219;&#24847;&#30772;&#22351;&#20998;&#24067;&#20013;&#35266;&#27979;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#25105;&#20204;&#23545;&#36825;&#20123;&#30772;&#22351;&#20998;&#24067;&#19981;&#20570;&#20219;&#20309;&#20551;&#35774;&#65292;&#23427;&#20204;&#21487;&#20197;&#26159;&#26080;&#30028;&#30340;&#12290;&#22312;&#36825;&#31181;&#21487;&#33021;&#20855;&#26377;&#26080;&#30028;&#30772;&#22351;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#20026;&#32473;&#23450;&#30340;&#33218;&#20998;&#24067;&#26063;&#24314;&#31435;&#20102;&#19968;&#20010;&#19982;&#38382;&#39064;&#30456;&#20851;&#30340;&#36951;&#25022;&#19979;&#30028;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;CRIMED&#65292;&#36825;&#26159;&#19968;&#20010;&#28176;&#36817;&#26368;&#20248;&#30340;&#31639;&#27861;&#65292;&#23427;&#22312;&#20855;&#26377;&#24050;&#30693;&#26041;&#24046;&#30340;&#39640;&#26031;&#20998;&#24067;&#36172;&#24466;&#38382;&#39064;&#19978;&#23454;&#29616;&#20102;&#36951;&#25022;&#19979;&#30028;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23545;&#26377;&#38480;&#26679;&#26412;&#36827;&#34892;&#20102;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the regret-minimisation problem in a multi-armed bandit setting with arbitrary corruptions. Similar to the classical setup, the agent receives rewards generated independently from the distribution of the arm chosen at each time. However, these rewards are not directly observed. Instead, with a fixed $\varepsilon\in (0,\frac{1}{2})$, the agent observes a sample from the chosen arm's distribution with probability $1-\varepsilon$, or from an arbitrary corruption distribution with probability $\varepsilon$. Importantly, we impose no assumptions on these corruption distributions, which can be unbounded. In this setting, accommodating potentially unbounded corruptions, we establish a problem-dependent lower bound on regret for a given family of arm distributions. We introduce CRIMED, an asymptotically-optimal algorithm that achieves the exact lower bound on regret for bandits with Gaussian distributions with known variance. Additionally, we provide a finite-sample analysis of 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SFAVEL&#30340;&#26080;&#30417;&#30563;&#26694;&#26550;&#65292;&#36890;&#36807;&#35821;&#35328;&#27169;&#22411;&#33976;&#39311;&#23558;&#33258;&#30417;&#30563;&#29305;&#24449;&#36716;&#21270;&#20026;&#39640;&#36136;&#37327;&#30340;&#20027;&#24352;-&#20107;&#23454;&#23545;&#40784;&#65292;&#23454;&#29616;&#26080;&#30417;&#30563;&#20107;&#23454;&#39564;&#35777;&#12290;&#36825;&#36890;&#36807;&#19968;&#31181;&#26032;&#39062;&#30340;&#23545;&#27604;&#25439;&#22833;&#20989;&#25968;&#23454;&#29616;&#65292;&#21516;&#26102;&#20445;&#30041;&#35821;&#26009;&#24211;&#38388;&#30340;&#35821;&#20041;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2309.16540</link><description>&lt;p&gt;
&#26080;&#30417;&#30563;&#35821;&#35328;&#27169;&#22411;&#33976;&#39311;&#30340;&#20107;&#23454;&#39564;&#35777;
&lt;/p&gt;
&lt;p&gt;
Unsupervised Fact Verification by Language Model Distillation. (arXiv:2309.16540v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16540
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;SFAVEL&#30340;&#26080;&#30417;&#30563;&#26694;&#26550;&#65292;&#36890;&#36807;&#35821;&#35328;&#27169;&#22411;&#33976;&#39311;&#23558;&#33258;&#30417;&#30563;&#29305;&#24449;&#36716;&#21270;&#20026;&#39640;&#36136;&#37327;&#30340;&#20027;&#24352;-&#20107;&#23454;&#23545;&#40784;&#65292;&#23454;&#29616;&#26080;&#30417;&#30563;&#20107;&#23454;&#39564;&#35777;&#12290;&#36825;&#36890;&#36807;&#19968;&#31181;&#26032;&#39062;&#30340;&#23545;&#27604;&#25439;&#22833;&#20989;&#25968;&#23454;&#29616;&#65292;&#21516;&#26102;&#20445;&#30041;&#35821;&#26009;&#24211;&#38388;&#30340;&#35821;&#20041;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#20107;&#23454;&#39564;&#35777;&#26088;&#22312;&#36890;&#36807;&#21487;&#38752;&#30693;&#35782;&#24211;&#20013;&#30340;&#35777;&#25454;&#26469;&#39564;&#35777;&#20027;&#24352;&#65292;&#32780;&#26080;&#38656;&#20219;&#20309;&#24418;&#24335;&#30340;&#25968;&#25454;&#27880;&#37322;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#31639;&#27861;&#24517;&#39035;&#20026;&#27599;&#20010;&#20027;&#24352;&#29983;&#25104;&#26082;&#35821;&#20041;&#26126;&#30830;&#21448;&#32039;&#20945;&#30340;&#29305;&#24449;&#65292;&#20197;&#20415;&#19982;&#28304;&#20449;&#24687;&#36827;&#34892;&#35821;&#20041;&#23545;&#40784;&#12290;&#19982;&#20043;&#21069;&#30340;&#24037;&#20316;&#19981;&#21516;&#65292;&#21069;&#32773;&#36890;&#36807;&#23398;&#20064;&#21253;&#21547;&#20027;&#24352;&#21450;&#20854;&#30456;&#24212;&#26631;&#31614;&#30340;&#27880;&#37322;&#35821;&#26009;&#24211;&#26469;&#35299;&#20915;&#23545;&#40784;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;SFAVEL&#65288;&#36890;&#36807;&#35821;&#35328;&#27169;&#22411;&#33976;&#39311;&#30340;&#33258;&#30417;&#30563;&#20107;&#23454;&#39564;&#35777;&#65289;&#65292;&#36825;&#26159;&#19968;&#20010;&#26032;&#39062;&#30340;&#26080;&#30417;&#30563;&#26694;&#26550;&#65292;&#21033;&#29992;&#39044;&#35757;&#32451;&#30340;&#35821;&#35328;&#27169;&#22411;&#23558;&#33258;&#30417;&#30563;&#29305;&#24449;&#33976;&#39311;&#20026;&#39640;&#36136;&#37327;&#30340;&#20027;&#24352;-&#20107;&#23454;&#23545;&#40784;&#65292;&#32780;&#26080;&#38656;&#27880;&#37322;&#12290;&#36825;&#26159;&#36890;&#36807;&#19968;&#31181;&#26032;&#39062;&#30340;&#23545;&#27604;&#25439;&#22833;&#20989;&#25968;&#23454;&#29616;&#30340;&#65292;&#35813;&#20989;&#25968;&#40723;&#21169;&#29305;&#24449;&#22312;&#20445;&#25345;&#35821;&#26009;&#24211;&#38388;&#30340;&#35821;&#20041;&#20851;&#31995;&#30340;&#21516;&#26102;&#23454;&#29616;&#39640;&#36136;&#37327;&#30340;&#20027;&#24352;&#21644;&#35777;&#25454;&#23545;&#40784;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36798;&#21040;&#26032;&#39062;&#30340;&#29366;&#24577;&#19968;.
&lt;/p&gt;
&lt;p&gt;
Unsupervised fact verification aims to verify a claim using evidence from a trustworthy knowledge base without any kind of data annotation. To address this challenge, algorithms must produce features for every claim that are both semantically meaningful, and compact enough to find a semantic alignment with the source information. In contrast to previous work, which tackled the alignment problem by learning over annotated corpora of claims and their corresponding labels, we propose SFAVEL (Self-supervised Fact Verification via Language Model Distillation), a novel unsupervised framework that leverages pre-trained language models to distil self-supervised features into high-quality claim-fact alignments without the need for annotations. This is enabled by a novel contrastive loss function that encourages features to attain high-quality claim and evidence alignments whilst preserving the semantic relationships across the corpora. Notably, we present results that achieve a new state-of-the
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;&#29983;&#25104;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#21644;&#20915;&#31574;&#29702;&#35770;&#30456;&#32467;&#21512;&#30340;&#26032;&#26694;&#26550;&#65292;&#29992;&#20110;&#29983;&#25104;&#20010;&#24615;&#21270;&#30340;&#33008;&#23707;&#32032;&#27835;&#30103;&#31574;&#30053;&#12290;&#36890;&#36807;&#23398;&#20064;&#29983;&#25104;&#36924;&#30495;&#30340;&#20010;&#24615;&#21270;&#27835;&#30103;&#21644;&#26410;&#26469;&#32467;&#26524;&#36712;&#36857;&#65292;&#21487;&#20197;&#20026;&#20010;&#24615;&#21270;&#24739;&#32773;&#21382;&#21490;&#21305;&#37197;&#19988;&#38024;&#23545;&#26368;&#20339;&#26410;&#26469;&#25928;&#26524;&#30340;&#26032;&#22411;&#22810;&#21464;&#37327;&#27835;&#30103;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2309.16521</link><description>&lt;p&gt;
&#20351;&#29992;&#28145;&#24230;&#26465;&#20214;&#29983;&#25104;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#29983;&#25104;&#20010;&#24615;&#21270;&#30340;&#33008;&#23707;&#32032;&#27835;&#30103;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Generating Personalized Insulin Treatments Strategies with Deep Conditional Generative Time Series Models. (arXiv:2309.16521v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16521
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#28145;&#24230;&#29983;&#25104;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#21644;&#20915;&#31574;&#29702;&#35770;&#30456;&#32467;&#21512;&#30340;&#26032;&#26694;&#26550;&#65292;&#29992;&#20110;&#29983;&#25104;&#20010;&#24615;&#21270;&#30340;&#33008;&#23707;&#32032;&#27835;&#30103;&#31574;&#30053;&#12290;&#36890;&#36807;&#23398;&#20064;&#29983;&#25104;&#36924;&#30495;&#30340;&#20010;&#24615;&#21270;&#27835;&#30103;&#21644;&#26410;&#26469;&#32467;&#26524;&#36712;&#36857;&#65292;&#21487;&#20197;&#20026;&#20010;&#24615;&#21270;&#24739;&#32773;&#21382;&#21490;&#21305;&#37197;&#19988;&#38024;&#23545;&#26368;&#20339;&#26410;&#26469;&#25928;&#26524;&#30340;&#26032;&#22411;&#22810;&#21464;&#37327;&#27835;&#30103;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26694;&#26550;&#65292;&#23558;&#28145;&#24230;&#29983;&#25104;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#19982;&#20915;&#31574;&#29702;&#35770;&#30456;&#32467;&#21512;&#65292;&#29992;&#20110;&#29983;&#25104;&#20010;&#24615;&#21270;&#30340;&#27835;&#30103;&#31574;&#30053;&#12290;&#23427;&#21033;&#29992;&#21382;&#21490;&#24739;&#32773;&#36712;&#36857;&#25968;&#25454;&#65292;&#36890;&#36807;&#28145;&#24230;&#29983;&#25104;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#20849;&#21516;&#23398;&#20064;&#29983;&#25104;&#36924;&#30495;&#30340;&#20010;&#24615;&#21270;&#27835;&#30103;&#21644;&#26410;&#26469;&#32467;&#26524;&#36712;&#36857;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#26681;&#25454;&#26465;&#20214;&#21270;&#26399;&#26395;&#25928;&#29992;&#26368;&#22823;&#21270;&#35757;&#32451;&#29983;&#25104;&#19982;&#20010;&#24615;&#21270;&#24739;&#32773;&#21382;&#21490;&#21305;&#37197;&#19988;&#38024;&#23545;&#26368;&#20339;&#26410;&#26469;&#25928;&#26524;&#30340;&#26032;&#22411;&#22810;&#21464;&#37327;&#27835;&#30103;&#31574;&#30053;&#12290;&#25105;&#20204;&#36890;&#36807;&#20026;&#20303;&#38498;&#31958;&#23615;&#30149;&#24739;&#32773;&#29983;&#25104;&#20010;&#24615;&#21270;&#30340;&#33008;&#23707;&#32032;&#27835;&#30103;&#31574;&#30053;&#21644;&#34880;&#31958;&#39044;&#27979;&#26469;&#23637;&#31034;&#25105;&#20204;&#30340;&#26694;&#26550;&#65292;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#29983;&#25104;&#25913;&#36827;&#30340;&#20010;&#24615;&#21270;&#27835;&#30103;&#31574;&#30053;&#26041;&#38754;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel framework that combines deep generative time series models with decision theory for generating personalized treatment strategies. It leverages historical patient trajectory data to jointly learn the generation of realistic personalized treatment and future outcome trajectories through deep generative time series models. In particular, our framework enables the generation of novel multivariate treatment strategies tailored to the personalized patient history and trained for optimal expected future outcomes based on conditional expected utility maximization. We demonstrate our framework by generating personalized insulin treatment strategies and blood glucose predictions for hospitalized diabetes patients, showcasing the potential of our approach for generating improved personalized treatment strategies. Keywords: deep generative model, probabilistic decision support, personalized treatment generation, insulin and blood glucose prediction
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;Clifford&#30340;&#20960;&#20309;&#20195;&#25968;&#21644;&#20984;&#20248;&#21270;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#26512;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#20248;&#26435;&#37325;&#21487;&#20197;&#36890;&#36807;&#35757;&#32451;&#26679;&#26412;&#30340;&#26964;&#31215;&#26469;&#33719;&#24471;&#65292;&#24182;&#19988;&#35757;&#32451;&#38382;&#39064;&#21487;&#20197;&#31616;&#21270;&#20026;&#23545;&#26964;&#31215;&#29305;&#24449;&#36827;&#34892;&#20984;&#20248;&#21270;&#65292;&#20174;&#32780;&#25581;&#31034;&#20102;&#31070;&#32463;&#32593;&#32476;&#20869;&#37096;&#30340;&#20960;&#20309;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2309.16512</link><description>&lt;p&gt;
&#20174;&#22797;&#26434;&#21040;&#28165;&#26224;&#65306;&#36890;&#36807;Clifford&#30340;&#20960;&#20309;&#20195;&#25968;&#21644;&#20984;&#20248;&#21270;&#30340;&#20998;&#26512;&#34920;&#36798;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#26435;&#37325;
&lt;/p&gt;
&lt;p&gt;
From Complexity to Clarity: Analytical Expressions of Deep Neural Network Weights via Clifford's Geometric Algebra and Convexity. (arXiv:2309.16512v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16512
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;Clifford&#30340;&#20960;&#20309;&#20195;&#25968;&#21644;&#20984;&#20248;&#21270;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#26512;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#20248;&#26435;&#37325;&#21487;&#20197;&#36890;&#36807;&#35757;&#32451;&#26679;&#26412;&#30340;&#26964;&#31215;&#26469;&#33719;&#24471;&#65292;&#24182;&#19988;&#35757;&#32451;&#38382;&#39064;&#21487;&#20197;&#31616;&#21270;&#20026;&#23545;&#26964;&#31215;&#29305;&#24449;&#36827;&#34892;&#20984;&#20248;&#21270;&#65292;&#20174;&#32780;&#25581;&#31034;&#20102;&#31070;&#32463;&#32593;&#32476;&#20869;&#37096;&#30340;&#20960;&#20309;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#20960;&#20309;&#65288;Clifford&#65289;&#20195;&#25968;&#21644;&#20984;&#20248;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#20998;&#26512;&#26041;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#24403;&#20351;&#29992;&#26631;&#20934;&#27491;&#21017;&#21270;&#25439;&#22833;&#36827;&#34892;&#35757;&#32451;&#26102;&#65292;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#20248;&#26435;&#37325;&#30001;&#35757;&#32451;&#26679;&#26412;&#30340;&#26964;&#31215;&#32473;&#20986;&#12290;&#27492;&#22806;&#65292;&#35757;&#32451;&#38382;&#39064;&#21487;&#31616;&#21270;&#20026;&#23545;&#26964;&#31215;&#29305;&#24449;&#36827;&#34892;&#20984;&#20248;&#21270;&#65292;&#22312;&#20854;&#20013;&#32534;&#30721;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#20960;&#20309;&#32467;&#26500;&#12290;&#35813;&#32467;&#26500;&#20197;&#25968;&#25454;&#21521;&#37327;&#29983;&#25104;&#30340;&#19977;&#35282;&#24418;&#21644;&#24179;&#34892;&#20307;&#30340;&#26377;&#31526;&#21495;&#20307;&#31215;&#34920;&#31034;&#12290;&#20984;&#38382;&#39064;&#36890;&#36807;$\ell_1$&#27491;&#21017;&#21270;&#25214;&#21040;&#26679;&#26412;&#30340;&#19968;&#20010;&#23567;&#23376;&#38598;&#65292;&#20197;&#21457;&#29616;&#20165;&#30456;&#20851;&#30340;&#26964;&#31215;&#29305;&#24449;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#25552;&#20379;&#20102;&#23545;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20869;&#37096;&#24037;&#20316;&#26426;&#21046;&#30340;&#26032;&#35270;&#35282;&#65292;&#24182;&#25581;&#31034;&#20102;&#38544;&#34255;&#23618;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we introduce a novel analysis of neural networks based on geometric (Clifford) algebra and convex optimization. We show that optimal weights of deep ReLU neural networks are given by the wedge product of training samples when trained with standard regularized loss. Furthermore, the training problem reduces to convex optimization over wedge product features, which encode the geometric structure of the training dataset. This structure is given in terms of signed volumes of triangles and parallelotopes generated by data vectors. The convex problem finds a small subset of samples via $\ell_1$ regularization to discover only relevant wedge product features. Our analysis provides a novel perspective on the inner workings of deep neural networks and sheds light on the role of the hidden layers.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36164;&#20135;&#25414;&#32465;-&#39044;&#27979;-&#35843;&#25972;&#65288;BPR&#65289;&#26694;&#26550;&#65292;&#23558;&#36164;&#20135;&#25414;&#32465;&#12289;&#26426;&#22120;&#23398;&#20064;&#21644;&#39044;&#27979;&#21327;&#35843;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#20197;&#23454;&#29616;&#23545;&#39118;&#30005;&#21151;&#29575;&#30340;&#20934;&#30830;&#39044;&#27979;&#21644;&#19968;&#33268;&#24615;&#35843;&#25972;&#12290;</title><link>http://arxiv.org/abs/2309.16492</link><description>&lt;p&gt;
&#39118;&#30005;&#21151;&#29575;&#39044;&#27979;&#30340;&#36164;&#20135;&#25414;&#32465;
&lt;/p&gt;
&lt;p&gt;
Asset Bundling for Wind Power Forecasting. (arXiv:2309.16492v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16492
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36164;&#20135;&#25414;&#32465;-&#39044;&#27979;-&#35843;&#25972;&#65288;BPR&#65289;&#26694;&#26550;&#65292;&#23558;&#36164;&#20135;&#25414;&#32465;&#12289;&#26426;&#22120;&#23398;&#20064;&#21644;&#39044;&#27979;&#21327;&#35843;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#20197;&#23454;&#29616;&#23545;&#39118;&#30005;&#21151;&#29575;&#30340;&#20934;&#30830;&#39044;&#27979;&#21644;&#19968;&#33268;&#24615;&#35843;&#25972;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32654;&#22269;&#30005;&#32593;&#20013;&#38388;&#26029;&#24615;&#21487;&#20877;&#29983;&#33021;&#28304;&#30340;&#19981;&#26029;&#22686;&#21152;&#65292;&#29305;&#21035;&#26159;&#39118;&#33021;&#21644;&#22826;&#38451;&#33021;&#21457;&#30005;&#65292;&#23548;&#33268;&#36816;&#33829;&#19981;&#30830;&#23450;&#24615;&#22686;&#21152;&#12290;&#22312;&#36825;&#31181;&#32972;&#26223;&#19979;&#65292;&#20934;&#30830;&#30340;&#39044;&#27979;&#38750;&#24120;&#37325;&#35201;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#39118;&#33021;&#21457;&#30005;&#65292;&#30001;&#20110;&#20854;&#21464;&#21270;&#24133;&#24230;&#22823;&#19988;&#21382;&#21490;&#19978;&#38590;&#20197;&#39044;&#27979;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#19968;&#25361;&#25112;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#36164;&#20135;&#25414;&#32465;-&#39044;&#27979;-&#35843;&#25972;&#65288;BPR&#65289;&#26694;&#26550;&#65292;&#23558;&#36164;&#20135;&#25414;&#32465;&#12289;&#26426;&#22120;&#23398;&#20064;&#21644;&#39044;&#27979;&#21327;&#35843;&#25216;&#26415;&#30456;&#32467;&#21512;&#12290;BPR&#26694;&#26550;&#39318;&#20808;&#23398;&#20064;&#20013;&#38388;&#30340;&#23618;&#27425;&#32467;&#26500;&#65288;&#25414;&#32465;&#65289;&#65292;&#28982;&#21518;&#39044;&#27979;&#36164;&#20135;&#12289;&#25414;&#32465;&#21644;&#25972;&#20010;&#39118;&#30005;&#22330;&#30340;&#39118;&#30005;&#21151;&#29575;&#65292;&#26368;&#21518;&#35843;&#25972;&#25152;&#26377;&#39044;&#27979;&#32467;&#26524;&#20197;&#30830;&#20445;&#19968;&#33268;&#24615;&#12290;&#36825;&#31181;&#26041;&#27861;&#26377;&#25928;&#22320;&#24341;&#20837;&#20102;&#19968;&#20010;&#36741;&#21161;&#23398;&#20064;&#20219;&#21153;&#65288;&#39044;&#27979;&#25414;&#32465;&#23618;&#27425;&#30340;&#26102;&#38388;&#24207;&#21015;&#65289;&#65292;&#20197;&#24110;&#21161;&#20027;&#35201;&#30340;&#23398;&#20064;&#20219;&#21153;&#12290;&#26412;&#25991;&#36824;&#20171;&#32461;&#20102;&#33021;&#22815;&#25429;&#25417;&#39118;&#30005;&#26102;&#38388;&#24207;&#21015;&#30340;&#26102;&#31354;&#21160;&#24577;&#30340;&#26032;&#30340;&#36164;&#20135;&#25414;&#32465;&#26631;&#20934;&#12290;&#36827;&#34892;&#20102;&#22823;&#37327;&#30340;&#25968;&#20540;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
The growing penetration of intermittent, renewable generation in US power grids, especially wind and solar generation, results in increased operational uncertainty. In that context, accurate forecasts are critical, especially for wind generation, which exhibits large variability and is historically harder to predict. To overcome this challenge, this work proposes a novel Bundle-Predict-Reconcile (BPR) framework that integrates asset bundling, machine learning, and forecast reconciliation techniques. The BPR framework first learns an intermediate hierarchy level (the bundles), then predicts wind power at the asset, bundle, and fleet level, and finally reconciles all forecasts to ensure consistency. This approach effectively introduces an auxiliary learning task (predicting the bundle-level time series) to help the main learning tasks. The paper also introduces new asset-bundling criteria that capture the spatio-temporal dynamics of wind power time series. Extensive numerical experiments
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#39640;&#32500;&#24230;&#21644;&#37325;&#23614;&#24178;&#25200;&#26465;&#20214;&#19979;&#30340;&#40065;&#26834;&#22238;&#24402;&#20272;&#35745;&#22120;&#30340;&#24615;&#36136;&#65292;&#36890;&#36807;&#30740;&#31350;&#19968;&#31867;&#26925;&#22278;&#21327;&#21464;&#37327;&#21644;&#22122;&#22768;&#25968;&#25454;&#20998;&#24067;&#30340;M-&#20272;&#35745;&#22120;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;&#23384;&#22312;&#37325;&#23614;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#65292;Huber&#25439;&#22833;&#38656;&#35201;&#36827;&#19968;&#27493;&#27491;&#21017;&#21270;&#25165;&#33021;&#36798;&#21040;&#26368;&#20248;&#24615;&#33021;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#25512;&#23548;&#20986;&#20102;&#23725;&#22238;&#24402;&#30340;&#36229;&#39069;&#39118;&#38505;&#30340;&#34928;&#20943;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2309.16476</link><description>&lt;p&gt;
&#39640;&#32500;&#24230;&#19979;&#37325;&#23614;&#25968;&#25454;&#19979;&#30340;&#40065;&#26834;&#22238;&#24402;: &#28176;&#36817;&#24615;&#21644;&#26222;&#36866;&#24615;
&lt;/p&gt;
&lt;p&gt;
High-dimensional robust regression under heavy-tailed data: Asymptotics and Universality. (arXiv:2309.16476v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16476
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#39640;&#32500;&#24230;&#21644;&#37325;&#23614;&#24178;&#25200;&#26465;&#20214;&#19979;&#30340;&#40065;&#26834;&#22238;&#24402;&#20272;&#35745;&#22120;&#30340;&#24615;&#36136;&#65292;&#36890;&#36807;&#30740;&#31350;&#19968;&#31867;&#26925;&#22278;&#21327;&#21464;&#37327;&#21644;&#22122;&#22768;&#25968;&#25454;&#20998;&#24067;&#30340;M-&#20272;&#35745;&#22120;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;&#23384;&#22312;&#37325;&#23614;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#65292;Huber&#25439;&#22833;&#38656;&#35201;&#36827;&#19968;&#27493;&#27491;&#21017;&#21270;&#25165;&#33021;&#36798;&#21040;&#26368;&#20248;&#24615;&#33021;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#25512;&#23548;&#20986;&#20102;&#23725;&#22238;&#24402;&#30340;&#36229;&#39069;&#39118;&#38505;&#30340;&#34928;&#20943;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#21327;&#21464;&#37327;&#21644;&#21709;&#24212;&#20989;&#25968;&#37117;&#21463;&#37325;&#23614;&#24178;&#25200;&#30340;&#24773;&#20917;&#19979;&#65292;&#40065;&#26834;&#22238;&#24402;&#20272;&#35745;&#37327;&#30340;&#39640;&#32500;&#24615;&#36136;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#38024;&#23545;&#19968;&#31867;&#21253;&#21547;&#26925;&#22278;&#21327;&#21464;&#37327;&#21644;&#22122;&#22768;&#25968;&#25454;&#20998;&#24067;&#30340;M-&#20272;&#35745;&#22120;&#25552;&#20379;&#20102;&#38160;&#21033;&#30340;&#28176;&#36817;&#29305;&#24449;&#21270;&#65292;&#21253;&#25324;&#20108;&#38454;&#21450;&#20197;&#19978;&#30697;&#19981;&#23384;&#22312;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#23384;&#22312;&#37325;&#23614;&#22122;&#22768;&#30340;&#39640;&#32500;&#24773;&#20917;&#19979;&#65292;&#23613;&#31649;Huber&#25439;&#22833;&#36890;&#36807;&#26368;&#20248;&#35843;&#25972;&#30340;&#20301;&#32622;&#21442;&#25968;$\delta$&#26159;&#19968;&#33268;&#30340;&#65292;&#20294;&#20854;&#22312;&#24615;&#33021;&#19978;&#26159;&#27425;&#20248;&#30340;&#65292;&#31361;&#26174;&#20102;&#36827;&#19968;&#27493;&#27491;&#21017;&#21270;&#20197;&#36798;&#21040;&#26368;&#20248;&#24615;&#33021;&#30340;&#24517;&#35201;&#24615;&#12290;&#36825;&#20010;&#32467;&#26524;&#36824;&#25581;&#31034;&#20102;$\delta$&#20316;&#20026;&#26679;&#26412;&#22797;&#26434;&#24230;&#21644;&#27745;&#26579;&#30340;&#20989;&#25968;&#23384;&#22312;&#30340;&#19968;&#20010;&#26377;&#36259;&#30340;&#36716;&#21464;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25512;&#23548;&#20986;&#23725;&#22238;&#24402;&#20013;&#36229;&#39069;&#39118;&#38505;&#30340;&#34928;&#20943;&#36895;&#29575;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#23545;&#20110;&#20855;&#26377;&#26377;&#38480;&#20108;&#38454;&#30697;&#30340;&#22122;&#22768;&#20998;&#24067;&#65292;&#23725;&#22238;&#24402;&#19981;&#20165;&#26159;&#26368;&#20248;&#30340;&#65292;&#32780;&#19988;&#26159;&#26222;&#36866;&#30340;&#65292;&#20294;&#20854;&#34928;&#20943;&#36895;&#29575;&#21487;&#20197;&#26159;...
&lt;/p&gt;
&lt;p&gt;
We investigate the high-dimensional properties of robust regression estimators in the presence of heavy-tailed contamination of both the covariates and response functions. In particular, we provide a sharp asymptotic characterisation of M-estimators trained on a family of elliptical covariate and noise data distributions including cases where second and higher moments do not exist. We show that, despite being consistent, the Huber loss with optimally tuned location parameter $\delta$ is suboptimal in the high-dimensional regime in the presence of heavy-tailed noise, highlighting the necessity of further regularisation to achieve optimal performance. This result also uncovers the existence of a curious transition in $\delta$ as a function of the sample complexity and contamination. Moreover, we derive the decay rates for the excess risk of ridge regression. We show that, while it is both optimal and universal for noise distributions with finite second moment, its decay rate can be consi
&lt;/p&gt;</description></item><item><title>MPRS&#26159;&#19968;&#31181;&#35745;&#31639;&#39640;&#25928;&#12289;&#20855;&#26377;&#29289;&#29702;&#21551;&#21457;&#30340;&#31354;&#38388;&#22238;&#24402;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#36317;&#31163;&#30456;&#20851;&#30340;&#8220;&#30456;&#20114;&#20316;&#29992;&#8221;&#26469;&#24341;&#20837;&#31354;&#38388;&#25110;&#26102;&#38388;&#30456;&#20851;&#24615;&#65292;&#33021;&#22815;&#22788;&#29702;&#20219;&#24847;&#31354;&#38388;&#32500;&#24230;&#30340;&#20998;&#25955;&#25968;&#25454;&#12290;&#22312;&#21508;&#31181;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#30340;&#27979;&#35797;&#20013;&#65292;MPRS&#23637;&#29616;&#20102;&#19982;&#26631;&#20934;&#25554;&#20540;&#26041;&#27861;&#30456;&#24403;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#22635;&#34917;&#31895;&#31961;&#21644;&#38750;&#39640;&#26031;&#25968;&#25454;&#30340;&#32570;&#21475;&#12290;</title><link>http://arxiv.org/abs/2309.16448</link><description>&lt;p&gt;
&#19968;&#31181;&#31616;&#32422;&#12289;&#35745;&#31639;&#39640;&#25928;&#30340;&#31354;&#38388;&#22238;&#24402;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A parsimonious, computationally efficient machine learning method for spatial regression. (arXiv:2309.16448v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16448
&lt;/p&gt;
&lt;p&gt;
MPRS&#26159;&#19968;&#31181;&#35745;&#31639;&#39640;&#25928;&#12289;&#20855;&#26377;&#29289;&#29702;&#21551;&#21457;&#30340;&#31354;&#38388;&#22238;&#24402;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#36317;&#31163;&#30456;&#20851;&#30340;&#8220;&#30456;&#20114;&#20316;&#29992;&#8221;&#26469;&#24341;&#20837;&#31354;&#38388;&#25110;&#26102;&#38388;&#30456;&#20851;&#24615;&#65292;&#33021;&#22815;&#22788;&#29702;&#20219;&#24847;&#31354;&#38388;&#32500;&#24230;&#30340;&#20998;&#25955;&#25968;&#25454;&#12290;&#22312;&#21508;&#31181;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#30340;&#27979;&#35797;&#20013;&#65292;MPRS&#23637;&#29616;&#20102;&#19982;&#26631;&#20934;&#25554;&#20540;&#26041;&#27861;&#30456;&#24403;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#22635;&#34917;&#31895;&#31961;&#21644;&#38750;&#39640;&#26031;&#25968;&#25454;&#30340;&#32570;&#21475;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#25913;&#36827;&#30340;&#24179;&#38754;&#26059;&#36716;&#22120;&#26041;&#27861;&#65288;MPRS&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#21463;&#29289;&#29702;&#21551;&#21457;&#30340;&#29992;&#20110;&#31354;&#38388;/&#26102;&#38388;&#22238;&#24402;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#12290;MPRS&#26159;&#19968;&#20010;&#38750;&#21442;&#25968;&#27169;&#22411;&#65292;&#36890;&#36807;&#30701;&#31243;&#12289;&#36317;&#31163;&#30456;&#20851;&#30340;&#8220;&#30456;&#20114;&#20316;&#29992;&#8221;&#26469;&#24341;&#20837;&#31354;&#38388;&#25110;&#26102;&#38388;&#30456;&#20851;&#24615;&#65292;&#32780;&#19981;&#38656;&#35201;&#20551;&#35774;&#24213;&#23618;&#27010;&#29575;&#20998;&#24067;&#30340;&#29305;&#23450;&#24418;&#24335;&#12290;&#39044;&#27979;&#26159;&#36890;&#36807;&#23436;&#20840;&#33258;&#20027;&#30340;&#23398;&#20064;&#31639;&#27861;&#36827;&#34892;&#30340;&#65292;&#35813;&#31639;&#27861;&#20351;&#29992;&#24179;&#34913;&#26465;&#20214;&#30340;&#33945;&#29305;&#21345;&#32599;&#27169;&#25311;&#12290;MPRS&#33021;&#22815;&#22788;&#29702;&#20998;&#25955;&#30340;&#25968;&#25454;&#21644;&#20219;&#24847;&#30340;&#31354;&#38388;&#32500;&#24230;&#12290;&#25105;&#20204;&#22312;&#19968;&#32500;&#12289;&#20108;&#32500;&#21644;&#19977;&#32500;&#19978;&#23545;&#21508;&#31181;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#27979;&#35797;&#32467;&#26524;&#34920;&#26126;MPRS&#30340;&#39044;&#27979;&#24615;&#33021;&#65288;&#26080;&#38656;&#21442;&#25968;&#35843;&#25972;&#65289;&#19982;&#26222;&#36890;&#20811;&#37324;&#37329;&#27861;&#21644;&#36870;&#36317;&#31163;&#21152;&#26435;&#27861;&#31561;&#26631;&#20934;&#25554;&#20540;&#26041;&#27861;&#30456;&#24403;&#12290;&#29305;&#21035;&#26159;&#65292;MPRS&#26159;&#19968;&#31181;&#29305;&#21035;&#26377;&#25928;&#30340;&#22635;&#34917;&#32570;&#21475;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#31895;&#31961;&#21644;&#38750;&#39640;&#26031;&#25968;&#25454;&#65288;&#22914;&#27599;&#26085;&#38477;&#27700;&#26102;&#38388;&#24207;&#21015;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce the modified planar rotator method (MPRS), a physically inspired machine learning method for spatial/temporal regression. MPRS is a non-parametric model which incorporates spatial or temporal correlations via short-range, distance-dependent ``interactions'' without assuming a specific form for the underlying probability distribution. Predictions are obtained by means of a fully autonomous learning algorithm which employs equilibrium conditional Monte Carlo simulations. MPRS is able to handle scattered data and arbitrary spatial dimensions. We report tests on various synthetic and real-word data in one, two and three dimensions which demonstrate that the MPRS prediction performance (without parameter tuning) is competitive with standard interpolation methods such as ordinary kriging and inverse distance weighting. In particular, MPRS is a particularly effective gap-filling method for rough and non-Gaussian data (e.g., daily precipitation time series). MPRS shows superior co
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#26816;&#39564;&#32473;&#23450;&#26465;&#20214;&#26041;&#24046;&#30340;&#20551;&#35774;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#36873;&#25321;&#24615;&#38750;&#21442;&#25968;&#22238;&#24402;&#26041;&#27861;&#65292;&#20801;&#35768;&#32771;&#34385;&#26041;&#24046;&#26412;&#36523;&#30340;&#20540;&#20197;&#21450;&#23545;&#24212;&#26041;&#24046;&#39044;&#27979;&#22120;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#20272;&#35745;&#22120;&#30340;&#39118;&#38505;&#30340;&#38750;&#28176;&#36817;&#30028;&#12290;</title><link>http://arxiv.org/abs/2309.16412</link><description>&lt;p&gt;
&#36890;&#36807;&#26816;&#39564;&#36827;&#34892;&#36873;&#25321;&#24615;&#38750;&#21442;&#25968;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Selective Nonparametric Regression via Testing. (arXiv:2309.16412v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16412
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26816;&#39564;&#32473;&#23450;&#26465;&#20214;&#26041;&#24046;&#30340;&#20551;&#35774;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#36873;&#25321;&#24615;&#38750;&#21442;&#25968;&#22238;&#24402;&#26041;&#27861;&#65292;&#20801;&#35768;&#32771;&#34385;&#26041;&#24046;&#26412;&#36523;&#30340;&#20540;&#20197;&#21450;&#23545;&#24212;&#26041;&#24046;&#39044;&#27979;&#22120;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#20272;&#35745;&#22120;&#30340;&#39118;&#38505;&#30340;&#38750;&#28176;&#36817;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20855;&#26377;&#35823;&#24046;&#25935;&#24863;&#30340;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#65292;&#39044;&#27979;&#20013;&#30340;&#25918;&#24323;&#21487;&#33021;&#24615;&#65288;&#25110;&#36873;&#25321;&#24615;&#39044;&#27979;&#65289;&#26159;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#12290;&#34429;&#28982;&#20998;&#31867;&#35774;&#32622;&#20013;&#24471;&#21040;&#20102;&#24191;&#27867;&#30740;&#31350;&#65292;&#20294;&#23545;&#20110;&#22238;&#24402;&#38382;&#39064;&#30340;&#36873;&#25321;&#24615;&#26041;&#27861;&#21457;&#23637;&#36739;&#23569;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#38750;&#21442;&#25968;&#24322;&#26041;&#24046;&#22238;&#24402;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#26816;&#39564;&#32473;&#23450;&#28857;&#22788;&#26465;&#20214;&#26041;&#24046;&#30340;&#20551;&#35774;&#26469;&#24320;&#21457;&#19968;&#20010;&#25918;&#24323;&#31243;&#24207;&#12290;&#19982;&#29616;&#26377;&#26041;&#27861;&#19981;&#21516;&#65292;&#25552;&#20986;&#30340;&#26041;&#27861;&#19981;&#20165;&#20801;&#35768;&#32771;&#34385;&#26041;&#24046;&#26412;&#36523;&#30340;&#20540;&#65292;&#36824;&#20801;&#35768;&#32771;&#34385;&#23545;&#24212;&#26041;&#24046;&#39044;&#27979;&#22120;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#24471;&#20272;&#35745;&#22120;&#30340;&#39118;&#38505;&#30340;&#38750;&#28176;&#36817;&#30028;&#65292;&#24182;&#23637;&#31034;&#20102;&#20960;&#31181;&#19981;&#21516;&#25910;&#25947;&#27169;&#24335;&#30340;&#23384;&#22312;&#12290;&#29702;&#35770;&#20998;&#26512;&#19982;&#19968;&#31995;&#21015;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#19978;&#30340;&#23454;&#39564;&#19968;&#36215;&#36827;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;
Prediction with the possibility of abstention (or selective prediction) is an important problem for error-critical machine learning applications. While well-studied in the classification setup, selective approaches to regression are much less developed. In this work, we consider the nonparametric heteroskedastic regression problem and develop an abstention procedure via testing the hypothesis on the value of the conditional variance at a given point. Unlike existing methods, the proposed one allows to account not only for the value of the variance itself but also for the uncertainty of the corresponding variance predictor. We prove non-asymptotic bounds on the risk of the resulting estimator and show the existence of several different convergence regimes. Theoretical analysis is illustrated with a series of experiments on simulated and real-world data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#27809;&#26377;&#22343;&#20540;&#20114;&#25442;&#24615;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#26500;&#24314;&#21512;&#25104;&#27835;&#30103;&#32452;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#28304;&#32676;&#20307;&#30340;&#27835;&#30103;&#32452;&#21152;&#26435;&#28151;&#21512;&#26469;&#26500;&#24314;&#30446;&#26631;&#20154;&#32676;&#30340;&#21512;&#25104;&#27835;&#30103;&#32452;&#65292;&#24182;&#36890;&#36807;&#26368;&#23567;&#21270;&#26465;&#20214;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#26469;&#20272;&#35745;&#26435;&#37325;&#12290;&#35813;&#26041;&#27861;&#22312;&#22343;&#20540;&#20114;&#25442;&#24615;&#20551;&#35774;&#34987;&#36829;&#21453;&#26102;&#21487;&#20197;&#20316;&#20026;&#19968;&#31181;&#26032;&#39062;&#30340;&#34917;&#20805;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2309.16409</link><description>&lt;p&gt;
&#22312;&#27809;&#26377;&#22343;&#20540;&#20114;&#25442;&#24615;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#26500;&#24314;&#21512;&#25104;&#27835;&#30103;&#32452;
&lt;/p&gt;
&lt;p&gt;
Constructing Synthetic Treatment Groups without the Mean Exchangeability Assumption. (arXiv:2309.16409v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16409
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#27809;&#26377;&#22343;&#20540;&#20114;&#25442;&#24615;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#26500;&#24314;&#21512;&#25104;&#27835;&#30103;&#32452;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#28304;&#32676;&#20307;&#30340;&#27835;&#30103;&#32452;&#21152;&#26435;&#28151;&#21512;&#26469;&#26500;&#24314;&#30446;&#26631;&#20154;&#32676;&#30340;&#21512;&#25104;&#27835;&#30103;&#32452;&#65292;&#24182;&#36890;&#36807;&#26368;&#23567;&#21270;&#26465;&#20214;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#26469;&#20272;&#35745;&#26435;&#37325;&#12290;&#35813;&#26041;&#27861;&#22312;&#22343;&#20540;&#20114;&#25442;&#24615;&#20551;&#35774;&#34987;&#36829;&#21453;&#26102;&#21487;&#20197;&#20316;&#20026;&#19968;&#31181;&#26032;&#39062;&#30340;&#34917;&#20805;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30340;&#30446;&#30340;&#26159;&#23558;&#22810;&#20010;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#30340;&#20449;&#24687;&#20256;&#36882;&#32473;&#25105;&#20204;&#20165;&#26377;&#25511;&#21046;&#32452;&#25968;&#25454;&#30340;&#30446;&#26631;&#20154;&#32676;&#12290;&#20197;&#21069;&#30340;&#24037;&#20316;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#20381;&#36182;&#20110;&#22343;&#20540;&#20114;&#25442;&#24615;&#30340;&#20551;&#35774;&#12290;&#28982;&#32780;&#65292;&#27491;&#22914;&#35768;&#22810;&#29616;&#26377;&#30740;&#31350;&#25152;&#25351;&#20986;&#30340;&#65292;&#22343;&#20540;&#20114;&#25442;&#24615;&#20551;&#35774;&#21487;&#33021;&#34987;&#36829;&#21453;&#12290;&#21463;&#21512;&#25104;&#25511;&#21046;&#26041;&#27861;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#36890;&#36807;&#23545;&#28304;&#32676;&#20307;&#30340;&#27835;&#30103;&#32452;&#21152;&#26435;&#28151;&#21512;&#26500;&#24314;&#20102;&#30446;&#26631;&#20154;&#32676;&#30340;&#21512;&#25104;&#27835;&#30103;&#32452;&#12290;&#25105;&#20204;&#36890;&#36807;&#26368;&#23567;&#21270;&#28304;&#32676;&#20307;&#30340;&#21152;&#26435;&#23545;&#29031;&#32452;&#19982;&#30446;&#26631;&#20154;&#32676;&#20043;&#38388;&#30340;&#26465;&#20214;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#26469;&#20272;&#35745;&#26435;&#37325;&#12290;&#25105;&#20204;&#22522;&#20110;&#31579;&#36873;&#21322;&#21442;&#25968;&#29702;&#35770;&#24314;&#31435;&#20102;&#21512;&#25104;&#27835;&#30103;&#32452;&#20272;&#35745;&#37327;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;&#24403;&#22343;&#20540;&#20114;&#25442;&#24615;&#20551;&#35774;&#34987;&#36829;&#21453;&#26102;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#20316;&#20026;&#19968;&#31181;&#26032;&#39062;&#30340;&#34917;&#20805;&#26041;&#27861;&#12290;&#22312;&#21512;&#25104;&#21644;&#29616;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The purpose of this work is to transport the information from multiple randomized controlled trials to the target population where we only have the control group data. Previous works rely critically on the mean exchangeability assumption. However, as pointed out by many current studies, the mean exchangeability assumption might be violated. Motivated by the synthetic control method, we construct a synthetic treatment group for the target population by a weighted mixture of treatment groups of source populations. We estimate the weights by minimizing the conditional maximum mean discrepancy between the weighted control groups of source populations and the target population. We establish the asymptotic normality of the synthetic treatment group estimator based on the sieve semiparametric theory. Our method can serve as a novel complementary approach when the mean exchangeability assumption is violated. Experiments are conducted on synthetic and real-world datasets to demonstrate the effe
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#32508;&#36848;&#20171;&#32461;&#20102;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;BNNs&#65289;&#30340;&#22522;&#26412;&#27010;&#24565;&#21644;&#20854;&#22312;&#35299;&#20915;&#31070;&#32463;&#32593;&#32476;&#23616;&#38480;&#24615;&#26041;&#38754;&#30340;&#37325;&#35201;&#24615;&#12290;&#30446;&#26631;&#35835;&#32773;&#21253;&#25324;&#20855;&#22791;&#36125;&#21494;&#26031;&#26041;&#27861;&#32972;&#26223;&#20294;&#32570;&#20047;&#28145;&#24230;&#23398;&#20064;&#19987;&#19994;&#30693;&#35782;&#30340;&#32479;&#35745;&#23398;&#23478;&#65292;&#20197;&#21450;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#19987;&#19994;&#20294;&#23545;&#36125;&#21494;&#26031;&#32479;&#35745;&#23398;&#26377;&#38480;&#20102;&#35299;&#30340;&#26426;&#22120;&#23398;&#20064;&#19987;&#23478;&#12290;</title><link>http://arxiv.org/abs/2309.16314</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65306;&#32508;&#36848;&#21644;&#35752;&#35770;&#30340;&#20837;&#38376;&#25351;&#21335;
&lt;/p&gt;
&lt;p&gt;
A Primer on Bayesian Neural Networks: Review and Debates. (arXiv:2309.16314v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16314
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#32508;&#36848;&#20171;&#32461;&#20102;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;BNNs&#65289;&#30340;&#22522;&#26412;&#27010;&#24565;&#21644;&#20854;&#22312;&#35299;&#20915;&#31070;&#32463;&#32593;&#32476;&#23616;&#38480;&#24615;&#26041;&#38754;&#30340;&#37325;&#35201;&#24615;&#12290;&#30446;&#26631;&#35835;&#32773;&#21253;&#25324;&#20855;&#22791;&#36125;&#21494;&#26031;&#26041;&#27861;&#32972;&#26223;&#20294;&#32570;&#20047;&#28145;&#24230;&#23398;&#20064;&#19987;&#19994;&#30693;&#35782;&#30340;&#32479;&#35745;&#23398;&#23478;&#65292;&#20197;&#21450;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#19987;&#19994;&#20294;&#23545;&#36125;&#21494;&#26031;&#32479;&#35745;&#23398;&#26377;&#38480;&#20102;&#35299;&#30340;&#26426;&#22120;&#23398;&#20064;&#19987;&#23478;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#22312;&#21508;&#20010;&#38382;&#39064;&#39046;&#22495;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#24615;&#33021;&#65292;&#20294;&#20854;&#24191;&#27867;&#24212;&#29992;&#21463;&#21040;&#20102;&#22266;&#26377;&#23616;&#38480;&#30340;&#38480;&#21046;&#65292;&#22914;&#36807;&#20110;&#33258;&#20449;&#30340;&#39044;&#27979;&#12289;&#32570;&#20047;&#21487;&#35299;&#37322;&#24615;&#20197;&#21450;&#23481;&#26131;&#21463;&#21040;&#23545;&#25239;&#25915;&#20987;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;BNNs&#65289;&#20316;&#20026;&#20256;&#32479;&#31070;&#32463;&#32593;&#32476;&#30340;&#19968;&#20010;&#24341;&#20154;&#27880;&#30446;&#30340;&#25193;&#23637;&#65292;&#23558;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#25972;&#21512;&#21040;&#20854;&#39044;&#27979;&#33021;&#21147;&#20013;&#12290;&#26412;&#31687;&#32508;&#36848;&#24615;&#20837;&#38376;&#25351;&#21335;&#31995;&#32479;&#20171;&#32461;&#20102;&#31070;&#32463;&#32593;&#32476;&#21644;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#22522;&#26412;&#27010;&#24565;&#65292;&#38416;&#26126;&#20102;&#23427;&#20204;&#22312;BNNs&#24320;&#21457;&#20013;&#30340;&#21327;&#21516;&#25972;&#21512;&#12290;&#30446;&#26631;&#35835;&#32773;&#21253;&#25324;&#20855;&#22791;&#36125;&#21494;&#26031;&#26041;&#27861;&#32972;&#26223;&#20294;&#32570;&#20047;&#28145;&#24230;&#23398;&#20064;&#19987;&#19994;&#30693;&#35782;&#30340;&#32479;&#35745;&#23398;&#23478;&#65292;&#20197;&#21450;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#19987;&#19994;&#20294;&#23545;&#36125;&#21494;&#26031;&#32479;&#35745;&#23398;&#26377;&#38480;&#20102;&#35299;&#30340;&#26426;&#22120;&#23398;&#20064;&#19987;&#23478;&#12290;&#25105;&#20204;&#27010;&#36848;&#20102;&#24120;&#29992;&#30340;&#20808;&#39564;&#30693;&#35782;&#65292;&#32771;&#23519;&#20102;&#23427;&#20204;&#23545;&#27169;&#22411;&#34892;&#20026;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural networks have achieved remarkable performance across various problem domains, but their widespread applicability is hindered by inherent limitations such as overconfidence in predictions, lack of interpretability, and vulnerability to adversarial attacks. To address these challenges, Bayesian neural networks (BNNs) have emerged as a compelling extension of conventional neural networks, integrating uncertainty estimation into their predictive capabilities.  This comprehensive primer presents a systematic introduction to the fundamental concepts of neural networks and Bayesian inference, elucidating their synergistic integration for the development of BNNs. The target audience comprises statisticians with a potential background in Bayesian methods but lacking deep learning expertise, as well as machine learners proficient in deep neural networks but with limited exposure to Bayesian statistics. We provide an overview of commonly employed priors, examining their impact on model beh
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;&#39640;&#32500;&#25968;&#25454;&#37197;&#23545;&#26679;&#26412;&#30340;&#20551;&#35774;&#26816;&#39564;&#26694;&#26550;&#65292;&#36890;&#36807;&#22402;&#30452;&#24179;&#20998;&#32447;&#29983;&#25104;&#35780;&#20998;&#20989;&#25968;&#65292;&#24182;&#21033;&#29992;&#20266;&#20013;&#20301;&#25968;&#27714;&#24471;&#26368;&#20248;&#35780;&#20998;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2309.16274</link><description>&lt;p&gt;
&#39640;&#32500;&#25968;&#25454;&#37197;&#23545;&#26679;&#26412;&#20551;&#35774;&#26816;&#39564;&#30340;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A framework for paired-sample hypothesis testing for high-dimensional data. (arXiv:2309.16274v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16274
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38024;&#23545;&#39640;&#32500;&#25968;&#25454;&#37197;&#23545;&#26679;&#26412;&#30340;&#20551;&#35774;&#26816;&#39564;&#26694;&#26550;&#65292;&#36890;&#36807;&#22402;&#30452;&#24179;&#20998;&#32447;&#29983;&#25104;&#35780;&#20998;&#20989;&#25968;&#65292;&#24182;&#21033;&#29992;&#20266;&#20013;&#20301;&#25968;&#27714;&#24471;&#26368;&#20248;&#35780;&#20998;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22810;&#32500;&#25968;&#25454;&#30340;&#37197;&#23545;&#26679;&#26412;&#26816;&#39564;&#20013;&#65292;&#26631;&#20934;&#30340;&#26041;&#27861;&#26159;&#23545;&#27599;&#20010;&#29305;&#24449;&#24212;&#29992;&#22810;&#20010;&#21333;&#21464;&#37327;&#26816;&#39564;&#65292;&#28982;&#21518;&#36827;&#34892;p&#20540;&#35843;&#25972;&#12290;&#28982;&#32780;&#65292;&#24403;&#25968;&#25454;&#21547;&#26377;&#22823;&#37327;&#29305;&#24449;&#26102;&#65292;&#36825;&#31181;&#26041;&#27861;&#23384;&#22312;&#38382;&#39064;&#12290;&#24050;&#26377;&#19968;&#20123;&#30740;&#31350;&#34920;&#26126;&#65292;&#20998;&#31867;&#20934;&#30830;&#29575;&#21487;&#20197;&#20316;&#20026;&#21452;&#26679;&#26412;&#26816;&#39564;&#30340;&#20195;&#29702;&#12290;&#28982;&#32780;&#65292;&#36804;&#20170;&#20026;&#27490;&#23578;&#26410;&#25552;&#20986;&#29702;&#35770;&#22522;&#30784;&#25110;&#23454;&#38469;&#26041;&#27861;&#26469;&#23558;&#36825;&#31181;&#31574;&#30053;&#25193;&#23637;&#21040;&#22810;&#32500;&#37197;&#23545;&#26679;&#26412;&#26816;&#39564;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24819;&#27861;&#65292;&#21363;&#36890;&#36807;&#27599;&#23545;&#23454;&#20363;&#36830;&#25509;&#32447;&#27573;&#30340;&#22402;&#30452;&#24179;&#20998;&#32447;&#23450;&#20041;&#30340;&#20915;&#31574;&#35268;&#21017;&#26469;&#29983;&#25104;&#35780;&#20998;&#20989;&#25968;&#12290;&#28982;&#21518;&#65292;&#36890;&#36807;&#36825;&#20123;&#35268;&#21017;&#30340;&#20266;&#20013;&#20301;&#25968;&#26469;&#20272;&#35745;&#26368;&#20248;&#35780;&#20998;&#20989;&#25968;&#65292;&#25105;&#20204;&#36890;&#36807;&#33258;&#28982;&#22320;&#25193;&#23637;Hodges-Lehmann&#20272;&#35745;&#37327;&#26469;&#36827;&#34892;&#20272;&#35745;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#27493;&#26816;&#39564;&#36807;&#31243;&#30340;&#26694;&#26550;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#20272;&#35745;&#27599;&#20010;&#29305;&#24449;&#30340;&#24179;&#20998;&#32447;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#26681;&#25454;&#36825;&#20123;&#24179;&#20998;&#32447;&#23450;&#20041;&#35780;&#20998;&#20989;&#25968;&#65292;&#24182;&#36890;&#36807;&#20266;&#20013;&#20301;&#25968;&#27714;&#24471;&#26368;&#20248;&#35780;&#20998;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
The standard paired-sample testing approach in the multidimensional setting applies multiple univariate tests on the individual features, followed by p-value adjustments. Such an approach suffers when the data carry numerous features. A number of studies have shown that classification accuracy can be seen as a proxy for two-sample testing. However, neither theoretical foundations nor practical recipes have been proposed so far on how this strategy could be extended to multidimensional paired-sample testing. In this work, we put forward the idea that scoring functions can be produced by the decision rules defined by the perpendicular bisecting hyperplanes of the line segments connecting each pair of instances. Then, the optimal scoring function can be obtained by the pseudomedian of those rules, which we estimate by extending naturally the Hodges-Lehmann estimator. We accordingly propose a framework of a two-step testing procedure. First, we estimate the bisecting hyperplanes for each p
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24341;&#20837;&#22810;&#26679;&#24046;&#24322;&#32422;&#26463;&#25512;&#24191;&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;&#65288;DPO&#65289;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#28040;&#38500;&#20102;&#23545;&#20272;&#35745;&#26041;&#27861;&#30340;&#38656;&#35201;&#24182;&#31616;&#21270;&#20102;&#22870;&#21169;&#21644;&#26368;&#20248;&#31574;&#30053;&#20043;&#38388;&#30340;&#22797;&#26434;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2309.16240</link><description>&lt;p&gt;
&#36229;&#36234;&#36870;KL&#65306;&#36890;&#36807;&#22810;&#26679;&#30340;&#24046;&#24322;&#32422;&#26463;&#25512;&#24191;&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Beyond Reverse KL: Generalizing Direct Preference Optimization with Diverse Divergence Constraints. (arXiv:2309.16240v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16240
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24341;&#20837;&#22810;&#26679;&#24046;&#24322;&#32422;&#26463;&#25512;&#24191;&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;&#65288;DPO&#65289;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#28040;&#38500;&#20102;&#23545;&#20272;&#35745;&#26041;&#27861;&#30340;&#38656;&#35201;&#24182;&#31616;&#21270;&#20102;&#22870;&#21169;&#21644;&#26368;&#20248;&#31574;&#30053;&#20043;&#38388;&#30340;&#22797;&#26434;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#19981;&#26029;&#22686;&#24378;&#33021;&#21147;&#20026;&#20154;&#24037;&#26234;&#33021;&#25552;&#20379;&#20102;&#26426;&#20250;&#65292;&#20294;&#21516;&#26102;&#20063;&#25918;&#22823;&#20102;&#23433;&#20840;&#38382;&#39064;&#65292;&#22914;AI&#31995;&#32479;&#30340;&#28508;&#22312;&#28389;&#29992;&#65292;&#36825;&#38656;&#35201;&#26377;&#25928;&#30340;AI&#23545;&#40784;&#12290;&#22522;&#20110;&#20154;&#31867;&#21453;&#39304;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288;RLHF&#65289;&#24050;&#32463;&#25104;&#20026;AI&#23545;&#40784;&#30340;&#19968;&#26465;&#26377;&#24076;&#26395;&#30340;&#36335;&#24452;&#65292;&#20294;&#30001;&#20110;&#20854;&#22797;&#26434;&#24615;&#21644;&#23545;&#29420;&#31435;&#22870;&#21169;&#27169;&#22411;&#30340;&#20381;&#36182;&#24615;&#32780;&#24102;&#26469;&#20102;&#25361;&#25112;&#12290;&#30452;&#25509;&#20559;&#22909;&#20248;&#21270;&#65288;DPO&#65289;&#34987;&#25552;&#20986;&#20316;&#20026;&#19968;&#31181;&#26367;&#20195;&#26041;&#27861;&#65292;&#22312;&#36870;KL&#27491;&#21017;&#21270;&#32422;&#26463;&#19979;&#31561;&#21516;&#20110;RLHF&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;f-DPO&#65292;&#19968;&#31181;&#36890;&#36807;&#25972;&#21512;&#22810;&#26679;&#30340;&#24046;&#24322;&#32422;&#26463;&#26469;&#25512;&#24191;DPO&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#26576;&#20123;f-&#25955;&#24230;&#19979;&#65292;&#21253;&#25324;Jensen-Shannon&#25955;&#24230;&#12289;&#27491;&#21521;KL&#25955;&#24230;&#21644;&#945;-&#25955;&#24230;&#65292;&#22870;&#21169;&#21644;&#26368;&#20248;&#31574;&#30053;&#20043;&#38388;&#30340;&#22797;&#26434;&#20851;&#31995;&#20063;&#21487;&#20197;&#36890;&#36807;&#35299;&#20915;Karush-Kuhn-Tucker&#26465;&#20214;&#26469;&#31616;&#21270;&#12290;&#36825;&#28040;&#38500;&#20102;&#23545;&#20272;&#35745;&#26041;&#27861;&#30340;&#38656;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
The increasing capabilities of large language models (LLMs) raise opportunities for artificial general intelligence but concurrently amplify safety concerns, such as potential misuse of AI systems, necessitating effective AI alignment. Reinforcement Learning from Human Feedback (RLHF) has emerged as a promising pathway towards AI alignment but brings forth challenges due to its complexity and dependence on a separate reward model. Direct Preference Optimization (DPO) has been proposed as an alternative, and it remains equivalent to RLHF under the reverse KL regularization constraint. This paper presents $f$-DPO, a generalized approach to DPO by incorporating diverse divergence constraints. We show that under certain $f$-divergences, including Jensen-Shannon divergence, forward KL divergences and $\alpha$-divergences, the complex relationship between the reward and optimal policy can also be simplified by addressing the Karush-Kuhn-Tucker conditions. This eliminates the need for estimat
&lt;/p&gt;</description></item><item><title>Stackelberg&#25209;&#37327;&#31574;&#30053;&#23398;&#20064;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#38543;&#26426;&#26799;&#24230;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#37319;&#29992;&#21338;&#24328;&#35770;&#30340;&#35266;&#28857;&#65292;&#23545;&#31574;&#30053;&#23398;&#20064;&#36827;&#34892;&#24314;&#27169;&#65292;&#24182;&#32771;&#34385;&#20102;&#20248;&#21270;&#26223;&#35266;&#20013;&#30340;&#20998;&#23618;&#20915;&#31574;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2309.16188</link><description>&lt;p&gt;
Stackelberg&#25209;&#37327;&#31574;&#30053;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Stackelberg Batch Policy Learning. (arXiv:2309.16188v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16188
&lt;/p&gt;
&lt;p&gt;
Stackelberg&#25209;&#37327;&#31574;&#30053;&#23398;&#20064;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#38543;&#26426;&#26799;&#24230;&#30340;&#23398;&#20064;&#31639;&#27861;&#65292;&#37319;&#29992;&#21338;&#24328;&#35770;&#30340;&#35266;&#28857;&#65292;&#23545;&#31574;&#30053;&#23398;&#20064;&#36827;&#34892;&#24314;&#27169;&#65292;&#24182;&#32771;&#34385;&#20102;&#20248;&#21270;&#26223;&#35266;&#20013;&#30340;&#20998;&#23618;&#20915;&#31574;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25209;&#37327;&#24378;&#21270;&#23398;&#20064;&#23450;&#20041;&#20102;&#20174;&#22266;&#23450;&#30340;&#25968;&#25454;&#25209;&#27425;&#20013;&#36827;&#34892;&#23398;&#20064;&#65292;&#32570;&#20047;&#35814;&#23613;&#30340;&#25506;&#32034;&#12290;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#26368;&#20248;&#31639;&#27861;&#20351;&#29992;&#32463;&#39564;&#25968;&#25454;&#26469;&#26657;&#20934;&#20215;&#20540;&#20989;&#25968;&#27169;&#22411;&#65292;&#24182;&#22312;&#23398;&#20064;&#27169;&#22411;&#19979;&#25191;&#34892;&#26576;&#31181;&#24754;&#35266;&#35780;&#20272;&#65292;&#24050;&#32463;&#25104;&#20026;&#25209;&#37327;&#24378;&#21270;&#23398;&#20064;&#20013;&#19968;&#31181;&#26377;&#21069;&#26223;&#30340;&#33539;&#24335;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#36825;&#20010;&#27969;&#27966;&#30340;&#29616;&#20195;&#30740;&#31350;&#36890;&#24120;&#24573;&#35270;&#20102;&#20248;&#21270;&#26223;&#35266;&#20013;&#38544;&#34255;&#30340;&#20998;&#23618;&#20915;&#31574;&#32467;&#26500;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#37319;&#29992;&#21338;&#24328;&#35770;&#30340;&#35266;&#28857;&#65292;&#23558;&#31574;&#30053;&#23398;&#20064;&#22270;&#34920;&#24314;&#27169;&#20026;&#20855;&#26377;&#39046;&#23548;&#32773;-&#36319;&#38543;&#32773;&#32467;&#26500;&#30340;&#20004;&#20154;&#38646;&#21644;&#21338;&#24328;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22522;&#20110;&#38543;&#26426;&#26799;&#24230;&#30340;&#23398;&#20064;&#31639;&#27861;&#65306;StackelbergLearner&#65292;&#39046;&#23548;&#32773;&#26681;&#25454;&#20854;&#30446;&#26631;&#30340;&#20840;&#23548;&#25968;&#36827;&#34892;&#26356;&#26032;&#65292;&#32780;&#19981;&#26159;&#36890;&#24120;&#30340;&#20010;&#20307;&#26799;&#24230;&#65292;&#32780;&#36319;&#38543;&#32773;&#36827;&#34892;&#20010;&#20307;&#26356;&#26032;&#24182;&#30830;&#20445;&#36807;&#28193;&#19968;&#33268;&#30340;&#24754;&#35266;&#25512;&#29702;&#12290;&#25512;&#23548;&#20986;&#30340;&#23398;&#20064;&#21160;&#21147;
&lt;/p&gt;
&lt;p&gt;
Batch reinforcement learning (RL) defines the task of learning from a fixed batch of data lacking exhaustive exploration. Worst-case optimality algorithms, which calibrate a value-function model class from logged experience and perform some type of pessimistic evaluation under the learned model, have emerged as a promising paradigm for batch RL. However, contemporary works on this stream have commonly overlooked the hierarchical decision-making structure hidden in the optimization landscape. In this paper, we adopt a game-theoretical viewpoint and model the policy learning diagram as a two-player general-sum game with a leader-follower structure. We propose a novel stochastic gradient-based learning algorithm: StackelbergLearner, in which the leader player updates according to the total derivative of its objective instead of the usual individual gradient, and the follower player makes individual updates and ensures transition-consistent pessimistic reasoning. The derived learning dynam
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29983;&#25104;&#22522;&#30784;&#27169;&#22411;&#29983;&#25104;&#30340;&#21512;&#25104;&#26679;&#26412;&#36827;&#34892;&#21322;&#30417;&#30563;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#26088;&#22312;&#35299;&#20915;&#23454;&#38469;&#24212;&#29992;&#20013;&#26080;&#27861;&#33719;&#21462;&#22823;&#35268;&#27169;&#26080;&#26631;&#31614;&#25968;&#25454;&#38598;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.16143</link><description>&lt;p&gt;
&#22522;&#20110;&#20803;&#20248;&#21270;&#21512;&#25104;&#26679;&#26412;&#30340;&#29983;&#25104;&#24335;&#21322;&#30417;&#30563;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Generative Semi-supervised Learning with Meta-Optimized Synthetic Samples. (arXiv:2309.16143v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16143
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29983;&#25104;&#22522;&#30784;&#27169;&#22411;&#29983;&#25104;&#30340;&#21512;&#25104;&#26679;&#26412;&#36827;&#34892;&#21322;&#30417;&#30563;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#26088;&#22312;&#35299;&#20915;&#23454;&#38469;&#24212;&#29992;&#20013;&#26080;&#27861;&#33719;&#21462;&#22823;&#35268;&#27169;&#26080;&#26631;&#31614;&#25968;&#25454;&#38598;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21322;&#30417;&#30563;&#23398;&#20064;&#26159;&#20351;&#29992;&#26377;&#26631;&#31614;&#21644;&#26080;&#26631;&#31614;&#25968;&#25454;&#38598;&#26469;&#35757;&#32451;&#28145;&#24230;&#20998;&#31867;&#27169;&#22411;&#30340;&#19968;&#31181;&#26377;&#21069;&#26223;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#20381;&#36182;&#20110;&#22823;&#35268;&#27169;&#30340;&#26080;&#26631;&#31614;&#25968;&#25454;&#38598;&#65292;&#22312;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#20013;&#30001;&#20110;&#27861;&#24459;&#38480;&#21046;&#65288;&#20363;&#22914;&#65292;GDPR&#65289;&#21487;&#33021;&#26080;&#27861;&#33719;&#21462;&#12290;&#26412;&#25991;&#30740;&#31350;&#19968;&#20010;&#38382;&#39064;&#65306;&#25105;&#20204;&#33021;&#21542;&#22312;&#27809;&#26377;&#23454;&#38469;&#26080;&#26631;&#31614;&#25968;&#25454;&#38598;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;&#21322;&#30417;&#30563;&#23398;&#20064;&#27169;&#22411;&#65311;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20174;&#21253;&#21547;&#25968;&#30334;&#19975;&#26679;&#26412;&#30340;&#22810;&#26679;&#39046;&#22495;&#25968;&#25454;&#38598;&#65288;&#20363;&#22914;ImageNet&#65289;&#35757;&#32451;&#30340;&#29983;&#25104;&#22522;&#30784;&#27169;&#22411;&#29983;&#25104;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#24605;&#24819;&#26159;&#35782;&#21035;&#29983;&#25104;&#22522;&#30784;&#27169;&#22411;&#20013;&#20223;&#30495;&#26080;&#26631;&#31614;&#26679;&#26412;&#30340;&#21512;&#25104;&#26679;&#26412;&#65292;&#24182;&#20351;&#29992;&#36825;&#20123;&#21512;&#25104;&#26679;&#26412;&#26469;&#35757;&#32451;&#20998;&#31867;&#22120;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#28857;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#34987;&#26500;&#24314;&#20026;&#19968;&#20010;&#20132;&#26367;&#20248;&#21270;&#38382;&#39064;&#65306;&#65288;i&#65289;&#20803;&#23398;&#20064;&#29983;&#25104;&#22522;&#30784;&#27169;&#22411;&#21644;&#65288;ii&#65289;&#20351;&#29992;&#30495;&#23454;&#26631;&#35760;&#26679;&#26412;&#21644;&#21512;&#25104;&#26679;&#26412;&#36827;&#34892;&#21322;&#30417;&#30563;&#23398;&#20064;&#30340;&#20998;&#31867;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Semi-supervised learning (SSL) is a promising approach for training deep classification models using labeled and unlabeled datasets. However, existing SSL methods rely on a large unlabeled dataset, which may not always be available in many real-world applications due to legal constraints (e.g., GDPR). In this paper, we investigate the research question: Can we train SSL models without real unlabeled datasets? Instead of using real unlabeled datasets, we propose an SSL method using synthetic datasets generated from generative foundation models trained on datasets containing millions of samples in diverse domains (e.g., ImageNet). Our main concepts are identifying synthetic samples that emulate unlabeled samples from generative foundation models and training classifiers using these synthetic samples. To achieve this, our method is formulated as an alternating optimization problem: (i) meta-learning of generative foundation models and (ii) SSL of classifiers using real labeled and synthet
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#38750;&#23545;&#27604;&#23398;&#20064;&#20013;&#30340;&#21160;&#21147;&#23849;&#28291;&#38382;&#39064;&#65292;&#21457;&#29616;&#29305;&#24449;&#24402;&#19968;&#21270;&#21487;&#20197;&#38450;&#27490;&#27492;&#38382;&#39064;&#30340;&#20986;&#29616;&#65292;&#20026;&#35299;&#20915;&#33258;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#30340;&#35745;&#31639;&#25928;&#29575;&#25552;&#20379;&#20102;&#26032;&#30340;&#24605;&#36335;&#12290;</title><link>http://arxiv.org/abs/2309.16109</link><description>&lt;p&gt;
&#29305;&#24449;&#24402;&#19968;&#21270;&#38450;&#27490;&#38750;&#23545;&#27604;&#23398;&#20064;&#21160;&#21147;&#30340;&#23849;&#28291;
&lt;/p&gt;
&lt;p&gt;
Feature Normalization Prevents Collapse of Non-contrastive Learning Dynamics. (arXiv:2309.16109v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16109
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#38750;&#23545;&#27604;&#23398;&#20064;&#20013;&#30340;&#21160;&#21147;&#23849;&#28291;&#38382;&#39064;&#65292;&#21457;&#29616;&#29305;&#24449;&#24402;&#19968;&#21270;&#21487;&#20197;&#38450;&#27490;&#27492;&#38382;&#39064;&#30340;&#20986;&#29616;&#65292;&#20026;&#35299;&#20915;&#33258;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#30340;&#35745;&#31639;&#25928;&#29575;&#25552;&#20379;&#20102;&#26032;&#30340;&#24605;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#27604;&#23398;&#20064;&#26159;&#19968;&#31181;&#33258;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#25968;&#25454;&#22686;&#24378;&#29983;&#25104;&#30340;&#20004;&#20010;&#27491;&#35270;&#22270;&#22312;&#25968;&#25454;&#34920;&#31034;&#31354;&#38388;&#20013;&#36890;&#36807;&#21560;&#24341;&#21147;&#20351;&#23427;&#20204;&#30456;&#20284;&#65292;&#32780;&#36890;&#36807;&#25490;&#26021;&#21147;&#20351;&#23427;&#20204;&#36828;&#31163;&#36127;&#26679;&#26412;&#12290;&#38750;&#23545;&#27604;&#23398;&#20064;&#36890;&#36807;BYOL&#21644;SimSiam&#31561;&#25163;&#27573;&#21435;&#38500;&#20102;&#36127;&#26679;&#26412;&#65292;&#24182;&#25552;&#39640;&#20102;&#35745;&#31639;&#25928;&#29575;&#12290;&#34429;&#28982;&#30001;&#20110;&#32570;&#20047;&#25490;&#26021;&#21147;&#65292;&#23398;&#21040;&#30340;&#34920;&#31034;&#21487;&#33021;&#20250;&#23849;&#28291;&#25104;&#19968;&#20010;&#21333;&#28857;&#65292;&#20294;&#30000;&#31561;&#20154;&#65288;2021&#65289;&#36890;&#36807;&#23398;&#20064;&#21160;&#21147;&#20998;&#26512;&#25581;&#31034;&#65292;&#22914;&#26524;&#25968;&#25454;&#22686;&#24378;&#36275;&#22815;&#24378;&#20110;&#27491;&#21017;&#21270;&#65292;&#21017;&#34920;&#31034;&#21487;&#20197;&#36991;&#20813;&#23849;&#28291;&#12290;&#28982;&#32780;&#65292;&#20182;&#20204;&#30340;&#20998;&#26512;&#27809;&#26377;&#32771;&#34385;&#24120;&#29992;&#30340;&#29305;&#24449;&#24402;&#19968;&#21270;&#65292;&#21363;&#22312;&#34913;&#37327;&#34920;&#31034;&#30456;&#20284;&#24615;&#20043;&#21069;&#36827;&#34892;&#30340;&#24402;&#19968;&#21270;&#25805;&#20316;&#65292;&#22240;&#27492;&#36807;&#24378;&#30340;&#27491;&#21017;&#21270;&#21487;&#33021;&#20250;&#23548;&#33268;&#21160;&#21147;&#23849;&#28291;&#65292;&#36825;&#22312;&#29305;&#24449;&#24402;&#19968;&#21270;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#26159;&#19981;&#33258;&#28982;&#30340;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
Contrastive learning is a self-supervised representation learning framework, where two positive views generated through data augmentation are made similar by an attraction force in a data representation space, while a repulsive force makes them far from negative examples. Non-contrastive learning, represented by BYOL and SimSiam, further gets rid of negative examples and improves computational efficiency. While learned representations may collapse into a single point due to the lack of the repulsive force at first sight, Tian et al. (2021) revealed through the learning dynamics analysis that the representations can avoid collapse if data augmentation is sufficiently stronger than regularization. However, their analysis does not take into account commonly-used feature normalization, a normalizer before measuring the similarity of representations, and hence excessively strong regularization may collapse the dynamics, which is an unnatural behavior under the presence of feature normalizat
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#23545;&#21327;&#21464;&#37327;&#35843;&#25972;&#30340;&#21453;&#20107;&#23454;&#27835;&#30103;&#26041;&#26696;&#21709;&#24212;&#26354;&#32447;&#36827;&#34892;&#20272;&#35745;&#65292;&#36890;&#36807;&#25552;&#20986;&#21453;&#27010;&#29575;&#21152;&#26435;&#30340;&#20272;&#35745;&#22120;&#26469;&#24179;&#28369;&#26354;&#32447;&#20989;&#25968;&#65292;&#24182;&#32473;&#20986;&#20102;&#32622;&#20449;&#21306;&#38388;&#21644;&#25910;&#25947;&#24615;&#35777;&#26126;&#12290;</title><link>http://arxiv.org/abs/2309.16099</link><description>&lt;p&gt;
&#19968;&#31181;&#23545;&#21327;&#21464;&#37327;&#35843;&#25972;&#30340;&#21453;&#20107;&#23454;&#27835;&#30103;&#26041;&#26696;&#21709;&#24212;&#26354;&#32447;&#30340;&#38750;&#21442;&#25968;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Nonparametric estimation of a covariate-adjusted counterfactual treatment regimen response curve. (arXiv:2309.16099v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16099
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#23545;&#21327;&#21464;&#37327;&#35843;&#25972;&#30340;&#21453;&#20107;&#23454;&#27835;&#30103;&#26041;&#26696;&#21709;&#24212;&#26354;&#32447;&#36827;&#34892;&#20272;&#35745;&#65292;&#36890;&#36807;&#25552;&#20986;&#21453;&#27010;&#29575;&#21152;&#26435;&#30340;&#20272;&#35745;&#22120;&#26469;&#24179;&#28369;&#26354;&#32447;&#20989;&#25968;&#65292;&#24182;&#32473;&#20986;&#20102;&#32622;&#20449;&#21306;&#38388;&#21644;&#25910;&#25947;&#24615;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28789;&#27963;&#20272;&#35745;&#27835;&#30103;&#26041;&#26696;&#19979;&#30340;&#24179;&#22343;&#32467;&#26524;&#65288;&#21363;&#20215;&#20540;&#20989;&#25968;&#65289;&#26159;&#20010;&#24615;&#21270;&#21307;&#23398;&#30340;&#20851;&#38190;&#27493;&#39588;&#12290;&#25105;&#20204;&#23558;&#30446;&#26631;&#21442;&#25968;&#23450;&#20041;&#20026;&#32473;&#23450;&#19968;&#32452;&#22522;&#32447;&#21327;&#21464;&#37327;&#30340;&#26465;&#20214;&#20215;&#20540;&#20989;&#25968;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#22522;&#20110;&#20998;&#23618;&#30340;&#20215;&#20540;&#20989;&#25968;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#21322;&#21442;&#25968;&#21270;&#20915;&#31574;&#35268;&#21017;&#30340;&#31867;&#21035;&#65292;&#24182;&#22312;&#35813;&#31867;&#21035;&#20013;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31579;&#36873;&#30340;&#38750;&#21442;&#25968;&#21327;&#21464;&#37327;&#35843;&#25972;&#26041;&#26696;&#21709;&#24212;&#26354;&#32447;&#20272;&#35745;&#22120;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#22312;&#22810;&#20010;&#26041;&#38754;&#26377;&#25152;&#36129;&#29486;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21453;&#27010;&#29575;&#21152;&#26435;&#30340;&#38750;&#21442;&#25968;&#39640;&#25928;&#20272;&#35745;&#22120;&#20197;&#24179;&#28369;&#30340;&#26041;&#26696;&#21709;&#24212;&#26354;&#32447;&#20989;&#25968;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#24178;&#25200;&#20989;&#25968;&#34987;&#36275;&#22815;&#22320;&#27424;&#24179;&#28369;&#26102;&#65292;&#28176;&#36817;&#32447;&#24615;&#24615;&#24471;&#20197;&#23454;&#29616;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#24130;&#27861;&#21644;&#26377;&#38480;&#26679;&#26412;&#20934;&#21017;&#20197;&#36827;&#34892;&#27424;&#24179;&#28369;&#12290;&#20854;&#27425;&#65292;&#21033;&#29992;&#39640;&#26031;&#36807;&#31243;&#29702;&#35770;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#23545;&#24179;&#28369;&#30340;&#26041;&#26696;&#21709;&#24212;&#26354;&#32447;&#20989;&#25968;&#30340;&#21516;&#26102;&#32622;&#20449;&#21306;&#38388;&#12290;&#31532;&#19977;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20248;&#21270;&#38382;&#39064;&#30340;&#19968;&#33268;&#24615;&#21644;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Flexible estimation of the mean outcome under a treatment regimen (i.e., value function) is the key step toward personalized medicine. We define our target parameter as a conditional value function given a set of baseline covariates which we refer to as a stratum based value function. We focus on semiparametric class of decision rules and propose a sieve based nonparametric covariate adjusted regimen-response curve estimator within that class. Our work contributes in several ways. First, we propose an inverse probability weighted nonparametrically efficient estimator of the smoothed regimen-response curve function. We show that asymptotic linearity is achieved when the nuisance functions are undersmoothed sufficiently. Asymptotic and finite sample criteria for undersmoothing are proposed. Second, using Gaussian process theory, we propose simultaneous confidence intervals for the smoothed regimen-response curve function. Third, we provide consistency and convergence rate for the optimiz
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#19968;&#31181;&#26032;&#39062;&#30340;&#36830;&#32493;&#26102;&#38388;&#21551;&#21457;&#24335;&#31639;&#27861;&#65292;&#25552;&#39640;&#20102;&#33258;&#36866;&#24212;&#22312;&#32447;&#23398;&#20064;&#30340;&#25928;&#26524;&#65292;&#23558;&#26799;&#24230;&#26041;&#24046;&#30340;&#20381;&#36182;&#24615;&#20174;&#27425;&#20248;&#30340;$O(\sqrt{V_T\log V_T})$&#25913;&#36827;&#21040;&#26368;&#20248;&#36895;&#29575;$O(\sqrt{V_T})$&#65292;&#24182;&#21487;&#36866;&#29992;&#20110;&#26410;&#30693;Lipschitz&#24120;&#25968;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2309.16044</link><description>&lt;p&gt;
&#25913;&#36827;&#30340;&#31934;&#32454;&#31163;&#25955;&#21270;&#26041;&#27861;&#25552;&#39640;&#33258;&#36866;&#24212;&#22312;&#32447;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Improving Adaptive Online Learning Using Refined Discretization. (arXiv:2309.16044v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16044
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#19968;&#31181;&#26032;&#39062;&#30340;&#36830;&#32493;&#26102;&#38388;&#21551;&#21457;&#24335;&#31639;&#27861;&#65292;&#25552;&#39640;&#20102;&#33258;&#36866;&#24212;&#22312;&#32447;&#23398;&#20064;&#30340;&#25928;&#26524;&#65292;&#23558;&#26799;&#24230;&#26041;&#24046;&#30340;&#20381;&#36182;&#24615;&#20174;&#27425;&#20248;&#30340;$O(\sqrt{V_T\log V_T})$&#25913;&#36827;&#21040;&#26368;&#20248;&#36895;&#29575;$O(\sqrt{V_T})$&#65292;&#24182;&#21487;&#36866;&#29992;&#20110;&#26410;&#30693;Lipschitz&#24120;&#25968;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;Lipschitz&#25439;&#22833;&#30340;&#38750;&#32422;&#26463;&#22312;&#32447;&#32447;&#24615;&#20248;&#21270;&#38382;&#39064;&#12290;&#30446;&#26631;&#26159;&#21516;&#26102;&#36798;&#21040;&#65288;i&#65289;&#20108;&#38454;&#26799;&#24230;&#33258;&#36866;&#24212;&#24615;&#65307;&#21644;&#65288;ii&#65289;&#27604;&#36739;&#22120;&#33539;&#25968;&#33258;&#36866;&#24212;&#24615;&#65292;&#20063;&#34987;&#31216;&#20026;&#25991;&#29486;&#20013;&#30340;&#8220;&#21442;&#25968;&#33258;&#30001;&#24615;&#8221;&#12290;&#29616;&#26377;&#30340;&#36951;&#25022;&#30028;&#65288;Cutkosky&#21644;Orabona&#65292;2018&#65307;Mhammedi&#21644;Koolen&#65292;2020&#65307;Jacobsen&#21644;Cutkosky&#65292;2022&#65289;&#23545;&#20110;&#26799;&#24230;&#26041;&#24046;$V_T$&#26377;&#27425;&#20248;&#30340;$O(\sqrt{V_T\log V_T})$&#20381;&#36182;&#24615;&#65292;&#32780;&#26412;&#24037;&#20316;&#21033;&#29992;&#19968;&#31181;&#26032;&#39062;&#30340;&#36830;&#32493;&#26102;&#38388;&#21551;&#21457;&#24335;&#31639;&#27861;&#23558;&#20854;&#25913;&#36827;&#20026;&#26368;&#20248;&#36895;&#29575;$O(\sqrt{V_T})$&#65292;&#32780;&#26080;&#38656;&#20219;&#20309;&#19981;&#20999;&#23454;&#38469;&#30340;&#21152;&#20493;&#25216;&#24039;&#12290;&#36825;&#19968;&#32467;&#26524;&#21487;&#20197;&#25512;&#24191;&#21040;&#26410;&#30693;Lipschitz&#24120;&#25968;&#30340;&#24773;&#20917;&#65292;&#28040;&#38500;&#20102;&#20808;&#21069;&#24037;&#20316;&#20013;&#30340;&#33539;&#22260;&#27604;&#29575;&#38382;&#39064;&#65288;Mhammedi&#21644;Koolen&#65292;2020&#65289;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#39318;&#20808;&#23637;&#31034;&#20102;&#22312;&#38382;&#39064;&#30340;&#36830;&#32493;&#26102;&#38388;&#31867;&#27604;&#20013;&#21487;&#20197;&#30456;&#24403;&#23481;&#26131;&#22320;&#23454;&#29616;&#30446;&#26631;&#30340;&#21516;&#26102;&#36866;&#24212;&#24615;&#65292;&#20854;&#20013;&#29615;&#22659;&#30001;&#20219;&#24847;&#36830;&#32493;&#21322;&#38808;&#24335;&#24314;&#27169;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#30340;&#20851;&#38190;&#21019;&#26032;&#26159;
&lt;/p&gt;
&lt;p&gt;
We study unconstrained Online Linear Optimization with Lipschitz losses. The goal is to simultaneously achieve ($i$) second order gradient adaptivity; and ($ii$) comparator norm adaptivity also known as "parameter freeness" in the literature. Existing regret bounds (Cutkosky and Orabona, 2018; Mhammedi and Koolen, 2020; Jacobsen and Cutkosky, 2022) have the suboptimal $O(\sqrt{V_T\log V_T})$ dependence on the gradient variance $V_T$, while the present work improves it to the optimal rate $O(\sqrt{V_T})$ using a novel continuous-time-inspired algorithm, without any impractical doubling trick. This result can be extended to the setting with unknown Lipschitz constant, eliminating the range ratio problem from prior works (Mhammedi and Koolen, 2020).  Concretely, we first show that the aimed simultaneous adaptivity can be achieved fairly easily in a continuous time analogue of the problem, where the environment is modeled by an arbitrary continuous semimartingale. Then, our key innovation 
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#31532;&#19968;&#20010;&#22312;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#22238;&#24402;&#38382;&#39064;&#20013;&#22788;&#29702;&#21152;&#27861;&#26080;&#24847;&#35782;&#22122;&#22768;&#30340;&#31639;&#27861;&#12290;&#31639;&#27861;&#30340;&#30446;&#26631;&#26159;&#36890;&#36807;&#26679;&#26412;&#35775;&#38382;&#26469;&#20934;&#30830;&#22320;&#24674;&#22797;&#21442;&#25968;&#21521;&#37327;&#65292;&#20351;&#24471;&#27169;&#22411;&#30340;&#39044;&#27979;&#19982;&#30495;&#23454;&#20540;&#30340;&#35823;&#24046;&#23613;&#21487;&#33021;&#23567;&#12290;</title><link>http://arxiv.org/abs/2309.11657</link><description>&lt;p&gt;
GLM&#22238;&#24402;&#19982;&#26080;&#24847;&#35782;&#25968;&#25454;&#25439;&#22351;
&lt;/p&gt;
&lt;p&gt;
GLM Regression with Oblivious Corruptions. (arXiv:2309.11657v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.11657
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#31532;&#19968;&#20010;&#22312;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#22238;&#24402;&#38382;&#39064;&#20013;&#22788;&#29702;&#21152;&#27861;&#26080;&#24847;&#35782;&#22122;&#22768;&#30340;&#31639;&#27861;&#12290;&#31639;&#27861;&#30340;&#30446;&#26631;&#26159;&#36890;&#36807;&#26679;&#26412;&#35775;&#38382;&#26469;&#20934;&#30830;&#22320;&#24674;&#22797;&#21442;&#25968;&#21521;&#37327;&#65292;&#20351;&#24471;&#27169;&#22411;&#30340;&#39044;&#27979;&#19982;&#30495;&#23454;&#20540;&#30340;&#35823;&#24046;&#23613;&#21487;&#33021;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#65288;GLMs&#65289;&#30340;&#22238;&#24402;&#38382;&#39064;&#20013;&#65292;&#23384;&#22312;&#21152;&#27861;&#26080;&#24847;&#35782;&#22122;&#22768;&#30340;&#31532;&#19968;&#20010;&#31639;&#27861;&#12290;&#25105;&#20204;&#20551;&#35774;&#25105;&#20204;&#26377;&#26679;&#26412;&#35775;&#38382;&#21040;&#30340;&#20363;&#23376;$(x, y)$&#65292;&#20854;&#20013;$y$&#26159;$g(w^* \cdot x)$&#30340;&#24102;&#22122;&#22768;&#27979;&#37327;&#20540;&#12290;&#29305;&#21035;&#22320;&#65292;&#22122;&#22768;&#26631;&#31614;&#30340;&#24418;&#24335;&#20026;$y = g(w^* \cdot x) + \xi + \epsilon$&#65292;&#20854;&#20013;$\xi$&#26159;&#19982;$x$&#29420;&#31435;&#25277;&#21462;&#30340;&#26080;&#24847;&#35782;&#22122;&#22768;&#28385;&#36275;$\Pr[\xi = 0] \geq o(1)$&#65292;&#32780;$\epsilon \sim \mathcal N(0, \sigma^2)$&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#20934;&#30830;&#22320;&#24674;&#22797;&#19968;&#20010;&#21442;&#25968;&#21521;&#37327;$w$&#65292;&#20351;&#24471;&#20989;&#25968;$g(w \cdot x)$&#19982;&#30495;&#23454;&#20540;$g(w^* \cdot x)$&#30456;&#27604;&#20855;&#26377;&#20219;&#24847;&#23567;&#30340;&#35823;&#24046;&#65292;&#32780;&#19981;&#26159;&#19982;&#22122;&#22768;&#27979;&#37327;$y$&#30456;&#27604;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#26368;&#19968;&#33324;&#30340;&#19982;&#20998;&#24067;&#26080;&#20851;&#30340;&#24773;&#20917;&#65292;&#20854;&#20013;&#35299;&#21487;&#33021;&#29978;&#33267;&#19981;&#21487;&#35782;&#21035;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#36820;&#22238;&#19968;&#20010;&#20934;&#30830;&#30340;&#20272;&#35745;&#65292;&#22914;&#26524;&#23427;&#26159;&#21487;&#35782;&#21035;&#30340;&#65292;&#21542;&#21017;
&lt;/p&gt;
&lt;p&gt;
We demonstrate the first algorithms for the problem of regression for generalized linear models (GLMs) in the presence of additive oblivious noise. We assume we have sample access to examples $(x, y)$ where $y$ is a noisy measurement of $g(w^* \cdot x)$. In particular, \new{the noisy labels are of the form} $y = g(w^* \cdot x) + \xi + \epsilon$, where $\xi$ is the oblivious noise drawn independently of $x$ \new{and satisfies} $\Pr[\xi = 0] \geq o(1)$, and $\epsilon \sim \mathcal N(0, \sigma^2)$. Our goal is to accurately recover a \new{parameter vector $w$ such that the} function $g(w \cdot x)$ \new{has} arbitrarily small error when compared to the true values $g(w^* \cdot x)$, rather than the noisy measurements $y$.  We present an algorithm that tackles \new{this} problem in its most general distribution-independent setting, where the solution may not \new{even} be identifiable. \new{Our} algorithm returns \new{an accurate estimate of} the solution if it is identifiable, and otherwise
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#22810;&#39033;&#24335;&#25968;&#37327;&#30340;&#26679;&#26412;&#21644;&#24046;&#20998;&#38544;&#31169;&#32422;&#26463;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#20197;&#20272;&#35745;&#39640;&#26031;&#28151;&#21512;&#29289;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#20010;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#32780;&#26080;&#38656;&#23545;GMMs&#20570;&#20219;&#20309;&#32467;&#26500;&#24615;&#20551;&#35774;&#12290;</title><link>http://arxiv.org/abs/2309.03847</link><description>&lt;p&gt;
&#39640;&#26031;&#28151;&#21512;&#29289;&#21487;&#20197;&#36890;&#36807;&#22810;&#39033;&#24335;&#25968;&#37327;&#30340;&#26679;&#26412;&#36827;&#34892;&#24046;&#20998;&#38544;&#31169;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Mixtures of Gaussians are Privately Learnable with a Polynomial Number of Samples. (arXiv:2309.03847v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03847
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#22810;&#39033;&#24335;&#25968;&#37327;&#30340;&#26679;&#26412;&#21644;&#24046;&#20998;&#38544;&#31169;&#32422;&#26463;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#20197;&#20272;&#35745;&#39640;&#26031;&#28151;&#21512;&#29289;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#20010;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#32780;&#26080;&#38656;&#23545;GMMs&#20570;&#20219;&#20309;&#32467;&#26500;&#24615;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#24046;&#20998;&#38544;&#31169;(DP)&#32422;&#26463;&#19979;&#20272;&#35745;&#39640;&#26031;&#28151;&#21512;&#29289;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;&#65292;&#20351;&#29992;$\tilde{O}(k^2 d^4 \log(1/\delta) / \alpha^2 \varepsilon)$&#20010;&#26679;&#26412;&#21363;&#21487;&#22312;&#28385;&#36275;$(\varepsilon, \delta)$-DP&#30340;&#26465;&#20214;&#19979;&#20272;&#35745;$k$&#20010;&#39640;&#26031;&#28151;&#21512;&#29289;&#65292;&#20351;&#20854;&#36798;&#21040;&#24635;&#21464;&#24046;&#36317;&#31163;$\alpha$&#12290;&#36825;&#26159;&#35813;&#38382;&#39064;&#30340;&#31532;&#19968;&#20010;&#26377;&#38480;&#26679;&#26412;&#22797;&#26434;&#24615;&#19978;&#38480;&#65292;&#32780;&#26080;&#38656;&#23545;GMMs&#20570;&#20219;&#20309;&#32467;&#26500;&#24615;&#20551;&#35774;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#23545;&#20110;&#20854;&#20182;&#20219;&#21153;&#21487;&#33021;&#20063;&#26377;&#29992;&#12290;&#22312;&#39640;&#23618;&#27425;&#19978;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#26524;&#19968;&#20010;&#20998;&#24067;&#31867;&#65288;&#27604;&#22914;&#39640;&#26031;&#20998;&#24067;&#65289;&#26159;&#65288;1&#65289;&#21487;&#21015;&#34920;&#35793;&#30721;&#30340;&#24182;&#19988;&#65288;2&#65289;&#22312;&#24635;&#21464;&#24046;&#36317;&#31163;&#26041;&#38754;&#20855;&#26377;&#8220;&#23616;&#37096;&#23567;&#8221;&#35206;&#30422;[ BKSW19]&#65292;&#21017;&#20854;&#28151;&#21512;&#29289;&#31867;&#26159;&#31169;&#23494;&#21487;&#23398;&#20064;&#30340;&#12290;&#35777;&#26126;&#32469;&#36807;&#20102;&#19968;&#20010;&#24050;&#30693;&#38556;&#30861;&#65292;&#34920;&#26126;&#19982;&#39640;&#26031;&#20998;&#24067;&#19981;&#21516;&#65292;GMMs&#19981;&#20855;&#26377;&#23616;&#37096;&#23567;&#30340;&#35206;&#30422;[AAL21]&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of estimating mixtures of Gaussians under the constraint of differential privacy (DP). Our main result is that $\tilde{O}(k^2 d^4 \log(1/\delta) / \alpha^2 \varepsilon)$ samples are sufficient to estimate a mixture of $k$ Gaussians up to total variation distance $\alpha$ while satisfying $(\varepsilon, \delta)$-DP. This is the first finite sample complexity upper bound for the problem that does not make any structural assumptions on the GMMs.  To solve the problem, we devise a new framework which may be useful for other tasks. On a high level, we show that if a class of distributions (such as Gaussians) is (1) list decodable and (2) admits a "locally small'' cover [BKSW19] with respect to total variation distance, then the class of its mixtures is privately learnable. The proof circumvents a known barrier indicating that, unlike Gaussians, GMMs do not admit a locally small cover [AAL21].
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20302;&#27425;&#22810;&#39033;&#24335;&#35745;&#31639;&#22270;&#35770;&#20272;&#35745;&#23384;&#22312;&#35745;&#31639;&#38556;&#30861;&#65292;&#20256;&#32479;&#30340;&#20248;&#21270;&#20272;&#35745;&#26041;&#27861;&#20855;&#26377;&#25351;&#25968;&#32423;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#32780;&#26368;&#20248;&#22810;&#39033;&#24335;&#26102;&#38388;&#20272;&#35745;&#22120;&#21482;&#33021;&#36798;&#21040;&#36739;&#24930;&#30340;&#20272;&#35745;&#38169;&#35823;&#29575;&#12290;</title><link>http://arxiv.org/abs/2308.15728</link><description>&lt;p&gt;
&#36890;&#36807;&#20302;&#27425;&#22810;&#39033;&#24335;&#35745;&#31639;&#22270;&#35770;&#20272;&#35745;&#30340;&#19979;&#30028;
&lt;/p&gt;
&lt;p&gt;
Computational Lower Bounds for Graphon Estimation via Low-degree Polynomials. (arXiv:2308.15728v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.15728
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20302;&#27425;&#22810;&#39033;&#24335;&#35745;&#31639;&#22270;&#35770;&#20272;&#35745;&#23384;&#22312;&#35745;&#31639;&#38556;&#30861;&#65292;&#20256;&#32479;&#30340;&#20248;&#21270;&#20272;&#35745;&#26041;&#27861;&#20855;&#26377;&#25351;&#25968;&#32423;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#32780;&#26368;&#20248;&#22810;&#39033;&#24335;&#26102;&#38388;&#20272;&#35745;&#22120;&#21482;&#33021;&#36798;&#21040;&#36739;&#24930;&#30340;&#20272;&#35745;&#38169;&#35823;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#35770;&#20272;&#35745;&#26159;&#32593;&#32476;&#20998;&#26512;&#20013;&#26368;&#22522;&#26412;&#30340;&#38382;&#39064;&#20043;&#19968;&#65292;&#22312;&#36807;&#21435;&#21313;&#24180;&#20013;&#21463;&#21040;&#20102;&#30456;&#24403;&#22823;&#30340;&#20851;&#27880;&#12290;&#20174;&#32479;&#35745;&#23398;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#39640;&#31561;&#25552;&#20986;&#20102;&#23545;&#20110;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;SBM&#65289;&#21644;&#38750;&#21442;&#25968;&#22270;&#35770;&#20272;&#35745;&#30340;&#22270;&#35770;&#20272;&#35745;&#30340;&#26497;&#23567;&#26497;&#24046;&#35823;&#24046;&#29575;&#12290;&#32479;&#35745;&#20248;&#21270;&#20272;&#35745;&#26159;&#22522;&#20110;&#32422;&#26463;&#26368;&#23567;&#20108;&#20056;&#27861;&#65292;&#24182;&#19988;&#22312;&#32500;&#24230;&#19978;&#20855;&#26377;&#25351;&#25968;&#32423;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;&#20174;&#35745;&#31639;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#24050;&#30693;&#30340;&#26368;&#20248;&#22810;&#39033;&#24335;&#26102;&#38388;&#20272;&#35745;&#22120;&#26159;&#22522;&#20110;&#36890;&#29992;&#22855;&#24322;&#20540;&#38408;&#20540;&#65288;USVT&#65289;&#65292;&#20294;&#26159;&#23427;&#21482;&#33021;&#36798;&#21040;&#27604;&#26497;&#23567;&#26497;&#24046;&#38169;&#35823;&#29575;&#24930;&#24471;&#22810;&#30340;&#20272;&#35745;&#38169;&#35823;&#29575;&#12290;&#20154;&#20204;&#33258;&#28982;&#20250;&#24819;&#30693;&#36947;&#36825;&#26679;&#30340;&#24046;&#36317;&#26159;&#21542;&#26159;&#24517;&#35201;&#30340;&#12290;USVT&#30340;&#35745;&#31639;&#20248;&#21270;&#24615;&#25110;&#22270;&#35770;&#20272;&#35745;&#20013;&#30340;&#35745;&#31639;&#38556;&#30861;&#30340;&#23384;&#22312;&#19968;&#30452;&#26159;&#19968;&#20010;&#38271;&#26399;&#23384;&#22312;&#30340;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23545;&#27492;&#36808;&#20986;&#20102;&#31532;&#19968;&#27493;&#65292;&#24182;&#20026;&#22270;&#35770;&#20272;&#35745;&#30340;&#35745;&#31639;&#38556;&#30861;&#25552;&#20379;&#20102;&#20005;&#26684;&#30340;&#35777;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graphon estimation has been one of the most fundamental problems in network analysis and has received considerable attention in the past decade. From the statistical perspective, the minimax error rate of graphon estimation has been established by Gao et al (2015) for both stochastic block model (SBM) and nonparametric graphon estimation. The statistical optimal estimators are based on constrained least squares and have computational complexity exponential in the dimension. From the computational perspective, the best-known polynomial-time estimator is based on universal singular value thresholding (USVT), but it can only achieve a much slower estimation error rate than the minimax one. It is natural to wonder if such a gap is essential. The computational optimality of the USVT or the existence of a computational barrier in graphon estimation has been a long-standing open problem. In this work, we take the first step towards it and provide rigorous evidence for the computational barrie
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25506;&#32034;&#20102;&#19968;&#31181;&#31070;&#32463;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#24403;&#21069;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#23384;&#22312;&#30340;&#21487;&#20449;&#24230;&#38382;&#39064;&#65292;&#21253;&#25324;&#39044;&#27979;&#32467;&#26524;&#35299;&#37322;&#19981;&#36275;&#12289;&#23398;&#20064;&#27169;&#22411;&#27867;&#21270;&#24615;&#19981;&#36275;&#21644;&#19981;&#36866;&#24212;&#19981;&#30830;&#23450;&#29615;&#22659;&#30340;&#38382;&#39064;&#65292;&#20197;&#25552;&#39640;&#21487;&#20449;&#24230;&#32593;&#32476;&#30340;&#35774;&#35745;&#32423;&#21487;&#35299;&#37322;&#24615;&#21644;&#27867;&#21270;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.03666</link><description>&lt;p&gt;
&#26550;&#36215;&#21487;&#20449;&#24230;&#19982;&#24320;&#25918;&#19990;&#30028;&#23398;&#20064;&#30340;&#26725;&#26753;&#65306;&#19968;&#31181;&#25506;&#32034;&#24615;&#31070;&#32463;&#26041;&#27861;&#65292;&#29992;&#20110;&#22686;&#24378;&#21487;&#35299;&#37322;&#24615;&#12289;&#27867;&#21270;&#24615;&#21644;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Bridging Trustworthiness and Open-World Learning: An Exploratory Neural Approach for Enhancing Interpretability, Generalization, and Robustness. (arXiv:2308.03666v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.03666
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25506;&#32034;&#20102;&#19968;&#31181;&#31070;&#32463;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#24403;&#21069;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#23384;&#22312;&#30340;&#21487;&#20449;&#24230;&#38382;&#39064;&#65292;&#21253;&#25324;&#39044;&#27979;&#32467;&#26524;&#35299;&#37322;&#19981;&#36275;&#12289;&#23398;&#20064;&#27169;&#22411;&#27867;&#21270;&#24615;&#19981;&#36275;&#21644;&#19981;&#36866;&#24212;&#19981;&#30830;&#23450;&#29615;&#22659;&#30340;&#38382;&#39064;&#65292;&#20197;&#25552;&#39640;&#21487;&#20449;&#24230;&#32593;&#32476;&#30340;&#35774;&#35745;&#32423;&#21487;&#35299;&#37322;&#24615;&#21644;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#30740;&#31350;&#20154;&#21592;&#21162;&#21147;&#32553;&#23567;&#26426;&#22120;&#26234;&#33021;&#19982;&#20154;&#31867;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#36890;&#36807;&#21457;&#23637;&#20154;&#24037;&#26234;&#33021;&#25216;&#26415;&#65292;&#25105;&#20204;&#24517;&#39035;&#35748;&#35782;&#21040;&#21487;&#20449;&#24230;&#22312;&#24320;&#25918;&#19990;&#30028;&#20013;&#30340;&#20851;&#38190;&#37325;&#35201;&#24615;&#65292;&#22312;&#26085;&#24120;&#29983;&#27963;&#30340;&#21508;&#20010;&#26041;&#38754;&#23545;&#27599;&#20010;&#20154;&#37117;&#24050;&#32463;&#26080;&#22788;&#19981;&#22312;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#30340;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#23384;&#22312;&#20960;&#20010;&#25361;&#25112;&#65292;&#21487;&#33021;&#20250;&#23548;&#33268;&#20449;&#20219;&#21361;&#26426;&#65306;1&#65289;&#23545;&#39044;&#27979;&#32467;&#26524;&#30340;&#35299;&#37322;&#19981;&#36275;&#65307;2&#65289;&#23398;&#20064;&#27169;&#22411;&#30340;&#27867;&#21270;&#24615;&#19981;&#36275;&#65307;3&#65289;&#23545;&#19981;&#30830;&#23450;&#29615;&#22659;&#30340;&#36866;&#24212;&#33021;&#21147;&#24046;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#19968;&#31181;&#31070;&#32463;&#31243;&#24207;&#65292;&#29992;&#20110;&#26550;&#36215;&#21487;&#20449;&#24230;&#19982;&#24320;&#25918;&#19990;&#30028;&#23398;&#20064;&#20043;&#38388;&#30340;&#26725;&#26753;&#65292;&#20174;&#21333;&#27169;&#24577;&#25193;&#23637;&#21040;&#22810;&#27169;&#24577;&#22330;&#26223;&#65292;&#20197;&#20379;&#35835;&#32773;&#20351;&#29992;&#12290;1&#65289;&#20026;&#20102;&#22686;&#24378;&#35774;&#35745;&#32423;&#21487;&#35299;&#37322;&#24615;&#65292;&#25105;&#20204;&#39318;&#20808;&#23450;&#21046;&#20102;&#20855;&#26377;&#29305;&#23450;&#29289;&#29702;&#21547;&#20041;&#30340;&#21487;&#20449;&#32593;&#32476;&#65307;2&#65289;&#28982;&#21518;&#65292;&#36890;&#36807;&#28789;&#27963;&#30340;&#23398;&#20064;&#27491;&#21017;&#21270;&#22120;&#35774;&#35745;&#29615;&#22659;&#31119;&#31049;&#20219;&#21153;&#25509;&#21475;&#65292;&#20197;&#25913;&#21892;&#21487;&#20449;&#32593;&#32476;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
As researchers strive to narrow the gap between machine intelligence and human through the development of artificial intelligence technologies, it is imperative that we recognize the critical importance of trustworthiness in open-world, which has become ubiquitous in all aspects of daily life for everyone. However, several challenges may create a crisis of trust in current artificial intelligence systems that need to be bridged: 1) Insufficient explanation of predictive results; 2) Inadequate generalization for learning models; 3) Poor adaptability to uncertain environments. Consequently, we explore a neural program to bridge trustworthiness and open-world learning, extending from single-modal to multi-modal scenarios for readers. 1) To enhance design-level interpretability, we first customize trustworthy networks with specific physical meanings; 2) We then design environmental well-being task-interfaces via flexible learning regularizers for improving the generalization of trustworthy
&lt;/p&gt;</description></item><item><title>&#22312;&#32479;&#35745;&#25512;&#26029;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#26080;&#25439;&#36716;&#25442;&#21644;&#36807;&#37327;&#39118;&#38505;&#30340;&#27010;&#24565;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#26080;&#25439;&#36716;&#25442;&#30340;&#29305;&#24449;&#65292;&#24182;&#26500;&#24314;&#20102;&#19968;&#20010;&#29992;&#20110;&#21028;&#26029;&#32473;&#23450;&#36716;&#25442;&#26159;&#21542;&#26159;&#26080;&#25439;&#30340;&#32479;&#35745;&#37327;&#12290;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;delta-&#26080;&#25439;&#36716;&#25442;&#30340;&#27010;&#24565;&#65292;&#24182;&#32473;&#20986;&#20102;&#20805;&#20998;&#26465;&#20214;&#12290;&#36825;&#20123;&#30740;&#31350;&#22312;&#20998;&#31867;&#12289;&#38750;&#21442;&#25968;&#22238;&#24402;&#21644;&#25237;&#36164;&#32452;&#21512;&#31574;&#30053;&#31561;&#39046;&#22495;&#20855;&#26377;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2307.16735</link><description>&lt;p&gt;
&#26080;&#25439;&#36716;&#25442;&#21644;&#32479;&#35745;&#25512;&#26029;&#20013;&#30340;&#36807;&#37327;&#39118;&#38505;&#30028;&#38480;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Lossless Transformations and Excess Risk Bounds in Statistical Inference. (arXiv:2307.16735v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16735
&lt;/p&gt;
&lt;p&gt;
&#22312;&#32479;&#35745;&#25512;&#26029;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#26080;&#25439;&#36716;&#25442;&#21644;&#36807;&#37327;&#39118;&#38505;&#30340;&#27010;&#24565;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#26080;&#25439;&#36716;&#25442;&#30340;&#29305;&#24449;&#65292;&#24182;&#26500;&#24314;&#20102;&#19968;&#20010;&#29992;&#20110;&#21028;&#26029;&#32473;&#23450;&#36716;&#25442;&#26159;&#21542;&#26159;&#26080;&#25439;&#30340;&#32479;&#35745;&#37327;&#12290;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;delta-&#26080;&#25439;&#36716;&#25442;&#30340;&#27010;&#24565;&#65292;&#24182;&#32473;&#20986;&#20102;&#20805;&#20998;&#26465;&#20214;&#12290;&#36825;&#20123;&#30740;&#31350;&#22312;&#20998;&#31867;&#12289;&#38750;&#21442;&#25968;&#22238;&#24402;&#21644;&#25237;&#36164;&#32452;&#21512;&#31574;&#30053;&#31561;&#39046;&#22495;&#20855;&#26377;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#32479;&#35745;&#25512;&#26029;&#20013;&#30340;&#36807;&#37327;&#26368;&#23567;&#39118;&#38505;&#65292;&#23450;&#20041;&#20026;&#20174;&#35266;&#27979;&#21040;&#30340;&#29305;&#24449;&#21521;&#37327;&#20013;&#20272;&#35745;&#38543;&#26426;&#21464;&#37327;&#30340;&#26368;&#23567;&#26399;&#26395;&#25439;&#22833;&#19982;&#20174;&#29305;&#24449;&#21521;&#37327;&#30340;&#36716;&#25442;&#65288;&#32479;&#35745;&#37327;&#65289;&#20013;&#20272;&#35745;&#30456;&#21516;&#38543;&#26426;&#21464;&#37327;&#30340;&#26368;&#23567;&#26399;&#26395;&#25439;&#22833;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#22312;&#25551;&#36848;&#20102;&#26080;&#25439;&#36716;&#25442;&#65288;&#21363;&#23545;&#20110;&#25152;&#26377;&#25439;&#22833;&#20989;&#25968;&#65292;&#36807;&#37327;&#39118;&#38505;&#20026;&#38646;&#30340;&#36716;&#25442;&#65289;&#20043;&#21518;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#23545;&#20551;&#35774;&#36827;&#34892;&#20998;&#21306;&#26816;&#39564;&#30340;&#32479;&#35745;&#37327;&#65292;&#29992;&#20110;&#21028;&#26029;&#32473;&#23450;&#36716;&#25442;&#26159;&#21542;&#20026;&#26080;&#25439;&#36716;&#25442;&#65292;&#24182;&#35777;&#26126;&#23545;&#20110;i.i.d.&#25968;&#25454;&#65292;&#35813;&#26816;&#39564;&#26159;&#24378;&#19968;&#33268;&#30340;&#12290;&#26356;&#19968;&#33324;&#22320;&#65292;&#25105;&#20204;&#26681;&#25454;&#20449;&#24687;&#29702;&#35770;&#32473;&#20986;&#20102;&#36807;&#37327;&#39118;&#38505;&#30340;&#19978;&#30028;&#65292;&#35813;&#19978;&#30028;&#22312;&#30456;&#24403;&#19968;&#33324;&#30340;&#25439;&#22833;&#20989;&#25968;&#31867;&#19978;&#37117;&#26159;&#19968;&#33268;&#30340;&#12290;&#22522;&#20110;&#36825;&#20123;&#30028;&#38480;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#8220;delta-&#26080;&#25439;&#36716;&#25442;&#8221;&#30340;&#27010;&#24565;&#65292;&#24182;&#32473;&#20986;&#20102;&#32473;&#23450;&#36716;&#25442;&#26222;&#36941;&#26159;delta-&#26080;&#25439;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#35813;&#30740;&#31350;&#22312;&#20998;&#31867;&#12289;&#38750;&#21442;&#25968;&#22238;&#24402;&#12289;&#25237;&#36164;&#32452;&#21512;&#31574;&#30053;&#31561;&#26041;&#38754;&#20855;&#26377;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the excess minimum risk in statistical inference, defined as the difference between the minimum expected loss in estimating a random variable from an observed feature vector and the minimum expected loss in estimating the same random variable from a transformation (statistic) of the feature vector. After characterizing lossless transformations, i.e., transformations for which the excess risk is zero for all loss functions, we construct a partitioning test statistic for the hypothesis that a given transformation is lossless and show that for i.i.d. data the test is strongly consistent. More generally, we develop information-theoretic upper bounds on the excess risk that uniformly hold over fairly general classes of loss functions. Based on these bounds, we introduce the notion of a delta-lossless transformation and give sufficient conditions for a given transformation to be universally delta-lossless. Applications to classification, nonparametric regression, portfolio strategie
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31354;&#38388;&#26497;&#31471;&#20540;&#27169;&#22411;&#65292;&#36890;&#36807;&#38598;&#25104;&#22312;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#30340;&#32467;&#26500;&#20013;&#65292;&#21487;&#20197;&#28789;&#27963;&#12289;&#39640;&#25928;&#22320;&#27169;&#25311;&#20855;&#26377;&#38750;&#24179;&#31283;&#30456;&#20851;&#24615;&#30340;&#26497;&#31471;&#20107;&#20214;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#26102;&#38388;&#25928;&#29575;&#21644;&#24615;&#33021;&#19978;&#65292;&#30456;&#23545;&#20110;&#20256;&#32479;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#21644;&#35768;&#22810;&#20855;&#26377;&#24179;&#31283;&#30456;&#20851;&#24615;&#30340;&#31354;&#38388;&#26497;&#31471;&#20540;&#27169;&#22411;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2307.08079</link><description>&lt;p&gt;
&#36890;&#36807;&#21464;&#20998;&#33258;&#21160; &#32534;&#30721;&#22120;&#23454;&#29616;&#28789;&#27963;&#39640;&#25928;&#30340;&#31354;&#38388;&#26497;&#31471;&#20540;&#27169;&#25311;
&lt;/p&gt;
&lt;p&gt;
Flexible and efficient spatial extremes emulation via variational autoencoders. (arXiv:2307.08079v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.08079
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31354;&#38388;&#26497;&#31471;&#20540;&#27169;&#22411;&#65292;&#36890;&#36807;&#38598;&#25104;&#22312;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#30340;&#32467;&#26500;&#20013;&#65292;&#21487;&#20197;&#28789;&#27963;&#12289;&#39640;&#25928;&#22320;&#27169;&#25311;&#20855;&#26377;&#38750;&#24179;&#31283;&#30456;&#20851;&#24615;&#30340;&#26497;&#31471;&#20107;&#20214;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#26102;&#38388;&#25928;&#29575;&#21644;&#24615;&#33021;&#19978;&#65292;&#30456;&#23545;&#20110;&#20256;&#32479;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#21644;&#35768;&#22810;&#20855;&#26377;&#24179;&#31283;&#30456;&#20851;&#24615;&#30340;&#31354;&#38388;&#26497;&#31471;&#20540;&#27169;&#22411;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#29616;&#23454;&#19990;&#30028;&#30340;&#36807;&#31243;&#20855;&#26377;&#22797;&#26434;&#30340;&#23614;&#20381;&#36182;&#32467;&#26500;&#65292;&#36825;&#31181;&#32467;&#26500;&#26080;&#27861;&#20351;&#29992;&#20256;&#32479;&#30340;&#39640;&#26031;&#36807;&#31243;&#26469;&#25551;&#36848;&#12290;&#26356;&#28789;&#27963;&#30340;&#31354;&#38388;&#26497;&#31471;&#20540;&#27169;&#22411;&#65292; &#22914;&#39640;&#26031;&#23610;&#24230;&#28151;&#21512;&#27169;&#22411;&#21644;&#21333;&#31449;&#28857;&#35843;&#33410;&#27169;&#22411;&#65292;&#20855;&#26377;&#21560;&#24341;&#20154;&#30340;&#26497;&#31471;&#20381;&#36182;&#24615;&#36136;&#65292;&#20294;&#24448;&#24448;&#38590;&#20197;&#25311;&#21512;&#21644;&#27169;&#25311;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31354;&#38388;&#26497;&#31471;&#20540;&#27169;&#22411;&#65292;&#20855;&#26377;&#28789;&#27963;&#21644;&#38750;&#24179;&#31283;&#30340;&#30456;&#20851;&#24615;&#23646;&#24615;&#65292;&#24182;&#23558;&#20854;&#38598;&#25104;&#21040;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120; (extVAE) &#30340;&#32534;&#30721;-&#35299;&#30721;&#32467;&#26500;&#20013;&#12290; extVAE &#21487;&#20197;&#20316;&#20026;&#19968;&#20010;&#26102;&#31354;&#27169;&#25311;&#22120;&#65292;&#23545;&#28508;&#22312;&#30340;&#26426;&#21046;&#27169;&#22411;&#36755;&#20986;&#29366;&#24577;&#30340;&#20998;&#24067;&#36827;&#34892;&#24314;&#27169;&#65292;&#24182;&#20135;&#29983;&#20855;&#26377;&#19982;&#36755;&#20837;&#30456;&#21516;&#23646;&#24615;&#30340;&#36755;&#20986;&#65292;&#23588;&#20854;&#26159;&#22312;&#23614;&#37096;&#21306;&#22495;&#12290;&#36890;&#36807;&#24191;&#27867;&#30340;&#27169;&#25311;&#30740;&#31350;&#65292;&#25105;&#20204;&#35777;&#26126;&#25105;&#20204;&#30340;extVAE&#27604;&#20256;&#32479;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#26356;&#39640;&#25928;&#65292;&#24182;&#19988;&#22312;&#20855;&#26377; &#24179;&#31283;&#30456;&#20851;&#24615;&#32467;&#26500;&#30340;&#35768;&#22810;&#31354;&#38388;&#26497;&#31471;&#20540;&#27169;&#22411;&#20013;&#34920;&#29616; &#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many real-world processes have complex tail dependence structures that cannot be characterized using classical Gaussian processes. More flexible spatial extremes models such as Gaussian scale mixtures and single-station conditioning models exhibit appealing extremal dependence properties but are often exceedingly prohibitive to fit and simulate from. In this paper, we develop a new spatial extremes model that has flexible and non-stationary dependence properties, and we integrate it in the encoding-decoding structure of a variational autoencoder (extVAE). The extVAE can be used as a spatio-temporal emulator that characterizes the distribution of potential mechanistic model output states and produces outputs that have the same properties as the inputs, especially in the tail. Through extensive simulation studies, we show that our extVAE is vastly more time-efficient than traditional Bayesian inference while also outperforming many spatial extremes models with a stationary dependence str
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20132;&#36890;&#22270;&#26410;&#35843;&#25972;&#30340; Langevin &#31639;&#27861; (ULA) &#21644; Riemann &#27969;&#24418; Langevin &#21160;&#21147;&#23398; (RMLD)&#65292;&#36890;&#36807;&#24212;&#29992;&#20132;&#36890;&#22270;&#21487;&#20197;&#21152;&#36895; Langevin &#21160;&#21147;&#23398;&#30340;&#25910;&#25947;&#65292;&#24182;&#25552;&#20379;&#20102;&#23398;&#20064;&#24230;&#37327;&#21644;&#25200;&#21160;&#30340;&#26032;&#24605;&#36335;&#12290;</title><link>http://arxiv.org/abs/2302.07227</link><description>&lt;p&gt;
&#20132;&#36890;&#22270;&#26410;&#35843;&#25972;&#30340; Langevin &#31639;&#27861;&#65306;&#23398;&#20064;&#21644;&#31163;&#25955;&#21270;&#25200;&#21160;&#37319;&#26679;&#22120;
&lt;/p&gt;
&lt;p&gt;
Transport map unadjusted Langevin algorithms: learning and discretizing perturbed samplers. (arXiv:2302.07227v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.07227
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20132;&#36890;&#22270;&#26410;&#35843;&#25972;&#30340; Langevin &#31639;&#27861; (ULA) &#21644; Riemann &#27969;&#24418; Langevin &#21160;&#21147;&#23398; (RMLD)&#65292;&#36890;&#36807;&#24212;&#29992;&#20132;&#36890;&#22270;&#21487;&#20197;&#21152;&#36895; Langevin &#21160;&#21147;&#23398;&#30340;&#25910;&#25947;&#65292;&#24182;&#25552;&#20379;&#20102;&#23398;&#20064;&#24230;&#37327;&#21644;&#25200;&#21160;&#30340;&#26032;&#24605;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Langevin &#21160;&#21147;&#23398;&#34987;&#24191;&#27867;&#29992;&#20110;&#25277;&#26679;&#39640;&#32500;&#12289;&#38750;&#39640;&#26031;&#20998;&#24067;&#65292;&#20854;&#23494;&#24230;&#24050;&#30693;&#20294;&#24120;&#25968;&#26410;&#30693;&#12290;&#29305;&#21035;&#24863;&#20852;&#36259;&#30340;&#26159;&#26410;&#20462;&#27491;&#30340; Langevin &#31639;&#27861; (ULA)&#65292;&#23427;&#30452;&#25509;&#31163;&#25955;&#21270; Langevin &#21160;&#21147;&#23398;&#20197;&#20272;&#35745;&#30446;&#26631;&#20998;&#24067;&#19978;&#30340;&#26399;&#26395;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#20351;&#29992;&#20132;&#36890;&#22270;&#26469;&#36817;&#20284;&#26631;&#20934;&#21270;&#30446;&#26631;&#20998;&#24067;&#30340;&#26041;&#27861;&#65292;&#20197;&#39044;&#22788;&#29702;&#21644;&#21152;&#36895; Langevin &#21160;&#21147;&#23398;&#30340;&#25910;&#25947;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#36830;&#32493;&#26102;&#38388;&#19979;&#65292;&#24403;&#23558;&#20132;&#36890;&#22270;&#24212;&#29992;&#20110; Langevin &#21160;&#21147;&#23398;&#26102;&#65292;&#32467;&#26524;&#26159;&#20855;&#26377;&#30001;&#20132;&#36890;&#22270;&#23450;&#20041;&#30340;&#24230;&#37327;&#30340; Riemann &#27969;&#24418; Langevin &#21160;&#21147;&#23398;&#65288;RMLD&#65289;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#23558;&#20132;&#36890;&#22270;&#24212;&#29992;&#20110;&#19981;&#21487;&#36870;&#25200;&#21160;&#30340; ULA &#20250;&#20135;&#29983;&#21407;&#21160;&#21147;&#23398;&#30340;&#20960;&#20309;&#20449;&#24687;&#19981;&#21487;&#36870;&#25200;&#21160; &#65288;GiIrr&#65289;&#12290;&#36825;&#20123;&#32852;&#31995;&#34920;&#26126;&#20102;&#23398;&#20064;&#24230;&#37327;&#21644;&#25200;&#21160;&#30340;&#26356;&#31995;&#32479;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#25551;&#36848; RMLD &#30340;&#26367;&#20195;&#31163;&#25955;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Langevin dynamics are widely used in sampling high-dimensional, non-Gaussian distributions whose densities are known up to a normalizing constant. In particular, there is strong interest in unadjusted Langevin algorithms (ULA), which directly discretize Langevin dynamics to estimate expectations over the target distribution. We study the use of transport maps that approximately normalize a target distribution as a way to precondition and accelerate the convergence of Langevin dynamics. We show that in continuous time, when a transport map is applied to Langevin dynamics, the result is a Riemannian manifold Langevin dynamics (RMLD) with metric defined by the transport map. We also show that applying a transport map to an irreversibly-perturbed ULA results in a geometry-informed irreversible perturbation (GiIrr) of the original dynamics. These connections suggest more systematic ways of learning metrics and perturbations, and also yield alternative discretizations of the RMLD described b
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22823;&#38388;&#38548;&#20998;&#31867;&#22120;&#65292;&#23427;&#20351;&#29992;&#27985;&#25311;&#22278;&#20915;&#31574;&#36793;&#30028;&#21487;&#20197;&#20248;&#21270;&#27979;&#22320;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20854;&#31454;&#20105;&#24615;&#33021;&#20248;&#36234;&#12290;</title><link>http://arxiv.org/abs/2302.06807</link><description>&lt;p&gt;
&#36229;&#20284;&#26354;&#31354;&#38388;&#30340;&#22823;&#38388;&#38548;&#20998;&#31867;&#30340;&#27985;&#25311;&#22278;&#20915;&#31574;&#36793;&#30028;
&lt;/p&gt;
&lt;p&gt;
Horospherical Decision Boundaries for Large Margin Classification in Hyperbolic Space. (arXiv:2302.06807v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.06807
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22823;&#38388;&#38548;&#20998;&#31867;&#22120;&#65292;&#23427;&#20351;&#29992;&#27985;&#25311;&#22278;&#20915;&#31574;&#36793;&#30028;&#21487;&#20197;&#20248;&#21270;&#27979;&#22320;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20854;&#31454;&#20105;&#24615;&#33021;&#20248;&#36234;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#29992;&#36229;&#20284;&#26354;&#31354;&#38388;&#34920;&#31034;&#23618;&#27425;&#32467;&#26500;&#21270;&#25968;&#25454;&#24050;&#32463;&#36234;&#26469;&#36234;&#27969;&#34892;&#65292;&#21516;&#26102;&#65292;&#25991;&#29486;&#20013;&#20063;&#25552;&#20986;&#20102;&#20960;&#20010;&#38024;&#23545;&#36825;&#20123;&#31354;&#38388;&#20013;&#25968;&#25454;&#20998;&#31867;&#30340;&#31639;&#27861;&#12290;&#36825;&#20123;&#31639;&#27861;&#20027;&#35201;&#20351;&#29992;&#36229;&#24179;&#38754;&#25110;&#27979;&#22320;&#32447;&#20316;&#20026;&#20915;&#31574;&#36793;&#30028;&#65292;&#20351;&#29992;&#22823;&#38388;&#38548;&#20998;&#31867;&#22120;&#35774;&#32622;&#65292;&#20174;&#32780;&#23548;&#33268;&#19968;&#20010;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27985;&#25311;&#22278;&#20915;&#31574;&#36793;&#30028;&#30340;&#26032;&#22411;&#22823;&#38388;&#38548;&#20998;&#31867;&#22120;&#65292;&#23427;&#21487;&#20197;&#23548;&#33268;&#19968;&#20010;&#27979;&#22320;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#21487;&#20197;&#20351;&#29992;&#20219;&#20309;&#40654;&#26364;&#26799;&#24230;&#19979;&#38477;&#25216;&#26415;&#26469;&#20248;&#21270;&#65292;&#20445;&#35777;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20960;&#20010;&#23454;&#39564;&#65292;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#20998;&#31867;&#22120;&#30456;&#27604;&#20110; SOTA &#30340;&#31454;&#20105;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hyperbolic spaces have been quite popular in the recent past for representing hierarchically organized data. Further, several classification algorithms for data in these spaces have been proposed in the literature. These algorithms mainly use either hyperplanes or geodesics for decision boundaries in a large margin classifiers setting leading to a non-convex optimization problem. In this paper, we propose a novel large margin classifier based on horospherical decision boundaries that leads to a geodesically convex optimization problem that can be optimized using any Riemannian gradient descent technique guaranteeing a globally optimal solution. We present several experiments depicting the competitive performance of our classifier in comparison to SOTA.
&lt;/p&gt;</description></item><item><title>&#22312;&#20844;&#24179;&#20998;&#31867;&#20013;&#65292;&#27169;&#22411;&#30340;&#39044;&#27979;&#26041;&#24046;&#26159;&#19968;&#20010;&#37325;&#35201;&#20294;&#40092;&#20026;&#20154;&#30693;&#30340;&#35823;&#24046;&#26469;&#28304;&#38382;&#39064;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#20010;&#33258;&#27965;&#24615;&#26631;&#20934;&#26469;&#34913;&#37327;&#27979;&#37327;&#21644;&#20943;&#23569;&#38543;&#24847;&#24615;&#12290;&#20316;&#32773;&#36824;&#24320;&#21457;&#20102;&#19968;&#20010;&#31639;&#27861;&#26469;&#22788;&#29702;&#38543;&#24847;&#24615;&#39044;&#27979;&#65292;&#24182;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#25581;&#31034;&#20102;&#24403;&#21069;&#27169;&#22411;&#26080;&#27861;&#22788;&#29702;&#26576;&#20123;&#31867;&#22411;&#25968;&#25454;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2301.11562</link><description>&lt;p&gt;
&#39044;&#27979;&#26159;&#21542;&#38543;&#24847;&#65311;&#22312;&#20844;&#24179;&#20998;&#31867;&#20013;&#35780;&#20272;&#33258;&#27965;&#24615;
&lt;/p&gt;
&lt;p&gt;
Is My Prediction Arbitrary? Measuring Self-Consistency in Fair Classification. (arXiv:2301.11562v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11562
&lt;/p&gt;
&lt;p&gt;
&#22312;&#20844;&#24179;&#20998;&#31867;&#20013;&#65292;&#27169;&#22411;&#30340;&#39044;&#27979;&#26041;&#24046;&#26159;&#19968;&#20010;&#37325;&#35201;&#20294;&#40092;&#20026;&#20154;&#30693;&#30340;&#35823;&#24046;&#26469;&#28304;&#38382;&#39064;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#20010;&#33258;&#27965;&#24615;&#26631;&#20934;&#26469;&#34913;&#37327;&#27979;&#37327;&#21644;&#20943;&#23569;&#38543;&#24847;&#24615;&#12290;&#20316;&#32773;&#36824;&#24320;&#21457;&#20102;&#19968;&#20010;&#31639;&#27861;&#26469;&#22788;&#29702;&#38543;&#24847;&#24615;&#39044;&#27979;&#65292;&#24182;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#25581;&#31034;&#20102;&#24403;&#21069;&#27169;&#22411;&#26080;&#27861;&#22788;&#29702;&#26576;&#20123;&#31867;&#22411;&#25968;&#25454;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20844;&#24179;&#20998;&#31867;&#20013;&#65292;&#19981;&#21516;&#32463;&#36807;&#35757;&#32451;&#30340;&#27169;&#22411;&#20043;&#38388;&#30340;&#39044;&#27979;&#26041;&#24046;&#26159;&#19968;&#20010;&#37325;&#35201;&#20294;&#40092;&#20026;&#20154;&#30693;&#30340;&#35823;&#24046;&#26469;&#28304;&#38382;&#39064;&#12290; &#23454;&#35777;&#34920;&#26126;&#65292;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#39044;&#27979;&#30340;&#26041;&#24046;&#24046;&#24322;&#38750;&#24120;&#22823;&#65292;&#20197;&#33267;&#20110;&#20915;&#31574;&#23454;&#38469;&#19978;&#26159;&#38543;&#24847;&#30340;&#12290; &#20026;&#20102;&#30740;&#31350;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#22823;&#35268;&#27169;&#30340;&#23454;&#35777;&#30740;&#31350;&#65292;&#24182;&#20570;&#20986;&#20102;&#22235;&#20010;&#24635;&#20307;&#36129;&#29486;&#65306;&#25105;&#20204;1&#65289;&#23450;&#20041;&#20102;&#19968;&#31181;&#22522;&#20110;&#26041;&#24046;&#30340;&#24230;&#37327;&#26631;&#20934;&#65292;&#31216;&#20026;&#33258;&#27965;&#24615;&#65292;&#22312;&#27979;&#37327;&#21644;&#20943;&#23569;&#38543;&#24847;&#24615;&#26102;&#20351;&#29992;&#65307; 2&#65289;&#24320;&#21457;&#20102;&#19968;&#31181;&#21512;&#29702;&#30340;&#31639;&#27861;&#65292;&#24403;&#39044;&#27979;&#26080;&#27861;&#20570;&#20986;&#20915;&#31574;&#26102;&#65292;&#21487;&#20197;&#25918;&#24323;&#20998;&#31867;&#65307; 3&#65289;&#36827;&#34892;&#20102;&#36804;&#20170;&#20026;&#27490;&#26377;&#20851;&#20844;&#24179;&#20998;&#31867;&#20013;&#26041;&#24046;&#65288;&#30456;&#23545;&#20110;&#33258;&#27965;&#24615;&#21644;&#38543;&#24847;&#24615;&#65289;&#20316;&#29992;&#30340;&#26368;&#22823;&#35268;&#27169;&#23454;&#35777;&#30740;&#31350;&#65307; 4&#65289;&#25512;&#20986;&#20102;&#19968;&#20010;&#24037;&#20855;&#21253;&#65292;&#20351;&#32654;&#22269;&#20303;&#25151;&#25269;&#25276;&#36151;&#27454;&#25259;&#38706;&#27861;&#26696;&#65288;HMDA&#65289;&#25968;&#25454;&#38598;&#26131;&#20110;&#29992;&#20110;&#26410;&#26469;&#30740;&#31350;&#12290; &#24635;&#30340;&#26469;&#35828;&#65292;&#25105;&#20204;&#30340;&#23454;&#35777;&#32467;&#26524;&#25581;&#31034;&#20102;&#20851;&#20110;&#21487;&#37325;&#22797;&#24615;&#30340;&#20196;&#20154;&#38663;&#24778;&#30340;&#35265;&#35299;&#12290;&#24403;&#32771;&#34385;&#21040;&#26041;&#24046;&#21644;&#38543;&#24847;&#39044;&#27979;&#30340;&#21487;&#33021;&#24615;&#26102;&#65292;&#22823;&#22810;&#25968;&#20844;&#24179;&#20998;&#31867;&#22522;&#20934;&#25509;&#36817;&#20844;&#24179;&#12290; &#20294;&#26159;&#65292;&#19968;&#23567;&#37096;&#20998;&#23454;&#20363;&#26174;&#31034;&#20986;&#26497;&#22823;&#30340;&#38543;&#24847;&#24615;&#27700;&#24179;&#65292;&#36825;&#34920;&#26126;&#24403;&#21069;&#30340;&#27169;&#22411;&#21487;&#33021;&#26080;&#27861;&#22788;&#29702;&#26576;&#20123;&#31867;&#22411;&#30340;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variance in predictions across different trained models is a significant, under-explored source of error in fair classification. Empirically, the variance on some instances is so large that decisions can be effectively arbitrary. To study this problem, we perform a large-scale empirical study and make four overarching contributions: We 1) Define a metric called self-consistency, derived from variance, which we use as a proxy for measuring and reducing arbitrariness; 2) Develop an ensembling algorithm that abstains from classification when a prediction would be arbitrary; 3) Conduct the largest to-date empirical study of the role of variance (vis-a-vis self-consistency and arbitrariness) in fair classification; and, 4) Release a toolkit that makes the US Home Mortgage Disclosure Act (HMDA) datasets easily usable for future research. Altogether, our empirical results reveal shocking insights about reproducibility. Most fairness classification benchmarks are close-to-fair when taking into
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;HyperBO+&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#20998;&#23618;&#39640;&#26031;&#36807;&#31243;&#30340;&#39044;&#20808;&#35757;&#32451;&#65292;&#23454;&#29616;&#20102;&#22312;&#20855;&#26377;&#19981;&#21516;&#36755;&#20837;&#31354;&#38388;&#30340;&#20989;&#25968;&#19978;&#26222;&#36866;&#20110;&#36125;&#21494;&#26031;&#20248;&#21270;&#12290;&#30740;&#31350;&#20154;&#21592;&#35774;&#35745;&#20102;&#19968;&#31181;&#20004;&#27493;&#39044;&#20808;&#35757;&#32451;&#26041;&#27861;&#65292;&#24182;&#20998;&#26512;&#20102;&#20854;&#21560;&#24341;&#20154;&#30340;&#28176;&#36817;&#24615;&#36136;&#12290;</title><link>http://arxiv.org/abs/2212.10538</link><description>&lt;p&gt;
HyperBO+&#65306;&#20351;&#29992;&#20998;&#23618;&#39640;&#26031;&#36807;&#31243;&#20026;&#36125;&#21494;&#26031;&#20248;&#21270;&#39044;&#20808;&#35757;&#32451;&#36890;&#29992;&#20808;&#39564;
&lt;/p&gt;
&lt;p&gt;
HyperBO+: Pre-training a universal prior for Bayesian optimization with hierarchical Gaussian processes. (arXiv:2212.10538v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.10538
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;HyperBO+&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#20998;&#23618;&#39640;&#26031;&#36807;&#31243;&#30340;&#39044;&#20808;&#35757;&#32451;&#65292;&#23454;&#29616;&#20102;&#22312;&#20855;&#26377;&#19981;&#21516;&#36755;&#20837;&#31354;&#38388;&#30340;&#20989;&#25968;&#19978;&#26222;&#36866;&#20110;&#36125;&#21494;&#26031;&#20248;&#21270;&#12290;&#30740;&#31350;&#20154;&#21592;&#35774;&#35745;&#20102;&#19968;&#31181;&#20004;&#27493;&#39044;&#20808;&#35757;&#32451;&#26041;&#27861;&#65292;&#24182;&#20998;&#26512;&#20102;&#20854;&#21560;&#24341;&#20154;&#30340;&#28176;&#36817;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#22312;&#35768;&#22810;&#40657;&#30418;&#20989;&#25968;&#20248;&#21270;&#20219;&#21153;&#20013;&#34987;&#35777;&#26126;&#38750;&#24120;&#26377;&#25928;&#65292;&#20294;&#38656;&#35201;&#23454;&#36341;&#32773;&#31934;&#24515;&#36873;&#25321;&#36866;&#21512;&#20854;&#24863;&#20852;&#36259;&#20989;&#25968;&#30340;&#20808;&#39564;&#27010;&#29575;&#27169;&#22411;&#12290;&#30740;&#31350;&#20154;&#21592;&#24050;&#32463;&#25506;&#32034;&#20102;&#22522;&#20110;&#36801;&#31227;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#22914;&#22810;&#20219;&#21153;BO&#12289;&#23569;&#26679;&#26412;BO&#21644;HyperBO&#65292;&#26469;&#33258;&#21160;&#23398;&#20064;&#20808;&#39564;&#27010;&#29575;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#36890;&#24120;&#20551;&#35774;&#25152;&#26377;&#20219;&#21153;&#30340;&#36755;&#20837;&#31354;&#38388;&#30456;&#21516;&#65292;&#38480;&#21046;&#20102;&#23427;&#20204;&#22312;&#19981;&#21516;&#36755;&#20837;&#31354;&#38388;&#19978;&#20351;&#29992;&#35266;&#27979;&#32467;&#26524;&#25110;&#25512;&#24191;&#23398;&#20064;&#21040;&#30340;&#20808;&#39564;&#27010;&#29575;&#27169;&#22411;&#30340;&#33021;&#21147;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;HyperBO+&#65292;&#36825;&#26159;&#19968;&#31181;&#22522;&#20110;&#20998;&#23618;&#39640;&#26031;&#36807;&#31243;&#30340;&#39044;&#20808;&#35757;&#32451;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#20855;&#26377;&#19981;&#21516;&#36755;&#20837;&#31354;&#38388;&#30340;&#20989;&#25968;&#19978;&#26222;&#36941;&#36866;&#29992;&#20110;&#36125;&#21494;&#26031;&#20248;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20004;&#27493;&#39044;&#20808;&#35757;&#32451;&#26041;&#27861;&#65292;&#24182;&#20998;&#26512;&#20102;&#20854;&#21560;&#24341;&#20154;&#30340;&#28176;&#36817;&#24615;&#36136;&#21450;&#29305;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian optimization (BO), while proved highly effective for many black-box function optimization tasks, requires practitioners to carefully select priors that well model their functions of interest. Rather than specifying by hand, researchers have investigated transfer learning based methods to automatically learn the priors, e.g. multi-task BO (Swersky et al., 2013), few-shot BO (Wistuba and Grabocka, 2021) and HyperBO (Wang et al., 2022). However, those prior learning methods typically assume that the input domains are the same for all tasks, weakening their ability to use observations on functions with different domains or generalize the learned priors to BO on different search spaces. In this work, we present HyperBO+: a pre-training approach for hierarchical Gaussian processes that enables the same prior to work universally for Bayesian optimization on functions with different domains. We propose a two-step pre-training method and analyze its appealing asymptotic properties and 
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#38024;&#23545;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#36335;&#24452;&#30340;&#22810;&#31867;&#21035;&#20998;&#31867;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#25554;&#20214;&#20998;&#31867;&#22120;&#65292;&#24182;&#22312;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#20998;&#31867;&#36807;&#31243;&#30340;&#19968;&#33268;&#24615;&#21644;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#36890;&#36807;&#25968;&#20540;&#30740;&#31350;&#39564;&#35777;&#20102;&#29702;&#35770;&#21457;&#29616;&#12290;</title><link>http://arxiv.org/abs/2212.10259</link><description>&lt;p&gt;
&#38024;&#23545;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#36335;&#24452;&#30340;&#22810;&#31867;&#21035;&#20998;&#31867;&#30340;&#38750;&#21442;&#25968;&#25554;&#20214;&#20998;&#31867;&#22120;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Nonparametric plug-in classifier for multiclass classification of S.D.E. paths. (arXiv:2212.10259v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.10259
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#30740;&#31350;&#20102;&#38024;&#23545;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#36335;&#24452;&#30340;&#22810;&#31867;&#21035;&#20998;&#31867;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#25554;&#20214;&#20998;&#31867;&#22120;&#65292;&#24182;&#22312;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#20998;&#31867;&#36807;&#31243;&#30340;&#19968;&#33268;&#24615;&#21644;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#36890;&#36807;&#25968;&#20540;&#30740;&#31350;&#39564;&#35777;&#20102;&#29702;&#35770;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22810;&#31867;&#21035;&#20998;&#31867;&#38382;&#39064;&#65292;&#20854;&#20013;&#29305;&#24449;&#26469;&#33258;&#20110;&#26102;&#38388;&#40784;&#27425;&#25193;&#25955;&#30340;&#28151;&#21512;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#36890;&#36807;&#23427;&#20204;&#30340;&#28418;&#31227;&#20989;&#25968;&#26469;&#21306;&#20998;&#19981;&#21516;&#30340;&#31867;&#21035;&#65292;&#32780;&#25193;&#25955;&#31995;&#25968;&#23545;&#20110;&#25152;&#26377;&#31867;&#21035;&#37117;&#26159;&#30456;&#21516;&#19988;&#26410;&#30693;&#30340;&#12290;&#22312;&#36825;&#20010;&#26694;&#26550;&#19979;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#22522;&#20110;&#28418;&#31227;&#20989;&#25968;&#21644;&#25193;&#25955;&#20989;&#25968;&#30340;&#38750;&#21442;&#25968;&#20272;&#35745;&#30340;&#25554;&#20214;&#20998;&#31867;&#22120;&#12290;&#25105;&#20204;&#39318;&#20808;&#22312;&#28201;&#21644;&#20551;&#35774;&#19979;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#20998;&#31867;&#36807;&#31243;&#30340;&#19968;&#33268;&#24615;&#65292;&#28982;&#21518;&#22312;&#19981;&#21516;&#30340;&#20551;&#35774;&#38598;&#19979;&#32473;&#20986;&#20102;&#25910;&#25947;&#36895;&#24230;&#12290;&#26368;&#21518;&#65292;&#19968;&#20010;&#25968;&#20540;&#30740;&#31350;&#25903;&#25345;&#25105;&#20204;&#30340;&#29702;&#35770;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the multiclass classification problem where the features come from the mixture of time-homogeneous diffusions. Specifically, the classes are discriminated by their drift functions while the diffusion coefficient is common to all classes and unknown. In this framework, we build a plug-in classifier which relies on nonparametric estimators of the drift and diffusion functions. We first establish the consistency of our classification procedure under mild assumptions and then provide rates of cnvergence under different set of assumptions. Finally, a numerical study supports our theoretical findings.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#22823;&#30340;&#26368;&#22351;&#24773;&#20917;Lipschitz&#21442;&#25968;&#30340;&#24046;&#20998;&#38544;&#31169;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#19981;&#20381;&#36182;&#20110;&#32479;&#19968;Lipschitz&#21442;&#25968;&#30340;&#25509;&#36817;&#26368;&#20248;&#30340;&#36807;&#37327;&#39118;&#38505;&#30028;&#38480;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2209.07403</link><description>&lt;p&gt;
&#20855;&#26377;&#22823;&#30340;&#26368;&#22351;&#24773;&#20917;Lipschitz&#21442;&#25968;&#30340;&#31169;&#26377;&#38543;&#26426;&#20248;&#21270;&#65306;&#65288;&#38750;&#20809;&#28369;&#65289;&#20984;&#25439;&#22833;&#30340;&#26368;&#20248;&#36895;&#29575;&#21450;&#20854;&#23545;&#38750;&#20984;&#25439;&#22833;&#30340;&#25193;&#23637;
&lt;/p&gt;
&lt;p&gt;
Private Stochastic Optimization With Large Worst-Case Lipschitz Parameter: Optimal Rates for (Non-Smooth) Convex Losses and Extension to Non-Convex Losses. (arXiv:2209.07403v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.07403
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#22823;&#30340;&#26368;&#22351;&#24773;&#20917;Lipschitz&#21442;&#25968;&#30340;&#24046;&#20998;&#38544;&#31169;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#19981;&#20381;&#36182;&#20110;&#32479;&#19968;Lipschitz&#21442;&#25968;&#30340;&#25509;&#36817;&#26368;&#20248;&#30340;&#36807;&#37327;&#39118;&#38505;&#30028;&#38480;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#26368;&#22351;&#24773;&#20917;Lipschitz&#21442;&#25968;&#21487;&#33021;&#38750;&#24120;&#22823;&#30340;&#25439;&#22833;&#20989;&#25968;&#30340;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#38543;&#26426;&#20248;&#21270;&#65288;SO&#65289;&#12290;&#36804;&#20170;&#20026;&#27490;&#65292;&#22823;&#37096;&#20998;&#20851;&#20110;DP SO&#30340;&#24037;&#20316;&#37117;&#20551;&#35774;&#25439;&#22833;&#22312;&#25152;&#26377;&#25968;&#25454;&#28857;&#19978;&#26159;&#22343;&#21248;Lipschitz&#36830;&#32493;&#30340;&#65288;&#21363;&#38543;&#26426;&#26799;&#24230;&#22312;&#25152;&#26377;&#25968;&#25454;&#28857;&#19978;&#37117;&#26377;&#30028;&#65289;&#12290;&#34429;&#28982;&#36825;&#31181;&#20551;&#35774;&#24456;&#26041;&#20415;&#65292;&#20294;&#36890;&#24120;&#20250;&#23548;&#33268;&#24754;&#35266;&#30340;&#36807;&#37327;&#39118;&#38505;&#30028;&#38480;&#12290;&#22312;&#35768;&#22810;&#23454;&#38469;&#38382;&#39064;&#20013;&#65292;&#30001;&#20110;&#24322;&#24120;&#20540;&#65292;&#25439;&#22833;&#22312;&#25152;&#26377;&#25968;&#25454;&#28857;&#19978;&#30340;&#26368;&#22351;&#24773;&#20917;&#65288;&#32479;&#19968;&#65289;Lipschitz&#21442;&#25968;&#21487;&#33021;&#38750;&#24120;&#22823;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;DP SO&#30340;&#35823;&#24046;&#30028;&#38480;&#19982;&#25439;&#22833;&#30340;&#26368;&#22351;&#24773;&#20917;Lipschitz&#21442;&#25968;&#25104;&#27604;&#20363;&#65292;&#23558;&#20250;&#26159;&#31354;&#27934;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#65292;&#26412;&#24037;&#20316;&#25552;&#20379;&#20102;&#19968;&#31181;&#25509;&#36817;&#26368;&#20248;&#30340;&#36807;&#37327;&#39118;&#38505;&#30028;&#38480;&#65292;&#19981;&#20381;&#36182;&#20110;&#25439;&#22833;&#30340;&#32479;&#19968;Lipschitz&#21442;&#25968;&#12290;&#22312;&#26368;&#36817;&#30340;&#24037;&#20316;&#65288;Wang&#31561;&#20154;&#65292;2020; Kamath&#31561;&#20154;&#65292;2022&#65289;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#20551;&#35774;&#38543;&#26426;&#26799;&#24230;&#20855;&#26377;&#26377;&#30028;&#30340;k&#38454;&#30697;
&lt;/p&gt;
&lt;p&gt;
We study differentially private (DP) stochastic optimization (SO) with loss functions whose worst-case Lipschitz parameter over all data points may be extremely large. To date, the vast majority of work on DP SO assumes that the loss is uniformly Lipschitz continuous over data (i.e. stochastic gradients are uniformly bounded over all data points). While this assumption is convenient, it often leads to pessimistic excess risk bounds. In many practical problems, the worst-case (uniform) Lipschitz parameter of the loss over all data points may be extremely large due to outliers. In such cases, the error bounds for DP SO, which scale with the worst-case Lipschitz parameter of the loss, are vacuous. To address these limitations, this work provides near-optimal excess risk bounds that do not depend on the uniform Lipschitz parameter of the loss. Building on a recent line of work (Wang et al., 2020; Kamath et al., 2022), we assume that stochastic gradients have bounded $k$-th order moments fo
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20379;&#20102;&#25968;&#25454;&#22686;&#24378;&#22914;&#20309;&#24433;&#21709;&#20272;&#35745;&#30340;&#26041;&#24046;&#21644;&#26497;&#38480;&#20998;&#24067;&#30340;&#30830;&#20999;&#37327;&#21270;&#32467;&#26524;&#65292;&#21457;&#29616;&#25968;&#25454;&#22686;&#24378;&#21487;&#33021;&#20250;&#22686;&#21152;&#20272;&#35745;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#19988;&#20854;&#25928;&#26524;&#21462;&#20915;&#20110;&#22810;&#20010;&#22240;&#32032;&#12290;&#21516;&#26102;&#65292;&#35813;&#30740;&#31350;&#36824;&#36890;&#36807;&#38543;&#26426;&#36716;&#25442;&#30340;&#39640;&#32500;&#38543;&#26426;&#21521;&#37327;&#30340;&#20989;&#25968;&#30340;&#26497;&#38480;&#23450;&#29702;&#36827;&#34892;&#20102;&#35777;&#26126;&#12290;</title><link>http://arxiv.org/abs/2202.09134</link><description>&lt;p&gt;
&#22312;&#27424;&#21442;&#25968;&#21270;&#21644;&#36807;&#21442;&#25968;&#21270;&#30340;&#27169;&#24335;&#20013;&#30340;&#25968;&#25454;&#22686;&#24378;
&lt;/p&gt;
&lt;p&gt;
Data Augmentation in the Underparameterized and Overparameterized Regimes. (arXiv:2202.09134v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.09134
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20379;&#20102;&#25968;&#25454;&#22686;&#24378;&#22914;&#20309;&#24433;&#21709;&#20272;&#35745;&#30340;&#26041;&#24046;&#21644;&#26497;&#38480;&#20998;&#24067;&#30340;&#30830;&#20999;&#37327;&#21270;&#32467;&#26524;&#65292;&#21457;&#29616;&#25968;&#25454;&#22686;&#24378;&#21487;&#33021;&#20250;&#22686;&#21152;&#20272;&#35745;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#19988;&#20854;&#25928;&#26524;&#21462;&#20915;&#20110;&#22810;&#20010;&#22240;&#32032;&#12290;&#21516;&#26102;&#65292;&#35813;&#30740;&#31350;&#36824;&#36890;&#36807;&#38543;&#26426;&#36716;&#25442;&#30340;&#39640;&#32500;&#38543;&#26426;&#21521;&#37327;&#30340;&#20989;&#25968;&#30340;&#26497;&#38480;&#23450;&#29702;&#36827;&#34892;&#20102;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20379;&#20102;&#30830;&#20999;&#37327;&#21270;&#25968;&#25454;&#22686;&#24378;&#22914;&#20309;&#24433;&#21709;&#20272;&#35745;&#30340;&#26041;&#24046;&#21644;&#26497;&#38480;&#20998;&#24067;&#30340;&#32467;&#26524;&#65292;&#24182;&#35814;&#32454;&#20998;&#26512;&#20102;&#20960;&#20010;&#20855;&#20307;&#27169;&#22411;&#12290;&#32467;&#26524;&#35777;&#23454;&#20102;&#26426;&#22120;&#23398;&#20064;&#23454;&#36341;&#20013;&#30340;&#19968;&#20123;&#35266;&#23519;&#65292;&#20294;&#20063;&#24471;&#20986;&#20102;&#24847;&#22806;&#30340;&#21457;&#29616;&#65306;&#25968;&#25454;&#22686;&#24378;&#21487;&#33021;&#20250;&#22686;&#21152;&#32780;&#19981;&#26159;&#20943;&#23569;&#20272;&#35745;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#27604;&#22914;&#32463;&#39564;&#39044;&#27979;&#39118;&#38505;&#12290;&#23427;&#21487;&#20197;&#20805;&#24403;&#27491;&#21017;&#21270;&#22120;&#65292;&#20294;&#22312;&#26576;&#20123;&#39640;&#32500;&#38382;&#39064;&#20013;&#21364;&#26080;&#27861;&#23454;&#29616;&#65292;&#24182;&#19988;&#21487;&#33021;&#20250;&#25913;&#21464;&#32463;&#39564;&#39118;&#38505;&#30340;&#21452;&#37325;&#19979;&#38477;&#23792;&#20540;&#12290;&#24635;&#30340;&#26469;&#35828;&#65292;&#20998;&#26512;&#34920;&#26126;&#25968;&#25454;&#22686;&#24378;&#34987;&#36171;&#20104;&#30340;&#20960;&#20010;&#23646;&#24615;&#35201;&#20040;&#26159;&#30495;&#30340;&#65292;&#35201;&#20040;&#26159;&#20551;&#30340;&#65292;&#32780;&#26159;&#21462;&#20915;&#20110;&#22810;&#20010;&#22240;&#32032;&#30340;&#32452;&#21512;-&#29305;&#21035;&#26159;&#25968;&#25454;&#20998;&#24067;&#65292;&#20272;&#35745;&#22120;&#30340;&#23646;&#24615;&#20197;&#21450;&#26679;&#26412;&#22823;&#23567;&#65292;&#22686;&#24378;&#25968;&#37327;&#21644;&#32500;&#25968;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#29702;&#35770;&#24037;&#20855;&#26159;&#38543;&#26426;&#36716;&#25442;&#30340;&#39640;&#32500;&#38543;&#26426;&#21521;&#37327;&#30340;&#20989;&#25968;&#30340;&#26497;&#38480;&#23450;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
We provide results that exactly quantify how data augmentation affects the variance and limiting distribution of estimates, and analyze several specific models in detail. The results confirm some observations made in machine learning practice, but also lead to unexpected findings: Data augmentation may increase rather than decrease the uncertainty of estimates, such as the empirical prediction risk. It can act as a regularizer, but fails to do so in certain high-dimensional problems, and it may shift the double-descent peak of an empirical risk. Overall, the analysis shows that several properties data augmentation has been attributed with are not either true or false, but rather depend on a combination of factors -- notably the data distribution, the properties of the estimator, and the interplay of sample size, number of augmentations, and dimension. Our main theoretical tool is a limit theorem for functions of randomly transformed, high-dimensional random vectors. The proof draws on 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23884;&#22871;&#27169;&#25311;&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#33021;&#22815;&#22312;&#20445;&#25345;&#26465;&#20214;&#26399;&#26395;&#36275;&#22815;&#24179;&#28369;&#30340;&#24773;&#20917;&#19979;&#65292;&#26377;&#25928;&#22320;&#32531;&#35299;&#39640;&#32500;&#24230;&#20013;&#30340;&#32500;&#24230;&#28798;&#38590;&#65292;&#20197;&#26725;&#25509;&#26631;&#20934;&#23884;&#22871;&#27169;&#25311;&#30340;&#31435;&#26041;&#26681;&#25910;&#25947;&#29575;&#21644;&#26631;&#20934;&#33945;&#29305;&#21345;&#27931;&#27169;&#25311;&#30340;&#24179;&#26041;&#26681;&#25910;&#25947;&#29575;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;</title><link>http://arxiv.org/abs/2201.02958</link><description>&lt;p&gt;
&#24179;&#28369;&#30340;&#23884;&#22871;&#27169;&#25311;&#26041;&#27861;&#65306;&#22312;&#39640;&#32500;&#24230;&#20013;&#26725;&#25509;&#31435;&#26041;&#21644;&#24179;&#26041;&#26681;&#25910;&#25947;&#29575;
&lt;/p&gt;
&lt;p&gt;
Smooth Nested Simulation: Bridging Cubic and Square Root Convergence Rates in High Dimensions. (arXiv:2201.02958v4 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.02958
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23884;&#22871;&#27169;&#25311;&#30340;&#26032;&#26041;&#27861;&#65292;&#23427;&#33021;&#22815;&#22312;&#20445;&#25345;&#26465;&#20214;&#26399;&#26395;&#36275;&#22815;&#24179;&#28369;&#30340;&#24773;&#20917;&#19979;&#65292;&#26377;&#25928;&#22320;&#32531;&#35299;&#39640;&#32500;&#24230;&#20013;&#30340;&#32500;&#24230;&#28798;&#38590;&#65292;&#20197;&#26725;&#25509;&#26631;&#20934;&#23884;&#22871;&#27169;&#25311;&#30340;&#31435;&#26041;&#26681;&#25910;&#25947;&#29575;&#21644;&#26631;&#20934;&#33945;&#29305;&#21345;&#27931;&#27169;&#25311;&#30340;&#24179;&#26041;&#26681;&#25910;&#25947;&#29575;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23884;&#22871;&#27169;&#25311;&#26159;&#36890;&#36807;&#27169;&#25311;&#26469;&#20272;&#35745;&#26465;&#20214;&#26399;&#26395;&#30340;&#21151;&#33021;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#23725;&#22238;&#24402;&#30340;&#26032;&#26041;&#27861;&#65292;&#20197;&#21033;&#29992;&#26465;&#20214;&#26399;&#26395;&#20316;&#20026;&#22810;&#32500;&#35843;&#33410;&#21464;&#37327;&#30340;&#24179;&#28369;&#20989;&#25968;&#12290;&#28176;&#36817;&#20998;&#26512;&#34920;&#26126;&#65292;&#21482;&#35201;&#26465;&#20214;&#26399;&#26395;&#36275;&#22815;&#24179;&#28369;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#33021;&#22815;&#22312;&#27169;&#25311;&#27425;&#25968;&#22686;&#21152;&#26102;&#26377;&#25928;&#22320;&#20943;&#23569;&#32500;&#24230;&#28798;&#38590;&#30340;&#24433;&#21709;&#12290;&#24179;&#28369;&#24615;&#26725;&#25509;&#20102;&#31435;&#26041;&#26681;&#25910;&#25947;&#29575;&#65288;&#21363;&#26631;&#20934;&#23884;&#22871;&#27169;&#25311;&#30340;&#26368;&#20248;&#25910;&#25947;&#29575;&#65289;&#21644;&#24179;&#26041;&#26681;&#25910;&#25947;&#29575;&#65288;&#21363;&#26631;&#20934;&#33945;&#29305;&#21345;&#27931;&#27169;&#25311;&#30340;&#35268;&#33539;&#25910;&#25947;&#29575;&#65289;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;&#25105;&#20204;&#36890;&#36807;&#32452;&#21512;&#39118;&#38505;&#31649;&#29702;&#21644;&#36755;&#20837;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#25968;&#20540;&#31034;&#20363;&#65292;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Nested simulation concerns estimating functionals of a conditional expectation via simulation. In this paper, we propose a new method based on kernel ridge regression to exploit the smoothness of the conditional expectation as a function of the multidimensional conditioning variable. Asymptotic analysis shows that the proposed method can effectively alleviate the curse of dimensionality on the convergence rate as the simulation budget increases, provided that the conditional expectation is sufficiently smooth. The smoothness bridges the gap between the cubic root convergence rate (that is, the optimal rate for the standard nested simulation) and the square root convergence rate (that is, the canonical rate for the standard Monte Carlo simulation). We demonstrate the performance of the proposed method via numerical examples from portfolio risk management and input uncertainty quantification.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#31639;&#27861;&#20915;&#31574;&#20013;&#30340;&#21160;&#24577;&#36873;&#25321;&#38382;&#39064;&#65292;&#38024;&#23545;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#20013;&#25968;&#25454;&#30340;&#20869;&#29983;&#24615;&#23548;&#33268;&#30340;&#20559;&#24046;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24037;&#20855;&#21464;&#37327;&#30340;&#32416;&#27491;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#21487;&#20197;&#33719;&#24471;&#30495;&#23454;&#21442;&#25968;&#20540;&#21644;&#36739;&#20302;&#36951;&#25022;&#27700;&#24179;&#12290;&#30740;&#31350;&#36824;&#25552;&#20379;&#20102;&#32479;&#35745;&#25512;&#26029;&#30340;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#12290;</title><link>http://arxiv.org/abs/2108.12547</link><description>&lt;p&gt;
&#31639;&#27861;&#20915;&#31574;&#20013;&#30340;&#21160;&#24577;&#36873;&#25321;&#38382;&#39064;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Dynamic Selection in Algorithmic Decision-making. (arXiv:2108.12547v3 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2108.12547
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31639;&#27861;&#20915;&#31574;&#20013;&#30340;&#21160;&#24577;&#36873;&#25321;&#38382;&#39064;&#65292;&#38024;&#23545;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#20013;&#25968;&#25454;&#30340;&#20869;&#29983;&#24615;&#23548;&#33268;&#30340;&#20559;&#24046;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24037;&#20855;&#21464;&#37327;&#30340;&#32416;&#27491;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#31639;&#27861;&#21487;&#20197;&#33719;&#24471;&#30495;&#23454;&#21442;&#25968;&#20540;&#21644;&#36739;&#20302;&#36951;&#25022;&#27700;&#24179;&#12290;&#30740;&#31350;&#36824;&#25552;&#20379;&#20102;&#32479;&#35745;&#25512;&#26029;&#30340;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35782;&#21035;&#21644;&#35299;&#20915;&#20102;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#20013;&#30340;&#21160;&#24577;&#36873;&#25321;&#38382;&#39064;&#65292;&#36825;&#20123;&#38382;&#39064;&#19982;&#20869;&#29983;&#25968;&#25454;&#26377;&#20851;&#12290;&#22312;&#19978;&#19979;&#25991;&#22810;&#33218;&#36172;&#21338;&#27169;&#22411;&#20013;&#65292;&#30001;&#20110;&#25968;&#25454;&#30340;&#20869;&#29983;&#24615;&#24433;&#21709;&#20915;&#31574;&#30340;&#36873;&#25321;&#65292;&#20250;&#20135;&#29983;&#19968;&#31181;&#26032;&#30340;&#20559;&#24046;&#65288;&#33258;&#25105;&#23454;&#29616;&#20559;&#24046;&#65289;&#65292;&#20174;&#32780;&#24433;&#21709;&#21040;&#26410;&#26469;&#24453;&#25910;&#38598;&#21644;&#20998;&#26512;&#30340;&#25968;&#25454;&#30340;&#20998;&#24067;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24037;&#20855;&#21464;&#37327;&#30340;&#31639;&#27861;&#65292;&#20197;&#32416;&#27491;&#36825;&#31181;&#20559;&#24046;&#12290;&#35813;&#31639;&#27861;&#21487;&#20197;&#33719;&#24471;&#30495;&#23454;&#21442;&#25968;&#20540;&#65292;&#24182;&#33719;&#24471;&#36739;&#20302;&#65288;&#31867;&#20284;&#23545;&#25968;&#30340;&#65289;&#36951;&#25022;&#27700;&#24179;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#32479;&#35745;&#25512;&#26029;&#30340;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#12290;&#20026;&#20102;&#24314;&#31435;&#29702;&#35770;&#24615;&#36136;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#36890;&#29992;&#25216;&#26415;&#65292;&#20197;&#35299;&#24320;&#25968;&#25454;&#21644;&#34892;&#21160;&#20043;&#38388;&#30340;&#30456;&#20114;&#20381;&#36182;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper identifies and addresses dynamic selection problems in online learning algorithms with endogenous data. In a contextual multi-armed bandit model, a novel bias (self-fulfilling bias) arises because the endogeneity of the data influences the choices of decisions, affecting the distribution of future data to be collected and analyzed. We propose an instrumental-variable-based algorithm to correct for the bias. It obtains true parameter values and attains low (logarithmic-like) regret levels. We also prove a central limit theorem for statistical inference. To establish the theoretical properties, we develop a general technique that untangles the interdependence between data and actions.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Pani&#30340;&#36890;&#29992;&#27491;&#21017;&#21270;&#22120;&#65292;&#23427;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#36827;&#34892;&#38750;&#23616;&#37096;&#34920;&#31034;&#65292;&#24182;&#23558;&#37051;&#22495;&#34917;&#19969;&#29305;&#24449;&#36827;&#34892;&#32447;&#24615;&#25554;&#20540;&#65292;&#20174;&#32780;&#26500;&#24314;&#20102;&#19968;&#31181;&#36890;&#29992;&#19988;&#26377;&#25928;&#30340;&#27491;&#21017;&#21270;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/1911.09307</link><description>&lt;p&gt;
Patch-level Neighborhood Interpolation: &#19968;&#31181;&#36890;&#29992;&#19988;&#26377;&#25928;&#30340;&#22522;&#20110;&#22270;&#30340;&#27491;&#21017;&#21270;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Patch-level Neighborhood Interpolation: A General and Effective Graph-based Regularization Strategy. (arXiv:1911.09307v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1911.09307
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Pani&#30340;&#36890;&#29992;&#27491;&#21017;&#21270;&#22120;&#65292;&#23427;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#36827;&#34892;&#38750;&#23616;&#37096;&#34920;&#31034;&#65292;&#24182;&#23558;&#37051;&#22495;&#34917;&#19969;&#29305;&#24449;&#36827;&#34892;&#32447;&#24615;&#25554;&#20540;&#65292;&#20174;&#32780;&#26500;&#24314;&#20102;&#19968;&#31181;&#36890;&#29992;&#19988;&#26377;&#25928;&#30340;&#27491;&#21017;&#21270;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27491;&#21017;&#21270;&#23545;&#20110;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#23588;&#20854;&#26159;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#38750;&#24120;&#37325;&#35201;&#12290;&#29616;&#26377;&#30340;&#27491;&#21017;&#21270;&#25216;&#26415;&#20027;&#35201;&#20381;&#36182;&#20110;&#29420;&#31435;&#21516;&#20998;&#24067;&#20551;&#35774;&#65292;&#24182;&#19988;&#20165;&#32771;&#34385;&#24403;&#21069;&#26679;&#26412;&#30340;&#30693;&#35782;&#65292;&#27809;&#26377;&#21033;&#29992;&#26679;&#26412;&#20043;&#38388;&#30340;&#37051;&#23621;&#20851;&#31995;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#8220;Patch-level Neighborhood Interpolation&#65288;Pani&#65289;&#8221;&#30340;&#36890;&#29992;&#27491;&#21017;&#21270;&#22120;&#65292;&#22312;&#32593;&#32476;&#35745;&#31639;&#20013;&#36827;&#34892;&#38750;&#23616;&#37096;&#34920;&#31034;&#12290;&#25105;&#20204;&#30340;&#25552;&#35758;&#26126;&#30830;&#22320;&#26500;&#24314;&#20102;&#19981;&#21516;&#23618;&#27425;&#30340;&#34917;&#19969;&#32423;&#22270;&#65292;&#28982;&#21518;&#32447;&#24615;&#25554;&#20540;&#37051;&#22495;&#34917;&#19969;&#29305;&#24449;&#65292;&#20316;&#20026;&#19968;&#31181;&#36890;&#29992;&#19988;&#26377;&#25928;&#30340;&#27491;&#21017;&#21270;&#31574;&#30053;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#23450;&#21046;&#20026;&#20004;&#31181;&#27969;&#34892;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#21363;&#34394;&#25311;&#23545;&#25239;&#35757;&#32451;&#65288;VAT&#65289;&#21644;MixUp&#20197;&#21450;&#20854;&#21464;&#20307;&#12290;&#39318;&#20808;&#27966;&#29983;&#30340;&#8220;Pani VAT&#8221;&#36890;&#36807;&#20351;&#29992;&#34917;&#19969;&#32423;&#25554;&#20540;&#25200;&#21160;&#26500;&#24314;&#38750;&#23616;&#37096;&#23545;&#25239;&#24179;&#28369;&#24230;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Regularization plays a crucial role in machine learning models, especially for deep neural networks. The existing regularization techniques mainly rely on the i.i.d. assumption and only consider the knowledge from the current sample, without the leverage of the neighboring relationship between samples. In this work, we propose a general regularizer called \textbf{Patch-level Neighborhood Interpolation~(Pani)} that conducts a non-local representation in the computation of networks. Our proposal explicitly constructs patch-level graphs in different layers and then linearly interpolates neighborhood patch features, serving as a general and effective regularization strategy. Further, we customize our approach into two kinds of popular regularization methods, namely Virtual Adversarial Training (VAT) and MixUp as well as its variants. The first derived \textbf{Pani VAT} presents a novel way to construct non-local adversarial smoothness by employing patch-level interpolated perturbations. Th
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#20915;&#31574;&#26862;&#26519;&#26500;&#24314;&#21487;&#35299;&#37322;&#30340;&#29305;&#24449;&#26680;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#22522;&#20110;&#21494;&#33410;&#28857;&#30456;&#20284;&#24615;&#30340;&#26680;&#24179;&#22343;&#23884;&#20837;&#38543;&#26426;&#26862;&#26519;&#65288;KMERF&#65289;&#65292;&#24182;&#35777;&#26126;&#20854;&#22312;&#31163;&#25955;&#21644;&#36830;&#32493;&#25968;&#25454;&#19978;&#37117;&#34920;&#29616;&#20986;&#28176;&#36827;&#29305;&#24449;&#12290;&#23454;&#39564;&#35777;&#26126;KMERF&#22312;&#22810;&#31181;&#39640;&#32500;&#25968;&#25454;&#27979;&#35797;&#20013;&#20248;&#20110;&#30446;&#21069;&#30340;&#26368;&#20808;&#36827;&#30340;&#22522;&#20110;&#26680;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/1812.00029</link><description>&lt;p&gt;
&#36890;&#36807;&#20915;&#31574;&#26862;&#26519;&#23398;&#20064;&#21487;&#35299;&#37322;&#30340;&#29305;&#24449;&#26680;
&lt;/p&gt;
&lt;p&gt;
Learning Interpretable Characteristic Kernels via Decision Forests. (arXiv:1812.00029v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1812.00029
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#20915;&#31574;&#26862;&#26519;&#26500;&#24314;&#21487;&#35299;&#37322;&#30340;&#29305;&#24449;&#26680;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#22522;&#20110;&#21494;&#33410;&#28857;&#30456;&#20284;&#24615;&#30340;&#26680;&#24179;&#22343;&#23884;&#20837;&#38543;&#26426;&#26862;&#26519;&#65288;KMERF&#65289;&#65292;&#24182;&#35777;&#26126;&#20854;&#22312;&#31163;&#25955;&#21644;&#36830;&#32493;&#25968;&#25454;&#19978;&#37117;&#34920;&#29616;&#20986;&#28176;&#36827;&#29305;&#24449;&#12290;&#23454;&#39564;&#35777;&#26126;KMERF&#22312;&#22810;&#31181;&#39640;&#32500;&#25968;&#25454;&#27979;&#35797;&#20013;&#20248;&#20110;&#30446;&#21069;&#30340;&#26368;&#20808;&#36827;&#30340;&#22522;&#20110;&#26680;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20915;&#31574;&#26862;&#26519;&#34987;&#24191;&#27867;&#29992;&#20110;&#20998;&#31867;&#21644;&#22238;&#24402;&#20219;&#21153;&#12290;&#26641;&#26041;&#27861;&#30340;&#19968;&#20010;&#36739;&#23569;&#34987;&#30693;&#26195;&#30340;&#29305;&#24615;&#26159;&#21487;&#20197;&#20174;&#26641;&#26500;&#24314;&#30456;&#20284;&#24615;&#30697;&#38453;&#65292;&#24182;&#19988;&#36825;&#20123;&#30456;&#20284;&#24615;&#30697;&#38453;&#26159;&#30001;&#26680;&#35825;&#23548;&#30340;&#12290;&#23613;&#31649;&#23545;&#20110;&#26680;&#30340;&#24212;&#29992;&#21644;&#24615;&#36136;&#36827;&#34892;&#20102;&#24191;&#27867;&#30740;&#31350;&#65292;&#20294;&#23545;&#20110;&#30001;&#20915;&#31574;&#26862;&#26519;&#35825;&#23548;&#30340;&#26680;&#30340;&#30740;&#31350;&#30456;&#23545;&#36739;&#23569;&#12290;&#25105;&#20204;&#26500;&#24314;&#20102;&#22522;&#20110;&#21494;&#33410;&#28857;&#30456;&#20284;&#24615;&#30340;&#26680;&#24179;&#22343;&#23884;&#20837;&#38543;&#26426;&#26862;&#26519;&#65288;KMERF&#65289;&#65292;&#23427;&#21487;&#20197;&#20174;&#38543;&#26426;&#26641;&#25110;&#26862;&#26519;&#20013;&#35825;&#23548;&#26680;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#28176;&#36827;&#29305;&#24449;&#26680;&#30340;&#27010;&#24565;&#65292;&#24182;&#35777;&#26126;KMERF&#26680;&#23545;&#20110;&#31163;&#25955;&#21644;&#36830;&#32493;&#25968;&#25454;&#37117;&#26159;&#28176;&#36827;&#29305;&#24449;&#30340;&#12290;&#30001;&#20110;KMERF&#26159;&#25968;&#25454;&#33258;&#36866;&#24212;&#30340;&#65292;&#25105;&#20204;&#24576;&#30097;&#23427;&#23558;&#22312;&#26377;&#38480;&#26679;&#26412;&#25968;&#25454;&#19978;&#32988;&#36807;&#39044;&#20808;&#36873;&#25321;&#30340;&#26680;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;KMERF&#22312;&#21508;&#31181;&#39640;&#32500;&#20004;&#26679;&#26412;&#21644;&#29420;&#31435;&#24615;&#27979;&#35797;&#22330;&#26223;&#20013;&#20960;&#20046;&#21344;&#25454;&#20102;&#30446;&#21069;&#30340;&#26368;&#20808;&#36827;&#30340;&#22522;&#20110;&#26680;&#30340;&#27979;&#35797;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Decision forests are widely used for classification and regression tasks. A lesser known property of tree-based methods is that one can construct a proximity matrix from the tree(s), and these proximity matrices are induced kernels. While there has been extensive research on the applications and properties of kernels, there is relatively little research on kernels induced by decision forests. We construct Kernel Mean Embedding Random Forests (KMERF), which induce kernels from random trees and/or forests using leaf-node proximity. We introduce the notion of an asymptotically characteristic kernel, and prove that KMERF kernels are asymptotically characteristic for both discrete and continuous data. Because KMERF is data-adaptive, we suspected it would outperform kernels selected a priori on finite sample data. We illustrate that KMERF nearly dominates current state-of-the-art kernel-based tests across a diverse range of high-dimensional two-sample and independence testing settings. Furth
&lt;/p&gt;</description></item></channel></rss>