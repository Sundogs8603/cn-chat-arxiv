<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>ODTlearn&#26159;&#19968;&#20010;&#24320;&#28304;&#30340;Python&#21253;&#65292;&#29992;&#20110;&#23398;&#20064;&#39044;&#27979;&#21644;&#22788;&#26041;&#30340;&#26368;&#20248;&#20915;&#31574;&#26641;&#12290;&#23427;&#25552;&#20379;&#20102;&#22810;&#31181;&#20248;&#21270;&#26041;&#27861;&#65292;&#24182;&#25903;&#25345;&#21508;&#31181;&#38382;&#39064;&#21644;&#31639;&#27861;&#30340;&#25193;&#23637;&#12290;</title><link>http://arxiv.org/abs/2307.15691</link><description>&lt;p&gt;
ODTlearn: &#19968;&#20010;&#29992;&#20110;&#23398;&#20064;&#39044;&#27979;&#21644;&#22788;&#26041;&#30340;&#26368;&#20248;&#20915;&#31574;&#26641;&#30340;&#21253;
&lt;/p&gt;
&lt;p&gt;
ODTlearn: A Package for Learning Optimal Decision Trees for Prediction and Prescription. (arXiv:2307.15691v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15691
&lt;/p&gt;
&lt;p&gt;
ODTlearn&#26159;&#19968;&#20010;&#24320;&#28304;&#30340;Python&#21253;&#65292;&#29992;&#20110;&#23398;&#20064;&#39044;&#27979;&#21644;&#22788;&#26041;&#30340;&#26368;&#20248;&#20915;&#31574;&#26641;&#12290;&#23427;&#25552;&#20379;&#20102;&#22810;&#31181;&#20248;&#21270;&#26041;&#27861;&#65292;&#24182;&#25903;&#25345;&#21508;&#31181;&#38382;&#39064;&#21644;&#31639;&#27861;&#30340;&#25193;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
ODTLearn&#26159;&#19968;&#20010;&#24320;&#28304;&#30340;Python&#21253;&#65292;&#25552;&#20379;&#20102;&#22522;&#20110;&#28151;&#21512;&#25972;&#25968;&#20248;&#21270;(MIO)&#26694;&#26550;&#30340;&#39640;&#39118;&#38505;&#39044;&#27979;&#21644;&#22788;&#26041;&#20219;&#21153;&#30340;&#26368;&#20248;&#20915;&#31574;&#26641;&#23398;&#20064;&#26041;&#27861;&#12290;&#35813;&#21253;&#30340;&#24403;&#21069;&#29256;&#26412;&#25552;&#20379;&#20102;&#23398;&#20064;&#26368;&#20248;&#20998;&#31867;&#26641;&#12289;&#20844;&#24179;&#26368;&#20248;&#20998;&#31867;&#26641;&#12289;&#40065;&#26834;&#26368;&#20248;&#20998;&#31867;&#26641;&#21644;&#20174;&#35266;&#27979;&#25968;&#25454;&#23398;&#20064;&#26368;&#20248;&#22788;&#26041;&#26641;&#30340;&#23454;&#29616;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#35813;&#21253;&#20197;&#20415;&#20110;&#32500;&#25252;&#21644;&#25193;&#23637;&#65292;&#24403;&#24341;&#20837;&#26032;&#30340;&#26368;&#20248;&#20915;&#31574;&#26641;&#38382;&#39064;&#31867;&#12289;&#37325;&#26500;&#31574;&#30053;&#21644;&#35299;&#20915;&#31639;&#27861;&#26102;&#65292;&#21487;&#20197;&#36731;&#26494;&#26356;&#26032;&#12290;&#20026;&#27492;&#65292;&#35813;&#21253;&#36981;&#24490;&#38754;&#21521;&#23545;&#35937;&#30340;&#35774;&#35745;&#21407;&#21017;&#65292;&#24182;&#25903;&#25345;&#21830;&#19994;(Gurobi)&#21644;&#24320;&#28304;(COIN-OR branch and cut)&#27714;&#35299;&#22120;&#12290;&#21253;&#30340;&#25991;&#26723;&#21644;&#35814;&#32454;&#29992;&#25143;&#25351;&#21335;&#21487;&#20197;&#22312;https://d3m-research-group.github.io/odtlearn/&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
ODTLearn is an open-source Python package that provides methods for learning optimal decision trees for high-stakes predictive and prescriptive tasks based on the mixed-integer optimization (MIO) framework proposed in Aghaei et al. (2019) and several of its extensions. The current version of the package provides implementations for learning optimal classification trees, optimal fair classification trees, optimal classification trees robust to distribution shifts, and optimal prescriptive trees from observational data. We have designed the package to be easy to maintain and extend as new optimal decision tree problem classes, reformulation strategies, and solution algorithms are introduced. To this end, the package follows object-oriented design principles and supports both commercial (Gurobi) and open source (COIN-OR branch and cut) solvers. The package documentation and an extensive user guide can be found at https://d3m-research-group.github.io/odtlearn/. Additionally, users can view
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#27604;&#36739;&#20102;&#19981;&#21516;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#36710;&#36947;&#25913;&#21464;&#24847;&#22270;&#35782;&#21035;&#20013;&#30340;&#24615;&#33021;&#65292;&#32467;&#26524;&#34920;&#26126;&#38598;&#25104;&#26041;&#27861;&#33021;&#38477;&#20302;&#20998;&#31867;&#38169;&#35823;&#30340;&#24433;&#21709;&#65292;&#32780;LightGBM&#30456;&#27604;XGBoost&#31639;&#27861;&#22312;&#27169;&#22411;&#35757;&#32451;&#25928;&#29575;&#19978;&#26377;&#26174;&#33879;&#25552;&#21319;&#12290;</title><link>http://arxiv.org/abs/2307.15625</link><description>&lt;p&gt;
&#36890;&#36807;&#36710;&#36742;&#36712;&#36857;&#25968;&#25454;&#36827;&#34892;&#36710;&#36947;&#25913;&#21464;&#24847;&#22270;&#35782;&#21035;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#30340;&#27604;&#36739;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
A Comparative Analysis of Machine Learning Methods for Lane Change Intention Recognition Using Vehicle Trajectory Data. (arXiv:2307.15625v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15625
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#27604;&#36739;&#20102;&#19981;&#21516;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#36710;&#36947;&#25913;&#21464;&#24847;&#22270;&#35782;&#21035;&#20013;&#30340;&#24615;&#33021;&#65292;&#32467;&#26524;&#34920;&#26126;&#38598;&#25104;&#26041;&#27861;&#33021;&#38477;&#20302;&#20998;&#31867;&#38169;&#35823;&#30340;&#24433;&#21709;&#65292;&#32780;LightGBM&#30456;&#27604;XGBoost&#31639;&#27861;&#22312;&#27169;&#22411;&#35757;&#32451;&#25928;&#29575;&#19978;&#26377;&#26174;&#33879;&#25552;&#21319;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20934;&#30830;&#22320;&#26816;&#27979;&#21644;&#39044;&#27979;&#36710;&#36947;&#25913;&#21464;&#36807;&#31243;&#21487;&#20197;&#24110;&#21161;&#33258;&#21160;&#39550;&#39542;&#27773;&#36710;&#26356;&#22909;&#22320;&#29702;&#35299;&#21608;&#22260;&#29615;&#22659;&#65292;&#35782;&#21035;&#28508;&#22312;&#30340;&#23433;&#20840;&#38544;&#24739;&#65292;&#24182;&#25552;&#39640;&#20132;&#36890;&#23433;&#20840;&#24615;&#12290;&#26412;&#25991;&#20027;&#35201;&#30740;&#31350;&#36710;&#36947;&#25913;&#21464;&#36807;&#31243;&#65292;&#24182;&#27604;&#36739;&#19981;&#21516;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#22312;&#20174;&#39640;&#32500;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#35782;&#21035;&#36710;&#36947;&#25913;&#21464;&#24847;&#22270;&#26041;&#38754;&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#39564;&#35777;&#25152;&#25552;&#27169;&#22411;&#30340;&#24615;&#33021;&#65292;&#20174;CitySim&#25968;&#25454;&#38598;&#20013;&#25552;&#21462;&#20102;&#24635;&#20849;1023&#20010;&#36710;&#36742;&#36712;&#36857;&#12290;&#23545;&#20110;&#36710;&#36947;&#25913;&#21464;&#24847;&#22270;&#35782;&#21035;&#38382;&#39064;&#65292;&#32467;&#26524;&#34920;&#26126;&#65292;&#38598;&#25104;&#26041;&#27861;&#21487;&#20197;&#23558;II&#22411;&#21644;III&#22411;&#20998;&#31867;&#38169;&#35823;&#30340;&#24433;&#21709;&#38477;&#20302;&#21040;98%&#30340;&#20998;&#31867;&#20934;&#30830;&#29575;&#12290;&#22312;&#19981;&#25439;&#22833;&#35782;&#21035;&#20934;&#30830;&#29575;&#30340;&#24773;&#20917;&#19979;&#65292;LightGBM&#30456;&#27604;XGBoost&#31639;&#27861;&#22312;&#27169;&#22411;&#35757;&#32451;&#25928;&#29575;&#19978;&#25552;&#39640;&#20102;6&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;
Accurately detecting and predicting lane change (LC)processes can help autonomous vehicles better understand their surrounding environment, recognize potential safety hazards, and improve traffic safety. This paper focuses on LC processes and compares different machine learning methods' performance to recognize LC intention from high-dimensionality time series data. To validate the performance of the proposed models, a total number of 1023 vehicle trajectories is extracted from the CitySim dataset. For LC intention recognition issues, the results indicate that with ninety-eight percent of classification accuracy, ensemble methods reduce the impact of Type II and Type III classification errors. Without sacrificing recognition accuracy, the LightGBM demonstrates a sixfold improvement in model training efficiency than the XGBoost algorithm.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#20351;&#29992;&#24352;&#37327;&#21015;&#36710;&#26041;&#27861;&#32467;&#21512;&#22238;&#24402;&#31867;&#22411;&#26041;&#27861;&#26469;&#35299;&#20915;&#39640;&#32500;&#24230;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#25968;&#20540;&#36924;&#36817;&#38382;&#39064;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#31934;&#24230;&#21644;&#35745;&#31639;&#25928;&#29575;&#20043;&#38388;&#21462;&#24471;&#20102;&#26377;&#21033;&#30340;&#25240;&#20013;&#12290;</title><link>http://arxiv.org/abs/2307.15496</link><description>&lt;p&gt;
&#20174;&#36830;&#32493;&#26102;&#38388;&#34920;&#36848;&#21040;&#31163;&#25955;&#21270;&#26041;&#26696;&#65306;&#24352;&#37327;&#21015;&#36710;&#21644;&#40065;&#26834;&#22238;&#24402;&#29992;&#20110;BSDEs&#21644;&#25243;&#29289;&#32447;PDEs
&lt;/p&gt;
&lt;p&gt;
From continuous-time formulations to discretization schemes: tensor trains and robust regression for BSDEs and parabolic PDEs. (arXiv:2307.15496v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15496
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#20351;&#29992;&#24352;&#37327;&#21015;&#36710;&#26041;&#27861;&#32467;&#21512;&#22238;&#24402;&#31867;&#22411;&#26041;&#27861;&#26469;&#35299;&#20915;&#39640;&#32500;&#24230;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#25968;&#20540;&#36924;&#36817;&#38382;&#39064;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#31934;&#24230;&#21644;&#35745;&#31639;&#25928;&#29575;&#20043;&#38388;&#21462;&#24471;&#20102;&#26377;&#21033;&#30340;&#25240;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39640;&#32500;&#24230;&#20013;&#25968;&#20540;&#36924;&#36817;&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;PDEs&#65289;&#38754;&#20020;&#30528;&#24040;&#22823;&#30340;&#25361;&#25112;&#65292;&#22240;&#20026;&#20256;&#32479;&#30340;&#22522;&#20110;&#32593;&#26684;&#30340;&#26041;&#27861;&#21463;&#21040;&#25152;&#35859;&#32500;&#25968;&#35781;&#21650;&#30340;&#38480;&#21046;&#12290;&#26368;&#36817;&#30340;&#23581;&#35797;&#20381;&#36182;&#20110;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#21644;&#21464;&#20998;&#34920;&#36848;&#30340;&#32452;&#21512;&#65292;&#21033;&#29992;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#20989;&#25968;&#36924;&#36817;&#12290;&#24310;&#32493;&#20043;&#21069;&#30340;&#24037;&#20316;&#65288;Richter&#31561;&#65292;2021&#65289;&#65292;&#25105;&#20204;&#35748;&#20026;&#24352;&#37327;&#21015;&#36710;&#20026;&#25243;&#29289;&#22411;PDE&#25552;&#20379;&#20102;&#19968;&#31181;&#21560;&#24341;&#20154;&#30340;&#26694;&#26550;&#65306;&#36890;&#36807;&#20197;&#36870;&#21521;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#21644;&#22238;&#24402;&#31867;&#22411;&#26041;&#27861;&#30340;&#24418;&#24335;&#37325;&#26032;&#34920;&#36848;&#65292;&#32467;&#21512;&#28508;&#22312;&#30340;&#20302;&#31209;&#32467;&#26500;&#65292;&#26377;&#26395;&#23454;&#29616;&#21387;&#32553;&#21644;&#39640;&#25928;&#35745;&#31639;&#30340;&#30446;&#26631;&#12290;&#24378;&#35843;&#36830;&#32493;&#26102;&#38388;&#35266;&#28857;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#36845;&#20195;&#26041;&#26696;&#65292;&#20854;&#22312;&#35745;&#31639;&#25928;&#29575;&#21644;&#40065;&#26834;&#24615;&#26041;&#38754;&#26377;&#25152;&#19981;&#21516;&#12290;&#25105;&#20204;&#20174;&#29702;&#35770;&#21644;&#25968;&#20540;&#19978;&#37117;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#22312;&#31934;&#24230;&#21644;&#35745;&#31639;&#25928;&#29575;&#20043;&#38388;&#21462;&#24471;&#26377;&#21033;&#30340;&#25240;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
The numerical approximation of partial differential equations (PDEs) poses formidable challenges in high dimensions since classical grid-based methods suffer from the so-called curse of dimensionality. Recent attempts rely on a combination of Monte Carlo methods and variational formulations, using neural networks for function approximation. Extending previous work (Richter et al., 2021), we argue that tensor trains provide an appealing framework for parabolic PDEs: The combination of reformulations in terms of backward stochastic differential equations and regression-type methods holds the promise of leveraging latent low-rank structures, enabling both compression and efficient computation. Emphasizing a continuous-time viewpoint, we develop iterative schemes, which differ in terms of computational efficiency and robustness. We demonstrate both theoretically and numerically that our methods can achieve a favorable trade-off between accuracy and computational efficiency. While previous 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#36817;&#26399;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#21457;&#23637;&#65292;&#37325;&#28857;&#20851;&#27880;&#34920;&#26684;&#25968;&#25454;&#38598;&#12290;&#36890;&#36807;&#20351;&#29992;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#29983;&#25104;&#38544;&#31169;&#25935;&#24863;&#25968;&#25454;&#30340;&#21512;&#25104;&#25968;&#25454;&#65292;&#24182;&#35299;&#20915;&#25968;&#25454;&#24402;&#19968;&#21270;&#12289;&#38544;&#31169;&#21644;&#35780;&#20272;&#31561;&#26041;&#38754;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2307.15424</link><description>&lt;p&gt;
&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#12289;&#21512;&#25104;&#34920;&#26684;&#25968;&#25454;&#21644;&#24046;&#20998;&#38544;&#31169;&#65306;&#32508;&#36848;&#19982;&#32508;&#21512;
&lt;/p&gt;
&lt;p&gt;
Deep Generative Models, Synthetic Tabular Data, and Differential Privacy: An Overview and Synthesis. (arXiv:2307.15424v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15424
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#36817;&#26399;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#30340;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#21457;&#23637;&#65292;&#37325;&#28857;&#20851;&#27880;&#34920;&#26684;&#25968;&#25454;&#38598;&#12290;&#36890;&#36807;&#20351;&#29992;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#29983;&#25104;&#38544;&#31169;&#25935;&#24863;&#25968;&#25454;&#30340;&#21512;&#25104;&#25968;&#25454;&#65292;&#24182;&#35299;&#20915;&#25968;&#25454;&#24402;&#19968;&#21270;&#12289;&#38544;&#31169;&#21644;&#35780;&#20272;&#31561;&#26041;&#38754;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20840;&#38754;&#32508;&#36848;&#20102;&#36890;&#36807;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#29983;&#25104;&#21512;&#25104;&#25968;&#25454;&#30340;&#26368;&#26032;&#21457;&#23637;&#65292;&#37325;&#28857;&#20851;&#27880;&#34920;&#26684;&#25968;&#25454;&#38598;&#12290;&#25105;&#20204;&#29305;&#21035;&#27010;&#36848;&#20102;&#22312;&#38544;&#31169;&#25935;&#24863;&#25968;&#25454;&#32972;&#26223;&#19979;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#30340;&#37325;&#35201;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24378;&#35843;&#20102;&#20351;&#29992;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30456;&#23545;&#20110;&#20854;&#20182;&#26041;&#27861;&#30340;&#20248;&#21183;&#65292;&#24182;&#35814;&#32454;&#35299;&#37322;&#20102;&#21253;&#25324;&#26080;&#30417;&#30563;&#23398;&#20064;&#12289;&#31070;&#32463;&#32593;&#32476;&#21644;&#29983;&#25104;&#27169;&#22411;&#22312;&#20869;&#30340;&#22522;&#26412;&#27010;&#24565;&#12290;&#35770;&#25991;&#28085;&#30422;&#20102;&#22312;&#20351;&#29992;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#22788;&#29702;&#34920;&#26684;&#25968;&#25454;&#38598;&#26102;&#28041;&#21450;&#30340;&#25361;&#25112;&#21644;&#32771;&#34385;&#22240;&#32032;&#65292;&#22914;&#25968;&#25454;&#24402;&#19968;&#21270;&#12289;&#38544;&#31169;&#38382;&#39064;&#21644;&#27169;&#22411;&#35780;&#20272;&#12290;&#26412;&#32508;&#36848;&#20026;&#23545;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#21450;&#20854;&#24212;&#29992;&#24863;&#20852;&#36259;&#30340;&#30740;&#31350;&#20154;&#21592;&#21644;&#23454;&#36341;&#32773;&#25552;&#20379;&#20102;&#23453;&#36149;&#30340;&#36164;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article provides a comprehensive synthesis of the recent developments in synthetic data generation via deep generative models, focusing on tabular datasets. We specifically outline the importance of synthetic data generation in the context of privacy-sensitive data. Additionally, we highlight the advantages of using deep generative models over other methods and provide a detailed explanation of the underlying concepts, including unsupervised learning, neural networks, and generative models. The paper covers the challenges and considerations involved in using deep generative models for tabular datasets, such as data normalization, privacy concerns, and model evaluation. This review provides a valuable resource for researchers and practitioners interested in synthetic data generation and its applications.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23558;&#33258;&#21160;&#24494;&#20998;&#25216;&#26415;&#25193;&#23637;&#21040;&#33945;&#29305;&#21345;&#27931;&#36807;&#31243;&#20013;&#65292;&#36890;&#36807;&#20351;&#29992;&#21704;&#23494;&#39039;&#26041;&#27861;&#20195;&#26367;&#37325;&#21152;&#26435;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#23545;&#26399;&#26395;&#20540;&#30340;&#23548;&#25968;&#30340;&#26041;&#24046;&#20943;&#23567;&#65292;&#20026;&#21457;&#29616;&#20854;&#20182;&#26399;&#26395;&#20540;&#23548;&#25968;&#26041;&#24046;&#20943;&#23567;&#25216;&#26415;&#25552;&#20379;&#20102;&#26032;&#24605;&#36335;&#12290;</title><link>http://arxiv.org/abs/2307.15406</link><description>&lt;p&gt;
&#33945;&#29305;&#21345;&#27931;&#36807;&#31243;&#30340;&#38543;&#26426;&#33258;&#21160;&#24494;&#20998;
&lt;/p&gt;
&lt;p&gt;
Stochastic automatic differentiation for Monte Carlo processes. (arXiv:2307.15406v1 [hep-lat])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15406
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#33258;&#21160;&#24494;&#20998;&#25216;&#26415;&#25193;&#23637;&#21040;&#33945;&#29305;&#21345;&#27931;&#36807;&#31243;&#20013;&#65292;&#36890;&#36807;&#20351;&#29992;&#21704;&#23494;&#39039;&#26041;&#27861;&#20195;&#26367;&#37325;&#21152;&#26435;&#26041;&#27861;&#65292;&#23454;&#29616;&#20102;&#23545;&#26399;&#26395;&#20540;&#30340;&#23548;&#25968;&#30340;&#26041;&#24046;&#20943;&#23567;&#65292;&#20026;&#21457;&#29616;&#20854;&#20182;&#26399;&#26395;&#20540;&#23548;&#25968;&#26041;&#24046;&#20943;&#23567;&#25216;&#26415;&#25552;&#20379;&#20102;&#26032;&#24605;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#26159;&#35745;&#31639;&#26426;&#31185;&#23398;&#30340;&#19968;&#20010;&#22522;&#30707;&#65292;&#23427;&#20204;&#33021;&#22815;&#39640;&#25928;&#22320;&#37319;&#26679;&#39640;&#32500;&#20998;&#24067;&#20989;&#25968;&#12290;&#26412;&#25991;&#32771;&#34385;&#23558;&#33258;&#21160;&#24494;&#20998;&#65288;AD&#65289;&#25216;&#26415;&#25193;&#23637;&#21040;&#33945;&#29305;&#21345;&#27931;&#36807;&#31243;&#65292;&#35299;&#20915;&#33719;&#21462;&#26399;&#26395;&#20540;&#30340;&#23548;&#25968;&#65288;&#20197;&#21450;&#27888;&#21202;&#32423;&#25968;&#65289;&#30340;&#38382;&#39064;&#12290;&#20511;&#37492;&#26230;&#26684;&#22330;&#35770;&#31038;&#21306;&#30340;&#24605;&#24819;&#65292;&#25105;&#20204;&#32771;&#23519;&#20102;&#20004;&#31181;&#26041;&#27861;&#12290;&#19968;&#31181;&#26159;&#22522;&#20110;&#37325;&#21152;&#26435;&#30340;&#26041;&#27861;&#65292;&#21478;&#19968;&#31181;&#26159;&#25193;&#23637;&#20102;&#28151;&#21512;&#33945;&#29305;&#21345;&#27931;&#65288;HMC&#65289;&#21644;&#31867;&#20284;&#31639;&#27861;&#20013;&#36890;&#24120;&#20351;&#29992;&#30340;&#21704;&#23494;&#39039;&#26041;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#21704;&#23494;&#39039;&#26041;&#27861;&#21487;&#20197;&#34987;&#29702;&#35299;&#20026;&#37325;&#21152;&#26435;&#26041;&#27861;&#30340;&#21464;&#37327;&#21464;&#25442;&#65292;&#20174;&#32780;&#22823;&#22823;&#20943;&#23567;&#20102;&#27888;&#21202;&#32423;&#25968;&#30340;&#31995;&#25968;&#30340;&#26041;&#24046;&#12290;&#36825;&#39033;&#24037;&#20316;&#20026;&#33719;&#21462;&#26399;&#26395;&#20540;&#23548;&#25968;&#30340;&#20854;&#20182;&#26041;&#24046;&#20943;&#23567;&#25216;&#26415;&#24320;&#36767;&#20102;&#26032;&#30340;&#24605;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Monte Carlo methods represent a cornerstone of computer science. They allow to sample high dimensional distribution functions in an efficient way. In this paper we consider the extension of Automatic Differentiation (AD) techniques to Monte Carlo process, addressing the problem of obtaining derivatives (and in general, the Taylor series) of expectation values. Borrowing ideas from the lattice field theory community, we examine two approaches. One is based on reweighting while the other represents an extension of the Hamiltonian approach typically used by the Hybrid Monte Carlo (HMC) and similar algorithms. We show that the Hamiltonian approach can be understood as a change of variables of the reweighting approach, resulting in much reduced variances of the coefficients of the Taylor series. This work opens the door to find other variance reduction techniques for derivatives of expectation values.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#30830;&#23450;&#24615;&#29305;&#24449;&#25490;&#24207;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#29305;&#24449;&#37325;&#35201;&#24615;&#20540;&#30340;&#20004;&#20004;&#27604;&#36739;&#65292;&#21487;&#20197;&#20135;&#29983;&#25490;&#24207;&#21644;&#21516;&#26102;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#24182;&#19988;&#21487;&#20197;&#36873;&#25321;&#21069;k&#20010;&#38598;&#21512;&#12290;</title><link>http://arxiv.org/abs/2307.15361</link><description>&lt;p&gt;
&#30830;&#23450;&#24615;&#29305;&#24449;&#25490;&#24207;
&lt;/p&gt;
&lt;p&gt;
Confident Feature Ranking. (arXiv:2307.15361v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15361
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#30830;&#23450;&#24615;&#29305;&#24449;&#25490;&#24207;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#29305;&#24449;&#37325;&#35201;&#24615;&#20540;&#30340;&#20004;&#20004;&#27604;&#36739;&#65292;&#21487;&#20197;&#20135;&#29983;&#25490;&#24207;&#21644;&#21516;&#26102;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#24182;&#19988;&#21487;&#20197;&#36873;&#25321;&#21069;k&#20010;&#38598;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29305;&#24449;&#37325;&#35201;&#24615;&#30340;&#35299;&#37322;&#36890;&#24120;&#20381;&#36182;&#20110;&#29305;&#24449;&#30340;&#30456;&#23545;&#39034;&#24207;&#32780;&#19981;&#26159;&#25968;&#20540;&#26412;&#36523;&#65292;&#20063;&#23601;&#26159;&#25490;&#24207;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#35745;&#31639;&#37325;&#35201;&#24615;&#20540;&#26102;&#20351;&#29992;&#30340;&#26679;&#26412;&#37327;&#36739;&#23567;&#65292;&#25490;&#24207;&#21487;&#33021;&#19981;&#31283;&#23450;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20107;&#21518;&#37325;&#35201;&#24615;&#26041;&#27861;&#65292;&#21487;&#20197;&#20135;&#29983;&#19968;&#31181;&#25490;&#24207;&#21644;&#21516;&#26102;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#22522;&#20110;&#29305;&#24449;&#37325;&#35201;&#24615;&#20540;&#30340;&#20004;&#20004;&#27604;&#36739;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#20445;&#35777;&#39640;&#27010;&#29575;&#21253;&#21547;&#8220;&#30495;&#23454;&#8221;&#65288;&#26080;&#38480;&#26679;&#26412;&#65289;&#25490;&#24207;&#65292;&#24182;&#20801;&#35768;&#36873;&#25321;&#21069;k&#20010;&#38598;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Interpretation of feature importance values often relies on the relative order of the features rather than on the value itself, referred to as ranking. However, the order may be unstable due to the small sample sizes used in calculating the importance values. We propose that post-hoc importance methods produce a ranking and simultaneous confident intervals for the rankings. Based on pairwise comparisons of the feature importance values, our method is guaranteed to include the ``true'' (infinite sample) ranking with high probability and allows for selecting top-k sets.
&lt;/p&gt;</description></item><item><title>Med-HALT&#26159;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#21644;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#35780;&#20272;&#21644;&#20943;&#23569;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#20013;&#21307;&#30103;&#39046;&#22495;&#30340;&#24187;&#35273;&#38382;&#39064;&#12290;&#36825;&#20010;&#25968;&#25454;&#38598;&#21253;&#25324;&#22810;&#31181;&#21019;&#26032;&#30340;&#27979;&#35797;&#27169;&#24335;&#65292;&#24182;&#35780;&#20272;&#20102;&#39046;&#20808;&#30340;LLMs&#22312;&#24615;&#33021;&#19978;&#30340;&#24046;&#24322;&#12290;</title><link>http://arxiv.org/abs/2307.15343</link><description>&lt;p&gt;
Med-HALT:&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#20013;&#21307;&#30103;&#39046;&#22495;&#24187;&#35273;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
Med-HALT: Medical Domain Hallucination Test for Large Language Models. (arXiv:2307.15343v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15343
&lt;/p&gt;
&lt;p&gt;
Med-HALT&#26159;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#21644;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#35780;&#20272;&#21644;&#20943;&#23569;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#20013;&#21307;&#30103;&#39046;&#22495;&#30340;&#24187;&#35273;&#38382;&#39064;&#12290;&#36825;&#20010;&#25968;&#25454;&#38598;&#21253;&#25324;&#22810;&#31181;&#21019;&#26032;&#30340;&#27979;&#35797;&#27169;&#24335;&#65292;&#24182;&#35780;&#20272;&#20102;&#39046;&#20808;&#30340;LLMs&#22312;&#24615;&#33021;&#19978;&#30340;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35770;&#25991;&#20851;&#27880;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20013;&#24187;&#35273;&#38382;&#39064;&#30340;&#25361;&#25112;&#65292;&#29305;&#21035;&#26159;&#22312;&#21307;&#30103;&#39046;&#22495;&#30340;&#32972;&#26223;&#19979;&#12290;&#24187;&#35273;&#25351;&#36825;&#20123;&#27169;&#22411;&#29983;&#25104;&#20102;&#21512;&#29702;&#20294;&#26410;&#32463;&#39564;&#35777;&#25110;&#38169;&#35823;&#30340;&#20449;&#24687;&#65292;&#36825;&#21487;&#33021;&#23545;&#21307;&#30103;&#24212;&#29992;&#20135;&#29983;&#20005;&#37325;&#24433;&#21709;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#21644;&#25968;&#25454;&#38598;&#65292;Med-HALT&#65288;&#21307;&#30103;&#39046;&#22495;&#24187;&#35273;&#27979;&#35797;&#65289;&#65292;&#19987;&#38376;&#35774;&#35745;&#29992;&#20110;&#35780;&#20272;&#21644;&#20943;&#23569;&#24187;&#35273;&#12290;Med-HALT&#25552;&#20379;&#20102;&#19968;&#20010;&#22810;&#20803;&#21270;&#30340;&#36328;&#22269;&#25968;&#25454;&#38598;&#65292;&#36825;&#20123;&#25968;&#25454;&#38598;&#26469;&#33258;&#19981;&#21516;&#22269;&#23478;&#30340;&#21307;&#30103;&#26816;&#26597;&#65292;&#21253;&#25324;&#22810;&#31181;&#21019;&#26032;&#30340;&#27979;&#35797;&#27169;&#24335;&#12290;Med-HALT&#21253;&#25324;&#20004;&#31867;&#27979;&#35797;&#65306;&#25512;&#29702;&#21644;&#22522;&#20110;&#35760;&#24518;&#30340;&#24187;&#35273;&#27979;&#35797;&#65292;&#26088;&#22312;&#35780;&#20272;LLMs&#30340;&#38382;&#39064;&#35299;&#20915;&#21644;&#20449;&#24687;&#26816;&#32034;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#35780;&#20272;&#20102;&#25991;&#26412;Davinci&#65292;GPT-3.5&#65292;LlaMa-2&#65292;MPT&#21644;Falcon&#31561;&#39046;&#20808;&#30340;LLMs&#65292;&#25581;&#31034;&#20102;&#23427;&#20204;&#22312;&#24615;&#33021;&#19978;&#30340;&#26174;&#33879;&#24046;&#24322;&#12290;&#36825;&#31687;&#35770;&#25991;&#25552;&#20379;&#20102;&#26377;&#20851;&#25968;&#25454;&#38598;&#30340;&#35814;&#32454;&#35265;&#35299;&#65292;&#20419;&#36827;&#20102;&#36827;&#19968;&#27493;&#30340;&#30740;&#31350;&#21644;&#21457;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
This research paper focuses on the challenges posed by hallucinations in large language models (LLMs), particularly in the context of the medical domain. Hallucination, wherein these models generate plausible yet unverified or incorrect information, can have serious consequences in healthcare applications. We propose a new benchmark and dataset, Med-HALT (Medical Domain Hallucination Test), designed specifically to evaluate and reduce hallucinations. Med-HALT provides a diverse multinational dataset derived from medical examinations across various countries and includes multiple innovative testing modalities. Med-HALT includes two categories of tests reasoning and memory-based hallucination tests, designed to assess LLMs's problem-solving and information retrieval abilities.  Our study evaluated leading LLMs, including Text Davinci, GPT-3.5, LlaMa-2, MPT, and Falcon, revealing significant differences in their performance. The paper provides detailed insights into the dataset, promoting
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#35299;&#20915;&#20102;Zonoid&#30340;&#26368;&#20248;&#36924;&#36817;&#21644;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#22343;&#21248;&#36924;&#36817;&#20004;&#20010;&#38382;&#39064;&#12290;&#23545;&#20110;Zonoid&#30340;&#36924;&#36817;&#65292;&#25105;&#20204;&#22635;&#34917;&#20102;&#22312;$d=2,3$&#26102;&#30340;&#23545;&#25968;&#24046;&#36317;&#65292;&#23454;&#29616;&#20102;&#22312;&#25152;&#26377;&#32500;&#24230;&#19978;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#23545;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#36924;&#36817;&#65292;&#25105;&#20204;&#30340;&#25216;&#26415;&#22312;$k \geq 1$&#26102;&#26174;&#33879;&#25552;&#39640;&#20102;&#30446;&#21069;&#30340;&#36924;&#36817;&#29575;&#65292;&#24182;&#33021;&#22815;&#22343;&#21248;&#36924;&#36817;&#30446;&#26631;&#20989;&#25968;&#21450;&#20854;&#23548;&#25968;&#12290;</title><link>http://arxiv.org/abs/2307.15285</link><description>&lt;p&gt;
Zonoid&#30340;&#26368;&#20248;&#36924;&#36817;&#21644;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#22343;&#21248;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
Optimal Approximation of Zonoids and Uniform Approximation by Shallow Neural Networks. (arXiv:2307.15285v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15285
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#35299;&#20915;&#20102;Zonoid&#30340;&#26368;&#20248;&#36924;&#36817;&#21644;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#22343;&#21248;&#36924;&#36817;&#20004;&#20010;&#38382;&#39064;&#12290;&#23545;&#20110;Zonoid&#30340;&#36924;&#36817;&#65292;&#25105;&#20204;&#22635;&#34917;&#20102;&#22312;$d=2,3$&#26102;&#30340;&#23545;&#25968;&#24046;&#36317;&#65292;&#23454;&#29616;&#20102;&#22312;&#25152;&#26377;&#32500;&#24230;&#19978;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#23545;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#36924;&#36817;&#65292;&#25105;&#20204;&#30340;&#25216;&#26415;&#22312;$k \geq 1$&#26102;&#26174;&#33879;&#25552;&#39640;&#20102;&#30446;&#21069;&#30340;&#36924;&#36817;&#29575;&#65292;&#24182;&#33021;&#22815;&#22343;&#21248;&#36924;&#36817;&#30446;&#26631;&#20989;&#25968;&#21450;&#20854;&#23548;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20197;&#19979;&#20004;&#20010;&#30456;&#20851;&#38382;&#39064;&#12290;&#31532;&#19968;&#20010;&#38382;&#39064;&#26159;&#30830;&#23450;&#19968;&#20010;&#20219;&#24847;&#30340;&#22312;$\mathbb{R}^{d+1}$&#31354;&#38388;&#20013;&#30340;Zonoid&#21487;&#20197;&#36890;&#36807;$n$&#20010;&#32447;&#27573;&#30340;Hausdorff&#36317;&#31163;&#26469;&#36924;&#36817;&#30340;&#35823;&#24046;&#12290;&#31532;&#20108;&#20010;&#38382;&#39064;&#26159;&#30830;&#23450;&#27973;&#23618;ReLU$^k$&#31070;&#32463;&#32593;&#32476;&#22312;&#20854;&#21464;&#20998;&#31354;&#38388;&#20013;&#30340;&#22343;&#21248;&#33539;&#25968;&#30340;&#26368;&#20248;&#36924;&#36817;&#29575;&#12290;&#31532;&#19968;&#20010;&#38382;&#39064;&#24050;&#32463;&#22312;$d \neq 2, 3$&#26102;&#24471;&#21040;&#35299;&#20915;&#65292;&#20294;&#24403;$d = 2, 3$&#26102;&#65292;&#26368;&#20248;&#19978;&#30028;&#21644;&#26368;&#20248;&#19979;&#30028;&#20043;&#38388;&#20173;&#23384;&#22312;&#19968;&#20010;&#23545;&#25968;&#24046;&#36317;&#12290;&#25105;&#20204;&#22635;&#34917;&#20102;&#36825;&#20010;&#24046;&#36317;&#65292;&#23436;&#25104;&#20102;&#25152;&#26377;&#32500;&#24230;&#19978;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#23545;&#20110;&#31532;&#20108;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#30340;&#25216;&#26415;&#22312;$k \geq 1$&#26102;&#26174;&#33879;&#25552;&#39640;&#20102;&#29616;&#26377;&#30340;&#36924;&#36817;&#29575;&#65292;&#24182;&#23454;&#29616;&#20102;&#30446;&#26631;&#20989;&#25968;&#21450;&#20854;&#23548;&#25968;&#30340;&#22343;&#21248;&#36924;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the following two related problems. The first is to determine to what error an arbitrary zonoid in $\mathbb{R}^{d+1}$ can be approximated in the Hausdorff distance by a sum of $n$ line segments. The second is to determine optimal approximation rates in the uniform norm for shallow ReLU$^k$ neural networks on their variation spaces. The first of these problems has been solved for $d\neq 2,3$, but when $d=2,3$ a logarithmic gap between the best upper and lower bounds remains. We close this gap, which completes the solution in all dimensions. For the second problem, our techniques significantly improve upon existing approximation rates when $k\geq 1$, and enable uniform approximation of both the target function and its derivatives.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#37325;&#26032;&#25490;&#24207;&#35266;&#27979;&#20540;&#30340;&#39044;&#26399;&#27531;&#24046;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#27979;&#35797;&#31243;&#24207;&#26469;&#35780;&#20272;&#27169;&#22411;&#30340;&#24378;&#26657;&#20934;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2307.15247</link><description>&lt;p&gt;
&#36825;&#20010;&#27169;&#22411;&#23545;&#27599;&#20010;&#20154;&#37117;&#21487;&#38752;&#21527;&#65311;&#27979;&#35797;&#24378;&#26657;&#20934;
&lt;/p&gt;
&lt;p&gt;
Is this model reliable for everyone? Testing for strong calibration. (arXiv:2307.15247v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15247
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#37325;&#26032;&#25490;&#24207;&#35266;&#27979;&#20540;&#30340;&#39044;&#26399;&#27531;&#24046;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#27979;&#35797;&#31243;&#24207;&#26469;&#35780;&#20272;&#27169;&#22411;&#30340;&#24378;&#26657;&#20934;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#19968;&#20010;&#26657;&#20934;&#33391;&#22909;&#30340;&#39118;&#38505;&#39044;&#27979;&#27169;&#22411;&#20013;&#65292;&#23545;&#20110;&#20219;&#20309;&#32473;&#23450;&#30340;&#23376;&#32676;&#20307;&#65292;&#24179;&#22343;&#39044;&#27979;&#27010;&#29575;&#19982;&#30495;&#23454;&#20107;&#20214;&#29575;&#25509;&#36817;&#12290;&#36825;&#26679;&#30340;&#27169;&#22411;&#36866;&#29992;&#20110;&#24322;&#36136;&#20154;&#32676;&#65292;&#24182;&#28385;&#36275;&#24378;&#31639;&#27861;&#20844;&#24179;&#24615;&#30340;&#27010;&#24565;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#24378;&#26657;&#20934;&#65292;&#23545;&#27169;&#22411;&#36827;&#34892;&#23457;&#26680;&#26159;&#19968;&#20010;&#24050;&#30693;&#22256;&#38590;&#30340;&#20219;&#21153;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#26469;&#35828;&#65292;&#30001;&#20110;&#28508;&#22312;&#30340;&#23376;&#32676;&#20307;&#25968;&#37327;&#24222;&#22823;&#12290;&#22240;&#27492;&#65292;&#24120;&#35265;&#20570;&#27861;&#26159;&#21482;&#26681;&#25454;&#23569;&#25968;&#39044;&#23450;&#20041;&#30340;&#23376;&#32676;&#20307;&#35780;&#20272;&#26657;&#20934;&#12290;&#26368;&#36817;&#22312;&#25311;&#21512;&#24230;&#26816;&#39564;&#26041;&#38754;&#30340;&#21457;&#23637;&#25552;&#20379;&#20102;&#28508;&#22312;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#23545;&#20110;&#20449;&#21495;&#36739;&#24369;&#25110;&#26657;&#20934;&#19981;&#33391;&#30340;&#23376;&#32676;&#20307;&#36739;&#23567;&#30340;&#24773;&#20917;&#65292;&#36825;&#20123;&#26041;&#27861;&#35201;&#20040;&#36807;&#24230;&#32454;&#20998;&#25968;&#25454;&#65292;&#35201;&#20040;&#26681;&#26412;&#19981;&#36827;&#34892;&#32454;&#20998;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#27979;&#35797;&#36807;&#31243;&#65292;&#22522;&#20110;&#20197;&#19979;&#27934;&#23519;&#65306;&#22914;&#26524;&#25105;&#20204;&#33021;&#22815;&#25353;&#39044;&#26399;&#30340;&#27531;&#24046;&#23545;&#35266;&#27979;&#36827;&#34892;&#37325;&#26032;&#25490;&#24207;&#65292;&#39044;&#27979;&#20540;&#21644;&#35266;&#23519;&#20540;&#20043;&#38388;&#30340;&#20851;&#32852;&#24615;&#24212;&#35813;&#20250;&#21457;&#29983;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
In a well-calibrated risk prediction model, the average predicted probability is close to the true event rate for any given subgroup. Such models are reliable across heterogeneous populations and satisfy strong notions of algorithmic fairness. However, the task of auditing a model for strong calibration is well-known to be difficult -- particularly for machine learning (ML) algorithms -- due to the sheer number of potential subgroups. As such, common practice is to only assess calibration with respect to a few predefined subgroups. Recent developments in goodness-of-fit testing offer potential solutions but are not designed for settings with weak signal or where the poorly calibrated subgroup is small, as they either overly subdivide the data or fail to divide the data at all. We introduce a new testing procedure based on the following insight: if we can reorder observations by their expected residuals, there should be a change in the association between the predicted and observed resi
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35814;&#32454;&#30740;&#31350;&#20102;PCA&#26041;&#27861;&#20013;&#25968;&#25454;&#23621;&#20013;&#21270;&#27493;&#39588;&#30340;&#24433;&#21709;&#65292;&#20998;&#26512;&#20102;&#24102;&#23621;&#20013;&#21270;&#21644;&#19981;&#24102;&#23621;&#20013;&#21270;&#30340;&#20004;&#20010;PCA&#23884;&#20837;&#20043;&#38388;&#30340;&#23545;&#40784;&#24615;&#65292;&#24182;&#25506;&#35752;&#20102;&#20854;&#19982;&#22855;&#24322;&#21521;&#37327;&#20197;&#21450;&#22343;&#20540;&#26041;&#21521;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2307.15213</link><description>&lt;p&gt;
PCA&#12289;SVD&#21644;&#25968;&#25454;&#23621;&#20013;&#21270;
&lt;/p&gt;
&lt;p&gt;
PCA, SVD, and Centering of Data. (arXiv:2307.15213v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15213
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35814;&#32454;&#30740;&#31350;&#20102;PCA&#26041;&#27861;&#20013;&#25968;&#25454;&#23621;&#20013;&#21270;&#27493;&#39588;&#30340;&#24433;&#21709;&#65292;&#20998;&#26512;&#20102;&#24102;&#23621;&#20013;&#21270;&#21644;&#19981;&#24102;&#23621;&#20013;&#21270;&#30340;&#20004;&#20010;PCA&#23884;&#20837;&#20043;&#38388;&#30340;&#23545;&#40784;&#24615;&#65292;&#24182;&#25506;&#35752;&#20102;&#20854;&#19982;&#22855;&#24322;&#21521;&#37327;&#20197;&#21450;&#22343;&#20540;&#26041;&#21521;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35814;&#32454;&#30740;&#31350;&#20102;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;PCA&#65289;&#65292;&#36825;&#26159;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#24120;&#29992;&#30340;&#38477;&#32500;&#26041;&#27861;&#12290;&#22855;&#24322;&#20540;&#20998;&#35299;&#65288;SVD&#65289;&#36890;&#24120;&#34987;&#29992;&#20316;&#35745;&#31639;PCA&#30340;&#20027;&#35201;&#26041;&#27861;&#65292;&#36825;&#20010;&#36807;&#31243;&#20013;&#24517;&#19981;&#21487;&#23569;&#22320;&#21253;&#21547;&#20102;&#25968;&#25454;&#23621;&#20013;&#21270;&#30340;&#27493;&#39588;&#65292;&#21363;&#20174;&#25968;&#25454;&#38598;&#20013;&#20943;&#21435;&#22343;&#20540;&#20301;&#32622;&#12290;&#22312;&#25105;&#20204;&#30340;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#28145;&#20837;&#25506;&#35752;&#20102;&#36825;&#20010;&#20851;&#38190;&#20294;&#24120;&#24120;&#34987;&#24573;&#35270;&#25110;&#36731;&#35270;&#30340;&#25968;&#25454;&#23621;&#20013;&#21270;&#27493;&#39588;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#31934;&#32454;&#22320;&#30740;&#31350;&#20102;&#22312;&#20160;&#20040;&#26465;&#20214;&#19979;&#65292;&#20174;&#24102;&#26377;&#23621;&#20013;&#21270;&#30340;SVD&#21644;&#19981;&#24102;&#23621;&#20013;&#21270;&#30340;SVD&#24471;&#21040;&#30340;&#20004;&#20010;PCA&#23884;&#20837;&#21487;&#20197;&#30475;&#20316;&#26159;&#23545;&#40784;&#30340;&#12290;&#20316;&#20026;&#36825;&#20010;&#25506;&#32034;&#30340;&#19968;&#37096;&#20998;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#31532;&#19968;&#20010;&#22855;&#24322;&#21521;&#37327;&#21644;&#22343;&#20540;&#26041;&#21521;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#38543;&#21518;&#23558;&#36825;&#19968;&#35266;&#23519;&#32467;&#26524;&#19982;&#20013;&#24515;&#21270;&#21644;&#38750;&#20013;&#24515;&#21270;&#30697;&#38453;&#30340;&#20004;&#20010;SVD&#20043;&#38388;&#30340;&#19968;&#33268;&#24615;&#32852;&#31995;&#36215;&#26469;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25506;&#35752;&#20102;&#21487;&#33021;&#20135;&#29983;&#30340;&#30456;&#20851;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
The research detailed in this paper scrutinizes Principal Component Analysis (PCA), a seminal method employed in statistics and machine learning for the purpose of reducing data dimensionality. Singular Value Decomposition (SVD) is often employed as the primary means for computing PCA, a process that indispensably includes the step of centering - the subtraction of the mean location from the data set. In our study, we delve into a detailed exploration of the influence of this critical yet often ignored or downplayed data centering step. Our research meticulously investigates the conditions under which two PCA embeddings, one derived from SVD with centering and the other without, can be viewed as aligned. As part of this exploration, we analyze the relationship between the first singular vector and the mean direction, subsequently linking this observation to the congruity between two SVDs of centered and uncentered matrices. Furthermore, we explore the potential implications arising fro
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#38750;&#31283;&#24577;&#29615;&#22659;&#20013;&#30340;&#32447;&#24615;&#36172;&#21338;&#26426;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#20174;&#19968;&#20010;G-&#26368;&#20248;&#35774;&#35745;&#20013;&#38543;&#26426;&#36873;&#25321;&#33218;&#26469;&#23454;&#29616;&#26368;&#20339;&#33218;&#30340;&#40065;&#26834;&#35782;&#21035;&#12290;</title><link>http://arxiv.org/abs/2307.15154</link><description>&lt;p&gt;
A/B&#27979;&#35797;&#21644;&#20855;&#26377;&#38750;&#31283;&#24577;&#40065;&#26834;&#24615;&#30340;&#32447;&#24615;&#36172;&#21338;&#26426;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
A/B Testing and Best-arm Identification for Linear Bandits with Robustness to Non-stationarity. (arXiv:2307.15154v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15154
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#38750;&#31283;&#24577;&#29615;&#22659;&#20013;&#30340;&#32447;&#24615;&#36172;&#21338;&#26426;&#30340;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#20174;&#19968;&#20010;G-&#26368;&#20248;&#35774;&#35745;&#20013;&#38543;&#26426;&#36873;&#25321;&#33218;&#26469;&#23454;&#29616;&#26368;&#20339;&#33218;&#30340;&#40065;&#26834;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#21487;&#33021;&#23384;&#22312;&#38750;&#31283;&#24577;&#29615;&#22659;&#19979;&#30340;&#32447;&#24615;&#36172;&#21338;&#26426;&#20013;&#30340;&#22266;&#23450;&#39044;&#31639;&#26368;&#20339;&#33218;&#35782;&#21035;&#38382;&#39064;&#12290;&#32473;&#23450;&#26377;&#38480;&#33218;&#38598;&#21512;X&#65292;&#22266;&#23450;&#39044;&#31639;T&#20197;&#21450;&#19981;&#21487;&#39044;&#27979;&#30340;&#21442;&#25968;&#24207;&#21015;&#952;&#65292;&#31639;&#27861;&#30340;&#30446;&#26631;&#26159;&#20197;&#23613;&#21487;&#33021;&#39640;&#30340;&#27010;&#29575;&#27491;&#30830;&#35782;&#21035;&#26368;&#20339;&#33218;x*&#12290;&#20043;&#21069;&#30340;&#24037;&#20316;&#24050;&#32463;&#22312;&#31283;&#24577;&#35774;&#32622;&#19979;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#38169;&#35823;&#27010;&#29575;&#38543;&#30528;&#39044;&#31639;&#30340;&#22686;&#21152;&#32780;&#25351;&#25968;&#19979;&#38477;&#12290;&#20294;&#22312;&#35768;&#22810;&#29616;&#23454;&#19990;&#30028;&#30340;A/B/n&#22810;&#21464;&#37327;&#27979;&#35797;&#22330;&#26223;&#20013;&#65292;&#29615;&#22659;&#26159;&#38750;&#31283;&#24577;&#30340;&#65292;&#32780;&#19968;&#20010;&#26399;&#26395;&#31283;&#24577;&#30340;&#31639;&#27861;&#24456;&#23481;&#26131;&#22833;&#36133;&#12290;&#20026;&#20102;&#20855;&#26377;&#40065;&#26834;&#30340;&#35782;&#21035;&#33021;&#21147;&#65292;&#20247;&#25152;&#21608;&#30693;&#65292;&#22914;&#26524;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#20174;X&#30340;&#19968;&#20010;G-&#26368;&#20248;&#35774;&#35745;&#20013;&#20197;&#38543;&#26426;&#21644;&#38750;&#33258;&#36866;&#24212;&#30340;&#26041;&#24335;&#36873;&#25321;&#33218;&#65292;&#37027;&#20040;&#21487;&#20197;&#23454;&#29616;&#26368;&#20339;&#33218;&#30340;&#40065;&#26834;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the fixed-budget best-arm identification (BAI) problem for linear bandits in a potentially non-stationary environment. Given a finite arm set $\mathcal{X}\subset\mathbb{R}^d$, a fixed budget $T$, and an unpredictable sequence of parameters $\left\lbrace\theta_t\right\rbrace_{t=1}^{T}$, an algorithm will aim to correctly identify the best arm $x^* := \arg\max_{x\in\mathcal{X}}x^\top\sum_{t=1}^{T}\theta_t$ with probability as high as possible. Prior work has addressed the stationary setting where $\theta_t = \theta_1$ for all $t$ and demonstrated that the error probability decreases as $\exp(-T /\rho^*)$ for a problem-dependent constant $\rho^*$. But in many real-world $A/B/n$ multivariate testing scenarios that motivate our work, the environment is non-stationary and an algorithm expecting a stationary setting can easily fail. For robust identification, it is well-known that if arms are chosen randomly and non-adaptively from a G-optimal design over $\mathcal{X}$ at each 
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39046;&#22495;&#20449;&#24687;&#30340;&#20808;&#39564;&#20998;&#24067;&#27169;&#22411;Q-SAVI&#65292;&#33021;&#22815;&#35299;&#20915;&#33647;&#29289;&#21457;&#29616;&#20013;&#26631;&#31614;&#25968;&#25454;&#31232;&#32570;&#21644;&#29305;&#24449;&#36716;&#31227;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#36879;&#26126;&#19988;&#27010;&#29575;&#19978;&#21512;&#29702;&#30340;&#25968;&#25454;&#39537;&#21160;&#27169;&#22411;&#24314;&#27169;&#26041;&#24335;&#12290;</title><link>http://arxiv.org/abs/2307.15073</link><description>&lt;p&gt;
&#22312;&#29305;&#24449;&#36716;&#31227;&#26465;&#20214;&#19979;&#21033;&#29992;&#22522;&#20110;&#39046;&#22495;&#20449;&#24687;&#30340;&#20808;&#39564;&#20998;&#24067;&#36827;&#34892;&#33647;&#29289;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
Drug Discovery under Covariate Shift with Domain-Informed Prior Distributions over Functions. (arXiv:2307.15073v1 [q-bio.BM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15073
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#39046;&#22495;&#20449;&#24687;&#30340;&#20808;&#39564;&#20998;&#24067;&#27169;&#22411;Q-SAVI&#65292;&#33021;&#22815;&#35299;&#20915;&#33647;&#29289;&#21457;&#29616;&#20013;&#26631;&#31614;&#25968;&#25454;&#31232;&#32570;&#21644;&#29305;&#24449;&#36716;&#31227;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#36879;&#26126;&#19988;&#27010;&#29575;&#19978;&#21512;&#29702;&#30340;&#25968;&#25454;&#39537;&#21160;&#27169;&#22411;&#24314;&#27169;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21152;&#36895;&#21457;&#29616;&#26032;&#22411;&#21644;&#26356;&#26377;&#25928;&#30340;&#27835;&#30103;&#33647;&#29289;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#21046;&#33647;&#38382;&#39064;&#65292;&#28145;&#24230;&#23398;&#20064;&#22312;&#20854;&#20013;&#25198;&#28436;&#30528;&#24840;&#21457;&#37325;&#35201;&#30340;&#35282;&#33394;&#12290;&#28982;&#32780;&#65292;&#30495;&#23454;&#19990;&#30028;&#30340;&#33647;&#29289;&#21457;&#29616;&#20219;&#21153;&#36890;&#24120;&#29305;&#28857;&#26159;&#26631;&#31614;&#25968;&#25454;&#31232;&#32570;&#21644;&#26174;&#33879;&#30340;&#29305;&#24449;&#36716;&#31227;&#65292;&#36825;&#23545;&#20110;&#26631;&#20934;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#26500;&#25104;&#20102;&#25361;&#25112;&#12290;&#22312;&#26412;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Q-SAVI&#65292;&#36825;&#26159;&#19968;&#20010;&#27010;&#29575;&#27169;&#22411;&#65292;&#33021;&#22815;&#36890;&#36807;&#23558;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#30340;&#26174;&#24335;&#20808;&#39564;&#30693;&#35782;&#32534;&#30721;&#20026;&#20989;&#25968;&#30340;&#20808;&#39564;&#20998;&#24067;&#65292;&#20026;&#30740;&#31350;&#20154;&#21592;&#25552;&#20379;&#20102;&#19968;&#31181;&#36879;&#26126;&#19988;&#27010;&#29575;&#19978;&#21512;&#29702;&#30340;&#26041;&#24335;&#26469;&#32534;&#30721;&#25968;&#25454;&#39537;&#21160;&#30340;&#24314;&#27169;&#20559;&#22909;&#12290;&#22522;&#20110;&#19968;&#20010;&#26032;&#39062;&#30340;&#65292;&#39640;&#26631;&#20934;&#30340;&#29983;&#29289;&#27963;&#24615;&#25968;&#25454;&#38598;&#65292;&#20351;&#24471;&#22312;&#22806;&#25512;&#27169;&#24335;&#19979;&#33021;&#22815;&#36827;&#34892;&#26377;&#24847;&#20041;&#30340;&#27169;&#22411;&#27604;&#36739;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#19981;&#21516;&#30340;&#26041;&#27861;&#26469;&#35825;&#23548;&#25968;&#25454;&#36716;&#31227;&#24182;&#26500;&#24314;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#35780;&#20272;&#29615;&#22659;&#12290;&#28982;&#21518;&#25105;&#20204;&#35777;&#26126;&#20102;&#20351;&#29992;Q-SAVI&#21487;&#20197;&#22312;&#29305;&#24449;&#36716;&#31227;&#26465;&#20214;&#19979;&#26356;&#22909;&#22320;&#36827;&#34892;&#33647;&#29289;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Accelerating the discovery of novel and more effective therapeutics is an important pharmaceutical problem in which deep learning is playing an increasingly significant role. However, real-world drug discovery tasks are often characterized by a scarcity of labeled data and significant covariate shift$\unicode{x2013}\unicode{x2013}$a setting that poses a challenge to standard deep learning methods. In this paper, we present Q-SAVI, a probabilistic model able to address these challenges by encoding explicit prior knowledge of the data-generating process into a prior distribution over functions, presenting researchers with a transparent and probabilistically principled way to encode data-driven modeling preferences. Building on a novel, gold-standard bioactivity dataset that facilitates a meaningful comparison of models in an extrapolative regime, we explore different approaches to induce data shift and construct a challenging evaluation setup. We then demonstrate that using Q-SAVI to int
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38750;&#21442;&#25968;&#30340;&#27169;&#22411;&#26080;&#20851;&#26694;&#26550;&#65292;&#29992;&#20110;&#24314;&#31435;&#20445;&#38505;&#29702;&#36180;&#30340;&#39044;&#27979;&#21306;&#38388;&#65292;&#24182;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#30340;&#32479;&#35745;&#20445;&#35777;&#65292;&#25193;&#23637;&#20102;split conformal prediction&#25216;&#26415;&#21040;&#20004;&#38454;&#27573;&#39057;&#29575;-&#20005;&#37325;&#24615;&#24314;&#27169;&#39046;&#22495;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#38543;&#26426;&#26862;&#26519;&#20316;&#20026;&#20005;&#37325;&#24615;&#27169;&#22411;&#65292;&#21033;&#29992;&#20102;&#34955;&#22806;&#26426;&#21046;&#28040;&#38500;&#20102;&#26657;&#20934;&#38598;&#30340;&#38656;&#35201;&#65292;&#24182;&#23454;&#29616;&#20102;&#20855;&#26377;&#33258;&#36866;&#24212;&#23485;&#24230;&#30340;&#39044;&#27979;&#21306;&#38388;&#30340;&#29983;&#25104;&#12290;</title><link>http://arxiv.org/abs/2307.13124</link><description>&lt;p&gt;
&#39057;&#29575;-&#20005;&#37325;&#24615;&#24314;&#27169;&#30340;&#31526;&#21512;&#24615;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Conformal prediction for frequency-severity modeling. (arXiv:2307.13124v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13124
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38750;&#21442;&#25968;&#30340;&#27169;&#22411;&#26080;&#20851;&#26694;&#26550;&#65292;&#29992;&#20110;&#24314;&#31435;&#20445;&#38505;&#29702;&#36180;&#30340;&#39044;&#27979;&#21306;&#38388;&#65292;&#24182;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#30340;&#32479;&#35745;&#20445;&#35777;&#65292;&#25193;&#23637;&#20102;split conformal prediction&#25216;&#26415;&#21040;&#20004;&#38454;&#27573;&#39057;&#29575;-&#20005;&#37325;&#24615;&#24314;&#27169;&#39046;&#22495;&#65292;&#24182;&#36890;&#36807;&#20351;&#29992;&#38543;&#26426;&#26862;&#26519;&#20316;&#20026;&#20005;&#37325;&#24615;&#27169;&#22411;&#65292;&#21033;&#29992;&#20102;&#34955;&#22806;&#26426;&#21046;&#28040;&#38500;&#20102;&#26657;&#20934;&#38598;&#30340;&#38656;&#35201;&#65292;&#24182;&#23454;&#29616;&#20102;&#20855;&#26377;&#33258;&#36866;&#24212;&#23485;&#24230;&#30340;&#39044;&#27979;&#21306;&#38388;&#30340;&#29983;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#38750;&#21442;&#25968;&#30340;&#27169;&#22411;&#26080;&#20851;&#26694;&#26550;&#65292;&#29992;&#20110;&#24314;&#31435;&#20445;&#38505;&#29702;&#36180;&#30340;&#39044;&#27979;&#21306;&#38388;&#65292;&#24182;&#20855;&#26377;&#26377;&#38480;&#26679;&#26412;&#30340;&#32479;&#35745;&#20445;&#35777;&#65292;&#23558;&#20998;&#21106;&#31526;&#21512;&#24615;&#39044;&#27979;&#25216;&#26415;&#25193;&#23637;&#21040;&#20004;&#38454;&#27573;&#39057;&#29575;-&#20005;&#37325;&#24615;&#24314;&#27169;&#39046;&#22495;&#12290;&#36890;&#36807;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#23637;&#31034;&#20102;&#35813;&#26694;&#26550;&#30340;&#26377;&#25928;&#24615;&#12290;&#24403;&#22522;&#30784;&#20005;&#37325;&#24615;&#27169;&#22411;&#26159;&#38543;&#26426;&#26862;&#26519;&#26102;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;&#20004;&#38454;&#27573;&#20998;&#21106;&#31526;&#21512;&#24615;&#39044;&#27979;&#36807;&#31243;&#65292;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#34955;&#22806;&#26426;&#21046;&#28040;&#38500;&#26657;&#20934;&#38598;&#30340;&#38656;&#35201;&#65292;&#24182;&#23454;&#29616;&#20855;&#26377;&#33258;&#36866;&#24212;&#23485;&#24230;&#30340;&#39044;&#27979;&#21306;&#38388;&#30340;&#29983;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a nonparametric model-agnostic framework for building prediction intervals of insurance claims, with finite sample statistical guarantees, extending the technique of split conformal prediction to the domain of two-stage frequency-severity modeling. The effectiveness of the framework is showcased with simulated and real datasets. When the underlying severity model is a random forest, we extend the two-stage split conformal prediction procedure, showing how the out-of-bag mechanism can be leveraged to eliminate the need for a calibration set and to enable the production of prediction intervals with adaptive width.
&lt;/p&gt;</description></item><item><title>&#36817;&#31471;&#23884;&#22871;&#25277;&#26679;&#26041;&#27861;&#20801;&#35768;&#29289;&#29702;&#31185;&#23398;&#23478;&#24212;&#29992;&#36125;&#21494;&#26031;&#27169;&#22411;&#36873;&#25321;&#20110;&#39640;&#32500;&#38382;&#39064;&#20013;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#25968;&#25454;&#39537;&#21160;&#20808;&#39564;&#30340;&#25903;&#25345;&#26469;&#25193;&#23637;&#35813;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2307.00056</link><description>&lt;p&gt;
&#29992;&#20110;&#29289;&#29702;&#31185;&#23398;&#23478;&#30340;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#20808;&#39564;&#30340;&#36817;&#31471;&#23884;&#22871;&#25277;&#26679;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Proximal nested sampling with data-driven priors for physical scientists. (arXiv:2307.00056v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00056
&lt;/p&gt;
&lt;p&gt;
&#36817;&#31471;&#23884;&#22871;&#25277;&#26679;&#26041;&#27861;&#20801;&#35768;&#29289;&#29702;&#31185;&#23398;&#23478;&#24212;&#29992;&#36125;&#21494;&#26031;&#27169;&#22411;&#36873;&#25321;&#20110;&#39640;&#32500;&#38382;&#39064;&#20013;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#36890;&#36807;&#25968;&#25454;&#39537;&#21160;&#20808;&#39564;&#30340;&#25903;&#25345;&#26469;&#25193;&#23637;&#35813;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#24341;&#20837;&#20102;&#36817;&#31471;&#23884;&#22871;&#25277;&#26679;&#26041;&#27861;&#65292;&#20197;&#24320;&#36767;&#36125;&#21494;&#26031;&#27169;&#22411;&#36873;&#25321;&#22312;&#39640;&#32500;&#38382;&#39064;&#20013;&#30340;&#24212;&#29992;&#65292;&#20363;&#22914;&#35745;&#31639;&#25104;&#20687;&#12290;&#35813;&#26694;&#26550;&#36866;&#29992;&#20110;&#20855;&#26377;&#23545;&#25968;&#20984;&#20284;&#28982;&#20989;&#25968;&#30340;&#27169;&#22411;&#65292;&#36825;&#22312;&#25104;&#20687;&#31185;&#23398;&#20013;&#38750;&#24120;&#26222;&#36941;&#12290;&#26412;&#25991;&#26377;&#20004;&#20010;&#30446;&#30340;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#20197;&#25945;&#23398;&#30340;&#26041;&#24335;&#23545;&#36817;&#31471;&#23884;&#22871;&#25277;&#26679;&#26041;&#27861;&#36827;&#34892;&#32508;&#36848;&#65292;&#20197;&#21162;&#21147;&#20026;&#29289;&#29702;&#31185;&#23398;&#23478;&#35299;&#37322;&#35813;&#26694;&#26550;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36817;&#31471;&#23884;&#22871;&#25277;&#26679;&#26041;&#27861;&#22914;&#20309;&#22312;&#32463;&#39564;&#36125;&#21494;&#26031;&#35774;&#32622;&#20013;&#25193;&#23637;&#65292;&#20197;&#25903;&#25345;&#25968;&#25454;&#39537;&#21160;&#30340;&#20808;&#39564;&#65292;&#22914;&#20174;&#35757;&#32451;&#25968;&#25454;&#20013;&#23398;&#20064;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;
Proximal nested sampling was introduced recently to open up Bayesian model selection for high-dimensional problems such as computational imaging. The framework is suitable for models with a log-convex likelihood, which are ubiquitous in the imaging sciences. The purpose of this article is two-fold. First, we review proximal nested sampling in a pedagogical manner in an attempt to elucidate the framework for physical scientists. Second, we show how proximal nested sampling can be extended in an empirical Bayes setting to support data-driven priors, such as deep neural networks learned from training data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22522;&#20110;&#33258;&#23450;&#20041;&#28151;&#21512;&#33410;&#28857; Forney &#26679;&#24335;&#30340;&#22240;&#23376;&#22270;&#28040;&#24687;&#20256;&#36882;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#33258;&#21160;&#21270;&#36125;&#21494;&#26031;&#27169;&#22411;&#24179;&#22343;&#12289;&#36873;&#25321;&#21644;&#32452;&#21512;&#65292;&#24182;&#32553;&#30701;&#20102;&#27169;&#22411;&#35774;&#35745;&#21608;&#26399;&#12290;</title><link>http://arxiv.org/abs/2306.05965</link><description>&lt;p&gt;
&#22312;&#22240;&#23376;&#22270;&#20013;&#33258;&#21160;&#36827;&#34892;&#27169;&#22411;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
Automating Model Comparison in Factor Graphs. (arXiv:2306.05965v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05965
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22522;&#20110;&#33258;&#23450;&#20041;&#28151;&#21512;&#33410;&#28857; Forney &#26679;&#24335;&#30340;&#22240;&#23376;&#22270;&#28040;&#24687;&#20256;&#36882;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#33258;&#21160;&#21270;&#36125;&#21494;&#26031;&#27169;&#22411;&#24179;&#22343;&#12289;&#36873;&#25321;&#21644;&#32452;&#21512;&#65292;&#24182;&#32553;&#30701;&#20102;&#27169;&#22411;&#35774;&#35745;&#21608;&#26399;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25991;&#29486;&#20013;&#65292;&#36125;&#21494;&#26031;&#29366;&#24577;&#21644;&#21442;&#25968;&#20272;&#35745;&#24050;&#32463;&#34987;&#26377;&#25928;&#33258;&#21160;&#21270;&#65292;&#20294;&#23545;&#20110;&#27169;&#22411;&#27604;&#36739;&#23578;&#26410;&#22914;&#27492;&#65292;&#22240;&#27492;&#20173;&#38656;&#35201;&#23481;&#26131;&#20986;&#38169;&#21644;&#32791;&#26102;&#30340;&#25163;&#21160;&#25512;&#23548;&#12290;&#22240;&#27492;&#65292;&#27169;&#22411;&#27604;&#36739;&#32463;&#24120;&#34987;&#24573;&#35270;&#21644;&#24573;&#30053;&#65292;&#23613;&#31649;&#23427;&#24456;&#37325;&#35201;&#12290;&#26412;&#25991;&#36890;&#36807;&#22312;Forney&#26679;&#24335;&#30340;&#22240;&#23376;&#22270;&#19978;&#20351;&#29992;&#33258;&#23450;&#20041;&#28151;&#21512;&#33410;&#28857;&#19978;&#30340;&#28040;&#24687;&#20256;&#36882;&#26469;&#39640;&#25928;&#22320;&#33258;&#21160;&#21270;&#36125;&#21494;&#26031;&#27169;&#22411;&#24179;&#22343;&#12289;&#36873;&#25321;&#21644;&#32452;&#21512;&#12290;&#36827;&#32780;&#21487;&#20351;&#29992;&#32553;&#25918;&#22240;&#23376;&#21516;&#26102;&#25191;&#34892;&#21442;&#25968;&#21644;&#29366;&#24577;&#25512;&#26029;&#20197;&#21450;&#27169;&#22411;&#27604;&#36739;&#12290;&#36825;&#31181;&#26041;&#27861;&#32553;&#30701;&#20102;&#27169;&#22411;&#35774;&#35745;&#21608;&#26399;&#65292;&#21516;&#26102;&#20801;&#35768;&#31616;&#21333;&#22320;&#25193;&#23637;&#21040;&#20998;&#23618;&#21644;&#26102;&#38388;&#27169;&#22411;&#20808;&#39564;&#65292;&#20197;&#36866;&#24212;&#24314;&#27169;&#22797;&#26434;&#30340;&#26102;&#21464;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian state and parameter estimation have been automated effectively in the literature, however, this has not yet been the case for model comparison, which therefore still requires error-prone and time-consuming manual derivations. As a result, model comparison is often overlooked and ignored, despite its importance. This paper efficiently automates Bayesian model averaging, selection, and combination by message passing on a Forney-style factor graph with a custom mixture node. Parameter and state inference, and model comparison can then be executed simultaneously using message passing with scale factors. This approach shortens the model design cycle and allows for the straightforward extension to hierarchical and temporal model priors to accommodate for modeling complicated time-varying processes.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#20998;&#26512;Hugging Face&#19978;1,417&#20010;ML&#27169;&#22411;&#21450;&#30456;&#20851;&#25968;&#25454;&#38598;&#30340;&#30899;&#36275;&#36857;&#27979;&#37327;&#24773;&#20917;&#65292;&#25552;&#20986;&#20102;&#26377;&#20851;&#22914;&#20309;&#25253;&#21578;&#21644;&#20248;&#21270;ML&#27169;&#22411;&#30340;&#30899;&#25928;&#29575;&#30340;&#35265;&#35299;&#21644;&#24314;&#35758;&#12290;</title><link>http://arxiv.org/abs/2305.11164</link><description>&lt;p&gt;
&#25506;&#32034;&#25265;&#25265;&#33080;ML&#27169;&#22411;&#30340;&#30899;&#36275;&#36857;&#65306;&#19968;&#39033;&#23384;&#20648;&#24211;&#25366;&#25496;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Exploring the Carbon Footprint of Hugging Face's ML Models: A Repository Mining Study. (arXiv:2305.11164v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11164
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#20998;&#26512;Hugging Face&#19978;1,417&#20010;ML&#27169;&#22411;&#21450;&#30456;&#20851;&#25968;&#25454;&#38598;&#30340;&#30899;&#36275;&#36857;&#27979;&#37327;&#24773;&#20917;&#65292;&#25552;&#20986;&#20102;&#26377;&#20851;&#22914;&#20309;&#25253;&#21578;&#21644;&#20248;&#21270;ML&#27169;&#22411;&#30340;&#30899;&#25928;&#29575;&#30340;&#35265;&#35299;&#21644;&#24314;&#35758;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;(ML)&#31995;&#32479;&#30340;&#23835;&#36215;&#21152;&#21095;&#20102;&#23427;&#20204;&#30340;&#30899;&#36275;&#36857;&#65292;&#36825;&#26159;&#30001;&#20110;&#20854;&#22686;&#21152;&#30340;&#33021;&#21147;&#21644;&#27169;&#22411;&#22823;&#23567;&#25152;&#33268;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#23545;ML&#27169;&#22411;&#30340;&#30899;&#36275;&#36857;&#22914;&#20309;&#23454;&#38469;&#27979;&#37327;&#12289;&#25253;&#21578;&#21644;&#35780;&#20272;&#30340;&#35748;&#35782;&#30456;&#23545;&#36739;&#23569;&#12290;&#22240;&#27492;&#65292;&#26412;&#35770;&#25991;&#26088;&#22312;&#20998;&#26512;&#22312;Hugging Face&#19978;1,417&#20010;ML&#27169;&#22411;&#21644;&#30456;&#20851;&#25968;&#25454;&#38598;&#30340;&#30899;&#36275;&#36857;&#27979;&#37327;&#24773;&#20917;&#65292;Hugging Face&#26159;&#26368;&#21463;&#27426;&#36814;&#30340;&#39044;&#35757;&#32451;ML&#27169;&#22411;&#30340;&#23384;&#20648;&#24211;&#12290;&#30446;&#26631;&#26159;&#25552;&#20379;&#26377;&#20851;&#22914;&#20309;&#25253;&#21578;&#21644;&#20248;&#21270;ML&#27169;&#22411;&#30340;&#30899;&#25928;&#29575;&#30340;&#35265;&#35299;&#21644;&#24314;&#35758;&#12290;&#35813;&#30740;&#31350;&#21253;&#25324;Hugging Face Hub API&#19978;&#26377;&#20851;&#30899;&#25490;&#25918;&#30340;&#31532;&#19968;&#39033;&#23384;&#20648;&#24211;&#25366;&#25496;&#30740;&#31350;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#22238;&#31572;&#20004;&#20010;&#30740;&#31350;&#38382;&#39064;&#65306;(1) ML&#27169;&#22411;&#30340;&#21019;&#24314;&#32773;&#22914;&#20309;&#22312;Hugging Face Hub&#19978;&#27979;&#37327;&#21644;&#25253;&#21578;&#30899;&#25490;&#25918;&#65311;(2) &#21738;&#20123;&#26041;&#38754;&#24433;&#21709;&#20102;&#35757;&#32451;ML&#27169;&#22411;&#30340;&#30899;&#25490;&#25918;&#65311;&#35813;&#30740;&#31350;&#24471;&#20986;&#20102;&#20960;&#20010;&#20851;&#38190;&#21457;&#29616;&#12290;&#20854;&#20013;&#21253;&#25324;&#30899;&#25490;&#25918;&#25253;&#21578;&#27169;&#24335;&#27604;&#20363;&#30340;&#36880;&#27493;&#19979;&#38477;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;
The rise of machine learning (ML) systems has exacerbated their carbon footprint due to increased capabilities and model sizes. However, there is scarce knowledge on how the carbon footprint of ML models is actually measured, reported, and evaluated. In light of this, the paper aims to analyze the measurement of the carbon footprint of 1,417 ML models and associated datasets on Hugging Face, which is the most popular repository for pretrained ML models. The goal is to provide insights and recommendations on how to report and optimize the carbon efficiency of ML models. The study includes the first repository mining study on the Hugging Face Hub API on carbon emissions. This study seeks to answer two research questions: (1) how do ML model creators measure and report carbon emissions on Hugging Face Hub?, and (2) what aspects impact the carbon emissions of training ML models? The study yielded several key findings. These include a decreasing proportion of carbon emissions-reporting mode
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;&#65292;CUQB&#65292;&#26469;&#35299;&#20915;&#22797;&#21512;&#20989;&#25968;&#65288;&#28151;&#21512;&#27169;&#22411;&#65289;&#30340;&#39640;&#25928;&#32422;&#26463;&#20840;&#23616;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#25928;&#26524;&#65292;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#30340;&#24212;&#29992;&#31243;&#24207;&#20013;&#22343;&#24471;&#21040;&#20102;&#39564;&#35777;&#65292;&#21253;&#25324;&#36827;&#34892;&#20102;&#26368;&#20248;&#25511;&#21046;&#30340;&#27969;&#20307;&#27969;&#37327;&#21644;&#25299;&#25169;&#32467;&#26500;&#20248;&#21270;&#65292;&#21518;&#32773;&#27604;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#35774;&#35745;&#24378;2&#20493;&#12290;</title><link>http://arxiv.org/abs/2305.03824</link><description>&lt;p&gt;
&#26080;&#36951;&#25022;&#30340;&#32422;&#26463;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#29992;&#20110;&#24102;&#26377;&#22122;&#22768;&#21644;&#26114;&#36149;&#28151;&#21512;&#27169;&#22411;&#30340;&#24046;&#20998;&#20998;&#20301;&#25968;&#20989;&#25968;&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
No-Regret Constrained Bayesian Optimization of Noisy and Expensive Hybrid Models using Differentiable Quantile Function Approximations. (arXiv:2305.03824v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.03824
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;&#65292;CUQB&#65292;&#26469;&#35299;&#20915;&#22797;&#21512;&#20989;&#25968;&#65288;&#28151;&#21512;&#27169;&#22411;&#65289;&#30340;&#39640;&#25928;&#32422;&#26463;&#20840;&#23616;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#21462;&#24471;&#20102;&#33391;&#22909;&#30340;&#25928;&#26524;&#65292;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#30340;&#24212;&#29992;&#31243;&#24207;&#20013;&#22343;&#24471;&#21040;&#20102;&#39564;&#35777;&#65292;&#21253;&#25324;&#36827;&#34892;&#20102;&#26368;&#20248;&#25511;&#21046;&#30340;&#27969;&#20307;&#27969;&#37327;&#21644;&#25299;&#25169;&#32467;&#26500;&#20248;&#21270;&#65292;&#21518;&#32773;&#27604;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#35774;&#35745;&#24378;2&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22797;&#21512;&#20989;&#25968;&#65288;&#28151;&#21512;&#27169;&#22411;&#65289;&#30340;&#39640;&#25928;&#32422;&#26463;&#20840;&#23616;&#20248;&#21270;&#38382;&#39064;&#65292;&#35813;&#27169;&#22411;&#30340;&#36755;&#20837;&#26159;&#20855;&#26377;&#30690;&#37327;&#20540;&#36755;&#20986;&#21644;&#26377;&#22122;&#22768;&#35266;&#27979;&#30340;&#26114;&#36149;&#40657;&#30418;&#20989;&#25968;&#65292;&#36825;&#22312;&#23454;&#38469;&#30340;&#31185;&#23398;&#12289;&#24037;&#31243;&#12289;&#21046;&#36896;&#21644;&#25511;&#21046;&#24212;&#29992;&#20013;&#32463;&#24120;&#20986;&#29616;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;Constrained Upper Quantile Bound&#65288;CUQB&#65289;&#65292;&#29992;&#20110;&#35299;&#20915;&#36825;&#31181;&#38382;&#39064;&#65292;&#30452;&#25509;&#21033;&#29992;&#20102;&#25105;&#20204;&#23637;&#31034;&#30340;&#30446;&#26631;&#21644;&#32422;&#26463;&#20989;&#25968;&#30340;&#22797;&#21512;&#32467;&#26500;&#65292;&#20174;&#32780;&#22823;&#22823;&#25552;&#39640;&#20102;&#37319;&#26679;&#25928;&#29575;&#12290;CUQB&#30340;&#27010;&#24565;&#31616;&#21333;&#65292;&#36991;&#20813;&#20102;&#20808;&#21069;&#26041;&#27861;&#25152;&#20351;&#29992;&#30340;&#32422;&#26463;&#36924;&#36817;&#12290;&#34429;&#28982;CUQB&#30340;&#25910;&#36141;&#20989;&#25968;&#19981;&#22312;&#23553;&#38381;&#24418;&#24335;&#20013;&#65292;&#20294;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21487;&#24494;&#38543;&#26426;&#36924;&#36817;&#65292;&#20351;&#20854;&#33021;&#22815;&#26377;&#25928;&#22320;&#26368;&#22823;&#21270;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#24471;&#20986;&#20102;&#23545;&#20110;&#32047;&#31215;&#36951;&#25022;&#21644;&#32422;&#26463;&#36829;&#35268;&#30340;&#30028;&#38480;&#12290;&#30001;&#20110;&#22312;&#26576;&#20123;&#35268;&#21017;&#20551;&#35774;&#19979;&#36825;&#20123;&#30028;&#38480;&#23545;&#36845;&#20195;&#27425;&#25968;&#20855;&#26377;&#27425;&#32447;&#24615;&#20381;&#36182;&#24615;&#65292;&#22240;&#27492;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#28176;&#36817;&#24847;&#20041;&#19979;&#26080;&#36951;&#25022;&#24182;&#28385;&#36275;&#32422;&#26463;&#26465;&#20214;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#21512;&#25104;&#21644;&#30495;&#23454;&#30340;&#24212;&#29992;&#31243;&#24207;&#20013;&#23637;&#31034;&#20102;CUQB&#30340;&#21151;&#25928;&#65292;&#21253;&#25324;&#26725;&#26550;&#25299;&#25169; - &#22312;&#20854;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#30340;&#32467;&#26500;&#27604;&#24403;&#21069;&#26368;&#20808;&#36827;&#30340;&#35774;&#35745;&#24378;2&#20493; - &#20197;&#21450;&#27969;&#20307;&#27969;&#37327;&#30340;&#26368;&#20248;&#25511;&#21046;&#65292;&#20854;&#20013;&#25105;&#20204;&#20351;&#29992;&#30340;&#26041;&#27861;&#27604;&#20197;&#21069;&#30340;&#26041;&#27861;&#23569;&#20102;3&#20493;&#30340;&#27169;&#25311;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates the problem of efficient constrained global optimization of composite functions (hybrid models) whose input is an expensive black-box function with vector-valued outputs and noisy observations, which often arises in real-world science, engineering, manufacturing, and control applications. We propose a novel algorithm, Constrained Upper Quantile Bound (CUQB), to solve such problems that directly exploits the composite structure of the objective and constraint functions that we show leads substantially improved sampling efficiency. CUQB is conceptually simple and avoids the constraint approximations used by previous methods. Although the CUQB acquisition function is not available in closed form, we propose a novel differentiable stochastic approximation that enables it to be efficiently maximized. We further derive bounds on the cumulative regret and constraint violation. Since these bounds depend sublinearly on the number of iterations under some regularity assum
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;&#35774;&#35745;&#30340;&#31526;&#21512;&#24615;&#39044;&#27979;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#29983;&#25104;&#36866;&#29992;&#20110;&#21508;&#31181;&#39044;&#27979;&#27169;&#22411;&#30340;&#39044;&#27979;&#21306;&#38388;&#65292;&#24182;&#20445;&#35777;&#26377;&#38480;&#26679;&#26412;&#35206;&#30422;&#29575;&#12290;&#25105;&#20204;&#36992;&#35831;&#35843;&#26597;&#26041;&#27861;&#23398;&#23478;&#20351;&#29992;&#21644;&#36129;&#29486;&#36825;&#20123;&#26041;&#27861;&#65292;&#36890;&#36807;&#20171;&#32461;&#22914;&#20309;&#23558;&#20854;&#24212;&#29992;&#20110;&#22797;&#26434;&#26679;&#26412;&#35843;&#26597;&#35774;&#35745;&#25968;&#25454;&#65292;&#24182;&#25351;&#20986;&#35843;&#26597;&#26041;&#27861;&#23398;&#23478;&#21487;&#20197;&#22312;&#20854;&#20013;&#21457;&#25381;&#19987;&#19994;&#30693;&#35782;&#30340;&#39046;&#22495;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#29702;&#35770;&#20445;&#35777;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#36890;&#36807;&#23454;&#38469;&#25968;&#25454;&#31034;&#20363;&#23637;&#31034;&#20102;&#31526;&#21512;&#24615;&#39044;&#27979;&#22312;&#23454;&#36341;&#20013;&#30340;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2303.01422</link><description>&lt;p&gt;
&#22522;&#20110;&#35774;&#35745;&#30340;&#31526;&#21512;&#24615;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Design-based conformal prediction. (arXiv:2303.01422v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.01422
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#22522;&#20110;&#35774;&#35745;&#30340;&#31526;&#21512;&#24615;&#39044;&#27979;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#29983;&#25104;&#36866;&#29992;&#20110;&#21508;&#31181;&#39044;&#27979;&#27169;&#22411;&#30340;&#39044;&#27979;&#21306;&#38388;&#65292;&#24182;&#20445;&#35777;&#26377;&#38480;&#26679;&#26412;&#35206;&#30422;&#29575;&#12290;&#25105;&#20204;&#36992;&#35831;&#35843;&#26597;&#26041;&#27861;&#23398;&#23478;&#20351;&#29992;&#21644;&#36129;&#29486;&#36825;&#20123;&#26041;&#27861;&#65292;&#36890;&#36807;&#20171;&#32461;&#22914;&#20309;&#23558;&#20854;&#24212;&#29992;&#20110;&#22797;&#26434;&#26679;&#26412;&#35843;&#26597;&#35774;&#35745;&#25968;&#25454;&#65292;&#24182;&#25351;&#20986;&#35843;&#26597;&#26041;&#27861;&#23398;&#23478;&#21487;&#20197;&#22312;&#20854;&#20013;&#21457;&#25381;&#19987;&#19994;&#30693;&#35782;&#30340;&#39046;&#22495;&#12290;&#23454;&#39564;&#35777;&#26126;&#20102;&#29702;&#35770;&#20445;&#35777;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#36890;&#36807;&#23454;&#38469;&#25968;&#25454;&#31034;&#20363;&#23637;&#31034;&#20102;&#31526;&#21512;&#24615;&#39044;&#27979;&#22312;&#23454;&#36341;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31526;&#21512;&#24615;&#39044;&#27979;&#26159;&#19968;&#31181;&#19981;&#20381;&#36182;&#20110;&#20551;&#35774;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104;&#26080;&#20998;&#24067;&#30340;&#39044;&#27979;&#21306;&#38388;&#25110;&#38598;&#21512;&#65292;&#36866;&#29992;&#20110;&#20960;&#20046;&#20219;&#20309;&#39044;&#27979;&#27169;&#22411;&#65292;&#24182;&#19988;&#20855;&#26377;&#20445;&#35777;&#30340;&#26377;&#38480;&#26679;&#26412;&#35206;&#30422;&#29575;&#12290;&#31526;&#21512;&#24615;&#26041;&#27861;&#22312;&#32479;&#35745;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#26159;&#19968;&#20010;&#27963;&#36291;&#30340;&#30740;&#31350;&#20027;&#39064;&#65292;&#20294;&#36817;&#26399;&#25165;&#34987;&#25193;&#23637;&#21040;&#38750;&#21487;&#20132;&#25442;&#25968;&#25454;&#19978;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36992;&#35831;&#35843;&#26597;&#26041;&#27861;&#23398;&#23478;&#24320;&#22987;&#20351;&#29992;&#21644;&#36129;&#29486;&#31526;&#21512;&#24615;&#26041;&#27861;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#22914;&#20309;&#23558;&#31526;&#21512;&#24615;&#39044;&#27979;&#24212;&#29992;&#20110;&#20960;&#31181;&#24120;&#35265;&#30340;&#22797;&#26434;&#26679;&#26412;&#35843;&#26597;&#35774;&#35745;&#25968;&#25454;&#19978;&#65292;&#36890;&#36807;&#26377;&#38480;&#24635;&#20307;&#35774;&#35745;&#25512;&#26029;&#30340;&#26694;&#26550;&#65292;&#21516;&#26102;&#25351;&#20986;&#35843;&#26597;&#26041;&#27861;&#23398;&#23478;&#21487;&#20197;&#26377;&#30410;&#22320;&#24212;&#29992;&#20854;&#19987;&#19994;&#30693;&#35782;&#30340;&#39046;&#22495;&#12290;&#25105;&#20204;&#30340;&#27169;&#25311;&#23454;&#39564;&#20174;&#32463;&#39564;&#19978;&#39564;&#35777;&#20102;&#26377;&#38480;&#26679;&#26412;&#35206;&#30422;&#29575;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#25105;&#20204;&#30340;&#23454;&#38469;&#25968;&#25454;&#31034;&#20363;&#23637;&#31034;&#20102;&#31526;&#21512;&#24615;&#39044;&#27979;&#22914;&#20309;&#22312;&#23454;&#36341;&#20013;&#24212;&#29992;&#20110;&#22797;&#26434;&#26679;&#26412;&#35843;&#26597;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Conformal prediction is an assumption-lean approach to generating distribution-free prediction intervals or sets, for nearly arbitrary predictive models, with guaranteed finite-sample coverage. Conformal methods are an active research topic in statistics and machine learning, but only recently have they been extended to non-exchangeable data. In this paper, we invite survey methodologists to begin using and contributing to conformal methods. We introduce how conformal prediction can be applied to data from several common complex sample survey designs, under a framework of design-based inference for a finite population, and we point out gaps where survey methodologists could fruitfully apply their expertise. Our simulations empirically bear out the theoretical guarantees of finite-sample coverage, and our real-data example demonstrates how conformal prediction can be applied to complex sample survey data in practice.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#35299;&#20915;&#38750;&#31283;&#24577;&#36172;&#21338;&#26426;&#23450;&#20041;&#27495;&#20041;&#30340;&#26032;&#23450;&#20041;&#65292;&#35299;&#20915;&#20102;&#20043;&#21069;&#23450;&#20041;&#20013;&#30340;&#38382;&#39064;&#24182;&#20462;&#22797;&#20102;&#20195;&#29702;&#35774;&#35745;&#20013;&#25506;&#32034;&#36807;&#24230;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2302.12202</link><description>&lt;p&gt;
&#38750;&#31283;&#24577;&#36172;&#21338;&#26426;&#30340;&#23450;&#20041;
&lt;/p&gt;
&lt;p&gt;
A Definition of Non-Stationary Bandits. (arXiv:2302.12202v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.12202
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#35299;&#20915;&#38750;&#31283;&#24577;&#36172;&#21338;&#26426;&#23450;&#20041;&#27495;&#20041;&#30340;&#26032;&#23450;&#20041;&#65292;&#35299;&#20915;&#20102;&#20043;&#21069;&#23450;&#20041;&#20013;&#30340;&#38382;&#39064;&#24182;&#20462;&#22797;&#20102;&#20195;&#29702;&#35774;&#35745;&#20013;&#25506;&#32034;&#36807;&#24230;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#38750;&#31283;&#24577;&#36172;&#21338;&#26426;&#23398;&#20064;&#30340;&#35838;&#39064;&#21560;&#24341;&#20102;&#26368;&#36817;&#30340;&#24456;&#22810;&#20851;&#27880;&#65292;&#20294;&#25105;&#20204;&#36824;&#27809;&#26377;&#25214;&#21040;&#19968;&#20010;&#33021;&#22815;&#21306;&#20998;&#38750;&#31283;&#24577;&#36172;&#21338;&#26426;&#21644;&#31283;&#24577;&#36172;&#21338;&#26426;&#30340;&#24418;&#24335;&#23450;&#20041;&#12290;&#20043;&#21069;&#30340;&#30740;&#31350;&#23558;&#38750;&#31283;&#24577;&#36172;&#21338;&#26426;&#23450;&#20041;&#20026;&#22870;&#21169;&#20998;&#24067;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#36172;&#21338;&#26426;&#12290;&#25105;&#20204;&#35777;&#26126;&#36825;&#20010;&#23450;&#20041;&#22312;&#23558;&#21516;&#19968;&#20010;&#36172;&#21338;&#26426;&#21516;&#26102;&#20998;&#31867;&#20026;&#31283;&#24577;&#21644;&#38750;&#31283;&#24577;&#26102;&#23384;&#22312;&#27495;&#20041;&#65307;&#36825;&#31181;&#27495;&#20041;&#28304;&#20110;&#35813;&#23450;&#20041;&#23545;&#28508;&#22312;&#22870;&#21169;&#20998;&#24067;&#24207;&#21015;&#30340;&#20381;&#36182;&#12290;&#27492;&#22806;&#65292;&#36825;&#20010;&#23450;&#20041;&#20063;&#23548;&#33268;&#20102;&#20004;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#36951;&#25022;&#27010;&#24565;&#65306;&#21160;&#24577;&#36951;&#25022;&#21644;&#24369;&#36951;&#25022;&#12290;&#36825;&#20123;&#27010;&#24565;&#22312;&#19968;&#20123;&#36172;&#21338;&#26426;&#20013;&#24182;&#19981;&#33021;&#20934;&#30830;&#22320;&#21453;&#26144;&#20195;&#29702;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#36825;&#20010;&#38750;&#31283;&#24577;&#36172;&#21338;&#26426;&#30340;&#23450;&#20041;&#36824;&#23548;&#33268;&#20102;&#25506;&#32034;&#36807;&#24230;&#30340;&#20195;&#29702;&#35774;&#35745;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#30340;&#38750;&#31283;&#24577;&#36172;&#21338;&#26426;&#30340;&#24418;&#24335;&#23450;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the subject of non-stationary bandit learning having attracted much recent attention, we have yet to identify a formal definition of non-stationarity that can consistently distinguish non-stationary bandits from stationary ones. Prior work has characterized non-stationary bandits as bandits for which the reward distribution changes over time. We demonstrate that this definition can ambiguously classify the same bandit as both stationary and non-stationary; this ambiguity arises in the existing definition's dependence on the latent sequence of reward distributions. Moreover, the definition has given rise to two widely used notions of regret: the dynamic regret and the weak regret. These notions are not indicative of qualitative agent performance in some bandits. Additionally, this definition of non-stationary bandits has led to the design of agents that explore excessively. We introduce a formal definition of non-stationary bandits that resolves these issues. Our new definition 
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21518;&#26399;&#24773;&#33410;&#24335;&#24378;&#21270;&#23398;&#20064;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#35780;&#20272;&#21453;&#20107;&#23454;&#30340;&#33258;&#36866;&#24212;&#31574;&#30053;&#24182;&#20272;&#35745;&#21160;&#24577;&#22788;&#29702;&#25928;&#24212;&#65292;&#36890;&#36807;&#37325;&#26032;&#21152;&#26435;&#30340;$Z$-&#20272;&#35745;&#26041;&#27861;&#31283;&#23450;&#24773;&#33410;&#21464;&#21270;&#30340;&#20272;&#35745;&#26041;&#24046;&#12290;</title><link>http://arxiv.org/abs/2302.08854</link><description>&lt;p&gt;
&#21518;&#26399;&#24773;&#33410;&#24335;&#24378;&#21270;&#23398;&#20064;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Post-Episodic Reinforcement Learning Inference. (arXiv:2302.08854v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.08854
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21518;&#26399;&#24773;&#33410;&#24335;&#24378;&#21270;&#23398;&#20064;&#25512;&#26029;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#35780;&#20272;&#21453;&#20107;&#23454;&#30340;&#33258;&#36866;&#24212;&#31574;&#30053;&#24182;&#20272;&#35745;&#21160;&#24577;&#22788;&#29702;&#25928;&#24212;&#65292;&#36890;&#36807;&#37325;&#26032;&#21152;&#26435;&#30340;$Z$-&#20272;&#35745;&#26041;&#27861;&#31283;&#23450;&#24773;&#33410;&#21464;&#21270;&#30340;&#20272;&#35745;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20174;&#24773;&#33410;&#24335;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#25910;&#38598;&#30340;&#25968;&#25454;&#36827;&#34892;&#20272;&#35745;&#21644;&#25512;&#26029;&#65307;&#21363;&#22312;&#27599;&#20010;&#26102;&#26399;&#65288;&#20063;&#31216;&#20026;&#24773;&#33410;&#65289;&#20197;&#39034;&#24207;&#26041;&#24335;&#19982;&#21333;&#20010;&#21463;&#35797;&#21333;&#20803;&#22810;&#27425;&#20132;&#20114;&#30340;&#33258;&#36866;&#24212;&#35797;&#39564;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#22312;&#25910;&#38598;&#25968;&#25454;&#21518;&#33021;&#22815;&#35780;&#20272;&#21453;&#20107;&#23454;&#30340;&#33258;&#36866;&#24212;&#31574;&#30053;&#65292;&#24182;&#20272;&#35745;&#32467;&#26500;&#21442;&#25968;&#65292;&#22914;&#21160;&#24577;&#22788;&#29702;&#25928;&#24212;&#65292;&#36825;&#21487;&#20197;&#29992;&#20110;&#20449;&#29992;&#20998;&#37197;&#65288;&#20363;&#22914;&#65292;&#31532;&#19968;&#20010;&#26102;&#26399;&#30340;&#34892;&#21160;&#23545;&#26368;&#32456;&#32467;&#26524;&#30340;&#24433;&#21709;&#65289;&#12290;&#36825;&#20123;&#24863;&#20852;&#36259;&#30340;&#21442;&#25968;&#21487;&#20197;&#26500;&#25104;&#30697;&#26041;&#31243;&#30340;&#35299;&#65292;&#20294;&#19981;&#26159;&#24635;&#20307;&#25439;&#22833;&#20989;&#25968;&#30340;&#26368;&#23567;&#21270;&#22120;&#65292;&#22312;&#38745;&#24577;&#25968;&#25454;&#24773;&#20917;&#19979;&#23548;&#33268;&#20102;$Z$-&#20272;&#35745;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#36825;&#26679;&#30340;&#20272;&#35745;&#37327;&#22312;&#33258;&#36866;&#24212;&#25968;&#25454;&#25910;&#38598;&#30340;&#24773;&#20917;&#19979;&#19981;&#33021;&#28176;&#36817;&#27491;&#24577;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#37325;&#26032;&#21152;&#26435;&#30340;$Z$-&#20272;&#35745;&#26041;&#27861;&#65292;&#20351;&#29992;&#31934;&#24515;&#35774;&#35745;&#30340;&#33258;&#36866;&#24212;&#26435;&#37325;&#26469;&#31283;&#23450;&#24773;&#33410;&#21464;&#21270;&#30340;&#20272;&#35745;&#26041;&#24046;&#65292;&#36825;&#26159;&#30001;&#38750;...
&lt;/p&gt;
&lt;p&gt;
We consider estimation and inference with data collected from episodic reinforcement learning (RL) algorithms; i.e. adaptive experimentation algorithms that at each period (aka episode) interact multiple times in a sequential manner with a single treated unit. Our goal is to be able to evaluate counterfactual adaptive policies after data collection and to estimate structural parameters such as dynamic treatment effects, which can be used for credit assignment (e.g. what was the effect of the first period action on the final outcome). Such parameters of interest can be framed as solutions to moment equations, but not minimizers of a population loss function, leading to $Z$-estimation approaches in the case of static data. However, such estimators fail to be asymptotically normal in the case of adaptive data collection. We propose a re-weighted $Z$-estimation approach with carefully designed adaptive weights to stabilize the episode-varying estimation variance, which results from the non
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#39564;&#35777;&#22522;&#20110;&#26377;&#20559;&#25968;&#25454;&#35757;&#32451;&#30340;&#39044;&#27979;&#27169;&#22411;&#30340;&#20844;&#24179;&#24615;&#12290;&#36890;&#36807;&#19968;&#33268;&#33539;&#22260;&#36924;&#36817;&#30340;&#26041;&#27861;&#65292;&#22312;&#30446;&#26631;&#20154;&#32676;&#19978;&#26500;&#24314;&#20102;&#21487;&#35777;&#26126;&#20844;&#24179;&#30340;&#39044;&#27979;&#27169;&#22411;&#65292;&#24182;&#22312;&#30495;&#23454;&#25968;&#25454;&#19978;&#23637;&#31034;&#20102;&#26126;&#26174;&#30340;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2212.10839</link><description>&lt;p&gt;
&#20844;&#24179;&#39044;&#27979;&#24314;&#27169;&#30340;&#19968;&#31181;&#19968;&#33268;&#33539;&#22260;&#36924;&#36817;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Consistent Range Approximation for Fair Predictive Modeling. (arXiv:2212.10839v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.10839
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#39564;&#35777;&#22522;&#20110;&#26377;&#20559;&#25968;&#25454;&#35757;&#32451;&#30340;&#39044;&#27979;&#27169;&#22411;&#30340;&#20844;&#24179;&#24615;&#12290;&#36890;&#36807;&#19968;&#33268;&#33539;&#22260;&#36924;&#36817;&#30340;&#26041;&#27861;&#65292;&#22312;&#30446;&#26631;&#20154;&#32676;&#19978;&#26500;&#24314;&#20102;&#21487;&#35777;&#26126;&#20844;&#24179;&#30340;&#39044;&#27979;&#27169;&#22411;&#65292;&#24182;&#22312;&#30495;&#23454;&#25968;&#25454;&#19978;&#23637;&#31034;&#20102;&#26126;&#26174;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#39564;&#35777;&#22522;&#20110;&#26377;&#20559;&#25968;&#25454;&#35757;&#32451;&#30340;&#39044;&#27979;&#27169;&#22411;&#30340;&#20844;&#24179;&#24615;&#12290;&#23427;&#20511;&#37492;&#20102;&#23545;&#19981;&#23436;&#25972;&#21644;&#19981;&#19968;&#33268;&#25968;&#25454;&#24211;&#30340;&#26597;&#35810;&#22238;&#31572;&#65292;&#20197;&#24418;&#24335;&#21270;&#20844;&#24179;&#26597;&#35810;&#22312;&#30446;&#26631;&#20154;&#32676;&#19978;&#30340;&#19968;&#33268;&#33539;&#22260;&#36924;&#36817;&#65288;CRA&#65289;&#38382;&#39064;&#12290;&#35813;&#26694;&#26550;&#21033;&#29992;&#25968;&#25454;&#25910;&#38598;&#36807;&#31243;&#21644;&#26377;&#20559;&#25968;&#25454;&#30340;&#32972;&#26223;&#30693;&#35782;&#65292;&#21487;&#20197;&#22312;&#26377;&#38480;&#30340;&#30446;&#26631;&#20154;&#32676;&#32479;&#35745;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#35745;&#31639;&#20844;&#24179;&#26597;&#35810;&#30340;&#31572;&#26696;&#33539;&#22260;&#12290;&#36890;&#36807;CRA&#65292;&#35813;&#26694;&#26550;&#26500;&#24314;&#30340;&#39044;&#27979;&#27169;&#22411;&#21487;&#20197;&#22312;&#30446;&#26631;&#20154;&#32676;&#19978;&#33719;&#24471;&#21487;&#35777;&#26126;&#30340;&#20844;&#24179;&#24615;&#65292;&#32780;&#19981;&#21463;&#35757;&#32451;&#36807;&#31243;&#20013;&#22806;&#37096;&#25968;&#25454;&#30340;&#21487;&#29992;&#24615;&#38480;&#21046;&#12290;&#36890;&#36807;&#23545;&#30495;&#23454;&#25968;&#25454;&#30340;&#35780;&#20272;&#65292;&#39564;&#35777;&#20102;&#35813;&#26694;&#26550;&#30340;&#26377;&#25928;&#24615;&#65292;&#26174;&#31034;&#20986;&#26126;&#26174;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#26041;&#27861;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a novel framework for certifying the fairness of predictive models trained on biased data. It draws from query answering for incomplete and inconsistent databases to formulate the problem of consistent range approximation (CRA) of fairness queries for a predictive model on a target population. The framework employs background knowledge of the data collection process and biased data, working with or without limited statistics about the target population, to compute a range of answers for fairness queries. Using CRA, the framework builds predictive models that are certifiably fair on the target population, regardless of the availability of external data during training. The framework's efficacy is demonstrated through evaluations on real data, showing substantial improvement over existing state-of-the-art methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20197;&#24179;&#28369;&#30340;&#35282;&#24230;&#24341;&#20837;&#20102;Shapley&#26354;&#32447;&#20316;&#20026;&#23616;&#37096;&#21464;&#37327;&#37325;&#35201;&#24615;&#30340;&#24230;&#37327;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#20272;&#35745;&#31574;&#30053;&#65292;&#24182;&#22312;&#29305;&#24449;&#30340;&#29420;&#31435;&#21644;&#20381;&#36182;&#24773;&#20917;&#19979;&#24471;&#21040;&#20102;&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24577;&#24615;&#65292;&#20026;&#20272;&#35745;&#30340;Shapley&#26354;&#32447;&#26500;&#24314;&#20102;&#32622;&#20449;&#21306;&#38388;&#24182;&#36827;&#34892;&#20102;&#25512;&#26029;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#23454;&#20102;&#28176;&#36817;&#32467;&#26524;&#12290;&#24212;&#29992;&#20013;&#20998;&#26512;&#20102;&#21738;&#20123;&#23646;&#24615;&#39537;&#21160;&#36710;&#36742;&#20215;&#26684;&#12290;</title><link>http://arxiv.org/abs/2211.13289</link><description>&lt;p&gt;
Shapley&#26354;&#32447;&#65306;&#19968;&#31181;&#24179;&#28369;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Shapley Curves: A Smoothing Perspective. (arXiv:2211.13289v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.13289
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20197;&#24179;&#28369;&#30340;&#35282;&#24230;&#24341;&#20837;&#20102;Shapley&#26354;&#32447;&#20316;&#20026;&#23616;&#37096;&#21464;&#37327;&#37325;&#35201;&#24615;&#30340;&#24230;&#37327;&#65292;&#25552;&#20986;&#20102;&#20004;&#31181;&#20272;&#35745;&#31574;&#30053;&#65292;&#24182;&#22312;&#29305;&#24449;&#30340;&#29420;&#31435;&#21644;&#20381;&#36182;&#24773;&#20917;&#19979;&#24471;&#21040;&#20102;&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24577;&#24615;&#65292;&#20026;&#20272;&#35745;&#30340;Shapley&#26354;&#32447;&#26500;&#24314;&#20102;&#32622;&#20449;&#21306;&#38388;&#24182;&#36827;&#34892;&#20102;&#25512;&#26029;&#65292;&#36890;&#36807;&#23454;&#39564;&#35777;&#23454;&#20102;&#28176;&#36817;&#32467;&#26524;&#12290;&#24212;&#29992;&#20013;&#20998;&#26512;&#20102;&#21738;&#20123;&#23646;&#24615;&#39537;&#21160;&#36710;&#36742;&#20215;&#26684;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28304;&#33258;&#21512;&#20316;&#21338;&#24328;&#29702;&#35770;&#65292;Shapley&#20540;&#24050;&#25104;&#20026;&#24212;&#29992;&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#24191;&#27867;&#20351;&#29992;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#24230;&#37327;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#23545;Shapley&#20540;&#30340;&#32479;&#35745;&#29702;&#35299;&#20173;&#28982;&#26377;&#38480;&#12290;&#26412;&#25991;&#20197;&#38750;&#21442;&#25968;(&#25110;&#24179;&#28369;)&#30340;&#35282;&#24230;&#65292;&#24341;&#20837;Shapley&#26354;&#32447;&#20316;&#20026;&#23616;&#37096;&#21464;&#37327;&#37325;&#35201;&#24615;&#30340;&#24230;&#37327;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#20272;&#35745;&#31574;&#30053;&#65292;&#24182;&#22312;&#29305;&#24449;&#29420;&#31435;&#21644;&#20381;&#36182;&#30340;&#24773;&#20917;&#19979;&#37117;&#24471;&#20986;&#20102;&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;&#36825;&#26679;&#65292;&#25105;&#20204;&#21487;&#20197;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#24182;&#23545;&#20272;&#35745;&#30340;Shapley&#26354;&#32447;&#36827;&#34892;&#25512;&#26029;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#37326;&#34542;&#24341;&#23548;&#31243;&#24207;&#29256;&#26412;&#65292;&#19987;&#38376;&#35843;&#25972;&#20197;&#33719;&#24471;Shapley&#26354;&#32447;&#30340;&#33391;&#22909;&#26377;&#38480;&#26679;&#26412;&#35206;&#30422;&#12290;&#28176;&#36817;&#32467;&#26524;&#22312;&#22823;&#37327;&#23454;&#39564;&#35777;&#23454;&#20102;&#12290;&#22312;&#23454;&#35777;&#24212;&#29992;&#20013;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#21738;&#20123;&#23646;&#24615;&#39537;&#21160;&#20102;&#36710;&#36742;&#30340;&#20215;&#26684;&#12290;
&lt;/p&gt;
&lt;p&gt;
Originating from cooperative game theory, Shapley values have become one of the most widely used measures for variable importance in applied Machine Learning. However, the statistical understanding of Shapley values is still limited. In this paper, we take a nonparametric (or smoothing) perspective by introducing Shapley curves as a local measure of variable importance. We propose two estimation strategies and derive the consistency and asymptotic normality both under independence and dependence among the features. This allows us to construct confidence intervals and conduct inference on the estimated Shapley curves. We propose a novel version of the wild bootstrap procedure, specifically adjusted to give good finite sample coverage of the Shapley curves. The asymptotic results are validated in extensive experiments. In an empirical application, we analyze which attributes drive the prices of vehicles.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21452;&#23618;&#38750;&#32447;&#24615;&#29305;&#24449;&#21521;&#37327;&#31639;&#27861;&#65288;WDA-nepv&#65289;&#30340;Wasserstein&#21028;&#21035;&#20998;&#26512;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;&#19981;&#21516;&#31867;&#21035;&#30340;&#31163;&#25955;&#24230;&#65292;&#24182;&#26368;&#23567;&#21270;&#30456;&#21516;&#31867;&#21035;&#30340;&#31163;&#25955;&#24230;&#65292;&#20805;&#20998;&#21033;&#29992;WDA&#30340;&#21452;&#23618;&#20248;&#21270;&#32467;&#26500;&#65292;&#24182;&#22312;&#33258;&#27965;&#22330;&#26694;&#26550;&#19979;&#39640;&#25928;&#27714;&#35299;&#12290;</title><link>http://arxiv.org/abs/2211.11891</link><description>&lt;p&gt;
&#22522;&#20110;&#21452;&#23618;&#38750;&#32447;&#24615;&#29305;&#24449;&#21521;&#37327;&#31639;&#27861;&#30340;Wasserstein&#21028;&#21035;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
A Bi-level Nonlinear Eigenvector Algorithm for Wasserstein Discriminant Analysis. (arXiv:2211.11891v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.11891
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21452;&#23618;&#38750;&#32447;&#24615;&#29305;&#24449;&#21521;&#37327;&#31639;&#27861;&#65288;WDA-nepv&#65289;&#30340;Wasserstein&#21028;&#21035;&#20998;&#26512;&#26041;&#27861;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;&#19981;&#21516;&#31867;&#21035;&#30340;&#31163;&#25955;&#24230;&#65292;&#24182;&#26368;&#23567;&#21270;&#30456;&#21516;&#31867;&#21035;&#30340;&#31163;&#25955;&#24230;&#65292;&#20805;&#20998;&#21033;&#29992;WDA&#30340;&#21452;&#23618;&#20248;&#21270;&#32467;&#26500;&#65292;&#24182;&#22312;&#33258;&#27965;&#22330;&#26694;&#26550;&#19979;&#39640;&#25928;&#27714;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#21516;&#32463;&#20856;&#30340;Fisher&#32447;&#24615;&#21028;&#21035;&#20998;&#26512;&#65288;LDA&#65289;&#65292;&#26368;&#36817;&#25552;&#20986;&#30340;Wasserstein&#21028;&#21035;&#20998;&#26512;&#65288;WDA&#65289;&#26159;&#19968;&#31181;&#32447;&#24615;&#38477;&#32500;&#26041;&#27861;&#65292;&#36890;&#36807;&#21452;&#23618;&#20248;&#21270;&#26469;&#23547;&#27714;&#19968;&#20010;&#25237;&#24433;&#30697;&#38453;&#65292;&#26368;&#22823;&#21270;&#19981;&#21516;&#25968;&#25454;&#31867;&#21035;&#30340;&#31163;&#25955;&#24230;&#65292;&#24182;&#26368;&#23567;&#21270;&#30456;&#21516;&#25968;&#25454;&#31867;&#21035;&#30340;&#31163;&#25955;&#24230;&#12290;&#19982;LDA&#19981;&#21516;&#65292;WDA&#21033;&#29992;&#26368;&#20248;&#20256;&#36755;&#30340;&#22522;&#26412;&#21407;&#29702;&#65292;&#21487;&#20197;&#32771;&#34385;&#25968;&#25454;&#31867;&#21035;&#20043;&#38388;&#30340;&#20840;&#23616;&#21644;&#23616;&#37096;&#30456;&#20114;&#20851;&#32852;&#20851;&#31995;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21452;&#23618;&#38750;&#32447;&#24615;&#29305;&#24449;&#21521;&#37327;&#31639;&#27861;&#65288;WDA-nepv&#65289;&#26469;&#20805;&#20998;&#21033;&#29992;WDA&#30340;&#21452;&#23618;&#20248;&#21270;&#32467;&#26500;&#12290;WDA-nepv&#30340;&#20869;&#37096;&#23618;&#29992;&#20110;&#35745;&#31639;&#26368;&#20248;&#20256;&#36755;&#30697;&#38453;&#65292;&#24182;&#34987;&#26500;&#36896;&#20026;&#19968;&#20010;&#20381;&#36182;&#20110;&#29305;&#24449;&#21521;&#37327;&#30340;&#38750;&#32447;&#24615;&#29305;&#24449;&#20540;&#38382;&#39064;&#65288;NEPv&#65289;&#65292;&#21516;&#26102;&#65292;&#22806;&#37096;&#23618;&#29992;&#20110;&#36861;&#36394;&#27604;&#29575;&#20248;&#21270;&#65292;&#24182;&#34987;&#26500;&#36896;&#20026;&#21478;&#19968;&#20010;NEPv&#38382;&#39064;&#12290;&#36825;&#20004;&#20010;NEPv&#38382;&#39064;&#21487;&#20197;&#22312;&#33258;&#27965;&#22330;&#65288;SCF&#65289;&#26694;&#26550;&#19979;&#39640;&#25928;&#35745;&#31639;&#12290;WDA-nepv&#26159;&#21487;&#23548;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Much like the classical Fisher linear discriminant analysis (LDA), the recently proposed Wasserstein discriminant analysis (WDA) is a linear dimensionality reduction method that seeks a projection matrix to maximize the dispersion of different data classes and minimize the dispersion of same data classes via a bi-level optimization. In contrast to LDA, WDA can account for both global and local interconnections between data classes by using the underlying principles of optimal transport. In this paper, a bi-level nonlinear eigenvector algorithm (WDA-nepv) is presented to fully exploit the structures of the bi-level optimization of WDA. The inner level of WDA-nepv for computing the optimal transport matrices is formulated as an eigenvector-dependent nonlinear eigenvalue problem (NEPv), and meanwhile, the outer level for trace ratio optimizations is formulated as another NEPv. Both NEPvs can be computed efficiently under the self-consistent field (SCF) framework. WDA-nepv is derivative-fr
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Refoqus&#30340;&#36164;&#28304;&#33410;&#32422;&#30340;&#37327;&#23376;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20248;&#21270;&#22120;&#65292;&#36890;&#36807;&#21516;&#26102;&#38543;&#26426;&#37319;&#26679;&#25968;&#25454;&#38598;&#21644;&#27979;&#37327;&#25805;&#20316;&#65292;&#33021;&#22815;&#20445;&#23384;&#22823;&#37327;&#36164;&#28304;&#12290;</title><link>http://arxiv.org/abs/2211.04965</link><description>&lt;p&gt;
&#36164;&#28304;&#33410;&#32422;&#30340;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#20248;&#21270;&#22120;
&lt;/p&gt;
&lt;p&gt;
Resource frugal optimizer for quantum machine learning. (arXiv:2211.04965v2 [quant-ph] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.04965
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Refoqus&#30340;&#36164;&#28304;&#33410;&#32422;&#30340;&#37327;&#23376;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20248;&#21270;&#22120;&#65292;&#36890;&#36807;&#21516;&#26102;&#38543;&#26426;&#37319;&#26679;&#25968;&#25454;&#38598;&#21644;&#27979;&#37327;&#25805;&#20316;&#65292;&#33021;&#22815;&#20445;&#23384;&#22823;&#37327;&#36164;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#23376;&#22686;&#24378;&#30340;&#25968;&#25454;&#31185;&#23398;&#65292;&#20063;&#31216;&#20026;&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#65288;QML&#65289;&#65292;&#20316;&#20026;&#36817;&#26399;&#37327;&#23376;&#35745;&#31639;&#26426;&#30340;&#24212;&#29992;&#36234;&#26469;&#36234;&#21463;&#20851;&#27880;&#12290;&#21464;&#20998;QML&#31639;&#27861;&#22312;&#28041;&#21450;&#37327;&#23376;&#25968;&#25454;&#26102;&#26377;&#33021;&#21147;&#35299;&#20915;&#23454;&#38469;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#35757;&#32451;&#36825;&#20123;&#31639;&#27861;&#21487;&#33021;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#24182;&#38656;&#35201;&#23450;&#21046;&#30340;&#20248;&#21270;&#31243;&#24207;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;QML&#24212;&#29992;&#21487;&#33021;&#38656;&#35201;&#22823;&#37327;&#30340;&#37319;&#26679;&#27425;&#25968;&#65292;&#22240;&#20026;&#28041;&#21450;&#22823;&#22411;&#25968;&#25454;&#38598;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20513;&#23545;&#25968;&#25454;&#38598;&#21644;&#23450;&#20041;&#25439;&#22833;&#20989;&#25968;&#30340;&#27979;&#37327;&#25805;&#20316;&#36827;&#34892;&#21516;&#26102;&#38543;&#26426;&#37319;&#26679;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#39640;&#24230;&#36890;&#29992;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#21253;&#25324;&#20102;&#35768;&#22810;QML&#24212;&#29992;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#26500;&#24314;&#20854;&#26799;&#24230;&#30340;&#26080;&#20559;&#20272;&#35745;&#22120;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#25552;&#20986;&#19968;&#31181;&#31216;&#20026;Refoqus&#65288;&#36164;&#28304;&#33410;&#32422;&#30340;&#37327;&#23376;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20248;&#21270;&#22120;&#65289;&#30340;&#33410;&#32422;&#37319;&#26679;&#26799;&#24230;&#19979;&#38477;&#20248;&#21270;&#22120;&#12290;&#25105;&#20204;&#30340;&#25968;&#20540;&#32467;&#26524;&#34920;&#26126;&#65292;Refoqus&#33021;&#22815;&#33410;&#30465;&#20960;&#20010;&#25968;&#37327;&#32423;&#30340;&#36164;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantum-enhanced data science, also known as quantum machine learning (QML), is of growing interest as an application of near-term quantum computers. Variational QML algorithms have the potential to solve practical problems on real hardware, particularly when involving quantum data. However, training these algorithms can be challenging and calls for tailored optimization procedures. Specifically, QML applications can require a large shot-count overhead due to the large datasets involved. In this work, we advocate for simultaneous random sampling over both the dataset as well as the measurement operators that define the loss function. We consider a highly general loss function that encompasses many QML applications, and we show how to construct an unbiased estimator of its gradient. This allows us to propose a shot-frugal gradient descent optimizer called Refoqus (REsource Frugal Optimizer for QUantum Stochastic gradient descent). Our numerics indicate that Refoqus can save several orde
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#28789;&#27963;&#32780;&#23433;&#20840;&#30340;&#27169;&#20223;&#23398;&#20064;&#26041;&#27861;&#65292;&#21253;&#25324;&#19968;&#20010;&#23433;&#20840;&#23618;&#65292;&#20351;&#24471;&#29983;&#25104;&#36830;&#32493;&#31574;&#30053;&#30340;&#27010;&#29575;&#23494;&#24230;/&#26799;&#24230;&#25104;&#20026;&#38381;&#21512;&#24418;&#24335;&#65292;&#25552;&#20379;&#20102;&#31471;&#21040;&#31471;&#30340;&#29983;&#25104;&#23545;&#25239;&#35757;&#32451;&#21644;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#23433;&#20840;&#20445;&#35777;&#12290;&#37319;&#29992;&#23545;&#25239;&#21487;&#36798;&#24615;&#20998;&#26512;&#21644;&#21033;&#26222;&#24076;&#33576;&#36830;&#32493;&#24615;&#31561;&#26041;&#27861;&#65292;&#36890;&#36807;&#25512;&#26029;&#34892;&#21160;&#37051;&#22495;&#30340;&#23433;&#20840;&#24615;&#26469;&#30830;&#23450;&#19968;&#32452;&#23433;&#20840;&#34892;&#21160;&#12290;&#22312;&#23454;&#38469;&#39550;&#39542;&#21592;&#20132;&#20114;&#25968;&#25454;&#30340;&#23454;&#39564;&#20013;&#65292;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#21487;&#34892;&#24615;&#21644;&#40065;&#26834;&#24615;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2203.01696</link><description>&lt;p&gt;
&#23433;&#20840;&#21487;&#38752;&#30340;&#23545;&#25239;&#29983;&#25104;&#27169;&#20223;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Fail-Safe Adversarial Generative Imitation Learning. (arXiv:2203.01696v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.01696
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#28789;&#27963;&#32780;&#23433;&#20840;&#30340;&#27169;&#20223;&#23398;&#20064;&#26041;&#27861;&#65292;&#21253;&#25324;&#19968;&#20010;&#23433;&#20840;&#23618;&#65292;&#20351;&#24471;&#29983;&#25104;&#36830;&#32493;&#31574;&#30053;&#30340;&#27010;&#29575;&#23494;&#24230;/&#26799;&#24230;&#25104;&#20026;&#38381;&#21512;&#24418;&#24335;&#65292;&#25552;&#20379;&#20102;&#31471;&#21040;&#31471;&#30340;&#29983;&#25104;&#23545;&#25239;&#35757;&#32451;&#21644;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#23433;&#20840;&#20445;&#35777;&#12290;&#37319;&#29992;&#23545;&#25239;&#21487;&#36798;&#24615;&#20998;&#26512;&#21644;&#21033;&#26222;&#24076;&#33576;&#36830;&#32493;&#24615;&#31561;&#26041;&#27861;&#65292;&#36890;&#36807;&#25512;&#26029;&#34892;&#21160;&#37051;&#22495;&#30340;&#23433;&#20840;&#24615;&#26469;&#30830;&#23450;&#19968;&#32452;&#23433;&#20840;&#34892;&#21160;&#12290;&#22312;&#23454;&#38469;&#39550;&#39542;&#21592;&#20132;&#20114;&#25968;&#25454;&#30340;&#23454;&#39564;&#20013;&#65292;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#21487;&#34892;&#24615;&#21644;&#40065;&#26834;&#24615;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#23454;&#29616;&#28789;&#27963;&#32780;&#23433;&#20840;&#30340;&#27169;&#20223;&#23398;&#20064;&#65288;IL&#65289;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29702;&#35770;&#21644;&#27169;&#22359;&#21270;&#26041;&#27861;&#65292;&#20854;&#20013;&#21253;&#25324;&#19968;&#20010;&#23433;&#20840;&#23618;&#65292;&#35813;&#23618;&#33021;&#22815;&#20351;&#23433;&#20840;&#29983;&#25104;&#36830;&#32493;&#31574;&#30053;&#30340;&#27010;&#29575;&#23494;&#24230;/&#26799;&#24230;&#25104;&#20026;&#38381;&#21512;&#24418;&#24335;&#65292;&#24182;&#25552;&#20379;&#31471;&#21040;&#31471;&#30340;&#29983;&#25104;&#23545;&#25239;&#35757;&#32451;&#21644;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#23433;&#20840;&#20445;&#35777;&#12290;&#23433;&#20840;&#23618;&#23558;&#25152;&#26377;&#34892;&#21160;&#26144;&#23556;&#21040;&#19968;&#32452;&#23433;&#20840;&#34892;&#21160;&#65292;&#24182;&#20351;&#29992;&#21464;&#37327;&#36716;&#25442;&#20844;&#24335;&#21644;&#24230;&#37327;&#30340;&#21487;&#21152;&#24615;&#26469;&#35745;&#31639;&#23494;&#24230;&#12290;&#36890;&#36807;&#23545;&#22238;&#36864;&#25805;&#20316;&#30340;&#23545;&#25239;&#21487;&#36798;&#24615;&#20998;&#26512;&#65292;&#25105;&#20204;&#39318;&#20808;&#26816;&#26597;&#26377;&#38480;&#26679;&#26412;&#30340;&#34892;&#21160;&#23433;&#20840;&#24615;&#65292;&#28982;&#21518;&#36890;&#36807;&#21033;&#26222;&#24076;&#33576;&#36830;&#32493;&#24615;&#31561;&#26041;&#27861;&#26469;&#25512;&#26029;&#36825;&#20123;&#34892;&#21160;&#37051;&#22495;&#30340;&#23433;&#20840;&#24615;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#34920;&#26126;&#19982;&#20165;&#22312;&#27979;&#35797;&#26102;&#20351;&#29992;&#23433;&#20840;&#23618;&#65288;&#26368;&#22810;&#20108;&#27425;&#35823;&#24046;&#65289;&#30456;&#27604;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#20351;&#29992;&#23433;&#20840;&#23618;&#30340;&#40065;&#26834;&#24615;&#20248;&#21183;&#65288;&#27169;&#20223;&#35823;&#24046;&#19982;&#26102;&#38388;&#24207;&#21015;&#32447;&#24615;&#30456;&#20851;&#65289;&#12290;&#22312;&#23454;&#38469;&#39550;&#39542;&#21592;&#20132;&#20114;&#25968;&#25454;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#32463;&#39564;&#24615;&#22320;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
For flexible yet safe imitation learning (IL), we propose theory and a modular method, with a safety layer that enables a closed-form probability density/gradient of the safe generative continuous policy, end-to-end generative adversarial training, and worst-case safety guarantees. The safety layer maps all actions into a set of safe actions, and uses the change-of-variables formula plus additivity of measures for the density. The set of safe actions is inferred by first checking safety of a finite sample of actions via adversarial reachability analysis of fallback maneuvers, and then concluding on the safety of these actions' neighborhoods using, e.g., Lipschitz continuity. We provide theoretical analysis showing the robustness advantage of using the safety layer already during training (imitation error linear in the horizon) compared to only using it at test time (up to quadratic error). In an experiment on real-world driver interaction data, we empirically demonstrate tractability, 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#20844;&#24179;&#24615;&#32422;&#26463;&#19979;&#30340;&#21160;&#24577;&#27495;&#35270;&#24615;&#23450;&#20215;&#38382;&#39064;&#65292;&#38024;&#23545;&#22312;&#32447;&#38646;&#21806;&#20013;&#23384;&#22312;&#30340;&#20215;&#26684;&#27495;&#35270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20844;&#24179;&#24863;&#30693;&#30340;&#35299;&#20915;&#26041;&#27861;&#65292;&#26088;&#22312;&#22312;&#26368;&#22823;&#21270;&#25910;&#20837;&#30340;&#21516;&#26102;&#30830;&#20445;&#20844;&#24179;&#24615;&#12290;</title><link>http://arxiv.org/abs/2111.08221</link><description>&lt;p&gt;
&#20855;&#26377;&#38750;&#21442;&#25968;&#38656;&#27714;&#27169;&#22411;&#30340;&#20844;&#24179;&#24863;&#30693;&#22312;&#32447;&#20215;&#26684;&#27495;&#35270;
&lt;/p&gt;
&lt;p&gt;
Fairness-aware Online Price Discrimination with Nonparametric Demand Models. (arXiv:2111.08221v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.08221
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#20844;&#24179;&#24615;&#32422;&#26463;&#19979;&#30340;&#21160;&#24577;&#27495;&#35270;&#24615;&#23450;&#20215;&#38382;&#39064;&#65292;&#38024;&#23545;&#22312;&#32447;&#38646;&#21806;&#20013;&#23384;&#22312;&#30340;&#20215;&#26684;&#27495;&#35270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20844;&#24179;&#24863;&#30693;&#30340;&#35299;&#20915;&#26041;&#27861;&#65292;&#26088;&#22312;&#22312;&#26368;&#22823;&#21270;&#25910;&#20837;&#30340;&#21516;&#26102;&#30830;&#20445;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20215;&#26684;&#27495;&#35270;&#26159;&#22312;&#32593;&#19978;&#38646;&#21806;&#20013;&#24191;&#27867;&#20351;&#29992;&#30340;&#19968;&#31181;&#31574;&#30053;&#65292;&#25351;&#30340;&#26159;&#20026;&#19981;&#21516;&#30340;&#23458;&#25143;&#32676;&#20307;&#35774;&#23450;&#19981;&#21516;&#30340;&#20215;&#26684;&#12290;&#23613;&#31649;&#23427;&#26377;&#21161;&#20110;&#25552;&#39640;&#32593;&#19978;&#38646;&#21806;&#21830;&#30340;&#25910;&#20837;&#65292;&#20294;&#21487;&#33021;&#24341;&#21457;&#20851;&#20110;&#20844;&#24179;&#24615;&#30340;&#20005;&#37325;&#25285;&#24551;&#65292;&#29978;&#33267;&#36829;&#21453;&#35268;&#23450;&#21644;&#27861;&#24459;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20844;&#24179;&#24615;&#32422;&#26463;&#19979;&#30340;&#21160;&#24577;&#27495;&#35270;&#24615;&#23450;&#20215;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#26377;&#38480;&#38144;&#21806;&#21608;&#26399;&#38271;&#24230;&#20026;T&#30340;&#21333;&#19968;&#20135;&#21697;&#65292;&#26377;&#20004;&#32452;&#23458;&#25143;&#12290;&#27599;&#32452;&#23458;&#25143;&#37117;&#26377;&#20854;&#26410;&#30693;&#30340;&#38656;&#27714;&#20989;&#25968;&#38656;&#35201;&#23398;&#20064;&#12290;&#23545;&#20110;&#27599;&#20010;&#38144;&#21806;&#21608;&#26399;&#65292;&#21334;&#23478;&#30830;&#23450;&#27599;&#32452;&#30340;&#20215;&#26684;&#24182;&#35266;&#23519;&#20854;&#36141;&#20080;&#34892;&#20026;&#12290;&#34429;&#28982;&#29616;&#26377;&#25991;&#29486;&#20027;&#35201;&#20851;&#27880;&#26368;&#22823;&#21270;&#25910;&#20837;&#65292;&#20294;&#22312;&#21160;&#24577;&#23450;&#20215;&#25991;&#29486;&#20013;&#23578;&#26410;&#20805;&#20998;&#25506;&#35752;&#30830;&#20445;&#19981;&#21516;&#23458;&#25143;&#20043;&#38388;&#30340;&#20844;&#24179;&#24615;&#12290;&#26412;&#30740;&#31350;&#37319;&#29992;&#20102;Cohen&#31561;&#20154;&#65288;2022&#65289;&#30340;&#20844;&#24179;&#27010;&#24565;&#12290;&#23545;&#20110;&#20215;&#26684;&#20844;&#24179;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26368;&#20248;&#21160;&#24577;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Price discrimination, which refers to the strategy of setting different prices for different customer groups, has been widely used in online retailing. Although it helps boost the collected revenue for online retailers, it might create serious concerns about fairness, which even violates the regulation and laws. This paper studies the problem of dynamic discriminatory pricing under fairness constraints. In particular, we consider a finite selling horizon of length $T$ for a single product with two groups of customers. Each group of customers has its unknown demand function that needs to be learned. For each selling period, the seller determines the price for each group and observes their purchase behavior. While existing literature mainly focuses on maximizing revenue, ensuring fairness among different customers has not been fully explored in the dynamic pricing literature. This work adopts the fairness notion from Cohen et al. (2022). For price fairness, we propose an optimal dynamic 
&lt;/p&gt;</description></item><item><title>COVID-19&#22823;&#27969;&#34892;&#26399;&#38388;&#65292;&#19990;&#30028;&#21508;&#22320;&#30340;&#32452;&#32455;&#22312;&#27807;&#36890;&#19978;&#21464;&#24471;&#26356;&#21152;&#23396;&#31435;&#65292;&#27169;&#22359;&#21270;&#22686;&#21152;&#65292;&#21592;&#24037;&#24320;&#22987;&#26356;&#21152;&#28789;&#27963;&#22320;&#36827;&#34892;&#27807;&#36890;&#12290;</title><link>http://arxiv.org/abs/2104.00641</link><description>&lt;p&gt;
&#21160;&#24577;&#27807;&#36890;&#32593;&#32476;&#65306;COVID-19&#22823;&#27969;&#34892;&#26399;&#38388;&#32452;&#32455;&#20869;&#37096;&#27807;&#36890;&#32593;&#32476;&#20013;&#30340;&#27169;&#22359;&#21270;&#22686;&#21152;
&lt;/p&gt;
&lt;p&gt;
Dynamic Silos: Increased Modularity in Intra-organizational Communication Networks during the Covid-19 Pandemic. (arXiv:2104.00641v6 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2104.00641
&lt;/p&gt;
&lt;p&gt;
COVID-19&#22823;&#27969;&#34892;&#26399;&#38388;&#65292;&#19990;&#30028;&#21508;&#22320;&#30340;&#32452;&#32455;&#22312;&#27807;&#36890;&#19978;&#21464;&#24471;&#26356;&#21152;&#23396;&#31435;&#65292;&#27169;&#22359;&#21270;&#22686;&#21152;&#65292;&#21592;&#24037;&#24320;&#22987;&#26356;&#21152;&#28789;&#27963;&#22320;&#36827;&#34892;&#27807;&#36890;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
COVID-19&#65292;&#30456;&#20851;&#30340;&#23621;&#23478;&#21150;&#20844;&#25919;&#31574;&#21644;&#36828;&#31243;&#24037;&#20316;&#30340;&#20852;&#36215;&#65292;&#26497;&#22823;&#22320;&#25913;&#21464;&#20102;&#19990;&#30028;&#21508;&#22320;&#30340;&#24037;&#20316;&#22330;&#25152;&#27807;&#36890;&#26041;&#24335;&#12290;&#20026;&#20102;&#20102;&#35299;&#36825;&#20123;&#21464;&#21270;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#26469;&#33258;&#20840;&#29699;4361&#20010;&#32452;&#32455;&#30340;3600&#20159;&#23553;&#30005;&#23376;&#37038;&#20214;&#30340;&#32858;&#21512;&#12289;&#21311;&#21517;&#21270;&#20803;&#25968;&#25454;&#12290;&#36890;&#36807;&#27604;&#36739;&#27599;&#26376;&#21644;&#24180;&#24230;&#30340;&#25351;&#26631;&#65292;&#25105;&#20204;&#23545;COVID-19&#20043;&#21069;&#21644;&#20043;&#21518;24&#20010;&#26376;&#20869;&#32593;&#32476;&#31038;&#32676;&#32467;&#26500;&#30340;&#21464;&#21270;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#21333;&#20010;&#20840;&#29699;&#32452;&#32455;&#20869;&#22810;&#31181;&#27807;&#36890;&#23186;&#20307;&#65288;&#30005;&#23376;&#37038;&#20214;&#12289;&#21363;&#26102;&#28040;&#24687;&#12289;&#35270;&#39057;&#36890;&#35805;&#21644;&#26085;&#21382;&#36719;&#20214;&#65289;&#30340;&#21464;&#21270;&#65292;&#24182;&#23558;&#20854;&#19982;&#30001;&#20110;&#32452;&#32455;&#32467;&#26500;&#25913;&#21464;&#32780;&#25512;&#21160;&#30340;&#27807;&#36890;&#21464;&#21270;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;2020&#24180;&#65292;&#19990;&#30028;&#21508;&#22320;&#30340;&#32452;&#32455;&#27604;2019&#24180;&#26356;&#21152;&#23396;&#31435;&#65292;&#34920;&#29616;&#20026;&#22686;&#21152;&#30340;&#27169;&#22359;&#21270;&#12290;&#36825;&#19968;&#36716;&#21464;&#19982;&#27169;&#22359;&#20869;&#31283;&#23450;&#24615;&#30340;&#38477;&#20302;&#21516;&#26102;&#21457;&#29983;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#20849;&#21516;&#34920;&#26126;&#65292;COVID-19&#29190;&#21457;&#21518;&#65292;&#21592;&#24037;&#24320;&#22987;&#26356;&#21152;&#28789;&#27963;&#22320;&#36827;&#34892;&#27807;&#36890;&#12290;
&lt;/p&gt;
&lt;p&gt;
Workplace communications around the world were drastically altered by Covid-19, related work-from-home orders, and the rise of remote work. To understand these shifts, we analyzed aggregated, anonymized metadata from over 360 billion emails within 4,361 organizations worldwide. By comparing month-to-month and year-over-year metrics, we examined changes in network community structures over 24 months before and after Covid-19. We also examined shifts across multiple communication media (email, instant messages, video calls, and calendaring software) within a single global organization, and compared them to communications shifts that were driven by changes in formal organizational structure. We found that, in 2020, organizations around the world became more siloed than in 2019, evidenced by increased modularity. This shift was concurrent with decreased stability within silos. Collectively, our analyses indicate that following the onset of Covid-19, employees began to shift more dynamicall
&lt;/p&gt;</description></item></channel></rss>