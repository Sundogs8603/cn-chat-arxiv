<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22823;&#23398;&#20064;&#29575;&#22312;&#38750;&#20984;&#20248;&#21270;&#20013;&#20135;&#29983;&#30340;&#38544;&#24615;&#20559;&#24046;&#65292;&#21253;&#25324;&#31283;&#23450;&#30340;&#36793;&#30028;&#12289;&#24179;&#34913;&#21644;&#24377;&#23556;&#65292;&#24182;&#36890;&#36807;&#21457;&#23637;&#26032;&#30340;&#20840;&#23616;&#25910;&#25947;&#29702;&#35770;&#21644;&#30740;&#31350;&#33391;&#22909;&#35268;&#21017;&#24615;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#23558;&#36825;&#20123;&#29616;&#35937;&#24402;&#32435;&#20026;&#21516;&#19968;&#29616;&#35937;&#30340;&#19981;&#21516;&#34920;&#29616;&#24418;&#24335;&#12290;</title><link>http://arxiv.org/abs/2310.17087</link><description>&lt;p&gt;
&#33391;&#22909;&#30340;&#35268;&#21017;&#24615;&#21019;&#36896;&#20102;&#22823;&#23398;&#20064;&#29575;&#30340;&#38544;&#24615;&#20559;&#24046;&#65306;&#31283;&#23450;&#30340;&#36793;&#30028;&#65292;&#24179;&#34913;&#21644;&#24377;&#23556;
&lt;/p&gt;
&lt;p&gt;
Good regularity creates large learning rate implicit biases: edge of stability, balancing, and catapult. (arXiv:2310.17087v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.17087
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22823;&#23398;&#20064;&#29575;&#22312;&#38750;&#20984;&#20248;&#21270;&#20013;&#20135;&#29983;&#30340;&#38544;&#24615;&#20559;&#24046;&#65292;&#21253;&#25324;&#31283;&#23450;&#30340;&#36793;&#30028;&#12289;&#24179;&#34913;&#21644;&#24377;&#23556;&#65292;&#24182;&#36890;&#36807;&#21457;&#23637;&#26032;&#30340;&#20840;&#23616;&#25910;&#25947;&#29702;&#35770;&#21644;&#30740;&#31350;&#33391;&#22909;&#35268;&#21017;&#24615;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#23558;&#36825;&#20123;&#29616;&#35937;&#24402;&#32435;&#20026;&#21516;&#19968;&#29616;&#35937;&#30340;&#19981;&#21516;&#34920;&#29616;&#24418;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#24212;&#29992;&#20110;&#38750;&#20984;&#20248;&#21270;&#30340;&#26799;&#24230;&#19979;&#38477;&#26102;&#65292;&#22823;&#23398;&#20064;&#29575;&#20250;&#20135;&#29983;&#21508;&#31181;&#38544;&#24615;&#20559;&#24046;&#65292;&#21253;&#25324;&#31283;&#23450;&#30340;&#36793;&#30028;&#12289;&#24179;&#34913;&#21644;&#24377;&#23556;&#12290;&#36825;&#20123;&#29616;&#35937;&#26080;&#27861;&#29992;&#32463;&#20856;&#30340;&#20248;&#21270;&#29702;&#35770;&#24456;&#22909;&#22320;&#35299;&#37322;&#12290;&#23613;&#31649;&#22312;&#29702;&#35299;&#36825;&#20123;&#38544;&#24615;&#20559;&#24046;&#26041;&#38754;&#24050;&#32463;&#21462;&#24471;&#20102;&#37325;&#35201;&#30340;&#29702;&#35770;&#36827;&#23637;&#65292;&#20294;&#20173;&#28982;&#19981;&#28165;&#26970;&#23427;&#20204;&#22312;&#21738;&#20123;&#30446;&#26631;&#20989;&#25968;&#19978;&#20250;&#21457;&#29983;&#12290;&#26412;&#25991;&#23545;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#25552;&#20379;&#20102;&#19968;&#20010;&#21021;&#22987;&#30340;&#27493;&#39588;&#65292;&#21363;&#36825;&#20123;&#38544;&#24615;&#20559;&#24046;&#23454;&#38469;&#19978;&#26159;&#21516;&#19968;&#20912;&#23665;&#30340;&#21508;&#31181;&#23574;&#31471;&#12290;&#24403;&#20248;&#21270;&#30340;&#30446;&#26631;&#20989;&#25968;&#20855;&#26377;&#19968;&#23450;&#30340;&#33391;&#22909;&#35268;&#21017;&#24615;&#65292;&#24182;&#19982;&#22823;&#23398;&#20064;&#29575;&#26799;&#24230;&#19979;&#38477;&#23545;&#21521;&#26356;&#24179;&#22374;&#21306;&#22495;&#31227;&#21160;&#30340;&#21487;&#35777;&#26126;&#20559;&#22909;&#30456;&#32467;&#21512;&#26102;&#65292;&#23601;&#20250;&#20135;&#29983;&#36825;&#20123;&#38750;&#24179;&#20961;&#30340;&#21160;&#21147;&#23398;&#29616;&#35937;&#12290;&#20026;&#20102;&#24314;&#31435;&#36825;&#20010;&#32467;&#26524;&#65292;&#25105;&#20204;&#21457;&#23637;&#20102;&#19968;&#20010;&#26032;&#30340;&#22823;&#23398;&#20064;&#29575;&#20840;&#23616;&#25910;&#25947;&#29702;&#35770;&#65292;&#38024;&#23545;&#19968;&#26063;&#38750;&#20984;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large learning rates, when applied to gradient descent for nonconvex optimization, yield various implicit biases including the edge of stability (Cohen et al., 2021), balancing (Wang et al., 2022), and catapult (Lewkowycz et al., 2020). These phenomena cannot be well explained by classical optimization theory. Though significant theoretical progress has been made in understanding these implicit biases, it remains unclear for which objective functions would they occur. This paper provides an initial step in answering this question, namely that these implicit biases are in fact various tips of the same iceberg. They occur when the objective function of optimization has some good regularity, which, in combination with a provable preference of large learning rate gradient descent for moving toward flatter regions, results in these nontrivial dynamical phenomena. To establish this result, we develop a new global convergence theory under large learning rates, for a family of nonconvex functi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;Clifford&#30340;&#20960;&#20309;&#20195;&#25968;&#21644;&#20984;&#20248;&#21270;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#26512;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#20248;&#26435;&#37325;&#21487;&#20197;&#36890;&#36807;&#35757;&#32451;&#26679;&#26412;&#30340;&#26964;&#31215;&#26469;&#33719;&#24471;&#65292;&#24182;&#19988;&#35757;&#32451;&#38382;&#39064;&#21487;&#20197;&#31616;&#21270;&#20026;&#23545;&#26964;&#31215;&#29305;&#24449;&#36827;&#34892;&#20984;&#20248;&#21270;&#65292;&#20174;&#32780;&#25581;&#31034;&#20102;&#31070;&#32463;&#32593;&#32476;&#20869;&#37096;&#30340;&#20960;&#20309;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2309.16512</link><description>&lt;p&gt;
&#20174;&#22797;&#26434;&#21040;&#28165;&#26224;&#65306;&#36890;&#36807;Clifford&#30340;&#20960;&#20309;&#20195;&#25968;&#21644;&#20984;&#20248;&#21270;&#30340;&#20998;&#26512;&#34920;&#36798;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#26435;&#37325;
&lt;/p&gt;
&lt;p&gt;
From Complexity to Clarity: Analytical Expressions of Deep Neural Network Weights via Clifford's Geometric Algebra and Convexity. (arXiv:2309.16512v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.16512
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;Clifford&#30340;&#20960;&#20309;&#20195;&#25968;&#21644;&#20984;&#20248;&#21270;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#26512;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#20248;&#26435;&#37325;&#21487;&#20197;&#36890;&#36807;&#35757;&#32451;&#26679;&#26412;&#30340;&#26964;&#31215;&#26469;&#33719;&#24471;&#65292;&#24182;&#19988;&#35757;&#32451;&#38382;&#39064;&#21487;&#20197;&#31616;&#21270;&#20026;&#23545;&#26964;&#31215;&#29305;&#24449;&#36827;&#34892;&#20984;&#20248;&#21270;&#65292;&#20174;&#32780;&#25581;&#31034;&#20102;&#31070;&#32463;&#32593;&#32476;&#20869;&#37096;&#30340;&#20960;&#20309;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#20960;&#20309;&#65288;Clifford&#65289;&#20195;&#25968;&#21644;&#20984;&#20248;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#20998;&#26512;&#26041;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#24403;&#20351;&#29992;&#26631;&#20934;&#27491;&#21017;&#21270;&#25439;&#22833;&#36827;&#34892;&#35757;&#32451;&#26102;&#65292;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#20248;&#26435;&#37325;&#30001;&#35757;&#32451;&#26679;&#26412;&#30340;&#26964;&#31215;&#32473;&#20986;&#12290;&#27492;&#22806;&#65292;&#35757;&#32451;&#38382;&#39064;&#21487;&#31616;&#21270;&#20026;&#23545;&#26964;&#31215;&#29305;&#24449;&#36827;&#34892;&#20984;&#20248;&#21270;&#65292;&#22312;&#20854;&#20013;&#32534;&#30721;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#20960;&#20309;&#32467;&#26500;&#12290;&#35813;&#32467;&#26500;&#20197;&#25968;&#25454;&#21521;&#37327;&#29983;&#25104;&#30340;&#19977;&#35282;&#24418;&#21644;&#24179;&#34892;&#20307;&#30340;&#26377;&#31526;&#21495;&#20307;&#31215;&#34920;&#31034;&#12290;&#20984;&#38382;&#39064;&#36890;&#36807;$\ell_1$&#27491;&#21017;&#21270;&#25214;&#21040;&#26679;&#26412;&#30340;&#19968;&#20010;&#23567;&#23376;&#38598;&#65292;&#20197;&#21457;&#29616;&#20165;&#30456;&#20851;&#30340;&#26964;&#31215;&#29305;&#24449;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#25552;&#20379;&#20102;&#23545;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20869;&#37096;&#24037;&#20316;&#26426;&#21046;&#30340;&#26032;&#35270;&#35282;&#65292;&#24182;&#25581;&#31034;&#20102;&#38544;&#34255;&#23618;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we introduce a novel analysis of neural networks based on geometric (Clifford) algebra and convex optimization. We show that optimal weights of deep ReLU neural networks are given by the wedge product of training samples when trained with standard regularized loss. Furthermore, the training problem reduces to convex optimization over wedge product features, which encode the geometric structure of the training dataset. This structure is given in terms of signed volumes of triangles and parallelotopes generated by data vectors. The convex problem finds a small subset of samples via $\ell_1$ regularization to discover only relevant wedge product features. Our analysis provides a novel perspective on the inner workings of deep neural networks and sheds light on the role of the hidden layers.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#19968;&#31867;&#23494;&#24230;&#27604;&#29575;&#20272;&#35745;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#23398;&#20064;&#30340;&#21442;&#25968;&#36873;&#25321;&#21407;&#21017;&#65292;&#24182;&#22312;&#26377;&#38480;&#26679;&#26412;&#24773;&#20917;&#19979;&#25512;&#23548;&#20986;&#26032;&#30340;&#35823;&#24046;&#30028;&#12290;&#20854;&#26041;&#27861;&#22312;&#20108;&#27425;&#25439;&#22833;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#26497;&#23567;&#21270;&#26368;&#20248;&#35823;&#24046;&#29575;&#12290;</title><link>http://arxiv.org/abs/2307.16164</link><description>&lt;p&gt;
&#22312;RKHS&#20013;&#33258;&#36866;&#24212;&#23398;&#20064;&#23494;&#24230;&#27604;&#29575;
&lt;/p&gt;
&lt;p&gt;
Adaptive learning of density ratios in RKHS. (arXiv:2307.16164v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.16164
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#19968;&#31867;&#23494;&#24230;&#27604;&#29575;&#20272;&#35745;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#23398;&#20064;&#30340;&#21442;&#25968;&#36873;&#25321;&#21407;&#21017;&#65292;&#24182;&#22312;&#26377;&#38480;&#26679;&#26412;&#24773;&#20917;&#19979;&#25512;&#23548;&#20986;&#26032;&#30340;&#35823;&#24046;&#30028;&#12290;&#20854;&#26041;&#27861;&#22312;&#20108;&#27425;&#25439;&#22833;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#26497;&#23567;&#21270;&#26368;&#20248;&#35823;&#24046;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#26377;&#38480;&#25968;&#37327;&#30340;&#23494;&#24230;&#35266;&#27979;&#20013;&#20272;&#35745;&#20004;&#20010;&#27010;&#29575;&#23494;&#24230;&#30340;&#27604;&#29575;&#26159;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#23398;&#20013;&#30340;&#19968;&#20010;&#26680;&#24515;&#38382;&#39064;&#65292;&#24212;&#29992;&#21253;&#25324;&#21452;&#26679;&#26412;&#26816;&#39564;&#12289;&#20998;&#27495;&#20272;&#35745;&#12289;&#29983;&#25104;&#24314;&#27169;&#12289;&#21327;&#21464;&#37327;&#36716;&#31227;&#36866;&#24212;&#12289;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#21644;&#26032;&#39062;&#24615;&#26816;&#27979;&#12290;&#26412;&#30740;&#31350;&#20998;&#26512;&#20102;&#19968;&#22823;&#31867;&#23494;&#24230;&#27604;&#29575;&#20272;&#35745;&#26041;&#27861;&#65292;&#23427;&#20204;&#36890;&#36807;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#20013;&#26368;&#23567;&#21270;&#30495;&#23454;&#23494;&#24230;&#27604;&#29575;&#19982;&#27169;&#22411;&#20043;&#38388;&#30340;&#27491;&#21017;Bregman&#36317;&#31163;&#12290;&#25105;&#20204;&#25512;&#23548;&#20986;&#26032;&#30340;&#26377;&#38480;&#26679;&#26412;&#35823;&#24046;&#30028;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;Lepskii&#31867;&#22411;&#30340;&#21442;&#25968;&#36873;&#25321;&#21407;&#21017;&#65292;&#22312;&#19981;&#30693;&#36947;&#23494;&#24230;&#27604;&#29575;&#30340;&#27491;&#21017;&#24615;&#30340;&#24773;&#20917;&#19979;&#26368;&#23567;&#21270;&#35823;&#24046;&#30028;&#12290;&#22312;&#20108;&#27425;&#25439;&#22833;&#30340;&#29305;&#27530;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33258;&#36866;&#24212;&#22320;&#23454;&#29616;&#20102;&#26497;&#23567;&#21270;&#26368;&#20248;&#35823;&#24046;&#29575;&#12290;&#25552;&#20379;&#20102;&#19968;&#20010;&#25968;&#20540;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating the ratio of two probability densities from finitely many observations of the densities is a central problem in machine learning and statistics with applications in two-sample testing, divergence estimation, generative modeling, covariate shift adaptation, conditional density estimation, and novelty detection. In this work, we analyze a large class of density ratio estimation methods that minimize a regularized Bregman divergence between the true density ratio and a model in a reproducing kernel Hilbert space (RKHS). We derive new finite-sample error bounds, and we propose a Lepskii type parameter choice principle that minimizes the bounds without knowledge of the regularity of the density ratio. In the special case of quadratic loss, our method adaptively achieves a minimax optimal error rate. A numerical illustration is provided.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#27169;&#22411;&#31639;&#27861;&#65292;&#37319;&#29992;&#26041;&#24046;&#32553;&#20943;&#21644;&#33258;&#36866;&#24212;&#25191;&#34892;&#31574;&#30053;&#36716;&#25442;&#25216;&#26415;&#65292;&#22312;&#30701;&#28903;&#21270;&#26102;&#38388;MDPs&#19978;&#23454;&#29616;&#20102;&#36951;&#25022;&#26368;&#20248;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#31639;&#27861;&#26080;&#27861;&#23454;&#29616;&#26368;&#20248;&#24615;&#21644;&#38656;&#35201;&#20184;&#20986;&#39640;&#26114;&#20869;&#23384;&#35745;&#31639;&#25104;&#26412;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2305.15546</link><description>&lt;p&gt;
&#30701;&#28903;&#21270;&#26102;&#38388;MDPs&#19978;&#20855;&#26377;&#36951;&#25022;&#26368;&#20248;&#30340;&#26080;&#27169;&#22411;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Regret-Optimal Model-Free Reinforcement Learning for Discounted MDPs with Short Burn-In Time. (arXiv:2305.15546v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15546
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#27169;&#22411;&#31639;&#27861;&#65292;&#37319;&#29992;&#26041;&#24046;&#32553;&#20943;&#21644;&#33258;&#36866;&#24212;&#25191;&#34892;&#31574;&#30053;&#36716;&#25442;&#25216;&#26415;&#65292;&#22312;&#30701;&#28903;&#21270;&#26102;&#38388;MDPs&#19978;&#23454;&#29616;&#20102;&#36951;&#25022;&#26368;&#20248;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#31639;&#27861;&#26080;&#27861;&#23454;&#29616;&#26368;&#20248;&#24615;&#21644;&#38656;&#35201;&#20184;&#20986;&#39640;&#26114;&#20869;&#23384;&#35745;&#31639;&#25104;&#26412;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#21270;&#23398;&#20064;&#20013;&#19968;&#20010;&#20851;&#38190;&#38382;&#39064;&#26159;&#23398;&#20064;&#26368;&#20248;&#31574;&#30053;&#12290;&#25105;&#20204;&#22312;&#22312;&#32447;&#35774;&#32622;&#19979;&#30740;&#31350;&#20102;&#22312;&#34920;&#26684;&#26080;&#38480;&#26102;&#27573;&#25240;&#25187;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#30340;&#26368;&#20248;&#31574;&#30053;&#23398;&#20064;&#12290;&#29616;&#26377;&#31639;&#27861;&#35201;&#20040;&#26080;&#27861;&#23454;&#29616;&#36951;&#25022;&#26368;&#20248;&#24615;&#65292;&#35201;&#20040;&#38656;&#35201;&#20184;&#20986;&#39640;&#26114;&#30340;&#20869;&#23384;&#21644;&#35745;&#31639;&#25104;&#26412;&#12290;&#27492;&#22806;&#65292;&#22312;&#29616;&#26377;&#30340;&#26368;&#20248;&#31639;&#27861;&#20013;&#65292;&#20026;&#20102;&#23454;&#29616;&#26368;&#20248;&#26679;&#26412;&#25928;&#29575;&#65292;&#25152;&#26377;&#31639;&#27861;&#37117;&#35201;&#32463;&#36807;&#36739;&#38271;&#30340;&#28903;&#21270;&#26102;&#38388;&#65292;&#21363;&#21482;&#26377;&#26679;&#26412;&#23481;&#37327;&#36229;&#36807;&#19968;&#20010;&#39640;&#38408;&#20540;&#25165;&#33021;&#20445;&#35777;&#26368;&#20248;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#24341;&#20837;&#19968;&#31181;&#26080;&#27169;&#22411;&#31639;&#27861;&#26469;&#35299;&#20915;&#36825;&#20004;&#20010;&#24320;&#25918;&#24615;&#38382;&#39064;&#65292;&#35813;&#31639;&#27861;&#37319;&#29992;&#26041;&#24046;&#32553;&#20943;&#21644;&#19968;&#31181;&#24930;&#32780;&#33258;&#36866;&#24212;&#30340;&#25191;&#34892;&#31574;&#30053;&#36716;&#25442;&#25216;&#26415;&#12290;&#36825;&#26159;&#25240;&#25187;&#35774;&#32622;&#19979;&#31532;&#19968;&#20010;&#20855;&#26377;&#36951;&#25022;&#26368;&#20248;&#30340;&#26080;&#27169;&#22411;&#31639;&#27861;&#65292;&#24182;&#20855;&#26377;&#20302;&#28903;&#21270;&#26102;&#38388;&#30340;&#39069;&#22806;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
A crucial problem in reinforcement learning is learning the optimal policy. We study this in tabular infinite-horizon discounted Markov decision processes under the online setting. The existing algorithms either fail to achieve regret optimality or have to incur a high memory and computational cost. In addition, existing optimal algorithms all require a long burn-in time in order to achieve optimal sample efficiency, i.e., their optimality is not guaranteed unless sample size surpasses a high threshold. We address both open problems by introducing a model-free algorithm that employs variance reduction and a novel technique that switches the execution policy in a slow-yet-adaptive manner. This is the first regret-optimal model-free algorithm in the discounted setting, with the additional benefit of a low burn-in time.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#25552;&#20986;&#20102;&#20351;&#29992;CNN&#23398;&#20064;&#31354;&#38388;&#36807;&#31243;&#30340;&#20284;&#28982;&#20989;&#25968;&#12290;&#21363;&#20351;&#22312;&#27809;&#26377;&#30830;&#20999;&#20284;&#28982;&#20989;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#20998;&#31867;&#20219;&#21153;&#36827;&#34892;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#65292;&#21487;&#20197;&#38544;&#24335;&#22320;&#23398;&#20064;&#20284;&#28982;&#20989;&#25968;&#12290;&#20351;&#29992;Platt&#32553;&#25918;&#21487;&#20197;&#25552;&#39640;&#31070;&#32463;&#20284;&#28982;&#38754;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.04634</link><description>&lt;p&gt;
&#31354;&#38388;&#36807;&#31243;&#30340;&#31070;&#32463;&#20284;&#28982;&#38754;
&lt;/p&gt;
&lt;p&gt;
Neural Likelihood Surfaces for Spatial Processes with Computationally Intensive or Intractable Likelihoods. (arXiv:2305.04634v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04634
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#25552;&#20986;&#20102;&#20351;&#29992;CNN&#23398;&#20064;&#31354;&#38388;&#36807;&#31243;&#30340;&#20284;&#28982;&#20989;&#25968;&#12290;&#21363;&#20351;&#22312;&#27809;&#26377;&#30830;&#20999;&#20284;&#28982;&#20989;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#36890;&#36807;&#20998;&#31867;&#20219;&#21153;&#36827;&#34892;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#65292;&#21487;&#20197;&#38544;&#24335;&#22320;&#23398;&#20064;&#20284;&#28982;&#20989;&#25968;&#12290;&#20351;&#29992;Platt&#32553;&#25918;&#21487;&#20197;&#25552;&#39640;&#31070;&#32463;&#20284;&#28982;&#38754;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31354;&#38388;&#32479;&#35745;&#20013;&#65292;&#24403;&#25311;&#21512;&#31354;&#38388;&#36807;&#31243;&#21040;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#26102;&#65292;&#24555;&#36895;&#20934;&#30830;&#30340;&#21442;&#25968;&#20272;&#35745;&#21644;&#21487;&#38752;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#25163;&#27573;&#21487;&#33021;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#22240;&#20026;&#20284;&#28982;&#20989;&#25968;&#21487;&#33021;&#35780;&#20272;&#32531;&#24930;&#25110;&#38590;&#20197;&#22788;&#29702;&#12290; &#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#23398;&#20064;&#31354;&#38388;&#36807;&#31243;&#30340;&#20284;&#28982;&#20989;&#25968;&#12290;&#36890;&#36807;&#29305;&#23450;&#35774;&#35745;&#30340;&#20998;&#31867;&#20219;&#21153;&#65292;&#25105;&#20204;&#30340;&#31070;&#32463;&#32593;&#32476;&#38544;&#24335;&#22320;&#23398;&#20064;&#20284;&#28982;&#20989;&#25968;&#65292;&#21363;&#20351;&#22312;&#27809;&#26377;&#26174;&#24335;&#21487;&#29992;&#30340;&#30830;&#20999;&#20284;&#28982;&#20989;&#25968;&#30340;&#24773;&#20917;&#19979;&#20063;&#21487;&#20197;&#23454;&#29616;&#12290;&#19968;&#26086;&#22312;&#20998;&#31867;&#20219;&#21153;&#19978;&#36827;&#34892;&#20102;&#35757;&#32451;&#65292;&#25105;&#20204;&#30340;&#31070;&#32463;&#32593;&#32476;&#20351;&#29992;Platt&#32553;&#25918;&#36827;&#34892;&#26657;&#20934;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#31070;&#32463;&#20284;&#28982;&#38754;&#30340;&#20934;&#30830;&#24615;&#12290;&#20026;&#20102;&#23637;&#31034;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#25105;&#20204;&#27604;&#36739;&#20102;&#26469;&#33258;&#31070;&#32463;&#20284;&#28982;&#38754;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#21644;&#36817;&#20284;&#32622;&#20449;&#21306;&#38388;&#19982;&#20004;&#20010;&#19981;&#21516;&#31354;&#38388;&#36807;&#31243;&#65288;&#39640;&#26031;&#36807;&#31243;&#21644;&#23545;&#25968;&#39640;&#26031;Cox&#36807;&#31243;&#65289;&#30340;&#30456;&#24212;&#31934;&#30830;&#25110;&#36817;&#20284;&#30340;&#20284;&#28982;&#20989;&#25968;&#26500;&#25104;&#30340;&#31561;&#25928;&#29289;&#12290;
&lt;/p&gt;
&lt;p&gt;
In spatial statistics, fast and accurate parameter estimation coupled with a reliable means of uncertainty quantification can be a challenging task when fitting a spatial process to real-world data because the likelihood function might be slow to evaluate or intractable. In this work, we propose using convolutional neural networks (CNNs) to learn the likelihood function of a spatial process. Through a specifically designed classification task, our neural network implicitly learns the likelihood function, even in situations where the exact likelihood is not explicitly available. Once trained on the classification task, our neural network is calibrated using Platt scaling which improves the accuracy of the neural likelihood surfaces. To demonstrate our approach, we compare maximum likelihood estimates and approximate confidence regions constructed from the neural likelihood surface with the equivalent for exact or approximate likelihood for two different spatial processes: a Gaussian Pro
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861; Iterative Markovian Fitting&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#24230; Schr\"odinger&#26725;&#65288;SBs&#65289;&#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#30340;&#25968;&#20540;&#23454;&#39564;&#34920;&#29616;&#20986;&#22312;&#20934;&#30830;&#24615;&#21644;&#24615;&#33021;&#26041;&#38754;&#30340;&#26174;&#33879;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2303.16852</link><description>&lt;p&gt;
&#25193;&#25955;Schr\"odinger&#26725;&#21305;&#37197;
&lt;/p&gt;
&lt;p&gt;
Diffusion Schr\"odinger Bridge Matching. (arXiv:2303.16852v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16852
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861; Iterative Markovian Fitting&#65292;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#24230; Schr\"odinger&#26725;&#65288;SBs&#65289;&#38382;&#39064;&#65292;&#35813;&#26041;&#27861;&#30340;&#25968;&#20540;&#23454;&#39564;&#34920;&#29616;&#20986;&#22312;&#20934;&#30830;&#24615;&#21644;&#24615;&#33021;&#26041;&#38754;&#30340;&#26174;&#33879;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35299;&#20915;&#36816;&#36755;&#38382;&#39064;&#65292;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#26377;&#30528;&#35768;&#22810;&#24212;&#29992;&#65292;&#20363;&#22914;&#26032;&#22411;&#30340;&#36136;&#37327;&#20256;&#36755;&#26041;&#27861;&#65292;&#22914;&#21435;&#22122;&#25193;&#25955;&#27169;&#22411;&#65288;DDMs&#65289;&#21644;&#27969;&#21305;&#37197;&#27169;&#22411;&#65288;FMMs&#65289;&#65292;&#36890;&#36807;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;SDE&#65289;&#25110;&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;ODE&#65289;&#23454;&#29616;&#36825;&#26679;&#30340;&#20256;&#36755;&#12290;&#28982;&#32780;&#65292;&#34429;&#28982;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#65292;&#36817;&#20284;&#30830;&#23450;&#24615;&#21160;&#24577;&#26368;&#20248;&#20256;&#36755;&#65288;OT&#65289;&#26144;&#23556;&#26159;&#21487;&#21462;&#30340;&#65292;&#22240;&#20026;&#20855;&#26377;&#21560;&#24341;&#20154;&#30340;&#24615;&#36136;&#65292;&#20294; DDMs &#21644; FMMs &#24182;&#19981;&#33021;&#20445;&#35777;&#25552;&#20379;&#25509;&#36817; OT &#26144;&#23556;&#30340;&#20256;&#36755;&#12290;&#30456;&#21453;&#65292;Schr\"odinger&#26725;&#65288;SBs&#65289;&#35745;&#31639;&#38543;&#26426;&#21160;&#24577;&#26144;&#23556;&#65292;&#21487;&#20197;&#24674;&#22797;&#27491;&#21017;&#29109;&#29256;&#26412;&#30340; OT&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#29616;&#26377;&#30340;&#25968;&#20540;&#26041;&#27861;&#36817;&#20284; SBs &#30340;&#32500;&#24230;&#32553;&#25918;&#24046;&#25110;&#22312;&#36845;&#20195;&#20013;&#31215;&#32047;&#35823;&#24046;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#36845;&#20195;&#39532;&#23572;&#31185;&#22827;&#25311;&#21512;&#65292;&#19968;&#31181;&#35299;&#20915;&#39640;&#32500;&#24230; SB &#38382;&#39064;&#30340;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#26041;&#27861;&#35774;&#35745;&#20026;&#19968;&#20010;&#36845;&#20195;&#36807;&#31243;&#65292;&#23558;&#32622;&#20449;&#20256;&#25773;&#25193;&#23637;&#21040; KL &#25955;&#24230;&#65292;&#21033;&#29992;&#26465;&#20214;&#29420;&#31435;&#24615;&#38477;&#20302;&#35745;&#31639;&#22797;&#26434;&#24230;&#65292;&#24182;&#30830;&#20445;&#19968;&#33268;&#24615;&#21644;&#25910;&#25947;&#24615;&#36136;&#12290;&#25105;&#20204;&#30340;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#30456;&#23545;&#20110;&#29616;&#26377;&#25104;&#26524;&#26041;&#27861;&#65292;&#22312;&#20934;&#30830;&#24615;&#21644;&#24615;&#33021;&#26041;&#38754;&#37117;&#26377;&#26174;&#33879;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Solving transport problems, i.e. finding a map transporting one given distribution to another, has numerous applications in machine learning. Novel mass transport methods motivated by generative modeling have recently been proposed, e.g. Denoising Diffusion Models (DDMs) and Flow Matching Models (FMMs) implement such a transport through a Stochastic Differential Equation (SDE) or an Ordinary Differential Equation (ODE). However, while it is desirable in many applications to approximate the deterministic dynamic Optimal Transport (OT) map which admits attractive properties, DDMs and FMMs are not guaranteed to provide transports close to the OT map. In contrast, Schr\"odinger bridges (SBs) compute stochastic dynamic mappings which recover entropy-regularized versions of OT. Unfortunately, existing numerical methods approximating SBs either scale poorly with dimension or accumulate errors across iterations. In this work, we introduce Iterative Markovian Fitting, a new methodology for solv
&lt;/p&gt;</description></item><item><title>&#31526;&#21512;&#24615;&#36125;&#21494;&#26031;&#20248;&#21270;&#22312;&#20915;&#31574;&#36807;&#31243;&#20013;&#24212;&#29992;&#31526;&#21512;&#24615;&#39044;&#27979;&#38598;&#65292;&#21487;&#20197;&#32416;&#27491;&#30001;&#20110;&#27169;&#22411;&#35268;&#33539;&#19981;&#24403;&#21644;&#21327;&#21464;&#37327;&#36716;&#31227;&#24102;&#26469;&#30340;&#20027;&#35266;&#19978;&#19981;&#21487;&#33021;&#30340;&#32467;&#26524;&#65292;&#24182;&#22312;&#40657;&#30418;&#20248;&#21270;&#20219;&#21153;&#21644;&#34920;&#26684;&#25490;&#21517;&#20219;&#21153;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;</title><link>http://arxiv.org/abs/2210.12496</link><description>&lt;p&gt;
&#24102;&#26377;&#31526;&#21512;&#24615;&#39044;&#27979;&#38598;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Bayesian Optimization with Conformal Prediction Sets. (arXiv:2210.12496v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.12496
&lt;/p&gt;
&lt;p&gt;
&#31526;&#21512;&#24615;&#36125;&#21494;&#26031;&#20248;&#21270;&#22312;&#20915;&#31574;&#36807;&#31243;&#20013;&#24212;&#29992;&#31526;&#21512;&#24615;&#39044;&#27979;&#38598;&#65292;&#21487;&#20197;&#32416;&#27491;&#30001;&#20110;&#27169;&#22411;&#35268;&#33539;&#19981;&#24403;&#21644;&#21327;&#21464;&#37327;&#36716;&#31227;&#24102;&#26469;&#30340;&#20027;&#35266;&#19978;&#19981;&#21487;&#33021;&#30340;&#32467;&#26524;&#65292;&#24182;&#22312;&#40657;&#30418;&#20248;&#21270;&#20219;&#21153;&#21644;&#34920;&#26684;&#25490;&#21517;&#20219;&#21153;&#20013;&#34920;&#29616;&#20248;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#26159;&#38754;&#23545;&#19981;&#30830;&#23450;&#24615;&#26102;&#20570;&#20986;&#20915;&#31574;&#30340;&#26222;&#36941;&#26041;&#27861;&#65292;&#24212;&#29992;&#21253;&#25324;&#22810;&#33218;&#32769;&#34382;&#26426;&#12289;&#20027;&#21160;&#23398;&#20064;&#21644;&#40657;&#30418;&#20248;&#21270;&#12290;&#36125;&#21494;&#26031;&#20248;&#21270;&#36890;&#36807;&#22522;&#20110;&#36125;&#21494;&#26031;&#27169;&#22411;&#30340;&#21518;&#39564;&#20998;&#24067;&#36873;&#25321;&#20855;&#26377;&#26368;&#22823;&#39044;&#26399;&#25928;&#29992;&#30340;&#20915;&#31574;(&#21363;&#30446;&#26631;&#20989;&#25968;&#26597;&#35810;)&#65292;&#35813;&#21518;&#39564;&#20998;&#24067;&#37327;&#21270;&#20102;&#26597;&#35810;&#32467;&#26524;&#30340;&#21487;&#20943;&#23569;&#30340;&#20808;&#39564;&#20449;&#24687;&#19981;&#30830;&#23450;&#24615;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#22240;&#27169;&#22411;&#35268;&#33539;&#19981;&#24403;&#21644;&#21327;&#21464;&#37327;&#36716;&#31227;&#30340;&#21407;&#22240;&#65292;&#20027;&#35266;&#19978;&#19981;&#21487;&#33021;&#30340;&#32467;&#26524;&#21487;&#33021;&#32463;&#24120;&#21457;&#29983;&#12290;&#31526;&#21512;&#24615;&#39044;&#27979;&#26159;&#19968;&#31181;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#27861;&#65292;&#21363;&#20351;&#23545;&#20110;&#35268;&#33539;&#19981;&#33391;&#30340;&#27169;&#22411;&#20063;&#20855;&#26377;&#35206;&#30422;&#20445;&#35777;&#65292;&#24182;&#19988;&#20855;&#26377;&#32416;&#27491;&#21327;&#21464;&#37327;&#36716;&#31227;&#30340;&#31616;&#21333;&#26426;&#21046;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#31526;&#21512;&#24615;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#23558;&#26597;&#35810;&#24341;&#23548;&#21040;&#27169;&#22411;&#39044;&#27979;&#20855;&#26377;&#20445;&#35777;&#26377;&#25928;&#24615;&#30340;&#25628;&#32034;&#31354;&#38388;&#21306;&#22495;&#65292;&#24182;&#30740;&#31350;&#20102;&#23427;&#22312;&#19968;&#32452;&#40657;&#30418;&#20248;&#21270;&#20219;&#21153;&#21644;&#34920;&#26684;&#25490;&#21517;&#20219;&#21153;&#20013;&#30340;&#34892;&#20026;&#12290;&#22312;&#35768;&#22810;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#21457;&#29616;&#31526;&#21512;&#24615;&#36125;&#21494;&#26031;&#20248;&#21270;&#20248;&#20110;&#26631;&#20934;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian optimization is a coherent, ubiquitous approach to decision-making under uncertainty, with applications including multi-arm bandits, active learning, and black-box optimization. Bayesian optimization selects decisions (i.e. objective function queries) with maximal expected utility with respect to the posterior distribution of a Bayesian model, which quantifies reducible, epistemic uncertainty about query outcomes. In practice, subjectively implausible outcomes can occur regularly for two reasons: 1) model misspecification and 2) covariate shift. Conformal prediction is an uncertainty quantification method with coverage guarantees even for misspecified models and a simple mechanism to correct for covariate shift. We propose conformal Bayesian optimization, which directs queries towards regions of search space where the model predictions have guaranteed validity, and investigate its behavior on a suite of black-box optimization tasks and tabular ranking tasks. In many cases we f
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#21033;&#29992;&#23616;&#37096;&#20989;&#25968;&#22797;&#26434;&#24615;&#65288;LFC&#65289;&#30340;&#20272;&#35745;&#65292;&#24314;&#31435;&#20102;&#19968;&#20010;&#23616;&#37096;&#32467;&#26500;&#22797;&#26434;&#24615;&#30340;&#27010;&#24565;&#65292;&#24182;&#23558;&#20854;&#29992;&#20110;&#21457;&#23637;&#19968;&#20010;&#19982;&#27169;&#22411;&#26080;&#20851;&#30340;&#20027;&#21160;&#23398;&#20064;&#26694;&#26550;&#12290;&#36890;&#36807;&#20351;&#29992;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#65288;GPR&#65289;&#30340;&#23616;&#37096;&#22810;&#39033;&#24335;&#24179;&#28369;&#65288;LPS&#65289;&#27169;&#22411;&#30340;&#31867;&#27604;&#65292;&#20351;&#24471;&#35813;&#26694;&#26550;&#20855;&#26377;&#40065;&#26834;&#24615;&#21644;&#21487;&#20280;&#32553;&#24615;&#12290;</title><link>http://arxiv.org/abs/1902.10664</link><description>&lt;p&gt;
&#36890;&#36807;&#39640;&#26031;&#36807;&#31243;&#28151;&#21512;&#23454;&#29616;&#20027;&#21160;&#23398;&#20064;&#20013;&#30340;&#23616;&#37096;&#20989;&#25968;&#22797;&#26434;&#24615;
&lt;/p&gt;
&lt;p&gt;
Local Function Complexity for Active Learning via Mixture of Gaussian Processes. (arXiv:1902.10664v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1902.10664
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#21033;&#29992;&#23616;&#37096;&#20989;&#25968;&#22797;&#26434;&#24615;&#65288;LFC&#65289;&#30340;&#20272;&#35745;&#65292;&#24314;&#31435;&#20102;&#19968;&#20010;&#23616;&#37096;&#32467;&#26500;&#22797;&#26434;&#24615;&#30340;&#27010;&#24565;&#65292;&#24182;&#23558;&#20854;&#29992;&#20110;&#21457;&#23637;&#19968;&#20010;&#19982;&#27169;&#22411;&#26080;&#20851;&#30340;&#20027;&#21160;&#23398;&#20064;&#26694;&#26550;&#12290;&#36890;&#36807;&#20351;&#29992;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#65288;GPR&#65289;&#30340;&#23616;&#37096;&#22810;&#39033;&#24335;&#24179;&#28369;&#65288;LPS&#65289;&#27169;&#22411;&#30340;&#31867;&#27604;&#65292;&#20351;&#24471;&#35813;&#26694;&#26550;&#20855;&#26377;&#40065;&#26834;&#24615;&#21644;&#21487;&#20280;&#32553;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#30340;&#19981;&#22343;&#21248;&#24615;&#65292;&#20363;&#22914;&#35266;&#27979;&#22122;&#22768;&#27700;&#24179;&#30340;&#21464;&#21270;&#25110;&#28304;&#20989;&#25968;&#32467;&#26500;&#22797;&#26434;&#24615;&#30340;&#21464;&#21270;&#65292;&#32473;&#32479;&#35745;&#25512;&#26029;&#24102;&#26469;&#20102;&#19968;&#31995;&#21015;&#29420;&#29305;&#30340;&#25361;&#25112;&#12290;&#32771;&#34385;&#21040;&#36825;&#20123;&#22240;&#32032;&#21487;&#20197;&#22312;&#29289;&#29702;&#36164;&#28304;&#25110;&#35745;&#31639;&#26102;&#38388;&#26377;&#38480;&#30340;&#24773;&#20917;&#19979;&#26174;&#33879;&#25552;&#39640;&#39044;&#27979;&#33021;&#21147;&#12290;&#26412;&#25991;&#20511;&#37492;&#20102;&#26368;&#36817;&#20851;&#20110;&#23616;&#37096;&#22810;&#39033;&#24335;&#24179;&#28369;&#65288;LPS&#65289;&#39046;&#22495;&#20013;&#23616;&#37096;&#20989;&#25968;&#22797;&#26434;&#24615;&#65288;LFC&#65289;&#30340;&#20272;&#35745;&#30340;&#29702;&#35770;&#32467;&#26524;&#65292;&#24314;&#31435;&#20102;&#19968;&#20010;&#23616;&#37096;&#32467;&#26500;&#22797;&#26434;&#24615;&#30340;&#27010;&#24565;&#65292;&#24182;&#29992;&#23427;&#26469;&#24320;&#21457;&#19968;&#20010;&#19982;&#27169;&#22411;&#26080;&#20851;&#30340;&#20027;&#21160;&#23398;&#20064;&#65288;AL&#65289;&#26694;&#26550;&#12290;&#30001;&#20110;&#20854;&#20381;&#36182;&#20110;&#28857;&#20272;&#35745;&#65292;LPS&#27169;&#22411;&#31867;&#22312;&#22788;&#29702;&#36890;&#24120;&#20276;&#38543;&#30495;&#23454;&#19990;&#30028;&#38382;&#39064;&#30340;&#22823;&#36755;&#20837;&#31354;&#38388;&#32500;&#24230;&#26102;&#19981;&#20855;&#26377;&#40065;&#26834;&#24615;&#21644;&#21487;&#20280;&#32553;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25512;&#23548;&#21644;&#20272;&#35745;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#65288;GPR&#65289;&#30340;LPS-based LFC&#30340;&#31867;&#27604;&#65292;&#24182;&#23558;&#20854;&#20316;&#20026;&#20197;&#19978;&#26694;&#26550;&#30340;&#26367;&#20195;&#65292;&#20351;&#20043;&#20855;&#26377;&#40065;&#26834;&#24615;&#21644;&#21487;&#20280;&#32553;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Inhomogeneities in real-world data, e.g., due to changes in the observation noise level or variations in the structural complexity of the source function, pose a unique set of challenges for statistical inference. Accounting for them can greatly improve predictive power when physical resources or computation time is limited. In this paper, we draw on recent theoretical results on the estimation of local function complexity (LFC), derived from the domain of local polynomial smoothing (LPS), to establish a notion of local structural complexity, which is used to develop a model-agnostic active learning (AL) framework. Due to its reliance on pointwise estimates, the LPS model class is not robust and scalable concerning large input space dimensions that typically come along with real-world problems. Here, we derive and estimate the Gaussian process regression (GPR)-based analog of the LPS-based LFC and use it as a substitute in the above framework to make it robust and scalable. We assess t
&lt;/p&gt;</description></item></channel></rss>