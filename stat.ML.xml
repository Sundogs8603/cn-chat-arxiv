<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#25968;&#25454;&#20381;&#36182;&#32806;&#21512;&#26469;&#26500;&#24314;&#29983;&#25104;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#36229;&#20998;&#36776;&#29575;&#21644;&#20462;&#22797;&#20219;&#21153;&#20013;&#30340;&#23454;&#39564;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.03725</link><description>&lt;p&gt;
&#20855;&#26377;&#25968;&#25454;&#20381;&#36182;&#32806;&#21512;&#30340;&#38543;&#26426;&#25554;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic interpolants with data-dependent couplings. (arXiv:2310.03725v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.03725
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#25968;&#25454;&#20381;&#36182;&#32806;&#21512;&#26469;&#26500;&#24314;&#29983;&#25104;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#36229;&#20998;&#36776;&#29575;&#21644;&#20462;&#22797;&#20219;&#21153;&#20013;&#30340;&#23454;&#39564;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#21160;&#24577;&#27979;&#24230;&#20256;&#36755;&#21551;&#21457;&#30340;&#29983;&#25104;&#27169;&#22411;&#65288;&#22914;&#27969;&#21644;&#25193;&#25955;&#65289;&#26500;&#24314;&#20102;&#20004;&#20010;&#27010;&#29575;&#23494;&#24230;&#20043;&#38388;&#30340;&#36830;&#32493;&#26102;&#38388;&#26144;&#23556;&#12290;&#25353;&#29031;&#20256;&#32479;&#26041;&#27861;&#65292;&#20854;&#20013;&#19968;&#20010;&#26159;&#30446;&#26631;&#23494;&#24230;&#65292;&#21482;&#33021;&#36890;&#36807;&#26679;&#26412;&#35775;&#38382;&#65292;&#32780;&#21478;&#19968;&#20010;&#26159;&#31616;&#21333;&#30340;&#22522;&#30784;&#23494;&#24230;&#65292;&#19982;&#25968;&#25454;&#26080;&#20851;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#38543;&#26426;&#25554;&#20540;&#30340;&#26694;&#26550;&#65292;&#35268;&#33539;&#21270;&#20102;&#22914;&#20309;&#8220;&#32806;&#21512;&#8221;&#22522;&#26412;&#23494;&#24230;&#21644;&#30446;&#26631;&#23494;&#24230;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#23558;&#31867;&#21035;&#26631;&#31614;&#25110;&#36830;&#32493;&#23884;&#20837;&#30340;&#20449;&#24687;&#32435;&#20837;&#21040;&#26500;&#24314;&#21160;&#24577;&#20256;&#36755;&#26144;&#23556;&#30340;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#20013;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#36807;&#35299;&#20915;&#31867;&#20284;&#20110;&#26631;&#20934;&#29420;&#31435;&#35774;&#32622;&#30340;&#31616;&#21333;&#24179;&#26041;&#25439;&#22833;&#22238;&#24402;&#38382;&#39064;&#26469;&#23398;&#20064;&#36825;&#20123;&#20256;&#36755;&#26144;&#23556;&#12290;&#36890;&#36807;&#36229;&#20998;&#36776;&#29575;&#21644;&#20462;&#22797;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#26500;&#24314;&#20381;&#36182;&#32806;&#21512;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative models inspired by dynamical transport of measure -- such as flows and diffusions -- construct a continuous-time map between two probability densities. Conventionally, one of these is the target density, only accessible through samples, while the other is taken as a simple base density that is data-agnostic. In this work, using the framework of stochastic interpolants, we formalize how to \textit{couple} the base and the target densities. This enables us to incorporate information about class labels or continuous embeddings to construct dynamical transport maps that serve as conditional generative models. We show that these transport maps can be learned by solving a simple square loss regression problem analogous to the standard independent setting. We demonstrate the usefulness of constructing dependent couplings in practice through experiments in super-resolution and in-painting.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#24615;&#31163;&#31574;&#30053;&#20540;&#20989;&#25968;&#20272;&#35745;&#20013;&#30340;&#36924;&#36817;&#22240;&#23376;&#65292;&#24182;&#22312;&#22810;&#31181;&#35774;&#32622;&#19979;&#24314;&#31435;&#20102;&#26368;&#20248;&#30340;&#28176;&#36817;&#36924;&#36817;&#22240;&#23376;&#65292;&#36825;&#20123;&#22240;&#23376;&#20915;&#23450;&#20102;&#31163;&#31574;&#30053;&#35780;&#20272;&#30340;&#22256;&#38590;&#31243;&#24230;&#12290;</title><link>http://arxiv.org/abs/2307.13332</link><description>&lt;p&gt;
&#22312;&#38169;&#35823;&#25351;&#23450;&#30340;&#31163;&#31574;&#30053;&#20540;&#20989;&#25968;&#20272;&#35745;&#20013;&#30340;&#26368;&#20339;&#36924;&#36817;&#22240;&#23376;
&lt;/p&gt;
&lt;p&gt;
The Optimal Approximation Factors in Misspecified Off-Policy Value Function Estimation. (arXiv:2307.13332v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.13332
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#24615;&#31163;&#31574;&#30053;&#20540;&#20989;&#25968;&#20272;&#35745;&#20013;&#30340;&#36924;&#36817;&#22240;&#23376;&#65292;&#24182;&#22312;&#22810;&#31181;&#35774;&#32622;&#19979;&#24314;&#31435;&#20102;&#26368;&#20248;&#30340;&#28176;&#36817;&#36924;&#36817;&#22240;&#23376;&#65292;&#36825;&#20123;&#22240;&#23376;&#20915;&#23450;&#20102;&#31163;&#31574;&#30053;&#35780;&#20272;&#30340;&#22256;&#38590;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24050;&#32463;&#30693;&#36947;&#65292;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#29702;&#35770;&#20445;&#35777;&#22312;&#20989;&#25968;&#36924;&#36817;&#30340;&#38169;&#35823;&#25351;&#23450;&#20013;&#20250;&#20986;&#29616;&#20056;&#27861;&#25918;&#22823;&#22240;&#23376;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;\emph{&#36924;&#36817;&#22240;&#23376;}&#30340;&#24615;&#36136;&#65292;&#29305;&#21035;&#26159;&#22312;&#32473;&#23450;&#30340;&#23398;&#20064;&#38382;&#39064;&#20013;&#30340;&#26368;&#20339;&#24418;&#24335;&#65292;&#20173;&#28982;&#19981;&#20026;&#20154;&#25152;&#20102;&#35299;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#36825;&#20010;&#38382;&#39064;&#22312;&#32447;&#24615;&#31163;&#31574;&#30053;&#20540;&#20989;&#25968;&#20272;&#35745;&#20013;&#30340;&#24191;&#27867;&#35774;&#32622;&#20013;&#30340;&#36924;&#36817;&#22240;&#23376;&#65292;&#20854;&#20013;&#20173;&#26377;&#35768;&#22810;&#24320;&#25918;&#38382;&#39064;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#22810;&#31181;&#35774;&#32622;&#19979;&#30340;&#36924;&#36817;&#22240;&#23376;&#65292;&#20363;&#22914;&#21152;&#26435;$L_2$&#33539;&#25968;&#65288;&#20854;&#20013;&#21152;&#26435;&#26159;&#31163;&#32447;&#29366;&#24577;&#20998;&#24067;&#65289;&#65292;$L_\infty$&#33539;&#25968;&#65292;&#29366;&#24577;&#21035;&#21517;&#30340;&#23384;&#22312;&#19982;&#21542;&#20197;&#21450;&#23545;&#29366;&#24577;&#31354;&#38388;&#30340;&#20840;&#38754;&#19982;&#37096;&#20998;&#35206;&#30422;&#12290;&#23545;&#20110;&#25152;&#26377;&#36825;&#20123;&#35774;&#32622;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#26368;&#20248;&#30340;&#28176;&#36817;&#36924;&#36817;&#22240;&#23376;&#65288;&#33267;&#22810;&#24120;&#25968;&#65289;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#30340;&#30028;&#38480;&#30830;&#23450;&#20102;$L_2(\mu)$&#33539;&#25968;&#30340;&#20004;&#20010;&#20381;&#36182;&#20110;&#23454;&#20363;&#30340;&#22240;&#23376;&#21644;$L_\infty$&#33539;&#25968;&#30340;&#19968;&#20010;&#22240;&#23376;&#65292;&#23427;&#20204;&#34987;&#35777;&#26126;&#20915;&#23450;&#20102;&#31163;&#31574;&#30053;&#35780;&#20272;&#30340;&#22256;&#38590;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Theoretical guarantees in reinforcement learning (RL) are known to suffer multiplicative blow-up factors with respect to the misspecification error of function approximation. Yet, the nature of such \emph{approximation factors} -especially their optimal form in a given learning problem -- is poorly understood. In this paper we study this question in linear off-policy value function estimation, where many open questions remain. We study the approximation factor in a broad spectrum of settings, such as with the weighted $L_2$-norm (where the weighting is the offline state distribution), the $L_\infty$ norm, the presence vs. absence of state aliasing, and full vs. partial coverage of the state space. We establish the optimal asymptotic approximation factors (up to constants) for all of these settings. In particular, our bounds identify two instance-dependent factors for the $L_2(\mu)$ norm and only one for the $L_\infty$ norm, which are shown to dictate the hardness of off-policy evalua
&lt;/p&gt;</description></item><item><title>&#38750;&#32447;&#24615;&#20803;&#23398;&#20064;&#21487;&#20197;&#20445;&#35777;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2307.10870</link><description>&lt;p&gt;
&#38750;&#32447;&#24615;&#20803;&#23398;&#20064;&#21487;&#20197;&#20445;&#35777;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;
&lt;/p&gt;
&lt;p&gt;
Nonlinear Meta-Learning Can Guarantee Faster Rates. (arXiv:2307.10870v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10870
&lt;/p&gt;
&lt;p&gt;
&#38750;&#32447;&#24615;&#20803;&#23398;&#20064;&#21487;&#20197;&#20445;&#35777;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#35768;&#22810;&#20851;&#20110;&#20803;&#23398;&#20064;&#30340;&#29702;&#35770;&#30740;&#31350;&#26088;&#22312;&#21033;&#29992;&#30456;&#20851;&#20219;&#21153;&#20013;&#30340;&#30456;&#20284;&#34920;&#31034;&#32467;&#26500;&#26469;&#31616;&#21270;&#30446;&#26631;&#20219;&#21153;&#65292;&#24182;&#23454;&#29616;&#25910;&#25947;&#36895;&#29575;&#30340;&#20445;&#35777;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#34920;&#31034;&#24448;&#24448;&#26159;&#39640;&#24230;&#38750;&#32447;&#24615;&#30340;&#65292;&#24341;&#20837;&#20102;&#27599;&#20010;&#20219;&#21153;&#20013;&#19981;&#21487;&#31616;&#21333;&#24179;&#22343;&#30340;&#38750;&#24179;&#20961;&#20559;&#24046;&#12290;&#26412;&#30740;&#31350;&#36890;&#36807;&#38750;&#32447;&#24615;&#34920;&#31034;&#25512;&#23548;&#20986;&#20803;&#23398;&#20064;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many recent theoretical works on \emph{meta-learning} aim to achieve guarantees in leveraging similar representational structures from related tasks towards simplifying a target task. Importantly, the main aim in theory works on the subject is to understand the extent to which convergence rates -- in learning a common representation -- \emph{may scale with the number $N$ of tasks} (as well as the number of samples per task). First steps in this setting demonstrate this property when both the shared representation amongst tasks, and task-specific regression functions, are linear. This linear setting readily reveals the benefits of aggregating tasks, e.g., via averaging arguments. In practice, however, the representation is often highly nonlinear, introducing nontrivial biases in each task that cannot easily be averaged out as in the linear case. In the present work, we derive theoretical guarantees for meta-learning with nonlinear representations. In particular, assuming the shared nonl
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#24067;&#24335;&#21322;&#30417;&#30563;&#31232;&#30095;&#32479;&#35745;&#25512;&#26029;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#34701;&#21512;&#20102;&#26377;/&#26080;&#26631;&#31614;&#25968;&#25454;&#65292;&#20026;M&#20272;&#35745;&#21644;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#25552;&#20379;&#20102;&#23450;&#21046;&#21435;&#20559;&#26041;&#27861;&#65292;&#24182;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#24212;&#29992;&#20013;&#23637;&#31034;&#20102;&#32467;&#21512;&#26080;&#26631;&#31614;&#25968;&#25454;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.10395</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#21322;&#30417;&#30563;&#31232;&#30095;&#32479;&#35745;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Distributed Semi-Supervised Sparse Statistical Inference. (arXiv:2306.10395v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.10395
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#24067;&#24335;&#21322;&#30417;&#30563;&#31232;&#30095;&#32479;&#35745;&#25512;&#26029;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#34701;&#21512;&#20102;&#26377;/&#26080;&#26631;&#31614;&#25968;&#25454;&#65292;&#20026;M&#20272;&#35745;&#21644;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#25552;&#20379;&#20102;&#23450;&#21046;&#21435;&#20559;&#26041;&#27861;&#65292;&#24182;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#24212;&#29992;&#20013;&#23637;&#31034;&#20102;&#32467;&#21512;&#26080;&#26631;&#31614;&#25968;&#25454;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#24067;&#24335;&#29615;&#22659;&#19979;&#21322;&#30417;&#30563;&#31232;&#30095;&#32479;&#35745;&#25512;&#26029;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#22810;&#36718;&#20998;&#24067;&#24335;&#21435;&#20559;&#20272;&#35745;&#22120;&#65292;&#23427;&#34701;&#21512;&#20102;&#26377;&#26631;&#35760;&#21644;&#26080;&#26631;&#35760;&#25968;&#25454;&#65292;&#24182;&#19988;&#28436;&#31034;&#20102;&#39069;&#22806;&#30340;&#26080;&#26631;&#31614;&#25968;&#25454;&#22914;&#20309;&#24110;&#21161;&#25552;&#39640;&#27599;&#36718;&#36845;&#20195;&#30340;&#32479;&#35745;&#36895;&#29575;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20026;$M$- &#20272;&#35745;&#21644;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#25552;&#20379;&#20102;&#37327;&#36523;&#23450;&#21046;&#30340;&#21435;&#20559;&#26041;&#27861;&#65292;&#20855;&#20307;&#26681;&#25454;&#25439;&#22833;&#20989;&#25968;&#30340;&#29305;&#23450;&#24418;&#24335;&#32780;&#23450;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#36824;&#21487;&#20197;&#24212;&#29992;&#20110;&#38750;&#20809;&#28369;&#25439;&#22833;&#65292;&#20363;&#22914;&#32477;&#23545;&#20559;&#24046;&#25439;&#22833;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#35745;&#31639;&#25928;&#29575;&#39640;&#65292;&#22240;&#20026;&#23427;&#21482;&#38656;&#35201;&#39640;&#32500;&#36870;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#20272;&#35745;&#12290;&#36890;&#36807;&#27169;&#25311;&#30740;&#31350;&#21644;&#30495;&#23454;&#25968;&#25454;&#24212;&#29992;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#24182;&#31361;&#20986;&#20102;&#32467;&#21512;&#26080;&#26631;&#31614;&#25968;&#25454;&#30340;&#22909;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper is devoted to studying the semi-supervised sparse statistical inference in a distributed setup. An efficient multi-round distributed debiased estimator, which integrates both labeled and unlabelled data, is developed. We will show that the additional unlabeled data helps to improve the statistical rate of each round of iteration. Our approach offers tailored debiasing methods for $M$-estimation and generalized linear model according to the specific form of the loss function. Our method also applies to a non-smooth loss like absolute deviation loss. Furthermore, our algorithm is computationally efficient since it requires only one estimation of a high-dimensional inverse covariance matrix. We demonstrate the effectiveness of our method by presenting simulation studies and real data applications that highlight the benefits of incorporating unlabeled data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#36335;&#24452;&#30456;&#20851;&#30340;&#31070;&#32463;&#36339;&#36291;ODE&#23545;&#36890;&#29992;&#21160;&#21147;&#23398;&#36827;&#34892;&#26368;&#20248;&#20272;&#35745;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#25903;&#25345;&#20102;&#36825;&#20123;&#29702;&#35770;&#32467;&#26524;&#65292;&#23637;&#31034;&#20102;&#20854;&#22312;&#38750;&#39532;&#23572;&#21487;&#22827;&#25968;&#25454;&#21644;&#38480;&#20215;&#35746;&#21333;&#31807;&#25968;&#25454;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2206.14284</link><description>&lt;p&gt;
&#20351;&#29992;&#36335;&#24452;&#30456;&#20851;&#30340;&#31070;&#32463;&#36339;&#36291;ODE&#23545;&#36890;&#29992;&#21160;&#21147;&#23398;&#36827;&#34892;&#26368;&#20248;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Optimal Estimation of Generic Dynamics by Path-Dependent Neural Jump ODEs. (arXiv:2206.14284v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.14284
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#36335;&#24452;&#30456;&#20851;&#30340;&#31070;&#32463;&#36339;&#36291;ODE&#23545;&#36890;&#29992;&#21160;&#21147;&#23398;&#36827;&#34892;&#26368;&#20248;&#20272;&#35745;&#30340;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#25903;&#25345;&#20102;&#36825;&#20123;&#29702;&#35770;&#32467;&#26524;&#65292;&#23637;&#31034;&#20102;&#20854;&#22312;&#38750;&#39532;&#23572;&#21487;&#22827;&#25968;&#25454;&#21644;&#38480;&#20215;&#35746;&#21333;&#31807;&#25968;&#25454;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#31070;&#32463;&#36339;&#36291;ODE&#65288;NJ-ODE&#65289;&#26694;&#26550;&#30340;&#36335;&#24452;&#30456;&#20851;&#25193;&#23637;&#26469;&#39044;&#27979;&#19968;&#33324;&#38543;&#26426;&#36807;&#31243;&#30340;&#38382;&#39064;&#12290;&#34429;&#28982;NJ-ODE&#26159;&#31532;&#19968;&#20010;&#24314;&#31435;&#36215;&#38024;&#23545;&#19981;&#35268;&#21017;&#35266;&#27979;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#25910;&#25947;&#24615;&#20445;&#35777;&#30340;&#26694;&#26550;&#65292;&#20294;&#36825;&#20123;&#32467;&#26524;&#20165;&#36866;&#29992;&#20110;&#26469;&#33258;&#20855;&#26377;&#23436;&#25972;&#35266;&#27979;&#30340;It\^o&#25193;&#25955;&#30340;&#25968;&#25454;&#65292;&#29305;&#21035;&#26159;&#25152;&#26377;&#22352;&#26631;&#21516;&#26102;&#35266;&#27979;&#21040;&#30340;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#21033;&#29992;&#31614;&#21517;&#21464;&#25442;&#30340;&#37325;&#26500;&#24615;&#36136;&#23558;&#36825;&#20123;&#32467;&#26524;&#25512;&#24191;&#21040;&#36890;&#29992;&#30340;&#12289;&#21487;&#33021;&#26159;&#38750;&#39532;&#23572;&#21487;&#22827;&#25110;&#19981;&#36830;&#32493;&#30340;&#38543;&#26426;&#36807;&#31243;&#65292;&#24182;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#25903;&#25345;&#20102;&#36825;&#20123;&#29702;&#35770;&#32467;&#26524;&#65292;&#22312;&#38750;&#39532;&#23572;&#21487;&#22827;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#36335;&#24452;&#30456;&#20851;&#30340;NJ-ODE&#20248;&#20110;&#21407;&#22987;NJ-ODE&#26694;&#26550;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;PD-NJ-ODE&#21487;&#20197;&#25104;&#21151;&#24212;&#29992;&#20110;&#32463;&#20856;&#30340;&#38543;&#26426;&#28388;&#27874;&#38382;&#39064;&#21644;&#38480;&#20215;&#35746;&#21333;&#31807;&#65288;LOB&#65289;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the problem of forecasting general stochastic processes using a path-dependent extension of the Neural Jump ODE (NJ-ODE) framework. While NJ-ODE was the first framework to establish convergence guarantees for the prediction of irregularly observed time series, these results were limited to data stemming from It\^o-diffusions with complete observations, in particular Markov processes where all coordinates are observed simultaneously. In this work, we generalise these results to generic, possibly non-Markovian or discontinuous, stochastic processes with incomplete observations, by utilising the reconstruction properties of the signature transform. These theoretical results are supported by empirical studies, where it is shown that the path-dependent NJ-ODE outperforms the original NJ-ODE framework in the case of non-Markovian data. Moreover, we show that PD-NJ-ODE can be applied successfully to classical stochastic filtering problems and to limit order book (LOB) data.
&lt;/p&gt;</description></item></channel></rss>