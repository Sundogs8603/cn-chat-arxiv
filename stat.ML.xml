<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;ODE&#30340;&#28145;&#24230;&#29983;&#25104;&#26041;&#27861;&#65292;&#36890;&#36807;&#26465;&#20214;Follmer&#27969;&#26469;&#23398;&#20064;&#26465;&#20214;&#20998;&#24067;&#65292;&#36890;&#36807;&#31163;&#25955;&#21270;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#39640;&#25928;&#36716;&#21270;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;Wasserstein&#36317;&#31163;&#30340;&#38750;&#28176;&#36817;&#25910;&#25947;&#36895;&#29575;&#65292;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#31471;&#21040;&#31471;&#35823;&#24046;&#20998;&#26512;&#65292;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20854;&#22312;&#19981;&#21516;&#22330;&#26223;&#19979;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01460</link><description>&lt;p&gt;
&#28145;&#24230;&#26465;&#20214;&#29983;&#25104;&#23398;&#20064;&#65306;&#27169;&#22411;&#19982;&#35823;&#24046;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Deep Conditional Generative Learning: Model and Error Analysis
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01460
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;ODE&#30340;&#28145;&#24230;&#29983;&#25104;&#26041;&#27861;&#65292;&#36890;&#36807;&#26465;&#20214;Follmer&#27969;&#26469;&#23398;&#20064;&#26465;&#20214;&#20998;&#24067;&#65292;&#36890;&#36807;&#31163;&#25955;&#21270;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#39640;&#25928;&#36716;&#21270;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;Wasserstein&#36317;&#31163;&#30340;&#38750;&#28176;&#36817;&#25910;&#25947;&#36895;&#29575;&#65292;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#31471;&#21040;&#31471;&#35823;&#24046;&#20998;&#26512;&#65292;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20854;&#22312;&#19981;&#21516;&#22330;&#26223;&#19979;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26222;&#36890;&#24494;&#20998;&#26041;&#31243;&#65288;ODE&#65289;&#30340;&#28145;&#24230;&#29983;&#25104;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#26465;&#20214;&#20998;&#24067;&#65292;&#31216;&#20026;&#26465;&#20214;Follmer&#27969;&#12290;&#20174;&#26631;&#20934;&#39640;&#26031;&#20998;&#24067;&#24320;&#22987;&#65292;&#25152;&#25552;&#20986;&#30340;&#27969;&#33021;&#22815;&#20197;&#39640;&#25928;&#30340;&#26041;&#24335;&#23558;&#20854;&#36716;&#21270;&#20026;&#30446;&#26631;&#26465;&#20214;&#20998;&#24067;&#65292;&#22312;&#26102;&#38388;1&#22788;&#36798;&#21040;&#31283;&#23450;&#12290;&#20026;&#20102;&#26377;&#25928;&#23454;&#29616;&#65292;&#25105;&#20204;&#20351;&#29992;&#27431;&#25289;&#26041;&#27861;&#23545;&#27969;&#36827;&#34892;&#31163;&#25955;&#21270;&#65292;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#38750;&#21442;&#25968;&#21270;&#20272;&#35745;&#36895;&#24230;&#22330;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23548;&#20986;&#20102;&#23398;&#20064;&#26679;&#26412;&#30340;&#20998;&#24067;&#19982;&#30446;&#26631;&#20998;&#24067;&#20043;&#38388;&#30340;Wasserstein&#36317;&#31163;&#30340;&#38750;&#28176;&#36817;&#25910;&#25947;&#36895;&#29575;&#65292;&#22312;&#26465;&#20214;&#20998;&#24067;&#23398;&#20064;&#20013;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#20840;&#38754;&#30340;&#31471;&#21040;&#31471;&#35823;&#24046;&#20998;&#26512;&#12290;&#25105;&#20204;&#30340;&#25968;&#20540;&#23454;&#39564;&#23637;&#31034;&#20102;&#23427;&#22312;&#19968;&#31995;&#21015;&#24773;&#20917;&#19979;&#30340;&#26377;&#25928;&#24615;&#65292;&#20174;&#26631;&#20934;&#30340;&#38750;&#21442;&#25968;&#21270;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#38382;&#39064;&#21040;&#28041;&#21450;&#22270;&#20687;&#25968;&#25454;&#30340;&#26356;&#22797;&#26434;&#30340;&#25361;&#25112;&#65292;&#35828;&#26126;&#23427;&#20248;&#20110;&#21508;&#31181;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce an Ordinary Differential Equation (ODE) based deep generative method for learning a conditional distribution, named the Conditional Follmer Flow. Starting from a standard Gaussian distribution, the proposed flow could efficiently transform it into the target conditional distribution at time 1. For effective implementation, we discretize the flow with Euler's method where we estimate the velocity field nonparametrically using a deep neural network. Furthermore, we derive a non-asymptotic convergence rate in the Wasserstein distance between the distribution of the learned samples and the target distribution, providing the first comprehensive end-to-end error analysis for conditional distribution learning via ODE flow. Our numerical experiments showcase its effectiveness across a range of scenarios, from standard nonparametric conditional density estimation problems to more intricate challenges involving image data, illustrating its superiority over various existing condition
&lt;/p&gt;</description></item><item><title>&#20171;&#32461;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#20989;&#25968;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19981;&#20381;&#36182;&#20110;&#24378;&#20984;&#20551;&#35774;&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#20202;&#34920;&#22238;&#24402;&#21644;&#24378;&#21270;&#23398;&#20064;&#20219;&#21153;&#20013;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#30340;&#20248;&#21183;&#12290;</title><link>https://arxiv.org/abs/2403.20233</link><description>&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#20989;&#25968;&#21452;&#23618;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Functional Bilevel Optimization for Machine Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.20233
&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#20989;&#25968;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19981;&#20381;&#36182;&#20110;&#24378;&#20984;&#20551;&#35774;&#30340;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#20202;&#34920;&#22238;&#24402;&#21644;&#24378;&#21270;&#23398;&#20064;&#20219;&#21153;&#20013;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#38024;&#23545;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#30340;&#19968;&#31181;&#26032;&#30340;&#20989;&#25968;&#35270;&#35282;&#65292;&#20854;&#20013;&#20869;&#37096;&#30446;&#26631;&#22312;&#20989;&#25968;&#31354;&#38388;&#19978;&#34987;&#26368;&#23567;&#21270;&#12290;&#36825;&#20123;&#31867;&#22411;&#30340;&#38382;&#39064;&#36890;&#24120;&#36890;&#36807;&#22312;&#21442;&#25968;&#35774;&#32622;&#19979;&#24320;&#21457;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#65292;&#20854;&#20013;&#20869;&#37096;&#30446;&#26631;&#23545;&#20110;&#39044;&#27979;&#20989;&#25968;&#30340;&#21442;&#25968;&#24378;&#20984;&#12290;&#20989;&#25968;&#35270;&#35282;&#19981;&#20381;&#36182;&#20110;&#27492;&#20551;&#35774;&#65292;&#29305;&#21035;&#20801;&#35768;&#20351;&#29992;&#36229;&#21442;&#25968;&#21270;&#30340;&#31070;&#32463;&#32593;&#32476;&#20316;&#20026;&#20869;&#37096;&#39044;&#27979;&#20989;&#25968;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#21487;&#25193;&#23637;&#21644;&#39640;&#25928;&#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#20989;&#25968;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#22312;&#36866;&#21512;&#33258;&#28982;&#20989;&#25968;&#21452;&#23618;&#32467;&#26500;&#30340;&#20202;&#34920;&#22238;&#24402;&#21644;&#24378;&#21270;&#23398;&#20064;&#20219;&#21153;&#19978;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.20233v1 Announce Type: cross  Abstract: In this paper, we introduce a new functional point of view on bilevel optimization problems for machine learning, where the inner objective is minimized over a function space. These types of problems are most often solved by using methods developed in the parametric setting, where the inner objective is strongly convex with respect to the parameters of the prediction function. The functional point of view does not rely on this assumption and notably allows using over-parameterized neural networks as the inner prediction function. We propose scalable and efficient algorithms for the functional bilevel optimization problem and illustrate the benefits of our approach on instrumental regression and reinforcement learning tasks, which admit natural functional bilevel structures.
&lt;/p&gt;</description></item><item><title>&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#20026;&#20102;&#30830;&#20445;&#39640;&#36136;&#37327;&#30340;&#25512;&#26029;&#27169;&#22411;&#65292;&#21487;&#20197;&#36890;&#36807;&#36845;&#20195;&#35757;&#32451;&#26368;&#22823;&#21270;&#19982;&#25512;&#26029;&#27169;&#22411;&#30456;&#20851;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#20197;&#35299;&#20915;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#20013;&#25512;&#26029;&#27169;&#22411;&#36817;&#20284;&#19981;&#20934;&#30830;&#23548;&#33268;&#30340;&#23616;&#37096;&#26368;&#20248;&#35299;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2403.08941</link><description>&lt;p&gt;
&#38754;&#21521;&#27169;&#22411;&#26080;&#20851;&#21518;&#39564;&#36924;&#36817;&#30340;&#24555;&#36895;&#20934;&#30830;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;
&lt;/p&gt;
&lt;p&gt;
Towards Model-Agnostic Posterior Approximation for Fast and Accurate Variational Autoencoders
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08941
&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#20026;&#20102;&#30830;&#20445;&#39640;&#36136;&#37327;&#30340;&#25512;&#26029;&#27169;&#22411;&#65292;&#21487;&#20197;&#36890;&#36807;&#36845;&#20195;&#35757;&#32451;&#26368;&#22823;&#21270;&#19982;&#25512;&#26029;&#27169;&#22411;&#30456;&#20851;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#20197;&#35299;&#20915;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#20013;&#25512;&#26029;&#27169;&#22411;&#36817;&#20284;&#19981;&#20934;&#30830;&#23548;&#33268;&#30340;&#23616;&#37096;&#26368;&#20248;&#35299;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;VAEs&#65289;&#30340;&#25512;&#26029;&#21253;&#25324;&#23398;&#20064;&#20004;&#20010;&#27169;&#22411;&#65306;&#65288;1&#65289;&#29983;&#25104;&#27169;&#22411;&#65292;&#23558;&#28508;&#22312;&#31354;&#38388;&#19978;&#30340;&#31616;&#21333;&#20998;&#24067;&#36716;&#25442;&#20026;&#35266;&#27979;&#25968;&#25454;&#20998;&#24067;&#65292;&#20197;&#21450;&#65288;2&#65289;&#25512;&#26029;&#27169;&#22411;&#65292;&#36817;&#20284;&#32473;&#23450;&#25968;&#25454;&#30340;&#28508;&#22312;&#32534;&#30721;&#21518;&#39564;&#12290;&#36825;&#20004;&#20010;&#32452;&#20214;&#36890;&#36807;&#23545;&#29983;&#25104;&#27169;&#22411;&#23545;&#25968;&#36793;&#38469;&#20284;&#28982;&#30340;&#19979;&#30028;&#36827;&#34892;&#32852;&#21512;&#23398;&#20064;&#12290;&#22312;&#32852;&#21512;&#35757;&#32451;&#30340;&#26089;&#26399;&#38454;&#27573;&#65292;&#25512;&#26029;&#27169;&#22411;&#24456;&#24046;&#22320;&#36817;&#20284;&#20102;&#28508;&#22312;&#32534;&#30721;&#21518;&#39564;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#36825;&#23548;&#33268;&#20248;&#21270;&#38519;&#20837;&#23616;&#37096;&#26368;&#20248;&#35299;&#65292;&#23545;&#23398;&#20064;&#21040;&#30340;&#29983;&#25104;&#27169;&#22411;&#36896;&#25104;&#36127;&#38754;&#24433;&#21709;&#12290;&#22240;&#27492;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#24314;&#35758;&#36890;&#36807;&#36845;&#20195;&#35757;&#32451;&#30830;&#20445;&#39640;&#36136;&#37327;&#30340;&#25512;&#26029;&#27169;&#22411;&#65306;&#30456;&#23545;&#20110;&#29983;&#25104;&#27169;&#22411;&#30340;&#27599;&#27425;&#26356;&#26032;&#20043;&#21069;&#26368;&#22823;&#21270;&#19982;&#25512;&#26029;&#27169;&#22411;&#30456;&#20851;&#30340;&#30446;&#26631;&#20989;&#25968;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#36845;&#20195;&#35757;&#32451;&#25928;&#29575;&#20302;&#65292;&#38656;&#35201;&#21551;&#21457;&#24335;&#26631;&#20934;&#26469;&#20174;&#36845;&#20195;&#20013;&#24674;&#22797;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08941v1 Announce Type: cross  Abstract: Inference for Variational Autoencoders (VAEs) consists of learning two models: (1) a generative model, which transforms a simple distribution over a latent space into the distribution over observed data, and (2) an inference model, which approximates the posterior of the latent codes given data. The two components are learned jointly via a lower bound to the generative model's log marginal likelihood. In early phases of joint training, the inference model poorly approximates the latent code posteriors. Recent work showed that this leads optimization to get stuck in local optima, negatively impacting the learned generative model. As such, recent work suggests ensuring a high-quality inference model via iterative training: maximizing the objective function relative to the inference model before every update to the generative model. Unfortunately, iterative training is inefficient, requiring heuristic criteria for reverting from iterative
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;Brenier&#30340;&#26497;&#20998;&#35299;&#23450;&#29702;&#30340;&#31070;&#32463;&#23454;&#29616;&#65292;&#25506;&#35752;&#20102;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#28508;&#22312;&#20989;&#25968;$u$&#65292;&#20174;&#26368;&#26032;&#31070;&#32463;&#26368;&#20248;&#36755;&#36816;&#39046;&#22495;&#30340;&#36827;&#23637;&#20013;&#27762;&#21462;&#28789;&#24863;&#12290;</title><link>https://arxiv.org/abs/2403.03071</link><description>&lt;p&gt;
&#35770;Brenier&#30340;&#26497;&#20998;&#35299;&#30340;&#31070;&#32463;&#23454;&#29616;
&lt;/p&gt;
&lt;p&gt;
On a Neural Implementation of Brenier's Polar Factorization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.03071
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;Brenier&#30340;&#26497;&#20998;&#35299;&#23450;&#29702;&#30340;&#31070;&#32463;&#23454;&#29616;&#65292;&#25506;&#35752;&#20102;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#36890;&#36807;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#21270;&#28508;&#22312;&#20989;&#25968;$u$&#65292;&#20174;&#26368;&#26032;&#31070;&#32463;&#26368;&#20248;&#36755;&#36816;&#39046;&#22495;&#30340;&#36827;&#23637;&#20013;&#27762;&#21462;&#28789;&#24863;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;1991&#24180;&#65292;Brenier&#35777;&#26126;&#20102;&#19968;&#20010;&#23450;&#29702;&#65292;&#23558;$QR$&#20998;&#35299;&#65288;&#20998;&#20026;&#21322;&#27491;&#23450;&#30697;&#38453;$\times$&#37193;&#30697;&#38453;&#65289;&#25512;&#24191;&#21040;&#20219;&#24847;&#30690;&#37327;&#22330;$F:\mathbb{R}^d\rightarrow \mathbb{R}^d$&#12290;&#36825;&#20010;&#34987;&#31216;&#20026;&#26497;&#20998;&#35299;&#23450;&#29702;&#30340;&#23450;&#29702;&#34920;&#26126;&#65292;&#20219;&#24847;&#22330;$F$&#37117;&#21487;&#20197;&#34920;&#31034;&#20026;&#20984;&#20989;&#25968;$u$&#30340;&#26799;&#24230;&#19982;&#20445;&#27979;&#24230;&#26144;&#23556;$M$&#30340;&#22797;&#21512;&#65292;&#21363;$F=\nabla u \circ M$&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#36825;&#19968;&#20855;&#26377;&#28145;&#36828;&#29702;&#35770;&#24847;&#20041;&#30340;&#32467;&#26524;&#30340;&#23454;&#38469;&#23454;&#29616;&#65292;&#24182;&#25506;&#35752;&#20102;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#21487;&#33021;&#30340;&#24212;&#29992;&#12290;&#35813;&#23450;&#29702;&#19982;&#26368;&#20248;&#36755;&#36816;&#65288;OT&#65289;&#29702;&#35770;&#23494;&#20999;&#30456;&#20851;&#65292;&#25105;&#20204;&#20511;&#37492;&#20102;&#31070;&#32463;&#26368;&#20248;&#36755;&#36816;&#39046;&#22495;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#23558;&#28508;&#22312;&#20989;&#25968;$u$&#21442;&#25968;&#21270;&#20026;&#36755;&#20837;&#20984;&#31070;&#32463;&#32593;&#32476;&#12290;&#26144;&#23556;$M$&#21487;&#20197;&#36890;&#36807;&#20351;&#29992;$u^*$&#65292;&#21363;$u$&#30340;&#20984;&#20849;&#36717;&#65292;&#36880;&#28857;&#35745;&#31639;&#24471;&#21040;&#65292;&#21363;$M=\nabla u^* \circ F$&#65292;&#25110;&#32773;&#20316;&#20026;&#36741;&#21161;&#32593;&#32476;&#23398;&#20064;&#24471;&#21040;&#12290;&#22240;&#20026;$M$&#22312;&#22522;&#22240;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.03071v1 Announce Type: cross  Abstract: In 1991, Brenier proved a theorem that generalizes the $QR$ decomposition for square matrices -- factored as PSD $\times$ unitary -- to any vector field $F:\mathbb{R}^d\rightarrow \mathbb{R}^d$. The theorem, known as the polar factorization theorem, states that any field $F$ can be recovered as the composition of the gradient of a convex function $u$ with a measure-preserving map $M$, namely $F=\nabla u \circ M$. We propose a practical implementation of this far-reaching theoretical result, and explore possible uses within machine learning. The theorem is closely related to optimal transport (OT) theory, and we borrow from recent advances in the field of neural optimal transport to parameterize the potential $u$ as an input convex neural network. The map $M$ can be either evaluated pointwise using $u^*$, the convex conjugate of $u$, through the identity $M=\nabla u^* \circ F$, or learned as an auxiliary network. Because $M$ is, in gene
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#21644;&#19978;&#19979;&#25991;&#23398;&#20064;&#26041;&#27861;&#23454;&#29616;PDE&#36816;&#31639;&#31526;&#23398;&#20064;&#30340;&#39640;&#25928;&#26041;&#24335;&#65292;&#20197;&#25552;&#39640;&#25968;&#25454;&#25928;&#29575;&#24182;&#25913;&#21892;&#27169;&#22411;&#30340;&#22806;&#22495;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.15734</link><description>&lt;p&gt;
&#36890;&#36807;&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#21644;&#19978;&#19979;&#25991;&#23398;&#20064;&#23454;&#29616;&#39640;&#25928;&#30340;&#36816;&#31639;&#31526;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Data-Efficient Operator Learning via Unsupervised Pretraining and In-Context Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15734
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#21644;&#19978;&#19979;&#25991;&#23398;&#20064;&#26041;&#27861;&#23454;&#29616;PDE&#36816;&#31639;&#31526;&#23398;&#20064;&#30340;&#39640;&#25928;&#26041;&#24335;&#65292;&#20197;&#25552;&#39640;&#25968;&#25454;&#25928;&#29575;&#24182;&#25913;&#21892;&#27169;&#22411;&#30340;&#22806;&#22495;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#20154;&#20204;&#35265;&#35777;&#20102;&#23558;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#19982;&#29289;&#29702;&#39046;&#22495;&#29305;&#23450;&#27934;&#23519;&#21147;&#30456;&#32467;&#21512;&#65292;&#20197;&#35299;&#20915;&#22522;&#20110;&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;PDEs&#65289;&#30340;&#31185;&#23398;&#38382;&#39064;&#30340;&#28508;&#21147;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#25968;&#25454;&#23494;&#38598;&#65292;&#36825;&#20123;&#26041;&#27861;&#20173;&#28982;&#38656;&#35201;&#22823;&#37327;PDE&#25968;&#25454;&#12290; &#36825;&#37325;&#26032;&#24341;&#20837;&#20102;&#23545;&#26114;&#36149;&#30340;&#25968;&#20540;PDE&#35299;&#20915;&#26041;&#26696;&#30340;&#38656;&#27714;&#65292;&#37096;&#20998;&#21066;&#24369;&#20102;&#36991;&#20813;&#36825;&#20123;&#26114;&#36149;&#27169;&#25311;&#30340;&#21407;&#22987;&#30446;&#26631;&#12290; &#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#20026;&#20102;&#23547;&#27714;&#25968;&#25454;&#25928;&#29575;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#29992;&#20110;PDE&#36816;&#31639;&#31526;&#23398;&#20064;&#30340;&#26080;&#30417;&#30563;&#39044;&#35757;&#32451;&#21644;&#19978;&#19979;&#25991;&#23398;&#20064;&#26041;&#27861;&#12290; &#20026;&#20102;&#20943;&#23569;&#23545;&#24102;&#26377;&#27169;&#25311;&#35299;&#30340;&#35757;&#32451;&#25968;&#25454;&#30340;&#38656;&#27714;&#65292;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;&#37325;&#26500;&#30340;&#20195;&#29702;&#20219;&#21153;&#22312;&#26410;&#26631;&#35760;&#30340;PDE&#25968;&#25454;&#19978;&#39044;&#35757;&#32451;&#31070;&#32463;&#36816;&#31639;&#31526;&#12290; &#20026;&#20102;&#25552;&#39640;&#36229;&#20986;&#20998;&#24067;&#24615;&#33021;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#24110;&#21161;&#31070;&#32463;&#36816;&#31639;&#31526;&#28789;&#27963;&#22320;&#21033;&#29992;&#19978;&#19979;&#25991;&#23398;&#20064;&#26041;&#27861;&#65292;&#32780;&#26080;&#38656;&#39069;&#22806;&#30340;&#35757;&#32451;&#25104;&#26412;&#25110;&#35774;&#35745;&#12290; &#22312;&#21508;&#31181;PD&#19978;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#35777;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15734v1 Announce Type: new  Abstract: Recent years have witnessed the promise of coupling machine learning methods and physical domain-specific insight for solving scientific problems based on partial differential equations (PDEs). However, being data-intensive, these methods still require a large amount of PDE data. This reintroduces the need for expensive numerical PDE solutions, partially undermining the original goal of avoiding these expensive simulations. In this work, seeking data efficiency, we design unsupervised pretraining and in-context learning methods for PDE operator learning. To reduce the need for training data with simulated solutions, we pretrain neural operators on unlabeled PDE data using reconstruction-based proxy tasks. To improve out-of-distribution performance, we further assist neural operators in flexibly leveraging in-context learning methods, without incurring extra training costs or designs. Extensive empirical evaluations on a diverse set of PD
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#28151;&#21512;&#29380;&#21033;&#20811;&#38647;&#20998;&#24067;&#26469;&#25913;&#36827;&#35777;&#25454;&#28145;&#24230;&#23398;&#20064;&#65288;EDL&#65289;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#20013;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#22312;&#26080;&#38480;&#26679;&#26412;&#38480;&#21046;&#19979;&#21487;&#33021;&#19981;&#20250;&#28040;&#22833;&#30340;&#38382;&#39064;&#12290;</title><link>https://arxiv.org/abs/2402.06160</link><description>&lt;p&gt;
&#36890;&#36807;&#28151;&#21512;&#29380;&#21033;&#20811;&#38647;&#20998;&#24067;&#25913;&#36827;&#35777;&#25454;&#28145;&#24230;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Improved Evidential Deep Learning via a Mixture of Dirichlet Distributions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06160
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#28151;&#21512;&#29380;&#21033;&#20811;&#38647;&#20998;&#24067;&#26469;&#25913;&#36827;&#35777;&#25454;&#28145;&#24230;&#23398;&#20064;&#65288;EDL&#65289;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#20013;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#22312;&#26080;&#38480;&#26679;&#26412;&#38480;&#21046;&#19979;&#21487;&#33021;&#19981;&#20250;&#28040;&#22833;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#19968;&#31181;&#29616;&#20195;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#26041;&#27861;&#65292;&#31216;&#20026;&#35777;&#25454;&#28145;&#24230;&#23398;&#20064;&#65288;EDL&#65289;&#65292;&#20854;&#20013;&#36890;&#36807;&#26368;&#23567;&#21270;&#29305;&#23450;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#35757;&#32451;&#21333;&#20010;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#20197;&#23398;&#20064;&#39044;&#27979;&#20998;&#24067;&#19978;&#30340;&#20803;&#20998;&#24067;&#12290;&#23613;&#31649;&#29616;&#26377;&#26041;&#27861;&#22312;&#32463;&#39564;&#24615;&#33021;&#26041;&#38754;&#34920;&#29616;&#24378;&#22823;&#65292;&#20294;Bengs&#31561;&#20154;&#30340;&#26368;&#36817;&#30740;&#31350;&#21457;&#29616;&#20102;&#29616;&#26377;&#26041;&#27861;&#30340;&#19968;&#20010;&#26681;&#26412;&#32570;&#38519;&#65306;&#21363;&#20351;&#22312;&#26080;&#38480;&#26679;&#26412;&#38480;&#21046;&#19979;&#65292;&#23398;&#20064;&#21040;&#30340;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#21487;&#33021;&#19981;&#20250;&#28040;&#22833;&#12290;&#36890;&#36807;&#25552;&#20379;&#25991;&#29486;&#20013;&#19968;&#31867;&#24191;&#27867;&#20351;&#29992;&#30340;&#30446;&#26631;&#20989;&#25968;&#30340;&#32479;&#19968;&#35270;&#35282;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#36825;&#20010;&#35266;&#23519;&#30340;&#35777;&#23454;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#25581;&#31034;&#20102;EDL&#26041;&#27861;&#26412;&#36136;&#19978;&#36890;&#36807;&#26368;&#23567;&#21270;&#20998;&#24067;&#19982;&#19982;&#26679;&#26412;&#22823;&#23567;&#26080;&#20851;&#30340;&#30446;&#26631;&#20998;&#24067;&#20043;&#38388;&#30340;&#29305;&#23450;&#24046;&#24322;&#24230;&#37327;&#26469;&#35757;&#32451;&#20803;&#20998;&#24067;&#65292;&#20174;&#32780;&#20135;&#29983;&#38169;&#35823;&#30340;&#35748;&#30693;&#19981;&#30830;&#23450;&#24615;&#12290;&#22522;&#20110;&#29702;&#35770;&#21407;&#21017;&#65292;&#25105;&#20204;&#25552;&#20986;&#36890;&#36807;&#23558;&#20854;&#24314;&#27169;&#20026;&#29380;&#21033;&#20811;&#38647;&#20998;&#24067;&#28151;&#21512;&#29289;&#26469;&#23398;&#20064;&#19968;&#33268;&#30446;&#26631;&#20998;&#24067;&#65292;&#20174;&#32780;&#25913;&#36827;&#20102;EDL&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper explores a modern predictive uncertainty estimation approach, called evidential deep learning (EDL), in which a single neural network model is trained to learn a meta distribution over the predictive distribution by minimizing a specific objective function. Despite their strong empirical performance, recent studies by Bengs et al. identify a fundamental pitfall of the existing methods: the learned epistemic uncertainty may not vanish even in the infinite-sample limit. We corroborate the observation by providing a unifying view of a class of widely used objectives from the literature. Our analysis reveals that the EDL methods essentially train a meta distribution by minimizing a certain divergence measure between the distribution and a sample-size-independent target distribution, resulting in spurious epistemic uncertainty. Grounded in theoretical principles, we propose learning a consistent target distribution by modeling it with a mixture of Dirichlet distributions and lear
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20381;&#36182;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#23574;&#38160;&#29575;&#65292;&#20027;&#35201;&#26159;&#20026;&#20102;&#36991;&#20813;&#26679;&#26412;&#22823;&#23567;&#32553;&#20943;&#23545;&#26041;&#24046;&#20135;&#29983;&#24433;&#21709;&#12290;&#24403;&#20551;&#35774;&#31867;&#21035;&#30340;&#25299;&#25169;&#32467;&#26500;&#31526;&#21512;&#26576;&#20123;&#26465;&#20214;&#26102;&#65292;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#32773;&#30340;&#24615;&#33021;&#19982;&#31867;&#21035;&#30340;&#22797;&#26434;&#24615;&#21644;&#20108;&#38454;&#32479;&#35745;&#37327;&#26377;&#20851;&#12290;</title><link>https://arxiv.org/abs/2402.05928</link><description>&lt;p&gt;
&#20381;&#36182;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#23574;&#38160;&#29575;&#65306;&#36991;&#20813;&#26679;&#26412;&#22823;&#23567;&#32553;&#20943;&#30340;&#24179;&#26041;&#25439;&#22833;
&lt;/p&gt;
&lt;p&gt;
Sharp Rates in Dependent Learning Theory: Avoiding Sample Size Deflation for the Square Loss
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05928
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20381;&#36182;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#23574;&#38160;&#29575;&#65292;&#20027;&#35201;&#26159;&#20026;&#20102;&#36991;&#20813;&#26679;&#26412;&#22823;&#23567;&#32553;&#20943;&#23545;&#26041;&#24046;&#20135;&#29983;&#24433;&#21709;&#12290;&#24403;&#20551;&#35774;&#31867;&#21035;&#30340;&#25299;&#25169;&#32467;&#26500;&#31526;&#21512;&#26576;&#20123;&#26465;&#20214;&#26102;&#65292;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#32773;&#30340;&#24615;&#33021;&#19982;&#31867;&#21035;&#30340;&#22797;&#26434;&#24615;&#21644;&#20108;&#38454;&#32479;&#35745;&#37327;&#26377;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#20381;&#36182;&#24615;&#65288;&#946;-&#28151;&#21512;&#65289;&#25968;&#25454;&#21644;&#24179;&#26041;&#25439;&#22833;&#30340;&#32479;&#35745;&#23398;&#20064;&#65292;&#22312;&#19968;&#20010;&#20551;&#35774;&#31867;&#21035;&#934;_p&#30340;&#23376;&#38598;F&#20013;&#65292;&#20854;&#20013;&#934;_p&#26159;&#33539;&#25968;&#8741;f&#8741;_&#934;_p&#8801;sup_m&#8805;1 m^{-1/p}&#8741;f&#8741;_L^m&#65292;&#20854;&#20013;p&#8712;[2&#65292;&#8734;]&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21160;&#26426;&#26159;&#22312;&#20855;&#26377;&#20381;&#36182;&#24615;&#25968;&#25454;&#30340;&#23398;&#20064;&#20013;&#23547;&#25214;&#23574;&#38160;&#30340;&#22122;&#22768;&#20132;&#20114;&#39033;&#25110;&#26041;&#24046;&#20195;&#29702;&#12290;&#22312;&#27809;&#26377;&#20219;&#20309;&#21487;&#23454;&#29616;&#24615;&#20551;&#35774;&#30340;&#24773;&#20917;&#19979;&#65292;&#20856;&#22411;&#30340;&#38750;&#28176;&#36817;&#32467;&#26524;&#26174;&#31034;&#20986;&#26041;&#24046;&#20195;&#29702;&#36890;&#36807;&#24213;&#23618;&#21327;&#21464;&#37327;&#36807;&#31243;&#30340;&#28151;&#21512;&#26102;&#38388;&#36827;&#34892;&#20102;&#20056;&#31215;&#32553;&#20943;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#21482;&#35201;&#22312;&#25105;&#20204;&#30340;&#20551;&#35774;&#31867;&#21035;F&#19978;&#65292;L^2&#21644;&#934;_p&#30340;&#25299;&#25169;&#26159;&#21487;&#27604;&#36739;&#30340;&#65292;&#21363;&#934;_p&#26159;&#19968;&#20010;&#24369;&#20122;&#39640;&#26031;&#31867;&#21035;&#65306;&#8741;f&#8741;_&#934;_p&#8818;&#8741;f&#8741;_L^2^&#951;&#65292;&#20854;&#20013;&#951;&#8712;(0&#65292;1]&#65292;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#32773;&#22312;&#20854;&#20027;&#23548;&#39033;&#20013;&#21482;&#23454;&#29616;&#20102;&#19968;&#31181;&#21482;&#20381;&#36182;&#20110;&#31867;&#21035;&#22797;&#26434;&#24615;&#21644;&#20108;&#38454;&#32479;&#35745;&#37327;&#30340;&#36895;&#29575;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#36866;&#29992;&#20110;&#35768;&#22810;&#20381;&#36182;&#24615;&#25968;&#25454;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we study statistical learning with dependent ($\beta$-mixing) data and square loss in a hypothesis class $\mathscr{F}\subset L_{\Psi_p}$ where $\Psi_p$ is the norm $\|f\|_{\Psi_p} \triangleq \sup_{m\geq 1} m^{-1/p} \|f\|_{L^m} $ for some $p\in [2,\infty]$. Our inquiry is motivated by the search for a sharp noise interaction term, or variance proxy, in learning with dependent data. Absent any realizability assumption, typical non-asymptotic results exhibit variance proxies that are deflated \emph{multiplicatively} by the mixing time of the underlying covariates process. We show that whenever the topologies of $L^2$ and $\Psi_p$ are comparable on our hypothesis class $\mathscr{F}$ -- that is, $\mathscr{F}$ is a weakly sub-Gaussian class: $\|f\|_{\Psi_p} \lesssim \|f\|_{L^2}^\eta$ for some $\eta\in (0,1]$ -- the empirical risk minimizer achieves a rate that only depends on the complexity of the class and second order statistics in its leading term. Our result holds whether t
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#20174;&#30701;&#26399;&#20449;&#21495;&#20013;&#23398;&#20064;&#25351;&#26631;&#65292;&#30452;&#25509;&#26368;&#22823;&#21270;&#25351;&#26631;&#19982;&#21271;&#26497;&#24230;&#37327;&#26631;&#20934;&#20043;&#38388;&#30340;&#32479;&#35745;&#33021;&#21147;&#65292;&#20174;&#32780;&#20943;&#23569;&#22312;&#32447;&#25511;&#21046;&#23454;&#39564;&#30340;&#25104;&#26412;&#12290;</title><link>https://arxiv.org/abs/2402.03915</link><description>&lt;p&gt;
&#23398;&#20064;&#26368;&#22823;&#21270;&#21152;&#36895;A/B&#27979;&#35797;&#30340;&#25351;&#26631;
&lt;/p&gt;
&lt;p&gt;
Learning Metrics that Maximise Power for Accelerated A/B-Tests
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03915
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#20174;&#30701;&#26399;&#20449;&#21495;&#20013;&#23398;&#20064;&#25351;&#26631;&#65292;&#30452;&#25509;&#26368;&#22823;&#21270;&#25351;&#26631;&#19982;&#21271;&#26497;&#24230;&#37327;&#26631;&#20934;&#20043;&#38388;&#30340;&#32479;&#35745;&#33021;&#21147;&#65292;&#20174;&#32780;&#20943;&#23569;&#22312;&#32447;&#25511;&#21046;&#23454;&#39564;&#30340;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25216;&#26415;&#20844;&#21496;&#20013;&#65292;&#22312;&#32447;&#25511;&#21046;&#23454;&#39564;&#26159;&#19968;&#31181;&#37325;&#35201;&#30340;&#24037;&#20855;&#65292;&#21487;&#20197;&#23454;&#29616;&#33258;&#20449;&#30340;&#20915;&#31574;&#12290;&#23450;&#20041;&#20102;&#19968;&#20010;&#21271;&#26497;&#24230;&#37327;&#26631;&#20934;&#65288;&#22914;&#38271;&#26399;&#25910;&#20837;&#25110;&#29992;&#25143;&#20445;&#30041;&#65289;&#65292;&#22312;A/B&#27979;&#35797;&#20013;&#65292;&#33021;&#22815;&#22312;&#36825;&#20010;&#25351;&#26631;&#19978;&#26377;&#32479;&#35745;&#26174;&#33879;&#25552;&#21319;&#30340;&#31995;&#32479;&#21464;&#20307;&#21487;&#20197;&#34987;&#35748;&#20026;&#26159;&#20248;&#36234;&#30340;&#12290;&#28982;&#32780;&#65292;&#21271;&#26497;&#24230;&#37327;&#26631;&#20934;&#36890;&#24120;&#20855;&#26377;&#26102;&#24310;&#21644;&#19981;&#25935;&#24863;&#24615;&#12290;&#22240;&#27492;&#65292;&#23454;&#39564;&#30340;&#25104;&#26412;&#24456;&#39640;&#65306;&#23454;&#39564;&#38656;&#35201;&#38271;&#26102;&#38388;&#36816;&#34892;&#65292;&#21363;&#20351;&#22914;&#27492;&#65292;&#20108;&#31867;&#38169;&#35823;&#65288;&#21363;&#20551;&#38452;&#24615;&#65289;&#20173;&#28982;&#26222;&#36941;&#23384;&#22312;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#30701;&#26399;&#20449;&#21495;&#20013;&#23398;&#20064;&#25351;&#26631;&#30340;&#26041;&#27861;&#65292;&#36825;&#20123;&#25351;&#26631;&#30452;&#25509;&#26368;&#22823;&#21270;&#23427;&#20204;&#30456;&#23545;&#20110;&#21271;&#26497;&#24230;&#37327;&#26631;&#20934;&#25152;&#20855;&#26377;&#30340;&#32479;&#35745;&#33021;&#21147;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#29616;&#26377;&#26041;&#27861;&#23481;&#26131;&#36807;&#25311;&#21512;&#30340;&#38382;&#39064;&#65292;&#21363;&#26356;&#39640;&#30340;&#24179;&#22343;&#24230;&#37327;&#25935;&#24863;&#24615;&#24182;&#19981;&#24847;&#21619;&#30528;&#25913;&#36827;&#20102;&#20108;&#31867;&#38169;&#35823;&#65292;&#25105;&#20204;&#24314;&#35758;&#36890;&#36807;&#26368;&#23567;&#21270;&#25351;&#26631;&#22312;&#36807;&#21435;&#23454;&#39564;&#30340;$log$&#19978;&#20135;&#29983;&#30340;$p$-value&#26469;&#35299;&#20915;&#12290;&#25105;&#20204;&#20174;&#20004;&#20010;&#31038;&#20132;&#23186;&#20307;&#24212;&#29992;&#31243;&#24207;&#20013;&#25910;&#38598;&#20102;&#36825;&#26679;&#30340;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
Online controlled experiments are a crucial tool to allow for confident decision-making in technology companies. A North Star metric is defined (such as long-term revenue or user retention), and system variants that statistically significantly improve on this metric in an A/B-test can be considered superior. North Star metrics are typically delayed and insensitive. As a result, the cost of experimentation is high: experiments need to run for a long time, and even then, type-II errors (i.e. false negatives) are prevalent.   We propose to tackle this by learning metrics from short-term signals that directly maximise the statistical power they harness with respect to the North Star. We show that existing approaches are prone to overfitting, in that higher average metric sensitivity does not imply improved type-II errors, and propose to instead minimise the $p$-values a metric would have produced on a log of past experiments. We collect such datasets from two social media applications with
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20302;&#31209;&#36866;&#37197;&#22120;&#30340;&#21160;&#21147;&#23398;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#25237;&#24433;&#30340;&#26041;&#27861;Flora&#65292;&#36890;&#36807;&#37325;&#26032;&#37319;&#26679;&#25237;&#24433;&#30697;&#38453;&#23454;&#29616;&#39640;&#31209;&#26356;&#26032;&#65292;&#21516;&#26102;&#20943;&#23569;&#20248;&#21270;&#29366;&#24577;&#30340;&#31354;&#38388;&#22797;&#26434;&#24230;&#12290;</title><link>https://arxiv.org/abs/2402.03293</link><description>&lt;p&gt;
Flora: &#20302;&#31209;&#36866;&#37197;&#22120;&#26159;&#24708;&#24708;&#30340;&#26799;&#24230;&#21387;&#32553;&#22120;
&lt;/p&gt;
&lt;p&gt;
Flora: Low-Rank Adapters Are Secretly Gradient Compressors
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.03293
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20302;&#31209;&#36866;&#37197;&#22120;&#30340;&#21160;&#21147;&#23398;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#25237;&#24433;&#30340;&#26041;&#27861;Flora&#65292;&#36890;&#36807;&#37325;&#26032;&#37319;&#26679;&#25237;&#24433;&#30697;&#38453;&#23454;&#29616;&#39640;&#31209;&#26356;&#26032;&#65292;&#21516;&#26102;&#20943;&#23569;&#20248;&#21270;&#29366;&#24577;&#30340;&#31354;&#38388;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#22823;&#22411;&#31070;&#32463;&#32593;&#32476;&#23637;&#31034;&#20102;&#23436;&#25104;&#19981;&#21516;&#20219;&#21153;&#30340;&#26174;&#30528;&#33021;&#21147;&#65292;&#20294;&#23427;&#20204;&#38656;&#35201;&#36807;&#22810;&#30340;&#20869;&#23384;&#20351;&#29992;&#26469;&#23384;&#20648;&#35757;&#32451;&#30340;&#20248;&#21270;&#29366;&#24577;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#65292;&#25552;&#20986;&#20302;&#31209;&#36866;&#37197;&#65288;LoRA&#65289;&#26469;&#36890;&#36807;&#35757;&#32451;&#26356;&#23569;&#30340;&#21442;&#25968;&#26469;&#20943;&#23569;&#20248;&#21270;&#29366;&#24577;&#12290;&#28982;&#32780;&#65292;LoRA&#23558;&#25972;&#20307;&#26435;&#37325;&#26356;&#26032;&#30697;&#38453;&#38480;&#21046;&#20026;&#20302;&#31209;&#65292;&#38480;&#21046;&#20102;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;LoRA&#30340;&#21160;&#21147;&#23398;&#65292;&#24182;&#30830;&#23450;&#23427;&#21487;&#20197;&#36817;&#20284;&#20026;&#38543;&#26426;&#25237;&#24433;&#12290;&#22522;&#20110;&#36825;&#19968;&#35266;&#23519;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Flora&#65292;&#23427;&#33021;&#22815;&#36890;&#36807;&#37325;&#26032;&#37319;&#26679;&#25237;&#24433;&#30697;&#38453;&#23454;&#29616;&#39640;&#31209;&#26356;&#26032;&#65292;&#21516;&#26102;&#20139;&#21463;&#20248;&#21270;&#29366;&#24577;&#30340;&#27425;&#32447;&#24615;&#31354;&#38388;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#22312;&#19981;&#21516;&#20219;&#21153;&#21644;&#27169;&#22411;&#26550;&#26500;&#19978;&#36827;&#34892;&#23454;&#39564;&#35777;&#23454;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite large neural networks demonstrating remarkable abilities to complete different tasks, they require excessive memory usage to store the optimization states for training. To alleviate this, the low-rank adaptation (LoRA) is proposed to reduce the optimization states by training fewer parameters. However, LoRA restricts overall weight update matrices to be low-rank, limiting the model performance. In this work, we investigate the dynamics of LoRA and identify that it can be approximated by a random projection. Based on this observation, we propose Flora, which is able to achieve high-rank updates by resampling the projection matrices while enjoying the sublinear space complexity of optimization states. We conduct experiments across different tasks and model architectures to verify the effectiveness of our approach.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22270;&#24494;&#20998;&#26041;&#31243;&#32593;&#32476;&#65288;GDeNet&#65289;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#28909;&#21644;&#27874;&#21160;&#26041;&#31243;&#21160;&#21147;&#23398;&#29305;&#24449;&#26469;&#24674;&#22797;&#22270;&#30340;&#25299;&#25169;&#23646;&#24615;&#65292;&#33021;&#22815;&#22312;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#20013;&#33719;&#24471;&#20248;&#31168;&#30340;&#34920;&#29616;&#65292;&#21516;&#26102;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#20063;&#23637;&#29616;&#20102;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.09924</link><description>&lt;p&gt;
&#22522;&#20110;&#28909;&#21644;&#27874;&#21160;&#21160;&#21147;&#23398;&#29305;&#24449;&#30340;&#22270;&#25299;&#25169;&#23646;&#24615;&#24674;&#22797;
&lt;/p&gt;
&lt;p&gt;
Graph topological property recovery with heat and wave dynamics-based features on graphsD. (arXiv:2309.09924v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.09924
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22270;&#24494;&#20998;&#26041;&#31243;&#32593;&#32476;&#65288;GDeNet&#65289;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#28909;&#21644;&#27874;&#21160;&#26041;&#31243;&#21160;&#21147;&#23398;&#29305;&#24449;&#26469;&#24674;&#22797;&#22270;&#30340;&#25299;&#25169;&#23646;&#24615;&#65292;&#33021;&#22815;&#22312;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#20013;&#33719;&#24471;&#20248;&#31168;&#30340;&#34920;&#29616;&#65292;&#21516;&#26102;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#20063;&#23637;&#29616;&#20102;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22270;&#24494;&#20998;&#26041;&#31243;&#32593;&#32476;&#65288;GDeNet&#65289;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#22270;&#19978;&#30340;PDE&#35299;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#20026;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#33719;&#24471;&#36830;&#32493;&#30340;&#33410;&#28857;&#21644;&#22270;&#32423;&#34920;&#31034;&#12290;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#28909;&#21644;&#27874;&#21160;&#26041;&#31243;&#21160;&#21147;&#23398;&#19982;&#22270;&#30340;&#35889;&#29305;&#24615;&#20197;&#21450;&#36830;&#32493;&#26102;&#38388;&#38543;&#26426;&#28216;&#36208;&#22312;&#22270;&#19978;&#34892;&#20026;&#20043;&#38388;&#30340;&#29702;&#35770;&#32467;&#26524;&#12290;&#25105;&#20204;&#36890;&#36807;&#24674;&#22797;&#38543;&#26426;&#22270;&#29983;&#25104;&#21442;&#25968;&#12289;Ricci&#26354;&#29575;&#21644;&#25345;&#20037;&#21516;&#35843;&#31561;&#26041;&#24335;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#20123;&#21160;&#21147;&#23398;&#33021;&#22815;&#25429;&#25417;&#21040;&#22270;&#24418;&#20960;&#20309;&#21644;&#25299;&#25169;&#30340;&#26174;&#33879;&#26041;&#38754;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;GDeNet&#22312;&#21253;&#25324;&#24341;&#29992;&#22270;&#12289;&#33647;&#29289;&#20998;&#23376;&#21644;&#34507;&#30333;&#36136;&#22312;&#20869;&#30340;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose Graph Differential Equation Network (GDeNet), an approach that harnesses the expressive power of solutions to PDEs on a graph to obtain continuous node- and graph-level representations for various downstream tasks. We derive theoretical results connecting the dynamics of heat and wave equations to the spectral properties of the graph and to the behavior of continuous-time random walks on graphs. We demonstrate experimentally that these dynamics are able to capture salient aspects of graph geometry and topology by recovering generating parameters of random graphs, Ricci curvature, and persistent homology. Furthermore, we demonstrate the superior performance of GDeNet on real-world datasets including citation graphs, drug-like molecules, and proteins.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#22312;&#21482;&#26377;&#24102;&#26631;&#31614;&#30340;&#21333;&#27169;&#24577;&#25968;&#25454;&#21644;&#33258;&#28982;&#20986;&#29616;&#30340;&#22810;&#27169;&#24577;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#22914;&#20309;&#37327;&#21270;&#22810;&#27169;&#24577;&#20132;&#20114;&#30340;&#25361;&#25112;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#20010;&#19979;&#30028;&#21644;&#19968;&#20010;&#19978;&#30028;&#26469;&#37327;&#21270;&#22810;&#27169;&#24577;&#20132;&#20114;&#37327;&#12290;</title><link>http://arxiv.org/abs/2306.04539</link><description>&lt;p&gt;
&#26080;&#26631;&#35760;&#22810;&#27169;&#24577;&#25968;&#25454;&#30340;&#22810;&#27169;&#24577;&#23398;&#20064;&#65306;&#20445;&#35777;&#21644;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Multimodal Learning Without Labeled Multimodal Data: Guarantees and Applications. (arXiv:2306.04539v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04539
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22312;&#21482;&#26377;&#24102;&#26631;&#31614;&#30340;&#21333;&#27169;&#24577;&#25968;&#25454;&#21644;&#33258;&#28982;&#20986;&#29616;&#30340;&#22810;&#27169;&#24577;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#22914;&#20309;&#37327;&#21270;&#22810;&#27169;&#24577;&#20132;&#20114;&#30340;&#25361;&#25112;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#20010;&#19979;&#30028;&#21644;&#19968;&#20010;&#19978;&#30028;&#26469;&#37327;&#21270;&#22810;&#27169;&#24577;&#20132;&#20114;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#20849;&#21516;&#23398;&#20064;&#22810;&#20010;&#27169;&#24577;&#30340;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#20013;&#65292;&#19968;&#20010;&#26680;&#24515;&#30340;&#30740;&#31350;&#38382;&#39064;&#26159;&#29702;&#35299;&#22810;&#27169;&#24577;&#20132;&#20114;&#30340;&#26412;&#36136;&#65306;&#22312;&#20174;&#20004;&#20010;&#37117;&#27809;&#26377;&#30340;&#27169;&#24577;&#23398;&#20064;&#26102;&#20986;&#29616;&#20102;&#26032;&#30340;&#20219;&#21153;&#30456;&#20851;&#20449;&#24687;&#12290;&#25105;&#20204;&#22312;&#21322;&#30417;&#30563;&#30340;&#24773;&#20917;&#19979;&#30740;&#31350;&#36825;&#19968;&#20132;&#20114;&#37327;&#21270;&#30340;&#25361;&#25112;&#65292;&#21482;&#20351;&#29992;&#24102;&#26631;&#31614;&#30340;&#21333;&#27169;&#24577;&#25968;&#25454;&#21644;&#33258;&#28982;&#20986;&#29616;&#30340;&#22810;&#27169;&#24577;&#25968;&#25454;&#65288;&#20363;&#22914;&#65292;&#26080;&#26631;&#31614;&#30340;&#22270;&#20687;&#21644;&#26631;&#39064;&#65292;&#35270;&#39057;&#21644;&#30456;&#24212;&#30340;&#38899;&#39057;&#65289;&#12290;&#21033;&#29992;&#31934;&#30830;&#30340;&#20449;&#24687;&#35770;&#20132;&#20114;&#23450;&#20041;&#65292;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#25512;&#23548;&#19979;&#30028;&#21644;&#19978;&#30028;&#65292;&#37327;&#21270;&#36825;&#31181;&#21322;&#30417;&#30563;&#35774;&#32622;&#19979;&#30340;&#22810;&#27169;&#24577;&#20132;&#20114;&#37327;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#27169;&#24577;&#20849;&#20139;&#20449;&#24687;&#37327;&#21644;&#21333;&#29420;&#35757;&#32451;&#30340;&#21333;&#27169;&#24577;&#20998;&#31867;&#22120;&#20043;&#38388;&#30340;&#19981;&#19968;&#33268;&#24615;&#30340;&#20004;&#20010;&#19979;&#30028;&#65292;&#24182;&#36890;&#36807;&#36830;&#25509;&#21040;&#36817;&#20284;&#31639;&#27861;&#26469;&#25512;&#23548;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
In many machine learning systems that jointly learn from multiple modalities, a core research question is to understand the nature of multimodal interactions: the emergence of new task-relevant information during learning from both modalities that was not present in either alone. We study this challenge of interaction quantification in a semi-supervised setting with only labeled unimodal data and naturally co-occurring multimodal data (e.g., unlabeled images and captions, video and corresponding audio) but when labeling them is time-consuming. Using a precise information-theoretic definition of interactions, our key contributions are the derivations of lower and upper bounds to quantify the amount of multimodal interactions in this semi-supervised setting. We propose two lower bounds based on the amount of shared information between modalities and the disagreement between separately trained unimodal classifiers, and derive an upper bound through connections to approximate algorithms fo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#26032;&#30340;&#31639;&#27861;&#31283;&#23450;&#24615;&#29702;&#35770;&#26469;&#25913;&#36827;&#20998;&#24067;&#24335;SGD&#31639;&#27861;&#30340;&#27867;&#21270;&#24615;&#33021;&#20998;&#26512;&#65292;&#25512;&#32763;&#20102;&#29616;&#26377;&#25216;&#26415;&#23545;&#36890;&#20449;&#22270;&#36127;&#38754;&#24433;&#21709;&#30340;&#35266;&#28857;&#65292;&#24182;&#23637;&#31034;&#20102;D-SGD&#22312;&#20984;&#35774;&#32622;&#20013;&#19982;&#32463;&#20856;SGD&#31639;&#27861;&#27867;&#21270;&#30028;&#30456;&#21516;&#12290;</title><link>http://arxiv.org/abs/2306.02939</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;SGD&#31639;&#27861;&#30340;&#31283;&#23450;&#24615;&#19982;&#27867;&#21270;&#20998;&#26512;&#25913;&#36827;
&lt;/p&gt;
&lt;p&gt;
Improved Stability and Generalization Analysis of the Decentralized SGD Algorithm. (arXiv:2306.02939v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02939
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#26032;&#30340;&#31639;&#27861;&#31283;&#23450;&#24615;&#29702;&#35770;&#26469;&#25913;&#36827;&#20998;&#24067;&#24335;SGD&#31639;&#27861;&#30340;&#27867;&#21270;&#24615;&#33021;&#20998;&#26512;&#65292;&#25512;&#32763;&#20102;&#29616;&#26377;&#25216;&#26415;&#23545;&#36890;&#20449;&#22270;&#36127;&#38754;&#24433;&#21709;&#30340;&#35266;&#28857;&#65292;&#24182;&#23637;&#31034;&#20102;D-SGD&#22312;&#20984;&#35774;&#32622;&#20013;&#19982;&#32463;&#20856;SGD&#31639;&#27861;&#27867;&#21270;&#30028;&#30456;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22522;&#20110;&#31639;&#27861;&#31283;&#23450;&#24615;&#65292;&#25552;&#20986;&#20102;&#20998;&#24067;&#24335;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;(D-SGD)&#31639;&#27861;&#30340;&#26032;&#30340;&#27867;&#21270;&#35823;&#24046;&#20998;&#26512;&#26041;&#27861;&#12290;&#24471;&#21040;&#30340;&#32467;&#26524;&#22823;&#22823;&#25913;&#36827;&#20102;&#29616;&#26377;&#25216;&#26415;&#65292;&#24182;&#25512;&#32763;&#20102;&#23427;&#20204;&#20851;&#20110;&#36890;&#20449;&#22270;&#23545;&#27867;&#21270;&#30340;&#36127;&#38754;&#24433;&#21709;&#30340;&#35266;&#28857;&#12290;&#20363;&#22914;&#65292;&#22312;&#20984;&#35774;&#32622;&#20013;&#65292;&#26080;&#35770;&#22270;&#30340;&#36873;&#25321;&#22914;&#20309;&#65292;D-SGD&#20855;&#26377;&#19982;&#32463;&#20856;SGD&#31639;&#27861;&#30456;&#21516;&#30340;&#27867;&#21270;&#30028;&#12290;&#25105;&#20204;&#21457;&#29616;&#36825;&#31181;&#21453;&#30452;&#35273;&#30340;&#32467;&#26524;&#26469;&#33258;&#20110;&#32771;&#34385;&#26412;&#22320;&#21442;&#25968;&#30340;&#24179;&#22343;&#20540;&#65292;&#36825;&#20250;&#38544;&#34255;&#19968;&#20010;&#19982;&#20998;&#24067;&#24335;&#22330;&#26223;&#19981;&#20860;&#23481;&#30340;&#26368;&#32456;&#20840;&#23616;&#24179;&#22343;&#21270;&#27493;&#39588;&#12290;&#32771;&#34385;&#21040;&#36825;&#19968;&#35266;&#23519;&#32467;&#26524;&#65292;&#25105;&#20204;&#20513;&#23548;&#20998;&#26512;&#26412;&#22320;&#21442;&#25968;&#30340;&#19978;&#30830;&#30028;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#22270;&#30830;&#23454;&#23545;&#27867;&#21270;&#20135;&#29983;&#24433;&#21709;&#12290;&#19982;&#20043;&#21069;&#30340;&#32467;&#26524;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#21363;&#20351;&#23545;&#20110;&#38750;&#36830;&#25509;&#22270;&#20063;&#33021;&#20135;&#29983;&#38750;&#24179;&#20961;&#36793;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a new generalization error analysis for the Decentralized Stochastic Gradient Descent (D-SGD) algorithm based on algorithmic stability. The obtained results largely improve upon state-of-the-art results, and even invalidate their claims that the communication graph has a detrimental effect on generalization. For instance, we show that in convex settings, D-SGD has the same generalization bounds as the classical SGD algorithm, no matter the choice of graph. We exhibit that this counter-intuitive result comes from considering the average of local parameters, which hides a final global averaging step incompatible with the decentralized scenario. In light of this observation, we advocate to analyze the supremum over local parameters and show that in this case, the graph does have an impact on the generalization. Unlike prior results, our analysis yields non-vacuous bounds even for non-connected graphs.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#19968;&#33324;&#22238;&#24402;&#35823;&#24046;&#20551;&#35774;&#30340;&#26080;&#22122;&#22768;&#22238;&#24402;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#20540;&#30340;&#22343;&#26041;&#35823;&#24046;&#65292;&#24182;&#21457;&#29616;&#21253;&#21547;&#22823;&#37327;&#19981;&#37325;&#35201;&#30340;&#21442;&#25968;&#21487;&#20197;&#26377;&#25928;&#22320;&#38477;&#20302;&#20272;&#35745;&#22120;&#30340;&#22343;&#26041;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2305.12883</link><description>&lt;p&gt;
&#22522;&#20110;&#19968;&#33324;&#22238;&#24402;&#35823;&#24046;&#20551;&#35774;&#26469;&#30740;&#31350;&#26080;&#22122;&#22768;&#22238;&#24402;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#20540;&#30340;&#22343;&#26041;&#35823;&#24046;
&lt;/p&gt;
&lt;p&gt;
The Mean Squared Error of the Ridgeless Least Squares Estimator under General Assumptions on Regression Errors. (arXiv:2305.12883v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12883
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#19968;&#33324;&#22238;&#24402;&#35823;&#24046;&#20551;&#35774;&#30340;&#26080;&#22122;&#22768;&#22238;&#24402;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#20540;&#30340;&#22343;&#26041;&#35823;&#24046;&#65292;&#24182;&#21457;&#29616;&#21253;&#21547;&#22823;&#37327;&#19981;&#37325;&#35201;&#30340;&#21442;&#25968;&#21487;&#20197;&#26377;&#25928;&#22320;&#38477;&#20302;&#20272;&#35745;&#22120;&#30340;&#22343;&#26041;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#26368;&#23567;$\ell_2$&#33539;&#25968;&#65288;&#26080;&#23725;&#65289;&#25554;&#20540;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#30340;&#30740;&#31350;&#26041;&#20852;&#26410;&#33406;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#20998;&#26512;&#37117;&#23616;&#38480;&#20110;&#31616;&#21333;&#30340;&#22238;&#24402;&#35823;&#24046;&#32467;&#26500;&#65292;&#20551;&#35774;&#35823;&#24046;&#26159;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#65292;&#20855;&#26377;&#38646;&#22343;&#20540;&#21644;&#30456;&#21516;&#30340;&#26041;&#24046;&#65292;&#19982;&#29305;&#24449;&#21521;&#37327;&#26080;&#20851;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#29702;&#35770;&#20998;&#26512;&#30340;&#20027;&#35201;&#37325;&#28857;&#26159;&#26679;&#26412;&#22806;&#39044;&#27979;&#39118;&#38505;&#12290;&#26412;&#25991;&#36890;&#36807;&#26816;&#26597;&#26080;&#23725;&#25554;&#20540;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#30340;&#22343;&#26041;&#35823;&#24046;&#65292;&#20801;&#35768;&#26356;&#19968;&#33324;&#30340;&#22238;&#24402;&#35823;&#24046;&#20551;&#35774;&#65292;&#25171;&#30772;&#20102;&#29616;&#26377;&#25991;&#29486;&#30340;&#23616;&#38480;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30740;&#31350;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#28508;&#22312;&#22909;&#22788;&#65292;&#36890;&#36807;&#25551;&#32472;&#26377;&#38480;&#26679;&#26412;&#20013;&#30340;&#22343;&#26041;&#35823;&#24046;&#26469;&#34920;&#24449;&#22343;&#26041;&#35823;&#24046;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#30456;&#23545;&#20110;&#26679;&#26412;&#37327;&#65292;&#21253;&#21547;&#22823;&#37327;&#19981;&#37325;&#35201;&#30340;&#21442;&#25968;&#21487;&#20197;&#26377;&#25928;&#22320;&#38477;&#20302;&#20272;&#35745;&#22120;&#30340;&#22343;&#26041;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, there has been a significant growth in research focusing on minimum $\ell_2$ norm (ridgeless) interpolation least squares estimators. However, the majority of these analyses have been limited to a simple regression error structure, assuming independent and identically distributed errors with zero mean and common variance, independent of the feature vectors. Additionally, the main focus of these theoretical analyses has been on the out-of-sample prediction risk. This paper breaks away from the existing literature by examining the mean squared error of the ridgeless interpolation least squares estimator, allowing for more general assumptions about the regression errors. Specifically, we investigate the potential benefits of overparameterization by characterizing the mean squared error in a finite sample. Our findings reveal that including a large number of unimportant parameters relative to the sample size can effectively reduce the mean squared error of the estimator. N
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23618;&#32423;&#22686;&#24378;&#23398;&#20064;&#20013;&#30340;&#30693;&#35782;&#20256;&#36755;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#27809;&#26377;&#20808;&#39564;&#30693;&#35782;&#30340;&#20219;&#21153;&#30456;&#20284;&#24615;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#24378;&#22823;&#30340;&#30693;&#35782;&#20256;&#36755;&#12290;</title><link>http://arxiv.org/abs/2302.05534</link><description>&lt;p&gt;
&#24378;&#22823;&#30340;&#23618;&#32423;&#22686;&#24378;&#23398;&#20064;&#20013;&#30340;&#30693;&#35782;&#20256;&#36755;
&lt;/p&gt;
&lt;p&gt;
Robust Knowledge Transfer in Tiered Reinforcement Learning. (arXiv:2302.05534v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.05534
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23618;&#32423;&#22686;&#24378;&#23398;&#20064;&#20013;&#30340;&#30693;&#35782;&#20256;&#36755;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#22312;&#27809;&#26377;&#20808;&#39564;&#30693;&#35782;&#30340;&#20219;&#21153;&#30456;&#20284;&#24615;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#24378;&#22823;&#30340;&#30693;&#35782;&#20256;&#36755;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23618;&#32423;&#22686;&#24378;&#23398;&#20064;&#35774;&#32622;&#65292;&#36825;&#26159;&#19968;&#20010;&#24182;&#34892;&#20256;&#36755;&#23398;&#20064;&#26694;&#26550;&#65292;&#22312;&#36825;&#20010;&#26694;&#26550;&#20013;&#65292;&#30446;&#26631;&#26159;&#23558;&#30693;&#35782;&#20174;&#20302;&#23618;&#65288;&#28304;&#65289;&#20219;&#21153;&#20256;&#36755;&#21040;&#39640;&#23618;&#65288;&#30446;&#26631;&#65289;&#20219;&#21153;&#65292;&#20197;&#20943;&#23569;&#21518;&#32773;&#30340;&#25506;&#32034;&#39118;&#38505;&#65292;&#21516;&#26102;&#24182;&#34892;&#35299;&#20915;&#36825;&#20004;&#20010;&#20219;&#21153;&#12290;&#19982;&#20808;&#21069;&#30340;&#24037;&#20316;&#19981;&#21516;&#65292;&#25105;&#20204;&#19981;&#20551;&#35774;&#20302;&#23618;&#21644;&#39640;&#23618;&#20219;&#21153;&#20849;&#20139;&#30456;&#21516;&#30340;&#21160;&#24577;&#25110;&#22870;&#21169;&#20989;&#25968;&#65292;&#24182;&#19988;&#19987;&#27880;&#20110;&#22312;&#27809;&#26377;&#20808;&#39564;&#30693;&#35782;&#30340;&#20219;&#21153;&#30456;&#20284;&#24615;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#24378;&#22823;&#30340;&#30693;&#35782;&#20256;&#36755;&#12290;&#25105;&#20204;&#30830;&#23450;&#20102;&#19968;&#20010;&#31216;&#20026;&#8220;&#26368;&#20248;&#20540;&#25903;&#37197;&#8221;&#30340;&#33258;&#28982;&#32780;&#24517;&#35201;&#30340;&#26465;&#20214;&#65292;&#36866;&#29992;&#20110;&#25105;&#20204;&#30340;&#30446;&#26631;&#12290;&#22312;&#36825;&#20010;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#20351;&#24471;&#23545;&#20110;&#39640;&#23618;&#20219;&#21153;&#65292;&#22312;&#37096;&#20998;&#29366;&#24577;&#19978;&#21487;&#20197;&#23454;&#29616;&#24658;&#23450;&#30340;&#36951;&#25022;&#65292;&#36825;&#21462;&#20915;&#20110;&#20219;&#21153;&#30456;&#20284;&#24615;&#65292;&#24182;&#22312;&#20004;&#20010;&#20219;&#21153;&#19981;&#30456;&#20284;&#26102;&#20445;&#25345;&#25509;&#36817;&#26368;&#20248;&#36951;&#25022;&#65307;&#32780;&#23545;&#20110;&#20302;&#23618;&#20219;&#21153;&#65292;&#23427;&#21487;&#20197;&#22312;&#19981;&#20570;&#20986;&#29306;&#29298;&#30340;&#24773;&#20917;&#19979;&#20445;&#25345;&#25509;&#36817;&#26368;&#20248;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#30740;&#31350;&#20102;&#20855;&#26377;&#22810;&#20010;&#20302;&#23618;&#20219;&#21153;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study the Tiered Reinforcement Learning setting, a parallel transfer learning framework, where the goal is to transfer knowledge from the low-tier (source) task to the high-tier (target) task to reduce the exploration risk of the latter while solving the two tasks in parallel. Unlike previous work, we do not assume the low-tier and high-tier tasks share the same dynamics or reward functions, and focus on robust knowledge transfer without prior knowledge on the task similarity. We identify a natural and necessary condition called the ``Optimal Value Dominance'' for our objective. Under this condition, we propose novel online learning algorithms such that, for the high-tier task, it can achieve constant regret on partial states depending on the task similarity and retain near-optimal regret when the two tasks are dissimilar, while for the low-tier task, it can keep near-optimal without making sacrifice. Moreover, we further study the setting with multiple low-tier tasks
&lt;/p&gt;</description></item></channel></rss>