<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#20998;&#26512;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#20013;&#30340;&#38160;&#24230;&#21160;&#21147;&#23398;&#65292;&#25581;&#31034;&#20986;&#26089;&#26399;&#38160;&#24230;&#38477;&#20302;&#12289;&#36880;&#28176;&#22686;&#21152;&#38160;&#21270;&#21644;&#31283;&#23450;&#36793;&#30028;&#30340;&#26426;&#21046;&#65292;&#24182;&#21457;&#29616;&#22686;&#22823;&#23398;&#20064;&#29575;&#26102;&#65292;&#31283;&#23450;&#36793;&#30028;&#27969;&#24418;&#19978;&#21457;&#29983;&#20493;&#22686;&#28151;&#27788;&#36335;&#24452;&#12290;</title><link>http://arxiv.org/abs/2311.02076</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#20013;&#30340;&#26222;&#36866;&#38160;&#24230;&#21160;&#21147;&#23398;&#65306;&#22266;&#23450;&#28857;&#20998;&#26512;&#12289;&#31283;&#23450;&#36793;&#30028;&#21644;&#28151;&#27788;&#36335;&#24452;
&lt;/p&gt;
&lt;p&gt;
Universal Sharpness Dynamics in Neural Network Training: Fixed Point Analysis, Edge of Stability, and Route to Chaos. (arXiv:2311.02076v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.02076
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#20998;&#26512;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#20013;&#30340;&#38160;&#24230;&#21160;&#21147;&#23398;&#65292;&#25581;&#31034;&#20986;&#26089;&#26399;&#38160;&#24230;&#38477;&#20302;&#12289;&#36880;&#28176;&#22686;&#21152;&#38160;&#21270;&#21644;&#31283;&#23450;&#36793;&#30028;&#30340;&#26426;&#21046;&#65292;&#24182;&#21457;&#29616;&#22686;&#22823;&#23398;&#20064;&#29575;&#26102;&#65292;&#31283;&#23450;&#36793;&#30028;&#27969;&#24418;&#19978;&#21457;&#29983;&#20493;&#22686;&#28151;&#27788;&#36335;&#24452;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31070;&#32463;&#32593;&#32476;&#30340;&#26799;&#24230;&#19979;&#38477;&#21160;&#21147;&#23398;&#20013;&#65292;&#25439;&#22833;&#20989;&#25968;&#28023;&#26862;&#30697;&#38453;&#30340;&#26368;&#22823;&#29305;&#24449;&#20540;&#65288;&#38160;&#24230;&#65289;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#23637;&#31034;&#20986;&#21508;&#31181;&#31283;&#20581;&#30340;&#29616;&#35937;&#12290;&#36825;&#21253;&#25324;&#26089;&#26399;&#26102;&#38388;&#38454;&#27573;&#65292;&#22312;&#35757;&#32451;&#30340;&#26089;&#26399;&#38454;&#27573;&#38160;&#24230;&#21487;&#33021;&#20943;&#23567;&#65288;&#38477;&#20302;&#38160;&#24230;&#65289;&#65292;&#20197;&#21450;&#21518;&#26399;&#34892;&#20026;&#65292;&#22914;&#36880;&#28176;&#22686;&#21152;&#30340;&#38160;&#21270;&#21644;&#31283;&#23450;&#36793;&#30028;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;2&#23618;&#32447;&#24615;&#32593;&#32476;&#65288;UV&#27169;&#22411;&#65289;&#65292;&#22312;&#21333;&#20010;&#35757;&#32451;&#26679;&#26412;&#19978;&#35757;&#32451;&#65292;&#23637;&#31034;&#20102;&#22312;&#30495;&#23454;&#22330;&#26223;&#20013;&#35266;&#23519;&#21040;&#30340;&#25152;&#26377;&#20851;&#38190;&#38160;&#24230;&#29616;&#35937;&#12290;&#36890;&#36807;&#20998;&#26512;&#20989;&#25968;&#31354;&#38388;&#20013;&#21160;&#21147;&#23398;&#22266;&#23450;&#28857;&#30340;&#32467;&#26500;&#21644;&#20989;&#25968;&#26356;&#26032;&#30340;&#21521;&#37327;&#22330;&#65292;&#25105;&#20204;&#25581;&#31034;&#20102;&#36825;&#20123;&#38160;&#24230;&#36235;&#21183;&#32972;&#21518;&#30340;&#26426;&#21046;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#25581;&#31034;&#20102;&#65306;(i)&#26089;&#26399;&#38160;&#24230;&#38477;&#20302;&#21644;&#36880;&#28176;&#22686;&#21152;&#38160;&#21270;&#30340;&#26426;&#21046;&#65292;(ii)&#31283;&#23450;&#36793;&#30028;&#25152;&#38656;&#30340;&#26465;&#20214;&#65292;&#20197;&#21450; (iii)&#24403;&#23398;&#20064;&#29575;&#22686;&#21152;&#26102;&#65292;&#31283;&#23450;&#36793;&#30028;&#27969;&#24418;&#19978;&#30340;&#20493;&#22686;&#28151;&#27788;&#36335;&#24452;.
&lt;/p&gt;
&lt;p&gt;
In gradient descent dynamics of neural networks, the top eigenvalue of the Hessian of the loss (sharpness) displays a variety of robust phenomena throughout training. This includes early time regimes where the sharpness may decrease during early periods of training (sharpness reduction), and later time behavior such as progressive sharpening and edge of stability. We demonstrate that a simple $2$-layer linear network (UV model) trained on a single training example exhibits all of the essential sharpness phenomenology observed in real-world scenarios. By analyzing the structure of dynamical fixed points in function space and the vector field of function updates, we uncover the underlying mechanisms behind these sharpness trends. Our analysis reveals (i) the mechanism behind early sharpness reduction and progressive sharpening, (ii) the required conditions for edge of stability, and (iii) a period-doubling route to chaos on the edge of stability manifold as learning rate is increased. Fi
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#20915;&#31574;&#20998;&#26512;&#30340;&#26041;&#27861;&#65292;&#23545;&#20110;&#20219;&#20309;&#36125;&#21494;&#26031;&#22238;&#24402;&#27169;&#22411;&#65292;&#21487;&#20197;&#24471;&#21040;&#27599;&#20010;&#26465;&#20214;&#20998;&#20301;&#25968;&#30340;&#26368;&#20339;&#21644;&#21487;&#35299;&#37322;&#30340;&#32447;&#24615;&#20272;&#35745;&#20540;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#35813;&#26041;&#27861;&#26159;&#19968;&#31181;&#36866;&#29992;&#20110;&#29305;&#23450;&#20998;&#20301;&#25968;&#23376;&#38598;&#36873;&#25321;&#30340;&#26377;&#25928;&#24037;&#20855;&#12290;</title><link>http://arxiv.org/abs/2311.02043</link><description>&lt;p&gt;
&#22522;&#20110;&#23376;&#38598;&#36873;&#25321;&#30340;&#36125;&#21494;&#26031;&#20998;&#20301;&#22238;&#24402;&#65306;&#21518;&#39564;&#24635;&#32467;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Bayesian Quantile Regression with Subset Selection: A Posterior Summarization Perspective. (arXiv:2311.02043v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.02043
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#20915;&#31574;&#20998;&#26512;&#30340;&#26041;&#27861;&#65292;&#23545;&#20110;&#20219;&#20309;&#36125;&#21494;&#26031;&#22238;&#24402;&#27169;&#22411;&#65292;&#21487;&#20197;&#24471;&#21040;&#27599;&#20010;&#26465;&#20214;&#20998;&#20301;&#25968;&#30340;&#26368;&#20339;&#21644;&#21487;&#35299;&#37322;&#30340;&#32447;&#24615;&#20272;&#35745;&#20540;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#35813;&#26041;&#27861;&#26159;&#19968;&#31181;&#36866;&#29992;&#20110;&#29305;&#23450;&#20998;&#20301;&#25968;&#23376;&#38598;&#36873;&#25321;&#30340;&#26377;&#25928;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#20301;&#22238;&#24402;&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#24037;&#20855;&#65292;&#29992;&#20110;&#25512;&#26029;&#21327;&#21464;&#37327;&#22914;&#20309;&#24433;&#21709;&#21709;&#24212;&#20998;&#24067;&#30340;&#29305;&#23450;&#20998;&#20301;&#25968;&#12290;&#29616;&#26377;&#26041;&#27861;&#35201;&#20040;&#20998;&#21035;&#20272;&#35745;&#27599;&#20010;&#24863;&#20852;&#36259;&#20998;&#20301;&#25968;&#30340;&#26465;&#20214;&#20998;&#20301;&#25968;&#65292;&#35201;&#20040;&#20351;&#29992;&#21322;&#21442;&#25968;&#25110;&#38750;&#21442;&#25968;&#27169;&#22411;&#20272;&#35745;&#25972;&#20010;&#26465;&#20214;&#20998;&#24067;&#12290;&#21069;&#32773;&#32463;&#24120;&#20135;&#29983;&#19981;&#36866;&#21512;&#23454;&#38469;&#25968;&#25454;&#30340;&#27169;&#22411;&#65292;&#24182;&#19988;&#19981;&#22312;&#20998;&#20301;&#25968;&#20043;&#38388;&#20849;&#20139;&#20449;&#24687;&#65292;&#32780;&#21518;&#32773;&#21017;&#20197;&#22797;&#26434;&#19988;&#21463;&#38480;&#21046;&#30340;&#27169;&#22411;&#20026;&#29305;&#28857;&#65292;&#38590;&#20197;&#35299;&#37322;&#21644;&#35745;&#31639;&#25928;&#29575;&#20302;&#19979;&#12290;&#27492;&#22806;&#65292;&#36825;&#20004;&#31181;&#26041;&#27861;&#37117;&#19981;&#36866;&#21512;&#20110;&#29305;&#23450;&#20998;&#20301;&#25968;&#30340;&#23376;&#38598;&#36873;&#25321;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#20174;&#36125;&#21494;&#26031;&#20915;&#31574;&#20998;&#26512;&#30340;&#35282;&#24230;&#20986;&#21457;&#65292;&#25552;&#20986;&#20102;&#32447;&#24615;&#20998;&#20301;&#20272;&#35745;&#12289;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#23376;&#38598;&#36873;&#25321;&#30340;&#22522;&#26412;&#38382;&#39064;&#12290;&#23545;&#20110;&#20219;&#20309;&#36125;&#21494;&#26031;&#22238;&#24402;&#27169;&#22411;&#65292;&#25105;&#20204;&#20026;&#27599;&#20010;&#22522;&#20110;&#27169;&#22411;&#30340;&#26465;&#20214;&#20998;&#20301;&#25968;&#25512;&#23548;&#20986;&#26368;&#20339;&#21644;&#21487;&#35299;&#37322;&#30340;&#32447;&#24615;&#20272;&#35745;&#20540;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#24341;&#20837;&#20102;&#19968;&#31181;&#20998;&#20301;&#25968;&#32858;&#28966;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantile regression is a powerful tool for inferring how covariates affect specific percentiles of the response distribution. Existing methods either estimate conditional quantiles separately for each quantile of interest or estimate the entire conditional distribution using semi- or non-parametric models. The former often produce inadequate models for real data and do not share information across quantiles, while the latter are characterized by complex and constrained models that can be difficult to interpret and computationally inefficient. Further, neither approach is well-suited for quantile-specific subset selection. Instead, we pose the fundamental problems of linear quantile estimation, uncertainty quantification, and subset selection from a Bayesian decision analysis perspective. For any Bayesian regression model, we derive optimal and interpretable linear estimates and uncertainty quantification for each model-based conditional quantile. Our approach introduces a quantile-focu
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20351;&#29992;&#34955;&#35013;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26131;&#20110;&#20351;&#29992;&#19988;&#24191;&#27867;&#36866;&#29992;&#30340;&#26041;&#27861;&#26469;&#25913;&#21892;&#22312;&#27169;&#22411;&#38169;&#35823;&#35268;&#33539;&#19979;&#30340;&#21487;&#37325;&#29616;&#24615;&#12290;</title><link>http://arxiv.org/abs/2311.02019</link><description>&lt;p&gt;
&#20351;&#29992;&#34955;&#35013;&#21518;&#39564;&#36827;&#34892;&#21487;&#37325;&#29616;&#30340;&#21442;&#25968;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Reproducible Parameter Inference Using Bagged Posteriors. (arXiv:2311.02019v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.02019
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;&#34955;&#35013;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26131;&#20110;&#20351;&#29992;&#19988;&#24191;&#27867;&#36866;&#29992;&#30340;&#26041;&#27861;&#26469;&#25913;&#21892;&#22312;&#27169;&#22411;&#38169;&#35823;&#35268;&#33539;&#19979;&#30340;&#21487;&#37325;&#29616;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#27169;&#22411;&#38169;&#35823;&#35268;&#33539;&#19979;&#65292;&#24050;&#30693;&#36125;&#21494;&#26031;&#21518;&#39564;&#36890;&#24120;&#19981;&#33021;&#27491;&#30830;&#37327;&#21270;&#20851;&#20110;&#30495;&#23454;&#25110;&#20266;&#30495;&#21442;&#25968;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#26356;&#37325;&#35201;&#30340;&#26159;&#65292;&#38169;&#35823;&#35268;&#33539;&#20250;&#23548;&#33268;&#22312;&#29420;&#31435;&#25968;&#25454;&#38598;&#19978;&#21516;&#19968;&#27169;&#22411;&#20135;&#29983;&#30456;&#20114;&#30683;&#30462;&#30340;&#21518;&#39564;&#32467;&#26524;&#65292;&#20174;&#32780;&#32570;&#20047;&#21487;&#37325;&#29616;&#24615;&#12290;&#20026;&#20102;&#23450;&#20041;&#22312;&#38169;&#35823;&#35268;&#33539;&#19979;&#21487;&#37325;&#29616;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#26631;&#20934;&#65292;&#25105;&#20204;&#32771;&#34385;&#20174;&#29420;&#31435;&#25968;&#25454;&#38598;&#26500;&#24314;&#30340;&#20004;&#20010;&#32622;&#20449;&#21306;&#38388;&#20855;&#26377;&#38750;&#31354;&#20132;&#38598;&#30340;&#27010;&#29575;&#65292;&#24182;&#20026;&#20219;&#20309;&#26377;&#25928;&#32622;&#20449;&#21306;&#38388;&#24314;&#31435;&#20102;&#35813;&#20132;&#38598;&#27010;&#29575;&#30340;&#19979;&#30028;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#26631;&#20934;&#21518;&#39564;&#30340;&#21487;&#20449;&#21306;&#38388;&#22312;&#39640;&#32500;&#35774;&#32622;&#19979;&#65288;&#21363;&#26679;&#26412;&#22823;&#23567;&#22686;&#21152;&#26102;&#30340;&#32500;&#24230;&#65289;&#21487;&#20197;&#20005;&#37325;&#36829;&#21453;&#36825;&#20010;&#19979;&#30028;&#65292;&#34920;&#26126;&#22312;&#38169;&#35823;&#35268;&#33539;&#19979;&#23427;&#19981;&#26159;&#20869;&#37096;&#19968;&#33268;&#30340;&#12290;&#20026;&#20102;&#25552;&#39640;&#26131;&#20110;&#20351;&#29992;&#19988;&#24191;&#27867;&#36866;&#29992;&#30340;&#21487;&#37325;&#29616;&#24615;&#65292;&#25105;&#20204;&#24314;&#35758;&#24212;&#29992;&#34955;&#35013;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Under model misspecification, it is known that Bayesian posteriors often do not properly quantify uncertainty about true or pseudo-true parameters. Even more fundamentally, misspecification leads to a lack of reproducibility in the sense that the same model will yield contradictory posteriors on independent data sets from the true distribution. To define a criterion for reproducible uncertainty quantification under misspecification, we consider the probability that two confidence sets constructed from independent data sets have nonempty overlap, and we establish a lower bound on this overlap probability that holds for any valid confidence sets. We prove that credible sets from the standard posterior can strongly violate this bound, particularly in high-dimensional settings (i.e., with dimension increasing with sample size), indicating that it is not internally coherent under misspecification. To improve reproducibility in an easy-to-use and widely applicable way, we propose to apply ba
&lt;/p&gt;</description></item><item><title>Adam&#31639;&#27861;&#22312;&#38750;&#20984;&#24179;&#28369;&#38543;&#26426;&#20248;&#21270;&#20013;&#65292;&#32463;&#36807;&#28145;&#20837;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#22312;&#22352;&#26631;-wise&#8220;&#20223;&#23556;&#8221;&#26041;&#24046;&#22122;&#22768;&#19979;&#65292;Adam&#21487;&#20197;&#20197;&#39640;&#27010;&#29575;&#25910;&#25947;&#21040;&#31283;&#23450;&#28857;&#65292;&#26080;&#38656;&#20219;&#20309;&#26377;&#30028;&#26799;&#24230;&#20551;&#35774;&#21644;&#38382;&#39064;&#30456;&#20851;&#30340;&#30693;&#35782;&#12290;</title><link>http://arxiv.org/abs/2311.02000</link><description>&lt;p&gt;
Adam&#31639;&#27861;&#22312;&#26080;&#30028;&#26799;&#24230;&#21644;&#20223;&#23556;&#26041;&#24046;&#22122;&#22768;&#19979;&#30340;&#39640;&#27010;&#29575;&#25910;&#25947;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
High Probability Convergence of Adam Under Unbounded Gradients and Affine Variance Noise. (arXiv:2311.02000v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.02000
&lt;/p&gt;
&lt;p&gt;
Adam&#31639;&#27861;&#22312;&#38750;&#20984;&#24179;&#28369;&#38543;&#26426;&#20248;&#21270;&#20013;&#65292;&#32463;&#36807;&#28145;&#20837;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#22312;&#22352;&#26631;-wise&#8220;&#20223;&#23556;&#8221;&#26041;&#24046;&#22122;&#22768;&#19979;&#65292;Adam&#21487;&#20197;&#20197;&#39640;&#27010;&#29575;&#25910;&#25947;&#21040;&#31283;&#23450;&#28857;&#65292;&#26080;&#38656;&#20219;&#20309;&#26377;&#30028;&#26799;&#24230;&#20551;&#35774;&#21644;&#38382;&#39064;&#30456;&#20851;&#30340;&#30693;&#35782;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#38750;&#20984;&#24179;&#28369;&#38543;&#26426;&#20248;&#21270;&#20013;&#65292;&#33258;&#36866;&#24212;&#30697;&#27861;&#65288;Adam&#65289;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;&#23613;&#31649;&#22312;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#20294;&#20854;&#29702;&#35770;&#24615;&#36136;&#20173;&#28982;&#26377;&#38480;&#12290;&#20043;&#21069;&#30340;&#30740;&#31350;&#20027;&#35201;&#20174;&#26399;&#26395;&#35282;&#24230;&#32771;&#34385;&#20102;Adam&#30340;&#25910;&#25947;&#24615;&#65292;&#24120;&#24120;&#38656;&#35201;&#24378;&#20551;&#35774;&#65292;&#27604;&#22914;&#22343;&#21248;&#38543;&#26426;&#26377;&#30028;&#26799;&#24230;&#25110;&#32773;&#20808;&#39564;&#30340;&#38382;&#39064;&#30456;&#20851;&#30693;&#35782;&#12290;&#22240;&#27492;&#65292;&#36825;&#20123;&#32467;&#26524;&#22312;&#23454;&#38469;&#30340;&#29616;&#23454;&#22330;&#26223;&#20013;&#30340;&#36866;&#29992;&#24615;&#21463;&#21040;&#20102;&#38480;&#21046;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#23616;&#38480;&#65292;&#25105;&#20204;&#36827;&#34892;&#20102;&#28145;&#20837;&#20998;&#26512;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#22352;&#26631;-wise&#8220;&#20223;&#23556;&#8221;&#26041;&#24046;&#22122;&#22768;&#19979;&#65292;Adam&#21487;&#20197;&#20197;&#39640;&#27010;&#29575;&#25910;&#25947;&#21040;&#31283;&#23450;&#28857;&#65292;&#20854;&#25910;&#25947;&#36895;&#29575;&#20026;$\mathcal{O}\left({\rm poly}(\log T)/\sqrt{T}\right)$&#65292;&#19981;&#38656;&#35201;&#20219;&#20309;&#26377;&#30028;&#26799;&#24230;&#20551;&#35774;&#21644;&#20219;&#20309;&#38382;&#39064;&#30456;&#20851;&#30340;&#30693;&#35782;&#26469;&#35843;&#25972;&#36229;&#21442;&#25968;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#21457;&#29616;Adam&#38480;&#21046;&#20102;&#20854;&#26799;&#24230;&#30340;...
&lt;/p&gt;
&lt;p&gt;
In this paper, we study the convergence of the Adaptive Moment Estimation (Adam) algorithm under unconstrained non-convex smooth stochastic optimizations. Despite the widespread usage in machine learning areas, its theoretical properties remain limited. Prior researches primarily investigated Adam's convergence from an expectation view, often necessitating strong assumptions like uniformly stochastic bounded gradients or problem-dependent knowledge in prior. As a result, the applicability of these findings in practical real-world scenarios has been constrained. To overcome these limitations, we provide a deep analysis and show that Adam could converge to the stationary point in high probability with a rate of $\mathcal{O}\left({\rm poly}(\log T)/\sqrt{T}\right)$ under coordinate-wise "affine" variance noise, not requiring any bounded gradient assumption and any problem-dependent knowledge in prior to tune hyper-parameters. Additionally, it is revealed that Adam confines its gradients' 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#33719;&#21462;&#21487;&#35299;&#37322;&#30340;&#20998;&#31867;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#31232;&#30095;&#30340;&#35268;&#21017;&#38598;&#21512;&#26469;&#21516;&#26102;&#35299;&#20915;&#35268;&#21017;&#38598;&#30340;&#31232;&#30095;&#24615;&#21644;&#39044;&#27979;&#20934;&#30830;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#20174;&#32780;&#20445;&#35777;&#27867;&#21270;&#24615;&#33021;&#24182;&#38477;&#20302;&#35745;&#31639;&#25104;&#26412;&#12290;</title><link>http://arxiv.org/abs/2311.01994</link><description>&lt;p&gt;
&#21033;&#29992;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#33719;&#21462;&#21487;&#35299;&#37322;&#30340;&#20998;&#31867;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Obtaining Explainable Classification Models using Distributionally Robust Optimization. (arXiv:2311.01994v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01994
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#33719;&#21462;&#21487;&#35299;&#37322;&#30340;&#20998;&#31867;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#26500;&#24314;&#31232;&#30095;&#30340;&#35268;&#21017;&#38598;&#21512;&#26469;&#21516;&#26102;&#35299;&#20915;&#35268;&#21017;&#38598;&#30340;&#31232;&#30095;&#24615;&#21644;&#39044;&#27979;&#20934;&#30830;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#20174;&#32780;&#20445;&#35777;&#27867;&#21270;&#24615;&#33021;&#24182;&#38477;&#20302;&#35745;&#31639;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#20154;&#31867;&#29992;&#25143;&#26469;&#35828;&#65292;&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#23545;&#20110;&#29702;&#35299;&#25552;&#35758;&#20998;&#31867;&#22120;&#22914;&#20309;&#26681;&#25454;&#29305;&#24449;&#20540;&#32473;&#25968;&#25454;&#20998;&#37197;&#26631;&#31614;&#33267;&#20851;&#37325;&#35201;&#12290;&#25105;&#20204;&#30740;&#31350;&#20351;&#29992;&#29305;&#24449;&#20540;&#35268;&#21017;&#38598;&#26500;&#24314;&#30340;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#25429;&#25417;&#38750;&#32447;&#24615;&#20381;&#36182;&#21644;&#20132;&#20114;&#20316;&#29992;&#12290;&#35268;&#21017;&#38598;&#30340;&#31232;&#30095;&#24615;&#21644;&#39044;&#27979;&#20934;&#30830;&#24615;&#20043;&#38388;&#23384;&#22312;&#22266;&#26377;&#30340;&#26435;&#34913;&#12290;&#20351;&#29992;&#29616;&#26377;&#26041;&#27861;&#26469;&#25214;&#21040;&#21512;&#36866;&#30340;&#31232;&#30095;&#24230;&#36873;&#25321;&#65288;&#20363;&#22914;&#36890;&#36807;&#20132;&#21449;&#39564;&#35777;&#65289;&#35745;&#31639;&#25104;&#26412;&#24456;&#39640;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#20844;&#24335;&#26469;&#23398;&#20064;&#21516;&#26102;&#35299;&#20915;&#36825;&#20123;&#31454;&#20105;&#22240;&#32032;&#30340;&#35268;&#21017;&#38598;&#21512;&#12290;&#36890;&#36807;&#21033;&#29992;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#26469;&#30830;&#20445;&#33391;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#65292;&#21516;&#26102;&#20445;&#25345;&#20302;&#35745;&#31639;&#25104;&#26412;&#12290;&#35813;&#20844;&#24335;&#21033;&#29992;&#21015;&#29983;&#25104;&#26377;&#25928;&#22320;&#25628;&#32034;&#35268;&#21017;&#38598;&#21512;&#30340;&#31354;&#38388;&#24182;&#26500;&#24314;&#31232;&#30095;&#30340;&#35268;&#21017;&#38598;&#21512;&#65292;&#19982;&#38543;&#26426;&#26862;&#26519;&#25110;Boosting&#21450;&#20854;&#21464;&#20307;&#31561;&#25216;&#26415;&#30456;&#27604;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#29702;&#35770;&#32467;&#26524;&#26469;&#25512;&#21160;&#36825;&#19968;&#20844;&#24335;&#30340;&#21457;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
Model explainability is crucial for human users to be able to interpret how a proposed classifier assigns labels to data based on its feature values. We study generalized linear models constructed using sets of feature value rules, which can capture nonlinear dependencies and interactions. An inherent trade-off exists between rule set sparsity and its prediction accuracy. It is computationally expensive to find the right choice of sparsity -- e.g., via cross-validation -- with existing methods. We propose a new formulation to learn an ensemble of rule sets that simultaneously addresses these competing factors. Good generalization is ensured while keeping computational costs low by utilizing distributionally robust optimization. The formulation utilizes column generation to efficiently search the space of rule sets and constructs a sparse ensemble of rule sets, in contrast with techniques like random forests or boosting and their variants. We present theoretical results that motivate an
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#19987;&#38376;&#29992;&#20110;&#26465;&#20214;&#19979;&#20648;&#23618;&#30456;&#29983;&#25104;&#30340;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;&#65292;&#36890;&#36807;&#20805;&#20998;&#20445;&#30041;&#26465;&#20214;&#25968;&#25454;&#65292;&#29983;&#25104;&#20102;&#39640;&#20445;&#30495;&#24230;&#30340;&#20648;&#23618;&#30456;&#12290;&#23427;&#22312;&#24615;&#33021;&#19978;&#26126;&#26174;&#20248;&#20110;&#22522;&#20110;GANs&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2311.01968</link><description>&lt;p&gt;
&#26465;&#20214;&#20648;&#23618;&#30456;&#29983;&#25104;&#30340;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Latent Diffusion Model for Conditional Reservoir Facies Generation. (arXiv:2311.01968v1 [physics.geo-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01968
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#19987;&#38376;&#29992;&#20110;&#26465;&#20214;&#19979;&#20648;&#23618;&#30456;&#29983;&#25104;&#30340;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;&#65292;&#36890;&#36807;&#20805;&#20998;&#20445;&#30041;&#26465;&#20214;&#25968;&#25454;&#65292;&#29983;&#25104;&#20102;&#39640;&#20445;&#30495;&#24230;&#30340;&#20648;&#23618;&#30456;&#12290;&#23427;&#22312;&#24615;&#33021;&#19978;&#26126;&#26174;&#20248;&#20110;&#22522;&#20110;GANs&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#27833;&#27668;&#39046;&#22495;&#30340;&#30000;&#22320;&#24320;&#21457;&#21644;&#20648;&#23618;&#31649;&#29702;&#20013;&#65292;&#22522;&#20110;&#26377;&#38480;&#27979;&#37327;&#25968;&#25454;&#21019;&#24314;&#20934;&#30830;&#19988;&#22320;&#36136;&#30495;&#23454;&#30340;&#20648;&#23618;&#30456;&#33267;&#20851;&#37325;&#35201;&#12290;&#20256;&#32479;&#30340;&#20004;&#28857;&#22320;&#36136;&#32479;&#35745;&#26041;&#27861;&#34429;&#28982;&#22522;&#30784;&#65292;&#20294;&#24448;&#24448;&#38590;&#20197;&#25429;&#25417;&#22797;&#26434;&#30340;&#22320;&#36136;&#27169;&#24335;&#12290;&#22810;&#28857;&#32479;&#35745;&#26041;&#27861;&#25552;&#20379;&#20102;&#26356;&#22823;&#30340;&#28789;&#27963;&#24615;&#65292;&#20294;&#20063;&#38754;&#20020;&#30528;&#25361;&#25112;&#12290;&#38543;&#30528;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GANs&#65289;&#30340;&#20852;&#36215;&#21644;&#23427;&#20204;&#22312;&#19981;&#21516;&#39046;&#22495;&#30340;&#25104;&#21151;&#65292;&#20154;&#20204;&#24320;&#22987;&#20542;&#21521;&#20110;&#20351;&#29992;&#23427;&#20204;&#36827;&#34892;&#20648;&#23618;&#30456;&#29983;&#25104;&#12290;&#28982;&#32780;&#65292;&#35745;&#31639;&#26426;&#35270;&#35273;&#39046;&#22495;&#30340;&#26368;&#26032;&#36827;&#23637;&#26174;&#31034;&#20102;&#25193;&#25955;&#27169;&#22411;&#30456;&#36739;&#20110;GANs&#30340;&#21331;&#36234;&#24615;&#33021;&#12290;&#21463;&#27492;&#21551;&#21457;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#28508;&#22312;&#25193;&#25955;&#27169;&#22411;&#65292;&#19987;&#38376;&#29992;&#20110;&#26465;&#20214;&#19979;&#30340;&#20648;&#23618;&#30456;&#29983;&#25104;&#12290;&#35813;&#27169;&#22411;&#20135;&#29983;&#20102;&#39640;&#20445;&#30495;&#24230;&#30340;&#20648;&#23618;&#30456;&#65292;&#20005;&#26684;&#20445;&#30041;&#20102;&#26465;&#20214;&#25968;&#25454;&#12290;&#23427;&#26126;&#26174;&#20248;&#20110;&#22522;&#20110;GANs&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Creating accurate and geologically realistic reservoir facies based on limited measurements is crucial for field development and reservoir management, especially in the oil and gas sector. Traditional two-point geostatistics, while foundational, often struggle to capture complex geological patterns. Multi-point statistics offers more flexibility, but comes with its own challenges. With the rise of Generative Adversarial Networks (GANs) and their success in various fields, there has been a shift towards using them for facies generation. However, recent advances in the computer vision domain have shown the superiority of diffusion models over GANs. Motivated by this, a novel Latent Diffusion Model is proposed, which is specifically designed for conditional generation of reservoir facies. The proposed model produces high-fidelity facies realizations that rigorously preserve conditioning data. It significantly outperforms a GAN-based alternative.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#38750;&#21442;&#25968;&#20284;&#28982;&#27604;&#20272;&#35745;&#65288;OLRE&#65289;&#26694;&#26550;&#65292;&#36866;&#29992;&#20110;&#20272;&#35745;&#20004;&#20010;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#20043;&#38388;&#24046;&#24322;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#21033;&#29992;&#26680;&#26041;&#27861;&#21644;&#20989;&#25968;&#26368;&#23567;&#21270;&#25216;&#26415;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#39640;&#25928;&#22320;&#36827;&#34892;&#22312;&#32447;&#26356;&#26032;&#65292;&#21516;&#26102;&#20855;&#26377;&#23545;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#24418;&#24335;&#26080;&#30693;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2311.01900</link><description>&lt;p&gt;
&#22312;&#32447;&#38750;&#21442;&#25968;&#20284;&#28982;&#27604;&#20272;&#35745;&#30340;&#30382;&#23572;&#36874;&#25955;&#24230;&#20989;&#25968;&#26368;&#23567;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Online non-parametric likelihood-ratio estimation by Pearson-divergence functional minimization. (arXiv:2311.01900v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01900
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#38750;&#21442;&#25968;&#20284;&#28982;&#27604;&#20272;&#35745;&#65288;OLRE&#65289;&#26694;&#26550;&#65292;&#36866;&#29992;&#20110;&#20272;&#35745;&#20004;&#20010;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#20043;&#38388;&#24046;&#24322;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#21033;&#29992;&#26680;&#26041;&#27861;&#21644;&#20989;&#25968;&#26368;&#23567;&#21270;&#25216;&#26415;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#33021;&#22815;&#39640;&#25928;&#22320;&#36827;&#34892;&#22312;&#32447;&#26356;&#26032;&#65292;&#21516;&#26102;&#20855;&#26377;&#23545;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#24418;&#24335;&#26080;&#30693;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#20351;&#29992;&#21487;&#29992;&#25968;&#25454;&#37327;&#21270;&#20004;&#20010;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;p&#21644;q&#20043;&#38388;&#30340;&#24046;&#24322;&#26159;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#12290;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#30340;&#19968;&#31181;&#24120;&#35265;&#26041;&#27861;&#26159;&#20284;&#28982;&#27604;&#20272;&#35745;&#65288;LRE&#65289;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#20026;&#22312;&#32447;&#38750;&#21442;&#25968;&#20284;&#28982;&#27604;&#20272;&#35745;&#65288;OLRE&#65289;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#26694;&#26550;&#65292;&#36866;&#29992;&#20110;&#38543;&#26102;&#38388;&#35266;&#23519;&#21040;&#30340;i.i.d&#35266;&#27979;&#20540;&#65288;$x_t \sim p, x'_t \sim q$&#65289;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#30340;&#38750;&#21442;&#25968;&#24615;&#36136;&#20855;&#26377;&#23545;$p$&#21644;$q$&#30340;&#24418;&#24335;&#26080;&#30693;&#30340;&#20248;&#21183;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21033;&#29992;&#26680;&#26041;&#27861;&#21644;&#20989;&#25968;&#26368;&#23567;&#21270;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#24320;&#21457;&#20102;&#19968;&#20010;&#21487;&#20197;&#36827;&#34892;&#39640;&#25928;&#22312;&#32447;&#26356;&#26032;&#30340;&#20272;&#35745;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;OLRE&#26041;&#27861;&#24615;&#33021;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#22312;&#21512;&#25104;&#23454;&#39564;&#20013;&#36827;&#34892;&#20102;&#23454;&#35777;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantifying the difference between two probability density functions, $p$ and $q$, using available data, is a fundamental problem in Statistics and Machine Learning. A usual approach for addressing this problem is the likelihood-ratio estimation (LRE) between $p$ and $q$, which -- to our best knowledge -- has been investigated mainly for the offline case. This paper contributes by introducing a new framework for online non-parametric LRE (OLRE) for the setting where pairs of iid observations $(x_t \sim p, x'_t \sim q)$ are observed over time. The non-parametric nature of our approach has the advantage of being agnostic to the forms of $p$ and $q$. Moreover, we capitalize on the recent advances in Kernel Methods and functional minimization to develop an estimator that can be efficiently updated online. We provide theoretical guarantees for the performance of the OLRE method along with empirical validation in synthetic experiments.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29109;&#30340;&#23398;&#20064;&#30446;&#26631;&#65292;&#29992;&#20110;&#31232;&#30095;&#32534;&#30721;&#21442;&#25968;&#30340;&#23398;&#20064;&#65292;&#36890;&#36807;&#38750;&#24179;&#20961;&#30340;&#21518;&#39564;&#36924;&#36817;&#21644;&#35299;&#26512;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#23454;&#29616;&#20102;&#26631;&#20934;&#31232;&#30095;&#32534;&#30721;&#30340;&#23398;&#20064;&#65292;&#22312;&#25968;&#20540;&#23454;&#39564;&#20013;&#35777;&#26126;&#20102;&#20854;&#21487;&#34892;&#24615;&#12290;</title><link>http://arxiv.org/abs/2311.01888</link><description>&lt;p&gt;
&#20351;&#29992;&#22522;&#20110;&#29109;&#30340;ELBO&#23398;&#20064;&#31232;&#30095;&#32534;&#30721;
&lt;/p&gt;
&lt;p&gt;
Learning Sparse Codes with Entropy-Based ELBOs. (arXiv:2311.01888v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01888
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29109;&#30340;&#23398;&#20064;&#30446;&#26631;&#65292;&#29992;&#20110;&#31232;&#30095;&#32534;&#30721;&#21442;&#25968;&#30340;&#23398;&#20064;&#65292;&#36890;&#36807;&#38750;&#24179;&#20961;&#30340;&#21518;&#39564;&#36924;&#36817;&#21644;&#35299;&#26512;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#23454;&#29616;&#20102;&#26631;&#20934;&#31232;&#30095;&#32534;&#30721;&#30340;&#23398;&#20064;&#65292;&#22312;&#25968;&#20540;&#23454;&#39564;&#20013;&#35777;&#26126;&#20102;&#20854;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#20934;&#27010;&#29575;&#31232;&#30095;&#32534;&#30721;&#20551;&#35774;&#25289;&#26222;&#25289;&#26031;&#20808;&#39564;&#12289;&#20174;&#28508;&#22312;&#21040;&#21487;&#35266;&#27979;&#30340;&#32447;&#24615;&#26144;&#23556;&#20197;&#21450;&#39640;&#26031;&#21487;&#35266;&#27979;&#20998;&#24067;&#12290;&#25105;&#20204;&#22312;&#36825;&#37324;&#23548;&#20986;&#20102;&#19968;&#20010;&#20165;&#22522;&#20110;&#29109;&#30340;&#23398;&#20064;&#30446;&#26631;&#65292;&#29992;&#20110;&#26631;&#20934;&#31232;&#30095;&#32534;&#30721;&#30340;&#21442;&#25968;&#12290;&#36825;&#20010;&#26032;&#30340;&#21464;&#20998;&#30446;&#26631;&#20855;&#26377;&#20197;&#19979;&#29305;&#28857;&#65306;&#65288;A&#65289;&#19982;MAP&#36924;&#36817;&#19981;&#21516;&#65292;&#23427;&#20351;&#29992;&#20102;&#27010;&#29575;&#25512;&#29702;&#30340;&#38750;&#24179;&#20961;&#21518;&#39564;&#36924;&#36817;&#65307;&#65288;B&#65289;&#19982;&#20197;&#21069;&#30340;&#38750;&#24179;&#20961;&#36924;&#36817;&#19981;&#21516;&#65292;&#36825;&#20010;&#26032;&#30340;&#30446;&#26631;&#26159;&#23436;&#20840;&#35299;&#26512;&#30340;&#65307;&#65288;C&#65289;&#35813;&#30446;&#26631;&#20801;&#35768;&#19968;&#31181;&#26032;&#30340;&#21407;&#21017;&#24615;&#30340;&#36864;&#28779;&#24418;&#24335;&#12290;&#30446;&#26631;&#30340;&#23548;&#20986;&#39318;&#20808;&#36890;&#36807;&#35777;&#26126;&#26631;&#20934;ELBO&#30446;&#26631;&#25910;&#25947;&#21040;&#29109;&#30340;&#21644;&#65292;&#36825;&#19982;&#20855;&#26377;&#39640;&#26031;&#20808;&#39564;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#26368;&#36817;&#31867;&#20284;&#32467;&#26524;&#30456;&#21305;&#37197;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;ELBO&#31561;&#20110;&#29109;&#30340;&#26465;&#20214;&#20855;&#26377;&#35299;&#26512;&#35299;&#65292;&#20174;&#32780;&#24471;&#21040;&#20102;&#23436;&#20840;&#35299;&#26512;&#30340;&#30446;&#26631;&#12290;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#23398;&#20064;&#36924;&#30495;&#24615;&#30340;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Standard probabilistic sparse coding assumes a Laplace prior, a linear mapping from latents to observables, and Gaussian observable distributions. We here derive a solely entropy-based learning objective for the parameters of standard sparse coding. The novel variational objective has the following features: (A) unlike MAP approximations, it uses non-trivial posterior approximations for probabilistic inference; (B) unlike for previous non-trivial approximations, the novel objective is fully analytical; and (C) the objective allows for a novel principled form of annealing. The objective is derived by first showing that the standard ELBO objective converges to a sum of entropies, which matches similar recent results for generative models with Gaussian priors. The conditions under which the ELBO becomes equal to entropies are then shown to have analytical solutions, which leads to the fully analytical objective. Numerical experiments are used to demonstrate the feasibility of learning wit
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#36739;&#22823;&#35268;&#27169;&#20248;&#21270;&#38382;&#39064;&#30340;&#24555;&#36895;&#36895;&#20889;&#31639;&#27861;&#65292;&#36866;&#29992;&#20110;&#20984;&#25110;&#38750;&#20984;&#27491;&#21017;&#21270;&#20989;&#25968;&#30340;&#26368;&#23567;&#20108;&#20056;&#38382;&#39064;&#12290;&#30456;&#27604;&#24050;&#26377;&#30340;&#38543;&#26426;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22788;&#29702;&#36890;&#29992;&#30340;Frechet&#23376;&#24494;&#20998;&#27491;&#21017;&#21270;&#20989;&#25968;&#24182;&#25552;&#20379;&#20102;&#19968;&#33324;&#30340;&#36817;&#20284;&#35823;&#24046;&#29702;&#35770;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#35299;&#20915;&#36895;&#20889;&#30340;&#31232;&#30095;&#20984;&#25110;&#38750;&#20984;&#23398;&#20064;&#38382;&#39064;&#65292;&#25105;&#20204;&#36824;&#24471;&#21040;&#20102;&#31232;&#30095;&#20449;&#21495;&#20272;&#35745;&#30340;&#26497;&#23567;&#26497;&#22823;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2311.01806</link><description>&lt;p&gt;
&#21033;&#29992;&#23646;&#24615;&#30340;&#26368;&#23567;&#20108;&#20056;&#38382;&#39064;&#30340;&#36895;&#20889;&#31639;&#27861;&#21644;&#38160;&#21033;&#20445;&#35777;&#30340;&#20984;&#21644;&#38750;&#20984;&#27491;&#21017;&#21270;&#12290; &#65288;arXiv&#65306;2311.01806v1 [math.OC]&#65289;
&lt;/p&gt;
&lt;p&gt;
Sketching for Convex and Nonconvex Regularized Least Squares with Sharp Guarantees. (arXiv:2311.01806v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01806
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#35299;&#20915;&#36739;&#22823;&#35268;&#27169;&#20248;&#21270;&#38382;&#39064;&#30340;&#24555;&#36895;&#36895;&#20889;&#31639;&#27861;&#65292;&#36866;&#29992;&#20110;&#20984;&#25110;&#38750;&#20984;&#27491;&#21017;&#21270;&#20989;&#25968;&#30340;&#26368;&#23567;&#20108;&#20056;&#38382;&#39064;&#12290;&#30456;&#27604;&#24050;&#26377;&#30340;&#38543;&#26426;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22788;&#29702;&#36890;&#29992;&#30340;Frechet&#23376;&#24494;&#20998;&#27491;&#21017;&#21270;&#20989;&#25968;&#24182;&#25552;&#20379;&#20102;&#19968;&#33324;&#30340;&#36817;&#20284;&#35823;&#24046;&#29702;&#35770;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#35299;&#20915;&#36895;&#20889;&#30340;&#31232;&#30095;&#20984;&#25110;&#38750;&#20984;&#23398;&#20064;&#38382;&#39064;&#65292;&#25105;&#20204;&#36824;&#24471;&#21040;&#20102;&#31232;&#30095;&#20449;&#21495;&#20272;&#35745;&#30340;&#26497;&#23567;&#26497;&#22823;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#31639;&#27861;&#23545;&#20110;&#35299;&#20915;&#22823;&#35268;&#27169;&#20248;&#21270;&#38382;&#39064;&#38750;&#24120;&#37325;&#35201;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24555;&#36895;&#36895;&#20889;&#31639;&#27861;&#65292;&#29992;&#20110;&#36890;&#36807;&#20984;&#25110;&#38750;&#20984;&#27491;&#21017;&#21270;&#20989;&#25968;&#27491;&#21017;&#21270;&#30340;&#26368;&#23567;&#20108;&#20056;&#38382;&#39064;&#65292;&#21363;&#36895;&#20889;&#27491;&#21017;&#21270;&#20248;&#21270;&#65288;SRO&#65289;&#12290;&#25105;&#20204;&#30340;SRO&#31639;&#27861;&#39318;&#20808;&#29983;&#25104;&#21407;&#22987;&#25968;&#25454;&#30697;&#38453;&#30340;&#36895;&#20889;&#65292;&#28982;&#21518;&#35299;&#20915;&#36895;&#20889;&#38382;&#39064;&#12290;&#19982;&#29616;&#26377;&#30340;&#38543;&#26426;&#31639;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#22312;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#20013;&#22788;&#29702;&#36890;&#29992;&#30340;Frechet&#23376;&#24494;&#20998;&#27491;&#21017;&#21270;&#20989;&#25968;&#12290;&#25105;&#20204;&#20026;&#20984;&#25110;&#38750;&#20984;&#27491;&#21017;&#21270;&#30340;&#26368;&#23567;&#20108;&#20056;&#38382;&#39064;&#30340;&#21407;&#22987;&#38382;&#39064;&#30340;&#20248;&#21270;&#32467;&#26524;&#21644;&#36895;&#20889;&#38382;&#39064;&#20043;&#38388;&#30340;&#36817;&#20284;&#35823;&#24046;&#25552;&#20379;&#20102;&#19968;&#33324;&#30340;&#29702;&#35770;&#32467;&#26524;&#12290;&#23545;&#20110;&#20219;&#24847;&#30340;&#20984;&#27491;&#21017;&#21270;&#22120;&#65292;&#35777;&#26126;&#20102;&#30456;&#23545;&#35823;&#24046;&#30028;&#38480;&#30340;&#36817;&#20284;&#35823;&#24046;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#20351;&#29992;&#25105;&#20204;&#30340;&#19968;&#33324;&#26497;&#23567;&#26497;&#22823;&#36895;&#20889;&#31232;&#30095;&#20984;&#25110;&#38750;&#20984;&#23398;&#20064;&#38382;&#39064;&#30340;&#35299;&#20915;&#26041;&#26696;&#30340;&#31232;&#30095;&#20449;&#21495;&#20272;&#35745;&#30340;&#26497;&#23567;&#21270;&#36895;&#29575;&#20063;&#24471;&#21040;&#20102;&#12290;
&lt;/p&gt;
&lt;p&gt;
Randomized algorithms are important for solving large-scale optimization problems. In this paper, we propose a fast sketching algorithm for least square problems regularized by convex or nonconvex regularization functions, Sketching for Regularized Optimization (SRO). Our SRO algorithm first generates a sketch of the original data matrix, then solves the sketched problem. Different from existing randomized algorithms, our algorithm handles general Frechet subdifferentiable regularization functions in an unified framework. We present general theoretical result for the approximation error between the optimization results of the original problem and the sketched problem for regularized least square problems which can be convex or nonconvex. For arbitrary convex regularizer, relative-error bound is proved for the approximation error. Importantly, minimax rates for sparse signal estimation by solving the sketched sparse convex or nonconvex learning problems are also obtained using our gener
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23545;&#25193;&#25955;&#27169;&#22411;&#30340;&#27867;&#21270;&#23646;&#24615;&#36827;&#34892;&#20102;&#29702;&#35770;&#30740;&#31350;&#65292;&#24314;&#31435;&#20102;&#22522;&#20110;&#35780;&#20998;&#27861;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#35757;&#32451;&#21160;&#24577;&#20013;&#27867;&#21270;&#24046;&#36317;&#30340;&#29702;&#35770;&#20272;&#35745;&#65292;&#24182;&#22312;&#20572;&#27490;&#35757;&#32451;&#26102;&#21487;&#20197;&#36991;&#20813;&#32500;&#24230;&#35781;&#21650;&#12290;&#36827;&#19968;&#27493;&#23558;&#23450;&#37327;&#20998;&#26512;&#25193;&#23637;&#21040;&#20102;&#25968;&#25454;&#20381;&#36182;&#30340;&#24773;&#26223;&#12290;</title><link>http://arxiv.org/abs/2311.01797</link><description>&lt;p&gt;
&#20851;&#20110;&#25193;&#25955;&#27169;&#22411;&#30340;&#27867;&#21270;&#23646;&#24615;
&lt;/p&gt;
&lt;p&gt;
On the Generalization Properties of Diffusion Models. (arXiv:2311.01797v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01797
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23545;&#25193;&#25955;&#27169;&#22411;&#30340;&#27867;&#21270;&#23646;&#24615;&#36827;&#34892;&#20102;&#29702;&#35770;&#30740;&#31350;&#65292;&#24314;&#31435;&#20102;&#22522;&#20110;&#35780;&#20998;&#27861;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#35757;&#32451;&#21160;&#24577;&#20013;&#27867;&#21270;&#24046;&#36317;&#30340;&#29702;&#35770;&#20272;&#35745;&#65292;&#24182;&#22312;&#20572;&#27490;&#35757;&#32451;&#26102;&#21487;&#20197;&#36991;&#20813;&#32500;&#24230;&#35781;&#21650;&#12290;&#36827;&#19968;&#27493;&#23558;&#23450;&#37327;&#20998;&#26512;&#25193;&#23637;&#21040;&#20102;&#25968;&#25454;&#20381;&#36182;&#30340;&#24773;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27169;&#22411;&#26159;&#19968;&#31867;&#29983;&#25104;&#27169;&#22411;&#65292;&#29992;&#20110;&#24314;&#31435;&#19968;&#20010;&#38543;&#26426;&#20256;&#36755;&#26144;&#23556;&#65292;&#23558;&#32463;&#39564;&#35266;&#27979;&#21040;&#30340;&#20294;&#26410;&#30693;&#30340;&#30446;&#26631;&#20998;&#24067;&#19982;&#24050;&#30693;&#30340;&#20808;&#39564;&#20998;&#24067;&#32852;&#31995;&#36215;&#26469;&#12290;&#23613;&#31649;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#65292;&#20294;&#23545;&#20854;&#27867;&#21270;&#33021;&#21147;&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#26410;&#20805;&#20998;&#21457;&#23637;&#12290;&#26412;&#25991;&#23545;&#25193;&#25955;&#27169;&#22411;&#30340;&#27867;&#21270;&#23646;&#24615;&#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#29702;&#35770;&#30740;&#31350;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#22522;&#20110;&#35780;&#20998;&#27861;&#30340;&#25193;&#25955;&#27169;&#22411;&#30340;&#35757;&#32451;&#21160;&#24577;&#20013;&#27867;&#21270;&#24046;&#36317;&#30340;&#29702;&#35770;&#20272;&#35745;&#65292;&#34920;&#26126;&#22312;&#26679;&#26412;&#22823;&#23567;$n$&#21644;&#27169;&#22411;&#23481;&#37327;$m$&#19978;&#37117;&#23384;&#22312;&#22810;&#39033;&#24335;&#23567;&#30340;&#27867;&#21270;&#35823;&#24046;($O(n^{-2/5}+m^{-4/5})$)&#65292;&#22312;&#20572;&#27490;&#35757;&#32451;&#26102;&#21487;&#20197;&#36991;&#20813;&#32500;&#24230;&#35781;&#21650;&#65288;&#21363;&#25968;&#25454;&#32500;&#24230;&#19981;&#21576;&#25351;&#25968;&#32423;&#22686;&#38271;&#65289;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#23450;&#37327;&#20998;&#26512;&#25193;&#23637;&#21040;&#20102;&#19968;&#20010;&#25968;&#25454;&#20381;&#36182;&#30340;&#24773;&#26223;&#65292;&#20854;&#20013;&#30446;&#26631;&#20998;&#24067;&#34987;&#25551;&#32472;&#20026;&#19968;&#31995;&#21015;&#30340;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models are a class of generative models that serve to establish a stochastic transport map between an empirically observed, yet unknown, target distribution and a known prior. Despite their remarkable success in real-world applications, a theoretical understanding of their generalization capabilities remains underdeveloped. This work embarks on a comprehensive theoretical exploration of the generalization attributes of diffusion models. We establish theoretical estimates of the generalization gap that evolves in tandem with the training dynamics of score-based diffusion models, suggesting a polynomially small generalization error ($O(n^{-2/5}+m^{-4/5})$) on both the sample size $n$ and the model capacity $m$, evading the curse of dimensionality (i.e., not exponentially large in the data dimension) when early-stopped. Furthermore, we extend our quantitative analysis to a data-dependent scenario, wherein target distributions are portrayed as a succession of densities with progr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24191;&#20041;&#20302;&#31209;&#24352;&#37327;&#24773;&#22659;&#36172;&#21338;&#31639;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;G-LowTESTR&#31639;&#27861;&#26469;&#23454;&#29616;&#25506;&#32034;&#21644;&#21033;&#29992;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;</title><link>http://arxiv.org/abs/2311.01771</link><description>&lt;p&gt;
&#39640;&#25928;&#30340;&#24191;&#20041;&#20302;&#31209;&#24352;&#37327;&#24773;&#22659;&#36172;&#21338;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Efficient Generalized Low-Rank Tensor Contextual Bandits. (arXiv:2311.01771v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01771
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24191;&#20041;&#20302;&#31209;&#24352;&#37327;&#24773;&#22659;&#36172;&#21338;&#31639;&#27861;&#65292;&#24182;&#24341;&#20837;&#20102;G-LowTESTR&#31639;&#27861;&#26469;&#23454;&#29616;&#25506;&#32034;&#21644;&#21033;&#29992;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#26500;&#24314;&#19968;&#31181;&#26032;&#39062;&#30340;&#36172;&#21338;&#31639;&#27861;&#65292;&#33021;&#22815;&#20805;&#20998;&#21033;&#29992;&#22810;&#32500;&#25968;&#25454;&#21644;&#22870;&#21169;&#20989;&#25968;&#30340;&#22266;&#26377;&#38750;&#32447;&#24615;&#29305;&#24615;&#65292;&#25552;&#20379;&#39640;&#21487;&#29992;&#21644;&#36127;&#36131;&#20219;&#30340;&#20915;&#31574;&#26381;&#21153;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#24191;&#20041;&#20302;&#31209;&#24352;&#37327;&#24773;&#22659;&#36172;&#21338;&#27169;&#22411;&#65292;&#20854;&#20013;&#19968;&#20010;&#21160;&#20316;&#30001;&#19977;&#20010;&#29305;&#24449;&#21521;&#37327;&#32452;&#25104;&#65292;&#22240;&#27492;&#21487;&#20197;&#29992;&#24352;&#37327;&#34920;&#31034;&#12290;&#22312;&#36825;&#20010;&#27169;&#22411;&#20013;&#65292;&#22870;&#21169;&#26159;&#36890;&#36807;&#23558;&#21160;&#20316;&#30340;&#29305;&#24449;&#24352;&#37327;&#19982;&#19968;&#20010;&#22266;&#23450;&#20294;&#26410;&#30693;&#30340;&#21442;&#25968;&#24352;&#37327;&#30340;&#20869;&#31215;&#24212;&#29992;&#20110;&#24191;&#20041;&#32447;&#24615;&#20989;&#25968;&#26469;&#30830;&#23450;&#30340;&#65292;&#32780;&#36825;&#20010;&#21442;&#25968;&#24352;&#37327;&#20855;&#26377;&#36739;&#20302;&#30340;&#31649;&#29366;&#31209;&#12290;&#20026;&#20102;&#23454;&#29616;&#25506;&#32034;&#21644;&#21033;&#29992;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026;&#8220;&#24191;&#20041;&#20302;&#31209;&#24352;&#37327;&#25506;&#32034;&#23376;&#31354;&#38388;&#28982;&#21518;&#32454;&#21270;&#8221;&#30340;&#26032;&#31639;&#27861;&#65288;G-LowTESTR&#65289;&#12290;&#35813;&#31639;&#27861;&#39318;&#20808;&#25910;&#38598;&#21407;&#22987;&#25968;&#25454;&#65292;&#20197;&#25506;&#32034;&#23884;&#20837;&#22312;&#20915;&#31574;&#24773;&#22659;&#20013;&#30340;&#26412;&#36136;&#20302;&#31209;&#24352;&#37327;&#23376;&#31354;&#38388;&#20449;&#24687;&#65292;&#28982;&#21518;&#23558;&#21407;&#22987;&#27010;&#29575;&#36716;&#25442;&#20026;&#21487;&#35299;&#37322;&#30340;&#32467;&#26500;&#21270;&#27010;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we aim to build a novel bandits algorithm that is capable of fully harnessing the power of multi-dimensional data and the inherent non-linearity of reward functions to provide high-usable and accountable decision-making services. To this end, we introduce a generalized low-rank tensor contextual bandits model in which an action is formed from three feature vectors, and thus can be represented by a tensor. In this formulation, the reward is determined through a generalized linear function applied to the inner product of the action's feature tensor and a fixed but unknown parameter tensor with a low tubal rank. To effectively achieve the trade-off between exploration and exploitation, we introduce a novel algorithm called "Generalized Low-Rank Tensor Exploration Subspace then Refine" (G-LowTESTR). This algorithm first collects raw data to explore the intrinsic low-rank tensor subspace information embedded in the decision-making scenario, and then converts the original prob
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#27861;&#35299;&#20915;&#38750;&#24120;&#25968;&#26680;&#30340;&#26680;&#23725;&#22238;&#24402;&#12290;&#36890;&#36807;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#36880;&#28176;&#20943;&#23567;&#24102;&#23485;&#65292;&#36991;&#20813;&#20102;&#36229;&#21442;&#25968;&#36873;&#25321;&#30340;&#38656;&#27714;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#23485;&#26356;&#26032;&#26041;&#26696;&#65292;&#35777;&#26126;&#20102;&#20854;&#20248;&#20110;&#20351;&#29992;&#24120;&#25968;&#24102;&#23485;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2311.01762</link><description>&lt;p&gt;
&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#27861;&#35299;&#20915;&#38750;&#24120;&#25968;&#26680;&#30340;&#26680;&#23725;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Solving Kernel Ridge Regression with Gradient Descent for a Non-Constant Kernel. (arXiv:2311.01762v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01762
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#27861;&#35299;&#20915;&#38750;&#24120;&#25968;&#26680;&#30340;&#26680;&#23725;&#22238;&#24402;&#12290;&#36890;&#36807;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#36880;&#28176;&#20943;&#23567;&#24102;&#23485;&#65292;&#36991;&#20813;&#20102;&#36229;&#21442;&#25968;&#36873;&#25321;&#30340;&#38656;&#27714;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#24102;&#23485;&#26356;&#26032;&#26041;&#26696;&#65292;&#35777;&#26126;&#20102;&#20854;&#20248;&#20110;&#20351;&#29992;&#24120;&#25968;&#24102;&#23485;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26680;&#23725;&#22238;&#24402;&#65288;KRR&#65289;&#26159;&#32447;&#24615;&#23725;&#22238;&#24402;&#30340;&#25512;&#24191;&#65292;&#23427;&#22312;&#25968;&#25454;&#20013;&#26159;&#38750;&#32447;&#24615;&#30340;&#65292;&#20294;&#22312;&#21442;&#25968;&#20013;&#26159;&#32447;&#24615;&#30340;&#12290;&#35299;&#20915;&#26041;&#26696;&#21487;&#20197;&#36890;&#36807;&#38381;&#24335;&#35299;&#33719;&#24471;&#65292;&#20854;&#20013;&#21253;&#25324;&#30697;&#38453;&#27714;&#36870;&#65292;&#20063;&#21487;&#20197;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#36845;&#20195;&#33719;&#24471;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#25913;&#21464;&#26680;&#20989;&#25968;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#20174;&#29702;&#35770;&#19978;&#25506;&#35752;&#20102;&#36825;&#23545;&#27169;&#22411;&#22797;&#26434;&#24615;&#21644;&#27867;&#21270;&#24615;&#33021;&#30340;&#24433;&#21709;&#12290;&#22522;&#20110;&#25105;&#20204;&#30340;&#21457;&#29616;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#24179;&#31227;&#19981;&#21464;&#26680;&#30340;&#24102;&#23485;&#26356;&#26032;&#26041;&#26696;&#65292;&#20854;&#20013;&#24102;&#23485;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#36880;&#28176;&#20943;&#23567;&#33267;&#38646;&#65292;&#20174;&#32780;&#36991;&#20813;&#20102;&#36229;&#21442;&#25968;&#36873;&#25321;&#30340;&#38656;&#35201;&#12290;&#25105;&#20204;&#22312;&#30495;&#23454;&#21644;&#21512;&#25104;&#25968;&#25454;&#19978;&#23637;&#31034;&#20102;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#36880;&#28176;&#20943;&#23567;&#24102;&#23485;&#30340;&#20248;&#20110;&#20351;&#29992;&#24120;&#25968;&#24102;&#23485;&#65292;&#36890;&#36807;&#20132;&#21449;&#39564;&#35777;&#21644;&#36793;&#32536;&#20284;&#28982;&#26368;&#22823;&#21270;&#36873;&#25321;&#30340;&#24102;&#23485;&#12290;&#25105;&#20204;&#36824;&#20174;&#29702;&#35770;&#21644;&#23454;&#35777;&#19978;&#35777;&#26126;&#20102;&#20351;&#29992;&#36880;&#28176;&#20943;&#23567;&#30340;&#24102;&#23485;&#26102;&#65292;&#25105;&#20204;&#33021;&#22815;...
&lt;/p&gt;
&lt;p&gt;
Kernel ridge regression, KRR, is a generalization of linear ridge regression that is non-linear in the data, but linear in the parameters. The solution can be obtained either as a closed-form solution, which includes a matrix inversion, or iteratively through gradient descent. Using the iterative approach opens up for changing the kernel during training, something that is investigated in this paper. We theoretically address the effects this has on model complexity and generalization. Based on our findings, we propose an update scheme for the bandwidth of translational-invariant kernels, where we let the bandwidth decrease to zero during training, thus circumventing the need for hyper-parameter selection. We demonstrate on real and synthetic data how decreasing the bandwidth during training outperforms using a constant bandwidth, selected by cross-validation and marginal likelihood maximization. We also show theoretically and empirically that using a decreasing bandwidth, we are able to
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#21327;&#21464;&#37327;&#34920;&#31034;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#22823;&#32500;&#24230;&#21327;&#21464;&#37327;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#21487;&#38752;&#30340;&#22240;&#26524;&#25512;&#26029;&#65292;&#24182;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#20854;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2311.01709</link><description>&lt;p&gt;
&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#21327;&#21464;&#37327;&#34920;&#31034;&#30340;&#22240;&#26524;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Causal inference with Machine Learning-Based Covariate Representation. (arXiv:2311.01709v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01709
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#21327;&#21464;&#37327;&#34920;&#31034;&#26041;&#27861;&#65292;&#21487;&#20197;&#22312;&#22823;&#32500;&#24230;&#21327;&#21464;&#37327;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#21487;&#38752;&#30340;&#22240;&#26524;&#25512;&#26029;&#65292;&#24182;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#20854;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21033;&#29992;&#21327;&#21464;&#37327;&#20449;&#24687;&#26159;&#25552;&#39640;&#22240;&#26524;&#25512;&#26029;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#30340;&#24378;&#26377;&#21147;&#26041;&#27861;&#65292;&#21487;&#25903;&#25345;&#22312;&#25968;&#25454;&#39537;&#21160;&#20225;&#19994;&#19978;&#36816;&#34892;&#30340;&#22823;&#37327;&#38543;&#26426;&#23454;&#39564;&#12290;&#28982;&#32780;&#65292;&#22312;&#21327;&#21464;&#37327;&#32500;&#24230;&#22686;&#21152;&#21040;50&#26102;&#65292;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#21487;&#33021;&#21464;&#24471;&#19981;&#21487;&#38752;&#65292;&#32780;&#22823;&#22411;&#24179;&#21488;&#19978;&#30340;&#23454;&#39564;&#21487;&#33021;&#35266;&#23519;&#21040;&#26356;&#39640;&#32500;&#24230;&#30340;&#21327;&#21464;&#37327;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26426;&#22120;&#23398;&#20064;&#36741;&#21161;&#30340;&#21327;&#21464;&#37327;&#34920;&#31034;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#21033;&#29992;&#22312;&#21516;&#19968;&#24179;&#21488;&#19978;&#36816;&#34892;&#30340;&#21382;&#21490;&#23454;&#39564;&#25110;&#35266;&#27979;&#25968;&#25454;&#65292;&#20102;&#35299;&#21738;&#20123;&#20302;&#32500;&#24230;&#21487;&#20197;&#26377;&#25928;&#22320;&#34920;&#31034;&#39640;&#32500;&#21327;&#21464;&#37327;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#35774;&#35745;&#21644;&#20272;&#35745;&#26041;&#27861;&#26469;&#22788;&#29702;&#21327;&#21464;&#37327;&#34920;&#31034;&#12290;&#25105;&#20204;&#20026;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;&#32479;&#35745;&#21487;&#38752;&#24615;&#21644;&#24615;&#33021;&#20445;&#35777;&#12290;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#20854;&#23454;&#35777;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Utilizing covariate information has been a powerful approach to improve the efficiency and accuracy for causal inference, which support massive amount of randomized experiments run on data-driven enterprises. However, state-of-art approaches can become practically unreliable when the dimension of covariate increases to just 50, whereas experiments on large platforms can observe even higher dimension of covariate. We propose a machine-learning-assisted covariate representation approach that can effectively make use of historical experiment or observational data that are run on the same platform to understand which lower dimensions can effectively represent the higher-dimensional covariate. We then propose design and estimation methods with the covariate representation. We prove statistically reliability and performance guarantees for the proposed methods. The empirical performance is demonstrated using numerical experiments.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29983;&#23384;&#20998;&#26512;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#37325;&#35201;&#25277;&#26679;&#65292;&#28040;&#38500;&#20102;&#35843;&#25972;&#36229;&#21442;&#25968;&#30340;&#38656;&#27714;&#65292;&#22914;&#28151;&#21512;&#20998;&#37197;&#21644;&#31665;&#23610;&#23544;&#65292;&#20943;&#36731;&#20102;&#20174;&#19994;&#20154;&#21592;&#30340;&#36127;&#25285;&#12290;</title><link>http://arxiv.org/abs/2311.01660</link><description>&lt;p&gt;
&#24341;&#20837;&#37325;&#35201;&#25277;&#26679;&#30340;&#26580;&#24615;&#29983;&#23384;&#23494;&#24230;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Maximum Likelihood Estimation of Flexible Survival Densities with Importance Sampling. (arXiv:2311.01660v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01660
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29983;&#23384;&#20998;&#26512;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#37325;&#35201;&#25277;&#26679;&#65292;&#28040;&#38500;&#20102;&#35843;&#25972;&#36229;&#21442;&#25968;&#30340;&#38656;&#27714;&#65292;&#22914;&#28151;&#21512;&#20998;&#37197;&#21644;&#31665;&#23610;&#23544;&#65292;&#20943;&#36731;&#20102;&#20174;&#19994;&#20154;&#21592;&#30340;&#36127;&#25285;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#23384;&#20998;&#26512;&#26159;&#19968;&#31181;&#24191;&#27867;&#24212;&#29992;&#20110;&#20998;&#26512;&#20855;&#26377;&#25130;&#23614;&#30340;&#26102;&#38388;&#33267;&#20107;&#20214;&#25968;&#25454;&#30340;&#25216;&#26415;&#12290;&#26368;&#36817;&#20960;&#24180;&#65292;&#20986;&#29616;&#20102;&#35768;&#22810;&#33021;&#22815;&#36866;&#29992;&#20110;&#22823;&#25968;&#25454;&#38598;&#24182;&#25918;&#26494;&#20256;&#32479;&#20551;&#35774;&#65288;&#22914;&#27604;&#20363;&#39118;&#38505;&#65289;&#30340;&#29983;&#23384;&#20998;&#26512;&#26041;&#27861;&#12290;&#23613;&#31649;&#36825;&#20123;&#27169;&#22411;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#23545;&#20110;&#27169;&#22411;&#30340;&#36229;&#21442;&#25968;&#65288;&#22914;&#31163;&#25955;&#27169;&#22411;&#30340;&#31665;&#25968;&#21644;&#31665;&#23610;&#23544;&#65292;&#20197;&#21450;&#22522;&#20110;&#28151;&#21512;&#27169;&#22411;&#30340;&#31751;&#20998;&#37197;&#25968;&#65289;&#38656;&#35201;&#22823;&#37327;&#35843;&#25972;&#20197;&#23454;&#29616;&#26368;&#20339;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#35777;&#26126;&#20102;&#20197;&#19979;&#20107;&#23454;&#65306;&#65288;1&#65289;&#26368;&#20339;&#31665;&#23610;&#23544;&#21487;&#33021;&#20250;&#22240;&#25152;&#20851;&#27880;&#30340;&#25351;&#26631;&#65288;&#22914;&#19968;&#33268;&#24615;&#21644;&#24067;&#37324;&#23572;&#20998;&#25968;&#65289;&#32780;&#22823;&#20026;&#19981;&#21516;&#65292;&#20197;&#21450;&#65288;2&#65289;&#28151;&#21512;&#27169;&#22411;&#21487;&#33021;&#20250;&#36973;&#21463;&#27169;&#24335;&#22349;&#22604;&#21644;&#25968;&#20540;&#19981;&#31283;&#23450;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29983;&#23384;&#20998;&#26512;&#26041;&#27861;&#65292;&#28040;&#38500;&#20102;&#35843;&#25972;&#28151;&#21512;&#20998;&#37197;&#21644;&#31665;&#23610;&#23544;&#31561;&#36229;&#21442;&#25968;&#30340;&#38656;&#27714;&#65292;&#20174;&#32780;&#20943;&#36731;&#20102;&#20174;&#19994;&#20154;&#21592;&#30340;&#36127;&#25285;&#12290;
&lt;/p&gt;
&lt;p&gt;
Survival analysis is a widely-used technique for analyzing time-to-event data in the presence of censoring. In recent years, numerous survival analysis methods have emerged which scale to large datasets and relax traditional assumptions such as proportional hazards. These models, while being performant, are very sensitive to model hyperparameters including: (1) number of bins and bin size for discrete models and (2) number of cluster assignments for mixture-based models. Each of these choices requires extensive tuning by practitioners to achieve optimal performance. In addition, we demonstrate in empirical studies that: (1) optimal bin size may drastically differ based on the metric of interest (e.g., concordance vs brier score), and (2) mixture models may suffer from mode collapse and numerical instability. We propose a survival analysis approach which eliminates the need to tune hyperparameters such as mixture assignments and bin sizes, reducing the burden on practitioners. We show t
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#27424;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#65292;&#23398;&#29983;&#32593;&#32476;&#26159;&#21542;&#24212;&#35813;&#22797;&#21046;&#25945;&#24072;&#31070;&#32463;&#20803;&#25110;&#24179;&#22343;&#19968;&#32452;&#25945;&#24072;&#31070;&#32463;&#20803;&#30340;&#26435;&#37325;&#12290;&#30740;&#31350;&#21457;&#29616;&#23545;&#20110;&#29305;&#23450;&#30340;&#32593;&#32476;&#32467;&#26500;&#21644;&#36755;&#20837;&#20998;&#24067;&#65292;&#24403;&#25945;&#24072;&#32593;&#32476;&#30340;&#36755;&#20837;&#21521;&#37327;&#27491;&#20132;&#19988;&#36755;&#20986;&#26435;&#37325;&#20026;&#37193;&#26102;&#65292;&#22797;&#21046;-&#24179;&#22343;&#37197;&#32622;&#23558;&#36798;&#21040;&#20248;&#21270;&#32467;&#26524;&#65292;&#20854;&#20013;&#22823;&#37096;&#20998;&#23398;&#29983;&#31070;&#32463;&#20803;&#22797;&#21046;&#19968;&#20010;&#25945;&#24072;&#31070;&#32463;&#20803;&#65292;&#26368;&#21518;&#19968;&#20010;&#23398;&#29983;&#31070;&#32463;&#20803;&#23545;&#25152;&#26377;&#25945;&#24072;&#31070;&#32463;&#20803;&#21462;&#24179;&#22343;&#20540;&#12290;</title><link>http://arxiv.org/abs/2311.01644</link><description>&lt;p&gt;
&#23398;&#29983;&#32593;&#32476;&#26159;&#21542;&#24212;&#35813;&#22797;&#21046;&#25110;&#24179;&#22343;&#25945;&#24072;&#26435;&#37325;&#65311;
&lt;/p&gt;
&lt;p&gt;
Should Under-parameterized Student Networks Copy or Average Teacher Weights?. (arXiv:2311.01644v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01644
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#27424;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#65292;&#23398;&#29983;&#32593;&#32476;&#26159;&#21542;&#24212;&#35813;&#22797;&#21046;&#25945;&#24072;&#31070;&#32463;&#20803;&#25110;&#24179;&#22343;&#19968;&#32452;&#25945;&#24072;&#31070;&#32463;&#20803;&#30340;&#26435;&#37325;&#12290;&#30740;&#31350;&#21457;&#29616;&#23545;&#20110;&#29305;&#23450;&#30340;&#32593;&#32476;&#32467;&#26500;&#21644;&#36755;&#20837;&#20998;&#24067;&#65292;&#24403;&#25945;&#24072;&#32593;&#32476;&#30340;&#36755;&#20837;&#21521;&#37327;&#27491;&#20132;&#19988;&#36755;&#20986;&#26435;&#37325;&#20026;&#37193;&#26102;&#65292;&#22797;&#21046;-&#24179;&#22343;&#37197;&#32622;&#23558;&#36798;&#21040;&#20248;&#21270;&#32467;&#26524;&#65292;&#20854;&#20013;&#22823;&#37096;&#20998;&#23398;&#29983;&#31070;&#32463;&#20803;&#22797;&#21046;&#19968;&#20010;&#25945;&#24072;&#31070;&#32463;&#20803;&#65292;&#26368;&#21518;&#19968;&#20010;&#23398;&#29983;&#31070;&#32463;&#20803;&#23545;&#25152;&#26377;&#25945;&#24072;&#31070;&#32463;&#20803;&#21462;&#24179;&#22343;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20219;&#20309;&#36830;&#32493;&#20989;&#25968; $f^*$ &#37117;&#21487;&#20197;&#29992;&#36275;&#22815;&#22810;&#30340;&#31070;&#32463;&#20803; $k$&#26469;&#36817;&#20284;&#12290;&#25105;&#20204;&#32771;&#34385; $f^*$ &#26412;&#36523;&#26159;&#19968;&#20010;&#20855;&#26377;&#19968;&#20010;&#38544;&#34255;&#23618;&#21644; $k$ &#20010;&#31070;&#32463;&#20803;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#24773;&#20917;&#12290;&#29992;&#20855;&#26377; $n&lt;k$ &#20010;&#31070;&#32463;&#20803;&#30340;&#31070;&#32463;&#32593;&#32476;&#26469;&#36924;&#36817; $f^*$ &#21487;&#20197;&#30475;&#20316;&#26159;&#23558;&#19968;&#20010;&#27424;&#21442;&#25968;&#21270;&#30340;&#8220;&#23398;&#29983;&#8221;&#32593;&#32476;&#19982; $k$ &#20010;&#31070;&#32463;&#20803;&#30340;&#8220;&#25945;&#24072;&#8221;&#32593;&#32476;&#36827;&#34892;&#25311;&#21512;&#12290;&#30001;&#20110;&#23398;&#29983;&#20855;&#26377;&#36739;&#23569;&#30340;&#31070;&#32463;&#20803;&#65292;&#25152;&#20197;&#19981;&#28165;&#26970;&#27599;&#20010; $n$ &#20010;&#23398;&#29983;&#31070;&#32463;&#20803;&#24212;&#35813;&#22797;&#21046;&#19968;&#20010;&#25945;&#24072;&#31070;&#32463;&#20803;&#36824;&#26159;&#24179;&#22343;&#19968;&#32452;&#25945;&#24072;&#31070;&#32463;&#20803;&#12290;&#23545;&#20110;&#20855;&#26377; erf &#28608;&#27963;&#20989;&#25968;&#21644;&#26631;&#20934;&#39640;&#26031;&#36755;&#20837;&#20998;&#24067;&#30340;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#25945;&#24072;&#30340;&#36755;&#20837;&#21521;&#37327;&#26159;&#27491;&#20132;&#30340;&#24182;&#19988;&#36755;&#20986;&#26435;&#37325;&#26159;&#37193;&#30340;&#26102;&#20505;&#65292;&#8220;&#22797;&#21046;-&#24179;&#22343;&#8221;&#37197;&#32622;&#26159;&#20020;&#30028;&#28857;&#12290;&#27492;&#22806;&#65292;&#22312;&#36825;&#26679;&#30340;&#37197;&#32622;&#20013;&#65292;&#20248;&#21270;&#32467;&#26524;&#26159;&#24403; $n-1$ &#20010;&#23398;&#29983;&#31070;&#32463;&#20803;&#20998;&#21035;&#22797;&#21046;&#19968;&#20010;&#25945;&#24072;&#31070;&#32463;&#20803;&#65292;&#24182;&#19988;&#31532; $n$ &#20010;&#23398;&#29983;&#31070;&#32463;&#20803;&#26159;&#25152;&#26377;&#25945;&#24072;&#31070;&#32463;&#20803;&#30340;&#24179;&#22343;&#12290;
&lt;/p&gt;
&lt;p&gt;
Any continuous function $f^*$ can be approximated arbitrarily well by a neural network with sufficiently many neurons $k$. We consider the case when $f^*$ itself is a neural network with one hidden layer and $k$ neurons. Approximating $f^*$ with a neural network with $n&lt; k$ neurons can thus be seen as fitting an under-parameterized "student" network with $n$ neurons to a "teacher" network with $k$ neurons. As the student has fewer neurons than the teacher, it is unclear, whether each of the $n$ student neurons should copy one of the teacher neurons or rather average a group of teacher neurons. For shallow neural networks with erf activation function and for the standard Gaussian input distribution, we prove that "copy-average" configurations are critical points if the teacher's incoming vectors are orthonormal and its outgoing weights are unitary. Moreover, the optimum among such configurations is reached when $n-1$ student neurons each copy one teacher neuron and the $n$-th student ne
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FRED&#30340;&#26032;&#39062;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#37322;&#25991;&#26412;&#39044;&#27979;&#12290;FRED&#21487;&#20197;&#35782;&#21035;&#25991;&#26723;&#20013;&#30340;&#20851;&#38190;&#35789;&#65292;&#24182;&#19988;&#36890;&#36807;&#19982;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#36827;&#34892;&#30340;&#23454;&#35777;&#35780;&#20272;&#35777;&#26126;&#20102;&#20854;&#22312;&#25552;&#20379;&#23545;&#25991;&#26412;&#27169;&#22411;&#30340;&#28145;&#20837;&#35265;&#35299;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2311.01605</link><description>&lt;p&gt;
&#23545;&#20110;&#25991;&#26412;&#39044;&#27979;&#30340;&#24544;&#23454;&#21644;&#31283;&#20581;&#30340;&#26412;&#22320;&#21487;&#35299;&#37322;&#24615;
&lt;/p&gt;
&lt;p&gt;
Faithful and Robust Local Interpretability for Textual Predictions. (arXiv:2311.01605v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01605
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FRED&#30340;&#26032;&#39062;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#37322;&#25991;&#26412;&#39044;&#27979;&#12290;FRED&#21487;&#20197;&#35782;&#21035;&#25991;&#26723;&#20013;&#30340;&#20851;&#38190;&#35789;&#65292;&#24182;&#19988;&#36890;&#36807;&#19982;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#36827;&#34892;&#30340;&#23454;&#35777;&#35780;&#20272;&#35777;&#26126;&#20102;&#20854;&#22312;&#25552;&#20379;&#23545;&#25991;&#26412;&#27169;&#22411;&#30340;&#28145;&#20837;&#35265;&#35299;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#35299;&#37322;&#24615;&#23545;&#20110;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#20851;&#38190;&#39046;&#22495;&#20013;&#24471;&#21040;&#20449;&#20219;&#21644;&#37096;&#32626;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#29992;&#20110;&#35299;&#37322;&#25991;&#26412;&#27169;&#22411;&#30340;&#26041;&#27861;&#36890;&#24120;&#22797;&#26434;&#65292;&#24182;&#19988;&#32570;&#20047;&#22362;&#23454;&#30340;&#25968;&#23398;&#22522;&#30784;&#65292;&#23427;&#20204;&#30340;&#24615;&#33021;&#20063;&#19981;&#33021;&#20445;&#35777;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;FRED&#65288;Faithful and Robust Explainer for textual Documents&#65289;&#65292;&#29992;&#20110;&#35299;&#37322;&#25991;&#26412;&#39044;&#27979;&#12290;FRED&#21487;&#20197;&#35782;&#21035;&#25991;&#26723;&#20013;&#30340;&#20851;&#38190;&#35789;&#65292;&#24403;&#36825;&#20123;&#35789;&#34987;&#31227;&#38500;&#26102;&#23545;&#39044;&#27979;&#32467;&#26524;&#20135;&#29983;&#37325;&#22823;&#24433;&#21709;&#12290;&#25105;&#20204;&#36890;&#36807;&#27491;&#24335;&#30340;&#23450;&#20041;&#21644;&#23545;&#21487;&#35299;&#37322;&#20998;&#31867;&#22120;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#30830;&#31435;&#20102;FRED&#30340;&#21487;&#38752;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#36890;&#36807;&#19982;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#36827;&#34892;&#30340;&#23454;&#35777;&#35780;&#20272;&#65292;&#35777;&#26126;&#20102;FRED&#22312;&#25552;&#20379;&#23545;&#25991;&#26412;&#27169;&#22411;&#30340;&#28145;&#20837;&#35265;&#35299;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Interpretability is essential for machine learning models to be trusted and deployed in critical domains. However, existing methods for interpreting text models are often complex, lack solid mathematical foundations, and their performance is not guaranteed. In this paper, we propose FRED (Faithful and Robust Explainer for textual Documents), a novel method for interpreting predictions over text. FRED identifies key words in a document that significantly impact the prediction when removed. We establish the reliability of FRED through formal definitions and theoretical analyses on interpretable classifiers. Additionally, our empirical evaluation against state-of-the-art methods demonstrates the effectiveness of FRED in providing insights into text models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#29380;&#21033;&#20811;&#38647;&#20998;&#24067;&#32467;&#21512;&#22810;&#20010;&#19981;&#23436;&#21892;&#27169;&#22411;&#32467;&#26524;&#30340;&#36125;&#21494;&#26031;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#22312;&#25552;&#39640;&#22797;&#26434;&#35745;&#31639;&#27169;&#22411;&#30340;&#21487;&#39044;&#27979;&#24615;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#23588;&#20854;&#22312;&#26680;&#36136;&#37327;&#25366;&#25496;&#20013;&#21462;&#24471;&#20102;&#24456;&#22909;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2311.01596</link><description>&lt;p&gt;
&#19981;&#23436;&#21892;&#27169;&#22411;&#30340;&#26412;&#22320;&#36125;&#21494;&#26031;&#29380;&#21033;&#20811;&#38647;&#28151;&#21512;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Local Bayesian Dirichlet mixing of imperfect models. (arXiv:2311.01596v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01596
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#29380;&#21033;&#20811;&#38647;&#20998;&#24067;&#32467;&#21512;&#22810;&#20010;&#19981;&#23436;&#21892;&#27169;&#22411;&#32467;&#26524;&#30340;&#36125;&#21494;&#26031;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#22312;&#25552;&#39640;&#22797;&#26434;&#35745;&#31639;&#27169;&#22411;&#30340;&#21487;&#39044;&#27979;&#24615;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#23588;&#20854;&#22312;&#26680;&#36136;&#37327;&#25366;&#25496;&#20013;&#21462;&#24471;&#20102;&#24456;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#25552;&#39640;&#22312;&#26410;&#30693;&#39046;&#22495;&#20013;&#22797;&#26434;&#35745;&#31639;&#27169;&#22411;&#30340;&#21487;&#39044;&#27979;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#29380;&#21033;&#20811;&#38647;&#20998;&#24067;&#32467;&#21512;&#22810;&#20010;&#19981;&#23436;&#21892;&#27169;&#22411;&#32467;&#26524;&#30340;&#36125;&#21494;&#26031;&#32479;&#35745;&#26426;&#22120;&#23398;&#20064;&#26694;&#26550;&#12290;&#36825;&#20010;&#26694;&#26550;&#21487;&#20197;&#30475;&#20316;&#26159;&#36125;&#21494;&#26031;&#22534;&#21472;&#30340;&#25193;&#23637;&#12290;&#20026;&#20102;&#35828;&#26126;&#36825;&#20010;&#26041;&#27861;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#36125;&#21494;&#26031;&#27169;&#22411;&#24179;&#22343;&#21644;&#28151;&#21512;&#25216;&#26415;&#22312;&#25366;&#25496;&#26680;&#36136;&#37327;&#26041;&#38754;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#20840;&#23616;&#21644;&#23616;&#37096;&#27169;&#22411;&#28151;&#21512;&#22312;&#39044;&#27979;&#31934;&#24230;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26041;&#38754;&#37117;&#36798;&#21040;&#20102;&#38750;&#24120;&#22909;&#30340;&#34920;&#29616;&#65292;&#24182;&#19988;&#27604;&#20256;&#32479;&#30340;&#36125;&#21494;&#26031;&#27169;&#22411;&#24179;&#22343;&#26356;&#21487;&#21462;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#32479;&#35745;&#20998;&#26512;&#34920;&#26126;&#65292;&#36890;&#36807;&#28151;&#21512;&#32780;&#19981;&#26159;&#32416;&#27491;&#27169;&#22411;&#30340;&#28151;&#21512;&#26469;&#25913;&#21892;&#27169;&#22411;&#39044;&#27979;&#21487;&#20197;&#33719;&#24471;&#26356;&#31283;&#20581;&#30340;&#22806;&#25512;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
To improve the predictability of complex computational models in the experimentally-unknown domains, we propose a Bayesian statistical machine learning framework utilizing the Dirichlet distribution that combines results of several imperfect models. This framework can be viewed as an extension of Bayesian stacking. To illustrate the method, we study the ability of Bayesian model averaging and mixing techniques to mine nuclear masses. We show that the global and local mixtures of models reach excellent performance on both prediction accuracy and uncertainty quantification and are preferable to classical Bayesian model averaging. Additionally, our statistical analysis indicates that improving model predictions through mixing rather than mixing of corrected models leads to more robust extrapolations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#25968;&#25454;&#38598;&#27604;&#36739;&#20013;&#30340;&#21464;&#37327;&#36873;&#25321;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#22823;&#24179;&#22343;&#24046;&#24322;&#30340;&#20004;&#26679;&#26412;&#27979;&#35797;&#26041;&#27861;&#65292;&#36890;&#36807;&#20248;&#21270;&#33258;&#21160;&#30456;&#20851;&#24615;&#26816;&#27979;&#26435;&#37325;&#26469;&#22686;&#24378;&#27979;&#35797;&#30340;&#21151;&#25928;&#65292;&#24182;&#24341;&#20837;&#31232;&#30095;&#27491;&#21017;&#21270;&#26041;&#27861;&#26469;&#35299;&#20915;&#27491;&#21017;&#21270;&#21442;&#25968;&#36873;&#25321;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2311.01537</link><description>&lt;p&gt;
&#22312;&#21487;&#35299;&#37322;&#30340;&#20998;&#24067;&#27604;&#36739;&#20013;&#30340;&#26368;&#22823;&#24179;&#22343;&#24046;&#24322;&#20013;&#30340;&#21464;&#37327;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Variable Selection in Maximum Mean Discrepancy for Interpretable Distribution Comparison. (arXiv:2311.01537v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01537
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#25968;&#25454;&#38598;&#27604;&#36739;&#20013;&#30340;&#21464;&#37327;&#36873;&#25321;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#22823;&#24179;&#22343;&#24046;&#24322;&#30340;&#20004;&#26679;&#26412;&#27979;&#35797;&#26041;&#27861;&#65292;&#36890;&#36807;&#20248;&#21270;&#33258;&#21160;&#30456;&#20851;&#24615;&#26816;&#27979;&#26435;&#37325;&#26469;&#22686;&#24378;&#27979;&#35797;&#30340;&#21151;&#25928;&#65292;&#24182;&#24341;&#20837;&#31232;&#30095;&#27491;&#21017;&#21270;&#26041;&#27861;&#26469;&#35299;&#20915;&#27491;&#21017;&#21270;&#21442;&#25968;&#36873;&#25321;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20004;&#26679;&#26412;&#27979;&#35797;&#26159;&#20026;&#20102;&#21028;&#26029;&#20004;&#20010;&#25968;&#25454;&#38598;&#26159;&#21542;&#26469;&#33258;&#21516;&#19968;&#20998;&#24067;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#26679;&#26412;&#27979;&#35797;&#20013;&#30340;&#21464;&#37327;&#36873;&#25321;&#38382;&#39064;&#65292;&#21363;&#35782;&#21035;&#36896;&#25104;&#20004;&#20010;&#20998;&#24067;&#24046;&#24322;&#30340;&#21464;&#37327;&#65288;&#25110;&#32500;&#24230;&#65289;&#30340;&#20219;&#21153;&#12290;&#36825;&#20010;&#20219;&#21153;&#19982;&#27169;&#24335;&#20998;&#26512;&#21644;&#26426;&#22120;&#23398;&#20064;&#30340;&#35768;&#22810;&#38382;&#39064;&#30456;&#20851;&#65292;&#22914;&#25968;&#25454;&#38598;&#28418;&#31227;&#36866;&#24212;&#12289;&#22240;&#26524;&#25512;&#26029;&#21644;&#27169;&#22411;&#39564;&#35777;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#22522;&#20110;&#26368;&#22823;&#24179;&#22343;&#24046;&#24322;&#65288;MMD&#65289;&#30340;&#20004;&#26679;&#26412;&#26816;&#39564;&#12290;&#25105;&#20204;&#20248;&#21270;&#38024;&#23545;&#21508;&#20010;&#21464;&#37327;&#23450;&#20041;&#30340;&#33258;&#21160;&#30456;&#20851;&#24615;&#26816;&#27979;&#65288;ARD&#65289;&#26435;&#37325;&#65292;&#20197;&#26368;&#22823;&#21270;&#22522;&#20110;MMD&#30340;&#26816;&#39564;&#30340;&#21151;&#29575;&#12290;&#23545;&#20110;&#36825;&#31181;&#20248;&#21270;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#31232;&#30095;&#27491;&#21017;&#21270;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#26041;&#27861;&#26469;&#35299;&#20915;&#36873;&#25321;&#36866;&#24403;&#27491;&#21017;&#21270;&#21442;&#25968;&#30340;&#38382;&#39064;&#12290;&#19968;&#31181;&#26041;&#27861;&#26159;&#20197;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#24335;&#30830;&#23450;&#27491;&#21017;&#21270;&#21442;&#25968;&#65292;&#21478;&#19968;&#31181;&#26041;&#27861;&#26159;&#21512;&#24182;&#19981;&#21516;&#27491;&#21017;&#21270;&#21442;&#25968;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#30830;&#35748;&#20102;&#36825;&#20010;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Two-sample testing decides whether two datasets are generated from the same distribution. This paper studies variable selection for two-sample testing, the task being to identify the variables (or dimensions) responsible for the discrepancies between the two distributions. This task is relevant to many problems of pattern analysis and machine learning, such as dataset shift adaptation, causal inference and model validation. Our approach is based on a two-sample test based on the Maximum Mean Discrepancy (MMD). We optimise the Automatic Relevance Detection (ARD) weights defined for individual variables to maximise the power of the MMD-based test. For this optimisation, we introduce sparse regularisation and propose two methods for dealing with the issue of selecting an appropriate regularisation parameter. One method determines the regularisation parameter in a data-driven way, and the other aggregates the results of different regularisation parameters. We confirm the validity of the pr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19981;&#21464;&#22240;&#26524;&#27169;&#20223;&#23398;&#20064;&#65288;ICIL&#65289;&#30340;&#26032;&#25216;&#26415;&#65292;&#36890;&#36807;&#23398;&#20064;&#19968;&#20010;&#36328;&#39046;&#22495;&#19981;&#21464;&#30340;&#29305;&#24449;&#34920;&#31034;&#65292;&#23454;&#29616;&#22312;&#26410;&#30693;&#29615;&#22659;&#20013;&#36827;&#34892;&#27169;&#20223;&#31574;&#30053;&#65292;&#24182;&#35299;&#20915;&#36716;&#25442;&#21160;&#24577;&#19981;&#21305;&#37197;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2311.01489</link><description>&lt;p&gt;
&#36890;&#29992;&#30340;&#19981;&#21464;&#22240;&#26524;&#27169;&#20223;&#23398;&#20064;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Invariant Causal Imitation Learning for Generalizable Policies. (arXiv:2311.01489v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01489
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19981;&#21464;&#22240;&#26524;&#27169;&#20223;&#23398;&#20064;&#65288;ICIL&#65289;&#30340;&#26032;&#25216;&#26415;&#65292;&#36890;&#36807;&#23398;&#20064;&#19968;&#20010;&#36328;&#39046;&#22495;&#19981;&#21464;&#30340;&#29305;&#24449;&#34920;&#31034;&#65292;&#23454;&#29616;&#22312;&#26410;&#30693;&#29615;&#22659;&#20013;&#36827;&#34892;&#27169;&#20223;&#31574;&#30053;&#65292;&#24182;&#35299;&#20915;&#36716;&#25442;&#21160;&#24577;&#19981;&#21305;&#37197;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#22522;&#20110;&#22810;&#20010;&#29615;&#22659;&#20013;&#30340;&#31034;&#33539;&#34892;&#20026;&#23398;&#20064;&#27169;&#20223;&#31574;&#30053;&#65292;&#24182;&#19988;&#24076;&#26395;&#33021;&#22815;&#22312;&#26410;&#30693;&#29615;&#22659;&#20013;&#36827;&#34892;&#24212;&#29992;&#12290;&#30001;&#20110;&#27599;&#20010;&#29615;&#22659;&#30340;&#21487;&#35266;&#23519;&#29305;&#24449;&#21487;&#33021;&#19981;&#21516;&#65292;&#30452;&#25509;&#23398;&#20064;&#23558;&#29305;&#24449;&#26144;&#23556;&#21040;&#21160;&#20316;&#30340;&#20010;&#21035;&#31574;&#30053;&#23481;&#26131;&#20135;&#29983;&#38169;&#35823;&#30340;&#30456;&#20851;&#24615;&#65292;&#24182;&#19988;&#21487;&#33021;&#26080;&#27861;&#24456;&#22909;&#22320;&#36827;&#34892;&#27867;&#21270;&#12290;&#28982;&#32780;&#65292;&#19987;&#23478;&#31574;&#30053;&#36890;&#24120;&#26159;&#22522;&#20110;&#19968;&#20010;&#22312;&#19981;&#21516;&#29615;&#22659;&#20013;&#37117;&#19981;&#21464;&#30340;&#20849;&#20139;&#28508;&#22312;&#32467;&#26500;&#30340;&#20989;&#25968;&#12290;&#36890;&#36807;&#21033;&#29992;&#26469;&#33258;&#22810;&#20010;&#29615;&#22659;&#30340;&#25968;&#25454;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19981;&#21464;&#22240;&#26524;&#27169;&#20223;&#23398;&#20064;&#65288;ICIL&#65289;&#30340;&#26032;&#25216;&#26415;&#65292;&#22312;&#35813;&#25216;&#26415;&#20013;&#25105;&#20204;&#23398;&#20064;&#19968;&#20010;&#36328;&#39046;&#22495;&#19981;&#21464;&#30340;&#29305;&#24449;&#34920;&#31034;&#65292;&#28982;&#21518;&#22522;&#20110;&#27492;&#23398;&#20064;&#19982;&#19987;&#23478;&#34892;&#20026;&#30456;&#21305;&#37197;&#30340;&#27169;&#20223;&#31574;&#30053;&#12290;&#20026;&#20102;&#35299;&#20915;&#36716;&#25442;&#21160;&#24577;&#19981;&#21305;&#37197;&#30340;&#38382;&#39064;&#65292;ICIL&#23398;&#20064;&#20102;&#19968;&#20010;&#20851;&#20110;&#35757;&#32451;&#29615;&#22659;&#20013;&#30340;&#22240;&#26524;&#29305;&#24449;&#30340;&#20849;&#20139;&#34920;&#31034;&#65292;&#35813;&#34920;&#31034;&#19982;&#22122;&#22768;&#21464;&#37327;&#30340;&#29305;&#23450;&#34920;&#31034;&#30456;&#20998;&#31163;&#12290;
&lt;/p&gt;
&lt;p&gt;
Consider learning an imitation policy on the basis of demonstrated behavior from multiple environments, with an eye towards deployment in an unseen environment. Since the observable features from each setting may be different, directly learning individual policies as mappings from features to actions is prone to spurious correlations -- and may not generalize well. However, the expert's policy is often a function of a shared latent structure underlying those observable features that is invariant across settings. By leveraging data from multiple environments, we propose Invariant Causal Imitation Learning (ICIL), a novel technique in which we learn a feature representation that is invariant across domains, on the basis of which we learn an imitation policy that matches expert behavior. To cope with transition dynamics mismatch, ICIL learns a shared representation of causal features (for all training environments), that is disentangled from the specific representations of noise variables
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25551;&#36848;&#20102;&#32858;&#21512;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#65288;AMP&#65289;&#30340;&#29702;&#35770;&#22914;&#20309;&#24212;&#29992;&#20110;&#38543;&#26426;&#23398;&#20064;&#29702;&#35770;&#20013;&#65292;&#20197;&#38477;&#20302;&#32500;&#24230;&#24182;&#23454;&#29616;&#23398;&#20064;&#29305;&#23450;&#20219;&#21153;&#30340;&#30446;&#26631;&#12290;</title><link>http://arxiv.org/abs/2311.01476</link><description>&lt;p&gt;
&#22312;&#38543;&#26426;&#23398;&#20064;&#29702;&#35770;&#20013;&#24212;&#29992;&#32858;&#21512;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Applications of the Theory of Aggregated Markov Processes in Stochastic Learning Theory. (arXiv:2311.01476v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01476
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25551;&#36848;&#20102;&#32858;&#21512;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#65288;AMP&#65289;&#30340;&#29702;&#35770;&#22914;&#20309;&#24212;&#29992;&#20110;&#38543;&#26426;&#23398;&#20064;&#29702;&#35770;&#20013;&#65292;&#20197;&#38477;&#20302;&#32500;&#24230;&#24182;&#23454;&#29616;&#23398;&#20064;&#29305;&#23450;&#20219;&#21153;&#30340;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23558;&#20989;&#25968;&#19982;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#32452;&#21512;&#24471;&#21040;&#30340;&#38543;&#26426;&#36807;&#31243;&#34987;&#31216;&#20026;&#32858;&#21512;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#65288;AMP&#65289;&#12290;&#23558;&#39532;&#23572;&#21487;&#22827;&#36807;&#31243;&#19982;&#20989;&#25968;&#32452;&#21512;&#30340;&#30446;&#30340;&#21487;&#20197;&#26159;&#38477;&#20302;&#32500;&#24230;&#65292;&#20363;&#22914;&#22312;&#29305;&#23450;&#22352;&#26631;&#19978;&#36827;&#34892;&#25237;&#24433;&#12290;AMP&#30340;&#29702;&#35770;&#24050;&#32463;&#34987;Dynkin&#12289;Cameron&#12289;Rogers&#21644;Pitman&#20197;&#21450;Kelly&#31561;&#20154;&#24191;&#27867;&#30740;&#31350;&#65292;&#20182;&#20204;&#25552;&#20379;&#20102;AMP&#20445;&#25345;&#39532;&#23572;&#21487;&#22827;&#24615;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#22312;&#21478;&#19968;&#20010;&#26041;&#21521;&#19978;&#65292;Larget&#25552;&#20379;&#20102;AMP&#30340;&#35268;&#33539;&#34920;&#31034;&#65292;&#21487;&#20197;&#29992;&#20110;&#39564;&#35777;&#20004;&#20010;AMP&#30340;&#31561;&#20215;&#24615;&#12290;&#26412;&#25991;&#26088;&#22312;&#25551;&#36848;&#22914;&#20309;&#23558;AMP&#30340;&#29702;&#35770;&#24212;&#29992;&#20110;&#38543;&#26426;&#23398;&#20064;&#29702;&#35770;&#20013;&#65292;&#20197;&#23454;&#29616;&#20182;&#20204;&#22312;&#23398;&#20064;&#29305;&#23450;&#20219;&#21153;&#26102;&#30340;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
A stochastic process that arises by composing a function with a Markov process is called an aggregated Markov process (AMP). The purpose of composing a Markov process with a function can be a reduction of dimensions, e.g., a projection onto certain coordinates. The theory around AMP has been extensively studied e.g. by Dynkin, Cameron, Rogers and Pitman, and Kelly, all of whom provided sufficient conditions for an AMP to remain Markov. In another direction, Larget provided a canonical representation for AMP, which can be used to verify the equivalence of two AMPs. The purpose of this paper is to describe how the theory of AMP can be applied to stochastic learning theory as they learn a particular task.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#20844;&#24335;&#30340;&#23725;&#22238;&#24402;&#26041;&#27861;&#65292;&#36890;&#36807;&#26399;&#26395;&#26368;&#22823;&#21270;&#26469;&#35843;&#33410;&#27491;&#21017;&#21270;&#36229;&#21442;&#25968;&#65292;&#35813;&#26041;&#27861;&#19981;&#38656;&#35201;&#25351;&#23450;&#20505;&#36873;&#30340;&#955;&#24182;&#19988;&#22312;&#22823;&#26679;&#26412;&#19979;&#21487;&#20197;&#25214;&#21040;&#21807;&#19968;&#30340;&#26368;&#20248;&#35299;&#12290;</title><link>http://arxiv.org/abs/2310.18860</link><description>&lt;p&gt;
Bayes&#25112;&#32988;&#20132;&#21449;&#39564;&#35777;&#65306;&#36890;&#36807;&#26399;&#26395;&#26368;&#22823;&#21270;&#23454;&#29616;&#39640;&#25928;&#20934;&#30830;&#30340;&#23725;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Bayes beats Cross Validation: Efficient and Accurate Ridge Regression via Expectation Maximization. (arXiv:2310.18860v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18860
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#20844;&#24335;&#30340;&#23725;&#22238;&#24402;&#26041;&#27861;&#65292;&#36890;&#36807;&#26399;&#26395;&#26368;&#22823;&#21270;&#26469;&#35843;&#33410;&#27491;&#21017;&#21270;&#36229;&#21442;&#25968;&#65292;&#35813;&#26041;&#27861;&#19981;&#38656;&#35201;&#25351;&#23450;&#20505;&#36873;&#30340;&#955;&#24182;&#19988;&#22312;&#22823;&#26679;&#26412;&#19979;&#21487;&#20197;&#25214;&#21040;&#21807;&#19968;&#30340;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#35843;&#33410;&#23725;&#22238;&#24402;&#30340;&#27491;&#21017;&#21270;&#36229;&#21442;&#25968;&#955;&#65292;&#35813;&#26041;&#27861;&#30340;&#35745;&#31639;&#36895;&#24230;&#27604;&#30041;&#19968;&#20132;&#21449;&#39564;&#35777;(LOOCV)&#24555;&#65292;&#21516;&#26102;&#22312;&#31232;&#30095;&#21327;&#21464;&#37327;&#30340;&#24773;&#20917;&#19979;&#21487;&#20197;&#33719;&#24471;&#19982;LOOCV&#30456;&#31561;&#25110;&#26356;&#22909;&#30340;&#22238;&#24402;&#21442;&#25968;&#20272;&#35745;&#12290;&#23545;&#20110;&#26377;&#38480;&#30340;n&#65292;LOOCV&#39118;&#38505;&#21487;&#33021;&#21463;&#21040;&#22810;&#20010;&#21644;&#19981;&#22909;&#30340;&#23616;&#37096;&#26368;&#23567;&#20540;&#30340;&#24433;&#21709;&#65292;&#22240;&#27492;&#38656;&#35201;&#25351;&#23450;&#19968;&#32452;&#20505;&#36873;&#30340;&#955;&#65292;&#36825;&#21487;&#33021;&#26080;&#27861;&#25552;&#20379;&#33391;&#22909;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#36275;&#22815;&#22823;&#30340;n&#19979;&#21487;&#20197;&#25214;&#21040;&#21807;&#19968;&#30340;&#26368;&#20248;&#35299;&#65292;&#24182;&#19988;&#19981;&#38656;&#35201;&#25351;&#23450;&#20219;&#20309;&#38590;&#20197;&#30830;&#23450;&#30340;&#36229;&#21442;&#25968;&#12290;&#36825;&#26159;&#22522;&#20110;&#23725;&#22238;&#24402;&#30340;&#36125;&#21494;&#26031;&#20844;&#24335;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#36275;&#22815;&#22823;&#30340;n&#65292;&#21518;&#39564;&#26159;&#21333;&#23792;&#30340;&#65292;&#21487;&#20197;&#21516;&#26102;&#23398;&#20064;&#26368;&#20248;&#30340;&#955;&#21644;&#22238;&#24402;&#31995;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a novel method for tuning the regularization hyper-parameter, $\lambda$, of a ridge regression that is faster to compute than leave-one-out cross-validation (LOOCV) while yielding estimates of the regression parameters of equal, or particularly in the setting of sparse covariates, superior quality to those obtained by minimising the LOOCV risk. The LOOCV risk can suffer from multiple and bad local minima for finite $n$ and thus requires the specification of a set of candidate $\lambda$, which can fail to provide good solutions. In contrast, we show that the proposed method is guaranteed to find a unique optimal solution for large enough $n$, under relatively mild conditions, without requiring the specification of any difficult to determine hyper-parameters. This is based on a Bayesian formulation of ridge regression that we prove to have a unimodal posterior for large enough $n$, allowing for both the optimal $\lambda$ and the regression coefficients to be jointly learned wi
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Q&#38598;&#25104;&#30340;CATE&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#20854;&#36890;&#36807;&#20351;&#29992;&#21452;&#37325;&#40065;&#26834;&#25439;&#22833;&#23454;&#29616;&#20102;&#32479;&#35745;&#19978;&#30340;&#26368;&#20339;&#39044;&#27979;&#27169;&#22411;&#36873;&#25321;&#36951;&#25022;&#29575;</title><link>http://arxiv.org/abs/2310.16945</link><description>&lt;p&gt;
Causal Q-Aggregation for CATE Model Selection&#65288;CATE&#27169;&#22411;&#36873;&#25321;&#20013;&#30340;&#22240;&#26524;Q&#38598;&#25104;&#65289;
&lt;/p&gt;
&lt;p&gt;
Causal Q-Aggregation for CATE Model Selection. (arXiv:2310.16945v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.16945
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Q&#38598;&#25104;&#30340;CATE&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#20854;&#36890;&#36807;&#20351;&#29992;&#21452;&#37325;&#40065;&#26834;&#25439;&#22833;&#23454;&#29616;&#20102;&#32479;&#35745;&#19978;&#30340;&#26368;&#20339;&#39044;&#27979;&#27169;&#22411;&#36873;&#25321;&#36951;&#25022;&#29575;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20934;&#30830;&#20272;&#35745;&#26465;&#20214;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#65288;CATE&#65289;&#26159;&#20010;&#24615;&#21270;&#20915;&#31574;&#30340;&#26680;&#24515;&#12290;&#23613;&#31649;&#26377;&#22823;&#37327;&#29992;&#20110;CATE&#20272;&#35745;&#30340;&#27169;&#22411;&#65292;&#20294;&#30001;&#20110;&#22240;&#26524;&#25512;&#26029;&#30340;&#22522;&#26412;&#38382;&#39064;&#65292;&#27169;&#22411;&#36873;&#25321;&#26159;&#19968;&#39033;&#38750;&#24120;&#26840;&#25163;&#30340;&#20219;&#21153;&#12290;&#26368;&#36817;&#30340;&#23454;&#35777;&#24037;&#20316;&#25552;&#20379;&#20102;&#26377;&#21033;&#20110;&#20855;&#26377;&#21452;&#37325;&#40065;&#26834;&#24615;&#36136;&#30340;&#20195;&#29702;&#25439;&#22833;&#24230;&#37327;&#21644;&#27169;&#22411;&#38598;&#25104;&#30340;&#35777;&#25454;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#36825;&#20123;&#27169;&#22411;&#30340;&#29702;&#35770;&#29702;&#35299;&#36824;&#19981;&#22815;&#12290;&#30452;&#25509;&#24212;&#29992;&#20808;&#21069;&#30340;&#29702;&#35770;&#24037;&#20316;&#20250;&#30001;&#20110;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#30340;&#38750;&#20984;&#24615;&#32780;&#23548;&#33268;&#27425;&#20248;&#30340;&#39044;&#27979;&#27169;&#22411;&#36873;&#25321;&#29575;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#29616;&#26377;&#20027;&#35201;CATE&#38598;&#25104;&#26041;&#27861;&#30340;&#36951;&#25022;&#29575;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21452;&#37325;&#40065;&#26834;&#25439;&#22833;&#30340;Q&#38598;&#25104;&#30340;&#26032;&#30340;CATE&#27169;&#22411;&#38598;&#25104;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#34920;&#26126;&#65292;&#22240;&#26524;Q&#38598;&#25104;&#22312;&#39044;&#27979;&#27169;&#22411;&#36873;&#25321;&#30340;&#36951;&#25022;&#29575;&#19978;&#36798;&#21040;&#20102;&#32479;&#35745;&#19978;&#30340;&#26368;&#20248;&#20540;&#20026;$\frac{\log(M)}{n}$&#65288;&#20854;&#20013;$M$&#20026;&#27169;&#22411;&#25968;&#65292;$n$&#20026;&#26679;&#26412;&#25968;&#65289;&#65292;&#21152;&#19978;&#39640;&#38454;&#20272;&#35745;&#35823;&#24046;&#39033;
&lt;/p&gt;
&lt;p&gt;
Accurate estimation of conditional average treatment effects (CATE) is at the core of personalized decision making. While there is a plethora of models for CATE estimation, model selection is a nontrivial task, due to the fundamental problem of causal inference. Recent empirical work provides evidence in favor of proxy loss metrics with double robust properties and in favor of model ensembling. However, theoretical understanding is lacking. Direct application of prior theoretical work leads to suboptimal oracle model selection rates due to the non-convexity of the model selection problem. We provide regret rates for the major existing CATE ensembling approaches and propose a new CATE model ensembling approach based on Q-aggregation using the doubly robust loss. Our main result shows that causal Q-aggregation achieves statistically optimal oracle model selection regret rates of $\frac{\log(M)}{n}$ (with $M$ models and $n$ samples), with the addition of higher-order estimation error term
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#35889;&#26041;&#27861;&#30340;&#20248;&#21270;&#26041;&#26696;&#65292;&#29992;&#20110;&#35299;&#20915;&#22312;&#38750;&#20984;&#24615;&#38382;&#39064;&#19979;&#23398;&#29983;&#32593;&#32476;&#19982;&#25945;&#24072;&#32593;&#32476;&#20043;&#38388;&#23384;&#22312;&#30340;&#19981;&#21464;&#23376;&#32593;&#32476;&#30340;&#35782;&#21035;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.12612</link><description>&lt;p&gt;
&#23398;&#29983;&#22914;&#20309;&#25104;&#20026;&#25945;&#24072;&#65306;&#36890;&#36807;&#35889;&#26041;&#27861;&#23398;&#20064;&#21644;&#36951;&#24536;
&lt;/p&gt;
&lt;p&gt;
How a student becomes a teacher: learning and forgetting through Spectral methods. (arXiv:2310.12612v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.12612
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#35889;&#26041;&#27861;&#30340;&#20248;&#21270;&#26041;&#26696;&#65292;&#29992;&#20110;&#35299;&#20915;&#22312;&#38750;&#20984;&#24615;&#38382;&#39064;&#19979;&#23398;&#29983;&#32593;&#32476;&#19982;&#25945;&#24072;&#32593;&#32476;&#20043;&#38388;&#23384;&#22312;&#30340;&#19981;&#21464;&#23376;&#32593;&#32476;&#30340;&#35782;&#21035;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29702;&#35770;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#23398;&#29983;-&#25945;&#24072;&#27169;&#22411;&#24120;&#34987;&#29992;&#20316;&#29616;&#23454;&#29983;&#27963;&#20013;&#25945;&#23398;&#30340;&#26377;&#25928;&#38544;&#21947;&#12290;&#24403;&#23398;&#29983;&#32593;&#32476;&#30456;&#23545;&#20110;&#25945;&#24072;&#32593;&#32476;&#36807;&#24230;&#21442;&#25968;&#21270;&#26102;&#65292;&#19978;&#36848;&#27169;&#22411;&#23588;&#20026;&#30456;&#20851;&#12290;&#22312;&#36825;&#31181;&#25805;&#20316;&#26465;&#20214;&#19979;&#65292;&#24456;&#23481;&#26131;&#25512;&#27979;&#23398;&#29983;&#22788;&#29702;&#32473;&#23450;&#20219;&#21153;&#30340;&#33021;&#21147;&#26368;&#32456;&#21487;&#33021;&#20648;&#23384;&#22312;&#25972;&#20010;&#32593;&#32476;&#30340;&#19968;&#20010;&#23376;&#37096;&#20998;&#20013;&#12290;&#26681;&#25454;&#36866;&#24403;&#30340;&#25351;&#26631;&#65292;&#36825;&#20010;&#23376;&#37096;&#20998;&#24212;&#35813;&#22312;&#19968;&#23450;&#31243;&#24230;&#19978;&#31867;&#20284;&#20110;&#20923;&#32467;&#30340;&#25945;&#24072;&#32467;&#26500;&#65292;&#24182;&#19988;&#22312;&#23398;&#29983;&#20505;&#36873;&#32593;&#32476;&#30340;&#19981;&#21516;&#26550;&#26500;&#19979;&#36817;&#20284;&#19981;&#21464;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#25152;&#30740;&#31350;&#38382;&#39064;&#30340;&#22266;&#26377;&#38750;&#20984;&#24615;&#31243;&#24230;&#65292;&#26368;&#26032;&#30340;&#20256;&#32479;&#23398;&#20064;&#25216;&#26415;&#26080;&#27861;&#35782;&#21035;&#36825;&#26679;&#19968;&#20010;&#19981;&#21464;&#23376;&#32593;&#32476;&#30340;&#23384;&#22312;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#37319;&#21462;&#20102;&#19968;&#20010;&#26681;&#26412;&#19981;&#21516;&#30340;&#20248;&#21270;&#26041;&#26696;&#65292;&#35813;&#26041;&#26696;&#24314;&#31435;&#22312;&#35889;&#34920;&#31034;&#30340;&#22522;&#30784;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
In theoretical ML, the teacher-student paradigm is often employed as an effective metaphor for real-life tuition. The above scheme proves particularly relevant when the student network is overparameterized as compared to the teacher network. Under these operating conditions, it is tempting to speculate that the student ability to handle the given task could be eventually stored in a sub-portion of the whole network. This latter should be to some extent reminiscent of the frozen teacher structure, according to suitable metrics, while being approximately invariant across different architectures of the student candidate network. Unfortunately, state-of-the-art conventional learning techniques could not help in identifying the existence of such an invariant subnetwork, due to the inherent degree of non-convexity that characterizes the examined problem. In this work, we take a leap forward by proposing a radically different optimization scheme which builds on a spectral representation of th
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23637;&#31034;&#20102;&#22312;&#20984;&#38750;&#20984;&#26694;&#26550;&#20013;&#65292;&#36890;&#36807;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#27491;&#21017;&#21270;&#22120;&#65292;&#21487;&#20197;&#23454;&#29616;&#25910;&#25947;&#27491;&#21017;&#21270;&#65307;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24369;&#20984;&#36755;&#20837;&#31070;&#32463;&#32593;&#32476;&#26500;&#24314;&#65292;&#35299;&#20915;&#20102;&#20043;&#21069;&#23545;&#25239;&#24615;&#26041;&#27861;&#30340;&#25968;&#20540;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.05812</link><description>&lt;p&gt;
&#21487;&#35777;&#25910;&#25947;&#30340;&#25968;&#25454;&#39537;&#21160;&#20984;&#38750;&#20984;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
Provably Convergent Data-Driven Convex-Nonconvex Regularization. (arXiv:2310.05812v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05812
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23637;&#31034;&#20102;&#22312;&#20984;&#38750;&#20984;&#26694;&#26550;&#20013;&#65292;&#36890;&#36807;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#27491;&#21017;&#21270;&#22120;&#65292;&#21487;&#20197;&#23454;&#29616;&#25910;&#25947;&#27491;&#21017;&#21270;&#65307;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24369;&#20984;&#36755;&#20837;&#31070;&#32463;&#32593;&#32476;&#26500;&#24314;&#65292;&#35299;&#20915;&#20102;&#20043;&#21069;&#23545;&#25239;&#24615;&#26041;&#27861;&#30340;&#25968;&#20540;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#27491;&#21017;&#21270;&#22120;&#26159;&#35299;&#20915;&#36870;&#38382;&#39064;&#30340;&#26032;&#20852;&#33539;&#24335;&#12290;&#36825;&#23548;&#33268;&#20102;&#39640;&#36136;&#37327;&#30340;&#32467;&#26524;&#65292;&#20294;&#24448;&#24448;&#26080;&#27861;&#25552;&#20379;&#21487;&#35777;&#26126;&#30340;&#20445;&#35777;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#20984;&#38750;&#20984;&#65288;CNC&#65289;&#26694;&#26550;&#20013;&#20986;&#29616;&#20102;&#33391;&#23450;&#20041;&#24615;&#21644;&#25910;&#25947;&#24615;&#27491;&#21017;&#21270;&#30340;&#21407;&#22240;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#24369;&#20984;&#36755;&#20837;&#31070;&#32463;&#32593;&#32476;&#65288;IWCNN&#65289;&#26500;&#24314;&#65292;&#23558;&#23398;&#20064;&#23545;&#25239;&#24615;&#27491;&#21017;&#21270;&#26041;&#27861;&#36866;&#24212;&#21040;CNC&#26694;&#26550;&#20013;&#12290;&#20174;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20811;&#26381;&#20102;&#20043;&#21069;&#23545;&#25239;&#24615;&#26041;&#27861;&#30340;&#25968;&#20540;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
An emerging new paradigm for solving inverse problems is via the use of deep learning to learn a regularizer from data. This leads to high-quality results, but often at the cost of provable guarantees. In this work, we show how well-posedness and convergent regularization arises within the convex-nonconvex (CNC) framework for inverse problems. We introduce a novel input weakly convex neural network (IWCNN) construction to adapt the method of learned adversarial regularization to the CNC framework. Empirically we show that our method overcomes numerical issues of previous adversarial methods.
&lt;/p&gt;</description></item><item><title>&#25968;&#25454;&#39537;&#21160;&#30340;&#26426;&#22120;&#23398;&#20064;&#22825;&#27668;&#39044;&#25253;&#27169;&#22411;&#19981;&#20855;&#22791;&#20256;&#32479;&#22522;&#20110;&#29289;&#29702;&#30340;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#21644;&#29289;&#29702;&#19968;&#33268;&#24615;&#65292;&#23427;&#20204;&#22312;&#39044;&#27979;&#25216;&#33021;&#19978;&#30340;&#20248;&#21183;&#24456;&#22823;&#31243;&#24230;&#19978;&#21487;&#20197;&#24402;&#22240;&#20110;&#36825;&#20123;&#29305;&#27530;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.08473</link><description>&lt;p&gt;
&#25968;&#25454;&#39537;&#21160;&#22825;&#27668;&#39044;&#25253;&#27169;&#22411;&#30340;&#23616;&#38480;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the limitations of data-driven weather forecasting models. (arXiv:2309.08473v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.08473
&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#39537;&#21160;&#30340;&#26426;&#22120;&#23398;&#20064;&#22825;&#27668;&#39044;&#25253;&#27169;&#22411;&#19981;&#20855;&#22791;&#20256;&#32479;&#22522;&#20110;&#29289;&#29702;&#30340;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#21644;&#29289;&#29702;&#19968;&#33268;&#24615;&#65292;&#23427;&#20204;&#22312;&#39044;&#27979;&#25216;&#33021;&#19978;&#30340;&#20248;&#21183;&#24456;&#22823;&#31243;&#24230;&#19978;&#21487;&#20197;&#24402;&#22240;&#20110;&#36825;&#20123;&#29305;&#27530;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#22312;&#22825;&#27668;&#21644;&#27668;&#20505;&#39044;&#27979;&#39046;&#22495;&#20135;&#29983;&#20102;&#28145;&#36828;&#24433;&#21709;&#12290;&#26368;&#36817;&#30340;&#21457;&#23637;&#26159;&#25968;&#25454;&#39537;&#21160;&#30340;&#26426;&#22120;&#23398;&#20064;&#39044;&#27979;&#27169;&#22411;&#30340;&#20986;&#29616;&#65292;&#23427;&#20204;&#36890;&#24120;&#22768;&#31216;&#27604;&#20256;&#32479;&#30340;&#22522;&#20110;&#29289;&#29702;&#30340;&#27169;&#22411;&#20855;&#26377;&#26356;&#39640;&#30340;&#24615;&#33021;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#24403;&#21069;&#19968;&#20195;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20043;&#19968;Pangu-Weather&#30340;&#39044;&#27979;&#26041;&#38754;&#30340;&#19968;&#20123;&#38382;&#39064;&#65292;&#37325;&#28857;&#20851;&#27880;&#39044;&#27979;&#30340;&#20934;&#30830;&#24615;&#21644;&#29289;&#29702;&#19968;&#33268;&#24615;&#20197;&#21450;&#36825;&#20123;&#29305;&#24449;&#19982;&#24863;&#30693;&#39044;&#27979;&#24615;&#33021;&#20043;&#38388;&#30340;&#20851;&#31995;&#12290;&#20027;&#35201;&#32467;&#35770;&#26159;Pangu-Weather&#30340;&#39044;&#27979;&#65292;&#20197;&#21450;&#31867;&#20284;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#19981;&#20855;&#22791;&#22522;&#20110;&#29289;&#29702;&#30340;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#21644;&#29289;&#29702;&#19968;&#33268;&#24615;&#65292;&#32780;&#23427;&#20204;&#22312;&#20256;&#32479;&#30340;&#30830;&#23450;&#24615;&#39044;&#27979;&#25216;&#33021;&#25351;&#26631;&#19978;&#30340;&#20248;&#21183;&#24456;&#22823;&#31243;&#24230;&#19978;&#21487;&#20197;&#24402;&#22240;&#20110;&#36825;&#20123;&#29305;&#27530;&#24615;&#12290;&#19982;&#20854;&#20182;&#24403;&#21069;&#30340;&#21518;&#22788;&#29702;&#25216;&#26415;&#31867;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;
As in many other areas of engineering and applied science, Machine Learning (ML) is having a profound impact in the domain of Weather and Climate Prediction. A very recent development in this area has been the emergence of fully data-driven ML prediction models which routinely claim superior performance to that of traditional physics-based models. In this work, we examine some aspects of the forecasts produced by an exemplar of the current generation of ML models, Pangu-Weather, with a focus on the fidelity and physical consistency of those forecasts and how these characteristics relate to perceived forecast performance. The main conclusion is that Pangu-Weather forecasts, and by extension those of similar ML models, do not have the fidelity and physical consistency of physics-based models and their advantage in accuracy on traditional deterministic metrics of forecast skill can be attributed, to a large extent, to these peculiarities. Similarly to other current post-processing technol
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#24773;&#22659;&#36172;&#21338;&#35774;&#32622;&#30340;&#26032;&#22411;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#36172;&#21338;&#31639;&#27861;&#65292;&#20855;&#26377;&#31616;&#21333;&#21644;&#32047;&#31215;&#36951;&#25022;&#26368;&#23567;&#21270;&#30340;&#20248;&#21183;&#65292;&#24182;&#21487;&#33258;&#36866;&#24212;&#27169;&#22411;&#38169;&#35823;&#35268;&#33539;&#21644;&#36830;&#32493;&#33218;&#35774;&#32622;&#12290;&#35813;&#31639;&#27861;&#21033;&#29992;"&#19968;&#33268;&#33218;&#38598;"&#65288;CAS&#65289;&#26469;&#25552;&#20379;&#22312;&#27599;&#20010;&#24773;&#22659;&#19979;&#22218;&#25324;&#24773;&#22659;&#29305;&#23450;&#30340;&#26368;&#20339;&#33218;&#30340;&#19968;&#32452;&#33218;&#65292;&#36328;&#36234;&#24773;&#22659;&#20998;&#24067;&#12290;&#36825;&#31687;&#35770;&#25991;&#23545;&#31616;&#21333;&#21644;&#32047;&#31215;&#36951;&#25022;&#20445;&#35777;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#27491;&#38754;&#32467;&#26524;&#65292;&#21516;&#26102;&#20063;&#25581;&#31034;&#20102;&#26080;&#27861;&#23454;&#29616;&#23454;&#20363;&#20381;&#36182;&#24615;&#30340;&#31616;&#21333;&#36951;&#25022;&#20445;&#35777;&#30340;&#28040;&#26497;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2307.02108</link><description>&lt;p&gt;
&#27604;&#20363;&#21709;&#24212;&#65306;&#29992;&#20110;&#31616;&#21333;&#21644;&#32047;&#31215;&#36951;&#25022;&#26368;&#23567;&#21270;&#30340;&#24773;&#22659;&#36172;&#21338;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Proportional Response: Contextual Bandits for Simple and Cumulative Regret Minimization. (arXiv:2307.02108v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.02108
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#24773;&#22659;&#36172;&#21338;&#35774;&#32622;&#30340;&#26032;&#22411;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#36172;&#21338;&#31639;&#27861;&#65292;&#20855;&#26377;&#31616;&#21333;&#21644;&#32047;&#31215;&#36951;&#25022;&#26368;&#23567;&#21270;&#30340;&#20248;&#21183;&#65292;&#24182;&#21487;&#33258;&#36866;&#24212;&#27169;&#22411;&#38169;&#35823;&#35268;&#33539;&#21644;&#36830;&#32493;&#33218;&#35774;&#32622;&#12290;&#35813;&#31639;&#27861;&#21033;&#29992;"&#19968;&#33268;&#33218;&#38598;"&#65288;CAS&#65289;&#26469;&#25552;&#20379;&#22312;&#27599;&#20010;&#24773;&#22659;&#19979;&#22218;&#25324;&#24773;&#22659;&#29305;&#23450;&#30340;&#26368;&#20339;&#33218;&#30340;&#19968;&#32452;&#33218;&#65292;&#36328;&#36234;&#24773;&#22659;&#20998;&#24067;&#12290;&#36825;&#31687;&#35770;&#25991;&#23545;&#31616;&#21333;&#21644;&#32047;&#31215;&#36951;&#25022;&#20445;&#35777;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#27491;&#38754;&#32467;&#26524;&#65292;&#21516;&#26102;&#20063;&#25581;&#31034;&#20102;&#26080;&#27861;&#23454;&#29616;&#23454;&#20363;&#20381;&#36182;&#24615;&#30340;&#31616;&#21333;&#36951;&#25022;&#20445;&#35777;&#30340;&#28040;&#26497;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21307;&#30103;&#20445;&#20581;&#21644;&#30005;&#23376;&#21830;&#21153;&#31561;&#39046;&#22495;&#65292;&#31616;&#21333;&#36951;&#25022;&#26368;&#23567;&#21270;&#26159;&#23398;&#20064;&#26368;&#20339;&#27835;&#30103;&#20998;&#37197;&#31574;&#30053;&#30340;&#20851;&#38190;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#24773;&#22659;&#36172;&#21338;&#35774;&#32622;&#20013;&#30340;&#31616;&#21333;&#36951;&#25022;&#26368;&#23567;&#21270;&#38382;&#39064;&#20173;&#26410;&#20805;&#20998;&#30740;&#31350;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#36172;&#21338;&#31639;&#27861;&#26063;&#65292;&#38024;&#23545;&#38543;&#26426;&#24773;&#22659;&#36172;&#21338;&#35774;&#32622;&#65292;&#22312;&#32047;&#31215;&#36951;&#25022;&#26368;&#23567;&#21270;&#65288;&#20855;&#26377;&#36817;&#20046;&#26368;&#20248;&#30340;&#26497;&#23567;&#26497;&#22823;&#20445;&#35777;&#65289;&#21644;&#31616;&#21333;&#36951;&#25022;&#26368;&#23567;&#21270;&#65288;&#20855;&#26377;SOTA&#20445;&#35777;&#65289;&#26041;&#38754;&#20855;&#26377;&#28789;&#27963;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#23545;&#27169;&#22411;&#38169;&#35823;&#35268;&#33539;&#36827;&#34892;&#33258;&#36866;&#24212;&#65292;&#24182;&#25193;&#23637;&#21040;&#36830;&#32493;&#33218;&#35774;&#32622;&#12290;&#36825;&#20123;&#20248;&#21183;&#26469;&#33258;&#20110;&#26500;&#24314;&#21644;&#20381;&#36182;&#20110;&#8220;&#19968;&#33268;&#33218;&#38598;&#8221;&#65288;CAS&#65289;&#65292;CAS&#22312;&#27599;&#20010;&#24773;&#22659;&#19979;&#25552;&#20379;&#19968;&#32452;&#33218;&#65292;&#36825;&#20123;&#33218;&#20197;&#19968;&#23450;&#30340;&#27010;&#29575;&#22218;&#25324;&#20102;&#24773;&#22659;&#29305;&#23450;&#30340;&#26368;&#20339;&#33218;&#65292;&#36328;&#36234;&#20102;&#24773;&#22659;&#20998;&#24067;&#12290;&#25105;&#20204;&#20851;&#20110;&#31616;&#21333;&#21644;&#32047;&#31215;&#36951;&#25022;&#20445;&#35777;&#30340;&#31215;&#26497;&#32467;&#26524;&#19982;&#19968;&#20010;&#28040;&#26497;&#32467;&#26524;&#24418;&#25104;&#23545;&#27604;&#65292;&#21518;&#32773;&#34920;&#26126;&#19968;&#20010;&#31639;&#27861;&#26080;&#27861;&#23454;&#29616;&#23454;&#20363;&#20381;&#36182;&#24615;&#30340;&#31616;&#21333;&#36951;&#25022;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Simple regret minimization is a critical problem in learning optimal treatment assignment policies across various domains, including healthcare and e-commerce. However, it remains understudied in the contextual bandit setting. We propose a new family of computationally efficient bandit algorithms for the stochastic contextual bandit settings, with the flexibility to be adapted for cumulative regret minimization (with near-optimal minimax guarantees) and simple regret minimization (with SOTA guarantees). Furthermore, our algorithms adapt to model misspecification and extend to the continuous arm settings. These advantages come from constructing and relying on "conformal arm sets" (CASs), which provide a set of arms at every context that encompass the context-specific optimal arm with some probability across the context distribution. Our positive results on simple and cumulative regret guarantees are contrasted by a negative result, which shows that an algorithm can't achieve instance-de
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26368;&#20248;&#36816;&#36755;&#21644;&#21464;&#20998;&#25512;&#26029;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36335;&#24452;&#31354;&#38388;&#25955;&#24230;&#30340;&#37319;&#26679;&#21644;&#29983;&#25104;&#24314;&#27169;&#26694;&#26550;&#12290;&#36890;&#36807;&#24320;&#21457;&#26032;&#39062;&#30340;&#22522;&#20110;&#24471;&#20998;&#30340;&#22238;&#28779;&#27969;&#25216;&#26415;&#21644;&#27491;&#21017;&#21270;&#30340;&#36845;&#20195;&#27604;&#20363;&#25311;&#21512;&#30446;&#26631;&#65292;&#26412;&#25991;&#23637;&#31034;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#28508;&#21147;&#12290;</title><link>http://arxiv.org/abs/2307.01050</link><description>&lt;p&gt;
&#36816;&#36755;&#12289;&#21464;&#20998;&#25512;&#26029;&#21644;&#25193;&#25955;&#65306;&#24212;&#29992;&#20110;&#22238;&#28779;&#27969;&#21644;&#34203;&#23450;&#35860;&#26725;&#30340;&#35770;&#25991;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Transport, Variational Inference and Diffusions: with Applications to Annealed Flows and Schr\"odinger Bridges. (arXiv:2307.01050v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.01050
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26368;&#20248;&#36816;&#36755;&#21644;&#21464;&#20998;&#25512;&#26029;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36335;&#24452;&#31354;&#38388;&#25955;&#24230;&#30340;&#37319;&#26679;&#21644;&#29983;&#25104;&#24314;&#27169;&#26694;&#26550;&#12290;&#36890;&#36807;&#24320;&#21457;&#26032;&#39062;&#30340;&#22522;&#20110;&#24471;&#20998;&#30340;&#22238;&#28779;&#27969;&#25216;&#26415;&#21644;&#27491;&#21017;&#21270;&#30340;&#36845;&#20195;&#27604;&#20363;&#25311;&#21512;&#30446;&#26631;&#65292;&#26412;&#25991;&#23637;&#31034;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#26368;&#20248;&#36816;&#36755;&#19982;&#21464;&#20998;&#25512;&#26029;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#37325;&#28857;&#30740;&#31350;&#20102;&#27491;&#21521;&#21644;&#21453;&#21521;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#20197;&#21450;Girsanov&#21464;&#25442;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#36335;&#24452;&#31354;&#38388;&#25955;&#24230;&#30340;&#37319;&#26679;&#21644;&#29983;&#25104;&#24314;&#27169;&#30340;&#21407;&#21017;&#24615;&#21644;&#31995;&#32479;&#24615;&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#26368;&#32456;&#21457;&#23637;&#20986;&#19968;&#20010;&#26032;&#39062;&#30340;&#22522;&#20110;&#24471;&#20998;&#30340;&#22238;&#28779;&#27969;&#25216;&#26415;&#65288;&#19982;&#32479;&#35745;&#29289;&#29702;&#20013;&#30340;Jarzynski&#21644;Crooks&#24658;&#31561;&#24335;&#26377;&#20851;&#65289;&#21644;&#19968;&#20010;&#27491;&#21017;&#21270;&#30340;&#36845;&#20195;&#27604;&#20363;&#25311;&#21512;&#65288;IPF&#65289;&#22411;&#30446;&#26631;&#65292;&#19981;&#21516;&#20110;&#26631;&#20934;IPF&#30340;&#39034;&#24207;&#24615;&#12290;&#36890;&#36807;&#19968;&#31995;&#21015;&#30340;&#29983;&#25104;&#24314;&#27169;&#31034;&#20363;&#21644;&#22522;&#20110;&#21452;&#20117;&#30340;&#31232;&#26377;&#20107;&#20214;&#20219;&#21153;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#25552;&#26041;&#27861;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper explores the connections between optimal transport and variational inference, with a focus on forward and reverse time stochastic differential equations and Girsanov transformations.We present a principled and systematic framework for sampling and generative modelling centred around divergences on path space. Our work culminates in the development of a novel score-based annealed flow technique (with connections to Jarzynski and Crooks identities from statistical physics) and a regularised iterative proportional fitting (IPF)-type objective, departing from the sequential nature of standard IPF. Through a series of generative modelling examples and a double-well-based rare event task, we showcase the potential of the proposed methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#31639;&#27861;&#65292;&#29992;&#20110;&#23485;&#26494;Pareto&#38598;&#30340;&#35782;&#21035;&#65292;&#36890;&#36807;&#25918;&#26494;&#31574;&#30053;&#26469;&#20943;&#23569;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#30340;&#33391;&#22909;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2307.00424</link><description>&lt;p&gt;
&#23485;&#26494;Pareto&#38598;&#35782;&#21035;&#30340;&#33258;&#36866;&#24212;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Adaptive Algorithms for Relaxed Pareto Set Identification. (arXiv:2307.00424v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.00424
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#31639;&#27861;&#65292;&#29992;&#20110;&#23485;&#26494;Pareto&#38598;&#30340;&#35782;&#21035;&#65292;&#36890;&#36807;&#25918;&#26494;&#31574;&#30053;&#26469;&#20943;&#23569;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#30340;&#33391;&#22909;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;&#22312;&#22810;&#30446;&#26631;&#22810;&#33218;&#36172;&#21338;&#26426;&#27169;&#22411;&#20013;&#22266;&#23450;&#32622;&#20449;&#24230;&#19979;&#30340;Pareto&#26368;&#20248;&#38598;&#21512;&#30340;&#35782;&#21035;&#38382;&#39064;&#12290;&#30001;&#20110;&#20934;&#30830;&#35782;&#21035;Pareto&#38598;&#21512;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#21487;&#33021;&#38750;&#24120;&#22823;&#65292;&#22240;&#27492;&#30740;&#31350;&#20102;&#20801;&#35768;&#36755;&#20986;&#19968;&#20123;&#39069;&#22806;&#36817;&#20284;&#26368;&#20248;&#33218;&#30340;&#25918;&#26494;&#31574;&#30053;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36824;&#35299;&#20915;&#20102;&#20854;&#20182;&#20801;&#35768;&#35782;&#21035;Pareto&#38598;&#21512;&#30340;&#30456;&#20851;&#23376;&#38598;&#30340;&#25918;&#26494;&#31574;&#30053;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#33258;&#36866;&#24212;Pareto&#25506;&#32034;&#30340;&#21333;&#19968;&#25277;&#26679;&#31574;&#30053;&#65292;&#21487;&#20197;&#19982;&#19981;&#21516;&#30340;&#20572;&#27490;&#35268;&#21017;&#32467;&#21512;&#20351;&#29992;&#65292;&#20197;&#32771;&#34385;Pareto&#38598;&#21512;&#35782;&#21035;&#38382;&#39064;&#30340;&#19981;&#21516;&#25918;&#26494;&#31574;&#30053;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#36825;&#20123;&#19981;&#21516;&#32452;&#21512;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24182;&#29305;&#21035;&#37327;&#21270;&#20102;&#22312;&#23547;&#25214;&#35782;&#21035;&#26368;&#22810;$k$&#20010;Pareto&#26368;&#20248;&#33218;&#26102;&#26679;&#26412;&#22797;&#26434;&#24230;&#30340;&#20943;&#23569;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#33258;&#36866;&#24212;Pareto&#25506;&#32034;&#22312;&#19968;&#20010;&#30495;&#23454;&#22330;&#26223;&#20013;&#30340;&#33391;&#22909;&#23454;&#38469;&#24615;&#33021;&#65292;&#20854;&#20013;&#25105;&#20204;&#33258;&#36866;&#24212;&#22320;&#25506;&#32034;&#20102;&#20960;&#31181;&#30123;&#33495;&#25509;&#31181;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we revisit the fixed-confidence identification of the Pareto optimal set in a multi-objective multi-armed bandit model. As the sample complexity to identify the exact Pareto set can be very large, a relaxation allowing to output some additional near-optimal arms has been studied. In this work we also tackle alternative relaxations that allow instead to identify a relevant subset of the Pareto set. Notably, we propose a single sampling strategy, called Adaptive Pareto Exploration, that can be used in conjunction with different stopping rules to take into account different relaxations of the Pareto Set Identification problem. We analyze the sample complexity of these different combinations, quantifying in particular the reduction in sample complexity that occurs when one seeks to identify at most $k$ Pareto optimal arms. We showcase the good practical performance of Adaptive Pareto Exploration on a real-world scenario, in which we adaptively explore several vaccination stra
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#27599;&#20010;&#21608;&#26399;&#23558;&#19968;&#21333;&#20301;&#21487;&#20998;&#36164;&#28304;&#20998;&#37197;&#21040;&#22810;&#20010;&#33218;&#19978;&#30340;&#38382;&#39064;&#65292;&#33218;&#19978;&#30340;&#22870;&#21169;&#26159;&#26410;&#30693;&#21644;&#38543;&#26426;&#30340;&#65292;&#32780;&#19988;&#19982;&#20998;&#37197;&#30340;&#36164;&#28304;&#25104;&#27604;&#20363;&#65292;&#32780;&#26041;&#24046;&#19982;&#20998;&#37197;&#36164;&#28304;&#30340;&#38454;&#25968;&#25104;&#27604;&#20363;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#20004;&#31181;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#19981;&#21516;&#38454;&#25968;&#19979;&#30340;&#26368;&#20248;&#26377;&#30028;&#21644;&#26080;&#30028;&#36951;&#25022;&#65292;&#32467;&#26524;&#34920;&#26126;&#22312;&#38454;&#25968;&#20026;1/2&#26102;&#23384;&#22312;&#30456;&#21464;&#29616;&#35937;&#12290;</title><link>http://arxiv.org/abs/2306.16578</link><description>&lt;p&gt;
&#22312;&#20855;&#26377;&#26410;&#30693;&#21644;&#38543;&#26426;&#22870;&#21169;&#30340;&#33218;&#19978;&#20998;&#37197;&#21487;&#20998;&#36164;&#28304;
&lt;/p&gt;
&lt;p&gt;
Allocating Divisible Resources on Arms with Unknown and Random Rewards. (arXiv:2306.16578v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.16578
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#27599;&#20010;&#21608;&#26399;&#23558;&#19968;&#21333;&#20301;&#21487;&#20998;&#36164;&#28304;&#20998;&#37197;&#21040;&#22810;&#20010;&#33218;&#19978;&#30340;&#38382;&#39064;&#65292;&#33218;&#19978;&#30340;&#22870;&#21169;&#26159;&#26410;&#30693;&#21644;&#38543;&#26426;&#30340;&#65292;&#32780;&#19988;&#19982;&#20998;&#37197;&#30340;&#36164;&#28304;&#25104;&#27604;&#20363;&#65292;&#32780;&#26041;&#24046;&#19982;&#20998;&#37197;&#36164;&#28304;&#30340;&#38454;&#25968;&#25104;&#27604;&#20363;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#20004;&#31181;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#19981;&#21516;&#38454;&#25968;&#19979;&#30340;&#26368;&#20248;&#26377;&#30028;&#21644;&#26080;&#30028;&#36951;&#25022;&#65292;&#32467;&#26524;&#34920;&#26126;&#22312;&#38454;&#25968;&#20026;1/2&#26102;&#23384;&#22312;&#30456;&#21464;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#19968;&#20010;&#20915;&#31574;&#32773;&#22312;&#27599;&#20010;&#21608;&#26399;&#23558;&#19968;&#20010;&#21487;&#20877;&#29983;&#21644;&#21487;&#20998;&#36164;&#28304;&#20998;&#37197;&#21040;&#22810;&#20010;&#33218;&#19978;&#12290;&#36825;&#20123;&#33218;&#20855;&#26377;&#26410;&#30693;&#21644;&#38543;&#26426;&#30340;&#22870;&#21169;&#65292;&#20854;&#22343;&#20540;&#19982;&#20998;&#37197;&#30340;&#36164;&#28304;&#25104;&#27604;&#20363;&#65292;&#26041;&#24046;&#19982;&#20998;&#37197;&#36164;&#28304;&#30340;&#38454;&#25968;$b$&#25104;&#27604;&#20363;&#12290;&#29305;&#21035;&#22320;&#65292;&#22914;&#26524;&#20915;&#31574;&#32773;&#22312;&#19968;&#20010;&#21608;&#26399;&#23558;&#36164;&#28304;$A_i$&#20998;&#37197;&#32473;&#33218;$i$&#65292;&#37027;&#20040;&#22870;&#21169;$Y_i$&#26159;$Y_i(A_i)=A_i\mu_i+A_i^b\xi_i$&#65292;&#20854;&#20013;$\mu_i$&#26159;&#26410;&#30693;&#30340;&#22343;&#20540;&#65292;&#22122;&#22768;$\xi_i$&#26159;&#29420;&#31435;&#19988;&#23376;&#39640;&#26031;&#30340;&#12290;&#24403;&#38454;&#25968;$b$&#20174;0&#21040;1&#21464;&#21270;&#26102;&#65292;&#35813;&#26694;&#26550;&#24179;&#28369;&#22320;&#36830;&#25509;&#20102;&#26631;&#20934;&#30340;&#38543;&#26426;&#22810;&#33218;&#36172;&#21338;&#26426;&#21644;&#24102;&#26377;&#23436;&#20840;&#21453;&#39304;&#30340;&#22312;&#32447;&#23398;&#20064;&#12290;&#25105;&#20204;&#35774;&#35745;&#20102;&#20004;&#31181;&#31639;&#27861;&#65292;&#23427;&#20204;&#23454;&#29616;&#20102;$b\in[0,1]$&#26102;&#30340;&#26368;&#20248;&#26377;&#30028;&#24046;&#21644;&#26080;&#30028;&#24046;&#30340;&#36951;&#25022;&#30028;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;$b=1/2$&#22788;&#30340;&#30456;&#21464;&#12290;&#29702;&#35770;&#32467;&#26524;&#20381;&#36182;&#20110;&#25105;&#20204;&#24320;&#21457;&#30340;&#19968;&#31181;&#26032;&#22411;&#27987;&#24230;&#19981;&#31561;&#24335;&#65292;&#23427;&#38480;&#21046;&#20102;&#23376;&#39640;&#26031;&#38543;&#26426;&#21464;&#37327;&#30340;&#32447;&#24615;&#32452;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a decision maker allocating one unit of renewable and divisible resource in each period on a number of arms. The arms have unknown and random rewards whose means are proportional to the allocated resource and whose variances are proportional to an order $b$ of the allocated resource. In particular, if the decision maker allocates resource $A_i$ to arm $i$ in a period, then the reward $Y_i$ is$Y_i(A_i)=A_i \mu_i+A_i^b \xi_{i}$, where $\mu_i$ is the unknown mean and the noise $\xi_{i}$ is independent and sub-Gaussian. When the order $b$ ranges from 0 to 1, the framework smoothly bridges the standard stochastic multi-armed bandit and online learning with full feedback. We design two algorithms that attain the optimal gap-dependent and gap-independent regret bounds for $b\in [0,1]$, and demonstrate a phase transition at $b=1/2$. The theoretical results hinge on a novel concentration inequality we have developed that bounds a linear combination of sub-Gaussian random variables w
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#23545;&#20110;&#36125;&#21494;&#26031;&#36172;&#21338;&#26426;&#30340;&#39318;&#20010;&#26377;&#38480;&#26102;&#38388;&#23545;&#25968;&#36951;&#25022;&#36793;&#30028;&#65292;&#24182;&#29992;&#20110;&#39640;&#26031;&#21644;&#32447;&#24615;&#36172;&#21338;&#26426;&#65292;&#20174;&#32780;&#38416;&#26126;&#20102;&#36125;&#21494;&#26031;&#35774;&#32622;&#20013;&#20808;&#39564;&#20215;&#20540;&#20197;&#21450;&#23545;$\tilde{O}(\sqrt{n})$&#30028;&#38480;&#30340;&#25913;&#21892;&#12290;</title><link>http://arxiv.org/abs/2306.09136</link><description>&lt;p&gt;
&#23545;&#25968;&#36125;&#21494;&#26031;&#36951;&#25022;&#36793;&#30028;
&lt;/p&gt;
&lt;p&gt;
Logarithmic Bayes Regret Bounds. (arXiv:2306.09136v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09136
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#23545;&#20110;&#36125;&#21494;&#26031;&#36172;&#21338;&#26426;&#30340;&#39318;&#20010;&#26377;&#38480;&#26102;&#38388;&#23545;&#25968;&#36951;&#25022;&#36793;&#30028;&#65292;&#24182;&#29992;&#20110;&#39640;&#26031;&#21644;&#32447;&#24615;&#36172;&#21338;&#26426;&#65292;&#20174;&#32780;&#38416;&#26126;&#20102;&#36125;&#21494;&#26031;&#35774;&#32622;&#20013;&#20808;&#39564;&#20215;&#20540;&#20197;&#21450;&#23545;$\tilde{O}(\sqrt{n})$&#30028;&#38480;&#30340;&#25913;&#21892;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20026;&#36125;&#21494;&#26031;&#36172;&#21338;&#26426;&#23548;&#20986;&#20102;&#39318;&#20010;&#26377;&#38480;&#26102;&#38388;&#23545;&#25968;&#36951;&#25022;&#36793;&#30028;&#12290;&#23545;&#20110;&#39640;&#26031;&#36172;&#21338;&#26426;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#19968;&#20010;$O(c_h \log^2 n)$&#30340;&#36793;&#30028;&#65292;&#20854;&#20013;$c_h$&#26159;&#19982;&#20808;&#39564;&#30456;&#20851;&#30340;&#24120;&#37327;&#12290;&#36825;&#19982;Lai&#65288;1987&#65289;&#30340;&#28176;&#36817;&#19979;&#38480;&#30456;&#21305;&#37197;&#12290;&#25105;&#20204;&#30340;&#35777;&#26126;&#19982;&#20808;&#21069;&#30340;&#24037;&#20316;&#26377;&#25152;&#19981;&#21516;&#65292;&#19988;&#31616;&#21333;&#19988;&#26222;&#36941;&#12290;&#20026;&#20102;&#26174;&#31034;&#19968;&#33324;&#24615;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#25216;&#26415;&#24212;&#29992;&#20110;&#32447;&#24615;&#36172;&#21338;&#26426;&#12290;&#25105;&#20204;&#30340;&#30028;&#38480;&#38416;&#26126;&#20102;&#36125;&#21494;&#26031;&#35774;&#32622;&#20013;&#20808;&#39564;&#30340;&#20215;&#20540;&#65292;&#26082;&#21487;&#20197;&#20316;&#20026;&#30446;&#26631;&#65292;&#20063;&#21487;&#20197;&#20316;&#20026;&#20256;&#36882;&#32473;&#23398;&#20064;&#32773;&#30340;&#38468;&#21152;&#20449;&#24687;&#12290;&#23427;&#20204;&#26174;&#30528;&#25913;&#21892;&#20102;&#29616;&#26377;&#30340;$\tilde{O}(\sqrt{n})$&#30028;&#38480;&#65292;&#23613;&#31649;&#23384;&#22312;&#19979;&#38480;&#65292;&#20294;&#24050;&#25104;&#20026;&#25991;&#29486;&#20013;&#30340;&#26631;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;
We derive the first finite-time logarithmic regret bounds for Bayesian bandits. For Gaussian bandits, we obtain a $O(c_h \log^2 n)$ bound, where $c_h$ is a prior-dependent constant. This matches the asymptotic lower bound of Lai (1987). Our proofs mark a technical departure from prior works, and are simple and general. To show generality, we apply our technique to linear bandits. Our bounds shed light on the value of the prior in the Bayesian setting, both in the objective and as a side information given to the learner. They significantly improve the $\tilde{O}(\sqrt{n})$ bounds, that despite the existing lower bounds, have become standard in the literature.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22686;&#24378;Hopfield-like&#31070;&#32463;&#32593;&#32476;&#24207;&#21015;&#35760;&#24518;&#27169;&#22411;&#30340;&#24207;&#21015;&#23481;&#37327;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#38750;&#32447;&#24615;&#30456;&#20114;&#20316;&#29992;&#39033;&#65292;&#26174;&#33879;&#20248;&#20110;&#20256;&#32479;Hopfield&#32593;&#32476;&#65292;&#21516;&#26102;&#20063;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#22238;&#24518;&#35268;&#21017;&#20197;&#22238;&#24518;&#36830;&#32493;&#30340;&#24207;&#21015;&#12290;</title><link>http://arxiv.org/abs/2306.04532</link><description>&lt;p&gt;
&#38271;&#24207;&#21015; Hopfield&#20869;&#23384;
&lt;/p&gt;
&lt;p&gt;
Long Sequence Hopfield Memory. (arXiv:2306.04532v2 [cs.NE] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.04532
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22686;&#24378;Hopfield-like&#31070;&#32463;&#32593;&#32476;&#24207;&#21015;&#35760;&#24518;&#27169;&#22411;&#30340;&#24207;&#21015;&#23481;&#37327;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#38750;&#32447;&#24615;&#30456;&#20114;&#20316;&#29992;&#39033;&#65292;&#26174;&#33879;&#20248;&#20110;&#20256;&#32479;Hopfield&#32593;&#32476;&#65292;&#21516;&#26102;&#20063;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#22238;&#24518;&#35268;&#21017;&#20197;&#22238;&#24518;&#36830;&#32493;&#30340;&#24207;&#21015;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24207;&#21015;&#35760;&#24518;&#26159;&#33258;&#28982;&#21644;&#20154;&#24037;&#26234;&#33021;&#30340;&#37325;&#35201;&#23646;&#24615;&#65292;&#23427;&#20351;&#20195;&#29702;&#33021;&#22815;&#32534;&#30721;&#12289;&#23384;&#20648;&#21644;&#26816;&#32034;&#22797;&#26434;&#30340;&#21050;&#28608;&#21644;&#34892;&#20026;&#24207;&#21015;&#12290;&#24050;&#32463;&#25552;&#20986;&#20102;&#35745;&#31639;&#27169;&#22411;&#65292;&#20854;&#20013;&#29992;&#26102;&#38388;&#38750;&#23545;&#31216;&#30340;Hebbian&#35268;&#21017;&#35757;&#32451;&#36882;&#24402;&#30340;Hopfield&#26679;&#31070;&#32463;&#32593;&#32476;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#32593;&#32476;&#30001;&#20110;&#35760;&#24518;&#20043;&#38388;&#30340;&#24178;&#25200;&#32780;&#20855;&#26377;&#26377;&#38480;&#30340;&#24207;&#21015;&#23481;&#37327;&#65288;&#23384;&#20648;&#24207;&#21015;&#30340;&#26368;&#22823;&#38271;&#24230;&#65289;&#12290;&#21463;&#23494;&#38598;&#20851;&#32852;&#35760;&#24518;&#30340;&#26368;&#26032;&#24037;&#20316;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#36890;&#36807;&#24341;&#20837;&#38750;&#32447;&#24615;&#30456;&#20114;&#20316;&#29992;&#39033;&#26469;&#25193;&#23637;&#36825;&#20123;&#27169;&#22411;&#30340;&#24207;&#21015;&#23481;&#37327;&#65292;&#22686;&#24378;&#27169;&#24335;&#20043;&#38388;&#30340;&#20998;&#31163;&#24615;&#12290;&#25105;&#20204;&#25512;&#23548;&#20986;&#24207;&#21015;&#23481;&#37327;&#19982;&#32593;&#32476;&#22823;&#23567;&#30340;&#26032;&#30340;&#26631;&#24230;&#23450;&#24459;&#65292;&#26174;&#33879;&#20248;&#20110;&#22522;&#20110;&#20256;&#32479;Hopfield&#32593;&#32476;&#30340;&#29616;&#26377;&#26631;&#24230;&#23450;&#24459;&#65292;&#24182;&#36890;&#36807;&#25968;&#20540;&#27169;&#25311;&#39564;&#35777;&#20102;&#36825;&#20123;&#29702;&#35770;&#32467;&#26524;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#24191;&#20041;&#20266;&#36870;&#35268;&#21017;&#26469;&#22238;&#24518;&#39640;&#24230;&#36830;&#32493;&#30340;&#24207;&#21015;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sequence memory is an essential attribute of natural and artificial intelligence that enables agents to encode, store, and retrieve complex sequences of stimuli and actions. Computational models of sequence memory have been proposed where recurrent Hopfield-like neural networks are trained with temporally asymmetric Hebbian rules. However, these networks suffer from limited sequence capacity (maximal length of the stored sequence) due to interference between the memories. Inspired by recent work on Dense Associative Memories, we expand the sequence capacity of these models by introducing a nonlinear interaction term, enhancing separation between the patterns. We derive novel scaling laws for sequence capacity with respect to network size, significantly outperforming existing scaling laws for models based on traditional Hopfield networks, and verify these theoretical results with numerical simulation. Moreover, we introduce a generalized pseudoinverse rule to recall sequences of highly 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#20855;&#26377;&#26410;&#30693;&#24178;&#39044;&#30340;&#38750;&#21442;&#25968;&#28508;&#22312;&#22240;&#26524;&#22270;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24314;&#31435;&#26465;&#20214;&#30830;&#23450;&#38750;&#21442;&#25968;&#28508;&#22312;&#22240;&#26524;&#22270;&#24182;&#20174;&#20013;&#37325;&#26500;&#12290;&#36825;&#31181;&#26041;&#27861;&#19981;&#38656;&#35201;&#21442;&#25968;&#20551;&#35774;&#65292;&#21487;&#29992;&#20110;&#35782;&#21035;&#27979;&#37327;&#27169;&#22411;&#20013;&#28508;&#22312;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2306.02899</link><description>&lt;p&gt;
&#23398;&#20064;&#20855;&#26377;&#26410;&#30693;&#24178;&#39044;&#30340;&#38750;&#21442;&#25968;&#28508;&#22312;&#22240;&#26524;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning nonparametric latent causal graphs with unknown interventions. (arXiv:2306.02899v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.02899
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#20855;&#26377;&#26410;&#30693;&#24178;&#39044;&#30340;&#38750;&#21442;&#25968;&#28508;&#22312;&#22240;&#26524;&#22270;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24314;&#31435;&#26465;&#20214;&#30830;&#23450;&#38750;&#21442;&#25968;&#28508;&#22312;&#22240;&#26524;&#22270;&#24182;&#20174;&#20013;&#37325;&#26500;&#12290;&#36825;&#31181;&#26041;&#27861;&#19981;&#38656;&#35201;&#21442;&#25968;&#20551;&#35774;&#65292;&#21487;&#29992;&#20110;&#35782;&#21035;&#27979;&#37327;&#27169;&#22411;&#20013;&#28508;&#22312;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#26410;&#30693;&#24178;&#39044;&#30340;&#28508;&#22312;&#31354;&#38388;&#24314;&#31435;&#26465;&#20214;&#65292;&#20197;&#30830;&#23450;&#38750;&#21442;&#25968;&#28508;&#22312;&#22240;&#26524;&#22270;&#24182;&#20174;&#20013;&#37325;&#26500;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#37325;&#28857;&#26159;&#27979;&#37327;&#27169;&#22411;&#20013;&#28508;&#22312;&#32467;&#26500;&#30340;&#35782;&#21035;&#65292;&#21363;&#22240;&#26524;&#22270;&#27169;&#22411;&#65292;&#22312;&#20854;&#20013;&#35266;&#23519;&#21464;&#37327;&#20043;&#38388;&#30340;&#20381;&#36182;&#24615;&#19982;&#28508;&#22312;&#34920;&#31034;&#20043;&#38388;&#30340;&#20381;&#36182;&#24615;&#30456;&#27604;&#65292;&#24182;&#19981;&#20570;&#20986;&#21442;&#25968;&#20551;&#35774;&#65292;&#22914;&#32447;&#24615;&#25110;&#39640;&#26031;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#19981;&#20551;&#35774;&#38544;&#34255;&#21464;&#37327;&#30340;&#25968;&#37327;&#24050;&#30693;&#65292;&#24182;&#19988;&#25105;&#20204;&#34920;&#26126;&#27599;&#20010;&#38544;&#34255;&#21464;&#37327;&#26368;&#22810;&#21482;&#38656;&#35201;&#19968;&#20010;&#26410;&#30693;&#30340;&#24178;&#39044;&#12290;&#36825;&#25193;&#23637;&#20102;&#26368;&#36817;&#20851;&#20110;&#20174;&#35266;&#27979;&#21644;&#24178;&#39044;&#20013;&#23398;&#20064;&#22240;&#26524;&#34920;&#31034;&#30340;&#24037;&#20316;&#12290;&#35777;&#26126;&#26159;&#24314;&#35774;&#24615;&#30340;&#65292;&#24182;&#24341;&#20837;&#20102;&#20004;&#20010;&#26032;&#30340;&#22270;&#24418;&#27010;&#24565;&#8212;&#8212;&#24819;&#35937;&#23376;&#38598;&#21644;&#23396;&#31435;&#36793;&#8212;&#8212;&#23427;&#20204;&#26412;&#36523;&#21487;&#33021;&#26159;&#26377;&#29992;&#30340;&#12290;&#20316;&#20026;&#19968;&#20010;&#29420;&#31435;&#30340;&#24863;&#20852;&#36259;&#30340;&#38382;&#39064;&#65292;&#35777;&#26126;&#36824;&#28041;&#21450;&#23545;&#36793;&#32536;&#23450;&#21521;&#38480;&#21046;&#30340;&#26032;&#30340;&#29305;&#24449;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
We establish conditions under which latent causal graphs are nonparametrically identifiable and can be reconstructed from unknown interventions in the latent space. Our primary focus is the identification of the latent structure in a measurement model, i.e. causal graphical models where dependence between observed variables is insignificant compared to dependence between latent representations, without making parametric assumptions such as linearity or Gaussianity. Moreover, we do not assume the number of hidden variables is known, and we show that at most one unknown intervention per hidden variable is needed. This extends a recent line of work on learning causal representations from observations and interventions. The proofs are constructive and introduce two new graphical concepts -- imaginary subsets and isolated edges -- that may be useful in their own right. As a matter of independent interest, the proofs also involve a novel characterization of the limits of edge orientations wi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21457;&#23637;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#26512;&#25216;&#26415;&#65292;&#24182;&#25512;&#24191;&#20102;&#24191;&#20041;&#24179;&#28369;&#24230;&#26465;&#20214;&#65292;&#20351;&#20984;&#21644;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#33719;&#24471;&#26356;&#24378;&#30340;&#32467;&#26524;&#12290;&#22312;&#35813;&#26465;&#20214;&#19979;&#65292;&#33719;&#24471;&#20102;&#65288;&#38543;&#26426;&#65289;&#26799;&#24230;&#19979;&#38477;&#21644;Nesterov&#21152;&#36895;&#26799;&#24230;&#26041;&#27861;&#30340;&#32463;&#20856;&#25910;&#25947;&#29575;&#12290;</title><link>http://arxiv.org/abs/2306.01264</link><description>&lt;p&gt;
&#24191;&#20041;&#24179;&#28369;&#24230;&#19979;&#30340;&#20984;&#21644;&#38750;&#20984;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Convex and Non-Convex Optimization under Generalized Smoothness. (arXiv:2306.01264v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01264
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21457;&#23637;&#20102;&#19968;&#31181;&#26032;&#30340;&#20998;&#26512;&#25216;&#26415;&#65292;&#24182;&#25512;&#24191;&#20102;&#24191;&#20041;&#24179;&#28369;&#24230;&#26465;&#20214;&#65292;&#20351;&#20984;&#21644;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#33719;&#24471;&#26356;&#24378;&#30340;&#32467;&#26524;&#12290;&#22312;&#35813;&#26465;&#20214;&#19979;&#65292;&#33719;&#24471;&#20102;&#65288;&#38543;&#26426;&#65289;&#26799;&#24230;&#19979;&#38477;&#21644;Nesterov&#21152;&#36895;&#26799;&#24230;&#26041;&#27861;&#30340;&#32463;&#20856;&#25910;&#25947;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32463;&#20856;&#30340;&#20984;&#21644;&#38750;&#20984;&#20248;&#21270;&#26041;&#27861;&#30340;&#20998;&#26512;&#36890;&#24120;&#38656;&#35201;&#26799;&#24230;&#30340;Lipshitz&#24615;&#36136;&#65292;&#36825;&#38480;&#21046;&#20102;&#20998;&#26512;&#33539;&#22260;&#20165;&#38480;&#20110;&#20108;&#27425;&#20989;&#25968;&#30340;&#30028;&#38480;&#20869;&#12290;&#26368;&#36817;&#30340;&#24037;&#20316;&#25918;&#26494;&#20102;&#36825;&#20010;&#35201;&#27714;&#65292;&#36716;&#32780;&#20351;&#29992;&#19968;&#31181;&#38750;&#22343;&#21248;&#24179;&#28369;&#26465;&#20214;&#65292;&#20854;&#20013;Hessian&#33539;&#25968;&#21463;&#26799;&#24230;&#33539;&#25968;&#30340;&#20223;&#23556;&#20989;&#25968;&#38480;&#21046;&#65292;&#24182;&#36890;&#36807;&#26799;&#24230;&#35009;&#21098;&#35777;&#26126;&#20102;&#38750;&#20984;&#24773;&#20917;&#19979;&#30340;&#25910;&#25947;&#24615;&#65292;&#20551;&#35774;&#23384;&#22312;&#26377;&#30028;&#22122;&#22768;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25512;&#24191;&#20102;&#36825;&#31181;&#38750;&#22343;&#21248;&#24179;&#28369;&#26465;&#20214;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#31616;&#21333;&#20294;&#21151;&#33021;&#24378;&#22823;&#30340;&#20998;&#26512;&#25216;&#26415;&#65292;&#21487;&#20197;&#27839;&#36712;&#36857;&#26041;&#21521;&#38480;&#21046;&#26799;&#24230;&#65292;&#20174;&#32780;&#33719;&#24471;&#26356;&#24378;&#30340;&#20984;&#21644;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#32467;&#26524;&#12290;&#29305;&#21035;&#22320;&#65292;&#22312;&#36825;&#20010;&#24191;&#20041;&#24179;&#28369;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#65288;&#38543;&#26426;&#65289;&#26799;&#24230;&#19979;&#38477;&#21644;Nesterov&#21152;&#36895;&#26799;&#24230;&#26041;&#27861;&#30340;&#32463;&#20856;&#25910;&#25947;&#29575;&#65292;&#36866;&#29992;&#20110;&#20984;&#21644;&#65288;&#25110;&#65289;&#38750;&#20984;&#35774;&#23450;&#12290;&#26032;&#30340;&#20998;&#26512;&#26041;&#27861;&#19981;&#38656;&#35201;&#26799;&#24230;&#35009;&#21098;&#65292;&#24182;&#20801;&#35768;&#26377;&#37325;&#23614;&#22122;&#22768;&#65292;&#36825;&#26159;&#19968;&#31181;&#38750;&#24120;&#23454;&#29992;&#30340;&#20248;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Classical analysis of convex and non-convex optimization methods often requires the Lipshitzness of the gradient, which limits the analysis to functions bounded by quadratics. Recent work relaxed this requirement to a non-uniform smoothness condition with the Hessian norm bounded by an affine function of the gradient norm, and proved convergence in the non-convex setting via gradient clipping, assuming bounded noise. In this paper, we further generalize this non-uniform smoothness condition and develop a simple, yet powerful analysis technique that bounds the gradients along the trajectory, thereby leading to stronger results for both convex and non-convex optimization problems. In particular, we obtain the classical convergence rates for (stochastic) gradient descent and Nesterov's accelerated gradient method in the convex and/or non-convex setting under this general smoothness condition. The new analysis approach does not require gradient clipping and allows heavy-tailed noise with b
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#31283;&#20581;&#33258;&#25105;&#35757;&#32451;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#20266;&#26631;&#31614;&#19981;&#20934;&#30830;&#21644;&#23436;&#20840;&#20934;&#30830;&#26102;&#20998;&#21035;&#37319;&#21462;&#19981;&#21516;&#30340;&#35757;&#32451;&#31574;&#30053;&#65292;&#23454;&#29616;&#26377;&#25928;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#31639;&#27861;&#22312;ImageNet&#21644;nuScenes&#25968;&#25454;&#38598;&#19978;&#22343;&#27604;&#26631;&#20934;&#33258;&#25105;&#35757;&#32451;&#24635;&#32467;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2306.00265</link><description>&lt;p&gt;
&#21452;&#37325;&#31283;&#20581;&#33258;&#25105;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Doubly Robust Self-Training. (arXiv:2306.00265v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00265
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#31283;&#20581;&#33258;&#25105;&#35757;&#32451;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#20266;&#26631;&#31614;&#19981;&#20934;&#30830;&#21644;&#23436;&#20840;&#20934;&#30830;&#26102;&#20998;&#21035;&#37319;&#21462;&#19981;&#21516;&#30340;&#35757;&#32451;&#31574;&#30053;&#65292;&#23454;&#29616;&#26377;&#25928;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#31639;&#27861;&#22312;ImageNet&#21644;nuScenes&#25968;&#25454;&#38598;&#19978;&#22343;&#27604;&#26631;&#20934;&#33258;&#25105;&#35757;&#32451;&#24635;&#32467;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#25105;&#35757;&#32451;&#26159;&#35299;&#20915;&#21322;&#30417;&#30563;&#23398;&#20064;&#38382;&#39064;&#30340;&#19968;&#31181;&#37325;&#35201;&#25216;&#26415;&#12290;&#23427;&#36890;&#36807;&#29983;&#25104;&#20266;&#26631;&#31614;&#24182;&#23558;&#20854;&#19982;&#26377;&#38480;&#30340;&#26631;&#35760;&#25968;&#25454;&#38598;&#32467;&#21512;&#20351;&#29992;&#36827;&#34892;&#35757;&#32451;&#65292;&#20174;&#32780;&#21033;&#29992;&#26080;&#26631;&#31614;&#25968;&#25454;&#12290;&#33258;&#25105;&#35757;&#32451;&#30340;&#26377;&#25928;&#24615;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#20381;&#36182;&#20110;&#36825;&#20123;&#20266;&#26631;&#31614;&#30340;&#20934;&#30830;&#24615;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#21452;&#37325;&#31283;&#20581;&#33258;&#25105;&#35757;&#32451;&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#21322;&#30417;&#30563;&#31639;&#27861;&#65292;&#21487;&#20197;&#20445;&#35777;&#22312;&#20004;&#20010;&#26497;&#31471;&#20043;&#38388;&#24179;&#34913;&#12290;&#24403;&#20266;&#26631;&#31614;&#23436;&#20840;&#19981;&#27491;&#30830;&#26102;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#34987;&#20943;&#23569;&#21040;&#20165;&#20351;&#29992;&#26631;&#35760;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#12290;&#30456;&#21453;&#65292;&#24403;&#20266;&#26631;&#31614;&#23436;&#20840;&#20934;&#30830;&#26102;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#21464;&#25104;&#21033;&#29992;&#25152;&#26377;&#20266;&#26631;&#31614;&#25968;&#25454;&#21644;&#26631;&#35760;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#30340;&#36807;&#31243;&#65292;&#20174;&#32780;&#22686;&#21152;&#26377;&#25928;&#30340;&#26679;&#26412;&#37327;&#12290;&#36890;&#36807;&#22312;ImageNet&#22270;&#20687;&#20998;&#31867;&#21644;nuScenes&#33258;&#20027;&#39550;&#39542;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#35777;&#35780;&#20272;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21452;&#37325;&#31283;&#20581;&#25439;&#22833;&#20248;&#20110;&#26631;&#20934;&#33258;&#25105;&#35757;&#32451;&#22522;&#32447;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Self-training is an important technique for solving semi-supervised learning problems. It leverages unlabeled data by generating pseudo-labels and combining them with a limited labeled dataset for training. The effectiveness of self-training heavily relies on the accuracy of these pseudo-labels. In this paper, we introduce doubly robust self-training, a novel semi-supervised algorithm that provably balances between two extremes. When the pseudo-labels are entirely incorrect, our method reduces to a training process solely using labeled data. Conversely, when the pseudo-labels are completely accurate, our method transforms into a training process utilizing all pseudo-labeled data and labeled data, thus increasing the effective sample size. Through empirical evaluations on both the ImageNet dataset for image classification and the nuScenes autonomous driving dataset for 3D object detection, we demonstrate the superiority of the doubly robust loss over the standard self-training baseline.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23581;&#35797;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#23454;&#29616;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#24182;&#29983;&#25104;&#25509;&#36817;&#26368;&#20248;&#30340;&#31169;&#26377;&#25345;&#20037;&#22270;&#65292;&#25552;&#20986;&#20351;&#29992; $L^1$-&#36317;&#31163;&#35745;&#31639;&#25345;&#20037;&#22270;&#24182;&#37319;&#29992;&#25351;&#25968;&#26426;&#21046;&#20445;&#25252;&#38544;&#31169;&#65292;&#25104;&#21151;&#23454;&#29616;&#22312;&#38544;&#31169;&#20445;&#25252;&#21644;&#25968;&#25454;&#20998;&#26512;&#20043;&#38388;&#30340;&#24179;&#34913;&#12290;</title><link>http://arxiv.org/abs/2305.03609</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#22312;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Topological Data Analysis. (arXiv:2305.03609v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.03609
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23581;&#35797;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#23454;&#29616;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#24182;&#29983;&#25104;&#25509;&#36817;&#26368;&#20248;&#30340;&#31169;&#26377;&#25345;&#20037;&#22270;&#65292;&#25552;&#20986;&#20351;&#29992; $L^1$-&#36317;&#31163;&#35745;&#31639;&#25345;&#20037;&#22270;&#24182;&#37319;&#29992;&#25351;&#25968;&#26426;&#21046;&#20445;&#25252;&#38544;&#31169;&#65292;&#25104;&#21151;&#23454;&#29616;&#22312;&#38544;&#31169;&#20445;&#25252;&#21644;&#25968;&#25454;&#20998;&#26512;&#20043;&#38388;&#30340;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26159;&#39318;&#31687;&#23581;&#35797;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#23454;&#29616;&#25299;&#25169;&#25968;&#25454;&#20998;&#26512;&#24182;&#29983;&#25104;&#25509;&#36817;&#26368;&#20248;&#30340;&#31169;&#26377;&#25345;&#20037;&#22270;&#12290;&#25105;&#20204;&#36890;&#36807;&#29942;&#39048;&#36317;&#31163;&#20998;&#26512;&#25345;&#20037;&#22270;&#30340;&#28789;&#25935;&#24230;&#65292;&#21457;&#29616;&#24120;&#29992;&#30340; \v{C}ech &#22797;&#24418;&#30340;&#28789;&#25935;&#24230;&#24182;&#19981;&#20250;&#38543;&#30528;&#26679;&#26412;&#37327; $n$ &#30340;&#22686;&#21152;&#32780;&#38477;&#20302;&#65292;&#36825;&#20351;&#24471; \v{C}ech &#22797;&#24418;&#25345;&#20037;&#22270;&#38590;&#20197;&#38544;&#31169;&#21270;&#12290;&#20316;&#20026;&#26367;&#20195;&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992; $L^1$-&#36317;&#31163;&#26469;&#35745;&#31639;&#25345;&#20037;&#22270;&#65292;&#21457;&#29616;&#20854;&#28789;&#25935;&#24230;&#20026; $O(1/n)$&#12290;&#22522;&#20110;&#28789;&#25935;&#24230;&#20998;&#26512;&#65292;&#25105;&#20204;&#25552;&#20986;&#37319;&#29992;&#25351;&#25968;&#26426;&#21046;&#65292;&#20854;&#25928;&#29992;&#20989;&#25968;&#23450;&#20041;&#20026; $L^1$-DTM &#25345;&#20037;&#22270;&#30340;&#29942;&#39048;&#36317;&#31163;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#25512;&#23548;&#20986;&#20102;&#25105;&#20204;&#38544;&#31169;&#26426;&#21046;&#30340;&#31934;&#24230;&#19978;&#19979;&#30028;&#65307;&#24471;&#21040;&#30340;&#30028;&#38480;&#34920;&#26126;&#25105;&#20204;&#30340;&#26426;&#21046;&#38544;&#31169;&#35823;&#24046;&#25509;&#36817;&#26368;&#20248;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#31169;&#26377;&#25345;&#20037;&#22270;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper is the first to attempt differentially private (DP) topological data analysis (TDA), producing near-optimal private persistence diagrams. We analyze the sensitivity of persistence diagrams in terms of the bottleneck distance, and we show that the commonly used \v{C}ech complex has sensitivity that does not decrease as the sample size $n$ increases. This makes it challenging for the persistence diagrams of \v{C}ech complexes to be privatized. As an alternative, we show that the persistence diagram obtained by the $L^1$-distance to measure (DTM) has sensitivity $O(1/n)$. Based on the sensitivity analysis, we propose using the exponential mechanism whose utility function is defined in terms of the bottleneck distance of the $L^1$-DTM persistence diagrams. We also derive upper and lower bounds of the accuracy of our privacy mechanism; the obtained bounds indicate that the privacy error of our mechanism is near-optimal. We demonstrate the performance of our privatized persistence
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#36801;&#31227;&#23398;&#20064;&#20013;&#20351;&#29992;&#21333;&#20010;&#39044;&#35757;&#32451;&#26816;&#26597;&#28857;&#24494;&#35843;&#30340;&#27169;&#22411;&#38598;&#21512;&#65292;&#21457;&#29616;&#36890;&#36807;&#26356;&#22909;&#22320;&#25506;&#32034;&#39044;&#35757;&#32451;&#22522;&#22495;&#21487;&#20197;&#25913;&#36827;&#38598;&#25104;&#27169;&#22411;&#65292;&#20294;&#31163;&#24320;&#22522;&#22495;&#20250;&#23548;&#33268;&#22833;&#21435;&#36801;&#31227;&#23398;&#20064;&#30340;&#22909;&#22788;&#65292;&#24182;&#19988;&#38477;&#20302;&#38598;&#25104;&#36136;&#37327;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#26377;&#25928;&#30340;&#20462;&#25913;&#26041;&#27861;StarSSE&#65292;&#21487;&#20197;&#20135;&#29983;&#26356;&#24378;&#30340;&#38598;&#25104;&#27169;&#22411;&#21644;&#22343;&#21248;&#30340;&#27169;&#22411;&#28151;&#21512;&#12290;</title><link>http://arxiv.org/abs/2303.03374</link><description>&lt;p&gt;
&#20572;&#30041;&#36824;&#26159;&#31163;&#24320;&#39044;&#35757;&#32451;&#22522;&#22495;&#65306;&#20851;&#20110;&#38598;&#25104;&#23398;&#20064;&#22312;&#36801;&#31227;&#23398;&#20064;&#20013;&#30340;&#27934;&#35265;
&lt;/p&gt;
&lt;p&gt;
To Stay or Not to Stay in the Pre-train Basin: Insights on Ensembling in Transfer Learning. (arXiv:2303.03374v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.03374
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#36801;&#31227;&#23398;&#20064;&#20013;&#20351;&#29992;&#21333;&#20010;&#39044;&#35757;&#32451;&#26816;&#26597;&#28857;&#24494;&#35843;&#30340;&#27169;&#22411;&#38598;&#21512;&#65292;&#21457;&#29616;&#36890;&#36807;&#26356;&#22909;&#22320;&#25506;&#32034;&#39044;&#35757;&#32451;&#22522;&#22495;&#21487;&#20197;&#25913;&#36827;&#38598;&#25104;&#27169;&#22411;&#65292;&#20294;&#31163;&#24320;&#22522;&#22495;&#20250;&#23548;&#33268;&#22833;&#21435;&#36801;&#31227;&#23398;&#20064;&#30340;&#22909;&#22788;&#65292;&#24182;&#19988;&#38477;&#20302;&#38598;&#25104;&#36136;&#37327;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#26377;&#25928;&#30340;&#20462;&#25913;&#26041;&#27861;StarSSE&#65292;&#21487;&#20197;&#20135;&#29983;&#26356;&#24378;&#30340;&#38598;&#25104;&#27169;&#22411;&#21644;&#22343;&#21248;&#30340;&#27169;&#22411;&#28151;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36801;&#31227;&#23398;&#20064;&#21644;&#38598;&#25104;&#23398;&#20064;&#26159;&#25913;&#21892;&#31070;&#32463;&#32593;&#32476;&#24615;&#33021;&#21644;&#40065;&#26834;&#24615;&#30340;&#20004;&#31181;&#28909;&#38376;&#25216;&#26415;&#12290;&#30001;&#20110;&#39044;&#35757;&#32451;&#25104;&#26412;&#39640;&#26114;&#65292;&#36890;&#24120;&#23454;&#36341;&#20013;&#20351;&#29992;&#20174;&#21333;&#20010;&#39044;&#35757;&#32451;&#26816;&#26597;&#28857;&#24494;&#35843;&#30340;&#27169;&#22411;&#38598;&#21512;&#12290;&#36825;&#20123;&#27169;&#22411;&#26368;&#32456;&#20250;&#36827;&#20837;&#25439;&#22833;&#20989;&#25968;&#26799;&#24230;&#19979;&#38477;&#31354;&#38388;&#30340;&#30456;&#21516;&#21306;&#22495;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#39044;&#35757;&#32451;&#22522;&#22495;&#65292;&#22240;&#27492;&#20855;&#26377;&#26377;&#38480;&#30340;&#22810;&#26679;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20174;&#21333;&#20010;&#39044;&#35757;&#32451;&#26816;&#26597;&#28857;&#35757;&#32451;&#30340;&#38598;&#25104;&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#26356;&#22909;&#22320;&#25506;&#32034;&#39044;&#35757;&#32451;&#22522;&#22495;&#26469;&#25913;&#36827;&#65292;&#28982;&#32780;&#65292;&#31163;&#24320;&#22522;&#22495;&#20250;&#23548;&#33268;&#22833;&#21435;&#36801;&#31227;&#23398;&#20064;&#30340;&#22909;&#22788;&#24182;&#23548;&#33268;&#38598;&#25104;&#36136;&#37327;&#30340;&#19979;&#38477;&#12290;&#22522;&#20110;&#23545;&#29616;&#26377;&#25506;&#32034;&#26041;&#27861;&#30340;&#20998;&#26512;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#26377;&#25928;&#30340;&#20462;&#25913;Transfer Learning Setup&#20013;&#30340;Snapshot Ensembles&#65288;SSE&#65289;&#26041;&#27861;&#65292;&#21517;&#20026;StarSSE&#65292;&#23427;&#33021;&#20135;&#29983;&#26356;&#24378;&#30340;&#38598;&#25104;&#27169;&#22411;&#21644;&#22343;&#21248;&#30340;&#27169;&#22411;&#28151;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Transfer learning and ensembling are two popular techniques for improving the performance and robustness of neural networks. Due to the high cost of pre-training, ensembles of models fine-tuned from a single pre-trained checkpoint are often used in practice. Such models end up in the same basin of the loss landscape, which we call the pre-train basin, and thus have limited diversity. In this work, we show that ensembles trained from a single pre-trained checkpoint may be improved by better exploring the pre-train basin, however, leaving the basin results in losing the benefits of transfer learning and in degradation of the ensemble quality. Based on the analysis of existing exploration methods, we propose a more effective modification of the Snapshot Ensembles (SSE) for transfer learning setup, StarSSE, which results in stronger ensembles and uniform model soups.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21322;&#23450;&#35268;&#21010;&#26041;&#27861;&#26469;&#35299;&#20915;&#22522;&#20110;&#36229;&#22270;&#30340;&#22810;&#23618;&#32858;&#31867;&#38382;&#39064;&#65292;&#21516;&#26102;&#22312;&#21516;&#37197;&#21644;&#38750;&#21516;&#37197;&#24773;&#20917;&#19979;&#20445;&#35777;&#20102;&#31934;&#30830;&#24674;&#22797;&#12290;</title><link>http://arxiv.org/abs/2301.11657</link><description>&lt;p&gt;
&#20351;&#29992;&#32858;&#21512;&#30456;&#20284;&#30697;&#38453;&#30340;&#22810;&#23618;&#36229;&#22270;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Multilayer hypergraph clustering using the aggregate similarity matrix. (arXiv:2301.11657v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11657
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21322;&#23450;&#35268;&#21010;&#26041;&#27861;&#26469;&#35299;&#20915;&#22522;&#20110;&#36229;&#22270;&#30340;&#22810;&#23618;&#32858;&#31867;&#38382;&#39064;&#65292;&#21516;&#26102;&#22312;&#21516;&#37197;&#21644;&#38750;&#21516;&#37197;&#24773;&#20917;&#19979;&#20445;&#35777;&#20102;&#31934;&#30830;&#24674;&#22797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#22312;&#36229;&#22270;&#30340;&#22810;&#23618;&#21464;&#20307;&#19978;&#25191;&#34892;&#31038;&#21306;&#24674;&#22797;&#38382;&#39064;&#65292;&#27599;&#20010;&#23618;&#19982; N &#20010;&#39030;&#28857;&#19978;&#30340; d-&#22343;&#21248;&#36229;&#22270;&#38543;&#26426;&#22359;&#27169;&#22411; (HSBM) &#30340;&#29420;&#31435;&#23454;&#29616;&#30456;&#20851;&#12290;&#32473;&#20986;&#21253;&#21547;&#19982;&#27599;&#23545;&#39030;&#28857;&#30456;&#20132;&#30340;&#36229;&#36793;&#25968;&#37327;&#32858;&#21512;&#30340;&#30456;&#20284;&#30697;&#38453;&#65292;&#30446;&#26631;&#26159;&#23558; N &#20010;&#39030;&#28857;&#21010;&#20998;&#20026;&#19981;&#30456;&#20132;&#30340;&#31038;&#21306;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#21322;&#23450;&#35268;&#21010; (SDP) &#26041;&#27861;&#65292;&#24182;&#33719;&#24471;&#20102;&#26377;&#20851;&#27169;&#22411;&#21442;&#25968;&#30340;&#20449;&#24687;&#35770;&#26465;&#20214;&#65292;&#20445;&#35777;&#22312;&#21516;&#37197;&#21644;&#38750;&#21516;&#37197;&#24773;&#20917;&#19979;&#22343;&#33021;&#30830;&#20445;&#31934;&#30830;&#24674;&#22797;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the community recovery problem on a multilayer variant of the hypergraph stochastic block model (HSBM). Each layer is associated with an independent realization of a d-uniform HSBM on N vertices. Given the similarity matrix containing the aggregated number of hyperedges incident to each pair of vertices, the goal is to obtain a partition of the N vertices into disjoint communities. In this work, we investigate a semidefinite programming (SDP) approach and obtain information-theoretic conditions on the model parameters that guarantee exact recovery both in the assortative and the disassortative cases.
&lt;/p&gt;</description></item><item><title>Tracr&#26159;&#19968;&#20010;&#32534;&#35793;&#22120;&#65292;&#23558;&#21487;&#35835;&#24615;&#24378;&#30340;&#31243;&#24207;&#32534;&#35793;&#25104;&#26631;&#20934;&#30340;&#20165;&#35299;&#30721;&#21464;&#21387;&#22120;&#27169;&#22411;&#65292;&#35813;&#32534;&#35793;&#27169;&#22411;&#30340;&#24050;&#30693;&#32467;&#26500;&#21487;&#20197;&#29992;&#20110;&#35774;&#35745;&#23454;&#39564;&#21644;&#35780;&#20272;&#21487;&#35299;&#37322;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2301.05062</link><description>&lt;p&gt;
Tracr: &#32534;&#35793;&#21464;&#21387;&#22120;&#27169;&#22411;&#20316;&#20026;&#21487;&#35299;&#37322;&#24615;&#23454;&#39564;&#23460;
&lt;/p&gt;
&lt;p&gt;
Tracr: Compiled Transformers as a Laboratory for Interpretability. (arXiv:2301.05062v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.05062
&lt;/p&gt;
&lt;p&gt;
Tracr&#26159;&#19968;&#20010;&#32534;&#35793;&#22120;&#65292;&#23558;&#21487;&#35835;&#24615;&#24378;&#30340;&#31243;&#24207;&#32534;&#35793;&#25104;&#26631;&#20934;&#30340;&#20165;&#35299;&#30721;&#21464;&#21387;&#22120;&#27169;&#22411;&#65292;&#35813;&#32534;&#35793;&#27169;&#22411;&#30340;&#24050;&#30693;&#32467;&#26500;&#21487;&#20197;&#29992;&#20110;&#35774;&#35745;&#23454;&#39564;&#21644;&#35780;&#20272;&#21487;&#35299;&#37322;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#21487;&#35835;&#24615;&#24378;&#30340;&#31243;&#24207;&#32534;&#35793;&#25104;&#26631;&#20934;&#30340;&#20165;&#35299;&#30721;&#21464;&#21387;&#22120;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#32534;&#35793;&#22120;Tracr&#29983;&#25104;&#20855;&#26377;&#24050;&#30693;&#32467;&#26500;&#30340;&#27169;&#22411;&#65292;&#21487;&#20197;&#29992;&#20110;&#35774;&#35745;&#23454;&#39564;&#12290;&#20363;&#22914;&#65292;&#25105;&#20204;&#20351;&#29992;&#23427;&#26469;&#30740;&#31350;&#25191;&#34892;&#22810;&#27493;&#31639;&#27861;&#30340;&#21464;&#21387;&#22120;&#20013;&#30340;&#8220;&#21472;&#21152;&#8221;&#12290;&#27492;&#22806;&#65292;Tracr&#32534;&#35793;&#27169;&#22411;&#30340;&#24050;&#30693;&#32467;&#26500;&#21487;&#20197;&#20316;&#20026;&#35780;&#20272;&#21487;&#35299;&#37322;&#26041;&#27861;&#30340;&#30495;&#23454;&#22522;&#20934;&#12290;&#36890;&#24120;&#65292;&#30001;&#20110;&#21464;&#21387;&#22120;&#23398;&#20064;&#30340;&#8220;&#31243;&#24207;&#8221;&#26159;&#26410;&#30693;&#30340;&#65292;&#22240;&#27492;&#19981;&#28165;&#26970;&#35299;&#37322;&#26159;&#21542;&#25104;&#21151;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#29616;&#21644;&#26816;&#26597;&#21253;&#25324;&#35745;&#31639;&#20196;&#29260;&#39057;&#29575;&#12289;&#25490;&#24207;&#21644;&#25324;&#21495;&#26816;&#26597;&#22312;&#20869;&#30340;&#31243;&#24207;&#26469;&#28436;&#31034;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#22312;https://github.com/deepmind/tracr&#25552;&#20379;&#20102;Tracr&#30340;&#24320;&#28304;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We show how to "compile" human-readable programs into standard decoder-only transformer models. Our compiler, Tracr, generates models with known structure. This structure can be used to design experiments. For example, we use it to study "superposition" in transformers that execute multi-step algorithms. Additionally, the known structure of Tracr-compiled models can serve as ground-truth for evaluating interpretability methods. Commonly, because the "programs" learned by transformers are unknown it is unclear whether an interpretation succeeded. We demonstrate our approach by implementing and examining programs including computing token frequencies, sorting, and parenthesis checking. We provide an open-source implementation of Tracr at https://github.com/deepmind/tracr.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#36830;&#25509;&#26680;&#26426;&#22120;&#21644;&#26497;&#38480;&#23398;&#20064;&#26426;&#65292;&#23454;&#29616;&#20102;&#22312;&#22810;&#20219;&#21153;&#22238;&#24402;&#38382;&#39064;&#20013;&#30340;&#29305;&#24449;&#31354;&#38388;&#30340;&#23398;&#20064;&#12290;&#35813;&#26041;&#27861;&#25552;&#20379;&#20102;&#20248;&#21270;RBF&#26680;&#21442;&#25968;&#12289;&#27169;&#22411;&#22797;&#26434;&#24230;&#21644;&#22810;&#36755;&#20986;&#31232;&#30095;&#24615;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2209.03028</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#23398;&#20064;&#22810;&#20219;&#21153;&#38382;&#39064;&#30340;&#29305;&#24449;&#31354;&#38388;
&lt;/p&gt;
&lt;p&gt;
Bayesian learning of feature spaces for multitasks problems. (arXiv:2209.03028v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.03028
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#36830;&#25509;&#26680;&#26426;&#22120;&#21644;&#26497;&#38480;&#23398;&#20064;&#26426;&#65292;&#23454;&#29616;&#20102;&#22312;&#22810;&#20219;&#21153;&#22238;&#24402;&#38382;&#39064;&#20013;&#30340;&#29305;&#24449;&#31354;&#38388;&#30340;&#23398;&#20064;&#12290;&#35813;&#26041;&#27861;&#25552;&#20379;&#20102;&#20248;&#21270;RBF&#26680;&#21442;&#25968;&#12289;&#27169;&#22411;&#22797;&#26434;&#24230;&#21644;&#22810;&#36755;&#20986;&#31232;&#30095;&#24615;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#22810;&#20219;&#21153;&#22238;&#24402;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#38543;&#26426;&#20613;&#37324;&#21494;&#29305;&#24449;(RFFs)&#36817;&#20284;&#24452;&#21521;&#22522;&#20989;&#25968;(RBF)&#26680;&#65292;&#23558;&#26680;&#26426;&#22120;(KM)&#21644;&#26497;&#38480;&#23398;&#20064;&#26426;(ELM)&#30456;&#36830;&#25509;&#12290;&#20854;&#20013;&#30340;&#19968;&#20010;&#36129;&#29486;&#26159;&#34920;&#26126;&#23545;&#20110;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#65292;KM&#21644;ELM&#30340;&#24418;&#24335;&#21487;&#20197;&#34987;&#30475;&#20316;&#26159;&#21516;&#19968;&#26522;&#30828;&#24065;&#30340;&#20004;&#38754;&#12290;&#36825;&#20123;&#25552;&#20986;&#30340;&#27169;&#22411;&#31216;&#20026;RFF-BLR&#65292;&#24314;&#31435;&#22312;&#36125;&#21494;&#26031;&#26694;&#26550;&#19978;&#65292;&#21516;&#26102;&#35299;&#20915;&#20102;&#20004;&#20010;&#20027;&#35201;&#30340;&#35774;&#35745;&#30446;&#26631;&#12290;&#19968;&#26041;&#38754;&#65292;&#23427;&#22522;&#20110;&#24102;&#26377;RBF&#26680;&#30340;KM&#25311;&#21512;&#22810;&#20219;&#21153;&#22238;&#24402;&#22120;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#23427;&#24341;&#20837;&#20102;&#19968;&#31181;&#36328;&#20219;&#21153;&#30340;&#20849;&#21516;&#20808;&#39564;&#65292;&#20419;&#36827;&#20102;ELM&#35270;&#22270;&#20013;&#30340;&#22810;&#36755;&#20986;&#31232;&#30095;&#24615;&#12290;&#36825;&#31181;&#36125;&#21494;&#26031;&#26041;&#27861;&#20351;&#24471;&#33021;&#22815;&#21516;&#26102;&#32771;&#34385;KM&#21644;ELM&#30340;&#35266;&#28857;&#65292;&#23454;&#29616;&#20102;(i)&#22312;&#27010;&#29575;&#26694;&#26550;&#20869;&#20248;&#21270;RBF&#26680;&#21442;&#25968;$\gamma$&#65292;(ii)&#20248;&#21270;&#27169;&#22411;&#22797;&#26434;&#24230;&#65292;&#21644;(iii)
&lt;/p&gt;
&lt;p&gt;
This paper introduces a novel approach for multi-task regression that connects Kernel Machines (KMs) and Extreme Learning Machines (ELMs) through the exploitation of the Random Fourier Features (RFFs) approximation of the RBF kernel. In this sense, one of the contributions of this paper shows that for the proposed models, the KM and the ELM formulations can be regarded as two sides of the same coin. These proposed models, termed RFF-BLR, stand on a Bayesian framework that simultaneously addresses two main design goals. On the one hand, it fits multitask regressors based on KMs endowed with RBF kernels. On the other hand, it enables the introduction of a common-across-tasks prior that promotes multioutput sparsity in the ELM view. This Bayesian approach facilitates the simultaneous consideration of both the KM and ELM perspectives enabling (i) the optimisation of the RBF kernel parameter $\gamma$ within a probabilistic framework, (ii) the optimisation of the model complexity, and (iii) 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#37325;&#26032;&#32553;&#25918;&#30340;&#29790;&#21033;&#21830;&#20989;&#25968;&#20316;&#20026;&#20934;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#24182;&#37319;&#29992;&#36125;&#21494;&#26031;&#26694;&#26550;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#35745;&#31639;&#31232;&#30095;&#35268;&#33539;&#21521;&#37327;&#30340;&#20272;&#35745;&#20540;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#36830;&#32493;&#21644;&#25130;&#26029;&#25968;&#25454;&#19978;&#34920;&#29616;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2010.08627</link><description>&lt;p&gt;
&#26368;&#23567;&#26368;&#22823;&#25311;&#36125;&#21494;&#26031;&#20272;&#35745;&#22312;&#31232;&#30095;&#35268;&#33539;&#30456;&#20851;&#20998;&#26512;&#20013;&#30340;&#24212;&#29992;&#65306;&#22522;&#20110;&#29790;&#21033;&#21830;&#20989;&#25968;&#30340;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Minimax Quasi-Bayesian estimation in sparse canonical correlation analysis via a Rayleigh quotient function. (arXiv:2010.08627v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2010.08627
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#37325;&#26032;&#32553;&#25918;&#30340;&#29790;&#21033;&#21830;&#20989;&#25968;&#20316;&#20026;&#20934;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#24182;&#37319;&#29992;&#36125;&#21494;&#26031;&#26694;&#26550;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#35745;&#31639;&#31232;&#30095;&#35268;&#33539;&#21521;&#37327;&#30340;&#20272;&#35745;&#20540;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#22312;&#36830;&#32493;&#21644;&#25130;&#26029;&#25968;&#25454;&#19978;&#34920;&#29616;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35268;&#33539;&#30456;&#20851;&#20998;&#26512;&#65288;CCA&#65289;&#26159;&#19968;&#31181;&#29992;&#20110;&#25506;&#32034;&#25968;&#25454;&#38598;&#20043;&#38388;&#20851;&#31995;&#30340;&#27969;&#34892;&#32479;&#35745;&#25216;&#26415;&#12290;&#36817;&#24180;&#26469;&#65292;&#31232;&#30095;&#35268;&#33539;&#21521;&#37327;&#30340;&#20272;&#35745;&#24050;&#25104;&#20026;CCA&#38382;&#39064;&#30340;&#19968;&#20010;&#37325;&#35201;&#19988;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#21464;&#20307;&#65292;&#24212;&#29992;&#24191;&#27867;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#29616;&#26377;&#30340;&#31232;&#30095;&#35268;&#33539;&#21521;&#37327;&#30340;&#26368;&#20248;&#20272;&#35745;&#22120;&#35745;&#31639;&#25104;&#26412;&#36739;&#39640;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20934;&#36125;&#21494;&#26031;&#20272;&#35745;&#36807;&#31243;&#65292;&#26082;&#36798;&#21040;&#20102;&#26368;&#23567;&#26368;&#22823;&#20272;&#35745;&#36895;&#29575;&#65292;&#21448;&#21487;&#20197;&#36890;&#36807;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#65288;MCMC&#65289;&#36731;&#26494;&#35745;&#31639;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;Tan&#31561;&#20154;&#65288;2018&#65289;&#30340;&#30740;&#31350;&#65292;&#20351;&#29992;&#37325;&#26032;&#32553;&#25918;&#30340;&#29790;&#21033;&#21830;&#20989;&#25968;&#20316;&#20026;&#20934;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#12290;&#28982;&#32780;&#65292;&#19982;Tan&#31561;&#20154;&#65288;2018&#65289;&#19981;&#21516;&#30340;&#26159;&#65292;&#25105;&#20204;&#37319;&#29992;&#20102;&#19968;&#20010;&#36125;&#21494;&#26031;&#26694;&#26550;&#65292;&#23558;&#36825;&#20010;&#20934;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#19982;&#23574;&#23792;-&#24179;&#26495;&#20808;&#39564;&#32467;&#21512;&#36215;&#26469;&#36827;&#34892;&#35268;&#33539;&#21270;&#25512;&#29702;&#21644;&#20419;&#36827;&#31232;&#30095;&#24615;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#22312;&#36830;&#32493;&#21644;&#25130;&#26029;&#25968;&#25454;&#19978;&#30340;&#32463;&#39564;&#34892;&#20026;&#65292;&#24182;&#35777;&#26126;&#23427;&#20248;&#20110;&#20960;&#31181;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Canonical correlation analysis (CCA) is a popular statistical technique for exploring relationships between datasets. In recent years, the estimation of sparse canonical vectors has emerged as an important but challenging variant of the CCA problem, with widespread applications. Unfortunately, existing rate-optimal estimators for sparse canonical vectors have high computational cost. We propose a quasi-Bayesian estimation procedure that not only achieves the minimax estimation rate, but also is easy to compute by Markov Chain Monte Carlo (MCMC). The method builds on Tan et al. (2018) and uses a re-scaled Rayleigh quotient function as the quasi-log-likelihood. However, unlike Tan et al. (2018), we adopt a Bayesian framework that combines this quasi-log-likelihood with a spike-and-slab prior to regularize the inference and promote sparsity. We investigate the empirical behavior of the proposed method on both continuous and truncated data, and we demonstrate that it outperforms several st
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36882;&#24402;&#31070;&#32463;&#32447;&#24615;&#21518;&#39564;&#25277;&#26679;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#38750;&#24179;&#31283;&#24773;&#22659;&#19979;&#30340;&#24773;&#22659;&#36172;&#21338;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#33021;&#22815;&#26377;&#25928;&#22320;&#34920;&#31034;&#30456;&#20851;&#24773;&#22659;&#24182;&#20570;&#20986;&#20915;&#31574;&#12290;</title><link>http://arxiv.org/abs/2007.04750</link><description>&lt;p&gt;
&#38750;&#24179;&#31283;&#32972;&#26223;&#19979;&#30340;&#36882;&#24402;&#31070;&#32463;&#32447;&#24615;&#21518;&#39564;&#25277;&#26679;&#24212;&#29992;&#20110;&#24773;&#22659;&#36172;&#21338;
&lt;/p&gt;
&lt;p&gt;
Recurrent Neural-Linear Posterior Sampling for Nonstationary Contextual Bandits. (arXiv:2007.04750v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2007.04750
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36882;&#24402;&#31070;&#32463;&#32447;&#24615;&#21518;&#39564;&#25277;&#26679;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#38750;&#24179;&#31283;&#24773;&#22659;&#19979;&#30340;&#24773;&#22659;&#36172;&#21338;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#33021;&#22815;&#26377;&#25928;&#22320;&#34920;&#31034;&#30456;&#20851;&#24773;&#22659;&#24182;&#20570;&#20986;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#38750;&#24179;&#31283;&#24773;&#22659;&#36172;&#21338;&#38382;&#39064;&#20013;&#65292;&#19968;&#20010;&#26234;&#33021;&#20307;&#38656;&#35201;&#22312;&#25506;&#32034;&#21644;&#21033;&#29992;&#20854;&#20808;&#21069;&#32463;&#39564;&#20013;&#23384;&#22312;&#30340;(&#21608;&#26399;&#24615;&#25110;&#32467;&#26500;&#21270;)&#27169;&#24335;&#20043;&#38388;&#20445;&#25345;&#24179;&#34913;&#12290;&#25163;&#24037;&#35774;&#35745;&#19968;&#20010;&#21512;&#36866;&#30340;&#21382;&#21490;&#24773;&#22659;&#26159;&#23558;&#38750;&#24179;&#31283;&#38382;&#39064;&#36716;&#21270;&#20026;&#21487;&#20197;&#39640;&#25928;&#35299;&#20915;&#30340;&#24179;&#31283;&#38382;&#39064;&#30340;&#19968;&#31181;&#26377;&#21560;&#24341;&#21147;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#21363;&#20351;&#26159;&#31934;&#24515;&#35774;&#35745;&#30340;&#21382;&#21490;&#24773;&#22659;&#20063;&#21487;&#33021;&#24341;&#20837;&#34394;&#20551;&#20851;&#31995;&#25110;&#32570;&#20047;&#20851;&#38190;&#20449;&#24687;&#30340;&#26041;&#20415;&#34920;&#31034;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23398;&#20064;&#20165;&#22522;&#20110;&#26234;&#33021;&#20307;&#19982;&#29615;&#22659;&#20043;&#38388;&#30340;&#21407;&#22987;&#20132;&#20114;&#21382;&#21490;&#26469;&#34920;&#31034;&#30456;&#20851;&#24773;&#22659;&#24182;&#20570;&#20986;&#20915;&#31574;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#20102;&#30001;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#25552;&#21462;&#30340;&#29305;&#24449;&#19982;&#22522;&#20110;&#21518;&#39564;&#25277;&#26679;&#30340;&#24773;&#22659;&#32447;&#24615;&#36172;&#21338;&#31639;&#27861;&#30340;&#32452;&#21512;&#12290;&#25105;&#20204;&#22312;&#22810;&#26679;&#30340;&#24773;&#22659;&#21644;&#38750;&#24773;&#22659;&#38750;&#24179;&#31283;&#38382;&#39064;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#36882;&#24402;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
An agent in a nonstationary contextual bandit problem should balance between exploration and the exploitation of (periodic or structured) patterns present in its previous experiences. Handcrafting an appropriate historical context is an attractive alternative to transform a nonstationary problem into a stationary problem that can be solved efficiently. However, even a carefully designed historical context may introduce spurious relationships or lack a convenient representation of crucial information. In order to address these issues, we propose an approach that learns to represent the relevant context for a decision based solely on the raw history of interactions between the agent and the environment. This approach relies on a combination of features extracted by recurrent neural networks with a contextual linear bandit algorithm based on posterior sampling. Our experiments on a diverse selection of contextual and noncontextual nonstationary problems show that our recurrent approach co
&lt;/p&gt;</description></item></channel></rss>