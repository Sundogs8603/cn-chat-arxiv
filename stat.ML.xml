<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#25955;&#33258;&#23548;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#23548;&#25193;&#25955;&#27169;&#22411;&#30340;&#20869;&#37096;&#34920;&#31034;&#26469;&#25552;&#20379;&#23545;&#29983;&#25104;&#22270;&#20687;&#30340;&#26356;&#22823;&#25511;&#21046;&#65292;&#21487;&#20197;&#29992;&#20110;&#25191;&#34892;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22270;&#20687;&#25805;&#20316;&#65292;&#21516;&#26102;&#19981;&#38656;&#35201;&#39069;&#22806;&#27169;&#22411;&#25110;&#35757;&#32451;&#12290;</title><link>http://arxiv.org/abs/2306.00986</link><description>&lt;p&gt;
&#21487;&#25511;&#22270;&#20687;&#29983;&#25104;&#30340;&#25193;&#25955;&#33258;&#23548;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Diffusion Self-Guidance for Controllable Image Generation. (arXiv:2306.00986v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00986
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25193;&#25955;&#33258;&#23548;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#23548;&#25193;&#25955;&#27169;&#22411;&#30340;&#20869;&#37096;&#34920;&#31034;&#26469;&#25552;&#20379;&#23545;&#29983;&#25104;&#22270;&#20687;&#30340;&#26356;&#22823;&#25511;&#21046;&#65292;&#21487;&#20197;&#29992;&#20110;&#25191;&#34892;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22270;&#20687;&#25805;&#20316;&#65292;&#21516;&#26102;&#19981;&#38656;&#35201;&#39069;&#22806;&#27169;&#22411;&#25110;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#35268;&#27169;&#29983;&#25104;&#27169;&#22411;&#33021;&#22815;&#20174;&#35814;&#32454;&#25991;&#26412;&#25551;&#36848;&#20013;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#22270;&#20687;&#12290;&#28982;&#32780;&#65292;&#22270;&#20687;&#30340;&#35768;&#22810;&#26041;&#38754;&#24456;&#38590;&#25110;&#19981;&#21487;&#33021;&#36890;&#36807;&#25991;&#26412;&#26469;&#20256;&#36798;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#33258;&#23548;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#23548;&#25193;&#25955;&#27169;&#22411;&#30340;&#20869;&#37096;&#34920;&#31034;&#26469;&#25552;&#20379;&#23545;&#29983;&#25104;&#22270;&#20687;&#30340;&#26356;&#22823;&#25511;&#21046;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#21487;&#20197;&#20174;&#36825;&#20123;&#34920;&#31034;&#20013;&#25552;&#21462;&#20986;&#23545;&#35937;&#30340;&#24418;&#29366;&#12289;&#20301;&#32622;&#21644;&#22806;&#35266;&#31561;&#23646;&#24615;&#24182;&#29992;&#20110;&#25351;&#23548;&#37319;&#26679;&#12290;&#33258;&#23548;&#31867;&#20284;&#20110;&#20998;&#31867;&#22120;&#24341;&#23548;&#65292;&#20294;&#26159;&#20351;&#29992;&#39044;&#35757;&#32451;&#27169;&#22411;&#26412;&#36523;&#20013;&#23384;&#22312;&#30340;&#20449;&#21495;&#65292;&#19981;&#38656;&#35201;&#39069;&#22806;&#30340;&#27169;&#22411;&#25110;&#35757;&#32451;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#32452;&#21512;&#19968;&#32452;&#31616;&#21333;&#30340;&#23646;&#24615;&#26469;&#25191;&#34892;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22270;&#20687;&#25805;&#20316;&#65292;&#20363;&#22914;&#20462;&#25913;&#23545;&#35937;&#30340;&#20301;&#32622;&#25110;&#22823;&#23567;&#65292;&#23558;&#19968;&#20010;&#22270;&#20687;&#20013;&#30340;&#23545;&#35937;&#22806;&#35266;&#19982;&#21478;&#19968;&#20010;&#22270;&#20687;&#30340;&#24067;&#23616;&#30456;&#32467;&#21512;&#65292;&#23558;&#22810;&#20010;&#22270;&#20687;&#30340;&#23545;&#35937;&#32452;&#21512;&#25104;&#19968;&#20010;&#65292;&#31561;&#31561;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#33258;&#23548;&#21487;&#20197;&#29992;&#20110;&#32534;&#36753;&#30495;&#23454;&#22270;&#20687;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large-scale generative models are capable of producing high-quality images from detailed text descriptions. However, many aspects of an image are difficult or impossible to convey through text. We introduce self-guidance, a method that provides greater control over generated images by guiding the internal representations of diffusion models. We demonstrate that properties such as the shape, location, and appearance of objects can be extracted from these representations and used to steer sampling. Self-guidance works similarly to classifier guidance, but uses signals present in the pretrained model itself, requiring no additional models or training. We show how a simple set of properties can be composed to perform challenging image manipulations, such as modifying the position or size of objects, merging the appearance of objects in one image with the layout of another, composing objects from many images into one, and more. We also show that self-guidance can be used to edit real images
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39640;&#38454;&#30456;&#20114;&#20316;&#29992;&#30340;&#27979;&#37327;&#26041;&#27861;&#21644;&#22522;&#20110;&#26680;&#30340;&#27979;&#35797;&#26041;&#27861;&#65292;&#24182;&#19982;&#26684;&#29702;&#35770;&#24314;&#31435;&#20102;&#25968;&#23398;&#32852;&#31995;&#65292;&#20026;&#22686;&#24378;&#30456;&#20114;&#20316;&#29992;&#27169;&#22411;&#25552;&#20379;&#20102;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.00904</link><description>&lt;p&gt;
&#30456;&#20114;&#20316;&#29992;&#27979;&#37327;&#65292;&#20998;&#21306;&#26684;&#21644;&#26680;&#27979;&#35797;&#29992;&#20110;&#39640;&#38454;&#30456;&#20114;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
Interaction Measures, Partition Lattices and Kernel Tests for High-Order Interactions. (arXiv:2306.00904v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00904
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#39640;&#38454;&#30456;&#20114;&#20316;&#29992;&#30340;&#27979;&#37327;&#26041;&#27861;&#21644;&#22522;&#20110;&#26680;&#30340;&#27979;&#35797;&#26041;&#27861;&#65292;&#24182;&#19982;&#26684;&#29702;&#35770;&#24314;&#31435;&#20102;&#25968;&#23398;&#32852;&#31995;&#65292;&#20026;&#22686;&#24378;&#30456;&#20114;&#20316;&#29992;&#27169;&#22411;&#25552;&#20379;&#20102;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20165;&#20381;&#36182;&#20110;&#25104;&#23545;&#20851;&#31995;&#30340;&#27169;&#22411;&#24448;&#24448;&#26080;&#27861;&#25429;&#25417;&#21040;&#21508;&#31181;&#39046;&#22495;&#65288;&#22914;&#31038;&#20250;&#32463;&#27982;&#12289;&#29983;&#24577;&#25110;&#29983;&#29289;&#21307;&#23398;&#31995;&#32479;&#65289;&#20013;&#25214;&#21040;&#30340;&#22797;&#26434;&#22810;&#21464;&#37327;&#25968;&#25454;&#30340;&#23436;&#25972;&#32479;&#35745;&#32467;&#26500;&#12290;&#20004;&#20010;&#20197;&#19978;&#21464;&#37327;&#32452;&#20043;&#38388;&#30340;&#38750;&#24179;&#20961;&#20381;&#36182;&#20851;&#31995;&#22312;&#36825;&#20123;&#31995;&#32479;&#30340;&#20998;&#26512;&#21644;&#24314;&#27169;&#20013;&#21487;&#20197;&#21457;&#25381;&#37325;&#35201;&#20316;&#29992;&#65292;&#20294;&#20174;&#25968;&#25454;&#20013;&#25552;&#21462;&#36825;&#26679;&#30340;&#39640;&#38454;&#30456;&#20114;&#20316;&#29992;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31995;&#21015;$d$-order ($d \geq 2$)&#30456;&#20114;&#20316;&#29992;&#27979;&#37327;&#65292;&#20381;&#27425;&#21253;&#25324;&#21487;&#33021;&#30340;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#20998;&#35299;&#65292;&#24182;&#23450;&#20041;&#20102;&#38750;&#21442;&#25968;&#12289;&#22522;&#20110;&#26680;&#30340;&#27979;&#35797;&#65292;&#20197;&#31995;&#32479;&#22320;&#30830;&#23450;$d$-order&#30456;&#20114;&#20316;&#29992;&#30340;&#32479;&#35745;&#26174;&#30528;&#24615;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19982;&#26684;&#29702;&#35770;&#30340;&#25968;&#23398;&#32852;&#31995;&#65292;&#38416;&#26126;&#20102;&#30456;&#20114;&#20316;&#29992;&#24230;&#37327;&#30340;&#23548;&#20986;&#21450;&#20854;&#22797;&#21512;&#25490;&#21015;&#27979;&#35797;&#30340;&#28085;&#20041;&#65307;&#28548;&#28165;&#20102;&#21333;&#32431;&#22797;&#21512;&#20307;&#19982;&#26680;&#30697;&#38453;&#20013;&#24515;&#21270;&#30340;&#32852;&#31995;&#65307;&#24182;&#25552;&#20379;&#20102;&#19968;&#31181;&#22686;&#24378;&#30456;&#20114;&#20316;&#29992;&#27169;&#22411;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Models that rely solely on pairwise relationships often fail to capture the complete statistical structure of the complex multivariate data found in diverse domains, such as socio-economic, ecological, or biomedical systems. Non-trivial dependencies between groups of more than two variables can play a significant role in the analysis and modelling of such systems, yet extracting such high-order interactions from data remains challenging. Here, we introduce a hierarchy of $d$-order ($d \geq 2$) interaction measures, increasingly inclusive of possible factorisations of the joint probability distribution, and define non-parametric, kernel-based tests to establish systematically the statistical significance of $d$-order interactions. We also establish mathematical links with lattice theory, which elucidate the derivation of the interaction measures and their composite permutation tests; clarify the connection of simplicial complexes with kernel matrix centring; and provide a means to enhan
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32622;&#20449;&#38598;&#27169;&#22411;&#33258;&#30001;&#31639;&#27861; SW-OPEA&#65292;&#20854;&#20855;&#26377;&#28369;&#21160;&#31383;&#21475;&#26426;&#21046;&#21644;&#26032;&#30340;&#32622;&#20449;&#38598;&#35774;&#35745;&#26469;&#35299;&#20915;&#38750;&#24179;&#31283; MDP &#38382;&#39064;</title><link>http://arxiv.org/abs/2306.00861</link><description>&lt;p&gt;
&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#19979;&#30340;&#38750;&#24179;&#31283;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Non-stationary Reinforcement Learning under General Function Approximation. (arXiv:2306.00861v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00861
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32622;&#20449;&#38598;&#27169;&#22411;&#33258;&#30001;&#31639;&#27861; SW-OPEA&#65292;&#20854;&#20855;&#26377;&#28369;&#21160;&#31383;&#21475;&#26426;&#21046;&#21644;&#26032;&#30340;&#32622;&#20449;&#38598;&#35774;&#35745;&#26469;&#35299;&#20915;&#38750;&#24179;&#31283; MDP &#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#26159;&#22788;&#29702;&#24191;&#27867;&#24378;&#21270;&#23398;&#20064;&#22330;&#26223;&#20013;&#30340;&#22823;&#29366;&#24577;&#21644;&#21160;&#20316;&#31354;&#38388;&#30340;&#19968;&#31181;&#24378;&#26377;&#21147;&#30340;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#20855;&#26377;&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#30340;&#38750;&#24179;&#31283;MDP&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#26377;&#38480;&#12290;&#26412;&#25991;&#39318;&#27425;&#23581;&#35797;&#35299;&#20915;&#27492;&#38382;&#39064;&#12290;&#25105;&#20204;&#39318;&#20808;&#20026;&#38750;&#24179;&#31283;MDP&#25552;&#20986;&#20102;&#19968;&#20010;&#31216;&#20026;&#21160;&#24577;&#36125;&#23572;&#26364;&#38590;&#24230;&#32500;&#25968;&#65288;DBE&#65289;&#30340;&#26032;&#22797;&#26434;&#24230;&#24230;&#37327;&#65292;&#35813;&#24230;&#37327;&#21253;&#21547;&#38745;&#24577;MDP&#20013;&#22823;&#22810;&#25968;&#29616;&#26377;&#26131;&#22788;&#29702;&#30340;RL&#38382;&#39064;&#20197;&#21450;&#38750;&#24179;&#31283;MDP&#12290;&#22522;&#20110;&#25152;&#25552;&#20986;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32622;&#20449;&#38598;&#27169;&#22411;&#33258;&#30001;&#31639;&#27861;SW-OPEA, &#20854;&#20855;&#26377;&#28369;&#21160;&#31383;&#21475;&#26426;&#21046;&#21644;&#26032;&#30340;&#32622;&#20449;&#38598;&#35774;&#35745;&#26469;&#35299;&#20915;&#38750;&#24179;&#31283;MDP&#38382;&#39064;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#25152;&#25552;&#20986;&#31639;&#27861;&#30340;&#21160;&#24577;&#21518;&#24724;&#19978;&#30028;&#65292;&#24182;&#34920;&#26126;&#65292;&#21482;&#35201;&#21464;&#21270;&#39044;&#31639;&#19981;&#26159;&#26174;&#33879;&#22823;&#65292;SW-OPEA&#21487;&#20197;&#35777;&#26126;&#26159;&#26377;&#25928;&#30340;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#38750;&#24179;&#31283;&#32447;&#24615;&#21644;&#34920;&#26684;&#21270;&#29615;&#22659;&#30340;&#31034;&#20363;&#35777;&#26126;&#65292;SW-OPEA&#21487;&#20197;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#26377;&#25928;&#22320;&#23398;&#20064;&#25509;&#36817;&#26368;&#20248;&#31574;&#30053;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
General function approximation is a powerful tool to handle large state and action spaces in a broad range of reinforcement learning (RL) scenarios. However, theoretical understanding of non-stationary MDPs with general function approximation is still limited. In this paper, we make the first such an attempt. We first propose a new complexity metric called dynamic Bellman Eluder (DBE) dimension for non-stationary MDPs, which subsumes majority of existing tractable RL problems in static MDPs as well as non-stationary MDPs. Based on the proposed complexity metric, we propose a novel confidence-set based model-free algorithm called SW-OPEA, which features a sliding window mechanism and a new confidence set design for non-stationary MDPs. We then establish an upper bound on the dynamic regret for the proposed algorithm, and show that SW-OPEA is provably efficient as long as the variation budget is not significantly large. We further demonstrate via examples of non-stationary linear and tab
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20026;&#25439;&#22833;&#26368;&#23567;&#21270;&#20998;&#31867;&#26641;&#30340;&#35299;&#20915;&#25552;&#20379;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#22522;&#20110;&#36923;&#36753;&#26031;&#33922;&#22238;&#24402;&#30340;&#35299;&#20915;&#26041;&#24335;&#20855;&#26377;&#20855;&#26377;&#35299;&#37322;&#24615;&#29305;&#24449;&#21644;&#31454;&#20105;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2306.00857</link><description>&lt;p&gt;
&#25439;&#22833;&#26368;&#23567;&#21270;&#20998;&#31867;&#26641;&#65306;&#19968;&#20010;&#36890;&#29992;&#30340;&#26694;&#26550;&#21644;&#36923;&#36753;&#26031;&#33922;&#22238;&#24402;&#24773;&#20917;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Loss-Optimal Classification Trees: A Generalized Framework and the Logistic Case. (arXiv:2306.00857v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00857
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20026;&#25439;&#22833;&#26368;&#23567;&#21270;&#20998;&#31867;&#26641;&#30340;&#35299;&#20915;&#25552;&#20379;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#22522;&#20110;&#36923;&#36753;&#26031;&#33922;&#22238;&#24402;&#30340;&#35299;&#20915;&#26041;&#24335;&#20855;&#26377;&#20855;&#26377;&#35299;&#37322;&#24615;&#29305;&#24449;&#21644;&#31454;&#20105;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#31867;&#26641;&#26159;&#21487;&#35299;&#37322;&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#24120;&#35265;&#30340;&#27169;&#22411;&#20043;&#19968;&#65292;&#23613;&#31649;&#36825;&#26679;&#30340;&#27169;&#22411;&#36890;&#24120;&#37319;&#29992;&#36138;&#23146;&#31574;&#30053;&#26500;&#24314;&#65292;&#20294;&#26159;&#36817;&#24180;&#26469;&#65292;&#30001;&#20110;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010;&#65288;MIP&#65289;&#27714;&#35299;&#22120;&#30340;&#26174;&#33879;&#36827;&#23637;&#65292;&#24050;&#32463;&#24320;&#21457;&#20102;&#20960;&#31181;&#31934;&#30830;&#30340;&#23398;&#20064;&#38382;&#39064;&#30340;&#34920;&#36848;&#12290;&#26412;&#25991;&#35748;&#20026;&#20854;&#20013;&#19968;&#20123;&#26368;&#30456;&#20851;&#30340;&#35757;&#32451;&#27169;&#22411;&#21487;&#20197;&#23553;&#35013;&#22312;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#20869;&#65292;&#20854;&#23454;&#20363;&#30001;&#25439;&#22833;&#20989;&#25968;&#21644;&#27491;&#21017;&#21270;&#22120;&#30340;&#35268;&#23450;&#22609;&#36896;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#36825;&#20010;&#26694;&#26550;&#30340;&#26032;&#39062;&#23454;&#29616;&#65306;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#32771;&#34385;&#36923;&#36753;&#25439;&#22833;&#65292;&#23427;&#22312;MIP&#35774;&#32622;&#20013;&#36890;&#36807;&#32447;&#24615;&#20998;&#27573;&#36924;&#36817;&#22788;&#29702;&#65292;&#24182;&#19982;$\ell_1$-&#35268;&#21017;&#21270;&#39033;&#30456;&#32467;&#21512;&#12290;&#26368;&#32456;&#30340;&#26368;&#20248;&#36923;&#36753;&#26641;&#27169;&#22411;&#22312;&#25968;&#20540;&#19978;&#34987;&#35777;&#26126;&#33021;&#22815;&#35825;&#23548;&#20855;&#26377;&#22686;&#24378;&#21487;&#35299;&#37322;&#24615;&#29305;&#24449;&#21644;&#31454;&#20105;&#24615;&#27867;&#21270;&#33021;&#21147;&#30340;&#26641;&#65292;&#19982;&#26368;&#20808;&#36827;&#30340;&#22522;&#20110;MIP&#30340;&#26041;&#27861;&#30456;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Classification Tree (CT) is one of the most common models in interpretable machine learning. Although such models are usually built with greedy strategies, in recent years, thanks to remarkable advances in Mixer-Integer Programming (MIP) solvers, several exact formulations of the learning problem have been developed. In this paper, we argue that some of the most relevant ones among these training models can be encapsulated within a general framework, whose instances are shaped by the specification of loss functions and regularizers. Next, we introduce a novel realization of this framework: specifically, we consider the logistic loss, handled in the MIP setting by a linear piece-wise approximation, and couple it with $\ell_1$-regularization terms. The resulting Optimal Logistic Tree model numerically proves to be able to induce trees with enhanced interpretability features and competitive generalization capabilities, compared to the state-of-the-art MIP-based approaches.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#33258;&#19979;&#32780;&#19978;&#31639;&#27861;&#24674;&#22797;Hierarchical Stochastic Block Model&#30340;&#26641;&#24418;&#32467;&#26500;&#21644;&#31038;&#21306;&#32467;&#26500;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#30830;&#23450;&#20102;&#20854;&#22312;&#20013;&#38388;&#23618;&#27425;&#19978;&#36798;&#21040;&#20102;&#30830;&#20999;&#24674;&#22797;&#20449;&#24687;&#29702;&#35770;&#38408;&#20540;&#12290;</title><link>http://arxiv.org/abs/2306.00833</link><description>&lt;p&gt;
&#33258;&#19979;&#32780;&#19978;&#20309;&#26102;&#20987;&#36133;&#33258;&#19978;&#32780;&#19979;&#36827;&#34892;&#20998;&#23618;&#31038;&#21306;&#26816;&#27979;&#65311;
&lt;/p&gt;
&lt;p&gt;
When Does Bottom-up Beat Top-down in Hierarchical Community Detection?. (arXiv:2306.00833v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00833
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#33258;&#19979;&#32780;&#19978;&#31639;&#27861;&#24674;&#22797;Hierarchical Stochastic Block Model&#30340;&#26641;&#24418;&#32467;&#26500;&#21644;&#31038;&#21306;&#32467;&#26500;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#24182;&#30830;&#23450;&#20102;&#20854;&#22312;&#20013;&#38388;&#23618;&#27425;&#19978;&#36798;&#21040;&#20102;&#30830;&#20999;&#24674;&#22797;&#20449;&#24687;&#29702;&#35770;&#38408;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32593;&#32476;&#30340;&#20998;&#23618;&#32858;&#31867;&#26159;&#25351;&#26597;&#25214;&#19968;&#32452;&#31038;&#21306;&#30340;&#26641;&#24418;&#32467;&#26500;&#65292;&#20854;&#20013;&#23618;&#27425;&#32467;&#26500;&#30340;&#36739;&#20302;&#32423;&#21035;&#26174;&#31034;&#26356;&#32454;&#31890;&#24230;&#30340;&#31038;&#21306;&#32467;&#26500;&#12290;&#35299;&#20915;&#36825;&#19968;&#38382;&#39064;&#30340;&#31639;&#27861;&#26377;&#20004;&#20010;&#20027;&#35201;&#31867;&#21035;&#65306;&#33258;&#19978;&#32780;&#19979;&#30340;&#31639;&#27861;&#21644;&#33258;&#19979;&#32780;&#19978;&#30340;&#31639;&#27861;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#33258;&#19979;&#32780;&#19978;&#31639;&#27861;&#24674;&#22797;&#20998;&#23618;&#38543;&#26426;&#22359;&#27169;&#22411;&#30340;&#26641;&#24418;&#32467;&#26500;&#21644;&#31038;&#21306;&#32467;&#26500;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#25105;&#20204;&#36824;&#30830;&#23450;&#20102;&#36825;&#31181;&#33258;&#19979;&#32780;&#19978;&#31639;&#27861;&#22312;&#23618;&#27425;&#32467;&#26500;&#30340;&#20013;&#38388;&#23618;&#27425;&#19978;&#36798;&#21040;&#20102;&#30830;&#20999;&#24674;&#22797;&#20449;&#24687;&#29702;&#35770;&#38408;&#20540;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#36825;&#20123;&#24674;&#22797;&#26465;&#20214;&#30456;&#23545;&#20110;&#29616;&#26377;&#30340;&#33258;&#19978;&#32780;&#19979;&#31639;&#27861;&#30340;&#26465;&#20214;&#26469;&#35828;&#65292;&#38480;&#21046;&#26356;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;
Hierarchical clustering of networks consists in finding a tree of communities, such that lower levels of the hierarchy reveal finer-grained community structures. There are two main classes of algorithms tackling this problem. Divisive ($\textit{top-down}$) algorithms recursively partition the nodes into two communities, until a stopping rule indicates that no further split is needed. In contrast, agglomerative ($\textit{bottom-up}$) algorithms first identify the smallest community structure and then repeatedly merge the communities using a $\textit{linkage}$ method. In this article, we establish theoretical guarantees for the recovery of the hierarchical tree and community structure of a Hierarchical Stochastic Block Model by a bottom-up algorithm. We also establish that this bottom-up algorithm attains the information-theoretic threshold for exact recovery at intermediate levels of the hierarchy. Notably, these recovery conditions are less restrictive compared to those existing for to
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#8220;&#21021;&#22987;&#29468;&#27979;&#20559;&#24046;&#8221;&#29616;&#35937;&#65292;&#21363;&#22312;&#26410;&#32463;&#36807;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#30001;&#20110;&#26550;&#26500;&#36873;&#25321;&#30340;&#24433;&#21709;&#65292;&#27169;&#22411;&#24448;&#24448;&#20250;&#23558;&#25152;&#26377;&#39044;&#27979;&#25351;&#21521;&#21516;&#19968;&#20010;&#31867;&#21035;&#12290;&#35813;&#29616;&#35937;&#23545;&#26550;&#26500;&#36873;&#25321;&#21644;&#21021;&#22987;&#21270;&#26377;&#23454;&#38469;&#25351;&#23548;&#24847;&#20041;&#65292;&#24182;&#20855;&#26377;&#29702;&#35770;&#21518;&#26524;&#65292;&#20363;&#22914;&#33410;&#28857;&#32622;&#25442;&#23545;&#31216;&#24615;&#30340;&#23849;&#28291;&#21644;&#28145;&#24230;&#24102;&#26469;&#30340;&#38750;&#24179;&#20961;&#24046;&#24322;&#12290;</title><link>http://arxiv.org/abs/2306.00809</link><description>&lt;p&gt;
&#21021;&#22987;&#29468;&#27979;&#20559;&#24046;&#65306;&#26410;&#32463;&#36807;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#20542;&#21521;&#20110;&#26576;&#20123;&#31867;&#21035;
&lt;/p&gt;
&lt;p&gt;
Initial Guessing Bias: How Untrained Networks Favor Some Classes. (arXiv:2306.00809v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00809
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#8220;&#21021;&#22987;&#29468;&#27979;&#20559;&#24046;&#8221;&#29616;&#35937;&#65292;&#21363;&#22312;&#26410;&#32463;&#36807;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#30001;&#20110;&#26550;&#26500;&#36873;&#25321;&#30340;&#24433;&#21709;&#65292;&#27169;&#22411;&#24448;&#24448;&#20250;&#23558;&#25152;&#26377;&#39044;&#27979;&#25351;&#21521;&#21516;&#19968;&#20010;&#31867;&#21035;&#12290;&#35813;&#29616;&#35937;&#23545;&#26550;&#26500;&#36873;&#25321;&#21644;&#21021;&#22987;&#21270;&#26377;&#23454;&#38469;&#25351;&#23548;&#24847;&#20041;&#65292;&#24182;&#20855;&#26377;&#29702;&#35770;&#21518;&#26524;&#65292;&#20363;&#22914;&#33410;&#28857;&#32622;&#25442;&#23545;&#31216;&#24615;&#30340;&#23849;&#28291;&#21644;&#28145;&#24230;&#24102;&#26469;&#30340;&#38750;&#24179;&#20961;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#30340;&#21021;&#22987;&#29366;&#24577;&#22312;&#35843;&#33410;&#21518;&#32493;&#30340;&#35757;&#32451;&#36807;&#31243;&#20013;&#25198;&#28436;&#37325;&#35201;&#35282;&#33394;&#12290;&#22312;&#20998;&#31867;&#38382;&#39064;&#30340;&#32972;&#26223;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#29702;&#35770;&#20998;&#26512;&#65292;&#35777;&#26126;&#31070;&#32463;&#32593;&#32476;&#30340;&#32467;&#26500;&#21487;&#20197;&#22312;&#35757;&#32451;&#20043;&#21069;&#65292;&#29978;&#33267;&#22312;&#19981;&#23384;&#22312;&#26174;&#24335;&#20559;&#24046;&#30340;&#24773;&#20917;&#19979;&#65292;&#20351;&#27169;&#22411;&#23558;&#25152;&#26377;&#39044;&#27979;&#37117;&#25351;&#21521;&#21516;&#19968;&#20010;&#31867;&#21035;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#29616;&#35937;&#30340;&#23384;&#22312;&#65292;&#31216;&#20026;&#8220;&#21021;&#22987;&#29468;&#27979;&#20559;&#24046;&#8221;&#65288;Initial Guessing Bias&#65292;IGB&#65289;&#65292;&#36825;&#21462;&#20915;&#20110;&#26550;&#26500;&#36873;&#25321;&#65292;&#20363;&#22914;&#28608;&#27963;&#20989;&#25968;&#12289;&#26368;&#22823;&#27744;&#21270;&#23618;&#21644;&#32593;&#32476;&#28145;&#24230;&#12290;&#25105;&#20204;&#23545;IGB&#36827;&#34892;&#30340;&#20998;&#26512;&#20855;&#26377;&#23454;&#38469;&#24847;&#20041;&#65292;&#21487;&#20197;&#25351;&#23548;&#26550;&#26500;&#30340;&#36873;&#25321;&#21644;&#21021;&#22987;&#21270;&#12290;&#25105;&#20204;&#36824;&#24378;&#35843;&#29702;&#35770;&#21518;&#26524;&#65292;&#20363;&#22914;&#33410;&#28857;&#32622;&#25442;&#23545;&#31216;&#24615;&#30340;&#23849;&#28291;&#12289;&#33258;&#24179;&#22343;&#30340;&#30772;&#22351;&#12289;&#26576;&#20123;&#22343;&#22330;&#36817;&#20284;&#30340;&#26377;&#25928;&#24615;&#20197;&#21450;&#28145;&#24230;&#24102;&#26469;&#30340;&#38750;&#24179;&#20961;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
The initial state of neural networks plays a central role in conditioning the subsequent training dynamics. In the context of classification problems, we provide a theoretical analysis demonstrating that the structure of a neural network can condition the model to assign all predictions to the same class, even before the beginning of training, and in the absence of explicit biases. We show that the presence of this phenomenon, which we call "Initial Guessing Bias" (IGB), depends on architectural choices such as activation functions, max-pooling layers, and network depth. Our analysis of IGB has practical consequences, in that it guides architecture selection and initialization. We also highlight theoretical consequences, such as the breakdown of node-permutation symmetry, the violation of self-averaging, the validity of some mean-field approximations, and the non-trivial differences arising with depth.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;transformers&#22914;&#20309;&#24179;&#34913;&#20840;&#23616;&#20998;&#24067;&#21644;&#19978;&#19979;&#25991;&#29305;&#23450;&#20998;&#24067;&#30340;&#20004;&#31181;&#30693;&#35782;&#31867;&#22411;&#65292;&#24182;&#25552;&#20379;&#20102;&#26377;&#20851;&#26435;&#20540;&#30697;&#38453;&#20316;&#20026;&#32852;&#24819;&#35760;&#24518;&#30340;&#20316;&#29992;&#21450;&#26799;&#24230;&#22914;&#20309;&#23454;&#29616;&#26435;&#37325;&#23398;&#20064;&#30340;&#29702;&#35770;&#35265;&#35299;&#12290;</title><link>http://arxiv.org/abs/2306.00802</link><description>&lt;p&gt;
&#19968;&#31181;&#35760;&#24518;&#35270;&#35282;&#19979;&#30340;Transformer&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Birth of a Transformer: A Memory Viewpoint. (arXiv:2306.00802v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00802
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;transformers&#22914;&#20309;&#24179;&#34913;&#20840;&#23616;&#20998;&#24067;&#21644;&#19978;&#19979;&#25991;&#29305;&#23450;&#20998;&#24067;&#30340;&#20004;&#31181;&#30693;&#35782;&#31867;&#22411;&#65292;&#24182;&#25552;&#20379;&#20102;&#26377;&#20851;&#26435;&#20540;&#30697;&#38453;&#20316;&#20026;&#32852;&#24819;&#35760;&#24518;&#30340;&#20316;&#29992;&#21450;&#26799;&#24230;&#22914;&#20309;&#23454;&#29616;&#26435;&#37325;&#23398;&#20064;&#30340;&#29702;&#35770;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;Transformer&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#21462;&#24471;&#20102;&#24040;&#22823;&#30340;&#23454;&#35777;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#38543;&#30528;&#23427;&#20204;&#34987;&#24191;&#27867;&#37096;&#32626;&#65292;&#36234;&#26469;&#36234;&#38656;&#35201;&#26356;&#22909;&#22320;&#29702;&#35299;&#23427;&#20204;&#30340;&#20869;&#37096;&#26426;&#21046;&#20197;&#20351;&#23427;&#20204;&#26356;&#21152;&#21487;&#38752;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;transformers&#22914;&#20309;&#36890;&#36807;&#32771;&#34385;&#19968;&#20010;&#21512;&#25104;&#30340;&#35774;&#32622;&#26469;&#24179;&#34913;&#23384;&#20648;&#20110;&#23427;&#20204;&#20043;&#20013;&#30340;&#20004;&#31181;&#30693;&#35782;&#31867;&#22411;&#8212;&#8212;&#20840;&#23616;&#20998;&#24067;&#21644;&#19978;&#19979;&#25991;&#29305;&#23450;&#30340;&#20108;&#20803;&#20998;&#24067;&#12290;&#36890;&#36807;&#23545;&#31616;&#21270;&#30340;&#20004;&#23618;Transformer&#30340;&#35757;&#32451;&#36807;&#31243;&#36827;&#34892;&#20180;&#32454;&#30340;&#23454;&#35777;&#20998;&#26512;&#65292;&#25105;&#20204;&#38416;&#36848;&#20102;&#23545;&#20840;&#23616;&#20108;&#20803;&#20998;&#24067;&#30340;&#24555;&#36895;&#23398;&#20064;&#20197;&#21450;&#23545;&#19978;&#19979;&#25991;&#20013;&#30340;&#20108;&#20803;&#20998;&#24067;&#30340;"&#24402;&#32435;&#22836;"&#26426;&#21046;&#30340;&#36739;&#24930;&#21457;&#23637;&#12290;&#25105;&#20204;&#24378;&#35843;&#20102;&#26435;&#20540;&#30697;&#38453;&#20316;&#20026;&#32852;&#24819;&#35760;&#24518;&#30340;&#20316;&#29992;&#65292;&#25552;&#20379;&#20102;&#29702;&#35770;&#19978;&#30340;&#35265;&#35299;&#65292;&#35828;&#26126;&#20102;&#26799;&#24230;&#22914;&#20309;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#23454;&#29616;&#26435;&#37325;&#30340;&#23398;&#20064;&#65292;&#24182;&#30740;&#31350;&#20102;&#25968;&#25454;&#20998;&#24067;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models based on transformers have achieved great empirical successes. However, as they are deployed more widely, there is a growing need to better understand their internal mechanisms in order to make them more reliable. These models appear to store vast amounts of knowledge from their training data, and to adapt quickly to new information provided in their context or prompt. We study how transformers balance these two types of knowledge by considering a synthetic setup where tokens are generated from either global or context-specific bigram distributions. By a careful empirical analysis of the training process on a simplified two-layer transformer, we illustrate the fast learning of global bigrams and the slower development of an "induction head" mechanism for the in-context bigrams. We highlight the role of weight matrices as associative memories, provide theoretical insights on how gradients enable their learning during training, and study the role of data-distributio
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;RKHS&#36924;&#36817;&#26041;&#27861;&#65292;&#25581;&#31034;&#20102;&#33258;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#20013;&#22909;&#30340;&#25968;&#25454;&#22686;&#24378;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#38416;&#36848;&#20102;&#23545;&#20110;&#20219;&#24847;&#32534;&#30721;&#22120;&#65292;&#22686;&#24191;&#20989;&#25968;&#36136;&#37327;&#30340;&#25552;&#21319;&#21487;&#20197;&#25552;&#39640;&#32534;&#30721;&#22120;&#30340;&#34920;&#31034;&#33021;&#21147;&#65292;&#21516;&#26102;&#20998;&#26512;&#20102;&#25209;&#37327;&#24402;&#19968;&#21270;&#21644;&#25968;&#25454;&#22686;&#24378;&#22312;&#33258;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2306.00788</link><description>&lt;p&gt;
&#36890;&#36807;RKHS&#36924;&#36817;&#29702;&#35299;&#22522;&#20110;&#22686;&#24191;&#30340;&#33258;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Understanding Augmentation-based Self-Supervised Representation Learning via RKHS Approximation. (arXiv:2306.00788v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00788
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;RKHS&#36924;&#36817;&#26041;&#27861;&#65292;&#25581;&#31034;&#20102;&#33258;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#20013;&#22909;&#30340;&#25968;&#25454;&#22686;&#24378;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#38416;&#36848;&#20102;&#23545;&#20110;&#20219;&#24847;&#32534;&#30721;&#22120;&#65292;&#22686;&#24191;&#20989;&#25968;&#36136;&#37327;&#30340;&#25552;&#21319;&#21487;&#20197;&#25552;&#39640;&#32534;&#30721;&#22120;&#30340;&#34920;&#31034;&#33021;&#21147;&#65292;&#21516;&#26102;&#20998;&#26512;&#20102;&#25209;&#37327;&#24402;&#19968;&#21270;&#21644;&#25968;&#25454;&#22686;&#24378;&#22312;&#33258;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22909;&#30340;&#25968;&#25454;&#22686;&#24378;&#26159;&#33258;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#65288;&#22914;&#23545;&#27604;&#23398;&#20064;&#21644;&#25513;&#30721;&#35821;&#35328;&#24314;&#27169;&#65289;&#23454;&#29616;&#32463;&#39564;&#25104;&#21151;&#30340;&#20851;&#38190;&#22240;&#32032;&#20043;&#19968;&#65292;&#20294;&#20854;&#22312;&#23398;&#20064;&#22909;&#30340;&#34920;&#31034;&#26041;&#38754;&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#26377;&#38480;&#12290;&#26368;&#36817;&#30340;&#24037;&#20316;&#24314;&#31435;&#20102;&#33258;&#30417;&#30563;&#23398;&#20064;&#21644;&#36924;&#36817;&#22270;&#25289;&#26222;&#25289;&#26031;&#31639;&#23376;&#30340;&#39030;&#37096;&#29305;&#24449;&#31354;&#38388;&#20043;&#38388;&#30340;&#32852;&#31995;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#36825;&#19968;&#27934;&#23519;&#21147;&#23545;&#22522;&#20110;&#22686;&#24191;&#30340;&#39044;&#35757;&#32451;&#36827;&#34892;&#32479;&#35745;&#20998;&#26512;&#12290;&#25105;&#20204;&#20174;&#20445;&#25345;&#31561;&#36317;&#30340;&#23646;&#24615;&#20986;&#21457;&#65292;&#36825;&#26159;&#30001;&#22686;&#24378;&#32473;&#20986;&#30340;&#30446;&#26631;&#20989;&#25968;&#30340;&#20851;&#38190;&#20960;&#20309;&#29305;&#24449;&#12290;&#25105;&#20204;&#30340;&#31532;&#19968;&#20027;&#35201;&#23450;&#29702;&#20026;&#20219;&#24847;&#32534;&#30721;&#22120;&#25552;&#20379;&#20102;&#25509;&#36817;&#32039;&#23494;&#30340;&#19978;&#38480;&#65292;&#29992;&#20110;&#20272;&#35745;&#36890;&#36807;&#22312;&#32534;&#30721;&#22120;&#20043;&#19978;&#25311;&#21512;&#32447;&#24615;&#25506;&#27979;&#22120;&#32780;&#20135;&#29983;&#30340;&#20272;&#35745;&#35823;&#24046;&#21644;&#32534;&#30721;&#22120;&#23398;&#20064;&#30340;RKHS&#30340;&#36924;&#36817;&#35823;&#24046;&#12290;&#25105;&#20204;&#30340;&#31532;&#20108;&#20010;&#20027;&#35201;&#23450;&#29702;&#34920;&#26126;&#65292;&#22312;&#28201;&#21644;&#26465;&#20214;&#19979;&#65292;&#21487;&#20197;&#36890;&#36807;RKHS&#20989;&#25968;&#20219;&#24847;&#31934;&#30830;&#22320;&#36924;&#36817;&#22686;&#24191;&#20989;&#25968;&#12290;&#36825;&#20010;&#32467;&#26524;&#24847;&#21619;&#30528;&#65292;&#38543;&#30528;&#22686;&#24191;&#20989;&#25968;&#36136;&#37327;&#30340;&#25552;&#39640;&#65292;&#23398;&#20064;&#30340;&#32534;&#30721;&#22120;&#30340;&#34920;&#31034;&#33021;&#21147;&#20063;&#20250;&#25552;&#39640;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#36824;&#25581;&#31034;&#20102;&#33258;&#30417;&#30563;&#23398;&#20064;&#20013;&#25209;&#37327;&#24402;&#19968;&#21270;&#21644;&#25968;&#25454;&#22686;&#24378;&#30340;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
Good data augmentation is one of the key factors that lead to the empirical success of self-supervised representation learning such as contrastive learning and masked language modeling, yet theoretical understanding of its role in learning good representations remains limited. Recent work has built the connection between self-supervised learning and approximating the top eigenspace of a graph Laplacian operator. Learning a linear probe on top of such features can naturally be connected to RKHS regression. In this work, we use this insight to perform a statistical analysis of augmentation-based pretraining. We start from the isometry property, a key geometric characterization of the target function given by the augmentation. Our first main theorem provides, for an arbitrary encoder, near tight bounds for both the estimation error incurred by fitting the linear probe on top of the encoder, and the approximation error entailed by the fitness of the RKHS the encoder learns. Our second main
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35752;&#35770;&#20102;&#22312;&#39640;&#38454;&#26799;&#24230;&#27491;&#21017;&#21270;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#20013;&#20248;&#21270;&#36776;&#21035;&#22120;&#30340;&#38382;&#39064;&#65292;&#21457;&#29616;&#26368;&#20248;&#36776;&#21035;&#22120;&#38382;&#39064;&#26159;$n$&#32500;&#20869;&#25554;&#38382;&#39064;&#65292;&#24182;&#20351;&#29992;&#22810;&#39033;RBF&#20869;&#25554;&#38381;&#24335;&#27714;&#35299;&#65292;&#23454;&#29616;&#26356;&#20248;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.00785</link><description>&lt;p&gt;
&#25968;&#25454;&#20869;&#25554;&#22120;&#8212;&#8212;&#39640;&#38454;&#26799;&#24230;&#27491;&#21017;&#21270;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#20013;&#30340;&#36776;&#21035;&#22120;
&lt;/p&gt;
&lt;p&gt;
Data Interpolants -- That's What Discriminators in Higher-order Gradient-regularized GANs Are. (arXiv:2306.00785v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00785
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35752;&#35770;&#20102;&#22312;&#39640;&#38454;&#26799;&#24230;&#27491;&#21017;&#21270;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#20013;&#20248;&#21270;&#36776;&#21035;&#22120;&#30340;&#38382;&#39064;&#65292;&#21457;&#29616;&#26368;&#20248;&#36776;&#21035;&#22120;&#38382;&#39064;&#26159;$n$&#32500;&#20869;&#25554;&#38382;&#39064;&#65292;&#24182;&#20351;&#29992;&#22810;&#39033;RBF&#20869;&#25554;&#38381;&#24335;&#27714;&#35299;&#65292;&#23454;&#29616;&#26356;&#20248;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#22312;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#20013;&#23545;&#36776;&#21035;&#22120;&#36827;&#34892;&#39640;&#38454;&#26799;&#24230;&#27491;&#21017;&#21270;&#20248;&#21270;&#30340;&#38382;&#39064;&#12290;&#36890;&#36807;&#26368;&#23567;&#20108;&#20056;&#65288;LSGAN&#65289;&#21644;Wasserstein&#65288;WGAN&#65289; GAN&#21464;&#20307;&#30340;&#20998;&#26512;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36776;&#21035;&#22120;&#20248;&#21270;&#38382;&#39064;&#26159;n&#32500;&#20869;&#25554;&#38382;&#39064;&#12290;&#36890;&#36807;&#21464;&#20998;&#24494;&#31215;&#20998;&#23548;&#20986;&#30340;&#26368;&#20248;&#36776;&#21035;&#22120;&#65292;&#23454;&#38469;&#19978;&#25104;&#20026;&#28041;&#21450;&#36845;&#20195;&#30340;Laplacian&#25110;polyharmonic&#31639;&#23376;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#35299;&#12290;&#36890;&#36807;polyharmonic&#31639;&#23376;&#30340;&#32852;&#31995;&#65292;&#25105;&#20204;&#31216;&#23545;&#24212;&#30340;GAN&#20026;Poly-LSGAN&#21644;Poly-WGAN&#65292;&#24182;&#36890;&#36807;&#22312;&#22810;&#20803;&#39640;&#26031;&#19978;&#30340;&#23454;&#39564;&#39564;&#35777;&#34920;&#26126;&#65292;&#20351;&#29992;&#38381;&#24335;RBF&#20869;&#25554;&#23454;&#29616;&#26368;&#20248;&#36776;&#21035;&#22120;&#65292;&#24809;&#32602;&#38454;&#25968;$m \approx\lceil \frac{n}{2} \rceil$&#65292;&#21487;&#20197;&#33719;&#24471;&#26356;&#20248;&#24322;&#30340;&#24615;&#33021;&#65292;&#30456;&#27604;&#20110;&#29992;&#20219;&#24847;&#36873;&#25321;&#30340;&#36776;&#21035;&#22120;&#36827;&#34892;&#35757;&#32451;&#30340;GAN&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of optimizing the discriminator in generative adversarial networks (GANs) subject to higher-order gradient regularization. We show analytically, via the least-squares (LSGAN) and Wasserstein (WGAN) GAN variants, that the discriminator optimization problem is one of interpolation in $n$-dimensions. The optimal discriminator, derived using variational Calculus, turns out to be the solution to a partial differential equation involving the iterated Laplacian or the polyharmonic operator. The solution is implementable in closed-form via polyharmonic radial basis function (RBF) interpolation. In view of the polyharmonic connection, we refer to the corresponding GANs as Poly-LSGAN and Poly-WGAN. Through experimental validation on multivariate Gaussians, we show that implementing the optimal RBF discriminator in closed-form, with penalty orders $m \approx\lceil \frac{n}{2} \rceil $, results in superior performance, compared to training GAN with arbitrarily chosen discri
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31471;&#21040;&#31471;&#30340;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#65292;&#21487;&#20197;&#21516;&#26102;&#36827;&#34892;&#32570;&#22833;&#20540;&#25554;&#34917;&#21644;&#39044;&#27979;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#27169;&#22411;&#22312;&#36825;&#20004;&#20010;&#20219;&#21153;&#19978;&#34920;&#29616;&#33391;&#22909;&#12290;</title><link>http://arxiv.org/abs/2306.00778</link><description>&lt;p&gt;
&#19968;&#31181;&#31471;&#21040;&#31471;&#30340;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#65292;&#21516;&#26102;&#36827;&#34892;&#32570;&#22833;&#20540;&#25554;&#34917;&#21644;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
An End-to-End Time Series Model for Simultaneous Imputation and Forecast. (arXiv:2306.00778v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00778
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31471;&#21040;&#31471;&#30340;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#65292;&#21487;&#20197;&#21516;&#26102;&#36827;&#34892;&#32570;&#22833;&#20540;&#25554;&#34917;&#21644;&#39044;&#27979;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#27169;&#22411;&#22312;&#36825;&#20004;&#20010;&#20219;&#21153;&#19978;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#21382;&#21490;&#25968;&#25454;&#36827;&#34892;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#19968;&#30452;&#26159;&#19968;&#20010;&#26377;&#36259;&#19988;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#35838;&#39064;&#65292;&#23588;&#20854;&#26159;&#24403;&#25968;&#25454;&#34987;&#32570;&#22833;&#20540;&#25439;&#22351;&#26102;&#12290;&#22312;&#35768;&#22810;&#24037;&#19994;&#38382;&#39064;&#20013;&#65292;&#23398;&#20064;&#36741;&#21161;&#35266;&#27979;&#21644;&#30446;&#26631;&#21464;&#37327;&#20043;&#38388;&#30340;&#25512;&#29702;&#20989;&#25968;&#38750;&#24120;&#37325;&#35201;&#65292;&#22240;&#20026;&#24403;&#25968;&#25454;&#26410;&#23436;&#20840;&#35266;&#27979;&#21040;&#26102;&#65292;&#23427;&#25552;&#20379;&#20102;&#39069;&#22806;&#30340;&#30693;&#35782;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#31471;&#21040;&#31471;&#30340;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#65292;&#26088;&#22312;&#23398;&#20064;&#36825;&#31181;&#25512;&#29702;&#20851;&#31995;&#24182;&#36827;&#34892;&#22810;&#27493;&#39044;&#27979;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21516;&#26102;&#35757;&#32451;&#20004;&#20010;&#31070;&#32463;&#32593;&#32476;&#65292;&#19968;&#20010;&#29992;&#20110;&#23398;&#20064;&#29305;&#24449;&#30456;&#20851;&#24615;&#65292;&#21478;&#19968;&#20010;&#29992;&#20110;&#24314;&#27169;&#26102;&#38388;&#34892;&#20026;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#33021;&#22815;&#21516;&#26102;&#25554;&#34917;&#32570;&#22833;&#26465;&#30446;&#24182;&#36827;&#34892;&#22810;&#27493;&#39044;&#27979;&#12290;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#22312;&#25554;&#34917;&#21644;&#39044;&#27979;&#20219;&#21153;&#30340;&#25972;&#20307;&#34920;&#29616;&#37117;&#24456;&#22909;&#65292;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Time series forecasting using historical data has been an interesting and challenging topic, especially when the data is corrupted by missing values. In many industrial problem, it is important to learn the inference function between the auxiliary observations and target variables as it provides additional knowledge when the data is not fully observed. We develop an end-to-end time series model that aims to learn the such inference relation and make a multiple-step ahead forecast. Our framework trains jointly two neural networks, one to learn the feature-wise correlations and the other for the modeling of temporal behaviors. Our model is capable of simultaneously imputing the missing entries and making a multiple-step ahead prediction. The experiments show good overall performance of our framework over existing methods in both imputation and forecasting tasks.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#28508;&#22312;&#25193;&#25955;&#36807;&#31243;&#20013;&#25512;&#26029;&#21644;&#37319;&#26679;&#28857;&#36807;&#31243;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#23558;&#36830;&#32493;&#36335;&#24452;&#31354;&#38388;&#20013;&#30340;&#25193;&#25955;&#36820;&#22238;&#26102;&#38388;&#19982;&#28857;&#36807;&#31243;&#30340;&#26032;&#21040;&#36798;&#30456;&#20851;&#32852;&#65292;&#20026;&#35768;&#22810;&#23398;&#31185;&#20013;&#30340;&#28857;&#36807;&#31243;&#25552;&#20379;&#20102;&#22522;&#30784;&#12290;</title><link>http://arxiv.org/abs/2306.00762</link><description>&lt;p&gt;
&#20174;&#25193;&#25955;&#36807;&#31243;&#20013;&#30340;&#28418;&#31227;&#25512;&#26029;&#21644;&#37319;&#26679;&#28857;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Inference and Sampling of Point Processes from Diffusion Excursions. (arXiv:2306.00762v1 [stat.CO])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00762
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#28508;&#22312;&#25193;&#25955;&#36807;&#31243;&#20013;&#25512;&#26029;&#21644;&#37319;&#26679;&#28857;&#36807;&#31243;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#23558;&#36830;&#32493;&#36335;&#24452;&#31354;&#38388;&#20013;&#30340;&#25193;&#25955;&#36820;&#22238;&#26102;&#38388;&#19982;&#28857;&#36807;&#31243;&#30340;&#26032;&#21040;&#36798;&#30456;&#20851;&#32852;&#65292;&#20026;&#35768;&#22810;&#23398;&#31185;&#20013;&#30340;&#28857;&#36807;&#31243;&#25552;&#20379;&#20102;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28857;&#36807;&#31243;&#36890;&#24120;&#21487;&#20197;&#36890;&#36807;&#19982;&#36830;&#32493;&#36807;&#31243;&#30340;&#20851;&#31995;&#36827;&#34892;&#33258;&#28982;&#35299;&#37322;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25551;&#36848;&#21040;&#36798;&#26102;&#38388;&#35266;&#27979;&#30340;&#28857;&#36807;&#31243;&#26500;&#24314;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20351;&#29992;&#28508;&#22312;&#25193;&#25955;&#36807;&#31243;&#30340;&#29366;&#24577;&#26469;&#25551;&#36848;&#12290;&#22312;&#27492;&#26694;&#26550;&#20013;&#65292;&#25105;&#20204;&#23558;&#25193;&#25955;&#30340;&#36820;&#22238;&#26102;&#38388;&#19982;&#28857;&#36807;&#31243;&#30340;&#26032;&#21040;&#36798;&#30456;&#20851;&#32852;&#12290;&#36825;&#23548;&#33268;&#20102;&#19968;&#20010;&#36830;&#32493;&#26679;&#26412;&#36335;&#24452;&#65292;&#29992;&#20110;&#25551;&#36848;&#29983;&#25104;&#21040;&#36798;&#20998;&#24067;&#30340;&#22522;&#30784;&#26426;&#21046;&#12290;&#36825;&#20123;&#27169;&#22411;&#22312;&#35768;&#22810;&#23398;&#31185;&#20013;&#20986;&#29616;&#65292;&#20363;&#22914;&#37329;&#34701;&#39046;&#22495;&#65292;&#22312;&#35813;&#39046;&#22495;&#20013;&#65292;&#24066;&#22330;&#19978;&#30340;&#34892;&#21160;&#30001;&#38544;&#34255;&#30340;&#36830;&#32493;&#20215;&#26684;&#20915;&#23450;&#65292;&#25110;&#32773;&#22312;&#31070;&#32463;&#31185;&#23398;&#20013;&#65292;&#28508;&#22312;&#30340;&#21050;&#28608;&#29983;&#25104;&#23574;&#23792;&#21015;&#12290;&#22522;&#20110;&#20234;&#34276;&#28418;&#31227;&#29702;&#35770;&#30340;&#21457;&#23637;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20174;&#28508;&#22312;&#25193;&#25955;&#36807;&#31243;&#27966;&#29983;&#30340;&#28857;&#36807;&#31243;&#30340;&#25512;&#26029;&#21644;&#37319;&#26679;&#26041;&#27861;&#12290;&#25105;&#20204;&#20351;&#29992;&#27169;&#25311;&#21644;&#23454;&#38469;&#25968;&#25454;&#30340;&#25968;&#23383;&#31034;&#20363;&#35828;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#24212;&#29992;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21644;&#26694;&#26550;&#20026;&#35299;&#37322;&#35768;&#22810;&#28857;&#36807;&#31243;&#25552;&#20379;&#20102;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
Point processes often have a natural interpretation with respect to a continuous process. We propose a point process construction that describes arrival time observations in terms of the state of a latent diffusion process. In this framework, we relate the return times of a diffusion in a continuous path space to new arrivals of the point process. This leads to a continuous sample path that is used to describe the underlying mechanism generating the arrival distribution. These models arise in many disciplines, such as financial settings where actions in a market are determined by a hidden continuous price or in neuroscience where a latent stimulus generates spike trains. Based on the developments in It\^o's excursion theory, we propose methods for inferring and sampling from the point process derived from the latent diffusion process. We illustrate the approach with numerical examples using both simulated and real data. The proposed methods and framework provide a basis for interpretin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20004;&#31181;&#26032;&#30340;&#35889;&#23884;&#20837;&#26041;&#27861;&#65292;&#19968;&#31181;&#22522;&#20110;&#20989;&#25968;&#20998;&#26512;&#21407;&#29702;&#21644;&#26680;&#26041;&#27861;&#65292;&#21478;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#32593;&#32476;&#20248;&#21270;&#25439;&#22833;&#65292;&#25552;&#20379;&#29702;&#35770;&#20445;&#35777;&#21644;&#23454;&#38469;&#26377;&#25928;&#30340;&#31639;&#27861;&#65292;&#24182;&#25552;&#20379;&#26032;&#30340;&#37319;&#26679;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.00742</link><description>&lt;p&gt;
&#22522;&#20110;&#35889;&#23884;&#20837;&#30340;&#28145;&#24230;&#23398;&#20064;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Going Deeper with Spectral Embeddings. (arXiv:2306.00742v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00742
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20004;&#31181;&#26032;&#30340;&#35889;&#23884;&#20837;&#26041;&#27861;&#65292;&#19968;&#31181;&#22522;&#20110;&#20989;&#25968;&#20998;&#26512;&#21407;&#29702;&#21644;&#26680;&#26041;&#27861;&#65292;&#21478;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#32593;&#32476;&#20248;&#21270;&#25439;&#22833;&#65292;&#25552;&#20379;&#29702;&#35770;&#20445;&#35777;&#21644;&#23454;&#38469;&#26377;&#25928;&#30340;&#31639;&#27861;&#65292;&#24182;&#25552;&#20379;&#26032;&#30340;&#37319;&#26679;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#26377;&#25928;&#22320;&#22788;&#29702;&#28023;&#37327;&#30340;&#25968;&#25454;&#65292;&#20174;&#32780;&#26356;&#22909;&#22320;&#23545;&#20854;&#36827;&#34892;&#34920;&#24449;&#65292;&#31185;&#23398;&#23478;&#20204;&#37319;&#29992;&#34920;&#31034;&#23398;&#20064;&#12290;&#26368;&#36817;&#65292;&#36825;&#20123;&#26041;&#27861;&#19982;&#19968;&#20123;&#24213;&#23618;&#36816;&#31639;&#30340;&#35889;&#20998;&#35299;&#20043;&#38388;&#23637;&#29616;&#20986;&#26126;&#26174;&#30340;&#32852;&#31995;&#12290;&#22312;&#21382;&#21490;&#19978;&#65292;&#26159;&#36890;&#36807;&#22312;&#25968;&#25454;&#30340;&#39030;&#37096;&#26500;&#24314;&#22270;&#24418;&#26469;&#24314;&#31435;&#26126;&#30830;&#30340;&#35889;&#23884;&#20837;&#65292;&#32780;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#26041;&#27861;&#65306;&#19968;&#31181;&#22522;&#20110;&#20989;&#25968;&#20998;&#26512;&#21407;&#29702;&#21644;&#26680;&#26041;&#27861;&#26500;&#24314;&#30340;&#65292;&#36825;&#23558;&#23548;&#33268;&#20855;&#26377;&#29702;&#35770;&#20445;&#35777;&#30340;&#31639;&#27861;&#65292;&#21478;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#32593;&#32476;&#35757;&#32451;&#20197;&#20248;&#21270;&#22522;&#26412;&#21464;&#20998;&#25439;&#22833;&#30340;&#31639;&#27861;&#65292;&#23427;&#20204;&#20135;&#29983;&#20102;&#23454;&#38469;&#26377;&#25928;&#30340;&#31639;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#37319;&#26679;&#31639;&#27861;&#65292;&#21033;&#29992;&#23398;&#20064;&#21040;&#30340;&#34920;&#24449;&#26469;&#22312;&#19968;&#27493;&#20013;&#29983;&#25104;&#26032;&#30340;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
To make sense of millions of raw data and represent them efficiently, practitioners rely on representation learning. Recently, deep connections have been shown between these approaches and the spectral decompositions of some underlying operators. Historically, explicit spectral embeddings were built from graphs constructed on top of the data. In contrast, we propose two new methods to build spectral embeddings: one based on functional analysis principles and kernel methods, which leads to algorithms with theoretical guarantees, and the other based on deep networks trained to optimize principled variational losses, which yield practically efficient algorithms. Furthermore, we provide a new sampling algorithm that leverages learned representations to generate new samples in a single step.
&lt;/p&gt;</description></item><item><title>&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#35757;&#32451;&#28857;&#21608;&#22260;&#26377;&#22823;&#30340;&#20960;&#20046;&#30830;&#23450;&#30340;&#32622;&#20449;&#37051;&#22495;&#65292;&#36825;&#23548;&#33268;&#29616;&#20195;&#27169;&#22411;&#26657;&#20934;&#38754;&#20020;&#37325;&#35201;&#38556;&#30861;&#12290;</title><link>http://arxiv.org/abs/2306.00740</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#19968;&#33268;&#32622;&#20449;&#29616;&#35937;&#21450;&#20854;&#23545;&#26657;&#20934;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
A Uniform Confidence Phenomenon in Deep Learning and its Implications for Calibration. (arXiv:2306.00740v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00740
&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#35757;&#32451;&#28857;&#21608;&#22260;&#26377;&#22823;&#30340;&#20960;&#20046;&#30830;&#23450;&#30340;&#32622;&#20449;&#37051;&#22495;&#65292;&#36825;&#23548;&#33268;&#29616;&#20195;&#27169;&#22411;&#26657;&#20934;&#38754;&#20020;&#37325;&#35201;&#38556;&#30861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20855;&#26377;&#24778;&#20154;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#20294;&#23427;&#20204;&#23649;&#27425;&#34920;&#29616;&#20986;&#22312;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#26041;&#38754;&#20272;&#35745;&#19981;&#20339;&#30340;&#24773;&#20917;&#8212;&#8212;&#25442;&#21477;&#35805;&#35828;&#65292;&#23427;&#20204;&#22312;&#38169;&#35823;&#26102;&#32463;&#24120;&#36807;&#24230;&#33258;&#20449;&#12290;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#34987;&#31216;&#20026;&#27169;&#22411;&#26657;&#20934;&#65292;&#24182;&#20197;&#20462;&#25913;&#35757;&#32451;&#26041;&#26696;&#21644;&#35757;&#32451;&#21518;&#26657;&#20934;&#31243;&#24207;&#30340;&#24418;&#24335;&#21463;&#21040;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29616;&#20195;&#27169;&#22411;&#26657;&#20934;&#30340;&#37325;&#35201;&#38556;&#30861;&#65306;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#23427;&#20204;&#30340;&#35757;&#32451;&#28857;&#21608;&#22260;&#26377;&#22823;&#30340;&#20960;&#20046;&#30830;&#23450;&#30340;&#32622;&#20449;&#37051;&#22495;&#12290;&#25105;&#20204;&#22312;&#23454;&#39564;&#20013;&#35777;&#26126;&#20102;&#36825;&#31181;&#29616;&#35937;&#22312;&#24456;&#22810;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#23545;&#20013;&#37117;&#20250;&#20986;&#29616;&#65288;&#22312;&#22270;&#20687;&#20998;&#31867;&#30340;&#32972;&#26223;&#19979;&#65289;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#36825;&#31181;&#29616;&#35937;&#20986;&#29616;&#26102;&#65292;&#22312;&#31867;&#21035;&#20043;&#38388;&#23384;&#22312;&#37325;&#21472;&#30340;&#22823;&#31867;&#25968;&#25454;&#20998;&#24067;&#20013;&#65292;&#21363;&#20351;&#22312;&#24212;&#29992;&#26657;&#20934;&#21518;&#20063;&#19981;&#33021;&#33719;&#24471;&#27604;&#38543;&#26426;&#26356;&#22909;&#30340;&#28176;&#36817;&#26657;&#20934;&#27169;&#22411;&#65288;&#22312;&#28176;&#36817;&#24847;&#20041;&#19979;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Despite the impressive generalization capabilities of deep neural networks, they have been repeatedly shown to poorly estimate their predictive uncertainty - in other words, they are frequently overconfident when they are wrong. Fixing this issue is known as model calibration, and has consequently received much attention in the form of modified training schemes and post-training calibration procedures. In this work, we present a significant hurdle to the calibration of modern models: deep neural networks have large neighborhoods of almost certain confidence around their training points. We demonstrate in our experiments that this phenomenon consistently arises (in the context of image classification) across many model and dataset pairs. Furthermore, we prove that when this phenomenon holds, for a large class of data distributions with overlaps between classes, it is not possible to obtain a model that is asymptotically better than random (with respect to calibration) even after applyin
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;$\ell_p$&#23376;&#31354;&#38388;&#23884;&#20837;&#30340;&#28789;&#25935;&#24230;&#37319;&#26679;&#30028;&#38480;&#65292;&#21462;&#24471;&#20102;&#27604;&#36890;&#29992;&#30028;&#38480;&#26356;&#22909;&#30340;&#32467;&#26524;&#65292;&#23545;&#20110;$1\leq p&lt;2$&#30340;&#24773;&#20917;&#19979;&#65292;&#30028;&#38480;&#36798;&#21040;&#20102;$\mathfrak{S}^{2/p}$&#65292;&#23545;&#20110;$2&lt;p&lt;\infty$&#30340;&#24773;&#20917;&#19979;&#65292;&#30028;&#38480;&#36798;&#21040;&#20102;$\mathfrak{S}^{2-2/p}$&#12290;</title><link>http://arxiv.org/abs/2306.00732</link><description>&lt;p&gt;
$\ell_p$&#28789;&#25935;&#24230;&#37319;&#26679;&#30340;&#26356;&#20005;&#26684;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Sharper Bounds for $\ell_p$ Sensitivity Sampling. (arXiv:2306.00732v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00732
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;$\ell_p$&#23376;&#31354;&#38388;&#23884;&#20837;&#30340;&#28789;&#25935;&#24230;&#37319;&#26679;&#30028;&#38480;&#65292;&#21462;&#24471;&#20102;&#27604;&#36890;&#29992;&#30028;&#38480;&#26356;&#22909;&#30340;&#32467;&#26524;&#65292;&#23545;&#20110;$1\leq p&lt;2$&#30340;&#24773;&#20917;&#19979;&#65292;&#30028;&#38480;&#36798;&#21040;&#20102;$\mathfrak{S}^{2/p}$&#65292;&#23545;&#20110;$2&lt;p&lt;\infty$&#30340;&#24773;&#20917;&#19979;&#65292;&#30028;&#38480;&#36798;&#21040;&#20102;$\mathfrak{S}^{2-2/p}$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22823;&#35268;&#27169;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#38543;&#26426;&#37319;&#26679;&#26159;&#19968;&#31181;&#36817;&#20284;&#25968;&#25454;&#38598;&#30340;&#27969;&#34892;&#26041;&#24335;&#65292;&#36825;&#31181;&#26041;&#24335;&#21487;&#20197;&#36890;&#36807;&#19968;&#23567;&#37096;&#20998;&#20855;&#26377;&#20195;&#34920;&#24615;&#30340;&#31034;&#20363;&#26469;&#36827;&#34892;&#12290;&#29305;&#21035;&#22320;&#65292;&#28789;&#25935;&#24230;&#37319;&#26679;&#26159;&#19968;&#31181;&#24378;&#28872;&#30740;&#31350;&#30340;&#25216;&#26415;&#65292;&#23427;&#22312;&#26497;&#20854;&#26222;&#36941;&#30340;&#24773;&#20917;&#19979;&#25552;&#20379;&#21487;&#35777;&#26126;&#30340;&#36817;&#20284;&#36136;&#37327;&#20445;&#35777;&#65292;&#21516;&#26102;&#23558;&#31034;&#20363;&#30340;&#25968;&#37327;&#20943;&#23569;&#21040;VC&#32500;$d$&#21644;&#24635;&#28789;&#25935;&#24230;$\mathfrak{S}$&#30340;&#20056;&#31215;&#12290;&#28982;&#32780;&#65292;&#38500;&#20102;$\ell_2$&#23376;&#31354;&#38388;&#23884;&#20837;&#20197;&#22806;&#65292;&#24456;&#23569;&#26377;&#20445;&#35777;&#36229;&#36807;&#36825;&#20010;$\mathfrak{S}d$&#36890;&#29992;&#30028;&#38480;&#30340;&#30693;&#35782;&#65292;&#23613;&#31649;&#20197;&#21069;&#30340;&#24037;&#20316;&#38750;&#24120;&#24378;&#35843;&#28789;&#25935;&#24230;&#37319;&#26679;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#23637;&#31034;&#20102;&#23545;&#20110;$ p\neq2$&#30340;$\ell_p$&#23376;&#31354;&#38388;&#23884;&#20837;&#30340;&#28789;&#25935;&#24230;&#37319;&#26679;&#30028;&#38480;&#65292;&#36825;&#20123;&#30028;&#38480;&#36229;&#36807;&#20102;&#19968;&#33324;&#30340;$\mathfrak{S}d$&#30028;&#38480;&#65292;&#23545;&#20110;$1\leq p&lt;2$&#65292;&#25105;&#20204;&#21462;&#24471;&#20102;&#22823;&#32422;$\mathfrak{S}^{2/p}$&#30340;&#30028;&#38480;&#65292;&#24182;&#19988;&#23545;&#20110;$2&lt;p&lt;\infty$&#65292;&#21462;&#24471;&#20102;$\mathfrak{S}^{2-2/p}$&#30340;&#30028;&#38480;&#12290;&#22312;$1\leq p&lt;2$&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#34920;&#26126;&#36825;&#20010;&#36793;&#30028;&#26159;&#23494;&#20999;&#30456;&#20851;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
In large scale machine learning, random sampling is a popular way to approximate datasets by a small representative subset of examples. In particular, sensitivity sampling is an intensely studied technique which provides provable guarantees on the quality of approximation, while reducing the number of examples to the product of the VC dimension $d$ and the total sensitivity $\mathfrak S$ in remarkably general settings. However, guarantees going beyond this general bound of $\mathfrak S d$ are known in perhaps only one setting, for $\ell_2$ subspace embeddings, despite intense study of sensitivity sampling in prior work. In this work, we show the first bounds for sensitivity sampling for $\ell_p$ subspace embeddings for $p\neq 2$ that improve over the general $\mathfrak S d$ bound, achieving a bound of roughly $\mathfrak S^{2/p}$ for $1\leq p&lt;2$ and $\mathfrak S^{2-2/p}$ for $2&lt;p&lt;\infty$. For $1\leq p&lt;2$, we show that this bound is tight, in the sense that there exist matrices for which
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#33021;&#37327;&#22522;&#27169;&#22411;&#30340;&#35757;&#32451;&#31639;&#27861;&#65292;&#20351;&#29992;&#24402;&#19968;&#21270;&#27969;&#36827;&#34892;&#37319;&#26679;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#32479;&#35745;&#31934;&#24230;&#21644;&#29983;&#25104;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.00684</link><description>&lt;p&gt;
&#20351;&#29992;&#33258;&#36866;&#24212;&#27969;&#37319;&#26679;&#24179;&#34913;&#35757;&#32451;&#33021;&#37327;&#22522;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Balanced Training of Energy-Based Models with Adaptive Flow Sampling. (arXiv:2306.00684v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00684
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#33021;&#37327;&#22522;&#27169;&#22411;&#30340;&#35757;&#32451;&#31639;&#27861;&#65292;&#20351;&#29992;&#24402;&#19968;&#21270;&#27969;&#36827;&#34892;&#37319;&#26679;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#32479;&#35745;&#31934;&#24230;&#21644;&#29983;&#25104;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33021;&#37327;&#22522;&#27169;&#22411; (EBM) &#26159;&#19968;&#31181;&#30452;&#25509;&#21442;&#25968;&#21270;&#26410;&#26631;&#20934;&#21270;&#23545;&#25968;&#23494;&#24230;&#30340;&#22810;&#21151;&#33021;&#23494;&#24230;&#20272;&#35745;&#27169;&#22411;&#12290;EBM &#38750;&#24120;&#28789;&#27963;&#65292;&#20294;&#32570;&#20047;&#27169;&#22411;&#30340;&#35268;&#33539;&#21270;&#24120;&#37327;&#65292;&#20351;&#27169;&#22411;&#30340;&#20284;&#28982;&#20989;&#25968;&#35745;&#31639;&#19981;&#21487;&#34892;&#12290;&#36817;&#24180;&#26469;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#35768;&#22810;&#36817;&#20284;&#37319;&#26679;&#22120;&#21644;&#21464;&#20998;&#25512;&#29702;&#25216;&#26415;&#26469;&#20272;&#35745;&#20284;&#28982;&#20989;&#25968;&#26799;&#24230;&#36827;&#34892;&#35757;&#32451;&#12290;&#36825;&#20123;&#25216;&#26415;&#22312;&#29983;&#25104;&#26679;&#26412;&#26041;&#38754;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#23545;&#20110;&#20272;&#35745;&#23494;&#24230;&#30340;&#32479;&#35745;&#31934;&#24230;&#65292;&#20363;&#22914;&#30830;&#23450;&#25968;&#25454;&#38598;&#20013;&#19981;&#21516;&#31867;&#30340;&#30456;&#23545;&#37325;&#35201;&#24615;&#65292;&#21364;&#20184;&#20986;&#20102;&#24456;&#23569;&#30340;&#20851;&#27880;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26368;&#22823;&#20284;&#28982;&#35757;&#32451;&#31639;&#27861;&#65292;&#20351;&#29992;&#19968;&#31181;&#19981;&#21516;&#31867;&#22411;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#24402;&#19968;&#21270;&#27969; (NF)&#65292;&#36825;&#31181;&#27169;&#22411;&#26368;&#36817;&#34987;&#25552;&#20986;&#20197;&#20415;&#20110;&#37319;&#26679;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#23558; NF &#25311;&#21512;&#21040; EBM &#19978;&#65292;&#20197;&#20415; NF &#36741;&#21161;&#19979;&#30340;&#37319;&#26679;&#26041;&#26696;&#33021;&#22815;&#22987;&#32456;&#20026; EBM &#25552;&#20379;&#20934;&#30830;&#30340;&#26799;&#24230;&#65292;&#26368;&#32456;&#25552;&#39640;&#27169;&#22411;&#30340;&#32479;&#35745;&#31934;&#24230;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#20256;&#32479; EBM &#35757;&#32451;&#25216;&#26415;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20135;&#29983;&#20102;&#26356;&#39640;&#36136;&#37327;&#30340;&#26679;&#26412;&#21644;&#26356;&#22909;&#30340;&#29983;&#25104;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Energy-based models (EBMs) are versatile density estimation models that directly parameterize an unnormalized log density. Although very flexible, EBMs lack a specified normalization constant of the model, making the likelihood of the model computationally intractable. Several approximate samplers and variational inference techniques have been proposed to estimate the likelihood gradients for training. These techniques have shown promising results in generating samples, but little attention has been paid to the statistical accuracy of the estimated density, such as determining the relative importance of different classes in a dataset. In this work, we propose a new maximum likelihood training algorithm for EBMs that uses a different type of generative model, normalizing flows (NF), which have recently been proposed to facilitate sampling. Our method fits an NF to an EBM during training so that an NF-assisted sampling scheme provides an accurate gradient for the EBMs at all times, ultim
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;&#21487;&#20197;&#23646;&#24615;&#39640;&#25928;&#30340;&#23398;&#20064;&#20302;&#27425;&#22810;&#39033;&#24335;&#38408;&#20540;&#20989;&#25968;&#65292;&#24182;&#33021;&#22815;&#22312;&#22122;&#22768;&#19979;&#36827;&#34892;PAC&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2306.00673</link><description>&lt;p&gt;
&#23646;&#24615;&#39640;&#25928;&#30340;&#20302;&#27425;&#22810;&#39033;&#24335;&#38408;&#20540;&#20989;&#25968;&#24102;&#22122;&#22768;PAC&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Attribute-Efficient PAC Learning of Low-Degree Polynomial Threshold Functions with Nasty Noise. (arXiv:2306.00673v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00673
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;&#21487;&#20197;&#23646;&#24615;&#39640;&#25928;&#30340;&#23398;&#20064;&#20302;&#27425;&#22810;&#39033;&#24335;&#38408;&#20540;&#20989;&#25968;&#65292;&#24182;&#33021;&#22815;&#22312;&#22122;&#22768;&#19979;&#36827;&#34892;PAC&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20302;&#27425;&#22810;&#39033;&#24335;&#38408;&#20540;&#20989;&#25968;&#65288;PTFs&#65289;&#30340;&#27010;&#24565;&#31867;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#36215;&#30528;&#22522;&#30784;&#20316;&#29992;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;$\mathbb{R}^n$&#19978;$K$&#31232;&#30095;&#24230;-$d$ PTFs&#30340;&#23646;&#24615;&#39640;&#25928;PAC&#23398;&#20064;&#65292;&#20854;&#20013;&#20219;&#20309;&#36825;&#26679;&#30340;&#27010;&#24565;&#20165;&#20381;&#36182;&#20110;&#36755;&#20837;&#30340;$K$&#20010;&#23646;&#24615;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#65306;&#25552;&#20986;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;&#22312;&#39640;&#26031;&#36793;&#32536;&#20998;&#24067;&#19979;&#65292;&#21363;&#20351;&#26377;$O(\epsilon^d)$&#30340;$\eta$&#34987;&#24694;&#24847;&#22122;&#22768;Bshouty et al. (2002)&#30772;&#22351;&#65292;&#20063;&#21487;&#20197;&#22312;&#38169;&#35823;&#29575;$\epsilon$&#19979;&#20197;$O(\frac{K^{{4d}}}{\epsilon^{2d}}\cdot \log^{5d} n)$&#30340;&#26679;&#26412;PAC&#23398;&#20064;&#35813;&#31867;&#65292;&#31639;&#27861;&#36816;&#34892;&#26102;&#38388;&#20026;$({nd}/{\epsilon})^{O(d)}$&#12290;&#22312;&#27492;&#20043;&#21069;&#65292;&#20165;&#20026;&#31232;&#30095;&#40784;&#27425;&#36229;&#24179;&#38754;&#30340;&#29305;&#27530;&#24773;&#20917;&#24314;&#31435;&#20102;&#23646;&#24615;&#39640;&#25928;&#30340;&#40065;&#26834;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#20851;&#38190;&#22240;&#32032;&#26159;&#65306;1&#65289;&#23558;&#23646;&#24615;&#31232;&#30095;&#24615;&#36716;&#21270;&#20026;Hermite&#22810;&#39033;&#24335;&#22522;&#19979;chow&#21521;&#37327;&#30340;&#31232;&#30095;&#27169;&#24335;&#30340;&#32467;&#26500;&#32467;&#26524;&#65307;2&#65289;&#19968;&#31181;&#26032;&#30340;&#35268;&#33539;&#21270;&#26041;&#27861;&#65292;&#20197;&#21450;&#21033;&#29992;&#22810;&#39033;&#24335;&#36817;&#20284;&#30340;&#38408;&#20540;&#20989;&#25968;&#30340;&#30452;&#25509;&#21028;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;
The concept class of low-degree polynomial threshold functions (PTFs) plays a fundamental role in machine learning. In this paper, we study PAC learning of $K$-sparse degree-$d$ PTFs on $\mathbb{R}^n$, where any such concept depends only on $K$ out of $n$ attributes of the input. Our main contribution is a new algorithm that runs in time $({nd}/{\epsilon})^{O(d)}$ and under the Gaussian marginal distribution, PAC learns the class up to error rate $\epsilon$ with $O(\frac{K^{4d}}{\epsilon^{2d}} \cdot \log^{5d} n)$ samples even when an $\eta \leq O(\epsilon^d)$ fraction of them are corrupted by the nasty noise of Bshouty et al. (2002), possibly the strongest corruption model. Prior to this work, attribute-efficient robust algorithms are established only for the special case of sparse homogeneous halfspaces. Our key ingredients are: 1) a structural result that translates the attribute sparsity to a sparsity pattern of the Chow vector under the basis of Hermite polynomials, and 2) a novel 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;P-ReLU&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#29992;&#20110;&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#23398;&#20064;&#26368;&#20339;&#31574;&#30053;&#12290;&#35813;&#27169;&#22411;&#21487;&#24179;&#34913;&#25351;&#23548;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#20855;&#26377;&#28789;&#27963;&#24615;&#21644;&#26377;&#25928;&#24615;&#65292;&#22312;&#22810;&#20010;&#22522;&#20934;&#27979;&#35797;&#20013;&#22343;&#36798;&#21040;&#26368;&#20339;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2306.00651</link><description>&lt;p&gt;
&#23398;&#20064;&#25351;&#23548;&#22411;ReLU&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Learning Prescriptive ReLU Networks. (arXiv:2306.00651v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00651
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;P-ReLU&#30340;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#29992;&#20110;&#20174;&#35266;&#27979;&#25968;&#25454;&#20013;&#23398;&#20064;&#26368;&#20339;&#31574;&#30053;&#12290;&#35813;&#27169;&#22411;&#21487;&#24179;&#34913;&#25351;&#23548;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#20855;&#26377;&#28789;&#27963;&#24615;&#21644;&#26377;&#25928;&#24615;&#65292;&#22312;&#22810;&#20010;&#22522;&#20934;&#27979;&#35797;&#20013;&#22343;&#36798;&#21040;&#26368;&#20339;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20351;&#29992;&#35266;&#27979;&#25968;&#25454;&#20174;&#19968;&#32452;&#31163;&#25955;&#27835;&#30103;&#36873;&#25321;&#20013;&#23398;&#20064;&#26368;&#20339;&#31574;&#30053;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20998;&#27573;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#21487;&#20197;&#24179;&#34913;&#24378;&#22823;&#30340;&#25351;&#23548;&#24615;&#33021;&#21644;&#21487;&#35299;&#37322;&#24615;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#25351;&#23548;&#22411;ReLU&#32593;&#32476;&#25110;P-ReLU&#12290;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#23637;&#31034;&#20102;&#36825;&#20010;&#27169;&#22411;: (i) &#23558;&#36755;&#20837;&#31354;&#38388;&#20998;&#25104;&#19981;&#30456;&#20132;&#30340;&#22810;&#38754;&#20307;&#65292;&#23646;&#20110;&#21516;&#19968;&#20998;&#21306;&#30340;&#25152;&#26377;&#23454;&#20363;&#25509;&#21463;&#30456;&#21516;&#30340;&#27835;&#30103;&#26041;&#27861;&#65307;(ii) &#21487;&#20197;&#36716;&#21270;&#20026;&#20855;&#26377;&#21487;&#35299;&#37322;&#24615;&#30340;&#20855;&#26377;&#36229;&#24179;&#38754;&#20998;&#35010;&#30340;&#31561;&#25928;&#25351;&#23548;&#26641;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;P-ReLU&#32593;&#32476;&#30340;&#28789;&#27963;&#24615;&#65292;&#22240;&#20026;&#21487;&#20197;&#36890;&#36807;&#23545;&#20307;&#31995;&#32467;&#26500;&#36827;&#34892;&#23567;&#30340;&#20462;&#25913;&#26469;&#36731;&#26494;&#22320;&#21512;&#24182;&#32422;&#26463;&#26465;&#20214;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;P-ReLU&#30456;&#23545;&#20110;&#31454;&#20105;&#22522;&#20934;&#27169;&#22411;&#20855;&#26377;&#26356;&#22909;&#30340;&#25351;&#23548;&#31934;&#24230;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#22312;&#20351;&#29992;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#35757;&#32451;&#30340;P-ReLU&#20013;&#25552;&#21462;&#21487;&#35299;&#37322;&#30340;&#25351;&#23548;&#26641;&#30340;&#31034;&#20363;&#20013;&#65292;&#23637;&#31034;&#20102;&#26080;&#32422;&#26463;&#21644;&#32422;&#26463;&#24773;&#20917;&#19979;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of learning optimal policy from a set of discrete treatment options using observational data. We propose a piecewise linear neural network model that can balance strong prescriptive performance and interpretability, which we refer to as the prescriptive ReLU network, or P-ReLU. We show analytically that this model (i) partitions the input space into disjoint polyhedra, where all instances that belong to the same partition receive the same treatment, and (ii) can be converted into an equivalent prescriptive tree with hyperplane splits for interpretability. We demonstrate the flexibility of the P-ReLU network as constraints can be easily incorporated with minor modifications to the architecture. Through experiments, we validate the superior prescriptive accuracy of P-ReLU against competing benchmarks. Lastly, we present examples of interpretable prescriptive trees extracted from trained P-ReLUs using a real-world dataset, for both the unconstrained and constrained sc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32852;&#37030;&#23398;&#20064;&#29615;&#22659;&#19979;&#65292;&#38750;&#25308;&#21344;&#24237;&#26426;&#22120;&#21487;&#20197;&#34987;&#20998;&#25104;&#19981;&#30456;&#20132;&#30340;&#32858;&#31867;&#65292;&#32780;&#25308;&#21344;&#24237;&#26426;&#22120;&#21487;&#33021;&#20250;&#23545;&#20219;&#20309;&#32858;&#31867;&#23454;&#34892;&#25915;&#20987;&#65292;&#30772;&#22351;&#35757;&#32451;&#36807;&#31243;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#40065;&#26834;&#24615;&#32858;&#31867;&#32852;&#37030;&#23398;&#20064;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.00638</link><description>&lt;p&gt;
&#25308;&#21344;&#24237;-&#40065;&#26834;&#24615;&#32858;&#31867;&#32852;&#37030;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Byzantine-Robust Clustered Federated Learning. (arXiv:2306.00638v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00638
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32852;&#37030;&#23398;&#20064;&#29615;&#22659;&#19979;&#65292;&#38750;&#25308;&#21344;&#24237;&#26426;&#22120;&#21487;&#20197;&#34987;&#20998;&#25104;&#19981;&#30456;&#20132;&#30340;&#32858;&#31867;&#65292;&#32780;&#25308;&#21344;&#24237;&#26426;&#22120;&#21487;&#33021;&#20250;&#23545;&#20219;&#20309;&#32858;&#31867;&#23454;&#34892;&#25915;&#20987;&#65292;&#30772;&#22351;&#35757;&#32451;&#36807;&#31243;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#40065;&#26834;&#24615;&#32858;&#31867;&#32852;&#37030;&#23398;&#20064;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32852;&#37030;&#23398;&#20064;&#29615;&#22659;&#19979;&#65292;&#38750;&#25308;&#21344;&#24237;&#26426;&#22120;&#21487;&#20197;&#34987;&#20998;&#25104;&#19981;&#30456;&#20132;&#30340;&#32858;&#31867;&#65292;&#32780;&#25308;&#21344;&#24237;&#26426;&#22120;&#21487;&#33021;&#20250;&#23545;&#20219;&#20309;&#32858;&#31867;&#23454;&#34892;&#25915;&#20987;&#65292;&#30772;&#22351;&#35757;&#32451;&#36807;&#31243;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#35782;&#21035;&#38750;&#25308;&#21344;&#24237;&#26426;&#22120;&#30340;&#32858;&#31867;&#25104;&#21592;&#36523;&#20221;&#65292;&#24182;&#20248;&#21270;&#27599;&#20010;&#32858;&#31867;&#25152;&#23398;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#37319;&#29992; Ghosh &#31561;&#20154;&#65288;2020&#65289;&#30340;&#36845;&#20195;&#32852;&#37030;&#32858;&#31867;&#31639;&#27861;(IFCA) &#26694;&#26550;&#65292;&#20132;&#26367;&#20272;&#35745;&#32858;&#31867;&#25104;&#21592;&#36523;&#20221;&#21644;&#20248;&#21270;&#27169;&#22411;&#12290;&#20026;&#20102;&#20351;&#36825;&#20010;&#26694;&#26550;&#23545;&#26469;&#33258;&#25308;&#21344;&#24237;&#26426;&#22120;&#30340;&#25915;&#20987;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102; Yin &#31561;&#20154;&#20351;&#29992;&#30340;&#22352;&#26631;&#36724;&#35009;&#21098;&#24179;&#22343;&#20540;&#21644;&#22352;&#26631;&#36724;&#35009;&#21098;&#20013;&#20301;&#25968;&#32858;&#21512;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper focuses on the problem of adversarial attacks from Byzantine machines in a Federated Learning setting where non-Byzantine machines can be partitioned into disjoint clusters. In this setting, non-Byzantine machines in the same cluster have the same underlying data distribution, and different clusters of non-Byzantine machines have different learning tasks. Byzantine machines can adversarially attack any cluster and disturb the training process on clusters they attack. In the presence of Byzantine machines, the goal of our work is to identify cluster membership of non-Byzantine machines and optimize the models learned by each cluster. We adopt the Iterative Federated Clustering Algorithm (IFCA) framework of Ghosh et al. (2020) to alternatively estimate cluster membership and optimize models. In order to make this framework robust against adversarial attacks from Byzantine machines, we use coordinate-wise trimmed mean and coordinate-wise median aggregation methods used by Yin e
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20844;&#24179;&#26694;&#26550;&#8212;&#8212;&#32771;&#34385;&#25919;&#31574;&#20248;&#21270;&#21738;&#20010;&#25928;&#29992;&#65292;&#23450;&#20041;&#20102;&#20449;&#24687;&#20215;&#20540;&#20844;&#24179;&#65292;&#25552;&#20986;&#19981;&#24212;&#20351;&#29992;&#19981;&#28385;&#36275;&#36825;&#19968;&#26631;&#20934;&#30340;&#23454;&#29992;&#31243;&#24207;&#65292;&#24182;&#25506;&#35752;&#20102;&#20462;&#25913;&#23454;&#29992;&#31243;&#24207;&#20197;&#28385;&#36275;&#27492;&#20844;&#24179;&#26631;&#20934;&#21487;&#33021;&#23545;&#26368;&#20248;&#25919;&#31574;&#20135;&#29983;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2306.00636</link><description>&lt;p&gt;
&#19981;&#20844;&#24179;&#30340;&#23454;&#29992;&#31243;&#24207;&#21450;&#20854;&#25913;&#36827;&#30340;&#31532;&#19968;&#27493;
&lt;/p&gt;
&lt;p&gt;
Unfair Utilities and First Steps Towards Improving Them. (arXiv:2306.00636v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00636
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#20844;&#24179;&#26694;&#26550;&#8212;&#8212;&#32771;&#34385;&#25919;&#31574;&#20248;&#21270;&#21738;&#20010;&#25928;&#29992;&#65292;&#23450;&#20041;&#20102;&#20449;&#24687;&#20215;&#20540;&#20844;&#24179;&#65292;&#25552;&#20986;&#19981;&#24212;&#20351;&#29992;&#19981;&#28385;&#36275;&#36825;&#19968;&#26631;&#20934;&#30340;&#23454;&#29992;&#31243;&#24207;&#65292;&#24182;&#25506;&#35752;&#20102;&#20462;&#25913;&#23454;&#29992;&#31243;&#24207;&#20197;&#28385;&#36275;&#27492;&#20844;&#24179;&#26631;&#20934;&#21487;&#33021;&#23545;&#26368;&#20248;&#25919;&#31574;&#20135;&#29983;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#20844;&#24179;&#26631;&#20934;&#23545;&#25919;&#31574;&#25110;&#39044;&#27979;&#22120;&#30340;&#36873;&#25321;&#36827;&#34892;&#38480;&#21046;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#19981;&#21516;&#30340;&#24605;&#32771;&#20844;&#24179;&#30340;&#26694;&#26550;&#65306;&#25105;&#20204;&#32771;&#34385;&#25919;&#31574;&#27491;&#22312;&#20248;&#21270;&#21738;&#20010;&#25928;&#29992;&#65292;&#32780;&#19981;&#26159;&#38480;&#21046;&#25919;&#31574;&#25110;&#39044;&#27979;&#22120;&#30340;&#36873;&#25321;&#12290;&#25105;&#20204;&#23450;&#20041;&#20102;&#20449;&#24687;&#20215;&#20540;&#20844;&#24179;&#65292;&#24182;&#24314;&#35758;&#19981;&#20351;&#29992;&#19981;&#28385;&#36275;&#27492;&#26631;&#20934;&#30340;&#23454;&#29992;&#31243;&#24207;&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;&#22914;&#20309;&#20462;&#25913;&#23454;&#29992;&#31243;&#24207;&#20197;&#28385;&#36275;&#36825;&#31181;&#20844;&#24179;&#26631;&#20934;&#65292;&#24182;&#35752;&#35770;&#20102;&#36825;&#21487;&#33021;&#23545;&#30456;&#24212;&#30340;&#26368;&#20248;&#25919;&#31574;&#20135;&#29983;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many fairness criteria constrain the policy or choice of predictors. In this work, we propose a different framework for thinking about fairness: Instead of constraining the policy or choice of predictors, we consider which utility a policy is optimizing for. We define value of information fairness and propose to not use utilities that do not satisfy this criterion. We describe how to modify a utility to satisfy this fairness criterion and discuss the consequences this might have on the corresponding optimal policies.
&lt;/p&gt;</description></item><item><title>&#22312;&#28508;&#22312;&#28151;&#28102;&#22240;&#32032;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36880;&#27493;&#23436;&#21892;&#22240;&#26524;&#22270;&#30340;&#31639;&#27861;&#65292;&#20808;&#23398;&#20064;&#38271;&#26399;&#30340;&#26102;&#24577;&#20851;&#31995;&#32780;&#19981;&#26159;&#30701;&#26399;&#30340;&#20851;&#31995;&#65292;&#26368;&#21518;&#25165;&#23398;&#20064;&#21516;&#26102;&#24615;&#20851;&#31995;&#12290;&#36825;&#31181;&#26041;&#27861;&#20943;&#23569;&#20102;&#32479;&#35745;&#26816;&#39564;&#27425;&#25968;&#65292;&#25552;&#39640;&#20102;&#22240;&#26524;&#22270;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.00624</link><description>&lt;p&gt;
&#22312;&#28508;&#22312;&#28151;&#28102;&#22240;&#32032;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#20174;&#26102;&#24577;&#21040;&#21516;&#26102;&#24615;&#30340;&#36845;&#20195;&#22240;&#26524;&#21457;&#29616;
&lt;/p&gt;
&lt;p&gt;
From Temporal to Contemporaneous Iterative Causal Discovery in the Presence of Latent Confounders. (arXiv:2306.00624v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00624
&lt;/p&gt;
&lt;p&gt;
&#22312;&#28508;&#22312;&#28151;&#28102;&#22240;&#32032;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36880;&#27493;&#23436;&#21892;&#22240;&#26524;&#22270;&#30340;&#31639;&#27861;&#65292;&#20808;&#23398;&#20064;&#38271;&#26399;&#30340;&#26102;&#24577;&#20851;&#31995;&#32780;&#19981;&#26159;&#30701;&#26399;&#30340;&#20851;&#31995;&#65292;&#26368;&#21518;&#25165;&#23398;&#20064;&#21516;&#26102;&#24615;&#20851;&#31995;&#12290;&#36825;&#31181;&#26041;&#27861;&#20943;&#23569;&#20102;&#32479;&#35745;&#26816;&#39564;&#27425;&#25968;&#65292;&#25552;&#39640;&#20102;&#22240;&#26524;&#22270;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32422;&#26463;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#20174;&#35266;&#27979;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#23398;&#20064;&#22240;&#26524;&#32467;&#26500;&#65292;&#22312;&#23384;&#22312;&#28508;&#22312;&#28151;&#28102;&#22240;&#32032;&#30340;&#24773;&#20917;&#19979;&#12290;&#25105;&#20204;&#20551;&#35774;&#23384;&#22312;&#31163;&#25955;&#26102;&#38388;&#12289;&#31283;&#24577;&#32467;&#26500;&#21521;&#37327;&#33258;&#22238;&#24402;&#36807;&#31243;&#65292;&#20855;&#26377;&#26102;&#24577;&#21644;&#21516;&#26102;&#24615;&#22240;&#26524;&#20851;&#31995;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#20250;&#36880;&#27493;&#36890;&#36807;&#20808;&#23398;&#20064;&#38271;&#26399;&#30340;&#26102;&#24577;&#20851;&#31995;&#32780;&#19981;&#26159;&#30701;&#26399;&#30340;&#20851;&#31995;&#65288;&#21516;&#26102;&#24615;&#20851;&#31995;&#26368;&#21518;&#23398;&#20064;&#65289;&#65292;&#36880;&#27493;&#23436;&#21892;&#22240;&#26524;&#22270;&#12290;&#36825;&#31181;&#20851;&#31995;&#25490;&#24207;&#30340;&#23398;&#20064;&#26041;&#27861;&#23548;&#33268;&#25152;&#38656;&#30340;&#32479;&#35745;&#26816;&#39564;&#27425;&#25968;&#20943;&#23569;&#12290;&#25105;&#20204;&#22312;&#23454;&#39564;&#20013;&#36890;&#36807;&#21512;&#25104;&#25968;&#25454;&#39564;&#35777;&#20102;&#36825;&#31181;&#20943;&#23569;&#65292;&#21516;&#26102;&#35777;&#26126;&#19982;&#26368;&#20808;&#36827;&#30340;&#31639;&#27861;&#30456;&#27604;&#65292;&#36825;&#31181;&#20943;&#23569;&#20250;&#23548;&#33268;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#30340;&#26356;&#39640;&#20934;&#30830;&#24615;&#21644;&#26356;&#21512;&#29702;&#30340;&#22240;&#26524;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a constraint-based algorithm for learning causal structures from observational time-series data, in the presence of latent confounders. We assume a discrete-time, stationary structural vector autoregressive process, with both temporal and contemporaneous causal relations. One may ask if temporal and contemporaneous relations should be treated differently. The presented algorithm gradually refines a causal graph by learning long-term temporal relations before short-term ones, where contemporaneous relations are learned last. This ordering of causal relations to be learnt leads to a reduction in the required number of statistical tests. We validate this reduction empirically and demonstrate that it leads to higher accuracy for synthetic data and more plausible causal graphs for real-world data compared to state-of-the-art algorithms.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28151;&#21512;&#20114;&#20449;&#24687;&#20272;&#35745;&#30340;&#26377;&#25928;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#26041;&#27861;&#20197;&#24212;&#23545;&#21028;&#21035;&#24335;&#21644;&#29983;&#25104;&#24335;&#26041;&#27861;&#21508;&#33258;&#32570;&#28857;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#39044;&#27979;&#37327;&#21270;&#30340;&#29983;&#25104;&#26041;&#27861;&#65292;&#19982;&#21028;&#21035;&#24335;&#20272;&#35745;&#22120;&#32467;&#21512;&#21487;&#33719;&#24471;&#26356;&#31934;&#30830;&#30340;&#20114;&#20449;&#24687;&#20272;&#35745;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2306.00608</link><description>&lt;p&gt;
&#20851;&#20110;&#28151;&#21512;&#20114;&#20449;&#24687;&#20272;&#35745;&#30340;&#26377;&#25928;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Effectiveness of Hybrid Mutual Information Estimation. (arXiv:2306.00608v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00608
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28151;&#21512;&#20114;&#20449;&#24687;&#20272;&#35745;&#30340;&#26377;&#25928;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#26041;&#27861;&#20197;&#24212;&#23545;&#21028;&#21035;&#24335;&#21644;&#29983;&#25104;&#24335;&#26041;&#27861;&#21508;&#33258;&#32570;&#28857;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#39044;&#27979;&#37327;&#21270;&#30340;&#29983;&#25104;&#26041;&#27861;&#65292;&#19982;&#21028;&#21035;&#24335;&#20272;&#35745;&#22120;&#32467;&#21512;&#21487;&#33719;&#24471;&#26356;&#31934;&#30830;&#30340;&#20114;&#20449;&#24687;&#20272;&#35745;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20174;&#32852;&#21512;&#20998;&#24067;&#30340;&#26679;&#26412;&#20013;&#20272;&#35745;&#20114;&#20449;&#24687;&#26159;&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#30340;&#19968;&#20010;&#38590;&#39064;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#27010;&#25324;&#20102;&#21028;&#21035;&#24335;&#21644;&#29983;&#25104;&#24335;&#26041;&#27861;&#30340;&#21464;&#20998;&#30028;&#32422;&#26463;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#26041;&#27861;&#26469;&#20943;&#23569;&#23427;&#20204;&#21508;&#33258;&#30340;&#32570;&#28857;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#39044;&#27979;&#37327;&#21270; (PQ) &#30340;&#31616;&#21333;&#29983;&#25104;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#19982;&#21028;&#21035;&#24335;&#20272;&#35745;&#22120;&#36731;&#26494;&#32467;&#21512;&#20197;&#23454;&#29616;&#26368;&#23567;&#30340;&#35745;&#31639;&#24320;&#38144;&#12290;&#25105;&#20204;&#30340;&#25552;&#35758;&#36890;&#36807;&#38477;&#20302;&#20272;&#35745;&#22120;&#30340;&#26041;&#24046;&#32780;&#20135;&#29983;&#26356;&#32039;&#30340;&#20449;&#24687;&#30028;&#32422;&#26463;&#12290;&#25105;&#20204;&#23558;&#36825;&#20123;&#26041;&#27861;&#24212;&#29992;&#20110;&#30456;&#20851;&#30340;&#39640;&#32500;&#39640;&#26031;&#20998;&#24067;&#21644;&#28041;&#21450;&#21463;&#22266;&#23450;&#33021;&#37327;&#26223;&#35266;&#32422;&#26463;&#30340;&#33258;&#30001;&#31890;&#23376;&#31995;&#32479;&#30340;&#38543;&#26426;&#36807;&#31243;&#30340;&#25361;&#25112;&#24615;&#20219;&#21153;&#19978;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#19982;&#30456;&#24212;&#30340;&#21028;&#21035;&#24335;&#20272;&#35745;&#26041;&#27861;&#30456;&#27604;&#65292;&#28151;&#21512;&#26041;&#27861;&#21487;&#20197;&#25345;&#32493;&#25552;&#39640;&#20114;&#20449;&#24687;&#20272;&#35745;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating the mutual information from samples from a joint distribution is a challenging problem in both science and engineering. In this work, we realize a variational bound that generalizes both discriminative and generative approaches. Using this bound, we propose a hybrid method to mitigate their respective shortcomings. Further, we propose Predictive Quantization (PQ): a simple generative method that can be easily combined with discriminative estimators for minimal computational overhead. Our propositions yield a tighter bound on the information thanks to the reduced variance of the estimator. We test our methods on a challenging task of correlated high-dimensional Gaussian distributions and a stochastic process involving a system of free particles subjected to a fixed energy landscape. Empirical results show that hybrid methods consistently improved mutual information estimates when compared to the corresponding discriminative counterpart.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Wasserstein&#36317;&#31163;&#30340;&#25439;&#22833;&#20989;&#25968;hinge-Wasserstein&#65292;&#29992;&#20110;&#32531;&#35299;&#22238;&#24402;&#20219;&#21153;&#20013;&#30001;&#20110;&#36807;&#24230;&#33258;&#20449;&#23548;&#33268;&#30340;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#12290;&#36825;&#31181;&#25439;&#22833;&#20989;&#25968;&#26377;&#25928;&#25552;&#39640;&#20102;aleatoric&#21644;epistemic&#19981;&#30830;&#23450;&#24615;&#30340;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2306.00560</link><description>&lt;p&gt;
Hinge-Wasserstein: &#36890;&#36807;&#20998;&#31867;&#36991;&#20813;&#22238;&#24402;&#20013;&#30340;&#36807;&#24230;&#33258;&#20449;
&lt;/p&gt;
&lt;p&gt;
Hinge-Wasserstein: Mitigating Overconfidence in Regression by Classification. (arXiv:2306.00560v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00560
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Wasserstein&#36317;&#31163;&#30340;&#25439;&#22833;&#20989;&#25968;hinge-Wasserstein&#65292;&#29992;&#20110;&#32531;&#35299;&#22238;&#24402;&#20219;&#21153;&#20013;&#30001;&#20110;&#36807;&#24230;&#33258;&#20449;&#23548;&#33268;&#30340;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#12290;&#36825;&#31181;&#25439;&#22833;&#20989;&#25968;&#26377;&#25928;&#25552;&#39640;&#20102;aleatoric&#21644;epistemic&#19981;&#30830;&#23450;&#24615;&#30340;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#24615;&#33021;&#26041;&#38754;&#24471;&#21040;&#20102;&#24040;&#22823;&#30340;&#25552;&#39640;&#65292;&#20294;&#23427;&#20204;&#23481;&#26131;&#20135;&#29983;&#36807;&#24230;&#33258;&#20449;&#12290;&#22312;&#27169;&#31946;&#29978;&#33267;&#19981;&#21487;&#39044;&#27979;&#30340;&#29616;&#23454;&#19990;&#30028;&#22330;&#26223;&#20013;&#65292;&#36825;&#31181;&#36807;&#24230;&#33258;&#20449;&#21487;&#33021;&#23545;&#24212;&#29992;&#31243;&#24207;&#30340;&#23433;&#20840;&#24615;&#26500;&#25104;&#37325;&#22823;&#39118;&#38505;&#12290;&#38024;&#23545;&#22238;&#24402;&#20219;&#21153;&#65292;&#37319;&#29992;&#22238;&#24402;-&#20998;&#31867;&#26041;&#27861;&#26377;&#28508;&#21147;&#32531;&#35299;&#36825;&#20123;&#27495;&#20041;&#65292;&#22240;&#20026;&#23427;&#21487;&#20197;&#39044;&#27979;&#25152;&#38656;&#36755;&#20986;&#30340;&#31163;&#25955;&#27010;&#29575;&#23494;&#24230;&#12290;&#28982;&#32780;&#65292;&#23494;&#24230;&#20272;&#35745;&#20173;&#28982;&#20542;&#21521;&#20110;&#36807;&#24230;&#33258;&#20449;&#65292;&#23588;&#20854;&#26159;&#22312;&#20351;&#29992;&#24120;&#35265;&#30340;NLL&#25439;&#22833;&#20989;&#25968;&#35757;&#32451;&#26102;&#12290;&#20026;&#20102;&#32531;&#35299;&#36825;&#31181;&#36807;&#24230;&#33258;&#20449;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Wasserstein&#36317;&#31163;&#30340;&#25439;&#22833;&#20989;&#25968;&#65292;&#21363;hinge-Wasserstein&#12290;&#19982;&#20197;&#21069;&#30340;&#24037;&#20316;&#30456;&#27604;&#65292;&#27492;&#25439;&#22833;&#26174;&#30528;&#25552;&#39640;&#20102;&#20004;&#31181;&#19981;&#30830;&#23450;&#24615;&#30340;&#36136;&#37327;&#65306; aleatoric&#19981;&#30830;&#23450;&#24615;&#21644;epistemic&#19981;&#30830;&#23450;&#24615;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#26032;&#25439;&#22833;&#30340;&#33021;&#21147;&#65292;&#20854;&#20013;&#20004;&#31181;&#31867;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#21487;&#20197;&#20998;&#21035;&#25511;&#21046;&#12290;&#27492;&#22806;&#65292;&#20316;&#20026;&#29616;&#23454;&#19990;&#30028;&#22330;&#26223;&#30340;&#28436;&#31034;&#65292;&#25105;&#20204;&#22312;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern deep neural networks are prone to being overconfident despite their drastically improved performance. In ambiguous or even unpredictable real-world scenarios, this overconfidence can pose a major risk to the safety of applications. For regression tasks, the regression-by-classification approach has the potential to alleviate these ambiguities by instead predicting a discrete probability density over the desired output. However, a density estimator still tends to be overconfident when trained with the common NLL loss. To mitigate the overconfidence problem, we propose a loss function, hinge-Wasserstein, based on the Wasserstein Distance. This loss significantly improves the quality of both aleatoric and epistemic uncertainty, compared to previous work. We demonstrate the capabilities of the new loss on a synthetic dataset, where both types of uncertainty are controlled separately. Moreover, as a demonstration for real-world scenarios, we evaluate our approach on the benchmark dat
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#29992;&#20110;&#20174;&#26410;&#30693;&#24178;&#39044;&#25968;&#25454;&#20013;&#25512;&#26029;&#38750;&#21442;&#25968;&#22240;&#26524;&#34920;&#36798;&#24335;&#23398;&#20064;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#22312;&#20004;&#20010;&#22240;&#26524;&#21464;&#37327;&#30340;&#22522;&#26412;&#35774;&#32622;&#20013;&#65292;&#26080;&#27861;&#28040;&#38500;&#19968;&#20123;&#30001;&#24178;&#39044;&#25968;&#25454;&#24341;&#36215;&#30340;&#27495;&#20041;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.00542</link><description>&lt;p&gt;
&#26410;&#30693;&#24178;&#39044;&#30340;&#22240;&#26524;&#34920;&#36798;&#24335;&#30340;&#38750;&#21442;&#25968;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Nonparametric Identifiability of Causal Representations from Unknown Interventions. (arXiv:2306.00542v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00542
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#29992;&#20110;&#20174;&#26410;&#30693;&#24178;&#39044;&#25968;&#25454;&#20013;&#25512;&#26029;&#38750;&#21442;&#25968;&#22240;&#26524;&#34920;&#36798;&#24335;&#23398;&#20064;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#22312;&#20004;&#20010;&#22240;&#26524;&#21464;&#37327;&#30340;&#22522;&#26412;&#35774;&#32622;&#20013;&#65292;&#26080;&#27861;&#28040;&#38500;&#19968;&#20123;&#30001;&#24178;&#39044;&#25968;&#25454;&#24341;&#36215;&#30340;&#27495;&#20041;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#22240;&#26524;&#34920;&#36798;&#24335;&#23398;&#20064;&#65292;&#21363;&#20174;&#21464;&#37327;&#30340;&#39640;&#32500;&#20989;&#25968;&#65288;&#8220;&#28151;&#21512;&#29289;&#8221;&#65289;&#20013;&#25512;&#26029;&#28508;&#22312;&#30340;&#22240;&#26524;&#21464;&#37327;&#21450;&#20854;&#22240;&#26524;&#20851;&#31995;&#30340;&#20219;&#21153;&#12290;&#20197;&#21069;&#30340;&#24037;&#20316;&#20381;&#36182;&#20110;&#24369;&#30417;&#30563;&#65292;&#22914;&#21453;&#20107;&#23454;&#30340;&#24178;&#39044;&#35266;&#23519;&#25110;&#26102;&#38388;&#32467;&#26500;&#65307;&#23545;&#28151;&#21512;&#20989;&#25968;&#25110;&#28508;&#22312;&#22240;&#26524;&#27169;&#22411;&#26045;&#21152;&#38480;&#21046;&#65292;&#22914;&#32447;&#24615;&#65307;&#25110;&#38656;&#35201;&#37096;&#20998;&#20102;&#35299;&#29983;&#25104;&#36807;&#31243;&#65292;&#22914;&#22240;&#26524;&#22270;&#25110;&#24178;&#39044;&#30446;&#26631;&#12290;&#25105;&#20204;&#32771;&#34385;&#21040;&#22240;&#26524;&#27169;&#22411;&#21644;&#28151;&#21512;&#20989;&#25968;&#37117;&#26159;&#38750;&#21442;&#25968;&#30340;&#19968;&#33324;&#24773;&#20917;&#12290;&#23398;&#20064;&#20449;&#21495;&#37319;&#29992;&#26469;&#33258;&#22522;&#30784;&#22240;&#26524;&#27169;&#22411;&#20013;&#26410;&#30693;&#24178;&#39044;&#30340;&#22810;&#20010;&#25968;&#25454;&#38598;&#25110;&#29615;&#22659;&#30340;&#24418;&#24335;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#23558;&#22320;&#38754;&#30495;&#23454;&#28508;&#21464;&#37327;&#21450;&#20854;&#22240;&#26524;&#22270;&#37492;&#23450;&#20986;&#26469;&#65292;&#21516;&#26102;&#35299;&#20915;&#19968;&#32452;&#20174;&#24178;&#39044;&#25968;&#25454;&#26080;&#27861;&#28040;&#38500;&#30340;&#27495;&#20041;&#38382;&#39064;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#20004;&#20010;&#22240;&#26524;&#21464;&#37327;&#30340;&#22522;&#26412;&#35774;&#32622;&#65292;&#24182;&#35777;&#26126;&#20102;...
&lt;/p&gt;
&lt;p&gt;
We study causal representation learning, the task of inferring latent causal variables and their causal relations from high-dimensional functions ("mixtures") of the variables. Prior work relies on weak supervision, in the form of counterfactual pre- and post-intervention views or temporal structure; places restrictive assumptions, such as linearity, on the mixing function or latent causal model; or requires partial knowledge of the generative process, such as the causal graph or the intervention targets. We instead consider the general setting in which both the causal model and the mixing function are nonparametric. The learning signal takes the form of multiple datasets, or environments, arising from unknown interventions in the underlying causal model. Our goal is to identify both the ground truth latents and their causal graph up to a set of ambiguities which we show to be irresolvable from interventional data. We study the fundamental setting of two causal variables and prove that
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#20840;&#23616;&#25928;&#24212;&#24191;&#20041;&#21487;&#21152;&#20998;&#35299;&#65288;GADGET&#65289;&#26694;&#26550;&#65292;&#33021;&#22815;&#26368;&#23567;&#21270;&#29305;&#24449;&#20132;&#20114;&#20316;&#29992;&#30340;&#26412;&#22320;&#29305;&#24449;&#25928;&#24212;&#30340;&#20132;&#20114;&#24322;&#36136;&#24615;&#12290;&#21516;&#26102;&#36866;&#29992;&#20110;&#20559;&#20381;&#36182;&#12289;&#31215;&#32047;&#23616;&#37096;&#25928;&#24212;&#21644;Shapley&#21487;&#21152;&#35299;&#37322;&#65288;SHAP&#65289;&#20381;&#36182;&#30340;&#36793;&#38469;&#29305;&#24449;&#25928;&#24212;&#21487;&#35270;&#21270;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#32622;&#25442;&#30340;&#20132;&#20114;&#27979;&#35797;&#26469;&#26816;&#27979;&#26174;&#30528;&#30340;&#29305;&#24449;&#20132;&#20114;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2306.00541</link><description>&lt;p&gt;
&#22522;&#20110;&#29305;&#24449;&#20132;&#20114;&#20316;&#29992;&#36827;&#34892;&#20840;&#23616;&#29305;&#24449;&#25928;&#24212;&#20998;&#35299;
&lt;/p&gt;
&lt;p&gt;
Decomposing Global Feature Effects Based on Feature Interactions. (arXiv:2306.00541v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00541
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#20840;&#23616;&#25928;&#24212;&#24191;&#20041;&#21487;&#21152;&#20998;&#35299;&#65288;GADGET&#65289;&#26694;&#26550;&#65292;&#33021;&#22815;&#26368;&#23567;&#21270;&#29305;&#24449;&#20132;&#20114;&#20316;&#29992;&#30340;&#26412;&#22320;&#29305;&#24449;&#25928;&#24212;&#30340;&#20132;&#20114;&#24322;&#36136;&#24615;&#12290;&#21516;&#26102;&#36866;&#29992;&#20110;&#20559;&#20381;&#36182;&#12289;&#31215;&#32047;&#23616;&#37096;&#25928;&#24212;&#21644;Shapley&#21487;&#21152;&#35299;&#37322;&#65288;SHAP&#65289;&#20381;&#36182;&#30340;&#36793;&#38469;&#29305;&#24449;&#25928;&#24212;&#21487;&#35270;&#21270;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#32622;&#25442;&#30340;&#20132;&#20114;&#27979;&#35797;&#26469;&#26816;&#27979;&#26174;&#30528;&#30340;&#29305;&#24449;&#20132;&#20114;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20840;&#23616;&#29305;&#24449;&#25928;&#24212;&#26041;&#27861;&#65292;&#22914;&#20559;&#20381;&#36182;&#22270;&#65292;&#25552;&#20379;&#20102;&#39044;&#26399;&#36793;&#38469;&#29305;&#24449;&#25928;&#24212;&#30340;&#21487;&#29702;&#35299;&#30340;&#21487;&#35270;&#21270;&#12290;&#20294;&#26159;&#65292;&#24403;&#23384;&#22312;&#29305;&#24449;&#20132;&#20114;&#20316;&#29992;&#26102;&#65292;&#36825;&#31181;&#20840;&#23616;&#29305;&#24449;&#25928;&#24212;&#26041;&#27861;&#21487;&#33021;&#20250;&#35823;&#23548;&#65292;&#22240;&#20026;&#23427;&#20204;&#19981;&#33021;&#24456;&#22909;&#22320;&#34920;&#31034;&#21333;&#20010;&#35266;&#27979;&#30340;&#23616;&#37096;&#29305;&#24449;&#25928;&#24212;&#12290;&#25105;&#20204;&#27491;&#24335;&#20171;&#32461;&#20102;&#22522;&#20110;&#36882;&#24402;&#20998;&#21306;&#30340;&#20840;&#23616;&#25928;&#24212;&#24191;&#20041;&#21487;&#21152;&#20998;&#35299;&#65288;GADGET&#65289;&#26694;&#26550;&#65292;&#20197;&#25214;&#21040;&#35299;&#37322;&#24615;&#29305;&#24449;&#31354;&#38388;&#20013;&#30340;&#21487;&#35299;&#37322;&#21306;&#22495;&#65292;&#20174;&#32780;&#26368;&#23567;&#21270;&#26412;&#22320;&#29305;&#24449;&#25928;&#24212;&#30340;&#20132;&#20114;&#24322;&#36136;&#24615;&#12290;&#25105;&#20204;&#20026;&#35813;&#26694;&#26550;&#25552;&#20379;&#20102;&#25968;&#23398;&#22522;&#30784;&#65292;&#24182;&#23637;&#31034;&#23427;&#36866;&#29992;&#20110;&#26368;&#27969;&#34892;&#30340;&#26041;&#27861;&#26469;&#21487;&#35270;&#21270;&#36793;&#38469;&#29305;&#24449;&#25928;&#24212;&#65292;&#21363;&#20559;&#20381;&#36182;&#65292;&#31215;&#32047;&#23616;&#37096;&#25928;&#24212;&#21644;Shapley&#21487;&#21152;&#35299;&#37322;&#65288;SHAP&#65289;&#20381;&#36182;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#32622;&#25442;&#30340;&#20132;&#20114;&#27979;&#35797;&#26469;&#26816;&#27979;&#26174;&#30528;&#30340;&#29305;&#24449;&#20132;&#20114;&#20316;&#29992;&#65292;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#20219;&#20309;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Global feature effect methods, such as partial dependence plots, provide an intelligible visualization of the expected marginal feature effect. However, such global feature effect methods can be misleading, as they do not represent local feature effects of single observations well when feature interactions are present. We formally introduce generalized additive decomposition of global effects (GADGET), which is a new framework based on recursive partitioning to find interpretable regions in the feature space such that the interaction-related heterogeneity of local feature effects is minimized. We provide a mathematical foundation of the framework and show that it is applicable to the most popular methods to visualize marginal feature effects, namely partial dependence, accumulated local effects, and Shapley additive explanations (SHAP) dependence. Furthermore, we introduce a new permutation-based interaction test to detect significant feature interactions that is applicable to any feat
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#20405;&#20837;&#24335;&#30340;&#21518;&#22788;&#29702;&#27491;&#20132;&#21270;&#65288;PHO&#65289;&#26041;&#27861;&#65292;&#26088;&#22312;&#20445;&#35777;&#27169;&#22411;&#32452;&#25104;&#37096;&#20998;&#30340;&#35782;&#21035;&#24615;&#65292;&#25552;&#20379;&#26356;&#22909;&#30340;&#20272;&#35745;&#21644;&#39044;&#27979;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2306.00522</link><description>&lt;p&gt;
&#21322;&#32467;&#26500;&#21270;&#32593;&#32476;&#24615;&#33021;&#30340;&#26032;PHO&#20844;&#24335;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
A New PHO-rmula for Improved Performance of Semi-Structured Networks. (arXiv:2306.00522v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00522
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#20405;&#20837;&#24335;&#30340;&#21518;&#22788;&#29702;&#27491;&#20132;&#21270;&#65288;PHO&#65289;&#26041;&#27861;&#65292;&#26088;&#22312;&#20445;&#35777;&#27169;&#22411;&#32452;&#25104;&#37096;&#20998;&#30340;&#35782;&#21035;&#24615;&#65292;&#25552;&#20379;&#26356;&#22909;&#30340;&#20272;&#35745;&#21644;&#39044;&#27979;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#23558;&#32467;&#26500;&#22238;&#24402;&#27169;&#22411;&#19982;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30456;&#32467;&#21512;&#65292;&#20197;&#33719;&#24471;&#26356;&#22909;&#30340;&#21487;&#35299;&#37322;&#24615;&#12289;&#26356;&#24378;&#30340;&#34920;&#36798;&#21147;&#21644;&#32479;&#35745;&#19978;&#26377;&#25928;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65292;&#23637;&#31034;&#20102;&#21322;&#32467;&#26500;&#21270;&#31070;&#32463;&#32593;&#32476;&#30340;&#22810;&#21151;&#33021;&#24615;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;&#21322;&#32467;&#26500;&#21270;&#31070;&#32463;&#32593;&#32476;&#20013;&#65292;&#27491;&#30830;&#35782;&#21035;&#19981;&#21516;&#27169;&#22411;&#32452;&#25104;&#37096;&#20998;&#30340;&#25216;&#26415;&#20250;&#23548;&#33268;&#27425;&#20248;&#30340;&#32593;&#32476;&#20272;&#35745;&#65292;&#25910;&#25947;&#36895;&#24230;&#21464;&#24930;&#65292;&#29978;&#33267;&#20250;&#20986;&#29616;&#39044;&#27979;&#22833;&#35823;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#21516;&#26102;&#20445;&#25345;&#26377;&#21033;&#30340;&#27169;&#22411;&#29305;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#20405;&#20837;&#24335;&#30340;&#21518;&#22788;&#29702;&#27491;&#20132;&#21270;&#65288;PHO&#65289;&#26041;&#27861;&#65292;&#26088;&#22312;&#20445;&#35777;&#27169;&#22411;&#32452;&#25104;&#37096;&#20998;&#30340;&#35782;&#21035;&#24615;&#65292;&#25552;&#20379;&#26356;&#22909;&#30340;&#20272;&#35745;&#21644;&#39044;&#27979;&#36136;&#37327;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#21457;&#29616;&#24471;&#21040;&#20102;&#25968;&#20540;&#23454;&#39564;&#12289;&#22522;&#20934;&#27604;&#36739;&#20197;&#21450;COVID-19&#24863;&#26579;&#30340;&#23454;&#38469;&#24212;&#29992;&#30340;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent advances to combine structured regression models and deep neural networks for better interpretability, more expressiveness, and statistically valid uncertainty quantification demonstrate the versatility of semi-structured neural networks (SSNs). We show that techniques to properly identify the contributions of the different model components in SSNs, however, lead to suboptimal network estimation, slower convergence, and degenerated or erroneous predictions. In order to solve these problems while preserving favorable model properties, we propose a non-invasive post-hoc orthogonalization (PHO) that guarantees identifiability of model components and provides better estimation and prediction quality. Our theoretical findings are supported by numerical experiments, a benchmark comparison as well as a real-world application to COVID-19 infections.
&lt;/p&gt;</description></item><item><title>&#36974;&#34109;&#39044;&#35757;&#32451;&#21033;&#29992;&#32047;&#31215;&#25171;&#20998;&#20989;&#25968;&#23454;&#29616;&#20102;&#23545;&#27169;&#22411;&#30340;&#36793;&#32536;&#20284;&#28982;&#26497;&#22823;&#21270;&#65292;&#25552;&#20986;&#20102;&#35774;&#35745;&#36866;&#24403;&#30340;&#33258;&#30417;&#30563;&#26041;&#27861;&#26469;&#35757;&#32451;&#36125;&#21494;&#26031;&#27169;&#22411;&#30340;&#29702;&#35770;&#12290;&#23454;&#39564;&#35777;&#23454;&#20102;&#36825;&#19968;&#29702;&#35770;&#65292;&#24182;&#25506;&#32034;&#20102;&#36974;&#34109;&#39044;&#35757;&#32451;&#30340;&#20027;&#35201;&#23398;&#20064;&#21407;&#29702;&#12290;</title><link>http://arxiv.org/abs/2306.00520</link><description>&lt;p&gt;
&#20851;&#20110;&#36974;&#34109;&#39044;&#35757;&#32451;&#21644;&#36793;&#32536;&#20284;&#28982;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Masked Pre-training and the Marginal Likelihood. (arXiv:2306.00520v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00520
&lt;/p&gt;
&lt;p&gt;
&#36974;&#34109;&#39044;&#35757;&#32451;&#21033;&#29992;&#32047;&#31215;&#25171;&#20998;&#20989;&#25968;&#23454;&#29616;&#20102;&#23545;&#27169;&#22411;&#30340;&#36793;&#32536;&#20284;&#28982;&#26497;&#22823;&#21270;&#65292;&#25552;&#20986;&#20102;&#35774;&#35745;&#36866;&#24403;&#30340;&#33258;&#30417;&#30563;&#26041;&#27861;&#26469;&#35757;&#32451;&#36125;&#21494;&#26031;&#27169;&#22411;&#30340;&#29702;&#35770;&#12290;&#23454;&#39564;&#35777;&#23454;&#20102;&#36825;&#19968;&#29702;&#35770;&#65292;&#24182;&#25506;&#32034;&#20102;&#36974;&#34109;&#39044;&#35757;&#32451;&#30340;&#20027;&#35201;&#23398;&#20064;&#21407;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36974;&#34109;&#39044;&#35757;&#32451;&#26159;&#19968;&#31181;&#31227;&#38500;&#38543;&#26426;&#36755;&#20837;&#32500;&#24230;&#24182;&#23398;&#20064;&#21487;&#20197;&#39044;&#27979;&#32570;&#22833;&#20540;&#30340;&#27169;&#22411;&#30340;&#33258;&#25105;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#31181;&#30452;&#35266;&#30340;&#33258;&#25105;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#21487;&#20197;&#29983;&#25104;&#20855;&#26377;&#24456;&#22909;&#27867;&#21270;&#24615;&#33021;&#30340;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#36824;&#32570;&#20047;&#23545;&#20854;&#29702;&#35770;&#30340;&#28145;&#20837;&#29702;&#35299;&#12290;&#26412;&#25991;&#35777;&#26126;&#20102;&#36890;&#36807;&#36866;&#24403;&#30340;&#31215;&#20998;&#25171;&#20998;&#20989;&#25968;&#36827;&#34892;&#30340;&#36974;&#34109;&#39044;&#35757;&#32451;&#21487;&#20197;&#23545;&#27169;&#22411;&#30340;&#36793;&#32536;&#20284;&#28982;&#26497;&#22823;&#21270;&#12290;&#36793;&#32536;&#20284;&#28982;&#23454;&#38469;&#19978;&#26159;&#24191;&#20041;&#21270;&#27169;&#22411;&#36873;&#25321;&#30340;&#36125;&#21494;&#26031;&#24230;&#37327;&#12290;&#38500;&#20102;&#25581;&#31034;&#36974;&#34109;&#39044;&#35757;&#32451;&#25104;&#21151;&#30340;&#21407;&#22240;&#65292;&#26412;&#25991;&#30340;&#29702;&#35770;&#36824;&#24314;&#35758;&#21487;&#20197;&#35774;&#35745;&#36866;&#24403;&#30340;&#33258;&#30417;&#30563;&#26041;&#27861;&#26469;&#35757;&#32451;&#36125;&#21494;&#26031;&#27169;&#22411;&#12290;&#25105;&#20204;&#22312;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20013;&#23454;&#39564;&#39564;&#35777;&#20102;&#25152;&#24320;&#21457;&#30340;&#29702;&#35770;&#24182;&#25506;&#32034;&#20102;&#36974;&#34109;&#39044;&#35757;&#32451;&#30340;&#20027;&#35201;&#23398;&#20064;&#21407;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
Masked pre-training removes random input dimensions and learns a model that can predict the missing values. Empirical results indicate that this intuitive form of self-supervised learning yields models that generalize very well to new domains. A theoretical understanding is, however, lacking. This paper shows that masked pre-training with a suitable cumulative scoring function corresponds to maximizing the model's marginal likelihood, which is de facto the Bayesian model selection measure of generalization. Beyond shedding light on the success of masked pre-training, this insight also suggests that Bayesian models can be trained with appropriately designed self-supervision. Empirically, we confirm the developed theory and explore the main learning principles of masked pre-training in large language models.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#20108;&#20998;&#20998;&#31867;&#20013;&#25552;&#20379;&#36861;&#32034;&#26435;&#20250;&#22686;&#21152;&#38169;&#35823;&#29575;&#65292;&#23548;&#33268;&#26356;&#22810;&#38169;&#35823;&#30340;&#21457;&#29983;&#12290;&#25552;&#20379;&#31639;&#27861;&#36861;&#32034;&#26435;&#21487;&#33021;&#20063;&#20250;&#22312;&#31995;&#32479;&#32423;&#21035;&#19978;&#32473;&#20104;&#19981;&#21033;&#12290;</title><link>http://arxiv.org/abs/2306.00497</link><description>&lt;p&gt;
&#20108;&#20998;&#20998;&#31867;&#20013;&#36861;&#32034;&#26435;&#30340;&#39118;&#38505;
&lt;/p&gt;
&lt;p&gt;
The Risks of Recourse in Binary Classification. (arXiv:2306.00497v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00497
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#20108;&#20998;&#20998;&#31867;&#20013;&#25552;&#20379;&#36861;&#32034;&#26435;&#20250;&#22686;&#21152;&#38169;&#35823;&#29575;&#65292;&#23548;&#33268;&#26356;&#22810;&#38169;&#35823;&#30340;&#21457;&#29983;&#12290;&#25552;&#20379;&#31639;&#27861;&#36861;&#32034;&#26435;&#21487;&#33021;&#20063;&#20250;&#22312;&#31995;&#32479;&#32423;&#21035;&#19978;&#32473;&#20104;&#19981;&#21033;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31639;&#27861;&#36861;&#32034;&#26435;&#25552;&#20379;&#35299;&#37322;&#65292;&#20197;&#24110;&#21161;&#29992;&#25143;&#25512;&#32763;&#26426;&#22120;&#23398;&#20064;&#31995;&#32479;&#30340;&#19981;&#21033;&#20915;&#31574;&#12290;&#20294;&#21040;&#30446;&#21069;&#20026;&#27490;&#65292;&#24456;&#23569;&#26377;&#20154;&#20851;&#27880;&#25552;&#20379;&#36861;&#32034;&#26435;&#26159;&#21542;&#26377;&#30410;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#25277;&#35937;&#30340;&#23398;&#20064;&#29702;&#35770;&#26694;&#26550;&#65292;&#27604;&#36739;&#20102;&#20855;&#26377;&#21644;&#27809;&#26377;&#31639;&#27861;&#36861;&#32034;&#26435;&#30340;&#20998;&#31867;&#30340;&#39118;&#38505;&#65288;&#21363;&#26399;&#26395;&#25439;&#22833;&#65289;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#22238;&#31572;&#22312;&#25972;&#20010;&#20154;&#32676;&#27700;&#24179;&#19978;&#25552;&#20379;&#36861;&#32034;&#26435;&#20309;&#26102;&#26377;&#30410;&#25110;&#26377;&#23475;&#30340;&#38382;&#39064;&#12290;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;&#35768;&#22810;&#21487;&#20449;&#30340;&#24773;&#20917;&#19979;&#65292;&#25552;&#20379;&#36861;&#32034;&#26435;&#21453;&#32780;&#20250;&#26377;&#23475;&#65292;&#22240;&#20026;&#23427;&#23558;&#29992;&#25143;&#25512;&#21521;&#26356;&#39640;&#31867;&#21035;&#19981;&#30830;&#23450;&#24615;&#30340;&#21306;&#22495;&#65292;&#22240;&#27492;&#20250;&#23548;&#33268;&#26356;&#22810;&#30340;&#38169;&#35823;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#30740;&#31350;&#20102;&#37096;&#32626;&#20998;&#31867;&#22120;&#30340;&#19968;&#26041;&#26159;&#21542;&#26377;&#21160;&#26426;&#38024;&#23545;&#25552;&#20379;&#36861;&#32034;&#26435;&#30340;&#24773;&#20917;&#36827;&#34892;&#31574;&#30053;&#35268;&#21010;&#65292;&#25105;&#20204;&#21457;&#29616;&#26377;&#26102;&#20505;&#30830;&#23454;&#23384;&#22312;&#36825;&#31181;&#29616;&#35937;&#65292;&#36825;&#23545;&#20182;&#20204;&#30340;&#29992;&#25143;&#19981;&#21033;&#12290;&#22240;&#27492;&#65292;&#25552;&#20379;&#31639;&#27861;&#36861;&#32034;&#26435;&#22312;&#31995;&#32479;&#32423;&#21035;&#19978;&#21487;&#33021;&#20063;&#26159;&#26377;&#23475;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Algorithmic recourse provides explanations that help users overturn an unfavorable decision by a machine learning system. But so far very little attention has been paid to whether providing recourse is beneficial or not. We introduce an abstract learning-theoretic framework that compares the risks (i.e. expected losses) for classification with and without algorithmic recourse. This allows us to answer the question of when providing recourse is beneficial or harmful at the population level. Surprisingly, we find that there are many plausible scenarios in which providing recourse turns out to be harmful, because it pushes users to regions of higher class uncertainty and therefore leads to more mistakes. We further study whether the party deploying the classifier has an incentive to strategize in anticipation of having to provide recourse, and we find that sometimes they do, to the detriment of their users. Providing algorithmic recourse may therefore also be harmful at the systemic level
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#29255;&#30340;&#36125;&#21494;&#26031;&#21152;&#24615;&#22238;&#24402;&#26641;&#27169;&#22411;&#65292;&#36890;&#36807;&#24341;&#20837;&#38543;&#26426;&#21270;&#36741;&#21161;&#21464;&#37327;&#21644;&#20998;&#29255;&#26641;&#32467;&#26500;&#65292;&#37319;&#29992;&#36125;&#21494;&#26031;&#21152;&#24615;&#22238;&#24402;&#26641;&#36866;&#37197;&#27599;&#20010;&#20998;&#21306;&#32452;&#20214;&#21040;&#19968;&#20010;&#23376;&#27169;&#22411;&#20013;&#36827;&#34892;&#25968;&#25454;&#20998;&#21306;&#65292;&#24341;&#20837;&#20132;&#38598;&#26641;&#32467;&#26500;&#26469;&#23436;&#20840;&#20351;&#29992;&#26641;&#32467;&#26500;&#25351;&#23450;&#20998;&#29255;&#21644;&#24314;&#27169;&#12290;&#30740;&#31350;&#20013;&#36824;&#25512;&#23548;&#20102;&#29702;&#35770;&#26368;&#20248;&#26435;&#37325;&#21644;&#35777;&#26126;&#20102;&#27169;&#22411;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2306.00361</link><description>&lt;p&gt;
&#22522;&#20110;&#20998;&#29255;&#30340;&#36125;&#21494;&#26031;&#21152;&#24615;&#22238;&#24402;&#26641;
&lt;/p&gt;
&lt;p&gt;
Sharded Bayesian Additive Regression Trees. (arXiv:2306.00361v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00361
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#29255;&#30340;&#36125;&#21494;&#26031;&#21152;&#24615;&#22238;&#24402;&#26641;&#27169;&#22411;&#65292;&#36890;&#36807;&#24341;&#20837;&#38543;&#26426;&#21270;&#36741;&#21161;&#21464;&#37327;&#21644;&#20998;&#29255;&#26641;&#32467;&#26500;&#65292;&#37319;&#29992;&#36125;&#21494;&#26031;&#21152;&#24615;&#22238;&#24402;&#26641;&#36866;&#37197;&#27599;&#20010;&#20998;&#21306;&#32452;&#20214;&#21040;&#19968;&#20010;&#23376;&#27169;&#22411;&#20013;&#36827;&#34892;&#25968;&#25454;&#20998;&#21306;&#65292;&#24341;&#20837;&#20132;&#38598;&#26641;&#32467;&#26500;&#26469;&#23436;&#20840;&#20351;&#29992;&#26641;&#32467;&#26500;&#25351;&#23450;&#20998;&#29255;&#21644;&#24314;&#27169;&#12290;&#30740;&#31350;&#20013;&#36824;&#25512;&#23548;&#20102;&#29702;&#35770;&#26368;&#20248;&#26435;&#37325;&#21644;&#35777;&#26126;&#20102;&#27169;&#22411;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#20998;&#29255;&#30340;&#36125;&#21494;&#26031;&#21152;&#24615;&#22238;&#24402;&#26641;&#65288;SBT&#65289;&#27169;&#22411;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#38543;&#26426;&#21270;&#36741;&#21161;&#21464;&#37327;&#21644;&#19968;&#20010;&#20998;&#29255;&#26641;&#26469;&#20915;&#23450;&#25968;&#25454;&#30340;&#20998;&#21306;&#65292;&#24182;&#20351;&#29992;&#36125;&#21494;&#26031;&#21152;&#24615;&#22238;&#24402;&#26641;&#65288;BART&#65289;&#36866;&#37197;&#27599;&#20010;&#20998;&#21306;&#32452;&#20214;&#21040;&#19968;&#20010;&#23376;&#27169;&#22411;&#20013;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#20998;&#29255;&#26641;&#30340;&#26368;&#20248;&#35774;&#35745;&#21487;&#20197;&#30830;&#23450;&#20135;&#21697;&#31354;&#38388;&#19978;&#23376;&#27169;&#22411;&#30340;&#26368;&#20248;&#20998;&#29255;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#20132;&#38598;&#26641;&#32467;&#26500;&#26469;&#23436;&#20840;&#20351;&#29992;&#26641;&#32467;&#26500;&#25351;&#23450;&#20998;&#29255;&#21644;&#24314;&#27169;&#12290;&#38500;&#20102;&#23454;&#39564;&#22806;&#65292;&#25105;&#20204;&#36824;&#25512;&#23548;&#20102;&#26368;&#23567;&#21270;&#21518;&#39564;&#25910;&#32553;&#30340;&#29702;&#35770;&#26368;&#20248;&#26435;&#37325;&#65292;&#24182;&#35777;&#26126;&#20102;SBT&#30340;&#26368;&#22351;&#24773;&#20917;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we develop the randomized Sharded Bayesian Additive Regression Trees (SBT) model. We introduce a randomization auxiliary variable and a sharding tree to decide partitioning of data, and fit each partition component to a sub-model using Bayesian Additive Regression Tree (BART). By observing that the optimal design of a sharding tree can determine optimal sharding for sub-models on a product space, we introduce an intersection tree structure to completely specify both the sharding and modeling using only tree structures. In addition to experiments, we also derive the theoretical optimal weights for minimizing posterior contractions and prove the worst-case complexity of SBT.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#26377;&#20195;&#29702;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#36827;&#34892;&#25968;&#25454;&#39537;&#21160;&#25935;&#24863;&#24615;&#20998;&#26512;&#21644;&#26435;&#34913;&#22810;&#30446;&#26631;&#30340;&#32500;&#25968;&#32422;&#20943;&#21442;&#25968;&#36873;&#25321;&#26041;&#27861;&#65292;&#24182;&#22312;&#22810;&#20010;&#21512;&#25104;&#21644;&#29616;&#23454;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#35780;&#20272;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#31283;&#20581;&#19988;&#39640;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2306.00357</link><description>&lt;p&gt;
&#39640;&#25928;&#31283;&#20581;&#30340;&#36125;&#21494;&#26031;&#32500;&#25968;&#32422;&#20943;&#21442;&#25968;&#36873;&#25321;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Efficient and Robust Bayesian Selection of Hyperparameters in Dimension Reduction for Visualization. (arXiv:2306.00357v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00357
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#26377;&#20195;&#29702;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#36827;&#34892;&#25968;&#25454;&#39537;&#21160;&#25935;&#24863;&#24615;&#20998;&#26512;&#21644;&#26435;&#34913;&#22810;&#30446;&#26631;&#30340;&#32500;&#25968;&#32422;&#20943;&#21442;&#25968;&#36873;&#25321;&#26041;&#27861;&#65292;&#24182;&#22312;&#22810;&#20010;&#21512;&#25104;&#21644;&#29616;&#23454;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#35780;&#20272;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#31283;&#20581;&#19988;&#39640;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#31283;&#20581;&#30340;&#33258;&#21160;&#35843;&#21442;&#26694;&#26550;&#65292;&#22312;&#32500;&#25968;&#32422;&#20943;&#31639;&#27861;&#20013;&#36873;&#25321;&#36229;&#21442;&#25968;&#65292;&#27880;&#37325;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#21644;&#20219;&#24847;&#24615;&#33021;&#25351;&#26631;&#12290;&#36890;&#36807;&#21033;&#29992;&#26377;&#20195;&#29702;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#24471;&#36229;&#21442;&#25968;&#36873;&#25321;&#20855;&#26377;&#22810;&#30446;&#26631;&#26435;&#34913;&#65292;&#24182;&#19988;&#20801;&#35768;&#25105;&#20204;&#36827;&#34892;&#25968;&#25454;&#39537;&#21160;&#30340;&#25935;&#24863;&#24615;&#20998;&#26512;&#12290;&#36890;&#36807;&#32467;&#21512;&#24402;&#19968;&#21270;&#21644;&#23376;&#37319;&#26679;&#65292;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#22312;&#21487;&#35270;&#21270;&#25216;&#26415;&#22914;t-SNE&#21644;UMAP&#20013;&#23637;&#29616;&#20986;&#20102;&#36890;&#29992;&#24615;&#21644;&#39640;&#25928;&#24615;&#12290;&#25105;&#20204;&#20351;&#29992;&#22810;&#20010;&#36136;&#37327;&#24230;&#37327;&#22312;&#21508;&#31181;&#21512;&#25104;&#21644;&#29616;&#23454;&#25968;&#25454;&#38598;&#19978;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#32467;&#26524;&#65292;&#20026;&#32500;&#25968;&#32422;&#20943;&#31639;&#27861;&#30340;&#36229;&#21442;&#25968;&#36873;&#25321;&#25552;&#20379;&#20102;&#19968;&#31181;&#31283;&#20581;&#19988;&#39640;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce an efficient and robust auto-tuning framework for hyperparameter selection in dimension reduction (DR) algorithms, focusing on large-scale datasets and arbitrary performance metrics. By leveraging Bayesian optimization (BO) with a surrogate model, our approach enables efficient hyperparameter selection with multi-objective trade-offs and allows us to perform data-driven sensitivity analysis. By incorporating normalization and subsampling, the proposed framework demonstrates versatility and efficiency, as shown in applications to visualization techniques such as t-SNE and UMAP. We evaluate our results on various synthetic and real-world datasets using multiple quality metrics, providing a robust and efficient solution for hyperparameter selection in DR algorithms.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#27010;&#29575;&#35270;&#35282;&#30340;&#23545;&#25239;&#26679;&#26412;&#26500;&#24314;&#26041;&#27861;&#65292;&#21487;&#20197;&#29983;&#25104;&#35821;&#20041;&#24863;&#30693;&#30340;&#23545;&#25239;&#24615;&#26679;&#26412;&#65292;&#24182;&#21487;&#20197;&#26377;&#25928;&#35268;&#36991;&#20256;&#32479;&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#24378;&#21270;&#23545;&#25239;&#35757;&#32451;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.00353</link><description>&lt;p&gt;
&#20174;&#27010;&#29575;&#35282;&#24230;&#26500;&#24314;&#35821;&#20041;&#24863;&#30693;&#30340;&#23545;&#25239;&#26679;&#26412;
&lt;/p&gt;
&lt;p&gt;
Constructing Semantics-Aware Adversarial Examples with Probabilistic Perspective. (arXiv:2306.00353v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00353
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#27010;&#29575;&#35270;&#35282;&#30340;&#23545;&#25239;&#26679;&#26412;&#26500;&#24314;&#26041;&#27861;&#65292;&#21487;&#20197;&#29983;&#25104;&#35821;&#20041;&#24863;&#30693;&#30340;&#23545;&#25239;&#24615;&#26679;&#26412;&#65292;&#24182;&#21487;&#20197;&#26377;&#25928;&#35268;&#36991;&#20256;&#32479;&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#24378;&#21270;&#23545;&#25239;&#35757;&#32451;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27010;&#29575;&#35270;&#35282;&#23545;&#25239;&#26679;&#26412;&#26500;&#24314;&#26041;&#27861;&#8212;&#8212;&#31665;&#32422;&#26463; Langevin Monte Carlo&#65288;LMC&#65289;&#12290;&#20174;&#36825;&#20010;&#35282;&#24230;&#20986;&#21457;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#21019;&#26032;&#24615;&#30340;&#26041;&#27861;&#65292;&#20197;&#21407;&#21017;&#24615;&#30340;&#26041;&#24335;&#29983;&#25104;&#35821;&#20041;&#24863;&#30693;&#30340;&#23545;&#25239;&#24615;&#26679;&#26412;&#12290;&#36825;&#31181;&#26041;&#27861;&#36229;&#36234;&#20102;&#20960;&#20309;&#36317;&#31163;&#25152;&#26045;&#21152;&#30340;&#38480;&#21046;&#65292;&#36873;&#25321;&#20102;&#35821;&#20041;&#32422;&#26463;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36171;&#20104;&#20102;&#20010;&#20307;&#23558;&#20854;&#23545;&#35821;&#20041;&#30340;&#29702;&#35299;&#34701;&#20837;&#21040;&#27169;&#22411;&#20013;&#30340;&#33021;&#21147;&#12290;&#36890;&#36807;&#20154;&#31867;&#35780;&#20272;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#35821;&#20041;&#24863;&#30693;&#30340;&#23545;&#25239;&#26679;&#26412;&#20445;&#25345;&#20854;&#22266;&#26377;&#30340;&#21547;&#20041;&#12290;&#22312; MNIST &#21644; SVHN &#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#35821;&#20041;&#24863;&#30693;&#30340;&#23545;&#25239;&#26679;&#26412;&#21487;&#20197;&#26377;&#25928;&#22320;&#35268;&#36991;&#38024;&#23545;&#20256;&#32479;&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#24378;&#20581;&#24615;&#23545;&#25239;&#35757;&#32451;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this study, we introduce a novel, probabilistic viewpoint on adversarial examples, achieved through box-constrained Langevin Monte Carlo (LMC). Proceeding from this perspective, we develop an innovative approach for generating semantics-aware adversarial examples in a principled manner. This methodology transcends the restriction imposed by geometric distance, instead opting for semantic constraints. Our approach empowers individuals to incorporate their personal comprehension of semantics into the model. Through human evaluation, we validate that our semantics-aware adversarial examples maintain their inherent meaning. Experimental findings on the MNIST and SVHN datasets demonstrate that our semantics-aware adversarial examples can effectively circumvent robust adversarial training methods tailored for traditional adversarial attacks.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#33021;&#37327;&#23432;&#24658;&#19979;&#38477;&#65288;ECD&#65289;&#30340;&#29702;&#35770;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#31639;&#27861;ECDSep&#65292;&#33021;&#22815;&#22788;&#29702;&#20984;&#20248;&#21270;&#38382;&#39064;&#21644;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#25913;&#36827;&#21160;&#24577;&#21644;&#28151;&#27788;&#35825;&#23548;&#20803;&#32032;&#65292;&#25552;&#39640;&#24615;&#33021;&#65307;&#22312;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#19978;&#19982;&#27969;&#34892;&#30340;&#20248;&#21270;&#26041;&#27861;&#36827;&#34892;&#20102;&#23454;&#35777;&#27604;&#36739;&#65292;&#21457;&#29616;&#22312;&#27599;&#20010;&#20219;&#21153;&#20013;&#20855;&#26377;&#31454;&#20105;&#21147;&#25110;&#25913;&#36827;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.00352</link><description>&lt;p&gt;
&#25913;&#36827;&#26426;&#22120;&#23398;&#20064;&#30340;&#33021;&#37327;&#23432;&#24658;&#19979;&#38477;&#27861;&#65306;&#29702;&#35770;&#19982;&#23454;&#36341;
&lt;/p&gt;
&lt;p&gt;
Improving Energy Conserving Descent for Machine Learning: Theory and Practice. (arXiv:2306.00352v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00352
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#33021;&#37327;&#23432;&#24658;&#19979;&#38477;&#65288;ECD&#65289;&#30340;&#29702;&#35770;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#31639;&#27861;ECDSep&#65292;&#33021;&#22815;&#22788;&#29702;&#20984;&#20248;&#21270;&#38382;&#39064;&#21644;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#25913;&#36827;&#21160;&#24577;&#21644;&#28151;&#27788;&#35825;&#23548;&#20803;&#32032;&#65292;&#25552;&#39640;&#24615;&#33021;&#65307;&#22312;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#19978;&#19982;&#27969;&#34892;&#30340;&#20248;&#21270;&#26041;&#27861;&#36827;&#34892;&#20102;&#23454;&#35777;&#27604;&#36739;&#65292;&#21457;&#29616;&#22312;&#27599;&#20010;&#20219;&#21153;&#20013;&#20855;&#26377;&#31454;&#20105;&#21147;&#25110;&#25913;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#21457;&#23637;&#20102;&#33021;&#37327;&#23432;&#24658;&#19979;&#38477;&#65288;ECD&#65289;&#30340;&#29702;&#35770;&#65292;&#24182;&#20171;&#32461;&#20102;ECDSep&#65292;&#36825;&#26159;&#19968;&#31181;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#31639;&#27861;&#65292;&#33021;&#22815;&#22788;&#29702;&#20984;&#20248;&#21270;&#38382;&#39064;&#21644;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;&#26032;&#39062;&#30340;ECD&#20248;&#21270;&#26694;&#26550;&#65292;&#36890;&#36807;&#36866;&#24403;&#28151;&#27788;&#30340;&#33021;&#37327;&#23432;&#24658;&#21160;&#21147;&#31995;&#32479;&#30340;&#29289;&#29702;&#28436;&#21270;&#26469;&#23454;&#29616;&#65292;&#20351;&#24471;&#21363;&#20351;&#23545;&#20110;&#26080;&#23545;&#31216;&#24615;&#30340;&#36890;&#29992;&#39640;&#32500;&#38382;&#39064;&#30340;&#32467;&#26524;&#20998;&#24067;&#20063;&#33021;&#36827;&#34892;&#20998;&#26512;&#25511;&#21046;&#65292;&#20174;&#32780;&#20027;&#23548;&#20302;&#25439;&#22833;&#12290;&#19982;&#20197;&#24448;&#30340;&#23454;&#29616;&#30456;&#27604;&#65292;&#25105;&#20204;&#21033;&#29992;&#29702;&#35770;&#25511;&#21046;&#26469;&#25913;&#36827;&#21160;&#24577;&#21644;&#35825;&#23548;&#28151;&#27788;&#30340;&#20803;&#32032;&#65292;&#25552;&#39640;&#24615;&#33021;&#65292;&#21516;&#26102;&#31616;&#21270;&#38754;&#21521;&#19981;&#21516;&#31867;&#21035;&#38382;&#39064;&#30340;&#20248;&#21270;&#31639;&#27861;&#30340;&#36229;&#21442;&#25968;&#35843;&#25972;&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#19978;&#19982;&#27969;&#34892;&#30340;&#20248;&#21270;&#26041;&#27861;&#65288;&#22914;SGD&#65292;Adam&#21644;AdamW&#31561;&#65289;&#36827;&#34892;&#20102;&#23454;&#35777;&#27604;&#36739;&#65292;&#21457;&#29616;&#22312;&#27599;&#20010;&#20219;&#21153;&#20013;&#19982;&#23427;&#20204;&#20013;&#30340;&#26368;&#20339;&#26041;&#27861;&#30456;&#27604;&#20855;&#26377;&#31454;&#20105;&#21147;&#25110;&#25913;&#36827;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#30830;&#23450;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#26410;&#26469;&#30740;&#31350;&#30340;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop the theory of Energy Conserving Descent (ECD) and introduce ECDSep, a gradient-based optimization algorithm able to tackle convex and non-convex optimization problems. The method is based on the novel ECD framework of optimization as physical evolution of a suitable chaotic energy-conserving dynamical system, enabling analytic control of the distribution of results - dominated at low loss - even for generic high-dimensional problems with no symmetries. Compared to previous realizations of this idea, we exploit the theoretical control to improve both the dynamics and chaos-inducing elements, enhancing performance while simplifying the hyper-parameter tuning of the optimization algorithm targeted to different classes of problems. We empirically compare with popular optimization methods such as SGD, Adam and AdamW on a wide range of machine learning problems, finding competitive or improved performance compared to the best among them on each task. We identify limitations in our
&lt;/p&gt;</description></item><item><title>BOtied &#26159;&#19968;&#31181;&#24102;&#26377;&#30456;&#20851;&#22810;&#20803;&#31561;&#32423;&#30340;&#22810;&#30446;&#26631;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#65292;&#30456;&#36739;&#20110;&#29616;&#26377;&#30340;&#26041;&#27861;&#20855;&#26377;&#26356;&#39640;&#30340;&#26679;&#26412;&#25928;&#29575;&#21644;&#36739;&#22909;&#30340;&#36817;&#20284;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2306.00344</link><description>&lt;p&gt;
BOtied: &#24102;&#26377;&#30456;&#20851;&#22810;&#20803;&#31561;&#32423;&#30340;&#22810;&#30446;&#26631;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
BOtied: Multi-objective Bayesian optimization with tied multivariate ranks. (arXiv:2306.00344v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00344
&lt;/p&gt;
&lt;p&gt;
BOtied &#26159;&#19968;&#31181;&#24102;&#26377;&#30456;&#20851;&#22810;&#20803;&#31561;&#32423;&#30340;&#22810;&#30446;&#26631;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#65292;&#30456;&#36739;&#20110;&#29616;&#26377;&#30340;&#26041;&#27861;&#20855;&#26377;&#26356;&#39640;&#30340;&#26679;&#26412;&#25928;&#29575;&#21644;&#36739;&#22909;&#30340;&#36817;&#20284;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#31185;&#23398;&#21644;&#24037;&#19994;&#24212;&#29992;&#38656;&#35201;&#21516;&#26102;&#20248;&#21270;&#22810;&#20010;&#28508;&#22312;&#30340;&#30456;&#20114;&#20914;&#31361;&#30340;&#30446;&#26631;&#12290;&#22810;&#30446;&#26631;&#36125;&#21494;&#26031;&#20248;&#21270; (MOBO) &#26159;&#19968;&#31181;&#39640;&#25928;&#22320;&#35782;&#21035; Pareto &#26368;&#20248;&#35299;&#30340;&#26694;&#26550;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#26080;&#25903;&#37197;&#35299;&#21644;&#26368;&#39640;&#22810;&#20803;&#31561;&#32423;&#20043;&#38388;&#30340;&#33258;&#28982;&#32852;&#31995;&#65292;&#23427;&#19982;&#32852;&#21512;&#32047;&#31215;&#20998;&#24067;&#20989;&#25968;&#30340;&#26368;&#22806;&#23618;&#31561;&#39640;&#32447;&#37325;&#21512;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102; CDF indicator&#65292;&#36825;&#26159;&#19968;&#31181; Pareto &#21512;&#35268;&#30340;&#24230;&#37327;&#65292;&#29992;&#20110;&#35780;&#20272;&#36817;&#20284; Pareto &#38598;&#21512;&#30340;&#36136;&#37327;&#65292;&#23427;&#34917;&#20805;&#20102;&#27969;&#34892;&#30340; hypervolume indicator&#12290;MOBO &#30340;&#26680;&#24515;&#26159;&#37319;&#38598;&#20989;&#25968;&#65292;&#23427;&#36890;&#36807;&#23548;&#33322;&#30446;&#26631;&#20043;&#38388;&#30340;&#26368;&#20339;&#25240;&#20013;&#26469;&#30830;&#23450;&#19979;&#19968;&#20010;&#35201;&#35780;&#20272;&#30340;&#20505;&#36873;&#39033;&#12290; &#22522;&#20110;&#30418;&#23376;&#20998;&#35299;&#30446;&#26631;&#31354;&#38388;&#30340;&#22810;&#30446;&#26631;&#37319;&#38598;&#20989;&#25968;&#65288;&#20363;&#22914;&#26399;&#26395;&#30340; hypervolume &#25913;&#36827;&#65288;EHVI&#65289;&#21644;&#29109;&#25628;&#32034;&#65289;&#22312;&#23384;&#22312;&#22823;&#37327;&#30446;&#26631;&#26102;&#30340;&#24615;&#33021;&#32553;&#25918;&#24456;&#24046;&#12290;&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#37319;&#38598;&#20989;&#25968;&#65292;&#31216;&#20026; BOtied&#65292;&#23427;&#21033;&#29992;&#30456;&#20851;&#22810;&#20803;&#31561;&#32423;&#26469;&#39640;&#25928;&#25628;&#32034; Pareto frontier&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;BOtied &#22312;&#26679;&#26412;&#25928;&#29575;&#21644;&#36817;&#20284;&#36136;&#37327;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many scientific and industrial applications require joint optimization of multiple, potentially competing objectives. Multi-objective Bayesian optimization (MOBO) is a sample-efficient framework for identifying Pareto-optimal solutions. We show a natural connection between non-dominated solutions and the highest multivariate rank, which coincides with the outermost level line of the joint cumulative distribution function (CDF). We propose the CDF indicator, a Pareto-compliant metric for evaluating the quality of approximate Pareto sets that complements the popular hypervolume indicator. At the heart of MOBO is the acquisition function, which determines the next candidate to evaluate by navigating the best compromises among the objectives. Multi-objective acquisition functions that rely on box decomposition of the objective space, such as the expected hypervolume improvement (EHVI) and entropy search, scale poorly to a large number of objectives. We propose an acquisition function, call
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26174;&#24335;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#19982;&#38544;&#24335;&#27491;&#21017;&#21270;&#32467;&#21512;&#65292;&#21487;&#20197;&#20351;&#21333;&#23618;&#32593;&#32476;&#23454;&#29616;&#19982;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#30456;&#24403;&#30340;&#20302;&#31209;&#36817;&#20284;&#21644;&#27867;&#21270;&#35823;&#24046;&#65292;&#20351;&#28145;&#24230;&#19981;&#20877;&#26159;&#23398;&#20064;&#30340;&#24517;&#35201;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2306.00342</link><description>&lt;p&gt;
&#32467;&#21512;&#26174;&#24335;&#21644;&#38544;&#24335;&#27491;&#21017;&#21270;&#30340;&#28145;&#24230;&#32593;&#32476;&#39640;&#25928;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Combining Explicit and Implicit Regularization for Efficient Learning in Deep Networks. (arXiv:2306.00342v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00342
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26174;&#24335;&#27491;&#21017;&#21270;&#26041;&#27861;&#65292;&#19982;&#38544;&#24335;&#27491;&#21017;&#21270;&#32467;&#21512;&#65292;&#21487;&#20197;&#20351;&#21333;&#23618;&#32593;&#32476;&#23454;&#29616;&#19982;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#30456;&#24403;&#30340;&#20302;&#31209;&#36817;&#20284;&#21644;&#27867;&#21270;&#35823;&#24046;&#65292;&#20351;&#28145;&#24230;&#19981;&#20877;&#26159;&#23398;&#20064;&#30340;&#24517;&#35201;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38544;&#24335;&#27491;&#21017;&#21270;&#30740;&#31350;&#20248;&#21270;&#36807;&#31243;&#20013;&#30340;&#26799;&#24230;&#36712;&#36857;&#65292;&#20197;&#35299;&#37322;&#20026;&#20160;&#20040;&#28145;&#24230;&#32593;&#32476;&#26356;&#20542;&#21521;&#20110;&#26576;&#20123;&#35299;&#20915;&#26041;&#26696;&#12290;&#22312;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#20013;&#65292;&#24050;&#32463;&#35777;&#26126;&#26799;&#24230;&#19979;&#38477;&#38544;&#24335;&#22320;&#26397;&#21521;&#30697;&#38453;&#34917;&#20840;/&#22240;&#24335;&#20998;&#35299;&#20219;&#21153;&#19978;&#30340;&#20302;&#31209;&#35299;&#20915;&#26041;&#26696;&#36827;&#34892;&#27491;&#21017;&#21270;&#12290;&#28155;&#21152;&#23618;&#25968;&#19981;&#20165;&#21487;&#20197;&#25552;&#39640;&#36825;&#20123;&#20219;&#21153;&#30340;&#24615;&#33021;&#65292;&#32780;&#19988;&#20316;&#20026;&#19968;&#31181;&#21152;&#36895;&#30340;&#39044;&#22788;&#29702;&#26041;&#27861;&#36827;&#19968;&#27493;&#22686;&#24378;&#20102;&#36825;&#31181;&#20302;&#31209;&#20559;&#21521;&#12290;&#21463;&#27492;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#26174;&#24335;&#24809;&#32602;&#26469;&#21453;&#26144;&#36825;&#31181;&#38544;&#24335;&#20559;&#24046;&#65292;&#21482;&#22312;&#26576;&#20123;&#33258;&#36866;&#24212;&#26799;&#24230;&#20248;&#21270;&#22120;&#65288;&#20363;&#22914;Adam&#65289;&#36215;&#20316;&#29992;&#12290;&#36825;&#31181;&#32452;&#21512;&#21487;&#20197;&#20351;&#36864;&#21270;&#30340;&#21333;&#23618;&#32593;&#32476;&#23454;&#29616;&#19982;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#30456;&#24403;&#30340;&#20302;&#31209;&#36817;&#20284;&#21644;&#27867;&#21270;&#35823;&#24046;&#65292;&#20351;&#28145;&#24230;&#19981;&#20877;&#26159;&#23398;&#20064;&#30340;&#24517;&#35201;&#26465;&#20214;&#12290;&#21333;&#23618;&#32593;&#32476;&#36824;&#22312;&#19968;&#31995;&#21015;&#21442;&#25968;&#21644;&#25968;&#25454;&#38598;&#19978;&#33021;&#22815;&#34920;&#29616;&#20248;&#24322;&#65292;&#29978;&#33267;&#36229;&#36807;&#20102;&#21508;&#31181;&#30697;&#38453;&#34917;&#20840;&#26041;&#27861;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Works on implicit regularization have studied gradient trajectories during the optimization process to explain why deep networks favor certain kinds of solutions over others. In deep linear networks, it has been shown that gradient descent implicitly regularizes toward low-rank solutions on matrix completion/factorization tasks. Adding depth not only improves performance on these tasks but also acts as an accelerative pre-conditioning that further enhances this bias towards low-rankedness. Inspired by this, we propose an explicit penalty to mirror this implicit bias which only takes effect with certain adaptive gradient optimizers (e.g. Adam). This combination can enable a degenerate single-layer network to achieve low-rank approximations with generalization error comparable to deep linear networks, making depth no longer necessary for learning. The single-layer network also performs competitively or out-performs various approaches for matrix completion over a range of parameter and da
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#19981;&#19968;&#33268;&#24615;&#20559;&#24046;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#19968;&#20010;&#31616;&#21333;&#12289;&#30452;&#35266;&#30340;&#26465;&#20214;&#25512;&#23548;&#20986;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#20998;&#24067;&#36716;&#31227;&#19979;&#30340;(&#20960;&#20046;)&#21487;&#35777;&#26126;&#35823;&#24046;&#30028;&#38480;&#65292;&#30456;&#27604;&#20110;$\mathcal{H}\Delta\mathcal{H}$-divergence&#26356;&#32039;&#23494;&#12289;&#26356;&#26131;&#35780;&#20215;&#12290;</title><link>http://arxiv.org/abs/2306.00312</link><description>&lt;p&gt;
&#36890;&#36807;&#19981;&#19968;&#33268;&#24615;&#20559;&#24046;&#25512;&#23548;&#20986;&#20998;&#24067;&#36716;&#31227;&#19979;&#30340;(&#20960;&#20046;)&#21487;&#35777;&#26126;&#35823;&#24046;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
(Almost) Provable Error Bounds Under Distribution Shift via Disagreement Discrepancy. (arXiv:2306.00312v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00312
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#19981;&#19968;&#33268;&#24615;&#20559;&#24046;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#19968;&#20010;&#31616;&#21333;&#12289;&#30452;&#35266;&#30340;&#26465;&#20214;&#25512;&#23548;&#20986;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#20998;&#24067;&#36716;&#31227;&#19979;&#30340;(&#20960;&#20046;)&#21487;&#35777;&#26126;&#35823;&#24046;&#30028;&#38480;&#65292;&#30456;&#27604;&#20110;$\mathcal{H}\Delta\mathcal{H}$-divergence&#26356;&#32039;&#23494;&#12289;&#26356;&#26131;&#35780;&#20215;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#26410;&#26631;&#35760;&#30340;&#27979;&#35797;&#25968;&#25454;&#65292;&#25512;&#23548;&#20986;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#20998;&#24067;&#36716;&#25442;&#19979;&#35823;&#24046;&#30340;(&#20960;&#20046;)&#20445;&#35777;&#19978;&#38480;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#38656;&#35201;&#19968;&#20010;&#31616;&#21333;&#12289;&#30452;&#35266;&#30340;&#26465;&#20214;&#65292;&#30001;&#20808;&#21069;&#30340;&#32463;&#39564;&#30740;&#31350;&#24456;&#22909;&#22320;&#35777;&#26126;&#19988;&#22312;&#23454;&#38469;&#25805;&#20316;&#20013;&#26377;&#25928;&#29575;&#22320;&#28385;&#36275;&#65292;&#32780;&#19988;&#30456;&#27604;&#20110;$\mathcal{H}\Delta\mathcal{H}$-divergence&#26356;&#23481;&#26131;&#35780;&#20215;&#19988;&#20445;&#35777;&#26356;&#32039;&#23494;&#12289;&#26356;&#19981;&#34394;&#20266;&#12290;
&lt;/p&gt;
&lt;p&gt;
We derive an (almost) guaranteed upper bound on the error of deep neural networks under distribution shift using unlabeled test data. Prior methods either give bounds that are vacuous in practice or give estimates that are accurate on average but heavily underestimate error for a sizeable fraction of shifts. In particular, the latter only give guarantees based on complex continuous measures such as test calibration -- which cannot be identified without labels -- and are therefore unreliable. Instead, our bound requires a simple, intuitive condition which is well justified by prior empirical works and holds in practice effectively 100% of the time. The bound is inspired by $\mathcal{H}\Delta\mathcal{H}$-divergence but is easier to evaluate and substantially tighter, consistently providing non-vacuous guarantees. Estimating the bound requires optimizing one multiclass classifier to disagree with another, for which some prior works have used sub-optimal proxy losses; we devise a "disagree
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38754;&#21521;&#38750;&#22343;&#21248;&#21644;&#26102;&#21464;&#36890;&#20449;&#25925;&#38556;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FedPBC&#30340;&#32852;&#37030;&#23398;&#20064;&#31639;&#27861;&#26469;&#20462;&#27491;FedAvg&#30340;&#20559;&#24046;&#65292;&#35813;&#31639;&#27861;&#26500;&#24314;&#20108;&#21449;&#26641;&#26469;&#20943;&#36731;&#38750;&#22343;&#21248;&#36890;&#20449;&#25925;&#38556;&#30340;&#24433;&#21709;&#65292;&#24182;&#22312;&#38750;&#20984;&#20219;&#21153;&#19978;&#23454;&#39564;&#32467;&#26524;&#34920;&#29616;&#20248;&#20110;FedAvg&#12290;</title><link>http://arxiv.org/abs/2306.00280</link><description>&lt;p&gt;
&#38754;&#21521;&#38750;&#22343;&#21248;&#21644;&#26102;&#21464;&#36890;&#20449;&#30340;FedAvg&#20559;&#24046;&#20462;&#27491;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Towards Bias Correction of FedAvg over Nonuniform and Time-Varying Communications. (arXiv:2306.00280v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00280
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38754;&#21521;&#38750;&#22343;&#21248;&#21644;&#26102;&#21464;&#36890;&#20449;&#25925;&#38556;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FedPBC&#30340;&#32852;&#37030;&#23398;&#20064;&#31639;&#27861;&#26469;&#20462;&#27491;FedAvg&#30340;&#20559;&#24046;&#65292;&#35813;&#31639;&#27861;&#26500;&#24314;&#20108;&#21449;&#26641;&#26469;&#20943;&#36731;&#38750;&#22343;&#21248;&#36890;&#20449;&#25925;&#38556;&#30340;&#24433;&#21709;&#65292;&#24182;&#22312;&#38750;&#20984;&#20219;&#21153;&#19978;&#23454;&#39564;&#32467;&#26524;&#34920;&#29616;&#20248;&#20110;FedAvg&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#26159;&#19968;&#31181;&#20998;&#25955;&#30340;&#23398;&#20064;&#26694;&#26550;&#65292;&#22312;&#36825;&#20010;&#26694;&#26550;&#19979;&#65292;&#21442;&#25968;&#26381;&#21153;&#22120;&#65288;PS&#65289;&#21644;&#22810;&#20010;&#23458;&#25143;&#31471;&#21512;&#20316;&#36890;&#36807;&#26368;&#23567;&#21270;&#20840;&#23616;&#30446;&#26631;&#26469;&#35757;&#32451;&#27169;&#22411;&#12290;&#36890;&#20449;&#24102;&#23485;&#26159;&#19968;&#31181;&#31232;&#32570;&#36164;&#28304;&#65307;&#22312;&#27599;&#36718;&#36845;&#20195;&#20013;&#65292;PS&#20165;&#20174;&#23458;&#25143;&#31471;&#30340;&#23376;&#38598;&#32858;&#21512;&#26356;&#26032;&#12290;&#26412;&#25991;&#20851;&#27880;&#30340;&#26159;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#36825;&#31181;&#38382;&#39064;&#23481;&#26131;&#21463;&#21040;PS&#21644;&#23458;&#25143;&#31471;&#20043;&#38388;&#19981;&#22343;&#21248;&#12289;&#26102;&#21464;&#30340;&#36890;&#20449;&#25925;&#38556;&#30340;&#24433;&#21709;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#22312;&#27599;&#36718;$t$&#20013;&#65292;PS&#21644;&#23458;&#25143;&#31471;$i$&#20043;&#38388;&#30340;&#36830;&#25509;&#21482;&#26377;&#27010;&#29575;$p_i^t$&#26159;&#27963;&#36291;&#30340;&#65292;&#32780;&#36825;&#20010;&#27010;&#29575;&#26159;&#19981;&#30693;&#36947;&#30340;&#12290;&#24403;&#20449;&#36947;&#26465;&#20214;&#22312;&#23458;&#25143;&#31471;&#20043;&#38388;&#24322;&#26500;&#24182;&#19988;&#38543;&#26102;&#38388;&#21464;&#21270;&#26102;&#65292;&#36825;&#31181;&#24773;&#20917;&#20250;&#21457;&#29983;&#12290;&#25105;&#20204;&#21457;&#29616;&#24403;$p_i^t$&#38750;&#22343;&#21248;&#26102;&#65292;&#34987;&#24191;&#27867;&#37319;&#29992;&#30340;FL&#31639;&#27861;FedAvg&#26080;&#27861;&#26368;&#23567;&#21270;&#20840;&#23616;&#30446;&#26631;&#12290;&#37492;&#20110;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;FedPBC&#30340;&#31616;&#21333;&#26377;&#25928;&#30340;&#26041;&#27861;&#26469;&#20943;&#36731;&#38750;&#22343;&#21248;&#36890;&#20449;&#25925;&#38556;&#30340;&#24433;&#21709;&#12290;FedPBC&#22312;&#23458;&#25143;&#31471;&#20043;&#38388;&#26500;&#24314;&#20108;&#21449;&#26641;&#65292;&#22312;&#24314;&#31435;&#25299;&#25169;&#32467;&#26500;&#20043;&#21069;&#25512;&#36831;&#26356;&#26032;&#30340;&#20256;&#36755;&#65292;&#24182;&#25429;&#25417;&#26412;&#22320;&#26356;&#26032;&#30340;&#37325;&#35201;&#24615;&#12290;&#25105;&#20204;&#22312;&#28201;&#21644;&#20551;&#35774;&#19979;&#29702;&#35770;&#35777;&#26126;&#20102;FedPBC&#25910;&#25947;&#20110;&#38750;&#20984;&#38382;&#39064;&#30340;&#20840;&#23616;&#26368;&#20248;&#35299;&#12290;&#22312;&#38750;&#20984;&#20219;&#21153;&#65288;&#22914;&#22270;&#20687;&#20998;&#31867;&#21644;&#35821;&#35328;&#24314;&#27169;&#65289;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;FedPBC&#22312;&#38750;&#22343;&#21248;&#21644;&#26102;&#21464;&#30340;&#36890;&#20449;&#35774;&#32622;&#19979;&#20248;&#20110;FedAvg&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated learning (FL) is a decentralized learning framework wherein a parameter server (PS) and a collection of clients collaboratively train a model via minimizing a global objective. Communication bandwidth is a scarce resource; in each round, the PS aggregates the updates from a subset of clients only. In this paper, we focus on non-convex minimization that is vulnerable to non-uniform and time-varying communication failures between the PS and the clients. Specifically, in each round $t$, the link between the PS and client $i$ is active with probability $p_i^t$, which is $\textit{unknown}$ to both the PS and the clients. This arises when the channel conditions are heterogeneous across clients and are changing over time.  We show that when the $p_i^t$'s are not uniform, $\textit{Federated Average}$ (FedAvg) -- the most widely adopted FL algorithm -- fails to minimize the global objective. Observing this, we propose $\textit{Federated Postponed Broadcast}$ (FedPBC) which is a simple
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#35777;&#26126;&#20102;&#20351;&#29992;Mixup&#35757;&#32451;&#20855;&#26377;&#21487;&#35777;&#23454;&#30340;&#30410;&#22788;&#65292;&#21487;&#20197;&#26174;&#33879;&#38477;&#20302;&#22312;&#26356;&#21487;&#20998;&#31163;&#25968;&#25454;&#20998;&#24067;&#20013;&#23547;&#25214;&#26368;&#20339;&#20915;&#31574;&#36793;&#30028;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2306.00267</link><description>&lt;p&gt;
Mixup&#22312;&#23547;&#25214;&#26368;&#20339;&#20915;&#31574;&#36793;&#30028;&#20013;&#30340;&#21487;&#35777;&#23454;&#30410;&#22788;
&lt;/p&gt;
&lt;p&gt;
Provable Benefit of Mixup for Finding Optimal Decision Boundaries. (arXiv:2306.00267v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00267
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35777;&#26126;&#20102;&#20351;&#29992;Mixup&#35757;&#32451;&#20855;&#26377;&#21487;&#35777;&#23454;&#30340;&#30410;&#22788;&#65292;&#21487;&#20197;&#26174;&#33879;&#38477;&#20302;&#22312;&#26356;&#21487;&#20998;&#31163;&#25968;&#25454;&#20998;&#24067;&#20013;&#23547;&#25214;&#26368;&#20339;&#20915;&#31574;&#36793;&#30028;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20687;Mixup&#36825;&#26679;&#30340;&#25104;&#23545;&#25968;&#25454;&#22686;&#24378;&#25216;&#26415;&#22914;&#20309;&#24433;&#21709;&#22312;&#20108;&#20803;&#32447;&#24615;&#20998;&#31867;&#38382;&#39064;&#20013;&#23547;&#25214;&#26368;&#20339;&#20915;&#31574;&#36793;&#30028;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#38024;&#23545;&#19968;&#31867;&#20855;&#26377;&#21487;&#20998;&#31163;&#24120;&#25968;$\kappa$&#30340;&#25968;&#25454;&#20998;&#24067;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#35757;&#32451;&#25439;&#22833;&#26368;&#20248;&#20998;&#31867;&#22120;&#19982;&#27979;&#35797;&#20934;&#30830;&#29575;&#26368;&#20248;&#20998;&#31867;&#22120;&#65288;&#21363;&#36125;&#21494;&#26031;&#26368;&#20248;&#20998;&#31867;&#22120;&#65289;&#20043;&#38388;&#30340;&#23545;&#40784;&#31243;&#24230;&#12290;&#23545;&#20110;&#27809;&#26377;&#22686;&#24378;&#30340;&#26222;&#36890;&#35757;&#32451;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#19968;&#31181;&#26377;&#36259;&#30340;&#29616;&#35937;&#65292;&#31216;&#20026;&#21487;&#20998;&#31163;&#24615;&#30340;&#35781;&#21650;&#12290;&#38543;&#30528;&#25105;&#20204;&#22686;&#21152;$\kappa$&#20351;&#25968;&#25454;&#20998;&#24067;&#26356;&#21152;&#21487;&#20998;&#31163;&#65292;&#26222;&#36890;&#35757;&#32451;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20250;&#22312;$\kappa$&#20013;&#21576;&#25351;&#25968;&#22686;&#38271;&#12290;&#20063;&#35768;&#26356;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#23545;&#20110;&#26356;&#21487;&#20998;&#31163;&#30340;&#25968;&#25454;&#20998;&#24067;&#32780;&#35328;&#65292;&#23547;&#25214;&#26368;&#20339;&#20915;&#31574;&#36793;&#30028;&#30340;&#20219;&#21153;&#21464;&#24471;&#26356;&#21152;&#22256;&#38590;&#12290;&#38024;&#23545;Mixup&#35757;&#32451;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;Mixup&#20943;&#36731;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#36890;&#36807;&#26174;&#33879;&#38477;&#20302;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#36866;&#29992;&#20110;Mixup&#32771;&#34385;&#30340;$n^2$&#25104;&#23545;&#22686;&#24378;&#25968;&#25454;&#28857;&#30340;&#26032;&#30340;&#38598;&#20013;&#32467;&#26524;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25552;&#20379;&#20102;&#20851;&#20110;Mixup&#30340;&#27867;&#21270;&#30410;&#22788;&#30340;&#21487;&#35777;&#20445;&#35777;&#65292;&#24182;&#25552;&#20379;&#20102;&#29702;&#35299;Mixup&#20026;&#20160;&#20040;&#22312;&#23454;&#36341;&#20013;&#34920;&#29616;&#33391;&#22909;&#30340;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate how pair-wise data augmentation techniques like Mixup affect the sample complexity of finding optimal decision boundaries in a binary linear classification problem. For a family of data distributions with a separability constant $\kappa$, we analyze how well the optimal classifier in terms of training loss aligns with the optimal one in test accuracy (i.e., Bayes optimal classifier). For vanilla training without augmentation, we uncover an interesting phenomenon named the curse of separability. As we increase $\kappa$ to make the data distribution more separable, the sample complexity of vanilla training increases exponentially in $\kappa$; perhaps surprisingly, the task of finding optimal decision boundaries becomes harder for more separable distributions. For Mixup training, we show that Mixup mitigates this problem by significantly reducing the sample complexity. To this end, we develop new concentration results applicable to $n^2$ pair-wise augmented data points cons
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#38750;&#38646;&#30456;&#20851;&#24615;&#30340;&#38543;&#26426;&#22270;&#21305;&#37197;&#30340;&#22810;&#39033;&#24335;&#36845;&#20195;&#31639;&#27861;&#65292;&#24182;&#19988;&#22312;&#36793;&#32536;&#30456;&#20851;&#24615;&#38750;&#38646;&#26102;&#25104;&#21151;&#24674;&#22797;&#28508;&#22312;&#21305;&#37197;&#12290;</title><link>http://arxiv.org/abs/2306.00266</link><description>&lt;p&gt;
&#19968;&#31181;&#20855;&#26377;&#38750;&#38646;&#30456;&#20851;&#24615;&#30340;&#38543;&#26426;&#22270;&#21305;&#37197;&#30340;&#22810;&#39033;&#24335;&#36845;&#20195;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
A polynomial-time iterative algorithm for random graph matching with non-vanishing correlation. (arXiv:2306.00266v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00266
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20855;&#26377;&#38750;&#38646;&#30456;&#20851;&#24615;&#30340;&#38543;&#26426;&#22270;&#21305;&#37197;&#30340;&#22810;&#39033;&#24335;&#36845;&#20195;&#31639;&#27861;&#65292;&#24182;&#19988;&#22312;&#36793;&#32536;&#30456;&#20851;&#24615;&#38750;&#38646;&#26102;&#25104;&#21151;&#24674;&#22797;&#28508;&#22312;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#21305;&#37197;&#20004;&#20010;&#30456;&#20851;&#30340;Erd&#337;s-R&#233;nyi&#22270;&#34920;&#30340;&#26377;&#25928;&#31639;&#27861;&#65292;&#23427;&#20204;&#20855;&#26377; $n$ &#20010;&#39030;&#28857;&#65292;&#20854;&#36793;&#32536;&#36890;&#36807;&#28508;&#22312;&#30340;&#39030;&#28857;&#23545;&#24212;&#20851;&#31995;&#30456;&#20114;&#20851;&#32852;&#12290;&#24403;&#36793;&#32536;&#23494;&#24230; $q=n^{-\alpha+o(1)}$&#65292;&#23545;&#20110;&#19968;&#20010;&#24120;&#25968; $\alpha \in [0,1)$ &#26102;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#20855;&#26377;&#22810;&#39033;&#24335;&#36816;&#34892;&#26102;&#38388;&#65292;&#24182;&#19988;&#21482;&#35201;&#36793;&#32536;&#30456;&#20851;&#24615;&#38750;&#38646;&#65292;&#23601;&#33021;&#25104;&#21151;&#24674;&#22797;&#28508;&#22312;&#21305;&#37197;&#12290;&#36825;&#19982;&#25105;&#20204;&#20808;&#21069;&#20851;&#20110;&#21305;&#37197;&#20004;&#20010;&#20855;&#26377;&#38750;&#38646;&#30456;&#20851;&#24615;&#30340;&#39640;&#26031;Wigner&#30697;&#38453;&#30340;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#30340;&#24037;&#20316;&#23494;&#20999;&#30456;&#20851;&#65292;&#24182;&#19988;&#22312;&#36793;&#32536;&#30456;&#20851;&#24615;&#20302;&#20110;Otter&#24120;&#25968;&#30340;&#24179;&#26041;&#26681;&#65288;&#32422;&#20026;0.338&#65289;&#26102;&#65292;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#38543;&#26426;&#22270;&#21305;&#37197;&#31639;&#27861;&#65288;&#26080;&#35770; $q$ &#30340;&#33539;&#22260;&#22914;&#20309;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose an efficient algorithm for matching two correlated Erd\H{o}s--R\'enyi graphs with $n$ vertices whose edges are correlated through a latent vertex correspondence. When the edge density $q= n^{- \alpha+o(1)}$ for a constant $\alpha \in [0,1)$, we show that our algorithm has polynomial running time and succeeds to recover the latent matching as long as the edge correlation is non-vanishing. This is closely related to our previous work on a polynomial-time algorithm that matches two Gaussian Wigner matrices with non-vanishing correlation, and provides the first polynomial-time random graph matching algorithm (regardless of the regime of $q$) when the edge correlation is below the square root of the Otter's constant (which is $\approx 0.338$).
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#31283;&#20581;&#33258;&#25105;&#35757;&#32451;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#20266;&#26631;&#31614;&#19981;&#20934;&#30830;&#21644;&#23436;&#20840;&#20934;&#30830;&#26102;&#20998;&#21035;&#37319;&#21462;&#19981;&#21516;&#30340;&#35757;&#32451;&#31574;&#30053;&#65292;&#23454;&#29616;&#26377;&#25928;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#31639;&#27861;&#22312;ImageNet&#21644;nuScenes&#25968;&#25454;&#38598;&#19978;&#22343;&#27604;&#26631;&#20934;&#33258;&#25105;&#35757;&#32451;&#24635;&#32467;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2306.00265</link><description>&lt;p&gt;
&#21452;&#37325;&#31283;&#20581;&#33258;&#25105;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Doubly Robust Self-Training. (arXiv:2306.00265v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00265
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#31283;&#20581;&#33258;&#25105;&#35757;&#32451;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#20266;&#26631;&#31614;&#19981;&#20934;&#30830;&#21644;&#23436;&#20840;&#20934;&#30830;&#26102;&#20998;&#21035;&#37319;&#21462;&#19981;&#21516;&#30340;&#35757;&#32451;&#31574;&#30053;&#65292;&#23454;&#29616;&#26377;&#25928;&#30340;&#21322;&#30417;&#30563;&#23398;&#20064;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#31639;&#27861;&#22312;ImageNet&#21644;nuScenes&#25968;&#25454;&#38598;&#19978;&#22343;&#27604;&#26631;&#20934;&#33258;&#25105;&#35757;&#32451;&#24635;&#32467;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#25105;&#35757;&#32451;&#26159;&#35299;&#20915;&#21322;&#30417;&#30563;&#23398;&#20064;&#38382;&#39064;&#30340;&#19968;&#31181;&#37325;&#35201;&#25216;&#26415;&#12290;&#23427;&#36890;&#36807;&#29983;&#25104;&#20266;&#26631;&#31614;&#24182;&#23558;&#20854;&#19982;&#26377;&#38480;&#30340;&#26631;&#35760;&#25968;&#25454;&#38598;&#32467;&#21512;&#20351;&#29992;&#36827;&#34892;&#35757;&#32451;&#65292;&#20174;&#32780;&#21033;&#29992;&#26080;&#26631;&#31614;&#25968;&#25454;&#12290;&#33258;&#25105;&#35757;&#32451;&#30340;&#26377;&#25928;&#24615;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#20381;&#36182;&#20110;&#36825;&#20123;&#20266;&#26631;&#31614;&#30340;&#20934;&#30830;&#24615;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#21452;&#37325;&#31283;&#20581;&#33258;&#25105;&#35757;&#32451;&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#21322;&#30417;&#30563;&#31639;&#27861;&#65292;&#21487;&#20197;&#20445;&#35777;&#22312;&#20004;&#20010;&#26497;&#31471;&#20043;&#38388;&#24179;&#34913;&#12290;&#24403;&#20266;&#26631;&#31614;&#23436;&#20840;&#19981;&#27491;&#30830;&#26102;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#34987;&#20943;&#23569;&#21040;&#20165;&#20351;&#29992;&#26631;&#35760;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#12290;&#30456;&#21453;&#65292;&#24403;&#20266;&#26631;&#31614;&#23436;&#20840;&#20934;&#30830;&#26102;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#21464;&#25104;&#21033;&#29992;&#25152;&#26377;&#20266;&#26631;&#31614;&#25968;&#25454;&#21644;&#26631;&#35760;&#25968;&#25454;&#36827;&#34892;&#35757;&#32451;&#30340;&#36807;&#31243;&#65292;&#20174;&#32780;&#22686;&#21152;&#26377;&#25928;&#30340;&#26679;&#26412;&#37327;&#12290;&#36890;&#36807;&#22312;ImageNet&#22270;&#20687;&#20998;&#31867;&#21644;nuScenes&#33258;&#20027;&#39550;&#39542;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#35777;&#35780;&#20272;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21452;&#37325;&#31283;&#20581;&#25439;&#22833;&#20248;&#20110;&#26631;&#20934;&#33258;&#25105;&#35757;&#32451;&#22522;&#32447;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Self-training is an important technique for solving semi-supervised learning problems. It leverages unlabeled data by generating pseudo-labels and combining them with a limited labeled dataset for training. The effectiveness of self-training heavily relies on the accuracy of these pseudo-labels. In this paper, we introduce doubly robust self-training, a novel semi-supervised algorithm that provably balances between two extremes. When the pseudo-labels are entirely incorrect, our method reduces to a training process solely using labeled data. Conversely, when the pseudo-labels are completely accurate, our method transforms into a training process utilizing all pseudo-labeled data and labeled data, thus increasing the effective sample size. Through empirical evaluations on both the ImageNet dataset for image classification and the nuScenes autonomous driving dataset for 3D object detection, we demonstrate the superiority of the doubly robust loss over the standard self-training baseline.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#20010;&#32452;&#21512;&#31070;&#32463;&#33218;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26469;&#36817;&#20284;&#26410;&#30693;&#24471;&#20998;&#20989;&#25968;&#65292;&#36825;&#26159;&#22788;&#29702;&#31867;&#20284;&#38382;&#39064;&#30340;&#31532;&#19968;&#20010;&#31639;&#27861;&#26694;&#26550;&#12290;</title><link>http://arxiv.org/abs/2306.00242</link><description>&lt;p&gt;
&#32452;&#21512;&#31070;&#32463;&#33218;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Combinatorial Neural Bandits. (arXiv:2306.00242v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00242
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#20004;&#20010;&#32452;&#21512;&#31070;&#32463;&#33218;&#31639;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26469;&#36817;&#20284;&#26410;&#30693;&#24471;&#20998;&#20989;&#25968;&#65292;&#36825;&#26159;&#22788;&#29702;&#31867;&#20284;&#38382;&#39064;&#30340;&#31532;&#19968;&#20010;&#31639;&#27861;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#19978;&#19979;&#25991;&#32452;&#21512;&#33218;&#38382;&#39064;&#65292;&#20854;&#20013;&#23398;&#20064;&#20195;&#29702;&#22312;&#27599;&#19968;&#36718;&#36873;&#25321;&#19968;&#32452;&#33218;&#24182;&#26681;&#25454;&#20854;&#20998;&#25968;&#25509;&#25910;&#21453;&#39304;&#12290;&#33218;&#30340;&#24471;&#20998;&#26159;&#33218;&#29305;&#24449;&#30340;&#26410;&#30693;&#20989;&#25968;&#12290;&#36890;&#36807;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26469;&#36817;&#20284;&#36825;&#20010;&#26410;&#30693;&#30340;&#24471;&#20998;&#20989;&#25968;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31639;&#27861;&#65306;&#32452;&#21512;&#31070;&#32463;UCB&#65288;CN-UCB&#65289;&#21644;&#32452;&#21512;&#31070;&#32463;&#27748;&#26222;&#26862;&#25277;&#26679;&#65288;CN-TS&#65289;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;CN-UCB&#21487;&#20197;&#36798;&#21040;$\tilde{\mathcal{O}}(\tilde{d} \sqrt{T})$&#25110; $\tilde{\mathcal{O}}(\sqrt{\tilde{d} T K})$&#36951;&#25022;&#20540;&#65292;&#20854;&#20013;$\tilde{d}$&#26159;&#31070;&#32463;&#20999;&#21521;&#26680;&#30697;&#38453;&#30340;&#26377;&#25928;&#32500;&#24230;&#65292;$K$&#26159;&#19968;&#32452;&#33218;&#30340;&#22823;&#23567;&#65292;$T$&#26159;&#26102;&#38388;&#36328;&#24230;&#12290;&#23545;&#20110;CN-TS&#65292;&#25105;&#20204;&#37319;&#29992;&#19968;&#31181;&#20048;&#35266;&#25277;&#26679;&#25216;&#26415;&#26469;&#30830;&#20445;&#32452;&#21512;&#21160;&#20316;&#30340;&#20048;&#35266;&#24615;&#65292;&#36798;&#21040;&#26368;&#24046;&#24773;&#20917;&#65288;&#39057;&#29575;&#23398;&#27966;&#65289;&#36951;&#25022;&#20026;$\tilde{\mathcal{O}}(\tilde{d} \sqrt{TK})$&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#35299;&#20915;&#27492;&#31867;&#32452;&#21512;&#33218;&#38382;&#39064;&#30340;&#31639;&#27861;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a contextual combinatorial bandit problem where in each round a learning agent selects a subset of arms and receives feedback on the selected arms according to their scores. The score of an arm is an unknown function of the arm's feature. Approximating this unknown score function with deep neural networks, we propose algorithms: Combinatorial Neural UCB ($\texttt{CN-UCB}$) and Combinatorial Neural Thompson Sampling ($\texttt{CN-TS}$). We prove that $\texttt{CN-UCB}$ achieves $\tilde{\mathcal{O}}(\tilde{d} \sqrt{T})$ or $\tilde{\mathcal{O}}(\sqrt{\tilde{d} T K})$ regret, where $\tilde{d}$ is the effective dimension of a neural tangent kernel matrix, $K$ is the size of a subset of arms, and $T$ is the time horizon. For $\texttt{CN-TS}$, we adapt an optimistic sampling technique to ensure the optimism of the sampled combinatorial action, achieving a worst-case (frequentist) regret of $\tilde{\mathcal{O}}(\tilde{d} \sqrt{TK})$. To the best of our knowledge, these are the first 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#8212;&#8212;&#24191;&#20041;&#38544;&#24335;Follow-The-Regularized-Leader (FTRL)&#65292;&#23427;&#21487;&#20197;&#24674;&#22797;&#24050;&#30693;&#30340;&#31639;&#27861;&#65292;&#22914;&#32447;&#24615;&#25439;&#22833;&#30340;FTRL&#21644;&#38544;&#24335;FTRL&#65292;&#24182;&#20801;&#35768;&#35774;&#35745;&#26032;&#30340;&#26356;&#26032;&#35268;&#21017;&#12290;&#35813;&#31639;&#27861;&#30340;&#20851;&#38190;&#24605;&#24819;&#26159;&#29992;Fenchel-Young&#19981;&#31561;&#24335;&#20195;&#26367;&#25439;&#22833;&#30340;&#32447;&#24615;&#21270;&#65292;&#21487;&#20197;&#30452;&#25509;&#25913;&#36827;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#21518;&#24724;&#19978;&#38480;&#12290;</title><link>http://arxiv.org/abs/2306.00201</link><description>&lt;p&gt;
&#24191;&#20041;&#38544;&#24335;Follow-The-Regularized-Leader&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Generalized Implicit Follow-The-Regularized-Leader. (arXiv:2306.00201v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00201
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#8212;&#8212;&#24191;&#20041;&#38544;&#24335;Follow-The-Regularized-Leader (FTRL)&#65292;&#23427;&#21487;&#20197;&#24674;&#22797;&#24050;&#30693;&#30340;&#31639;&#27861;&#65292;&#22914;&#32447;&#24615;&#25439;&#22833;&#30340;FTRL&#21644;&#38544;&#24335;FTRL&#65292;&#24182;&#20801;&#35768;&#35774;&#35745;&#26032;&#30340;&#26356;&#26032;&#35268;&#21017;&#12290;&#35813;&#31639;&#27861;&#30340;&#20851;&#38190;&#24605;&#24819;&#26159;&#29992;Fenchel-Young&#19981;&#31561;&#24335;&#20195;&#26367;&#25439;&#22833;&#30340;&#32447;&#24615;&#21270;&#65292;&#21487;&#20197;&#30452;&#25509;&#25913;&#36827;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#21518;&#24724;&#19978;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31867;&#26032;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#31216;&#20026;&#24191;&#20041;&#38544;&#24335;Follow-The-Regularized-Leader (FTRL)&#65292;&#23427;&#25193;&#23637;&#20102;FTRL&#26694;&#26550;&#30340;&#33539;&#22260;&#12290;&#24191;&#20041;&#38544;&#24335;FTRL&#21487;&#20197;&#24674;&#22797;&#24050;&#30693;&#30340;&#31639;&#27861;&#65292;&#22914;&#32447;&#24615;&#25439;&#22833;&#30340;FTRL&#21644;&#38544;&#24335;FTRL&#65292;&#24182;&#20801;&#35768;&#35774;&#35745;&#26032;&#30340;&#26356;&#26032;&#35268;&#21017;&#65292;&#20363;&#22914;aProx&#21644;Mirror-Prox&#30340;&#25193;&#23637;&#21040;FTRL&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#26159;&#24314;&#35774;&#24615;&#30340;&#65292;&#22240;&#20026;&#23427;&#25552;&#20379;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#32479;&#19968;&#26694;&#26550;&#65292;&#20197;&#35774;&#35745;&#30452;&#25509;&#25913;&#36827;&#26368;&#22351;&#24773;&#20917;&#21518;&#24724;&#30340;&#19978;&#38480;&#30340;&#26356;&#26032;&#12290;&#20851;&#38190;&#24605;&#24819;&#26159;&#29992;Fenchel-Young&#19981;&#31561;&#24335;&#20195;&#26367;&#25439;&#22833;&#30340;&#32447;&#24615;&#21270;&#12290;&#25105;&#20204;&#36890;&#36807;&#35777;&#26126;&#19968;&#20123;&#24050;&#30693;&#30340;&#31639;&#27861;&#65292;&#22914;Mirror-Prox&#26356;&#26032;&#65292;&#26159;&#24191;&#20041;&#38544;&#24335;FTRL&#30340;&#23454;&#20363;&#65292;&#23637;&#31034;&#20102;&#26694;&#26550;&#30340;&#28789;&#27963;&#24615;&#12290;&#26368;&#21518;&#65292;&#26032;&#26694;&#26550;&#20351;&#25105;&#20204;&#33021;&#22815;&#24674;&#22797;&#38544;&#24335;OMD&#30340;&#26102;&#38388;&#21464;&#21270;&#30028;&#65292;&#21516;&#26102;&#20855;&#26377;&#30456;&#21516;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new class of online learning algorithms, generalized implicit Follow-The-Regularized-Leader (FTRL), that expands the scope of FTRL framework. Generalized implicit FTRL can recover known algorithms, as FTRL with linearized losses and implicit FTRL, and it allows the design of new update rules, as extensions of aProx and Mirror-Prox to FTRL. Our theory is constructive in the sense that it provides a simple unifying framework to design updates that directly improve the worst-case upper bound on the regret. The key idea is substituting the linearization of the losses with a Fenchel-Young inequality. We show the flexibility of the framework by proving that some known algorithms, like the Mirror-Prox updates, are instantiations of the generalized implicit FTRL. Finally, the new framework allows us to recover the temporal variation bound of implicit OMD, with the same computational complexity.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#26694;&#26550;&#65292;&#23558;&#20219;&#20309;&#21333;&#33218;&#31574;&#30053;&#36716;&#21270;&#20026;&#21407;&#22987;&#30340;$N$&#33218;&#38382;&#39064;&#30340;&#31574;&#30053;&#65292;&#35299;&#20915;&#20102;&#20381;&#36182;&#20110;&#22797;&#26434;UGAP&#20551;&#35774;&#30340;&#38382;&#39064;&#65292;&#24182;&#23454;&#29616;&#20102;&#20855;&#26377;$O(1/\sqrt{N})$&#26368;&#20248;&#24615;&#24046;&#36317;&#30340;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2306.00196</link><description>&lt;p&gt;
&#20855;&#26377;&#24179;&#22343;&#22870;&#21169;&#30340;&#19981;&#23433;&#23450;&#36172;&#24466;&#38382;&#39064;&#65306;&#25171;&#30772;&#32479;&#19968;&#20840;&#23616;&#24341;&#23376;&#20551;&#35774;
&lt;/p&gt;
&lt;p&gt;
Restless Bandits with Average Reward: Breaking the Uniform Global Attractor Assumption. (arXiv:2306.00196v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00196
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#26694;&#26550;&#65292;&#23558;&#20219;&#20309;&#21333;&#33218;&#31574;&#30053;&#36716;&#21270;&#20026;&#21407;&#22987;&#30340;$N$&#33218;&#38382;&#39064;&#30340;&#31574;&#30053;&#65292;&#35299;&#20915;&#20102;&#20381;&#36182;&#20110;&#22797;&#26434;UGAP&#20551;&#35774;&#30340;&#38382;&#39064;&#65292;&#24182;&#23454;&#29616;&#20102;&#20855;&#26377;$O(1/\sqrt{N})$&#26368;&#20248;&#24615;&#24046;&#36317;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#24179;&#22343;&#22870;&#21169;&#26631;&#20934;&#19979;&#30340;&#26080;&#38480;&#26102;&#19981;&#23433;&#23450;&#36172;&#24466;&#38382;&#39064;&#65292;&#21253;&#25324;&#31163;&#25955;&#26102;&#38388;&#21644;&#36830;&#32493;&#26102;&#38388;&#35774;&#32622;&#12290;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#26159;&#22914;&#20309;&#35774;&#35745;&#35745;&#31639;&#26377;&#25928;&#30340;&#31574;&#30053;&#65292;&#20351;&#24471;&#20248;&#21270;&#24046;&#36317;&#38543;&#30528;&#33218;&#30340;&#25968;&#37327;$N$&#30340;&#22686;&#21152;&#32780;&#20943;&#23567;&#12290;&#29616;&#26377;&#30340;&#28176;&#36817;&#26368;&#20248;&#24615;&#32467;&#26524;&#37117;&#20381;&#36182;&#20110;&#32479;&#19968;&#20840;&#23616;&#24341;&#23376;&#24615;&#36136;(UGAP)&#65292;&#36825;&#26159;&#19968;&#20010;&#22797;&#26434;&#19988;&#38590;&#20197;&#39564;&#35777;&#30340;&#20551;&#35774;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#12289;&#22522;&#20110;&#27169;&#25311;&#30340;&#26694;&#26550;&#65292;&#23558;&#20219;&#20309;&#21333;&#33218;&#31574;&#30053;&#36716;&#21270;&#20026;&#21407;&#22987;&#30340;$N$&#33218;&#38382;&#39064;&#30340;&#31574;&#30053;&#12290;&#36825;&#26159;&#36890;&#36807;&#22312;&#27599;&#20010;&#33218;&#19978;&#27169;&#25311;&#21333;&#33218;&#31574;&#30053;&#65292;&#24182;&#20180;&#32454;&#22320;&#23558;&#30495;&#23454;&#29366;&#24577;&#24341;&#23548;&#21521;&#27169;&#25311;&#29366;&#24577;&#26469;&#23454;&#29616;&#30340;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#23454;&#20363;&#21270;&#65292;&#20135;&#29983;&#19968;&#20010;&#20855;&#26377;$O(1/\sqrt{N})$&#30340;&#26368;&#20248;&#35299;&#24046;&#36317;&#30340;&#31574;&#30053;&#12290;&#22312;&#31163;&#25955;&#26102;&#38388;&#35774;&#32622;&#20013;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#22312;&#26356;&#31616;&#21333;&#30340;&#21516;&#27493;&#20551;&#35774;&#19979;&#25104;&#31435;&#65292;&#28085;&#30422;&#20102;&#19968;&#20123;&#19981;&#28385;&#36275;UGAP&#30340;&#38382;&#39064;&#23454;&#20363;&#12290;&#26356;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#22788;&#29702;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#22823;&#30340;&#38382;&#39064;&#31867;&#65292;&#32780;&#19981;&#38656;&#23545;&#38382;&#39064;&#23454;&#20363;&#20570;&#20219;&#20309;&#29305;&#23450;&#30340;&#32467;&#26500;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the infinite-horizon restless bandit problem with the average reward criterion, under both discrete-time and continuous-time settings. A fundamental question is how to design computationally efficient policies that achieve a diminishing optimality gap as the number of arms, $N$, grows large. Existing results on asymptotical optimality all rely on the uniform global attractor property (UGAP), a complex and challenging-to-verify assumption. In this paper, we propose a general, simulation-based framework that converts any single-armed policy into a policy for the original $N$-armed problem. This is accomplished by simulating the single-armed policy on each arm and carefully steering the real state towards the simulated state. Our framework can be instantiated to produce a policy with an $O(1/\sqrt{N})$ optimality gap. In the discrete-time setting, our result holds under a simpler synchronization assumption, which covers some problem instances that do not satisfy UGAP. More notabl
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#26465;&#20214;&#24378;&#23545;&#25968;&#20985;&#27169;&#22411;(CSLC)&#12290;&#25105;&#20204;&#23558;&#25968;&#25454;&#20998;&#24067;&#20998;&#35299;&#25104;&#19968;&#32452;&#28385;&#36275;&#24378;&#23545;&#25968;&#20985;&#26465;&#20214;&#30340;&#26465;&#20214;&#27010;&#29575;&#20998;&#24067;&#30340;&#20056;&#31215;&#24418;&#24335;&#12290;&#36890;&#36807;&#36866;&#24212;&#20110;&#25968;&#25454;&#20998;&#24067;&#30340;&#27491;&#20132;&#25237;&#24433;&#22120;&#24471;&#21040;&#20998;&#35299;&#65292;&#25552;&#20379;&#20102;&#26377;&#25928;&#30340;&#21442;&#25968;&#20272;&#35745;&#21644;&#37319;&#26679;&#31639;&#27861;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2306.00181</link><description>&lt;p&gt;
&#26465;&#20214;&#24378;&#23545;&#25968;&#20985;&#30340;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Conditionally Strongly Log-Concave Generative Models. (arXiv:2306.00181v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00181
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#26465;&#20214;&#24378;&#23545;&#25968;&#20985;&#27169;&#22411;(CSLC)&#12290;&#25105;&#20204;&#23558;&#25968;&#25454;&#20998;&#24067;&#20998;&#35299;&#25104;&#19968;&#32452;&#28385;&#36275;&#24378;&#23545;&#25968;&#20985;&#26465;&#20214;&#30340;&#26465;&#20214;&#27010;&#29575;&#20998;&#24067;&#30340;&#20056;&#31215;&#24418;&#24335;&#12290;&#36890;&#36807;&#36866;&#24212;&#20110;&#25968;&#25454;&#20998;&#24067;&#30340;&#27491;&#20132;&#25237;&#24433;&#22120;&#24471;&#21040;&#20998;&#35299;&#65292;&#25552;&#20379;&#20102;&#26377;&#25928;&#30340;&#21442;&#25968;&#20272;&#35745;&#21644;&#37319;&#26679;&#31639;&#27861;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#22312;&#29983;&#25104;&#22270;&#20687;&#26041;&#38754;&#24050;&#32463;&#20855;&#26377;&#24456;&#22909;&#30340;&#25928;&#26524;&#65292;&#20294;&#30001;&#20110;&#23384;&#22312;&#27169;&#24335;&#23849;&#28291;&#21644;&#35760;&#24518;&#38382;&#39064;&#65292;&#20854;&#24212;&#29992;&#21463;&#21040;&#38480;&#21046;&#12290;&#32463;&#20856;&#31639;&#27861;&#22312;&#29702;&#35770;&#19978;&#25552;&#20379;&#20005;&#26684;&#30340;&#20445;&#35777;&#65292;&#20294;&#23545;&#20110;&#39640;&#32428;&#24230;&#25968;&#25454;&#38656;&#35201;&#28385;&#36275;&#35832;&#22914;&#23545;&#25968;&#20985;&#24615;&#31561;&#38480;&#21046;&#26465;&#20214;&#26469;&#36991;&#20813;&#32500;&#24230;&#28798;&#38590;&#12290;&#26412;&#25991;&#36890;&#36807;&#20171;&#32461;&#26465;&#20214;&#24378;&#23545;&#25968;&#20985;&#27169;&#22411;(CSLC)&#65292;&#23558;&#25968;&#25454;&#20998;&#24067;&#20998;&#35299;&#25104;&#19968;&#32452;&#28385;&#36275;&#24378;&#23545;&#25968;&#20985;&#26465;&#20214;&#30340;&#26465;&#20214;&#27010;&#29575;&#20998;&#24067;&#30340;&#20056;&#31215;&#24418;&#24335;&#65292;&#35813;&#20998;&#35299;&#36890;&#36807;&#36866;&#24212;&#20110;&#25968;&#25454;&#20998;&#24067;&#30340;&#27491;&#20132;&#25237;&#24433;&#22120;&#24471;&#21040;&#12290;&#19982;&#25968;&#25454;&#20998;&#24067;&#19981;&#20840;&#23616;&#23545;&#25968;&#20985;&#30340;&#24773;&#20917;&#19981;&#21516;&#65292;&#35813;&#20998;&#35299;&#25552;&#20379;&#20102;&#26377;&#25928;&#30340;&#21442;&#25968;&#20272;&#35745;&#21644;&#37319;&#26679;&#31639;&#27861;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;&#25105;&#20204;&#20351;&#29992;&#23567;&#27874;&#21253;&#27491;&#20132;&#25237;&#24433;&#22120;&#35777;&#26126;&#20102;&#19968;&#20123;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#22810;&#23610;&#24230;&#36807;&#31243;&#28385;&#36275;&#26465;&#20214;&#23545;&#25968;&#20985;&#24615;&#12290; &#26368;&#21518;&#65292;&#25105;&#20204;&#22312;&#29289;&#29702;&#22330;&#39046;&#22495;&#23637;&#31034;&#20102;&#25968;&#20540;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
There is a growing gap between the impressive results of deep image generative models and classical algorithms that offer theoretical guarantees. The former suffer from mode collapse or memorization issues, limiting their application to scientific data. The latter require restrictive assumptions such as log-concavity to escape the curse of dimensionality. We partially bridge this gap by introducing conditionally strongly log-concave (CSLC) models, which factorize the data distribution into a product of conditional probability distributions that are strongly log-concave. This factorization is obtained with orthogonal projectors adapted to the data distribution. It leads to efficient parameter estimation and sampling algorithms, with theoretical guarantees, although the data distribution is not globally log-concave. We show that several challenging multiscale processes are conditionally log-concave using wavelet packet orthogonal projectors. Numerical results are shown for physical field
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#35777;&#26126;&#20102;&#26576;&#20123;&#38382;&#39064;&#22312;&#20043;&#21069;&#30340;&#30740;&#31350;&#20013;&#26410;&#24471;&#21040;&#35299;&#20915;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#38382;&#39064;&#30340;&#22238;&#31572;&#65292;&#21253;&#25324;&#24191;&#32780;&#27973;&#30340;ReLU&#32593;&#32476;&#19981;&#33021;&#34987;&#28145;&#32780;&#31364;&#30340;ReLU&#32593;&#32476;&#24456;&#22909;&#22320;&#36924;&#36817;&#31561;&#12290;</title><link>http://arxiv.org/abs/2306.00145</link><description>&lt;p&gt;
&#20851;&#20110;&#31070;&#32463;&#32593;&#32476;&#34920;&#36798;&#33021;&#21147;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Expressive Power of Neural Networks. (arXiv:2306.00145v1 [math.CA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00145
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#35777;&#26126;&#20102;&#26576;&#20123;&#38382;&#39064;&#22312;&#20043;&#21069;&#30340;&#30740;&#31350;&#20013;&#26410;&#24471;&#21040;&#35299;&#20915;&#65292;&#24182;&#25552;&#20986;&#20102;&#26032;&#38382;&#39064;&#30340;&#22238;&#31572;&#65292;&#21253;&#25324;&#24191;&#32780;&#27973;&#30340;ReLU&#32593;&#32476;&#19981;&#33021;&#34987;&#28145;&#32780;&#31364;&#30340;ReLU&#32593;&#32476;&#24456;&#22909;&#22320;&#36924;&#36817;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
1989&#24180;&#65292;George Cybenko&#22312;&#19968;&#31687;&#37324;&#31243;&#30865;&#24335;&#30340;&#35770;&#25991;&#20013;&#35777;&#26126;&#20102;&#23485;&#32780;&#27973;&#30340;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#22312;&#32039;&#33268;&#38598;&#19978;&#36924;&#36817;&#20219;&#24847;&#36830;&#32493;&#20989;&#25968;&#65292;&#36825;&#20010;&#36890;&#29992;&#36924;&#36817;&#23450;&#29702;&#24341;&#21457;&#20102;&#24456;&#22810;&#21518;&#32493;&#30740;&#31350;&#12290;&#26412;&#25991;&#23558;&#36890;&#36807;&#19968;&#20010;&#26694;&#26550;&#22238;&#31572;&#8220;&#26377;&#27809;&#26377;&#19968;&#20123;&#24191;&#32780;&#27973;&#30340;ReLU&#32593;&#32476;&#26080;&#27861;&#34987;&#28145;&#32780;&#31364;&#30340;ReLU&#32593;&#32476;&#24456;&#22909;&#22320;&#36924;&#36817;&#65311;&#8221;&#8220;&#26222;&#36941;&#36924;&#36817;&#23450;&#29702;&#26159;&#21542;&#20173;&#36866;&#29992;&#20110;Sobolev&#31354;&#38388;&#33539;&#25968;W 1,1&#65311;&#8221;&#8220;&#36825;&#20123;&#32467;&#26524;&#26159;&#21542;&#36866;&#29992;&#20110;&#38500;ReLU&#20043;&#22806;&#30340;&#28608;&#27963;&#20989;&#25968;&#65311;&#8221;&#31561;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
In 1989 George Cybenko proved in a landmark paper that wide shallow neural networks can approximate arbitrary continuous functions on a compact set. This universal approximation theorem sparked a lot of follow-up research.  Shen, Yang and Zhang determined optimal approximation rates for ReLU-networks in $L^p$-norms with $p \in [1,\infty)$. Kidger and Lyons proved a universal approximation theorem for deep narrow ReLU-networks. Telgarsky gave an example of a deep narrow ReLU-network that cannot be approximated by a wide shallow ReLU-network unless it has exponentially many neurons.  However, there are even more questions that still remain unresolved. Are there any wide shallow ReLU-networks that cannot be approximated well by deep narrow ReLU-networks? Is the universal approximation theorem still true for other norms like the Sobolev norm $W^{1,1}$? Do these results hold for activation functions other than ReLU?  We will answer all of those questions and more with a framework of two exp
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#36125;&#21494;&#26031;CART&#31639;&#27861;&#20013;&#30340;&#28151;&#21512;&#36895;&#29575;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20123;&#20805;&#20998;&#26465;&#20214;&#12290;&#20316;&#32773;&#25351;&#20986;&#65292;&#22522;&#20110;&#29983;&#38271;&#21644;&#20462;&#21098;&#27493;&#39588;&#30340;&#36125;&#21494;&#26031;CART&#26080;&#27861;&#24555;&#36895;&#21040;&#36798;&#28145;&#24230;&#23396;&#31435;&#20449;&#21495;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;Twiggy&#36125;&#21494;&#26031;CART&#20197;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2306.00126</link><description>&lt;p&gt;
&#20851;&#20110;&#36125;&#21494;&#26031;CART&#30340;&#28151;&#21512;&#36895;&#29575;
&lt;/p&gt;
&lt;p&gt;
On Mixing Rates for Bayesian CART. (arXiv:2306.00126v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00126
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#36125;&#21494;&#26031;CART&#31639;&#27861;&#20013;&#30340;&#28151;&#21512;&#36895;&#29575;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20123;&#20805;&#20998;&#26465;&#20214;&#12290;&#20316;&#32773;&#25351;&#20986;&#65292;&#22522;&#20110;&#29983;&#38271;&#21644;&#20462;&#21098;&#27493;&#39588;&#30340;&#36125;&#21494;&#26031;CART&#26080;&#27861;&#24555;&#36895;&#21040;&#36798;&#28145;&#24230;&#23396;&#31435;&#20449;&#21495;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;Twiggy&#36125;&#21494;&#26031;CART&#20197;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
MCMC&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#30340;&#25104;&#21151;&#19982;&#21542;&#22312;&#24456;&#22823;&#31243;&#24230;&#19978;&#21462;&#20915;&#20110;&#39532;&#23572;&#31185;&#22827;&#38142;&#26159;&#21542;&#33021;&#36805;&#36895;&#36798;&#21040;&#21518;&#39564;&#20998;&#24067;&#12290;&#23613;&#31649;&#23545;&#20110;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#21518;&#39564;&#30340;&#25512;&#29702;&#29702;&#35770;&#39047;&#20016;&#65292;&#20294;&#20174;&#29702;&#24819;&#30340;&#21518;&#39564;&#30446;&#26631;&#27169;&#25311;MCMC&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#36136;&#24182;&#19981;&#23436;&#20840;&#20102;&#35299;&#12290;&#26412;&#25991;&#37325;&#28857;&#30740;&#31350;&#20102;&#36125;&#21494;&#26031;CART&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#26159;&#36125;&#21494;&#26031;&#28155;&#21152;&#22238;&#24402;&#26641;(BART)&#30340;&#26500;&#24314;&#22359;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#22312;&#21508;&#31181;&#25552;&#35758;&#20998;&#24067;&#19979;&#20856;&#22411;&#21518;&#39564;&#30340;&#28151;&#21512;&#26102;&#38388;&#30340;&#19978;&#30028;&#12290;&#21033;&#29992;&#26641;&#30340;&#23567;&#27874;&#34920;&#31034;&#65292;&#25105;&#20204;&#22312;&#20449;&#21495;&#30340;&#26576;&#20123;&#20998;&#23618;&#36830;&#25509;&#38480;&#21046;&#19979;&#25552;&#20379;&#20102;&#36125;&#21494;&#26031;CART&#33391;&#22909;&#28151;&#21512;&#65288;&#22810;&#39033;&#24335;&#28151;&#21512;&#65289;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#25105;&#20204;&#36824;&#24471;&#20986;&#20102;&#19968;&#20010;&#36127;&#38754;&#32467;&#26524;&#65292;&#34920;&#26126;&#22522;&#20110;&#31616;&#21333;&#30340;&#29983;&#38271;&#21644;&#20462;&#21098;&#27493;&#39588;&#30340;&#36125;&#21494;&#26031;CART&#19981;&#33021;&#22312;&#25351;&#25968;&#28151;&#21512;&#26102;&#38388;&#20869;&#24555;&#36895;&#21040;&#36798;&#28145;&#24230;&#23396;&#31435;&#20449;&#21495;&#12290;&#20026;&#20102;&#32416;&#27491;&#36817;&#35270;&#26641;&#30340;&#25506;&#27979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Twiggy&#36125;&#21494;&#26031;CART&#12290;
&lt;/p&gt;
&lt;p&gt;
The success of Bayesian inference with MCMC depends critically on Markov chains rapidly reaching the posterior distribution. Despite the plentitude of inferential theory for posteriors in Bayesian non-parametrics, convergence properties of MCMC algorithms that simulate from such ideal inferential targets are not thoroughly understood. This work focuses on the Bayesian CART algorithm which forms a building block of Bayesian Additive Regression Trees (BART). We derive upper bounds on mixing times for typical posteriors under various proposal distributions. Exploiting the wavelet representation of trees, we provide sufficient conditions for Bayesian CART to mix well (polynomially) under certain hierarchical connectivity restrictions on the signal. We also derive a negative result showing that Bayesian CART (based on simple grow and prune steps) cannot reach deep isolated signals in faster than exponential mixing time. To remediate myopic tree exploration, we propose Twiggy Bayesian CART w
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#36866;&#29992;&#20110;&#32447;&#24615;Bandit&#30340;Pareto&#21069;&#27839;&#35782;&#21035;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20351;&#29992;&#25152;&#26377;&#21160;&#20316;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#65292;&#20855;&#26377;&#36739;&#20302;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24182;&#21516;&#26102;&#20445;&#35777;&#20102;Pareto&#21069;&#27839;&#35782;&#21035;&#21644;Pareto&#36951;&#25022;&#26368;&#23567;&#21270;&#12290;</title><link>http://arxiv.org/abs/2306.00096</link><description>&lt;p&gt;
&#36890;&#36807;&#36951;&#25022;&#26368;&#23567;&#21270;&#26041;&#27861;&#36827;&#34892;Pareto&#21069;&#27839;&#35782;&#21035;
&lt;/p&gt;
&lt;p&gt;
Pareto Front Identification with Regret Minimization. (arXiv:2306.00096v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00096
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#36866;&#29992;&#20110;&#32447;&#24615;Bandit&#30340;Pareto&#21069;&#27839;&#35782;&#21035;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20351;&#29992;&#25152;&#26377;&#21160;&#20316;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#65292;&#20855;&#26377;&#36739;&#20302;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#24182;&#21516;&#26102;&#20445;&#35777;&#20102;Pareto&#21069;&#27839;&#35782;&#21035;&#21644;Pareto&#36951;&#25022;&#26368;&#23567;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#32447;&#24615;Bandit&#24773;&#20917;&#19979;&#30340;Pareto&#21069;&#27839;&#35782;&#21035;&#65288;PFILin&#65289;&#65292;&#20854;&#30446;&#26631;&#26159;&#22312;&#24179;&#22343;&#22870;&#21169;&#21521;&#37327;&#20316;&#20026;&#29615;&#22659;&#30340;&#32447;&#24615;&#20989;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#35782;&#21035;&#19968;&#32452;&#22870;&#21169;&#21521;&#37327;&#19981;&#34987;&#20854;&#20182;&#20219;&#20309;&#21521;&#37327;&#25152;&#21344;&#20248;&#12290;PFILin&#21253;&#25324;&#26368;&#20339;&#21160;&#20316;&#35782;&#21035;&#21644;&#22810;&#30446;&#26631;&#20027;&#21160;&#23398;&#20064;&#31561;&#29305;&#27530;&#24773;&#20917;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20026;$\tilde{O}(d/\Delta^2)$&#65292;&#20854;&#20013;$d$&#26159;&#19978;&#19979;&#25991;&#30340;&#32500;&#25968;&#65292;$\Delta$&#26159;&#38382;&#39064;&#22797;&#26434;&#24615;&#30340;&#19968;&#31181;&#24230;&#37327;&#12290;&#25105;&#20204;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#22312;&#23545;&#25968;&#22240;&#23376;&#19978;&#26159;&#26368;&#20248;&#30340;&#12290;&#26412;&#31639;&#27861;&#30340;&#19968;&#20010;&#26032;&#29305;&#28857;&#26159;&#20351;&#29992;&#25152;&#26377;&#21160;&#20316;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#12290;&#38500;&#20102;&#26377;&#25928;&#22320;&#35782;&#21035;Pareto&#21069;&#27839;&#20043;&#22806;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#36824;&#20445;&#35777;&#65292;&#22312;&#26679;&#26412;&#25968;&#22823;&#20110;$\Omega(d\log dL)$&#26102;&#65292;&#23545;&#20110;$L$&#32500;&#30690;&#37327;&#22870;&#21169;&#65292;&#30636;&#26102;Pareto&#36951;&#25022;&#30340;$\tilde{O}(\sqrt{d/t})$&#30028;&#38480;&#12290;&#36890;&#36807;&#20351;&#29992;&#25152;&#26377;&#21160;&#20316;&#30340;&#19978;&#19979;&#25991;&#20449;&#24687;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#21516;&#26102;&#20026;&#32447;&#24615;Bandit&#25552;&#20379;&#20102;&#26377;&#25928;&#30340;Pareto&#21069;&#27839;&#35782;&#21035;&#21644;Pareto&#36951;&#25022;&#26368;&#23567;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider Pareto front identification for linear bandits (PFILin) where the goal is to identify a set of arms whose reward vectors are not dominated by any of the others when the mean reward vector is a linear function of the context. PFILin includes the best arm identification problem and multi-objective active learning as special cases. The sample complexity of our proposed algorithm is $\tilde{O}(d/\Delta^2)$, where $d$ is the dimension of contexts and $\Delta$ is a measure of problem complexity. Our sample complexity is optimal up to a logarithmic factor. A novel feature of our algorithm is that it uses the contexts of all actions. In addition to efficiently identifying the Pareto front, our algorithm also guarantees $\tilde{O}(\sqrt{d/t})$ bound for instantaneous Pareto regret when the number of samples is larger than $\Omega(d\log dL)$ for $L$ dimensional vector rewards. By using the contexts of all arms, our proposed algorithm simultaneously provides efficient Pareto front ide
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65292;&#33021;&#22815;&#23562;&#37325;&#20219;&#20309;&#19968;&#20010;&#32422;&#21270;&#26446;&#32676;G&#30340;&#26377;&#38480;&#32500;&#34920;&#31034;&#30340;&#23545;&#31216;&#24615;&#65292;&#24182;&#36890;&#36807;&#22312;&#22810;&#20010;&#39046;&#22495;&#30340;&#20219;&#21153;&#19978;&#36827;&#34892;&#23454;&#39564;&#26469;&#35777;&#26126;&#20854;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.00091</link><description>&lt;p&gt;
&#19968;&#20010;&#22312;&#32422;&#21270;&#26446;&#32676;&#19978;&#31561;&#21464;&#30340;&#31070;&#32463;&#32593;&#32476;&#36890;&#29992;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A General Framework for Equivariant Neural Networks on Reductive Lie Groups. (arXiv:2306.00091v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00091
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65292;&#33021;&#22815;&#23562;&#37325;&#20219;&#20309;&#19968;&#20010;&#32422;&#21270;&#26446;&#32676;G&#30340;&#26377;&#38480;&#32500;&#34920;&#31034;&#30340;&#23545;&#31216;&#24615;&#65292;&#24182;&#36890;&#36807;&#22312;&#22810;&#20010;&#39046;&#22495;&#30340;&#20219;&#21153;&#19978;&#36827;&#34892;&#23454;&#39564;&#26469;&#35777;&#26126;&#20854;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32422;&#21270;&#26446;&#32676;&#65292;&#22914;&#27491;&#20132;&#32676;&#12289;&#27931;&#20262;&#20857;&#32676;&#25110;&#24186;&#27491;&#32676;&#65292;&#22312;&#39640;&#33021;&#29289;&#29702;&#12289;&#37327;&#23376;&#21147;&#23398;&#12289;&#37327;&#23376;&#33394;&#21160;&#21147;&#23398;&#12289;&#20998;&#23376;&#21160;&#21147;&#23398;&#12289;&#35745;&#31639;&#26426;&#35270;&#35273;&#21644;&#25104;&#20687;&#31561;&#21508;&#20010;&#31185;&#23398;&#39046;&#22495;&#20013;&#25198;&#28436;&#30528;&#37325;&#35201;&#35282;&#33394;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#65292;&#33021;&#22815;&#23562;&#37325;&#20219;&#20309;&#19968;&#20010;&#32422;&#21270;&#26446;&#32676;G&#30340;&#26377;&#38480;&#32500;&#34920;&#31034;&#30340;&#23545;&#31216;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#25512;&#24191;&#20102;&#25104;&#21151;&#30340;ACE&#21644;MACE&#26550;&#26500;&#23545;&#20110;&#28857;&#20113;&#30340;&#21407;&#23376;&#32423;&#25968;&#25454;&#31561;&#21464;&#21040;&#20219;&#20309;&#19968;&#20010;&#23545;&#32422;&#21270;&#26446;&#32676;&#20316;&#29992;&#31561;&#21464;&#30340;&#25968;&#25454;&#12290;&#25105;&#20204;&#36824;&#24341;&#20837;&#20102;lie-nn&#36719;&#20214;&#24211;&#65292;&#25552;&#20379;&#20102;&#24320;&#21457;&#21644;&#23454;&#29616;&#36825;&#31181;&#36890;&#29992;G-&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#25152;&#38656;&#30340;&#25152;&#26377;&#24037;&#20855;&#12290;&#23427;&#23454;&#29616;&#20102;&#23558;&#34920;&#31034;&#30340;&#36890;&#29992;&#24352;&#37327;&#31215;&#20943;&#23569;&#21040;&#19981;&#21487;&#32422;&#34920;&#31034;&#30340;&#20363;&#34892;&#31243;&#24207;&#65292;&#20351;&#24471;&#25105;&#20204;&#30340;&#26550;&#26500;&#21487;&#20197;&#24212;&#29992;&#21040;&#21508;&#31181;&#38382;&#39064;&#21644;&#32676;&#20307;&#12290;&#36890;&#36807;&#22312;&#21508;&#31181;&#20219;&#21153;&#19978;&#30340;&#23454;&#39564;&#65292;&#21253;&#25324;&#20998;&#23376;&#21160;&#21147;&#23398;&#27169;&#25311;&#12289;&#25193;&#25955;MRI&#21644;&#35745;&#31639;&#26426;&#35270;&#35273;&#65292;&#23637;&#31034;&#20102;&#25105;&#20204;&#26694;&#26550;&#30340;&#26222;&#36866;&#24615;&#21644;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reductive Lie Groups, such as the orthogonal groups, the Lorentz group, or the unitary groups, play essential roles across scientific fields as diverse as high energy physics, quantum mechanics, quantum chromodynamics, molecular dynamics, computer vision, and imaging. In this paper, we present a general Equivariant Neural Network architecture capable of respecting the symmetries of the finite-dimensional representations of any reductive Lie Group G. Our approach generalizes the successful ACE and MACE architectures for atomistic point clouds to any data equivariant to a reductive Lie group action. We also introduce the lie-nn software library, which provides all the necessary tools to develop and implement such general G-equivariant neural networks. It implements routines for the reduction of generic tensor products of representations into irreducible representations, making it easy to apply our architecture to a wide range of problems and groups. The generality and performance of our 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#19968;&#31181;&#22522;&#20110;&#20027;&#21160;&#35810;&#38382;&#20915;&#31574;&#32773;&#20010;&#20154;&#20559;&#22909;&#30340;&#32622;&#20449;&#24230;&#26500;&#36896;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#32622;&#20449;&#24230;&#23545;&#20110;&#20915;&#31574;&#32773;&#20449;&#20219;&#20915;&#31574;&#30340;&#19981;&#20934;&#30830;&#38382;&#39064;&#65292;&#20174;&#32780;&#25552;&#39640;&#20915;&#31574;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2306.00074</link><description>&lt;p&gt;
&#20154;&#31867;&#23545;&#40784;&#26657;&#20934;&#29992;&#20110;AI&#36741;&#21161;&#20915;&#31574;&#21046;&#23450;
&lt;/p&gt;
&lt;p&gt;
Human-Aligned Calibration for AI-Assisted Decision Making. (arXiv:2306.00074v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00074
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#19968;&#31181;&#22522;&#20110;&#20027;&#21160;&#35810;&#38382;&#20915;&#31574;&#32773;&#20010;&#20154;&#20559;&#22909;&#30340;&#32622;&#20449;&#24230;&#26500;&#36896;&#26041;&#27861;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#32622;&#20449;&#24230;&#23545;&#20110;&#20915;&#31574;&#32773;&#20449;&#20219;&#20915;&#31574;&#30340;&#19981;&#20934;&#30830;&#38382;&#39064;&#65292;&#20174;&#32780;&#25552;&#39640;&#20915;&#31574;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#20351;&#29992;&#20108;&#20803;&#20998;&#31867;&#22120;&#25552;&#20379;&#20915;&#31574;&#25903;&#25345;&#26102;&#65292;&#23427;&#36890;&#24120;&#25552;&#20379;&#26631;&#31614;&#39044;&#27979;&#21644;&#32622;&#20449;&#24230;&#20540;&#12290;&#28982;&#21518;&#65292;&#20915;&#31574;&#32773;&#24212;&#20351;&#29992;&#32622;&#20449;&#24230;&#20540;&#26469;&#26657;&#20934;&#23545;&#39044;&#27979;&#30340;&#20449;&#20219;&#31243;&#24230;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#20154;&#20204;&#32463;&#24120;&#35748;&#20026;&#32622;&#20449;&#24230;&#20540;&#24212;&#23545;&#39044;&#27979;&#26631;&#31614;&#19982;&#23454;&#38469;&#26631;&#31614;&#21305;&#37197;&#30340;&#27010;&#29575;&#36827;&#34892;&#33391;&#22909;&#26657;&#20934;&#30340;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#22810;&#26465;&#23454;&#35777;&#35777;&#25454;&#34920;&#26126;&#65292;&#20915;&#31574;&#32773;&#38590;&#20197;&#20351;&#29992;&#36825;&#20123;&#32622;&#20449;&#24230;&#20540;&#24456;&#22909;&#22320;&#30830;&#23450;&#20309;&#26102;&#20449;&#20219;&#39044;&#27979;&#12290;&#26412;&#25991;&#30340;&#30446;&#26631;&#39318;&#20808;&#26159;&#29702;&#35299;&#20026;&#20160;&#20040;&#65292;&#28982;&#21518;&#30740;&#31350;&#22914;&#20309;&#26500;&#24314;&#26356;&#26377;&#29992;&#30340;&#32622;&#20449;&#24230;&#20540;&#12290;&#25105;&#20204;&#39318;&#20808;&#35748;&#20026;&#65292;&#22312;&#24191;&#27867;&#31867;&#30340;&#25928;&#29992;&#20989;&#25968;&#20013;&#65292;&#23384;&#22312;&#25968;&#25454;&#20998;&#24067;&#65292;&#23545;&#20110;&#36825;&#20123;&#20998;&#24067;&#65292;&#29702;&#24615;&#20915;&#31574;&#32773;&#36890;&#24120;&#38590;&#20197;&#20351;&#29992;&#20197;&#19978;&#32622;&#20449;&#24230;&#20540;&#21457;&#29616;&#26368;&#20339;&#20915;&#31574;&#25919;&#31574;&#8212;&#8212;&#26368;&#20339;&#30340;&#20915;&#31574;&#32773;&#38656;&#35201;&#20154;&#31867;&#23545;&#40784;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#20027;&#21160;&#35810;&#38382;&#20915;&#31574;&#32773;&#20182;&#20204;&#22312;&#25152;&#38754;&#20020;&#30340;&#20108;&#20803;&#20998;&#31867;&#20219;&#21153;&#30340;&#20915;&#31574;&#19978;&#30340;&#20010;&#20154;&#20559;&#22909;&#30340;&#26032;&#26041;&#27861;&#26469;&#26500;&#36896;&#32622;&#20449;&#24230;&#20540;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#20135;&#29983;&#30340;&#32622;&#20449;&#24230;&#20540;&#27604;&#20351;&#29992;&#26631;&#20934;&#32622;&#20449;&#24230;&#24230;&#37327;&#23548;&#33268;&#26356;&#22909;&#30340;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;
Whenever a binary classifier is used to provide decision support, it typically provides both a label prediction and a confidence value. Then, the decision maker is supposed to use the confidence value to calibrate how much to trust the prediction. In this context, it has been often argued that the confidence value should correspond to a well calibrated estimate of the probability that the predicted label matches the ground truth label. However, multiple lines of empirical evidence suggest that decision makers have difficulties at developing a good sense on when to trust a prediction using these confidence values. In this paper, our goal is first to understand why and then investigate how to construct more useful confidence values. We first argue that, for a broad class of utility functions, there exist data distributions for which a rational decision maker is, in general, unlikely to discover the optimal decision policy using the above confidence values -- an optimal decision maker wou
&lt;/p&gt;</description></item><item><title>&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#38656;&#35201;&#20351;&#29992;&#37327;&#23376;&#35745;&#31639;&#26426;&#36827;&#34892;&#35780;&#20272;&#65292;&#20294;&#25105;&#20204;&#25552;&#20986;&#22312;&#35757;&#32451;&#23436;&#21518;&#65292;&#20351;&#29992;&#37327;&#23376;&#35745;&#31639;&#26426;&#29983;&#25104;&#19968;&#20010;&#32463;&#20856;&#38452;&#24433;&#27169;&#22411;&#26469;&#35745;&#31639;&#20989;&#25968;&#30340;&#32463;&#20856;&#35745;&#31639;&#36817;&#20284;&#65292;&#36991;&#20813;&#20102;&#23545;&#37327;&#23376;&#35745;&#31639;&#26426;&#30340;&#38656;&#27714;&#12290;</title><link>http://arxiv.org/abs/2306.00061</link><description>&lt;p&gt;
&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#30340;&#38452;&#24433;
&lt;/p&gt;
&lt;p&gt;
Shadows of quantum machine learning. (arXiv:2306.00061v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00061
&lt;/p&gt;
&lt;p&gt;
&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#38656;&#35201;&#20351;&#29992;&#37327;&#23376;&#35745;&#31639;&#26426;&#36827;&#34892;&#35780;&#20272;&#65292;&#20294;&#25105;&#20204;&#25552;&#20986;&#22312;&#35757;&#32451;&#23436;&#21518;&#65292;&#20351;&#29992;&#37327;&#23376;&#35745;&#31639;&#26426;&#29983;&#25104;&#19968;&#20010;&#32463;&#20856;&#38452;&#24433;&#27169;&#22411;&#26469;&#35745;&#31639;&#20989;&#25968;&#30340;&#32463;&#20856;&#35745;&#31639;&#36817;&#20284;&#65292;&#36991;&#20813;&#20102;&#23545;&#37327;&#23376;&#35745;&#31639;&#26426;&#30340;&#38656;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;&#32463;&#24120;&#34987;&#35748;&#20026;&#26159;&#21033;&#29992;&#37327;&#23376;&#35745;&#31639;&#26426;&#35299;&#20915;&#23454;&#38469;&#38382;&#39064;&#30340;&#26368;&#26377;&#21069;&#36884;&#30340;&#24212;&#29992;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#38459;&#30861;&#20854;&#22312;&#23454;&#36341;&#20013;&#24191;&#27867;&#20351;&#29992;&#30340;&#20027;&#35201;&#38556;&#30861;&#26159;&#36825;&#20123;&#27169;&#22411;&#21363;&#20351;&#22312;&#35757;&#32451;&#36807;&#31243;&#21518;&#65292;&#20173;&#38656;&#35201;&#35775;&#38382;&#37327;&#23376;&#35745;&#31639;&#26426;&#25165;&#33021;&#23545;&#26032;&#25968;&#25454;&#36827;&#34892;&#35780;&#20272;&#12290;&#20026;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24314;&#35758;&#22312;&#37327;&#23376;&#27169;&#22411;&#30340;&#35757;&#32451;&#38454;&#27573;&#20043;&#21518;&#65292;&#37327;&#23376;&#35745;&#31639;&#26426;&#21487;&#20197;&#29992;&#26469;&#29983;&#25104;&#25105;&#20204;&#25152;&#35859;&#30340;&#35813;&#27169;&#22411;&#30340;&#8220;&#32463;&#20856;&#38452;&#24433;&#8221;&#65292;&#21363;&#24050;&#23398;&#20064;&#20989;&#25968;&#30340;&#32463;&#20856;&#35745;&#31639;&#36817;&#20284;&#12290;&#34429;&#28982;&#26368;&#36817;&#30340;&#30740;&#31350;&#24050;&#32463;&#25506;&#35752;&#20102;&#36825;&#20010;&#24819;&#27861;&#24182;&#25552;&#20986;&#20102;&#26500;&#24314;&#36825;&#31181;&#24433;&#23376;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#20294;&#23427;&#20204;&#20063;&#25552;&#20986;&#20102;&#19968;&#20010;&#23436;&#20840;&#32463;&#20856;&#27169;&#22411;&#21487;&#33021;&#20195;&#26367;&#30340;&#21487;&#33021;&#24615;&#65292;&#20174;&#32780;&#39318;&#20808;&#22238;&#36991;&#20102;&#37327;&#23376;&#35745;&#31639;&#26426;&#30340;&#38656;&#35201;&#12290;&#26412;&#25991;&#37319;&#29992;&#26032;&#30340;&#26041;&#27861;&#65292;&#22522;&#20110;&#37327;&#23376;&#32447;&#24615;&#27169;&#22411;&#21644;&#32463;&#20856;&#38452;&#24433;&#37325;&#26500;&#30340;&#26694;&#26550;&#26469;&#23450;&#20041;&#38452;&#24433;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Quantum machine learning is often highlighted as one of the most promising uses for a quantum computer to solve practical problems. However, a major obstacle to the widespread use of quantum machine learning models in practice is that these models, even once trained, still require access to a quantum computer in order to be evaluated on new data. To solve this issue, we suggest that following the training phase of a quantum model, a quantum computer could be used to generate what we call a classical shadow of this model, i.e., a classically computable approximation of the learned function. While recent works already explore this idea and suggest approaches to construct such shadow models, they also raise the possibility that a completely classical model could be trained instead, thus circumventing the need for a quantum computer in the first place. In this work, we take a novel approach to define shadow models based on the frameworks of quantum linear models and classical shadow tomogr
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;JLMs&#30340;&#26631;&#31614;&#23884;&#20837;&#26041;&#27861;&#65292;&#23558;&#22810;&#20803;&#20998;&#31867;&#38382;&#39064;&#36716;&#21270;&#20026;&#26377;&#38480;&#22238;&#24402;&#38382;&#39064;&#65292;&#20855;&#26377;&#36739;&#39640;&#30340;&#35745;&#31639;&#25928;&#29575;&#21644;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.19470</link><description>&lt;p&gt;
&#29992;Johnson-Lindenstrauss&#30697;&#38453;&#36827;&#34892;&#26631;&#31614;&#23884;&#20837;
&lt;/p&gt;
&lt;p&gt;
Label Embedding by Johnson-Lindenstrauss Matrices. (arXiv:2305.19470v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.19470
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;JLMs&#30340;&#26631;&#31614;&#23884;&#20837;&#26041;&#27861;&#65292;&#23558;&#22810;&#20803;&#20998;&#31867;&#38382;&#39064;&#36716;&#21270;&#20026;&#26377;&#38480;&#22238;&#24402;&#38382;&#39064;&#65292;&#20855;&#26377;&#36739;&#39640;&#30340;&#35745;&#31639;&#25928;&#29575;&#21644;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;Johnson-Lindenstrauss&#30697;&#38453;&#65288;JLMs&#65289;&#30340;&#31616;&#21333;&#19988;&#21487;&#25193;&#23637;&#30340;&#26497;&#31471;&#22810;&#20803;&#20998;&#31867;&#26694;&#26550;&#12290;&#21033;&#29992;JLM&#30340;&#21015;&#26469;&#23884;&#20837;&#26631;&#31614;&#65292;&#23558;&#19968;&#20010;C&#31867;&#20998;&#31867;&#38382;&#39064;&#36716;&#21270;&#20026;&#20855;&#26377;$\cO(\log C)$&#36755;&#20986;&#32500;&#24230;&#30340;&#22238;&#24402;&#38382;&#39064;&#12290;&#25105;&#20204;&#24471;&#20986;&#20102;&#19968;&#20010;&#36229;&#37327;&#39118;&#38505;&#38480;&#21046;&#65292;&#38416;&#26126;&#20102;&#35745;&#31639;&#25928;&#29575;&#21644;&#39044;&#27979;&#20934;&#30830;&#24615;&#20043;&#38388;&#30340;&#26435;&#34913;&#65292;&#24182;&#36827;&#19968;&#27493;&#34920;&#26126;&#65292;&#22312;Massart&#22122;&#22768;&#26465;&#20214;&#19979;&#65292;&#38477;&#32500;&#30340;&#24809;&#32602;&#20250;&#28040;&#22833;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26131;&#20110;&#24182;&#34892;&#21270;&#65292;&#24182;&#19988;&#23454;&#39564;&#32467;&#26524;&#23637;&#31034;&#20102;&#22312;&#22823;&#35268;&#27169;&#24212;&#29992;&#20013;&#20854;&#26377;&#25928;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a simple and scalable framework for extreme multiclass classification based on Johnson-Lindenstrauss matrices (JLMs). Using the columns of a JLM to embed the labels, a $C$-class classification problem is transformed into a regression problem with $\cO(\log C)$ output dimension. We derive an excess risk bound, revealing a tradeoff between computational efficiency and prediction accuracy, and further show that under the Massart noise condition, the penalty for dimension reduction vanishes. Our approach is easily parallelizable, and experimental results demonstrate its effectiveness and scalability in large-scale applications.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22914;&#20309;&#21033;&#29992;&#31526;&#21512;&#24615;&#39044;&#27979;&#25216;&#26415;&#65292;&#22312;&#22810;&#39033;&#36873;&#25321;&#39064;&#22238;&#31572;&#20219;&#21153;&#20013;&#20026;&#35821;&#35328;&#27169;&#22411;&#25552;&#20379;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#25105;&#20204;&#21457;&#29616;&#31526;&#21512;&#24615;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#19982;&#39044;&#27979;&#20934;&#30830;&#24615;&#23494;&#20999;&#30456;&#20851;&#12290;</title><link>http://arxiv.org/abs/2305.18404</link><description>&lt;p&gt;
&#22522;&#20110;&#22823;&#35821;&#35328;&#27169;&#22411;&#30340;&#22810;&#39033;&#36873;&#25321;&#39064;&#31572;&#26696;&#30830;&#35748;&#39044;&#27979;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Conformal Prediction with Large Language Models for Multi-Choice Question Answering. (arXiv:2305.18404v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18404
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22914;&#20309;&#21033;&#29992;&#31526;&#21512;&#24615;&#39044;&#27979;&#25216;&#26415;&#65292;&#22312;&#22810;&#39033;&#36873;&#25321;&#39064;&#22238;&#31572;&#20219;&#21153;&#20013;&#20026;&#35821;&#35328;&#27169;&#22411;&#25552;&#20379;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#25105;&#20204;&#21457;&#29616;&#31526;&#21512;&#24615;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#19982;&#39044;&#27979;&#20934;&#30830;&#24615;&#23494;&#20999;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24191;&#27867;&#24320;&#21457;&#65292;&#23545;&#23427;&#20204;&#36827;&#34892;&#20581;&#22766;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#25216;&#26415;&#23558;&#25104;&#20026;&#23427;&#20204;&#22312;&#39640;&#39118;&#38505;&#22330;&#26223;&#19979;&#23433;&#20840;&#37096;&#32626;&#30340;&#20851;&#38190;&#12290;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22914;&#20309;&#21033;&#29992;&#31526;&#21512;&#24615;&#39044;&#27979;&#25216;&#26415;&#65292;&#22312;&#22810;&#39033;&#36873;&#25321;&#39064;&#22238;&#31572;&#20219;&#21153;&#20013;&#20026;&#35821;&#35328;&#27169;&#22411;&#25552;&#20379;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#12290;&#25105;&#20204;&#21457;&#29616;&#31526;&#21512;&#24615;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#19982;&#39044;&#27979;&#20934;&#30830;&#24615;&#23494;&#20999;&#30456;&#20851;&#12290;&#36825;&#31181;&#35266;&#23519;&#23545;&#20110;&#19979;&#28216;&#24212;&#29992;&#65292;&#22914;&#36873;&#25321;&#24615;&#20998;&#31867;&#21644;&#36807;&#28388;&#20302;&#36136;&#37327;&#39044;&#27979;&#65292;&#21487;&#33021;&#20250;&#26377;&#29992;&#12290;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#31526;&#21512;&#24615;&#39044;&#27979;&#23545;&#20110;&#36229;&#20986;&#20027;&#39064;&#30340;&#38382;&#39064;&#30340;&#20132;&#25442;&#24615;&#20551;&#35774;&#65292;&#36825;&#21487;&#33021;&#26159;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#30340;&#26356;&#20026;&#29616;&#23454;&#30340;&#22330;&#26223;&#12290;&#26412;&#30740;&#31350;&#20026;&#22312;&#38656;&#35201;&#21487;&#38752;&#20445;&#35777;&#38169;&#35823;&#29575;&#30340;&#23433;&#20840;&#20851;&#38190;&#24773;&#20917;&#19979;&#26356;&#21152;&#20540;&#24471;&#20449;&#36182;&#21644;&#21487;&#38752;&#22320;&#20351;&#29992;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
As large language models continue to be widely developed, robust uncertainty quantification techniques will become crucial for their safe deployment in high-stakes scenarios. In this work, we explore how conformal prediction can be used to provide uncertainty quantification in language models for the specific task of multiple-choice question-answering. We find that the uncertainty estimates from conformal prediction are tightly correlated with prediction accuracy. This observation can be useful for downstream applications such as selective classification and filtering out low-quality predictions. We also investigate the exchangeability assumption required by conformal prediction to out-of-subject questions, which may be a more realistic scenario for many practical applications. Our work contributes towards more trustworthy and reliable usage of large language models in safety-critical situations, where robust guarantees of error rate are required.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#36890;&#36807;&#33609;&#22270;&#25216;&#26415;&#23558;&#31890;&#23376;&#26041;&#27861;&#21644;&#24352;&#37327;&#32593;&#32476;&#26041;&#27861;&#32467;&#21512;&#30340;&#26041;&#27861;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#36825;&#31181;&#26041;&#27861;&#21253;&#25324;&#31890;&#23376;&#27169;&#25311;&#21644;&#24352;&#37327;&#32593;&#32476;&#37325;&#26032;&#20272;&#35745;&#65292;&#24182;&#21487;&#29992;&#20316;&#31890;&#23376;&#25968;&#25511;&#21046;&#30340;&#21487;&#26367;&#20195;&#26041;&#27861;&#12290;&#22312;&#27169;&#25311;Fokker-Planck&#26041;&#31243;&#21644;&#37327;&#23376;&#34394;&#26102;&#38388;&#28436;&#21270;&#26041;&#38754;&#65292;&#35813;&#26041;&#27861;&#34920;&#29616;&#20986;&#36890;&#29992;&#24615;&#21644;&#28789;&#27963;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.17884</link><description>&lt;p&gt;
&#36890;&#36807;&#33609;&#22270;&#25216;&#26415;&#65292;&#23558;&#31890;&#23376;&#26041;&#27861;&#21644;&#24352;&#37327;&#32593;&#32476;&#26041;&#27861;&#32467;&#21512;&#29992;&#20110;&#20559;&#24494;&#20998;&#26041;&#31243;&#27714;&#35299;
&lt;/p&gt;
&lt;p&gt;
Combining Particle and Tensor-network Methods for Partial Differential Equations via Sketching. (arXiv:2305.17884v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17884
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#36890;&#36807;&#33609;&#22270;&#25216;&#26415;&#23558;&#31890;&#23376;&#26041;&#27861;&#21644;&#24352;&#37327;&#32593;&#32476;&#26041;&#27861;&#32467;&#21512;&#30340;&#26041;&#27861;&#29992;&#20110;&#35299;&#20915;&#39640;&#32500;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#36825;&#31181;&#26041;&#27861;&#21253;&#25324;&#31890;&#23376;&#27169;&#25311;&#21644;&#24352;&#37327;&#32593;&#32476;&#37325;&#26032;&#20272;&#35745;&#65292;&#24182;&#21487;&#29992;&#20316;&#31890;&#23376;&#25968;&#25511;&#21046;&#30340;&#21487;&#26367;&#20195;&#26041;&#27861;&#12290;&#22312;&#27169;&#25311;Fokker-Planck&#26041;&#31243;&#21644;&#37327;&#23376;&#34394;&#26102;&#38388;&#28436;&#21270;&#26041;&#38754;&#65292;&#35813;&#26041;&#27861;&#34920;&#29616;&#20986;&#36890;&#29992;&#24615;&#21644;&#28789;&#27963;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35299;&#20915;&#39640;&#32500;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#24352;&#37327;&#32593;&#32476;&#26694;&#26550;&#65292;&#20854;&#20013;&#25105;&#20204;&#37319;&#29992;&#31890;&#23376;&#27169;&#25311;&#26356;&#26032;&#35299;&#20915;&#26041;&#26696;&#65292;&#24182;&#20351;&#29992;&#26368;&#36817;&#25552;&#20986;&#30340;&#24352;&#37327;&#21015;&#36710;&#33609;&#22270;&#25216;&#26415;&#23558;&#26032;&#35299;&#20915;&#26041;&#26696;&#37325;&#26032;&#20272;&#35745;&#20026;&#24352;&#37327;&#32593;&#32476;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36824;&#21487;&#20197;&#34987;&#35299;&#37322;&#20026;&#36890;&#36807;&#20551;&#35774;&#31890;&#23376;&#26469;&#33258;&#24213;&#23618;&#24352;&#37327;&#32593;&#32476;&#26469;&#25191;&#34892;&#31890;&#23376;&#25968;&#25511;&#21046;&#30340;&#21487;&#26367;&#20195;&#26041;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#20854;&#24212;&#29992;&#20110;&#20004;&#31181;&#29305;&#23450;&#30340;&#24773;&#26223;&#26469;&#23637;&#31034;&#25105;&#20204;&#26041;&#27861;&#30340;&#36890;&#29992;&#24615;&#21644;&#28789;&#27963;&#24615;&#65306;&#36890;&#36807;Langevin&#21160;&#21147;&#23398;&#27169;&#25311;Fokker-Planck&#26041;&#31243;&#21644;&#36890;&#36807;&#36741;&#21161;&#22330;&#37327;&#23376;&#33945;&#29305;&#21345;&#32599;&#27169;&#25311;&#37327;&#23376;&#34394;&#26102;&#38388;&#28436;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a general framework for solving high-dimensional partial differential equations with tensor networks. Our approach offers a comprehensive solution methodology, wherein we employ a combination of particle simulations to update the solution and re-estimations of the new solution as a tensor-network using a recently proposed tensor train sketching technique. Our method can also be interpreted as an alternative approach for performing particle number control by assuming the particles originate from an underlying tensor network. We demonstrate the versatility and flexibility of our approach by applying it to two specific scenarios: simulating the Fokker-Planck equation through Langevin dynamics and quantum imaginary time evolution via auxiliary-field quantum Monte Carlo.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#30142;&#30149;&#24739;&#32773;&#20010;&#20307;&#30340;&#26681;&#26412;&#21407;&#22240;&#30340;&#26032;&#20844;&#24335;&#65292;&#21487;&#20197;&#29992;&#20110;&#33258;&#21160;&#20174;&#25968;&#25454;&#20013;&#26816;&#27979;&#26681;&#26412;&#21407;&#22240;&#65292;&#24182;&#32771;&#34385;&#20102;&#22122;&#22768;&#26631;&#31614;&#21644;&#30142;&#30149;&#27969;&#34892;&#29575;&#31561;&#22240;&#32032;&#65292;&#21516;&#26102;&#20855;&#26377;&#24555;&#36895;&#35745;&#31639;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2305.17574</link><description>&lt;p&gt;
&#30142;&#30149;&#24739;&#32773;&#20010;&#20307;&#26681;&#26412;&#21407;&#22240;&#30340;&#21453;&#20107;&#23454;&#20844;&#24335;&#21270;
&lt;/p&gt;
&lt;p&gt;
Counterfactual Formulation of Patient-Specific Root Causes of Disease. (arXiv:2305.17574v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17574
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#30142;&#30149;&#24739;&#32773;&#20010;&#20307;&#30340;&#26681;&#26412;&#21407;&#22240;&#30340;&#26032;&#20844;&#24335;&#65292;&#21487;&#20197;&#29992;&#20110;&#33258;&#21160;&#20174;&#25968;&#25454;&#20013;&#26816;&#27979;&#26681;&#26412;&#21407;&#22240;&#65292;&#24182;&#32771;&#34385;&#20102;&#22122;&#22768;&#26631;&#31614;&#21644;&#30142;&#30149;&#27969;&#34892;&#29575;&#31561;&#22240;&#32032;&#65292;&#21516;&#26102;&#20855;&#26377;&#24555;&#36895;&#35745;&#31639;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30142;&#30149;&#30340;&#26681;&#26412;&#21407;&#22240;&#30452;&#35266;&#22320;&#23545;&#24212;&#20110;&#22686;&#21152;&#35786;&#26029;&#21487;&#33021;&#24615;&#30340;&#26681;&#26412;&#39030;&#28857;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26681;&#26412;&#21407;&#22240;&#30340;&#25551;&#36848;&#32570;&#20047;&#35745;&#31639;&#26426;&#31639;&#27861;&#21457;&#23637;&#25152;&#38656;&#30340;&#20005;&#26684;&#25968;&#23398;&#20844;&#24335;&#12290;&#22312;&#20197;&#21069;&#30340;&#24037;&#20316;&#20013;&#65292;&#20351;&#29992;&#24178;&#39044;&#20027;&#20041;&#32773;&#24080;&#25143;&#23450;&#20041;&#20102;&#30142;&#30149;&#30340;&#30149;&#20154;&#29305;&#23450;&#26681;&#26412;&#21407;&#22240;&#65292;&#35813;&#24080;&#25143;&#20165;&#25856;&#21319;&#21040;&#29645;&#29664;&#30340;&#22240;&#26524;Ladder&#30340;&#31532;&#20108;&#23618;&#12290;&#22312;&#36825;&#20010;&#29702;&#35770;&#24615;&#30340;&#25991;&#31456;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#21453;&#20107;&#23454;&#30340;&#23450;&#20041;&#26469;&#25856;&#21319;&#21040;&#31532;&#19977;&#23618;&#65292;&#20197;&#21305;&#37197;&#22522;&#20110;&#22266;&#23450;&#20107;&#23454;&#25968;&#25454;&#30340;&#20020;&#24202;&#30452;&#35273;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#30340;Shapley&#20540;&#20026;&#27599;&#20010;&#21464;&#37327;&#20998;&#37197;&#26681;&#22240;&#36129;&#29486;&#24471;&#20998;&#12290;&#25552;&#20986;&#30340;&#30142;&#30149;&#24739;&#32773;&#20010;&#20307;&#26681;&#26412;&#21407;&#22240;&#30340;&#21453;&#20107;&#23454;&#20844;&#24335;&#21270;&#32771;&#34385;&#20102;&#22122;&#22768;&#26631;&#31614;&#65292;&#36866;&#24212;&#20102;&#30142;&#30149;&#30340;&#27969;&#34892;&#29575;&#65292;&#24182;&#20801;&#35768;&#24555;&#36895;&#35745;&#31639;&#65292;&#26080;&#38656;&#21453;&#20107;&#23454;&#27169;&#25311;&#12290;
&lt;/p&gt;
&lt;p&gt;
Root causes of disease intuitively correspond to root vertices that increase the likelihood of a diagnosis. This description of a root cause nevertheless lacks the rigorous mathematical formulation needed for the development of computer algorithms designed to automatically detect root causes from data. Prior work defined patient-specific root causes of disease using an interventionalist account that only climbs to the second rung of Pearl's Ladder of Causation. In this theoretical piece, we climb to the third rung by proposing a counterfactual definition matching clinical intuition based on fixed factual data alone. We then show how to assign a root causal contribution score to each variable using Shapley values from explainable artificial intelligence. The proposed counterfactual formulation of patient-specific root causes of disease accounts for noisy labels, adapts to disease prevalence and admits fast computation without the need for counterfactual simulation.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#21160;&#24577;&#31283;&#23450;&#24615;&#38544;&#24335;&#27491;&#21017;&#21270;&#65292;&#35777;&#26126;&#20102;&#20854;&#20855;&#26377;&#33391;&#22909;&#30340;&#27867;&#21270;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.17490</link><description>&lt;p&gt;
&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20013;&#21160;&#24577;&#31283;&#23450;&#24615;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
The Implicit Regularization of Dynamical Stability in Stochastic Gradient Descent. (arXiv:2305.17490v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17490
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#30340;&#21160;&#24577;&#31283;&#23450;&#24615;&#38544;&#24335;&#27491;&#21017;&#21270;&#65292;&#35777;&#26126;&#20102;&#20854;&#20855;&#26377;&#33391;&#22909;&#30340;&#27867;&#21270;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#8220;&#21160;&#24577;&#31283;&#23450;&#24615;&#8221;&#30340;&#35282;&#24230;&#30740;&#31350;&#20102;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#12290;&#25105;&#20204;&#39318;&#20808;&#20462;&#27491;&#20102;&#29616;&#26377;SGD&#31283;&#23450;&#24615;&#20998;&#26512;&#30340;&#38382;&#39064;&#65292;&#23637;&#31034;&#20102;Hessian&#30697;&#38453;&#30340;Frobenius&#33539;&#25968;&#21644;&#36857;&#19982;&#19981;&#21516;&#31283;&#23450;&#24615;&#27010;&#24565;&#30340;&#20851;&#31995;&#12290;&#29305;&#21035;&#22320;&#65292;&#22914;&#26524;&#20840;&#23616;&#26368;&#23567;&#20540;&#22312;SGD&#20013;&#26159;&#32447;&#24615;&#31283;&#23450;&#30340;&#65292;&#21017;Hessian&#30697;&#38453;&#30340;&#36857;&#24517;&#39035;&#23567;&#20110;&#25110;&#31561;&#20110;$2/\eta$&#65292;&#20854;&#20013;$\eta$&#34920;&#31034;&#23398;&#20064;&#29575;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#65292;&#31283;&#23450;&#24615;&#21482;&#23545;Hessian&#30697;&#38453;&#30340;&#26368;&#22823;&#29305;&#24449;&#20540;&#26045;&#21152;&#31867;&#20284;&#30340;&#32422;&#26463;&#12290;&#25105;&#20204;&#25509;&#30528;&#20998;&#26512;&#20102;&#36825;&#20123;&#31283;&#23450;&#26497;&#20540;&#30340;&#27867;&#21270;&#24615;&#36136;&#65292;&#30528;&#37325;&#20851;&#27880;&#20102;&#20004;&#23618;ReLU&#32593;&#32476;&#21644;&#23545;&#35282;&#32447;&#24615;&#32593;&#32476;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#36825;&#20004;&#20010;&#27169;&#22411;&#30340;&#23574;&#38160;&#24230;&#24230;&#37327;&#21644;&#26576;&#20123;&#21442;&#25968;&#35268;&#33539;&#20043;&#38388;&#30340;&#8220;&#31561;&#20215;&#24615;&#8221;&#65292;&#20174;&#32780;&#35777;&#26126;&#20102;SGD&#30340;&#31283;&#23450;&#26497;&#20540;&#20855;&#26377;&#33391;&#22909;&#30340;&#27867;&#21270;&#24615;&#12290;&#28982;&#32780;&#65292;GD&#30340;&#31283;&#23450;&#24615;&#27491;&#21017;&#21270;&#21482;&#22312;&#29305;&#23450;&#24773;&#20917;&#19979;&#20135;&#29983;&#27867;&#21270;&#25928;&#30410;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#29702;&#35770;&#24212;&#29992;&#20110;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#38382;&#39064;&#65292;&#32467;&#26524;&#34920;&#26126;&#23427;&#23545;&#26576;&#20123;&#27169;&#22411;&#30340;&#34920;&#29616;&#20248;&#20110;Lasso&#25110;&#23725;&#27491;&#21017;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study the implicit regularization of stochastic gradient descent (SGD) through the lens of {\em dynamical stability} (Wu et al., 2018). We start by revising existing stability analyses of SGD, showing how the Frobenius norm and trace of Hessian relate to different notions of stability. Notably, if a global minimum is linearly stable for SGD, then the trace of Hessian must be less than or equal to $2/\eta$, where $\eta$ denotes the learning rate. By contrast, for gradient descent (GD), the stability imposes a similar constraint but only on the largest eigenvalue of Hessian. We then turn to analyze the generalization properties of these stable minima, focusing specifically on two-layer ReLU networks and diagonal linear networks. Notably, we establish the {\em equivalence} between these metrics of sharpness and certain parameter norms for the two models, which allows us to show that the stable minima of SGD provably generalize well. By contrast, the stability-induced reg
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20174;&#29702;&#35770;&#23618;&#38754;&#25506;&#31350;&#20102;&#24102;&#26377;&#8220;&#24605;&#32500;&#38142;&#8221;&#25552;&#31034;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#35299;&#20915;&#22522;&#26412;&#25968;&#23398;&#21644;&#20915;&#31574;&#38382;&#39064;&#20013;&#30340;&#33021;&#21147;&#65292;&#21457;&#29616;&#33258;&#22238;&#24402;Transformer&#22823;&#23567;&#24658;&#23450;&#21363;&#21487;&#35299;&#20915;&#20219;&#21153;&#65292;&#25581;&#31034;&#20102;&#8220;&#24605;&#32500;&#38142;&#8221;&#25552;&#31034;&#30340;&#32972;&#21518;&#26426;&#21046;&#12290;</title><link>http://arxiv.org/abs/2305.15408</link><description>&lt;p&gt;
&#20174;&#29702;&#35770;&#35282;&#24230;&#25581;&#31034;&#8220;&#24605;&#32500;&#38142;&#8221;&#32972;&#21518;&#30340;&#22885;&#31192;
&lt;/p&gt;
&lt;p&gt;
Towards Revealing the Mystery behind Chain of Thought: a Theoretical Perspective. (arXiv:2305.15408v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15408
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#29702;&#35770;&#23618;&#38754;&#25506;&#31350;&#20102;&#24102;&#26377;&#8220;&#24605;&#32500;&#38142;&#8221;&#25552;&#31034;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#35299;&#20915;&#22522;&#26412;&#25968;&#23398;&#21644;&#20915;&#31574;&#38382;&#39064;&#20013;&#30340;&#33021;&#21147;&#65292;&#21457;&#29616;&#33258;&#22238;&#24402;Transformer&#22823;&#23567;&#24658;&#23450;&#21363;&#21487;&#35299;&#20915;&#20219;&#21153;&#65292;&#25581;&#31034;&#20102;&#8220;&#24605;&#32500;&#38142;&#8221;&#25552;&#31034;&#30340;&#32972;&#21518;&#26426;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;"&#24605;&#32500;&#38142;"&#25552;&#31034;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#30340;&#24615;&#33021;&#65292;&#29305;&#21035;&#26159;&#22312;&#28041;&#21450;&#25968;&#23398;&#25110;&#25512;&#29702;&#30340;&#22797;&#26434;&#20219;&#21153;&#20013;&#12290;&#23613;&#31649;&#33719;&#24471;&#20102;&#24040;&#22823;&#30340;&#23454;&#35777;&#25104;&#21151;&#65292;&#20294;&#8220;&#24605;&#32500;&#38142;&#8221;&#32972;&#21518;&#30340;&#26426;&#21046;&#20197;&#21450;&#23427;&#22914;&#20309;&#37322;&#25918;LLMs&#30340;&#28508;&#21147;&#20173;&#28982;&#26159;&#31070;&#31192;&#30340;&#12290;&#26412;&#25991;&#39318;&#27425;&#20174;&#29702;&#35770;&#19978;&#22238;&#31572;&#20102;&#36825;&#20123;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;LLMs&#24102;&#26377;&#8220;&#24605;&#32500;&#38142;&#8221;&#22312;&#35299;&#20915;&#22522;&#26412;&#25968;&#23398;&#21644;&#20915;&#31574;&#38382;&#39064;&#20013;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#39318;&#20808;&#32473;&#20986;&#19968;&#20010;&#19981;&#21487;&#33021;&#30340;&#32467;&#26524;&#65292;&#34920;&#26126;&#20219;&#20309;&#26377;&#38480;&#28145;&#24230;&#30340;Transformer&#37117;&#19981;&#33021;&#30452;&#25509;&#36755;&#20986;&#27491;&#30830;&#30340;&#22522;&#26412;&#31639;&#26415;/&#26041;&#31243;&#20219;&#21153;&#30340;&#31572;&#26696;&#65292;&#38500;&#38750;&#27169;&#22411;&#22823;&#23567;&#38543;&#30528;&#36755;&#20837;&#38271;&#24230;&#30340;&#22686;&#21152;&#21576;&#36229;&#22810;&#39033;&#24335;&#22686;&#38271;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#36890;&#36807;&#26500;&#36896;&#35777;&#26126;&#65292;&#22823;&#23567;&#24658;&#23450;&#30340;&#33258;&#22238;&#24402;Transformer&#36275;&#20197;&#36890;&#36807;&#20351;&#29992;&#24120;&#29992;&#30340;&#25968;&#23398;&#35821;&#35328;&#24418;&#24335;&#29983;&#25104;&#8220;&#24605;&#32500;&#38142;&#8221;&#25512;&#23548;&#26469;&#35299;&#20915;&#36825;&#20004;&#20010;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent studies have discovered that Chain-of-Thought prompting (CoT) can dramatically improve the performance of Large Language Models (LLMs), particularly when dealing with complex tasks involving mathematics or reasoning. Despite the enormous empirical success, the underlying mechanisms behind CoT and how it unlocks the potential of LLMs remain elusive. In this paper, we take a first step towards theoretically answering these questions. Specifically, we examine the capacity of LLMs with CoT in solving fundamental mathematical and decision-making problems. We start by giving an impossibility result showing that any bounded-depth Transformer cannot directly output correct answers for basic arithmetic/equation tasks unless the model size grows super-polynomially with respect to the input length. In contrast, we then prove by construction that autoregressive Transformers of a constant size suffice to solve both tasks by generating CoT derivations using a commonly-used math language forma
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#22312;&#24191;&#27867;&#27169;&#22411;&#20013;&#36827;&#34892;&#26368;&#20248;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#20013;&#24230;&#20559;&#24046;&#21407;&#29702;&#26500;&#24314;&#39640;&#24230;&#20934;&#30830;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#28385;&#36275;&#25351;&#25968;&#31934;&#24230;&#12289;&#19968;&#33268;&#24615;&#21644;&#26368;&#22823;&#31934;&#24230;&#31561;&#26631;&#20934;&#65292;&#20026;&#35813;&#26041;&#27861;&#25552;&#20379;&#20102;&#29702;&#35770;&#20381;&#25454;&#12290;</title><link>http://arxiv.org/abs/2305.14496</link><description>&lt;p&gt;
&#36890;&#36807;&#20013;&#24230;&#20559;&#24046;&#29702;&#35770;&#36827;&#34892;&#26368;&#20248;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Optimal Learning via Moderate Deviations Theory. (arXiv:2305.14496v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14496
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#22312;&#24191;&#27867;&#27169;&#22411;&#20013;&#36827;&#34892;&#26368;&#20248;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#20013;&#24230;&#20559;&#24046;&#21407;&#29702;&#26500;&#24314;&#39640;&#24230;&#20934;&#30830;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#28385;&#36275;&#25351;&#25968;&#31934;&#24230;&#12289;&#19968;&#33268;&#24615;&#21644;&#26368;&#22823;&#31934;&#24230;&#31561;&#26631;&#20934;&#65292;&#20026;&#35813;&#26041;&#27861;&#25552;&#20379;&#20102;&#29702;&#35770;&#20381;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#24191;&#27867;&#27169;&#22411;&#20013;&#20351;&#29992;&#32622;&#20449;&#21306;&#38388;&#23398;&#20064;&#20989;&#25968;&#20540;&#30340;&#32479;&#35745;&#26368;&#20248;&#26041;&#27861;&#65292;&#21253;&#25324;&#25551;&#36848;&#20026;&#38543;&#26426;&#35268;&#21010;&#38382;&#39064;&#25110;&#21508;&#31181;SDE&#27169;&#22411;&#30340;&#26399;&#26395;&#25439;&#22833;&#30340;&#19968;&#33324;&#38750;&#21442;&#25968;&#20272;&#35745;&#12290;&#26356;&#20934;&#30830;&#22320;&#35828;&#65292;&#25105;&#20204;&#36890;&#36807;&#37319;&#29992;&#22522;&#20110;&#20013;&#24230;&#20559;&#24046;&#21407;&#29702;&#30340;&#26041;&#27861;&#31995;&#32479;&#22320;&#26500;&#24314;&#39640;&#24230;&#20934;&#30830;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#32622;&#20449;&#21306;&#38388;&#22312;&#32479;&#35745;&#24847;&#20041;&#19978;&#26159;&#26368;&#20248;&#30340;&#65292;&#22240;&#20026;&#23427;&#20204;&#28385;&#36275;&#20197;&#25351;&#25968;&#31934;&#24230;&#12289;&#26368;&#23567;&#24615;&#12289;&#19968;&#33268;&#24615;&#12289;&#35823;&#21028;&#27010;&#29575;&#20197;&#21450;&#26368;&#32456;&#30340;&#19968;&#33268;&#26368;&#22823;&#31934;&#24230;&#20026;&#26631;&#20934;&#30340;&#35201;&#27714;&#12290;&#35813;&#26041;&#27861;&#25552;&#20986;&#30340;&#32622;&#20449;&#21306;&#38388;&#26159;&#36890;&#36807;&#24378;&#21270;&#20248;&#21270;&#38382;&#39064;&#30340;&#35299;&#26469;&#34920;&#36798;&#30340;&#65292;&#20854;&#20013;&#19981;&#30830;&#23450;&#24615;&#36890;&#36807;&#25968;&#25454;&#29983;&#25104;&#36807;&#31243;&#24341;&#21457;&#30340;&#20013;&#24230;&#20559;&#24046;&#29575;&#20989;&#25968;&#26469;&#34920;&#31034;&#12290;&#25105;&#20204;&#28436;&#31034;&#20102;&#23545;&#20110;&#35768;&#22810;&#27169;&#22411;&#65292;&#36825;&#20123;&#20248;&#21270;&#38382;&#39064;&#20855;&#26377;&#26131;&#20110;&#35299;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a statistically optimal approach for learning a function value using a confidence interval in a wide range of models, including general non-parametric estimation of an expected loss described as a stochastic programming problem or various SDE models. More precisely, we develop a systematic construction of highly accurate confidence intervals by using a moderate deviation principle-based approach. It is shown that the proposed confidence intervals are statistically optimal in the sense that they satisfy criteria regarding exponential accuracy, minimality, consistency, mischaracterization probability, and eventual uniformly most accurate (UMA) property. The confidence intervals suggested by this approach are expressed as solutions to robust optimization problems, where the uncertainty is expressed via the underlying moderate deviation rate function induced by the data-generating process. We demonstrate that for many models these optimization problems admit tractable r
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#23558;&#38464;&#34746;&#30690;&#37327;&#31354;&#38388;&#20013;&#30340;&#19968;&#20123;&#27010;&#24565;&#25512;&#24191;&#21040;SPD&#21644;Grassmann&#27969;&#24418;&#65292;&#25552;&#20986;&#20102;&#22312;&#36825;&#20123;&#27969;&#24418;&#19978;&#26500;&#24314;&#31070;&#32463;&#32593;&#32476;&#30340;&#26032;&#27169;&#22411;&#21644;&#26032;&#23618;&#65292;&#24182;&#22312;&#20154;&#31867;&#21160;&#20316;&#35782;&#21035;&#21644;&#30693;&#35782;&#22270;&#35889;&#23436;&#25104;&#20004;&#20010;&#24212;&#29992;&#20013;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.04560</link><description>&lt;p&gt;
&#22522;&#20110;&#30697;&#38453;&#27969;&#24418;&#30340;&#31070;&#32463;&#32593;&#32476;&#26500;&#24314;&#65306;&#38464;&#34746;&#30690;&#37327;&#31354;&#38388;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Building Neural Networks on Matrix Manifolds: A Gyrovector Space Approach. (arXiv:2305.04560v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04560
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#23558;&#38464;&#34746;&#30690;&#37327;&#31354;&#38388;&#20013;&#30340;&#19968;&#20123;&#27010;&#24565;&#25512;&#24191;&#21040;SPD&#21644;Grassmann&#27969;&#24418;&#65292;&#25552;&#20986;&#20102;&#22312;&#36825;&#20123;&#27969;&#24418;&#19978;&#26500;&#24314;&#31070;&#32463;&#32593;&#32476;&#30340;&#26032;&#27169;&#22411;&#21644;&#26032;&#23618;&#65292;&#24182;&#22312;&#20154;&#31867;&#21160;&#20316;&#35782;&#21035;&#21644;&#30693;&#35782;&#22270;&#35889;&#23436;&#25104;&#20004;&#20010;&#24212;&#29992;&#20013;&#23637;&#31034;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30697;&#38453;&#27969;&#24418;&#65292;&#22914;&#23545;&#31216;&#27491;&#23450;&#65288;SPD&#65289;&#30697;&#38453;&#21644;Grassmann&#27969;&#24418;&#65292;&#20986;&#29616;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#12290;&#26368;&#36817;&#65292;&#36890;&#36807;&#24212;&#29992;&#38464;&#34746;&#32676;&#21644;&#38464;&#34746;&#30690;&#37327;&#31354;&#38388;&#30340;&#29702;&#35770;&#8212;&#8212;&#36825;&#26159;&#19968;&#20010;&#30740;&#31350;&#21452;&#26354;&#20960;&#20309;&#30340;&#24378;&#22823;&#26694;&#26550;&#8212;&#8212;&#19968;&#20123;&#24037;&#20316;&#23581;&#35797;&#22312;&#30697;&#38453;&#27969;&#24418;&#19978;&#26500;&#24314;&#27431;&#20960;&#37324;&#24503;&#31070;&#32463;&#32593;&#32476;&#30340;&#21407;&#21017;&#24615;&#25512;&#24191;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#32570;&#20047;&#32771;&#34385;&#27969;&#24418;&#30340;&#20869;&#31215;&#21644;&#38464;&#34746;&#35282;&#31561;&#27010;&#24565;&#30340;&#38464;&#34746;&#30690;&#37327;&#31354;&#38388;&#65292;&#30456;&#27604;&#20110;&#29992;&#20110;&#30740;&#31350;&#21452;&#26354;&#20960;&#20309;&#30340;&#37027;&#20123;&#27010;&#24565;&#65292;&#36825;&#20123;&#24037;&#20316;&#25552;&#20379;&#30340;&#25216;&#26415;&#21644;&#25968;&#23398;&#24037;&#20855;&#20173;&#28982;&#26377;&#38480;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23558;&#38464;&#34746;&#30690;&#37327;&#31354;&#38388;&#20013;&#30340;&#19968;&#20123;&#27010;&#24565;&#25512;&#24191;&#21040;SPD&#21644;Grassmann&#27969;&#24418;&#65292;&#24182;&#25552;&#20986;&#20102;&#22312;&#36825;&#20123;&#27969;&#24418;&#19978;&#26500;&#24314;&#31070;&#32463;&#32593;&#32476;&#30340;&#26032;&#27169;&#22411;&#21644;&#26032;&#23618;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20154;&#31867;&#21160;&#20316;&#35782;&#21035;&#21644;&#30693;&#35782;&#22270;&#35889;&#23436;&#25104;&#20004;&#20010;&#24212;&#29992;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Matrix manifolds, such as manifolds of Symmetric Positive Definite (SPD) matrices and Grassmann manifolds, appear in many applications. Recently, by applying the theory of gyrogroups and gyrovector spaces that is a powerful framework for studying hyperbolic geometry, some works have attempted to build principled generalizations of Euclidean neural networks on matrix manifolds. However, due to the lack of many concepts in gyrovector spaces for the considered manifolds, e.g., the inner product and gyroangles, techniques and mathematical tools provided by these works are still limited compared to those developed for studying hyperbolic geometry. In this paper, we generalize some notions in gyrovector spaces for SPD and Grassmann manifolds, and propose new models and layers for building neural networks on these manifolds. We show the effectiveness of our approach in two applications, i.e., human action recognition and knowledge graph completion.
&lt;/p&gt;</description></item><item><title>Data-OOB&#26159;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#20215;&#20540;&#20272;&#35745;&#26041;&#27861;&#65292;&#23427;&#21033;&#29992;out-of-bag&#20272;&#35745;&#65292;&#24182;&#21487;&#20197;&#22312;&#35745;&#31639;&#19978;&#39640;&#25928;&#22788;&#29702;&#22823;&#22411;&#25968;&#25454;&#38598;&#12290;</title><link>http://arxiv.org/abs/2304.07718</link><description>&lt;p&gt;
Data-OOB:&#20197;&#26080;&#38656;&#39069;&#22806;&#35745;&#31639;&#30340;Out-of-bag&#20272;&#35745;&#20026;&#20934;&#30340;&#25968;&#25454;&#20215;&#20540;&#20272;&#35745;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Data-OOB: Out-of-bag Estimate as a Simple and Efficient Data Value. (arXiv:2304.07718v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.07718
&lt;/p&gt;
&lt;p&gt;
Data-OOB&#26159;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#20215;&#20540;&#20272;&#35745;&#26041;&#27861;&#65292;&#23427;&#21033;&#29992;out-of-bag&#20272;&#35745;&#65292;&#24182;&#21487;&#20197;&#22312;&#35745;&#31639;&#19978;&#39640;&#25928;&#22788;&#29702;&#22823;&#22411;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#35780;&#20272;&#26159;&#19968;&#20010;&#24378;&#22823;&#30340;&#26694;&#26550;&#65292;&#21487;&#20197;&#20026;&#27169;&#22411;&#35757;&#32451;&#25552;&#20379;&#32479;&#35745;&#27934;&#23519;&#21147;&#65292;&#20197;&#21306;&#20998;&#21738;&#20123;&#25968;&#25454;&#23545;&#20110;&#27169;&#22411;&#35757;&#32451;&#26159;&#26377;&#30410;&#30340;&#65292;&#21738;&#20123;&#26159;&#26377;&#23475;&#30340;&#12290;&#32437;&#35266;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#65292;&#35768;&#22810;&#20197;Shapley&#20026;&#22522;&#30784;&#30340;&#25968;&#25454;&#20215;&#20540;&#35780;&#20272;&#26041;&#27861;&#22343;&#26174;&#31034;&#20986;&#20102;&#24456;&#26377;&#21069;&#36884;&#30340;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#36825;&#38656;&#35201;&#35757;&#32451;&#22823;&#37327;&#30340;&#27169;&#22411;&#65292;&#22240;&#27492;&#20247;&#25152;&#21608;&#30693;&#65292;&#36825;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#22240;&#27492;&#65292;&#23558;&#27492;&#24212;&#29992;&#20110;&#22823;&#22411;&#25968;&#25454;&#38598;&#26159;&#19981;&#21487;&#34892;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Data-OOB&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#30340;&#25968;&#25454;&#20215;&#20540;&#20272;&#35745;&#26041;&#27861;&#65292;&#38024;&#23545;bagging&#27169;&#22411;&#65292;&#23427;&#21033;&#29992;&#20102;out-of-bag&#20272;&#35745;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#35745;&#31639;&#19978;&#26159;&#39640;&#25928;&#30340;&#65292;&#21487;&#20197;&#36890;&#36807;&#37325;&#22797;&#20351;&#29992;&#35757;&#32451;&#22909;&#30340;&#24369;&#23398;&#20064;&#22120;&#26469;&#25193;&#23637;&#21040;&#25968;&#30334;&#19975;&#20010;&#25968;&#25454;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#24403;&#35780;&#20272;100&#20010;&#36755;&#20837;&#32500;&#24230;&#19988;&#23384;&#22312;$10^6$&#20010;&#26679;&#26412;&#26102;&#65292;Data-OOB&#20165;&#38656;&#35201;&#22312;&#21333;&#20010;CPU&#22788;&#29702;&#22120;&#19978;&#25191;&#34892;&#19981;&#21040;2.25&#20010;&#23567;&#26102;&#12290;&#27492;&#22806;&#65292;Data-OOB&#22312;&#29702;&#35770;&#19978;&#26377;&#22362;&#23454;&#30340;&#35299;&#37322;&#65292;&#24403;&#20004;&#20010;&#31163;&#24046;&#20540;&#20989;&#25968;&#30456;&#21516;&#26102;&#65292;&#20854;&#35782;&#21035;&#20855;&#26377;&#30456;&#21516;&#37325;&#35201;&#24615;&#30340;&#25968;&#25454;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data valuation is a powerful framework for providing statistical insights into which data are beneficial or detrimental to model training. Many Shapley-based data valuation methods have shown promising results in various downstream tasks, however, they are well known to be computationally challenging as it requires training a large number of models. As a result, it has been recognized as infeasible to apply to large datasets. To address this issue, we propose Data-OOB, a new data valuation method for a bagging model that utilizes the out-of-bag estimate. The proposed method is computationally efficient and can scale to millions of data by reusing trained weak learners. Specifically, Data-OOB takes less than 2.25 hours on a single CPU processor when there are $10^6$ samples to evaluate and the input dimension is 100. Furthermore, Data-OOB has solid theoretical interpretations in that it identifies the same important data point as the infinitesimal jackknife influence function when two d
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#29366;&#24577;&#32858;&#21512;&#26041;&#27861;&#26469;&#38477;&#20302;&#21160;&#24577;&#31163;&#25955;&#36873;&#25321;&#27169;&#22411;&#30340;&#20272;&#35745;&#35745;&#31639;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#39318;&#20808;&#21033;&#29992;&#21453;&#21521;&#24378;&#21270;&#23398;&#20064;&#20272;&#35745;&#20195;&#29702;Q&#20989;&#25968;&#65292;&#28982;&#21518;&#29992;&#32858;&#31867;&#31639;&#27861;&#36873;&#25321;&#37325;&#35201;&#30340;&#29366;&#24577;&#32858;&#21512;&#65292;&#26368;&#32456;&#21033;&#29992;&#23884;&#22871;&#22266;&#23450;&#28857;&#31639;&#27861;&#36827;&#34892;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2304.04916</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#29366;&#24577;&#32858;&#21512;&#26041;&#27861;&#29992;&#20110;&#21160;&#24577;&#31163;&#25955;&#36873;&#25321;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Data-Driven State Aggregation Approach for Dynamic Discrete Choice Models. (arXiv:2304.04916v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04916
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#29366;&#24577;&#32858;&#21512;&#26041;&#27861;&#26469;&#38477;&#20302;&#21160;&#24577;&#31163;&#25955;&#36873;&#25321;&#27169;&#22411;&#30340;&#20272;&#35745;&#35745;&#31639;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#39318;&#20808;&#21033;&#29992;&#21453;&#21521;&#24378;&#21270;&#23398;&#20064;&#20272;&#35745;&#20195;&#29702;Q&#20989;&#25968;&#65292;&#28982;&#21518;&#29992;&#32858;&#31867;&#31639;&#27861;&#36873;&#25321;&#37325;&#35201;&#30340;&#29366;&#24577;&#32858;&#21512;&#65292;&#26368;&#32456;&#21033;&#29992;&#23884;&#22871;&#22266;&#23450;&#28857;&#31639;&#27861;&#36827;&#34892;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#21160;&#24577;&#31163;&#25955;&#36873;&#25321;&#27169;&#22411;&#65292;&#20854;&#20013;&#19968;&#20010;&#24120;&#35265;&#30340;&#38382;&#39064;&#26159;&#20351;&#29992;&#20195;&#29702;&#34892;&#20026;&#25968;&#25454;&#20272;&#35745;&#20195;&#29702;&#22870;&#21169;&#20989;&#25968;&#65288;&#20063;&#31216;&#20026;&#8220;&#32467;&#26500;&#21442;&#25968;&#8221;&#65289;&#30340;&#21442;&#25968;&#12290;&#36825;&#31181;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#38656;&#35201;&#21160;&#24577;&#35268;&#21010;&#65292;&#36825;&#21463;&#21040;&#32500;&#24230;&#28798;&#38590;&#30340;&#38480;&#21046;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#27861;&#26469;&#36873;&#25321;&#21644;&#32858;&#21512;&#29366;&#24577;&#65292;&#38477;&#20302;&#20102;&#20272;&#35745;&#30340;&#35745;&#31639;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20998;&#20004;&#20010;&#38454;&#27573;&#12290;&#22312;&#31532;&#19968;&#38454;&#27573;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#28789;&#27963;&#30340;&#21453;&#21521;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#26469;&#20272;&#35745;&#20195;&#29702;Q&#20989;&#25968;&#12290;&#25105;&#20204;&#20351;&#29992;&#36825;&#20123;&#20272;&#35745;&#30340;Q&#20989;&#25968;&#65292;&#20197;&#21450;&#19968;&#20010;&#32858;&#31867;&#31639;&#27861;&#65292;&#36873;&#25321;&#20102;&#19968;&#20123;&#26368;&#20026;&#37325;&#35201;&#30340;&#29366;&#24577;&#65292;&#36825;&#20123;&#29366;&#24577;&#23545;&#20110;&#39537;&#21160;Q&#20989;&#25968;&#30340;&#21464;&#21270;&#26368;&#20026;&#20851;&#38190;&#12290;&#22312;&#31532;&#20108;&#38454;&#27573;&#65292;&#21033;&#29992;&#36825;&#20123;&#34987;&#36873;&#25321;&#30340;&#8220;&#32858;&#21512;&#8221;&#29366;&#24577;&#65292;&#25105;&#20204;&#20351;&#29992;&#24120;&#29992;&#30340;&#23884;&#22871;&#22266;&#23450;&#28857;&#31639;&#27861;&#36827;&#34892;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#12290;&#25152;&#25552;&#20986;&#30340;&#20108;&#38454;&#27573;&#26041;&#27861;&#23454;&#29616;&#20102;...
&lt;/p&gt;
&lt;p&gt;
We study dynamic discrete choice models, where a commonly studied problem involves estimating parameters of agent reward functions (also known as "structural" parameters), using agent behavioral data. Maximum likelihood estimation for such models requires dynamic programming, which is limited by the curse of dimensionality. In this work, we present a novel algorithm that provides a data-driven method for selecting and aggregating states, which lowers the computational and sample complexity of estimation. Our method works in two stages. In the first stage, we use a flexible inverse reinforcement learning approach to estimate agent Q-functions. We use these estimated Q-functions, along with a clustering algorithm, to select a subset of states that are the most pivotal for driving changes in Q-functions. In the second stage, with these selected "aggregated" states, we conduct maximum likelihood estimation using a commonly used nested fixed-point algorithm. The proposed two-stage approach 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#20998;&#20301;&#38543;&#26426;&#26862;&#26519;&#27169;&#22411;&#22806;&#25512;&#23436;&#22791;&#22522;&#32452;&#26497;&#38480;&#65292;&#24182;&#25552;&#20379;&#20102;&#39044;&#27979;&#21306;&#38388;&#20197;&#37327;&#21270;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.14760</link><description>&lt;p&gt;
&#29992;&#20998;&#20301;&#38543;&#26426;&#26862;&#26519;&#27169;&#22411;&#22312;&#23494;&#24230;&#27867;&#20989;&#29702;&#35770;&#20013;&#22806;&#25512;&#23436;&#22791;&#22522;&#32452;&#26497;&#38480;
&lt;/p&gt;
&lt;p&gt;
Extrapolation to complete basis-set limit in density-functional theory by quantile random-forest models. (arXiv:2303.14760v2 [physics.comp-ph] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14760
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#20998;&#20301;&#38543;&#26426;&#26862;&#26519;&#27169;&#22411;&#22806;&#25512;&#23436;&#22791;&#22522;&#32452;&#26497;&#38480;&#65292;&#24182;&#25552;&#20379;&#20102;&#39044;&#27979;&#21306;&#38388;&#20197;&#37327;&#21270;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23494;&#24230;&#27867;&#20989;&#29702;&#35770;&#65288;DFT&#65289;&#35745;&#31639;&#30340;&#25968;&#20540;&#31934;&#24230;&#21462;&#20915;&#20110;&#21508;&#31181;&#35745;&#31639;&#21442;&#25968;&#65292;&#20854;&#20013;&#26368;&#20851;&#38190;&#30340;&#20043;&#19968;&#26159;&#22522;&#32452;&#22823;&#23567;&#12290;&#29702;&#35770;&#19978;&#65292;&#20351;&#29992;&#26080;&#38480;&#22823;&#30340;&#22522;&#32452;&#65292;&#21363;&#23436;&#22791;&#22522;&#32452;&#38598;&#65292;&#21487;&#20197;&#36798;&#21040;&#26368;&#39640;&#31934;&#24230;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#25214;&#21040;&#19968;&#31181;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#23558;&#26377;&#38480;&#22522;&#32452;&#22823;&#23567;&#35745;&#31639;&#22806;&#25512;&#21040;&#23436;&#22791;&#22522;&#32452;&#26497;&#38480;&#12290;&#25105;&#20204;&#20174;63&#20010;&#20108;&#20803;&#22266;&#20307;&#30340;&#25968;&#25454;&#38598;&#24320;&#22987;&#65292;&#36825;&#20123;&#22266;&#20307;&#20351;&#29992;&#20004;&#31181;&#20840;&#30005;&#23376;DFT&#20195;&#30721;&#65292;&#21363;exciting&#21644;FHI-aims&#65292;&#36825;&#20004;&#31181;&#20195;&#30721;&#20351;&#29992;&#38750;&#24120;&#19981;&#21516;&#31867;&#22411;&#30340;&#22522;&#32452;&#12290;&#20351;&#29992;&#20998;&#20301;&#38543;&#26426;&#26862;&#26519;&#27169;&#22411;&#26469;&#20272;&#35745;&#22522;&#32452;&#22823;&#23567;&#20851;&#20110;&#20840;&#25910;&#25947;&#35745;&#31639;&#30340;&#24635;&#33021;&#37327;&#20462;&#27491;&#12290;&#35813;&#38543;&#26426;&#26862;&#26519;&#27169;&#22411;&#23545;&#20110;&#20004;&#31181;&#20195;&#30721;&#37117;&#23454;&#29616;&#20102;&#23567;&#20110;25%&#30340;&#23545;&#31216;&#24179;&#22343;&#32477;&#23545;&#30334;&#20998;&#27604;&#35823;&#24046;&#65292;&#32780;&#19988;&#32988;&#36807;&#20102;&#25991;&#29486;&#20013;&#20043;&#21069;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36824;&#25552;&#20379;&#20102;&#39044;&#27979;&#21306;&#38388;&#65292;&#21487;&#20197;&#37327;&#21270;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The numerical precision of density-functional-theory (DFT) calculations depends on a variety of computational parameters, one of the most critical being the basis-set size. The ultimate precision is reached with an infinitely large basis set, i.e., in the limit of a complete basis set (CBS). Our aim in this work is to find a machine-learning model that extrapolates finite basis-size calculations to the CBS limit. We start with a data set of 63 binary solids investigated with two all-electron DFT codes, exciting and FHI-aims, which employ very different types of basis sets. A quantile-random-forest model is used to estimate the total-energy correction with respect to a fully converged calculation as a function of the basis-set size. The random-forest model achieves a symmetric mean absolute percentage error of lower than 25% for both codes and outperforms previous approaches in the literature. Our approach also provides prediction intervals, which quantify the uncertainty of the models'
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992;&#24067;&#38647;-&#29926;&#29791;&#26031;&#22374;&#36317;&#31163;&#35757;&#32451;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#28145;&#24230;&#30697;&#38453;&#20998;&#35299;&#27169;&#22411;&#65292;&#24182;&#22312;&#26377;&#38480;&#31209;&#30697;&#38453;&#31354;&#38388;&#20869;&#34920;&#24449;&#20851;&#38190;&#28857;&#21644;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#26368;&#32456;&#30830;&#23450;&#20102;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.03027</link><description>&lt;p&gt;
&#24067;&#38647;-&#29926;&#29791;&#26031;&#22374;&#36317;&#31163;&#35757;&#32451;&#19979;&#30340;&#29983;&#25104;&#24335;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#30340;&#20851;&#38190;&#28857;&#21644;&#25910;&#25947;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Critical Points and Convergence Analysis of Generative Deep Linear Networks Trained with Bures-Wasserstein Loss. (arXiv:2303.03027v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.03027
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#24067;&#38647;-&#29926;&#29791;&#26031;&#22374;&#36317;&#31163;&#35757;&#32451;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#28145;&#24230;&#30697;&#38453;&#20998;&#35299;&#27169;&#22411;&#65292;&#24182;&#22312;&#26377;&#38480;&#31209;&#30697;&#38453;&#31354;&#38388;&#20869;&#34920;&#24449;&#20851;&#38190;&#28857;&#21644;&#26368;&#23567;&#21270;&#38382;&#39064;&#65292;&#26368;&#32456;&#30830;&#23450;&#20102;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#19968;&#31181;&#20351;&#29992;&#24067;&#38647;-&#29926;&#29791;&#26031;&#22374;&#36317;&#31163;&#35757;&#32451;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#28145;&#24230;&#30697;&#38453;&#20998;&#35299;&#27169;&#22411;&#12290;&#30456;&#36739;&#20110;&#20197;&#24448;&#30340;&#30740;&#31350;&#65292;&#25105;&#20204;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#22312;&#25439;&#22833;&#20989;&#25968;&#21644;&#29983;&#25104;&#24335;&#35774;&#32622;&#19978;&#26377;&#25152;&#19981;&#21516;&#12290;&#25105;&#20204;&#22312;&#26377;&#38480;&#31209;&#30697;&#38453;&#31354;&#38388;&#20869;&#34920;&#24449;&#20102;&#35813;&#26041;&#27861;&#30340;&#20851;&#38190;&#28857;&#21644;&#26368;&#23567;&#21270;&#38382;&#39064;&#12290;&#38024;&#23545;&#20302;&#31209;&#30697;&#38453;&#32780;&#35328;&#65292;&#35813;&#26041;&#27861;&#30340;&#28023;&#26862;&#30697;&#38453;&#29702;&#35770;&#19978;&#21487;&#33021;&#20250;&#29190;&#28856;&#65292;&#36825;&#20026;&#20248;&#21270;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#20998;&#26512;&#24102;&#26469;&#20102;&#25361;&#25112;&#12290;&#25105;&#20204;&#30830;&#23450;&#20102;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#20013;&#20351;&#29992;&#25439;&#22833;&#30340;&#24179;&#28369;&#24494;&#25200;&#29256;&#26412;&#26102;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#22312;&#21021;&#22987;&#26435;&#37325;&#30340;&#19968;&#23450;&#20551;&#35774;&#26465;&#20214;&#19979;&#35777;&#26126;&#20102;&#26377;&#38480;&#27493;&#38271;&#26799;&#24230;&#19979;&#38477;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a deep matrix factorization model of covariance matrices trained with the Bures-Wasserstein distance. While recent works have made important advances in the study of the optimization problem for overparametrized low-rank matrix approximation, much emphasis has been placed on discriminative settings and the square loss. In contrast, our model considers another interesting type of loss and connects with the generative setting. We characterize the critical points and minimizers of the Bures-Wasserstein distance over the space of rank-bounded matrices. For low-rank matrices the Hessian of this loss can theoretically blow up, which creates challenges to analyze convergence of optimizaton methods. We establish convergence results for gradient flow using a smooth perturbative version of the loss and convergence results for finite step size gradient descent under certain assumptions on the initial weights.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#25512;&#24191;&#24179;&#22343;Lipschitz&#24179;&#28369;&#24615;&#21040;H&#246;lder&#24179;&#28369;&#24615;&#65292;&#24471;&#21040;&#20102;&#20851;&#20110;&#24179;&#22343;H&#246;lder&#24179;&#28369;&#24615;&#30340;&#19978;&#19979;&#39118;&#38505;&#30028;&#65292;&#26368;&#20248;&#30340;&#19979;&#30028;&#23545;&#25968;&#22240;&#23376;&#26368;&#22810;&#24046;&#19968;&#20010;&#65292;&#25552;&#20379;&#20102;&#29420;&#31435;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2302.06005</link><description>&lt;p&gt;
&#24179;&#22343;H&#246;lder&#24179;&#28369;&#24230;&#19979;&#30340;&#36817;&#20284;&#26368;&#20248;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Near-optimal learning with average H\"older smoothness. (arXiv:2302.06005v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.06005
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25512;&#24191;&#24179;&#22343;Lipschitz&#24179;&#28369;&#24615;&#21040;H&#246;lder&#24179;&#28369;&#24615;&#65292;&#24471;&#21040;&#20102;&#20851;&#20110;&#24179;&#22343;H&#246;lder&#24179;&#28369;&#24615;&#30340;&#19978;&#19979;&#39118;&#38505;&#30028;&#65292;&#26368;&#20248;&#30340;&#19979;&#30028;&#23545;&#25968;&#22240;&#23376;&#26368;&#22810;&#24046;&#19968;&#20010;&#65292;&#25552;&#20379;&#20102;&#29420;&#31435;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23558;Ashlagi&#31561;&#20154;&#65288;COLT 2021&#65289;&#25552;&#20986;&#30340;&#24179;&#22343;Lipschitz&#24179;&#28369;&#24615;&#27010;&#24565;&#25512;&#24191;&#21040;H&#246;lder&#24179;&#28369;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#20851;&#20110;&#24179;&#22343;H&#246;lder&#24179;&#28369;&#24615;&#30340;&#19978;&#19979;&#39118;&#38505;&#30028;&#65292;&#36825;&#20123;&#30028;&#30340;&#36895;&#29575;&#29978;&#33267;&#22312;&#24179;&#22343;Lipschitz&#24179;&#28369;&#24615;&#30340;&#29305;&#27530;&#24773;&#20917;&#19979;&#20063;&#20248;&#20110;&#20043;&#21069;&#24050;&#30693;&#30028;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#19979;&#30028;&#22312;&#21487;&#23454;&#29616;&#24773;&#20917;&#19979;&#26159;&#26368;&#20248;&#30340;&#65292;&#26368;&#22810;&#24046;&#19968;&#20010;&#23545;&#25968;&#22240;&#23376;&#65292;&#20174;&#32780;&#24314;&#31435;&#20102;&#26497;&#23567;&#20540;&#29575;&#12290;&#20174;&#31639;&#27861;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#30001;&#20110;&#25105;&#20204;&#23545;&#24179;&#22343;&#24179;&#28369;&#24230;&#30340;&#23450;&#20041;&#26159;&#38024;&#23545;&#26410;&#30693;&#30340;&#22522;&#30784;&#20998;&#24067;&#30340;&#65292;&#22240;&#27492;&#23398;&#20064;&#32773;&#27809;&#26377;&#20989;&#25968;&#31867;&#30340;&#26174;&#24335;&#34920;&#31034;&#65292;&#26080;&#27861;&#25191;&#34892;ERM&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#29420;&#31435;&#30340;&#23398;&#20064;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We generalize the notion of average Lipschitz smoothness proposed by Ashlagi et al. (COLT 2021) by extending it to H\"older smoothness. This measure of the "effective smoothness" of a function is sensitive to the underlying distribution and can be dramatically smaller than its classic "worst-case H\"older constant. We consider both the realizable and the agnostic (noisy) regression settings, proving upper and lower risk bounds in terms of the average H\"older smoothness; these rates improve upon both previously known rates even in the special case of average Lipschitz smoothness. Moreover, our lower bound is tight in the realizable setting up to log factors, thus we establish the minimax rate. From an algorithmic perspective, since our notion of average smoothness is defined with respect to the unknown underlying distribution, the learner does not have an explicit representation of the function class, hence is unable to execute ERM. Nevertheless, we provide distinct learning algorithms
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#20998;&#26512;&#25968;&#25454;&#22686;&#24378;&#12289;&#32593;&#32476;&#26550;&#26500;&#21644;&#35757;&#32451;&#31639;&#27861;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#30740;&#31350;&#20102;&#39044;&#35757;&#32451;&#21644;&#19979;&#28216;&#20219;&#21153;&#30340;&#27867;&#21270;&#24615;&#33021;&#65292;&#24182;&#20026;SSL&#20174;&#19994;&#20154;&#21592;&#25552;&#20379;&#20102;&#19968;&#20123;&#35265;&#35299;&#12290;</title><link>http://arxiv.org/abs/2302.02774</link><description>&lt;p&gt;
SSL&#30340;&#30456;&#20114;&#20316;&#29992;&#65306;&#22686;&#24378;&#12289;&#24402;&#32435;&#20559;&#24046;&#21644;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
The SSL Interplay: Augmentations, Inductive Bias, and Generalization. (arXiv:2302.02774v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.02774
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#20998;&#26512;&#25968;&#25454;&#22686;&#24378;&#12289;&#32593;&#32476;&#26550;&#26500;&#21644;&#35757;&#32451;&#31639;&#27861;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#30740;&#31350;&#20102;&#39044;&#35757;&#32451;&#21644;&#19979;&#28216;&#20219;&#21153;&#30340;&#27867;&#21270;&#24615;&#33021;&#65292;&#24182;&#20026;SSL&#20174;&#19994;&#20154;&#21592;&#25552;&#20379;&#20102;&#19968;&#20123;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#30417;&#30563;&#23398;&#20064;&#65288;SSL&#65289;&#24050;&#25104;&#20026;&#19968;&#31181;&#26080;&#38656;&#30417;&#30563;&#21363;&#21487;&#20174;&#21407;&#22987;&#25968;&#25454;&#20013;&#23398;&#20064;&#34920;&#31034;&#30340;&#24378;&#22823;&#26694;&#26550;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#36341;&#20013;&#65292;&#24037;&#31243;&#24072;&#38754;&#20020;&#30528;&#35843;&#25972;&#20248;&#21270;&#22120;&#21644;&#35757;&#32451;&#36807;&#31243;&#20013;&#34920;&#31034;&#22604;&#38519;&#31561;&#38382;&#39064;&#12290;&#36825;&#20123;&#25361;&#25112;&#20419;&#20351;&#25105;&#20204;&#38656;&#35201;&#19968;&#31181;&#29702;&#35770;&#26469;&#38416;&#26126;&#25968;&#25454;&#22686;&#24378;&#12289;&#32593;&#32476;&#26550;&#26500;&#21644;&#35757;&#32451;&#31639;&#27861;&#30340;&#36873;&#25321;&#20043;&#38388;&#30340;&#22797;&#26434;&#30456;&#20114;&#20316;&#29992;&#12290;&#25105;&#20204;&#22312;&#19968;&#20010;&#29702;&#35770;&#21451;&#22909;&#30340;&#35774;&#32622;&#19979;&#65292;&#36890;&#36807;&#23545;&#39044;&#35757;&#32451;&#21644;&#19979;&#28216;&#20219;&#21153;&#30340;&#27867;&#21270;&#24615;&#33021;&#36827;&#34892;&#31934;&#30830;&#20998;&#26512;&#65292;&#30740;&#31350;&#20102;&#36825;&#31181;&#30456;&#20114;&#20316;&#29992;&#65292;&#24182;&#24378;&#35843;&#20102;&#25105;&#20204;&#29702;&#35770;&#24471;&#20986;&#30340;SSL&#20174;&#19994;&#32773;&#30340;&#19968;&#20123;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Self-supervised learning (SSL) has emerged as a powerful framework to learn representations from raw data without supervision. Yet in practice, engineers face issues such as instability in tuning optimizers and collapse of representations during training. Such challenges motivate the need for a theory to shed light on the complex interplay between the choice of data augmentation, network architecture, and training algorithm. We study such an interplay with a precise analysis of generalization performance on both pretraining and downstream tasks in a theory friendly setup, and highlight several insights for SSL practitioners that arise from our theory.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25913;&#36827;&#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#22810;&#26102;&#26399;&#22810;&#20998;&#31867;&#35013;&#36733;&#38382;&#39064;&#65292;&#20854;&#20013;&#20351;&#29992;bandit&#21453;&#39304;&#65292;&#25552;&#20986;&#30340;&#31639;&#27861;&#20855;&#26377;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#29575;&#21644;&#26356;&#20302;&#30340;&#36951;&#25022;&#65292;&#21516;&#26102;&#35299;&#20915;&#20102;&#19968;&#20010;&#30456;&#20851;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2301.13791</link><description>&lt;p&gt;
&#25913;&#36827;&#30340;&#22810;&#26102;&#26399;&#22810;&#20998;&#31867;&#35013;&#36733;&#38382;&#39064;&#31639;&#27861;&#65292;&#21516;&#26102;&#24102;&#26377;bandit&#21453;&#39304;
&lt;/p&gt;
&lt;p&gt;
Improved Algorithms for Multi-period Multi-class Packing Problems with Bandit Feedback. (arXiv:2301.13791v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.13791
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25913;&#36827;&#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#22810;&#26102;&#26399;&#22810;&#20998;&#31867;&#35013;&#36733;&#38382;&#39064;&#65292;&#20854;&#20013;&#20351;&#29992;bandit&#21453;&#39304;&#65292;&#25552;&#20986;&#30340;&#31639;&#27861;&#20855;&#26377;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#29575;&#21644;&#26356;&#20302;&#30340;&#36951;&#25022;&#65292;&#21516;&#26102;&#35299;&#20915;&#20102;&#19968;&#20010;&#30456;&#20851;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#32447;&#24615;&#32972;&#26223;&#19979;&#30340;&#22810;&#31867;&#22810;&#26399;&#35013;&#36733;&#38382;&#39064;&#65288;LMMP&#65289;&#65292;&#23427;&#30340;&#30446;&#26631;&#26159;&#23558;&#29289;&#21697;&#35013;&#36733;&#21040;&#39044;&#31639;&#21521;&#37327;&#19979;&#65292;&#24182;&#20351;&#24635;&#20215;&#20540;&#23613;&#21487;&#33021;&#22823;&#12290;&#25105;&#20204;&#32771;&#34385;&#30340;&#24773;&#20917;&#26159;&#65292;&#19982;&#27599;&#20010;&#25805;&#20316;&#30456;&#20851;&#32852;&#30340;&#22870;&#21169;&#21644;&#28040;&#32791;&#21521;&#37327;&#26159;&#19978;&#19979;&#25991;&#30456;&#20851;&#30340;&#32447;&#24615;&#20989;&#25968;&#65292;&#24182;&#19988;&#20915;&#31574;&#32773;&#24471;&#21040;&#20102;bandit&#21453;&#39304;&#12290;&#24403;&#39044;&#31639;&#33267;&#23569;&#22686;&#38271;&#20026;$ \sqrt{T}$&#26102;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38381;&#21512;&#24418;&#24335;&#30340;bandit&#31574;&#30053;&#65292;&#36825;&#26679;&#21487;&#20197;&#22312;&#19978;&#19979;&#25991;&#32500;&#24230;&#65292;&#20998;&#31867;&#25968;&#21644;&#26102;&#38388;&#33539;&#22260;$T$&#19979;&#20445;&#25345;&#27425;&#32447;&#24615;&#30340;&#36951;&#25022;&#12290;&#25105;&#20204;&#36824;&#35299;&#20915;&#20102;Agrawal&#65286;Goyal&#65288;2018&#65289;&#22312;LCBK&#38382;&#39064;&#20013;&#25552;&#20986;&#30340;&#19968;&#20010;&#24320;&#25918;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#20197;&#33719;&#24471;&#26356;&#24555;&#25910;&#25947;&#36895;&#29575;&#30340;&#26032;&#30340;&#20272;&#35745;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the linear contextual multi-class multi-period packing problem (LMMP) where the goal is to pack items such that the total vector of consumption is below a given budget vector and the total value is as large as possible. We consider the setting where the reward and the consumption vector associated with each action is a class-dependent linear function of the context, and the decision-maker receives bandit feedback. LMMP includes linear contextual bandits with knapsacks and online revenue management as special cases. We establish a new estimator which guarantees a faster convergence rate, and consequently, a lower regret in such problems. We propose a bandit policy that is a closed-form function of said estimated parameters. When the contexts are non-degenerate, the regret of the proposed policy is sublinear in the context dimension, the number of classes, and the time horizon $T$ when the budget grows at least as $\sqrt{T}$. We also resolve an open problem posed by Agrawal &amp;
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30828;&#24065;&#25237;&#27880;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#65292;&#23436;&#20840;&#19981;&#38656;&#35201;&#23398;&#20064;&#36895;&#29575;&#65292;&#21487;&#20197;&#22312;&#39640;&#32500;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#19982;&#20854;&#20182;&#26041;&#27861;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2301.11294</link><description>&lt;p&gt;
&#22522;&#20110;&#30828;&#24065;&#37319;&#26679;&#30340;&#26080;&#38656;&#23398;&#20064;&#36895;&#29575;&#30340;&#22522;&#20110;&#26799;&#24230;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Coin Sampling: Gradient-Based Bayesian Inference without Learning Rates. (arXiv:2301.11294v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11294
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30828;&#24065;&#25237;&#27880;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#65292;&#23436;&#20840;&#19981;&#38656;&#35201;&#23398;&#20064;&#36895;&#29575;&#65292;&#21487;&#20197;&#22312;&#39640;&#32500;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#19978;&#34920;&#29616;&#20986;&#19982;&#20854;&#20182;&#26041;&#27861;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22522;&#20110;&#31890;&#23376;&#30340;&#21464;&#20998;&#25512;&#26029;&#65288;ParVI&#65289;&#26041;&#27861;&#22914;Stein&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;&#65288;SVGD&#65289;&#22240;&#21487;&#25193;&#23637;&#24615;&#22312;&#36125;&#21494;&#26031;&#25512;&#29702;&#20013;&#36234;&#26469;&#36234;&#21463;&#27426;&#36814;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#30340;&#24615;&#36136;&#19981;&#21487;&#36991;&#20813;&#22320;&#21462;&#20915;&#20110;&#36229;&#21442;&#25968;&#65288;&#22914;&#23398;&#20064;&#36895;&#29575;&#65289;&#65292;&#24517;&#39035;&#30001;&#20174;&#19994;&#32773;&#20180;&#32454;&#35843;&#25972;&#65292;&#20197;&#30830;&#20445;&#20197;&#21512;&#36866;&#30340;&#36895;&#29575;&#25910;&#25947;&#21040;&#30446;&#26631;&#27979;&#24230;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#32452;&#26032;&#30340;&#22522;&#20110;&#30828;&#24065;&#25237;&#27880;&#30340;&#21487;&#25193;&#23637;&#36125;&#21494;&#26031;&#25512;&#26029;&#26041;&#27861;&#65292;&#36825;&#20123;&#26041;&#27861;&#23436;&#20840;&#19981;&#38656;&#35201;&#23398;&#20064;&#36895;&#29575;&#12290;&#25105;&#20204;&#22312;&#19968;&#31995;&#21015;&#25968;&#20540;&#20363;&#23376;&#20013;&#28436;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#24615;&#33021;&#65292;&#21253;&#25324;&#20960;&#20010;&#39640;&#32500;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#65292;&#35777;&#26126;&#20102;&#19982;&#20854;&#20182;ParVI&#31639;&#27861;&#30456;&#24403;&#30340;&#24615;&#33021;&#65292;&#32780;&#26080;&#38656;&#35843;&#25972;&#23398;&#20064;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, particle-based variational inference (ParVI) methods such as Stein variational gradient descent (SVGD) have grown in popularity as scalable methods for Bayesian inference. Unfortunately, the properties of such methods invariably depend on hyperparameters such as the learning rate, which must be carefully tuned by the practitioner in order to ensure convergence to the target measure at a suitable rate. In this paper, we introduce a suite of new particle-based methods for scalable Bayesian inference based on coin betting, which are entirely learning-rate free. We illustrate the performance of our approach on a range of numerical examples, including several high-dimensional models and datasets, demonstrating comparable performance to other ParVI algorithms with no need to tune a learning rate.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20379;&#20102;&#24102;&#26377;&#20154;&#31867;&#21453;&#39304;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#35777;&#26126;&#20102;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22312;Bradley-Terry-Luce&#21644;Plackett-Luce&#27169;&#22411;&#19979;&#25910;&#25947;&#12290;&#27492;&#22806;&#65292;&#25552;&#20986;&#20102;&#22312;&#19968;&#23450;&#30340;&#35206;&#30422;&#20551;&#35774;&#19979;&#65292;&#22522;&#20110;&#24754;&#35266;&#20272;&#35745;&#30340;MLE&#25552;&#20379;&#20102;&#24615;&#33021;&#26356;&#22909;&#30340;&#31574;&#30053;&#12290;&#22312;&#35777;&#26126;&#20102;&#30495;&#23454;MLE&#21644;&#20197;&#25104;&#23545;&#27604;&#36739;&#24418;&#24335;&#26367;&#20195;&#30340;&#22791;&#36873;MLE&#37117;&#21487;&#20197;&#22312;PL&#27169;&#22411;&#19979;&#25910;&#25947;&#30340;&#21516;&#26102;&#65292;&#20063;&#34920;&#26126;&#20102;&#30495;&#23454;MLE&#30340;&#39640;&#25928;&#24615;&#12290;&#36825;&#20123;&#32467;&#26524;&#20026;RLHF&#31639;&#27861;&#25552;&#20379;&#20102;&#26032;&#30340;&#35265;&#35299;&#65292;&#24182;&#32479;&#19968;&#20102;RLHF&#38382;&#39064;&#21644;IRL&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2301.11270</link><description>&lt;p&gt;
&#20351;&#29992;&#26469;&#33258;&#25104;&#23545;&#25110;$K$&#20803;&#27604;&#36739;&#30340;&#20154;&#31867;&#21453;&#39304;&#30340;&#35268;&#33539;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Principled Reinforcement Learning with Human Feedback from Pairwise or $K$-wise Comparisons. (arXiv:2301.11270v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11270
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20379;&#20102;&#24102;&#26377;&#20154;&#31867;&#21453;&#39304;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#35777;&#26126;&#20102;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22312;Bradley-Terry-Luce&#21644;Plackett-Luce&#27169;&#22411;&#19979;&#25910;&#25947;&#12290;&#27492;&#22806;&#65292;&#25552;&#20986;&#20102;&#22312;&#19968;&#23450;&#30340;&#35206;&#30422;&#20551;&#35774;&#19979;&#65292;&#22522;&#20110;&#24754;&#35266;&#20272;&#35745;&#30340;MLE&#25552;&#20379;&#20102;&#24615;&#33021;&#26356;&#22909;&#30340;&#31574;&#30053;&#12290;&#22312;&#35777;&#26126;&#20102;&#30495;&#23454;MLE&#21644;&#20197;&#25104;&#23545;&#27604;&#36739;&#24418;&#24335;&#26367;&#20195;&#30340;&#22791;&#36873;MLE&#37117;&#21487;&#20197;&#22312;PL&#27169;&#22411;&#19979;&#25910;&#25947;&#30340;&#21516;&#26102;&#65292;&#20063;&#34920;&#26126;&#20102;&#30495;&#23454;MLE&#30340;&#39640;&#25928;&#24615;&#12290;&#36825;&#20123;&#32467;&#26524;&#20026;RLHF&#31639;&#27861;&#25552;&#20379;&#20102;&#26032;&#30340;&#35265;&#35299;&#65292;&#24182;&#32479;&#19968;&#20102;RLHF&#38382;&#39064;&#21644;IRL&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20026;&#24102;&#26377;&#20154;&#31867;&#21453;&#39304;&#30340;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#25552;&#20379;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#24403;&#30495;&#23454;&#22870;&#21169;&#20989;&#25968;&#20026;&#32447;&#24615;&#20989;&#25968;&#26102;&#65292;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#65288;MLE&#65289;&#22312;Bradley-Terry-Luce&#65288;BTL&#65289;&#27169;&#22411;&#21644;Plackett-Luce&#65288;PL&#65289;&#27169;&#22411;&#19979;&#22343;&#25910;&#25947;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#21457;&#29616;&#24403;&#22522;&#20110;&#23398;&#24471;&#30340;&#22870;&#21169;&#27169;&#22411;&#35757;&#32451;&#31574;&#30053;&#26102;&#65292;MLE&#20250;&#22833;&#36133;&#65292;&#32780;&#22522;&#20110;&#24754;&#35266;&#20272;&#35745;&#30340;MLE&#22312;&#19968;&#23450;&#30340;&#35206;&#30422;&#20551;&#35774;&#19979;&#25552;&#20379;&#24615;&#33021;&#26356;&#22909;&#30340;&#31574;&#30053;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;PL&#27169;&#22411;&#19979;&#65292;&#30495;&#23454;MLE&#21644;&#23558;$k$&#20803;&#27604;&#36739;&#25286;&#20998;&#20026;&#25104;&#23545;&#27604;&#36739;&#30340;&#22791;&#36873;MLE&#37117;&#25910;&#25947;&#12290;&#32780;&#30495;&#23454;MLE&#26159;&#28176;&#36817;&#26356;&#20026;&#39640;&#25928;&#30340;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#39564;&#35777;&#20102;&#29616;&#26377;RLHF&#31639;&#27861;&#65288;&#22914;InstructGPT&#65289;&#30340;&#23454;&#39564;&#25104;&#21151;&#65292;&#24182;&#20026;&#31639;&#27861;&#35774;&#35745;&#25552;&#20379;&#20102;&#26032;&#30340;&#35265;&#35299;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#32479;&#19968;&#20102;RLHF&#38382;&#39064;&#21644;&#26368;&#22823;&#29109;&#21453;&#21521;&#24378;&#21270;&#23398;&#20064;(IRL)&#38382;&#39064;&#65292;&#24182;&#20026;&#20854;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
We provide a theoretical framework for Reinforcement Learning with Human Feedback (RLHF). Our analysis shows that when the true reward function is linear, the widely used maximum likelihood estimator (MLE) converges under both the Bradley-Terry-Luce (BTL) model and the Plackett-Luce (PL) model. However, we show that when training a policy based on the learned reward model, MLE fails while a pessimistic MLE provides policies with improved performance under certain coverage assumptions. Additionally, we demonstrate that under the PL model, the true MLE and an alternative MLE that splits the $K$-wise comparison into pairwise comparisons both converge. Moreover, the true MLE is asymptotically more efficient. Our results validate the empirical success of existing RLHF algorithms in InstructGPT and provide new insights for algorithm design. Furthermore, our results unify the problem of RLHF and max-entropy Inverse Reinforcement Learning (IRL), and provide the first sample complexity bound fo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;GNTK&#21644;&#22270;&#26680;&#20989;&#25968;&#25506;&#31350;&#22823;&#35268;&#27169;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#21160;&#24577;&#65292;&#35777;&#26126;&#20102;GNTK&#22312;&#25910;&#25947;&#20110;&#22270;&#26680;&#20989;&#25968;&#26102;&#30340;&#30830;&#20999;&#24615;&#36136;&#12290;&#36825;&#24847;&#21619;&#30528;&#22312;&#22823;&#35268;&#27169;&#22270;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#22312;&#20013;&#31561;&#22823;&#23567;&#30340;&#22270;&#19978;&#36827;&#34892;&#25311;&#21512;&#24182;&#22312;&#25972;&#20010;&#22270;&#19978;&#20351;&#29992;&#12290;</title><link>http://arxiv.org/abs/2301.10808</link><description>&lt;p&gt;
&#22270;&#31070;&#32463;&#20999;&#27604;&#38634;&#22827;&#26680;&#65306;&#22823;&#35268;&#27169;&#22270;&#19978;&#30340;&#25910;&#25947;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Tangent Kernel: Convergence on Large Graphs. (arXiv:2301.10808v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.10808
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;GNTK&#21644;&#22270;&#26680;&#20989;&#25968;&#25506;&#31350;&#22823;&#35268;&#27169;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#21160;&#24577;&#65292;&#35777;&#26126;&#20102;GNTK&#22312;&#25910;&#25947;&#20110;&#22270;&#26680;&#20989;&#25968;&#26102;&#30340;&#30830;&#20999;&#24615;&#36136;&#12290;&#36825;&#24847;&#21619;&#30528;&#22312;&#22823;&#35268;&#27169;&#22270;&#30340;&#24773;&#20917;&#19979;&#65292;&#21487;&#20197;&#22312;&#20013;&#31561;&#22823;&#23567;&#30340;&#22270;&#19978;&#36827;&#34892;&#25311;&#21512;&#24182;&#22312;&#25972;&#20010;&#22270;&#19978;&#20351;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#22270;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#20294;&#22312;&#22823;&#35268;&#27169;&#22270;&#25968;&#25454;&#19978;&#35757;&#32451;&#26102;&#24448;&#24448;&#27604;&#36739;&#22256;&#38590;&#65292;&#22240;&#20026;&#23427;&#20204;&#30340;&#23398;&#20064;&#21160;&#24577;&#38590;&#20197;&#29702;&#35299;&#12290;&#26412;&#25991;&#21033;&#29992;&#22270;&#31070;&#32463;&#20999;&#27604;&#38634;&#22827;&#26680;&#65288;GNTK&#65289;&#21644;&#22270;&#26680;&#20989;&#25968;&#25506;&#31350;&#22823;&#35268;&#27169;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#35757;&#32451;&#21160;&#24577;&#12290;&#22312;&#23485;&#24230;&#36235;&#20110;&#26080;&#31351;&#22823;&#26102;&#65292;&#36807;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#30340;&#20248;&#21270;&#31561;&#20215;&#20110;&#22312;NTK&#19978;&#36827;&#34892;&#26680;&#22238;&#24402;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;GNTK&#22312;&#21478;&#19968;&#20010;&#29420;&#31435;&#30340;&#32500;&#24230;&#65288;&#22270;&#22823;&#23567;&#65289;&#21464;&#21270;&#26102;&#30340;&#28436;&#21270;&#24773;&#20917;&#65292;&#24182;&#20351;&#29992;&#22270;&#26680;&#20989;&#25968;&#26469;&#23450;&#20041;&#26497;&#38480;&#23545;&#35937;&#8212;&#8212;GNN&#30340;&#22270;&#26680;&#20989;&#25968;&#21644;GNTK&#30340;&#22270;&#26680;&#20989;&#25968;&#65292;&#24182;&#35777;&#26126;&#65292;&#22312;&#19968;&#31995;&#21015;&#22270;&#19978;&#65292;GNTK&#25910;&#25947;&#20110;&#22270;&#26680;&#20989;&#25968;&#12290;&#36827;&#19968;&#27493;&#35777;&#26126;&#20102;GNTK&#30340;&#35889;&#20381;&#36182;&#20110;&#26368;&#24555;&#23398;&#20064;&#30340;&#26041;&#21521;&#65292;&#36825;&#22312;&#26089;&#26399;&#20572;&#27490;&#35757;&#32451;&#26102;&#21464;&#24471;&#29305;&#21035;&#37325;&#35201;&#65292;&#35889;&#20063;&#25910;&#25947;&#20110;&#22270;&#26680;&#20989;&#25968;&#30340;&#35889;&#12290;&#36825;&#24847;&#21619;&#30528;&#22312;&#22823;&#35268;&#27169;&#22270;&#30340;&#38480;&#21046;&#19979;&#65292;&#23545;&#20013;&#31561;&#22823;&#23567;&#30340;&#22270;&#36827;&#34892;&#25311;&#21512;&#30340;GNTK&#21487;&#20197;&#29992;&#20110;&#22312;&#22270;&#19978;&#36827;&#34892;&#25311;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph neural networks (GNNs) achieve remarkable performance in graph machine learning tasks but can be hard to train on large-graph data, where their learning dynamics are not well understood. We investigate the training dynamics of large-graph GNNs using graph neural tangent kernels (GNTKs) and graphons. In the limit of large width, optimization of an overparametrized NN is equivalent to kernel regression on the NTK. Here, we investigate how the GNTK evolves as another independent dimension is varied: the graph size. We use graphons to define limit objects -- graphon NNs for GNNs, and graphon NTKs for GNTKs -- , and prove that, on a sequence of graphs, the GNTKs converge to the graphon NTK. We further prove that the spectrum of the GNTK, which is related to the directions of fastest learning which becomes relevant during early stopping, converges to the spectrum of the graphon NTK. This implies that in the large-graph limit, the GNTK fitted on a graph of moderate size can be used to s
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;$\mathsf{READ}$&#30340;&#26032;&#30340;&#33945;&#29305;&#21345;&#32599;&#20272;&#35745;&#22120;&#65292;&#20855;&#26377;&#27599;&#20010;&#22266;&#23450;$D$&#30340;&#26368;&#20248;&#35745;&#31639;&#25104;&#26412;$\mathcal{O}(\varepsilon^{-2})$&#20197;&#21450;&#22312;&#26356;&#19968;&#33324;&#30340;&#20551;&#35774;&#19979;&#65292;&#20219;&#24847;$0 &lt; \delta &lt; \frac{1}{2}$&#20960;&#20046;&#26368;&#20248;&#30340;&#35745;&#31639;&#25104;&#26412;$\mathcal{O}(\varepsilon^{-2(1 + \delta)})$&#12290;</title><link>http://arxiv.org/abs/2301.04095</link><description>&lt;p&gt;
&#37325;&#22797;&#23884;&#22871;&#26399;&#26395;&#30340;&#26368;&#20248;&#38543;&#26426;&#22810;&#23618;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Optimal randomized multilevel Monte Carlo for repeatedly nested expectations. (arXiv:2301.04095v3 [stat.CO] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.04095
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;$\mathsf{READ}$&#30340;&#26032;&#30340;&#33945;&#29305;&#21345;&#32599;&#20272;&#35745;&#22120;&#65292;&#20855;&#26377;&#27599;&#20010;&#22266;&#23450;$D$&#30340;&#26368;&#20248;&#35745;&#31639;&#25104;&#26412;$\mathcal{O}(\varepsilon^{-2})$&#20197;&#21450;&#22312;&#26356;&#19968;&#33324;&#30340;&#20551;&#35774;&#19979;&#65292;&#20219;&#24847;$0 &lt; \delta &lt; \frac{1}{2}$&#20960;&#20046;&#26368;&#20248;&#30340;&#35745;&#31639;&#25104;&#26412;$\mathcal{O}(\varepsilon^{-2(1 + \delta)})$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#29616;&#23454;&#19990;&#30028;&#30340;&#31995;&#32479;&#20013;&#65292;&#37325;&#22797;&#23884;&#22871;&#26399;&#26395;&#30340;&#20272;&#35745;&#26159;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#24403;&#23884;&#22871;&#25968;&#30446;&#21464;&#24471;&#24456;&#22823;&#26102;&#65292;&#29616;&#26377;&#30340;&#26041;&#27861;&#36890;&#24120;&#20250;&#36973;&#21463;&#39640;&#35745;&#31639;&#25104;&#26412;&#30340;&#22256;&#25200;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33945;&#29305;&#21345;&#32599;&#20272;&#35745;&#22120;$\mathsf{READ}$&#65292;&#23427;&#20855;&#26377;&#27599;&#20010;&#22266;&#23450;$D$&#30340;&#26368;&#20248;&#35745;&#31639;&#25104;&#26412;$\mathcal{O}(\varepsilon^{-2})$&#20197;&#21450;&#22312;&#26356;&#19968;&#33324;&#30340;&#20551;&#35774;&#19979;&#65292;&#20219;&#24847;$0 &lt; \delta &lt; \frac{1}{2}$&#20960;&#20046;&#26368;&#20248;&#30340;&#35745;&#31639;&#25104;&#26412;$\mathcal{O}(\varepsilon^{-2(1 + \delta)})$&#12290;
&lt;/p&gt;
&lt;p&gt;
The estimation of repeatedly nested expectations is a challenging task that arises in many real-world systems. However, existing methods generally suffer from high computational costs when the number of nestings becomes large. Fix any non-negative integer $D$ for the total number of nestings. Standard Monte Carlo methods typically cost at least $\mathcal{O}(\varepsilon^{-(2+D)})$ and sometimes $\mathcal{O}(\varepsilon^{-2(1+D)})$ to obtain an estimator up to $\varepsilon$-error. More advanced methods, such as multilevel Monte Carlo, currently only exist for $D = 1$. In this paper, we propose a novel Monte Carlo estimator called $\mathsf{READ}$, which stands for "Recursive Estimator for Arbitrary Depth.'' Our estimator has an optimal computational cost of $\mathcal{O}(\varepsilon^{-2})$ for every fixed $D$ under suitable assumptions, and a nearly optimal computational cost of $\mathcal{O}(\varepsilon^{-2(1 + \delta)})$ for any $0 &lt; \delta &lt; \frac12$ under much more general assumptions. 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22312;&#32431;&#21644;&#36817;&#20284;&#24046;&#20998;&#38544;&#31169;&#27169;&#22411;&#19979;&#65292;&#23545;&#20110;&#26410;&#30693;&#30340; $d$ &#32500;&#39640;&#26031;&#20998;&#24067;&#36827;&#34892;&#20219;&#24847;&#24494;&#23567;&#24046;&#24322;&#24635;&#21464;&#24046;&#35823;&#24046;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#24182;&#23481;&#24525;&#24694;&#24847;&#31163;&#32676;&#20540;&#30340;&#23384;&#22312;&#65292; &#26679;&#26412;&#22797;&#26434;&#24230;&#19982;&#32500;&#24230;&#30340;&#20381;&#36182;&#26159;&#26368;&#20248;&#30340;&#65307;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#26679;&#26412;&#19978;&#30028;&#19982;&#30446;&#26631;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#26465;&#20214;&#25968; $\kappa$ &#30340;&#20381;&#36182;&#20851;&#31995;&#20063;&#26159;&#26368;&#32039;&#23494;&#30340;&#12290;</title><link>http://arxiv.org/abs/2212.08018</link><description>&lt;p&gt;
&#31169;&#19979;&#39640;&#25928;&#12289;&#40065;&#26834;&#19988;&#26368;&#20248;&#22320;&#20272;&#35745;&#39640;&#26031;&#20998;&#24067;
&lt;/p&gt;
&lt;p&gt;
Privately Estimating a Gaussian: Efficient, Robust and Optimal. (arXiv:2212.08018v2 [cs.DS] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.08018
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#22312;&#32431;&#21644;&#36817;&#20284;&#24046;&#20998;&#38544;&#31169;&#27169;&#22411;&#19979;&#65292;&#23545;&#20110;&#26410;&#30693;&#30340; $d$ &#32500;&#39640;&#26031;&#20998;&#24067;&#36827;&#34892;&#20219;&#24847;&#24494;&#23567;&#24046;&#24322;&#24635;&#21464;&#24046;&#35823;&#24046;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#24182;&#23481;&#24525;&#24694;&#24847;&#31163;&#32676;&#20540;&#30340;&#23384;&#22312;&#65292; &#26679;&#26412;&#22797;&#26434;&#24230;&#19982;&#32500;&#24230;&#30340;&#20381;&#36182;&#26159;&#26368;&#20248;&#30340;&#65307;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#26679;&#26412;&#19978;&#30028;&#19982;&#30446;&#26631;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#26465;&#20214;&#25968; $\kappa$ &#30340;&#20381;&#36182;&#20851;&#31995;&#20063;&#26159;&#26368;&#32039;&#23494;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#32431;&#21644;&#36817;&#20284;&#24046;&#20998;&#38544;&#31169;&#27169;&#22411;&#19979;&#65292;&#38024;&#23545;&#39640;&#26031;&#20998;&#24067;&#30340;&#39640;&#25928;&#31639;&#27861;&#65292;&#24182;&#19988;&#26679;&#26412;&#22797;&#26434;&#24230;&#19982;&#32500;&#24230;&#30340;&#20381;&#36182;&#26159;&#26368;&#20248;&#30340;&#12290;&#22312;&#32431;&#24046;&#20998;&#38544;&#31169;&#35774;&#32622;&#19979;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#31639;&#27861;&#65292;&#20351;&#29992; $\widetilde{O}(d^2 \log \kappa)$ &#20010;&#26679;&#26412;&#65292;&#21487;&#20197;&#23545;&#26410;&#30693;&#30340; $d$ &#32500;&#39640;&#26031;&#20998;&#24067;&#36827;&#34892;&#20219;&#24847;&#24494;&#23567;&#24046;&#24322;&#24635;&#21464;&#24046;&#35823;&#24046;&#30340;&#20272;&#35745;&#65292;&#21516;&#26102;&#23481;&#24525;&#24694;&#24847;&#31163;&#32676;&#20540;&#30340;&#23384;&#22312;&#12290;&#36825;&#37324;&#65292;$\kappa$ &#26159;&#30446;&#26631;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#26465;&#20214;&#25968;&#12290;&#35813;&#26679;&#26412;&#19978;&#30028;&#22312;&#32500;&#24230;&#65288;&#22810;&#23545;&#25968;&#22240;&#23376;&#65289;&#30340;&#20381;&#36182;&#19978;&#19982;&#26368;&#20339;&#38750;&#38544;&#31169;&#20272;&#35745;&#22120;&#30456;&#21305;&#37197;, &#25105;&#20204;&#35777;&#26126;&#20102;&#38544;&#31169;&#21327;&#26041;&#24046;&#30697;&#38453;&#20272;&#35745;&#30340;&#19968;&#20010;&#26032;&#30340;&#19979;&#30028;&#65292;&#20026;&#20102;&#34920;&#26126;&#19978;&#25991;&#26679;&#26412;&#19978;&#30028;&#19982;&#30446;&#26631;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#26465;&#20214;&#25968; $\kappa$ &#30340;&#20381;&#36182;&#20851;&#31995;&#20063;&#26159;&#26368;&#32039;&#23494;&#30340;&#12290;&#22312;&#26412;&#24037;&#20316;&#20043;&#21069;&#65292;&#25105;&#20497;&#21482;&#30693;&#36947;&#35813;&#38382;&#39064;&#30340;&#21487;&#35782;&#21035;&#24615;&#32467;&#26524;&#65288;&#23548;&#33268;&#38750;&#24120;&#20302;&#25928;&#30340;&#36229;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we give efficient algorithms for privately estimating a Gaussian distribution in both pure and approximate differential privacy (DP) models with optimal dependence on the dimension in the sample complexity. In the pure DP setting, we give an efficient algorithm that estimates an unknown $d$-dimensional Gaussian distribution up to an arbitrary tiny total variation error using $\widetilde{O}(d^2 \log \kappa)$ samples while tolerating a constant fraction of adversarial outliers. Here, $\kappa$ is the condition number of the target covariance matrix. The sample bound matches best non-private estimators in the dependence on the dimension (up to a polylogarithmic factor). We prove a new lower bound on differentially private covariance estimation to show that the dependence on the condition number $\kappa$ in the above sample bound is also tight. Prior to our work, only identifiability results (yielding inefficient super-polynomial time algorithms) were known for the problem. In
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#20998;&#24067;&#21452;&#20998;&#22359;&#28151;&#21512;&#25104;&#21592;&#27169;&#22411;&#65288;BiMMDF&#65289;&#65292;&#21487;&#29992;&#20110;&#37325;&#21472;&#21452;&#20998;&#22359;&#21152;&#26435;&#32593;&#32476;&#30340;&#31038;&#21306;&#21457;&#29616;&#65292;&#24182;&#21487;&#20197;&#27169;&#25311;&#37325;&#21472;&#21452;&#20998;&#22359;&#31526;&#21495;&#32593;&#32476;&#12290;&#35813;&#27169;&#22411;&#30340;&#20272;&#35745;&#20855;&#26377;&#19968;&#33268;&#24615;&#20445;&#35777;&#21644;&#29702;&#35770;&#20998;&#31163;&#26465;&#20214;&#65292;&#24182;&#21487;&#25552;&#39640;&#22312;&#21512;&#25104;&#32593;&#32476;&#21644;&#29616;&#23454;&#32593;&#32476;&#24212;&#29992;&#20013;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2211.00912</link><description>&lt;p&gt;
&#26080;&#20998;&#24067;&#21452;&#20998;&#22359;&#28151;&#21512;&#25104;&#21592;&#27169;&#22411;&#65306;&#19968;&#31181;&#26032;&#30340;&#29992;&#20110;&#37325;&#21472;&#21452;&#20998;&#22359;&#21152;&#26435;&#32593;&#32476;&#31038;&#21306;&#21457;&#29616;&#30340;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Bipartite Mixed Membership Distribution-Free Model. A novel model for community detection in overlapping bipartite weighted networks. (arXiv:2211.00912v2 [cs.SI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.00912
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#20998;&#24067;&#21452;&#20998;&#22359;&#28151;&#21512;&#25104;&#21592;&#27169;&#22411;&#65288;BiMMDF&#65289;&#65292;&#21487;&#29992;&#20110;&#37325;&#21472;&#21452;&#20998;&#22359;&#21152;&#26435;&#32593;&#32476;&#30340;&#31038;&#21306;&#21457;&#29616;&#65292;&#24182;&#21487;&#20197;&#27169;&#25311;&#37325;&#21472;&#21452;&#20998;&#22359;&#31526;&#21495;&#32593;&#32476;&#12290;&#35813;&#27169;&#22411;&#30340;&#20272;&#35745;&#20855;&#26377;&#19968;&#33268;&#24615;&#20445;&#35777;&#21644;&#29702;&#35770;&#20998;&#31163;&#26465;&#20214;&#65292;&#24182;&#21487;&#25552;&#39640;&#22312;&#21512;&#25104;&#32593;&#32476;&#21644;&#29616;&#23454;&#32593;&#32476;&#24212;&#29992;&#20013;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#23545;&#20110;&#37325;&#21472;&#21333;&#20998;&#22359;&#26080;&#26435;&#37325;&#32593;&#32476;&#30340;&#28151;&#21512;&#25104;&#21592;&#24314;&#27169;&#21644;&#20272;&#35745;&#24050;&#32463;&#24471;&#21040;&#20102;&#24191;&#27867;&#30340;&#30740;&#31350;&#12290;&#28982;&#32780;&#65292;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#27809;&#26377;&#27169;&#22411;&#36866;&#29992;&#20110;&#26356;&#19968;&#33324;&#30340;&#24773;&#20917;&#65292;&#21363;&#37325;&#21472;&#21452;&#20998;&#22359;&#21152;&#26435;&#32593;&#32476;&#12290;&#20026;&#20102;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;&#65292;&#21363;&#26080;&#20998;&#24067;&#21452;&#20998;&#22359;&#28151;&#21512;&#25104;&#21592;&#27169;&#22411;&#65288;BiMMDF&#65289;&#12290;&#25105;&#20204;&#30340;&#27169;&#22411;&#20801;&#35768;&#37051;&#25509;&#30697;&#38453;&#36981;&#24490;&#20219;&#20309;&#20998;&#24067;&#65292;&#21482;&#35201;&#20854;&#26399;&#26395;&#20855;&#26377;&#19982;&#33410;&#28857;&#25104;&#21592;&#26377;&#20851;&#30340;&#22359;&#32467;&#26500;&#21363;&#21487;&#12290;&#29305;&#21035;&#22320;&#65292;BiMMDF&#21487;&#20197;&#27169;&#25311;&#37325;&#21472;&#21452;&#20998;&#22359;&#31526;&#21495;&#32593;&#32476;&#65292;&#24182;&#19988;&#26159;&#35768;&#22810;&#20808;&#21069;&#27169;&#22411;&#30340;&#25193;&#23637;&#65292;&#21253;&#25324;&#27969;&#34892;&#30340;&#28151;&#21512;&#25104;&#21592;&#38543;&#26426;&#22359;&#27169;&#22411;&#12290;&#25105;&#20204;&#24212;&#29992;&#20855;&#26377;&#19968;&#33268;&#20272;&#35745;&#29702;&#35770;&#20445;&#35777;&#30340;&#39640;&#25928;&#31639;&#27861;&#26469;&#25311;&#21512;BiMMDF&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#25506;&#35752;&#20102;&#19981;&#21516;&#20998;&#24067;&#30340;BiMMDF&#30340;&#20998;&#31163;&#26465;&#20214;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#32771;&#34385;&#20102;&#31232;&#30095;&#32593;&#32476;&#30340;&#32570;&#22833;&#36793;&#32536;&#12290;BiMMDF&#30340;&#20248;&#21183;&#22312;&#24191;&#27867;&#30340;&#21512;&#25104;&#32593;&#32476;&#21644;&#29616;&#23454;&#32593;&#32476;&#24212;&#29992;&#20013;&#24471;&#21040;&#20102;&#23637;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modeling and estimating mixed memberships for overlapping unipartite un-weighted networks has been well studied in recent years. However, to our knowledge, there is no model for a more general case, the overlapping bipartite weighted networks. To close this gap, we introduce a novel model, the Bipartite Mixed Membership Distribution-Free (BiMMDF) model. Our model allows an adjacency matrix to follow any distribution as long as its expectation has a block structure related to node membership. In particular, BiMMDF can model overlapping bipartite signed networks and it is an extension of many previous models, including the popular mixed membership stochastic blcokmodels. An efficient algorithm with a theoretical guarantee of consistent estimation is applied to fit BiMMDF. We then obtain the separation conditions of BiMMDF for different distributions. Furthermore, we also consider missing edges for sparse networks. The advantage of BiMMDF is demonstrated in extensive synthetic networks an
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#31456;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#26415;&#37319;&#26679;&#26694;&#26550;&#65292;&#35813;&#26041;&#27861;&#21487;&#20860;&#23481;&#24120;&#35265;&#30340;&#37319;&#26679;&#21464;&#21270;&#65292;&#20855;&#26377;&#21487;&#35777;&#26126;&#30340;&#26463;&#22810;&#26679;&#24615;&#21644;&#20196;&#20154;&#23604;&#23596;&#30340;&#24182;&#34892;&#24615;&#65292;&#20174;&#21407;&#22987;&#27169;&#22411;&#25552;&#20379;&#26080;&#20559;&#21644;&#19968;&#33268;&#30340;&#26399;&#26395;&#12290;&#22312;WMT&#26426;&#22120;&#32763;&#35793;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2210.15458</link><description>&lt;p&gt;
&#31639;&#26415;&#37319;&#26679;&#65306;&#29992;&#20110;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24182;&#34892;&#22810;&#26679;&#21270;&#35299;&#30721;
&lt;/p&gt;
&lt;p&gt;
Arithmetic Sampling: Parallel Diverse Decoding for Large Language Models. (arXiv:2210.15458v2 [cs.CL] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.15458
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#31456;&#25552;&#20986;&#20102;&#19968;&#31181;&#31639;&#26415;&#37319;&#26679;&#26694;&#26550;&#65292;&#35813;&#26041;&#27861;&#21487;&#20860;&#23481;&#24120;&#35265;&#30340;&#37319;&#26679;&#21464;&#21270;&#65292;&#20855;&#26377;&#21487;&#35777;&#26126;&#30340;&#26463;&#22810;&#26679;&#24615;&#21644;&#20196;&#20154;&#23604;&#23596;&#30340;&#24182;&#34892;&#24615;&#65292;&#20174;&#21407;&#22987;&#27169;&#22411;&#25552;&#20379;&#26080;&#20559;&#21644;&#19968;&#33268;&#30340;&#26399;&#26395;&#12290;&#22312;WMT&#26426;&#22120;&#32763;&#35793;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#35299;&#30721;&#26041;&#27861;&#36890;&#24120;&#22312;&#36755;&#20986;&#22810;&#26679;&#24615;&#21644;&#35745;&#31639;&#24182;&#34892;&#24615;&#20043;&#38388;&#36827;&#34892;&#26435;&#34913;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26694;&#26550;&#65292;&#26681;&#25454;&#30001;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#38544;&#24335;&#23450;&#20041;&#30340;&#31639;&#26415;&#20195;&#30721;&#20070;&#36827;&#34892;&#37319;&#26679;&#65292;&#20860;&#23481;&#24120;&#35265;&#30340;&#37319;&#26679;&#21464;&#21270;&#65292;&#28385;&#36275;&#19968;&#23450;&#26465;&#20214;&#19979;&#30340;&#21487;&#35777;&#26126;&#30340;&#26463;&#22810;&#26679;&#24615;&#65292;&#21516;&#26102;&#20855;&#26377;&#20196;&#20154;&#23604;&#23596;&#30340;&#24182;&#34892;&#24615;&#65292;&#24182;&#20174;&#21407;&#22987;&#27169;&#22411;&#25552;&#20379;&#26080;&#20559;&#21644;&#19968;&#33268;&#30340;&#26399;&#26395;&#12290;&#25105;&#20204;&#22312;WMT&#26426;&#22120;&#32763;&#35793;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65292;&#23558;&#39044;&#26399;&#30340;BLEU&#20998;&#25968;&#22870;&#21169;&#30340;&#26631;&#20934;&#24046;&#20943;&#23569;&#20102;&#19968;&#21322;&#20197;&#19978;&#65292;&#21516;&#26102;&#19982;&#20808;&#21069;&#30340;&#26368;&#26032;&#26041;&#27861;&#26377;&#20102;&#30456;&#24403;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Decoding methods for large language models often trade-off between diversity of outputs and parallelism of computation. Methods such as beam search and Gumbel top-k sampling can guarantee a different output for each element of the beam, but are not easy to parallelize. Alternatively, methods such as temperature sampling and its modifications (top-k sampling, nucleus sampling, typical decoding, and others), are embarrassingly parallel, but have no guarantees about duplicate samples. We present a framework for sampling according to an arithmetic code book implicitly defined by a large language model, compatible with common sampling variations, with provable beam diversity under certain conditions, as well as being embarrassingly parallel and providing unbiased and consistent expectations from the original model. We demonstrate the effectiveness of our approach on WMT machine translation, more than halving the standard deviation when estimating expected BLEU score reward, and closing the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20013;&#28857; Mixup &#30340;&#22810;&#35270;&#35282;&#25968;&#25454;&#23398;&#20064;&#26041;&#27861;&#65292;&#30456;&#27604;&#20110;&#20256;&#32479;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#26041;&#27861;&#33021;&#22815;&#26356;&#22909;&#22320;&#23398;&#20064;&#27599;&#20010;&#31867;&#21035;&#30340;&#25152;&#26377;&#29305;&#24449;&#65292;&#20855;&#26377;&#26356;&#22909;&#30340;&#27867;&#21270;&#21644;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2210.13512</link><description>&lt;p&gt;
&#29992;&#20013;&#28857; Mixup &#22312;&#22810;&#35270;&#35282;&#25968;&#25454;&#20013;&#21487;&#35777;&#26126;&#23398;&#20064;&#22810;&#20803;&#29305;&#24449;
&lt;/p&gt;
&lt;p&gt;
Provably Learning Diverse Features in Multi-View Data with Midpoint Mixup. (arXiv:2210.13512v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.13512
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20013;&#28857; Mixup &#30340;&#22810;&#35270;&#35282;&#25968;&#25454;&#23398;&#20064;&#26041;&#27861;&#65292;&#30456;&#27604;&#20110;&#20256;&#32479;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#26041;&#27861;&#33021;&#22815;&#26356;&#22909;&#22320;&#23398;&#20064;&#27599;&#20010;&#31867;&#21035;&#30340;&#25152;&#26377;&#29305;&#24449;&#65292;&#20855;&#26377;&#26356;&#22909;&#30340;&#27867;&#21270;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Mixup &#26159;&#19968;&#31181;&#25968;&#25454;&#22686;&#24378;&#25216;&#26415;&#65292;&#20381;&#36182;&#20110;&#20351;&#29992;&#25968;&#25454;&#28857;&#21644;&#26631;&#31614;&#30340;&#38543;&#26426;&#20984;&#32452;&#21512;&#36827;&#34892;&#35757;&#32451;&#12290;&#36817;&#24180;&#26469;&#65292;Mixup &#24050;&#25104;&#20026;&#35757;&#32451;&#26368;&#20808;&#36827;&#30340;&#22270;&#20687;&#20998;&#31867;&#27169;&#22411;&#30340;&#26631;&#20934;&#22522;&#20803;&#65292;&#22240;&#20026;&#23427;&#22312;&#27867;&#21270;&#21644;&#40065;&#26834;&#24615;&#26041;&#38754;&#27604;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#26377;&#26126;&#26174;&#30340;&#20248;&#21183;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35797;&#22270;&#20174;&#29305;&#24449;&#23398;&#20064;&#30340;&#35282;&#24230;&#35299;&#37322;&#19968;&#20123;&#36825;&#31181;&#25104;&#21151;&#12290;&#25105;&#20204;&#20851;&#27880;&#30340;&#20998;&#31867;&#38382;&#39064;&#26159;&#65292;&#27599;&#20010;&#31867;&#21035;&#21487;&#33021;&#20855;&#26377;&#22810;&#20010;&#30456;&#20851;&#29305;&#24449;&#65288;&#25110;&#35270;&#22270;&#65289;&#65292;&#21487;&#29992;&#20110;&#27491;&#30830;&#39044;&#27979;&#31867;&#21035;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#29702;&#35770;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#20855;&#26377;&#27599;&#31867;&#20004;&#20010;&#29305;&#24449;&#30340;&#19968;&#31867;&#38750;&#24179;&#20961;&#25968;&#25454;&#20998;&#24067;&#20013;&#65292;&#20351;&#29992;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#35757;&#32451; 2 &#23618;&#21367;&#31215;&#32593;&#32476;&#21487;&#33021;&#20250;&#23548;&#33268;&#20960;&#20046;&#25152;&#26377;&#31867;&#21035;&#21482;&#23398;&#20064;&#19968;&#20010;&#29305;&#24449;&#65292;&#32780;&#20351;&#29992; Mixup &#30340;&#29305;&#23450;&#23454;&#20363;&#36827;&#34892;&#35757;&#32451;&#21487;&#20197;&#25104;&#21151;&#22320;&#23398;&#20064;&#27599;&#20010;&#31867;&#21035;&#30340;&#20004;&#20010;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;
Mixup is a data augmentation technique that relies on training using random convex combinations of data points and their labels. In recent years, Mixup has become a standard primitive used in the training of state-of-the-art image classification models due to its demonstrated benefits over empirical risk minimization with regards to generalization and robustness. In this work, we try to explain some of this success from a feature learning perspective. We focus our attention on classification problems in which each class may have multiple associated features (or views) that can be used to predict the class correctly. Our main theoretical results demonstrate that, for a non-trivial class of data distributions with two features per class, training a 2-layer convolutional network using empirical risk minimization can lead to learning only one feature for almost all classes while training with a specific instantiation of Mixup succeeds in learning both features for every class. We also show
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#24322;&#26041;&#24046;&#22122;&#22768;&#27169;&#22411;&#65292;&#21457;&#29616;&#38500;&#29305;&#27530;&#24773;&#20917;&#22806;&#22240;&#26524;&#26041;&#21521;&#26159;&#21487;&#35782;&#21035;&#30340;&#12290;&#25552;&#20986;&#20102;&#20004;&#20010;&#20272;&#35745;&#22120;&#65292;&#33021;&#22815;&#20934;&#30830;&#35782;&#21035;&#22240;&#26524;&#25928;&#24212;&#12290;</title><link>http://arxiv.org/abs/2210.09054</link><description>&lt;p&gt;
&#20851;&#20110;&#22240;&#26524;&#20301;&#32622;-&#23610;&#24230;&#22122;&#22768;&#27169;&#22411;&#30340;&#21487;&#35782;&#21035;&#24615;&#21644;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
On the Identifiability and Estimation of Causal Location-Scale Noise Models. (arXiv:2210.09054v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.09054
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#24322;&#26041;&#24046;&#22122;&#22768;&#27169;&#22411;&#65292;&#21457;&#29616;&#38500;&#29305;&#27530;&#24773;&#20917;&#22806;&#22240;&#26524;&#26041;&#21521;&#26159;&#21487;&#35782;&#21035;&#30340;&#12290;&#25552;&#20986;&#20102;&#20004;&#20010;&#20272;&#35745;&#22120;&#65292;&#33021;&#22815;&#20934;&#30830;&#35782;&#21035;&#22240;&#26524;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;&#20301;&#32622;-&#23610;&#24230;&#25110;&#24322;&#26041;&#24046;&#22122;&#22768;&#27169;&#22411;&#65288;LSNMs&#65289;&#65292;&#22312;&#20854;&#20013;&#65292;&#25928;&#24212;$ Y $&#21487;&#20197;&#34987;&#20889;&#25104;&#26159;&#22240;&#26524;$ X $&#21644;&#19982;$ X $&#26080;&#20851;&#30340;&#22122;&#22768;&#28304;$ N $&#30340;&#20989;&#25968;&#65292;&#20294;&#21487;&#33021;&#34987;&#22240;&#26524;$ X $&#32553;&#25918;&#20026;&#19968;&#20010;&#27491;&#20989;&#25968;$ g&#65288;X&#65289;$&#65292;&#21363;$ Y = f&#65288;X&#65289;+ g&#65288;X&#65289;N $&#12290;&#23613;&#31649;&#27169;&#22411;&#31867;&#21035;&#38750;&#24120;&#24191;&#27867;&#65292;&#20294;&#25105;&#20204;&#21457;&#29616;&#38500;&#19968;&#20123;&#29305;&#27530;&#24773;&#20917;&#22806;&#65292;&#22240;&#26524;&#26041;&#21521;&#26159;&#21487;&#35782;&#21035;&#30340;&#12290;&#20026;&#20102;&#22312;&#23454;&#35777;&#19978;&#39564;&#35777;&#36825;&#20123;&#29702;&#35770;&#21457;&#29616;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#20010;LSNMs&#30340;&#20272;&#35745;&#22120;&#65306;&#19968;&#20010;&#22522;&#20110;&#65288;&#38750;&#32447;&#24615;&#65289;&#29305;&#24449;&#26144;&#23556;&#30340;&#20272;&#35745;&#22120;&#21644;&#19968;&#20010;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#20272;&#35745;&#22120;&#12290;&#20004;&#32773;&#23558;$ Y $&#32473;&#23450;$ X $&#30340;&#26465;&#20214;&#20998;&#24067;&#24314;&#27169;&#20026;&#30001;&#20854;&#33258;&#28982;&#21442;&#25968;&#21442;&#25968;&#21270;&#30340;&#39640;&#26031;&#20998;&#24067;&#12290;&#24403;&#29305;&#24449;&#26144;&#23556;&#34987;&#27491;&#30830;&#35268;&#23450;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#25105;&#20204;&#30340;&#20272;&#35745;&#22120;&#26159;&#32852;&#21512;&#20984;&#30340;&#65292;&#24182;&#19988;&#26159;&#22240;&#26524;&#25928;&#24212;&#35782;&#21035;&#20219;&#21153;&#30340;&#19968;&#33268;&#20272;&#35745;&#22120;&#12290;&#23613;&#31649;&#31070;&#32463;&#32593;&#32476;&#27809;&#26377;&#32487;&#25215;&#36825;&#20123;&#20445;&#35777;&#65292;&#20294;&#23427;&#21487;&#20197;&#25311;&#21512;&#20219;&#24847;&#22797;&#26434;&#24615;&#30340;&#20989;&#25968;&#65292;&#24182;&#36798;&#21040;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the class of location-scale or heteroscedastic noise models (LSNMs), in which the effect $Y$ can be written as a function of the cause $X$ and a noise source $N$ independent of $X$, which may be scaled by a positive function $g$ over the cause, i.e., $Y = f(X) + g(X)N$. Despite the generality of the model class, we show the causal direction is identifiable up to some pathological cases. To empirically validate these theoretical findings, we propose two estimators for LSNMs: an estimator based on (non-linear) feature maps, and one based on neural networks. Both model the conditional distribution of $Y$ given $X$ as a Gaussian parameterized by its natural parameters. When the feature maps are correctly specified, we prove that our estimator is jointly concave, and a consistent estimator for the cause-effect identification task. Although the the neural network does not inherit those guarantees, it can fit functions of arbitrary complexity, and reaches state-of-the-art performance
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35299;&#20915;&#20102;&#26925;&#22278;&#25311;&#21512;&#38382;&#39064;&#30340;&#19968;&#20010;&#29468;&#24819;&#65292;&#23545;&#20110;&#32473;&#23450;&#39640;&#26031;&#28857;$v_1,\ldots,v_n$&#65292;&#25105;&#20204;&#21487;&#20197;&#26500;&#36896;&#20986;&#19968;&#20010;&#23545;&#31216;&#20110;&#21407;&#28857;&#30340;&#25311;&#21512;&#26925;&#22278;&#65292;&#24403;$n\geq \Omega(\,d^2/\mathrm{polylog}(d)\,)$&#26102;&#65292;&#35813;&#26925;&#22278;&#23454;&#29616;&#20102;&#36817;&#20284;&#26368;&#20248;&#21305;&#37197;&#12290;</title><link>http://arxiv.org/abs/2208.09493</link><description>&lt;p&gt;
&#38543;&#26426;&#28857;&#21040;&#26925;&#22278;&#30340;&#36817;&#20284;&#26368;&#20248;&#21305;&#37197;
&lt;/p&gt;
&lt;p&gt;
Near-optimal fitting of ellipsoids to random points. (arXiv:2208.09493v4 [cs.DS] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.09493
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#26925;&#22278;&#25311;&#21512;&#38382;&#39064;&#30340;&#19968;&#20010;&#29468;&#24819;&#65292;&#23545;&#20110;&#32473;&#23450;&#39640;&#26031;&#28857;$v_1,\ldots,v_n$&#65292;&#25105;&#20204;&#21487;&#20197;&#26500;&#36896;&#20986;&#19968;&#20010;&#23545;&#31216;&#20110;&#21407;&#28857;&#30340;&#25311;&#21512;&#26925;&#22278;&#65292;&#24403;$n\geq \Omega(\,d^2/\mathrm{polylog}(d)\,)$&#26102;&#65292;&#35813;&#26925;&#22278;&#23454;&#29616;&#20102;&#36817;&#20284;&#26368;&#20248;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32473;&#23450;&#32500;&#24230;&#20026;$d$&#30340;&#29420;&#31435;&#26631;&#20934;&#39640;&#26031;&#28857;$v_1,\ldots,v_n$&#65292;&#23545;&#20110;&#21738;&#20123;$(n,d)$&#20540;&#33539;&#22260;&#20869;&#65292;&#39640;&#27010;&#29575;&#23384;&#22312;&#19968;&#20010;&#23545;&#31216;&#20110;&#21407;&#28857;&#30340;&#26925;&#22278;&#65292;&#21487;&#20197;&#21516;&#26102;&#36890;&#36807;&#25152;&#26377;&#36825;&#20123;&#28857;&#65311;&#23558;&#26925;&#22278;&#36924;&#36817;&#38543;&#26426;&#28857;&#30340;&#36825;&#20010;&#22522;&#26412;&#38382;&#39064;&#19982;&#20302;&#31209;&#30697;&#38453;&#20998;&#35299;&#12289;&#29420;&#31435;&#25104;&#20998;&#20998;&#26512;&#21644;&#20027;&#25104;&#20998;&#20998;&#26512;&#26377;&#20851;&#12290;Saunderson&#65292;Parrilo&#21644;Willsky [&#20915;&#31574;&#19982;&#25511;&#21046;&#20250;&#35758;&#35770;&#25991;&#38598;&#65292;6031-6036&#39029;&#65292;2013]&#26681;&#25454;&#24378;&#26377;&#21147;&#30340;&#25968;&#20540;&#35777;&#25454;&#36827;&#34892;&#29468;&#27979;&#65292;&#24403;&#28857;&#25968;$n$&#22686;&#21152;&#26102;&#65292;&#26925;&#22278;&#25311;&#21512;&#38382;&#39064;&#20174;&#21487;&#34892;&#29366;&#24577;&#21464;&#20026;&#19981;&#21487;&#34892;&#29366;&#24577;&#65292;&#27492;&#26102;$n\sim d^2/4$&#26377;&#19968;&#20010;&#26126;&#26174;&#30340;&#20998;&#30028;&#28857;&#12290;&#25105;&#20204;&#36890;&#36807;&#26500;&#24314;&#19968;&#31181;&#25311;&#21512;&#26925;&#22278;&#26469;&#35299;&#20915;&#36825;&#20010;&#29468;&#24819;&#30340;&#27491;&#30830;&#24615;&#65292;&#24403;$n=\Omega(\,d^2/\mathrm{polylog}(d)\,)$&#26102;&#65292;&#21487;&#20197;&#23454;&#29616;&#36817;&#20284;&#26368;&#20248;&#21305;&#37197;&#65292;&#36825;&#27604;&#20043;&#21069;Ghosh&#31561;&#20154;[&#35745;&#31639;&#26426;&#31185;&#23398;&#22522;&#30784;&#30740;&#35752;&#20250;&#35770;&#25991;&#38598;&#65292;954-965&#39029;&#65292;2020]&#30340;&#24037;&#20316;&#38656;&#35201;&#26356;&#23569;&#30340;&#28857;&#25968;$n=o(d^{3/2})$&#12290;
&lt;/p&gt;
&lt;p&gt;
Given independent standard Gaussian points $v_1, \ldots, v_n$ in dimension $d$, for what values of $(n, d)$ does there exist with high probability an origin-symmetric ellipsoid that simultaneously passes through all of the points? This basic problem of fitting an ellipsoid to random points has connections to low-rank matrix decompositions, independent component analysis, and principal component analysis. Based on strong numerical evidence, Saunderson, Parrilo, and Willsky [Proc. of Conference on Decision and Control, pp. 6031-6036, 2013] conjecture that the ellipsoid fitting problem transitions from feasible to infeasible as the number of points $n$ increases, with a sharp threshold at $n \sim d^2/4$. We resolve this conjecture up to logarithmic factors by constructing a fitting ellipsoid for some $n = \Omega( \, d^2/\mathrm{polylog}(d) \,)$, improving prior work of Ghosh et al. [Proc. of Symposium on Foundations of Computer Science, pp. 954-965, 2020] that requires $n = o(d^{3/2})$. O
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#35777;&#26126;&#20102;&#25968;&#25454;&#19981;&#24179;&#34913;&#23545;&#23398;&#20064;&#30340;&#36127;&#38754;&#24433;&#21709;&#65292;&#35828;&#26126;&#22312;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#26102;&#65292;&#23569;&#25968;&#21644;&#22810;&#25968;&#31867;&#30340;&#23398;&#20064;&#26354;&#32447;&#20250;&#36981;&#24490;&#27425;&#20248;&#36712;&#36857;&#65292;&#21516;&#26102;&#25552;&#20986;&#23545;&#27599;&#31181;&#31867;&#21035;&#26799;&#24230;&#20570;&#20986;&#36129;&#29486;&#30340;&#24402;&#19968;&#21270;&#21464;&#20307;&#65292;&#20197;&#35299;&#20915;&#20248;&#21270;&#19981;&#21516;&#31867;&#21035;&#20043;&#38388;&#30340;&#31454;&#20105;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2207.00391</link><description>&lt;p&gt;
&#31867;&#21035;&#19981;&#24179;&#34913;&#19979;&#30340;&#23398;&#20064;&#21160;&#24577;&#29702;&#35770;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
A Theoretical Analysis of the Learning Dynamics under Class Imbalance. (arXiv:2207.00391v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.00391
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#35777;&#26126;&#20102;&#25968;&#25454;&#19981;&#24179;&#34913;&#23545;&#23398;&#20064;&#30340;&#36127;&#38754;&#24433;&#21709;&#65292;&#35828;&#26126;&#22312;&#20351;&#29992;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#26102;&#65292;&#23569;&#25968;&#21644;&#22810;&#25968;&#31867;&#30340;&#23398;&#20064;&#26354;&#32447;&#20250;&#36981;&#24490;&#27425;&#20248;&#36712;&#36857;&#65292;&#21516;&#26102;&#25552;&#20986;&#23545;&#27599;&#31181;&#31867;&#21035;&#26799;&#24230;&#20570;&#20986;&#36129;&#29486;&#30340;&#24402;&#19968;&#21270;&#21464;&#20307;&#65292;&#20197;&#35299;&#20915;&#20248;&#21270;&#19981;&#21516;&#31867;&#21035;&#20043;&#38388;&#30340;&#31454;&#20105;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#19981;&#24179;&#34913;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#24120;&#35265;&#30340;&#38382;&#39064;&#65292;&#20250;&#20005;&#37325;&#24433;&#21709;&#27169;&#22411;&#24615;&#33021;&#12290;&#34429;&#28982;&#26377;&#21508;&#31181;&#35299;&#20915;&#26041;&#26696;&#65292;&#20294;&#23427;&#20204;&#23545;&#23398;&#20064;&#21160;&#24577;&#30340;&#25910;&#25947;&#24433;&#21709;&#23578;&#26410;&#34987;&#29702;&#35299;&#12290;&#26412;&#25991;&#38416;&#26126;&#20102;&#25968;&#25454;&#19981;&#24179;&#34913;&#23545;&#23398;&#20064;&#30340;&#26174;&#33879;&#36127;&#38754;&#24433;&#21709;&#65292;&#24403;&#20351;&#29992;&#26799;&#24230;&#20248;&#21270;&#22120;&#36827;&#34892;&#35757;&#32451;&#26102;&#65292;&#23569;&#25968;&#31867;&#21644;&#22810;&#25968;&#31867;&#30340;&#23398;&#20064;&#26354;&#32447;&#20250;&#36981;&#24490;&#27425;&#20248;&#36712;&#36857;&#12290;&#36825;&#31181;&#25918;&#32531;&#19982;&#19981;&#24179;&#34913;&#27604;&#30456;&#20851;&#65292;&#21487;&#20197;&#36861;&#28335;&#21040;&#20248;&#21270;&#19981;&#21516;&#31867;&#21035;&#20043;&#38388;&#30340;&#31454;&#20105;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#22312;&#20110;&#20998;&#26512;&#20102;&#20840;&#25209;&#27425;&#65288;GD&#65289;&#21644;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#25910;&#25947;&#21644;&#21508;&#31181;&#23545;&#27599;&#31181;&#31867;&#21035;&#26799;&#24230;&#20570;&#20986;&#36129;&#29486;&#30340;&#24402;&#19968;&#21270;&#21464;&#20307;&#12290;&#25105;&#20204;&#21457;&#29616;GD&#19981;&#33021;&#20445;&#35777;&#38477;&#20302;&#27599;&#20010;&#31867;&#21035;&#30340;&#25439;&#22833;&#65292;&#20294;&#21487;&#20197;&#36890;&#36807;&#25191;&#34892;&#21508;&#33258;&#24402;&#19968;&#21270;&#26799;&#24230;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#20351;&#29992;SGD&#26102;, &#31867;&#21035;&#19981;&#24179;&#34913;&#20250;&#23545;&#31639;&#27861;&#20135;&#29983;&#39069;&#22806;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data imbalance is a common problem in machine learning that can have a critical effect on the performance of a model. Various solutions exist but their impact on the convergence of the learning dynamics is not understood. Here, we elucidate the significant negative impact of data imbalance on learning, showing that the learning curves for minority and majority classes follow sub-optimal trajectories when training with a gradient-based optimizer. This slowdown is related to the imbalance ratio and can be traced back to a competition between the optimization of different classes. Our main contribution is the analysis of the convergence of full-batch (GD) and stochastic gradient descent (SGD), and of variants that renormalize the contribution of each per-class gradient. We find that GD is not guaranteed to decrease the loss for each class but that this problem can be addressed by performing a per-class normalization of the gradient. With SGD, class imbalance has an additional effect on th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#20010;&#26032;&#30340;&#26041;&#27861;&#65292;&#32771;&#34385;&#28151;&#21512;&#36807;&#31243;&#30340;&#20551;&#35774;&#65292;&#21363;&#32467;&#26500;&#31232;&#30095;&#24615;&#65292;&#26469;&#23454;&#29616;&#38750;&#32447;&#24615;ICA&#30340;&#21487;&#35782;&#21035;&#24615;&#65292;&#26080;&#38656;&#36741;&#21161;&#21464;&#37327;&#12290;</title><link>http://arxiv.org/abs/2206.07751</link><description>&lt;p&gt;
&#38750;&#32447;&#24615;&#29420;&#31435;&#20998;&#37327;&#20998;&#26512;&#30340;&#21487;&#36776;&#35782;&#24615;&#65306;&#31232;&#30095;&#24615;&#21450;&#20854;&#23427;
&lt;/p&gt;
&lt;p&gt;
On the Identifiability of Nonlinear ICA: Sparsity and Beyond. (arXiv:2206.07751v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.07751
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#20010;&#26032;&#30340;&#26041;&#27861;&#65292;&#32771;&#34385;&#28151;&#21512;&#36807;&#31243;&#30340;&#20551;&#35774;&#65292;&#21363;&#32467;&#26500;&#31232;&#30095;&#24615;&#65292;&#26469;&#23454;&#29616;&#38750;&#32447;&#24615;ICA&#30340;&#21487;&#35782;&#21035;&#24615;&#65292;&#26080;&#38656;&#36741;&#21161;&#21464;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#32447;&#24615;&#29420;&#31435;&#20998;&#37327;&#20998;&#26512;&#26088;&#22312;&#20174;&#20854;&#21487;&#35266;&#27979;&#30340;&#38750;&#32447;&#24615;&#28151;&#21512;&#20013;&#24674;&#22797;&#20986;&#28508;&#22312;&#29420;&#31435;&#20998;&#37327;&#12290;&#22914;&#20309;&#20351;&#38750;&#32447;&#24615;ICA&#27169;&#22411;&#21487;&#36776;&#35782;&#30452;&#21040;&#26576;&#20123;&#24179;&#20961;&#19981;&#30830;&#23450;&#24615;&#26159;&#26080;&#30417;&#30563;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#38271;&#26399;&#38382;&#39064;&#12290;&#26368;&#36817;&#30340;&#31361;&#30772;&#26159;&#23558;&#28304;&#30340;&#26631;&#20934;&#29420;&#31435;&#24615;&#20551;&#35774;&#37325;&#26032;&#23450;&#20041;&#20026;&#22312;&#26576;&#20123;&#36741;&#21161;&#21464;&#37327;&#65288;&#20363;&#22914;&#31867;&#26631;&#31614;&#21644;/&#25110;&#22495;/&#26102;&#38388;&#32034;&#24341;&#65289;&#32473;&#23450;&#30340;&#26465;&#20214;&#29420;&#31435;&#24615;&#65292;&#20316;&#20026;&#24369;&#30417;&#30563;&#25110;&#24402;&#32435;&#20559;&#32622;&#12290;&#28982;&#32780;&#65292;&#20855;&#26377;&#26080;&#26465;&#20214;&#20808;&#39564;&#30340;&#38750;&#32447;&#24615;ICA&#26080;&#27861;&#20174;&#36825;&#20123;&#21457;&#23637;&#20013;&#21463;&#30410;&#12290;&#25105;&#20204;&#25506;&#32034;&#20102;&#19968;&#26465;&#26367;&#20195;&#36335;&#24452;&#65292;&#24182;&#20165;&#32771;&#34385;&#28151;&#21512;&#36807;&#31243;&#30340;&#20551;&#35774;&#65292;&#20363;&#22914;&#32467;&#26500;&#31232;&#30095;&#24615;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#36825;&#20123;&#32422;&#26463;&#30340;&#20855;&#20307;&#23454;&#20363;&#19979;&#65292;&#29420;&#31435;&#30340;&#28508;&#22312;&#20998;&#37327;&#21487;&#20197;&#20174;&#20854;&#38750;&#32447;&#24615;&#28151;&#21512;&#20013;&#36776;&#35782;&#20986;&#26469;&#65292;&#36798;&#21040;&#38750;&#24179;&#20961;&#30340;&#38750;&#32447;&#24615;ICA&#21487;&#35782;&#21035;&#24615;&#65292;&#32780;&#26080;&#38656;&#36741;&#21161;&#21464;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Nonlinear independent component analysis (ICA) aims to recover the underlying independent latent sources from their observable nonlinear mixtures. How to make the nonlinear ICA model identifiable up to certain trivial indeterminacies is a long-standing problem in unsupervised learning. Recent breakthroughs reformulate the standard independence assumption of sources as conditional independence given some auxiliary variables (e.g., class labels and/or domain/time indexes) as weak supervision or inductive bias. However, nonlinear ICA with unconditional priors cannot benefit from such developments. We explore an alternative path and consider only assumptions on the mixing process, such as Structural Sparsity. We show that under specific instantiations of such constraints, the independent latent sources can be identified from their nonlinear mixtures up to a permutation and a component-wise transformation, thus achieving nontrivial identifiability of nonlinear ICA without auxiliary variable
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23545;&#25239;&#35757;&#32451;&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#23481;&#26131;&#21463;&#21040;&#23545;&#25239;&#25915;&#20987;&#30340;&#25968;&#25454;&#19978;&#26045;&#21152;&#26356;&#22810;&#27491;&#21017;&#21270;&#20197;&#25552;&#39640;&#23545;&#25239;&#24615;&#40065;&#26834;&#24615;&#65292;&#24471;&#21040;&#20102;&#22312;&#20934;&#30830;&#24615;&#21644;&#40065;&#26834;&#24615;&#26041;&#38754;&#22343;&#20026;&#26368;&#20248;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2206.03353</link><description>&lt;p&gt;
&#22312;&#19981;&#31283;&#20581;&#26679;&#26412;&#19978;&#26045;&#21152;&#26356;&#22810;&#27491;&#21017;&#21270;&#20197;&#25552;&#39640;&#23545;&#25239;&#24615;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Improving adversarial robustness by putting more regularizations on less robust samples. (arXiv:2206.03353v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.03353
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23545;&#25239;&#35757;&#32451;&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#23481;&#26131;&#21463;&#21040;&#23545;&#25239;&#25915;&#20987;&#30340;&#25968;&#25454;&#19978;&#26045;&#21152;&#26356;&#22810;&#27491;&#21017;&#21270;&#20197;&#25552;&#39640;&#23545;&#25239;&#24615;&#40065;&#26834;&#24615;&#65292;&#24471;&#21040;&#20102;&#22312;&#20934;&#30830;&#24615;&#21644;&#40065;&#26834;&#24615;&#26041;&#38754;&#22343;&#20026;&#26368;&#20248;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#24615;&#35757;&#32451;&#26159;&#25552;&#39640;&#23545;&#25239;&#25915;&#20987;&#40065;&#26834;&#24615;&#30340;&#19968;&#31181;&#26041;&#27861;&#65292;&#22312;&#20154;&#31867;&#35270;&#35273;&#26080;&#27861;&#23519;&#35273;&#30340;&#25968;&#25454;&#25200;&#21160;&#19979;&#65292;&#20351;&#32473;&#23450;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20135;&#29983;&#35823;&#21028;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23545;&#25239;&#35757;&#32451;&#31639;&#27861;&#65292;&#23427;&#22312;&#29702;&#35770;&#19978;&#24471;&#21040;&#24456;&#22909;&#30340;&#35777;&#26126;&#65292;&#24182;&#19988;&#22312;&#23454;&#36341;&#20013;&#34920;&#29616;&#20248;&#20110;&#20854;&#20182;&#29616;&#26377;&#30340;&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#30340;&#19968;&#20010;&#26032;&#30340;&#29305;&#28857;&#26159;&#65306;&#23545;&#20110;&#23481;&#26131;&#21463;&#21040;&#23545;&#25239;&#25915;&#20987;&#30340;&#25968;&#25454;&#65292;&#27604;&#20854;&#20182;&#29616;&#26377;&#30340;&#27491;&#21017;&#21270;&#31639;&#27861;&#26356;&#22810;&#22320;&#24212;&#29992;&#27491;&#21017;&#21270;&#12290;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#21487;&#20197;&#34987;&#29702;&#35299;&#20026;&#19968;&#20010;&#26368;&#23567;&#21270;&#32463;&#39564;&#39118;&#38505;&#30340;&#27491;&#21017;&#21270;&#31639;&#27861;&#65292;&#23427;&#26469;&#33258;&#19968;&#20010;&#26032;&#30340;&#40065;&#26834;&#39118;&#38505;&#19978;&#30028;&#30340;&#21160;&#26426;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#21516;&#26102;&#25552;&#39640;&#20102;&#27867;&#21270;&#24615;&#33021;(&#22312;&#20363;&#23376;&#19978;&#30340;&#20934;&#30830;&#24615;)&#21644;&#40065;&#26834;&#24615;(&#22312;&#23545;&#25239;&#25915;&#20987;&#19978;&#30340;&#20934;&#30830;&#24615;)&#65292;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#27700;&#24179;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adversarial training, which is to enhance robustness against adversarial attacks, has received much attention because it is easy to generate human-imperceptible perturbations of data to deceive a given deep neural network. In this paper, we propose a new adversarial training algorithm that is theoretically well motivated and empirically superior to other existing algorithms. A novel feature of the proposed algorithm is to apply more regularization to data vulnerable to adversarial attacks than other existing regularization algorithms do. Theoretically, we show that our algorithm can be understood as an algorithm of minimizing the regularized empirical risk motivated from a newly derived upper bound of the robust risk. Numerical experiments illustrate that our proposed algorithm improves the generalization (accuracy on examples) and robustness (accuracy on adversarial attacks) simultaneously to achieve the state-of-the-art performance.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21333;&#26426;&#20316;&#19994;&#35843;&#24230;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23398;&#20064;&#39044;&#27979;&#30340;&#38745;&#24577;&#35843;&#24230;&#31639;&#27861;&#65292;&#22312;&#31867;&#22411;&#26410;&#30693;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#27425;&#32447;&#24615;&#30340;&#36807;&#21097;&#25104;&#26412;&#65292;&#23588;&#20854;&#22312;&#25250;&#21344;&#24335;&#38382;&#39064;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#21487;&#20197;&#22312;&#19981;&#21516;&#20316;&#19994;&#31867;&#22411;&#25345;&#32493;&#26102;&#38388;&#30456;&#24046;&#24456;&#22823;&#26102;&#20248;&#20110;&#38750;&#25250;&#21344;&#21305;&#37197;&#12290;</title><link>http://arxiv.org/abs/2205.15695</link><description>&lt;p&gt;
&#36890;&#36807;&#39640;&#25928;&#25506;&#32034;&#23398;&#20064;&#39044;&#27979;&#30340;&#38745;&#24577;&#35843;&#24230;
&lt;/p&gt;
&lt;p&gt;
Static Scheduling with Predictions Learned through Efficient Exploration. (arXiv:2205.15695v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.15695
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21333;&#26426;&#20316;&#19994;&#35843;&#24230;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23398;&#20064;&#39044;&#27979;&#30340;&#38745;&#24577;&#35843;&#24230;&#31639;&#27861;&#65292;&#22312;&#31867;&#22411;&#26410;&#30693;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#27425;&#32447;&#24615;&#30340;&#36807;&#21097;&#25104;&#26412;&#65292;&#23588;&#20854;&#22312;&#25250;&#21344;&#24335;&#38382;&#39064;&#20013;&#34920;&#29616;&#20986;&#33394;&#65292;&#21487;&#20197;&#22312;&#19981;&#21516;&#20316;&#19994;&#31867;&#22411;&#25345;&#32493;&#26102;&#38388;&#30456;&#24046;&#24456;&#22823;&#26102;&#20248;&#20110;&#38750;&#25250;&#21344;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#21333;&#26426;&#20316;&#19994;&#35843;&#24230;&#65292;&#27599;&#20010;&#20316;&#19994;&#37117;&#23646;&#20110;&#20915;&#23450;&#20854;&#25345;&#32493;&#26102;&#38388;&#20998;&#24067;&#30340;&#20316;&#19994;&#31867;&#22411;&#12290;&#25105;&#20204;&#39318;&#20808;&#20998;&#26512;&#20102;&#31867;&#22411;&#29305;&#24449;&#24050;&#30693;&#30340;&#24773;&#20917;&#65292;&#28982;&#21518;&#36716;&#21521;&#20004;&#31181;&#23398;&#20064;&#24773;&#26223;&#65292;&#20854;&#20013;&#31867;&#22411;&#26410;&#30693;&#65306;&#38750;&#25250;&#21344;&#24335;&#38382;&#39064;&#65292;&#23427;&#35201;&#27714;&#23436;&#25104;&#24050;&#21551;&#21160;&#30340;&#20316;&#19994;&#65292;&#28982;&#21518;&#25165;&#33021;&#31227;&#21160;&#21040;&#21478;&#19968;&#20010;&#20316;&#19994;&#65307;&#21644;&#25250;&#21344;&#24335;&#38382;&#39064;&#65292;&#36825;&#37324;&#20316;&#19994;&#25191;&#34892;&#21487;&#20197;&#26242;&#20572;&#20197;&#20248;&#20808;&#36716;&#31227;&#21040;&#21478;&#19968;&#20010;&#20316;&#19994;&#12290;&#22312;&#20004;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35774;&#35745;&#30340;&#31639;&#27861;&#30456;&#23545;&#20110;&#24050;&#30693;&#31867;&#22411;&#30340;&#24615;&#33021;&#23454;&#29616;&#20102;&#27425;&#32447;&#24615;&#30340;&#36807;&#21097;&#25104;&#26412;&#65292;&#24182;&#35777;&#26126;&#20102;&#38750;&#25250;&#21344;&#24335;&#24773;&#20917;&#30340;&#19979;&#38480;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25250;&#21344;&#31639;&#27861;&#22312;&#19981;&#21516;&#20316;&#19994;&#31867;&#22411;&#25345;&#32493;&#26102;&#38388;&#30456;&#24046;&#24456;&#22823;&#26102;&#65292;&#29702;&#35770;&#19978;&#21644;&#36890;&#36807;&#27169;&#25311;&#30340;&#26041;&#24335;&#21487;&#20197;&#20248;&#20110;&#38750;&#25250;&#21344;&#21305;&#37197;&#65292;&#22312;&#31867;&#22411;&#25345;&#32493;&#26102;&#38388;&#24050;&#30693;&#26102;&#24182;&#19981;&#23384;&#22312;&#36825;&#31181;&#29616;&#35937;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study single-machine scheduling of jobs, each belonging to a job type that determines its duration distribution. We start by analyzing the scenario where the type characteristics are known and then move to two learning scenarios where the types are unknown: non-preemptive problems, where each started job must be completed before moving to another job; and preemptive problems, where job execution can be paused in the favor of moving to a different job. In both cases, we design algorithms that achieve sublinear excess cost, compared to the performance with known types, and prove lower bounds for the non-preemptive case. Notably, we demonstrate, both theoretically and through simulations, how preemptive algorithms can greatly outperform non-preemptive ones when the durations of different job types are far from one another, a phenomenon that does not occur when the type durations are known.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#28151;&#21512;&#21464;&#20998;&#27969;&#65288;MixFlows&#65289;&#65292;&#26159;&#30001;&#23545;&#21021;&#22987;&#21442;&#32771;&#20998;&#24067;&#30340;&#26144;&#23556;&#37325;&#22797;&#24212;&#29992;&#30340;&#28151;&#21512;&#32452;&#25104;&#30340;&#19968;&#31181;&#26032;&#30340;&#21464;&#20998;&#23478;&#26063;&#12290;MixFlows&#20855;&#26377;&#31867;&#20284;&#20110;MCMC&#30340;&#25910;&#25947;&#20445;&#35777;&#65292;&#24182;&#21487;&#20197;&#25552;&#20379;&#27604;&#20960;&#31181;&#40657;&#30418;&#24402;&#19968;&#21270;&#27969;&#26356;&#21487;&#38752;&#30340;&#21518;&#39564;&#36924;&#36817;&#65292;&#19982;&#26368;&#20808;&#36827;&#30340;MCMC&#26041;&#27861;&#25152;&#33719;&#24471;&#30340;&#26679;&#26412;&#36136;&#37327;&#30456;&#24403;&#12290;</title><link>http://arxiv.org/abs/2205.07475</link><description>&lt;p&gt;
&#28151;&#21512;&#27969;&#65306;&#22522;&#20110;&#28151;&#21512;&#27969;&#30340;&#21407;&#21017;&#21464;&#20998;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
MixFlows: principled variational inference via mixed flows. (arXiv:2205.07475v5 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.07475
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#28151;&#21512;&#21464;&#20998;&#27969;&#65288;MixFlows&#65289;&#65292;&#26159;&#30001;&#23545;&#21021;&#22987;&#21442;&#32771;&#20998;&#24067;&#30340;&#26144;&#23556;&#37325;&#22797;&#24212;&#29992;&#30340;&#28151;&#21512;&#32452;&#25104;&#30340;&#19968;&#31181;&#26032;&#30340;&#21464;&#20998;&#23478;&#26063;&#12290;MixFlows&#20855;&#26377;&#31867;&#20284;&#20110;MCMC&#30340;&#25910;&#25947;&#20445;&#35777;&#65292;&#24182;&#21487;&#20197;&#25552;&#20379;&#27604;&#20960;&#31181;&#40657;&#30418;&#24402;&#19968;&#21270;&#27969;&#26356;&#21487;&#38752;&#30340;&#21518;&#39564;&#36924;&#36817;&#65292;&#19982;&#26368;&#20808;&#36827;&#30340;MCMC&#26041;&#27861;&#25152;&#33719;&#24471;&#30340;&#26679;&#26412;&#36136;&#37327;&#30456;&#24403;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#28151;&#21512;&#21464;&#20998;&#27969;&#65288;MixFlows&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#30340;&#21464;&#20998;&#23478;&#26063;&#65292;&#30001;&#23545;&#21021;&#22987;&#21442;&#32771;&#20998;&#24067;&#30340;&#26144;&#23556;&#37325;&#22797;&#24212;&#29992;&#30340;&#28151;&#21512;&#32452;&#25104;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#26377;&#25928;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;i.i.d.&#37319;&#26679;&#12289;&#23494;&#24230;&#35780;&#20272;&#21644;&#26080;&#20559;ELBO&#20272;&#35745;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#27969;&#26144;&#23556;&#26159;&#36941;&#21382;&#21644;&#20445;&#24230;&#37327;&#30340;&#26102;&#65292;MixFlows&#20855;&#26377;&#31867;&#20284;&#20110;MCMC&#30340;&#25910;&#25947;&#20445;&#35777;&#65292;&#24182;&#20026;&#27969;&#26144;&#23556;&#36817;&#20284;&#23454;&#29616;&#25552;&#20379;&#20102;&#35823;&#24046;&#31215;&#32047;&#30340;&#30028;&#38480;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#22522;&#20110;&#26410;&#32416;&#27491;&#30340;&#31163;&#25955;&#21704;&#23494;&#39039;&#21160;&#21147;&#23398;&#21644;&#30830;&#23450;&#24615;&#21160;&#37327;&#24674;&#22797;&#24320;&#21457;&#20102; MixFlows &#30340;&#23454;&#29616;&#12290;&#27169;&#25311;&#21644;&#23454;&#38469;&#25968;&#25454;&#23454;&#39564;&#34920;&#26126;&#65292;MixFlows&#21487;&#20197;&#25552;&#20379;&#27604;&#20960;&#31181;&#40657;&#30418;&#24402;&#19968;&#21270;&#27969;&#26356;&#21487;&#38752;&#30340;&#21518;&#39564;&#36924;&#36817;&#65292;&#20197;&#21450;&#19982;&#26368;&#20808;&#36827;&#30340;MCMC&#26041;&#27861;&#25152;&#33719;&#24471;&#30340;&#26679;&#26412;&#36136;&#37327;&#30456;&#24403;&#30340;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work presents mixed variational flows (MixFlows), a new variational family that consists of a mixture of repeated applications of a map to an initial reference distribution. First, we provide efficient algorithms for i.i.d. sampling, density evaluation, and unbiased ELBO estimation. We then show that MixFlows have MCMC-like convergence guarantees when the flow map is ergodic and measure-preserving, and provide bounds on the accumulation of error for practical implementations where the flow map is approximated. Finally, we develop an implementation of MixFlows based on uncorrected discretized Hamiltonian dynamics combined with deterministic momentum refreshment. Simulated and real data experiments show that MixFlows can provide more reliable posterior approximations than several black-box normalizing flows, as well as samples of comparable quality to those obtained from state-of-the-art MCMC methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20004;&#23618;&#27425;&#30340;&#31283;&#20581;&#24615;&#24459;&#27861;&#65292;&#30740;&#31350;&#20102;&#22312;&#20219;&#24847;&#25968;&#25454;&#20998;&#24067;&#19979;&#30340;&#31283;&#20581;&#25554;&#20540;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20854;Lipschitz&#19979;&#30028;&#20998;&#21035;&#20026;$\Omega(\sqrt{n/p})$&#21644;$\Omega(n^{1/d})$&#12290;</title><link>http://arxiv.org/abs/2202.11592</link><description>&lt;p&gt;
&#36229;&#20986;&#31561;&#21608;&#24615;&#30340;&#31283;&#20581;&#24615;&#24459;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Law of Robustness beyond Isoperimetry. (arXiv:2202.11592v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.11592
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20004;&#23618;&#27425;&#30340;&#31283;&#20581;&#24615;&#24459;&#27861;&#65292;&#30740;&#31350;&#20102;&#22312;&#20219;&#24847;&#25968;&#25454;&#20998;&#24067;&#19979;&#30340;&#31283;&#20581;&#25554;&#20540;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20854;Lipschitz&#19979;&#30028;&#20998;&#21035;&#20026;$\Omega(\sqrt{n/p})$&#21644;$\Omega(n^{1/d})$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22312;&#19968;&#20010;&#26377;&#30028;&#31354;&#38388;&#19978;&#25903;&#25345;&#20219;&#24847;&#25968;&#25454;&#20998;&#24067;&#30340;&#31283;&#20581;&#25554;&#20540;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#20004;&#23618;&#27425;&#30340;&#31283;&#20581;&#24615;&#24459;&#27861;&#12290;&#31283;&#20581;&#25554;&#20540;&#26159;&#25351;&#36890;&#36807;Lipschitz&#20989;&#25968;&#25554;&#20540;$\mathbb{R}^d$&#20013;&#30340;$n$&#20010;&#22024;&#26434;&#35757;&#32451;&#25968;&#25454;&#28857;&#12290;&#23613;&#31649;&#24403;&#26679;&#26412;&#26469;&#33258;&#31561;&#21608;&#24615;&#20998;&#24067;&#26102;&#65292;&#24050;&#32463;&#24456;&#22909;&#22320;&#29702;&#35299;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#20294;&#22312;&#19968;&#33324;&#25110;&#26368;&#22351;&#24773;&#20917;&#20998;&#24067;&#19979;&#65292;&#20854;&#24615;&#33021;&#20173;&#28982;&#19981;&#28165;&#26970;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#20219;&#24847;&#25968;&#25454;&#20998;&#24067;&#65292;&#25554;&#20540;&#31070;&#32463;&#32593;&#32476;&#30340;Lipschitz&#19979;&#30028;&#20026;$\Omega(\sqrt{n/p})$&#65292;&#20854;&#20013;$p$&#34920;&#31034;&#21442;&#25968;&#25968;&#37327;&#12290;&#36890;&#36807;&#36825;&#20010;&#32467;&#26524;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;Bubeck&#65292;Li&#21644;Nagaraj&#22312;&#20108;&#23618;&#31070;&#32463;&#32593;&#32476;&#20013;&#20351;&#29992;&#22810;&#39033;&#24335;&#26435;&#37325;&#25552;&#20986;&#30340;&#31283;&#20581;&#24615;&#24459;&#27861;&#29468;&#24819;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23558;&#32467;&#26524;&#25193;&#23637;&#21040;&#20219;&#24847;&#25554;&#20540;&#36924;&#36817;&#22120;&#65292;&#24182;&#35777;&#26126;&#20102;&#31283;&#20581;&#25554;&#20540;&#30340;Lipschitz&#19979;&#30028;&#20026;$\Omega(n^{1/d})$&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#35777;&#26126;&#20102;&#19968;&#20010;&#20004;&#23618;&#27425;&#30340;&#31283;&#20581;&#24615;&#24459;&#27861;&#65306;
&lt;/p&gt;
&lt;p&gt;
We study the robust interpolation problem of arbitrary data distributions supported on a bounded space and propose a two-fold law of robustness. Robust interpolation refers to the problem of interpolating $n$ noisy training data points in $\mathbb{R}^d$ by a Lipschitz function. Although this problem has been well understood when the samples are drawn from an isoperimetry distribution, much remains unknown concerning its performance under generic or even the worst-case distributions. We prove a Lipschitzness lower bound $\Omega(\sqrt{n/p})$ of the interpolating neural network with $p$ parameters on arbitrary data distributions. With this result, we validate the law of robustness conjecture in prior work by Bubeck, Li, and Nagaraj on two-layer neural networks with polynomial weights. We then extend our result to arbitrary interpolating approximators and prove a Lipschitzness lower bound $\Omega(n^{1/d})$ for robust interpolation. Our results demonstrate a two-fold law of robustness: i) w
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;NN2Poly&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104;&#24050;&#32463;&#35757;&#32451;&#22909;&#30340;&#20840;&#36830;&#25509;&#21069;&#39304;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#30340;&#31934;&#30830;&#22810;&#39033;&#24335;&#34920;&#31034;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#20219;&#24847;&#28145;&#24230;&#30340;&#22810;&#23618;&#24863;&#30693;&#22120;&#65288;MLP&#65289;&#19988;&#35745;&#31639;&#25104;&#26412;&#30456;&#23545;&#36739;&#20302;&#65292;&#33021;&#22815;&#22312;&#22238;&#24402;&#21644;&#20998;&#31867;&#20219;&#21153;&#20013;&#25552;&#20379;&#38750;&#24120;&#20934;&#30830;&#30340;&#36924;&#36817;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2112.11397</link><description>&lt;p&gt;
NN2Poly&#65306;&#29992;&#20110;&#28145;&#24230;&#21069;&#39304;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#30340;&#22810;&#39033;&#24335;&#34920;&#31034;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
NN2Poly: A polynomial representation for deep feed-forward artificial neural networks. (arXiv:2112.11397v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.11397
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;NN2Poly&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#29983;&#25104;&#24050;&#32463;&#35757;&#32451;&#22909;&#30340;&#20840;&#36830;&#25509;&#21069;&#39304;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#30340;&#31934;&#30830;&#22810;&#39033;&#24335;&#34920;&#31034;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#20219;&#24847;&#28145;&#24230;&#30340;&#22810;&#23618;&#24863;&#30693;&#22120;&#65288;MLP&#65289;&#19988;&#35745;&#31639;&#25104;&#26412;&#30456;&#23545;&#36739;&#20302;&#65292;&#33021;&#22815;&#22312;&#22238;&#24402;&#21644;&#20998;&#31867;&#20219;&#21153;&#20013;&#25552;&#20379;&#38750;&#24120;&#20934;&#30830;&#30340;&#36924;&#36817;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#28145;&#24230;&#23398;&#20064;&#24212;&#29992;&#38750;&#24120;&#25104;&#21151;&#65292;&#20294;&#31070;&#32463;&#32593;&#32476;&#30340;&#21487;&#35299;&#37322;&#24615;&#21644;&#29702;&#35770;&#34892;&#20026;&#20173;&#28982;&#26159;&#19968;&#20010;&#24320;&#25918;&#30340;&#30740;&#31350;&#39046;&#22495;&#12290;&#26412;&#25991;&#25552;&#20986;NN2Poly&#65306;&#19968;&#31181;&#29702;&#35770;&#26041;&#27861;&#65292;&#29992;&#20110;&#33719;&#21462;&#19968;&#20010;&#26174;&#24335;&#22810;&#39033;&#24335;&#27169;&#22411;&#65292;&#20197;&#25552;&#20379;&#24050;&#32463;&#35757;&#32451;&#22909;&#30340;&#20840;&#36830;&#25509;&#21069;&#39304;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#65288;&#22810;&#23618;&#24863;&#30693;&#22120;&#25110;MLP&#65289;&#30340;&#31934;&#30830;&#34920;&#31034;&#12290;&#36825;&#31181;&#26041;&#27861;&#25193;&#23637;&#20102;&#25991;&#29486;&#20013;&#25552;&#20986;&#30340;&#20808;&#21069;&#24819;&#27861;&#65292;&#35813;&#24819;&#27861;&#20165;&#38480;&#20110;&#21333;&#38544;&#34255;&#23618;&#30340;&#32593;&#32476;&#65292;&#24182;&#19988;&#36866;&#29992;&#20110;&#22238;&#24402;&#21644;&#20998;&#31867;&#20219;&#21153;&#30340;&#20219;&#24847;&#28145;&#24230;MLP&#12290;&#26412;&#25991;&#30340;&#30446;&#26631;&#26159;&#36890;&#36807;&#22312;&#27599;&#23618;&#19978;&#20351;&#29992;&#28608;&#27963;&#20989;&#25968;&#30340;&#27888;&#21202;&#23637;&#24320;&#24335;&#65292;&#28982;&#21518;&#20351;&#29992;&#20960;&#20010;&#32452;&#21512;&#24615;&#36136;&#26469;&#35745;&#31639;&#25152;&#38656;&#22810;&#39033;&#24335;&#30340;&#31995;&#25968;&#65292;&#20174;&#32780;&#23454;&#29616;&#27492;&#30446;&#26631;&#12290;&#20316;&#32773;&#35752;&#35770;&#20102;&#27492;&#26041;&#27861;&#30340;&#20027;&#35201;&#35745;&#31639;&#25361;&#25112;&#20197;&#21450;&#36890;&#36807;&#24341;&#20837;&#19968;&#20123;&#36924;&#36817;&#26469;&#20811;&#26381;&#36825;&#20123;&#25361;&#25112;&#30340;&#26041;&#27861;&#65292;&#32780;&#19981;&#20250;&#24433;&#21709;&#20854;&#20934;&#30830;&#24615;&#12290;&#36890;&#36807;&#23454;&#39564;&#39564;&#35777;&#34920;&#26126;&#65292;&#23613;&#31649;NN2Poly&#26041;&#27861;&#31616;&#21333;&#19988;&#35745;&#31639;&#25104;&#26412;&#20302;&#65292;&#20294;&#23545;&#20110;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#65292;&#25552;&#20379;&#38750;&#24120;&#20934;&#30830;&#30340;&#22810;&#39033;&#24335;&#36924;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;
Interpretability of neural networks and their underlying theoretical behavior remain an open field of study even after the great success of their practical applications, particularly with the emergence of deep learning. In this work, NN2Poly is proposed: a theoretical approach to obtain an explicit polynomial model that provides an accurate representation of an already trained fully-connected feed-forward artificial neural network (a multilayer perceptron or MLP). This approach extends a previous idea proposed in the literature, which was limited to single hidden layer networks, to work with arbitrarily deep MLPs in both regression and classification tasks. The objective of this paper is to achieve this by using a Taylor expansion on the activation function, at each layer, and then using several combinatorial properties to calculate the coefficients of the desired polynomials. Discussion is presented on the main computational challenges of this method, and the way to overcome them by i
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#26032;&#30340;&#19968;&#31181;&#25490;&#38500;&#38480;&#21046;&#30340;&#25490;&#24207;&#19968;&#33268;&#24615;&#24207;&#22238;&#24402;&#26041;&#27861;&#65292;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21644;&#26465;&#20214;&#27010;&#29575;&#30340;&#24314;&#27169;&#65292;&#21487;&#20197;&#22312;&#20445;&#25345;&#36755;&#20986;&#27010;&#29575;&#25490;&#24207;&#19968;&#33268;&#24615;&#30340;&#21516;&#26102;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2111.08851</link><description>&lt;p&gt;
&#22522;&#20110;&#26465;&#20214;&#27010;&#29575;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#25490;&#24207;&#19968;&#33268;&#24207;&#22238;&#24402;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Deep Neural Networks for Rank-Consistent Ordinal Regression Based On Conditional Probabilities. (arXiv:2111.08851v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.08851
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#26032;&#30340;&#19968;&#31181;&#25490;&#38500;&#38480;&#21046;&#30340;&#25490;&#24207;&#19968;&#33268;&#24615;&#24207;&#22238;&#24402;&#26041;&#27861;&#65292;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#21644;&#26465;&#20214;&#27010;&#29575;&#30340;&#24314;&#27169;&#65292;&#21487;&#20197;&#22312;&#20445;&#25345;&#36755;&#20986;&#27010;&#29575;&#25490;&#24207;&#19968;&#33268;&#24615;&#30340;&#21516;&#26102;&#65292;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#21508;&#31181;&#20998;&#31867;&#21644;&#27169;&#24335;&#35782;&#21035;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#20986;&#33394;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#23454;&#38469;&#30340;&#39044;&#27979;&#38382;&#39064;&#20855;&#26377;&#24207;&#21709;&#24212;&#21464;&#37327;&#65292;&#24182;&#19988;&#20256;&#32479;&#30340;&#20998;&#31867;&#25439;&#22833;&#20989;&#25968;&#24573;&#30053;&#20102;&#36825;&#31181;&#25490;&#24207;&#20449;&#24687;&#12290;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#24207;&#22238;&#24402;&#26041;&#27861;&#35299;&#20915;&#20102;&#36825;&#20010;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#24314;&#31435;&#27599;&#20010;&#24207;&#20998;&#31867;&#30340;&#26465;&#20214;&#27010;&#29575;&#30340;&#28145;&#24230;&#31070;&#32463;&#32467;&#26500;&#65292;&#20174;&#32780;&#20445;&#35777;&#27169;&#22411;&#30340;&#36755;&#20986;&#27010;&#29575;&#22312;&#39044;&#27979;&#26631;&#31614;&#31867;&#21035;&#20013;&#20445;&#25345;&#20854;&#25490;&#24207;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent times, deep neural networks achieved outstanding predictive performance on various classification and pattern recognition tasks. However, many real-world prediction problems have ordinal response variables, and this ordering information is ignored by conventional classification losses such as the multi-category cross-entropy. Ordinal regression methods for deep neural networks address this. One such method is the CORAL method, which is based on an earlier binary label extension framework and achieves rank consistency among its output layer tasks by imposing a weight-sharing constraint. However, while earlier experiments showed that CORAL's rank consistency is beneficial for performance, it is limited by a weight-sharing constraint in a neural network's fully connected output layer, which may restrict the expressiveness and capacity of a network trained using CORAL. We propose a new method for rank-consistent ordinal regression without this limitation. Our rank-consistent ordi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28388;&#27874;&#31639;&#27861;&#30340;&#35780;&#32423;&#36801;&#31227;&#39044;&#27979;&#26041;&#27861;&#65292;&#36890;&#36807;&#28857;&#36807;&#31243;&#28388;&#27874;&#26694;&#26550;&#39640;&#25928;&#22320;&#25512;&#26029;&#20986;&#35780;&#32423;&#36801;&#31227;&#30340;&#38544;&#34255;&#22240;&#32032;&#65292;&#24182;&#26681;&#25454;&#21830;&#19994;&#21608;&#26399;&#36827;&#34892;&#39044;&#27979;&#65292;&#20174;&#32780;&#23454;&#26102;&#25581;&#31034;&#21644;&#26816;&#27979;&#24433;&#21709;&#35780;&#32423;&#36801;&#31227;&#21160;&#24577;&#30340;&#32463;&#27982;&#21464;&#21270;&#12290;</title><link>http://arxiv.org/abs/2109.10567</link><description>&lt;p&gt;
&#35780;&#32423;&#36801;&#31227;&#39044;&#27979;&#65306;&#19968;&#31181;&#28388;&#27874;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Rating transitions forecasting: a filtering approach. (arXiv:2109.10567v4 [math.PR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.10567
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28388;&#27874;&#31639;&#27861;&#30340;&#35780;&#32423;&#36801;&#31227;&#39044;&#27979;&#26041;&#27861;&#65292;&#36890;&#36807;&#28857;&#36807;&#31243;&#28388;&#27874;&#26694;&#26550;&#39640;&#25928;&#22320;&#25512;&#26029;&#20986;&#35780;&#32423;&#36801;&#31227;&#30340;&#38544;&#34255;&#22240;&#32032;&#65292;&#24182;&#26681;&#25454;&#21830;&#19994;&#21608;&#26399;&#36827;&#34892;&#39044;&#27979;&#65292;&#20174;&#32780;&#23454;&#26102;&#25581;&#31034;&#21644;&#26816;&#27979;&#24433;&#21709;&#35780;&#32423;&#36801;&#31227;&#21160;&#24577;&#30340;&#32463;&#27982;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#26512;&#21830;&#19994;&#21608;&#26399;&#23545;&#35780;&#32423;&#36801;&#31227;&#30340;&#24433;&#21709;&#26159;&#36817;&#21313;&#20116;&#24180;&#26469;&#24341;&#36215;&#26497;&#22823;&#20851;&#27880;&#30340;&#30740;&#31350;&#35838;&#39064;&#65292;&#29305;&#21035;&#26159;&#22312;&#30417;&#31649;&#26426;&#26500;&#36827;&#34892;&#21387;&#21147;&#27979;&#35797;&#30340;&#24773;&#20917;&#19979;&#12290;&#26412;&#25991;&#35748;&#20026;&#35780;&#32423;&#36801;&#31227;&#30340;&#21160;&#24577;&#30001;&#26410;&#35266;&#23519;&#21040;&#30340;&#28508;&#22312;&#22240;&#32032;&#25511;&#21046;&#12290;&#22312;&#19968;&#20010;&#28857;&#36807;&#31243;&#28388;&#27874;&#26694;&#26550;&#19979;&#65292;&#25105;&#20204;&#35299;&#37322;&#20102;&#22914;&#20309;&#20174;&#35780;&#32423;&#21382;&#21490;&#35266;&#27979;&#20013;&#39640;&#25928;&#22320;&#25512;&#26029;&#20986;&#38544;&#34255;&#22240;&#32032;&#30340;&#24403;&#21069;&#29366;&#24577;&#12290;&#28982;&#21518;&#25105;&#20204;&#23558;&#32463;&#20856;&#30340; Baum-Welsh &#31639;&#27861;&#35843;&#25972;&#21040;&#20102;&#25105;&#20204;&#30340;&#35821;&#22659;&#20013;&#65292;&#24182;&#35828;&#26126;&#20102;&#22914;&#20309;&#20272;&#35745;&#38544;&#34255;&#22240;&#32032;&#30340;&#21442;&#25968;&#12290;&#19968;&#26086;&#26657;&#20934;&#23436;&#25104;&#65292;&#25105;&#20204;&#23601;&#21487;&#20197;&#23454;&#26102;&#22320;&#25581;&#31034;&#21644;&#26816;&#27979;&#24433;&#21709;&#35780;&#32423;&#36801;&#31227;&#21160;&#24577;&#30340;&#32463;&#27982;&#21464;&#21270;&#65292;&#24182;&#20351;&#29992;&#26080;&#38656;&#20351;&#29992;&#20219;&#20309;&#22806;&#37096;&#21327;&#21464;&#37327;&#30340;&#28388;&#27874;&#20844;&#24335;&#39044;&#27979;&#26410;&#26469;&#30340;&#36716;&#25442;&#27010;&#29575;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#28388;&#27874;&#26694;&#26550;&#65306;&#31163;&#25955;&#29256;&#26412;&#21644;&#36830;&#32493;&#29256;&#26412;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#28436;&#31034;&#21644;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Analyzing the effect of business cycle on rating transitions has been a subject of great interest these last fifteen years, particularly due to the increasing pressure coming from regulators for stress testing. In this paper, we consider that the dynamics of rating migrations is governed by an unobserved latent factor. Under a point process filtering framework, we explain how the current state of the hidden factor can be efficiently inferred from observations of rating histories. We then adapt the classical Baum-Welsh algorithm to our setting and show how to estimate the latent factor parameters. Once calibrated, we may reveal and detect economic changes affecting the dynamics of rating migration, in real-time. To this end we adapt a filtering formula which can then be used for predicting future transition probabilities according to economic regimes without using any external covariates. We propose two filtering frameworks: a discrete and a continuous version. We demonstrate and compar
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#19981;&#24120;&#35265;&#20294;&#22312;&#32479;&#35745;&#12289;&#27010;&#29575;&#19982;&#20248;&#21270;&#31561;&#39046;&#22495;&#24120;&#29992;&#30340;&#25216;&#26415;&#8212;&#8212;&#25351;&#25968;&#20542;&#26012;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#21040;&#39118;&#38505;&#26368;&#23567;&#21270;&#20013;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#20197;&#20462;&#27491;&#21333;&#20010;&#25439;&#22833;&#30340;&#24433;&#21709;&#65292;&#22686;&#21152;&#25110;&#20943;&#23569;&#24322;&#24120;&#20540;&#30340;&#20316;&#29992;&#65292;&#21487;&#20197;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#65292;&#24182;&#21487;&#20197;&#34987;&#35270;&#20026;&#25439;&#22833;&#30340;&#23614;&#37096;&#27010;&#29575;&#30340;&#24179;&#28369;&#36817;&#20284;&#12290;</title><link>http://arxiv.org/abs/2109.06141</link><description>&lt;p&gt;
&#20851;&#20110;&#20542;&#26012;&#25439;&#22833;&#30340;&#26426;&#22120;&#23398;&#20064;&#29702;&#35770;&#19982;&#24212;&#29992;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Tilted Losses in Machine Learning: Theory and Applications. (arXiv:2109.06141v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.06141
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#19981;&#24120;&#35265;&#20294;&#22312;&#32479;&#35745;&#12289;&#27010;&#29575;&#19982;&#20248;&#21270;&#31561;&#39046;&#22495;&#24120;&#29992;&#30340;&#25216;&#26415;&#8212;&#8212;&#25351;&#25968;&#20542;&#26012;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#21040;&#39118;&#38505;&#26368;&#23567;&#21270;&#20013;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#21487;&#20197;&#20462;&#27491;&#21333;&#20010;&#25439;&#22833;&#30340;&#24433;&#21709;&#65292;&#22686;&#21152;&#25110;&#20943;&#23569;&#24322;&#24120;&#20540;&#30340;&#20316;&#29992;&#65292;&#21487;&#20197;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#65292;&#24182;&#21487;&#20197;&#34987;&#35270;&#20026;&#25439;&#22833;&#30340;&#23614;&#37096;&#27010;&#29575;&#30340;&#24179;&#28369;&#36817;&#20284;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25351;&#25968;&#20542;&#26012;&#26159;&#32479;&#35745;&#23398;&#12289;&#27010;&#29575;&#35770;&#12289;&#20449;&#24687;&#35770;&#21644;&#20248;&#21270;&#31561;&#39046;&#22495;&#24120;&#29992;&#30340;&#19968;&#31181;&#25216;&#26415;&#65292;&#29992;&#20110;&#21019;&#24314;&#21442;&#25968;&#21270;&#20998;&#24067;&#36716;&#31227;&#12290;&#23613;&#31649;&#22312;&#30456;&#20851;&#39046;&#22495;&#20013;&#38750;&#24120;&#24120;&#35265;&#65292;&#20294;&#20542;&#26012;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#23578;&#19981;&#26222;&#21450;&#12290;&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#30740;&#31350;&#20542;&#26012;&#22312;&#39118;&#38505;&#26368;&#23567;&#21270;&#20013;&#30340;&#24212;&#29992;&#26469;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#39564;&#31639;&#39118;&#38505;&#26368;&#23567;&#21270;&#65288;TERM&#65289;&#30340;&#31616;&#21333;&#25193;&#23637;&#65292;&#23427;&#20351;&#29992;&#25351;&#25968;&#20542;&#26012;&#26469;&#28789;&#27963;&#35843;&#25972;&#20010;&#21035;&#25439;&#22833;&#30340;&#24433;&#21709;&#12290;&#25152;&#24471;&#21040;&#30340;&#26694;&#26550;&#20855;&#26377;&#22810;&#31181;&#26377;&#29992;&#30340;&#24615;&#36136;&#65306;&#25105;&#20204;&#23637;&#31034;&#20102;TERM&#21487;&#20197;&#20998;&#21035;&#22686;&#21152;&#25110;&#20943;&#23569;&#24322;&#24120;&#20540;&#30340;&#24433;&#21709;&#65292;&#20174;&#32780;&#23454;&#29616;&#20844;&#24179;&#25110;&#40065;&#26834;&#24615;&#12290;TERM&#20063;&#20855;&#26377;&#38477;&#20302;&#26041;&#24046;&#20174;&#32780;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#30340;&#20248;&#21183;&#65292;&#24182;&#19988;&#21487;&#20197;&#34987;&#30475;&#20316;&#26159;&#23545;&#25439;&#22833;&#30340;&#23614;&#37096;&#27010;&#29575;&#30340;&#24179;&#28369;&#36817;&#20284;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#22312;TERM&#21644;&#20854;&#20182;&#30456;&#20851;&#30446;&#26631;&#20043;&#38388;&#24314;&#31435;&#20102;&#20005;&#26684;&#30340;&#32852;&#31995;&#65292;&#20363;&#22914;&#39118;&#38505;&#20215;&#20540;&#12289;&#26465;&#20214;&#39118;&#38505;&#20215;&#20540;&#21644;&#20998;&#24067;&#40065;&#26834;&#20248;&#21270;&#31561;&#12290;
&lt;/p&gt;
&lt;p&gt;
Exponential tilting is a technique commonly used in fields such as statistics, probability, information theory, and optimization to create parametric distribution shifts. Despite its prevalence in related fields, tilting has not seen widespread use in machine learning. In this work, we aim to bridge this gap by exploring the use of tilting in risk minimization. We study a simple extension to ERM -- tilted empirical risk minimization (TERM) -which uses exponential tilting to flexibly tune the impact of individual losses. The resulting framework has several useful properties: We show that TERM can increase or decrease the influence of outliers, respectively, to enable fairness or robustness; has variance-reduction properties that can benefit generalization; and can be viewed as a smooth approximation to the tail probability of losses. Our work makes rigorous connections between TERM and related objectives, such as Value-at-Risk, Conditional Value-at-Risk, and distributionally robust op
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#22312;&#21709;&#24212;&#24335;&#21644;&#20132;&#20114;&#24335;&#25968;&#25454;&#20998;&#24067;&#19979;&#65292;&#31639;&#27861;&#39044;&#27979;&#22120;&#30340;&#21487;&#36801;&#31227;&#24615;&#38382;&#39064;&#65292;&#25552;&#20379;&#20102;&#24615;&#33021;&#24046;&#36317;&#30340;&#19978;&#30028;&#21644;&#20998;&#31867;&#22120;&#24517;&#39035;&#28385;&#36275;&#30340;&#26435;&#34913;&#30340;&#19979;&#30028;&#65292;&#24182;&#21051;&#30011;&#20102;&#39044;&#27979;&#22120;&#12289;&#31574;&#30053;&#31354;&#38388;&#36873;&#25321;&#21644;&#20559;&#31227;&#24615;&#36136;&#23545;&#21487;&#36801;&#31227;&#24615;&#31243;&#24230;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2107.05911</link><description>&lt;p&gt;
&#21709;&#24212;&#24335;&#20915;&#31574;&#20027;&#20307;&#19979;&#30340;&#27169;&#22411;&#21487;&#36801;&#31227;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Model Transferability With Responsive Decision Subjects. (arXiv:2107.05911v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2107.05911
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#22312;&#21709;&#24212;&#24335;&#21644;&#20132;&#20114;&#24335;&#25968;&#25454;&#20998;&#24067;&#19979;&#65292;&#31639;&#27861;&#39044;&#27979;&#22120;&#30340;&#21487;&#36801;&#31227;&#24615;&#38382;&#39064;&#65292;&#25552;&#20379;&#20102;&#24615;&#33021;&#24046;&#36317;&#30340;&#19978;&#30028;&#21644;&#20998;&#31867;&#22120;&#24517;&#39035;&#28385;&#36275;&#30340;&#26435;&#34913;&#30340;&#19979;&#30028;&#65292;&#24182;&#21051;&#30011;&#20102;&#39044;&#27979;&#22120;&#12289;&#31574;&#30053;&#31354;&#38388;&#36873;&#25321;&#21644;&#20559;&#31227;&#24615;&#36136;&#23545;&#21487;&#36801;&#31227;&#24615;&#31243;&#24230;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20154;&#31867;&#26234;&#33021;&#20915;&#31574;&#21442;&#19982;&#30340;&#19968;&#20123;&#25968;&#25454;&#38598;&#19978;&#65292;&#22914;&#26524;&#23384;&#22312;&#19968;&#20010;&#20934;&#30830;&#30340;&#31639;&#27861;&#39044;&#27979;&#22120;&#65292;&#37027;&#20040;&#23427;&#22312;&#36825;&#20123;&#25968;&#25454;&#38598;&#19978;&#30340;&#20934;&#30830;&#29575;&#26159;&#21542;&#20250;&#34987;&#20445;&#25345;&#21602;&#65311;&#22312;&#25105;&#20204;&#30340;&#32972;&#26223;&#35774;&#32622;&#20013;&#65292;&#19968;&#20010;&#20195;&#29702;&#20154;&#25110;&#29992;&#25143;&#23545;&#24212;&#20110;&#20174;&#20998;&#24067;$D$&#20013;&#25277;&#26679;&#24471;&#21040;&#30340;&#19968;&#20010;&#26679;&#26412;$(X,Y)$&#65292;&#24182;&#38754;&#20020;&#30528;&#27169;&#22411;$h$&#21450;&#20854;&#20998;&#31867;&#32467;&#26524;$h(X)$&#12290;&#20195;&#29702;&#20154;&#21487;&#20197;&#20462;&#25913;$X$&#20197;&#36866;&#24212;$h$&#65292;&#36825;&#23558;&#23545;$(X,Y)$&#20135;&#29983;&#20998;&#24067;&#20559;&#31227;&#12290;&#25105;&#20204;&#30340;&#35774;&#32622;&#26159;&#21463;&#21040;&#20102;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#34987;&#20154;&#31867;&#20195;&#29702;&#20154;&#20351;&#29992;&#24182;&#26368;&#32456;&#38754;&#23545;&#21709;&#24212;&#24335;&#21644;&#20132;&#20114;&#24335;&#25968;&#25454;&#20998;&#24067;&#30340;&#24212;&#29992;&#26696;&#20363;&#30340;&#21551;&#21457;&#12290;&#25105;&#20204;&#36890;&#36807;&#30740;&#31350;&#27169;&#22411;&#22312;&#21487;&#29992;&#28304;&#20998;&#24067;&#65288;&#25968;&#25454;&#65289;&#19978;&#35757;&#32451;&#30340;&#24615;&#33021;&#22914;&#20309;&#36716;&#21270;&#20026;&#20854;&#35825;&#23548;&#22495;&#20013;&#24615;&#33021;&#26469;&#31995;&#32479;&#21270;&#22320;&#35752;&#35770;&#27169;&#22411;&#30340;&#21487;&#36801;&#31227;&#24615;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#30001;&#20110;&#35825;&#23548;&#22495;&#20559;&#31227;&#32780;&#23548;&#33268;&#30340;&#24615;&#33021;&#24046;&#36317;&#30340;&#19978;&#30028;&#65292;&#20197;&#21450;&#20998;&#31867;&#22120;&#24517;&#39035;&#28385;&#36275;&#30340;&#26435;&#34913;&#30340;&#19979;&#30028;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#21051;&#30011;&#20102;&#39044;&#27979;&#22120;&#12289;&#31574;&#30053;&#31354;&#38388;&#36873;&#25321;&#21644;&#20559;&#31227;&#24615;&#36136;&#23545;&#21487;&#36801;&#31227;&#24615;&#31243;&#24230;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Given an algorithmic predictor that is accurate on some source population consisting of strategic human decision subjects, will it remain accurate if the population respond to it? In our setting, an agent or a user corresponds to a sample $(X,Y)$ drawn from a distribution $\cal{D}$ and will face a model $h$ and its classification result $h(X)$. Agents can modify $X$ to adapt to $h$, which will incur a distribution shift on $(X,Y)$. Our formulation is motivated by applications where the deployed machine learning models are subjected to human agents, and will ultimately face responsive and interactive data distributions. We formalize the discussions of the transferability of a model by studying how the performance of the model trained on the available source distribution (data) would translate to the performance on its induced domain. We provide both upper bounds for the performance gap due to the induced domain shift, as well as lower bounds for the trade-offs that a classifier has to s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#23545;&#25239;&#25915;&#20987;&#19979;&#30340;UCB&#26368;&#20248;&#25289;&#33218;&#31574;&#30053;&#65292;&#25104;&#26412;&#20026;$\sqrt{\log T}$&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#27492;&#25915;&#20987;&#31574;&#30053;&#36817;&#20046;&#26159;&#26368;&#20248;&#30340;&#12290;</title><link>http://arxiv.org/abs/2008.09312</link><description>&lt;p&gt;
UCB Bandits&#22312;&#23545;&#25239;&#25915;&#20987;&#20013;&#30340;&#36817;&#20046;&#26368;&#20248;&#25915;&#20987;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Near Optimal Adversarial Attack on UCB Bandits. (arXiv:2008.09312v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2008.09312
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#23545;&#25239;&#25915;&#20987;&#19979;&#30340;UCB&#26368;&#20248;&#25289;&#33218;&#31574;&#30053;&#65292;&#25104;&#26412;&#20026;$\sqrt{\log T}$&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#27492;&#25915;&#20987;&#31574;&#30053;&#36817;&#20046;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#31181;&#38543;&#26426;&#22810;&#33218;&#36172;&#21338;&#38382;&#39064;&#65292;&#20854;&#20013;&#22870;&#21169;&#21463;&#21040;&#23545;&#25239;&#24615;&#30772;&#22351;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25915;&#20987;&#31574;&#30053;&#65292;&#36890;&#36807;&#25805;&#20316;UCB&#21407;&#21017;&#26469;&#25289;&#21160;&#19968;&#20123;&#38750;&#26368;&#20248;&#30446;&#26631;&#33218;$T-o(T)$&#27425;&#65292;&#32047;&#31215;&#25104;&#26412;&#30340;&#26631;&#24230;&#20026;$\sqrt{\log T}$&#65292;&#20854;&#20013;$T$&#20026;&#22238;&#21512;&#25968;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#32047;&#31215;&#25915;&#20987;&#25104;&#26412;&#30340;&#31532;&#19968;&#20010;&#19979;&#30028;&#12290;&#25105;&#20204;&#30340;&#19979;&#30028;&#19982;&#25105;&#20204;&#30340;&#19978;&#30028;&#21305;&#37197;&#65292;&#38500;&#20102;$\log\log T$&#22240;&#23376;&#65292;&#34920;&#26126;&#25105;&#20204;&#30340;&#25915;&#20987;&#31574;&#30053;&#36817;&#20046;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a stochastic multi-arm bandit problem where rewards are subject to adversarial corruption. We propose a novel attack strategy that manipulates a UCB principle into pulling some non-optimal target arm $T - o(T)$ times with a cumulative cost that scales as $\sqrt{\log T}$, where $T$ is the number of rounds. We also prove the first lower bound on the cumulative attack cost. Our lower bound matches our upper bound up to $\log \log T$ factors, showing our attack to be near optimal.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#22270;&#32858;&#31867;&#36825;&#19968;&#26080;&#30417;&#30563;&#38382;&#39064;&#19978;&#30340;&#32570;&#38519;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DMoN&#30340;&#26080;&#30417;&#30563;&#27719;&#32858;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#35299;&#20915;&#32858;&#31867;&#24674;&#22797;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2006.16904</link><description>&lt;p&gt;
&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#22270;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Graph Clustering with Graph Neural Networks. (arXiv:2006.16904v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2006.16904
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#22270;&#32858;&#31867;&#36825;&#19968;&#26080;&#30417;&#30563;&#38382;&#39064;&#19978;&#30340;&#32570;&#38519;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DMoN&#30340;&#26080;&#30417;&#30563;&#27719;&#32858;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#35299;&#20915;&#32858;&#31867;&#24674;&#22797;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#24050;&#32463;&#22312;&#35832;&#22914;&#33410;&#28857;&#20998;&#31867;&#21644;&#38142;&#36335;&#39044;&#27979;&#20043;&#31867;&#30340;&#35768;&#22810;&#22270;&#20998;&#26512;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;&#28982;&#32780;&#65292;&#22312;&#22270;&#19978;&#30340;&#19968;&#20123;&#37325;&#35201;&#26080;&#30417;&#30563;&#38382;&#39064;&#65292;&#27604;&#22914;&#22270;&#32858;&#31867;&#65292;&#21364;&#23545;GNN&#30340;&#36827;&#23637;&#26356;&#21152;&#26377;&#25269;&#25239;&#21147;&#12290;&#25105;&#20204;&#36890;&#36807;&#31934;&#24515;&#35774;&#35745;&#19968;&#32452;&#23454;&#39564;&#65292;&#30740;&#31350;&#20102;&#19981;&#21516;&#20449;&#22122;&#27604;&#24773;&#20917;&#19979;&#30340;&#34920;&#24449;&#25968;&#25454;&#23545;&#20110;&#22270;&#32467;&#26500;&#30340;&#24433;&#21709;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#26041;&#27861;&#22312;&#32858;&#31867;&#26041;&#38754;&#30340;&#24615;&#33021;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26080;&#30417;&#30563;&#27719;&#32858;&#26041;&#27861;&#65306;&#28145;&#24230;&#27169;&#22359;&#32593;&#32476;(DMoN)&#12290;&#36825;&#31181;&#26041;&#27861;&#21463;&#32858;&#31867;&#36136;&#37327;&#30340;&#27169;&#22359;&#24230;&#24230;&#37327;&#30340;&#21551;&#21457;&#65292;&#33021;&#22815;&#22788;&#29702;&#32858;&#31867;&#24674;&#22797;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Networks (GNNs) have achieved state-of-the-art results on many graph analysis tasks such as node classification and link prediction. However, important unsupervised problems on graphs, such as graph clustering, have proved more resistant to advances in GNNs. Graph clustering has the same overall goal as node pooling in GNNs - does this mean that GNN pooling methods do a good job at clustering graphs?  Surprisingly, the answer is no - current GNN pooling methods often fail to recover the cluster structure in cases where simple baselines, such as k-means applied on learned representations, work well. We investigate further by carefully designing a set of experiments to study different signal-to-noise scenarios both in graph structure and attribute data. To address these methods' poor performance in clustering, we introduce Deep Modularity Networks (DMoN), an unsupervised pooling method inspired by the modularity measure of clustering quality, and show how it tackles recovery
&lt;/p&gt;</description></item></channel></rss>