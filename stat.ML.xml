<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#25552;&#20379;&#20102;&#19968;&#20010;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#36827;&#34892;&#20559;&#22909;&#23398;&#20064;&#30340;&#26694;&#26550;&#65292;&#33021;&#22815;&#23558;&#29702;&#24615;&#21407;&#21017;&#34701;&#20837;&#23398;&#20064;&#36807;&#31243;&#65292;&#28085;&#30422;&#20102;&#22810;&#31181;&#20559;&#22909;&#23398;&#20064;&#27169;&#22411;&#12290;</title><link>https://arxiv.org/abs/2403.11782</link><description>&lt;p&gt;
&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#20174;&#20559;&#22909;&#21644;&#36873;&#25321;&#20013;&#23398;&#20064;&#30340;&#25945;&#31243;
&lt;/p&gt;
&lt;p&gt;
A tutorial on learning from preferences and choices with Gaussian Processes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11782
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20379;&#20102;&#19968;&#20010;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#36827;&#34892;&#20559;&#22909;&#23398;&#20064;&#30340;&#26694;&#26550;&#65292;&#33021;&#22815;&#23558;&#29702;&#24615;&#21407;&#21017;&#34701;&#20837;&#23398;&#20064;&#36807;&#31243;&#65292;&#28085;&#30422;&#20102;&#22810;&#31181;&#20559;&#22909;&#23398;&#20064;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20559;&#22909;&#24314;&#27169;&#20301;&#20110;&#32463;&#27982;&#23398;&#12289;&#20915;&#31574;&#29702;&#35770;&#12289;&#26426;&#22120;&#23398;&#20064;&#21644;&#32479;&#35745;&#23398;&#30340;&#20132;&#21449;&#28857;&#12290;&#36890;&#36807;&#29702;&#35299;&#20010;&#20307;&#30340;&#20559;&#22909;&#21450;&#20854;&#36873;&#25321;&#26041;&#24335;&#65292;&#25105;&#20204;&#21487;&#20197;&#26500;&#24314;&#26356;&#25509;&#36817;&#20182;&#20204;&#26399;&#26395;&#30340;&#20135;&#21697;&#65292;&#20026;&#36328;&#39046;&#22495;&#30340;&#26356;&#39640;&#25928;&#12289;&#20010;&#24615;&#21270;&#24212;&#29992;&#38138;&#24179;&#36947;&#36335;&#12290;&#27492;&#25945;&#31243;&#30340;&#30446;&#26631;&#26159;&#25552;&#20379;&#19968;&#20010;&#36830;&#36143;&#12289;&#20840;&#38754;&#30340;&#20559;&#22909;&#23398;&#20064;&#26694;&#26550;&#65292;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#28436;&#31034;&#22914;&#20309;&#23558;&#29702;&#24615;&#21407;&#21017;&#65288;&#26469;&#33258;&#32463;&#27982;&#23398;&#21644;&#20915;&#31574;&#29702;&#35770;&#65289;&#26080;&#32541;&#22320;&#32435;&#20837;&#23398;&#20064;&#36807;&#31243;&#20013;&#12290;&#36890;&#36807;&#21512;&#36866;&#22320;&#23450;&#21046;&#20284;&#28982;&#20989;&#25968;&#65292;&#36825;&#19968;&#26694;&#26550;&#20351;&#24471;&#33021;&#22815;&#26500;&#24314;&#28085;&#30422;&#38543;&#26426;&#25928;&#29992;&#27169;&#22411;&#12289;&#36776;&#35782;&#38480;&#21046;&#21644;&#23545;&#35937;&#21644;&#26631;&#31614;&#20559;&#22909;&#30340;&#22810;&#37325;&#20914;&#31361;&#25928;&#29992;&#24773;&#26223;&#30340;&#20559;&#22909;&#23398;&#20064;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11782v1 Announce Type: new  Abstract: Preference modelling lies at the intersection of economics, decision theory, machine learning and statistics. By understanding individuals' preferences and how they make choices, we can build products that closely match their expectations, paving the way for more efficient and personalised applications across a wide range of domains. The objective of this tutorial is to present a cohesive and comprehensive framework for preference learning with Gaussian Processes (GPs), demonstrating how to seamlessly incorporate rationality principles (from economics and decision theory) into the learning process. By suitably tailoring the likelihood function, this framework enables the construction of preference learning models that encompass random utility models, limits of discernment, and scenarios with multiple conflicting utilities for both object- and label-preference. This tutorial builds upon established research while simultaneously introducin
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#12289;&#23436;&#20840;&#38750;&#21442;&#25968;&#30340;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#35774;&#32622;&#65292;&#26088;&#22312;&#22312;&#22810;&#20010;&#20998;&#24067;&#20043;&#38388;&#23398;&#20064;&#22240;&#26524;&#20851;&#31995;&#65292;&#26080;&#38656;&#20551;&#35774;&#30828;&#24178;&#39044;&#12290;&#36890;&#36807;&#31232;&#30095;&#24615;&#32422;&#26463;&#65292;&#21487;&#20197;&#20174;&#22810;&#20010;&#20998;&#24067;&#20013;&#24674;&#22797;&#20986;&#22240;&#26524;&#20851;&#31995;&#12290;</title><link>https://arxiv.org/abs/2402.05052</link><description>&lt;p&gt;
&#20174;&#22810;&#20010;&#20998;&#24067;&#20013;&#36827;&#34892;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#65306;&#19968;&#20010;&#36890;&#29992;&#35774;&#32622;
&lt;/p&gt;
&lt;p&gt;
Causal Representation Learning from Multiple Distributions: A General Setting
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.05052
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#12289;&#23436;&#20840;&#38750;&#21442;&#25968;&#30340;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#35774;&#32622;&#65292;&#26088;&#22312;&#22312;&#22810;&#20010;&#20998;&#24067;&#20043;&#38388;&#23398;&#20064;&#22240;&#26524;&#20851;&#31995;&#65292;&#26080;&#38656;&#20551;&#35774;&#30828;&#24178;&#39044;&#12290;&#36890;&#36807;&#31232;&#30095;&#24615;&#32422;&#26463;&#65292;&#21487;&#20197;&#20174;&#22810;&#20010;&#20998;&#24067;&#20013;&#24674;&#22797;&#20986;&#22240;&#26524;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#38382;&#39064;&#20013;&#65292;&#27979;&#37327;&#21464;&#37327;&#65288;&#20363;&#22914;&#22270;&#20687;&#20687;&#32032;&#65289;&#21482;&#26159;&#38544;&#34255;&#30340;&#22240;&#26524;&#21464;&#37327;&#65288;&#20363;&#22914;&#28508;&#22312;&#30340;&#27010;&#24565;&#25110;&#23545;&#35937;&#65289;&#30340;&#25968;&#23398;&#20989;&#25968;&#12290;&#20026;&#20102;&#22312;&#19981;&#26029;&#21464;&#21270;&#30340;&#29615;&#22659;&#20013;&#36827;&#34892;&#39044;&#27979;&#25110;&#23545;&#31995;&#32479;&#36827;&#34892;&#36866;&#24403;&#30340;&#26356;&#25913;&#65292;&#24674;&#22797;&#38544;&#34255;&#30340;&#22240;&#26524;&#21464;&#37327;$Z_i$&#20197;&#21450;&#30001;&#22270;$\mathcal{G}_Z$&#34920;&#31034;&#30340;&#23427;&#20204;&#30340;&#22240;&#26524;&#20851;&#31995;&#26159;&#26377;&#24110;&#21161;&#30340;&#12290;&#36825;&#20010;&#38382;&#39064;&#26368;&#36817;&#34987;&#31216;&#20026;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#12290;&#26412;&#25991;&#20851;&#27880;&#26469;&#33258;&#22810;&#20010;&#20998;&#24067;&#65288;&#26469;&#33258;&#24322;&#26500;&#25968;&#25454;&#25110;&#38750;&#24179;&#31283;&#26102;&#38388;&#24207;&#21015;&#65289;&#30340;&#22240;&#26524;&#34920;&#31034;&#23398;&#20064;&#30340;&#36890;&#29992;&#12289;&#23436;&#20840;&#38750;&#21442;&#25968;&#30340;&#35774;&#32622;&#65292;&#19981;&#38656;&#35201;&#20551;&#35774;&#20998;&#24067;&#25913;&#21464;&#32972;&#21518;&#23384;&#22312;&#30828;&#24178;&#39044;&#12290;&#25105;&#20204;&#26088;&#22312;&#22312;&#36825;&#20010;&#22522;&#26412;&#24773;&#20917;&#19979;&#24320;&#21457;&#36890;&#29992;&#35299;&#20915;&#26041;&#26696;&#65307;&#20316;&#20026;&#21103;&#20135;&#21697;&#65292;&#36825;&#26377;&#21161;&#20110;&#30475;&#21040;&#20854;&#20182;&#20551;&#35774;&#65288;&#22914;&#21442;&#25968;&#22240;&#26524;&#27169;&#22411;&#25110;&#30828;&#24178;&#39044;&#65289;&#25552;&#20379;&#30340;&#29420;&#29305;&#22909;&#22788;&#12290;&#25105;&#20204;&#35777;&#26126;&#22312;&#24674;&#22797;&#36807;&#31243;&#20013;&#23545;&#22270;&#30340;&#31232;&#30095;&#24615;&#32422;&#26463;&#19979;&#65292;&#21487;&#20197;&#20174;&#22810;&#20010;&#20998;&#24067;&#20013;&#23398;&#20064;&#20986;&#22240;&#26524;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
In many problems, the measured variables (e.g., image pixels) are just mathematical functions of the hidden causal variables (e.g., the underlying concepts or objects). For the purpose of making predictions in changing environments or making proper changes to the system, it is helpful to recover the hidden causal variables $Z_i$ and their causal relations represented by graph $\mathcal{G}_Z$. This problem has recently been known as causal representation learning. This paper is concerned with a general, completely nonparametric setting of causal representation learning from multiple distributions (arising from heterogeneous data or nonstationary time series), without assuming hard interventions behind distribution changes. We aim to develop general solutions in this fundamental case; as a by product, this helps see the unique benefit offered by other assumptions such as parametric causal models or hard interventions. We show that under the sparsity constraint on the recovered graph over
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#21040;&#32039;&#25903;&#25345;&#22522;&#30340;&#26680;&#20998;&#32452;&#30340;&#36890;&#29992;&#29702;&#35770;&#65292;&#35813;&#29702;&#35770;&#21487;&#20197;&#29992;&#20110;&#38477;&#20302;&#39640;&#26031;&#36807;&#31243;&#30340;&#35757;&#32451;&#21644;&#39044;&#27979;&#26102;&#38388;&#65292;&#24182;&#19988;&#36890;&#36807;&#36866;&#24403;&#30340;&#32447;&#24615;&#32452;&#21512;&#20135;&#29983;&#20102;$m$&#20010;&#32039;&#25903;&#25345;&#30340;&#26680;&#20998;&#32452;&#20989;&#25968;&#12290;</title><link>https://arxiv.org/abs/2402.04022</link><description>&lt;p&gt;
&#19968;&#31181;&#20174;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#21040;&#32039;&#25903;&#25345;&#22522;&#30340;&#26680;&#20998;&#32452;&#30340;&#36890;&#29992;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
A General Theory for Kernel Packets: from state space model to compactly supported basis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04022
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#21040;&#32039;&#25903;&#25345;&#22522;&#30340;&#26680;&#20998;&#32452;&#30340;&#36890;&#29992;&#29702;&#35770;&#65292;&#35813;&#29702;&#35770;&#21487;&#20197;&#29992;&#20110;&#38477;&#20302;&#39640;&#26031;&#36807;&#31243;&#30340;&#35757;&#32451;&#21644;&#39044;&#27979;&#26102;&#38388;&#65292;&#24182;&#19988;&#36890;&#36807;&#36866;&#24403;&#30340;&#32447;&#24615;&#32452;&#21512;&#20135;&#29983;&#20102;$m$&#20010;&#32039;&#25903;&#25345;&#30340;&#26680;&#20998;&#32452;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20247;&#25152;&#21608;&#30693;&#65292;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#30340;&#29366;&#24577;&#31354;&#38388;&#65288;SS&#65289;&#27169;&#22411;&#20844;&#24335;&#21487;&#20197;&#23558;&#20854;&#35757;&#32451;&#21644;&#39044;&#27979;&#26102;&#38388;&#38477;&#20302;&#21040;O&#65288;n&#65289;&#65288;n&#20026;&#25968;&#25454;&#28857;&#20010;&#25968;&#65289;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;m&#32500;&#30340;GP&#30340;SS&#27169;&#22411;&#20844;&#24335;&#31561;&#20215;&#20110;&#25105;&#20204;&#24341;&#20837;&#30340;&#19968;&#20010;&#27010;&#24565;&#65292;&#31216;&#20026;&#36890;&#29992;&#21491;&#26680;&#20998;&#32452;&#65288;KP&#65289;&#65306;&#19968;&#31181;&#29992;&#20110;GP&#21327;&#26041;&#24046;&#20989;&#25968;K&#30340;&#21464;&#25442;&#65292;&#20351;&#24471;&#23545;&#20110;&#20219;&#24847;$t \leq t_1$&#65292;$0 \leq j \leq m-1$&#21644;$m+1$&#20010;&#36830;&#32493;&#28857;$t_i$&#65292;&#37117;&#28385;&#36275;$\sum_{i=0}^{m}a_iD_t^{(j)}K(t,t_i)=0$&#65292;&#20854;&#20013;${D}_t^{(j)}f(t)$&#34920;&#31034;&#22312;$t$&#19978;&#20316;&#29992;&#30340;&#31532;j&#38454;&#23548;&#25968;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#24605;&#24819;&#25193;&#23637;&#21040;&#20102;GP&#30340;&#21521;&#21518;SS&#27169;&#22411;&#20844;&#24335;&#65292;&#24471;&#21040;&#20102;&#19979;&#19968;&#20010;$m$&#20010;&#36830;&#32493;&#28857;&#30340;&#24038;&#26680;&#20998;&#32452;&#30340;&#27010;&#24565;&#65306;$\sum_{i=0}^{m}b_i{D}_t^{(j)}K(t,t_{m+i})=0$&#65292;&#23545;&#20110;&#20219;&#24847;$t\geq t_{2m}$&#12290;&#36890;&#36807;&#32467;&#21512;&#24038;&#21491;&#26680;&#20998;&#32452;&#65292;&#21487;&#20197;&#35777;&#26126;&#36825;&#20123;&#21327;&#26041;&#24046;&#20989;&#25968;&#30340;&#36866;&#24403;&#32447;&#24615;&#32452;&#21512;&#20135;&#29983;&#20102;$m$&#20010;&#32039;&#25903;&#25345;&#30340;&#26680;&#20998;&#32452;&#20989;&#25968;&#65306;&#23545;&#20110;&#20219;&#24847;$t\not\in(t_0,t_{2m})$&#21644;$j=0,\cdots,m-1$&#65292;$\phi^{(j)}(t)=0$&#12290;
&lt;/p&gt;
&lt;p&gt;
It is well known that the state space (SS) model formulation of a Gaussian process (GP) can lower its training and prediction time both to O(n) for n data points. We prove that an $m$-dimensional SS model formulation of GP is equivalent to a concept we introduce as the general right Kernel Packet (KP): a transformation for the GP covariance function $K$ such that $\sum_{i=0}^{m}a_iD_t^{(j)}K(t,t_i)=0$ holds for any $t \leq t_1$, 0 $\leq j \leq m-1$, and $m+1$ consecutive points $t_i$, where ${D}_t^{(j)}f(t) $ denotes $j$-th order derivative acting on $t$. We extend this idea to the backward SS model formulation of the GP, leading to the concept of the left KP for next $m$ consecutive points: $\sum_{i=0}^{m}b_i{D}_t^{(j)}K(t,t_{m+i})=0$ for any $t\geq t_{2m}$. By combining both left and right KPs, we can prove that a suitable linear combination of these covariance functions yields $m$ compactly supported KP functions: $\phi^{(j)}(t)=0$ for any $t\not\in(t_0,t_{2m})$ and $j=0,\cdots,m-1$
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20960;&#20309;&#35843;&#25972;&#30340;&#26799;&#24230;&#19979;&#38477;&#65292;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#20197;&#22343;&#21248;&#25351;&#25968;&#36895;&#29575;&#23454;&#29616;&#20840;&#23616;$\mathcal{L}^2$&#26368;&#23567;&#21270;&#65292;&#36825;&#19968;&#26041;&#27861;&#22312;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#20855;&#26377;&#26126;&#30830;&#33258;&#28982;&#30340;&#19981;&#21464;&#20960;&#20309;&#21547;&#20041;&#12290;</title><link>https://arxiv.org/abs/2311.15487</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#20013;&#36890;&#36807;&#20960;&#20309;&#35843;&#25972;&#30340;&#26799;&#24230;&#19979;&#38477;&#20197;&#22343;&#21248;&#25351;&#25968;&#36895;&#29575;&#20840;&#23616;$\mathcal{L}^2$&#26368;&#23567;&#21270;
&lt;/p&gt;
&lt;p&gt;
Global $\mathcal{L}^2$ minimization at uniform exponential rate via geometrically adapted gradient descent in Deep Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.15487
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20960;&#20309;&#35843;&#25972;&#30340;&#26799;&#24230;&#19979;&#38477;&#65292;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#20197;&#22343;&#21248;&#25351;&#25968;&#36895;&#29575;&#23454;&#29616;&#20840;&#23616;$\mathcal{L}^2$&#26368;&#23567;&#21270;&#65292;&#36825;&#19968;&#26041;&#27861;&#22312;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#20855;&#26377;&#26126;&#30830;&#33258;&#28982;&#30340;&#19981;&#21464;&#20960;&#20309;&#21547;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#28145;&#24230;&#23398;&#20064;&#32593;&#32476;&#20013;&#24191;&#27867;&#20351;&#29992;&#30340;&#29992;&#20110;&#26368;&#23567;&#21270;$\mathcal{L}^2$&#20195;&#20215;&#20989;&#25968;&#30340;&#26799;&#24230;&#19979;&#38477;&#27969;&#65292;&#24182;&#24341;&#20837;&#20004;&#20010;&#25913;&#36827;&#29256;&#26412;&#65307;&#19968;&#20010;&#36866;&#29992;&#20110;&#36807;&#21442;&#25968;&#21270;&#35774;&#32622;&#65292;&#21478;&#19968;&#20010;&#36866;&#29992;&#20110;&#27424;&#21442;&#25968;&#21270;&#35774;&#32622;&#12290;&#36825;&#20004;&#20010;&#29256;&#26412;&#37117;&#20855;&#26377;&#26126;&#30830;&#33258;&#28982;&#30340;&#19981;&#21464;&#20960;&#20309;&#21547;&#20041;&#65292;&#32771;&#34385;&#21040;&#22312;&#36807;&#21442;&#25968;&#21270;&#35774;&#32622;&#20013;&#30340;&#25289;&#22238;&#21521;&#37327;&#19995;&#32467;&#26500;&#21644;&#22312;&#27424;&#21442;&#25968;&#21270;&#35774;&#32622;&#20013;&#30340;&#25512;&#21069;&#21521;&#37327;&#19995;&#32467;&#26500;&#12290;&#22312;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#65292;&#21482;&#35201;&#28385;&#36275;&#31209;&#26465;&#20214;&#65292;&#25913;&#36827;&#30340;&#26799;&#24230;&#19979;&#38477;&#30340;&#25152;&#26377;&#36712;&#36947;&#23558;&#20197;&#22343;&#21248;&#25351;&#25968;&#25910;&#25947;&#36895;&#29575;&#23558;$\mathcal{L}^2$&#20195;&#20215;&#39537;&#21160;&#21040;&#20840;&#23616;&#26368;&#23567;&#20540;&#65307;&#22240;&#27492;&#65292;&#23545;&#20110;&#20219;&#20309;&#39044;&#20808;&#25351;&#23450;&#30340;&#25509;&#36817;&#20840;&#23616;&#26368;&#23567;&#20540;&#30340;&#36817;&#20284;&#65292;&#25105;&#20204;&#21487;&#20197;&#24471;&#21040;&#20808;&#39564;&#20572;&#27490;&#26102;&#38388;&#12290;&#25105;&#20204;&#25351;&#20986;&#21518;&#32773;&#19982;&#27425;Riemann&#20960;&#20309;&#30340;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.15487v3 Announce Type: replace-cross  Abstract: We consider the gradient descent flow widely used for the minimization of the $\mathcal{L}^2$ cost function in Deep Learning networks, and introduce two modified versions; one adapted for the overparametrized setting, and the other for the underparametrized setting. Both have a clear and natural invariant geometric meaning, taking into account the pullback vector bundle structure in the overparametrized, and the pushforward vector bundle structure in the underparametrized setting. In the overparametrized case, we prove that, provided that a rank condition holds, all orbits of the modified gradient descent drive the $\mathcal{L}^2$ cost to its global minimum at a uniform exponential convergence rate; one thereby obtains an a priori stopping time for any prescribed proximity to the global minimum. We point out relations of the latter to sub-Riemannian geometry.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23545;&#28145;&#24230;&#23398;&#20064;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#36827;&#34892;&#20102;&#35843;&#26597;&#65292;&#20174;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#30340;&#35282;&#24230;&#20998;&#26512;&#19981;&#21516;&#26041;&#27861;&#65292;&#20197;&#35780;&#20272;DNN&#39044;&#27979;&#30340;&#32622;&#20449;&#24230;&#12290;</title><link>https://arxiv.org/abs/2302.13425</link><description>&lt;p&gt;
&#23545;&#28145;&#24230;&#23398;&#20064;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#36827;&#34892;&#35843;&#26597;&#65306;&#20174;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#30340;&#35282;&#24230;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
A Survey on Uncertainty Quantification for Deep Learning: An Uncertainty Source Perspective
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2302.13425
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23545;&#28145;&#24230;&#23398;&#20064;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#36827;&#34892;&#20102;&#35843;&#26597;&#65292;&#20174;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#30340;&#35282;&#24230;&#20998;&#26512;&#19981;&#21516;&#26041;&#27861;&#65292;&#20197;&#35780;&#20272;DNN&#39044;&#27979;&#30340;&#32622;&#20449;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#22312;&#35745;&#31639;&#26426;&#35270;&#35273;&#12289;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20197;&#21450;&#31185;&#23398;&#19982;&#24037;&#31243;&#39046;&#22495;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#12290;&#28982;&#32780;&#65292;&#20154;&#20204;&#20063;&#35748;&#35782;&#21040;DNNs&#26377;&#26102;&#20250;&#20570;&#20986;&#24847;&#22806;&#12289;&#38169;&#35823;&#20294;&#36807;&#20110;&#33258;&#20449;&#30340;&#39044;&#27979;&#12290;&#36825;&#21487;&#33021;&#23548;&#33268;&#22312;&#33258;&#21160;&#39550;&#39542;&#12289;&#21307;&#23398;&#35786;&#26029;&#21644;&#28798;&#38590;&#21709;&#24212;&#31561;&#39640;&#39118;&#38505;&#24212;&#29992;&#20013;&#20986;&#29616;&#20005;&#37325;&#21518;&#26524;&#12290;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65288;UQ&#65289;&#26088;&#22312;&#20272;&#35745;DNN&#39044;&#27979;&#30340;&#32622;&#20449;&#24230;&#65292;&#36229;&#36234;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#36817;&#24180;&#26469;&#65292;&#24050;&#32463;&#24320;&#21457;&#20102;&#35768;&#22810;&#38024;&#23545;DNNs&#30340;UQ&#26041;&#27861;&#12290;&#31995;&#32479;&#22320;&#23545;&#36825;&#20123;UQ&#26041;&#27861;&#36827;&#34892;&#20998;&#31867;&#24182;&#27604;&#36739;&#23427;&#20204;&#30340;&#20248;&#21183;&#21644;&#21155;&#21183;&#20855;&#26377;&#26497;&#22823;&#30340;&#23454;&#38469;&#20215;&#20540;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#35843;&#26597;&#22823;&#22810;&#38598;&#20013;&#22312;&#20174;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#35282;&#24230;&#25110;&#36125;&#21494;&#26031;&#35282;&#24230;&#23545;UQ&#26041;&#27861;&#36827;&#34892;&#20998;&#31867;&#65292;&#24573;&#30053;&#20102;&#27599;&#31181;&#26041;&#27861;&#21487;&#33021;&#24341;&#20837;&#30340;&#19981;&#30830;&#23450;&#24615;&#26469;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2302.13425v3 Announce Type: replace  Abstract: Deep neural networks (DNNs) have achieved tremendous success in making accurate predictions for computer vision, natural language processing, as well as science and engineering domains. However, it is also well-recognized that DNNs sometimes make unexpected, incorrect, but overconfident predictions. This can cause serious consequences in high-stake applications, such as autonomous driving, medical diagnosis, and disaster response. Uncertainty quantification (UQ) aims to estimate the confidence of DNN predictions beyond prediction accuracy. In recent years, many UQ methods have been developed for DNNs. It is of great practical value to systematically categorize these UQ methods and compare their advantages and disadvantages. However, existing surveys mostly focus on categorizing UQ methodologies from a neural network architecture perspective or a Bayesian perspective and ignore the source of uncertainty that each methodology can incor
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29109;&#30340;&#23398;&#20064;&#30446;&#26631;&#65292;&#29992;&#20110;&#31232;&#30095;&#32534;&#30721;&#21442;&#25968;&#30340;&#23398;&#20064;&#65292;&#36890;&#36807;&#38750;&#24179;&#20961;&#30340;&#21518;&#39564;&#36924;&#36817;&#21644;&#35299;&#26512;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#23454;&#29616;&#20102;&#26631;&#20934;&#31232;&#30095;&#32534;&#30721;&#30340;&#23398;&#20064;&#65292;&#22312;&#25968;&#20540;&#23454;&#39564;&#20013;&#35777;&#26126;&#20102;&#20854;&#21487;&#34892;&#24615;&#12290;</title><link>http://arxiv.org/abs/2311.01888</link><description>&lt;p&gt;
&#20351;&#29992;&#22522;&#20110;&#29109;&#30340;ELBO&#23398;&#20064;&#31232;&#30095;&#32534;&#30721;
&lt;/p&gt;
&lt;p&gt;
Learning Sparse Codes with Entropy-Based ELBOs. (arXiv:2311.01888v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.01888
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29109;&#30340;&#23398;&#20064;&#30446;&#26631;&#65292;&#29992;&#20110;&#31232;&#30095;&#32534;&#30721;&#21442;&#25968;&#30340;&#23398;&#20064;&#65292;&#36890;&#36807;&#38750;&#24179;&#20961;&#30340;&#21518;&#39564;&#36924;&#36817;&#21644;&#35299;&#26512;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#23454;&#29616;&#20102;&#26631;&#20934;&#31232;&#30095;&#32534;&#30721;&#30340;&#23398;&#20064;&#65292;&#22312;&#25968;&#20540;&#23454;&#39564;&#20013;&#35777;&#26126;&#20102;&#20854;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#20934;&#27010;&#29575;&#31232;&#30095;&#32534;&#30721;&#20551;&#35774;&#25289;&#26222;&#25289;&#26031;&#20808;&#39564;&#12289;&#20174;&#28508;&#22312;&#21040;&#21487;&#35266;&#27979;&#30340;&#32447;&#24615;&#26144;&#23556;&#20197;&#21450;&#39640;&#26031;&#21487;&#35266;&#27979;&#20998;&#24067;&#12290;&#25105;&#20204;&#22312;&#36825;&#37324;&#23548;&#20986;&#20102;&#19968;&#20010;&#20165;&#22522;&#20110;&#29109;&#30340;&#23398;&#20064;&#30446;&#26631;&#65292;&#29992;&#20110;&#26631;&#20934;&#31232;&#30095;&#32534;&#30721;&#30340;&#21442;&#25968;&#12290;&#36825;&#20010;&#26032;&#30340;&#21464;&#20998;&#30446;&#26631;&#20855;&#26377;&#20197;&#19979;&#29305;&#28857;&#65306;&#65288;A&#65289;&#19982;MAP&#36924;&#36817;&#19981;&#21516;&#65292;&#23427;&#20351;&#29992;&#20102;&#27010;&#29575;&#25512;&#29702;&#30340;&#38750;&#24179;&#20961;&#21518;&#39564;&#36924;&#36817;&#65307;&#65288;B&#65289;&#19982;&#20197;&#21069;&#30340;&#38750;&#24179;&#20961;&#36924;&#36817;&#19981;&#21516;&#65292;&#36825;&#20010;&#26032;&#30340;&#30446;&#26631;&#26159;&#23436;&#20840;&#35299;&#26512;&#30340;&#65307;&#65288;C&#65289;&#35813;&#30446;&#26631;&#20801;&#35768;&#19968;&#31181;&#26032;&#30340;&#21407;&#21017;&#24615;&#30340;&#36864;&#28779;&#24418;&#24335;&#12290;&#30446;&#26631;&#30340;&#23548;&#20986;&#39318;&#20808;&#36890;&#36807;&#35777;&#26126;&#26631;&#20934;ELBO&#30446;&#26631;&#25910;&#25947;&#21040;&#29109;&#30340;&#21644;&#65292;&#36825;&#19982;&#20855;&#26377;&#39640;&#26031;&#20808;&#39564;&#30340;&#29983;&#25104;&#27169;&#22411;&#30340;&#26368;&#36817;&#31867;&#20284;&#32467;&#26524;&#30456;&#21305;&#37197;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;ELBO&#31561;&#20110;&#29109;&#30340;&#26465;&#20214;&#20855;&#26377;&#35299;&#26512;&#35299;&#65292;&#20174;&#32780;&#24471;&#21040;&#20102;&#23436;&#20840;&#35299;&#26512;&#30340;&#30446;&#26631;&#12290;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#23398;&#20064;&#36924;&#30495;&#24615;&#30340;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Standard probabilistic sparse coding assumes a Laplace prior, a linear mapping from latents to observables, and Gaussian observable distributions. We here derive a solely entropy-based learning objective for the parameters of standard sparse coding. The novel variational objective has the following features: (A) unlike MAP approximations, it uses non-trivial posterior approximations for probabilistic inference; (B) unlike for previous non-trivial approximations, the novel objective is fully analytical; and (C) the objective allows for a novel principled form of annealing. The objective is derived by first showing that the standard ELBO objective converges to a sum of entropies, which matches similar recent results for generative models with Gaussian priors. The conditions under which the ELBO becomes equal to entropies are then shown to have analytical solutions, which leads to the fully analytical objective. Numerical experiments are used to demonstrate the feasibility of learning wit
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#25511;&#21046;&#21464;&#37327;&#30340;&#26041;&#27861;&#31283;&#23450;Shapley&#20540;&#30340;&#20272;&#35745;&#65292;&#20943;&#23569;&#20102;&#27169;&#22411;&#35299;&#37322;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#36866;&#29992;&#20110;&#20219;&#20309;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2310.07672</link><description>&lt;p&gt;
&#29992;&#25511;&#21046;&#21464;&#37327;&#31283;&#23450;Shapley&#20540;&#30340;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Stabilizing Estimates of Shapley Values with Control Variates. (arXiv:2310.07672v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07672
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#25511;&#21046;&#21464;&#37327;&#30340;&#26041;&#27861;&#31283;&#23450;Shapley&#20540;&#30340;&#20272;&#35745;&#65292;&#20943;&#23569;&#20102;&#27169;&#22411;&#35299;&#37322;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#36866;&#29992;&#20110;&#20219;&#20309;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Shapley&#20540;&#26159;&#35299;&#37322;&#40657;&#30418;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#39044;&#27979;&#26368;&#27969;&#34892;&#30340;&#24037;&#20855;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#35745;&#31639;&#25104;&#26412;&#24456;&#39640;&#65292;&#22240;&#27492;&#37319;&#29992;&#25277;&#26679;&#36817;&#20284;&#26469;&#20943;&#23569;&#19981;&#30830;&#23450;&#24615;&#12290;&#20026;&#20102;&#31283;&#23450;&#36825;&#20123;&#27169;&#22411;&#35299;&#37322;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25511;&#21046;&#21464;&#37327;&#30340;&#33945;&#29305;&#21345;&#27931;&#25216;&#26415;&#30340;&#26041;&#27861;&#65292;&#31216;&#20026;ControlSHAP&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36866;&#29992;&#20110;&#20219;&#20309;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#24182;&#19988;&#20960;&#20046;&#19981;&#38656;&#35201;&#39069;&#22806;&#30340;&#35745;&#31639;&#25110;&#24314;&#27169;&#24037;&#20316;&#12290;&#22312;&#22810;&#20010;&#39640;&#32500;&#25968;&#25454;&#38598;&#19978;&#65292;&#25105;&#20204;&#21457;&#29616;&#23427;&#21487;&#20197;&#26174;&#33879;&#20943;&#23569;Shapley&#20272;&#35745;&#30340;&#33945;&#29305;&#21345;&#27931;&#21464;&#24322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Shapley values are among the most popular tools for explaining predictions of blackbox machine learning models. However, their high computational cost motivates the use of sampling approximations, inducing a considerable degree of uncertainty. To stabilize these model explanations, we propose ControlSHAP, an approach based on the Monte Carlo technique of control variates. Our methodology is applicable to any machine learning model and requires virtually no extra computation or modeling effort. On several high-dimensional datasets, we find it can produce dramatic reductions in the Monte Carlo variability of Shapley estimates.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20013;&#24515;&#32479;&#35745;&#37327;&#8212;&#8212;&#26368;&#36817;&#37051;&#27979;&#24230;&#65292;&#24182;&#36890;&#36807;&#22343;&#21248;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#21644;&#19968;&#31181;&#22343;&#21248;&#30340;&#38750;&#28176;&#36817;&#30028;&#38480;&#30740;&#31350;&#20102;&#23427;&#12290;&#35813;&#27979;&#24230;&#21487;&#33021;&#20026;&#25512;&#26029;&#25552;&#20379;&#20102;&#19968;&#31181;&#26367;&#20195;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2110.15083</link><description>&lt;p&gt;
&#26368;&#36817;&#37051;&#36807;&#31243;&#65306;&#24369;&#25910;&#25947;&#21644;&#38750;&#28176;&#36817;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Nearest neighbor process: weak convergence and non-asymptotic bound. (arXiv:2110.15083v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.15083
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20013;&#24515;&#32479;&#35745;&#37327;&#8212;&#8212;&#26368;&#36817;&#37051;&#27979;&#24230;&#65292;&#24182;&#36890;&#36807;&#22343;&#21248;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#21644;&#19968;&#31181;&#22343;&#21248;&#30340;&#38750;&#28176;&#36817;&#30028;&#38480;&#30740;&#31350;&#20102;&#23427;&#12290;&#35813;&#27979;&#24230;&#21487;&#33021;&#20026;&#25512;&#26029;&#25552;&#20379;&#20102;&#19968;&#31181;&#26367;&#20195;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#24182;&#30740;&#31350;&#20102;&#30001;&#32473;&#23450;&#28857;&#30340;&#26368;&#36817;&#37051;&#25152;&#24471;&#21040;&#30340;&#32463;&#39564;&#27979;&#24230;&#8212;&#8212;&#26368;&#36817;&#37051;&#27979;&#24230;&#20316;&#20026;&#19968;&#31181;&#20013;&#24515;&#32479;&#35745;&#37327;&#12290;&#39318;&#20808;&#65292;&#22312;&#24213;&#23618;&#20989;&#25968;&#31867;&#19978;&#28385;&#36275;&#65288;&#21453;&#26144;&#26368;&#36817;&#37051;&#31639;&#27861;&#30340;&#26412;&#22320;&#21270;&#29305;&#24615;&#30340;&#65289;&#65288;&#26412;&#22320;&#65289;&#25903;&#25745;&#29109;&#26465;&#20214;&#19979;&#65292;&#23558;&#30456;&#20851;&#32463;&#39564;&#36807;&#31243;&#35777;&#26126;&#20026;&#28385;&#36275;&#22343;&#21248;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#12290;&#20854;&#27425;&#65292;&#22312;&#32479;&#19968;&#29109;&#25968;&#30340;&#33879;&#21517;&#26465;&#20214;&#65288;&#36890;&#24120;&#31216;&#20026;Vapnik-Chervonenkis&#65289;&#19979;&#24314;&#31435;&#20102;&#19968;&#31181;&#22343;&#21248;&#30340;&#38750;&#28176;&#36817;&#30028;&#38480;&#12290;&#22312;&#22343;&#21248;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#20013;&#25152;&#33719;&#24471;&#30340;&#39640;&#26031;&#26497;&#38480;&#30340;&#21327;&#26041;&#24046;&#31561;&#20110;&#26465;&#20214;&#21327;&#26041;&#24046;&#31639;&#23376;&#65288;&#32473;&#20986;&#20852;&#36259;&#28857;&#65289;&#12290;&#36825;&#25552;&#31034;&#20102;&#19968;&#31181;&#21487;&#33021;&#24615;&#65292;&#21363;&#22312;&#20351;&#29992;&#30456;&#21516;&#30340;&#25512;&#29702;&#26041;&#24335;&#20294;&#20165;&#20351;&#29992;&#26368;&#36817;&#37051;&#32780;&#19981;&#26159;&#20840;&#37096;&#26367;&#25442;&#26631;&#20934;&#32463;&#39564;&#27979;&#24230;&#30340;&#26631;&#20934;&#26041;&#27861;&#30340;&#24773;&#20917;&#19979;&#65292;&#25193;&#23637;&#26631;&#20934;&#26041;&#27861; - &#38750;&#23616;&#37096;&#12290;
&lt;/p&gt;
&lt;p&gt;
The empirical measure resulting from the nearest neighbors to a given point \textit{the nearest neighbor measure} - is introduced and studied as a central statistical quantity. First, the associated empirical process is shown to satisfy a uniform central limit theorem under a (local) bracketing entropy condition on the underlying class of functions (reflecting the localizing nature of the nearest neighbor algorithm). Second a uniform non-asymptotic bound is established under a well-known condition, often referred to as Vapnik-Chervonenkis, on the uniform entropy numbers. The covariance of the Gaussian limit obtained in the uniform central limit theorem is equal to the conditional covariance operator (given the point of interest). This suggests the possibility of extending standard approaches - non local - replacing simply the standard empirical measure by the nearest neighbor measure while using the same way of making inference but with the nearest neighbors only instead of the full 
&lt;/p&gt;</description></item></channel></rss>