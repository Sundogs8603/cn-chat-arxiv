<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;kNN&#31639;&#27861;&#36827;&#34892;&#26465;&#20214;&#22343;&#20540;&#21644;&#26041;&#24046;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#37319;&#29992;&#20102;&#33258;&#21160;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#21464;&#37327;&#36873;&#25321;&#25216;&#26415;&#65292;&#25552;&#39640;&#20102;&#20272;&#35745;&#30340;&#20934;&#30830;&#24615;&#21644;&#24615;&#33021;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01635</link><description>&lt;p&gt;
kNN&#31639;&#27861;&#29992;&#20110;&#26465;&#20214;&#22343;&#20540;&#21644;&#26041;&#24046;&#20272;&#35745;&#65292;&#20855;&#26377;&#33258;&#21160;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#21464;&#37327;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
kNN Algorithm for Conditional Mean and Variance Estimation with Automated Uncertainty Quantification and Variable Selection
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01635
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;kNN&#31639;&#27861;&#36827;&#34892;&#26465;&#20214;&#22343;&#20540;&#21644;&#26041;&#24046;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#37319;&#29992;&#20102;&#33258;&#21160;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#21464;&#37327;&#36873;&#25321;&#25216;&#26415;&#65292;&#25552;&#39640;&#20102;&#20272;&#35745;&#30340;&#20934;&#30830;&#24615;&#21644;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;kNN&#30340;&#22238;&#24402;&#26041;&#27861;&#65292;&#23558;&#20256;&#32479;&#30340;&#38750;&#21442;&#25968;kNN&#27169;&#22411;&#30340;&#21487;&#25193;&#23637;&#24615;&#21644;&#36866;&#24212;&#24615;&#19982;&#19968;&#31181;&#26032;&#30340;&#21464;&#37327;&#36873;&#25321;&#25216;&#26415;&#30456;&#32467;&#21512;&#12290;&#35813;&#26041;&#27861;&#20027;&#35201;&#30446;&#26631;&#26159;&#20934;&#30830;&#20272;&#35745;&#38543;&#26426;&#21709;&#24212;&#21464;&#37327;&#30340;&#26465;&#20214;&#22343;&#20540;&#21644;&#26041;&#24046;&#65292;&#20174;&#32780;&#26377;&#25928;&#22320;&#25551;&#36848;&#21508;&#31181;&#24773;&#26223;&#19979;&#30340;&#26465;&#20214;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21253;&#21547;&#20102;&#19968;&#20010;&#20581;&#22766;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26426;&#21046;&#65292;&#21033;&#29992;&#25105;&#20204;&#20043;&#21069;&#20851;&#20110;&#26465;&#20214;&#22343;&#20540;&#21644;&#26041;&#24046;&#30340;&#20272;&#35745;&#24037;&#20316;&#12290; kNN&#30340;&#24212;&#29992;&#30830;&#20445;&#20102;&#22312;&#39044;&#27979;&#21306;&#38388;&#26102;&#21487;&#25193;&#23637;&#30340;&#35745;&#31639;&#25928;&#29575;&#21644;&#19982;&#26368;&#20248;&#38750;&#21442;&#25968;&#36895;&#29575;&#30456;&#19968;&#33268;&#30340;&#32479;&#35745;&#20934;&#30830;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;kNN&#21322;&#21442;&#25968;&#31639;&#27861;&#26469;&#20272;&#35745;&#32771;&#34385;&#21327;&#21464;&#37327;&#30340;ROC&#26354;&#32447;&#12290;&#23545;&#20110;&#36873;&#25321;&#24179;&#28369;&#21442;&#25968;k&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20855;&#26377;&#29702;&#35770;&#20445;&#35777;&#30340;&#31639;&#27861;&#12290;&#21464;&#37327;&#36873;&#25321;&#30340;&#24341;&#20837;&#26174;&#33879;&#25552;&#39640;&#20102;&#35813;&#26041;&#27861;&#30456;&#23545;&#20110;&#20256;&#32479;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we introduce a kNN-based regression method that synergizes the scalability and adaptability of traditional non-parametric kNN models with a novel variable selection technique. This method focuses on accurately estimating the conditional mean and variance of random response variables, thereby effectively characterizing conditional distributions across diverse scenarios.Our approach incorporates a robust uncertainty quantification mechanism, leveraging our prior estimation work on conditional mean and variance. The employment of kNN ensures scalable computational efficiency in predicting intervals and statistical accuracy in line with optimal non-parametric rates. Additionally, we introduce a new kNN semi-parametric algorithm for estimating ROC curves, accounting for covariates. For selecting the smoothing parameter k, we propose an algorithm with theoretical guarantees.Incorporation of variable selection enhances the performance of the method significantly over convention
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#22788;&#29702;&#20855;&#26377;&#20219;&#24847;&#31867;&#22411;&#26410;&#30693;&#36229;&#21442;&#25968;&#30340;&#24773;&#20917;&#65292;&#24182;&#20855;&#26377;&#26080;&#36951;&#25022;&#29305;&#24615;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01632</link><description>&lt;p&gt;
&#36229;&#36234;&#23610;&#24230;&#65306;&#20855;&#26377;&#20219;&#24847;&#31867;&#22411;&#26410;&#30693;&#36229;&#21442;&#25968;&#30340;&#26080;&#36951;&#25022;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Beyond Lengthscales: No-regret Bayesian Optimisation With Unknown Hyperparameters Of Any Type
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01632
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#65292;&#21487;&#20197;&#22788;&#29702;&#20855;&#26377;&#20219;&#24847;&#31867;&#22411;&#26410;&#30693;&#36229;&#21442;&#25968;&#30340;&#24773;&#20917;&#65292;&#24182;&#20855;&#26377;&#26080;&#36951;&#25022;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#38656;&#35201;&#25311;&#21512;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#65292;&#32780;&#25311;&#21512;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#38656;&#35201;&#25351;&#23450;&#36229;&#21442;&#25968; - &#22823;&#37096;&#20998;&#29702;&#35770;&#25991;&#29486;&#20551;&#35774;&#36825;&#20123;&#36229;&#21442;&#25968;&#26159;&#24050;&#30693;&#30340;&#12290;&#20043;&#21069;&#30340;&#29702;&#35770;&#30740;&#31350;&#36890;&#24120;&#20551;&#35774;&#25968;&#25454;&#22312;&#31354;&#38388;&#20013;&#22343;&#21248;&#22635;&#20805;&#65292;&#32780;&#24120;&#29992;&#30340;&#39640;&#26031;&#36807;&#31243;&#36229;&#21442;&#25968;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#22120;&#21482;&#26377;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#25165;&#26159;&#19968;&#33268;&#30340;&#12290;&#28982;&#32780;&#65292;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#65292;&#25968;&#25454;&#19981;&#19968;&#23450;&#28385;&#36275;&#36825;&#31181;&#22343;&#21248;&#22635;&#20805;&#30340;&#26465;&#20214;&#12290;&#30001;&#20110;&#26080;&#27861;&#20445;&#35777;&#36229;&#21442;&#25968;&#20272;&#35745;&#30340;&#27491;&#30830;&#24615;&#65292;&#24182;&#19988;&#36825;&#20123;&#36229;&#21442;&#25968;&#21487;&#20197;&#26174;&#33879;&#24433;&#21709;&#39640;&#26031;&#36807;&#31243;&#25311;&#21512;&#65292;&#22240;&#27492;&#23545;&#20855;&#26377;&#26410;&#30693;&#36229;&#21442;&#25968;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#36827;&#34892;&#29702;&#35770;&#20998;&#26512;&#38750;&#24120;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#20043;&#21069;&#25552;&#20986;&#30340;&#20855;&#26377;&#26080;&#36951;&#25022;&#29305;&#24615;&#30340;&#31639;&#27861;&#20165;&#33021;&#22788;&#29702;&#29305;&#27530;&#24773;&#20917;&#19979;&#30340;&#26410;&#30693;&#38271;&#24230;&#23610;&#24230;&#12289;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#33539;&#25968;&#65292;&#24182;&#19988;&#20165;&#36866;&#29992;&#20110;&#39057;&#29575;&#27966;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#21629;&#21517;&#20026;HE-GP-UCB&#65292;&#23427;&#26159;&#31532;&#19968;&#20010;&#20855;&#26377;&#26080;&#36951;&#25022;&#29305;&#24615;&#30340;&#31639;&#27861;&#65292;&#22312;&#20855;&#26377;&#26410;&#30693;&#36229;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#36125;&#21494;&#26031;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian optimisation requires fitting a Gaussian process model, which in turn requires specifying hyperparameters - most of the theoretical literature assumes those hyperparameters are known. The commonly used maximum likelihood estimator for hyperparameters of the Gaussian process is consistent only if the data fills the space uniformly, which does not have to be the case in Bayesian optimisation. Since no guarantees exist regarding the correctness of hyperparameter estimation, and those hyperparameters can significantly affect the Gaussian process fit, theoretical analysis of Bayesian optimisation with unknown hyperparameters is very challenging. Previously proposed algorithms with the no-regret property were only able to handle the special case of unknown lengthscales, reproducing kernel Hilbert space norm and applied only to the frequentist case. We propose a novel algorithm, HE-GP-UCB, which is the first algorithm enjoying the no-regret property in the case of unknown hyperparame
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#20854;&#20013;&#20351;&#29992;&#24191;&#20041;&#35821;&#27861;&#35268;&#21017;&#65288;GGRs&#65289;&#26469;&#23454;&#29616;&#32452;&#21512;&#19968;&#33324;&#21270;&#65292;&#23558;&#20854;&#35270;&#20026;&#36716;&#23548;&#20219;&#21153;&#20013;&#30340;&#23545;&#31216;&#24615;&#32422;&#26463;&#12290;&#35813;&#26694;&#26550;&#19981;&#20165;&#24418;&#24335;&#21270;&#20102;&#35821;&#35328;&#36716;&#23548;&#30340;&#24191;&#20041;&#23545;&#31216;&#24615;&#27010;&#24565;&#65292;&#36824;&#19982;&#24378;&#21270;&#23398;&#20064;&#21644;&#20854;&#20182;&#30740;&#31350;&#39046;&#22495;&#26377;&#20851;&#32852;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01629</link><description>&lt;p&gt;
&#12298;&#35770;&#25991;&#26631;&#39064;&#65306;&#24191;&#20041;&#35821;&#27861;&#35268;&#21017;&#21644;&#22522;&#20110;&#32467;&#26500;&#30340;&#19968;&#33324;&#21270;&#8212;&#8212;&#23545;&#20110;&#35789;&#27719;&#20219;&#21153;&#21644;&#36716;&#23548;&#30340;&#32463;&#20856;&#31561;&#21464;&#24615;&#20043;&#22806;&#30340;&#19968;&#33324;&#21270;&#30340;&#31435;&#22330;&#35770;&#25991;&#12299;
&lt;/p&gt;
&lt;p&gt;
Position Paper: Generalized grammar rules and structure-based generalization beyond classical equivariance for lexical tasks and transduction
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01629
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#20854;&#20013;&#20351;&#29992;&#24191;&#20041;&#35821;&#27861;&#35268;&#21017;&#65288;GGRs&#65289;&#26469;&#23454;&#29616;&#32452;&#21512;&#19968;&#33324;&#21270;&#65292;&#23558;&#20854;&#35270;&#20026;&#36716;&#23548;&#20219;&#21153;&#20013;&#30340;&#23545;&#31216;&#24615;&#32422;&#26463;&#12290;&#35813;&#26694;&#26550;&#19981;&#20165;&#24418;&#24335;&#21270;&#20102;&#35821;&#35328;&#36716;&#23548;&#30340;&#24191;&#20041;&#23545;&#31216;&#24615;&#27010;&#24565;&#65292;&#36824;&#19982;&#24378;&#21270;&#23398;&#20064;&#21644;&#20854;&#20182;&#30740;&#31350;&#39046;&#22495;&#26377;&#20851;&#32852;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32452;&#21512;&#19968;&#33324;&#21270;&#26159;&#20154;&#31867;&#23398;&#20064;&#35789;&#27719;&#19982;&#29616;&#26377;&#31070;&#32463;&#32593;&#32476;&#20043;&#38388;&#30340;&#20027;&#35201;&#24046;&#24322;&#20043;&#19968;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#29992;&#20110;&#26500;&#24314;&#33021;&#22815;&#20351;&#29992;&#24191;&#20041;&#35821;&#27861;&#35268;&#21017;&#65288;GGRs&#65289;&#36827;&#34892;&#32452;&#21512;&#19968;&#33324;&#21270;&#30340;&#27169;&#22411;&#65292;GGRs&#26159;&#19968;&#31867;&#22522;&#20110;&#23545;&#31216;&#24615;&#30340;&#36716;&#23548;&#20219;&#21153;&#30340;&#32452;&#21512;&#32422;&#26463;&#65292;&#25105;&#20204;&#23558;&#20854;&#35270;&#20026;&#21463;&#29289;&#29702;&#23398;&#20219;&#21153;&#20013;&#31561;&#21464;&#24615;&#32422;&#26463;&#21551;&#21457;&#30340;&#36716;&#23548;&#31867;&#27604;&#12290;&#38500;&#20102;&#20026;&#35821;&#35328;&#36716;&#23548;&#24418;&#24335;&#21270;&#24191;&#20041;&#30340;&#23545;&#31216;&#24615;&#27010;&#24565;&#20043;&#22806;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#36275;&#22815;&#36890;&#29992;&#65292;&#21487;&#20197;&#21253;&#21547;&#35768;&#22810;&#29616;&#26377;&#24037;&#20316;&#20316;&#20026;&#29305;&#20363;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20851;&#20110;&#22914;&#20309;&#23454;&#29616;GGRs&#30340;&#24819;&#27861;&#65292;&#24182;&#22312;&#27492;&#36807;&#31243;&#20013;&#19982;&#24378;&#21270;&#23398;&#20064;&#21644;&#20854;&#20182;&#30740;&#31350;&#39046;&#22495;&#24314;&#31435;&#20102;&#32852;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;
Compositional generalization is one of the main properties which differentiates lexical learning in humans from state-of-art neural networks. We propose a general framework for building models that can generalize compositionally using the concept of Generalized Grammar Rules (GGRs), a class of symmetry-based compositional constraints for transduction tasks, which we view as a transduction analogue of equivariance constraints in physics-inspired tasks. Besides formalizing generalized notions of symmetry for language transduction, our framework is general enough to contain many existing works as special cases. We present ideas on how GGRs might be implemented, and in the process draw connections to reinforcement learning and other areas of research.
&lt;/p&gt;</description></item><item><title>L2G2G&#26159;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#23616;&#37096;&#21040;&#20840;&#23616;&#32593;&#32476;&#23884;&#20837;&#26041;&#27861;&#65292;&#36890;&#36807;&#21160;&#24577;&#21516;&#27493;&#28508;&#22312;&#33410;&#28857;&#34920;&#31034;&#20197;&#25552;&#39640;GAE&#30340;&#20934;&#30830;&#24615;&#65292;&#24182;&#21033;&#29992;&#35299;&#30721;&#22120;&#35745;&#31639;&#21482;&#26377;&#26412;&#22320;&#22270;&#22359;&#25439;&#22833;&#65292;&#20174;&#32780;&#26356;&#22909;&#22320;&#21033;&#29992;&#20102;&#22270;&#30340;&#20449;&#24687;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01614</link><description>&lt;p&gt;
L2G2G: &#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#23616;&#37096;&#21040;&#20840;&#23616;&#32593;&#32476;&#23884;&#20837;&#26041;&#27861;&#65292;&#22522;&#20110;&#22270;&#33258;&#21160;&#32534;&#30721;&#22120;
&lt;/p&gt;
&lt;p&gt;
L2G2G: a Scalable Local-to-Global Network Embedding with Graph Autoencoders
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01614
&lt;/p&gt;
&lt;p&gt;
L2G2G&#26159;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#23616;&#37096;&#21040;&#20840;&#23616;&#32593;&#32476;&#23884;&#20837;&#26041;&#27861;&#65292;&#36890;&#36807;&#21160;&#24577;&#21516;&#27493;&#28508;&#22312;&#33410;&#28857;&#34920;&#31034;&#20197;&#25552;&#39640;GAE&#30340;&#20934;&#30830;&#24615;&#65292;&#24182;&#21033;&#29992;&#35299;&#30721;&#22120;&#35745;&#31639;&#21482;&#26377;&#26412;&#22320;&#22270;&#22359;&#25439;&#22833;&#65292;&#20174;&#32780;&#26356;&#22909;&#22320;&#21033;&#29992;&#20102;&#22270;&#30340;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#20998;&#26512;&#23454;&#38469;&#32593;&#32476;&#65292;&#22270;&#34920;&#31034;&#23398;&#20064;&#26159;&#19968;&#31181;&#24120;&#29992;&#24037;&#20855;&#12290;&#36825;&#20123;&#26041;&#27861;&#65292;&#22914;&#22270;&#33258;&#21160;&#32534;&#30721;&#22120;(GAE)&#65292;&#36890;&#24120;&#20381;&#36182;&#20110;&#20302;&#32500;&#34920;&#31034;&#65292;&#20063;&#31216;&#20026;&#23884;&#20837;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#25439;&#22833;&#20989;&#25968;&#33719;&#24471;;&#36825;&#20123;&#23884;&#20837;&#19982;&#35299;&#30721;&#22120;&#19968;&#36215;&#29992;&#20110;&#33410;&#28857;&#20998;&#31867;&#21644;&#36793;&#39044;&#27979;&#31561;&#19979;&#28216;&#20219;&#21153;&#12290;&#34429;&#28982;GAE&#24448;&#24448;&#30456;&#24403;&#20934;&#30830;&#65292;&#20294;&#23384;&#22312;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#12290;&#20026;&#20102;&#25913;&#21892;&#36895;&#24230;&#65292;Local2Global&#26041;&#27861;&#36890;&#36807;&#22522;&#20110;&#29305;&#24449;&#21521;&#37327;&#21516;&#27493;&#30340;&#22270;&#22359;&#23884;&#20837;&#30456;&#32467;&#21512;&#65292;&#26174;&#31034;&#20986;&#24555;&#36895;&#19988;&#20934;&#30830;&#30340;&#25928;&#26524;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;L2G2G&#65292;&#19968;&#31181;_Local2Global&#26041;&#27861;&#65292;&#23427;&#22312;&#19981;&#29306;&#29298;&#21487;&#25193;&#23637;&#24615;&#30340;&#24773;&#20917;&#19979;&#25552;&#39640;&#20102;GAE&#30340;&#20934;&#30830;&#24615;&#12290;&#36825;&#31181;&#25913;&#36827;&#26159;&#36890;&#36807;&#22312;&#35757;&#32451;GAE&#26399;&#38388;&#21160;&#24577;&#21516;&#27493;&#28508;&#22312;&#33410;&#28857;&#34920;&#31034;&#26469;&#23454;&#29616;&#30340;&#12290;&#23427;&#36824;&#21463;&#30410;&#20110;&#35299;&#30721;&#22120;&#35745;&#31639;&#21482;&#26377;&#26412;&#22320;&#22270;&#22359;&#25439;&#22833;&#12290;&#22240;&#27492;&#65292;&#27599;&#20010;&#26102;&#20195;&#20013;&#30340;&#26412;&#22320;&#23884;&#20837;&#23545;&#40784;&#21033;&#29992;&#20102;&#26356;&#22810;&#26469;&#33258;&#22270;&#30340;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
For analysing real-world networks, graph representation learning is a popular tool. These methods, such as a graph autoencoder (GAE), typically rely on low-dimensional representations, also called embeddings, which are obtained through minimising a loss function; these embeddings are used with a decoder for downstream tasks such as node classification and edge prediction. While GAEs tend to be fairly accurate, they suffer from scalability issues. For improved speed, a Local2Global approach, which combines graph patch embeddings based on eigenvector synchronisation, was shown to be fast and achieve good accuracy. Here we propose L2G2G, a Local2Global method which improves GAE accuracy without sacrificing scalability. This improvement is achieved by dynamically synchronising the latent node representations, while training the GAEs. It also benefits from the decoder computing an only local patch loss. Hence, aligning the local embeddings in each epoch utilises more information from the gr
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20998;&#26512;&#20102;&#19968;&#31181;&#23567;&#25209;&#37327;&#36817;&#20284;&#32447;&#24615;&#31639;&#27861;&#65292;&#22312;&#30697;&#38453;&#24863;&#30693;&#38382;&#39064;&#20013;&#65292;&#36890;&#36807;&#39044;&#27979;&#35823;&#24046;&#21644;&#30830;&#23450;&#24615;&#36882;&#24402;&#65292;&#23637;&#31034;&#20102;&#22914;&#20309;&#36827;&#34892;&#38750;&#28176;&#36817;&#30340;&#36229;&#21442;&#25968;&#35843;&#20248;&#12290;&#20998;&#26512;&#32467;&#26524;&#26174;&#31034;&#65292;&#35813;&#26041;&#27861;&#26159;&#38543;&#26426;&#30340;&#65292;&#20294;&#21487;&#20197;&#20174;&#19968;&#20010;&#26412;&#22320;&#21021;&#22987;&#21270;&#25910;&#25947;&#21040;&#19968;&#20010;&#32479;&#35745;&#35823;&#24046;&#36793;&#30028;&#65292;&#24182;&#25581;&#31034;&#20102;&#25209;&#37327;&#22823;&#23567;&#12289;&#27493;&#38271;&#21644;&#22122;&#22768;&#27700;&#24179;&#23545;&#25910;&#25947;&#36895;&#24230;&#21644;&#32479;&#35745;&#20272;&#35745;&#35823;&#24046;&#30340;&#24433;&#21709;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01599</link><description>&lt;p&gt;
&#36890;&#36807;&#36712;&#36857;&#39044;&#27979;&#36827;&#34892;&#36229;&#21442;&#25968;&#35843;&#20248;&#65306;&#30697;&#38453;&#24863;&#30693;&#20013;&#30340;&#38543;&#26426;&#36817;&#20284;&#32447;&#24615;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Hyperparameter tuning via trajectory predictions: Stochastic prox-linear methods in matrix sensing
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01599
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20998;&#26512;&#20102;&#19968;&#31181;&#23567;&#25209;&#37327;&#36817;&#20284;&#32447;&#24615;&#31639;&#27861;&#65292;&#22312;&#30697;&#38453;&#24863;&#30693;&#38382;&#39064;&#20013;&#65292;&#36890;&#36807;&#39044;&#27979;&#35823;&#24046;&#21644;&#30830;&#23450;&#24615;&#36882;&#24402;&#65292;&#23637;&#31034;&#20102;&#22914;&#20309;&#36827;&#34892;&#38750;&#28176;&#36817;&#30340;&#36229;&#21442;&#25968;&#35843;&#20248;&#12290;&#20998;&#26512;&#32467;&#26524;&#26174;&#31034;&#65292;&#35813;&#26041;&#27861;&#26159;&#38543;&#26426;&#30340;&#65292;&#20294;&#21487;&#20197;&#20174;&#19968;&#20010;&#26412;&#22320;&#21021;&#22987;&#21270;&#25910;&#25947;&#21040;&#19968;&#20010;&#32479;&#35745;&#35823;&#24046;&#36793;&#30028;&#65292;&#24182;&#25581;&#31034;&#20102;&#25209;&#37327;&#22823;&#23567;&#12289;&#27493;&#38271;&#21644;&#22122;&#22768;&#27700;&#24179;&#23545;&#25910;&#25947;&#36895;&#24230;&#21644;&#32479;&#35745;&#20272;&#35745;&#35823;&#24046;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#38024;&#23545;&#20174;&#34987;&#22122;&#22768;&#27745;&#26579;&#30340;&#31209;1&#39640;&#26031;&#27979;&#37327;&#20013;&#24674;&#22797;&#26410;&#30693;&#31209;1&#30697;&#38453;&#30340;&#38382;&#39064;&#65292;&#20998;&#26512;&#20102;&#19968;&#31181;&#36845;&#20195;&#30340;&#23567;&#25209;&#37327;&#36817;&#20284;&#32447;&#24615;&#31639;&#27861;&#65292;&#24182;&#25512;&#23548;&#20986;&#19968;&#31181;&#30830;&#23450;&#24615;&#36882;&#24402;&#26469;&#39044;&#27979;&#35813;&#26041;&#27861;&#30340;&#35823;&#24046;&#12290;&#20351;&#29992;&#38750;&#28176;&#36817;&#30340;&#26694;&#26550;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#20219;&#20309;&#25209;&#37327;&#22823;&#23567;&#21644;&#22823;&#33539;&#22260;&#30340;&#27493;&#38271;&#65292;&#36825;&#20010;&#39044;&#27979;&#26159;&#20934;&#30830;&#30340;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#25581;&#31034;&#20102;&#36825;&#20010;&#26041;&#27861;&#65292;&#23613;&#31649;&#26159;&#38543;&#26426;&#30340;&#65292;&#20174;&#19968;&#20010;&#26412;&#22320;&#21021;&#22987;&#21270;&#36890;&#36807;&#22266;&#23450;&#27493;&#38271;&#32447;&#24615;&#25910;&#25947;&#21040;&#19968;&#20010;&#32479;&#35745;&#35823;&#24046;&#36793;&#30028;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#36824;&#25581;&#31034;&#20102;&#25209;&#37327;&#22823;&#23567;&#12289;&#27493;&#38271;&#21644;&#22122;&#22768;&#27700;&#24179;&#22914;&#20309;&#24433;&#21709;&#65288;&#32447;&#24615;&#65289;&#25910;&#25947;&#36895;&#24230;&#21644;&#26368;&#32456;&#30340;&#32479;&#35745;&#20272;&#35745;&#35823;&#24046;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#25105;&#20204;&#30340;&#30830;&#23450;&#24615;&#39044;&#27979;&#26469;&#36827;&#34892;&#36229;&#21442;&#25968;&#35843;&#20248;&#65288;&#22914;&#27493;&#38271;&#21644;&#25209;&#37327;&#22823;&#23567;&#30340;&#36873;&#25321;&#65289;&#32780;&#26080;&#38656;&#36816;&#34892;&#20803;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by the desire to understand stochastic algorithms for nonconvex optimization that are robust to their hyperparameter choices, we analyze a mini-batched prox-linear iterative algorithm for the problem of recovering an unknown rank-1 matrix from rank-1 Gaussian measurements corrupted by noise. We derive a deterministic recursion that predicts the error of this method and show, using a non-asymptotic framework, that this prediction is accurate for any batch-size and a large range of step-sizes. In particular, our analysis reveals that this method, though stochastic, converges linearly from a local initialization with a fixed step-size to a statistical error floor. Our analysis also exposes how the batch-size, step-size, and noise level affect the (linear) convergence rate and the eventual statistical estimation error, and we demonstrate how to use our deterministic predictions to perform hyperparameter tuning (e.g. step-size and batch-size selection) without ever running the met
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#28145;&#24230;&#20027;&#21160;&#23398;&#20064;&#20174;&#20914;&#31361;&#25991;&#26412;&#35821;&#26009;&#24211;&#20013;&#36827;&#34892;&#25968;&#25454;&#25366;&#25496;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#36845;&#20195;&#30340;&#20027;&#21160;&#23398;&#20064;&#36807;&#31243;&#65292;&#32467;&#21512;&#22823;&#22411;&#30340;&#20165;&#32534;&#30721;&#22120;&#35821;&#35328;&#27169;&#22411;&#65292;&#21487;&#20197;&#25552;&#21462;&#19982;&#20914;&#31361;&#21160;&#24577;&#30456;&#20851;&#30340;&#23376;&#31867;&#20107;&#20214;&#65292;&#36798;&#21040;&#31867;&#20284;&#20110;&#20154;&#31867;&#30340;&#24615;&#33021;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01577</link><description>&lt;p&gt;
&#26469;&#33258;&#20914;&#31361;&#25991;&#26412;&#35821;&#26009;&#24211;&#30340;&#28145;&#24230;&#20027;&#21160;&#23398;&#20064;&#25968;&#25454;&#25366;&#25496;
&lt;/p&gt;
&lt;p&gt;
Deep Active Learning for Data Mining from Conflict Text Corpora
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01577
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#28145;&#24230;&#20027;&#21160;&#23398;&#20064;&#20174;&#20914;&#31361;&#25991;&#26412;&#35821;&#26009;&#24211;&#20013;&#36827;&#34892;&#25968;&#25454;&#25366;&#25496;&#30340;&#26041;&#27861;&#12290;&#36890;&#36807;&#36845;&#20195;&#30340;&#20027;&#21160;&#23398;&#20064;&#36807;&#31243;&#65292;&#32467;&#21512;&#22823;&#22411;&#30340;&#20165;&#32534;&#30721;&#22120;&#35821;&#35328;&#27169;&#22411;&#65292;&#21487;&#20197;&#25552;&#21462;&#19982;&#20914;&#31361;&#21160;&#24577;&#30456;&#20851;&#30340;&#23376;&#31867;&#20107;&#20214;&#65292;&#36798;&#21040;&#31867;&#20284;&#20110;&#20154;&#31867;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#20998;&#36776;&#29575;&#30340;&#27494;&#35013;&#20914;&#31361;&#20107;&#20214;&#25968;&#25454;&#20197;&#21450;&#30456;&#20851;&#36807;&#31243;&#24050;&#32463;&#36890;&#36807;UCDP GED&#12289;ACLED&#31561;&#25968;&#25454;&#38598;&#24443;&#24213;&#25913;&#21464;&#20102;&#25919;&#27835;&#20105;&#35770;&#30340;&#30740;&#31350;&#12290;&#28982;&#32780;&#65292;&#22823;&#37096;&#20998;&#36825;&#20123;&#25968;&#25454;&#38598;&#20165;&#38480;&#20110;&#25910;&#38598;&#26102;&#31354;&#65288;&#39640;&#20998;&#36776;&#29575;&#65289;&#21644;&#24378;&#24230;&#25968;&#25454;&#12290;&#20851;&#20110;&#30446;&#26631;&#12289;&#25112;&#26415;&#12289;&#30446;&#30340;&#31561;&#21160;&#24577;&#20449;&#24687;&#24456;&#23569;&#34987;&#25910;&#38598;&#65292;&#36825;&#26159;&#22240;&#20026;&#25968;&#25454;&#25910;&#38598;&#30340;&#24037;&#20316;&#37327;&#38750;&#24120;&#22823;&#12290;&#28982;&#32780;&#65292;&#22823;&#37096;&#20998;&#25968;&#25454;&#38598;&#20381;&#36182;&#20110;&#20016;&#23500;&#30340;&#25991;&#26412;&#25968;&#25454;&#24211;&#65292;&#21487;&#20197;&#36827;&#19968;&#27493;&#25366;&#25496;&#19982;&#27599;&#20010;&#20107;&#20214;&#30456;&#20851;&#30340;&#26356;&#22810;&#20449;&#24687;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#24265;&#20215;&#19988;&#39640;&#24615;&#33021;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#20027;&#21160;&#23398;&#20064;&#26469;&#25913;&#36827;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#36890;&#36807;&#39034;&#24207;&#65288;&#26377;&#23548;&#21521;&#30340;&#65289;&#20154;&#24037;&#36755;&#20837;&#30340;&#36845;&#20195;&#36807;&#31243;&#12290;&#28982;&#21518;&#65292;&#20351;&#29992;&#20027;&#21160;&#23398;&#20064;&#36880;&#27493;&#35757;&#32451;&#65288;&#24494;&#35843;&#65289;&#19968;&#20010;&#22823;&#22411;&#30340;&#20165;&#32534;&#30721;&#22120;&#35821;&#35328;&#27169;&#22411;&#65292;&#20197;&#25552;&#21462;&#19982;&#20914;&#31361;&#21160;&#24577;&#30456;&#20851;&#30340;&#23376;&#31867;&#20107;&#20214;&#12290;&#35813;&#26041;&#27861;&#34920;&#29616;&#20986;&#19982;&#20154;&#31867;&#65288;&#37329;&#26631;&#20934;&#65289;&#30456;&#20284;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
High-resolution event data on armed conflict and related processes have revolutionized the study of political contention with datasets like UCDP GED, ACLED etc. However, most of these datasets limit themselves to collecting spatio-temporal (high-resolution) and intensity data. Information on dynamics, such as targets, tactics, purposes etc. are rarely collected owing to the extreme workload of collecting data. However, most datasets rely on a rich corpus of textual data allowing further mining of further information connected to each event. This paper proposes one such approach that is inexpensive and high performance, leveraging active learning - an iterative process of improving a machine learning model based on sequential (guided) human input. Active learning is employed to then step-wise train (fine-tuning) of a large, encoder-only language model adapted for extracting sub-classes of events relating to conflict dynamics. The approach shows performance similar to human (gold-standar
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#32570;&#22833;&#25968;&#25454;&#39044;&#27979;&#30340;&#33258;&#36866;&#24212;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#26469;&#36866;&#24212;&#35266;&#27979;&#29305;&#24449;&#38598;&#65292;&#24182;&#23558;&#22635;&#20805;&#35268;&#21017;&#21644;&#22238;&#24402;&#27169;&#22411;&#21516;&#26102;&#23398;&#20064;&#65292;&#30456;&#27604;&#39034;&#24207;&#23398;&#20064;&#26041;&#27861;&#65292;&#22312;&#25968;&#25454;&#38750;&#23436;&#20840;&#38543;&#26426;&#32570;&#22833;&#24773;&#20917;&#19979;&#65292;&#26041;&#27861;&#23454;&#29616;&#20102;2-10%&#30340;&#20934;&#30830;&#24615;&#25913;&#36827;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01543</link><description>&lt;p&gt;
&#38024;&#23545;&#32570;&#22833;&#25968;&#25454;&#39044;&#27979;&#30340;&#33258;&#36866;&#24212;&#20248;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Adaptive Optimization for Prediction with Missing Data
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01543
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#32570;&#22833;&#25968;&#25454;&#39044;&#27979;&#30340;&#33258;&#36866;&#24212;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#26469;&#36866;&#24212;&#35266;&#27979;&#29305;&#24449;&#38598;&#65292;&#24182;&#23558;&#22635;&#20805;&#35268;&#21017;&#21644;&#22238;&#24402;&#27169;&#22411;&#21516;&#26102;&#23398;&#20064;&#65292;&#30456;&#27604;&#39034;&#24207;&#23398;&#20064;&#26041;&#27861;&#65292;&#22312;&#25968;&#25454;&#38750;&#23436;&#20840;&#38543;&#26426;&#32570;&#22833;&#24773;&#20917;&#19979;&#65292;&#26041;&#27861;&#23454;&#29616;&#20102;2-10%&#30340;&#20934;&#30830;&#24615;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35757;&#32451;&#20855;&#26377;&#32570;&#22833;&#26465;&#30446;&#30340;&#39044;&#27979;&#27169;&#22411;&#26102;&#65292;&#26368;&#24120;&#29992;&#21644;&#22810;&#21151;&#33021;&#30340;&#26041;&#27861;&#26159;&#19968;&#31181;&#27969;&#27700;&#32447;&#25216;&#26415;&#65292;&#39318;&#20808;&#22635;&#20805;&#32570;&#22833;&#26465;&#30446;&#65292;&#28982;&#21518;&#35745;&#31639;&#39044;&#27979;&#32467;&#26524;&#12290;&#26412;&#25991;&#23558;&#32570;&#22833;&#25968;&#25454;&#39044;&#27979;&#35270;&#20026;&#19968;&#20010;&#20004;&#38454;&#27573;&#30340;&#33258;&#36866;&#24212;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27169;&#22411;&#31867;&#21035;&#65292;&#33258;&#36866;&#24212;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#65292;&#20854;&#20013;&#22238;&#24402;&#31995;&#25968;&#33021;&#22815;&#36866;&#24212;&#35266;&#27979;&#29305;&#24449;&#38598;&#12290;&#25105;&#20204;&#34920;&#26126;&#19968;&#20123;&#33258;&#36866;&#24212;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#31561;&#21516;&#20110;&#21516;&#26102;&#23398;&#20064;&#22635;&#20805;&#35268;&#21017;&#21644;&#19979;&#28216;&#32447;&#24615;&#22238;&#24402;&#27169;&#22411;&#32780;&#19981;&#26159;&#39034;&#24207;&#23398;&#20064;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#31181;&#32852;&#21512;&#22635;&#20805;-&#22238;&#24402;&#30340;&#35299;&#37322;&#23558;&#25105;&#20204;&#30340;&#26694;&#26550;&#25512;&#24191;&#21040;&#38750;&#32447;&#24615;&#27169;&#22411;&#12290;&#22312;&#25968;&#25454;&#38750;&#23436;&#20840;&#38543;&#26426;&#32570;&#22833;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#26679;&#22806;&#20934;&#30830;&#24615;&#26041;&#38754;&#23454;&#29616;&#20102;2-10%&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
When training predictive models on data with missing entries, the most widely used and versatile approach is a pipeline technique where we first impute missing entries and then compute predictions. In this paper, we view prediction with missing data as a two-stage adaptive optimization problem and propose a new class of models, adaptive linear regression models, where the regression coefficients adapt to the set of observed features. We show that some adaptive linear regression models are equivalent to learning an imputation rule and a downstream linear regression model simultaneously instead of sequentially. We leverage this joint-impute-then-regress interpretation to generalize our framework to non-linear models. In settings where data is strongly not missing at random, our methods achieve a 2-10% improvement in out-of-sample accuracy.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;PRESTO&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#26144;&#23556;&#20381;&#36182;&#20110;&#28508;&#22312;&#34920;&#31034;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#22810;&#20803;&#23431;&#23449;&#12290;&#35813;&#26694;&#26550;&#20351;&#29992;&#25345;&#32493;&#21516;&#35843;&#26469;&#27979;&#37327;&#28508;&#22312;&#31354;&#38388;&#30340;&#24046;&#24322;&#65292;&#24182;&#32479;&#35745;&#25512;&#29702;&#23427;&#20204;&#30340;&#20998;&#24067;&#12290;&#21487;&#20197;&#29992;&#20110;&#25935;&#24863;&#24615;&#20998;&#26512;&#12289;&#26816;&#27979;&#24322;&#24120;&#23884;&#20837;&#21644;&#39640;&#25928;&#23548;&#33322;&#36229;&#21442;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01514</link><description>&lt;p&gt;
&#26144;&#23556;&#28508;&#22312;&#34920;&#31034;&#30340;&#22810;&#20803;&#23431;&#23449;
&lt;/p&gt;
&lt;p&gt;
Mapping the Multiverse of Latent Representations
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01514
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;PRESTO&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#26144;&#23556;&#20381;&#36182;&#20110;&#28508;&#22312;&#34920;&#31034;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#22810;&#20803;&#23431;&#23449;&#12290;&#35813;&#26694;&#26550;&#20351;&#29992;&#25345;&#32493;&#21516;&#35843;&#26469;&#27979;&#37327;&#28508;&#22312;&#31354;&#38388;&#30340;&#24046;&#24322;&#65292;&#24182;&#32479;&#35745;&#25512;&#29702;&#23427;&#20204;&#30340;&#20998;&#24067;&#12290;&#21487;&#20197;&#29992;&#20110;&#25935;&#24863;&#24615;&#20998;&#26512;&#12289;&#26816;&#27979;&#24322;&#24120;&#23884;&#20837;&#21644;&#39640;&#25928;&#23548;&#33322;&#36229;&#21442;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21709;&#24212;&#26368;&#36817;&#23545;&#36890;&#36807;&#22810;&#20803;&#23431;&#23449;&#20998;&#26512;&#26469;&#24212;&#23545;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#21487;&#38752;&#24615;&#21644;&#31283;&#20581;&#24615;&#38382;&#39064;&#30340;&#21628;&#21505;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;PRESTO&#65292;&#19968;&#31181;&#31995;&#32479;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#26144;&#23556;&#20381;&#36182;&#20110;&#28508;&#22312;&#34920;&#31034;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#22810;&#20803;&#23431;&#23449;&#12290;&#23613;&#31649;&#36825;&#20123;&#27169;&#22411;&#24471;&#21040;&#20102;&#24191;&#27867;&#30340;&#24212;&#29992;&#65292;&#20294;&#23545;&#23427;&#20204;&#23884;&#20837;&#30340;&#21464;&#24322;&#24615;&#20173;&#28982;&#19981;&#34987;&#20805;&#20998;&#29702;&#35299;&#65292;&#23548;&#33268;&#20102;&#19981;&#24517;&#35201;&#30340;&#22797;&#26434;&#24615;&#21644;&#19981;&#21487;&#38752;&#30340;&#34920;&#31034;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#20351;&#29992;&#25345;&#32493;&#21516;&#35843;&#26469;&#34920;&#24449;&#19981;&#21516;&#32452;&#21512;&#30340;&#22810;&#26679;&#21270;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#12289;(&#36229;)&#21442;&#25968;&#37197;&#32622;&#21644;&#25968;&#25454;&#38598;&#25152;&#20135;&#29983;&#30340;&#28508;&#22312;&#31354;&#38388;&#65292;&#20174;&#32780;&#20351;&#25105;&#20204;&#33021;&#22815;&#27979;&#37327;&#23427;&#20204;&#20043;&#38388;&#30340;&#25104;&#23545;(&#38750;)&#30456;&#20284;&#24615;&#24182;&#23545;&#20854;&#20998;&#24067;&#36827;&#34892;&#32479;&#35745;&#25512;&#29702;&#12290;&#27491;&#22914;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#21644;&#23454;&#35777;&#19978;&#25152;&#35777;&#26126;&#30340;&#37027;&#26679;&#65292;&#25105;&#20204;&#30340;&#27969;&#31243;&#20445;&#25345;&#20102;&#28508;&#22312;&#34920;&#31034;&#38598;&#21512;&#30340;&#29702;&#24819;&#29305;&#24615;&#65292;&#21487;&#20197;&#29992;&#20110;&#36827;&#34892;&#25935;&#24863;&#24615;&#20998;&#26512;&#12289;&#26816;&#27979;&#24322;&#24120;&#23884;&#20837;&#25110;&#39640;&#25928;&#26377;&#25928;&#22320;&#23548;&#33322;&#36229;&#21442;&#12290;
&lt;/p&gt;
&lt;p&gt;
Echoing recent calls to counter reliability and robustness concerns in machine learning via multiverse analysis, we present PRESTO, a principled framework for mapping the multiverse of machine-learning models that rely on latent representations. Although such models enjoy widespread adoption, the variability in their embeddings remains poorly understood, resulting in unnecessary complexity and untrustworthy representations. Our framework uses persistent homology to characterize the latent spaces arising from different combinations of diverse machine-learning methods, (hyper)parameter configurations, and datasets, allowing us to measure their pairwise (dis)similarity and statistically reason about their distributions. As we demonstrate both theoretically and empirically, our pipeline preserves desirable properties of collections of latent representations, and it can be leveraged to perform sensitivity analysis, detect anomalous embeddings, or efficiently and effectively navigate hyperpa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23558;&#26641;&#38598;&#25104;&#35299;&#37322;&#20026;&#33258;&#36866;&#24212;&#30340;&#33258;&#27491;&#21017;&#21270;&#24179;&#28369;&#22120;&#65292;&#36890;&#36807;&#37327;&#21270;&#39044;&#27979;&#30340;&#24179;&#28369;&#31243;&#24230;&#24182;&#26681;&#25454;&#27979;&#35797;&#21644;&#35757;&#32451;&#36755;&#20837;&#30340;&#24046;&#24322;&#35843;&#33410;&#24179;&#28369;&#24615;&#65292;&#25552;&#20379;&#20102;&#23545;&#26641;&#38598;&#25104;&#25104;&#21151;&#39537;&#21160;&#22240;&#32032;&#30340;&#26032;&#35265;&#35299;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01502</link><description>&lt;p&gt;
&#20026;&#20160;&#20040;&#38543;&#26426;&#26862;&#26519;&#26377;&#25928;&#65311;&#23558;&#26641;&#38598;&#25104;&#35299;&#37322;&#20026;&#33258;&#36866;&#24212;&#30340;&#33258;&#27491;&#21017;&#21270;&#24179;&#28369;&#22120;&#30340;&#29702;&#35299;
&lt;/p&gt;
&lt;p&gt;
Why do Random Forests Work? Understanding Tree Ensembles as Self-Regularizing Adaptive Smoothers
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01502
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#26641;&#38598;&#25104;&#35299;&#37322;&#20026;&#33258;&#36866;&#24212;&#30340;&#33258;&#27491;&#21017;&#21270;&#24179;&#28369;&#22120;&#65292;&#36890;&#36807;&#37327;&#21270;&#39044;&#27979;&#30340;&#24179;&#28369;&#31243;&#24230;&#24182;&#26681;&#25454;&#27979;&#35797;&#21644;&#35757;&#32451;&#36755;&#20837;&#30340;&#24046;&#24322;&#35843;&#33410;&#24179;&#28369;&#24615;&#65292;&#25552;&#20379;&#20102;&#23545;&#26641;&#38598;&#25104;&#25104;&#21151;&#39537;&#21160;&#22240;&#32032;&#30340;&#26032;&#35265;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#26641;&#38598;&#25104;&#22312;&#25928;&#26524;&#21644;&#24191;&#27867;&#24212;&#29992;&#26041;&#38754;&#34920;&#29616;&#20986;&#21331;&#36234;&#30340;&#33021;&#21147;&#65292;&#20294;&#20854;&#25104;&#21151;&#30340;&#39537;&#21160;&#22240;&#32032;&#23578;&#26410;&#23436;&#20840;&#34987;&#29702;&#35299;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24378;&#35843;&#23558;&#26641;&#38598;&#25104;&#35299;&#37322;&#20026;&#33258;&#36866;&#24212;&#30340;&#33258;&#27491;&#21017;&#21270;&#24179;&#28369;&#22120;&#21487;&#20197;&#25552;&#20379;&#26032;&#30340;&#30452;&#35273;&#21644;&#26356;&#28145;&#20837;&#30340;&#35265;&#35299;&#12290;&#25105;&#20204;&#21033;&#29992;&#36825;&#20010;&#35266;&#28857;&#26469;&#23637;&#31034;&#65292;&#24403;&#23558;&#38543;&#26426;&#21270;&#26641;&#38598;&#25104;&#35270;&#20026;&#24179;&#28369;&#22120;&#26102;&#65292;&#23427;&#20204;&#30340;&#39044;&#27979;&#19981;&#20165;&#27604;&#23427;&#20204;&#25152;&#21253;&#21547;&#30340;&#21333;&#20010;&#26641;&#30340;&#39044;&#27979;&#26356;&#21152;&#24179;&#28369;&#65292;&#32780;&#19988;&#36824;&#26681;&#25454;&#27979;&#35797;&#21644;&#35757;&#32451;&#36755;&#20837;&#20043;&#38388;&#30340;&#24046;&#24322;&#22312;&#27979;&#35797;&#26102;&#36827;&#19968;&#27493;&#35843;&#33410;&#23427;&#20204;&#30340;&#24179;&#28369;&#24615;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#21033;&#29992;&#36825;&#20010;&#27934;&#23519;&#21147;&#37325;&#26032;&#23457;&#35270;&#12289;&#31934;&#28860;&#21644;&#21327;&#35843;&#20102;&#26368;&#36817;&#20004;&#20010;&#23545;&#26862;&#26519;&#25104;&#21151;&#30340;&#35299;&#37322;&#65292;&#36890;&#36807;&#27979;&#37327;&#25152;&#26263;&#31034;&#30340;&#24179;&#28369;&#31243;&#24230;&#26469;&#23458;&#35266;&#22320;&#37327;&#21270;&#26641;&#38598;&#25104;&#30340;&#29468;&#24819;&#34892;&#20026;&#26041;&#24335;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#36229;&#36234;&#20102;&#29616;&#26377;&#30340;&#20851;&#20110;&#26641;&#38598;&#25104;&#25913;&#36827;&#26426;&#21046;&#30340;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Despite their remarkable effectiveness and broad application, the drivers of success underlying ensembles of trees are still not fully understood. In this paper, we highlight how interpreting tree ensembles as adaptive and self-regularizing smoothers can provide new intuition and deeper insight to this topic. We use this perspective to show that, when studied as smoothers, randomized tree ensembles not only make predictions that are quantifiably more smooth than the predictions of the individual trees they consist of, but also further regulate their smoothness at test-time based on the dissimilarity between testing and training inputs. First, we use this insight to revisit, refine and reconcile two recent explanations of forest success by providing a new way of quantifying the conjectured behaviors of tree ensembles objectively by measuring the effective degree of smoothing they imply. Then, we move beyond existing explanations for the mechanisms by which tree ensembles improve upon in
&lt;/p&gt;</description></item><item><title>&#36825;&#31181;&#26041;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#65292;&#20351;&#29992;&#29699;&#35856;&#20989;&#25968;&#20316;&#20026;&#25511;&#21046;&#21464;&#37327;&#26469;&#36817;&#20284;&#35745;&#31639;&#20999;&#29255;&#21326;&#29791;&#26031;&#22374;&#36317;&#31163;&#12290;&#19982;&#33945;&#29305;&#21345;&#32599;&#30456;&#27604;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#25910;&#25947;&#36895;&#24230;&#21644;&#29702;&#35770;&#24615;&#36136;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01493</link><description>&lt;p&gt;
&#20351;&#29992;&#29699;&#35856;&#20989;&#25968;&#20316;&#20026;&#25511;&#21046;&#21464;&#37327;&#30340;&#20999;&#29255;&#21326;&#29791;&#26031;&#22374;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Sliced-Wasserstein Estimation with Spherical Harmonics as Control Variates
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01493
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31181;&#26041;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#65292;&#20351;&#29992;&#29699;&#35856;&#20989;&#25968;&#20316;&#20026;&#25511;&#21046;&#21464;&#37327;&#26469;&#36817;&#20284;&#35745;&#31639;&#20999;&#29255;&#21326;&#29791;&#26031;&#22374;&#36317;&#31163;&#12290;&#19982;&#33945;&#29305;&#21345;&#32599;&#30456;&#27604;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#25910;&#25947;&#36895;&#24230;&#21644;&#29702;&#35770;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20999;&#29255;&#21326;&#29791;&#26031;&#22374;&#65288;SW&#65289;&#36317;&#31163;&#26159;&#27010;&#29575;&#27979;&#24230;&#20043;&#38388;&#30340;&#21326;&#29791;&#26031;&#22374;&#36317;&#31163;&#30340;&#24179;&#22343;&#20540;&#65292;&#32467;&#26524;&#20026;&#30456;&#20851;&#30340;&#19968;&#32500;&#25237;&#24433;&#30340;&#21326;&#29791;&#26031;&#22374;&#36317;&#31163;&#12290;&#22240;&#27492;&#65292;SW&#36317;&#31163;&#21487;&#20197;&#20889;&#25104;&#23545;&#29699;&#38754;&#19978;&#22343;&#21248;&#27979;&#24230;&#30340;&#31215;&#20998;&#65292;&#24182;&#19988;&#21487;&#20197;&#20351;&#29992;&#33945;&#29305;&#21345;&#32599;&#26694;&#26550;&#26469;&#35745;&#31639;SW&#36317;&#31163;&#12290;&#29699;&#35856;&#20989;&#25968;&#26159;&#29699;&#38754;&#19978;&#30340;&#22810;&#39033;&#24335;&#65292;&#23427;&#20204;&#26500;&#25104;&#20102;&#29699;&#38754;&#19978;&#21487;&#31215;&#20989;&#25968;&#38598;&#21512;&#30340;&#27491;&#20132;&#22522;&#12290;&#23558;&#36825;&#20004;&#20010;&#20107;&#23454;&#32467;&#21512;&#22312;&#19968;&#36215;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#65292;&#31216;&#20026;&#29699;&#35856;&#25511;&#21046;&#21464;&#37327;&#65288;SHCV&#65289;&#65292;&#29992;&#20110;&#20351;&#29992;&#29699;&#35856;&#20989;&#25968;&#20316;&#20026;&#25511;&#21046;&#21464;&#37327;&#36817;&#20284;&#35745;&#31639;SW&#36317;&#31163;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#33391;&#22909;&#30340;&#29702;&#35770;&#24615;&#36136;&#65292;&#20363;&#22914;&#22312;&#21464;&#37327;&#20043;&#38388;&#23384;&#22312;&#19968;&#23450;&#24418;&#24335;&#30340;&#32447;&#24615;&#20381;&#36182;&#26102;&#65292;&#28151;&#21512;&#39640;&#26031;&#27979;&#24230;&#30340;&#26080;&#35823;&#24046;&#29305;&#24615;&#12290;&#27492;&#22806;&#65292;&#19982;&#33945;&#29305;&#21345;&#32599;&#30456;&#27604;&#65292;&#24471;&#21040;&#20102;&#26356;&#24555;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Sliced-Wasserstein (SW) distance between probability measures is defined as the average of the Wasserstein distances resulting for the associated one-dimensional projections. As a consequence, the SW distance can be written as an integral with respect to the uniform measure on the sphere and the Monte Carlo framework can be employed for calculating the SW distance. Spherical harmonics are polynomials on the sphere that form an orthonormal basis of the set of square-integrable functions on the sphere. Putting these two facts together, a new Monte Carlo method, hereby referred to as Spherical Harmonics Control Variates (SHCV), is proposed for approximating the SW distance using spherical harmonics as control variates. The resulting approach is shown to have good theoretical properties, e.g., a no-error property for Gaussian measures under a certain form of linear dependency between the variables. Moreover, an improved rate of convergence, compared to Monte Carlo, is established for g
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#25581;&#31034;&#26435;&#37325;&#21644;&#20989;&#25968;&#31354;&#38388;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#25105;&#20204;&#25104;&#21151;&#23454;&#29616;&#20102;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;&#21487;&#34892;&#30340;&#22522;&#20110;&#26679;&#26412;&#25512;&#29702;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#36125;&#21494;&#26031;&#28145;&#24230;&#38598;&#25104;&#26041;&#27861;&#26469;&#35299;&#20915;&#37319;&#26679;&#21644;&#25910;&#25947;&#38382;&#39064;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01484</link><description>&lt;p&gt;
&#36830;&#25509;&#28857;&#65306;&#27169;&#24335;&#36830;&#25509;&#26159;&#21542;&#26159;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#21487;&#34892;&#30340;&#22522;&#20110;&#26679;&#26412;&#25512;&#29702;&#30340;&#20851;&#38190;&#65311;
&lt;/p&gt;
&lt;p&gt;
Connecting the Dots: Is Mode-Connectedness the Key to Feasible Sample-Based Inference in Bayesian Neural Networks?
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01484
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#25581;&#31034;&#26435;&#37325;&#21644;&#20989;&#25968;&#31354;&#38388;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#25105;&#20204;&#25104;&#21151;&#23454;&#29616;&#20102;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;&#21487;&#34892;&#30340;&#22522;&#20110;&#26679;&#26412;&#25512;&#29702;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#36125;&#21494;&#26031;&#28145;&#24230;&#38598;&#25104;&#26041;&#27861;&#26469;&#35299;&#20915;&#37319;&#26679;&#21644;&#25910;&#25947;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;&#22522;&#20110;&#26679;&#26412;&#25512;&#29702;&#65288;SBI&#65289;&#20013;&#65292;&#32593;&#32476;&#21442;&#25968;&#31354;&#38388;&#30340;&#22823;&#23567;&#21644;&#32467;&#26500;&#26159;&#19968;&#20010;&#20027;&#35201;&#25361;&#25112;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#36890;&#36807;&#25509;&#21463;&#26435;&#37325;&#21644;&#20989;&#25968;&#31354;&#38388;&#20043;&#38388;&#30340;&#29305;&#24449;&#20851;&#31995;&#65292;&#25104;&#21151;&#23454;&#29616;SBI&#26159;&#21487;&#33021;&#30340;&#65292;&#25581;&#31034;&#20102;&#36807;&#24230;&#21442;&#25968;&#21270;&#21644;&#37319;&#26679;&#38382;&#39064;&#22256;&#38590;&#20043;&#38388;&#30340;&#31995;&#32479;&#32852;&#31995;&#12290;&#36890;&#36807;&#22823;&#37327;&#23454;&#39564;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#37319;&#26679;&#21644;&#25910;&#25947;&#35786;&#26029;&#30340;&#23454;&#38469;&#25351;&#21335;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#28145;&#24230;&#38598;&#25104;&#26041;&#27861;&#20316;&#20026;&#19968;&#31181;&#26377;&#25928;&#30340;&#35299;&#20915;&#26041;&#26696;&#65292;&#20855;&#26377;&#31454;&#20105;&#24615;&#33021;&#21644;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
A major challenge in sample-based inference (SBI) for Bayesian neural networks is the size and structure of the networks' parameter space. Our work shows that successful SBI is possible by embracing the characteristic relationship between weight and function space, uncovering a systematic link between overparameterization and the difficulty of the sampling problem. Through extensive experiments, we establish practical guidelines for sampling and convergence diagnosis. As a result, we present a Bayesian deep ensemble approach as an effective solution with competitive performance and uncertainty quantification.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#33258;&#26680;-&#29305;&#24449;&#23545;&#31232;&#30095;&#21464;&#20998;&#39640;&#26031;&#36807;&#31243;&#65288;KEP-SVGP&#65289;&#29992;&#20110;&#26500;&#24314;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#30340;&#33258;&#27880;&#24847;&#21147;&#12290;&#36890;&#36807;&#26680;SVD&#65288;KSVD&#65289;&#35299;&#20915;&#20102;&#27880;&#24847;&#21147;&#26680;&#30340;&#19981;&#23545;&#31216;&#24615;&#65292;&#24182;&#23454;&#29616;&#20102;&#38477;&#20302;&#30340;&#22797;&#26434;&#24230;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01476</link><description>&lt;p&gt;
&#33258;&#26680;-&#29305;&#24449;&#23545;&#31232;&#30095;&#21464;&#20998;&#39640;&#26031;&#36807;&#31243;&#20013;&#30340;&#33258;&#27880;&#24847;&#21147;
&lt;/p&gt;
&lt;p&gt;
Self-Attention through Kernel-Eigen Pair Sparse Variational Gaussian Processes
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01476
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#33258;&#26680;-&#29305;&#24449;&#23545;&#31232;&#30095;&#21464;&#20998;&#39640;&#26031;&#36807;&#31243;&#65288;KEP-SVGP&#65289;&#29992;&#20110;&#26500;&#24314;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#30340;&#33258;&#27880;&#24847;&#21147;&#12290;&#36890;&#36807;&#26680;SVD&#65288;KSVD&#65289;&#35299;&#20915;&#20102;&#27880;&#24847;&#21147;&#26680;&#30340;&#19981;&#23545;&#31216;&#24615;&#65292;&#24182;&#23454;&#29616;&#20102;&#38477;&#20302;&#30340;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;Transformer&#20855;&#26377;&#26174;&#33879;&#25552;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#30340;&#33021;&#21147;&#65292;&#20294;&#23427;&#20063;&#21487;&#33021;&#20135;&#29983;&#36807;&#20110;&#33258;&#20449;&#30340;&#39044;&#27979;&#65292;&#24182;&#38656;&#35201;&#26657;&#20934;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#36825;&#36890;&#24120;&#21487;&#20197;&#36890;&#36807;&#39640;&#26031;&#36807;&#31243;&#65288;GPs&#65289;&#26469;&#35299;&#20915;&#12290;&#29616;&#26377;&#30340;&#24037;&#20316;&#23558;&#23545;&#31216;&#26680;&#24212;&#29992;&#20110;&#21464;&#20998;&#25512;&#26029;&#19979;&#30340;&#27880;&#24847;&#21147;&#26680;&#65307;&#28982;&#32780;&#65292;&#24573;&#30053;&#20102;&#27880;&#24847;&#21147;&#26680;&#26412;&#36136;&#19978;&#26159;&#19981;&#23545;&#31216;&#30340;&#20107;&#23454;&#12290;&#27492;&#22806;&#65292;&#25512;&#23548;&#20986;&#22823;&#35268;&#27169;&#25968;&#25454;&#30340;GP&#21518;&#39564;&#30340;&#22797;&#26434;&#24230;&#20173;&#28982;&#24456;&#39640;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#26500;&#24314;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#30340;&#33258;&#27880;&#24847;&#21147;&#30340;&#26680;-&#29305;&#24449;&#23545;&#31232;&#30095;&#21464; &#20998;&#39640;&#26031;&#36807;&#31243;&#65288;KEP-SVGP&#65289;&#65292;&#20854;&#20013;&#36890;&#36807;&#26680;SVD&#65288;KSVD&#65289;&#35299;&#20915;&#20102;&#27880;&#24847;&#21147;&#26680;&#30340;&#19981;&#23545;&#31216;&#24615;&#65292;&#24182;&#33719;&#24471;&#20102;&#38477;&#20302;&#30340;&#22797;&#26434;&#24230;&#12290;&#36890;&#36807;KEP-SVGP&#65292;i&#65289;&#30001;&#20110;&#19982;&#27880;&#24847;&#21147;&#26680;&#30340;KSVD&#30456;&#23545;&#24212;&#30340;&#20004;&#32452;&#22855;&#24322;&#21521;&#37327;&#24341;&#23548;&#30340;SVGP&#23545;&#23436;&#20840;&#34920;&#24449;&#20102;&#19981;&#23545;&#31216;&#24615;&#65307;ii&#65289;&#20165;&#20351;&#29992;&#23569;&#37327;&#19982;KSVD&#30456;&#23545;&#24212;&#30340;&#20276;&#38543;&#29305;&#24449;&#20989;&#25968;&#65292;&#25512;&#23548;SVGP&#21518;&#39564;&#27010;&#29575;&#23494;&#24230;&#21487;&#20197;&#23454;&#29616;&#36739;&#20302;&#30340;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
While the great capability of Transformers significantly boosts prediction accuracy, it could also yield overconfident predictions and require calibrated uncertainty estimation, which can be commonly tackled by Gaussian processes (GPs). Existing works apply GPs with symmetric kernels under variational inference to the attention kernel; however, omitting the fact that attention kernels are in essence asymmetric. Moreover, the complexity of deriving the GP posteriors remains high for large-scale data. In this work, we propose Kernel-Eigen Pair Sparse Variational Gaussian Processes (KEP-SVGP) for building uncertainty-aware self-attention where the asymmetry of attention kernels is tackled by Kernel SVD (KSVD) and a reduced complexity is acquired. Through KEP-SVGP, i) the SVGP pair induced by the two sets of singular vectors from KSVD w.r.t. the attention kernel fully characterizes the asymmetry; ii) using only a small set of adjoint eigenfunctions from KSVD, the derivation of SVGP posteri
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;ODE&#30340;&#28145;&#24230;&#29983;&#25104;&#26041;&#27861;&#65292;&#36890;&#36807;&#26465;&#20214;Follmer&#27969;&#26469;&#23398;&#20064;&#26465;&#20214;&#20998;&#24067;&#65292;&#36890;&#36807;&#31163;&#25955;&#21270;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#39640;&#25928;&#36716;&#21270;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;Wasserstein&#36317;&#31163;&#30340;&#38750;&#28176;&#36817;&#25910;&#25947;&#36895;&#29575;&#65292;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#31471;&#21040;&#31471;&#35823;&#24046;&#20998;&#26512;&#65292;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20854;&#22312;&#19981;&#21516;&#22330;&#26223;&#19979;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01460</link><description>&lt;p&gt;
&#28145;&#24230;&#26465;&#20214;&#29983;&#25104;&#23398;&#20064;&#65306;&#27169;&#22411;&#19982;&#35823;&#24046;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Deep Conditional Generative Learning: Model and Error Analysis
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01460
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;ODE&#30340;&#28145;&#24230;&#29983;&#25104;&#26041;&#27861;&#65292;&#36890;&#36807;&#26465;&#20214;Follmer&#27969;&#26469;&#23398;&#20064;&#26465;&#20214;&#20998;&#24067;&#65292;&#36890;&#36807;&#31163;&#25955;&#21270;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#23454;&#29616;&#39640;&#25928;&#36716;&#21270;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;Wasserstein&#36317;&#31163;&#30340;&#38750;&#28176;&#36817;&#25910;&#25947;&#36895;&#29575;&#65292;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#31471;&#21040;&#31471;&#35823;&#24046;&#20998;&#26512;&#65292;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20854;&#22312;&#19981;&#21516;&#22330;&#26223;&#19979;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26222;&#36890;&#24494;&#20998;&#26041;&#31243;&#65288;ODE&#65289;&#30340;&#28145;&#24230;&#29983;&#25104;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#26465;&#20214;&#20998;&#24067;&#65292;&#31216;&#20026;&#26465;&#20214;Follmer&#27969;&#12290;&#20174;&#26631;&#20934;&#39640;&#26031;&#20998;&#24067;&#24320;&#22987;&#65292;&#25152;&#25552;&#20986;&#30340;&#27969;&#33021;&#22815;&#20197;&#39640;&#25928;&#30340;&#26041;&#24335;&#23558;&#20854;&#36716;&#21270;&#20026;&#30446;&#26631;&#26465;&#20214;&#20998;&#24067;&#65292;&#22312;&#26102;&#38388;1&#22788;&#36798;&#21040;&#31283;&#23450;&#12290;&#20026;&#20102;&#26377;&#25928;&#23454;&#29616;&#65292;&#25105;&#20204;&#20351;&#29992;&#27431;&#25289;&#26041;&#27861;&#23545;&#27969;&#36827;&#34892;&#31163;&#25955;&#21270;&#65292;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#38750;&#21442;&#25968;&#21270;&#20272;&#35745;&#36895;&#24230;&#22330;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23548;&#20986;&#20102;&#23398;&#20064;&#26679;&#26412;&#30340;&#20998;&#24067;&#19982;&#30446;&#26631;&#20998;&#24067;&#20043;&#38388;&#30340;Wasserstein&#36317;&#31163;&#30340;&#38750;&#28176;&#36817;&#25910;&#25947;&#36895;&#29575;&#65292;&#22312;&#26465;&#20214;&#20998;&#24067;&#23398;&#20064;&#20013;&#25552;&#20379;&#20102;&#31532;&#19968;&#20010;&#20840;&#38754;&#30340;&#31471;&#21040;&#31471;&#35823;&#24046;&#20998;&#26512;&#12290;&#25105;&#20204;&#30340;&#25968;&#20540;&#23454;&#39564;&#23637;&#31034;&#20102;&#23427;&#22312;&#19968;&#31995;&#21015;&#24773;&#20917;&#19979;&#30340;&#26377;&#25928;&#24615;&#65292;&#20174;&#26631;&#20934;&#30340;&#38750;&#21442;&#25968;&#21270;&#26465;&#20214;&#23494;&#24230;&#20272;&#35745;&#38382;&#39064;&#21040;&#28041;&#21450;&#22270;&#20687;&#25968;&#25454;&#30340;&#26356;&#22797;&#26434;&#30340;&#25361;&#25112;&#65292;&#35828;&#26126;&#23427;&#20248;&#20110;&#21508;&#31181;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce an Ordinary Differential Equation (ODE) based deep generative method for learning a conditional distribution, named the Conditional Follmer Flow. Starting from a standard Gaussian distribution, the proposed flow could efficiently transform it into the target conditional distribution at time 1. For effective implementation, we discretize the flow with Euler's method where we estimate the velocity field nonparametrically using a deep neural network. Furthermore, we derive a non-asymptotic convergence rate in the Wasserstein distance between the distribution of the learned samples and the target distribution, providing the first comprehensive end-to-end error analysis for conditional distribution learning via ODE flow. Our numerical experiments showcase its effectiveness across a range of scenarios, from standard nonparametric conditional density estimation problems to more intricate challenges involving image data, illustrating its superiority over various existing condition
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22240;&#26524;&#21457;&#29616;&#20013;&#38598;&#25104;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#32479;&#35745;&#22240;&#26524;&#25552;&#31034;&#19982;&#30693;&#35782;&#22686;&#24378;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#20351;&#32479;&#35745;&#22240;&#26524;&#21457;&#29616;&#32467;&#26524;&#25509;&#36817;&#30495;&#23454;&#24773;&#20917;&#24182;&#36827;&#19968;&#27493;&#25913;&#36827;&#32467;&#26524;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01454</link><description>&lt;p&gt;
&#22312;&#22240;&#26524;&#21457;&#29616;&#20013;&#38598;&#25104;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;: &#19968;&#31181;&#32479;&#35745;&#22240;&#26524;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Integrating Large Language Models in Causal Discovery: A Statistical Causal Approach
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01454
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22240;&#26524;&#21457;&#29616;&#20013;&#38598;&#25104;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#32479;&#35745;&#22240;&#26524;&#25552;&#31034;&#19982;&#30693;&#35782;&#22686;&#24378;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#20351;&#32479;&#35745;&#22240;&#26524;&#21457;&#29616;&#32467;&#26524;&#25509;&#36817;&#30495;&#23454;&#24773;&#20917;&#24182;&#36827;&#19968;&#27493;&#25913;&#36827;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#38469;&#30340;&#32479;&#35745;&#22240;&#26524;&#21457;&#29616;&#65288;SCD&#65289;&#20013;&#65292;&#23558;&#39046;&#22495;&#19987;&#23478;&#30693;&#35782;&#20316;&#20026;&#32422;&#26463;&#23884;&#20837;&#21040;&#31639;&#27861;&#20013;&#34987;&#24191;&#27867;&#25509;&#21463;&#65292;&#22240;&#20026;&#36825;&#23545;&#20110;&#21019;&#24314;&#19968;&#33268;&#26377;&#24847;&#20041;&#30340;&#22240;&#26524;&#27169;&#22411;&#26159;&#37325;&#35201;&#30340;&#65292;&#23613;&#31649;&#35782;&#21035;&#32972;&#26223;&#30693;&#35782;&#30340;&#25361;&#25112;&#34987;&#35748;&#21487;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#25361;&#25112;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22240;&#26524;&#25512;&#26029;&#26041;&#27861;&#65292;&#21363;&#36890;&#36807;&#23558;LLM&#30340;&#8220;&#32479;&#35745;&#22240;&#26524;&#25552;&#31034;&#65288;SCP&#65289;&#8221;&#19982;SCD&#26041;&#27861;&#21644;&#22522;&#20110;&#30693;&#35782;&#30340;&#22240;&#26524;&#25512;&#26029;&#65288;KBCI&#65289;&#30456;&#32467;&#21512;&#65292;&#23545;SCD&#36827;&#34892;&#20808;&#39564;&#30693;&#35782;&#22686;&#24378;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;GPT-4&#21487;&#20197;&#20351;LLM-KBCI&#30340;&#36755;&#20986;&#19982;&#24102;&#26377;LLM-KBCI&#30340;&#20808;&#39564;&#30693;&#35782;&#30340;SCD&#32467;&#26524;&#25509;&#36817;&#30495;&#23454;&#24773;&#20917;&#65292;&#22914;&#26524;GPT-4&#32463;&#21382;&#20102;SCP&#65292;&#37027;&#20040;SCD&#30340;&#32467;&#26524;&#36824;&#21487;&#20197;&#36827;&#19968;&#27493;&#25913;&#21892;&#12290;&#32780;&#19988;&#65292;&#21363;&#20351;LLM&#19981;&#21547;&#26377;&#25968;&#25454;&#38598;&#30340;&#20449;&#24687;&#65292;LLM&#20173;&#28982;&#21487;&#20197;&#36890;&#36807;&#20854;&#32972;&#26223;&#30693;&#35782;&#26469;&#25913;&#36827;SCD&#12290;
&lt;/p&gt;
&lt;p&gt;
In practical statistical causal discovery (SCD), embedding domain expert knowledge as constraints into the algorithm is widely accepted as significant for creating consistent meaningful causal models, despite the recognized challenges in systematic acquisition of the background knowledge. To overcome these challenges, this paper proposes a novel methodology for causal inference, in which SCD methods and knowledge based causal inference (KBCI) with a large language model (LLM) are synthesized through "statistical causal prompting (SCP)" for LLMs and prior knowledge augmentation for SCD. Experiments have revealed that GPT-4 can cause the output of the LLM-KBCI and the SCD result with prior knowledge from LLM-KBCI to approach the ground truth, and that the SCD result can be further improved, if GPT-4 undergoes SCP. Furthermore, it has been clarified that an LLM can improve SCD with its background knowledge, even if the LLM does not contain information on the dataset. The proposed approach
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#21327;&#21464;&#37327;&#20559;&#31227;&#38382;&#39064;&#20013;&#25913;&#36827;&#37325;&#35201;&#24615;&#20272;&#35745;&#20197;&#25552;&#39640;&#39044;&#27979;&#35823;&#24046;&#30340;&#20934;&#30830;&#24615;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01450</link><description>&lt;p&gt;
&#22312;&#21327;&#21464;&#37327;&#20559;&#31227;&#20013;&#25913;&#36827;&#37325;&#35201;&#24615;&#20272;&#35745;&#20197;&#25552;&#20379;&#20934;&#30830;&#30340;&#39044;&#27979;&#35823;&#24046;
&lt;/p&gt;
&lt;p&gt;
Improving importance estimation in covariate shift for providing accurate prediction error
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01450
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#21327;&#21464;&#37327;&#20559;&#31227;&#38382;&#39064;&#20013;&#25913;&#36827;&#37325;&#35201;&#24615;&#20272;&#35745;&#20197;&#25552;&#39640;&#39044;&#27979;&#35823;&#24046;&#30340;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20256;&#32479;&#30340;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#31639;&#27861;&#30340;&#39044;&#27979;&#22522;&#20110;&#35757;&#32451;&#38598;&#21644;&#27979;&#35797;&#38598;&#20013;&#30340;&#25968;&#25454;&#36981;&#24490;&#30456;&#21516;&#30340;&#20998;&#24067;&#30340;&#20551;&#35774;&#12290;&#28982;&#32780;&#65292;&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#20013;&#65292;&#36825;&#20010;&#26465;&#20214;&#24182;&#19981;&#25104;&#31435;&#65292;&#20363;&#22914;&#65292;&#21327;&#21464;&#37327;&#30340;&#20998;&#24067;&#21457;&#29983;&#20102;&#21464;&#21270;&#65292;&#32780;&#30446;&#26631;&#30340;&#26465;&#20214;&#20998;&#24067;&#20445;&#25345;&#19981;&#21464;&#12290;&#36825;&#31181;&#24773;&#20917;&#34987;&#31216;&#20026;&#21327;&#21464;&#37327;&#20559;&#31227;&#38382;&#39064;&#65292;&#26631;&#20934;&#35823;&#24046;&#20272;&#35745;&#21487;&#33021;&#19981;&#20877;&#20934;&#30830;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#37325;&#35201;&#24615;&#26159;&#19968;&#31181;&#24120;&#29992;&#30340;&#24230;&#37327;&#65292;&#29992;&#20110;&#20943;&#36731;&#21327;&#21464;&#37327;&#20559;&#31227;&#23545;&#35823;&#24046;&#20272;&#35745;&#30340;&#24433;&#21709;&#12290;&#20027;&#35201;&#30340;&#32570;&#28857;&#26159;&#23427;&#19981;&#23481;&#26131;&#35745;&#31639;&#12290;Kullback-Leibler&#37325;&#35201;&#24615;&#20272;&#35745;&#36807;&#31243;&#65288;KLIEP&#65289;&#33021;&#22815;&#20197;&#19968;&#31181;&#26377;&#24076;&#26395;&#30340;&#26041;&#24335;&#20272;&#35745;&#37325;&#35201;&#24615;&#12290;&#23613;&#31649;&#23427;&#30340;&#24615;&#33021;&#24456;&#22909;&#65292;&#20294;&#23427;&#26080;&#27861;&#24573;&#30053;&#30446;&#26631;&#20449;&#24687;&#65292;&#22240;&#20026;&#23427;&#21482;&#21253;&#25324;&#29992;&#20110;&#35745;&#31639;&#37325;&#35201;&#24615;&#30340;&#21327;&#21464;&#37327;&#20449;&#24687;&#12290;&#22312;&#36825;&#20010;&#26041;&#21521;&#19978;&#65292;&#26412;&#25991;&#25506;&#35752;&#20102;&#22914;&#26524;&#22312;&#35745;&#31639;&#37325;&#35201;&#24615;&#26102;&#21253;&#25324;&#30446;&#26631;&#20449;&#24687;&#30340;&#28508;&#22312;&#24615;&#33021;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;
In traditional Machine Learning, the algorithms predictions are based on the assumption that the data follows the same distribution in both the training and the test datasets. However, in real world data this condition does not hold and, for instance, the distribution of the covariates changes whereas the conditional distribution of the targets remains unchanged. This situation is called covariate shift problem where standard error estimation may be no longer accurate. In this context, the importance is a measure commonly used to alleviate the influence of covariate shift on error estimations. The main drawback is that it is not easy to compute. The Kullback-Leibler Importance Estimation Procedure (KLIEP) is capable of estimating importance in a promising way. Despite its good performance, it fails to ignore target information, since it only includes the covariates information for computing the importance. In this direction, this paper explores the potential performance improvement if 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#32034;&#20102;&#22312;&#26080;&#31351;&#32500;&#31354;&#38388;&#20013;&#23545;&#38750;&#32447;&#24615;&#36807;&#31243;&#36827;&#34892;&#26465;&#20214;&#32422;&#26463;&#30340;&#26041;&#27861;&#65292;&#24182;&#24212;&#29992;&#20110;&#36827;&#21270;&#29983;&#29289;&#23398;&#20013;&#30340;&#29983;&#29289;&#24418;&#24577;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01434</link><description>&lt;p&gt;
&#38543;&#26426;&#38750;&#32447;&#24615;&#19982;&#26080;&#31351;&#32500;&#25193;&#25955;&#36807;&#31243;&#30340;&#26465;&#20214;&#32422;&#26463;
&lt;/p&gt;
&lt;p&gt;
Conditioning non-linear and infinite-dimensional diffusion processes
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01434
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#32034;&#20102;&#22312;&#26080;&#31351;&#32500;&#31354;&#38388;&#20013;&#23545;&#38750;&#32447;&#24615;&#36807;&#31243;&#36827;&#34892;&#26465;&#20214;&#32422;&#26463;&#30340;&#26041;&#27861;&#65292;&#24182;&#24212;&#29992;&#20110;&#36827;&#21270;&#29983;&#29289;&#23398;&#20013;&#30340;&#29983;&#29289;&#24418;&#24577;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#24615;&#25193;&#25955;&#27169;&#22411;&#21644;&#35768;&#22810;&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#30340;&#38543;&#26426;&#27169;&#22411;&#22312;&#31163;&#25955;&#21270;&#20043;&#21069;&#33258;&#28982;&#22320;&#23384;&#22312;&#20110;&#26080;&#31351;&#32500;&#31354;&#38388;&#20013;&#12290;&#20026;&#20102;&#23558;&#35266;&#27979;&#25968;&#25454;&#32435;&#20837;&#32479;&#35745;&#21644;&#23398;&#20064;&#20219;&#21153;&#20013;&#65292;&#38656;&#35201;&#23545;&#35266;&#27979;&#20540;&#36827;&#34892;&#26465;&#20214;&#32422;&#26463;&#12290;&#36817;&#26399;&#30340;&#30740;&#31350;&#24050;&#32463;&#22788;&#29702;&#20102;&#22312;&#26080;&#31351;&#32500;&#31354;&#38388;&#20013;&#23545;&#32447;&#24615;&#36807;&#31243;&#36827;&#34892;&#26465;&#20214;&#32422;&#26463;&#30340;&#38382;&#39064;&#65292;&#20294;&#23578;&#26410;&#25506;&#32034;&#22312;&#26080;&#31351;&#32500;&#31354;&#38388;&#20013;&#23545;&#38750;&#32447;&#24615;&#36807;&#31243;&#36827;&#34892;&#26465;&#20214;&#32422;&#26463;&#30340;&#26041;&#27861;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#26080;&#20808;&#39564;&#31163;&#25955;&#21270;&#30340;&#24773;&#20917;&#19979;&#23545;&#20989;&#25968;&#20540;&#38543;&#26426;&#36807;&#31243;&#36827;&#34892;&#26465;&#20214;&#32422;&#26463;&#30340;&#26041;&#27861;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;Girsanov&#23450;&#29702;&#30340;&#26080;&#31351;&#32500;&#29256;&#26412;&#26469;&#23545;&#20989;&#25968;&#20540;&#38543;&#26426;&#36807;&#31243;&#36827;&#34892;&#26465;&#20214;&#32422;&#26463;&#65292;&#20174;&#32780;&#24471;&#21040;&#20102;&#28041;&#21450;&#24471;&#20998;&#30340;&#26465;&#20214;&#36807;&#31243;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;(SDE)&#12290;&#25105;&#20204;&#23558;&#36825;&#31181;&#25216;&#26415;&#24212;&#29992;&#20110;&#36827;&#21270;&#29983;&#29289;&#23398;&#20013;&#30340;&#29983;&#29289;&#24418;&#24577;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#20013;&#65292;&#36890;&#36807;Fourier&#22522;&#20989;&#25968;&#31163;&#25955;&#21270;&#65292;&#28982;&#21518;&#21033;&#29992;&#24471;&#20998;&#21305;&#37197;&#26041;&#27861;&#23398;&#20064;&#24471;&#20998;&#20989;&#25968;&#30340;&#31995;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative diffusion models and many stochastic models in science and engineering naturally live in infinite dimensions before discretisation. To incorporate observed data for statistical and learning tasks, one needs to condition on observations. While recent work has treated conditioning linear processes in infinite dimensions, conditioning non-linear processes in infinite dimensions has not been explored. This paper conditions function valued stochastic processes without prior discretisation. To do so, we use an infinite-dimensional version of Girsanov's theorem to condition a function-valued stochastic process, leading to a stochastic differential equation (SDE) for the conditioned process involving the score. We apply this technique to do time series analysis for shapes of organisms in evolutionary biology, where we discretise via the Fourier basis and then learn the coefficients of the score function with score matching methods.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;Lipschitz&#27491;&#21017;&#21270;&#23454;&#29616;&#38646;&#26679;&#26412;&#26426;&#22120;&#36951;&#24536;&#65292;&#21487;&#20197;&#21450;&#26102;&#24536;&#35760;&#31169;&#20154;&#25110;&#21463;&#29256;&#26435;&#20445;&#25252;&#30340;&#20449;&#24687;&#65292;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#24615;&#33021;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01401</link><description>&lt;p&gt;
&#36890;&#36807;Lipschitz&#27491;&#21017;&#21270;&#22312;&#35268;&#27169;&#19978;&#23454;&#29616;&#38646;&#26679;&#26412;&#26426;&#22120;&#36951;&#24536;
&lt;/p&gt;
&lt;p&gt;
Zero-Shot Machine Unlearning at Scale via Lipschitz Regularization
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01401
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;Lipschitz&#27491;&#21017;&#21270;&#23454;&#29616;&#38646;&#26679;&#26412;&#26426;&#22120;&#36951;&#24536;&#65292;&#21487;&#20197;&#21450;&#26102;&#24536;&#35760;&#31169;&#20154;&#25110;&#21463;&#29256;&#26435;&#20445;&#25252;&#30340;&#20449;&#24687;&#65292;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#36981;&#23432;&#20154;&#24037;&#26234;&#33021;&#21644;&#25968;&#25454;&#35268;&#23450;&#65292;&#20174;&#35757;&#32451;&#24471;&#21040;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#36951;&#24536;&#31169;&#20154;&#25110;&#21463;&#29256;&#26435;&#20445;&#25252;&#30340;&#20449;&#24687;&#30340;&#38656;&#27714;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#12290;&#36951;&#24536;&#30340;&#20851;&#38190;&#25361;&#25112;&#26159;&#21450;&#26102;&#24536;&#35760;&#24517;&#35201;&#30340;&#25968;&#25454;&#65292;&#21516;&#26102;&#20445;&#25345;&#27169;&#22411;&#24615;&#33021;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#38646;&#26679;&#26412;&#36951;&#24536;&#30340;&#22330;&#26223;&#65292;&#21363;&#21482;&#26377;&#19968;&#20010;&#32463;&#36807;&#35757;&#32451;&#30340;&#27169;&#22411;&#21644;&#35201;&#36951;&#24536;&#30340;&#25968;&#25454;&#65292;&#36951;&#24536;&#31639;&#27861;&#24517;&#39035;&#33021;&#22815;&#31227;&#38500;&#25968;&#25454;&#12290;&#26681;&#25454;&#36825;&#26679;&#23450;&#20041;&#65292;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#26159;&#19981;&#22815;&#30340;&#12290;&#22522;&#20110;Lipschitz&#36830;&#32493;&#24615;&#30340;&#27010;&#24565;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#26679;&#26412;&#25200;&#21160;&#30340;&#36755;&#20986;&#36827;&#34892;&#24179;&#28369;&#22788;&#29702;&#26469;&#35825;&#23548;&#36951;&#24536;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#31181;&#24179;&#28369;&#24615;&#25104;&#21151;&#22320;&#23454;&#29616;&#20102;&#36951;&#24536;&#65292;&#21516;&#26102;&#20445;&#25345;&#20102;&#24635;&#20307;&#27169;&#22411;&#24615;&#33021;&#12290;&#25105;&#20204;&#23545;&#25105;&#20204;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#32463;&#39564;&#35780;&#20272;&#65292;&#21253;&#25324;&#19968;&#31995;&#21015;&#24403;&#20195;&#22522;&#20934;&#27979;&#35797;&#65292;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20005;&#26684;&#30340;&#38646;&#26679;&#26412;&#32422;&#26463;&#19979;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
To comply with AI and data regulations, the need to forget private or copyrighted information from trained machine learning models is increasingly important. The key challenge in unlearning is forgetting the necessary data in a timely manner, while preserving model performance. In this work, we address the zero-shot unlearning scenario, whereby an unlearning algorithm must be able to remove data given only a trained model and the data to be forgotten. Under such a definition, existing state-of-the-art methods are insufficient. Building on the concepts of Lipschitz continuity, we present a method that induces smoothing of the forget sample's output, with respect to perturbations of that sample. We show this smoothing successfully results in forgetting while preserving general model performance. We perform extensive empirical evaluation of our method over a range of contemporary benchmarks, verifying that our method achieves state-of-the-art performance under the strict constraints of ze
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20302;&#26597;&#35810;&#25104;&#26412;&#30340;&#32858;&#31867;&#26041;&#27861;&#65292;&#21033;&#29992;&#32431;&#22312;&#32452;&#21512;&#22810;&#33218;&#36172;&#21338;&#26426;&#25506;&#32034;&#33539;&#24335;&#23454;&#29616;&#22312;&#32447;&#23398;&#20064;&#65292;&#24182;&#35774;&#35745;&#20102;&#33021;&#22312;NP-hard&#24773;&#20917;&#19979;&#36816;&#34892;&#30340;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01400</link><description>&lt;p&gt;
&#20302;&#26597;&#35810;&#25104;&#26412;&#24102;&#22122;&#22768;or&#21516;&#26102;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Query-Efficient Correlation Clustering with Noisy Oracle
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01400
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20302;&#26597;&#35810;&#25104;&#26412;&#30340;&#32858;&#31867;&#26041;&#27861;&#65292;&#21033;&#29992;&#32431;&#22312;&#32452;&#21512;&#22810;&#33218;&#36172;&#21338;&#26426;&#25506;&#32034;&#33539;&#24335;&#23454;&#29616;&#22312;&#32447;&#23398;&#20064;&#65292;&#24182;&#35774;&#35745;&#20102;&#33021;&#22312;NP-hard&#24773;&#20917;&#19979;&#36816;&#34892;&#30340;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#24120;&#35265;&#30340;&#32858;&#31867;&#35774;&#32622;&#65292;&#20854;&#20013;&#25105;&#20204;&#38656;&#35201;&#23545;n&#20010;&#20803;&#32032;&#36827;&#34892;&#32858;&#31867;&#65292;&#24182;&#19988;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#23613;&#21487;&#33021;&#23569;&#22320;&#21521;&#36820;&#22238;&#20004;&#20010;&#20803;&#32032;&#30456;&#20284;&#24615;&#30340;&#26377;&#22122;&#22768;&#30340;oracle&#26597;&#35810;&#12290;&#25105;&#20204;&#30340;&#35774;&#32622;&#28085;&#30422;&#20102;&#35768;&#22810;&#24212;&#29992;&#39046;&#22495;&#65292;&#22312;&#36825;&#20123;&#39046;&#22495;&#20013;&#65292;&#30456;&#20284;&#24615;&#20989;&#25968;&#35745;&#31639;&#36215;&#26469;&#25104;&#26412;&#39640;&#24182;&#19988; inherently noisy&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;&#32431;&#22312;&#32452;&#21512;&#22810;&#33218;&#36172;&#21338;&#26426;&#25506;&#32034;&#33539;&#24335;(PE-CMAB)&#30340;&#22312;&#32447;&#23398;&#20064;&#38382;&#39064;&#30340;&#26032;&#39062;&#34920;&#36798;&#26041;&#27861;&#22266;&#23450;&#32622;&#20449;&#24230;&#21644;&#22266;&#23450;&#39044;&#31639;&#35774;&#32622;&#12290;&#23545;&#20110;&#36825;&#20004;&#31181;&#35774;&#32622;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#23558;&#25277;&#26679;&#31574;&#30053;&#19982;&#32463;&#20856;&#30340;&#30456;&#20851;&#32858;&#31867;&#36817;&#20284;&#31639;&#27861;&#30456;&#32467;&#21512;&#30340;&#31639;&#27861;&#65292;&#24182;&#30740;&#31350;&#20102;&#23427;&#20204;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26159;&#36825;&#26679;&#30340;&#65306;&#36825;&#20123;&#31639;&#27861;&#26159;&#31532;&#19968;&#20010;&#22312;&#24213;&#23618;&#31163;&#32447;&#20248;&#21270;&#38382;&#39064;&#20026;NP-hard&#30340;&#24773;&#20917;&#19979;&#36816;&#34892;&#30340;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#30340;&#20363;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study a general clustering setting in which we have $n$ elements to be clustered, and we aim to perform as few queries as possible to an oracle that returns a noisy sample of the similarity between two elements. Our setting encompasses many application domains in which the similarity function is costly to compute and inherently noisy. We propose two novel formulations of online learning problems rooted in the paradigm of Pure Exploration in Combinatorial Multi-Armed Bandits (PE-CMAB): fixed confidence and fixed budget settings. For both settings, we design algorithms that combine a sampling strategy with a classic approximation algorithm for correlation clustering and study their theoretical guarantees. Our results are the first examples of polynomial-time algorithms that work for the case of PE-CMAB in which the underlying offline optimization problem is NP-hard.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#27010;&#29575;&#27169;&#22411;&#26469;&#35299;&#37322;&#33258;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#30340;&#26426;&#21046;&#65292;&#24182;&#23637;&#31034;&#20102;&#37492;&#21035;&#24615;&#33258;&#30417;&#30563;&#31639;&#27861;&#22312;&#34920;&#31034;&#20013;&#36817;&#20284;&#35825;&#23548;&#28508;&#21464;&#37327;&#32467;&#26500;&#30340;&#32479;&#19968;&#29702;&#35770;&#26694;&#26550;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01399</link><description>&lt;p&gt;
&#35299;&#37322;&#33258;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#30340;&#27010;&#29575;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Probabilistic Model to explain Self-Supervised Representation Learning
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01399
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#27010;&#29575;&#27169;&#22411;&#26469;&#35299;&#37322;&#33258;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#30340;&#26426;&#21046;&#65292;&#24182;&#23637;&#31034;&#20102;&#37492;&#21035;&#24615;&#33258;&#30417;&#30563;&#31639;&#27861;&#22312;&#34920;&#31034;&#20013;&#36817;&#20284;&#35825;&#23548;&#28508;&#21464;&#37327;&#32467;&#26500;&#30340;&#32479;&#19968;&#29702;&#35770;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#30417;&#30563;&#23398;&#20064;&#65288;SSL&#65289;&#36890;&#36807;&#21033;&#29992;&#36741;&#21161;&#30340;&#26080;&#30417;&#30563;&#20219;&#21153;&#65292;&#20363;&#22914;&#23545;&#35821;&#20041;&#30456;&#20851;&#26679;&#26412;&#36827;&#34892;&#20998;&#31867;&#65292;&#22914;&#19981;&#21516;&#30340;&#25968;&#25454;&#22686;&#24378;&#25110;&#27169;&#24577;&#26469;&#23398;&#20064;&#34920;&#31034;&#12290;&#22312;&#20247;&#22810;SSL&#26041;&#27861;&#20013;&#65292;&#23545;&#27604;&#26041;&#27861;&#65288;&#20363;&#22914;SimCLR&#65292;CLIP&#21644;VicREG&#65289;&#22240;&#23398;&#20064;&#21040;&#30340;&#34920;&#31034;&#22312;&#19979;&#28216;&#24615;&#33021;&#19978;&#25509;&#36817;&#26377;&#30417;&#30563;&#23398;&#20064;&#32780;&#21463;&#21040;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#32972;&#21518;&#30340;&#26426;&#21046;&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#23384;&#22312;&#22256;&#38590;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29983;&#25104;&#28508;&#21464;&#37327;&#27169;&#22411;&#26469;&#34920;&#31034;&#25968;&#25454;&#65292;&#24182;&#23637;&#31034;&#20102;&#20960;&#31867;&#20855;&#26377;&#37492;&#21035;&#24615;&#30340;&#33258;&#30417;&#30563;&#31639;&#27861;&#65288;&#21253;&#25324;&#23545;&#27604;&#26041;&#27861;&#65289;&#36817;&#20284;&#35825;&#23548;&#20854;&#34920;&#31034;&#20013;&#30340;&#28508;&#21464;&#37327;&#32467;&#26500;&#65292;&#20174;&#32780;&#25552;&#20379;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#29702;&#35770;&#26694;&#26550;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#19982;&#20114;&#20449;&#24687;&#21644;&#25237;&#24433;&#22836;&#30340;&#30456;&#20851;&#24615;&#12290;&#36890;&#36807;&#29983;&#25104;&#24335;&#22320;&#25311;&#21512;&#25105;&#20204;&#30340;&#27169;&#22411;&#65288;&#22914;SimVE&#65289;&#65292;&#22312;&#24120;&#35265;&#30340;&#22522;&#20934;&#27979;&#35797;&#19978;&#65288;&#20363;&#22914;FashionMNIST&#65292;CIFAR10&#65292;CelebA&#65289;&#65292;&#24615;&#33021;&#20248;&#20110;&#20043;&#21069;&#30340;VAE&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Self-supervised learning (SSL) learns representations by leveraging an auxiliary unsupervised task, such as classifying semantically related samples, e.g. different data augmentations or modalities. Of the many approaches to SSL, contrastive methods, e.g. SimCLR, CLIP and VicREG, have gained attention for learning representations that achieve downstream performance close to that of supervised learning. However, a theoretical understanding of the mechanism behind these methods eludes. We propose a generative latent variable model for the data and show that several families of discriminative self-supervised algorithms, including contrastive methods, approximately induce its latent structure over representations, providing a unifying theoretical framework. We also justify links to mutual information and the use of a projection head. Fitting our model generatively, as SimVE, improves performance over previous VAE methods on common benchmarks (e.g. FashionMNIST, CIFAR10, CelebA), narrows th
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20998;&#26512;&#20102;&#40784;&#27425;&#21270;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#22312;&#25968;&#20540;&#23454;&#39564;&#20013;&#39564;&#35777;&#20102;&#21442;&#25968;&#23614;&#25351;&#25968;&#30340;&#26126;&#30830;&#19978;&#19979;&#30028;&#65292;&#24182;&#37327;&#21270;&#20102;&#20248;&#21270;&#21442;&#25968;&#19982;&#23614;&#25351;&#25968;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#20174;&#32780;&#20026;&#37325;&#23614;&#21644;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#24615;&#33021;&#20197;&#21450;SGD&#36991;&#20813;&#27425;&#20248;&#23616;&#37096;&#26368;&#23567;&#20540;&#33021;&#21147;&#20043;&#38388;&#30340;&#20851;&#31995;&#25552;&#20379;&#20102;&#36129;&#29486;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01382</link><description>&lt;p&gt;
&#40784;&#27425;&#21270;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#20013;&#37325;&#23614;&#29616;&#35937;&#30340;&#20986;&#29616;
&lt;/p&gt;
&lt;p&gt;
Emergence of heavy tails in homogenized stochastic gradient descent
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01382
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20998;&#26512;&#20102;&#40784;&#27425;&#21270;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#22312;&#25968;&#20540;&#23454;&#39564;&#20013;&#39564;&#35777;&#20102;&#21442;&#25968;&#23614;&#25351;&#25968;&#30340;&#26126;&#30830;&#19978;&#19979;&#30028;&#65292;&#24182;&#37327;&#21270;&#20102;&#20248;&#21270;&#21442;&#25968;&#19982;&#23614;&#25351;&#25968;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#20174;&#32780;&#20026;&#37325;&#23614;&#21644;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#24615;&#33021;&#20197;&#21450;SGD&#36991;&#20813;&#27425;&#20248;&#23616;&#37096;&#26368;&#23567;&#20540;&#33021;&#21147;&#20043;&#38388;&#30340;&#20851;&#31995;&#25552;&#20379;&#20102;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#36890;&#36807;&#26368;&#23567;&#21270;&#25439;&#22833;&#24050;&#32463;&#34987;&#21457;&#29616;&#23548;&#33268;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#30340;&#37325;&#23614;&#20998;&#24067;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;SGD&#30340;&#36830;&#32493;&#25193;&#25955;&#36924;&#36817;&#65292;&#31216;&#20026;&#40784;&#27425;&#21270;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65292;&#35777;&#26126;&#20102;&#23427;&#22312;&#28176;&#36827;&#24773;&#20917;&#19979;&#34920;&#29616;&#20986;&#37325;&#23614;&#29305;&#24615;&#65292;&#24182;&#32473;&#20986;&#20102;&#20851;&#20110;&#23614;&#25351;&#25968;&#30340;&#26126;&#30830;&#19978;&#19979;&#30028;&#12290;&#25105;&#20204;&#22312;&#25968;&#20540;&#23454;&#39564;&#20013;&#39564;&#35777;&#20102;&#36825;&#20123;&#30028;&#24182;&#26174;&#31034;&#23427;&#20204;&#36890;&#24120;&#26159;SGD&#36845;&#20195;&#30340;&#32463;&#39564;&#23614;&#25351;&#25968;&#30340;&#36817;&#20284;&#12290;&#21478;&#22806;&#65292;&#23427;&#20204;&#30340;&#26126;&#30830;&#24418;&#24335;&#20351;&#25105;&#20204;&#33021;&#22815;&#37327;&#21270;&#20248;&#21270;&#21442;&#25968;&#21644;&#23614;&#25351;&#25968;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#36890;&#36807;&#36825;&#26679;&#20570;&#65292;&#25105;&#20204;&#23545;&#20110;&#20851;&#20110;&#37325;&#23614;&#21644;&#31070;&#32463;&#32593;&#32476;&#30340;&#27867;&#21270;&#24615;&#33021;&#20197;&#21450;SGD&#36991;&#20813;&#27425;&#20248;&#23616;&#37096;&#26368;&#23567;&#20540;&#33021;&#21147;&#30340;&#32852;&#31995;&#30340;&#35752;&#35770;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;
It has repeatedly been observed that loss minimization by stochastic gradient descent (SGD) leads to heavy-tailed distributions of neural network parameters. Here, we analyze a continuous diffusion approximation of SGD, called homogenized stochastic gradient descent, show that it behaves asymptotically heavy-tailed, and give explicit upper and lower bounds on its tail-index. We validate these bounds in numerical experiments and show that they are typically close approximations to the empirical tail-index of SGD iterates. In addition, their explicit form enables us to quantify the interplay between optimization parameters and the tail-index. Doing so, we contribute to the ongoing discussion on links between heavy tails and the generalization performance of neural networks as well as the ability of SGD to avoid suboptimal local minima.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#36827;&#34892;&#31070;&#32463;&#20803;&#23545;&#40784;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#32622;&#25442;&#23376;&#31354;&#38388;&#20943;&#23569;&#20102;&#32447;&#24615;&#27169;&#22359;&#36830;&#36890;&#24615;&#30340;&#23616;&#38480;&#24615;&#65292;&#20026;&#27169;&#22411;&#34701;&#21512;&#31639;&#27861;&#30340;&#25913;&#36827;&#25552;&#20379;&#20102;&#21487;&#33021;&#24615;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01342</link><description>&lt;p&gt;
&#36890;&#36807;&#32622;&#25442;&#23376;&#31354;&#38388;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#23545;&#31070;&#32463;&#20803;&#36827;&#34892;&#23545;&#40784;&#65292;&#20197;&#25913;&#36827;&#32447;&#24615;&#27169;&#22359;&#36830;&#36890;&#24615;&#21644;&#27169;&#22411;&#34701;&#21512;
&lt;/p&gt;
&lt;p&gt;
Training-time Neuron Alignment through Permutation Subspace for Improving Linear Mode Connectivity and Model Fusion
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01342
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#36827;&#34892;&#31070;&#32463;&#20803;&#23545;&#40784;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#32622;&#25442;&#23376;&#31354;&#38388;&#20943;&#23569;&#20102;&#32447;&#24615;&#27169;&#22359;&#36830;&#36890;&#24615;&#30340;&#23616;&#38480;&#24615;&#65292;&#20026;&#27169;&#22411;&#34701;&#21512;&#31639;&#27861;&#30340;&#25913;&#36827;&#25552;&#20379;&#20102;&#21487;&#33021;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#65292;&#21363;&#20351;&#22312;&#30456;&#21516;&#21021;&#22987;&#21270;&#26465;&#20214;&#19979;&#65292;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#32463;&#24120;&#20135;&#29983;&#20855;&#26377;&#21151;&#33021;&#30456;&#20284;&#20294;&#22312;&#26435;&#37325;&#31354;&#38388;&#20013;&#20998;&#25955;&#30340;&#35299;&#65292;&#36825;&#23548;&#33268;&#20102;&#32447;&#24615;&#27169;&#22359;&#36830;&#36890;&#24615;&#65288;LMC&#65289;&#30340;&#23616;&#38480;&#24615;&#12290;&#20811;&#26381;&#36825;&#20123;&#23616;&#38480;&#24615;&#23545;&#20110;&#29702;&#35299;&#28145;&#24230;&#23398;&#20064;&#21160;&#24577;&#21644;&#25552;&#39640;&#27169;&#22411;&#34701;&#21512;&#31639;&#27861;&#33267;&#20851;&#37325;&#35201;&#12290;&#20197;&#21069;&#30340;&#30740;&#31350;&#24378;&#35843;&#32622;&#25442;&#23545;&#31216;&#24615;&#22312;&#36890;&#36807;&#32593;&#32476;&#32622;&#25442;&#20943;&#23569;&#35757;&#32451;&#21518;&#30340;&#23616;&#38480;&#24615;&#26041;&#38754;&#30340;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#20107;&#21518;&#30340;&#26041;&#27861;&#38656;&#35201;&#39069;&#22806;&#30340;&#35745;&#31639;&#65292;&#22312;&#26356;&#22823;&#12289;&#26356;&#22797;&#26434;&#30340;&#27169;&#22411;&#65288;&#22914;ViT&#65292;LLM&#65289;&#19978;&#25928;&#26524;&#36739;&#24046;&#65292;&#22240;&#20026;&#23384;&#22312;&#22823;&#37327;&#30340;&#32622;&#25442;&#30697;&#38453;&#12290;&#22240;&#27492;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#35757;&#32451;&#36807;&#31243;&#20013;&#31070;&#32463;&#20803;&#30340;&#23545;&#40784;&#12290;&#25105;&#20204;&#30340;&#20551;&#35774;&#26159;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#30340;&#32622;&#25442;&#23376;&#31354;&#38388;&#21487;&#20197;&#20813;&#36153;&#20943;&#23569;LMC&#30340;&#23616;&#38480;&#24615;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#21021;&#22987;&#21270;&#26102;&#36827;&#34892;&#20462;&#21098;&#21487;&#20197;&#25903;&#25345;&#36825;&#19968;&#20551;&#35774;&#12290;&#38500;&#20102;&#20462;&#21098;&#20043;&#22806;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;TNA-PFN&#65292;&#19968;&#31181;&#31616;&#21333;&#32780;&#26080;&#25439;&#30340;&#31639;&#27861;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#20351;&#29992;&#37096;&#20998;&#26799;&#24230;&#25513;&#30721;&#12290;TNA-PFN&#22312;&#29702;&#35770;&#19978;&#21644;&#23454;&#39564;&#19978;&#37117;&#24471;&#21040;&#20102;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;
In deep learning, stochastic gradient descent often yields functionally similar yet widely scattered solutions in the weight space even under the same initialization, causing barriers in the Linear Mode Connectivity (LMC) landscape. Overcoming these barriers is crucial for understanding deep learning dynamics and enhancing model-fusion algorithms. Previous studies highlight the role of permutation symmetry in reducing post-training barriers through network permutation. However, these post-hoc methods, demanding extra computations, are less effective for larger, complex models (e.g., ViT, LLM) due to numerous permutation matrices. Thus, in this paper, we study training-time neuron alignment. Our hypothesis suggests that training-time permutation subspace can reduce LMC barriers for free. We find that pruning at initialization supports this. Beyond pruning, we introduce TNA-PFN, a simple yet lossless algorithm using a partial gradient mask during training. TNA-PFN is theoretically and em
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#24314;&#31435;&#21644;&#20998;&#26512;&#22240;&#26524;&#29109;&#21644;&#22240;&#26524;&#20449;&#24687;&#22686;&#30410;&#30340;&#22522;&#26412;&#24615;&#36136;&#65292;&#21253;&#25324;&#30028;&#38480;&#21644;&#38142;&#35268;&#21017;&#65292;&#38416;&#26126;&#20102;&#22240;&#26524;&#29109;&#19982;&#38543;&#26426;&#24178;&#39044;&#30340;&#20851;&#31995;&#65292;&#24182;&#25552;&#20986;&#20102;&#22240;&#26524;&#26465;&#20214;&#29109;&#21644;&#22240;&#26524;&#26465;&#20214;&#20449;&#24687;&#22686;&#30410;&#30340;&#23450;&#20041;&#65292;&#20026;&#25552;&#21319;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#38138;&#24179;&#20102;&#36947;&#36335;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01341</link><description>&lt;p&gt;
&#22240;&#26524;&#29109;&#21644;&#20449;&#24687;&#22686;&#30410;&#30340;&#22522;&#26412;&#24615;&#36136;
&lt;/p&gt;
&lt;p&gt;
Fundamental Properties of Causal Entropy and Information Gain
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01341
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#24314;&#31435;&#21644;&#20998;&#26512;&#22240;&#26524;&#29109;&#21644;&#22240;&#26524;&#20449;&#24687;&#22686;&#30410;&#30340;&#22522;&#26412;&#24615;&#36136;&#65292;&#21253;&#25324;&#30028;&#38480;&#21644;&#38142;&#35268;&#21017;&#65292;&#38416;&#26126;&#20102;&#22240;&#26524;&#29109;&#19982;&#38543;&#26426;&#24178;&#39044;&#30340;&#20851;&#31995;&#65292;&#24182;&#25552;&#20986;&#20102;&#22240;&#26524;&#26465;&#20214;&#29109;&#21644;&#22240;&#26524;&#26465;&#20214;&#20449;&#24687;&#22686;&#30410;&#30340;&#23450;&#20041;&#65292;&#20026;&#25552;&#21319;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#38138;&#24179;&#20102;&#36947;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#21457;&#23637;&#20351;&#24471;&#33021;&#22815;&#37327;&#21270;&#22312;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;(SCM)&#19979;&#30340;&#22240;&#26524;&#25511;&#21046;&#12290;&#36825;&#26159;&#36890;&#36807;&#24341;&#20837;&#19968;&#20123;&#37327;&#26469;&#32534;&#30721;&#22312;&#24178;&#39044;&#21478;&#19968;&#20010;&#21464;&#37327;&#26102;&#26576;&#20010;&#21464;&#37327;&#29109;&#30340;&#21464;&#21270;&#26469;&#23454;&#29616;&#30340;&#12290;&#36825;&#20123;&#37327;&#34987;&#21629;&#21517;&#20026;&#22240;&#26524;&#29109;&#21644;&#22240;&#26524;&#20449;&#24687;&#22686;&#30410;&#65292;&#26088;&#22312;&#35299;&#20915;&#29616;&#26377;&#20449;&#24687;&#35770;&#26041;&#27861;&#22312;&#22240;&#26524;&#24615;&#22312;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#20013;&#36215;&#20851;&#38190;&#20316;&#29992;&#26102;&#30340;&#23616;&#38480;&#24615;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#36890;&#36807;&#24314;&#31435;&#21644;&#20998;&#26512;&#36825;&#20123;&#27010;&#24565;&#30340;&#22522;&#26412;&#24615;&#36136;&#65292;&#21253;&#25324;&#30028;&#38480;&#21644;&#38142;&#35268;&#21017;&#65292;&#23545;&#22240;&#26524;&#29109;&#21644;&#22240;&#26524;&#20449;&#24687;&#22686;&#30410;&#30340;&#27010;&#24565;&#36827;&#34892;&#20102;&#24418;&#24335;&#19978;&#30340;&#29702;&#35299;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#38416;&#26126;&#20102;&#22240;&#26524;&#29109;&#19982;&#38543;&#26426;&#24178;&#39044;&#30340;&#20851;&#31995;&#65292;&#24182;&#25552;&#20986;&#20102;&#22240;&#26524;&#26465;&#20214;&#29109;&#21644;&#22240;&#26524;&#26465;&#20214;&#20449;&#24687;&#22686;&#30410;&#30340;&#23450;&#20041;&#12290;&#24635;&#20307;&#32780;&#35328;&#65292;&#36825;&#20010;&#25506;&#32034;&#20026;&#25552;&#21319;&#22240;&#26524;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#38138;&#24179;&#20102;&#36947;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent developments enable the quantification of causal control given a structural causal model (SCM). This has been accomplished by introducing quantities which encode changes in the entropy of one variable when intervening on another. These measures, named causal entropy and causal information gain, aim to address limitations in existing information theoretical approaches for machine learning tasks where causality plays a crucial role. They have not yet been properly mathematically studied. Our research contributes to the formal understanding of the notions of causal entropy and causal information gain by establishing and analyzing fundamental properties of these concepts, including bounds and chain rules. Furthermore, we elucidate the relationship between causal entropy and stochastic interventions. We also propose definitions for causal conditional entropy and causal conditional information gain. Overall, this exploration paves the way for enhancing causal machine learning tasks th
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#36890;&#36807;&#25512;&#23548;&#26680;&#30697;&#38453;&#30340;&#29305;&#24449;&#25968;&#30028;&#38480;&#65292;&#22686;&#24378;&#20102;&#26680;&#23725;&#22238;&#24402;&#30340;&#27979;&#35797;&#35823;&#24046;&#30028;&#38480;&#12290;&#23545;&#20110;&#22810;&#39033;&#24335;&#35889;&#34928;&#20943;&#30340;&#26680;&#65292;&#25105;&#20204;&#24674;&#22797;&#20102;&#20808;&#21069;&#30340;&#32467;&#26524;&#65307;&#23545;&#20110;&#25351;&#25968;&#35889;&#34928;&#20943;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26032;&#30340;&#38750;&#24179;&#20961;&#30340;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#29305;&#24449;&#35889;&#34928;&#20943;&#22810;&#39033;&#24335;&#30340;&#26680;&#22238;&#24402;&#22120;&#20855;&#26377;&#33391;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#32780;&#29305;&#24449;&#35889;&#25351;&#25968;&#34928;&#20943;&#30340;&#26680;&#22238;&#24402;&#22120;&#21017;&#20855;&#26377;&#28798;&#38590;&#24615;&#30340;&#36807;&#25311;&#21512;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01297</link><description>&lt;p&gt;
&#36890;&#36807;&#29305;&#24449;&#35889;&#34920;&#24449;&#26680;&#23725;&#22238;&#24402;&#30340;&#36807;&#25311;&#21512;
&lt;/p&gt;
&lt;p&gt;
Characterizing Overfitting in Kernel Ridgeless Regression Through the Eigenspectrum
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01297
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#36890;&#36807;&#25512;&#23548;&#26680;&#30697;&#38453;&#30340;&#29305;&#24449;&#25968;&#30028;&#38480;&#65292;&#22686;&#24378;&#20102;&#26680;&#23725;&#22238;&#24402;&#30340;&#27979;&#35797;&#35823;&#24046;&#30028;&#38480;&#12290;&#23545;&#20110;&#22810;&#39033;&#24335;&#35889;&#34928;&#20943;&#30340;&#26680;&#65292;&#25105;&#20204;&#24674;&#22797;&#20102;&#20808;&#21069;&#30340;&#32467;&#26524;&#65307;&#23545;&#20110;&#25351;&#25968;&#35889;&#34928;&#20943;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26032;&#30340;&#38750;&#24179;&#20961;&#30340;&#30028;&#38480;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#29305;&#24449;&#35889;&#34928;&#20943;&#22810;&#39033;&#24335;&#30340;&#26680;&#22238;&#24402;&#22120;&#20855;&#26377;&#33391;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#32780;&#29305;&#24449;&#35889;&#25351;&#25968;&#34928;&#20943;&#30340;&#26680;&#22238;&#24402;&#22120;&#21017;&#20855;&#26377;&#28798;&#38590;&#24615;&#30340;&#36807;&#25311;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25512;&#23548;&#20102;&#26680;&#30697;&#38453;&#30340;&#26465;&#20214;&#25968;&#30340;&#26032;&#30028;&#38480;&#65292;&#28982;&#21518;&#21033;&#29992;&#36825;&#20123;&#30028;&#38480;&#22686;&#24378;&#20102;&#22312;&#22266;&#23450;&#36755;&#20837;&#32500;&#24230;&#30340;&#36807;&#21442;&#25968;&#21270;&#21306;&#22495;&#20013;&#26680;&#23725;&#22238;&#24402;&#30340;&#29616;&#26377;&#38750;&#28176;&#36817;&#27979;&#35797;&#35823;&#24046;&#30028;&#38480;&#12290;&#23545;&#20110;&#20855;&#26377;&#22810;&#39033;&#24335;&#35889;&#34928;&#20943;&#30340;&#26680;&#65292;&#25105;&#20204;&#24674;&#22797;&#20102;&#20808;&#21069;&#24037;&#20316;&#30340;&#30028;&#38480;&#65307;&#23545;&#20110;&#25351;&#25968;&#34928;&#20943;&#65292;&#25105;&#20204;&#30340;&#30028;&#38480;&#26159;&#38750;&#24179;&#20961;&#21644;&#26032;&#39062;&#30340;&#12290;&#25105;&#20204;&#23545;&#36807;&#25311;&#21512;&#30340;&#32467;&#35770;&#26159;&#21452;&#37325;&#30340;&#65306;(i) &#35889;&#34928;&#20943;&#22810;&#39033;&#24335;&#30340;&#26680;&#22238;&#24402;&#22120;&#24517;&#39035;&#22312;&#23384;&#22312;&#22122;&#22768;&#26631;&#35760;&#30340;&#35757;&#32451;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#24471;&#21040;&#24456;&#22909;&#30340;&#27867;&#21270;&#65307;&#36825;&#20123;&#27169;&#22411;&#34920;&#29616;&#20986;&#25152;&#35859;&#30340;&#28201;&#21644;&#36807;&#25311;&#21512;&#65307;(ii) &#22914;&#26524;&#20219;&#20309;&#26680;&#23725;&#22238;&#24402;&#22120;&#30340;&#29305;&#24449;&#35889;&#25351;&#25968;&#34928;&#20943;&#65292;&#21017;&#20854;&#27867;&#21270;&#24046;&#65292;&#21363;&#34920;&#29616;&#20986;&#28798;&#38590;&#24615;&#36807;&#25311;&#21512;&#12290;&#36825;&#22686;&#21152;&#20102;&#26680;&#23725;&#22238;&#24402;&#22120;&#34920;&#29616;&#20986;&#33391;&#24615;&#36807;&#25311;&#21512;&#30340;&#21487;&#29992;&#29305;&#24449;&#35889;&#34928;&#20943;&#27425;&#22810;&#39033;&#24335;&#30340;&#26497;&#31471;&#24773;&#20917;&#30340;&#34920;&#24449;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#32467;&#21512;&#20102;&#26032;&#30340;&#38543;&#26426;&#30697;&#38453;&#29702;&#35770;(RMT)&#12290;
&lt;/p&gt;
&lt;p&gt;
We derive new bounds for the condition number of kernel matrices, which we then use to enhance existing non-asymptotic test error bounds for kernel ridgeless regression in the over-parameterized regime for a fixed input dimension. For kernels with polynomial spectral decay, we recover the bound from previous work; for exponential decay, our bound is non-trivial and novel.   Our conclusion on overfitting is two-fold: (i) kernel regressors whose eigenspectrum decays polynomially must generalize well, even in the presence of noisy labeled training data; these models exhibit so-called tempered overfitting; (ii) if the eigenspectrum of any kernel ridge regressor decays exponentially, then it generalizes poorly, i.e., it exhibits catastrophic overfitting. This adds to the available characterization of kernel ridge regressors exhibiting benign overfitting as the extremal case where the eigenspectrum of the kernel decays sub-polynomially. Our analysis combines new random matrix theory (RMT) te
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;Transformer&#26550;&#26500;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#19978;&#19979;&#25991;&#20013;&#23398;&#20064;&#38750;&#32447;&#24615;&#29305;&#24449;&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#22312;&#22343;&#22330;&#21644;&#20004;&#20010;&#26102;&#38388;&#23610;&#24230;&#30340;&#26497;&#38480;&#24773;&#20917;&#19979;&#30340;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#21442;&#25968;&#20998;&#24067;&#30340;&#25439;&#22833;&#26223;&#35266;&#34429;&#28982;&#39640;&#24230;&#38750;&#20984;&#65292;&#20294;&#21464;&#24471;&#30456;&#24403;&#28201;&#21644;&#65292;&#24182;&#24314;&#31435;&#20102;&#26032;&#30340;&#26041;&#27861;&#26469;&#33719;&#24471;&#20855;&#20307;&#30340;&#25913;&#36827;&#36895;&#29575;&#65292;&#36825;&#23558;&#26377;&#21161;&#20110;&#22686;&#24378;&#19978;&#19979;&#25991;&#23398;&#20064;&#30340;&#33021;&#21147;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01258</link><description>&lt;p&gt;
Transformers&#22312;&#19978;&#19979;&#25991;&#20013;&#23398;&#20064;&#38750;&#32447;&#24615;&#29305;&#24449;&#65306;&#20851;&#20110;&#27880;&#24847;&#21147;&#22330;&#26223;&#20013;&#30340;&#38750;&#20984;&#22343;&#22330;&#21160;&#24577;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Transformers Learn Nonlinear Features In Context: Nonconvex Mean-field Dynamics on the Attention Landscape
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01258
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;Transformer&#26550;&#26500;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#22312;&#19978;&#19979;&#25991;&#20013;&#23398;&#20064;&#38750;&#32447;&#24615;&#29305;&#24449;&#30340;&#20248;&#21270;&#38382;&#39064;&#65292;&#36890;&#36807;&#22312;&#22343;&#22330;&#21644;&#20004;&#20010;&#26102;&#38388;&#23610;&#24230;&#30340;&#26497;&#38480;&#24773;&#20917;&#19979;&#30340;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102;&#21442;&#25968;&#20998;&#24067;&#30340;&#25439;&#22833;&#26223;&#35266;&#34429;&#28982;&#39640;&#24230;&#38750;&#20984;&#65292;&#20294;&#21464;&#24471;&#30456;&#24403;&#28201;&#21644;&#65292;&#24182;&#24314;&#31435;&#20102;&#26032;&#30340;&#26041;&#27861;&#26469;&#33719;&#24471;&#20855;&#20307;&#30340;&#25913;&#36827;&#36895;&#29575;&#65292;&#36825;&#23558;&#26377;&#21161;&#20110;&#22686;&#24378;&#19978;&#19979;&#25991;&#23398;&#20064;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;Transformer&#26550;&#26500;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#23637;&#31034;&#20102;&#22312;&#19978;&#19979;&#25991;&#20013;&#23398;&#20064;&#30340;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;&#20851;&#20110;&#36825;&#19968;&#29616;&#35937;&#20135;&#29983;&#30340;&#29616;&#26377;&#29702;&#35770;&#30740;&#31350;&#20165;&#38480;&#20110;&#23545;&#32447;&#24615;&#22238;&#24402;&#20219;&#21153;&#19978;&#35757;&#32451;&#30340;&#21333;&#23618;&#27880;&#24847;&#21147;&#30340;&#21160;&#24577;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#30001;&#20840;&#36830;&#25509;&#23618;&#21644;&#32447;&#24615;&#27880;&#24847;&#21147;&#23618;&#32452;&#25104;&#30340;Transformer&#30340;&#20248;&#21270;&#12290;MLP&#20805;&#24403;&#20102;&#19968;&#20010;&#24120;&#35265;&#30340;&#38750;&#32447;&#24615;&#34920;&#31034;&#25110;&#29305;&#24449;&#26144;&#23556;&#65292;&#26497;&#22823;&#22320;&#22686;&#24378;&#20102;&#19978;&#19979;&#25991;&#23398;&#20064;&#30340;&#33021;&#21147;&#12290;&#25105;&#20204;&#22312;&#22343;&#22330;&#21644;&#20004;&#20010;&#26102;&#38388;&#23610;&#24230;&#30340;&#26497;&#38480;&#24773;&#20917;&#19979;&#35777;&#26126;&#20102;&#21442;&#25968;&#20998;&#24067;&#30340;&#26080;&#38480;&#32500;&#25439;&#22833;&#26223;&#35266;&#65292;&#34429;&#28982;&#39640;&#24230;&#38750;&#20984;&#65292;&#20294;&#21464;&#24471;&#30456;&#24403;&#28201;&#21644;&#12290;&#25105;&#20204;&#36824;&#20998;&#26512;&#20102;&#22343;&#22330;&#21160;&#24577;&#30340;&#20108;&#38454;&#31283;&#23450;&#24615;&#65292;&#24182;&#34920;&#26126;Wasserstein&#26799;&#24230;&#27969;&#20960;&#20046;&#24635;&#26159;&#36991;&#24320;&#38797;&#28857;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#33719;&#24471;&#36828;&#31163;&#20020;&#30028;&#28857;&#21644;&#25509;&#36817;&#20020;&#30028;&#28857;&#30340;&#20855;&#20307;&#25913;&#36827;&#36895;&#29575;&#30340;&#26032;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Large language models based on the Transformer architecture have demonstrated impressive capabilities to learn in context. However, existing theoretical studies on how this phenomenon arises are limited to the dynamics of a single layer of attention trained on linear regression tasks. In this paper, we study the optimization of a Transformer consisting of a fully connected layer followed by a linear attention layer. The MLP acts as a common nonlinear representation or feature map, greatly enhancing the power of in-context learning. We prove in the mean-field and two-timescale limit that the infinite-dimensional loss landscape for the distribution of parameters, while highly nonconvex, becomes quite benign. We also analyze the second-order stability of mean-field dynamics and show that Wasserstein gradient flow almost always avoids saddle points. Furthermore, we establish novel methods for obtaining concrete improvement rates both away from and near critical points. This represents the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#32422;&#26463;&#26465;&#20214;&#65292;&#20351;&#29992;&#20108;&#27425;&#32422;&#26463;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010;&#65288;MIQCQP&#65289;&#26469;&#20272;&#35745;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;Lipschitz&#24120;&#25968;&#12290;&#36825;&#20123;&#38382;&#39064;&#30340;&#35299;&#21487;&#20197;&#32473;&#20986;Lipschitz&#24120;&#25968;&#30340;&#19979;&#30028;&#21644;&#19978;&#30028;&#65292;&#24182;&#19988;&#24403;&#29305;&#23450;&#26465;&#20214;&#28385;&#36275;&#26102;&#65292;&#23427;&#20204;&#19982;&#31934;&#30830;&#30340;Lipschitz&#24120;&#25968;&#37325;&#21512;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01199</link><description>&lt;p&gt;
MIQCQP reformulation of the ReLU neural networks Lipschitz constant estimation problem
&lt;/p&gt;
&lt;p&gt;
MIQCQP reformulation of the ReLU neural networks Lipschitz constant estimation problem
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01199
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#32422;&#26463;&#26465;&#20214;&#65292;&#20351;&#29992;&#20108;&#27425;&#32422;&#26463;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010;&#65288;MIQCQP&#65289;&#26469;&#20272;&#35745;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;Lipschitz&#24120;&#25968;&#12290;&#36825;&#20123;&#38382;&#39064;&#30340;&#35299;&#21487;&#20197;&#32473;&#20986;Lipschitz&#24120;&#25968;&#30340;&#19979;&#30028;&#21644;&#19978;&#30028;&#65292;&#24182;&#19988;&#24403;&#29305;&#23450;&#26465;&#20214;&#28385;&#36275;&#26102;&#65292;&#23427;&#20204;&#19982;&#31934;&#30830;&#30340;Lipschitz&#24120;&#25968;&#37325;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20247;&#25152;&#21608;&#30693;&#65292;&#20026;&#20102;&#30830;&#20445;&#31070;&#32463;&#32593;&#32476;&#30340;&#40065;&#26834;&#24615;&#65292;&#20854;Lipschitz&#24120;&#25968;&#36215;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#23427;&#30340;&#35745;&#31639;&#26159;NP&#22256;&#38590;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#36890;&#36807;&#23558;&#27599;&#19968;&#23618;&#30340;&#28608;&#27963;&#21306;&#22495;&#20316;&#20026;&#26032;&#30340;&#32422;&#26463;&#32771;&#34385;&#36827;&#21435;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31070;&#32463;&#32593;&#32476;Lipschitz&#20272;&#35745;&#38382;&#39064;&#30340;&#26032;&#30340;&#20108;&#27425;&#32422;&#26463;&#28151;&#21512;&#25972;&#25968;&#35268;&#21010;&#65288;MIQCQP&#65289;&#24418;&#24335;&#12290;&#36825;&#20123;&#38382;&#39064;&#30340;&#35299;&#32473;&#20986;&#20102;Lipschitz&#24120;&#25968;&#30340;&#19979;&#30028;&#21644;&#19978;&#30028;&#65292;&#24182;&#35814;&#32454;&#35752;&#35770;&#20102;&#23427;&#20204;&#19982;&#31934;&#30830;Lipschitz&#24120;&#25968;&#19968;&#33268;&#30340;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
It is well established that to ensure or certify the robustness of a neural network, its Lipschitz constant plays a prominent role. However, its calculation is NP-hard. In this note, by taking into account activation regions at each layer as new constraints, we propose new quadratically constrained MIP formulations for the neural network Lipschitz estimation problem. The solutions of these problems give lower bounds and upper bounds of the Lipschitz constant and we detail conditions when they coincide with the exact Lipschitz constant.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26680;&#20998;&#31867;&#22120;&#22312;Sobolev&#31354;&#38388;&#20013;&#30340;&#26368;&#20248;&#24615;&#36136;&#65292;&#24182;&#36890;&#36807;&#23545;&#26465;&#20214;&#27010;&#29575;&#30340;&#20551;&#35774;&#21644;&#26680;&#22238;&#24402;&#29702;&#35770;&#30340;&#24212;&#29992;&#65292;&#23548;&#20986;&#20102;&#26680;&#20998;&#31867;&#22120;&#30340;&#20998;&#31867;&#36229;&#39069;&#39118;&#38505;&#19978;&#30028;&#21644;Sobolev&#31354;&#38388;&#30340;&#26497;&#23567;&#26497;&#22823;&#19979;&#30028;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#26041;&#27861;&#26469;&#20272;&#35745;&#25554;&#20540;&#24179;&#28369;&#24230;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#23454;&#38469;&#25968;&#25454;&#38598;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01148</link><description>&lt;p&gt;
Sobolev&#31354;&#38388;&#20013;&#26680;&#20998;&#31867;&#22120;&#30340;&#26368;&#20248;&#24615;
&lt;/p&gt;
&lt;p&gt;
The Optimality of Kernel Classifiers in Sobolev Space
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01148
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26680;&#20998;&#31867;&#22120;&#22312;Sobolev&#31354;&#38388;&#20013;&#30340;&#26368;&#20248;&#24615;&#36136;&#65292;&#24182;&#36890;&#36807;&#23545;&#26465;&#20214;&#27010;&#29575;&#30340;&#20551;&#35774;&#21644;&#26680;&#22238;&#24402;&#29702;&#35770;&#30340;&#24212;&#29992;&#65292;&#23548;&#20986;&#20102;&#26680;&#20998;&#31867;&#22120;&#30340;&#20998;&#31867;&#36229;&#39069;&#39118;&#38505;&#19978;&#30028;&#21644;Sobolev&#31354;&#38388;&#30340;&#26497;&#23567;&#26497;&#22823;&#19979;&#30028;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#26041;&#27861;&#26469;&#20272;&#35745;&#25554;&#20540;&#24179;&#28369;&#24230;&#65292;&#24182;&#23558;&#20854;&#24212;&#29992;&#20110;&#23454;&#38469;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26680;&#26041;&#27861;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#24191;&#27867;&#24212;&#29992;&#65292;&#29305;&#21035;&#26159;&#29992;&#20110;&#20998;&#31867;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#26680;&#20998;&#31867;&#30340;&#29702;&#35770;&#20998;&#26512;&#20173;&#28982;&#26377;&#38480;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#26680;&#20998;&#31867;&#22120;&#30340;&#32479;&#35745;&#24615;&#33021;&#12290;&#22312;&#23545;&#26465;&#20214;&#27010;&#29575;$\eta(x)=\mathbb{P}(Y=1\mid X=x)$&#20316;&#20986;&#19968;&#20123;&#28201;&#21644;&#30340;&#20551;&#35774;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;&#26680;&#22238;&#24402;&#29702;&#35770;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#23548;&#20986;&#20102;&#26680;&#20998;&#31867;&#22120;&#20998;&#31867;&#36229;&#39069;&#39118;&#38505;&#30340;&#19978;&#30028;&#12290;&#25105;&#20204;&#36824;&#24471;&#21040;&#20102;Sobolev&#31354;&#38388;&#30340;&#26497;&#23567;&#26497;&#22823;&#19979;&#30028;&#65292;&#20174;&#32780;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#20998;&#31867;&#22120;&#30340;&#26368;&#20248;&#24615;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#21487;&#20197;&#25193;&#23637;&#21040;&#36229;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#30340;&#27867;&#21270;&#35823;&#24046;&#12290;&#20026;&#20102;&#20351;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#22312;&#23454;&#38469;&#29615;&#22659;&#20013;&#26356;&#21152;&#36866;&#29992;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#20272;&#35745;$2\eta(x)-1$&#25554;&#20540;&#24179;&#28369;&#24230;&#30340;&#31616;&#21333;&#26041;&#27861;&#65292;&#24182;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;&#23454;&#38469;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
Kernel methods are widely used in machine learning, especially for classification problems. However, the theoretical analysis of kernel classification is still limited. This paper investigates the statistical performances of kernel classifiers. With some mild assumptions on the conditional probability $\eta(x)=\mathbb{P}(Y=1\mid X=x)$, we derive an upper bound on the classification excess risk of a kernel classifier using recent advances in the theory of kernel regression. We also obtain a minimax lower bound for Sobolev spaces, which shows the optimality of the proposed classifier. Our theoretical results can be extended to the generalization error of overparameterized neural network classifiers. To make our theoretical results more applicable in realistic settings, we also propose a simple method to estimate the interpolation smoothness of $2\eta(x)-1$ and apply the method to real datasets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#35299;&#32544;&#31163;&#25955;&#22270;&#33258;&#32534;&#30721;&#22120;(DGA)&#21644;&#35299;&#32544;&#21464;&#20998;&#22270;&#33258;&#32534;&#30721;&#22120;(DVGA)&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#29983;&#25104;&#27169;&#22411;&#26469;&#23398;&#20064;&#35299;&#32544;&#34920;&#31034;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01143</link><description>&lt;p&gt;
&#29992;&#35299;&#32544;&#31163;&#25955;&#22270;&#33258;&#32534;&#30721;&#22120;&#23398;&#20064;&#32593;&#32476;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Learning Network Representations with Disentangled Graph Auto-Encoder
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01143
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#35299;&#32544;&#31163;&#25955;&#22270;&#33258;&#32534;&#30721;&#22120;(DGA)&#21644;&#35299;&#32544;&#21464;&#20998;&#22270;&#33258;&#32534;&#30721;&#22120;(DVGA)&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#29983;&#25104;&#27169;&#22411;&#26469;&#23398;&#20064;&#35299;&#32544;&#34920;&#31034;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
(&#21464;&#20998;)&#22270;&#33258;&#32534;&#30721;&#22120;&#24191;&#27867;&#29992;&#20110;&#23398;&#20064;&#22270;&#32467;&#26500;&#21270;&#25968;&#25454;&#30340;&#34920;&#31034;&#12290;&#28982;&#32780;&#65292;&#29616;&#23454;&#19990;&#30028;&#22270;&#30340;&#24418;&#25104;&#26159;&#19968;&#20010;&#30001;&#28508;&#22312;&#22240;&#32032;&#24433;&#21709;&#30340;&#22797;&#26434;&#21644;&#24322;&#36136;&#30340;&#36807;&#31243;&#12290;&#29616;&#26377;&#30340;&#32534;&#30721;&#22120;&#22522;&#26412;&#19978;&#26159;&#25972;&#20307;&#30340;&#65292;&#24573;&#35270;&#20102;&#28508;&#22312;&#22240;&#32032;&#30340;&#32416;&#32544;&#12290;&#36825;&#19981;&#20165;&#20351;&#24471;&#22270;&#20998;&#26512;&#20219;&#21153;&#19981;&#22826;&#26377;&#25928;&#65292;&#32780;&#19988;&#20351;&#24471;&#29702;&#35299;&#21644;&#35299;&#37322;&#36825;&#20123;&#34920;&#31034;&#21464;&#24471;&#26356;&#21152;&#22256;&#38590;&#12290;&#29992;(&#21464;&#20998;)&#22270;&#33258;&#32534;&#30721;&#22120;&#23398;&#20064;&#35299;&#32544;&#30340;&#22270;&#34920;&#31034;&#38754;&#20020;&#30528;&#37325;&#35201;&#25361;&#25112;&#65292;&#22312;&#29616;&#26377;&#25991;&#29486;&#20013;&#23578;&#26410;&#24471;&#21040;&#20805;&#20998;&#25506;&#32034;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#35299;&#32544;&#31163;&#25955;&#22270;&#33258;&#32534;&#30721;&#22120;(DGA)&#21644;&#35299;&#32544;&#21464;&#20998;&#22270;&#33258;&#32534;&#30721;&#22120;(DVGA)&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#29983;&#25104;&#27169;&#22411;&#26469;&#23398;&#20064;&#35299;&#32544;&#34920;&#31034;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#39318;&#20808;&#35774;&#35745;&#20102;&#19968;&#20010;&#35299;&#32544;&#30340;&#22270;&#21367;&#31215;&#32593;&#32476;&#65292;&#20351;&#29992;&#22810;&#36890;&#36947;&#28040;&#24687;&#20256;&#36882;&#23618;&#20316;&#20026;&#32534;&#30721;&#22120;&#65292;&#32858;&#21512;&#19982;&#27599;&#20010;&#33410;&#28857;&#30456;&#20851;&#30340;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;
The (variational) graph auto-encoder is extensively employed for learning representations of graph-structured data. However, the formation of real-world graphs is a complex and heterogeneous process influenced by latent factors. Existing encoders are fundamentally holistic, neglecting the entanglement of latent factors. This not only makes graph analysis tasks less effective but also makes it harder to understand and explain the representations. Learning disentangled graph representations with (variational) graph auto-encoder poses significant challenges, and remains largely unexplored in the existing literature. In this article, we introduce the Disentangled Graph Auto-Encoder (DGA) and Disentangled Variational Graph Auto-Encoder (DVGA), approaches that leverage generative models to learn disentangled representations. Specifically, we first design a disentangled graph convolutional network with multi-channel message-passing layers, as the encoder aggregating information related to eac
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#32447;&#33258;&#36866;&#24212;&#39044;&#27979;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#36882;&#20943;&#27493;&#38271;&#26469;&#25913;&#36827;&#22312;&#20219;&#24847;&#24207;&#21015;&#19978;&#30340;&#35206;&#30422;&#29575;&#20445;&#35777;&#65292;&#24182;&#19988;&#33021;&#22815;&#21516;&#26102;&#20272;&#35745;&#24635;&#20307;&#20998;&#20301;&#25968;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01139</link><description>&lt;p&gt;
&#22312;&#32447;&#33258;&#36866;&#24212;&#39044;&#27979;&#26041;&#27861;&#20013;&#24102;&#26377;&#36882;&#20943;&#27493;&#38271;
&lt;/p&gt;
&lt;p&gt;
Online conformal prediction with decaying step sizes
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01139
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22312;&#32447;&#33258;&#36866;&#24212;&#39044;&#27979;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#36882;&#20943;&#27493;&#38271;&#26469;&#25913;&#36827;&#22312;&#20219;&#24847;&#24207;&#21015;&#19978;&#30340;&#35206;&#30422;&#29575;&#20445;&#35777;&#65292;&#24182;&#19988;&#33021;&#22815;&#21516;&#26102;&#20272;&#35745;&#24635;&#20307;&#20998;&#20301;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#19968;&#31181;&#24102;&#26377;&#36882;&#20943;&#27493;&#38271;&#30340;&#22312;&#32447;&#33258;&#36866;&#24212;&#39044;&#27979;&#26041;&#27861;&#12290;&#21644;&#20043;&#21069;&#30340;&#26041;&#27861;&#19968;&#26679;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20063;&#33021;&#22312;&#20219;&#24847;&#24207;&#21015;&#19978;&#22238;&#28335;&#24615;&#22320;&#20445;&#35777;&#35206;&#30422;&#29575;&#12290;&#28982;&#32780;&#65292;&#19982;&#20043;&#21069;&#30340;&#26041;&#27861;&#19981;&#21516;&#30340;&#26159;&#65292;&#25105;&#20204;&#33021;&#22815;&#22312;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#21516;&#26102;&#20272;&#35745;&#20986;&#24635;&#20307;&#20998;&#20301;&#25968;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#21644;&#23454;&#39564;&#35777;&#26126;&#20102;&#26174;&#33879;&#25913;&#36827;&#30340;&#23454;&#38469;&#29305;&#24615;&#65306;&#29305;&#21035;&#26159;&#22312;&#20998;&#24067;&#31283;&#23450;&#30340;&#24773;&#20917;&#19979;&#65292;&#35206;&#30422;&#29575;&#25509;&#36817;&#25152;&#26399;&#26395;&#30340;&#27700;&#24179;&#65292;&#19981;&#20165;&#20165;&#22312;&#35266;&#27979;&#24207;&#21015;&#30340;&#24179;&#22343;&#20540;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a method for online conformal prediction with decaying step sizes. Like previous methods, ours possesses a retrospective guarantee of coverage for arbitrary sequences. However, unlike previous methods, we can simultaneously estimate a population quantile when it exists. Our theory and experiments indicate substantially improved practical properties: in particular, when the distribution is stable, the coverage is close to the desired level for every time point, not just on average over the observed sequence.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#33258;&#36866;&#24212;&#32422;&#26463;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28040;&#38500;&#31639;&#27861;&#65292;&#23558;&#21518;&#24724;&#25511;&#21046;&#22312;$\widetilde{O}(\sqrt{H^3 S^2 ABK})$&#65292;&#25209;&#37327;&#22797;&#26434;&#24230;&#20026;$O(H+\log\log K)$&#12290;&#27492;&#22806;&#65292;&#36824;&#32473;&#20986;&#20102;&#25152;&#26377;&#20855;&#26377;$\widetilde{O}(\sqrt{K})$&#21518;&#24724;&#30028;&#31639;&#27861;&#30340;&#25209;&#37327;&#22797;&#26434;&#24230;&#19979;&#30028;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01111</link><description>&lt;p&gt;
&#22312;&#33258;&#36866;&#24212;&#32422;&#26463;&#19979;&#30340;&#33258;&#23545;&#24328;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#36817;&#20046;&#26368;&#20248;&#35299;
&lt;/p&gt;
&lt;p&gt;
Near-Optimal Reinforcement Learning with Self-Play under Adaptivity Constraints
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01111
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#33258;&#36866;&#24212;&#32422;&#26463;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28040;&#38500;&#31639;&#27861;&#65292;&#23558;&#21518;&#24724;&#25511;&#21046;&#22312;$\widetilde{O}(\sqrt{H^3 S^2 ABK})$&#65292;&#25209;&#37327;&#22797;&#26434;&#24230;&#20026;$O(H+\log\log K)$&#12290;&#27492;&#22806;&#65292;&#36824;&#32473;&#20986;&#20102;&#25152;&#26377;&#20855;&#26377;$\widetilde{O}(\sqrt{K})$&#21518;&#24724;&#30028;&#31639;&#27861;&#30340;&#25209;&#37327;&#22797;&#26434;&#24230;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#33258;&#36866;&#24212;&#32422;&#26463;&#30340;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#65288;MARL&#65289; - &#36825;&#26159;&#19968;&#31181;&#30001;&#23454;&#38469;&#24212;&#29992;&#39537;&#21160;&#30340;&#26032;&#38382;&#39064;&#65292;&#20854;&#20013;&#37096;&#32626;&#26032;&#31574;&#30053;&#26159;&#26114;&#36149;&#30340;&#65292;&#24182;&#19988;&#24517;&#39035;&#26368;&#23567;&#21270;&#31574;&#30053;&#26356;&#26032;&#30340;&#27425;&#25968;&#12290;&#23545;&#20110;&#20004;&#20010;&#29609;&#23478;&#30340;&#38646;&#21644;&#39532;&#23572;&#21487;&#22827;&#21338;&#24328;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#65288;&#31574;&#30053;&#65289;&#22522;&#20110;&#28040;&#38500;&#30340;&#31639;&#27861;&#65292;&#23427;&#22312;&#21518;&#24724;&#20026;$\widetilde{O}(\sqrt{H^3 S^2 ABK})$&#30340;&#24773;&#20917;&#19979;&#65292;&#25209;&#37327;&#22797;&#26434;&#24230;&#20165;&#20026;$O(H+\log\log K)$&#12290;&#22312;&#19978;&#36848;&#24773;&#20917;&#19979;&#65292;$S$&#34920;&#31034;&#29366;&#24577;&#25968;&#65292;$A&#65292;B$&#20998;&#21035;&#20195;&#34920;&#20004;&#20010;&#29609;&#23478;&#30340;&#34892;&#21160;&#25968;&#65292;$H$&#26159;&#26102;&#38388;&#21608;&#26399;&#65292;$K$&#26159;&#28216;&#25103;&#27425;&#25968;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#25152;&#26377;&#20855;&#26377;$\widetilde{O}(\sqrt{K})$&#21518;&#24724;&#30028;&#30340;&#31639;&#27861;&#65292;&#19968;&#31181;&#25209;&#37327;&#22797;&#26434;&#24230;&#30340;&#19979;&#30028;&#20026;$\Omega(\frac{H}{\log_{A}K}+\log\log K)$&#65292;&#36825;&#19982;&#25105;&#20204;&#30340;&#19978;&#30028;&#22312;&#23545;&#25968;&#22240;&#23376;&#19978;&#21305;&#37197;&#12290;&#20316;&#20026;&#21103;&#20135;&#21697;&#65292;&#25105;&#20204;&#30340;&#25216;&#26415;&#33258;&#28982;&#22320;&#25193;&#23637;&#21040;&#23398;&#20064;&#36172;&#21338;&#21338;&#24328;&#21644;&#26080;&#22870;&#21169;&#30340;&#36817;&#20046;&#26368;&#20248;&#25209;&#37327;&#22797;&#26434;&#24230;MARL&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#20123;&#26159;&#36804;&#20170;&#20026;&#27490;&#26368;&#22909;&#30340;&#25104;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of multi-agent reinforcement learning (MARL) with adaptivity constraints -- a new problem motivated by real-world applications where deployments of new policies are costly and the number of policy updates must be minimized. For two-player zero-sum Markov Games, we design a (policy) elimination based algorithm that achieves a regret of $\widetilde{O}(\sqrt{H^3 S^2 ABK})$, while the batch complexity is only $O(H+\log\log K)$. In the above, $S$ denotes the number of states, $A,B$ are the number of actions for the two players respectively, $H$ is the horizon and $K$ is the number of episodes. Furthermore, we prove a batch complexity lower bound $\Omega(\frac{H}{\log_{A}K}+\log\log K)$ for all algorithms with $\widetilde{O}(\sqrt{K})$ regret bound, which matches our upper bound up to logarithmic factors. As a byproduct, our techniques naturally extend to learning bandit games and reward-free MARL within near optimal batch complexity. To the best of our knowledge, these 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#20351;&#29992;&#26031;&#22374;&#20248;&#21270;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#23558;&#26631;&#20934;&#30340;&#39057;&#29575;&#20027;&#20041;&#31070;&#32463;&#32593;&#32476;&#36716;&#21270;&#20026;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65292;&#20197;&#24212;&#23545;&#39044;&#27979;&#24615;&#32500;&#25252;&#20013;&#20272;&#35745;&#21097;&#20313;&#23551;&#21629;&#30340;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01098</link><description>&lt;p&gt;
&#22522;&#20110;&#26031;&#22374;&#20248;&#21270;&#26799;&#24230;&#19979;&#38477;&#30340;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#22312;&#21097;&#20313;&#23551;&#21629;&#20272;&#35745;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Bayesian Deep Learning for Remaining Useful Life Estimation via Stein Variational Gradient Descent
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01098
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#20351;&#29992;&#26031;&#22374;&#20248;&#21270;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#23558;&#26631;&#20934;&#30340;&#39057;&#29575;&#20027;&#20041;&#31070;&#32463;&#32593;&#32476;&#36716;&#21270;&#20026;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65292;&#20197;&#24212;&#23545;&#39044;&#27979;&#24615;&#32500;&#25252;&#20013;&#20272;&#35745;&#21097;&#20313;&#23551;&#21629;&#30340;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39044;&#27979;&#24615;&#32500;&#25252;&#20013;&#65292;&#20272;&#35745;&#29289;&#29702;&#31995;&#32479;&#30340;&#21097;&#20313;&#21487;&#29992;&#23551;&#21629;&#26159;&#19968;&#39033;&#20851;&#38190;&#20219;&#21153;&#12290;&#22312;&#36807;&#21435;&#21313;&#24180;&#20013;&#65292;&#28145;&#24230;&#23398;&#20064;&#22312;&#39044;&#27979;&#24615;&#33021;&#26041;&#38754;&#26174;&#33879;&#25913;&#36827;&#20102;&#20256;&#32479;&#30340;&#22522;&#20110;&#27169;&#22411;&#21644;&#32479;&#35745;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#20026;&#20102;&#20248;&#21270;&#35745;&#21010;&#32500;&#25252;&#25805;&#20316;&#65292;&#37327;&#21270;&#39044;&#27979;&#20013;&#22266;&#26377;&#30340;&#19981;&#30830;&#23450;&#24615;&#20063;&#24456;&#37325;&#35201;&#12290;&#36825;&#20010;&#38382;&#39064;&#21487;&#20197;&#36890;&#36807;&#23558;&#26631;&#20934;&#30340;&#39057;&#29575;&#20027;&#20041;&#31070;&#32463;&#32593;&#32476;&#36716;&#21270;&#20026;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#26469;&#35299;&#20915;&#65292;&#21518;&#32773;&#33021;&#22815;&#33258;&#28982;&#22320;&#22312;&#20272;&#35745;&#21608;&#22260;&#25552;&#20379;&#32622;&#20449;&#21306;&#38388;&#12290;&#23384;&#22312;&#22810;&#31181;&#35757;&#32451;&#36825;&#20123;&#27169;&#22411;&#30340;&#26041;&#27861;&#12290;&#30740;&#31350;&#20154;&#21592;&#20027;&#35201;&#20851;&#27880;&#21442;&#25968;&#21464;&#20998;&#25512;&#29702;&#21644;&#22522;&#20110;&#37319;&#26679;&#30340;&#25216;&#26415;&#65292;&#36825;&#20123;&#25216;&#26415;&#22240;&#36817;&#20284;&#33021;&#21147;&#26377;&#38480;&#21644;&#35745;&#31639;&#36127;&#25285;&#22823;&#32780;&#38395;&#21517;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#26031;&#22374;&#20248;&#21270;&#26799;&#24230;&#19979;&#38477;&#65292;&#36825;&#26159;&#19968;&#31181;&#26368;&#36817;&#25552;&#20986;&#30340;&#36924;&#36817;&#38590;&#20197;&#35745;&#31639;&#20998;&#24067;&#30340;&#31639;&#27861;&#65292;&#20811;&#26381;&#20102;&#19978;&#36848;&#26041;&#27861;&#30340;&#32570;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;
A crucial task in predictive maintenance is estimating the remaining useful life of physical systems. In the last decade, deep learning has improved considerably upon traditional model-based and statistical approaches in terms of predictive performance. However, in order to optimally plan maintenance operations, it is also important to quantify the uncertainty inherent to the predictions. This issue can be addressed by turning standard frequentist neural networks into Bayesian neural networks, which are naturally capable of providing confidence intervals around the estimates. Several methods exist for training those models. Researchers have focused mostly on parametric variational inference and sampling-based techniques, which notoriously suffer from limited approximation power and large computational burden, respectively. In this work, we use Stein variational gradient descent, a recently proposed algorithm for approximating intractable distributions that overcomes the drawbacks of th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#26368;&#23567;&#26377;&#25928;&#35270;&#22270;&#65288;MSVs&#65289;&#30340;&#27010;&#24565;&#65292;&#35813;&#27010;&#24565;&#31867;&#20284;&#20110;&#22810;&#35270;&#22270;&#65292;&#20294;&#36866;&#29992;&#20110;&#23454;&#38469;&#22270;&#20687;&#65292;&#24182;&#19988;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#34920;&#26126;&#65292;MSV&#30340;&#25968;&#37327;&#19982;&#27169;&#22411;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#20043;&#38388;&#23384;&#22312;&#20851;&#31995;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01095</link><description>&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#39044;&#27979;&#20351;&#29992;&#22810;&#23569;&#20010;&#35270;&#22270;&#65311;
&lt;/p&gt;
&lt;p&gt;
How many views does your deep neural network use for prediction?
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01095
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#26368;&#23567;&#26377;&#25928;&#35270;&#22270;&#65288;MSVs&#65289;&#30340;&#27010;&#24565;&#65292;&#35813;&#27010;&#24565;&#31867;&#20284;&#20110;&#22810;&#35270;&#22270;&#65292;&#20294;&#36866;&#29992;&#20110;&#23454;&#38469;&#22270;&#20687;&#65292;&#24182;&#19988;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#34920;&#26126;&#65292;MSV&#30340;&#25968;&#37327;&#19982;&#27169;&#22411;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#20043;&#38388;&#23384;&#22312;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#36827;&#34892;&#20102;&#35768;&#22810;&#29702;&#35770;&#21644;&#23454;&#35777;&#20998;&#26512;&#65292;&#20294;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNN&#65289;&#30340;&#27867;&#21270;&#33021;&#21147;&#20173;&#26410;&#23436;&#20840;&#29702;&#35299;&#12290;&#26368;&#36817;&#65292;Allen-Zhu&#21644;Li&#65288;2023&#65289;&#24341;&#20837;&#20102;&#22810;&#35270;&#22270;&#30340;&#27010;&#24565;&#26469;&#35299;&#37322;DNN&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#20294;&#20182;&#20204;&#30340;&#20027;&#35201;&#30446;&#26631;&#26159;&#38598;&#25104;&#25110;&#33976;&#39311;&#27169;&#22411;&#65292;&#24182;&#26410;&#35752;&#35770;&#29992;&#20110;&#29305;&#23450;&#36755;&#20837;&#39044;&#27979;&#30340;&#22810;&#35270;&#22270;&#20272;&#35745;&#26041;&#27861;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#26368;&#23567;&#26377;&#25928;&#35270;&#22270;&#65288;MSVs&#65289;&#65292;&#23427;&#31867;&#20284;&#20110;&#22810;&#35270;&#22270;&#65292;&#20294;&#21487;&#20197;&#39640;&#25928;&#22320;&#35745;&#31639;&#30495;&#23454;&#22270;&#20687;&#12290;MSVs&#26159;&#36755;&#20837;&#20013;&#30340;&#19968;&#32452;&#26368;&#23567;&#19988;&#19981;&#21516;&#30340;&#29305;&#24449;&#65292;&#27599;&#20010;&#29305;&#24449;&#20445;&#30041;&#20102;&#27169;&#22411;&#23545;&#35813;&#36755;&#20837;&#30340;&#39044;&#27979;&#12290;&#25105;&#20204;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#34920;&#26126;&#65292;&#19981;&#21516;&#27169;&#22411;&#65288;&#21253;&#25324;&#21367;&#31215;&#21644;&#36716;&#25442;&#27169;&#22411;&#65289;&#30340;MSV&#25968;&#37327;&#19982;&#39044;&#27979;&#20934;&#30830;&#24615;&#20043;&#38388;&#23384;&#22312;&#26126;&#30830;&#30340;&#20851;&#31995;&#65292;&#36825;&#34920;&#26126;&#22810;&#35270;&#22270;&#30340;&#35282;&#24230;&#23545;&#20110;&#29702;&#35299;&#65288;&#38750;&#38598;&#25104;&#25110;&#38750;&#33976;&#39311;&#65289;DNN&#30340;&#27867;&#21270;&#33021;&#21147;&#20063;&#24456;&#37325;&#35201;&#12290;
&lt;/p&gt;
&lt;p&gt;
The generalization ability of Deep Neural Networks (DNNs) is still not fully understood, despite numerous theoretical and empirical analyses. Recently, Allen-Zhu &amp; Li (2023) introduced the concept of multi-views to explain the generalization ability of DNNs, but their main target is ensemble or distilled models, and no method for estimating multi-views used in a prediction of a specific input is discussed. In this paper, we propose Minimal Sufficient Views (MSVs), which is similar to multi-views but can be efficiently computed for real images. MSVs is a set of minimal and distinct features in an input, each of which preserves a model's prediction for the input. We empirically show that there is a clear relationship between the number of MSVs and prediction accuracy across models, including convolutional and transformer models, suggesting that a multi-view like perspective is also important for understanding the generalization ability of (non-ensemble or non-distilled) DNNs.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21160;&#21147;&#23398;&#27169;&#22411;&#26469;&#35299;&#37322;&#31070;&#32463;&#32553;&#25918;&#23450;&#24459;&#12290;&#36890;&#36807;&#20998;&#26512;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#65292;&#30740;&#31350;&#21457;&#29616;&#35757;&#32451;&#26102;&#38388;&#21644;&#27169;&#22411;&#22823;&#23567;&#30340;&#32553;&#25918;&#20855;&#26377;&#19981;&#21516;&#30340;&#24130;&#24459;&#25351;&#25968;&#65292;&#32780;&#35745;&#31639;&#26368;&#20248;&#32553;&#25918;&#35268;&#21017;&#35201;&#27714;&#22686;&#21152;&#35757;&#32451;&#27493;&#25968;&#24555;&#20110;&#22686;&#21152;&#27169;&#22411;&#21442;&#25968;&#65292;&#19982;&#23454;&#35777;&#35266;&#23519;&#30456;&#19968;&#33268;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01092</link><description>&lt;p&gt;
&#31070;&#32463;&#32553;&#25918;&#23450;&#24459;&#30340;&#21160;&#21147;&#23398;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Dynamical Model of Neural Scaling Laws
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01092
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#21160;&#21147;&#23398;&#27169;&#22411;&#26469;&#35299;&#37322;&#31070;&#32463;&#32553;&#25918;&#23450;&#24459;&#12290;&#36890;&#36807;&#20998;&#26512;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#65292;&#30740;&#31350;&#21457;&#29616;&#35757;&#32451;&#26102;&#38388;&#21644;&#27169;&#22411;&#22823;&#23567;&#30340;&#32553;&#25918;&#20855;&#26377;&#19981;&#21516;&#30340;&#24130;&#24459;&#25351;&#25968;&#65292;&#32780;&#35745;&#31639;&#26368;&#20248;&#32553;&#25918;&#35268;&#21017;&#35201;&#27714;&#22686;&#21152;&#35757;&#32451;&#27493;&#25968;&#24555;&#20110;&#22686;&#21152;&#27169;&#22411;&#21442;&#25968;&#65292;&#19982;&#23454;&#35777;&#35266;&#23519;&#30456;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21508;&#31181;&#20219;&#21153;&#20013;&#65292;&#31070;&#32463;&#32593;&#32476;&#30340;&#24615;&#33021;&#38543;&#30528;&#35757;&#32451;&#26102;&#38388;&#12289;&#25968;&#25454;&#38598;&#22823;&#23567;&#21644;&#27169;&#22411;&#22823;&#23567;&#30340;&#22686;&#21152;&#32780;&#39044;&#27979;&#24615;&#22320;&#25552;&#39640;&#65292;&#36328;&#22810;&#20010;&#25968;&#37327;&#32423;&#12290;&#36825;&#31181;&#29616;&#35937;&#34987;&#31216;&#20026;&#31070;&#32463;&#32553;&#25918;&#23450;&#24459;&#12290;&#26368;&#37325;&#35201;&#30340;&#26159;&#35745;&#31639;&#26368;&#20248;&#32553;&#25918;&#23450;&#24459;&#65292;&#23427;&#25253;&#21578;&#20102;&#22312;&#36873;&#25321;&#26368;&#20339;&#27169;&#22411;&#22823;&#23567;&#26102;&#24615;&#33021;&#19982;&#35745;&#31639;&#25968;&#37327;&#30340;&#20851;&#31995;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#19968;&#20010;&#36890;&#36807;&#26799;&#24230;&#19979;&#38477;&#36827;&#34892;&#35757;&#32451;&#21644;&#27867;&#21270;&#30340;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#20316;&#20026;&#32593;&#32476;&#35757;&#32451;&#21644;&#27867;&#21270;&#30340;&#21487;&#35299;&#27169;&#22411;&#12290;&#36825;&#20010;&#27169;&#22411;&#22797;&#29616;&#20102;&#20851;&#20110;&#31070;&#32463;&#32553;&#25918;&#23450;&#24459;&#30340;&#35768;&#22810;&#35266;&#23519;&#32467;&#26524;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#23545;&#20110;&#20026;&#20160;&#20040;&#35757;&#32451;&#26102;&#38388;&#21644;&#27169;&#22411;&#22823;&#23567;&#30340;&#32553;&#25918;&#20855;&#26377;&#19981;&#21516;&#30340;&#24130;&#24459;&#25351;&#25968;&#25552;&#20986;&#20102;&#19968;&#20010;&#39044;&#27979;&#12290;&#22240;&#27492;&#65292;&#29702;&#35770;&#39044;&#27979;&#20102;&#19968;&#31181;&#19981;&#23545;&#31216;&#30340;&#35745;&#31639;&#26368;&#20248;&#32553;&#25918;&#35268;&#21017;&#65292;&#20854;&#20013;&#35757;&#32451;&#27493;&#25968;&#30340;&#22686;&#21152;&#36895;&#24230;&#24555;&#20110;&#27169;&#22411;&#21442;&#25968;&#30340;&#22686;&#21152;&#36895;&#24230;&#65292;&#19982;&#26368;&#36817;&#30340;&#23454;&#35777;&#35266;&#23519;&#19968;&#33268;&#12290;&#20854;&#27425;&#65292;&#35266;&#23519;&#21040;&#22312;&#35757;&#32451;&#30340;&#26089;&#26399;&#65292;&#32593;&#32476;&#20250;&#25910;&#25947;&#21040;&#26080;&#38480;&#23485;&#24230;&#24773;&#20917;&#19979;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
On a variety of tasks, the performance of neural networks predictably improves with training time, dataset size and model size across many orders of magnitude. This phenomenon is known as a neural scaling law. Of fundamental importance is the compute-optimal scaling law, which reports the performance as a function of units of compute when choosing model sizes optimally. We analyze a random feature model trained with gradient descent as a solvable model of network training and generalization. This reproduces many observations about neural scaling laws. First, our model makes a prediction about why the scaling of performance with training time and with model size have different power law exponents. Consequently, the theory predicts an asymmetric compute-optimal scaling rule where the number of training steps are increased faster than model parameters, consistent with recent empirical observations. Second, it has been observed that early in training, networks converge to their infinite-wi
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#39640;&#38454;&#24352;&#37327;&#31215;&#26679;&#26465;&#27169;&#22411;&#65292;&#20801;&#35768;&#21152;&#20837;&#25152;&#26377;&#65288;&#39640;&#38454;&#65289;&#38750;&#32447;&#24615;&#29305;&#24449;&#25928;&#24212;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#24182;&#20855;&#26377;&#19982;&#27809;&#26377;&#30456;&#20114;&#20316;&#29992;&#30340;&#27169;&#22411;&#25104;&#27604;&#20363;&#30340;&#35745;&#31639;&#25104;&#26412;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01090</link><description>&lt;p&gt;
&#21487;&#25193;&#23637;&#30340;&#39640;&#38454;&#24352;&#37327;&#31215;&#26679;&#26465;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Scalable Higher-Order Tensor Product Spline Models
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01090
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#39640;&#38454;&#24352;&#37327;&#31215;&#26679;&#26465;&#27169;&#22411;&#65292;&#20801;&#35768;&#21152;&#20837;&#25152;&#26377;&#65288;&#39640;&#38454;&#65289;&#38750;&#32447;&#24615;&#29305;&#24449;&#25928;&#24212;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#24182;&#20855;&#26377;&#19982;&#27809;&#26377;&#30456;&#20114;&#20316;&#29992;&#30340;&#27169;&#22411;&#25104;&#27604;&#20363;&#30340;&#35745;&#31639;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24403;&#21069;&#22823;&#25968;&#25454;&#21644;&#36879;&#26126;&#26426;&#22120;&#23398;&#20064;&#30340;&#26102;&#20195;&#65292;&#25216;&#26415;&#22312;&#22823;&#35268;&#27169;&#24212;&#29992;&#20013;&#36816;&#20316;&#30340;&#21516;&#26102;&#65292;&#36824;&#38656;&#35201;&#25552;&#20379;&#23545;&#26041;&#27861;&#20869;&#37096;&#24037;&#20316;&#30340;&#28165;&#26224;&#25968;&#23398;&#29702;&#35299;&#12290;&#34429;&#28982;&#24050;&#32463;&#23384;&#22312;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#24212;&#29992;&#30340;&#21487;&#35299;&#37322;&#30340;&#21322;&#21442;&#25968;&#22238;&#24402;&#26041;&#27861;&#65292;&#32771;&#34385;&#20102;&#25968;&#25454;&#30340;&#38750;&#32447;&#24615;&#65292;&#20294;&#27169;&#22411;&#30340;&#22797;&#26434;&#24615;&#24120;&#24120;&#21463;&#21040;&#38480;&#21046;&#12290;&#20027;&#35201;&#25361;&#25112;&#20043;&#19968;&#26159;&#36825;&#20123;&#27169;&#22411;&#20013;&#32570;&#20047;&#30456;&#20114;&#20316;&#29992;&#65292;&#20986;&#20110;&#26356;&#22909;&#30340;&#35299;&#37322;&#33021;&#21147;&#21644;&#19981;&#20999;&#23454;&#38469;&#30340;&#35745;&#31639;&#25104;&#26412;&#32771;&#34385;&#32780;&#34987;&#24573;&#30053;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#22240;&#23376;&#21270;&#26041;&#27861;&#25512;&#23548;&#20986;&#39640;&#24230;&#21487;&#25193;&#23637;&#30340;&#39640;&#38454;&#24352;&#37327;&#31215;&#26679;&#26465;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20801;&#35768;&#23558;&#25152;&#26377;&#65288;&#39640;&#38454;&#65289;&#38750;&#32447;&#24615;&#29305;&#24449;&#25928;&#24212;&#30340;&#30456;&#20114;&#20316;&#29992;&#32435;&#20837;&#27169;&#22411;&#65292;&#21516;&#26102;&#20855;&#26377;&#19982;&#27809;&#26377;&#30456;&#20114;&#20316;&#29992;&#30340;&#27169;&#22411;&#25104;&#27604;&#20363;&#30340;&#35745;&#31639;&#25104;&#26412;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#24320;&#21457;&#20102;&#19968;&#31181;&#26377;&#24847;&#20041;&#30340;&#24809;&#32602;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
In the current era of vast data and transparent machine learning, it is essential for techniques to operate at a large scale while providing a clear mathematical comprehension of the internal workings of the method. Although there already exist interpretable semi-parametric regression methods for large-scale applications that take into account non-linearity in the data, the complexity of the models is still often limited. One of the main challenges is the absence of interactions in these models, which are left out for the sake of better interpretability but also due to impractical computational costs. To overcome this limitation, we propose a new approach using a factorization method to derive a highly scalable higher-order tensor product spline model. Our method allows for the incorporation of all (higher-order) interactions of non-linear feature effects while having computational costs proportional to a model without interactions. We further develop a meaningful penalization scheme a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#22312;&#21021;&#22987;&#21270;&#26102;&#20462;&#21098;&#31070;&#32463;&#32593;&#32476;&#22256;&#38590;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#20851;&#20110;&#26377;&#25928;&#21442;&#25968;&#25968;&#37327;&#30340;&#29702;&#35770;&#35299;&#37322;&#12290;&#25105;&#20204;&#25351;&#20986;&#65292;&#22312;&#22024;&#26434;&#25968;&#25454;&#20013;&#40065;&#26834;&#22320;&#25554;&#20540;&#30340;&#31232;&#30095;&#31070;&#32463;&#32593;&#32476;&#38656;&#35201;&#20005;&#37325;&#20381;&#36182;&#20110;&#25968;&#25454;&#30340;&#25513;&#30721;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24576;&#30097;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#21644;&#35757;&#32451;&#21518;&#20462;&#21098;&#26159;&#24517;&#35201;&#30340;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01089</link><description>&lt;p&gt;
&#26080;&#20813;&#36153;&#20462;&#21098;&#65306;&#21021;&#22987;&#21270;&#26102;&#21098;&#26525;&#30340;&#20449;&#24687;&#35770;&#38556;&#30861;
&lt;/p&gt;
&lt;p&gt;
No Free Prune: Information-Theoretic Barriers to Pruning at Initialization
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01089
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#37322;&#20102;&#20026;&#20160;&#20040;&#22312;&#21021;&#22987;&#21270;&#26102;&#20462;&#21098;&#31070;&#32463;&#32593;&#32476;&#22256;&#38590;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#20851;&#20110;&#26377;&#25928;&#21442;&#25968;&#25968;&#37327;&#30340;&#29702;&#35770;&#35299;&#37322;&#12290;&#25105;&#20204;&#25351;&#20986;&#65292;&#22312;&#22024;&#26434;&#25968;&#25454;&#20013;&#40065;&#26834;&#22320;&#25554;&#20540;&#30340;&#31232;&#30095;&#31070;&#32463;&#32593;&#32476;&#38656;&#35201;&#20005;&#37325;&#20381;&#36182;&#20110;&#25968;&#25454;&#30340;&#25513;&#30721;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24576;&#30097;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#21644;&#35757;&#32451;&#21518;&#20462;&#21098;&#26159;&#24517;&#35201;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#8220;&#25277;&#22870;&#20013;&#22870;&#32773;&#8221;&#26159;&#21542;&#22312;&#21021;&#22987;&#21270;&#26102;&#23384;&#22312;&#65292;&#24341;&#21457;&#20102;&#19968;&#20010;&#20196;&#20154;&#30528;&#36855;&#30340;&#38382;&#39064;&#65306;&#28145;&#24230;&#23398;&#20064;&#26159;&#21542;&#38656;&#35201;&#22823;&#22411;&#27169;&#22411;&#65292;&#25110;&#32773;&#21487;&#20197;&#22312;&#19981;&#35757;&#32451;&#21253;&#21547;&#23427;&#20204;&#30340;&#23494;&#38598;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#36805;&#36895;&#35782;&#21035;&#21644;&#35757;&#32451;&#31232;&#30095;&#32593;&#32476;&#12290;&#28982;&#32780;&#65292;&#23581;&#35797;&#22312;&#21021;&#22987;&#21270;&#26102;&#25214;&#21040;&#36825;&#20123;&#31232;&#30095;&#23376;&#32593;&#32476;&#65288;&#8220;&#21021;&#22987;&#21270;&#26102;&#20462;&#21098;&#8221;&#65289;&#30340;&#21162;&#21147;&#22312;&#24191;&#27867;&#19978;&#37117;&#27809;&#26377;&#25104;&#21151;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29702;&#35770;&#35299;&#37322;&#65292;&#22522;&#20110;&#27169;&#22411;&#30340;&#26377;&#25928;&#21442;&#25968;&#25968;&#37327;$p_\text{eff}$&#65292;&#30001;&#26368;&#32456;&#32593;&#32476;&#20013;&#38750;&#38646;&#26435;&#37325;&#30340;&#25968;&#37327;&#21644;&#31232;&#30095;&#25513;&#30721;&#19982;&#25968;&#25454;&#20043;&#38388;&#30340;&#30456;&#20114;&#20449;&#24687;&#30340;&#24635;&#21644;&#32473;&#20986;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#8220;&#40065;&#26834;&#24615;&#23450;&#24459;&#8221;&#65288;arXiv:2105.12806&#65289;&#24310;&#20280;&#21040;&#31232;&#30095;&#32593;&#32476;&#65292;&#20854;&#20013;&#24120;&#35268;&#21442;&#25968;&#25968;&#37327;&#34987;$p_\text{eff}$&#25152;&#21462;&#20195;&#65292;&#36825;&#24847;&#21619;&#30528;&#19968;&#20010;&#33021;&#22815;&#22312;&#22024;&#26434;&#25968;&#25454;&#20013;&#40065;&#26834;&#22320;&#25554;&#20540;&#30340;&#31232;&#30095;&#31070;&#32463;&#32593;&#32476;&#38656;&#35201;&#20005;&#37325;&#20381;&#36182;&#20110;&#25968;&#25454;&#30340;&#25513;&#30721;&#12290;&#25105;&#20204;&#20551;&#35774;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#21644;&#35757;&#32451;&#21518;&#20462;&#21098;&#12290;
&lt;/p&gt;
&lt;p&gt;
The existence of "lottery tickets" arXiv:1803.03635 at or near initialization raises the tantalizing question of whether large models are necessary in deep learning, or whether sparse networks can be quickly identified and trained without ever training the dense models that contain them. However, efforts to find these sparse subnetworks without training the dense model ("pruning at initialization") have been broadly unsuccessful arXiv:2009.08576. We put forward a theoretical explanation for this, based on the model's effective parameter count, $p_\text{eff}$, given by the sum of the number of non-zero weights in the final network and the mutual information between the sparsity mask and the data. We show the Law of Robustness of arXiv:2105.12806 extends to sparse networks with the usual parameter count replaced by $p_\text{eff}$, meaning a sparse neural network which robustly interpolates noisy data requires a heavily data-dependent mask. We posit that pruning during and after training 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#29992;&#20110;&#20174;&#24102;&#26377;&#22122;&#22768;&#26631;&#31614;&#30340;&#25968;&#25454;&#20013;&#23398;&#20064;&#38750;&#21487;&#20998;&#35299;&#24615;&#33021;&#24230;&#37327;&#30340;&#22810;&#31867;&#23398;&#20064;&#31639;&#27861;&#12290;&#36825;&#20123;&#31639;&#27861;&#20998;&#21035;&#36866;&#29992;&#20110;&#21333;&#35843;&#20984;&#24615;&#21644;&#32447;&#24615;&#27604;&#29575;&#20004;&#31867;&#24615;&#33021;&#24230;&#37327;&#65292;&#24182;&#22522;&#20110;&#31867;&#26465;&#20214;&#22122;&#22768;&#27169;&#22411;&#36827;&#34892;&#22122;&#22768;&#26657;&#27491;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01055</link><description>&lt;p&gt;
&#20174;&#26377;&#22122;&#22768;&#26631;&#31614;&#23398;&#20064;&#38750;&#21487;&#20998;&#35299;&#24615;&#33021;&#24230;&#37327;&#30340;&#22810;&#31867;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Multiclass Learning from Noisy Labels for Non-decomposable Performance Measures
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01055
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#29992;&#20110;&#20174;&#24102;&#26377;&#22122;&#22768;&#26631;&#31614;&#30340;&#25968;&#25454;&#20013;&#23398;&#20064;&#38750;&#21487;&#20998;&#35299;&#24615;&#33021;&#24230;&#37327;&#30340;&#22810;&#31867;&#23398;&#20064;&#31639;&#27861;&#12290;&#36825;&#20123;&#31639;&#27861;&#20998;&#21035;&#36866;&#29992;&#20110;&#21333;&#35843;&#20984;&#24615;&#21644;&#32447;&#24615;&#27604;&#29575;&#20004;&#31867;&#24615;&#33021;&#24230;&#37327;&#65292;&#24182;&#22522;&#20110;&#31867;&#26465;&#20214;&#22122;&#22768;&#27169;&#22411;&#36827;&#34892;&#22122;&#22768;&#26657;&#27491;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#23398;&#20064;&#20174;&#24102;&#26377;&#22122;&#22768;&#26631;&#31614;&#30340;&#25968;&#25454;&#20013;&#24471;&#21040;&#33391;&#22909;&#20998;&#31867;&#22120;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#22823;&#22810;&#25968;&#20851;&#20110;&#20174;&#26377;&#22122;&#22768;&#26631;&#31614;&#23398;&#20064;&#30340;&#24037;&#20316;&#37117;&#38598;&#20013;&#22312;&#26631;&#20934;&#30340;&#22522;&#20110;&#25439;&#22833;&#30340;&#24615;&#33021;&#24230;&#37327;&#19978;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#38656;&#35201;&#20351;&#29992;&#38750;&#21487;&#20998;&#35299;&#24615;&#33021;&#24230;&#37327;&#65292;&#36825;&#20123;&#24230;&#37327;&#19981;&#33021;&#34920;&#31034;&#20026;&#21333;&#20010;&#31034;&#20363;&#19978;&#30340;&#25439;&#22833;&#30340;&#26399;&#26395;&#25110;&#24635;&#21644;&#65307;&#20854;&#20013;&#21253;&#25324;&#31867;&#19981;&#24179;&#34913;&#35774;&#32622;&#20013;&#30340;H-mean&#65292;Q-mean&#21644;G-mean&#65292;&#20197;&#21450;&#20449;&#24687;&#26816;&#32034;&#20013;&#30340;Micro F1&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#31639;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#20004;&#31867;&#24191;&#27867;&#30340;&#22810;&#31867;&#38750;&#21487;&#20998;&#35299;&#24615;&#33021;&#24230;&#37327;&#65292;&#21363;&#21333;&#35843;&#20984;&#24615;&#21644;&#32447;&#24615;&#27604;&#29575;&#65292;&#23427;&#20204;&#21253;&#25324;&#19978;&#36848;&#25152;&#26377;&#31034;&#20363;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#22522;&#20110;Narasimhan&#31561;&#20154;&#30340;Frank-Wolfe&#21644;Bisection&#31639;&#27861;(2015)&#12290;&#22312;&#36825;&#20004;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#22312;&#24191;&#27867;&#30740;&#31350;&#30340;&#31867;&#26465;&#20214;&#22122;&#22768;&#27169;&#22411;&#23478;&#26063;&#19979;&#24320;&#21457;&#20102;&#31639;&#27861;&#30340;&#22122;&#22768;&#26657;&#27491;&#29256;&#26412;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#36951;&#25022;(&#36229;&#39069;&#39118;&#38505;)&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;
There has been much interest in recent years in learning good classifiers from data with noisy labels. Most work on learning from noisy labels has focused on standard loss-based performance measures. However, many machine learning problems require using non-decomposable performance measures which cannot be expressed as the expectation or sum of a loss on individual examples; these include for example the H-mean, Q-mean and G-mean in class imbalance settings, and the Micro $F_1$ in information retrieval. In this paper, we design algorithms to learn from noisy labels for two broad classes of multiclass non-decomposable performance measures, namely, monotonic convex and ratio-of-linear, which encompass all the above examples. Our work builds on the Frank-Wolfe and Bisection based methods of Narasimhan et al. (2015). In both cases, we develop noise-corrected versions of the algorithms under the widely studied family of class-conditional noise models. We provide regret (excess risk) bounds 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20851;&#20110;&#36870;&#38382;&#39064;&#30340;&#24369;&#20984;&#27491;&#21017;&#21270;&#22120;&#30340;&#25910;&#25947;&#24615;&#38382;&#39064;&#30340;&#19968;&#33324;&#21270;&#20844;&#24335;&#65292;&#24182;&#35777;&#26126;&#20102;&#36890;&#36807;&#19968;&#31867;&#24369;&#20984;&#27491;&#21017;&#21270;&#22120;&#30340;&#23454;&#29616;&#21487;&#20197;&#36798;&#21040;&#25910;&#25947;&#65292;&#24182;&#24212;&#29992;&#20110;&#23398;&#20064;&#30340;&#27491;&#21017;&#21270;&#20013;&#23454;&#29616;&#20102;&#23545;&#35745;&#31639;&#26426;&#23618;&#26512;&#25104;&#20687;&#20013;&#23398;&#20064;&#23545;&#25239;&#24615;&#27491;&#21017;&#21270;&#22120;&#24615;&#33021;&#30340;&#25552;&#39640;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01052</link><description>&lt;p&gt;
&#24369;&#20984;&#27491;&#21017;&#21270;&#22120;&#22312;&#36870;&#38382;&#39064;&#20013;&#30340;&#25910;&#25947;&#24615;&#65306;&#20020;&#30028;&#28857;&#21644;&#21407;&#22987;-&#23545;&#20598;&#20248;&#21270;&#30340;&#25910;&#25947;
&lt;/p&gt;
&lt;p&gt;
Weakly Convex Regularisers for Inverse Problems: Convergence of Critical Points and Primal-Dual Optimisation
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01052
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20851;&#20110;&#36870;&#38382;&#39064;&#30340;&#24369;&#20984;&#27491;&#21017;&#21270;&#22120;&#30340;&#25910;&#25947;&#24615;&#38382;&#39064;&#30340;&#19968;&#33324;&#21270;&#20844;&#24335;&#65292;&#24182;&#35777;&#26126;&#20102;&#36890;&#36807;&#19968;&#31867;&#24369;&#20984;&#27491;&#21017;&#21270;&#22120;&#30340;&#23454;&#29616;&#21487;&#20197;&#36798;&#21040;&#25910;&#25947;&#65292;&#24182;&#24212;&#29992;&#20110;&#23398;&#20064;&#30340;&#27491;&#21017;&#21270;&#20013;&#23454;&#29616;&#20102;&#23545;&#35745;&#31639;&#26426;&#23618;&#26512;&#25104;&#20687;&#20013;&#23398;&#20064;&#23545;&#25239;&#24615;&#27491;&#21017;&#21270;&#22120;&#24615;&#33021;&#30340;&#25552;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#27491;&#21017;&#21270;&#26159;&#35299;&#20915;&#36870;&#38382;&#39064;&#30340;&#20027;&#35201;&#26041;&#27861;&#65292;&#26368;&#36817;&#26377;&#24456;&#22810;&#30740;&#31350;&#21033;&#29992;&#28145;&#24230;&#23398;&#20064;&#30340;&#27491;&#21017;&#21270;&#26041;&#27861;&#26469;&#25552;&#39640;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#22312;&#35299;&#20915;&#36825;&#31181;&#27491;&#21017;&#21270;&#25910;&#25947;&#24615;&#30340;&#38382;&#39064;&#19978;&#65292;&#24456;&#23569;&#26377;&#20851;&#20110;&#20020;&#30028;&#28857;&#25910;&#25947;&#24615;&#30340;&#32467;&#26524;&#65292;&#32780;&#38750;&#20840;&#23616;&#26497;&#23567;&#20540;&#28857;&#30340;&#25910;&#25947;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20851;&#20110;&#20020;&#30028;&#28857;&#25910;&#25947;&#24615;&#30340;&#19968;&#33324;&#21270;&#20844;&#24335;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#26159;&#36890;&#36807;&#19968;&#31867;&#24369;&#20984;&#27491;&#21017;&#21270;&#22120;&#23454;&#29616;&#30340;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#19982;&#30456;&#20851;&#21464;&#20998;&#38382;&#39064;&#30456;&#20851;&#30340;&#21407;&#22987;-&#23545;&#20598;&#28151;&#21512;&#26799;&#24230;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#22312;&#32473;&#23450;Kurdyka-Lojasiewicz&#26465;&#20214;&#30340;&#24773;&#20917;&#19979;&#65292;&#35777;&#26126;&#20102;O(log(k)/k)&#30340;&#36951;&#20256;&#25910;&#25947;&#36895;&#24230;&#12290;&#26368;&#21518;&#65292;&#23558;&#36825;&#20010;&#29702;&#35770;&#24212;&#29992;&#20110;&#23398;&#20064;&#30340;&#27491;&#21017;&#21270;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36755;&#20837;&#20026;&#24369;&#20984;&#31070;&#32463;&#32593;&#32476;&#65288;IWCNN&#65289;&#30340;&#36890;&#29992;&#36924;&#36817;&#24615;&#65292;&#24182;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;IWCNN&#21487;&#20197;&#25552;&#39640;&#35745;&#31639;&#26426;&#23618;&#26512;&#25104;&#20687;&#20013;&#23398;&#20064;&#23545;&#25239;&#24615;&#27491;&#21017;&#21270;&#22120;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variational regularisation is the primary method for solving inverse problems, and recently there has been considerable work leveraging deeply learned regularisation for enhanced performance. However, few results exist addressing the convergence of such regularisation, particularly within the context of critical points as opposed to global minima. In this paper, we present a generalised formulation of convergent regularisation in terms of critical points, and show that this is achieved by a class of weakly convex regularisers. We prove convergence of the primal-dual hybrid gradient method for the associated variational problem, and, given a Kurdyka-Lojasiewicz condition, an $\mathcal{O}(\log{k}/k)$ ergodic convergence rate. Finally, applying this theory to learned regularisation, we prove universal approximation for input weakly convex neural networks (IWCNN), and show empirically that IWCNNs can lead to improved performance of learned adversarial regularisers for computed tomography (
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#24067;&#24335;MCMC&#25512;&#29702;&#30340;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#28508;&#22312;&#20998;&#22359;&#27169;&#22411;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#35266;&#27979;&#20540;&#21644;&#29305;&#24449;&#21010;&#20998;&#20026;&#20998;&#21306;&#65292;&#24182;&#37319;&#29992;Master/Worker&#26550;&#26500;&#26469;&#25552;&#39640;&#32858;&#31867;&#26631;&#31614;&#20934;&#30830;&#24615;&#21644;&#25191;&#34892;&#26102;&#38388;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01050</link><description>&lt;p&gt;
&#22522;&#20110;&#20998;&#24067;&#24335;MCMC&#25512;&#29702;&#30340;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#28508;&#22312;&#20998;&#22359;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Distributed MCMC inference for Bayesian Non-Parametric Latent Block Model
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01050
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20998;&#24067;&#24335;MCMC&#25512;&#29702;&#30340;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#28508;&#22312;&#20998;&#22359;&#27169;&#22411;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#35266;&#27979;&#20540;&#21644;&#29305;&#24449;&#21010;&#20998;&#20026;&#20998;&#21306;&#65292;&#24182;&#37319;&#29992;Master/Worker&#26550;&#26500;&#26469;&#25552;&#39640;&#32858;&#31867;&#26631;&#31614;&#20934;&#30830;&#24615;&#21644;&#25191;&#34892;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#24067;&#24335;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#65288;MCMC&#65289;&#25512;&#29702;&#26041;&#27861;&#65292;&#29992;&#20110;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#28508;&#22312;&#20998;&#22359;&#27169;&#22411;&#65288;DisNPLBM&#65289;&#65292;&#37319;&#29992;Master/Worker&#26550;&#26500;&#12290;&#25105;&#20204;&#30340;&#38750;&#21442;&#25968;&#20849;&#32858;&#31867;&#31639;&#27861;&#20351;&#29992;&#28508;&#22312;&#22810;&#20803;&#39640;&#26031;&#22359;&#20998;&#24067;&#23558;&#35266;&#27979;&#20540;&#21644;&#29305;&#24449;&#21010;&#20998;&#20026;&#20998;&#21306;&#12290;&#34892;&#19978;&#30340;&#24037;&#20316;&#36127;&#36733;&#22343;&#21248;&#20998;&#24067;&#22312;&#24037;&#20154;&#20043;&#38388;&#65292;&#20182;&#20204;&#21482;&#19982;&#20027;&#33410;&#28857;&#36827;&#34892;&#36890;&#20449;&#65292;&#32780;&#19981;&#19982;&#24444;&#27492;&#36890;&#20449;&#12290;&#36890;&#36807;&#23454;&#39564;&#32467;&#26524;&#65292;DisNPLBM&#35777;&#26126;&#20102;&#20854;&#23545;&#32858;&#31867;&#26631;&#31614;&#20934;&#30830;&#24615;&#21644;&#25191;&#34892;&#26102;&#38388;&#30340;&#24433;&#21709;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#36890;&#36807;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#20849;&#21516;&#32858;&#31867;&#22522;&#22240;&#34920;&#36798;&#25968;&#25454;&#26469;&#23637;&#31034;&#19968;&#20010;&#30495;&#23454;&#30340;&#29992;&#20363;&#12290;&#20195;&#30721;&#28304;&#21487;&#20844;&#24320;&#35775;&#38382;https://github.com/redakhoufache/Distributed-NPLBM&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we introduce a novel Distributed Markov Chain Monte Carlo (MCMC) inference method for the Bayesian Non-Parametric Latent Block Model (DisNPLBM), employing the Master/Worker architecture. Our non-parametric co-clustering algorithm divides observations and features into partitions using latent multivariate Gaussian block distributions. The workload on rows is evenly distributed among workers, who exclusively communicate with the master and not among themselves. DisNPLBM demonstrates its impact on cluster labeling accuracy and execution times through experimental results. Moreover, we present a real-use case applying our approach to co-cluster gene expression data. The code source is publicly available at https://github.com/redakhoufache/Distributed-NPLBM.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20379;&#20102;&#26102;&#38388;&#19981;&#40784;&#27425;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#36153;&#33293;&#23572;&#20449;&#24687;&#32791;&#25955;&#26041;&#27861;&#12290;&#36890;&#36807;&#23558;Langevin&#21160;&#21147;&#23398;&#30340;&#27010;&#29575;&#36716;&#31227;&#26041;&#31243;&#26500;&#36896;&#20026;&#20851;&#20110;&#26102;&#38388;&#20381;&#36182;&#30340;&#26368;&#20248;&#20256;&#36755;&#24230;&#37327;&#30340;&#20462;&#27491;&#26799;&#24230;&#27969;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#30340;&#25910;&#25947;&#24615;&#20445;&#35777;&#65292;&#24182;&#22312;&#20960;&#20010;&#26102;&#38388;&#19981;&#40784;&#27425;Langevin&#21160;&#21147;&#23398;&#20013;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01036</link><description>&lt;p&gt;
&#26102;&#38388;&#19981;&#40784;&#27425;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#36153;&#33293;&#23572;&#20449;&#24687;&#32791;&#25955;
&lt;/p&gt;
&lt;p&gt;
Fisher information dissipation for time inhomogeneous stochastic differential equations
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01036
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#26102;&#38388;&#19981;&#40784;&#27425;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#36153;&#33293;&#23572;&#20449;&#24687;&#32791;&#25955;&#26041;&#27861;&#12290;&#36890;&#36807;&#23558;Langevin&#21160;&#21147;&#23398;&#30340;&#27010;&#29575;&#36716;&#31227;&#26041;&#31243;&#26500;&#36896;&#20026;&#20851;&#20110;&#26102;&#38388;&#20381;&#36182;&#30340;&#26368;&#20248;&#20256;&#36755;&#24230;&#37327;&#30340;&#20462;&#27491;&#26799;&#24230;&#27969;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#30340;&#25910;&#25947;&#24615;&#20445;&#35777;&#65292;&#24182;&#22312;&#20960;&#20010;&#26102;&#38388;&#19981;&#40784;&#27425;Langevin&#21160;&#21147;&#23398;&#20013;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20026;&#26102;&#38388;&#19981;&#40784;&#27425;&#21464;&#31995;&#25968;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;(SDEs)&#25552;&#20379;&#20102;&#19968;&#20010;Lyapunov&#25910;&#25947;&#24615;&#20998;&#26512;&#12290;&#19977;&#20010;&#20856;&#22411;&#30340;&#20363;&#23376;&#21253;&#25324;&#36807;&#38459;&#23612;&#12289;&#19981;&#21487;&#36870;&#28418;&#31227;&#21644;&#27424;&#38459;&#23612;Langevin&#21160;&#21147;&#23398;&#12290;&#25105;&#20204;&#39318;&#20808;&#23558;Langevin&#21160;&#21147;&#23398;&#30340;&#27010;&#29575;&#36716;&#31227;&#26041;&#31243;&#26500;&#36896;&#20026;&#27010;&#29575;&#31354;&#38388;&#20013;&#20851;&#20110;&#26102;&#38388;&#20381;&#36182;&#30340;&#26368;&#20248;&#20256;&#36755;&#24230;&#37327;&#30340;Kullback-Leibler&#25955;&#24230;&#30340;&#20462;&#27491;&#26799;&#24230;&#27969;&#12290;&#36825;&#20010;&#20844;&#24335;&#21253;&#21547;&#20102;&#26799;&#24230;&#21644;&#38750;&#26799;&#24230;&#26041;&#21521;&#65292;&#21462;&#20915;&#20110;&#19968;&#31867;&#26102;&#38388;&#20381;&#36182;&#30340;&#30446;&#26631;&#20998;&#24067;&#12290;&#28982;&#21518;&#25105;&#20204;&#36873;&#25321;&#19968;&#20010;&#26102;&#38388;&#20381;&#36182;&#30340;&#30456;&#23545;&#36153;&#33293;&#23572;&#20449;&#24687;&#27867;&#20989;&#20316;&#20026;Lyapunov&#20989;&#25968;&#12290;&#25105;&#20204;&#21457;&#23637;&#20102;&#19968;&#20010;&#26102;&#38388;&#20381;&#36182;&#30340;Hessian&#30697;&#38453;&#26465;&#20214;&#65292;&#20445;&#35777;&#20102;SDE&#30340;&#27010;&#29575;&#23494;&#24230;&#20989;&#25968;&#30340;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#39564;&#35777;&#20102;&#20960;&#20010;&#26102;&#38388;&#19981;&#40784;&#27425;Langevin&#21160;&#21147;&#23398;&#30340;&#25152;&#25552;&#20986;&#30340;&#26465;&#20214;&#12290;&#23545;&#20110;&#36807;&#38459;&#23612;Langevin&#21160;&#21147;&#23398;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;$L^1$&#36317;&#31163;&#19978;&#30340;$O(t^{-1/2})$&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;
We provide a Lyapunov convergence analysis for time-inhomogeneous variable coefficient stochastic differential equations (SDEs). Three typical examples include overdamped, irreversible drift, and underdamped Langevin dynamics. We first formula the probability transition equation of Langevin dynamics as a modified gradient flow of the Kullback-Leibler divergence in the probability space with respect to time-dependent optimal transport metrics. This formulation contains both gradient and non-gradient directions depending on a class of time-dependent target distribution. We then select a time-dependent relative Fisher information functional as a Lyapunov functional. We develop a time-dependent Hessian matrix condition, which guarantees the convergence of the probability density function of the SDE. We verify the proposed conditions for several time-inhomogeneous Langevin dynamics. For the overdamped Langevin dynamics, we prove the $O(t^{-1/2})$ convergence in $L^1$ distance for the simula
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#22522;&#20110;&#20302;&#31209;&#21152;&#23545;&#35282;&#32447;&#21442;&#25968;&#21270;&#21327;&#26041;&#24046;&#30697;&#38453;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#21051;&#30011;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#35823;&#24046;&#30340;&#33258;&#30456;&#20851;&#24615;&#65292;&#24182;&#20855;&#26377;&#22797;&#26434;&#24230;&#20302;&#12289;&#26657;&#20934;&#39044;&#27979;&#20934;&#30830;&#24615;&#39640;&#31561;&#20248;&#28857;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01000</link><description>&lt;p&gt;
&#22810;&#20803;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#19982;&#30456;&#20851;&#35823;&#24046;
&lt;/p&gt;
&lt;p&gt;
Multivariate Probabilistic Time Series Forecasting with Correlated Errors
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01000
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#22522;&#20110;&#20302;&#31209;&#21152;&#23545;&#35282;&#32447;&#21442;&#25968;&#21270;&#21327;&#26041;&#24046;&#30697;&#38453;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#21051;&#30011;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#35823;&#24046;&#30340;&#33258;&#30456;&#20851;&#24615;&#65292;&#24182;&#20855;&#26377;&#22797;&#26434;&#24230;&#20302;&#12289;&#26657;&#20934;&#39044;&#27979;&#20934;&#30830;&#24615;&#39640;&#31561;&#20248;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24314;&#27169;&#35823;&#24046;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#19982;&#27169;&#22411;&#33021;&#22815;&#20934;&#30830;&#37327;&#21270;&#27010;&#29575;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#20013;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#23494;&#20999;&#30456;&#20851;&#12290;&#26368;&#36817;&#30340;&#22810;&#20803;&#27169;&#22411;&#22312;&#32771;&#34385;&#35823;&#24046;&#20043;&#38388;&#30340;&#21516;&#26102;&#30456;&#20851;&#24615;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#36827;&#23637;&#65292;&#28982;&#32780;&#65292;&#23545;&#20110;&#32479;&#35745;&#31616;&#21270;&#30340;&#30446;&#30340;&#65292;&#23545;&#36825;&#20123;&#35823;&#24046;&#30340;&#24120;&#35265;&#20551;&#35774;&#26159;&#23427;&#20204;&#22312;&#26102;&#38388;&#19978;&#26159;&#29420;&#31435;&#30340;&#12290;&#28982;&#32780;&#65292;&#23454;&#38469;&#35266;&#27979;&#24448;&#24448;&#20559;&#31163;&#20102;&#36825;&#20010;&#20551;&#35774;&#65292;&#22240;&#20026;&#35823;&#24046;&#36890;&#24120;&#30001;&#20110;&#21508;&#31181;&#22240;&#32032;&#65288;&#22914;&#25490;&#38500;&#26102;&#38388;&#30456;&#20851;&#30340;&#21327;&#21464;&#37327;&#65289;&#32780;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#33258;&#30456;&#20851;&#24615;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#20302;&#31209;&#21152;&#23545;&#35282;&#32447;&#21442;&#25968;&#21270;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#39640;&#25928;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#21051;&#30011;&#35823;&#24046;&#30340;&#33258;&#30456;&#20851;&#24615;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#20855;&#26377;&#20960;&#20010;&#21487;&#21462;&#30340;&#29305;&#24615;&#65306;&#22797;&#26434;&#24230;&#19981;&#38543;&#26102;&#38388;&#24207;&#21015;&#25968;&#30446;&#22686;&#21152;&#65292;&#24471;&#21040;&#30340;&#21327;&#26041;&#24046;&#21487;&#20197;&#29992;&#20110;&#26657;&#20934;&#39044;&#27979;&#65292;&#19988;&#20855;&#26377;&#36739;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modeling the correlations among errors is closely associated with how accurately the model can quantify predictive uncertainty in probabilistic time series forecasting. Recent multivariate models have made significant progress in accounting for contemporaneous correlations among errors, while a common assumption on these errors is that they are temporally independent for the sake of statistical simplicity. However, real-world observations often deviate from this assumption, since errors usually exhibit substantial autocorrelation due to various factors such as the exclusion of temporally correlated covariates. In this work, we propose an efficient method, based on a low-rank-plus-diagonal parameterization of the covariance matrix, which can effectively characterize the autocorrelation of errors. The proposed method possesses several desirable properties: the complexity does not scale with the number of time series, the resulting covariance can be used for calibrating predictions, and i
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20449;&#20219;&#23398;&#20064;&#29702;&#35770;&#65292;&#36890;&#36807;&#20351;&#29992;&#20984;&#38598;&#30340;&#27010;&#29575;&#26469;&#24314;&#27169;&#25968;&#25454;&#29983;&#25104;&#20998;&#24067;&#30340;&#21464;&#24322;&#24615;&#65292;&#20174;&#26377;&#38480;&#26679;&#26412;&#30340;&#35757;&#32451;&#38598;&#20013;&#25512;&#26029;&#20986;&#20449;&#20219;&#38598;&#65292;&#24182;&#25512;&#23548;&#20986;bounds&#12290;</title><link>https://rss.arxiv.org/abs/2402.00957</link><description>&lt;p&gt;
&#20449;&#20219;&#23398;&#20064;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Credal Learning Theory
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.00957
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20449;&#20219;&#23398;&#20064;&#29702;&#35770;&#65292;&#36890;&#36807;&#20351;&#29992;&#20984;&#38598;&#30340;&#27010;&#29575;&#26469;&#24314;&#27169;&#25968;&#25454;&#29983;&#25104;&#20998;&#24067;&#30340;&#21464;&#24322;&#24615;&#65292;&#20174;&#26377;&#38480;&#26679;&#26412;&#30340;&#35757;&#32451;&#38598;&#20013;&#25512;&#26029;&#20986;&#20449;&#20219;&#38598;&#65292;&#24182;&#25512;&#23548;&#20986;bounds&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#26159;&#26426;&#22120;&#23398;&#20064;&#30340;&#22522;&#30784;&#65292;&#20026;&#20174;&#26410;&#30693;&#27010;&#29575;&#20998;&#24067;&#20013;&#23398;&#20064;&#21040;&#30340;&#27169;&#22411;&#30340;&#39118;&#38505;&#25552;&#20379;&#29702;&#35770;&#36793;&#30028;&#12290;&#28982;&#32780;&#65292;&#22312;&#23454;&#38469;&#37096;&#32626;&#20013;&#65292;&#25968;&#25454;&#20998;&#24067;&#21487;&#33021;&#20250;&#21464;&#21270;&#65292;&#23548;&#33268;&#39046;&#22495;&#36866;&#24212;/&#27867;&#21270;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#8220;&#20449;&#20219;&#8221;&#23398;&#20064;&#29702;&#35770;&#30340;&#22522;&#30784;&#65292;&#20351;&#29992;&#27010;&#29575;&#30340;&#20984;&#38598;&#65288;&#20449;&#20219;&#38598;&#65289;&#26469;&#24314;&#27169;&#25968;&#25454;&#29983;&#25104;&#20998;&#24067;&#30340;&#21464;&#24322;&#24615;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#36825;&#26679;&#30340;&#20449;&#20219;&#38598;&#21487;&#20197;&#20174;&#26377;&#38480;&#26679;&#26412;&#30340;&#35757;&#32451;&#38598;&#20013;&#25512;&#26029;&#20986;&#26469;&#12290;&#23545;&#20110;&#26377;&#38480;&#20551;&#35774;&#31354;&#38388;&#65288;&#26080;&#35770;&#26159;&#21542;&#21487;&#23454;&#29616;&#65289;&#21644;&#26080;&#38480;&#27169;&#22411;&#31354;&#38388;&#65292;&#25512;&#23548;&#20986;&#30028;&#38480;&#65292;&#36825;&#30452;&#25509;&#25512;&#24191;&#20102;&#32463;&#20856;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Statistical learning theory is the foundation of machine learning, providing theoretical bounds for the risk of models learnt from a (single) training set, assumed to issue from an unknown probability distribution. In actual deployment, however, the data distribution may (and often does) vary, causing domain adaptation/generalization issues. In this paper we lay the foundations for a `credal' theory of learning, using convex sets of probabilities (credal sets) to model the variability in the data-generating distribution. Such credal sets, we argue, may be inferred from a finite sample of training sets. Bounds are derived for the case of finite hypotheses spaces (both assuming realizability or not) as well as infinite model spaces, which directly generalize classical results.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#20195;&#25968;&#20960;&#20309;&#24037;&#20855;&#30740;&#31350;&#20102;&#20855;&#26377;&#21333;&#39033;&#24335;&#28608;&#27963;&#20989;&#25968;&#30340;&#22810;&#39033;&#24335;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#36798;&#24615;&#21644;&#23398;&#20064;&#36807;&#31243;&#65292;&#36890;&#36807;&#23545;&#31070;&#32463;&#27969;&#24418;&#30340;&#32500;&#24230;&#21644;&#23398;&#20064;&#24230;&#30340;&#30740;&#31350;&#65292;&#25552;&#20379;&#20102;&#32593;&#32476;&#34920;&#36798;&#33021;&#21147;&#21644;&#35757;&#32451;&#22797;&#26434;&#24230;&#30340;&#24230;&#37327;&#65292;&#24182;&#32473;&#20986;&#20102;&#21487;&#23398;&#20989;&#25968;&#25968;&#37327;&#30340;&#19978;&#30028;&#12290;</title><link>https://rss.arxiv.org/abs/2402.00949</link><description>&lt;p&gt;
&#22810;&#39033;&#24335;&#31070;&#32463;&#32593;&#32476;&#30340;&#20960;&#20309;&#24615;&#36136;
&lt;/p&gt;
&lt;p&gt;
Geometry of Polynomial Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.00949
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#20195;&#25968;&#20960;&#20309;&#24037;&#20855;&#30740;&#31350;&#20102;&#20855;&#26377;&#21333;&#39033;&#24335;&#28608;&#27963;&#20989;&#25968;&#30340;&#22810;&#39033;&#24335;&#31070;&#32463;&#32593;&#32476;&#30340;&#34920;&#36798;&#24615;&#21644;&#23398;&#20064;&#36807;&#31243;&#65292;&#36890;&#36807;&#23545;&#31070;&#32463;&#27969;&#24418;&#30340;&#32500;&#24230;&#21644;&#23398;&#20064;&#24230;&#30340;&#30740;&#31350;&#65292;&#25552;&#20379;&#20102;&#32593;&#32476;&#34920;&#36798;&#33021;&#21147;&#21644;&#35757;&#32451;&#22797;&#26434;&#24230;&#30340;&#24230;&#37327;&#65292;&#24182;&#32473;&#20986;&#20102;&#21487;&#23398;&#20989;&#25968;&#25968;&#37327;&#30340;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#21333;&#39033;&#24335;&#28608;&#27963;&#20989;&#25968;&#30340;&#22810;&#39033;&#24335;&#31070;&#32463;&#32593;&#32476;&#65288;PNN&#65289;&#30340;&#34920;&#36798;&#24615;&#21644;&#23398;&#20064;&#36807;&#31243;&#12290;&#32593;&#32476;&#30340;&#26435;&#37325;&#21442;&#25968;&#21270;&#20102;&#31070;&#32463;&#27969;&#24418;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#20195;&#25968;&#20960;&#20309;&#24037;&#20855;&#30740;&#31350;&#20102;&#26576;&#20123;&#31070;&#32463;&#27969;&#24418;&#65306;&#25105;&#20204;&#32473;&#20986;&#20102;&#21322;&#20195;&#25968;&#38598;&#30340;&#26126;&#30830;&#25551;&#36848;&#24182;&#29305;&#24449;&#21270;&#20102;&#23427;&#20204;&#30340;Zariski&#38381;&#21253;&#65292;&#31216;&#20026;&#31070;&#32463;&#22810;&#26679;&#24615;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#23427;&#20204;&#30340;&#32500;&#24230;&#24182;&#23558;&#19968;&#20010;&#20195;&#25968;&#24230;&#37327;&#65292;&#23398;&#20064;&#24230;&#65292;&#19982;&#31070;&#32463;&#22810;&#26679;&#24615;&#30456;&#20851;&#32852;&#12290;&#32500;&#24230;&#20316;&#20026;&#32593;&#32476;&#34920;&#36798;&#33021;&#21147;&#30340;&#20960;&#20309;&#24230;&#37327;&#65292;&#23398;&#20064;&#24230;&#26159;&#35757;&#32451;&#32593;&#32476;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#65292;&#24182;&#25552;&#20379;&#21487;&#23398;&#20989;&#25968;&#25968;&#37327;&#30340;&#19978;&#30028;&#12290;&#36825;&#20123;&#29702;&#35770;&#32467;&#26524;&#36824;&#20276;&#38543;&#30528;&#23454;&#39564;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the expressivity and learning process for polynomial neural networks (PNNs) with monomial activation functions. The weights of the network parametrize the neuromanifold. In this paper, we study certain neuromanifolds using tools from algebraic geometry: we give explicit descriptions as semialgebraic sets and characterize their Zariski closures, called neurovarieties. We study their dimension and associate an algebraic degree, the learning degree, to the neurovariety. The dimension serves as a geometric measure for the expressivity of the network, the learning degree is a measure for the complexity of training the network and provides upper bounds on the number of learnable functions. These theoretical results are accompanied with experiments.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#20351;&#29992;&#20855;&#26377;&#21487;&#35777;&#26126;&#24615;&#33021;&#20445;&#35777;&#30340;&#24369;&#30417;&#30563;AI&#38169;&#35823;&#20462;&#27491;&#22120;&#26469;&#22788;&#29702;AI&#38169;&#35823;&#12290;&#20462;&#27491;&#22120;&#36890;&#36807;&#25209;&#20934;&#25110;&#25298;&#32477;&#24213;&#23618;&#20998;&#31867;&#22120;&#30340;&#20915;&#31574;&#26469;&#25552;&#21319;&#24615;&#33021;&#65292;&#24182;&#36890;&#36807;&#27010;&#29575;&#30028;&#38480;&#20445;&#35777;&#20854;&#24615;&#33021;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#35757;&#32451;&#25968;&#25454;&#31232;&#32570;&#30340;&#30495;&#23454;&#19990;&#30028;&#20219;&#21153;&#20013;&#25552;&#21319;&#22270;&#20687;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#12290;</title><link>https://rss.arxiv.org/abs/2402.00899</link><description>&lt;p&gt;
&#24369;&#30417;&#30563;&#23398;&#20064;&#22120;&#23454;&#29616;&#20855;&#26377;&#21487;&#35777;&#26126;&#24615;&#33021;&#20445;&#35777;&#30340;AI&#38169;&#35823;&#20462;&#27491;
&lt;/p&gt;
&lt;p&gt;
Weakly Supervised Learners for Correction of AI Errors with Provable Performance Guarantees
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.00899
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#24037;&#20316;&#25552;&#20986;&#20102;&#20351;&#29992;&#20855;&#26377;&#21487;&#35777;&#26126;&#24615;&#33021;&#20445;&#35777;&#30340;&#24369;&#30417;&#30563;AI&#38169;&#35823;&#20462;&#27491;&#22120;&#26469;&#22788;&#29702;AI&#38169;&#35823;&#12290;&#20462;&#27491;&#22120;&#36890;&#36807;&#25209;&#20934;&#25110;&#25298;&#32477;&#24213;&#23618;&#20998;&#31867;&#22120;&#30340;&#20915;&#31574;&#26469;&#25552;&#21319;&#24615;&#33021;&#65292;&#24182;&#36890;&#36807;&#27010;&#29575;&#30028;&#38480;&#20445;&#35777;&#20854;&#24615;&#33021;&#12290;&#23454;&#39564;&#35777;&#26126;&#35813;&#26041;&#27861;&#22312;&#35757;&#32451;&#25968;&#25454;&#31232;&#32570;&#30340;&#30495;&#23454;&#19990;&#30028;&#20219;&#21153;&#20013;&#25552;&#21319;&#22270;&#20687;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#26469;&#22788;&#29702;AI&#38169;&#35823;&#65292;&#36890;&#36807;&#24341;&#20837;&#20855;&#26377;&#20808;&#39564;&#24615;&#33021;&#20445;&#35777;&#30340;&#24369;&#30417;&#30563;AI&#38169;&#35823;&#20462;&#27491;&#22120;&#12290;&#36825;&#20123;AI&#20462;&#27491;&#22120;&#26159;&#36741;&#21161;&#26144;&#23556;&#65292;&#20854;&#20316;&#29992;&#26159;&#36890;&#36807;&#25209;&#20934;&#25110;&#25298;&#32477;&#20197;&#35843;&#33410;&#20043;&#21069;&#26500;&#24314;&#30340;&#24213;&#23618;&#20998;&#31867;&#22120;&#30340;&#20915;&#31574;&#12290;&#25298;&#32477;&#19968;&#20010;&#20915;&#31574;&#21487;&#20197;&#29992;&#20316;&#24314;&#35758;&#25918;&#24323;&#20570;&#20986;&#20915;&#31574;&#30340;&#20449;&#21495;&#12290;&#35813;&#24037;&#20316;&#30340;&#19968;&#20010;&#20851;&#38190;&#25216;&#26415;&#37325;&#28857;&#26159;&#36890;&#36807;&#23545;&#38169;&#35823;&#20915;&#31574;&#30340;&#27010;&#29575;&#30028;&#38480;&#25552;&#20379;&#36825;&#20123;&#26032;&#30340;AI&#20462;&#27491;&#22120;&#30340;&#24615;&#33021;&#20445;&#35777;&#12290;&#36825;&#20123;&#30028;&#38480;&#26159;&#20998;&#24067;&#19981;&#21487;&#30693;&#30340;&#65292;&#24182;&#19988;&#19981;&#20381;&#36182;&#20110;&#23545;&#25968;&#25454;&#32500;&#24230;&#30340;&#20551;&#35774;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#31034;&#20363;&#35828;&#26126;&#20102;&#35813;&#26694;&#26550;&#22914;&#20309;&#24212;&#29992;&#20110;&#25913;&#21892;&#22312;&#35757;&#32451;&#25968;&#25454;&#31232;&#32570;&#30340;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#30495;&#23454;&#19990;&#30028;&#20219;&#21153;&#20013;&#22270;&#20687;&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a new methodology for handling AI errors by introducing weakly supervised AI error correctors with a priori performance guarantees. These AI correctors are auxiliary maps whose role is to moderate the decisions of some previously constructed underlying classifier by either approving or rejecting its decisions. The rejection of a decision can be used as a signal to suggest abstaining from making a decision. A key technical focus of the work is in providing performance guarantees for these new AI correctors through bounds on the probabilities of incorrect decisions. These bounds are distribution agnostic and do not rely on assumptions on the data dimension. Our empirical example illustrates how the framework can be applied to improve the performance of an image classifier in a challenging real-world task where training data are scarce.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#23398;&#20064;&#30340;&#31639;&#27861;&#65292;&#21517;&#20026;&#22312;&#32447;VSMC&#65292;&#23427;&#22522;&#20110;&#21464;&#20998;&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#65292;&#22312;&#22788;&#29702;&#25968;&#25454;&#27969;&#26102;&#33021;&#22815;&#23454;&#26102;&#36827;&#34892;&#27169;&#22411;&#21442;&#25968;&#20272;&#35745;&#21644;&#31890;&#23376;&#25552;&#35758;&#36866;&#24212;&#12290;</title><link>https://rss.arxiv.org/abs/2312.12616</link><description>&lt;p&gt;
&#22312;&#32447;&#21464;&#20998;&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Online Variational Sequential Monte Carlo
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2312.12616
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#32447;&#23398;&#20064;&#30340;&#31639;&#27861;&#65292;&#21517;&#20026;&#22312;&#32447;VSMC&#65292;&#23427;&#22522;&#20110;&#21464;&#20998;&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#65292;&#22312;&#22788;&#29702;&#25968;&#25454;&#27969;&#26102;&#33021;&#22815;&#23454;&#26102;&#36827;&#34892;&#27169;&#22411;&#21442;&#25968;&#20272;&#35745;&#21644;&#31890;&#23376;&#25552;&#35758;&#36866;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29366;&#24577;&#31354;&#38388;&#27169;&#22411;&#65288;SSM&#65289;&#26159;AI&#21644;&#32479;&#35745;&#26426;&#22120;&#23398;&#20064;&#20013;&#26368;&#32463;&#20856;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#23545;&#20110;&#20219;&#20309;&#24418;&#24335;&#30340;&#21442;&#25968;&#23398;&#20064;&#25110;&#28508;&#22312;&#29366;&#24577;&#25512;&#26029;&#65292;&#36890;&#24120;&#38656;&#35201;&#35745;&#31639;&#22797;&#26434;&#30340;&#28508;&#22312;&#29366;&#24577;&#21518;&#39564;&#20998;&#24067;&#12290;&#26412;&#25991;&#22312;&#21464;&#20998;&#39034;&#24207;&#33945;&#29305;&#21345;&#27931;&#65288;VSMC&#65289;&#26041;&#27861;&#30340;&#22522;&#30784;&#19978;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#32467;&#21512;&#31890;&#23376;&#26041;&#27861;&#21644;&#21464;&#20998;&#25512;&#26029;&#65292;&#25552;&#20379;&#20102;&#35745;&#31639;&#39640;&#25928;&#19988;&#20934;&#30830;&#30340;&#27169;&#22411;&#21442;&#25968;&#20272;&#35745;&#21644;&#36125;&#21494;&#26031;&#28508;&#22312;&#29366;&#24577;&#25512;&#26029;&#12290;&#20256;&#32479;&#30340;VSMC&#26041;&#27861;&#22312;&#31163;&#32447;&#27169;&#24335;&#19979;&#36816;&#34892;&#65292;&#36890;&#36807;&#37325;&#22797;&#22788;&#29702;&#32473;&#23450;&#30340;&#25968;&#25454;&#25209;&#27425;&#65292;&#32780;&#25105;&#20204;&#20351;&#29992;&#38543;&#26426;&#36924;&#36817;&#26041;&#27861;&#23558;VSMC&#20195;&#29702;ELBO&#30340;&#26799;&#24230;&#36924;&#36817;&#20998;&#24067;&#21040;&#26102;&#38388;&#19978;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#22312;&#25968;&#25454;&#27969;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#30340;&#22312;&#32447;&#23398;&#20064;&#12290;&#36825;&#23548;&#33268;&#20102;&#19968;&#31181;&#21517;&#20026;&#22312;&#32447;VSMC&#30340;&#31639;&#27861;&#65292;&#33021;&#22815;&#39640;&#25928;&#22320;&#36827;&#34892;&#21442;&#25968;&#20272;&#35745;&#21644;&#31890;&#23376;&#25552;&#35758;&#36866;&#24212;&#65292;&#32780;&#19988;&#23436;&#20840;&#23454;&#26102;&#22788;&#29702;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Being the most classical generative model for serial data, state-space models (SSM) are fundamental in AI and statistical machine learning. In SSM, any form of parameter learning or latent state inference typically involves the computation of complex latent-state posteriors. In this work, we build upon the variational sequential Monte Carlo (VSMC) method, which provides computationally efficient and accurate model parameter estimation and Bayesian latent-state inference by combining particle methods and variational inference. While standard VSMC operates in the offline mode, by re-processing repeatedly a given batch of data, we distribute the approximation of the gradient of the VSMC surrogate ELBO in time using stochastic approximation, allowing for online learning in the presence of streams of data. This results in an algorithm, online VSMC, that is capable of performing efficiently, entirely on-the-fly, both parameter estimation and particle proposal adaptation. In addition, we prov
&lt;/p&gt;</description></item><item><title>&#36793;&#38469;&#25289;&#26222;&#25289;&#26031;&#20998;&#25968;&#65288;MLS&#65289;&#26159;&#19968;&#31181;&#38024;&#23545;&#39640;&#32500;&#24230;&#19981;&#24179;&#34913;&#25968;&#25454;&#30340;&#25913;&#36827;&#29256;&#25289;&#26222;&#25289;&#26031;&#20998;&#25968;&#65288;LS&#65289;&#65292;&#36890;&#36807;&#20445;&#30041;&#25968;&#25454;&#38598;&#36793;&#32536;&#30340;&#23616;&#37096;&#32467;&#26500;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#26080;&#30417;&#30563;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#34987;&#25104;&#21151;&#22320;&#38598;&#25104;&#21040;&#19981;&#21516;iable&#26080;&#30417;&#30563;&#29305;&#24449;&#36873;&#25321;&#65288;DUFS&#65289;&#31639;&#27861;&#20013;&#65292;&#22312;&#21512;&#25104;&#21644;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#31283;&#20581;&#19988;&#25913;&#36827;&#30340;&#24615;&#33021;&#12290;</title><link>https://rss.arxiv.org/abs/2311.17795</link><description>&lt;p&gt;
&#36793;&#38469;&#25289;&#26222;&#25289;&#26031;&#20998;&#25968;
&lt;/p&gt;
&lt;p&gt;
Marginal Laplacian Score
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2311.17795
&lt;/p&gt;
&lt;p&gt;
&#36793;&#38469;&#25289;&#26222;&#25289;&#26031;&#20998;&#25968;&#65288;MLS&#65289;&#26159;&#19968;&#31181;&#38024;&#23545;&#39640;&#32500;&#24230;&#19981;&#24179;&#34913;&#25968;&#25454;&#30340;&#25913;&#36827;&#29256;&#25289;&#26222;&#25289;&#26031;&#20998;&#25968;&#65288;LS&#65289;&#65292;&#36890;&#36807;&#20445;&#30041;&#25968;&#25454;&#38598;&#36793;&#32536;&#30340;&#23616;&#37096;&#32467;&#26500;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#26080;&#30417;&#30563;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#34987;&#25104;&#21151;&#22320;&#38598;&#25104;&#21040;&#19981;&#21516;iable&#26080;&#30417;&#30563;&#29305;&#24449;&#36873;&#25321;&#65288;DUFS&#65289;&#31639;&#27861;&#20013;&#65292;&#22312;&#21512;&#25104;&#21644;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#31283;&#20581;&#19988;&#25913;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#32500;&#24230;&#19981;&#24179;&#34913;&#25968;&#25454;&#32473;&#26426;&#22120;&#23398;&#20064;&#24102;&#26469;&#20102;&#25361;&#25112;&#12290;&#22312;&#27809;&#26377;&#36275;&#22815;&#25110;&#39640;&#36136;&#37327;&#30340;&#26631;&#31614;&#30340;&#24773;&#20917;&#19979;&#65292;&#26080;&#30417;&#30563;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#23545;&#21518;&#32493;&#31639;&#27861;&#30340;&#25104;&#21151;&#33267;&#20851;&#37325;&#35201;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#36793;&#38469;&#25289;&#26222;&#25289;&#26031;&#20998;&#25968;&#65288;MLS&#65289;&#65292;&#23427;&#26159;&#33879;&#21517;&#30340;&#25289;&#26222;&#25289;&#26031;&#20998;&#25968;&#65288;LS&#65289;&#30340;&#20462;&#25913;&#29256;&#26412;&#65292;&#26088;&#22312;&#26356;&#22909;&#22320;&#22788;&#29702;&#19981;&#24179;&#34913;&#25968;&#25454;&#12290;&#25105;&#20204;&#20551;&#35774;&#23569;&#25968;&#31867;&#25110;&#24322;&#24120;&#31867;&#22312;&#29305;&#24449;&#30340;&#36793;&#32536;&#20013;&#26356;&#39057;&#32321;&#20986;&#29616;&#12290;&#22240;&#27492;&#65292;MLS&#26088;&#22312;&#20445;&#30041;&#25968;&#25454;&#38598;&#36793;&#32536;&#30340;&#23616;&#37096;&#32467;&#26500;&#12290;&#25105;&#20204;&#23558;&#20854;&#38598;&#25104;&#21040;&#21033;&#29992;&#25289;&#26222;&#25289;&#26031;&#20998;&#25968;&#30340;&#29616;&#20195;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#20013;&#12290;&#25105;&#20204;&#23558;MLS&#31639;&#27861;&#38598;&#25104;&#21040;&#21487;&#24494;&#26080;&#30417;&#30563;&#29305;&#24449;&#36873;&#25321;&#65288;DUFS&#65289;&#20013;&#65292;&#24471;&#21040;&#20102;DUFS-MLS&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#21512;&#25104;&#21644;&#20844;&#20849;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#31283;&#20581;&#19988;&#25913;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
High-dimensional imbalanced data poses a machine learning challenge. In the absence of sufficient or high-quality labels, unsupervised feature selection methods are crucial for the success of subsequent algorithms. Therefore, we introduce a Marginal Laplacian Score (MLS), a modification of the well known Laplacian Score (LS) tailored to better address imbalanced data. We introduce an assumption that the minority class or anomalous appear more frequently in the margin of the features. Consequently, MLS aims to preserve the local structure of the dataset's margin. We propose its integration into modern feature selection methods that utilize the Laplacian score. We integrate the MLS algorithm into the Differentiable Unsupervised Feature Selection (DUFS), resulting in DUFS-MLS. The proposed methods demonstrate robust and improved performance on synthetic and public datasets.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#20351;&#29992;&#27491;&#21017;&#27969;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#24046;&#20998;&#38544;&#31169;&#26426;&#22120;&#23398;&#20064;&#20013;&#21382;&#21490;&#38590;&#39064;&#65292;&#25552;&#39640;&#20102;&#20934;&#30830;&#24615;&#21644;&#38544;&#31169;&#20445;&#25252;&#12290;</title><link>https://rss.arxiv.org/abs/2311.09200</link><description>&lt;p&gt;
&#27491;&#21017;&#27969;&#26159;&#21542;&#26159;&#35299;&#38145;&#25351;&#25968;&#26426;&#21046;&#30340;&#20851;&#38190;&#65311;&#32463;&#36807;&#20934;&#30830;&#24615;&#21644;&#38544;&#31169;&#21452;&#37325;&#32422;&#26463;&#30340;&#24046;&#20998;&#38544;&#31169;&#26426;&#22120;&#23398;&#20064;&#30340;&#19968;&#26465;&#36335;&#24452;
&lt;/p&gt;
&lt;p&gt;
Are Normalizing Flows the Key to Unlocking the Exponential Mechanism? A Path through the Accuracy-Privacy Ceiling Constraining Differentially Private ML
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2311.09200
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#20351;&#29992;&#27491;&#21017;&#27969;&#27169;&#22411;&#65292;&#35299;&#20915;&#20102;&#24046;&#20998;&#38544;&#31169;&#26426;&#22120;&#23398;&#20064;&#20013;&#21382;&#21490;&#38590;&#39064;&#65292;&#25552;&#39640;&#20102;&#20934;&#30830;&#24615;&#21644;&#38544;&#31169;&#20445;&#25252;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#21069;&#30340;&#24046;&#20998;&#38544;&#31169;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#30340;&#26368;&#20808;&#36827;&#19988;&#20107;&#23454;&#26631;&#20934;&#26159;&#24046;&#20998;&#38544;&#31169;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;DPSGD&#65289;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#26041;&#27861;&#26412;&#36136;&#19978;&#26159;&#28010;&#36153;&#30340;&#12290;&#36890;&#36807;&#21521;&#27599;&#20010;&#26799;&#24230;&#28155;&#21152;&#22122;&#22768;&#65292;&#23427;&#20250;&#22312;&#27599;&#20010;&#26799;&#24230;&#27493;&#39588;&#20013;&#38477;&#20302;&#25972;&#20307;&#38544;&#31169;&#12290;&#23613;&#31649;&#32463;&#36807;15&#24180;&#30340;&#20016;&#23500;&#30740;&#31350;&#65292;&#25512;&#36827;&#20102;&#32452;&#21512;&#23450;&#29702;&#12289;&#23376;&#37319;&#26679;&#26041;&#27861;&#21644;&#23454;&#29616;&#25216;&#26415;&#65292;&#20294;&#24403;&#21069;&#30340;&#38544;&#31169;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#24448;&#24448;&#26080;&#27861;&#36798;&#21040;&#36275;&#22815;&#30340;&#20934;&#30830;&#24615;&#21644;&#38544;&#31169;&#20445;&#25252;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#20026;&#20102;&#31169;&#19979;&#20248;&#21270;&#32780;&#35774;&#35745;&#30340;&#25351;&#25968;&#26426;&#21046;&#65288;ExpM&#65289;&#21382;&#26469;&#34987;&#25490;&#38500;&#22312;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#30340;&#31169;&#19979;&#35757;&#32451;&#20043;&#22806;&#65292;&#20027;&#35201;&#26159;&#22240;&#20026;ExpM&#38656;&#35201;&#20174;&#19968;&#31181;&#21382;&#26469;&#38590;&#20197;&#22788;&#29702;&#30340;&#23494;&#24230;&#20013;&#36827;&#34892;&#37319;&#26679;&#12290;&#23613;&#31649;&#26368;&#36817;&#21457;&#29616;&#20102;&#27491;&#21017;&#27969;&#27169;&#22411;&#65288;NFs&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#29992;&#20110;&#36924;&#36817;&#38590;&#20197;&#22788;&#29702;&#20998;&#24067;&#30340;&#34920;&#36798;&#28145;&#24230;&#32593;&#32476;&#65292;&#20294;ExpM&#20173;&#28982;&#22788;&#20110;&#32972;&#26223;&#20013;&#12290;&#25105;&#20204;&#30340;&#35266;&#28857;&#26159;&#21033;&#29992;&#27491;&#21017;&#27969;&#26469;&#32469;&#36807;ExpM&#30340;&#21382;&#21490;&#38556;&#30861;&#26159;&#19968;&#20010;&#28508;&#22312;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The state of the art and de facto standard for differentially private machine learning (ML) is differentially private stochastic gradient descent (DPSGD). Yet, the method is inherently wasteful. By adding noise to every gradient, it diminishes the overall privacy with every gradient step. Despite 15 years of fruitful research advancing the composition theorems, sub-sampling methods, and implementation techniques, adequate accuracy and privacy is often unattainable with current private ML methods. Meanwhile, the Exponential Mechanism (ExpM), designed for private optimization, has been historically sidelined from privately training modern ML algorithms primarily because ExpM requires sampling from a historically intractable density. Despite the recent discovery of Normalizing Flow models (NFs), expressive deep networks for approximating intractable distributions, ExpM remains in the background. Our position is that leveraging NFs to circumvent historic obstructions of ExpM is a potential
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#38477;&#32500;&#31639;&#27861;&#65292;&#21033;&#29992;&#20559;&#26368;&#23567;&#20108;&#20056;&#22238;&#24402;&#26469;&#20943;&#23569;&#26500;&#24314;&#28151;&#21512;&#21464;&#37327;&#39640;&#26031;&#36807;&#31243;&#25152;&#38656;&#30340;&#36229;&#21442;&#25968;&#25968;&#37327;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#32467;&#26500;&#21644;&#22810;&#23398;&#31185;&#24212;&#29992;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#28508;&#21147;&#65292;&#36866;&#29992;&#20110;&#32511;&#33394;&#39134;&#26426;&#30340;&#20248;&#21270;&#31561;&#22810;&#20010;&#39046;&#22495;&#12290;</title><link>https://rss.arxiv.org/abs/2311.06130</link><description>&lt;p&gt;
&#39640;&#32500;&#28151;&#21512;&#31867;&#21035;&#39640;&#26031;&#36807;&#31243;&#22312;&#32511;&#33394;&#39134;&#26426;&#22810;&#23398;&#31185;&#35774;&#35745;&#20248;&#21270;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
High-dimensional mixed-categorical Gaussian processes with application to multidisciplinary design optimization for a green aircraft
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2311.06130
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#38477;&#32500;&#31639;&#27861;&#65292;&#21033;&#29992;&#20559;&#26368;&#23567;&#20108;&#20056;&#22238;&#24402;&#26469;&#20943;&#23569;&#26500;&#24314;&#28151;&#21512;&#21464;&#37327;&#39640;&#26031;&#36807;&#31243;&#25152;&#38656;&#30340;&#36229;&#21442;&#25968;&#25968;&#37327;&#12290;&#36825;&#31181;&#26041;&#27861;&#22312;&#32467;&#26500;&#21644;&#22810;&#23398;&#31185;&#24212;&#29992;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#28508;&#21147;&#65292;&#36866;&#29992;&#20110;&#32511;&#33394;&#39134;&#26426;&#30340;&#20248;&#21270;&#31561;&#22810;&#20010;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#30340;&#28151;&#21512;&#31867;&#21035;&#20803;&#27169;&#22411;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#22312;&#36825;&#20010;&#32972;&#26223;&#19979;&#65292;&#21487;&#20197;&#20351;&#29992;&#19981;&#21516;&#30340;&#26041;&#27861;&#26469;&#26500;&#24314;&#28151;&#21512;&#31867;&#21035;&#30340;GP&#12290;&#20854;&#20013;&#35768;&#22810;&#26041;&#27861;&#28041;&#21450;&#22823;&#37327;&#30340;&#36229;&#21442;&#25968;&#65307;&#20107;&#23454;&#19978;&#65292;&#29992;&#20110;&#26500;&#24314;GP&#30340;&#31574;&#30053;&#36234;&#36890;&#29992;&#21644;&#31934;&#30830;&#65292;&#38656;&#35201;&#20272;&#35745;&#30340;&#36229;&#21442;&#25968;&#36234;&#22810;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#21019;&#26032;&#30340;&#38477;&#32500;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#20381;&#36182;&#20110;&#20559;&#26368;&#23567;&#20108;&#20056;&#22238;&#24402;&#65292;&#20197;&#20943;&#23569;&#29992;&#20110;&#26500;&#24314;&#28151;&#21512;&#21464;&#37327;GP&#30340;&#36229;&#21442;&#25968;&#25968;&#37327;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#23558;&#24120;&#29992;&#20110;&#22788;&#29702;&#36830;&#32493;&#36755;&#20837;&#30340;&#32463;&#20856;&#38477;&#32500;&#25216;&#26415;&#25512;&#24191;&#21040;&#22788;&#29702;&#28151;&#21512;&#31867;&#21035;&#36755;&#20837;&#12290;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#28508;&#21147;&#22312;&#32467;&#26500;&#21644;&#22810;&#23398;&#31185;&#24212;&#29992;&#20013;&#24471;&#21040;&#20102;&#24456;&#22909;&#30340;&#35777;&#26126;&#12290;&#30446;&#26631;&#24212;&#29992;&#21253;&#25324;&#24748;&#33218;&#26753;&#30340;&#20998;&#26512;&#20197;&#21450;&#32511;&#33394;&#39134;&#26426;&#30340;&#20248;&#21270;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, there has been a growing interest in mixed-categorical metamodels based on Gaussian Process (GP) for Bayesian optimization. In this context, different approaches can be used to build the mixed-categorical GP. Many of these approaches involve a high number of hyperparameters; in fact, the more general and precise the strategy used to build the GP, the greater the number of hyperparameters to estimate. This paper introduces an innovative dimension reduction algorithm that relies on partial least squares regression to reduce the number of hyperparameters used to build a mixed-variable GP. Our goal is to generalize classical dimension reduction techniques commonly used within GP (for continuous inputs) to handle mixed-categorical inputs. The good potential of the proposed method is demonstrated in both structural and multidisciplinary application contexts. The targeted applications include the analysis of a cantilever beam as well as the optimization of a green aircraft, resultin
&lt;/p&gt;</description></item><item><title>&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#21069;&#21521;$\chi^2$&#25955;&#24230;&#30340;&#21464;&#20998;&#37325;&#35201;&#25277;&#26679;&#26041;&#27861;(VIS)&#65292;&#36890;&#36807;&#30452;&#25509;&#20272;&#35745;&#21644;&#26368;&#22823;&#21270;&#23545;&#25968;&#20284;&#28982;&#26469;&#22686;&#24378;&#23545;&#22797;&#26434;&#21518;&#39564;&#20998;&#24067;&#30340;&#20272;&#35745;&#24615;&#33021;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;VIS&#26041;&#27861;&#22312;&#22810;&#31181;&#28508;&#21464;&#37327;&#27169;&#22411;&#20013;&#22343;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#22522;&#32447;&#26041;&#27861;&#65292;&#34920;&#29616;&#20986;&#26356;&#39640;&#30340;&#23545;&#25968;&#20284;&#28982;&#21644;&#27169;&#22411;&#21442;&#25968;&#20272;&#35745;&#20934;&#30830;&#24615;&#12290;</title><link>https://rss.arxiv.org/abs/2311.02516</link><description>&lt;p&gt;
&#22522;&#20110;&#21069;&#21521;$\chi^2$&#25955;&#24230;&#30340;&#21464;&#20998;&#37325;&#35201;&#25277;&#26679;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Forward $\chi^2$ Divergence Based Variational Importance Sampling
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2311.02516
&lt;/p&gt;
&lt;p&gt;
&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#21069;&#21521;$\chi^2$&#25955;&#24230;&#30340;&#21464;&#20998;&#37325;&#35201;&#25277;&#26679;&#26041;&#27861;(VIS)&#65292;&#36890;&#36807;&#30452;&#25509;&#20272;&#35745;&#21644;&#26368;&#22823;&#21270;&#23545;&#25968;&#20284;&#28982;&#26469;&#22686;&#24378;&#23545;&#22797;&#26434;&#21518;&#39564;&#20998;&#24067;&#30340;&#20272;&#35745;&#24615;&#33021;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;VIS&#26041;&#27861;&#22312;&#22810;&#31181;&#28508;&#21464;&#37327;&#27169;&#22411;&#20013;&#22343;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#22522;&#32447;&#26041;&#27861;&#65292;&#34920;&#29616;&#20986;&#26356;&#39640;&#30340;&#23545;&#25968;&#20284;&#28982;&#21644;&#27169;&#22411;&#21442;&#25968;&#20272;&#35745;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#22823;&#21270;&#23545;&#25968;&#20284;&#28982;&#26159;&#23398;&#20064;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#20851;&#38190;&#26041;&#38754;&#65292;&#32780;&#21464;&#20998;&#25512;&#26029;&#65288;VI&#65289;&#26159;&#30446;&#21069;&#24120;&#29992;&#30340;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#24403;&#22788;&#29702;&#22797;&#26434;&#30340;&#21518;&#39564;&#20998;&#24067;&#26102;&#65292;VI&#22312;&#23454;&#29616;&#39640;&#23545;&#25968;&#20284;&#28982;&#26041;&#38754;&#21487;&#33021;&#36935;&#21040;&#25361;&#25112;&#12290;&#38024;&#23545;&#36825;&#20010;&#38480;&#21046;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21464;&#20998;&#37325;&#35201;&#25277;&#26679;&#65288;VIS&#65289;&#26041;&#27861;&#65292;&#30452;&#25509;&#20272;&#35745;&#21644;&#26368;&#22823;&#21270;&#23545;&#25968;&#20284;&#28982;&#12290;VIS&#21033;&#29992;&#36890;&#36807;&#26368;&#23567;&#21270;&#21069;&#21521;$\chi^2$&#25955;&#24230;&#23454;&#29616;&#30340;&#26368;&#20339;&#25552;&#35758;&#20998;&#24067;&#26469;&#22686;&#24378;&#23545;&#25968;&#20284;&#28982;&#20272;&#35745;&#12290;&#25105;&#20204;&#23558;VIS&#24212;&#29992;&#20110;&#22810;&#31181;&#27969;&#34892;&#30340;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#21253;&#25324;&#28151;&#21512;&#27169;&#22411;&#12289;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#21644;&#37096;&#20998;&#35266;&#27979;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#23545;&#25968;&#20284;&#28982;&#21644;&#27169;&#22411;&#21442;&#25968;&#20272;&#35745;&#26041;&#38754;&#22987;&#32456;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#22522;&#32447;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Maximizing the log-likelihood is a crucial aspect of learning latent variable models, and variational inference (VI) stands as the commonly adopted method. However, VI can encounter challenges in achieving a high log-likelihood when dealing with complicated posterior distributions. In response to this limitation, we introduce a novel variational importance sampling (VIS) approach that directly estimates and maximizes the log-likelihood. VIS leverages the optimal proposal distribution, achieved by minimizing the forward $\chi^2$ divergence, to enhance log-likelihood estimation. We apply VIS to various popular latent variable models, including mixture models, variational auto-encoders, and partially observable generalized linear models. Results demonstrate that our approach consistently outperforms state-of-the-art baselines, both in terms of log-likelihood and model parameter estimation.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21464;&#20998;&#31232;&#30095;&#39640;&#26031;&#36807;&#31243;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#36817;&#20284;&#32447;&#24615;&#21270;Laplace&#36817;&#20284;&#22312;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#12290;&#35813;&#26041;&#27861;&#20445;&#30041;&#20102;&#21407;&#22987;DNN&#30340;&#39044;&#27979;&#22343;&#20540;&#65292;&#24182;&#20855;&#26377;&#39640;&#25928;&#30340;&#38543;&#26426;&#20248;&#21270;&#65292;&#35757;&#32451;&#25104;&#26412;&#19982;&#35757;&#32451;&#28857;&#30340;&#25968;&#37327;&#26080;&#20851;&#12290;</title><link>https://rss.arxiv.org/abs/2302.12565</link><description>&lt;p&gt;
&#21464;&#20998;&#32447;&#24615;&#21270;Laplace&#36817;&#20284;&#22312;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Variational Linearized Laplace Approximation for Bayesian Deep Learning
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2302.12565
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21464;&#20998;&#31232;&#30095;&#39640;&#26031;&#36807;&#31243;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#36817;&#20284;&#32447;&#24615;&#21270;Laplace&#36817;&#20284;&#22312;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#12290;&#35813;&#26041;&#27861;&#20445;&#30041;&#20102;&#21407;&#22987;DNN&#30340;&#39044;&#27979;&#22343;&#20540;&#65292;&#24182;&#20855;&#26377;&#39640;&#25928;&#30340;&#38543;&#26426;&#20248;&#21270;&#65292;&#35757;&#32451;&#25104;&#26412;&#19982;&#35757;&#32451;&#28857;&#30340;&#25968;&#37327;&#26080;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#32447;&#24615;&#21270;Laplace&#36817;&#20284;&#65288;LLA&#65289;&#34987;&#29992;&#26469;&#23545;&#39044;&#35757;&#32451;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;DNNs&#65289;&#30340;&#39044;&#27979;&#36827;&#34892;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#22312;&#35757;&#32451;&#28857;&#25110;DNN&#21442;&#25968;&#36739;&#22810;&#30340;&#24773;&#20917;&#19979;&#65292;&#20854;&#24191;&#27867;&#24212;&#29992;&#21463;&#21040;&#20102;&#35745;&#31639;&#25104;&#26412;&#30340;&#38480;&#21046;&#12290;&#22240;&#27492;&#65292;&#20854;&#20182;LLA&#30340;&#36817;&#20284;&#26041;&#27861;&#65292;&#22914;Kronecker&#20998;&#35299;&#25110;&#23545;&#35282;&#32447;GGN&#30697;&#38453;&#30340;&#36817;&#20284;&#65292;&#34987;&#20351;&#29992;&#65292;&#21487;&#33021;&#20250;&#24433;&#21709;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21464;&#20998;&#31232;&#30095;&#39640;&#26031;&#36807;&#31243;&#65288;GP&#65289;&#30340;LLA&#36817;&#20284;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;GP&#30340;&#23545;&#20598;RKHS&#20844;&#24335;&#65292;&#24182;&#20445;&#30041;&#20102;&#21407;&#22987;DNN&#30340;&#39044;&#27979;&#22343;&#20540;&#12290;&#27492;&#22806;&#65292;&#23427;&#20801;&#35768;&#26377;&#25928;&#30340;&#38543;&#26426;&#20248;&#21270;&#65292;&#20174;&#32780;&#22312;&#35757;&#32451;&#25968;&#25454;&#38598;&#30340;&#22823;&#23567;&#20013;&#23454;&#29616;&#23376;&#32447;&#24615;&#35757;&#32451;&#26102;&#38388;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#20854;&#35757;&#32451;&#25104;&#26412;&#19982;&#35757;&#32451;&#28857;&#30340;&#25968;&#37327;&#26080;&#20851;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#20854;&#20182;&#36817;&#20284;&#26041;&#27861;&#30340;&#24615;&#33021;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;&#20934;&#30830;&#24615;&#21644;&#35745;&#31639;&#25928;&#29575;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Linearized Laplace Approximation (LLA) has been recently used to perform uncertainty estimation on the predictions of pre-trained deep neural networks (DNNs). However, its widespread application is hindered by significant computational costs, particularly in scenarios with a large number of training points or DNN parameters. Consequently, additional approximations of LLA, such as Kronecker-factored or diagonal approximate GGN matrices, are utilized, potentially compromising the model's performance. To address these challenges, we propose a new method for approximating LLA using a variational sparse Gaussian Process (GP). Our method is based on the dual RKHS formulation of GPs and retains as the predictive mean the output of the original DNN. Furthermore, it allows for efficient stochastic optimization, which results in sub-linear training time in the size of the training dataset. Specifically, its training cost is independent of the number of training points. We compare our propose
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#29983;&#25104;&#23545;&#25239;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#26469;&#23398;&#20064;Sinkhorn&#31639;&#27861;&#30340;&#21021;&#22987;&#21270;&#65292;&#26174;&#33879;&#21152;&#24555;&#25910;&#25947;&#36895;&#24230;&#65292;&#21516;&#26102;&#20445;&#25345;&#31639;&#27861;&#30340;&#21487;&#24494;&#20998;&#24615;&#21644;&#24182;&#34892;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#32593;&#32476;&#30340;&#26222;&#36866;&#24615;&#21644;&#29420;&#31435;&#27714;&#35299;&#33021;&#21147;&#12290;</title><link>https://rss.arxiv.org/abs/2212.00133</link><description>&lt;p&gt;
&#29983;&#25104;&#23545;&#25239;&#23398;&#20064;Sinkhorn&#31639;&#27861;&#21021;&#22987;&#21270;
&lt;/p&gt;
&lt;p&gt;
Generative Adversarial Learning of Sinkhorn Algorithm Initializations
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2212.00133
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#29983;&#25104;&#23545;&#25239;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#26469;&#23398;&#20064;Sinkhorn&#31639;&#27861;&#30340;&#21021;&#22987;&#21270;&#65292;&#26174;&#33879;&#21152;&#24555;&#25910;&#25947;&#36895;&#24230;&#65292;&#21516;&#26102;&#20445;&#25345;&#31639;&#27861;&#30340;&#21487;&#24494;&#20998;&#24615;&#21644;&#24182;&#34892;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#32593;&#32476;&#30340;&#26222;&#36866;&#24615;&#21644;&#29420;&#31435;&#27714;&#35299;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Sinkhorn&#31639;&#27861;&#26159;&#36817;&#20284;&#27714;&#35299;&#31163;&#25955;&#27010;&#29575;&#20998;&#24067;&#20043;&#38388;&#29109;&#27491;&#21017;&#36755;&#36816;&#65288;OT&#65289;&#36317;&#31163;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#36807;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#26469;&#23398;&#20064;&#31639;&#27861;&#21021;&#22987;&#21270;&#65292;&#21487;&#20197;&#26174;&#33879;&#21152;&#24555;&#25910;&#25947;&#36895;&#24230;&#65292;&#21516;&#26102;&#20445;&#25345;Sinkhorn&#31639;&#27861;&#30340;&#21487;&#24494;&#20998;&#24615;&#21644;&#24182;&#34892;&#24615;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#25239;&#35757;&#32451;&#30340;&#26041;&#24335;&#20351;&#29992;&#31532;&#20108;&#20010;&#29983;&#25104;&#32593;&#32476;&#21644;&#33258;&#30417;&#30563;&#24341;&#23548;&#25439;&#22833;&#26469;&#35757;&#32451;&#25105;&#20204;&#30340;&#39044;&#27979;&#32593;&#32476;&#12290;&#39044;&#27979;&#32593;&#32476;&#20855;&#26377;&#26222;&#36866;&#24615;&#65292;&#33021;&#22815;&#25512;&#24191;&#21040;&#20219;&#24847;&#22266;&#23450;&#32500;&#24230;&#21644;&#25104;&#26412;&#30340;&#27010;&#29575;&#20998;&#24067;&#23545;&#65292;&#24182;&#19988;&#25105;&#20204;&#35777;&#26126;&#29983;&#25104;&#32593;&#32476;&#21487;&#20197;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#20135;&#29983;&#20219;&#24847;&#27010;&#29575;&#20998;&#24067;&#23545;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#32593;&#32476;&#21487;&#20197;&#20316;&#20026;&#29420;&#31435;&#30340;OT&#27714;&#35299;&#22120;&#26469;&#36817;&#20284;&#27491;&#21017;&#21270;&#36755;&#36816;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Sinkhorn algorithm is the state-of-the-art to approximate solutions of entropic optimal transport (OT) distances between discrete probability distributions. We show that meticulously training a neural network to learn initializations to the algorithm via the entropic OT dual problem can significantly speed up convergence, while maintaining desirable properties of the Sinkhorn algorithm, such as differentiability and parallelizability. We train our predictive network in an adversarial fashion using a second, generating network and a self-supervised bootstrapping loss. The predictive network is universal in the sense that it is able to generalize to any pair of distributions of fixed dimension and cost at inference, and we prove that we can make the generating network universal in the sense that it is capable of producing any pair of distributions during training. Furthermore, we show that our network can even be used as a standalone OT solver to approximate regularized transport dis
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#21644;&#31639;&#27861;&#24037;&#20855;&#31665;&#65292;&#35299;&#20915;&#20102;&#32593;&#32476;&#27604;&#36739;&#20013;&#30340;&#22810;&#20010;&#25361;&#25112;&#65292;&#24182;&#20855;&#26377;&#39640;&#38454;&#31934;&#30830;&#24230;&#21644;&#21151;&#29575;&#20248;&#21270;&#30340;&#29305;&#28857;&#12290;&#36825;&#20010;&#26041;&#27861;&#22312;&#36895;&#24230;&#21644;&#20934;&#30830;&#24230;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#24037;&#20855;&#65292;&#24182;&#19988;&#20855;&#26377;&#24378;&#22823;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>https://rss.arxiv.org/abs/2208.07573</link><description>&lt;p&gt;
&#39640;&#38454;&#31934;&#30830;&#24230;&#30340;&#20004;&#20010;&#26679;&#26412;&#32593;&#32476;&#25512;&#26029;&#19982;&#21704;&#24076;
&lt;/p&gt;
&lt;p&gt;
Higher-order accurate two-sample network inference and network hashing
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2208.07573
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#21644;&#31639;&#27861;&#24037;&#20855;&#31665;&#65292;&#35299;&#20915;&#20102;&#32593;&#32476;&#27604;&#36739;&#20013;&#30340;&#22810;&#20010;&#25361;&#25112;&#65292;&#24182;&#20855;&#26377;&#39640;&#38454;&#31934;&#30830;&#24230;&#21644;&#21151;&#29575;&#20248;&#21270;&#30340;&#29305;&#28857;&#12290;&#36825;&#20010;&#26041;&#27861;&#22312;&#36895;&#24230;&#21644;&#20934;&#30830;&#24230;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#24037;&#20855;&#65292;&#24182;&#19988;&#20855;&#26377;&#24378;&#22823;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32593;&#32476;&#27604;&#36739;&#30340;&#20004;&#20010;&#26679;&#26412;&#20551;&#35774;&#26816;&#39564;&#38754;&#20020;&#35768;&#22810;&#37325;&#22823;&#25361;&#25112;&#65292;&#21253;&#25324;&#65306;&#21033;&#29992;&#37325;&#22797;&#30340;&#32593;&#32476;&#35266;&#27979;&#21644;&#24050;&#30693;&#30340;&#33410;&#28857;&#27880;&#20876;&#65292;&#20294;&#19981;&#38656;&#35201;&#23427;&#20204;&#19968;&#36215;&#25805;&#20316;&#65307;&#25918;&#26494;&#24378;&#32467;&#26500;&#24615;&#20551;&#35774;&#65307;&#23454;&#29616;&#26377;&#38480;&#26679;&#26412;&#39640;&#38454;&#31934;&#30830;&#24230;&#65307;&#22788;&#29702;&#19981;&#21516;&#30340;&#32593;&#32476;&#22823;&#23567;&#21644;&#31232;&#30095;&#31243;&#24230;&#65307;&#24555;&#36895;&#35745;&#31639;&#21644;&#20869;&#23384;&#33410;&#30465;&#65307;&#22312;&#22810;&#37325;&#26816;&#39564;&#20013;&#25511;&#21046;&#20551;&#38451;&#24615;&#21457;&#29616;&#29575;&#65288;FDR&#65289;&#65307;&#20197;&#21450;&#22312;&#29702;&#35770;&#19978;&#23545;&#26377;&#38480;&#26679;&#26412;&#31934;&#30830;&#24230;&#21644;&#26368;&#23567;&#26497;&#20540;&#24615;&#30340;&#29702;&#35299;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#20840;&#38754;&#30340;&#24037;&#20855;&#31665;&#65292;&#20854;&#20013;&#21253;&#25324;&#19968;&#31181;&#26032;&#30340;&#20027;&#35201;&#26041;&#27861;&#21450;&#20854;&#21464;&#20307;&#65292;&#25152;&#26377;&#36825;&#20123;&#26041;&#27861;&#37117;&#20276;&#38543;&#30528;&#24378;&#22823;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#20197;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#36895;&#24230;&#21644;&#20934;&#30830;&#24230;&#19978;&#20248;&#20110;&#29616;&#26377;&#24037;&#20855;&#65292;&#24182;&#34987;&#35777;&#26126;&#26159;&#21151;&#29575;&#20248;&#21270;&#30340;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#23545;&#20110;&#22788;&#29702;&#21508;&#31181;&#25968;&#25454;&#32467;&#26500;&#65288;&#21333;&#19968;&#25110;&#37325;&#22797;&#30340;&#32593;&#32476;&#35266;&#27979;&#65307;&#24050;&#30693;&#25110;&#26410;&#30693;&#30340;&#33410;&#28857;&#27880;&#20876;&#65289;&#38750;&#24120;&#21451;&#22909;&#21644;&#22810;&#21151;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Two-sample hypothesis testing for network comparison presents many significant challenges, including: leveraging repeated network observations and known node registration, but without requiring them to operate; relaxing strong structural assumptions; achieving finite-sample higher-order accuracy; handling different network sizes and sparsity levels; fast computation and memory parsimony; controlling false discovery rate (FDR) in multiple testing; and theoretical understandings, particularly regarding finite-sample accuracy and minimax optimality. In this paper, we develop a comprehensive toolbox, featuring a novel main method and its variants, all accompanied by strong theoretical guarantees, to address these challenges. Our method outperforms existing tools in speed and accuracy, and it is proved power-optimal. Our algorithms are user-friendly and versatile in handling various data structures (single or repeated network observations; known or unknown node registration). We also develo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20174;&#32479;&#35745;&#23398;&#20064;&#30340;&#35270;&#35282;&#23545;&#31616;&#21333;&#20811;&#37324;&#37329;&#26041;&#27861;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#35299;&#20915;&#20102;&#22312;&#22823;&#25968;&#25454;&#26102;&#20195;&#20013;&#65292;&#32771;&#34385;&#22797;&#26434;&#31354;&#38388;&#30456;&#20851;&#32467;&#26500;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#39044;&#27979;&#38382;&#39064;&#12290;</title><link>https://rss.arxiv.org/abs/2202.07365</link><description>&lt;p&gt;
&#32479;&#35745;&#23398;&#20064;&#35270;&#35282;&#19979;&#30340;&#31616;&#21333;&#20811;&#37324;&#37329;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Statistical Learning View of Simple Kriging
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2202.07365
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#32479;&#35745;&#23398;&#20064;&#30340;&#35270;&#35282;&#23545;&#31616;&#21333;&#20811;&#37324;&#37329;&#26041;&#27861;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#35299;&#20915;&#20102;&#22312;&#22823;&#25968;&#25454;&#26102;&#20195;&#20013;&#65292;&#32771;&#34385;&#22797;&#26434;&#31354;&#38388;&#30456;&#20851;&#32467;&#26500;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#39044;&#27979;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22823;&#25968;&#25454;&#26102;&#20195;&#65292;&#29305;&#21035;&#26159;&#30001;&#20110;&#22320;&#29702;&#23450;&#20301;&#20256;&#24863;&#22120;&#30340;&#26222;&#21450;&#65292;&#20986;&#29616;&#20102;&#36234;&#26469;&#36234;&#22810;&#23637;&#31034;&#21487;&#33021;&#20855;&#26377;&#22797;&#26434;&#31354;&#38388;&#30456;&#20851;&#32467;&#26500;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#26631;&#20934;&#30340;&#32479;&#35745;&#23398;&#20064;&#30340;&#27010;&#29575;&#29702;&#35770;&#19981;&#30452;&#25509;&#36866;&#29992;&#65292;&#24182;&#19988;&#20174;&#36825;&#20123;&#25968;&#25454;&#20013;&#23398;&#20064;&#30340;&#39044;&#27979;&#35268;&#21017;&#30340;&#27867;&#21270;&#33021;&#21147;&#30340;&#20445;&#35777;&#26377;&#24453;&#24314;&#31435;&#12290;&#26412;&#25991;&#20174;&#32479;&#35745;&#23398;&#20064;&#30340;&#35270;&#35282;&#23545;&#31616;&#21333;&#20811;&#37324;&#37329;&#26041;&#27861;&#36827;&#34892;&#20102;&#20998;&#26512;&#65292;&#21363;&#36890;&#36807;&#36827;&#34892;&#38750;&#21442;&#25968;&#26377;&#38480;&#26679;&#26412;&#30340;&#39044;&#27979;&#20998;&#26512;&#12290;&#32473;&#23450;$d\geq 1$&#20010;&#30001;&#26410;&#30693;&#21327;&#26041;&#24046;&#32467;&#26500;&#30340;&#24179;&#26041;&#21487;&#31215;&#38543;&#26426;&#22330;$X=\{X_s\}_{s\in S}$&#22312;$S\subset \mathbb{R}^2$&#20013;&#30340;$s_1,\; \ldots,\; s_d$&#22788;&#30340;&#23454;&#29616;&#20540;&#65292;&#30446;&#26631;&#26159;&#29992;&#26368;&#23567;&#20108;&#27425;&#39118;&#38505;&#39044;&#27979;&#23427;&#22312;$S$&#20013;&#30340;&#20219;&#20309;&#20854;&#20182;&#20301;&#32622;$s\in S$&#19978;&#30340;&#26410;&#30693;&#20540;&#12290;&#39044;&#27979;&#35268;&#21017;&#26159;&#20174;&#35757;&#32451;&#31354;&#38388;&#25968;&#25454;&#38598;&#23548;&#20986;&#30340;&#65306;&#26469;&#33258;&#29420;&#31435;&#20110;&#24453;&#39044;&#27979;&#20301;&#32622;&#30340;&#23454;&#29616;$X'$&#12290;
&lt;/p&gt;
&lt;p&gt;
In the Big Data era, with the ubiquity of geolocation sensors in particular, massive datasets exhibiting a possibly complex spatial dependence structure are becoming increasingly available. In this context, the standard probabilistic theory of statistical learning does not apply directly and guarantees of the generalization capacity of predictive rules learned from such data are left to establish. We analyze here the simple Kriging task from a statistical learning perspective, i.e. by carrying out a nonparametric finite-sample predictive analysis. Given $d\geq 1$ values taken by a realization of a square integrable random field $X=\{X_s\}_{s\in S}$, $S\subset \mathbb{R}^2$, with unknown covariance structure, at sites $s_1,\; \ldots,\; s_d$ in $S$, the goal is to predict the unknown values it takes at any other location $s\in S$ with minimum quadratic risk. The prediction rule being derived from a training spatial dataset: a single realization $X'$ of $X$, independent from those to be p
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;SinkhornDRL&#26041;&#27861;&#65292;&#20351;&#29992;Sinkhorn&#25955;&#24230;&#26469;&#20943;&#23567;&#24403;&#21069;&#21644;&#30446;&#26631;Bellman&#22238;&#25253;&#20998;&#24067;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#35777;&#26126;&#21644;&#23454;&#35777;&#23454;&#39564;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>https://rss.arxiv.org/abs/2202.00769</link><description>&lt;p&gt;
&#20351;&#29992;Sinkhorn&#25955;&#24230;&#30340;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Distributional Reinforcement Learning by Sinkhorn Divergence
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2202.00769
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;SinkhornDRL&#26041;&#27861;&#65292;&#20351;&#29992;Sinkhorn&#25955;&#24230;&#26469;&#20943;&#23567;&#24403;&#21069;&#21644;&#30446;&#26631;Bellman&#22238;&#25253;&#20998;&#24067;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#35777;&#26126;&#21644;&#23454;&#35777;&#23454;&#39564;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#30340;&#23454;&#35777;&#25104;&#21151;&#39640;&#24230;&#20381;&#36182;&#20110;&#20998;&#24067;&#34920;&#31034;&#21644;&#20998;&#24067;&#25955;&#24230;&#30340;&#36873;&#25321;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;Sinkhorn&#20998;&#24067;&#24378;&#21270;&#23398;&#20064; (SinkhornDRL)&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20174;&#22238;&#25253;&#20998;&#24067;&#20013;&#23398;&#20064;&#26080;&#38480;&#21046;&#30340;&#32479;&#35745;&#37327;&#65292;&#24182;&#21033;&#29992;Sinkhorn&#25955;&#24230;&#26469;&#20943;&#23567;&#24403;&#21069;&#21644;&#30446;&#26631;Bellman&#22238;&#25253;&#20998;&#24067;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#20174;&#29702;&#35770;&#19978;&#26469;&#35762;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;SinkhornDRL&#30340;&#25910;&#32553;&#24615;&#36136;&#65292;&#19982;Sinkhorn&#25955;&#24230;&#22312;Wasserstein&#36317;&#31163;&#21644;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322; (MMD)&#20043;&#38388;&#30340;&#25554;&#20540;&#24615;&#36136;&#19968;&#33268;&#12290;&#25105;&#20204;&#36824;&#24314;&#31435;&#20102;Sinkhorn&#25955;&#24230;&#19982;&#24102;&#26377;&#27491;&#21017;&#21270;Moment Matching&#34892;&#20026;&#30340;&#27491;&#21017;&#21270;MMD&#20043;&#38388;&#30340;&#31561;&#20215;&#20851;&#31995;&#65292;&#20174;&#32780;&#35299;&#37322;&#20102;SinkhornDRL&#30340;&#20248;&#36234;&#24615;&#12290;&#22312;&#23454;&#35777;&#19978;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;SinkhornDRL&#22312;Atari&#28216;&#25103;&#22871;&#20214;&#19978;&#22987;&#32456;&#34920;&#29616;&#27604;&#29616;&#26377;&#31639;&#27861;&#26356;&#22909;&#25110;&#21487;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;
The empirical success of distributional reinforcement learning~(RL) highly depends on the distribution representation and the choice of distribution divergence. In this paper, we propose \textit{Sinkhorn distributional RL~(SinkhornDRL)} that learns unrestricted statistics from return distributions and leverages Sinkhorn divergence to minimize the difference between current and target Bellman return distributions. Theoretically, we prove the contraction properties of SinkhornDRL, consistent with the interpolation nature of Sinkhorn divergence between Wasserstein distance and Maximum Mean Discrepancy~(MMD). We also establish the equivalence between Sinkhorn divergence and a regularized MMD with a regularized Moment Matching behavior, contributing to explaining the superiority of SinkhornDRL. Empirically, we show that SinkhornDRL is consistently better or comparable to existing algorithms on the Atari games suite.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#23545;&#32570;&#22833;&#25968;&#25454;&#38382;&#39064;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#36890;&#36807;&#23545;&#27604;&#29702;&#35770;&#21644;&#23454;&#35777;&#32467;&#26524;&#65292;&#23637;&#31034;&#20102;&#19968;&#20123;&#31616;&#21333;&#22635;&#34917;&#35268;&#21017;&#22312;&#39044;&#27979;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#12290;&#22312;&#24191;&#27867;&#22635;&#34917;&#26041;&#27861;&#23478;&#26063;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#22343;&#20540;&#22635;&#34917;&#26159;&#26368;&#20248;&#30340;&#65292;&#32780;&#20247;&#25968;&#22635;&#34917;&#26159;&#27425;&#20248;&#30340;&#12290;&#23454;&#35777;&#32467;&#26524;&#38500;&#20102;&#25903;&#25345;&#29702;&#35770;&#21457;&#29616;&#22806;&#65292;&#36824;&#24378;&#35843;&#20102;&#29702;&#35770;&#21644;&#23454;&#36341;&#20043;&#38388;&#30340;&#24046;&#36317;&#21644;&#26410;&#26469;&#30740;&#31350;&#30340;&#26426;&#20250;&#12290;</title><link>https://rss.arxiv.org/abs/2104.03158</link><description>&lt;p&gt;
&#39044;&#27979;&#20013;&#32570;&#22833;&#25968;&#25454;&#30340;&#31616;&#21333;&#22635;&#34917;&#35268;&#21017;&#65306;&#29702;&#35770;&#20445;&#35777;&#19982;&#23454;&#35777;&#24615;&#33021;&#30340;&#23545;&#27604;
&lt;/p&gt;
&lt;p&gt;
Simple Imputation Rules for Prediction with Missing Data: Contrasting Theoretical Guarantees with Empirical Performance
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2104.03158
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#23545;&#32570;&#22833;&#25968;&#25454;&#38382;&#39064;&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#36890;&#36807;&#23545;&#27604;&#29702;&#35770;&#21644;&#23454;&#35777;&#32467;&#26524;&#65292;&#23637;&#31034;&#20102;&#19968;&#20123;&#31616;&#21333;&#22635;&#34917;&#35268;&#21017;&#22312;&#39044;&#27979;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#12290;&#22312;&#24191;&#27867;&#22635;&#34917;&#26041;&#27861;&#23478;&#26063;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#22343;&#20540;&#22635;&#34917;&#26159;&#26368;&#20248;&#30340;&#65292;&#32780;&#20247;&#25968;&#22635;&#34917;&#26159;&#27425;&#20248;&#30340;&#12290;&#23454;&#35777;&#32467;&#26524;&#38500;&#20102;&#25903;&#25345;&#29702;&#35770;&#21457;&#29616;&#22806;&#65292;&#36824;&#24378;&#35843;&#20102;&#29702;&#35770;&#21644;&#23454;&#36341;&#20043;&#38388;&#30340;&#24046;&#36317;&#21644;&#26410;&#26469;&#30740;&#31350;&#30340;&#26426;&#20250;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32570;&#22833;&#25968;&#25454;&#26159;&#23454;&#38469;&#25968;&#25454;&#38598;&#20013;&#24120;&#35265;&#30340;&#38382;&#39064;&#12290;&#26412;&#25991;&#36890;&#36807;&#23545;&#27604;&#29702;&#35770;&#21644;&#23454;&#35777;&#35777;&#25454;&#26469;&#30740;&#31350;&#22635;&#34917;-&#22238;&#24402;&#27969;&#31243;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#36866;&#29992;&#20110;&#24191;&#27867;&#22635;&#34917;&#26041;&#27861;&#23478;&#26063;&#30340;&#28176;&#36827;&#19968;&#33268;&#24615;&#12290;&#23613;&#31649;&#24120;&#35782;&#35748;&#20026;&#8220;&#22909;&#8221;&#30340;&#22635;&#34917;&#26041;&#27861;&#29983;&#25104;&#30340;&#25968;&#25454;&#38598;&#26159;&#21512;&#29702;&#30340;&#65292;&#20294;&#26159;&#25105;&#20204;&#21457;&#29616;&#65292;&#22312;&#39044;&#27979;&#26041;&#38754;&#65292;&#31895;&#31961;&#25968;&#25454;&#20063;&#21487;&#33021;&#26159;&#22909;&#30340;&#12290;&#25105;&#20204;&#21457;&#29616;&#20854;&#20013;&#19968;&#20123;&#32467;&#35770;&#26159;&#65292;&#20247;&#25968;&#22635;&#34917;&#22312;&#28176;&#36827;&#19978;&#26159;&#27425;&#20248;&#30340;&#65292;&#32780;&#22343;&#20540;&#22635;&#34917;&#22312;&#28176;&#36827;&#19978;&#26159;&#26368;&#20248;&#30340;&#12290;&#28982;&#21518;&#25105;&#20204;&#22312;&#22823;&#37327;&#30340;&#21512;&#25104;&#12289;&#21322;&#30495;&#23454;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#35814;&#23613;&#35780;&#20272;&#20102;&#36825;&#20123;&#29702;&#35770;&#32467;&#35770;&#30340;&#26377;&#25928;&#24615;&#12290;&#23613;&#31649;&#25105;&#20204;&#25910;&#38598;&#30340;&#23454;&#35777;&#35777;&#25454;&#22823;&#22810;&#25903;&#25345;&#25105;&#20204;&#30340;&#29702;&#35770;&#21457;&#29616;&#65292;&#20294;&#20063;&#24378;&#35843;&#20102;&#29702;&#35770;&#19982;&#23454;&#36341;&#20043;&#38388;&#30340;&#24046;&#36317;&#21644;&#26410;&#26469;&#30740;&#31350;&#30340;&#26426;&#20250;&#65292;&#20197;&#35299;&#20915;MAR&#20551;&#35774;&#30340;&#30456;&#20851;&#24615;&#65292;&#22635;&#34917;&#21644;&#22238;&#24402;&#20219;&#21153;&#20043;&#38388;&#30340;&#22797;&#26434;&#30456;&#20114;&#20381;&#36182;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Missing data is a common issue in real-world datasets. This paper studies the performance of impute-then-regress pipelines by contrasting theoretical and empirical evidence. We establish the asymptotic consistency of such pipelines for a broad family of imputation methods. While common sense suggests that a `good' imputation method produces datasets that are plausible, we show, on the contrary, that, as far as prediction is concerned, crude can be good. Among others, we find that mode-impute is asymptotically sub-optimal, while mean-impute is asymptotically optimal. We then exhaustively assess the validity of these theoretical conclusions on a large corpus of synthetic, semi-real, and real datasets. While the empirical evidence we collect mostly supports our theoretical findings, it also highlights gaps between theory and practice and opportunities for future research, regarding the relevance of the MAR assumption, the complex interdependency between the imputation and regression tasks
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20849;&#20139;&#31070;&#32463;&#20803;&#30340;RBF&#32593;&#32476;&#30340;&#38750;&#21442;&#25968;&#21270;&#27835;&#30103;&#25928;&#24212;&#20272;&#35745;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#22810;&#27835;&#30103;&#35774;&#32622;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#24314;&#27169;&#27835;&#30103;&#32467;&#26524;&#30340;&#20849;&#21516;&#24615;&#65292;&#24182;&#22312;&#36125;&#21494;&#26031;&#26694;&#26550;&#19979;&#23454;&#29616;&#20272;&#35745;&#21644;&#25512;&#26029;&#65292;&#36890;&#36807;&#27169;&#25311;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#25968;&#20540;&#24615;&#33021;&#65292;&#24212;&#29992;&#20110;&#30495;&#23454;&#20020;&#24202;&#25968;&#25454;&#21518;&#20063;&#24471;&#21040;&#20102;&#26377;&#36259;&#30340;&#21457;&#29616;&#12290;</title><link>http://arxiv.org/abs/2401.16571</link><description>&lt;p&gt;
&#20351;&#29992;&#20849;&#20139;&#31070;&#32463;&#20803;&#30340;RBF&#32593;&#32476;&#20272;&#35745;&#20010;&#20307;&#21270;&#22810;&#27835;&#30103;&#21453;&#24212;&#26354;&#32447;
&lt;/p&gt;
&lt;p&gt;
Individualized Multi-Treatment Response Curves Estimation using RBF-net with Shared Neurons. (arXiv:2401.16571v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.16571
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#20849;&#20139;&#31070;&#32463;&#20803;&#30340;RBF&#32593;&#32476;&#30340;&#38750;&#21442;&#25968;&#21270;&#27835;&#30103;&#25928;&#24212;&#20272;&#35745;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#22810;&#27835;&#30103;&#35774;&#32622;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#24314;&#27169;&#27835;&#30103;&#32467;&#26524;&#30340;&#20849;&#21516;&#24615;&#65292;&#24182;&#22312;&#36125;&#21494;&#26031;&#26694;&#26550;&#19979;&#23454;&#29616;&#20272;&#35745;&#21644;&#25512;&#26029;&#65292;&#36890;&#36807;&#27169;&#25311;&#23454;&#39564;&#35777;&#26126;&#20102;&#20854;&#25968;&#20540;&#24615;&#33021;&#65292;&#24212;&#29992;&#20110;&#30495;&#23454;&#20020;&#24202;&#25968;&#25454;&#21518;&#20063;&#24471;&#21040;&#20102;&#26377;&#36259;&#30340;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24322;&#36136;&#27835;&#30103;&#25928;&#24212;&#20272;&#35745;&#26159;&#31934;&#30830;&#21307;&#23398;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#20852;&#36259;&#22312;&#20110;&#22522;&#20110;&#19968;&#20123;&#22806;&#37096;&#21327;&#21464;&#37327;&#65292;&#30830;&#23450;&#19981;&#21516;&#27835;&#30103;&#26041;&#24335;&#30340;&#24046;&#24322;&#25928;&#24212;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38750;&#21442;&#25968;&#21270;&#27835;&#30103;&#25928;&#24212;&#20272;&#35745;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#22810;&#27835;&#30103;&#35774;&#32622;&#12290;&#25105;&#20204;&#23545;&#21709;&#24212;&#26354;&#32447;&#30340;&#38750;&#21442;&#25968;&#24314;&#27169;&#20381;&#36182;&#20110;&#24102;&#26377;&#20849;&#20139;&#38544;&#34255;&#31070;&#32463;&#20803;&#30340;&#24452;&#21521;&#22522;&#20989;&#25968;&#65288;RBF&#65289;&#32593;&#32476;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#26377;&#21161;&#20110;&#24314;&#27169;&#27835;&#30103;&#32467;&#26524;&#30340;&#20849;&#21516;&#24615;&#12290;&#25105;&#20204;&#22312;&#36125;&#21494;&#26031;&#26694;&#26550;&#19979;&#24320;&#21457;&#20102;&#20272;&#35745;&#21644;&#25512;&#26029;&#26041;&#26696;&#65292;&#24182;&#36890;&#36807;&#39640;&#25928;&#30340;&#39532;&#23572;&#31185;&#22827;&#38142;&#33945;&#29305;&#21345;&#32599;&#31639;&#27861;&#36827;&#34892;&#23454;&#29616;&#65292;&#36866;&#24403;&#22320;&#22788;&#29702;&#20102;&#20998;&#26512;&#21508;&#20010;&#26041;&#38754;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#36890;&#36807;&#27169;&#25311;&#23454;&#39564;&#65292;&#23637;&#31034;&#20102;&#35813;&#26041;&#27861;&#30340;&#25968;&#20540;&#24615;&#33021;&#12290;&#23558;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;MIMIC&#25968;&#25454;&#21518;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#20851;&#20110;&#19981;&#21516;&#27835;&#30103;&#31574;&#30053;&#23545;ICU&#20303;&#38498;&#26102;&#38388;&#21644;12&#23567;&#26102;SOFA&#35780;&#20998;&#30340;&#24433;&#21709;&#30340;&#19968;&#20123;&#26377;&#36259;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Heterogeneous treatment effect estimation is an important problem in precision medicine. Specific interests lie in identifying the differential effect of different treatments based on some external covariates. We propose a novel non-parametric treatment effect estimation method in a multi-treatment setting. Our non-parametric modeling of the response curves relies on radial basis function (RBF)-nets with shared hidden neurons. Our model thus facilitates modeling commonality among the treatment outcomes. The estimation and inference schemes are developed under a Bayesian framework and implemented via an efficient Markov chain Monte Carlo algorithm, appropriately accommodating uncertainty in all aspects of the analysis. The numerical performance of the method is demonstrated through simulation experiments. Applying our proposed method to MIMIC data, we obtain several interesting findings related to the impact of different treatment strategies on the length of ICU stay and 12-hour SOFA sc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#22312;&#20915;&#31574;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#23398;&#20064;&#21487;&#34892;&#20915;&#31574;&#30340;&#20998;&#24067;&#65292;&#22312;&#21407;&#22987;&#31354;&#38388;&#21644;&#28508;&#22312;&#31354;&#38388;&#20043;&#38388;&#23454;&#29616;&#20102;&#21452;&#21521;&#26144;&#23556;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#20844;&#20849;&#20915;&#31574;&#21046;&#23450;&#20013;&#30340;&#38544;&#34255;&#32422;&#26463;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.18449</link><description>&lt;p&gt;
&#22522;&#20110;&#28508;&#22312;&#20915;&#31574;&#27169;&#22411;&#30340;&#20855;&#26377;&#38544;&#34255;&#32422;&#26463;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Bayesian Optimization with Hidden Constraints via Latent Decision Models. (arXiv:2310.18449v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.18449
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#22312;&#20915;&#31574;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#21033;&#29992;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#23398;&#20064;&#21487;&#34892;&#20915;&#31574;&#30340;&#20998;&#24067;&#65292;&#22312;&#21407;&#22987;&#31354;&#38388;&#21644;&#28508;&#22312;&#31354;&#38388;&#20043;&#38388;&#23454;&#29616;&#20102;&#21452;&#21521;&#26144;&#23556;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;&#20844;&#20849;&#20915;&#31574;&#21046;&#23450;&#20013;&#30340;&#38544;&#34255;&#32422;&#26463;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;BO&#65289;&#24050;&#32463;&#25104;&#20026;&#35299;&#20915;&#22797;&#26434;&#20915;&#31574;&#38382;&#39064;&#30340;&#24378;&#22823;&#24037;&#20855;&#65292;&#23588;&#20854;&#22312;&#20844;&#20849;&#25919;&#31574;&#39046;&#22495;&#22914;&#35686;&#23519;&#21010;&#21306;&#26041;&#38754;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#23450;&#20041;&#21487;&#34892;&#21306;&#22495;&#30340;&#22797;&#26434;&#24615;&#21644;&#20915;&#31574;&#30340;&#39640;&#32500;&#24230;&#65292;&#20854;&#22312;&#20844;&#20849;&#20915;&#31574;&#21046;&#23450;&#20013;&#30340;&#24191;&#27867;&#24212;&#29992;&#21463;&#21040;&#20102;&#38459;&#30861;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#8212;&#8212;&#38544;&#34255;&#32422;&#26463;&#28508;&#22312;&#31354;&#38388;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;HC-LSBO&#65289;&#65292;&#35813;&#26041;&#27861;&#38598;&#25104;&#20102;&#28508;&#22312;&#20915;&#31574;&#27169;&#22411;&#12290;&#35813;&#26041;&#27861;&#21033;&#29992;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#26469;&#23398;&#20064;&#21487;&#34892;&#20915;&#31574;&#30340;&#20998;&#24067;&#65292;&#23454;&#29616;&#20102;&#21407;&#22987;&#20915;&#31574;&#31354;&#38388;&#19982;&#36739;&#20302;&#32500;&#24230;&#30340;&#28508;&#22312;&#31354;&#38388;&#20043;&#38388;&#30340;&#21452;&#21521;&#26144;&#23556;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#24335;&#65292;HC-LSBO&#25429;&#25417;&#20102;&#20844;&#20849;&#20915;&#31574;&#21046;&#23450;&#20013;&#22266;&#26377;&#30340;&#38544;&#34255;&#32422;&#26463;&#30340;&#32454;&#24494;&#24046;&#21035;&#65292;&#22312;&#28508;&#22312;&#31354;&#38388;&#20013;&#36827;&#34892;&#20248;&#21270;&#30340;&#21516;&#26102;&#65292;&#22312;&#21407;&#22987;&#31354;&#38388;&#20013;&#35780;&#20272;&#30446;&#26631;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#36827;&#34892;&#25968;&#20540;&#23454;&#39564;&#26469;&#39564;&#35777;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#29305;&#21035;&#20851;&#27880;&#22823;&#35268;&#27169;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian optimization (BO) has emerged as a potent tool for addressing intricate decision-making challenges, especially in public policy domains such as police districting. However, its broader application in public policymaking is hindered by the complexity of defining feasible regions and the high-dimensionality of decisions. This paper introduces the Hidden-Constrained Latent Space Bayesian Optimization (HC-LSBO), a novel BO method integrated with a latent decision model. This approach leverages a variational autoencoder to learn the distribution of feasible decisions, enabling a two-way mapping between the original decision space and a lower-dimensional latent space. By doing so, HC-LSBO captures the nuances of hidden constraints inherent in public policymaking, allowing for optimization in the latent space while evaluating objectives in the original space. We validate our method through numerical experiments on both synthetic and real data sets, with a specific focus on large-scal
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#20351;&#29992;&#38543;&#26426;&#25506;&#32034;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#33021;&#22815;&#23454;&#29616;&#26368;&#20339;&#30340;&#35823;&#24046;&#29575;&#21644;&#26368;&#20248;&#36951;&#25022;&#20445;&#35777;&#12290;&#21516;&#26102;&#65292;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#36890;&#36807;&#38543;&#26426;&#25506;&#32034;&#36991;&#20813;&#20102;&#27599;&#27425;&#36845;&#20195;&#20013;&#38750;&#20984;&#33719;&#21462;&#20989;&#25968;&#30340;&#26114;&#36149;&#20248;&#21270;&#65292;&#20855;&#26377;&#35745;&#31639;&#19978;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2310.15351</link><description>&lt;p&gt;
&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#30340;&#38543;&#26426;&#25506;&#32034;&#65306;&#26368;&#20339;&#36951;&#25022;&#21644;&#35745;&#31639;&#25928;&#29575;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Random Exploration in Bayesian Optimization: Order-Optimal Regret and Computational Efficiency. (arXiv:2310.15351v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.15351
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#20351;&#29992;&#38543;&#26426;&#25506;&#32034;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#33021;&#22815;&#23454;&#29616;&#26368;&#20339;&#30340;&#35823;&#24046;&#29575;&#21644;&#26368;&#20248;&#36951;&#25022;&#20445;&#35777;&#12290;&#21516;&#26102;&#65292;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#36890;&#36807;&#38543;&#26426;&#25506;&#32034;&#36991;&#20813;&#20102;&#27599;&#27425;&#36845;&#20195;&#20013;&#38750;&#20984;&#33719;&#21462;&#20989;&#25968;&#30340;&#26114;&#36149;&#20248;&#21270;&#65292;&#20855;&#26377;&#35745;&#31639;&#19978;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#20063;&#31216;&#20026;&#22522;&#20110;&#26680;&#30340;&#36172;&#21338;&#20248;&#21270;&#12290;&#25105;&#20204;&#30740;&#31350;&#20351;&#29992;&#20174;&#20998;&#24067;&#20013;&#38543;&#26426;&#25277;&#26679;&#26469;&#25506;&#32034;&#39046;&#22495;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#31181;&#38543;&#26426;&#25506;&#32034;&#26041;&#27861;&#33021;&#22815;&#23454;&#29616;&#26368;&#20339;&#30340;&#35823;&#24046;&#29575;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#22522;&#20110;&#22312;&#26412;&#30740;&#31350;&#20013;&#24314;&#31435;&#30340;&#26080;&#38480;&#32500;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20013;&#30340;&#26032;&#22411;&#38598;&#20013;&#36793;&#30028;&#65292;&#36825;&#21487;&#33021;&#20855;&#26377;&#29420;&#31435;&#30340;&#24847;&#20041;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#38543;&#26426;&#25506;&#32034;&#21644;&#39046;&#22495;&#32553;&#23567;&#30340;&#31639;&#27861;&#65292;&#24182;&#22312;&#26080;&#22122;&#22768;&#21644;&#26377;&#22122;&#22768;&#29615;&#22659;&#19979;&#24314;&#31435;&#20854;&#26368;&#20339;&#36951;&#25022;&#20445;&#35777;&#12290;&#22312;&#26080;&#22122;&#22768;&#29615;&#22659;&#20013;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#22635;&#34917;&#20102;&#22312;&#36951;&#25022;&#24615;&#33021;&#26041;&#38754;&#23384;&#22312;&#30340;&#24046;&#36317;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;COLT&#20013;&#30340;&#19968;&#20010;&#24320;&#25918;&#38382;&#39064;&#12290;&#30001;&#20110;&#38543;&#26426;&#25506;&#32034;&#28040;&#38500;&#20102;&#27599;&#27425;&#36845;&#20195;&#20013;&#36873;&#25321;&#26597;&#35810;&#28857;&#30340;&#38750;&#20984;&#33719;&#21462;&#20989;&#25968;&#30340;&#26114;&#36149;&#20248;&#21270;&#65292;&#25152;&#20197;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#20063;&#20855;&#26377;&#35745;&#31639;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider Bayesian optimization using Gaussian Process models, also referred to as kernel-based bandit optimization. We study the methodology of exploring the domain using random samples drawn from a distribution. We show that this random exploration approach achieves the optimal error rates. Our analysis is based on novel concentration bounds in an infinite dimensional Hilbert space established in this work, which may be of independent interest. We further develop an algorithm based on random exploration with domain shrinking and establish its order-optimal regret guarantees under both noise-free and noisy settings. In the noise-free setting, our analysis closes the existing gap in regret performance and thereby resolves a COLT open problem. The proposed algorithm also enjoys a computational advantage over prevailing methods due to the random exploration that obviates the expensive optimization of a non-convex acquisition function for choosing the query points at each iteration.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20960;&#20046;&#31561;&#21464;&#24615;&#30340;&#20027;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#19981;&#21516;&#20110;&#29616;&#26377;&#23450;&#20041;&#30340;&#20960;&#20046;&#31561;&#21464;&#24615;&#23450;&#20041;&#65292;&#24182;&#36890;&#36807;&#21033;&#29992;&#26446;&#32676;&#30340;&#26446;&#20195;&#25968;&#32473;&#20986;&#20102;&#22312;&#27169;&#22411;&#20013;&#32534;&#30721;&#20960;&#20046;&#31561;&#21464;&#24615;&#30340;&#23454;&#29992;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.13164</link><description>&lt;p&gt;
&#20960;&#20046;&#31561;&#21464;&#24615;&#36890;&#36807;&#26446;&#20195;&#25968;&#21367;&#31215;
&lt;/p&gt;
&lt;p&gt;
Almost Equivariance via Lie Algebra Convolutions. (arXiv:2310.13164v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.13164
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20960;&#20046;&#31561;&#21464;&#24615;&#30340;&#20027;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#19981;&#21516;&#20110;&#29616;&#26377;&#23450;&#20041;&#30340;&#20960;&#20046;&#31561;&#21464;&#24615;&#23450;&#20041;&#65292;&#24182;&#36890;&#36807;&#21033;&#29992;&#26446;&#32676;&#30340;&#26446;&#20195;&#25968;&#32473;&#20986;&#20102;&#22312;&#27169;&#22411;&#20013;&#32534;&#30721;&#20960;&#20046;&#31561;&#21464;&#24615;&#30340;&#23454;&#29992;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#27169;&#22411;&#30456;&#23545;&#20110;&#32676;&#20316;&#29992;&#30340;&#31561;&#21464;&#24615;&#24050;&#25104;&#20026;&#19968;&#20010;&#37325;&#35201;&#30340;&#30740;&#31350;&#35838;&#39064;&#12290;&#28982;&#32780;&#65292;&#36171;&#20104;&#19968;&#20010;&#26550;&#26500;&#20855;&#20307;&#30340;&#32676;&#31561;&#21464;&#24615;&#23545;&#27169;&#22411;&#25152;&#26399;&#26395;&#30475;&#21040;&#30340;&#25968;&#25454;&#21464;&#25442;&#31867;&#22411;&#26045;&#21152;&#20102;&#24378;&#22823;&#30340;&#20808;&#39564;&#12290;&#20005;&#26684;&#31561;&#21464;&#27169;&#22411;&#24378;&#21046;&#25191;&#34892;&#23545;&#31216;&#24615;&#65292;&#20294;&#30495;&#23454;&#19990;&#30028;&#30340;&#25968;&#25454;&#24182;&#19981;&#24635;&#26159;&#31526;&#21512;&#36825;&#26679;&#30340;&#20005;&#26684;&#31561;&#21464;&#24615;&#65292;&#21487;&#33021;&#26159;&#22240;&#20026;&#25968;&#25454;&#20013;&#30340;&#22122;&#22768;&#25110;&#20165;&#32534;&#30721;&#20102;&#36817;&#20284;&#25110;&#37096;&#20998;&#23545;&#31216;&#24615;&#30340;&#28508;&#22312;&#29289;&#29702;&#23450;&#24459;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#20005;&#26684;&#31561;&#21464;&#24615;&#30340;&#20808;&#39564;&#23454;&#38469;&#19978;&#21487;&#33021;&#36807;&#20110;&#24378;&#22823;&#65292;&#23548;&#33268;&#27169;&#22411;&#22312;&#30495;&#23454;&#25968;&#25454;&#19978;&#34920;&#29616;&#19981;&#20339;&#12290;&#22240;&#27492;&#65292;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#20010;&#30456;&#20851;&#30340;&#20027;&#39064;&#65292;&#21363;&#20960;&#20046;&#31561;&#21464;&#24615;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#19982;&#24403;&#21069;&#25991;&#29486;&#20013;&#29616;&#26377;&#23450;&#20041;&#19981;&#21516;&#30340;&#20960;&#20046;&#31561;&#21464;&#24615;&#23450;&#20041;&#65292;&#24182;&#36890;&#36807;&#21033;&#29992;&#26446;&#32676;&#30340;&#26446;&#20195;&#25968;&#32473;&#20986;&#20102;&#22312;&#27169;&#22411;&#20013;&#32534;&#30721;&#20960;&#20046;&#31561;&#21464;&#24615;&#30340;&#23454;&#29992;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, the equivariance of models with respect to a group action has become an important topic of research in machine learning. However, imbuing an architecture with a specific group equivariance imposes a strong prior on the types of data transformations that the model expects to see. While strictly-equivariant models enforce symmetries, real-world data does not always conform to such strict equivariances, be it due to noise in the data or underlying physical laws that encode only approximate or partial symmetries. In such cases, the prior of strict equivariance can actually prove too strong and cause models to underperform on real-world data. Therefore, in this work we study a closely related topic, that of almost equivariance. We provide a definition of almost equivariance that differs from those extant in the current literature and give a practical method for encoding almost equivariance in models by appealing to the Lie algebra of a Lie group. Specifically, we define Lie algebr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#23384;&#22312;&#31163;&#32447;&#25968;&#25454;&#38598;&#30340;&#24773;&#20917;&#19979;&#65292;&#22914;&#20309;&#22312;&#26080;&#38480;&#26102;&#22495;&#36827;&#34892;&#39640;&#25928;&#30340;&#22312;&#32447;&#23398;&#20064;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#23398;&#20064;&#20195;&#29702;&#27169;&#25311;&#19987;&#23478;&#30340;&#34892;&#20026;&#31574;&#30053;&#33021;&#22815;&#26174;&#33879;&#20943;&#23567;&#32047;&#31215;&#36951;&#25022;&#12290;&#36890;&#36807;&#36125;&#21494;&#26031;&#26041;&#27861;&#36827;&#34892;&#30340;&#20808;&#39564;&#30456;&#20851;&#36951;&#25022;&#20998;&#26512;&#25552;&#20379;&#20102;&#31639;&#27861;&#30340;&#24615;&#33021;&#19978;&#30028;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#20284;&#30340;&#27169;&#20223;&#23398;&#20064;&#31639;&#27861;&#26469;&#32467;&#21512;&#31163;&#32447;&#25968;&#25454;&#38598;&#21644;&#22312;&#32447;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2310.11531</link><description>&lt;p&gt;
&#22312;&#26080;&#38480;&#26102;&#22495;&#30340;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20013;&#65292;&#21033;&#29992;&#31163;&#32447;&#25968;&#25454;&#38598;&#36827;&#34892;&#39640;&#25928;&#22312;&#32447;&#23398;&#20064;&#65306;&#19968;&#31181;&#36125;&#21494;&#26031;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Efficient Online Learning with Offline Datasets for Infinite Horizon MDPs: A Bayesian Approach. (arXiv:2310.11531v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.11531
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#23384;&#22312;&#31163;&#32447;&#25968;&#25454;&#38598;&#30340;&#24773;&#20917;&#19979;&#65292;&#22914;&#20309;&#22312;&#26080;&#38480;&#26102;&#22495;&#36827;&#34892;&#39640;&#25928;&#30340;&#22312;&#32447;&#23398;&#20064;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#23398;&#20064;&#20195;&#29702;&#27169;&#25311;&#19987;&#23478;&#30340;&#34892;&#20026;&#31574;&#30053;&#33021;&#22815;&#26174;&#33879;&#20943;&#23567;&#32047;&#31215;&#36951;&#25022;&#12290;&#36890;&#36807;&#36125;&#21494;&#26031;&#26041;&#27861;&#36827;&#34892;&#30340;&#20808;&#39564;&#30456;&#20851;&#36951;&#25022;&#20998;&#26512;&#25552;&#20379;&#20102;&#31639;&#27861;&#30340;&#24615;&#33021;&#19978;&#30028;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#20284;&#30340;&#27169;&#20223;&#23398;&#20064;&#31639;&#27861;&#26469;&#32467;&#21512;&#31163;&#32447;&#25968;&#25454;&#38598;&#21644;&#22312;&#32447;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24403;&#23384;&#22312;&#19968;&#20010;&#31163;&#32447;&#25968;&#25454;&#38598;&#26102;&#65292;&#22914;&#20309;&#22312;&#26080;&#38480;&#26102;&#22495;&#35774;&#32622;&#19979;&#36827;&#34892;&#39640;&#25928;&#30340;&#22312;&#32447;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#12290;&#25105;&#20204;&#20551;&#35774;&#31163;&#32447;&#25968;&#25454;&#38598;&#26159;&#30001;&#19968;&#20010;&#19987;&#23478;&#29983;&#25104;&#30340;&#65292;&#20294;&#20854;&#33021;&#21147;&#27700;&#24179;&#26410;&#30693;&#65292;&#21363;&#23427;&#19981;&#26159;&#23436;&#32654;&#30340;&#65292;&#20063;&#19981;&#19968;&#23450;&#20351;&#29992;&#26368;&#20248;&#31574;&#30053;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#26524;&#23398;&#20064;&#20195;&#29702;&#27169;&#25311;&#19987;&#23478;&#20351;&#29992;&#30340;&#34892;&#20026;&#31574;&#30053;&#65288;&#30001;&#33021;&#21147;&#21442;&#25968;&#21442;&#25968;&#21270;&#65289;&#65292;&#22312;&#32047;&#31215;&#36951;&#25022;&#26368;&#23567;&#21270;&#26041;&#38754;&#33021;&#21462;&#24471;&#26126;&#26174;&#26356;&#22909;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#20197; $\tilde{O}(\sqrt{T})$ &#20026;&#32553;&#25918;&#30340;&#31934;&#30830;&#26377;&#29992;PSRL&#31639;&#27861;&#36951;&#25022;&#30340;&#19978;&#30028;&#12290;&#36825;&#38656;&#35201;&#23545;&#36125;&#21494;&#26031;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#22312;&#26080;&#38480;&#26102;&#22495;&#35774;&#32622;&#19979;&#36827;&#34892;&#26032;&#39062;&#30340;&#20808;&#39564;&#30456;&#20851;&#36951;&#25022;&#20998;&#26512;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36817;&#20284;&#30340;Informed RLSVI&#31639;&#27861;&#65292;&#21487;&#20197;&#29702;&#35299;&#20026;&#20351;&#29992;&#31163;&#32447;&#25968;&#25454;&#38598;&#36827;&#34892;&#27169;&#20223;&#23398;&#20064;&#65292;&#28982;&#21518;&#36827;&#34892;&#22312;&#32447;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study the problem of efficient online reinforcement learning in the infinite horizon setting when there is an offline dataset to start with. We assume that the offline dataset is generated by an expert but with unknown level of competence, i.e., it is not perfect and not necessarily using the optimal policy. We show that if the learning agent models the behavioral policy (parameterized by a competence parameter) used by the expert, it can do substantially better in terms of minimizing cumulative regret, than if it doesn't do that. We establish an upper bound on regret of the exact informed PSRL algorithm that scales as $\tilde{O}(\sqrt{T})$. This requires a novel prior-dependent regret analysis of Bayesian online learning algorithms for the infinite horizon setting. We then propose an approximate Informed RLSVI algorithm that we can interpret as performing imitation learning with the offline dataset, and then performing online learning.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;&#21518;&#39564;&#37319;&#26679;&#23398;&#20064;&#31639;&#27861;&#22312;&#24207;&#21015;&#21270;POMDPs&#20013;&#30340;&#36951;&#25022;&#24615;&#33021;&#65292;&#24182;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#25552;&#20379;&#20102;&#25913;&#36827;&#30340;&#22810;&#39033;&#24335;&#36125;&#21494;&#26031;&#36951;&#25022;&#30028;&#12290;</title><link>http://arxiv.org/abs/2310.10107</link><description>&lt;p&gt;
&#21518;&#39564;&#37319;&#26679;&#23398;&#20064;&#31639;&#27861;&#22312;&#24207;&#21015;&#21270;POMDPs&#20013;&#30340;&#36951;&#25022;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Regret Analysis of the Posterior Sampling-based Learning Algorithm for Episodic POMDPs. (arXiv:2310.10107v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10107
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#21518;&#39564;&#37319;&#26679;&#23398;&#20064;&#31639;&#27861;&#22312;&#24207;&#21015;&#21270;POMDPs&#20013;&#30340;&#36951;&#25022;&#24615;&#33021;&#65292;&#24182;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#25552;&#20379;&#20102;&#25913;&#36827;&#30340;&#22810;&#39033;&#24335;&#36125;&#21494;&#26031;&#36951;&#25022;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30456;&#27604;&#20110;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDPs&#65289;&#65292;&#37096;&#20998;&#21487;&#35266;&#23519;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;POMDPs&#65289;&#30340;&#23398;&#20064;&#30001;&#20110;&#35266;&#23519;&#25968;&#25454;&#38590;&#20197;&#35299;&#35835;&#32780;&#21464;&#24471;&#26356;&#21152;&#22256;&#38590;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#20855;&#26377;&#26410;&#30693;&#36716;&#31227;&#21644;&#35266;&#27979;&#27169;&#22411;&#30340;POMDPs&#20013;&#30340;&#24207;&#21015;&#21270;&#23398;&#20064;&#38382;&#39064;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#22522;&#20110;&#21518;&#39564;&#37319;&#26679;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65288;PSRL&#65289;&#22312;POMDPs&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#35777;&#26126;&#20854;&#36125;&#21494;&#26031;&#36951;&#25022;&#38543;&#30528;&#24207;&#21015;&#30340;&#25968;&#37327;&#30340;&#24179;&#26041;&#26681;&#32780;&#32553;&#23567;&#12290;&#19968;&#33324;&#26469;&#35828;&#65292;&#36951;&#25022;&#38543;&#30528;&#26102;&#38388;&#38271;&#24230;$H$&#21576;&#25351;&#25968;&#32423;&#22686;&#38271;&#65292;&#24182;&#36890;&#36807;&#25552;&#20379;&#19968;&#20010;&#19979;&#30028;&#35777;&#26126;&#20102;&#36825;&#19968;&#28857;&#12290;&#28982;&#32780;&#65292;&#22312;POMDP&#26159;&#27424;&#23436;&#22791;&#19988;&#24369;&#21487;&#35782;&#21035;&#30340;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#22810;&#39033;&#24335;&#36125;&#21494;&#26031;&#36951;&#25022;&#30028;&#65292;&#30456;&#27604;&#20110;arXiv:2204.08967&#30340;&#26368;&#26032;&#32467;&#26524;&#65292;&#25913;&#36827;&#20102;&#36951;&#25022;&#30028;&#32422;$\Omega(H^2\sqrt{SA})$&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;
Compared to Markov Decision Processes (MDPs), learning in Partially Observable Markov Decision Processes (POMDPs) can be significantly harder due to the difficulty of interpreting observations. In this paper, we consider episodic learning problems in POMDPs with unknown transition and observation models. We consider the Posterior Sampling-based Reinforcement Learning (PSRL) algorithm for POMDPs and show that its Bayesian regret scales as the square root of the number of episodes. In general, the regret scales exponentially with the horizon length $H$, and we show that this is inevitable by providing a lower bound. However, under the condition that the POMDP is undercomplete and weakly revealing, we establish a polynomial Bayesian regret bound that improves the regret bound by a factor of $\Omega(H^2\sqrt{SA})$ over the recent result by arXiv:2204.08967.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#20999;&#21521;&#26680;&#35270;&#35282;&#30340;&#32852;&#37030;&#24179;&#22343;&#26041;&#27861;&#22312;&#28145;&#24230;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#19978;&#30340;&#24212;&#29992;&#65292;&#24182;&#25506;&#35752;&#20102;&#35813;&#26041;&#27861;&#38754;&#20020;&#30340;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2310.05495</link><description>&lt;p&gt;
&#22522;&#20110;&#31070;&#32463;&#20999;&#21521;&#26680;&#30340;&#32852;&#37030;&#24179;&#22343;&#22312;&#28145;&#24230;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#19978;&#30340;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
A Neural Tangent Kernel View on Federated Averaging for Deep Linear Neural Network. (arXiv:2310.05495v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05495
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#20999;&#21521;&#26680;&#35270;&#35282;&#30340;&#32852;&#37030;&#24179;&#22343;&#26041;&#27861;&#22312;&#28145;&#24230;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#19978;&#30340;&#24212;&#29992;&#65292;&#24182;&#25506;&#35752;&#20102;&#35813;&#26041;&#27861;&#38754;&#20020;&#30340;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#24179;&#22343;&#65288;FedAvg&#65289;&#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#33539;&#24335;&#65292;&#29992;&#20110;&#22312;&#19981;&#20849;&#20139;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#21327;&#21516;&#35757;&#32451;&#26469;&#33258;&#20998;&#24067;&#24335;&#23458;&#25143;&#31471;&#30340;&#27169;&#22411;&#12290;&#22914;&#20170;&#65292;&#30001;&#20110;&#20854;&#21331;&#36234;&#24615;&#33021;&#65292;&#31070;&#32463;&#32593;&#32476;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#65292;&#36825;&#20351;&#24471;&#23427;&#25104;&#20026;FedAvg&#20013;&#30340;&#39318;&#36873;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#31070;&#32463;&#32593;&#32476;&#30340;&#20248;&#21270;&#38382;&#39064;&#36890;&#24120;&#26159;&#38750;&#20984;&#30340;&#29978;&#33267;&#26159;&#38750;&#20809;&#28369;&#30340;&#12290;&#27492;&#22806;&#65292;FedAvg&#24635;&#26159;&#28041;&#21450;&#22810;&#20010;&#23458;&#25143;&#31471;&#21644;&#26412;&#22320;&#26356;&#26032;&#65292;&#23548;&#33268;&#19981;&#20934;&#30830;&#30340;&#26356;&#26032;&#26041;&#21521;&#12290;&#36825;&#20123;&#23646;&#24615;&#32473;&#20998;&#26512;FedAvg&#22312;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#25910;&#25947;&#24615;&#24102;&#26469;&#20102;&#22256;&#38590;&#12290;&#26368;&#36817;&#65292;&#31070;&#32463;&#20999;&#21521;&#26680;&#65288;NTK&#65289;&#29702;&#35770;&#24050;&#34987;&#25552;&#20986;&#65292;&#29992;&#20110;&#29702;&#35299;&#35299;&#20915;&#31070;&#32463;&#32593;&#32476;&#38750;&#20984;&#38382;&#39064;&#20013;&#30340;&#19968;&#38454;&#26041;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;&#28145;&#24230;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#26159;&#29702;&#35770;&#23398;&#31185;&#20013;&#30340;&#32463;&#20856;&#27169;&#22411;&#65292;&#30001;&#20110;&#20854;&#31616;&#21333;&#30340;&#20844;&#24335;&#12290;&#28982;&#32780;&#65292;&#22312;&#35757;&#32451;&#28145;&#24230;&#32447;&#24615;&#31070;&#32463;&#32593;&#32476;&#19978;&#65292;&#23545;&#20110;FedAvg&#30340;&#25910;&#25947;&#24615;&#30446;&#21069;&#36824;&#27809;&#26377;&#29702;&#35770;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated averaging (FedAvg) is a widely employed paradigm for collaboratively training models from distributed clients without sharing data. Nowadays, the neural network has achieved remarkable success due to its extraordinary performance, which makes it a preferred choice as the model in FedAvg. However, the optimization problem of the neural network is often non-convex even non-smooth. Furthermore, FedAvg always involves multiple clients and local updates, which results in an inaccurate updating direction. These properties bring difficulties in analyzing the convergence of FedAvg in training neural networks. Recently, neural tangent kernel (NTK) theory has been proposed towards understanding the convergence of first-order methods in tackling the non-convex problem of neural networks. The deep linear neural network is a classical model in theoretical subject due to its simple formulation. Nevertheless, there exists no theoretical result for the convergence of FedAvg in training the d
&lt;/p&gt;</description></item><item><title>&#12298;&#26469;&#33258;&#24425;&#31080;&#31080;&#38598;&#25104;&#30340;&#31070;&#32463;&#35268;&#27169;&#23450;&#24459;&#12299;&#36890;&#36807;&#30740;&#31350;&#31070;&#32463;&#35268;&#27169;&#23450;&#24459;&#29616;&#35937;&#65292;&#21457;&#29616;&#20854;&#19982;&#24425;&#31080;&#31080;&#38598;&#25104;&#26377;&#20851;&#65292;&#20174;&#32780;&#24418;&#25104;&#20102;&#26032;&#30340;&#32553;&#25918;&#23450;&#24459;&#65292;&#20855;&#26377;&#28508;&#22312;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2310.02258</link><description>&lt;p&gt;
&#12298;&#26469;&#33258;&#24425;&#31080;&#31080;&#38598;&#25104;&#30340;&#31070;&#32463;&#35268;&#27169;&#23450;&#24459;&#12299;
&lt;/p&gt;
&lt;p&gt;
A Neural Scaling Law from Lottery Ticket Ensembling. (arXiv:2310.02258v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.02258
&lt;/p&gt;
&lt;p&gt;
&#12298;&#26469;&#33258;&#24425;&#31080;&#31080;&#38598;&#25104;&#30340;&#31070;&#32463;&#35268;&#27169;&#23450;&#24459;&#12299;&#36890;&#36807;&#30740;&#31350;&#31070;&#32463;&#35268;&#27169;&#23450;&#24459;&#29616;&#35937;&#65292;&#21457;&#29616;&#20854;&#19982;&#24425;&#31080;&#31080;&#38598;&#25104;&#26377;&#20851;&#65292;&#20174;&#32780;&#24418;&#25104;&#20102;&#26032;&#30340;&#32553;&#25918;&#23450;&#24459;&#65292;&#20855;&#26377;&#28508;&#22312;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#35268;&#27169;&#23450;&#24459;&#65288;NSL&#65289;&#25351;&#30340;&#26159;&#27169;&#22411;&#24615;&#33021;&#38543;&#30528;&#35268;&#27169;&#22686;&#21152;&#32780;&#25552;&#39640;&#30340;&#29616;&#35937;&#12290;Sharma&#65286;Kaplan&#20351;&#29992;&#36817;&#20284;&#29702;&#35770;&#20998;&#26512;&#20102;NSL&#65292;&#24182;&#39044;&#27979;&#20102;MSE&#25439;&#22833;&#30340;&#34928;&#20943;&#26041;&#24335;&#20026;$N^{-\alpha}$&#65292;&#20854;&#20013;$\alpha=4/d$&#65292;$N$&#20026;&#27169;&#22411;&#21442;&#25968;&#25968;&#37327;&#65292;$d$&#20026;&#20869;&#22312;&#36755;&#20837;&#32500;&#24230;&#12290;&#23613;&#31649;&#20182;&#20204;&#30340;&#29702;&#35770;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#25928;&#26524;&#33391;&#22909;&#65288;&#20363;&#22914;ReLU&#32593;&#32476;&#65289;&#65292;&#20294;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#25105;&#20204;&#21457;&#29616;&#22312;&#31616;&#21333;&#30340;1D&#38382;&#39064;$y=x^2$&#20013;&#65292;&#34920;&#29616;&#20986;&#20102;&#19982;&#20182;&#20204;&#39044;&#27979;&#19981;&#21516;&#30340;&#32553;&#25918;&#23450;&#24459;&#65288;$\alpha=1$&#32780;&#19981;&#26159;$\alpha=4$&#65289;&#12290;&#25105;&#20204;&#25171;&#24320;&#20102;&#31070;&#32463;&#32593;&#32476;&#24182;&#21457;&#29616;&#26032;&#30340;&#32553;&#25918;&#23450;&#24459;&#28304;&#20110;&#24425;&#31080;&#31080;&#38598;&#25104;&#65306;&#24179;&#22343;&#32780;&#35328;&#65292;&#26356;&#23485;&#30340;&#32593;&#32476;&#26377;&#26356;&#22810;&#30340;&#8220;&#24425;&#31080;&#31080;&#8221;&#65292;&#23427;&#20204;&#34987;&#38598;&#25104;&#26469;&#20943;&#23567;&#36755;&#20986;&#30340;&#26041;&#24046;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#21333;&#20010;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#26426;&#26800;&#35299;&#37322;&#20197;&#21450;&#23545;&#23427;&#20204;&#36827;&#34892;&#32479;&#35745;&#30740;&#31350;&#26469;&#25903;&#25345;&#38598;&#25104;&#26426;&#21046;&#12290;&#25105;&#20204;&#23558;$N^{-1}$&#30340;&#32553;&#25918;&#23450;&#24459;&#24402;&#22240;&#20110;&#8220;&#24425;&#31080;&#31080;&#30340;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#8221;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#23427;&#30340;&#28508;&#22312;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural scaling laws (NSL) refer to the phenomenon where model performance improves with scale. Sharma &amp; Kaplan analyzed NSL using approximation theory and predict that MSE losses decay as $N^{-\alpha}$, $\alpha=4/d$, where $N$ is the number of model parameters, and $d$ is the intrinsic input dimension. Although their theory works well for some cases (e.g., ReLU networks), we surprisingly find that a simple 1D problem $y=x^2$ manifests a different scaling law ($\alpha=1$) from their predictions ($\alpha=4$). We opened the neural networks and found that the new scaling law originates from lottery ticket ensembling: a wider network on average has more "lottery tickets", which are ensembled to reduce the variance of outputs. We support the ensembling mechanism by mechanistically interpreting single neural networks, as well as studying them statistically. We attribute the $N^{-1}$ scaling law to the "central limit theorem" of lottery tickets. Finally, we discuss its potential implications f
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#22312;&#22270;&#25299;&#25169;&#30340;&#22270;&#28857;&#36807;&#31243;&#26041;&#27861;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#28145;&#24230;&#22270;&#26680;&#26469;&#25551;&#36848;&#20107;&#20214;&#20043;&#38388;&#30340;&#35302;&#21457;&#21644;&#25233;&#21046;&#25928;&#24212;&#65292;&#35813;&#26041;&#27861;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#20855;&#26377;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.11313</link><description>&lt;p&gt;
&#28145;&#24230;&#22270;&#26680;&#28857;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Deep graph kernel point processes. (arXiv:2306.11313v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11313
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#22312;&#22270;&#25299;&#25169;&#30340;&#22270;&#28857;&#36807;&#31243;&#26041;&#27861;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#28145;&#24230;&#22270;&#26680;&#26469;&#25551;&#36848;&#20107;&#20214;&#20043;&#38388;&#30340;&#35302;&#21457;&#21644;&#25233;&#21046;&#25928;&#24212;&#65292;&#35813;&#26041;&#27861;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#20855;&#26377;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28857;&#36807;&#31243;&#27169;&#22411;&#24191;&#27867;&#29992;&#20110;&#20998;&#26512;&#22270;&#20013;&#24322;&#27493;&#20107;&#20214;&#65292;&#21453;&#26144;&#19981;&#21516;&#31867;&#22411;&#20107;&#20214;&#20043;&#38388;&#30340;&#30456;&#20114;&#24433;&#21709;&#12290;&#39044;&#27979;&#26410;&#26469;&#20107;&#20214;&#30340;&#26102;&#38388;&#21644;&#31867;&#22411;&#26159;&#19968;&#39033;&#20851;&#38190;&#20219;&#21153;&#65292;&#24182;&#19988;&#22270;&#30340;&#22823;&#23567;&#21644;&#25299;&#25169;&#32467;&#26500;&#22686;&#21152;&#20102;&#38382;&#39064;&#30340;&#38590;&#24230;&#12290;&#26368;&#36817;&#30340;&#31070;&#32463;&#28857;&#36807;&#31243;&#27169;&#22411;&#25581;&#31034;&#20102;&#25429;&#25417;&#22797;&#26434;&#30340;&#20107;&#20214;&#31867;&#21035;&#20043;&#38388;&#20381;&#36182;&#20851;&#31995;&#30340;&#21487;&#33021;&#24615;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#27599;&#20010;&#30446;&#26631;&#20107;&#20214;&#31867;&#22411;&#30340;&#24378;&#24230;&#35745;&#31639;&#20013;&#20351;&#29992;&#20102;&#21253;&#25324;&#25152;&#26377;&#20107;&#20214;&#31867;&#21035;&#22312;&#20869;&#30340;&#26410;&#32463;&#28388;&#27874;&#30340;&#20107;&#20214;&#35760;&#24405;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28508;&#22312;&#22270;&#25299;&#25169;&#30340;&#22270;&#28857;&#36807;&#31243;&#26041;&#27861;&#12290;&#23545;&#24212;&#30340;&#26080;&#21521;&#22270;&#20855;&#26377;&#20195;&#34920;&#20107;&#20214;&#31867;&#21035;&#30340;&#33410;&#28857;&#21644;&#34920;&#31034;&#28508;&#22312;&#36129;&#29486;&#20851;&#31995;&#30340;&#36793;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#28145;&#24230;&#22270;&#26680;&#26469;&#25551;&#36848;&#20107;&#20214;&#20043;&#38388;&#30340;&#35302;&#21457;&#21644;&#25233;&#21046;&#25928;&#24212;&#12290;&#26412;&#36136;&#24433;&#21709;&#32467;&#26500;&#36890;&#36807;&#22270;&#31070;&#32463;&#32593;&#32476;-based&#30340;&#23616;&#37096;&#37051;&#22495;&#20449;&#24687;&#32858;&#21512;&#36827;&#34892;&#20102;&#34701;&#21512;&#12290;&#25105;&#20204;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#27604;&#26368;&#20808;&#36827;&#30340;&#27169;&#22411;&#26356;&#20855;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Point process models are widely used to analyze asynchronous events occurring within a graph that reflect how different types of events influence one another. Predicting future events' times and types is a crucial task, and the size and topology of the graph add to the challenge of the problem. Recent neural point process models unveil the possibility of capturing intricate inter-event-category dependencies. However, such methods utilize an unfiltered history of events, including all event categories in the intensity computation for each target event type. In this work, we propose a graph point process method where event interactions occur based on a latent graph topology. The corresponding undirected graph has nodes representing event categories and edges indicating potential contribution relationships. We then develop a novel deep graph kernel to characterize the triggering and inhibiting effects between events. The intrinsic influence structures are incorporated via the graph neural
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#23616;&#37096;&#32447;&#24615;&#27169;&#22411;&#23454;&#29616;&#30446;&#26631;&#21644;&#31890;&#23376;&#20998;&#24067;KL&#25955;&#24230;&#38477;&#20302;&#30340;&#26032;&#20272;&#35745;&#22120;&#65292;&#21487;&#20197;&#20351;&#29992;&#26679;&#26412;&#36827;&#34892;&#35745;&#31639;&#32780;&#19981;&#38656;&#35201;&#30446;&#26631;&#24471;&#20998;&#20989;&#25968;&#65292;&#20855;&#26377;&#27604;SVGD&#26356;&#31616;&#21333;&#26377;&#25928;&#30340;&#35745;&#31639;&#26041;&#27861;&#65292;&#23545;&#20110;&#39640;&#32500;&#24230;&#24773;&#20917;&#19979;&#30340;&#27169;&#22411;&#20063;&#26377;&#20248;&#21270;&#65292;&#25552;&#21319;&#20272;&#35745;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2305.15577</link><description>&lt;p&gt;
&#37319;&#29992;&#23616;&#37096;&#32447;&#24615;&#27169;&#22411;&#30340;&#21464;&#20998;&#26799;&#24230;&#19979;&#38477;
&lt;/p&gt;
&lt;p&gt;
Variational Gradient Descent using Local Linear Models. (arXiv:2305.15577v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15577
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#23616;&#37096;&#32447;&#24615;&#27169;&#22411;&#23454;&#29616;&#30446;&#26631;&#21644;&#31890;&#23376;&#20998;&#24067;KL&#25955;&#24230;&#38477;&#20302;&#30340;&#26032;&#20272;&#35745;&#22120;&#65292;&#21487;&#20197;&#20351;&#29992;&#26679;&#26412;&#36827;&#34892;&#35745;&#31639;&#32780;&#19981;&#38656;&#35201;&#30446;&#26631;&#24471;&#20998;&#20989;&#25968;&#65292;&#20855;&#26377;&#27604;SVGD&#26356;&#31616;&#21333;&#26377;&#25928;&#30340;&#35745;&#31639;&#26041;&#27861;&#65292;&#23545;&#20110;&#39640;&#32500;&#24230;&#24773;&#20917;&#19979;&#30340;&#27169;&#22411;&#20063;&#26377;&#20248;&#21270;&#65292;&#25552;&#21319;&#20272;&#35745;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Stein Variational Gradient Descent (SVGD) &#33021;&#22815;&#27839;&#30528;&#36712;&#36857;&#20256;&#36755;&#31890;&#23376;&#65292;&#20174;&#32780;&#20943;&#23569;&#30446;&#26631;&#21644;&#31890;&#23376;&#20998;&#24067;&#20043;&#38388;&#30340;KL&#25955;&#24230;&#65292;&#20294;&#38656;&#35201;&#30446;&#26631;&#24471;&#20998;&#20989;&#25968;&#26469;&#35745;&#31639;&#26356;&#26032;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;SVGD&#35270;&#35282;&#65292;&#23558;&#20854;&#35270;&#20026;&#21453;&#21521;KL&#26799;&#24230;&#27969;&#30340;&#23616;&#37096;&#20272;&#35745;&#22120;&#12290;&#36825;&#31181;&#35270;&#35282;&#21551;&#21457;&#25105;&#20204;&#25552;&#20986;&#20102;&#20351;&#29992;&#23616;&#37096;&#32447;&#24615;&#27169;&#22411;&#26469;&#23454;&#29616;&#30456;&#21516;&#30446;&#30340;&#30340;&#26032;&#20272;&#35745;&#22120;&#12290;&#36825;&#20123;&#25552;&#35758;&#30340;&#20272;&#35745;&#22120;&#21487;&#20197;&#20165;&#20351;&#29992;&#30446;&#26631;&#21644;&#31890;&#23376;&#20998;&#24067;&#30340;&#26679;&#26412;&#36827;&#34892;&#35745;&#31639;&#65292;&#32780;&#19981;&#38656;&#35201;&#30446;&#26631;&#24471;&#20998;&#20989;&#25968;&#12290;&#25105;&#20204;&#25552;&#35758;&#30340;&#21464;&#20998;&#26799;&#24230;&#20272;&#35745;&#22120;&#21033;&#29992;&#20102;&#23616;&#37096;&#32447;&#24615;&#27169;&#22411;&#65292;&#20174;&#32780;&#22312;&#20445;&#25345;&#20272;&#35745;&#20559;&#24046;&#19982;SVGD&#30456;&#24403;&#30340;&#25928;&#26524;&#30340;&#21516;&#26102;&#20855;&#26377;&#35745;&#31639;&#31616;&#20415;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#28201;&#21644;&#30340;&#20551;&#35774;&#19979;&#65292;&#39640;&#32500;&#26799;&#24230;&#27969;&#30340;&#20272;&#35745;&#21487;&#20197;&#36716;&#21270;&#20026;&#19968;&#20010;&#20302;&#32500;&#20272;&#35745;&#38382;&#39064;&#65292;&#20174;&#32780;&#23548;&#33268;&#26356;&#22909;&#30340;&#20272;&#35745;&#31934;&#24230;&#12290;&#25105;&#20204;&#23545;&#25552;&#35758;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#39564;&#35777;&#65292;&#24182;&#23545;&#20854;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stein Variational Gradient Descent (SVGD) can transport particles along trajectories that reduce the KL divergence between the target and particle distribution but requires the target score function to compute the update. We introduce a new perspective on SVGD that views it as a local estimator of the reversed KL gradient flow. This perspective inspires us to propose new estimators that use local linear models to achieve the same purpose. The proposed estimators can be computed using only samples from the target and particle distribution without needing the target score function. Our proposed variational gradient estimators utilize local linear models, resulting in computational simplicity while maintaining effectiveness comparable to SVGD in terms of estimation biases. Additionally, we demonstrate that under a mild assumption, the estimation of high-dimensional gradient flow can be translated into a lower-dimensional estimation problem, leading to improved estimation accuracy. We vali
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20010;&#20154;&#21487;&#20197;&#36873;&#25321;&#19982;&#20915;&#31574;&#31995;&#32479;&#20849;&#20139;&#21487;&#36873;&#20010;&#20154;&#20449;&#24687;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#20445;&#25252;&#29992;&#25143;&#21516;&#24847;&#30340;PUC&#27010;&#24565;&#65292;&#20026;&#29992;&#25143;&#38544;&#31169;&#20445;&#25252;&#25552;&#20379;&#20102;&#26377;&#21147;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2210.13954</link><description>&lt;p&gt;
&#25105;&#19981;&#24819;&#35828;&#65306;&#22312;&#21487;&#36873;&#20010;&#20154;&#25968;&#25454;&#27169;&#22411;&#20013;&#20445;&#25252;&#29992;&#25143;&#21516;&#24847;
&lt;/p&gt;
&lt;p&gt;
I Prefer not to Say: Protecting User Consent in Models with Optional Personal Data. (arXiv:2210.13954v4 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.13954
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#20010;&#20154;&#21487;&#20197;&#36873;&#25321;&#19982;&#20915;&#31574;&#31995;&#32479;&#20849;&#20139;&#21487;&#36873;&#20010;&#20154;&#20449;&#24687;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#24182;&#25552;&#20986;&#20102;&#20445;&#25252;&#29992;&#25143;&#21516;&#24847;&#30340;PUC&#27010;&#24565;&#65292;&#20026;&#29992;&#25143;&#38544;&#31169;&#20445;&#25252;&#25552;&#20379;&#20102;&#26377;&#21147;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#20854;&#20013;&#20010;&#20154;&#21487;&#20197;&#36873;&#25321;&#19982;&#20915;&#31574;&#31995;&#32479;&#20849;&#20139;&#21487;&#36873;&#20010;&#20154;&#20449;&#24687;&#65292;&#36825;&#22312;&#29616;&#20195;&#20445;&#38505;&#23450;&#20215;&#27169;&#22411;&#20013;&#24456;&#24120;&#35265;&#12290;&#19968;&#20123;&#29992;&#25143;&#21516;&#24847;&#20351;&#29992;&#20182;&#20204;&#30340;&#25968;&#25454;&#65292;&#32780;&#20854;&#20182;&#20154;&#21017;&#21453;&#23545;&#24182;&#20445;&#25345;&#20854;&#25968;&#25454;&#26410;&#20844;&#24320;&#12290;&#26412;&#25991;&#34920;&#26126;&#65292;&#19981;&#20849;&#20139;&#25968;&#25454;&#30340;&#20915;&#23450;&#26412;&#36523;&#21487;&#20197;&#34987;&#35270;&#20026;&#20449;&#24687;&#65292;&#24212;&#35813;&#21463;&#21040;&#20445;&#25252;&#65292;&#20197;&#23562;&#37325;&#29992;&#25143;&#30340;&#38544;&#31169;&#12290;&#36825;&#19968;&#35266;&#23519;&#32467;&#26524;&#24341;&#21457;&#20102;&#19968;&#20010;&#34987;&#24573;&#35270;&#30340;&#38382;&#39064;&#65292;&#21363;&#22914;&#20309;&#30830;&#20445;&#20445;&#25252;&#20854;&#20010;&#20154;&#25968;&#25454;&#30340;&#29992;&#25143;&#19981;&#20250;&#22240;&#27492;&#21463;&#21040;&#20219;&#20309;&#19981;&#21033;&#24433;&#21709;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#23545;&#20165;&#20351;&#29992;&#33719;&#24471;&#31215;&#26497;&#29992;&#25143;&#21516;&#24847;&#30340;&#20449;&#24687;&#30340;&#27169;&#22411;&#36827;&#34892;&#20102;&#20445;&#25252;&#35201;&#27714;&#30340;&#27491;&#24335;&#21270;&#12290;&#36825;&#25490;&#38500;&#20102;&#20316;&#20986;&#20849;&#20139;&#25968;&#25454;&#19982;&#21542;&#20915;&#23450;&#25152;&#21253;&#21547;&#30340;&#38544;&#21547;&#20449;&#24687;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;Protected User Consent (PUC)&#27010;&#24565;&#65292;&#36825;&#26159;&#25105;&#20204;&#35777;&#26126;&#22312;&#20445;&#25252;&#35201;&#27714;&#19979;&#25439;&#22833;&#26368;&#23567;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
We examine machine learning models in a setup where individuals have the choice to share optional personal information with a decision-making system, as seen in modern insurance pricing models. Some users consent to their data being used whereas others object and keep their data undisclosed. In this work, we show that the decision not to share data can be considered as information in itself that should be protected to respect users' privacy. This observation raises the overlooked problem of how to ensure that users who protect their personal data do not suffer any disadvantages as a result. To address this problem, we formalize protection requirements for models which only use the information for which active user consent was obtained. This excludes implicit information contained in the decision to share data or not. We offer the first solution to this problem by proposing the notion of Protected User Consent (PUC), which we prove to be loss-optimal under our protection requirement. To
&lt;/p&gt;</description></item></channel></rss>