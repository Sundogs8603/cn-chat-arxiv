<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;Tukey&#28145;&#24230;&#30340;&#38543;&#26426;&#36817;&#20284;&#36136;&#37327;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#22312;&#32500;&#24230;&#36739;&#39640;&#19988;&#25968;&#25454;&#20174;&#23545;&#25968;&#20985;&#38598;&#30340;&#22343;&#21248;&#20998;&#24067;&#20013;&#25277;&#26679;&#30340;&#24773;&#20917;&#19979;&#65292;&#38543;&#26426;&#31639;&#27861;&#21487;&#20197;&#27491;&#30830;&#36817;&#20284;&#26368;&#22823;&#28145;&#24230;&#21644;&#25509;&#36817;&#38646;&#30340;&#28145;&#24230;&#65292;&#32780;&#23545;&#20110;&#20013;&#38388;&#28145;&#24230;&#30340;&#28857;&#65292;&#20219;&#20309;&#22909;&#30340;&#36817;&#20284;&#37117;&#38656;&#35201;&#25351;&#25968;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2309.05657</link><description>&lt;p&gt;
&#20851;&#20110;Tukey&#28145;&#24230;&#30340;&#38543;&#26426;&#36817;&#20284;&#36136;&#37327;
&lt;/p&gt;
&lt;p&gt;
On the quality of randomized approximations of Tukey's depth. (arXiv:2309.05657v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05657
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;Tukey&#28145;&#24230;&#30340;&#38543;&#26426;&#36817;&#20284;&#36136;&#37327;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#22312;&#32500;&#24230;&#36739;&#39640;&#19988;&#25968;&#25454;&#20174;&#23545;&#25968;&#20985;&#38598;&#30340;&#22343;&#21248;&#20998;&#24067;&#20013;&#25277;&#26679;&#30340;&#24773;&#20917;&#19979;&#65292;&#38543;&#26426;&#31639;&#27861;&#21487;&#20197;&#27491;&#30830;&#36817;&#20284;&#26368;&#22823;&#28145;&#24230;&#21644;&#25509;&#36817;&#38646;&#30340;&#28145;&#24230;&#65292;&#32780;&#23545;&#20110;&#20013;&#38388;&#28145;&#24230;&#30340;&#28857;&#65292;&#20219;&#20309;&#22909;&#30340;&#36817;&#20284;&#37117;&#38656;&#35201;&#25351;&#25968;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Tukey&#28145;&#24230;&#65288;&#25110;&#21322;&#31354;&#38388;&#28145;&#24230;&#65289;&#26159;&#29992;&#20110;&#22810;&#20803;&#25968;&#25454;&#20013;&#24515;&#24230;&#37327;&#30340;&#24191;&#27867;&#24212;&#29992;&#30340;&#25351;&#26631;&#12290;&#28982;&#32780;&#65292;&#22312;&#39640;&#32500;&#24230;&#19979;&#65292;Tukey&#28145;&#24230;&#30340;&#31934;&#30830;&#35745;&#31639;&#34987;&#35748;&#20026;&#26159;&#19968;&#20010;&#22256;&#38590;&#30340;&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20154;&#20204;&#25552;&#20986;&#20102;Tukey&#28145;&#24230;&#30340;&#38543;&#26426;&#36817;&#20284;&#26041;&#27861;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#36825;&#26679;&#30340;&#38543;&#26426;&#31639;&#27861;&#20309;&#26102;&#33021;&#22815;&#36820;&#22238;&#19968;&#20010;&#33391;&#22909;&#30340;Tukey&#28145;&#24230;&#36817;&#20284;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#25968;&#25454;&#20174;&#23545;&#25968;&#20985;&#38519;&#22343;&#21248;&#20998;&#24067;&#20013;&#25277;&#26679;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#65292;&#22914;&#26524;&#35201;&#27714;&#31639;&#27861;&#22312;&#32500;&#24230;&#19978;&#20197;&#22810;&#39033;&#24335;&#26102;&#38388;&#36816;&#34892;&#65292;&#38543;&#26426;&#31639;&#27861;&#21487;&#20197;&#27491;&#30830;&#22320;&#36817;&#20284;&#26368;&#22823;&#28145;&#24230;1/2&#21644;&#25509;&#36817;&#38646;&#30340;&#28145;&#24230;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#23545;&#20110;&#20219;&#20309;&#20013;&#38388;&#28145;&#24230;&#30340;&#28857;&#65292;&#20219;&#20309;&#22909;&#30340;&#36817;&#20284;&#37117;&#38656;&#35201;&#25351;&#25968;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tukey's depth (or halfspace depth) is a widely used measure of centrality for multivariate data. However, exact computation of Tukey's depth is known to be a hard problem in high dimensions. As a remedy, randomized approximations of Tukey's depth have been proposed. In this paper we explore when such randomized algorithms return a good approximation of Tukey's depth. We study the case when the data are sampled from a log-concave isotropic distribution. We prove that, if one requires that the algorithm runs in polynomial time in the dimension, the randomized algorithm correctly approximates the maximal depth $1/2$ and depths close to zero. On the other hand, for any point of intermediate depth, any good approximation requires exponential complexity.
&lt;/p&gt;</description></item><item><title>&#19968;&#31867;&#36793;&#30028;&#21093;&#31163;&#26159;&#19968;&#31181;&#26080;&#30417;&#30563;&#30340;&#24322;&#24120;&#26816;&#27979;&#31639;&#27861;&#65292;&#20351;&#29992;&#20102;&#24179;&#22343;&#26377;&#31526;&#21495;&#36317;&#31163;&#21644;&#28789;&#27963;&#30340;&#36793;&#30028;&#29983;&#25104;&#26041;&#27861;&#12290;&#22312;&#26080;&#24322;&#24120;&#20540;&#21644;&#26377;&#24322;&#24120;&#20540;&#30340;&#24773;&#20917;&#19979;&#65292;&#19968;&#31867;&#36793;&#30028;&#21093;&#31163;&#34920;&#29616;&#20986;&#20248;&#36234;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.05630</link><description>&lt;p&gt;
&#36793;&#30028;&#21093;&#31163;&#65306;&#20351;&#29992;&#19968;&#31867;&#21093;&#31163;&#30340;&#24322;&#24120;&#26816;&#27979;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Boundary Peeling: Outlier Detection Method Using One-Class Peeling. (arXiv:2309.05630v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05630
&lt;/p&gt;
&lt;p&gt;
&#19968;&#31867;&#36793;&#30028;&#21093;&#31163;&#26159;&#19968;&#31181;&#26080;&#30417;&#30563;&#30340;&#24322;&#24120;&#26816;&#27979;&#31639;&#27861;&#65292;&#20351;&#29992;&#20102;&#24179;&#22343;&#26377;&#31526;&#21495;&#36317;&#31163;&#21644;&#28789;&#27963;&#30340;&#36793;&#30028;&#29983;&#25104;&#26041;&#27861;&#12290;&#22312;&#26080;&#24322;&#24120;&#20540;&#21644;&#26377;&#24322;&#24120;&#20540;&#30340;&#24773;&#20917;&#19979;&#65292;&#19968;&#31867;&#36793;&#30028;&#21093;&#31163;&#34920;&#29616;&#20986;&#20248;&#36234;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#30417;&#30563;&#24322;&#24120;&#26816;&#27979;&#22312;&#25968;&#25454;&#20998;&#26512;&#20013;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#38454;&#27573;&#65292;&#20173;&#28982;&#26159;&#19968;&#20010;&#20805;&#28385;&#27963;&#21147;&#30340;&#30740;&#31350;&#39046;&#22495;&#12290;&#19968;&#20010;&#22909;&#30340;&#24322;&#24120;&#26816;&#27979;&#31639;&#27861;&#24212;&#35813;&#20855;&#22791;&#35745;&#31639;&#25928;&#29575;&#39640;&#12289;&#23545;&#35843;&#21442;&#36873;&#25321;&#40065;&#26834;&#12289;&#22312;&#19981;&#21516;&#30340;&#25968;&#25454;&#20998;&#24067;&#19979;&#34920;&#29616;&#31283;&#23450;&#31561;&#29305;&#28857;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31867;&#36793;&#30028;&#21093;&#31163;&#65292;&#19968;&#31181;&#26080;&#30417;&#30563;&#24322;&#24120;&#26816;&#27979;&#31639;&#27861;&#12290;&#19968;&#31867;&#36793;&#30028;&#21093;&#31163;&#20351;&#29992;&#20102;&#19968;&#31867;&#25903;&#25345;&#21521;&#37327;&#26426;&#19981;&#26029;&#21093;&#31163;&#30340;&#12289;&#28789;&#27963;&#30340;&#36793;&#30028;&#29983;&#25104;&#30340;&#24179;&#22343;&#26377;&#31526;&#21495;&#36317;&#31163;&#12290;&#19968;&#31867;&#36793;&#30028;&#21093;&#31163;&#20855;&#26377;&#40065;&#26834;&#30340;&#36229;&#21442;&#25968;&#35774;&#32622;&#65292;&#24182;&#19988;&#20026;&#20102;&#22686;&#21152;&#28789;&#27963;&#24615;&#65292;&#21487;&#20197;&#34987;&#30475;&#20316;&#26159;&#19968;&#20010;&#38598;&#25104;&#26041;&#27861;&#12290;&#22312;&#21512;&#25104;&#25968;&#25454;&#27169;&#25311;&#20013;&#65292;&#19968;&#31867;&#36793;&#30028;&#21093;&#31163;&#22312;&#27809;&#26377;&#24322;&#24120;&#20540;&#30340;&#24773;&#20917;&#19979;&#20248;&#20110;&#25152;&#26377;&#20808;&#36827;&#26041;&#27861;&#65292;&#24182;&#19988;&#22312;&#26377;&#24322;&#24120;&#20540;&#23384;&#22312;&#30340;&#24773;&#20917;&#19979;&#65292;&#19982;&#22522;&#20934;&#26041;&#27861;&#30456;&#27604;&#65292;&#22312;&#27491;&#30830;&#20998;&#31867;&#26041;&#38754;&#34920;&#29616;&#20986;&#21487;&#27604;&#25110;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Unsupervised outlier detection constitutes a crucial phase within data analysis and remains a dynamic realm of research. A good outlier detection algorithm should be computationally efficient, robust to tuning parameter selection, and perform consistently well across diverse underlying data distributions. We introduce One-Class Boundary Peeling, an unsupervised outlier detection algorithm. One-class Boundary Peeling uses the average signed distance from iteratively-peeled, flexible boundaries generated by one-class support vector machines. One-class Boundary Peeling has robust hyperparameter settings and, for increased flexibility, can be cast as an ensemble method. In synthetic data simulations One-Class Boundary Peeling outperforms all state of the art methods when no outliers are present while maintaining comparable or superior performance in the presence of outliers, as compared to benchmark methods. One-Class Boundary Peeling performs competitively in terms of correct classificati
&lt;/p&gt;</description></item><item><title>&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#37325;&#22797;&#21442;&#25968;&#20849;&#20139;&#20250;&#27844;&#38706;&#31169;&#20154;&#25968;&#25454;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#34920;&#31034;&#32852;&#37030;&#23398;&#20064;&#30446;&#26631;&#65292;&#26088;&#22312;&#22312;&#20445;&#38556;&#24046;&#20998;&#38544;&#31169;&#30340;&#21516;&#26102;&#20801;&#35768;&#26412;&#22320;&#20010;&#24615;&#21270;&#65292;&#36890;&#36807;&#25552;&#20986;&#30340;&#26032;&#31639;&#27861;DPFEDREP&#65292;&#21487;&#20197;&#22312;&#32447;&#24615;&#34920;&#31034;&#35774;&#32622;&#20013;&#25910;&#25947;&#21040;&#20197;&#20840;&#23616;&#20026;&#20013;&#24515;&#30340;&#29699;&#24418;&#21306;&#22495;&#12290;</title><link>http://arxiv.org/abs/2309.05505</link><description>&lt;p&gt;
&#20998;&#20139;&#20320;&#30340;&#34920;&#31034;&#65306;&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#20445;&#35777;&#38544;&#31169;&#21644;&#25928;&#29992;&#30340;&#26435;&#34913;&#30340;&#25913;&#21892;
&lt;/p&gt;
&lt;p&gt;
Share Your Representation Only: Guaranteed Improvement of the Privacy-Utility Tradeoff in Federated Learning. (arXiv:2309.05505v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05505
&lt;/p&gt;
&lt;p&gt;
&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#37325;&#22797;&#21442;&#25968;&#20849;&#20139;&#20250;&#27844;&#38706;&#31169;&#20154;&#25968;&#25454;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#34920;&#31034;&#32852;&#37030;&#23398;&#20064;&#30446;&#26631;&#65292;&#26088;&#22312;&#22312;&#20445;&#38556;&#24046;&#20998;&#38544;&#31169;&#30340;&#21516;&#26102;&#20801;&#35768;&#26412;&#22320;&#20010;&#24615;&#21270;&#65292;&#36890;&#36807;&#25552;&#20986;&#30340;&#26032;&#31639;&#27861;DPFEDREP&#65292;&#21487;&#20197;&#22312;&#32447;&#24615;&#34920;&#31034;&#35774;&#32622;&#20013;&#25910;&#25947;&#21040;&#20197;&#20840;&#23616;&#20026;&#20013;&#24515;&#30340;&#29699;&#24418;&#21306;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32852;&#37030;&#23398;&#20064;&#20013;&#37325;&#22797;&#21442;&#25968;&#20849;&#20139;&#20250;&#23548;&#33268;&#31169;&#20154;&#25968;&#25454;&#30340;&#26174;&#33879;&#20449;&#24687;&#27844;&#38706;&#65292;&#20174;&#32780;&#36829;&#32972;&#20102;&#25968;&#25454;&#38544;&#31169;&#30340;&#20027;&#35201;&#30446;&#30340;&#12290;&#23613;&#31649;&#20351;&#29992;&#26368;&#20808;&#36827;&#30340;&#24046;&#20998;&#38544;&#31169;&#31639;&#27861;&#21487;&#20197;&#20943;&#36731;&#20449;&#24687;&#27844;&#38706;&#30340;&#39118;&#38505;&#65292;&#20294;&#36825;&#24182;&#38750;&#27809;&#26377;&#20195;&#20215;&#12290;&#38543;&#26426;&#21270;&#26426;&#21046;&#21487;&#33021;&#20250;&#38459;&#27490;&#27169;&#22411;&#23545;&#26377;&#29992;&#30340;&#34920;&#31034;&#20989;&#25968;&#30340;&#23398;&#20064;&#25910;&#25947;&#65292;&#23588;&#20854;&#26159;&#24403;&#26412;&#22320;&#27169;&#22411;&#20043;&#38388;&#22312;&#20998;&#31867;&#20989;&#25968;&#19978;&#23384;&#22312;&#26356;&#22823;&#30340;&#19981;&#19968;&#33268;&#24615;&#26102;&#65288;&#30001;&#20110;&#25968;&#25454;&#24322;&#26500;&#24615;&#65289;&#12290;&#26412;&#25991;&#32771;&#34385;&#19968;&#31181;&#34920;&#31034;&#32852;&#37030;&#23398;&#20064;&#30446;&#26631;&#65292;&#40723;&#21169;&#21508;&#26041;&#22312;&#20445;&#38556;&#24046;&#20998;&#38544;&#31169;&#30340;&#21516;&#26102;&#20849;&#21516;&#25913;&#36827;&#27169;&#22411;&#30340;&#20849;&#35782;&#37096;&#20998;&#65292;&#24182;&#19988;&#21333;&#29420;&#20801;&#35768;&#36275;&#22815;&#30340;&#33258;&#30001;&#36827;&#34892;&#26412;&#22320;&#20010;&#24615;&#21270;&#65288;&#26080;&#38656;&#20849;&#20139;&#65289;&#12290;&#25105;&#20204;&#35777;&#26126;&#22312;&#32447;&#24615;&#34920;&#31034;&#35774;&#32622;&#20013;&#65292;&#34429;&#28982;&#30446;&#26631;&#26159;&#38750;&#20984;&#30340;&#65292;&#25105;&#20204;&#25552;&#20986;&#30340;&#26032;&#31639;&#27861;DPFEDREP&#20250;&#25910;&#25947;&#21040;&#20197;&#20840;&#23616;&#20026;&#20013;&#24515;&#30340;&#29699;&#24418;&#21306;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
Repeated parameter sharing in federated learning causes significant information leakage about private data, thus defeating its main purpose: data privacy. Mitigating the risk of this information leakage, using state of the art differentially private algorithms, also does not come for free. Randomized mechanisms can prevent convergence of models on learning even the useful representation functions, especially if there is more disagreement between local models on the classification functions (due to data heterogeneity). In this paper, we consider a representation federated learning objective that encourages various parties to collaboratively refine the consensus part of the model, with differential privacy guarantees, while separately allowing sufficient freedom for local personalization (without releasing it). We prove that in the linear representation setting, while the objective is non-convex, our proposed new algorithm \DPFEDREP\ converges to a ball centered around the \emph{global o
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#26032;&#29983;&#20799;&#33041;MRI&#22270;&#20687;&#30340;&#20998;&#21106;&#20219;&#21153;&#65292;&#36890;&#36807;&#32508;&#21512;&#21512;&#25104;&#23398;&#20064;&#30340;&#26041;&#27861;&#35757;&#32451;&#20102;&#23545;&#22270;&#20687;&#23545;&#27604;&#24230;&#21464;&#21270;&#21644;&#35299;&#21078;&#32467;&#26500;&#30340;&#31354;&#38388;&#37197;&#32622;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#27169;&#22411;&#12290;&#22312;&#23545;&#36229;&#36807;700&#21517;&#23156;&#20799;&#30340;&#39640;&#36136;&#37327;&#22270;&#20687;&#25968;&#25454;&#36827;&#34892;&#23454;&#39564;&#21518;&#65292;&#25105;&#20204;&#21457;&#29616;&#26631;&#20934;Unet&#27169;&#22411;&#22312;&#23569;&#25968;T2&#21152;&#26435;&#20307;&#31215;&#19978;&#34920;&#29616;&#20986;&#24778;&#20154;&#30340;&#24615;&#33021;&#65292;&#20294;&#36825;&#20123;&#27169;&#22411;&#23398;&#20064;&#21040;&#30340;&#29305;&#24449;&#19982;&#35757;&#32451;&#39046;&#22495;&#30340;&#24378;&#24230;&#30456;&#20851;&#12290;</title><link>http://arxiv.org/abs/2309.05306</link><description>&lt;p&gt;
&#24212;&#29992;&#20110;&#26032;&#29983;&#20799;&#33041;MRI&#20998;&#21106;&#30340;&#32508;&#21512;&#21512;&#25104;&#23398;&#20064;&#30340;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Comprehensive analysis of synthetic learning applied to neonatal brain MRI segmentation. (arXiv:2309.05306v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05306
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#26032;&#29983;&#20799;&#33041;MRI&#22270;&#20687;&#30340;&#20998;&#21106;&#20219;&#21153;&#65292;&#36890;&#36807;&#32508;&#21512;&#21512;&#25104;&#23398;&#20064;&#30340;&#26041;&#27861;&#35757;&#32451;&#20102;&#23545;&#22270;&#20687;&#23545;&#27604;&#24230;&#21464;&#21270;&#21644;&#35299;&#21078;&#32467;&#26500;&#30340;&#31354;&#38388;&#37197;&#32622;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#27169;&#22411;&#12290;&#22312;&#23545;&#36229;&#36807;700&#21517;&#23156;&#20799;&#30340;&#39640;&#36136;&#37327;&#22270;&#20687;&#25968;&#25454;&#36827;&#34892;&#23454;&#39564;&#21518;&#65292;&#25105;&#20204;&#21457;&#29616;&#26631;&#20934;Unet&#27169;&#22411;&#22312;&#23569;&#25968;T2&#21152;&#26435;&#20307;&#31215;&#19978;&#34920;&#29616;&#20986;&#24778;&#20154;&#30340;&#24615;&#33021;&#65292;&#20294;&#36825;&#20123;&#27169;&#22411;&#23398;&#20064;&#21040;&#30340;&#29305;&#24449;&#19982;&#35757;&#32451;&#39046;&#22495;&#30340;&#24378;&#24230;&#30456;&#20851;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#33041;&#32467;&#26500;&#24418;&#29366;&#21644;&#20449;&#21495;&#24378;&#24230;&#21464;&#21270;&#36739;&#22823;&#21453;&#26144;&#32974;&#20799;&#21457;&#32946;&#36807;&#31243;&#30340;&#21464;&#21270;&#65292;&#26032;&#29983;&#20799;MRI&#22270;&#20687;&#30340;&#33041;&#20998;&#21106;&#26159;&#19968;&#39033;&#38750;&#24120;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#12290;&#22312;&#36825;&#31181;&#32972;&#26223;&#19979;&#65292;&#38656;&#35201;&#20855;&#26377;&#23545;&#22270;&#20687;&#23545;&#27604;&#24230;&#21464;&#21270;&#21644;&#35299;&#21078;&#32467;&#26500;&#30340;&#31354;&#38388;&#37197;&#32622;&#30340;&#40065;&#26834;&#24615;&#30340;&#20998;&#21106;&#25216;&#26415;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#21512;&#25104;&#23398;&#20064;&#30340;&#28508;&#21147;&#65292;&#21363;&#20351;&#29992;&#20174;&#38750;&#24120;&#23569;&#25968;&#21463;&#35797;&#32773;&#30340;&#22320;&#38754;&#30495;&#23454;&#26631;&#31614;&#29983;&#25104;&#30340;&#21512;&#25104;&#22270;&#20687;&#35757;&#32451;&#30340;&#29420;&#31435;&#20110;&#23545;&#27604;&#24230;&#30340;&#27169;&#22411;&#12290;&#25105;&#20204;&#22522;&#20110;&#21457;&#23637;&#24615;&#20154;&#31867;&#36830;&#25509;&#32452;&#35745;&#21010;&#21457;&#24067;&#30340;&#25968;&#25454;&#38598;&#36827;&#34892;&#23454;&#39564;&#65292;&#35813;&#25968;&#25454;&#38598;&#25552;&#20379;&#20102;&#36229;&#36807;700&#21517;26&#33267;45&#21608;&#23381;&#40836;&#30340;&#23156;&#20799;&#30340;&#39640;&#36136;&#37327;T1&#21644;T2&#21152;&#26435;&#22270;&#20687;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#35777;&#23454;&#20102;&#20165;&#22522;&#20110;&#23569;&#25968;T2&#21152;&#26435;&#20307;&#31215;&#35757;&#32451;&#30340;&#26631;&#20934;Unet&#30340;&#20196;&#20154;&#21360;&#35937;&#28145;&#21051;&#30340;&#24615;&#33021;&#65292;&#20294;&#20063;&#35777;&#23454;&#20102;&#36825;&#31867;&#27169;&#22411;&#23398;&#20064;&#29305;&#23450;&#20110;&#35757;&#32451;&#22495;&#30340;&#24378;&#24230;&#30456;&#20851;&#29305;&#24449;&#12290;&#28982;&#21518;&#25105;&#20204;&#36827;&#19968;&#27493;&#35780;&#20272;&#20102;&#35768;&#22810;&#22522;&#20110;&#21512;&#25104;&#23398;&#20064;&#30340;&#25913;&#36827;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
Brain segmentation from neonatal MRI images is a very challenging task due to large changes in the shape of cerebral structures and variations in signal intensities reflecting the gestational process. In this context, there is a clear need for segmentation techniques that are robust to variations in image contrast and to the spatial configuration of anatomical structures. In this work, we evaluate the potential of synthetic learning, a contrast-independent model trained using synthetic images generated from the ground truth labels of very few subjects.We base our experiments on the dataset released by the developmental Human Connectome Project, for which high-quality T1- and T2-weighted images are available for more than 700 babies aged between 26 and 45 weeks post-conception. First, we confirm the impressive performance of a standard Unet trained on a few T2-weighted volumes, but also confirm that such models learn intensity-related features specific to the training domain. We then ev
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#28145;&#20837;&#25506;&#35752;&#20102;&#28151;&#26434;&#21518;&#39564;&#21442;&#25968;&#30340;&#38382;&#39064;&#65292;&#21457;&#29616;&#20102;&#19968;&#20123;&#37325;&#35201;&#30340;&#26032;&#35266;&#28857;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#23454;&#38469;&#24773;&#20917;&#19979;&#65292;&#38543;&#26426;&#24615;&#36890;&#24120;&#19981;&#33021;&#25552;&#39640;&#27979;&#35797;&#20934;&#30830;&#24615;&#65292;&#24182;&#19988;&#23545;&#20110;&#26576;&#20123;&#36125;&#21494;&#26031;&#27169;&#22411;&#65292;&#22686;&#21152;&#38543;&#26426;&#24615;&#21453;&#32780;&#20250;&#38477;&#20302;&#27979;&#35797;&#20934;&#30830;&#24615;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#36824;&#35299;&#37322;&#20102;&#20248;&#21270;&#30446;&#26631;&#20013;&#28201;&#24230;&#21442;&#25968;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#25351;&#20986;&#28201;&#24230;&#19981;&#33021;&#31616;&#21333;&#22320;&#34987;&#35270;&#20026;&#20462;&#27491;&#20102;&#20808;&#39564;&#25110;&#20284;&#28982;&#30340;&#38169;&#35823;&#35774;&#23450;&#12290;</title><link>http://arxiv.org/abs/2309.05292</link><description>&lt;p&gt;
&#28145;&#20837;&#30740;&#31350;&#28151;&#26434;&#21518;&#39564;&#21442;&#25968;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
The fine print on tempered posteriors. (arXiv:2309.05292v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05292
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#28145;&#20837;&#25506;&#35752;&#20102;&#28151;&#26434;&#21518;&#39564;&#21442;&#25968;&#30340;&#38382;&#39064;&#65292;&#21457;&#29616;&#20102;&#19968;&#20123;&#37325;&#35201;&#30340;&#26032;&#35266;&#28857;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#23454;&#38469;&#24773;&#20917;&#19979;&#65292;&#38543;&#26426;&#24615;&#36890;&#24120;&#19981;&#33021;&#25552;&#39640;&#27979;&#35797;&#20934;&#30830;&#24615;&#65292;&#24182;&#19988;&#23545;&#20110;&#26576;&#20123;&#36125;&#21494;&#26031;&#27169;&#22411;&#65292;&#22686;&#21152;&#38543;&#26426;&#24615;&#21453;&#32780;&#20250;&#38477;&#20302;&#27979;&#35797;&#20934;&#30830;&#24615;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#36824;&#35299;&#37322;&#20102;&#20248;&#21270;&#30446;&#26631;&#20013;&#28201;&#24230;&#21442;&#25968;&#30340;&#37325;&#35201;&#24615;&#65292;&#24182;&#25351;&#20986;&#28201;&#24230;&#19981;&#33021;&#31616;&#21333;&#22320;&#34987;&#35270;&#20026;&#20462;&#27491;&#20102;&#20808;&#39564;&#25110;&#20284;&#28982;&#30340;&#38169;&#35823;&#35774;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23545;&#28151;&#26434;&#21518;&#39564;&#21442;&#25968;&#36827;&#34892;&#20102;&#35814;&#32454;&#35843;&#26597;&#65292;&#21457;&#29616;&#20102;&#19968;&#20123;&#20851;&#38190;&#32780;&#20197;&#21069;&#26410;&#34987;&#35752;&#35770;&#30340;&#38382;&#39064;&#12290;&#19982;&#20197;&#24448;&#30340;&#32467;&#26524;&#30456;&#21453;&#65292;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#65292;&#22312;&#23454;&#38469;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#20197;&#21450;&#23545;&#21518;&#39564;&#30340;&#32039;&#23494;&#25511;&#21046;&#30340;Laplace&#36817;&#20284;&#24773;&#20917;&#19979;&#65292;&#38543;&#26426;&#24615;&#36890;&#24120;&#24182;&#19981;&#33021;&#25552;&#39640;&#27979;&#35797;&#20934;&#30830;&#24615;&#12290;&#26368;&#20302;&#30340;&#28201;&#24230;&#36890;&#24120;&#26159;&#26368;&#20248;&#30340;&#12290;&#20154;&#20204;&#21487;&#33021;&#20250;&#35748;&#20026;&#65292;&#20855;&#26377;&#19968;&#23450;&#38543;&#26426;&#24615;&#30340;&#36125;&#21494;&#26031;&#27169;&#22411;&#33267;&#23569;&#33021;&#22312;&#26657;&#20934;&#26041;&#38754;&#21462;&#24471;&#25913;&#36827;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#24403;&#33719;&#24471;&#22686;&#30410;&#26102;&#65292;&#36825;&#26159;&#20197;&#27979;&#35797;&#20934;&#30830;&#24615;&#30340;&#38477;&#20302;&#20026;&#20195;&#20215;&#30340;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#20351;&#29992;&#36125;&#21494;&#26031;&#27169;&#22411;&#20197;&#30446;&#26631;&#39057;&#29575;&#20027;&#20041;&#25351;&#26631;&#25552;&#20379;&#23545;&#20248;&#21270;&#30446;&#26631;&#20013;&#28201;&#24230;&#21442;&#25968;&#955;&#30340;&#31616;&#21333;&#35299;&#37322;&#30340;&#38382;&#39064;&#12290;&#19982;&#20043;&#21069;&#30340;&#30740;&#31350;&#30456;&#21453;&#65292;&#25105;&#20204;&#26368;&#32456;&#36890;&#36807;PAC-Bayesian&#20998;&#26512;&#34920;&#26126;&#65292;&#28201;&#24230;&#955;&#19981;&#33021;&#31616;&#21333;&#22320;&#34987;&#35270;&#20026;&#20462;&#27491;&#20102;&#20808;&#39564;&#25110;&#20284;&#28982;&#30340;&#38169;&#35823;&#35774;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;
We conduct a detailed investigation of tempered posteriors and uncover a number of crucial and previously undiscussed points. Contrary to previous results, we first show that for realistic models and datasets and the tightly controlled case of the Laplace approximation to the posterior, stochasticity does not in general improve test accuracy. The coldest temperature is often optimal. One might think that Bayesian models with some stochasticity can at least obtain improvements in terms of calibration. However, we show empirically that when gains are obtained this comes at the cost of degradation in test accuracy. We then discuss how targeting Frequentist metrics using Bayesian models provides a simple explanation of the need for a temperature parameter $\lambda$ in the optimization objective. Contrary to prior works, we finally show through a PAC-Bayesian analysis that the temperature $\lambda$ cannot be seen as simply fixing a misspecified prior or likelihood.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#21327;&#21516;&#25193;&#25955;&#24674;&#22797;&#20284;&#28982;&#65288;CDRL&#65289;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#21644;&#37319;&#26679;&#19968;&#31995;&#21015;&#22522;&#20110;&#33021;&#37327;&#30340;&#27169;&#22411;&#65288;EBMs&#65289;&#65292;&#36890;&#36807;&#22312;&#19981;&#26029;&#22024;&#26434;&#21270;&#30340;&#25968;&#25454;&#38598;&#29256;&#26412;&#19978;&#23450;&#20041;&#19981;&#21516;&#22122;&#22768;&#27700;&#24179;&#30340;EBMs&#65292;&#24182;&#19982;&#21021;&#22987;&#21270;&#27169;&#22411;&#37197;&#23545;&#21327;&#21516;&#35757;&#32451;&#12290;&#36825;&#31181;&#26041;&#27861;&#26088;&#22312;&#20851;&#38381;EBMs&#21644;&#20854;&#20182;&#29983;&#25104;&#26694;&#26550;&#20043;&#38388;&#30340;&#26679;&#26412;&#36136;&#37327;&#24046;&#36317;&#12290;</title><link>http://arxiv.org/abs/2309.05153</link><description>&lt;p&gt;
&#36890;&#36807;&#21327;&#21516;&#25193;&#25955;&#24674;&#22797;&#20284;&#28982;&#23398;&#20064;&#22522;&#20110;&#33021;&#37327;&#30340;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Learning Energy-Based Models by Cooperative Diffusion Recovery Likelihood. (arXiv:2309.05153v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05153
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#21327;&#21516;&#25193;&#25955;&#24674;&#22797;&#20284;&#28982;&#65288;CDRL&#65289;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#21644;&#37319;&#26679;&#19968;&#31995;&#21015;&#22522;&#20110;&#33021;&#37327;&#30340;&#27169;&#22411;&#65288;EBMs&#65289;&#65292;&#36890;&#36807;&#22312;&#19981;&#26029;&#22024;&#26434;&#21270;&#30340;&#25968;&#25454;&#38598;&#29256;&#26412;&#19978;&#23450;&#20041;&#19981;&#21516;&#22122;&#22768;&#27700;&#24179;&#30340;EBMs&#65292;&#24182;&#19982;&#21021;&#22987;&#21270;&#27169;&#22411;&#37197;&#23545;&#21327;&#21516;&#35757;&#32451;&#12290;&#36825;&#31181;&#26041;&#27861;&#26088;&#22312;&#20851;&#38381;EBMs&#21644;&#20854;&#20182;&#29983;&#25104;&#26694;&#26550;&#20043;&#38388;&#30340;&#26679;&#26412;&#36136;&#37327;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#39640;&#32500;&#25968;&#25454;&#19978;&#20351;&#29992;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#35757;&#32451;&#33021;&#37327;&#22522;&#20934;&#27169;&#22411;&#65288;EBMs&#65289;&#21487;&#33021;&#20855;&#26377;&#25361;&#25112;&#24615;&#19988;&#32791;&#26102;&#36739;&#38271;&#12290;&#22240;&#27492;&#65292;EBMs&#21644;&#20854;&#20182;&#29983;&#25104;&#26694;&#26550;&#65288;&#22914;GANs&#21644;&#25193;&#25955;&#27169;&#22411;&#65289;&#20043;&#38388;&#23384;&#22312;&#26126;&#26174;&#30340;&#26679;&#26412;&#36136;&#37327;&#24046;&#36317;&#12290;&#20026;&#20102;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#21463;&#26368;&#36817;&#36890;&#36807;&#26368;&#22823;&#21270;&#25193;&#25955;&#24674;&#22797;&#20284;&#28982;&#65288;DRL&#65289;&#26469;&#23398;&#20064;EBMs&#30340;&#21162;&#21147;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21327;&#21516;&#25193;&#25955;&#24674;&#22797;&#20284;&#28982;&#65288;CDRL&#65289;&#65292;&#19968;&#31181;&#26377;&#25928;&#30340;&#26041;&#27861;&#26469;&#21487;&#34892;&#22320;&#23398;&#20064;&#21644;&#20174;&#19968;&#31995;&#21015;EBMs&#20013;&#36827;&#34892;&#37319;&#26679;&#65292;&#36825;&#20123;EBMs&#23450;&#20041;&#22312;&#36234;&#26469;&#36234;&#22024;&#26434;&#30340;&#25968;&#25454;&#38598;&#29256;&#26412;&#19978;&#65292;&#24182;&#19982;&#27599;&#20010;EBM&#30340;&#21021;&#22987;&#21270;&#27169;&#22411;&#37197;&#23545;&#12290;&#22312;&#27599;&#20010;&#22122;&#22768;&#27700;&#24179;&#19978;&#65292;&#21021;&#22987;&#21270;&#27169;&#22411;&#23398;&#20064;&#22312;EBM&#30340;&#37319;&#26679;&#36807;&#31243;&#20013;&#20998;&#25674;&#65292;&#32780;&#20004;&#20010;&#27169;&#22411;&#22312;&#21327;&#21516;&#35757;&#32451;&#26694;&#26550;&#20869;&#20849;&#21516;&#20272;&#35745;&#12290;&#21021;&#22987;&#21270;&#27169;&#22411;&#29983;&#25104;&#30340;&#26679;&#26412;&#20316;&#20026;&#36215;&#22987;&#28857;&#65292;&#32463;&#36807;EBM&#30340;&#20960;&#20010;&#37319;&#26679;&#27493;&#39588;&#36827;&#34892;&#25913;&#36827;&#12290;&#36890;&#36807;&#25913;&#36827;&#21518;&#30340;&#26679;&#26412;&#65292;&#36890;&#36807;&#26368;&#22823;&#21270;&#24674;&#22797;&#20284;&#28982;&#26469;&#20248;&#21270;EBM&#12290;
&lt;/p&gt;
&lt;p&gt;
Training energy-based models (EBMs) with maximum likelihood estimation on high-dimensional data can be both challenging and time-consuming. As a result, there a noticeable gap in sample quality between EBMs and other generative frameworks like GANs and diffusion models. To close this gap, inspired by the recent efforts of learning EBMs by maximimizing diffusion recovery likelihood (DRL), we propose cooperative diffusion recovery likelihood (CDRL), an effective approach to tractably learn and sample from a series of EBMs defined on increasingly noisy versons of a dataset, paired with an initializer model for each EBM. At each noise level, the initializer model learns to amortize the sampling process of the EBM, and the two models are jointly estimated within a cooperative training framework. Samples from the initializer serve as starting points that are refined by a few sampling steps from the EBM. With the refined samples, the EBM is optimized by maximizing recovery likelihood, while t
&lt;/p&gt;</description></item><item><title>&#24322;&#24120;&#20540;&#40065;&#26834;&#23545;&#25239;&#35757;&#32451;&#65288;ORAT&#65289;&#26159;&#19968;&#31181;&#21516;&#26102;&#22788;&#29702;&#35757;&#32451;&#25968;&#25454;&#36136;&#37327;&#21644;&#25512;&#29702;&#26102;&#38388;&#23545;&#25239;&#25915;&#20987;&#30340;&#27169;&#22411;&#65292;&#37319;&#29992;&#20102;&#40065;&#26834;&#30340;&#25490;&#21517;&#25439;&#22833;&#20989;&#25968;&#65292;&#20855;&#26377;&#36739;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.05145</link><description>&lt;p&gt;
&#24322;&#24120;&#20540;&#40065;&#26834;&#23545;&#25239;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Outlier Robust Adversarial Training. (arXiv:2309.05145v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05145
&lt;/p&gt;
&lt;p&gt;
&#24322;&#24120;&#20540;&#40065;&#26834;&#23545;&#25239;&#35757;&#32451;&#65288;ORAT&#65289;&#26159;&#19968;&#31181;&#21516;&#26102;&#22788;&#29702;&#35757;&#32451;&#25968;&#25454;&#36136;&#37327;&#21644;&#25512;&#29702;&#26102;&#38388;&#23545;&#25239;&#25915;&#20987;&#30340;&#27169;&#22411;&#65292;&#37319;&#29992;&#20102;&#40065;&#26834;&#30340;&#25490;&#21517;&#25439;&#22833;&#20989;&#25968;&#65292;&#20855;&#26377;&#36739;&#22909;&#30340;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30417;&#30563;&#23398;&#20064;&#27169;&#22411;&#21463;&#21040;&#35757;&#32451;&#25968;&#25454;&#30340;&#22266;&#26377;&#22797;&#26434;&#24615;&#30340;&#25361;&#25112;&#65292;&#22914;&#24322;&#24120;&#20540;&#21644;&#23569;&#25968;&#23376;&#32676;&#65292;&#24182;&#19988;&#36824;&#21463;&#21040;&#25512;&#29702;&#26102;&#38388;&#30340;&#26377;&#24847;&#25915;&#20987;&#65292;&#20854;&#20013;&#20351;&#29992;&#23545;&#25239;&#26679;&#26412;&#12290;&#34429;&#28982;&#20256;&#32479;&#30340;&#40065;&#26834;&#23398;&#20064;&#26041;&#27861;&#21644;&#26368;&#36817;&#30340;&#23545;&#25239;&#35757;&#32451;&#26041;&#27861;&#20998;&#21035;&#35774;&#35745;&#29992;&#20110;&#22788;&#29702;&#36825;&#20004;&#20010;&#25361;&#25112;&#65292;&#20294;&#36804;&#20170;&#20026;&#27490;&#65292;&#36824;&#27809;&#26377;&#30740;&#31350;&#24320;&#21457;&#20986;&#21516;&#26102;&#23545;&#35757;&#32451;&#25968;&#25454;&#36136;&#37327;&#20302;&#21644;&#25512;&#29702;&#26102;&#38388;&#28508;&#22312;&#23545;&#25239;&#25915;&#20987;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#27169;&#22411;&#12290;&#20986;&#20110;&#36825;&#20010;&#21407;&#22240;&#65292;&#25105;&#20204;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#20171;&#32461;&#20102;&#24322;&#24120;&#20540;&#40065;&#26834;&#23545;&#25239;&#35757;&#32451;&#65288;ORAT&#65289;&#12290;ORAT&#22522;&#20110;&#19968;&#20010;&#21452;&#23618;&#20248;&#21270;&#20844;&#24335;&#30340;&#23545;&#25239;&#35757;&#32451;&#65292;&#37319;&#29992;&#40065;&#26834;&#30340;&#22522;&#20110;&#25490;&#21517;&#30340;&#25439;&#22833;&#20989;&#25968;&#12290;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;ORAT&#30340;&#23398;&#20064;&#30446;&#26631;&#28385;&#36275;&#20108;&#20998;&#31867;&#30340;H-&#19968;&#33268;&#24615;&#65292;&#20174;&#32780;&#23558;&#20854;&#30830;&#31435;&#20026;&#23545;&#25239;0/1&#25439;&#22833;&#30340;&#21512;&#36866;&#26367;&#20195;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#23427;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#24182;&#25552;&#20379;&#20102;&#32479;&#19968;&#30340;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Supervised learning models are challenged by the intrinsic complexities of training data such as outliers and minority subpopulations and intentional attacks at inference time with adversarial samples. While traditional robust learning methods and the recent adversarial training approaches are designed to handle each of the two challenges, to date, no work has been done to develop models that are robust with regard to the low-quality training data and the potential adversarial attack at inference time simultaneously. It is for this reason that we introduce Outlier Robust Adversarial Training (ORAT) in this work. ORAT is based on a bi-level optimization formulation of adversarial training with a robust rank-based loss function. Theoretically, we show that the learning objective of ORAT satisfies the $\mathcal{H}$-consistency in binary classification, which establishes it as a proper surrogate to adversarial 0/1 loss. Furthermore, we analyze its generalization ability and provide uniform
&lt;/p&gt;</description></item><item><title>DAD++&#26159;&#19968;&#31181;&#25913;&#36827;&#30340;&#26080;&#25968;&#25454;&#27979;&#35797;&#26102;&#23545;&#25239;&#38450;&#24481;&#26041;&#27861;&#65292;&#36890;&#36807;&#21253;&#21547;&#26816;&#27979;&#21644;&#20462;&#27491;&#26694;&#26550;&#20197;&#25552;&#39640;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#40065;&#26834;&#24615;&#12290;&#21516;&#26102;&#65292;&#24341;&#20837;&#20102;&#36719;&#26816;&#27979;&#26041;&#26696;&#20197;&#22686;&#24378;&#20462;&#27491;&#26694;&#26550;&#22312;&#26816;&#27979;&#22120;&#32622;&#20449;&#24230;&#19981;&#36275;&#26102;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2309.05132</link><description>&lt;p&gt;
DAD++&#65306;&#25913;&#36827;&#30340;&#26080;&#25968;&#25454;&#27979;&#35797;&#26102;&#23545;&#25239;&#38450;&#24481;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
DAD++: Improved Data-free Test Time Adversarial Defense. (arXiv:2309.05132v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05132
&lt;/p&gt;
&lt;p&gt;
DAD++&#26159;&#19968;&#31181;&#25913;&#36827;&#30340;&#26080;&#25968;&#25454;&#27979;&#35797;&#26102;&#23545;&#25239;&#38450;&#24481;&#26041;&#27861;&#65292;&#36890;&#36807;&#21253;&#21547;&#26816;&#27979;&#21644;&#20462;&#27491;&#26694;&#26550;&#20197;&#25552;&#39640;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#40065;&#26834;&#24615;&#12290;&#21516;&#26102;&#65292;&#24341;&#20837;&#20102;&#36719;&#26816;&#27979;&#26041;&#26696;&#20197;&#22686;&#24378;&#20462;&#27491;&#26694;&#26550;&#22312;&#26816;&#27979;&#22120;&#32622;&#20449;&#24230;&#19981;&#36275;&#26102;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#35832;&#22914;&#33258;&#21160;&#39550;&#39542;&#27773;&#36710;&#12289;&#21307;&#23398;&#24433;&#20687;&#12289;&#24322;&#24120;&#26816;&#27979;&#31561;&#23433;&#20840;&#20851;&#38190;&#24212;&#29992;&#20013;&#30340;&#26085;&#30410;&#37096;&#32626;&#65292;&#23545;&#25239;&#40065;&#26834;&#24615;&#24050;&#25104;&#20026;&#36825;&#20123;&#32593;&#32476;&#22312;&#23454;&#38469;&#22330;&#26223;&#20013;&#21487;&#38752;&#24615;&#30340;&#20851;&#38190;&#38382;&#39064;&#12290;&#35768;&#22810;&#22522;&#20110;&#23545;&#25239;&#35757;&#32451;&#21644;&#27491;&#21017;&#21270;&#25216;&#26415;&#30340;&#24037;&#20316;&#24050;&#34987;&#25552;&#20986;&#65292;&#20197;&#20351;&#36825;&#20123;&#28145;&#24230;&#32593;&#32476;&#23545;&#25239;&#25915;&#20987;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#35201;&#27714;&#37325;&#26032;&#35757;&#32451;&#27169;&#22411;&#25110;&#20174;&#22836;&#24320;&#22987;&#35757;&#32451;&#65292;&#20351;&#24471;&#22312;&#35757;&#32451;&#25968;&#25454;&#35775;&#38382;&#21463;&#38480;&#30340;&#24773;&#20917;&#19979;&#20445;&#25252;&#39044;&#35757;&#32451;&#27169;&#22411;&#21464;&#24471;&#19981;&#21487;&#34892;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#21253;&#21547;&#26816;&#27979;&#21644;&#20462;&#27491;&#26694;&#26550;&#30340;&#27979;&#35797;&#26102;&#26080;&#25968;&#25454;&#23545;&#25239;&#38450;&#24481;&#26041;&#27861;&#65288;DAD&#65289;&#12290;&#27492;&#22806;&#65292;&#20026;&#20102;&#22312;&#26816;&#27979;&#22120;&#32622;&#20449;&#24230;&#19981;&#36275;&#26102;&#36827;&#19968;&#27493;&#25552;&#39640;&#20462;&#27491;&#26694;&#26550;&#30340;&#26377;&#25928;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36719;&#26816;&#27979;&#26041;&#26696;&#65288;&#31216;&#20026;"DAD++"&#65289;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#23454;&#39564;&#21644;&#28040;&#34701;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the increasing deployment of deep neural networks in safety-critical applications such as self-driving cars, medical imaging, anomaly detection, etc., adversarial robustness has become a crucial concern in the reliability of these networks in real-world scenarios. A plethora of works based on adversarial training and regularization-based techniques have been proposed to make these deep networks robust against adversarial attacks. However, these methods require either retraining models or training them from scratch, making them infeasible to defend pre-trained models when access to training data is restricted. To address this problem, we propose a test time Data-free Adversarial Defense (DAD) containing detection and correction frameworks. Moreover, to further improve the efficacy of the correction framework in cases when the detector is under-confident, we propose a soft-detection scheme (dubbed as "DAD++"). We conduct a wide range of experiments and ablations on several datasets 
&lt;/p&gt;</description></item><item><title>&#20351;&#29992;&#26680;&#23725;&#22238;&#24402;&#30340; mlcausality &#26159;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#21644;Python&#24211;&#65292;&#29992;&#20110;&#35782;&#21035;&#38750;&#32447;&#24615; Granger &#22240;&#26524;&#20851;&#31995;&#65292;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#24615;&#33021;&#21644;&#26356;&#31934;&#32454;&#26657;&#20934;&#30340; p &#20540;&#65292;&#20197;&#21450;&#26174;&#33879;&#38477;&#20302;&#30340;&#35745;&#31639;&#26102;&#38388;&#12290;</title><link>http://arxiv.org/abs/2309.05107</link><description>&lt;p&gt;
&#20351;&#29992;&#26680;&#23725;&#22238;&#24402;&#30340;&#38750;&#32447;&#24615; Granger &#22240;&#26524;&#20851;&#31995;
&lt;/p&gt;
&lt;p&gt;
Nonlinear Granger Causality using Kernel Ridge Regression. (arXiv:2309.05107v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05107
&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#26680;&#23725;&#22238;&#24402;&#30340; mlcausality &#26159;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#21644;Python&#24211;&#65292;&#29992;&#20110;&#35782;&#21035;&#38750;&#32447;&#24615; Granger &#22240;&#26524;&#20851;&#31995;&#65292;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#24615;&#33021;&#21644;&#26356;&#31934;&#32454;&#26657;&#20934;&#30340; p &#20540;&#65292;&#20197;&#21450;&#26174;&#33879;&#38477;&#20302;&#30340;&#35745;&#31639;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#24341;&#20837;&#20102;&#19968;&#31181;&#21517;&#20026; mlcausality &#30340;&#26032;&#31639;&#27861;&#21644;&#20276;&#38543;&#30340;Python&#24211;&#65292;&#29992;&#20110;&#35782;&#21035;&#38750;&#32447;&#24615; Granger &#22240;&#26524;&#20851;&#31995;&#12290;&#35813;&#26032;&#31639;&#27861;&#20351;&#29992;&#20102;&#28789;&#27963;&#30340;&#25554;&#20214;&#26550;&#26500;&#65292;&#20351;&#30740;&#31350;&#20154;&#21592;&#33021;&#22815;&#23558;&#20219;&#20309;&#38750;&#32447;&#24615;&#22238;&#24402;&#22120;&#20316;&#20026;&#22522;&#26412;&#30340;&#39044;&#27979;&#27169;&#22411;&#12290;&#38543;&#21518;&#65292;&#25105;&#23545; mlcausality &#36827;&#34892;&#20102;&#20840;&#38754;&#30340;&#24615;&#33021;&#20998;&#26512;&#65292;&#20854;&#20013;&#39044;&#27979;&#22238;&#24402;&#22120;&#20026;&#24102;&#26377;&#24452;&#21521;&#22522;&#20989;&#25968;&#26680;&#30340;&#26680;&#23725;&#22238;&#24402;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#22810;&#26679;&#21270;&#30340;&#27169;&#25311;&#25968;&#25454;&#38598;&#19978;&#65292;mlcausality &#20351;&#29992;&#26680;&#23725;&#22238;&#24402;&#33719;&#24471;&#20102;&#31454;&#20105;&#21147;&#30340;AUC&#24471;&#20998;&#12290;&#27492;&#22806;&#65292;&#19982;&#31454;&#20105;&#31639;&#27861;&#30456;&#27604;&#65292;&#20351;&#29992;&#26680;&#23725;&#22238;&#24402;&#30340; mlcausality &#20135;&#29983;&#26356;&#31934;&#32454;&#26657;&#20934;&#30340; p &#20540;&#12290;&#36825;&#31181;&#20248;&#21270;&#20351;&#24471; mlcausality &#22312;&#20351;&#29992;&#30452;&#35266;&#30340; p &#20540;&#38408;&#20540;&#20934;&#21017;&#26102;&#33719;&#24471;&#20102;&#26356;&#39640;&#30340;&#20934;&#30830;&#24230;&#24471;&#20998;&#12290;&#26368;&#21518;&#65292;&#20351;&#29992;&#26680;&#23725;&#22238;&#24402;&#30340; mlcausality &#26174;&#33879;&#38477;&#20302;&#20102;&#35745;&#31639;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
I introduce a novel algorithm and accompanying Python library, named mlcausality, designed for the identification of nonlinear Granger causal relationships. This novel algorithm uses a flexible plug-in architecture that enables researchers to employ any nonlinear regressor as the base prediction model. Subsequently, I conduct a comprehensive performance analysis of mlcausality when the prediction regressor is the kernel ridge regressor with the radial basis function kernel. The results demonstrate that mlcausality employing kernel ridge regression achieves competitive AUC scores across a diverse set of simulated data. Furthermore, mlcausality with kernel ridge regression yields more finely calibrated $p$-values in comparison to rival algorithms. This enhancement enables mlcausality to attain superior accuracy scores when using intuitive $p$-value-based thresholding criteria. Finally, mlcausality with the kernel ridge regression exhibits significantly reduced computation times compared 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#26377;&#30028;&#26356;&#26032;&#30340;&#36845;&#20195;&#23398;&#20064;&#31639;&#27861;&#22312;&#38750;&#20984;&#25439;&#22833;&#20989;&#25968;&#19978;&#30340;&#27867;&#21270;&#29305;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#65292;&#21033;&#29992;&#20102;&#20449;&#24687;&#35770;&#25216;&#26415;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#27169;&#22411;&#32500;&#24230;&#21644;&#35757;&#32451;&#25968;&#25454;&#26679;&#26412;&#25968;&#37327;&#30456;&#31561;&#30340;&#24773;&#20917;&#19979;&#65292;&#30028;&#38480;&#24471;&#21040;&#20102;&#25913;&#21892;&#12290;</title><link>http://arxiv.org/abs/2309.05077</link><description>&lt;p&gt;
&#20855;&#26377;&#26377;&#30028;&#26356;&#26032;&#30340;&#36845;&#20195;&#23398;&#20064;&#31639;&#27861;&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Generalization error bounds for iterative learning algorithms with bounded updates. (arXiv:2309.05077v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05077
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#26377;&#30028;&#26356;&#26032;&#30340;&#36845;&#20195;&#23398;&#20064;&#31639;&#27861;&#22312;&#38750;&#20984;&#25439;&#22833;&#20989;&#25968;&#19978;&#30340;&#27867;&#21270;&#29305;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#65292;&#21033;&#29992;&#20102;&#20449;&#24687;&#35770;&#25216;&#26415;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#27169;&#22411;&#32500;&#24230;&#21644;&#35757;&#32451;&#25968;&#25454;&#26679;&#26412;&#25968;&#37327;&#30456;&#31561;&#30340;&#24773;&#20917;&#19979;&#65292;&#30028;&#38480;&#24471;&#21040;&#20102;&#25913;&#21892;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#20855;&#26377;&#26377;&#30028;&#26356;&#26032;&#30340;&#36845;&#20195;&#23398;&#20064;&#31639;&#27861;&#22312;&#38750;&#20984;&#25439;&#22833;&#20989;&#25968;&#19978;&#30340;&#27867;&#21270;&#29305;&#24615;&#65292;&#37319;&#29992;&#20102;&#20449;&#24687;&#35770;&#25216;&#26415;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#38024;&#23545;&#20855;&#26377;&#26377;&#30028;&#26356;&#26032;&#30340;&#31639;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#65292;&#36229;&#20986;&#20102;&#20197;&#21069;&#21482;&#20851;&#27880;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#33539;&#22260;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#24341;&#20837;&#20102;&#20004;&#20010;&#20027;&#35201;&#30340;&#21019;&#26032;&#20043;&#22788;&#65306;1&#65289;&#25105;&#20204;&#23558;&#20114;&#20449;&#24687;&#37325;&#26032;&#23450;&#20041;&#20026;&#26356;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#35270;&#35282;&#65307;2&#65289;&#25105;&#20204;&#19981;&#20351;&#29992;&#20114;&#20449;&#24687;&#30340;&#38142;&#24335;&#27861;&#21017;&#65292;&#32780;&#26159;&#37319;&#29992;&#26041;&#24046;&#20998;&#35299;&#25216;&#26415;&#26469;&#23558;&#20449;&#24687;&#20998;&#35299;&#21040;&#36845;&#20195;&#20013;&#65292;&#20174;&#32780;&#20801;&#35768;&#31616;&#21270;&#30340;&#20195;&#29702;&#36807;&#31243;&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#35774;&#32622;&#19979;&#20998;&#26512;&#20102;&#25105;&#20204;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#22312;&#27169;&#22411;&#32500;&#24230;&#20197;&#19982;&#35757;&#32451;&#25968;&#25454;&#26679;&#26412;&#25968;&#37327;&#30456;&#21516;&#30340;&#36895;&#29575;&#22686;&#21152;&#26102;&#23637;&#31034;&#20102;&#25913;&#36827;&#30340;&#30028;&#38480;&#12290;&#20026;&#20102;&#24357;&#21512;&#29702;&#35770;&#19982;&#23454;&#36341;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#20808;&#21069;&#35266;&#23519;&#21040;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper explores the generalization characteristics of iterative learning algorithms with bounded updates for non-convex loss functions, employing information-theoretic techniques. Our key contribution is a novel bound for the generalization error of these algorithms with bounded updates, extending beyond the scope of previous works that only focused on Stochastic Gradient Descent (SGD). Our approach introduces two main novelties: 1) we reformulate the mutual information as the uncertainty of updates, providing a new perspective, and 2) instead of using the chaining rule of mutual information, we employ a variance decomposition technique to decompose information across iterations, allowing for a simpler surrogate process. We analyze our generalization bound under various settings and demonstrate improved bounds when the model dimension increases at the same rate as the number of training data samples. To bridge the gap between theory and practice, we also examine the previously obse
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#21435;&#27542;&#27665;&#21270;&#20154;&#24037;&#26234;&#33021;&#23545;&#40784;&#30340;&#19977;&#20010;&#24314;&#35758;&#65306;&#25913;&#21464;&#22522;&#26412;&#36947;&#24503;&#21746;&#23398;&#20026;&#36798;&#23572;&#29595;&#21746;&#23398;&#65292;&#20801;&#35768;&#22810;&#20803;&#20027;&#20041;&#30340;&#35770;&#35777;&#20256;&#32479;&#23384;&#22312;&#20110;&#23545;&#40784;&#25216;&#26415;&#20013;&#65292;&#20197;&#21450;&#23558;&#20215;&#20540;&#35748;&#35782;&#35770;&#25193;&#23637;&#21040;&#36229;&#36234;&#33258;&#28982;&#35821;&#35328;&#20013;&#30340;&#25351;&#20196;&#12290;</title><link>http://arxiv.org/abs/2309.05030</link><description>&lt;p&gt;
&#21435;&#27542;&#27665;&#21270;&#30340;&#20154;&#24037;&#26234;&#33021;&#23545;&#40784;&#65306;&#23041;&#33394;&#36798;&#23572;&#29595;&#12289;&#35770;&#35777;&#21644;&#33402;&#26415;&#34920;&#36798;
&lt;/p&gt;
&lt;p&gt;
Decolonial AI Alignment: Vi\'{s}esadharma, Argument, and Artistic Expression. (arXiv:2309.05030v1 [cs.CY])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05030
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#21435;&#27542;&#27665;&#21270;&#20154;&#24037;&#26234;&#33021;&#23545;&#40784;&#30340;&#19977;&#20010;&#24314;&#35758;&#65306;&#25913;&#21464;&#22522;&#26412;&#36947;&#24503;&#21746;&#23398;&#20026;&#36798;&#23572;&#29595;&#21746;&#23398;&#65292;&#20801;&#35768;&#22810;&#20803;&#20027;&#20041;&#30340;&#35770;&#35777;&#20256;&#32479;&#23384;&#22312;&#20110;&#23545;&#40784;&#25216;&#26415;&#20013;&#65292;&#20197;&#21450;&#23558;&#20215;&#20540;&#35748;&#35782;&#35770;&#25193;&#23637;&#21040;&#36229;&#36234;&#33258;&#28982;&#35821;&#35328;&#20013;&#30340;&#25351;&#20196;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20808;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#38416;&#26126;&#20102;&#20154;&#24037;&#26234;&#33021;&#65288;AI&#65289;&#24320;&#21457;&#21644;&#37096;&#32626;&#30340;&#27542;&#27665;&#24615;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#30740;&#31350;&#24456;&#23569;&#28041;&#21450;&#21040;&#23545;&#40784;&#65306;&#21363;&#22522;&#20110;&#32454;&#33268;&#30340;&#20154;&#31867;&#21453;&#39304;&#65292;&#35843;&#25972;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#30340;&#34892;&#20026;&#19982;&#26399;&#26395;&#20540;&#19968;&#33268;&#12290;&#38500;&#20102;&#20854;&#20182;&#23454;&#36341;&#65292;&#27542;&#27665;&#20027;&#20041;&#36824;&#26377;&#19968;&#37096;&#20998;&#26159;&#25913;&#21464;&#34987;&#27542;&#27665;&#27665;&#26063;&#30340;&#20449;&#20208;&#21644;&#20215;&#20540;&#35266;&#30340;&#21382;&#21490;&#65307;&#32780;&#24403;&#21069;&#30340;LLM&#23545;&#40784;&#23454;&#36341;&#27491;&#26159;&#36825;&#19968;&#21382;&#21490;&#30340;&#22797;&#21046;&#12290;&#25105;&#20204;&#24314;&#35758;&#36890;&#36807;&#19977;&#20010;&#25552;&#35758;&#23545;AI&#23545;&#40784;&#36827;&#34892;&#21435;&#27542;&#27665;&#21270;&#65306;&#65288;a&#65289;&#23558;&#22522;&#26412;&#36947;&#24503;&#21746;&#23398;&#20174;&#35199;&#26041;&#21746;&#23398;&#36716;&#21464;&#20026;&#36798;&#23572;&#29595;&#21746;&#23398;&#65292;&#65288;b&#65289;&#22312;&#23545;&#40784;&#25216;&#26415;&#20013;&#20801;&#35768;&#35770;&#35777;&#21644;&#22810;&#20803;&#20027;&#20041;&#30340;&#20256;&#32479;&#65292;&#20197;&#21450;&#65288;c&#65289;&#23558;&#20215;&#20540;&#30340;&#35748;&#35782;&#35770;&#25193;&#23637;&#21040;&#36229;&#36234;&#33258;&#28982;&#35821;&#35328;&#20013;&#30340;&#25351;&#20196;&#25110;&#21629;&#20196;&#12290;
&lt;/p&gt;
&lt;p&gt;
Prior work has explicated the coloniality of artificial intelligence (AI) development and deployment. One process that that work has not engaged with much is alignment: the tuning of large language model (LLM) behavior to be in line with desired values based on fine-grained human feedback. In addition to other practices, colonialism has a history of altering the beliefs and values of colonized peoples; this history is recapitulated in current LLM alignment practices. We suggest that AI alignment be decolonialized using three proposals: (a) changing the base moral philosophy from Western philosophy to dharma, (b) permitting traditions of argument and pluralism in alignment technologies, and (c) expanding the epistemology of values beyond instructions or commandments given in natural language.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#39640;&#25928;&#38543;&#26426;&#20122;&#24403;&#26041;&#27861;SA-Solver&#65292;&#29992;&#20110;&#35299;&#25193;&#25955;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#20197;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#25968;&#25454;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#23427;&#22312;&#23569;&#27493;&#37319;&#26679;&#20013;&#30456;&#36739;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#26377;&#25913;&#36827;&#25110;&#21487;&#27604;&#30340;&#24615;&#33021;&#65292;&#24182;&#36798;&#21040;&#20102;SOTA FID&#20998;&#25968;&#12290;</title><link>http://arxiv.org/abs/2309.05019</link><description>&lt;p&gt;
SA-Solver&#65306;&#29992;&#20110;&#24555;&#36895;&#37319;&#26679;&#25193;&#25955;&#27169;&#22411;&#30340;&#38543;&#26426;&#20122;&#24403;&#27714;&#35299;&#22120;
&lt;/p&gt;
&lt;p&gt;
SA-Solver: Stochastic Adams Solver for Fast Sampling of Diffusion Models. (arXiv:2309.05019v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05019
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25913;&#36827;&#30340;&#39640;&#25928;&#38543;&#26426;&#20122;&#24403;&#26041;&#27861;SA-Solver&#65292;&#29992;&#20110;&#35299;&#25193;&#25955;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#20197;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#25968;&#25454;&#65292;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#23427;&#22312;&#23569;&#27493;&#37319;&#26679;&#20013;&#30456;&#36739;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#26377;&#25913;&#36827;&#25110;&#21487;&#27604;&#30340;&#24615;&#33021;&#65292;&#24182;&#36798;&#21040;&#20102;SOTA FID&#20998;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#22312;&#29983;&#25104;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#30456;&#24403;&#22823;&#30340;&#25104;&#21151;&#12290;&#30001;&#20110;&#20174;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#20013;&#36827;&#34892;&#37319;&#26679;&#30456;&#24403;&#20110;&#35299;&#25193;&#25955;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#25110;&#24120;&#24494;&#20998;&#26041;&#31243;&#65292;&#36825;&#26159;&#19968;&#39033;&#32791;&#26102;&#30340;&#24037;&#20316;&#65292;&#22240;&#27492;&#25552;&#20986;&#20102;&#35768;&#22810;&#22522;&#20110;&#25913;&#36827;&#30340;&#24494;&#20998;&#26041;&#31243;&#27714;&#35299;&#22120;&#30340;&#24555;&#36895;&#37319;&#26679;&#26041;&#27861;&#12290;&#36825;&#20123;&#25216;&#26415;&#20013;&#30340;&#22823;&#37096;&#20998;&#26041;&#27861;&#37117;&#32771;&#34385;&#35299;&#25193;&#25955;&#24120;&#24494;&#20998;&#26041;&#31243;&#65292;&#22240;&#20026;&#23427;&#20855;&#26377;&#26356;&#22909;&#30340;&#25928;&#29575;&#12290;&#28982;&#32780;&#65292;&#38543;&#26426;&#37319;&#26679;&#21487;&#20197;&#22312;&#29983;&#25104;&#22810;&#26679;&#21270;&#21644;&#39640;&#36136;&#37327;&#25968;&#25454;&#26041;&#38754;&#25552;&#20379;&#39069;&#22806;&#30340;&#20248;&#21183;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20174;&#20004;&#20010;&#26041;&#38754;&#36827;&#34892;&#20102;&#23545;&#38543;&#26426;&#37319;&#26679;&#30340;&#32508;&#21512;&#20998;&#26512;&#65306;&#26041;&#24046;&#25511;&#21046;&#30340;&#25193;&#25955;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#21644;&#32447;&#24615;&#22810;&#27493;&#25193;&#25955;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#27714;&#35299;&#22120;&#12290;&#22522;&#20110;&#25105;&#20204;&#30340;&#20998;&#26512;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;SA-Solver&#65292;&#23427;&#26159;&#19968;&#31181;&#25913;&#36827;&#30340;&#39640;&#25928;&#38543;&#26426;&#20122;&#24403;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#25193;&#25955;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#20197;&#29983;&#25104;&#39640;&#36136;&#37327;&#30340;&#25968;&#25454;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#26174;&#31034;&#65292;SA-Solver&#23454;&#29616;&#20102;&#65306;1&#65289;&#22312;&#23569;&#27493;&#37319;&#26679;&#20013;&#19982;&#29616;&#26377;&#26368;&#20808;&#36827;&#30340;&#37319;&#26679;&#26041;&#27861;&#30456;&#27604;&#65292;&#26377;&#25913;&#36827;&#25110;&#21487;&#27604;&#24615;&#33021;&#65307;2&#65289;SOTA FID&#20998;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion Probabilistic Models (DPMs) have achieved considerable success in generation tasks. As sampling from DPMs is equivalent to solving diffusion SDE or ODE which is time-consuming, numerous fast sampling methods built upon improved differential equation solvers are proposed. The majority of such techniques consider solving the diffusion ODE due to its superior efficiency. However, stochastic sampling could offer additional advantages in generating diverse and high-quality data. In this work, we engage in a comprehensive analysis of stochastic sampling from two aspects: variance-controlled diffusion SDE and linear multi-step SDE solver. Based on our analysis, we propose SA-Solver, which is an improved efficient stochastic Adams method for solving diffusion SDE to generate data with high quality. Our experiments show that SA-Solver achieves: 1) improved or comparable performance compared with the existing state-of-the-art sampling methods for few-step sampling; 2) SOTA FID scores o
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#28176;&#21464;&#20248;&#21270;&#21644;&#21464;&#20998;&#19981;&#31561;&#24335;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#65292;&#24378;&#35843;&#20102;&#20174;&#27169;&#24335;&#35782;&#21035;&#21040;&#20915;&#31574;&#21644;&#22810;&#26234;&#33021;&#20307;&#38382;&#39064;&#30340;&#36716;&#21464;&#65292;&#20197;&#21450;&#28041;&#21450;&#22343;&#34913;&#21644;&#21338;&#24328;&#35770;&#30340;&#25968;&#23398;&#25361;&#25112;&#65292;&#25552;&#20379;&#20102;&#19968;&#20123;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#35777;&#26126;&#65292;&#20294;&#20027;&#35201;&#20851;&#27880;&#20110;&#25552;&#20379;&#21160;&#26426;&#21644;&#30452;&#35266;&#29702;&#35299;&#12290;</title><link>http://arxiv.org/abs/2309.04877</link><description>&lt;p&gt;
&#28176;&#21464;&#20248;&#21270;&#21644;&#21464;&#20998;&#19981;&#31561;&#24335;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#28201;&#21644;&#20171;&#32461;
&lt;/p&gt;
&lt;p&gt;
A Gentle Introduction to Gradient-Based Optimization and Variational Inequalities for Machine Learning. (arXiv:2309.04877v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.04877
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#20171;&#32461;&#20102;&#28176;&#21464;&#20248;&#21270;&#21644;&#21464;&#20998;&#19981;&#31561;&#24335;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#65292;&#24378;&#35843;&#20102;&#20174;&#27169;&#24335;&#35782;&#21035;&#21040;&#20915;&#31574;&#21644;&#22810;&#26234;&#33021;&#20307;&#38382;&#39064;&#30340;&#36716;&#21464;&#65292;&#20197;&#21450;&#28041;&#21450;&#22343;&#34913;&#21644;&#21338;&#24328;&#35770;&#30340;&#25968;&#23398;&#25361;&#25112;&#65292;&#25552;&#20379;&#20102;&#19968;&#20123;&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#35777;&#26126;&#65292;&#20294;&#20027;&#35201;&#20851;&#27880;&#20110;&#25552;&#20379;&#21160;&#26426;&#21644;&#30452;&#35266;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#26426;&#22120;&#23398;&#20064;&#30340;&#24555;&#36895;&#21457;&#23637;&#22522;&#20110;&#19982;&#28176;&#21464;&#20248;&#21270;&#30340;&#32039;&#23494;&#32852;&#31995;&#12290;&#36827;&#19968;&#27493;&#30340;&#36827;&#23637;&#37096;&#20998;&#21462;&#20915;&#20110;&#20174;&#27169;&#24335;&#35782;&#21035;&#21040;&#20915;&#31574;&#21644;&#22810;&#26234;&#33021;&#20307;&#38382;&#39064;&#30340;&#36716;&#21464;&#12290;&#22312;&#36825;&#20123;&#26356;&#24191;&#27867;&#30340;&#32972;&#26223;&#19979;&#65292;&#28041;&#21450;&#22343;&#34913;&#21644;&#21338;&#24328;&#35770;&#32780;&#19981;&#26159;&#26497;&#20540;&#30340;&#26032;&#30340;&#25968;&#23398;&#25361;&#25112;&#20986;&#29616;&#20102;&#12290;&#22522;&#20110;&#26799;&#24230;&#30340;&#26041;&#27861;&#20173;&#28982;&#33267;&#20851;&#37325;&#35201;--&#32771;&#34385;&#21040;&#26426;&#22120;&#23398;&#20064;&#38382;&#39064;&#30340;&#39640;&#32500;&#24230;&#21644;&#22823;&#35268;&#27169;--&#20294;&#31616;&#21333;&#30340;&#26799;&#24230;&#19979;&#38477;&#19981;&#20877;&#26159;&#31639;&#27861;&#35774;&#35745;&#30340;&#20986;&#21457;&#28857;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#23545;&#26426;&#22120;&#23398;&#20064;&#20013;&#22522;&#20110;&#26799;&#24230;&#30340;&#31639;&#27861;&#30340;&#26356;&#24191;&#27867;&#26694;&#26550;&#30340;&#28201;&#21644;&#20171;&#32461;&#65292;&#20174;&#38797;&#28857;&#21644;&#21333;&#35843;&#21338;&#24328;&#24320;&#22987;&#65292;&#28982;&#21518;&#21040;&#19968;&#33324;&#30340;&#21464;&#20998;&#19981;&#31561;&#24335;&#12290;&#34429;&#28982;&#25105;&#20204;&#23545;&#25152;&#25552;&#20986;&#30340;&#20960;&#20010;&#31639;&#27861;&#36827;&#34892;&#20102;&#25910;&#25947;&#24615;&#35777;&#26126;&#65292;&#20294;&#25105;&#20204;&#30340;&#20027;&#35201;&#20851;&#27880;&#28857;&#26159;&#25552;&#20379;&#21160;&#26426;&#21644;&#30452;&#35266;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
The rapid progress in machine learning in recent years has been based on a highly productive connection to gradient-based optimization. Further progress hinges in part on a shift in focus from pattern recognition to decision-making and multi-agent problems. In these broader settings, new mathematical challenges emerge that involve equilibria and game theory instead of optima. Gradient-based methods remain essential -- given the high dimensionality and large scale of machine-learning problems -- but simple gradient descent is no longer the point of departure for algorithm design. We provide a gentle introduction to a broader framework for gradient-based algorithms in machine learning, beginning with saddle points and monotone games, and proceeding to general variational inequalities. While we provide convergence proofs for several of the algorithms that we present, our main focus is that of providing motivation and intuition.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#37319;&#29992;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#36817;&#20284;&#20445;&#35777;&#65292;&#21033;&#29992;&#36830;&#32493;&#30340;&#35823;&#24046;&#33539;&#25968;&#23545;&#32593;&#32476;&#36827;&#34892;&#20998;&#26512;&#65292;&#24182;&#21457;&#29616;&#22312;&#27424;&#21442;&#25968;&#21270;&#30340;&#24773;&#20917;&#19979;&#30456;&#23545;&#20110;&#24050;&#26377;&#30340;&#36924;&#36817;&#26041;&#27861;&#23384;&#22312;&#36924;&#36817;&#29575;&#19979;&#38477;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2309.04860</link><description>&lt;p&gt;
&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#36817;&#20284;&#32467;&#26524;
&lt;/p&gt;
&lt;p&gt;
Approximation Results for Gradient Descent trained Neural Networks. (arXiv:2309.04860v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.04860
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#37319;&#29992;&#26799;&#24230;&#19979;&#38477;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#36817;&#20284;&#20445;&#35777;&#65292;&#21033;&#29992;&#36830;&#32493;&#30340;&#35823;&#24046;&#33539;&#25968;&#23545;&#32593;&#32476;&#36827;&#34892;&#20998;&#26512;&#65292;&#24182;&#21457;&#29616;&#22312;&#27424;&#21442;&#25968;&#21270;&#30340;&#24773;&#20917;&#19979;&#30456;&#23545;&#20110;&#24050;&#26377;&#30340;&#36924;&#36817;&#26041;&#27861;&#23384;&#22312;&#36924;&#36817;&#29575;&#19979;&#38477;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#23545;&#37319;&#29992;&#26799;&#24230;&#27969;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#20102;&#36817;&#20284;&#20445;&#35777;&#65292;&#20854;&#20013;&#35823;&#24046;&#20197;&#36830;&#32493;&#30340;$L_2(\mathbb{S}^{d-1})$&#33539;&#25968;&#22312;$d$&#32500;&#21333;&#20301;&#29699;&#38754;&#19978;&#27979;&#37327;&#65292;&#30446;&#26631;&#20026;Sobolev&#24179;&#28369;&#12290;&#32593;&#32476;&#26159;&#23436;&#20840;&#36830;&#25509;&#30340;&#65292;&#28145;&#24230;&#24658;&#23450;&#65292;&#23485;&#24230;&#36882;&#22686;&#12290;&#34429;&#28982;&#25152;&#26377;&#23618;&#37117;&#36827;&#34892;&#20102;&#35757;&#32451;&#65292;&#20294;&#26799;&#24230;&#27969;&#30340;&#25910;&#25947;&#24615;&#26159;&#22522;&#20110;&#23545;&#20110;&#38750;&#20984;&#30340;&#20498;&#25968;&#31532;&#20108;&#23618;&#30340;&#31070;&#32463;&#20999;&#21521;&#26680;(NTK)&#30340;&#35770;&#35777;&#12290;&#19982;&#26631;&#20934;&#30340;NTK&#20998;&#26512;&#19981;&#21516;&#65292;&#36830;&#32493;&#35823;&#24046;&#33539;&#25968;&#26263;&#31034;&#20102;&#19968;&#20010;&#27424;&#21442;&#25968;&#21270;&#30340;&#21306;&#22495;&#65292;&#22312;&#36924;&#36817;&#26102;&#38656;&#35201;&#33258;&#28982;&#30340;&#20809;&#28369;&#24615;&#20551;&#35774;&#12290;&#20856;&#22411;&#30340;&#36807;&#21442;&#25968;&#21270;&#36890;&#36807;&#36924;&#36817;&#29575;&#30340;&#25439;&#22833;&#20197;&#21450;&#30456;&#23545;&#20110;Sobolev&#24179;&#28369;&#20989;&#25968;&#30340;&#24050;&#24314;&#31435;&#30340;&#36924;&#36817;&#26041;&#27861;&#32780;&#37325;&#26032;&#36827;&#20837;&#32467;&#26524;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
The paper contains approximation guarantees for neural networks that are trained with gradient flow, with error measured in the continuous $L_2(\mathbb{S}^{d-1})$-norm on the $d$-dimensional unit sphere and targets that are Sobolev smooth. The networks are fully connected of constant depth and increasing width. Although all layers are trained, the gradient flow convergence is based on a neural tangent kernel (NTK) argument for the non-convex second but last layer. Unlike standard NTK analysis, the continuous error norm implies an under-parametrized regime, possible by the natural smoothness assumption required for approximation. The typical over-parametrization re-enters the results in form of a loss in approximation rate relative to established approximation methods for Sobolev smooth functions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24341;&#20837;&#20102;&#38750;&#32447;&#24615;&#32500;&#24230;&#38477;&#20302;&#26041;&#27861;&#65292;&#22312;&#22240;&#23376;&#25193;&#23637;&#21521;&#37327;&#33258;&#22238;&#24402;&#20013;&#20998;&#26512;&#32463;&#27982;&#20914;&#20987;&#65292;&#35777;&#26126;&#20102;&#22312;&#32463;&#27982;&#21608;&#26399;&#21160;&#33633;&#21644;&#39640;&#24230;&#27874;&#21160;&#25968;&#25454;&#19979;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#33391;&#22909;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#24182;&#33021;&#22788;&#29702;COVID-19&#30123;&#24773;&#24341;&#36215;&#30340;&#31163;&#32676;&#20540;&#12290;</title><link>http://arxiv.org/abs/2309.04821</link><description>&lt;p&gt;
&#38750;&#32447;&#24615;&#32500;&#24230;&#38477;&#20302;&#22312;&#22240;&#23376;&#25193;&#23637;&#21521;&#37327;&#33258;&#22238;&#24402;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Non-linear dimension reduction in factor-augmented vector autoregressions. (arXiv:2309.04821v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.04821
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#38750;&#32447;&#24615;&#32500;&#24230;&#38477;&#20302;&#26041;&#27861;&#65292;&#22312;&#22240;&#23376;&#25193;&#23637;&#21521;&#37327;&#33258;&#22238;&#24402;&#20013;&#20998;&#26512;&#32463;&#27982;&#20914;&#20987;&#65292;&#35777;&#26126;&#20102;&#22312;&#32463;&#27982;&#21608;&#26399;&#21160;&#33633;&#21644;&#39640;&#24230;&#27874;&#21160;&#25968;&#25454;&#19979;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#33391;&#22909;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#24182;&#33021;&#22788;&#29702;COVID-19&#30123;&#24773;&#24341;&#36215;&#30340;&#31163;&#32676;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#38750;&#32447;&#24615;&#32500;&#24230;&#38477;&#20302;&#26041;&#27861;&#24341;&#20837;&#22240;&#23376;&#25193;&#23637;&#21521;&#37327;&#33258;&#22238;&#24402;&#27169;&#22411;&#65292;&#20998;&#26512;&#19981;&#21516;&#32463;&#27982;&#20914;&#20987;&#30340;&#24433;&#21709;&#12290;&#20316;&#32773;&#35748;&#20026;&#22312;&#32463;&#27982;&#21608;&#26399;&#21160;&#33633;&#26102;&#65292;&#25511;&#21046;&#22823;&#32500;&#24230;&#25968;&#25454;&#38598;&#19982;&#28508;&#22312;&#22240;&#23376;&#20043;&#38388;&#30340;&#38750;&#32447;&#24615;&#20851;&#31995;&#23588;&#20026;&#26377;&#29992;&#12290;&#36890;&#36807;&#27169;&#25311;&#23454;&#39564;&#35777;&#26126;&#65292;&#38750;&#32447;&#24615;&#32500;&#24230;&#38477;&#20302;&#25216;&#26415;&#22312;&#25968;&#25454;&#39640;&#24230;&#27874;&#21160;&#26102;&#20855;&#26377;&#33391;&#22909;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#22312;&#23454;&#35777;&#24212;&#29992;&#20013;&#65292;&#26412;&#25991;&#25490;&#38500;&#21644;&#21253;&#21547;COVID-19&#30123;&#24773;&#35266;&#27979;&#65292;&#30830;&#23450;&#20102;&#36135;&#24065;&#25919;&#31574;&#21644;&#19981;&#30830;&#23450;&#24615;&#20914;&#20987;&#12290;&#36825;&#20004;&#20010;&#24212;&#29992;&#34920;&#26126;&#38750;&#32447;&#24615;FAVAR&#26041;&#27861;&#33021;&#22815;&#22788;&#29702;COVID-19&#30123;&#24773;&#24341;&#36215;&#30340;&#26497;&#22823;&#31163;&#32676;&#20540;&#65292;&#24182;&#22312;&#20004;&#31181;&#24773;&#26223;&#19979;&#33719;&#24471;&#21487;&#38752;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper introduces non-linear dimension reduction in factor-augmented vector autoregressions to analyze the effects of different economic shocks. I argue that controlling for non-linearities between a large-dimensional dataset and the latent factors is particularly useful during turbulent times of the business cycle. In simulations, I show that non-linear dimension reduction techniques yield good forecasting performance, especially when data is highly volatile. In an empirical application, I identify a monetary policy as well as an uncertainty shock excluding and including observations of the COVID-19 pandemic. Those two applications suggest that the non-linear FAVAR approaches are capable of dealing with the large outliers caused by the COVID-19 pandemic and yield reliable results in both scenarios.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#31070;&#32463;&#28508;&#22312;&#20960;&#20309;&#25628;&#32034;(NLGS)&#30340;&#27010;&#24565;&#65292;&#26088;&#22312;&#36890;&#36807;&#26684;&#32599;&#33707;&#22827;-&#35946;&#26031;&#22810;&#22827;&#36317;&#31163;&#26469;&#33258;&#21160;&#35782;&#21035;&#19979;&#28216;&#20219;&#21153;&#30340;&#26368;&#20339;&#28508;&#22312;&#20960;&#20309;&#32467;&#26500;&#65292;&#20197;&#25552;&#39640;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.04810</link><description>&lt;p&gt;
&#31070;&#32463;&#28508;&#22312;&#20960;&#20309;&#25628;&#32034;&#65306;&#36890;&#36807;&#26684;&#32599;&#33707;&#22827;-&#35946;&#26031;&#22810;&#22827;&#20449;&#24687;&#39537;&#21160;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#26469;&#36827;&#34892;&#20056;&#31215;&#27969;&#24418;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Neural Latent Geometry Search: Product Manifold Inference via Gromov-Hausdorff-Informed Bayesian Optimization. (arXiv:2309.04810v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.04810
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#31070;&#32463;&#28508;&#22312;&#20960;&#20309;&#25628;&#32034;(NLGS)&#30340;&#27010;&#24565;&#65292;&#26088;&#22312;&#36890;&#36807;&#26684;&#32599;&#33707;&#22827;-&#35946;&#26031;&#22810;&#22827;&#36317;&#31163;&#26469;&#33258;&#21160;&#35782;&#21035;&#19979;&#28216;&#20219;&#21153;&#30340;&#26368;&#20339;&#28508;&#22312;&#20960;&#20309;&#32467;&#26500;&#65292;&#20197;&#25552;&#39640;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#36890;&#36807;&#23558;&#28508;&#22312;&#31354;&#38388;&#30340;&#20960;&#20309;&#32467;&#26500;&#19982;&#24213;&#23618;&#25968;&#25454;&#32467;&#26500;&#23545;&#40784;&#65292;&#21487;&#20197;&#25552;&#39640;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#30740;&#31350;&#20154;&#21592;&#25552;&#20986;&#20351;&#29992;&#20855;&#26377;&#24658;&#23450;&#26354;&#29575;&#30340;&#21452;&#26354;&#21644;&#29699;&#24418;&#31354;&#38388;&#65292;&#25110;&#32773;&#23427;&#20204;&#30340;&#32452;&#21512;&#65292;&#26469;&#26356;&#22909;&#22320;&#24314;&#27169;&#28508;&#22312;&#31354;&#38388;&#24182;&#22686;&#24378;&#27169;&#22411;&#24615;&#33021;&#65292;&#32780;&#19981;&#20165;&#20165;&#20381;&#36182;&#20110;&#27431;&#20960;&#37324;&#24471;&#31354;&#38388;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#23545;&#33258;&#21160;&#35782;&#21035;&#19979;&#28216;&#20219;&#21153;&#30340;&#26368;&#20339;&#28508;&#22312;&#20960;&#20309;&#32467;&#26500;&#38382;&#39064;&#36824;&#27809;&#26377;&#32473;&#20104;&#36275;&#22815;&#20851;&#27880;&#12290;&#25105;&#20204;&#22312;&#25968;&#23398;&#19978;&#23450;&#20041;&#20102;&#36825;&#20010;&#26032;&#39062;&#30340;&#38382;&#39064;&#65292;&#24182;&#23558;&#20854;&#31216;&#20026;&#31070;&#32463;&#28508;&#22312;&#20960;&#20309;&#25628;&#32034;(NLGS)&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#26684;&#32599;&#33707;&#22827;-&#35946;&#26031;&#22810;&#22827;&#36317;&#31163;&#30340;&#20505;&#36873;&#28508;&#22312;&#20960;&#20309;&#32467;&#26500;&#20043;&#38388;&#30340;&#26032;&#27010;&#24565;&#36317;&#31163;&#65292;&#20197;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#12290;&#20026;&#20102;&#35745;&#31639;&#26684;&#32599;&#33707;&#22827;-&#35946;&#26031;&#22810;&#22827;&#36317;&#31163;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#26368;&#23567;&#26597;&#35810;&#35780;&#20272;&#25628;&#32034;&#30001;&#24658;&#23450;&#26354;&#29575;&#27169;&#22411;&#31354;&#38388;&#20056;&#31215;&#32452;&#25104;&#30340;&#28508;&#22312;&#20960;&#20309;&#32467;&#26500;&#30340;&#21407;&#21017;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent research indicates that the performance of machine learning models can be improved by aligning the geometry of the latent space with the underlying data structure. Rather than relying solely on Euclidean space, researchers have proposed using hyperbolic and spherical spaces with constant curvature, or combinations thereof, to better model the latent space and enhance model performance. However, little attention has been given to the problem of automatically identifying the optimal latent geometry for the downstream task. We mathematically define this novel formulation and coin it as neural latent geometry search (NLGS). More specifically, we introduce a principled method that searches for a latent geometry composed of a product of constant curvature model spaces with minimal query evaluations. To accomplish this, we propose a novel notion of distance between candidate latent geometries based on the Gromov-Hausdorff distance from metric geometry. In order to compute the Gromov-Ha
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20223;&#23556;&#19981;&#21464;&#38598;&#25104;&#21464;&#25442;&#26041;&#27861;&#65292;&#21487;&#20197;&#25913;&#21892;&#22312;ReLU&#32593;&#32476;&#20013;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#12290;&#36890;&#36807;&#22522;&#20110;&#38598;&#21512;&#21345;&#23572;&#26364;&#28388;&#27874;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#20010;&#30456;&#20114;&#20316;&#29992;&#30340;&#31890;&#23376;&#31995;&#32479;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#25910;&#25947;&#24615;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#25506;&#35752;&#20102;&#36825;&#20123;&#26041;&#27861;&#29992;&#20110;&#37327;&#21270;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2309.04742</link><description>&lt;p&gt;
&#25913;&#36827;ReLU&#32593;&#32476;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#20223;&#23556;&#19981;&#21464;&#38598;&#25104;&#21464;&#25442;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Affine Invariant Ensemble Transform Methods to Improve Predictive Uncertainty in ReLU Networks. (arXiv:2309.04742v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.04742
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20223;&#23556;&#19981;&#21464;&#38598;&#25104;&#21464;&#25442;&#26041;&#27861;&#65292;&#21487;&#20197;&#25913;&#21892;&#22312;ReLU&#32593;&#32476;&#20013;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#12290;&#36890;&#36807;&#22522;&#20110;&#38598;&#21512;&#21345;&#23572;&#26364;&#28388;&#27874;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#20010;&#30456;&#20114;&#20316;&#29992;&#30340;&#31890;&#23376;&#31995;&#32479;&#65292;&#24182;&#35777;&#26126;&#20102;&#23427;&#20204;&#30340;&#25910;&#25947;&#24615;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#25506;&#35752;&#20102;&#36825;&#20123;&#26041;&#27861;&#29992;&#20110;&#37327;&#21270;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#21512;&#36866;&#30340;&#38598;&#21512;&#21345;&#23572;&#26364;&#28388;&#27874;&#30340;&#25193;&#23637;&#36827;&#34892;&#36923;&#36753;&#22238;&#24402;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#20010;&#30456;&#20114;&#20316;&#29992;&#30340;&#31890;&#23376;&#31995;&#32479;&#65292;&#20174;&#36817;&#20284;&#21518;&#39564;&#20998;&#24067;&#20013;&#37319;&#26679;&#65292;&#24182;&#35777;&#26126;&#24403;&#31890;&#23376;&#25968;&#37327;&#36235;&#20110;&#26080;&#31351;&#26102;&#65292;&#36825;&#20123;&#30456;&#20114;&#20316;&#29992;&#31890;&#23376;&#31995;&#32479;&#25910;&#25947;&#21040;&#22343;&#22330;&#26497;&#38480;&#30340;&#37327;&#21270;&#25910;&#25947;&#36895;&#29575;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24212;&#29992;&#36825;&#20123;&#25216;&#26415;&#24182;&#32771;&#23519;&#23427;&#20204;&#20316;&#20026;&#36125;&#21494;&#26031;&#36817;&#20284;&#26041;&#27861;&#22312;ReLU&#32593;&#32476;&#20013;&#37327;&#21270;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of performing Bayesian inference for logistic regression using appropriate extensions of the ensemble Kalman filter. Two interacting particle systems are proposed that sample from an approximate posterior and prove quantitative convergence rates of these interacting particle systems to their mean-field limit as the number of particles tends to infinity. Furthermore, we apply these techniques and examine their effectiveness as methods of Bayesian approximation for quantifying predictive uncertainty in ReLU networks.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#27010;&#29575;&#23433;&#20840;&#21306;&#22495;&#30340;&#27010;&#24565;&#65292;&#29992;&#20110;&#25551;&#36848;&#19968;&#20010;&#36755;&#20837;&#31354;&#38388;&#23376;&#38598;&#65292;&#22312;&#36825;&#20010;&#23376;&#38598;&#20013;&#65292;&#35823;&#20998;&#31867;&#23454;&#20363;&#30340;&#25968;&#37327;&#21487;&#20197;&#34987;&#27010;&#29575;&#19978;&#24471;&#21040;&#25511;&#21046;&#12290;&#21516;&#26102;&#65292;&#21033;&#29992;&#21487;&#20280;&#32553;&#20998;&#31867;&#22120;&#26469;&#23558;&#26426;&#22120;&#23398;&#20064;&#30340;&#35843;&#21442;&#19982;&#35823;&#24046;&#25511;&#21046;&#30456;&#32467;&#21512;&#12290;</title><link>http://arxiv.org/abs/2309.04627</link><description>&lt;p&gt;
&#20351;&#29992;&#21487;&#20280;&#32553;&#20998;&#31867;&#22120;&#30340;&#27010;&#29575;&#23433;&#20840;&#21306;&#22495;
&lt;/p&gt;
&lt;p&gt;
Probabilistic Safety Regions Via Finite Families of Scalable Classifiers. (arXiv:2309.04627v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.04627
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#27010;&#29575;&#23433;&#20840;&#21306;&#22495;&#30340;&#27010;&#24565;&#65292;&#29992;&#20110;&#25551;&#36848;&#19968;&#20010;&#36755;&#20837;&#31354;&#38388;&#23376;&#38598;&#65292;&#22312;&#36825;&#20010;&#23376;&#38598;&#20013;&#65292;&#35823;&#20998;&#31867;&#23454;&#20363;&#30340;&#25968;&#37327;&#21487;&#20197;&#34987;&#27010;&#29575;&#19978;&#24471;&#21040;&#25511;&#21046;&#12290;&#21516;&#26102;&#65292;&#21033;&#29992;&#21487;&#20280;&#32553;&#20998;&#31867;&#22120;&#26469;&#23558;&#26426;&#22120;&#23398;&#20064;&#30340;&#35843;&#21442;&#19982;&#35823;&#24046;&#25511;&#21046;&#30456;&#32467;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30417;&#30563;&#20998;&#31867;&#21487;&#20197;&#35782;&#21035;&#25968;&#25454;&#20013;&#30340;&#27169;&#24335;&#20197;&#20998;&#31163;&#19981;&#21516;&#30340;&#34892;&#20026;&#31867;&#21035;&#12290;&#28982;&#32780;&#65292;&#26426;&#22120;&#23398;&#20064;&#30340;&#25968;&#20540;&#36924;&#36817;&#24615;&#36136;&#20915;&#23450;&#20102;&#20998;&#31867;&#31639;&#27861;&#19978;&#30340;&#35823;&#24046;&#38382;&#39064;&#12290;&#25968;&#25454;&#20998;&#26512;&#24072;&#21487;&#33021;&#20250;&#36890;&#36807;&#20943;&#23567;&#26576;&#20010;&#31867;&#21035;&#30340;&#38169;&#35823;&#26469;&#22686;&#21152;&#20854;&#20182;&#31867;&#21035;&#30340;&#38169;&#35823;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#35774;&#35745;&#38454;&#27573;&#30340;&#35823;&#24046;&#25511;&#21046;&#36890;&#24120;&#20197;&#21551;&#21457;&#24335;&#30340;&#26041;&#24335;&#36827;&#34892;&#12290;&#22240;&#27492;&#65292;&#26377;&#24517;&#35201;&#21457;&#23637;&#19968;&#31181;&#29702;&#35770;&#22522;&#30784;&#65292;&#33021;&#22815;&#23545;&#33719;&#24471;&#30340;&#20998;&#31867;&#22120;&#36827;&#34892;&#27010;&#29575;&#35777;&#26126;&#12290;&#22312;&#36825;&#20010;&#35270;&#35282;&#19979;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#27010;&#29575;&#23433;&#20840;&#21306;&#22495;&#30340;&#27010;&#24565;&#65292;&#29992;&#26469;&#25551;&#36848;&#19968;&#20010;&#36755;&#20837;&#31354;&#38388;&#23376;&#38598;&#65292;&#20854;&#20013;&#35823;&#20998;&#31867;&#23454;&#20363;&#30340;&#25968;&#37327;&#21487;&#20197;&#27010;&#29575;&#19978;&#24471;&#21040;&#25511;&#21046;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#21033;&#29992;&#21487;&#20280;&#32553;&#20998;&#31867;&#22120;&#26469;&#23558;&#26426;&#22120;&#23398;&#20064;&#30340;&#35843;&#21442;&#19982;&#35823;&#24046;&#25511;&#21046;&#30456;&#32467;&#21512;&#12290;&#36890;&#36807;&#21512;&#25104;&#25968;&#25454;&#25552;&#20379;&#20102;&#22810;&#31181;&#27979;&#35797;&#26469;&#39564;&#35777;&#35813;&#26041;&#27861;&#65292;&#20197;&#31361;&#20986;&#25152;&#26377;&#27493;&#39588;&#12290;
&lt;/p&gt;
&lt;p&gt;
Supervised classification recognizes patterns in the data to separate classes of behaviours. Canonical solutions contain misclassification errors that are intrinsic to the numerical approximating nature of machine learning. The data analyst may minimize the classification error on a class at the expense of increasing the error of the other classes. The error control of such a design phase is often done in a heuristic manner. In this context, it is key to develop theoretical foundations capable of providing probabilistic certifications to the obtained classifiers. In this perspective, we introduce the concept of probabilistic safety region to describe a subset of the input space in which the number of misclassified instances is probabilistically controlled. The notion of scalable classifiers is then exploited to link the tuning of machine learning with error control. Several tests corroborate the approach. They are provided through synthetic data in order to highlight all the steps invo
&lt;/p&gt;</description></item><item><title>&#24863;&#30693;&#35843;&#25972;&#26597;&#35810;&#65288;PAQ&#65289;&#26159;&#19968;&#31181;&#26032;&#30340;&#29992;&#20110;&#25910;&#38598;&#20154;&#31867;&#21453;&#39304;&#30340;&#26597;&#35810;&#26426;&#21046;&#65292;&#37319;&#29992;&#21453;&#21521;&#27979;&#37327;&#26041;&#26696;&#65292;&#32467;&#21512;&#20102;&#22522;&#25968;&#26597;&#35810;&#21644;&#24207;&#25968;&#26597;&#35810;&#30340;&#20248;&#28857;&#12290;&#25105;&#20204;&#23558;PAQ&#24212;&#29992;&#20110;&#24230;&#37327;&#23398;&#20064;&#38382;&#39064;&#20013;&#65292;&#36890;&#36807;PAQ&#27979;&#37327;&#26469;&#23398;&#20064;&#26410;&#30693;&#30340;&#39532;&#27663;&#36317;&#31163;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#20004;&#38454;&#27573;&#20272;&#35745;&#22120;&#65292;&#25552;&#20379;&#20102;&#26679;&#26412;&#22797;&#26434;&#24615;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2309.04626</link><description>&lt;p&gt;
&#20302;&#31209;&#24230;&#24230;&#37327;&#23398;&#20064;&#20013;&#30340;&#24863;&#30693;&#35843;&#25972;&#26597;&#35810;&#21644;&#21453;&#21521;&#27979;&#37327;&#33539;&#24335;
&lt;/p&gt;
&lt;p&gt;
Perceptual adjustment queries and an inverted measurement paradigm for low-rank metric learning. (arXiv:2309.04626v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.04626
&lt;/p&gt;
&lt;p&gt;
&#24863;&#30693;&#35843;&#25972;&#26597;&#35810;&#65288;PAQ&#65289;&#26159;&#19968;&#31181;&#26032;&#30340;&#29992;&#20110;&#25910;&#38598;&#20154;&#31867;&#21453;&#39304;&#30340;&#26597;&#35810;&#26426;&#21046;&#65292;&#37319;&#29992;&#21453;&#21521;&#27979;&#37327;&#26041;&#26696;&#65292;&#32467;&#21512;&#20102;&#22522;&#25968;&#26597;&#35810;&#21644;&#24207;&#25968;&#26597;&#35810;&#30340;&#20248;&#28857;&#12290;&#25105;&#20204;&#23558;PAQ&#24212;&#29992;&#20110;&#24230;&#37327;&#23398;&#20064;&#38382;&#39064;&#20013;&#65292;&#36890;&#36807;PAQ&#27979;&#37327;&#26469;&#23398;&#20064;&#26410;&#30693;&#30340;&#39532;&#27663;&#36317;&#31163;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#20004;&#38454;&#27573;&#20272;&#35745;&#22120;&#65292;&#25552;&#20379;&#20102;&#26679;&#26412;&#22797;&#26434;&#24615;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#29992;&#20110;&#25910;&#38598;&#20154;&#31867;&#21453;&#39304;&#30340;&#26597;&#35810;&#26426;&#21046;&#65292;&#31216;&#20026;&#24863;&#30693;&#35843;&#25972;&#26597;&#35810;&#65288;PAQ&#65289;&#12290;PAQ&#37319;&#29992;&#20102;&#21453;&#21521;&#27979;&#37327;&#26041;&#26696;&#65292;&#26082;&#20855;&#26377;&#20449;&#24687;&#37327;&#21448;&#36731;&#37327;&#32423;&#65292;&#32467;&#21512;&#20102;&#22522;&#25968;&#26597;&#35810;&#21644;&#24207;&#25968;&#26597;&#35810;&#30340;&#20248;&#28857;&#12290;&#25105;&#20204;&#23558;PAQ&#23637;&#31034;&#22312;&#24230;&#37327;&#23398;&#20064;&#38382;&#39064;&#20013;&#65292;&#21033;&#29992;PAQ&#27979;&#37327;&#26469;&#23398;&#20064;&#26410;&#30693;&#30340;&#39532;&#27663;&#36317;&#31163;&#12290;&#36825;&#23548;&#33268;&#20102;&#19968;&#20010;&#39640;&#32500;&#20302;&#31209;&#30697;&#38453;&#20272;&#35745;&#38382;&#39064;&#65292;&#26080;&#27861;&#24212;&#29992;&#26631;&#20934;&#30697;&#38453;&#20272;&#35745;&#22120;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#20174;PAQ&#20013;&#23398;&#20064;&#24230;&#37327;&#30340;&#20004;&#38454;&#27573;&#20272;&#35745;&#22120;&#65292;&#24182;&#25552;&#20379;&#20102;&#35813;&#20272;&#35745;&#22120;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#20445;&#35777;&#12290;&#25105;&#20204;&#36890;&#36807;&#25968;&#20540;&#27169;&#25311;&#23637;&#31034;&#20102;&#35813;&#20272;&#35745;&#22120;&#30340;&#24615;&#33021;&#21644;&#26174;&#33879;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a new type of query mechanism for collecting human feedback, called the perceptual adjustment query ( PAQ). Being both informative and cognitively lightweight, the PAQ adopts an inverted measurement scheme, and combines advantages from both cardinal and ordinal queries. We showcase the PAQ in the metric learning problem, where we collect PAQ measurements to learn an unknown Mahalanobis distance. This gives rise to a high-dimensional, low-rank matrix estimation problem to which standard matrix estimators cannot be applied. Consequently, we develop a two-stage estimator for metric learning from PAQs, and provide sample complexity guarantees for this estimator. We present numerical simulations demonstrating the performance of the estimator and its notable properties.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#20351;&#29992;&#36335;&#24452;&#31614;&#21517;&#26469;&#29983;&#25104;&#36924;&#36817;&#23454;&#38469;&#25968;&#25454;&#30340;&#37329;&#34701;&#20215;&#26684;&#36335;&#24452;&#65292;&#24182;&#24212;&#29992;&#20110;&#23450;&#20215;&#22238;&#25764;&#20445;&#38505;&#26399;&#26435;&#21644;&#25237;&#36164;&#32452;&#21512;&#22238;&#25764;&#25511;&#21046;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2309.04507</link><description>&lt;p&gt;
&#20351;&#29992;&#36335;&#24452;&#31614;&#21517;&#29983;&#25104;&#36924;&#36817;&#23454;&#38469;&#25968;&#25454;&#30340;&#37329;&#34701;&#20215;&#26684;&#36335;&#24452;
&lt;/p&gt;
&lt;p&gt;
Generating drawdown-realistic financial price paths using path signatures. (arXiv:2309.04507v1 [q-fin.CP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.04507
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#20351;&#29992;&#36335;&#24452;&#31614;&#21517;&#26469;&#29983;&#25104;&#36924;&#36817;&#23454;&#38469;&#25968;&#25454;&#30340;&#37329;&#34701;&#20215;&#26684;&#36335;&#24452;&#65292;&#24182;&#24212;&#29992;&#20110;&#23450;&#20215;&#22238;&#25764;&#20445;&#38505;&#26399;&#26435;&#21644;&#25237;&#36164;&#32452;&#21512;&#22238;&#25764;&#25511;&#21046;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29983;&#25104;&#24335;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#27169;&#25311;&#20855;&#26377;&#25509;&#36817;&#23454;&#38469;&#25968;&#25454;&#30340;&#22238;&#25764;&#30340;&#37329;&#34701;&#20215;&#26684;&#24207;&#21015;&#12290;&#24212;&#29992;&#22330;&#26223;&#22914;&#23450;&#20215;&#22238;&#25764;&#20445;&#38505;&#26399;&#26435;&#25110;&#24320;&#21457;&#25237;&#36164;&#32452;&#21512;&#22238;&#25764;&#25511;&#21046;&#31574;&#30053;&#38656;&#35201;&#20351;&#29992;&#25509;&#36817;&#30495;&#23454;&#30340;&#22238;&#25764;&#36335;&#24452;&#12290;&#21382;&#21490;&#24773;&#26223;&#21487;&#33021;&#19981;&#36275;&#20197;&#26377;&#25928;&#35757;&#32451;&#21644;&#22238;&#27979;&#31574;&#30053;&#65292;&#32780;&#26631;&#20934;&#30340;&#21442;&#25968;&#21270;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#26080;&#27861;&#20805;&#20998;&#20445;&#30041;&#22238;&#25764;&#12290;&#25105;&#20204;&#25552;&#20513;&#19968;&#31181;&#38750;&#21442;&#25968;&#21270;&#33945;&#29305;&#21345;&#32599;&#26041;&#27861;&#65292;&#23558;&#21464;&#20998;&#33258;&#32534;&#30721;&#29983;&#25104;&#27169;&#22411;&#19982;&#22238;&#25764;&#37325;&#24314;&#25439;&#22833;&#20989;&#25968;&#30456;&#32467;&#21512;&#12290;&#20026;&#20102;&#20811;&#26381;&#25968;&#20540;&#22797;&#26434;&#24615;&#21644;&#38750;&#21487;&#24494;&#24615;&#38382;&#39064;&#65292;&#25105;&#20204;&#23558;&#22238;&#25764;&#36817;&#20284;&#20026;&#36335;&#24452;&#30340;&#30697;&#20989;&#25968;&#65292;&#21363;&#36335;&#24452;&#31614;&#21517;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22238;&#25764;&#20989;&#25968;&#30340;&#25152;&#38656;&#27491;&#21017;&#24615;&#21644;&#36817;&#20284;&#30340;&#19968;&#33268;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20351;&#29992;&#32447;&#24615;&#22238;&#24402;&#33719;&#24471;&#20102;&#25509;&#36817;&#30340;&#25968;&#20540;&#36817;&#20284;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
A novel generative machine learning approach for the simulation of sequences of financial price data with drawdowns quantifiably close to empirical data is introduced. Applications such as pricing drawdown insurance options or developing portfolio drawdown control strategies call for a host of drawdown-realistic paths. Historical scenarios may be insufficient to effectively train and backtest the strategy, while standard parametric Monte Carlo does not adequately preserve drawdowns. We advocate a non-parametric Monte Carlo approach combining a variational autoencoder generative model with a drawdown reconstruction loss function. To overcome issues of numerical complexity and non-differentiability, we approximate drawdown as a linear function of the moments of the path, known in the literature as path signatures. We prove the required regularity of drawdown function and consistency of the approximation. Furthermore, we obtain close numerical approximations using linear regression for fr
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#35889;&#26041;&#27861;&#25913;&#36827;&#20102;&#25490;&#21517;&#32858;&#21512;&#38382;&#39064;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#36890;&#36807;&#30740;&#31350;&#22522;&#20110;&#26410;&#24402;&#19968;&#21270;&#21644;&#24402;&#19968;&#21270;&#25968;&#25454;&#30697;&#38453;&#30340;&#35889;&#25490;&#21517;&#31639;&#27861;&#65292;&#25552;&#20379;&#20102;&#26356;&#20934;&#30830;&#30340;&#25200;&#21160;&#35823;&#24046;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2309.03808</link><description>&lt;p&gt;
&#36890;&#36807;&#35889;&#26041;&#27861;&#25913;&#36827;&#20102;&#25490;&#21517;&#32858;&#21512;&#30340;&#29702;&#35770;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Improved theoretical guarantee for rank aggregation via spectral method. (arXiv:2309.03808v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.03808
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#35889;&#26041;&#27861;&#25913;&#36827;&#20102;&#25490;&#21517;&#32858;&#21512;&#38382;&#39064;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#36890;&#36807;&#30740;&#31350;&#22522;&#20110;&#26410;&#24402;&#19968;&#21270;&#21644;&#24402;&#19968;&#21270;&#25968;&#25454;&#30697;&#38453;&#30340;&#35889;&#25490;&#21517;&#31639;&#27861;&#65292;&#25552;&#20379;&#20102;&#26356;&#20934;&#30830;&#30340;&#25200;&#21160;&#35823;&#24046;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32473;&#23450;&#22810;&#20010;&#39033;&#30446;&#20043;&#38388;&#30340;&#25104;&#23545;&#27604;&#36739;&#65292;&#22914;&#20309;&#23545;&#23427;&#20204;&#36827;&#34892;&#25490;&#21517;&#20197;&#20351;&#24471;&#25490;&#21517;&#19982;&#35266;&#23519;&#30456;&#21305;&#37197;&#65311;&#36825;&#20010;&#38382;&#39064;&#34987;&#31216;&#20026;&#25490;&#21517;&#32858;&#21512;&#65292;&#22312;&#20307;&#32946;&#12289;&#25512;&#33616;&#31995;&#32479;&#21644;&#20854;&#20182;&#32593;&#32476;&#24212;&#29992;&#20013;&#24050;&#32463;&#25214;&#21040;&#20102;&#35768;&#22810;&#24212;&#29992;&#12290;&#30001;&#20110;&#25214;&#21040;&#26368;&#23567;&#21270;&#19981;&#21305;&#37197;&#30340;&#20840;&#23616;&#25490;&#21517;&#36890;&#24120;&#26159;NP&#22256;&#38590;&#30340;&#65288;&#31216;&#20026;Kemeny&#20248;&#21270;&#65289;&#65292;&#25105;&#20204;&#23558;&#37325;&#28857;&#25918;&#22312;Erd\"os-R\'enyi&#31163;&#32676;&#28857;&#65288;ERO&#65289;&#27169;&#22411;&#19978;&#12290;&#22312;&#36825;&#20010;&#25490;&#21517;&#38382;&#39064;&#20013;&#65292;&#27599;&#20010;&#25104;&#23545;&#27604;&#36739;&#26159;&#30495;&#23454;&#20998;&#25968;&#24046;&#24322;&#30340;&#34987;&#25439;&#22351;&#21103;&#26412;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#22522;&#20110;&#26410;&#24402;&#19968;&#21270;&#21644;&#24402;&#19968;&#21270;&#25968;&#25454;&#30697;&#38453;&#30340;&#35889;&#25490;&#21517;&#31639;&#27861;&#12290;&#20851;&#38190;&#26159;&#29702;&#35299;&#23427;&#20204;&#22312;&#20174;&#35266;&#23519;&#25968;&#25454;&#20013;&#24674;&#22797;&#27599;&#20010;&#39033;&#30446;&#30340;&#28508;&#22312;&#20998;&#25968;&#26041;&#38754;&#30340;&#24615;&#33021;&#12290;&#36825;&#24402;&#32467;&#20026;&#25512;&#23548;&#26410;&#24402;&#19968;&#21270;/&#24402;&#19968;&#21270;&#25968;&#25454;&#30697;&#38453;&#30340;&#21069;&#20960;&#20010;&#29305;&#24449;&#21521;&#37327;&#21644;&#20854;&#24635;&#20307;&#23545;&#24212;&#29289;&#20043;&#38388;&#30340;&#36880;&#20010;&#39033;&#25200;&#21160;&#35823;&#24046;&#30028;&#38480;&#12290;&#36890;&#36807;&#20351;&#29992;&#30041;&#20986;&#25216;&#26415;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#26356;&#20934;&#30830;&#30340;$\ell_{\infty}$-norm&#25200;&#21160;&#35823;&#24046;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
Given pairwise comparisons between multiple items, how to rank them so that the ranking matches the observations? This problem, known as rank aggregation, has found many applications in sports, recommendation systems, and other web applications. As it is generally NP-hard to find a global ranking that minimizes the mismatch (known as the Kemeny optimization), we focus on the Erd\"os-R\'enyi outliers (ERO) model for this ranking problem. Here, each pairwise comparison is a corrupted copy of the true score difference. We investigate spectral ranking algorithms that are based on unnormalized and normalized data matrices. The key is to understand their performance in recovering the underlying scores of each item from the observed data. This reduces to deriving an entry-wise perturbation error bound between the top eigenvectors of the unnormalized/normalized data matrix and its population counterpart. By using the leave-one-out technique, we provide a sharper $\ell_{\infty}$-norm perturbati
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20027;&#35201;&#20197;&#26080;&#31351;&#23485;&#24230;&#21644;&#22823;&#23485;&#24230;&#33539;&#22260;&#20869;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20026;&#30740;&#31350;&#23545;&#35937;&#65292;&#35752;&#35770;&#20102;&#36825;&#20123;&#32593;&#32476;&#30340;&#21508;&#31181;&#32479;&#35745;&#21644;&#21160;&#21147;&#23398;&#29305;&#24615;&#65292;&#21253;&#25324;&#38543;&#26426;&#32593;&#32476;&#30340;&#24615;&#36136;&#12289;&#35757;&#32451;&#21518;&#30340;&#32593;&#32476;&#19982;&#32447;&#24615;&#27169;&#22411;&#12289;&#26680;&#20989;&#25968;&#21644;&#39640;&#26031;&#36807;&#31243;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#20197;&#21450;&#23545;&#22823;&#20294;&#26377;&#38480;&#23485;&#24230;&#32593;&#32476;&#22312;&#21021;&#22987;&#21270;&#21644;&#35757;&#32451;&#21518;&#30340;&#25668;&#21160;&#21644;&#38750;&#25668;&#21160;&#22788;&#29702;&#12290;</title><link>http://arxiv.org/abs/2309.01592</link><description>&lt;p&gt;
&#22823;&#23610;&#24230;&#21644;&#26080;&#31351;&#23485;&#24230;&#19979;&#30340;&#28145;&#24230;&#23398;&#20064;&#21202;&#35753;&#28436;&#35762;
&lt;/p&gt;
&lt;p&gt;
Les Houches Lectures on Deep Learning at Large &amp; Infinite Width. (arXiv:2309.01592v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.01592
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20027;&#35201;&#20197;&#26080;&#31351;&#23485;&#24230;&#21644;&#22823;&#23485;&#24230;&#33539;&#22260;&#20869;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20026;&#30740;&#31350;&#23545;&#35937;&#65292;&#35752;&#35770;&#20102;&#36825;&#20123;&#32593;&#32476;&#30340;&#21508;&#31181;&#32479;&#35745;&#21644;&#21160;&#21147;&#23398;&#29305;&#24615;&#65292;&#21253;&#25324;&#38543;&#26426;&#32593;&#32476;&#30340;&#24615;&#36136;&#12289;&#35757;&#32451;&#21518;&#30340;&#32593;&#32476;&#19982;&#32447;&#24615;&#27169;&#22411;&#12289;&#26680;&#20989;&#25968;&#21644;&#39640;&#26031;&#36807;&#31243;&#20043;&#38388;&#30340;&#20851;&#31995;&#65292;&#20197;&#21450;&#23545;&#22823;&#20294;&#26377;&#38480;&#23485;&#24230;&#32593;&#32476;&#22312;&#21021;&#22987;&#21270;&#21644;&#35757;&#32451;&#21518;&#30340;&#25668;&#21160;&#21644;&#38750;&#25668;&#21160;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36825;&#20123;&#28436;&#35762;&#26159;&#22312;2022&#24180;&#21202;&#35753;&#22799;&#23395;&#23398;&#26657;&#32479;&#35745;&#29289;&#29702;&#21644;&#26426;&#22120;&#23398;&#20064;&#35838;&#31243;&#19978;&#23637;&#31034;&#30340;&#65292;&#30528;&#37325;&#25506;&#35752;&#20102;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#26080;&#38480;&#23485;&#24230;&#21644;&#22823;&#23485;&#24230;&#33539;&#22260;&#20869;&#30340;&#24773;&#20917;&#12290;&#28085;&#30422;&#30340;&#20027;&#39064;&#21253;&#25324;&#36825;&#20123;&#32593;&#32476;&#30340;&#21508;&#31181;&#32479;&#35745;&#21644;&#21160;&#21147;&#23398;&#29305;&#24615;&#12290;&#29305;&#21035;&#26159;&#65292;&#35762;&#24072;&#20204;&#35752;&#35770;&#20102;&#38543;&#26426;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#29305;&#24615;&#65307;&#35757;&#32451;&#36807;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65292;&#32447;&#24615;&#27169;&#22411;&#65292;&#26680;&#20989;&#25968;&#21644;&#39640;&#26031;&#36807;&#31243;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#36825;&#20123;&#32852;&#31995;&#22312;&#26080;&#31351;&#23485;&#24230;&#30340;&#26497;&#38480;&#19979;&#20986;&#29616;&#65307;&#20197;&#21450;&#22312;&#21021;&#22987;&#21270;&#21644;&#35757;&#32451;&#21518;&#23545;&#22823;&#20294;&#26377;&#38480;&#23485;&#24230;&#32593;&#32476;&#30340;&#25668;&#21160;&#21644;&#38750;&#25668;&#21160;&#22788;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
These lectures, presented at the 2022 Les Houches Summer School on Statistical Physics and Machine Learning, focus on the infinite-width limit and large-width regime of deep neural networks. Topics covered include various statistical and dynamical properties of these networks. In particular, the lecturers discuss properties of random deep neural networks; connections between trained deep neural networks, linear models, kernels, and Gaussian processes that arise in the infinite-width limit; and perturbative and non-perturbative treatments of large but finite-width networks, at initialization and after training.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32452;&#21512;&#22238;&#24402;&#30340;&#26465;&#20214;&#29983;&#23384;&#39044;&#27979;&#26041;&#27861;&#65292;&#20854;&#20013;&#20351;&#29992;&#38754;&#31215;&#20316;&#20026;&#30456;&#20284;&#24230;&#24230;&#37327;&#65292;&#36890;&#36807;&#36873;&#25321;&#26368;&#37325;&#35201;&#30340;&#21464;&#37327;&#26469;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2309.00417</link><description>&lt;p&gt;
&#26465;&#20214;&#29983;&#23384;&#39044;&#27979;&#20013;&#30340;&#38754;&#31215;&#35268;&#33539;COBRA
&lt;/p&gt;
&lt;p&gt;
Area-norm COBRA on Conditional Survival Prediction. (arXiv:2309.00417v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.00417
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#32452;&#21512;&#22238;&#24402;&#30340;&#26465;&#20214;&#29983;&#23384;&#39044;&#27979;&#26041;&#27861;&#65292;&#20854;&#20013;&#20351;&#29992;&#38754;&#31215;&#20316;&#20026;&#30456;&#20284;&#24230;&#24230;&#37327;&#65292;&#36890;&#36807;&#36873;&#25321;&#26368;&#37325;&#35201;&#30340;&#21464;&#37327;&#26469;&#25552;&#39640;&#27169;&#22411;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#19968;&#31181;&#19981;&#21516;&#30340;&#32452;&#21512;&#22238;&#24402;&#31574;&#30053;&#26469;&#35745;&#31639;&#26465;&#20214;&#29983;&#23384;&#20989;&#25968;&#12290;&#25105;&#20204;&#20351;&#29992;&#22522;&#20110;&#22238;&#24402;&#30340;&#24369;&#23398;&#20064;&#22120;&#26469;&#21019;&#24314;&#25152;&#25552;&#20986;&#30340;&#38598;&#25104;&#25216;&#26415;&#12290;&#25152;&#25552;&#20986;&#30340;&#32452;&#21512;&#22238;&#24402;&#31574;&#30053;&#20351;&#29992;&#30456;&#20284;&#24230;&#24230;&#37327;&#20316;&#20026;&#20004;&#20010;&#29983;&#23384;&#26354;&#32447;&#20043;&#38388;&#30340;&#38754;&#31215;&#12290;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#34920;&#26126;&#20854;&#34920;&#29616;&#20248;&#20110;&#38543;&#26426;&#29983;&#23384;&#26862;&#26519;&#12290;&#26412;&#25991;&#35752;&#35770;&#20102;&#19968;&#31181;&#22312;&#32452;&#21512;&#22238;&#24402;&#35774;&#32622;&#20013;&#36873;&#25321;&#26368;&#37325;&#35201;&#21464;&#37327;&#30340;&#26032;&#25216;&#26415;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#19968;&#39033;&#27169;&#25311;&#30740;&#31350;&#65292;&#34920;&#26126;&#25105;&#20204;&#23545;&#21464;&#37327;&#30456;&#20851;&#24615;&#30340;&#25552;&#35758;&#25928;&#26524;&#24456;&#22909;&#12290;&#25105;&#20204;&#36824;&#20351;&#29992;&#20102;&#19977;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#26469;&#35828;&#26126;&#35813;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
The paper explores a different variation of combined regression strategy to calculate the conditional survival function. We use regression based weak learners to create the proposed ensemble technique. The proposed combined regression strategy uses proximity measure as area between two survival curves. The proposed model shows a construction which ensures that it performs better than the Random Survival Forest. The paper discusses a novel technique to select the most important variable in the combined regression setup. We perform a simulation study to show that our proposition for finding relevance of the variables works quite well. We also use three real-life datasets to illustrate the model.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#29256;&#30340;GentleAdaboost&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#32447;&#26041;&#24335;&#23558;&#24369;&#20998;&#31867;&#22120;&#19982;&#24378;&#20998;&#31867;&#22120;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#32447;&#25628;&#32034;&#23558;&#25209;&#22788;&#29702;&#26041;&#27861;&#25193;&#23637;&#20026;&#22312;&#32447;&#26041;&#27861;&#30340;&#26041;&#27861;&#65292;&#24182;&#19982;&#20854;&#20182;&#22312;&#32447;&#26041;&#27861;&#22312;&#21508;&#31181;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23545;&#27604;&#12290;</title><link>http://arxiv.org/abs/2308.14004</link><description>&lt;p&gt;
&#22312;&#32447;GentleAdaBoost -- &#25216;&#26415;&#25253;&#21578;
&lt;/p&gt;
&lt;p&gt;
Online GentleAdaBoost -- Technical Report. (arXiv:2308.14004v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14004
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#32447;&#29256;&#30340;GentleAdaboost&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#32447;&#26041;&#24335;&#23558;&#24369;&#20998;&#31867;&#22120;&#19982;&#24378;&#20998;&#31867;&#22120;&#32467;&#21512;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#32447;&#25628;&#32034;&#23558;&#25209;&#22788;&#29702;&#26041;&#27861;&#25193;&#23637;&#20026;&#22312;&#32447;&#26041;&#27861;&#30340;&#26041;&#27861;&#65292;&#24182;&#19982;&#20854;&#20182;&#22312;&#32447;&#26041;&#27861;&#22312;&#21508;&#31181;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#23545;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32447;&#29256;&#30340;GentleAdaboost&#65292;&#20854;&#20013;&#25105;&#20204;&#20197;&#22312;&#32447;&#26041;&#24335;&#23558;&#19968;&#20010;&#24369;&#20998;&#31867;&#22120;&#19982;&#19968;&#20010;&#24378;&#20998;&#31867;&#22120;&#32467;&#21512;&#36215;&#26469;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#36890;&#36807;&#32447;&#25628;&#32034;&#24212;&#29992;&#30340;&#26041;&#27861;&#65292;&#23558;&#25209;&#22788;&#29702;&#26041;&#27861;&#25193;&#23637;&#20026;&#22312;&#32447;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#29702;&#35770;&#35777;&#26126;&#20102;&#20854;&#27491;&#30830;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#22312;&#21508;&#31181;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#27604;&#36739;&#20102;&#25105;&#20204;&#30340;&#22312;&#32447;boosting&#26041;&#27861;&#19982;&#20854;&#20182;&#22312;&#32447;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the online variant of GentleAdaboost, where we combine a weak learner to a strong learner in an online fashion. We provide an approach to extend the batch approach to an online approach with theoretical justifications through application of line search. Finally we compare our online boosting approach with other online approaches across a variety of benchmark datasets.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22823;&#35268;&#27169;&#32972;&#26223;&#22270;&#20013;&#26597;&#25214;&#22810;&#20010;&#23884;&#20837;&#30340;&#27169;&#26495;&#22270;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#36845;&#20195;&#24809;&#32602;&#30456;&#20284;&#24230;&#30697;&#38453;&#26469;&#23454;&#29616;&#22810;&#26679;&#21270;&#21305;&#37197;&#30340;&#21457;&#29616;&#65292;&#24182;&#25552;&#20986;&#20102;&#31639;&#27861;&#21152;&#36895;&#25514;&#26045;&#12290;&#22312;&#29702;&#35770;&#39564;&#35777;&#21644;&#23454;&#39564;&#35777;&#26126;&#20013;&#65292;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#21487;&#34892;&#24615;&#21644;&#23454;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.13451</link><description>&lt;p&gt;
&#25235;&#20303;&#23427;&#20204;&#65306;&#22270;&#21305;&#37197;&#21305;&#37197;&#28388;&#27874;&#20013;&#30340;&#35299;&#20915;&#26041;&#26696;&#22810;&#26679;&#21270;
&lt;/p&gt;
&lt;p&gt;
Gotta match 'em all: Solution diversification in graph matching matched filters. (arXiv:2308.13451v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13451
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22823;&#35268;&#27169;&#32972;&#26223;&#22270;&#20013;&#26597;&#25214;&#22810;&#20010;&#23884;&#20837;&#30340;&#27169;&#26495;&#22270;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#36845;&#20195;&#24809;&#32602;&#30456;&#20284;&#24230;&#30697;&#38453;&#26469;&#23454;&#29616;&#22810;&#26679;&#21270;&#21305;&#37197;&#30340;&#21457;&#29616;&#65292;&#24182;&#25552;&#20986;&#20102;&#31639;&#27861;&#21152;&#36895;&#25514;&#26045;&#12290;&#22312;&#29702;&#35770;&#39564;&#35777;&#21644;&#23454;&#39564;&#35777;&#26126;&#20013;&#65292;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#21487;&#34892;&#24615;&#21644;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#38750;&#24120;&#22823;&#30340;&#32972;&#26223;&#22270;&#20013;&#26597;&#25214;&#22810;&#20010;&#23884;&#20837;&#22312;&#20854;&#20013;&#30340;&#27169;&#26495;&#22270;&#30340;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;Sussman&#31561;&#20154;&#25552;&#20986;&#30340;&#22270;&#21305;&#37197;&#21305;&#37197;&#28388;&#27874;&#25216;&#26415;&#65292;&#36890;&#36807;&#22312;&#21305;&#37197;&#28388;&#27874;&#31639;&#27861;&#20013;&#36845;&#20195;&#22320;&#24809;&#32602;&#21512;&#36866;&#30340;&#33410;&#28857;&#23545;&#30456;&#20284;&#24230;&#30697;&#38453;&#26469;&#23454;&#29616;&#22810;&#26679;&#21270;&#21305;&#37197;&#30340;&#21457;&#29616;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31639;&#27861;&#21152;&#36895;&#65292;&#26497;&#22823;&#22320;&#25552;&#39640;&#20102;&#25105;&#20204;&#30340;&#21305;&#37197;&#28388;&#27874;&#26041;&#27861;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;&#25105;&#20204;&#22312;&#30456;&#20851;&#30340;Erdos-Renyi&#22270;&#35774;&#32622;&#20013;&#23545;&#25105;&#20204;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#29702;&#35770;&#19978;&#30340;&#39564;&#35777;&#65292;&#26174;&#31034;&#20854;&#22312;&#28201;&#21644;&#30340;&#27169;&#22411;&#26465;&#20214;&#19979;&#33021;&#22815;&#39034;&#24207;&#22320;&#21457;&#29616;&#22810;&#20010;&#27169;&#26495;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#20351;&#29992;&#27169;&#25311;&#27169;&#22411;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#65288;&#21253;&#25324;&#20154;&#33041;&#36830;&#25509;&#32452;&#21644;&#22823;&#22411;&#20132;&#26131;&#30693;&#35782;&#24211;&#65289;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a novel approach for finding multiple noisily embedded template graphs in a very large background graph. Our method builds upon the graph-matching-matched-filter technique proposed in Sussman et al., with the discovery of multiple diverse matchings being achieved by iteratively penalizing a suitable node-pair similarity matrix in the matched filter algorithm. In addition, we propose algorithmic speed-ups that greatly enhance the scalability of our matched-filter approach. We present theoretical justification of our methodology in the setting of correlated Erdos-Renyi graphs, showing its ability to sequentially discover multiple templates under mild model conditions. We additionally demonstrate our method's utility via extensive experiments both using simulated models and real-world dataset, include human brain connectomes and a large transactional knowledge base.
&lt;/p&gt;</description></item><item><title>SciRE-Solver&#26159;&#19968;&#31181;&#39640;&#25928;&#30340;&#37319;&#26679;&#22120;&#65292;&#36890;&#36807;&#24341;&#20837;&#24471;&#20998;&#31215;&#20998;&#27714;&#35299;&#22120;&#21644;&#36882;&#24402;&#23548;&#25968;&#20272;&#35745;&#26041;&#27861;&#65292;&#23427;&#35299;&#20915;&#20102;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#37319;&#26679;&#36807;&#31243;&#32531;&#24930;&#30340;&#25361;&#25112;&#65292;&#24182;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#37319;&#26679;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2308.07896</link><description>&lt;p&gt;
SciRE-Solver: &#29992;&#24471;&#20998;&#31215;&#20998;&#27714;&#35299;&#22120;&#21644;&#36882;&#24402;&#23548;&#25968;&#20272;&#35745;&#24555;&#36895;&#37319;&#26679;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
SciRE-Solver: Efficient Sampling of Diffusion Probabilistic Models by Score-integrand Solver with Recursive Derivative Estimation. (arXiv:2308.07896v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.07896
&lt;/p&gt;
&lt;p&gt;
SciRE-Solver&#26159;&#19968;&#31181;&#39640;&#25928;&#30340;&#37319;&#26679;&#22120;&#65292;&#36890;&#36807;&#24341;&#20837;&#24471;&#20998;&#31215;&#20998;&#27714;&#35299;&#22120;&#21644;&#36882;&#24402;&#23548;&#25968;&#20272;&#35745;&#26041;&#27861;&#65292;&#23427;&#35299;&#20915;&#20102;&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;&#37319;&#26679;&#36807;&#31243;&#32531;&#24930;&#30340;&#25361;&#25112;&#65292;&#24182;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#37319;&#26679;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25193;&#25955;&#27010;&#29575;&#27169;&#22411;(DPMs)&#26159;&#19968;&#31867;&#24378;&#22823;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;&#20197;&#20854;&#29983;&#25104;&#39640;&#20445;&#30495;&#22270;&#20687;&#26679;&#26412;&#30340;&#33021;&#21147;&#32780;&#38395;&#21517;&#12290;DPMs&#30340;&#23454;&#29616;&#38754;&#20020;&#30340;&#20027;&#35201;&#25361;&#25112;&#26159;&#37319;&#26679;&#36807;&#31243;&#32531;&#24930;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;DPMs&#37319;&#26679;&#22120;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#38024;&#23545;&#19982;DPMs&#37319;&#26679;&#36807;&#31243;&#23545;&#24212;&#30340;&#25193;&#25955;ODE&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#24471;&#20998;&#30340;&#31934;&#30830;&#35299;&#20915;&#26041;&#26696;&#33539;&#24335;&#65292;&#35813;&#33539;&#24335;&#20026;&#27714;&#35299;&#25193;&#25955;ODE&#30340;&#25968;&#20540;&#31639;&#27861;&#24320;&#21457;&#25552;&#20379;&#20102;&#26032;&#30340;&#35270;&#35282;&#12290;&#20026;&#20102;&#23454;&#29616;&#39640;&#25928;&#30340;&#37319;&#26679;&#22120;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36882;&#24402;&#23548;&#25968;&#20272;&#35745;(RDE)&#26041;&#27861;&#26469;&#20943;&#23567;&#20272;&#35745;&#35823;&#24046;&#12290;&#36890;&#36807;&#25105;&#20204;&#25552;&#20986;&#30340;&#35299;&#20915;&#26041;&#26696;&#33539;&#24335;&#21644;RDE&#26041;&#27861;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20855;&#26377;&#25910;&#25947;&#39034;&#24207;&#20445;&#35777;&#30340;&#24471;&#20998;&#31215;&#20998;&#27714;&#35299;&#22120;(SciRE-Solver)&#26469;&#35299;&#20915;&#25193;&#25955;ODEs&#12290;SciRE-Solver&#22312;&#31163;&#25955;&#26102;&#38388;&#21644;&#36830;&#32493;&#26102;&#38388;DPMs&#19978;&#33719;&#24471;&#20102;&#26368;&#20808;&#36827;&#30340;&#37319;&#26679;&#24615;&#33021;&#65292;&#24182;&#19988;&#20165;&#38656;&#26377;&#38480;&#25968;&#37327;&#30340;&#24471;&#20998;&#20989;&#25968;&#35780;&#20272;(NFE)&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion probabilistic models (DPMs) are a powerful class of generative models known for their ability to generate high-fidelity image samples. A major challenge in the implementation of DPMs is the slow sampling process. In this work, we bring a high-efficiency sampler for DPMs. Specifically, we propose a score-based exact solution paradigm for the diffusion ODEs corresponding to the sampling process of DPMs, which introduces a new perspective on developing numerical algorithms for solving diffusion ODEs. To achieve an efficient sampler, we propose a recursive derivative estimation (RDE) method to reduce the estimation error. With our proposed solution paradigm and RDE method, we propose the score-integrand solver with the convergence order guarantee as efficient solver (SciRE-Solver) for solving diffusion ODEs. The SciRE-Solver attains state-of-the-art (SOTA) sampling performance with a limited number of score function evaluations (NFE) on both discrete-time and continuous-time DPMs
&lt;/p&gt;</description></item><item><title>InVAErt&#32593;&#32476;&#26159;&#19968;&#20010;&#25968;&#25454;&#39537;&#21160;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#20998;&#26512;&#21644;&#21512;&#25104;&#29289;&#29702;&#31995;&#32479;&#65292;&#20855;&#26377;&#27169;&#22411;&#21453;&#28436;&#21644;&#21487;&#35782;&#21035;&#24615;&#20998;&#26512;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2307.12586</link><description>&lt;p&gt;
InVAErt&#32593;&#32476;&#65306;&#19968;&#20010;&#25968;&#25454;&#39537;&#21160;&#30340;&#26694;&#26550;&#29992;&#20110;&#20223;&#30495;&#12289;&#25512;&#29702;&#21644;&#21487;&#35782;&#21035;&#24615;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
InVAErt networks: a data-driven framework for emulation, inference and identifiability analysis. (arXiv:2307.12586v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.12586
&lt;/p&gt;
&lt;p&gt;
InVAErt&#32593;&#32476;&#26159;&#19968;&#20010;&#25968;&#25454;&#39537;&#21160;&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#20998;&#26512;&#21644;&#21512;&#25104;&#29289;&#29702;&#31995;&#32479;&#65292;&#20855;&#26377;&#27169;&#22411;&#21453;&#28436;&#21644;&#21487;&#35782;&#21035;&#24615;&#20998;&#26512;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#21069;&#65292;&#22522;&#20110;&#29289;&#29702;&#30340;&#31995;&#32479;&#20351;&#29992;&#29983;&#25104;&#27169;&#22411;&#21644;&#28145;&#24230;&#23398;&#20064;&#20027;&#35201;&#29992;&#20110;&#20223;&#30495;&#20219;&#21153;&#12290;&#28982;&#32780;&#65292;&#25968;&#25454;&#39537;&#21160;&#32467;&#26500;&#25552;&#20379;&#30340;&#20986;&#33394;&#28789;&#27963;&#24615;&#34920;&#26126;&#24212;&#23558;&#35813;&#34920;&#31034;&#25193;&#23637;&#21040;&#31995;&#32479;&#32508;&#21512;&#30340;&#20854;&#20182;&#26041;&#38754;&#65292;&#21253;&#25324;&#27169;&#22411;&#21453;&#28436;&#21644;&#21487;&#35782;&#21035;&#24615;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;InVAErt&#32593;&#32476;&#65292;&#36825;&#26159;&#19968;&#20010;&#32508;&#21512;&#30340;&#25968;&#25454;&#39537;&#21160;&#20998;&#26512;&#21644;&#21512;&#25104;&#21442;&#25968;&#21270;&#29289;&#29702;&#31995;&#32479;&#30340;&#26694;&#26550;&#65292;&#23427;&#20351;&#29992;&#30830;&#23450;&#24615;&#32534;&#30721;&#22120;&#21644;&#35299;&#30721;&#22120;&#34920;&#31034;&#21069;&#21521;&#21644;&#36870;&#21521;&#35299;&#26144;&#23556;&#65292;&#29992;&#24402;&#19968;&#21270;&#27969;&#26469;&#25429;&#25417;&#31995;&#32479;&#36755;&#20986;&#30340;&#27010;&#29575;&#20998;&#24067;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#31181;&#21464;&#20998;&#32534;&#30721;&#22120;&#26469;&#23398;&#20064;&#36755;&#20837;&#21644;&#36755;&#20986;&#20043;&#38388;&#32570;&#20047;&#21452;&#23556;&#24615;&#30340;&#32039;&#20945;&#28508;&#22312;&#34920;&#31034;&#12290;&#25105;&#20204;&#27491;&#24335;&#30740;&#31350;&#20102;&#25439;&#22833;&#20989;&#25968;&#20013;&#24809;&#32602;&#31995;&#25968;&#30340;&#36873;&#25321;&#21644;&#28508;&#22312;&#31354;&#38388;&#37319;&#26679;&#31574;&#30053;&#65292;&#22240;&#20026;&#25105;&#20204;&#21457;&#29616;&#36825;&#20123;&#22240;&#32032;&#20250;&#26174;&#33879;&#24433;&#21709;&#35757;&#32451;&#21644;&#27979;&#35797;&#24615;&#33021;&#12290;&#25105;&#20204;&#26377;&#25928;&#22320;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Use of generative models and deep learning for physics-based systems is currently dominated by the task of emulation. However, the remarkable flexibility offered by data-driven architectures would suggest to extend this representation to other aspects of system synthesis including model inversion and identifiability. We introduce inVAErt (pronounced \emph{invert}) networks, a comprehensive framework for data-driven analysis and synthesis of parametric physical systems which uses a deterministic encoder and decoder to represent the forward and inverse solution maps, normalizing flow to capture the probabilistic distribution of system outputs, and a variational encoder designed to learn a compact latent representation for the lack of bijectivity between inputs and outputs. We formally investigate the selection of penalty coefficients in the loss function and strategies for latent space sampling, since we find that these significantly affect both training and testing performance. We valid
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22240;&#26524;&#20851;&#31995;&#35299;&#37322;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#35299;&#37322;&#20013;&#24341;&#20837;&#38750;&#34394;&#20551;&#24615;&#21644;&#25928;&#29575;&#65292;&#20174;&#22240;&#26524;&#25512;&#26029;&#30340;&#35282;&#24230;&#23450;&#20041;&#20102;&#22240;&#26524;&#27010;&#29575;&#65292;&#20174;&#32780;&#24314;&#31435;&#20102;&#24517;&#35201;&#21644;&#20805;&#20998;&#35299;&#37322;&#30340;&#20027;&#35201;&#32452;&#25104;&#37096;&#20998;&#65292;&#30456;&#27604;&#29616;&#26377;&#30340;&#22522;&#20110;&#20851;&#32852;&#30340;&#35299;&#37322;&#26041;&#27861;&#65292;&#36825;&#31181;&#26041;&#27861;&#26377;&#26356;&#21152;&#20248;&#36234;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2306.14115</link><description>&lt;p&gt;
&#26397;&#30528;&#21487;&#20449;&#30340;&#35299;&#37322;&#65306;&#22240;&#26524;&#20851;&#31995;&#35299;&#37322;&#35770;&#25991;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Towards Trustworthy Explanation: On Causal Rationalization. (arXiv:2306.14115v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.14115
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#30340;&#22240;&#26524;&#20851;&#31995;&#35299;&#37322;&#26041;&#27861;&#65292;&#36890;&#36807;&#22312;&#35299;&#37322;&#20013;&#24341;&#20837;&#38750;&#34394;&#20551;&#24615;&#21644;&#25928;&#29575;&#65292;&#20174;&#22240;&#26524;&#25512;&#26029;&#30340;&#35282;&#24230;&#23450;&#20041;&#20102;&#22240;&#26524;&#27010;&#29575;&#65292;&#20174;&#32780;&#24314;&#31435;&#20102;&#24517;&#35201;&#21644;&#20805;&#20998;&#35299;&#37322;&#30340;&#20027;&#35201;&#32452;&#25104;&#37096;&#20998;&#65292;&#30456;&#27604;&#29616;&#26377;&#30340;&#22522;&#20110;&#20851;&#32852;&#30340;&#35299;&#37322;&#26041;&#27861;&#65292;&#36825;&#31181;&#26041;&#27861;&#26377;&#26356;&#21152;&#20248;&#36234;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#35299;&#37322;&#25104;&#20026;&#20102;&#36890;&#36807;&#36873;&#25321;&#36755;&#20837;&#25991;&#26412;&#30340;&#23376;&#38598;&#26469;&#35299;&#37322;&#40657;&#30418;&#27169;&#22411;&#20013;&#20027;&#35201;&#21464;&#21270;&#30340;&#19968;&#20010;&#22522;&#26412;&#30340;&#33258;&#25105;&#35299;&#37322;&#22270;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#22522;&#20110;&#20851;&#32852;&#30340;&#35299;&#37322;&#26041;&#27861;&#22312;&#20004;&#20010;&#25110;&#22810;&#20010;&#29255;&#27573;&#39640;&#24230;&#20114;&#30456;&#20851;&#32852;&#26102;&#26080;&#27861;&#35782;&#21035;&#30495;&#27491;&#30340;&#35299;&#37322;&#65292;&#22240;&#27492;&#23545;&#39044;&#27979;&#20934;&#30830;&#24615;&#25552;&#20379;&#31867;&#20284;&#30340;&#36129;&#29486;&#65292;&#25152;&#35859;&#30340;&#34394;&#20551;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#19968;&#38480;&#21046;&#65292;&#25105;&#20204;&#20174;&#22240;&#26524;&#25512;&#26029;&#30340;&#35282;&#24230;&#26032;&#39062;&#22320;&#23558;&#20004;&#20010;&#22240;&#26524;&#26399;&#26395;&#20540;&#65288;&#38750;&#34394;&#20551;&#24615;&#21644;&#25928;&#29575;&#65289;&#24341;&#20837;&#20102;&#35299;&#37322;&#20013;&#12290;&#25105;&#20204;&#26681;&#25454;&#19968;&#31181;&#26032;&#25552;&#20986;&#30340;&#35299;&#37322;&#32467;&#26500;&#22240;&#26524;&#27169;&#22411;&#23450;&#20041;&#20102;&#19968;&#31995;&#21015;&#30340;&#22240;&#26524;&#27010;&#29575;&#65292;&#36890;&#36807;&#20854;&#29702;&#35770;&#37492;&#23450;&#65292;&#24314;&#31435;&#20102;&#24517;&#35201;&#21644;&#20805;&#20998;&#35299;&#37322;&#30340;&#20027;&#35201;&#32452;&#25104;&#37096;&#20998;&#12290;&#25105;&#20204;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#35780;&#35770;&#21644;&#21307;&#30103;&#25968;&#25454;&#38598;&#19978;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#22240;&#26524;&#20851;&#31995;&#35299;&#37322;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
With recent advances in natural language processing, rationalization becomes an essential self-explaining diagram to disentangle the black box by selecting a subset of input texts to account for the major variation in prediction. Yet, existing association-based approaches on rationalization cannot identify true rationales when two or more snippets are highly inter-correlated and thus provide a similar contribution to prediction accuracy, so-called spuriousness. To address this limitation, we novelly leverage two causal desiderata, non-spuriousness and efficiency, into rationalization from the causal inference perspective. We formally define a series of probabilities of causation based on a newly proposed structural causal model of rationalization, with its theoretical identification established as the main component of learning necessary and sufficient rationales. The superior performance of the proposed causal rationalization is demonstrated on real-world review and medical datasets w
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#23454;&#35777;&#26694;&#26550;&#65292;&#29992;&#20110;&#20272;&#31639;&#35777;&#25454;&#20915;&#31574;&#30340;&#20215;&#20540;&#21644;&#32479;&#35745;&#31934;&#24230;&#25237;&#36164;&#22238;&#25253;&#12290;</title><link>http://arxiv.org/abs/2306.13681</link><description>&lt;p&gt;
&#20272;&#31639;&#22522;&#20110;&#35777;&#25454;&#20915;&#31574;&#30340;&#20215;&#20540;
&lt;/p&gt;
&lt;p&gt;
Estimating the Value of Evidence-Based Decision Making. (arXiv:2306.13681v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13681
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#23454;&#35777;&#26694;&#26550;&#65292;&#29992;&#20110;&#20272;&#31639;&#35777;&#25454;&#20915;&#31574;&#30340;&#20215;&#20540;&#21644;&#32479;&#35745;&#31934;&#24230;&#25237;&#36164;&#22238;&#25253;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21830;&#19994;/&#25919;&#31574;&#20915;&#31574;&#36890;&#24120;&#22522;&#20110;&#38543;&#26426;&#23454;&#39564;&#21644;&#35266;&#23519;&#24615;&#30740;&#31350;&#30340;&#35777;&#25454;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#23454;&#35777;&#26694;&#26550;&#26469;&#20272;&#31639;&#22522;&#20110;&#35777;&#25454;&#30340;&#20915;&#31574;&#65288;EBDM&#65289;&#30340;&#20215;&#20540;&#21644;&#32479;&#35745;&#31934;&#24230;&#25237;&#36164;&#22238;&#25253;&#12290;
&lt;/p&gt;
&lt;p&gt;
Business/policy decisions are often based on evidence from randomized experiments and observational studies. In this article we propose an empirical framework to estimate the value of evidence-based decision making (EBDM) and the return on the investment in statistical precision.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#30340;&#36125;&#21494;&#26031;&#25968;&#20540;&#31215;&#20998;&#26041;&#27861;&#65292;&#31216;&#20026;&#36125;&#21494;&#26031; Stein &#31070;&#32463;&#32593;&#32476;&#12290;&#35813;&#26041;&#27861;&#21487;&#39640;&#25928;&#22320;&#32534;&#30721;&#31215;&#20998;&#20808;&#39564;&#20449;&#24687;&#24182;&#35745;&#31639;&#31215;&#20998;&#20272;&#35745;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#22312;&#23454;&#38469;&#38382;&#39064;&#20013;&#65292;&#35813;&#26041;&#27861;&#23637;&#29616;&#20986;&#25968;&#37327;&#32423;&#30340;&#21152;&#36895;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2305.13248</link><description>&lt;p&gt;
&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#36125;&#21494;&#26031;&#25968;&#20540;&#31215;&#20998;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Bayesian Numerical Integration with Neural Networks. (arXiv:2305.13248v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13248
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#30340;&#36125;&#21494;&#26031;&#25968;&#20540;&#31215;&#20998;&#26041;&#27861;&#65292;&#31216;&#20026;&#36125;&#21494;&#26031; Stein &#31070;&#32463;&#32593;&#32476;&#12290;&#35813;&#26041;&#27861;&#21487;&#39640;&#25928;&#22320;&#32534;&#30721;&#31215;&#20998;&#20808;&#39564;&#20449;&#24687;&#24182;&#35745;&#31639;&#31215;&#20998;&#20272;&#35745;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#22312;&#23454;&#38469;&#38382;&#39064;&#20013;&#65292;&#35813;&#26041;&#27861;&#23637;&#29616;&#20986;&#25968;&#37327;&#32423;&#30340;&#21152;&#36895;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#27010;&#29575;&#25968;&#20540;&#26041;&#27861;&#23545;&#20110;&#25968;&#20540;&#31215;&#20998;&#20855;&#26377;&#26174;&#33879;&#20248;&#21183;&#65306;&#21487;&#20197;&#32534;&#30721;&#31215;&#20998;&#30340;&#20808;&#39564;&#20449;&#24687;&#65292;&#21487;&#20197;&#37327;&#21270;&#31215;&#20998;&#20272;&#35745;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#20294;&#26159;&#65292;&#36825;&#31867;&#26041;&#27861;&#20013;&#26368;&#27969;&#34892;&#30340;&#36125;&#21494;&#26031;&#31215;&#20998;&#31639;&#27861;&#65288;Bayesian Quadrature&#65289;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#65292;&#22240;&#27492;&#35745;&#31639;&#25104;&#26412;&#24456;&#39640;&#12290;&#20026;&#20102;&#25552;&#39640;&#21487;&#25193;&#23637;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#30340;&#26367;&#20195;&#26041;&#27861;&#65292;&#31216;&#20026;&#36125;&#21494;&#26031; Stein &#31070;&#32463;&#32593;&#32476;&#12290;&#20851;&#38190;&#25104;&#20998;&#26159;&#22522;&#20110; Stein &#31639;&#23376;&#30340;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#65292;&#20197;&#21450;&#22522;&#20110; Laplace &#36817;&#20284;&#30340;&#36125;&#21494;&#26031;&#21518;&#39564;&#30340;&#36817;&#20284;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#23548;&#33268;&#20102;&#22312;&#27969;&#34892;&#30340; Genz &#20989;&#25968;&#22522;&#20934;&#27979;&#35797;&#21644;&#22312;&#36125;&#21494;&#26031;&#21160;&#21147;&#31995;&#32479;&#20998;&#26512;&#20197;&#21450;&#22823;&#35268;&#27169;&#39118;&#21147;&#21457;&#30005;&#39044;&#27979;&#20013;&#35268;&#27169;&#30340;&#25968;&#37327;&#32423;&#21152;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian probabilistic numerical methods for numerical integration offer significant advantages over their non-Bayesian counterparts: they can encode prior information about the integrand, and can quantify uncertainty over estimates of an integral. However, the most popular algorithm in this class, Bayesian quadrature, is based on Gaussian process models and is therefore associated with a high computational cost. To improve scalability, we propose an alternative approach based on Bayesian neural networks which we call Bayesian Stein networks. The key ingredients are a neural network architecture based on Stein operators, and an approximation of the Bayesian posterior based on the Laplace approximation. We show that this leads to orders of magnitude speed-ups on the popular Genz functions benchmark, and on challenging problems arising in the Bayesian analysis of dynamical systems, and the prediction of energy production for a large-scale wind farm.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#37327;&#23376;&#23567;&#27874;&#21464;&#25442;(QRT)&#20316;&#20026;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#37325;&#35201;&#24212;&#29992;&#65292;&#36890;&#36807;&#37327;&#23376;&#35745;&#31639;&#23454;&#29616;&#20102;&#23545;&#37327;&#23376;&#24577;&#30340;&#23567;&#27874;&#21464;&#25442;&#65292;&#24182;&#19988;&#21487;&#20197;&#39640;&#25928;&#22320;&#25214;&#21040;&#22823;&#22411;&#31070;&#32463;&#32593;&#32476;&#30340;&#31232;&#30095;&#21487;&#35757;&#32451;&#23376;&#32593;&#32476;&#12290;</title><link>http://arxiv.org/abs/2301.11936</link><description>&lt;p&gt;
&#37327;&#23376;&#23567;&#27874;&#21464;&#25442;&#65306;&#20855;&#26377;&#37327;&#23376;&#35745;&#31639;&#20248;&#21183;&#30340;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#37325;&#35201;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Quantum Ridgelet Transform: Winning Lottery Ticket of Neural Networks with Quantum Computation. (arXiv:2301.11936v2 [quant-ph] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11936
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#37327;&#23376;&#23567;&#27874;&#21464;&#25442;(QRT)&#20316;&#20026;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#37325;&#35201;&#24212;&#29992;&#65292;&#36890;&#36807;&#37327;&#23376;&#35745;&#31639;&#23454;&#29616;&#20102;&#23545;&#37327;&#23376;&#24577;&#30340;&#23567;&#27874;&#21464;&#25442;&#65292;&#24182;&#19988;&#21487;&#20197;&#39640;&#25928;&#22320;&#25214;&#21040;&#22823;&#22411;&#31070;&#32463;&#32593;&#32476;&#30340;&#31232;&#30095;&#21487;&#35757;&#32451;&#23376;&#32593;&#32476;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37327;&#23376;&#26426;&#22120;&#23398;&#20064;(QML)&#39046;&#22495;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#25361;&#25112;&#26159;&#24314;&#31435;&#37327;&#23376;&#35745;&#31639;&#22312;&#21152;&#36895;&#31070;&#32463;&#32593;&#32476;&#31561;&#24120;&#35265;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#20013;&#30340;&#24212;&#29992;&#12290;&#23567;&#27874;&#21464;&#25442;&#19968;&#30452;&#26159;&#31070;&#32463;&#32593;&#32476;&#29702;&#35770;&#30740;&#31350;&#20013;&#30340;&#22522;&#26412;&#25968;&#23398;&#24037;&#20855;&#65292;&#20294;&#30001;&#20110;&#20256;&#32479;&#32463;&#20856;&#35745;&#31639;&#30340;&#25968;&#20540;&#23454;&#29616;&#38656;&#35201;&#25351;&#25968;&#32423;&#36816;&#34892;&#26102;&#38388;$\exp(O(D))$&#65292;&#22240;&#27492;&#23567;&#27874;&#21464;&#25442;&#30340;&#23454;&#38469;&#24212;&#29992;&#24615;&#21463;&#21040;&#38480;&#21046;&#65292;&#23588;&#20854;&#22312;&#25968;&#25454;&#32500;&#24230;$D$&#22686;&#21152;&#26102;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#37327;&#23376;&#23567;&#27874;&#21464;&#25442;(QRT)&#65292;&#23427;&#22312;&#37327;&#23376;&#35745;&#31639;&#30340;&#32447;&#24615;&#36816;&#34892;&#26102;&#38388;$O(D)$&#20869;&#23454;&#29616;&#20102;&#23545;&#37327;&#23376;&#24577;&#30340;&#23567;&#27874;&#21464;&#25442;&#12290;&#20316;&#20026;&#19968;&#20010;&#24212;&#29992;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#21033;&#29992;QRT&#20316;&#20026;QML&#30340;&#22522;&#26412;&#23376;&#31243;&#24207;&#65292;&#21487;&#20197;&#39640;&#25928;&#22320;&#25214;&#21040;&#22823;&#22411;&#27973;&#23485;&#31070;&#32463;&#32593;&#32476;&#30340;&#31232;&#30095;&#21487;&#35757;&#32451;&#23376;&#32593;&#32476;&#65292;&#32780;&#26080;&#38656;&#23545;&#21407;&#22987;&#32593;&#32476;&#36827;&#34892;&#22823;&#35268;&#27169;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
A significant challenge in the field of quantum machine learning (QML) is to establish applications of quantum computation to accelerate common tasks in machine learning such as those for neural networks. Ridgelet transform has been a fundamental mathematical tool in the theoretical studies of neural networks, but the practical applicability of ridgelet transform to conducting learning tasks was limited since its numerical implementation by conventional classical computation requires an exponential runtime $\exp(O(D))$ as data dimension $D$ increases. To address this problem, we develop a quantum ridgelet transform (QRT), which implements the ridgelet transform of a quantum state within a linear runtime $O(D)$ of quantum computation. As an application, we also show that one can use QRT as a fundamental subroutine for QML to efficiently find a sparse trainable subnetwork of large shallow wide neural networks without conducting large-scale optimization of the original network. This appli
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#39640;&#32500;&#21464;&#20998;&#25512;&#29702;&#30340;&#25237;&#24433;&#31215;&#20998;&#26356;&#26032;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#38477;&#20302;&#21442;&#25968;&#25935;&#24863;&#24615;&#26469;&#23454;&#29616;&#26356;&#24378;&#20581;&#30340;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2301.08374</link><description>&lt;p&gt;
&#39640;&#32500;&#21464;&#20998;&#25512;&#29702;&#30340;&#25237;&#24433;&#31215;&#20998;&#26356;&#26032;
&lt;/p&gt;
&lt;p&gt;
Projective Integral Updates for High-Dimensional Variational Inference. (arXiv:2301.08374v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.08374
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#39640;&#32500;&#21464;&#20998;&#25512;&#29702;&#30340;&#25237;&#24433;&#31215;&#20998;&#26356;&#26032;&#26041;&#27861;&#65292;&#24182;&#36890;&#36807;&#38477;&#20302;&#21442;&#25968;&#25935;&#24863;&#24615;&#26469;&#23454;&#29616;&#26356;&#24378;&#20581;&#30340;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#25512;&#29702;&#26159;&#19968;&#31181;&#36125;&#21494;&#26031;&#25512;&#29702;&#30340;&#36817;&#20284;&#26694;&#26550;&#65292;&#36890;&#36807;&#20248;&#21270;&#31616;&#21270;&#30340;&#21442;&#25968;&#20998;&#24067;&#26469;&#20195;&#26367;&#23436;&#25972;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#20174;&#32780;&#25913;&#21892;&#39044;&#27979;&#20013;&#30340;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#12290;&#25429;&#25417;&#19982;&#35757;&#32451;&#25968;&#25454;&#19968;&#33268;&#30340;&#27169;&#22411;&#21464;&#21270;&#21487;&#20197;&#36890;&#36807;&#38477;&#20302;&#21442;&#25968;&#25935;&#24863;&#24615;&#26469;&#23454;&#29616;&#26356;&#24378;&#20581;&#30340;&#39044;&#27979;&#12290;&#26412;&#30740;&#31350;&#24341;&#20837;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#21464;&#20998;&#25512;&#29702;&#30340;&#22266;&#23450;&#28857;&#26368;&#20248;&#21270;&#26041;&#27861;&#65292;&#24403;&#27599;&#20010;&#21487;&#34892;&#30340;&#23545;&#25968;&#23494;&#24230;&#21487;&#20197;&#34920;&#31034;&#20026;&#32473;&#23450;&#22522;&#20989;&#25968;&#30340;&#32447;&#24615;&#32452;&#21512;&#26102;&#65292;&#35813;&#26041;&#27861;&#29983;&#25928;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#20248;&#21270;&#22120;&#25104;&#20026;&#25237;&#24433;&#31215;&#20998;&#26356;&#26032;&#30340;&#19968;&#20010;&#19981;&#21160;&#28857;&#12290;&#24403;&#22522;&#20989;&#25968;&#36328;&#36234;&#27599;&#20010;&#21442;&#25968;&#30340;&#20108;&#27425;&#20989;&#25968;&#26102;&#65292;&#21487;&#34892;&#23494;&#24230;&#20026;&#39640;&#26031;&#20998;&#24067;&#65292;&#25237;&#24433;&#31215;&#20998;&#26356;&#26032;&#20135;&#29983;&#20102;&#20934;&#29275;&#39039;&#21464;&#20998;&#36125;&#21494;&#26031; (QNVB)&#12290;&#20854;&#20182;&#22522;&#20989;&#25968;&#21644;&#26356;&#26032;&#26041;&#27861;&#20063;&#26159;&#21487;&#33021;&#30340;&#12290;&#30001;&#20110;&#36825;&#20123;&#26356;&#26032;&#38656;&#35201;&#39640;&#32500;&#31215;&#20998;&#65292;&#26412;&#30740;&#31350;&#39318;&#20808;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#20934;&#38543;&#26426;&#31215;&#20998;&#24207;&#21015;&#29992;&#20110;&#22343;&#21248;&#22343;&#21248;&#22343;&#21248;&#22343;&#21248;&#22343;&#21248;&#22343;&#21248;&#31215;&#20998;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variational inference is an approximation framework for Bayesian inference that seeks to improve quantified uncertainty in predictions by optimizing a simplified distribution over parameters to stand in for the full posterior. Capturing model variations that remain consistent with training data enables more robust predictions by reducing parameter sensitivity. This work introduces a fixed-point optimization for variational inference that is applicable when every feasible log density can be expressed as a linear combination of functions from a given basis. In such cases, the optimizer becomes a fixed-point of projective integral updates. When the basis spans univariate quadratics in each parameter, feasible densities are Gaussian and the projective integral updates yield quasi-Newton variational Bayes (QNVB). Other bases and updates are also possible. As these updates require high-dimensional integration, this work first proposes an efficient quasirandom quadrature sequence for mean-fie
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#39044;&#35774;&#26041;&#27861;&#65292;&#20197;&#36873;&#25321;&#22312;&#38543;&#26426;&#35797;&#39564;&#20013;&#35843;&#25972;&#21738;&#20123;&#21464;&#37327;&#65292;&#20197;&#21450;&#20197;&#20309;&#31181;&#24418;&#24335;&#36827;&#34892;&#35843;&#25972;&#65292;&#20174;&#32780;&#26368;&#22823;&#21270;&#31934;&#24230;&#65292;&#21516;&#26102;&#20445;&#25345;&#8544;&#31867;&#38169;&#35823;&#25511;&#21046;&#12290;</title><link>http://arxiv.org/abs/2210.17453</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#36873;&#25321;&#26368;&#20248;&#31574;&#30053;&#20197;&#25552;&#39640;&#38543;&#26426;&#35797;&#39564;&#30340;&#31934;&#24230;&#21644;&#21151;&#25928;
&lt;/p&gt;
&lt;p&gt;
Adaptive Selection of the Optimal Strategy to Improve Precision and Power in Randomized Trials. (arXiv:2210.17453v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.17453
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20379;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#39044;&#35774;&#26041;&#27861;&#65292;&#20197;&#36873;&#25321;&#22312;&#38543;&#26426;&#35797;&#39564;&#20013;&#35843;&#25972;&#21738;&#20123;&#21464;&#37327;&#65292;&#20197;&#21450;&#20197;&#20309;&#31181;&#24418;&#24335;&#36827;&#34892;&#35843;&#25972;&#65292;&#20174;&#32780;&#26368;&#22823;&#21270;&#31934;&#24230;&#65292;&#21516;&#26102;&#20445;&#25345;&#8544;&#31867;&#38169;&#35823;&#25511;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Benkeser&#31561;&#20154;&#23637;&#31034;&#20102;&#22914;&#20309;&#22312;&#38543;&#26426;&#35797;&#39564;&#20013;&#35843;&#25972;&#22522;&#32447;&#21327;&#21464;&#37327;&#65292;&#20174;&#32780;&#26377;&#24847;&#20041;&#22320;&#25552;&#39640;&#21508;&#31181;&#32467;&#26524;&#31867;&#22411;&#30340;&#31934;&#24230;&#12290;&#20182;&#20204;&#30340;&#30740;&#31350;&#24314;&#31435;&#22312;&#24456;&#38271;&#26102;&#38388;&#30340;&#21382;&#21490;&#22522;&#30784;&#19978;&#65292;&#22987;&#20110;1932&#24180;&#30340;R.A. Fisher&#65292;&#21253;&#25324;&#32654;&#22269;&#39135;&#21697;&#21644;&#33647;&#29289;&#31649;&#29702;&#23616;&#20197;&#21450;&#27431;&#27954;&#33647;&#21697;&#31649;&#29702;&#23616;&#26368;&#36817;&#30340;&#35748;&#21487;&#12290;&#26412;&#25991;&#30528;&#37325;&#25506;&#35752;&#20102;&#19968;&#20010;&#37325;&#35201;&#30340;&#23454;&#38469;&#38382;&#39064;&#65306;&#22914;&#20309;&#36873;&#25321;&#35843;&#25972;&#26041;&#27861;&#65292;&#21363;&#21738;&#20123;&#21464;&#37327;&#20197;&#21450;&#20197;&#20309;&#31181;&#24418;&#24335;&#65292;&#20197;&#26368;&#22823;&#21270;&#31934;&#24230;&#65292;&#21516;&#26102;&#20445;&#25345;&#8544;&#31867;&#38169;&#35823;&#25511;&#21046;&#12290;Balzer&#31561;&#20154;&#20197;&#21069;&#25552;&#20986;&#20102;&#22312;TMLE&#20013;&#30340;&#33258;&#36866;&#24212;&#39044;&#35774;&#27861;&#65292;&#20197;&#28789;&#27963;&#33258;&#21160;&#22320;&#20174;&#39044;&#20808;&#35268;&#23450;&#30340;&#38598;&#21512;&#20013;&#36873;&#25321;&#22312;&#23567;&#22411;&#35797;&#39564;&#65288;N &lt; 40&#65289;&#20013;&#26368;&#22823;&#21270;&#32463;&#39564;&#25928;&#29575;&#30340;&#26041;&#27861;&#12290;&#20026;&#20102;&#36991;&#20813;&#22312;&#23569;&#25968;&#38543;&#26426;&#21333;&#20301;&#20013;&#36807;&#24230;&#25311;&#21512;&#65292;&#20043;&#21069;&#30340;&#36873;&#25321;&#20165;&#38480;&#20110;&#24037;&#20316;&#24191;&#20041;&#32447;&#24615;&#27169;&#22411;&#65292;&#35843;&#25972;&#21333;&#20010;&#21327;&#21464;&#37327;&#12290;&#29616;&#22312;&#65292;&#25105;&#20204;&#23558;&#33258;&#36866;&#24212;&#39044;&#35774;&#27861;&#38024;&#23545;&#20855;&#26377;&#35768;&#22810;&#38543;&#26426;&#21333;&#20803;&#30340;&#35797;&#39564;&#36827;&#34892;&#20102;&#35843;&#25972;&#12290;&#20351;&#29992;V-fold
&lt;/p&gt;
&lt;p&gt;
Benkeser et al. demonstrate how adjustment for baseline covariates in randomized trials can meaningfully improve precision for a variety of outcome types. Their findings build on a long history, starting in 1932 with R.A. Fisher and including more recent endorsements by the U.S. Food and Drug Administration and the European Medicines Agency. Here, we address an important practical consideration: *how* to select the adjustment approach -- which variables and in which form -- to maximize precision, while maintaining Type-I error control. Balzer et al. previously proposed *Adaptive Prespecification* within TMLE to flexibly and automatically select, from a prespecified set, the approach that maximizes empirical efficiency in small trials (N$&lt;$40). To avoid overfitting with few randomized units, selection was previously limited to working generalized linear models, adjusting for a single covariate. Now, we tailor Adaptive Prespecification to trials with many randomized units. Using $V$-fold
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;PopArt&#30340;&#39640;&#25928;&#31232;&#30095;&#32447;&#24615;&#20272;&#35745;&#26041;&#27861;&#65292;&#30456;&#27604;&#20110;Lasso&#65292;&#22312;&#35768;&#22810;&#38382;&#39064;&#20013;&#20855;&#26377;&#26356;&#32039;&#30340;$\ell_1$&#24674;&#22797;&#20445;&#35777;&#65292;&#24182;&#22522;&#20110;&#27492;&#25512;&#23548;&#20986;&#31232;&#30095;&#32447;&#24615;&#25671;&#33218;&#31639;&#27861;&#65292;&#20855;&#26377;&#25913;&#36827;&#30340;&#36951;&#25022;&#19978;&#30028;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#25968;&#25454;&#31232;&#32570;&#24773;&#20917;&#19979;&#31232;&#30095;&#32447;&#24615;&#25671;&#33218;&#30340;&#21305;&#37197;&#19979;&#30028;&#12290;</title><link>http://arxiv.org/abs/2210.15345</link><description>&lt;p&gt;
PopArt: &#39640;&#25928;&#31232;&#30095;&#22238;&#24402;&#21644;&#20248;&#21270;&#31232;&#30095;&#32447;&#24615;&#25671;&#33218;&#30340;&#23454;&#39564;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
PopArt: Efficient Sparse Regression and Experimental Design for Optimal Sparse Linear Bandits. (arXiv:2210.15345v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.15345
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;PopArt&#30340;&#39640;&#25928;&#31232;&#30095;&#32447;&#24615;&#20272;&#35745;&#26041;&#27861;&#65292;&#30456;&#27604;&#20110;Lasso&#65292;&#22312;&#35768;&#22810;&#38382;&#39064;&#20013;&#20855;&#26377;&#26356;&#32039;&#30340;$\ell_1$&#24674;&#22797;&#20445;&#35777;&#65292;&#24182;&#22522;&#20110;&#27492;&#25512;&#23548;&#20986;&#31232;&#30095;&#32447;&#24615;&#25671;&#33218;&#31639;&#27861;&#65292;&#20855;&#26377;&#25913;&#36827;&#30340;&#36951;&#25022;&#19978;&#30028;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#25968;&#25454;&#31232;&#32570;&#24773;&#20917;&#19979;&#31232;&#30095;&#32447;&#24615;&#25671;&#33218;&#30340;&#21305;&#37197;&#19979;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31232;&#30095;&#32447;&#24615;&#25671;&#33218;&#20013;&#65292;&#23398;&#20064;&#20195;&#29702;&#25353;&#39034;&#24207;&#36873;&#25321;&#19968;&#20010;&#21160;&#20316;&#24182;&#25509;&#25910;&#22870;&#21169;&#21453;&#39304;&#65292;&#32780;&#22870;&#21169;&#20989;&#25968;&#32447;&#24615;&#20381;&#36182;&#20110;&#21160;&#20316;&#30340;&#19968;&#20123;&#22352;&#26631;&#30340;&#21327;&#21464;&#37327;&#12290;&#36825;&#22312;&#35768;&#22810;&#23454;&#38469;&#30340;&#39034;&#24207;&#20915;&#31574;&#38382;&#39064;&#20013;&#37117;&#26377;&#24212;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#35745;&#31639;&#39640;&#25928;&#30340;&#31232;&#30095;&#32447;&#24615;&#20272;&#35745;&#26041;&#27861;&#65292;&#31216;&#20026;PopArt&#65292;&#19982;Lasso&#65288;Tibshirani, 1996&#65289;&#30456;&#27604;&#65292;&#23427;&#22312;&#35768;&#22810;&#38382;&#39064;&#20013;&#20855;&#26377;&#26356;&#32039;&#30340;$\ell_1$&#24674;&#22797;&#20445;&#35777;&#12290;&#25105;&#20204;&#30340;&#30028;&#38480;&#33258;&#28982;&#22320;&#28608;&#21457;&#20102;&#19968;&#31181;&#20984;&#23454;&#39564;&#35774;&#35745;&#20934;&#21017;&#65292;&#22240;&#27492;&#22312;&#35745;&#31639;&#19978;&#26159;&#39640;&#25928;&#30340;&#35299;&#20915;&#26041;&#27861;&#12290;&#22522;&#20110;&#25105;&#20204;&#30340;&#26032;&#20272;&#35745;&#22120;&#21644;&#35774;&#35745;&#20934;&#21017;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#31232;&#30095;&#32447;&#24615;&#25671;&#33218;&#31639;&#27861;&#65292;&#20854;&#22312;&#32473;&#23450;&#21160;&#20316;&#38598;&#30340;&#20960;&#20309;&#24615;&#26041;&#38754;&#30456;&#23545;&#20110;&#29616;&#26377;&#25216;&#26415;&#65288;Hao et al., 2020&#65289;&#20855;&#26377;&#25913;&#36827;&#30340;&#36951;&#25022;&#19978;&#30028;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#25968;&#25454;&#31232;&#32570;&#24773;&#20917;&#19979;&#31232;&#30095;&#32447;&#24615;&#25671;&#33218;&#30340;&#21305;&#37197;&#19979;&#30028;&#65292;&#36825;&#22635;&#34917;&#20102;&#19978;&#30028;&#21644;&#19979;&#30028;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;
In sparse linear bandits, a learning agent sequentially selects an action and receive reward feedback, and the reward function depends linearly on a few coordinates of the covariates of the actions. This has applications in many real-world sequential decision making problems. In this paper, we propose a simple and computationally efficient sparse linear estimation method called PopArt that enjoys a tighter $\ell_1$ recovery guarantee compared to Lasso (Tibshirani, 1996) in many problems. Our bound naturally motivates an experimental design criterion that is convex and thus computationally efficient to solve. Based on our novel estimator and design criterion, we derive sparse linear bandit algorithms that enjoy improved regret upper bounds upon the state of the art (Hao et al., 2020), especially w.r.t. the geometry of the given action set. Finally, we prove a matching lower bound for sparse linear bandits in the data-poor regime, which closes the gap between upper and lower bounds in pr
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#23614;&#24179;&#22343;&#21644;&#27491;&#21017;&#21270;&#25216;&#26415;&#65292;&#23545;&#26102;&#24207;&#24046;&#24322;(TD)&#23398;&#20064;&#31639;&#27861;&#36827;&#34892;&#20102;&#26377;&#38480;&#26102;&#38388;&#34892;&#20026;&#30340;&#30740;&#31350;&#12290;&#25105;&#20204;&#24471;&#20986;&#32467;&#35770;&#65292;&#23614;&#24179;&#22343;TD&#33021;&#20197;&#26368;&#20248;&#36895;&#29575; $O(1/t)$ &#25910;&#25947;&#65292;&#24182;&#19988;&#21021;&#22987;&#35823;&#24046;&#34928;&#20943;&#36895;&#29575;&#26356;&#24555;&#12290;&#27492;&#22806;&#65292;&#27491;&#21017;&#21270;&#30340;TD&#29256;&#26412;&#22312;&#20855;&#26377;&#30149;&#24577;&#29305;&#24449;&#30340;&#38382;&#39064;&#19978;&#24456;&#26377;&#29992;&#12290;</title><link>http://arxiv.org/abs/2210.05918</link><description>&lt;p&gt;
&#26377;&#38480;&#26102;&#38388;&#20869;&#20351;&#29992;&#32447;&#24615;&#20989;&#25968;&#36924;&#36817;&#36827;&#34892;&#26102;&#24207;&#24046;&#24322;&#23398;&#20064;&#30340;&#20998;&#26512;&#65306;&#23614;&#24179;&#22343;&#21644;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
Finite time analysis of temporal difference learning with linear function approximation: Tail averaging and regularisation. (arXiv:2210.05918v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.05918
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#24341;&#20837;&#23614;&#24179;&#22343;&#21644;&#27491;&#21017;&#21270;&#25216;&#26415;&#65292;&#23545;&#26102;&#24207;&#24046;&#24322;(TD)&#23398;&#20064;&#31639;&#27861;&#36827;&#34892;&#20102;&#26377;&#38480;&#26102;&#38388;&#34892;&#20026;&#30340;&#30740;&#31350;&#12290;&#25105;&#20204;&#24471;&#20986;&#32467;&#35770;&#65292;&#23614;&#24179;&#22343;TD&#33021;&#20197;&#26368;&#20248;&#36895;&#29575; $O(1/t)$ &#25910;&#25947;&#65292;&#24182;&#19988;&#21021;&#22987;&#35823;&#24046;&#34928;&#20943;&#36895;&#29575;&#26356;&#24555;&#12290;&#27492;&#22806;&#65292;&#27491;&#21017;&#21270;&#30340;TD&#29256;&#26412;&#22312;&#20855;&#26377;&#30149;&#24577;&#29305;&#24449;&#30340;&#38382;&#39064;&#19978;&#24456;&#26377;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23558;&#27969;&#34892;&#30340;&#26102;&#24207;&#24046;&#24322;(TD)&#23398;&#20064;&#31639;&#27861;&#19982;&#23614;&#24179;&#22343;&#30456;&#32467;&#21512;&#26102;&#30340;&#26377;&#38480;&#26102;&#38388;&#34892;&#20026;&#12290;&#25105;&#20204;&#22312;&#19981;&#38656;&#35201;&#20851;&#20110;&#24213;&#23618;&#25237;&#24433;TD&#19981;&#21160;&#28857;&#30697;&#38453;&#30340;&#29305;&#24449;&#20540;&#20449;&#24687;&#30340;&#27493;&#38271;&#36873;&#25321;&#19979;&#65292;&#25512;&#23548;&#20102;&#23614;&#24179;&#22343;TD&#36845;&#20195;&#30340;&#21442;&#25968;&#35823;&#24046;&#30340;&#26377;&#38480;&#26102;&#38388;&#30028;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;&#23614;&#24179;&#22343;TD&#20197;&#26399;&#26395;&#36895;&#29575;&#21644;&#39640;&#27010;&#29575;&#25910;&#25947;&#20110;&#26368;&#20248;&#30340; $O(1/t)$ &#36895;&#29575;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#30028;&#38480;&#23637;&#31034;&#20102;&#21021;&#22987;&#35823;&#24046;(&#20559;&#24046;)&#30340;&#26356;&#24555;&#34928;&#20943;&#36895;&#29575;&#65292;&#36825;&#26159;&#23545;&#25152;&#26377;&#36845;&#20195;&#30340;&#24179;&#22343;&#20540;&#30340;&#25913;&#36827;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#24182;&#20998;&#26512;&#20102;&#19968;&#31181;&#32467;&#21512;&#27491;&#21017;&#21270;&#30340;TD&#21464;&#20307;&#12290;&#36890;&#36807;&#20998;&#26512;&#65292;&#25105;&#20204;&#24471;&#20986;&#32467;&#35770;&#35748;&#20026;&#27491;&#21017;&#21270;&#30340;TD&#29256;&#26412;&#22312;&#20855;&#26377;&#30149;&#24577;&#29305;&#24449;&#30340;&#38382;&#39064;&#19978;&#26159;&#26377;&#29992;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the finite-time behaviour of the popular temporal difference (TD) learning algorithm when combined with tail-averaging. We derive finite time bounds on the parameter error of the tail-averaged TD iterate under a step-size choice that does not require information about the eigenvalues of the matrix underlying the projected TD fixed point. Our analysis shows that tail-averaged TD converges at the optimal $O\left(1/t\right)$ rate, both in expectation and with high probability. In addition, our bounds exhibit a sharper rate of decay for the initial error (bias), which is an improvement over averaging all iterates. We also propose and analyse a variant of TD that incorporates regularisation. From analysis, we conclude that the regularised version of TD is useful for problems with ill-conditioned features.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#24191;&#20041;&#26680;&#27491;&#21017;&#21270;&#26368;&#23567;&#20108;&#20056;&#27861; (gKRLS)&#65292;&#35299;&#20915;&#20102;&#26680;&#27491;&#21017;&#21270;&#26368;&#23567;&#20108;&#20056;&#27861; (KRLS) &#22312;&#24403;&#21069;&#20351;&#29992;&#20013;&#30340;&#20004;&#20010;&#38480;&#21046;&#65306;&#23427;&#30340;&#25193;&#23637;&#33021;&#21147;&#19981;&#36275;&#65292;&#19988;&#21363;&#20351;&#22312;&#23567;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#65292;&#20854;&#35745;&#31639;&#20195;&#20215;&#20063;&#38750;&#24120;&#39640;&#26114;&#12290;</title><link>http://arxiv.org/abs/2209.14355</link><description>&lt;p&gt;
&#24191;&#20041;&#26680;&#27491;&#21017;&#21270;&#26368;&#23567;&#20108;&#20056;&#27861;
&lt;/p&gt;
&lt;p&gt;
Generalized Kernel Regularized Least Squares. (arXiv:2209.14355v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.14355
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#24191;&#20041;&#26680;&#27491;&#21017;&#21270;&#26368;&#23567;&#20108;&#20056;&#27861; (gKRLS)&#65292;&#35299;&#20915;&#20102;&#26680;&#27491;&#21017;&#21270;&#26368;&#23567;&#20108;&#20056;&#27861; (KRLS) &#22312;&#24403;&#21069;&#20351;&#29992;&#20013;&#30340;&#20004;&#20010;&#38480;&#21046;&#65306;&#23427;&#30340;&#25193;&#23637;&#33021;&#21147;&#19981;&#36275;&#65292;&#19988;&#21363;&#20351;&#22312;&#23567;&#35268;&#27169;&#25968;&#25454;&#38598;&#19978;&#65292;&#20854;&#35745;&#31639;&#20195;&#20215;&#20063;&#38750;&#24120;&#39640;&#26114;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26680;&#27491;&#21017;&#21270;&#26368;&#23567;&#20108;&#20056;&#27861; (KRLS) &#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#28789;&#27963;&#22320;&#20272;&#35745;&#20855;&#26377;&#22797;&#26434;&#21464;&#37327;&#20851;&#31995;&#30340;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#20854;&#21487;&#29992;&#24615;&#22240;&#20004;&#20010;&#21407;&#22240;&#32780;&#21463;&#21040;&#35768;&#22810;&#30740;&#31350;&#20154;&#21592;&#30340;&#38480;&#21046;&#12290;&#39318;&#20808;&#65292;&#29616;&#26377;&#26041;&#27861;&#32570;&#20047;&#28789;&#27963;&#24615;&#65292;&#19981;&#20801;&#35768;&#23558;KRLS&#19982;&#29702;&#35770;&#21160;&#26426;&#19979;&#30340;&#25193;&#23637;&#22914;&#38543;&#26426;&#25928;&#24212;&#12289;&#26410;&#32463;&#27491;&#21017;&#21270;&#30340;&#22266;&#23450;&#25928;&#24212;&#25110;&#38750;&#39640;&#26031;&#32467;&#26524;&#32452;&#21512;&#20351;&#29992;&#12290;&#20854;&#27425;&#65292;&#21363;&#20351;&#26159;&#35268;&#27169;&#36739;&#23567;&#30340;&#25968;&#25454;&#38598;&#65292;&#20272;&#35745;&#20063;&#38750;&#24120;&#35745;&#31639;&#23494;&#38598;&#12290;&#26412;&#25991;&#36890;&#36807;&#24341;&#20837;&#24191;&#20041;KRLS (gKRLS) &#26469;&#35299;&#20915;&#36825;&#20004;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#25351;&#20986;&#65292;KRLS&#21487;&#20197;&#37325;&#26032;&#35774;&#23450;&#20026;&#20998;&#23618;&#27169;&#22411;&#65292;&#20174;&#32780;&#20801;&#35768;&#36731;&#26494;&#25512;&#29702;&#21644;&#27169;&#22359;&#21270;&#27169;&#22411;&#26500;&#24314;&#65292;&#22312;&#20854;&#20013;KRLS&#21487;&#20197;&#19982;&#38543;&#26426;&#25928;&#24212;&#12289;&#26679;&#26465;&#21644;&#26410;&#32463;&#27491;&#21017;&#21270;&#30340;&#22266;&#23450;&#25928;&#24212;&#24182;&#29992;&#12290;&#22312;&#35745;&#31639;&#26041;&#38754;&#65292;&#25105;&#20204;&#36824;&#23454;&#29616;&#20102;&#38543;&#26426;&#33609;&#22270;&#26041;&#27861;&#65292;&#20197;&#26497;&#22823;&#22320;&#21152;&#36895;&#20272;&#35745;&#65292;&#24182;&#22312;&#20272;&#35745;&#36136;&#37327;&#19978;&#25215;&#25285;&#26377;&#38480;&#30340;&#24809;&#32602;&#12290;&#25105;&#20204;&#35777;&#26126;gKRLS&#21487;&#36866;&#29992;&#20110;&#20855;&#26377;&#22823;&#37327;&#26679;&#26412;&#30340;&#25968;&#25454;&#38598;&#30340;&#25311;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Kernel Regularized Least Squares (KRLS) is a popular method for flexibly estimating models that may have complex relationships between variables. However, its usefulness to many researchers is limited for two reasons. First, existing approaches are inflexible and do not allow KRLS to be combined with theoretically-motivated extensions such as random effects, unregularized fixed effects, or non-Gaussian outcomes. Second, estimation is extremely computationally intensive for even modestly sized datasets. Our paper addresses both concerns by introducing generalized KRLS (gKRLS). We note that KRLS can be re-formulated as a hierarchical model thereby allowing easy inference and modular model construction where KRLS can be used alongside random effects, splines, and unregularized fixed effects. Computationally, we also implement random sketching to dramatically accelerate estimation while incurring a limited penalty in estimation quality. We demonstrate that gKRLS can be fit on datasets with
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#30456;&#20851;&#26435;&#37325;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#26497;&#38480;&#34892;&#20026;&#65292;&#21457;&#29616;&#26080;&#38480;&#23485;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#27599;&#19968;&#23618;&#21487;&#20197;&#36890;&#36807;&#20004;&#20010;&#31616;&#21333;&#30340;&#37327;&#26469;&#21051;&#30011;&#65292;&#24403;&#20854;&#20013;&#33267;&#23569;&#19968;&#23618;&#30340;&#37327;&#26159;&#38750;&#24179;&#20961;&#30340;&#26102;&#20505;&#65292;&#24471;&#21040;&#20102;&#39640;&#26031;&#36807;&#31243;&#30340;&#28151;&#21512;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2205.08187</link><description>&lt;p&gt;
&#20855;&#26377;&#30456;&#20851;&#26435;&#37325;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65306;&#39640;&#26031;&#36807;&#31243;&#28151;&#21512;&#26497;&#38480;&#12289;&#37325;&#23614;&#12289;&#31232;&#30095;&#24615;&#21644;&#21487;&#21387;&#32553;&#24615;
&lt;/p&gt;
&lt;p&gt;
Deep neural networks with dependent weights: Gaussian Process mixture limit, heavy tails, sparsity and compressibility. (arXiv:2205.08187v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.08187
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#30456;&#20851;&#26435;&#37325;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#26497;&#38480;&#34892;&#20026;&#65292;&#21457;&#29616;&#26080;&#38480;&#23485;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#27599;&#19968;&#23618;&#21487;&#20197;&#36890;&#36807;&#20004;&#20010;&#31616;&#21333;&#30340;&#37327;&#26469;&#21051;&#30011;&#65292;&#24403;&#20854;&#20013;&#33267;&#23569;&#19968;&#23618;&#30340;&#37327;&#26159;&#38750;&#24179;&#20961;&#30340;&#26102;&#20505;&#65292;&#24471;&#21040;&#20102;&#39640;&#26031;&#36807;&#31243;&#30340;&#28151;&#21512;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#30456;&#20851;&#26435;&#37325;&#24182;&#36890;&#36807;&#39640;&#26031;&#20998;&#24067;&#28151;&#21512;&#24314;&#27169;&#30340;&#26080;&#38480;&#23485;&#24230;&#21069;&#39304;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#26497;&#38480;&#12290;&#32593;&#32476;&#30340;&#27599;&#20010;&#38544;&#34255;&#33410;&#28857;&#34987;&#20998;&#37197;&#19968;&#20010;&#38750;&#36127;&#38543;&#26426;&#21464;&#37327;&#65292;&#35813;&#38543;&#26426;&#21464;&#37327;&#25511;&#21046;&#35813;&#33410;&#28857;&#30340;&#36755;&#20986;&#26435;&#37325;&#30340;&#26041;&#24046;&#12290;&#25105;&#20204;&#23545;&#36825;&#20123;&#33410;&#28857;&#38543;&#26426;&#21464;&#37327;&#20570;&#20102;&#26368;&#23567;&#30340;&#20551;&#35774;&#65306;&#23427;&#20204;&#26159;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#65292;&#24182;&#19988;&#22312;&#26080;&#38480;&#23485;&#24230;&#26497;&#38480;&#19979;&#65292;&#27599;&#19968;&#23618;&#30340;&#38543;&#26426;&#21464;&#37327;&#21644;&#25910;&#25947;&#21040;&#19968;&#20123;&#26377;&#38480;&#30340;&#38543;&#26426;&#21464;&#37327;&#12290;&#22312;&#36825;&#20010;&#27169;&#22411;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#26080;&#38480;&#23485;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#27599;&#19968;&#23618;&#21487;&#20197;&#36890;&#36807;&#20004;&#20010;&#31616;&#21333;&#30340;&#37327;&#26469;&#21051;&#30011;&#65306;&#19968;&#20010;&#38750;&#36127;&#26631;&#37327;&#21442;&#25968;&#21644;&#19968;&#20010;&#27491;&#23454;&#25968;&#19978;&#30340;L&#233;vy&#27979;&#24230;&#12290;&#22914;&#26524;&#26631;&#37327;&#21442;&#25968;&#20005;&#26684;&#20026;&#27491;&#19988;&#25152;&#26377;&#38544;&#34255;&#23618;&#30340;L&#233;vy&#27979;&#24230;&#37117;&#26159;&#24179;&#20961;&#30340;&#65292;&#37027;&#20040;&#23601;&#24471;&#21040;&#20102;&#32463;&#20856;&#30340;&#39640;&#26031;&#36807;&#31243;(GP)&#26497;&#38480;&#65292;&#21363;&#36890;&#36807;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#39640;&#26031;&#26435;&#37325;&#33719;&#24471;&#12290;&#26356;&#26377;&#36259;&#30340;&#26159;&#65292;&#22914;&#26524;&#33267;&#23569;&#19968;&#23618;&#30340;L&#233;vy&#27979;&#24230;&#26159;&#38750;&#24179;&#20961;&#30340;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#39640;&#26031;&#36807;&#31243;&#30340;&#28151;&#21512;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
This article studies the infinite-width limit of deep feedforward neural networks whose weights are dependent, and modelled via a mixture of Gaussian distributions. Each hidden node of the network is assigned a nonnegative random variable that controls the variance of the outgoing weights of that node. We make minimal assumptions on these per-node random variables: they are iid and their sum, in each layer, converges to some finite random variable in the infinite-width limit. Under this model, we show that each layer of the infinite-width neural network can be characterised by two simple quantities: a non-negative scalar parameter and a L\'evy measure on the positive reals. If the scalar parameters are strictly positive and the L\'evy measures are trivial at all hidden layers, then one recovers the classical Gaussian process (GP) limit, obtained with iid Gaussian weights. More interestingly, if the L\'evy measure of at least one layer is non-trivial, we obtain a mixture of Gaussian pro
&lt;/p&gt;</description></item><item><title>HERMES&#26159;&#19968;&#20010;&#29992;&#20110;&#39044;&#27979;&#38750;&#24179;&#31283;&#26102;&#24207;&#25968;&#25454;&#30340;&#28151;&#21512;&#32416;&#38169;&#27169;&#22411;&#65292;&#24182;&#19988;&#21033;&#29992;&#22806;&#37096;&#20449;&#21495;&#25552;&#20379;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2202.03224</link><description>&lt;p&gt;
HERMES: &#38750;&#24179;&#31283;&#26102;&#24207;&#26102;&#23578;&#25968;&#25454;&#30340;&#28151;&#21512;&#32416;&#38169;&#27169;&#22411;&#65292;&#21253;&#25324;&#22806;&#37096;&#20449;&#21495;
&lt;/p&gt;
&lt;p&gt;
HERMES: Hybrid Error-corrector Model with inclusion of External Signals for nonstationary fashion time series. (arXiv:2202.03224v3 [eess.SP] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.03224
&lt;/p&gt;
&lt;p&gt;
HERMES&#26159;&#19968;&#20010;&#29992;&#20110;&#39044;&#27979;&#38750;&#24179;&#31283;&#26102;&#24207;&#25968;&#25454;&#30340;&#28151;&#21512;&#32416;&#38169;&#27169;&#22411;&#65292;&#24182;&#19988;&#21033;&#29992;&#22806;&#37096;&#20449;&#21495;&#25552;&#20379;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24320;&#21457;&#29992;&#20110;&#39044;&#27979;&#38750;&#24179;&#31283;&#26102;&#24207;&#25968;&#25454;&#30340;&#27169;&#22411;&#21644;&#31639;&#27861;&#26159;&#19968;&#20010;&#38271;&#26399;&#23384;&#22312;&#30340;&#32479;&#35745;&#38382;&#39064;&#12290;&#23545;&#20110;&#26102;&#23578;&#25110;&#38646;&#21806;&#34892;&#19994;&#31561;&#35768;&#22810;&#24212;&#29992;&#26469;&#35828;&#65292;&#36825;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#65292;&#21487;&#20197;&#24110;&#21161;&#20570;&#20986;&#26368;&#20339;&#24211;&#23384;&#20915;&#31574;&#24182;&#36991;&#20813;&#24040;&#22823;&#30340;&#28010;&#36153;&#12290;&#26412;&#25991;&#20351;&#29992;&#26368;&#20808;&#36827;&#30340;&#35745;&#31639;&#26426;&#35270;&#35273;&#26041;&#27861;&#65292;&#36319;&#36394;&#31038;&#20132;&#23186;&#20307;&#19978;&#30340;&#25968;&#21315;&#31181;&#26102;&#23578;&#36235;&#21183;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26102;&#23578;&#26102;&#24207;&#39044;&#27979;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#36129;&#29486;&#26377;&#20004;&#20010;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#20844;&#24320;&#25552;&#20379;&#20102;&#19968;&#20010;&#25910;&#38598;&#20102;10000&#20010;&#27599;&#21608;&#26102;&#23578;&#26102;&#24207;&#25968;&#25454;&#30340;&#25968;&#25454;&#38598;&#12290;&#30001;&#20110;&#24433;&#21709;&#21147;&#21160;&#24577;&#26159;&#26032;&#20852;&#36235;&#21183;&#26816;&#27979;&#30340;&#20851;&#38190;&#65292;&#25105;&#20204;&#23558;&#27599;&#20010;&#26102;&#24207;&#25968;&#25454;&#19982;&#22806;&#37096;&#24369;&#20449;&#21495;&#20851;&#32852;&#36215;&#26469;&#65292;&#20195;&#34920;&#24433;&#21709;&#32773;&#30340;&#34892;&#20026;&#12290;&#20854;&#27425;&#65292;&#20026;&#20102;&#21033;&#29992;&#36825;&#26679;&#30340;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#28151;&#21512;&#39044;&#27979;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23558;&#27599;&#20010;&#26102;&#24207;&#30340;&#21442;&#25968;&#21270;&#27169;&#22411;&#19982;&#23395;&#33410;&#24615;&#32452;&#20214;&#21644;&#19968;&#20010;&#20840;&#23616;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#30456;&#32467;&#21512;&#65292;&#20197;&#21253;&#25324;&#38388;&#26029;&#30340;&#22806;&#37096;&#20449;&#21495;&#12290;&#36825;&#31181;&#28151;&#21512;&#27169;&#22411;&#22312;&#25552;&#35758;&#30340;&#25968;&#25454;&#38598;&#19978;&#25552;&#20379;&#20102;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Developing models and algorithms to predict nonstationary time series is a long standing statistical problem. It is crucial for many applications, in particular for fashion or retail industries, to make optimal inventory decisions and avoid massive wastes. By tracking thousands of fashion trends on social media with state-of-the-art computer vision approaches, we propose a new model for fashion time series forecasting. Our contribution is twofold. We first provide publicly a dataset gathering 10000 weekly fashion time series. As influence dynamics are the key of emerging trend detection, we associate with each time series an external weak signal representing behaviours of influencers. Secondly, to leverage such a dataset, we propose a new hybrid forecasting model. Our approach combines per-time-series parametric models with seasonal components and a global recurrent neural network to include sporadic external signals. This hybrid model provides state-of-the-art results on the proposed 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20272;&#35745;&#20102;&#23454;&#20540;&#20989;&#25968;&#31867;&#32858;&#21512;&#35268;&#21017;&#30340;&#30772;&#35010;&#32500;&#25968;&#65292;&#24182;&#32473;&#20986;&#20102;&#20851;&#20110;&#32447;&#24615;&#21644;&#20223;&#23556;&#20989;&#25968;&#31867;&#30340;&#26356;&#23574;&#38160;&#19978;&#30028;&#21644;&#21305;&#37197;&#30340;&#19979;&#30028;&#12290;&#21516;&#26102;&#25913;&#36827;&#20102;&#24050;&#30693;&#32467;&#26524;&#65292;&#24182;&#32416;&#27491;&#20102;&#25991;&#29486;&#20013;&#30340;&#19968;&#20123;&#38169;&#35823;&#35770;&#26029;&#12290;</title><link>http://arxiv.org/abs/2110.04763</link><description>&lt;p&gt;
$k$&#27425;&#32858;&#21512;&#30340;&#30772;&#35010;&#32500;&#25968;&#65288;arXiv:2110.04763v2 [math.FA]&#24050;&#26356;&#26032;&#65289;
&lt;/p&gt;
&lt;p&gt;
Fat-Shattering Dimension of $k$-fold Aggregations. (arXiv:2110.04763v2 [math.FA] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.04763
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20272;&#35745;&#20102;&#23454;&#20540;&#20989;&#25968;&#31867;&#32858;&#21512;&#35268;&#21017;&#30340;&#30772;&#35010;&#32500;&#25968;&#65292;&#24182;&#32473;&#20986;&#20102;&#20851;&#20110;&#32447;&#24615;&#21644;&#20223;&#23556;&#20989;&#25968;&#31867;&#30340;&#26356;&#23574;&#38160;&#19978;&#30028;&#21644;&#21305;&#37197;&#30340;&#19979;&#30028;&#12290;&#21516;&#26102;&#25913;&#36827;&#20102;&#24050;&#30693;&#32467;&#26524;&#65292;&#24182;&#32416;&#27491;&#20102;&#25991;&#29486;&#20013;&#30340;&#19968;&#20123;&#38169;&#35823;&#35770;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23545;&#23454;&#20540;&#20989;&#25968;&#31867;&#32858;&#21512;&#35268;&#21017;&#30340;&#30772;&#35010;&#32500;&#25968;&#36827;&#34892;&#20102;&#20272;&#35745;&#12290;&#21518;&#32773;&#21253;&#25324;&#36873;&#25321;$k$&#20010;&#20989;&#25968;&#65288;&#27599;&#20010;&#31867;&#36873;&#25321;&#19968;&#20010;&#65289;&#24182;&#35745;&#31639;&#23427;&#20204;&#30340;&#28857;&#20989;&#25968;&#65292;&#22914;&#20013;&#20540;&#12289;&#24179;&#22343;&#20540;&#21644;&#26368;&#22823;&#20540;&#30340;&#25152;&#26377;&#26041;&#24335;&#12290;&#35813;&#30028;&#38480;&#26159;&#22522;&#20110;&#32452;&#25104;&#31867;&#30340;&#30772;&#35010;&#32500;&#25968;&#34920;&#36848;&#30340;&#12290;&#23545;&#20110;&#32447;&#24615;&#21644;&#20223;&#23556;&#20989;&#25968;&#31867;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#26126;&#26174;&#26356;&#23574;&#38160;&#30340;&#19978;&#30028;&#21644;&#19968;&#20010;&#30456;&#21305;&#37197;&#30340;&#19979;&#30028;&#65292;&#23454;&#29616;&#20102;&#23545;$k$&#30340;&#26368;&#20248;&#20381;&#36182;&#12290;&#22312;&#27492;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#25913;&#36827;&#20102;&#20960;&#20010;&#24050;&#30693;&#32467;&#26524;&#65292;&#21516;&#26102;&#25351;&#20986;&#21644;&#32416;&#27491;&#20102;&#25991;&#29486;&#20013;&#30340;&#19968;&#20123;&#38169;&#35823;&#35770;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;
We provide estimates on the fat-shattering dimension of aggregation rules of real-valued function classes. The latter consists of all ways of choosing $k$ functions, one from each of the $k$ classes, and computing a pointwise function of them, such as the median, mean, and maximum. The bound is stated in terms of the fat-shattering dimensions of the component classes. For linear and affine function classes, we provide a considerably sharper upper bound and a matching lower bound, achieving, in particular, an optimal dependence on $k$. Along the way, we improve several known results in addition to pointing out and correcting a number of erroneous claims in the literature.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22797;&#26434;&#24230;&#20248;&#21270;&#31232;&#30095;&#36125;&#21494;&#26031;&#23398;&#20064;&#26041;&#27861;DQN-SBL&#26469;&#35299;&#20915;&#39640;&#32500;&#29305;&#24449;&#31354;&#38388;&#25110;&#22823;&#25968;&#25454;&#35268;&#27169;&#38382;&#39064;&#20013;&#30340;&#20869;&#23384;&#28322;&#20986;&#21644;&#35745;&#31639;&#22797;&#26434;&#24230;&#39640;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;&#22823;&#35268;&#27169;&#38382;&#39064;&#19978;&#23637;&#29616;&#20102;&#31454;&#20105;&#21147;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2107.08195</link><description>&lt;p&gt;
&#29992;&#20110;&#21487;&#25193;&#23637;&#20998;&#31867;&#20219;&#21153;&#30340;&#22797;&#26434;&#24230;&#20248;&#21270;&#31232;&#30095;&#36125;&#21494;&#26031;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Complexity-Optimized Sparse Bayesian Learning for Scalable Classification Tasks. (arXiv:2107.08195v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2107.08195
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22797;&#26434;&#24230;&#20248;&#21270;&#31232;&#30095;&#36125;&#21494;&#26031;&#23398;&#20064;&#26041;&#27861;DQN-SBL&#26469;&#35299;&#20915;&#39640;&#32500;&#29305;&#24449;&#31354;&#38388;&#25110;&#22823;&#25968;&#25454;&#35268;&#27169;&#38382;&#39064;&#20013;&#30340;&#20869;&#23384;&#28322;&#20986;&#21644;&#35745;&#31639;&#22797;&#26434;&#24230;&#39640;&#30340;&#38382;&#39064;&#65292;&#24182;&#22312;&#22823;&#35268;&#27169;&#38382;&#39064;&#19978;&#23637;&#29616;&#20102;&#31454;&#20105;&#21147;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31232;&#30095;&#36125;&#21494;&#26031;&#23398;&#20064;&#65288;Sparse Bayesian Learning&#65292;SBL&#65289;&#26500;&#24314;&#20102;&#19968;&#20010;&#26497;&#20854;&#31232;&#30095;&#30340;&#27010;&#29575;&#27169;&#22411;&#65292;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#28982;&#32780;&#65292;SBL&#38656;&#35201;&#27714;&#35299;&#19968;&#20010;&#22797;&#26434;&#24230;&#20026;$O(M^3)$&#65288;M&#65306;&#29305;&#24449;&#32500;&#24230;&#65289;&#30340;&#22823;&#22411;&#21327;&#26041;&#24046;&#30697;&#38453;&#20197;&#26356;&#26032;&#27491;&#21017;&#21270;&#20808;&#39564;&#65292;&#36825;&#20351;&#24471;&#22312;&#29305;&#24449;&#31354;&#38388;&#32500;&#24230;&#39640;&#25110;&#25968;&#25454;&#35268;&#27169;&#22823;&#30340;&#38382;&#39064;&#20013;&#21464;&#24471;&#22256;&#38590;&#65292;&#23481;&#26131;&#36973;&#36935;&#20869;&#23384;&#28322;&#20986;&#38382;&#39064;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;DQN-SBL&#30340;&#29992;&#20110;SBL&#30340;&#26032;&#22411;&#23545;&#35282;&#25311;&#29275;&#39039;&#65288;Diagonal Quasi-Newton&#65292;DQN&#65289;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#23427;&#24573;&#30053;&#20102;&#22823;&#22411;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#27714;&#36870;&#65292;&#20174;&#32780;&#23558;&#22797;&#26434;&#24230;&#38477;&#20302;&#21040;$O(M)$&#12290;&#21033;&#29992;&#21508;&#31181;&#19981;&#21516;&#35268;&#27169;&#30340;&#22522;&#20934;&#36827;&#34892;&#20102;&#23545;&#38750;&#32447;&#24615;&#21644;&#32447;&#24615;&#20998;&#31867;&#38382;&#39064;&#30340;&#20840;&#38754;&#35780;&#20272;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;DQN-SBL&#22312;&#20855;&#26377;&#38750;&#24120;&#31232;&#30095;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#24182;&#19988;&#33021;&#22815;&#24456;&#22909;&#22320;&#25193;&#23637;&#21040;&#22823;&#35268;&#27169;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Sparse Bayesian Learning (SBL) constructs an extremely sparse probabilistic model with very competitive generalization. However, SBL needs to invert a big covariance matrix with complexity $O(M^3)$ (M: feature size) for updating the regularization priors, making it difficult for problems with high dimensional feature space or large data size. As it may easily suffer from the memory overflow issue in such problems. This paper addresses this issue with a newly proposed diagonal Quasi-Newton (DQN) method for SBL called DQN-SBL where the inversion of big covariance matrix is ignored so that the complexity is reduced to $O(M)$. The DQN-SBL is thoroughly evaluated for non linear and linear classifications with various benchmarks of different sizes. Experimental results verify that DQN-SBL receives competitive generalization with a very sparse model and scales well to large-scale problems.
&lt;/p&gt;</description></item><item><title>AngularGrad&#26159;&#19968;&#31181;&#26032;&#30340;&#20248;&#21270;&#22120;&#65292;&#36890;&#36807;&#32771;&#34385;&#36830;&#32493;&#26799;&#24230;&#30340;&#26041;&#21521;/&#35282;&#24230;&#34892;&#20026;&#26469;&#20248;&#21270;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#35282;&#24230;&#25910;&#25947;&#12290;&#36890;&#36807;&#25429;&#25417;&#35282;&#24230;&#20449;&#24687;&#20197;&#33719;&#24471;&#26356;&#20934;&#30830;&#30340;&#27493;&#38271;&#65292;&#20248;&#21270;&#27493;&#39588;&#21464;&#24471;&#26356;&#21152;&#24179;&#28369;&#12290;</title><link>http://arxiv.org/abs/2105.10190</link><description>&lt;p&gt;
AngularGrad&#65306;&#19968;&#31181;&#29992;&#20110;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#35282;&#24230;&#25910;&#25947;&#30340;&#26032;&#20248;&#21270;&#25216;&#26415;
&lt;/p&gt;
&lt;p&gt;
AngularGrad: A New Optimization Technique for Angular Convergence of Convolutional Neural Networks. (arXiv:2105.10190v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2105.10190
&lt;/p&gt;
&lt;p&gt;
AngularGrad&#26159;&#19968;&#31181;&#26032;&#30340;&#20248;&#21270;&#22120;&#65292;&#36890;&#36807;&#32771;&#34385;&#36830;&#32493;&#26799;&#24230;&#30340;&#26041;&#21521;/&#35282;&#24230;&#34892;&#20026;&#26469;&#20248;&#21270;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#35282;&#24230;&#25910;&#25947;&#12290;&#36890;&#36807;&#25429;&#25417;&#35282;&#24230;&#20449;&#24687;&#20197;&#33719;&#24471;&#26356;&#20934;&#30830;&#30340;&#27493;&#38271;&#65292;&#20248;&#21270;&#27493;&#39588;&#21464;&#24471;&#26356;&#21152;&#24179;&#28369;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;(CNNs)&#20351;&#29992;&#22522;&#20110;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;(SGD)&#30340;&#20248;&#21270;&#22120;&#36827;&#34892;&#35757;&#32451;&#12290;&#26368;&#36817;&#65292;&#33258;&#36866;&#24212;&#26102;&#21051;&#20272;&#35745;(Adam)&#20248;&#21270;&#22120;&#22240;&#20854;&#33258;&#36866;&#24212;&#21160;&#37327;&#32780;&#21464;&#24471;&#38750;&#24120;&#27969;&#34892;&#65292;&#20174;&#32780;&#35299;&#20915;&#20102;SGD&#30340;&#26799;&#24230;&#28040;&#22833;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#20248;&#21270;&#22120;&#20173;&#28982;&#26080;&#27861;&#26377;&#25928;&#21033;&#29992;&#20248;&#21270;&#26354;&#29575;&#20449;&#24687;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;AngularGrad&#20248;&#21270;&#22120;&#65292;&#23427;&#32771;&#34385;&#20102;&#36830;&#32493;&#26799;&#24230;&#30340;&#26041;&#21521;/&#35282;&#24230;&#30340;&#34892;&#20026;&#12290;&#36825;&#26159;&#25991;&#29486;&#20013;&#31532;&#19968;&#27425;&#23581;&#35797;&#21033;&#29992;&#26799;&#24230;&#35282;&#24230;&#20449;&#24687;&#32780;&#19981;&#20165;&#20165;&#26159;&#26799;&#24230;&#22823;&#23567;&#12290;&#25152;&#25552;&#20986;&#30340;AngularGrad&#26681;&#25454;&#20808;&#21069;&#36845;&#20195;&#30340;&#26799;&#24230;&#35282;&#24230;&#20449;&#24687;&#29983;&#25104;&#19968;&#20010;&#24471;&#20998;&#26469;&#25511;&#21046;&#27493;&#38271;&#12290;&#22240;&#27492;&#65292;&#36890;&#36807;&#35282;&#24230;&#20449;&#24687;&#25429;&#33719;&#21040;&#26356;&#20934;&#30830;&#30340;&#36817;&#26399;&#26799;&#24230;&#27493;&#38271;&#65292;&#20248;&#21270;&#27493;&#39588;&#21464;&#24471;&#26356;&#21152;&#24179;&#28369;&#12290;&#22522;&#20110;&#20351;&#29992;&#27491;&#20999;&#25110;&#20313;&#24358;&#20989;&#25968;&#30340;&#20004;&#20010;AngularGrad&#21464;&#20307;&#24471;&#21040;&#20102;&#24320;&#21457;&#12290;
&lt;/p&gt;
&lt;p&gt;
Convolutional neural networks (CNNs) are trained using stochastic gradient descent (SGD)-based optimizers. Recently, the adaptive moment estimation (Adam) optimizer has become very popular due to its adaptive momentum, which tackles the dying gradient problem of SGD. Nevertheless, existing optimizers are still unable to exploit the optimization curvature information efficiently. This paper proposes a new AngularGrad optimizer that considers the behavior of the direction/angle of consecutive gradients. This is the first attempt in the literature to exploit the gradient angular information apart from its magnitude. The proposed AngularGrad generates a score to control the step size based on the gradient angular information of previous iterations. Thus, the optimization steps become smoother as a more accurate step size of immediate past gradients is captured through the angular information. Two variants of AngularGrad are developed based on the use of Tangent or Cosine functions for comp
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#32416;&#27491;&#31616;&#21333;&#30340;&#22522;&#27169;&#22411;&#26469;&#35299;&#37322;AI&#39044;&#27979;&#30340;&#23616;&#37096;&#26367;&#20195;&#26041;&#27861;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#36890;&#36807;&#30830;&#23450;&#20934;&#30830;&#24615;&#25439;&#22833;&#12289;&#20934;&#30830;&#24615;&#21644;&#26367;&#20195;&#21697;&#24544;&#23454;&#24230;&#20043;&#38388;&#30340;&#20934;&#30830;&#20851;&#31995;&#65292;&#21487;&#20197;&#24471;&#21040;&#29702;&#24819;&#22823;&#23567;&#30340;&#35299;&#37322;&#23454;&#20363;&#37051;&#22495;&#65292;&#20197;&#23454;&#29616;&#26368;&#22823;&#30340;&#20934;&#30830;&#24615;&#21644;&#24544;&#23454;&#24230;&#12290;</title><link>http://arxiv.org/abs/2103.07155</link><description>&lt;p&gt;
&#36890;&#36807;BAPC&#8212;&#8212;&#20808;&#21518;&#21442;&#25968;&#27604;&#36739;&#35299;&#37322;AI
&lt;/p&gt;
&lt;p&gt;
Explainable AI by BAPC -- Before and After correction Parameter Comparison. (arXiv:2103.07155v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2103.07155
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#32416;&#27491;&#31616;&#21333;&#30340;&#22522;&#27169;&#22411;&#26469;&#35299;&#37322;AI&#39044;&#27979;&#30340;&#23616;&#37096;&#26367;&#20195;&#26041;&#27861;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#36890;&#36807;&#30830;&#23450;&#20934;&#30830;&#24615;&#25439;&#22833;&#12289;&#20934;&#30830;&#24615;&#21644;&#26367;&#20195;&#21697;&#24544;&#23454;&#24230;&#20043;&#38388;&#30340;&#20934;&#30830;&#20851;&#31995;&#65292;&#21487;&#20197;&#24471;&#21040;&#29702;&#24819;&#22823;&#23567;&#30340;&#35299;&#37322;&#23454;&#20363;&#37051;&#22495;&#65292;&#20197;&#23454;&#29616;&#26368;&#22823;&#30340;&#20934;&#30830;&#24615;&#21644;&#24544;&#23454;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#32416;&#27491;&#31616;&#21333;&#8220;&#22522;&#8221;&#27169;&#22411;&#30340;AI&#27169;&#22411;&#30340;&#23616;&#37096;&#26367;&#20195;&#21697;&#65292;&#34920;&#31034;&#35299;&#37322;AI&#39044;&#27979;&#30340;&#20998;&#26512;&#26041;&#27861;&#12290;&#22312;&#36825;&#37324;&#65292;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;&#22522;&#27169;&#22411;&#20026;&#32447;&#24615;&#22238;&#24402;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;&#30740;&#31350;&#12290;AI&#27169;&#22411;&#36924;&#36817;&#20102;&#32447;&#24615;&#27169;&#22411;&#30340;&#27531;&#24046;&#35823;&#24046;&#65292;&#24182;&#20197;&#21487;&#35299;&#37322;&#30340;&#22522;&#27169;&#22411;&#21442;&#25968;&#30340;&#21464;&#21270;&#24418;&#24335;&#25552;&#20986;&#20102;&#35299;&#37322;&#12290;&#20026;AI&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#25439;&#22833;&#12289;AI&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#21644;&#26367;&#20195;&#21697;&#24544;&#23454;&#24230;&#20043;&#38388;&#30340;&#20934;&#30830;&#20851;&#31995;&#21046;&#23450;&#20102;&#20934;&#21017;&#12290;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#20551;&#35774;&#35266;&#27979;&#25968;&#25454;&#23384;&#22312;&#19968;&#23450;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#65292;&#36825;&#20123;&#20934;&#21017;&#23548;&#33268;&#20102;&#19968;&#20010;&#29702;&#24819;&#22823;&#23567;&#30340;&#38656;&#35201;&#35299;&#37322;&#30340;&#23454;&#20363;&#37051;&#22495;&#65292;&#20197;&#23454;&#29616;&#26368;&#22823;&#30340;&#20934;&#30830;&#24615;&#21644;&#24544;&#23454;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
A local surrogate for an AI-model correcting a simpler 'base' model is introduced representing an analytical method to yield explanations of AI-predictions. The approach is studied here in the context of the base model being linear regression. The AI-model approximates the residual error of the linear model and the explanations are formulated in terms of the change of the interpretable base model's parameters. Criteria are formulated for the precise relation between lost accuracy of the surrogate, the accuracy of the AI-model, and the surrogate fidelity. It is shown that, assuming a certain maximal amount of noise in the observed data, these criteria induce neighborhoods of the instances to be explained which have an ideal size in terms of maximal accuracy and fidelity.
&lt;/p&gt;</description></item><item><title>&#31070;&#32463;ODE&#27169;&#22411;&#30340;&#24615;&#33021;&#21462;&#20915;&#20110;&#35757;&#32451;&#36807;&#31243;&#20013;&#20351;&#29992;&#30340;&#25968;&#20540;&#26041;&#27861;&#65292;&#22914;&#26524;&#20351;&#29992;&#36807;&#20110;&#31895;&#31961;&#30340;&#35299;&#31639;&#22120;&#36827;&#34892;&#35757;&#32451;&#65292;&#21017;&#20351;&#29992;&#21478;&#19968;&#20010;&#25968;&#20540;&#35823;&#24046;&#30456;&#31561;&#25110;&#26356;&#23567;&#30340;&#35299;&#31639;&#22120;&#36827;&#34892;&#27979;&#35797;&#20250;&#23548;&#33268;&#20934;&#30830;&#24615;&#19979;&#38477;&#12290;</title><link>http://arxiv.org/abs/2007.15386</link><description>&lt;p&gt;
&#31350;&#31455;&#26159;ResNet&#65311;&#31070;&#32463;ODE&#21450;&#20854;&#25968;&#20540;&#35299;
&lt;/p&gt;
&lt;p&gt;
ResNet After All? Neural ODEs and Their Numerical Solution. (arXiv:2007.15386v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2007.15386
&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;ODE&#27169;&#22411;&#30340;&#24615;&#33021;&#21462;&#20915;&#20110;&#35757;&#32451;&#36807;&#31243;&#20013;&#20351;&#29992;&#30340;&#25968;&#20540;&#26041;&#27861;&#65292;&#22914;&#26524;&#20351;&#29992;&#36807;&#20110;&#31895;&#31961;&#30340;&#35299;&#31639;&#22120;&#36827;&#34892;&#35757;&#32451;&#65292;&#21017;&#20351;&#29992;&#21478;&#19968;&#20010;&#25968;&#20540;&#35823;&#24046;&#30456;&#31561;&#25110;&#26356;&#23567;&#30340;&#35299;&#31639;&#22120;&#36827;&#34892;&#27979;&#35797;&#20250;&#23548;&#33268;&#20934;&#30830;&#24615;&#19979;&#38477;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#25552;&#20986;&#30340;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;(ODE)&#26694;&#26550;&#20855;&#26377;&#36830;&#32493;&#26102;&#38388;&#25193;&#23637;&#31163;&#25955;&#27531;&#24046;&#31070;&#32463;&#32593;&#32476;&#30340;&#29305;&#28857;&#12290;&#20294;&#26159;&#65292;&#25105;&#20204;&#22312;&#36825;&#37324;&#23637;&#31034;&#65292;&#35757;&#32451;&#30340;&#31070;&#32463;ODE&#27169;&#22411;&#23454;&#38469;&#19978;&#21462;&#20915;&#20110;&#35757;&#32451;&#36807;&#31243;&#20013;&#20351;&#29992;&#30340;&#29305;&#23450;&#25968;&#20540;&#26041;&#27861;&#12290;&#22914;&#26524;&#35757;&#32451;&#20986;&#30340;&#27169;&#22411;&#34987;&#35748;&#20026;&#26159;&#20174;ODE&#29983;&#25104;&#30340;&#27969;&#21160;&#65292;&#37027;&#20040;&#21487;&#20197;&#36873;&#25321;&#21478;&#19968;&#20010;&#25968;&#20540;&#35299;&#31639;&#22120;&#65292;&#20854;&#25968;&#20540;&#35823;&#24046;&#22823;&#23567;&#30456;&#21516;&#25110;&#26356;&#23567;&#65292;&#32780;&#19981;&#20250;&#25439;&#22833;&#24615;&#33021;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#22914;&#26524;&#35757;&#32451;&#20381;&#36182;&#20110;&#36807;&#20110;&#31895;&#31961;&#30340;&#31163;&#25955;&#21270;&#35299;&#31639;&#22120;&#65292;&#21017;&#20351;&#29992;&#21478;&#19968;&#20010;&#25968;&#20540;&#35823;&#24046;&#30456;&#31561;&#25110;&#26356;&#23567;&#30340;&#35299;&#31639;&#22120;&#36827;&#34892;&#27979;&#35797;&#20250;&#23548;&#33268;&#20934;&#30830;&#24615;&#24613;&#21095;&#19979;&#38477;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#21521;&#37327;&#22330;&#21644;&#25968;&#20540;&#26041;&#27861;&#30340;&#32452;&#21512;&#19981;&#33021;&#34987;&#35299;&#37322;&#20026;&#20174;ODE&#29983;&#25104;&#30340;&#27969;&#21160;&#65292;&#36825;&#21487;&#20197;&#34987;&#35748;&#20026;&#26159;&#31070;&#32463;ODE&#27010;&#24565;&#30340;&#33268;&#21629;&#26029;&#35010;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#35266;&#23519;&#21040;&#23384;&#22312;&#19968;&#20010;&#20020;&#30028;&#27493;&#38271;&#65292;&#36229;&#36807;&#35813;&#27493;&#38271;&#65292;&#35757;&#32451;&#20250;&#20135;&#29983;&#19968;&#20010;&#26377;&#25928;&#30340;ODE&#21521;&#37327;&#22330;&#12290;
&lt;/p&gt;
&lt;p&gt;
A key appeal of the recently proposed Neural Ordinary Differential Equation (ODE) framework is that it seems to provide a continuous-time extension of discrete residual neural networks. As we show herein, though, trained Neural ODE models actually depend on the specific numerical method used during training. If the trained model is supposed to be a flow generated from an ODE, it should be possible to choose another numerical solver with equal or smaller numerical error without loss of performance. We observe that if training relies on a solver with overly coarse discretization, then testing with another solver of equal or smaller numerical error results in a sharp drop in accuracy. In such cases, the combination of vector field and numerical method cannot be interpreted as a flow generated from an ODE, which arguably poses a fatal breakdown of the Neural ODE concept. We observe, however, that there exists a critical step size beyond which the training yields a valid ODE vector field. W
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#21452;&#32447;&#24615;LSTM&#26694;&#26550;&#65292;&#36890;&#36807;&#24179;&#34913;&#32447;&#24615;&#21644;&#21452;&#32447;&#24615;&#39033;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#23454;&#29616;&#20102;&#23545;&#24207;&#21015;&#25968;&#25454;&#38598;&#20013;&#36755;&#20837;&#29305;&#24449;&#30340;&#38750;&#32447;&#24615;&#20132;&#20114;&#30340;&#21033;&#29992;&#65292;&#20197;&#23454;&#29616;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#21516;&#26102;&#19981;&#22686;&#21152;&#26356;&#22810;&#30340;&#23398;&#20064;&#21442;&#25968;&#12290;</title><link>http://arxiv.org/abs/1910.10294</link><description>&lt;p&gt;
&#19968;&#20010;&#32479;&#19968;&#30340;&#21452;&#32447;&#24615;LSTM&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
A Unifying Framework of Bilinear LSTMs. (arXiv:1910.10294v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1910.10294
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#21452;&#32447;&#24615;LSTM&#26694;&#26550;&#65292;&#36890;&#36807;&#24179;&#34913;&#32447;&#24615;&#21644;&#21452;&#32447;&#24615;&#39033;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#23454;&#29616;&#20102;&#23545;&#24207;&#21015;&#25968;&#25454;&#38598;&#20013;&#36755;&#20837;&#29305;&#24449;&#30340;&#38750;&#32447;&#24615;&#20132;&#20114;&#30340;&#21033;&#29992;&#65292;&#20197;&#23454;&#29616;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#21516;&#26102;&#19981;&#22686;&#21152;&#26356;&#22810;&#30340;&#23398;&#20064;&#21442;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#39062;&#30340;&#32479;&#19968;&#21452;&#32447;&#24615;LSTM&#26694;&#26550;&#65292;&#21487;&#20197;&#34920;&#31034;&#21644;&#21033;&#29992;&#24207;&#21015;&#25968;&#25454;&#38598;&#20013;&#36755;&#20837;&#29305;&#24449;&#30340;&#38750;&#32447;&#24615;&#20132;&#20114;&#65292;&#20197;&#23454;&#29616;&#27604;&#32447;&#24615;LSTM&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#21516;&#26102;&#19981;&#20250;&#22686;&#21152;&#26356;&#22810;&#38656;&#35201;&#23398;&#20064;&#30340;&#21442;&#25968;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#28857;&#65292;&#25105;&#20204;&#30340;&#32479;&#19968;&#26694;&#26550;&#20801;&#35768;&#36890;&#36807;&#35843;&#25972;&#38544;&#34255;&#29366;&#24577;&#21521;&#37327;&#30340;&#22823;&#23567;&#19982;&#21452;&#32447;&#24615;&#39033;&#20013;&#26435;&#37325;&#30697;&#38453;&#30340;&#36924;&#36817;&#36136;&#37327;&#20043;&#38388;&#30340;&#26435;&#34913;&#26469;&#24179;&#34913;&#32447;&#24615;&#21644;&#21452;&#32447;&#24615;&#39033;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#20174;&#32780;&#20248;&#21270;&#25105;&#20204;&#30340;&#21452;&#32447;&#24615;LSTM&#30340;&#24615;&#33021;&#65292;&#21516;&#26102;&#19981;&#20250;&#22686;&#21152;&#26356;&#22810;&#38656;&#35201;&#23398;&#20064;&#30340;&#21442;&#25968;&#12290;&#25105;&#20204;&#22312;&#20960;&#20010;&#22522;&#20110;&#35821;&#35328;&#30340;&#24207;&#21015;&#23398;&#20064;&#20219;&#21153;&#20013;&#23545;&#25105;&#20204;&#30340;&#21452;&#32447;&#24615;LSTM&#30340;&#24615;&#33021;&#36827;&#34892;&#20102;&#23454;&#35777;&#35780;&#20272;&#65292;&#20197;&#23637;&#31034;&#20854;&#26222;&#36866;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a novel unifying framework of bilinear LSTMs that can represent and utilize the nonlinear interaction of the input features present in sequence datasets for achieving superior performance over a linear LSTM and yet not incur more parameters to be learned. To realize this, our unifying framework allows the expressivity of the linear vs. bilinear terms to be balanced by correspondingly trading off between the hidden state vector size vs. approximation quality of the weight matrix in the bilinear term so as to optimize the performance of our bilinear LSTM, while not incurring more parameters to be learned. We empirically evaluate the performance of our bilinear LSTM in several language-based sequence learning tasks to demonstrate its general applicability.
&lt;/p&gt;</description></item></channel></rss>