<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#31216;&#20026;CAP&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#29983;&#25104;&#31867;&#21035;&#29305;&#23450;&#30340;&#23398;&#20064;&#31574;&#30053;&#26469;&#26356;&#22909;&#22320;&#36866;&#24212;&#24322;&#36136;&#24615;&#25968;&#25454;&#65292;&#24182;&#22312;&#25439;&#22833;&#20989;&#25968;&#35774;&#35745;&#21644;&#26631;&#31614;&#19981;&#24179;&#34913;&#38382;&#39064;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2401.14343</link><description>&lt;p&gt;
&#31867;&#23646;&#24615;&#20808;&#39564;&#65306;&#23558;&#20248;&#21270;&#26041;&#27861;&#24212;&#29992;&#20110;&#24322;&#36136;&#24615;&#21644;&#20844;&#24179;&#30446;&#26631;
&lt;/p&gt;
&lt;p&gt;
Class-attribute Priors: Adapting Optimization to Heterogeneity and Fairness Objective. (arXiv:2401.14343v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14343
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#31216;&#20026;CAP&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#29983;&#25104;&#31867;&#21035;&#29305;&#23450;&#30340;&#23398;&#20064;&#31574;&#30053;&#26469;&#26356;&#22909;&#22320;&#36866;&#24212;&#24322;&#36136;&#24615;&#25968;&#25454;&#65292;&#24182;&#22312;&#25439;&#22833;&#20989;&#25968;&#35774;&#35745;&#21644;&#26631;&#31614;&#19981;&#24179;&#34913;&#38382;&#39064;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#20998;&#31867;&#38382;&#39064;&#22312;&#21508;&#20010;&#31867;&#21035;&#20043;&#38388;&#23384;&#22312;&#24322;&#36136;&#24615;&#65306;&#27599;&#20010;&#31867;&#21035;&#21487;&#33021;&#20855;&#26377;&#29420;&#29305;&#30340;&#23646;&#24615;&#65292;&#20363;&#22914;&#26679;&#26412;&#22823;&#23567;&#65292;&#26631;&#31614;&#36136;&#37327;&#25110;&#21487;&#39044;&#27979;&#24615;&#65288;&#26131; vs &#38590;&#65289;&#65292;&#20197;&#21450;&#22312;&#27979;&#35797;&#26102;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#12290;&#22914;&#26524;&#19981;&#27880;&#24847;&#22788;&#29702;&#65292;&#36825;&#20123;&#24322;&#36136;&#24615;&#20250;&#38459;&#30861;&#23398;&#20064;&#36807;&#31243;&#65292;&#23588;&#20854;&#26159;&#22312;&#20248;&#21270;&#20844;&#24179;&#30446;&#26631;&#26102;&#12290;&#22312;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#35774;&#23450;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20026;&#20102;&#36798;&#21040;&#24179;&#34913;&#20934;&#30830;&#24230;&#65292;&#26368;&#20248;&#30340;&#25903;&#25345;&#21521;&#37327;&#26426;&#20998;&#31867;&#22120;&#38656;&#35201;&#36866;&#24212;&#31867;&#21035;&#23646;&#24615;&#12290;&#36825;&#28608;&#21457;&#20102;&#25105;&#20204;&#25552;&#20986;&#20102;CAP&#65306;&#19968;&#31181;&#22522;&#20110;&#31867;&#21035;&#23646;&#24615;&#29983;&#25104;&#31867;&#21035;&#29305;&#23450;&#23398;&#20064;&#31574;&#30053;&#65288;&#20363;&#22914;&#36229;&#21442;&#25968;&#65289;&#30340;&#26377;&#25928;&#21644;&#36890;&#29992;&#26041;&#27861;&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#24335;&#65292;&#20248;&#21270;&#36807;&#31243;&#26356;&#22909;&#22320;&#36866;&#24212;&#24322;&#36136;&#24615;&#12290;CAP&#30456;&#27604;&#20110;&#23558;&#19981;&#21516;&#30340;&#36229;&#21442;&#25968;&#20998;&#37197;&#32473;&#27599;&#20010;&#31867;&#21035;&#30340;&#26420;&#32032;&#26041;&#27861;&#26377;&#26174;&#33879;&#25913;&#36827;&#12290;&#25105;&#20204;&#23558;CAP&#23454;&#20363;&#21270;&#20026;&#25439;&#22833;&#20989;&#25968;&#35774;&#35745;&#21644;&#20107;&#21518;&#23545;&#25968;&#35843;&#25972;&#65292;&#37325;&#28857;&#20851;&#27880;&#26631;&#31614;&#19981;&#24179;&#34913;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern classification problems exhibit heterogeneities across individual classes: Each class may have unique attributes, such as sample size, label quality, or predictability (easy vs difficult), and variable importance at test-time. Without care, these heterogeneities impede the learning process, most notably, when optimizing fairness objectives. Confirming this, under a gaussian mixture setting, we show that the optimal SVM classifier for balanced accuracy needs to be adaptive to the class attributes. This motivates us to propose CAP: An effective and general method that generates a class-specific learning strategy (e.g. hyperparameter) based on the attributes of that class. This way, optimization process better adapts to heterogeneities. CAP leads to substantial improvements over the naive approach of assigning separate hyperparameters to each class. We instantiate CAP for loss function design and post-hoc logit adjustment, with emphasis on label-imbalanced problems. We show that CA
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24471;&#20998;&#32467;&#26500;&#20808;&#39564;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#37096;&#20998;&#24050;&#30693;&#39640;&#26031;&#22270;&#27169;&#22411;&#12290;&#36890;&#36807;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#26469;&#20272;&#35745;&#22270;&#30340;&#24471;&#20998;&#20989;&#25968;&#65292;&#25105;&#20204;&#21487;&#20197;&#22312;&#29983;&#25104;&#26679;&#26412;&#26102;&#21033;&#29992;&#36864;&#28779;&#26391;&#26684;&#32500;&#33021;&#25193;&#25955;&#65292;&#20174;&#32780;&#26356;&#20934;&#30830;&#22320;&#20272;&#35745;&#21518;&#39564;&#20998;&#24067;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#26126;&#26174;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2401.14340</link><description>&lt;p&gt;
&#22522;&#20110;&#24471;&#20998;&#32467;&#26500;&#20808;&#39564;&#30340;&#37096;&#20998;&#24050;&#30693;&#39640;&#26031;&#22270;&#27169;&#22411;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Estimation of partially known Gaussian graphical models with score-based structural priors. (arXiv:2401.14340v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14340
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24471;&#20998;&#32467;&#26500;&#20808;&#39564;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#37096;&#20998;&#24050;&#30693;&#39640;&#26031;&#22270;&#27169;&#22411;&#12290;&#36890;&#36807;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#26469;&#20272;&#35745;&#22270;&#30340;&#24471;&#20998;&#20989;&#25968;&#65292;&#25105;&#20204;&#21487;&#20197;&#22312;&#29983;&#25104;&#26679;&#26412;&#26102;&#21033;&#29992;&#36864;&#28779;&#26391;&#26684;&#32500;&#33021;&#25193;&#25955;&#65292;&#20174;&#32780;&#26356;&#20934;&#30830;&#22320;&#20272;&#35745;&#21518;&#39564;&#20998;&#24067;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20855;&#26377;&#26126;&#26174;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#25903;&#25345;&#20272;&#35745;&#37096;&#20998;&#24050;&#30693;&#30340;&#39640;&#26031;&#22270;&#27169;&#22411;&#65292;&#24182;&#19988;&#32467;&#21512;&#20102;&#20851;&#20110;&#24213;&#23618;&#22270;&#30340;&#20808;&#39564;&#20449;&#24687;&#12290;&#19982;&#20256;&#32479;&#26041;&#27861;&#30456;&#27604;&#65292;&#20256;&#32479;&#26041;&#27861;&#20351;&#29992;&#28857;&#20272;&#35745;&#26041;&#27861;&#22522;&#20110;&#26368;&#22823;&#20284;&#28982;&#25110;&#26368;&#22823;&#21518;&#39564;&#20934;&#21017;&#65292;&#24182;&#20351;&#29992;&#65288;&#31616;&#21333;&#30340;&#65289;&#31934;&#24230;&#30697;&#38453;&#20808;&#39564;&#26469;&#25552;&#20379;&#28857;&#20272;&#35745;&#12290;&#25105;&#20204;&#32771;&#34385;&#23545;&#22270;&#36827;&#34892;&#20808;&#39564;&#65292;&#24182;&#20381;&#36182;&#36864;&#28779;&#26391;&#26684;&#32500;&#33021;&#25193;&#25955;&#20174;&#21518;&#39564;&#20998;&#24067;&#20013;&#29983;&#25104;&#26679;&#26412;&#12290;&#30001;&#20110;&#26391;&#26684;&#32500;&#33021;&#37319;&#26679;&#22120;&#38656;&#35201;&#35775;&#38382;&#24213;&#23618;&#22270;&#20808;&#39564;&#30340;&#24471;&#20998;&#20989;&#25968;&#65292;&#22240;&#27492;&#25105;&#20204;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#26469;&#26377;&#25928;&#22320;&#20174;&#22270;&#25968;&#25454;&#38598;&#65288;&#20107;&#20808;&#21487;&#29992;&#25110;&#20174;&#24050;&#30693;&#20998;&#24067;&#29983;&#25104;&#65289;&#20272;&#35745;&#24471;&#20998;&#12290;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel algorithm for the support estimation of partially known Gaussian graphical models that incorporates prior information about the underlying graph. In contrast to classical approaches that provide a point estimate based on a maximum likelihood or a maximum a posteriori criterion using (simple) priors on the precision matrix, we consider a prior on the graph and rely on annealed Langevin diffusion to generate samples from the posterior distribution. Since the Langevin sampler requires access to the score function of the underlying graph prior, we use graph neural networks to effectively estimate the score from a graph dataset (either available beforehand or generated from a known distribution). Numerical experiments demonstrate the benefits of our approach.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#36890;&#36807;&#24314;&#31435;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#21033;&#29992;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#21644;&#20449;&#24687;&#35770;&#26469;&#20934;&#30830;&#37327;&#21270;&#21644;&#26816;&#27979;&#20449;&#24687;&#27844;&#28431;&#65292;&#36890;&#36807;&#36817;&#20284;&#36125;&#21494;&#26031;&#39044;&#27979;&#30340;&#23545;&#25968;&#25439;&#22833;&#21644;&#20934;&#30830;&#24615;&#26469;&#20934;&#30830;&#20272;&#35745;&#20114;&#20449;&#24687;&#12290;</title><link>http://arxiv.org/abs/2401.14283</link><description>&lt;p&gt;
&#36890;&#36807;&#36817;&#20284;&#36125;&#21494;&#26031;&#26368;&#20248;&#39044;&#27979;&#26816;&#27979;&#20449;&#24687;&#27844;&#28431;
&lt;/p&gt;
&lt;p&gt;
Information Leakage Detection through Approximate Bayes-optimal Prediction. (arXiv:2401.14283v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14283
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#36890;&#36807;&#24314;&#31435;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#65292;&#21033;&#29992;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#21644;&#20449;&#24687;&#35770;&#26469;&#20934;&#30830;&#37327;&#21270;&#21644;&#26816;&#27979;&#20449;&#24687;&#27844;&#28431;&#65292;&#36890;&#36807;&#36817;&#20284;&#36125;&#21494;&#26031;&#39044;&#27979;&#30340;&#23545;&#25968;&#25439;&#22833;&#21644;&#20934;&#30830;&#24615;&#26469;&#20934;&#30830;&#20272;&#35745;&#20114;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20170;&#22825;&#30340;&#20197;&#25968;&#25454;&#39537;&#21160;&#30340;&#19990;&#30028;&#20013;&#65292;&#20844;&#24320;&#21487;&#33719;&#24471;&#30340;&#20449;&#24687;&#30340;&#22686;&#21152;&#21152;&#21095;&#20102;&#20449;&#24687;&#27844;&#28431;&#65288;IL&#65289;&#30340;&#25361;&#25112;&#65292;&#24341;&#21457;&#20102;&#23433;&#20840;&#38382;&#39064;&#12290;IL&#28041;&#21450;&#36890;&#36807;&#31995;&#32479;&#30340;&#21487;&#35266;&#23519;&#20449;&#24687;&#26080;&#24847;&#22320;&#23558;&#31192;&#23494;&#65288;&#25935;&#24863;&#65289;&#20449;&#24687;&#26292;&#38706;&#32473;&#26410;&#32463;&#25480;&#26435;&#30340;&#26041;&#65292;&#20256;&#32479;&#30340;&#32479;&#35745;&#26041;&#27861;&#36890;&#36807;&#20272;&#35745;&#21487;&#35266;&#23519;&#20449;&#24687;&#21644;&#31192;&#23494;&#20449;&#24687;&#20043;&#38388;&#30340;&#20114;&#20449;&#24687;&#65288;MI&#65289;&#26469;&#26816;&#27979;IL&#65292;&#38754;&#20020;&#32500;&#24230;&#28798;&#38590;&#12289;&#25910;&#25947;&#12289;&#35745;&#31639;&#22797;&#26434;&#24230;&#21644;MI&#20272;&#35745;&#38169;&#35823;&#31561;&#25361;&#25112;&#12290;&#27492;&#22806;&#65292;&#34429;&#28982;&#26032;&#20852;&#30340;&#30417;&#30563;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#26041;&#27861;&#22312;&#20108;&#36827;&#21046;&#31995;&#32479;&#25935;&#24863;&#20449;&#24687;&#30340;&#26816;&#27979;&#19978;&#26377;&#25928;&#65292;&#20294;&#32570;&#20047;&#19968;&#20010;&#20840;&#38754;&#30340;&#29702;&#35770;&#26694;&#26550;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#20351;&#29992;&#32479;&#35745;&#23398;&#20064;&#29702;&#35770;&#21644;&#20449;&#24687;&#35770;&#24314;&#31435;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#26469;&#20934;&#30830;&#37327;&#21270;&#21644;&#26816;&#27979;IL&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#21487;&#20197;&#36890;&#36807;&#36817;&#20284;&#36125;&#21494;&#26031;&#39044;&#27979;&#30340;&#23545;&#25968;&#25439;&#22833;&#21644;&#20934;&#30830;&#24615;&#26469;&#20934;&#30830;&#20272;&#35745;MI&#12290;
&lt;/p&gt;
&lt;p&gt;
In today's data-driven world, the proliferation of publicly available information intensifies the challenge of information leakage (IL), raising security concerns. IL involves unintentionally exposing secret (sensitive) information to unauthorized parties via systems' observable information. Conventional statistical approaches, which estimate mutual information (MI) between observable and secret information for detecting IL, face challenges such as the curse of dimensionality, convergence, computational complexity, and MI misestimation. Furthermore, emerging supervised machine learning (ML) methods, though effective, are limited to binary system-sensitive information and lack a comprehensive theoretical framework. To address these limitations, we establish a theoretical framework using statistical learning theory and information theory to accurately quantify and detect IL. We demonstrate that MI can be accurately estimated by approximating the log-loss and accuracy of the Bayes predict
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#36890;&#36807;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#21644;&#26497;&#20540;&#29702;&#35770;&#39537;&#21160;&#30340;&#27169;&#22411;&#65292;&#24320;&#21457;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26041;&#27861;&#26469;&#20272;&#35745;&#28369;&#22369;&#28798;&#23475;&#12290;&#36825;&#31181;&#26041;&#27861;&#23558;&#28369;&#22369;&#20301;&#32622;&#30340;&#31354;&#38388;&#20449;&#24687;&#12289;&#23041;&#32961;&#31243;&#24230;&#21644;&#39057;&#29575;&#32467;&#21512;&#36215;&#26469;&#65292;&#22635;&#34917;&#20102;&#30446;&#21069;&#22312;&#22788;&#29702;&#22823;&#33539;&#22260;&#22320;&#21306;&#26102;&#20165;&#32771;&#34385;&#20004;&#20010;&#20803;&#32032;&#30340;&#19981;&#36275;&#20043;&#22788;&#12290;</title><link>http://arxiv.org/abs/2401.14210</link><description>&lt;p&gt;
&#22312;&#28145;&#24230;&#23398;&#20064;&#19982;&#26497;&#20540;&#32479;&#35745;&#20043;&#38388;&#65306;&#23545;&#28369;&#22369;&#28798;&#23475;&#23450;&#20041;&#30340;&#24418;&#24335;&#21270;
&lt;/p&gt;
&lt;p&gt;
At the junction between deep learning and statistics of extremes: formalizing the landslide hazard definition. (arXiv:2401.14210v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14210
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#36890;&#36807;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#21644;&#26497;&#20540;&#29702;&#35770;&#39537;&#21160;&#30340;&#27169;&#22411;&#65292;&#24320;&#21457;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26041;&#27861;&#26469;&#20272;&#35745;&#28369;&#22369;&#28798;&#23475;&#12290;&#36825;&#31181;&#26041;&#27861;&#23558;&#28369;&#22369;&#20301;&#32622;&#30340;&#31354;&#38388;&#20449;&#24687;&#12289;&#23041;&#32961;&#31243;&#24230;&#21644;&#39057;&#29575;&#32467;&#21512;&#36215;&#26469;&#65292;&#22635;&#34917;&#20102;&#30446;&#21069;&#22312;&#22788;&#29702;&#22823;&#33539;&#22260;&#22320;&#21306;&#26102;&#20165;&#32771;&#34385;&#20004;&#20010;&#20803;&#32032;&#30340;&#19981;&#36275;&#20043;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28369;&#22369;&#28798;&#23475;&#30340;&#26368;&#24120;&#29992;&#23450;&#20041;&#32467;&#21512;&#20102;&#28369;&#22369;&#20301;&#32622;&#30340;&#31354;&#38388;&#20449;&#24687;&#65288;&#26131;&#21457;&#24615;&#65289;&#12289;&#23041;&#32961;&#31243;&#24230;&#65288;&#24378;&#24230;&#65289;&#21644;&#39057;&#29575;&#65288;&#37325;&#29616;&#26399;&#65289;&#12290;&#22312;&#22788;&#29702;&#22823;&#33539;&#22260;&#22320;&#21306;&#26102;&#65292;&#36890;&#24120;&#21482;&#32771;&#34385;&#21644;&#20272;&#35745;&#21069;&#20004;&#20010;&#20803;&#32032;&#12290;&#21363;&#20415;&#22914;&#27492;&#65292;&#20998;&#31163;&#30340;&#27169;&#22411;&#20173;&#26159;&#26631;&#20934;&#65292;&#23545;&#39057;&#29575;&#30340;&#30740;&#31350;&#24456;&#23569;&#12290;&#39057;&#29575;&#21644;&#24378;&#24230;&#30456;&#20114;&#20132;&#32455;&#24182;&#30456;&#20114;&#20381;&#36182;&#65292;&#22240;&#20026;&#26356;&#22823;&#35268;&#27169;&#30340;&#20107;&#20214;&#21457;&#29983;&#30340;&#39057;&#29575;&#36739;&#20302;&#65292;&#21453;&#20043;&#20134;&#28982;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#32570;&#20047;&#22810;&#26102;&#26399;&#28165;&#21333;&#21644;&#32852;&#21512;&#32479;&#35745;&#27169;&#22411;&#65292;&#36890;&#36807;&#32479;&#19968;&#30340;&#28798;&#23475;&#27169;&#22411;&#23545;&#36825;&#20123;&#23646;&#24615;&#36827;&#34892;&#24314;&#27169;&#19968;&#30452;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#23578;&#26410;&#23581;&#35797;&#36807;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#32479;&#19968;&#27169;&#22411;&#65292;&#20197;&#21333;&#20803;&#22369;&#24230;&#27700;&#24179;&#20272;&#35745;&#28369;&#22369;&#28798;&#23475;&#65292;&#20197;&#35299;&#20915;&#36825;&#20123;&#24046;&#36317;&#12290;&#25105;&#20204;&#37319;&#29992;&#28145;&#24230;&#23398;&#20064;&#32467;&#21512;&#26497;&#20540;&#29702;&#35770;&#39537;&#21160;&#30340;&#27169;&#22411;&#65292;&#20998;&#26512;&#20102;&#23612;&#27850;&#23572;30&#24180;&#22303;&#22756;&#38477;&#38632;&#24341;&#21457;&#28369;&#22369;&#30340;&#28165;&#21333;&#65292;&#24182;&#35780;&#20272;&#20102;&#22810;&#20010;&#22320;&#21306;&#30340;&#28369;&#22369;&#28798;&#23475;&#12290;
&lt;/p&gt;
&lt;p&gt;
The most adopted definition of landslide hazard combines spatial information about landslide location (susceptibility), threat (intensity), and frequency (return period). Only the first two elements are usually considered and estimated when working over vast areas. Even then, separate models constitute the standard, with frequency being rarely investigated. Frequency and intensity are intertwined and depend on each other because larger events occur less frequently and vice versa. However, due to the lack of multi-temporal inventories and joint statistical models, modelling such properties via a unified hazard model has always been challenging and has yet to be attempted. Here, we develop a unified model to estimate landslide hazard at the slope unit level to address such gaps. We employed deep learning, combined with a model motivated by extreme-value theory to analyse an inventory of 30 years of observed rainfall-triggered landslides in Nepal and assess landslide hazard for multiple r
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#36890;&#36807;&#27169;&#25311;&#23454;&#39564;&#27604;&#36739;&#20102;&#20256;&#32479;&#30340;&#22810;&#37325;&#25554;&#34917;&#19982;&#22522;&#20110;&#26641;&#30340;&#26041;&#27861;&#22312;&#22810;&#23618;&#25968;&#25454;&#19978;&#30340;&#24615;&#33021;&#65292;&#21457;&#29616;MICE&#22312;&#20934;&#30830;&#30340;&#25298;&#32477;&#29575;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#65292;&#32780;&#26497;&#38480;&#26799;&#24230;&#25552;&#21319;&#22312;&#20943;&#23569;&#20559;&#24046;&#26041;&#38754;&#34920;&#29616;&#36739;&#22909;&#12290;</title><link>http://arxiv.org/abs/2401.14161</link><description>&lt;p&gt;
&#36866;&#24212;&#22810;&#23618;&#25968;&#25454;&#30340;&#22522;&#20110;&#26641;&#30340;&#22810;&#37325;&#25554;&#34917;&#26041;&#27861;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Adapting tree-based multiple imputation methods for multi-level data? A simulation study. (arXiv:2401.14161v1 [stat.AP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14161
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#36890;&#36807;&#27169;&#25311;&#23454;&#39564;&#27604;&#36739;&#20102;&#20256;&#32479;&#30340;&#22810;&#37325;&#25554;&#34917;&#19982;&#22522;&#20110;&#26641;&#30340;&#26041;&#27861;&#22312;&#22810;&#23618;&#25968;&#25454;&#19978;&#30340;&#24615;&#33021;&#65292;&#21457;&#29616;MICE&#22312;&#20934;&#30830;&#30340;&#25298;&#32477;&#29575;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#65292;&#32780;&#26497;&#38480;&#26799;&#24230;&#25552;&#21319;&#22312;&#20943;&#23569;&#20559;&#24046;&#26041;&#38754;&#34920;&#29616;&#36739;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#27169;&#25311;&#30740;&#31350;&#35780;&#20272;&#20102;&#38024;&#23545;&#22810;&#23618;&#25968;&#25454;&#30340;&#22810;&#37325;&#25554;&#34917;(MI)&#25216;&#26415;&#30340;&#26377;&#25928;&#24615;&#12290;&#23427;&#27604;&#36739;&#20102;&#20256;&#32479;&#30340;&#20197;&#38142;&#24335;&#26041;&#31243;&#20026;&#22522;&#30784;&#30340;&#22810;&#37325;&#25554;&#34917;(MICE)&#19982;&#22522;&#20110;&#26641;&#30340;&#26041;&#27861;&#65288;&#22914;&#38142;&#24335;&#38543;&#26426;&#26862;&#26519;&#19982;&#39044;&#27979;&#22343;&#20540;&#21305;&#37197;&#21644;&#26497;&#38480;&#26799;&#24230;&#25552;&#21319;&#65289;&#30340;&#24615;&#33021;&#12290;&#36824;&#23545;&#22522;&#20110;&#26641;&#30340;&#26041;&#27861;&#21253;&#25324;&#20102;&#21253;&#25324;&#38598;&#32676;&#25104;&#21592;&#30340;&#34394;&#25311;&#21464;&#37327;&#30340;&#25913;&#36827;&#29256;&#26412;&#36827;&#34892;&#20102;&#35780;&#20272;&#12290;&#35813;&#30740;&#31350;&#20351;&#29992;&#20855;&#26377;&#19981;&#21516;&#38598;&#32676;&#22823;&#23567;(25&#21644;50)&#21644;&#19981;&#23436;&#25972;&#31243;&#24230;(10\%&#21644;50\%)&#30340;&#27169;&#25311;&#20998;&#23618;&#25968;&#25454;&#23545;&#31995;&#25968;&#20272;&#35745;&#20559;&#24046;&#12289;&#32479;&#35745;&#21151;&#25928;&#21644;&#31867;&#22411;I&#38169;&#35823;&#29575;&#36827;&#34892;&#35780;&#20272;&#12290;&#31995;&#25968;&#26159;&#20351;&#29992;&#38543;&#26426;&#25130;&#36317;&#21644;&#38543;&#26426;&#26012;&#29575;&#27169;&#22411;&#36827;&#34892;&#20272;&#35745;&#30340;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#34429;&#28982;MICE&#26356;&#36866;&#21512;&#20934;&#30830;&#30340;&#25298;&#32477;&#29575;&#65292;&#20294;&#26497;&#38480;&#26799;&#24230;&#25552;&#21319;&#26377;&#21161;&#20110;&#20943;&#23569;&#20559;&#24046;&#12290;&#27492;&#22806;&#65292;&#30740;&#31350;&#21457;&#29616;&#65292;&#19981;&#21516;&#38598;&#32676;&#22823;&#23567;&#30340;&#20559;&#24046;&#27700;&#24179;&#30456;&#20284;&#65292;&#20294;&#25298;&#32477;&#29575;&#22312;&#23569;&#25968;&#32570;&#22833;&#24773;&#20917;&#19979;&#36739;&#19981;&#29702;&#24819;&#12290;
&lt;/p&gt;
&lt;p&gt;
This simulation study evaluates the effectiveness of multiple imputation (MI) techniques for multilevel data. It compares the performance of traditional Multiple Imputation by Chained Equations (MICE) with tree-based methods such as Chained Random Forests with Predictive Mean Matching and Extreme Gradient Boosting. Adapted versions that include dummy variables for cluster membership are also included for the tree-based methods. Methods are evaluated for coefficient estimation bias, statistical power, and type I error rates on simulated hierarchical data with different cluster sizes (25 and 50) and levels of missingness (10\% and 50\%). Coefficients are estimated using random intercept and random slope models. The results show that while MICE is preferred for accurate rejection rates, Extreme Gradient Boosting is advantageous for reducing bias. Furthermore, the study finds that bias levels are similar across different cluster sizes, but rejection rates tend to be less favorable with few
&lt;/p&gt;</description></item><item><title>&#22522;&#20110;&#33021;&#37327;&#30340;&#27010;&#24565;&#29942;&#39048;&#27169;&#22411;&#32479;&#19968;&#20102;&#39044;&#27979;&#12289;&#27010;&#24565;&#24178;&#39044;&#21644;&#26465;&#20214;&#35299;&#37322;&#30340;&#21151;&#33021;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#22312;&#39640;&#38454;&#38750;&#32447;&#24615;&#30456;&#20114;&#20316;&#29992;&#21644;&#22797;&#26434;&#26465;&#20214;&#20381;&#36182;&#20851;&#31995;&#19978;&#30340;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2401.14142</link><description>&lt;p&gt;
&#22522;&#20110;&#33021;&#37327;&#30340;&#27010;&#24565;&#29942;&#39048;&#27169;&#22411;&#65306;&#32479;&#19968;&#39044;&#27979;&#12289;&#27010;&#24565;&#24178;&#39044;&#21644;&#26465;&#20214;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Energy-Based Concept Bottleneck Models: Unifying Prediction, Concept Intervention, and Conditional Interpretations. (arXiv:2401.14142v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.14142
&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#33021;&#37327;&#30340;&#27010;&#24565;&#29942;&#39048;&#27169;&#22411;&#32479;&#19968;&#20102;&#39044;&#27979;&#12289;&#27010;&#24565;&#24178;&#39044;&#21644;&#26465;&#20214;&#35299;&#37322;&#30340;&#21151;&#33021;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#22312;&#39640;&#38454;&#38750;&#32447;&#24615;&#30456;&#20114;&#20316;&#29992;&#21644;&#22797;&#26434;&#26465;&#20214;&#20381;&#36182;&#20851;&#31995;&#19978;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#26377;&#26041;&#27861;&#65292;&#22914;&#27010;&#24565;&#29942;&#39048;&#27169;&#22411; (CBM)&#65292;&#22312;&#20026;&#40657;&#30418;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#25552;&#20379;&#22522;&#20110;&#27010;&#24565;&#30340;&#35299;&#37322;&#26041;&#38754;&#21462;&#24471;&#20102;&#25104;&#21151;&#12290;&#23427;&#20204;&#36890;&#24120;&#36890;&#36807;&#22312;&#32473;&#23450;&#36755;&#20837;&#30340;&#24773;&#20917;&#19979;&#39044;&#27979;&#27010;&#24565;&#65292;&#28982;&#21518;&#22312;&#32473;&#23450;&#39044;&#27979;&#30340;&#27010;&#24565;&#30340;&#24773;&#20917;&#19979;&#39044;&#27979;&#26368;&#32456;&#30340;&#31867;&#21035;&#26631;&#31614;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#32463;&#24120;&#26080;&#27861;&#25429;&#25417;&#21040;&#27010;&#24565;&#20043;&#38388;&#30340;&#39640;&#38454;&#38750;&#32447;&#24615;&#30456;&#20114;&#20316;&#29992;&#65292;&#20363;&#22914;&#32416;&#27491;&#19968;&#20010;&#39044;&#27979;&#30340;&#27010;&#24565;&#65288;&#20363;&#22914;&#8220;&#40644;&#33394;&#33016;&#37096;&#8221;&#65289;&#26080;&#27861;&#24110;&#21161;&#32416;&#27491;&#39640;&#24230;&#30456;&#20851;&#30340;&#27010;&#24565;&#65288;&#20363;&#22914;&#8220;&#40644;&#33394;&#33145;&#37096;&#8221;&#65289;&#65292;&#23548;&#33268;&#26368;&#32456;&#20934;&#30830;&#29575;&#19981;&#29702;&#24819;&#65307;&#23427;&#20204;&#26080;&#27861;&#33258;&#28982;&#22320;&#37327;&#21270;&#19981;&#21516;&#27010;&#24565;&#21644;&#31867;&#21035;&#26631;&#31614;&#20043;&#38388;&#30340;&#22797;&#26434;&#26465;&#20214;&#20381;&#36182;&#20851;&#31995;&#65288;&#20363;&#22914;&#23545;&#20110;&#19968;&#20010;&#24102;&#26377;&#31867;&#21035;&#26631;&#31614;&#8220;Kentucky Warbler&#8221;&#21644;&#27010;&#24565;&#8220;&#40657;&#33394;&#22068;&#24052;&#8221;&#30340;&#22270;&#20687;&#65292;&#27169;&#22411;&#33021;&#22815;&#27491;&#30830;&#39044;&#27979;&#21478;&#19968;&#20010;&#27010;&#24565;&#8220;&#40657;&#33394;&#20896;&#8221;&#30340;&#27010;&#29575;&#26159;&#22810;&#23569;&#65289;&#65292;&#22240;&#27492;&#26080;&#27861;&#25552;&#20379;&#20851;&#20110;&#40657;&#30418;&#27169;&#22411;&#24037;&#20316;&#21407;&#29702;&#26356;&#28145;&#23618;&#27425;&#30340;&#27934;&#23519;&#12290;&#38024;&#23545;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#33021;&#37327;&#30340;&#27010;&#24565;&#29942;&#39048;&#27169;&#22411;&#65288;Energy-based Concept Bottleneck Models&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Existing methods, such as concept bottleneck models (CBMs), have been successful in providing concept-based interpretations for black-box deep learning models. They typically work by predicting concepts given the input and then predicting the final class label given the predicted concepts. However, (1) they often fail to capture the high-order, nonlinear interaction between concepts, e.g., correcting a predicted concept (e.g., "yellow breast") does not help correct highly correlated concepts (e.g., "yellow belly"), leading to suboptimal final accuracy; (2) they cannot naturally quantify the complex conditional dependencies between different concepts and class labels (e.g., for an image with the class label "Kentucky Warbler" and a concept "black bill", what is the probability that the model correctly predicts another concept "black crown"), therefore failing to provide deeper insight into how a black-box model works. In response to these limitations, we propose Energy-based Concept Bot
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#19968;&#31181;&#26032;&#30340;&#21453;&#20107;&#23454;&#25512;&#29702;&#33539;&#24335;&#65292;&#22522;&#20110;&#22238;&#28335;&#21453;&#20107;&#23454;&#65292;&#36890;&#36807;&#22238;&#28335;&#24050;&#26377;&#36335;&#24452;&#65292;&#32780;&#19981;&#26159;&#24819;&#35937;&#22312;&#27861;&#24459;&#20445;&#25252;&#29305;&#24449;&#19978;&#36827;&#34892;&#30340;&#21487;&#24178;&#39044;&#30340;&#20551;&#35774;&#24178;&#39044;&#12290;</title><link>http://arxiv.org/abs/2401.13935</link><description>&lt;p&gt;
&#20844;&#24179;&#24615;&#21644;&#25937;&#27982;&#20013;&#21453;&#20107;&#23454;&#25512;&#29702;&#30340;&#26032;&#33539;&#24335;
&lt;/p&gt;
&lt;p&gt;
A New Paradigm for Counterfactual Reasoning in Fairness and Recourse. (arXiv:2401.13935v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13935
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#32034;&#20102;&#19968;&#31181;&#26032;&#30340;&#21453;&#20107;&#23454;&#25512;&#29702;&#33539;&#24335;&#65292;&#22522;&#20110;&#22238;&#28335;&#21453;&#20107;&#23454;&#65292;&#36890;&#36807;&#22238;&#28335;&#24050;&#26377;&#36335;&#24452;&#65292;&#32780;&#19981;&#26159;&#24819;&#35937;&#22312;&#27861;&#24459;&#20445;&#25252;&#29305;&#24449;&#19978;&#36827;&#34892;&#30340;&#21487;&#24178;&#39044;&#30340;&#20551;&#35774;&#24178;&#39044;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21453;&#20107;&#23454;&#21644;&#21453;&#20107;&#23454;&#25512;&#29702;&#26159;&#23457;&#35745;&#21644;&#29702;&#35299;&#20154;&#24037;&#26234;&#33021;&#31995;&#32479;&#30340;&#35768;&#22810;&#25216;&#26415;&#30340;&#22522;&#30784;&#12290;&#22312;&#36825;&#19968;&#39046;&#22495;&#20013;&#65292;&#21453;&#20107;&#23454;&#25512;&#29702;&#30340;&#20256;&#32479;&#33539;&#24335;&#26159;&#24178;&#39044;&#21453;&#20107;&#23454;&#65292;&#21363;&#24819;&#35937;&#21644;&#27169;&#25311;&#20551;&#35774;&#24615;&#24178;&#39044;&#12290;&#22240;&#27492;&#65292;&#20851;&#20110;&#20154;&#24037;&#26234;&#33021;&#20013;&#30340;&#27861;&#24459;&#20445;&#25252;&#21644;&#20154;&#21475;&#32479;&#35745;&#25968;&#25454;&#30340;&#22240;&#26524;&#25512;&#29702;&#30340;&#20986;&#21457;&#28857;&#26159;&#23545;&#27861;&#24459;&#20445;&#25252;&#29305;&#24449;&#65288;&#22914;&#31181;&#26063;&#12289;&#24615;&#21035;&#12289;&#27531;&#30142;&#12289;&#24180;&#40836;&#31561;&#65289;&#36827;&#34892;&#20551;&#35774;&#24178;&#39044;&#12290;&#25105;&#20204;&#38382;&#30340;&#38382;&#39064;&#26159;&#65292;&#22914;&#26524;&#20320;&#30340;&#31181;&#26063;&#19981;&#21516;&#65292;&#20250;&#21457;&#29983;&#20160;&#20040;&#24773;&#20917;&#65311;&#36825;&#20010;&#33539;&#24335;&#30340;&#19968;&#20010;&#22266;&#26377;&#38480;&#21046;&#26159;&#65292;&#19968;&#20123;&#20154;&#21475;&#32479;&#35745;&#24178;&#39044;&#65288;&#27604;&#22914;&#31181;&#26063;&#24178;&#39044;&#65289;&#21487;&#33021;&#26080;&#27861;&#36716;&#21270;&#20026;&#24178;&#39044;&#21453;&#20107;&#23454;&#30340;&#24418;&#24335;&#20027;&#20041;&#12290;&#22312;&#36825;&#39033;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#19968;&#31181;&#22522;&#20110;&#22238;&#28335;&#21453;&#20107;&#23454;&#30340;&#26032;&#33539;&#24335;&#65292;&#19982;&#24819;&#35937;&#22312;&#27861;&#24459;&#20445;&#25252;&#29305;&#24449;&#19978;&#36827;&#34892;&#30340;&#20551;&#35774;&#24178;&#39044;&#19981;&#21516;&#65292;&#25105;&#20204;&#24819;&#35937;&#21487;&#20197;&#27839;&#30528;&#24050;&#26377;&#30340;&#36335;&#24452;&#36827;&#34892;&#22238;&#28335;&#30340;&#21453;&#20107;&#23454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Counterfactuals and counterfactual reasoning underpin numerous techniques for auditing and understanding artificial intelligence (AI) systems. The traditional paradigm for counterfactual reasoning in this literature is the interventional counterfactual, where hypothetical interventions are imagined and simulated. For this reason, the starting point for causal reasoning about legal protections and demographic data in AI is an imagined intervention on a legally-protected characteristic, such as ethnicity, race, gender, disability, age, etc. We ask, for example, what would have happened had your race been different? An inherent limitation of this paradigm is that some demographic interventions -- like interventions on race -- may not translate into the formalisms of interventional counterfactuals. In this work, we explore a new paradigm based instead on the backtracking counterfactual, where rather than imagine hypothetical interventions on legally-protected characteristics, we imagine al
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#38024;&#23545;&#37325;&#24615;&#25233;&#37057;&#38556;&#30861;(MDD)&#20013;&#30340;&#22870;&#21169;&#22788;&#29702;&#24322;&#24120;&#65292;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#21644;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#32467;&#21512;&#65292;&#25506;&#32034;&#20915;&#31574;&#21046;&#23450;&#36807;&#31243;&#20013;&#30340;&#23398;&#20064;&#31574;&#30053;&#21160;&#24577;&#23545;&#20010;&#20307;&#22870;&#21169;&#23398;&#20064;&#33021;&#21147;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2401.13929</link><description>&lt;p&gt;
&#20351;&#29992;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#26469;&#21457;&#29616;&#20915;&#31574;&#21160;&#24577;
&lt;/p&gt;
&lt;p&gt;
Reinforcement Learning with Hidden Markov Models for Discovering Decision-Making Dynamics. (arXiv:2401.13929v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13929
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#38024;&#23545;&#37325;&#24615;&#25233;&#37057;&#38556;&#30861;(MDD)&#20013;&#30340;&#22870;&#21169;&#22788;&#29702;&#24322;&#24120;&#65292;&#20351;&#29992;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#21644;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411;&#32467;&#21512;&#65292;&#25506;&#32034;&#20915;&#31574;&#21046;&#23450;&#36807;&#31243;&#20013;&#30340;&#23398;&#20064;&#31574;&#30053;&#21160;&#24577;&#23545;&#20010;&#20307;&#22870;&#21169;&#23398;&#20064;&#33021;&#21147;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30001;&#20110;&#20854;&#22797;&#26434;&#21644;&#24322;&#36136;&#24615;&#65292;&#37325;&#24615;&#25233;&#37057;&#38556;&#30861;(MDD)&#22312;&#35786;&#26029;&#21644;&#27835;&#30103;&#26041;&#38754;&#23384;&#22312;&#25361;&#25112;&#12290;&#26032;&#30340;&#35777;&#25454;&#34920;&#26126;&#22870;&#21169;&#22788;&#29702;&#24322;&#24120;&#21487;&#33021;&#20316;&#20026;MDD&#30340;&#34892;&#20026;&#26631;&#35760;&#12290;&#20026;&#20102;&#34913;&#37327;&#22870;&#21169;&#22788;&#29702;&#65292;&#24739;&#32773;&#25191;&#34892;&#28041;&#21450;&#20570;&#20986;&#36873;&#25321;&#25110;&#23545;&#19982;&#19981;&#21516;&#32467;&#26524;&#30456;&#20851;&#32852;&#30340;&#21050;&#28608;&#20316;&#20986;&#21453;&#24212;&#30340;&#22522;&#20110;&#35745;&#31639;&#26426;&#30340;&#34892;&#20026;&#20219;&#21153;&#12290;&#24378;&#21270;&#23398;&#20064;(RL)&#27169;&#22411;&#34987;&#25311;&#21512;&#20197;&#25552;&#21462;&#34913;&#37327;&#22870;&#21169;&#22788;&#29702;&#21508;&#20010;&#26041;&#38754;&#30340;&#21442;&#25968;&#65292;&#20197;&#34920;&#24449;&#24739;&#32773;&#22312;&#34892;&#20026;&#20219;&#21153;&#20013;&#30340;&#20915;&#31574;&#26041;&#24335;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#20165;&#22522;&#20110;&#21333;&#20010;RL&#27169;&#22411;&#30340;&#22870;&#21169;&#23398;&#20064;&#34920;&#24449;&#19981;&#36275;; &#30456;&#21453;&#65292;&#20915;&#31574;&#36807;&#31243;&#20013;&#21487;&#33021;&#23384;&#22312;&#22810;&#31181;&#31574;&#30053;&#20043;&#38388;&#30340;&#20999;&#25442;&#12290;&#19968;&#20010;&#37325;&#35201;&#30340;&#31185;&#23398;&#38382;&#39064;&#26159;&#20915;&#31574;&#21046;&#23450;&#20013;&#23398;&#20064;&#31574;&#30053;&#30340;&#21160;&#24577;&#22914;&#20309;&#24433;&#21709;MDD&#24739;&#32773;&#30340;&#22870;&#21169;&#23398;&#20064;&#33021;&#21147;&#12290;&#30001;&#27010;&#29575;&#22870;&#21169;&#20219;&#21153;(PRT)&#25152;&#21551;&#21457;
&lt;/p&gt;
&lt;p&gt;
Major depressive disorder (MDD) presents challenges in diagnosis and treatment due to its complex and heterogeneous nature. Emerging evidence indicates that reward processing abnormalities may serve as a behavioral marker for MDD. To measure reward processing, patients perform computer-based behavioral tasks that involve making choices or responding to stimulants that are associated with different outcomes. Reinforcement learning (RL) models are fitted to extract parameters that measure various aspects of reward processing to characterize how patients make decisions in behavioral tasks. Recent findings suggest the inadequacy of characterizing reward learning solely based on a single RL model; instead, there may be a switching of decision-making processes between multiple strategies. An important scientific question is how the dynamics of learning strategies in decision-making affect the reward learning ability of individuals with MDD. Motivated by the probabilistic reward task (PRT) wi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35889;&#32858;&#31867;&#21644;&#20998;&#24067;&#30456;&#20284;&#24230;&#24230;&#37327;&#30340;&#26694;&#26550;&#26469;&#35299;&#20915;&#31163;&#25955;&#20998;&#24067;&#32858;&#31867;&#38382;&#39064;&#12290;&#36890;&#36807;&#20351;&#29992;&#32447;&#24615;&#26368;&#20248;&#20256;&#36755;&#26500;&#24314;&#30456;&#20284;&#24230;&#30697;&#38453;&#65292;&#25105;&#20204;&#22312;&#32858;&#31867;&#20934;&#30830;&#24615;&#21644;&#35745;&#31639;&#25928;&#29575;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2401.13913</link><description>&lt;p&gt;
&#31163;&#25955;&#20998;&#24067;&#30340;&#35889;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Spectral Clustering for Discrete Distributions. (arXiv:2401.13913v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13913
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35889;&#32858;&#31867;&#21644;&#20998;&#24067;&#30456;&#20284;&#24230;&#24230;&#37327;&#30340;&#26694;&#26550;&#26469;&#35299;&#20915;&#31163;&#25955;&#20998;&#24067;&#32858;&#31867;&#38382;&#39064;&#12290;&#36890;&#36807;&#20351;&#29992;&#32447;&#24615;&#26368;&#20248;&#20256;&#36755;&#26500;&#24314;&#30456;&#20284;&#24230;&#30697;&#38453;&#65292;&#25105;&#20204;&#22312;&#32858;&#31867;&#20934;&#30830;&#24615;&#21644;&#35745;&#31639;&#25928;&#29575;&#26041;&#38754;&#21462;&#24471;&#20102;&#26174;&#33879;&#30340;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31163;&#25955;&#20998;&#24067;&#32858;&#31867;&#65288;D2C&#65289;&#36890;&#24120;&#36890;&#36807;Wasserstein&#36136;&#24515;&#26041;&#27861;&#26469;&#35299;&#20915;&#12290;&#36825;&#20123;&#26041;&#27861;&#22312;&#19968;&#20010;&#20849;&#21516;&#30340;&#20551;&#35774;&#19979;&#24037;&#20316;&#65292;&#21363;&#32858;&#31867;&#21487;&#20197;&#36890;&#36807;&#36136;&#24515;&#24456;&#22909;&#22320;&#34920;&#31034;&#65292;&#20294;&#22312;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#20013;&#21487;&#33021;&#19981;&#25104;&#31435;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#22522;&#20110;&#35889;&#32858;&#31867;&#21644;&#20998;&#24067;&#30456;&#20284;&#24230;&#24230;&#37327;&#65288;&#20363;&#22914;&#26368;&#22823;&#22343;&#20540;&#24046;&#24322;&#21644;Wasserstein&#36317;&#31163;&#65289;&#30340;&#26694;&#26550;&#26469;&#35299;&#20915;D2C&#38382;&#39064;&#12290;&#20026;&#20102;&#25552;&#39640;&#21487;&#25193;&#23637;&#24615;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#32447;&#24615;&#26368;&#20248;&#20256;&#36755;&#22312;&#22823;&#22411;&#25968;&#25454;&#38598;&#19978;&#39640;&#25928;&#22320;&#26500;&#24314;&#30456;&#20284;&#24230;&#30697;&#38453;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#65292;&#20445;&#35777;&#20102;&#25152;&#25552;&#26041;&#27861;&#22312;&#32858;&#31867;&#20998;&#24067;&#26041;&#38754;&#30340;&#25104;&#21151;&#12290;&#22312;&#21512;&#25104;&#25968;&#25454;&#21644;&#30495;&#23454;&#25968;&#25454;&#19978;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#32858;&#31867;&#20934;&#30830;&#24615;&#21644;&#35745;&#31639;&#25928;&#29575;&#26041;&#38754;&#22823;&#22823;&#20248;&#20110;&#22522;&#20934;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Discrete distribution clustering (D2C) was often solved by Wasserstein barycenter methods. These methods are under a common assumption that clusters can be well represented by barycenters, which may not hold in many real applications. In this work, we propose a simple yet effective framework based on spectral clustering and distribution affinity measures (e.g., maximum mean discrepancy and Wasserstein distance) for D2C. To improve the scalability, we propose to use linear optimal transport to construct affinity matrices efficiently on large datasets. We provide theoretical guarantees for the success of the proposed methods in clustering distributions. Experiments on synthetic and real data show that our methods outperform the baselines largely in terms of both clustering accuracy and computational efficiency.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24120;&#25968;&#27493;&#38271;&#24322;&#27493;Q-learning&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#20998;&#26512;&#20854;&#19982;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#20851;&#32852;&#65292;&#23637;&#31034;&#20102;&#20854;&#36845;&#20195;&#22312;&#20998;&#24067;&#19978;&#30340;&#25910;&#25947;&#24615;&#21644;&#25351;&#25968;&#25910;&#25947;&#36895;&#24230;&#12290;&#21516;&#26102;&#65292;&#30740;&#31350;&#32773;&#36824;&#24314;&#31435;&#20102;&#35813;&#31639;&#27861;&#36845;&#20195;&#30340;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#65292;&#24182;&#23545;&#20854;&#28176;&#36817;&#20559;&#24046;&#36827;&#34892;&#20102;&#31934;&#30830;&#30340;&#23637;&#24320;&#12290;&#36890;&#36807;&#36825;&#20123;&#20998;&#26512;&#65292;&#25105;&#20204;&#21487;&#20197;&#28145;&#20837;&#29702;&#35299;&#36825;&#31181;&#31639;&#27861;&#30340;&#20248;&#21270;&#25928;&#26524;&#21644;&#20559;&#24046;&#29305;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.13884</link><description>&lt;p&gt;
Constant Stepsize Q-learning: &#20998;&#24067;&#25910;&#25947;&#24615;&#12289;&#20559;&#24046;&#21644;&#22806;&#25512;
&lt;/p&gt;
&lt;p&gt;
Constant Stepsize Q-learning: Distributional Convergence, Bias and Extrapolation. (arXiv:2401.13884v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13884
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24120;&#25968;&#27493;&#38271;&#24322;&#27493;Q-learning&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#20998;&#26512;&#20854;&#19982;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#20851;&#32852;&#65292;&#23637;&#31034;&#20102;&#20854;&#36845;&#20195;&#22312;&#20998;&#24067;&#19978;&#30340;&#25910;&#25947;&#24615;&#21644;&#25351;&#25968;&#25910;&#25947;&#36895;&#24230;&#12290;&#21516;&#26102;&#65292;&#30740;&#31350;&#32773;&#36824;&#24314;&#31435;&#20102;&#35813;&#31639;&#27861;&#36845;&#20195;&#30340;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#65292;&#24182;&#23545;&#20854;&#28176;&#36817;&#20559;&#24046;&#36827;&#34892;&#20102;&#31934;&#30830;&#30340;&#23637;&#24320;&#12290;&#36890;&#36807;&#36825;&#20123;&#20998;&#26512;&#65292;&#25105;&#20204;&#21487;&#20197;&#28145;&#20837;&#29702;&#35299;&#36825;&#31181;&#31639;&#27861;&#30340;&#20248;&#21270;&#25928;&#26524;&#21644;&#20559;&#24046;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#36924;&#36817;&#65288;SA&#65289;&#26159;&#19968;&#31181;&#24191;&#27867;&#24212;&#29992;&#20110;&#21508;&#20010;&#39046;&#22495;&#30340;&#31639;&#27861;&#26041;&#27861;&#65292;&#21253;&#25324;&#20248;&#21270;&#21644;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#12290;&#22312;RL&#31639;&#27861;&#20013;&#65292;&#30001;&#20110;&#20854;&#32463;&#39564;&#25104;&#21151;&#65292;Q-learning&#29305;&#21035;&#21463;&#27426;&#36814;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#24120;&#25968;&#27493;&#38271;&#24322;&#27493;Q-learning&#65292;&#36825;&#22312;&#23454;&#36341;&#20013;&#36890;&#24120;&#29992;&#20110;&#24555;&#36895;&#25910;&#25947;&#12290;&#36890;&#36807;&#23558;&#24120;&#25968;&#27493;&#38271;Q-learning&#19982;&#26102;&#38388;&#22343;&#21248;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#30456;&#20851;&#32852;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36845;&#20195;&#22312;Wasserstein&#36317;&#31163;&#19979;&#30340;&#20998;&#24067;&#25910;&#25947;&#24615;&#65292;&#24182;&#24314;&#31435;&#20102;&#20854;&#25351;&#25968;&#25910;&#25947;&#36895;&#24230;&#12290;&#25105;&#20204;&#36824;&#20026;Q-learning&#36845;&#20195;&#24314;&#31435;&#20102;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#65292;&#35777;&#26126;&#20102;&#24179;&#22343;&#36845;&#20195;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#24179;&#22343;&#36845;&#20195;&#27493;&#39588;&#30340;&#28176;&#36817;&#20559;&#24046;&#30340;&#26126;&#30830;&#23637;&#24320;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#20559;&#24046;&#19982;&#27493;&#38271;&#25104;&#27491;&#27604;&#65292;&#30452;&#21040;&#39640;&#38454;&#39033;&#65292;&#24182;&#20026;&#32447;&#24615;&#31995;&#25968;&#25552;&#20379;&#20102;&#26126;&#30830;&#30340;&#34920;&#36798;&#24335;&#12290;&#36825;&#31181;&#23545;&#20559;&#24046;&#30340;&#31934;&#30830;&#25551;&#36848;&#21487;&#20197;&#20351;&#24471;&#25105;&#20204;&#21487;&#20197;&#25506;&#32034;&#20986;&#23545;&#20110;&#36825;&#31181;&#20559;&#24046;&#30340;&#26356;&#28145;&#20837;&#29702;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic Approximation (SA) is a widely used algorithmic approach in various fields, including optimization and reinforcement learning (RL). Among RL algorithms, Q-learning is particularly popular due to its empirical success. In this paper, we study asynchronous Q-learning with constant stepsize, which is commonly used in practice for its fast convergence. By connecting the constant stepsize Q-learning to a time-homogeneous Markov chain, we show the distributional convergence of the iterates in Wasserstein distance and establish its exponential convergence rate. We also establish a Central Limit Theory for Q-learning iterates, demonstrating the asymptotic normality of the averaged iterates. Moreover, we provide an explicit expansion of the asymptotic bias of the averaged iterate in stepsize. Specifically, the bias is proportional to the stepsize up to higher-order terms and we provide an explicit expression for the linear coefficient. This precise characterization of the bias allows
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28201;&#24230;&#23545;Softmax&#39640;&#26031;&#28151;&#21512;&#19987;&#23478;&#30340;&#37319;&#26679;&#25928;&#29575;&#30340;&#24433;&#21709;&#65292;&#35777;&#26126;&#20102;&#30001;&#20110;&#28201;&#24230;&#21644;&#20854;&#20182;&#27169;&#22411;&#21442;&#25968;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#21442;&#25968;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#24230;&#36739;&#24930;&#65292;&#24182;&#19988;&#21487;&#33021;&#24456;&#24930;&#12290;</title><link>http://arxiv.org/abs/2401.13875</link><description>&lt;p&gt;
&#28201;&#24230;&#23545;Softmax&#39640;&#26031;&#28151;&#21512;&#19987;&#23478;&#26159;&#21542;&#20855;&#26377;&#37319;&#26679;&#25928;&#29575;&#65311;
&lt;/p&gt;
&lt;p&gt;
Is Temperature Sample Efficient for Softmax Gaussian Mixture of Experts?. (arXiv:2401.13875v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13875
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28201;&#24230;&#23545;Softmax&#39640;&#26031;&#28151;&#21512;&#19987;&#23478;&#30340;&#37319;&#26679;&#25928;&#29575;&#30340;&#24433;&#21709;&#65292;&#35777;&#26126;&#20102;&#30001;&#20110;&#28201;&#24230;&#21644;&#20854;&#20182;&#27169;&#22411;&#21442;&#25968;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#21442;&#25968;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#24230;&#36739;&#24930;&#65292;&#24182;&#19988;&#21487;&#33021;&#24456;&#24930;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#23494;&#38598;-&#31232;&#30095;&#38376;&#25511;&#19987;&#23478;&#28151;&#21512;&#27169;&#22411;&#65288;MoE&#65289;&#24050;&#25104;&#20026;&#24191;&#20026;&#20351;&#29992;&#30340;&#31232;&#30095;MoE&#30340;&#26377;&#25928;&#26367;&#20195;&#26041;&#26696;&#12290;&#19982;&#21518;&#32773;&#27169;&#22411;&#20013;&#22266;&#23450;&#28608;&#27963;&#30340;&#19987;&#23478;&#25968;&#37327;&#19981;&#21516;&#65292;&#21069;&#32773;&#27169;&#22411;&#21033;&#29992;&#28201;&#24230;&#26469;&#25511;&#21046;softmax&#26435;&#37325;&#20998;&#24067;&#21644;MoE&#30340;&#31232;&#30095;&#24615;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#31283;&#23450;&#19987;&#23478;&#30340;&#19987;&#19994;&#21270;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#20197;&#21069;&#26377;&#23581;&#35797;&#20174;&#29702;&#35770;&#19978;&#29702;&#35299;&#31232;&#30095;MoE&#30340;&#26041;&#27861;&#65292;&#23545;&#20110;&#23494;&#38598;&#21040;&#31232;&#30095;&#38376;&#25511;MoE&#30340;&#20840;&#38754;&#20998;&#26512;&#20173;&#28982;&#22256;&#38590;&#37325;&#37325;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#26088;&#22312;&#25506;&#35752;&#23494;&#38598;&#21040;&#31232;&#30095;&#38376;&#25511;&#23545;Gaussian MoE&#19979;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#35777;&#26126;&#30001;&#20110;&#28201;&#24230;&#21644;&#20854;&#20182;&#27169;&#22411;&#21442;&#25968;&#20043;&#38388;&#36890;&#36807;&#19968;&#20123;&#20559;&#24494;&#20998;&#26041;&#31243;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#21442;&#25968;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#24230;&#27604;&#20219;&#20309;&#22810;&#39033;&#24335;&#36895;&#29575;&#37117;&#35201;&#24930;&#65292;&#24182;&#19988;&#21487;&#33021;&#24930;&#21040;$\mathcal{
&lt;/p&gt;
&lt;p&gt;
Dense-to-sparse gating mixture of experts (MoE) has recently become an effective alternative to a well-known sparse MoE. Rather than fixing the number of activated experts as in the latter model, which could limit the investigation of potential experts, the former model utilizes the temperature to control the softmax weight distribution and the sparsity of the MoE during training in order to stabilize the expert specialization. Nevertheless, while there are previous attempts to theoretically comprehend the sparse MoE, a comprehensive analysis of the dense-to-sparse gating MoE has remained elusive. Therefore, we aim to explore the impacts of the dense-to-sparse gate on the maximum likelihood estimation under the Gaussian MoE in this paper. We demonstrate that due to interactions between the temperature and other model parameters via some partial differential equations, the convergence rates of parameter estimations are slower than any polynomial rates, and could be as slow as $\mathcal{
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;V2X&#30340;&#38544;&#31169;&#20445;&#25252;&#32852;&#21512;&#27979;&#37327;&#21644;&#23398;&#20064;&#31995;&#32479;&#65292;&#36890;&#36807;V2V&#36890;&#20449;&#21521;&#20854;&#20182;&#36710;&#36742;&#25552;&#20379;&#23454;&#26102;&#25968;&#25454;&#65292;&#21516;&#26102;&#36890;&#36807;V2N&#38142;&#36335;&#19978;&#30340;FL&#26041;&#26696;&#21019;&#24314;&#20132;&#36890;&#32593;&#32476;&#30340;&#39044;&#27979;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2401.13848</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;V2X&#30340;&#38544;&#31169;&#20445;&#25252;&#32852;&#21512;&#27979;&#37327;&#21644;&#23398;&#20064;&#31995;&#32479;
&lt;/p&gt;
&lt;p&gt;
A V2X-based Privacy Preserving Federated Measuring and Learning System. (arXiv:2401.13848v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13848
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;V2X&#30340;&#38544;&#31169;&#20445;&#25252;&#32852;&#21512;&#27979;&#37327;&#21644;&#23398;&#20064;&#31995;&#32479;&#65292;&#36890;&#36807;V2V&#36890;&#20449;&#21521;&#20854;&#20182;&#36710;&#36742;&#25552;&#20379;&#23454;&#26102;&#25968;&#25454;&#65292;&#21516;&#26102;&#36890;&#36807;V2N&#38142;&#36335;&#19978;&#30340;FL&#26041;&#26696;&#21019;&#24314;&#20132;&#36890;&#32593;&#32476;&#30340;&#39044;&#27979;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26410;&#26469;&#30340;&#33258;&#21160;&#39550;&#39542;&#36710;&#36742;&#23558;&#20351;&#29992;&#21508;&#31181;&#20256;&#24863;&#22120;&#29983;&#25104;&#22823;&#37327;&#25968;&#25454;&#12290;&#36825;&#20123;&#25968;&#25454;&#19981;&#20165;&#21487;&#20197;&#29992;&#20110;&#33258;&#21160;&#39550;&#39542;&#31639;&#27861;&#65292;&#36824;&#21487;&#20197;&#24110;&#21161;&#20854;&#20182;&#36710;&#36742;&#25110;&#22522;&#30784;&#35774;&#26045;&#36827;&#34892;&#23454;&#26102;&#20915;&#31574;&#12290;&#22240;&#27492;&#65292;&#36710;&#36742;&#38656;&#35201;&#36890;&#36807;&#36710;&#36742;&#21040;&#19968;&#20999;(V2X)&#25216;&#26415;&#26469;&#20132;&#25442;&#27979;&#37327;&#25968;&#25454;&#12290;&#27492;&#22806;&#65292;&#39044;&#27979;&#36947;&#36335;&#32593;&#32476;&#30340;&#29366;&#24577;&#21487;&#33021;&#20063;&#20250;&#26377;&#30410;&#22788;&#12290;&#36890;&#36807;&#36825;&#31181;&#39044;&#27979;&#65292;&#25105;&#20204;&#21487;&#20197;&#20943;&#36731;&#36947;&#36335;&#25317;&#22581;&#12289;&#24179;&#34913;&#20572;&#36710;&#22330;&#20351;&#29992;&#24773;&#20917;&#25110;&#20248;&#21270;&#20132;&#36890;&#27969;&#21160;&#12290;&#36825;&#23558;&#38477;&#20302;&#36816;&#36755;&#25104;&#26412;&#65292;&#20943;&#23569;&#29615;&#22659;&#24433;&#21709;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#32852;&#21512;&#27979;&#37327;&#21644;&#23398;&#20064;&#31995;&#32479;&#65292;&#36890;&#36807;&#36710;&#36742;&#21040;&#36710;&#36742;(V2V)&#36890;&#20449;&#21521;&#20854;&#20182;&#36710;&#36742;&#25552;&#20379;&#23454;&#26102;&#25968;&#25454;&#65292;&#21516;&#26102;&#36890;&#36807;&#36710;&#36742;&#21040;&#32593;&#32476;(V2N)&#38142;&#36335;&#19978;&#30340;&#32852;&#21512;&#23398;&#20064;(FL)&#26041;&#26696;&#21019;&#24314;&#20132;&#36890;&#32593;&#32476;&#30340;&#39044;&#27979;&#27169;&#22411;&#12290;&#30001;&#20110;&#23578;&#26080;&#30495;&#23454;&#19990;&#30028;&#30340;&#33258;&#21160;&#39550;&#39542;&#25968;&#25454;&#65292;&#25105;&#20204;&#27169;&#25311;&#20102;&#25968;&#25454;&#65292;
&lt;/p&gt;
&lt;p&gt;
Future autonomous vehicles (AVs) will use a variety of sensors that generate a vast amount of data. Naturally, this data not only serves self-driving algorithms; but can also assist other vehicles or the infrastructure in real-time decision-making. Consequently, vehicles shall exchange their measurement data over Vehicle-to-Everything (V2X) technologies. Moreover, predicting the state of the road network might be beneficial too. With such a prediction, we might mitigate road congestion, balance parking lot usage, or optimize the traffic flow. That would decrease transportation costs as well as reduce its environmental impact.  In this paper, we propose a federated measurement and learning system that provides real-time data to fellow vehicles over Vehicle-to-Vehicle (V2V) communication while also operating a federated learning (FL) scheme over the Vehicle-to-Network (V2N) link to create a predictive model of the transportation network. As we are yet to have real-world AV data, we model
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#31995;&#32479;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#38024;&#23545;&#28145;&#24230;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#40065;&#26834;&#24615;&#24314;&#27169;&#12290;&#30740;&#31350;&#21457;&#29616;&#38544;&#34255;&#23618;&#25968;&#37327;&#23545;&#27169;&#22411;&#30340;&#25512;&#24191;&#24615;&#33021;&#26377;&#24433;&#21709;&#65292;&#21516;&#26102;&#36824;&#27979;&#35797;&#20102;&#27169;&#22411;&#22823;&#23567;&#12289;&#28014;&#28857;&#31934;&#24230;&#12289;&#35757;&#32451;&#25968;&#25454;&#21644;&#27169;&#22411;&#36755;&#20986;&#30340;&#22122;&#22768;&#27700;&#24179;&#31561;&#21442;&#25968;&#12290;&#20026;&#20102;&#25913;&#36827;&#27169;&#22411;&#30340;&#39044;&#27979;&#33021;&#21147;&#21644;&#35745;&#31639;&#25104;&#26412;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#35825;&#21457;&#25925;&#38556;&#26469;&#24314;&#27169;&#25925;&#38556;&#27010;&#29575;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.13751</link><description>&lt;p&gt;
&#19968;&#31181;&#38024;&#23545;&#28145;&#24230;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#40065;&#26834;&#24615;&#24314;&#27169;&#30340;&#31995;&#32479;&#21270;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Systematic Approach to Robustness Modelling for Deep Convolutional Neural Networks. (arXiv:2401.13751v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13751
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#19968;&#31181;&#31995;&#32479;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#38024;&#23545;&#28145;&#24230;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#40065;&#26834;&#24615;&#24314;&#27169;&#12290;&#30740;&#31350;&#21457;&#29616;&#38544;&#34255;&#23618;&#25968;&#37327;&#23545;&#27169;&#22411;&#30340;&#25512;&#24191;&#24615;&#33021;&#26377;&#24433;&#21709;&#65292;&#21516;&#26102;&#36824;&#27979;&#35797;&#20102;&#27169;&#22411;&#22823;&#23567;&#12289;&#28014;&#28857;&#31934;&#24230;&#12289;&#35757;&#32451;&#25968;&#25454;&#21644;&#27169;&#22411;&#36755;&#20986;&#30340;&#22122;&#22768;&#27700;&#24179;&#31561;&#21442;&#25968;&#12290;&#20026;&#20102;&#25913;&#36827;&#27169;&#22411;&#30340;&#39044;&#27979;&#33021;&#21147;&#21644;&#35745;&#31639;&#25104;&#26412;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#35825;&#21457;&#25925;&#38556;&#26469;&#24314;&#27169;&#25925;&#38556;&#27010;&#29575;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#26377;&#22823;&#37327;&#26631;&#35760;&#25968;&#25454;&#21487;&#29992;&#26102;&#65292;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#24050;&#32463;&#34987;&#35777;&#26126;&#22312;&#35768;&#22810;&#39046;&#22495;&#37117;&#21487;&#20197;&#24191;&#27867;&#24212;&#29992;&#12290;&#26368;&#36817;&#30340;&#36235;&#21183;&#26159;&#20351;&#29992;&#20855;&#26377;&#36234;&#26469;&#36234;&#22810;&#21487;&#35843;&#21442;&#25968;&#30340;&#27169;&#22411;&#65292;&#20197;&#25552;&#39640;&#27169;&#22411;&#20934;&#30830;&#24615;&#65292;&#38477;&#20302;&#27169;&#22411;&#25439;&#22833;&#25110;&#21019;&#24314;&#26356;&#20855;&#23545;&#25239;&#40065;&#26834;&#24615;&#30340;&#27169;&#22411;&#65292;&#32780;&#36825;&#20123;&#30446;&#26631;&#36890;&#24120;&#30456;&#20114;&#30683;&#30462;&#12290;&#29305;&#21035;&#26159;&#65292;&#26368;&#36817;&#30340;&#29702;&#35770;&#30740;&#31350;&#25552;&#20986;&#20102;&#23545;&#26356;&#22823;&#27169;&#22411;&#33021;&#21542;&#25512;&#24191;&#21040;&#21463;&#25511;&#30340;&#35757;&#32451;&#21644;&#27979;&#35797;&#38598;&#20043;&#22806;&#30340;&#25968;&#25454;&#30340;&#30097;&#38382;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;ResNet&#27169;&#22411;&#20013;&#38544;&#34255;&#23618;&#30340;&#25968;&#37327;&#22312;MNIST&#12289;CIFAR10&#21644;CIFAR100&#25968;&#25454;&#38598;&#19978;&#30340;&#20316;&#29992;&#12290;&#25105;&#20204;&#27979;&#35797;&#20102;&#21508;&#31181;&#21442;&#25968;&#65292;&#21253;&#25324;&#27169;&#22411;&#30340;&#22823;&#23567;&#12289;&#28014;&#28857;&#31934;&#24230;&#65292;&#20197;&#21450;&#35757;&#32451;&#25968;&#25454;&#21644;&#27169;&#22411;&#36755;&#20986;&#30340;&#22122;&#22768;&#27700;&#24179;&#12290;&#20026;&#20102;&#25913;&#36827;&#27169;&#22411;&#30340;&#39044;&#27979;&#33021;&#21147;&#21644;&#35745;&#31639;&#25104;&#26412;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#20351;&#29992;&#35825;&#21457;&#25925;&#38556;&#26469;&#24314;&#27169;&#25925;&#38556;&#27010;&#29575;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Convolutional neural networks have shown to be widely applicable to a large number of fields when large amounts of labelled data are available. The recent trend has been to use models with increasingly larger sets of tunable parameters to increase model accuracy, reduce model loss, or create more adversarially robust models -- goals that are often at odds with one another. In particular, recent theoretical work raises questions about the ability for even larger models to generalize to data outside of the controlled train and test sets. As such, we examine the role of the number of hidden layers in the ResNet model, demonstrated on the MNIST, CIFAR10, CIFAR100 datasets. We test a variety of parameters including the size of the model, the floating point precision, and the noise level of both the training data and the model output. To encapsulate the model's predictive power and computational cost, we provide a method that uses induced failures to model the probability of failure as a fun
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#34920;&#26126;&#65292;&#36890;&#36807;&#35268;&#33539;&#39044;&#27979;&#37327;&#21270;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#21487;&#20197;&#25552;&#39640;&#20154;&#31867;&#20915;&#31574;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#26524;&#65292;&#23545;&#20154;&#26426;&#21327;&#21516;&#20915;&#31574;&#20855;&#26377;&#23454;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2401.13744</link><description>&lt;p&gt;
&#12298;&#35268;&#33539;&#39044;&#27979;&#38598;&#25552;&#21319;&#20154;&#31867;&#20915;&#31574;&#33021;&#21147;&#12299;
&lt;/p&gt;
&lt;p&gt;
Conformal Prediction Sets Improve Human Decision Making. (arXiv:2401.13744v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13744
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#34920;&#26126;&#65292;&#36890;&#36807;&#35268;&#33539;&#39044;&#27979;&#37327;&#21270;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#21487;&#20197;&#25552;&#39640;&#20154;&#31867;&#20915;&#31574;&#30340;&#20934;&#30830;&#24615;&#21644;&#25928;&#26524;&#65292;&#23545;&#20154;&#26426;&#21327;&#21516;&#20915;&#31574;&#20855;&#26377;&#23454;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20316;&#20026;&#23545;&#26085;&#24120;&#26597;&#35810;&#30340;&#22238;&#24212;&#65292;&#20154;&#31867;&#26126;&#30830;&#22320;&#34920;&#36798;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#22312;&#19981;&#30830;&#23450;&#30340;&#24773;&#20917;&#19979;&#25552;&#20379;&#26367;&#20195;&#31572;&#26696;&#12290;&#36890;&#36807;&#35268;&#33539;&#39044;&#27979;&#36755;&#20986;&#26657;&#20934;&#30340;&#39044;&#27979;&#38598;&#65292;&#27169;&#20223;&#20102;&#20154;&#31867;&#30340;&#36825;&#31181;&#34892;&#20026;&#65307;&#26356;&#22823;&#30340;&#39044;&#27979;&#38598;&#34920;&#31034;&#26356;&#22823;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#26367;&#20195;&#26041;&#26696;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#23454;&#26045;&#39044;&#27880;&#20876;&#30340;&#38543;&#26426;&#23545;&#29031;&#35797;&#39564;&#65292;&#24182;&#32473;&#20154;&#31867;&#21463;&#35797;&#32773;&#25552;&#20379;&#35268;&#33539;&#39044;&#27979;&#38598;&#65292;&#30740;&#31350;&#20102;&#35268;&#33539;&#39044;&#27979;&#38598;&#23545;&#20154;&#31867;&#20915;&#31574;&#30340;&#23454;&#29992;&#24615;&#12290;&#36890;&#36807;&#32479;&#35745;&#23398;&#26174;&#33879;&#24615;&#65292;&#25105;&#20204;&#21457;&#29616;&#24403;&#20154;&#31867;&#33719;&#24471;&#35268;&#33539;&#39044;&#27979;&#38598;&#26102;&#65292;&#20182;&#20204;&#22312;&#20219;&#21153;&#19978;&#30340;&#20934;&#30830;&#24615;&#27604;&#20351;&#29992;&#30456;&#21516;&#35206;&#30422;&#20445;&#35777;&#30340;&#22266;&#23450;&#23610;&#23544;&#39044;&#27979;&#38598;&#26102;&#26377;&#25152;&#25552;&#39640;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#29992;&#35268;&#33539;&#39044;&#27979;&#37327;&#21270;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#26377;&#21161;&#20110;&#20154;&#26426;&#21327;&#21516;&#20915;&#31574;&#21644;&#20154;&#24037;&#26234;&#33021;&#22242;&#38431;&#30340;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;
In response to everyday queries, humans explicitly signal uncertainty and offer alternative answers when they are unsure. Machine learning models that output calibrated prediction sets through conformal prediction mimic this human behaviour; larger sets signal greater uncertainty while providing alternatives. In this work, we study the usefulness of conformal prediction sets as an aid for human decision making by conducting a pre-registered randomized controlled trial with conformal prediction sets provided to human subjects. With statistical significance, we find that when humans are given conformal prediction sets their accuracy on tasks improves compared to fixed-size prediction sets with the same coverage guarantee. The results show that quantifying model uncertainty with conformal prediction is helpful for human-in-the-loop decision making and human-AI teams.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#21152;&#36895;&#21452;&#26354;&#32447;t-SNE&#31639;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#26497;&#22352;&#26631;&#22235;&#21449;&#26641;&#30340;&#21152;&#36895;&#32467;&#26500;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#22312;&#22788;&#29702;&#22823;&#35268;&#27169;&#36755;&#20837;&#25968;&#25454;&#26102;&#30340;&#25928;&#29575;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.13708</link><description>&lt;p&gt;
&#21152;&#36895;&#21452;&#26354;&#32447;t-SNE&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Accelerating hyperbolic t-SNE. (arXiv:2401.13708v1 [cs.HC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13708
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#21152;&#36895;&#21452;&#26354;&#32447;t-SNE&#31639;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#26497;&#22352;&#26631;&#22235;&#21449;&#26641;&#30340;&#21152;&#36895;&#32467;&#26500;&#65292;&#35299;&#20915;&#20102;&#29616;&#26377;&#26041;&#27861;&#22312;&#22788;&#29702;&#22823;&#35268;&#27169;&#36755;&#20837;&#25968;&#25454;&#26102;&#30340;&#25928;&#29575;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#21508;&#20010;&#39046;&#22495;&#20013;&#65292;&#29702;&#35299;&#23618;&#27425;&#21270;&#25110;&#39640;&#32500;&#25968;&#25454;&#30340;&#32467;&#26500;&#26159;&#24517;&#35201;&#30340;&#12290;&#21452;&#26354;&#31354;&#38388;&#24050;&#32463;&#34987;&#35777;&#26126;&#26159;&#19968;&#31181;&#37325;&#35201;&#30340;&#23884;&#20837;&#35745;&#31639;&#21644;&#20998;&#26512;&#24037;&#20855;&#65292;&#22240;&#20026;&#23427;&#20204;&#30340;&#38750;&#32447;&#24615;&#29305;&#24615;&#24456;&#36866;&#21512;&#22788;&#29702;&#26641;&#29366;&#25110;&#22270;&#24418;&#25968;&#25454;&#12290;&#22240;&#27492;&#65292;&#23427;&#20204;&#20063;&#34987;&#29992;&#20110;&#39640;&#32500;&#25968;&#25454;&#30340;&#21487;&#35270;&#21270;&#65292;&#20854;&#20013;&#23427;&#20204;&#34920;&#29616;&#20986;&#26356;&#22909;&#30340;&#23884;&#20837;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#23884;&#20837;&#21040;&#21452;&#26354;&#31354;&#38388;&#30340;&#38477;&#32500;&#26041;&#27861;&#37117;&#19981;&#33021;&#24456;&#22909;&#22320;&#22788;&#29702;&#36755;&#20837;&#25968;&#25454;&#30340;&#35268;&#27169;&#25193;&#23637;&#38382;&#39064;&#12290;&#36825;&#26159;&#22240;&#20026;&#23884;&#20837;&#26159;&#36890;&#36807;&#36845;&#20195;&#20248;&#21270;&#26041;&#26696;&#35745;&#31639;&#30340;&#65292;&#32780;&#27599;&#27425;&#36845;&#20195;&#30340;&#35745;&#31639;&#25104;&#26412;&#19982;&#36755;&#20837;&#35268;&#27169;&#30340;&#24179;&#26041;&#25104;&#27491;&#27604;&#12290;&#27492;&#22806;&#65292;&#30001;&#20110;&#21452;&#26354;&#31354;&#38388;&#30340;&#38750;&#32447;&#24615;&#29305;&#24615;&#65292;&#27431;&#20960;&#37324;&#24503;&#21152;&#36895;&#32467;&#26500;&#19981;&#33021;&#30452;&#25509;&#36716;&#21270;&#20026;&#21452;&#26354;&#35774;&#32622;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#31532;&#19968;&#20010;&#29992;&#20110;&#21452;&#26354;&#23884;&#20837;&#21152;&#36895;&#30340;&#32467;&#26500;&#65292;&#22522;&#20110;&#26497;&#22352;&#26631;&#22235;&#21449;&#26641;&#12290;&#25105;&#20204;&#23558;&#20854;&#24212;&#29992;&#20110;t-SNE&#31639;&#27861;&#65292;&#25552;&#20986;&#20102;&#21152;&#36895;&#21452;&#26354;&#32447;t-SNE&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The need to understand the structure of hierarchical or high-dimensional data is present in a variety of fields. Hyperbolic spaces have proven to be an important tool for embedding computations and analysis tasks as their non-linear nature lends itself well to tree or graph data. Subsequently, they have also been used in the visualization of high-dimensional data, where they exhibit increased embedding performance. However, none of the existing dimensionality reduction methods for embedding into hyperbolic spaces scale well with the size of the input data. That is because the embeddings are computed via iterative optimization schemes and the computation cost of every iteration is quadratic in the size of the input. Furthermore, due to the non-linear nature of hyperbolic spaces, Euclidean acceleration structures cannot directly be translated to the hyperbolic setting. This paper introduces the first acceleration structure for hyperbolic embeddings, building upon a polar quadtree. We com
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#35777;&#26126;&#20102;&#21363;&#20351;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#23545;&#22122;&#22768;&#25968;&#25454;&#25311;&#21512;&#24471;&#24456;&#22909;&#65292;&#23545;&#25932;&#23545;&#31034;&#20363;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#20294;&#24403;&#38754;&#20020;&#25932;&#23545;&#25805;&#32437;&#30340;&#25968;&#25454;&#26102;&#65292;&#36807;&#24230;&#25311;&#21512;&#30340;&#27169;&#22411;&#21487;&#33021;&#20250;&#32473;&#31995;&#32479;&#24102;&#26469;&#24847;&#22806;&#30340;&#21361;&#23475;&#12290;</title><link>http://arxiv.org/abs/2401.12236</link><description>&lt;p&gt;
&#26080;&#23475;&#36807;&#24230;&#25311;&#21512;&#23545;&#25932;&#23545;&#40065;&#26834;&#24615;&#30340;&#24847;&#22806;&#21361;&#23475;
&lt;/p&gt;
&lt;p&gt;
The Surprising Harmfulness of Benign Overfitting for Adversarial Robustness. (arXiv:2401.12236v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.12236
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#35777;&#26126;&#20102;&#21363;&#20351;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#23545;&#22122;&#22768;&#25968;&#25454;&#25311;&#21512;&#24471;&#24456;&#22909;&#65292;&#23545;&#25932;&#23545;&#31034;&#20363;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#20294;&#24403;&#38754;&#20020;&#25932;&#23545;&#25805;&#32437;&#30340;&#25968;&#25454;&#26102;&#65292;&#36807;&#24230;&#25311;&#21512;&#30340;&#27169;&#22411;&#21487;&#33021;&#20250;&#32473;&#31995;&#32479;&#24102;&#26469;&#24847;&#22806;&#30340;&#21361;&#23475;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#23454;&#35777;&#21644;&#29702;&#35770;&#30740;&#31350;&#24050;&#32463;&#35777;&#26126;&#20102;&#22823;&#35268;&#27169;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#23545;&#35757;&#32451;&#22122;&#22768;&#25968;&#25454;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;&#20196;&#20154;&#24778;&#35766;&#30340;&#32467;&#26524;&#65306;&#21363;&#20351;&#30495;&#27491;&#30340;&#25968;&#25454;&#26412;&#36523;&#23545;&#25932;&#23545;&#31034;&#20363;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#32780;&#19988;&#36807;&#24230;&#25311;&#21512;&#30340;&#27169;&#22411;&#22312;&#8220;&#26631;&#20934;&#8221;&#30340;&#26679;&#26412;&#22806;&#39118;&#38505;&#30446;&#26631;&#19978;&#26159;&#26080;&#23475;&#30340;&#65292;&#20294;&#22312;&#26679;&#26412;&#22806;&#25968;&#25454;&#21463;&#21040;&#25932;&#23545;&#25805;&#32437;&#26102;&#65292;&#36825;&#31181;&#26080;&#23475;&#30340;&#36807;&#24230;&#25311;&#21512;&#36807;&#31243;&#21487;&#33021;&#26159;&#26377;&#23475;&#30340;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#21253;&#21547;&#20004;&#20010;&#37096;&#20998;&#65306;&#65288;i&#65289;&#22312;&#36807;&#24230;&#21442;&#25968;&#21270;&#32447;&#24615;&#27169;&#22411;&#20013;&#65292;&#26368;&#23567;&#33539;&#25968;&#20272;&#35745;&#24635;&#26159;&#22312;&#8220;&#26080;&#23475;&#36807;&#24230;&#25311;&#21512;&#8221;&#35774;&#32622;&#20013;&#23548;&#33268;&#25932;&#23545;&#26131;&#21463;&#25915;&#20987;&#65307;&#65288;ii&#65289;&#25105;&#20204;&#39564;&#35777;&#20102;&#27599;&#20010;&#23725;&#22238;&#24402;&#20272;&#35745;&#22120;&#30340;&#26631;&#20934;&#39118;&#38505;&#21644;&#8220;&#25932;&#23545;&#8221;&#39118;&#38505;&#20043;&#38388;&#30340;&#28176;&#36827;&#26435;&#34913;&#32467;&#26524;&#65292;&#36825;&#24847;&#21619;&#30528;&#22312;&#36866;&#24403;&#30340;&#26465;&#20214;&#19979;&#65292;&#36825;&#20004;&#20010;&#39033;&#30446;&#19981;&#33021;&#21516;&#26102;&#36890;&#36807;&#20219;&#20309;&#21333;&#20010;&#23725;&#27491;&#21017;&#21270;&#21442;&#25968;&#30340;&#36873;&#25321;&#26469;&#20445;&#25345;&#24456;&#23567;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent empirical and theoretical studies have established the generalization capabilities of large machine learning models that are trained to (approximately or exactly) fit noisy data. In this work, we prove a surprising result that even if the ground truth itself is robust to adversarial examples, and the benignly overfitted model is benign in terms of the ``standard'' out-of-sample risk objective, this benign overfitting process can be harmful when out-of-sample data are subject to adversarial manipulation. More specifically, our main results contain two parts: (i) the min-norm estimator in overparameterized linear model always leads to adversarial vulnerability in the ``benign overfitting'' setting; (ii) we verify an asymptotic trade-off result between the standard risk and the ``adversarial'' risk of every ridge regression estimator, implying that under suitable conditions these two items cannot both be small at the same time by any single choice of the ridge regularization parame
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;&#26680;&#26426;&#22120;&#39044;&#22788;&#29702;&#20013;&#20351;&#29992;Nystrom&#36924;&#36817;&#30340;&#26435;&#34913;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#20351;&#29992;&#23545;&#25968;&#22823;&#23567;&#30340;&#26679;&#26412;&#33021;&#22815;&#35753;Nystrom&#36924;&#36817;&#30340;&#39044;&#22788;&#29702;&#22120;&#20960;&#20046;&#19982;&#26799;&#24230;&#19979;&#38477;&#21516;&#26679;&#26377;&#25928;&#22320;&#21152;&#36895;&#12290;</title><link>http://arxiv.org/abs/2312.03311</link><description>&lt;p&gt;
&#23545;&#20110;&#26680;&#26426;&#22120;&#22312;&#39044;&#22788;&#29702;&#20013;&#30340;Nystrom&#36924;&#36817;
&lt;/p&gt;
&lt;p&gt;
On the Nystrom Approximation for Preconditioning in Kernel Machines. (arXiv:2312.03311v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.03311
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#26680;&#26426;&#22120;&#39044;&#22788;&#29702;&#20013;&#20351;&#29992;Nystrom&#36924;&#36817;&#30340;&#26435;&#34913;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#20351;&#29992;&#23545;&#25968;&#22823;&#23567;&#30340;&#26679;&#26412;&#33021;&#22815;&#35753;Nystrom&#36924;&#36817;&#30340;&#39044;&#22788;&#29702;&#22120;&#20960;&#20046;&#19982;&#26799;&#24230;&#19979;&#38477;&#21516;&#26679;&#26377;&#25928;&#22320;&#21152;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26680;&#26041;&#27861;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#19968;&#31867;&#27969;&#34892;&#30340;&#38750;&#32447;&#24615;&#39044;&#27979;&#27169;&#22411;&#12290;&#23398;&#20064;&#26680;&#27169;&#22411;&#30340;&#21487;&#25193;&#23637;&#31639;&#27861;&#38656;&#35201;&#20855;&#26377;&#36845;&#20195;&#24615;&#36136;&#65292;&#20294;&#30001;&#20110;&#31967;&#31957;&#30340;&#26465;&#20214;&#65292;&#25910;&#25947;&#21487;&#33021;&#24456;&#24930;&#12290;&#35889;&#39044;&#22788;&#29702;&#26159;&#21152;&#24555;&#35757;&#32451;&#26680;&#27169;&#22411;&#36845;&#20195;&#31639;&#27861;&#25910;&#25947;&#36895;&#24230;&#30340;&#37325;&#35201;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#35745;&#31639;&#21644;&#23384;&#20648;&#35889;&#39044;&#22788;&#29702;&#22120;&#21487;&#33021;&#20195;&#20215;&#39640;&#26114;&#65292;&#20250;&#23548;&#33268;&#22823;&#37327;&#30340;&#35745;&#31639;&#21644;&#23384;&#20648;&#24320;&#38144;&#65292;&#38480;&#21046;&#20102;&#26680;&#26041;&#27861;&#22312;&#22823;&#22411;&#25968;&#25454;&#38598;&#38382;&#39064;&#19978;&#30340;&#24212;&#29992;&#12290;Nystrom&#36924;&#36817;&#30340;&#35889;&#39044;&#22788;&#29702;&#22120;&#36890;&#24120;&#26356;&#20415;&#23452;&#21644;&#26356;&#23481;&#26131;&#35745;&#31639;&#21644;&#23384;&#20648;&#65292;&#24182;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#21462;&#24471;&#20102;&#25104;&#21151;&#12290;&#26412;&#25991;&#20998;&#26512;&#20102;&#20351;&#29992;&#36825;&#31181;&#36924;&#36817;&#39044;&#22788;&#29702;&#22120;&#30340;&#26435;&#34913;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#34920;&#26126;&#19982;&#25968;&#25454;&#38598;&#22823;&#23567;&#30456;&#20851;&#30340;&#23545;&#25968;&#26679;&#26412;&#25968;&#37327;&#33021;&#22815;&#35753;&#22522;&#20110;Nystrom&#36924;&#36817;&#30340;&#39044;&#22788;&#29702;&#22120;&#20960;&#20046;&#19982;&#26799;&#24230;&#19979;&#38477;&#21516;&#26679;&#26377;&#25928;&#22320;&#21152;&#36895;&#12290;
&lt;/p&gt;
&lt;p&gt;
Kernel methods are a popular class of nonlinear predictive models in machine learning. Scalable algorithms for learning kernel models need to be iterative in nature, but convergence can be slow due to poor conditioning. Spectral preconditioning is an important tool to speed-up the convergence of such iterative algorithms for training kernel models. However computing and storing a spectral preconditioner can be expensive which can lead to large computational and storage overheads, precluding the application of kernel methods to problems with large datasets. A Nystrom approximation of the spectral preconditioner is often cheaper to compute and store, and has demonstrated success in practical applications. In this paper we analyze the trade-offs of using such an approximated preconditioner. Specifically, we show that a sample of logarithmic size (as a function of the size of the dataset) enables the Nystrom-based approximated preconditioner to accelerate gradient descent nearly as well as
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31209;&#30340;&#22810;&#37325;&#26816;&#39564;&#20462;&#27491;&#26041;&#27861;&#65292;&#33021;&#22815;&#26377;&#25928;&#21033;&#29992;&#27491;&#30456;&#20851;&#30340;&#32479;&#35745;&#20551;&#35774;&#26816;&#39564;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#24182;&#22312;&#23384;&#22312;&#27491;&#30456;&#20851;&#20381;&#36182;&#24773;&#20917;&#19979;&#20248;&#20110;Bonferroni&#20462;&#27491;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23588;&#20854;&#36866;&#29992;&#20110;&#24182;&#34892;&#32622;&#25442;&#26816;&#39564;&#65292;&#22312;&#20445;&#35777;FWER&#25511;&#21046;&#30340;&#21516;&#26102;&#20445;&#25345;&#39640;&#32479;&#35745;&#21151;&#25928;&#12290;</title><link>http://arxiv.org/abs/2311.10900</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#31209;&#30340;&#22810;&#37325;&#26816;&#39564;&#27491;&#30456;&#20851;&#20381;&#36182;&#30340;&#24378;&#22823;&#20462;&#27491;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A powerful rank-based correction to multiple testing under positive dependency. (arXiv:2311.10900v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.10900
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31209;&#30340;&#22810;&#37325;&#26816;&#39564;&#20462;&#27491;&#26041;&#27861;&#65292;&#33021;&#22815;&#26377;&#25928;&#21033;&#29992;&#27491;&#30456;&#20851;&#30340;&#32479;&#35745;&#20551;&#35774;&#26816;&#39564;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#24182;&#22312;&#23384;&#22312;&#27491;&#30456;&#20851;&#20381;&#36182;&#24773;&#20917;&#19979;&#20248;&#20110;Bonferroni&#20462;&#27491;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#23588;&#20854;&#36866;&#29992;&#20110;&#24182;&#34892;&#32622;&#25442;&#26816;&#39564;&#65292;&#22312;&#20445;&#35777;FWER&#25511;&#21046;&#30340;&#21516;&#26102;&#20445;&#25345;&#39640;&#32479;&#35745;&#21151;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#33021;&#22815;&#39640;&#25928;&#21033;&#29992;&#21487;&#33021;&#30456;&#20851;&#30340;&#32479;&#35745;&#20551;&#35774;&#26816;&#39564;&#20043;&#38388;&#27491;&#30456;&#20851;&#24615;&#30340;&#23478;&#26063;&#35823;&#24046;&#29575;(FWER)&#25511;&#21046;&#30340;&#26032;&#22411;&#22810;&#37325;&#20551;&#35774;&#26816;&#39564;&#20462;&#27491;&#31639;&#27861;$\texttt{max-rank}$&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#27010;&#24565;&#19978;&#24456;&#30452;&#35266;&#65292;&#20381;&#36182;&#20110;&#22312;&#35745;&#31639;&#30340;&#32479;&#35745;&#26816;&#39564;&#30340;&#31209;&#22495;&#20351;&#29992;$\max$&#31639;&#23376;&#12290;&#36890;&#36807;&#29702;&#35770;&#21644;&#32463;&#39564;&#30340;&#27604;&#36739;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#23384;&#22312;&#27491;&#30456;&#20851;&#20381;&#36182;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#32463;&#24120;&#20351;&#29992;&#30340;Bonferroni&#20462;&#27491;&#65292;&#32780;&#22312;&#19981;&#23384;&#22312;&#27491;&#30456;&#20851;&#20381;&#36182;&#30340;&#24773;&#20917;&#19979;&#31561;&#25928;&#12290;&#25105;&#20204;&#30340;&#20248;&#21183;&#38543;&#30528;&#27979;&#35797;&#25968;&#37327;&#30340;&#22686;&#21152;&#32780;&#22686;&#21152;&#65292;&#21516;&#26102;&#22312;&#20445;&#35777;FWER&#25511;&#21046;&#30340;&#24773;&#20917;&#19979;&#20445;&#25345;&#39640;&#32479;&#35745;&#21151;&#25928;&#12290;&#25105;&#20204;&#29305;&#21035;&#23558;&#25105;&#20204;&#30340;&#31639;&#27861;&#24212;&#29992;&#20110;&#24182;&#34892;&#32622;&#25442;&#26816;&#39564;&#30340;&#32972;&#26223;&#20013;&#65292;&#36825;&#26159;&#22312;&#25105;&#20204;&#20027;&#35201;&#24212;&#29992;&#30340;&#19968;&#31181;&#22797;&#26434;&#39044;&#27979;&#22330;&#26223;&#20013;&#20135;&#29983;&#30340;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop a novel multiple hypothesis testing correction with family-wise error rate (FWER) control that efficiently exploits positive dependencies between potentially correlated statistical hypothesis tests. Our proposed algorithm $\texttt{max-rank}$ is conceptually straight-forward, relying on the use of a $\max$-operator in the rank domain of computed test statistics. We compare our approach to the frequently employed Bonferroni correction, theoretically and empirically demonstrating its superiority over Bonferroni in the case of existing positive dependency, and its equivalence otherwise. Our advantage over Bonferroni increases as the number of tests rises, and we maintain high statistical power whilst ensuring FWER control. We specifically frame our algorithm in the context of parallel permutation testing, a scenario that arises in our primary application of conformal prediction, a recently popularized approach for quantifying uncertainty in complex predictive settings.
&lt;/p&gt;</description></item><item><title>&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32447;&#35774;&#32622;&#19979;&#23398;&#20064;&#26080;&#38480;&#32500;&#32447;&#24615;&#31639;&#23376;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#19968;&#23450;&#30340;&#26465;&#20214;&#19979;&#65292;&#32447;&#24615;&#31639;&#23376;&#26159;&#21487;&#20197;&#22312;&#32447;&#23398;&#20064;&#30340;&#65292;&#32780;&#22312;&#21478;&#19968;&#20123;&#26465;&#20214;&#19979;&#21017;&#19981;&#21487;&#20197;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#22312;&#32447;&#22343;&#19968;&#25910;&#25947;&#21644;&#23398;&#20064;&#33021;&#21147;&#20043;&#38388;&#30340;&#20998;&#31163;&#65292;&#24182;&#22312;PAC&#35774;&#32622;&#19979;&#24471;&#21040;&#20102;&#30456;&#21516;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2309.06548</link><description>&lt;p&gt;
&#22312;&#22312;&#32447;&#35774;&#32622;&#19979;&#23398;&#20064;&#32447;&#24615;&#31639;&#23376;&#30340;&#26080;&#38480;&#32500;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Online Infinite-Dimensional Regression: Learning Linear Operators. (arXiv:2309.06548v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.06548
&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#31687;&#35770;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32447;&#35774;&#32622;&#19979;&#23398;&#20064;&#26080;&#38480;&#32500;&#32447;&#24615;&#31639;&#23376;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#19968;&#23450;&#30340;&#26465;&#20214;&#19979;&#65292;&#32447;&#24615;&#31639;&#23376;&#26159;&#21487;&#20197;&#22312;&#32447;&#23398;&#20064;&#30340;&#65292;&#32780;&#22312;&#21478;&#19968;&#20123;&#26465;&#20214;&#19979;&#21017;&#19981;&#21487;&#20197;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#22312;&#32447;&#22343;&#19968;&#25910;&#25947;&#21644;&#23398;&#20064;&#33021;&#21147;&#20043;&#38388;&#30340;&#20998;&#31163;&#65292;&#24182;&#22312;PAC&#35774;&#32622;&#19979;&#24471;&#21040;&#20102;&#30456;&#21516;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#32447;&#35774;&#32622;&#19979;&#23398;&#20064;&#20004;&#20010;&#26080;&#38480;&#32500;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#20043;&#38388;&#30340;&#32447;&#24615;&#31639;&#23376;&#38382;&#39064;&#65292;&#36890;&#36807;&#26368;&#23567;&#20108;&#20056;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;&#23398;&#20064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;$p \in [1, \infty)$&#33539;&#22260;&#20869;&#65292;&#20855;&#26377;&#22343;&#21248;&#26377;&#30028;$p$-Schatten&#33539;&#25968;&#30340;&#32447;&#24615;&#31639;&#23376;&#31867;&#26159;&#21487;&#20197;&#22312;&#32447;&#23398;&#20064;&#30340;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20855;&#26377;&#22343;&#21248;&#26377;&#30028;&#31639;&#23376;&#33539;&#25968;&#30340;&#32447;&#24615;&#31639;&#23376;&#31867;\textit{&#19981;}&#26159;&#21487;&#20197;&#22312;&#32447;&#23398;&#20064;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36890;&#36807;&#25214;&#21040;&#19968;&#31867;&#26377;&#30028;&#32447;&#24615;&#31639;&#23376;&#65292;&#35777;&#26126;&#20102;&#22312;&#32447;&#22343;&#19968;&#25910;&#25947;&#21644;&#23398;&#20064;&#33021;&#21147;&#20043;&#38388;&#30340;&#20998;&#31163;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#19981;&#21487;&#33021;&#24615;&#32467;&#26524;&#21644;&#22343;&#19968;&#25910;&#25947;&#19982;&#23398;&#20064;&#33021;&#21147;&#20043;&#38388;&#30340;&#20998;&#31163;&#22312;PAC&#35774;&#32622;&#19979;&#21516;&#26679;&#25104;&#31435;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of learning linear operators under squared loss between two infinite-dimensional Hilbert spaces in the online setting. We show that the class of linear operators with uniformly bounded $p$-Schatten norm is online learnable for any $p \in [1, \infty)$. On the other hand, we prove an impossibility result by showing that the class of uniformly bounded linear operators with respect to the operator norm is \textit{not} online learnable. Moreover, we show a separation between online uniform convergence and online learnability by identifying a class of bounded linear operators that is online learnable but uniform convergence does not hold. Finally, we prove that the impossibility result and the separation between uniform convergence and learnability also hold in the agnostic PAC setting.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22788;&#29702;&#39034;&#24207;&#39044;&#27979;&#30340;&#27169;&#22411;&#65292;&#20801;&#35768;&#22312;&#19981;&#23545;&#23545;&#25239;&#24615;&#26679;&#20363;&#36827;&#34892;&#39044;&#27979;&#30340;&#24773;&#20917;&#19979;&#25552;&#39640;&#31639;&#27861;&#25239;&#23545;&#25239;&#25915;&#20987;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2306.13119</link><description>&lt;p&gt;
&#36890;&#36807;&#24323;&#26435;&#23454;&#29616;&#39034;&#24207;&#39044;&#27979;&#20013;&#30340;&#23545;&#25239;&#40065;&#26834;&#24615;
&lt;/p&gt;
&lt;p&gt;
Adversarial Resilience in Sequential Prediction via Abstention. (arXiv:2306.13119v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.13119
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22788;&#29702;&#39034;&#24207;&#39044;&#27979;&#30340;&#27169;&#22411;&#65292;&#20801;&#35768;&#22312;&#19981;&#23545;&#23545;&#25239;&#24615;&#26679;&#20363;&#36827;&#34892;&#39044;&#27979;&#30340;&#24773;&#20917;&#19979;&#25552;&#39640;&#31639;&#27861;&#25239;&#23545;&#25239;&#25915;&#20987;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#24102;&#26377;&#20801;&#35768;&#27880;&#20837;&#24178;&#20928;&#26631;&#31614;&#23545;&#25239;&#24615;&#65288;&#25110;&#36229;&#20986;&#20998;&#24067;&#65289;&#31034;&#20363;&#30340;&#23545;&#25239;&#32773;&#30340;&#24773;&#20917;&#19979;&#65292;&#22312;&#38543;&#26426;&#35774;&#32622;&#19979;&#30340;&#39034;&#24207;&#39044;&#27979;&#38382;&#39064;&#12290;&#38024;&#23545;&#32431;&#38543;&#26426;&#25968;&#25454;&#30340;&#31639;&#27861;&#22312;&#23384;&#22312;&#27492;&#31867;&#23545;&#25239;&#24615;&#31034;&#20363;&#30340;&#24773;&#20917;&#19979;&#24448;&#24448;&#22833;&#36133;&#65292;&#20174;&#32780;&#23548;&#33268;&#38169;&#35823;&#30340;&#39044;&#27979;&#12290;&#36825;&#22312;&#35768;&#22810;&#39640;&#39118;&#38505;&#24212;&#29992;&#20013;&#26159;&#19981;&#21487;&#21462;&#30340;&#65292;&#20363;&#22914;&#21307;&#23398;&#24314;&#35758;&#65292;&#36825;&#37324;&#24323;&#26435;&#19981;&#36827;&#34892;&#23545;&#25239;&#24615;&#31034;&#20363;&#30340;&#39044;&#27979;&#20248;&#20110;&#35823;&#20998;&#31867;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#20551;&#35774;&#23436;&#20840;&#23545;&#25239;&#24615;&#25968;&#25454;&#23548;&#33268;&#38750;&#24120;&#24754;&#35266;&#30340;&#30028;&#38480;&#65292;&#22312;&#23454;&#36341;&#20013;&#24448;&#24448;&#26159;&#31354;&#27934;&#30340;&#12290;&#20026;&#20102;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#39034;&#24207;&#39044;&#27979;&#27169;&#22411;&#65292;&#23427;&#20301;&#20110;&#32431;&#38543;&#26426;&#21644;&#23436;&#20840;&#23545;&#25239;&#24615;&#35774;&#32622;&#20043;&#38388;&#65292;&#36890;&#36807;&#20801;&#35768;&#23398;&#20064;&#22120;&#22312;&#23545;&#25239;&#26679;&#20363;&#19978;&#26080;&#20195;&#20215;&#22320;&#25918;&#24323;&#36827;&#34892;&#39044;&#27979;&#26469;&#23454;&#29616;&#12290;&#20551;&#35774;&#35775;&#38382;&#38750;&#23545;&#25239;&#26679;&#20363;&#30340;&#36793;&#38469;&#20998;&#24067;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#23398;&#20064;&#22120;&#65292;&#20854;&#35823;&#24046;&#38543;&#30528;VC&#32500;&#30340;&#21464;&#21270;&#32780;&#21464;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of sequential prediction in the stochastic setting with an adversary that is allowed to inject clean-label adversarial (or out-of-distribution) examples. Algorithms designed to handle purely stochastic data tend to fail in the presence of such adversarial examples, often leading to erroneous predictions. This is undesirable in many high-stakes applications such as medical recommendations, where abstaining from predictions on adversarial examples is preferable to misclassification. On the other hand, assuming fully adversarial data leads to very pessimistic bounds that are often vacuous in practice.  To capture this motivation, we propose a new model of sequential prediction that sits between the purely stochastic and fully adversarial settings by allowing the learner to abstain from making a prediction at no cost on adversarial examples. Assuming access to the marginal distribution on the non-adversarial examples, we design a learner whose error scales with the VC 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36880;&#23618;&#21442;&#25968;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#23454;&#29616;&#20869;&#32622;&#40065;&#26834;&#24615;&#20445;&#35777;&#30340;1D&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;CNN&#29305;&#24449;&#30340;Lipschitz&#24120;&#25968;&#20316;&#20026;&#40065;&#26834;&#24615;&#24230;&#37327;&#65292;&#24182;&#20351;&#29992;Cayley&#21464;&#25442;&#21644;&#21487;&#25511;&#24615;Gram&#30697;&#26469;&#23454;&#29616;CNN&#30340;Lipschitz&#36830;&#32493;&#24615;&#21644;&#26080;&#32422;&#26463;&#35757;&#32451;&#65292;&#26368;&#21518;&#22312;&#24515;&#24459;&#22833;&#24120;&#25968;&#25454;&#20998;&#31867;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#25913;&#36827;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.11835</link><description>&lt;p&gt;
&#21033;&#29992;Cayley&#21464;&#25442;&#21644;&#21487;&#25511;&#24615;Gram&#30697;&#30340;Lipschitz-bounded 1D&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;(arXiv:2303.11835v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
Lipschitz-bounded 1D convolutional neural networks using the Cayley transform and the controllability Gramian. (arXiv:2303.11835v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11835
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36880;&#23618;&#21442;&#25968;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#23454;&#29616;&#20869;&#32622;&#40065;&#26834;&#24615;&#20445;&#35777;&#30340;1D&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;CNN&#29305;&#24449;&#30340;Lipschitz&#24120;&#25968;&#20316;&#20026;&#40065;&#26834;&#24615;&#24230;&#37327;&#65292;&#24182;&#20351;&#29992;Cayley&#21464;&#25442;&#21644;&#21487;&#25511;&#24615;Gram&#30697;&#26469;&#23454;&#29616;CNN&#30340;Lipschitz&#36830;&#32493;&#24615;&#21644;&#26080;&#32422;&#26463;&#35757;&#32451;&#65292;&#26368;&#21518;&#22312;&#24515;&#24459;&#22833;&#24120;&#25968;&#25454;&#20998;&#31867;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#25913;&#36827;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#31181;&#29992;&#20110;1D&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#30340;&#36880;&#23618;&#21442;&#25968;&#21270;&#65292;&#20855;&#26377;&#20869;&#32622;&#30340;&#31471;&#21040;&#31471;&#40065;&#26834;&#24615;&#20445;&#35777;&#12290;&#25105;&#20204;&#20351;&#29992;CNN&#29305;&#24449;&#30340;Lipschitz&#24120;&#25968;&#20316;&#20026;&#40065;&#26834;&#24615;&#24230;&#37327;&#12290;&#25105;&#20204;&#22522;&#20110;Cayley&#21464;&#25442;&#23545;&#27491;&#20132;&#30697;&#38453;&#36827;&#34892;&#21442;&#25968;&#21270;&#20197;&#21450;&#23545;&#21367;&#31215;&#23618;&#30340;&#29366;&#24577;&#31354;&#38388;&#34920;&#24449;&#30340;&#21487;&#25511;&#24615;Gram&#30697;&#36827;&#34892;&#21442;&#25968;&#21270;&#12290;&#25152;&#25552;&#20986;&#30340;&#21442;&#25968;&#21270;&#35774;&#35745;&#28385;&#36275;&#32447;&#24615;&#30697;&#38453;&#19981;&#31561;&#24335;&#65292;&#20174;&#32780;&#23454;&#29616;CNN&#30340;Lipschitz&#36830;&#32493;&#24615;&#65292;&#36827;&#19968;&#27493;&#23454;&#29616;Lipschitz-bounded 1D CNNs&#30340;&#26080;&#32422;&#26463;&#35757;&#32451;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23545;&#24515;&#24459;&#22833;&#24120;&#25968;&#25454;&#36827;&#34892;Lipschitz-bounded 1D CNNs&#30340;&#20998;&#31867;&#35757;&#32451;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#25913;&#36827;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We establish a layer-wise parameterization for 1D convolutional neural networks (CNNs) with built-in end-to-end robustness guarantees. Herein, we use the Lipschitz constant of the input-output mapping characterized by a CNN as a robustness measure. We base our parameterization on the Cayley transform that parameterizes orthogonal matrices and the controllability Gramian for the state space representation of the convolutional layers. The proposed parameterization by design fulfills linear matrix inequalities that are sufficient for Lipschitz continuity of the CNN, which further enables unconstrained training of Lipschitz-bounded 1D CNNs. Finally, we train Lipschitz-bounded 1D CNNs for the classification of heart arrythmia data and show their improved robustness.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#30456;&#20851;&#32858;&#31867;&#20013;&#25104;&#23545;&#30456;&#20284;&#24615;&#19981;&#20107;&#20808;&#32473;&#20986;&#30340;&#24773;&#20917;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#20027;&#21160;&#23398;&#20064;&#26694;&#26550;&#65292;&#36866;&#24212;&#21508;&#31181;&#30456;&#20851;&#32858;&#31867;&#31639;&#27861;&#21644;&#26597;&#35810;&#31574;&#30053;&#65292;&#21516;&#26102;&#20855;&#26377;&#36866;&#24212;&#24615;&#28789;&#27963;&#12289;&#22122;&#22768;&#40065;&#26834;&#24615;&#31561;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2302.10295</link><description>&lt;p&gt;
&#20351;&#29992;&#20027;&#21160;&#23398;&#20064;&#26041;&#27861;&#30340;&#30456;&#20851;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Correlation Clustering with Active Learning of Pairwise Similarities. (arXiv:2302.10295v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.10295
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#30456;&#20851;&#32858;&#31867;&#20013;&#25104;&#23545;&#30456;&#20284;&#24615;&#19981;&#20107;&#20808;&#32473;&#20986;&#30340;&#24773;&#20917;&#65292;&#24182;&#24320;&#21457;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#20027;&#21160;&#23398;&#20064;&#26694;&#26550;&#65292;&#36866;&#24212;&#21508;&#31181;&#30456;&#20851;&#32858;&#31867;&#31639;&#27861;&#21644;&#26597;&#35810;&#31574;&#30053;&#65292;&#21516;&#26102;&#20855;&#26377;&#36866;&#24212;&#24615;&#28789;&#27963;&#12289;&#22122;&#22768;&#40065;&#26834;&#24615;&#31561;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30456;&#20851;&#32858;&#31867;&#26159;&#19968;&#20010;&#20247;&#25152;&#21608;&#30693;&#30340;&#26080;&#30417;&#30563;&#23398;&#20064;&#35774;&#32622;&#65292;&#22788;&#29702;&#27491;&#36127;&#30456;&#20284;&#24615;&#23545;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#24773;&#20917;&#65292;&#21363;&#25104;&#23545;&#30456;&#20284;&#24615;&#19981;&#20107;&#20808;&#32473;&#20986;&#65292;&#24517;&#39035;&#20197;&#39640;&#25928;&#30340;&#26041;&#24335;&#26597;&#35810;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#20010;&#36890;&#29992;&#30340;&#20027;&#21160;&#23398;&#20064;&#26694;&#26550;&#65292;&#38024;&#23545;&#36825;&#20010;&#20219;&#21153;&#20855;&#26377;&#22810;&#31181;&#20248;&#21183;&#65292;&#20363;&#22914;&#65292;&#29992;&#25143;/&#27880;&#37322;&#32773;&#21487;&#20197;&#25552;&#20379;&#21508;&#31181;&#21453;&#39304;&#31867;&#22411;&#12289;&#36866;&#24212;&#20219;&#20309;&#30456;&#20851;&#32858;&#31867;&#31639;&#27861;&#21644;&#26597;&#35810;&#31574;&#30053;&#20197;&#21450;&#23545;&#22122;&#22768;&#20855;&#26377;&#40065;&#26834;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#21644;&#20998;&#26512;&#20102;&#19968;&#20123;&#36866;&#21512;&#36825;&#31181;&#35774;&#32622;&#30340;&#26032;&#30340;&#26597;&#35810;&#31574;&#30053;&#12290;&#36890;&#36807;&#20960;&#20010;&#23454;&#39564;&#30740;&#31350;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#26694;&#26550;&#21644;&#25152;&#25552;&#20986;&#30340;&#26597;&#35810;&#31574;&#30053;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Correlation clustering is a well-known unsupervised learning setting that deals with positive and negative pairwise similarities. In this paper, we study the case where the pairwise similarities are not given in advance and must be queried in a cost-efficient way. Thereby, we develop a generic active learning framework for this task that benefits from several advantages, e.g., flexibility in the type of feedback that a user/annotator can provide, adaptation to any correlation clustering algorithm and query strategy, and robustness to noise. In addition, we propose and analyze a number of novel query strategies suited to this setting. We demonstrate the effectiveness of our framework and the proposed query strategies via several experimental studies.
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#20998;&#24067;&#36716;&#21464;&#30340;&#20915;&#26007;&#23545;&#25239;&#38382;&#39064;&#65292;&#24182;&#25506;&#35752;&#20102;&#35774;&#35745;&#33258;&#36866;&#24212;&#31639;&#27861;&#20197;&#35299;&#20915;&#21160;&#24577;&#36951;&#25022;&#30340;&#38382;&#39064;&#65292;&#32467;&#26524;&#21457;&#29616;&#21462;&#20915;&#20110;&#24213;&#23618;&#20559;&#22909;&#20998;&#24067;&#30340;&#23646;&#24615;&#12290;&#36798;&#21040;$O(\sqrt{K\tilde{L}T})$&#30340;&#21160;&#24577;&#36951;&#25022;&#26159;&#19981;&#21487;&#33021;&#30340;&#65307;&#23545;&#20110;$\text{SST} \cap \text{STI}$&#24773;&#20917;&#65292;&#23384;&#22312;&#19968;&#31181;&#31639;&#27861;&#23454;&#29616;&#21160;&#24577;&#36951;&#25022;&#20026;$O(\sqrt{K\tilde{L}T})$&#12290;</title><link>http://arxiv.org/abs/2302.06595</link><description>&lt;p&gt;
&#20309;&#26102;&#21487;&#20197;&#36861;&#36394;&#21040;&#20915;&#26007;&#23545;&#25239;&#20013;&#30340;&#26174;&#33879;&#20559;&#22909;&#36716;&#21464;&#65311;
&lt;/p&gt;
&lt;p&gt;
When Can We Track Significant Preference Shifts in Dueling Bandits?. (arXiv:2302.06595v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.06595
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#20998;&#24067;&#36716;&#21464;&#30340;&#20915;&#26007;&#23545;&#25239;&#38382;&#39064;&#65292;&#24182;&#25506;&#35752;&#20102;&#35774;&#35745;&#33258;&#36866;&#24212;&#31639;&#27861;&#20197;&#35299;&#20915;&#21160;&#24577;&#36951;&#25022;&#30340;&#38382;&#39064;&#65292;&#32467;&#26524;&#21457;&#29616;&#21462;&#20915;&#20110;&#24213;&#23618;&#20559;&#22909;&#20998;&#24067;&#30340;&#23646;&#24615;&#12290;&#36798;&#21040;$O(\sqrt{K\tilde{L}T})$&#30340;&#21160;&#24577;&#36951;&#25022;&#26159;&#19981;&#21487;&#33021;&#30340;&#65307;&#23545;&#20110;$\text{SST} \cap \text{STI}$&#24773;&#20917;&#65292;&#23384;&#22312;&#19968;&#31181;&#31639;&#27861;&#23454;&#29616;&#21160;&#24577;&#36951;&#25022;&#20026;$O(\sqrt{K\tilde{L}T})$&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20449;&#24687;&#26816;&#32034;&#12289;&#25512;&#33616;&#31995;&#32479;&#31561;&#39046;&#22495;&#24212;&#29992;&#24191;&#27867;&#30340;$K$&#33218;&#20915;&#26007;&#23545;&#25239;&#38382;&#39064;&#20013;&#65292;&#21453;&#39304;&#20197;&#26377;&#22122;&#22768;&#30340;&#25104;&#23545;&#20559;&#22909;&#24418;&#24335;&#32473;&#20986;&#65292;&#22240;&#27492;&#24471;&#21040;&#20102;&#24191;&#27867;&#30740;&#31350;&#12290;&#32771;&#34385;&#21040;&#29992;&#25143;&#30340;&#20559;&#22909;/&#21475;&#21619;&#21487;&#33021;&#38543;&#26102;&#38388;&#28436;&#21464;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#20855;&#26377;&#20998;&#24067;&#36716;&#21464;&#30340;&#20915;&#26007;&#23545;&#25239;&#38382;&#39064;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#26368;&#36817;&#25552;&#20986;&#30340;&#26174;&#33879;&#36716;&#21464;&#27010;&#24565;&#65288;Suk&#21644;Kpotufe&#65292;2022&#65289;&#65292;&#24182;&#25552;&#20986;&#26159;&#21542;&#21487;&#20197;&#35774;&#35745;&#19968;&#31181;&#33258;&#36866;&#24212;&#31639;&#27861;&#26469;&#35299;&#20915;&#20855;&#26377;$O(\sqrt{K\tilde{L}T})$&#21160;&#24577;&#36951;&#25022;&#65288;regret&#65289;&#30340;&#20915;&#26007;&#38382;&#39064;&#65292;&#20854;&#20013;$\tilde{L}$&#26159;&#20559;&#22909;&#20013;&#26174;&#33879;&#36716;&#21464;&#30340;&#65288;&#26410;&#30693;&#65289;&#25968;&#37327;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#36825;&#20010;&#38382;&#39064;&#30340;&#31572;&#26696;&#21462;&#20915;&#20110;&#24213;&#23618;&#20559;&#22909;&#20998;&#24067;&#30340;&#23646;&#24615;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#19968;&#20010;&#19981;&#21487;&#33021;&#30340;&#32467;&#26524;&#65292;&#25490;&#38500;&#20102;&#22312;&#24191;&#21463;&#30740;&#31350;&#30340;Condorcet&#21644;SST&#20559;&#22909;&#20998;&#24067;&#31867;&#19979;&#20855;&#26377;$O(\sqrt{K\tilde{L}T})$&#21160;&#24577;&#36951;&#25022;&#30340;&#20219;&#20309;&#31639;&#27861;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#34920;&#26126;$\text{SST} \cap \text{STI}$&#26159;&#22823;&#35268;&#27169;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
The $K$-armed dueling bandits problem, where the feedback is in the form of noisy pairwise preferences, has been widely studied due its applications in information retrieval, recommendation systems, etc. Motivated by concerns that user preferences/tastes can evolve over time, we consider the problem of dueling bandits with distribution shifts. Specifically, we study the recent notion of significant shifts (Suk and Kpotufe, 2022), and ask whether one can design an adaptive algorithm for the dueling problem with $O(\sqrt{K\tilde{L}T})$ dynamic regret, where $\tilde{L}$ is the (unknown) number of significant shifts in preferences. We show that the answer to this question depends on the properties of underlying preference distributions.  Firstly, we give an impossibility result that rules out any algorithm with $O(\sqrt{K\tilde{L}T})$ dynamic regret under the well-studied Condorcet and SST classes of preference distributions. Secondly, we show that $\text{SST} \cap \text{STI}$ is the large
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#24212;&#20110;&#31163;&#25955;&#24207;&#21015;&#20998;&#31867;&#22120;&#30340;&#38543;&#26426;&#21024;&#38500;&#65288;RS-Del&#65289;&#24179;&#28369;&#26426;&#21046;&#65292;&#25552;&#20379;&#38024;&#23545;&#32534;&#36753;&#36317;&#31163;&#21463;&#38480;&#23545;&#25239;&#24615;&#30340;&#40065;&#26834;&#24615;&#35777;&#26126;&#12290;</title><link>http://arxiv.org/abs/2302.01757</link><description>&lt;p&gt;
RS-Del: &#38543;&#26426;&#21024;&#38500;&#23545;&#24207;&#21015;&#20998;&#31867;&#22120;&#30340;&#32534;&#36753;&#36317;&#31163;&#40065;&#26834;&#24615;&#35777;&#26126;
&lt;/p&gt;
&lt;p&gt;
RS-Del: Edit Distance Robustness Certificates for Sequence Classifiers via Randomized Deletion. (arXiv:2302.01757v2 [cs.CR] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.01757
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#24212;&#20110;&#31163;&#25955;&#24207;&#21015;&#20998;&#31867;&#22120;&#30340;&#38543;&#26426;&#21024;&#38500;&#65288;RS-Del&#65289;&#24179;&#28369;&#26426;&#21046;&#65292;&#25552;&#20379;&#38024;&#23545;&#32534;&#36753;&#36317;&#31163;&#21463;&#38480;&#23545;&#25239;&#24615;&#30340;&#40065;&#26834;&#24615;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#24179;&#28369;&#26159;&#26500;&#24314;&#20855;&#26377;&#35748;&#35777;&#40065;&#26834;&#24615;&#30340;&#20998;&#31867;&#22120;&#30340;&#20027;&#35201;&#26041;&#27861;&#12290;&#29616;&#26377;&#30340;&#38543;&#26426;&#24179;&#28369;&#26041;&#27861;&#20027;&#35201;&#38024;&#23545;&#20855;&#26377;&#36830;&#32493;&#36755;&#20837;&#65288;&#22914;&#22270;&#20687;&#65289;&#30340;&#20998;&#31867;&#22120;&#65292;&#20854;&#20013;&#24120;&#24120;&#30740;&#31350;$\ell_p$&#33539;&#25968;&#21463;&#38480;&#30340;&#23545;&#25239;&#24615;&#31034;&#20363;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#20855;&#26377;&#31163;&#25955;&#25110;&#21487;&#21464;&#22823;&#23567;&#36755;&#20837;&#65288;&#20363;&#22914;&#28304;&#20195;&#30721;&#65289;&#30340;&#20998;&#31867;&#22120;&#30340;&#30740;&#31350;&#36739;&#23569;&#65292;&#36825;&#20123;&#20998;&#31867;&#22120;&#38656;&#35201;&#19981;&#21516;&#30340;&#23041;&#32961;&#27169;&#22411;&#21644;&#24179;&#28369;&#26426;&#21046;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#20462;&#25913;&#20102;&#38543;&#26426;&#24179;&#28369;&#26041;&#27861;&#65292;&#20197;&#36866;&#29992;&#20110;&#31163;&#25955;&#24207;&#21015;&#20998;&#31867;&#22120;&#65292;&#20197;&#25552;&#20379;&#38024;&#23545;&#32534;&#36753;&#36317;&#31163;&#21463;&#38480;&#30340;&#23545;&#25239;&#24615;&#30340;&#21487;&#35777;&#26126;&#30340;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#24179;&#28369;&#26426;&#21046;&#38543;&#26426;&#21024;&#38500;&#65288;RS-Del&#65289;&#24212;&#29992;&#20102;&#38543;&#26426;&#21024;&#38500;&#32534;&#36753;&#65292;&#36825;&#31181;&#26041;&#24335;&#65288;&#20063;&#35768;&#20196;&#20154;&#24778;&#35766;&#22320;&#65289;&#36275;&#20197;&#25552;&#20379;&#38024;&#23545;&#23545;&#25239;&#24615;&#21024;&#38500;&#12289;&#25554;&#20837;&#21644;&#26367;&#25442;&#32534;&#36753;&#30340;&#40065;&#26834;&#24615;&#12290;&#25105;&#20204;&#30340;&#35748;&#35777;&#35777;&#26126;&#19981;&#21516;&#20110;&#20256;&#32479;&#30340;Neyman-Pearson&#26041;&#27861;&#65292;&#22312;&#25105;&#20204;&#30340;&#24773;&#20917;&#19979;&#26080;&#27861;&#35745;&#31639;&#65292;&#32780;&#26159;&#22260;&#32469;&#30528;&#21478;&#19968;&#31181;&#26041;&#24335;&#36827;&#34892;&#32452;&#32455;&#12290;
&lt;/p&gt;
&lt;p&gt;
Randomized smoothing is a leading approach for constructing classifiers that are certifiably robust against adversarial examples. Existing work on randomized smoothing has focused on classifiers with continuous inputs, such as images, where $\ell_p$-norm bounded adversaries are commonly studied. However, there has been limited work for classifiers with discrete or variable-size inputs, such as for source code, which require different threat models and smoothing mechanisms. In this work, we adapt randomized smoothing for discrete sequence classifiers to provide certified robustness against edit distance-bounded adversaries. Our proposed smoothing mechanism randomized deletion (RS-Del) applies random deletion edits, which are (perhaps surprisingly) sufficient to confer robustness against adversarial deletion, insertion and substitution edits. Our proof of certification deviates from the established Neyman-Pearson approach, which is intractable in our setting, and is instead organized aro
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19978;&#19979;&#25991;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#30340;&#36716;&#31227;&#23398;&#20064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#26469;&#26368;&#23567;&#21270;&#36951;&#25022;&#65292;&#24182;&#37327;&#21270;&#20102;&#28304;&#39046;&#22495;&#25968;&#25454;&#23545;&#30446;&#26631;&#39046;&#22495;&#23398;&#20064;&#30340;&#36129;&#29486;&#12290;</title><link>http://arxiv.org/abs/2211.12612</link><description>&lt;p&gt;
&#36716;&#31227;&#23398;&#20064;&#29992;&#20110;&#19978;&#19979;&#25991;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Transfer Learning for Contextual Multi-armed Bandits. (arXiv:2211.12612v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.12612
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19978;&#19979;&#25991;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#30340;&#36716;&#31227;&#23398;&#20064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#26469;&#26368;&#23567;&#21270;&#36951;&#25022;&#65292;&#24182;&#37327;&#21270;&#20102;&#28304;&#39046;&#22495;&#25968;&#25454;&#23545;&#30446;&#26631;&#39046;&#22495;&#23398;&#20064;&#30340;&#36129;&#29486;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#38754;&#23545;&#19968;&#31995;&#21015;&#24212;&#29992;&#30340;&#39537;&#21160;&#19979;&#65292;&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#21327;&#21464;&#37327;&#36716;&#31227;&#27169;&#22411;&#19979;&#38750;&#21442;&#25968;&#19978;&#19979;&#25991;&#22810;&#33218;&#36172;&#21338;&#26426;&#30340;&#36716;&#31227;&#23398;&#20064;&#38382;&#39064;&#65292;&#20854;&#20013;&#22312;&#30446;&#26631;&#36172;&#21338;&#26426;&#24320;&#22987;&#23398;&#20064;&#20043;&#21069;&#65292;&#25105;&#20204;&#24050;&#32463;&#25910;&#38598;&#21040;&#20102;&#28304;&#36172;&#21338;&#26426;&#30340;&#25968;&#25454;&#12290;&#26412;&#25991;&#24314;&#31435;&#20102;&#32047;&#31215;&#36951;&#25022;&#30340;&#26368;&#23567;&#21270;&#36895;&#29575;&#25910;&#25947;&#24615;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#36716;&#31227;&#23398;&#20064;&#31639;&#27861;&#65292;&#23427;&#36798;&#21040;&#20102;&#26368;&#23567;&#21270;&#36951;&#25022;&#30340;&#26497;&#38480;&#12290;&#32467;&#26524;&#37327;&#21270;&#20102;&#28304;&#39046;&#22495;&#25968;&#25454;&#22312;&#19978;&#19979;&#25991;&#38750;&#21442;&#25968;&#22810;&#33218;&#36172;&#21338;&#26426;&#23398;&#20064;&#20013;&#23545;&#30446;&#26631;&#39046;&#22495;&#23398;&#20064;&#30340;&#36129;&#29486;&#12290;&#37492;&#20110;&#23545;&#26410;&#30693;&#24179;&#28369;&#24615;&#30340;&#19968;&#33324;&#19981;&#21487;&#33021;&#24615;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#31639;&#27861;&#65292;&#23427;&#22312;&#39069;&#22806;&#30340;&#33258;&#30456;&#20284;&#24615;&#20551;&#35774;&#19979;&#22312;&#22823;&#37327;&#21442;&#25968;&#31354;&#38388;&#20013;&#33258;&#21160;&#36866;&#24212;&#26410;&#30693;&#21442;&#25968;&#65292;&#24182;&#23454;&#29616;&#20102;&#25509;&#36817;&#26368;&#20248;&#30340;&#32479;&#35745;&#20445;&#35777;&#65288;&#38500;&#20197;&#23545;&#25968;&#22240;&#23376;&#65289;&#12290;&#36890;&#36807;&#27169;&#25311;&#23454;&#39564;&#35828;&#26126;&#20102;&#36716;&#31227;&#23398;&#20064;&#22312;&#19978;&#19979;&#25991;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#20013;&#30340;&#22909;&#22788;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by a range of applications, we study in this paper the problem of transfer learning for nonparametric contextual multi-armed bandits under the covariate shift model, where we have data collected on source bandits before the start of the target bandit learning. The minimax rate of convergence for the cumulative regret is established and a novel transfer learning algorithm that attains the minimax regret is proposed. The results quantify the contribution of the data from the source domains for learning in the target domain in the context of nonparametric contextual multi-armed bandits.  In view of the general impossibility of adaptation to unknown smoothness, we develop a data-driven algorithm that achieves near-optimal statistical guarantees (up to a logarithmic factor) while automatically adapting to the unknown parameters over a large collection of parameter spaces under an additional self-similarity assumption. A simulation study is carried out to illustrate the benefits of
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#35777;&#26126;&#20102;&#20351;&#29992;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;&#39118;&#38505;&#25935;&#24863;&#24378;&#21270;&#23398;&#20064;&#30340;&#36951;&#25022;&#20445;&#35777;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#39062;&#31639;&#27861;&#65292;&#20854;&#36951;&#25022;&#19978;&#30028;&#19982;&#20808;&#21069;&#26041;&#27861;&#30456;&#21305;&#37197;&#12290;</title><link>http://arxiv.org/abs/2210.14051</link><description>&lt;p&gt;
&#35777;&#26126;&#20102;&#20998;&#24067;&#24335;&#39118;&#38505;&#25935;&#24863;&#24378;&#21270;&#23398;&#20064;&#19982;&#39118;&#38505;&#25935;&#24863;&#24378;&#21270;&#23398;&#20064;&#20043;&#38388;&#30340;&#21487;&#35777;&#26126;&#36951;&#25022;&#19978;&#30028;
&lt;/p&gt;
&lt;p&gt;
Bridging Distributional and Risk-sensitive Reinforcement Learning with Provable Regret Bounds. (arXiv:2210.14051v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.14051
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#35777;&#26126;&#20102;&#20351;&#29992;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#21487;&#20197;&#23454;&#29616;&#39118;&#38505;&#25935;&#24863;&#24378;&#21270;&#23398;&#20064;&#30340;&#36951;&#25022;&#20445;&#35777;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#39062;&#31639;&#27861;&#65292;&#20854;&#36951;&#25022;&#19978;&#30028;&#19982;&#20808;&#21069;&#26041;&#27861;&#30456;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#23545;&#39118;&#38505;&#25935;&#24863;&#24378;&#21270;&#23398;&#20064;&#65288;RSRL&#65289;&#30340;&#36951;&#25022;&#20445;&#35777;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#30446;&#26631;&#20026;&#22238;&#25253;&#30340;&#29109;&#39118;&#38505;&#27979;&#24230;&#65288;EntRM&#65289;&#30340;&#26377;&#38480;&#24773;&#33410;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#12290;&#36890;&#36807;&#21033;&#29992;EntRM&#30340;&#19968;&#20010;&#20851;&#38190;&#23646;&#24615;&#65292;&#29420;&#31435;&#24615;&#23646;&#24615;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#39118;&#38505;&#25935;&#24863;&#20998;&#24067;&#24335;&#21160;&#24577;&#35268;&#21010;&#26694;&#26550;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#39062;&#30340;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#36890;&#36807;&#20004;&#31181;&#19981;&#21516;&#30340;&#26041;&#26696;&#23454;&#29616;&#20102;&#20048;&#35266;&#24615;&#65292;&#21253;&#25324;&#22522;&#20110;&#27169;&#22411;&#21644;&#26080;&#27169;&#22411;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#36825;&#20004;&#31181;&#31639;&#27861;&#37117;&#36798;&#21040;&#20102;$\tilde{\mathcal{O}}(\frac{\exp(|\beta| H)-1}{|\beta|}H\sqrt{S^2AK})$&#30340;&#36951;&#25022;&#19978;&#30028;&#65292;&#20854;&#20013;$S$&#65292;$A$&#65292;$K$&#21644;$H$&#20998;&#21035;&#34920;&#31034;&#29366;&#24577;&#30340;&#25968;&#37327;&#65292;&#21160;&#20316;&#30340;&#25968;&#37327;&#65292;&#24773;&#33410;&#30340;&#25968;&#37327;&#21644;&#26102;&#38388;&#30340;&#38271;&#24230;&#12290;&#36825;&#19982;\cite{fei2021exponential}&#20013;&#25552;&#20986;&#30340;RSVI2&#30456;&#19968;&#33268;&#65292;&#24182;&#36827;&#34892;&#20102;&#26032;&#39062;&#30340;&#20998;&#24067;&#24335;&#20998;&#26512;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#20197;&#26679;&#26412;&#22797;&#26434;&#24230;&#26041;&#21521;&#23558;&#20998;&#24067;&#24335;&#24378;&#21270;&#23398;&#20064;&#21644;&#39118;&#38505;&#25935;&#24863;&#24378;&#21270;&#23398;&#20064;&#32852;&#31995;&#36215;&#26469;&#30340;&#36951;&#25022;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the regret guarantee for risk-sensitive reinforcement learning (RSRL) via distributional reinforcement learning (DRL) methods. In particular, we consider finite episodic Markov decision processes whose objective is the entropic risk measure (EntRM) of return. By leveraging a key property of the EntRM, the independence property, we establish the risk-sensitive distributional dynamic programming framework. We then propose two novel DRL algorithms that implement optimism through two different schemes, including a model-free one and a model-based one.  We prove that they both attain $\tilde{\mathcal{O}}(\frac{\exp(|\beta| H)-1}{|\beta|}H\sqrt{S^2AK})$ regret upper bound, where $S$, $A$, $K$, and $H$ represent the number of states, actions, episodes, and the time horizon, respectively. It matches RSVI2 proposed in \cite{fei2021exponential}, with novel distributional analysis. To the best of our knowledge, this is the first regret analysis that bridges DRL and RSRL in terms of sampl
&lt;/p&gt;</description></item><item><title>MCCE&#26159;&#19968;&#20010;&#26032;&#39062;&#30340;&#21453;&#20107;&#23454;&#35299;&#37322;&#26041;&#27861;&#65292;&#36890;&#36807;&#27169;&#25311;&#21487;&#21464;&#29305;&#24449;&#21644;&#20915;&#31574;&#30340;&#32852;&#21512;&#20998;&#24067;&#65292;&#29983;&#25104;&#22788;&#20110;&#27969;&#24418;&#19978;&#12289;&#21487;&#34892;&#24182;&#19988;&#26377;&#25928;&#30340;&#21453;&#20107;&#23454;&#12290;&#19982;&#20854;&#20182;&#26041;&#27861;&#30456;&#27604;&#65292;MCCE&#21487;&#20197;&#22788;&#29702;&#20219;&#20309;&#31867;&#22411;&#30340;&#39044;&#27979;&#27169;&#22411;&#21644;&#20855;&#26377;&#22810;&#20010;&#32423;&#21035;&#30340;&#20998;&#31867;&#29305;&#24449;&#12290;</title><link>http://arxiv.org/abs/2111.09790</link><description>&lt;p&gt;
MCCE&#65306;&#33945;&#29305;&#21345;&#27931;&#37319;&#26679;&#30340;&#29616;&#23454;&#21453;&#20107;&#23454;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
MCCE: Monte Carlo sampling of realistic counterfactual explanations. (arXiv:2111.09790v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.09790
&lt;/p&gt;
&lt;p&gt;
MCCE&#26159;&#19968;&#20010;&#26032;&#39062;&#30340;&#21453;&#20107;&#23454;&#35299;&#37322;&#26041;&#27861;&#65292;&#36890;&#36807;&#27169;&#25311;&#21487;&#21464;&#29305;&#24449;&#21644;&#20915;&#31574;&#30340;&#32852;&#21512;&#20998;&#24067;&#65292;&#29983;&#25104;&#22788;&#20110;&#27969;&#24418;&#19978;&#12289;&#21487;&#34892;&#24182;&#19988;&#26377;&#25928;&#30340;&#21453;&#20107;&#23454;&#12290;&#19982;&#20854;&#20182;&#26041;&#27861;&#30456;&#27604;&#65292;MCCE&#21487;&#20197;&#22788;&#29702;&#20219;&#20309;&#31867;&#22411;&#30340;&#39044;&#27979;&#27169;&#22411;&#21644;&#20855;&#26377;&#22810;&#20010;&#32423;&#21035;&#30340;&#20998;&#31867;&#29305;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;MCCE: Monte Carlo&#37319;&#26679;&#30340;&#26377;&#25928;&#21644;&#29616;&#23454;&#30340;&#34920;&#26684;&#25968;&#25454;&#21453;&#20107;&#23454;&#35299;&#37322;&#65292;&#36825;&#26159;&#19968;&#31181;&#26032;&#39062;&#30340;&#21453;&#20107;&#23454;&#35299;&#37322;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#32473;&#23450;&#19981;&#21487;&#21464;&#29305;&#24449;&#21644;&#20915;&#31574;&#30340;&#21487;&#21464;&#29305;&#24449;&#30340;&#32852;&#21512;&#20998;&#24067;&#36827;&#34892;&#24314;&#27169;&#65292;&#29983;&#25104;&#22788;&#20110;&#27969;&#24418;&#19978;&#12289;&#21487;&#34892;&#24182;&#19988;&#26377;&#25928;&#30340;&#21453;&#20107;&#23454;&#12290;&#19982;&#20854;&#20182;&#20381;&#36182;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#21644;&#20855;&#26377;&#20005;&#26684;&#39044;&#27979;&#27169;&#22411;&#21644;&#25968;&#25454;&#35201;&#27714;&#30340;&#27969;&#24418;&#26041;&#27861;&#19981;&#21516;&#65292;MCCE&#21487;&#20197;&#22788;&#29702;&#20219;&#20309;&#31867;&#22411;&#30340;&#39044;&#27979;&#27169;&#22411;&#21644;&#20855;&#26377;&#20004;&#20010;&#20197;&#19978;&#32423;&#21035;&#30340;&#20998;&#31867;&#29305;&#24449;&#12290;MCCE&#39318;&#20808;&#20351;&#29992;&#33258;&#22238;&#24402;&#29983;&#25104;&#27169;&#22411;&#23545;&#29305;&#24449;&#21644;&#20915;&#31574;&#30340;&#32852;&#21512;&#20998;&#24067;&#36827;&#34892;&#24314;&#27169;&#65292;&#20854;&#20013;&#26465;&#20214;&#27010;&#29575;&#20351;&#29992;&#20915;&#31574;&#26641;&#36827;&#34892;&#20272;&#35745;&#12290;&#28982;&#21518;&#65292;&#23427;&#20174;&#35813;&#27169;&#22411;&#20013;&#37319;&#26679;&#19968;&#22823;&#32452;&#35266;&#27979;&#20540;&#65292;&#26368;&#21518;&#21024;&#38500;&#19981;&#31526;&#21512;&#29305;&#23450;&#26465;&#20214;&#30340;&#26679;&#26412;&#12290;&#25105;&#20204;&#20351;&#29992;&#22235;&#20010;&#30693;&#21517;&#25968;&#25454;&#38598;&#23558;MCCE&#19982;&#19968;&#31995;&#21015;&#26368;&#20808;&#36827;&#30340;&#27969;&#24418;&#21453;&#20107;&#23454;&#26041;&#27861;&#36827;&#34892;&#27604;&#36739;&#65292;&#24182;&#23637;&#31034;&#20102;MCCE&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce MCCE: Monte Carlo sampling of valid and realistic Counterfactual Explanations for tabular data, a novel counterfactual explanation method that generates on-manifold, actionable and valid counterfactuals by modeling the joint distribution of the mutable features given the immutable features and the decision. Unlike other on-manifold methods that tend to rely on variational autoencoders and have strict prediction model and data requirements, MCCE handles any type of prediction model and categorical features with more than two levels. MCCE first models the joint distribution of the features and the decision with an autoregressive generative model where the conditionals are estimated using decision trees. Then, it samples a large set of observations from this model, and finally, it removes the samples that do not obey certain criteria. We compare MCCE with a range of state-of-the-art on-manifold counterfactual methods using four well-known data sets and show that MCCE outperfo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#38024;&#23545;&#38750;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#26080;&#23548;&#25968;&#20132;&#26367;&#25237;&#24433;&#31639;&#27861;&#65292;&#21253;&#25324;&#20809;&#28369;&#38382;&#39064;&#30340;&#20132;&#26367;&#38543;&#26426;&#26799;&#24230;&#25237;&#24433;&#31639;&#27861;&#65288;ZO-AGP&#65289;&#65292;&#20197;&#21450;&#22359;&#29366;&#38750;&#20809;&#28369;&#38382;&#39064;&#30340;&#20998;&#22359;&#20132;&#26367;&#38543;&#26426;&#36817;&#31471;&#26799;&#24230;&#31639;&#27861;&#65288;ZO-BAPG&#65289;&#12290;&#36825;&#20123;&#31639;&#27861;&#20855;&#26377;&#36739;&#23569;&#30340;&#20989;&#25968;&#20540;&#20272;&#35745;&#21644;&#36739;&#39640;&#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2108.00473</link><description>&lt;p&gt;
&#38024;&#23545;&#38750;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#26080;&#23548;&#25968;&#20132;&#26367;&#25237;&#24433;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Derivative-free Alternating Projection Algorithms for General Nonconvex-Concave Minimax Problems. (arXiv:2108.00473v3 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2108.00473
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#38024;&#23545;&#38750;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#26080;&#23548;&#25968;&#20132;&#26367;&#25237;&#24433;&#31639;&#27861;&#65292;&#21253;&#25324;&#20809;&#28369;&#38382;&#39064;&#30340;&#20132;&#26367;&#38543;&#26426;&#26799;&#24230;&#25237;&#24433;&#31639;&#27861;&#65288;ZO-AGP&#65289;&#65292;&#20197;&#21450;&#22359;&#29366;&#38750;&#20809;&#28369;&#38382;&#39064;&#30340;&#20998;&#22359;&#20132;&#26367;&#38543;&#26426;&#36817;&#31471;&#26799;&#24230;&#31639;&#27861;&#65288;ZO-BAPG&#65289;&#12290;&#36825;&#20123;&#31639;&#27861;&#20855;&#26377;&#36739;&#23569;&#30340;&#20989;&#25968;&#20540;&#20272;&#35745;&#21644;&#36739;&#39640;&#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38750;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#30340;&#38646;&#38454;&#31639;&#27861;&#65292;&#36825;&#31867;&#38382;&#39064;&#36817;&#24180;&#22312;&#26426;&#22120;&#23398;&#20064;&#12289;&#20449;&#21495;&#22788;&#29702;&#31561;&#39046;&#22495;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38646;&#38454;&#20132;&#26367;&#38543;&#26426;&#26799;&#24230;&#25237;&#24433;&#65288;ZO-AGP&#65289;&#31639;&#27861;&#26469;&#35299;&#20915;&#20809;&#28369;&#30340;&#38750;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#65292;&#20854;&#36845;&#20195;&#22797;&#26434;&#24230;&#20026; $\mathcal{O}(\varepsilon^{-4})$&#65292;&#27599;&#27425;&#36845;&#20195;&#30340;&#20989;&#25968;&#20540;&#20272;&#35745;&#27425;&#25968;&#20026; $\mathcal{O}(d_{x}+d_{y})$&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#38646;&#38454;&#20998;&#22359;&#20132;&#26367;&#38543;&#26426;&#36817;&#31471;&#26799;&#24230;&#31639;&#27861;&#65288;ZO-BAPG&#65289;&#26469;&#35299;&#20915;&#22359;&#29366;&#38750;&#20809;&#28369;&#30340;&#38750;&#20984;-&#20985;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#38382;&#39064;&#65292;&#20854;&#36845;&#20195;&#22797;&#26434;&#24230;&#20026; $\mathcal{O}(\varepsilon^{-4})$&#65292;&#27599;&#27425;&#36845;&#20195;&#30340;&#20989;&#25968;&#20540;&#20272;&#35745;&#27425;&#25968;&#20026; $\mathcal{O}(K d_{x}+d_{y})$&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#39318;&#27425;&#25552;&#20986;&#36825;&#20123;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study zeroth-order algorithms for nonconvex-concave minimax problems, which have attracted widely attention in machine learning, signal processing and many other fields in recent years. We propose a zeroth-order alternating randomized gradient projection (ZO-AGP) algorithm for smooth nonconvex-concave minimax problems, and its iteration complexity to obtain an $\varepsilon$-stationary point is bounded by $\mathcal{O}(\varepsilon^{-4})$, and the number of function value estimation is bounded by $\mathcal{O}(d_{x}+d_{y})$ per iteration. Moreover, we propose a zeroth-order block alternating randomized proximal gradient algorithm (ZO-BAPG) for solving block-wise nonsmooth nonconvex-concave minimax optimization problems, and the iteration complexity to obtain an $\varepsilon$-stationary point is bounded by $\mathcal{O}(\varepsilon^{-4})$ and the number of function value estimation per iteration is bounded by $\mathcal{O}(K d_{x}+d_{y})$. To the best of our knowledge, this 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#22522;&#26412;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GANs&#65289;&#36827;&#34892;&#20102;&#35814;&#32454;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#22312;&#38750;&#21442;&#25968;&#23494;&#24230;&#20272;&#35745;&#24212;&#29992;&#20013;&#65292;GAN&#20272;&#35745;&#19982;&#30495;&#23454;&#23494;&#24230;&#20043;&#38388;&#30340;JS&#25955;&#24230;&#25910;&#25947;&#36895;&#24230;&#36798;&#21040;&#20102;&#26497;&#23567;&#26497;&#38480;&#26368;&#20248;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2102.00199</link><description>&lt;p&gt;
&#20351;&#29992;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#36827;&#34892;&#23494;&#24230;&#20272;&#35745;&#30340;&#25910;&#25947;&#36895;&#24230;
&lt;/p&gt;
&lt;p&gt;
Rates of convergence for density estimation with generative adversarial networks. (arXiv:2102.00199v4 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2102.00199
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#22522;&#26412;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GANs&#65289;&#36827;&#34892;&#20102;&#35814;&#32454;&#30740;&#31350;&#65292;&#35777;&#26126;&#20102;&#22312;&#38750;&#21442;&#25968;&#23494;&#24230;&#20272;&#35745;&#24212;&#29992;&#20013;&#65292;GAN&#20272;&#35745;&#19982;&#30495;&#23454;&#23494;&#24230;&#20043;&#38388;&#30340;JS&#25955;&#24230;&#25910;&#25947;&#36895;&#24230;&#36798;&#21040;&#20102;&#26497;&#23567;&#26497;&#38480;&#26368;&#20248;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23545;&#22522;&#26412;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GANs&#65289;&#30340;&#38750;&#28176;&#36817;&#29305;&#24615;&#36827;&#34892;&#20102;&#20840;&#38754;&#30740;&#31350;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#23545;&#20110;&#22522;&#26412;&#23494;&#24230;$\mathsf{p}^*$&#21644;GAN&#20272;&#35745;&#20043;&#38388;&#30340;Jensen-Shannon&#65288;JS&#65289;&#25955;&#24230;&#65292;&#23384;&#22312;&#19968;&#20010;&#27491;&#21017;&#21270;&#19981;&#31561;&#24335;&#65292;&#20854;&#32479;&#35745;&#35823;&#24046;&#39033;&#30456;&#36739;&#20110;&#20808;&#21069;&#24050;&#30693;&#30340;&#32467;&#26524;&#26174;&#33879;&#25913;&#36827;&#12290;&#25105;&#20204;&#30340;&#30028;&#38480;&#30340;&#20248;&#21183;&#22312;&#20110;&#38750;&#21442;&#25968;&#23494;&#24230;&#20272;&#35745;&#30340;&#24212;&#29992;&#20013;&#21464;&#24471;&#26126;&#26174;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;GAN&#20272;&#35745;&#19982;$\mathsf{p}^*$&#20043;&#38388;&#30340;JS&#25955;&#24230;&#30340;&#25910;&#25947;&#36895;&#24230;&#19982;&#26679;&#26412;&#37327;$n$&#30340;&#36895;&#29575;&#20026;$(\log{n}/n)^{2\beta/(2\beta + d)}$&#65292;&#20854;&#20013;$n$&#20026;&#26679;&#26412;&#22823;&#23567;&#65292;$\beta$&#20915;&#23450;&#20102;$\mathsf{p}^*$&#30340;&#24179;&#28369;&#31243;&#24230;&#12290;&#36825;&#31181;&#25910;&#25947;&#36895;&#24230;&#65288;&#38500;&#20102;&#23545;&#25968;&#22240;&#23376;&#65289;&#19982;&#25152;&#32771;&#34385;&#30340;&#23494;&#24230;&#31867;&#30340;&#26497;&#23567;&#26497;&#38480;&#26368;&#20248;&#36895;&#29575;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work we undertake a thorough study of the non-asymptotic properties of the vanilla generative adversarial networks (GANs). We prove an oracle inequality for the Jensen-Shannon (JS) divergence between the underlying density $\mathsf{p}^*$ and the GAN estimate with a significantly better statistical error term compared to the previously known results. The advantage of our bound becomes clear in application to nonparametric density estimation. We show that the JS-divergence between the GAN estimate and $\mathsf{p}^*$ decays as fast as $(\log{n}/n)^{2\beta/(2\beta + d)}$, where $n$ is the sample size and $\beta$ determines the smoothness of $\mathsf{p}^*$. This rate of convergence coincides (up to logarithmic factors) with minimax optimal for the considered class of densities.
&lt;/p&gt;</description></item></channel></rss>