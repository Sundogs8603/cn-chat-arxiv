<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#22810;&#23618;&#27425;&#38543;&#26426;&#22359;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#32858;&#21512;&#26469;&#33258;&#19981;&#21516;&#20449;&#24687;&#28304;&#30340;&#22810;&#20010;&#32858;&#31867;&#65292;&#24182;&#23558;&#35266;&#27979;&#20998;&#21306;&#21040;&#19981;&#21516;&#30340;&#32858;&#31867;&#20013;&#65292;&#32771;&#34385;&#21040;&#23427;&#20204;&#22312;&#32452;&#20214;&#20869;&#30340;&#29305;&#23450;&#24615;&#12290;&#35813;&#26041;&#27861;&#22312;&#21512;&#25104;&#25968;&#25454;&#21644;&#20840;&#29699;&#39135;&#21697;&#36152;&#26131;&#32593;&#32476;&#20013;&#24471;&#21040;&#20102;&#26377;&#36259;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2401.04682</link><description>&lt;p&gt;
&#28151;&#21512;&#22810;&#23618;&#27425;&#38543;&#26426;&#22359;&#27169;&#22411;&#29992;&#20110;&#22810;&#35270;&#35282;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Mixture of multilayer stochastic block models for multiview clustering. (arXiv:2401.04682v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04682
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#22810;&#23618;&#27425;&#38543;&#26426;&#22359;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#32858;&#21512;&#26469;&#33258;&#19981;&#21516;&#20449;&#24687;&#28304;&#30340;&#22810;&#20010;&#32858;&#31867;&#65292;&#24182;&#23558;&#35266;&#27979;&#20998;&#21306;&#21040;&#19981;&#21516;&#30340;&#32858;&#31867;&#20013;&#65292;&#32771;&#34385;&#21040;&#23427;&#20204;&#22312;&#32452;&#20214;&#20869;&#30340;&#29305;&#23450;&#24615;&#12290;&#35813;&#26041;&#27861;&#22312;&#21512;&#25104;&#25968;&#25454;&#21644;&#20840;&#29699;&#39135;&#21697;&#36152;&#26131;&#32593;&#32476;&#20013;&#24471;&#21040;&#20102;&#26377;&#36259;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#32858;&#21512;&#26469;&#33258;&#19981;&#21516;&#20449;&#24687;&#28304;&#30340;&#22810;&#20010;&#32858;&#31867;&#30340;&#21407;&#22987;&#26041;&#27861;&#12290;&#27599;&#20010;&#20998;&#21306;&#30001;&#35266;&#27979;&#20043;&#38388;&#30340;&#20849;&#23646;&#24615;&#30697;&#38453;&#36827;&#34892;&#32534;&#30721;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20351;&#29992;&#20102;&#28151;&#21512;&#22810;&#23618;&#27425;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;SBM&#65289;&#23558;&#20855;&#26377;&#30456;&#20284;&#20449;&#24687;&#30340;&#20849;&#23646;&#24615;&#30697;&#38453;&#20998;&#32452;&#20026;&#32452;&#20214;&#65292;&#24182;&#23558;&#35266;&#27979;&#20998;&#21306;&#21040;&#19981;&#21516;&#30340;&#32858;&#31867;&#20013;&#65292;&#32771;&#34385;&#21040;&#23427;&#20204;&#22312;&#32452;&#20214;&#20869;&#30340;&#29305;&#23450;&#24615;&#12290;&#27169;&#22411;&#21442;&#25968;&#30340;&#21487;&#35782;&#21035;&#24615;&#34987;&#24314;&#31435;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#21464;&#20998;&#36125;&#21494;&#26031;EM&#31639;&#27861;&#26469;&#20272;&#35745;&#36825;&#20123;&#21442;&#25968;&#12290;&#36125;&#21494;&#26031;&#26694;&#26550;&#20801;&#35768;&#36873;&#25321;&#26368;&#20248;&#30340;&#32858;&#31867;&#21644;&#32452;&#20214;&#25968;&#37327;&#12290;&#21033;&#29992;&#21512;&#25104;&#25968;&#25454;&#23558;&#25552;&#20986;&#30340;&#26041;&#27861;&#19982;&#20849;&#35782;&#32858;&#31867;&#21644;&#22522;&#20110;&#24352;&#37327;&#30340;&#31639;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#65292;&#29992;&#20110;&#22823;&#35268;&#27169;&#22797;&#26434;&#32593;&#32476;&#20013;&#30340;&#31038;&#21306;&#26816;&#27979;&#12290;&#26368;&#21518;&#65292;&#35813;&#26041;&#27861;&#34987;&#29992;&#20110;&#20998;&#26512;&#20840;&#29699;&#39135;&#21697;&#36152;&#26131;&#32593;&#32476;&#65292;&#24471;&#21040;&#20102;&#26377;&#36259;&#30340;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we propose an original method for aggregating multiple clustering coming from different sources of information. Each partition is encoded by a co-membership matrix between observations. Our approach uses a mixture of multilayer Stochastic Block Models (SBM) to group co-membership matrices with similar information into components and to partition observations into different clusters, taking into account their specificities within the components. The identifiability of the model parameters is established and a variational Bayesian EM algorithm is proposed for the estimation of these parameters. The Bayesian framework allows for selecting an optimal number of clusters and components. The proposed approach is compared using synthetic data with consensus clustering and tensor-based algorithms for community detection in large-scale complex networks. Finally, the method is utilized to analyze global food trading networks, leading to structures of interest.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#36882;&#24402;&#29305;&#24449;&#26426;&#22120;&#65288;RFMs&#65289;&#31639;&#27861;&#65292;&#23427;&#36890;&#36807;&#20132;&#26367;&#37325;&#26032;&#21152;&#26435;&#29305;&#24449;&#21521;&#37327;&#21644;&#22312;&#36716;&#25442;&#31354;&#38388;&#20013;&#23398;&#20064;&#39044;&#27979;&#20989;&#25968;&#26469;&#25191;&#34892;&#26174;&#24335;&#30340;&#29305;&#24449;&#23398;&#20064;&#12290;&#30740;&#31350;&#20998;&#26512;&#20102;RFM&#22312;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#21644;&#20302;&#31209;&#30697;&#38453;&#24674;&#22797;&#38382;&#39064;&#20013;&#30340;&#32500;&#25968;&#20943;&#23569;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.04553</link><description>&lt;p&gt;
&#32447;&#24615;&#36882;&#24402;&#29305;&#24449;&#26426;&#22120;&#21487;&#20197;&#21487;&#38752;&#22320;&#24674;&#22797;&#20302;&#31209;&#30697;&#38453;
&lt;/p&gt;
&lt;p&gt;
Linear Recursive Feature Machines provably recover low-rank matrices. (arXiv:2401.04553v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04553
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#36882;&#24402;&#29305;&#24449;&#26426;&#22120;&#65288;RFMs&#65289;&#31639;&#27861;&#65292;&#23427;&#36890;&#36807;&#20132;&#26367;&#37325;&#26032;&#21152;&#26435;&#29305;&#24449;&#21521;&#37327;&#21644;&#22312;&#36716;&#25442;&#31354;&#38388;&#20013;&#23398;&#20064;&#39044;&#27979;&#20989;&#25968;&#26469;&#25191;&#34892;&#26174;&#24335;&#30340;&#29305;&#24449;&#23398;&#20064;&#12290;&#30740;&#31350;&#20998;&#26512;&#20102;RFM&#22312;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#21644;&#20302;&#31209;&#30697;&#38453;&#24674;&#22797;&#38382;&#39064;&#20013;&#30340;&#32500;&#25968;&#20943;&#23569;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#20013;&#19968;&#20010;&#22522;&#26412;&#30340;&#38382;&#39064;&#26159;&#35201;&#29702;&#35299;&#31070;&#32463;&#32593;&#32476;&#22914;&#20309;&#20934;&#30830;&#39044;&#27979;&#65292;&#21516;&#26102;&#20284;&#20046;&#36991;&#20813;&#20102;&#32500;&#25968;&#35781;&#21650;&#12290;&#19968;&#20010;&#21487;&#33021;&#30340;&#35299;&#37322;&#26159;&#31070;&#32463;&#32593;&#32476;&#30340;&#24120;&#35265;&#35757;&#32451;&#31639;&#27861;&#38544;&#21547;&#22320;&#36827;&#34892;&#32500;&#25968;&#20943;&#23569; - &#19968;&#20010;&#34987;&#31216;&#20026;&#29305;&#24449;&#23398;&#20064;&#30340;&#36807;&#31243;&#12290;&#26368;&#36817;&#30340;&#24037;&#20316;&#20551;&#35774;&#29305;&#24449;&#23398;&#20064;&#30340;&#25928;&#26524;&#21487;&#20197;&#20174;&#19968;&#20010;&#31216;&#20026;&#24179;&#22343;&#26799;&#24230;&#22806;&#31215;&#65288;AGOP&#65289;&#30340;&#32463;&#20856;&#32479;&#35745;&#20272;&#35745;&#22120;&#20013;&#25512;&#27979;&#20986;&#26469;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#36882;&#24402;&#29305;&#24449;&#26426;&#22120;&#65288;RFMs&#65289;&#20316;&#20026;&#19968;&#31181;&#31639;&#27861;&#65292;&#36890;&#36807;&#22312;&#36716;&#25442;&#31354;&#38388;&#20013;&#20132;&#26367;&#36827;&#34892;&#65288;1&#65289;&#36890;&#36807;AGOP&#23545;&#29305;&#24449;&#21521;&#37327;&#37325;&#26032;&#21152;&#26435;&#21644;&#65288;2&#65289;&#23398;&#20064;&#39044;&#27979;&#20989;&#25968;&#65292;&#26174;&#24335;&#22320;&#25191;&#34892;&#29305;&#24449;&#23398;&#20064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#20851;&#27880;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#21644;&#20302;&#31209;&#30697;&#38453;&#24674;&#22797;&#20013;&#20986;&#29616;&#30340;&#36807;&#21442;&#25968;&#21270;&#38382;&#39064;&#30340;&#31867;&#21035;&#65292;&#24320;&#21457;&#20102;&#20851;&#20110;RFM&#22914;&#20309;&#36827;&#34892;&#32500;&#25968;&#20943;&#23569;&#30340;&#31532;&#19968;&#20010;&#29702;&#35770;&#20445;&#35777;&#12290;&#20855;&#20307;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;RFM&#22312;&#38480;&#21046;&#26465;&#20214;&#19979;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
A fundamental problem in machine learning is to understand how neural networks make accurate predictions, while seemingly bypassing the curse of dimensionality. A possible explanation is that common training algorithms for neural networks implicitly perform dimensionality reduction - a process called feature learning. Recent work posited that the effects of feature learning can be elicited from a classical statistical estimator called the average gradient outer product (AGOP). The authors proposed Recursive Feature Machines (RFMs) as an algorithm that explicitly performs feature learning by alternating between (1) reweighting the feature vectors by the AGOP and (2) learning the prediction function in the transformed space. In this work, we develop the first theoretical guarantees for how RFM performs dimensionality reduction by focusing on the class of overparametrized problems arising in sparse linear regression and low-rank matrix recovery. Specifically, we show that RFM restricted t
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21322;&#30417;&#30563;&#28145;&#24230;Sobolev&#22238;&#24402;&#22120;&#65292;&#21033;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#26799;&#24230;&#33539;&#25968;&#27491;&#21017;&#21270;&#65292;&#21487;&#20197;&#21516;&#26102;&#20272;&#35745;&#22238;&#24402;&#20989;&#25968;&#21644;&#20854;&#26799;&#24230;&#65292;&#21363;&#20351;&#23384;&#22312;&#26174;&#33879;&#39046;&#22495;&#21464;&#21270;&#12290;&#36825;&#22312;&#21322;&#30417;&#30563;&#23398;&#20064;&#20013;&#21033;&#29992;&#26080;&#26631;&#31614;&#25968;&#25454;&#26041;&#38754;&#20855;&#26377;&#21487;&#35777;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2401.04535</link><description>&lt;p&gt;
&#21322;&#30417;&#30563;&#28145;&#24230;Sobolev&#22238;&#24402;: &#20272;&#35745;&#12289;&#21464;&#37327;&#36873;&#25321;&#21450;&#20854;&#20182;
&lt;/p&gt;
&lt;p&gt;
Semi-Supervised Deep Sobolev Regression: Estimation, Variable Selection and Beyond. (arXiv:2401.04535v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04535
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21322;&#30417;&#30563;&#28145;&#24230;Sobolev&#22238;&#24402;&#22120;&#65292;&#21033;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#26799;&#24230;&#33539;&#25968;&#27491;&#21017;&#21270;&#65292;&#21487;&#20197;&#21516;&#26102;&#20272;&#35745;&#22238;&#24402;&#20989;&#25968;&#21644;&#20854;&#26799;&#24230;&#65292;&#21363;&#20351;&#23384;&#22312;&#26174;&#33879;&#39046;&#22495;&#21464;&#21270;&#12290;&#36825;&#22312;&#21322;&#30417;&#30563;&#23398;&#20064;&#20013;&#21033;&#29992;&#26080;&#26631;&#31614;&#25968;&#25454;&#26041;&#38754;&#20855;&#26377;&#21487;&#35777;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;SDORE&#65292;&#19968;&#31181;&#21322;&#30417;&#30563;&#28145;&#24230;Sobolev&#22238;&#24402;&#22120;&#65292;&#29992;&#20110;&#38750;&#21442;&#25968;&#20272;&#35745;&#28508;&#22312;&#30340;&#22238;&#24402;&#20989;&#25968;&#21450;&#20854;&#26799;&#24230;&#12290;SDORE&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26469;&#26368;&#23567;&#21270;&#32463;&#39564;&#39118;&#38505;&#65292;&#24182;&#37319;&#29992;&#26799;&#24230;&#33539;&#25968;&#27491;&#21017;&#21270;&#65292;&#20801;&#35768;&#23545;&#26080;&#26631;&#31614;&#25968;&#25454;&#35745;&#31639;&#26799;&#24230;&#33539;&#25968;&#12290;&#25105;&#20204;&#23545;SDORE&#30340;&#25910;&#25947;&#36895;&#24230;&#36827;&#34892;&#20102;&#20840;&#38754;&#20998;&#26512;&#65292;&#24182;&#24314;&#31435;&#20102;&#22238;&#24402;&#20989;&#25968;&#30340;&#26368;&#23567;&#21270;&#26368;&#20248;&#36895;&#29575;&#12290;&#37325;&#35201;&#30340;&#26159;&#65292;&#22312;&#23384;&#22312;&#26174;&#33879;&#39046;&#22495;&#21464;&#21270;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#36824;&#25512;&#23548;&#20986;&#20102;&#20851;&#32852;&#30340;&#25554;&#20540;&#26799;&#24230;&#20272;&#35745;&#22120;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;&#36825;&#20123;&#29702;&#35770;&#32467;&#26524;&#20026;&#36873;&#25321;&#27491;&#21017;&#21270;&#21442;&#25968;&#21644;&#30830;&#23450;&#31070;&#32463;&#32593;&#32476;&#30340;&#22823;&#23567;&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#20808;&#39564;&#25351;&#23548;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#21322;&#30417;&#30563;&#23398;&#20064;&#20013;&#21033;&#29992;&#26080;&#26631;&#31614;&#25968;&#25454;&#30340;&#21487;&#35777;&#20248;&#21183;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;SDORE&#26159;&#31532;&#19968;&#20010;&#21516;&#26102;&#20272;&#35745;&#22238;&#24402;&#20989;&#25968;&#21450;&#20854;&#26799;&#24230;&#30340;&#21487;&#35777;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#65292;&#20855;&#26377;&#22810;&#26679;&#21270;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose SDORE, a semi-supervised deep Sobolev regressor, for the nonparametric estimation of the underlying regression function and its gradient. SDORE employs deep neural networks to minimize empirical risk with gradient norm regularization, allowing computation of the gradient norm on unlabeled data. We conduct a comprehensive analysis of the convergence rates of SDORE and establish a minimax optimal rate for the regression function. Crucially, we also derive a convergence rate for the associated plug-in gradient estimator, even in the presence of significant domain shift. These theoretical findings offer valuable prior guidance for selecting regularization parameters and determining the size of the neural network, while showcasing the provable advantage of leveraging unlabeled data in semi-supervised learning. To the best of our knowledge, SDORE is the first provable neural network-based approach that simultaneously estimates the regression function and its gradient, with diverse
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31283;&#23450;&#30340;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#25193;&#25955;&#26144;&#23556;&#19982;&#26391;&#20043;&#19975;&#21160;&#21147;&#23398;&#30456;&#32467;&#21512;&#65292;&#22312;&#20165;&#26377;&#26377;&#38480;&#25968;&#37327;&#30340;&#35757;&#32451;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#29983;&#25104;&#26032;&#26679;&#26412;&#65292;&#24182;&#35299;&#20915;&#20102;&#26102;&#38388;&#27493;&#38271;&#20725;&#30828;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#20013;&#30340;&#31283;&#23450;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2401.04372</link><description>&lt;p&gt;
&#20351;&#29992;&#25193;&#25955;&#26144;&#23556;&#36827;&#34892;&#31283;&#23450;&#30340;&#29983;&#25104;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Stable generative modeling using diffusion maps. (arXiv:2401.04372v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04372
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31283;&#23450;&#30340;&#29983;&#25104;&#24314;&#27169;&#26041;&#27861;&#65292;&#36890;&#36807;&#23558;&#25193;&#25955;&#26144;&#23556;&#19982;&#26391;&#20043;&#19975;&#21160;&#21147;&#23398;&#30456;&#32467;&#21512;&#65292;&#22312;&#20165;&#26377;&#26377;&#38480;&#25968;&#37327;&#30340;&#35757;&#32451;&#26679;&#26412;&#30340;&#24773;&#20917;&#19979;&#29983;&#25104;&#26032;&#26679;&#26412;&#65292;&#24182;&#35299;&#20915;&#20102;&#26102;&#38388;&#27493;&#38271;&#20725;&#30828;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#20013;&#30340;&#31283;&#23450;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20174;&#20165;&#26377;&#36275;&#22815;&#25968;&#37327;&#30340;&#35757;&#32451;&#26679;&#26412;&#21487;&#24471;&#21040;&#30340;&#26410;&#30693;&#20998;&#24067;&#20013;&#25277;&#26679;&#30340;&#38382;&#39064;&#12290;&#22312;&#29983;&#25104;&#24314;&#27169;&#30340;&#32972;&#26223;&#19979;&#65292;&#36825;&#26679;&#30340;&#35774;&#32622;&#26368;&#36817;&#24341;&#36215;&#20102;&#30456;&#24403;&#22823;&#30340;&#20851;&#27880;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#23558;&#25193;&#25955;&#26144;&#23556;&#21644;&#26391;&#20043;&#19975;&#21160;&#21147;&#23398;&#30456;&#32467;&#21512;&#30340;&#29983;&#25104;&#27169;&#22411;&#12290;&#25193;&#25955;&#26144;&#23556;&#29992;&#20110;&#20174;&#21487;&#29992;&#30340;&#35757;&#32451;&#26679;&#26412;&#20013;&#36817;&#20284;&#24471;&#21040;&#28418;&#31227;&#39033;&#65292;&#28982;&#21518;&#22312;&#31163;&#25955;&#26102;&#38388;&#30340;&#26391;&#20043;&#19975;&#37319;&#26679;&#22120;&#20013;&#23454;&#29616;&#29983;&#25104;&#26032;&#26679;&#26412;&#12290;&#36890;&#36807;&#23558;&#26680;&#24102;&#23485;&#35774;&#32622;&#20026;&#19982;&#26410;&#35843;&#25972;&#30340;&#26391;&#20043;&#19975;&#31639;&#27861;&#20013;&#20351;&#29992;&#30340;&#26102;&#38388;&#27493;&#38271;&#21305;&#37197;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#22320;&#36991;&#20813;&#36890;&#24120;&#19982;&#26102;&#38388;&#27493;&#38271;&#20725;&#30828;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30456;&#20851;&#30340;&#31283;&#23450;&#24615;&#38382;&#39064;&#12290;&#26356;&#20934;&#30830;&#22320;&#35828;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20998;&#35010;&#27493;&#39588;&#26041;&#26696;&#65292;&#30830;&#20445;&#29983;&#25104;&#30340;&#26679;&#26412;&#20445;&#25345;&#22312;&#35757;&#32451;&#26679;&#26412;&#30340;&#20984;&#21253;&#20869;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#21487;&#20197;&#33258;&#28982;&#22320;&#25193;&#23637;&#20026;&#29983;&#25104;&#26465;&#20214;&#26679;&#26412;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of sampling from an unknown distribution for which only a sufficiently large number of training samples are available. Such settings have recently drawn considerable interest in the context of generative modelling. In this paper, we propose a generative model combining diffusion maps and Langevin dynamics. Diffusion maps are used to approximate the drift term from the available training samples, which is then implemented in a discrete-time Langevin sampler to generate new samples. By setting the kernel bandwidth to match the time step size used in the unadjusted Langevin algorithm, our method effectively circumvents any stability issues typically associated with time-stepping stiff stochastic differential equations. More precisely, we introduce a novel split-step scheme, ensuring that the generated samples remain within the convex hull of the training samples. Our framework can be naturally extended to generate conditional samples. We demonstrate the performance
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25193;&#23637;&#20102;&#20043;&#21069;&#30340;&#32467;&#26524;&#65292;&#35777;&#26126;&#20102;&#22522;&#20110;&#23485;&#32780;&#28145;&#30340;ReLU&#31070;&#32463;&#32593;&#32476;&#21644;&#36923;&#36753;&#25439;&#22833;&#35757;&#32451;&#30340;&#20998;&#31867;&#35268;&#21017;&#20855;&#26377;&#26222;&#36866;&#19968;&#33268;&#24615;&#65292;&#24182;&#32473;&#20986;&#20102;&#19968;&#31867;&#27010;&#29575;&#27979;&#24230;&#26465;&#20214;&#19979;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#31867;&#22120;&#23454;&#29616;&#26497;&#23567;&#26497;&#38480;&#25910;&#25947;&#36895;&#29575;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2401.04286</link><description>&lt;p&gt;
&#23485;&#32780;&#28145;&#30340;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#26222;&#36866;&#19968;&#33268;&#24615;&#20197;&#21450;Kolmogorov-Donoho&#26368;&#20248;&#20989;&#25968;&#31867;&#30340;&#26497;&#23567;&#26497;&#38480;&#25910;&#25947;&#36895;&#29575;
&lt;/p&gt;
&lt;p&gt;
Universal Consistency of Wide and Deep ReLU Neural Networks and Minimax Optimal Convergence Rates for Kolmogorov-Donoho Optimal Function Classes. (arXiv:2401.04286v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04286
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25193;&#23637;&#20102;&#20043;&#21069;&#30340;&#32467;&#26524;&#65292;&#35777;&#26126;&#20102;&#22522;&#20110;&#23485;&#32780;&#28145;&#30340;ReLU&#31070;&#32463;&#32593;&#32476;&#21644;&#36923;&#36753;&#25439;&#22833;&#35757;&#32451;&#30340;&#20998;&#31867;&#35268;&#21017;&#20855;&#26377;&#26222;&#36866;&#19968;&#33268;&#24615;&#65292;&#24182;&#32473;&#20986;&#20102;&#19968;&#31867;&#27010;&#29575;&#27979;&#24230;&#26465;&#20214;&#19979;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#31867;&#22120;&#23454;&#29616;&#26497;&#23567;&#26497;&#38480;&#25910;&#25947;&#36895;&#29575;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#39318;&#20808;&#25193;&#23637;&#20102;FL93&#30340;&#32467;&#26524;&#65292;&#24182;&#35777;&#26126;&#20102;&#22522;&#20110;&#23485;&#32780;&#28145;&#30340;ReLU&#31070;&#32463;&#32593;&#32476;&#21644;&#36923;&#36753;&#25439;&#22833;&#35757;&#32451;&#30340;&#20998;&#31867;&#35268;&#21017;&#30340;&#26222;&#36866;&#19968;&#33268;&#24615;&#12290;&#19982;FL93&#20013;&#20998;&#35299;&#20272;&#35745;&#21644;&#32463;&#39564;&#35823;&#24046;&#30340;&#26041;&#27861;&#19981;&#21516;&#65292;&#25105;&#20204;&#26681;&#25454;&#19968;&#20010;&#24191;&#27867;&#30340;&#31070;&#32463;&#32593;&#32476;&#33021;&#22815;&#25554;&#20540;&#20219;&#24847;&#25968;&#37327;&#30340;&#28857;&#30340;&#35266;&#23519;&#65292;&#30452;&#25509;&#20998;&#26512;&#20998;&#31867;&#39118;&#38505;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#19968;&#31867;&#27010;&#29575;&#27979;&#24230;&#30340;&#20805;&#20998;&#26465;&#20214;&#65292;&#22312;&#36825;&#20123;&#26465;&#20214;&#19979;&#65292;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#20998;&#31867;&#22120;&#23454;&#29616;&#20102;&#26497;&#23567;&#26497;&#38480;&#25910;&#25947;&#36895;&#29575;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#28304;&#20110;&#23454;&#36341;&#32773;&#35266;&#23519;&#21040;&#31070;&#32463;&#32593;&#32476;&#36890;&#24120;&#34987;&#35757;&#32451;&#25104;&#36798;&#21040;0&#35757;&#32451;&#35823;&#24046;&#30340;&#20107;&#23454;&#65292;&#36825;&#20063;&#26159;&#25105;&#20204;&#25552;&#20986;&#30340;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#30340;&#24773;&#20917;&#12290;&#25105;&#20204;&#30340;&#35777;&#26126;&#20381;&#36182;&#20110;&#26368;&#36817;&#22312;&#32463;&#39564;&#39118;&#38505;&#26368;&#23567;&#21270;&#21644;&#28145;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#36924;&#36817;&#36895;&#29575;&#26041;&#38754;&#30340;&#21457;&#23637;&#65292;&#36866;&#29992;&#20110;&#19981;&#21516;&#30340;&#24863;&#20852;&#36259;&#20989;&#25968;&#31867;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we first extend the result of FL93 and prove universal consistency for a classification rule based on wide and deep ReLU neural networks trained on the logistic loss. Unlike the approach in FL93 that decomposes the estimation and empirical error, we directly analyze the classification risk based on the observation that a realization of a neural network that is wide enough is capable of interpolating an arbitrary number of points. Secondly, we give sufficient conditions for a class of probability measures under which classifiers based on neural networks achieve minimax optimal rates of convergence. Our result is motivated from the practitioner's observation that neural networks are often trained to achieve 0 training error, which is the case for our proposed neural network classifiers. Our proofs hinge on recent developments in empirical risk minimization and on approximation rates of deep ReLU neural networks for various function classes of interest. Applications to clas
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39044;&#27979;&#21160;&#24577;&#22270;&#32467;&#26500;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#26102;&#38388;&#24207;&#21015;&#26041;&#27861;&#39044;&#27979;&#26410;&#26469;&#26102;&#38388;&#28857;&#30340;&#33410;&#28857;&#24230;&#65292;&#24182;&#32467;&#21512;&#36890;&#37327;&#24179;&#34913;&#20998;&#26512;&#26041;&#27861;&#33719;&#24471;&#26410;&#26469;&#22270;&#30340;&#32467;&#26500;&#65292;&#35780;&#20272;&#20102;&#35813;&#26041;&#27861;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#29992;&#24615;&#21644;&#36866;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.04280</link><description>&lt;p&gt;
&#39044;&#27979;&#21160;&#24577;&#22270;&#30340;&#32467;&#26500;
&lt;/p&gt;
&lt;p&gt;
Predicting the structure of dynamic graphs. (arXiv:2401.04280v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.04280
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#39044;&#27979;&#21160;&#24577;&#22270;&#32467;&#26500;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#26102;&#38388;&#24207;&#21015;&#26041;&#27861;&#39044;&#27979;&#26410;&#26469;&#26102;&#38388;&#28857;&#30340;&#33410;&#28857;&#24230;&#65292;&#24182;&#32467;&#21512;&#36890;&#37327;&#24179;&#34913;&#20998;&#26512;&#26041;&#27861;&#33719;&#24471;&#26410;&#26469;&#22270;&#30340;&#32467;&#26500;&#65292;&#35780;&#20272;&#20102;&#35813;&#26041;&#27861;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#29992;&#24615;&#21644;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21160;&#24577;&#22270;&#23884;&#20837;&#12289;&#24402;&#32435;&#21644;&#22686;&#37327;&#23398;&#20064;&#26377;&#21161;&#20110;&#39044;&#27979;&#20219;&#21153;&#65292;&#22914;&#33410;&#28857;&#20998;&#31867;&#21644;&#38142;&#25509;&#39044;&#27979;&#12290;&#28982;&#32780;&#65292;&#20174;&#22270;&#30340;&#26102;&#38388;&#24207;&#21015;&#20013;&#39044;&#27979;&#26410;&#26469;&#26102;&#38388;&#27493;&#30340;&#22270;&#32467;&#26500;&#65292;&#20801;&#35768;&#26377;&#26032;&#33410;&#28857;&#65292;&#24182;&#27809;&#26377;&#21463;&#21040;&#22826;&#22810;&#20851;&#27880;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36825;&#26679;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#20351;&#29992;&#26102;&#38388;&#24207;&#21015;&#26041;&#27861;&#39044;&#27979;&#26410;&#26469;&#26102;&#38388;&#28857;&#30340;&#33410;&#28857;&#24230;&#65292;&#24182;&#23558;&#20854;&#19982;&#36890;&#37327;&#24179;&#34913;&#20998;&#26512;&#65288;&#19968;&#31181;&#22312;&#29983;&#29289;&#21270;&#23398;&#20013;&#20351;&#29992;&#30340;&#32447;&#24615;&#35268;&#21010;&#26041;&#27861;&#65289;&#32467;&#21512;&#36215;&#26469;&#65292;&#20197;&#33719;&#24471;&#26410;&#26469;&#22270;&#30340;&#32467;&#26500;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#19981;&#21516;&#21442;&#25968;&#20540;&#30340;&#39044;&#27979;&#22270;&#20998;&#24067;&#12290;&#25105;&#20204;&#20351;&#29992;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#35780;&#20272;&#20102;&#35813;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#23454;&#29992;&#24615;&#21644;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dynamic graph embeddings, inductive and incremental learning facilitate predictive tasks such as node classification and link prediction. However, predicting the structure of a graph at a future time step from a time series of graphs, allowing for new nodes has not gained much attention. In this paper, we present such an approach. We use time series methods to predict the node degree at future time points and combine it with flux balance analysis -- a linear programming method used in biochemistry -- to obtain the structure of future graphs. Furthermore, we explore the predictive graph distribution for different parameter values. We evaluate this method using synthetic and real datasets and demonstrate its utility and applicability.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#36890;&#36807;&#25968;&#25454;&#22810;&#26679;&#24615;&#27010;&#24565;&#26469;&#32479;&#19968;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#22522;&#20110;&#29256;&#26412;&#31354;&#38388;&#12289;&#27491;&#21017;&#21270;&#20248;&#21270;&#21644;&#21518;&#39564;&#37319;&#26679;&#30340;&#31639;&#27861;&#22312;&#26631;&#20934;&#20551;&#35774;&#19979;&#36798;&#21040;&#20102;&#21487;&#27604;&#30340;&#26679;&#26412;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2401.03301</link><description>&lt;p&gt;
&#22312;&#26679;&#26412;&#39640;&#25928;&#30340;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20013;&#65306;&#25968;&#25454;&#22810;&#26679;&#24615;&#12289;&#21518;&#39564;&#37319;&#26679;&#65292;&#20197;&#21450;&#26356;&#22810;
&lt;/p&gt;
&lt;p&gt;
On Sample-Efficient Offline Reinforcement Learning: Data Diversity, Posterior Sampling, and Beyond. (arXiv:2401.03301v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.03301
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#36890;&#36807;&#25968;&#25454;&#22810;&#26679;&#24615;&#27010;&#24565;&#26469;&#32479;&#19968;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#22522;&#20110;&#29256;&#26412;&#31354;&#38388;&#12289;&#27491;&#21017;&#21270;&#20248;&#21270;&#21644;&#21518;&#39564;&#37319;&#26679;&#30340;&#31639;&#27861;&#22312;&#26631;&#20934;&#20551;&#35774;&#19979;&#36798;&#21040;&#20102;&#21487;&#27604;&#30340;&#26679;&#26412;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35797;&#22270;&#29702;&#35299;&#20160;&#20040;&#20419;&#36827;&#20102;&#23545;&#20110;&#24207;&#36125;&#21494;&#26031;&#20915;&#31574;&#30340;&#21382;&#21490;&#25968;&#25454;&#38598;&#36827;&#34892;&#26679;&#26412;&#39640;&#25928;&#23398;&#20064;&#65292;&#36825;&#20010;&#38382;&#39064;&#36890;&#24120;&#34987;&#31216;&#20026;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23545;&#20110;&#22312;&#21033;&#29992;&#65288;&#20540;&#65289;&#20989;&#25968;&#36924;&#36817;&#30340;&#21516;&#26102;&#20139;&#21463;&#26679;&#26412;&#25928;&#29575;&#30340;&#31639;&#27861;&#24863;&#20852;&#36259;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#19968;&#20010;&#21253;&#25324;&#31163;&#32447;RL&#20013;&#35206;&#30422;&#24230;&#37327;&#30340;&#20808;&#21069;&#27010;&#24565;&#30340;&#25968;&#25454;&#22810;&#26679;&#24615;&#27010;&#24565;&#26469;&#35299;&#20915;&#36825;&#20123;&#22522;&#26412;&#38382;&#39064;&#65292;&#24182;&#19988;&#21033;&#29992;&#36825;&#20010;&#27010;&#24565;&#23558;&#22522;&#20110;&#29256;&#26412;&#31354;&#38388;&#65288;VS&#65289;&#12289;&#27491;&#21017;&#21270;&#20248;&#21270;&#65288;RO&#65289;&#21644;&#21518;&#39564;&#37319;&#26679;&#65288;PS&#65289;&#30340;&#19977;&#20010;&#19981;&#21516;&#31867;&#21035;&#30340;&#31163;&#32447;RL&#31639;&#27861;&#36827;&#34892;&#32479;&#19968;&#12290;&#25105;&#20204;&#22312;&#26631;&#20934;&#20551;&#35774;&#19979;&#35777;&#26126;&#65292;&#22522;&#20110;VS&#12289;&#22522;&#20110;RO&#21644;&#22522;&#20110;PS&#30340;&#31639;&#27861;&#36798;&#21040;&#20102;\emph{&#21487;&#27604;}&#30340;&#26679;&#26412;&#25928;&#29575;&#65292;&#36825;&#24674;&#22797;&#20102;&#22312;&#26377;&#38480;&#21644;&#32447;&#24615;&#27169;&#22411;&#31867;&#21035;&#19979;&#30340;&#26368;&#20248;&#24615;&#30340;&#26631;&#20934;&#20551;&#35774;&#30340;&#36793;&#30028;&#12290;&#36825;&#20010;&#32467;&#26524;&#20196;&#20154;&#24778;&#35766;&#65292;&#22240;&#20026;&#20043;&#21069;&#30340;&#30740;&#31350;&#34920;&#26126;&#36825;&#20123;&#31639;&#27861;&#19981;&#20855;&#26377;&#26377;&#21033;&#24615;&#30340;&#26679;&#26412;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
We seek to understand what facilitates sample-efficient learning from historical datasets for sequential decision-making, a problem that is popularly known as offline reinforcement learning (RL). Further, we are interested in algorithms that enjoy sample efficiency while leveraging (value) function approximation. In this paper, we address these fundamental questions by (i) proposing a notion of data diversity that subsumes the previous notions of coverage measures in offline RL and (ii) using this notion to {unify} three distinct classes of offline RL algorithms based on version spaces (VS), regularized optimization (RO), and posterior sampling (PS). We establish that VS-based, RO-based, and PS-based algorithms, under standard assumptions, achieve \emph{comparable} sample efficiency, which recovers the state-of-the-art sub-optimality bounds for finite and linear model classes with the standard assumptions. This result is surprising, given that the prior work suggested an unfavorable sa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21551;&#21457;&#24335;&#26041;&#27861;&#65292;&#26681;&#25454;&#25191;&#34892;&#26102;&#38388;&#21464;&#24322;&#24615;&#20026;&#27599;&#20010;&#20302;&#20851;&#38190;&#23454;&#26102;&#20219;&#21153;&#20998;&#37197;&#25191;&#34892;&#26102;&#38388;&#39044;&#31639;&#65292;&#38477;&#20302;&#20102;&#36229;&#20986;&#39044;&#31639;&#30340;&#27010;&#29575;&#12290;</title><link>http://arxiv.org/abs/2401.02431</link><description>&lt;p&gt;
&#25191;&#34892;&#26102;&#38388;&#39044;&#31639;&#20998;&#37197;&#22312;&#28151;&#21512;&#20851;&#38190;&#31995;&#32479;&#20013;
&lt;/p&gt;
&lt;p&gt;
Execution time budget assignment for mixed criticality systems. (arXiv:2401.02431v2 [cs.PF] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.02431
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21551;&#21457;&#24335;&#26041;&#27861;&#65292;&#26681;&#25454;&#25191;&#34892;&#26102;&#38388;&#21464;&#24322;&#24615;&#20026;&#27599;&#20010;&#20302;&#20851;&#38190;&#23454;&#26102;&#20219;&#21153;&#20998;&#37197;&#25191;&#34892;&#26102;&#38388;&#39044;&#31639;&#65292;&#38477;&#20302;&#20102;&#36229;&#20986;&#39044;&#31639;&#30340;&#27010;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#32479;&#35745;&#31163;&#25955;&#21442;&#25968;&#26469;&#37327;&#21270;&#31243;&#24207;&#30340;&#25191;&#34892;&#26102;&#38388;&#21464;&#24322;&#24615;&#65292;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#22312;&#28151;&#21512;&#20851;&#38190;&#23454;&#26102;&#31995;&#32479;&#20013;&#21033;&#29992;&#25191;&#34892;&#26102;&#38388;&#21464;&#24322;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21551;&#21457;&#24335;&#26041;&#27861;&#65292;&#26681;&#25454;&#25191;&#34892;&#26102;&#38388;&#21464;&#24322;&#24615;&#20026;&#27599;&#20010;&#20302;&#20851;&#38190;&#23454;&#26102;&#20219;&#21153;&#20998;&#37197;&#25191;&#34892;&#26102;&#38388;&#39044;&#31639;&#12290;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#65292;&#19982;&#19981;&#32771;&#34385;&#25191;&#34892;&#26102;&#38388;&#21464;&#24322;&#24615;&#21442;&#25968;&#30340;&#31639;&#27861;&#30456;&#27604;&#65292;&#25152;&#25552;&#20986;&#30340;&#21551;&#21457;&#24335;&#26041;&#27861;&#38477;&#20302;&#20102;&#36229;&#20986;&#20998;&#37197;&#39044;&#31639;&#30340;&#27010;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we propose to quantify execution time variability of programs using statistical dispersion parameters. We show how the execution time variability can be exploited in mixed criticality real-time systems. We propose a heuristic to compute the execution time budget to be allocated to each low criticality real-time task according to its execution time variability. We show using experiments and simulations that the proposed heuristic reduces the probability of exceeding the allocated budget compared to algorithms which do not take into account the execution time variability parameter.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20351;&#29992;&#27169;&#25311;&#25512;&#26029;&#26041;&#27861;&#32467;&#21512;&#33033;&#20914;&#26143;&#31181;&#32676;&#21512;&#25104;&#65292;&#26469;&#38480;&#21046;&#23396;&#31435;&#38134;&#27827;&#23556;&#30005;&#33033;&#20914;&#26143;&#30340;&#30913;&#26059;&#36716;&#29305;&#24615;&#12290;</title><link>http://arxiv.org/abs/2312.14848</link><description>&lt;p&gt;
&#29992;&#22522;&#20110;&#27169;&#25311;&#25512;&#26029;&#30340;&#23396;&#31435;&#33033;&#20914;&#26143;&#31181;&#32676;&#21512;&#25104;
&lt;/p&gt;
&lt;p&gt;
Isolated pulsar population synthesis with simulation-based inference. (arXiv:2312.14848v1 [astro-ph.HE] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.14848
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20351;&#29992;&#27169;&#25311;&#25512;&#26029;&#26041;&#27861;&#32467;&#21512;&#33033;&#20914;&#26143;&#31181;&#32676;&#21512;&#25104;&#65292;&#26469;&#38480;&#21046;&#23396;&#31435;&#38134;&#27827;&#23556;&#30005;&#33033;&#20914;&#26143;&#30340;&#30913;&#26059;&#36716;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23558;&#33033;&#20914;&#26143;&#31181;&#32676;&#21512;&#25104;&#19982;&#22522;&#20110;&#27169;&#25311;&#25512;&#26029;&#30456;&#32467;&#21512;&#65292;&#20197;&#38480;&#21046;&#23396;&#31435;&#38134;&#27827;&#23556;&#30005;&#33033;&#20914;&#26143;&#30340;&#30913;&#26059;&#36716;&#29305;&#24615;&#12290;&#25105;&#20204;&#39318;&#20808;&#26500;&#24314;&#20102;&#19968;&#20010;&#28789;&#27963;&#30340;&#26694;&#26550;&#26469;&#27169;&#25311;&#20013;&#23376;&#26143;&#30340;&#35806;&#29983;&#29305;&#24615;&#21644;&#28436;&#21270;&#65292;&#37325;&#28857;&#26159;&#23427;&#20204;&#30340;&#21160;&#21147;&#23398;&#12289;&#26059;&#36716;&#21644;&#30913;&#24615;&#29305;&#24449;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#20174;&#23545;&#25968;&#27491;&#24577;&#20998;&#24067;&#20013;&#37319;&#26679;&#21021;&#22987;&#30913;&#22330;&#24378;&#24230;B&#21644;&#33258;&#36716;&#21608;&#26399;P&#65292;&#24182;&#29992;&#24130;&#24459;&#26469;&#25429;&#25417;&#21518;&#26399;&#30913;&#22330;&#30340;&#34928;&#20943;&#12290;&#27599;&#20010;&#23545;&#25968;&#27491;&#24577;&#20998;&#24067;&#30001;&#22343;&#20540;&#956;logB&#65292;&#956;logP&#21644;&#26631;&#20934;&#24046;&#963;logB&#65292;&#963;logP&#25551;&#36848;&#65292;&#32780;&#24130;&#24459;&#30001;&#25351;&#25968;a_late&#25551;&#36848;&#65292;&#20849;&#35745;&#20116;&#20010;&#33258;&#30001;&#21442;&#25968;&#12290;&#28982;&#21518;&#25105;&#20204;&#27169;&#25311;&#20102;&#26143;&#20307;&#30340;&#23556;&#30005;&#21457;&#23556;&#21644;&#35266;&#27979;&#20559;&#24046;&#65292;&#20197;&#27169;&#25311;&#19977;&#20010;&#23556;&#30005;&#35843;&#26597;&#20013;&#30340;&#25506;&#27979;&#65292;&#24182;&#36890;&#36807;&#25913;&#21464;&#36755;&#20837;&#21442;&#25968;&#20135;&#29983;&#20102;&#19968;&#20010;&#22823;&#22411;&#30340;&#21512;&#25104;P-&#7766;&#22270;&#25968;&#25454;&#24211;&#12290;&#25509;&#30528;&#25105;&#20204;&#37319;&#29992;&#22522;&#20110;&#27169;&#25311;&#25512;&#26029;&#30340;&#26041;&#27861;&#36827;&#34892;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
We combine pulsar population synthesis with simulation-based inference to constrain the magneto-rotational properties of isolated Galactic radio pulsars. We first develop a flexible framework to model neutron-star birth properties and evolution, focusing on their dynamical, rotational and magnetic characteristics. In particular, we sample initial magnetic-field strengths, $B$, and spin periods, $P$, from log-normal distributions and capture the late-time magnetic-field decay with a power law. Each log-normal is described by a mean, $\mu_{\log B}, \mu_{\log P}$, and standard deviation, $\sigma_{\log B}, \sigma_{\log P}$, while the power law is characterized by the index, $a_{\rm late}$, resulting in five free parameters. We subsequently model the stars' radio emission and observational biases to mimic detections with three radio surveys, and produce a large database of synthetic $P$-$\dot{P}$ diagrams by varying our input parameters. We then follow a simulation-based inference approach 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#24102;&#26377;&#26080;&#30028;&#26041;&#24046;&#30340;&#26377;&#20559;&#22122;&#22768;&#23545;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#30340;&#24433;&#21709;&#65292;&#24182;&#20171;&#32461;&#20102;&#35813;&#31639;&#27861;&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2312.02828</link><description>&lt;p&gt;
&#38543;&#26426;&#36924;&#36817;&#30340;&#25910;&#25947;&#36895;&#24230;&#65306;&#24102;&#26377;&#26080;&#30028;&#26041;&#24046;&#30340;&#26377;&#20559;&#22122;&#22768;&#21644;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Convergence Rates for Stochastic Approximation: Biased Noise with Unbounded Variance, and Applications. (arXiv:2312.02828v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2312.02828
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#24102;&#26377;&#26080;&#30028;&#26041;&#24046;&#30340;&#26377;&#20559;&#22122;&#22768;&#23545;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#30340;&#25910;&#25947;&#36895;&#24230;&#30340;&#24433;&#21709;&#65292;&#24182;&#20171;&#32461;&#20102;&#35813;&#31639;&#27861;&#22312;&#21508;&#20010;&#39046;&#22495;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
1951&#24180;&#32599;&#23486;&#26031;&#21644;&#33707;&#27931;&#24341;&#20837;&#30340;&#38543;&#26426;&#36924;&#36817;&#65288;SA&#65289;&#31639;&#27861;&#24050;&#32463;&#25104;&#20026;&#35299;&#26041;&#31243;$\mathbf{f}({\boldsymbol{\theta}}) = \mathbf{0}$&#30340;&#26631;&#20934;&#26041;&#27861;&#65292;&#24403;&#21482;&#26377;$\mathbf{f}(\cdot)$&#30340;&#24102;&#22122;&#22768;&#27979;&#37327;&#21487;&#29992;&#26102;&#12290;&#22914;&#26524;&#23545;&#20110;&#26576;&#20010;&#20989;&#25968;$J(\cdot)$&#65292;$\mathbf{f}({\boldsymbol{\theta}}) = \nabla J({\boldsymbol{\theta}})$&#65292;&#37027;&#20040;SA&#20063;&#21487;&#20197;&#29992;&#26469;&#23547;&#25214;$J(\cdot)$&#30340;&#19968;&#20010;&#31283;&#23450;&#28857;&#12290;&#22312;&#27599;&#20010;&#26102;&#38388;$t$&#65292;&#24403;&#21069;&#30340;&#29468;&#27979;${\boldsymbol{\theta}}_t$&#36890;&#36807;&#24418;&#24335;&#20026;$\mathbf{f}({\boldsymbol{\theta}}_t) + {\boldsymbol{\xi}}_{t+1}$&#30340;&#24102;&#22122;&#22768;&#27979;&#37327;&#26356;&#26032;&#20026;${\boldsymbol{\theta}}_{t+1}$&#12290;&#22312;&#35768;&#22810;&#25991;&#29486;&#20013;&#65292;&#20551;&#35774;&#35823;&#24046;&#39033;${\boldsymbol{\xi}}_{t+1}$&#30340;&#26465;&#20214;&#22343;&#20540;&#20026;&#38646;&#65292;&#21644;/&#25110;&#32773;&#23427;&#30340;&#26465;&#20214;&#26041;&#24046;&#38543;$t$&#65288;&#32780;&#19981;&#26159;${\boldsymbol{\theta}}_t$&#65289;&#34987;&#38480;&#21046;&#12290;&#22810;&#24180;&#26469;&#65292;SA&#24050;&#32463;&#24212;&#29992;&#20110;&#21508;&#31181;&#39046;&#22495;&#65292;&#26412;&#25991;&#37325;&#28857;&#30740;&#31350;&#20854;&#20013;&#19968;&#20010;&#39046;&#22495;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Stochastic Approximation (SA) algorithm introduced by Robbins and Monro in 1951 has been a standard method for solving equations of the form $\mathbf{f}({\boldsymbol {\theta}}) = \mathbf{0}$, when only noisy measurements of $\mathbf{f}(\cdot)$ are available. If $\mathbf{f}({\boldsymbol {\theta}}) = \nabla J({\boldsymbol {\theta}})$ for some function $J(\cdot)$, then SA can also be used to find a stationary point of $J(\cdot)$. At each time $t$, the current guess ${\boldsymbol {\theta}}_t$ is updated to ${\boldsymbol {\theta}}_{t+1}$ using a noisy measurement of the form $\mathbf{f}({\boldsymbol {\theta}}_t) + {\boldsymbol {\xi}}_{t+1}$. In much of the literature, it is assumed that the error term ${\boldsymbol {\xi}}_{t+1}$ has zero conditional mean, and/or that its conditional variance is bounded as a function of $t$ (though not necessarily with respect to ${\boldsymbol {\theta}}_t$). Over the years, SA has been applied to a variety of areas, out of which the focus in this paper i
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20998;&#24067;&#26694;&#26550;&#65292;&#29992;&#20110;&#35780;&#20272;&#20855;&#26377;&#32479;&#35745;&#26174;&#33879;&#24615;&#30340;&#22522;&#30784;&#27169;&#22411;&#30340;&#39118;&#38505;&#12290;&#36890;&#36807;&#19968;&#31181;&#26032;&#30340;&#32479;&#35745;&#30456;&#23545;&#27979;&#35797;&#26041;&#27861;&#65292;&#35813;&#26694;&#26550;&#32467;&#21512;&#20102;&#19968;&#38454;&#21644;&#20108;&#38454;&#38543;&#26426;&#20248;&#21183;&#65292;&#24182;&#20511;&#37492;&#20102;&#35745;&#37327;&#32463;&#27982;&#23398;&#21644;&#25968;&#23398;&#37329;&#34701;&#20013;&#24120;&#29992;&#30340;&#24179;&#22343;&#39118;&#38505;&#27169;&#22411;&#12290;&#22312;&#32473;&#23450;&#25351;&#23450;&#24230;&#37327;&#37327;&#21270;&#30340;&#38450;&#25252;&#26639;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#39118;&#38505;&#24847;&#35782;&#30340;&#22522;&#30784;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#12290;&#21463;&#25968;&#23398;&#37329;&#34701;&#20013;&#30340;&#25237;&#36164;&#32452;&#21512;&#20248;&#21270;&#21644;&#36873;&#25321;&#29702;&#35770;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#20026;&#27599;&#20010;&#27169;&#22411;&#23450;&#20041;&#20102;&#19968;&#20010;"&#24230;&#37327;&#32452;&#21512;"&#65292;&#24182;&#26681;&#25454;&#36825;&#20123;&#32452;&#21512;&#30340;&#38543;&#26426;&#20248;&#21183;&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;&#12290;</title><link>http://arxiv.org/abs/2310.07132</link><description>&lt;p&gt;
&#22312;&#22522;&#30784;&#27169;&#22411;&#26102;&#20195;&#30340;&#39118;&#38505;&#35780;&#20272;&#21644;&#32479;&#35745;&#26174;&#33879;&#24615;
&lt;/p&gt;
&lt;p&gt;
Risk Assessment and Statistical Significance in the Age of Foundation Models. (arXiv:2310.07132v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.07132
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20998;&#24067;&#26694;&#26550;&#65292;&#29992;&#20110;&#35780;&#20272;&#20855;&#26377;&#32479;&#35745;&#26174;&#33879;&#24615;&#30340;&#22522;&#30784;&#27169;&#22411;&#30340;&#39118;&#38505;&#12290;&#36890;&#36807;&#19968;&#31181;&#26032;&#30340;&#32479;&#35745;&#30456;&#23545;&#27979;&#35797;&#26041;&#27861;&#65292;&#35813;&#26694;&#26550;&#32467;&#21512;&#20102;&#19968;&#38454;&#21644;&#20108;&#38454;&#38543;&#26426;&#20248;&#21183;&#65292;&#24182;&#20511;&#37492;&#20102;&#35745;&#37327;&#32463;&#27982;&#23398;&#21644;&#25968;&#23398;&#37329;&#34701;&#20013;&#24120;&#29992;&#30340;&#24179;&#22343;&#39118;&#38505;&#27169;&#22411;&#12290;&#22312;&#32473;&#23450;&#25351;&#23450;&#24230;&#37327;&#37327;&#21270;&#30340;&#38450;&#25252;&#26639;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#39118;&#38505;&#24847;&#35782;&#30340;&#22522;&#30784;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#12290;&#21463;&#25968;&#23398;&#37329;&#34701;&#20013;&#30340;&#25237;&#36164;&#32452;&#21512;&#20248;&#21270;&#21644;&#36873;&#25321;&#29702;&#35770;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#20026;&#27599;&#20010;&#27169;&#22411;&#23450;&#20041;&#20102;&#19968;&#20010;"&#24230;&#37327;&#32452;&#21512;"&#65292;&#24182;&#26681;&#25454;&#36825;&#20123;&#32452;&#21512;&#30340;&#38543;&#26426;&#20248;&#21183;&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#20998;&#24067;&#26694;&#26550;&#65292;&#29992;&#20110;&#35780;&#20272;&#20855;&#26377;&#32479;&#35745;&#26174;&#33879;&#24615;&#30340;&#22522;&#30784;&#27169;&#22411;&#30340;&#31038;&#20250;&#25216;&#26415;&#39118;&#38505;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20381;&#36182;&#20110;&#19968;&#31181;&#22522;&#20110;&#23454;&#38469;&#38543;&#26426;&#21464;&#37327;&#30340;&#19968;&#38454;&#21644;&#20108;&#38454;&#38543;&#26426;&#20248;&#21183;&#30340;&#26032;&#30340;&#32479;&#35745;&#30456;&#23545;&#27979;&#35797;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#36825;&#20010;&#27979;&#35797;&#20013;&#30340;&#20108;&#38454;&#32479;&#35745;&#19982;&#22312;&#35745;&#37327;&#32463;&#27982;&#23398;&#21644;&#25968;&#23398;&#37329;&#34701;&#20013;&#24120;&#29992;&#30340;&#24179;&#22343;&#39118;&#38505;&#27169;&#22411;&#30456;&#32852;&#31995;&#65292;&#29992;&#20110;&#22312;&#36873;&#25321;&#26041;&#26696;&#26102;&#24179;&#34913;&#39118;&#38505;&#21644;&#25928;&#29992;&#12290;&#21033;&#29992;&#36825;&#20010;&#26694;&#26550;&#65292;&#25105;&#20204;&#27491;&#24335;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#39118;&#38505;&#24847;&#35782;&#30340;&#22522;&#30784;&#27169;&#22411;&#36873;&#25321;&#26041;&#27861;&#65292;&#32473;&#23450;&#30001;&#25351;&#23450;&#24230;&#37327;&#37327;&#21270;&#30340;&#38450;&#25252;&#26639;&#12290;&#21463;&#25968;&#23398;&#37329;&#34701;&#20013;&#30340;&#25237;&#36164;&#32452;&#21512;&#20248;&#21270;&#21644;&#36873;&#25321;&#29702;&#35770;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#20026;&#27599;&#20010;&#27169;&#22411;&#23450;&#20041;&#20102;&#19968;&#20010;"&#24230;&#37327;&#32452;&#21512;"&#65292;&#20316;&#20026;&#32858;&#21512;&#19968;&#31995;&#21015;&#24230;&#37327;&#30340;&#25163;&#27573;&#65292;&#24182;&#26681;&#25454;&#36825;&#20123;&#32452;&#21512;&#30340;&#38543;&#26426;&#20248;&#21183;&#36827;&#34892;&#27169;&#22411;&#36873;&#25321;&#12290;&#25105;&#20204;&#30340;&#27979;&#35797;&#30340;&#32479;&#35745;&#26174;&#33879;&#24615;&#22312;&#29702;&#35770;&#19978;&#30001;&#36890;&#36807;&#20013;&#24515;&#26497;&#38480;&#30340;&#28176;&#36817;&#20998;&#26512;&#25903;&#25345;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a distributional framework for assessing socio-technical risks of foundation models with quantified statistical significance. Our approach hinges on a new statistical relative testing based on first and second order stochastic dominance of real random variables. We show that the second order statistics in this test are linked to mean-risk models commonly used in econometrics and mathematical finance to balance risk and utility when choosing between alternatives. Using this framework, we formally develop a risk-aware approach for foundation model selection given guardrails quantified by specified metrics. Inspired by portfolio optimization and selection theory in mathematical finance, we define a \emph{metrics portfolio} for each model as a means to aggregate a collection of metrics, and perform model selection based on the stochastic dominance of these portfolios. The statistical significance of our tests is backed theoretically by an asymptotic analysis via central limit th
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#36890;&#20449;&#29702;&#35770;&#20013;&#32467;&#21512;&#27880;&#24847;&#21147;&#21644;&#30456;&#23545;&#29109;&#30340;&#27010;&#24565;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#36890;&#20449;&#20013;&#20351;&#29992;&#27880;&#24847;&#21147;&#23548;&#21521;&#30340;&#21152;&#26435;&#30456;&#23545;&#29109;&#26159;&#19981;&#36866;&#24403;&#30340;&#65292;&#32780;&#36866;&#24403;&#30340;&#27880;&#24847;&#21147;&#36890;&#20449;&#21487;&#36890;&#36807;&#21457;&#36865;&#32773;&#20165;&#38656;&#35201;&#20102;&#35299;&#25509;&#25910;&#32773;&#30340;&#25928;&#29992;&#20989;&#25968;&#26469;&#23454;&#29616;&#26368;&#20339;&#36890;&#30693;&#12290;</title><link>http://arxiv.org/abs/2307.11423</link><description>&lt;p&gt;
&#27880;&#24847;&#21147;&#23545;&#29109;&#36890;&#20449;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Attention to Entropic Communication. (arXiv:2307.11423v1 [cs.IT])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.11423
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22312;&#36890;&#20449;&#29702;&#35770;&#20013;&#32467;&#21512;&#27880;&#24847;&#21147;&#21644;&#30456;&#23545;&#29109;&#30340;&#27010;&#24565;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#36890;&#20449;&#20013;&#20351;&#29992;&#27880;&#24847;&#21147;&#23548;&#21521;&#30340;&#21152;&#26435;&#30456;&#23545;&#29109;&#26159;&#19981;&#36866;&#24403;&#30340;&#65292;&#32780;&#36866;&#24403;&#30340;&#27880;&#24847;&#21147;&#36890;&#20449;&#21487;&#36890;&#36807;&#21457;&#36865;&#32773;&#20165;&#38656;&#35201;&#20102;&#35299;&#25509;&#25910;&#32773;&#30340;&#25928;&#29992;&#20989;&#25968;&#26469;&#23454;&#29616;&#26368;&#20339;&#36890;&#30693;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27880;&#24847;&#21147;&#30340;&#27010;&#24565;&#26159;&#25351;&#22312;&#20154;&#24037;&#26234;&#33021;&#20013;&#24378;&#35843;&#29305;&#23450;&#25968;&#25454;&#37325;&#35201;&#24615;&#30340;&#25968;&#20540;&#26435;&#37325;&#65292;&#22312;&#36890;&#20449;&#29702;&#35770;&#20013;&#30456;&#23545;&#29109;&#65288;RE&#65292;&#20063;&#31216;&#20026;&#24211;&#23572;&#24052;&#20811;-&#21202;&#24067;&#21202;&#25955;&#24230;&#65289;&#21457;&#25381;&#30528;&#26680;&#24515;&#20316;&#29992;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#32467;&#21512;&#20102;&#36825;&#20123;&#27010;&#24565;&#65292;&#21363;&#27880;&#24847;&#21147;&#21644;RE&#12290;RE&#24341;&#23548;&#24102;&#23485;&#26377;&#38480;&#36890;&#20449;&#20013;&#30340;&#26368;&#20339;&#32534;&#30721;&#20197;&#21450;&#36890;&#36807;&#26368;&#22823;&#29109;&#21407;&#29702;&#65288;MEP&#65289;&#36827;&#34892;&#26368;&#20339;&#28040;&#24687;&#35299;&#30721;&#12290;&#22312;&#32534;&#30721;&#22330;&#26223;&#20013;&#65292;RE&#21487;&#20197;&#20174;&#22235;&#20010;&#35201;&#27714;&#20013;&#25512;&#23548;&#20986;&#26469;&#65292;&#21363;&#20998;&#26512;&#24615;&#12289;&#23616;&#37096;&#24615;&#12289;&#36866;&#24403;&#24615;&#21644;&#26657;&#20934;&#24615;&#12290;&#32780;&#29992;&#20110;&#36890;&#20449;&#20013;&#27880;&#24847;&#21147;&#23548;&#21521;&#30340;&#21152;&#26435;RE&#23454;&#38469;&#19978;&#26159;&#19981;&#36866;&#24403;&#30340;&#12290;&#20026;&#20102;&#30475;&#21040;&#36866;&#24403;&#30340;&#27880;&#24847;&#21147;&#36890;&#20449;&#26159;&#22914;&#20309;&#20986;&#29616;&#30340;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#19968;&#20010;&#22330;&#26223;&#65292;&#21363;&#28040;&#24687;&#21457;&#36865;&#32773;&#24076;&#26395;&#30830;&#20445;&#25509;&#25910;&#32773;&#33021;&#22815;&#25191;&#34892;&#30693;&#24773;&#30340;&#25805;&#20316;&#12290;&#22914;&#26524;&#25509;&#25910;&#32773;&#20351;&#29992;MEP&#35299;&#30721;&#28040;&#24687;&#65292;&#21017;&#21457;&#36865;&#32773;&#21482;&#38656;&#35201;&#30693;&#36947;&#25509;&#25910;&#32773;&#30340;&#25928;&#29992;&#20989;&#25968;&#26469;&#36827;&#34892;&#26368;&#20339;&#36890;&#30693;&#65292;&#19981;&#38656;&#35201;&#30693;&#36947;&#25509;&#25910;&#32773;&#30340;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
The concept of attention, numerical weights that emphasize the importance of particular data, has proven to be very relevant in artificial intelligence. Relative entropy (RE, aka Kullback-Leibler divergence) plays a central role in communication theory. Here we combine these concepts, attention and RE. RE guides optimal encoding of messages in bandwidth-limited communication as well as optimal message decoding via the maximum entropy principle (MEP). In the coding scenario, RE can be derived from four requirements, namely being analytical, local, proper, and calibrated. Weighted RE, used for attention steering in communications, turns out to be improper. To see how proper attention communication can emerge, we analyze a scenario of a message sender who wants to ensure that the receiver of the message can perform well-informed actions. If the receiver decodes the message using the MEP, the sender only needs to know the receiver's utility function to inform optimally, but not the receive
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#37325;&#26032;&#25512;&#23548;&#20102;&#22312;&#32447; Laplace &#26041;&#27861;&#65292;&#24182;&#23558;&#20854;&#30446;&#26631;&#23450;&#20301;&#20026;&#27169;&#24577;&#20462;&#27491;&#30340;&#21464;&#20998;&#19978;&#30028;&#65292;&#36991;&#20813;&#20102;&#23545;&#24179;&#31283;&#24615;&#30340;&#20551;&#35774;&#12290;&#36890;&#36807;&#20351;&#29992;&#20840;&#25209;&#37327;&#26799;&#24230;&#30340;&#22312;&#32447;&#31639;&#27861;&#65292;&#25105;&#20204;&#28436;&#31034;&#20102;&#22312;&#23454;&#36341;&#20013;&#23454;&#29616;&#20102;&#36825;&#20123;&#26368;&#20248;&#28857;&#65292;&#24182;&#39564;&#35777;&#20102;&#20854;&#36866;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2307.06093</link><description>&lt;p&gt;
&#22312;&#32447; Laplace &#27169;&#22411;&#36873;&#25321;&#30340;&#20877;&#25506;&#35752;
&lt;/p&gt;
&lt;p&gt;
Online Laplace Model Selection Revisited. (arXiv:2307.06093v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.06093
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#37325;&#26032;&#25512;&#23548;&#20102;&#22312;&#32447; Laplace &#26041;&#27861;&#65292;&#24182;&#23558;&#20854;&#30446;&#26631;&#23450;&#20301;&#20026;&#27169;&#24577;&#20462;&#27491;&#30340;&#21464;&#20998;&#19978;&#30028;&#65292;&#36991;&#20813;&#20102;&#23545;&#24179;&#31283;&#24615;&#30340;&#20551;&#35774;&#12290;&#36890;&#36807;&#20351;&#29992;&#20840;&#25209;&#37327;&#26799;&#24230;&#30340;&#22312;&#32447;&#31639;&#27861;&#65292;&#25105;&#20204;&#28436;&#31034;&#20102;&#22312;&#23454;&#36341;&#20013;&#23454;&#29616;&#20102;&#36825;&#20123;&#26368;&#20248;&#28857;&#65292;&#24182;&#39564;&#35777;&#20102;&#20854;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Laplace &#36817;&#20284;&#20026;&#31070;&#32463;&#32593;&#32476;&#25552;&#20379;&#20102;&#19968;&#20010;&#23553;&#38381;&#24418;&#24335;&#30340;&#27169;&#22411;&#36873;&#25321;&#30446;&#26631;&#12290;&#22312;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;&#39046;&#22495;&#65292;&#23558;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#19982;&#36229;&#21442;&#25968;&#65288;&#22914;&#26435;&#37325;&#34928;&#20943;&#24378;&#24230;&#65289;&#19968;&#36215;&#36827;&#34892;&#20248;&#21270;&#30340;&#22312;&#32447;&#21464;&#20307;&#26041;&#27861;&#20877;&#27425;&#24341;&#36215;&#20102;&#20154;&#20204;&#30340;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#36829;&#21453;&#20102; Laplace &#26041;&#27861;&#30340;&#19968;&#20010;&#20851;&#38190;&#20551;&#35774;&#65292;&#21363;&#36817;&#20284;&#26159;&#22260;&#32469;&#25439;&#22833;&#30340;&#27169;&#24577;&#36827;&#34892;&#30340;&#65292;&#36825;&#23601;&#23545;&#23427;&#20204;&#30340;&#21512;&#29702;&#24615;&#25552;&#20986;&#20102;&#36136;&#30097;&#12290;&#26412;&#30740;&#31350;&#37325;&#26032;&#25512;&#23548;&#20102;&#22312;&#32447; Laplace &#26041;&#27861;&#65292;&#23637;&#31034;&#20102;&#23427;&#20204;&#38024;&#23545; Laplace &#35777;&#25454;&#30340;&#19968;&#20010;&#20462;&#27491;&#27169;&#24577;&#30340;&#21464;&#20998;&#19978;&#30028;&#65292;&#20174;&#32780;&#36991;&#20813;&#20102;&#23545;&#24179;&#31283;&#24615;&#30340;&#20551;&#35774;&#12290;&#22312;&#32447; Laplace &#26041;&#27861;&#21450;&#20854;&#20462;&#27491;&#27169;&#24577;&#30340;&#23545;&#24212;&#28857;&#28385;&#36275;&#20004;&#20010;&#26465;&#20214;&#65306;1. &#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#26159;&#19968;&#20010;&#26368;&#22823;&#21518;&#39564;&#27010;&#29575;&#65292;&#28385;&#36275; Laplace &#26041;&#27861;&#30340;&#20551;&#35774;&#65307;2. &#36229;&#21442;&#25968;&#26368;&#22823;&#21270; Laplace &#35777;&#25454;&#65292;&#20174;&#32780;&#20419;&#20351;&#22312;&#32447;&#26041;&#27861;&#30340;&#24212;&#29992;&#12290;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#20840;&#25209;&#37327;&#26799;&#24230;&#30340;&#22312;&#32447;&#31639;&#27861;&#28436;&#31034;&#20102;&#36825;&#20123;&#26368;&#20248;&#28857;&#22312;&#23454;&#36341;&#20013;&#30340;&#36817;&#20284;&#31243;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
The Laplace approximation provides a closed-form model selection objective for neural networks (NN). Online variants, which optimise NN parameters jointly with hyperparameters, like weight decay strength, have seen renewed interest in the Bayesian deep learning community. However, these methods violate Laplace's method's critical assumption that the approximation is performed around a mode of the loss, calling into question their soundness. This work re-derives online Laplace methods, showing them to target a variational bound on a mode-corrected variant of the Laplace evidence which does not make stationarity assumptions. Online Laplace and its mode-corrected counterpart share stationary points where 1. the NN parameters are a maximum a posteriori, satisfying the Laplace method's assumption, and 2. the hyperparameters maximise the Laplace evidence, motivating online methods. We demonstrate that these optima are roughly attained in practise by online algorithms using full-batch gradien
&lt;/p&gt;</description></item><item><title>&#35813;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#21442;&#25968;&#21270;&#35745;&#31639;&#20284;&#28982;&#27604;&#30340;&#25216;&#24039;&#65292;&#24182;&#35814;&#32454;&#27604;&#36739;&#20102;&#19981;&#21516;&#35774;&#32622;&#30340;&#24615;&#33021;&#12290;&#36825;&#23545;&#20110;&#35768;&#22810;&#25968;&#25454;&#25110;&#22522;&#20110;&#27169;&#25311;&#30340;&#31185;&#23398;&#24212;&#29992;&#38750;&#24120;&#26377;&#29992;&#12290;</title><link>http://arxiv.org/abs/2305.10500</link><description>&lt;p&gt;
&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#23398;&#20064;&#20284;&#28982;&#27604;
&lt;/p&gt;
&lt;p&gt;
Learning Likelihood Ratios with Neural Network Classifiers. (arXiv:2305.10500v1 [hep-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.10500
&lt;/p&gt;
&lt;p&gt;
&#35813;&#30740;&#31350;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#21442;&#25968;&#21270;&#35745;&#31639;&#20284;&#28982;&#27604;&#30340;&#25216;&#24039;&#65292;&#24182;&#35814;&#32454;&#27604;&#36739;&#20102;&#19981;&#21516;&#35774;&#32622;&#30340;&#24615;&#33021;&#12290;&#36825;&#23545;&#20110;&#35768;&#22810;&#25968;&#25454;&#25110;&#22522;&#20110;&#27169;&#25311;&#30340;&#31185;&#23398;&#24212;&#29992;&#38750;&#24120;&#26377;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#31185;&#23398;&#20013;&#65292;&#20284;&#28982;&#27604;&#26159;&#32479;&#35745;&#25512;&#26029;&#30340;&#20851;&#38190;&#24615;&#37327;&#65292;&#23427;&#20351;&#24471;&#20551;&#35774;&#26816;&#39564;&#12289;&#32622;&#20449;&#21306;&#38388;&#26500;&#24314;&#12289;&#20998;&#24067;&#21152;&#26435;&#31561;&#25104;&#20026;&#21487;&#33021;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;&#29616;&#20195;&#31185;&#23398;&#24212;&#29992;&#20351;&#29992;&#22522;&#20110;&#25968;&#25454;&#25110;&#22522;&#20110;&#27169;&#25311;&#30340;&#27169;&#22411;&#65292;&#32780;&#35745;&#31639;&#20284;&#28982;&#27604;&#21487;&#33021;&#38750;&#24120;&#22256;&#38590;&#29978;&#33267;&#19981;&#21487;&#33021;&#12290;&#36890;&#36807;&#24212;&#29992;&#25152;&#35859;&#30340;&#8220;&#20284;&#28982;&#27604;&#25216;&#24039;&#8221;&#65292;&#21487;&#20197;&#20351;&#29992;&#32874;&#26126;&#30340;&#31070;&#32463;&#32593;&#32476;&#20998;&#31867;&#22120;&#21442;&#25968;&#21270;&#26469;&#35745;&#31639;&#20284;&#28982;&#27604;&#30340;&#36817;&#20284;&#20540;&#12290;&#21487;&#20197;&#23450;&#20041;&#35768;&#22810;&#19981;&#21516;&#30340;&#31070;&#32463;&#32593;&#32476;&#35774;&#32622;&#26469;&#28385;&#36275;&#27492;&#36807;&#31243;&#65292;&#27599;&#20010;&#35774;&#32622;&#22312;&#20351;&#29992;&#26377;&#38480;&#35757;&#32451;&#25968;&#25454;&#26102;&#36817;&#20284;&#20284;&#28982;&#27604;&#30340;&#24615;&#33021;&#21508;&#24322;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#32463;&#39564;&#30740;&#31350;&#65292;&#35814;&#32454;&#20171;&#32461;&#20102;&#20960;&#31181;&#24120;&#35265;&#25439;&#22833;&#20989;&#25968;&#21644;&#20998;&#31867;&#22120;&#36755;&#20986;&#21442;&#25968;&#21270;&#22312;&#36817;&#20284;&#20004;&#20010;&#19968;&#20803;&#21644;&#22810;&#20803;&#39640;&#26031;&#20998;&#24067;&#30340;&#20284;&#28982;&#27604;&#26041;&#38754;&#30340;&#34920;&#29616;&#20197;&#21450;&#27169;&#25311;&#39640;&#33021;&#29289;&#29702;&#30340;&#20449;&#21495;&#21644;&#32972;&#26223;&#20107;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
The likelihood ratio is a crucial quantity for statistical inference in science that enables hypothesis testing, construction of confidence intervals, reweighting of distributions, and more. Many modern scientific applications, however, make use of data- or simulation-driven models for which computing the likelihood ratio can be very difficult or even impossible. By applying the so-called ``likelihood ratio trick,'' approximations of the likelihood ratio may be computed using clever parametrizations of neural network-based classifiers. A number of different neural network setups can be defined to satisfy this procedure, each with varying performance in approximating the likelihood ratio when using finite training data. We present a series of empirical studies detailing the performance of several common loss functionals and parametrizations of the classifier output in approximating the likelihood ratio of two univariate and multivariate Gaussian distributions as well as simulated high-e
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#23457;&#35745;&#26694;&#26550;&#65292;&#33021;&#22815;&#20197;&#20840;&#38754;&#30340;&#26041;&#24335;&#35780;&#20272;&#21512;&#25104;&#25968;&#25454;&#21644;AI&#27169;&#22411;&#30340;&#20855;&#20307;&#25928;&#26524;&#65292;&#21253;&#25324;&#20559;&#35265;&#21644;&#27495;&#35270;&#39044;&#38450;&#12289;&#23545;&#30495;&#23454;&#25968;&#25454;&#30340;&#24544;&#23454;&#31243;&#24230;&#12289;&#25928;&#29992;&#12289;&#40065;&#26834;&#24615;&#21644;&#38544;&#31169;&#20445;&#25252;&#12290;&#22312;&#22810;&#20010;&#29992;&#20363;&#20013;&#65292;&#23457;&#35745;&#26694;&#26550;&#24179;&#34913;&#20102;&#20449;&#20219;&#21644;&#25928;&#29992;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;</title><link>http://arxiv.org/abs/2304.10819</link><description>&lt;p&gt;
&#21487;&#25511;&#30340;&#20449;&#20219;&#26435;&#34913;&#19979;&#30340;&#21512;&#25104;&#25968;&#25454;&#23457;&#35745;&#19982;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Auditing and Generating Synthetic Data with Controllable Trust Trade-offs. (arXiv:2304.10819v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10819
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#23457;&#35745;&#26694;&#26550;&#65292;&#33021;&#22815;&#20197;&#20840;&#38754;&#30340;&#26041;&#24335;&#35780;&#20272;&#21512;&#25104;&#25968;&#25454;&#21644;AI&#27169;&#22411;&#30340;&#20855;&#20307;&#25928;&#26524;&#65292;&#21253;&#25324;&#20559;&#35265;&#21644;&#27495;&#35270;&#39044;&#38450;&#12289;&#23545;&#30495;&#23454;&#25968;&#25454;&#30340;&#24544;&#23454;&#31243;&#24230;&#12289;&#25928;&#29992;&#12289;&#40065;&#26834;&#24615;&#21644;&#38544;&#31169;&#20445;&#25252;&#12290;&#22312;&#22810;&#20010;&#29992;&#20363;&#20013;&#65292;&#23457;&#35745;&#26694;&#26550;&#24179;&#34913;&#20102;&#20449;&#20219;&#21644;&#25928;&#29992;&#20043;&#38388;&#30340;&#26435;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#23454;&#20013;&#25910;&#38598;&#30340;&#25968;&#25454;&#24448;&#24448;&#23384;&#22312;&#20559;&#24046;&#12289;&#19981;&#24179;&#34913;&#65292;&#24182;&#19988;&#26377;&#27844;&#38706;&#25935;&#24863;&#21644;&#38544;&#31169;&#20449;&#24687;&#30340;&#39118;&#38505;&#12290;&#36825;&#19968;&#20107;&#23454;&#24341;&#21457;&#20102;&#21019;&#24314;&#21512;&#25104;&#25968;&#25454;&#38598;&#30340;&#24819;&#27861;&#65292;&#20197;&#20943;&#36731;&#30495;&#23454;&#25968;&#25454;&#20013;&#22266;&#26377;&#30340;&#39118;&#38505;&#12289;&#20559;&#35265;&#12289;&#20260;&#23475;&#21644;&#38544;&#31169;&#38382;&#39064;&#12290;&#36825;&#20010;&#27010;&#24565;&#20381;&#36182;&#20110;&#29983;&#25104;AI&#27169;&#22411;&#65292;&#20197;&#20135;&#29983;&#19981;&#20559;&#25191;&#12289;&#20445;&#25252;&#38544;&#31169;&#30340;&#21512;&#25104;&#25968;&#25454;&#65292;&#21516;&#26102;&#24544;&#23454;&#20110;&#30495;&#23454;&#25968;&#25454;&#12290;&#22312;&#36825;&#31181;&#26032;&#33539;&#24335;&#20013;&#65292;&#25105;&#20204;&#22914;&#20309;&#30693;&#36947;&#36825;&#31181;&#26041;&#27861;&#26159;&#21542;&#20817;&#29616;&#20102;&#20854;&#25215;&#35834;&#65311;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23457;&#35745;&#26694;&#26550;&#65292;&#25552;&#20379;&#20102;&#23545;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#22522;&#20110;&#23427;&#20204;&#35757;&#32451;&#30340;AI&#27169;&#22411;&#30340;&#20840;&#38754;&#35780;&#20272;&#65292;&#22260;&#32469;&#20559;&#35265;&#21644;&#27495;&#35270;&#30340;&#39044;&#38450;&#12289;&#23545;&#30495;&#23454;&#25968;&#25454;&#30340;&#24544;&#23454;&#31243;&#24230;&#12289;&#25928;&#29992;&#12289;&#40065;&#26834;&#24615;&#21644;&#38544;&#31169;&#20445;&#25252;&#12290;&#25105;&#20204;&#36890;&#36807;&#23457;&#35745;&#22810;&#20010;&#29983;&#25104;&#27169;&#22411;&#22312;&#19981;&#21516;&#29992;&#20363;&#20013;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26694;&#26550;&#65292;&#21253;&#25324;&#25945;&#32946;&#12289;&#21307;&#30103;&#20445;&#20581;&#12289;&#38134;&#34892;&#12289;&#20154;&#21147;&#36164;&#28304;&#65292;&#20197;&#21450;&#20174;&#34920;&#26684;&#65292;&#26102;&#38388;&#24207;&#21015;&#21040;&#33258;&#28982;&#35821;&#35328;&#30340;&#19981;&#21516;&#27169;&#24577;&#12290;&#25105;&#20204;&#30340;&#29992;&#20363;&#23637;&#31034;&#20102;&#22312;&#21512;&#25104;&#25968;&#25454;&#29983;&#25104;&#20013;&#24179;&#34913;&#20449;&#20219;&#21644;&#25928;&#29992;&#30340;&#26435;&#34913;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data collected from the real world tends to be biased, unbalanced, and at risk of exposing sensitive and private information. This reality has given rise to the idea of creating synthetic datasets to alleviate risk, bias, harm, and privacy concerns inherent in the real data. This concept relies on Generative AI models to produce unbiased, privacy-preserving synthetic data while being true to the real data. In this new paradigm, how can we tell if this approach delivers on its promises? We present an auditing framework that offers a holistic assessment of synthetic datasets and AI models trained on them, centered around bias and discrimination prevention, fidelity to the real data, utility, robustness, and privacy preservation. We showcase our framework by auditing multiple generative models on diverse use cases, including education, healthcare, banking, human resources, and across different modalities, from tabular, to time-series, to natural language. Our use cases demonstrate the imp
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;Shallow ReLU$^k$&#31070;&#32463;&#32593;&#32476;&#30340;&#36924;&#36817;&#23481;&#37327;&#65292;&#35777;&#26126;&#20102;&#20854;&#26368;&#20248;&#36924;&#36817;&#36895;&#29575;&#12290;&#24212;&#29992;&#21040;&#38750;&#21442;&#25968;&#22238;&#24402;&#19978;&#65292;&#35777;&#26126;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#23454;&#29616;&#23398;&#20064;H\"older&#20989;&#25968;&#30340;&#26368;&#20248;&#28176;&#36827;&#36895;&#29575;&#65292;&#34917;&#20805;&#20102;&#28145;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#36817;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2304.01561</link><description>&lt;p&gt;
Shallow ReLU$^k$&#31070;&#32463;&#32593;&#32476;&#30340;&#36924;&#36817;&#36895;&#29575;&#21450;&#20854;&#22312;&#38750;&#21442;&#25968;&#22238;&#24402;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Optimal rates of approximation by shallow ReLU$^k$ neural networks and applications to nonparametric regression. (arXiv:2304.01561v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01561
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;Shallow ReLU$^k$&#31070;&#32463;&#32593;&#32476;&#30340;&#36924;&#36817;&#23481;&#37327;&#65292;&#35777;&#26126;&#20102;&#20854;&#26368;&#20248;&#36924;&#36817;&#36895;&#29575;&#12290;&#24212;&#29992;&#21040;&#38750;&#21442;&#25968;&#22238;&#24402;&#19978;&#65292;&#35777;&#26126;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#23454;&#29616;&#23398;&#20064;H\"older&#20989;&#25968;&#30340;&#26368;&#20248;&#28176;&#36827;&#36895;&#29575;&#65292;&#34917;&#20805;&#20102;&#28145;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#36817;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#19982;Shallow ReLU$^k$&#31070;&#32463;&#32593;&#32476;&#30456;&#20851;&#30340;&#21464;&#24322;&#31354;&#38388;&#30340;&#36924;&#36817;&#23481;&#37327;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#26377;&#38480;&#21464;&#24322;&#33539;&#25968;&#19979;&#65292;&#23481;&#32435;&#20102;&#36275;&#22815;&#24179;&#28369;&#30340;&#20989;&#25968;&#12290;&#23545;&#20110;&#36739;&#23569;&#24179;&#28369;&#30340;&#20989;&#25968;&#65292;&#26681;&#25454;&#21464;&#24322;&#33539;&#25968;&#24314;&#31435;&#20102;&#36924;&#36817;&#36895;&#29575;&#12290;&#36816;&#29992;&#36825;&#20123;&#32467;&#26524;&#65292;&#25105;&#20204;&#21487;&#20197;&#35777;&#26126;Shallow ReLU$^k$&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#20248;&#36924;&#36817;&#36895;&#29575;&#12290;&#21516;&#26102;&#38416;&#26126;&#20102;&#36825;&#20123;&#32467;&#26524;&#22914;&#20309;&#29992;&#20110;&#25512;&#23548;&#28145;&#23618;&#31070;&#32463;&#32593;&#32476;&#21644;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;(CNNs)&#30340;&#36924;&#36817;&#30028;&#38480;&#12290;&#20026;&#24212;&#29992;&#30740;&#31350;&#65292;&#25105;&#20204;&#20351;&#29992;&#20102;&#19977;&#31181;ReLU&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65306;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#65292;&#36229;&#21442;&#25968;&#31070;&#32463;&#32593;&#32476;&#21644;CNN&#36827;&#34892;&#38750;&#21442;&#25968;&#22238;&#24402;&#25910;&#25947;&#36895;&#29575;&#30740;&#31350;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#21487;&#20197;&#23454;&#29616;&#23398;&#20064;H\"older&#20989;&#25968;&#30340;&#26368;&#20248;&#28176;&#36827;&#36895;&#29575;&#65292;&#36825;&#34917;&#20805;&#20102;&#28145;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#26368;&#36817;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the approximation capacity of some variation spaces corresponding to shallow ReLU$^k$ neural networks. It is shown that sufficiently smooth functions are contained in these spaces with finite variation norms. For functions with less smoothness, the approximation rates in terms of the variation norm are established. Using these results, we are able to prove the optimal approximation rates in terms of the number of neurons for shallow ReLU$^k$ neural networks. It is also shown how these results can be used to derive approximation bounds for deep neural networks and convolutional neural networks (CNNs). As applications, we study convergence rates for nonparametric regression using three ReLU neural network models: shallow neural network, over-parameterized neural network, and CNN. In particular, we show that shallow neural networks can achieve the minimax optimal rates for learning H\"older functions, which complements recent results for deep neural networks. It is also proven th
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28151;&#21512;&#35889;&#26041;&#27861;&#21644;&#35856;&#25391;&#23376;&#30340;&#38750;&#21487;&#20998;&#31163;&#21327;&#26041;&#24046;&#26680;&#30340;&#26102;&#31354;&#39640;&#26031;&#36807;&#31243;&#30740;&#31350;&#65292;&#36890;&#36807;&#29289;&#29702;&#35770;&#35777;&#25512;&#23548;&#20986;&#19968;&#31867;&#26032;&#22411;&#30340;&#38750;&#21487;&#20998;&#31163;&#21327;&#26041;&#24046;&#26680;&#65292;&#33021;&#26356;&#22909;&#22320;&#25429;&#25417;&#35266;&#27979;&#21040;&#30340;&#26102;&#31354;&#30456;&#20851;&#24615;&#12290;</title><link>http://arxiv.org/abs/2302.09580</link><description>&lt;p&gt;
&#22522;&#20110;&#28151;&#21512;&#35889;&#26041;&#27861;&#21644;&#35856;&#25391;&#23376;&#30340;&#38750;&#21487;&#20998;&#31163;&#21327;&#26041;&#24046;&#26680;&#30340;&#26102;&#31354;&#39640;&#26031;&#36807;&#31243;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Non-separable Covariance Kernels for Spatiotemporal Gaussian Processes based on a Hybrid Spectral Method and the Harmonic Oscillator. (arXiv:2302.09580v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09580
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28151;&#21512;&#35889;&#26041;&#27861;&#21644;&#35856;&#25391;&#23376;&#30340;&#38750;&#21487;&#20998;&#31163;&#21327;&#26041;&#24046;&#26680;&#30340;&#26102;&#31354;&#39640;&#26031;&#36807;&#31243;&#30740;&#31350;&#65292;&#36890;&#36807;&#29289;&#29702;&#35770;&#35777;&#25512;&#23548;&#20986;&#19968;&#31867;&#26032;&#22411;&#30340;&#38750;&#21487;&#20998;&#31163;&#21327;&#26041;&#24046;&#26680;&#65292;&#33021;&#26356;&#22909;&#22320;&#25429;&#25417;&#35266;&#27979;&#21040;&#30340;&#26102;&#31354;&#30456;&#20851;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#26031;&#36807;&#31243;&#25552;&#20379;&#20102;&#19968;&#20010;&#28789;&#27963;&#30340;&#38750;&#21442;&#25968;&#26694;&#26550;&#65292;&#29992;&#20110;&#36817;&#20284;&#39640;&#32500;&#31354;&#38388;&#20013;&#30340;&#20989;&#25968;&#12290;&#21327;&#26041;&#24046;&#26680;&#26159;&#39640;&#26031;&#36807;&#31243;&#30340;&#20027;&#35201;&#24341;&#25806;&#65292;&#21253;&#21547;&#20102;&#39044;&#27979;&#20998;&#24067;&#30340;&#30456;&#20851;&#24615;&#12290;&#23545;&#20110;&#20855;&#26377;&#26102;&#31354;&#25968;&#25454;&#38598;&#30340;&#24212;&#29992;&#65292;&#21512;&#36866;&#30340;&#26680;&#24212;&#35813;&#24314;&#27169;&#32852;&#21512;&#30340;&#26102;&#31354;&#20381;&#36182;&#20851;&#31995;&#12290;&#21487;&#20998;&#31163;&#30340;&#26102;&#31354;&#21327;&#26041;&#24046;&#26680;&#25552;&#20379;&#20102;&#31616;&#21333;&#21644;&#35745;&#31639;&#25928;&#29575;&#36739;&#39640;&#30340;&#26041;&#26696;&#12290;&#28982;&#32780;&#65292;&#38750;&#21487;&#20998;&#31163;&#26680;&#21253;&#21547;&#20102;&#26356;&#22909;&#22320;&#25429;&#25417;&#35266;&#27979;&#21040;&#30340;&#30456;&#20851;&#24615;&#30340;&#26102;&#31354;&#20132;&#20114;&#20316;&#29992;&#12290;&#22823;&#22810;&#25968;&#20855;&#26377;&#26174;&#24335;&#34920;&#36798;&#24335;&#30340;&#38750;&#21487;&#20998;&#31163;&#26680;&#26159;&#22522;&#20110;&#25968;&#23398;&#32771;&#34385;&#65288;&#21487;&#20801;&#35768;&#26465;&#20214;&#65289;&#32780;&#38750;&#22522;&#20110;&#31532;&#19968;&#21407;&#29702;&#23548;&#20986;&#30340;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#29289;&#29702;&#35770;&#35777;&#30340;&#28151;&#21512;&#35889;&#26041;&#27861;&#26469;&#29983;&#25104;&#21327;&#26041;&#24046;&#26680;&#12290;&#25105;&#20204;&#20351;&#29992;&#36825;&#31181;&#26041;&#27861;&#25512;&#23548;&#20102;&#19968;&#31867;&#26032;&#22411;&#30340;&#29289;&#29702;&#21160;&#26426;&#30340;&#38750;&#21487;&#20998;&#31163;&#21327;&#26041;&#24046;&#26680;&#65292;&#23427;&#20204;&#30340;&#26681;&#28304;&#26469;&#33258;&#38543;&#26426;&#32447;&#24615;...
&lt;/p&gt;
&lt;p&gt;
Gaussian processes provide a flexible, non-parametric framework for the approximation of functions in high-dimensional spaces. The covariance kernel is the main engine of Gaussian processes, incorporating correlations that underpin the predictive distribution. For applications with spatiotemporal datasets, suitable kernels should model joint spatial and temporal dependence. Separable space-time covariance kernels offer simplicity and computational efficiency. However, non-separable kernels include space-time interactions that better capture observed correlations. Most non-separable kernels that admit explicit expressions are based on mathematical considerations (admissibility conditions) rather than first-principles derivations. We present a hybrid spectral approach for generating covariance kernels which is based on physical arguments. We use this approach to derive a new class of physically motivated, non-separable covariance kernels which have their roots in the stochastic, linear, 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#23637;&#31034;&#20102;Transformer&#21644;&#20854;&#20182;&#40657;&#30418;&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#20803;&#23398;&#20064;&#35757;&#32451;&#25104;&#20026;&#36890;&#29992;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#22120;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#22312;&#21508;&#31181;&#38382;&#39064;&#19978;&#36827;&#34892;&#27979;&#35797;&#38598;&#39044;&#27979;&#65292;&#26080;&#38656;&#23450;&#20041;&#25512;&#29702;&#27169;&#22411;&#12289;&#35757;&#32451;&#25439;&#22833;&#25110;&#20248;&#21270;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2212.04458</link><description>&lt;p&gt;
&#36890;&#36807;&#20803;&#23398;&#20064;Transformer&#23454;&#29616;&#36890;&#29992;&#19978;&#19979;&#25991;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
General-Purpose In-Context Learning by Meta-Learning Transformers. (arXiv:2212.04458v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.04458
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23637;&#31034;&#20102;Transformer&#21644;&#20854;&#20182;&#40657;&#30418;&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#20803;&#23398;&#20064;&#35757;&#32451;&#25104;&#20026;&#36890;&#29992;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#22120;&#65292;&#35813;&#27169;&#22411;&#21487;&#20197;&#22312;&#21508;&#31181;&#38382;&#39064;&#19978;&#36827;&#34892;&#27979;&#35797;&#38598;&#39044;&#27979;&#65292;&#26080;&#38656;&#23450;&#20041;&#25512;&#29702;&#27169;&#22411;&#12289;&#35757;&#32451;&#25439;&#22833;&#25110;&#20248;&#21270;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#35201;&#27714;&#31995;&#32479;&#35774;&#35745;&#32773;&#25351;&#23450;&#23398;&#20064;&#27969;&#31243;&#30340;&#26041;&#26041;&#38754;&#38754;&#65292;&#20363;&#22914;&#25439;&#22833;&#20989;&#25968;&#12289;&#26550;&#26500;&#21644;&#20248;&#21270;&#22120;&#12290;&#32780;&#20803;&#23398;&#20064;&#65292;&#25110;&#32773;&#23398;&#20250;&#23398;&#20064;&#65292;&#30446;&#26631;&#26159;&#23398;&#20064;&#36825;&#20123;&#26041;&#38754;&#65292;&#24182;&#25215;&#35834;&#20197;&#26356;&#23569;&#30340;&#25163;&#21160;&#24037;&#20316;&#24320;&#21551;&#26356;&#22823;&#30340;&#33021;&#21147;&#12290;&#20803;&#23398;&#20064;&#30340;&#19968;&#20010;&#29305;&#21035;&#38596;&#24515;&#21187;&#21187;&#30340;&#30446;&#26631;&#26159;&#20174;&#22836;&#24320;&#22987;&#35757;&#32451;&#36890;&#29992;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#31639;&#27861;&#65292;&#20165;&#20351;&#29992;&#24102;&#26377;&#26368;&#23567;&#24402;&#32435;&#20559;&#35265;&#30340;&#40657;&#30418;&#27169;&#22411;&#12290;&#36825;&#26679;&#30340;&#27169;&#22411;&#25509;&#25910;&#35757;&#32451;&#25968;&#25454;&#65292;&#24182;&#22312;&#21508;&#31181;&#38382;&#39064;&#19978;&#20135;&#29983;&#27979;&#35797;&#38598;&#39044;&#27979;&#65292;&#32780;&#26080;&#38656;&#23450;&#20041;&#25512;&#29702;&#27169;&#22411;&#12289;&#35757;&#32451;&#25439;&#22833;&#25110;&#20248;&#21270;&#31639;&#27861;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;Transformer&#21644;&#20854;&#20182;&#40657;&#30418;&#27169;&#22411;&#21487;&#20197;&#34987;&#20803;&#35757;&#32451;&#25104;&#20026;&#36890;&#29992;&#30340;&#19978;&#19979;&#25991;&#23398;&#20064;&#22120;&#12290;&#25105;&#20204;&#36890;&#36807;&#27169;&#22411;&#22823;&#23567;&#12289;&#20219;&#21153;&#25968;&#37327;&#21644;&#20803;&#20248;&#21270;&#24341;&#36215;&#30340;&#31639;&#27861;&#20043;&#38388;&#30340;&#36716;&#25442;&#36827;&#34892;&#20102;&#34920;&#24449;&#65292;&#36825;&#20123;&#31639;&#27861;&#21487;&#20197;&#23454;&#29616;&#27867;&#21270;&#65292;&#20063;&#21487;&#20197;&#23454;&#29616;&#35760;&#24518;&#65292;&#36824;&#26377;&#19968;&#20123;&#31639;&#27861;&#26681;&#26412;&#26080;&#27861;&#36827;&#34892;&#20803;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modern machine learning requires system designers to specify aspects of the learning pipeline, such as losses, architectures, and optimizers. Meta-learning, or learning-to-learn, instead aims to learn those aspects, and promises to unlock greater capabilities with less manual effort. One particularly ambitious goal of meta-learning is to train general-purpose in-context learning algorithms from scratch, using only black-box models with minimal inductive bias. Such a model takes in training data, and produces test-set predictions across a wide range of problems, without any explicit definition of an inference model, training loss, or optimization algorithm. In this paper we show that Transformers and other black-box models can be meta-trained to act as general-purpose in-context learners. We characterize transitions between algorithms that generalize, algorithms that memorize, and algorithms that fail to meta-train at all, induced by changes in model size, number of tasks, and meta-opti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#36817;&#26399;&#22312;&#35774;&#23450;&#39044;&#27979;&#19979;&#30340;&#36827;&#23637;&#65292;&#26500;&#24314;&#20102;&#39044;&#27979;&#38598;&#20197;&#36866;&#24212;&#24402;&#32435;&#23398;&#20064;&#22330;&#26223;&#19979;&#30340;&#33410;&#28857;&#20998;&#31867;&#65292;&#35777;&#26126;&#20102;&#25552;&#20379;&#20102;&#27604;&#31616;&#21333;&#30340;&#31526;&#21512;&#39044;&#27979;&#24212;&#29992;&#26356;&#21152;&#32039;&#33268;&#21644;&#33391;&#22909;&#26657;&#20934;&#30340;&#39044;&#27979;&#38598;&#12290;</title><link>http://arxiv.org/abs/2211.14555</link><description>&lt;p&gt;
&#26080;&#20998;&#24067;&#20551;&#35774;&#30340;&#33410;&#28857;&#20998;&#31867;&#39044;&#27979;&#38598;
&lt;/p&gt;
&lt;p&gt;
Distribution Free Prediction Sets for Node Classification. (arXiv:2211.14555v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.14555
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#36817;&#26399;&#22312;&#35774;&#23450;&#39044;&#27979;&#19979;&#30340;&#36827;&#23637;&#65292;&#26500;&#24314;&#20102;&#39044;&#27979;&#38598;&#20197;&#36866;&#24212;&#24402;&#32435;&#23398;&#20064;&#22330;&#26223;&#19979;&#30340;&#33410;&#28857;&#20998;&#31867;&#65292;&#35777;&#26126;&#20102;&#25552;&#20379;&#20102;&#27604;&#31616;&#21333;&#30340;&#31526;&#21512;&#39044;&#27979;&#24212;&#29992;&#26356;&#21152;&#32039;&#33268;&#21644;&#33391;&#22909;&#26657;&#20934;&#30340;&#39044;&#27979;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#36890;&#24120;&#21487;&#20197;&#22312;&#35768;&#22810;&#37325;&#35201;&#30340;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#36798;&#21040;&#39640;&#31934;&#24230;&#20998;&#31867;&#30340;&#25928;&#26524;&#65292;&#20294;&#20854;&#26080;&#27861;&#25552;&#20379;&#20005;&#26684;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#23450;&#20041;&#12290;&#30001;&#20110;&#22270;&#32467;&#26500;&#24341;&#36215;&#30340;&#25968;&#25454;&#28857;&#20381;&#36182;&#24615;&#65292;&#37327;&#21270;GNN&#27169;&#22411;&#30340;&#32622;&#20449;&#24230;&#24456;&#22256;&#38590;&#12290;&#26412;&#25991;&#21033;&#29992;&#36817;&#26399;&#22312;&#35774;&#23450;&#39044;&#27979;&#19979;&#30340;&#36827;&#23637;&#65292;&#26500;&#24314;&#20102;&#39044;&#27979;&#38598;&#20197;&#36866;&#24212;&#24402;&#32435;&#23398;&#20064;&#22330;&#26223;&#19979;&#30340;&#33410;&#28857;&#20998;&#31867;&#12290;&#25105;&#20204;&#23545;&#29616;&#26377;&#30340;&#25442;&#20301;&#20998;&#31867;&#26041;&#27861;&#36827;&#34892;&#20102;&#25913;&#36827;&#65292;&#36890;&#36807;&#36866;&#24403;&#21152;&#26435;&#31526;&#21512;&#20998;&#25968;&#26469;&#21453;&#26144;&#32593;&#32476;&#32467;&#26500;&#12290;&#36890;&#36807;&#22312;&#24120;&#29992;&#26631;&#20934;&#22522;&#20934;&#25968;&#25454;&#38598;&#19978;&#20351;&#29992;&#27969;&#34892;&#30340;GNN&#27169;&#22411;&#36827;&#34892;&#23454;&#39564;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;&#27604;&#31616;&#21333;&#30340;&#31526;&#21512;&#39044;&#27979;&#24212;&#29992;&#26356;&#21152;&#32039;&#33268;&#21644;&#33391;&#22909;&#26657;&#20934;&#30340;&#39044;&#27979;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Networks (GNNs) are able to achieve high classification accuracy on many important real world datasets, but provide no rigorous notion of predictive uncertainty. Quantifying the confidence of GNN models is difficult due to the dependence between datapoints induced by the graph structure.  We leverage recent advances in conformal prediction to construct prediction sets for node classification in inductive learning scenarios. We do this by taking an existing approach for conformal classification that relies on \textit{exchangeable} data and modifying it by appropriately weighting the conformal scores to reflect the network structure. We show through experiments on standard benchmark datasets using popular GNN models that our approach provides tighter and better calibrated prediction sets than a naive application of conformal prediction.
&lt;/p&gt;</description></item></channel></rss>