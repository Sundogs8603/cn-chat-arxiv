<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#38754;&#26495;&#25968;&#25454;&#20013;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#30340;&#31616;&#21333;&#19988;&#26368;&#20339;&#21270;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#31616;&#21333;&#30340;&#30697;&#38453;&#20195;&#25968;&#21644;&#22855;&#24322;&#20540;&#20998;&#35299;&#26469;&#23454;&#29616;&#39640;&#25928;&#35745;&#31639;&#12290;&#36890;&#36807;&#23548;&#20986;&#38750;&#28176;&#36817;&#30028;&#38480;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36880;&#39033;&#35823;&#24046;&#19982;&#39640;&#26031;&#21464;&#37327;&#30340;&#36866;&#24403;&#32553;&#25918;&#20855;&#26377;&#25509;&#36817;&#24615;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#20010;&#25968;&#25454;&#39537;&#21160;&#31243;&#24207;&#65292;&#29992;&#20110;&#26500;&#24314;&#20855;&#26377;&#39044;&#20808;&#25351;&#23450;&#35206;&#30422;&#20445;&#35777;&#30340;&#36880;&#39033;&#32622;&#20449;&#21306;&#38388;&#12290;</title><link>http://arxiv.org/abs/2401.13665</link><description>&lt;p&gt;
&#12298;&#38754;&#26495;&#25968;&#25454;&#22240;&#26524;&#25512;&#26029;&#30340;&#36880;&#39033;&#25512;&#29702;&#26041;&#27861;&#65306;&#19968;&#31181;&#31616;&#21333;&#19988;&#26368;&#20339;&#21270;&#30340;&#26041;&#27861;&#12299;
&lt;/p&gt;
&lt;p&gt;
Entrywise Inference for Causal Panel Data: A Simple and Instance-Optimal Approach. (arXiv:2401.13665v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13665
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#38754;&#26495;&#25968;&#25454;&#20013;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#30340;&#31616;&#21333;&#19988;&#26368;&#20339;&#21270;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#31616;&#21333;&#30340;&#30697;&#38453;&#20195;&#25968;&#21644;&#22855;&#24322;&#20540;&#20998;&#35299;&#26469;&#23454;&#29616;&#39640;&#25928;&#35745;&#31639;&#12290;&#36890;&#36807;&#23548;&#20986;&#38750;&#28176;&#36817;&#30028;&#38480;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#36880;&#39033;&#35823;&#24046;&#19982;&#39640;&#26031;&#21464;&#37327;&#30340;&#36866;&#24403;&#32553;&#25918;&#20855;&#26377;&#25509;&#36817;&#24615;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#19968;&#20010;&#25968;&#25454;&#39537;&#21160;&#31243;&#24207;&#65292;&#29992;&#20110;&#26500;&#24314;&#20855;&#26377;&#39044;&#20808;&#25351;&#23450;&#35206;&#30422;&#20445;&#35777;&#30340;&#36880;&#39033;&#32622;&#20449;&#21306;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20998;&#38454;&#27573;&#37319;&#29992;&#30340;&#38754;&#26495;&#25968;&#25454;&#20013;&#30340;&#22240;&#26524;&#25512;&#26029;&#20013;&#65292;&#30446;&#26631;&#26159;&#20272;&#35745;&#21644;&#25512;&#23548;&#20986;&#28508;&#22312;&#32467;&#26524;&#21644;&#22788;&#29702;&#25928;&#24212;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#25928;&#29575;&#39640;&#30340;&#31243;&#24207;&#65292;&#20165;&#28041;&#21450;&#31616;&#21333;&#30340;&#30697;&#38453;&#20195;&#25968;&#21644;&#22855;&#24322;&#20540;&#20998;&#35299;&#12290;&#25105;&#20204;&#23548;&#20986;&#20102;&#36880;&#39033;&#35823;&#24046;&#30340;&#38750;&#28176;&#36817;&#30028;&#38480;&#65292;&#35777;&#26126;&#20854;&#25509;&#36817;&#20110;&#36866;&#24403;&#32553;&#25918;&#30340;&#39640;&#26031;&#21464;&#37327;&#12290;&#23613;&#31649;&#25105;&#20204;&#30340;&#31243;&#24207;&#31616;&#21333;&#65292;&#20294;&#21364;&#26159;&#23616;&#37096;&#26368;&#20339;&#21270;&#30340;&#65292;&#22240;&#20026;&#25105;&#20204;&#30340;&#29702;&#35770;&#32553;&#25918;&#19982;&#36890;&#36807;&#36125;&#21494;&#26031;Cram\'{e}r-Rao&#35770;&#35777;&#24471;&#20986;&#30340;&#23616;&#37096;&#23454;&#20363;&#19979;&#30028;&#30456;&#21305;&#37197;&#12290;&#21033;&#29992;&#25105;&#20204;&#30340;&#35265;&#35299;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#31243;&#24207;&#65292;&#29992;&#20110;&#26500;&#24314;&#20855;&#26377;&#39044;&#20808;&#25351;&#23450;&#35206;&#30422;&#20445;&#35777;&#30340;&#36880;&#39033;&#32622;&#20449;&#21306;&#38388;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#22522;&#20110;&#23545;&#30697;&#38453;&#21435;&#22122;&#27169;&#22411;&#24212;&#29992;SVD&#31639;&#27861;&#30340;&#19968;&#33324;&#25512;&#29702;&#24037;&#20855;&#31665;&#65292;&#36825;&#21487;&#33021;&#20855;&#26377;&#29420;&#31435;&#30340;&#20852;&#36259;&#12290;
&lt;/p&gt;
&lt;p&gt;
In causal inference with panel data under staggered adoption, the goal is to estimate and derive confidence intervals for potential outcomes and treatment effects. We propose a computationally efficient procedure, involving only simple matrix algebra and singular value decomposition. We derive non-asymptotic bounds on the entrywise error, establishing its proximity to a suitably scaled Gaussian variable. Despite its simplicity, our procedure turns out to be instance-optimal, in that our theoretical scaling matches a local instance-wise lower bound derived via a Bayesian Cram\'{e}r-Rao argument. Using our insights, we develop a data-driven procedure for constructing entrywise confidence intervals with pre-specified coverage guarantees. Our analysis is based on a general inferential toolbox for the SVD algorithm applied to the matrix denoising model, which might be of independent interest.
&lt;/p&gt;</description></item><item><title>&#36807;&#25311;&#21512;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#23545;&#25239;&#35757;&#32451;&#20013;&#33021;&#22815;&#27867;&#21270;&#65292;&#32780;&#19988;&#21487;&#20197;&#36890;&#36807;&#21512;&#36866;&#30340;&#26465;&#20214;&#33719;&#24471;&#33391;&#22909;&#30340;&#40065;&#26834;&#27867;&#21270;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.13624</link><description>&lt;p&gt;
&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#23545;&#25239;&#35757;&#32451;&#20013;&#30340;&#36807;&#25311;&#21512;&#29616;&#35937;&#33021;&#21542;&#27867;&#21270;&#65311;&#8212;&#8212;&#19968;&#20010;&#36817;&#20284;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Can overfitted deep neural networks in adversarial training generalize? -- An approximation viewpoint. (arXiv:2401.13624v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13624
&lt;/p&gt;
&lt;p&gt;
&#36807;&#25311;&#21512;&#30340;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22312;&#23545;&#25239;&#35757;&#32451;&#20013;&#33021;&#22815;&#27867;&#21270;&#65292;&#32780;&#19988;&#21487;&#20197;&#36890;&#36807;&#21512;&#36866;&#30340;&#26465;&#20214;&#33719;&#24471;&#33391;&#22909;&#30340;&#40065;&#26834;&#27867;&#21270;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#35757;&#32451;&#26159;&#19968;&#31181;&#24191;&#27867;&#24212;&#29992;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#25552;&#39640;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;(DNNs)&#23545;&#23545;&#25239;&#25200;&#21160;&#30340;&#40065;&#26834;&#24615;&#12290;&#28982;&#32780;&#65292;&#32463;&#39564;&#35266;&#23519;&#34920;&#26126;&#65292;&#22312;&#36807;&#21442;&#25968;&#21270;&#32593;&#32476;&#19978;&#36827;&#34892;&#23545;&#25239;&#35757;&#32451;&#24448;&#24448;&#20250;&#36973;&#21463;"&#40065;&#26834;&#24615;&#36807;&#25311;&#21512;"&#65306;&#23427;&#21487;&#20197;&#23454;&#29616;&#20960;&#20046;&#38646;&#30340;&#23545;&#25239;&#35757;&#32451;&#35823;&#24046;&#65292;&#32780;&#40065;&#26834;&#27867;&#21270;&#24615;&#33021;&#24182;&#19981;&#29702;&#24819;&#12290;&#26412;&#25991;&#20174;&#36817;&#20284;&#30340;&#35282;&#24230;&#25552;&#20379;&#20102;&#20851;&#20110;&#22312;&#23545;&#25239;&#35757;&#32451;&#20013;&#36807;&#25311;&#21512;&#30340;DNNs&#33021;&#21542;&#27867;&#21270;&#30340;&#29702;&#35770;&#29702;&#35299;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#24635;&#32467;&#20026;&#19977;&#20010;&#26041;&#38754;&#65306;i) &#23545;&#20110;&#20998;&#31867;&#38382;&#39064;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#36807;&#21442;&#25968;&#21270;&#30340;DNNs&#19978;&#21487;&#20197;&#26500;&#36896;&#20986;&#26080;&#38480;&#22810;&#20010;&#23545;&#25239;&#35757;&#32451;&#20998;&#31867;&#22120;&#65292;&#20854;&#33021;&#22815;&#22312;&#28385;&#36275;&#19968;&#23450;&#26465;&#20214;&#19979;&#65288;&#28041;&#21450;&#25968;&#25454;&#36136;&#37327;&#65292;&#33391;&#22909;&#20998;&#31163;&#21644;&#25200;&#21160;&#31243;&#24230;&#65289;&#33719;&#24471;&#20219;&#24847;&#23567;&#30340;&#23545;&#25239;&#35757;&#32451;&#35823;&#24046;&#65288;&#36807;&#25311;&#21512;&#65289;&#65292;&#21516;&#26102;&#22312;&#40065;&#26834;&#27867;&#21270;&#35823;&#24046;&#26041;&#38754;&#34920;&#29616;&#33391;&#22909;&#12290;ii) &#32447;&#24615;&#36229;&#36807;&#25311;&#21512;&#30340;DNNs&#20063;&#21487;&#20197;&#23454;&#29616;&#40065;&#26834;&#27867;&#21270;&#12290;iii) &#25105;&#20204;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#39564;&#35777;&#20102;&#25152;&#25552;&#20986;&#30340;&#29702;&#35770;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adversarial training is a widely used method to improve the robustness of deep neural networks (DNNs) over adversarial perturbations. However, it is empirically observed that adversarial training on over-parameterized networks often suffers from the \textit{robust overfitting}: it can achieve almost zero adversarial training error while the robust generalization performance is not promising. In this paper, we provide a theoretical understanding of the question of whether overfitted DNNs in adversarial training can generalize from an approximation viewpoint. Specifically, our main results are summarized into three folds: i) For classification, we prove by construction the existence of infinitely many adversarial training classifiers on over-parameterized DNNs that obtain arbitrarily small adversarial training error (overfitting), whereas achieving good robust generalization error under certain conditions concerning the data quality, well separated, and perturbation level. ii) Linear ove
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36229;&#36234;&#27010;&#24565;&#29942;&#39048;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#20351;&#40657;&#30418;&#27169;&#22411;&#21487;&#24178;&#39044;&#12290;&#36890;&#36807;&#22522;&#20110;&#27010;&#24565;&#30340;&#24178;&#39044;&#26469;&#24433;&#21709;&#27169;&#22411;&#30340;&#36755;&#20986;&#65292;&#24182;&#21033;&#29992;&#36825;&#31181;&#26041;&#27861;&#23545;&#40657;&#30418;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#24494;&#35843;&#21487;&#20197;&#25552;&#39640;&#24178;&#39044;&#30340;&#25928;&#26524;&#65292;&#24182;&#20135;&#29983;&#26356;&#22909;&#26657;&#20934;&#30340;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2401.13544</link><description>&lt;p&gt;
&#36229;&#36234;&#27010;&#24565;&#29942;&#39048;&#27169;&#22411;&#65306;&#22914;&#20309;&#20351;&#40657;&#30418;&#27169;&#22411;&#21487;&#24178;&#39044;&#65311;
&lt;/p&gt;
&lt;p&gt;
Beyond Concept Bottleneck Models: How to Make Black Boxes Intervenable?. (arXiv:2401.13544v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13544
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36229;&#36234;&#27010;&#24565;&#29942;&#39048;&#27169;&#22411;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#20351;&#40657;&#30418;&#27169;&#22411;&#21487;&#24178;&#39044;&#12290;&#36890;&#36807;&#22522;&#20110;&#27010;&#24565;&#30340;&#24178;&#39044;&#26469;&#24433;&#21709;&#27169;&#22411;&#30340;&#36755;&#20986;&#65292;&#24182;&#21033;&#29992;&#36825;&#31181;&#26041;&#27861;&#23545;&#40657;&#30418;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#24494;&#35843;&#21487;&#20197;&#25552;&#39640;&#24178;&#39044;&#30340;&#25928;&#26524;&#65292;&#24182;&#20135;&#29983;&#26356;&#22909;&#26657;&#20934;&#30340;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#21487;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#37325;&#26032;&#25506;&#32034;&#20102;&#27010;&#24565;&#29942;&#39048;&#27169;&#22411;&#65288;CBM&#65289;&#65292;&#21253;&#25324;&#20174;&#21407;&#22987;&#29305;&#24449;&#20013;&#36880;&#27493;&#39044;&#27979;&#39640;&#32423;&#27010;&#24565;&#21644;&#20174;&#39044;&#27979;&#30340;&#27010;&#24565;&#20013;&#39044;&#27979;&#30446;&#26631;&#21464;&#37327;&#12290;&#36825;&#20010;&#27169;&#22411;&#31867;&#21035;&#30340;&#19968;&#20010;&#24341;&#20154;&#27880;&#30446;&#30340;&#20248;&#21183;&#26159;&#29992;&#25143;&#33021;&#22815;&#23545;&#39044;&#27979;&#30340;&#27010;&#24565;&#20540;&#36827;&#34892;&#24178;&#39044;&#65292;&#20174;&#32780;&#24433;&#21709;&#27169;&#22411;&#30340;&#19979;&#28216;&#36755;&#20986;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#22312;&#24050;&#32463;&#35757;&#32451;&#22909;&#20294;&#26412;&#36136;&#19978;&#19981;&#21487;&#35299;&#37322;&#30340;&#31070;&#32463;&#32593;&#32476;&#19978;&#36827;&#34892;&#22522;&#20110;&#27010;&#24565;&#30340;&#24178;&#39044;&#65292;&#32473;&#23450;&#19968;&#20010;&#24102;&#26377;&#27880;&#37322;&#30340;&#39564;&#35777;&#38598;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#27169;&#22411;&#30340;&#21487;&#24178;&#39044;&#24615;&#23450;&#20041;&#20026;&#22522;&#20110;&#27010;&#24565;&#24178;&#39044;&#30340;&#26377;&#25928;&#24615;&#30340;&#24230;&#37327;&#65292;&#24182;&#21033;&#29992;&#36825;&#20010;&#23450;&#20041;&#26469;&#23545;&#40657;&#30418;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#12290;&#23454;&#35777;&#19978;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#21512;&#25104;&#34920;&#26684;&#25968;&#25454;&#21644;&#33258;&#28982;&#22270;&#20687;&#22522;&#20934;&#19978;&#40657;&#30418;&#20998;&#31867;&#22120;&#30340;&#24178;&#39044;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#24494;&#35843;&#25552;&#39640;&#20102;&#24178;&#39044;&#30340;&#25928;&#26524;&#65292;&#24182;&#32463;&#24120;&#20135;&#29983;&#26356;&#22909;&#26657;&#20934;&#30340;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, interpretable machine learning has re-explored concept bottleneck models (CBM), comprising step-by-step prediction of the high-level concepts from the raw features and the target variable from the predicted concepts. A compelling advantage of this model class is the user's ability to intervene on the predicted concept values, affecting the model's downstream output. In this work, we introduce a method to perform such concept-based interventions on already-trained neural networks, which are not interpretable by design, given an annotated validation set. Furthermore, we formalise the model's intervenability as a measure of the effectiveness of concept-based interventions and leverage this definition to fine-tune black-box models. Empirically, we explore the intervenability of black-box classifiers on synthetic tabular and natural image benchmarks. We demonstrate that fine-tuning improves intervention effectiveness and often yields better-calibrated predictions. To showcase the 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20840;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#26174;&#33879;&#24615;&#26816;&#39564;&#26041;&#27861;&#65288;nFBST&#65289;&#65292;&#36890;&#36807;&#21033;&#29992;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#25311;&#21512;&#38750;&#32447;&#24615;&#21644;&#22810;&#32500;&#20851;&#31995;&#65292;&#24182;&#35745;&#31639;&#35777;&#25454;&#20540;&#26469;&#26367;&#20195;&#20256;&#32479;&#26041;&#27861;&#20013;&#30340;&#29702;&#35770;&#25512;&#23548;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#27979;&#35797;&#20840;&#23616;&#12289;&#23616;&#37096;&#21644;&#23454;&#20363;&#32423;&#30340;&#26174;&#33879;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.13335</link><description>&lt;p&gt;
&#20840;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#26174;&#33879;&#24615;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Full Bayesian Significance Testing for Neural Networks. (arXiv:2401.13335v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13335
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20840;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#26174;&#33879;&#24615;&#26816;&#39564;&#26041;&#27861;&#65288;nFBST&#65289;&#65292;&#36890;&#36807;&#21033;&#29992;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#25311;&#21512;&#38750;&#32447;&#24615;&#21644;&#22810;&#32500;&#20851;&#31995;&#65292;&#24182;&#35745;&#31639;&#35777;&#25454;&#20540;&#26469;&#26367;&#20195;&#20256;&#32479;&#26041;&#27861;&#20013;&#30340;&#29702;&#35770;&#25512;&#23548;&#65292;&#35813;&#26041;&#27861;&#33021;&#22815;&#27979;&#35797;&#20840;&#23616;&#12289;&#23616;&#37096;&#21644;&#23454;&#20363;&#32423;&#30340;&#26174;&#33879;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26174;&#33879;&#24615;&#26816;&#39564;&#26088;&#22312;&#30830;&#23450;&#32473;&#23450;&#35266;&#27979;&#32467;&#26524;&#65292;&#20851;&#20110;&#24635;&#20307;&#20998;&#24067;&#30340;&#21629;&#39064;&#26159;&#21542;&#20026;&#30495;&#12290;&#28982;&#32780;&#65292;&#20256;&#32479;&#30340;&#26174;&#33879;&#24615;&#26816;&#39564;&#36890;&#24120;&#38656;&#35201;&#25512;&#23548;&#20986;&#26816;&#39564;&#32479;&#35745;&#37327;&#30340;&#20998;&#24067;&#65292;&#26080;&#27861;&#22788;&#29702;&#22797;&#26434;&#30340;&#38750;&#32447;&#24615;&#20851;&#31995;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#20840;&#36125;&#21494;&#26031;&#26174;&#33879;&#24615;&#26816;&#39564;&#26041;&#27861;&#65292;&#31216;&#20026;nFBST&#65292;&#26088;&#22312;&#20811;&#26381;&#20256;&#32479;&#26041;&#27861;&#22312;&#20851;&#31995;&#34920;&#24449;&#26041;&#38754;&#30340;&#23616;&#38480;&#24615;&#12290;&#21033;&#29992;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#25311;&#21512;&#38750;&#32447;&#24615;&#21644;&#22810;&#32500;&#20851;&#31995;&#65292;&#24182;&#36890;&#36807;&#35745;&#31639;&#35777;&#25454;&#20540;&#32780;&#19981;&#26159;&#36827;&#34892;&#32321;&#29712;&#30340;&#29702;&#35770;&#25512;&#23548;&#26469;&#36991;&#20813;&#38169;&#35823;&#12290;&#27492;&#22806;&#65292;nFBST&#36824;&#21487;&#20197;&#27979;&#35797;&#20840;&#23616;&#12289;&#23616;&#37096;&#21644;&#23454;&#20363;&#32423;&#30340;&#26174;&#33879;&#24615;&#65292;&#36825;&#26159;&#20043;&#21069;&#30340;&#26816;&#39564;&#26041;&#27861;&#25152;&#19981;&#20851;&#27880;&#30340;&#12290;&#27492;&#22806;&#65292;nFBST&#26159;&#19968;&#20010;&#36890;&#29992;&#26694;&#26550;&#65292;&#21487;&#20197;&#26681;&#25454;&#25152;&#36873;&#30340;&#24230;&#37327;&#36827;&#34892;&#25193;&#23637;&#65292;&#22914;Grad-nFBST&#65292;LRP-nFBST&#65292;DeepLIFT-nFBST&#12290;
&lt;/p&gt;
&lt;p&gt;
Significance testing aims to determine whether a proposition about the population distribution is the truth or not given observations. However, traditional significance testing often needs to derive the distribution of the testing statistic, failing to deal with complex nonlinear relationships. In this paper, we propose to conduct Full Bayesian Significance Testing for neural networks, called \textit{n}FBST, to overcome the limitation in relationship characterization of traditional approaches. A Bayesian neural network is utilized to fit the nonlinear and multi-dimensional relationships with small errors and avoid hard theoretical derivation by computing the evidence value. Besides, \textit{n}FBST can test not only global significance but also local and instance-wise significance, which previous testing methods don't focus on. Moreover, \textit{n}FBST is a general framework that can be extended based on the measures selected, such as Grad-\textit{n}FBST, LRP-\textit{n}FBST, DeepLIFT-\t
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26174;&#24335;&#30340;&#36335;&#24452;XVA&#35745;&#31639;&#26041;&#26696;&#65292;&#20351;&#29992;&#27169;&#25311;/&#22238;&#24402;&#26041;&#27861;&#22788;&#29702;&#20132;&#21449;&#20272;&#20540;&#35843;&#25972;&#65288;XVA&#65289;&#26041;&#31243;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#26696;&#22312;&#39640;&#32500;&#21644;&#28151;&#21512;&#39118;&#38505;XVA&#29992;&#20363;&#20013;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2401.13314</link><description>&lt;p&gt;
&#19968;&#31181;&#29992;&#20110;&#36335;&#24452;XVA&#35745;&#31639;&#30340;&#26174;&#24335;&#26041;&#26696;
&lt;/p&gt;
&lt;p&gt;
An Explicit Scheme for Pathwise XVA Computations. (arXiv:2401.13314v1 [q-fin.RM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13314
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26174;&#24335;&#30340;&#36335;&#24452;XVA&#35745;&#31639;&#26041;&#26696;&#65292;&#20351;&#29992;&#27169;&#25311;/&#22238;&#24402;&#26041;&#27861;&#22788;&#29702;&#20132;&#21449;&#20272;&#20540;&#35843;&#25972;&#65288;XVA&#65289;&#26041;&#31243;&#65292;&#24182;&#35777;&#26126;&#20102;&#35813;&#26041;&#26696;&#22312;&#39640;&#32500;&#21644;&#28151;&#21512;&#39118;&#38505;XVA&#29992;&#20363;&#20013;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38024;&#23545;&#36164;&#26412;&#20316;&#20026;&#36148;&#29616;&#20445;&#35777;&#37329;&#30340;&#36164;&#37329;&#26469;&#28304;&#30340;&#30495;&#23454;&#24773;&#20917;&#19979;&#65292;&#20132;&#21449;&#20272;&#20540;&#35843;&#25972;&#65288;XVA&#65289;&#26041;&#31243;&#30340;&#21160;&#26426;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#27169;&#25311;/&#22238;&#24402;&#26041;&#26696;&#29992;&#20110;&#19968;&#31867;&#39044;&#26399;BSDE&#65292;&#20854;&#20013;&#31995;&#25968;&#28041;&#21450;&#35299;&#30340;&#38789;&#37096;&#20998;&#30340;&#26465;&#20214;&#26399;&#26395;&#32570;&#22833;&#29575;&#12290;&#35813;&#26041;&#26696;&#22312;&#26102;&#38388;&#19978;&#26159;&#26174;&#24335;&#30340;&#65292;&#24182;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#26368;&#23567;&#20108;&#20056;&#21644;&#20998;&#20301;&#25968;&#22238;&#24402;&#36827;&#34892;&#23884;&#20837;&#26465;&#20214;&#26399;&#26395;&#21644;&#26399;&#26395;&#32570;&#22833;&#29575;&#30340;&#35745;&#31639;&#12290;&#19968;&#31181;&#21518;&#39564;&#33945;&#29305;&#21345;&#32599;&#39564;&#35777;&#36807;&#31243;&#20801;&#35768;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#39588;&#35780;&#20272;&#26041;&#26696;&#30340;&#22238;&#24402;&#35823;&#24046;&#12290;&#23558;&#35813;&#26041;&#26696;&#19982;Picard&#36845;&#20195;&#30456;&#27604;&#36739;&#65292;&#35777;&#26126;&#20102;&#23427;&#22312;&#39640;&#32500;&#21644;&#28151;&#21512;&#24066;&#22330;/&#36829;&#32422;&#39118;&#38505;XVA&#30340;&#29992;&#20363;&#20013;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by the equations of cross valuation adjustments (XVAs) in the realistic case where capital is deemed fungible as a source of funding for variation margin, we introduce a simulation/regression scheme for a class of anticipated BSDEs, where the coefficient entails a conditional expected shortfall of the martingale part of the solution. The scheme is explicit in time and uses neural network least-squares and quantile regressions for the embedded conditional expectations and expected shortfall computations. An a posteriori Monte Carlo validation procedure allows assessing the regression error of the scheme at each time step. The superiority of this scheme with respect to Picard iterations is illustrated in a high-dimensional and hybrid market/default risks XVA use-case.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#37327;&#23376;&#33258;&#28982;&#26799;&#24230;&#26041;&#27861;&#65292;&#21435;&#38500;&#20102;&#21333;&#35843;&#24615;&#26465;&#20214;&#65292;&#36890;&#36807;&#25552;&#20379;&#29702;&#35770;&#21644;&#25968;&#20540;&#35777;&#25454;&#26469;&#25903;&#25345;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2401.13237</link><description>&lt;p&gt;
&#26080;&#21333;&#35843;&#24615;&#30340;&#37327;&#23376;&#33258;&#28982;&#26799;&#24230;
&lt;/p&gt;
&lt;p&gt;
Quantum natural gradient without monotonicity. (arXiv:2401.13237v1 [quant-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13237
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#37327;&#23376;&#33258;&#28982;&#26799;&#24230;&#26041;&#27861;&#65292;&#21435;&#38500;&#20102;&#21333;&#35843;&#24615;&#26465;&#20214;&#65292;&#36890;&#36807;&#25552;&#20379;&#29702;&#35770;&#21644;&#25968;&#20540;&#35777;&#25454;&#26469;&#25903;&#25345;&#35813;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#28982;&#26799;&#24230;&#26159;&#19968;&#31181;&#20449;&#24687;&#20960;&#20309;&#20248;&#21270;&#26041;&#27861;&#65292;&#22312;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65288;&#22914;&#31070;&#32463;&#32593;&#32476;&#65289;&#21442;&#25968;&#20272;&#35745;&#20013;&#21457;&#25381;&#30528;&#33267;&#20851;&#37325;&#35201;&#30340;&#20316;&#29992;&#12290;&#20026;&#20102;&#23558;&#33258;&#28982;&#26799;&#24230;&#24212;&#29992;&#20110;&#37327;&#23376;&#31995;&#32479;&#65292;&#24341;&#20837;&#20102;&#37327;&#23376;&#33258;&#28982;&#26799;&#24230;&#65288;QNG&#65289;&#24182;&#22312;&#22122;&#22768;&#20013;&#31561;&#35268;&#27169;&#35774;&#22791;&#20013;&#21152;&#20197;&#21033;&#29992;&#12290;&#27492;&#22806;&#65292;&#36824;&#23454;&#26045;&#20102;&#19968;&#31181;&#25968;&#23398;&#19978;&#31561;&#25928;&#30340; QNG &#26041;&#27861;&#65292;&#31216;&#20026;&#38543;&#26426;&#37325;&#26500;&#26041;&#27861;&#65292;&#20197;&#25552;&#39640;&#37327;&#23376;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#36825;&#20123;&#26041;&#27861;&#22522;&#20110;&#23545;&#25968;&#23548;&#25968;&#65288;SLD&#65289;&#24230;&#37327;&#65292;&#23427;&#26159;&#21333;&#35843;&#24230;&#37327;&#20043;&#19968;&#12290;&#21040;&#30446;&#21069;&#20026;&#27490;&#65292;&#21333;&#35843;&#24615;&#19968;&#30452;&#34987;&#35748;&#20026;&#26159;&#26500;&#24314;&#29289;&#29702;&#20960;&#20309;&#30340;&#25351;&#23548;&#21407;&#21017;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21435;&#38500;&#21333;&#35843;&#24615;&#26465;&#20214;&#30340;&#24191;&#20041;QNG&#12290;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#20102;&#22312;&#20256;&#32479;QNG&#20013;&#65292;&#21333;&#35843;&#24615;&#26159;&#19968;&#20010;&#20851;&#38190;&#26465;&#20214;&#12290;&#38543;&#21518;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#20998;&#26512;&#21644;&#25968;&#20540;&#35777;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Natural gradient (NG) is an information-geometric optimization method that plays a crucial role, especially in the estimation of parameters for machine learning models like neural networks. To apply NG to quantum systems, the quantum natural gradient (QNG) was introduced and utilized for noisy intermediate-scale devices. Additionally, a mathematically equivalent approach to QNG, known as the stochastic reconfiguration method, has been implemented to enhance the performance of quantum Monte Carlo methods. It is worth noting that these methods are based on the symmetric logarithmic derivative (SLD) metric, which is one of the monotone metrics. So far, monotonicity has been believed to be a guiding principle to construct a geometry in physics. In this paper, we propose generalized QNG by removing the condition of monotonicity. Initially, we demonstrate that monotonicity is a crucial condition for conventional QNG to be optimal. Subsequently, we provide analytical and numerical evidence sh
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#20851;&#20110;&#32852;&#37030;&#23398;&#20064;&#20013;&#23616;&#37096;&#20248;&#21270;&#26041;&#27861;&#30340;&#30740;&#31350;&#65292;&#20027;&#35201;&#21253;&#25324;&#23545;FedAvg&#31639;&#27861;&#30340;&#30028;&#38480;&#25506;&#32034;&#20197;&#21450;&#25552;&#20986;&#20102;&#32852;&#37030;&#21152;&#36895;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;FedAc&#65289;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.13216</link><description>&lt;p&gt;
&#20851;&#20110;&#32852;&#37030;&#23398;&#20064;&#30340;&#21407;&#21017;&#24615;&#23616;&#37096;&#20248;&#21270;&#26041;&#27861;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Principled Local Optimization Methods for Federated Learning. (arXiv:2401.13216v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13216
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#20851;&#20110;&#32852;&#37030;&#23398;&#20064;&#20013;&#23616;&#37096;&#20248;&#21270;&#26041;&#27861;&#30340;&#30740;&#31350;&#65292;&#20027;&#35201;&#21253;&#25324;&#23545;FedAvg&#31639;&#27861;&#30340;&#30028;&#38480;&#25506;&#32034;&#20197;&#21450;&#25552;&#20986;&#20102;&#32852;&#37030;&#21152;&#36895;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;FedAc&#65289;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#26159;&#19968;&#31181;&#20998;&#24067;&#24335;&#23398;&#20064;&#33539;&#24335;&#65292;&#36890;&#36807;&#22312;&#35774;&#22791;&#19978;&#21327;&#21516;&#36827;&#34892;&#23398;&#20064;&#65292;&#24050;&#32463;&#25104;&#20026;&#21435;&#20013;&#24515;&#21270;&#20154;&#24037;&#26234;&#33021;&#24212;&#29992;&#30340;&#19968;&#31181;&#26377;&#21069;&#26223;&#30340;&#26041;&#27861;&#12290;&#20687;&#32852;&#37030;&#24179;&#22343;&#65288;FedAvg&#65289;&#36825;&#26679;&#30340;&#23616;&#37096;&#20248;&#21270;&#26041;&#27861;&#26159;&#32852;&#37030;&#23398;&#20064;&#24212;&#29992;&#20013;&#26368;&#31361;&#20986;&#30340;&#26041;&#27861;&#12290;&#23613;&#31649;&#36825;&#20123;&#26041;&#27861;&#31616;&#21333;&#19988;&#21463;&#27426;&#36814;&#65292;&#20294;&#23545;&#23616;&#37096;&#20248;&#21270;&#26041;&#27861;&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#19981;&#22815;&#28165;&#26224;&#12290;&#26412;&#35770;&#25991;&#26088;&#22312;&#25512;&#36827;&#23616;&#37096;&#26041;&#27861;&#30340;&#29702;&#35770;&#22522;&#30784;&#65292;&#20027;&#35201;&#21253;&#25324;&#20197;&#19979;&#19977;&#20010;&#26041;&#38754;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#20026;FedAvg&#24314;&#31435;&#20102;&#20005;&#26684;&#30340;&#30028;&#38480;&#65292;&#36825;&#26159;&#32852;&#37030;&#23398;&#20064;&#20013;&#26368;&#27969;&#34892;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;FedAvg&#21487;&#33021;&#21463;&#21040;&#30340;&#19968;&#20010;&#25105;&#20204;&#31216;&#20043;&#20026;&#36845;&#20195;&#20559;&#35265;&#30340;&#27010;&#24565;&#65292;&#24182;&#19988;&#35828;&#26126;&#20102;&#39069;&#22806;&#30340;&#19977;&#38454;&#24179;&#28369;&#24615;&#20551;&#35774;&#22914;&#20309;&#20943;&#36731;&#36825;&#31181;&#24433;&#21709;&#24182;&#23548;&#33268;&#26356;&#22909;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;&#25105;&#20204;&#20174;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#35282;&#24230;&#35299;&#37322;&#20102;&#36825;&#19968;&#29616;&#35937;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#32852;&#37030;&#21152;&#36895;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;FedAc&#65289;&#65292;&#36825;&#26159;&#31532;&#19968;&#20010;&#26377;&#21407;&#21017;&#24615;&#19988;&#36895;&#24230;&#26356;&#24555;&#30340;&#32852;&#37030;&#23398;&#20064;&#20248;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated Learning (FL), a distributed learning paradigm that scales on-device learning collaboratively, has emerged as a promising approach for decentralized AI applications. Local optimization methods such as Federated Averaging (FedAvg) are the most prominent methods for FL applications. Despite their simplicity and popularity, the theoretical understanding of local optimization methods is far from clear. This dissertation aims to advance the theoretical foundation of local methods in the following three directions.  First, we establish sharp bounds for FedAvg, the most popular algorithm in Federated Learning. We demonstrate how FedAvg may suffer from a notion we call iterate bias, and how an additional third-order smoothness assumption may mitigate this effect and lead to better convergence rates. We explain this phenomenon from a Stochastic Differential Equation (SDE) perspective.  Second, we propose Federated Accelerated Stochastic Gradient Descent (FedAc), the first principled a
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#26368;&#20248;&#20256;&#36755;&#36827;&#34892;&#20998;&#24067;&#24335;&#23545;&#25239;&#35299;&#37322;&#30340;&#26041;&#27861;DISCOUNT&#65292;&#23558;&#23545;&#25239;&#35299;&#37322;&#30340;&#27010;&#24565;&#25193;&#23637;&#21040;&#25972;&#20010;&#36755;&#20837;&#36755;&#20986;&#20998;&#24067;&#65292;&#24182;&#36890;&#36807;&#32479;&#35745;&#32622;&#20449;&#24230;&#26469;&#25903;&#25745;&#36825;&#19968;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.13112</link><description>&lt;p&gt;
DISCOUNT: &#20351;&#29992;&#26368;&#20248;&#20256;&#36755;&#36827;&#34892;&#20998;&#24067;&#24335;&#23545;&#25239;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
DISCOUNT: Distributional Counterfactual Explanation With Optimal Transport. (arXiv:2401.13112v1 [cs.AI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13112
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20351;&#29992;&#26368;&#20248;&#20256;&#36755;&#36827;&#34892;&#20998;&#24067;&#24335;&#23545;&#25239;&#35299;&#37322;&#30340;&#26041;&#27861;DISCOUNT&#65292;&#23558;&#23545;&#25239;&#35299;&#37322;&#30340;&#27010;&#24565;&#25193;&#23637;&#21040;&#25972;&#20010;&#36755;&#20837;&#36755;&#20986;&#20998;&#24067;&#65292;&#24182;&#36890;&#36807;&#32479;&#35745;&#32622;&#20449;&#24230;&#26469;&#25903;&#25745;&#36825;&#19968;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#35299;&#37322;&#26159;&#22312;&#40657;&#30418;&#20915;&#31574;&#27169;&#22411;&#20013;&#25552;&#20379;&#27934;&#23519;&#21147;&#21644;&#21487;&#35299;&#37322;&#24615;&#30340;&#20107;&#23454;&#26041;&#27861;&#65292;&#36890;&#36807;&#30830;&#23450;&#23548;&#33268;&#19981;&#21516;&#32467;&#26524;&#30340;&#26367;&#20195;&#36755;&#20837;&#23454;&#20363;&#26469;&#23454;&#29616;&#12290;&#26412;&#25991;&#23558;&#23545;&#25239;&#35299;&#37322;&#30340;&#27010;&#24565;&#25193;&#23637;&#21040;&#20998;&#24067;&#19978;&#19979;&#25991;&#65292;&#20174;&#20010;&#20307;&#25968;&#25454;&#28857;&#25193;&#22823;&#21040;&#25972;&#20010;&#36755;&#20837;&#36755;&#20986;&#20998;&#24067;&#65292;&#21629;&#21517;&#20026;&#20998;&#24067;&#24335;&#23545;&#25239;&#35299;&#37322;&#12290;&#22312;&#20998;&#24067;&#24335;&#23545;&#25239;&#35299;&#37322;&#20013;&#65292;&#25105;&#20204;&#30340;&#37325;&#28857;&#36716;&#21521;&#20998;&#26512;&#20107;&#23454;&#21644;&#23545;&#25239;&#30340;&#20998;&#24067;&#23646;&#24615;&#65292;&#31867;&#20284;&#20110;&#35780;&#20272;&#20010;&#20307;&#23454;&#20363;&#21450;&#20854;&#32467;&#26524;&#20915;&#31574;&#30340;&#32463;&#20856;&#26041;&#27861;&#12290;&#25105;&#20204;&#21033;&#29992;&#26368;&#20248;&#20256;&#36755;&#26469;&#26500;&#24314;&#19968;&#20010;&#26426;&#20250;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#65292;&#26088;&#22312;&#23548;&#20986;&#19982;&#20107;&#23454;&#23545;&#24212;&#30340;&#23545;&#25239;&#20998;&#24067;&#65292;&#20197;&#32479;&#35745;&#32622;&#20449;&#24230;&#20570;&#25903;&#25745;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#20248;&#21270;&#26041;&#27861;DISCOUNT&#22312;&#36755;&#20837;&#21644;&#36755;&#20986;&#20998;&#24067;&#20043;&#38388;&#24179;&#34913;&#36825;&#31181;&#32622;&#20449;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Counterfactual Explanations (CE) is the de facto method for providing insight and interpretability in black-box decision-making models by identifying alternative input instances that lead to different outcomes. This paper extends the concept of CEs to a distributional context, broadening the scope from individual data points to entire input and output distributions, named Distributional Counterfactual Explanation (DCE). In DCE, our focus shifts to analyzing the distributional properties of the factual and counterfactual, drawing parallels to the classical approach of assessing individual instances and their resulting decisions. We leverage Optimal Transport (OT) to frame a chance-constrained optimization problem, aiming to derive a counterfactual distribution that closely aligns with its factual counterpart, substantiated by statistical confidence. Our proposed optimization method, DISCOUNT, strategically balances this confidence across both input and output distributions. This algorit
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#27010;&#29575;&#38656;&#27714;&#39044;&#27979;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#22312;&#29616;&#26377;&#30340;DeepAR&#27169;&#22411;&#20013;&#38598;&#25104;&#20102;GNN&#32534;&#30721;&#22120;&#65292;&#24182;&#37319;&#29992;&#22522;&#20110;&#25991;&#31456;&#23646;&#24615;&#30456;&#20284;&#24615;&#26500;&#24314;&#22270;&#30340;&#31574;&#30053;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.13096</link><description>&lt;p&gt;
&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#27010;&#29575;&#38656;&#27714;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Probabilistic Demand Forecasting with Graph Neural Networks. (arXiv:2401.13096v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13096
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#27010;&#29575;&#38656;&#27714;&#39044;&#27979;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#22312;&#29616;&#26377;&#30340;DeepAR&#27169;&#22411;&#20013;&#38598;&#25104;&#20102;GNN&#32534;&#30721;&#22120;&#65292;&#24182;&#37319;&#29992;&#22522;&#20110;&#25991;&#31456;&#23646;&#24615;&#30456;&#20284;&#24615;&#26500;&#24314;&#22270;&#30340;&#31574;&#30053;&#65292;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#20248;&#20110;&#20256;&#32479;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38656;&#27714;&#39044;&#27979;&#26159;&#19968;&#31181;&#37325;&#35201;&#30340;&#21830;&#19994;&#24212;&#29992;&#26696;&#20363;&#65292;&#23427;&#21487;&#20197;&#24110;&#21161;&#38646;&#21806;&#21830;&#20248;&#21270;&#24211;&#23384;&#35268;&#21010;&#12289;&#29289;&#27969;&#21644;&#26680;&#24515;&#19994;&#21153;&#20915;&#31574;&#12290;&#38656;&#27714;&#39044;&#27979;&#30340;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#26159;&#32771;&#34385;&#25991;&#31456;&#20043;&#38388;&#30340;&#20851;&#31995;&#21644;&#20114;&#21160;&#12290;&#22823;&#22810;&#25968;&#29616;&#20195;&#39044;&#27979;&#26041;&#27861;&#25552;&#20379;&#29420;&#31435;&#30340;&#25991;&#31456;&#32423;&#39044;&#27979;&#65292;&#19981;&#32771;&#34385;&#30456;&#20851;&#25991;&#31456;&#30340;&#24433;&#21709;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#23581;&#35797;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#26469;&#35299;&#20915;&#36825;&#20010;&#25361;&#25112;&#65292;&#24182;&#21462;&#24471;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;&#26412;&#25991;&#22312;&#20043;&#21069;&#30340;GNNs&#30740;&#31350;&#22522;&#30784;&#19978;&#20570;&#20986;&#20102;&#20004;&#20010;&#36129;&#29486;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23558;GNN&#32534;&#30721;&#22120;&#38598;&#25104;&#21040;&#26368;&#20808;&#36827;&#30340;DeepAR&#27169;&#22411;&#20013;&#12290;&#36825;&#20010;&#32452;&#21512;&#27169;&#22411;&#20135;&#29983;&#27010;&#29575;&#39044;&#27979;&#65292;&#36825;&#22312;&#19981;&#30830;&#23450;&#24615;&#19979;&#30340;&#20915;&#31574;&#21046;&#23450;&#20013;&#33267;&#20851;&#37325;&#35201;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#25991;&#31456;&#23646;&#24615;&#30456;&#20284;&#24615;&#26500;&#24314;&#22270;&#65292;&#36991;&#20813;&#20381;&#36182;&#39044;&#23450;&#20041;&#30340;&#22270;&#32467;&#26500;&#12290;&#23545;&#19977;&#20010;&#23454;&#38469;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22987;&#32456;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Demand forecasting is a prominent business use case that allows retailers to optimize inventory planning, logistics, and core business decisions. One of the key challenges in demand forecasting is accounting for relationships and interactions between articles. Most modern forecasting approaches provide independent article-level predictions that do not consider the impact of related articles. Recent research has attempted addressing this challenge using Graph Neural Networks (GNNs) and showed promising results. This paper builds on previous research on GNNs and makes two contributions. First, we integrate a GNN encoder into a state-of-the-art DeepAR model. The combined model produces probabilistic forecasts, which are crucial for decision-making under uncertainty. Second, we propose to build graphs using article attribute similarity, which avoids reliance on a pre-defined graph structure. Experiments on three real-world datasets show that the proposed approach consistently outperforms n
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#36890;&#36807;&#31070;&#32463;&#20449;&#24687;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#26469;&#35780;&#20272;&#22899;&#24615;&#36816;&#21160;&#21592;&#33041;&#38663;&#33633;&#30340;&#26041;&#27861;&#12290;&#30456;&#27604;&#20256;&#32479;&#30340;&#20020;&#24202;&#26041;&#27861;&#65292;&#22312;&#22899;&#24615;&#36816;&#21160;&#21592;&#20013;&#35786;&#26029;&#33041;&#38663;&#33633;&#23384;&#22312;&#19968;&#20123;&#23616;&#38480;&#24615;&#65292;&#32780;&#36825;&#20123;&#26032;&#25216;&#26415;&#21487;&#20197;&#36890;&#36807;&#25968;&#25454;&#20998;&#26512;&#25214;&#20986;&#19982;&#24615;&#21035;&#30456;&#20851;&#30340;&#29983;&#29289;&#26426;&#21046;&#65292;&#20174;&#32780;&#22635;&#34917;&#36825;&#19968;&#24046;&#36317;&#12290;</title><link>http://arxiv.org/abs/2401.13045</link><description>&lt;p&gt;
&#35780;&#20272;&#22899;&#24615;&#36816;&#21160;&#21592;&#33041;&#38663;&#33633;&#65306;&#31070;&#32463;&#20449;&#24687;&#23398;&#30340;&#20316;&#29992;&#65311;
&lt;/p&gt;
&lt;p&gt;
Assessment of Sports Concussion in Female Athletes: A Role for Neuroinformatics?. (arXiv:2401.13045v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13045
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#36890;&#36807;&#31070;&#32463;&#20449;&#24687;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#26469;&#35780;&#20272;&#22899;&#24615;&#36816;&#21160;&#21592;&#33041;&#38663;&#33633;&#30340;&#26041;&#27861;&#12290;&#30456;&#27604;&#20256;&#32479;&#30340;&#20020;&#24202;&#26041;&#27861;&#65292;&#22312;&#22899;&#24615;&#36816;&#21160;&#21592;&#20013;&#35786;&#26029;&#33041;&#38663;&#33633;&#23384;&#22312;&#19968;&#20123;&#23616;&#38480;&#24615;&#65292;&#32780;&#36825;&#20123;&#26032;&#25216;&#26415;&#21487;&#20197;&#36890;&#36807;&#25968;&#25454;&#20998;&#26512;&#25214;&#20986;&#19982;&#24615;&#21035;&#30456;&#20851;&#30340;&#29983;&#29289;&#26426;&#21046;&#65292;&#20174;&#32780;&#22635;&#34917;&#36825;&#19968;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36807;&#21435;&#30340;&#21313;&#24180;&#20013;&#65292;&#22899;&#24615;&#36816;&#21160;&#21592;&#33041;&#38663;&#33633;&#30340;&#22797;&#26434;&#24615;&#21464;&#24471;&#26126;&#26174;&#12290;&#20256;&#32479;&#30340;&#20020;&#24202;&#35786;&#26029;&#33041;&#38663;&#33633;&#30340;&#26041;&#27861;&#22312;&#24212;&#29992;&#20110;&#22899;&#24615;&#36816;&#21160;&#21592;&#26102;&#23384;&#22312;&#23616;&#38480;&#24615;&#65292;&#24448;&#24448;&#26080;&#27861;&#25429;&#25417;&#21040;&#33041;&#32467;&#26500;&#21644;&#21151;&#33021;&#30340;&#32454;&#24494;&#21464;&#21270;&#12290;&#20808;&#36827;&#30340;&#31070;&#32463;&#20449;&#24687;&#23398;&#25216;&#26415;&#21644;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#22312;&#36825;&#26041;&#38754;&#24050;&#32463;&#25104;&#20026;&#23453;&#36149;&#30340;&#36164;&#20135;&#12290;&#34429;&#28982;&#36825;&#20123;&#25216;&#26415;&#22312;&#29702;&#35299;&#30007;&#24615;&#36816;&#21160;&#21592;&#30340;&#33041;&#38663;&#33633;&#26041;&#38754;&#24050;&#32463;&#34987;&#24191;&#27867;&#24212;&#29992;&#65292;&#20294;&#22312;&#25105;&#20204;&#23545;&#20110;&#23427;&#20204;&#23545;&#22899;&#24615;&#36816;&#21160;&#21592;&#30340;&#26377;&#25928;&#24615;&#30340;&#29702;&#35299;&#19978;&#20173;&#23384;&#22312;&#26174;&#33879;&#24046;&#36317;&#12290;&#36890;&#36807;&#21033;&#29992;&#26426;&#22120;&#23398;&#20064;&#30340;&#24378;&#22823;&#25968;&#25454;&#20998;&#26512;&#33021;&#21147;&#65292;&#30740;&#31350;&#20154;&#21592;&#21487;&#20197;&#23558;&#35266;&#23519;&#21040;&#30340;&#34920;&#22411;&#31070;&#32463;&#24433;&#20687;&#25968;&#25454;&#32852;&#31995;&#21040;&#29305;&#23450;&#20110;&#24615;&#21035;&#30340;&#29983;&#29289;&#26426;&#21046;&#65292;&#25581;&#31034;&#22899;&#24615;&#36816;&#21160;&#21592;&#33041;&#38663;&#33633;&#30340;&#22885;&#31192;&#12290;&#27492;&#22806;&#65292;&#23884;&#20837;&#26426;&#22120;&#23398;&#20064;&#30340;&#26041;&#27861;&#36824;&#21487;&#20197;&#22312;&#30740;&#31350;&#20013;&#36827;&#34892;&#20132;&#21449;&#39564;&#35777;&#65292;&#36827;&#19968;&#27493;&#26816;&#39564;&#24615;&#21035;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Over the past decade, the intricacies of sports-related concussions among female athletes have become readily apparent. Traditional clinical methods for diagnosing concussions suffer limitations when applied to female athletes, often failing to capture subtle changes in brain structure and function. Advanced neuroinformatics techniques and machine learning models have become invaluable assets in this endeavor. While these technologies have been extensively employed in understanding concussion in male athletes, there remains a significant gap in our comprehension of their effectiveness for female athletes. With its remarkable data analysis capacity, machine learning offers a promising avenue to bridge this deficit. By harnessing the power of machine learning, researchers can link observed phenotypic neuroimaging data to sex-specific biological mechanisms, unraveling the mysteries of concussions in female athletes. Furthermore, embedding methods within machine learning enable examining b
&lt;/p&gt;</description></item><item><title>&#23545;&#20110;&#24490;&#29615;&#27169;&#22411;&#20013;&#21547;&#26377;&#38544;&#34255;&#22240;&#21464;&#37327;&#30340;&#22240;&#26524;&#21457;&#29616;&#65292;&#24050;&#32463;&#20986;&#29616;&#20102;&#33021;&#22815;&#22788;&#29702;&#36825;&#31181;&#24773;&#20917;&#30340;&#22810;&#31181;&#25216;&#26415;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2401.13009</link><description>&lt;p&gt;
&#24490;&#29615;&#27169;&#22411;&#20013;&#21547;&#26377;&#38544;&#34255;&#22240;&#21464;&#37327;&#30340;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#30340;&#27604;&#36739;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Comparative Study of Causal Discovery Methods for Cyclic Models with Hidden Confounders. (arXiv:2401.13009v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.13009
&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#24490;&#29615;&#27169;&#22411;&#20013;&#21547;&#26377;&#38544;&#34255;&#22240;&#21464;&#37327;&#30340;&#22240;&#26524;&#21457;&#29616;&#65292;&#24050;&#32463;&#20986;&#29616;&#20102;&#33021;&#22815;&#22788;&#29702;&#36825;&#31181;&#24773;&#20917;&#30340;&#22810;&#31181;&#25216;&#26415;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22914;&#20170;&#65292;&#23545;&#22240;&#26524;&#21457;&#29616;&#30340;&#38656;&#27714;&#26080;&#22788;&#19981;&#22312;&#12290;&#29702;&#35299;&#31995;&#32479;&#20013;&#37096;&#20998;&#20043;&#38388;&#30340;&#38543;&#26426;&#20381;&#36182;&#24615;&#20197;&#21450;&#23454;&#38469;&#30340;&#22240;&#26524;&#20851;&#31995;&#23545;&#31185;&#23398;&#30340;&#21508;&#20010;&#37096;&#20998;&#37117;&#33267;&#20851;&#37325;&#35201;&#12290;&#22240;&#27492;&#65292;&#23547;&#25214;&#21487;&#38752;&#30340;&#26041;&#27861;&#26469;&#26816;&#27979;&#22240;&#26524;&#26041;&#21521;&#30340;&#38656;&#27714;&#19981;&#26029;&#22686;&#38271;&#12290;&#22312;&#36807;&#21435;&#30340;50&#24180;&#37324;&#65292;&#20986;&#29616;&#20102;&#35768;&#22810;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#65292;&#20294;&#22823;&#22810;&#25968;&#20165;&#36866;&#29992;&#20110;&#31995;&#32479;&#27809;&#26377;&#21453;&#39304;&#29615;&#36335;&#24182;&#19988;&#20855;&#26377;&#22240;&#26524;&#20805;&#20998;&#24615;&#30340;&#20551;&#35774;&#65292;&#21363;&#27809;&#26377;&#26410;&#27979;&#37327;&#30340;&#23376;&#31995;&#32479;&#33021;&#22815;&#24433;&#21709;&#22810;&#20010;&#24050;&#27979;&#37327;&#21464;&#37327;&#12290;&#36825;&#26159;&#19981;&#24184;&#30340;&#65292;&#22240;&#20026;&#36825;&#20123;&#38480;&#21046;&#22312;&#23454;&#36341;&#20013;&#24448;&#24448;&#19981;&#33021;&#20551;&#23450;&#12290;&#21453;&#39304;&#26159;&#35768;&#22810;&#36807;&#31243;&#30340;&#19968;&#20010;&#37325;&#35201;&#29305;&#24615;&#65292;&#29616;&#23454;&#19990;&#30028;&#30340;&#31995;&#32479;&#24456;&#23569;&#26159;&#23436;&#20840;&#38548;&#31163;&#21644;&#23436;&#20840;&#27979;&#37327;&#30340;&#12290;&#24184;&#36816;&#30340;&#26159;&#65292;&#22312;&#26368;&#36817;&#20960;&#24180;&#20013;&#65292;&#24050;&#32463;&#21457;&#23637;&#20102;&#20960;&#31181;&#33021;&#22815;&#22788;&#29702;&#24490;&#29615;&#30340;&#12289;&#22240;&#26524;&#19981;&#20805;&#20998;&#30340;&#31995;&#32479;&#30340;&#25216;&#26415;&#12290;&#38543;&#30528;&#22810;&#31181;&#26041;&#27861;&#30340;&#20986;&#29616;&#65292;&#19968;&#31181;&#23454;&#38469;&#30340;&#24212;&#29992;&#26041;&#27861;&#24320;&#22987;&#21464;&#24471;&#21487;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Nowadays, the need for causal discovery is ubiquitous. A better understanding of not just the stochastic dependencies between parts of a system, but also the actual cause-effect relations, is essential for all parts of science. Thus, the need for reliable methods to detect causal directions is growing constantly. In the last 50 years, many causal discovery algorithms have emerged, but most of them are applicable only under the assumption that the systems have no feedback loops and that they are causally sufficient, i.e. that there are no unmeasured subsystems that can affect multiple measured variables. This is unfortunate since those restrictions can often not be presumed in practice. Feedback is an integral feature of many processes, and real-world systems are rarely completely isolated and fully measured. Fortunately, in recent years, several techniques, that can cope with cyclic, causally insufficient systems, have been developed. And with multiple methods available, a practical ap
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#26862;&#26519;&#20462;&#21098;&#26041;&#27861;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20860;&#39038;&#38543;&#26426;&#26862;&#26519;&#20934;&#30830;&#24615;&#21644;&#20915;&#31574;&#26641;&#21487;&#35299;&#37322;&#24615;&#30340;&#26041;&#27861;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#22823;&#22810;&#25968;&#24773;&#26223;&#19979;&#65292;&#36825;&#31181;&#26041;&#27861;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#38543;&#26426;&#26862;&#26519;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.05535</link><description>&lt;p&gt;
&#36890;&#36807;&#26862;&#26519;&#20462;&#21098;&#25552;&#39640;&#38543;&#26426;&#26862;&#26519;&#30340;&#20934;&#30830;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;
&lt;/p&gt;
&lt;p&gt;
Improving the Accuracy and Interpretability of Random Forests via Forest Pruning. (arXiv:2401.05535v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.05535
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26862;&#26519;&#20462;&#21098;&#26041;&#27861;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#20860;&#39038;&#38543;&#26426;&#26862;&#26519;&#20934;&#30830;&#24615;&#21644;&#20915;&#31574;&#26641;&#21487;&#35299;&#37322;&#24615;&#30340;&#26041;&#27861;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#22823;&#22810;&#25968;&#24773;&#26223;&#19979;&#65292;&#36825;&#31181;&#26041;&#27861;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#38543;&#26426;&#26862;&#26519;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25509;&#36817;&#20960;&#21313;&#24180;&#30340;&#21457;&#23637;&#20043;&#21518;&#65292;&#38543;&#26426;&#26862;&#26519;&#20173;&#28982;&#22312;&#21508;&#31181;&#23398;&#20064;&#38382;&#39064;&#20013;&#25552;&#20379;&#26368;&#20808;&#36827;&#30340;&#20934;&#30830;&#24615;&#65292;&#22312;&#36825;&#26041;&#38754;&#36229;&#36234;&#20102;&#20915;&#31574;&#26641;&#29978;&#33267;&#31070;&#32463;&#32593;&#32476;&#31561;&#26367;&#20195;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#12290;&#28982;&#32780;&#65292;&#20316;&#20026;&#19968;&#31181;&#38598;&#25104;&#26041;&#27861;&#65292;&#38543;&#26426;&#26862;&#26519;&#22312;&#35299;&#37322;&#24615;&#26041;&#38754;&#24448;&#24448;&#27604;&#20915;&#31574;&#26641;&#34920;&#29616;&#19981;&#20339;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20107;&#21518;&#26041;&#27861;&#65292;&#26088;&#22312;&#20860;&#39038;&#38543;&#26426;&#26862;&#26519;&#30340;&#20934;&#30830;&#24615;&#21644;&#20915;&#31574;&#26641;&#30340;&#21487;&#35299;&#37322;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26862;&#26519;&#20462;&#21098;&#26041;&#27861;&#65292;&#20197;&#22312;&#32473;&#23450;&#30340;&#38543;&#26426;&#26862;&#26519;&#20869;&#25214;&#21040;&#26368;&#20339;&#23376;&#26862;&#26519;&#65292;&#28982;&#21518;&#22312;&#36866;&#29992;&#30340;&#24773;&#20917;&#19979;&#23558;&#36873;&#23450;&#30340;&#26641;&#21512;&#24182;&#20026;&#19968;&#26869;&#12290;&#25105;&#20204;&#30340;&#31532;&#19968;&#31181;&#26041;&#27861;&#20381;&#36182;&#20110;&#32422;&#26463;&#31351;&#20030;&#25628;&#32034;&#65292;&#32780;&#31532;&#20108;&#31181;&#26041;&#27861;&#22522;&#20110;LASSO&#26041;&#27861;&#30340;&#25913;&#36827;&#12290;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#30340;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#65292;&#22312;&#22823;&#22810;&#25968;&#24773;&#26223;&#19979;&#65292;&#36825;&#20004;&#31181;&#26041;&#27861;&#20013;&#33267;&#23569;&#26377;&#19968;&#31181;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#38543;&#26426;&#26862;&#26519;&#30340;&#20934;&#30830;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Decades after their inception, random forests continue to provide state-of-the-art accuracy in a variety of learning problems, outperforming in this respect alternative machine learning algorithms such as decision trees or even neural networks. However, being an ensemble method, the one aspect where random forests tend to severely underperform decision trees is interpretability. In the present work, we propose a post-hoc approach that aims to have the best of both worlds: the accuracy of random forests and the interpretability of decision trees. To this end, we present two forest-pruning methods to find an optimal sub-forest within a given random forest, and then, when applicable, combine the selected trees into one. Our first method relies on constrained exhaustive search, while our second method is based on an adaptation of the LASSO methodology. Extensive experiments over synthetic and real world datasets show that, in the majority of scenarios, at least one of the two methods propo
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#28145;&#24230;&#28508;&#22312;&#21147;&#27169;&#22411;(DLFM)&#30340;&#36890;&#29992;&#22495;&#27169;&#22411;&#65292;&#20351;&#29992;&#20102;&#22522;&#20110;&#29289;&#29702;&#20449;&#24687;&#26680;&#30340;&#28145;&#24230;&#39640;&#26031;&#36807;&#31243;&#65292;&#36890;&#36807;&#36807;&#31243;&#21367;&#31215;&#26041;&#27861;&#20174;&#26222;&#36890;&#24494;&#20998;&#26041;&#31243;&#25512;&#23548;&#20986;&#26469;&#12290;DLFM&#33021;&#22815;&#25429;&#25417;&#39640;&#24230;&#38750;&#32447;&#24615;&#23454;&#38469;&#22810;&#36755;&#20986;&#26102;&#38388;&#24207;&#21015;&#20013;&#30340;&#21160;&#24577;&#24615;&#65292;&#24182;&#22312;&#22522;&#20934;&#27979;&#35797;&#19978;&#36798;&#21040;&#19982;&#19968;&#31995;&#21015;&#38750;&#29289;&#29702;&#32508;&#21512;&#27010;&#29575;&#27169;&#22411;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2311.14828</link><description>&lt;p&gt;
&#28145;&#24230;&#28508;&#22312;&#21147;&#27169;&#22411;&#65306;&#22522;&#20110;ODE&#30340;&#36807;&#31243;&#21367;&#31215;&#29992;&#20110;&#36125;&#21494;&#26031;&#28145;&#24230;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Deep Latent Force Models: ODE-based Process Convolutions for Bayesian Deep Learning. (arXiv:2311.14828v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2311.14828
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31216;&#20026;&#28145;&#24230;&#28508;&#22312;&#21147;&#27169;&#22411;(DLFM)&#30340;&#36890;&#29992;&#22495;&#27169;&#22411;&#65292;&#20351;&#29992;&#20102;&#22522;&#20110;&#29289;&#29702;&#20449;&#24687;&#26680;&#30340;&#28145;&#24230;&#39640;&#26031;&#36807;&#31243;&#65292;&#36890;&#36807;&#36807;&#31243;&#21367;&#31215;&#26041;&#27861;&#20174;&#26222;&#36890;&#24494;&#20998;&#26041;&#31243;&#25512;&#23548;&#20986;&#26469;&#12290;DLFM&#33021;&#22815;&#25429;&#25417;&#39640;&#24230;&#38750;&#32447;&#24615;&#23454;&#38469;&#22810;&#36755;&#20986;&#26102;&#38388;&#24207;&#21015;&#20013;&#30340;&#21160;&#24577;&#24615;&#65292;&#24182;&#22312;&#22522;&#20934;&#27979;&#35797;&#19978;&#36798;&#21040;&#19982;&#19968;&#31995;&#21015;&#38750;&#29289;&#29702;&#32508;&#21512;&#27010;&#29575;&#27169;&#22411;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24314;&#27169;&#39640;&#24230;&#38750;&#32447;&#24615;&#21160;&#24577;&#31995;&#32479;&#24182;&#20855;&#26377;&#31283;&#20581;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#26159;&#19968;&#39033;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#20219;&#21153;&#65292;&#36890;&#24120;&#38656;&#35201;&#19987;&#38376;&#35774;&#35745;&#30340;&#26041;&#27861;&#26469;&#35299;&#20915;&#38382;&#39064;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#36890;&#29992;&#22495;&#27169;&#22411;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#31216;&#20026;&#28145;&#24230;&#28508;&#22312;&#21147;&#27169;&#22411;(DLFM)&#65292;&#23427;&#26159;&#19968;&#20010;&#28145;&#24230;&#39640;&#26031;&#36807;&#31243;&#65292;&#27599;&#20010;&#23618;&#27425;&#37117;&#20855;&#26377;&#29289;&#29702;&#20449;&#24687;&#26680;&#65292;&#20351;&#29992;&#36807;&#31243;&#21367;&#31215;&#30340;&#26222;&#36890;&#24494;&#20998;&#26041;&#31243;&#25512;&#23548;&#20986;&#12290;&#25552;&#20986;&#20102;DLFM&#30340;&#20004;&#31181;&#19981;&#21516;&#24418;&#24335;&#65292;&#23427;&#20204;&#21033;&#29992;&#22522;&#20110;&#26435;&#31354;&#38388;&#21644;&#22522;&#20110;&#21464;&#20998;&#24863;&#24212;&#28857;&#30340;&#39640;&#26031;&#36807;&#31243;&#36817;&#20284;&#26041;&#27861;&#65292;&#37117;&#36866;&#29992;&#20110;&#21452;&#37325;&#38543;&#26426;&#21464;&#20998;&#25512;&#26029;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;DLFM&#25429;&#25417;&#39640;&#24230;&#38750;&#32447;&#24615;&#23454;&#38469;&#22810;&#36755;&#20986;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#20013;&#23384;&#22312;&#30340;&#21160;&#24577;&#24615;&#30340;&#32463;&#39564;&#35777;&#25454;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21457;&#29616;DLFM&#33021;&#22815;&#22312;&#22522;&#20934;&#27979;&#35797;&#19978;&#36798;&#21040;&#19982;&#19968;&#31995;&#21015;&#38750;&#29289;&#29702;&#32508;&#21512;&#27010;&#29575;&#27169;&#22411;&#30456;&#24403;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Modelling the behaviour of highly nonlinear dynamical systems with robust uncertainty quantification is a challenging task which typically requires approaches specifically designed to address the problem at hand. We introduce a domain-agnostic model to address this issue termed the deep latent force model (DLFM), a deep Gaussian process with physics-informed kernels at each layer, derived from ordinary differential equations using the framework of process convolutions. Two distinct formulations of the DLFM are presented which utilise weight-space and variational inducing points-based Gaussian process approximations, both of which are amenable to doubly stochastic variational inference. We present empirical evidence of the capability of the DLFM to capture the dynamics present in highly nonlinear real-world multi-output time series data. Additionally, we find that the DLFM is capable of achieving comparable performance to a range of non-physics-informed probabilistic models on benchmark
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#35270;&#35273;&#35266;&#23519;&#20013;&#36827;&#34892;&#27169;&#20223;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#28508;&#22312;&#23545;&#25239;&#35266;&#23519;&#27169;&#20223;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#31163;&#31574;&#30053;&#23545;&#25239;&#23398;&#20064;&#25216;&#26415;&#21644;&#20174;&#35266;&#23519;&#24207;&#21015;&#20013;&#23398;&#20064;&#30340;&#20195;&#29702;&#29366;&#24577;&#30340;&#28508;&#22312;&#34920;&#31034;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#31181;&#31639;&#27861;&#33021;&#19982;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#30456;&#21305;&#37197;&#12290;</title><link>http://arxiv.org/abs/2309.17371</link><description>&lt;p&gt;
&#21033;&#29992;&#28508;&#22312;&#20449;&#24687;&#20174;&#35270;&#35273;&#35266;&#23519;&#20013;&#36827;&#34892;&#23545;&#25239;&#24615;&#27169;&#20223;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Adversarial Imitation Learning from Visual Observations using Latent Information. (arXiv:2309.17371v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.17371
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20174;&#35270;&#35273;&#35266;&#23519;&#20013;&#36827;&#34892;&#27169;&#20223;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#28508;&#22312;&#23545;&#25239;&#35266;&#23519;&#27169;&#20223;&#30340;&#31639;&#27861;&#65292;&#36890;&#36807;&#32467;&#21512;&#31163;&#31574;&#30053;&#23545;&#25239;&#23398;&#20064;&#25216;&#26415;&#21644;&#20174;&#35266;&#23519;&#24207;&#21015;&#20013;&#23398;&#20064;&#30340;&#20195;&#29702;&#29366;&#24577;&#30340;&#28508;&#22312;&#34920;&#31034;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#31181;&#31639;&#27861;&#33021;&#19982;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#30456;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#19987;&#27880;&#20110;&#20174;&#35270;&#35273;&#35266;&#23519;&#20013;&#36827;&#34892;&#27169;&#20223;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#23398;&#20064;&#20195;&#29702;&#21482;&#33021;&#35775;&#38382;&#19987;&#23478;&#30340;&#35270;&#39057;&#20316;&#20026;&#20854;&#21807;&#19968;&#30340;&#23398;&#20064;&#28304;&#12290;&#36825;&#20010;&#26694;&#26550;&#30340;&#25361;&#25112;&#21253;&#25324;&#32570;&#20047;&#19987;&#23478;&#30340;&#21160;&#20316;&#21644;&#29615;&#22659;&#30340;&#23616;&#37096;&#21487;&#35266;&#27979;&#24615;&#65292;&#22240;&#20026;&#22320;&#38754;&#30495;&#23454;&#29366;&#24577;&#21482;&#33021;&#20174;&#20687;&#32032;&#20013;&#25512;&#26029;&#20986;&#26469;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#39318;&#20808;&#23545;&#37096;&#20998;&#21487;&#35266;&#27979;&#29615;&#22659;&#20013;&#30340;&#27169;&#20223;&#23398;&#20064;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#12290;&#25105;&#20204;&#22312;&#19987;&#23478;&#21644;&#20195;&#29702;&#28508;&#22312;&#29366;&#24577;&#36716;&#25442;&#20998;&#24067;&#20043;&#38388;&#30340;&#24046;&#24322;&#24230;&#19978;&#24314;&#31435;&#20102;&#23398;&#20064;&#20195;&#29702;&#23376;&#20248;&#24230;&#30340;&#19978;&#30028;&#12290;&#21463;&#21040;&#36825;&#20010;&#20998;&#26512;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#31216;&#20026;&#28508;&#22312;&#23545;&#25239;&#35266;&#23519;&#27169;&#20223;&#30340;&#31639;&#27861;&#65292;&#23427;&#23558;&#31163;&#31574;&#30053;&#23545;&#25239;&#23398;&#20064;&#25216;&#26415;&#19982;&#20174;&#35266;&#23519;&#24207;&#21015;&#20013;&#23398;&#20064;&#30340;&#20195;&#29702;&#29366;&#24577;&#30340;&#28508;&#22312;&#34920;&#31034;&#30456;&#32467;&#21512;&#12290;&#22312;&#39640;&#32500;&#36830;&#32493;&#26426;&#22120;&#20154;&#20219;&#21153;&#30340;&#23454;&#39564;&#35777;&#26126;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#19982;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#30456;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;
We focus on the problem of imitation learning from visual observations, where the learning agent has access to videos of experts as its sole learning source. The challenges of this framework include the absence of expert actions and the partial observability of the environment, as the ground-truth states can only be inferred from pixels. To tackle this problem, we first conduct a theoretical analysis of imitation learning in partially observable environments. We establish upper bounds on the suboptimality of the learning agent with respect to the divergence between the expert and the agent latent state-transition distributions. Motivated by this analysis, we introduce an algorithm called Latent Adversarial Imitation from Observations, which combines off-policy adversarial imitation techniques with a learned latent representation of the agent's state from sequences of observations. In experiments on high-dimensional continuous robotic tasks, we show that our algorithm matches state-of-t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32593;&#32476;&#29615;&#22659;&#20013;&#30340;&#20998;&#24067;&#24335;&#20272;&#35745;&#21644;&#23398;&#20064;&#38382;&#39064;&#65292;&#36890;&#36807;&#20132;&#25442;&#31169;&#26377;&#35266;&#27979;&#20449;&#24687;&#65292;&#20195;&#29702;&#21487;&#20197;&#38598;&#20307;&#20272;&#35745;&#26410;&#30693;&#25968;&#37327;&#65292;&#32780;&#20445;&#25252;&#38544;&#31169;&#12290;&#36890;&#36807;&#32447;&#24615;&#32858;&#21512;&#26041;&#26696;&#21644;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#35843;&#25972;&#30340;&#38543;&#26426;&#21270;&#26041;&#26696;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#22312;&#20445;&#35777;&#38544;&#31169;&#30340;&#21516;&#26102;&#39640;&#25928;&#32452;&#21512;&#35266;&#27979;&#25968;&#25454;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.15865</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#20998;&#24067;&#24335;&#20272;&#35745;&#21644;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Distributed Estimation and Learning. (arXiv:2306.15865v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.15865
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#32593;&#32476;&#29615;&#22659;&#20013;&#30340;&#20998;&#24067;&#24335;&#20272;&#35745;&#21644;&#23398;&#20064;&#38382;&#39064;&#65292;&#36890;&#36807;&#20132;&#25442;&#31169;&#26377;&#35266;&#27979;&#20449;&#24687;&#65292;&#20195;&#29702;&#21487;&#20197;&#38598;&#20307;&#20272;&#35745;&#26410;&#30693;&#25968;&#37327;&#65292;&#32780;&#20445;&#25252;&#38544;&#31169;&#12290;&#36890;&#36807;&#32447;&#24615;&#32858;&#21512;&#26041;&#26696;&#21644;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#35843;&#25972;&#30340;&#38543;&#26426;&#21270;&#26041;&#26696;&#65292;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#22815;&#22312;&#20445;&#35777;&#38544;&#31169;&#30340;&#21516;&#26102;&#39640;&#25928;&#32452;&#21512;&#35266;&#27979;&#25968;&#25454;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#32593;&#32476;&#29615;&#22659;&#20013;&#30340;&#20998;&#24067;&#24335;&#20272;&#35745;&#21644;&#23398;&#20064;&#38382;&#39064;&#65292;&#20854;&#20013;&#20195;&#29702;&#36890;&#36807;&#20132;&#25442;&#20449;&#24687;&#26469;&#20272;&#35745;&#20174;&#20854;&#31169;&#19979;&#35266;&#23519;&#30340;&#26679;&#26412;&#20013;&#26410;&#30693;&#30340;&#32479;&#35745;&#23646;&#24615;&#12290;&#36890;&#36807;&#20132;&#25442;&#31169;&#26377;&#35266;&#27979;&#20449;&#24687;&#65292;&#20195;&#29702;&#21487;&#20197;&#38598;&#20307;&#20272;&#35745;&#26410;&#30693;&#25968;&#37327;&#65292;&#20294;&#20182;&#20204;&#20063;&#38754;&#20020;&#38544;&#31169;&#39118;&#38505;&#12290;&#25105;&#20204;&#30340;&#32858;&#21512;&#26041;&#26696;&#30340;&#30446;&#26631;&#26159;&#22312;&#26102;&#38388;&#21644;&#32593;&#32476;&#20013;&#39640;&#25928;&#22320;&#32452;&#21512;&#35266;&#27979;&#25968;&#25454;&#65292;&#21516;&#26102;&#28385;&#36275;&#20195;&#29702;&#30340;&#38544;&#31169;&#38656;&#27714;&#65292;&#32780;&#19981;&#38656;&#35201;&#20219;&#20309;&#36229;&#36234;&#20182;&#20204;&#26412;&#22320;&#38468;&#36817;&#30340;&#21327;&#35843;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#20351;&#21442;&#19982;&#30340;&#20195;&#29702;&#33021;&#22815;&#20174;&#31163;&#32447;&#25110;&#38543;&#26102;&#38388;&#22312;&#32447;&#33719;&#21462;&#30340;&#31169;&#26377;&#20449;&#21495;&#20013;&#20272;&#35745;&#23436;&#25972;&#30340;&#20805;&#20998;&#32479;&#35745;&#37327;&#65292;&#24182;&#20445;&#25252;&#20854;&#20449;&#21495;&#21644;&#32593;&#32476;&#38468;&#36817;&#30340;&#38544;&#31169;&#12290;&#36825;&#26159;&#36890;&#36807;&#32447;&#24615;&#32858;&#21512;&#26041;&#26696;&#21644;&#35843;&#25972;&#30340;&#38543;&#26426;&#21270;&#26041;&#26696;&#23454;&#29616;&#30340;&#65292;&#23558;&#22122;&#22768;&#28155;&#21152;&#21040;&#20132;&#25442;&#30340;&#20272;&#35745;&#25968;&#25454;&#20013;&#20197;&#28385;&#36275;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study distributed estimation and learning problems in a networked environment in which agents exchange information to estimate unknown statistical properties of random variables from their privately observed samples. By exchanging information about their private observations, the agents can collectively estimate the unknown quantities, but they also face privacy risks. The goal of our aggregation schemes is to combine the observed data efficiently over time and across the network, while accommodating the privacy needs of the agents and without any coordination beyond their local neighborhoods. Our algorithms enable the participating agents to estimate a complete sufficient statistic from private signals that are acquired offline or online over time, and to preserve the privacy of their signals and network neighborhoods. This is achieved through linear aggregation schemes with adjusted randomization schemes that add noise to the exchanged estimates subject to differential privacy (DP
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#32771;&#23519;&#20102;&#22312;&#39640;&#32500;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#65292;&#25910;&#36141;&#21151;&#33021;&#26368;&#22823;&#21270;&#22120;&#21021;&#22987;&#21270;&#23545;&#21033;&#29992;&#25910;&#36141;&#21151;&#33021;&#33021;&#21147;&#30340;&#24433;&#21709;&#12290;&#30740;&#31350;&#21457;&#29616;&#38543;&#26426;&#21021;&#22987;&#21270;&#26041;&#27861;&#19981;&#33021;&#20805;&#20998;&#21457;&#25381;&#25910;&#36141;&#21151;&#33021;&#30340;&#28508;&#21147;&#65292;&#22240;&#27492;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#22909;&#30340;&#21021;&#22987;&#21270;&#26041;&#27861;&#26469;&#21033;&#29992;&#21382;&#21490;&#25968;&#25454;&#12290;</title><link>http://arxiv.org/abs/2302.08298</link><description>&lt;p&gt;
&#22312;&#39640;&#32500;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#37322;&#25918;&#25910;&#36141;&#21151;&#33021;&#30340;&#28508;&#21147;
&lt;/p&gt;
&lt;p&gt;
Unleashing the Potential of Acquisition Functions in High-Dimensional Bayesian Optimization. (arXiv:2302.08298v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.08298
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#32771;&#23519;&#20102;&#22312;&#39640;&#32500;&#36125;&#21494;&#26031;&#20248;&#21270;&#20013;&#65292;&#25910;&#36141;&#21151;&#33021;&#26368;&#22823;&#21270;&#22120;&#21021;&#22987;&#21270;&#23545;&#21033;&#29992;&#25910;&#36141;&#21151;&#33021;&#33021;&#21147;&#30340;&#24433;&#21709;&#12290;&#30740;&#31350;&#21457;&#29616;&#38543;&#26426;&#21021;&#22987;&#21270;&#26041;&#27861;&#19981;&#33021;&#20805;&#20998;&#21457;&#25381;&#25910;&#36141;&#21151;&#33021;&#30340;&#28508;&#21147;&#65292;&#22240;&#27492;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#22909;&#30340;&#21021;&#22987;&#21270;&#26041;&#27861;&#26469;&#21033;&#29992;&#21382;&#21490;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;BO&#65289;&#34987;&#24191;&#27867;&#29992;&#20110;&#20248;&#21270;&#26114;&#36149;&#30340;&#40657;&#30418;&#20989;&#25968;&#12290;BO&#39318;&#20808;&#26500;&#24314;&#19968;&#20010;&#20195;&#29702;&#27169;&#22411;&#26469;&#34920;&#31034;&#30446;&#26631;&#20989;&#25968;&#24182;&#35780;&#20272;&#20854;&#19981;&#30830;&#23450;&#24615;&#12290;&#28982;&#21518;&#65292;&#23427;&#36890;&#36807;&#26368;&#22823;&#21270;&#22522;&#20110;&#20195;&#29702;&#27169;&#22411;&#30340;&#25910;&#36141;&#20989;&#25968;&#65288;AF&#65289;&#26469;&#20915;&#23450;&#37319;&#26679;&#20301;&#32622;&#12290;&#28982;&#32780;&#65292;&#22312;&#22788;&#29702;&#39640;&#32500;&#38382;&#39064;&#26102;&#65292;&#25214;&#21040;AF&#30340;&#20840;&#23616;&#26368;&#22823;&#20540;&#21464;&#24471;&#36234;&#26469;&#36234;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;AF&#26368;&#22823;&#21270;&#22120;&#30340;&#21021;&#22987;&#21270;&#21457;&#25381;&#20102;&#20851;&#38190;&#20316;&#29992;&#65292;&#22240;&#20026;&#19981;&#24688;&#24403;&#30340;&#35774;&#32622;&#21487;&#33021;&#20005;&#37325;&#24433;&#21709;AF&#30340;&#26377;&#25928;&#24615;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#20010;&#24456;&#22823;&#31243;&#24230;&#19978;&#26410;&#34987;&#30740;&#31350;&#30340;&#38382;&#39064;&#65292;&#21363;AF&#26368;&#22823;&#21270;&#22120;&#21021;&#22987;&#21270;&#23545;&#21033;&#29992;AF&#33021;&#21147;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#30340;&#22823;&#35268;&#27169;&#23454;&#35777;&#30740;&#31350;&#34920;&#26126;&#65292;&#24191;&#27867;&#20351;&#29992;&#30340;&#38543;&#26426;&#21021;&#22987;&#21270;&#31574;&#30053;&#24448;&#24448;&#26080;&#27861;&#20805;&#20998;&#21457;&#25381;AF&#30340;&#28508;&#21147;&#12290;&#22522;&#20110;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26356;&#22909;&#30340;&#21021;&#22987;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#20351;&#29992;&#22810;&#20010;&#21551;&#21457;&#24335;&#20248;&#21270;&#22120;&#26469;&#21033;&#29992;&#40657;&#30418;&#30340;&#21382;&#21490;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian optimization (BO) is widely used to optimize expensive-to-evaluate black-box functions.BO first builds a surrogate model to represent the objective function and assesses its uncertainty. It then decides where to sample by maximizing an acquisition function (AF) based on the surrogate model. However, when dealing with high-dimensional problems, finding the global maximum of the AF becomes increasingly challenging. In such cases, the initialization of the AF maximizer plays a pivotal role, as an inadequate setup can severely hinder the effectiveness of the AF.  This paper investigates a largely understudied problem concerning the impact of AF maximizer initialization on exploiting AFs' capability. Our large-scale empirical study shows that the widely used random initialization strategy often fails to harness the potential of an AF. In light of this, we propose a better initialization approach by employing multiple heuristic optimizers to leverage the historical data of black-box
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#28151;&#21512;&#31867;&#21035;&#30456;&#20851;&#26680;&#30340;&#39640;&#26031;&#36807;&#31243;&#20195;&#29702;&#65292;&#30456;&#36739;&#20110;&#20854;&#20182;&#29616;&#26377;&#27169;&#22411;&#22312;&#20998;&#26512;&#21644;&#24037;&#31243;&#38382;&#39064;&#19978;&#34920;&#29616;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2211.08262</link><description>&lt;p&gt;
&#19968;&#31181;&#28151;&#21512;&#31867;&#21035;&#30456;&#20851;&#26680;&#30340;&#39640;&#26031;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
A mixed-categorical correlation kernel for Gaussian process. (arXiv:2211.08262v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.08262
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#19968;&#31181;&#26032;&#30340;&#28151;&#21512;&#31867;&#21035;&#30456;&#20851;&#26680;&#30340;&#39640;&#26031;&#36807;&#31243;&#20195;&#29702;&#65292;&#30456;&#36739;&#20110;&#20854;&#20182;&#29616;&#26377;&#27169;&#22411;&#22312;&#20998;&#26512;&#21644;&#24037;&#31243;&#38382;&#39064;&#19978;&#34920;&#29616;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#20195;&#29702;&#30340;&#28151;&#21512;&#31867;&#21035;&#20803;&#27169;&#22411;&#24341;&#36215;&#20102;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#12290;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#19968;&#20123;&#29616;&#26377;&#30340;&#26041;&#27861;&#20351;&#29992;&#19981;&#21516;&#30340;&#31574;&#30053;&#65292;&#36890;&#36807;&#20351;&#29992;&#36830;&#32493;&#26680;&#65288;&#20363;&#22914;&#65292;&#36830;&#32493;&#26494;&#24347;&#21644;Gower&#36317;&#31163;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#65289;&#25110;&#36890;&#36807;&#30452;&#25509;&#20272;&#35745;&#30456;&#20851;&#30697;&#38453;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26680;&#30340;&#26041;&#27861;&#65292;&#23558;&#36830;&#32493;&#25351;&#25968;&#26680;&#25193;&#23637;&#20026;&#22788;&#29702;&#28151;&#21512;&#31867;&#21035;&#21464;&#37327;&#12290;&#25152;&#25552;&#20986;&#30340;&#26680;&#24341;&#23548;&#21040;&#20102;&#19968;&#20010;&#26032;&#30340;&#39640;&#26031;&#20195;&#29702;&#65292;&#23427;&#27010;&#25324;&#20102;&#36830;&#32493;&#26494;&#24347;&#21644;Gower&#36317;&#31163;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#12290;&#25105;&#20204;&#22312;&#20998;&#26512;&#21644;&#24037;&#31243;&#38382;&#39064;&#19978;&#35777;&#26126;&#20102;&#65292;&#25105;&#20204;&#30340;&#25552;&#20986;&#30340;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#27604;&#20854;&#20182;&#22522;&#20110;&#26680;&#30340;&#29616;&#26377;&#27169;&#22411;&#20855;&#26377;&#26356;&#39640;&#30340;&#21487;&#33021;&#24615;&#21644;&#26356;&#23567;&#30340;&#27531;&#24046;&#35823;&#24046;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20351;&#29992;&#24320;&#28304;&#36719;&#20214;SMT&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, there has been a growing interest for mixed-categorical meta-models based on Gaussian process (GP) surrogates. In this setting, several existing approaches use different strategies either by using continuous kernels (e.g., continuous relaxation and Gower distance based GP) or by using a direct estimation of the correlation matrix. In this paper, we present a kernel-based approach that extends continuous exponential kernels to handle mixed-categorical variables. The proposed kernel leads to a new GP surrogate that generalizes both the continuous relaxation and the Gower distance based GP models. We demonstrate, on both analytical and engineering problems, that our proposed GP model gives a higher likelihood and a smaller residual error than the other kernel-based state-of-the-art models. Our method is available in the open-source software SMT.
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#31216;&#20026;&#28120;&#27760;&#23545;&#27604;&#20132;&#21449;&#39564;&#35777;&#65288;TLPO&#65289;&#65292;&#29992;&#20110;&#35299;&#20915;&#20351;&#29992;&#26631;&#20934;&#20132;&#21449;&#39564;&#35777;&#26041;&#27861;&#20272;&#35745;&#25509;&#25910;&#22120;&#24037;&#20316;&#29305;&#24615;&#65288;ROC&#65289;&#26354;&#32447;&#19979;&#38754;&#31215;&#65288;AUC&#65289;&#26102;&#30340;&#20559;&#24046;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#25968;&#25454;&#25490;&#24207;&#21151;&#33021;&#65292;&#20026;ROC&#20998;&#26512;&#25552;&#20379;&#20102;&#21487;&#38752;&#30340;&#24037;&#20855;&#12290;</title><link>http://arxiv.org/abs/1801.09386</link><description>&lt;p&gt;
&#29992;&#20110;&#25509;&#25910;&#22120;&#24037;&#20316;&#29305;&#24615;&#65288;ROC&#65289;&#20998;&#26512;&#30340;&#28120;&#27760;&#23545;&#27604;&#20132;&#21449;&#39564;&#35777;(Tournament Leave-pair-out Cross-validation)
&lt;/p&gt;
&lt;p&gt;
Tournament Leave-pair-out Cross-validation for Receiver Operating Characteristic (ROC) Analysis. (arXiv:1801.09386v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1801.09386
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#31216;&#20026;&#28120;&#27760;&#23545;&#27604;&#20132;&#21449;&#39564;&#35777;&#65288;TLPO&#65289;&#65292;&#29992;&#20110;&#35299;&#20915;&#20351;&#29992;&#26631;&#20934;&#20132;&#21449;&#39564;&#35777;&#26041;&#27861;&#20272;&#35745;&#25509;&#25910;&#22120;&#24037;&#20316;&#29305;&#24615;&#65288;ROC&#65289;&#26354;&#32447;&#19979;&#38754;&#31215;&#65288;AUC&#65289;&#26102;&#30340;&#20559;&#24046;&#38382;&#39064;&#65292;&#24182;&#25552;&#20379;&#20102;&#25968;&#25454;&#25490;&#24207;&#21151;&#33021;&#65292;&#20026;ROC&#20998;&#26512;&#25552;&#20379;&#20102;&#21487;&#38752;&#30340;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25509;&#25910;&#22120;&#24037;&#20316;&#29305;&#24615;&#65288;ROC&#65289;&#20998;&#26512;&#34987;&#24191;&#27867;&#29992;&#20110;&#35780;&#20272;&#35786;&#26029;&#31995;&#32479;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#20351;&#29992;&#26631;&#20934;&#20132;&#21449;&#39564;&#35777;&#26041;&#27861;&#20272;&#35745;ROC&#26354;&#32447;&#19979;&#38754;&#31215;&#65288;AUC&#65289;&#23384;&#22312;&#36739;&#22823;&#20559;&#24046;&#12290;&#28120;&#27760;&#23545;&#27604;&#20132;&#21449;&#39564;&#35777;&#65288;LPO&#65289;&#34987;&#35777;&#26126;&#21487;&#20197;&#20462;&#27491;&#36825;&#31181;&#20559;&#24046;&#12290;&#28982;&#32780;&#65292;&#34429;&#28982;LPO&#21487;&#20197;&#20960;&#20046;&#26080;&#20559;&#22320;&#20272;&#35745;AUC&#65292;&#20294;&#23427;&#26080;&#27861;&#25552;&#20379;&#32472;&#21046;&#21644;&#20998;&#26512;ROC&#26354;&#32447;&#25152;&#38656;&#30340;&#25968;&#25454;&#25490;&#24207;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#31216;&#20026;&#28120;&#27760;&#23545;&#27604;&#20132;&#21449;&#39564;&#35777;&#65288;TLPO&#65289;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#21019;&#24314;&#20174;&#23545;&#27604;&#20013;&#24471;&#20986;&#25490;&#21517;&#30340;&#27604;&#36187;&#65292;&#25193;&#23637;&#20102;LPO&#30340;&#21151;&#33021;&#65292;&#20174;&#32780;&#20026;&#25968;&#25454;&#25552;&#20379;&#20102;&#25490;&#24207;&#12290;TLPO&#26082;&#20445;&#30041;&#20102;LPO&#20272;&#35745;AUC&#30340;&#20248;&#21183;&#65292;&#21448;&#21487;&#20197;&#36827;&#34892;ROC&#20998;&#26512;&#12290;&#25105;&#20204;&#20351;&#29992;&#21512;&#25104;&#25968;&#25454;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#35777;&#26126;&#20102;TLPO&#23545;&#20110;AUC&#20272;&#35745;&#19982;LPO&#19968;&#26679;&#21487;&#38752;&#65292;&#24182;&#39564;&#35777;&#20102;&#30041;&#19968;&#20132;&#21449;&#39564;&#35777;&#22312;&#20302;&#32500;&#25968;&#25454;&#19978;&#30340;&#20559;&#24046;&#12290;&#20316;&#20026;ROC&#20998;&#26512;&#30340;&#26696;&#20363;&#30740;&#31350;&#65292;&#25105;&#20204;
&lt;/p&gt;
&lt;p&gt;
Receiver operating characteristic (ROC) analysis is widely used for evaluating diagnostic systems. Recent studies have shown that estimating an area under ROC curve (AUC) with standard cross-validation methods suffers from a large bias. The leave-pair-out (LPO) cross-validation has been shown to correct this bias. However, while LPO produces an almost unbiased estimate of AUC, it does not provide a ranking of the data needed for plotting and analyzing the ROC curve. In this study, we propose a new method called tournament leave-pair-out (TLPO) cross-validation. This method extends LPO by creating a tournament from pair comparisons to produce a ranking for the data. TLPO preserves the advantage of LPO for estimating AUC, while it also allows performing ROC analyses. We have shown using both synthetic and real world data that TLPO is as reliable as LPO for AUC estimation, and confirmed the bias in leave-one-out cross-validation on low-dimensional data. As a case study on ROC analysis, we
&lt;/p&gt;</description></item></channel></rss>