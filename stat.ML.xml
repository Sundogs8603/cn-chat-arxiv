<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#39318;&#27425;&#23558;&#21345;&#23572;&#26364;&#21644;&#25193;&#23637;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#25512;&#24191;&#21040;&#22270;&#24418;&#19978;&#65292;&#20351;&#24471;&#23427;&#21487;&#20197;&#36866;&#29992;&#20110;&#36755;&#20986;&#26159;&#21521;&#37327;&#25110;&#26631;&#37327;&#30340;&#24773;&#20917;&#65292;&#24182;&#19988;&#21487;&#20197;&#23398;&#20064;&#26410;&#30693;&#30340;&#29366;&#24577;&#36716;&#31227;&#21644;&#35835;&#21462;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2303.12021</link><description>&lt;p&gt;
&#22270;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;
&lt;/p&gt;
&lt;p&gt;
Graph Kalman Filters. (arXiv:2303.12021v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.12021
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#39318;&#27425;&#23558;&#21345;&#23572;&#26364;&#21644;&#25193;&#23637;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#25512;&#24191;&#21040;&#22270;&#24418;&#19978;&#65292;&#20351;&#24471;&#23427;&#21487;&#20197;&#36866;&#29992;&#20110;&#36755;&#20986;&#26159;&#21521;&#37327;&#25110;&#26631;&#37327;&#30340;&#24773;&#20917;&#65292;&#24182;&#19988;&#21487;&#20197;&#23398;&#20064;&#26410;&#30693;&#30340;&#29366;&#24577;&#36716;&#31227;&#21644;&#35835;&#21462;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20247;&#25152;&#21608;&#30693;&#65292;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#36890;&#36807;&#20351;&#29992;&#29366;&#24577;&#31354;&#38388;&#34920;&#31034;&#26469;&#27169;&#25311;&#21160;&#24577;&#31995;&#32479;&#65292;&#19979;&#19968;&#20010;&#29366;&#24577;&#30340;&#26356;&#26032;&#20197;&#21450;&#19982;&#26032;&#35266;&#23519;&#21040;&#30340;&#31995;&#32479;&#36755;&#20986;&#30456;&#20851;&#30340;&#20449;&#24687;&#26469;&#25511;&#21046;&#20854;&#19981;&#30830;&#23450;&#24615;&#12290;&#26412;&#25991;&#39318;&#27425;&#23558;&#21345;&#23572;&#26364;&#21644;&#25193;&#23637;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#25512;&#24191;&#21040;&#31163;&#25955;&#26102;&#38388;&#30340;&#35774;&#32622;&#19979;&#65292;&#20854;&#20013;&#36755;&#20837;&#12289;&#29366;&#24577;&#21644;&#36755;&#20986;&#22343;&#34920;&#31034;&#20026;&#24102;&#23646;&#24615;&#30340;&#22270;&#24418;&#65292;&#20854;&#25299;&#25169;&#21644;&#23646;&#24615;&#21487;&#20197;&#38543;&#26102;&#38388;&#21464;&#21270;&#12290;&#27492;&#35774;&#32622;&#20351;&#24471;&#25105;&#20204;&#21487;&#20197;&#23558;&#26694;&#26550;&#36866;&#24212;&#20110;&#36755;&#20986;&#26159;&#21521;&#37327;&#25110;&#26631;&#37327;&#30340;&#24773;&#20917;&#65288;&#33410;&#28857;/&#22270;&#32423;&#20219;&#21153;&#65289;&#12290;&#22312;&#25152;&#25552;&#20986;&#30340;&#29702;&#35770;&#26694;&#26550;&#20869;&#65292;&#26410;&#30693;&#30340;&#29366;&#24577;&#36716;&#31227;&#21644;&#35835;&#21462;&#20989;&#25968;&#19982;&#19979;&#28216;&#39044;&#27979;&#20219;&#21153;&#19968;&#36215;&#31471;&#21040;&#31471;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
The well-known Kalman filters model dynamical systems by relying on state-space representations with the next state updated, and its uncertainty controlled, by fresh information associated with newly observed system outputs. This paper generalizes, for the first time in the literature, Kalman and extended Kalman filters to discrete-time settings where inputs, states, and outputs are represented as attributed graphs whose topology and attributes can change with time. The setup allows us to adapt the framework to cases where the output is a vector or a scalar too (node/graph level tasks). Within the proposed theoretical framework, the unknown state-transition and the readout functions are learned end-to-end along with the downstream prediction task.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21152;&#26435;&#31227;&#21160;&#24179;&#22343;&#24179;&#28369;&#22120;&#30340;&#26368;&#20339;&#21152;&#26435;&#31383;&#21475;&#65292;&#23558;&#38382;&#39064;&#36716;&#21270;&#20026;&#21407;&#28857;&#22312;&#20984;&#22810;&#38754;&#20307;&#19978;&#30340;&#25237;&#24433;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20123;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2303.11958</link><description>&lt;p&gt;
&#21152;&#26435;&#24179;&#28369;&#22312;&#20984;&#22810;&#38754;&#20307;&#19978;&#30340;&#25237;&#24433;&#24335;
&lt;/p&gt;
&lt;p&gt;
Formulation of Weighted Average Smoothing as a Projection of the Origin onto a Convex Polytope. (arXiv:2303.11958v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11958
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21152;&#26435;&#31227;&#21160;&#24179;&#22343;&#24179;&#28369;&#22120;&#30340;&#26368;&#20339;&#21152;&#26435;&#31383;&#21475;&#65292;&#23558;&#38382;&#39064;&#36716;&#21270;&#20026;&#21407;&#28857;&#22312;&#20984;&#22810;&#38754;&#20307;&#19978;&#30340;&#25237;&#24433;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20123;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#24179;&#26041;&#25439;&#22833;&#19979;&#21152;&#26435;&#31227;&#21160;&#24179;&#22343;&#24179;&#28369;&#22120;&#30340;&#26368;&#20339;&#21152;&#26435;&#31383;&#21475;&#12290;&#25105;&#20204;&#35777;&#26126;&#23384;&#22312;&#19968;&#20010;&#26368;&#20248;&#30340;&#23545;&#31216;&#21152;&#26435;&#31383;&#21475;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#36880;&#27493;&#20943;&#24369;&#30340;&#21152;&#26435;&#31383;&#21475;&#65292;&#23427;&#20204;&#30340;&#26435;&#37325;&#38543;&#30528;&#36828;&#31163;&#20013;&#24515;&#32780;&#20943;&#23569;&#12290;&#25105;&#20204;&#23558;&#30456;&#24212;&#30340;&#26368;&#23567;&#20108;&#20056;&#38382;&#39064;&#20844;&#24335;&#21270;&#20026;&#19968;&#20010;&#20108;&#27425;&#35268;&#21010;&#38382;&#39064;&#65292;&#26368;&#32456;&#23558;&#20854;&#36716;&#21270;&#20026;&#21407;&#28857;&#22312;&#20984;&#22810;&#38754;&#20307;&#19978;&#30340;&#25237;&#24433;&#12290;&#27492;&#22806;&#65292;&#24403;&#36755;&#20837;&#25968;&#25454;&#28385;&#36275;&#26576;&#20123;&#26465;&#20214;&#26102;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#20123;&#26368;&#20339;&#31383;&#21475;&#30340;&#20998;&#26512;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;
Our study focuses on determining the best weight windows for a weighted moving average smoother under squared loss. We show that there exists an optimal weight window that is symmetrical around its center. We study the class of tapered weight windows, which decrease in weight as they move away from the center. We formulate the corresponding least squares problem as a quadratic program and finally as a projection of the origin onto a convex polytope. Additionally, we provide some analytical solutions to the best window when some conditions are met on the input data.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#27491;&#21017;&#21270;&#29109;Wasserstein&#37325;&#24515;&#20844;&#24335;&#65292;&#20855;&#26377;&#22909;&#30340;&#27491;&#21017;&#21270;&#12289;&#36924;&#36817;&#12289;&#31283;&#23450;&#24615;&#21644;&#65288;&#26080;&#32593;&#26684;&#65289;&#20248;&#21270;&#29305;&#24615;; &#20854;&#20013;&#65292;&#21482;&#26377;&#22312;$\tau=\lambda/2$&#30340;&#24773;&#20917;&#19979;&#26159;&#26080;&#20559;&#24046;&#30340;&#12290;</title><link>http://arxiv.org/abs/2303.11844</link><description>&lt;p&gt;
&#21452;&#37325;&#27491;&#21017;&#21270;&#29109; Wasserstein &#37325;&#24515;
&lt;/p&gt;
&lt;p&gt;
Doubly Regularized Entropic Wasserstein Barycenters. (arXiv:2303.11844v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11844
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#27491;&#21017;&#21270;&#29109;Wasserstein&#37325;&#24515;&#20844;&#24335;&#65292;&#20855;&#26377;&#22909;&#30340;&#27491;&#21017;&#21270;&#12289;&#36924;&#36817;&#12289;&#31283;&#23450;&#24615;&#21644;&#65288;&#26080;&#32593;&#26684;&#65289;&#20248;&#21270;&#29305;&#24615;; &#20854;&#20013;&#65292;&#21482;&#26377;&#22312;$\tau=\lambda/2$&#30340;&#24773;&#20917;&#19979;&#26159;&#26080;&#20559;&#24046;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#24120;&#35268;&#30340;&#27491;&#21017;&#21270;Wasserstein&#37325;&#24515;&#30340;&#20844;&#24335;&#65292;&#36825;&#20010;&#20844;&#24335;&#20855;&#26377;&#33391;&#22909;&#30340;&#27491;&#21017;&#21270;&#12289;&#36924;&#36817;&#12289;&#31283;&#23450;&#24615;&#21644;&#65288;&#26080;&#32593;&#26684;&#65289;&#20248;&#21270;&#29305;&#24615;&#12290;&#36825;&#20010;&#37325;&#24515;&#34987;&#23450;&#20041;&#20026;&#21807;&#19968;&#19968;&#31181;&#26368;&#23567;&#21270;&#20851;&#20110;&#19968;&#26063;&#32473;&#23450;&#27010;&#29575;&#27979;&#24230;&#30340;&#29109;&#26368;&#20248;&#36755;&#36816;&#65288;EOT&#65289;&#25104;&#26412;&#20043;&#21644;&#21450;&#29109;&#39033;&#30340;&#27010;&#29575;&#27979;&#24230;&#12290;&#25105;&#20204;&#31216;&#20043;&#20026;$(\lambda,\tau)$-&#37325;&#24515;&#65292;&#20854;&#20013;&#65292;$\lambda$ &#26159;&#20869;&#37096;&#27491;&#21017;&#21270;&#24378;&#24230;&#65292;$\tau$ &#26159;&#22806;&#37096;&#27491;&#21017;&#21270;&#24378;&#24230;&#12290;&#36825;&#31181;&#20844;&#24335;&#24674;&#22797;&#20102;&#24050;&#32463;&#25552;&#20986;&#30340;&#22810;&#31181;EOT&#37325;&#24515;&#65292;&#36866;&#21512;&#20110;&#19981;&#21516;&#30340; $\lambda, \tau \geq 0$ &#36873;&#25321;&#65292;&#24182;&#23545;&#23427;&#20204;&#36827;&#34892;&#20102;&#27867;&#21270;&#12290;&#39318;&#20808;&#65292;&#23613;&#31649;&#20855;&#26377;&#21452;&#37325;&#27491;&#21017;&#21270;&#65292;&#20294;&#22312;$\tau=\lambda/2$ &#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#20844;&#24335;&#26159;&#26080;&#20559;&#30340;: &#23545;&#20110;&#20809;&#28369;&#23494;&#24230;&#65292;&#65288;&#26410;&#27491;&#21017;&#21270;&#30340;&#65289;Wasserstein &#37325;&#24515;&#30446;&#26631;&#20989;&#25968;&#20013;&#30340;&#27425;&#20248;&#24615;&#26159;&#29109;&#27491;&#21017;&#21270;&#24378;&#24230;$\lambda^2$&#30340;&#65292;&#32780;&#19981;&#26159;&#19968;&#33324;&#24773;&#20917;&#19979;&#30340;$\max \{\lambda, \tau\}$&#12290;
&lt;/p&gt;
&lt;p&gt;
We study a general formulation of regularized Wasserstein barycenters that enjoys favorable regularity, approximation, stability and (grid-free) optimization properties. This barycenter is defined as the unique probability measure that minimizes the sum of entropic optimal transport (EOT) costs with respect to a family of given probability measures, plus an entropy term. We denote it $(\lambda,\tau)$-barycenter, where $\lambda$ is the inner regularization strength and $\tau$ the outer one. This formulation recovers several previously proposed EOT barycenters for various choices of $\lambda,\tau \geq 0$ and generalizes them. First, in spite of -- and in fact owing to -- being \emph{doubly} regularized, we show that our formulation is debiased for $\tau=\lambda/2$: the suboptimality in the (unregularized) Wasserstein barycenter objective is, for smooth densities, of the order of the strength $\lambda^2$ of entropic regularization, instead of $\max\{\lambda,\tau\}$ in general. We discuss 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36880;&#23618;&#21442;&#25968;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#23454;&#29616;&#20869;&#32622;&#40065;&#26834;&#24615;&#20445;&#35777;&#30340;1D&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;CNN&#29305;&#24449;&#30340;Lipschitz&#24120;&#25968;&#20316;&#20026;&#40065;&#26834;&#24615;&#24230;&#37327;&#65292;&#24182;&#20351;&#29992;Cayley&#21464;&#25442;&#21644;&#21487;&#25511;&#24615;Gram&#30697;&#26469;&#23454;&#29616;CNN&#30340;Lipschitz&#36830;&#32493;&#24615;&#21644;&#26080;&#32422;&#26463;&#35757;&#32451;&#65292;&#26368;&#21518;&#22312;&#24515;&#24459;&#22833;&#24120;&#25968;&#25454;&#20998;&#31867;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#25913;&#36827;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.11835</link><description>&lt;p&gt;
&#21033;&#29992;Cayley&#21464;&#25442;&#21644;&#21487;&#25511;&#24615;Gram&#30697;&#30340;Lipschitz-bounded 1D&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;(arXiv:2303.11835v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
Lipschitz-bounded 1D convolutional neural networks using the Cayley transform and the controllability Gramian. (arXiv:2303.11835v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11835
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#36880;&#23618;&#21442;&#25968;&#21270;&#26041;&#27861;&#65292;&#29992;&#20110;&#23454;&#29616;&#20869;&#32622;&#40065;&#26834;&#24615;&#20445;&#35777;&#30340;1D&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#12290;&#35813;&#26041;&#27861;&#22522;&#20110;CNN&#29305;&#24449;&#30340;Lipschitz&#24120;&#25968;&#20316;&#20026;&#40065;&#26834;&#24615;&#24230;&#37327;&#65292;&#24182;&#20351;&#29992;Cayley&#21464;&#25442;&#21644;&#21487;&#25511;&#24615;Gram&#30697;&#26469;&#23454;&#29616;CNN&#30340;Lipschitz&#36830;&#32493;&#24615;&#21644;&#26080;&#32422;&#26463;&#35757;&#32451;&#65292;&#26368;&#21518;&#22312;&#24515;&#24459;&#22833;&#24120;&#25968;&#25454;&#20998;&#31867;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#25913;&#36827;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#31181;&#29992;&#20110;1D&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#30340;&#36880;&#23618;&#21442;&#25968;&#21270;&#65292;&#20855;&#26377;&#20869;&#32622;&#30340;&#31471;&#21040;&#31471;&#40065;&#26834;&#24615;&#20445;&#35777;&#12290;&#25105;&#20204;&#20351;&#29992;CNN&#29305;&#24449;&#30340;Lipschitz&#24120;&#25968;&#20316;&#20026;&#40065;&#26834;&#24615;&#24230;&#37327;&#12290;&#25105;&#20204;&#22522;&#20110;Cayley&#21464;&#25442;&#23545;&#27491;&#20132;&#30697;&#38453;&#36827;&#34892;&#21442;&#25968;&#21270;&#20197;&#21450;&#23545;&#21367;&#31215;&#23618;&#30340;&#29366;&#24577;&#31354;&#38388;&#34920;&#24449;&#30340;&#21487;&#25511;&#24615;Gram&#30697;&#36827;&#34892;&#21442;&#25968;&#21270;&#12290;&#25152;&#25552;&#20986;&#30340;&#21442;&#25968;&#21270;&#35774;&#35745;&#28385;&#36275;&#32447;&#24615;&#30697;&#38453;&#19981;&#31561;&#24335;&#65292;&#20174;&#32780;&#23454;&#29616;CNN&#30340;Lipschitz&#36830;&#32493;&#24615;&#65292;&#36827;&#19968;&#27493;&#23454;&#29616;Lipschitz-bounded 1D CNNs&#30340;&#26080;&#32422;&#26463;&#35757;&#32451;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23545;&#24515;&#24459;&#22833;&#24120;&#25968;&#25454;&#36827;&#34892;Lipschitz-bounded 1D CNNs&#30340;&#20998;&#31867;&#35757;&#32451;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#25913;&#36827;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We establish a layer-wise parameterization for 1D convolutional neural networks (CNNs) with built-in end-to-end robustness guarantees. Herein, we use the Lipschitz constant of the input-output mapping characterized by a CNN as a robustness measure. We base our parameterization on the Cayley transform that parameterizes orthogonal matrices and the controllability Gramian for the state space representation of the convolutional layers. The proposed parameterization by design fulfills linear matrix inequalities that are sufficient for Lipschitz continuity of the CNN, which further enables unconstrained training of Lipschitz-bounded 1D CNNs. Finally, we train Lipschitz-bounded 1D CNNs for the classification of heart arrythmia data and show their improved robustness.
&lt;/p&gt;</description></item><item><title>&#36825;&#26159;&#19968;&#20010;&#22788;&#29702;&#20302;&#32500;&#27969;&#24418;&#25968;&#25454;&#30340;&#22238;&#24402;&#26694;&#26550;&#65292;&#39318;&#20808;&#36890;&#36807;&#26500;&#24314;&#22270;&#24418;&#39592;&#26550;&#26469;&#25429;&#25417;&#28508;&#22312;&#30340;&#27969;&#24418;&#20960;&#20309;&#32467;&#26500;&#65292;&#28982;&#21518;&#22312;&#20854;&#19978;&#36816;&#29992;&#38750;&#21442;&#25968;&#22238;&#24402;&#25216;&#26415;&#26469;&#20272;&#35745;&#22238;&#24402;&#20989;&#25968;&#65292;&#38500;&#20102;&#20855;&#26377;&#38750;&#21442;&#25968;&#20248;&#28857;&#20043;&#22806;&#65292;&#22312;&#22788;&#29702;&#22810;&#20010;&#27969;&#24418;&#25968;&#25454;&#65292;&#22024;&#26434;&#35266;&#23519;&#26102;&#20063;&#34920;&#29616;&#20986;&#36739;&#22909;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.11786</link><description>&lt;p&gt;
Skeleton Regression&#65306;&#19968;&#31181;&#22522;&#20110;&#27969;&#24418;&#32467;&#26500;&#20272;&#35745;&#30340;&#22522;&#20110;&#22270;&#24418;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Skeleton Regression: A Graph-Based Approach to Estimation with Manifold Structure. (arXiv:2303.11786v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11786
&lt;/p&gt;
&lt;p&gt;
&#36825;&#26159;&#19968;&#20010;&#22788;&#29702;&#20302;&#32500;&#27969;&#24418;&#25968;&#25454;&#30340;&#22238;&#24402;&#26694;&#26550;&#65292;&#39318;&#20808;&#36890;&#36807;&#26500;&#24314;&#22270;&#24418;&#39592;&#26550;&#26469;&#25429;&#25417;&#28508;&#22312;&#30340;&#27969;&#24418;&#20960;&#20309;&#32467;&#26500;&#65292;&#28982;&#21518;&#22312;&#20854;&#19978;&#36816;&#29992;&#38750;&#21442;&#25968;&#22238;&#24402;&#25216;&#26415;&#26469;&#20272;&#35745;&#22238;&#24402;&#20989;&#25968;&#65292;&#38500;&#20102;&#20855;&#26377;&#38750;&#21442;&#25968;&#20248;&#28857;&#20043;&#22806;&#65292;&#22312;&#22788;&#29702;&#22810;&#20010;&#27969;&#24418;&#25968;&#25454;&#65292;&#22024;&#26434;&#35266;&#23519;&#26102;&#20063;&#34920;&#29616;&#20986;&#36739;&#22909;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#26032;&#30340;&#22238;&#24402;&#26694;&#26550;&#65292;&#26088;&#22312;&#22788;&#29702;&#22260;&#32469;&#20302;&#32500;&#27969;&#24418;&#30340;&#22797;&#26434;&#25968;&#25454;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#39318;&#20808;&#26500;&#24314;&#19968;&#20010;&#22270;&#24418;&#34920;&#31034;&#65292;&#31216;&#20026;&#39592;&#26550;&#65292;&#20197;&#25429;&#33719;&#28508;&#22312;&#30340;&#20960;&#20309;&#32467;&#26500;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#22312;&#39592;&#26550;&#22270;&#19978;&#23450;&#20041;&#25351;&#26631;&#65292;&#24212;&#29992;&#38750;&#21442;&#25968;&#22238;&#24402;&#25216;&#26415;&#65292;&#20197;&#21450;&#22522;&#20110;&#22270;&#24418;&#30340;&#29305;&#24449;&#36716;&#25442;&#26469;&#20272;&#35745;&#22238;&#24402;&#20989;&#25968;&#12290;&#38500;&#20102;&#21253;&#25324;&#30340;&#38750;&#21442;&#25968;&#26041;&#27861;&#22806;&#65292;&#25105;&#20204;&#36824;&#35752;&#35770;&#20102;&#19968;&#20123;&#38750;&#21442;&#25968;&#22238;&#24402;&#22120;&#22312;&#39592;&#26550;&#22270;&#31561;&#19968;&#33324;&#24230;&#37327;&#31354;&#38388;&#26041;&#38754;&#30340;&#38480;&#21046;&#12290;&#25152;&#25552;&#20986;&#30340;&#22238;&#24402;&#26694;&#26550;&#20351;&#25105;&#20204;&#33021;&#22815;&#36991;&#24320;&#32500;&#24230;&#28798;&#38590;&#65292;&#20855;&#26377;&#21487;&#20197;&#22788;&#29702;&#22810;&#20010;&#27969;&#24418;&#30340;&#24182;&#38598;&#24182;&#19988;&#40065;&#26834;&#24615;&#33021;&#24212;&#23545;&#21152;&#24615;&#22122;&#22768;&#21644;&#22024;&#26434;&#35266;&#23519;&#30340;&#39069;&#22806;&#20248;&#21183;&#12290;&#25105;&#20204;&#20026;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;&#32479;&#35745;&#20445;&#35777;&#65292;&#24182;&#36890;&#36807;&#27169;&#25311;&#21644;&#23454;&#38469;&#25968;&#25454;&#31034;&#20363;&#35777;&#26126;&#20102;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a new regression framework designed to deal with large-scale, complex data that lies around a low-dimensional manifold. Our approach first constructs a graph representation, referred to as the skeleton, to capture the underlying geometric structure. We then define metrics on the skeleton graph and apply nonparametric regression techniques, along with feature transformations based on the graph, to estimate the regression function. In addition to the included nonparametric methods, we also discuss the limitations of some nonparametric regressors with respect to the general metric space such as the skeleton graph. The proposed regression framework allows us to bypass the curse of dimensionality and provides additional advantages that it can handle the union of multiple manifolds and is robust to additive noise and noisy observations. We provide statistical guarantees for the proposed method and demonstrate its effectiveness through simulations and real data examples.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#23454;&#20102;Rademacher&#38543;&#26426;&#25237;&#24433;&#30340;&#38750;&#36951;&#24536;&#24615;&#33021;&#65292;&#24182;&#24314;&#31435;&#20102;Schur-&#20985;&#24615;&#36136;&#12290;&#36825;&#39033;&#25104;&#26524;&#20026;&#38543;&#26426;&#25237;&#24433;&#30340;&#24615;&#33021;&#25552;&#20379;&#20102;&#26032;&#30340;&#20960;&#20309;&#35270;&#35282;&#65292;&#20855;&#26377;&#26356;&#22909;&#30340;&#37327;&#21270;&#30028;&#38480;&#65292;&#22635;&#34917;&#20102;&#29702;&#35770;&#21644;&#23454;&#36341;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;</title><link>http://arxiv.org/abs/2303.11774</link><description>&lt;p&gt;
Rademacher&#38543;&#26426;&#23884;&#20837;&#30340;&#31934;&#30830;&#38750;&#36951;&#24536;&#24615;&#33021;
&lt;/p&gt;
&lt;p&gt;
Exact Non-Oblivious Performance of Rademacher Random Embeddings. (arXiv:2303.11774v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11774
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#23454;&#20102;Rademacher&#38543;&#26426;&#25237;&#24433;&#30340;&#38750;&#36951;&#24536;&#24615;&#33021;&#65292;&#24182;&#24314;&#31435;&#20102;Schur-&#20985;&#24615;&#36136;&#12290;&#36825;&#39033;&#25104;&#26524;&#20026;&#38543;&#26426;&#25237;&#24433;&#30340;&#24615;&#33021;&#25552;&#20379;&#20102;&#26032;&#30340;&#20960;&#20309;&#35270;&#35282;&#65292;&#20855;&#26377;&#26356;&#22909;&#30340;&#37327;&#21270;&#30028;&#38480;&#65292;&#22635;&#34917;&#20102;&#29702;&#35770;&#21644;&#23454;&#36341;&#20043;&#38388;&#30340;&#24046;&#36317;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37325;&#26032;&#23457;&#35270;&#20102;Rademacher&#38543;&#26426;&#25237;&#24433;&#30340;&#24615;&#33021;&#65292;&#24314;&#31435;&#20102;&#26032;&#39062;&#30340;&#32479;&#35745;&#20445;&#35777;&#65292;&#19982;&#36755;&#20837;&#25968;&#25454;&#30456;&#27604;&#20855;&#26377;&#25968;&#20540;&#19978;&#30340;&#31934;&#24230;&#21644;&#38750;&#36951;&#24536;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#20013;&#24515;&#32467;&#26524;&#26159;Rademacher&#38543;&#26426;&#25237;&#24433;&#19982;&#36755;&#20837;&#30340;Schur-&#20985;&#24615;&#36136;&#12290;&#36825;&#25552;&#20379;&#20102;&#38543;&#26426;&#25237;&#24433;&#24615;&#33021;&#30340;&#26032;&#39062;&#20960;&#20309;&#35270;&#35282;&#65292;&#21516;&#26102;&#22312;&#27604;&#20197;&#21069;&#30340;&#30740;&#31350;&#26356;&#22909;&#22320;&#25552;&#39640;&#20102;&#37327;&#21270;&#30028;&#38480;&#12290;&#20316;&#20026;&#36825;&#19968;&#26356;&#24191;&#27867;&#32467;&#26524;&#30340;&#25512;&#35770;&#65292;&#25105;&#20204;&#22312;&#31232;&#30095;&#25968;&#25454;&#25110;&#20998;&#24067;&#20855;&#26377;&#23567;&#33539;&#22260;&#30340;&#25968;&#25454;&#19978;&#33719;&#24471;&#20102;&#25913;&#36827;&#30340;&#34920;&#29616;&#12290;&#36825;&#31181;&#38750;&#36951;&#24536;&#24615;&#20998;&#26512;&#19982;&#20197;&#21069;&#30340;&#25216;&#26415;&#30456;&#27604;&#26159;&#19968;&#31181;&#26032;&#22855;&#20043;&#22788;&#65292;&#24182;&#24357;&#21512;&#20102;&#29702;&#35770;&#21644;&#23454;&#36341;&#20043;&#38388;&#32463;&#24120;&#35266;&#23519;&#21040;&#30340;&#24046;&#36317;&#12290;&#20027;&#35201;&#32467;&#26524;&#20351;&#29992;&#20195;&#25968;&#26694;&#26550;&#26469;&#35777;&#26126;Schur-&#20985;&#24615;&#36136;&#65292;&#36825;&#26159;&#19968;&#20010;&#29420;&#31435;&#20110;&#20852;&#36259;&#30340;&#36129;&#29486;&#65292;&#24182;&#19988;&#26159;&#23548;&#25968;&#22522;&#30784;&#26631;&#20934;&#30340;&#19968;&#31181;&#20248;&#38597;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper revisits the performance of Rademacher random projections, establishing novel statistical guarantees that are numerically sharp and non-oblivious with respect to the input data. More specifically, the central result is the Schur-concavity property of Rademacher random projections with respect to the inputs. This offers a novel geometric perspective on the performance of random projections, while improving quantitatively on bounds from previous works. As a corollary of this broader result, we obtained the improved performance on data which is sparse or is distributed with small spread. This non-oblivious analysis is a novelty compared to techniques from previous work, and bridges the frequently observed gap between theory and practise. The main result uses an algebraic framework for proving Schur-concavity properties, which is a contribution of independent interest and an elegant alternative to derivative-based criteria.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#36890;&#29992;&#24179;&#28369;&#24471;&#20998;&#20989;&#25968;&#29992;&#20110;&#29983;&#25104;&#27169;&#22411;&#65292;&#36890;&#36807;&#23548;&#20986;&#20854;&#21442;&#25968;&#21270;&#30340;&#36890;&#29992;&#24418;&#24335;&#65292;&#35814;&#32454;&#25551;&#36848;&#20102;&#23398;&#20064;&#24179;&#28369;&#21518;&#30340;M-&#23494;&#24230;&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#12290;&#21516;&#26102;&#65292;&#20351;&#29992;M&#20010;&#29420;&#31435;&#39640;&#26031;&#36890;&#36947;&#30340;&#22240;&#23376;&#26680;&#23545;&#26410;&#30693;&#30340;&#20852;&#36259;&#23494;&#24230;&#36827;&#34892;&#24179;&#28369;&#65292;&#24182;&#35780;&#20272;&#20102;&#20854;&#22312;CIFAR-10&#25968;&#25454;&#38598;&#19978;&#30340;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2303.11669</link><description>&lt;p&gt;
&#36890;&#29992;&#24179;&#28369;&#24471;&#20998;&#20989;&#25968;&#29992;&#20110;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Universal Smoothed Score Functions for Generative Modeling. (arXiv:2303.11669v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11669
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#36890;&#29992;&#24179;&#28369;&#24471;&#20998;&#20989;&#25968;&#29992;&#20110;&#29983;&#25104;&#27169;&#22411;&#65292;&#36890;&#36807;&#23548;&#20986;&#20854;&#21442;&#25968;&#21270;&#30340;&#36890;&#29992;&#24418;&#24335;&#65292;&#35814;&#32454;&#25551;&#36848;&#20102;&#23398;&#20064;&#24179;&#28369;&#21518;&#30340;M-&#23494;&#24230;&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#12290;&#21516;&#26102;&#65292;&#20351;&#29992;M&#20010;&#29420;&#31435;&#39640;&#26031;&#36890;&#36947;&#30340;&#22240;&#23376;&#26680;&#23545;&#26410;&#30693;&#30340;&#20852;&#36259;&#23494;&#24230;&#36827;&#34892;&#24179;&#28369;&#65292;&#24182;&#35780;&#20272;&#20102;&#20854;&#22312;CIFAR-10&#25968;&#25454;&#38598;&#19978;&#30340;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#22522;&#20110;&#29992;&#20855;&#26377;&#31561;&#22122;&#22768;&#32423;&#30340;M&#20010;&#29420;&#31435;&#39640;&#26031;&#36890;&#36947;&#30340;&#22240;&#23376;&#26680;&#24179;&#28369;&#26410;&#30693;$\mathbb{R}^d$&#20852;&#36259;&#23494;&#24230;&#30340;&#29983;&#25104;&#24314;&#27169;&#38382;&#39064;&#65292;&#39318;&#20808;&#36890;&#36807;&#23548;&#20986;&#20854;&#21442;&#25968;&#21270;&#30340;&#36890;&#29992;&#24418;&#24335;&#65292;&#23436;&#25972;&#25551;&#36848;&#20102;&#22312;$\mathbb{R}^{Md}$&#20013;&#23398;&#20064;&#24179;&#28369;&#21518;&#30340;&#23494;&#24230;&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#65288;&#31216;&#20026;M-&#23494;&#24230;&#65289;&#65292;&#24182;&#22240;&#20026;&#20854;&#26500;&#36896;&#26041;&#24335;&#32780;&#20855;&#26377;&#25490;&#21015;&#19981;&#21464;&#24615;&#65307;&#25509;&#30528;&#36890;&#36807;&#20998;&#26512;&#35813;&#31867;&#39640;&#26031;&#20998;&#24067;&#30340;&#26465;&#20214;&#25968;&#65292;&#30740;&#31350;&#20102;M-&#23494;&#24230;&#25277;&#26679;&#30340;&#26102;&#38388;&#22797;&#26434;&#24230;&#65292;&#24471;&#21040;&#20102;&#38543;&#30528;$M$&#30340;&#22686;&#21152;&#32780;&#8220;&#24418;&#29366;&#8221;&#21464;&#21270;&#30340;&#20960;&#20309;&#35266;&#23519;&#32467;&#35770;&#65307;&#26368;&#21518;&#65292;&#22312;CIFAR-10&#25968;&#25454;&#38598;&#19978;&#38024;&#23545;&#36825;&#31867;&#29983;&#25104;&#27169;&#22411;&#30340;&#26679;&#26412;&#36136;&#37327;&#36827;&#34892;&#20102;&#21576;&#29616;&#33258;&#30001;&#21019;&#36896;&#36317;&#31163;&#65288;14.15&#65289;&#32467;&#26524;&#30340;&#23454;&#39564;&#65292;&#23588;&#20854;&#22312;&#38271;&#26102;&#38388;&#28151;&#21512;&#30340;MCMC&#38142;&#19978;&#20165;&#20351;&#29992;&#21333;&#20010;&#22122;&#22768;&#31243;&#24207;&#30340;&#24773;&#20917;&#19979;&#33719;&#24471;&#20102;&#20540;&#24471;&#27880;&#24847;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of generative modeling based on smoothing an unknown density of interest in $\mathbb{R}^d$ using factorial kernels with $M$ independent Gaussian channels with equal noise levels introduced by Saremi and Srivastava (2022). First, we fully characterize the time complexity of learning the resulting smoothed density in $\mathbb{R}^{Md}$, called M-density, by deriving a universal form for its parametrization in which the score function is by construction permutation equivariant. Next, we study the time complexity of sampling an M-density by analyzing its condition number for Gaussian distributions. This spectral analysis gives a geometric insight on the "shape" of M-densities as one increases $M$. Finally, we present results on the sample quality in this class of generative models on the CIFAR-10 dataset where we report Fr\'echet inception distances (14.15), notably obtained with a single noise level on long-run fast-mixing MCMC chains.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#30456;&#20851;&#25968;&#25454;&#24207;&#21015;&#30340;&#23398;&#20064;&#65292;&#19981;&#20381;&#36182;&#28151;&#21512;&#21442;&#25968;&#25110;&#32773;&#36830;&#32493;&#24102;&#21442;&#29031;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#65292;&#23637;&#31034;&#20102;&#32479;&#19968;&#30340;&#39118;&#38505;&#30028;&#38480;&#65292;&#24182;&#25552;&#20986;&#20102;&#21487;&#24212;&#29992;&#20110;&#22330;&#26223;&#20248;&#21270;&#30340;&#30456;&#20851;&#32422;&#26463;&#38543;&#26426;&#31243;&#24207;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#35745;&#31639;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2303.11650</link><description>&lt;p&gt;
&#24102;&#26377;&#30456;&#20851;&#25968;&#25454;&#24207;&#21015;&#30340;&#23398;&#20064;&#30340;&#32479;&#19968;&#39118;&#38505;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Uniform Risk Bounds for Learning with Dependent Data Sequences. (arXiv:2303.11650v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11650
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#30456;&#20851;&#25968;&#25454;&#24207;&#21015;&#30340;&#23398;&#20064;&#65292;&#19981;&#20381;&#36182;&#28151;&#21512;&#21442;&#25968;&#25110;&#32773;&#36830;&#32493;&#24102;&#21442;&#29031;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#65292;&#23637;&#31034;&#20102;&#32479;&#19968;&#30340;&#39118;&#38505;&#30028;&#38480;&#65292;&#24182;&#25552;&#20986;&#20102;&#21487;&#24212;&#29992;&#20110;&#22330;&#26223;&#20248;&#21270;&#30340;&#30456;&#20851;&#32422;&#26463;&#38543;&#26426;&#31243;&#24207;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#35745;&#31639;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#29420;&#31435;&#25968;&#25454;&#30340;&#23398;&#20064;&#29702;&#35770;&#25512;&#24191;&#21040;&#20102;&#30456;&#20851;&#25968;&#25454;&#24207;&#21015;&#30340;&#24773;&#20917;&#12290;&#19982;&#22823;&#22810;&#25968;&#25991;&#29486;&#19981;&#21516;&#30340;&#26159;&#65292;&#25105;&#20204;&#19981;&#20381;&#36182;&#20110;&#28151;&#21512;&#21442;&#25968;&#25110;&#32773;&#36830;&#32493;&#24102;&#21442;&#29031;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#65292;&#32780;&#26159;&#37319;&#29992;&#20102;&#32463;&#20856;&#30340;&#35777;&#26126;&#27169;&#24335;&#21644;&#23481;&#37327;&#24230;&#37327;&#26469;&#25512;&#23548;&#32479;&#19968;&#30340;&#39118;&#38505;&#30028;&#38480;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#26631;&#20934;&#20998;&#31867;&#39118;&#38505;&#26368;&#23567;&#21270;&#29702;&#35770;&#22312;&#30456;&#20851;&#25968;&#25454;&#24773;&#20917;&#19979;&#30340;VC&#32500;&#30028;&#38480;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#22522;&#20110;R&#31639;&#23376;&#30340;&#22797;&#26434;&#24230;&#30028;&#38480;&#65292;&#20854;&#19982;&#29420;&#31435;&#21516;&#20998;&#24067;&#24773;&#20917;&#19979;&#26631;&#20934;&#30340;&#30028;&#38480;&#27809;&#26377;&#21464;&#21270;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#36825;&#20123;&#32467;&#26524;&#24212;&#29992;&#20110;&#22330;&#26223;&#20248;&#21270;&#30340;&#24773;&#24418;&#65292;&#20174;&#32780;&#35745;&#31639;&#20986;&#20855;&#26377;&#30456;&#20851;&#32422;&#26463;&#30340;&#38543;&#26426;&#31243;&#24207;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper extends standard results from learning theory with independent data to sequences of dependent data. Contrary to most of the literature, we do not rely on mixing arguments or sequential measures of complexity and derive uniform risk bounds with classical proof patterns and capacity measures. In particular, we show that the standard classification risk bounds based on the VC-dimension hold in the exact same form for dependent data, and further provide Rademacher complexity-based bounds, that remain unchanged compared to the standard results for the identically and independently distributed case. Finally, we show how to apply these results in the context of scenario-based optimization in order to compute the sample complexity of random programs with dependent constraints.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#21644;&#31215;&#22810;&#39033;&#24335;&#30340;&#28856;&#35010;&#31639;&#27861;&#21644;&#20854; RLCT&#12290;</title><link>http://arxiv.org/abs/2303.11619</link><description>&lt;p&gt;
&#27714;&#35299;&#21644;&#31215;&#22810;&#39033;&#24335;&#21644;&#23454;&#23545;&#25968;&#35268;&#33539;&#38408;&#20540;&#30340;&#28856;&#35010;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Blow-up Algorithm for Sum-of-Products Polynomials and Real Log Canonical Thresholds. (arXiv:2303.11619v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11619
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21644;&#31215;&#22810;&#39033;&#24335;&#30340;&#28856;&#35010;&#31639;&#27861;&#21644;&#20854; RLCT&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32771;&#34385;&#32473;&#20986;&#36125;&#21494;&#26031;&#24191;&#20041;&#35823;&#24046;&#30340;&#23454;&#23545;&#25968;&#35268;&#33539;&#38408;&#20540;&#26102;&#65292;&#35770;&#25991;&#29992;&#31245;&#24494;&#31616;&#21333;&#30340;&#22810;&#39033;&#24335;&#26367;&#25442;&#24179;&#22343;&#35823;&#24046;&#20989;&#25968;&#65292;&#20854; RLCT &#23545;&#24212;&#20110;&#24179;&#22343;&#35823;&#24046;&#20989;&#25968;&#30340; RLCT&#65292;&#24182;&#36890;&#36807;&#31216;&#20026;&#28856;&#35010;&#30340;&#20195;&#25968;&#25805;&#20316;&#35299;&#20915;&#20854;&#22855;&#28857;&#26469;&#33719;&#24471;&#20854; RLCT&#12290;&#34429;&#28982;&#20247;&#25152;&#21608;&#30693;&#65292;&#20219;&#20309;&#22810;&#39033;&#24335;&#30340;&#22855;&#28857;&#37117;&#21487;&#20197;&#36890;&#36807;&#26377;&#38480;&#27425;&#30340;&#28856;&#35010;&#36845;&#20195;&#26469;&#35299;&#20915;&#65292;&#20294;&#24182;&#27809;&#26377;&#26126;&#30830;&#26159;&#21542;&#21487;&#20197;&#36890;&#36807;&#24212;&#29992;&#29305;&#23450;&#30340;&#28856;&#35010;&#31639;&#27861;&#26469;&#35299;&#20915;&#29305;&#23450;&#22810;&#39033;&#24335;&#30340;&#22855;&#28857;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#32771;&#34385;&#20102;&#31216;&#20026;&#21644;&#31215;&#22810;&#39033;&#24335;&#30340;&#22810;&#39033;&#24335;&#30340;&#28856;&#35010;&#31639;&#27861;&#21450;&#20854; RLCT&#12290;
&lt;/p&gt;
&lt;p&gt;
When considering a real log canonical threshold (RLCT) that gives a Bayesian generalization error, in general, papers replace a mean error function with a relatively simple polynomial whose RLCT corresponds to that of the mean error function, and obtain its RLCT by resolving its singularities through an algebraic operation called blow-up. Though it is known that the singularities of any polynomial can be resolved by a finite number of blow-up iterations, it is not clarified whether or not it is possible to resolve singularities of a specific polynomial by applying a specific blow-up algorithm. Therefore this paper considers the blow-up algorithm for the polynomials called sum-of-products (sop) polynomials and its RLCT.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#36125;&#21494;&#26031;&#31639;&#27861;&#30340;&#33258;&#36866;&#24212;&#23454;&#39564;&#26694;&#26550;&#65292;&#21487;&#28789;&#27963;&#22788;&#29702;&#20219;&#20309;&#25209;&#22788;&#29702;&#22823;&#23567;&#12290;&#36890;&#36807;&#27491;&#24577;&#36817;&#20284;&#25351;&#23548;&#21487;&#25193;&#23637;&#33258;&#36866;&#24212;&#35774;&#35745;&#65292;&#37319;&#29992;&#27531;&#20313;&#26102;&#38480;&#20248;&#21270;&#36873;&#25321;&#37319;&#26679;&#20998;&#37197;&#65292;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2303.11582</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#36866;&#24212;&#24615;&#23454;&#39564;&#65306;&#28789;&#27963;&#25209;&#22788;&#29702;&#30340;&#36125;&#21494;&#26031;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Adaptive Experimentation at Scale: Bayesian Algorithms for Flexible Batches. (arXiv:2303.11582v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11582
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#36125;&#21494;&#26031;&#31639;&#27861;&#30340;&#33258;&#36866;&#24212;&#23454;&#39564;&#26694;&#26550;&#65292;&#21487;&#28789;&#27963;&#22788;&#29702;&#20219;&#20309;&#25209;&#22788;&#29702;&#22823;&#23567;&#12290;&#36890;&#36807;&#27491;&#24577;&#36817;&#20284;&#25351;&#23548;&#21487;&#25193;&#23637;&#33258;&#36866;&#24212;&#35774;&#35745;&#65292;&#37319;&#29992;&#27531;&#20313;&#26102;&#38480;&#20248;&#21270;&#36873;&#25321;&#37319;&#26679;&#20998;&#37197;&#65292;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#20934;&#30340;&#36125;&#21494;&#26031;&#31639;&#27861;&#20551;&#23450;&#25345;&#32493;&#37325;&#26032;&#20998;&#37197;&#27979;&#37327;&#24037;&#20316;&#65292;&#36825;&#22312;&#23454;&#29616;&#36807;&#31243;&#20013;&#23384;&#22312;&#24310;&#36831;&#21453;&#39304;&#21644;&#22522;&#30784;&#35774;&#26045;/&#32452;&#32455;&#38590;&#39064;&#31561;&#25361;&#25112;&#12290;&#26412;&#25991;&#38024;&#23545;&#20165;&#26377;&#23569;&#25968;&#37325;&#26032;&#20998;&#37197;&#38454;&#27573;&#30340;&#23454;&#38469;&#24773;&#20917;&#65292;&#20854;&#20013;&#27979;&#37327;&#32467;&#26524;&#26159;&#20197;&#25209;&#22788;&#29702;&#24418;&#24335;&#27979;&#37327;&#30340;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36866;&#24212;&#24615;&#23454;&#39564;&#26694;&#26550;&#65292;&#21487;&#28789;&#27963;&#22788;&#29702;&#20219;&#20309;&#25209;&#22788;&#29702;&#22823;&#23567;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#35266;&#23519;&#26159;&#65292;&#22312;&#32479;&#35745;&#25512;&#26029;&#20013;&#26222;&#36941;&#20351;&#29992;&#30340;&#27491;&#24577;&#36817;&#20284;&#20063;&#21487;&#20197;&#25351;&#23548;&#21487;&#25193;&#23637;&#33258;&#36866;&#24212;&#35774;&#35745;&#12290;&#36890;&#36807;&#25512;&#23548;&#28176;&#36827;&#39034;&#24207;&#23454;&#39564;&#65292;&#25105;&#20204;&#21046;&#23450;&#20102;&#19968;&#31181;&#21160;&#24577;&#35268;&#21010;&#65292;&#21487;&#20197;&#21033;&#29992;&#24179;&#22343;&#22238;&#25253;&#30340;&#20808;&#39564;&#20449;&#24687;&#12290;&#21160;&#24577;&#35268;&#21010;&#30340;&#29366;&#24577;&#36716;&#31227;&#30456;&#23545;&#20110;&#37319;&#26679;&#20998;&#37197;&#26159;&#21487;&#24494;&#30340;&#65292;&#20801;&#35768;&#20351;&#29992;&#22522;&#20110;&#26799;&#24230;&#30340;&#26041;&#27861;&#36827;&#34892;&#35268;&#21010;&#21644;&#31574;&#30053;&#20248;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#36845;&#20195;&#35268;&#21010;&#26041;&#27861;&#65292;&#21363;&#27531;&#20313;&#26102;&#38480;&#20248;&#21270;&#65292;&#36890;&#36807;&#20248;&#21270;&#24179;&#34913;&#25506;&#32034;&#21644;&#21033;&#29992;&#30340;&#35268;&#21010;&#30446;&#26631;&#26469;&#36873;&#25321;&#37319;&#26679;&#20998;&#37197;&#12290;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#22522;&#20934;&#27979;&#35797;&#38382;&#39064;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#21516;&#26102;&#20855;&#26377;&#27169;&#22359;&#21270;&#21644;&#26131;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Standard bandit algorithms that assume continual reallocation of measurement effort are challenging to implement due to delayed feedback and infrastructural/organizational difficulties. Motivated by practical instances involving a handful of reallocation epochs in which outcomes are measured in batches, we develop a new adaptive experimentation framework that can flexibly handle any batch size. Our main observation is that normal approximations universal in statistical inference can also guide the design of scalable adaptive designs. By deriving an asymptotic sequential experiment, we formulate a dynamic program that can leverage prior information on average rewards. State transitions of the dynamic program are differentiable with respect to the sampling allocations, allowing the use of gradient-based methods for planning and policy optimization. We propose a simple iterative planning method, Residual Horizon Optimization, which selects sampling allocations by optimizing a planning obj
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20855;&#26377;ReLU&#28608;&#27963;&#30340;&#38543;&#26426;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#29305;&#24449;&#25551;&#36848;&#65292;&#23545;&#20110;&#22238;&#24402;&#38382;&#39064;&#65292;&#23427;&#20204;&#31867;&#20284;&#20110;&#26080;&#38480;&#24191;&#20041;&#21152;&#24615;&#27169;&#22411;&#65288;IGAM&#65289;</title><link>http://arxiv.org/abs/2303.11454</link><description>&lt;p&gt;
&#22914;&#20309;&#25551;&#36848;ReLU&#31070;&#32463;&#32593;&#32476;&#30340;&#38544;&#24335;&#27491;&#21017;&#21270;&#29305;&#24615;&#8212;&#8212;&#31532;&#20108;&#37096;&#20998;&#65306;&#20855;&#26377;&#38543;&#26426;&#31532;&#19968;&#23618;&#30340;&#20004;&#23618;&#22810;&#32500;&#24773;&#20917;
&lt;/p&gt;
&lt;p&gt;
How (Implicit) Regularization of ReLU Neural Networks Characterizes the Learned Function -- Part II: the Multi-D Case of Two Layers with Random First Layer. (arXiv:2303.11454v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11454
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20855;&#26377;ReLU&#28608;&#27963;&#30340;&#38543;&#26426;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#30340;&#29305;&#24449;&#25551;&#36848;&#65292;&#23545;&#20110;&#22238;&#24402;&#38382;&#39064;&#65292;&#23427;&#20204;&#31867;&#20284;&#20110;&#26080;&#38480;&#24191;&#20041;&#21152;&#24615;&#27169;&#22411;&#65288;IGAM&#65289;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#21270;&#31070;&#32463;&#32593;&#32476;&#26159;&#19968;&#31181;&#24378;&#22823;&#30340;&#27169;&#22411;&#65292;&#20854;&#20013;&#20165;&#20248;&#21270;&#20102;&#26368;&#32456;&#23618;&#30340;&#26435;&#37325;&#65292;&#21487;&#38477;&#20302;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#30340;&#35745;&#31639;&#26102;&#38388;&#12290;&#21516;&#26102;&#65292;&#36825;&#20123;&#27169;&#22411;&#22312;&#21508;&#31181;&#22238;&#24402;&#21644;&#20998;&#31867;&#20219;&#21153;&#20013;&#30340;&#27867;&#21270;&#33021;&#21147;&#24778;&#20154;&#12290;&#26412;&#25991;&#23545;&#20110;&#20855;&#26377;ReLU&#28608;&#27963;&#30340;&#38543;&#26426;&#12289;&#27973;&#23618;&#31070;&#32463;&#32593;&#32476;&#25552;&#20986;&#20102;&#19968;&#20010;&#23439;&#35266;&#31934;&#30830;&#30340;&#29305;&#24449;&#25551;&#36848;&#65292;&#21363;&#24191;&#20041;&#21152;&#24615;&#27169;&#22411;&#65288;GAM&#65289;&#31867;&#22411;&#30340;&#22238;&#24402;&#38382;&#39064;&#65292;&#20854;&#20013;&#32771;&#34385;&#20102;&#26080;&#38480;&#22810;&#20010;&#26041;&#21521;&#65306;&#26080;&#38480;&#24191;&#20041;&#21152;&#24615;&#27169;&#22411;&#65288;IGAM&#65289;&#12290; IGAM&#34987;&#24418;&#24335;&#21270;&#20026;&#20989;&#25968;&#31354;&#38388;&#20013;&#29305;&#23450;&#27491;&#21017;&#21270;&#27867;&#20989;&#21644;&#30456;&#24403;&#19968;&#33324;&#30340;&#25439;&#22833;&#20989;&#25968;&#30340;&#20248;&#21270;&#38382;&#39064;&#30340;&#35299;&#12290;&#26412;&#25991;&#26159;&#22312;&#20808;&#21069;&#30740;&#31350;&#30340;&#22522;&#30784;&#19978;&#23545;&#22810;&#20803;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#30340;&#25193;&#23637;&#65292;&#25105;&#20204;&#22312;&#20808;&#21069;&#30740;&#31350;&#20013;&#23637;&#31034;&#20102;&#22312;&#26576;&#20123;&#26465;&#20214;&#19979;&#20855;&#26377;ReLU&#28608;&#27963;&#30340;&#23485;&#24335;RSNs&#30340;&#34892;&#20026;&#31867;&#20284;&#20110;&#26679;&#26465;&#22238;&#24402;&#12290;
&lt;/p&gt;
&lt;p&gt;
Randomized neural networks (randomized NNs), where only the terminal layer's weights are optimized constitute a powerful model class to reduce computational time in training the neural network model. At the same time, these models generalize surprisingly well in various regression and classification tasks. In this paper, we give an exact macroscopic characterization (i.e., a characterization in function space) of the generalization behavior of randomized, shallow NNs with ReLU activation (RSNs). We show that RSNs correspond to a generalized additive model (GAM)-typed regression in which infinitely many directions are considered: the infinite generalized additive model (IGAM). The IGAM is formalized as solution to an optimization problem in function space for a specific regularization functional and a fairly general loss. This work is an extension to multivariate NNs of prior work, where we showed how wide RSNs with ReLU activation behave like spline regression under certain conditions 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#30697;&#38453;&#24863;&#30693;&#38382;&#39064;&#20013;&#30740;&#31350;&#20102;&#22522;&#20110;Group Lasso&#27491;&#21017;&#21270;&#22120;&#30340;&#36138;&#23146;&#21098;&#26525;&#26041;&#27861;&#65292;&#35777;&#26126;&#20102;&#20462;&#21098;&#20302;$\ell_2$&#33539;&#25968;&#21015;&#30340;&#35299;&#21487;&#20197;&#27867;&#21270;&#21040;&#26032;&#26679;&#26412;&#19978;&#12290;</title><link>http://arxiv.org/abs/2303.11453</link><description>&lt;p&gt;
&#22522;&#20110;Group Lasso&#30340;&#36138;&#23146;&#21098;&#26525;&#22312;&#30697;&#38453;&#24863;&#30693;&#21644;&#20108;&#27425;&#28608;&#27963;&#31070;&#32463;&#32593;&#32476;&#19978;&#21487;&#35777;&#22320;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
Greedy Pruning with Group Lasso Provably Generalizes for Matrix Sensing and Neural Networks with Quadratic Activations. (arXiv:2303.11453v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11453
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#30697;&#38453;&#24863;&#30693;&#38382;&#39064;&#20013;&#30740;&#31350;&#20102;&#22522;&#20110;Group Lasso&#27491;&#21017;&#21270;&#22120;&#30340;&#36138;&#23146;&#21098;&#26525;&#26041;&#27861;&#65292;&#35777;&#26126;&#20102;&#20462;&#21098;&#20302;$\ell_2$&#33539;&#25968;&#21015;&#30340;&#35299;&#21487;&#20197;&#27867;&#21270;&#21040;&#26032;&#26679;&#26412;&#19978;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21098;&#26525;&#26041;&#26696;&#24191;&#27867;&#29992;&#20110;&#38477;&#20302;&#20855;&#26377;&#22823;&#37327;&#21442;&#25968;&#30340;&#27169;&#22411;&#30340;&#22797;&#26434;&#24615;&#12290;&#23454;&#36341;&#30740;&#31350;&#34920;&#26126;&#65292;&#20462;&#21098;&#36807;&#24230;&#21442;&#25968;&#21270;&#27169;&#22411;&#24182;&#24494;&#35843;&#21487;&#24456;&#22909;&#22320;&#27867;&#21270;&#21040;&#26032;&#26679;&#26412;&#19978;&#12290;&#34429;&#28982;&#20197;&#19978;&#34987;&#31216;&#20026;&#21098;&#26525;+&#24494;&#35843;&#30340;&#27969;&#31243;&#22312;&#38477;&#20302;&#35757;&#32451;&#27169;&#22411;&#30340;&#22797;&#26434;&#24615;&#26041;&#38754;&#38750;&#24120;&#25104;&#21151;&#65292;&#20294;&#20854;&#32972;&#21518;&#30340;&#29702;&#35770;&#20173;&#28982;&#19981;&#29978;&#20102;&#35299;&#12290;&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#36229;&#21442;&#25968;&#21270;&#30697;&#38453;&#24863;&#30693;&#38382;&#39064;&#19978;&#30340;&#21098;&#26525;+&#24494;&#35843;&#26694;&#26550;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#20854;&#20013;&#30495;&#23454;&#32467;&#26524;&#34920;&#31034;&#20026;$U_\star \in \mathbb{R}^{d \times r}$&#65292;&#32780;&#36229;&#21442;&#25968;&#21270;&#27169;&#22411;&#34920;&#31034;&#20026;$U \in \mathbb{R}^{d \times k}$&#65292;&#20854;&#20013;$k \gg r$&#12290;&#25105;&#20204;&#30740;&#31350;&#21152;&#19978;Group Lasso&#27491;&#21017;&#21270;&#22120;&#30340;&#24179;&#28369;&#29256;&#26412;$\sum_{i=1}^k \| U e_i \|_2$&#30340;&#24179;&#22343;&#35823;&#24046;&#30340;&#36817;&#20284;&#23616;&#37096;&#26497;&#23567;&#20540;&#65292;&#35777;&#26126;&#20462;&#21098;&#20302;$\ell_2$&#33539;&#25968;&#21015;&#30340;&#35299;$U_{
&lt;/p&gt;
&lt;p&gt;
Pruning schemes have been widely used in practice to reduce the complexity of trained models with a massive number of parameters. Several practical studies have shown that pruning an overparameterized model and fine-tuning generalizes well to new samples. Although the above pipeline, which we refer to as pruning + fine-tuning, has been extremely successful in lowering the complexity of trained models, there is very little known about the theory behind this success. In this paper we address this issue by investigating the pruning + fine-tuning framework on the overparameterized matrix sensing problem, with the ground truth denoted $U_\star \in \mathbb{R}^{d \times r}$ and the overparameterized model $U \in \mathbb{R}^{d \times k}$ with $k \gg r$. We study the approximate local minima of the empirical mean square error, augmented with a smooth version of a group Lasso regularizer, $\sum_{i=1}^k \| U e_i \|_2$ and show that pruning the low $\ell_2$-norm columns results in a solution $U_{\
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26629;&#26684;&#35268;&#33539;&#31561;&#21464;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#20840;&#23616;&#32676;&#31561;&#21464;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#20960;&#20309;&#20844;&#24335;&#65292;&#34920;&#26126;L-CNN&#20013;&#30340;&#21367;&#31215;&#26159;SU($N$)&#20027;&#19995;&#19978;&#35268;&#33539;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#30340;&#19968;&#20010;&#29305;&#20363;&#12290;</title><link>http://arxiv.org/abs/2303.11448</link><description>&lt;p&gt;
&#26629;&#26684;&#35268;&#33539;&#31561;&#21464;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#20960;&#20309;&#26041;&#38754;
&lt;/p&gt;
&lt;p&gt;
Geometrical aspects of lattice gauge equivariant convolutional neural networks. (arXiv:2303.11448v1 [hep-lat])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11448
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26629;&#26684;&#35268;&#33539;&#31561;&#21464;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#20840;&#23616;&#32676;&#31561;&#21464;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#20010;&#20960;&#20309;&#20844;&#24335;&#65292;&#34920;&#26126;L-CNN&#20013;&#30340;&#21367;&#31215;&#26159;SU($N$)&#20027;&#19995;&#19978;&#35268;&#33539;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#30340;&#19968;&#20010;&#29305;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26629;&#26684;&#35268;&#33539;&#31561;&#21464;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;(L-CNNs)&#26159;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#26694;&#26550;&#65292;&#21487;&#24212;&#29992;&#20110;&#38750;&#38463;&#36125;&#23572;&#26629;&#26684;&#35268;&#33539;&#29702;&#35770;&#65292;&#32780;&#19981;&#36829;&#21453;&#35268;&#33539;&#23545;&#31216;&#24615;&#12290;&#25105;&#20204;&#28436;&#31034;&#20102;&#22914;&#20309;&#23558;L-CNNs&#37197;&#22791;&#20840;&#23616;&#32676;&#31561;&#21464;&#24615;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#23558;&#20844;&#24335;&#25193;&#23637;&#20026;&#26082;&#31561;&#21464;&#20110;&#24179;&#31227;&#65292;&#21448;&#31561;&#21464;&#20110;&#20840;&#23616;&#32441;&#26684;&#23545;&#31216;&#24615;&#65292;&#20363;&#22914;&#26059;&#36716;&#21644;&#21453;&#23556;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;L-CNN&#30340;&#20960;&#20309;&#20844;&#24335;&#65292;&#24182;&#26174;&#31034;L-CNN&#20013;&#30340;&#21367;&#31215;&#26159;SU($N$)&#20027;&#19995;&#19978;&#35268;&#33539;&#31561;&#21464;&#31070;&#32463;&#32593;&#32476;&#30340;&#29305;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
Lattice gauge equivariant convolutional neural networks (L-CNNs) are a framework for convolutional neural networks that can be applied to non-Abelian lattice gauge theories without violating gauge symmetry. We demonstrate how L-CNNs can be equipped with global group equivariance. This allows us to extend the formulation to be equivariant not just under translations but under global lattice symmetries such as rotations and reflections. Additionally, we provide a geometric formulation of L-CNNs and show how convolutions in L-CNNs arise as a special case of gauge equivariant neural networks on SU($N$) principal bundles.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20195;&#29702;&#27169;&#22411;&#36827;&#34892;&#27969;&#22270;&#26657;&#20934;&#30340;&#26694;&#26550;&#65292; &#24182;&#32467;&#21512;&#20808;&#21069;&#36741;&#21161;&#36807;&#31243;&#30340;&#30693;&#35782;&#26469;&#35299;&#20915;&#39640;&#32500;&#36870;&#38382;&#39064;&#65292;&#25104;&#21151;&#35782;&#21035;&#20102;&#39640;&#32500;&#31995;&#32479;&#20013;&#30340;&#28304;&#12290;</title><link>http://arxiv.org/abs/2303.11379</link><description>&lt;p&gt;
&#21033;&#29992;&#36741;&#21161;&#19981;&#30830;&#23450;&#24615;&#36827;&#34892;&#30340;&#36816;&#31639;&#22120;&#23398;&#20064;&#26469;&#35299;&#20915;&#39640;&#32500;&#36870;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Solving High-Dimensional Inverse Problems with Auxiliary Uncertainty via Operator Learning with Limited Data. (arXiv:2303.11379v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11379
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20195;&#29702;&#27169;&#22411;&#36827;&#34892;&#27969;&#22270;&#26657;&#20934;&#30340;&#26694;&#26550;&#65292; &#24182;&#32467;&#21512;&#20808;&#21069;&#36741;&#21161;&#36807;&#31243;&#30340;&#30693;&#35782;&#26469;&#35299;&#20915;&#39640;&#32500;&#36870;&#38382;&#39064;&#65292;&#25104;&#21151;&#35782;&#21035;&#20102;&#39640;&#32500;&#31995;&#32479;&#20013;&#30340;&#28304;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22797;&#26434;&#30340;&#22823;&#35268;&#27169;&#31995;&#32479;&#65288;&#22914;&#27668;&#20505;&#65289;&#20013;&#65292;&#37325;&#35201;&#30340;&#24433;&#21709;&#26159;&#30001;&#22810;&#31181;&#26410;&#34987;&#23436;&#20840;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#36807;&#31243;&#30456;&#20114;&#20316;&#29992;&#24341;&#36215;&#30340;&#12290;&#26681;&#25454;&#31995;&#32479;&#29366;&#24577;&#30340;&#35266;&#23519;&#32467;&#26524;&#26469;&#35782;&#21035;&#20986;&#36825;&#20123;&#24433;&#21709;&#22240;&#32032;&#23545;&#20110;&#24402;&#22240;&#21644;&#39044;&#27979;&#33267;&#20851;&#37325;&#35201;&#65292;&#36825;&#20123;&#32467;&#26524;&#21448;&#20026;&#20915;&#31574;&#21046;&#23450;&#25552;&#20379;&#20102;&#37325;&#35201;&#30340;&#20449;&#24687;&#12290;&#36825;&#20123;&#36870;&#38382;&#39064;&#30340;&#38590;&#28857;&#22312;&#20110;&#26080;&#27861;&#38548;&#31163;&#24433;&#21709;&#22240;&#32032;&#21644;&#35745;&#31639;&#27169;&#22411;&#27169;&#25311;&#30340;&#25104;&#26412;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#22522;&#20110;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20195;&#29702;&#27169;&#22411;&#36827;&#34892;&#27969;&#22270;&#26657;&#20934;&#65292;&#24182;&#32467;&#21512;&#20808;&#21069;&#36741;&#21161;&#36807;&#31243;&#30340;&#30693;&#35782;&#26469;&#35299;&#20915;&#26377;&#38480;&#25968;&#25454;&#19979;&#30340;&#39640;&#32500;&#36870;&#38382;&#39064;&#30340;&#26694;&#26550;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#25104;&#21151;&#22320;&#22312;&#35266;&#23519;&#25968;&#25454;&#31232;&#30095;&#22122;&#22768;&#36739;&#22823;&#30340;&#39640;&#32500;&#31995;&#32479;&#20013;&#30830;&#23450;&#20986;&#28304;&#65292;&#34920;&#29616;&#20248;&#20110;&#29616;&#26377;&#26377;&#38480;&#25968;&#25454;&#28304;&#35782;&#21035;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In complex large-scale systems such as climate, important effects are caused by a combination of confounding processes that are not fully observable. The identification of sources from observations of system state is vital for attribution and prediction, which inform critical policy decisions. The difficulty of these types of inverse problems lies in the inability to isolate sources and the cost of simulating computational models. Surrogate models may enable the many-query algorithms required for source identification, but data challenges arise from high dimensionality of the state and source, limited ensembles of costly model simulations to train a surrogate model, and few and potentially noisy state observations for inversion due to measurement limitations. The influence of auxiliary processes adds an additional layer of uncertainty that further confounds source identification. We introduce a framework based on (1) calibrating deep neural network surrogates to the flow maps provided 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#24191;&#20041;&#30340;&#20957;&#32858;&#27010;&#24565;&#65292;&#26500;&#24314;&#22312;&#20998;&#21306;&#23616;&#37096;&#28145;&#24230;&#30340;&#25216;&#26415;&#22522;&#30784;&#19978;&#65292;&#25193;&#23637;&#20102;&#26089;&#26399;&#32467;&#26524;&#24182;&#24212;&#29992;&#20110;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#30340;&#25968;&#25454;&#30340;&#31038;&#21306;&#21457;&#29616;&#20013;&#12290;</title><link>http://arxiv.org/abs/2303.10167</link><description>&lt;p&gt;
&#24191;&#20041;&#21010;&#20998;&#23616;&#37096;&#28145;&#24230;
&lt;/p&gt;
&lt;p&gt;
Generalized partitioned local depth. (arXiv:2303.10167v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.10167
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#24191;&#20041;&#30340;&#20957;&#32858;&#27010;&#24565;&#65292;&#26500;&#24314;&#22312;&#20998;&#21306;&#23616;&#37096;&#28145;&#24230;&#30340;&#25216;&#26415;&#22522;&#30784;&#19978;&#65292;&#25193;&#23637;&#20102;&#26089;&#26399;&#32467;&#26524;&#24182;&#24212;&#29992;&#20110;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#30340;&#25968;&#25454;&#30340;&#31038;&#21306;&#21457;&#29616;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20379;&#20102;&#19968;&#20010;&#26368;&#36817;&#30001;Berenhaut&#12289;Moore&#21644;Melvin [Proccedings of the National Academy of Sciences, 119 (4) (2022)]&#25552;&#20986;&#30340;&#20957;&#32858;&#27010;&#24565;&#30340;&#27010;&#25324;&#12290;&#25152;&#25552;&#20986;&#30340;&#34920;&#36848;&#22522;&#20110;&#20998;&#21306;&#23616;&#37096;&#28145;&#24230;&#30340;&#25216;&#26415;&#24182;&#25552;&#28860;&#20102;&#20004;&#20010;&#20851;&#38190;&#27010;&#29575;&#27010;&#24565;&#65306;&#23616;&#37096;&#30456;&#20851;&#24615;&#21644;&#25903;&#25345;&#20998;&#21106;&#12290;&#26089;&#26399;&#32467;&#26524;&#22312;&#26032;&#30340;&#32972;&#26223;&#19979;&#24471;&#21040;&#25193;&#23637;&#65292;&#24182;&#21253;&#25324;&#22312;&#20855;&#26377;&#19981;&#30830;&#23450;&#24615;&#30340;&#25968;&#25454;&#20013;&#25581;&#31034;&#31038;&#21306;&#30340;&#24212;&#29992;&#31034;&#20363;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper we provide a generalization of the concept of cohesion as introduced recently by Berenhaut, Moore and Melvin [Proceedings of the National Academy of Sciences, 119 (4) (2022)]. The formulation presented builds on the technique of partitioned local depth by distilling two key probabilistic concepts: local relevance and support division. Earlier results are extended within the new context, and examples of applications to revealing communities in data with uncertainty are included.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20174;&#36125;&#21494;&#26031;&#20915;&#31574;&#29702;&#35770;&#30340;&#35282;&#24230;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#19988;&#26377;&#21407;&#21017;&#30340;&#26694;&#26550;&#65292;&#20026;&#38271;&#23614;&#20998;&#31867;&#25552;&#20379;&#20102;&#29702;&#35770;&#19978;&#30340;&#25903;&#25345;&#65292;&#24182;&#37319;&#29992;&#32508;&#21512;&#39118;&#38505;&#21644;&#36125;&#21494;&#26031;&#28145;&#24230;&#38598;&#25104;&#26041;&#27861;&#20197;&#25552;&#39640;&#25152;&#26377;&#31867;&#21035;&#30340;&#20934;&#30830;&#24615;&#65292;&#29305;&#21035;&#26159;&#8220;&#38271;&#23614;&#8221;&#31867;&#21035;&#12290;</title><link>http://arxiv.org/abs/2303.06075</link><description>&lt;p&gt;
&#20174;&#36125;&#21494;&#26031;&#20915;&#31574;&#29702;&#35770;&#30340;&#35282;&#24230;&#30475;&#24453;&#38271;&#23614;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Long-tailed Classification from a Bayesian-decision-theory Perspective. (arXiv:2303.06075v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.06075
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#36125;&#21494;&#26031;&#20915;&#31574;&#29702;&#35770;&#30340;&#35282;&#24230;&#25552;&#20986;&#20102;&#19968;&#20010;&#36890;&#29992;&#19988;&#26377;&#21407;&#21017;&#30340;&#26694;&#26550;&#65292;&#20026;&#38271;&#23614;&#20998;&#31867;&#25552;&#20379;&#20102;&#29702;&#35770;&#19978;&#30340;&#25903;&#25345;&#65292;&#24182;&#37319;&#29992;&#32508;&#21512;&#39118;&#38505;&#21644;&#36125;&#21494;&#26031;&#28145;&#24230;&#38598;&#25104;&#26041;&#27861;&#20197;&#25552;&#39640;&#25152;&#26377;&#31867;&#21035;&#30340;&#20934;&#30830;&#24615;&#65292;&#29305;&#21035;&#26159;&#8220;&#38271;&#23614;&#8221;&#31867;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38271;&#23614;&#20998;&#31867;&#30001;&#20110;&#31867;&#21035;&#27010;&#29575;&#30340;&#20005;&#37325;&#19981;&#24179;&#34913;&#21644;&#23545;&#31216;&#38169;&#35823;&#39044;&#27979;&#25104;&#26412;&#23384;&#22312;&#23614;&#37096;&#25935;&#24863;&#39118;&#38505;&#32780;&#38754;&#20020;&#25361;&#25112;&#12290;&#26368;&#36817;&#30340;&#23581;&#35797;&#37319;&#29992;&#37325;&#26032;&#24179;&#34913;&#25439;&#22833;&#21644;&#38598;&#25104;&#26041;&#27861;&#65292;&#20294;&#23427;&#20204;&#24456;&#22823;&#31243;&#24230;&#19978;&#26159;&#21551;&#21457;&#24335;&#30340;&#65292;&#24182;&#19988;&#20005;&#37325;&#20381;&#36182;&#32463;&#39564;&#32467;&#26524;&#65292;&#32570;&#20047;&#29702;&#35770;&#35299;&#37322;&#12290;&#27492;&#22806;&#65292;&#29616;&#26377;&#26041;&#27861;&#24573;&#30053;&#20102;&#20915;&#31574;&#25439;&#22833;&#65292;&#23427;&#21051;&#30011;&#20102;&#19982;&#23614;&#37096;&#31867;&#21035;&#30456;&#20851;&#30340;&#19981;&#21516;&#25104;&#26412;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20174;&#36125;&#21494;&#26031;&#20915;&#31574;&#29702;&#35770;&#30340;&#35282;&#24230;&#30475;&#24453;&#38271;&#23614;&#20998;&#31867;&#30340;&#36890;&#29992;&#19988;&#26377;&#21407;&#21017;&#30340;&#26694;&#26550;&#65292;&#23427;&#32479;&#19968;&#20102;&#21253;&#25324;&#37325;&#26032;&#24179;&#34913;&#21644;&#38598;&#25104;&#26041;&#27861;&#22312;&#20869;&#30340;&#29616;&#26377;&#25216;&#26415;&#65292;&#24182;&#20026;&#23427;&#20204;&#30340;&#26377;&#25928;&#24615;&#25552;&#20379;&#20102;&#29702;&#35770;&#19978;&#30340;&#35777;&#26126;&#12290;&#20174;&#36825;&#20010;&#35282;&#24230;&#30475;&#65292;&#25105;&#20204;&#22522;&#20110;&#32508;&#21512;&#39118;&#38505;&#23548;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#30446;&#26631;&#21644;&#19968;&#20010;&#36125;&#21494;&#26031;&#28145;&#24230;&#38598;&#25104;&#26041;&#27861;&#65292;&#20197;&#25552;&#39640;&#25152;&#26377;&#31867;&#21035;&#30340;&#20934;&#30830;&#24615;&#65292;&#29305;&#21035;&#26159;&#8220;&#38271;&#23614;&#8221;&#31867;&#21035;&#30340;&#20934;&#30830;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26694;&#26550;&#20801;&#35768;&#20219;&#21153;&#33258;&#36866;&#24212;&#20915;&#31574;&#25439;&#22833;&#65292;&#20174;&#32780;&#25552;&#20379;&#20102;&#22312;&#19981;&#21516;&#20219;&#21153;&#20013;&#21487;&#35777;&#26126;&#30340;&#26368;&#20248;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;
Long-tailed classification poses a challenge due to its heavy imbalance in class probabilities and tail-sensitivity risks with asymmetric misprediction costs. Recent attempts have used re-balancing loss and ensemble methods, but they are largely heuristic and depend heavily on empirical results, lacking theoretical explanation. Furthermore, existing methods overlook the decision loss, which characterizes different costs associated with tailed classes. This paper presents a general and principled framework from a Bayesian-decision-theory perspective, which unifies existing techniques including re-balancing and ensemble methods, and provides theoretical justifications for their effectiveness. From this perspective, we derive a novel objective based on the integrated risk and a Bayesian deep-ensemble approach to improve the accuracy of all classes, especially the "tail". Besides, our framework allows for task-adaptive decision loss which provides provably optimal decisions in varying task
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#38480;&#21046;&#21322;&#27491;&#23450;&#30697;&#38453;&#27969;&#24418;&#19978;&#30340;&#26412;&#36136;&#22343;&#20540;&#27169;&#22411;&#21450;&#20854;Karcher&#22343;&#20540;&#30340;&#32479;&#35745;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#19968;&#33324;&#22806;&#37096;&#20449;&#21495;&#21152;&#22122;&#22768;&#27169;&#22411;&#19979;&#30340;&#30830;&#23450;&#24615;&#35823;&#24046;&#30028;&#65292;&#24182;&#34920;&#26126;LRC-dPCA&#31639;&#27861;&#19982;&#20840;&#26679;&#26412;PCA&#31639;&#27861;&#24615;&#33021;&#30456;&#21516;&#12290;</title><link>http://arxiv.org/abs/2302.12426</link><description>&lt;p&gt;
&#38480;&#21046;&#21322;&#27491;&#23450;&#30697;&#38453;&#30340;Karcher&#22343;&#20540;&#30340;&#32479;&#35745;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Statistical Analysis of Karcher Means for Random Restricted PSD Matrices. (arXiv:2302.12426v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.12426
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#38480;&#21046;&#21322;&#27491;&#23450;&#30697;&#38453;&#27969;&#24418;&#19978;&#30340;&#26412;&#36136;&#22343;&#20540;&#27169;&#22411;&#21450;&#20854;Karcher&#22343;&#20540;&#30340;&#32479;&#35745;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#19968;&#33324;&#22806;&#37096;&#20449;&#21495;&#21152;&#22122;&#22768;&#27169;&#22411;&#19979;&#30340;&#30830;&#23450;&#24615;&#35823;&#24046;&#30028;&#65292;&#24182;&#34920;&#26126;LRC-dPCA&#31639;&#27861;&#19982;&#20840;&#26679;&#26412;PCA&#31639;&#27861;&#24615;&#33021;&#30456;&#21516;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#20960;&#20309;&#24863;&#30693;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#36890;&#24120;&#30001;&#20110;&#21487;&#33021;&#22797;&#26434;&#30340;&#38750;&#32447;&#24615;&#27969;&#24418;&#32467;&#26500;&#32780;&#32570;&#20047;&#38750;&#28176;&#36827;&#32479;&#35745;&#20998;&#26512;&#12290;&#26412;&#25991;&#22312;&#38480;&#21046;&#21322;&#27491;&#23450;&#30697;&#38453;&#27969;&#24418;&#19978;&#30740;&#31350;&#26412;&#36136;&#22343;&#20540;&#27169;&#22411;&#65292;&#24182;&#25552;&#20379;Karcher&#22343;&#20540;&#30340;&#38750;&#28176;&#36827;&#32479;&#35745;&#20998;&#26512;&#12290;&#25105;&#20204;&#36824;&#32771;&#34385;&#20102;&#19968;&#33324;&#30340;&#22806;&#37096;&#20449;&#21495;&#21152;&#22122;&#22768;&#27169;&#22411;&#65292;&#22312;&#27492;&#27169;&#22411;&#19979;&#25552;&#20379;&#20102;Karcher&#22343;&#20540;&#30340;&#30830;&#23450;&#24615;&#35823;&#24046;&#30028;&#12290;&#20316;&#20026;&#19968;&#20010;&#24212;&#29992;&#65292;&#25105;&#20204;&#23637;&#31034;&#20998;&#24067;&#24335;&#20027;&#25104;&#20998;&#20998;&#26512;&#31639;&#27861;LRC-dPCA&#30340;&#24615;&#33021;&#19982;&#20840;&#26679;&#26412;PCA&#31639;&#27861;&#30456;&#21516;&#12290;&#25968;&#20540;&#23454;&#39564;&#20805;&#20998;&#25903;&#25345;&#25105;&#20204;&#30340;&#29702;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
Non-asymptotic statistical analysis is often missing for modern geometry-aware machine learning algorithms due to the possibly intricate non-linear manifold structure. This paper studies an intrinsic mean model on the manifold of restricted positive semi-definite matrices and provides a non-asymptotic statistical analysis of the Karcher mean. We also consider a general extrinsic signal-plus-noise model, under which a deterministic error bound of the Karcher mean is provided. As an application, we show that the distributed principal component analysis algorithm, LRC-dPCA, achieves the same performance as the full sample PCA algorithm. Numerical experiments lend strong support to our theories.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#40654;&#26364;&#23376;&#27969;&#24418;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#20102;&#31616;&#21270;&#65292;&#25552;&#20986;&#20102;&#40654;&#26364;&#27491;&#24120;&#22352;&#26631;&#30340;&#24191;&#20041;&#29256;&#26412;&#65292;&#21487;&#29992;&#20110;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#30340;&#23376;&#27969;&#24418;&#20248;&#21270;&#65292;&#24182;&#20026;&#28145;&#24230;&#23398;&#20064;&#24320;&#21457;&#20102;&#39640;&#25928;&#30340;&#20108;&#38454;&#20248;&#21270;&#22120;&#65292;&#26080;&#38656;&#26174;&#24335;&#30697;&#38453;&#27714;&#36870;&#12290;</title><link>http://arxiv.org/abs/2302.09738</link><description>&lt;p&gt;
&#31616;&#21270;&#22522;&#20110;&#21160;&#37327;&#30340;&#40654;&#26364;&#23376;&#27969;&#24418;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Simplifying Momentum-based Riemannian Submanifold Optimization. (arXiv:2302.09738v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.09738
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#40654;&#26364;&#23376;&#27969;&#24418;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#20102;&#31616;&#21270;&#65292;&#25552;&#20986;&#20102;&#40654;&#26364;&#27491;&#24120;&#22352;&#26631;&#30340;&#24191;&#20041;&#29256;&#26412;&#65292;&#21487;&#29992;&#20110;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#30340;&#23376;&#27969;&#24418;&#20248;&#21270;&#65292;&#24182;&#20026;&#28145;&#24230;&#23398;&#20064;&#24320;&#21457;&#20102;&#39640;&#25928;&#30340;&#20108;&#38454;&#20248;&#21270;&#22120;&#65292;&#26080;&#38656;&#26174;&#24335;&#30697;&#38453;&#27714;&#36870;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24102;&#26377;&#21160;&#37327;&#30340;&#40654;&#26364;&#23376;&#27969;&#24418;&#20248;&#21270;&#22312;&#35745;&#31639;&#19978;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#65292;&#22240;&#20026;&#30830;&#20445;&#36845;&#20195;&#20445;&#25345;&#22312;&#23376;&#27969;&#24418;&#19978;&#36890;&#24120;&#38656;&#35201;&#35299;&#20915;&#22256;&#38590;&#30340;&#24494;&#20998;&#26041;&#31243;&#12290;&#26412;&#25991;&#38024;&#23545;&#20855;&#26377;&#20223;&#23556;&#19981;&#21464;&#24230;&#37327;&#30340;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#30340;&#23376;&#27969;&#24418;&#20248;&#21270;&#31639;&#27861;&#36827;&#34892;&#20102;&#31616;&#21270;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#40654;&#26364;&#27491;&#24120;&#22352;&#26631;&#30340;&#24191;&#20041;&#29256;&#26412;&#65292;&#21487;&#20197;&#23558;&#38382;&#39064;&#21160;&#24577;&#22320;&#31616;&#21270;&#20026;&#27431;&#20960;&#37324;&#24471;&#26080;&#32422;&#26463;&#38382;&#39064;&#12290;&#25105;&#20204;&#20351;&#29992;&#25105;&#20204;&#30340;&#26041;&#27861;&#26469;&#35299;&#37322;&#21644;&#31616;&#21270;&#29616;&#26377;&#30340;&#32467;&#26500;&#21270;&#21327;&#26041;&#24046;&#26041;&#27861;&#65292;&#24182;&#20026;&#28145;&#24230;&#23398;&#20064;&#24320;&#21457;&#20102;&#39640;&#25928;&#30340;&#20108;&#38454;&#20248;&#21270;&#22120;&#65292;&#32780;&#26080;&#38656;&#26174;&#24335;&#30697;&#38453;&#27714;&#36870;&#12290;
&lt;/p&gt;
&lt;p&gt;
Riemannian submanifold optimization with momentum is computationally challenging because ensuring iterates remain on the submanifold often requires solving difficult differential equations. We simplify such optimization algorithms for the submanifold of symmetric positive-definite matrices with the affine invariant metric. We propose a generalized version of the Riemannian normal coordinates which dynamically trivializes the problem into a Euclidean unconstrained problem. We use our approach to explain and simplify existing approaches for structured covariances and develop efficient second-order optimizers for deep learning without explicit matrix inverses.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#24335;&#8212;&#8212;&#21367;&#31215;&#39640;&#26031;&#31070;&#32463;&#36807;&#31243;&#65288;ConvGNP&#65289;&#65292;&#29992;&#20110;&#25552;&#39640;&#29615;&#22659;&#20256;&#24863;&#22120;&#30340;&#25918;&#32622;&#25928;&#29575;&#12290;ConvGNP&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#26469;&#21442;&#25968;&#21270;&#32852;&#21512;&#39640;&#26031;&#20998;&#24067;&#65292;&#36890;&#36807;&#23398;&#20064;&#31354;&#38388;&#21644;&#23395;&#33410;&#24615;&#38750;&#24179;&#31283;&#24615;&#65292;&#20248;&#20110;&#20256;&#32479;&#30340;&#38750;&#24179;&#31283;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2211.10381</link><description>&lt;p&gt;
&#24102;&#26377;&#21367;&#31215;&#39640;&#26031;&#31070;&#32463;&#36807;&#31243;&#30340;&#29615;&#22659;&#20256;&#24863;&#22120;&#25918;&#32622;
&lt;/p&gt;
&lt;p&gt;
Environmental Sensor Placement with Convolutional Gaussian Neural Processes. (arXiv:2211.10381v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.10381
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#24335;&#8212;&#8212;&#21367;&#31215;&#39640;&#26031;&#31070;&#32463;&#36807;&#31243;&#65288;ConvGNP&#65289;&#65292;&#29992;&#20110;&#25552;&#39640;&#29615;&#22659;&#20256;&#24863;&#22120;&#30340;&#25918;&#32622;&#25928;&#29575;&#12290;ConvGNP&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#26469;&#21442;&#25968;&#21270;&#32852;&#21512;&#39640;&#26031;&#20998;&#24067;&#65292;&#36890;&#36807;&#23398;&#20064;&#31354;&#38388;&#21644;&#23395;&#33410;&#24615;&#38750;&#24179;&#31283;&#24615;&#65292;&#20248;&#20110;&#20256;&#32479;&#30340;&#38750;&#24179;&#31283;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29615;&#22659;&#20256;&#24863;&#22120;&#23545;&#20110;&#30417;&#27979;&#22825;&#27668;&#21644;&#27668;&#20505;&#21464;&#21270;&#30340;&#24433;&#21709;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#22312;&#20687;&#21335;&#26497;&#36825;&#26679;&#30340;&#20559;&#36828;&#22320;&#21306;&#65292;&#26368;&#22823;&#21270;&#27979;&#37327;&#20449;&#24687;&#21644;&#26377;&#25928;&#25918;&#32622;&#20256;&#24863;&#22120;&#26159;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#27010;&#29575;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21487;&#20197;&#36890;&#36807;&#39044;&#27979;&#26032;&#20256;&#24863;&#22120;&#25552;&#20379;&#30340;&#19981;&#30830;&#23450;&#24615;&#20943;&#23569;&#26469;&#35780;&#20272;&#25918;&#32622;&#20449;&#24687;&#12290;&#39640;&#26031;&#36807;&#31243;&#27169;&#22411;&#24191;&#27867;&#29992;&#20110;&#27492;&#30446;&#30340;&#65292;&#20294;&#38590;&#20197;&#25429;&#25417;&#22797;&#26434;&#30340;&#38750;&#24179;&#31283;&#34892;&#20026;&#24182;&#32553;&#25918;&#21040;&#22823;&#22411;&#25968;&#25454;&#38598;&#12290;&#26412;&#25991;&#25552;&#20986;&#20351;&#29992;&#21367;&#31215;&#39640;&#26031;&#31070;&#32463;&#36807;&#31243;&#65288;ConvGNP&#65289;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;ConvGNP&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#26469;&#21442;&#25968;&#21270;&#20219;&#24847;&#30446;&#26631;&#20301;&#32622;&#30340;&#32852;&#21512;&#39640;&#26031;&#20998;&#24067;&#65292;&#23454;&#29616;&#20102;&#28789;&#27963;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;&#20351;&#29992;&#27169;&#25311;&#30340;&#21335;&#26497;&#22320;&#21306;&#22320;&#38754;&#28201;&#24230;&#24322;&#24120;&#20316;&#20026;&#30495;&#23454;&#25968;&#25454;&#65292;ConvGNP&#23398;&#20064;&#20102;&#31354;&#38388;&#21644;&#23395;&#33410;&#24615;&#38750;&#24179;&#31283;&#24615;&#65292;&#24182;&#20248;&#20110;&#38750;&#24179;&#31283;GP&#22522;&#32447;&#12290;&#22312;&#27169;&#25311;&#30340;s&#20013;&#65292;
&lt;/p&gt;
&lt;p&gt;
Environmental sensors are crucial for monitoring weather conditions and the impacts of climate change. However, it is challenging to maximise measurement informativeness and place sensors efficiently, particularly in remote regions like Antarctica. Probabilistic machine learning models can evaluate placement informativeness by predicting the uncertainty reduction provided by a new sensor. Gaussian process (GP) models are widely used for this purpose, but they struggle with capturing complex non-stationary behaviour and scaling to large datasets. This paper proposes using a convolutional Gaussian neural process (ConvGNP) to address these issues. A ConvGNP uses neural networks to parameterise a joint Gaussian distribution at arbitrary target locations, enabling flexibility and scalability. Using simulated surface air temperature anomaly over Antarctica as ground truth, the ConvGNP learns spatial and seasonal non-stationarities, outperforming a non-stationary GP baseline. In a simulated s
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#24102;&#26377;&#36164;&#28304;&#32447;&#24615;&#32422;&#26463;&#30340;&#19978;&#19979;&#25991;&#24184;&#23384;&#32773;&#38382;&#39064;&#30340;&#21464;&#31181;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#31616;&#21333;&#12289;&#35745;&#31639;&#25928;&#29575;&#39640;&#65292;&#21516;&#26102;&#33021;&#22815;&#23454;&#29616;&#36739;&#20302;&#30340;&#21518;&#24724;&#12290;&#27492;&#22806;&#65292;&#24403;&#26576;&#20123;&#32422;&#26463;&#34987;&#36829;&#21453;&#26102;&#65292;&#31639;&#27861;&#22312;&#32479;&#35745;&#19978;&#26159;&#26368;&#20248;&#30340;&#12290;</title><link>http://arxiv.org/abs/2211.07484</link><description>&lt;p&gt;
&#24102;&#35013;&#36733;&#21644;&#35206;&#30422;&#32422;&#26463;&#30340;&#19978;&#19979;&#25991;&#24184;&#23384;&#32773;&#38382;&#39064;&#65306;&#22522;&#20110;&#22238;&#24402;&#30340;&#27169;&#22359;&#21270;Lagrangian&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Contextual Bandits with Packing and Covering Constraints: A Modular Lagrangian Approach via Regression. (arXiv:2211.07484v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.07484
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#24102;&#26377;&#36164;&#28304;&#32447;&#24615;&#32422;&#26463;&#30340;&#19978;&#19979;&#25991;&#24184;&#23384;&#32773;&#38382;&#39064;&#30340;&#21464;&#31181;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#31616;&#21333;&#12289;&#35745;&#31639;&#25928;&#29575;&#39640;&#65292;&#21516;&#26102;&#33021;&#22815;&#23454;&#29616;&#36739;&#20302;&#30340;&#21518;&#24724;&#12290;&#27492;&#22806;&#65292;&#24403;&#26576;&#20123;&#32422;&#26463;&#34987;&#36829;&#21453;&#26102;&#65292;&#31639;&#27861;&#22312;&#32479;&#35745;&#19978;&#26159;&#26368;&#20248;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#19968;&#31181;&#19978;&#19979;&#25991;&#24184;&#23384;&#32773;&#38382;&#39064;&#30340;&#21464;&#31181;&#65292;&#20854;&#20013;&#31639;&#27861;&#22312;&#24635;&#28040;&#36153;&#30340;&#32447;&#24615;&#32422;&#26463;&#19979;&#20351;&#29992;&#22810;&#20010;&#36164;&#28304;&#12290;&#36825;&#20010;&#38382;&#39064;&#25512;&#24191;&#20102;&#24102;&#32972;&#21253;&#30340;&#19978;&#19979;&#25991;&#24184;&#23384;&#32773;&#38382;&#39064;(CBwK)&#65292;&#20801;&#35768;&#35013;&#36733;&#21644;&#35206;&#30422;&#32422;&#26463;&#65292;&#20197;&#21450;&#27491;&#36127;&#36164;&#28304;&#28040;&#32791;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31639;&#27861;&#65292;&#31616;&#21333;&#12289;&#35745;&#31639;&#25928;&#29575;&#39640;&#65292;&#33021;&#22815;&#23454;&#29616;&#36864;&#21270;&#30340;&#21518;&#24724;&#12290;&#24403;&#26576;&#20123;&#32422;&#26463;&#34987;&#36829;&#21453;&#26102;&#65292;&#23545;&#20110;CBwK&#65292;&#23427;&#22312;&#32479;&#35745;&#19978;&#26159;&#26368;&#20248;&#30340;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#22522;&#20110;LagrangianBwK(Immorlica&#31561;&#20154;&#65292;FOCS 2019)&#65292;&#36825;&#26159;&#19968;&#31181;&#38754;&#21521;CBwK&#30340;Lagrangian&#25216;&#26415;&#65292;&#20197;&#21450;SquareCB(Foster&#21644;Rakhlin&#65292;ICML 2020)&#65292;&#36825;&#26159;&#19968;&#31181;&#38754;&#21521;&#19978;&#19979;&#25991;&#24184;&#23384;&#32773;&#30340;&#22238;&#24402;&#25216;&#26415;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#21033;&#29992;&#20102;&#20004;&#31181;&#25216;&#26415;&#26412;&#36136;&#19978;&#30340;&#27169;&#22359;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a variant of contextual bandits in which the algorithm consumes multiple resources subject to linear constraints on total consumption. This problem generalizes contextual bandits with knapsacks (CBwK), allowing for packing and covering constraints, as well as positive and negative resource consumption. We present a new algorithm that is simple, computationally efficient, and admits vanishing regret. It is statistically optimal for CBwK when an algorithm must stop once some constraint is violated. Our algorithm builds on LagrangeBwK (Immorlica et al., FOCS 2019) , a Lagrangian-based technique for CBwK, and SquareCB (Foster and Rakhlin, ICML 2020), a regression-based technique for contextual bandits. Our analysis leverages the inherent modularity of both techniques.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#24320;&#21457;&#20102;&#24037;&#20855;&#20197;&#23454;&#29616;&#22240;&#26524;&#21457;&#29616;&#21518;&#30340;&#26377;&#25928;&#25512;&#26029;&#65292;&#35299;&#20915;&#20102;&#20351;&#29992;&#30456;&#21516;&#25968;&#25454;&#36816;&#34892;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#21518;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#23548;&#33268;&#32463;&#20856;&#32622;&#20449;&#21306;&#38388;&#30340;&#35206;&#30422;&#20445;&#35777;&#26080;&#25928;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2208.05949</link><description>&lt;p&gt;
&#22240;&#26524;&#21457;&#29616;&#21518;&#30340;&#26377;&#25928;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Valid Inference after Causal Discovery. (arXiv:2208.05949v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.05949
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#24320;&#21457;&#20102;&#24037;&#20855;&#20197;&#23454;&#29616;&#22240;&#26524;&#21457;&#29616;&#21518;&#30340;&#26377;&#25928;&#25512;&#26029;&#65292;&#35299;&#20915;&#20102;&#20351;&#29992;&#30456;&#21516;&#25968;&#25454;&#36816;&#34892;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#21518;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#23548;&#33268;&#32463;&#20856;&#32622;&#20449;&#21306;&#38388;&#30340;&#35206;&#30422;&#20445;&#35777;&#26080;&#25928;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#21457;&#29616;&#21644;&#22240;&#26524;&#25928;&#24212;&#20272;&#35745;&#26159;&#22240;&#26524;&#25512;&#26029;&#20013;&#30340;&#20004;&#20010;&#22522;&#26412;&#20219;&#21153;&#12290;&#34429;&#28982;&#24050;&#32463;&#38024;&#23545;&#27599;&#20010;&#20219;&#21153;&#21333;&#29420;&#24320;&#21457;&#20102;&#35768;&#22810;&#26041;&#27861;&#65292;&#20294;&#26159;&#21516;&#26102;&#24212;&#29992;&#36825;&#20123;&#26041;&#27861;&#26102;&#20250;&#20986;&#29616;&#32479;&#35745;&#19978;&#30340;&#25361;&#25112;&#65306;&#22312;&#23545;&#30456;&#21516;&#25968;&#25454;&#36816;&#34892;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#21518;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#20250;&#23548;&#33268;"&#21452;&#37325;&#25361;&#36873;"&#65292;&#20174;&#32780;&#20351;&#32463;&#20856;&#32622;&#20449;&#21306;&#38388;&#30340;&#35206;&#30422;&#20445;&#35777;&#26080;&#25928;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#38024;&#23545;&#22240;&#26524;&#21457;&#29616;&#21518;&#26377;&#25928;&#30340;&#25512;&#26029;&#24037;&#20855;&#12290;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#65292;&#25105;&#20204;&#21457;&#29616;&#65292;&#22825;&#30495;&#32452;&#21512;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;&#21644;&#38543;&#21518;&#25512;&#26029;&#31639;&#27861;&#20250;&#23548;&#33268;&#39640;&#24230;&#33192;&#32960;&#30340;&#35823;&#35206;&#30422;&#29575;&#65292;&#32780;&#24212;&#29992;&#25105;&#20204;&#30340;&#26041;&#27861;&#21017;&#25552;&#20379;&#21487;&#38752;&#30340;&#35206;&#30422;&#24182;&#23454;&#29616;&#27604;&#25968;&#25454;&#20998;&#21106;&#26356;&#20934;&#30830;&#30340;&#22240;&#26524;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal discovery and causal effect estimation are two fundamental tasks in causal inference. While many methods have been developed for each task individually, statistical challenges arise when applying these methods jointly: estimating causal effects after running causal discovery algorithms on the same data leads to "double dipping," invalidating the coverage guarantees of classical confidence intervals. To this end, we develop tools for valid post-causal-discovery inference. Across empirical studies, we show that a naive combination of causal discovery and subsequent inference algorithms leads to highly inflated miscoverage rates; on the other hand, applying our method provides reliable coverage while achieving more accurate causal discovery than data splitting.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#38134;&#34892;&#21453;&#27927;&#38065;&#30340;&#32479;&#35745;&#21644;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#23458;&#25143;&#39118;&#38505;&#35780;&#20272;&#21644;&#21487;&#30097;&#34892;&#20026;&#26631;&#35782;&#20004;&#20010;&#26680;&#24515;&#35201;&#32032;&#12290;&#26410;&#26469;&#30340;&#30740;&#31350;&#26041;&#21521;&#21253;&#25324;&#29983;&#25104;&#21512;&#25104;&#25968;&#25454;&#12289;&#21322;&#30417;&#30563;&#21644;&#28145;&#24230;&#23398;&#20064;&#12289;&#21487;&#35299;&#37322;&#24615;&#20197;&#21450;&#32467;&#26524;&#30340;&#20844;&#24179;&#24615;&#12290;</title><link>http://arxiv.org/abs/2201.04207</link><description>&lt;p&gt;
&#29992;&#32479;&#35745;&#21644;&#26426;&#22120;&#23398;&#20064;&#25171;&#20987;&#27927;&#38065;&#65306;&#32508;&#36848;&#19982;&#20171;&#32461;
&lt;/p&gt;
&lt;p&gt;
Fighting Money Laundering with Statistics and Machine Learning: An Introduction and Review. (arXiv:2201.04207v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.04207
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#38134;&#34892;&#21453;&#27927;&#38065;&#30340;&#32479;&#35745;&#21644;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#23458;&#25143;&#39118;&#38505;&#35780;&#20272;&#21644;&#21487;&#30097;&#34892;&#20026;&#26631;&#35782;&#20004;&#20010;&#26680;&#24515;&#35201;&#32032;&#12290;&#26410;&#26469;&#30340;&#30740;&#31350;&#26041;&#21521;&#21253;&#25324;&#29983;&#25104;&#21512;&#25104;&#25968;&#25454;&#12289;&#21322;&#30417;&#30563;&#21644;&#28145;&#24230;&#23398;&#20064;&#12289;&#21487;&#35299;&#37322;&#24615;&#20197;&#21450;&#32467;&#26524;&#30340;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27927;&#38065;&#26159;&#19968;&#20010;&#20005;&#37325;&#30340;&#20840;&#29699;&#24615;&#38382;&#39064;&#65292;&#20294;&#26159;&#38024;&#23545;&#21453;&#27927;&#38065;&#30340;&#32479;&#35745;&#21644;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#30340;&#31185;&#23398;&#25991;&#29486;&#21364;&#24456;&#23569;&#12290;&#26412;&#25991;&#30528;&#37325;&#20110;&#38134;&#34892;&#21453;&#27927;&#38065;&#65292;&#24182;&#25552;&#20379;&#20102;&#25991;&#29486;&#32508;&#36848;&#21644;&#20171;&#32461;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26415;&#35821;&#65292;&#20854;&#20013;&#21253;&#25324;&#23458;&#25143;&#39118;&#38505;&#35780;&#20272;&#21644;&#21487;&#30097;&#34892;&#20026;&#26631;&#35782;&#20004;&#20010;&#26680;&#24515;&#35201;&#32032;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;&#23458;&#25143;&#39118;&#38505;&#35780;&#20272;&#26159;&#36890;&#36807;&#35786;&#26029;&#26469;&#23547;&#25214;&#21644;&#35299;&#37322;&#39118;&#38505;&#22240;&#32032;&#65292;&#32780;&#21487;&#30097;&#34892;&#20026;&#26631;&#35782;&#21017;&#26159;&#36890;&#36807;&#26410;&#20844;&#24320;&#30340;&#29305;&#24449;&#21644;&#25163;&#24037;&#39118;&#38505;&#25351;&#25968;&#26469;&#23454;&#29616;&#30340;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#26410;&#26469;&#30740;&#31350;&#30340;&#26041;&#21521;&#65292;&#20854;&#20013;&#20027;&#35201;&#25361;&#25112;&#20043;&#19968;&#26159;&#38656;&#35201;&#26356;&#22810;&#30340;&#20844;&#20849;&#25968;&#25454;&#38598;&#65292;&#36825;&#21487;&#33021;&#21487;&#20197;&#36890;&#36807;&#29983;&#25104;&#21512;&#25104;&#25968;&#25454;&#26469;&#35299;&#20915;&#65292;&#20854;&#20182;&#21487;&#33021;&#30340;&#30740;&#31350;&#26041;&#21521;&#21253;&#25324;&#21322;&#30417;&#30563;&#21644;&#28145;&#24230;&#23398;&#20064;&#12289;&#21487;&#35299;&#37322;&#24615;&#20197;&#21450;&#32467;&#26524;&#30340;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Money laundering is a profound global problem. Nonetheless, there is little scientific literature on statistical and machine learning methods for anti-money laundering. In this paper, we focus on anti-money laundering in banks and provide an introduction and review of the literature. We propose a unifying terminology with two central elements: (i) client risk profiling and (ii) suspicious behavior flagging. We find that client risk profiling is characterized by diagnostics, i.e., efforts to find and explain risk factors. On the other hand, suspicious behavior flagging is characterized by non-disclosed features and hand-crafted risk indices. Finally, we discuss directions for future research. One major challenge is the need for more public data sets. This may potentially be addressed by synthetic data generation. Other possible research directions include semi-supervised and deep learning, interpretability, and fairness of the results.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;SMM&#30340;&#25193;&#23637;&#65292;&#35813;&#25193;&#23637;&#25903;&#25345;&#20195;&#29702;&#20989;&#25968;&#30340;&#24369;&#20984;&#24615;&#21644;&#22359;&#22810;&#20984;&#24615;&#65292;&#24182;&#22312;&#35299;&#20915;&#38750;&#20984;&#32422;&#26463;&#38382;&#39064;&#19978;&#20855;&#26377;&#26174;&#33879;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2201.01652</link><description>&lt;p&gt;
&#24369;&#20984;&#21644;&#22810;&#20984;&#20195;&#29702;&#20989;&#25968;&#30340;&#38543;&#26426;&#27491;&#21017;&#21270;&#20027;&#23548;&#26497;&#23567;&#21270;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic regularized majorization-minimization with weakly convex and multi-convex surrogates. (arXiv:2201.01652v3 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2201.01652
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;SMM&#30340;&#25193;&#23637;&#65292;&#35813;&#25193;&#23637;&#25903;&#25345;&#20195;&#29702;&#20989;&#25968;&#30340;&#24369;&#20984;&#24615;&#21644;&#22359;&#22810;&#20984;&#24615;&#65292;&#24182;&#22312;&#35299;&#20915;&#38750;&#20984;&#32422;&#26463;&#38382;&#39064;&#19978;&#20855;&#26377;&#26174;&#33879;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#20027;&#23548;&#26497;&#23567;&#21270;&#65288;SMM&#65289;&#26159;&#19968;&#31867;&#37319;&#26679;&#26032;&#25968;&#25454;&#28857;&#24182;&#26368;&#23567;&#21270;&#30446;&#26631;&#20989;&#25968;&#30340;&#20195;&#29702;&#20989;&#25968;&#30340;&#36882;&#24402;&#24179;&#22343;&#25968;&#30340;&#20248;&#21270;&#31639;&#27861;&#12290;&#35201;&#27714;&#20195;&#29702;&#20989;&#25968;&#26159;&#24378;&#20984;&#30340;&#65292;&#38750;&#20984;&#24773;&#20917;&#19979;&#30340;&#25910;&#25947;&#29575;&#20998;&#26512;&#24182;&#19981;&#21487;&#34892;&#12290;&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;SMM&#30340;&#25193;&#23637;&#65292;&#35813;&#25193;&#23637;&#20801;&#35768;&#20195;&#29702;&#20989;&#25968;&#20165;&#20026;&#24369;&#20984;&#25110;&#22359;&#22810;&#20984;&#65292;&#24182;&#19988;&#24179;&#22343;&#20195;&#29702;&#20989;&#25968;&#22312;&#36817;&#31471;&#27491;&#21017;&#21270;&#25110;&#22359;&#26368;&#23567;&#21270;&#30340;&#20943;&#23567;&#21322;&#24452;&#20013;&#36817;&#20284;&#26368;&#23567;&#21270;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#35813;&#31639;&#27861;&#22312;&#20984;&#32422;&#26463;&#19979;&#22788;&#29702;&#38750;i.i.d.&#25968;&#25454;&#26679;&#26412;&#30340;&#19968;&#38454;&#26368;&#20248;&#24615;&#24046;&#36317;&#20197;&#36895;&#29575;$O((\log n)^{1+\epsilon}/n^{1/2})$&#19979;&#38477;&#65292;&#26399;&#26395;&#25439;&#22833;&#20026;$O((\log n)^{1+\epsilon}/n^{1/4})$&#65292;&#20854;&#20013;$n$&#34920;&#31034;&#22788;&#29702;&#30340;&#25968;&#25454;&#26679;&#26412;&#25968;&#37327;&#12290;&#22312;&#19968;&#20123;&#39069;&#22806;&#30340;&#20551;&#35774;&#19979;&#65292;&#36824;&#25552;&#20379;&#20102;&#30446;&#26631;&#20989;&#25968;&#30340;&#21518;&#26399;&#25910;&#25947;&#36895;&#29575;&#12290;&#35813;&#26041;&#27861;&#22312;&#22810;&#20010;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#23637;&#31034;&#65292;&#24182;&#19982;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
Stochastic majorization-minimization (SMM) is a class of stochastic optimization algorithms that proceed by sampling new data points and minimizing a recursive average of surrogate functions of an objective function. The surrogates are required to be strongly convex and convergence rate analysis for the general non-convex setting was not available. In this paper, we propose an extension of SMM where surrogates are allowed to be only weakly convex or block multi-convex, and the averaged surrogates are approximately minimized with proximal regularization or block-minimized within diminishing radii, respectively. For the general nonconvex constrained setting with non-i.i.d. data samples, we show that the first-order optimality gap of the proposed algorithm decays at the rate $O((\log n)^{1+\epsilon}/n^{1/2})$ for the empirical loss and $O((\log n)^{1+\epsilon}/n^{1/4})$ for the expected loss, where $n$ denotes the number of data samples processed. Under some additional assumption, the lat
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#22122;&#22768;&#29305;&#24449;&#30340;&#19978;&#19979;&#25991;&#32447;&#24615;Bandit&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31639;&#27861;&#65292;&#36890;&#36807;&#35266;&#23519;&#20449;&#24687;&#65292;&#23454;&#29616;&#20102;&#36125;&#21494;&#26031;&#31070;&#35861;&#24182;&#24471;&#21040;&#20102;$\tilde{O}(d\sqrt{T})$&#30340;&#36951;&#25022;&#30028;&#12290;</title><link>http://arxiv.org/abs/1703.01347</link><description>&lt;p&gt;
&#24102;&#22122;&#22768;&#29305;&#24449;&#30340;&#19978;&#19979;&#25991;&#32447;&#24615;Bandit&#65306;&#26397;&#21521;&#36125;&#21494;&#26031;&#31070;&#35861;&#21069;&#36827;
&lt;/p&gt;
&lt;p&gt;
Contextual Linear Bandits under Noisy Features: Towards Bayesian Oracles. (arXiv:1703.01347v3 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1703.01347
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#22122;&#22768;&#29305;&#24449;&#30340;&#19978;&#19979;&#25991;&#32447;&#24615;Bandit&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31639;&#27861;&#65292;&#36890;&#36807;&#35266;&#23519;&#20449;&#24687;&#65292;&#23454;&#29616;&#20102;&#36125;&#21494;&#26031;&#31070;&#35861;&#24182;&#24471;&#21040;&#20102;$\tilde{O}(d\sqrt{T})$&#30340;&#36951;&#25022;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#24102;&#26377;&#22122;&#22768;&#21644;&#32570;&#22833;&#39033;&#30340;&#19978;&#19979;&#25991;&#32447;&#24615;Bandit&#38382;&#39064;&#12290;&#20026;&#20102;&#35299;&#20915;&#22122;&#22768;&#30340;&#25361;&#25112;&#65292;&#25105;&#20204;&#20998;&#26512;&#20102;&#22312;&#35266;&#27979;&#22122;&#22768;&#29305;&#24449;&#30340;&#24773;&#20917;&#19979;&#32473;&#20986;&#30340;&#36125;&#21494;&#26031;&#31070;&#35861;&#12290;&#25105;&#20204;&#30340;&#36125;&#21494;&#26031;&#20998;&#26512;&#21457;&#29616;&#65292;&#26368;&#20248;&#20551;&#35774;&#21487;&#33021;&#20250;&#36828;&#31163;&#28508;&#22312;&#30340;&#21487;&#23454;&#29616;&#20989;&#25968;&#65292;&#36825;&#21462;&#20915;&#20110;&#22122;&#22768;&#29305;&#24449;&#65292;&#36825;&#26159;&#39640;&#24230;&#38750;&#30452;&#35266;&#30340;&#65292;&#24182;&#19988;&#22312;&#32463;&#20856;&#30340;&#26080;&#22122;&#22768;&#35774;&#32622;&#19979;&#19981;&#20250;&#21457;&#29983;&#12290;&#36825;&#24847;&#21619;&#30528;&#32463;&#20856;&#26041;&#27861;&#19981;&#33021;&#20445;&#35777;&#38750;&#24179;&#20961;&#30340;&#36951;&#25022;&#30028;&#65288;regret bound&#65289;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31639;&#27861;&#65292;&#26088;&#22312;&#20174;&#36825;&#20010;&#27169;&#22411;&#19979;&#30340;&#35266;&#23519;&#20449;&#24687;&#20013;&#23454;&#29616;&#36125;&#21494;&#26031;&#31070;&#35861;&#65292;&#24403;&#26377;&#22823;&#37327;&#25163;&#33218;&#26102;&#65292;&#21487;&#20197;&#23454;&#29616;$\tilde{O}(d\sqrt{T})$&#36951;&#25022;&#30028;&#12290;&#25105;&#20204;&#20351;&#29992;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#28436;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study contextual linear bandit problems under feature uncertainty; they are noisy with missing entries. To address the challenges of the noise, we analyze Bayesian oracles given observed noisy features. Our Bayesian analysis finds that the optimal hypothesis can be far from the underlying realizability function, depending on the noise characteristics, which are highly non-intuitive and do not occur for classical noiseless setups. This implies that classical approaches cannot guarantee a non-trivial regret bound. Therefore, we propose an algorithm that aims at the Bayesian oracle from observed information under this model, achieving $\tilde{O}(d\sqrt{T})$ regret bound when there is a large number of arms. We demonstrate the proposed algorithm using synthetic and real-world datasets.
&lt;/p&gt;</description></item></channel></rss>