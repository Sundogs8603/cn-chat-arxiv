<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#27010;&#29575;&#27169;&#22411;&#26469;&#35299;&#37322;&#33258;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#30340;&#26426;&#21046;&#65292;&#24182;&#23637;&#31034;&#20102;&#37492;&#21035;&#24615;&#33258;&#30417;&#30563;&#31639;&#27861;&#22312;&#34920;&#31034;&#20013;&#36817;&#20284;&#35825;&#23548;&#28508;&#21464;&#37327;&#32467;&#26500;&#30340;&#32479;&#19968;&#29702;&#35770;&#26694;&#26550;&#12290;</title><link>https://rss.arxiv.org/abs/2402.01399</link><description>&lt;p&gt;
&#35299;&#37322;&#33258;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#30340;&#27010;&#29575;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Probabilistic Model to explain Self-Supervised Representation Learning
&lt;/p&gt;
&lt;p&gt;
https://rss.arxiv.org/abs/2402.01399
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#27010;&#29575;&#27169;&#22411;&#26469;&#35299;&#37322;&#33258;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#30340;&#26426;&#21046;&#65292;&#24182;&#23637;&#31034;&#20102;&#37492;&#21035;&#24615;&#33258;&#30417;&#30563;&#31639;&#27861;&#22312;&#34920;&#31034;&#20013;&#36817;&#20284;&#35825;&#23548;&#28508;&#21464;&#37327;&#32467;&#26500;&#30340;&#32479;&#19968;&#29702;&#35770;&#26694;&#26550;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#30417;&#30563;&#23398;&#20064;&#65288;SSL&#65289;&#36890;&#36807;&#21033;&#29992;&#36741;&#21161;&#30340;&#26080;&#30417;&#30563;&#20219;&#21153;&#65292;&#20363;&#22914;&#23545;&#35821;&#20041;&#30456;&#20851;&#26679;&#26412;&#36827;&#34892;&#20998;&#31867;&#65292;&#22914;&#19981;&#21516;&#30340;&#25968;&#25454;&#22686;&#24378;&#25110;&#27169;&#24577;&#26469;&#23398;&#20064;&#34920;&#31034;&#12290;&#22312;&#20247;&#22810;SSL&#26041;&#27861;&#20013;&#65292;&#23545;&#27604;&#26041;&#27861;&#65288;&#20363;&#22914;SimCLR&#65292;CLIP&#21644;VicREG&#65289;&#22240;&#23398;&#20064;&#21040;&#30340;&#34920;&#31034;&#22312;&#19979;&#28216;&#24615;&#33021;&#19978;&#25509;&#36817;&#26377;&#30417;&#30563;&#23398;&#20064;&#32780;&#21463;&#21040;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#32972;&#21518;&#30340;&#26426;&#21046;&#30340;&#29702;&#35770;&#29702;&#35299;&#20173;&#28982;&#23384;&#22312;&#22256;&#38590;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29983;&#25104;&#28508;&#21464;&#37327;&#27169;&#22411;&#26469;&#34920;&#31034;&#25968;&#25454;&#65292;&#24182;&#23637;&#31034;&#20102;&#20960;&#31867;&#20855;&#26377;&#37492;&#21035;&#24615;&#30340;&#33258;&#30417;&#30563;&#31639;&#27861;&#65288;&#21253;&#25324;&#23545;&#27604;&#26041;&#27861;&#65289;&#36817;&#20284;&#35825;&#23548;&#20854;&#34920;&#31034;&#20013;&#30340;&#28508;&#21464;&#37327;&#32467;&#26500;&#65292;&#20174;&#32780;&#25552;&#20379;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#29702;&#35770;&#26694;&#26550;&#12290;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#19982;&#20114;&#20449;&#24687;&#21644;&#25237;&#24433;&#22836;&#30340;&#30456;&#20851;&#24615;&#12290;&#36890;&#36807;&#29983;&#25104;&#24335;&#22320;&#25311;&#21512;&#25105;&#20204;&#30340;&#27169;&#22411;&#65288;&#22914;SimVE&#65289;&#65292;&#22312;&#24120;&#35265;&#30340;&#22522;&#20934;&#27979;&#35797;&#19978;&#65288;&#20363;&#22914;FashionMNIST&#65292;CIFAR10&#65292;CelebA&#65289;&#65292;&#24615;&#33021;&#20248;&#20110;&#20043;&#21069;&#30340;VAE&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Self-supervised learning (SSL) learns representations by leveraging an auxiliary unsupervised task, such as classifying semantically related samples, e.g. different data augmentations or modalities. Of the many approaches to SSL, contrastive methods, e.g. SimCLR, CLIP and VicREG, have gained attention for learning representations that achieve downstream performance close to that of supervised learning. However, a theoretical understanding of the mechanism behind these methods eludes. We propose a generative latent variable model for the data and show that several families of discriminative self-supervised algorithms, including contrastive methods, approximately induce its latent structure over representations, providing a unifying theoretical framework. We also justify links to mutual information and the use of a projection head. Fitting our model generatively, as SimVE, improves performance over previous VAE methods on common benchmarks (e.g. FashionMNIST, CIFAR10, CelebA), narrows th
&lt;/p&gt;</description></item><item><title>&#22312;&#38750;&#20809;&#28369;&#35774;&#32622;&#19979;&#65292;&#25552;&#20986;&#20102;&#29992;&#20110;&#35745;&#31639;&#20855;&#26377;&#20869;&#26144;&#23556;&#30340;&#22806;&#26144;&#23556;&#22266;&#23450;&#28857;&#30340;&#38544;&#24335;&#23548;&#25968;&#30340;&#26032;&#26041;&#27861;NSID&#65292;&#24182;&#25552;&#20379;&#20102;&#30830;&#23450;&#24615;&#24773;&#20917;&#19979;&#36845;&#20195;&#24494;&#20998;&#65288;ITD&#65289;&#21644;&#36817;&#20284;&#38544;&#24335;&#24494;&#20998;&#65288;AID&#65289;&#30340;&#25913;&#36827;&#32447;&#24615;&#25910;&#25947;&#36895;&#29575;&#12290;</title><link>https://arxiv.org/abs/2403.11687</link><description>&lt;p&gt;
&#38750;&#20809;&#28369;&#38544;&#24335;&#24494;&#20998;&#65306;&#30830;&#23450;&#24615;&#21644;&#38543;&#26426;&#25910;&#25947;&#36895;&#29575;
&lt;/p&gt;
&lt;p&gt;
Nonsmooth Implicit Differentiation: Deterministic and Stochastic Convergence Rates
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11687
&lt;/p&gt;
&lt;p&gt;
&#22312;&#38750;&#20809;&#28369;&#35774;&#32622;&#19979;&#65292;&#25552;&#20986;&#20102;&#29992;&#20110;&#35745;&#31639;&#20855;&#26377;&#20869;&#26144;&#23556;&#30340;&#22806;&#26144;&#23556;&#22266;&#23450;&#28857;&#30340;&#38544;&#24335;&#23548;&#25968;&#30340;&#26032;&#26041;&#27861;NSID&#65292;&#24182;&#25552;&#20379;&#20102;&#30830;&#23450;&#24615;&#24773;&#20917;&#19979;&#36845;&#20195;&#24494;&#20998;&#65288;ITD&#65289;&#21644;&#36817;&#20284;&#38544;&#24335;&#24494;&#20998;&#65288;AID&#65289;&#30340;&#25913;&#36827;&#32447;&#24615;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#26377;&#25928;&#35745;&#31639;&#21442;&#25968;&#21270;&#19981;&#21487;&#24494;&#25910;&#32553;&#26144;&#23556;&#22266;&#23450;&#28857;&#23548;&#25968;&#30340;&#38382;&#39064;&#12290;&#36825;&#20010;&#38382;&#39064;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#65292;&#21253;&#25324;&#36229;&#21442;&#25968;&#20248;&#21270;&#12289;&#20803;&#23398;&#20064;&#21644;&#25968;&#25454;&#27745;&#26579;&#25915;&#20987;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#20004;&#31181;&#27969;&#34892;&#30340;&#26041;&#27861;&#65306;&#36845;&#20195;&#24494;&#20998;&#65288;ITD&#65289;&#21644;&#36817;&#20284;&#38544;&#24335;&#24494;&#20998;&#65288;AID&#65289;&#12290;&#22312;&#38750;&#20809;&#28369;&#35774;&#32622;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#26159;&#38142;&#35268;&#21017;&#19981;&#20877;&#25104;&#31435;&#12290;&#22312;Bolte&#31561;&#20154;&#65288;2022&#65289;&#26368;&#36817;&#30340;&#24037;&#20316;&#22522;&#30784;&#19978;&#65292;&#20182;&#20204;&#35777;&#26126;&#20102;&#19981;&#21487;&#24494;&#20998;ITD&#30340;&#32447;&#24615;&#25910;&#25947;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#30830;&#23450;&#24615;&#24773;&#20917;&#19979;ITD&#21644;AID&#30340;&#25913;&#36827;&#32447;&#24615;&#25910;&#25947;&#36895;&#29575;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#20171;&#32461;&#20102;NSID&#65292;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#22266;&#23450;&#28857;&#34987;&#23450;&#20041;&#20026;&#21482;&#36890;&#36807;&#38543;&#26426;&#26080;&#20559;&#20272;&#35745;&#22120;&#35775;&#38382;&#30340;&#22806;&#26144;&#23556;&#21644;&#20869;&#26144;&#23556;&#30340;&#32452;&#21512;&#26102;&#35745;&#31639;&#38544;&#24335;&#23548;&#25968;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;&#35813;&#26041;&#27861;&#30340;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11687v1 Announce Type: cross  Abstract: We study the problem of efficiently computing the derivative of the fixed-point of a parametric non-differentiable contraction map. This problem has wide applications in machine learning, including hyperparameter optimization, meta-learning and data poisoning attacks. We analyze two popular approaches: iterative differentiation (ITD) and approximate implicit differentiation (AID). A key challenge behind the nonsmooth setting is that the chain rule does not hold anymore. Building upon the recent work by Bolte et al. (2022), who proved the linear convergence of non-differentiable ITD, we provide refined linear convergence rates for both ITD and AID in the deterministic case. We further introduce NSID, a new method to compute the implicit derivative when the fixed point is defined as the composition of an outer map and an inner map which is accessible only through a stochastic unbiased estimator. We establish rates for the convergence of 
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36845;&#20195;INLA&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#38750;&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#20013;&#25512;&#26029;&#29366;&#24577;&#21644;&#21442;&#25968;&#65292;&#33021;&#22815;&#20445;&#30041;&#21487;&#35299;&#37322;&#24615;&#24182;&#19988;&#36866;&#29992;&#20110;&#20219;&#24847;&#38750;&#32447;&#24615;&#31995;&#32479;&#12290;</title><link>https://arxiv.org/abs/2402.17036</link><description>&lt;p&gt;
&#36845;&#20195;INLA&#29992;&#20110;&#38750;&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#20013;&#30340;&#29366;&#24577;&#21644;&#21442;&#25968;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Iterated INLA for State and Parameter Estimation in Nonlinear Dynamical Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.17036
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36845;&#20195;INLA&#30340;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#38750;&#32447;&#24615;&#21160;&#21147;&#31995;&#32479;&#20013;&#25512;&#26029;&#29366;&#24577;&#21644;&#21442;&#25968;&#65292;&#33021;&#22815;&#20445;&#30041;&#21487;&#35299;&#37322;&#24615;&#24182;&#19988;&#36866;&#29992;&#20110;&#20219;&#24847;&#38750;&#32447;&#24615;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#21516;&#21270;&#65288;DA&#65289;&#26041;&#27861;&#20351;&#29992;&#28304;&#33258;&#24494;&#20998;&#26041;&#31243;&#30340;&#20808;&#39564;&#26465;&#20214;&#26469;&#31283;&#20581;&#22320;&#23545;&#25968;&#25454;&#36827;&#34892;&#25554;&#20540;&#21644;&#22806;&#25512;&#12290;&#27969;&#34892;&#30340;&#25216;&#26415;&#65292;&#22914;&#22788;&#29702;&#39640;&#32500;&#38750;&#32447;&#24615;PDE&#20808;&#39564;&#26465;&#20214;&#30340;&#38598;&#21512;&#26041;&#27861;&#65292;&#20027;&#35201;&#20851;&#27880;&#29366;&#24577;&#20272;&#35745;&#65292;&#20294;&#21487;&#33021;&#20250;&#22312;&#23398;&#20064;&#21442;&#25968;&#26041;&#38754;&#36935;&#21040;&#22256;&#38590;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#30340;&#26041;&#27861;&#21487;&#20197;&#33258;&#28982;&#22320;&#23398;&#20064;&#29366;&#24577;&#21644;&#21442;&#25968;&#65292;&#20294;&#23427;&#20204;&#30340;&#36866;&#29992;&#24615;&#21487;&#33021;&#21463;&#21040;&#38480;&#21046;&#65292;&#25110;&#32773;&#20135;&#29983;&#38590;&#20197;&#35299;&#37322;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#21463;&#31354;&#38388;&#32479;&#35745;&#20013;&#38598;&#25104;&#23884;&#22871;&#25289;&#26222;&#25289;&#26031;&#36817;&#20284;&#65288;INLA&#65289;&#26041;&#27861;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#36845;&#20195;&#32447;&#24615;&#21270;&#21160;&#21147;&#23398;&#27169;&#22411;&#30340;DA&#26367;&#20195;&#26041;&#27861;&#12290;&#36825;&#22312;&#27599;&#27425;&#36845;&#20195;&#20013;&#20135;&#29983;&#19968;&#20010;&#39640;&#26031;&#39532;&#23572;&#21487;&#22827;&#38543;&#26426;&#22330;&#65292;&#20351;&#24471;&#21487;&#20197;&#20351;&#29992;INLA&#26469;&#25512;&#26029;&#29366;&#24577;&#21644;&#21442;&#25968;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#21487;&#20197;&#29992;&#20110;&#20219;&#24847;&#38750;&#32447;&#24615;&#31995;&#32479;&#65292;&#21516;&#26102;&#20445;&#25345;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#19988;&#36827;&#19968;&#27493;&#34987;&#35777;&#26126;&#21487;&#20197;o
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.17036v1 Announce Type: cross  Abstract: Data assimilation (DA) methods use priors arising from differential equations to robustly interpolate and extrapolate data. Popular techniques such as ensemble methods that handle high-dimensional, nonlinear PDE priors focus mostly on state estimation, however can have difficulty learning the parameters accurately. On the other hand, machine learning based approaches can naturally learn the state and parameters, but their applicability can be limited, or produce uncertainties that are hard to interpret. Inspired by the Integrated Nested Laplace Approximation (INLA) method in spatial statistics, we propose an alternative approach to DA based on iteratively linearising the dynamical model. This produces a Gaussian Markov random field at each iteration, enabling one to use INLA to infer the state and parameters. Our approach can be used for arbitrary nonlinear systems, while retaining interpretability, and is furthermore demonstrated to o
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#20004;&#38454;&#27573;&#30340;&#20056;&#24130;&#31283;&#20581;&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#25913;&#21892;&#34920;&#26684;&#25968;&#25454;&#20998;&#26512;&#20013;&#27599;&#20010;&#20010;&#20307;&#37096;&#20998;&#30340;&#27169;&#22411;&#24615;&#33021;&#65292;&#24182;&#24314;&#31435;&#20102;&#22312;&#27979;&#35797;&#39118;&#38505;&#19978;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>https://arxiv.org/abs/2402.14145</link><description>&lt;p&gt;
&#24102;&#26377;&#22810;&#20010;&#39046;&#22495;&#30340;&#26412;&#22320;&#20998;&#24067;&#20559;&#31227;&#30340;&#20056;&#24130;&#31283;&#20581;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Multiply Robust Estimation for Local Distribution Shifts with Multiple Domains
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14145
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#20004;&#38454;&#27573;&#30340;&#20056;&#24130;&#31283;&#20581;&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#25913;&#21892;&#34920;&#26684;&#25968;&#25454;&#20998;&#26512;&#20013;&#27599;&#20010;&#20010;&#20307;&#37096;&#20998;&#30340;&#27169;&#22411;&#24615;&#33021;&#65292;&#24182;&#24314;&#31435;&#20102;&#22312;&#27979;&#35797;&#39118;&#38505;&#19978;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#20559;&#31227;&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#26222;&#36941;&#23384;&#22312;&#65292;&#32473;&#22312;&#19968;&#20010;&#25968;&#25454;&#20998;&#24067;&#19978;&#35757;&#32451;&#30340;&#27169;&#22411;&#25512;&#24191;&#21040;&#21478;&#19968;&#20010;&#25968;&#25454;&#20998;&#24067;&#24102;&#26469;&#25361;&#25112;&#12290;&#26412;&#25991;&#19987;&#27880;&#20110;&#25968;&#25454;&#20998;&#24067;&#38543;&#25972;&#20010;&#24635;&#20307;&#30340;&#22810;&#20010;&#37096;&#20998;&#21464;&#21270;&#30340;&#24773;&#24418;&#65292;&#24182;&#20165;&#22312;&#27599;&#20010;&#37096;&#20998;&#20869;&#23545;&#35757;&#32451;&#19982;&#27979;&#35797;&#65288;&#37096;&#32626;&#65289;&#25968;&#25454;&#20998;&#24067;&#30340;&#24046;&#24322;&#36827;&#34892;&#23616;&#37096;&#20551;&#35774;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20004;&#38454;&#27573;&#30340;&#20056;&#24130;&#31283;&#20581;&#20272;&#35745;&#26041;&#27861;&#65292;&#29992;&#20110;&#25913;&#21892;&#34920;&#26684;&#25968;&#25454;&#20998;&#26512;&#20013;&#27599;&#20010;&#20010;&#20307;&#37096;&#20998;&#30340;&#27169;&#22411;&#24615;&#33021;&#12290;&#35813;&#26041;&#27861;&#28041;&#21450;&#25311;&#21512;&#22522;&#20110;&#20174;&#22810;&#20010;&#37096;&#20998;&#30340;&#35757;&#32451;&#25968;&#25454;&#20013;&#23398;&#21040;&#30340;&#27169;&#22411;&#30340;&#32447;&#24615;&#32452;&#21512;&#65292;&#28982;&#21518;&#23545;&#27599;&#20010;&#37096;&#20998;&#36827;&#34892;&#32454;&#21270;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26088;&#22312;&#19982;&#24120;&#29992;&#30340;&#29616;&#25104;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#19968;&#36215;&#23454;&#26045;&#12290;&#25105;&#20204;&#22312;&#27979;&#35797;&#39118;&#38505;&#19978;&#24314;&#31435;&#20102;&#35813;&#26041;&#27861;&#27867;&#21270;&#30028;&#38480;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#36890;&#36807;&#22823;&#37327;&#23454;&#39564;...
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14145v1 Announce Type: cross  Abstract: Distribution shifts are ubiquitous in real-world machine learning applications, posing a challenge to the generalization of models trained on one data distribution to another. We focus on scenarios where data distributions vary across multiple segments of the entire population and only make local assumptions about the differences between training and test (deployment) distributions within each segment. We propose a two-stage multiply robust estimation method to improve model performance on each individual segment for tabular data analysis. The method involves fitting a linear combination of the based models, learned using clusters of training data from multiple segments, followed by a refinement step for each segment. Our method is designed to be implemented with commonly used off-the-shelf machine learning models. We establish theoretical guarantees on the generalization bound of the method on the test risk. With extensive experiments
&lt;/p&gt;</description></item><item><title>&#30417;&#30563;&#23398;&#20064;&#38382;&#39064;&#30340;&#22256;&#38590;&#24615;&#20855;&#26377;&#32039;&#20945;&#30340;&#26377;&#38480;&#29305;&#24615;&#34920;&#24449;&#12290;</title><link>https://arxiv.org/abs/2402.10360</link><description>&lt;p&gt;
&#23398;&#20064;&#24615;&#26159;&#19968;&#31181;&#32039;&#20945;&#24615;&#36136;
&lt;/p&gt;
&lt;p&gt;
Learnability is a Compact Property
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.10360
&lt;/p&gt;
&lt;p&gt;
&#30417;&#30563;&#23398;&#20064;&#38382;&#39064;&#30340;&#22256;&#38590;&#24615;&#20855;&#26377;&#32039;&#20945;&#30340;&#26377;&#38480;&#29305;&#24615;&#34920;&#24449;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#20851;&#20110;&#23398;&#20064;&#30340;&#24037;&#20316;&#21462;&#24471;&#20102;&#19968;&#20010;&#24341;&#20154;&#27880;&#30446;&#30340;&#32467;&#26524;&#65306;&#21508;&#31181;&#38382;&#39064;&#30340;&#21487;&#23398;&#20064;&#24615;&#21487;&#33021;&#26159;&#19981;&#21487;&#21028;&#23450;&#30340;&#65292;&#25110;&#32773;&#19982;&#26631;&#20934;&#38598;&#21512;&#35770;ZFC&#20844;&#29702;&#26080;&#20851;&#12290;&#27492;&#22806;&#65292;&#36825;&#31181;&#38382;&#39064;&#30340;&#21487;&#23398;&#20064;&#24615;&#21487;&#33021;&#19981;&#26159;&#20855;&#26377;&#26377;&#38480;&#29305;&#24615;&#30340;&#23646;&#24615;&#65306;&#38750;&#27491;&#24335;&#22320;&#35828;&#65292;&#23427;&#19981;&#33021;&#36890;&#36807;&#26816;&#26597;&#38382;&#39064;&#30340;&#26377;&#38480;&#25237;&#24433;&#26469;&#26816;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.10360v1 Announce Type: new  Abstract: Recent work on learning has yielded a striking result: the learnability of various problems can be undecidable, or independent of the standard ZFC axioms of set theory. Furthermore, the learnability of such problems can fail to be a property of finite character: informally, it cannot be detected by examining finite projections of the problem.   On the other hand, learning theory abounds with notions of dimension that characterize learning and consider only finite restrictions of the problem, i.e., are properties of finite character. How can these results be reconciled? More precisely, which classes of learning problems are vulnerable to logical undecidability, and which are within the grasp of finite characterizations?   We demonstrate that the difficulty of supervised learning with metric losses admits a tight finite characterization. In particular, we prove that the sample complexity of learning a hypothesis class can be detected by ex
&lt;/p&gt;</description></item><item><title>PASOA&#26159;&#19968;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#31243;&#24207;&#65292;&#36890;&#36807;&#25552;&#20379;&#36830;&#32493;&#30340;&#21518;&#39564;&#20998;&#24067;&#30340;&#20934;&#30830;&#20272;&#35745;&#65292;&#21516;&#26102;&#25191;&#34892;&#39034;&#24207;&#35774;&#35745;&#20248;&#21270;&#21644;&#21442;&#25968;&#25512;&#26029;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992; stochastic optimization &#21644; tempered SMC &#26469;&#26368;&#22823;&#21270;&#26399;&#26395;&#20449;&#24687;&#22686;&#30410;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#33268;&#24615;&#30340;&#26368;&#20248;&#35774;&#35745;&#20272;&#35745;&#12290;</title><link>https://arxiv.org/abs/2402.07160</link><description>&lt;p&gt;
PASOA-&#22522;&#20110;&#31890;&#23376;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#33258;&#36866;&#24212;&#35774;&#35745;
&lt;/p&gt;
&lt;p&gt;
PASOA- PArticle baSed Bayesian Optimal Adaptive design
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07160
&lt;/p&gt;
&lt;p&gt;
PASOA&#26159;&#19968;&#31181;&#26032;&#30340;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#31243;&#24207;&#65292;&#36890;&#36807;&#25552;&#20379;&#36830;&#32493;&#30340;&#21518;&#39564;&#20998;&#24067;&#30340;&#20934;&#30830;&#20272;&#35745;&#65292;&#21516;&#26102;&#25191;&#34892;&#39034;&#24207;&#35774;&#35745;&#20248;&#21270;&#21644;&#21442;&#25968;&#25512;&#26029;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992; stochastic optimization &#21644; tempered SMC &#26469;&#26368;&#22823;&#21270;&#26399;&#26395;&#20449;&#24687;&#22686;&#30410;&#65292;&#24182;&#25552;&#20379;&#20102;&#19968;&#33268;&#24615;&#30340;&#26368;&#20248;&#35774;&#35745;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;PASOA&#30340;&#26032;&#31243;&#24207;&#65292;&#29992;&#20110;&#36125;&#21494;&#26031;&#23454;&#39564;&#35774;&#35745;&#65292;&#36890;&#36807;&#21516;&#26102;&#25552;&#20379;&#36830;&#32493;&#30340;&#21518;&#39564;&#20998;&#24067;&#30340;&#20934;&#30830;&#20272;&#35745;&#26469;&#25191;&#34892;&#39034;&#24207;&#35774;&#35745;&#20248;&#21270;&#12290;&#39034;&#24207;&#35774;&#35745;&#36807;&#31243;&#36890;&#36807;&#23545;&#27604;&#20272;&#35745;&#21407;&#21017;&#36827;&#34892;&#65292;&#20351;&#29992;&#38543;&#26426;&#20248;&#21270;&#21644;&#39034;&#24207;&#33945;&#29305;&#21345;&#32599;&#65288;SMC&#65289;&#37319;&#26679;&#22120;&#26469;&#26368;&#22823;&#21270;&#26399;&#26395;&#20449;&#24687;&#22686;&#30410;&#65288;EIG&#65289;&#12290;&#30001;&#20110;&#36830;&#32493;&#21518;&#39564;&#20998;&#24067;&#20043;&#38388;&#30340;&#36317;&#31163;&#36234;&#22823;&#65292;&#33719;&#24471;&#30340;&#20449;&#24687;&#22686;&#30410;&#36234;&#22823;&#65292;&#22240;&#27492;&#36825;&#20010;EIG&#30446;&#26631;&#21487;&#33021;&#20250;&#24694;&#21270;&#32463;&#20856;SMC&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#28201;&#24230;&#35843;&#33410;&#65292;&#26082;&#21487;&#20197;&#33719;&#24471;&#22823;&#30340;&#20449;&#24687;&#22686;&#30410;&#65292;&#21448;&#21487;&#20197;&#33719;&#24471;&#20934;&#30830;&#30340;SMC&#37319;&#26679;&#65292;&#25105;&#20204;&#35777;&#26126;&#36825;&#23545;&#24615;&#33021;&#26469;&#35828;&#26159;&#33267;&#20851;&#37325;&#35201;&#30340;&#12290;&#36825;&#31181;&#38543;&#26426;&#20248;&#21270;&#21644;&#28201;&#24230;&#35843;&#33410;&#30340;&#26032;&#39062;&#32452;&#21512;&#20801;&#35768;&#21516;&#26102;&#22788;&#29702;&#35774;&#35745;&#20248;&#21270;&#21644;&#21442;&#25968;&#25512;&#26029;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#24471;&#21040;&#30340;&#26368;&#20248;&#35774;&#35745;&#20272;&#35745;&#37327;&#20855;&#26377;&#19968;&#33268;&#24615;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#30456;&#21516;&#35745;&#31639;&#39044;&#31639;&#19979;&#27604;&#20854;&#20182;&#26041;&#27861;&#26356;&#22909;&#22320;&#20248;&#21270;&#20102;&#35774;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new procedure named PASOA, for Bayesian experimental design, that performs sequential design optimization by simultaneously providing accurate estimates of successive posterior distributions for parameter inference. The sequential design process is carried out via a contrastive estimation principle, using stochastic optimization and Sequential Monte Carlo (SMC) samplers to maximise the Expected Information Gain (EIG). As larger information gains are obtained for larger distances between successive posterior distributions, this EIG objective may worsen classical SMC performance. To handle this issue, tempering is proposed to have both a large information gain and an accurate SMC sampling, that we show is crucial for performance. This novel combination of stochastic optimization and tempered SMC allows to jointly handle design optimization and parameter inference. We provide a proof that the obtained optimal design estimators benefit from some consistency property. Numerical
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#20004;&#31181;&#31169;&#26377;&#21464;&#20307;&#30340;&#38750;&#21442;&#25968;bootstrap&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#24046;&#20998;&#38544;&#31169;&#30340;&#24773;&#20917;&#19979;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#12290;&#26041;&#27861;&#22312;&#35745;&#31639;&#25928;&#29575;&#21644;&#32622;&#20449;&#21306;&#38388;&#38271;&#24230;&#19978;&#30456;&#27604;&#29616;&#26377;&#26041;&#27861;&#26377;&#26174;&#33879;&#25913;&#36827;&#12290;</title><link>https://arxiv.org/abs/2402.07131</link><description>&lt;p&gt;
&#38024;&#23545;&#31169;&#26377;&#32479;&#35745;&#25512;&#26029;&#30340;&#37325;&#37319;&#26679;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Resampling methods for Private Statistical Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07131
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#25552;&#20986;&#20102;&#20004;&#31181;&#31169;&#26377;&#21464;&#20307;&#30340;&#38750;&#21442;&#25968;bootstrap&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#24046;&#20998;&#38544;&#31169;&#30340;&#24773;&#20917;&#19979;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#12290;&#26041;&#27861;&#22312;&#35745;&#31639;&#25928;&#29575;&#21644;&#32622;&#20449;&#21306;&#38388;&#38271;&#24230;&#19978;&#30456;&#27604;&#29616;&#26377;&#26041;&#27861;&#26377;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#30340;&#20219;&#21153;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#31169;&#26377;&#21464;&#20307;&#30340;&#38750;&#21442;&#25968;bootstrap&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#25968;&#25454;&#30340;&#20998;&#21306;&#19978;&#31169;&#19979;&#35745;&#31639;&#22810;&#20010;&#8220;&#23567;&#8221;bootstrap&#30340;&#32467;&#26524;&#30340;&#20013;&#20301;&#25968;&#65292;&#24182;&#32473;&#20986;&#20102;&#24471;&#21040;&#30340;&#32622;&#20449;&#21306;&#38388;&#30340;&#28176;&#36827;&#35206;&#30422;&#35823;&#24046;&#19978;&#30028;&#12290;&#23545;&#20110;&#22266;&#23450;&#30340;&#24046;&#20998;&#38544;&#31169;&#21442;&#25968;&#949;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#26679;&#26412;&#22823;&#23567;n&#19978;&#30340;&#35823;&#24046;&#29575;&#19982;&#38750;&#31169;&#26377;bootstrap&#30456;&#24403;&#65292;&#21482;&#26159;&#22312;&#23545;&#25968;&#22240;&#23376;&#20869;&#12290;&#25105;&#20204;&#20351;&#29992;&#30495;&#23454;&#25968;&#25454;&#21644;&#21512;&#25104;&#25968;&#25454;&#22312;&#22343;&#20540;&#20272;&#35745;&#12289;&#20013;&#20301;&#25968;&#20272;&#35745;&#21644;&#36923;&#36753;&#22238;&#24402;&#26041;&#38754;&#23545;&#25105;&#20204;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#32463;&#39564;&#39564;&#35777;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#25552;&#20379;&#31867;&#20284;&#30340;&#35206;&#30422;&#31934;&#24230;&#30340;&#21516;&#26102;&#65292;&#27604;&#20197;&#21069;&#30340;&#26041;&#27861;&#25552;&#20379;&#20102;&#26174;&#33879;&#32553;&#30701;&#65288;&#22823;&#32422;10&#20493;&#65289;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the task of constructing confidence intervals with differential privacy. We propose two private variants of the non-parametric bootstrap, which privately compute the median of the results of multiple ``little'' bootstraps run on partitions of the data and give asymptotic bounds on the coverage error of the resulting confidence intervals. For a fixed differential privacy parameter $\epsilon$, our methods enjoy the same error rates as that of the non-private bootstrap to within logarithmic factors in the sample size $n$. We empirically validate the performance of our methods for mean estimation, median estimation, and logistic regression with both real and synthetic data. Our methods achieve similar coverage accuracy to existing methods (and non-private baselines) while providing notably shorter ($\gtrsim 10$ times) confidence intervals than previous approaches.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#30740;&#31350;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#22312;&#19968;&#27425;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#21518;&#30340;&#29305;&#24449;&#23398;&#20064;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#22312;&#39640;&#32500;&#26497;&#38480;&#19979;&#36890;&#29992;&#21270;&#35823;&#24046;&#30340;&#31934;&#30830;&#28176;&#36817;&#25551;&#36848;&#65292;&#24182;&#21457;&#29616;&#22312;&#36866;&#24212;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#32593;&#32476;&#33021;&#22815;&#39640;&#25928;&#22320;&#23398;&#20064;&#26799;&#24230;&#26041;&#21521;&#19978;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#12290;</title><link>https://arxiv.org/abs/2402.04980</link><description>&lt;p&gt;
&#19968;&#27425;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#21518;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#22312;&#29305;&#24449;&#23398;&#20064;&#20013;&#30340;&#28176;&#36817;&#24615;&#36136;
&lt;/p&gt;
&lt;p&gt;
Asymptotics of feature learning in two-layer networks after one gradient-step
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.04980
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#30740;&#31350;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#22312;&#19968;&#27425;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#21518;&#30340;&#29305;&#24449;&#23398;&#20064;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#22312;&#39640;&#32500;&#26497;&#38480;&#19979;&#36890;&#29992;&#21270;&#35823;&#24046;&#30340;&#31934;&#30830;&#28176;&#36817;&#25551;&#36848;&#65292;&#24182;&#21457;&#29616;&#22312;&#36866;&#24212;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#32593;&#32476;&#33021;&#22815;&#39640;&#25928;&#22320;&#23398;&#20064;&#26799;&#24230;&#26041;&#21521;&#19978;&#30340;&#38750;&#32447;&#24615;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#22312;&#20174;&#25968;&#25454;&#20013;&#23398;&#20064;&#29305;&#24449;&#65292;&#24182;&#22312;&#20351;&#29992;&#21333;&#19968;&#26799;&#24230;&#19979;&#38477;&#27493;&#39588;&#35757;&#32451;&#21518;&#22914;&#20309;&#25913;&#36827;&#26680;&#24515;&#26041;&#27861;&#30340;&#38382;&#39064;&#12290;&#20511;&#21161;&#20110;&#65288;Ba et al., 2022&#65289;&#19982;&#38750;&#32447;&#24615;&#23574;&#23792;&#30697;&#38453;&#27169;&#22411;&#30340;&#20851;&#32852;&#20197;&#21450;&#23545;&#39640;&#26031;&#27867;&#21270;&#24615;&#30340;&#26368;&#26032;&#36827;&#23637;&#65288;Dandi et al., 2023&#65289;&#65292;&#25105;&#20204;&#22312;&#26679;&#26412;&#25968;$n$&#12289;&#23485;&#24230;$p$&#21644;&#36755;&#20837;&#32500;&#24230;$d$&#25104;&#27604;&#20363;&#22686;&#38271;&#30340;&#39640;&#32500;&#26497;&#38480;&#19979;&#65292;&#32473;&#20986;&#20102;&#19968;&#31181;&#31934;&#30830;&#30340;&#19968;&#33268;&#24615;&#35823;&#24046;&#25551;&#36848;&#12290;&#25105;&#20204;&#20934;&#30830;&#22320;&#21051;&#30011;&#20102;&#36866;&#24212;&#25968;&#25454;&#23545;&#20110;&#32593;&#32476;&#22312;&#26799;&#24230;&#26041;&#21521;&#19978;&#39640;&#25928;&#23398;&#20064;&#38750;&#32447;&#24615;&#20989;&#25968;&#30340;&#37325;&#35201;&#24615;&#8212;&#8212;&#22312;&#21021;&#22987;&#21270;&#38454;&#27573;&#65292;&#32593;&#32476;&#21482;&#33021;&#34920;&#36798;&#32447;&#24615;&#20989;&#25968;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#25552;&#20379;&#20102;&#22312;&#22823;&#23398;&#20064;&#29575;$\eta=\Theta_{d}(d)$&#30340;&#24773;&#20917;&#19979;&#29305;&#24449;&#23398;&#20064;&#23545;&#20110;&#20004;&#23618;&#31070;&#32463;&#32593;&#32476;&#27867;&#21270;&#30340;&#39318;&#20010;&#20934;&#30830;&#25551;&#36848;&#65292;&#36229;&#36234;&#20102;&#26680;&#24515;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this manuscript we investigate the problem of how two-layer neural networks learn features from data, and improve over the kernel regime, after being trained with a single gradient descent step. Leveraging a connection from (Ba et al., 2022) with a non-linear spiked matrix model and recent progress on Gaussian universality (Dandi et al., 2023), we provide an exact asymptotic description of the generalization error in the high-dimensional limit where the number of samples $n$, the width $p$ and the input dimension $d$ grow at a proportional rate. We characterize exactly how adapting to the data is crucial for the network to efficiently learn non-linear functions in the direction of the gradient -- where at initialization it can only express linear functions in this regime. To our knowledge, our results provides the first tight description of the impact of feature learning in the generalization of two-layer neural networks in the large learning rate regime $\eta=\Theta_{d}(d)$, beyond
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#26088;&#22312;&#26089;&#26399;&#24320;&#21457;&#22823;&#35268;&#27169;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#65288;LTSM&#65289;&#65292;&#36890;&#36807;&#39044;&#35757;&#32451;&#21644;GPT&#39118;&#26684;&#26550;&#26500;&#65292;&#20811;&#26381;&#28145;&#24230;&#27169;&#22411;&#22312;&#23567;&#26679;&#26412;&#22330;&#26223;&#20013;&#30340;&#24615;&#33021;&#29942;&#39048;&#65292;&#24182;&#23454;&#29616;&#22312;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#20013;&#30340;&#22823;&#26679;&#26412;&#27867;&#21270;&#33021;&#21147;&#12289;&#21487;&#25193;&#23637;&#24615;&#21644;&#20219;&#21153;&#26222;&#36866;&#24615;&#12290;</title><link>https://arxiv.org/abs/2402.02368</link><description>&lt;p&gt;
&#35745;&#26102;&#22120;: &#29992;&#20110;&#22823;&#35268;&#27169;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#30340;Transformer&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Timer: Transformers for Time Series Analysis at Scale
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02368
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#26089;&#26399;&#24320;&#21457;&#22823;&#35268;&#27169;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#65288;LTSM&#65289;&#65292;&#36890;&#36807;&#39044;&#35757;&#32451;&#21644;GPT&#39118;&#26684;&#26550;&#26500;&#65292;&#20811;&#26381;&#28145;&#24230;&#27169;&#22411;&#22312;&#23567;&#26679;&#26412;&#22330;&#26223;&#20013;&#30340;&#24615;&#33021;&#29942;&#39048;&#65292;&#24182;&#23454;&#29616;&#22312;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#20013;&#30340;&#22823;&#26679;&#26412;&#27867;&#21270;&#33021;&#21147;&#12289;&#21487;&#25193;&#23637;&#24615;&#21644;&#20219;&#21153;&#26222;&#36866;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#22312;&#26102;&#38388;&#24207;&#21015;&#20998;&#26512;&#26041;&#38754;&#20570;&#20986;&#20102;&#26174;&#33879;&#36129;&#29486;&#12290;&#28982;&#32780;&#65292;&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#23567;&#26679;&#26412;&#22330;&#26223;&#20013;&#65292;&#28145;&#24230;&#27169;&#22411;&#21487;&#33021;&#36935;&#21040;&#24615;&#33021;&#29942;&#39048;&#65292;&#36825;&#21487;&#33021;&#30001;&#20110;&#24403;&#21069;&#22522;&#20934;&#27979;&#35797;&#20013;&#23567;&#27169;&#22411;&#30340;&#24615;&#33021;&#39281;&#21644;&#32780;&#38544;&#34109;&#12290;&#21516;&#26102;&#65292;&#36890;&#36807;&#22823;&#35268;&#27169;&#39044;&#35757;&#32451;&#65292;&#22823;&#27169;&#22411;&#22312;&#36825;&#20123;&#22330;&#26223;&#20013;&#23637;&#31034;&#20102;&#24040;&#22823;&#30340;&#33021;&#21147;&#12290;&#38543;&#30528;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#20986;&#29616;&#65292;&#21462;&#24471;&#20102;&#25345;&#32493;&#30340;&#36827;&#23637;&#65292;&#22312;&#23569;&#26679;&#26412;&#27867;&#21270;&#33021;&#21147;&#12289;&#21487;&#25193;&#23637;&#24615;&#21644;&#20219;&#21153;&#26222;&#36866;&#24615;&#26041;&#38754;&#23637;&#29616;&#20102;&#21069;&#25152;&#26410;&#26377;&#30340;&#33021;&#21147;&#65292;&#20294;&#36825;&#20123;&#33021;&#21147;&#22312;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#20013;&#19981;&#23384;&#22312;&#12290;&#20026;&#20102;&#25913;&#21464;&#30446;&#21069;&#22312;&#29305;&#23450;&#25968;&#25454;&#38598;&#19978;&#20174;&#22836;&#24320;&#22987;&#35757;&#32451;&#23567;&#27169;&#22411;&#30340;&#20570;&#27861;&#65292;&#26412;&#25991;&#26088;&#22312;&#26089;&#26399;&#24320;&#21457;&#22823;&#35268;&#27169;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#65288;LTSM&#65289;&#12290;&#22312;&#39044;&#35757;&#32451;&#26399;&#38388;&#65292;&#25105;&#20204;&#31574;&#21010;&#20102;&#21253;&#21547;10&#20159;&#20010;&#26102;&#38388;&#28857;&#30340;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#65292;&#23558;&#24322;&#26500;&#26102;&#38388;&#24207;&#21015;&#32479;&#19968;&#20026;&#21333;&#24207;&#21015;&#24207;&#21015;&#65288;S3&#65289;&#26684;&#24335;&#65292;&#24182;&#24320;&#21457;&#20102;&#38754;&#21521;LTSM&#30340;GPT&#39118;&#26684;&#26550;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep learning has contributed remarkably to the advancement of time series analysis. Still, deep models can encounter performance bottlenecks in real-world small-sample scenarios, which can be concealed due to the performance saturation with small models on current benchmarks. Meanwhile, large models have demonstrated great powers in these scenarios through large-scale pre-training. Continuous progresses have been achieved as the emergence of large language models, exhibiting unprecedented ability in few-shot generalization, scalability, and task generality, which is however absent in time series models. To change the current practices of training small models on specific datasets from scratch, this paper aims at an early development of large time series models (LTSM). During pre-training, we curate large-scale datasets with up to 1 billion time points, unify heterogeneous time series into single-series sequence (S3) format, and develop the GPT-style architecture toward LTSMs. To meet 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;$\ell_0$&#27491;&#21017;&#21270;&#38382;&#39064;&#30340;&#23545;&#20598;&#24418;&#24335;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#21407;&#23545;&#20598;&#31639;&#27861;&#65292;&#36890;&#36807;&#20805;&#20998;&#21033;&#29992;&#23545;&#20598;&#33539;&#22260;&#20272;&#35745;&#21644;&#22686;&#37327;&#31574;&#30053;&#65292;&#25552;&#39640;&#20102;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;&#38382;&#39064;&#30340;&#35299;&#20915;&#26041;&#26696;&#30340;&#25928;&#29575;&#21644;&#32479;&#35745;&#24615;&#36136;&#12290;</title><link>https://arxiv.org/abs/2402.02322</link><description>&lt;p&gt;
&#21160;&#24577;&#22686;&#37327;&#20248;&#21270;&#29992;&#20110;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;
&lt;/p&gt;
&lt;p&gt;
Dynamic Incremental Optimization for Best Subset Selection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.02322
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;$\ell_0$&#27491;&#21017;&#21270;&#38382;&#39064;&#30340;&#23545;&#20598;&#24418;&#24335;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#21407;&#23545;&#20598;&#31639;&#27861;&#65292;&#36890;&#36807;&#20805;&#20998;&#21033;&#29992;&#23545;&#20598;&#33539;&#22260;&#20272;&#35745;&#21644;&#22686;&#37327;&#31574;&#30053;&#65292;&#25552;&#39640;&#20102;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;&#38382;&#39064;&#30340;&#35299;&#20915;&#26041;&#26696;&#30340;&#25928;&#29575;&#21644;&#32479;&#35745;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;&#34987;&#35748;&#20026;&#26159;&#31232;&#30095;&#23398;&#20064;&#38382;&#39064;&#30340;&#8220;&#40644;&#37329;&#26631;&#20934;&#8221;&#12290;&#24050;&#32463;&#25552;&#20986;&#20102;&#21508;&#31181;&#20248;&#21270;&#25216;&#26415;&#26469;&#25915;&#20987;&#36825;&#20010;&#38750;&#20809;&#28369;&#38750;&#20984;&#38382;&#39064;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31867;$\ell_0$&#27491;&#21017;&#21270;&#38382;&#39064;&#30340;&#23545;&#20598;&#24418;&#24335;&#12290;&#22522;&#20110;&#21407;&#22987;&#38382;&#39064;&#21644;&#23545;&#20598;&#38382;&#39064;&#30340;&#32467;&#26500;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#21407;&#23545;&#20598;&#31639;&#27861;&#12290;&#36890;&#36807;&#20805;&#20998;&#21033;&#29992;&#23545;&#20598;&#33539;&#22260;&#20272;&#35745;&#21644;&#22686;&#37327;&#31574;&#30053;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#28508;&#22312;&#22320;&#20943;&#23569;&#20102;&#20887;&#20313;&#35745;&#31639;&#24182;&#25913;&#36827;&#20102;&#26368;&#20339;&#23376;&#38598;&#36873;&#25321;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#29702;&#35770;&#20998;&#26512;&#21644;&#23545;&#21512;&#25104;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#39564;&#35777;&#20102;&#25152;&#25552;&#20986;&#35299;&#20915;&#26041;&#26696;&#30340;&#25928;&#29575;&#21644;&#32479;&#35745;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
Best subset selection is considered the `gold standard' for many sparse learning problems. A variety of optimization techniques have been proposed to attack this non-smooth non-convex problem. In this paper, we investigate the dual forms of a family of $\ell_0$-regularized problems. An efficient primal-dual algorithm is developed based on the primal and dual problem structures. By leveraging the dual range estimation along with the incremental strategy, our algorithm potentially reduces redundant computation and improves the solutions of best subset selection. Theoretical analysis and experiments on synthetic and real-world datasets validate the efficiency and statistical properties of the proposed solutions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#35757;&#32451;PINNs&#30340;&#25361;&#25112;&#65292;&#24378;&#35843;&#20102;&#25439;&#22833;&#20989;&#25968;&#31354;&#38388;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#30340;&#20316;&#29992;&#65292;&#24341;&#20837;&#20102;&#26032;&#39062;&#30340;&#20108;&#38454;&#20248;&#21270;&#22120;NNCG&#24182;&#20248;&#21270;&#20102;PINN&#24615;&#33021;&#65292;&#20026;&#35757;&#32451;PINNs&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#27934;&#35265;&#21644;&#26356;&#24378;&#22823;&#30340;&#20248;&#21270;&#31574;&#30053;&#12290;</title><link>https://arxiv.org/abs/2402.01868</link><description>&lt;p&gt;
&#35757;&#32451;PINNs&#30340;&#25361;&#25112;&#65306;&#20174;&#25439;&#22833;&#20989;&#25968;&#31354;&#38388;&#35282;&#24230;&#25506;&#31350;
&lt;/p&gt;
&lt;p&gt;
Challenges in Training PINNs: A Loss Landscape Perspective
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.01868
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#35757;&#32451;PINNs&#30340;&#25361;&#25112;&#65292;&#24378;&#35843;&#20102;&#25439;&#22833;&#20989;&#25968;&#31354;&#38388;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#30340;&#20316;&#29992;&#65292;&#24341;&#20837;&#20102;&#26032;&#39062;&#30340;&#20108;&#38454;&#20248;&#21270;&#22120;NNCG&#24182;&#20248;&#21270;&#20102;PINN&#24615;&#33021;&#65292;&#20026;&#35757;&#32451;PINNs&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#27934;&#35265;&#21644;&#26356;&#24378;&#22823;&#30340;&#20248;&#21270;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#30740;&#31350;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#65288;PINNs&#65289;&#30340;&#35757;&#32451;&#25361;&#25112;&#65292;&#24378;&#35843;&#20102;&#25439;&#22833;&#20989;&#25968;&#31354;&#38388;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#30340;&#20316;&#29992;&#12290;&#25105;&#20204;&#20998;&#26512;&#20102;&#22312;&#26368;&#23567;&#21270;PINN&#25439;&#22833;&#20989;&#25968;&#26041;&#38754;&#30340;&#22256;&#38590;&#65292;&#29305;&#21035;&#26159;&#30001;&#20110;&#27531;&#24046;&#39033;&#20013;&#30340;&#24494;&#20998;&#31639;&#23376;&#24341;&#36215;&#30340;&#30149;&#24577;&#26465;&#20214;&#12290;&#25105;&#20204;&#27604;&#36739;&#20102;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#22120;Adam&#12289;L-BFGS&#20197;&#21450;&#23427;&#20204;&#30340;&#32452;&#21512;Adam+L-BFGS&#30340;&#24615;&#33021;&#65292;&#34920;&#26126;Adam+L-BFGS&#26356;&#20248;&#65292;&#24182;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20108;&#38454;&#20248;&#21270;&#22120;NysNewton-CG&#65288;NNCG&#65289;&#65292;&#26174;&#33879;&#25552;&#39640;&#20102;PINN&#30340;&#24615;&#33021;&#12290;&#20174;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#38416;&#26126;&#20102;&#30149;&#24577;&#24494;&#20998;&#31639;&#23376;&#19982;PINN&#25439;&#22833;&#20013;&#30340;&#30149;&#24577;&#26465;&#20214;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#24182;&#23637;&#31034;&#20102;&#32467;&#21512;&#19968;&#38454;&#21644;&#20108;&#38454;&#20248;&#21270;&#26041;&#27861;&#30340;&#22909;&#22788;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#20026;&#35757;&#32451;PINNs&#25552;&#20379;&#20102;&#26377;&#20215;&#20540;&#30340;&#27934;&#35265;&#21644;&#26356;&#24378;&#22823;&#30340;&#20248;&#21270;&#31574;&#30053;&#65292;&#21487;&#20197;&#25552;&#39640;PINNs&#22312;&#35299;&#20915;&#22256;&#38590;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#20013;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper explores challenges in training Physics-Informed Neural Networks (PINNs), emphasizing the role of the loss landscape in the training process. We examine difficulties in minimizing the PINN loss function, particularly due to ill-conditioning caused by differential operators in the residual term. We compare gradient-based optimizers Adam, L-BFGS, and their combination Adam+L-BFGS, showing the superiority of Adam+L-BFGS, and introduce a novel second-order optimizer, NysNewton-CG (NNCG), which significantly improves PINN performance. Theoretically, our work elucidates the connection between ill-conditioned differential operators and ill-conditioning in the PINN loss and shows the benefits of combining first- and second-order optimization methods. Our work presents valuable insights and more powerful optimization strategies for training PINNs, which could improve the utility of PINNs for solving difficult partial differential equations.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#36817;&#37051;&#30340;&#37096;&#20998;&#26631;&#31614;&#23398;&#20064;&#31639;&#27861;&#65292;&#21033;&#29992;Dempster-Shafer&#29702;&#35770;&#23454;&#29616;&#23545;&#27169;&#31946;&#26631;&#35760;&#30340;&#25968;&#25454;&#30340;&#35757;&#32451;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#25552;&#20379;&#33391;&#22909;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#24182;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;</title><link>https://arxiv.org/abs/2402.00592</link><description>&lt;p&gt;
&#19981;&#30830;&#23450;&#24615;&#24863;&#30693;&#30340;&#37096;&#20998;&#26631;&#31614;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Uncertainty-Aware Partial-Label Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.00592
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#36817;&#37051;&#30340;&#37096;&#20998;&#26631;&#31614;&#23398;&#20064;&#31639;&#27861;&#65292;&#21033;&#29992;Dempster-Shafer&#29702;&#35770;&#23454;&#29616;&#23545;&#27169;&#31946;&#26631;&#35760;&#30340;&#25968;&#25454;&#30340;&#35757;&#32451;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#25552;&#20379;&#33391;&#22909;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#24182;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29616;&#23454;&#19990;&#30028;&#30340;&#24212;&#29992;&#20013;&#65292;&#20154;&#20204;&#32463;&#24120;&#36935;&#21040;&#26631;&#35760;&#27169;&#31946;&#30340;&#25968;&#25454;&#65292;&#21363;&#19981;&#21516;&#30340;&#26631;&#27880;&#32773;&#20026;&#30456;&#21516;&#26679;&#26412;&#20998;&#37197;&#20102;&#20914;&#31361;&#30340;&#31867;&#21035;&#26631;&#31614;&#12290;&#37096;&#20998;&#26631;&#31614;&#23398;&#20064;&#20801;&#35768;&#22312;&#36825;&#31181;&#24369;&#30417;&#30563;&#30340;&#24773;&#20917;&#19979;&#35757;&#32451;&#20998;&#31867;&#22120;&#12290;&#34429;&#28982;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#24050;&#32463;&#20855;&#26377;&#33391;&#22909;&#30340;&#39044;&#27979;&#24615;&#33021;&#65292;&#20294;&#23427;&#20204;&#24448;&#24448;&#21463;&#21040;&#38169;&#35823;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#30340;&#24433;&#21709;&#12290;&#28982;&#32780;&#65292;&#22312;&#21307;&#23398;&#21644;&#33258;&#21160;&#39550;&#39542;&#31561;&#23433;&#20840;&#20851;&#38190;&#39046;&#22495;&#65292;&#20855;&#26377;&#33391;&#22909;&#26657;&#20934;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#23588;&#20026;&#37325;&#35201;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#36817;&#37051;&#30340;&#37096;&#20998;&#26631;&#31614;&#23398;&#20064;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#21033;&#29992;&#20102;Dempster-Shafer&#29702;&#35770;&#12290;&#23545;&#20154;&#24037;&#25968;&#25454;&#38598;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#36827;&#34892;&#30340;&#24191;&#27867;&#23454;&#39564;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#33021;&#22815;&#25552;&#20379;&#33391;&#22909;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#65292;&#24182;&#20855;&#26377;&#31454;&#20105;&#21147;&#30340;&#39044;&#27979;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#20855;&#26377;&#39118;&#38505;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In real-world applications, one often encounters ambiguously labeled data, where different annotators assign conflicting class labels. Partial-label learning allows training classifiers in this weakly supervised setting. While state-of-the-art methods already feature good predictive performance, they often suffer from miscalibrated uncertainty estimates. However, having well-calibrated uncertainty estimates is important, especially in safety-critical domains like medicine and autonomous driving. In this article, we propose a novel nearest-neighbor-based partial-label-learning algorithm that leverages Dempster-Shafer theory. Extensive experiments on artificial and real-world datasets show that the proposed method provides a well-calibrated uncertainty estimate and achieves competitive prediction performance. Additionally, we prove that our algorithm is risk-consistent.
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#37327;&#23376;&#21551;&#33945;&#20998;&#25968;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;&#37327;&#23376;&#29983;&#25104;&#27169;&#22411;&#36136;&#37327;&#30340;&#26032;&#25351;&#26631;&#65292;&#35777;&#26126;&#37327;&#23376;&#29983;&#25104;&#27169;&#22411;&#22312;&#36136;&#37327;&#19978;&#20248;&#20110;&#32463;&#20856;&#29983;&#25104;&#27169;&#22411;&#65292;&#24182;&#21033;&#29992;&#37327;&#23376;&#27874;&#21160;&#23450;&#29702;&#25581;&#31034;&#20102;&#20854;&#29289;&#29702;&#38480;&#21046;&#12290;</title><link>https://arxiv.org/abs/2311.12163</link><description>&lt;p&gt;
&#37327;&#23376;&#21551;&#33945;&#20998;&#25968;
&lt;/p&gt;
&lt;p&gt;
Quantum Inception Score
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.12163
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#37327;&#23376;&#21551;&#33945;&#20998;&#25968;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#35780;&#20272;&#37327;&#23376;&#29983;&#25104;&#27169;&#22411;&#36136;&#37327;&#30340;&#26032;&#25351;&#26631;&#65292;&#35777;&#26126;&#37327;&#23376;&#29983;&#25104;&#27169;&#22411;&#22312;&#36136;&#37327;&#19978;&#20248;&#20110;&#32463;&#20856;&#29983;&#25104;&#27169;&#22411;&#65292;&#24182;&#21033;&#29992;&#37327;&#23376;&#27874;&#21160;&#23450;&#29702;&#25581;&#31034;&#20102;&#20854;&#29289;&#29702;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#21040;&#32463;&#20856;&#29983;&#25104;&#27169;&#22411;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#21462;&#24471;&#24040;&#22823;&#25104;&#21151;&#30340;&#21551;&#21457;&#65292;&#36817;&#26399;&#24320;&#22987;&#20102;&#23545;&#23427;&#20204;&#37327;&#23376;&#29256;&#26412;&#30340;&#28909;&#20999;&#25506;&#32034;&#12290;&#20026;&#20102;&#24320;&#22987;&#36825;&#19968;&#25506;&#32034;&#20043;&#26053;&#65292;&#24320;&#21457;&#19968;&#20010;&#30456;&#20851;&#30340;&#24230;&#37327;&#26631;&#20934;&#26469;&#35780;&#20272;&#37327;&#23376;&#29983;&#25104;&#27169;&#22411;&#30340;&#36136;&#37327;&#26159;&#24456;&#37325;&#35201;&#30340;&#65307;&#22312;&#32463;&#20856;&#24773;&#20917;&#19979;&#65292;&#19968;&#20010;&#36825;&#26679;&#30340;&#20363;&#23376;&#20415;&#26159;&#21551;&#33945;&#20998;&#25968;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#37327;&#23376;&#21551;&#33945;&#20998;&#25968;&#65292;&#23427;&#23558;&#36136;&#37327;&#19982;&#29992;&#20110;&#23545;&#32473;&#23450;&#25968;&#25454;&#38598;&#36827;&#34892;&#20998;&#31867;&#30340;&#37327;&#23376;&#36890;&#36947;&#30340;Holevo&#20449;&#24687;&#32852;&#31995;&#36215;&#26469;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#36825;&#20010;&#25552;&#20986;&#30340;&#24230;&#37327;&#26631;&#20934;&#19979;&#65292;&#37327;&#23376;&#29983;&#25104;&#27169;&#22411;&#25552;&#20379;&#27604;&#23427;&#20204;&#30340;&#32463;&#20856;&#23545;&#24212;&#29289;&#26356;&#22909;&#30340;&#36136;&#37327;&#65292;&#22240;&#20026;&#23384;&#22312;&#30528;&#30001;&#19981;&#23545;&#31216;&#24615;&#30340;&#36164;&#28304;&#29702;&#35770;&#21644;&#32416;&#32544;&#25152;&#34920;&#24449;&#30340;&#37327;&#23376;&#30456;&#24178;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21033;&#29992;&#37327;&#23376;&#27874;&#21160;&#23450;&#29702;&#26469;&#34920;&#24449;&#38480;&#21046;&#37327;&#23376;&#29983;&#25104;&#27169;&#22411;&#36136;&#37327;&#30340;&#29289;&#29702;&#38480;&#21046;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#24212;&#29992;&#37327;&#23376;&#21551;&#33945;&#20998;&#25968;&#26469;
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.12163v2 Announce Type: replace-cross  Abstract: Motivated by the great success of classical generative models in machine learning, enthusiastic exploration of their quantum version has recently started. To depart on this journey, it is important to develop a relevant metric to evaluate the quality of quantum generative models; in the classical case, one such example is the inception score. In this paper, we propose the quantum inception score, which relates the quality to the Holevo information of the quantum channel that classifies a given dataset. We prove that, under this proposed measure, the quantum generative models provide better quality than their classical counterparts because of the presence of quantum coherence, characterized by the resource theory of asymmetry, and entanglement. Furthermore, we harness the quantum fluctuation theorem to characterize the physical limitation of the quality of quantum generative models. Finally, we apply the quantum inception score 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20844;&#24179;&#30340;Wasserstein&#26680;&#24515;&#38598;(FWC)&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#26368;&#23567;&#21270;&#21407;&#22987;&#25968;&#25454;&#38598;&#19982;&#21152;&#26435;&#21512;&#25104;&#26679;&#26412;&#20043;&#38388;&#30340;Wasserstein&#36317;&#31163;&#65292;&#24182;&#24378;&#21046;&#23454;&#29616;&#20154;&#21475;&#24179;&#31561;&#65292;&#29983;&#25104;&#20844;&#24179;&#30340;&#21512;&#25104;&#20195;&#34920;&#24615;&#26679;&#26412;&#65292;&#21487;&#29992;&#20110;&#19979;&#28216;&#23398;&#20064;&#20219;&#21153;&#12290;</title><link>https://arxiv.org/abs/2311.05436</link><description>&lt;p&gt;
&#36890;&#36807;&#26368;&#20248;&#20256;&#36755;&#23454;&#29616;&#20844;&#24179;&#30340;&#26680;&#24515;&#38598;
&lt;/p&gt;
&lt;p&gt;
Fair Coresets via Optimal Transport
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.05436
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20844;&#24179;&#30340;Wasserstein&#26680;&#24515;&#38598;(FWC)&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#26368;&#23567;&#21270;&#21407;&#22987;&#25968;&#25454;&#38598;&#19982;&#21152;&#26435;&#21512;&#25104;&#26679;&#26412;&#20043;&#38388;&#30340;Wasserstein&#36317;&#31163;&#65292;&#24182;&#24378;&#21046;&#23454;&#29616;&#20154;&#21475;&#24179;&#31561;&#65292;&#29983;&#25104;&#20844;&#24179;&#30340;&#21512;&#25104;&#20195;&#34920;&#24615;&#26679;&#26412;&#65292;&#21487;&#29992;&#20110;&#19979;&#28216;&#23398;&#20064;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#31934;&#28860;&#21644;&#26680;&#24515;&#38598;&#24050;&#25104;&#20026;&#29983;&#25104;&#29992;&#20110;&#22788;&#29702;&#22823;&#35268;&#27169;&#25968;&#25454;&#38598;&#30340;&#19979;&#28216;&#23398;&#20064;&#20219;&#21153;&#30340;&#36739;&#23567;&#20195;&#34920;&#24615;&#26679;&#26412;&#38598;&#30340;&#27969;&#34892;&#26041;&#27861;&#12290;&#19982;&#27492;&#21516;&#26102;&#65292;&#26426;&#22120;&#23398;&#20064;&#36234;&#26469;&#36234;&#22810;&#22320;&#24212;&#29992;&#20110;&#31038;&#20250;&#23618;&#38754;&#30340;&#20915;&#31574;&#36807;&#31243;&#65292;&#20351;&#24471;&#27169;&#22411;&#26500;&#24314;&#32773;&#24517;&#39035;&#35299;&#20915;&#23384;&#22312;&#20110;&#25968;&#25454;&#20013;&#30340;&#23376;&#32676;&#20307;&#30340;&#22266;&#26377;&#20559;&#35265;&#38382;&#39064;&#12290;&#24403;&#21069;&#26041;&#27861;&#36890;&#36807;&#20248;&#21270;&#30456;&#23545;&#20110;&#21407;&#22987;&#26679;&#26412;&#30340;&#23616;&#37096;&#23646;&#24615;&#26469;&#21019;&#24314;&#20844;&#24179;&#30340;&#21512;&#25104;&#20195;&#34920;&#24615;&#26679;&#26412;&#65292;&#20294;&#20854;&#23545;&#19979;&#28216;&#23398;&#20064;&#36807;&#31243;&#30340;&#24433;&#21709;&#23578;&#26410;&#34987;&#25506;&#32034;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20844;&#24179;&#30340;Wasserstein&#26680;&#24515;&#38598;&#65288;FWC&#65289;&#65292;&#19968;&#31181;&#26032;&#39062;&#30340;&#26680;&#24515;&#38598;&#26041;&#27861;&#65292;&#23427;&#29983;&#25104;&#26082;&#20855;&#26377;&#20844;&#24179;&#24615;&#30340;&#21512;&#25104;&#20195;&#34920;&#24615;&#26679;&#26412;&#65292;&#21448;&#20855;&#26377;&#29992;&#20110;&#19979;&#28216;&#23398;&#20064;&#20219;&#21153;&#30340;&#26679;&#26412;&#32423;&#26435;&#37325;&#12290;FWC&#26368;&#23567;&#21270;&#21407;&#22987;&#25968;&#25454;&#38598;&#19982;&#21152;&#26435;&#21512;&#25104;&#26679;&#26412;&#20043;&#38388;&#30340;Wasserstein&#36317;&#31163;&#65292;&#21516;&#26102;&#24378;&#21046;&#23454;&#29616;&#20154;&#21475;&#24179;&#31561;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;FWC&#30340;&#26080;&#32422;&#26463;&#29256;&#26412;&#31561;&#20215;&#20110;&#36890;&#24120;&#30340;&#26368;&#20248;&#20256;&#36755;&#38382;&#39064;&#65292;&#24182;&#19988;&#36890;&#36807;&#23454;&#39564;&#35777;&#26126;&#20102;FWC&#30340;&#26377;&#25928;&#24615;&#21644;&#20844;&#24179;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data distillation and coresets have emerged as popular approaches to generate a smaller representative set of samples for downstream learning tasks to handle large-scale datasets. At the same time, machine learning is being increasingly applied to decision-making processes at a societal level, making it imperative for modelers to address inherent biases towards subgroups present in the data. Current approaches create fair synthetic representative samples by optimizing local properties relative to the original samples, but their effect on downstream learning processes has yet to be explored. In this work, we present fair Wasserstein coresets (FWC), a novel coreset approach which generates fair synthetic representative samples along with sample-level weights to be used in downstream learning tasks. FWC minimizes the Wasserstein distance between the original dataset and the weighted synthetic samples while enforcing demographic parity. We show that an unconstrained version of FWC is equiv
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21160;&#24577;&#29983;&#23384;&#20998;&#26512;&#26041;&#27861;&#65292;&#36890;&#36807;&#25511;&#21046;&#28508;&#22312;&#29366;&#24577;&#26469;&#23398;&#20064;&#20010;&#20307;&#29305;&#23450;&#30340;&#35745;&#25968;&#36807;&#31243;&#24378;&#24230;&#12290;&#30740;&#31350;&#32773;&#35774;&#35745;&#20102;&#19968;&#20010;&#31070;&#32463;&#25511;&#21046;&#24494;&#20998;&#26041;&#31243;&#27169;&#22411;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#36275;&#22815;&#27491;&#21017;&#26465;&#20214;&#19979;&#65292;&#21487;&#20197;&#22312;&#31614;&#21517;&#31354;&#38388;&#20013;&#32447;&#24615;&#21270;&#27169;&#22411;&#65292;&#24471;&#21040;&#19968;&#31181;&#22522;&#20110;&#31614;&#21517;&#30340;&#20272;&#35745;&#22120;&#12290;&#36890;&#36807;&#23545;&#37329;&#34701;&#12289;&#39044;&#27979;&#24615;&#32500;&#25252;&#21644;&#39135;&#21697;&#20379;&#24212;&#38142;&#31649;&#29702;&#31561;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#65292;&#39564;&#35777;&#20102;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2401.17077</link><description>&lt;p&gt;
&#21160;&#24577;&#29983;&#23384;&#20998;&#26512;&#19982;&#25511;&#21046;&#28508;&#22312;&#29366;&#24577;
&lt;/p&gt;
&lt;p&gt;
Dynamical Survival Analysis with Controlled Latent States. (arXiv:2401.17077v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.17077
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21160;&#24577;&#29983;&#23384;&#20998;&#26512;&#26041;&#27861;&#65292;&#36890;&#36807;&#25511;&#21046;&#28508;&#22312;&#29366;&#24577;&#26469;&#23398;&#20064;&#20010;&#20307;&#29305;&#23450;&#30340;&#35745;&#25968;&#36807;&#31243;&#24378;&#24230;&#12290;&#30740;&#31350;&#32773;&#35774;&#35745;&#20102;&#19968;&#20010;&#31070;&#32463;&#25511;&#21046;&#24494;&#20998;&#26041;&#31243;&#27169;&#22411;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#36275;&#22815;&#27491;&#21017;&#26465;&#20214;&#19979;&#65292;&#21487;&#20197;&#22312;&#31614;&#21517;&#31354;&#38388;&#20013;&#32447;&#24615;&#21270;&#27169;&#22411;&#65292;&#24471;&#21040;&#19968;&#31181;&#22522;&#20110;&#31614;&#21517;&#30340;&#20272;&#35745;&#22120;&#12290;&#36890;&#36807;&#23545;&#37329;&#34701;&#12289;&#39044;&#27979;&#24615;&#32500;&#25252;&#21644;&#39135;&#21697;&#20379;&#24212;&#38142;&#31649;&#29702;&#31561;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#65292;&#39564;&#35777;&#20102;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#20174;&#19968;&#32452;&#38745;&#24577;&#21464;&#37327;&#21644;&#19981;&#35268;&#21017;&#37319;&#26679;&#30340;&#26102;&#38388;&#24207;&#21015;&#20013;&#23398;&#20064;&#20010;&#20307;&#29305;&#23450;&#30340;&#35745;&#25968;&#36807;&#31243;&#24378;&#24230;&#30340;&#20219;&#21153;&#12290;&#25105;&#20204;&#24341;&#20837;&#19968;&#31181;&#26032;&#39062;&#30340;&#24314;&#27169;&#26041;&#27861;&#65292;&#20854;&#20013;&#24378;&#24230;&#26159;&#25511;&#21046;&#24494;&#20998;&#26041;&#31243;&#30340;&#35299;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#36890;&#36807;&#26500;&#24314;&#31070;&#32463;&#25511;&#21046;&#24494;&#20998;&#26041;&#31243;&#26469;&#35774;&#35745;&#19968;&#20010;&#31070;&#32463;&#20272;&#35745;&#22120;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#22312;&#36275;&#22815;&#27491;&#21017;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#30340;&#27169;&#22411;&#21487;&#20197;&#22312;&#31614;&#21517;&#31354;&#38388;&#20013;&#32447;&#24615;&#21270;&#65292;&#24471;&#21040;&#19968;&#31181;&#22522;&#20110;&#31614;&#21517;&#30340;&#20272;&#35745;&#22120;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;CoxSig&#12290;&#25105;&#20204;&#20026;&#36825;&#20004;&#31181;&#20272;&#35745;&#22120;&#25552;&#20379;&#29702;&#35770;&#23398;&#20064;&#20445;&#35777;&#65292;&#24182;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#22312;&#37329;&#34701;&#12289;&#39044;&#27979;&#24615;&#32500;&#25252;&#21644;&#39135;&#21697;&#20379;&#24212;&#38142;&#31649;&#29702;&#31561;&#21508;&#31181;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the task of learning individual-specific intensities of counting processes from a set of static variables and irregularly sampled time series. We introduce a novel modelization approach in which the intensity is the solution to a controlled differential equation. We first design a neural estimator by building on neural controlled differential equations. In a second time, we show that our model can be linearized in the signature space under sufficient regularity conditions, yielding a signature-based estimator which we call CoxSig. We provide theoretical learning guarantees for both estimators, before showcasing the performance of our models on a vast array of simulated and real-world datasets from finance, predictive maintenance and food supply chain management.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#25552;&#20986;&#30340;&#24322;&#36136;&#24615;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;HSBM&#65289;&#26469;&#25552;&#20379;&#23545;&#19981;&#21516;&#24322;&#36136;&#24615;&#27169;&#24335;&#23545;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#24433;&#21709;&#30340;&#29702;&#35770;&#29702;&#35299;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#24322;&#36136;&#24615;&#23545;&#20998;&#31867;&#30340;&#24433;&#21709;&#38656;&#35201;&#19982;&#24179;&#22343;&#33410;&#28857;&#24230;&#19968;&#36215;&#35780;&#20272;&#65292;&#24182;&#19988;&#25299;&#25169;&#22122;&#22768;&#23545;&#20998;&#31867;&#26377;&#36127;&#38754;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2401.09125</link><description>&lt;p&gt;
&#29702;&#35299;&#22270;&#31070;&#32463;&#32593;&#32476;&#30340;&#24322;&#36136;&#24615;
&lt;/p&gt;
&lt;p&gt;
Understanding Heterophily for Graph Neural Networks. (arXiv:2401.09125v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2401.09125
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25552;&#20986;&#30340;&#24322;&#36136;&#24615;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;HSBM&#65289;&#26469;&#25552;&#20379;&#23545;&#19981;&#21516;&#24322;&#36136;&#24615;&#27169;&#24335;&#23545;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#24433;&#21709;&#30340;&#29702;&#35770;&#29702;&#35299;&#12290;&#30740;&#31350;&#21457;&#29616;&#65292;&#24322;&#36136;&#24615;&#23545;&#20998;&#31867;&#30340;&#24433;&#21709;&#38656;&#35201;&#19982;&#24179;&#22343;&#33410;&#28857;&#24230;&#19968;&#36215;&#35780;&#20272;&#65292;&#24182;&#19988;&#25299;&#25169;&#22122;&#22768;&#23545;&#20998;&#31867;&#26377;&#36127;&#38754;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20855;&#26377;&#24322;&#36136;&#24615;&#30340;&#22270;&#34987;&#35748;&#20026;&#26159;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#38754;&#20020;&#25361;&#25112;&#30340;&#24773;&#26223;&#65292;&#20854;&#20013;&#33410;&#28857;&#36890;&#36807;&#21508;&#31181;&#27169;&#24335;&#19982;&#19981;&#21516;&#30340;&#37051;&#23621;&#30456;&#36830;&#25509;&#12290;&#26412;&#25991;&#36890;&#36807;&#23558;&#22270;&#21367;&#31215;&#65288;GC&#65289;&#25805;&#20316;&#21512;&#24182;&#21040;&#23436;&#20840;&#36830;&#25509;&#30340;&#32593;&#32476;&#20013;&#65292;&#36890;&#36807;&#25552;&#20986;&#30340;&#24322;&#36136;&#24615;&#38543;&#26426;&#22359;&#27169;&#22411;&#65288;HSBM&#65289;&#26469;&#25552;&#20379;&#23545;&#19981;&#21516;&#24322;&#36136;&#24615;&#27169;&#24335;&#23545;GNNs&#24433;&#21709;&#30340;&#29702;&#35770;&#29702;&#35299;&#65292;HSBM&#26159;&#19968;&#20010;&#21487;&#20197;&#23481;&#32435;&#22810;&#26679;&#30340;&#24322;&#36136;&#24615;&#27169;&#24335;&#30340;&#36890;&#29992;&#38543;&#26426;&#22270;&#27169;&#22411;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#36807;&#24212;&#29992;GC&#25805;&#20316;&#65292;&#21487;&#20998;&#24615;&#22686;&#30410;&#21462;&#20915;&#20110;&#20004;&#20010;&#22240;&#32032;&#65292;&#21363;&#37051;&#22495;&#20998;&#24067;&#30340;&#27431;&#27663;&#36317;&#31163;&#21644;$\sqrt{\mathbb{E}\left[\operatorname{deg}\right]}$&#65292;&#20854;&#20013;$\mathbb{E}\left[\operatorname{deg}\right]$&#26159;&#24179;&#22343;&#33410;&#28857;&#24230;&#12290;&#23427;&#25581;&#31034;&#20102;&#24322;&#36136;&#24615;&#23545;&#20998;&#31867;&#30340;&#24433;&#21709;&#38656;&#35201;&#19982;&#24179;&#22343;&#33410;&#28857;&#24230;&#19968;&#36215;&#35780;&#20272;&#12290;&#20854;&#27425;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25299;&#25169;&#22122;&#22768;&#20855;&#26377;&#36127;&#38754;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Graphs with heterophily have been regarded as challenging scenarios for Graph Neural Networks (GNNs), where nodes are connected with dissimilar neighbors through various patterns. In this paper, we present theoretical understandings of the impacts of different heterophily patterns for GNNs by incorporating the graph convolution (GC) operations into fully connected networks via the proposed Heterophilous Stochastic Block Models (HSBM), a general random graph model that can accommodate diverse heterophily patterns. Firstly, we show that by applying a GC operation, the separability gains are determined by two factors, i.e., the Euclidean distance of the neighborhood distributions and $\sqrt{\mathbb{E}\left[\operatorname{deg}\right]}$, where $\mathbb{E}\left[\operatorname{deg}\right]$ is the averaged node degree. It reveals that the impact of heterophily on classification needs to be evaluated alongside the averaged node degree. Secondly, we show that the topological noise has a detrimenta
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#23545;&#25239;&#30340;&#22522;&#20110;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#30340;&#23545;&#40784;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#32452;&#23545;&#40784;&#19978;&#30028;&#65292;&#35299;&#20915;&#20102;&#20808;&#21069;&#26041;&#27861;&#20013;&#23384;&#22312;&#30340;&#19981;&#31283;&#23450;&#24615;&#21644;&#38480;&#21046;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#31181;&#26032;&#39062;&#30340;&#23545;&#40784;&#25439;&#22833;&#21487;&#20197;&#22312;&#19981;&#25913;&#21464;&#21407;&#22987;&#26550;&#26500;&#30340;&#24773;&#20917;&#19979;&#21462;&#20195;&#23545;&#25239;&#25439;&#22833;&#65292;&#25193;&#23637;&#20102;&#24212;&#29992;&#33539;&#22260;&#12290;</title><link>http://arxiv.org/abs/2310.19690</link><description>&lt;p&gt;
&#36890;&#36807;&#21464;&#20998;&#30028;&#38480;&#23454;&#29616;&#23454;&#29992;&#30340;&#38750;&#23545;&#25239;&#20998;&#24067;&#23545;&#40784;
&lt;/p&gt;
&lt;p&gt;
Towards Practical Non-Adversarial Distribution Alignment via Variational Bounds. (arXiv:2310.19690v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.19690
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#23545;&#25239;&#30340;&#22522;&#20110;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#30340;&#23545;&#40784;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#19968;&#32452;&#23545;&#40784;&#19978;&#30028;&#65292;&#35299;&#20915;&#20102;&#20808;&#21069;&#26041;&#27861;&#20013;&#23384;&#22312;&#30340;&#19981;&#31283;&#23450;&#24615;&#21644;&#38480;&#21046;&#12290;&#23454;&#39564;&#35777;&#26126;&#65292;&#36825;&#31181;&#26032;&#39062;&#30340;&#23545;&#40784;&#25439;&#22833;&#21487;&#20197;&#22312;&#19981;&#25913;&#21464;&#21407;&#22987;&#26550;&#26500;&#30340;&#24773;&#20917;&#19979;&#21462;&#20195;&#23545;&#25239;&#25439;&#22833;&#65292;&#25193;&#23637;&#20102;&#24212;&#29992;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20998;&#24067;&#23545;&#40784;&#21487;&#29992;&#20110;&#23398;&#20064;&#20855;&#26377;&#20844;&#24179;&#24615;&#21644;&#40065;&#26834;&#24615;&#24212;&#29992;&#30340;&#19981;&#21464;&#34920;&#31034;&#12290;&#22823;&#22810;&#25968;&#20808;&#21069;&#30340;&#24037;&#20316;&#37117;&#37319;&#29992;&#23545;&#25239;&#23545;&#40784;&#26041;&#27861;&#65292;&#20294;&#30001;&#27492;&#20135;&#29983;&#30340;&#26497;&#23567;&#26497;&#22823;&#38382;&#39064;&#19981;&#31283;&#23450;&#19988;&#38590;&#20197;&#20248;&#21270;&#12290;&#38750;&#23545;&#25239;&#30340;&#22522;&#20110;&#20284;&#28982;&#30340;&#26041;&#27861;&#35201;&#20040;&#38656;&#35201;&#27169;&#22411;&#21487;&#36870;&#24615;&#65292;&#35201;&#20040;&#23545;&#28508;&#22312;&#20808;&#39564;&#26045;&#21152;&#32422;&#26463;&#65292;&#35201;&#20040;&#32570;&#20047;&#36890;&#29992;&#30340;&#23545;&#40784;&#26694;&#26550;&#12290;&#20026;&#20102;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#23545;&#25239;&#30340;&#22522;&#20110;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#30340;&#23545;&#40784;&#26041;&#27861;&#65292;&#21487;&#24212;&#29992;&#20110;&#20219;&#20309;&#27169;&#22411;&#31649;&#36947;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#32452;&#23545;&#40784;&#19978;&#30028;&#65288;&#21253;&#25324;&#19968;&#20010;&#21547;&#22122;&#38899;&#30340;&#19978;&#30028;&#65289;&#65292;&#20854;&#20855;&#26377;&#31867;&#20284;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#30340;&#30446;&#26631;&#20294;&#20855;&#26377;&#19981;&#21516;&#30340;&#35270;&#35282;&#12290;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#21644;&#23454;&#35777;&#19978;&#20180;&#32454;&#27604;&#36739;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#19982;&#20808;&#21069;&#30340;&#22522;&#20110;&#21464;&#20998;&#33258;&#21160;&#32534;&#30721;&#22120;&#30340;&#23545;&#40784;&#26041;&#27861;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35777;&#26126;&#25105;&#20204;&#30340;&#26032;&#39062;&#23545;&#40784;&#25439;&#22833;&#21487;&#20197;&#22312;&#26631;&#20934;&#30340;&#19981;&#21464;&#34920;&#31034;&#23398;&#20064;&#31649;&#36947;&#20013;&#21462;&#20195;&#23545;&#25239;&#25439;&#22833;&#65292;&#32780;&#26080;&#38656;&#20462;&#25913;&#21407;&#22987;&#26550;&#26500;&#65292;&#20174;&#32780;&#26174;&#33879;&#25299;&#23637;&#20102;&#24212;&#29992;&#33539;&#22260;&#12290;
&lt;/p&gt;
&lt;p&gt;
Distribution alignment can be used to learn invariant representations with applications in fairness and robustness. Most prior works resort to adversarial alignment methods but the resulting minimax problems are unstable and challenging to optimize. Non-adversarial likelihood-based approaches either require model invertibility, impose constraints on the latent prior, or lack a generic framework for alignment. To overcome these limitations, we propose a non-adversarial VAE-based alignment method that can be applied to any model pipeline. We develop a set of alignment upper bounds (including a noisy bound) that have VAE-like objectives but with a different perspective. We carefully compare our method to prior VAE-based alignment approaches both theoretically and empirically. Finally, we demonstrate that our novel alignment losses can replace adversarial losses in standard invariant representation learning pipelines without modifying the original architectures -- thereby significantly bro
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#23545;&#32452;&#21512;&#22810;&#33218;&#32769;&#34382;&#26426;&#30340;&#22870;&#21169;&#27745;&#26579;&#25915;&#20987;&#65292;&#24182;&#32473;&#20986;&#20102;&#25915;&#20987;&#21487;&#33021;&#24615;&#30340;&#26465;&#20214;&#12290;&#19982;&#20197;&#24448;&#23545;&#22810;&#33218;&#32769;&#34382;&#26426;&#30340;&#29702;&#35299;&#30456;&#21453;&#65292;&#25105;&#20204;&#21457;&#29616;&#29305;&#23450;CMAB&#23454;&#20363;&#30340;&#25915;&#20987;&#21487;&#33021;&#24615;&#36824;&#21462;&#20915;&#20110;&#21457;&#21733;&#23454;&#20363;&#26159;&#21542;&#34987;&#23545;&#25163;&#30693;&#26195;&#12290;&#36825;&#34920;&#26126;&#22312;&#23454;&#36341;&#20013;&#23545;CMAB&#36827;&#34892;&#23545;&#25239;&#25915;&#20987;&#26159;&#22256;&#38590;&#30340;&#65292;&#22240;&#20026;&#23545;&#25163;&#22823;&#37096;&#20998;&#24773;&#20917;&#19979;&#26080;&#27861;&#20102;&#35299;&#29615;&#22659;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2310.05308</link><description>&lt;p&gt;
&#23545;&#32452;&#21512;&#22810;&#33218;&#32769;&#34382;&#26426;&#30340;&#23545;&#25239;&#25915;&#20987;
&lt;/p&gt;
&lt;p&gt;
Adversarial Attacks on Combinatorial Multi-Armed Bandits. (arXiv:2310.05308v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05308
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23545;&#32452;&#21512;&#22810;&#33218;&#32769;&#34382;&#26426;&#30340;&#22870;&#21169;&#27745;&#26579;&#25915;&#20987;&#65292;&#24182;&#32473;&#20986;&#20102;&#25915;&#20987;&#21487;&#33021;&#24615;&#30340;&#26465;&#20214;&#12290;&#19982;&#20197;&#24448;&#23545;&#22810;&#33218;&#32769;&#34382;&#26426;&#30340;&#29702;&#35299;&#30456;&#21453;&#65292;&#25105;&#20204;&#21457;&#29616;&#29305;&#23450;CMAB&#23454;&#20363;&#30340;&#25915;&#20987;&#21487;&#33021;&#24615;&#36824;&#21462;&#20915;&#20110;&#21457;&#21733;&#23454;&#20363;&#26159;&#21542;&#34987;&#23545;&#25163;&#30693;&#26195;&#12290;&#36825;&#34920;&#26126;&#22312;&#23454;&#36341;&#20013;&#23545;CMAB&#36827;&#34892;&#23545;&#25239;&#25915;&#20987;&#26159;&#22256;&#38590;&#30340;&#65292;&#22240;&#20026;&#23545;&#25163;&#22823;&#37096;&#20998;&#24773;&#20917;&#19979;&#26080;&#27861;&#20102;&#35299;&#29615;&#22659;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#23545;&#32452;&#21512;&#22810;&#33218;&#32769;&#34382;&#26426;&#65288;CMAB&#65289;&#30340;&#22870;&#21169;&#27745;&#26579;&#25915;&#20987;&#12290;&#25105;&#20204;&#39318;&#20808;&#32473;&#20986;&#20102;CMAB&#25915;&#20987;&#21487;&#33021;&#24615;&#30340;&#20805;&#20998;&#24517;&#35201;&#26465;&#20214;&#65292;&#35813;&#26465;&#20214;&#21462;&#20915;&#20110;&#30456;&#24212;CMAB&#23454;&#20363;&#30340;&#20869;&#22312;&#29305;&#24615;&#65292;&#22914;&#36229;&#33218;&#30340;&#22870;&#21169;&#20998;&#24067;&#21644;&#22522;&#26412;&#33218;&#30340;&#32467;&#26524;&#20998;&#24067;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#36866;&#29992;&#20110;&#21487;&#25915;&#20987;CMAB&#23454;&#20363;&#30340;&#25915;&#20987;&#31639;&#27861;&#12290;&#19982;&#20197;&#24448;&#23545;&#22810;&#33218;&#32769;&#34382;&#26426;&#30340;&#29702;&#35299;&#30456;&#21453;&#65292;&#25105;&#20204;&#30340;&#30740;&#31350;&#25581;&#31034;&#20102;&#19968;&#20010;&#20196;&#20154;&#24778;&#35766;&#30340;&#20107;&#23454;&#65292;&#21363;&#29305;&#23450;CMAB&#23454;&#20363;&#30340;&#25915;&#20987;&#21487;&#33021;&#24615;&#36824;&#21462;&#20915;&#20110;&#21457;&#21733;&#23454;&#20363;&#26159;&#21542;&#34987;&#23545;&#25163;&#30693;&#26195;&#12290;&#36825;&#19968;&#21457;&#29616;&#34920;&#26126;&#65292;CMAB&#30340;&#23545;&#25239;&#25915;&#20987;&#22312;&#23454;&#36341;&#20013;&#24456;&#22256;&#38590;&#65292;&#24182;&#19988;&#19981;&#23384;&#22312;&#36866;&#29992;&#20110;&#20219;&#20309;CMAB&#23454;&#20363;&#30340;&#36890;&#29992;&#25915;&#20987;&#31574;&#30053;&#65292;&#22240;&#20026;&#29615;&#22659;&#23545;&#20110;&#23545;&#25163;&#26469;&#35828;&#22823;&#37096;&#20998;&#26159;&#26410;&#30693;&#30340;&#12290;&#25105;&#20204;&#36890;&#36807;&#23545;&#23454;&#38469;CMAB&#24212;&#29992;&#65288;&#21253;&#25324;&#27010;&#29575;&#26368;&#22823;&#35206;&#30422;&#38382;&#39064;&#12289;&#22312;&#32447;&#26368;&#23567;&#29983;&#25104;&#26641;&#38382;&#39064;&#65289;&#30340;&#22823;&#37327;&#23454;&#39564;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study reward poisoning attacks on Combinatorial Multi-armed Bandits (CMAB). We first provide a sufficient and necessary condition for the attackability of CMAB, which depends on the intrinsic properties of the corresponding CMAB instance such as the reward distributions of super arms and outcome distributions of base arms. Additionally, we devise an attack algorithm for attackable CMAB instances. Contrary to prior understanding of multi-armed bandits, our work reveals a surprising fact that the attackability of a specific CMAB instance also depends on whether the bandit instance is known or unknown to the adversary. This finding indicates that adversarial attacks on CMAB are difficult in practice and a general attack strategy for any CMAB instance does not exist since the environment is mostly unknown to the adversary. We validate our theoretical findings via extensive experiments on real-world CMAB applications including probabilistic maximum covering problem, online minimum spanni
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Causal Inference with Attention (CInA)&#30340;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;&#22240;&#26524;&#25512;&#26029;&#21644;&#27880;&#24847;&#21147;&#30340;&#23545;&#20598;&#20851;&#31995;&#65292;&#22312;&#22797;&#26434;&#20219;&#21153;&#20013;&#23454;&#29616;&#20102;&#38646;&#26679;&#26412;&#30340;&#22240;&#26524;&#25512;&#26029;&#12290;</title><link>http://arxiv.org/abs/2310.00809</link><description>&lt;p&gt;
&#25351;&#21521;&#22240;&#26524;&#22522;&#30784;&#27169;&#22411;: &#22240;&#26524;&#25512;&#26029;&#19982;&#27880;&#24847;&#21147;&#30340;&#23545;&#20598;&#20851;&#31995;
&lt;/p&gt;
&lt;p&gt;
Towards Causal Foundation Model: on Duality between Causal Inference and Attention. (arXiv:2310.00809v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.00809
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Causal Inference with Attention (CInA)&#30340;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;&#22240;&#26524;&#25512;&#26029;&#21644;&#27880;&#24847;&#21147;&#30340;&#23545;&#20598;&#20851;&#31995;&#65292;&#22312;&#22797;&#26434;&#20219;&#21153;&#20013;&#23454;&#29616;&#20102;&#38646;&#26679;&#26412;&#30340;&#22240;&#26524;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#22240;&#26524;&#25512;&#26029;&#21644;&#27880;&#24847;&#21147;&#20043;&#38388;&#30340;&#23545;&#20598;&#36830;&#25509;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Causal Inference with Attention (CInA)&#30340;&#29702;&#35770;&#19978;&#23436;&#22791;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#22810;&#20010;&#26080;&#26631;&#31614;&#25968;&#25454;&#38598;&#36827;&#34892;&#33258;&#30417;&#30563;&#22240;&#26524;&#23398;&#20064;&#65292;&#24182;&#22312;&#26032;&#25968;&#25454;&#30340;&#26410;&#35265;&#20219;&#21153;&#19978;&#23454;&#29616;&#38646;&#26679;&#26412;&#22240;&#26524;&#25512;&#26029;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#22797;&#26434;&#20219;&#21153;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Foundation models have brought changes to the landscape of machine learning, demonstrating sparks of human-level intelligence across a diverse array of tasks. However, a gap persists in complex tasks such as causal inference, primarily due to challenges associated with intricate reasoning steps and high numerical precision requirements. In this work, we take a first step towards building causally-aware foundation models for complex tasks. We propose a novel, theoretically sound method called Causal Inference with Attention (CInA), which utilizes multiple unlabeled datasets to perform self-supervised causal learning, and subsequently enables zero-shot causal inference on unseen tasks with new data. This is based on our theoretical results that demonstrate the primal-dual connection between optimal covariate balancing and self-attention, facilitating zero-shot causal inference through the final layer of a trained transformer-type architecture. We demonstrate empirically that our approach
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#38480;&#39044;&#31639;&#30340;&#38543;&#26426;&#20108;&#33218;&#36172;&#21338;&#26426;&#20013;&#36827;&#34892;&#26368;&#20339;&#33218;&#36873;&#25321;&#30340;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#19981;&#23384;&#22312;&#27604;&#31561;&#27010;&#29575;&#37319;&#26679;&#31639;&#27861;&#26356;&#22909;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#33268;&#31283;&#23450;&#31639;&#27861;&#30340;&#27010;&#24565;&#65292;&#24182;&#35777;&#26126;&#20219;&#20309;&#22312;&#25152;&#26377;&#24773;&#20917;&#19979;&#19982;&#31561;&#27010;&#29575;&#37319;&#26679;&#31639;&#27861;&#34920;&#29616;&#19968;&#26679;&#22909;&#30340;&#31639;&#27861;&#24517;&#39035;&#23646;&#20110;&#36825;&#20010;&#31867;&#21035;&#12290;&#36825;&#19968;&#32467;&#26524;&#35299;&#20915;&#20102;&#20043;&#21069;&#30340;&#20004;&#20010;&#26410;&#35299;&#20043;&#35868;&#12290;</title><link>http://arxiv.org/abs/2308.12000</link><description>&lt;p&gt;
&#26377;&#20851;&#22312;&#26377;&#38480;&#39044;&#31639;&#20108;&#33218;&#36172;&#21338;&#26426;&#20013;&#36827;&#34892;&#26368;&#20339;&#33218;&#36873;&#25321;&#30340;&#32479;&#19968;&#26368;&#20248;&#31639;&#27861;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Uniformly Optimal Algorithms for Best Arm Identification in Two-Armed Bandits with Fixed Budget. (arXiv:2308.12000v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.12000
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26377;&#38480;&#39044;&#31639;&#30340;&#38543;&#26426;&#20108;&#33218;&#36172;&#21338;&#26426;&#20013;&#36827;&#34892;&#26368;&#20339;&#33218;&#36873;&#25321;&#30340;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#19981;&#23384;&#22312;&#27604;&#31561;&#27010;&#29575;&#37319;&#26679;&#31639;&#27861;&#26356;&#22909;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#33268;&#31283;&#23450;&#31639;&#27861;&#30340;&#27010;&#24565;&#65292;&#24182;&#35777;&#26126;&#20219;&#20309;&#22312;&#25152;&#26377;&#24773;&#20917;&#19979;&#19982;&#31561;&#27010;&#29575;&#37319;&#26679;&#31639;&#27861;&#34920;&#29616;&#19968;&#26679;&#22909;&#30340;&#31639;&#27861;&#24517;&#39035;&#23646;&#20110;&#36825;&#20010;&#31867;&#21035;&#12290;&#36825;&#19968;&#32467;&#26524;&#35299;&#20915;&#20102;&#20043;&#21069;&#30340;&#20004;&#20010;&#26410;&#35299;&#20043;&#35868;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20855;&#26377;&#20271;&#21162;&#21033;&#22870;&#21169;&#30340;&#38543;&#26426;&#20108;&#33218;&#36172;&#21338;&#26426;&#20013;&#65292;&#20351;&#29992;&#26377;&#38480;&#39044;&#31639;&#36827;&#34892;&#26368;&#20339;&#33218;&#36873;&#25321;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#19981;&#23384;&#22312;&#19968;&#20010;&#31639;&#27861;&#21487;&#20197;&#22312;&#25152;&#26377;&#24773;&#20917;&#19979;&#19982;&#31561;&#27010;&#29575;&#37319;&#26679;&#31639;&#27861;&#34920;&#29616;&#19968;&#26679;&#22909;&#65288;&#35813;&#31639;&#27861;&#34987;&#31216;&#20026;&#8220;&#22343;&#21248;&#37319;&#26679;&#8221;&#31639;&#27861;&#65289;&#65292;&#24182;&#19988;&#22312;&#33267;&#23569;&#19968;&#20010;&#24773;&#20917;&#19979;&#26126;&#26174;&#20248;&#20110;&#35813;&#31639;&#27861;&#12290;&#31616;&#32780;&#35328;&#20043;&#65292;&#19981;&#23384;&#22312;&#27604;&#22343;&#21248;&#37319;&#26679;&#31639;&#27861;&#26356;&#22909;&#30340;&#31639;&#27861;&#12290;&#20026;&#20102;&#35777;&#26126;&#36825;&#19968;&#32467;&#26524;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#8220;&#19968;&#33268;&#8221;&#21644;&#8220;&#31283;&#23450;&#8221;&#31639;&#27861;&#30340;&#33258;&#28982;&#31867;&#65292;&#24182;&#19988;&#35777;&#26126;&#20102;&#20219;&#20309;&#31639;&#27861;&#35201;&#22312;&#25152;&#26377;&#24773;&#20917;&#19979;&#19982;&#22343;&#21248;&#37319;&#26679;&#31639;&#27861;&#34920;&#29616;&#19968;&#26679;&#22909;&#65292;&#24517;&#39035;&#23646;&#20110;&#36825;&#20010;&#31867;&#21035;&#12290;&#36890;&#36807;&#23548;&#20986;&#28385;&#36275;&#20219;&#20309;&#19968;&#33268;&#19988;&#31283;&#23450;&#31639;&#27861;&#30340;&#38169;&#35823;&#29575;&#30340;&#19979;&#30028;&#65292;&#24182;&#35777;&#26126;&#22343;&#21248;&#37319;&#26679;&#31639;&#27861;&#19982;&#27492;&#19979;&#30028;&#30456;&#21305;&#37197;&#65292;&#25105;&#20204;&#23436;&#25104;&#20102;&#35777;&#26126;&#36807;&#31243;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#35299;&#20915;&#20102;\cite{qin2022open}&#20013;&#25552;&#20986;&#30340;&#20004;&#20010;&#26410;&#35299;&#20043;&#35868;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the problem of best-arm identification with fixed budget in stochastic two-arm bandits with Bernoulli rewards. We prove that surprisingly, there is no algorithm that (i) performs as well as the algorithm sampling each arm equally (this algorithm is referred to as the {\it uniform sampling} algorithm) on all instances, and that (ii) strictly outperforms this algorithm on at least one instance. In short, there is no algorithm better than the uniform sampling algorithm. Towards this result, we introduce the natural class of {\it consistent} and {\it stable} algorithms, and show that any algorithm that performs as well as the uniform sampling algorithm on all instances belongs to this class. The proof is completed by deriving a lower bound on the error rate satisfied by any consistent and stable algorithm, and by showing that the uniform sampling algorithm matches this lower bound. Our results provide a solution to the two open problems presented in \cite{qin2022open}.
&lt;/p&gt;</description></item><item><title>VITS&#26159;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#21464;&#20998;&#25512;&#29702;&#30340;&#26032;&#31639;&#27861;&#65292;&#29992;&#20110;&#24773;&#22659;&#32972;&#31163;&#38382;&#39064;&#30340;&#27748;&#26222;&#26862;&#25277;&#26679;&#12290;&#23427;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#21518;&#39564;&#36817;&#20284;&#65292;&#35745;&#31639;&#25928;&#29575;&#39640;&#65292;&#24182;&#19988;&#22312;&#32447;&#24615;&#24773;&#22659;&#32972;&#31163;&#38382;&#39064;&#20013;&#36798;&#21040;&#19982;&#20256;&#32479;TS&#30456;&#21516;&#38454;&#25968;&#30340;&#27425;&#32447;&#24615;&#36951;&#25022;&#19978;&#30028;&#12290;</title><link>http://arxiv.org/abs/2307.10167</link><description>&lt;p&gt;
VITS: &#22522;&#20110;&#21464;&#20998;&#25512;&#29702;&#30340;&#27748;&#26222;&#26862;&#25277;&#26679;&#29992;&#20110;&#24773;&#22659;&#32972;&#31163;&#38382;&#39064;&#30340;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
VITS : Variational Inference Thomson Sampling for contextual bandits. (arXiv:2307.10167v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.10167
&lt;/p&gt;
&lt;p&gt;
VITS&#26159;&#19968;&#31181;&#22522;&#20110;&#39640;&#26031;&#21464;&#20998;&#25512;&#29702;&#30340;&#26032;&#31639;&#27861;&#65292;&#29992;&#20110;&#24773;&#22659;&#32972;&#31163;&#38382;&#39064;&#30340;&#27748;&#26222;&#26862;&#25277;&#26679;&#12290;&#23427;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#21518;&#39564;&#36817;&#20284;&#65292;&#35745;&#31639;&#25928;&#29575;&#39640;&#65292;&#24182;&#19988;&#22312;&#32447;&#24615;&#24773;&#22659;&#32972;&#31163;&#38382;&#39064;&#20013;&#36798;&#21040;&#19982;&#20256;&#32479;TS&#30456;&#21516;&#38454;&#25968;&#30340;&#27425;&#32447;&#24615;&#36951;&#25022;&#19978;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#24182;&#20998;&#26512;&#20102;&#19968;&#31181;&#29992;&#20110;&#24773;&#22659;&#32972;&#31163;&#38382;&#39064;&#30340;&#27748;&#26222;&#26862;&#25277;&#26679;&#65288;TS&#65289;&#31639;&#27861;&#30340;&#21464;&#20307;&#12290;&#20256;&#32479;&#30340;TS&#31639;&#27861;&#22312;&#27599;&#36718;&#38656;&#35201;&#20174;&#24403;&#21069;&#30340;&#21518;&#39564;&#20998;&#24067;&#20013;&#25277;&#26679;&#65292;&#32780;&#36825;&#36890;&#24120;&#26159;&#38590;&#20197;&#35745;&#31639;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#21487;&#20197;&#20351;&#29992;&#36817;&#20284;&#25512;&#29702;&#25216;&#26415;&#24182;&#25552;&#20379;&#25509;&#36817;&#21518;&#39564;&#20998;&#24067;&#30340;&#26679;&#26412;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#36817;&#20284;&#25216;&#26415;&#35201;&#20040;&#20272;&#35745;&#19981;&#20934;&#30830;&#65288;&#25289;&#26222;&#25289;&#26031;&#36817;&#20284;&#65289;&#65292;&#35201;&#20040;&#35745;&#31639;&#24320;&#38144;&#36739;&#22823;&#65288;MCMC&#26041;&#27861;&#65292;&#38598;&#25104;&#25277;&#26679;...&#65289;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#22522;&#20110;&#39640;&#26031;&#21464;&#20998;&#25512;&#29702;&#30340;&#21464;&#20998;&#25512;&#29702;&#27748;&#26222;&#26862;&#25277;&#26679;&#65288;VITS&#65289;&#12290;&#36825;&#31181;&#26041;&#27861;&#25552;&#20379;&#20102;&#24378;&#22823;&#30340;&#21518;&#39564;&#36817;&#20284;&#65292;&#24182;&#19988;&#23481;&#26131;&#20174;&#20013;&#25277;&#26679;&#65292;&#32780;&#19988;&#35745;&#31639;&#25928;&#29575;&#39640;&#65292;&#26159;TS&#30340;&#29702;&#24819;&#36873;&#25321;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#35777;&#26126;&#20102;&#22312;&#32447;&#24615;&#24773;&#22659;&#32972;&#31163;&#38382;&#39064;&#20013;&#65292;VITS&#23454;&#29616;&#20102;&#19982;&#20256;&#32479;TS&#30456;&#21516;&#38454;&#25968;&#30340;&#27425;&#32447;&#24615;&#36951;&#25022;&#19978;&#30028;&#65292;&#19982;&#32500;&#24230;&#21644;&#22238;&#21512;&#25968;&#25104;&#27491;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we introduce and analyze a variant of the Thompson sampling (TS) algorithm for contextual bandits. At each round, traditional TS requires samples from the current posterior distribution, which is usually intractable. To circumvent this issue, approximate inference techniques can be used and provide samples with distribution close to the posteriors. However, current approximate techniques yield to either poor estimation (Laplace approximation) or can be computationally expensive (MCMC methods, Ensemble sampling...). In this paper, we propose a new algorithm, Varational Inference Thompson sampling VITS, based on Gaussian Variational Inference. This scheme provides powerful posterior approximations which are easy to sample from, and is computationally efficient, making it an ideal choice for TS. In addition, we show that VITS achieves a sub-linear regret bound of the same order in the dimension and number of round as traditional TS for linear contextual bandit. Finally, we 
&lt;/p&gt;</description></item><item><title>MALIBO&#26159;&#19968;&#31181;&#20803;&#23398;&#20064;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#30452;&#25509;&#23398;&#20064;&#36328;&#20219;&#21153;&#30340;&#26597;&#35810;&#25928;&#29992;&#65292;&#24182;&#24341;&#20837;&#36741;&#21161;&#27169;&#22411;&#20197;&#23454;&#29616;&#23545;&#26032;&#20219;&#21153;&#30340;&#31283;&#20581;&#36866;&#24212;&#65292;&#20811;&#26381;&#20102;&#29616;&#26377;&#26041;&#27861;&#30340;&#21487;&#20280;&#32553;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#30340;&#38480;&#21046;&#12290;</title><link>http://arxiv.org/abs/2307.03565</link><description>&lt;p&gt;
MALIBO: &#20803;&#23398;&#20064;&#24212;&#29992;&#20110;&#26080;&#20284;&#28982;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
MALIBO: Meta-learning for Likelihood-free Bayesian Optimization. (arXiv:2307.03565v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.03565
&lt;/p&gt;
&lt;p&gt;
MALIBO&#26159;&#19968;&#31181;&#20803;&#23398;&#20064;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#36890;&#36807;&#30452;&#25509;&#23398;&#20064;&#36328;&#20219;&#21153;&#30340;&#26597;&#35810;&#25928;&#29992;&#65292;&#24182;&#24341;&#20837;&#36741;&#21161;&#27169;&#22411;&#20197;&#23454;&#29616;&#23545;&#26032;&#20219;&#21153;&#30340;&#31283;&#20581;&#36866;&#24212;&#65292;&#20811;&#26381;&#20102;&#29616;&#26377;&#26041;&#27861;&#30340;&#21487;&#20280;&#32553;&#24615;&#21644;&#19981;&#30830;&#23450;&#24615;&#30340;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#26159;&#19968;&#31181;&#20248;&#21270;&#26114;&#36149;&#40657;&#30418;&#20989;&#25968;&#30340;&#27969;&#34892;&#26041;&#27861;&#12290;&#20256;&#32479;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#20250;&#20174;&#22836;&#24320;&#22987;&#20248;&#21270;&#27599;&#20010;&#26032;&#30340;&#30446;&#26631;&#20219;&#21153;&#65292;&#32780;&#20803;&#23398;&#20064;&#21017;&#26159;&#21033;&#29992;&#30456;&#20851;&#20219;&#21153;&#30340;&#30693;&#35782;&#26469;&#26356;&#24555;&#22320;&#20248;&#21270;&#26032;&#20219;&#21153;&#30340;&#19968;&#31181;&#26041;&#24335;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#20803;&#23398;&#20064;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#20381;&#36182;&#20110;&#26631;&#20934;&#27169;&#22411;&#65292;&#36825;&#20123;&#27169;&#22411;&#23384;&#22312;&#21487;&#20280;&#32553;&#24615;&#38382;&#39064;&#65292;&#24182;&#19988;&#23545;&#19981;&#21516;&#20219;&#21153;&#20043;&#38388;&#35266;&#23519;&#25968;&#25454;&#30340;&#23610;&#24230;&#21644;&#22122;&#22768;&#31867;&#22411;&#38750;&#24120;&#25935;&#24863;&#12290;&#27492;&#22806;&#65292;&#23427;&#20204;&#24120;&#24120;&#24573;&#35270;&#19982;&#20219;&#21153;&#30456;&#20284;&#24615;&#30456;&#20851;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#36825;&#23548;&#33268;&#22312;&#20165;&#26377;&#26377;&#38480;&#35266;&#23519;&#25968;&#25454;&#25110;&#26032;&#20219;&#21153;&#19982;&#30456;&#20851;&#20219;&#21153;&#24046;&#24322;&#26174;&#33879;&#26102;&#65292;&#20219;&#21153;&#36866;&#24212;&#24615;&#19981;&#21487;&#38752;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38480;&#21046;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#20803;&#23398;&#20064;&#36125;&#21494;&#26031;&#20248;&#21270;&#26041;&#27861;&#65292;&#26088;&#22312;&#32469;&#24320;&#26631;&#20934;&#27169;&#22411;&#65292;&#30452;&#25509;&#23398;&#20064;&#36328;&#20219;&#21153;&#30340;&#26597;&#35810;&#25928;&#29992;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#26126;&#30830;&#24314;&#27169;&#20219;&#21153;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#24341;&#20837;&#20102;&#19968;&#20010;&#36741;&#21161;&#27169;&#22411;&#65292;&#20351;&#20854;&#33021;&#22815;&#23545;&#26032;&#20219;&#21153;&#36827;&#34892;&#31283;&#20581;&#36866;&#24212;&#12290;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian optimization (BO) is a popular method to optimize costly black-box functions. While traditional BO optimizes each new target task from scratch, meta-learning has emerged as a way to leverage knowledge from related tasks to optimize new tasks faster. However, existing meta-learning BO methods rely on surrogate models that suffer from scalability issues and are sensitive to observations with different scales and noise types across tasks. Moreover, they often overlook the uncertainty associated with task similarity. This leads to unreliable task adaptation when only limited observations are obtained or when the new tasks differ significantly from the related tasks. To address these limitations, we propose a novel meta-learning BO approach that bypasses the surrogate model and directly learns the utility of queries across tasks. Our method explicitly models task uncertainty and includes an auxiliary model to enable robust adaptation to new tasks. Extensive experiments show that ou
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#39640;&#27010;&#29575;PAC-Bayes&#30028;&#38480;&#65292;&#22312;&#26377;&#30028;&#21644;&#19968;&#33324;&#23614;&#37096;&#34892;&#20026;&#30340;&#25439;&#22833;&#20013;&#22343;&#36866;&#29992;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#30028;&#38480;&#36824;&#33021;&#22815;&#20445;&#25345;&#38543;&#26102;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.12214</link><description>&lt;p&gt;
&#26356;&#22810;&#30340;PAC-Bayes Bounds&#65306;&#20174;&#26377;&#30028;&#25439;&#22833;&#21040;&#20855;&#26377;&#19968;&#33324;&#24615;&#23614;&#37096;&#34892;&#20026;&#30340;&#25439;&#22833;&#65292;&#21040;&#20219;&#20309;&#26102;&#38388;&#22343;&#26377;&#25928;&#30340;&#25439;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;
More PAC-Bayes bounds: From bounded losses, to losses with general tail behaviors, to anytime-validity. (arXiv:2306.12214v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.12214
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#39640;&#27010;&#29575;PAC-Bayes&#30028;&#38480;&#65292;&#22312;&#26377;&#30028;&#21644;&#19968;&#33324;&#23614;&#37096;&#34892;&#20026;&#30340;&#25439;&#22833;&#20013;&#22343;&#36866;&#29992;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#30028;&#38480;&#36824;&#33021;&#22815;&#20445;&#25345;&#38543;&#26102;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#19981;&#21516;&#31867;&#22411;&#30340;&#25439;&#22833;&#25552;&#20986;&#20102;&#26032;&#30340;&#39640;&#27010;&#29575;PAC-Bayes&#30028;&#38480;&#12290;&#39318;&#20808;&#65292;&#38024;&#23545;&#26377;&#30028;&#33539;&#22260;&#30340;&#25439;&#22833;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;Catoni&#30028;&#30340;&#21152;&#24378;&#29256;&#26412;&#65292;&#36866;&#29992;&#20110;&#25152;&#26377;&#21442;&#25968;&#20540;&#30340;&#32479;&#19968;&#30028;&#12290;&#36825;&#23548;&#33268;&#20102;&#26032;&#30340;&#24555;&#36895;&#36895;&#29575;&#21644;&#28151;&#21512;&#36895;&#29575;&#19978;&#38480;&#65292;&#36825;&#20123;&#19978;&#38480;&#21487;&#35299;&#37322;&#24615;&#24378;&#19988;&#27604;&#25991;&#29486;&#20013;&#20808;&#21069;&#30028;&#38480;&#26356;&#32039;&#12290;&#20854;&#27425;&#65292;&#38024;&#23545;&#26356;&#19968;&#33324;&#30340;&#23614;&#37096;&#34892;&#20026;&#30340;&#25439;&#22833;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#20004;&#20010;&#26032;&#30340;&#26080;&#21442;&#25968;&#19978;&#38480;&#65306;&#24403;&#25439;&#22833;&#30340;&#32047;&#31215;&#29983;&#25104;&#20989;&#25968;&#26377;&#30028;&#26102;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;PAC-Bayes Chernoff&#31867;&#27604;&#65292;&#21478;&#19968;&#20010;&#19978;&#38480;&#26159;&#25439;&#22833;&#30340;&#20108;&#38454;&#30697;&#26377;&#30028;&#12290;&#36825;&#20004;&#20010;&#19978;&#38480;&#26159;&#21033;&#29992;&#19968;&#31181;&#22522;&#20110;&#21487;&#33021;&#20107;&#20214;&#31354;&#38388;&#30340;&#31163;&#25955;&#21270;&#30340;&#26032;&#25216;&#26415;&#33719;&#24471;&#30340;&#65292;&#8220;&#22312;&#27010;&#29575;&#8221;&#21442;&#25968;&#20248;&#21270;&#38382;&#39064;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20351;&#29992;&#19968;&#31181;&#36866;&#29992;&#20110;&#20219;&#20309;&#29616;&#26377;&#30028;&#38480;&#30340;&#31616;&#21333;&#25216;&#26415;&#23558;&#25152;&#26377;&#20808;&#21069;&#32467;&#26524;&#25193;&#23637;&#21040;&#20219;&#20309;&#26102;&#38388;&#26377;&#25928;&#30340;&#19978;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we present new high-probability PAC-Bayes bounds for different types of losses. Firstly, for losses with a bounded range, we present a strengthened version of Catoni's bound that holds uniformly for all parameter values. This leads to new fast rate and mixed rate bounds that are interpretable and tighter than previous bounds in the literature. Secondly, for losses with more general tail behaviors, we introduce two new parameter-free bounds: a PAC-Bayes Chernoff analogue when the loss' cumulative generating function is bounded, and a bound when the loss' second moment is bounded. These two bounds are obtained using a new technique based on a discretization of the space of possible events for the "in probability" parameter optimization problem. Finally, we extend all previous results to anytime-valid bounds using a simple technique applicable to any existing bound.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#21487;&#20197;&#26377;&#25928;&#32416;&#27491;&#25968;&#25454;&#20559;&#24046;&#21644;&#20132;&#21449;&#20559;&#24046;&#30340;&#23398;&#20064;&#26041;&#27861;&#65292;&#24182;&#26500;&#36896;&#20102;&#19968;&#20010;&#37325;&#26032;&#21152;&#26435;&#26041;&#26696;&#65292;&#21487;&#20197;&#31934;&#30830;&#35780;&#20272;&#20219;&#20309;&#20551;&#35774;&#22312;&#30495;&#23454;&#20998;&#24067;&#19978;&#30340;&#25439;&#22833;&#12290;</title><link>http://arxiv.org/abs/2306.11112</link><description>&lt;p&gt;
&#32416;&#27491;&#20844;&#24179;&#20998;&#31867;&#20013;&#30340;&#20302;&#20272;&#20559;&#24046;&#21644;&#20132;&#21449;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
Correcting Underrepresentation and Intersectional Bias for Fair Classification. (arXiv:2306.11112v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11112
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#21487;&#20197;&#26377;&#25928;&#32416;&#27491;&#25968;&#25454;&#20559;&#24046;&#21644;&#20132;&#21449;&#20559;&#24046;&#30340;&#23398;&#20064;&#26041;&#27861;&#65292;&#24182;&#26500;&#36896;&#20102;&#19968;&#20010;&#37325;&#26032;&#21152;&#26435;&#26041;&#26696;&#65292;&#21487;&#20197;&#31934;&#30830;&#35780;&#20272;&#20219;&#20309;&#20551;&#35774;&#22312;&#30495;&#23454;&#20998;&#24067;&#19978;&#30340;&#25439;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#23398;&#20064;&#34987;&#20302;&#20272;&#20559;&#24046;&#25439;&#22351;&#30340;&#25968;&#25454;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#27491;&#20363;&#22312;&#22266;&#23450;&#25968;&#37327;&#30340;&#25935;&#24863;&#32452;&#20013;&#20197;&#19981;&#21516;&#30340;&#26410;&#30693;&#36895;&#29575;&#20174;&#25968;&#25454;&#20013;&#36807;&#28388;&#25481;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#22312;&#26377;&#23569;&#37327;&#26080;&#20559;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#21487;&#20197;&#26377;&#25928;&#22320;&#20272;&#35745;&#27599;&#20010;&#32452;&#30340;&#20943;&#23569;&#21442;&#25968;&#65292;&#21363;&#20351;&#22312;&#20132;&#21449;&#32452;&#25104;&#21592;&#36164;&#26684;&#20351;&#24471;&#23398;&#20064;&#27599;&#20010;&#20132;&#21449;&#29575;&#21464;&#24471;&#35745;&#31639;&#19978;&#19981;&#21487;&#34892;&#30340;&#24773;&#20917;&#19979;&#12290;&#21033;&#29992;&#36825;&#20010;&#20998;&#32452;&#20002;&#22833;&#29575;&#30340;&#20272;&#35745;&#65292;&#25105;&#20204;&#26500;&#36896;&#20102;&#19968;&#20010;&#37325;&#26032;&#21152;&#26435;&#26041;&#26696;&#65292;&#21487;&#20197;&#20351;&#25105;&#20204;&#36817;&#20284;&#35780;&#20272;&#20219;&#20309;&#20551;&#35774;&#22312;&#30495;&#23454;&#20998;&#24067;&#19978;&#30340;&#25439;&#22833;&#65292;&#21363;&#20351;&#25105;&#20204;&#21482;&#33021;&#22312;&#19968;&#20010;&#26377;&#20559;&#26679;&#26412;&#19978;&#35266;&#23519;&#21040;&#32463;&#39564;&#35823;&#24046;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#23553;&#35013;&#20102;&#36825;&#20010;&#23398;&#20064;&#21644;&#37325;&#26032;&#21152;&#26435;&#36807;&#31243;&#30340;&#31639;&#27861;&#65292;&#24182;&#25552;&#20379;&#20102;&#24378;PAC&#39118;&#26684;&#30340;&#20445;&#35777;&#65292;&#21363;&#26377;&#24456;&#39640;&#30340;&#27010;&#29575;&#25105;&#20204;&#23545;&#20551;&#35774;&#22312;&#30495;&#23454;&#20998;&#24067;&#19978;&#30340;&#39118;&#38505;&#30340;&#20272;&#35745;&#23558;&#19982;&#30495;&#23454;&#39118;&#38505;&#20219;&#24847;&#25509;&#36817;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of learning from data corrupted by underrepresentation bias, where positive examples are filtered from the data at different, unknown rates for a fixed number of sensitive groups. We show that with a small amount of unbiased data, we can efficiently estimate the group-wise drop-out parameters, even in settings where intersectional group membership makes learning each intersectional rate computationally infeasible. Using this estimate for the group-wise drop-out rate, we construct a re-weighting scheme that allows us to approximate the loss of any hypothesis on the true distribution, even if we only observe the empirical error on a biased sample. Finally, we present an algorithm encapsulating this learning and re-weighting process, and we provide strong PAC-style guarantees that, with high probability, our estimate of the risk of the hypothesis over the true distribution will be arbitrarily close to the true risk.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25581;&#31034;&#20102;&#23618;&#38388;&#21453;&#39304;&#23545;&#40784;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#20445;&#23432;&#24615;&#65292;&#24182;&#21457;&#29616;FA&#19982;GD&#20043;&#38388;&#23384;&#22312;&#38544;&#24335;&#20559;&#24046;&#30340;&#30456;&#20284;&#20043;&#22788;&#65292;&#21516;&#26102;&#38416;&#26126;&#20102;ReLU&#32593;&#32476;&#20013;&#19982;&#21453;&#39304;&#30697;&#38453;&#23545;&#40784;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;</title><link>http://arxiv.org/abs/2306.01870</link><description>&lt;p&gt;
&#23618;&#38388;&#21453;&#39304;&#23545;&#40784;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#20445;&#23432;&#24615;
&lt;/p&gt;
&lt;p&gt;
Layer-Wise Feedback Alignment is Conserved in Deep Neural Networks. (arXiv:2306.01870v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.01870
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25581;&#31034;&#20102;&#23618;&#38388;&#21453;&#39304;&#23545;&#40784;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#20445;&#23432;&#24615;&#65292;&#24182;&#21457;&#29616;FA&#19982;GD&#20043;&#38388;&#23384;&#22312;&#38544;&#24335;&#20559;&#24046;&#30340;&#30456;&#20284;&#20043;&#22788;&#65292;&#21516;&#26102;&#38416;&#26126;&#20102;ReLU&#32593;&#32476;&#20013;&#19982;&#21453;&#39304;&#30697;&#38453;&#23545;&#40784;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#25552;&#39640;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#25928;&#29575;&#21644;&#29983;&#29289;&#21487;&#22609;&#24615;&#65292;&#21453;&#39304;&#23545;&#40784;&#65288;FA&#65289;&#20316;&#20026;&#20256;&#32479;&#21453;&#21521;&#20256;&#25773;&#30340;&#26367;&#20195;&#26041;&#27861;&#24212;&#36816;&#32780;&#29983;&#65292;&#23427;&#23558;&#35757;&#32451;&#36807;&#31243;&#20013;&#30340;&#21453;&#21521;&#20256;&#36755;&#26435;&#37325;&#26367;&#25442;&#20026;&#38543;&#26426;&#30697;&#38453;&#12290;&#34429;&#28982;FA&#30340;&#21560;&#24341;&#21147;&#22312;&#20110;&#23427;&#33021;&#22815;&#32469;&#36807;&#35745;&#31639;&#25361;&#25112;&#21644;&#20854;&#21487;&#20449;&#30340;&#29983;&#29289;&#23545;&#40784;&#24615;&#65292;&#20294;&#23545;&#20110;&#36825;&#31181;&#23398;&#20064;&#35268;&#21017;&#30340;&#29702;&#35299;&#36824;&#26159;&#26377;&#25152;&#27424;&#32570;&#30340;&#12290;&#26412;&#25991;&#25581;&#31034;&#20102;&#25903;&#25745;FA&#23398;&#20064;&#21160;&#24577;&#30340;&#19968;&#32452;&#23432;&#24658;&#23450;&#24459;&#65292;&#25581;&#31034;&#20102;FA&#21644;&#26799;&#24230;&#19979;&#38477;&#65288;GD&#65289;&#20043;&#38388;&#30340;&#26377;&#36259;&#30456;&#20284;&#20043;&#22788;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#34920;&#26126;&#65292;FA&#20855;&#26377;&#19982;GD&#34920;&#29616;&#20986;&#30340;&#38544;&#24335;&#20559;&#24046;&#30456;&#20284;&#30340;&#38544;&#24335;&#20559;&#24046;&#65292;&#25361;&#25112;&#20102;&#29616;&#26377;&#30340;&#36825;&#20123;&#23398;&#20064;&#31639;&#27861;&#20043;&#38388;&#26681;&#26412;&#19981;&#21516;&#30340;&#27969;&#34892;&#35828;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#65292;&#36825;&#20123;&#23432;&#24658;&#23450;&#24459;&#38416;&#26126;&#20102;ReLU&#32593;&#32476;&#20013;&#19982;&#21453;&#39304;&#30697;&#38453;&#23545;&#40784;&#30340;&#20805;&#20998;&#26465;&#20214;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#23637;&#31034;&#65292;&#36825;&#24847;&#21619;&#30528;&#36807;&#21442;&#25968;&#21270;&#30340;&#21452;&#32447;&#24615;&#32593;&#32476;&#20013;&#21487;&#20197;&#23454;&#29616;&#32447;&#24615;&#22320;&#20195;&#26367;&#21518;&#21521;&#26435;&#37325;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the quest to enhance the efficiency and bio-plausibility of training deep neural networks, Feedback Alignment (FA), which replaces the backward pass weights with random matrices in the training process, has emerged as an alternative to traditional backpropagation. While the appeal of FA lies in its circumvention of computational challenges and its plausible biological alignment, the theoretical understanding of this learning rule remains partial. This paper uncovers a set of conservation laws underpinning the learning dynamics of FA, revealing intriguing parallels between FA and Gradient Descent (GD). Our analysis reveals that FA harbors implicit biases akin to those exhibited by GD, challenging the prevailing narrative that these learning algorithms are fundamentally different. Moreover, we demonstrate that these conservation laws elucidate sufficient conditions for layer-wise alignment with feedback matrices in ReLU networks. We further show that this implies over-parameterized tw
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#25968;&#23398;&#20998;&#26512;&#35777;&#26126;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#24182;&#19981;&#33021;&#35299;&#20915;&#24179;&#28369;&#36807;&#24230;&#38382;&#39064;&#65292;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#38656;&#35201;&#26356;&#22810;&#20851;&#27880;&#19981;&#23545;&#31216;&#12289;&#29366;&#24577;&#30456;&#20851;&#21644;&#26377;&#21521;&#22270;&#32467;&#26500;&#12290;</title><link>http://arxiv.org/abs/2305.16102</link><description>&lt;p&gt;
&#25581;&#31034;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#24179;&#28369;&#36807;&#24230;&#29616;&#35937;
&lt;/p&gt;
&lt;p&gt;
Demystifying Oversmoothing in Attention-Based Graph Neural Networks. (arXiv:2305.16102v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16102
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#25968;&#23398;&#20998;&#26512;&#35777;&#26126;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#24182;&#19981;&#33021;&#35299;&#20915;&#24179;&#28369;&#36807;&#24230;&#38382;&#39064;&#65292;&#22312;&#23454;&#38469;&#24212;&#29992;&#20013;&#38656;&#35201;&#26356;&#22810;&#20851;&#27880;&#19981;&#23545;&#31216;&#12289;&#29366;&#24577;&#30456;&#20851;&#21644;&#26377;&#21521;&#22270;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#24179;&#28369;&#36807;&#24230;&#25351;&#30340;&#26159;&#22686;&#21152;&#32593;&#32476;&#28145;&#24230;&#23548;&#33268;&#33410;&#28857;&#34920;&#31034;&#21464;&#24471;&#30456;&#21516;&#30340;&#29616;&#35937;&#12290;&#23613;&#31649;&#20043;&#21069;&#30340;&#30740;&#31350;&#24050;&#32463;&#35777;&#23454;&#20102;&#22270;&#21367;&#31215;&#32593;&#32476;(GCN)&#20250;&#25351;&#25968;&#32423;&#22833;&#21435;&#34920;&#36798;&#33021;&#21147;&#65292;&#20294;&#26159;&#22270;&#27880;&#24847;&#21147;&#26426;&#21046;&#26159;&#21542;&#21487;&#20197;&#32531;&#35299;&#24179;&#28369;&#36807;&#24230;&#38382;&#39064;&#36824;&#23384;&#22312;&#20105;&#35758;&#12290;&#26412;&#25991;&#36890;&#36807;&#23558;&#22522;&#20110;&#27880;&#24847;&#21147;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#35270;&#20026;&#38750;&#32447;&#24615;&#26102;&#21464;&#21160;&#24577;&#31995;&#32479;&#65292;&#24182;&#32467;&#21512;&#38750;&#40784;&#27425;&#30697;&#38453;&#20056;&#31215;&#21644;&#32852;&#21512;&#35889;&#21322;&#24452;&#29702;&#35770;&#30340;&#24037;&#20855;&#21644;&#25216;&#26415;&#65292;&#23545;&#36825;&#20010;&#38382;&#39064;&#36827;&#34892;&#20102;&#20005;&#26684;&#30340;&#25968;&#23398;&#20998;&#26512;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#26126;&#30830;&#30340;&#31572;&#26696;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#19982;&#27969;&#34892;&#35266;&#28857;&#30456;&#21453;&#65292;&#22270;&#27880;&#24847;&#21147;&#26426;&#21046;&#19981;&#33021;&#38450;&#27490;&#24179;&#28369;&#36807;&#24230;&#29616;&#35937;&#65292;&#24182;&#19988;&#21576;&#25351;&#25968;&#32423;&#22833;&#21435;&#34920;&#36798;&#33021;&#21147;&#12290;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#23558;&#23545;&#31216;GCN&#30340;&#24179;&#28369;&#36807;&#24230;&#38382;&#39064;&#25193;&#23637;&#21040;&#20102;&#26356;&#24191;&#27867;&#30340;GNN&#27169;&#22411;&#31867;&#21035;&#20013;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#32771;&#34385;&#20102;&#22312;&#29616;&#23454;&#24212;&#29992;&#20013;&#26222;&#36941;&#23384;&#22312;&#30340;&#19981;&#23545;&#31216;&#12289;&#29366;&#24577;&#30456;&#20851;&#21644;&#26377;&#21521;&#22270;&#32467;&#26500;&#12290;
&lt;/p&gt;
&lt;p&gt;
Oversmoothing in Graph Neural Networks (GNNs) refers to the phenomenon where increasing network depth leads to homogeneous node representations. While previous work has established that Graph Convolutional Networks (GCNs) exponentially lose expressive power, it remains controversial whether the graph attention mechanism can mitigate oversmoothing. In this work, we provide a definitive answer to this question through a rigorous mathematical analysis, by viewing attention-based GNNs as nonlinear time-varying dynamical systems and incorporating tools and techniques from the theory of products of inhomogeneous matrices and the joint spectral radius. We establish that, contrary to popular belief, the graph attention mechanism cannot prevent oversmoothing and loses expressive power exponentially. The proposed framework extends the existing results on oversmoothing for symmetric GCNs to a significantly broader class of GNN models. In particular, our analysis accounts for asymmetric, state-dep
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#39532;&#23572;&#31185;&#22827;&#36716;&#25442;&#27169;&#22411;&#30340;&#21487;&#36776;&#35782;&#24615;&#65292;&#36890;&#36807;&#38750;&#32447;&#24615;&#39640;&#26031;&#21442;&#25968;&#21270;&#36801;&#31227;&#20998;&#24067;&#23454;&#29616;&#31532;&#19968;&#38454;&#27573;&#39532;&#23572;&#31185;&#22827;&#20381;&#36182;&#32467;&#26500;&#20013;&#30340;&#21487;&#36776;&#35782;&#24615;&#26465;&#20214;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#20381;&#36182;&#20110;&#25919;&#26435;&#30340;&#22240;&#26524;&#21457;&#29616;&#21644;&#39640;&#32500;&#26102;&#38388;&#24207;&#21015;&#20998;&#21106;&#12290;</title><link>http://arxiv.org/abs/2305.15925</link><description>&lt;p&gt;
&#20851;&#20110;&#39532;&#23572;&#31185;&#22827;&#36716;&#25442;&#27169;&#22411;&#30340;&#21487;&#36776;&#35782;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Identifiability of Markov Switching Models. (arXiv:2305.15925v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15925
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#39532;&#23572;&#31185;&#22827;&#36716;&#25442;&#27169;&#22411;&#30340;&#21487;&#36776;&#35782;&#24615;&#65292;&#36890;&#36807;&#38750;&#32447;&#24615;&#39640;&#26031;&#21442;&#25968;&#21270;&#36801;&#31227;&#20998;&#24067;&#23454;&#29616;&#31532;&#19968;&#38454;&#27573;&#39532;&#23572;&#31185;&#22827;&#20381;&#36182;&#32467;&#26500;&#20013;&#30340;&#21487;&#36776;&#35782;&#24615;&#26465;&#20214;&#12290;&#35813;&#26041;&#27861;&#36866;&#29992;&#20110;&#20381;&#36182;&#20110;&#25919;&#26435;&#30340;&#22240;&#26524;&#21457;&#29616;&#21644;&#39640;&#32500;&#26102;&#38388;&#24207;&#21015;&#20998;&#21106;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#21487;&#36776;&#35782;&#24615;&#22240;&#20854;&#22312;&#21487;&#35299;&#37322;&#24615;&#25110;&#20998;&#24067;&#27867;&#21270;&#26041;&#38754;&#30340;&#24212;&#29992;&#32780;&#22791;&#21463;&#20851;&#27880;&#12290;&#26412;&#25991;&#25506;&#35752;&#20102;&#20316;&#20026;&#23558;&#26368;&#36817;&#30340;&#32467;&#26524;&#25193;&#23637;&#21040;&#24207;&#21015;&#28508;&#21464;&#37327;&#27169;&#22411;&#30340;&#31532;&#19968;&#27493;&#30340;&#39532;&#23572;&#31185;&#22827;&#36716;&#25442;&#27169;&#22411;&#30340;&#21487;&#36776;&#35782;&#24615;&#12290;&#25105;&#20204;&#22312;&#31532;&#19968;&#38454;&#27573;&#39532;&#23572;&#31185;&#22827;&#20381;&#36182;&#32467;&#26500;&#20013;&#25552;&#20986;&#20102;&#21487;&#36776;&#35782;&#24615;&#26465;&#20214;&#65292;&#24182;&#36890;&#36807;&#38750;&#32447;&#24615;&#39640;&#26031;&#21442;&#25968;&#21270;&#36801;&#31227;&#20998;&#24067;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#22312;&#20381;&#36182;&#20110;&#25919;&#26435;&#30340;&#22240;&#26524;&#21457;&#29616;&#21644;&#39640;&#32500;&#26102;&#38388;&#24207;&#21015;&#20998;&#21106;&#26041;&#38754;&#30340;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Identifiability of latent variable models has recently gained interest in terms of its applications to interpretability or out of distribution generalisation. In this work, we study identifiability of Markov Switching Models as a first step towards extending recent results to sequential latent variable models. We present identifiability conditions within first-order Markov dependency structures, and parametrise the transition distribution via non-linear Gaussians. Our experiments showcase the applicability of our approach for regime-dependent causal discovery and high-dimensional time series segmentation.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;L2&#65292;0&#22522;&#25968;&#24809;&#32602;&#30340;&#22270;&#36235;&#21183;&#36807;&#28388;&#65288;GTF&#65289;&#27169;&#22411;&#65292;&#21487;&#21516;&#26102;&#36827;&#34892;k-means&#32858;&#31867;&#21644;&#22522;&#20110;&#22270;&#30340;&#26368;&#23567;&#21106;&#65292;&#20197;&#20272;&#35745;&#22312;&#33410;&#28857;&#20043;&#38388;&#20855;&#26377;&#19981;&#22343;&#21248;&#24179;&#28369;&#27700;&#24179;&#30340;&#20998;&#27573;&#24179;&#28369;&#22270;&#20449;&#21495;&#65292;&#24182;&#22312;&#38477;&#22122;&#12289;&#25903;&#25345;&#24674;&#22797;&#21644;&#21322;&#30417;&#30563;&#20998;&#31867;&#20219;&#21153;&#19978;&#34920;&#29616;&#26356;&#22909;&#65292;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#39640;&#25928;&#22320;&#22788;&#29702;&#22823;&#22411;&#25968;&#25454;&#38598;&#12290;</title><link>http://arxiv.org/abs/2304.05223</link><description>&lt;p&gt;
&#22522;&#20110;L2&#65292;0&#22522;&#25968;&#24809;&#32602;&#30340;&#19981;&#22343;&#21248;&#22270;&#36235;&#21183;&#36807;&#28388;&#12290;
&lt;/p&gt;
&lt;p&gt;
Inhomogeneous graph trend filtering via a l2,0 cardinality penalty. (arXiv:2304.05223v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05223
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;L2&#65292;0&#22522;&#25968;&#24809;&#32602;&#30340;&#22270;&#36235;&#21183;&#36807;&#28388;&#65288;GTF&#65289;&#27169;&#22411;&#65292;&#21487;&#21516;&#26102;&#36827;&#34892;k-means&#32858;&#31867;&#21644;&#22522;&#20110;&#22270;&#30340;&#26368;&#23567;&#21106;&#65292;&#20197;&#20272;&#35745;&#22312;&#33410;&#28857;&#20043;&#38388;&#20855;&#26377;&#19981;&#22343;&#21248;&#24179;&#28369;&#27700;&#24179;&#30340;&#20998;&#27573;&#24179;&#28369;&#22270;&#20449;&#21495;&#65292;&#24182;&#22312;&#38477;&#22122;&#12289;&#25903;&#25345;&#24674;&#22797;&#21644;&#21322;&#30417;&#30563;&#20998;&#31867;&#20219;&#21153;&#19978;&#34920;&#29616;&#26356;&#22909;&#65292;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#39640;&#25928;&#22320;&#22788;&#29702;&#22823;&#22411;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#22312;&#22270;&#19978;&#20272;&#35745;&#20998;&#27573;&#24179;&#28369;&#20449;&#21495;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;$\ell_{2,0}$-&#33539;&#25968;&#24809;&#32602;&#22270;&#36235;&#21183;&#36807;&#28388;&#65288;GTF&#65289;&#27169;&#22411;&#65292;&#20197;&#20272;&#35745;&#22312;&#33410;&#28857;&#20043;&#38388;&#20855;&#26377;&#19981;&#22343;&#21248;&#24179;&#28369;&#27700;&#24179;&#30340;&#20998;&#27573;&#24179;&#28369;&#22270;&#20449;&#21495;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;GTF&#27169;&#22411;&#21516;&#26102;&#26159;&#22522;&#20110;&#33410;&#28857;&#19978;&#30340;&#20449;&#21495;&#30340;k-means&#32858;&#31867;&#21644;&#22522;&#20110;&#22270;&#30340;&#26368;&#23567;&#21106;&#65292;&#20854;&#20013;&#32858;&#31867;&#21644;&#21106;&#20849;&#20139;&#30456;&#21516;&#30340;&#20998;&#37197;&#30697;&#38453;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26041;&#27861;&#26469;&#35299;&#20915;&#25152;&#25552;&#20986;&#30340;GTF&#27169;&#22411;&#65306;&#19968;&#31181;&#26159;&#22522;&#20110;&#35889;&#20998;&#35299;&#30340;&#26041;&#27861;&#65292;&#21478;&#19968;&#31181;&#26159;&#22522;&#20110;&#27169;&#25311;&#36864;&#28779;&#30340;&#26041;&#27861;&#12290;&#22312;&#21512;&#25104;&#21644;&#29616;&#23454;&#25968;&#25454;&#38598;&#30340;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;GTF&#27169;&#22411;&#22312;&#38477;&#22122;&#12289;&#25903;&#25345;&#24674;&#22797;&#21644;&#21322;&#30417;&#30563;&#20998;&#31867;&#20219;&#21153;&#19978;&#34920;&#29616;&#26356;&#22909;&#65292;&#19988;&#27604;&#29616;&#26377;&#26041;&#27861;&#26356;&#39640;&#25928;&#22320;&#35299;&#20915;&#20102;&#22823;&#22411;&#25968;&#25454;&#38598;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study estimation of piecewise smooth signals over a graph. We propose a $\ell_{2,0}$-norm penalized Graph Trend Filtering (GTF) model to estimate piecewise smooth graph signals that exhibits inhomogeneous levels of smoothness across the nodes. We prove that the proposed GTF model is simultaneously a k-means clustering on the signal over the nodes and a minimum graph cut on the edges of the graph, where the clustering and the cut share the same assignment matrix. We propose two methods to solve the proposed GTF model: a spectral decomposition method and a method based on simulated annealing. In the experiment on synthetic and real-world datasets, we show that the proposed GTF model has a better performances compared with existing approaches on the tasks of denoising, support recovery and semi-supervised classification. We also show that the proposed GTF model can be solved more efficiently than existing models for the dataset with a large edge set.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21327;&#21516;&#22270;&#34701;&#21512;&#30340;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22788;&#29702;&#20855;&#26377;&#20849;&#21516;&#39030;&#28857;&#38598;&#30340;&#22810;&#20010;&#22270;&#65292;&#26377;&#30528;&#38750;&#24120;&#29702;&#24819;&#30340;&#8220;&#21327;&#21516;&#25928;&#24212;&#8221;&#65292;&#21363;&#39030;&#28857;&#20998;&#31867;&#20934;&#30830;&#24230;&#24635;&#26159;&#21463;&#30410;&#20110;&#39069;&#22806;&#30340;&#22270;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#35777;&#23454;&#20102;&#20854;&#21331;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2303.18051</link><description>&lt;p&gt;
&#22522;&#20110;&#32534;&#30721;&#22120;&#23884;&#20837;&#30340;&#21327;&#21516;&#22270;&#34701;&#21512;
&lt;/p&gt;
&lt;p&gt;
Synergistic Graph Fusion via Encoder Embedding. (arXiv:2303.18051v1 [cs.SI])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.18051
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21327;&#21516;&#22270;&#34701;&#21512;&#30340;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22788;&#29702;&#20855;&#26377;&#20849;&#21516;&#39030;&#28857;&#38598;&#30340;&#22810;&#20010;&#22270;&#65292;&#26377;&#30528;&#38750;&#24120;&#29702;&#24819;&#30340;&#8220;&#21327;&#21516;&#25928;&#24212;&#8221;&#65292;&#21363;&#39030;&#28857;&#20998;&#31867;&#20934;&#30830;&#24230;&#24635;&#26159;&#21463;&#30410;&#20110;&#39069;&#22806;&#30340;&#22270;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#35777;&#23454;&#20102;&#20854;&#21331;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;&#22270;&#34701;&#21512;&#32534;&#30721;&#22120;&#23884;&#20837;&#30340;&#22810;&#22270;&#23884;&#20837;&#26032;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#26088;&#22312;&#22788;&#29702;&#20855;&#26377;&#20849;&#21516;&#39030;&#28857;&#38598;&#30340;&#22810;&#20010;&#22270;&#12290;&#22312;&#30417;&#30563;&#23398;&#20064;&#35774;&#32622;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#23637;&#29616;&#20986;&#20102;&#20196;&#20154;&#24778;&#21497;&#20294;&#38750;&#24120;&#29702;&#24819;&#30340;&#8220;&#21327;&#21516;&#25928;&#24212;&#8221;&#65306;&#23545;&#20110;&#36275;&#22815;&#22823;&#30340;&#39030;&#28857;&#25968;&#65292;&#20998;&#31867;&#20934;&#30830;&#24230;&#24635;&#26159;&#21463;&#30410;&#20110;&#39069;&#22806;&#30340;&#22270;&#12290;&#25105;&#20204;&#22312;&#38543;&#26426;&#22359;&#27169;&#22411;&#19979;&#25552;&#20379;&#20102;&#36825;&#31181;&#25928;&#24212;&#30340;&#25968;&#23398;&#35777;&#26126;&#65292;&#24182;&#30830;&#23450;&#20102;&#28176;&#36817;&#23436;&#32654;&#20998;&#31867;&#30340;&#24517;&#35201;&#26465;&#20214;&#21644;&#20805;&#20998;&#26465;&#20214;&#12290;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#23454;&#39564;&#35777;&#23454;&#20102;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#21331;&#36234;&#24615;&#33021;&#65292;&#35813;&#26041;&#27861;&#22312;&#20998;&#31867;&#20013;&#22987;&#32456;&#20248;&#20110;&#26368;&#36817;&#30340;&#22522;&#20934;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we introduce a novel approach to multi-graph embedding called graph fusion encoder embedding. The method is designed to work with multiple graphs that share a common vertex set. Under the supervised learning setting, we show that the resulting embedding exhibits a surprising yet highly desirable "synergistic effect": for sufficiently large vertex size, the vertex classification accuracy always benefits from additional graphs. We provide a mathematical proof of this effect under the stochastic block model, and identify the necessary and sufficient condition for asymptotically perfect classification. The simulations and real data experiments confirm the superiority of the proposed method, which consistently outperforms recent benchmark methods in classification.
&lt;/p&gt;</description></item></channel></rss>