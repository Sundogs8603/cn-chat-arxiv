<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; HopCPT &#30340;&#26032;&#19968;&#33268;&#24615;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#26041;&#27861;&#65292;&#19981;&#20165;&#33021;&#22815;&#22788;&#29702;&#26102;&#38388;&#32467;&#26500;&#65292;&#32780;&#19988;&#33021;&#22815;&#21033;&#29992;&#20854;&#20248;&#21183;&#65292;&#24050;&#22312;&#22810;&#31181;&#30495;&#23454;&#19990;&#30028;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#19978;&#35777;&#26126;&#20102;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2303.12783</link><description>&lt;p&gt;
&#22522;&#20110;&#29616;&#20195; Hopfield &#32593;&#32476;&#30340;&#26102;&#38388;&#24207;&#21015;&#19968;&#33268;&#24615;&#39044;&#27979;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Conformal Prediction for Time Series with Modern Hopfield Networks. (arXiv:2303.12783v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.12783
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026; HopCPT &#30340;&#26032;&#19968;&#33268;&#24615;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#26041;&#27861;&#65292;&#19981;&#20165;&#33021;&#22815;&#22788;&#29702;&#26102;&#38388;&#32467;&#26500;&#65292;&#32780;&#19988;&#33021;&#22815;&#21033;&#29992;&#20854;&#20248;&#21183;&#65292;&#24050;&#22312;&#22810;&#31181;&#30495;&#23454;&#19990;&#30028;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#19978;&#35777;&#26126;&#20102;&#20248;&#20110;&#29616;&#26377;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#37327;&#21270;&#19981;&#30830;&#23450;&#24615;&#65292;&#19968;&#33268;&#24615;&#39044;&#27979;&#26041;&#27861;&#21463;&#21040;&#36234;&#26469;&#36234;&#22810;&#30340;&#20851;&#27880;&#65292;&#24182;&#24050;&#25104;&#21151;&#24212;&#29992;&#20110;&#21508;&#20010;&#39046;&#22495;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#38590;&#20197;&#24212;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#65292;&#22240;&#20026;&#26102;&#38388;&#24207;&#21015;&#30340;&#33258;&#30456;&#20851;&#32467;&#26500;&#36829;&#21453;&#20102;&#19968;&#33268;&#24615;&#39044;&#27979;&#25152;&#38656;&#30340;&#22522;&#26412;&#20551;&#35774;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102; HopCPT&#65292;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110; Hopfield &#32593;&#32476;&#30340;&#26102;&#38388;&#24207;&#21015;&#19968;&#33268;&#24615;&#39044;&#27979;&#26041;&#27861;&#65292;&#19981;&#20165;&#33021;&#22815;&#24212;&#23545;&#26102;&#38388;&#32467;&#26500;&#65292;&#32780;&#19988;&#33021;&#22815;&#21033;&#29992;&#23427;&#20204;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#23384;&#22312;&#26102;&#38388;&#20381;&#36182;&#24615;&#30340;&#26102;&#38388;&#24207;&#21015;&#20013;&#22312;&#29702;&#35770;&#19978;&#26159;&#26377;&#24456;&#22909;&#30340;&#29702;&#35770;&#22522;&#30784;&#30340;&#12290;&#22312;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26032;&#26041;&#27861;&#22312;&#22235;&#20010;&#19981;&#21516;&#39046;&#22495;&#30340;&#22810;&#20010;&#30495;&#23454;&#19990;&#30028;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#19978;&#20248;&#20110;&#29616;&#26377;&#30340;&#26368;&#20808;&#36827;&#30340;&#19968;&#33268;&#24615;&#39044;&#27979;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
To quantify uncertainty, conformal prediction methods are gaining continuously more interest and have already been successfully applied to various domains. However, they are difficult to apply to time series as the autocorrelative structure of time series violates basic assumptions required by conformal prediction. We propose HopCPT, a novel conformal prediction approach for time series that not only copes with temporal structures but leverages them. We show that our approach is theoretically well justified for time series where temporal dependencies are present. In experiments, we demonstrate that our new approach outperforms state-of-the-art conformal prediction methods on multiple real-world time series datasets from four different domains.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;&#20998;&#20301;&#25968;&#22238;&#24402;&#26862;&#26519;&#26469;&#23398;&#20064;&#38750;&#25311;&#21512;&#20998;&#25968;&#30340;&#20998;&#24067;&#65292;&#24182;&#21033;&#29992;&#20854;&#26435;&#37325;&#20998;&#37197;&#26356;&#22810;&#30340;&#37325;&#35201;&#24615;&#32473;&#27531;&#24046;&#19982;&#27979;&#35797;&#28857;&#30456;&#20284;&#30340;&#26679;&#26412;&#65292;&#20174;&#32780;&#23454;&#29616;&#26356;&#31526;&#21512;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;</title><link>http://arxiv.org/abs/2303.12695</link><description>&lt;p&gt;
&#38750;&#25311;&#21512;&#20998;&#25968;&#37325;&#26032;&#26435;&#37325;&#23454;&#29616;&#33258;&#36866;&#24212;&#19968;&#33268;&#24615;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Adaptive Conformal Prediction by Reweighting Nonconformity Score. (arXiv:2303.12695v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.12695
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#21033;&#29992;&#20998;&#20301;&#25968;&#22238;&#24402;&#26862;&#26519;&#26469;&#23398;&#20064;&#38750;&#25311;&#21512;&#20998;&#25968;&#30340;&#20998;&#24067;&#65292;&#24182;&#21033;&#29992;&#20854;&#26435;&#37325;&#20998;&#37197;&#26356;&#22810;&#30340;&#37325;&#35201;&#24615;&#32473;&#27531;&#24046;&#19982;&#27979;&#35797;&#28857;&#30456;&#20284;&#30340;&#26679;&#26412;&#65292;&#20174;&#32780;&#23454;&#29616;&#26356;&#31526;&#21512;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#30340;&#39044;&#27979;&#21306;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23613;&#31649;&#20855;&#26377;&#21560;&#24341;&#20154;&#30340;&#29702;&#35770;&#20445;&#35777;&#21644;&#23454;&#38469;&#25104;&#21151;&#65292;&#20294;&#30001;&#19968;&#33268;&#24615;&#39044;&#27979;&#65288;CP&#65289;&#32473;&#20986;&#30340;&#39044;&#27979;&#21306;&#38388;&#65288;PI&#65289;&#21487;&#33021;&#26080;&#27861;&#21453;&#26144;&#32473;&#23450;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#36825;&#31181;&#38480;&#21046;&#28304;&#20110;CP&#26041;&#27861;&#23545;&#25152;&#26377;&#27979;&#35797;&#28857;&#20351;&#29992;&#24120;&#25968;&#20462;&#27491;&#65292;&#26080;&#35270;&#23427;&#20204;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#20197;&#30830;&#20445;&#35206;&#30422;&#29305;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20351;&#29992;&#20998;&#20301;&#25968;&#22238;&#24402;&#26862;&#26519;&#65288;QRF&#65289;&#26469;&#23398;&#20064;&#38750;&#25311;&#21512;&#20998;&#25968;&#30340;&#20998;&#24067;&#65292;&#24182;&#21033;&#29992;QRF&#30340;&#26435;&#37325;&#23558;&#26356;&#22810;&#30340;&#37325;&#35201;&#24615;&#20998;&#37197;&#32473;&#27531;&#24046;&#19982;&#27979;&#35797;&#28857;&#30456;&#20284;&#30340;&#26679;&#26412;&#12290;&#36825;&#31181;&#26041;&#27861;&#23548;&#33268;&#30340;PI&#38271;&#24230;&#26356;&#31526;&#21512;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#27492;&#22806;&#65292;QRF&#23398;&#20064;&#21040;&#30340;&#26435;&#37325;&#25552;&#20379;&#20102;&#29305;&#24449;&#31354;&#38388;&#30340;&#21010;&#20998;&#65292;&#36890;&#36807;&#32452;&#21512;&#19968;&#33268;&#21270;&#21487;&#20197;&#23454;&#29616;&#26356;&#39640;&#25928;&#30340;&#35745;&#31639;&#21644;&#25913;&#36827;PI&#30340;&#36866;&#24212;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20139;&#26377;&#22522;&#20110;&#26679;&#26412;&#21644;&#22522;&#20110;&#35757;&#32451;&#26465;&#20214;&#30340;&#26080;&#20551;&#35774;&#26377;&#38480;&#35206;&#30422;&#29575;&#65292;&#24182;&#22312;&#36866;&#24403;&#30340;&#20551;&#35774;&#19979;&#65292;&#20063;&#21487;&#20197;
&lt;/p&gt;
&lt;p&gt;
Despite attractive theoretical guarantees and practical successes, Predictive Interval (PI) given by Conformal Prediction (CP) may not reflect the uncertainty of a given model. This limitation arises from CP methods using a constant correction for all test points, disregarding their individual uncertainties, to ensure coverage properties. To address this issue, we propose using a Quantile Regression Forest (QRF) to learn the distribution of nonconformity scores and utilizing the QRF's weights to assign more importance to samples with residuals similar to the test point. This approach results in PI lengths that are more aligned with the model's uncertainty. In addition, the weights learnt by the QRF provide a partition of the features space, allowing for more efficient computations and improved adaptiveness of the PI through groupwise conformalization. Our approach enjoys an assumption-free finite sample marginal and training-conditional coverage, and under suitable assumptions, it also
&lt;/p&gt;</description></item><item><title>EDGI&#26159;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#21644;&#35268;&#21010;&#31639;&#27861;&#65292;&#36890;&#36807;&#31561;&#21464;&#25193;&#25955;&#22788;&#29702;&#20869;&#22312;&#23545;&#31216;&#24615;&#65292;&#20855;&#26377;&#26356;&#39640;&#25928;&#30340;&#37319;&#26679;&#21644;&#26356;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#20869;&#22312;&#23545;&#31216;&#24615;&#30340;&#26426;&#22120;&#20154;&#25805;&#20316;&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2303.12410</link><description>&lt;p&gt;
EDGI: &#20869;&#22312;&#23545;&#31216;&#24615;&#35268;&#21010;&#30340;&#31561;&#21464;&#25193;&#25955;
&lt;/p&gt;
&lt;p&gt;
EDGI: Equivariant Diffusion for Planning with Embodied Agents. (arXiv:2303.12410v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.12410
&lt;/p&gt;
&lt;p&gt;
EDGI&#26159;&#19968;&#31181;&#22522;&#20110;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#21644;&#35268;&#21010;&#31639;&#27861;&#65292;&#36890;&#36807;&#31561;&#21464;&#25193;&#25955;&#22788;&#29702;&#20869;&#22312;&#23545;&#31216;&#24615;&#65292;&#20855;&#26377;&#26356;&#39640;&#25928;&#30340;&#37319;&#26679;&#21644;&#26356;&#22909;&#30340;&#27867;&#21270;&#33021;&#21147;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#20869;&#22312;&#23545;&#31216;&#24615;&#30340;&#26426;&#22120;&#20154;&#25805;&#20316;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20869;&#22312;&#23545;&#31216;&#24615;&#26159;&#26102;&#31354;&#21644;&#25490;&#21015;&#19978;&#30340;&#65292;&#22823;&#22810;&#25968;&#35745;&#21010;&#21644;&#22522;&#20110;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#27809;&#26377;&#32771;&#34385;&#36825;&#31181;&#20016;&#23500;&#30340;&#20960;&#20309;&#32467;&#26500;&#65292;&#23548;&#33268;&#37319;&#26679;&#25928;&#29575;&#20302;&#21644;&#27867;&#21270;&#33021;&#21147;&#24369;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20869;&#22312;&#23545;&#31216;&#24615;&#35268;&#21010;&#30340;&#31561;&#21464;&#25193;&#25955;&#31639;&#27861;(EDGI), &#21487;&#29992;&#20110;&#22522;&#20110;&#27169;&#22411;&#30340;&#24378;&#21270;&#23398;&#20064;&#21644;&#35268;&#21010;&#65292;&#24182;&#24341;&#20837;&#19968;&#31181;&#26032;&#30340;&#25903;&#25345;&#22810;&#31181;&#34920;&#31034;&#24418;&#24335;&#30340;&#25193;&#25955;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Embodied agents operate in a structured world, often solving tasks with spatial, temporal, and permutation symmetries. Most algorithms for planning and model-based reinforcement learning (MBRL) do not take this rich geometric structure into account, leading to sample inefficiency and poor generalization. We introduce the Equivariant Diffuser for Generating Interactions (EDGI), an algorithm for MBRL and planning that is equivariant with respect to the product of the spatial symmetry group $\mathrm{SE(3)}$, the discrete-time translation group $\mathbb{Z}$, and the object permutation group $\mathrm{S}_n$. EDGI follows the Diffuser framework (Janner et al. 2022) in treating both learning a world model and planning in it as a conditional generative modeling problem, training a diffusion model on an offline trajectory dataset. We introduce a new $\mathrm{SE(3)} \times \mathbb{Z} \times \mathrm{S}_n$-equivariant diffusion model that supports multiple representations. We integrate this model i
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;Langevin&#22411;&#31639;&#27861;&#24182;&#24212;&#29992;&#20110;&#21513;&#24067;&#26031;&#20998;&#24067;&#12290;&#36890;&#36807;&#25552;&#20986;&#30340;2-Wasserstein&#36317;&#31163;&#19978;&#38480;&#65292;&#25105;&#20204;&#21457;&#29616;&#21183;&#20989;&#25968;&#30340;&#32791;&#25955;&#24615;&#20197;&#21450;&#26799;&#24230; $\alpha&gt;1/3$ &#19979;&#30340; $\alpha$-H\"{o}lder&#36830;&#32493;&#24615;&#21487;&#20197;&#20445;&#35777;&#31639;&#27861;&#20855;&#26377;&#25509;&#36817;&#38646;&#30340;&#35823;&#24046;&#12290;&#26032;&#30340;Langevin&#22411;&#31639;&#27861;&#36824;&#21487;&#20197;&#24212;&#29992;&#20110;&#26080;&#20984;&#24615;&#25110;&#36830;&#32493;&#21487;&#24494;&#24615;&#30340;&#21183;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2303.12407</link><description>&lt;p&gt;
Langevin&#22411;Monte Carlo&#31639;&#27861;&#30340;&#38750;&#28176;&#36827;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Non-asymptotic analysis of Langevin-type Monte Carlo algorithms. (arXiv:2303.12407v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.12407
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;Langevin&#22411;&#31639;&#27861;&#24182;&#24212;&#29992;&#20110;&#21513;&#24067;&#26031;&#20998;&#24067;&#12290;&#36890;&#36807;&#25552;&#20986;&#30340;2-Wasserstein&#36317;&#31163;&#19978;&#38480;&#65292;&#25105;&#20204;&#21457;&#29616;&#21183;&#20989;&#25968;&#30340;&#32791;&#25955;&#24615;&#20197;&#21450;&#26799;&#24230; $\alpha&gt;1/3$ &#19979;&#30340; $\alpha$-H\"{o}lder&#36830;&#32493;&#24615;&#21487;&#20197;&#20445;&#35777;&#31639;&#27861;&#20855;&#26377;&#25509;&#36817;&#38646;&#30340;&#35823;&#24046;&#12290;&#26032;&#30340;Langevin&#22411;&#31639;&#27861;&#36824;&#21487;&#20197;&#24212;&#29992;&#20110;&#26080;&#20984;&#24615;&#25110;&#36830;&#32493;&#21487;&#24494;&#24615;&#30340;&#21183;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;Langevin&#22411;&#31639;&#27861;&#24212;&#29992;&#20110;&#21513;&#24067;&#26031;&#20998;&#24067;&#30340;&#24773;&#20917;&#65292;&#20854;&#20013;&#21183;&#20989;&#25968;&#26159;&#32791;&#25955;&#30340;&#65292;&#19988;&#20854;&#24369;&#26799;&#24230;&#20855;&#26377;&#26377;&#38480;&#30340;&#36830;&#32493;&#24615;&#27169;&#37327;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#26159;2-Wasserstein&#36317;&#31163;&#19978;&#38480;&#30340;&#38750;&#28176;&#36827;&#24615;&#65292;&#23427;&#34913;&#37327;&#20102;&#21513;&#24067;&#26031;&#20998;&#24067;&#19982;&#22522;&#20110;Liptser-Shiryaev&#29702;&#35770;&#21644;&#20989;&#25968;&#19981;&#31561;&#24335;&#30340;Langevin&#22411;&#31639;&#27861;&#30340;&#19968;&#33324;&#20998;&#24067;&#20043;&#38388;&#30340;&#36317;&#31163;&#12290;&#25105;&#20204;&#24212;&#29992;&#36825;&#20010;&#19978;&#38480;&#26469;&#23637;&#31034;&#21183;&#20989;&#25968;&#30340;&#32791;&#25955;&#24615;&#20197;&#21450;&#26799;&#24230; $\alpha&gt;1/3$ &#19979;&#30340; $\alpha$-H\"{o}lder&#36830;&#32493;&#24615;&#26159;&#20805;&#20998;&#30340;&#65292;&#21487;&#20197;&#36890;&#36807;&#36866;&#24403;&#25511;&#21046;&#21442;&#25968;&#26469;&#33719;&#24471;Langevin Monte Carlo&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#12290;&#25105;&#20204;&#36824;&#38024;&#23545;&#26080;&#20984;&#24615;&#25110;&#36830;&#32493;&#21487;&#24494;&#24615;&#30340;&#21183;&#20989;&#25968;&#25552;&#20986;&#20102;&#29699;&#24418;&#24179;&#28369;&#25216;&#26415;&#30340;Langevin&#22411;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the Langevin-type algorithms for Gibbs distributions such that the potentials are dissipative and their weak gradients have the finite moduli of continuity. Our main result is a non-asymptotic upper bound of the 2-Wasserstein distance between the Gibbs distribution and the law of general Langevin-type algorithms based on the Liptser--Shiryaev theory and functional inequalities. We apply this bound to show that the dissipativity of the potential and the $\alpha$-H\"{o}lder continuity of the gradient with $\alpha&gt;1/3$ are sufficient for the convergence of the Langevin Monte Carlo algorithm with appropriate control of the parameters. We also propose Langevin-type algorithms with spherical smoothing for potentials without convexity or continuous differentiability.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#25955;&#24335;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#22312;&#26631;&#20934;&#39532;&#23572;&#21487;&#22827;&#21338;&#24328;&#26694;&#26550;&#19979;&#19981;&#23384;&#22312;&#21487;&#33719;&#24471;&#32435;&#20160;&#22343;&#34913;&#19988;&#21487;&#29420;&#31435;&#23398;&#20064;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2303.12287</link><description>&lt;p&gt;
&#29420;&#31435;&#23398;&#20064;&#21644;&#31232;&#30095;&#22343;&#34913;&#35745;&#31639;&#22312;&#39532;&#23572;&#21487;&#22827;&#21338;&#24328;&#20013;&#30340;&#38590;&#24230;
&lt;/p&gt;
&lt;p&gt;
Hardness of Independent Learning and Sparse Equilibrium Computation in Markov Games. (arXiv:2303.12287v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.12287
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#25955;&#24335;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#22312;&#26631;&#20934;&#39532;&#23572;&#21487;&#22827;&#21338;&#24328;&#26694;&#26550;&#19979;&#19981;&#23384;&#22312;&#21487;&#33719;&#24471;&#32435;&#20160;&#22343;&#34913;&#19988;&#21487;&#29420;&#31435;&#23398;&#20064;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#39532;&#23572;&#21487;&#22827;&#21338;&#24328;&#20013;&#20998;&#25955;&#24335;&#22810;&#26234;&#33021;&#20307;&#24378;&#21270;&#23398;&#20064;&#30340;&#38382;&#39064;&#12290;&#19968;&#20010;&#22522;&#26412;&#38382;&#39064;&#26159;&#65292;&#26159;&#21542;&#23384;&#22312;&#31639;&#27861;&#65292;&#24403;&#25152;&#26377;&#20195;&#29702;&#37319;&#29992;&#24182;&#22312;&#20998;&#25955;&#26041;&#24335;&#19979;&#29420;&#31435;&#36816;&#34892;&#26102;&#65292;&#27599;&#20010;&#29609;&#23478;&#37117;&#21487;&#20197;&#19981;&#21518;&#24724;&#22320;&#36827;&#23637;&#65292;&#31867;&#20284;&#20110;&#27491;&#24120;&#24418;&#24335;&#28216;&#25103;&#20013;&#30340;&#33879;&#21517;&#25910;&#25947;&#32467;&#26524;&#12290;&#34429;&#28982;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#21463;&#38480;&#21046;&#30340;&#24773;&#20917;&#19979;&#65288;&#29305;&#21035;&#26159;&#24403;&#21518;&#24724;&#19982;&#39532;&#23572;&#21487;&#22827;&#31574;&#30053;&#30340;&#20559;&#31163;&#26377;&#20851;&#26102;&#65289;&#65292;&#36825;&#31181;&#31639;&#27861;&#23384;&#22312;&#65292;&#20294;&#26159;&#29420;&#31435;&#30340;&#19981;&#21518;&#24724;&#23398;&#20064;&#26159;&#21542;&#33021;&#22312;&#26631;&#20934;&#30340;&#39532;&#23572;&#21487;&#22827;&#21338;&#24328;&#26694;&#26550;&#19979;&#23454;&#29616;&#26159;&#20540;&#24471;&#25506;&#35752;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#20174;&#35745;&#31639;&#21644;&#32479;&#35745;&#35282;&#24230;&#30456;&#24212;&#22320;&#25552;&#20986;&#20102;&#19968;&#20010;&#26126;&#30830;&#30340;&#21542;&#23450;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of decentralized multi-agent reinforcement learning in Markov games. A fundamental question is whether there exist algorithms that, when adopted by all agents and run independently in a decentralized fashion, lead to no-regret for each player, analogous to celebrated convergence results in normal-form games. While recent work has shown that such algorithms exist for restricted settings (notably, when regret is defined with respect to deviations to Markovian policies), the question of whether independent no-regret learning can be achieved in the standard Markov game framework was open. We provide a decisive negative resolution this problem, both from a computational and statistical perspective. We show that:  - Under the widely-believed assumption that PPAD-hard problems cannot be solved in polynomial time, there is no polynomial-time algorithm that attains no-regret in general-sum Markov games when executed independently by all players, even when the game is kno
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#27969;&#22330;&#20272;&#35745;&#30340;&#20256;&#24863;&#22120;&#36873;&#25321;&#26694;&#26550;&#65292;&#33021;&#22815;&#20351;&#29992;&#23569;&#37327;&#20256;&#24863;&#22120;&#39640;&#25928;&#22320;&#20272;&#35745;&#39640;&#25915;&#35282;&#19979;&#26426;&#32764;&#21518;&#27969;&#30340;&#27969;&#22330;&#12290;</title><link>http://arxiv.org/abs/2303.12260</link><description>&lt;p&gt;
&#22522;&#20110;&#20449;&#24687;&#30340;&#20256;&#24863;&#22120;&#25918;&#32622;&#29992;&#20110;&#26080;&#23450;&#24120;&#27969;&#37327;&#30340;&#25968;&#25454;&#39537;&#21160;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Information-Based Sensor Placement for Data-Driven Estimation of Unsteady Flows. (arXiv:2303.12260v1 [physics.flu-dyn])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.12260
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#27969;&#22330;&#20272;&#35745;&#30340;&#20256;&#24863;&#22120;&#36873;&#25321;&#26694;&#26550;&#65292;&#33021;&#22815;&#20351;&#29992;&#23569;&#37327;&#20256;&#24863;&#22120;&#39640;&#25928;&#22320;&#20272;&#35745;&#39640;&#25915;&#35282;&#19979;&#26426;&#32764;&#21518;&#27969;&#30340;&#27969;&#22330;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#39134;&#34892;&#22120;&#21608;&#22260;&#30340;&#26080;&#23450;&#24120;&#27969;&#22330;&#30340;&#20272;&#35745;&#21487;&#33021;&#20250;&#25913;&#21892;&#27969;&#22330;&#20132;&#20114;&#24182;&#23548;&#33268;&#39134;&#34892;&#22120;&#24615;&#33021;&#30340;&#25552;&#39640;&#12290;&#23613;&#31649;&#27969;&#22330;&#34920;&#31034;&#21487;&#20197;&#26159;&#38750;&#24120;&#39640;&#32500;&#30340;&#65292;&#20294;&#23427;&#20204;&#30340;&#21160;&#24577;&#21487;&#20197;&#20855;&#26377;&#20302;&#38454;&#34920;&#31034;&#65292;&#24182;&#19988;&#21487;&#20197;&#20351;&#29992;&#19968;&#20123;&#36866;&#24403;&#25918;&#32622;&#30340;&#27979;&#37327;&#26469;&#20272;&#35745;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#20256;&#24863;&#22120;&#36873;&#25321;&#26694;&#26550;&#65292;&#29992;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#27969;&#22330;&#20272;&#35745;&#12290;&#35813;&#26694;&#26550;&#32467;&#21512;&#20102;&#25968;&#25454;&#39537;&#21160;&#24314;&#27169;&#12289;&#31283;&#24577;&#21345;&#23572;&#26364;&#28388;&#27874;&#22120;&#35774;&#35745;&#21644;&#19968;&#31181;&#29992;&#20110;&#39034;&#24207;&#36873;&#25321;&#20256;&#24863;&#22120;&#30340;&#31232;&#30095;&#21270;&#25216;&#26415;&#12290;&#26412;&#25991;&#36824;&#20351;&#29992;&#20256;&#24863;&#22120;&#36873;&#25321;&#26694;&#26550;&#35774;&#35745;&#20102;&#20256;&#24863;&#22120;&#38453;&#21015;&#65292;&#21487;&#20197;&#22312;&#21508;&#31181;&#25805;&#20316;&#26465;&#20214;&#19979;&#34920;&#29616;&#33391;&#22909;&#12290;&#25968;&#20540;&#25968;&#25454;&#19978;&#30340;&#27969;&#37327;&#20272;&#35745;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#20351;&#29992;&#23884;&#20837;&#24335;&#21387;&#21147;&#20256;&#24863;&#22120;&#33021;&#22815;&#39640;&#25928;&#22320;&#20272;&#35745;&#39640;&#25915;&#35282;&#19979;&#26426;&#32764;&#21518;&#27969;&#30340;&#27969;&#22330;&#12290;&#27969;&#22330;&#20998;&#26512;&#34920;&#26126;
&lt;/p&gt;
&lt;p&gt;
Estimation of unsteady flow fields around flight vehicles may improve flow interactions and lead to enhanced vehicle performance. Although flow-field representations can be very high-dimensional, their dynamics can have low-order representations and may be estimated using a few, appropriately placed measurements. This paper presents a sensor-selection framework for the intended application of data-driven, flow-field estimation. This framework combines data-driven modeling, steady-state Kalman Filter design, and a sparsification technique for sequential selection of sensors. This paper also uses the sensor selection framework to design sensor arrays that can perform well across a variety of operating conditions. Flow estimation results on numerical data show that the proposed framework produces arrays that are highly effective at flow-field estimation for the flow behind and an airfoil at a high angle of attack using embedded pressure sensors. Analysis of the flow fields reveals that pa
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#25237;&#24433;&#30340;kNN&#38598;&#25104;&#20998;&#31867;&#22120;&#65292;&#20351;&#29992;&#25193;&#23637;&#37051;&#22495;&#35268;&#21017;&#21644;&#38477;&#32500;&#26469;&#22686;&#21152;&#22522;&#26412;&#23398;&#20064;&#32773;&#30340;&#38543;&#26426;&#24615;&#24182;&#20445;&#30041;&#29305;&#24449;&#20449;&#24687;&#12290;</title><link>http://arxiv.org/abs/2303.12210</link><description>&lt;p&gt;
&#38543;&#26426;&#25237;&#24433;k&#26368;&#36817;&#37051;&#38598;&#25104;&#20998;&#31867;&#22120; via &#25193;&#23637;&#37051;&#22495;&#35268;&#21017;
&lt;/p&gt;
&lt;p&gt;
A Random Projection k Nearest Neighbours Ensemble for Classification via Extended Neighbourhood Rule. (arXiv:2303.12210v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.12210
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38543;&#26426;&#25237;&#24433;&#30340;kNN&#38598;&#25104;&#20998;&#31867;&#22120;&#65292;&#20351;&#29992;&#25193;&#23637;&#37051;&#22495;&#35268;&#21017;&#21644;&#38477;&#32500;&#26469;&#22686;&#21152;&#22522;&#26412;&#23398;&#20064;&#32773;&#30340;&#38543;&#26426;&#24615;&#24182;&#20445;&#30041;&#29305;&#24449;&#20449;&#24687;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;k&#26368;&#36817;&#37051;&#65288;kNN&#65289;&#30340;&#38598;&#25104;&#23558;&#35768;&#22810;&#22522;&#26412;&#23398;&#20064;&#32773;&#32452;&#21512;&#22312;&#19968;&#36215;&#65292;&#27599;&#20010;&#23398;&#20064;&#32773;&#37117;&#26159;&#22522;&#20110;&#32473;&#23450;&#35757;&#32451;&#25968;&#25454;&#20013;&#30340;&#19968;&#20010;&#26679;&#26412;&#26500;&#24314;&#30340;&#12290;&#36825;&#31687;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#38543;&#26426;&#25237;&#24433;&#25193;&#23637;&#37051;&#22495;&#35268;&#21017;&#65288;RPExNRule&#65289;&#38598;&#25104;&#65292;&#20854;&#20013;&#26469;&#33258;&#32473;&#23450;&#35757;&#32451;&#25968;&#25454;&#30340;&#33258;&#20030;&#26679;&#26412;&#22312;&#38477;&#20302;&#30340;&#32500;&#24230;&#20013;&#34987;&#38543;&#26426;&#25237;&#24433;&#65292;&#20197;&#22686;&#21152;&#22522;&#26412;&#27169;&#22411;&#30340;&#38543;&#26426;&#24615;&#24182;&#20445;&#30041;&#29305;&#24449;&#20449;&#24687;&#65292;&#24182;&#20351;&#29992;&#25193;&#23637;&#37051;&#22495;&#35268;&#21017;&#65288;ExNRule&#65289;&#23558;kNN&#20316;&#20026;&#22522;&#26412;&#23398;&#20064;&#32773;&#25311;&#21512;&#38543;&#26426;&#25237;&#24433;&#30340;&#33258;&#20030;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Ensembles based on k nearest neighbours (kNN) combine a large number of base learners, each constructed on a sample taken from a given training data. Typical kNN based ensembles determine the k closest observations in the training data bounded to a test sample point by a spherical region to predict its class. In this paper, a novel random projection extended neighbourhood rule (RPExNRule) ensemble is proposed where bootstrap samples from the given training data are randomly projected into lower dimensions for additional randomness in the base models and to preserve features information. It uses the extended neighbourhood rule (ExNRule) to fit kNN as base learners on randomly projected bootstrap samples.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#31163;&#25955;&#21270;&#30340;&#21704;&#23494;&#39039;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#24341;&#36215;&#30340;Hamiltonian&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#36890;&#29992;&#36924;&#36817;&#33021;&#21147;&#65292;&#35777;&#26126;&#20102;&#20854;&#20013;&#30340;&#19968;&#37096;&#20998;&#27969;&#21487;&#20197;&#36880;&#28176;&#36924;&#36817;&#32039;&#33268;&#22495;&#19978;&#30340;&#20219;&#20309;&#36830;&#32493;&#20989;&#25968;&#65292;&#20026;&#23454;&#38469;&#20351;&#29992;&#25552;&#20379;&#20102;&#29702;&#35770;&#22522;&#30784;&#12290;</title><link>http://arxiv.org/abs/2303.12147</link><description>&lt;p&gt;
Hamiltonian&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#19975;&#33021;&#36924;&#36817;&#24615;&#36136;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Universal Approximation Property of Hamiltonian Deep Neural Networks. (arXiv:2303.12147v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.12147
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#31163;&#25955;&#21270;&#30340;&#21704;&#23494;&#39039;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#24341;&#36215;&#30340;Hamiltonian&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#36890;&#29992;&#36924;&#36817;&#33021;&#21147;&#65292;&#35777;&#26126;&#20102;&#20854;&#20013;&#30340;&#19968;&#37096;&#20998;&#27969;&#21487;&#20197;&#36880;&#28176;&#36924;&#36817;&#32039;&#33268;&#22495;&#19978;&#30340;&#20219;&#20309;&#36830;&#32493;&#20989;&#25968;&#65292;&#20026;&#23454;&#38469;&#20351;&#29992;&#25552;&#20379;&#20102;&#29702;&#35770;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#30001;&#31163;&#25955;&#21270;&#30340;&#21704;&#23494;&#39039;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#24341;&#36215;&#30340;Hamiltonian&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#65288;HDNN&#65289;&#30340;&#36890;&#29992;&#36924;&#36817;&#33021;&#21147;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;HDNN&#22240;&#35774;&#35745;&#32780;&#20855;&#26377;&#38750;&#28040;&#22833;&#26799;&#24230;&#65292;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#25552;&#20379;&#25968;&#20540;&#31283;&#23450;&#24615;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#22312;&#20960;&#20010;&#24212;&#29992;&#20013;HDNN&#24050;&#32463;&#23637;&#31034;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#65292;&#20294;&#32570;&#23569;&#37327;&#21270;&#20854;&#34920;&#29616;&#21147;&#30340;&#20840;&#38754;&#30740;&#31350;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;HDNN&#30340;&#36890;&#29992;&#36924;&#36817;&#23450;&#29702;&#65292;&#24182;&#35777;&#26126;&#20102;HDNN&#30340;&#19968;&#37096;&#20998;&#27969;&#21487;&#20197;&#36880;&#28176;&#36924;&#36817;&#32039;&#33268;&#22495;&#19978;&#30340;&#20219;&#20309;&#36830;&#32493;&#20989;&#25968;&#12290;&#27492;&#32467;&#26524;&#20026;&#23454;&#38469;&#20351;&#29992;HDNN&#25552;&#20379;&#20102;&#29282;&#22266;&#30340;&#29702;&#35770;&#22522;&#30784;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper investigates the universal approximation capabilities of Hamiltonian Deep Neural Networks (HDNNs) that arise from the discretization of Hamiltonian Neural Ordinary Differential Equations. Recently, it has been shown that HDNNs enjoy, by design, non-vanishing gradients, which provide numerical stability during training. However, although HDNNs have demonstrated state-of-the-art performance in several applications, a comprehensive study to quantify their expressivity is missing. In this regard, we provide a universal approximation theorem for HDNNs and prove that a portion of the flow of HDNNs can approximate arbitrary well any continuous function over a compact domain. This result provides a solid theoretical foundation for the practical use of HDNNs.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#28145;&#20837;&#29702;&#35299;&#20102;&#25193;&#25955;&#30446;&#26631;&#65292;&#24182;&#25581;&#31034;&#20102;&#21152;&#26435;&#25439;&#22833;&#21644;ELBO&#30446;&#26631;&#20043;&#38388;&#30340;&#30452;&#25509;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2303.00848</link><description>&lt;p&gt;
&#20197;ELBOs&#30340;&#21152;&#26435;&#31215;&#20998;&#29702;&#35299;&#25193;&#25955;&#30446;&#26631;
&lt;/p&gt;
&lt;p&gt;
Understanding the Diffusion Objective as a Weighted Integral of ELBOs. (arXiv:2303.00848v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.00848
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#28145;&#20837;&#29702;&#35299;&#20102;&#25193;&#25955;&#30446;&#26631;&#65292;&#24182;&#25581;&#31034;&#20102;&#21152;&#26435;&#25439;&#22833;&#21644;ELBO&#30446;&#26631;&#20043;&#38388;&#30340;&#30452;&#25509;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25991;&#29486;&#20013;&#30340;&#25193;&#25955;&#27169;&#22411;&#37319;&#29992;&#19981;&#21516;&#30340;&#30446;&#26631;&#36827;&#34892;&#20248;&#21270;&#65292;&#24182;&#19988;&#36825;&#20123;&#30446;&#26631;&#37117;&#26159;&#21152;&#26435;&#25439;&#22833;&#30340;&#29305;&#20363;&#65292;&#20854;&#20013;&#21152;&#26435;&#20989;&#25968;&#25351;&#23450;&#27599;&#20010;&#22122;&#22768;&#32423;&#21035;&#30340;&#26435;&#37325;&#12290;&#22343;&#21248;&#21152;&#26435;&#23545;&#24212;&#20110;&#26368;&#22823;&#20284;&#28982;&#30340;&#21407;&#21017;&#24615;&#36817;&#20284;ELBO&#30340;&#26368;&#22823;&#21270;&#12290;&#20294;&#26159;&#23454;&#38469;&#19978;&#65292;&#30001;&#20110;&#26356;&#22909;&#30340;&#26679;&#26412;&#36136;&#37327;&#65292;&#30446;&#21069;&#30340;&#25193;&#25955;&#27169;&#22411;&#20351;&#29992;&#38750;&#22343;&#21248;&#21152;&#26435;&#12290;&#26412;&#25991;&#25581;&#31034;&#20102;&#21152;&#26435;&#25439;&#22833;&#65288;&#24102;&#26377;&#20219;&#20309;&#21152;&#26435;&#65289;&#21644;ELBO&#30446;&#26631;&#20043;&#38388;&#30340;&#30452;&#25509;&#20851;&#31995;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#21152;&#26435;&#25439;&#22833;&#21487;&#20197;&#34987;&#20889;&#25104;&#19968;&#31181;ELBOs&#30340;&#21152;&#26435;&#31215;&#20998;&#24418;&#24335;&#65292;&#20854;&#20013;&#27599;&#20010;&#22122;&#22768;&#32423;&#21035;&#37117;&#26377;&#19968;&#20010;ELBO&#12290;&#22914;&#26524;&#26435;&#37325;&#20989;&#25968;&#26159;&#21333;&#35843;&#30340;&#65292;&#37027;&#20040;&#21152;&#26435;&#25439;&#22833;&#26159;&#19968;&#31181;&#22522;&#20110;&#20284;&#28982;&#30340;&#30446;&#26631;&#65306;&#23427;&#22312;&#31616;&#21333;&#30340;&#25968;&#25454;&#22686;&#24378;&#19979;&#65288;&#21363;&#39640;&#26031;&#22122;&#22768;&#25200;&#21160;&#65289;&#19979;&#26368;&#22823;&#21270;ELBO&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#26356;&#28145;&#20837;&#22320;&#29702;&#35299;&#20102;&#25193;&#25955;&#30446;&#26631;&#65292;&#20294;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#19968;&#20123;&#27604;&#36739;&#21333;&#35843;&#21644;&#38750;&#21333;&#35843;&#26435;&#37325;&#30340;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
Diffusion models in the literature are optimized with various objectives that are special cases of a weighted loss, where the weighting function specifies the weight per noise level. Uniform weighting corresponds to maximizing the ELBO, a principled approximation of maximum likelihood. In current practice diffusion models are optimized with non-uniform weighting due to better results in terms of sample quality. In this work we expose a direct relationship between the weighted loss (with any weighting) and the ELBO objective.  We show that the weighted loss can be written as a weighted integral of ELBOs, with one ELBO per noise level. If the weighting function is monotonic, then the weighted loss is a likelihood-based objective: it maximizes the ELBO under simple data augmentation, namely Gaussian noise perturbation. Our main contribution is a deeper theoretical understanding of the diffusion objective, but we also performed some experiments comparing monotonic with non-monotonic weight
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#38750;&#36138;&#23146;&#31639;&#27861;&#21644;&#20855;&#26377;&#22806;&#25512;&#30340;&#36817;&#31471;&#20132;&#26367;&#26368;&#23567;&#21270;&#26041;&#27861;&#22312; $L_1$-&#33539;&#25968;PCA&#20013;&#30340;&#26377;&#38480;&#27493;&#25910;&#25947;&#24615;&#65292;&#35777;&#26126;&#20102;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#65292;&#31639;&#27861;&#29983;&#25104;&#30340;&#36845;&#20195;&#28857;&#23558;&#22312;&#26377;&#38480;&#27493;&#39588;&#20013;&#20445;&#25345;&#19981;&#21464;&#12290;&#36890;&#36807;&#23558;&#31639;&#27861;&#35270;&#20026;&#20132;&#26367;&#26368;&#20248;&#21270;&#26041;&#27861;&#65292;&#21516;&#26102;&#20248;&#21270;&#26465;&#20214;&#19979;&#22266;&#23450;&#30446;&#26631;&#20540;&#12290;</title><link>http://arxiv.org/abs/2302.07712</link><description>&lt;p&gt;
&#38750;&#36138;&#23146;&#31639;&#27861;&#21644;&#20855;&#26377;&#22806;&#25512;&#30340;&#36817;&#31471;&#20132;&#26367;&#26368;&#23567;&#21270;&#26041;&#27861;&#22312; $L_1$-&#33539;&#25968;PCA&#20013;&#30340;&#26377;&#38480;&#27493;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
On Finite-Step Convergence of the Non-Greedy Algorithm and Proximal Alternating Minimization Method with Extrapolation for $L_1$-Norm PCA. (arXiv:2302.07712v3 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.07712
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#38750;&#36138;&#23146;&#31639;&#27861;&#21644;&#20855;&#26377;&#22806;&#25512;&#30340;&#36817;&#31471;&#20132;&#26367;&#26368;&#23567;&#21270;&#26041;&#27861;&#22312; $L_1$-&#33539;&#25968;PCA&#20013;&#30340;&#26377;&#38480;&#27493;&#25910;&#25947;&#24615;&#65292;&#35777;&#26126;&#20102;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#65292;&#31639;&#27861;&#29983;&#25104;&#30340;&#36845;&#20195;&#28857;&#23558;&#22312;&#26377;&#38480;&#27493;&#39588;&#20013;&#20445;&#25345;&#19981;&#21464;&#12290;&#36890;&#36807;&#23558;&#31639;&#27861;&#35270;&#20026;&#20132;&#26367;&#26368;&#20248;&#21270;&#26041;&#27861;&#65292;&#21516;&#26102;&#20248;&#21270;&#26465;&#20214;&#19979;&#22266;&#23450;&#30446;&#26631;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37325;&#35775;&#20102;&#32463;&#20856;&#30340;&#38750;&#36138;&#23146;&#31639;&#27861;&#65288;NGA&#65289;&#21644;&#26368;&#36817;&#25552;&#20986;&#30340;&#20855;&#26377;&#22806;&#25512;&#30340;&#36817;&#31471;&#20132;&#26367;&#26368;&#23567;&#21270;&#65288;PAMe&#65289;&#26041;&#27861;&#22312; $L_1$-&#33539;&#25968;PCA&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#30740;&#31350;&#20102;&#23427;&#20204;&#30340;&#26377;&#38480;&#27493;&#25910;&#25947;&#24615;&#12290;&#25991;&#31456;&#39318;&#20808;&#35777;&#26126;&#20102;NGA&#21487;&#20197;&#20316;&#20026;&#26465;&#20214;&#27425;&#26799;&#24230;&#25110;&#32773;&#20132;&#26367;&#26368;&#22823;&#21270;&#26041;&#27861;&#36827;&#34892;&#35299;&#37322;&#12290;&#36890;&#36807;&#23558;&#20854;&#35270;&#20026;&#26465;&#20214;&#27425;&#26799;&#24230;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#65292;&#31639;&#27861;&#29983;&#25104;&#30340;&#36845;&#20195;&#28857;&#23558;&#22312;&#26377;&#38480;&#27493;&#39588;&#20013;&#20445;&#25345;&#19981;&#21464;&#65307;&#24403;&#25237;&#23556;&#32500;&#25968;&#20026;&#19968;&#26102;&#65292;&#21487;&#20197;&#28040;&#38500;&#36825;&#31181;&#26465;&#20214;&#30340;&#38480;&#21046;&#12290;&#32780;&#23558;&#31639;&#27861;&#35270;&#20026;&#20132;&#26367;&#26368;&#20248;&#21270;&#26041;&#27861;&#65292;&#28982;&#21518;&#35777;&#26126;&#30446;&#26631;&#20540;&#22312;&#28385;&#36275;&#19968;&#23450;&#20248;&#21270;&#26465;&#20214;&#30340;&#24773;&#20917;&#19979;&#26368;&#22810;&#22312; $\left\lceil\frac{F^{\max}}{\tau_0} \right\rceil$ &#27493;&#21518;&#22266;&#23450;&#19981;&#21464;&#12290;&#25509;&#30528;&#65292;&#25991;&#31456;&#20998;&#26512;&#20102;NGA&#30340;&#25913;&#36827;&#24418;&#24335;&#21450;&#20854;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The classical non-greedy algorithm (NGA) and the recently proposed proximal alternating minimization method with extrapolation (PAMe) for $L_1$-norm PCA are revisited and their finite-step convergence are studied. It is first shown that NGA can be interpreted as a conditional subgradient or an alternating maximization method. By recognizing it as a conditional subgradient, we prove that the iterative points generated by the algorithm will be constant in finitely many steps under a certain full-rank assumption; such an assumption can be removed when the projection dimension is one. By treating the algorithm as an alternating maximization, we then prove that the objective value will be fixed after at most $\left\lceil\frac{F^{\max}}{\tau_0} \right\rceil$ steps, where the stopping point satisfies certain optimality conditions. Then, a slight modification of NGA with improved convergence properties is analyzed. It is shown that the iterative points generated by the modified algorithm will 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#24102;&#38543;&#26426;&#20808;&#39564;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#29992;&#20110;&#39640;&#32500;&#36755;&#20986;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#21487;&#26377;&#25928;&#22320;&#22788;&#29702;&#20840;&#23616;&#20248;&#21270;&#38382;&#39064;&#65292;&#21363;&#20351;&#22312;&#39640;&#32500;&#24230;&#21521;&#37327;&#31354;&#38388;&#25110;&#26080;&#38480;&#32500;&#20989;&#25968;&#31354;&#38388;&#20013;&#20063;&#33021;&#36817;&#20284;&#21151;&#33021;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2302.07260</link><description>&lt;p&gt;
&#22522;&#20110;&#38543;&#26426;&#20808;&#39564;&#32593;&#32476;&#30340;&#39640;&#32500;&#36755;&#20986;&#21487;&#25193;&#23637;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Scalable Bayesian optimization with high-dimensional outputs using randomized prior networks. (arXiv:2302.07260v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.07260
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#24102;&#38543;&#26426;&#20808;&#39564;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#29992;&#20110;&#39640;&#32500;&#36755;&#20986;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#21487;&#26377;&#25928;&#22320;&#22788;&#29702;&#20840;&#23616;&#20248;&#21270;&#38382;&#39064;&#65292;&#21363;&#20351;&#22312;&#39640;&#32500;&#24230;&#21521;&#37327;&#31354;&#38388;&#25110;&#26080;&#38480;&#32500;&#20989;&#25968;&#31354;&#38388;&#20013;&#20063;&#33021;&#36817;&#20284;&#21151;&#33021;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#30340;&#19968;&#20123;&#22522;&#26412;&#38382;&#39064;&#28041;&#21450;&#21040;&#26410;&#30693;&#30340;&#39640;&#32500;&#24230;&#26144;&#23556;&#19968;&#32452;&#21487;&#25511;&#21464;&#37327;&#21040;&#26114;&#36149;&#23454;&#39564;&#32467;&#26524;&#30340;&#40657;&#30418;&#20989;&#25968;&#30340;&#20840;&#23616;&#20248;&#21270;&#20219;&#21153;&#12290;&#36125;&#21494;&#26031;&#20248;&#21270;&#65288;BO&#65289;&#25216;&#26415;&#24050;&#34987;&#35777;&#26126;&#22312;&#20351;&#29992;&#30456;&#23545;&#36739;&#23569;&#30340;&#30446;&#26631;&#20989;&#25968;&#35780;&#20272;&#26102;&#22788;&#29702;&#20840;&#23616;&#20248;&#21270;&#38382;&#39064;&#26102;&#38750;&#24120;&#26377;&#25928;&#65292;&#20294;&#24403;&#22788;&#29702;&#39640;&#32500;&#36755;&#20986;&#26102;&#65292;&#20854;&#24615;&#33021;&#21463;&#21040;&#24433;&#21709;&#12290;&#20026;&#20811;&#26381;&#32500;&#24230;&#20027;&#35201;&#25361;&#25112;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;&#24102;&#38543;&#26426;&#20808;&#39564;&#30340;&#31070;&#32463;&#32593;&#32476;&#30340;&#33258;&#20030;&#38598;&#25104;&#30340;BO&#21644;&#24207;&#36143;&#20915;&#31574;&#21046;&#23450;&#30340;&#28145;&#24230;&#23398;&#20064;&#26694;&#26550;&#12290;&#20351;&#29992;&#36866;&#24403;&#30340;&#20307;&#31995;&#32467;&#26500;&#36873;&#25321;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#26694;&#26550;&#21487;&#20197;&#36817;&#20284;&#35774;&#35745;&#21464;&#37327;&#21644;&#24863;&#20852;&#36259;&#37327;&#20043;&#38388;&#30340;&#21151;&#33021;&#20851;&#31995;&#65292;&#21363;&#20351;&#22312;&#21518;&#32773;&#21462;&#20540;&#20110;&#39640;&#32500;&#21521;&#37327;&#31354;&#38388;&#25110;&#29978;&#33267;&#26080;&#38480;&#32500;&#20989;&#25968;&#31354;&#38388;&#30340;&#24773;&#20917;&#19979;&#12290;&#22312;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#32972;&#26223;&#19979;&#65292;&#35813;&#26041;&#27861;&#20801;&#35768;&#39640;&#25928;&#21644;&#21487;&#25193;&#23637;&#30340;&#22788;&#29702;&#39640;&#32500;&#24230;&#40657;&#30418;&#20989;&#25968;&#30340;&#20840;&#23616;&#20248;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Several fundamental problems in science and engineering consist of global optimization tasks involving unknown high-dimensional (black-box) functions that map a set of controllable variables to the outcomes of an expensive experiment. Bayesian Optimization (BO) techniques are known to be effective in tackling global optimization problems using a relatively small number objective function evaluations, but their performance suffers when dealing with high-dimensional outputs. To overcome the major challenge of dimensionality, here we propose a deep learning framework for BO and sequential decision making based on bootstrapped ensembles of neural architectures with randomized priors. Using appropriate architecture choices, we show that the proposed framework can approximate functional relationships between design variables and quantities of interest, even in cases where the latter take values in high-dimensional vector spaces or even infinite-dimensional function spaces. In the context of 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#24809;&#32602;&#30340;&#21452;&#23618;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#19979;&#23618;&#38750;&#24378;&#20984;&#32422;&#26463;&#21452;&#23618;&#38382;&#39064;&#65292;&#23454;&#39564;&#34920;&#26126;&#35813;&#31639;&#27861;&#26377;&#25928;&#12290;</title><link>http://arxiv.org/abs/2302.05185</link><description>&lt;p&gt;
&#22522;&#20110;&#24809;&#32602;&#30340;&#21452;&#23618;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Penalty-based Bilevel Gradient Descent Method. (arXiv:2302.05185v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.05185
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22522;&#20110;&#24809;&#32602;&#30340;&#21452;&#23618;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65292;&#35299;&#20915;&#20102;&#19979;&#23618;&#38750;&#24378;&#20984;&#32422;&#26463;&#21452;&#23618;&#38382;&#39064;&#65292;&#23454;&#39564;&#34920;&#26126;&#35813;&#31639;&#27861;&#26377;&#25928;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a penalty-based bilevel gradient descent algorithm to solve the constrained bilevel problem without lower-level strong convexity, and experiments show its efficiency.
&lt;/p&gt;
&lt;p&gt;
&#21452;&#23618;&#20248;&#21270;&#22312;&#36229;&#21442;&#25968;&#20248;&#21270;&#12289;&#20803;&#23398;&#20064;&#21644;&#24378;&#21270;&#23398;&#20064;&#31561;&#39046;&#22495;&#26377;&#24191;&#27867;&#24212;&#29992;&#65292;&#20294;&#26159;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#38590;&#20197;&#35299;&#20915;&#12290;&#26368;&#36817;&#30340;&#21487;&#25193;&#23637;&#21452;&#23618;&#31639;&#27861;&#20027;&#35201;&#38598;&#20013;&#22312;&#19979;&#23618;&#30446;&#26631;&#20989;&#25968;&#26159;&#24378;&#20984;&#25110;&#26080;&#32422;&#26463;&#30340;&#21452;&#23618;&#20248;&#21270;&#38382;&#39064;&#19978;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#24809;&#32602;&#26041;&#27861;&#26469;&#35299;&#20915;&#21452;&#23618;&#38382;&#39064;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#65292;&#24809;&#32602;&#37325;&#26500;&#21487;&#20197;&#24674;&#22797;&#21407;&#22987;&#21452;&#23618;&#38382;&#39064;&#30340;&#35299;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#24809;&#32602;&#30340;&#21452;&#23618;&#26799;&#24230;&#19979;&#38477;&#65288;PBGD&#65289;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#22312;&#19979;&#23618;&#38750;&#24378;&#20984;&#32422;&#26463;&#21452;&#23618;&#38382;&#39064;&#19978;&#30340;&#26377;&#38480;&#26102;&#38388;&#25910;&#25947;&#24615;&#12290;&#23454;&#39564;&#23637;&#31034;&#20102;&#25152;&#25552;&#20986;&#30340;PBGD&#31639;&#27861;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bilevel optimization enjoys a wide range of applications in hyper-parameter optimization, meta-learning and reinforcement learning. However, bilevel optimization problems are difficult to solve. Recent progress on scalable bilevel algorithms mainly focuses on bilevel optimization problems where the lower-level objective is either strongly convex or unconstrained. In this work, we tackle the bilevel problem through the lens of the penalty method. We show that under certain conditions, the penalty reformulation recovers the solutions of the original bilevel problem. Further, we propose the penalty-based bilevel gradient descent (PBGD) algorithm and establish its finite-time convergence for the constrained bilevel problem without lower-level strong convexity. Experiments showcase the efficiency of the proposed PBGD algorithm.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#32447;&#32447;&#24615;&#20248;&#21270;&#65288;OLO&#65289;&#28041;&#21450;&#26080;&#32422;&#26463;&#38382;&#39064;&#21644;&#21160;&#24577;&#36951;&#25022;&#38382;&#39064;&#30340;&#22797;&#26434;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#37325;&#26032;&#26500;&#36896;&#38382;&#39064;&#20026;&#31232;&#30095;&#32534;&#30721;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#26041;&#24335;&#65292;&#22312;&#36866;&#24212;&#24615;&#21644;&#24212;&#29992;&#19978;&#26377;&#36739;&#22909;&#30340;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2301.13349</link><description>&lt;p&gt;
&#36890;&#36807;&#31232;&#30095;&#32534;&#30721;&#23454;&#29616;&#26080;&#32422;&#26463;&#21160;&#24577;&#36951;&#25022;
&lt;/p&gt;
&lt;p&gt;
Unconstrained Dynamic Regret via Sparse Coding. (arXiv:2301.13349v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.13349
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#32447;&#32447;&#24615;&#20248;&#21270;&#65288;OLO&#65289;&#28041;&#21450;&#26080;&#32422;&#26463;&#38382;&#39064;&#21644;&#21160;&#24577;&#36951;&#25022;&#38382;&#39064;&#30340;&#22797;&#26434;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#37325;&#26032;&#26500;&#36896;&#38382;&#39064;&#20026;&#31232;&#30095;&#32534;&#30721;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#26041;&#24335;&#65292;&#22312;&#36866;&#24212;&#24615;&#21644;&#24212;&#29992;&#19978;&#26377;&#36739;&#22909;&#30340;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21463;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#30340;&#24433;&#21709;&#65292;&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#22312;&#32447;&#32447;&#24615;&#20248;&#21270;&#65288;OLO&#65289;&#22312;&#20004;&#20010;&#38382;&#39064;&#32467;&#26500;&#30340;&#32806;&#21512;&#19979;&#30340;&#24773;&#20917;&#65306;&#22495;&#26080;&#30028;&#65292;&#32780;&#31639;&#27861;&#30340;&#24615;&#33021;&#26159;&#36890;&#36807;&#21160;&#24577;&#36951;&#25022;&#26469;&#34913;&#37327;&#30340;&#12290;&#22788;&#29702;&#20219;&#19968;&#38382;&#39064;&#37117;&#35201;&#27714;&#36951;&#25022;&#30028;&#38480;&#20381;&#36182;&#20110;&#27604;&#36739;&#24207;&#21015;&#30340;&#26576;&#20123;&#22797;&#26434;&#24230;&#37327;&#24230; - &#29305;&#21035;&#26159;&#26080;&#32422;&#26463;OLO&#20013;&#30340;&#27604;&#36739;&#22120;&#33539;&#25968;&#65292;&#20197;&#21450;&#21160;&#24577;&#36951;&#25022;&#20013;&#30340;&#36335;&#24452;&#38271;&#24230;&#12290;&#19982;&#26368;&#36817;&#19968;&#31687;&#25991;&#31456;(Jacobsen&amp; Cutkosky&#65292;2022)&#36866;&#24212;&#36825;&#20004;&#20010;&#22797;&#26434;&#24230;&#37327;&#24230;&#30456;&#27604;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#37325;&#26032;&#26500;&#36896;&#38382;&#39064;&#20026;&#31232;&#30095;&#32534;&#30721;&#30340;&#22797;&#26434;&#24230;&#24230;&#37327;&#26041;&#24335;&#12290;&#21487;&#20197;&#36890;&#36807;&#19968;&#20010;&#31616;&#21333;&#30340;&#27169;&#22359;&#21270;&#26694;&#26550;&#23454;&#29616;&#36866;&#24212;&#24615;&#65292;&#36825;&#20010;&#26694;&#26550;&#33258;&#28982;&#22320;&#21033;&#29992;&#20102;&#29615;&#22659;&#26356;&#22797;&#26434;&#30340;&#21069;&#32622;&#30693;&#35782;&#12290;&#21516;&#26102;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38745;&#24577;&#26080;&#32422;&#26463;OLO&#26799;&#24230;&#33258;&#36866;&#24212;&#31639;&#27861;&#65292;&#20351;&#29992;&#20102;&#26032;&#39062;&#30340;&#36830;&#32493;&#26102;&#38388;&#26426;&#21046;&#35774;&#35745;&#12290;&#36825;&#21487;&#33021;&#26159;&#20855;&#26377;&#29420;&#31435;&#20852;&#36259;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Motivated by time series forecasting, we study Online Linear Optimization (OLO) under the coupling of two problem structures: the domain is unbounded, and the performance of an algorithm is measured by its dynamic regret. Handling either of them requires the regret bound to depend on certain complexity measure of the comparator sequence -- specifically, the comparator norm in unconstrained OLO, and the path length in dynamic regret. In contrast to a recent work (Jacobsen &amp; Cutkosky, 2022) that adapts to the combination of these two complexity measures, we propose an alternative complexity measure by recasting the problem into sparse coding. Adaptivity can be achieved by a simple modular framework, which naturally exploits more intricate prior knowledge of the environment. Along the way, we also present a new gradient adaptive algorithm for static unconstrained OLO, designed using novel continuous time machinery. This could be of independent interest.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#31350;&#20102;&#19968;&#31181;&#21333;&#27425;&#29983;&#25104;&#27169;&#22411;&#30340;&#22810;&#26679;&#24615;&#65292;&#20027;&#35201;&#32858;&#28966;&#20110;&#23376;&#24207;&#21015;&#30456;&#20284;&#24615;&#22914;&#20309;&#24433;&#21709;&#25972;&#20010;&#24207;&#21015;&#30456;&#20284;&#24615;&#65292;&#24182;&#36890;&#36807;&#29983;&#25104;&#23376;&#24207;&#21015;&#30456;&#20284;&#30340;&#24207;&#21015;&#26469;&#22686;&#24378;&#25968;&#25454;&#38598;&#12290;</title><link>http://arxiv.org/abs/2301.08403</link><description>&lt;p&gt;
&#36890;&#36807;&#23376;&#24207;&#21015;&#30456;&#20284;&#24615;&#29983;&#25104;&#24207;&#21015;&#65306;&#29702;&#35770;&#21450;&#20854;&#22312;&#26080;&#20154;&#26426;&#35782;&#21035;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Sequence Generation via Subsequence Similarity: Theory and Application to UAV Identification. (arXiv:2301.08403v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.08403
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#31350;&#20102;&#19968;&#31181;&#21333;&#27425;&#29983;&#25104;&#27169;&#22411;&#30340;&#22810;&#26679;&#24615;&#65292;&#20027;&#35201;&#32858;&#28966;&#20110;&#23376;&#24207;&#21015;&#30456;&#20284;&#24615;&#22914;&#20309;&#24433;&#21709;&#25972;&#20010;&#24207;&#21015;&#30456;&#20284;&#24615;&#65292;&#24182;&#36890;&#36807;&#29983;&#25104;&#23376;&#24207;&#21015;&#30456;&#20284;&#30340;&#24207;&#21015;&#26469;&#22686;&#24378;&#25968;&#25454;&#38598;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#20154;&#24037;&#21512;&#25104;&#24207;&#21015;&#30340;&#33021;&#21147;&#22312;&#24191;&#27867;&#30340;&#24212;&#29992;&#20013;&#33267;&#20851;&#37325;&#35201;&#65292;&#32780;&#28145;&#24230;&#23398;&#20064;&#26550;&#26500;&#21644;&#29983;&#25104;&#26694;&#26550;&#30340;&#26368;&#26032;&#36827;&#23637;&#24050;&#32463;&#26497;&#22823;&#22320;&#20419;&#36827;&#20102;&#36825;&#19968;&#36807;&#31243;&#12290;&#26412;&#25991;&#20351;&#29992;&#19968;&#31181;&#21333;&#27425;&#29983;&#25104;&#27169;&#22411;&#26469;&#37319;&#26679;&#65292;&#36890;&#36807;&#30456;&#20284;&#24615;&#29983;&#25104;&#23376;&#24207;&#21015;&#65292;&#24182;&#35777;&#26126;&#20102;&#23376;&#24207;&#21015;&#30456;&#20284;&#24615;&#23545;&#25972;&#20010;&#24207;&#21015;&#30456;&#20284;&#24615;&#30340;&#24433;&#21709;&#65292;&#32473;&#20986;&#20102;&#30456;&#24212;&#30340;&#30028;&#38480;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#31181;&#19968;&#27425;&#24615;&#29983;&#25104;&#27169;&#22411;&#26469;&#20174;&#21333;&#20010;&#24207;&#21015;&#30340;&#33539;&#22260;&#20869;&#21462;&#26679;&#65292;&#24182;&#29983;&#25104;&#23376;&#24207;&#21015;&#30456;&#20284;&#30340;&#24207;&#21015;&#65292;&#35777;&#26126;&#20102;&#25968;&#25454;&#38598;&#22686;&#24378;&#26041;&#38754;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The ability to generate synthetic sequences is crucial for a wide range of applications, and recent advances in deep learning architectures and generative frameworks have greatly facilitated this process. Particularly, unconditional one-shot generative models constitute an attractive line of research that focuses on capturing the internal information of a single image or video to generate samples with similar contents. Since many of those one-shot models are shifting toward efficient non-deep and non-adversarial approaches, we examine the versatility of a one-shot generative model for augmenting whole datasets. In this work, we focus on how similarity at the subsequence level affects similarity at the sequence level, and derive bounds on the optimal transport of real and generated sequences based on that of corresponding subsequences. We use a one-shot generative model to sample from the vicinity of individual sequences and generate subsequence-similar ones and demonstrate the improvem
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#39640;&#32500;&#25968;&#25454;&#30340;&#20581;&#22766;expectile&#22238;&#24402;&#26041;&#27861;&#65288;Robust Retire&#65289;&#65292;&#24182;&#38024;&#23545;&#36845;&#20195;&#37325;&#26032;&#21152;&#26435;l1&#24809;&#32602;&#25552;&#20986;&#20102;oracle&#23646;&#24615;&#35299;&#20915;&#20102;&#24809;&#32602;&#20998;&#20301;&#25968;&#30340;&#38750;&#24179;&#28369;&#21644;expectile&#22238;&#24402;&#25935;&#24863;&#35823;&#24046;&#20998;&#24067;&#30340;&#38382;&#39064;&#12290;&#23454;&#39564;&#34920;&#26126;&#36825;&#31181;&#26041;&#27861;&#22312;&#39044;&#27979;&#21644;&#21464;&#37327;&#36873;&#25321;&#26041;&#38754;&#30340;&#34920;&#29616;&#37117;&#20248;&#20110;&#20854;&#20182;&#29616;&#26377;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2212.05562</link><description>&lt;p&gt;
&#39640;&#32500;&#25968;&#25454;&#20013;&#30340;&#20581;&#22766;&#24615;expectile&#22238;&#24402;&#26041;&#27861;Robust Retire
&lt;/p&gt;
&lt;p&gt;
Retire: Robust Expectile Regression in High Dimensions. (arXiv:2212.05562v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.05562
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36866;&#29992;&#20110;&#39640;&#32500;&#25968;&#25454;&#30340;&#20581;&#22766;expectile&#22238;&#24402;&#26041;&#27861;&#65288;Robust Retire&#65289;&#65292;&#24182;&#38024;&#23545;&#36845;&#20195;&#37325;&#26032;&#21152;&#26435;l1&#24809;&#32602;&#25552;&#20986;&#20102;oracle&#23646;&#24615;&#35299;&#20915;&#20102;&#24809;&#32602;&#20998;&#20301;&#25968;&#30340;&#38750;&#24179;&#28369;&#21644;expectile&#22238;&#24402;&#25935;&#24863;&#35823;&#24046;&#20998;&#24067;&#30340;&#38382;&#39064;&#12290;&#23454;&#39564;&#34920;&#26126;&#36825;&#31181;&#26041;&#27861;&#22312;&#39044;&#27979;&#21644;&#21464;&#37327;&#36873;&#25321;&#26041;&#38754;&#30340;&#34920;&#29616;&#37117;&#20248;&#20110;&#20854;&#20182;&#29616;&#26377;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#32500;&#25968;&#25454;&#32463;&#24120;&#34920;&#29616;&#20986;&#30001;&#24322;&#26041;&#24046;&#26041;&#24046;&#25110;&#19981;&#22343;&#21248;&#21327;&#21464;&#37327;&#25928;&#24212;&#24341;&#36215;&#30340;&#24322;&#36136;&#24615;&#12290;&#24809;&#32602;&#30340;&#20998;&#20301;&#25968;&#21644;expectile&#22238;&#24402;&#26041;&#27861;&#25552;&#20379;&#20102;&#22312;&#39640;&#32500;&#25968;&#25454;&#20013;&#26816;&#27979;&#24322;&#26041;&#24046;&#24615;&#30340;&#26377;&#29992;&#24037;&#20855;&#12290;&#21069;&#32773;&#30001;&#20110;check loss&#30340;&#38750;&#24179;&#28369;&#29305;&#24615;&#32780;&#20855;&#26377;&#35745;&#31639;&#19978;&#30340;&#25361;&#25112;&#24615;&#65292;&#32780;&#21518;&#32773;&#23545;&#37325;&#23614;&#35823;&#24046;&#20998;&#24067;&#25935;&#24863;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#24182;&#30740;&#31350;&#20102;&#65288;&#24809;&#32602;&#65289;&#20581;&#22766;expectile&#22238;&#24402;&#65288;retire&#65289;&#65292;&#37325;&#28857;&#26159;&#36845;&#20195;&#37325;&#26032;&#21152;&#26435;$\ell_1$&#24809;&#32602;&#65292;&#23427;&#20943;&#23569;&#20102; $\ell_1$&#24809;&#32602;&#30340;&#20272;&#35745;&#20559;&#24046;&#65292;&#24182;&#23548;&#33268;&#20102;oracle&#23646;&#24615;&#12290;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#22312;&#20004;&#31181;&#24773;&#20917;&#19979;&#24314;&#31435;&#20102;retire&#20272;&#35745;&#22120;&#30340;&#32479;&#35745;&#24615;&#36136;&#65306;&#65288;i&#65289;&#24403;$d\ll n$&#26102;&#30340;&#20302;&#32500;&#24773;&#26223;&#65307;&#65288;ii&#65289;&#24403;$s\ll n\ll d$&#65292;&#20854;&#20013;$s$&#34920;&#31034;&#26174;&#33879;&#39044;&#27979;&#21464;&#37327;&#30340;&#25968;&#37327;&#12290;&#22312;&#39640;&#32500;&#24230;&#35774;&#23450;&#19979;&#65292;&#25105;&#20204;&#20180;&#32454;&#25551;&#36848;&#20102;iteratively reweighted l1-penalized retire estimator&#30340;&#35299;&#36335;&#24452;&#65292;&#24182;&#24320;&#21457;&#20102;&#26377;&#25928;&#30340;&#31639;&#27861;&#26469;&#35299;&#20915;&#25152;&#24471;&#21040;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;&#27169;&#25311;&#21644;&#23454;&#38469;&#25968;&#25454;&#20998;&#26512;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#39044;&#27979;&#31934;&#24230;&#21644;&#21464;&#37327;&#36873;&#25321;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#29616;&#26377;&#30340;&#24809;&#32602;&#20998;&#20301;&#25968;&#21644;expectile&#22238;&#24402;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
High-dimensional data can often display heterogeneity due to heteroscedastic variance or inhomogeneous covariate effects. Penalized quantile and expectile regression methods offer useful tools to detect heteroscedasticity in high-dimensional data. The former is computationally challenging due to the non-smooth nature of the check loss, and the latter is sensitive to heavy-tailed error distributions. In this paper, we propose and study (penalized) robust expectile regression (retire), with a focus on iteratively reweighted $\ell_1$-penalization which reduces the estimation bias from $\ell_1$-penalization and leads to oracle properties. Theoretically, we establish the statistical properties of the retire estimator under two regimes: (i) low-dimensional regime in which $d \ll n$; (ii) high-dimensional regime in which $s\ll n\ll d$ with $s$ denoting the number of significant predictors. In the high-dimensional setting, we carefully characterize the solution path of the iteratively reweight
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#30417;&#30563;&#23545;&#27604;&#25439;&#22833;&#24418;&#24335;&#65288;epsilon-SupInfoNCE&#65289;&#20197;&#21450;&#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#27491;&#21017;&#21270;&#25439;&#22833;&#65288;FairKL&#65289;&#65292;&#26088;&#22312;&#35299;&#20915;&#20174;&#26377;&#20559;&#25968;&#25454;&#20013;&#23398;&#20064;&#26080;&#20559;&#27169;&#22411;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2211.05568</link><description>&lt;p&gt;
&#26080;&#20559;&#30340;&#30417;&#30563;&#23545;&#27604;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Unbiased Supervised Contrastive Learning. (arXiv:2211.05568v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.05568
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#30417;&#30563;&#23545;&#27604;&#25439;&#22833;&#24418;&#24335;&#65288;epsilon-SupInfoNCE&#65289;&#20197;&#21450;&#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#27491;&#21017;&#21270;&#25439;&#22833;&#65288;FairKL&#65289;&#65292;&#26088;&#22312;&#35299;&#20915;&#20174;&#26377;&#20559;&#25968;&#25454;&#20013;&#23398;&#20064;&#26080;&#20559;&#27169;&#22411;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#25968;&#25454;&#38598;&#23384;&#22312;&#20559;&#24046;&#65292;&#21363;&#23427;&#20204;&#21253;&#21547;&#20165;&#22312;&#25968;&#25454;&#38598;&#20013;&#19982;&#30446;&#26631;&#31867;&#39640;&#24230;&#30456;&#20851;&#30340;&#26131;&#20110;&#23398;&#20064;&#30340;&#29305;&#24449;&#65292;&#20294;&#19981;&#22312;&#30495;&#23454;&#30340;&#25968;&#25454;&#20998;&#24067;&#20013;&#12290;&#22240;&#27492;&#65292;&#20174;&#26377;&#20559;&#25968;&#25454;&#20013;&#23398;&#20064;&#26080;&#20559;&#27169;&#22411;&#24050;&#25104;&#20026;&#36817;&#24180;&#26469;&#38750;&#24120;&#30456;&#20851;&#30340;&#30740;&#31350;&#35838;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#23398;&#20064;&#23545;&#20559;&#24046;&#20855;&#26377;&#40065;&#26834;&#24615;&#30340;&#34920;&#24449;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#39318;&#20808;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36793;&#32536;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#21487;&#20197;&#24110;&#21161;&#25105;&#20204;&#28548;&#28165;&#20026;&#20160;&#20040;&#26368;&#36817;&#30340;&#23545;&#27604;&#25439;&#22833;&#65288;InfoNCE&#65292;SupCon&#31561;&#65289;&#22312;&#22788;&#29702;&#20559;&#24046;&#25968;&#25454;&#26102;&#21487;&#33021;&#22833;&#36133;&#12290;&#22522;&#20110;&#27492;&#65292;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#30417;&#30563;&#23545;&#27604;&#25439;&#22833;&#24418;&#24335;&#65288;epsilon-SupInfoNCE&#65289;&#65292;&#25552;&#20379;&#20102;&#26356;&#20934;&#30830;&#30340;&#23545;&#27491;&#36127;&#26679;&#26412;&#20043;&#38388;&#26368;&#23567;&#36317;&#31163;&#30340;&#25511;&#21046;&#12290;&#27492;&#22806;&#65292;&#30001;&#20110;&#25105;&#20204;&#30340;&#29702;&#35770;&#26694;&#26550;&#65292;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;FairKL&#65292;&#19968;&#31181;&#26032;&#30340;&#21435;&#20559;&#27491;&#21017;&#21270;&#25439;&#22833;&#65292;&#21363;&#20351;&#22312;&#26497;&#24230;&#20559;&#24046;&#30340;&#25968;&#25454;&#24773;&#20917;&#19979;&#20063;&#21487;&#20197;&#24456;&#22909;&#22320;&#24037;&#20316;&#12290;&#25105;&#20204;&#22312;&#26631;&#20934;&#30340;&#35270;&#35273;&#25968;&#25454;&#38598;&#19978;&#39564;&#35777;&#20102;&#25152;&#25552;&#20986;&#30340;&#25439;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many datasets are biased, namely they contain easy-to-learn features that are highly correlated with the target class only in the dataset but not in the true underlying distribution of the data. For this reason, learning unbiased models from biased data has become a very relevant research topic in the last years. In this work, we tackle the problem of learning representations that are robust to biases. We first present a margin-based theoretical framework that allows us to clarify why recent contrastive losses (InfoNCE, SupCon, etc.) can fail when dealing with biased data. Based on that, we derive a novel formulation of the supervised contrastive loss (epsilon-SupInfoNCE), providing more accurate control of the minimal distance between positive and negative samples. Furthermore, thanks to our theoretical framework, we also propose FairKL, a new debiasing regularization loss, that works well even with extremely biased data. We validate the proposed losses on standard vision datasets inc
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986; Safe reWard-frEe ExploraTion (SWEET)&#26694;&#26550;&#65292;&#22312;RF-RL&#20219;&#21153;&#20013;&#21487;&#23558;&#23433;&#20840;&#32422;&#26463;&#21644;&#25506;&#32034;&#25928;&#29575;&#21516;&#26102;&#23454;&#29616;&#65292;&#20351;&#24471;&#23433;&#20840;&#25506;&#32034;&#20960;&#20046;&#19981;&#20250;&#22686;&#21152;&#39069;&#22806;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2206.14057</link><description>&lt;p&gt;
&#23433;&#20840;&#25506;&#32034;&#22312;&#27809;&#26377;&#22870;&#21169;&#21453;&#39304;&#30340;&#24378;&#21270;&#23398;&#20064;&#20219;&#21153;&#20013;&#20960;&#20046;&#19981;&#20250;&#22686;&#21152;&#26679;&#26412;&#30340;&#22797;&#26434;&#24230;
&lt;/p&gt;
&lt;p&gt;
Safe Exploration Incurs Nearly No Additional Sample Complexity for Reward-free RL. (arXiv:2206.14057v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.14057
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986; Safe reWard-frEe ExploraTion (SWEET)&#26694;&#26550;&#65292;&#22312;RF-RL&#20219;&#21153;&#20013;&#21487;&#23558;&#23433;&#20840;&#32422;&#26463;&#21644;&#25506;&#32034;&#25928;&#29575;&#21516;&#26102;&#23454;&#29616;&#65292;&#20351;&#24471;&#23433;&#20840;&#25506;&#32034;&#20960;&#20046;&#19981;&#20250;&#22686;&#21152;&#39069;&#22806;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26080;&#22870;&#21169;&#21453;&#39304;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288;RF-RL&#65289;&#26159;&#26368;&#36817;&#24341;&#20837;&#30340;&#19968;&#31181;&#24378;&#21270;&#23398;&#20064;&#33539;&#24335;&#65292;&#20381;&#38752;&#38543;&#26426;&#37319;&#21462;&#34892;&#21160;&#26469;&#25506;&#32034;&#26410;&#30693;&#30340;&#29615;&#22659;&#65292;&#27809;&#26377;&#20219;&#20309;&#22870;&#21169;&#21453;&#39304;&#20449;&#24687;&#12290;&#34429;&#28982;RF-RL&#20013;&#25506;&#32034;&#38454;&#27573;&#30340;&#20027;&#35201;&#30446;&#26631;&#26159;&#22312;&#26368;&#23569;&#36712;&#36857;&#25968;&#37327;&#30340;&#24773;&#20917;&#19979;&#20943;&#23569;&#23545;&#20272;&#35745;&#27169;&#22411;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#20294;&#22312;&#23454;&#36341;&#20013;&#65292;&#26234;&#33021;&#20307;&#32463;&#24120;&#38656;&#35201;&#21516;&#26102;&#36981;&#23432;&#26576;&#20123;&#23433;&#20840;&#32422;&#26463;&#12290;&#30446;&#21069;&#23578;&#19981;&#26126;&#30830;&#36825;&#31181;&#23433;&#20840;&#25506;&#32034;&#35201;&#27714;&#20250;&#22914;&#20309;&#24433;&#21709;&#30456;&#24212;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#20197;&#20415;&#22312;&#35268;&#21010;&#20013;&#23454;&#29616;&#25152;&#24471;&#21040;&#31574;&#30053;&#30340;&#25152;&#38656;&#26368;&#20248;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#23581;&#35797;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#32771;&#34385;&#24050;&#30693;&#19968;&#20010;&#23433;&#20840;&#22522;&#32447;&#31574;&#30053;&#30340;&#24773;&#20917;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#23433;&#20840;&#26080;&#22870;&#21169;&#25506;&#32034;&#65288;SWEET&#65289;&#26694;&#26550;&#12290;&#25105;&#20204;&#28982;&#21518;&#29305;&#21270;SWEET&#26694;&#26550;&#21040;&#34920;&#26684;&#21644;&#20302;&#31209;MDP&#35774;&#32622;&#20013;&#65292;&#24182;&#20998;&#21035;&#24320;&#21457;&#20102;&#34987;&#31216;&#20026;Tabular-SWEET&#21644;Low-rank-SWEET&#30340;&#31639;&#27861;&#12290;&#36825;&#20004;&#31181;&#31639;&#27861;&#33021;&#22815;&#22312;RF-RL&#30340;&#25506;&#32034;&#38454;&#27573;&#20013;&#24182;&#20837;&#23433;&#20840;&#32422;&#26463;&#65292;&#24182;&#22312;&#26576;&#20123;&#20551;&#35774;&#19979;&#20445;&#35777;&#21487;&#35777;&#26126;&#30340;&#23433;&#20840;&#24615;&#65292;&#21516;&#26102;&#23454;&#29616;&#25152;&#38656;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#22312;&#25105;&#20204;&#25552;&#20986;&#30340;&#31639;&#27861;&#20013;&#65292;&#23433;&#20840;&#25506;&#32034;&#24341;&#21457;&#30340;&#38468;&#21152;&#26679;&#26412;&#22797;&#26434;&#24230;&#20960;&#20046;&#20026;&#38646;&#65292;&#36825;&#34920;&#26126;&#23433;&#20840;&#32422;&#26463;&#21644;&#26368;&#20248;&#24615;&#30446;&#26631;&#21487;&#20197;&#21516;&#26102;&#23454;&#29616;&#32780;&#19981;&#20250;&#22826;&#22823;&#22320;&#38477;&#20302;&#26679;&#26412;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reward-free reinforcement learning (RF-RL), a recently introduced RL paradigm, relies on random action-taking to explore the unknown environment without any reward feedback information. While the primary goal of the exploration phase in RF-RL is to reduce the uncertainty in the estimated model with minimum number of trajectories, in practice, the agent often needs to abide by certain safety constraint at the same time. It remains unclear how such safe exploration requirement would affect the corresponding sample complexity in order to achieve the desired optimality of the obtained policy in planning. In this work, we make a first attempt to answer this question. In particular, we consider the scenario where a safe baseline policy is known beforehand, and propose a unified Safe reWard-frEe ExploraTion (SWEET) framework. We then particularize the SWEET framework to the tabular and the low-rank MDP settings, and develop algorithms coined Tabular-SWEET and Low-rank-SWEET, respectively. Bot
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#27604;&#36739;&#20102;&#22810;&#31181;&#24120;&#29992;&#30340;&#21452;&#37325;&#31283;&#20581;&#26041;&#27861;&#65292;&#25506;&#35752;&#20102;&#23427;&#20204;&#20351;&#29992;&#27835;&#30103;&#27169;&#22411;&#21644;&#32467;&#26524;&#27169;&#22411;&#30340;&#31574;&#30053;&#24322;&#21516;&#65292;&#24182;&#30740;&#31350;&#20102;&#22914;&#20309;&#32467;&#21512;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#20197;&#25552;&#39640;&#20854;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2204.10969</link><description>&lt;p&gt;
&#24403;&#21452;&#37325;&#31283;&#20581;&#26041;&#27861;&#36935;&#21040;&#26426;&#22120;&#23398;&#20064;&#65306;&#29992;&#20110;&#20174;&#23454;&#38469;&#25968;&#25454;&#20013;&#20272;&#35745;&#27835;&#30103;&#25928;&#26524;&#30340;&#27604;&#36739;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
When Doubly Robust Methods Meet Machine Learning for Estimating Treatment Effects from Real-World Data: A Comparative Study. (arXiv:2204.10969v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.10969
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#27604;&#36739;&#20102;&#22810;&#31181;&#24120;&#29992;&#30340;&#21452;&#37325;&#31283;&#20581;&#26041;&#27861;&#65292;&#25506;&#35752;&#20102;&#23427;&#20204;&#20351;&#29992;&#27835;&#30103;&#27169;&#22411;&#21644;&#32467;&#26524;&#27169;&#22411;&#30340;&#31574;&#30053;&#24322;&#21516;&#65292;&#24182;&#30740;&#31350;&#20102;&#22914;&#20309;&#32467;&#21512;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#20197;&#25552;&#39640;&#20854;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35266;&#23519;&#24615;&#38431;&#21015;&#30740;&#31350;&#36234;&#26469;&#36234;&#24120;&#29992;&#20110;&#27604;&#36739;&#25928;&#26524;&#30740;&#31350;&#65292;&#20197;&#35780;&#20272;&#27835;&#30103;&#26041;&#27861;&#30340;&#23433;&#20840;&#24615;&#12290;&#26368;&#36817;&#65292;&#21508;&#31181;&#21452;&#37325;&#31283;&#20581;&#26041;&#27861;&#24050;&#34987;&#25552;&#20986;&#65292;&#36890;&#36807;&#21305;&#37197;&#12289;&#21152;&#26435;&#21644;&#22238;&#24402;&#31561;&#19981;&#21516;&#26041;&#24335;&#65292;&#36890;&#36807;&#32452;&#21512;&#27835;&#30103;&#27169;&#22411;&#21644;&#32467;&#26524;&#27169;&#22411;&#26469;&#20272;&#35745;&#24179;&#22343;&#27835;&#30103;&#25928;&#24212;&#12290;&#21452;&#37325;&#31283;&#20581;&#20272;&#35745;&#22120;&#30340;&#20851;&#38190;&#20248;&#21183;&#22312;&#20110;&#65292;&#23427;&#20204;&#35201;&#27714;&#27835;&#30103;&#27169;&#22411;&#25110;&#32467;&#26524;&#27169;&#22411;&#20043;&#19968;&#34987;&#27491;&#30830;&#35268;&#23450;&#65292;&#20197;&#33719;&#24471;&#24179;&#22343;&#27835;&#30103;&#25928;&#26524;&#30340;&#19968;&#33268;&#20272;&#35745;&#20540;&#65292;&#20174;&#32780;&#23548;&#33268;&#26356;&#20934;&#30830;&#12289;&#36890;&#24120;&#26356;&#31934;&#30830;&#30340;&#25512;&#26029;&#12290;&#28982;&#32780;&#65292;&#24456;&#23569;&#26377;&#24037;&#20316;&#21435;&#29702;&#35299;&#21452;&#37325;&#31283;&#20581;&#20272;&#35745;&#22120;&#30001;&#20110;&#20351;&#29992;&#27835;&#30103;&#21644;&#32467;&#26524;&#27169;&#22411;&#30340;&#29420;&#29305;&#31574;&#30053;&#22914;&#20309;&#19981;&#21516;&#20197;&#21450;&#22914;&#20309;&#32467;&#21512;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#20197;&#25552;&#39640;&#20854;&#24615;&#33021;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#26816;&#26597;&#20102;&#22810;&#20010;&#21463;&#27426;&#36814;&#30340;&#21452;&#37325;&#31283;&#20581;&#26041;&#27861;&#65292;&#24182;&#20351;&#29992;&#19981;&#21516;&#30340;&#27835;&#30103;&#21644;&#32467;&#26524;&#27169;&#22411;&#27604;&#36739;&#23427;&#20204;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Observational cohort studies are increasingly being used for comparative effectiveness research to assess the safety of therapeutics. Recently, various doubly robust methods have been proposed for average treatment effect estimation by combining the treatment model and the outcome model via different vehicles, such as matching, weighting, and regression. The key advantage of doubly robust estimators is that they require either the treatment model or the outcome model to be correctly specified to obtain a consistent estimator of average treatment effects, and therefore lead to a more accurate and often more precise inference. However, little work has been done to understand how doubly robust estimators differ due to their unique strategies of using the treatment and outcome models and how machine learning techniques can be combined to boost their performance. Here we examine multiple popular doubly robust methods and compare their performance using different treatment and outcome modeli
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20123;&#22312;&#32447;&#21435;&#20559;&#20272;&#35745;&#30340;&#26041;&#27861;&#26469;&#20462;&#27491;&#33258;&#36866;&#24212;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#28176;&#36817;&#20559;&#24046;&#65292;&#21033;&#29992;&#25968;&#25454;&#38598;&#20013;&#30340;&#21327;&#26041;&#24046;&#32467;&#26500;&#25552;&#20379;&#26356;&#38160;&#21033;&#30340;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2107.02266</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#36817;&#26368;&#20248;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Near-optimal inference in adaptive linear regression. (arXiv:2107.02266v3 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2107.02266
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20123;&#22312;&#32447;&#21435;&#20559;&#20272;&#35745;&#30340;&#26041;&#27861;&#26469;&#20462;&#27491;&#33258;&#36866;&#24212;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#28176;&#36817;&#20559;&#24046;&#65292;&#21033;&#29992;&#25968;&#25454;&#38598;&#20013;&#30340;&#21327;&#26041;&#24046;&#32467;&#26500;&#25552;&#20379;&#26356;&#38160;&#21033;&#30340;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24403;&#25968;&#25454;&#20197;&#33258;&#36866;&#24212;&#26041;&#24335;&#25910;&#38598;&#26102;&#65292;&#21363;&#20351;&#26159;&#26368;&#31616;&#21333;&#30340;&#26041;&#27861;&#22914;&#26222;&#36890;&#26368;&#23567;&#20108;&#20056;&#27861;&#20063;&#21487;&#33021;&#34920;&#29616;&#20986;&#38750;&#27491;&#24120;&#30340;&#28176;&#36817;&#34892;&#20026;&#12290; &#20316;&#20026;&#19981;&#33391;&#21518;&#26524;&#65292;&#22522;&#20110;&#28176;&#36817;&#27491;&#24120;&#24615;&#30340;&#20551;&#35774;&#26816;&#39564;&#21644;&#32622;&#20449;&#21306;&#38388;&#21487;&#33021;&#23548;&#33268;&#38169;&#35823;&#32467;&#26524;&#12290; &#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20123;&#22312;&#32447;&#21435;&#20559;&#20272;&#35745;&#30340;&#26041;&#27861;&#26469;&#32416;&#27491;&#36825;&#20123;&#35823;&#24046;&#65292;&#24182;&#21033;&#29992;&#25968;&#25454;&#38598;&#20013;&#23384;&#22312;&#30340;&#21327;&#26041;&#24046;&#32467;&#26500;&#65292;&#22312;&#20854;&#26356;&#22810;&#20449;&#24687;&#24050;&#32047;&#31215;&#30340;&#26041;&#21521;&#19978;&#25552;&#20379;&#26356;&#38160;&#21033;&#30340;&#20272;&#35745;&#12290; &#25105;&#20204;&#22312;&#25968;&#25454;&#25910;&#38598;&#36807;&#31243;&#30340;&#28201;&#21644;&#26465;&#20214;&#19979;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#22312;&#32447;&#21435;&#20559;&#20272;&#35745;&#30340;&#28176;&#36817;&#27491;&#24577;&#24615;&#36136;&#65292;&#24182;&#25552;&#20379;&#20102;&#28176;&#36817;&#31934;&#30830;&#30340;&#32622;&#20449;&#21306;&#38388;&#12290; &#25105;&#20204;&#36824;&#38024;&#23545;&#33258;&#36866;&#24212;&#32447;&#24615;&#22238;&#24402;&#38382;&#39064;&#35777;&#26126;&#20102;&#26368;&#23567;&#21270;&#19979;&#30028;&#65292;&#20174;&#32780;&#25552;&#20379;&#20102;&#27604;&#36739;&#20272;&#35745;&#22120;&#30340;&#22522;&#32447;&#12290; &#22312;&#25105;&#20204;&#25552;&#20986;&#30340;&#20272;&#35745;&#22120;&#36798;&#21040;&#26368;&#23567;&#20540;&#30340;&#21508;&#31181;&#26465;&#20214;&#19979;&#65292;&#26368;&#23567;&#21270;&#19979;&#30028;&#22343;&#23454;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
When data is collected in an adaptive manner, even simple methods like ordinary least squares can exhibit non-normal asymptotic behavior. As an undesirable consequence, hypothesis tests and confidence intervals based on asymptotic normality can lead to erroneous results. We propose a family of online debiasing estimators to correct these distributional anomalies in least squares estimation. Our proposed methods take advantage of the covariance structure present in the dataset and provide sharper estimates in directions for which more information has accrued. We establish an asymptotic normality property for our proposed online debiasing estimators under mild conditions on the data collection process and provide asymptotically exact confidence intervals. We additionally prove a minimax lower bound for the adaptive linear regression problem, thereby providing a baseline by which to compare estimators. There are various conditions under which our proposed estimators achieve the minimax lo
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#25152;&#26377;&#32467;&#26524;&#20849;&#20139;&#30340;&#20449;&#24687;&#26469;&#23398;&#20064;&#39640;&#32500;&#32447;&#24615;&#20915;&#31574;&#35268;&#21017;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;&#21253;&#25324;&#20351;&#29992;&#22810;&#20219;&#21153;&#23398;&#20064;&#65288;MTL&#65289;&#26469;&#25552;&#39640;&#25928;&#29575;&#65292;&#24182;&#20351;&#29992;&#26657;&#20934;&#27493;&#39588;&#26469;&#32416;&#27491;&#20272;&#35745;&#20559;&#24046;&#12290;</title><link>http://arxiv.org/abs/2011.05493</link><description>&lt;p&gt;
&#21033;&#29992;&#36741;&#21161;&#32467;&#26524;&#24378;&#38887;&#28789;&#27963;&#22320;&#23398;&#20064;&#39640;&#32500;&#20998;&#31867;&#35268;&#21017;
&lt;/p&gt;
&lt;p&gt;
Robust and flexible learning of a high-dimensional classification rule using auxiliary outcomes. (arXiv:2011.05493v3 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2011.05493
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#25152;&#26377;&#32467;&#26524;&#20849;&#20139;&#30340;&#20449;&#24687;&#26469;&#23398;&#20064;&#39640;&#32500;&#32447;&#24615;&#20915;&#31574;&#35268;&#21017;&#30340;&#26041;&#27861;&#65292;&#20854;&#20013;&#21253;&#25324;&#20351;&#29992;&#22810;&#20219;&#21153;&#23398;&#20064;&#65288;MTL&#65289;&#26469;&#25552;&#39640;&#25928;&#29575;&#65292;&#24182;&#20351;&#29992;&#26657;&#20934;&#27493;&#39588;&#26469;&#32416;&#27491;&#20272;&#35745;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30456;&#20851;&#32467;&#26524;&#22312;&#35768;&#22810;&#23454;&#38469;&#38382;&#39064;&#20013;&#24456;&#24120;&#35265;&#12290;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#19968;&#20010;&#32467;&#26524;&#29305;&#21035;&#37325;&#35201;&#65292;&#32780;&#20854;&#20182;&#32467;&#26524;&#26159;&#36741;&#21161;&#30340;&#12290;&#20026;&#20102;&#21033;&#29992;&#25152;&#26377;&#32467;&#26524;&#20849;&#20139;&#30340;&#20449;&#24687;&#65292;&#20256;&#32479;&#30340;&#22810;&#20219;&#21153;&#23398;&#20064;&#65288;MTL&#65289;&#26368;&#23567;&#21270;&#20102;&#25152;&#26377;&#32467;&#26524;&#30340;&#24179;&#22343;&#25439;&#22833;&#20989;&#25968;&#65292;&#36825;&#21487;&#33021;&#20250;&#22312;MTL&#27169;&#22411;&#34987;&#38169;&#35823;&#35828;&#26126;&#26102;&#23548;&#33268;&#30446;&#26631;&#32467;&#26524;&#30340;&#20272;&#35745;&#20559;&#24046;&#12290;&#22522;&#20110;&#23545;&#20272;&#35745;&#20559;&#24046;&#30340;&#20998;&#35299;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#24378;&#38887;&#30340;&#36716;&#31227;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#20272;&#35745;&#20855;&#26377;&#36741;&#21161;&#32467;&#26524;&#23384;&#22312;&#30340;&#39640;&#32500;&#32447;&#24615;&#20915;&#31574;&#35268;&#21017;&#65292;&#35813;&#26041;&#27861;&#21253;&#25324;&#20351;&#29992;&#25152;&#26377;&#32467;&#26524;&#36827;&#34892;MTL&#27493;&#39588;&#20197;&#33719;&#24471;&#25928;&#29575;&#65292;&#20197;&#21450;&#38543;&#21518;&#20351;&#29992;&#20165;&#24863;&#20852;&#36259;&#30340;&#32467;&#26524;&#36827;&#34892;&#26657;&#20934;&#27493;&#39588;&#65292;&#20197;&#20462;&#27491;&#20004;&#31181;&#31867;&#22411;&#30340;&#20559;&#24046;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#26368;&#32456;&#30340;&#20272;&#35745;&#22120;&#21487;&#20197;&#23454;&#29616;&#27604;&#20165;&#20351;&#29992;&#21333;&#20010;&#24863;&#20852;&#36259;&#32467;&#26524;&#30340;&#20272;&#35745;&#22120;&#20855;&#26377;&#26356;&#20302;&#30340;&#20272;&#35745;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Correlated outcomes are common in many practical problems. In some settings, one outcome is of particular interest, and others are auxiliary. To leverage information shared by all the outcomes, traditional multi-task learning (MTL) minimizes an averaged loss function over all the outcomes, which may lead to biased estimation for the target outcome, especially when the MTL model is mis-specified. In this work, based on a decomposition of estimation bias into two types, within-subspace and against-subspace, we develop a robust transfer learning approach to estimating a high-dimensional linear decision rule for the outcome of interest with the presence of auxiliary outcomes. The proposed method includes an MTL step using all outcomes to gain efficiency, and a subsequent calibration step using only the outcome of interest to correct both types of biases. We show that the final estimator can achieve a lower estimation error than the one using only the single outcome of interest. Simulations
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#22312;&#28145;&#20837;&#25506;&#35752;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#22120;&#30340;&#26368;&#22823;&#38388;&#38548;&#32447;&#24615;&#20998;&#31867;&#22120;&#38382;&#39064;&#19978;&#21457;&#29616;&#20102;&#19968;&#20123;&#20851;&#20110;&#36807;&#24230;&#25311;&#21512;&#20197;&#21450;&#39640;&#32500;&#28176;&#36817;&#24615;&#30340;&#27867;&#21270;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/1911.01544</link><description>&lt;p&gt;
&#26368;&#22823;&#38388;&#38548;&#32447;&#24615;&#20998;&#31867;&#22120;&#30340;&#27867;&#21270;&#35823;&#24046;&#65306;&#36807;&#24230;&#25311;&#21512;&#21644;&#36229;&#21442;&#25968;&#21306;&#22495;&#30340;&#39640;&#32500;&#28176;&#36817;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The generalization error of max-margin linear classifiers: Benign overfitting and high dimensional asymptotics in the overparametrized regime. (arXiv:1911.01544v3 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1911.01544
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#22312;&#28145;&#20837;&#25506;&#35752;&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#22120;&#30340;&#26368;&#22823;&#38388;&#38548;&#32447;&#24615;&#20998;&#31867;&#22120;&#38382;&#39064;&#19978;&#21457;&#29616;&#20102;&#19968;&#20123;&#20851;&#20110;&#36807;&#24230;&#25311;&#21512;&#20197;&#21450;&#39640;&#32500;&#28176;&#36817;&#24615;&#30340;&#27867;&#21270;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#20998;&#31867;&#22120;&#36890;&#24120;&#22312;&#35757;&#32451;&#38598;&#19978;&#34920;&#29616;&#20986;&#28040;&#22833;&#30340;&#20998;&#31867;&#35823;&#24046;&#12290;&#23427;&#20204;&#36890;&#36807;&#23398;&#20064;&#23558;&#25968;&#25454;&#26144;&#23556;&#21040;&#32447;&#24615;&#21487;&#20998;&#30340;&#31867;&#21035;&#30340;&#36755;&#20837;&#30340;&#38750;&#32447;&#24615;&#34920;&#31034;&#26469;&#23454;&#29616;&#36825;&#19968;&#28857;&#12290;&#21463;&#36825;&#20123;&#29616;&#35937;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#32447;&#24615;&#21487;&#20998;&#25968;&#25454;&#30340;&#39640;&#32500;&#26368;&#22823;&#38388;&#38548;&#20998;&#31867;&#38382;&#39064;&#12290;&#25105;&#20204;&#32771;&#34385;&#36825;&#26679;&#19968;&#20010;&#35774;&#23450;: &#25968;&#25454;$(y_i,{\boldsymbol x}_i)$&#65292; $i\le n$&#29420;&#31435;&#21516;&#20998;&#24067;&#65292;&#20854;&#20013;${\boldsymbol x}_i\sim \mathsf{N}({\boldsymbol 0},{\boldsymbol \Sigma})$&#20026;$p$&#32500;&#39640;&#26031;&#29305;&#24449;&#21521;&#37327;&#65292;$y_i \in\{+1,-1\}$&#34920;&#31034;&#26631;&#31614;&#65292;&#20854;&#20998;&#24067;&#21462;&#20915;&#20110;&#21327;&#21464;&#37327;${\boldsymbol \theta}_*$ &#21644; ${\boldsymbol x}_i$&#30340;&#32447;&#24615;&#32452;&#21512;&#12290;&#34429;&#28982;&#39640;&#26031;&#27169;&#22411;&#21487;&#33021;&#30475;&#36215;&#26469;&#38750;&#24120;&#31616;&#21333;&#65292;&#20294;&#26222;&#36941;&#24615;&#35770;&#25454;&#21487;&#29992;&#20110;&#34920;&#26126;&#22312;&#36825;&#20010;&#35774;&#32622;&#20013;&#24471;&#20986;&#30340;&#32467;&#26524;&#20063;&#36866;&#29992;&#20110;&#26576;&#20123;&#38750;&#32447;&#24615;&#26144;&#23556;&#30340;&#36755;&#20986;&#12290;&#25105;&#20204;&#32771;&#34385;&#27604;&#20363;&#28176;&#36817;&#20851;&#31995;$n,p\to\infty$&#65292;&#19988;$p/n\to\psi$&#65292;
&lt;/p&gt;
&lt;p&gt;
Modern machine learning classifiers often exhibit vanishing classification error on the training set. They achieve this by learning nonlinear representations of the inputs that maps the data into linearly separable classes.  Motivated by these phenomena, we revisit high-dimensional maximum margin classification for linearly separable data. We consider a stylized setting in which data $(y_i,{\boldsymbol x}_i)$, $i\le n$ are i.i.d. with ${\boldsymbol x}_i\sim\mathsf{N}({\boldsymbol 0},{\boldsymbol \Sigma})$ a $p$-dimensional Gaussian feature vector, and $y_i \in\{+1,-1\}$ a label whose distribution depends on a linear combination of the covariates $\langle {\boldsymbol \theta}_*,{\boldsymbol x}_i \rangle$. While the Gaussian model might appear extremely simplistic, universality arguments can be used to show that the results derived in this setting also apply to the output of certain nonlinear featurization maps.  We consider the proportional asymptotics $n,p\to\infty$ with $p/n\to \psi$,
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#22914;&#20309;&#21033;&#29992;&#36125;&#21494;&#26031;&#25512;&#26029;&#20174;&#22797;&#26434;&#32593;&#32476;&#20013;&#25552;&#21462;&#22823;&#35268;&#27169;&#27169;&#22359;&#32467;&#26500;&#65292;&#24182;&#25506;&#35752;&#20102;&#20854;&#28508;&#22312;&#24212;&#29992;&#65292;&#21516;&#26102;&#23637;&#31034;&#20102;&#23558;&#20854;&#24212;&#29992;&#20110;&#39044;&#27979;&#32593;&#32476;&#20013;&#32570;&#22833;&#21644;&#34394;&#20551;&#38142;&#25509;&#30340;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/1705.10225</link><description>&lt;p&gt;
&#36125;&#21494;&#26031;&#38543;&#26426;&#22359;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Bayesian stochastic blockmodeling. (arXiv:1705.10225v9 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1705.10225
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#22914;&#20309;&#21033;&#29992;&#36125;&#21494;&#26031;&#25512;&#26029;&#20174;&#22797;&#26434;&#32593;&#32476;&#20013;&#25552;&#21462;&#22823;&#35268;&#27169;&#27169;&#22359;&#32467;&#26500;&#65292;&#24182;&#25506;&#35752;&#20102;&#20854;&#28508;&#22312;&#24212;&#29992;&#65292;&#21516;&#26102;&#23637;&#31034;&#20102;&#23558;&#20854;&#24212;&#29992;&#20110;&#39044;&#27979;&#32593;&#32476;&#20013;&#32570;&#22833;&#21644;&#34394;&#20551;&#38142;&#25509;&#30340;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#31456;&#33410;&#25552;&#20379;&#20102;&#19968;&#20010;&#33258;&#21253;&#21547;&#30340;&#20171;&#32461;&#65292;&#25945;&#25480;&#22914;&#20309;&#20351;&#29992;&#36125;&#21494;&#26031;&#25512;&#26029;&#20174;&#32593;&#32476;&#25968;&#25454;&#20013;&#25552;&#21462;&#22823;&#35268;&#27169;&#27169;&#22359;&#32467;&#26500;&#65292;&#22522;&#20110;&#38543;&#26426;&#22359;&#27169;&#22411;(SBM)&#65292;&#20197;&#21450;&#20854;&#26657;&#27491;&#24230;&#37327;&#21644;&#37325;&#21472;&#25512;&#24191;&#12290;&#25105;&#20204;&#30528;&#37325;&#20110;&#38750;&#21442;&#25968;&#30340;&#34920;&#36848;&#65292;&#20801;&#35768;&#23427;&#20204;&#22312;&#26377;&#25928;&#38450;&#27490;&#36807;&#25311;&#21512;&#21644;&#23454;&#29616;&#27169;&#22411;&#36873;&#25321;&#30340;&#24773;&#20917;&#19979;&#25512;&#26029;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#20808;&#39564;&#36873;&#25321;&#30340;&#26041;&#38754;&#65292;&#29305;&#21035;&#26159;&#22914;&#20309;&#36890;&#36807;&#22686;&#21152;&#36125;&#21494;&#26031;&#23618;&#27425;&#32467;&#26500;&#36991;&#20813;&#27424;&#25311;&#21512;&#65292;&#24182;&#23545;&#27604;&#20102;&#20174;&#21518;&#39564;&#20998;&#24067;&#20013;&#37319;&#26679;&#32593;&#32476;&#20998;&#21306;&#21644;&#23547;&#25214;&#26368;&#22823;&#21270;&#21518;&#39564;&#20998;&#24067;&#30340;&#21333;&#20010;&#28857;&#20272;&#35745;&#20043;&#38388;&#30340;&#20219;&#21153;&#65292;&#21516;&#26102;&#25551;&#36848;&#20102;&#25191;&#34892;&#20219;&#20309;&#19968;&#20010;&#20219;&#21153;&#30340;&#39640;&#25928;&#31639;&#27861;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#25512;&#26029;SBM&#26469;&#39044;&#27979;&#32570;&#22833;&#21644;&#34394;&#20551;&#38142;&#25509;&#65292;&#24182;&#25581;&#31034;&#20102;&#32593;&#32476;&#20013;&#27169;&#22359;&#21270;&#32467;&#26500;&#30340;&#21487;&#26816;&#27979;&#24615;&#30340;&#22522;&#26412;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
This chapter provides a self-contained introduction to the use of Bayesian inference to extract large-scale modular structures from network data, based on the stochastic blockmodel (SBM), as well as its degree-corrected and overlapping generalizations. We focus on nonparametric formulations that allow their inference in a manner that prevents overfitting, and enables model selection. We discuss aspects of the choice of priors, in particular how to avoid underfitting via increased Bayesian hierarchies, and we contrast the task of sampling network partitions from the posterior distribution with finding the single point estimate that maximizes it, while describing efficient algorithms to perform either one. We also show how inferring the SBM can be used to predict missing and spurious links, and shed light on the fundamental limitations of the detectability of modular structures in networks.
&lt;/p&gt;</description></item></channel></rss>