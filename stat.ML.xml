<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#33258;&#36866;&#24212;&#31639;&#27861;(&#22914;Adagrad&#21644;Adam)&#30340;&#23398;&#20064;&#29575;&#20272;&#35745;&#26041;&#27861;Prodigy&#21644;Resetting&#65292;&#21487;&#20197;&#24555;&#36895;&#19988;&#27491;&#30830;&#22320;&#20272;&#35745;&#21040;&#36798;&#35299;&#20915;&#26041;&#26696;&#25152;&#38656;&#30340;&#36317;&#31163;D&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#23454;&#39564;&#34920;&#26126;&#35813;&#26041;&#27861;&#20248;&#20110;D-Adaptation&#24182;&#21487;&#36798;&#21040;&#25163;&#21160;&#35843;&#25972;Adam&#30340;&#27979;&#35797;&#20934;&#30830;&#24230;&#20540;&#12290;</title><link>http://arxiv.org/abs/2306.06101</link><description>&lt;p&gt;
Prodigy: &#19968;&#31181;&#24555;&#36895;&#33258;&#36866;&#24212;&#38646;&#21442;&#25968;&#23398;&#20064;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Prodigy: An Expeditiously Adaptive Parameter-Free Learner. (arXiv:2306.06101v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06101
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#33258;&#36866;&#24212;&#31639;&#27861;(&#22914;Adagrad&#21644;Adam)&#30340;&#23398;&#20064;&#29575;&#20272;&#35745;&#26041;&#27861;Prodigy&#21644;Resetting&#65292;&#21487;&#20197;&#24555;&#36895;&#19988;&#27491;&#30830;&#22320;&#20272;&#35745;&#21040;&#36798;&#35299;&#20915;&#26041;&#26696;&#25152;&#38656;&#30340;&#36317;&#31163;D&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#22312;&#22810;&#20010;&#25968;&#25454;&#38598;&#21644;&#27169;&#22411;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#23454;&#39564;&#34920;&#26126;&#35813;&#26041;&#27861;&#20248;&#20110;D-Adaptation&#24182;&#21487;&#36798;&#21040;&#25163;&#21160;&#35843;&#25972;Adam&#30340;&#27979;&#35797;&#20934;&#30830;&#24230;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#33258;&#36866;&#24212;&#31639;&#27861;(&#22914;Adagrad&#21644;Adam)&#20013;&#30340;&#23398;&#20064;&#29575;&#20272;&#35745;&#38382;&#39064;&#65292;&#25551;&#36848;&#20102;&#20004;&#31181;&#25216;&#26415;Prodigy&#21644;Resetting&#65292;&#21487;&#20197;&#35777;&#26126;&#22320;&#20272;&#35745;&#21040;&#36798;&#35299;&#20915;&#26041;&#26696;&#25152;&#38656;&#30340;&#36317;&#31163;D&#65292;&#20197;&#20415;&#26368;&#20248;&#35774;&#32622;&#23398;&#20064;&#29575;&#12290;&#25105;&#20204;&#30340;&#25216;&#26415;&#26159;&#22522;&#20110;&#23398;&#20064;&#29575;&#33258;&#30001;&#30340;D-Adaptation&#26041;&#27861;&#30340;&#20462;&#25913;&#65292;&#24182;&#36890;&#36807;$O(\sqrt{\log(D/d_0)})$&#30340;&#22240;&#23376;&#25552;&#39640;&#20102;D-Adaptation&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#20854;&#20013;$d_0$&#26159;$D$&#30340;&#21021;&#22987;&#20272;&#35745;&#20540;&#12290;&#25105;&#20204;&#22312;12&#20010;&#24120;&#35265;&#30340;&#36923;&#36753;&#22238;&#24402;&#22522;&#20934;&#25968;&#25454;&#38598;&#12289;&#22312;CIFAR10&#19978;&#35757;&#32451;&#30340;VGG11&#21644;ResNet-50&#12289;&#22312;Imagenet&#19978;&#35757;&#32451;&#30340;ViT&#12289;&#22312;IWSLT14&#19978;&#35757;&#32451;&#30340;LSTM&#12289;&#22312;Criteo&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;DLRM&#12289;&#22312;Knee MRI&#25968;&#25454;&#38598;&#19978;&#30340;VarNet&#65292;&#20197;&#21450;&#22312;BookWiki&#19978;&#35757;&#32451;&#30340;RoBERTa&#21644;GPT transformer&#19978;&#27979;&#35797;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22987;&#32456;&#20248;&#20110;D-Adaptation&#65292;&#24182;&#36798;&#21040;&#25163;&#21160;&#35843;&#25972;Adam&#30340;&#27979;&#35797;&#20934;&#30830;&#24230;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of estimating the learning rate in adaptive methods, such as Adagrad and Adam. We describe two techniques, Prodigy and Resetting, to provably estimate the distance to the solution $D$, which is needed to set the learning rate optimally. Our techniques are modifications of the D-Adaptation method for learning-rate-free learning. Our methods improve upon the convergence rate of D-Adaptation by a factor of $O(\sqrt{\log(D/d_0)})$, where $d_0$ is the initial estimate of $D$. We test our methods on 12 common logistic-regression benchmark datasets, VGG11 and ResNet-50 training on CIFAR10, ViT training on Imagenet, LSTM training on IWSLT14, DLRM training on Criteo dataset, VarNet on Knee MRI dataset, as well as RoBERTa and GPT transformer training on BookWiki. Our experimental results show that our approaches consistently outperform D-Adaptation and reach test accuracy values close to that of hand-tuned Adam.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DP-RandP&#30340;&#26041;&#27861;&#65292;&#20174;&#38543;&#26426;&#36807;&#31243;&#20013;&#23398;&#20064;&#20808;&#39564;&#30693;&#35782;&#65292;&#24182;&#23558;&#20854;&#20256;&#36882;&#32473;&#31169;&#26377;&#25968;&#25454;&#65292;&#20197;&#25913;&#36827;&#24046;&#20998;&#38544;&#31169;&#30340;&#22270;&#20687;&#20998;&#31867;&#65292;&#23454;&#29616;&#20102;&#26032;&#30340;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65292;&#25552;&#39640;&#20102;CIFAR-10&#30340;&#31934;&#24230;&#12290;</title><link>http://arxiv.org/abs/2306.06076</link><description>&lt;p&gt;
&#20174;&#38543;&#26426;&#36807;&#31243;&#20013;&#23398;&#20064;&#20808;&#39564;&#30693;&#35782;&#30340;&#24046;&#20998;&#38544;&#31169;&#22270;&#20687;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Image Classification by Learning Priors from Random Processes. (arXiv:2306.06076v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06076
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;DP-RandP&#30340;&#26041;&#27861;&#65292;&#20174;&#38543;&#26426;&#36807;&#31243;&#20013;&#23398;&#20064;&#20808;&#39564;&#30693;&#35782;&#65292;&#24182;&#23558;&#20854;&#20256;&#36882;&#32473;&#31169;&#26377;&#25968;&#25454;&#65292;&#20197;&#25913;&#36827;&#24046;&#20998;&#38544;&#31169;&#30340;&#22270;&#20687;&#20998;&#31867;&#65292;&#23454;&#29616;&#20102;&#26032;&#30340;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65292;&#25552;&#39640;&#20102;CIFAR-10&#30340;&#31934;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#38544;&#31169;&#20445;&#25252;&#30340;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#19981;&#21516;ially&#31169;&#26377;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;DP-SGD&#65289;&#30001;&#20110;&#27599;&#20010;&#26679;&#26412;&#26799;&#24230;&#21098;&#36753;&#21644;&#22122;&#22768;&#28155;&#21152;&#32780;&#34920;&#29616;&#19981;&#20339;&#12290;&#38544;&#31169;&#23398;&#20064;&#30740;&#31350;&#30340;&#19968;&#20010;&#26368;&#36817;&#37325;&#28857;&#26159;&#36890;&#36807;&#23558;&#22312;&#30495;&#23454;&#19990;&#30028;&#20844;&#20849;&#25968;&#25454;&#19978;&#23398;&#20064;&#30340;&#20808;&#39564;&#30693;&#35782;&#32435;&#20837;&#36825;&#20123;&#25968;&#25454;&#65292;&#20174;&#32780;&#25552;&#39640;DP-SGD&#22312;&#31169;&#26377;&#25968;&#25454;&#19978;&#30340;&#24615;&#33021;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#22914;&#20309;&#36890;&#36807;&#20174;&#30001;&#38543;&#26426;&#36807;&#31243;&#29983;&#25104;&#30340;&#22270;&#20687;&#20013;&#23398;&#20064;&#20808;&#39564;&#30693;&#35782;&#24182;&#23558;&#36825;&#20123;&#20808;&#39564;&#30693;&#35782;&#36716;&#31227;&#21040;&#31169;&#26377;&#25968;&#25454;&#26469;&#25913;&#36827;DP-SGD&#30340;&#38544;&#31169;-&#25928;&#29992;&#25240;&#34935;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;DP-RandP&#65292;&#36825;&#26159;&#19968;&#20010;&#19977;&#38454;&#27573;&#30340;&#26041;&#27861;&#12290;&#22312;CIFAR10&#12289;CIFAR100&#21644;MedMNIST&#19978;&#20174;&#22836;&#24320;&#22987;&#35757;&#32451;&#26102;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#26032;&#30340;&#26368;&#20808;&#36827;&#30340;&#32467;&#26524;&#65292;&#24182;&#36866;&#29992;&#20110;&#19968;&#31995;&#21015;&#38544;&#31169;&#39044;&#31639;&#949;&#8712;[1&#65292;8]&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23558;&#22312;&#949;=1&#26102;&#22312;CIFAR10&#19978;&#25253;&#21578;&#30340;&#26368;&#20339;&#20934;&#30830;&#24615;&#20174;60.6%&#25552;&#39640;&#21040;72.3%&#12290;&#25105;&#20204;&#30340;&#20195;&#30721;&#21487;&#22312;https://github.com/inspire-group/DP-RandP&#19978;&#25214;&#21040;&#12290;
&lt;/p&gt;
&lt;p&gt;
In privacy-preserving machine learning, differentially private stochastic gradient descent (DP-SGD) performs worse than SGD due to per-sample gradient clipping and noise addition. A recent focus in private learning research is improving the performance of DP-SGD on private data by incorporating priors that are learned on real-world public data. In this work, we explore how we can improve the privacy-utility tradeoff of DP-SGD by learning priors from images generated by random processes and transferring these priors to private data. We propose DP-RandP, a three-phase approach. We attain new state-of-the-art accuracy when training from scratch on CIFAR10, CIFAR100, and MedMNIST for a range of privacy budgets $\varepsilon \in [1, 8]$. In particular, we improve the previous best reported accuracy on CIFAR10 from $60.6 \%$ to $72.3 \%$ for $\varepsilon=1$. Our code is available at https://github.com/inspire-group/DP-RandP.
&lt;/p&gt;</description></item><item><title>DYGR&#26159;&#19968;&#31181;&#29992;&#20110;&#20851;&#31995;&#25512;&#26029;&#30340;&#21160;&#24577;&#22270;&#20808;&#39564;&#26041;&#27861;&#65292;&#23427;&#21033;&#29992;&#39640;&#24230;&#38750;&#23616;&#37096;&#30340;&#22810;&#39033;&#24335;&#28388;&#27874;&#22120;&#20013;&#26500;&#36896;&#24615;&#22320;&#21033;&#29992;&#35823;&#24046;&#25918;&#22823;&#26469;&#29983;&#25104;&#29992;&#20110;&#22270;&#24418;&#23398;&#20064;&#30340;&#33391;&#22909;&#26799;&#24230;&#65292;&#24182;&#33021;&#22815;&#21516;&#26102;&#36866;&#29992;&#20110;&#20855;&#26377;&#20849;&#20139;&#22270;&#25299;&#25169;&#30340;&#8220;&#27973;&#23618;&#8221;&#19968;&#27493;&#27169;&#22411;&#12290;</title><link>http://arxiv.org/abs/2306.06041</link><description>&lt;p&gt;
&#21160;&#24577;&#22270;&#37051;&#20808;&#39564;&#29992;&#20110;&#20851;&#31995;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
A Dynamical Graph Prior for Relational Inference. (arXiv:2306.06041v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.06041
&lt;/p&gt;
&lt;p&gt;
DYGR&#26159;&#19968;&#31181;&#29992;&#20110;&#20851;&#31995;&#25512;&#26029;&#30340;&#21160;&#24577;&#22270;&#20808;&#39564;&#26041;&#27861;&#65292;&#23427;&#21033;&#29992;&#39640;&#24230;&#38750;&#23616;&#37096;&#30340;&#22810;&#39033;&#24335;&#28388;&#27874;&#22120;&#20013;&#26500;&#36896;&#24615;&#22320;&#21033;&#29992;&#35823;&#24046;&#25918;&#22823;&#26469;&#29983;&#25104;&#29992;&#20110;&#22270;&#24418;&#23398;&#20064;&#30340;&#33391;&#22909;&#26799;&#24230;&#65292;&#24182;&#33021;&#22815;&#21516;&#26102;&#36866;&#29992;&#20110;&#20855;&#26377;&#20849;&#20139;&#22270;&#25299;&#25169;&#30340;&#8220;&#27973;&#23618;&#8221;&#19968;&#27493;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20851;&#31995;&#25512;&#26029;&#26088;&#22312;&#20174;&#35266;&#23519;&#21040;&#30340;&#21160;&#24577;&#31995;&#32479;&#20013;&#35782;&#21035;&#37096;&#20214;&#20043;&#38388;&#30340;&#30456;&#20114;&#20316;&#29992;&#12290;&#30446;&#21069;&#30340;&#26368;&#20808;&#36827;&#26041;&#27861;&#26159;&#22312;&#21487;&#23398;&#20064;&#30340;&#22270;&#19978;&#25311;&#21512;&#22270;&#31070;&#32463;&#32593;&#32476; (GNN) &#26469;&#36827;&#34892;&#20851;&#31995;&#25512;&#26029;&#12290;&#23427;&#20204;&#20351;&#29992;&#19968;&#27493;&#28040;&#24687;&#20256;&#36882; GNN--&#30452;&#35266;&#19978;&#26469;&#35828;&#26159;&#27491;&#30830;&#30340;&#36873;&#25321;&#65292;&#22240;&#20026;&#22810;&#27493;&#25110;&#35889; GNN &#30340;&#38750;&#23616;&#37096;&#24615;&#21487;&#33021;&#20250;&#28151;&#28102;&#30452;&#25509;&#21644;&#38388;&#25509;&#30456;&#20114;&#20316;&#29992;&#12290;&#20294;&#26159;&#8220;&#26377;&#25928;&#8221;&#30340;&#20132;&#20114;&#22270;&#21462;&#20915;&#20110;&#37319;&#26679;&#36895;&#29575;&#65292;&#24456;&#23569;&#23616;&#38480;&#20110;&#30452;&#25509;&#37051;&#23621;&#65292;&#23548;&#33268;&#19968;&#20010;&#27493;&#39588;&#27169;&#22411;&#30340;&#23616;&#37096;&#26368;&#23567;&#20540;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#8220;&#21160;&#24577;&#22270;&#20808;&#39564;&#8221;(DYGR)&#26469;&#36827;&#34892;&#20851;&#31995;&#25512;&#26029;&#12290;&#25105;&#20204;&#31216;&#20043;&#20026;&#20808;&#39564;&#30340;&#21407;&#22240;&#26159;&#65292;&#19982;&#24050;&#26377;&#30340;&#26041;&#27861;&#19981;&#21516;&#65292;&#23427;&#22312;&#39640;&#24230;&#38750;&#23616;&#37096;&#30340;&#22810;&#39033;&#24335;&#28388;&#27874;&#22120;&#20013;&#26500;&#36896;&#24615;&#22320;&#21033;&#29992;&#35823;&#24046;&#25918;&#22823;&#26469;&#29983;&#25104;&#29992;&#20110;&#22270;&#24418;&#23398;&#20064;&#30340;&#33391;&#22909;&#26799;&#24230;&#12290;&#20026;&#20102;&#22788;&#29702;&#38750;&#21807;&#19968;&#24615;&#65292;DYGR &#21516;&#26102;&#36866;&#29992;&#20110;&#20855;&#26377;&#20849;&#20139;&#22270;&#25299;&#25169;&#30340;&#8220;&#27973;&#23618;&#8221;&#19968;&#27493;&#27169;&#22411;&#12290;&#23454;&#39564;&#35777;&#26126; DYGR &#33021;&#22815;&#37325;&#26032;&#26500;&#24314;&#20132;&#20114;&#32467;&#26500;&#65292;&#21516;&#26102;&#33719;&#24471;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Relational inference aims to identify interactions between parts of a dynamical system from the observed dynamics. Current state-of-the-art methods fit a graph neural network (GNN) on a learnable graph to the dynamics. They use one-step message-passing GNNs -- intuitively the right choice since non-locality of multi-step or spectral GNNs may confuse direct and indirect interactions. But the \textit{effective} interaction graph depends on the sampling rate and it is rarely localized to direct neighbors, leading to local minima for the one-step model. In this work, we propose a \textit{dynamical graph prior} (DYGR) for relational inference. The reason we call it a prior is that, contrary to established practice, it constructively uses error amplification in high-degree non-local polynomial filters to generate good gradients for graph learning. To deal with non-uniqueness, DYGR simultaneously fits a ``shallow'' one-step model with shared graph topology. Experiments show that DYGR reconstr
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#21160;&#24577;&#29615;&#22659;&#20013;&#22788;&#29702;&#22810;&#26234;&#33021;&#20307;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#30340;&#20998;&#24067;&#24335;&#20849;&#35782;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#26368;&#23567;&#21270;&#27599;&#20010;&#26102;&#38388;&#27493;&#19981;&#36873;&#25321;&#26368;&#20248;&#33218;&#25152;&#20135;&#29983;&#30340;&#26399;&#26395;&#24635;&#25439;&#22833;&#12290;</title><link>http://arxiv.org/abs/2306.05998</link><description>&lt;p&gt;
&#22810;&#26234;&#33021;&#20307;&#22810;&#33218;&#32769;&#34382;&#26426;&#30340;&#20998;&#24067;&#24335;&#20849;&#35782;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Distributed Consensus Algorithm for Decision-Making in Multi-agent Multi-armed Bandit. (arXiv:2306.05998v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05998
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#21160;&#24577;&#29615;&#22659;&#20013;&#22788;&#29702;&#22810;&#26234;&#33021;&#20307;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#30340;&#20998;&#24067;&#24335;&#20849;&#35782;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#26368;&#23567;&#21270;&#27599;&#20010;&#26102;&#38388;&#27493;&#19981;&#36873;&#25321;&#26368;&#20248;&#33218;&#25152;&#20135;&#29983;&#30340;&#26399;&#26395;&#24635;&#25439;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#21160;&#24577;&#29615;&#22659;&#20013;&#32467;&#26500;&#21270;&#30340;&#22810;&#26234;&#33021;&#20307;&#22810;&#33218;&#32769;&#34382;&#26426;&#38382;&#39064;&#12290;&#22270;&#24418;&#21453;&#26144;&#20102;&#20195;&#29702;&#20043;&#38388;&#30340;&#20449;&#24687;&#20849;&#20139;&#32467;&#26500;&#65292;&#33218;&#30340;&#22870;&#21169;&#20998;&#24067;&#26159;&#20855;&#26377;&#20960;&#20010;&#26410;&#30693;&#21464;&#21270;&#28857;&#30340;&#20998;&#27573;&#23450;&#24120;&#20998;&#24067;&#12290;&#20195;&#29702;&#38754;&#20020;&#30456;&#21516;&#30340;&#20998;&#27573;&#23450;&#24120;MAB&#38382;&#39064;&#12290;&#30446;&#26631;&#26159;&#20026;&#20195;&#29702;&#24320;&#21457;&#19968;&#20010;&#20915;&#31574;&#31574;&#30053;&#65292;&#20351;&#24471;&#21518;&#24724;&#26368;&#23567;&#65292;&#21363;&#27599;&#20010;&#26102;&#38388;&#27493;&#19981;&#36873;&#25321;&#26368;&#20248;&#33218;&#25152;&#20135;&#29983;&#30340;&#26399;&#26395;&#24635;&#25439;&#22833;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#35299;&#20915;&#26041;&#26696;&#26159;&#20855;&#26377;&#36125;&#21494;&#26031;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#30340;&#37325;&#26032;&#21551;&#21160;&#21327;&#20316;UCB&#31639;&#27861;(RBO-Coop-UCB)&#65292;&#20854;&#20013;&#21253;&#25324;&#19968;&#20010;&#39640;&#25928;&#30340;&#22810;&#26234;&#33021;&#20307;UCB&#31639;&#27861;&#20316;&#20026;&#26680;&#24515;&#65292;&#24182;&#25552;&#21319;&#20102;&#21512;&#20316;&#20915;&#31574;&#12290;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;RBO-Coop-UCB&#30340;&#39044;&#26399;&#22242;&#20307;&#21518;&#24724;&#19978;&#30028;&#20026;$\mathcal{O}(KNM\log T + K\sqrt{MT\log T})$&#12290;
&lt;/p&gt;
&lt;p&gt;
We study a structured multi-agent multi-armed bandit (MAMAB) problem in a dynamic environment. A graph reflects the information-sharing structure among agents, and the arms' reward distributions are piecewise-stationary with several unknown change points. The agents face the identical piecewise-stationary MAB problem. The goal is to develop a decision-making policy for the agents that minimizes the regret, which is the expected total loss of not playing the optimal arm at each time step. Our proposed solution, Restarted Bayesian Online Change Point Detection in Cooperative Upper Confidence Bound Algorithm (RBO-Coop-UCB), involves an efficient multi-agent UCB algorithm as its core enhanced with a Bayesian change point detector. We also develop a simple restart decision cooperation that improves decision-making. Theoretically, we establish that the expected group regret of RBO-Coop-UCB is upper bounded by $\mathcal{O}(KNM\log T + K\sqrt{MT\log T})$, where K is the number of agents, M is 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;QBSD&#30340;&#23454;&#26102;&#39044;&#27979;&#26041;&#27861;&#65292;&#20197;&#22312;&#26102;&#38388;&#24207;&#21015;&#24322;&#24120;&#26816;&#27979;&#20013;&#21462;&#24471;&#26368;&#20339;&#24179;&#34913;&#12290;</title><link>http://arxiv.org/abs/2306.05989</link><description>&lt;p&gt;
&#22522;&#20110;&#22235;&#20998;&#20301;&#25968;&#30340;&#23395;&#33410;&#24615;&#20998;&#35299;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#21644;&#24322;&#24120;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Quartile-Based Seasonality Decomposition for Time Series Forecasting and Anomaly Detection. (arXiv:2306.05989v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05989
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;QBSD&#30340;&#23454;&#26102;&#39044;&#27979;&#26041;&#27861;&#65292;&#20197;&#22312;&#26102;&#38388;&#24207;&#21015;&#24322;&#24120;&#26816;&#27979;&#20013;&#21462;&#24471;&#26368;&#20339;&#24179;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#30005;&#20449;&#39046;&#22495;&#65292;&#21450;&#26102;&#26816;&#27979;&#24322;&#24120;&#38750;&#24120;&#37325;&#35201;&#65292;&#22240;&#20026;&#36825;&#26377;&#21161;&#20110;&#35782;&#21035;&#21644;&#34920;&#24449;&#19981;&#35268;&#21017;&#27169;&#24335;&#12289;&#24322;&#24120;&#34892;&#20026;&#21644;&#32593;&#32476;&#24322;&#24120;&#65292;&#20174;&#32780;&#25552;&#39640;&#26381;&#21153;&#36136;&#37327;&#21644;&#25805;&#20316;&#25928;&#29575;&#12290;&#31934;&#30830;&#22320;&#39044;&#27979;&#21644;&#28040;&#38500;&#21487;&#39044;&#27979;&#30340;&#26102;&#38388;&#24207;&#21015;&#27169;&#24335;&#26159;&#26102;&#38388;&#24207;&#21015;&#24322;&#24120;&#26816;&#27979;&#30340;&#37325;&#35201;&#32452;&#25104;&#37096;&#20998;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22522;&#20110;&#22235;&#20998;&#20301;&#25968;&#30340;&#23395;&#33410;&#24615;&#20998;&#35299;&#65288;QBSD&#65289;&#30340;&#23454;&#26102;&#39044;&#27979;&#26041;&#27861;&#65292;&#20197;&#22312;&#35745;&#31639;&#22797;&#26434;&#24230;&#21644;&#39044;&#27979;&#20934;&#30830;&#29575;&#20043;&#38388;&#21462;&#24471;&#26368;&#20339;&#24179;&#34913;&#12290;&#26412;&#25991;&#27604;&#36739;&#20102;QBSD&#19982;&#29616;&#26377;&#39044;&#27979;&#26041;&#27861;&#30340;&#24615;&#33021;&#21450;&#20854;&#36866;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The timely detection of anomalies is essential in the telecom domain as it facilitates the identification and characterization of irregular patterns, abnormal behaviors, and network anomalies, contributing to enhanced service quality and operational efficiency. Precisely forecasting and eliminating predictable time series patterns constitutes a vital component of time series anomaly detection. While the state-of-the-art methods aim to maximize forecasting accuracy, the computational performance takes a hit. In a system composed of a large number of time series variables, e.g., cell Key Performance Indicators (KPIs), the time and space complexity of the forecasting employed is of crucial importance. Quartile-Based Seasonality Decomposition (QBSD) is a live forecasting method proposed in this paper to make an optimal trade-off between computational complexity and forecasting accuracy. This paper compares the performance of QBSD to the state-of-the-art forecasting methods and their applic
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#65292;&#26412;&#30740;&#31350;&#26500;&#24314;&#20102;&#19968;&#20010;&#33258;&#30417;&#30563;&#23398;&#20064;&#27169;&#22411;&#65292;&#29992;&#20110;&#23398;&#20064;&#20195;&#29702;&#24066;&#22330;&#35746;&#21333;&#30340;&#34920;&#31034;&#12290;&#36827;&#19968;&#27493;&#22320;&#65292;&#25105;&#20204;&#20351;&#29992;K&#22343;&#20540;&#32858;&#31867;&#31639;&#27861;&#23545;&#20195;&#29702;&#35746;&#21333;&#30340;&#23398;&#20064;&#34920;&#31034;&#21521;&#37327;&#36827;&#34892;&#32858;&#31867;&#65292;&#20197;&#30830;&#23450;&#27599;&#20010;&#31751;&#20013;&#30340;&#19981;&#21516;&#34892;&#20026;&#31867;&#22411;&#12290;</title><link>http://arxiv.org/abs/2306.05987</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#30340;&#20195;&#29702;&#24066;&#22330;&#35746;&#21333;&#34920;&#31034;
&lt;/p&gt;
&lt;p&gt;
Agent market orders representation through a contrastive learning approach. (arXiv:2306.05987v1 [q-fin.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05987
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#23545;&#27604;&#23398;&#20064;&#26041;&#27861;&#65292;&#26412;&#30740;&#31350;&#26500;&#24314;&#20102;&#19968;&#20010;&#33258;&#30417;&#30563;&#23398;&#20064;&#27169;&#22411;&#65292;&#29992;&#20110;&#23398;&#20064;&#20195;&#29702;&#24066;&#22330;&#35746;&#21333;&#30340;&#34920;&#31034;&#12290;&#36827;&#19968;&#27493;&#22320;&#65292;&#25105;&#20204;&#20351;&#29992;K&#22343;&#20540;&#32858;&#31867;&#31639;&#27861;&#23545;&#20195;&#29702;&#35746;&#21333;&#30340;&#23398;&#20064;&#34920;&#31034;&#21521;&#37327;&#36827;&#34892;&#32858;&#31867;&#65292;&#20197;&#30830;&#23450;&#27599;&#20010;&#31751;&#20013;&#30340;&#19981;&#21516;&#34892;&#20026;&#31867;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#35775;&#38382;Euronext&#30340;CAC40&#25968;&#25454;&#20013;&#30340;&#26631;&#35760;&#35746;&#21333;&#65292;&#20998;&#26512;&#20195;&#29702;&#22312;&#24066;&#22330;&#20013;&#26681;&#25454;&#20854;&#19979;&#36798;&#30340;&#35746;&#21333;&#30340;&#34892;&#20026;&#12290;&#26412;&#30740;&#31350;&#26500;&#24314;&#20102;&#19968;&#20010;&#33258;&#30417;&#30563;&#23398;&#20064;&#27169;&#22411;&#65292;&#20351;&#29992;&#19977;&#20803;&#32452;&#25439;&#22833;&#26469;&#26377;&#25928;&#22320;&#23398;&#20064;&#20195;&#29702;&#24066;&#22330;&#35746;&#21333;&#30340;&#34920;&#31034;&#12290;&#36890;&#36807;&#33719;&#21462;&#36825;&#20010;&#23398;&#20064;&#34920;&#31034;&#65292;&#21508;&#31181;&#19979;&#28216;&#20219;&#21153;&#21464;&#24471;&#21487;&#34892;&#12290;&#26412;&#30740;&#31350;&#20351;&#29992;K&#22343;&#20540;&#32858;&#31867;&#31639;&#27861;&#23545;&#20195;&#29702;&#35746;&#21333;&#30340;&#23398;&#20064;&#34920;&#31034;&#21521;&#37327;&#36827;&#34892;&#32858;&#31867;&#65292;&#20197;&#30830;&#23450;&#27599;&#20010;&#31751;&#20013;&#30340;&#19981;&#21516;&#34892;&#20026;&#31867;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Due to the access to the labeled orders on the CAC40 data from Euronext, we are able to analyse agents' behaviours in the market based on their placed orders. In this study, we construct a self-supervised learning model using triplet loss to effectively learn the representation of agent market orders. By acquiring this learned representation, various downstream tasks become feasible. In this work, we utilise the K-means clustering algorithm on the learned representation vectors of agent orders to identify distinct behaviour types within each cluster.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22522;&#20110;&#33258;&#23450;&#20041;&#28151;&#21512;&#33410;&#28857; Forney &#26679;&#24335;&#30340;&#22240;&#23376;&#22270;&#28040;&#24687;&#20256;&#36882;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#33258;&#21160;&#21270;&#36125;&#21494;&#26031;&#27169;&#22411;&#24179;&#22343;&#12289;&#36873;&#25321;&#21644;&#32452;&#21512;&#65292;&#24182;&#32553;&#30701;&#20102;&#27169;&#22411;&#35774;&#35745;&#21608;&#26399;&#12290;</title><link>http://arxiv.org/abs/2306.05965</link><description>&lt;p&gt;
&#22312;&#22240;&#23376;&#22270;&#20013;&#33258;&#21160;&#36827;&#34892;&#27169;&#22411;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
Automating Model Comparison in Factor Graphs. (arXiv:2306.05965v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05965
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22522;&#20110;&#33258;&#23450;&#20041;&#28151;&#21512;&#33410;&#28857; Forney &#26679;&#24335;&#30340;&#22240;&#23376;&#22270;&#28040;&#24687;&#20256;&#36882;&#65292;&#23454;&#29616;&#20102;&#39640;&#25928;&#33258;&#21160;&#21270;&#36125;&#21494;&#26031;&#27169;&#22411;&#24179;&#22343;&#12289;&#36873;&#25321;&#21644;&#32452;&#21512;&#65292;&#24182;&#32553;&#30701;&#20102;&#27169;&#22411;&#35774;&#35745;&#21608;&#26399;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#25991;&#29486;&#20013;&#65292;&#36125;&#21494;&#26031;&#29366;&#24577;&#21644;&#21442;&#25968;&#20272;&#35745;&#24050;&#32463;&#34987;&#26377;&#25928;&#33258;&#21160;&#21270;&#65292;&#20294;&#23545;&#20110;&#27169;&#22411;&#27604;&#36739;&#23578;&#26410;&#22914;&#27492;&#65292;&#22240;&#27492;&#20173;&#38656;&#35201;&#23481;&#26131;&#20986;&#38169;&#21644;&#32791;&#26102;&#30340;&#25163;&#21160;&#25512;&#23548;&#12290;&#22240;&#27492;&#65292;&#27169;&#22411;&#27604;&#36739;&#32463;&#24120;&#34987;&#24573;&#35270;&#21644;&#24573;&#30053;&#65292;&#23613;&#31649;&#23427;&#24456;&#37325;&#35201;&#12290;&#26412;&#25991;&#36890;&#36807;&#22312;Forney&#26679;&#24335;&#30340;&#22240;&#23376;&#22270;&#19978;&#20351;&#29992;&#33258;&#23450;&#20041;&#28151;&#21512;&#33410;&#28857;&#19978;&#30340;&#28040;&#24687;&#20256;&#36882;&#26469;&#39640;&#25928;&#22320;&#33258;&#21160;&#21270;&#36125;&#21494;&#26031;&#27169;&#22411;&#24179;&#22343;&#12289;&#36873;&#25321;&#21644;&#32452;&#21512;&#12290;&#36827;&#32780;&#21487;&#20351;&#29992;&#32553;&#25918;&#22240;&#23376;&#21516;&#26102;&#25191;&#34892;&#21442;&#25968;&#21644;&#29366;&#24577;&#25512;&#26029;&#20197;&#21450;&#27169;&#22411;&#27604;&#36739;&#12290;&#36825;&#31181;&#26041;&#27861;&#32553;&#30701;&#20102;&#27169;&#22411;&#35774;&#35745;&#21608;&#26399;&#65292;&#21516;&#26102;&#20801;&#35768;&#31616;&#21333;&#22320;&#25193;&#23637;&#21040;&#20998;&#23618;&#21644;&#26102;&#38388;&#27169;&#22411;&#20808;&#39564;&#65292;&#20197;&#36866;&#24212;&#24314;&#27169;&#22797;&#26434;&#30340;&#26102;&#21464;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian state and parameter estimation have been automated effectively in the literature, however, this has not yet been the case for model comparison, which therefore still requires error-prone and time-consuming manual derivations. As a result, model comparison is often overlooked and ignored, despite its importance. This paper efficiently automates Bayesian model averaging, selection, and combination by message passing on a Forney-style factor graph with a custom mixture node. Parameter and state inference, and model comparison can then be executed simultaneously using message passing with scale factors. This approach shortens the model design cycle and allows for the straightforward extension to hierarchical and temporal model priors to accommodate for modeling complicated time-varying processes.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#36335;&#24452;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#36890;&#36807;&#32858;&#21512;&#20174;&#33410;&#28857;&#20986;&#21457;&#30340;&#36335;&#24452;&#26469;&#26356;&#26032;&#33410;&#28857;&#34920;&#31034;&#65292;&#30456;&#27604;&#26631;&#20934;&#22270;&#31070;&#32463;&#32593;&#32476;&#20855;&#26377;&#26356;&#24378;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#33021;&#22815;&#21306;&#20998;&#19968;&#20123;1-WL&#26080;&#27861;&#21306;&#20998;&#30340;&#38750;&#21516;&#26500;&#22270;&#23545;&#12290;</title><link>http://arxiv.org/abs/2306.05955</link><description>&lt;p&gt;
&#36335;&#24452;&#31070;&#32463;&#32593;&#32476;&#65306;&#34920;&#36798;&#33021;&#21147;&#24378;&#19988;&#31934;&#30830;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Path Neural Networks: Expressive and Accurate Graph Neural Networks. (arXiv:2306.05955v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05955
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#36335;&#24452;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#36890;&#36807;&#32858;&#21512;&#20174;&#33410;&#28857;&#20986;&#21457;&#30340;&#36335;&#24452;&#26469;&#26356;&#26032;&#33410;&#28857;&#34920;&#31034;&#65292;&#30456;&#27604;&#26631;&#20934;&#22270;&#31070;&#32463;&#32593;&#32476;&#20855;&#26377;&#26356;&#24378;&#30340;&#34920;&#36798;&#33021;&#21147;&#65292;&#33021;&#22815;&#21306;&#20998;&#19968;&#20123;1-WL&#26080;&#27861;&#21306;&#20998;&#30340;&#38750;&#21516;&#26500;&#22270;&#23545;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#36817;&#26399;&#25104;&#20026;&#20102;&#23398;&#20064;&#22270;&#32467;&#26500;&#25968;&#25454;&#30340;&#26631;&#20934;&#26041;&#27861;&#12290;&#26089;&#20808;&#30340;&#30740;&#31350;&#25581;&#31034;&#20102;&#23427;&#20204;&#30340;&#28508;&#21147;&#65292;&#20063;&#25581;&#31034;&#20102;&#23427;&#20204;&#30340;&#38480;&#21046;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#26631;&#20934;&#30340;GNN&#22312;&#34920;&#36798;&#33021;&#21147;&#19978;&#23384;&#22312;&#23616;&#38480;&#24615;&#12290;&#22312;&#21306;&#20998;&#38750;&#21516;&#26500;&#22270;&#26041;&#38754;&#65292;&#36825;&#20123;&#27169;&#22411;&#30340;&#33021;&#21147;&#19981;&#36229;&#36807;&#19968;&#32500;Weisfeiler-Leman&#65288;1-WL&#65289;&#31639;&#27861;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#36335;&#24452;&#31070;&#32463;&#32593;&#32476;&#65288;PathNNs&#65289;&#65292;&#35813;&#27169;&#22411;&#36890;&#36807;&#32858;&#21512;&#20174;&#33410;&#28857;&#20986;&#21457;&#30340;&#36335;&#24452;&#26469;&#26356;&#26032;&#33410;&#28857;&#34920;&#31034;&#12290;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#19977;&#31181;&#19981;&#21516;&#30340;PathNN&#27169;&#22411;&#21464;&#20307;&#65292;&#20197;&#32858;&#21512;&#21333;&#20010;&#26368;&#30701;&#36335;&#24452;&#12289;&#25152;&#26377;&#26368;&#30701;&#36335;&#24452;&#21644;&#25152;&#26377;&#38271;&#24230;&#19981;&#36229;&#36807;K&#30340;&#31616;&#21333;&#36335;&#24452;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#20854;&#20013;&#20004;&#20010;&#21464;&#20307;&#22312;&#34920;&#36798;&#33021;&#21147;&#19978;&#27604;1-WL&#31639;&#27861;&#20005;&#35880;&#65292;&#21516;&#26102;&#25105;&#20204;&#36890;&#36807;&#23454;&#39564;&#35777;&#23454;&#20102;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#12290;&#25105;&#20204;&#21457;&#29616;&#65292;PathNNs&#21487;&#20197;&#21306;&#20998;&#19968;&#20123;1-WL&#26080;&#27861;&#21306;&#20998;&#30340;&#38750;&#21516;&#26500;&#22270;&#23545;&#65292;&#32780;&#25105;&#20204;&#26368;&#34920;&#36798;&#20016;&#23500;&#30340;PathNN&#21464;&#20307;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph neural networks (GNNs) have recently become the standard approach for learning with graph-structured data. Prior work has shed light into their potential, but also their limitations. Unfortunately, it was shown that standard GNNs are limited in their expressive power. These models are no more powerful than the 1-dimensional Weisfeiler-Leman (1-WL) algorithm in terms of distinguishing non-isomorphic graphs. In this paper, we propose Path Neural Networks (PathNNs), a model that updates node representations by aggregating paths emanating from nodes. We derive three different variants of the PathNN model that aggregate single shortest paths, all shortest paths and all simple paths of length up to K. We prove that two of these variants are strictly more powerful than the 1-WL algorithm, and we experimentally validate our theoretical results. We find that PathNNs can distinguish pairs of non-isomorphic graphs that are indistinguishable by 1-WL, while our most expressive PathNN variant 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#31185;&#23572;&#33707;&#25096;&#27931;&#22827; - &#26031;&#31859;&#23572;&#35834;&#22827;&#25351;&#26631;&#20989;&#25968;&#26469;&#25512;&#26029;&#24930;&#27169;&#24335;&#33391;&#22909;&#22522;&#30784;&#30340;&#20195;&#29702;&#21487;&#35266;&#27979;&#21464;&#37327;&#65292;&#24182;&#26174;&#30528;&#25913;&#21892;Koopman&#31639;&#23376;&#20027;&#35201;&#29305;&#24449;&#20540;&#30340;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2306.05945</link><description>&lt;p&gt;
&#29992;&#31185;&#23572;&#33707;&#25096;&#27931;&#22827; - &#26031;&#31859;&#23572;&#35834;&#22827;&#25351;&#26631;&#20989;&#25968;&#25552;&#39640; Koopman &#31639;&#23376;&#30340;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Improving Estimation of the Koopman Operator with Kolmogorov-Smirnov Indicator Functions. (arXiv:2306.05945v1 [physics.data-an])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05945
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26041;&#27861;&#65292;&#20351;&#29992;&#31185;&#23572;&#33707;&#25096;&#27931;&#22827; - &#26031;&#31859;&#23572;&#35834;&#22827;&#25351;&#26631;&#20989;&#25968;&#26469;&#25512;&#26029;&#24930;&#27169;&#24335;&#33391;&#22909;&#22522;&#30784;&#30340;&#20195;&#29702;&#21487;&#35266;&#27979;&#21464;&#37327;&#65292;&#24182;&#26174;&#30528;&#25913;&#21892;Koopman&#31639;&#23376;&#20027;&#35201;&#29305;&#24449;&#20540;&#30340;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20351;&#29992;&#36817;&#20284;&#30340; Koopman &#31639;&#23376;&#23545;&#39640;&#32500;&#26102;&#38388;&#24207;&#21015;&#36827;&#34892;&#21160;&#21147;&#23398;&#20998;&#26512;&#24050;&#21464;&#24471;&#24456;&#26222;&#36941;&#65292;&#23558;&#20854;&#36716;&#25442;&#20026;&#25490;&#21517;&#21160;&#24577;&#27169;&#24335;&#12290;&#35813;&#26041;&#27861;&#23454;&#38469;&#25104;&#21151;&#30340;&#20851;&#38190;&#22312;&#20110;&#35782;&#21035;&#24418;&#25104;&#33391;&#22909;&#22522;&#30784;&#30340;&#19968;&#32452;&#21487;&#35266;&#27979;&#21464;&#37327;&#26469;&#25193;&#23637;&#24930;&#26494;&#24347;&#27169;&#24335;&#12290;&#28982;&#32780;&#65292;&#33391;&#22909;&#30340;&#21487;&#35266;&#27979;&#21464;&#37327;&#24456;&#38590;&#20107;&#20808;&#35782;&#21035;&#65292;&#24182;&#19988;&#27425;&#20248;&#36873;&#25321;&#21487;&#33021;&#20250;&#23548;&#33268;&#26102;&#38388;&#23610;&#24230;&#30340;&#26174;&#33879;&#20302;&#20272;&#12290;&#36890;&#36807;&#21033;&#29992;&#29992;&#38544;&#39532;&#23572;&#21487;&#22827;&#27169;&#22411; (HMM) &#34920;&#31034;&#24930;&#21160;&#21147;&#23398;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#35745;&#31639;&#26377;&#25928;&#30340;&#20998;&#31867;&#36807;&#31243;&#65292;&#20197;&#25512;&#26029;&#24418;&#25104;&#24930;&#27169;&#24335;&#33391;&#22909;&#22522;&#30784;&#30340;&#20195;&#29702;&#21487;&#35266;&#27979;&#21464;&#37327;&#12290;&#25105;&#20204;&#23558;&#35813;&#26041;&#27861;&#24212;&#29992;&#20110;&#19968;&#20010;&#35299;&#26512;&#21487;&#35299;&#30340;&#27169;&#22411;&#31995;&#32479;&#65292;&#20197;&#21450;&#19977;&#20010;&#19981;&#21516;&#22797;&#26434;&#24230;&#30340;&#34507;&#30333;&#36136;&#31995;&#32479;&#12290;&#25105;&#20204;&#19968;&#33268;&#22320;&#35777;&#26126;&#65292;&#25512;&#26029;&#24471;&#21040;&#30340;&#25351;&#26631;&#20989;&#25968;&#21487;&#20197;&#26174;&#30528;&#25913;&#21892; Koopman &#31639;&#23376;&#30340;&#20027;&#35201;&#29305;&#24449;&#20540;&#30340;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
It has become common to perform kinetic analysis using approximate Koopman operators that transforms high-dimensional time series of observables into ranked dynamical modes. Key to a practical success of the approach is the identification of a set of observables which form a good basis in which to expand the slow relaxation modes. Good observables are, however, difficult to identify {\em a priori} and sub-optimal choices can lead to significant underestimations of characteristic timescales. Leveraging the representation of slow dynamics in terms of Hidden Markov Model (HMM), we propose a simple and computationally efficient clustering procedure to infer surrogate observables that form a good basis for slow modes. We apply the approach to an analytically solvable model system, as well as on three protein systems of different complexities. We consistently demonstrate that the inferred indicator functions can significantly improve the estimation of the leading eigenvalues of the Koopman o
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#32467;&#21512;&#21333;&#27493;&#30340;Fisher&#24471;&#20998;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#28176;&#36827;&#39640;&#25928;&#30340;&#21442;&#25968;&#20272;&#35745;&#65292;&#26159;&#19968;&#31181;&#20248;&#31168;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.05896</link><description>&lt;p&gt;
&#28176;&#36827;&#39640;&#25928;&#21333;&#27493;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#27861;
&lt;/p&gt;
&lt;p&gt;
Asymptotically efficient one-step stochastic gradient descent. (arXiv:2306.05896v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05896
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#65292;&#32467;&#21512;&#21333;&#27493;&#30340;Fisher&#24471;&#20998;&#31639;&#27861;&#65292;&#23454;&#29616;&#20102;&#28176;&#36827;&#39640;&#25928;&#30340;&#21442;&#25968;&#20272;&#35745;&#65292;&#26159;&#19968;&#31181;&#20248;&#31168;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25551;&#36848;&#20102;&#19968;&#31181;&#36890;&#29992;&#12289;&#24555;&#36895;&#21644;&#28176;&#36827;&#39640;&#25928;&#30340;&#21442;&#25968;&#20272;&#35745;&#26041;&#27861;&#12290;&#23427;&#22522;&#20110;&#23545;&#25968;&#20284;&#28982;&#20989;&#25968;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65292;&#32416;&#27491;&#20102;Fisher&#24471;&#20998;&#31639;&#27861;&#30340;&#21333;&#19968;&#27493;&#39588;&#12290;&#25105;&#20204;&#22312;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#24773;&#20917;&#19979;&#29702;&#35770;&#19978;&#21644;&#27169;&#25311;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#23427;&#26159;&#19982;&#36890;&#24120;&#30340;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#24179;&#22343;&#25110;&#33258;&#36866;&#24212;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#26377;&#36259;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
A generic, fast and asymptotically efficient method for parametric estimation is described. It is based on the stochastic gradient descent on the loglikelihood function corrected by a single step of the Fisher scoring algorithm. We show theoretically and by simulations in the i.i.d. setting that it is an interesting alternative to the usual stochastic gradient descent with averaging or the adaptative stochastic gradient descent.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26816;&#27979;&#38750;&#40065;&#26834;&#26041;&#21521;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#23616;&#22495;&#20108;&#27425;&#36924;&#36817;&#26469;&#26816;&#27979;&#23545;&#25239;&#24615;&#25915;&#20987;&#65292;&#24182;&#20026;&#23433;&#20840;&#35266;&#27979;&#21644;&#23545;&#25239;&#24615;&#35266;&#27979;&#20043;&#38388;&#30340;&#22522;&#26412;&#25130;&#27490;&#25552;&#20379;&#20102;&#29702;&#35770;&#22522;&#30784;&#12290;&#24182;&#19988;&#35813;&#26041;&#27861;&#26159;&#38750;&#24120;&#26377;&#25928;&#30340;&#65292;&#33021;&#25104;&#21151;&#26816;&#27979;&#21040;&#23545;&#25239;&#24615;&#26041;&#21521;&#24182;&#20570;&#20986;&#40065;&#26834;&#20915;&#31574;&#12290;</title><link>http://arxiv.org/abs/2306.05873</link><description>&lt;p&gt;
&#26816;&#27979;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#23545;&#25239;&#24615;&#26041;&#21521;&#20197;&#20570;&#20986;&#40065;&#26834;&#20915;&#31574;
&lt;/p&gt;
&lt;p&gt;
Detecting Adversarial Directions in Deep Reinforcement Learning to Make Robust Decisions. (arXiv:2306.05873v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05873
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26816;&#27979;&#38750;&#40065;&#26834;&#26041;&#21521;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#23616;&#22495;&#20108;&#27425;&#36924;&#36817;&#26469;&#26816;&#27979;&#23545;&#25239;&#24615;&#25915;&#20987;&#65292;&#24182;&#20026;&#23433;&#20840;&#35266;&#27979;&#21644;&#23545;&#25239;&#24615;&#35266;&#27979;&#20043;&#38388;&#30340;&#22522;&#26412;&#25130;&#27490;&#25552;&#20379;&#20102;&#29702;&#35770;&#22522;&#30784;&#12290;&#24182;&#19988;&#35813;&#26041;&#27861;&#26159;&#38750;&#24120;&#26377;&#25928;&#30340;&#65292;&#33021;&#25104;&#21151;&#26816;&#27979;&#21040;&#23545;&#25239;&#24615;&#26041;&#21521;&#24182;&#20570;&#20986;&#40065;&#26834;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#30340;&#19981;&#26029;&#21457;&#23637;&#65292;&#29616;&#22312;&#21487;&#20197;&#22312;&#20855;&#26377;&#39640;&#24230;&#22797;&#26434;&#29366;&#24577;&#34920;&#31034;&#30340;MDPs&#20013;&#36827;&#34892;&#23398;&#20064;&#12290;&#28982;&#32780;&#65292;&#36825;&#31181;&#22797;&#26434;&#24230;&#30340;&#22686;&#21152;&#20197;&#21450;&#35266;&#27979;&#31354;&#38388;&#32500;&#24230;&#30340;&#22686;&#21152;&#37117;&#24102;&#26469;&#20102;&#26131;&#21463;&#23545;&#25239;&#24615;&#25915;&#20987;&#30340;&#27874;&#21160;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#31574;&#30053;&#19981;&#31283;&#23450;&#24615;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#28145;&#24230;&#31070;&#32463;&#31574;&#30053;&#25439;&#22833;&#30340;&#23616;&#22495;&#20108;&#27425;&#36924;&#36817;&#26469;&#26816;&#27979;&#36825;&#20123;&#38750;&#40065;&#26834;&#26041;&#21521;&#30340;&#23384;&#22312;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20026;&#23433;&#20840;&#35266;&#27979;&#21644;&#23545;&#25239;&#24615;&#35266;&#27979;&#20043;&#38388;&#30340;&#22522;&#26412;&#25130;&#27490;&#25552;&#20379;&#20102;&#29702;&#35770;&#22522;&#30784;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#25216;&#26415;&#20855;&#26377;&#35745;&#31639;&#19978;&#30340;&#25928;&#29575;&#65292;&#24182;&#19988;&#19981;&#20381;&#36182;&#20110;&#29983;&#25104;&#26368;&#22351;&#24773;&#20917;&#26041;&#21521;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#22312;Arcade Learning Environment&#20013;&#36827;&#34892;&#20102;&#22823;&#37327;&#30340;&#23454;&#39564;&#65292;&#20351;&#29992;&#20102;&#22810;&#31181;&#19981;&#21516;&#30340;&#23545;&#25239;&#24615;&#25915;&#20987;&#25216;&#26415;&#12290;&#26368;&#26174;&#30528;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#26159;&#38750;&#24120;&#26377;&#25928;&#30340;&#65292;&#33021;&#22815;&#25104;&#21151;&#26816;&#27979;&#21040;&#23545;&#25239;&#24615;&#26041;&#21521;&#24182;&#20570;&#20986;&#30456;&#24212;&#30340;&#40065;&#26834;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning in MDPs with highly complex state representations is currently possible due to multiple advancements in reinforcement learning algorithm design. However, this incline in complexity, and furthermore the increase in the dimensions of the observation came at the cost of volatility that can be taken advantage of via adversarial attacks (i.e. moving along worst-case directions in the observation space). To solve this policy instability problem we propose a novel method to detect the presence of these non-robust directions via local quadratic approximation of the deep neural policy loss. Our method provides a theoretical basis for the fundamental cut-off between safe observations and adversarial observations. Furthermore, our technique is computationally efficient, and does not depend on the methods used to produce the worst-case directions. We conduct extensive experiments in the Arcade Learning Environment with several different adversarial attack techniques. Most significantly, w
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#32852;&#37030;&#23398;&#20064;&#35774;&#23450;&#65292;&#25506;&#35752;&#20102;&#36890;&#20449;&#27425;&#25968;&#23545;&#27867;&#21270;&#35823;&#24046;&#30340;&#24433;&#21709;&#65292;&#24182;&#24314;&#31435;&#20102;PAC-Bayes&#21644;&#29575;&#22833;&#30495;&#29702;&#35770;&#38480;&#21046;&#65292;&#36825;&#20123;&#38480;&#21046;&#23545;&#24191;&#27867;&#30340;&#25439;&#22833;&#20989;&#25968;&#21644;&#23398;&#20064;&#31639;&#27861;&#36866;&#29992;&#12290;</title><link>http://arxiv.org/abs/2306.05862</link><description>&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#65306;&#20943;&#23569;&#36890;&#20449;&#27425;&#25968;&#65281;
&lt;/p&gt;
&lt;p&gt;
Federated Learning You May Communicate Less Often!. (arXiv:2306.05862v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05862
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#32852;&#37030;&#23398;&#20064;&#35774;&#23450;&#65292;&#25506;&#35752;&#20102;&#36890;&#20449;&#27425;&#25968;&#23545;&#27867;&#21270;&#35823;&#24046;&#30340;&#24433;&#21709;&#65292;&#24182;&#24314;&#31435;&#20102;PAC-Bayes&#21644;&#29575;&#22833;&#30495;&#29702;&#35770;&#38480;&#21046;&#65292;&#36825;&#20123;&#38480;&#21046;&#23545;&#24191;&#27867;&#30340;&#25439;&#22833;&#20989;&#25968;&#21644;&#23398;&#20064;&#31639;&#27861;&#36866;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25506;&#35752;&#20102;&#32852;&#37030;&#23398;&#20064;(Federated Learning, FL)&#27169;&#22411;&#22312;&#19968;&#33324;&#24615;&#30340;&#35774;&#32622;&#19979;&#30340;&#27867;&#21270;&#35823;&#24046;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#23458;&#25143;&#31471;&#21644;&#21442;&#25968;&#26381;&#21153;&#22120;&#20043;&#38388;&#36890;&#20449;&#27425;&#25968;&#30340;&#27867;&#21270;&#35823;&#24046;&#28436;&#21464;&#65292;&#21363;&#23458;&#25143;&#31471;&#35745;&#31639;&#30340;&#26412;&#22320;&#27169;&#22411;&#22312;&#21442;&#25968;&#26381;&#21153;&#22120;&#19978;&#21512;&#24182;&#30340;&#39057;&#29575;&#23545;&#27867;&#21270;&#35823;&#24046;&#30340;&#24433;&#21709;&#12290;&#25105;&#20204;&#24314;&#31435;&#20102;PAC-Bayes&#21644;&#29575;&#22833;&#30495;&#29702;&#35770;&#23545;&#27867;&#21270;&#35823;&#24046;&#30340;&#38480;&#21046;&#65292;&#26126;&#30830;&#32771;&#34385;&#36890;&#20449;&#27425;&#25968;&#23545;&#35823;&#24046;&#30340;&#24433;&#21709;&#65292;&#21478;&#22806;&#36824;&#32771;&#34385;&#20102;&#21442;&#19982;&#35774;&#22791;&#25968;&#37327;K&#21644;&#20010;&#20154;&#25968;&#25454;&#38598;&#22823;&#23567;n&#23545;&#35823;&#24046;&#30340;&#24433;&#21709;&#12290;&#36825;&#20123;&#38480;&#21046;&#36866;&#29992;&#20110;&#24191;&#27867;&#30340;&#25439;&#22833;&#20989;&#25968;&#21644;&#23398;&#20064;&#31639;&#27861;&#65292;&#20284;&#20046;&#26159;FL&#35774;&#32622;&#20013;&#39318;&#27425;&#20986;&#29616;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23558;&#25105;&#20204;&#30340;&#38480;&#21046;&#24212;&#29992;&#20110;FL&#31867;&#22411;&#30340;&#25903;&#25345;&#21521;&#37327;&#26426;(FSVM)&#65307;&#25105;&#20204;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#25512;&#23548;&#20102;&#26356;&#26126;&#30830;&#30340;&#27867;&#21270;&#35823;&#24046;&#38480;&#21046;&#12290;
&lt;/p&gt;
&lt;p&gt;
We investigate the generalization error of statistical learning models in a Federated Learning (FL) setting. Specifically, we study the evolution of the generalization error with the number of communication rounds between the clients and the parameter server, i.e., the effect on the generalization error of how often the local models as computed by the clients are aggregated at the parameter server. We establish PAC-Bayes and rate-distortion theoretic bounds on the generalization error that account explicitly for the effect of the number of rounds, say $ R \in \mathbb{N}$, in addition to the number of participating devices $K$ and individual datasets size $n$. The bounds, which apply in their generality for a large class of loss functions and learning algorithms, appear to be the first of their kind for the FL setting. Furthermore, we apply our bounds to FL-type Support Vector Machines (FSVM); and we derive (more) explicit bounds on the generalization error in this case. In particular, 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20174;&#39640;&#32500;&#20960;&#20309;&#30340;&#35282;&#24230;&#65292;&#36890;&#36807;&#22312;&#21407;&#22987;&#25439;&#22833;&#20989;&#25968;&#20013;&#24378;&#21046;&#26045;&#21152;&#31232;&#30095;&#24615;&#32422;&#26463;&#65292;&#25551;&#36848;&#20102;&#28145;&#24230;&#32593;&#32476;&#21098;&#26525;&#27604;&#29575;&#30340;&#30456;&#21464;&#28857;&#65292;&#35813;&#28857;&#31561;&#20110;&#26576;&#20123;&#20984;&#20307;&#30340;&#24179;&#26041;&#39640;&#26031;&#23485;&#24230;&#38500;&#20197;&#21442;&#25968;&#30340;&#21407;&#22987;&#32500;&#24230;&#12290;</title><link>http://arxiv.org/abs/2306.05857</link><description>&lt;p&gt;
&#28145;&#24230;&#32593;&#32476;&#21487;&#20197;&#34987;&#21098;&#26525;&#21040;&#22810;&#20040;&#31232;&#30095;&#65306;&#20960;&#20309;&#35270;&#35282;&#19979;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
How Sparse Can We Prune A Deep Network: A Geometric Viewpoint. (arXiv:2306.05857v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05857
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20174;&#39640;&#32500;&#20960;&#20309;&#30340;&#35282;&#24230;&#65292;&#36890;&#36807;&#22312;&#21407;&#22987;&#25439;&#22833;&#20989;&#25968;&#20013;&#24378;&#21046;&#26045;&#21152;&#31232;&#30095;&#24615;&#32422;&#26463;&#65292;&#25551;&#36848;&#20102;&#28145;&#24230;&#32593;&#32476;&#21098;&#26525;&#27604;&#29575;&#30340;&#30456;&#21464;&#28857;&#65292;&#35813;&#28857;&#31561;&#20110;&#26576;&#20123;&#20984;&#20307;&#30340;&#24179;&#26041;&#39640;&#26031;&#23485;&#24230;&#38500;&#20197;&#21442;&#25968;&#30340;&#21407;&#22987;&#32500;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#24230;&#21442;&#25968;&#21270;&#26159;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26368;&#37325;&#35201;&#30340;&#29305;&#24449;&#20043;&#19968;&#12290;&#34429;&#28982;&#23427;&#21487;&#20197;&#25552;&#20379;&#20986;&#33394;&#30340;&#27867;&#21270;&#24615;&#33021;&#65292;&#20294;&#21516;&#26102;&#20063;&#24378;&#21152;&#20102;&#37325;&#22823;&#30340;&#23384;&#20648;&#36127;&#25285;&#65292;&#22240;&#27492;&#26377;&#24517;&#35201;&#30740;&#31350;&#32593;&#32476;&#21098;&#26525;&#12290;&#19968;&#20010;&#33258;&#28982;&#32780;&#22522;&#26412;&#30340;&#38382;&#39064;&#26159;&#65306;&#25105;&#20204;&#33021;&#21098;&#26525;&#19968;&#20010;&#28145;&#24230;&#32593;&#32476;&#21040;&#22810;&#20040;&#31232;&#30095;&#65288;&#20960;&#20046;&#19981;&#24433;&#21709;&#24615;&#33021;&#65289;&#65311;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#37319;&#29992;&#20102;&#31532;&#19968;&#21407;&#29702;&#26041;&#27861;&#65292;&#20855;&#20307;&#22320;&#65292;&#21482;&#36890;&#36807;&#22312;&#21407;&#22987;&#25439;&#22833;&#20989;&#25968;&#20013;&#24378;&#21046;&#26045;&#21152;&#31232;&#30095;&#24615;&#32422;&#26463;&#65292;&#25105;&#20204;&#33021;&#22815;&#20174;&#39640;&#32500;&#20960;&#20309;&#30340;&#35282;&#24230;&#25551;&#36848;&#21098;&#26525;&#27604;&#29575;&#30340;&#23574;&#38160;&#30456;&#21464;&#28857;&#65292;&#35813;&#28857;&#23545;&#24212;&#20110;&#21487;&#34892;&#21644;&#19981;&#21487;&#34892;&#20043;&#38388;&#30340;&#36793;&#30028;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#21098;&#26525;&#27604;&#29575;&#30340;&#30456;&#21464;&#28857;&#31561;&#20110;&#26576;&#20123;&#20984;&#20307;&#30340;&#24179;&#26041;&#39640;&#26031;&#23485;&#24230;&#65292;&#36825;&#20123;&#20984;&#20307;&#26159;&#30001;$l_1$-&#35268;&#21017;&#21270;&#25439;&#22833;&#20989;&#25968;&#24471;&#20986;&#30340;&#65292;&#38500;&#20197;&#21442;&#25968;&#30340;&#21407;&#22987;&#32500;&#24230;&#12290;&#20316;&#20026;&#21103;&#20135;&#21697;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#21098;&#26525;&#36807;&#31243;&#20013;&#21442;&#25968;&#30340;&#20998;&#24067;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
Overparameterization constitutes one of the most significant hallmarks of deep neural networks. Though it can offer the advantage of outstanding generalization performance, it meanwhile imposes substantial storage burden, thus necessitating the study of network pruning. A natural and fundamental question is: How sparse can we prune a deep network (with almost no hurt on the performance)? To address this problem, in this work we take a first principles approach, specifically, by merely enforcing the sparsity constraint on the original loss function, we're able to characterize the sharp phase transition point of pruning ratio, which corresponds to the boundary between the feasible and the infeasible, from the perspective of high-dimensional geometry. It turns out that the phase transition point of pruning ratio equals the squared Gaussian width of some convex body resulting from the $l_1$-regularized loss function, normalized by the original dimension of parameters. As a byproduct, we pr
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#24102;&#26377;&#38543;&#26426;&#26435;&#37325;&#12289;&#20559;&#32622;&#21644;&#25968;&#25454;&#30340;&#22810;&#23618;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#20013;&#19982;&#20043;&#30456;&#20851;&#30340;&#20849;&#36717;&#26680;&#65292;&#21457;&#29616;&#20854;&#32463;&#39564;&#35889;&#20998;&#24067;&#20250;&#25910;&#25947;&#21040;&#19968;&#20010;&#30830;&#23450;&#24615;&#30340;&#26497;&#38480;&#65292;&#36890;&#36807;&#32463;&#20856;&#30697;&#38453;&#36816;&#31639;&#21487;&#20197;&#25551;&#36848;&#36825;&#31181;&#26497;&#38480;&#31561;&#20215;&#29289;&#12290;</title><link>http://arxiv.org/abs/2306.05850</link><description>&lt;p&gt;
&#19982;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#30456;&#20851;&#30340;&#20849;&#36717;&#26680;&#30697;&#38453;&#30340;&#30830;&#23450;&#24615;&#31561;&#20215;
&lt;/p&gt;
&lt;p&gt;
Deterministic equivalent of the Conjugate Kernel matrix associated to Artificial Neural Networks. (arXiv:2306.05850v1 [math.PR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05850
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#24102;&#26377;&#38543;&#26426;&#26435;&#37325;&#12289;&#20559;&#32622;&#21644;&#25968;&#25454;&#30340;&#22810;&#23618;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#20013;&#19982;&#20043;&#30456;&#20851;&#30340;&#20849;&#36717;&#26680;&#65292;&#21457;&#29616;&#20854;&#32463;&#39564;&#35889;&#20998;&#24067;&#20250;&#25910;&#25947;&#21040;&#19968;&#20010;&#30830;&#23450;&#24615;&#30340;&#26497;&#38480;&#65292;&#36890;&#36807;&#32463;&#20856;&#30697;&#38453;&#36816;&#31639;&#21487;&#20197;&#25551;&#36848;&#36825;&#31181;&#26497;&#38480;&#31561;&#20215;&#29289;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19982;&#20855;&#26377;&#38543;&#26426;&#26435;&#37325;&#65292;&#20559;&#32622;&#21644;&#25968;&#25454;&#30340;&#22810;&#23618;&#32447;&#24615;&#23485;&#24230;&#21069;&#39304;&#31070;&#32463;&#32593;&#32476;&#30456;&#20851;&#30340;&#20849;&#36717;&#26680;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#20849;&#36717;&#26680;&#30340;&#32463;&#39564;&#35889;&#20998;&#24067;&#25910;&#25947;&#21040;&#30830;&#23450;&#24615;&#26497;&#38480;&#12290;&#26356;&#20934;&#30830;&#22320;&#35828;&#65292;&#25105;&#20204;&#20026;&#20854;Stieltjes&#21464;&#25442;&#21644;&#20854;&#21487;&#35299;&#37096;&#20998;&#33719;&#24471;&#20102;&#30830;&#23450;&#24615;&#31561;&#20215;&#29289;&#65292;&#24182;&#23558;&#23450;&#37327;&#30028;&#38480;&#28041;&#21450;&#27169;&#22411;&#30340;&#32500;&#24230;&#21644;&#35889;&#21442;&#25968;&#12290;&#26497;&#38480;&#31561;&#20215;&#29289;&#21487;&#20197;&#36890;&#36807;&#36845;&#20195;&#33258;&#30001;&#27979;&#37327;&#21367;&#31215;&#21644;&#28041;&#21450;&#27169;&#22411;&#21442;&#25968;&#30340;&#32463;&#20856;&#30697;&#38453;&#36816;&#31639;&#26469;&#25551;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the Conjugate Kernel associated to a multi-layer linear-width feed-forward neural network with random weights, biases and data. We show that the empirical spectral distribution of the Conjugate Kernel converges to a deterministic limit. More precisely we obtain a deterministic equivalent for its Stieltjes transform and its resolvent, with quantitative bounds involving both the dimension and the spectral parameter. The limiting equivalent objects are described by iterating free convolution of measures and classical matrix operations involving the parameters of the model.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;cSOBER&#65292;&#19968;&#31181;&#22788;&#29702;&#22810;&#26679;&#21270;&#32422;&#26463;&#26465;&#20214;&#12289;&#31163;&#25955;&#21644;&#28151;&#21512;&#31354;&#38388;&#12289;&#26410;&#30693;&#32422;&#26463;&#20197;&#21450;&#26597;&#35810;&#25298;&#32477;&#38382;&#39064;&#30340;&#39046;&#22495;&#26080;&#20851;&#22411;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.05843</link><description>&lt;p&gt;
&#26080;&#39046;&#22495;&#20559;&#35265;&#25209;&#37327;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#36890;&#36807;&#36125;&#21494;&#26031;&#31215;&#20998;&#22788;&#29702;&#22810;&#31181;&#32422;&#26463;&#26465;&#20214;
&lt;/p&gt;
&lt;p&gt;
Domain-Agnostic Batch Bayesian Optimization with Diverse Constraints via Bayesian Quadrature. (arXiv:2306.05843v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05843
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;cSOBER&#65292;&#19968;&#31181;&#22788;&#29702;&#22810;&#26679;&#21270;&#32422;&#26463;&#26465;&#20214;&#12289;&#31163;&#25955;&#21644;&#28151;&#21512;&#31354;&#38388;&#12289;&#26410;&#30693;&#32422;&#26463;&#20197;&#21450;&#26597;&#35810;&#25298;&#32477;&#38382;&#39064;&#30340;&#39046;&#22495;&#26080;&#20851;&#22411;&#36125;&#21494;&#26031;&#20248;&#21270;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#23454;&#19990;&#30028;&#30340;&#20248;&#21270;&#38382;&#39064;&#36890;&#24120;&#20855;&#26377;&#22810;&#26679;&#30340;&#32422;&#26463;&#26465;&#20214;&#12289;&#31163;&#25955;&#21644;&#28151;&#21512;&#31354;&#38388;&#12289;&#39640;&#24230;&#21487;&#24182;&#34892;&#21270;&#31561;&#29305;&#28857;&#12290;&#21516;&#26102;&#65292;&#24403;&#23384;&#22312;&#26410;&#30693;&#32422;&#26463;&#26102;&#65292;&#20363;&#22914;&#22312;&#33647;&#29289;&#21457;&#29616;&#21644;&#21160;&#29289;&#23454;&#39564;&#23433;&#20840;&#24615;&#31561;&#39046;&#22495;&#65292;&#24517;&#39035;&#30830;&#31435;&#26410;&#30693;&#32422;&#26463;&#20043;&#21518;&#25165;&#33021;&#26597;&#35810;&#30446;&#26631;&#20989;&#25968;&#12290;&#29616;&#26377;&#24037;&#20316;&#36890;&#24120;&#20165;&#38024;&#23545;&#19978;&#36848;&#26576;&#20123;&#29305;&#24449;&#32780;&#24182;&#38750;&#32508;&#21512;&#32771;&#34385;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;cSOBER&#65292;&#19968;&#31181;&#22522;&#20110;SOBER&#31639;&#27861;&#30340;&#39046;&#22495;&#26080;&#20851;&#22411;&#35880;&#24910;&#24182;&#34892;&#20027;&#21160;&#37319;&#26679;&#22120;&#65292;&#32771;&#34385;&#21040;&#20102;&#26410;&#30693;&#32422;&#26463;&#24773;&#20917;&#19979;&#30340;&#38598;&#25104;&#35823;&#24046;&#30340;&#24433;&#21709;&#24182;&#25552;&#20986;&#20102;&#22788;&#29702;&#26041;&#27861;&#65292;&#22788;&#29702;&#22810;&#31181;&#32422;&#26463;&#26465;&#20214;&#21644;&#26410;&#30693;&#32422;&#26463;&#26597;&#35810;&#25298;&#32477;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Real-world optimisation problems often feature complex combinations of (1) diverse constraints, (2) discrete and mixed spaces, and are (3) highly parallelisable. (4) There are also cases where the objective function cannot be queried if unknown constraints are not satisfied, e.g. in drug discovery, safety on animal experiments (unknown constraints) must be established before human clinical trials (querying objective function) may proceed. However, most existing works target each of the above three problems in isolation and do not consider (4) unknown constraints with query rejection. For problems with diverse constraints and/or unconventional input spaces, it is difficult to apply these techniques as they are often mutually incompatible. We propose cSOBER, a domain-agnostic prudent parallel active sampler for Bayesian optimisation, based on SOBER of Adachi et al. (2023). We consider infeasibility under unknown constraints as a type of integration error that we can estimate. We propose 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#20598;&#21270;&#25193;&#23637;&#30340;&#26680;&#20027;&#25104;&#20998;&#20998;&#26512;&#26041;&#27861;&#65292;&#20351;KPCA&#33258;&#28982;&#22320;&#25193;&#23637;&#21040;&#22810;&#30446;&#26631;&#20989;&#25968;&#65292;&#24182;&#23548;&#33268;&#36991;&#20813;&#35745;&#31639;&#26684;&#25289;&#22982;&#30697;&#38453;&#30340;&#26114;&#36149;SVD&#30340;&#39640;&#25928;&#26799;&#24230;&#31639;&#27861;&#12290;&#35813;&#26041;&#27861;&#36824;&#33021;&#22312;&#21516;&#19968;&#26694;&#26550;&#20869;&#20419;&#36827;&#31283;&#20581;&#24615;&#21644;&#31232;&#30095;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.05815</link><description>&lt;p&gt;
&#36890;&#36807;&#23545;&#20598;&#21270;&#25193;&#23637;&#26680;&#20027;&#25104;&#20998;&#20998;&#26512;&#65306;&#31232;&#30095;&#24615;&#12289;&#40065;&#26834;&#24615;&#21644;&#24555;&#36895;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Extending Kernel PCA through Dualization: Sparsity, Robustness and Fast Algorithms. (arXiv:2306.05815v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05815
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#23545;&#20598;&#21270;&#25193;&#23637;&#30340;&#26680;&#20027;&#25104;&#20998;&#20998;&#26512;&#26041;&#27861;&#65292;&#20351;KPCA&#33258;&#28982;&#22320;&#25193;&#23637;&#21040;&#22810;&#30446;&#26631;&#20989;&#25968;&#65292;&#24182;&#23548;&#33268;&#36991;&#20813;&#35745;&#31639;&#26684;&#25289;&#22982;&#30697;&#38453;&#30340;&#26114;&#36149;SVD&#30340;&#39640;&#25928;&#26799;&#24230;&#31639;&#27861;&#12290;&#35813;&#26041;&#27861;&#36824;&#33021;&#22312;&#21516;&#19968;&#26694;&#26550;&#20869;&#20419;&#36827;&#31283;&#20581;&#24615;&#21644;&#31232;&#30095;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#23545;&#20598;&#21270;&#20984;&#24046;&#20989;&#25968;&#65292;&#37325;&#26032;&#23457;&#35270;&#26680;&#20027;&#25104;&#20998;&#20998;&#26512;&#65288;KPCA&#65289;&#12290;&#36825;&#31181;&#26041;&#27861;&#20351;KPCA&#33258;&#28982;&#22320;&#25193;&#23637;&#21040;&#22810;&#30446;&#26631;&#20989;&#25968;&#65292;&#24182;&#23548;&#33268;&#36991;&#20813;&#35745;&#31639;&#26684;&#25289;&#22982;&#30697;&#38453;&#30340;&#26114;&#36149;SVD&#30340;&#39640;&#25928;&#26799;&#24230;&#31639;&#27861;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#32771;&#34385;&#21487;&#20197;&#20889;&#25104;Moreau&#21253;&#32476;&#30340;&#30446;&#26631;&#20989;&#25968;&#65292;&#28436;&#31034;&#22914;&#20309;&#22312;&#21516;&#19968;&#26694;&#26550;&#20869;&#20419;&#36827;&#31283;&#20581;&#24615;&#21644;&#31232;&#30095;&#24615;&#12290;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#21512;&#25104;&#21644;&#23454;&#38469;&#22522;&#20934;&#27979;&#35797;&#20013;&#36827;&#34892;&#20102;&#35780;&#20272;&#65292;&#26174;&#31034;&#20986;KPCA&#35757;&#32451;&#26102;&#38388;&#26174;&#33879;&#21152;&#36895;&#65292;&#32780;&#19988;&#22312;&#31283;&#20581;&#24615;&#21644;&#31232;&#30095;&#24615;&#26041;&#38754;&#20855;&#26377;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
The goal of this paper is to revisit Kernel Principal Component Analysis (KPCA) through dualization of a difference of convex functions. This allows to naturally extend KPCA to multiple objective functions and leads to efficient gradient-based algorithms avoiding the expensive SVD of the Gram matrix. Particularly, we consider objective functions that can be written as Moreau envelopes, demonstrating how to promote robustness and sparsity within the same framework. The proposed method is evaluated on synthetic and real-world benchmarks, showing significant speedup in KPCA training time as well as highlighting the benefits in terms of robustness and sparsity.
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#20102;&#22240;&#26524;&#22270;&#21457;&#29616;&#30340;&#36866;&#24212;&#24615;&#22797;&#26434;&#24230;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;r-adaptive&#31639;&#27861;&#22312;&#26368;&#23567;&#21270;&#24635;&#24178;&#39044;&#27425;&#25968;&#30340;&#21516;&#26102;&#27491;&#30830;&#23398;&#20064;&#20986;&#22240;&#26524;&#22270;&#12290;</title><link>http://arxiv.org/abs/2306.05781</link><description>&lt;p&gt;
&#22240;&#26524;&#22270;&#21457;&#29616;&#30340;&#36866;&#24212;&#24615;&#22797;&#26434;&#24230;
&lt;/p&gt;
&lt;p&gt;
Adaptivity Complexity for Causal Graph Discovery. (arXiv:2306.05781v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05781
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#20102;&#22240;&#26524;&#22270;&#21457;&#29616;&#30340;&#36866;&#24212;&#24615;&#22797;&#26434;&#24230;&#65292;&#25552;&#20379;&#20102;&#19968;&#20010;r-adaptive&#31639;&#27861;&#22312;&#26368;&#23567;&#21270;&#24635;&#24178;&#39044;&#27425;&#25968;&#30340;&#21516;&#26102;&#27491;&#30830;&#23398;&#20064;&#20986;&#22240;&#26524;&#22270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22240;&#26524;&#21457;&#29616;&#26159;&#19968;&#20010;&#37325;&#35201;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#20219;&#21153;&#26159;&#35774;&#35745;&#19968;&#20010;&#24178;&#39044;&#31574;&#30053;&#65292;&#22312;&#26368;&#23567;&#21270;&#25191;&#34892;&#24178;&#39044;&#30340;&#25968;&#37327;&#30340;&#21516;&#26102;&#23398;&#20064;&#21253;&#21547;n&#20010;&#33410;&#28857;&#30340;&#22240;&#26524;&#22270;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#23545;&#20110;&#24635;&#20849;$r$&#20010;&#39034;&#24207;&#22238;&#21512;&#65292;&#31639;&#27861;&#35774;&#35745;&#24072;&#22914;&#20309;&#22312;&#26368;&#23567;&#21270;&#24635;&#24178;&#39044;&#27425;&#25968;&#30340;&#21516;&#26102;&#24674;&#22797;&#22240;&#26524;&#22270;&#30340;$r$&#36866;&#24212;&#24615;&#38382;&#39064;&#12290;&#23545;&#20110;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;$r$-adaptive&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#22312;$O(n^2 2^r)$&#30340;&#24635;&#24178;&#39044;&#27425;&#25968;&#19979;&#65292;&#20197;&#39640;&#27010;&#29575;&#27491;&#30830;&#22320;&#23398;&#20064;$n$&#20010;&#33410;&#28857;&#30340;&#22240;&#26524;&#22270;&#65292;&#24182;&#35777;&#26126;&#20102;&#36825;&#20010;&#30028;&#38480;&#26159;&#26368;&#20339;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal discovery from interventional data is an important problem, where the task is to design an interventional strategy that learns the hidden ground truth causal graph $G(V,E)$ on $|V| = n$ nodes while minimizing the number of performed interventions. Most prior interventional strategies broadly fall into two categories: non-adaptive and adaptive. Non-adaptive strategies decide on a single fixed set of interventions to be performed while adaptive strategies can decide on which nodes to intervene on sequentially based on past interventions. While adaptive algorithms may use exponentially fewer interventions than their non-adaptive counterparts, there are practical concerns that constrain the amount of adaptivity allowed. Motivated by this trade-off, we study the problem of $r$-adaptivity, where the algorithm designer recovers the causal graph under a total of $r$ sequential rounds whilst trying to minimize the total number of interventions. For this problem, we provide a $r$-adaptive
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;Shapley&#20540;&#35299;&#37322;&#19981;&#30830;&#23450;&#24615;&#39044;&#27979;&#65292;&#21487;&#20197;&#37327;&#21270;&#27599;&#20010;&#29305;&#24449;&#23545;&#20010;&#21035;&#27169;&#22411;&#36755;&#20986;&#26465;&#20214;&#29109;&#30340;&#36129;&#29486;&#65292;&#36866;&#29992;&#20110;&#21327;&#21464;&#37327;&#36716;&#31227;&#26816;&#27979;&#12289;&#20027;&#21160;&#23398;&#20064;&#12289;&#29305;&#24449;&#36873;&#25321;&#21644;&#27963;&#21160;&#29305;&#24449;&#20215;&#20540;&#35780;&#20272;&#31561;&#26041;&#38754;&#12290;</title><link>http://arxiv.org/abs/2306.05724</link><description>&lt;p&gt;
&#29992;&#20449;&#24687;&#29702;&#35770;&#30340;Shapley&#20540;&#35299;&#37322;&#39044;&#27979;&#30340;&#19981;&#30830;&#23450;&#24615;
&lt;/p&gt;
&lt;p&gt;
Explaining Predictive Uncertainty with Information Theoretic Shapley Values. (arXiv:2306.05724v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05724
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;Shapley&#20540;&#35299;&#37322;&#19981;&#30830;&#23450;&#24615;&#39044;&#27979;&#65292;&#21487;&#20197;&#37327;&#21270;&#27599;&#20010;&#29305;&#24449;&#23545;&#20010;&#21035;&#27169;&#22411;&#36755;&#20986;&#26465;&#20214;&#29109;&#30340;&#36129;&#29486;&#65292;&#36866;&#29992;&#20110;&#21327;&#21464;&#37327;&#36716;&#31227;&#26816;&#27979;&#12289;&#20027;&#21160;&#23398;&#20064;&#12289;&#29305;&#24449;&#36873;&#25321;&#21644;&#27963;&#21160;&#29305;&#24449;&#20215;&#20540;&#35780;&#20272;&#31561;&#26041;&#38754;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21487;&#35299;&#37322;&#20154;&#24037;&#26234;&#33021;&#30740;&#31350;&#20154;&#21592;&#24320;&#21457;&#20102;&#22823;&#37327;&#26041;&#27861;&#26469;&#24110;&#21161;&#29992;&#25143;&#29702;&#35299;&#22797;&#26434;&#30417;&#30563;&#23398;&#20064;&#27169;&#22411;&#30340;&#39044;&#27979;&#32467;&#26524;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#35299;&#37322;&#27169;&#22411;&#36755;&#20986;&#30340;$\textit{&#19981;&#30830;&#23450;&#24615;}$&#21364;&#21463;&#21040;&#20102;&#30456;&#23545;&#36739;&#23569;&#30340;&#20851;&#27880;&#12290;&#25105;&#20204;&#23558;&#24191;&#27867;&#20351;&#29992;&#30340;Shapley&#20540;&#26694;&#26550;&#29992;&#20110;&#35299;&#37322;&#21508;&#31181;&#31867;&#22411;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#65292;&#37327;&#21270;&#27599;&#20010;&#29305;&#24449;&#23545;&#20010;&#21035;&#27169;&#22411;&#36755;&#20986;&#26465;&#20214;&#29109;&#30340;&#36129;&#29486;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#20462;&#25913;&#29305;&#24449;&#20989;&#25968;&#30340;&#21338;&#24328;&#65292;&#24182;&#21457;&#29616;&#20102;&#30001;&#27492;&#20135;&#29983;&#30340;Shapley&#20540;&#19982;&#20449;&#24687;&#35770;&#21644;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#20013;&#30340;&#22522;&#26412;&#37327;&#20043;&#38388;&#30340;&#28145;&#21051;&#32852;&#31995;&#12290;&#25105;&#20204;&#27010;&#36848;&#20102;&#26377;&#35777;&#26126;&#20445;&#35777;&#30340;&#26377;&#38480;&#26679;&#26412;&#35823;&#24046;&#29575;&#25511;&#21046;&#30340;&#25512;&#29702;&#36807;&#31243;&#65292;&#24182;&#23454;&#29616;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#31639;&#27861;&#65292;&#22312;&#30495;&#23454;&#21644;&#27169;&#25311;&#25968;&#25454;&#30340;&#19968;&#31995;&#21015;&#23454;&#39564;&#20013;&#34920;&#29616;&#33391;&#22909;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36866;&#29992;&#20110;&#21327;&#21464;&#37327;&#36716;&#31227;&#26816;&#27979;&#12289;&#20027;&#21160;&#23398;&#20064;&#12289;&#29305;&#24449;&#36873;&#25321;&#21644;&#27963;&#21160;&#29305;&#24449;&#20215;&#20540;&#35780;&#20272;&#31561;&#26041;&#38754;&#12290;
&lt;/p&gt;
&lt;p&gt;
Researchers in explainable artificial intelligence have developed numerous methods for helping users understand the predictions of complex supervised learning models. By contrast, explaining the $\textit{uncertainty}$ of model outputs has received relatively little attention. We adapt the popular Shapley value framework to explain various types of predictive uncertainty, quantifying each feature's contribution to the conditional entropy of individual model outputs. We consider games with modified characteristic functions and find deep connections between the resulting Shapley values and fundamental quantities from information theory and conditional independence testing. We outline inference procedures for finite sample error rate control with provable guarantees, and implement an efficient algorithm that performs well in a range of experiments on real and simulated data. Our method has applications to covariate shift detection, active learning, feature selection, and active feature-val
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#32034;&#20102;&#21033;&#29992;&#23494;&#24230;&#20989;&#25968;&#30340;&#38750;&#32447;&#24615;&#21464;&#25442;&#23545;&#23725;&#30340;&#20272;&#35745;&#65292;&#24182;&#21457;&#29616;&#20854;&#21487;&#20197;&#25913;&#36827;&#23545;&#20999;&#31354;&#38388;&#30340;&#20272;&#35745;&#20197;&#21450;&#22312;&#36817;&#20284;&#24213;&#23618;&#30495;&#23454;&#27969;&#24418;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#27969;&#24418;&#25311;&#21512;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.05722</link><description>&lt;p&gt;
&#21033;&#29992;&#23494;&#24230;&#20989;&#25968;&#30340;&#38750;&#32447;&#24615;&#21464;&#25442;&#20272;&#35745;&#23725;
&lt;/p&gt;
&lt;p&gt;
Estimation of Ridge Using Nonlinear Transformation on Density Function. (arXiv:2306.05722v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05722
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#32034;&#20102;&#21033;&#29992;&#23494;&#24230;&#20989;&#25968;&#30340;&#38750;&#32447;&#24615;&#21464;&#25442;&#23545;&#23725;&#30340;&#20272;&#35745;&#65292;&#24182;&#21457;&#29616;&#20854;&#21487;&#20197;&#25913;&#36827;&#23545;&#20999;&#31354;&#38388;&#30340;&#20272;&#35745;&#20197;&#21450;&#22312;&#36817;&#20284;&#24213;&#23618;&#30495;&#23454;&#27969;&#24418;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#27969;&#24418;&#25311;&#21512;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23725;&#22312;&#20934;&#30830;&#36817;&#20284;&#27969;&#24418;&#30340;&#22522;&#30784;&#32467;&#26500;&#26041;&#38754;&#21457;&#25381;&#30528;&#37325;&#35201;&#20316;&#29992;&#12290;&#26412;&#25991;&#36890;&#36807;&#23558;&#20985;&#38750;&#32447;&#24615;&#21464;&#25442;&#24212;&#29992;&#20110;&#23494;&#24230;&#20989;&#25968;&#20197;&#25506;&#32034;&#23725;&#30340;&#21464;&#21270;&#12290;&#36890;&#36807;&#23545;Hessian&#30697;&#38453;&#30340;&#25512;&#23548;&#21644;&#20998;&#26512;&#65292;&#25105;&#20204;&#21457;&#29616;&#38750;&#32447;&#24615;&#21464;&#25442;&#20135;&#29983;&#20102;Hessian&#30697;&#38453;&#30340;&#31209;&#19968;&#20462;&#25913;&#12290;&#21033;&#29992;&#29305;&#24449;&#20540;&#38382;&#39064;&#30340;&#21464;&#20998;&#24615;&#36136;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#30456;&#24212;&#23725;&#20043;&#38388;&#30340;&#20559;&#24207;&#21253;&#21547;&#20851;&#31995;&#12290;&#25105;&#20204;&#30452;&#35266;&#22320;&#21457;&#29616;&#65292;&#36890;&#36807;Hessian&#30697;&#38453;&#30340;&#31209;&#19968;&#20462;&#25913;&#65292;&#21464;&#25442;&#21487;&#20197;&#23548;&#33268;&#23545;&#20999;&#31354;&#38388;&#30340;&#20272;&#35745;&#25913;&#36827;&#12290;&#20026;&#39564;&#35777;&#25105;&#20204;&#30340;&#29702;&#35770;&#65292;&#25105;&#20204;&#22312;&#21512;&#25104;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#22823;&#37327;&#25968;&#20540;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#19982;&#20854;&#20182;&#27969;&#24418;&#25311;&#21512;&#31639;&#27861;&#30456;&#27604;&#65292;&#25105;&#20204;&#30340;&#21464;&#25442;&#26041;&#27861;&#24471;&#21040;&#30340;&#23725;&#22312;&#36817;&#20284;&#24213;&#23618;&#30495;&#23454;&#27969;&#24418;&#26041;&#38754;&#26356;&#21152;&#20248;&#36234;&#12290;
&lt;/p&gt;
&lt;p&gt;
Ridges play a vital role in accurately approximating the underlying structure of manifolds. In this paper, we explore the ridge's variation by applying a concave nonlinear transformation to the density function. Through the derivation of the Hessian matrix, we observe that nonlinear transformations yield a rank-one modification of the Hessian matrix. Leveraging the variational properties of eigenvalue problems, we establish a partial order inclusion relationship among the corresponding ridges. We intuitively discover that the transformation can lead to improved estimation of the tangent space via rank-one modification of the Hessian matrix. To validate our theories, we conduct extensive numerical experiments on synthetic and real-world datasets that demonstrate the superiority of the ridges obtained from our transformed approach in approximating the underlying truth manifold compared to other manifold fitting algorithms.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#39318;&#27425;&#30740;&#31350;&#20102;&#20855;&#26377;&#32593;&#32476;&#36741;&#21161;&#20449;&#24687;&#30340;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#23398;&#20064;&#38382;&#39064;&#65292;&#24341;&#20837;&#20102;Reg-Graph&#27169;&#22411;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;AMP&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#22312;&#23454;&#39564;&#20013;&#20248;&#20110;&#29616;&#26377;&#30340;&#20960;&#31181;&#32593;&#32476;&#36741;&#21161;&#22238;&#24402;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.05679</link><description>&lt;p&gt;
&#20855;&#26377;&#32593;&#32476;&#36741;&#21161;&#20449;&#24687;&#30340;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Bayes optimal learning in high-dimensional linear regression with network side information. (arXiv:2306.05679v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05679
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#39318;&#27425;&#30740;&#31350;&#20102;&#20855;&#26377;&#32593;&#32476;&#36741;&#21161;&#20449;&#24687;&#30340;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#23398;&#20064;&#38382;&#39064;&#65292;&#24341;&#20837;&#20102;Reg-Graph&#27169;&#22411;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;AMP&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#22312;&#23454;&#39564;&#20013;&#20248;&#20110;&#29616;&#26377;&#30340;&#20960;&#31181;&#32593;&#32476;&#36741;&#21161;&#22238;&#24402;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22522;&#22240;&#32452;&#23398;&#12289;&#34507;&#30333;&#36136;&#32452;&#23398;&#21644;&#31070;&#32463;&#31185;&#23398;&#31561;&#24212;&#29992;&#20013;&#65292;&#20855;&#26377;&#32593;&#32476;&#36741;&#21161;&#20449;&#24687;&#30340;&#30417;&#30563;&#23398;&#20064;&#38382;&#39064;&#32463;&#24120;&#20986;&#29616;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#30740;&#31350;&#20102;&#20855;&#26377;&#32593;&#32476;&#36741;&#21161;&#20449;&#24687;&#30340;&#39640;&#32500;&#32447;&#24615;&#22238;&#24402;&#20013;&#30340;&#36125;&#21494;&#26031;&#26368;&#20248;&#23398;&#20064;&#38382;&#39064;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#39318;&#20808;&#24341;&#20837;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#29983;&#25104;&#27169;&#22411;&#65288;&#31216;&#20026;Reg-Graph&#27169;&#22411;&#65289;&#65292;&#36890;&#36807;&#19968;&#32452;&#20849;&#21516;&#30340;&#28508;&#22312;&#21442;&#25968;&#20026;&#30417;&#30563;&#25968;&#25454;&#21644;&#35266;&#27979;&#21040;&#30340;&#32593;&#32476;&#35774;&#23450;&#20102;&#19968;&#20010;&#32852;&#21512;&#20998;&#24067;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#36817;&#20284;&#28040;&#24687;&#20256;&#36882;&#65288;AMP&#65289;&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#22312;&#38750;&#24120;&#19968;&#33324;&#30340;&#26465;&#20214;&#19979;&#21487;&#35777;&#26126;&#26159;&#36125;&#21494;&#26031;&#26368;&#20248;&#30340;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23545;&#28508;&#22312;&#20449;&#21495;&#21644;&#35266;&#27979;&#21040;&#30340;&#25968;&#25454;&#20043;&#38388;&#30340;&#26497;&#38480;&#20114;&#20449;&#24687;&#36827;&#34892;&#20102;&#34920;&#24449;&#65292;&#20174;&#32780;&#31934;&#30830;&#37327;&#21270;&#20102;&#32593;&#32476;&#36741;&#21161;&#20449;&#24687;&#22312;&#22238;&#24402;&#38382;&#39064;&#20013;&#30340;&#32479;&#35745;&#24433;&#21709;&#12290;&#25105;&#20204;&#23545;&#27169;&#25311;&#25968;&#25454;&#21644;&#23454;&#38469;&#25968;&#25454;&#30340;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#29616;&#26377;&#30340;&#20960;&#31181;&#32593;&#32476;&#36741;&#21161;&#22238;&#24402;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Supervised learning problems with side information in the form of a network arise frequently in applications in genomics, proteomics and neuroscience. For example, in genetic applications, the network side information can accurately capture background biological information on the intricate relations among the relevant genes. In this paper, we initiate a study of Bayes optimal learning in high-dimensional linear regression with network side information. To this end, we first introduce a simple generative model (called the Reg-Graph model) which posits a joint distribution for the supervised data and the observed network through a common set of latent parameters. Next, we introduce an iterative algorithm based on Approximate Message Passing (AMP) which is provably Bayes optimal under very general conditions. In addition, we characterize the limiting mutual information between the latent signal and the data observed, and thus precisely quantify the statistical impact of the network side 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#22522;&#20110;&#31070;&#32463;&#20999;&#21521;&#26680;&#29702;&#35770;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#26041;&#27861;&#20197;&#20943;&#23569;&#36229;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#36807;&#31243;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#21482;&#38656;&#35201;&#20351;&#29992;&#19968;&#31181;&#36741;&#21161;&#32593;&#32476;&#23601;&#21487;&#20197;&#28040;&#38500;&#36825;&#31181;&#19981;&#30830;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.05674</link><description>&lt;p&gt;
&#38754;&#21521;&#36229;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#30340;&#39640;&#25928;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#21644;&#20943;&#23569;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Efficient Uncertainty Quantification and Reduction for Over-Parameterized Neural Networks. (arXiv:2306.05674v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05674
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#22522;&#20110;&#31070;&#32463;&#20999;&#21521;&#26680;&#29702;&#35770;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#26041;&#27861;&#20197;&#20943;&#23569;&#36229;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#20013;&#30340;&#36807;&#31243;&#19981;&#30830;&#23450;&#24615;&#65292;&#24182;&#21482;&#38656;&#35201;&#20351;&#29992;&#19968;&#31181;&#36741;&#21161;&#32593;&#32476;&#23601;&#21487;&#20197;&#28040;&#38500;&#36825;&#31181;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#65288;UQ&#65289;&#23545;&#20110;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#21487;&#38752;&#24615;&#35780;&#20272;&#21644;&#25913;&#36827;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#28145;&#24230;&#23398;&#20064;&#20013;&#65292;&#19981;&#30830;&#23450;&#24615;&#19981;&#20165;&#26469;&#33258;&#25968;&#25454;&#65292;&#36824;&#26469;&#33258;&#35757;&#32451;&#36807;&#31243;&#20013;&#27880;&#20837;&#30340;&#22823;&#37327;&#22122;&#22768;&#21644;&#20559;&#24046;&#12290;&#36825;&#20123;&#22122;&#22768;&#21644;&#20559;&#24046;&#22952;&#30861;&#20102;&#32479;&#35745;&#20445;&#35777;&#30340;&#23454;&#29616;&#65292;&#24182;&#19988;&#30001;&#20110;&#38656;&#35201;&#37325;&#22797;&#30340;&#32593;&#32476;&#37325;&#26032;&#35757;&#32451;&#65292;&#23545;UQ&#25552;&#20986;&#20102;&#35745;&#31639;&#25361;&#25112;&#12290;&#22522;&#20110;&#26368;&#36817;&#30340;&#31070;&#32463;&#20999;&#21521;&#26680;&#29702;&#35770;&#65292;&#25105;&#20204;&#21019;&#24314;&#20102;&#20855;&#26377;&#32479;&#35745;&#20445;&#35777;&#30340;&#26041;&#26696;&#65292;&#20197;&#36890;&#36807;&#38750;&#24120;&#20302;&#30340;&#35745;&#31639;&#37327;&#37327;&#21270;&#21644;&#20943;&#23569;&#36229;&#21442;&#25968;&#21270;&#31070;&#32463;&#32593;&#32476;&#30340;&#36807;&#31243;&#19981;&#30830;&#23450;&#24615;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#25105;&#20204;&#31216;&#20026;&#36807;&#31243;&#22122;&#22768;&#26657;&#27491;&#65288;PNC&#65289;&#39044;&#27979;&#22120;&#65292;&#36890;&#36807;&#21482;&#20351;&#29992;&#19968;&#31181;&#36866;&#24403;&#26631;&#35760;&#25968;&#25454;&#38598;&#19978;&#35757;&#32451;&#30340;&#36741;&#21161;&#32593;&#32476;&#26469;&#28040;&#38500;&#36807;&#31243;&#19981;&#30830;&#23450;&#24615;&#65292;&#32780;&#19981;&#26159;&#20351;&#29992;&#28145;&#23618;&#38598;&#25104;&#20013;&#30340;&#35768;&#22810;&#37325;&#26032;&#35757;&#32451;&#30340;&#32593;&#32476;&#12290;&#27492;&#22806;&#65292;&#36890;&#36807;&#23558;&#25105;&#20204;&#30340;PNC&#39044;&#27979;&#22120;&#19982;&#25152;&#25552;&#20986;&#30340;&#20808;&#39564;&#27169;&#22411;&#32467;&#21512;&#36215;&#26469;&#65292;&#25105;&#20204;&#21487;&#20197;&#26174;&#33879;&#20943;&#23569;&#25152;&#38656;&#30340;&#32593;&#32476;&#27491;&#21017;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Uncertainty quantification (UQ) is important for reliability assessment and enhancement of machine learning models. In deep learning, uncertainties arise not only from data, but also from the training procedure that often injects substantial noises and biases. These hinder the attainment of statistical guarantees and, moreover, impose computational challenges on UQ due to the need for repeated network retraining. Building upon the recent neural tangent kernel theory, we create statistically guaranteed schemes to principally \emph{quantify}, and \emph{remove}, the procedural uncertainty of over-parameterized neural networks with very low computation effort. In particular, our approach, based on what we call a procedural-noise-correcting (PNC) predictor, removes the procedural uncertainty by using only \emph{one} auxiliary network that is trained on a suitably labeled data set, instead of many retrained networks employed in deep ensembles. Moreover, by combining our PNC predictor with su
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22788;&#29702;&#22810;&#26234;&#33021;&#20307;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#31639;&#27861;&#26694;&#26550;&#65292;&#36890;&#36807;&#31283;&#20581;&#27169;&#25311;&#29983;&#25104;&#38543;&#26426;&#22270;&#24182;&#23558;&#21152;&#26435;&#25216;&#26415;&#32467;&#21512;UCB&#31639;&#27861;&#65292;&#20197;&#21327;&#20316;&#26041;&#24335;&#20943;&#23567;&#25972;&#20010;&#31995;&#32479;&#30340;&#24635;&#36951;&#25022;&#12290;</title><link>http://arxiv.org/abs/2306.05579</link><description>&lt;p&gt;
&#20998;&#24067;&#24335;&#38543;&#26426;&#20998;&#24067;&#30340;&#24322;&#26500;&#22870;&#21169;&#22810;&#26234;&#33021;&#20307;&#22810;&#33218;&#36172;&#21338;&#26426;
&lt;/p&gt;
&lt;p&gt;
Decentralized Randomly Distributed Multi-agent Multi-armed Bandit with Heterogeneous Rewards. (arXiv:2306.05579v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05579
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22788;&#29702;&#22810;&#26234;&#33021;&#20307;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#30340;&#31639;&#27861;&#26694;&#26550;&#65292;&#36890;&#36807;&#31283;&#20581;&#27169;&#25311;&#29983;&#25104;&#38543;&#26426;&#22270;&#24182;&#23558;&#21152;&#26435;&#25216;&#26415;&#32467;&#21512;UCB&#31639;&#27861;&#65292;&#20197;&#21327;&#20316;&#26041;&#24335;&#20943;&#23567;&#25972;&#20010;&#31995;&#32479;&#30340;&#24635;&#36951;&#25022;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20998;&#24067;&#24335;&#22810;&#26234;&#33021;&#20307;&#22810;&#33218;&#36172;&#21338;&#26426;&#38382;&#39064;&#65292;&#22810;&#20010;&#23458;&#25143;&#31471;&#36890;&#36807;&#30001;&#29615;&#22659;&#25552;&#20379;&#30340;&#26102;&#38388;&#20381;&#36182;&#24615;&#38543;&#26426;&#22270;&#36827;&#34892;&#36830;&#25509;&#12290;&#27599;&#20010;&#33218;&#30340;&#22870;&#21169;&#20998;&#24067;&#22240;&#23458;&#25143;&#32780;&#24322;&#65292;&#24182;&#19988;&#22870;&#21169;&#26159;&#26681;&#25454;&#21253;&#25324;&#20122;&#25351;&#25968;&#21644;&#20122;&#39640;&#26031;&#20998;&#24067;&#22312;&#20869;&#30340;&#20998;&#24067;&#65292;&#30001;&#29615;&#22659;&#29420;&#31435;&#22320;&#38543;&#26102;&#38388;&#29983;&#25104;&#30340;&#12290;&#27599;&#20010;&#23458;&#25143;&#31471;&#37117;&#20250;&#25289;&#21160;&#19968;&#20010;&#33218;&#65292;&#24182;&#26681;&#25454;&#30001;&#29615;&#22659;&#25552;&#20379;&#30340;&#22270;&#19982;&#37051;&#23621;&#36827;&#34892;&#36890;&#20449;&#12290;&#25105;&#20204;&#30340;&#30446;&#26631;&#26159;&#36890;&#36807;&#21327;&#20316;&#26469;&#20943;&#23567;&#25972;&#20010;&#31995;&#32479;&#30340;&#24635;&#36951;&#25022;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#39318;&#20808;&#25552;&#20379;&#20102;&#20351;&#29992;&#24555;&#36895;&#28151;&#21512;&#39532;&#23572;&#21487;&#22827;&#38142;&#25110;&#38543;&#26426;&#22270;&#27169;&#22411;&#29983;&#25104;&#38543;&#26426;&#22270;&#30340;&#31283;&#20581;&#20223;&#30495;&#26041;&#27861;&#65292;&#28982;&#21518;&#23558;&#22522;&#20110;&#24179;&#22343;&#19968;&#33268;&#24615;&#26041;&#27861;&#21644;&#26032;&#25552;&#20986;&#30340;&#21152;&#26435;&#25216;&#26415;&#20197;&#21450;&#19978;&#32622;&#20449;&#38480;&#32467;&#21512;&#36215;&#26469;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;UCB&#31867;&#22411;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#25105;&#20204;&#30340;&#31639;&#27861;&#32771;&#34385;&#21040;&#20102;&#22270;&#24418;&#20013;&#30340;&#38543;&#26426;&#24615;&#65292;&#28040;&#38500;&#20102;&#38480;&#21046;&#26465;&#20214;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study a decentralized multi-agent multi-armed bandit problem in which multiple clients are connected by time dependent random graphs provided by an environment. The reward distributions of each arm vary across clients and rewards are generated independently over time by an environment based on distributions that include both sub-exponential and sub-gaussian distributions. Each client pulls an arm and communicates with neighbors based on the graph provided by the environment. The goal is to minimize the overall regret of the entire system through collaborations. To this end, we introduce a novel algorithmic framework, which first provides robust simulation methods for generating random graphs using rapidly mixing Markov chains or the random graph model, and then combines an averaging-based consensus approach with a newly proposed weighting technique and the upper confidence bound to deliver a UCB-type solution. Our algorithms account for the randomness in the graphs, removing the con
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807; MACE &#31639;&#27861;&#65292;&#20197;&#38543;&#26426;&#26862;&#26519;&#21644;&#21463;&#38480;&#23725;&#22238;&#24402;&#20248;&#21270;&#32452;&#21512;&#26435;&#37325;&#65292;&#23454;&#29616;&#20102;&#26368;&#22823;&#31243;&#24230;&#30340;&#21487;&#39044;&#27979;&#24615;&#21644;&#30408;&#21033;&#33021;&#21147;&#65292;&#36866;&#29992;&#20110;&#20219;&#20309;&#39044;&#27979;&#31639;&#27861;&#21644;&#39044;&#27979;&#22120;&#38598;&#65292;&#21487;&#20197;&#22788;&#29702;&#22823;&#22411;&#32452;&#21512;&#12290;</title><link>http://arxiv.org/abs/2306.05568</link><description>&lt;p&gt;
&#26368;&#22823;&#26426;&#22120;&#23398;&#20064;&#32452;&#21512;&#30340;&#26500;&#24314;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Maximally Machine-Learnable Portfolios. (arXiv:2306.05568v1 [econ.EM])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05568
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807; MACE &#31639;&#27861;&#65292;&#20197;&#38543;&#26426;&#26862;&#26519;&#21644;&#21463;&#38480;&#23725;&#22238;&#24402;&#20248;&#21270;&#32452;&#21512;&#26435;&#37325;&#65292;&#23454;&#29616;&#20102;&#26368;&#22823;&#31243;&#24230;&#30340;&#21487;&#39044;&#27979;&#24615;&#21644;&#30408;&#21033;&#33021;&#21147;&#65292;&#36866;&#29992;&#20110;&#20219;&#20309;&#39044;&#27979;&#31639;&#27861;&#21644;&#39044;&#27979;&#22120;&#38598;&#65292;&#21487;&#20197;&#22788;&#29702;&#22823;&#22411;&#32452;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#32929;&#31080;&#22238;&#25253;&#65292;&#20219;&#20309;&#24418;&#24335;&#30340;&#21487;&#39044;&#27979;&#24615;&#37117;&#21487;&#20197;&#22686;&#24378;&#35843;&#25972;&#39118;&#38505;&#21518;&#30340;&#30408;&#21033;&#33021;&#21147;&#12290;&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#21327;&#20316;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#65292;&#20248;&#21270;&#32452;&#21512;&#26435;&#37325;&#65292;&#20197;&#20351;&#24471;&#21512;&#25104;&#35777;&#21048;&#26368;&#22823;&#31243;&#24230;&#30340;&#21487;&#39044;&#27979;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;MACE&#65292;Alternating Conditional Expectations&#30340;&#22810;&#20803;&#25193;&#23637;&#65292;&#36890;&#36807;&#22312;&#26041;&#31243;&#30340;&#19968;&#20391;&#20351;&#29992;&#38543;&#26426;&#26862;&#26519;&#21644;&#21463;&#38480;&#23725;&#22238;&#24402;&#22312;&#21478;&#19968;&#20391;&#23454;&#29616;&#20102;&#19978;&#36848;&#30446;&#26631;&#12290;&#30456;&#36739;&#20110;Lo&#21644;MacKinlay&#30340;&#26368;&#22823;&#21487;&#39044;&#27979;&#32452;&#21512;&#26041;&#27861;&#65292;&#26412;&#25991;&#26377;&#20004;&#20010;&#20851;&#38190;&#25913;&#36827;&#12290;&#31532;&#19968;&#65292;&#23427;&#36866;&#29992;&#20110;&#20219;&#20309;&#65288;&#38750;&#32447;&#24615;&#65289;&#39044;&#27979;&#31639;&#27861;&#21644;&#39044;&#27979;&#22120;&#38598;&#12290;&#31532;&#20108;&#65292;&#23427;&#21487;&#20197;&#22788;&#29702;&#22823;&#22411;&#32452;&#21512;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#26085;&#39057;&#21644;&#26376;&#39057;&#30340;&#23454;&#39564;&#65292;&#24182;&#21457;&#29616;&#22312;&#20351;&#29992;&#24456;&#23569;&#30340;&#26465;&#20214;&#20449;&#24687;&#26102;&#65292;&#21487;&#39044;&#27979;&#24615;&#21644;&#30408;&#21033;&#33021;&#21147;&#26174;&#33879;&#22686;&#21152;&#12290;&#26377;&#36259;&#30340;&#26159;&#65292;&#21487;&#39044;&#27979;&#24615;&#22312;&#22909;&#26102;&#21644;&#22351;&#26102;&#37117;&#23384;&#22312;&#65292;&#24182;&#19988;MACE&#25104;&#21151;&#22320;&#23548;&#33322;&#20102;&#20004;&#32773;&#12290;
&lt;/p&gt;
&lt;p&gt;
When it comes to stock returns, any form of predictability can bolster risk-adjusted profitability. We develop a collaborative machine learning algorithm that optimizes portfolio weights so that the resulting synthetic security is maximally predictable. Precisely, we introduce MACE, a multivariate extension of Alternating Conditional Expectations that achieves the aforementioned goal by wielding a Random Forest on one side of the equation, and a constrained Ridge Regression on the other. There are two key improvements with respect to Lo and MacKinlay's original maximally predictable portfolio approach. First, it accommodates for any (nonlinear) forecasting algorithm and predictor set. Second, it handles large portfolios. We conduct exercises at the daily and monthly frequency and report significant increases in predictability and profitability using very little conditioning information. Interestingly, predictability is found in bad as well as good times, and MACE successfully navigates
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#33258;&#36866;&#24212;&#30340;&#36125;&#21494;&#26031;&#28388;&#27874;&#33539;&#24335;&#26469;&#35299;&#20915;&#29616;&#26377;&#27010;&#29575;ODE&#27714;&#35299;&#22120;&#26080;&#27861;&#35299;&#20915;&#30340;&#28145;&#23618;&#30340;&#23616;&#37096;&#26368;&#23567;&#20540;&#38382;&#39064;&#65292;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#27604;&#29616;&#26377;&#27010;&#29575;ODE&#27714;&#35299;&#22120;&#26356;&#31934;&#30830;&#12290;</title><link>http://arxiv.org/abs/2306.05566</link><description>&lt;p&gt;
&#25968;&#25454;&#33258;&#36866;&#24212;&#27010;&#29575;&#20284;&#28982;&#36924;&#36817;&#24120;&#24494;&#20998;&#26041;&#31243;
&lt;/p&gt;
&lt;p&gt;
Data-Adaptive Probabilistic Likelihood Approximation for Ordinary Differential Equations. (arXiv:2306.05566v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05566
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#33258;&#36866;&#24212;&#30340;&#36125;&#21494;&#26031;&#28388;&#27874;&#33539;&#24335;&#26469;&#35299;&#20915;&#29616;&#26377;&#27010;&#29575;ODE&#27714;&#35299;&#22120;&#26080;&#27861;&#35299;&#20915;&#30340;&#28145;&#23618;&#30340;&#23616;&#37096;&#26368;&#23567;&#20540;&#38382;&#39064;&#65292;&#32467;&#26524;&#34920;&#26126;&#35813;&#26041;&#27861;&#27604;&#29616;&#26377;&#27010;&#29575;ODE&#27714;&#35299;&#22120;&#26356;&#31934;&#30830;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;ODEs&#65289;&#30340;&#21442;&#25968;&#25512;&#26029;&#22312;&#35768;&#22810;&#31185;&#23398;&#24212;&#29992;&#20013;&#20855;&#26377;&#22522;&#26412;&#37325;&#35201;&#24615;&#12290;&#34429;&#28982;ODE&#35299;&#36890;&#24120;&#30001;&#30830;&#23450;&#24615;&#31639;&#27861;&#36817;&#20284;&#65292;&#20294;&#26377;&#20851;&#27010;&#29575;&#27714;&#35299;&#22120;&#30340;&#26032;&#30740;&#31350;&#34920;&#26126;&#65292;&#23427;&#20204;&#36890;&#36807;&#26356;&#22909;&#22320;&#32771;&#34385;&#25968;&#23383;&#35823;&#24046;&#20135;&#29983;&#26356;&#21487;&#38752;&#30340;&#21442;&#25968;&#20272;&#35745;&#12290;&#28982;&#32780;&#65292;&#35768;&#22810;ODE&#31995;&#32479;&#23545;&#20854;&#21442;&#25968;&#20540;&#38750;&#24120;&#25935;&#24863;&#12290;&#36825;&#22312;&#20284;&#28982;&#20989;&#25968;&#20013;&#20135;&#29983;&#20102;&#28145;&#23618;&#30340;&#23616;&#37096;&#26368;&#23567;&#20540;&#8212;&#8212;&#29616;&#26377;&#30340;&#27010;&#29575;&#27714;&#35299;&#22120;&#23578;&#26410;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19968;&#31181;&#29992;&#20110;&#27010;&#29575;ODE&#35299;&#30340;&#36125;&#21494;&#26031;&#28388;&#27874;&#33539;&#24335;&#65292;&#36890;&#36807;&#25968;&#25454;&#33258;&#36866;&#24212;&#22320;&#23398;&#20064;&#22024;&#26434;&#30340;ODE&#35266;&#23519;&#32467;&#26524;&#65292;&#21487;&#20197;&#26174;&#30528;&#38477;&#20302;&#21442;&#25968;&#30340;&#25935;&#24863;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36866;&#29992;&#20110;&#20855;&#26377;&#37096;&#20998;&#26410;&#35266;&#27979;&#20998;&#37327;&#21644;&#20219;&#24847;&#38750;&#39640;&#26031;&#22122;&#22768;&#30340;ODEs&#12290;&#20960;&#20010;&#20363;&#23376;&#34920;&#26126;&#65292;&#23427;&#27604;&#29616;&#26377;&#30340;&#27010;&#29575;ODE&#27714;&#35299;&#22120;&#26356;&#31934;&#30830;&#65292;&#29978;&#33267;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#27604;&#31934;&#30830;ODE&#20284;&#28982;&#20989;&#25968;&#26356;&#31934;&#30830;&#12290;
&lt;/p&gt;
&lt;p&gt;
Parameter inference for ordinary differential equations (ODEs) is of fundamental importance in many scientific applications. While ODE solutions are typically approximated by deterministic algorithms, new research on probabilistic solvers indicates that they produce more reliable parameter estimates by better accounting for numerical errors. However, many ODE systems are highly sensitive to their parameter values. This produces deep local minima in the likelihood function -- a problem which existing probabilistic solvers have yet to resolve. Here, we show that a Bayesian filtering paradigm for probabilistic ODE solution can dramatically reduce sensitivity to parameters by learning from the noisy ODE observations in a data-adaptive manner. Our method is applicable to ODEs with partially unobserved components and with arbitrary non-Gaussian noise. Several examples demonstrate that it is more accurate than existing probabilistic ODE solvers, and even in some cases than the exact ODE likel
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31616;&#21333;&#12289;&#36890;&#29992;&#21644;&#39640;&#25928;&#30340;&#21322;&#21442;&#25968;&#36125;&#21494;&#26031;&#22238;&#24402;&#30340;&#33945;&#29305;&#21345;&#27931;&#25512;&#26029;&#31574;&#30053;&#65292;&#21487;&#29992;&#20110;&#32852;&#21512;&#21518;&#39564;&#19968;&#33268;&#24615;&#65292;&#21363;&#20351;&#32463;&#20856;&#30340;&#20284;&#28982;&#20989;&#25968;&#26159;&#38590;&#20197;&#22788;&#29702;&#25110;&#26410;&#30693;&#30340;&#12290;</title><link>http://arxiv.org/abs/2306.05498</link><description>&lt;p&gt;
&#21322;&#21442;&#25968;&#36125;&#21494;&#26031;&#22238;&#24402;&#30340;&#33945;&#29305;&#21345;&#27931;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Monte Carlo inference for semiparametric Bayesian regression. (arXiv:2306.05498v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05498
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31616;&#21333;&#12289;&#36890;&#29992;&#21644;&#39640;&#25928;&#30340;&#21322;&#21442;&#25968;&#36125;&#21494;&#26031;&#22238;&#24402;&#30340;&#33945;&#29305;&#21345;&#27931;&#25512;&#26029;&#31574;&#30053;&#65292;&#21487;&#29992;&#20110;&#32852;&#21512;&#21518;&#39564;&#19968;&#33268;&#24615;&#65292;&#21363;&#20351;&#32463;&#20856;&#30340;&#20284;&#28982;&#20989;&#25968;&#26159;&#38590;&#20197;&#22788;&#29702;&#25110;&#26410;&#30693;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#36716;&#25442;&#23545;&#20110;&#21442;&#25968;&#22238;&#24402;&#27169;&#22411;&#30340;&#24191;&#27867;&#36866;&#29992;&#24615;&#33267;&#20851;&#37325;&#35201;&#65292;&#20294;&#23545;&#20110;&#36125;&#21494;&#26031;&#20998;&#26512;&#65292;&#32852;&#21512;&#25512;&#26029;&#36716;&#25442;&#21644;&#27169;&#22411;&#21442;&#25968;&#36890;&#24120;&#38656;&#35201;&#38480;&#21046;&#24615;&#21442;&#25968;&#36716;&#25442;&#25110;&#38750;&#21442;&#25968;&#34920;&#31034;&#65292;&#36825;&#23545;&#23454;&#29616;&#21644;&#29702;&#35770;&#20998;&#26512;&#26469;&#35828;&#35745;&#31639;&#25928;&#29575;&#20302;&#19979;&#19988;&#32321;&#29712;&#65292;&#38480;&#21046;&#20102;&#20182;&#20204;&#22312;&#23454;&#36341;&#20013;&#30340;&#21487;&#29992;&#24615;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#31616;&#21333;&#12289;&#36890;&#29992;&#21644;&#39640;&#25928;&#30340;&#31574;&#30053;&#65292;&#30452;&#25509;&#36890;&#36807;&#23558;&#36716;&#25442;&#19982;&#29420;&#31435;&#21464;&#37327;&#21644;&#22240;&#21464;&#37327;&#30340;&#36793;&#32536;&#20998;&#24067;&#30456;&#36830;&#30340;&#26041;&#24335;&#26469;&#23450;&#20301;&#26410;&#30693;&#36716;&#25442;&#21644;&#25152;&#26377;&#22238;&#24402;&#27169;&#22411;&#21442;&#25968;&#30340;&#21518;&#39564;&#20998;&#24067;&#65292;&#24182;&#36890;&#36807;&#36125;&#21494;&#26031;&#38750;&#21442;&#25968;&#27169;&#22411;&#20351;&#29992;&#36125;&#21494;&#26031;&#33258;&#20030;&#26041;&#27861;&#12290;&#20851;&#38190;&#26159;&#65292;&#36825;&#31181;&#26041;&#27861;&#22312;&#24191;&#27867;&#30340;&#22238;&#24402;&#27169;&#22411;&#20013;&#37117;&#21487;&#20197;&#23454;&#29616;(1)&#32852;&#21512;&#21518;&#39564;&#19968;&#33268;&#24615;&#65292;&#21253;&#25324;&#22810;&#20010;&#27169;&#22411;&#38169;&#37197;&#24773;&#20917;&#65292;&#21644;(2)&#39640;&#25928;&#30340;&#33945;&#29305;&#21345;&#32599;&#31639;&#27861;&#65292;&#21363;&#20351;&#32463;&#20856;&#30340;&#20284;&#28982;&#20989;&#25968;&#26159;&#38590;&#20197;&#22788;&#29702;&#25110;&#26410;&#30693;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data transformations are essential for broad applicability of parametric regression models. However, for Bayesian analysis, joint inference of the transformation and model parameters typically involves restrictive parametric transformations or nonparametric representations that are computationally inefficient and cumbersome for implementation and theoretical analysis, which limits their usability in practice. This paper introduces a simple, general, and efficient strategy for joint posterior inference of an unknown transformation and all regression model parameters. The proposed approach directly targets the posterior distribution of the transformation by linking it with the marginal distributions of the independent and dependent variables, and then deploys a Bayesian nonparametric model via the Bayesian bootstrap. Crucially, this approach delivers (1) joint posterior consistency under general conditions, including multiple model misspecifications, and (2) efficient Monte Carlo (not Ma
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20197;&#28201;&#24230;&#25351;&#25968;&#27979;&#24230;&#20026;&#22522;&#30784;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#8212;&#8212;$t$-AdaBoost&#65292;&#24182;&#35777;&#26126;&#20854;&#22312;$t\in [0,1)$&#26102;&#21487;&#20197;&#20445;&#25345;AdaBoost&#30340;&#25351;&#25968;&#25910;&#25947;&#36895;&#29575;&#65292;&#21516;&#26102;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2306.05487</link><description>&lt;p&gt;
&#24102;&#28201;&#24230;&#25351;&#25968;&#27979;&#24230;&#30340;&#22686;&#24378;&#23398;&#20064;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Boosting with Tempered Exponential Measures. (arXiv:2306.05487v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05487
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20197;&#28201;&#24230;&#25351;&#25968;&#27979;&#24230;&#20026;&#22522;&#30784;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#8212;&#8212;$t$-AdaBoost&#65292;&#24182;&#35777;&#26126;&#20854;&#22312;$t\in [0,1)$&#26102;&#21487;&#20197;&#20445;&#25345;AdaBoost&#30340;&#25351;&#25968;&#25910;&#25947;&#36895;&#29575;&#65292;&#21516;&#26102;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#8212;&#8212;$t$-AdaBoost&#65292;&#23427;&#26159;AdaBoost&#31639;&#27861;&#30340;&#25512;&#24191;&#12290;&#25105;&#20204;&#20351;&#29992;&#20197;&#28201;&#24230;&#21442;&#25968;$t$&#20026;&#32034;&#24341;&#30340;&#28201;&#24230;&#25351;&#25968;&#27979;&#24230;&#65288;TEM&#65289;&#23545;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;&#24314;&#27169;&#24182;&#35777;&#26126;&#24403;$t\in [0,1)$&#26102;&#65292;&#35813;&#31639;&#27861;&#20445;&#25345;&#20102;AdaBoost&#30340;&#25351;&#25968;&#25910;&#25947;&#36895;&#29575;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#36827;&#34892;&#20102;&#19968;&#20123;&#23454;&#39564;&#65292;&#23558;&#26412;&#31639;&#27861;&#19982;AdaBoost&#31639;&#27861;&#36827;&#34892;&#27604;&#36739;&#65292;&#24182;&#23637;&#31034;&#20102;$t$-AdaBoost&#31639;&#27861;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#30340;&#24615;&#33021;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
One of the most popular ML algorithms, AdaBoost, can be derived from the dual of a relative entropy minimization problem subject to the fact that the positive weights on the examples sum to one. Essentially, harder examples receive higher probabilities. We generalize this setup to the recently introduced {\it tempered exponential measure}s (TEMs) where normalization is enforced on a specific power of the measure and not the measure itself. TEMs are indexed by a parameter $t$ and generalize exponential families ($t=1$). Our algorithm, $t$-AdaBoost, recovers AdaBoost~as a special case ($t=1$). We show that $t$-AdaBoost retains AdaBoost's celebrated exponential convergence rate when $t\in [0,1)$ while allowing a slight improvement of the rate's hidden constant compared to $t=1$. $t$-AdaBoost partially computes on a generalization of classical arithmetic over the reals and brings notable properties like guaranteed bounded leveraging coefficients for $t\in [0,1)$. From the loss that $t$-Ada
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20219;&#21153;&#29305;&#23450;&#30340;&#23454;&#39564;&#35774;&#35745;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#27835;&#30103;&#25928;&#26524;&#35780;&#20272;&#65292;&#24182;&#22312;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#21644;&#26679;&#26412;&#37327;&#19978;&#20248;&#20110;&#20854;&#20182;&#22522;&#20934;&#26041;&#27861;&#65292;&#20363;&#22914;&#22312;&#23450;&#21521;&#33829;&#38144;&#20219;&#21153;&#19978;&#38656;&#35201;&#26356;&#23569;&#30340;&#25968;&#25454;&#26469;&#36798;&#21040;&#19982;RCT&#30456;&#21516;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2306.05484</link><description>&lt;p&gt;
&#20219;&#21153;&#29305;&#23450;&#30340;&#23454;&#39564;&#35774;&#35745;&#29992;&#20110;&#27835;&#30103;&#25928;&#26524;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Task-specific experimental design for treatment effect estimation. (arXiv:2306.05484v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05484
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#20219;&#21153;&#29305;&#23450;&#30340;&#23454;&#39564;&#35774;&#35745;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#27835;&#30103;&#25928;&#26524;&#35780;&#20272;&#65292;&#24182;&#22312;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#21644;&#26679;&#26412;&#37327;&#19978;&#20248;&#20110;&#20854;&#20182;&#22522;&#20934;&#26041;&#27861;&#65292;&#20363;&#22914;&#22312;&#23450;&#21521;&#33829;&#38144;&#20219;&#21153;&#19978;&#38656;&#35201;&#26356;&#23569;&#30340;&#25968;&#25454;&#26469;&#36798;&#21040;&#19982;RCT&#30456;&#21516;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29702;&#35299;&#22240;&#26524;&#20851;&#31995;&#24212;&#35813;&#26159;&#36890;&#36807;&#20154;&#24037;&#26234;&#33021;&#23454;&#29616;&#30495;&#27491;&#24433;&#21709;&#30340;&#26680;&#24515;&#35201;&#27714;&#12290;&#30001;&#20110;&#21453;&#20107;&#23454;&#30340;&#20869;&#22312;&#19981;&#21487;&#35266;&#27979;&#24615;&#65292;&#22823;&#22411;&#38543;&#26426;&#35797;&#39564;&#65288;RCT&#65289;&#26159;&#22240;&#26524;&#25512;&#26029;&#30340;&#26631;&#20934;&#12290;&#20294;&#22823;&#22411;&#23454;&#39564;&#36890;&#24120;&#20195;&#20215;&#39640;&#26114;&#65292;&#32780;&#38543;&#26426;&#21270;&#26412;&#36523;&#20063;&#20855;&#26377;&#25104;&#26412;&#65292;&#20363;&#22914;&#22312;&#35797;&#39564;&#30340;&#26102;&#20505;&#36827;&#34892;&#27425;&#20248;&#20915;&#31574;&#12290;&#26368;&#36817;&#30340;&#30740;&#31350;&#25552;&#20986;&#20102;&#26356;&#21152;&#26679;&#26412;&#39640;&#25928;&#30340;&#26367;&#20195;&#21697;&#65292;&#20294;&#36825;&#20123;&#26367;&#20195;&#21697;&#19981;&#33021;&#36866;&#24212;&#23547;&#27714;&#22240;&#26524;&#25928;&#24212;&#30340;&#19979;&#28216;&#24212;&#29992;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#20219;&#21153;&#29305;&#23450;&#30340;&#23454;&#39564;&#35774;&#35745;&#26041;&#27861;&#65292;&#24182;&#25512;&#23548;&#20986;&#36866;&#29992;&#20110;&#29305;&#23450;&#19979;&#28216;&#24212;&#29992;&#30340;&#37319;&#26679;&#31574;&#30053;&#12290;&#22312;&#19968;&#31995;&#21015;&#37325;&#35201;&#20219;&#21153;&#12289;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#21644;&#26679;&#26412;&#37327;&#19978;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20248;&#20110;&#20854;&#20182;&#22522;&#20934;&#65292;&#20363;&#22914;&#22312;&#23450;&#21521;&#33829;&#38144;&#20219;&#21153;&#19978;&#38656;&#35201;&#19968;&#20010;&#25968;&#37327;&#32423;&#30340;&#26356;&#23569;&#25968;&#25454;&#26469;&#19982;RCT&#30340;&#24615;&#33021;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;
Understanding causality should be a core requirement of any attempt to build real impact through AI. Due to the inherent unobservability of counterfactuals, large randomised trials (RCTs) are the standard for causal inference. But large experiments are generically expensive, and randomisation carries its own costs, e.g. when suboptimal decisions are trialed. Recent work has proposed more sample-efficient alternatives to RCTs, but these are not adaptable to the downstream application for which the causal effect is sought. In this work, we develop a task-specific approach to experimental design and derive sampling strategies customised to particular downstream applications. Across a range of important tasks, real-world datasets, and sample sizes, our method outperforms other benchmarks, e.g. requiring an order-of-magnitude less data to match RCT performance on targeted marketing tasks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24102;&#26377;&#29992;&#25143;&#32423;&#24046;&#20998;&#38544;&#31169;&#30340;&#32852;&#37030;&#32447;&#24615;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#65292;&#20026;CDP&#25552;&#20986;&#20102;&#36817;&#20046;&#26368;&#20248;&#30340;&#32852;&#37030;&#31639;&#27861;\robin&#65292;&#22312;LDP&#19979;&#35777;&#26126;&#20102;&#23398;&#20064;&#24517;&#39035;&#25215;&#21463;&#33267;&#23569;&#19968;&#20010;&#36951;&#25022;&#33192;&#32960;&#22240;&#23376;&#12290;</title><link>http://arxiv.org/abs/2306.05275</link><description>&lt;p&gt;
&#24102;&#26377;&#29992;&#25143;&#32423;&#24046;&#20998;&#38544;&#31169;&#30340;&#32852;&#37030;&#32447;&#24615;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Federated Linear Contextual Bandits with User-level Differential Privacy. (arXiv:2306.05275v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.05275
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24102;&#26377;&#29992;&#25143;&#32423;&#24046;&#20998;&#38544;&#31169;&#30340;&#32852;&#37030;&#32447;&#24615;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#65292;&#20026;CDP&#25552;&#20986;&#20102;&#36817;&#20046;&#26368;&#20248;&#30340;&#32852;&#37030;&#31639;&#27861;\robin&#65292;&#22312;LDP&#19979;&#35777;&#26126;&#20102;&#23398;&#20064;&#24517;&#39035;&#25215;&#21463;&#33267;&#23569;&#19968;&#20010;&#36951;&#25022;&#33192;&#32960;&#22240;&#23376;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#29992;&#25143;&#32423;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#27010;&#24565;&#19979;&#30340;&#32852;&#37030;&#32447;&#24615;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#12290;&#25105;&#20204;&#39318;&#20808;&#20171;&#32461;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#32852;&#37030;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#65292;&#21487;&#20197;&#36866;&#24212;&#39034;&#24207;&#20915;&#31574;&#35774;&#32622;&#20013;DP&#30340;&#21508;&#31181;&#23450;&#20041;&#12290;&#28982;&#21518;&#22312;&#32852;&#37030;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;&#20013;&#27491;&#24335;&#24341;&#20837;&#20102;&#29992;&#25143;&#32423;&#20013;&#24515;DP&#21644;&#26412;&#22320;DP&#65292;&#24182;&#30740;&#31350;&#20102;&#32852;&#37030;&#32447;&#24615;&#19978;&#19979;&#25991;&#24378;&#21270;&#23398;&#20064;&#27169;&#22411;&#20013;&#23398;&#20064;&#36951;&#25022;&#21644;&#30456;&#24212;DP&#20445;&#35777;&#20043;&#38388;&#30340;&#22522;&#26412;&#26435;&#34913;&#12290;&#23545;&#20110;CDP&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#31216;&#20026;\robin&#30340;&#32852;&#37030;&#31639;&#27861;&#65292;&#24182;&#36890;&#36807;&#25512;&#23548;&#22312;&#28385;&#36275;&#29992;&#25143;&#32423;DP&#26102;&#30340;&#20960;&#20046;&#21305;&#37197;&#30340;&#19978;&#30028;&#21644;&#19979;&#30028;&#36951;&#25022;&#30028;&#65292;&#35777;&#26126;&#20854;&#22312;&#23458;&#25143;&#31471;&#25968;&#37327;$M$&#21644;&#38544;&#31169;&#39044;&#31639;$\varepsilon$&#26041;&#38754;&#26159;&#36817;&#20046;&#26368;&#20248;&#30340;&#12290;&#23545;&#20110;LDP&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#20960;&#20010;&#19979;&#30028;&#65292;&#34920;&#26126;&#22312;&#29992;&#25143;&#32423;$(\varepsilon,\delta)$-LDP&#19979;&#23398;&#20064;&#24517;&#39035;&#33267;&#23569;&#25215;&#21463;&#19968;&#20010;&#36951;&#25022;&#33192;&#32960;&#22240;&#23376;&#33267;&#23569;&#20026;{$\min\{1/\varepsilon,M\}$&#25110;$\min\{1/\sqrt{\varepsilon},\sq
&lt;/p&gt;
&lt;p&gt;
This paper studies federated linear contextual bandits under the notion of user-level differential privacy (DP). We first introduce a unified federated bandits framework that can accommodate various definitions of DP in the sequential decision-making setting. We then formally introduce user-level central DP (CDP) and local DP (LDP) in the federated bandits framework, and investigate the fundamental trade-offs between the learning regrets and the corresponding DP guarantees in a federated linear contextual bandits model. For CDP, we propose a federated algorithm termed as \robin and show that it is near-optimal in terms of the number of clients $M$ and the privacy budget $\varepsilon$ by deriving nearly-matching upper and lower regret bounds when user-level DP is satisfied. For LDP, we obtain several lower bounds, indicating that learning under user-level $(\varepsilon,\delta)$-LDP must suffer a regret blow-up factor at least {$\min\{1/\varepsilon,M\}$ or $\min\{1/\sqrt{\varepsilon},\sq
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992;&#28789;&#27963;&#30340;PFN&#20316;&#20026;BO&#20195;&#29702;&#24314;&#27169;&#65292;&#35813;&#27169;&#22411;&#33021;&#22815;&#20801;&#35768;&#36827;&#19968;&#27493;&#20449;&#24687;&#32435;&#20837;&#20197;&#36827;&#34892;&#38750;&#36828;&#35270;BO&#12290;&#22312;&#19977;&#31181;&#19981;&#21516;&#30340;&#38382;&#39064;&#19978;&#24471;&#21040;&#20102;&#24456;&#22909;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2305.17535</link><description>&lt;p&gt;
PFN&#26159;&#36866;&#29992;&#20110;&#23454;&#38469;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#28789;&#27963;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
PFNs Are Flexible Models for Real-World Bayesian Optimization. (arXiv:2305.17535v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.17535
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#28789;&#27963;&#30340;PFN&#20316;&#20026;BO&#20195;&#29702;&#24314;&#27169;&#65292;&#35813;&#27169;&#22411;&#33021;&#22815;&#20801;&#35768;&#36827;&#19968;&#27493;&#20449;&#24687;&#32435;&#20837;&#20197;&#36827;&#34892;&#38750;&#36828;&#35270;BO&#12290;&#22312;&#19977;&#31181;&#19981;&#21516;&#30340;&#38382;&#39064;&#19978;&#24471;&#21040;&#20102;&#24456;&#22909;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#20808;&#39564;&#25968;&#25454;&#25311;&#21512;&#32593;&#32476;(PFNs)&#20316;&#20026;&#36125;&#21494;&#26031;&#20248;&#21270;(BO)&#30340;&#28789;&#27963;&#20195;&#29702;&#12290;PFN&#26159;&#19968;&#31181;&#31070;&#32463;&#36807;&#31243;&#65292;&#34987;&#35757;&#32451;&#29992;&#20110;&#36817;&#20284;&#21518;&#39564;&#39044;&#27979;&#20998;&#24067;(PPD)&#65292;&#36866;&#29992;&#20110;&#20219;&#20309;&#21487;&#26377;&#25928;&#37319;&#26679;&#30340;&#20808;&#39564;&#20998;&#24067;&#12290;&#25105;&#20204;&#25551;&#36848;&#20102;&#22914;&#20309;&#21033;&#29992;&#36825;&#31181;&#28789;&#27963;&#24615;&#26469;&#36827;&#34892;BO&#30340;&#20195;&#29702;&#24314;&#27169;&#12290;&#25105;&#20204;&#20351;&#29992;PFN&#26469;&#27169;&#25311;&#19968;&#20010;&#26420;&#32032;&#39640;&#26031;&#36807;&#31243;(GP)&#65292;&#19968;&#20010;&#20808;&#36827;&#30340;GP&#21644;&#19968;&#20010;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;(BNN)&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#36827;&#19968;&#27493;&#30340;&#20449;&#24687;&#32435;&#20837;&#20808;&#39564;&#65292;&#20363;&#22914;&#20801;&#35768;&#26377;&#20851;&#26368;&#20248;&#20301;&#32622;&#30340;&#25552;&#31034;(&#29992;&#25143;&#20808;&#39564;)&#65292;&#24573;&#30053;&#19981;&#30456;&#20851;&#30340;&#32500;&#24230;&#65292;&#24182;&#36890;&#36807;&#23398;&#20064;&#33719;&#21462;&#20989;&#25968;&#26469;&#25191;&#34892;&#38750;&#36828;&#35270;BO&#12290;&#36825;&#20123;&#25193;&#23637;&#30340;&#28789;&#27963;&#24615;&#20026;&#20351;&#29992;PFN&#36827;&#34892;BO&#24320;&#36767;&#20102;&#24191;&#38420;&#30340;&#21487;&#33021;&#24615;&#12290;&#25105;&#20204;&#22312;&#20154;&#24037;&#39640;&#26031;&#36807;&#31243;&#26679;&#26412;&#21644;&#19977;&#20010;&#19981;&#21516;&#30340;&#36229;&#21442;&#25968;&#20248;&#21270;&#27979;&#35797;&#24179;&#21488;&#19978;&#23637;&#31034;&#20102;PFN&#23545;BO&#30340;&#26377;&#29992;&#24615;&#65306;HPO-B&#12289;Bayesmark&#21644;PD1&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we use Prior-data Fitted Networks (PFNs) as a flexible surrogate for Bayesian Optimization (BO). PFNs are neural processes that are trained to approximate the posterior predictive distribution (PPD) for any prior distribution that can be efficiently sampled from. We describe how this flexibility can be exploited for surrogate modeling in BO. We use PFNs to mimic a naive Gaussian process (GP), an advanced GP, and a Bayesian Neural Network (BNN). In addition, we show how to incorporate further information into the prior, such as allowing hints about the position of optima (user priors), ignoring irrelevant dimensions, and performing non-myopic BO by learning the acquisition function. The flexibility underlying these extensions opens up vast possibilities for using PFNs for BO. We demonstrate the usefulness of PFNs for BO in a large-scale evaluation on artificial GP samples and three different hyperparameter optimization testbeds: HPO-B, Bayesmark, and PD1. We publish code 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21327;&#35843;&#26041;&#27861;&#26469;&#25552;&#39640;&#32858;&#21512;&#26354;&#32447;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#65292;&#24182;&#22312;&#24503;&#22269;&#26085;&#21069;&#30005;&#21147;&#31454;&#25293;&#24066;&#22330;&#36827;&#34892;&#20102;&#23454;&#35777;&#30740;&#31350;&#12290;</title><link>http://arxiv.org/abs/2305.16255</link><description>&lt;p&gt;
&#23618;&#27425;&#39044;&#27979;&#32858;&#21512;&#26354;&#32447;&#24182;&#24212;&#29992;&#20110;&#26085;&#21069;&#30005;&#21147;&#31454;&#25293;
&lt;/p&gt;
&lt;p&gt;
Hierarchical forecasting for aggregated curves with an application to day-ahead electricity price auctions. (arXiv:2305.16255v1 [stat.AP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.16255
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21327;&#35843;&#26041;&#27861;&#26469;&#25552;&#39640;&#32858;&#21512;&#26354;&#32447;&#30340;&#39044;&#27979;&#20934;&#30830;&#24615;&#65292;&#24182;&#22312;&#24503;&#22269;&#26085;&#21069;&#30005;&#21147;&#31454;&#25293;&#24066;&#22330;&#36827;&#34892;&#20102;&#23454;&#35777;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32858;&#21512;&#26354;&#32447;&#22312;&#32463;&#27982;&#21644;&#37329;&#34701;&#20013;&#24456;&#24120;&#35265;&#65292;&#26368;&#31361;&#20986;&#30340;&#20363;&#23376;&#26159;&#20379;&#32473;&#21644;&#38656;&#27714;&#26354;&#32447;&#12290;&#25105;&#20204;&#21457;&#29616;&#25152;&#26377;&#32858;&#21512;&#26354;&#32447;&#37117;&#20855;&#26377;&#20869;&#22312;&#30340;&#23618;&#27425;&#32467;&#26500;&#65292;&#22240;&#27492;&#21487;&#20197;&#20351;&#29992;&#23618;&#27425;&#21327;&#35843;&#26041;&#27861;&#26469;&#25552;&#39640;&#39044;&#27979;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#32858;&#21512;&#26354;&#32447;&#22914;&#20309;&#26500;&#24314;&#25110;&#35299;&#26500;&#30340;&#28145;&#20837;&#29702;&#35770;&#65292;&#24182;&#24471;&#20986;&#36825;&#20123;&#26041;&#27861;&#22312;&#24369;&#20551;&#35774;&#19979;&#26159;&#31561;&#25928;&#30340;&#32467;&#35770;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#22810;&#31181;&#32858;&#21512;&#26354;&#32447;&#30340;&#21327;&#35843;&#26041;&#27861;&#65292;&#21253;&#25324;&#24050;&#32463;&#24314;&#31435;&#30340;&#33258;&#19979;&#32780;&#19978;&#12289;&#33258;&#19978;&#32780;&#19979;&#21644;&#32447;&#24615;&#26368;&#20248;&#21327;&#35843;&#26041;&#27861;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20934;&#21327;&#35843;&#26041;&#27861;&#65292;&#31216;&#20026;&#8220;&#32858;&#21512;-&#19979;&#8221;&#65292;&#20854;&#22797;&#26434;&#24230;&#31867;&#20284;&#20110;&#33258;&#19979;&#32780;&#19978;&#21644;&#33258;&#19978;&#32780;&#19979;&#26041;&#27861;&#65292;&#20294;&#22312;&#36825;&#31181;&#35774;&#32622;&#20013;&#24448;&#24448;&#25552;&#20379;&#26356;&#22909;&#30340;&#20934;&#30830;&#24615;&#12290;&#25105;&#20204;&#23545;&#24503;&#22269;&#26085;&#21069;&#30005;&#21147;&#31454;&#25293;&#24066;&#22330;&#36827;&#34892;&#20102;&#23454;&#35777;&#39044;&#27979;&#30740;&#31350;&#65292;&#39044;&#27979;&#20102;&#38656;&#27714;&#21644;&#20379;&#32473;&#26354;&#32447;&#65292;&#24182;&#23545;&#20854;&#22343;&#34913;&#24615;&#36827;&#34892;&#20102;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Aggregated curves are common structures in economics and finance, and the most prominent examples are supply and demand curves. In this study, we exploit the fact that all aggregated curves have an intrinsic hierarchical structure, and thus hierarchical reconciliation methods can be used to improve the forecast accuracy. We provide an in-depth theory on how aggregated curves can be constructed or deconstructed, and conclude that these methods are equivalent under weak assumptions. We consider multiple reconciliation methods for aggregated curves, including previously established bottom-up, top-down, and linear optimal reconciliation approaches. We also present a new benchmark reconciliation method called 'aggregated-down' with similar complexity to bottom-up and top-down approaches, but it tends to provide better accuracy in this setup. We conducted an empirical forecasting study on the German day-ahead power auction market by predicting the demand and supply curves, where their equili
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#39318;&#20010;&#36890;&#29992;&#30340;&#26041;&#27861;&#26469;&#22788;&#29702;&#22522;&#20110;&#27169;&#25311;&#30340;&#25512;&#35770;&#65288;&#22914;ABC&#21644;NPE&#65289;&#20013;&#30001;&#20110;&#27169;&#22411;&#38169;&#35823;&#24341;&#36215;&#30340;&#19981;&#21487;&#38752;&#25512;&#35770;&#12290;&#36890;&#36807;&#32422;&#26463;&#32479;&#35745;&#37327;&#30340;&#36873;&#25321;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#24809;&#32602;&#19982;&#25968;&#25454;&#21644;&#27169;&#22411;&#20043;&#38388;&#19981;&#21305;&#37197;&#30340;&#32479;&#35745;&#37327;&#26469;&#38450;&#27490;&#19981;&#21487;&#38752;&#25512;&#35770;&#32467;&#26524;&#12290;&#25105;&#20204;&#22312;&#39640;&#32500;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#26412;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2305.15871</link><description>&lt;p&gt;
&#23398;&#20064;&#40065;&#26834;&#32479;&#35745;&#29992;&#20110;&#27169;&#22411;&#38169;&#35823;&#24773;&#20917;&#19979;&#30340;&#22522;&#20110;&#27169;&#25311;&#25512;&#35770;
&lt;/p&gt;
&lt;p&gt;
Learning Robust Statistics for Simulation-based Inference under Model Misspecification. (arXiv:2305.15871v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.15871
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#39318;&#20010;&#36890;&#29992;&#30340;&#26041;&#27861;&#26469;&#22788;&#29702;&#22522;&#20110;&#27169;&#25311;&#30340;&#25512;&#35770;&#65288;&#22914;ABC&#21644;NPE&#65289;&#20013;&#30001;&#20110;&#27169;&#22411;&#38169;&#35823;&#24341;&#36215;&#30340;&#19981;&#21487;&#38752;&#25512;&#35770;&#12290;&#36890;&#36807;&#32422;&#26463;&#32479;&#35745;&#37327;&#30340;&#36873;&#25321;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#24809;&#32602;&#19982;&#25968;&#25454;&#21644;&#27169;&#22411;&#20043;&#38388;&#19981;&#21305;&#37197;&#30340;&#32479;&#35745;&#37327;&#26469;&#38450;&#27490;&#19981;&#21487;&#38752;&#25512;&#35770;&#32467;&#26524;&#12290;&#25105;&#20204;&#22312;&#39640;&#32500;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#35777;&#26126;&#20102;&#26412;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#27169;&#25311;&#30340;&#25512;&#35770;&#26041;&#27861;&#65288;&#22914;&#36817;&#20284;&#36125;&#21494;&#26031;&#35745;&#31639;&#65288;ABC&#65289;&#65292;&#21512;&#25104;&#20284;&#28982;&#24615;&#21644;&#31070;&#32463;&#21518;&#39564;&#20272;&#35745;&#65288;NPE&#65289;&#65289;&#20381;&#36182;&#20110;&#27169;&#25311;&#32479;&#35745;&#37327;&#20197;&#25512;&#26029;&#38590;&#20197;&#35745;&#31639;&#30340;&#20284;&#28982;&#27169;&#22411;&#30340;&#21442;&#25968;&#12290;&#28982;&#32780;&#65292;&#24050;&#30693;&#36825;&#31181;&#26041;&#27861;&#22312;&#27169;&#22411;&#38169;&#35823;&#24773;&#20917;&#19979;&#20250;&#20135;&#29983;&#19981;&#21487;&#20449;&#21644;&#35823;&#23548;&#24615;&#30340;&#25512;&#35770;&#32467;&#26524;&#65292;&#20174;&#32780;&#38459;&#30861;&#20102;&#23427;&#20204;&#30340;&#24191;&#27867;&#24212;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#36890;&#29992;&#26041;&#27861;&#26469;&#22788;&#29702;&#36328;&#19981;&#21516;&#31867;&#21035;&#30340;SBI&#26041;&#27861;&#30340;&#27169;&#22411;&#38169;&#35823;&#24773;&#20917;&#12290;&#21033;&#29992;&#32479;&#35745;&#37327;&#30340;&#36873;&#25321;&#30830;&#23450;SBI&#20013;&#30340;&#35823;&#24046;&#31243;&#24230;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#20010;&#27491;&#21017;&#21270;&#25439;&#22833;&#20989;&#25968;&#65292;&#24809;&#32602;&#37027;&#20123;&#22686;&#21152;&#25968;&#25454;&#21644;&#27169;&#22411;&#20043;&#38388;&#19981;&#21305;&#37197;&#30340;&#32479;&#35745;&#37327;&#12290;&#20197;NPE&#21644;ABC&#20026;&#24212;&#29992;&#26696;&#20363;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#20154;&#24037;&#38169;&#35823;&#35268;&#33539;&#21270;&#30340;&#39640;&#32500;&#26102;&#38388;&#24207;&#21015;&#27169;&#22411;&#19978;&#34920;&#29616;&#20986;&#20248;&#36234;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#36824;&#23558;&#25105;&#20204;&#30340;&#26041;&#27861;&#24212;&#29992;&#20110;&#26469;&#33258;&#26080;&#32447;&#30005;&#20256;&#25773;&#39046;&#22495;&#30340;&#23454;&#38469;&#25968;&#25454;&#12290;
&lt;/p&gt;
&lt;p&gt;
Simulation-based inference (SBI) methods such as approximate Bayesian computation (ABC), synthetic likelihood, and neural posterior estimation (NPE) rely on simulating statistics to infer parameters of intractable likelihood models. However, such methods are known to yield untrustworthy and misleading inference outcomes under model misspecification, thus hindering their widespread applicability. In this work, we propose the first general approach to handle model misspecification that works across different classes of SBI methods. Leveraging the fact that the choice of statistics determines the degree of misspecification in SBI, we introduce a regularized loss function that penalises those statistics that increase the mismatch between the data and the model. Taking NPE and ABC as use cases, we demonstrate the superior performance of our method on high-dimensional time-series models that are artificially misspecified. We also apply our method to real data from the field of radio propagat
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#21152;&#26435;&#30340;&#26368;&#23567;&#26497;&#22823;&#39118;&#38505;&#20998;&#31867;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#36991;&#20813;&#21327;&#21464;&#37327;&#28418;&#31227;&#23545;&#30417;&#30563;&#23398;&#20064;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2305.08637</link><description>&lt;p&gt;
&#20026;&#21327;&#21464;&#37327;&#28418;&#31227;&#33258;&#36866;&#24212;&#24341;&#20837;&#21452;&#37325;&#21152;&#26435;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Double-Weighting for Covariate Shift Adaptation. (arXiv:2305.08637v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.08637
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#21152;&#26435;&#30340;&#26368;&#23567;&#26497;&#22823;&#39118;&#38505;&#20998;&#31867;&#26041;&#27861;&#65292;&#21487;&#20197;&#26377;&#25928;&#36991;&#20813;&#21327;&#21464;&#37327;&#28418;&#31227;&#23545;&#30417;&#30563;&#23398;&#20064;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30417;&#30563;&#23398;&#20064;&#20013;&#24120;&#24120;&#21463;&#21040;&#21327;&#21464;&#37327;&#28418;&#31227;&#24433;&#21709;&#65292;&#21363;&#35757;&#32451;&#26679;&#26412;&#21644;&#27979;&#35797;&#26679;&#26412;&#30340;&#23454;&#20363;&#36793;&#32536;&#20998;&#24067;&#19981;&#21516;&#20294;&#26631;&#31614;&#26465;&#20214;&#30456;&#21516;&#12290;&#29616;&#26377;&#26041;&#27861;&#36890;&#36807;&#20351;&#29992;&#27604;&#29575;p_te&#65288;x&#65289;/p_tr&#65288;x&#65289;&#23545;&#35757;&#32451;&#26679;&#26412;&#36827;&#34892;&#21152;&#26435;&#65288;&#37325;&#26032;&#21152;&#26435;&#26041;&#27861;&#65289;&#65292;&#25110;&#32773;&#20351;&#29992;&#27604;&#29575;p_tr&#65288;x&#65289;/p_te&#65288;x&#65289;&#23545;&#27979;&#35797;&#26679;&#26412;&#36827;&#34892;&#21152;&#26435;&#65288;&#40065;&#26834;&#26041;&#27861;&#65289;&#26469;&#35299;&#20915;&#36825;&#31181;&#21327;&#21464;&#37327;&#28418;&#31227;&#12290;&#28982;&#32780;&#65292;&#22312;&#25903;&#25345;&#19981;&#21305;&#37197;&#25110;&#19978;&#36848;&#27604;&#29575;&#21462;&#22823;&#20540;&#26102;&#65292;&#36825;&#20123;&#26041;&#27861;&#30340;&#24615;&#33021;&#21487;&#33021;&#24456;&#24046;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26368;&#23567;&#26497;&#22823;&#39118;&#38505;&#20998;&#31867;(MRC)&#26041;&#27861;&#65292;&#36890;&#36807;&#23545;&#35757;&#32451;&#26679;&#26412;&#21644;&#27979;&#35797;&#26679;&#26412;&#36827;&#34892;&#21152;&#26435;&#26469;&#36991;&#20813;&#36825;&#31181;&#38480;&#21046;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#26377;&#25928;&#30340;&#25216;&#26415;&#26469;&#33719;&#24471;&#20004;&#32452;&#21152;&#26435;&#65292;&#24182;&#25512;&#24191;&#20102;&#20256;&#32479;&#30340;&#26680;&#22343;&#20540;&#21305;&#37197;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#26032;&#30340;&#29983;&#25104;&#27169;&#22411;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#26469;&#35777;&#26126;&#25105;&#20204;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Supervised learning is often affected by a covariate shift in which the marginal distributions of instances (covariates $x$) of training and testing samples $\mathrm{p}_\text{tr}(x)$ and $\mathrm{p}_\text{te}(x)$ are different but the label conditionals coincide. Existing approaches address such covariate shift by either using the ratio $\mathrm{p}_\text{te}(x)/\mathrm{p}_\text{tr}(x)$ to weight training samples (reweighting methods) or using the ratio $\mathrm{p}_\text{tr}(x)/\mathrm{p}_\text{te}(x)$ to weight testing samples (robust methods). However, the performance of such approaches can be poor under support mismatch or when the above ratios take large values. We propose a minimax risk classification (MRC) approach for covariate shift adaptation that avoids such limitations by weighting both training and testing samples. In addition, we develop effective techniques that obtain both sets of weights and generalize the conventional kernel mean matching method. We provide novel genera
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#37319;&#29992;&#36125;&#21494;&#26031;&#26694;&#26550;&#19979;&#30340;&#38543;&#26426;&#21160;&#24577;&#35268;&#21010;&#26041;&#27861;&#65292;&#24320;&#21457;&#19968;&#31181;&#39034;&#24207;&#25277;&#26679;&#31574;&#30053;&#65292;&#25552;&#39640;&#20102;&#36873;&#25321;&#19978;&#19979;&#25991;&#30456;&#20851;&#35774;&#35745;&#30340;&#21069;m&#20010;&#30340;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2305.04086</link><description>&lt;p&gt;
&#36873;&#25321;&#21069;m&#20010;&#19978;&#19979;&#25991;&#30456;&#20851;&#35774;&#35745;&#30340;&#39640;&#25928;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Efficient Learning for Selecting Top-m Context-Dependent Designs. (arXiv:2305.04086v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.04086
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#37319;&#29992;&#36125;&#21494;&#26031;&#26694;&#26550;&#19979;&#30340;&#38543;&#26426;&#21160;&#24577;&#35268;&#21010;&#26041;&#27861;&#65292;&#24320;&#21457;&#19968;&#31181;&#39034;&#24207;&#25277;&#26679;&#31574;&#30053;&#65292;&#25552;&#39640;&#20102;&#36873;&#25321;&#19978;&#19979;&#25991;&#30456;&#20851;&#35774;&#35745;&#30340;&#21069;m&#20010;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#19968;&#20010;&#38024;&#23545;&#19978;&#19979;&#25991;&#30456;&#20851;&#20915;&#31574;&#30340;&#27169;&#25311;&#20248;&#21270;&#38382;&#39064;&#65292;&#26088;&#22312;&#30830;&#23450;&#25152;&#26377;&#19978;&#19979;&#25991;&#24773;&#22659;&#19979;&#30340;&#21069;m&#20010;&#35774;&#35745;&#12290;&#22312;&#36125;&#21494;&#26031;&#26694;&#26550;&#19979;&#65292;&#25105;&#20204;&#23558;&#26368;&#20248;&#21160;&#24577;&#25277;&#26679;&#20915;&#31574;&#21046;&#23450;&#20026;&#38543;&#26426;&#21160;&#24577;&#35268;&#21010;&#38382;&#39064;&#65292;&#24182;&#24320;&#21457;&#19968;&#31181;&#39034;&#24207;&#25277;&#26679;&#31574;&#30053;&#65292;&#20197;&#39640;&#25928;&#22320;&#23398;&#20064;&#27599;&#20010;&#19978;&#19979;&#25991;&#24773;&#22659;&#19979;&#27599;&#20010;&#35774;&#35745;&#30340;&#24615;&#33021;&#12290;&#23548;&#20986;&#20102;&#28176;&#36827;&#26368;&#20248;&#25277;&#26679;&#27604;&#20363;&#20197;&#23454;&#29616;&#36873;&#25321;&#35823;&#25253;&#27010;&#29575;&#30340;&#26368;&#22351;&#24773;&#20917;&#30340;&#26368;&#20248;&#22823;&#20559;&#24046;&#29575;&#12290;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#25277;&#26679;&#31574;&#30053;&#26159;&#19968;&#33268;&#30340;&#65292;&#24182;&#19988;&#20854;&#28176;&#36817;&#25277;&#26679;&#27604;&#29575;&#26159;&#28176;&#36817;&#26368;&#20248;&#30340;&#12290;&#25968;&#23383;&#23454;&#39564;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#25913;&#21892;&#20102;&#36873;&#25321;&#19978;&#19979;&#25991;&#30456;&#20851;&#35774;&#35745;&#30340;&#21069;m&#20010;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider a simulation optimization problem for a context-dependent decision-making, which aims to determine the top-m designs for all contexts. Under a Bayesian framework, we formulate the optimal dynamic sampling decision as a stochastic dynamic programming problem, and develop a sequential sampling policy to efficiently learn the performance of each design under each context. The asymptotically optimal sampling ratios are derived to attain the optimal large deviations rate of the worst-case of probability of false selection. The proposed sampling policy is proved to be consistent and its asymptotic sampling ratios are asymptotically optimal. Numerical experiments demonstrate that the proposed method improves the efficiency for selection of top-m context-dependent designs.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#38543;&#26426;&#22806;&#25512;&#25216;&#26415;&#65292;&#29992;&#20110;&#38477;&#20302;&#26465;&#20214;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#20013;&#30340;&#20559;&#24046;&#65292;&#24182;&#35777;&#26126;&#22312;&#38750;&#20984;&#20809;&#28369;&#30446;&#26631;&#20989;&#25968;&#20013;&#65292;&#23558;&#22806;&#25512;&#19982;&#26041;&#24046;&#32553;&#20943;&#25216;&#26415;&#30456;&#32467;&#21512;&#21487;&#20197;&#26174;&#33879;&#25913;&#21892;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2304.10613</link><description>&lt;p&gt;
&#28040;&#38500;&#26465;&#20214;&#38543;&#26426;&#20248;&#21270;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
Debiasing Conditional Stochastic Optimization. (arXiv:2304.10613v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10613
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#38543;&#26426;&#22806;&#25512;&#25216;&#26415;&#65292;&#29992;&#20110;&#38477;&#20302;&#26465;&#20214;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#20013;&#30340;&#20559;&#24046;&#65292;&#24182;&#35777;&#26126;&#22312;&#38750;&#20984;&#20809;&#28369;&#30446;&#26631;&#20989;&#25968;&#20013;&#65292;&#23558;&#22806;&#25512;&#19982;&#26041;&#24046;&#32553;&#20943;&#25216;&#26415;&#30456;&#32467;&#21512;&#21487;&#20197;&#26174;&#33879;&#25913;&#21892;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#35206;&#30422;&#20102;&#22810;&#20010;&#24212;&#29992;&#39046;&#22495;&#65292;&#21253;&#25324;&#25237;&#36164;&#32452;&#21512;&#36873;&#25321;&#12289;&#24378;&#21270;&#23398;&#20064;&#12289;&#40065;&#26834;&#23398;&#20064;&#12289;&#22240;&#26524;&#25512;&#26029;&#31561;&#30340;&#26465;&#20214;&#38543;&#26426;&#20248;&#21270;&#65288;CSO&#65289;&#38382;&#39064;&#12290;&#30001;&#20110;&#20854;&#23884;&#22871;&#32467;&#26500;&#65292;CSO&#30446;&#26631;&#30340;&#26679;&#26412;&#24179;&#22343;&#26799;&#24230;&#23384;&#22312;&#20559;&#24046;&#65292;&#22240;&#27492;&#38656;&#35201;&#36739;&#39640;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#25165;&#33021;&#36798;&#21040;&#25910;&#25947;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26377;&#25928;&#38477;&#20302;&#20559;&#24046;&#30340;&#36890;&#29992;&#38543;&#26426;&#22806;&#25512;&#25216;&#26415;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#38750;&#20984;&#20809;&#28369;&#30446;&#26631;&#20989;&#25968;&#20013;&#65292;&#23558;&#36825;&#31181;&#22806;&#25512;&#19982;&#26041;&#24046;&#32553;&#20943;&#25216;&#26415;&#30456;&#32467;&#21512;&#65292;&#21487;&#20197;&#36798;&#21040;&#27604;&#29616;&#26377;&#30028;&#38480;&#26356;&#22909;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#29992;&#20110;&#26377;&#38480;&#21644;&#21464;&#37327;&#30340;CSO&#30340;&#26032;&#31639;&#27861;&#65292;&#20063;&#26174;&#33879;&#25913;&#36827;&#20102;&#29616;&#26377;&#32467;&#26524;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35748;&#20026;&#25105;&#20204;&#30340;&#21435;&#20559;&#25216;&#26415;&#20063;&#21487;&#33021;&#26159;&#36866;&#29992;&#20110;&#20854;&#20182;&#38543;&#26426;&#20248;&#21270;&#38382;&#39064;&#30340;&#26377;&#36259;&#24037;&#20855;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study the conditional stochastic optimization (CSO) problem which covers a variety of applications including portfolio selection, reinforcement learning, robust learning, causal inference, etc. The sample-averaged gradient of the CSO objective is biased due to its nested structure and therefore requires a high sample complexity to reach convergence. We introduce a general stochastic extrapolation technique that effectively reduces the bias. We show that for nonconvex smooth objectives, combining this extrapolation with variance reduction techniques can achieve a significantly better sample complexity than existing bounds. We also develop new algorithms for the finite-sum variant of CSO that also significantly improve upon existing results. Finally, we believe that our debiasing technique could be an interesting tool applicable to other stochastic optimization problems too.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#21453;&#23556;&#25193;&#25955;&#27169;&#22411;&#65292;&#36890;&#36807;&#23398;&#20064;&#21453;&#23556;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#25200;&#21160;&#35780;&#20998;&#20989;&#25968;&#65292;&#23558;&#25968;&#25454;&#32422;&#26463;&#21407;&#21017;&#24615;&#22320;&#25972;&#21512;&#21040;&#29983;&#25104;&#36807;&#31243;&#20013;&#65292;&#20197;&#21462;&#20195;&#20043;&#21069;&#37319;&#29992;&#30340;&#23548;&#33268;&#19981;&#33258;&#28982;&#26679;&#26412;&#30340;&#38408;&#20540;&#22788;&#29702;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2304.04740</link><description>&lt;p&gt;
&#21453;&#23556;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Reflected Diffusion Models. (arXiv:2304.04740v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04740
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#21453;&#23556;&#25193;&#25955;&#27169;&#22411;&#65292;&#36890;&#36807;&#23398;&#20064;&#21453;&#23556;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#25200;&#21160;&#35780;&#20998;&#20989;&#25968;&#65292;&#23558;&#25968;&#25454;&#32422;&#26463;&#21407;&#21017;&#24615;&#22320;&#25972;&#21512;&#21040;&#29983;&#25104;&#36807;&#31243;&#20013;&#65292;&#20197;&#21462;&#20195;&#20043;&#21069;&#37319;&#29992;&#30340;&#23548;&#33268;&#19981;&#33258;&#28982;&#26679;&#26412;&#30340;&#38408;&#20540;&#22788;&#29702;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#20998;&#25968;&#30340;&#25193;&#25955;&#27169;&#22411;&#23398;&#20064;&#23558;&#25968;&#25454;&#26144;&#23556;&#21040;&#22122;&#22768;&#30340;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#30340;&#21453;&#21521;&#12290;&#28982;&#32780;&#65292;&#23545;&#20110;&#22797;&#26434;&#20219;&#21153;&#65292;&#25968;&#20540;&#35823;&#24046;&#21487;&#20197;&#32047;&#31215;&#24182;&#23548;&#33268;&#39640;&#24230;&#19981;&#33258;&#28982;&#30340;&#26679;&#26412;&#12290;&#20197;&#21069;&#30340;&#24037;&#20316;&#36890;&#36807;&#38408;&#20540;&#22788;&#29702;&#26469;&#32531;&#35299;&#28418;&#31227;&#65292;&#27599;&#27425;&#25193;&#25955;&#27493;&#39588;&#21518;&#25237;&#24433;&#21040;&#33258;&#28982;&#25968;&#25454;&#22495;&#65288;&#20363;&#22914;&#22270;&#20687;&#30340;&#20687;&#32032;&#31354;&#38388;&#65289;&#65292;&#20294;&#36825;&#23548;&#33268;&#35757;&#32451;&#21644;&#29983;&#25104;&#36807;&#31243;&#20043;&#38388;&#23384;&#22312;&#19981;&#21305;&#37197;&#12290;&#20026;&#20102;&#20197;&#19968;&#31181;&#21407;&#21017;&#24615;&#30340;&#26041;&#24335;&#21512;&#24182;&#25968;&#25454;&#32422;&#26463;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#21453;&#23556;&#25193;&#25955;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#21453;&#21521;&#28436;&#21270;&#22312;&#25968;&#25454;&#25903;&#25345;&#30340;&#21453;&#23556;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#19978;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#36890;&#36807;&#19968;&#33324;&#21270;&#30340;&#20998;&#25968;&#21305;&#37197;&#25439;&#22833;&#20989;&#25968;&#23398;&#20064;&#25200;&#21160;&#35780;&#20998;&#20989;&#25968;&#65292;&#24182;&#25193;&#23637;&#20102;&#26631;&#20934;&#25193;&#25955;&#27169;&#22411;&#30340;&#20851;&#38190;&#32452;&#20214;&#65292;&#21253;&#25324;&#25193;&#25955;&#24341;&#23548;&#12289;&#22522;&#20110;&#20284;&#28982;&#30340;&#35757;&#32451;&#21644;ODE&#37319;&#26679;&#12290;&#25105;&#20204;&#36824;&#24357;&#21512;&#20102;&#38408;&#20540;&#22788;&#29702;&#30340;&#29702;&#35770;&#24046;&#36317;:&#36825;&#26679;&#30340;&#26041;&#26696;&#21482;&#26159;&#21453;&#23556;SDE&#30340;&#31163;&#25955;&#21270;&#12290;&#22312;&#26631;&#20934;&#22270;&#20687;&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;&#25105;&#20204;&#30340;
&lt;/p&gt;
&lt;p&gt;
Score-based diffusion models learn to reverse a stochastic differential equation that maps data to noise. However, for complex tasks, numerical error can compound and result in highly unnatural samples. Previous work mitigates this drift with thresholding, which projects to the natural data domain (such as pixel space for images) after each diffusion step, but this leads to a mismatch between the training and generative processes. To incorporate data constraints in a principled manner, we present Reflected Diffusion Models, which instead reverse a reflected stochastic differential equation evolving on the support of the data. Our approach learns the perturbed score function through a generalize score matching loss and extends key components of standard diffusion models including diffusion guidance, likelihood-based training, and ODE sampling. We also bridge the theoretical gap with thresholding: such schemes are just discretizations of reflected SDEs. On standard image benchmarks, our 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#24179;&#28369;&#65288;&#24378;&#65289;&#20984;&#26377;&#38480;&#21644;&#26368;&#23567;&#21270;&#38382;&#39064;&#30340;&#26080;&#26367;&#25442;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#25910;&#25947;&#19979;&#30028;&#65292;&#25552;&#20986;&#20102;&#20855;&#26377;&#27604;&#29616;&#26377;&#19979;&#30028;&#26356;&#32039;&#30340;$k$&#20381;&#36182;&#24615;&#30340;&#19979;&#30028;&#65292;&#24182;&#36890;&#36807;&#22312;&#24378;&#20984;&#21644;&#20984;&#24773;&#20917;&#19979;&#23436;&#20840;&#28040;&#38500;&#21152;&#26435;&#24179;&#22343;&#36845;&#20195;&#30340;&#19978;&#19979;&#30028;&#24046;&#36317;&#65292;&#35777;&#26126;&#20102;&#20854;&#21487;&#34892;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.07160</link><description>&lt;p&gt;
&#25913;&#36827; Shuffling SGD &#30340;&#25910;&#25947;&#19979;&#30028;&#65306;&#38543;&#26426;&#32622;&#25442;&#21450;&#20854;&#20182;
&lt;/p&gt;
&lt;p&gt;
Tighter Lower Bounds for Shuffling SGD: Random Permutations and Beyond. (arXiv:2303.07160v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.07160
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24179;&#28369;&#65288;&#24378;&#65289;&#20984;&#26377;&#38480;&#21644;&#26368;&#23567;&#21270;&#38382;&#39064;&#30340;&#26080;&#26367;&#25442;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#25910;&#25947;&#19979;&#30028;&#65292;&#25552;&#20986;&#20102;&#20855;&#26377;&#27604;&#29616;&#26377;&#19979;&#30028;&#26356;&#32039;&#30340;$k$&#20381;&#36182;&#24615;&#30340;&#19979;&#30028;&#65292;&#24182;&#36890;&#36807;&#22312;&#24378;&#20984;&#21644;&#20984;&#24773;&#20917;&#19979;&#23436;&#20840;&#28040;&#38500;&#21152;&#26435;&#24179;&#22343;&#36845;&#20195;&#30340;&#19978;&#19979;&#30028;&#24046;&#36317;&#65292;&#35777;&#26126;&#20102;&#20854;&#21487;&#34892;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24179;&#28369;&#65288;&#24378;&#65289;&#20984;&#26377;&#38480;&#21644;&#26368;&#23567;&#21270;&#38382;&#39064;&#30340;&#26080;&#26367;&#25442;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#25910;&#25947;&#19979;&#30028;&#12290;&#19982;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#32467;&#26524;&#20391;&#37325;&#20110;&#26368;&#32456;&#36845;&#20195;&#19979;&#30028;&#65292;&#36825;&#20123;&#19979;&#30028;&#26159;&#20851;&#20110;&#32452;&#20214;&#25968;$n$&#21644;&#36845;&#20195;&#27425;&#25968;$K$&#30340;&#65292;&#25105;&#20204;&#23547;&#27714;&#21508;&#31181;&#24102;&#26435;&#37325;&#24179;&#22343;&#36845;&#20195;&#30340;&#19979;&#30028;&#65292;&#36825;&#20123;&#19979;&#30028;&#22312;&#21253;&#25324;&#26465;&#20214;&#25968;$k$&#22312;&#20869;&#30340;&#25152;&#26377;&#22240;&#32032;&#20013;&#37117;&#26159;&#32039;&#30340;&#12290;&#23545;&#20110;&#24102;&#38543;&#26426;&#27927;&#29260;&#30340;SGD&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20855;&#26377;&#27604;&#29616;&#26377;&#19979;&#30028;&#26356;&#32039;&#30340;$k$&#20381;&#36182;&#24615;&#30340;&#19979;&#30028;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#26159;&#39318;&#20010;&#22312;&#24378;&#20984;&#21644;&#20984;&#24773;&#20917;&#19979;&#23436;&#20840;&#28040;&#38500;&#21152;&#26435;&#24179;&#22343;&#36845;&#20195;&#30340;&#19978;&#19979;&#30028;&#24046;&#36317;&#30340;&#12290;&#25105;&#20204;&#36824;&#20026;&#20219;&#24847;&#22522;&#20110;&#32622;&#25442;&#30340;SGD&#35777;&#26126;&#20102;&#21152;&#26435;&#24179;&#22343;&#36845;&#20195;&#30340;&#19979;&#30028;&#65292;&#36825;&#36866;&#29992;&#20110;&#25152;&#26377;&#23567;&#24515;&#36873;&#25321;&#26368;&#20339;&#32622;&#25442;&#30340;&#21464;&#20307;&#12290;&#25105;&#20204;&#30340;&#19979;&#30028;&#22312;$n$&#21644;$k$&#22240;&#32032;&#26041;&#38754;&#37117;&#20248;&#20110;&#29616;&#26377;&#19979;&#30028;&#65292;&#20174;&#32780;&#19982;&#26368;&#36817;&#25552;&#20986;&#30340;&#31639;&#27861;&#30340;&#19978;&#30028;&#30456;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study convergence lower bounds of without-replacement stochastic gradient descent (SGD) for solving smooth (strongly-)convex finite-sum minimization problems. Unlike most existing results focusing on final iterate lower bounds in terms of the number of components $n$ and the number of epochs $K$, we seek bounds for arbitrary weighted average iterates that are tight in all factors including the condition number $\kappa$. For SGD with Random Reshuffling, we present lower bounds that have tighter $\kappa$ dependencies than existing bounds. Our results are the first to perfectly close the gap between lower and upper bounds for weighted average iterates in both strongly-convex and convex cases. We also prove weighted average iterate lower bounds for arbitrary permutation-based SGD, which apply to all variants that carefully choose the best permutation. Our bounds improve the existing bounds in factors of $n$ and $\kappa$ and thereby match the upper bounds shown for a recently proposed al
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#24179;&#28369;&#38750;&#20984;ERM&#30340;&#24046;&#20998;&#38544;&#31169;&#20248;&#21270;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#37319;&#29992;&#32447;&#24615;&#25628;&#32034;&#12289;&#23567;&#25209;&#37327;&#35757;&#32451;&#21644;&#20004;&#38454;&#27573;&#31574;&#30053;&#31561;&#65292;&#33021;&#22815;&#26377;&#25928;&#25552;&#39640;&#31639;&#27861;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2302.04972</link><description>&lt;p&gt;
&#24179;&#28369;&#38750;&#20984;ERM&#30340;&#24046;&#20998;&#38544;&#31169;&#20248;&#21270;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Optimization for Smooth Nonconvex ERM. (arXiv:2302.04972v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.04972
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#24179;&#28369;&#38750;&#20984;ERM&#30340;&#24046;&#20998;&#38544;&#31169;&#20248;&#21270;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#37319;&#29992;&#32447;&#24615;&#25628;&#32034;&#12289;&#23567;&#25209;&#37327;&#35757;&#32451;&#21644;&#20004;&#38454;&#27573;&#31574;&#30053;&#31561;&#65292;&#33021;&#22815;&#26377;&#25928;&#25552;&#39640;&#31639;&#27861;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#19968;&#31181;&#31616;&#21333;&#30340;&#24046;&#20998;&#38544;&#31169;&#20248;&#21270;&#31639;&#27861;&#65292;&#27839;&#30528;&#26399;&#26395;&#19979;&#38477;&#26041;&#21521;&#23547;&#25214;&#38750;&#20984;ERM&#30340;&#20108;&#38454;&#36817;&#20284;&#35299;&#12290;&#25105;&#20204;&#20351;&#29992;&#32447;&#24615;&#25628;&#32034;&#65292;&#23567;&#25209;&#37327;&#35757;&#32451;&#21644;&#20004;&#38454;&#27573;&#31574;&#30053;&#26469;&#25552;&#39640;&#31639;&#27861;&#30340;&#36895;&#24230;&#21644;&#23454;&#29992;&#24615;&#12290;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#36825;&#20123;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop simple differentially private optimization algorithms that move along directions of (expected) descent to find an approximate second-order solution for nonconvex ERM. We use line search, mini-batching, and a two-phase strategy to improve the speed and practicality of the algorithm. Numerical experiments demonstrate the effectiveness of these approaches.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;GAN&#29983;&#25104;&#24314;&#27169;&#26694;&#26550;MonoFlow&#65292;&#36890;&#36807;Wasserstein&#26799;&#24230;&#27969;&#33719;&#24471;&#29702;&#35770;&#27934;&#35265;&#21644;&#31639;&#27861;&#21551;&#31034;&#12290;&#35813;&#26694;&#26550;&#20351;&#29992;&#23494;&#24230;&#27604;&#20363;&#30340;&#21333;&#35843;&#36882;&#22686;&#26144;&#23556;&#37325;&#26032;&#32553;&#25918;&#31890;&#23376;&#28436;&#21270;&#65292;&#24182;&#36890;&#36807;&#35757;&#32451;&#37492;&#21035;&#22120;&#33719;&#24471;MonoFlow&#30340;&#21521;&#37327;&#22330;&#65292;&#21033;&#29992;&#30456;&#24212;&#30340;&#21521;&#37327;&#22330;&#36827;&#34892;&#31890;&#23376;&#27969;&#30340;&#29983;&#25104;&#12290;</title><link>http://arxiv.org/abs/2302.01075</link><description>&lt;p&gt;
MonoFlow: &#20174;Wasserstein&#26799;&#24230;&#27969;&#30340;&#35282;&#24230;&#37325;&#26032;&#24605;&#32771;Divergence GANs
&lt;/p&gt;
&lt;p&gt;
MonoFlow: Rethinking Divergence GANs via the Perspective of Wasserstein Gradient Flows. (arXiv:2302.01075v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.01075
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;GAN&#29983;&#25104;&#24314;&#27169;&#26694;&#26550;MonoFlow&#65292;&#36890;&#36807;Wasserstein&#26799;&#24230;&#27969;&#33719;&#24471;&#29702;&#35770;&#27934;&#35265;&#21644;&#31639;&#27861;&#21551;&#31034;&#12290;&#35813;&#26694;&#26550;&#20351;&#29992;&#23494;&#24230;&#27604;&#20363;&#30340;&#21333;&#35843;&#36882;&#22686;&#26144;&#23556;&#37325;&#26032;&#32553;&#25918;&#31890;&#23376;&#28436;&#21270;&#65292;&#24182;&#36890;&#36807;&#35757;&#32451;&#37492;&#21035;&#22120;&#33719;&#24471;MonoFlow&#30340;&#21521;&#37327;&#22330;&#65292;&#21033;&#29992;&#30456;&#24212;&#30340;&#21521;&#37327;&#22330;&#36827;&#34892;&#31890;&#23376;&#27969;&#30340;&#29983;&#25104;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20256;&#32479;&#19978;&#65292;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GANs&#65289;&#30340;&#23545;&#25239;&#35757;&#32451;&#26159;&#36890;&#36807;&#21028;&#21035;&#22120;&#26469;&#20272;&#35745;&#31163;&#25955;&#24230;&#65292;&#29983;&#25104;&#22120;&#23398;&#20064;&#26368;&#23567;&#21270;&#36825;&#20010;&#31163;&#25955;&#24230;&#12290;&#25105;&#20204;&#35748;&#20026;&#65292;&#23613;&#31649;&#35768;&#22810;GANs&#21464;&#20307;&#37117;&#26159;&#25353;&#29031;&#36825;&#20010;&#33539;&#20363;&#24320;&#21457;&#30340;&#65292;&#20294;&#24403;&#21069;GANs&#30340;&#29702;&#35770;&#29702;&#35299;&#21644;&#23454;&#38469;&#31639;&#27861;&#26159;&#19981;&#19968;&#33268;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#36890;&#36807;&#21033;&#29992;&#23637;&#31034;&#20102;&#26679;&#26412;&#31354;&#38388;&#20869;&#31890;&#23376;&#28436;&#21270;&#30340;Wasserstein&#26799;&#24230;&#27969;&#26469;&#33719;&#24471;GANs&#30340;&#29702;&#35770;&#27934;&#35265;&#21644;&#31639;&#27861;&#21551;&#31034;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#29983;&#25104;&#24314;&#27169;&#26694;&#26550;MonoFlow&#65306;&#31890;&#23376;&#28436;&#21270;&#36890;&#36807;&#23494;&#24230;&#27604;&#20363;&#30340;&#21333;&#35843;&#36882;&#22686;&#26144;&#23556;&#36827;&#34892;&#37325;&#26032;&#32553;&#25918;&#12290;&#22312;&#25105;&#20204;&#30340;&#26694;&#26550;&#19979;&#65292;&#23545;&#25239;&#24615;&#35757;&#32451;&#21487;&#20197;&#34987;&#35270;&#20026;&#19968;&#20010;&#36807;&#31243;&#65292;&#39318;&#20808;&#36890;&#36807;&#35757;&#32451;&#37492;&#21035;&#22120;&#33719;&#24471;MonoFlow&#30340;&#21521;&#37327;&#22330;&#65292;&#28982;&#21518;&#29983;&#25104;&#22120;&#23398;&#20064;&#30001;&#30456;&#24212;&#21521;&#37327;&#22330;&#25152;&#23450;&#20041;&#30340;&#31890;&#23376;&#27969;&#12290;
&lt;/p&gt;
&lt;p&gt;
The conventional understanding of adversarial training in generative adversarial networks (GANs) is that the discriminator is trained to estimate a divergence, and the generator learns to minimize this divergence. We argue that despite the fact that many variants of GANs were developed following this paradigm, the current theoretical understanding of GANs and their practical algorithms are inconsistent. In this paper, we leverage Wasserstein gradient flows which characterize the evolution of particles in the sample space, to gain theoretical insights and algorithmic inspiration of GANs. We introduce a unified generative modeling framework - MonoFlow: the particle evolution is rescaled via a monotonically increasing mapping of the log density ratio. Under our framework, adversarial training can be viewed as a procedure first obtaining MonoFlow's vector field via training the discriminator and the generator learns to draw the particle flow defined by the corresponding vector field. We al
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#22343;&#22330;&#21338;&#24328;&#20013;&#20351;&#29992;&#31574;&#30053;&#38236;&#38754;&#19978;&#21319;&#23454;&#29616;&#39640;&#25928;&#29420;&#31435;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#19981;&#38656;&#35201;&#20154;&#21475;&#29983;&#25104;&#27169;&#22411;&#65292;&#19988;&#21482;&#38656;&#35201;&#32422;$\widetilde{\mathcal{O}}(\varepsilon^{-2})$&#20010;&#26679;&#26412;&#21363;&#21487;&#36798;&#21040;&#32435;&#20160;&#22343;&#34913;&#12290;</title><link>http://arxiv.org/abs/2212.14449</link><description>&lt;p&gt;
&#12298;&#22312;&#22343;&#22330;&#21338;&#24328;&#20013;&#20351;&#29992;&#31574;&#30053;&#38236;&#38754;&#19978;&#21319;&#23454;&#29616;&#39640;&#25928;&#29420;&#31435;&#23398;&#20064;&#12299;
&lt;/p&gt;
&lt;p&gt;
Policy Mirror Ascent for Efficient and Independent Learning in Mean Field Games. (arXiv:2212.14449v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.14449
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#22312;&#22343;&#22330;&#21338;&#24328;&#20013;&#20351;&#29992;&#31574;&#30053;&#38236;&#38754;&#19978;&#21319;&#23454;&#29616;&#39640;&#25928;&#29420;&#31435;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#19981;&#38656;&#35201;&#20154;&#21475;&#29983;&#25104;&#27169;&#22411;&#65292;&#19988;&#21482;&#38656;&#35201;&#32422;$\widetilde{\mathcal{O}}(\varepsilon^{-2})$&#20010;&#26679;&#26412;&#21363;&#21487;&#36798;&#21040;&#32435;&#20160;&#22343;&#34913;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22343;&#22330;&#21338;&#24328;&#34987;&#29992;&#20316;&#33719;&#24471;&#23545;&#31216;&#21644;&#21311;&#21517;&#30340;N&#20154;&#21338;&#24328;&#30340;&#36817;&#20284;&#32435;&#20160;&#22343;&#34913;&#30340;&#29702;&#35770;&#24037;&#20855;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30340;&#29702;&#35770;&#32467;&#26524;&#21482;&#36866;&#29992;&#20110;"&#20154;&#21475;&#29983;&#25104;&#27169;&#22411;"&#30340;&#21464;&#21270;&#65292;&#35813;&#27169;&#22411;&#20801;&#35768;&#23398;&#20064;&#31639;&#27861;&#36890;&#36807;&#20154;&#21475;&#20998;&#24067;&#36827;&#34892;&#20219;&#24847;&#20462;&#25913;&#12290;&#27492;&#22806;&#65292;&#23398;&#20064;&#31639;&#27861;&#36890;&#24120;&#20351;&#29992;&#20855;&#26377;&#20154;&#21475;&#23646;&#24615;&#30340;&#25277;&#35937;&#27169;&#25311;&#22120;&#65292;&#32780;&#19981;&#26159;N&#20154;&#21338;&#24328;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;N&#20010;&#20195;&#29702;&#36816;&#34892;&#31574;&#30053;&#38236;&#38754;&#19978;&#21319;&#26159;&#22914;&#20309;&#22312;&#19981;&#20351;&#29992;&#20154;&#21475;&#29983;&#25104;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#65292;&#20174;&#21333;&#20010;&#26679;&#26412;&#36712;&#36857;&#20013;&#25910;&#25947;&#20110;&#35268;&#21017;&#21338;&#24328;&#30340;&#32435;&#20160;&#22343;&#34913;&#65292;&#21482;&#38656;&#35201;&#22823;&#32422;$\widetilde{\mathcal{O}}(\varepsilon^{-2})$&#30340;&#26679;&#26412;&#65292;&#30001;&#20110;&#22343;&#22330;&#30340;&#32536;&#25925;&#65292;&#35823;&#24046;&#20026;$\mathcal{O}(\frac{1}{\sqrt{N}})$&#12290;&#30456;&#36739;&#20110;&#25991;&#29486;&#30340;&#19981;&#21516;&#26041;&#27861;&#65292;&#25105;&#20204;&#39318;&#20808;&#23637;&#31034;&#20102;&#21487;&#20197;&#20351;&#29992;&#31574;&#30053;&#38236;&#38754;&#19978;&#21319;&#26144;&#23556;&#26469;&#26500;&#24314;&#19968;&#20010;&#22865;&#32422;&#31639;&#23376;&#65292;&#32780;&#19981;&#26159;&#19982;&#26368;&#20339;&#21709;&#24212;&#26144;&#23556;&#19968;&#36215;&#24037;&#20316;&#12290;
&lt;/p&gt;
&lt;p&gt;
Mean-field games have been used as a theoretical tool to obtain an approximate Nash equilibrium for symmetric and anonymous $N$-player games. However, limiting applicability, existing theoretical results assume variations of a "population generative model", which allows arbitrary modifications of the population distribution by the learning algorithm. Moreover, learning algorithms typically work on abstract simulators with population instead of the $N$-player game. Instead, we show that $N$ agents running policy mirror ascent converge to the Nash equilibrium of the regularized game within $\widetilde{\mathcal{O}}(\varepsilon^{-2})$ samples from a single sample trajectory without a population generative model, up to a standard $\mathcal{O}(\frac{1}{\sqrt{N}})$ error due to the mean field. Taking a divergent approach from the literature, instead of working with the best-response map we first show that a policy mirror ascent map can be used to construct a contractive operator having the Na
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#24179;&#28369;&#26799;&#24230;&#19979;&#38477;&#19978;&#21319;&#27861; (DSGDA)&#65292;&#35813;&#31639;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#38750;&#20984;-&#38750;&#20985;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#65292;&#24182;&#19988;&#33021;&#22815;&#20840;&#23616;&#25910;&#25947;&#24182;&#28040;&#38500;&#26497;&#38480;&#29615;&#12290;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#65292;DSGDA &#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#36798;&#21040;&#20102;&#25991;&#29486;&#20013;&#21333;&#24490;&#29615;&#31639;&#27861;&#30340;&#26368;&#20339;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2212.12978</link><description>&lt;p&gt;
&#21452;&#37325;&#24179;&#28369;GDA&#65306;&#29992;&#20110;&#38750;&#20984;-&#38750;&#20985;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#30340;&#20840;&#23616;&#25910;&#25947;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Doubly Smoothed GDA: Global Convergent Algorithm for Constrained Nonconvex-Nonconcave Minimax Optimization. (arXiv:2212.12978v3 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.12978
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21452;&#37325;&#24179;&#28369;&#26799;&#24230;&#19979;&#38477;&#19978;&#21319;&#27861; (DSGDA)&#65292;&#35813;&#31639;&#27861;&#21487;&#20197;&#24212;&#29992;&#20110;&#38750;&#20984;-&#38750;&#20985;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#65292;&#24182;&#19988;&#33021;&#22815;&#20840;&#23616;&#25910;&#25947;&#24182;&#28040;&#38500;&#26497;&#38480;&#29615;&#12290;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#65292;DSGDA &#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#36798;&#21040;&#20102;&#25991;&#29486;&#20013;&#21333;&#24490;&#29615;&#31639;&#27861;&#30340;&#26368;&#20339;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#20984;-&#38750;&#20985;&#26497;&#23567;&#26497;&#22823;&#20248;&#21270;&#36817;&#24180;&#26469;&#21463;&#21040;&#20102;&#24191;&#27867;&#30340;&#20851;&#27880;&#65292;&#20854;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#20855;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#29616;&#26377;&#31639;&#27861;&#19981;&#33021;&#20445;&#35777;&#20840;&#23616;&#25910;&#25947;&#65292;&#29978;&#33267;&#20250;&#36973;&#21463;&#26497;&#38480;&#29615;&#30340;&#22256;&#25200;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#21333;&#24490;&#29615;&#31639;&#27861;&#65292;&#31216;&#20026;&#21452;&#37325;&#24179;&#28369;&#26799;&#24230;&#19979;&#38477;&#19978;&#21319;&#27861; (DSGDA)&#65292;&#23427;&#33021;&#22815;&#33258;&#28982;&#22320;&#24179;&#34913;&#21407;&#22987;&#19982;&#23545;&#20598;&#26356;&#26032;&#65292;&#24182;&#19988;&#23558;&#26497;&#20854;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38750;&#20984;-&#38750;&#20985;&#20363;&#23376;&#20013;&#30340;&#26497;&#38480;&#29615;&#28040;&#38500;&#65292;&#21253;&#25324; Forsaken&#65292;Bilinearly-coupled minimax&#65292;Sixth-order polynomial &#21644; PolarGame&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#35777;&#26126;&#65292;&#22312;&#19968;&#20010;&#21333;&#20391;&#30340; $\theta\in(0,1)$ Kurdyka-\L{}ojasiewicz&#26465;&#20214;&#65288;&#25110;&#20984;&#21407;&#22987;/&#20985;&#23545;&#20598;&#20989;&#25968;&#65289;&#19979;&#65292;DSGDA &#21487;&#20197;&#25214;&#21040;&#19968;&#20010;&#28216;&#25103;&#24179;&#34913;&#28857;&#65292;&#24182;&#19988;&#20855;&#26377;&#36845;&#20195;&#22797;&#26434;&#24230; $\mathcal{O}(\epsilon^{-2\max\{2\theta,1\}})$&#65288;&#25110; $\mathcal{O}(\epsilon^{-4})$&#65289;&#65292;&#36825;&#20123;&#19982;&#25991;&#29486;&#20013;&#21333;&#24490;&#29615;&#31639;&#27861;&#30340;&#26368;&#20339;&#32467;&#26524;&#30456;&#21305;&#37197;&#12290;
&lt;/p&gt;
&lt;p&gt;
Nonconvex-nonconcave minimax optimization has received intense attention over the last decade due to its broad applications in machine learning. Unfortunately, most existing algorithms cannot be guaranteed to converge globally and even suffer from limit cycles. To address this issue, we propose a novel single-loop algorithm called doubly smoothed gradient descent ascent method (DSGDA), which naturally balances the primal and dual updates. The proposed DSGDA can get rid of limit cycles in various challenging nonconvex-nonconcave examples in the literature, including Forsaken, Bilinearly-coupled minimax, Sixth-order polynomial, and PolarGame. We further show that under an one-sided Kurdyka-\L{}ojasiewicz condition with exponent $\theta\in(0,1)$ (resp. convex primal/concave dual function), DSGDA can find a game-stationary point with an iteration complexity of $\mathcal{O}(\epsilon^{-2\max\{2\theta,1\}})$ (resp. $\mathcal{O}(\epsilon^{-4})$). These match the best results for single-loop al
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;Huber&#33021;&#37327;&#37327;&#21270;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#25214;&#21040;&#30446;&#26631;&#27010;&#29575;&#23450;&#24459;&#30340;&#26368;&#20339;&#36924;&#36817;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#21407;&#27979;&#24230;&#19982;&#37327;&#21270;&#29256;&#26412;&#20043;&#38388;&#30340;&#32479;&#35745;&#36317;&#31163;&#26469;&#23454;&#29616;&#12290;&#35813;&#31639;&#27861;&#24050;&#22312;&#22810;&#32500;&#39640;&#26031;&#28151;&#21512;&#29289;&#12289;&#32500;&#32435;&#31354;&#38388;&#39764;&#26041;&#31561;&#20960;&#20010;&#25968;&#25454;&#24211;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#12290;</title><link>http://arxiv.org/abs/2212.08162</link><description>&lt;p&gt;
Huber&#33021;&#37327;&#37327;&#21270;
&lt;/p&gt;
&lt;p&gt;
Huber-energy measure quantization. (arXiv:2212.08162v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.08162
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;Huber&#33021;&#37327;&#37327;&#21270;&#30340;&#31639;&#27861;&#65292;&#29992;&#20110;&#25214;&#21040;&#30446;&#26631;&#27010;&#29575;&#23450;&#24459;&#30340;&#26368;&#20339;&#36924;&#36817;&#65292;&#36890;&#36807;&#26368;&#23567;&#21270;&#21407;&#27979;&#24230;&#19982;&#37327;&#21270;&#29256;&#26412;&#20043;&#38388;&#30340;&#32479;&#35745;&#36317;&#31163;&#26469;&#23454;&#29616;&#12290;&#35813;&#31639;&#27861;&#24050;&#22312;&#22810;&#32500;&#39640;&#26031;&#28151;&#21512;&#29289;&#12289;&#32500;&#32435;&#31354;&#38388;&#39764;&#26041;&#31561;&#20960;&#20010;&#25968;&#25454;&#24211;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25551;&#36848;&#20102;&#19968;&#31181;&#27979;&#37327;&#37327;&#21270;&#36807;&#31243;&#65292;&#21363;&#19968;&#31181;&#31639;&#27861;&#65292;&#23427;&#36890;&#36807;$Q$&#20010;&#29380;&#25289;&#20811;&#20989;&#25968;&#30340;&#24635;&#21644;&#65288;$Q$&#20026;&#37327;&#21270;&#21442;&#25968;&#65289;&#65292;&#25214;&#21040;&#30446;&#26631;&#27010;&#29575;&#23450;&#24459;&#65288;&#26356;&#19968;&#33324;&#22320;&#65292;&#20026;&#26377;&#38480;&#21464;&#24046;&#27979;&#24230;&#65289;&#30340;&#26368;&#20339;&#36924;&#36817;&#12290;&#35813;&#36807;&#31243;&#36890;&#36807;&#23558;&#21407;&#27979;&#24230;&#19982;&#20854;&#37327;&#21270;&#29256;&#26412;&#20043;&#38388;&#30340;&#32479;&#35745;&#36317;&#31163;&#26368;&#23567;&#21270;&#26469;&#23454;&#29616;&#65307;&#35813;&#36317;&#31163;&#22522;&#20110;&#36127;&#23450;&#26680;&#26500;&#24314;&#65292;&#24182;&#19988;&#22914;&#26524;&#24517;&#35201;&#65292;&#21487;&#20197;&#23454;&#26102;&#35745;&#31639;&#24182;&#36755;&#20837;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#65288;&#22914;SGD&#65292;Adam&#31561;&#65289;&#12290;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#30740;&#31350;&#20102;&#26368;&#20248;&#27979;&#37327;&#37327;&#21270;&#22120;&#30340;&#23384;&#22312;&#30340;&#22522;&#26412;&#38382;&#39064;&#65292;&#24182;&#30830;&#23450;&#20102;&#38656;&#35201;&#20445;&#35777;&#21512;&#36866;&#34892;&#20026;&#30340;&#26680;&#23646;&#24615;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#20010;&#26368;&#20339;&#32447;&#24615;&#26080;&#20559;&#65288;BLUE&#65289;&#20272;&#35745;&#22120;&#65292;&#29992;&#20110;&#24179;&#26041;&#32479;&#35745;&#36317;&#31163;&#65292;&#24182;&#23558;&#23427;&#20204;&#29992;&#20110;&#26080;&#20559;&#31243;&#24207;HEMQ&#20013;&#65292;&#20197;&#25214;&#21040;&#26368;&#20339;&#37327;&#21270;&#12290;&#25105;&#20204;&#22312;&#22810;&#32500;&#39640;&#26031;&#28151;&#21512;&#29289;&#12289;&#32500;&#32435;&#31354;&#38388;&#39764;&#26041;&#31561;&#20960;&#20010;&#25968;&#25454;&#24211;&#19978;&#27979;&#35797;&#20102;HEMQ
&lt;/p&gt;
&lt;p&gt;
We describe a measure quantization procedure i.e., an algorithm which finds the best approximation of a target probability law (and more generally signed finite variation measure) by a sum of $Q$ Dirac masses ($Q$ being the quantization parameter). The procedure is implemented by minimizing the statistical distance between the original measure and its quantized version; the distance is built from a negative definite kernel and, if necessary, can be computed on the fly and feed to a stochastic optimization algorithm (such as SGD, Adam, ...). We investigate theoretically the fundamental questions of existence of the optimal measure quantizer and identify what are the required kernel properties that guarantee suitable behavior. We propose two best linear unbiased (BLUE) estimators for the squared statistical distance and use them in an unbiased procedure, called HEMQ, to find the optimal quantization. We test HEMQ on several databases: multi-dimensional Gaussian mixtures, Wiener space cub
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;DRL&#21435;&#28151;&#28102;&#26041;&#27861;&#65292;&#36890;&#36807;&#37325;&#26032;&#21152;&#26435;&#25110;&#37325;&#26032;&#37319;&#26679;&#31163;&#32447;&#25968;&#25454;&#38598;&#26469;&#35843;&#25972;&#19981;&#21516;&#37319;&#26679;&#23545;&#25439;&#22833;&#20989;&#25968;&#30340;&#24433;&#21709;&#65292;&#20197;&#30830;&#20445;&#20854;&#26080;&#20559;&#12290;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#25552;&#39640;DRL&#31639;&#27861;&#30340;&#40065;&#26834;&#24615;&#21644;&#27867;&#21270;&#24615;&#12290;</title><link>http://arxiv.org/abs/2211.15355</link><description>&lt;p&gt;
&#21033;&#29992;&#35266;&#27979;&#25968;&#25454;&#36827;&#34892;&#22240;&#26524;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Causal Deep Reinforcement Learning Using Observational Data. (arXiv:2211.15355v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.15355
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;DRL&#21435;&#28151;&#28102;&#26041;&#27861;&#65292;&#36890;&#36807;&#37325;&#26032;&#21152;&#26435;&#25110;&#37325;&#26032;&#37319;&#26679;&#31163;&#32447;&#25968;&#25454;&#38598;&#26469;&#35843;&#25972;&#19981;&#21516;&#37319;&#26679;&#23545;&#25439;&#22833;&#20989;&#25968;&#30340;&#24433;&#21709;&#65292;&#20197;&#30830;&#20445;&#20854;&#26080;&#20559;&#12290;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#26377;&#25928;&#25552;&#39640;DRL&#31639;&#27861;&#30340;&#40065;&#26834;&#24615;&#21644;&#27867;&#21270;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#65288;DRL&#65289;&#38656;&#35201;&#25910;&#38598;&#24178;&#39044;&#25968;&#25454;&#65292;&#22312;&#29616;&#23454;&#19990;&#30028;&#20013;&#26377;&#26102;&#26114;&#36149;&#29978;&#33267;&#19981;&#36947;&#24503;&#65292;&#27604;&#22914;&#22312;&#33258;&#21160;&#39550;&#39542;&#21644;&#21307;&#30103;&#39046;&#22495;&#12290;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#36890;&#36807;&#21033;&#29992;&#29616;&#23454;&#19990;&#30028;&#20013;&#24191;&#27867;&#21487;&#29992;&#30340;&#35266;&#27979;&#25968;&#25454;&#26469;&#32531;&#35299;&#36825;&#20010;&#38382;&#39064;&#12290;&#20294;&#26159;&#65292;&#22914;&#26524;&#20135;&#29983;&#25968;&#25454;&#30340;&#34892;&#20026;&#31574;&#30053;&#21462;&#20915;&#20110;&#26410;&#35266;&#23519;&#21040;&#30340;&#38543;&#26426;&#21464;&#37327;&#65288;&#21363;&#28151;&#28102;&#22240;&#32032;&#65289;&#65292;&#37027;&#20040;&#35266;&#27979;&#25968;&#25454;&#21487;&#33021;&#20250;&#35823;&#23548;&#23398;&#20064;&#26234;&#33021;&#20307;&#20135;&#29983;&#19981;&#24819;&#35201;&#30340;&#32467;&#26524;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;DRL&#21435;&#28151;&#28102;&#26041;&#27861;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#36825;&#20123;&#26041;&#27861;&#39318;&#20808;&#20351;&#29992;&#22240;&#26524;&#25512;&#26029;&#25216;&#26415;&#35745;&#31639;&#19981;&#21516;&#37319;&#26679;&#30340;&#37325;&#35201;&#31243;&#24230;&#65292;&#28982;&#21518;&#36890;&#36807;&#37325;&#26032;&#21152;&#26435;&#25110;&#37325;&#26032;&#37319;&#26679;&#31163;&#32447;&#25968;&#25454;&#38598;&#26469;&#35843;&#25972;&#19981;&#21516;&#37319;&#26679;&#23545;&#25439;&#22833;&#20989;&#25968;&#30340;&#24433;&#21709;&#65292;&#20197;&#30830;&#20445;&#20854;&#26080;&#20559;&#12290;&#36825;&#20123;&#21435;&#28151;&#28102;&#30340;&#26041;&#27861;&#21487;&#20197;&#28789;&#27963;&#22320;&#19982;&#29616;&#26377;&#30340;&#22522;&#20110;&#27169;&#22411;&#30340;DRL&#31639;&#27861;&#65288;&#22914;&#36719;&#28436;&#21592;-&#35780;&#35770;&#23478;&#21644;&#36817;&#31471;&#31574;&#30053;&#20248;&#21270;&#65289;&#30456;&#32467;&#21512;&#65292;&#20197;&#23398;&#20064;&#22240;&#26524;&#26368;&#20248;&#31574;&#30053;&#12290;&#25105;&#20204;&#22312;&#20154;&#24037;&#21512;&#25104;&#25968;&#25454;&#38598;&#21644;&#20855;&#26377;&#28151;&#28102;&#22240;&#32032;&#30340;&#22522;&#20934;&#27979;&#35797;&#29615;&#22659;&#20013;&#35780;&#20272;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#34920;&#26126;&#23427;&#20204;&#21487;&#20197;&#26377;&#25928;&#22320;&#20272;&#35745;&#22240;&#26524;&#25928;&#24212;&#65292;&#24182;&#25552;&#39640;DRL&#31639;&#27861;&#30340;&#40065;&#26834;&#24615;&#21644;&#27867;&#21270;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep reinforcement learning (DRL) requires the collection of interventional data, which is sometimes expensive and even unethical in the real world, such as in the autonomous driving and the medical field. Offline reinforcement learning promises to alleviate this issue by exploiting the vast amount of observational data available in the real world. However, observational data may mislead the learning agent to undesirable outcomes if the behavior policy that generates the data depends on unobserved random variables (i.e., confounders). In this paper, we propose two deconfounding methods in DRL to address this problem. The methods first calculate the importance degree of different samples based on the causal inference technique, and then adjust the impact of different samples on the loss function by reweighting or resampling the offline dataset to ensure its unbiasedness. These deconfounding methods can be flexibly combined with existing model-free DRL algorithms such as soft actor-criti
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#38024;&#23545;&#20855;&#26377;&#22810;&#27425;&#36890;&#36807;&#25968;&#25454;&#30340;&#22522;&#20110;&#26799;&#24230;&#30340;&#26426;&#22120;&#23398;&#20064;&#25552;&#20986;&#20102;&#26032;&#30340;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;&#65292;&#22823;&#22823;&#25913;&#21892;&#20102;&#38544;&#31169;&#12289;&#25928;&#29992;&#21644;&#35745;&#31639;&#20043;&#38388;&#30340;&#25240;&#34935;&#38382;&#39064;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#30697;&#38453;&#20998;&#35299;&#25193;&#23637;&#26041;&#27861;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#20613;&#37324;&#21494;&#21464;&#25442;&#26426;&#21046;&#65292;&#21516;&#26102;&#21462;&#24471;&#20102;&#20248;&#20110;&#20197;&#24448;&#26041;&#27861;&#30340;&#26174;&#33879;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2211.06530</link><description>&lt;p&gt;
&#38024;&#23545;&#31169;&#26377;&#26426;&#22120;&#23398;&#20064;&#30340;&#22810;&#26102;&#26399;&#30697;&#38453;&#20998;&#35299;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
Multi-Epoch Matrix Factorization Mechanisms for Private Machine Learning. (arXiv:2211.06530v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.06530
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#38024;&#23545;&#20855;&#26377;&#22810;&#27425;&#36890;&#36807;&#25968;&#25454;&#30340;&#22522;&#20110;&#26799;&#24230;&#30340;&#26426;&#22120;&#23398;&#20064;&#25552;&#20986;&#20102;&#26032;&#30340;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;&#65292;&#22823;&#22823;&#25913;&#21892;&#20102;&#38544;&#31169;&#12289;&#25928;&#29992;&#21644;&#35745;&#31639;&#20043;&#38388;&#30340;&#25240;&#34935;&#38382;&#39064;&#12290;&#20316;&#32773;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#30697;&#38453;&#20998;&#35299;&#25193;&#23637;&#26041;&#27861;&#65292;&#24182;&#35774;&#35745;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#20613;&#37324;&#21494;&#21464;&#25442;&#26426;&#21046;&#65292;&#21516;&#26102;&#21462;&#24471;&#20102;&#20248;&#20110;&#20197;&#24448;&#26041;&#27861;&#30340;&#26174;&#33879;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#20102;&#26032;&#30340;&#24046;&#20998;&#38544;&#31169;&#65288;DP&#65289;&#26426;&#21046;&#65292;&#29992;&#20110;&#20855;&#26377;&#22810;&#27425;&#36890;&#36807;&#65288;&#26102;&#26399;&#65289;&#25968;&#25454;&#38598;&#30340;&#22522;&#20110;&#26799;&#24230;&#30340;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#65292;&#22823;&#22823;&#25913;&#21892;&#20102;&#21487;&#23454;&#29616;&#30340;&#38544;&#31169;-&#25928;&#29992;-&#35745;&#31639;&#25240;&#34935;&#12290;&#25105;&#20204;&#24418;&#24335;&#21270;&#20102;&#38024;&#23545;&#20855;&#26377;&#22810;&#27425;&#21442;&#19982;&#30340;&#33258;&#36866;&#24212;&#27969;&#30340;DP&#26426;&#21046;&#30340;&#38382;&#39064;&#65292;&#24182;&#23558;&#22312;&#32447;&#30697;&#38453;&#20998;&#35299;DP&#26426;&#21046;&#30340;&#38750;&#24179;&#20961;&#25193;&#23637;&#24341;&#20837;&#21040;&#25105;&#20204;&#30340;&#35774;&#32622;&#20013;&#12290;&#36825;&#21253;&#25324;&#24314;&#31435;&#28789;&#25935;&#24230;&#35745;&#31639;&#30340;&#24517;&#35201;&#29702;&#35770;&#21644;&#20248;&#21270;&#30697;&#38453;&#30340;&#39640;&#25928;&#35745;&#31639;&#12290;&#23545;&#20110;&#19968;&#20123;&#24212;&#29992;&#31243;&#24207;&#65292;&#20363;&#22914;$&gt;\!\! 10,000$ SGD&#27493;&#39588;&#65292;&#24212;&#29992;&#36825;&#20123;&#26368;&#20339;&#25216;&#26415;&#20250;&#21464;&#24471;&#35745;&#31639;&#26114;&#36149;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#31181;&#22522;&#20110;&#20613;&#37324;&#21494;&#21464;&#25442;&#30340;&#39640;&#25928;&#26426;&#21046;&#65292;&#21482;&#26377;&#36731;&#24494;&#30340;&#25928;&#29992;&#25439;&#22833;&#12290;&#23545;&#20110;&#22270;&#20687;&#20998;&#31867;&#30340;&#31034;&#20363;&#32423;DP&#21644;&#35821;&#35328;&#27169;&#22411;&#30340;&#29992;&#25143;&#32423;DP&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#32463;&#39564;&#35780;&#20272;&#65292;&#35777;&#26126;&#20102;&#22312;&#25152;&#26377;&#20808;&#21069;&#26041;&#27861;&#20013;&#22343;&#33719;&#24471;&#20102;&#26174;&#30528;&#30340;&#25913;&#36827;&#65292;&#21253;&#25324;&#24191;&#27867;&#20351;&#29992;&#30340;DP-SGD&#12290;&#34429;&#28982;&#25105;&#20204;&#30340;&#20027;&#35201;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
We introduce new differentially private (DP) mechanisms for gradient-based machine learning (ML) with multiple passes (epochs) over a dataset, substantially improving the achievable privacy-utility-computation tradeoffs. We formalize the problem of DP mechanisms for adaptive streams with multiple participations and introduce a non-trivial extension of online matrix factorization DP mechanisms to our setting. This includes establishing the necessary theory for sensitivity calculations and efficient computation of optimal matrices. For some applications like $&gt;\!\! 10,000$ SGD steps, applying these optimal techniques becomes computationally expensive. We thus design an efficient Fourier-transform-based mechanism with only a minor utility loss. Extensive empirical evaluation on both example-level DP for image classification and user-level DP for language modeling demonstrate substantial improvements over all previous methods, including the widely-used DP-SGD . Though our primary applicati
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#33258;&#21160;&#29983;&#25104;&#26032;&#30340;&#31163;&#32447;&#26816;&#27979;&#26041;&#27861;&#30340;&#26041;&#24335;&#65292;&#24212;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#20013;&#30340;&#33258;&#21160;&#21464;&#28857;&#26816;&#27979;&#65292;&#20854;&#24615;&#33021;&#21487;&#19982;&#26631;&#20934;CUSUM&#20998;&#31867;&#22120;&#24615;&#33021;&#31454;&#20105;&#12290;</title><link>http://arxiv.org/abs/2211.03860</link><description>&lt;p&gt;
&#36890;&#36807;&#28145;&#24230;&#23398;&#20064;&#23454;&#29616;&#26102;&#38388;&#24207;&#21015;&#20013;&#30340;&#33258;&#21160;&#21464;&#28857;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Automatic Change-Point Detection in Time Series via Deep Learning. (arXiv:2211.03860v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.03860
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#33258;&#21160;&#29983;&#25104;&#26032;&#30340;&#31163;&#32447;&#26816;&#27979;&#26041;&#27861;&#30340;&#26041;&#24335;&#65292;&#24212;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#20013;&#30340;&#33258;&#21160;&#21464;&#28857;&#26816;&#27979;&#65292;&#20854;&#24615;&#33021;&#21487;&#19982;&#26631;&#20934;CUSUM&#20998;&#31867;&#22120;&#24615;&#33021;&#31454;&#20105;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#20013;&#30340;&#21464;&#28857;&#26816;&#27979;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#25105;&#20204;&#36890;&#36807;&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#33258;&#21160;&#29983;&#25104;&#26032;&#30340;&#31163;&#32447;&#26816;&#27979;&#26041;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#29702;&#35770;&#37327;&#21270;&#27492;&#26041;&#27861;&#30340;&#35823;&#24046;&#29575;&#21450;&#20854;&#19982;&#35757;&#32451;&#25968;&#25454;&#37327;&#30340;&#20851;&#31995;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#21363;&#20351;&#26377;&#38480;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#20854;&#24615;&#33021;&#20063;&#21487;&#19982;&#29992;&#20110;&#26816;&#27979;&#20013;&#21464;&#21270;&#30340;&#26631;&#20934;CUSUM&#20998;&#31867;&#22120;&#30340;&#24615;&#33021;&#31454;&#20105;&#12290;
&lt;/p&gt;
&lt;p&gt;
Detecting change-points in data is challenging because of the range of possible types of change and types of behaviour of data when there is no change. Statistically efficient methods for detecting a change will depend on both of these features, and it can be difficult for a practitioner to develop an appropriate detection method for their application of interest. We show how to automatically generate new offline detection methods based on training a neural network. Our approach is motivated by many existing tests for the presence of a change-point being representable by a simple neural network, and thus a neural network trained with sufficient data should have performance at least as good as these methods. We present theory that quantifies the error rate for such an approach, and how it depends on the amount of training data. Empirical results show that, even with limited training data, its performance is competitive with the standard CUSUM-based classifier for detecting a change in m
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#22810;&#38454;&#27573;&#20272;&#35745;&#26041;&#27861;&#26469;&#20272;&#35745;&#39640;&#26031;&#22270;&#27169;&#22411;&#20013;&#30340;&#65288;&#23545;&#35282;&#32447;&#21344;&#20248;&#30340;&#65289;M&#30697;&#38453;&#65292;&#21516;&#26102;&#22522;&#20110;&#26799;&#24230;&#25237;&#24433;&#27861;&#24320;&#21457;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#26469;&#35299;&#20915;&#27491;&#21017;&#21270;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#22312;&#31934;&#24230;&#30697;&#38453;&#20272;&#35745;&#21644;&#22270;&#36793;&#32536;&#35782;&#21035;&#26041;&#38754;&#34920;&#29616;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2210.15471</link><description>&lt;p&gt;
&#20840;&#27491;&#21322;&#23450;&#19979;&#22270;&#27169;&#22411;&#30340;&#33258;&#36866;&#24212;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Adaptive Estimation of Graphical Models under Total Positivity. (arXiv:2210.15471v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.15471
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#22810;&#38454;&#27573;&#20272;&#35745;&#26041;&#27861;&#26469;&#20272;&#35745;&#39640;&#26031;&#22270;&#27169;&#22411;&#20013;&#30340;&#65288;&#23545;&#35282;&#32447;&#21344;&#20248;&#30340;&#65289;M&#30697;&#38453;&#65292;&#21516;&#26102;&#22522;&#20110;&#26799;&#24230;&#25237;&#24433;&#27861;&#24320;&#21457;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#26469;&#35299;&#20915;&#27491;&#21017;&#21270;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#22312;&#31934;&#24230;&#30697;&#38453;&#20272;&#35745;&#21644;&#22270;&#36793;&#32536;&#35782;&#21035;&#26041;&#38754;&#34920;&#29616;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#22312;&#39640;&#26031;&#22270;&#27169;&#22411;&#20013;&#23558;&#65288;&#23545;&#35282;&#32447;&#21344;&#20248;&#30340;&#65289;M&#30697;&#38453;&#20316;&#20026;&#31934;&#24230;&#30697;&#38453;&#36827;&#34892;&#20272;&#35745;&#30340;&#38382;&#39064;&#12290;&#36825;&#20123;&#27169;&#22411;&#23637;&#29616;&#20102;&#26377;&#36259;&#30340;&#24615;&#36136;&#65292;&#20363;&#22914;&#20165;&#20351;&#29992;&#20004;&#20010;&#35266;&#27979;&#20540;&#23601;&#33021;&#33719;&#24471;M&#30697;&#38453;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745; \citep{lauritzen2019maximum,slawski2015estimation}&#65292;&#20197;&#21450;&#23545;&#35282;&#32447;&#21344;&#20248;&#30340;M&#30697;&#38453;&#20165;&#29992;&#19968;&#20010;&#35266;&#27979;&#20540;&#23601;&#33021;&#33719;&#24471;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745; \citep{truell2021maximum}&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#33258;&#36866;&#24212;&#22810;&#38454;&#27573;&#20272;&#35745;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#36890;&#36807;&#22312;&#27599;&#20010;&#38454;&#27573;&#35299;&#20915;&#21152;&#26435;&#30340;$\ell_1$-&#27491;&#21017;&#38382;&#39064;&#26469;&#20248;&#21270;&#20272;&#35745;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#22522;&#20110;&#26799;&#24230;&#25237;&#24433;&#27861;&#24320;&#21457;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#26694;&#26550;&#26469;&#35299;&#20915;&#27491;&#21017;&#21270;&#38382;&#39064;&#65292;&#32467;&#21512;&#19981;&#21516;&#30340;&#25237;&#24433;&#26469;&#22788;&#29702;M&#30697;&#38453;&#21644;&#23545;&#35282;&#32447;&#21344;&#20248;&#30340;M&#30697;&#38453;&#30340;&#32422;&#26463;&#12290;&#25552;&#20379;&#20102;&#23545;&#20272;&#35745;&#35823;&#24046;&#30340;&#29702;&#35770;&#20998;&#26512;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#31934;&#24230;&#30697;&#38453;&#20272;&#35745;&#21644;&#22270;&#36793;&#32536;&#35782;&#21035;&#26041;&#38754;&#20248;&#20110;&#29616;&#26377;&#26368;&#20808;&#36827;&#26041;&#27861;&#65292;&#36825;&#19968;&#28857;&#22312;&#21512;&#25104;&#21644;&#37329;&#34701;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#19978;&#24471;&#21040;&#20102;&#35777;&#23454;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of estimating (diagonally dominant) M-matrices as precision matrices in Gaussian graphical models. These models exhibit intriguing properties, such as the existence of the maximum likelihood estimator with merely two observations for M-matrices \citep{lauritzen2019maximum,slawski2015estimation} and even one observation for diagonally dominant M-matrices \citep{truell2021maximum}. We propose an adaptive multiple-stage estimation method that refines the estimate by solving a weighted $\ell_1$-regularized problem at each stage. Furthermore, we develop a unified framework based on the gradient projection method to solve the regularized problem, incorporating distinct projections to handle the constraints of M-matrices and diagonally dominant M-matrices. A theoretical analysis of the estimation error is provided. Our method outperforms state-of-the-art methods in precision matrix estimation and graph edge identification, as evidenced by synthetic and financial time-s
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#21160;&#24577;&#32447;&#24615;&#25237;&#24433;&#26041;&#27861;&#26469;&#20998;&#26512;&#27969;&#34892;&#30340;&#38750;&#32447;&#24615;&#27169;&#22411;&#30340;&#23616;&#37096;&#35299;&#37322;&#30340;&#26041;&#27861;&#65292;&#25506;&#32034;&#39044;&#27979;&#21464;&#37327;&#20043;&#38388;&#30340;&#20132;&#20114;&#22914;&#20309;&#24433;&#21709;&#21464;&#37327;&#37325;&#35201;&#24615;&#20272;&#35745;&#65292;&#36825;&#23545;&#20110;&#29702;&#35299;&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#38750;&#24120;&#26377;&#29992;&#12290;</title><link>http://arxiv.org/abs/2205.05359</link><description>&lt;p&gt;
&#20351;&#29992;&#21160;&#24577;&#32447;&#24615;&#25237;&#24433;&#26041;&#27861;&#25506;&#32034;&#38750;&#32447;&#24615;&#27169;&#22411;&#30340;&#23616;&#37096;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Exploring Local Explanations of Nonlinear Models Using Animated Linear Projections. (arXiv:2205.05359v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.05359
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#21160;&#24577;&#32447;&#24615;&#25237;&#24433;&#26041;&#27861;&#26469;&#20998;&#26512;&#27969;&#34892;&#30340;&#38750;&#32447;&#24615;&#27169;&#22411;&#30340;&#23616;&#37096;&#35299;&#37322;&#30340;&#26041;&#27861;&#65292;&#25506;&#32034;&#39044;&#27979;&#21464;&#37327;&#20043;&#38388;&#30340;&#20132;&#20114;&#22914;&#20309;&#24433;&#21709;&#21464;&#37327;&#37325;&#35201;&#24615;&#20272;&#35745;&#65292;&#36825;&#23545;&#20110;&#29702;&#35299;&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#38750;&#24120;&#26377;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#39044;&#27979;&#33021;&#21147;&#26085;&#30410;&#22686;&#24378;&#65292;&#20294;&#19982;&#21442;&#25968;&#32479;&#35745;&#27169;&#22411;&#30456;&#27604;&#65292;&#20854;&#22797;&#26434;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#19979;&#38477;&#12290;&#36825;&#31181;&#25240;&#34935;&#23548;&#33268;&#20102;&#21487;&#35299;&#37322;&#30340;&#20154;&#24037;&#26234;&#33021;&#65288;XAI&#65289;&#30340;&#20986;&#29616;&#65292;&#25552;&#20379;&#20102;&#35832;&#22914;&#23616;&#37096;&#35299;&#37322;&#65288;LE&#65289;&#21644;&#23616;&#37096;&#21464;&#37327;&#24402;&#22240;&#65288;LVA&#65289;&#20043;&#31867;&#30340;&#26041;&#27861;&#65292;&#20197;&#25581;&#31034;&#27169;&#22411;&#22914;&#20309;&#20351;&#29992;&#39044;&#27979;&#21464;&#37327;&#36827;&#34892;&#39044;&#27979;&#12290;&#28982;&#32780;&#65292;LVA&#36890;&#24120;&#19981;&#33021;&#26377;&#25928;&#22788;&#29702;&#39044;&#27979;&#21464;&#37327;&#20043;&#38388;&#30340;&#20851;&#32852;&#12290;&#20026;&#20102;&#29702;&#35299;&#39044;&#27979;&#21464;&#37327;&#20043;&#38388;&#30340;&#20132;&#20114;&#22914;&#20309;&#24433;&#21709;&#21464;&#37327;&#37325;&#35201;&#24615;&#20272;&#35745;&#65292;&#21487;&#20197;&#23558;LVA&#36716;&#25442;&#20026;&#32447;&#24615;&#25237;&#24433;&#65292;&#24182;&#20351;&#29992;&#24452;&#21521;&#28216;&#35272;&#12290;&#36825;&#23545;&#20110;&#23398;&#20064;&#27169;&#22411;&#22914;&#20309;&#29359;&#38169;&#65292;&#25110;&#24322;&#24120;&#20540;&#30340;&#24433;&#21709;&#65292;&#25110;&#35266;&#27979;&#20540;&#30340;&#32858;&#31867;&#20063;&#38750;&#24120;&#26377;&#29992;&#12290;&#26412;&#25991;&#20351;&#29992;&#21508;&#31181;&#27969;&#34892;&#30340;&#38750;&#32447;&#24615;&#27169;&#22411;&#65288;&#21253;&#25324;&#38543;&#26426;&#26862;&#26519;&#21644;&#31070;&#32463;&#32593;&#32476;&#65289;&#30340;&#31034;&#20363;&#26469;&#35828;&#26126;&#36825;&#31181;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The increased predictive power of machine learning models comes at the cost of increased complexity and loss of interpretability, particularly in comparison to parametric statistical models. This trade-off has led to the emergence of eXplainable AI (XAI) which provides methods, such as local explanations (LEs) and local variable attributions (LVAs), to shed light on how a model use predictors to arrive at a prediction. These provide a point estimate of the linear variable importance in the vicinity of a single observation. However, LVAs tend not to effectively handle association between predictors. To understand how the interaction between predictors affects the variable importance estimate, we can convert LVAs into linear projections and use the radial tour. This is also useful for learning how a model has made a mistake, or the effect of outliers, or the clustering of observations. The approach is illustrated with examples from categorical (penguin species, chocolate types) and quant
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24369;&#30417;&#30563;&#30340;&#20027;&#21160;&#23398;&#20064;&#31639;&#27861;&#65292;&#19981;&#20165;&#36873;&#25321;&#35201;&#27880;&#37322;&#30340;&#35266;&#27979;&#32467;&#26524;&#65292;&#36824;&#36873;&#25321;&#35201;&#33719;&#24471;&#30340;&#27880;&#37322;&#31934;&#24230;&#65292;&#24182;&#22312;&#39640;&#26031;&#36807;&#31243;&#20013;&#36827;&#34892;&#20102;&#23454;&#39564;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2204.08335</link><description>&lt;p&gt;
&#22522;&#20110;&#24369;&#30417;&#30563;&#30340;&#39640;&#26031;&#36807;&#31243;&#20027;&#21160;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Active Learning with Weak Supervision for Gaussian Processes. (arXiv:2204.08335v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2204.08335
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#24369;&#30417;&#30563;&#30340;&#20027;&#21160;&#23398;&#20064;&#31639;&#27861;&#65292;&#19981;&#20165;&#36873;&#25321;&#35201;&#27880;&#37322;&#30340;&#35266;&#27979;&#32467;&#26524;&#65292;&#36824;&#36873;&#25321;&#35201;&#33719;&#24471;&#30340;&#27880;&#37322;&#31934;&#24230;&#65292;&#24182;&#22312;&#39640;&#26031;&#36807;&#31243;&#20013;&#36827;&#34892;&#20102;&#23454;&#39564;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#20110;&#30417;&#30563;&#23398;&#20064;&#65292;&#36827;&#34892;&#25968;&#25454;&#27880;&#37322;&#38656;&#35201;&#32791;&#36153;&#22823;&#37327;&#25104;&#26412;&#12290;&#24403;&#27880;&#37322;&#39044;&#31639;&#26377;&#38480;&#26102;&#65292;&#21487;&#20197;&#20351;&#29992;&#20027;&#21160;&#23398;&#20064;&#26469;&#36873;&#25321;&#21644;&#27880;&#37322;&#37027;&#20123;&#21487;&#33021;&#22312;&#27169;&#22411;&#24615;&#33021;&#19978;&#33719;&#24471;&#26368;&#22823;&#25910;&#30410;&#30340;&#35266;&#27979;&#32467;&#26524;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20027;&#21160;&#23398;&#20064;&#31639;&#27861;&#65292;&#38500;&#20102;&#36873;&#25321;&#35201;&#27880;&#37322;&#30340;&#35266;&#27979;&#32467;&#26524;&#22806;&#65292;&#36824;&#36873;&#25321;&#35201;&#33719;&#24471;&#30340;&#27880;&#37322;&#31934;&#24230;&#12290;&#20551;&#23450;&#20855;&#26377;&#20302;&#31934;&#24230;&#30340;&#27880;&#37322;&#27604;&#20855;&#26377;&#39640;&#31934;&#24230;&#30340;&#27880;&#37322;&#26356;&#20415;&#23452;&#65292;&#36825;&#20351;&#24471;&#27169;&#22411;&#33021;&#22815;&#22312;&#30456;&#21516;&#30340;&#27880;&#37322;&#39044;&#31639;&#19979;&#25506;&#32034;&#36755;&#20837;&#31354;&#38388;&#30340;&#26356;&#22823;&#37096;&#20998;&#12290;&#25105;&#20204;&#22312;&#20808;&#21069;&#38024;&#23545;&#39640;&#26031;&#36807;&#31243;&#25552;&#20986;&#30340;BALD&#30446;&#26631;&#22522;&#30784;&#19978;&#26500;&#24314;&#20102;&#25105;&#20204;&#30340;&#33719;&#21462;&#20989;&#25968;&#65292;&#24182;&#22312;&#23454;&#39564;&#20013;&#23637;&#31034;&#20102;&#33021;&#22815;&#35843;&#25972;&#20027;&#21160;&#23398;&#20064;&#24490;&#29615;&#20013;&#30340;&#27880;&#37322;&#31934;&#24230;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Annotating data for supervised learning can be costly. When the annotation budget is limited, active learning can be used to select and annotate those observations that are likely to give the most gain in model performance. We propose an active learning algorithm that, in addition to selecting which observation to annotate, selects the precision of the annotation that is acquired. Assuming that annotations with low precision are cheaper to obtain, this allows the model to explore a larger part of the input space, with the same annotation budget. We build our acquisition function on the previously proposed BALD objective for Gaussian Processes, and empirically demonstrate the gains of being able to adjust the annotation precision in the active learning loop.
&lt;/p&gt;</description></item><item><title>L0Learn&#26159;&#19968;&#20010;&#21487;&#20197;&#29992;&#20110;&#35299;&#20915;&#25968;&#30334;&#19975;&#29305;&#24449;&#38382;&#39064;&#30340;&#31232;&#30095;&#23398;&#20064;&#36719;&#20214;&#21253;&#65292;&#20855;&#26377;&#21487;&#25193;&#23637;&#30340;&#36817;&#20284;&#31639;&#27861;&#21644;&#29992;&#25143;&#21451;&#22909;&#30340;R&#21644;Python&#25509;&#21475;&#12290;</title><link>http://arxiv.org/abs/2202.04820</link><description>&lt;p&gt;
L0Learn: &#20351;&#29992;L0&#27491;&#21017;&#21270;&#30340;&#31232;&#30095;&#23398;&#20064;&#30340;&#21487;&#25193;&#23637;&#36719;&#20214;&#21253;
&lt;/p&gt;
&lt;p&gt;
L0Learn: A Scalable Package for Sparse Learning using L0 Regularization. (arXiv:2202.04820v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.04820
&lt;/p&gt;
&lt;p&gt;
L0Learn&#26159;&#19968;&#20010;&#21487;&#20197;&#29992;&#20110;&#35299;&#20915;&#25968;&#30334;&#19975;&#29305;&#24449;&#38382;&#39064;&#30340;&#31232;&#30095;&#23398;&#20064;&#36719;&#20214;&#21253;&#65292;&#20855;&#26377;&#21487;&#25193;&#23637;&#30340;&#36817;&#20284;&#31639;&#27861;&#21644;&#29992;&#25143;&#21451;&#22909;&#30340;R&#21644;Python&#25509;&#21475;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;L0Learn&#65306;&#19968;&#20010;&#20351;&#29992; $\ell_0$ &#27491;&#21017;&#21270;&#36827;&#34892;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#21644;&#20998;&#31867;&#30340;&#24320;&#28304;&#36719;&#20214;&#21253;&#12290;L0Learn&#23454;&#29616;&#20102;&#22522;&#20110;&#22352;&#26631;&#19979;&#38477;&#21644;&#26412;&#22320;&#32452;&#21512;&#20248;&#21270;&#30340;&#21487;&#25193;&#23637;&#30340;&#36817;&#20284;&#31639;&#27861;&#12290;&#35813;&#36719;&#20214;&#21253;&#20351;&#29992;C ++&#26500;&#24314;&#65292;&#24182;&#20855;&#26377;&#29992;&#25143;&#21451;&#22909;&#30340;R&#21644;Python&#25509;&#21475;&#12290;L0Learn&#33021;&#22815;&#35299;&#20915;&#20855;&#26377;&#25968;&#30334;&#19975;&#29305;&#24449;&#30340;&#38382;&#39064;&#65292;&#22312;&#19982;&#26368;&#20808;&#36827;&#30340;&#31232;&#30095;&#23398;&#20064;&#36719;&#20214;&#21253;&#30456;&#27604;&#33719;&#24471;&#26377;&#31454;&#20105;&#21147;&#30340;&#36816;&#34892;&#26102;&#21644;&#32479;&#35745;&#24615;&#33021;&#12290;L0Learn&#22312;CRAN&#21644;GitHub&#19978;&#37117;&#21487;&#29992;&#65288;https://cran.r-project.org/package=L0Learn&#21644;https://github.com/hazimehh/L0Learn&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present L0Learn: an open-source package for sparse linear regression and classification using $\ell_0$ regularization. L0Learn implements scalable, approximate algorithms, based on coordinate descent and local combinatorial optimization. The package is built using C++ and has user-friendly R and Python interfaces. L0Learn can address problems with millions of features, achieving competitive run times and statistical performance with state-of-the-art sparse learning packages. L0Learn is available on both CRAN and GitHub (https://cran.r-project.org/package=L0Learn and https://github.com/hazimehh/L0Learn).
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38024;&#23545;&#39640;&#32500;&#30697;&#38453;&#25968;&#25454;&#30340;&#29305;&#24449;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#20351;&#29992;&#21152;&#26435;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#24046;&#24322;&#20316;&#20026;&#19981;&#30456;&#20284;&#24230;&#27979;&#37327;&#30340;&#23618;&#27425;&#32858;&#31867;&#31639;&#27861;&#65292;&#29702;&#35770;&#19978;&#23454;&#29616;&#20102;&#32858;&#31867;&#19968;&#33268;&#24615;&#65292;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#31034;&#20363;&#20013;&#35777;&#26126;&#20102;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;</title><link>http://arxiv.org/abs/2112.12909</link><description>&lt;p&gt;
&#38024;&#23545;&#39640;&#32500;&#30697;&#38453;&#25968;&#25454;&#30340;&#26368;&#20248;&#21464;&#37327;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Optimal Variable Clustering for High-Dimensional Matrix Valued Data. (arXiv:2112.12909v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.12909
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38024;&#23545;&#39640;&#32500;&#30697;&#38453;&#25968;&#25454;&#30340;&#29305;&#24449;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#20351;&#29992;&#21152;&#26435;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#24046;&#24322;&#20316;&#20026;&#19981;&#30456;&#20284;&#24230;&#27979;&#37327;&#30340;&#23618;&#27425;&#32858;&#31867;&#31639;&#27861;&#65292;&#29702;&#35770;&#19978;&#23454;&#29616;&#20102;&#32858;&#31867;&#19968;&#33268;&#24615;&#65292;&#22312;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#31034;&#20363;&#20013;&#35777;&#26126;&#20102;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30697;&#38453;&#20540;&#25968;&#25454;&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#26085;&#30410;&#26222;&#21450;&#12290;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#36825;&#31181;&#31867;&#22411;&#25968;&#25454;&#30340;&#32858;&#31867;&#26041;&#27861;&#26159;&#38024;&#23545;&#24179;&#22343;&#27169;&#22411;&#35774;&#35745;&#30340;&#65292;&#19981;&#32771;&#34385;&#29305;&#24449;&#30340;&#20381;&#36182;&#32467;&#26500;&#65292;&#32780;&#35813;&#32467;&#26500;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#23588;&#20026;&#37325;&#35201;&#12290;&#20026;&#20102;&#20174;&#20381;&#36182;&#32467;&#26500;&#20013;&#25552;&#21462;&#20449;&#24687;&#36827;&#34892;&#32858;&#31867;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29305;&#24449;&#28508;&#21464;&#37327;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#23558;&#29305;&#24449;&#25490;&#21015;&#25104;&#30697;&#38453;&#24418;&#24335;&#65292;&#24182;&#20351;&#29992;&#19968;&#20123;&#26410;&#30693;&#30340;&#25104;&#21592;&#30697;&#38453;&#34920;&#31034;&#34892;&#21644;&#21015;&#30340;&#32858;&#31867;&#12290;&#22312;&#27492;&#27169;&#22411;&#19979;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#25552;&#20986;&#20102;&#19968;&#31867;&#20351;&#29992;&#21152;&#26435;&#21327;&#26041;&#24046;&#30697;&#38453;&#30340;&#24046;&#24322;&#20316;&#20026;&#19981;&#30456;&#20284;&#24230;&#27979;&#37327;&#30340;&#23618;&#27425;&#32858;&#31867;&#31639;&#27861;&#12290;&#22312;&#29702;&#35770;&#19978;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#28201;&#21644;&#30340;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#30340;&#31639;&#27861;&#21487;&#20197;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#23454;&#29616;&#32858;&#31867;&#19968;&#33268;&#24615;&#12290;&#34429;&#28982;&#36825;&#31181;&#19968;&#33268;&#24615;&#32467;&#26524;&#36866;&#29992;&#20110;&#25105;&#20204;&#30340;&#31639;&#27861;&#21644;&#24191;&#27867;&#30340;&#21152;&#26435;&#21327;&#26041;&#24046;&#30697;&#38453;&#31867;&#21035;&#65292;&#20294;&#36825;&#20010;&#32467;&#26524;&#30340;&#26465;&#20214;&#20381;&#36182;&#20110;&#21327;&#26041;&#24046;&#20989;&#25968;&#21644;&#21152;&#26435;&#26426;&#21046;&#30340;&#36873;&#25321;&#12290;&#36890;&#36807;&#27169;&#25311;&#21644;&#30495;&#23454;&#25968;&#25454;&#31034;&#20363;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#26041;&#27861;&#30456;&#23545;&#20110;&#29616;&#26377;&#26041;&#27861;&#25552;&#20379;&#20102;&#26356;&#22909;&#30340;&#32858;&#31867;&#24615;&#33021;&#21644;&#29305;&#24449;&#36873;&#25321;&#20934;&#30830;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Matrix valued data has become increasingly prevalent in many applications. Most of the existing clustering methods for this type of data are tailored to the mean model and do not account for the dependence structure of the features, which can be very informative, especially in high-dimensional settings. To extract the information from the dependence structure for clustering, we propose a new latent variable model for the features arranged in matrix form, with some unknown membership matrices representing the clusters for the rows and columns. Under this model, we further propose a class of hierarchical clustering algorithms using the difference of a weighted covariance matrix as the dissimilarity measure. Theoretically, we show that under mild conditions, our algorithm attains clustering consistency in the high-dimensional setting. While this consistency result holds for our algorithm with a broad class of weighted covariance matrices, the conditions for this result depend on the choic
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#33410;&#28857;&#32593;&#32476;&#21450;&#20854;&#20043;&#38388;&#30340;&#27969;&#20316;&#20026;&#22270;&#20687;&#36827;&#34892;&#22788;&#29702;&#65292;&#24182;&#21033;&#29992;&#22270;&#20687;&#21387;&#32553;&#25216;&#26415;&#21644;&#22320;&#29702;&#31614;&#21517;&#23398;&#20064;&#32593;&#32476;&#32467;&#26500;&#20197;&#25512;&#33616;&#26410;&#26469;&#30340;&#32593;&#32476;&#36830;&#36890;&#24615;&#12290;&#27492;&#22806;&#65292;&#35813;&#35770;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#21033;&#29992;&#32479;&#35745;&#25688;&#35201;&#30340;&#32593;&#32476;&#20449;&#24687;&#21644;&#29992;&#25143;&#20915;&#31574;&#26469;&#24378;&#21270;&#20195;&#29702;&#27010;&#29575;&#20915;&#31574;&#30340;&#36125;&#21494;&#26031;&#24378;&#21270;&#31639;&#27861;&#65292;&#24182;&#25506;&#31350;&#20102;&#21033;&#29992;&#21387;&#32553;&#30452;&#25509;&#36827;&#34892;&#24378;&#21270;&#23398;&#20064;&#30340;&#26041;&#24335;&#12290;</title><link>http://arxiv.org/abs/2112.03419</link><description>&lt;p&gt;
&#21033;&#29992;&#22270;&#20687;&#21464;&#25442;&#23398;&#20064;&#32593;&#32476;&#32467;&#26500;
&lt;/p&gt;
&lt;p&gt;
Using Image Transformations to Learn Network Structure. (arXiv:2112.03419v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2112.03419
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#33410;&#28857;&#32593;&#32476;&#21450;&#20854;&#20043;&#38388;&#30340;&#27969;&#20316;&#20026;&#22270;&#20687;&#36827;&#34892;&#22788;&#29702;&#65292;&#24182;&#21033;&#29992;&#22270;&#20687;&#21387;&#32553;&#25216;&#26415;&#21644;&#22320;&#29702;&#31614;&#21517;&#23398;&#20064;&#32593;&#32476;&#32467;&#26500;&#20197;&#25512;&#33616;&#26410;&#26469;&#30340;&#32593;&#32476;&#36830;&#36890;&#24615;&#12290;&#27492;&#22806;&#65292;&#35813;&#35770;&#25991;&#24320;&#21457;&#20102;&#19968;&#31181;&#21033;&#29992;&#32479;&#35745;&#25688;&#35201;&#30340;&#32593;&#32476;&#20449;&#24687;&#21644;&#29992;&#25143;&#20915;&#31574;&#26469;&#24378;&#21270;&#20195;&#29702;&#27010;&#29575;&#20915;&#31574;&#30340;&#36125;&#21494;&#26031;&#24378;&#21270;&#31639;&#27861;&#65292;&#24182;&#25506;&#31350;&#20102;&#21033;&#29992;&#21387;&#32553;&#30452;&#25509;&#36827;&#34892;&#24378;&#21270;&#23398;&#20064;&#30340;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35768;&#22810;&#23398;&#20064;&#20219;&#21153;&#38656;&#35201;&#35266;&#23519;&#19968;&#31995;&#21015;&#22270;&#20687;&#24182;&#20570;&#20986;&#20915;&#31574;&#12290;&#22312;&#35774;&#35745;&#21644;&#35268;&#21010;&#33410;&#28857;&#20043;&#38388;&#30340;&#36135;&#36816;&#31665;&#30340;&#36816;&#36755;&#38382;&#39064;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#33410;&#28857;&#32593;&#32476;&#21450;&#20854;&#20043;&#38388;&#30340;&#27969;&#20316;&#20026;&#22270;&#20687;&#22788;&#29702;&#12290;&#36825;&#20123;&#22270;&#20687;&#20855;&#26377;&#26377;&#29992;&#30340;&#32467;&#26500;&#20449;&#24687;&#65292;&#21487;&#20197;&#36827;&#34892;&#32479;&#35745;&#25688;&#35201;&#12290;&#21033;&#29992;&#22270;&#20687;&#21387;&#32553;&#25216;&#26415;&#65292;&#23558;&#22270;&#20687;&#21387;&#32553;&#25104;&#21253;&#21547;&#21487;&#35299;&#37322;&#22320;&#29702;&#20449;&#24687;&#30340;&#25968;&#23383;&#38598;&#21512;&#65292;&#25105;&#20204;&#23558;&#20854;&#31216;&#20316;&#22320;&#29702;&#31614;&#21517;&#12290;&#21033;&#29992;&#22320;&#29702;&#31614;&#21517;&#65292;&#25105;&#20204;&#23398;&#20064;&#32593;&#32476;&#32467;&#26500;&#65292;&#20197;&#25512;&#33616;&#26410;&#26469;&#30340;&#32593;&#32476;&#36830;&#36890;&#24615;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#36125;&#21494;&#26031;&#24378;&#21270;&#31639;&#27861;&#65292;&#21033;&#29992;&#32479;&#35745;&#25688;&#35201;&#30340;&#32593;&#32476;&#20449;&#24687;&#20316;&#20026;&#20808;&#39564;&#30693;&#35782;&#21644;&#29992;&#25143;&#20915;&#31574;&#26469;&#24378;&#21270;&#20195;&#29702;&#30340;&#27010;&#29575;&#20915;&#31574;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22312;&#31616;&#21333;&#20219;&#21153;&#20013;&#22914;&#20309;&#30452;&#25509;&#20351;&#29992;&#21387;&#32553;&#36827;&#34892;&#24378;&#21270;&#23398;&#20064;&#65292;&#19981;&#38656;&#35201;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
Many learning tasks require observing a sequence of images and making a decision. In a transportation problem of designing and planning for shipping boxes between nodes, we show how to treat the network of nodes and the flows between them as images. These images have useful structural information that can be statistically summarized. Using image compression techniques, we reduce an image down to a set of numbers that contain interpretable geographic information that we call geographic signatures. Using geographic signatures, we learn network structure that can be utilized to recommend future network connectivity. We develop a Bayesian reinforcement algorithm that takes advantage of statistically summarized network information as priors and user-decisions to reinforce an agent's probabilistic decision. Additionally, we show how reinforcement learning can be used with compression directly without interpretation in simple tasks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27867;&#21270;&#24067;&#38647;&#26031;-&#29926;&#29791;&#26031;&#22374;&#65288;BW&#65289;&#20960;&#20309;&#65292;&#31216;&#20026;GBW&#20960;&#20309;&#65292;&#23427;&#36890;&#36807;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#21442;&#25968;&#21270;&#65292;&#25299;&#23637;&#21040;&#22810;&#20010;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#65292;&#23454;&#39564;&#35777;&#26126;GBW&#20960;&#20309;&#20248;&#20110;BW&#20960;&#20309;&#12290;</title><link>http://arxiv.org/abs/2110.10464</link><description>&lt;p&gt;
&#36890;&#36807;&#24191;&#20041;&#24067;&#38647;&#26031;-&#29926;&#29791;&#26031;&#22374;&#65288;GBW&#65289;&#20960;&#20309;&#23398;&#23398;&#20064;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;
&lt;/p&gt;
&lt;p&gt;
Learning with symmetric positive definite matrices via generalized Bures-Wasserstein geometry. (arXiv:2110.10464v2 [math.FA] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.10464
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27867;&#21270;&#24067;&#38647;&#26031;-&#29926;&#29791;&#26031;&#22374;&#65288;BW&#65289;&#20960;&#20309;&#65292;&#31216;&#20026;GBW&#20960;&#20309;&#65292;&#23427;&#36890;&#36807;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;&#21442;&#25968;&#21270;&#65292;&#25299;&#23637;&#21040;&#22810;&#20010;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#65292;&#23454;&#39564;&#35777;&#26126;GBW&#20960;&#20309;&#20248;&#20110;BW&#20960;&#20309;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#65292;&#23398;&#20064;&#23545;&#31216;&#27491;&#23450;&#65288;SPD&#65289;&#30697;&#38453;&#20855;&#26377;&#35768;&#22810;&#24212;&#29992;&#12290;&#22240;&#27492;&#65292;&#36817;&#26469;&#23545;SPD&#30697;&#38453;&#30340;&#40654;&#26364;&#20960;&#20309;&#30340;&#29702;&#35299;&#24341;&#36215;&#20102;&#24191;&#27867;&#20851;&#27880;&#12290;&#19968;&#31181;&#29305;&#23450;&#30340;&#40654;&#26364;&#20960;&#20309;&#26159;&#26368;&#36817;&#25552;&#20986;&#30340;&#24067;&#38647;&#26031;-&#29926;&#29791;&#26031;&#22374;&#65288;BW&#65289;&#20960;&#20309;&#23398;&#65292;&#23427;&#24314;&#31435;&#22312;&#39640;&#26031;&#23494;&#24230;&#20043;&#38388;&#30340;Wasserstein&#36317;&#31163;&#19978;&#12290;&#26412;&#25991;&#25552;&#20986;&#19968;&#20010;&#26032;&#30340;BW&#20960;&#20309;&#30340;&#27867;&#21270;&#27169;&#22411;&#65292;&#31216;&#20026;GBW&#20960;&#20309;&#12290;&#25152;&#25552;&#20986;&#30340;&#27867;&#21270;&#26159;&#30001;&#19968;&#20010;&#23545;&#31216;&#27491;&#23450;&#30697;&#38453;M&#21442;&#25968;&#21270;&#30340;&#65292;&#24403;M = I&#26102;&#65292;&#25105;&#20204;&#24674;&#22797;&#20102;BW&#20960;&#20309;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#20005;&#26684;&#30340;&#30740;&#31350;&#26469;&#30740;&#31350;&#25152;&#25552;&#20986;&#30340;&#26032;&#22411;&#24191;&#20041;&#20960;&#20309;&#30340;&#21508;&#31181;&#24494;&#20998;&#20960;&#20309;&#27010;&#24565;&#65292;&#36825;&#20351;&#24471;&#23427;&#36866;&#29992;&#20110;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;&#23454;&#39564;&#35777;&#26126;&#25152;&#25552;&#20986;&#30340;GBW&#20960;&#20309;&#20248;&#20110;BW&#20960;&#20309;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning with symmetric positive definite (SPD) matrices has many applications in machine learning. Consequently, understanding the Riemannian geometry of SPD matrices has attracted much attention lately. A particular Riemannian geometry of interest is the recently proposed Bures-Wasserstein (BW) geometry which builds on the Wasserstein distance between the Gaussian densities. In this paper, we propose a novel generalization of the BW geometry, which we call the GBW geometry. The proposed generalization is parameterized by a symmetric positive definite matrix $\mathbf{M}$ such that when $\mathbf{M} = \mathbf{I}$, we recover the BW geometry. We provide a rigorous treatment to study various differential geometric notions on the proposed novel generalized geometry which makes it amenable to various machine learning applications. We also present experiments that illustrate the efficacy of the proposed GBW geometry over the BW geometry.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#33218;&#32769;&#34382;&#26426;&#20013;&#21518;&#24724;&#26368;&#23567;&#21270;&#21644;&#26368;&#20339;&#33218;&#35782;&#21035;&#30340;&#24085;&#32047;&#25176;&#21069;&#27839;,&#35774;&#35745;&#20102;BoBW-lil'UCB $(\gamma)$&#31639;&#27861;&#65292;&#35777;&#26126;&#20102;&#27809;&#26377;&#31639;&#27861;&#33021;&#21516;&#26102;&#20026;RM&#21644;BAI&#30446;&#26631;&#34920;&#29616;&#26368;&#20339;&#65292;BoBW-lil'UCB $(\gamma)$&#21487;&#22312;&#19981;&#21516;&#30340;$\gamma$&#20540;&#19979;&#23454;&#29616;RM&#25110;BAI&#30340;&#26368;&#20248;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2110.08627</link><description>&lt;p&gt;
&#22312;&#22810;&#33218;&#32769;&#34382;&#26426;&#20013;&#23454;&#29616;&#21518;&#24724;&#26368;&#23567;&#21270;&#21644;&#26368;&#20339;&#33218;&#35782;&#21035;&#30340;&#24085;&#32047;&#25176;&#21069;&#27839;
&lt;/p&gt;
&lt;p&gt;
Achieving the Pareto Frontier of Regret Minimization and Best Arm Identification in Multi-Armed Bandits. (arXiv:2110.08627v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.08627
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#33218;&#32769;&#34382;&#26426;&#20013;&#21518;&#24724;&#26368;&#23567;&#21270;&#21644;&#26368;&#20339;&#33218;&#35782;&#21035;&#30340;&#24085;&#32047;&#25176;&#21069;&#27839;,&#35774;&#35745;&#20102;BoBW-lil'UCB $(\gamma)$&#31639;&#27861;&#65292;&#35777;&#26126;&#20102;&#27809;&#26377;&#31639;&#27861;&#33021;&#21516;&#26102;&#20026;RM&#21644;BAI&#30446;&#26631;&#34920;&#29616;&#26368;&#20339;&#65292;BoBW-lil'UCB $(\gamma)$&#21487;&#22312;&#19981;&#21516;&#30340;$\gamma$&#20540;&#19979;&#23454;&#29616;RM&#25110;BAI&#30340;&#26368;&#20248;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22810;&#33218;&#32769;&#34382;&#26426;&#20013;&#20004;&#20010;&#20856;&#22411;&#30446;&#26631;&#30340;&#24085;&#32047;&#25176;&#21069;&#27839;&#65292;&#21363;&#22266;&#23450;&#26102;&#38388;&#20869;&#30340;&#21518;&#24724;&#26368;&#23567;&#21270;&#21644;&#26368;&#20339;&#33218;&#35782;&#21035;&#12290;&#24179;&#34913;&#25506;&#32034;&#21644;&#21033;&#29992;&#23545;&#20110;&#21518;&#24724;&#26368;&#23567;&#21270;&#21644;&#26368;&#20339;&#33218;&#35782;&#21035;&#37117;&#33267;&#20851;&#37325;&#35201;&#65292;&#20294;&#23545;&#20110;&#21518;&#32773;&#26469;&#35828;&#65292;&#25506;&#32034;&#26356;&#20851;&#38190;&#12290;&#26412;&#25991;&#35774;&#35745;&#21644;&#20998;&#26512;&#20102;BoBW-lil'UCB $(\gamma)$&#31639;&#27861;&#65292;&#36890;&#36807;&#24314;&#31435;&#22522;&#20110;BAI&#22833;&#36133;&#27010;&#29575;&#30340;&#21487;&#36798;&#21040;&#36951;&#25022;&#19979;&#38480;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;(i)&#27809;&#26377;&#31639;&#27861;&#33021;&#21516;&#26102;&#20026;RM&#21644;BAI&#30446;&#26631;&#34920;&#29616;&#26368;&#20339;&#65292;(ii)BoBW-lil'UCB $(\gamma)$&#21487;&#22312;&#19981;&#21516;&#30340;$\gamma$&#20540;&#19979;&#23454;&#29616;RM&#25110;BAI&#30340;&#26368;&#20248;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#36890;&#36807;&#23637;&#31034;&#20808;&#21069;&#20316;&#21697;&#20013;&#30340;&#24120;&#25968;&#22914;&#20309;&#20381;&#36182;&#26576;&#20123;&#38590;&#24230;&#21442;&#25968;&#65292;&#26356;&#31934;&#30830;&#22320;&#38416;&#26126;&#20102;&#27492;&#31867;&#31639;&#27861;&#20013;&#30340;&#26435;&#34913;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;BoBW-lil'UCB&#20248;&#20110;&#20854;&#26368;&#25509;&#36817;&#30340;&#31454;&#20105;&#32773;UCB$_\alpha$&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the Pareto frontier of two archetypal objectives in multi-armed bandits, namely, regret minimization (RM) and best arm identification (BAI) with a fixed horizon. It is folklore that the balance between exploitation and exploration is crucial for both RM and BAI, but exploration is more critical in achieving the optimal performance for the latter objective. To this end, we design and analyze the BoBW-lil'UCB$(\gamma)$ algorithm. Complementarily, by establishing lower bounds on the regret achievable by any algorithm with a given BAI failure probability, we show that (i) no algorithm can simultaneously perform optimally for both the RM and BAI objectives, and (ii) BoBW-lil'UCB$(\gamma)$ achieves order-wise optimal performance for RM or BAI under different values of $\gamma$. Our work elucidates the trade-off more precisely by showing how the constants in previous works depend on certain hardness parameters. Finally, we show that BoBW-lil'UCB outperforms a close competitor UCB$_\a
&lt;/p&gt;</description></item></channel></rss>