<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;IW-GAE&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24320;&#21457;&#19968;&#31181;&#26032;&#39062;&#30340;&#21152;&#26435;&#32676;&#20934;&#30830;&#29575;&#20272;&#35745;&#22120;&#26469;&#35299;&#20915;&#38750;&#30417;&#30563;&#39046;&#22495;&#36866;&#24212;&#20013;&#30340;&#26657;&#20934;&#21644;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#32463;&#36807;&#29702;&#35770;&#20998;&#26512;&#21644;&#23454;&#39564;&#39564;&#35777;&#65292;&#35813;&#26041;&#27861;&#22312;&#22788;&#29702;&#25968;&#25454;&#20998;&#24067;&#20559;&#31227;&#26041;&#38754;&#34920;&#29616;&#20986;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.10611</link><description>&lt;p&gt;
IW-GAE: &#29992;&#20110;&#25552;&#39640;&#38750;&#30417;&#30563;&#39046;&#22495;&#36866;&#24212;&#20013;&#30340;&#26657;&#20934;&#21644;&#27169;&#22411;&#36873;&#25321;&#30340;&#21152;&#26435;&#32676;&#20934;&#30830;&#29575;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
IW-GAE: Importance weighted group accuracy estimation for improved calibration and model selection in unsupervised domain adaptation. (arXiv:2310.10611v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10611
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;IW-GAE&#30340;&#26041;&#27861;&#65292;&#36890;&#36807;&#24320;&#21457;&#19968;&#31181;&#26032;&#39062;&#30340;&#21152;&#26435;&#32676;&#20934;&#30830;&#29575;&#20272;&#35745;&#22120;&#26469;&#35299;&#20915;&#38750;&#30417;&#30563;&#39046;&#22495;&#36866;&#24212;&#20013;&#30340;&#26657;&#20934;&#21644;&#27169;&#22411;&#36873;&#25321;&#38382;&#39064;&#12290;&#32463;&#36807;&#29702;&#35770;&#20998;&#26512;&#21644;&#23454;&#39564;&#39564;&#35777;&#65292;&#35813;&#26041;&#27861;&#22312;&#22788;&#29702;&#25968;&#25454;&#20998;&#24067;&#20559;&#31227;&#26041;&#38754;&#34920;&#29616;&#20986;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35745;&#31639;&#27169;&#22411;&#22312;&#27979;&#35797;&#26679;&#26412;&#19978;&#30340;&#20934;&#30830;&#29575;&#24182;&#20174;&#20013;&#25512;&#26029;&#20854;&#32622;&#20449;&#24230;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#26680;&#24515;&#38382;&#39064;&#65292;&#19982;&#19981;&#30830;&#23450;&#24615;&#34920;&#31034;&#12289;&#27169;&#22411;&#36873;&#25321;&#21644;&#25506;&#32034;&#31561;&#37325;&#35201;&#24212;&#29992;&#23494;&#20999;&#30456;&#20851;&#12290;&#34429;&#28982;&#36825;&#20123;&#36830;&#25509;&#22312;&#29420;&#31435;&#21516;&#20998;&#24067;&#35774;&#32622;&#20013;&#24050;&#32463;&#34987;&#24191;&#27867;&#30740;&#31350;&#65292;&#20294;&#25968;&#25454;&#20998;&#24067;&#30340;&#20559;&#31227;&#32473;&#20256;&#32479;&#26041;&#27861;&#24102;&#26469;&#20102;&#37325;&#22823;&#25361;&#25112;&#12290;&#22240;&#27492;&#65292;&#22312;&#38750;&#30417;&#30563;&#39046;&#22495;&#36866;&#24212;&#38382;&#39064;&#20013;&#65292;&#27169;&#22411;&#26657;&#20934;&#21644;&#27169;&#22411;&#36873;&#25321;&#20173;&#28982;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#36825;&#26159;&#19968;&#31181;&#22312;&#27809;&#26377;&#26631;&#31614;&#30340;&#24773;&#20917;&#19979;&#22312;&#25968;&#25454;&#20998;&#24067;&#21457;&#29983;&#20559;&#31227;&#30340;&#39046;&#22495;&#20013;&#34920;&#29616;&#33391;&#22909;&#30340;&#22330;&#26223;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#24320;&#21457;&#19968;&#31181;&#26032;&#39062;&#30340;&#21152;&#26435;&#32676;&#20934;&#30830;&#29575;&#20272;&#35745;&#22120;&#26469;&#35299;&#20915;&#30001;&#20110;&#25968;&#25454;&#20998;&#24067;&#30340;&#20559;&#31227;&#32780;&#24102;&#26469;&#30340;&#22256;&#38590;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#21046;&#23450;&#20102;&#19968;&#20010;&#20248;&#21270;&#38382;&#39064;&#65292;&#25214;&#21040;&#23548;&#33268;&#22312;&#25968;&#25454;&#20998;&#24067;&#20559;&#31227;&#30340;&#39046;&#22495;&#20013;&#20934;&#30830;&#20272;&#35745;&#32676;&#20934;&#30830;&#29575;&#30340;&#37325;&#35201;&#26435;&#37325;&#65292;&#24182;&#36827;&#34892;&#20102;&#29702;&#35770;&#20998;&#26512;&#12290;&#22823;&#37327;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#20102;&#32676;&#20934;&#30830;&#29575;&#20272;&#35745;&#22312;&#27169;&#22411;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reasoning about a model's accuracy on a test sample from its confidence is a central problem in machine learning, being connected to important applications such as uncertainty representation, model selection, and exploration. While these connections have been well-studied in the i.i.d. settings, distribution shifts pose significant challenges to the traditional methods. Therefore, model calibration and model selection remain challenging in the unsupervised domain adaptation problem--a scenario where the goal is to perform well in a distribution shifted domain without labels. In this work, we tackle difficulties coming from distribution shifts by developing a novel importance weighted group accuracy estimator. Specifically, we formulate an optimization problem for finding an importance weight that leads to an accurate group accuracy estimation in the distribution shifted domain with theoretical analyses. Extensive experiments show the effectiveness of group accuracy estimation on model 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21457;&#29616;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;MPNNs&#65289;&#21487;&#20197;&#27169;&#25311;&#26631;&#20934;&#20869;&#28857;&#27861;&#26469;&#35299;&#20915;&#32447;&#24615;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#19988;&#22312;&#35299;&#20915;&#26102;&#38388;&#19978;&#34920;&#29616;&#20986;&#33394;&#65292;&#36229;&#36807;&#20102;&#20256;&#32479;&#27714;&#35299;&#22120;&#21644;&#31454;&#20105;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.10603</link><description>&lt;p&gt;
&#25506;&#32034;&#22270;&#31070;&#32463;&#32593;&#32476;&#22312;&#35299;&#20915;&#32447;&#24615;&#20248;&#21270;&#38382;&#39064;&#20013;&#30340;&#23041;&#21147;
&lt;/p&gt;
&lt;p&gt;
Exploring the Power of Graph Neural Networks in Solving Linear Optimization Problems. (arXiv:2310.10603v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10603
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21457;&#29616;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;MPNNs&#65289;&#21487;&#20197;&#27169;&#25311;&#26631;&#20934;&#20869;&#28857;&#27861;&#26469;&#35299;&#20915;&#32447;&#24615;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#19988;&#22312;&#35299;&#20915;&#26102;&#38388;&#19978;&#34920;&#29616;&#20986;&#33394;&#65292;&#36229;&#36807;&#20102;&#20256;&#32479;&#27714;&#35299;&#22120;&#21644;&#31454;&#20105;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#26426;&#22120;&#23398;&#20064;&#29305;&#21035;&#26159;&#28040;&#24687;&#20256;&#36882;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;MPNNs&#65289;&#22312;&#22686;&#24378;&#31934;&#30830;&#20248;&#21270;&#31639;&#27861;&#26041;&#38754;&#24050;&#32463;&#24341;&#36215;&#20102;&#20851;&#27880;&#12290;&#20363;&#22914;&#65292;MPNNs&#36890;&#36807;&#27169;&#25311;&#35745;&#31639;&#23494;&#38598;&#22411;&#21551;&#21457;&#24335;&#26041;&#27861;&#22914;&#24378;&#25903;&#20998;&#25903;&#21152;&#36895;&#35299;&#20915;&#28151;&#21512;&#25972;&#25968;&#20248;&#21270;&#38382;&#39064;&#65292;&#36825;&#38656;&#35201;&#35299;&#20915;&#22810;&#20010;&#32447;&#24615;&#20248;&#21270;&#38382;&#39064;&#65288;LPs&#65289;&#12290;&#23613;&#31649;&#26377;&#23454;&#35777;&#25104;&#21151;&#65292;&#20294;MPNNs&#22312;&#27169;&#25311;&#32447;&#24615;&#20248;&#21270;&#26041;&#38754;&#30340;&#26377;&#25928;&#24615;&#30340;&#21407;&#22240;&#20173;&#28982;&#19981;&#28165;&#26970;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;MPNNs&#21487;&#20197;&#27169;&#25311;LPs&#30340;&#26631;&#20934;&#20869;&#28857;&#27861;&#65292;&#35299;&#37322;&#20102;&#23427;&#20204;&#22312;&#23454;&#36341;&#20013;&#30340;&#25104;&#21151;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#24378;&#35843;&#20102;MPNNs&#22914;&#20309;&#20316;&#20026;&#35299;&#20915;LPs&#30340;&#36731;&#37327;&#32423;&#20195;&#29702;&#65292;&#36866;&#24212;&#32473;&#23450;&#30340;&#38382;&#39064;&#23454;&#20363;&#20998;&#24067;&#12290;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;MPNNs&#22312;&#25509;&#36817;&#26368;&#20248;&#24615;&#19978;&#35299;&#20915;&#20102;&#26631;&#20934;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#30340;LP&#26494;&#24347;&#65292;&#36890;&#24120;&#22312;&#35299;&#20915;&#26102;&#38388;&#19978;&#36229;&#36807;&#20102;&#20256;&#32479;&#27714;&#35299;&#22120;&#21644;&#31454;&#20105;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recently, machine learning, particularly message-passing graph neural networks (MPNNs), has gained traction in enhancing exact optimization algorithms. For example, MPNNs speed up solving mixed-integer optimization problems by imitating computational intensive heuristics like strong branching, which entails solving multiple linear optimization problems (LPs). Despite the empirical success, the reasons behind MPNNs' effectiveness in emulating linear optimization remain largely unclear. Here, we show that MPNNs can simulate standard interior-point methods for LPs, explaining their practical success. Furthermore, we highlight how MPNNs can serve as a lightweight proxy for solving LPs, adapting to a given problem instance distribution. Empirically, we show that MPNNs solve LP relaxations of standard combinatorial optimization problems close to optimality, often surpassing conventional solvers and competing approaches in solving time.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#26524;&#21160;&#24577;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;CDVAE&#65289;&#26469;&#35299;&#20915;&#32437;&#21521;&#25968;&#25454;&#20013;&#30340;&#21453;&#20107;&#23454;&#22238;&#24402;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#20551;&#35774;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#35843;&#25972;&#21464;&#37327;&#65292;&#24182;&#36890;&#36807;&#32467;&#21512;&#21160;&#24577;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;DVAE&#65289;&#26694;&#26550;&#21644;&#20351;&#29992;&#20542;&#21521;&#24471;&#20998;&#30340;&#21152;&#26435;&#31574;&#30053;&#26469;&#20272;&#35745;&#21453;&#20107;&#23454;&#21709;&#24212;&#12290;</title><link>http://arxiv.org/abs/2310.10559</link><description>&lt;p&gt;
&#22240;&#26524;&#21160;&#24577;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#29992;&#20110;&#32437;&#21521;&#25968;&#25454;&#20013;&#30340;&#21453;&#20107;&#23454;&#22238;&#24402;
&lt;/p&gt;
&lt;p&gt;
Causal Dynamic Variational Autoencoder for Counterfactual Regression in Longitudinal Data. (arXiv:2310.10559v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10559
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22240;&#26524;&#21160;&#24577;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;CDVAE&#65289;&#26469;&#35299;&#20915;&#32437;&#21521;&#25968;&#25454;&#20013;&#30340;&#21453;&#20107;&#23454;&#22238;&#24402;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#20551;&#35774;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#35843;&#25972;&#21464;&#37327;&#65292;&#24182;&#36890;&#36807;&#32467;&#21512;&#21160;&#24577;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;DVAE&#65289;&#26694;&#26550;&#21644;&#20351;&#29992;&#20542;&#21521;&#24471;&#20998;&#30340;&#21152;&#26435;&#31574;&#30053;&#26469;&#20272;&#35745;&#21453;&#20107;&#23454;&#21709;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#24456;&#22810;&#23454;&#38469;&#24212;&#29992;&#20013;&#65292;&#22914;&#31934;&#20934;&#21307;&#23398;&#12289;&#27969;&#34892;&#30149;&#23398;&#12289;&#32463;&#27982;&#21644;&#24066;&#22330;&#33829;&#38144;&#20013;&#65292;&#20272;&#35745;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#27835;&#30103;&#25928;&#26524;&#26159;&#30456;&#20851;&#30340;&#12290;&#35768;&#22810;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#35201;&#20040;&#20551;&#35774;&#20102;&#25152;&#26377;&#28151;&#26434;&#21464;&#37327;&#30340;&#35266;&#27979;&#32467;&#26524;&#65292;&#35201;&#20040;&#35797;&#22270;&#25512;&#26029;&#26410;&#35266;&#23519;&#21040;&#30340;&#28151;&#26434;&#21464;&#37327;&#12290;&#25105;&#20204;&#37319;&#21462;&#20102;&#19981;&#21516;&#30340;&#35266;&#28857;&#65292;&#20551;&#35774;&#23384;&#22312;&#26410;&#35266;&#23519;&#21040;&#30340;&#39118;&#38505;&#22240;&#32032;&#65292;&#21363;&#20165;&#24433;&#21709;&#32467;&#26524;&#24207;&#21015;&#30340;&#35843;&#25972;&#21464;&#37327;&#12290;&#22312;&#26080;&#28151;&#26434;&#24615;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#20197;&#26410;&#35266;&#27979;&#21040;&#30340;&#39118;&#38505;&#22240;&#32032;&#23548;&#33268;&#30340;&#27835;&#30103;&#21453;&#24212;&#20013;&#30340;&#26410;&#30693;&#24322;&#36136;&#24615;&#20026;&#30446;&#26631;&#65292;&#20272;&#35745;&#20010;&#20307;&#27835;&#30103;&#25928;&#26524;&#65288;ITE&#65289;&#12290;&#25105;&#20204;&#24212;&#23545;&#20102;&#26102;&#21464;&#25928;&#24212;&#21644;&#26410;&#35266;&#23519;&#21040;&#30340;&#35843;&#25972;&#21464;&#37327;&#25152;&#24102;&#26469;&#30340;&#25361;&#25112;&#12290;&#22312;&#23398;&#20064;&#21040;&#30340;&#35843;&#25972;&#21464;&#37327;&#30340;&#26377;&#25928;&#24615;&#21644;&#27835;&#30103;&#25928;&#26524;&#30340;&#19968;&#33324;&#21270;&#30028;&#38480;&#30340;&#29702;&#35770;&#32467;&#26524;&#25351;&#23548;&#19979;&#65292;&#25105;&#20204;&#35774;&#35745;&#20102;&#22240;&#26524;DVAE&#65288;CDVAE&#65289;&#12290;&#35813;&#27169;&#22411;&#23558;&#21160;&#24577;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#65288;DVAE&#65289;&#26694;&#26550;&#19982;&#20351;&#29992;&#20542;&#21521;&#24471;&#20998;&#30340;&#21152;&#26435;&#31574;&#30053;&#30456;&#32467;&#21512;&#65292;&#29992;&#20110;&#20272;&#35745;&#21453;&#20107;&#23454;&#21709;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
Estimating treatment effects over time is relevant in many real-world applications, such as precision medicine, epidemiology, economy, and marketing. Many state-of-the-art methods either assume the observations of all confounders or seek to infer the unobserved ones. We take a different perspective by assuming unobserved risk factors, i.e., adjustment variables that affect only the sequence of outcomes. Under unconfoundedness, we target the Individual Treatment Effect (ITE) estimation with unobserved heterogeneity in the treatment response due to missing risk factors. We address the challenges posed by time-varying effects and unobserved adjustment variables. Led by theoretical results over the validity of the learned adjustment variables and generalization bounds over the treatment effect, we devise Causal DVAE (CDVAE). This model combines a Dynamic Variational Autoencoder (DVAE) framework with a weighting strategy using propensity scores to estimate counterfactual responses. The CDVA
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#28145;&#24230;&#32593;&#32476;&#20013;&#20351;&#29992;&#20154;&#31867;&#20559;&#22909;&#36827;&#34892;&#38750;&#21442;&#25968;&#31163;&#31574;&#30053;&#35780;&#20272;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#65292;&#24182;&#24314;&#31435;&#20102;&#32479;&#35745;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2310.10556</link><description>&lt;p&gt;
&#22522;&#20110;&#20154;&#31867;&#20559;&#22909;&#30340;&#38750;&#21442;&#25968;&#31163;&#31574;&#30053;&#35780;&#20272;&#22312;&#28145;&#24230;&#32593;&#32476;&#20013;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;
&lt;/p&gt;
&lt;p&gt;
Sample Complexity of Preference-Based Nonparametric Off-Policy Evaluation with Deep Networks. (arXiv:2310.10556v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10556
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#28145;&#24230;&#32593;&#32476;&#20013;&#20351;&#29992;&#20154;&#31867;&#20559;&#22909;&#36827;&#34892;&#38750;&#21442;&#25968;&#31163;&#31574;&#30053;&#35780;&#20272;&#30340;&#26679;&#26412;&#22797;&#26434;&#24615;&#65292;&#24182;&#24314;&#31435;&#20102;&#32479;&#35745;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#27969;&#34892;&#30340;&#35299;&#20915;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#30340;&#26041;&#27861;&#26159;&#20351;&#29992;&#20154;&#31867;&#20559;&#22909;&#25968;&#25454;&#12290;&#20107;&#23454;&#19978;&#65292;&#20154;&#31867;&#20559;&#22909;&#25968;&#25454;&#29616;&#22312;&#19982;&#32463;&#20856;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65288;&#22914;&#28436;&#21592;-&#35780;&#35770;&#23478;&#26041;&#27861;&#65289;&#19968;&#36215;&#20351;&#29992;&#65292;&#22312;&#20174;&#20154;&#31867;&#20559;&#22909;&#25968;&#25454;&#20013;&#23398;&#20064;&#30340;&#22870;&#21169;&#19978;&#35780;&#20272;&#20013;&#38388;&#31574;&#30053;&#65292;&#21363;&#31163;&#31574;&#30053;&#35780;&#20272;&#65288;OPE&#65289;&#12290;&#35813;&#31639;&#27861;&#21253;&#25324;&#65288;i&#65289;&#20174;&#20154;&#31867;&#20559;&#22909;&#25968;&#25454;&#38598;&#20013;&#23398;&#20064;&#22870;&#21169;&#20989;&#25968;&#65292;&#20197;&#21450;&#65288;ii&#65289;&#23398;&#20064;&#30446;&#26631;&#31574;&#30053;&#30340;&#32047;&#31215;&#22870;&#21169;&#12290;&#23613;&#31649;&#26377;&#24040;&#22823;&#30340;&#32463;&#39564;&#25104;&#21151;&#65292;&#20294;&#29616;&#26377;&#30340;&#20351;&#29992;&#20559;&#22909;&#25968;&#25454;&#30340;OPE&#26041;&#27861;&#36890;&#24120;&#32570;&#20047;&#29702;&#35770;&#29702;&#35299;&#65292;&#24182;&#19988;&#20005;&#37325;&#20381;&#36182;&#20110;&#21551;&#21457;&#24335;&#26041;&#27861;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22522;&#20110;&#20154;&#31867;&#20559;&#22909;&#30340;OPE&#30340;&#26679;&#26412;&#25928;&#29575;&#65292;&#24182;&#20026;&#20854;&#24314;&#31435;&#20102;&#32479;&#35745;&#20445;&#35777;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#36890;&#36807;&#20351;&#29992;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#25311;&#21512;Q&#35780;&#20272;&#26469;&#22788;&#29702;OPE&#12290;&#36890;&#36807;&#36866;&#24403;&#36873;&#25321;ReLU&#32593;&#32476;&#30340;&#22823;&#23567;&#65292;&#25105;&#20204;&#34920;&#26126;&#21487;&#20197;&#21033;&#29992;&#20219;&#20309;lo
&lt;/p&gt;
&lt;p&gt;
A recently popular approach to solving reinforcement learning is with data from human preferences. In fact, human preference data are now used with classic reinforcement learning algorithms such as actor-critic methods, which involve evaluating an intermediate policy over a reward learned from human preference data with distribution shift, known as off-policy evaluation (OPE). Such algorithm includes (i) learning reward function from human preference dataset, and (ii) learning expected cumulative reward of a target policy. Despite the huge empirical success, existing OPE methods with preference data often lack theoretical understanding and rely heavily on heuristics. In this paper, we study the sample efficiency of OPE with human preference and establish a statistical guarantee for it. Specifically, we approach OPE by learning the value function by fitted-Q-evaluation with a deep neural network. By appropriately selecting the size of a ReLU network, we show that one can leverage any lo
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;TacticAI&#65292;&#19968;&#31181;&#19982;&#21033;&#29289;&#28006;&#36275;&#29699;&#20465;&#20048;&#37096;&#30340;&#39046;&#22495;&#19987;&#23478;&#23494;&#20999;&#21512;&#20316;&#24320;&#21457;&#21644;&#35780;&#20215;&#30340;AI&#36275;&#29699;&#25112;&#26415;&#21161;&#25163;&#12290;TacticAI&#33021;&#22815;&#36890;&#36807;&#39044;&#27979;&#21644;&#29983;&#25104;&#30340;&#26041;&#24335;&#24110;&#21161;&#25945;&#32451;&#20204;&#20998;&#26512;&#35282;&#29699;&#24773;&#20917;&#65292;&#24182;&#20026;&#27599;&#20010;&#35282;&#29699;&#24815;&#20363;&#36873;&#25321;&#25104;&#21151;&#21487;&#33021;&#24615;&#26368;&#39640;&#30340;&#29699;&#21592;&#37197;&#32622;&#12290;</title><link>http://arxiv.org/abs/2310.10553</link><description>&lt;p&gt;
TacticAI:&#19968;&#31181;&#36275;&#29699;&#25112;&#26415;&#30340;&#20154;&#24037;&#26234;&#33021;&#21161;&#25163;
&lt;/p&gt;
&lt;p&gt;
TacticAI: an AI assistant for football tactics. (arXiv:2310.10553v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10553
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;TacticAI&#65292;&#19968;&#31181;&#19982;&#21033;&#29289;&#28006;&#36275;&#29699;&#20465;&#20048;&#37096;&#30340;&#39046;&#22495;&#19987;&#23478;&#23494;&#20999;&#21512;&#20316;&#24320;&#21457;&#21644;&#35780;&#20215;&#30340;AI&#36275;&#29699;&#25112;&#26415;&#21161;&#25163;&#12290;TacticAI&#33021;&#22815;&#36890;&#36807;&#39044;&#27979;&#21644;&#29983;&#25104;&#30340;&#26041;&#24335;&#24110;&#21161;&#25945;&#32451;&#20204;&#20998;&#26512;&#35282;&#29699;&#24773;&#20917;&#65292;&#24182;&#20026;&#27599;&#20010;&#35282;&#29699;&#24815;&#20363;&#36873;&#25321;&#25104;&#21151;&#21487;&#33021;&#24615;&#26368;&#39640;&#30340;&#29699;&#21592;&#37197;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36776;&#21035;&#23545;&#25163;&#22242;&#38431;&#23454;&#26045;&#30340;&#25112;&#26415;&#20851;&#38190;&#27169;&#24335;&#24182;&#24320;&#21457;&#26377;&#25928;&#30340;&#24212;&#23545;&#26041;&#27861;&#26159;&#29616;&#20195;&#36275;&#29699;&#30340;&#26680;&#24515;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#20197;&#31639;&#27861;&#30340;&#26041;&#24335;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#20173;&#26159;&#19968;&#20010;&#26410;&#35299;&#20915;&#30340;&#30740;&#31350;&#25361;&#25112;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38656;&#27714;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;TacticAI&#65292;&#19968;&#31181;&#19982;&#21033;&#29289;&#28006;&#36275;&#29699;&#20465;&#20048;&#37096;&#30340;&#39046;&#22495;&#19987;&#23478;&#23494;&#20999;&#21512;&#20316;&#24320;&#21457;&#21644;&#35780;&#20215;&#30340;AI&#36275;&#29699;&#25112;&#26415;&#21161;&#25163;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#20998;&#26512;&#35282;&#29699;&#65292;&#22240;&#20026;&#23427;&#20204;&#32473;&#25945;&#32451;&#20204;&#25552;&#20379;&#20102;&#30452;&#25509;&#30340;&#24178;&#39044;&#21644;&#25913;&#36827;&#26426;&#20250;&#12290;TacticAI&#21253;&#21547;&#20102;&#19968;&#20010;&#39044;&#27979;&#21644;&#29983;&#25104;&#30340;&#32452;&#20214;&#65292;&#20351;&#25945;&#32451;&#33021;&#22815;&#26377;&#25928;&#22320;&#37319;&#26679;&#21644;&#25506;&#32034;&#27599;&#20010;&#35282;&#29699;&#24815;&#20363;&#30340;&#26367;&#20195;&#29699;&#21592;&#37197;&#32622;&#65292;&#24182;&#36873;&#25321;&#37027;&#20123;&#39044;&#27979;&#25104;&#21151;&#21487;&#33021;&#24615;&#26368;&#39640;&#30340;&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#20123;&#30456;&#20851;&#30340;&#22522;&#20934;&#20219;&#21153;&#23545;TacticAI&#36827;&#34892;&#20102;&#39564;&#35777;&#65306;&#39044;&#27979;&#25509;&#25910;&#29699;&#21592;&#21644;&#23556;&#38376;&#23581;&#35797;&#20197;&#21450;&#25512;&#33616;&#29699;&#21592;&#20301;&#32622;&#35843;&#25972;&#12290;TacticAI&#30340;&#23454;&#29992;&#24615;&#36890;&#36807;&#19982;&#21033;&#29289;&#28006;&#36275;&#29699;&#39046;&#22495;&#19987;&#23478;&#36827;&#34892;&#30340;&#23450;&#24615;&#30740;&#31350;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Identifying key patterns of tactics implemented by rival teams, and developing effective responses, lies at the heart of modern football. However, doing so algorithmically remains an open research challenge. To address this unmet need, we propose TacticAI, an AI football tactics assistant developed and evaluated in close collaboration with domain experts from Liverpool FC. We focus on analysing corner kicks, as they offer coaches the most direct opportunities for interventions and improvements. TacticAI incorporates both a predictive and a generative component, allowing the coaches to effectively sample and explore alternative player setups for each corner kick routine and to select those with the highest predicted likelihood of success. We validate TacticAI on a number of relevant benchmark tasks: predicting receivers and shot attempts and recommending player position adjustments. The utility of TacticAI is validated by a qualitative study conducted with football domain experts at Liv
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37319;&#29992;&#36890;&#36135;&#32039;&#32553;&#21464;&#37327;&#26059;&#36716;&#30340;&#25311;&#21512;&#22240;&#23376;&#20998;&#26512;&#26041;&#27861;&#65292;&#22312;&#27599;&#19968;&#34892;&#19978;&#36880;&#27493;&#27714;&#35299;&#27491;&#20132;&#30697;&#38453;&#65292;&#30456;&#27604;&#20110;&#20256;&#32479;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#35745;&#31639;&#24615;&#33021;&#21644;&#28789;&#27963;&#24615;&#65292;&#24182;&#19988;&#22312;&#26356;&#24191;&#27867;&#30340;&#32972;&#26223;&#19979;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2310.10545</link><description>&lt;p&gt;
&#20248;&#21270;&#25311;&#21512;&#22240;&#23376;&#20998;&#26512;&#19982;&#36890;&#36135;&#32039;&#32553;&#21464;&#37327;&#26059;&#36716;
&lt;/p&gt;
&lt;p&gt;
Optimal vintage factor analysis with deflation varimax. (arXiv:2310.10545v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10545
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37319;&#29992;&#36890;&#36135;&#32039;&#32553;&#21464;&#37327;&#26059;&#36716;&#30340;&#25311;&#21512;&#22240;&#23376;&#20998;&#26512;&#26041;&#27861;&#65292;&#22312;&#27599;&#19968;&#34892;&#19978;&#36880;&#27493;&#27714;&#35299;&#27491;&#20132;&#30697;&#38453;&#65292;&#30456;&#27604;&#20110;&#20256;&#32479;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#35745;&#31639;&#24615;&#33021;&#21644;&#28789;&#27963;&#24615;&#65292;&#24182;&#19988;&#22312;&#26356;&#24191;&#27867;&#30340;&#32972;&#26223;&#19979;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36135;&#32039;&#32553;&#21464;&#37327;&#26059;&#36716;&#26159;&#19968;&#31181;&#37325;&#35201;&#30340;&#22240;&#23376;&#20998;&#26512;&#26041;&#27861;&#65292;&#26088;&#22312;&#39318;&#20808;&#25214;&#21040;&#21407;&#22987;&#25968;&#25454;&#30340;&#20302;&#32500;&#34920;&#31034;&#65292;&#28982;&#21518;&#23547;&#27714;&#26059;&#36716;&#65292;&#20351;&#26059;&#36716;&#21518;&#30340;&#20302;&#32500;&#34920;&#31034;&#20855;&#26377;&#31185;&#23398;&#24847;&#20041;&#12290;&#23613;&#31649;Principal Component Analysis (PCA) followed by the varimax rotation&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#25311;&#21512;&#22240;&#23376;&#20998;&#26512;&#65292;&#20294;&#30001;&#20110;varimax rotation&#38656;&#35201;&#22312;&#27491;&#20132;&#30697;&#38453;&#38598;&#21512;&#19978;&#35299;&#38750;&#20984;&#20248;&#21270;&#38382;&#39064;&#65292;&#22240;&#27492;&#24456;&#38590;&#25552;&#20379;&#29702;&#35770;&#20445;&#35777;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36880;&#34892;&#27714;&#35299;&#27491;&#20132;&#30697;&#38453;&#30340;&#36890;&#36135;&#32039;&#32553;&#21464;&#37327;&#26059;&#36716;&#36807;&#31243;&#12290;&#38500;&#20102;&#22312;&#35745;&#31639;&#19978;&#30340;&#20248;&#21183;&#21644;&#28789;&#27963;&#24615;&#20043;&#22806;&#65292;&#25105;&#20204;&#36824;&#33021;&#22312;&#24191;&#27867;&#30340;&#32972;&#26223;&#19979;&#23545;&#25152;&#25552;&#20986;&#30340;&#36807;&#31243;&#36827;&#34892;&#23436;&#20840;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#22312;PCA&#20043;&#21518;&#37319;&#29992;&#36825;&#31181;&#26032;&#30340;varimax&#26041;&#27861;&#20316;&#20026;&#31532;&#20108;&#27493;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#20998;&#26512;&#20102;&#36825;&#20010;&#20004;&#27493;&#36807;&#31243;&#22312;&#19968;&#20010;&#26356;&#19968;&#33324;&#30340;&#22240;&#23376;&#27169;&#22411;&#30340;&#24773;&#20917;&#19979;&#12290;
&lt;/p&gt;
&lt;p&gt;
Vintage factor analysis is one important type of factor analysis that aims to first find a low-dimensional representation of the original data, and then to seek a rotation such that the rotated low-dimensional representation is scientifically meaningful. Perhaps the most widely used vintage factor analysis is the Principal Component Analysis (PCA) followed by the varimax rotation. Despite its popularity, little theoretical guarantee can be provided mainly because varimax rotation requires to solve a non-convex optimization over the set of orthogonal matrices.  In this paper, we propose a deflation varimax procedure that solves each row of an orthogonal matrix sequentially. In addition to its net computational gain and flexibility, we are able to fully establish theoretical guarantees for the proposed procedure in a broad context.  Adopting this new varimax approach as the second step after PCA, we further analyze this two step procedure under a general class of factor models. Our resul
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25512;&#23548;&#20102;&#28041;&#21450;&#20219;&#24847;&#20984;&#27604;&#36739;&#20989;&#25968;&#30340;&#36890;&#29992;&#20449;&#24687;&#29702;&#35770;&#21644;PAC-Bayesian&#27867;&#21270;&#30028;&#38480;&#65292;&#35777;&#26126;&#20102;&#26368;&#32039;&#30028;&#38480;&#26159;&#30001;&#20984;&#20849;&#36717;&#30340;&#32047;&#31215;&#29983;&#25104;&#20989;&#25968;(CGF)&#26500;&#25104;&#30340;&#65292;&#20351;&#24471;&#36825;&#20123;&#30028;&#38480;&#24191;&#27867;&#36866;&#29992;&#20110;&#19981;&#21516;&#32467;&#26500;&#30340;&#27867;&#21270;&#30028;&#38480;&#12290;</title><link>http://arxiv.org/abs/2310.10534</link><description>&lt;p&gt;
&#23545;&#27604;&#20998;&#31867;&#22120;&#22312;&#27867;&#21270;&#30028;&#38480;&#20013;&#30340;&#27604;&#36739;
&lt;/p&gt;
&lt;p&gt;
Comparing Comparators in Generalization Bounds. (arXiv:2310.10534v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10534
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25512;&#23548;&#20102;&#28041;&#21450;&#20219;&#24847;&#20984;&#27604;&#36739;&#20989;&#25968;&#30340;&#36890;&#29992;&#20449;&#24687;&#29702;&#35770;&#21644;PAC-Bayesian&#27867;&#21270;&#30028;&#38480;&#65292;&#35777;&#26126;&#20102;&#26368;&#32039;&#30028;&#38480;&#26159;&#30001;&#20984;&#20849;&#36717;&#30340;&#32047;&#31215;&#29983;&#25104;&#20989;&#25968;(CGF)&#26500;&#25104;&#30340;&#65292;&#20351;&#24471;&#36825;&#20123;&#30028;&#38480;&#24191;&#27867;&#36866;&#29992;&#20110;&#19981;&#21516;&#32467;&#26500;&#30340;&#27867;&#21270;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25512;&#23548;&#20102;&#28041;&#21450;&#20219;&#24847;&#20984;&#27604;&#36739;&#20989;&#25968;&#30340;&#36890;&#29992;&#20449;&#24687;&#29702;&#35770;&#21644;PAC-Bayesian&#27867;&#21270;&#30028;&#38480;&#65292;&#35813;&#20989;&#25968;&#27979;&#37327;&#35757;&#32451;&#35823;&#24046;&#21644;&#26679;&#26412;&#35823;&#24046;&#20043;&#38388;&#30340;&#24046;&#24322;&#12290;&#35813;&#30028;&#38480;&#22312;&#27604;&#36739;&#20989;&#25968;&#30340;&#32047;&#31215;&#29983;&#25104;&#20989;&#25968;(CG), &#34987;&#30028;&#23450;&#22312;&#19968;&#26063;&#38480;&#21046;&#20998;&#24067;&#20989;&#25968;&#30340;CGF&#19978;&#38480;&#30340;&#20551;&#35774;&#19979;&#25104;&#31435;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#24403;&#27604;&#36739;&#20989;&#25968;&#26159;CGF&#30340;&#20984;&#20849;&#36717;&#65292;&#20063;&#34987;&#31216;&#20026;Cram\'er&#20989;&#25968;&#26102;&#65292;&#24471;&#21040;&#30340;&#30028;&#38480;&#26159;&#26368;&#32039;&#30340;&#12290;&#36825;&#20010;&#32467;&#35770;&#26356;&#24191;&#27867;&#22320;&#36866;&#29992;&#20110;&#20855;&#26377;&#31867;&#20284;&#32467;&#26500;&#30340;&#27867;&#21270;&#30028;&#38480;&#12290;&#36825;&#35777;&#23454;&#20102;&#24050;&#30693;&#30028;&#38480;&#22312;&#26377;&#30028;&#21644;&#27425;&#39640;&#26031;&#25439;&#22833;&#24773;&#20917;&#19979;&#30340;&#36817;&#26368;&#20248;&#24615;&#65292;&#24182;&#19988;&#22312;&#20854;&#20182;&#38480;&#21046;&#20998;&#24067;&#19979;&#24471;&#21040;&#20102;&#26032;&#30340;&#30028;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;
We derive generic information-theoretic and PAC-Bayesian generalization bounds involving an arbitrary convex comparator function, which measures the discrepancy between the training and population loss. The bounds hold under the assumption that the cumulant-generating function (CGF) of the comparator is upper-bounded by the corresponding CGF within a family of bounding distributions. We show that the tightest possible bound is obtained with the comparator being the convex conjugate of the CGF of the bounding distribution, also known as the Cram\'er function. This conclusion applies more broadly to generalization bounds with a similar structure. This confirms the near-optimality of known bounds for bounded and sub-Gaussian losses and leads to novel bounds under other bounding distributions.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#40654;&#26364;&#27969;&#24418;&#19978;&#30340;&#31561;&#21464;&#28040;&#24687;&#20256;&#36882;&#30340;&#20960;&#20309;&#27934;&#23519;&#65292;&#36890;&#36807;&#20248;&#21270;&#24230;&#37327;&#26469;&#23454;&#29616;&#23545;&#40654;&#26364;&#27969;&#24418;&#19978;&#30340;&#25968;&#20540;&#29305;&#24449;&#30340;&#28040;&#24687;&#20256;&#36882;&#65292;&#24182;&#36890;&#36807;&#25193;&#25955;&#36807;&#31243;&#36827;&#34892;&#31163;&#25955;&#21270;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#38454;&#31561;&#21464;&#25193;&#25955;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2310.10448</link><description>&lt;p&gt;
&#19968;&#31181;&#22312;&#40654;&#26364;&#27969;&#24418;&#19978;&#30340;&#31561;&#21464;&#28040;&#24687;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#30340;&#20960;&#20309;&#27934;&#23519;
&lt;/p&gt;
&lt;p&gt;
A Geometric Insight into Equivariant Message Passing Neural Networks on Riemannian Manifolds. (arXiv:2310.10448v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10448
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#40654;&#26364;&#27969;&#24418;&#19978;&#30340;&#31561;&#21464;&#28040;&#24687;&#20256;&#36882;&#30340;&#20960;&#20309;&#27934;&#23519;&#65292;&#36890;&#36807;&#20248;&#21270;&#24230;&#37327;&#26469;&#23454;&#29616;&#23545;&#40654;&#26364;&#27969;&#24418;&#19978;&#30340;&#25968;&#20540;&#29305;&#24449;&#30340;&#28040;&#24687;&#20256;&#36882;&#65292;&#24182;&#36890;&#36807;&#25193;&#25955;&#36807;&#31243;&#36827;&#34892;&#31163;&#25955;&#21270;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#39640;&#38454;&#31561;&#21464;&#25193;&#25955;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#40654;&#26364;&#27969;&#24418;&#19978;&#36827;&#34892;&#31561;&#21464;&#28040;&#24687;&#20256;&#36882;&#30340;&#20960;&#20309;&#27934;&#23519;&#12290;&#22914;&#20808;&#21069;&#25552;&#20986;&#30340;&#65292;&#40654;&#26364;&#27969;&#24418;&#19978;&#30340;&#25968;&#20540;&#29305;&#24449;&#34987;&#34920;&#31034;&#20026;&#27969;&#24418;&#19978;&#30340;&#26080;&#22352;&#26631;&#29305;&#24449;&#22330;&#12290;&#23545;&#20110;&#27969;&#24418;&#19978;&#30340;&#20219;&#20309;&#26080;&#22352;&#26631;&#29305;&#24449;&#22330;&#65292;&#37117;&#38468;&#24102;&#26377;&#19968;&#20010;&#20027;&#19995;&#21040;&#25968;&#20540;&#29305;&#24449;&#31354;&#38388;&#30340;&#31561;&#21464;&#23884;&#20837;&#12290;&#25105;&#20204;&#35748;&#20026;&#36825;&#20010;&#23884;&#20837;&#35825;&#23548;&#30340;&#24230;&#37327;&#24212;&#35813;&#26368;&#20248;&#22320;&#20445;&#30041;&#20027;&#19995;&#21407;&#22987;&#30340;&#24230;&#37327;&#12290;&#36825;&#20010;&#26368;&#20248;&#24615;&#26631;&#20934;&#23548;&#33268;&#20102;&#23545;&#35813;&#23884;&#20837;&#30340;&#22270;&#30340;Polyakov&#20316;&#29992;&#30340;&#25197;&#26354;&#24418;&#24335;&#30340;&#26368;&#23567;&#21270;&#65292;&#20174;&#32780;&#24471;&#21040;&#20102;&#20851;&#32852;&#21521;&#37327;&#19995;&#19978;&#30340;&#31561;&#21464;&#25193;&#25955;&#36807;&#31243;&#12290;&#36890;&#36807;&#23545;&#25193;&#25955;&#26041;&#31243;&#27969;&#36827;&#34892;&#31163;&#25955;&#21270;&#65292;&#25105;&#20204;&#24471;&#21040;&#20102;&#19968;&#20010;&#22312;&#27969;&#24418;&#19978;&#30340;&#28040;&#24687;&#20256;&#36882;&#26041;&#26696;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#39640;&#38454;&#31561;&#21464;&#25193;&#25955;&#36807;&#31243;&#65292;&#23427;&#31561;&#20215;&#20110;&#22312;&#22522;&#26412;&#27969;&#24418;&#30340;&#31515;&#21345;&#23572;&#20056;&#31215;&#19978;&#36827;&#34892;&#25193;&#25955;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work proposes a geometric insight into equivariant message passing on Riemannian manifolds. As previously proposed, numerical features on Riemannian manifolds are represented as coordinate-independent feature fields on the manifold. To any coordinate-independent feature field on a manifold comes attached an equivariant embedding of the principal bundle to the space of numerical features. We argue that the metric this embedding induces on the numerical feature space should optimally preserve the principal bundle's original metric. This optimality criterion leads to the minimization of a twisted form of the Polyakov action with respect to the graph of this embedding, yielding an equivariant diffusion process on the associated vector bundle. We obtain a message passing scheme on the manifold by discretizing the diffusion equation flow for a fixed time step. We propose a higher-order equivariant diffusion process equivalent to diffusion on the cartesian product of the base manifold. T
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24230;&#29305;&#24449;&#21305;&#37197;&#31639;&#27861;&#39640;&#25928;&#21305;&#37197;&#38543;&#26426;&#19981;&#22343;&#21248;&#22270;&#30340;&#26041;&#27861;&#65292;&#35201;&#27714;&#26368;&#23567;&#24179;&#22343;&#24230;&#21644;&#26368;&#23567;&#30456;&#20851;&#24615;&#36798;&#21040;&#19968;&#23450;&#38408;&#20540;&#12290;</title><link>http://arxiv.org/abs/2310.10441</link><description>&lt;p&gt;
&#36890;&#36807;&#24230;&#29305;&#24449;&#39640;&#25928;&#21305;&#37197;&#38543;&#26426;&#19981;&#22343;&#21248;&#22270;
&lt;/p&gt;
&lt;p&gt;
Efficiently matching random inhomogeneous graphs via degree profiles. (arXiv:2310.10441v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10441
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#24230;&#29305;&#24449;&#21305;&#37197;&#31639;&#27861;&#39640;&#25928;&#21305;&#37197;&#38543;&#26426;&#19981;&#22343;&#21248;&#22270;&#30340;&#26041;&#27861;&#65292;&#35201;&#27714;&#26368;&#23567;&#24179;&#22343;&#24230;&#21644;&#26368;&#23567;&#30456;&#20851;&#24615;&#36798;&#21040;&#19968;&#23450;&#38408;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24674;&#22797;&#20004;&#20010;&#30456;&#20851;&#30340;&#38543;&#26426;&#22270;&#20043;&#38388;&#28508;&#22312;&#39030;&#28857;&#23545;&#24212;&#20851;&#31995;&#30340;&#38382;&#39064;&#65292;&#36825;&#20004;&#20010;&#22270;&#20855;&#26377;&#26497;&#19981;&#22343;&#21248;&#19988;&#26410;&#30693;&#30340;&#19981;&#21516;&#39030;&#28857;&#23545;&#20043;&#38388;&#30340;&#36793;&#27010;&#29575;&#12290;&#22312;Ding&#12289;Ma&#12289;Wu&#21644;Xu(2021)&#25552;&#20986;&#30340;&#24230;&#29305;&#24449;&#21305;&#37197;&#31639;&#27861;&#30340;&#22522;&#30784;&#19978;&#65292;&#25105;&#20204;&#25193;&#23637;&#20986;&#20102;&#19968;&#31181;&#39640;&#25928;&#30340;&#21305;&#37197;&#31639;&#27861;&#65292;&#21482;&#35201;&#26368;&#23567;&#24179;&#22343;&#24230;&#33267;&#23569;&#20026;$\Omega(\log^{2} n)$&#65292;&#26368;&#23567;&#30456;&#20851;&#24615;&#33267;&#23569;&#20026;$1 - O(\log^{-2} n)$&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study the problem of recovering the latent vertex correspondence between two correlated random graphs with vastly inhomogeneous and unknown edge probabilities between different pairs of vertices. Inspired by and extending the matching algorithm via degree profiles by Ding, Ma, Wu and Xu (2021), we obtain an efficient matching algorithm as long as the minimal average degree is at least $\Omega(\log^{2} n)$ and the minimal correlation is at least $1 - O(\log^{-2} n)$.
&lt;/p&gt;</description></item><item><title>&#30697;&#38453;&#20989;&#25968;&#31070;&#32463;&#32593;&#32476;&#65288;MFNs&#65289;&#26159;&#19968;&#31181;&#36890;&#36807;&#35299;&#26512;&#30697;&#38453;&#31561;&#21464;&#20989;&#25968;&#26469;&#21442;&#25968;&#21270;&#38750;&#23616;&#37096;&#30456;&#20114;&#20316;&#29992;&#30340;&#26032;&#22411;&#26550;&#26500;&#65292;&#33021;&#22815;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#23454;&#29616;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.10434</link><description>&lt;p&gt;
&#31561;&#21464;&#30697;&#38453;&#20989;&#25968;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Equivariant Matrix Function Neural Networks. (arXiv:2310.10434v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10434
&lt;/p&gt;
&lt;p&gt;
&#30697;&#38453;&#20989;&#25968;&#31070;&#32463;&#32593;&#32476;&#65288;MFNs&#65289;&#26159;&#19968;&#31181;&#36890;&#36807;&#35299;&#26512;&#30697;&#38453;&#31561;&#21464;&#20989;&#25968;&#26469;&#21442;&#25968;&#21270;&#38750;&#23616;&#37096;&#30456;&#20114;&#20316;&#29992;&#30340;&#26032;&#22411;&#26550;&#26500;&#65292;&#33021;&#22815;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#23454;&#29616;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNNs&#65289;&#65292;&#23588;&#20854;&#26159;&#28040;&#24687;&#20256;&#36882;&#31070;&#32463;&#32593;&#32476;&#65288;MPNNs&#65289;&#65292;&#24050;&#32463;&#25104;&#20026;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#23398;&#20064;&#22270;&#24418;&#30340;&#24378;&#22823;&#26550;&#26500;&#12290;&#28982;&#32780;&#65292;&#24403;&#24314;&#27169;&#38750;&#23616;&#37096;&#30456;&#20114;&#20316;&#29992;&#26102;&#65292;MPNNs&#22312;&#22823;&#20849;&#36717;&#20998;&#23376;&#65292;&#37329;&#23646;&#25110;&#38750;&#26230;&#24577;&#26448;&#26009;&#31561;&#31995;&#32479;&#20013;&#38754;&#20020;&#25361;&#25112;&#12290;&#23613;&#31649;&#35889;GNN&#21644;&#20256;&#32479;&#30340;&#31070;&#32463;&#32593;&#32476;&#65288;&#20363;&#22914;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#21644;Transformer&#65289;&#21487;&#20197;&#32531;&#35299;&#36825;&#20123;&#25361;&#25112;&#65292;&#20294;&#23427;&#20204;&#24120;&#24120;&#32570;&#20047;&#25193;&#23637;&#24615;&#65292;&#36866;&#24212;&#24615;&#65292;&#27867;&#21270;&#33021;&#21147;&#65292;&#35745;&#31639;&#25928;&#29575;&#65292;&#25110;&#32773;&#19981;&#33021;&#25429;&#25417;&#25968;&#25454;&#20013;&#30340;&#35814;&#32454;&#32467;&#26500;&#20851;&#31995;&#25110;&#23545;&#31216;&#24615;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#30697;&#38453;&#20989;&#25968;&#31070;&#32463;&#32593;&#32476;&#65288;MFNs&#65289;&#65292;&#19968;&#31181;&#36890;&#36807;&#35299;&#26512;&#30697;&#38453;&#31561;&#21464;&#20989;&#25968;&#26469;&#21442;&#25968;&#21270;&#38750;&#23616;&#37096;&#30456;&#20114;&#20316;&#29992;&#30340;&#26032;&#22411;&#26550;&#26500;&#12290;&#37319;&#29992;&#35299;&#26512;&#30697;&#38453;&#23637;&#24320;&#25552;&#20379;&#20102;&#19968;&#31181;&#30452;&#25509;&#30340;&#23454;&#29616;&#26041;&#27861;&#65292;&#24182;&#20855;&#26377;&#38543;&#31995;&#32479;&#22823;&#23567;&#32447;&#24615;&#25193;&#23637;&#30340;&#28508;&#21147;&#12290;&#35813;MFN&#26550;&#26500;&#22312;&#26631;&#20934;&#20219;&#21153;&#20013;&#23454;&#29616;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph Neural Networks (GNNs), especially message-passing neural networks (MPNNs), have emerged as powerful architectures for learning on graphs in diverse applications. However, MPNNs face challenges when modeling non-local interactions in systems such as large conjugated molecules, metals, or amorphous materials. Although Spectral GNNs and traditional neural networks such as recurrent neural networks and transformers mitigate these challenges, they often lack extensivity, adaptability, generalizability, computational efficiency, or fail to capture detailed structural relationships or symmetries in the data. To address these concerns, we introduce Matrix Function Neural Networks (MFNs), a novel architecture that parameterizes non-local interactions through analytic matrix equivariant functions. Employing resolvent expansions offers a straightforward implementation and the potential for linear scaling with system size. The MFN architecture achieves state-of-the-art performance in standa
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#26500;&#24314;&#21516;&#26102;&#20855;&#22791;&#20844;&#24179;&#24615;&#21644;&#26657;&#20934;&#24615;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#19982;&#32463;&#20856;&#23450;&#20041;&#19981;&#21516;&#30340;&#20844;&#24179;&#24615;&#27010;&#24565;&#65292;&#23637;&#31034;&#20102;&#20808;&#21069;&#30340;&#36127;&#38754;&#32467;&#26524;&#22312;&#36825;&#19968;&#26032;&#23450;&#20041;&#19979;&#19981;&#20877;&#25104;&#31435;&#12290;</title><link>http://arxiv.org/abs/2310.10399</link><description>&lt;p&gt;
&#26397;&#30528;&#20844;&#24179;&#21644;&#26657;&#20934;&#27169;&#22411;&#30340;&#26041;&#21521;
&lt;/p&gt;
&lt;p&gt;
Towards Fair and Calibrated Models. (arXiv:2310.10399v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10399
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#26500;&#24314;&#21516;&#26102;&#20855;&#22791;&#20844;&#24179;&#24615;&#21644;&#26657;&#20934;&#24615;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#19982;&#32463;&#20856;&#23450;&#20041;&#19981;&#21516;&#30340;&#20844;&#24179;&#24615;&#27010;&#24565;&#65292;&#23637;&#31034;&#20102;&#20808;&#21069;&#30340;&#36127;&#38754;&#32467;&#26524;&#22312;&#36825;&#19968;&#26032;&#23450;&#20041;&#19979;&#19981;&#20877;&#25104;&#31435;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#25991;&#29486;&#27880;&#37325;&#20110;&#26500;&#24314;&#20855;&#26377;&#29305;&#23450;&#23646;&#24615;&#30340;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#22914;&#20844;&#24179;&#24615;&#65288;&#21363;&#23545;&#20110;&#32473;&#23450;&#30340;&#19968;&#32452;&#23646;&#24615;&#65292;&#19981;&#20559;&#34962;&#20219;&#20309;&#19968;&#26041;&#65289;&#12289;&#26657;&#20934;&#24615;&#65288;&#21363;&#27169;&#22411;&#20449;&#24515;&#19982;&#39044;&#27979;&#20934;&#30830;&#24615;&#19968;&#33268;&#65289;&#12289;&#21487;&#35299;&#37322;&#24615;&#65288;&#21363;&#33021;&#22815;&#34987;&#20154;&#29702;&#35299;&#30340;&#33021;&#21147;&#65289;&#12290;&#34429;&#28982;&#24050;&#32463;&#26377;&#20851;&#20110;&#27599;&#20010;&#26041;&#38754;&#30340;&#30740;&#31350;&#24037;&#20316;&#65292;&#20294;&#30740;&#31350;&#20154;&#21592;&#36804;&#20170;&#20026;&#27490;&#36824;&#27809;&#26377;&#21516;&#26102;&#35299;&#20915;&#36825;&#20123;&#32500;&#24230;&#20013;&#36229;&#36807;&#19968;&#20010;&#30340;&#38382;&#39064;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#26500;&#24314;&#26082;&#20844;&#24179;&#21448;&#26657;&#20934;&#30340;&#27169;&#22411;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;&#19982;[Biswas et. al. 2019]&#38750;&#24120;&#25509;&#36817;&#30340;&#20844;&#24179;&#24615;&#23450;&#20041;&#65292;&#24182;&#19988;&#22312;&#25105;&#20204;&#30340;&#23450;&#20041;&#19979;&#65292;&#36125;&#21494;&#26031;&#26368;&#20248;&#20998;&#31867;&#22120;&#20855;&#26377;&#26368;&#22823;&#21487;&#33021;&#30340;&#20844;&#24179;&#24615;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;&#29616;&#26377;&#30340;&#20851;&#20110;&#23454;&#29616;&#20844;&#24179;&#21644;&#26657;&#20934;&#27169;&#22411;&#30340;&#36127;&#38754;&#32467;&#26524;[Kleinberg et. al. 2017]&#22312;&#25105;&#20204;&#30340;&#20844;&#24179;&#24615;&#23450;&#20041;&#19979;&#19981;&#25104;&#31435;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#30830;&#20445;&#32676;&#20307;&#26234;&#33021;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent literature has seen a significant focus on building machine learning models with specific properties such as fairness, i.e., being non-biased with respect to a given set of attributes, calibration i.e., model confidence being aligned with its predictive accuracy, and explainability, i.e., ability to be understandable to humans. While there has been work focusing on each of these aspects individually, researchers have shied away from simultaneously addressing more than one of these dimensions. In this work, we address the problem of building models which are both fair and calibrated. We work with a specific definition of fairness, which closely matches [Biswas et. al. 2019], and has the nice property that Bayes optimal classifier has the maximum possible fairness under our definition. We show that an existing negative result towards achieving a fair and calibrated model [Kleinberg et. al. 2017] does not hold for our definition of fairness. Further, we show that ensuring group-wis
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#37325;&#26032;&#23457;&#35270;&#21644;&#37325;&#26032;&#35774;&#35745;&#20102;&#36923;&#36753;-softmax&#20284;&#28982;&#65292;&#36890;&#36807;&#28201;&#24230;&#21442;&#25968;&#25511;&#21046;&#20808;&#39564;&#32622;&#20449;&#27700;&#24179;&#65292;&#20174;&#32780;&#25913;&#21892;&#20102;&#36125;&#21494;&#26031;&#20803;&#23398;&#20064;&#20013;&#30340;&#23569;&#26679;&#26412;&#20998;&#31867;&#38382;&#39064;&#12290;&#21516;&#26102;&#35777;&#26126;softmax&#26159;&#36923;&#36753;-softmax&#30340;&#19968;&#31181;&#29305;&#27530;&#24773;&#20917;&#65292;&#36923;&#36753;-softmax&#33021;&#22815;&#24341;&#23548;&#26356;&#22823;&#30340;&#25968;&#25454;&#20998;&#24067;&#23478;&#26063;&#12290;</title><link>http://arxiv.org/abs/2310.10379</link><description>&lt;p&gt;
&#37325;&#26032;&#23457;&#35270;&#36125;&#21494;&#26031;&#20803;&#23398;&#20064;&#20013;&#36923;&#36753;-softmax&#20284;&#28982;&#29992;&#20110;&#23569;&#26679;&#26412;&#20998;&#31867;
&lt;/p&gt;
&lt;p&gt;
Revisiting Logistic-softmax Likelihood in Bayesian Meta-Learning for Few-Shot Classification. (arXiv:2310.10379v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10379
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37325;&#26032;&#23457;&#35270;&#21644;&#37325;&#26032;&#35774;&#35745;&#20102;&#36923;&#36753;-softmax&#20284;&#28982;&#65292;&#36890;&#36807;&#28201;&#24230;&#21442;&#25968;&#25511;&#21046;&#20808;&#39564;&#32622;&#20449;&#27700;&#24179;&#65292;&#20174;&#32780;&#25913;&#21892;&#20102;&#36125;&#21494;&#26031;&#20803;&#23398;&#20064;&#20013;&#30340;&#23569;&#26679;&#26412;&#20998;&#31867;&#38382;&#39064;&#12290;&#21516;&#26102;&#35777;&#26126;softmax&#26159;&#36923;&#36753;-softmax&#30340;&#19968;&#31181;&#29305;&#27530;&#24773;&#20917;&#65292;&#36923;&#36753;-softmax&#33021;&#22815;&#24341;&#23548;&#26356;&#22823;&#30340;&#25968;&#25454;&#20998;&#24067;&#23478;&#26063;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20803;&#23398;&#20064;&#36890;&#36807;&#23398;&#20064;&#20351;&#29992;&#20808;&#21069;&#30340;&#30693;&#35782;&#35299;&#20915;&#26032;&#38382;&#39064;&#65292;&#22312;&#23569;&#26679;&#26412;&#20998;&#31867;&#20013;&#21462;&#24471;&#20102;&#26377;&#24076;&#26395;&#30340;&#32467;&#26524;&#12290;&#36125;&#21494;&#26031;&#26041;&#27861;&#33021;&#22815;&#26377;&#25928;&#22320;&#34920;&#24449;&#23569;&#26679;&#26412;&#20998;&#31867;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#36825;&#22312;&#39640;&#39118;&#38505;&#39046;&#22495;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#22312;&#22810;&#31867;&#21035;&#39640;&#26031;&#36807;&#31243;&#20998;&#31867;&#20013;&#65292;&#36923;&#36753;-softmax&#20284;&#28982;&#19968;&#30452;&#34987;&#29992;&#20316;softmax&#20284;&#28982;&#30340;&#26367;&#20195;&#26041;&#27861;&#65292;&#22240;&#20026;&#20854;&#20855;&#26377;&#26465;&#20214;&#20849;&#36717;&#24615;&#36136;&#12290;&#28982;&#32780;&#65292;&#36923;&#36753;-softmax&#30340;&#29702;&#35770;&#29305;&#24615;&#19981;&#28165;&#26970;&#65292;&#20197;&#21069;&#30340;&#30740;&#31350;&#34920;&#26126;&#36923;&#36753;-softmax&#30340;&#22266;&#26377;&#19981;&#30830;&#23450;&#24615;&#23548;&#33268;&#20102;&#27425;&#20248;&#30340;&#24615;&#33021;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#37325;&#26032;&#23457;&#35270;&#21644;&#37325;&#26032;&#35774;&#35745;&#20102;&#36923;&#36753;-softmax&#20284;&#28982;&#65292;&#36890;&#36807;&#19968;&#20010;&#28201;&#24230;&#21442;&#25968;&#23454;&#29616;&#23545;&#20808;&#39564;&#32622;&#20449;&#27700;&#24179;&#30340;&#25511;&#21046;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#20174;&#29702;&#35770;&#21644;&#23454;&#36341;&#30340;&#35282;&#24230;&#35777;&#26126;&#20102;softmax&#21487;&#20197;&#34987;&#35270;&#20026;&#36923;&#36753;-softmax&#30340;&#19968;&#31181;&#29305;&#27530;&#24773;&#20917;&#65292;&#24182;&#19988;&#36923;&#36753;-softmax&#24341;&#23548;&#20102;&#27604;softmax&#26356;&#22823;&#30340;&#25968;&#25454;&#20998;&#24067;&#23478;&#26063;&#12290;
&lt;/p&gt;
&lt;p&gt;
Meta-learning has demonstrated promising results in few-shot classification (FSC) by learning to solve new problems using prior knowledge. Bayesian methods are effective at characterizing uncertainty in FSC, which is crucial in high-risk fields. In this context, the logistic-softmax likelihood is often employed as an alternative to the softmax likelihood in multi-class Gaussian process classification due to its conditional conjugacy property. However, the theoretical property of logistic-softmax is not clear and previous research indicated that the inherent uncertainty of logistic-softmax leads to suboptimal performance. To mitigate these issues, we revisit and redesign the logistic-softmax likelihood, which enables control of the \textit{a priori} confidence level through a temperature parameter. Furthermore, we theoretically and empirically show that softmax can be viewed as a special case of logistic-softmax and logistic-softmax induces a larger family of data distribution than soft
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#20960;&#20309;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#65288;GTA&#65289;&#65292;&#29992;&#20110;&#23558;&#20960;&#20309;&#32467;&#26500;&#32534;&#30721;&#20026;&#30456;&#23545;&#21464;&#25442;&#65292;&#20174;&#32780;&#25913;&#36827;&#20102;&#22810;&#35270;&#22270;Transformer&#30340;&#23398;&#20064;&#25928;&#29575;&#21644;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2310.10375</link><description>&lt;p&gt;
GTA&#65306;&#19968;&#31181;&#38754;&#21521;&#20960;&#20309;&#30340;&#22810;&#35270;&#22270;Transformer&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;
&lt;/p&gt;
&lt;p&gt;
GTA: A Geometry-Aware Attention Mechanism for Multi-View Transformers. (arXiv:2310.10375v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10375
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#20960;&#20309;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#65288;GTA&#65289;&#65292;&#29992;&#20110;&#23558;&#20960;&#20309;&#32467;&#26500;&#32534;&#30721;&#20026;&#30456;&#23545;&#21464;&#25442;&#65292;&#20174;&#32780;&#25913;&#36827;&#20102;&#22810;&#35270;&#22270;Transformer&#30340;&#23398;&#20064;&#25928;&#29575;&#21644;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;transformers&#23545;&#36755;&#20837;&#26631;&#35760;&#30340;&#25490;&#21015;&#20855;&#26377;&#31561;&#21464;&#24615;&#65292;&#23545;&#26631;&#35760;&#30340;&#20301;&#32622;&#20449;&#24687;&#36827;&#34892;&#32534;&#30721;&#23545;&#35768;&#22810;&#20219;&#21153;&#26159;&#24517;&#35201;&#30340;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#29616;&#26377;&#30340;&#20301;&#32622;&#32534;&#30721;&#26041;&#26696;&#26368;&#21021;&#26159;&#20026;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#20219;&#21153;&#35774;&#35745;&#30340;&#65292;&#23545;&#20110;&#36890;&#24120;&#22312;&#20854;&#25968;&#25454;&#20013;&#34920;&#29616;&#20986;&#19981;&#21516;&#32467;&#26500;&#29305;&#24615;&#30340;&#35270;&#35273;&#20219;&#21153;&#26469;&#35828;&#65292;&#23427;&#20204;&#30340;&#36866;&#29992;&#24615;&#20540;&#24471;&#24576;&#30097;&#12290;&#25105;&#20204;&#35748;&#20026;&#29616;&#26377;&#30340;&#20301;&#32622;&#32534;&#30721;&#26041;&#26696;&#23545;&#20110;3D&#35270;&#35273;&#20219;&#21153;&#26469;&#35828;&#26159;&#27425;&#20248;&#30340;&#65292;&#22240;&#20026;&#23427;&#20204;&#19981;&#23562;&#37325;&#20854;&#24213;&#23618;&#30340;3D&#20960;&#20309;&#32467;&#26500;&#12290;&#22522;&#20110;&#36825;&#20010;&#20551;&#35774;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38754;&#21521;&#20960;&#20309;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#65292;&#23427;&#23558;&#26631;&#35760;&#30340;&#20960;&#20309;&#32467;&#26500;&#32534;&#30721;&#20026;&#30001;&#26597;&#35810;&#21644;&#38190;&#20540;&#23545;&#20043;&#38388;&#30340;&#20960;&#20309;&#20851;&#31995;&#25152;&#30830;&#23450;&#30340;&#30456;&#23545;&#21464;&#25442;&#12290;&#36890;&#36807;&#22312;&#31232;&#30095;&#23485;&#22522;&#32447;&#22810;&#35270;&#22270;&#35774;&#32622;&#20013;&#35780;&#20272;&#22810;&#20010;&#26032;&#39062;&#35270;&#22270;&#21512;&#25104;&#65288;NVS&#65289;&#25968;&#25454;&#38598;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#27880;&#24847;&#21147;&#26426;&#21046;&#8212;&#8212;&#20960;&#20309;&#21464;&#25442;&#27880;&#24847;&#21147;&#65288;GTA&#65289;&#22914;&#20309;&#25552;&#39640;&#20102;&#26368;&#20808;&#36827;&#30340;Transformer&#30340;&#23398;&#20064;&#25928;&#29575;&#21644;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
As transformers are equivariant to the permutation of input tokens, encoding the positional information of tokens is necessary for many tasks. However, since existing positional encoding schemes have been initially designed for NLP tasks, their suitability for vision tasks, which typically exhibit different structural properties in their data, is questionable. We argue that existing positional encoding schemes are suboptimal for 3D vision tasks, as they do not respect their underlying 3D geometric structure. Based on this hypothesis, we propose a geometry-aware attention mechanism that encodes the geometric structure of tokens as relative transformation determined by the geometric relationship between queries and key-value pairs. By evaluating on multiple novel view synthesis (NVS) datasets in the sparse wide-baseline multi-view setting, we show that our attention, called Geometric Transform Attention (GTA), improves learning efficiency and performance of state-of-the-art transformer-b
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#38543;&#26426;&#36125;&#21494;&#26031;&#33218;&#26426;&#30340;&#38543;&#26102;&#21644;&#26080;&#21442;&#25968;&#37319;&#26679;&#35268;&#21017;APGAI&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#31574;&#30053;&#25552;&#39640;&#20102;&#22909;&#33218;&#35782;&#21035;&#25928;&#29575;&#65292;&#22312;&#22266;&#23450;&#32622;&#20449;&#24230;&#21644;&#22266;&#23450;&#39044;&#31639;&#30340;&#24773;&#20917;&#19979;&#26377;&#33391;&#22909;&#23454;&#39564;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2310.10359</link><description>&lt;p&gt;
&#19968;&#20010;&#36866;&#29992;&#20110;&#22909;&#33218;&#35782;&#21035;&#30340;&#38543;&#26102;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
An Anytime Algorithm for Good Arm Identification. (arXiv:2310.10359v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10359
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#20010;&#36866;&#29992;&#20110;&#38543;&#26426;&#36125;&#21494;&#26031;&#33218;&#26426;&#30340;&#38543;&#26102;&#21644;&#26080;&#21442;&#25968;&#37319;&#26679;&#35268;&#21017;APGAI&#65292;&#36890;&#36807;&#33258;&#36866;&#24212;&#31574;&#30053;&#25552;&#39640;&#20102;&#22909;&#33218;&#35782;&#21035;&#25928;&#29575;&#65292;&#22312;&#22266;&#23450;&#32622;&#20449;&#24230;&#21644;&#22266;&#23450;&#39044;&#31639;&#30340;&#24773;&#20917;&#19979;&#26377;&#33391;&#22909;&#23454;&#39564;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22909;&#33218;&#35782;&#21035;&#65288;GAI&#65289;&#20013;&#65292;&#30446;&#26631;&#26159;&#35782;&#21035;&#20854;&#20013;&#19968;&#20010;&#24179;&#22343;&#24615;&#33021;&#36229;&#36807;&#32473;&#23450;&#38408;&#20540;&#30340;&#33218;&#65292;&#31216;&#20026;&#22909;&#33218;&#65288;&#22914;&#26524;&#23384;&#22312;&#65289;&#12290;&#30446;&#21069;&#24456;&#23569;&#26377;&#30740;&#31350;&#22312;&#22266;&#23450;&#39044;&#31639;&#30340;&#24773;&#20917;&#19979;&#36827;&#34892;GAI&#65292;&#21363;&#22312;&#20808;&#30830;&#23450;&#22909;&#39044;&#31639;&#20043;&#21518;&#65292;&#25110;&#32773;&#22312;&#20219;&#20309;&#26102;&#21051;&#37117;&#21487;&#20197;&#35201;&#27714;&#25512;&#33616;&#30340;&#38543;&#26102;&#35774;&#32622;&#19979;&#36827;&#34892;GAI&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;APGAI&#30340;&#38543;&#26102;&#21644;&#26080;&#21442;&#25968;&#37319;&#26679;&#35268;&#21017;&#65292;&#29992;&#20110;&#38543;&#26426;&#36125;&#21494;&#26031;&#33218;&#26426;&#12290;APGAI&#21487;&#20197;&#30452;&#25509;&#29992;&#20110;&#22266;&#23450;&#32622;&#20449;&#24230;&#21644;&#22266;&#23450;&#39044;&#31639;&#30340;&#35774;&#23450;&#20013;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#24471;&#20986;&#20854;&#20219;&#20309;&#26102;&#21051;&#30340;&#35823;&#24046;&#27010;&#29575;&#30340;&#19978;&#30028;&#12290;&#36825;&#20123;&#19978;&#30028;&#34920;&#26126;&#65292;&#33258;&#36866;&#24212;&#31574;&#30053;&#22312;&#26816;&#27979;&#27809;&#26377;&#22909;&#33218;&#30340;&#26102;&#20505;&#27604;&#22343;&#21248;&#37319;&#26679;&#26356;&#39640;&#25928;&#12290;&#20854;&#27425;&#65292;&#24403;APGAI&#19982;&#19968;&#20010;&#20572;&#27490;&#35268;&#21017;&#32467;&#21512;&#26102;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#20219;&#20309;&#32622;&#20449;&#27700;&#24179;&#19979;&#30340;&#39044;&#26399;&#37319;&#26679;&#22797;&#26434;&#24615;&#30340;&#19978;&#30028;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;APGAI&#22312;&#21512;&#25104;&#25968;&#25454;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#19978;&#30340;&#33391;&#22909;&#23454;&#39564;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#20026;&#25152;&#26377;&#35774;&#32622;&#20013;&#30340;GAI&#38382;&#39064;&#25552;&#20379;&#20102;&#19968;&#20010;&#24191;&#27867;&#30340;&#27010;&#36848;&#12290;
&lt;/p&gt;
&lt;p&gt;
In good arm identification (GAI), the goal is to identify one arm whose average performance exceeds a given threshold, referred to as good arm, if it exists. Few works have studied GAI in the fixed-budget setting, when the sampling budget is fixed beforehand, or the anytime setting, when a recommendation can be asked at any time. We propose APGAI, an anytime and parameter-free sampling rule for GAI in stochastic bandits. APGAI can be straightforwardly used in fixed-confidence and fixed-budget settings. First, we derive upper bounds on its probability of error at any time. They show that adaptive strategies are more efficient in detecting the absence of good arms than uniform sampling. Second, when APGAI is combined with a stopping rule, we prove upper bounds on the expected sampling complexity, holding at any confidence level. Finally, we show good empirical performance of APGAI on synthetic and real-world data. Our work offers an extensive overview of the GAI problem in all settings.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#34276;&#34067;&#21487;&#27712;&#27169;&#22411;&#65292;&#35780;&#20272;&#20102;&#24052;&#20240;&#21033;&#20122;&#22320;&#21306;&#33258;1952&#24180;&#33267;2020&#24180;&#26399;&#38388;&#30340;&#19968;&#20803;&#24178;&#26097;&#21644;&#26202;&#38684;&#30340;&#39118;&#38505;&#65292;&#24182;&#36827;&#34892;&#20102;&#32852;&#21512;&#39118;&#38505;&#20998;&#26512;&#12290;&#30740;&#31350;&#32467;&#26524;&#21457;&#29616;&#20102;&#19968;&#20123;"&#39118;&#38505;&#21306;&#22495;"&#65292;&#24378;&#35843;&#20102;&#27668;&#20505;&#21464;&#21270;&#23545;&#26862;&#26519;&#36866;&#24212;&#30340;&#24517;&#35201;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.10324</link><description>&lt;p&gt;
&#20351;&#29992;&#34276;&#34067;&#21487;&#27712;&#27169;&#22411;&#35780;&#20272;&#24917;&#23612;&#40657;&#30340;&#26202;&#38684;&#21644;&#24178;&#26097;&#30340;&#19968;&#20803;&#21644;&#20108;&#20803;&#39118;&#38505;&#65306;&#19968;&#39033;&#21382;&#21490;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Assessing univariate and bivariate risks of late-frost and drought using vine copulas: A historical study for Bavaria. (arXiv:2310.10324v1 [stat.AP])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10324
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;&#20351;&#29992;&#34276;&#34067;&#21487;&#27712;&#27169;&#22411;&#65292;&#35780;&#20272;&#20102;&#24052;&#20240;&#21033;&#20122;&#22320;&#21306;&#33258;1952&#24180;&#33267;2020&#24180;&#26399;&#38388;&#30340;&#19968;&#20803;&#24178;&#26097;&#21644;&#26202;&#38684;&#30340;&#39118;&#38505;&#65292;&#24182;&#36827;&#34892;&#20102;&#32852;&#21512;&#39118;&#38505;&#20998;&#26512;&#12290;&#30740;&#31350;&#32467;&#26524;&#21457;&#29616;&#20102;&#19968;&#20123;"&#39118;&#38505;&#21306;&#22495;"&#65292;&#24378;&#35843;&#20102;&#27668;&#20505;&#21464;&#21270;&#23545;&#26862;&#26519;&#36866;&#24212;&#30340;&#24517;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37492;&#20110;&#27668;&#20505;&#21464;&#21270;&#23545;&#26862;&#26519;&#30340;&#24433;&#21709;&#65292;&#21253;&#25324;&#26497;&#31471;&#24178;&#26097;&#21644;&#26202;&#38684;&#65292;&#23548;&#33268;&#26893;&#34987;&#20943;&#36864;&#21644;&#23616;&#37096;&#26862;&#26519;&#34928;&#36864;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#24052;&#20240;&#21033;&#20122;&#20174;1952&#24180;&#21040;2020&#24180;&#30340;&#19968;&#20803;&#24178;&#26097;&#21644;&#26202;&#38684;&#39118;&#38505;&#65292;&#24182;&#36827;&#34892;&#20102;&#32852;&#21512;&#39118;&#38505;&#20998;&#26512;&#12290;&#21033;&#29992;&#21253;&#21547;26&#20010;&#29983;&#29289;&#27668;&#20505;&#21644;&#22320;&#24418;&#21464;&#37327;&#30340;&#24222;&#22823;&#25968;&#25454;&#38598;&#65292;&#30001;&#20110;&#25968;&#25454;&#30340;&#38750;&#39640;&#26031;&#21644;&#19981;&#23545;&#31216;&#24615;&#20381;&#36182;&#24615;&#65292;&#25105;&#20204;&#37319;&#29992;&#34276;&#34067;&#21487;&#27712;&#27169;&#22411;&#12290;&#25105;&#20204;&#20351;&#29992;D-vine&#22238;&#24402;&#36827;&#34892;&#19968;&#20803;&#20998;&#26512;&#65292;&#20351;&#29992;Y-vine&#22238;&#24402;&#36827;&#34892;&#20108;&#20803;&#20998;&#26512;&#65292;&#24182;&#25552;&#20986;&#30456;&#24212;&#30340;&#19968;&#20803;&#21644;&#20108;&#20803;&#26465;&#20214;&#27010;&#29575;&#39118;&#38505;&#24230;&#37327;&#12290;&#25105;&#20204;&#30830;&#23450;&#20102;"&#39118;&#38505;&#21306;&#22495;"&#65292;&#24378;&#35843;&#20102;&#30001;&#20110;&#27668;&#20505;&#21464;&#21270;&#32780;&#38656;&#35201;&#26862;&#26519;&#36866;&#24212;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In light of climate change's impacts on forests, including extreme drought and late-frost, leading to vitality decline and regional forest die-back, we assess univariate drought and late-frost risks and perform a joint risk analysis in Bavaria, Germany, from 1952 to 2020. Utilizing a vast dataset with 26 bioclimatic and topographic variables, we employ vine copula models due to the data's non-Gaussian and asymmetric dependencies. We use D-vine regression for univariate and Y-vine regression for bivariate analysis, and propose corresponding univariate and bivariate conditional probability risk measures. We identify "at-risk" regions, emphasizing the need for forest adaptation due to climate change.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25913;&#36827;&#30340;YOLOv5&#30340;&#21475;&#32617;&#20329;&#25140;&#29289;&#20307;&#26816;&#27979;&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#24341;&#20837;&#22810;&#22836;&#27880;&#24847;&#21147;&#33258;&#21367;&#31215;&#21644;Swin Transformer Block&#26469;&#25552;&#39640;&#27169;&#22411;&#30340;&#26816;&#27979;&#31934;&#24230;&#21644;&#36866;&#24212;&#33021;&#21147;&#65292;&#26368;&#32456;&#22312;MASK&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;1.1%&#30340;mAP(0.5)&#25552;&#21319;&#21644;1.3%&#30340;&#25913;&#21892;&#12290;</title><link>http://arxiv.org/abs/2310.10245</link><description>&lt;p&gt;
&#22522;&#20110;&#25913;&#36827;&#30340;YOLOv5&#30340;&#21475;&#32617;&#20329;&#25140;&#29289;&#20307;&#26816;&#27979;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Mask wearing object detection algorithm based on improved YOLOv5. (arXiv:2310.10245v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10245
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25913;&#36827;&#30340;YOLOv5&#30340;&#21475;&#32617;&#20329;&#25140;&#29289;&#20307;&#26816;&#27979;&#31639;&#27861;&#12290;&#35813;&#31639;&#27861;&#36890;&#36807;&#24341;&#20837;&#22810;&#22836;&#27880;&#24847;&#21147;&#33258;&#21367;&#31215;&#21644;Swin Transformer Block&#26469;&#25552;&#39640;&#27169;&#22411;&#30340;&#26816;&#27979;&#31934;&#24230;&#21644;&#36866;&#24212;&#33021;&#21147;&#65292;&#26368;&#32456;&#22312;MASK&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;1.1%&#30340;mAP(0.5)&#25552;&#21319;&#21644;1.3%&#30340;&#25913;&#21892;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25140;&#21475;&#32617;&#26159;&#39044;&#38450;&#20256;&#26579;&#30149;&#30340;&#37325;&#35201;&#25514;&#26045;&#20043;&#19968;&#65292;&#28982;&#32780;&#22312;&#20154;&#27969;&#37327;&#36739;&#22823;&#30340;&#20844;&#20849;&#22330;&#25152;&#24456;&#38590;&#26816;&#27979;&#21040;&#20154;&#20204;&#20329;&#25140;&#21475;&#32617;&#30340;&#24773;&#20917;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;YOLOv5l&#30340;&#21475;&#32617;&#20329;&#25140;&#20154;&#33080;&#26816;&#27979;&#27169;&#22411;&#12290;&#39318;&#20808;&#65292;&#24341;&#20837;&#20102;&#22810;&#22836;&#27880;&#24847;&#21147;&#33258;&#21367;&#31215;&#65292;&#19981;&#20165;&#25552;&#39640;&#20102;&#27169;&#22411;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#36824;&#22686;&#24378;&#20102;&#27169;&#22411;&#30340;&#26816;&#27979;&#31934;&#24230;&#12290;&#20854;&#27425;&#65292;&#24341;&#20837;&#20102;Swin Transformer Block&#65292;&#33021;&#22815;&#25552;&#21462;&#26356;&#22810;&#26377;&#29992;&#30340;&#29305;&#24449;&#20449;&#24687;&#65292;&#22686;&#24378;&#23545;&#23567;&#30446;&#26631;&#30340;&#26816;&#27979;&#33021;&#21147;&#65292;&#25552;&#39640;&#27169;&#22411;&#30340;&#25972;&#20307;&#31934;&#24230;&#12290;&#25105;&#20204;&#35774;&#35745;&#30340;I-CBAM&#27169;&#22359;&#21487;&#20197;&#25552;&#39640;&#30446;&#26631;&#26816;&#27979;&#30340;&#20934;&#30830;&#24615;&#12290;&#27492;&#22806;&#65292;&#37319;&#29992;&#22686;&#24378;&#30340;&#29305;&#24449;&#34701;&#21512;&#20351;&#24471;&#27169;&#22411;&#33021;&#22815;&#26356;&#22909;&#22320;&#36866;&#24212;&#19981;&#21516;&#23610;&#24230;&#30340;&#30446;&#26631;&#26816;&#27979;&#20219;&#21153;&#12290;&#22312;MASK&#25968;&#25454;&#38598;&#19978;&#30340;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#26412;&#25991;&#25552;&#20986;&#30340;&#27169;&#22411;&#22312;mAP(0.5)&#19978;&#21462;&#24471;&#20102;1.1%&#30340;&#25552;&#21319;&#21644;1.3%&#30340;&#25913;&#21892;&#12290;
&lt;/p&gt;
&lt;p&gt;
Wearing a mask is one of the important measures to prevent infectious diseases. However, it is difficult to detect people's mask-wearing situation in public places with high traffic flow. To address the above problem, this paper proposes a mask-wearing face detection model based on YOLOv5l. Firstly, Multi-Head Attentional Self-Convolution not only improves the convergence speed of the model but also enhances the accuracy of the model detection. Secondly, the introduction of Swin Transformer Block is able to extract more useful feature information, enhance the detection ability of small targets, and improve the overall accuracy of the model. Our designed I-CBAM module can improve target detection accuracy. In addition, using enhanced feature fusion enables the model to better adapt to object detection tasks of different scales. In the experimentation on the MASK dataset, the results show that the model proposed in this paper achieved a 1.1% improvement in mAP(0.5) and a 1.3% improvement
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#28857;&#38388;&#20114;&#20449;&#24687;&#30340;&#29305;&#24449;&#65292;&#24341;&#20837;&#20102;&#32454;&#20998;&#24067;&#23478;&#26063;&#26469;&#35299;&#20915;&#29616;&#26377;&#20114;&#20449;&#24687;&#20272;&#35745;&#22120;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#25506;&#31350;&#20102;&#31070;&#32463;&#25209;&#35780;&#23478;&#22312;&#21464;&#20998;&#20272;&#35745;&#22120;&#20013;&#30340;&#34892;&#20026;&#65292;&#20197;&#21450;&#23454;&#39564;&#24322;&#24120;&#20540;&#23545;&#20114;&#20449;&#24687;&#20272;&#35745;&#30340;&#24433;&#21709;&#12290;&#27492;&#22806;&#65292;&#36824;&#20171;&#32461;&#20102;&#22522;&#20110;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#19988;&#38656;&#35201;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.10240</link><description>&lt;p&gt;
&#28151;&#21512;&#29289;&#19982;&#31070;&#32463;&#25209;&#35780;&#23478;&#65306;&#20851;&#20110;&#31934;&#32454;&#20998;&#24067;&#30340;&#28857;&#38388;&#20114;&#20449;&#24687;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
The Mixtures and the Neural Critics: On the Pointwise Mutual Information Profiles of Fine Distributions. (arXiv:2310.10240v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10240
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#28857;&#38388;&#20114;&#20449;&#24687;&#30340;&#29305;&#24449;&#65292;&#24341;&#20837;&#20102;&#32454;&#20998;&#24067;&#23478;&#26063;&#26469;&#35299;&#20915;&#29616;&#26377;&#20114;&#20449;&#24687;&#20272;&#35745;&#22120;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#25506;&#31350;&#20102;&#31070;&#32463;&#25209;&#35780;&#23478;&#22312;&#21464;&#20998;&#20272;&#35745;&#22120;&#20013;&#30340;&#34892;&#20026;&#65292;&#20197;&#21450;&#23454;&#39564;&#24322;&#24120;&#20540;&#23545;&#20114;&#20449;&#24687;&#20272;&#35745;&#30340;&#24433;&#21709;&#12290;&#27492;&#22806;&#65292;&#36824;&#20171;&#32461;&#20102;&#22522;&#20110;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#19988;&#38656;&#35201;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20114;&#20449;&#24687;&#37327;&#21270;&#20102;&#20004;&#20010;&#38543;&#26426;&#21464;&#37327;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#24182;&#19988;&#22312;&#24494;&#20998;&#21516;&#32986;&#19979;&#20445;&#25345;&#19981;&#21464;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25506;&#35752;&#20102;&#28857;&#38388;&#20114;&#20449;&#24687;&#30340;&#29305;&#24449;&#65292;&#36825;&#26159;&#20114;&#20449;&#24687;&#30340;&#25512;&#24191;&#24418;&#24335;&#65292;&#20445;&#25345;&#20102;&#36825;&#31181;&#19981;&#21464;&#24615;&#12290;&#25105;&#20204;&#22312;&#35299;&#26512;&#19978;&#25551;&#36848;&#20102;&#22810;&#20803;&#27491;&#24577;&#20998;&#24067;&#30340;&#29305;&#24449;&#65292;&#24182;&#24341;&#20837;&#20102;&#32454;&#20998;&#24067;&#23478;&#26063;&#65292;&#36890;&#36807;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#21487;&#20197;&#20934;&#30830;&#22320;&#36924;&#36817;&#36825;&#31181;&#29305;&#24449;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#32454;&#20998;&#24067;&#26469;&#30740;&#31350;&#29616;&#26377;&#20114;&#20449;&#24687;&#20272;&#35745;&#22120;&#30340;&#23616;&#38480;&#24615;&#65292;&#35843;&#26597;&#22312;&#21464;&#20998;&#20272;&#35745;&#22120;&#20013;&#20351;&#29992;&#30340;&#31070;&#32463;&#25209;&#35780;&#23478;&#30340;&#34892;&#20026;&#65292;&#24182;&#20102;&#35299;&#23454;&#39564;&#24322;&#24120;&#20540;&#23545;&#20114;&#20449;&#24687;&#20272;&#35745;&#30340;&#24433;&#21709;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#21033;&#29992;&#32454;&#20998;&#24067;&#26469;&#33719;&#24471;&#22522;&#20110;&#27169;&#22411;&#30340;&#36125;&#21494;&#26031;&#20272;&#35745;&#30340;&#20114;&#20449;&#24687;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;&#21487;&#29992;&#39046;&#22495;&#19987;&#19994;&#30693;&#35782;&#19988;&#38656;&#35201;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Mutual information quantifies the dependence between two random variables and remains invariant under diffeomorphisms. In this paper, we explore the pointwise mutual information profile, an extension of mutual information that maintains this invariance. We analytically describe the profiles of multivariate normal distributions and introduce the family of fine distributions, for which the profile can be accurately approximated using Monte Carlo methods. We then show how fine distributions can be used to study the limitations of existing mutual information estimators, investigate the behavior of neural critics used in variational estimators, and understand the effect of experimental outliers on mutual information estimation. Finally, we show how fine distributions can be used to obtain model-based Bayesian estimates of mutual information, suitable for problems with available domain expertise in which uncertainty quantification is necessary.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#38750;&#39640;&#26031;&#26377;&#21521;&#26080;&#29615;&#22270;&#30340;&#32467;&#26500;&#36801;&#31227;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#26032;&#39062;&#30340;DAG&#32467;&#26500;&#30456;&#20284;&#24230;&#24230;&#37327;&#24182;&#21033;&#29992;&#19981;&#21516;&#30456;&#20284;&#24615;&#27700;&#24179;&#30340;&#36741;&#21161;DAG&#30340;&#20449;&#24687;&#65292;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#30446;&#26631;&#30740;&#31350;&#20013;&#30340;DAG&#37325;&#26500;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2310.10239</link><description>&lt;p&gt;
&#38750;&#39640;&#26031;&#26377;&#21521;&#26080;&#29615;&#22270;&#30340;&#32467;&#26500;&#36801;&#31227;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Structural transfer learning of non-Gaussian DAG. (arXiv:2310.10239v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10239
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#38750;&#39640;&#26031;&#26377;&#21521;&#26080;&#29615;&#22270;&#30340;&#32467;&#26500;&#36801;&#31227;&#23398;&#20064;&#26041;&#27861;&#65292;&#36890;&#36807;&#24341;&#20837;&#26032;&#39062;&#30340;DAG&#32467;&#26500;&#30456;&#20284;&#24230;&#24230;&#37327;&#24182;&#21033;&#29992;&#19981;&#21516;&#30456;&#20284;&#24615;&#27700;&#24179;&#30340;&#36741;&#21161;DAG&#30340;&#20449;&#24687;&#65292;&#33021;&#22815;&#26174;&#33879;&#25552;&#39640;&#30446;&#26631;&#30740;&#31350;&#20013;&#30340;DAG&#37325;&#26500;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26377;&#21521;&#26080;&#29615;&#22270;(DAG)&#34987;&#24191;&#27867;&#29992;&#20110;&#34920;&#31034;&#19968;&#32452;&#25910;&#38598;&#21040;&#30340;&#33410;&#28857;&#20043;&#38388;&#30340;&#26041;&#21521;&#20851;&#31995;&#12290;&#28982;&#32780;&#65292;&#19968;&#27425;&#21333;&#29420;&#30740;&#31350;&#20013;&#21487;&#29992;&#30340;&#25968;&#25454;&#24448;&#24448;&#26377;&#38480;&#65292;&#19981;&#36275;&#20197;&#20934;&#30830;&#22320;&#37325;&#26500;DAG&#65292;&#32780;&#24322;&#26500;&#25968;&#25454;&#21487;&#33021;&#20250;&#20174;&#22810;&#20010;&#30456;&#20851;&#30740;&#31350;&#20013;&#25910;&#38598;&#21040;&#12290;&#22914;&#20309;&#23558;&#24322;&#26500;&#25968;&#25454;&#27719;&#38598;&#21040;&#30446;&#26631;&#30740;&#31350;&#20013;&#20197;&#26356;&#22909;&#22320;&#37325;&#26500;DAG&#32467;&#26500;&#20173;&#28982;&#26159;&#19968;&#20010;&#26410;&#35299;&#20915;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#24341;&#20837;&#20102;&#19968;&#22871;&#26032;&#39062;&#30340;DAG&#32467;&#26500;&#30456;&#20284;&#24230;&#24230;&#37327;&#65292;&#28982;&#21518;&#25552;&#20986;&#20102;&#19968;&#20010;&#20256;&#36755;DAG&#23398;&#20064;&#26694;&#26550;&#65292;&#36890;&#36807;&#26377;&#25928;&#22320;&#21033;&#29992;&#19981;&#21516;&#30456;&#20284;&#24615;&#27700;&#24179;&#30340;&#36741;&#21161;DAG&#30340;&#20449;&#24687;&#26469;&#25552;&#39640;&#30446;&#26631;&#30740;&#31350;&#20013;&#30340;DAG&#37325;&#26500;&#25928;&#26524;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#34920;&#26126;&#65292;&#22312;&#30446;&#26631;DAG&#27809;&#26377;&#25972;&#20307;&#19982;&#36741;&#21161;DAG&#30456;&#20284;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20063;&#33021;&#22312;DAG&#37325;&#26500;&#26041;&#38754;&#23454;&#29616;&#26174;&#33879;&#30340;&#25913;&#36827;&#65292;&#36825;&#19982;&#22823;&#22810;&#25968;&#29616;&#26377;&#30340;&#20256;&#36755;&#23398;&#20064;&#26041;&#27861;&#24418;&#25104;&#40092;&#26126;&#23545;&#27604;&#12290;&#25105;&#20204;&#30340;&#23454;&#39564;&#32467;&#26524;&#20063;&#25903;&#25345;&#20102;&#25152;&#25552;&#20986;&#30340;&#20256;&#36755;DAG&#23398;&#20064;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;
Directed acyclic graph (DAG) has been widely employed to represent directional relationships among a set of collected nodes. Yet, the available data in one single study is often limited for accurate DAG reconstruction, whereas heterogeneous data may be collected from multiple relevant studies. It remains an open question how to pool the heterogeneous data together for better DAG structure reconstruction in the target study. In this paper, we first introduce a novel set of structural similarity measures for DAG and then present a transfer DAG learning framework by effectively leveraging information from auxiliary DAGs of different levels of similarities. Our theoretical analysis shows substantial improvement in terms of DAG reconstruction in the target study, even when no auxiliary DAG is overall similar to the target DAG, which is in sharp contrast to most existing transfer learning methods. The advantage of the proposed transfer DAG learning is also supported by extensive numerical ex
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#21518;&#39564;&#20013;&#30340;&#32622;&#25442;&#23545;&#31216;&#24615;&#65292;&#25581;&#31034;&#20102;&#22312;&#26799;&#24230;&#19979;&#38477;&#30340;&#23616;&#37096;&#35299;&#20043;&#38388;&#22522;&#26412;&#19978;&#19981;&#23384;&#22312;&#25439;&#22833;&#38459;&#30861;&#12290;&#36890;&#36807;&#20351;&#29992;&#32622;&#25442;&#30697;&#38453;&#23545;&#40784;&#20004;&#20010;&#36125;&#21494;&#26031;&#35299;&#20915;&#26041;&#26696;&#30340;&#20998;&#24067;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#23547;&#25214;&#32447;&#24615;&#30456;&#36830;&#35299;&#30340;&#21305;&#37197;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.10171</link><description>&lt;p&gt;
&#20851;&#20110;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#21518;&#39564;&#20013;&#32622;&#25442;&#23545;&#31216;&#24615;&#30340;&#30740;&#31350;: &#19968;&#20010;&#21464;&#20998;&#35282;&#24230;
&lt;/p&gt;
&lt;p&gt;
On permutation symmetries in Bayesian neural network posteriors: a variational perspective. (arXiv:2310.10171v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10171
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#21518;&#39564;&#20013;&#30340;&#32622;&#25442;&#23545;&#31216;&#24615;&#65292;&#25581;&#31034;&#20102;&#22312;&#26799;&#24230;&#19979;&#38477;&#30340;&#23616;&#37096;&#35299;&#20043;&#38388;&#22522;&#26412;&#19978;&#19981;&#23384;&#22312;&#25439;&#22833;&#38459;&#30861;&#12290;&#36890;&#36807;&#20351;&#29992;&#32622;&#25442;&#30697;&#38453;&#23545;&#40784;&#20004;&#20010;&#36125;&#21494;&#26031;&#35299;&#20915;&#26041;&#26696;&#30340;&#20998;&#24067;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#23547;&#25214;&#32447;&#24615;&#30456;&#36830;&#35299;&#30340;&#21305;&#37197;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#20013;&#22522;&#20110;&#26799;&#24230;&#30340;&#20248;&#21270;&#30340;&#38590;&#20197;&#25417;&#25720;&#30340;&#24615;&#36136;&#19982;&#20854;&#25439;&#22833;&#20989;&#25968;&#30340;&#20960;&#20309;&#24418;&#24577;&#26377;&#20851;&#65292;&#32780;&#36825;&#20010;&#20960;&#20309;&#24418;&#24577;&#30446;&#21069;&#36824;&#19981;&#22826;&#34987;&#29702;&#35299;&#12290;&#28982;&#32780;&#65292;&#26368;&#36817;&#30340;&#30740;&#31350;&#24050;&#32463;&#25552;&#20379;&#20102;&#22362;&#23454;&#30340;&#35777;&#25454;&#65292;&#35777;&#26126;&#22312;&#26799;&#24230;&#19979;&#38477;&#30340;&#23616;&#37096;&#35299;&#20043;&#38388;&#22522;&#26412;&#19978;&#19981;&#23384;&#22312;&#25439;&#22833;&#38459;&#30861;&#65292;&#21482;&#35201;&#32771;&#34385;&#21040;&#20445;&#25345;&#32593;&#32476;&#35745;&#31639;&#19981;&#21464;&#30340;&#26435;&#37325;&#32622;&#25442;&#12290;&#36825;&#24341;&#21457;&#20102;&#23545;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#65288;BNNs&#65289;&#20013;&#36817;&#20284;&#25512;&#26029;&#30340;&#38382;&#39064;&#65292;&#25105;&#20204;&#20851;&#24515;&#30340;&#26159;&#22312;&#25439;&#22833;&#20989;&#25968;&#31354;&#38388;&#20013;&#23545;&#22810;&#20010;&#28857;&#36827;&#34892;&#36793;&#32536;&#21270;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#39318;&#20808;&#23558;&#36793;&#32536;&#21270;&#30340;&#25439;&#22833;&#38459;&#30861;&#21644;&#35299;&#25554;&#20540;&#30340;&#24418;&#24335;&#20027;&#20041;&#25193;&#23637;&#21040;BNNs&#20013;&#65292;&#28982;&#21518;&#25552;&#20986;&#20102;&#19968;&#31181;&#21305;&#37197;&#31639;&#27861;&#26469;&#23547;&#25214;&#32447;&#24615;&#30456;&#36830;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;&#36825;&#26159;&#36890;&#36807;&#23558;&#20004;&#20010;&#29420;&#31435;&#30340;&#36817;&#20284;&#36125;&#21494;&#26031;&#35299;&#20915;&#26041;&#26696;&#30340;&#20998;&#24067;&#19982;&#32622;&#25442;&#30697;&#38453;&#23545;&#40784;&#26469;&#23454;&#29616;&#30340;&#12290;&#25105;&#20204;&#22522;&#20110;Ainsworth&#31561;&#20154;&#65288;2023&#65289;&#30340;&#32467;&#26524;&#65292;&#23558;&#38382;&#39064;&#37325;&#26032;&#26694;&#26550;&#20026;&#19968;&#20010;&#32452;&#21512;&#20248;&#21270;&#38382;&#39064;&#65292;&#24182;&#20351;&#29992;&#19968;&#31181;&#36817;&#20284;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The elusive nature of gradient-based optimization in neural networks is tied to their loss landscape geometry, which is poorly understood. However recent work has brought solid evidence that there is essentially no loss barrier between the local solutions of gradient descent, once accounting for weight-permutations that leave the network's computation unchanged. This raises questions for approximate inference in Bayesian neural networks (BNNs), where we are interested in marginalizing over multiple points in the loss landscape. In this work, we first extend the formalism of marginalized loss barrier and solution interpolation to BNNs, before proposing a matching algorithm to search for linearly connected solutions. This is achieved by aligning the distributions of two independent approximate Bayesian solutions with respect to permutation matrices. We build on the results of Ainsworth et al. (2023), reframing the problem as a combinatorial optimization one, using an approximation to the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26641;&#32467;&#26500;&#19978;&#21033;&#29992;Wasserstein&#36317;&#31163;&#36827;&#34892;&#31616;&#21270;&#34920;&#31034;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;SimCLR&#21644;&#36127;TWD&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#26469;&#20272;&#35745;&#31616;&#21270;&#34920;&#31034;&#65292;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#25214;&#21040;&#20102;&#31283;&#23450;&#30340;&#35757;&#32451;&#31574;&#30053;&#12290;</title><link>http://arxiv.org/abs/2310.10143</link><description>&lt;p&gt;
&#29992;Wasserstein&#36317;&#31163;&#36827;&#34892;&#31616;&#21270;&#34920;&#31034;&#23398;&#20064;&#30340;&#23454;&#35777;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
An Empirical Study of Simplicial Representation Learning with Wasserstein Distance. (arXiv:2310.10143v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10143
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#26641;&#32467;&#26500;&#19978;&#21033;&#29992;Wasserstein&#36317;&#31163;&#36827;&#34892;&#31616;&#21270;&#34920;&#31034;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;SimCLR&#21644;&#36127;TWD&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#26469;&#20272;&#35745;&#31616;&#21270;&#34920;&#31034;&#65292;&#36890;&#36807;&#23454;&#35777;&#30740;&#31350;&#25214;&#21040;&#20102;&#31283;&#23450;&#30340;&#35757;&#32451;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#22312;&#26641;&#32467;&#26500;&#19978;&#21033;&#29992;1-Wasserstein&#36317;&#31163;&#36827;&#34892;&#31616;&#21270;&#34920;&#31034;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#26641;- Wasserstein&#36317;&#31163;(TWD)&#23450;&#20041;&#20026;&#20004;&#20010;&#26641;&#23884;&#20837;&#21521;&#37327;&#20043;&#38388;&#30340;L1&#36317;&#31163;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#31181;&#22522;&#20110;SimCLR&#21644;&#36127;TWD&#20316;&#20026;&#30456;&#20284;&#24230;&#24230;&#37327;&#30340;&#33258;&#30417;&#30563;&#23398;&#20064;&#26041;&#27861;&#26469;&#20272;&#35745;&#31616;&#21270;&#34920;&#31034;&#12290;&#22312;SimCLR&#20013;&#65292;&#36890;&#24120;&#20351;&#29992;&#19982;&#23454;&#21521;&#37327;&#23884;&#20837;&#30340;&#20313;&#24358;&#30456;&#20284;&#24230;&#65292;&#20294;&#26159;&#23578;&#26410;&#23545;&#21033;&#29992;L1&#36317;&#31163;&#19982;&#31616;&#21270;&#23884;&#20837;&#36827;&#34892;&#28145;&#20837;&#30740;&#31350;&#12290;&#19968;&#20010;&#20851;&#38190;&#25361;&#25112;&#26159;&#35757;&#32451;L1&#36317;&#31163;&#22312;&#25968;&#20540;&#19978;&#20855;&#26377;&#25361;&#25112;&#24615;&#65292;&#24182;&#19988;&#24448;&#24448;&#20250;&#20135;&#29983;&#19981;&#20196;&#20154;&#28385;&#24847;&#30340;&#32467;&#26524;&#65292;&#27010;&#29575;&#27169;&#22411;&#30340;&#36873;&#25321;&#20063;&#26377;&#24456;&#22810;&#12290;&#22240;&#27492;&#65292;&#26412;&#30740;&#31350;&#20174;&#23454;&#35777;&#35282;&#24230;&#25506;&#31350;&#20102;&#29992;TWD&#20248;&#21270;&#33258;&#30417;&#30563;&#23398;&#20064;&#30340;&#31574;&#30053;&#65292;&#24182;&#25214;&#21040;&#20102;&#31283;&#23450;&#30340;&#35757;&#32451;&#36807;&#31243;&#12290;&#26356;&#20855;&#20307;&#22320;&#35828;&#65292;&#25105;&#20204;&#35780;&#20272;&#20102;&#20004;&#31181;&#31867;&#22411;TWD&#30340;&#32452;&#21512;&#65288;&#24635; ...
&lt;/p&gt;
&lt;p&gt;
In this paper, we delve into the problem of simplicial representation learning utilizing the 1-Wasserstein distance on a tree structure (a.k.a., Tree-Wasserstein distance (TWD)), where TWD is defined as the L1 distance between two tree-embedded vectors. Specifically, we consider a framework for simplicial representation estimation employing a self-supervised learning approach based on SimCLR with a negative TWD as a similarity measure. In SimCLR, the cosine similarity with real-vector embeddings is often utilized; however, it has not been well studied utilizing L1-based measures with simplicial embeddings. A key challenge is that training the L1 distance is numerically challenging and often yields unsatisfactory outcomes, and there are numerous choices for probability models. Thus, this study empirically investigates a strategy for optimizing self-supervised learning with TWD and find a stable training procedure. More specifically, we evaluate the combination of two types of TWD (total
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#39640;&#25928;&#30340;&#24320;&#28304;SMPC&#20179;&#24211;&#65292;&#35299;&#20915;&#20102;&#22312;&#36164;&#28304;&#26377;&#38480;&#30340;&#26426;&#22120;&#19978;&#23454;&#29616;SMPC&#21327;&#35758;&#30340;&#23454;&#38469;&#21644;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#20248;&#21270;&#20869;&#23384;&#20351;&#29992;&#12289;&#20943;&#23569;&#25191;&#34892;&#26102;&#38388;&#21644;&#25552;&#39640;&#25928;&#29575;&#30340;&#26041;&#27861;&#65292;&#22312;&#20445;&#25252;&#25968;&#25454;&#38544;&#31169;&#30340;&#21516;&#26102;&#23436;&#25104;&#20102;MNIST&#25968;&#25454;&#38598;&#25512;&#26029;&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2310.10133</link><description>&lt;p&gt;
&#25552;&#21319;SMPC: &#22312;&#31070;&#32463;&#32593;&#32476;&#25512;&#26029;&#20013;&#36328;&#36234;&#21487;&#25193;&#23637;&#24615;&#12289;&#20869;&#23384;&#25928;&#29575;&#21644;&#38544;&#31169;&#20043;&#38388;&#30340;&#24046;&#36317;
&lt;/p&gt;
&lt;p&gt;
Empowering SMPC: Bridging the Gap Between Scalability, Memory Efficiency and Privacy in Neural Network Inference. (arXiv:2310.10133v1 [cs.CR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10133
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#39640;&#25928;&#30340;&#24320;&#28304;SMPC&#20179;&#24211;&#65292;&#35299;&#20915;&#20102;&#22312;&#36164;&#28304;&#26377;&#38480;&#30340;&#26426;&#22120;&#19978;&#23454;&#29616;SMPC&#21327;&#35758;&#30340;&#23454;&#38469;&#21644;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#65292;&#24182;&#36890;&#36807;&#20248;&#21270;&#20869;&#23384;&#20351;&#29992;&#12289;&#20943;&#23569;&#25191;&#34892;&#26102;&#38388;&#21644;&#25552;&#39640;&#25928;&#29575;&#30340;&#26041;&#27861;&#65292;&#22312;&#20445;&#25252;&#25968;&#25454;&#38544;&#31169;&#30340;&#21516;&#26102;&#23436;&#25104;&#20102;MNIST&#25968;&#25454;&#38598;&#25512;&#26029;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#26088;&#22312;&#24320;&#21457;&#19968;&#20010;&#39640;&#25928;&#30340;&#24320;&#28304;Secure Multi-Party Computation&#65288;SMPC&#65289;&#20179;&#24211;&#65292;&#35299;&#20915;&#20102;&#22312;&#20013;&#31561;&#35745;&#31639;&#36164;&#28304;&#30340;&#26426;&#22120;&#19978;&#23454;&#29616;SMPC&#21327;&#35758;&#30340;&#23454;&#38469;&#21644;&#21487;&#25193;&#23637;&#24615;&#38382;&#39064;&#65292;&#24182;&#26088;&#22312;&#20943;&#23569;&#25191;&#34892;&#26102;&#38388;&#12290;&#25105;&#20204;&#23454;&#29616;&#20102;ABY2.0&#21327;&#35758;&#65292;&#20026;&#24320;&#21457;&#20154;&#21592;&#25552;&#20379;&#20102;&#22312;ABY 2.0&#21327;&#35758;&#19978;&#26500;&#24314;&#24212;&#29992;&#31243;&#24207;&#30340;&#26377;&#25928;&#24037;&#20855;&#12290;&#25991;&#31456;&#35299;&#20915;&#20102;&#22522;&#20110;C++&#30340;MOTION2NX&#26694;&#26550;&#30340;&#38480;&#21046;&#65292;&#21253;&#25324;&#20869;&#23384;&#38480;&#21046;&#21644;&#25805;&#20316;&#20860;&#23481;&#24615;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#25913;&#36827;&#21253;&#25324;&#20248;&#21270;&#20869;&#23384;&#20351;&#29992;&#12289;&#21033;&#29992;&#31532;&#19977;&#26041;Helper&#33410;&#28857;&#20943;&#23569;&#25191;&#34892;&#26102;&#38388;&#65292;&#24182;&#22312;&#20445;&#25252;&#25968;&#25454;&#38544;&#31169;&#30340;&#21516;&#26102;&#25552;&#39640;&#25928;&#29575;&#12290;&#36825;&#20123;&#20248;&#21270;&#20351;&#24471;MNIST&#25968;&#25454;&#38598;&#30340;&#25512;&#26029;&#21482;&#38656;32&#31186;&#65292;&#20165;&#38656;0.2GB&#30340;RAM&#29992;&#20110;5&#23618;&#31070;&#32463;&#32593;&#32476;&#12290;&#30456;&#27604;&#20043;&#19979;&#65292;&#20043;&#21069;&#30340;&#22522;&#20934;&#23454;&#29616;&#38656;&#35201;8.03GB&#30340;RAM&#21644;200&#31186;&#30340;&#25191;&#34892;&#26102;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper aims to develop an efficient open-source Secure Multi-Party Computation (SMPC) repository, that addresses the issue of practical and scalable implementation of SMPC protocol on machines with moderate computational resources, while aiming to reduce the execution time. We implement the ABY2.0 protocol for SMPC, providing developers with effective tools for building applications on the ABY 2.0 protocol. This article addresses the limitations of the C++ based MOTION2NX framework for secure neural network inference, including memory constraints and operation compatibility issues. Our enhancements include optimizing the memory usage, reducing execution time using a third-party Helper node, and enhancing efficiency while still preserving data privacy. These optimizations enable MNIST dataset inference in just 32 seconds with only 0.2 GB of RAM for a 5-layer neural network. In contrast, the previous baseline implementation required 8.03 GB of RAM and 200 seconds of execution time.
&lt;/p&gt;</description></item><item><title>&#26412;&#32508;&#36848;&#31995;&#32479;&#20840;&#38754;&#22320;&#22238;&#39038;&#20102;&#21033;&#29992;&#36830;&#32493;&#21160;&#21147;&#23398;&#26694;&#26550;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#20197;&#24110;&#21161;&#20174;&#26681;&#26412;&#19978;&#29702;&#35299;&#21644;&#25913;&#36827;GNN&#30340;&#33021;&#21147;&#21644;&#32570;&#38519;&#12290;</title><link>http://arxiv.org/abs/2310.10121</link><description>&lt;p&gt;
&#20174;&#36830;&#32493;&#21160;&#21147;&#23398;&#21040;&#22270;&#31070;&#32463;&#32593;&#32476;&#65306;&#31070;&#32463;&#25193;&#25955;&#19982;&#26356;&#22810;
&lt;/p&gt;
&lt;p&gt;
From Continuous Dynamics to Graph Neural Networks: Neural Diffusion and Beyond. (arXiv:2310.10121v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10121
&lt;/p&gt;
&lt;p&gt;
&#26412;&#32508;&#36848;&#31995;&#32479;&#20840;&#38754;&#22320;&#22238;&#39038;&#20102;&#21033;&#29992;&#36830;&#32493;&#21160;&#21147;&#23398;&#26694;&#26550;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;&#65292;&#20197;&#24110;&#21161;&#20174;&#26681;&#26412;&#19978;&#29702;&#35299;&#21644;&#25913;&#36827;GNN&#30340;&#33021;&#21147;&#21644;&#32570;&#38519;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;GNN&#65289;&#22312;&#24314;&#27169;&#20851;&#31995;&#25968;&#25454;&#26041;&#38754;&#34920;&#29616;&#20986;&#26174;&#33879;&#30340;&#28508;&#21147;&#65292;&#24182;&#22312;&#21508;&#20010;&#39046;&#22495;&#24471;&#21040;&#24191;&#27867;&#24212;&#29992;&#12290;GNN&#32972;&#21518;&#30340;&#20851;&#38190;&#26426;&#21046;&#26159;&#25152;&#35859;&#30340;&#28040;&#24687;&#20256;&#36882;&#65292;&#23427;&#36890;&#36807;&#20174;&#37051;&#23621;&#33410;&#28857;&#20013;&#38598;&#20013;&#22320;&#32858;&#21512;&#20449;&#24687;&#26469;&#36827;&#34892;&#36845;&#20195;&#12290;&#36825;&#31181;&#26041;&#26696;&#19982;&#31216;&#20026;&#28909;&#20256;&#23548;&#30340;&#29289;&#29702;&#36807;&#31243;&#23494;&#20999;&#30456;&#20851;&#65292;&#20854;&#20013;GNN&#30340;&#20256;&#25773;&#33258;&#28982;&#23545;&#24212;&#20110;&#28909;&#23494;&#24230;&#30340;&#28436;&#21270;&#12290;&#23558;&#28040;&#24687;&#20256;&#36882;&#36807;&#31243;&#31867;&#27604;&#20026;&#28909;&#21160;&#21147;&#23398;&#21487;&#20197;&#20174;&#26681;&#26412;&#19978;&#29702;&#35299;GNN&#30340;&#33021;&#21147;&#21644;&#32570;&#38519;&#65292;&#20174;&#32780;&#26377;&#21161;&#20110;&#26356;&#22909;&#22320;&#35774;&#35745;&#27169;&#22411;&#12290;&#26368;&#36817;&#20986;&#29616;&#20102;&#22823;&#37327;&#26088;&#22312;&#20943;&#36731;GNN&#24050;&#30693;&#38480;&#21046;&#65288;&#22914;&#36807;&#24230;&#24179;&#28369;&#21644;&#36807;&#24230;&#21387;&#32553;&#65289;&#30340;GNN&#25552;&#20986;&#20316;&#21697;&#65292;&#36825;&#20123;&#20316;&#21697;&#21463;&#21040;&#36830;&#32493;&#21160;&#21147;&#23398;&#30340;&#21551;&#21457;&#12290;&#22312;&#26412;&#32508;&#36848;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#31995;&#32479;&#20840;&#38754;&#22320;&#22238;&#39038;&#20102;&#21033;&#29992;&#36830;&#32493;&#21160;&#21147;&#23398;&#26694;&#26550;&#30340;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph neural networks (GNNs) have demonstrated significant promise in modelling relational data and have been widely applied in various fields of interest. The key mechanism behind GNNs is the so-called message passing where information is being iteratively aggregated to central nodes from their neighbourhood. Such a scheme has been found to be intrinsically linked to a physical process known as heat diffusion, where the propagation of GNNs naturally corresponds to the evolution of heat density. Analogizing the process of message passing to the heat dynamics allows to fundamentally understand the power and pitfalls of GNNs and consequently informs better model design. Recently, there emerges a plethora of works that proposes GNNs inspired from the continuous dynamics formulation, in an attempt to mitigate the known limitations of GNNs, such as oversmoothing and oversquashing. In this survey, we provide the first systematic and comprehensive review of studies that leverage the continuou
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20998;&#26512;&#20102;&#21518;&#39564;&#37319;&#26679;&#23398;&#20064;&#31639;&#27861;&#22312;&#24207;&#21015;&#21270;POMDPs&#20013;&#30340;&#36951;&#25022;&#24615;&#33021;&#65292;&#24182;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#25552;&#20379;&#20102;&#25913;&#36827;&#30340;&#22810;&#39033;&#24335;&#36125;&#21494;&#26031;&#36951;&#25022;&#30028;&#12290;</title><link>http://arxiv.org/abs/2310.10107</link><description>&lt;p&gt;
&#21518;&#39564;&#37319;&#26679;&#23398;&#20064;&#31639;&#27861;&#22312;&#24207;&#21015;&#21270;POMDPs&#20013;&#30340;&#36951;&#25022;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Regret Analysis of the Posterior Sampling-based Learning Algorithm for Episodic POMDPs. (arXiv:2310.10107v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10107
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20998;&#26512;&#20102;&#21518;&#39564;&#37319;&#26679;&#23398;&#20064;&#31639;&#27861;&#22312;&#24207;&#21015;&#21270;POMDPs&#20013;&#30340;&#36951;&#25022;&#24615;&#33021;&#65292;&#24182;&#22312;&#19968;&#23450;&#26465;&#20214;&#19979;&#25552;&#20379;&#20102;&#25913;&#36827;&#30340;&#22810;&#39033;&#24335;&#36125;&#21494;&#26031;&#36951;&#25022;&#30028;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30456;&#27604;&#20110;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDPs&#65289;&#65292;&#37096;&#20998;&#21487;&#35266;&#23519;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;POMDPs&#65289;&#30340;&#23398;&#20064;&#30001;&#20110;&#35266;&#23519;&#25968;&#25454;&#38590;&#20197;&#35299;&#35835;&#32780;&#21464;&#24471;&#26356;&#21152;&#22256;&#38590;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#20855;&#26377;&#26410;&#30693;&#36716;&#31227;&#21644;&#35266;&#27979;&#27169;&#22411;&#30340;POMDPs&#20013;&#30340;&#24207;&#21015;&#21270;&#23398;&#20064;&#38382;&#39064;&#12290;&#25105;&#20204;&#32771;&#34385;&#20102;&#22522;&#20110;&#21518;&#39564;&#37319;&#26679;&#30340;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65288;PSRL&#65289;&#22312;POMDPs&#20013;&#30340;&#24212;&#29992;&#65292;&#24182;&#35777;&#26126;&#20854;&#36125;&#21494;&#26031;&#36951;&#25022;&#38543;&#30528;&#24207;&#21015;&#30340;&#25968;&#37327;&#30340;&#24179;&#26041;&#26681;&#32780;&#32553;&#23567;&#12290;&#19968;&#33324;&#26469;&#35828;&#65292;&#36951;&#25022;&#38543;&#30528;&#26102;&#38388;&#38271;&#24230;$H$&#21576;&#25351;&#25968;&#32423;&#22686;&#38271;&#65292;&#24182;&#36890;&#36807;&#25552;&#20379;&#19968;&#20010;&#19979;&#30028;&#35777;&#26126;&#20102;&#36825;&#19968;&#28857;&#12290;&#28982;&#32780;&#65292;&#22312;POMDP&#26159;&#27424;&#23436;&#22791;&#19988;&#24369;&#21487;&#35782;&#21035;&#30340;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#22810;&#39033;&#24335;&#36125;&#21494;&#26031;&#36951;&#25022;&#30028;&#65292;&#30456;&#27604;&#20110;arXiv:2204.08967&#30340;&#26368;&#26032;&#32467;&#26524;&#65292;&#25913;&#36827;&#20102;&#36951;&#25022;&#30028;&#32422;$\Omega(H^2\sqrt{SA})$&#20493;&#12290;
&lt;/p&gt;
&lt;p&gt;
Compared to Markov Decision Processes (MDPs), learning in Partially Observable Markov Decision Processes (POMDPs) can be significantly harder due to the difficulty of interpreting observations. In this paper, we consider episodic learning problems in POMDPs with unknown transition and observation models. We consider the Posterior Sampling-based Reinforcement Learning (PSRL) algorithm for POMDPs and show that its Bayesian regret scales as the square root of the number of episodes. In general, the regret scales exponentially with the horizon length $H$, and we show that this is inevitable by providing a lower bound. However, under the condition that the POMDP is undercomplete and weakly revealing, we establish a polynomial Bayesian regret bound that improves the regret bound by a factor of $\Omega(H^2\sqrt{SA})$ over the recent result by arXiv:2204.08967.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25506;&#35752;&#20102;&#20174;&#26631;&#31614;&#27604;&#20363;&#20013;&#23398;&#20064;&#32447;&#24615;&#38408;&#20540;&#20989;&#25968;&#30340;&#35745;&#31639;&#21487;&#23398;&#20064;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;LTFs&#26377;&#25928;&#23398;&#20064;LTFs&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.10098</link><description>&lt;p&gt;
&#20174;&#26631;&#31614;&#27604;&#20363;&#20013;&#23398;&#20064;&#32447;&#24615;&#38408;&#20540;&#65288;&#26631;&#39064;&#32763;&#35793;&#65289;
&lt;/p&gt;
&lt;p&gt;
PAC Learning Linear Thresholds from Label Proportions. (arXiv:2310.10098v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10098
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#20174;&#26631;&#31614;&#27604;&#20363;&#20013;&#23398;&#20064;&#32447;&#24615;&#38408;&#20540;&#20989;&#25968;&#30340;&#35745;&#31639;&#21487;&#23398;&#20064;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#20351;&#29992;LTFs&#26377;&#25928;&#23398;&#20064;LTFs&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#31614;&#27604;&#20363;&#23398;&#20064;&#65288;LLP&#65289;&#26159;&#19968;&#31181;&#30417;&#30563;&#23398;&#20064;&#30340;&#27867;&#21270;&#24418;&#24335;&#65292;&#20854;&#20013;&#35757;&#32451;&#25968;&#25454;&#20197;&#29305;&#24449;&#21521;&#37327;&#65288;&#23454;&#20363;&#65289;&#30340;&#38598;&#21512;&#25110;&#21253;&#30340;&#24418;&#24335;&#32473;&#20986;&#65292;&#21516;&#26102;&#36824;&#25552;&#20379;&#20102;&#27599;&#20010;&#21253;&#30340;&#24179;&#22343;&#23454;&#20363;&#26631;&#31614;&#12290;&#20854;&#30446;&#26631;&#26159;&#35757;&#32451;&#19968;&#20010;&#33391;&#22909;&#30340;&#23454;&#20363;&#20998;&#31867;&#22120;&#12290;&#23613;&#31649;&#20043;&#21069;&#30340;LLP&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#35813;&#35757;&#32451;&#25968;&#25454;&#19978;&#35757;&#32451;&#27169;&#22411;&#65292;&#20294;&#26368;&#36817;&#30340;&#24037;&#20316;[Saket'21, Saket'22]&#25506;&#32034;&#20102;LLP&#30340;&#35745;&#31639;&#21487;&#23398;&#20064;&#24615;&#65292;&#23637;&#31034;&#20102;&#20174;&#26631;&#31614;&#27604;&#20363;&#20013;&#20934;&#30830;&#23398;&#20064;&#32447;&#24615;&#38408;&#20540;&#20989;&#25968;&#65288;LTFs&#65289;&#30340;&#26368;&#22351;&#24773;&#20917;&#22797;&#26434;&#24615;&#12290;&#28982;&#32780;&#65292;&#20182;&#20204;&#30340;&#24037;&#20316;&#27809;&#26377;&#25490;&#38500;&#22312;&#33258;&#28982;&#20998;&#24067;&#19979;&#35813;&#38382;&#39064;&#30340;&#39640;&#25928;&#31639;&#27861;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#36807;&#20351;&#29992;LTFs&#20174;&#26576;&#20010;&#26631;&#31614;&#27604;&#20363;&#30340;&#38543;&#26426;&#21253;&#33719;&#21462;&#30340;&#26465;&#20214;&#19979;&#26631;&#31614;&#29420;&#31435;&#22320;&#20174;&#39640;&#26031;&#20998;&#24067;$N(\mathbf{\mu}, \mathbf{\Sigma})$&#20013;&#37319;&#26679;&#30340;&#29305;&#24449;&#21521;&#37327;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#23398;&#20064;LTFs&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#34920;&#26126;&#65292;&#36890;&#36807;&#26576;&#31181;&#30697;&#38453;&#30340;&#24418;&#24335;-
&lt;/p&gt;
&lt;p&gt;
Learning from label proportions (LLP) is a generalization of supervised learning in which the training data is available as sets or bags of feature-vectors (instances) along with the average instance-label of each bag. The goal is to train a good instance classifier. While most previous works on LLP have focused on training models on such training data, computational learnability of LLP was only recently explored by [Saket'21, Saket'22] who showed worst case intractability of properly learning linear threshold functions (LTFs) from label proportions. However, their work did not rule out efficient algorithms for this problem on natural distributions.  In this work we show that it is indeed possible to efficiently learn LTFs using LTFs when given access to random bags of some label proportion in which feature-vectors are, conditioned on their labels, independently sampled from a Gaussian distribution $N(\mathbf{\mu}, \mathbf{\Sigma})$. Our work shows that a certain matrix -- formed using
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22823;&#35268;&#27169;&#34920;&#26684;LLP&#22522;&#20934;&#65292;&#22635;&#34917;&#20102;&#34920;&#26684;LLP&#39046;&#22495;&#30340;&#30740;&#31350;&#31354;&#30333;&#12290;&#22312;&#35813;&#22522;&#20934;&#20013;&#65292;&#25105;&#20204;&#21487;&#20197;&#21019;&#24314;&#29305;&#24449;bags&#65292;&#20854;&#20013;&#25152;&#26377;&#23454;&#20363;&#20855;&#26377;&#30456;&#21516;&#30340;&#29305;&#24449;&#20540;&#65292;&#20174;&#32780;&#26356;&#22909;&#22320;&#27169;&#25311;&#23454;&#38469;&#24212;&#29992;&#22330;&#26223;&#12290;</title><link>http://arxiv.org/abs/2310.10096</link><description>&lt;p&gt;
LLP-Bench&#65306;&#19968;&#31181;&#29992;&#20110;&#20174;&#26631;&#31614;&#27604;&#20363;&#20013;&#23398;&#20064;&#30340;&#22823;&#35268;&#27169;&#34920;&#26684;&#22522;&#20934;
&lt;/p&gt;
&lt;p&gt;
LLP-Bench: A Large Scale Tabular Benchmark for Learning from Label Proportions. (arXiv:2310.10096v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10096
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22823;&#35268;&#27169;&#34920;&#26684;LLP&#22522;&#20934;&#65292;&#22635;&#34917;&#20102;&#34920;&#26684;LLP&#39046;&#22495;&#30340;&#30740;&#31350;&#31354;&#30333;&#12290;&#22312;&#35813;&#22522;&#20934;&#20013;&#65292;&#25105;&#20204;&#21487;&#20197;&#21019;&#24314;&#29305;&#24449;bags&#65292;&#20854;&#20013;&#25152;&#26377;&#23454;&#20363;&#20855;&#26377;&#30456;&#21516;&#30340;&#29305;&#24449;&#20540;&#65292;&#20174;&#32780;&#26356;&#22909;&#22320;&#27169;&#25311;&#23454;&#38469;&#24212;&#29992;&#22330;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23398;&#20064;&#20174;&#26631;&#31614;&#27604;&#20363;&#20013;&#23398;&#20064;&#65288;LLP&#65289;&#20219;&#21153;&#20013;&#65292;&#27169;&#22411;&#36890;&#36807;&#23545;&#23454;&#20363;&#32452;&#65288;&#31216;&#20026;bags&#65289;&#21644;&#30456;&#24212;&#30340;&#26631;&#31614;&#27604;&#20363;&#36827;&#34892;&#35757;&#32451;&#65292;&#20197;&#39044;&#27979;&#20010;&#20307;&#23454;&#20363;&#30340;&#26631;&#31614;&#12290;LLP&#20027;&#35201;&#24212;&#29992;&#20110;&#22270;&#20687;&#21644;&#34920;&#26684;&#20004;&#31181;&#25968;&#25454;&#38598;&#12290;&#22312;&#22270;&#20687;LLP&#20013;&#65292;&#36890;&#36807;&#20174;&#24213;&#23618;&#25968;&#25454;&#38598;&#20013;&#38543;&#26426;&#25277;&#26679;&#23454;&#20363;&#26469;&#21019;&#24314;&#22266;&#23450;&#22823;&#23567;&#30340;bags&#12290;&#36890;&#36807;&#36825;&#31181;&#26041;&#27861;&#21019;&#24314;&#30340;bags&#31216;&#20026;&#38543;&#26426;bags&#12290;&#23545;&#22270;&#20687;LLP&#30340;&#23454;&#39564;&#20027;&#35201;&#38598;&#20013;&#22312;CIFAR-*&#21644;MNIST&#25968;&#25454;&#38598;&#30340;&#38543;&#26426;bags&#19978;&#12290;&#23613;&#31649;&#34920;&#26684;LLP&#22312;&#38544;&#31169;&#25935;&#24863;&#24212;&#29992;&#20013;&#38750;&#24120;&#37325;&#35201;&#65292;&#20294;&#23578;&#32570;&#20047;&#19968;&#20010;&#24320;&#25918;&#30340;&#12289;&#22823;&#35268;&#27169;&#30340;&#34920;&#26684;LLP&#22522;&#20934;&#12290;&#34920;&#26684;LLP&#30340;&#19968;&#20010;&#29420;&#29305;&#29305;&#24615;&#26159;&#33021;&#22815;&#21019;&#24314;&#29305;&#24449;bags&#65292;&#20854;&#20013;bag&#20013;&#30340;&#25152;&#26377;&#23454;&#20363;&#23545;&#20110;&#32473;&#23450;&#30340;&#29305;&#24449;&#20855;&#26377;&#30456;&#21516;&#30340;&#20540;&#12290;&#20808;&#21069;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#29305;&#24449;bags&#22312;&#23454;&#38469;&#30340;&#29616;&#23454;&#24212;&#29992;&#20013;&#38750;&#24120;&#24120;&#35265;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35299;&#20915;&#20102;&#34920;&#26684;LLP&#30340;&#30740;&#31350;&#31354;&#30333;&#65292;&#25552;&#20986;&#20102;&#19968;&#20010;&#29992;&#20110;&#22823;&#35268;&#27169;&#34920;&#26684;LLP&#30340;&#22522;&#20934;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the task of Learning from Label Proportions (LLP), a model is trained on groups (a.k.a bags) of instances and their corresponding label proportions to predict labels for individual instances. LLP has been applied pre-dominantly on two types of datasets - image and tabular. In image LLP, bags of fixed size are created by randomly sampling instances from an underlying dataset. Bags created via this methodology are called random bags. Experimentation on Image LLP has been mostly on random bags on CIFAR-* and MNIST datasets. Despite being a very crucial task in privacy sensitive applications, tabular LLP does not yet have a open, large scale LLP benchmark. One of the unique properties of tabular LLP is the ability to create feature bags where all the instances in a bag have the same value for a given feature. It has been shown in prior research that feature bags are very common in practical, real world applications [Chen et. al '23, Saket et. al. '22].  In this paper, we address the lac
&lt;/p&gt;</description></item><item><title>&#20197;&#21069;&#30740;&#31350;&#34920;&#26126;&#26420;&#32032;&#30340;LBA&#21644;LLP&#19981;&#33021;&#25552;&#20379;&#26631;&#31614;&#24046;&#20998;&#38544;&#31169;&#12290;&#20294;&#26412;&#30740;&#31350;&#26174;&#31034;&#65292;&#20351;&#29992;&#20855;&#26377;&#38543;&#26426;&#25277;&#26679;&#30340;&#21152;&#26435;LBA&#21487;&#20197;&#25552;&#20379;&#26631;&#31614;&#24046;&#20998;&#38544;&#31169;&#12290;</title><link>http://arxiv.org/abs/2310.10092</link><description>&lt;p&gt;
&#36890;&#36807;&#32858;&#21512;&#23454;&#29616;&#26631;&#31614;&#24046;&#20998;&#38544;&#31169;
&lt;/p&gt;
&lt;p&gt;
Label Differential Privacy via Aggregation. (arXiv:2310.10092v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10092
&lt;/p&gt;
&lt;p&gt;
&#20197;&#21069;&#30740;&#31350;&#34920;&#26126;&#26420;&#32032;&#30340;LBA&#21644;LLP&#19981;&#33021;&#25552;&#20379;&#26631;&#31614;&#24046;&#20998;&#38544;&#31169;&#12290;&#20294;&#26412;&#30740;&#31350;&#26174;&#31034;&#65292;&#20351;&#29992;&#20855;&#26377;&#38543;&#26426;&#25277;&#26679;&#30340;&#21152;&#26435;LBA&#21487;&#20197;&#25552;&#20379;&#26631;&#31614;&#24046;&#20998;&#38544;&#31169;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#29616;&#23454;&#24212;&#29992;&#20013;&#65292;&#29305;&#21035;&#26159;&#30001;&#20110;&#38544;&#31169;&#39046;&#22495;&#30340;&#26368;&#26032;&#21457;&#23637;&#65292;&#35757;&#32451;&#25968;&#25454;&#21487;&#20197;&#36827;&#34892;&#32858;&#21512;&#65292;&#20197;&#20445;&#25252;&#25935;&#24863;&#35757;&#32451;&#26631;&#31614;&#30340;&#38544;&#31169;&#12290;&#22312;&#26631;&#31614;&#27604;&#20363;&#23398;&#20064;(LLP)&#26694;&#26550;&#20013;&#65292;&#25968;&#25454;&#38598;&#34987;&#21010;&#20998;&#20026;&#29305;&#24449;&#21521;&#37327;&#30340;&#21253;&#65292;&#21482;&#33021;&#33719;&#24471;&#27599;&#20010;&#21253;&#20013;&#26631;&#31614;&#30340;&#24635;&#21644;&#12290;&#36827;&#19968;&#27493;&#38480;&#21046;&#30340;&#38480;&#21046;&#23398;&#20064;(LBA)&#26159;&#21482;&#33021;&#33719;&#24471;&#21253;&#30340;&#29305;&#24449;&#21521;&#37327;&#30340;&#24635;&#21644;&#65288;&#21487;&#33021;&#26159;&#21152;&#26435;&#30340;&#65289;&#12290;&#25105;&#20204;&#30740;&#31350;&#36825;&#31181;&#32858;&#21512;&#25216;&#26415;&#26159;&#21542;&#33021;&#22815;&#22312;&#26631;&#31614;&#24046;&#20998;&#38544;&#31169;(label-DP)&#30340;&#27010;&#24565;&#19979;&#25552;&#20379;&#38544;&#31169;&#20445;&#35777;&#65292;&#35813;&#27010;&#24565;&#20043;&#21069;&#22312;[Chaudhuri-Hsu'11, Ghazi et al.'21, Esfandiari et al.'22]&#20013;&#36827;&#34892;&#20102;&#30740;&#31350;&#12290;&#24456;&#23481;&#26131;&#30475;&#20986;&#65292;&#26420;&#32032;&#30340;LBA&#21644;LLP&#19981;&#33021;&#25552;&#20379;&#26631;&#31614;&#24046;&#20998;&#38544;&#31169;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#30340;&#20027;&#35201;&#32467;&#26524;&#34920;&#26126;&#65292;&#20351;&#29992;&#20855;&#26377;$m$&#20010;&#38543;&#26426;&#25277;&#26679;&#30340;&#19981;&#30456;&#20132;$k$-&#22823;&#23567;&#21253;&#30340;&#21152;&#26435;LBA&#23454;&#38469;&#19978;&#26159;$(\varepsilon,
&lt;/p&gt;
&lt;p&gt;
In many real-world applications, in particular due to recent developments in the privacy landscape, training data may be aggregated to preserve the privacy of sensitive training labels. In the learning from label proportions (LLP) framework, the dataset is partitioned into bags of feature-vectors which are available only with the sum of the labels per bag. A further restriction, which we call learning from bag aggregates (LBA) is where instead of individual feature-vectors, only the (possibly weighted) sum of the feature-vectors per bag is available. We study whether such aggregation techniques can provide privacy guarantees under the notion of label differential privacy (label-DP) previously studied in for e.g. [Chaudhuri-Hsu'11, Ghazi et al.'21, Esfandiari et al.'22].  It is easily seen that naive LBA and LLP do not provide label-DP. Our main result however, shows that weighted LBA using iid Gaussian weights with $m$ randomly sampled disjoint $k$-sized bags is in fact $(\varepsilon, 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#40654;&#26364;&#27531;&#24046;&#31070;&#32463;&#32593;&#32476;&#30340;&#25193;&#23637;&#65292;&#23558;&#20854;&#24212;&#29992;&#20110;&#36890;&#29992;&#40654;&#26364;&#27969;&#24418;&#65292;&#25552;&#20379;&#20102;&#35299;&#20915;&#28040;&#22833;&#26799;&#24230;&#38382;&#39064;&#30340;&#20960;&#20309;&#21407;&#29702;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#20248;&#24322;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2310.10013</link><description>&lt;p&gt;
&#40654;&#26364;&#27531;&#24046;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Riemannian Residual Neural Networks. (arXiv:2310.10013v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10013
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#40654;&#26364;&#27531;&#24046;&#31070;&#32463;&#32593;&#32476;&#30340;&#25193;&#23637;&#65292;&#23558;&#20854;&#24212;&#29992;&#20110;&#36890;&#29992;&#40654;&#26364;&#27969;&#24418;&#65292;&#25552;&#20379;&#20102;&#35299;&#20915;&#28040;&#22833;&#26799;&#24230;&#38382;&#39064;&#30340;&#20960;&#20309;&#21407;&#29702;&#26041;&#27861;&#65292;&#24182;&#23637;&#31034;&#20102;&#20854;&#22312;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#20248;&#24322;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#22312;&#20960;&#20309;&#28145;&#24230;&#23398;&#20064;&#20013;&#65292;&#24341;&#20837;&#20102;&#21508;&#31181;&#31070;&#32463;&#32593;&#32476;&#26469;&#22788;&#29702;&#22788;&#20110;&#40654;&#26364;&#27969;&#24418;&#19978;&#30340;&#25968;&#25454;&#12290;&#36825;&#26679;&#30340;&#32593;&#32476;&#36890;&#24120;&#29992;&#20110;&#22312;&#20855;&#26377;&#20998;&#23618;&#32467;&#26500;&#30340;&#22270;&#24418;&#19978;&#23398;&#20064;&#65292;&#25110;&#32773;&#29992;&#20110;&#22312;&#33258;&#28982;&#31185;&#23398;&#20013;&#36935;&#21040;&#30340;&#27969;&#24418;&#20540;&#25968;&#25454;&#19978;&#23398;&#20064;&#12290;&#36825;&#20123;&#32593;&#32476;&#24120;&#24120;&#21463;&#21040;&#26631;&#20934;&#27431;&#20960;&#37324;&#24471;&#31070;&#32463;&#32593;&#32476;&#30340;&#21551;&#21457;&#65292;&#24182;&#30452;&#25509;&#25512;&#24191;&#12290;&#28982;&#32780;&#65292;&#25193;&#23637;&#27431;&#20960;&#37324;&#24471;&#32593;&#32476;&#26159;&#22256;&#38590;&#30340;&#65292;&#24182;&#19988;&#21482;&#36866;&#29992;&#20110;&#23569;&#25968;&#20960;&#20010;&#27969;&#24418;&#12290;&#22312;&#36825;&#39033;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#27531;&#24046;&#31070;&#32463;&#32593;&#32476;&#65288;ResNet&#65289;&#24182;&#23637;&#31034;&#20102;&#22914;&#20309;&#20197;&#20960;&#20309;&#21407;&#29702;&#30340;&#26041;&#24335;&#23558;&#20854;&#25193;&#23637;&#21040;&#36890;&#29992;&#40654;&#26364;&#27969;&#24418;&#19978;&#12290;ResNet&#26368;&#21021;&#34987;&#24341;&#20837;&#26469;&#24110;&#21161;&#35299;&#20915;&#28040;&#22833;&#26799;&#24230;&#38382;&#39064;&#65292;&#30001;&#20110;&#20854;&#33391;&#22909;&#30340;&#23398;&#20064;&#24615;&#36136;&#12289;&#20248;&#24322;&#30340;&#23454;&#39564;&#32467;&#26524;&#21644;&#26131;&#20110;&#26500;&#24314;&#19981;&#21516;&#31070;&#32463;&#32593;&#32476;&#30340;&#29305;&#28857;&#65292;&#36825;&#31181;&#32593;&#32476;&#24050;&#32463;&#24191;&#27867;&#24212;&#29992;&#20110;&#26426;&#22120;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent methods in geometric deep learning have introduced various neural networks to operate over data that lie on Riemannian manifolds. Such networks are often necessary to learn well over graphs with a hierarchical structure or to learn over manifold-valued data encountered in the natural sciences. These networks are often inspired by and directly generalize standard Euclidean neural networks. However, extending Euclidean networks is difficult and has only been done for a select few manifolds. In this work, we examine the residual neural network (ResNet) and show how to extend this construction to general Riemannian manifolds in a geometrically principled manner. Originally introduced to help solve the vanishing gradient problem, ResNets have become ubiquitous in machine learning due to their beneficial learning properties, excellent empirical results, and easy-to-incorporate nature when building varied neural networks. We find that our Riemannian ResNets mirror these desirable prope
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#36719;&#21270;&#30340;&#36880;&#28857;&#26426;&#21046;&#65288;SoftAD&#65289;&#26469;&#23454;&#29616;&#27491;&#21017;&#21270;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#40065;&#26834;&#24615;&#65292;&#21487;&#20197;&#20943;&#23569;&#36229;&#21442;&#25968;&#30340;&#24433;&#21709;&#65292;&#24182;&#20445;&#30041;&#19978;&#21319;-&#19979;&#38477;&#25928;&#24212;&#12290;</title><link>http://arxiv.org/abs/2310.10006</link><description>&lt;p&gt;
&#36890;&#36807;&#36719;&#19978;&#21319;-&#19979;&#38477;&#23454;&#29616;&#38544;&#24335;&#27491;&#21017;&#21270;
&lt;/p&gt;
&lt;p&gt;
Implicit regularization via soft ascent-descent. (arXiv:2310.10006v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10006
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#36719;&#21270;&#30340;&#36880;&#28857;&#26426;&#21046;&#65288;SoftAD&#65289;&#26469;&#23454;&#29616;&#27491;&#21017;&#21270;&#30340;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#40065;&#26834;&#24615;&#65292;&#21487;&#20197;&#20943;&#23569;&#36229;&#21442;&#25968;&#30340;&#24433;&#21709;&#65292;&#24182;&#20445;&#30041;&#19978;&#21319;-&#19979;&#38477;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#27169;&#22411;&#21464;&#24471;&#36234;&#26469;&#36234;&#22823;&#21644;&#22797;&#26434;&#65292;&#36890;&#36807;&#26368;&#23567;&#30340;&#35797;&#38169;&#26469;&#23454;&#29616;&#26356;&#22909;&#30340;&#31163;&#32447;&#27867;&#21270;&#23545;&#26426;&#22120;&#23398;&#20064;&#24037;&#20316;&#27969;&#31243;&#30340;&#21487;&#38752;&#24615;&#21644;&#32463;&#27982;&#24615;&#33267;&#20851;&#37325;&#35201;&#12290;&#20316;&#20026;&#23547;&#27714;&#8220;&#24179;&#22374;&#8221;&#23616;&#37096;&#26368;&#23567;&#20540;&#30340;&#20247;&#25152;&#21608;&#30693;&#30340;&#21551;&#21457;&#24335;&#26041;&#27861;&#30340;&#20195;&#29702;&#65292;&#26799;&#24230;&#27491;&#21017;&#21270;&#26159;&#19968;&#26465;&#33258;&#28982;&#30340;&#36884;&#24452;&#65292;&#19968;&#38454;&#36817;&#20284;&#26041;&#27861;&#22914;Floding&#21644;Sharpness-Aware Minimization (SAM) &#24050;&#32463;&#21463;&#21040;&#20102;&#30456;&#24403;&#22823;&#30340;&#20851;&#27880;&#65292;&#20294;&#23427;&#20204;&#30340;&#24615;&#33021;&#20005;&#37325;&#20381;&#36182;&#20110;&#36229;&#21442;&#25968;&#65288;&#27946;&#27700;&#38408;&#20540;&#21644;&#37051;&#22495;&#21322;&#24452;&#65289;&#65292;&#36825;&#20123;&#36229;&#21442;&#25968;&#19981;&#23481;&#26131;&#20107;&#20808;&#30830;&#23450;&#12290;&#20026;&#20102;&#24320;&#21457;&#19968;&#20010;&#23545;&#38169;&#35823;&#36229;&#21442;&#25968;&#26356;&#20855;&#38887;&#24615;&#30340;&#36807;&#31243;&#65292;&#21463;Flooding&#20013;&#20351;&#29992;&#30340;&#30828;&#38408;&#20540;&#8220;&#19978;&#21319;-&#19979;&#38477;&#8221;&#24320;&#20851;&#35013;&#32622;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36719;&#21270;&#30340;&#36880;&#28857;&#26426;&#21046;&#65292;&#31216;&#20026;SoftAD&#65292;&#23427;&#23545;&#36793;&#30028;&#19978;&#30340;&#28857;&#36827;&#34892;&#38477;&#26435;&#65292;&#38480;&#21046;&#24322;&#24120;&#20540;&#30340;&#24433;&#21709;&#65292;&#24182;&#20445;&#30041;&#19978;&#21319;-&#19979;&#38477;&#25928;&#24212;&#12290;&#25105;&#20204;&#23558;&#24418;&#24335;&#30340;&#24179;&#31283;&#24615;&#20445;&#35777;&#19982;Flooding&#36827;&#34892;&#23545;&#27604;&#12290;
&lt;/p&gt;
&lt;p&gt;
As models grow larger and more complex, achieving better off-sample generalization with minimal trial-and-error is critical to the reliability and economy of machine learning workflows. As a proxy for the well-studied heuristic of seeking "flat" local minima, gradient regularization is a natural avenue, and first-order approximations such as Flooding and sharpness-aware minimization (SAM) have received significant attention, but their performance depends critically on hyperparameters (flood threshold and neighborhood radius, respectively) that are non-trivial to specify in advance. In order to develop a procedure which is more resilient to misspecified hyperparameters, with the hard-threshold "ascent-descent" switching device used in Flooding as motivation, we propose a softened, pointwise mechanism called SoftAD that downweights points on the borderline, limits the effects of outliers, and retains the ascent-descent effect. We contrast formal stationarity guarantees with those for Flo
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;Conformal-Predict-Then-Optimize&#65288;CPO&#65289;&#26694;&#26550;&#65292;&#21033;&#29992;&#39640;&#32500;&#38750;&#20984;&#25311;&#21512;&#39044;&#27979;&#21306;&#22495;&#65292;&#22312;&#25968;&#25454;&#39537;&#21160;&#30340;&#39044;&#27979;-&#20248;&#21270;&#20915;&#31574;&#38382;&#39064;&#20013;&#20943;&#36731;&#20102;&#23433;&#20840;&#20851;&#38190;&#29615;&#22659;&#20013;&#19981;&#30830;&#23450;&#24615;&#21306;&#22495;&#24314;&#27169;&#38169;&#35823;&#30340;&#39118;&#38505;&#65292;&#24182;&#36890;&#36807;&#25552;&#20379;&#35821;&#20041;&#21487;&#29702;&#35299;&#30340;&#21487;&#35270;&#21270;&#24635;&#32467;&#26469;&#35299;&#37322;&#26368;&#20248;&#20915;&#31574;&#12290;</title><link>http://arxiv.org/abs/2310.10003</link><description>&lt;p&gt;
&#12298;&#19968;&#31181;&#31526;&#21512;&#29615;&#22659;&#30340;&#40065;&#26834;&#24615;&#20248;&#21270;&#26041;&#27861;&#12299;
&lt;/p&gt;
&lt;p&gt;
Conformal Contextual Robust Optimization. (arXiv:2310.10003v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.10003
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;Conformal-Predict-Then-Optimize&#65288;CPO&#65289;&#26694;&#26550;&#65292;&#21033;&#29992;&#39640;&#32500;&#38750;&#20984;&#25311;&#21512;&#39044;&#27979;&#21306;&#22495;&#65292;&#22312;&#25968;&#25454;&#39537;&#21160;&#30340;&#39044;&#27979;-&#20248;&#21270;&#20915;&#31574;&#38382;&#39064;&#20013;&#20943;&#36731;&#20102;&#23433;&#20840;&#20851;&#38190;&#29615;&#22659;&#20013;&#19981;&#30830;&#23450;&#24615;&#21306;&#22495;&#24314;&#27169;&#38169;&#35823;&#30340;&#39118;&#38505;&#65292;&#24182;&#36890;&#36807;&#25552;&#20379;&#35821;&#20041;&#21487;&#29702;&#35299;&#30340;&#21487;&#35270;&#21270;&#24635;&#32467;&#26469;&#35299;&#37322;&#26368;&#20248;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#39537;&#21160;&#30340;&#39044;&#27979;-&#20248;&#21270;&#20915;&#31574;&#38382;&#39064;&#30340;&#26041;&#27861;&#26088;&#22312;&#20943;&#36731;&#23433;&#20840;&#20851;&#38190;&#29615;&#22659;&#20013;&#19981;&#30830;&#23450;&#24615;&#21306;&#22495;&#24314;&#27169;&#38169;&#35823;&#30340;&#39118;&#38505;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#30340;&#26041;&#27861;&#24448;&#24448;&#32771;&#34385;&#36807;&#20110;&#20445;&#23432;&#30340;&#19981;&#30830;&#23450;&#24615;&#21306;&#22495;&#65292;&#23548;&#33268;&#27425;&#20248;&#30340;&#20915;&#31574;&#32467;&#26524;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Conformal-Predict-Then-Optimize (CPO)&#30340;&#26694;&#26550;&#65292;&#35813;&#26694;&#26550;&#21033;&#29992;&#22522;&#20110;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#30340;&#39640;&#32500;&#38750;&#20984;&#25311;&#21512;&#39044;&#27979;&#21306;&#22495;&#65292;&#20855;&#26377;&#26399;&#26395;&#30340;&#26080;&#20998;&#24067;&#24615;&#20445;&#35777;&#12290;&#23613;&#31649;&#33021;&#22815;&#20445;&#35777;&#40065;&#26834;&#24615;&#65292;&#20294;&#20165;&#20165;&#20351;&#29992;&#36825;&#31181;&#40657;&#30418;&#20248;&#21270;&#36807;&#31243;&#20250;&#24102;&#26469;&#24456;&#23569;&#30340;&#32622;&#20449;&#24230;&#65292;&#22240;&#20026;&#26080;&#27861;&#35299;&#37322;&#20026;&#20309;&#26576;&#20010;&#20915;&#31574;&#34987;&#35748;&#20026;&#26159;&#26368;&#20248;&#30340;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#36824;&#22686;&#21152;&#20102;CPO&#30340;&#21151;&#33021;&#65292;&#21487;&#20197;&#25552;&#20379;&#23545;&#19981;&#30830;&#23450;&#24615;&#21306;&#22495;&#30340;&#35821;&#20041;&#21487;&#29702;&#35299;&#30340;&#21487;&#35270;&#21270;&#24635;&#32467;&#65292;&#20197;&#20415;&#30452;&#35266;&#22320;&#29702;&#35299;&#26368;&#20248;&#20915;&#31574;&#12290;&#25105;&#20204;&#36890;&#36807;&#23637;&#31034;&#26469;&#31361;&#20986;CPO&#26694;&#26550;&#30340;&#37325;&#35201;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data-driven approaches to predict-then-optimize decision-making problems seek to mitigate the risk of uncertainty region misspecification in safety-critical settings. Current approaches, however, suffer from considering overly conservative uncertainty regions, often resulting in suboptimal decisionmaking. To this end, we propose Conformal-Predict-Then-Optimize (CPO), a framework for leveraging highly informative, nonconvex conformal prediction regions over high-dimensional spaces based on conditional generative models, which have the desired distribution-free coverage guarantees. Despite guaranteeing robustness, such black-box optimization procedures alone inspire little confidence owing to the lack of explanation of why a particular decision was found to be optimal. We, therefore, augment CPO to additionally provide semantically meaningful visual summaries of the uncertainty regions to give qualitative intuition for the optimal decision. We highlight the CPO framework by demonstrating
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#24322;&#24120;&#20540;&#26816;&#27979;&#30340;&#26041;&#27861;&#65292;&#24314;&#31435;&#20102;&#22312;&#21463;&#31232;&#30095;&#24322;&#24120;&#20540;&#19979;&#20351;&#29992;&#29983;&#25104;&#27169;&#22411;&#37325;&#24314;&#20449;&#21495;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#32473;&#20986;&#20102;&#19979;&#30028;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#20010;&#31639;&#27861;&#35299;&#20915;&#24322;&#24120;&#20540;&#26816;&#27979;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.09999</link><description>&lt;p&gt;
&#20351;&#29992;&#20855;&#26377;&#29702;&#35770;&#24615;&#33021;&#20445;&#35777;&#30340;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#24322;&#24120;&#20540;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Outlier Detection Using Generative Models with Theoretical Performance Guarantees. (arXiv:2310.09999v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09999
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#29983;&#25104;&#27169;&#22411;&#36827;&#34892;&#24322;&#24120;&#20540;&#26816;&#27979;&#30340;&#26041;&#27861;&#65292;&#24314;&#31435;&#20102;&#22312;&#21463;&#31232;&#30095;&#24322;&#24120;&#20540;&#19979;&#20351;&#29992;&#29983;&#25104;&#27169;&#22411;&#37325;&#24314;&#20449;&#21495;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;&#32473;&#20986;&#20102;&#19979;&#30028;&#65292;&#24182;&#25552;&#20986;&#20102;&#20004;&#20010;&#31639;&#27861;&#35299;&#20915;&#24322;&#24120;&#20540;&#26816;&#27979;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#21033;&#29992;&#29983;&#25104;&#27169;&#22411;&#20174;&#21463;&#31232;&#30095;&#24322;&#24120;&#20540;&#27745;&#26579;&#30340;&#32447;&#24615;&#27979;&#37327;&#20013;&#24674;&#22797;&#20449;&#21495;&#30340;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22312;&#21463;&#31232;&#30095;&#24322;&#24120;&#20540;&#19979;&#37325;&#24314;&#30001;&#29983;&#25104;&#27169;&#22411;&#24314;&#27169;&#30340;&#30495;&#23454;&#20449;&#21495;&#30340;&#24322;&#24120;&#20540;&#26816;&#27979;&#26041;&#27861;&#12290;&#25105;&#20204;&#22312;&#23384;&#22312;&#24322;&#24120;&#20540;&#30340;&#24773;&#20917;&#19979;&#24314;&#31435;&#20102;&#20351;&#29992;&#29983;&#25104;&#27169;&#22411;&#37325;&#24314;&#20449;&#21495;&#30340;&#29702;&#35770;&#24674;&#22797;&#20445;&#35777;&#65292;&#24182;&#32473;&#20986;&#20102;&#21487;&#32416;&#27491;&#24322;&#24120;&#20540;&#25968;&#37327;&#30340;&#19979;&#30028;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#36866;&#29992;&#20110;&#20855;&#26377;&#20219;&#24847;&#23618;&#25968;&#30340;&#32447;&#24615;&#29983;&#25104;&#22120;&#31070;&#32463;&#32593;&#32476;&#21644;&#38750;&#32447;&#24615;&#29983;&#25104;&#22120;&#31070;&#32463;&#32593;&#32476;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#36890;&#36807;$\ell_1$&#33539;&#25968;&#26368;&#23567;&#21270;&#35299;&#20915;&#24322;&#24120;&#20540;&#26816;&#27979;&#38382;&#39064;&#30340;&#36845;&#20195;&#20132;&#26367;&#26041;&#21521;&#20056;&#23376;&#27861;&#65288;ADMM&#65289;&#31639;&#27861;&#65292;&#20197;&#21450;&#19968;&#31181;&#29992;&#20110;&#36890;&#36807;&#24179;&#26041;$\ell_1$&#33539;&#25968;&#26368;&#23567;&#21270;&#35299;&#20915;&#24322;&#24120;&#20540;&#26816;&#27979;&#38382;&#39064;&#30340;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#12290;&#25105;&#20204;&#20351;&#29992;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#21644;&#28145;&#24230;&#21367;&#31215;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#36827;&#34892;&#20102;&#24191;&#27867;&#23454;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper considers the problem of recovering signals modeled by generative models from linear measurements contaminated with sparse outliers. We propose an outlier detection approach for reconstructing the ground-truth signals modeled by generative models under sparse outliers. We establish theoretical recovery guarantees for reconstruction of signals using generative models in the presence of outliers, giving lower bounds on the number of correctable outliers. Our results are applicable to both linear generator neural networks and the nonlinear generator neural networks with an arbitrary number of layers. We propose an iterative alternating direction method of multipliers (ADMM) algorithm for solving the outlier detection problem via $\ell_1$ norm minimization, and a gradient descent algorithm for solving the outlier detection problem via squared $\ell_1$ norm minimization. We conduct extensive experiments using variational auto-encoder and deep convolutional generative adversarial 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20266;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#24182;&#36890;&#36807;&#30740;&#31350;&#26368;&#23567;&#35201;&#27714;&#30340;&#20844;&#29702;&#26694;&#26550;&#65292;&#26500;&#24314;&#20102;&#33021;&#30830;&#20445;&#40657;&#30418;&#20248;&#21270;&#25910;&#25947;&#24615;&#30340;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2310.09766</link><description>&lt;p&gt;
&#20266;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Pseudo-Bayesian Optimization. (arXiv:2310.09766v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09766
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20266;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#24182;&#36890;&#36807;&#30740;&#31350;&#26368;&#23567;&#35201;&#27714;&#30340;&#20844;&#29702;&#26694;&#26550;&#65292;&#26500;&#24314;&#20102;&#33021;&#30830;&#20445;&#40657;&#30418;&#20248;&#21270;&#25910;&#25947;&#24615;&#30340;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#26159;&#19968;&#31181;&#20248;&#21270;&#26114;&#36149;&#40657;&#30418;&#20989;&#25968;&#30340;&#27969;&#34892;&#26041;&#27861;&#12290;&#20854;&#20851;&#38190;&#24605;&#24819;&#26159;&#20351;&#29992;&#19968;&#20010;&#26367;&#20195;&#27169;&#22411;&#26469;&#36817;&#20284;&#30446;&#26631;&#65292;&#24182;&#19988;&#37325;&#35201;&#30340;&#26159;&#37327;&#21270;&#30456;&#20851;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#20174;&#32780;&#23454;&#29616;&#25506;&#32034;&#21644;&#24320;&#21457;&#20043;&#38388;&#30340;&#24179;&#34913;&#30340;&#39034;&#24207;&#25628;&#32034;&#12290;&#39640;&#26031;&#36807;&#31243;(GP)&#19968;&#30452;&#26159;&#26367;&#20195;&#27169;&#22411;&#30340;&#39318;&#36873;&#65292;&#22240;&#20026;&#23427;&#20855;&#26377;&#36125;&#21494;&#26031;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#33021;&#21147;&#21644;&#24314;&#27169;&#28789;&#27963;&#24615;&#12290;&#28982;&#32780;&#65292;&#23427;&#30340;&#25361;&#25112;&#20063;&#24341;&#21457;&#20102;&#19968;&#31995;&#21015;&#25910;&#25947;&#24615;&#26356;&#26174;&#24471;&#19981;&#26126;&#26174;&#30340;&#22791;&#36873;&#26041;&#26696;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#30740;&#31350;&#24341;&#20986;&#26368;&#23567;&#35201;&#27714;&#30340;&#20844;&#29702;&#26694;&#26550;&#26469;&#30830;&#20445;&#40657;&#30418;&#20248;&#21270;&#30340;&#25910;&#25947;&#24615;&#65292;&#20197;&#24212;&#29992;&#20110;&#38500;&#20102;GP&#30456;&#20851;&#26041;&#27861;&#20043;&#22806;&#30340;&#24773;&#20917;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#21033;&#29992;&#25105;&#20204;&#30340;&#26694;&#26550;&#20013;&#30340;&#35774;&#35745;&#33258;&#30001;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;&#20266;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#26469;&#26500;&#24314;&#32463;&#39564;&#19978;&#26356;&#20248;&#30340;&#31639;&#27861;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#20351;&#29992;&#31616;&#21333;&#30340;&#23616;&#37096;&#22238;&#24402;&#21644;&#19968;&#20010;&#36866;&#24212;&#38382;&#39064;&#29305;&#24615;&#30340;&#20195;&#29702;&#27169;&#22411;&#26469;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian Optimization is a popular approach for optimizing expensive black-box functions. Its key idea is to use a surrogate model to approximate the objective and, importantly, quantify the associated uncertainty that allows a sequential search of query points that balance exploitation-exploration. Gaussian process (GP) has been a primary candidate for the surrogate model, thanks to its Bayesian-principled uncertainty quantification power and modeling flexibility. However, its challenges have also spurred an array of alternatives whose convergence properties could be more opaque. Motivated by these, we study in this paper an axiomatic framework that elicits the minimal requirements to guarantee black-box optimization convergence that could apply beyond GP-related methods. Moreover, we leverage the design freedom in our framework, which we call Pseudo-Bayesian Optimization, to construct empirically superior algorithms. In particular, we show how using simple local regression, and a sui
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#22312;&#22238;&#24402;&#35774;&#32622;&#19979;&#32473;&#20986;&#20102;Mondrian&#38543;&#26426;&#26862;&#26519;&#30340;&#20272;&#35745;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#21644;&#21435;&#20559;&#36807;&#31243;&#65292;&#20351;&#20854;&#33021;&#22815;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#21644;&#23454;&#29616;&#26368;&#23567;&#26497;&#22823;&#20272;&#35745;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2310.09702</link><description>&lt;p&gt;
&#24102;&#26377;Mondrian&#38543;&#26426;&#26862;&#26519;&#30340;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Inference with Mondrian Random Forests. (arXiv:2310.09702v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09702
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312;&#22238;&#24402;&#35774;&#32622;&#19979;&#32473;&#20986;&#20102;Mondrian&#38543;&#26426;&#26862;&#26519;&#30340;&#20272;&#35745;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#21644;&#21435;&#20559;&#36807;&#31243;&#65292;&#20351;&#20854;&#33021;&#22815;&#36827;&#34892;&#32479;&#35745;&#25512;&#26029;&#21644;&#23454;&#29616;&#26368;&#23567;&#26497;&#22823;&#20272;&#35745;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#26862;&#26519;&#26159;&#19968;&#31181;&#24120;&#29992;&#30340;&#20998;&#31867;&#21644;&#22238;&#24402;&#26041;&#27861;&#65292;&#22312;&#26368;&#36817;&#20960;&#24180;&#20013;&#25552;&#20986;&#20102;&#35768;&#22810;&#19981;&#21516;&#30340;&#21464;&#20307;&#12290;&#19968;&#20010;&#26377;&#36259;&#30340;&#20363;&#23376;&#26159;Mondrian&#38543;&#26426;&#26862;&#26519;&#65292;&#20854;&#20013;&#24213;&#23618;&#26641;&#26159;&#26681;&#25454;Mondrian&#36807;&#31243;&#26500;&#24314;&#30340;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;Mondrian&#38543;&#26426;&#26862;&#26519;&#22312;&#22238;&#24402;&#35774;&#32622;&#19979;&#30340;&#20272;&#35745;&#30340;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#12290;&#24403;&#19982;&#20559;&#24046;&#34920;&#24449;&#21644;&#19968;&#33268;&#26041;&#24046;&#20272;&#35745;&#22120;&#30456;&#32467;&#21512;&#26102;&#65292;&#36825;&#20801;&#35768;&#36827;&#34892;&#28176;&#36817;&#26377;&#25928;&#30340;&#32479;&#35745;&#25512;&#26029;&#65292;&#22914;&#26500;&#24314;&#32622;&#20449;&#21306;&#38388;&#65292;&#23545;&#26410;&#30693;&#30340;&#22238;&#24402;&#20989;&#25968;&#36827;&#34892;&#25512;&#26029;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#19968;&#31181;&#21435;&#20559;&#36807;&#31243;&#65292;&#29992;&#20110;Mondrian&#38543;&#26426;&#26862;&#26519;&#65292;&#20351;&#20854;&#33021;&#22815;&#22312;&#36866;&#24403;&#30340;&#21442;&#25968;&#35843;&#25972;&#19979;&#23454;&#29616;$\beta$-H\"older&#22238;&#24402;&#20989;&#25968;&#30340;&#26368;&#23567;&#26497;&#22823;&#20272;&#35745;&#36895;&#29575;&#65292;&#23545;&#20110;&#25152;&#26377;&#30340;$\beta$&#21644;&#20219;&#24847;&#32500;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Random forests are popular methods for classification and regression, and many different variants have been proposed in recent years. One interesting example is the Mondrian random forest, in which the underlying trees are constructed according to a Mondrian process. In this paper we give a central limit theorem for the estimates made by a Mondrian random forest in the regression setting. When combined with a bias characterization and a consistent variance estimator, this allows one to perform asymptotically valid statistical inference, such as constructing confidence intervals, on the unknown regression function. We also provide a debiasing procedure for Mondrian random forests which allows them to achieve minimax-optimal estimation rates with $\beta$-H\"older regression functions, for all $\beta$ and in arbitrary dimension, assuming appropriate parameter tuning.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;DPZero&#31639;&#27861;&#65292;&#36825;&#26159;&#19968;&#31181;&#19982;&#32500;&#24230;&#26080;&#20851;&#19988;&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;&#30340;&#38646;&#38454;&#20248;&#21270;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#22312;&#32454;&#35843;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26102;&#38754;&#20020;&#30340;&#20869;&#23384;&#21644;&#38544;&#31169;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2310.09639</link><description>&lt;p&gt;
DPZero&#65306;&#19982;&#32500;&#24230;&#26080;&#20851;&#19988;&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;&#30340;&#38646;&#38454;&#20248;&#21270;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
DPZero: Dimension-Independent and Differentially Private Zeroth-Order Optimization. (arXiv:2310.09639v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09639
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;DPZero&#31639;&#27861;&#65292;&#36825;&#26159;&#19968;&#31181;&#19982;&#32500;&#24230;&#26080;&#20851;&#19988;&#20855;&#26377;&#24046;&#20998;&#38544;&#31169;&#30340;&#38646;&#38454;&#20248;&#21270;&#31639;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#22312;&#32454;&#35843;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#26102;&#38754;&#20020;&#30340;&#20869;&#23384;&#21644;&#38544;&#31169;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32454;&#35843;&#39044;&#35757;&#32451;&#30340;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#65288;LLM&#65289;&#20197;&#36866;&#24212;&#29305;&#23450;&#39046;&#22495;&#25968;&#25454;&#30340;&#24191;&#27867;&#23454;&#36341;&#20013;&#65292;&#38754;&#20020;&#30528;&#20869;&#23384;&#21644;&#38544;&#31169;&#20004;&#20010;&#20027;&#35201;&#25361;&#25112;&#12290;&#39318;&#20808;&#65292;&#38543;&#30528;LLM&#30340;&#35268;&#27169;&#19981;&#26029;&#22686;&#38271;&#65292;&#36798;&#21040;&#25968;&#21313;&#20159;&#20010;&#21442;&#25968;&#65292;&#22522;&#20110;&#26799;&#24230;&#30340;&#21453;&#21521;&#20256;&#25773;&#35757;&#32451;&#26041;&#27861;&#25152;&#38656;&#30340;&#20869;&#23384;&#28040;&#32791;&#21464;&#24471;&#38590;&#20197;&#25215;&#21463;&#12290;&#20854;&#27425;&#65292;&#32771;&#34385;&#21040;LLM&#20542;&#21521;&#20110;&#35760;&#24518;&#21644;&#27844;&#38706;&#25935;&#24863;&#30340;&#35757;&#32451;&#25968;&#25454;&#65292;&#24517;&#39035;&#20445;&#25252;&#32454;&#35843;&#25968;&#25454;&#30340;&#38544;&#31169;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#25506;&#32034;&#20102;&#23558;&#38646;&#38454;&#26041;&#27861;&#19982;&#24046;&#20998;&#38544;&#31169;&#20248;&#21270;&#30456;&#32467;&#21512;&#29992;&#20110;LLM&#30340;&#32454;&#35843;&#30340;&#28508;&#21147;&#12290;&#38646;&#38454;&#26041;&#27861;&#20165;&#20381;&#36182;&#21069;&#21521;&#20256;&#36882;&#65292;&#22823;&#22823;&#20943;&#23569;&#20102;&#35757;&#32451;&#36807;&#31243;&#20013;&#30340;&#20869;&#23384;&#28040;&#32791;&#12290;&#28982;&#32780;&#65292;&#30452;&#25509;&#23558;&#23427;&#20204;&#19982;&#26631;&#20934;&#30340;&#24046;&#20998;&#38544;&#31169;&#26426;&#21046;&#32467;&#21512;&#22312;&#19968;&#36215;&#20250;&#23548;&#33268;&#32500;&#24230;&#30456;&#20851;&#30340;&#22797;&#26434;&#24615;&#12290;&#20026;&#20102;&#24357;&#21512;&#36825;&#19968;&#24046;&#36317;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;DPZero&#65292;&#19968;&#31181;&#20855;&#26377;&#36817;&#20046;&#32500;&#24230;&#26080;&#20851;&#29575;&#30340;&#26032;&#22411;&#24046;&#20998;&#38544;&#31169;&#38646;&#38454;&#31639;&#27861;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#25581;&#31034;&#20986;&#20102;
&lt;/p&gt;
&lt;p&gt;
The widespread practice of fine-tuning pretrained large language models (LLMs) on domain-specific data faces two major challenges in memory and privacy. First, as the size of LLMs continue to grow, encompassing billions of parameters, the memory demands of gradient-based training methods via backpropagation become prohibitively high. Second, given the tendency of LLMs to memorize and disclose sensitive training data, the privacy of fine-tuning data must be respected. To this end, we explore the potential of zeroth-order methods in differentially private optimization for fine-tuning LLMs. Zeroth-order methods, which rely solely on forward passes, substantially reduce memory consumption during training. However, directly combining them with standard differential privacy mechanism poses dimension-dependent complexity. To bridge the gap, we introduce DPZero, a novel differentially private zeroth-order algorithm with nearly dimension-independent rates. Our theoretical analysis reveals that 
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#21516;&#20262;&#24310;&#32493;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#28145;&#24230;&#24179;&#34913;&#27169;&#22411;&#65288;DEQs&#65289;&#21644;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;Neural ODEs&#65289;&#20043;&#38388;&#30340;&#36830;&#25509;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38544;&#24335;&#27169;&#22411;HomoODE&#65292;&#23427;&#32487;&#25215;&#20102;DEQs&#30340;&#39640;&#31934;&#24230;&#24615;&#33021;&#21644;Neural ODEs&#30340;&#31283;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.09583</link><description>&lt;p&gt;
&#20004;&#26522;&#30828;&#24065;&#30340;&#20004;&#38754;&#65306;&#36890;&#36807;&#21516;&#20262;&#24310;&#32493;&#36830;&#25509;&#28145;&#24230;&#24179;&#34913;&#27169;&#22411;&#21644;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;
&lt;/p&gt;
&lt;p&gt;
Two Sides of The Same Coin: Bridging Deep Equilibrium Models and Neural ODEs via Homotopy Continuation. (arXiv:2310.09583v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09583
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#21516;&#20262;&#24310;&#32493;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#28145;&#24230;&#24179;&#34913;&#27169;&#22411;&#65288;DEQs&#65289;&#21644;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;Neural ODEs&#65289;&#20043;&#38388;&#30340;&#36830;&#25509;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38544;&#24335;&#27169;&#22411;HomoODE&#65292;&#23427;&#32487;&#25215;&#20102;DEQs&#30340;&#39640;&#31934;&#24230;&#24615;&#33021;&#21644;Neural ODEs&#30340;&#31283;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#24179;&#34913;&#27169;&#22411;&#65288;DEQs&#65289;&#21644;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#65288;Neural ODEs&#65289;&#26159;&#20004;&#31181;&#38544;&#24335;&#27169;&#22411;&#30340;&#20998;&#25903;&#65292;&#20197;&#20854;&#21331;&#36234;&#30340;&#24615;&#33021;&#21644;&#20302;&#20869;&#23384;&#28040;&#32791;&#25104;&#23601;&#20102;&#26174;&#33879;&#30340;&#25104;&#21151;&#12290;&#34429;&#28982;&#20004;&#32773;&#37117;&#26159;&#38544;&#24335;&#27169;&#22411;&#65292;&#20294;DEQs&#21644;Neural ODEs&#26159;&#20174;&#19981;&#21516;&#30340;&#25968;&#23398;&#24418;&#24335;&#23548;&#20986;&#30340;&#12290;&#21463;&#21516;&#20262;&#24310;&#32493;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#36825;&#20004;&#31181;&#27169;&#22411;&#20043;&#38388;&#30340;&#32852;&#31995;&#65292;&#24182;&#34920;&#26126;&#23427;&#20204;&#23454;&#38469;&#19978;&#26159;&#21516;&#19968;&#20010;&#30828;&#24065;&#30340;&#20004;&#38754;&#12290;&#21516;&#20262;&#24310;&#32493;&#26159;&#19968;&#31181;&#22522;&#20110;&#23545;&#24212;ODE&#30340;&#35299;&#38750;&#32447;&#24615;&#26041;&#31243;&#32452;&#30340;&#32463;&#20856;&#26041;&#27861;&#12290;&#32473;&#23450;&#36825;&#31181;&#32852;&#31995;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#38544;&#24335;&#27169;&#22411;&#31216;&#20026;HomoODE&#65292;&#23427;&#32487;&#25215;&#20102;DEQs&#30340;&#39640;&#31934;&#24230;&#24615;&#36136;&#21644;Neural ODEs&#30340;&#31283;&#23450;&#24615;&#12290;&#19982;DEQs&#19981;&#21516;&#65292;HomoODE&#36890;&#36807;&#21516;&#20262;&#24310;&#32493;&#20351;&#29992;&#20462;&#25913;&#21518;&#30340;&#31070;&#32463;&#24120;&#24494;&#20998;&#26041;&#31243;&#38544;&#24335;&#22320;&#35299;&#20915;&#24179;&#34913;&#28857;&#25214;&#23547;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
Deep Equilibrium Models (DEQs) and Neural Ordinary Differential Equations (Neural ODEs) are two branches of implicit models that have achieved remarkable success owing to their superior performance and low memory consumption. While both are implicit models, DEQs and Neural ODEs are derived from different mathematical formulations. Inspired by homotopy continuation, we establish a connection between these two models and illustrate that they are actually two sides of the same coin. Homotopy continuation is a classical method of solving nonlinear equations based on a corresponding ODE. Given this connection, we proposed a new implicit model called HomoODE that inherits the property of high accuracy from DEQs and the property of stability from Neural ODEs. Unlike DEQs, which explicitly solve an equilibrium-point-finding problem via Newton's methods in the forward pass, HomoODE solves the equilibrium-point-finding problem implicitly using a modified Neural ODE via homotopy continuation. Fur
&lt;/p&gt;</description></item><item><title>ARTree&#26159;&#19968;&#31181;&#29992;&#20110;&#31995;&#32479;&#21457;&#32946;&#25512;&#26029;&#30340;&#28145;&#24230;&#33258;&#22238;&#24402;&#27169;&#22411;&#65292;&#36890;&#36807;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#23545;&#26641;&#24418;&#25299;&#25169;&#32467;&#26500;&#30340;&#26465;&#20214;&#20998;&#24067;&#36827;&#34892;&#24314;&#27169;&#65292;&#33021;&#22815;&#25552;&#20379;&#25972;&#20010;&#26641;&#24418;&#25299;&#25169;&#31354;&#38388;&#30340;&#20016;&#23500;&#20998;&#24067;&#65292;&#24182;&#20855;&#26377;&#31616;&#21333;&#30340;&#37319;&#26679;&#31639;&#27861;&#21644;&#23494;&#24230;&#20272;&#35745;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2310.09553</link><description>&lt;p&gt;
ARTree: &#19968;&#31181;&#29992;&#20110;&#31995;&#32479;&#21457;&#32946;&#25512;&#26029;&#30340;&#28145;&#24230;&#33258;&#22238;&#24402;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
ARTree: A Deep Autoregressive Model for Phylogenetic Inference. (arXiv:2310.09553v1 [q-bio.PE])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09553
&lt;/p&gt;
&lt;p&gt;
ARTree&#26159;&#19968;&#31181;&#29992;&#20110;&#31995;&#32479;&#21457;&#32946;&#25512;&#26029;&#30340;&#28145;&#24230;&#33258;&#22238;&#24402;&#27169;&#22411;&#65292;&#36890;&#36807;&#20351;&#29992;&#22270;&#31070;&#32463;&#32593;&#32476;&#23545;&#26641;&#24418;&#25299;&#25169;&#32467;&#26500;&#30340;&#26465;&#20214;&#20998;&#24067;&#36827;&#34892;&#24314;&#27169;&#65292;&#33021;&#22815;&#25552;&#20379;&#25972;&#20010;&#26641;&#24418;&#25299;&#25169;&#31354;&#38388;&#30340;&#20016;&#23500;&#20998;&#24067;&#65292;&#24182;&#20855;&#26377;&#31616;&#21333;&#30340;&#37319;&#26679;&#31639;&#27861;&#21644;&#23494;&#24230;&#20272;&#35745;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35774;&#35745;&#28789;&#27963;&#30340;&#27010;&#29575;&#27169;&#22411;&#26469;&#24314;&#31435;&#26641;&#24418;&#25299;&#25169;&#32467;&#26500;&#23545;&#20110;&#24320;&#21457;&#39640;&#25928;&#30340;&#31995;&#32479;&#21457;&#32946;&#25512;&#26029;&#26041;&#27861;&#33267;&#20851;&#37325;&#35201;&#12290;&#20026;&#20102;&#20570;&#21040;&#36825;&#19968;&#28857;&#65292;&#20043;&#21069;&#30340;&#24037;&#20316;&#24448;&#24448;&#21033;&#29992;&#26641;&#24418;&#25299;&#25169;&#32467;&#26500;&#30340;&#30456;&#20284;&#24615;&#65292;&#36890;&#36807;&#25163;&#24037;&#35774;&#35745;&#30340;&#21551;&#21457;&#24335;&#29305;&#24449;&#26469;&#23454;&#29616;&#65292;&#36825;&#38656;&#35201;&#39044;&#20808;&#37319;&#26679;&#26641;&#24418;&#25299;&#25169;&#32467;&#26500;&#65292;&#24182;&#19988;&#21487;&#33021;&#21463;&#38480;&#20110;&#36817;&#20284;&#33021;&#21147;&#26377;&#38480;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#22270;&#31070;&#32463;&#32593;&#32476;(GNNs)&#30340;&#28145;&#24230;&#33258;&#22238;&#24402;&#27169;&#22411;&#29992;&#20110;&#31995;&#32479;&#21457;&#32946;&#25512;&#26029;&#65292;&#31216;&#20026;ARTree&#12290;&#36890;&#36807;&#23558;&#26641;&#24418;&#25299;&#25169;&#32467;&#26500;&#20998;&#35299;&#20026;&#19968;&#31995;&#21015;&#21494;&#33410;&#28857;&#28155;&#21152;&#25805;&#20316;&#65292;&#24182;&#21033;&#29992;&#21487;&#23398;&#20064;&#30340;&#25299;&#25169;&#29305;&#24449;&#36890;&#36807;GNNs&#23545;&#25152;&#28041;&#21450;&#30340;&#26465;&#20214;&#20998;&#24067;&#36827;&#34892;&#24314;&#27169;&#65292;ARTree&#21487;&#20197;&#25552;&#20379;&#19968;&#20010;&#20016;&#23500;&#30340;&#20998;&#24067;&#26063;&#65292;&#35206;&#30422;&#25972;&#20010;&#26641;&#24418;&#25299;&#25169;&#31354;&#38388;&#65292;&#24182;&#20855;&#26377;&#31616;&#21333;&#30340;&#37319;&#26679;&#31639;&#27861;&#21644;&#23494;&#24230;&#20272;&#35745;&#36807;&#31243;&#65292;&#32780;&#26080;&#38656;&#20351;&#29992;&#21551;&#21457;&#24335;&#29305;&#24449;&#12290;&#25105;&#20204;&#22312;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#30495;&#23454;&#25968;&#25454;&#26641;&#24418;&#25299;&#25169;&#23494;&#24230;&#20272;&#35745;&#21644;&#21464;&#20998;&#25512;&#26029;&#22522;&#20934;&#19978;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#25928;&#26524;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
Designing flexible probabilistic models over tree topologies is important for developing efficient phylogenetic inference methods. To do that, previous works often leverage the similarity of tree topologies via hand-engineered heuristic features which would require pre-sampled tree topologies and may suffer from limited approximation capability. In this paper, we propose a deep autoregressive model for phylogenetic inference based on graph neural networks (GNNs), called ARTree. By decomposing a tree topology into a sequence of leaf node addition operations and modeling the involved conditional distributions based on learnable topological features via GNNs, ARTree can provide a rich family of distributions over the entire tree topology space that have simple sampling algorithms and density estimation procedures, without using heuristic features. We demonstrate the effectiveness and efficiency of our method on a benchmark of challenging real data tree topology density estimation and vari
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#21322;&#21442;&#25968;&#30340;&#24037;&#20855;&#21464;&#24046;&#20998;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#26368;&#20248;&#27835;&#30103;&#25919;&#31574;&#65292;&#24182;&#26500;&#24314;&#20102;&#19968;&#20123;&#20272;&#35745;&#22120;&#26469;&#35299;&#20915;&#24179;&#34892;&#36235;&#21183;&#20551;&#35774;&#19981;&#25104;&#31435;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2310.09545</link><description>&lt;p&gt;
&#19968;&#31181;&#21322;&#21442;&#25968;&#30340;&#24037;&#20855;&#21464;&#24046;&#20998;&#26041;&#27861;&#29992;&#20110;&#25919;&#31574;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
A Semiparametric Instrumented Difference-in-Differences Approach to Policy Learning. (arXiv:2310.09545v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09545
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#21322;&#21442;&#25968;&#30340;&#24037;&#20855;&#21464;&#24046;&#20998;&#26041;&#27861;&#65292;&#29992;&#20110;&#23398;&#20064;&#26368;&#20248;&#27835;&#30103;&#25919;&#31574;&#65292;&#24182;&#26500;&#24314;&#20102;&#19968;&#20123;&#20272;&#35745;&#22120;&#26469;&#35299;&#20915;&#24179;&#34892;&#36235;&#21183;&#20551;&#35774;&#19981;&#25104;&#31435;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#65292;&#38024;&#23545;&#24046;&#24322;&#23545;&#24046;&#24322;&#65288;DiD&#65289;&#26041;&#27861;&#36827;&#34892;&#22240;&#26524;&#25928;&#24212;&#35780;&#20272;&#30340;&#26041;&#27861;&#23398;&#21457;&#23637;&#26377;&#25152;&#22686;&#21152;&#12290;&#25991;&#29486;&#20013;&#30340;&#26631;&#20934;&#26041;&#27861;&#20381;&#36182;&#20110;&#24179;&#34892;&#36235;&#21183;&#20551;&#35774;&#26469;&#35782;&#21035;&#23545;&#24453;&#22788;&#29702;&#30340;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#12290;&#28982;&#32780;&#65292;&#22312;&#23384;&#22312;&#26410;&#27979;&#23450;&#28151;&#28102;&#30340;&#24773;&#20917;&#19979;&#65292;&#24179;&#34892;&#36235;&#21183;&#20551;&#35774;&#21487;&#33021;&#20250;&#34987;&#36829;&#21453;&#65292;&#24182;&#19988;&#23545;&#24453;&#22788;&#29702;&#30340;&#24179;&#22343;&#22788;&#29702;&#25928;&#24212;&#21487;&#33021;&#23545;&#25972;&#20010;&#20154;&#32676;&#30340;&#27835;&#30103;&#20998;&#37197;&#25919;&#31574;&#23398;&#20064;&#27809;&#26377;&#29992;&#22788;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#29992;&#30340;&#24037;&#20855;&#21464;&#24046;&#20998;&#26041;&#27861;&#26469;&#23398;&#20064;&#26368;&#20248;&#30340;&#27835;&#30103;&#25919;&#31574;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#20108;&#36827;&#21046;&#24037;&#20855;&#21464;&#37327;&#65288;IV&#65289;&#30340;&#35782;&#21035;&#32467;&#26524;&#65292;&#24403;&#24179;&#34892;&#36235;&#21183;&#20551;&#35774;&#19981;&#25104;&#31435;&#26102;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#29926;&#23572;&#24503;&#20272;&#35745;&#22120;&#12289;&#26032;&#39062;&#30340;&#21453;&#27010;&#29575;&#21152;&#26435;&#20272;&#35745;&#22120;&#65288;IPW&#65289;&#21644;&#19968;&#31867;&#21322;&#21442;&#25968;&#26377;&#25928;&#19988;&#22810;&#37325;&#40065;&#26834;&#20272;&#35745;&#22120;&#65292;&#20855;&#26377;&#19968;&#33268;&#24615;&#21644;&#28176;&#36817;&#27491;&#24577;&#24615;&#30340;&#29702;&#35770;&#20445;&#35777;&#65292;
&lt;/p&gt;
&lt;p&gt;
Recently, there has been a surge in methodological development for the difference-in-differences (DiD) approach to evaluate causal effects. Standard methods in the literature rely on the parallel trends assumption to identify the average treatment effect on the treated. However, the parallel trends assumption may be violated in the presence of unmeasured confounding, and the average treatment effect on the treated may not be useful in learning a treatment assignment policy for the entire population. In this article, we propose a general instrumented DiD approach for learning the optimal treatment policy. Specifically, we establish identification results using a binary instrumental variable (IV) when the parallel trends assumption fails to hold. Additionally, we construct a Wald estimator, novel inverse probability weighting (IPW) estimators, and a class of semiparametric efficient and multiply robust estimators, with theoretical guarantees on consistency and asymptotic normality, even 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;GNN&#26550;&#26500;&#65292;&#36890;&#36807;&#36127;&#37319;&#26679;&#35825;&#23548;&#20102;&#27491;&#36793;&#21644;&#36127;&#36793;&#30340;&#27491;&#21521;&#20256;&#36882;&#65292;&#20197;&#26356;&#21152;&#28789;&#27963;&#32780;&#31283;&#23450;&#22320;&#36827;&#34892;&#38142;&#25509;&#39044;&#27979;&#12290;</title><link>http://arxiv.org/abs/2310.09516</link><description>&lt;p&gt;
&#36890;&#36807;&#36127;&#37319;&#26679;&#35825;&#23548;&#30340;GNN&#23618;&#36827;&#34892;&#39640;&#25928;&#30340;&#38142;&#25509;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Efficient Link Prediction via GNN Layers Induced by Negative Sampling. (arXiv:2310.09516v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09516
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;GNN&#26550;&#26500;&#65292;&#36890;&#36807;&#36127;&#37319;&#26679;&#35825;&#23548;&#20102;&#27491;&#36793;&#21644;&#36127;&#36793;&#30340;&#27491;&#21521;&#20256;&#36882;&#65292;&#20197;&#26356;&#21152;&#28789;&#27963;&#32780;&#31283;&#23450;&#22320;&#36827;&#34892;&#38142;&#25509;&#39044;&#27979;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38142;&#25509;&#39044;&#27979;&#20013;&#30340;&#22270;&#31070;&#32463;&#32593;&#32476;(GNN)&#21487;&#20197;&#22823;&#33268;&#20998;&#20026;&#20004;&#22823;&#31867;&#12290;&#31532;&#19968;&#31867;&#26159;&#22522;&#20110;&#33410;&#28857;&#30340;&#32467;&#26500;&#65292;&#20026;&#27599;&#20010;&#33410;&#28857;&#39044;&#20808;&#35745;&#31639;&#20010;&#20307;&#23884;&#20837;&#65292;&#24182;&#36890;&#36807;&#31616;&#21333;&#30340;&#35299;&#30721;&#22120;&#36827;&#34892;&#32452;&#21512;&#20197;&#36827;&#34892;&#39044;&#27979;&#12290;&#23613;&#31649;&#22312;&#25512;&#29702;&#26102;&#38750;&#24120;&#39640;&#25928;&#65288;&#22240;&#20026;&#33410;&#28857;&#23884;&#20837;&#21482;&#35745;&#31639;&#19968;&#27425;&#24182;&#21453;&#22797;&#37325;&#29992;&#65289;&#65292;&#20294;&#27169;&#22411;&#34920;&#36798;&#33021;&#21147;&#26377;&#38480;&#65292;&#23548;&#33268;&#26080;&#27861;&#21306;&#20998;&#23545;&#20505;&#36873;&#36793;&#26377;&#36129;&#29486;&#30340;&#21516;&#26500;&#33410;&#28857;&#65292;&#20174;&#32780;&#24433;&#21709;&#20934;&#30830;&#24615;&#12290;&#19982;&#20043;&#30456;&#21453;&#65292;&#31532;&#20108;&#31867;&#26041;&#27861;&#21017;&#20381;&#36182;&#20110;&#24418;&#25104;&#38024;&#23545;&#27599;&#20010;&#36793;&#30340;&#23376;&#22270;&#23884;&#20837;&#65292;&#20197;&#20016;&#23500;&#20004;&#20004;&#20851;&#31995;&#30340;&#34920;&#31034;&#65292;&#20174;&#32780;&#28040;&#38500;&#21516;&#26500;&#33410;&#28857;&#65292;&#25552;&#39640;&#20934;&#30830;&#24615;&#65292;&#20294;&#20195;&#20215;&#26159;&#22686;&#21152;&#20102;&#27169;&#22411;&#22797;&#26434;&#24230;&#12290;&#20026;&#20102;&#26356;&#22909;&#22320;&#26435;&#34913;&#36825;&#20010;&#21462;&#33293;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;GNN&#26550;&#26500;&#65292;&#20854;&#20013;&#30340;&#27491;&#21521;&#20256;&#36882;&#26126;&#30830;&#20381;&#36182;&#20110;&#27491;&#36793;&#65288;&#36890;&#24120;&#24773;&#20917;&#19979;&#65289;&#21644;&#36127;&#36793;&#65288;&#25105;&#20204;&#26041;&#27861;&#30340;&#29420;&#29305;&#20043;&#22788;&#65289;&#65292;&#20197;&#25552;&#20379;&#26356;&#28789;&#27963;&#20294;&#20173;&#31283;&#23450;&#30340;&#20449;&#21495;&#12290;
&lt;/p&gt;
&lt;p&gt;
Graph neural networks (GNNs) for link prediction can loosely be divided into two broad categories. First, \emph{node-wise} architectures pre-compute individual embeddings for each node that are later combined by a simple decoder to make predictions. While extremely efficient at inference time (since node embeddings are only computed once and repeatedly reused), model expressiveness is limited such that isomorphic nodes contributing to candidate edges may not be distinguishable, compromising accuracy. In contrast, \emph{edge-wise} methods rely on the formation of edge-specific subgraph embeddings to enrich the representation of pair-wise relationships, disambiguating isomorphic nodes to improve accuracy, but with the cost of increased model complexity. To better navigate this trade-off, we propose a novel GNN architecture whereby the \emph{forward pass} explicitly depends on \emph{both} positive (as is typical) and negative (unique to our approach) edges to inform more flexible, yet sti
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#23398;&#20064;&#22270;&#20687;&#21160;&#24577;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#28508;&#22312;&#21160;&#24577;&#20272;&#35745;&#22270;&#20687;&#28436;&#21464;&#30340;&#20013;&#38388;&#38454;&#27573;&#65292;&#20174;&#32780;&#23454;&#29616;&#35299;&#37322;&#24615;&#65292;&#24182;&#20445;&#30041;&#19982;&#22270;&#20687;&#30340;&#31354;&#38388;&#30456;&#20851;&#24615;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#20351;&#29992;&#36981;&#24490;&#29289;&#29702;&#27169;&#22411;&#30340;&#28508;&#22312;&#21464;&#37327;&#65292;&#30830;&#20445;&#20102;&#23398;&#20064;&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#22312;&#22320;&#29699;&#31185;&#23398;&#22270;&#20687;&#25968;&#25454;&#19978;&#23637;&#31034;&#20102;&#20854;&#40065;&#26834;&#24615;&#21644;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.09495</link><description>&lt;p&gt;
&#36890;&#36807;&#29289;&#29702;&#28508;&#22312;&#31354;&#38388;&#23398;&#20064;&#22270;&#20687;&#21160;&#24577;
&lt;/p&gt;
&lt;p&gt;
Learning In-between Imagery Dynamics via Physical Latent Spaces. (arXiv:2310.09495v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09495
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#23398;&#20064;&#22270;&#20687;&#21160;&#24577;&#30340;&#26694;&#26550;&#65292;&#36890;&#36807;&#28508;&#22312;&#21160;&#24577;&#20272;&#35745;&#22270;&#20687;&#28436;&#21464;&#30340;&#20013;&#38388;&#38454;&#27573;&#65292;&#20174;&#32780;&#23454;&#29616;&#35299;&#37322;&#24615;&#65292;&#24182;&#20445;&#30041;&#19982;&#22270;&#20687;&#30340;&#31354;&#38388;&#30456;&#20851;&#24615;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#20351;&#29992;&#36981;&#24490;&#29289;&#29702;&#27169;&#22411;&#30340;&#28508;&#22312;&#21464;&#37327;&#65292;&#30830;&#20445;&#20102;&#23398;&#20064;&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#22312;&#22320;&#29699;&#31185;&#23398;&#22270;&#20687;&#25968;&#25454;&#19978;&#23637;&#31034;&#20102;&#20854;&#40065;&#26834;&#24615;&#21644;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#26088;&#22312;&#23398;&#20064;&#22312;&#36830;&#32493;&#26102;&#38388;&#27493;&#39588;&#20013;&#35266;&#23519;&#21040;&#30340;&#20004;&#20010;&#22270;&#20687;&#20043;&#38388;&#30340;&#24213;&#23618;&#21160;&#24577;&#12290;&#22270;&#20687;&#25968;&#25454;&#30340;&#22797;&#26434;&#24615;&#21644;&#32570;&#20047;&#26102;&#38388;&#20449;&#24687;&#23548;&#33268;&#22312;&#25429;&#25417;&#29420;&#29305;&#30340;&#28436;&#21464;&#27169;&#24335;&#26102;&#23384;&#22312;&#37325;&#22823;&#25361;&#25112;&#12290;&#25105;&#20204;&#25552;&#20986;&#30340;&#26041;&#27861;&#19987;&#27880;&#20110;&#20272;&#35745;&#22270;&#20687;&#28436;&#21464;&#30340;&#20013;&#38388;&#38454;&#27573;&#65292;&#36890;&#36807;&#28508;&#22312;&#21160;&#24577;&#23454;&#29616;&#21487;&#35299;&#37322;&#24615;&#65292;&#21516;&#26102;&#20445;&#30041;&#19982;&#22270;&#20687;&#30340;&#31354;&#38388;&#30456;&#20851;&#24615;&#12290;&#36890;&#36807;&#23558;&#36981;&#24490;&#20559;&#24494;&#20998;&#26041;&#31243;&#65288;PDEs&#65289;&#30340;&#29289;&#29702;&#27169;&#22411;&#34920;&#36798;&#30340;&#28508;&#22312;&#21464;&#37327;&#32435;&#20837;&#25105;&#20204;&#30340;&#26041;&#27861;&#20013;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#30830;&#20445;&#20102;&#23398;&#20064;&#27169;&#22411;&#30340;&#21487;&#35299;&#37322;&#24615;&#65292;&#24182;&#25552;&#20379;&#20102;&#23545;&#24212;&#30340;&#22270;&#20687;&#21160;&#24577;&#30340;&#27934;&#23519;&#21147;&#12290;&#25105;&#20204;&#36890;&#36807;&#19968;&#31995;&#21015;&#20351;&#29992;&#22320;&#29699;&#31185;&#23398;&#22270;&#20687;&#25968;&#25454;&#30340;&#25968;&#20540;&#27979;&#35797;&#35777;&#26126;&#20102;&#25105;&#20204;&#23398;&#20064;&#26694;&#26550;&#30340;&#31283;&#20581;&#24615;&#21644;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a framework designed to learn the underlying dynamics between two images observed at consecutive time steps. The complex nature of image data and the lack of temporal information pose significant challenges in capturing the unique evolving patterns. Our proposed method focuses on estimating the intermediary stages of image evolution, allowing for interpretability through latent dynamics while preserving spatial correlations with the image. By incorporating a latent variable that follows a physical model expressed in partial differential equations (PDEs), our approach ensures the interpretability of the learned model and provides insight into corresponding image dynamics. We demonstrate the robustness and effectiveness of our learning framework through a series of numerical tests using geoscientific imagery data.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;ARM&#65292;&#19968;&#31181;&#22810;&#21464;&#37327;&#30340;&#26102;&#38388;-&#19978;&#19979;&#25991;&#33258;&#36866;&#24212;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#20248;&#21270;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#12290;ARM&#36890;&#36807;&#37319;&#29992;&#33258;&#36866;&#24212;&#21333;&#21464;&#37327;&#25928;&#24212;&#23398;&#20064;&#12289;&#38543;&#26426;&#20002;&#24323;&#35757;&#32451;&#31574;&#30053;&#21644;&#22810;&#26680;&#23616;&#37096;&#24179;&#28369;&#65292;&#33021;&#26356;&#22909;&#22320;&#22788;&#29702;&#26102;&#38388;&#27169;&#24335;&#21644;&#23398;&#20064;&#31995;&#21015;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;&#22312;&#22810;&#20010;&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;ARM&#23637;&#31034;&#20102;&#21331;&#36234;&#30340;&#24615;&#33021;&#65292;&#32780;&#35745;&#31639;&#25104;&#26412;&#30456;&#23545;&#36739;&#20302;&#12290;</title><link>http://arxiv.org/abs/2310.09488</link><description>&lt;p&gt;
&#20351;&#29992;&#33258;&#36866;&#24212;&#26102;&#38388;-&#19978;&#19979;&#25991;&#23398;&#20064;&#20248;&#21270;&#22810;&#21464;&#37327;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
ARM: Refining Multivariate Forecasting with Adaptive Temporal-Contextual Learning. (arXiv:2310.09488v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09488
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;ARM&#65292;&#19968;&#31181;&#22810;&#21464;&#37327;&#30340;&#26102;&#38388;-&#19978;&#19979;&#25991;&#33258;&#36866;&#24212;&#23398;&#20064;&#26041;&#27861;&#65292;&#29992;&#20110;&#20248;&#21270;&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#12290;ARM&#36890;&#36807;&#37319;&#29992;&#33258;&#36866;&#24212;&#21333;&#21464;&#37327;&#25928;&#24212;&#23398;&#20064;&#12289;&#38543;&#26426;&#20002;&#24323;&#35757;&#32451;&#31574;&#30053;&#21644;&#22810;&#26680;&#23616;&#37096;&#24179;&#28369;&#65292;&#33021;&#26356;&#22909;&#22320;&#22788;&#29702;&#26102;&#38388;&#27169;&#24335;&#21644;&#23398;&#20064;&#31995;&#21015;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;&#22312;&#22810;&#20010;&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;ARM&#23637;&#31034;&#20102;&#21331;&#36234;&#30340;&#24615;&#33021;&#65292;&#32780;&#35745;&#31639;&#25104;&#26412;&#30456;&#23545;&#36739;&#20302;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38271;&#26399;&#26102;&#38388;&#24207;&#21015;&#39044;&#27979;&#65288;LTSF&#65289;&#22312;&#21508;&#20010;&#39046;&#22495;&#20013;&#37117;&#24456;&#37325;&#35201;&#65292;&#20294;&#22312;&#22788;&#29702;&#22797;&#26434;&#30340;&#26102;&#38388;-&#19978;&#19979;&#25991;&#20851;&#31995;&#26041;&#38754;&#38754;&#20020;&#25361;&#25112;&#12290;&#30001;&#20110;&#22810;&#21464;&#37327;&#36755;&#20837;&#27169;&#22411;&#34920;&#29616;&#19981;&#22914;&#26368;&#36817;&#30340;&#19968;&#20123;&#21333;&#21464;&#37327;&#27169;&#22411;&#65292;&#25105;&#20204;&#35748;&#20026;&#38382;&#39064;&#22312;&#20110;&#29616;&#26377;&#30340;&#22810;&#21464;&#37327;LTSF&#21464;&#21387;&#22120;&#27169;&#22411;&#26080;&#27861;&#39640;&#25928;&#22320;&#24314;&#27169;&#31995;&#21015;&#20043;&#38388;&#30340;&#20851;&#31995;&#65306;&#24448;&#24448;&#19981;&#33021;&#27491;&#30830;&#22320;&#25429;&#25417;&#21040;&#31995;&#21015;&#20043;&#38388;&#30340;&#29305;&#24449;&#24046;&#24322;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;ARM&#65306;&#19968;&#31181;&#22810;&#21464;&#37327;&#30340;&#26102;&#38388;-&#19978;&#19979;&#25991;&#33258;&#36866;&#24212;&#23398;&#20064;&#26041;&#27861;&#65292;&#23427;&#26159;&#19987;&#38376;&#20026;&#22810;&#21464;&#37327;LTSF&#24314;&#27169;&#32780;&#35774;&#35745;&#30340;&#22686;&#24378;&#22411;&#26550;&#26500;&#12290;ARM&#37319;&#29992;&#33258;&#36866;&#24212;&#21333;&#21464;&#37327;&#25928;&#24212;&#23398;&#20064;&#65288;AUEL&#65289;&#12289;&#38543;&#26426;&#20002;&#24323;&#65288;RD&#65289;&#35757;&#32451;&#31574;&#30053;&#21644;&#22810;&#26680;&#23616;&#37096;&#24179;&#28369;&#65288;MKLS&#65289;&#26469;&#26356;&#22909;&#22320;&#22788;&#29702;&#21333;&#20010;&#31995;&#21015;&#30340;&#26102;&#38388;&#27169;&#24335;&#24182;&#27491;&#30830;&#23398;&#20064;&#31995;&#21015;&#20043;&#38388;&#30340;&#20381;&#36182;&#20851;&#31995;&#12290;ARM&#22312;&#22810;&#20010;&#22522;&#20934;&#27979;&#35797;&#19978;&#23637;&#31034;&#20102;&#21331;&#36234;&#30340;&#24615;&#33021;&#65292;&#32780;&#19982;&#29616;&#26377;&#26041;&#27861;&#30456;&#27604;&#24182;&#27809;&#26377;&#26174;&#33879;&#22686;&#21152;&#35745;&#31639;&#25104;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
Long-term time series forecasting (LTSF) is important for various domains but is confronted by challenges in handling the complex temporal-contextual relationships. As multivariate input models underperforming some recent univariate counterparts, we posit that the issue lies in the inefficiency of existing multivariate LTSF Transformers to model series-wise relationships: the characteristic differences between series are often captured incorrectly. To address this, we introduce ARM: a multivariate temporal-contextual adaptive learning method, which is an enhanced architecture specifically designed for multivariate LTSF modelling. ARM employs Adaptive Univariate Effect Learning (AUEL), Random Dropping (RD) training strategy, and Multi-kernel Local Smoothing (MKLS), to better handle individual series temporal patterns and correctly learn inter-series dependencies. ARM demonstrates superior performance on multiple benchmarks without significantly increasing computational costs compared to
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20351;&#29992;&#34892;&#21015;&#24335;&#25277;&#26679;&#36827;&#34892;&#20449;&#21495;&#37325;&#24314;&#30340;&#26041;&#27861;&#65292;&#22312;&#26377;&#38480;&#25968;&#37327;&#30340;&#38543;&#26426;&#33410;&#28857;&#35780;&#20272;&#20013;&#36817;&#20284;&#34920;&#31034;&#26041;&#21487;&#31215;&#20989;&#25968;&#65292;&#23454;&#29616;&#20102;&#24555;&#36895;&#25910;&#25947;&#21644;&#26356;&#39640;&#30340;&#36866;&#24212;&#24615;&#27491;&#21017;&#24615;&#12290;</title><link>http://arxiv.org/abs/2310.09437</link><description>&lt;p&gt;
&#20351;&#29992;&#34892;&#21015;&#24335;&#25277;&#26679;&#36827;&#34892;&#20449;&#21495;&#37325;&#24314;
&lt;/p&gt;
&lt;p&gt;
Signal reconstruction using determinantal sampling. (arXiv:2310.09437v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09437
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#20351;&#29992;&#34892;&#21015;&#24335;&#25277;&#26679;&#36827;&#34892;&#20449;&#21495;&#37325;&#24314;&#30340;&#26041;&#27861;&#65292;&#22312;&#26377;&#38480;&#25968;&#37327;&#30340;&#38543;&#26426;&#33410;&#28857;&#35780;&#20272;&#20013;&#36817;&#20284;&#34920;&#31034;&#26041;&#21487;&#31215;&#20989;&#25968;&#65292;&#23454;&#29616;&#20102;&#24555;&#36895;&#25910;&#25947;&#21644;&#26356;&#39640;&#30340;&#36866;&#24212;&#24615;&#27491;&#21017;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20174;&#38543;&#26426;&#33410;&#28857;&#30340;&#26377;&#38480;&#25968;&#37327;&#35780;&#20272;&#20013;&#36817;&#20284;&#34920;&#31034;&#19968;&#20010;&#26041;&#21487;&#31215;&#20989;&#25968;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#38543;&#26426;&#33410;&#28857;&#30340;&#36873;&#25321;&#20381;&#25454;&#26159;&#19968;&#20010;&#31934;&#24515;&#36873;&#25321;&#30340;&#20998;&#24067;&#12290;&#24403;&#20989;&#25968;&#34987;&#20551;&#35774;&#23646;&#20110;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#65288;RKHS&#65289;&#26102;&#65292;&#36825;&#23588;&#20026;&#30456;&#20851;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#23558;&#22522;&#20110;&#20004;&#31181;&#21487;&#33021;&#30340;&#33410;&#28857;&#27010;&#29575;&#20998;&#24067;&#30340;&#20960;&#20010;&#33258;&#28982;&#26377;&#38480;&#32500;&#36924;&#36817;&#26041;&#27861;&#30456;&#32467;&#21512;&#12290;&#36825;&#20123;&#27010;&#29575;&#20998;&#24067;&#19982;&#34892;&#21015;&#24335;&#28857;&#36807;&#31243;&#30456;&#20851;&#65292;&#24182;&#21033;&#29992;RKHS&#30340;&#26680;&#20989;&#25968;&#26469;&#20248;&#21270;&#22312;&#38543;&#26426;&#35774;&#35745;&#20013;&#30340;RKHS&#36866;&#24212;&#24615;&#27491;&#21017;&#24615;&#12290;&#34429;&#28982;&#20808;&#21069;&#30340;&#34892;&#21015;&#24335;&#25277;&#26679;&#24037;&#20316;&#20381;&#36182;&#20110;RKHS&#33539;&#25968;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;$L^2$&#33539;&#25968;&#19979;&#30340;&#22343;&#26041;&#20445;&#35777;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#34892;&#21015;&#24335;&#28857;&#36807;&#31243;&#21450;&#20854;&#28151;&#21512;&#20307;&#21487;&#20197;&#20135;&#29983;&#24555;&#36895;&#25910;&#25947;&#36895;&#24230;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#36824;&#25581;&#31034;&#20102;&#24403;&#20551;&#35774;&#26356;&#22810;&#30340;&#24179;&#28369;&#24615;&#26102;&#25910;&#25947;&#36895;&#24230;&#22914;&#20309;&#21464;&#21270;&#65292;&#36825;&#31181;&#29616;&#35937;&#34987;&#31216;&#20026;&#36229;&#25910;&#25947;&#12290;&#27492;&#22806;&#65292;&#34892;&#21015;&#24335;&#25277;&#26679;&#25512;&#24191;&#20102;&#20174;Christoffel&#20989;&#25968;&#36827;&#34892;i.i.d.&#25277;&#26679;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study the approximation of a square-integrable function from a finite number of evaluations on a random set of nodes according to a well-chosen distribution. This is particularly relevant when the function is assumed to belong to a reproducing kernel Hilbert space (RKHS). This work proposes to combine several natural finite-dimensional approximations based two possible probability distributions of nodes. These distributions are related to determinantal point processes, and use the kernel of the RKHS to favor RKHS-adapted regularity in the random design. While previous work on determinantal sampling relied on the RKHS norm, we prove mean-square guarantees in $L^2$ norm. We show that determinantal point processes and mixtures thereof can yield fast convergence rates. Our results also shed light on how the rate changes as more smoothness is assumed, a phenomenon known as superconvergence. Besides, determinantal sampling generalizes i.i.d. sampling from the Christoffel function which is
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#26469;&#20248;&#21270;&#29983;&#20135;&#29615;&#22659;&#20013;&#31454;&#26631;&#31574;&#30053;&#30340;&#36890;&#29992;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#20248;&#21270;&#20219;&#20309;&#21487;&#24494;&#20998;&#30340;&#22522;&#30784;&#31574;&#30053;&#65292;&#21482;&#38656;&#35201;&#20351;&#29992;&#22522;&#30784;&#31574;&#30053;&#29983;&#25104;&#30340;&#25968;&#25454;&#12290;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#20195;&#29702;&#26550;&#26500;&#65292;&#23558;&#22522;&#30784;&#31574;&#30053;&#19982;&#24378;&#21270;&#23398;&#20064;&#27169;&#22359;&#30456;&#32467;&#21512;&#12290;</title><link>http://arxiv.org/abs/2310.09426</link><description>&lt;p&gt;
&#32447;&#19979;&#24378;&#21270;&#23398;&#20064;&#29992;&#20110;&#20248;&#21270;&#29983;&#20135;&#31454;&#26631;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Offline Reinforcement Learning for Optimizing Production Bidding Policies. (arXiv:2310.09426v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09426
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#26469;&#20248;&#21270;&#29983;&#20135;&#29615;&#22659;&#20013;&#31454;&#26631;&#31574;&#30053;&#30340;&#36890;&#29992;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#20248;&#21270;&#20219;&#20309;&#21487;&#24494;&#20998;&#30340;&#22522;&#30784;&#31574;&#30053;&#65292;&#21482;&#38656;&#35201;&#20351;&#29992;&#22522;&#30784;&#31574;&#30053;&#29983;&#25104;&#30340;&#25968;&#25454;&#12290;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#28151;&#21512;&#20195;&#29702;&#26550;&#26500;&#65292;&#23558;&#22522;&#30784;&#31574;&#30053;&#19982;&#24378;&#21270;&#23398;&#20064;&#27169;&#22359;&#30456;&#32467;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32447;&#24191;&#21578;&#24066;&#22330;&#27599;&#31186;&#36827;&#34892;&#25968;&#21315;&#27425;&#25293;&#21334;&#65292;&#23545;&#20110;&#24076;&#26395;&#22312;&#39044;&#31639;&#38480;&#21046;&#19979;&#20248;&#21270;&#25903;&#20986;&#30340;&#24191;&#21578;&#21830;&#26469;&#35828;&#65292;&#36825;&#26159;&#19968;&#20010;&#33392;&#24040;&#30340;&#25361;&#25112;&#12290;&#22240;&#27492;&#65292;&#24191;&#21578;&#24179;&#21488;&#36890;&#24120;&#20026;&#20182;&#20204;&#30340;&#23458;&#25143;&#25552;&#20379;&#33258;&#21160;&#21270;&#20195;&#29702;&#20154;&#65292;&#20195;&#34920;&#20182;&#20204;&#23454;&#26102;&#22823;&#35268;&#27169;&#31454;&#26631;&#12290;&#30001;&#20110;&#36825;&#20123;&#20195;&#29702;&#20154;&#30001;&#24179;&#21488;&#25317;&#26377;&#20294;&#20351;&#29992;&#24191;&#21578;&#21830;&#30340;&#36164;&#37329;&#36827;&#34892;&#25805;&#20316;&#65292;&#22240;&#27492;&#22312;&#24179;&#34913;&#20195;&#29702;&#20154;&#30340;&#21487;&#38752;&#24615;&#21644;&#21487;&#35299;&#37322;&#24615;&#19982;&#20248;&#21270;&#24615;&#33021;&#26041;&#38754;&#23384;&#22312;&#30528;&#24378;&#28872;&#30340;&#23454;&#38469;&#38656;&#27714;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#36890;&#36807;&#31163;&#32447;&#24378;&#21270;&#23398;&#20064;&#20174;&#30495;&#23454;&#25968;&#25454;&#20013;&#23398;&#20064;&#30340;&#26041;&#27861;&#65292;&#20197;&#20248;&#21270;&#29983;&#20135;&#29615;&#22659;&#20013;&#30340;&#31454;&#26631;&#31574;&#30053;&#12290;&#36825;&#31181;&#26041;&#27861;&#21487;&#20197;&#29992;&#20110;&#20248;&#21270;&#20219;&#20309;&#21487;&#24494;&#20998;&#30340;&#22522;&#30784;&#31574;&#30053;&#65288;&#23454;&#38469;&#19978;&#26159;&#22522;&#20110;&#24191;&#21578;&#21830;&#33021;&#22815;&#36731;&#26494;&#29702;&#35299;&#30340;&#21407;&#21017;&#30340;&#21551;&#21457;&#24335;&#31574;&#30053;&#65289;&#65292;&#24182;&#19988;&#21482;&#38656;&#35201;&#30001;&#22522;&#30784;&#31574;&#30053;&#26412;&#36523;&#29983;&#25104;&#30340;&#25968;&#25454;&#12290;&#25105;&#20204;&#20351;&#29992;&#28151;&#21512;&#20195;&#29702;&#26550;&#26500;&#65292;&#23558;&#20219;&#24847;&#22522;&#30784;&#31574;&#30053;&#19982;&#24378;&#21270;&#23398;&#20064;&#27169;&#22359;&#30456;&#32467;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
The online advertising market, with its thousands of auctions run per second, presents a daunting challenge for advertisers who wish to optimize their spend under a budget constraint. Thus, advertising platforms typically provide automated agents to their customers, which act on their behalf to bid for impression opportunities in real time at scale. Because these proxy agents are owned by the platform but use advertiser funds to operate, there is a strong practical need to balance reliability and explainability of the agent with optimizing power. We propose a generalizable approach to optimizing bidding policies in production environments by learning from real data using offline reinforcement learning. This approach can be used to optimize any differentiable base policy (practically, a heuristic policy based on principles which the advertiser can easily understand), and only requires data generated by the base policy itself. We use a hybrid agent architecture that combines arbitrary ba
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#38024;&#23545;&#38543;&#26426;Metropolis-Hastings&#31639;&#27861;&#30340;&#32479;&#35745;&#20445;&#35777;&#12290;&#36890;&#36807;&#24341;&#20837;&#31616;&#21333;&#30340;&#20462;&#27491;&#39033;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#36991;&#20813;&#35745;&#31639;&#25104;&#26412;&#19978;&#30340;&#25439;&#22833;&#65292;&#24182;&#36890;&#36807;&#20998;&#26512;&#38750;&#21442;&#25968;&#22238;&#24402;&#24773;&#26223;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22238;&#24402;&#30340;&#25968;&#20540;&#23454;&#20363;&#26469;&#35777;&#26126;&#20102;&#20854;&#22312;&#37319;&#26679;&#21644;&#21487;&#20449;&#21306;&#38388;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;</title><link>http://arxiv.org/abs/2310.09335</link><description>&lt;p&gt;
&#38024;&#23545;&#38543;&#26426;Metropolis-Hastings&#31639;&#27861;&#30340;&#32479;&#35745;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Statistical guarantees for stochastic Metropolis-Hastings. (arXiv:2310.09335v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09335
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#38024;&#23545;&#38543;&#26426;Metropolis-Hastings&#31639;&#27861;&#30340;&#32479;&#35745;&#20445;&#35777;&#12290;&#36890;&#36807;&#24341;&#20837;&#31616;&#21333;&#30340;&#20462;&#27491;&#39033;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#36991;&#20813;&#35745;&#31639;&#25104;&#26412;&#19978;&#30340;&#25439;&#22833;&#65292;&#24182;&#36890;&#36807;&#20998;&#26512;&#38750;&#21442;&#25968;&#22238;&#24402;&#24773;&#26223;&#21644;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22238;&#24402;&#30340;&#25968;&#20540;&#23454;&#20363;&#26469;&#35777;&#26126;&#20102;&#20854;&#22312;&#37319;&#26679;&#21644;&#21487;&#20449;&#21306;&#38388;&#26041;&#38754;&#30340;&#20248;&#21183;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Metropolis-Hastings&#27493;&#39588;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#22522;&#20110;&#26799;&#24230;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#33945;&#29305;&#21345;&#27931;&#26041;&#27861;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#20013;&#12290;&#36890;&#36807;&#23545;&#25209;&#27425;&#35745;&#31639;&#25509;&#21463;&#27010;&#29575;&#65292;&#38543;&#26426;Metropolis-Hastings&#27493;&#39588;&#33410;&#30465;&#20102;&#35745;&#31639;&#25104;&#26412;&#65292;&#20294;&#38477;&#20302;&#20102;&#26377;&#25928;&#26679;&#26412;&#37327;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#36890;&#36807;&#31616;&#21333;&#30340;&#20462;&#27491;&#39033;&#21487;&#20197;&#36991;&#20813;&#36825;&#20010;&#38556;&#30861;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;&#22914;&#26524;&#22312;&#38750;&#21442;&#25968;&#22238;&#24402;&#35774;&#32622;&#20013;&#24212;&#29992;&#25913;&#36827;&#30340;&#38543;&#26426;Metropolis-Hastings&#26041;&#27861;&#20174;Gibbs&#21518;&#39564;&#20998;&#24067;&#20013;&#37319;&#26679;&#65292;&#21017;&#38142;&#30340;&#32467;&#26524;&#31283;&#24577;&#20998;&#24067;&#30340;&#32479;&#35745;&#23646;&#24615;&#12290;&#38024;&#23545;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#22238;&#24402;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;PAC-Bayes&#39044;&#35328;&#19981;&#31561;&#24335;&#65292;&#23427;&#25552;&#20379;&#20102;&#26368;&#20248;&#30340;&#25910;&#32553;&#36895;&#29575;&#65292;&#24182;&#20998;&#26512;&#20102;&#32467;&#26524;&#21487;&#20449;&#21306;&#38388;&#30340;&#30452;&#24452;&#21644;&#39640;&#32622;&#20449;&#27010;&#29575;&#12290;&#36890;&#36807;&#22312;&#39640;&#32500;&#21442;&#25968;&#31354;&#38388;&#20013;&#30340;&#25968;&#20540;&#23454;&#20363;&#65292;&#25105;&#20204;&#35828;&#26126;&#20102;&#38543;&#26426;Metropolis-Hastings&#31639;&#27861;&#30340;&#21487;&#20449;&#21306;&#38388;&#21644;&#25910;&#32553;&#36895;&#29575;&#30830;&#23454;&#34920;&#29616;&#20986;&#31867;&#20284;&#30340;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;
A Metropolis-Hastings step is widely used for gradient-based Markov chain Monte Carlo methods in uncertainty quantification. By calculating acceptance probabilities on batches, a stochastic Metropolis-Hastings step saves computational costs, but reduces the effective sample size. We show that this obstacle can be avoided by a simple correction term. We study statistical properties of the resulting stationary distribution of the chain if the corrected stochastic Metropolis-Hastings approach is applied to sample from a Gibbs posterior distribution in a nonparametric regression setting. Focusing on deep neural network regression, we prove a PAC-Bayes oracle inequality which yields optimal contraction rates and we analyze the diameter and show high coverage probability of the resulting credible sets. With a numerical example in a high-dimensional parameter space, we illustrate that credible sets and contraction rates of the stochastic Metropolis-Hastings algorithm indeed behave similar to 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#29983;&#25104;&#29109;&#31070;&#32463;&#26368;&#20248;&#20256;&#36755;&#22312;&#27979;&#24230;&#21040;&#27979;&#24230;&#26144;&#23556;&#20013;&#30340;&#24212;&#29992;&#65292;&#35299;&#20915;&#20102;&#22788;&#29702;&#38750;&#24179;&#26041;&#27431;&#27663;&#36317;&#31163;&#25104;&#26412;&#12289;&#30830;&#23450;&#24615;&#33945;&#26684;&#26144;&#23556;&#12289;&#26144;&#23556;&#36328;&#19981;&#21487;&#27604;&#36739;&#31354;&#38388;&#21644;&#36136;&#37327;&#23432;&#24658;&#32422;&#26463;&#31561;&#23454;&#38469;&#25361;&#25112;&#12290;</title><link>http://arxiv.org/abs/2310.09254</link><description>&lt;p&gt;
&#29983;&#25104;&#29109;&#31070;&#32463;&#26368;&#20248;&#20256;&#36755;&#22312;&#31354;&#38388;&#20869;&#22806;&#26144;&#23556;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Generative Entropic Neural Optimal Transport To Map Within and Across Spaces. (arXiv:2310.09254v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09254
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#29983;&#25104;&#29109;&#31070;&#32463;&#26368;&#20248;&#20256;&#36755;&#22312;&#27979;&#24230;&#21040;&#27979;&#24230;&#26144;&#23556;&#20013;&#30340;&#24212;&#29992;&#65292;&#35299;&#20915;&#20102;&#22788;&#29702;&#38750;&#24179;&#26041;&#27431;&#27663;&#36317;&#31163;&#25104;&#26412;&#12289;&#30830;&#23450;&#24615;&#33945;&#26684;&#26144;&#23556;&#12289;&#26144;&#23556;&#36328;&#19981;&#21487;&#27604;&#36739;&#31354;&#38388;&#21644;&#36136;&#37327;&#23432;&#24658;&#32422;&#26463;&#31561;&#23454;&#38469;&#25361;&#25112;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23398;&#20064;&#27979;&#24230;&#21040;&#27979;&#24230;&#30340;&#26144;&#23556;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#20851;&#38190;&#20219;&#21153;&#65292;&#23588;&#20854;&#22312;&#29983;&#25104;&#24314;&#27169;&#20013;&#21344;&#25454;&#37325;&#35201;&#22320;&#20301;&#12290;&#36817;&#24180;&#26469;&#65292;&#21463;&#26368;&#20248;&#20256;&#36755;&#29702;&#35770;&#21551;&#21457;&#30340;&#25216;&#26415;&#19981;&#26029;&#28044;&#29616;&#12290;&#32467;&#21512;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#65292;&#36825;&#20123;&#26041;&#27861;&#32479;&#31216;&#20026;"&#31070;&#32463;&#26368;&#20248;&#20256;&#36755;"&#65292;&#23558;&#26368;&#20248;&#20256;&#36755;&#20316;&#20026;&#24402;&#32435;&#20559;&#22909;&#65306;&#36825;&#20123;&#26144;&#23556;&#24212;&#35813;&#38024;&#23545;&#32473;&#23450;&#30340;&#25104;&#26412;&#20989;&#25968;&#26159;&#26368;&#20248;&#30340;&#65292;&#33021;&#20197;&#33410;&#32422;&#30340;&#26041;&#24335;&#65288;&#36890;&#36807;&#26368;&#23567;&#21270;&#20301;&#31227;&#65289;&#22312;&#31354;&#38388;&#20869;&#25110;&#31354;&#38388;&#38388;&#31227;&#21160;&#28857;&#12290;&#36825;&#19968;&#21407;&#21017;&#22312;&#30452;&#35266;&#19978;&#26159;&#21512;&#29702;&#30340;&#65292;&#20294;&#24448;&#24448;&#38754;&#20020;&#20960;&#20010;&#23454;&#38469;&#25361;&#25112;&#65292;&#38656;&#35201;&#35843;&#25972;&#26368;&#20248;&#20256;&#36755;&#24037;&#20855;&#31665;&#65306;&#22788;&#29702;&#20854;&#20182;&#38750;&#24179;&#26041;&#27431;&#27663;&#36317;&#31163;&#25104;&#26412;&#30340;&#25361;&#25112;&#65292;&#30830;&#23450;&#24615;&#29366;&#20917;&#19979;&#30340;&#33945;&#26684;&#26144;&#23556;&#20844;&#24335;&#20250;&#38480;&#21046;&#28789;&#27963;&#24615;&#65292;&#26144;&#23556;&#22312;&#19981;&#21487;&#27604;&#36739;&#30340;&#31354;&#38388;&#20013;&#20250;&#24102;&#26469;&#22810;&#20010;&#25361;&#25112;&#65292;&#26368;&#20248;&#20256;&#36755;&#22266;&#26377;&#30340;&#36136;&#37327;&#23432;&#24658;&#32422;&#26463;&#21487;&#33021;&#23545;&#24322;&#24120;&#25968;&#25454;&#32473;&#20104;&#36807;&#22810;&#30340;&#37325;&#35270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Learning measure-to-measure mappings is a crucial task in machine learning, featured prominently in generative modeling. Recent years have witnessed a surge of techniques that draw inspiration from optimal transport (OT) theory. Combined with neural network models, these methods collectively known as \textit{Neural OT} use optimal transport as an inductive bias: such mappings should be optimal w.r.t. a given cost function, in the sense that they are able to move points in a thrifty way, within (by minimizing displacements) or across spaces (by being isometric). This principle, while intuitive, is often confronted with several practical challenges that require adapting the OT toolbox: cost functions other than the squared-Euclidean cost can be challenging to handle, the deterministic formulation of Monge maps leaves little flexibility, mapping across incomparable spaces raises multiple challenges, while the mass conservation constraint inherent to OT can provide too much credit to outli
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#21487;&#20998;&#35299;&#27169;&#22411;&#20043;&#38388;&#36793;&#38469;&#21644;&#26465;&#20214;&#24046;&#24322;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#39640;&#32500;&#20998;&#24067;&#20013;&#31934;&#30830;&#35745;&#31639;&#24046;&#24322;&#65292;&#20855;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2310.09129</link><description>&lt;p&gt;
&#35745;&#31639;&#21487;&#20998;&#35299;&#27169;&#22411;&#20043;&#38388;&#30340;&#36793;&#38469;&#21644;&#26465;&#20214;&#24046;&#24322;&#21450;&#20854;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Computing Marginal and Conditional Divergences between Decomposable Models with Applications. (arXiv:2310.09129v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.09129
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#35745;&#31639;&#21487;&#20998;&#35299;&#27169;&#22411;&#20043;&#38388;&#36793;&#38469;&#21644;&#26465;&#20214;&#24046;&#24322;&#30340;&#26041;&#27861;&#65292;&#33021;&#22815;&#22312;&#39640;&#32500;&#20998;&#24067;&#20013;&#31934;&#30830;&#35745;&#31639;&#24046;&#24322;&#65292;&#20855;&#26377;&#24191;&#27867;&#30340;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#35768;&#22810;&#24212;&#29992;&#20013;&#65292;&#35745;&#31639;&#20004;&#20010;&#39640;&#32500;&#20998;&#24067;&#20043;&#38388;&#30340;&#31934;&#30830;&#24046;&#24322;&#26159;&#26377;&#29992;&#30340;&#65292;&#20294;&#30452;&#25509;&#35745;&#31639;&#26159;&#19981;&#21487;&#34892;&#30340;&#12290;&#23545;&#20110;&#20004;&#20010;&#21487;&#20998;&#35299;&#27169;&#22411;&#65288;&#21363;&#24358;&#22270;&#39532;&#23572;&#21487;&#22827;&#32593;&#32476;&#65289;&#30340;&#32852;&#21512;&#20998;&#24067;&#35745;&#31639;&#945;-&#946;&#24046;&#24322;&#65288;&#21253;&#25324;Kullback-Leibler&#24046;&#24322;&#21644;Hellinger&#36317;&#31163;&#65289;&#21487;&#20197;&#22312;&#25351;&#25968;&#26102;&#38388;&#20869;&#25104;&#20026;&#36825;&#20123;&#27169;&#22411;&#30340;&#26641;&#23485;&#24230;&#12290;&#28982;&#32780;&#65292;&#23558;&#20004;&#20010;&#39640;&#32500;&#23545;&#35937;&#20043;&#38388;&#30340;&#19981;&#30456;&#20284;&#24615;&#20943;&#23569;&#20026;&#21333;&#20010;&#26631;&#37327;&#20540;&#21487;&#33021;&#26159;&#19981;&#20855;&#26377;&#20449;&#24687;&#24615;&#30340;&#12290;&#27492;&#22806;&#65292;&#22312;&#35832;&#22914;&#30417;&#30563;&#23398;&#20064;&#30340;&#24212;&#29992;&#20013;&#65292;&#23545;&#20110;&#26465;&#20214;&#20998;&#24067;&#30340;&#24046;&#24322;&#21487;&#33021;&#26356;&#26377;&#20852;&#36259;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#35745;&#31639;&#20004;&#20010;&#21487;&#20998;&#35299;&#27169;&#22411;&#30340;&#20219;&#20309;&#36793;&#38469;&#25110;&#26465;&#20214;&#20998;&#24067;&#20043;&#38388;&#30340;&#31934;&#30830;&#945;-&#946;&#24046;&#24322;&#12290;&#20197;&#21487;&#34892;&#30340;&#26041;&#24335;&#36827;&#34892;&#27492;&#35745;&#31639;&#26159;&#38750;&#24179;&#20961;&#30340;&#65292;&#22240;&#20026;&#25105;&#20204;&#38656;&#35201;&#23545;&#36825;&#20123;&#20998;&#24067;&#20043;&#38388;&#30340;&#24046;&#24322;&#36827;&#34892;&#20998;&#35299;&#65292;&#22240;&#27492;&#38656;&#35201;&#23545;&#26465;&#20214;&#20998;&#24067;&#36827;&#34892;&#20998;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
The ability to compute the exact divergence between two high-dimensional distributions is useful in many applications but doing so naively is intractable. Computing the alpha-beta divergence -- a family of divergences that includes the Kullback-Leibler divergence and Hellinger distance -- between the joint distribution of two decomposable models, i.e chordal Markov networks, can be done in time exponential in the treewidth of these models. However, reducing the dissimilarity between two high-dimensional objects to a single scalar value can be uninformative. Furthermore, in applications such as supervised learning, the divergence over a conditional distribution might be of more interest. Therefore, we propose an approach to compute the exact alpha-beta divergence between any marginal or conditional distribution of two decomposable models. Doing so tractably is non-trivial as we need to decompose the divergence between these distributions and therefore, require a decomposition over the m
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#26368;&#20248;&#36755;&#36816;&#26469;&#34701;&#21512;&#22522;&#20110;Transformer&#30340;&#32593;&#32476;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#23545;&#40784;&#21508;&#31181;&#26550;&#26500;&#32452;&#20214;&#24182;&#20801;&#35768;&#19981;&#21516;&#22823;&#23567;&#30340;&#27169;&#22411;&#30340;&#34701;&#21512;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#39640;&#25928;&#21387;&#32553;Transformer&#30340;&#26041;&#24335;&#12290;</title><link>http://arxiv.org/abs/2310.05719</link><description>&lt;p&gt;
&#20351;&#29992;&#26368;&#20248;&#36755;&#36816;&#22120;&#21512;&#24182;Transformer
&lt;/p&gt;
&lt;p&gt;
Transformer Fusion with Optimal Transport. (arXiv:2310.05719v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2310.05719
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#20351;&#29992;&#26368;&#20248;&#36755;&#36816;&#26469;&#34701;&#21512;&#22522;&#20110;Transformer&#30340;&#32593;&#32476;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#23545;&#40784;&#21508;&#31181;&#26550;&#26500;&#32452;&#20214;&#24182;&#20801;&#35768;&#19981;&#21516;&#22823;&#23567;&#30340;&#27169;&#22411;&#30340;&#34701;&#21512;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#39640;&#25928;&#21387;&#32553;Transformer&#30340;&#26041;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34701;&#21512;&#26159;&#19968;&#31181;&#23558;&#22810;&#20010;&#29420;&#31435;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#21512;&#24182;&#20197;&#32467;&#21512;&#23427;&#20204;&#30340;&#33021;&#21147;&#30340;&#25216;&#26415;&#12290;&#36807;&#21435;&#30340;&#23581;&#35797;&#20165;&#38480;&#20110;&#20840;&#36830;&#25509;&#12289;&#21367;&#31215;&#21644;&#27531;&#24046;&#32593;&#32476;&#30340;&#24773;&#20917;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#31995;&#32479;&#30340;&#26041;&#27861;&#65292;&#21033;&#29992;&#26368;&#20248;&#36755;&#36816;&#26469;&#34701;&#21512;&#20004;&#20010;&#25110;&#22810;&#20010;&#22522;&#20110;Transformer&#30340;&#32593;&#32476;&#65292;&#20197;&#65288;&#36719;&#65289;&#23545;&#40784;&#21508;&#31181;&#26550;&#26500;&#32452;&#20214;&#12290;&#25105;&#20204;&#35814;&#32454;&#25551;&#36848;&#20102;&#19968;&#31181;&#23618;&#23545;&#40784;&#30340;&#25277;&#35937;&#26041;&#27861;&#65292;&#21487;&#20197;&#25512;&#24191;&#21040;&#20219;&#24847;&#26550;&#26500;&#65292;&#20363;&#22914;&#22810;&#22836;&#33258;&#27880;&#24847;&#21147;&#12289;&#23618;&#24402;&#19968;&#21270;&#21644;&#27531;&#24046;&#36830;&#25509;&#12290;&#25105;&#20204;&#36890;&#36807;&#21508;&#31181;&#28040;&#34701;&#30740;&#31350;&#35752;&#35770;&#20102;&#22914;&#20309;&#22788;&#29702;&#36825;&#20123;&#26550;&#26500;&#32452;&#20214;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#20801;&#35768;&#19981;&#21516;&#22823;&#23567;&#30340;&#27169;&#22411;&#36827;&#34892;&#34701;&#21512;&#65288;&#24322;&#26500;&#34701;&#21512;&#65289;&#65292;&#20026;Transformer&#30340;&#21387;&#32553;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#39640;&#25928;&#26041;&#27861;&#12290;&#25105;&#20204;&#36890;&#36807;Vision Transformer&#36827;&#34892;&#22270;&#20687;&#20998;&#31867;&#20219;&#21153;&#20197;&#21450;&#33258;&#28982;&#35821;&#35328;
&lt;/p&gt;
&lt;p&gt;
Fusion is a technique for merging multiple independently-trained neural networks in order to combine their capabilities. Past attempts have been restricted to the case of fully-connected, convolutional, and residual networks. In this paper, we present a systematic approach for fusing two or more transformer-based networks exploiting Optimal Transport to (soft-)align the various architectural components. We flesh out an abstraction for layer alignment, that can generalize to arbitrary architectures -- in principle -and we apply this to the key ingredients of Transformers such as multi-head self-attention, layer-normalization, and residual connections, and we discuss how to handle them via various ablation studies. Furthermore, our method allows the fusion of models of different sizes (heterogeneous fusion), providing a new and efficient way for compression of Transformers. The proposed approach is evaluated on both image classification tasks via Vision Transformer and natural language
&lt;/p&gt;</description></item><item><title>&#22810;&#37325;&#27835;&#30103;&#21644;&#22810;&#20010;&#32467;&#26524;&#30340;&#24182;&#34892;&#30740;&#31350;&#22312;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#20013;&#21487;&#20197;&#20114;&#30456;&#21327;&#21161;&#23454;&#29616;&#22240;&#26524;&#35782;&#21035;&#12290;</title><link>http://arxiv.org/abs/2309.17283</link><description>&lt;p&gt;
&#22810;&#37325;&#27835;&#30103;&#21644;&#22810;&#20010;&#32467;&#26524;&#22312;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#20013;&#30340;&#30410;&#22788;
&lt;/p&gt;
&lt;p&gt;
The Blessings of Multiple Treatments and Outcomes in Treatment Effect Estimation. (arXiv:2309.17283v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.17283
&lt;/p&gt;
&lt;p&gt;
&#22810;&#37325;&#27835;&#30103;&#21644;&#22810;&#20010;&#32467;&#26524;&#30340;&#24182;&#34892;&#30740;&#31350;&#22312;&#27835;&#30103;&#25928;&#26524;&#20272;&#35745;&#20013;&#21487;&#20197;&#20114;&#30456;&#21327;&#21161;&#23454;&#29616;&#22240;&#26524;&#35782;&#21035;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23384;&#22312;&#26410;&#35266;&#27979;&#28151;&#26434;&#30340;&#24773;&#20917;&#19979;&#35780;&#20272;&#22240;&#26524;&#25928;&#24212;&#26159;&#19968;&#20010;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#38382;&#39064;&#12290;&#29616;&#26377;&#30740;&#31350;&#21033;&#29992;&#20195;&#29702;&#21464;&#37327;&#25110;&#22810;&#37325;&#27835;&#30103;&#26469;&#35843;&#25972;&#28151;&#26434;&#20559;&#24046;&#12290;&#23588;&#20854;&#26159;&#21518;&#19968;&#31181;&#26041;&#27861;&#23558;&#21333;&#19968;&#32467;&#26524;&#30340;&#24433;&#21709;&#24402;&#22240;&#20110;&#22810;&#37325;&#27835;&#30103;&#65292;&#21487;&#20197;&#20272;&#35745;&#28151;&#26434;&#25511;&#21046;&#30340;&#28508;&#22312;&#21464;&#37327;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#26041;&#27861;&#20027;&#35201;&#20851;&#27880;&#21333;&#19968;&#32467;&#26524;&#65292;&#32780;&#22312;&#35768;&#22810;&#23454;&#38469;&#22330;&#26223;&#20013;&#65292;&#26356;&#24863;&#20852;&#36259;&#30340;&#26159;&#30740;&#31350;&#23545;&#22810;&#20010;&#32467;&#26524;&#30340;&#24433;&#21709;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#32467;&#26524;&#36890;&#24120;&#19982;&#22810;&#20010;&#27835;&#30103;&#30456;&#20851;&#12290;&#20363;&#22914;&#65292;&#37325;&#30151;&#30417;&#25252;&#30149;&#25151;&#65288;ICU&#65289;&#20013;&#65292;&#21307;&#30103;&#25552;&#20379;&#32773;&#35780;&#20272;&#27835;&#30103;&#23545;&#22810;&#20010;&#20581;&#24247;&#25351;&#26631;&#30340;&#26377;&#25928;&#24615;&#12290;&#20026;&#20102;&#36866;&#24212;&#36825;&#20123;&#22330;&#26223;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;&#19968;&#20010;&#26032;&#30340;&#35774;&#32622;&#65292;&#21363;&#22810;&#37325;&#27835;&#30103;&#21644;&#22810;&#20010;&#32467;&#26524;&#12290;&#28982;&#21518;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#36825;&#31181;&#35774;&#32622;&#20013;&#28041;&#21450;&#22810;&#20010;&#32467;&#26524;&#30340;&#24182;&#34892;&#30740;&#31350;&#21487;&#20197;&#20114;&#30456;&#21327;&#21161;&#23454;&#29616;&#22240;&#26524;&#35782;&#21035;&#65292;&#21363;
&lt;/p&gt;
&lt;p&gt;
Assessing causal effects in the presence of unobserved confounding is a challenging problem. Existing studies leveraged proxy variables or multiple treatments to adjust for the confounding bias. In particular, the latter approach attributes the impact on a single outcome to multiple treatments, allowing estimating latent variables for confounding control. Nevertheless, these methods primarily focus on a single outcome, whereas in many real-world scenarios, there is greater interest in studying the effects on multiple outcomes. Besides, these outcomes are often coupled with multiple treatments. Examples include the intensive care unit (ICU), where health providers evaluate the effectiveness of therapies on multiple health indicators. To accommodate these scenarios, we consider a new setting dubbed as multiple treatments and multiple outcomes. We then show that parallel studies of multiple outcomes involved in this setting can assist each other in causal identification, in the sense that
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#26377;&#30028;&#26356;&#26032;&#30340;&#36845;&#20195;&#23398;&#20064;&#31639;&#27861;&#22312;&#38750;&#20984;&#25439;&#22833;&#20989;&#25968;&#19978;&#30340;&#27867;&#21270;&#29305;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#65292;&#21033;&#29992;&#20102;&#20449;&#24687;&#35770;&#25216;&#26415;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#27169;&#22411;&#32500;&#24230;&#21644;&#35757;&#32451;&#25968;&#25454;&#26679;&#26412;&#25968;&#37327;&#30456;&#31561;&#30340;&#24773;&#20917;&#19979;&#65292;&#30028;&#38480;&#24471;&#21040;&#20102;&#25913;&#21892;&#12290;</title><link>http://arxiv.org/abs/2309.05077</link><description>&lt;p&gt;
&#20855;&#26377;&#26377;&#30028;&#26356;&#26032;&#30340;&#36845;&#20195;&#23398;&#20064;&#31639;&#27861;&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Generalization error bounds for iterative learning algorithms with bounded updates. (arXiv:2309.05077v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2309.05077
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20855;&#26377;&#26377;&#30028;&#26356;&#26032;&#30340;&#36845;&#20195;&#23398;&#20064;&#31639;&#27861;&#22312;&#38750;&#20984;&#25439;&#22833;&#20989;&#25968;&#19978;&#30340;&#27867;&#21270;&#29305;&#24615;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#65292;&#21033;&#29992;&#20102;&#20449;&#24687;&#35770;&#25216;&#26415;&#12290;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#27169;&#22411;&#32500;&#24230;&#21644;&#35757;&#32451;&#25968;&#25454;&#26679;&#26412;&#25968;&#37327;&#30456;&#31561;&#30340;&#24773;&#20917;&#19979;&#65292;&#30028;&#38480;&#24471;&#21040;&#20102;&#25913;&#21892;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25506;&#35752;&#20102;&#20855;&#26377;&#26377;&#30028;&#26356;&#26032;&#30340;&#36845;&#20195;&#23398;&#20064;&#31639;&#27861;&#22312;&#38750;&#20984;&#25439;&#22833;&#20989;&#25968;&#19978;&#30340;&#27867;&#21270;&#29305;&#24615;&#65292;&#37319;&#29992;&#20102;&#20449;&#24687;&#35770;&#25216;&#26415;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#38024;&#23545;&#20855;&#26377;&#26377;&#30028;&#26356;&#26032;&#30340;&#31639;&#27861;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#27867;&#21270;&#35823;&#24046;&#30028;&#38480;&#65292;&#36229;&#20986;&#20102;&#20197;&#21069;&#21482;&#20851;&#27880;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#30340;&#33539;&#22260;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#24341;&#20837;&#20102;&#20004;&#20010;&#20027;&#35201;&#30340;&#21019;&#26032;&#20043;&#22788;&#65306;1&#65289;&#25105;&#20204;&#23558;&#20114;&#20449;&#24687;&#37325;&#26032;&#23450;&#20041;&#20026;&#26356;&#26032;&#30340;&#19981;&#30830;&#23450;&#24615;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#35270;&#35282;&#65307;2&#65289;&#25105;&#20204;&#19981;&#20351;&#29992;&#20114;&#20449;&#24687;&#30340;&#38142;&#24335;&#27861;&#21017;&#65292;&#32780;&#26159;&#37319;&#29992;&#26041;&#24046;&#20998;&#35299;&#25216;&#26415;&#26469;&#23558;&#20449;&#24687;&#20998;&#35299;&#21040;&#36845;&#20195;&#20013;&#65292;&#20174;&#32780;&#20801;&#35768;&#31616;&#21270;&#30340;&#20195;&#29702;&#36807;&#31243;&#12290;&#25105;&#20204;&#22312;&#21508;&#31181;&#35774;&#32622;&#19979;&#20998;&#26512;&#20102;&#25105;&#20204;&#30340;&#27867;&#21270;&#30028;&#38480;&#65292;&#24182;&#22312;&#27169;&#22411;&#32500;&#24230;&#20197;&#19982;&#35757;&#32451;&#25968;&#25454;&#26679;&#26412;&#25968;&#37327;&#30456;&#21516;&#30340;&#36895;&#29575;&#22686;&#21152;&#26102;&#23637;&#31034;&#20102;&#25913;&#36827;&#30340;&#30028;&#38480;&#12290;&#20026;&#20102;&#24357;&#21512;&#29702;&#35770;&#19982;&#23454;&#36341;&#20043;&#38388;&#30340;&#24046;&#36317;&#65292;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;&#20808;&#21069;&#35266;&#23519;&#21040;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper explores the generalization characteristics of iterative learning algorithms with bounded updates for non-convex loss functions, employing information-theoretic techniques. Our key contribution is a novel bound for the generalization error of these algorithms with bounded updates, extending beyond the scope of previous works that only focused on Stochastic Gradient Descent (SGD). Our approach introduces two main novelties: 1) we reformulate the mutual information as the uncertainty of updates, providing a new perspective, and 2) instead of using the chaining rule of mutual information, we employ a variance decomposition technique to decompose information across iterations, allowing for a simpler surrogate process. We analyze our generalization bound under various settings and demonstrate improved bounds when the model dimension increases at the same rate as the number of training data samples. To bridge the gap between theory and practice, we also examine the previously obse
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30456;&#20851;&#24615;&#30340;&#27169;&#31946;&#32858;&#31867;&#26377;&#25928;&#24615;&#25351;&#26631;&#65292;&#35813;&#25351;&#26631;&#32771;&#34385;&#20102;&#22312;&#32858;&#31867;&#25968;&#37327;&#36873;&#25321;&#26102;&#21487;&#33021;&#23384;&#22312;&#30340;&#22810;&#20010;&#36873;&#39033;&#65292;&#24182;&#36890;&#36807;&#35780;&#20272;&#22312;&#22810;&#31181;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#65292;&#19982;&#29616;&#26377;&#25351;&#26631;&#36827;&#34892;&#27604;&#36739;&#12290;</title><link>http://arxiv.org/abs/2308.14785</link><description>&lt;p&gt;
&#22522;&#20110;&#30456;&#20851;&#24615;&#30340;&#27169;&#31946;&#32858;&#31867;&#26377;&#25928;&#24615;&#25351;&#26631;&#19982;&#27425;&#35201;&#36873;&#39033;&#26816;&#27979;&#22120;
&lt;/p&gt;
&lt;p&gt;
A correlation-based fuzzy cluster validity index with secondary options detector. (arXiv:2308.14785v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.14785
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#30456;&#20851;&#24615;&#30340;&#27169;&#31946;&#32858;&#31867;&#26377;&#25928;&#24615;&#25351;&#26631;&#65292;&#35813;&#25351;&#26631;&#32771;&#34385;&#20102;&#22312;&#32858;&#31867;&#25968;&#37327;&#36873;&#25321;&#26102;&#21487;&#33021;&#23384;&#22312;&#30340;&#22810;&#20010;&#36873;&#39033;&#65292;&#24182;&#36890;&#36807;&#35780;&#20272;&#22312;&#22810;&#31181;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#65292;&#19982;&#29616;&#26377;&#25351;&#26631;&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24212;&#29992;&#32858;&#31867;&#20998;&#26512;&#26102;&#65292;&#26368;&#20339;&#32858;&#31867;&#25968;&#37327;&#26159;&#20027;&#35201;&#20851;&#27880;&#28857;&#20043;&#19968;&#12290;&#24050;&#32463;&#24341;&#20837;&#20102;&#22810;&#20010;&#32858;&#31867;&#26377;&#25928;&#24615;&#25351;&#26631;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#65292;&#26377;&#22810;&#20010;&#36873;&#39033;&#21487;&#20197;&#20316;&#20026;&#26368;&#32456;&#30340;&#32858;&#31867;&#25968;&#37327;&#12290;&#22823;&#22810;&#25968;&#29616;&#26377;&#24037;&#20316;&#22312;&#36825;&#20010;&#39046;&#22495;&#24573;&#35270;&#20102;&#36825;&#19968;&#26041;&#38754;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22522;&#20110;&#30456;&#20851;&#24615;&#30340;&#27169;&#31946;&#32858;&#31867;&#26377;&#25928;&#24615;&#25351;&#26631;&#65292;&#31216;&#20026;Wiroonsri-Preedasawakul&#65288;WP&#65289;&#25351;&#26631;&#12290;&#35813;&#25351;&#26631;&#26681;&#25454;&#19968;&#23545;&#25968;&#25454;&#28857;&#30340;&#23454;&#38469;&#36317;&#31163;&#19982;&#30456;&#24212;&#23545;&#30340;&#35843;&#25972;&#36136;&#24515;&#20043;&#38388;&#30340;&#36317;&#31163;&#20043;&#38388;&#30340;&#30456;&#20851;&#24615;&#26469;&#23450;&#20041;&#12290;&#25105;&#20204;&#35780;&#20272;&#24182;&#27604;&#36739;&#20102;&#25105;&#20204;&#30340;&#25351;&#26631;&#19982;Xie-Beni&#65292;Pakhira-Bandyopadhyay-Maulik&#65292;Tang&#65292;Wu-Li&#65292;&#24191;&#20041;C&#21644;Kwon2&#31561;&#20960;&#20010;&#29616;&#26377;&#25351;&#26631;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#22312;&#22235;&#31181;&#31867;&#22411;&#30340;&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#20102;&#35780;&#20272;&#65306;&#20154;&#24037;&#25968;&#25454;&#38598;&#65292;&#29616;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#65292;&#24102;&#26377;&#31561;&#32423;&#30340;&#27169;&#25311;&#25968;&#25454;&#38598;&#21644;&#22270;&#20687;&#25968;&#25454;&#38598;&#65292;&#20351;&#29992;&#27169;&#31946;c-mea&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The optimal number of clusters is one of the main concerns when applying cluster analysis. Several cluster validity indexes have been introduced to address this problem. However, in some situations, there is more than one option that can be chosen as the final number of clusters. This aspect has been overlooked by most of the existing works in this area. In this study, we introduce a correlation-based fuzzy cluster validity index known as the Wiroonsri-Preedasawakul (WP) index. This index is defined based on the correlation between the actual distance between a pair of data points and the distance between adjusted centroids with respect to that pair. We evaluate and compare the performance of our index with several existing indexes, including Xie-Beni, Pakhira-Bandyopadhyay-Maulik, Tang, Wu-Li, generalized C, and Kwon2. We conduct this evaluation on four types of datasets: artificial datasets, real-world datasets, simulated datasets with ranks, and image datasets, using the fuzzy c-mea
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22270;&#19978;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#25910;&#25947;&#24615;&#12290;&#36890;&#36807;&#30740;&#31350;&#27431;&#20960;&#37324;&#24503;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#21644;Metropolis MCMC&#31639;&#27861;&#30340;&#25913;&#36827;&#29256;&#26412;&#22312;&#22270;&#19978;&#30340;&#34920;&#29616;&#65292;&#25105;&#20204;&#24471;&#20986;&#20102;&#38543;&#30528;&#22270;&#22823;&#23567;&#36235;&#36817;&#20110;&#26080;&#31351;&#22823;&#65292;&#38543;&#26426;&#36807;&#31243;&#30340;&#36712;&#36857;&#20250;&#25910;&#25947;&#21040;&#30830;&#23450;&#24615;&#26497;&#38480;&#30340;&#32467;&#35770;&#12290;&#36825;&#20123;&#26497;&#38480;&#26159;&#27979;&#24230;&#20540;&#22270;&#19978;&#30340;&#26354;&#32447;&#65292;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#24230;&#37327;&#65292;&#22312;&#36825;&#20010;&#31354;&#38388;&#20013;&#25552;&#20379;&#20102;&#33258;&#28982;&#30340;&#25910;&#25947;&#27010;&#24565;&#12290;</title><link>http://arxiv.org/abs/2308.09214</link><description>&lt;p&gt;
&#22823;&#22270;&#19978;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#36335;&#24452;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Path convergence of Markov chains on large graphs. (arXiv:2308.09214v1 [math.PR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.09214
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22823;&#22270;&#19978;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#25910;&#25947;&#24615;&#12290;&#36890;&#36807;&#30740;&#31350;&#27431;&#20960;&#37324;&#24503;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#21644;Metropolis MCMC&#31639;&#27861;&#30340;&#25913;&#36827;&#29256;&#26412;&#22312;&#22270;&#19978;&#30340;&#34920;&#29616;&#65292;&#25105;&#20204;&#24471;&#20986;&#20102;&#38543;&#30528;&#22270;&#22823;&#23567;&#36235;&#36817;&#20110;&#26080;&#31351;&#22823;&#65292;&#38543;&#26426;&#36807;&#31243;&#30340;&#36712;&#36857;&#20250;&#25910;&#25947;&#21040;&#30830;&#23450;&#24615;&#26497;&#38480;&#30340;&#32467;&#35770;&#12290;&#36825;&#20123;&#26497;&#38480;&#26159;&#27979;&#24230;&#20540;&#22270;&#19978;&#30340;&#26354;&#32447;&#65292;&#36890;&#36807;&#24341;&#20837;&#26032;&#30340;&#24230;&#37327;&#65292;&#22312;&#36825;&#20010;&#31354;&#38388;&#20013;&#25552;&#20379;&#20102;&#33258;&#28982;&#30340;&#25910;&#25947;&#27010;&#24565;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#26377;&#38480;&#26080;&#26631;&#24230;&#22270;&#19978;&#30340;&#20004;&#31867;&#33258;&#28982;&#38543;&#26426;&#36807;&#31243;&#12290;&#36825;&#20123;&#36807;&#31243;&#21253;&#25324;&#22312;&#21152;&#26435;&#22270;&#30340;&#37051;&#25509;&#30697;&#38453;&#19978;&#30340;&#27431;&#20960;&#37324;&#24503;&#38543;&#26426;&#20248;&#21270;&#31639;&#27861;&#20197;&#21450;&#22312;&#26080;&#26435;&#22270;&#19978;&#30340;Metropolis MCMC&#31639;&#27861;&#30340;&#25913;&#36827;&#29256;&#26412;&#12290;&#22312;&#36825;&#20004;&#31181;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#38543;&#30528;&#22270;&#30340;&#35268;&#27169;&#36235;&#36817;&#20110;&#26080;&#31351;&#22823;&#65292;&#38543;&#26426;&#36807;&#31243;&#30340;&#38543;&#26426;&#36712;&#36857;&#25910;&#25947;&#20110;&#30830;&#23450;&#24615;&#26497;&#38480;&#12290;&#36825;&#20123;&#30830;&#23450;&#24615;&#26497;&#38480;&#26159;&#27979;&#24230;&#20540;&#22270;&#19978;&#30340;&#26354;&#32447;&#12290;&#30001;Lov\'{a}sz&#21644;Szegedy&#24341;&#20837;&#30340;&#27979;&#24230;&#20540;&#22270;&#26159;&#22270;&#26500;&#26550;&#27010;&#24565;&#30340;&#32454;&#21270;&#65292;&#33021;&#22815;&#21306;&#20998;&#20351;&#24471;&#30456;&#21516;&#22270;&#26500;&#26550;&#26497;&#38480;&#30340;&#20004;&#20010;&#26080;&#31351;&#21487;&#20132;&#25442;&#25968;&#32452;&#12290;&#25105;&#20204;&#22312;&#36825;&#20010;&#31354;&#38388;&#19978;&#24341;&#20837;&#20102;&#26032;&#30340;&#24230;&#37327;&#65292;&#20026;&#25105;&#20204;&#30340;&#26497;&#38480;&#23450;&#29702;&#25552;&#20379;&#20102;&#33258;&#28982;&#30340;&#25910;&#25947;&#27010;&#24565;&#12290;&#36825;&#20010;&#27010;&#24565;&#31561;&#20215;&#20110;&#26080;&#31351;&#21487;&#20132;&#25442;&#25968;&#32452;&#30340;&#25910;&#25947;&#12290;&#22312;&#36866;&#24403;&#30340;&#26102;&#38388;&#32553;&#25918;&#19979;&#65292;Metropolis&#38142;&#20855;&#26377;&#25193;&#25955;&#23646;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider two classes of natural stochastic processes on finite unlabeled graphs. These are Euclidean stochastic optimization algorithms on the adjacency matrix of weighted graphs and a modified version of the Metropolis MCMC algorithm on stochastic block models over unweighted graphs. In both cases we show that, as the size of the graph goes to infinity, the random trajectories of the stochastic processes converge to deterministic limits. These deterministic limits are curves on the space of measure-valued graphons. Measure-valued graphons, introduced by Lov\'{a}sz and Szegedy, are a refinement of the concept of graphons that can distinguish between two infinite exchangeable arrays that give rise to the same graphon limit. We introduce new metrics on this space which provide us with a natural notion of convergence for our limit theorems. This notion is equivalent to the convergence of infinite-exchangeable arrays. Under a suitable time-scaling, the Metropolis chain admits a diffusio
&lt;/p&gt;</description></item><item><title>Med-HALT&#26159;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#21644;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#35780;&#20272;&#21644;&#20943;&#23569;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#20013;&#21307;&#30103;&#39046;&#22495;&#30340;&#24187;&#35273;&#38382;&#39064;&#12290;&#36825;&#20010;&#25968;&#25454;&#38598;&#21253;&#25324;&#22810;&#31181;&#21019;&#26032;&#30340;&#27979;&#35797;&#27169;&#24335;&#65292;&#24182;&#35780;&#20272;&#20102;&#39046;&#20808;&#30340;LLMs&#22312;&#24615;&#33021;&#19978;&#30340;&#24046;&#24322;&#12290;</title><link>http://arxiv.org/abs/2307.15343</link><description>&lt;p&gt;
Med-HALT:&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#20013;&#21307;&#30103;&#39046;&#22495;&#24187;&#35273;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
Med-HALT: Medical Domain Hallucination Test for Large Language Models. (arXiv:2307.15343v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2307.15343
&lt;/p&gt;
&lt;p&gt;
Med-HALT&#26159;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#21644;&#25968;&#25454;&#38598;&#65292;&#29992;&#20110;&#35780;&#20272;&#21644;&#20943;&#23569;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#20013;&#21307;&#30103;&#39046;&#22495;&#30340;&#24187;&#35273;&#38382;&#39064;&#12290;&#36825;&#20010;&#25968;&#25454;&#38598;&#21253;&#25324;&#22810;&#31181;&#21019;&#26032;&#30340;&#27979;&#35797;&#27169;&#24335;&#65292;&#24182;&#35780;&#20272;&#20102;&#39046;&#20808;&#30340;LLMs&#22312;&#24615;&#33021;&#19978;&#30340;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#35770;&#25991;&#20851;&#27880;&#22823;&#35268;&#27169;&#35821;&#35328;&#27169;&#22411;&#65288;LLMs&#65289;&#20013;&#24187;&#35273;&#38382;&#39064;&#30340;&#25361;&#25112;&#65292;&#29305;&#21035;&#26159;&#22312;&#21307;&#30103;&#39046;&#22495;&#30340;&#32972;&#26223;&#19979;&#12290;&#24187;&#35273;&#25351;&#36825;&#20123;&#27169;&#22411;&#29983;&#25104;&#20102;&#21512;&#29702;&#20294;&#26410;&#32463;&#39564;&#35777;&#25110;&#38169;&#35823;&#30340;&#20449;&#24687;&#65292;&#36825;&#21487;&#33021;&#23545;&#21307;&#30103;&#24212;&#29992;&#20135;&#29983;&#20005;&#37325;&#24433;&#21709;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#22522;&#20934;&#21644;&#25968;&#25454;&#38598;&#65292;Med-HALT&#65288;&#21307;&#30103;&#39046;&#22495;&#24187;&#35273;&#27979;&#35797;&#65289;&#65292;&#19987;&#38376;&#35774;&#35745;&#29992;&#20110;&#35780;&#20272;&#21644;&#20943;&#23569;&#24187;&#35273;&#12290;Med-HALT&#25552;&#20379;&#20102;&#19968;&#20010;&#22810;&#20803;&#21270;&#30340;&#36328;&#22269;&#25968;&#25454;&#38598;&#65292;&#36825;&#20123;&#25968;&#25454;&#38598;&#26469;&#33258;&#19981;&#21516;&#22269;&#23478;&#30340;&#21307;&#30103;&#26816;&#26597;&#65292;&#21253;&#25324;&#22810;&#31181;&#21019;&#26032;&#30340;&#27979;&#35797;&#27169;&#24335;&#12290;Med-HALT&#21253;&#25324;&#20004;&#31867;&#27979;&#35797;&#65306;&#25512;&#29702;&#21644;&#22522;&#20110;&#35760;&#24518;&#30340;&#24187;&#35273;&#27979;&#35797;&#65292;&#26088;&#22312;&#35780;&#20272;LLMs&#30340;&#38382;&#39064;&#35299;&#20915;&#21644;&#20449;&#24687;&#26816;&#32034;&#33021;&#21147;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#35780;&#20272;&#20102;&#25991;&#26412;Davinci&#65292;GPT-3.5&#65292;LlaMa-2&#65292;MPT&#21644;Falcon&#31561;&#39046;&#20808;&#30340;LLMs&#65292;&#25581;&#31034;&#20102;&#23427;&#20204;&#22312;&#24615;&#33021;&#19978;&#30340;&#26174;&#33879;&#24046;&#24322;&#12290;&#36825;&#31687;&#35770;&#25991;&#25552;&#20379;&#20102;&#26377;&#20851;&#25968;&#25454;&#38598;&#30340;&#35814;&#32454;&#35265;&#35299;&#65292;&#20419;&#36827;&#20102;&#36827;&#19968;&#27493;&#30340;&#30740;&#31350;&#21644;&#21457;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;
This research paper focuses on the challenges posed by hallucinations in large language models (LLMs), particularly in the context of the medical domain. Hallucination, wherein these models generate plausible yet unverified or incorrect information, can have serious consequences in healthcare applications. We propose a new benchmark and dataset, Med-HALT (Medical Domain Hallucination Test), designed specifically to evaluate and reduce hallucinations. Med-HALT provides a diverse multinational dataset derived from medical examinations across various countries and includes multiple innovative testing modalities. Med-HALT includes two categories of tests reasoning and memory-based hallucination tests, designed to assess LLMs's problem-solving and information retrieval abilities.  Our study evaluated leading LLMs, including Text Davinci, GPT-3.5, LlaMa-2, MPT, and Falcon, revealing significant differences in their performance. The paper provides detailed insights into the dataset, promoting
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35821;&#35328;&#26080;&#20851;&#30340;&#20114;&#20449;&#24687;&#20272;&#35745;&#22522;&#20934;&#24179;&#21488;&#65292;&#24182;&#35752;&#35770;&#20102;&#32463;&#20856;&#21644;&#31070;&#32463;&#20272;&#35745;&#22120;&#22312;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#12289;&#38271;&#23614;&#20998;&#24067;&#21644;&#39640;&#20114;&#20449;&#24687;&#26102;&#30340;&#26222;&#36866;&#24615;&#21644;&#23616;&#38480;&#24615;&#12290;</title><link>http://arxiv.org/abs/2306.11078</link><description>&lt;p&gt;
&#36229;&#36234;&#27491;&#24120;&#65306;&#20851;&#20110;&#20114;&#20449;&#24687;&#20272;&#35745;&#30340;&#35780;&#20272;
&lt;/p&gt;
&lt;p&gt;
Beyond Normal: On the Evaluation of Mutual Information Estimators. (arXiv:2306.11078v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.11078
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#35821;&#35328;&#26080;&#20851;&#30340;&#20114;&#20449;&#24687;&#20272;&#35745;&#22522;&#20934;&#24179;&#21488;&#65292;&#24182;&#35752;&#35770;&#20102;&#32463;&#20856;&#21644;&#31070;&#32463;&#20272;&#35745;&#22120;&#22312;&#22788;&#29702;&#39640;&#32500;&#25968;&#25454;&#12289;&#38271;&#23614;&#20998;&#24067;&#21644;&#39640;&#20114;&#20449;&#24687;&#26102;&#30340;&#26222;&#36866;&#24615;&#21644;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20114;&#20449;&#24687;&#26159;&#19968;&#31181;&#24120;&#29992;&#30340;&#32479;&#35745;&#30456;&#20851;&#24230;&#37327;&#65292;&#24050;&#22312;&#34920;&#31034;&#23398;&#20064;&#12289;&#22240;&#26524;&#24615;&#12289;&#22495;&#27867;&#21270;&#21644;&#35745;&#31639;&#29983;&#29289;&#23398;&#31561;&#39046;&#22495;&#24471;&#21040;&#24212;&#29992;&#12290;&#28982;&#32780;&#65292;&#20114;&#20449;&#24687;&#20272;&#35745;&#36890;&#24120;&#21482;&#22312;&#31616;&#21333;&#30340;&#27010;&#29575;&#20998;&#24067;&#26063;&#31867;&#65288;&#21363;&#22810;&#20803;&#27491;&#24577;&#20998;&#24067;&#21644;&#20855;&#26377;&#19968;&#32500;&#38543;&#26426;&#21464;&#37327;&#30340;&#36873;&#25321;&#20998;&#24067;&#65289;&#19978;&#36827;&#34892;&#35780;&#20272;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#26500;&#24314;&#20855;&#26377;&#24050;&#30693;&#22522;&#20934;&#20114;&#20449;&#24687;&#30340;&#21508;&#31181;&#20998;&#24067;&#26063;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#31181;&#35821;&#35328;&#26080;&#20851;&#30340;&#20114;&#20449;&#24687;&#20272;&#35745;&#22522;&#20934;&#24179;&#21488;&#12290;&#25105;&#20204;&#35752;&#35770;&#20102;&#32463;&#20856;&#21644;&#31070;&#32463;&#32593;&#32476;&#20272;&#35745;&#22120;&#22312;&#28041;&#21450;&#39640;&#32500;&#24230;&#12289;&#31232;&#30095;&#30456;&#20114;&#20316;&#29992;&#12289;&#38271;&#23614;&#20998;&#24067;&#21644;&#39640;&#20114;&#20449;&#24687;&#30340;&#24773;&#22659;&#20013;&#30340;&#26222;&#36866;&#24615;&#21644;&#23616;&#38480;&#24615;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#20026;&#20174;&#19994;&#20154;&#21592;&#25552;&#20379;&#20102;&#36873;&#25321;&#36866;&#24403;&#30340;&#20272;&#35745;&#22120;&#20197;&#36866;&#24212;&#25152;&#32771;&#34385;&#38382;&#39064;&#38590;&#24230;&#21644;&#24212;&#29992;&#20272;&#35745;&#20114;&#20449;&#24687;&#26102;&#38656;&#35201;&#32771;&#34385;&#30340;&#38382;&#39064;&#30340;&#25351;&#21335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Mutual information is a general statistical dependency measure which has found applications in representation learning, causality, domain generalization and computational biology. However, mutual information estimators are typically evaluated on simple families of probability distributions, namely multivariate normal distribution and selected distributions with one-dimensional random variables. In this paper, we show how to construct a diverse family of distributions with known ground-truth mutual information and propose a language-independent benchmarking platform for mutual information estimators. We discuss the general applicability and limitations of classical and neural estimators in settings involving high dimensions, sparse interactions, long-tailed distributions, and high mutual information. Finally, we provide guidelines for practitioners on how to select appropriate estimator adapted to the difficulty of problem considered and issues one needs to consider when applying an est
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32467;&#26500;&#21270;&#39044;&#27979;PAC-Bayesian&#39118;&#38505;&#30028;&#38480;&#65292;&#23427;&#21487;&#20197;&#38543;&#30528;&#32467;&#26500;&#21270;&#31034;&#20363;&#30340;&#25968;&#37327;&#21644;&#22823;&#23567;&#30340;&#21464;&#21270;&#32780;&#36827;&#34892;&#27867;&#21270;&#65292;&#20026;&#20351;&#29992;&#29983;&#25104;&#27169;&#22411;&#24314;&#31435;&#32467;&#26500;&#21270;&#39044;&#27979;&#30340;&#27867;&#21270;&#30028;&#38480;&#36808;&#20986;&#20102;&#31532;&#19968;&#27493;&#12290;</title><link>http://arxiv.org/abs/2306.09112</link><description>&lt;p&gt;
&#20851;&#20110;&#32467;&#26500;&#39044;&#27979;&#20013;&#30340;&#35748;&#35777;&#27867;&#21270;
&lt;/p&gt;
&lt;p&gt;
On Certified Generalization in Structured Prediction. (arXiv:2306.09112v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.09112
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32467;&#26500;&#21270;&#39044;&#27979;PAC-Bayesian&#39118;&#38505;&#30028;&#38480;&#65292;&#23427;&#21487;&#20197;&#38543;&#30528;&#32467;&#26500;&#21270;&#31034;&#20363;&#30340;&#25968;&#37327;&#21644;&#22823;&#23567;&#30340;&#21464;&#21270;&#32780;&#36827;&#34892;&#27867;&#21270;&#65292;&#20026;&#20351;&#29992;&#29983;&#25104;&#27169;&#22411;&#24314;&#31435;&#32467;&#26500;&#21270;&#39044;&#27979;&#30340;&#27867;&#21270;&#30028;&#38480;&#36808;&#20986;&#20102;&#31532;&#19968;&#27493;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#32467;&#26500;&#39044;&#27979;&#20013;&#65292;&#30446;&#26631;&#23545;&#35937;&#20855;&#26377;&#20016;&#23500;&#30340;&#20869;&#37096;&#32467;&#26500;&#65292;&#36825;&#31181;&#32467;&#26500;&#26080;&#27861;&#20998;&#35299;&#20026;&#29420;&#31435;&#30340;&#32452;&#20214;&#65292;&#24182;&#36829;&#21453;&#20102;&#24120;&#35265;&#30340;&#29420;&#31435;&#21516;&#20998;&#24067;&#20551;&#35774;&#12290;&#36825;&#19968;&#25361;&#25112;&#22312;&#24212;&#29992;&#31243;&#24207;&#20013;&#34920;&#29616;&#20026;&#25351;&#25968;&#32423;&#30340;&#36755;&#20986;&#31354;&#38388;&#65292;&#22914;&#22270;&#20687;&#20998;&#21106;&#25110;&#22330;&#26223;&#22270;&#29983;&#25104;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#32467;&#26500;&#21270;&#39044;&#27979;PAC-Bayesian&#39118;&#38505;&#30028;&#38480;&#65292;&#20854;&#20013;&#27867;&#21270;&#36895;&#29575;&#19981;&#20165;&#38543;&#30528;&#32467;&#26500;&#21270;&#31034;&#20363;&#30340;&#25968;&#37327;&#32780;&#19988;&#36824;&#38543;&#30528;&#23427;&#20204;&#30340;&#22823;&#23567;&#32780;&#21464;&#21270;&#12290;&#22522;&#26412;&#20551;&#35774;&#31526;&#21512;&#29983;&#25104;&#27169;&#22411;&#19978;&#30340;&#26368;&#26032;&#30740;&#31350;&#65292;&#21363;&#25968;&#25454;&#30001;&#20998;&#35299;&#21442;&#32771;&#24230;&#37327;&#30340;Knothe-Rosenblatt&#37325;&#26032;&#25490;&#21015;&#29983;&#25104;&#12290;&#36825;&#20351;&#24471;&#25105;&#20204;&#21487;&#20197;&#23558;&#38543;&#26426;&#36755;&#20986;&#21464;&#37327;&#20043;&#38388;&#30340;&#32467;&#26500;&#26174;&#24335;&#22320;&#25552;&#21462;&#21040;Wasserstein&#20381;&#36182;&#30697;&#38453;&#20013;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#20026;&#21033;&#29992;&#24378;&#22823;&#30340;&#29983;&#25104;&#27169;&#22411;&#22312;&#32467;&#26500;&#39044;&#27979;&#36825;&#31181;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#24773;&#20917;&#19979;&#24314;&#31435;&#21028;&#21035;&#24335;&#19979;&#28216;&#20219;&#21153;&#30340;&#27867;&#21270;&#30028;&#38480;&#36808;&#20986;&#20102;&#21021;&#27493;&#30340;&#19968;&#27493;&#12290;
&lt;/p&gt;
&lt;p&gt;
In structured prediction, target objects have rich internal structure which does not factorize into independent components and violates common i.i.d. assumptions. This challenge becomes apparent through the exponentially large output space in applications such as image segmentation or scene graph generation. We present a novel PAC-Bayesian risk bound for structured prediction wherein the rate of generalization scales not only with the number of structured examples but also with their size. The underlying assumption, conforming to ongoing research on generative models, is that data are generated by the Knothe-Rosenblatt rearrangement of a factorizing reference measure. This allows to explicitly distill the structure between random output variables into a Wasserstein dependency matrix. Our work makes a preliminary step towards leveraging powerful generative models to establish generalization bounds for discriminative downstream tasks in the challenging setting of structured prediction.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20004;&#31181;&#26032;&#30340;&#35889;&#23884;&#20837;&#26041;&#27861;&#65292;&#19968;&#31181;&#22522;&#20110;&#20989;&#25968;&#20998;&#26512;&#21407;&#29702;&#21644;&#26680;&#26041;&#27861;&#65292;&#21478;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#32593;&#32476;&#20248;&#21270;&#25439;&#22833;&#65292;&#25552;&#20379;&#29702;&#35770;&#20445;&#35777;&#21644;&#23454;&#38469;&#26377;&#25928;&#30340;&#31639;&#27861;&#65292;&#24182;&#25552;&#20379;&#26032;&#30340;&#37319;&#26679;&#31639;&#27861;&#12290;</title><link>http://arxiv.org/abs/2306.00742</link><description>&lt;p&gt;
&#22522;&#20110;&#35889;&#23884;&#20837;&#30340;&#28145;&#24230;&#23398;&#20064;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Going Deeper with Spectral Embeddings. (arXiv:2306.00742v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2306.00742
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20004;&#31181;&#26032;&#30340;&#35889;&#23884;&#20837;&#26041;&#27861;&#65292;&#19968;&#31181;&#22522;&#20110;&#20989;&#25968;&#20998;&#26512;&#21407;&#29702;&#21644;&#26680;&#26041;&#27861;&#65292;&#21478;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#32593;&#32476;&#20248;&#21270;&#25439;&#22833;&#65292;&#25552;&#20379;&#29702;&#35770;&#20445;&#35777;&#21644;&#23454;&#38469;&#26377;&#25928;&#30340;&#31639;&#27861;&#65292;&#24182;&#25552;&#20379;&#26032;&#30340;&#37319;&#26679;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#26377;&#25928;&#22320;&#22788;&#29702;&#28023;&#37327;&#30340;&#25968;&#25454;&#65292;&#20174;&#32780;&#26356;&#22909;&#22320;&#23545;&#20854;&#36827;&#34892;&#34920;&#24449;&#65292;&#31185;&#23398;&#23478;&#20204;&#37319;&#29992;&#34920;&#31034;&#23398;&#20064;&#12290;&#26368;&#36817;&#65292;&#36825;&#20123;&#26041;&#27861;&#19982;&#19968;&#20123;&#24213;&#23618;&#36816;&#31639;&#30340;&#35889;&#20998;&#35299;&#20043;&#38388;&#23637;&#29616;&#20986;&#26126;&#26174;&#30340;&#32852;&#31995;&#12290;&#22312;&#21382;&#21490;&#19978;&#65292;&#26159;&#36890;&#36807;&#22312;&#25968;&#25454;&#30340;&#39030;&#37096;&#26500;&#24314;&#22270;&#24418;&#26469;&#24314;&#31435;&#26126;&#30830;&#30340;&#35889;&#23884;&#20837;&#65292;&#32780;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31181;&#26032;&#30340;&#26041;&#27861;&#65306;&#19968;&#31181;&#22522;&#20110;&#20989;&#25968;&#20998;&#26512;&#21407;&#29702;&#21644;&#26680;&#26041;&#27861;&#26500;&#24314;&#30340;&#65292;&#36825;&#23558;&#23548;&#33268;&#20855;&#26377;&#29702;&#35770;&#20445;&#35777;&#30340;&#31639;&#27861;&#65292;&#21478;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#32593;&#32476;&#35757;&#32451;&#20197;&#20248;&#21270;&#22522;&#26412;&#21464;&#20998;&#25439;&#22833;&#30340;&#31639;&#27861;&#65292;&#23427;&#20204;&#20135;&#29983;&#20102;&#23454;&#38469;&#26377;&#25928;&#30340;&#31639;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#37319;&#26679;&#31639;&#27861;&#65292;&#21033;&#29992;&#23398;&#20064;&#21040;&#30340;&#34920;&#24449;&#26469;&#22312;&#19968;&#27493;&#20013;&#29983;&#25104;&#26032;&#30340;&#26679;&#26412;&#12290;
&lt;/p&gt;
&lt;p&gt;
To make sense of millions of raw data and represent them efficiently, practitioners rely on representation learning. Recently, deep connections have been shown between these approaches and the spectral decompositions of some underlying operators. Historically, explicit spectral embeddings were built from graphs constructed on top of the data. In contrast, we propose two new methods to build spectral embeddings: one based on functional analysis principles and kernel methods, which leads to algorithms with theoretical guarantees, and the other based on deep networks trained to optimize principled variational losses, which yield practically efficient algorithms. Furthermore, we provide a new sampling algorithm that leverages learned representations to generate new samples in a single step.
&lt;/p&gt;</description></item><item><title>ZeroSCROLLS&#26159;&#19968;&#20010;&#29992;&#20110;&#38271;&#25991;&#26412;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#30340;&#38646;Shot&#22522;&#20934;&#27979;&#35797;&#65292;&#21253;&#25324;&#20845;&#20010;&#20219;&#21153;&#21644;&#22235;&#20010;&#25968;&#25454;&#38598;&#65292;&#33021;&#22815;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#24403;&#21069;&#65292;GPT-4&#30340;&#24179;&#22343;&#24471;&#20998;&#26368;&#39640;&#65292;&#20294;&#22312;&#32858;&#21512;&#20219;&#21153;&#31561;&#22810;&#20010;&#25361;&#25112;&#19978;&#65292;&#20173;&#26377;&#25913;&#36827;&#30340;&#31354;&#38388;&#12290;</title><link>http://arxiv.org/abs/2305.14196</link><description>&lt;p&gt;
ZeroSCROLLS&#65306;&#19968;&#20010;&#29992;&#20110;&#38271;&#25991;&#26412;&#29702;&#35299;&#30340;&#38646;Shot&#22522;&#20934;&#27979;&#35797;
&lt;/p&gt;
&lt;p&gt;
ZeroSCROLLS: A Zero-Shot Benchmark for Long Text Understanding. (arXiv:2305.14196v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.14196
&lt;/p&gt;
&lt;p&gt;
ZeroSCROLLS&#26159;&#19968;&#20010;&#29992;&#20110;&#38271;&#25991;&#26412;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#30340;&#38646;Shot&#22522;&#20934;&#27979;&#35797;&#65292;&#21253;&#25324;&#20845;&#20010;&#20219;&#21153;&#21644;&#22235;&#20010;&#25968;&#25454;&#38598;&#65292;&#33021;&#22815;&#35780;&#20272;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#30340;&#24615;&#33021;&#12290;&#24403;&#21069;&#65292;GPT-4&#30340;&#24179;&#22343;&#24471;&#20998;&#26368;&#39640;&#65292;&#20294;&#22312;&#32858;&#21512;&#20219;&#21153;&#31561;&#22810;&#20010;&#25361;&#25112;&#19978;&#65292;&#20173;&#26377;&#25913;&#36827;&#30340;&#31354;&#38388;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#20171;&#32461;&#20102; ZeroSCROLLS&#65292;&#36825;&#26159;&#19968;&#20010;&#29992;&#20110;&#38271;&#25991;&#26412;&#33258;&#28982;&#35821;&#35328;&#29702;&#35299;&#30340;&#38646;Shot&#22522;&#20934;&#27979;&#35797;&#65292;&#20165;&#21253;&#21547;&#27979;&#35797;&#38598;&#32780;&#27809;&#26377;&#35757;&#32451;&#25110;&#24320;&#21457;&#25968;&#25454;&#12290;&#25105;&#20204;&#20174;SCROLLS&#22522;&#20934;&#27979;&#35797;&#20013;&#36866;&#24212;&#20102;&#20845;&#20010;&#20219;&#21153;&#65292;&#24182;&#28155;&#21152;&#20102;&#22235;&#20010;&#26032;&#25968;&#25454;&#38598;&#65292;&#21253;&#25324;&#20004;&#20010;&#26032;&#30340;&#20449;&#24687;&#34701;&#21512;&#20219;&#21153;&#65292;&#20363;&#22914;&#32858;&#21512;&#27491;&#38754;&#35780;&#20215;&#30340;&#30334;&#20998;&#27604;&#12290;&#20351;&#29992;ZeroSCROLLS&#65292;&#25105;&#20204;&#23545;&#24320;&#28304;&#21644;&#38381;&#28304;&#22823;&#22411;&#35821;&#35328;&#27169;&#22411;&#36827;&#34892;&#20102;&#20840;&#38754;&#35780;&#20272;&#65292;&#21457;&#29616;Claude&#20248;&#20110;ChatGPT&#65292;&#24182;&#19988;GPT-4&#33719;&#24471;&#20102;&#26368;&#39640;&#30340;&#24179;&#22343;&#20998;&#25968;&#12290;&#28982;&#32780;&#65292;&#22312;ZeroSCROLLS&#30340;&#22810;&#20010;&#24320;&#25918;&#25361;&#25112;&#26041;&#38754;&#65288;&#20363;&#22914;&#65292;&#32858;&#21512;&#20219;&#21153;&#65289;&#65292;&#36824;&#26377;&#25913;&#36827;&#30340;&#31354;&#38388;&#65292;&#22240;&#20026;&#27169;&#22411;&#24456;&#38590;&#36890;&#36807;&#26420;&#32032;&#30340;&#22522;&#20934;&#27979;&#35797;&#12290;&#30001;&#20110;&#26368;&#20808;&#36827;&#30340;&#25216;&#26415;&#36824;&#22312;&#19981;&#26029;&#26356;&#26032;&#65292;&#25105;&#20204;&#36992;&#35831;&#30740;&#31350;&#20154;&#21592;&#22312;&#23454;&#26102;&#30340;ZeroSCROLLS&#25490;&#34892;&#27036;&#19978;&#35780;&#20272;&#20182;&#20204;&#30340;&#24819;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce ZeroSCROLLS, a zero-shot benchmark for natural language understanding over long texts, which contains only test sets, without training or development data. We adapt six tasks from the SCROLLS benchmark, and add four new datasets, including two novel information fusing tasks, such as aggregating the percentage of positive reviews. Using ZeroSCROLLS, we conduct a comprehensive evaluation of both open-source and closed large language models, finding that Claude outperforms ChatGPT, and that GPT-4 achieves the highest average score. However, there is still room for improvement on multiple open challenges in ZeroSCROLLS, such as aggregation tasks, where models struggle to pass the naive baseline. As the state of the art is a moving target, we invite researchers to evaluate their ideas on the live ZeroSCROLLS leaderboard
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#32676;&#19981;&#21464;GAN&#30340;&#32479;&#35745;&#20445;&#35777;&#65292;&#21457;&#29616;&#24403;&#23398;&#20064;&#32676;&#19981;&#21464;&#20998;&#24067;&#26102;&#65292;&#32676;&#19981;&#21464;GAN&#25152;&#38656;&#26679;&#26412;&#25968;&#20250;&#25353;&#32676;&#20307;&#22823;&#23567;&#30340;&#24130;&#27604;&#20363;&#20943;&#23569;&#12290;</title><link>http://arxiv.org/abs/2305.13517</link><description>&lt;p&gt;
Group-Invariant GAN&#30340;&#32479;&#35745;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Statistical Guarantees of Group-Invariant GANs. (arXiv:2305.13517v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.13517
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#32676;&#19981;&#21464;GAN&#30340;&#32479;&#35745;&#20445;&#35777;&#65292;&#21457;&#29616;&#24403;&#23398;&#20064;&#32676;&#19981;&#21464;&#20998;&#24067;&#26102;&#65292;&#32676;&#19981;&#21464;GAN&#25152;&#38656;&#26679;&#26412;&#25968;&#20250;&#25353;&#32676;&#20307;&#22823;&#23567;&#30340;&#24130;&#27604;&#20363;&#20943;&#23569;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Group-Invariant&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;(GAN)&#26159;&#19968;&#31181;GAN&#65292;&#20854;&#20013;&#29983;&#25104;&#22120;&#21644;&#21028;&#21035;&#22120;&#20855;&#26377;&#30828;&#24615;&#38598;&#22242;&#23545;&#31216;&#24615;&#12290;&#23454;&#35777;&#30740;&#31350;&#34920;&#26126;&#65292;&#36825;&#20123;&#32593;&#32476;&#33021;&#22815;&#23398;&#20064;&#20855;&#26377;&#26174;&#30528;&#25913;&#36827;&#25968;&#25454;&#25928;&#29575;&#30340;&#38598;&#22242;&#19981;&#21464;&#20998;&#24067;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#26088;&#22312;&#36890;&#36807;&#20998;&#26512;&#32676;&#19981;&#21464;GAN&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#20943;&#23569;&#26469;&#20005;&#26684;&#37327;&#21270;&#36825;&#31181;&#25913;&#36827;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#21457;&#29616;&#65292;&#22312;&#23398;&#20064;&#32676;&#19981;&#21464;&#20998;&#24067;&#26102;&#65292;&#32676;&#19981;&#21464;GAN&#25152;&#38656;&#26679;&#26412;&#25968;&#25353;&#29031;&#32676;&#20307;&#22823;&#23567;&#30340;&#24130;&#27604;&#20363;&#20943;&#23569;&#65292;&#36825;&#20010;&#24130;&#21462;&#20915;&#20110;&#20998;&#24067;&#25903;&#25345;&#30340;&#26412;&#36136;&#32500;&#24230;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#39033;&#24037;&#20316;&#26159;&#39318;&#20010;&#20026;&#32676;&#19981;&#21464;&#29983;&#25104;&#27169;&#22411;&#65292;&#29305;&#21035;&#26159;GAN&#25552;&#20379;&#32479;&#35745;&#20272;&#35745;&#30340;&#24037;&#20316;&#65292;&#24182;&#21487;&#20197;&#20026;&#20854;&#20182;&#32676;&#19981;&#21464;&#29983;&#25104;&#27169;&#22411;&#30340;&#30740;&#31350;&#25552;&#20379;&#20511;&#37492;&#12290;
&lt;/p&gt;
&lt;p&gt;
Group-invariant generative adversarial networks (GANs) are a type of GANs in which the generators and discriminators are hardwired with group symmetries. Empirical studies have shown that these networks are capable of learning group-invariant distributions with significantly improved data efficiency. In this study, we aim to rigorously quantify this improvement by analyzing the reduction in sample complexity for group-invariant GANs. Our findings indicate that when learning group-invariant distributions, the number of samples required for group-invariant GANs decreases proportionally with a power of the group size, and this power depends on the intrinsic dimension of the distribution's support. To our knowledge, this work presents the first statistical estimation for group-invariant generative models, specifically for GANs, and it may shed light on the study of other group-invariant generative models.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#19968;&#33324;&#22238;&#24402;&#35823;&#24046;&#20551;&#35774;&#30340;&#26080;&#22122;&#22768;&#22238;&#24402;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#20540;&#30340;&#22343;&#26041;&#35823;&#24046;&#65292;&#24182;&#21457;&#29616;&#21253;&#21547;&#22823;&#37327;&#19981;&#37325;&#35201;&#30340;&#21442;&#25968;&#21487;&#20197;&#26377;&#25928;&#22320;&#38477;&#20302;&#20272;&#35745;&#22120;&#30340;&#22343;&#26041;&#35823;&#24046;&#12290;</title><link>http://arxiv.org/abs/2305.12883</link><description>&lt;p&gt;
&#22522;&#20110;&#19968;&#33324;&#22238;&#24402;&#35823;&#24046;&#20551;&#35774;&#26469;&#30740;&#31350;&#26080;&#22122;&#22768;&#22238;&#24402;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#20540;&#30340;&#22343;&#26041;&#35823;&#24046;
&lt;/p&gt;
&lt;p&gt;
The Mean Squared Error of the Ridgeless Least Squares Estimator under General Assumptions on Regression Errors. (arXiv:2305.12883v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12883
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#30740;&#31350;&#20102;&#22522;&#20110;&#19968;&#33324;&#22238;&#24402;&#35823;&#24046;&#20551;&#35774;&#30340;&#26080;&#22122;&#22768;&#22238;&#24402;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#20540;&#30340;&#22343;&#26041;&#35823;&#24046;&#65292;&#24182;&#21457;&#29616;&#21253;&#21547;&#22823;&#37327;&#19981;&#37325;&#35201;&#30340;&#21442;&#25968;&#21487;&#20197;&#26377;&#25928;&#22320;&#38477;&#20302;&#20272;&#35745;&#22120;&#30340;&#22343;&#26041;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#65292;&#26368;&#23567;$\ell_2$&#33539;&#25968;&#65288;&#26080;&#23725;&#65289;&#25554;&#20540;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#30340;&#30740;&#31350;&#26041;&#20852;&#26410;&#33406;&#12290;&#28982;&#32780;&#65292;&#22823;&#22810;&#25968;&#20998;&#26512;&#37117;&#23616;&#38480;&#20110;&#31616;&#21333;&#30340;&#22238;&#24402;&#35823;&#24046;&#32467;&#26500;&#65292;&#20551;&#35774;&#35823;&#24046;&#26159;&#29420;&#31435;&#21516;&#20998;&#24067;&#30340;&#65292;&#20855;&#26377;&#38646;&#22343;&#20540;&#21644;&#30456;&#21516;&#30340;&#26041;&#24046;&#65292;&#19982;&#29305;&#24449;&#21521;&#37327;&#26080;&#20851;&#12290;&#27492;&#22806;&#65292;&#36825;&#20123;&#29702;&#35770;&#20998;&#26512;&#30340;&#20027;&#35201;&#37325;&#28857;&#26159;&#26679;&#26412;&#22806;&#39044;&#27979;&#39118;&#38505;&#12290;&#26412;&#25991;&#36890;&#36807;&#26816;&#26597;&#26080;&#23725;&#25554;&#20540;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#30340;&#22343;&#26041;&#35823;&#24046;&#65292;&#20801;&#35768;&#26356;&#19968;&#33324;&#30340;&#22238;&#24402;&#35823;&#24046;&#20551;&#35774;&#65292;&#25171;&#30772;&#20102;&#29616;&#26377;&#25991;&#29486;&#30340;&#23616;&#38480;&#24615;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30740;&#31350;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#28508;&#22312;&#22909;&#22788;&#65292;&#36890;&#36807;&#25551;&#32472;&#26377;&#38480;&#26679;&#26412;&#20013;&#30340;&#22343;&#26041;&#35823;&#24046;&#26469;&#34920;&#24449;&#22343;&#26041;&#35823;&#24046;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#32467;&#26524;&#34920;&#26126;&#65292;&#30456;&#23545;&#20110;&#26679;&#26412;&#37327;&#65292;&#21253;&#21547;&#22823;&#37327;&#19981;&#37325;&#35201;&#30340;&#21442;&#25968;&#21487;&#20197;&#26377;&#25928;&#22320;&#38477;&#20302;&#20272;&#35745;&#22120;&#30340;&#22343;&#26041;&#35823;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
In recent years, there has been a significant growth in research focusing on minimum $\ell_2$ norm (ridgeless) interpolation least squares estimators. However, the majority of these analyses have been limited to a simple regression error structure, assuming independent and identically distributed errors with zero mean and common variance, independent of the feature vectors. Additionally, the main focus of these theoretical analyses has been on the out-of-sample prediction risk. This paper breaks away from the existing literature by examining the mean squared error of the ridgeless interpolation least squares estimator, allowing for more general assumptions about the regression errors. Specifically, we investigate the potential benefits of overparameterization by characterizing the mean squared error in a finite sample. Our findings reveal that including a large number of unimportant parameters relative to the sample size can effectively reduce the mean squared error of the estimator. N
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21033;&#29992;&#25193;&#23637;&#24433;&#21709;&#20989;&#25968;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#35782;&#21035;&#21644;&#37325;&#26032;&#26631;&#35760;&#26368;&#23567;&#35757;&#32451;&#23376;&#38598;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20854;&#22987;&#32456;&#33021;&#22815;&#25104;&#21151;&#32763;&#36716;&#27979;&#35797;&#32467;&#26524;&#65292;&#21516;&#26102;&#36824;&#25552;&#20379;&#20102;&#25361;&#25112;&#27169;&#22411;&#39044;&#27979;&#12289;&#35780;&#20272;&#27169;&#22411;&#40065;&#26834;&#24615;&#21644;&#27934;&#23519;&#35757;&#32451;&#38598;&#20559;&#24046;&#31561;&#22810;&#37325;&#20316;&#29992;&#12290;</title><link>http://arxiv.org/abs/2305.12809</link><description>&lt;p&gt;
&#36890;&#36807;&#37325;&#26032;&#26631;&#35760;&#26368;&#23567;&#35757;&#32451;&#23376;&#38598;&#26469;&#32763;&#36716;&#39044;&#27979;
&lt;/p&gt;
&lt;p&gt;
Relabel Minimal Training Subset to Flip a Prediction. (arXiv:2305.12809v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.12809
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21033;&#29992;&#25193;&#23637;&#24433;&#21709;&#20989;&#25968;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#35782;&#21035;&#21644;&#37325;&#26032;&#26631;&#35760;&#26368;&#23567;&#35757;&#32451;&#23376;&#38598;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20854;&#22987;&#32456;&#33021;&#22815;&#25104;&#21151;&#32763;&#36716;&#27979;&#35797;&#32467;&#26524;&#65292;&#21516;&#26102;&#36824;&#25552;&#20379;&#20102;&#25361;&#25112;&#27169;&#22411;&#39044;&#27979;&#12289;&#35780;&#20272;&#27169;&#22411;&#40065;&#26834;&#24615;&#21644;&#27934;&#23519;&#35757;&#32451;&#38598;&#20559;&#24046;&#31561;&#22810;&#37325;&#20316;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Yang&#31561;&#20154;&#21457;&#29616;&#65292;&#20165;&#21024;&#38500;1%&#30340;&#35757;&#32451;&#25968;&#25454;&#23601;&#21487;&#33021;&#23548;&#33268;&#39044;&#27979;&#32467;&#26524;&#32763;&#36716;&#12290;&#37492;&#20110;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#23384;&#22312;&#22122;&#22768;&#25968;&#25454;&#30340;&#26222;&#36941;&#24615;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38382;&#39064;&#65306;&#22312;&#27169;&#22411;&#35757;&#32451;&#20043;&#21069;&#36890;&#36807;&#37325;&#26032;&#26631;&#35760;&#19968;&#20010;&#23567;&#30340;&#35757;&#32451;&#25968;&#25454;&#23376;&#38598;&#21487;&#21542;&#23548;&#33268;&#27979;&#35797;&#32467;&#26524;&#32763;&#36716;&#65311;&#26412;&#25991;&#21033;&#29992;&#25193;&#23637;&#24433;&#21709;&#20989;&#25968;&#25552;&#20986;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#35782;&#21035;&#21644;&#37325;&#26032;&#26631;&#35760;&#36825;&#31181;&#23376;&#38598;&#30340;&#26041;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#22987;&#32456;&#33021;&#22815;&#20135;&#29983;&#25104;&#21151;&#30340;&#32467;&#26524;&#12290;&#36825;&#31181;&#26426;&#21046;&#26377;&#22810;&#37325;&#20316;&#29992;&#65306;&#65288;1&#65289;&#25552;&#20379;&#20102;&#19968;&#31181;&#34917;&#20805;&#26041;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#24674;&#22797;&#21487;&#33021;&#38169;&#35823;&#26631;&#35760;&#30340;&#35757;&#32451;&#25968;&#25454;&#26469;&#25361;&#25112;&#27169;&#22411;&#39044;&#27979;&#65307;&#65288;2&#65289;&#35780;&#20272;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#65292;&#22240;&#20026;&#26412;&#25991;&#21457;&#29616;&#23376;&#38598;&#30340;&#22823;&#23567;&#19982;&#35757;&#32451;&#38598;&#20013;&#22122;&#22768;&#25968;&#25454;&#30340;&#27604;&#20363;&#20043;&#38388;&#23384;&#22312;&#26174;&#33879;&#20851;&#31995;&#65307;&#65288;3&#65289;&#25552;&#20379;&#20102;&#27934;&#23519;&#35757;&#32451;&#38598;&#20559;&#24046;&#30340;&#35265;&#35299;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#39033;&#24037;&#20316;&#20195;&#34920;&#20102;&#23545;&#35782;&#21035;&#26368;&#23567;&#35757;&#32451;&#23376;&#38598;&#38382;&#39064;&#30340;&#31532;&#19968;&#27425;&#30740;&#31350;&#12290;
&lt;/p&gt;
&lt;p&gt;
Yang et al. (2023) discovered that removing a mere 1% of training points can often lead to the flipping of a prediction. Given the prevalence of noisy data in machine learning models, we pose the question: can we also result in the flipping of a test prediction by relabeling a small subset of the training data before the model is trained? In this paper, utilizing the extended influence function, we propose an efficient procedure for identifying and relabeling such a subset, demonstrating consistent success. This mechanism serves multiple purposes: (1) providing a complementary approach to challenge model predictions by recovering potentially mislabeled training points; (2) evaluating model resilience, as our research uncovers a significant relationship between the subset's size and the ratio of noisy data in the training set; and (3) offering insights into bias within the training set. To the best of our knowledge, this work represents the first investigation into the problem of identi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#36923;&#36753;&#22238;&#24402;&#24120;&#25968;&#27493;&#38271;&#26799;&#24230;&#19979;&#38477;&#22312;&#31283;&#23450;&#24615;&#36793;&#32536;&#30340;&#25910;&#25947;&#24615;&#21644;&#38544;&#24335;&#20559;&#24046;&#65292;&#35777;&#26126;&#20102;&#36923;&#36753;&#25439;&#22833;&#21487;&#20197;&#36890;&#36807;&#20219;&#20309;&#24120;&#25968;&#27493;&#38271;&#30340;&#26799;&#24230;&#19979;&#38477;&#36827;&#34892;&#26368;&#23567;&#21270;&#65292;&#21516;&#26102;&#20063;&#21457;&#29616;&#20102;&#25351;&#25968;&#25439;&#22833;&#19979;&#30340;&#21457;&#25955;&#24615;&#38382;&#39064;&#65292;&#24378;&#35843;&#20102;&#31283;&#23450;&#24615;&#36793;&#32536;&#19979;&#26799;&#24230;&#19979;&#38477;&#30340;&#19981;&#31283;&#23450;&#24615;&#12290;</title><link>http://arxiv.org/abs/2305.11788</link><description>&lt;p&gt;
&#31283;&#23450;&#24615;&#36793;&#32536;&#22788;&#30340;&#36923;&#36753;&#22238;&#24402;&#26799;&#24230;&#19979;&#38477;&#30340;&#38544;&#24335;&#20559;&#24046;
&lt;/p&gt;
&lt;p&gt;
Implicit Bias of Gradient Descent for Logistic Regression at the Edge of Stability. (arXiv:2305.11788v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11788
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#36923;&#36753;&#22238;&#24402;&#24120;&#25968;&#27493;&#38271;&#26799;&#24230;&#19979;&#38477;&#22312;&#31283;&#23450;&#24615;&#36793;&#32536;&#30340;&#25910;&#25947;&#24615;&#21644;&#38544;&#24335;&#20559;&#24046;&#65292;&#35777;&#26126;&#20102;&#36923;&#36753;&#25439;&#22833;&#21487;&#20197;&#36890;&#36807;&#20219;&#20309;&#24120;&#25968;&#27493;&#38271;&#30340;&#26799;&#24230;&#19979;&#38477;&#36827;&#34892;&#26368;&#23567;&#21270;&#65292;&#21516;&#26102;&#20063;&#21457;&#29616;&#20102;&#25351;&#25968;&#25439;&#22833;&#19979;&#30340;&#21457;&#25955;&#24615;&#38382;&#39064;&#65292;&#24378;&#35843;&#20102;&#31283;&#23450;&#24615;&#36793;&#32536;&#19979;&#26799;&#24230;&#19979;&#38477;&#30340;&#19981;&#31283;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26368;&#36817;&#30340;&#30740;&#31350;&#34920;&#26126;&#65292;&#22312;&#26426;&#22120;&#23398;&#20064;&#20248;&#21270;&#20013;&#65292;&#26799;&#24230;&#19979;&#38477; (GD) &#32463;&#24120;&#22312;&#31283;&#23450;&#24615;&#36793;&#32536; (EoS) [Cohen &#31561;&#65292;2021] &#36816;&#34892;&#65292;&#20854;&#20013;&#27493;&#38271;&#34987;&#35774;&#32622;&#20026;&#22823;&#65292;&#23548;&#33268;&#30001; GD &#36845;&#20195;&#24341;&#36215;&#30340;&#38750;&#21333;&#35843;&#25439;&#22833;&#12290;&#26412;&#25991;&#30740;&#31350;&#22312; EoS &#21306;&#22495;&#20869;&#20351;&#29992;&#24120;&#25968;&#27493;&#38271; GD &#36827;&#34892;&#36923;&#36753;&#22238;&#24402;&#30340;&#25910;&#25947;&#24615;&#21644;&#38544;&#24335;&#20559;&#24046;&#65292;&#23545;&#20110;&#32447;&#24615;&#21487;&#20998;&#30340;&#25968;&#25454;&#12290;&#23613;&#31649;&#23384;&#22312;&#23616;&#37096;&#25391;&#33633;&#65292;&#25105;&#20204;&#35777;&#26126;&#36923;&#36753;&#25439;&#22833;&#21487;&#20197;&#36890;&#36807;&#20219;&#20309;&#24120;&#25968;&#27493;&#38271;&#30340; GD &#22312;&#38271;&#26102;&#38388;&#23610;&#24230;&#19978;&#36827;&#34892;&#26368;&#23567;&#21270;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#65292;&#22312;&#20219;&#20309;&#24120;&#25968;&#27493;&#38271;&#19979;&#65292;&#24403;&#25237;&#24433;&#21040;&#26368;&#22823;&#36793;&#38469;&#26041;&#21521; (&#30828;&#36793; SVM &#26041;&#21521;) &#26102;&#65292;GD &#36845;&#20195;&#36235;&#21521;&#20110;&#26080;&#31351;&#22823;&#65292;&#24182;&#22312;&#25237;&#24433;&#21040;&#26368;&#22823;&#36793;&#32536;&#30340;&#27491;&#20132;&#34917;&#31354;&#38388;&#26102;&#65292;&#25910;&#25947;&#20110;&#26368;&#23567;&#21270;&#24378;&#20984;&#21183;&#33021;&#30340;&#22266;&#23450;&#21521;&#37327;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#20063;&#34920;&#26126;&#65292;&#22312; EoS &#21306;&#22495;&#65292;GD &#36845;&#20195;&#21487;&#33021;&#22312;&#25351;&#25968;&#25439;&#22833;&#19979;&#21457;&#29983;&#28798;&#38590;&#24615;&#21457;&#25955;&#65292;&#31361;&#26174;&#20102; EoS &#21306;&#22495;&#20013; GD &#30340;&#19981;&#31283;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recent research has observed that in machine learning optimization, gradient descent (GD) often operates at the edge of stability (EoS) [Cohen, et al., 2021], where the stepsizes are set to be large, resulting in non-monotonic losses induced by the GD iterates. This paper studies the convergence and implicit bias of constant-stepsize GD for logistic regression on linearly separable data in the EoS regime. Despite the presence of local oscillations, we prove that the logistic loss can be minimized by GD with any constant stepsize over a long time scale. Furthermore, we prove that with any constant stepsize, the GD iterates tend to infinity when projected to a max-margin direction (the hard-margin SVM direction) and converge to a fixed vector that minimizes a strongly convex potential when projected to the orthogonal complement of the max-margin direction. In contrast, we also show that in the EoS regime, GD iterates may diverge catastrophically under the exponential loss, highlighting t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#22411;&#25299;&#25169;&#8212;&#8212;&#22522;&#30784;$(k+1)$&#22270;&#65292;&#20854;&#20013;&#33410;&#28857;&#22312;&#26377;&#38480;&#30340;&#36845;&#20195;&#27425;&#25968;&#21518;&#33021;&#36798;&#21040;&#30830;&#20999;&#30340;&#20849;&#35782;&#65292;&#20855;&#26377;&#24555;&#36895;&#20849;&#35782;&#29575;&#21644;&#23567;&#30340;&#26368;&#22823;&#24230;&#25968;&#65292;&#20174;&#32780;&#21487;&#20197;&#29992;&#20110;&#20998;&#25955;&#24335;SGD&#12290;</title><link>http://arxiv.org/abs/2305.11420</link><description>&lt;p&gt;
&#36229;&#36234;&#25351;&#25968;&#22270;&#65306;&#26377;&#38480;&#26102;&#38388;&#25910;&#25947;&#30340;&#36890;&#20449;&#25928;&#29575;&#25299;&#25169;&#29992;&#20110;&#20998;&#25955;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Beyond Exponential Graph: Communication-Efficient Topologies for Decentralized Learning via Finite-time Convergence. (arXiv:2305.11420v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11420
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#26032;&#22411;&#25299;&#25169;&#8212;&#8212;&#22522;&#30784;$(k+1)$&#22270;&#65292;&#20854;&#20013;&#33410;&#28857;&#22312;&#26377;&#38480;&#30340;&#36845;&#20195;&#27425;&#25968;&#21518;&#33021;&#36798;&#21040;&#30830;&#20999;&#30340;&#20849;&#35782;&#65292;&#20855;&#26377;&#24555;&#36895;&#20849;&#35782;&#29575;&#21644;&#23567;&#30340;&#26368;&#22823;&#24230;&#25968;&#65292;&#20174;&#32780;&#21487;&#20197;&#29992;&#20110;&#20998;&#25955;&#24335;SGD&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36817;&#24180;&#26469;&#36234;&#26469;&#36234;&#22810;&#30340;&#30740;&#31350;&#20851;&#27880;&#20110;&#20998;&#25955;&#24335;&#23398;&#20064;&#22312;&#24182;&#34892;&#35745;&#31639;&#21644;&#38544;&#31169;&#20445;&#25252;&#20013;&#30340;&#24212;&#29992;&#12290;&#35768;&#22810;&#26368;&#36817;&#30340;&#30740;&#31350;&#25351;&#20986;&#65292;&#20855;&#26377;&#26356;&#24555;&#20849;&#35782;&#29575;&#65288;&#21363;&#35889;&#38388;&#38553;&#65289;&#30340;&#24213;&#23618;&#32593;&#32476;&#25299;&#25169;&#21487;&#23548;&#33268;&#20998;&#25955;&#24335;&#23398;&#20064;&#30340;&#26356;&#22909;&#25910;&#25947;&#36895;&#24230;&#21644;&#20934;&#30830;&#24615;&#12290;&#28982;&#32780;&#65292;&#20855;&#26377;&#24555;&#36895;&#20849;&#35782;&#29575;&#30340;&#25299;&#25169;&#65292;&#22914;&#25351;&#25968;&#22270;&#65292;&#36890;&#24120;&#20855;&#26377;&#36739;&#22823;&#30340;&#26368;&#22823;&#24230;&#25968;&#65292;&#36825;&#20250;&#23548;&#33268;&#37325;&#35201;&#30340;&#36890;&#20449;&#25104;&#26412;&#12290;&#22240;&#27492;&#65292;&#23547;&#27714;&#26082;&#20855;&#26377;&#24555;&#36895;&#20849;&#35782;&#29575;&#21448;&#20855;&#26377;&#23567;&#30340;&#26368;&#22823;&#24230;&#25968;&#30340;&#25299;&#25169;&#26159;&#37325;&#35201;&#30340;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#32467;&#21512;&#24555;&#36895;&#20849;&#35782;&#29575;&#21644;&#23567;&#26368;&#22823;&#24230;&#30340;&#26032;&#22411;&#25299;&#25169;&#65292;&#31216;&#20026;&#22522;&#30784;$(k+1)$ &#22270;&#12290;&#19982;&#29616;&#26377;&#30340;&#25299;&#25169;&#19981;&#21516;&#65292;&#22522;&#30784;$(k+1)$ &#22270;&#20351;&#25152;&#26377;&#33410;&#28857;&#22312;&#26377;&#38480;&#30340;&#36845;&#20195;&#27425;&#25968;&#21518;&#37117;&#33021;&#36798;&#21040;&#30830;&#20999;&#30340;&#20849;&#35782;&#65292;&#23545;&#20110;&#20219;&#20309;&#33410;&#28857;&#25968;&#21644;&#26368;&#22823;&#24230;k&#37117;&#36866;&#29992;&#12290;&#24471;&#30410;&#20110;&#36825;&#20010;&#26377;&#21033;&#30340;&#23646;&#24615;&#65292;&#22522;&#30784;$(k+1)$ &#22270;&#36171;&#20104;&#20102;&#20998;&#25955;&#24335;SGD
&lt;/p&gt;
&lt;p&gt;
Decentralized learning has recently been attracting increasing attention for its applications in parallel computation and privacy preservation. Many recent studies stated that the underlying network topology with a faster consensus rate (a.k.a. spectral gap) leads to a better convergence rate and accuracy for decentralized learning. However, a topology with a fast consensus rate, e.g., the exponential graph, generally has a large maximum degree, which incurs significant communication costs. Thus, seeking topologies with both a fast consensus rate and small maximum degree is important. In this study, we propose a novel topology combining both a fast consensus rate and small maximum degree called the Base-$(k + 1)$ Graph. Unlike the existing topologies, the Base-$(k + 1)$ Graph enables all nodes to reach the exact consensus after a finite number of iterations for any number of nodes and maximum degree k. Thanks to this favorable property, the Base-$(k + 1)$ Graph endows Decentralized SGD
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#19979;&#30340;&#22343;&#22330;&#25511;&#21046;(MFC)&#21644;&#22343;&#22330;&#21338;&#24328;(MFG)&#20013;&#30340;&#24378;&#21270;&#23398;&#20064;&#30340;&#32479;&#35745;&#25928;&#29575;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#20048;&#35266;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#31639;&#27861;&#65292;&#24182;&#20165;&#23545;&#36716;&#31227;&#21160;&#21147;&#23398;&#20855;&#26377;Lipschitz&#36830;&#32493;&#24615;&#30340;&#20551;&#35774;&#65292;&#26368;&#21518;&#24314;&#31435;&#20102;&#19968;&#20010;&#25351;&#25968;&#32423;&#30340;&#19979;&#30028;&#25903;&#25345;MFC&#35774;&#32622;&#12290;</title><link>http://arxiv.org/abs/2305.11283</link><description>&lt;p&gt;
&#20851;&#20110;&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#19979;&#30340;&#22343;&#22330;&#24378;&#21270;&#23398;&#20064;&#30340;&#32479;&#35745;&#25928;&#29575;
&lt;/p&gt;
&lt;p&gt;
On the Statistical Efficiency of Mean Field Reinforcement Learning with General Function Approximation. (arXiv:2305.11283v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.11283
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#19979;&#30340;&#22343;&#22330;&#25511;&#21046;(MFC)&#21644;&#22343;&#22330;&#21338;&#24328;(MFG)&#20013;&#30340;&#24378;&#21270;&#23398;&#20064;&#30340;&#32479;&#35745;&#25928;&#29575;&#65292;&#25552;&#20986;&#20102;&#22522;&#20110;&#20048;&#35266;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#31639;&#27861;&#65292;&#24182;&#20165;&#23545;&#36716;&#31227;&#21160;&#21147;&#23398;&#20855;&#26377;Lipschitz&#36830;&#32493;&#24615;&#30340;&#20551;&#35774;&#65292;&#26368;&#21518;&#24314;&#31435;&#20102;&#19968;&#20010;&#25351;&#25968;&#32423;&#30340;&#19979;&#30028;&#25903;&#25345;MFC&#35774;&#32622;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#33324;&#20989;&#25968;&#36924;&#36817;&#19979;&#30340;&#22343;&#22330;&#25511;&#21046;&#65288;MFC&#65289;&#21644;&#22343;&#22330;&#21338;&#24328;&#65288;MFG&#65289;&#20013;&#24378;&#21270;&#23398;&#20064;&#30340;&#32479;&#35745;&#25928;&#29575;&#12290;&#24341;&#20837;&#20102;&#19968;&#31181;&#31216;&#20026;Mean-Field Model-Based Eluder Dimension (MBED)&#30340;&#26032;&#27010;&#24565;&#65292;&#21253;&#21547;&#20102;&#19968;&#31995;&#21015;&#20016;&#23500;&#30340;&#22343;&#22330;&#24378;&#21270;&#23398;&#20064;&#38382;&#39064;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#22522;&#20110;&#20048;&#35266;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#36820;&#22238;&#19968;&#20010;$\epsilon$&#20248;&#30340;&#31574;&#30053;&#65292;&#36866;&#29992;&#20110;MFC&#25110;$\epsilon$&#32435;&#20160;&#22343;&#34913;&#31574;&#30053;&#36866;&#29992;&#20110;MFG&#65292;&#26679;&#26412;&#22797;&#26434;&#24230;&#22810;&#39033;&#24335;&#19982;&#30456;&#20851;&#21442;&#25968;&#26080;&#20851;&#65292;&#19982;&#29366;&#24577;&#12289;&#21160;&#20316;&#21644;&#20195;&#29702;&#25968;&#37327;&#26080;&#20851;&#12290;&#20540;&#24471;&#27880;&#24847;&#30340;&#26159;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#20165;&#23545;&#36716;&#31227;&#21160;&#21147;&#23398;&#20855;&#26377;Lipschitz&#36830;&#32493;&#24615;&#30340;&#20551;&#35774;&#65292;&#36991;&#20813;&#20102;&#20197;&#21069;&#30340;&#24378;&#32467;&#26500;&#20551;&#35774;&#12290;&#26368;&#21518;&#65292;&#22312;tabular&#35774;&#32622;&#19979;&#65292;&#20551;&#35774;&#26377;&#19968;&#20010;&#29983;&#25104;&#27169;&#22411;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#25351;&#25968;&#32423;&#30340;&#19979;&#30028;&#25903;&#25345;MFC&#35774;&#32622;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26679;&#26412;&#39640;&#25928;&#30340;&#27169;&#22411;&#28040;&#38500;&#31639;&#27861;&#20197;&#36924;&#36817;&#26368;&#20248;&#31574;&#30053;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study the statistical efficiency of Reinforcement Learning in Mean-Field Control (MFC) and Mean-Field Game (MFG) with general function approximation. We introduce a new concept called Mean-Field Model-Based Eluder Dimension (MBED), which subsumes a rich family of Mean-Field RL problems. Additionally, we propose algorithms based on Optimistic Maximal Likelihood Estimation, which can return an $\epsilon$-optimal policy for MFC or an $\epsilon$-Nash Equilibrium policy for MFG, with sample complexity polynomial w.r.t. relevant parameters and independent of the number of states, actions and the number of agents. Notably, our results only require a mild assumption of Lipschitz continuity on transition dynamics and avoid strong structural assumptions in previous work. Finally, in the tabular setting, given the access to a generative model, we establish an exponential lower bound for MFC setting, while providing a novel sample-efficient model elimination algorithm to approxim
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#23545;&#26080;&#19978;&#38480;&#25968;&#25454;&#36827;&#34892;&#24046;&#20998;&#38544;&#31169;&#20998;&#20301;&#25968;&#21644;&#26368;&#22823;&#20540;&#30340;&#35745;&#31639;&#12290;&#35843;&#29992;&#22522;&#26412;&#30340;&#31232;&#30095;&#21521;&#37327;&#25216;&#26415;&#20013;&#30340;$\texttt{AboveThreshold}$&#23376;&#31243;&#24207;&#21487;&#20197;&#23454;&#29616;&#36825;&#20010;&#30446;&#26631;&#65292;&#21487;&#20197;&#25552;&#20379;&#26356;&#20934;&#30830;&#21644;&#31283;&#20581;&#30340;&#26368;&#39640;&#20998;&#20301;&#25968;&#20272;&#35745;&#65292;&#20174;&#32780;&#24212;&#29992;&#20110;&#23545;&#20110;&#24046;&#20998;&#38544;&#31169;&#27714;&#21644;&#21644;&#22343;&#20540;&#20272;&#35745;&#33267;&#20851;&#37325;&#35201;&#30340;&#25968;&#25454;&#21098;&#20999;&#65292;&#35813;&#25216;&#26415;&#30340;&#38544;&#31169;&#20445;&#38556;&#21487;&#20197;&#36890;&#36807;&#26041;&#27861;&#25913;&#36827;&#12290;</title><link>http://arxiv.org/abs/2305.01177</link><description>&lt;p&gt;
&#26080;&#30028;&#24046;&#20998;&#38544;&#31169;&#20998;&#20301;&#25968;&#21644;&#26368;&#22823;&#20540;&#20272;&#31639;
&lt;/p&gt;
&lt;p&gt;
Unbounded Differentially Private Quantile and Maximum Estimation. (arXiv:2305.01177v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.01177
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22914;&#20309;&#23545;&#26080;&#19978;&#38480;&#25968;&#25454;&#36827;&#34892;&#24046;&#20998;&#38544;&#31169;&#20998;&#20301;&#25968;&#21644;&#26368;&#22823;&#20540;&#30340;&#35745;&#31639;&#12290;&#35843;&#29992;&#22522;&#26412;&#30340;&#31232;&#30095;&#21521;&#37327;&#25216;&#26415;&#20013;&#30340;$\texttt{AboveThreshold}$&#23376;&#31243;&#24207;&#21487;&#20197;&#23454;&#29616;&#36825;&#20010;&#30446;&#26631;&#65292;&#21487;&#20197;&#25552;&#20379;&#26356;&#20934;&#30830;&#21644;&#31283;&#20581;&#30340;&#26368;&#39640;&#20998;&#20301;&#25968;&#20272;&#35745;&#65292;&#20174;&#32780;&#24212;&#29992;&#20110;&#23545;&#20110;&#24046;&#20998;&#38544;&#31169;&#27714;&#21644;&#21644;&#22343;&#20540;&#20272;&#35745;&#33267;&#20851;&#37325;&#35201;&#30340;&#25968;&#25454;&#21098;&#20999;&#65292;&#35813;&#25216;&#26415;&#30340;&#38544;&#31169;&#20445;&#38556;&#21487;&#20197;&#36890;&#36807;&#26041;&#27861;&#25913;&#36827;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#22312;&#25968;&#25454;&#30340;&#20998;&#20301;&#25968;&#35745;&#31639;&#20013;&#65292;&#23588;&#20854;&#26159;&#26368;&#39640;&#20998;&#20301;&#25968;&#65288;&#22914;&#26368;&#22823;&#20540;&#65289;&#65292;&#22914;&#20309;&#23454;&#29616;&#23545;&#26080;&#30028;&#25968;&#25454;&#30340;&#24046;&#20998;&#38544;&#31169;&#35745;&#31639;&#12290;&#25105;&#20204;&#36890;&#36807;&#31616;&#21333;&#35843;&#29992;&#36845;&#20195;&#35843;&#29992;&#22522;&#26412;&#30340;&#31232;&#30095;&#21521;&#37327;&#25216;&#26415;&#20013;&#30340;$\texttt{AboveThreshold}$&#23376;&#31243;&#24207;&#65292;&#21363;&#21487;&#39640;&#25928;&#22320;&#23454;&#29616;&#27492;&#30446;&#26631;&#65292;&#21363;&#20351;&#25968;&#25454;&#27809;&#26377;&#19978;&#38480;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20986;&#27492;&#36807;&#31243;&#21487;&#25552;&#20379;&#26356;&#20934;&#30830;&#21644;&#31283;&#20581;&#30340;&#26368;&#39640;&#20998;&#20301;&#25968;&#20272;&#35745;&#65292;&#20174;&#32780;&#24212;&#29992;&#20110;&#23545;&#20110;&#24046;&#20998;&#38544;&#31169;&#27714;&#21644;&#21644;&#22343;&#20540;&#20272;&#35745;&#33267;&#20851;&#37325;&#35201;&#30340;&#25968;&#25454;&#21098;&#20999;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#20004;&#20010;&#35843;&#29992;&#22914;&#20309;&#22788;&#29702;&#23436;&#20840;&#26080;&#30028;&#30340;&#25968;&#25454;&#35774;&#32622;&#12290;&#22312;&#25105;&#20204;&#30340;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25913;&#36827;$\texttt{AboveThreshold}$&#30340;&#20998;&#26512;&#26041;&#27861;&#21487;&#20197;&#25552;&#39640;&#24191;&#27867;&#20351;&#29992;&#30340;&#31232;&#30095;&#21521;&#37327;&#25216;&#26415;&#30340;&#38544;&#31169;&#20445;&#38556;&#65288;&#36825;&#26159;&#29420;&#31435;&#20110;&#26412;&#25991;&#30340;&#20869;&#23481;&#65289;&#12290;&#25105;&#20204;&#32473;&#20986;&#20102;&#26356;&#26222;&#36941;&#30340;$\texttt{AboveThreshold}$&#38544;&#31169;&#25439;&#22833;&#29305;&#24449;&#65292;&#24182;&#23637;&#31034;&#20102;&#24046;&#20998;&#38544;&#31169;&#30340;&#26631;&#20934;&#32452;&#21512;&#35268;&#21017;&#21487;&#33021;&#20250;&#39640;&#20272;&#24635;&#20307;&#38544;&#31169;&#25439;&#22833;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work we consider the problem of differentially private computation of quantiles for the data, especially the highest quantiles such as maximum, but with an unbounded range for the dataset. We show that this can be done efficiently through a simple invocation of $\texttt{AboveThreshold}$, a subroutine that is iteratively called in the fundamental Sparse Vector Technique, even when there is no upper bound on the data. In particular, we show that this procedure can give more accurate and robust estimates on the highest quantiles with applications towards clipping that is essential for differentially private sum and mean estimation. In addition, we show how two invocations can handle the fully unbounded data setting. Within our study, we show that an improved analysis of $\texttt{AboveThreshold}$ can improve the privacy guarantees for the widely used Sparse Vector Technique that is of independent interest. We give a more general characterization of privacy loss for $\texttt{AboveTh
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#37327;&#20026;&#22522;&#30784;&#30340;&#20999;&#29255;Wasserstein&#36317;&#31163;&#65292;&#24182;&#23558;&#20854;&#21442;&#25968;&#21270;&#65292;&#20197;&#20811;&#26381;&#20256;&#32479;&#26041;&#27861;&#20013;&#30340;&#22266;&#23450;&#20808;&#39564;&#20998;&#24067;&#32570;&#20047;&#20449;&#24687;&#21644;&#20248;&#21270;&#26368;&#20339;&#20998;&#24067;&#26114;&#36149;&#19981;&#31283;&#23450;&#30340;&#23616;&#38480;&#12290;</title><link>http://arxiv.org/abs/2304.13586</link><description>&lt;p&gt;
&#33021;&#37327;&#20026;&#22522;&#30784;&#30340;&#20999;&#29255;Wasserstein&#36317;&#31163;
&lt;/p&gt;
&lt;p&gt;
Energy-Based Sliced Wasserstein Distance. (arXiv:2304.13586v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.13586
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#33021;&#37327;&#20026;&#22522;&#30784;&#30340;&#20999;&#29255;Wasserstein&#36317;&#31163;&#65292;&#24182;&#23558;&#20854;&#21442;&#25968;&#21270;&#65292;&#20197;&#20811;&#26381;&#20256;&#32479;&#26041;&#27861;&#20013;&#30340;&#22266;&#23450;&#20808;&#39564;&#20998;&#24067;&#32570;&#20047;&#20449;&#24687;&#21644;&#20248;&#21270;&#26368;&#20339;&#20998;&#24067;&#26114;&#36149;&#19981;&#31283;&#23450;&#30340;&#23616;&#38480;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20999;&#29255;Wasserstein&#65288;SW&#65289;&#36317;&#31163;&#34987;&#24191;&#27867;&#35748;&#20026;&#26159;&#20004;&#20010;&#27010;&#29575;&#27979;&#24230;&#20043;&#38388;&#30340;&#19968;&#31181;&#32479;&#35745;&#26377;&#25928;&#19988;&#35745;&#31639;&#39640;&#25928;&#30340;&#24230;&#37327;&#12290;SW&#36317;&#31163;&#30340;&#19968;&#20010;&#20851;&#38190;&#37096;&#20998;&#26159;&#20999;&#29255;&#20998;&#24067;&#12290;&#30446;&#21069;&#26377;&#20004;&#31181;&#26041;&#27861;&#26469;&#36873;&#25321;&#36825;&#20010;&#20998;&#24067;&#12290;&#31532;&#19968;&#31181;&#26041;&#27861;&#26159;&#20351;&#29992;&#22266;&#23450;&#30340;&#20808;&#39564;&#20998;&#24067;&#12290;&#31532;&#20108;&#31181;&#26159;&#20248;&#21270;&#24402;&#23646;&#20110;&#21442;&#25968;&#20998;&#24067;&#26063;&#30340;&#26368;&#20339;&#20998;&#24067;&#65292;&#24182;&#19988;&#21487;&#20197;&#26368;&#22823;&#21270;&#26399;&#26395;&#30340;&#36317;&#31163;&#12290;&#28982;&#32780;&#65292;&#36825;&#20004;&#31181;&#26041;&#27861;&#37117;&#26377;&#23616;&#38480;&#24615;&#12290;&#22266;&#23450;&#30340;&#20808;&#39564;&#20998;&#24067;&#22312;&#31361;&#20986;&#33021;&#22815;&#21306;&#20998;&#20004;&#20010;&#24120;&#35268;&#27010;&#29575;&#27979;&#24230;&#30340;&#25237;&#24433;&#26041;&#21521;&#26041;&#38754;&#32570;&#20047;&#20449;&#24687;&#12290;&#32780;&#20248;&#21270;&#26368;&#20339;&#20998;&#24067;&#36890;&#24120;&#26159;&#26114;&#36149;&#21644;&#19981;&#31283;&#23450;&#30340;&#12290;&#27492;&#22806;&#65292;&#35774;&#35745;&#20505;&#36873;&#20998;&#24067;&#30340;&#21442;&#25968;&#20998;&#24067;&#26063;&#21487;&#33021;&#20250;&#24456;&#23481;&#26131;&#34987;&#38169;&#35823;&#25351;&#23450;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#23558;&#20999;&#29255;&#20998;&#24067;&#35774;&#35745;&#20026;&#22522;&#20110;&#33021;&#37327;&#30340;&#20998;&#24067;&#65292;&#24182;&#23558;&#20854;&#21442;&#25968;&#21270;&#65292;&#20174;&#32780;&#20351;&#20854;&#26356;&#21152;&#36890;&#29992;&#32780;&#31283;&#20581;&#12290;
&lt;/p&gt;
&lt;p&gt;
The sliced Wasserstein (SW) distance has been widely recognized as a statistically effective and computationally efficient metric between two probability measures. A key component of the SW distance is the slicing distribution. There are two existing approaches for choosing this distribution. The first approach is using a fixed prior distribution. The second approach is optimizing for the best distribution which belongs to a parametric family of distributions and can maximize the expected distance. However, both approaches have their limitations. A fixed prior distribution is non-informative in terms of highlighting projecting directions that can discriminate two general probability measures. Doing optimization for the best distribution is often expensive and unstable. Moreover, designing the parametric family of the candidate distribution could be easily misspecified. To address the issues, we propose to design the slicing distribution as an energy-based distribution that is parameter
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;NF-ULA&#31639;&#27861;&#65292;&#20854;&#20013;&#21253;&#25324;&#23398;&#20064;&#27491;&#21017;&#21270;&#27969;&#20316;&#20026;&#20808;&#39564;&#65292;&#29992;&#20110;&#35299;&#20915;&#25104;&#20687;&#36870;&#38382;&#39064;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#37319;&#26679;&#31639;&#27861;&#65292;&#19988;&#26377;&#25928;&#24615;&#24471;&#21040;&#20102;&#22312;&#19977;&#20010;&#25104;&#20687;&#36870;&#38382;&#39064;&#19978;&#30340;&#35777;&#26126;&#12290;</title><link>http://arxiv.org/abs/2304.08342</link><description>&lt;p&gt;
&#24102;&#26377;&#27491;&#21017;&#21270;&#27969;&#20808;&#39564;&#30340;Langevin Monte Carlo&#29992;&#20110;&#25104;&#20687;&#36870;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
NF-ULA: Langevin Monte Carlo with Normalizing Flow Prior for Imaging Inverse Problems. (arXiv:2304.08342v1 [math.NA])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.08342
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;NF-ULA&#31639;&#27861;&#65292;&#20854;&#20013;&#21253;&#25324;&#23398;&#20064;&#27491;&#21017;&#21270;&#27969;&#20316;&#20026;&#20808;&#39564;&#65292;&#29992;&#20110;&#35299;&#20915;&#25104;&#20687;&#36870;&#38382;&#39064;&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#37319;&#26679;&#31639;&#27861;&#65292;&#19988;&#26377;&#25928;&#24615;&#24471;&#21040;&#20102;&#22312;&#19977;&#20010;&#25104;&#20687;&#36870;&#38382;&#39064;&#19978;&#30340;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#26041;&#27861;&#26159;&#35299;&#20915;&#36870;&#38382;&#39064;&#30340;&#19968;&#31181;&#24378;&#22823;&#26367;&#20195;&#26041;&#26696;&#65292;&#22240;&#20026;&#36125;&#21494;&#26031;&#26041;&#27861;&#25552;&#20379;&#20102;&#38382;&#39064;&#30340;&#27010;&#29575;&#25551;&#36848;&#24182;&#33021;&#22815;&#37327;&#21270;&#35299;&#20915;&#26041;&#26696;&#20013;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;&#26412;&#25991;&#23581;&#35797;&#23558;&#25968;&#25454;&#39537;&#21160;&#27169;&#22411;&#24182;&#20837;&#22522;&#20110;Langevin&#30340;&#36125;&#21494;&#26031;&#25512;&#26029;&#37319;&#26679;&#31639;&#27861;&#20013;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;NF-ULA&#65288;&#36890;&#36807;&#27491;&#21017;&#21270;&#27969;&#30340;&#26410;&#35843;&#25972;Langevin&#31639;&#27861;&#65289;&#65292;&#20854;&#20013;&#21253;&#25324;&#23398;&#20064;&#27491;&#21017;&#21270;&#27969;&#20316;&#20026;&#20808;&#39564;&#12290;&#25105;&#20204;&#36890;&#36807;&#35843;&#26597;&#36125;&#21494;&#26031;&#35299;&#30340;&#33391;&#22909;&#24615;&#21644;NF-ULA&#31639;&#27861;&#30340;&#38750;&#28176;&#36827;&#25910;&#25947;&#24615;&#36827;&#34892;&#29702;&#35770;&#20998;&#26512;&#12290;&#25105;&#20204;&#22312;&#19977;&#20010;&#25104;&#20687;&#36870;&#38382;&#39064;&#19978;&#36827;&#34892;&#30340;&#23454;&#39564;&#23637;&#31034;&#20102;&#25105;&#20204;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#65306;&#22270;&#20687;&#21435;&#27169;&#31946;&#65292;&#36229;&#20998;&#36776;&#29575;&#21644;&#35745;&#31639;&#26426;&#26029;&#23618;&#25195;&#25551;&#65288;CT&#65289;&#37325;&#24314;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian methods for solving inverse problems are a powerful alternative to classical methods since the Bayesian approach gives a probabilistic description of the problems and offers the ability to quantify the uncertainty in the solution. Meanwhile, solving inverse problems by data-driven techniques also proves to be successful, due to the increasing representation ability of data-based models. In this work, we try to incorporate the data-based models into a class of Langevin-based sampling algorithms in Bayesian inference. Loosely speaking, we introduce NF-ULA (Unadjusted Langevin algorithms by Normalizing Flows), which involves learning a normalizing flow as the prior. In particular, our algorithm only requires a pre-trained normalizing flow, which is independent of the considered inverse problem and the forward operator. We perform theoretical analysis by investigating the well-posedness of the Bayesian solution and the non-asymptotic convergence of the NF-ULA algorithm. The effica
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21457;&#23637;&#20102;PCA-Net&#30340;&#36817;&#20284;&#29702;&#35770;&#65292;&#24471;&#20986;&#20102;&#36890;&#29992;&#36924;&#36817;&#32467;&#26524;&#65292;&#24182;&#35782;&#21035;&#20986;&#20102;&#20351;&#29992;PCA-Net&#36827;&#34892;&#39640;&#25928;&#25805;&#20316;&#23398;&#20064;&#30340;&#28508;&#22312;&#38556;&#30861;&#65306;&#36755;&#20986;&#20998;&#24067;&#30340;&#22797;&#26434;&#24615;&#21644;&#31639;&#23376;&#31354;&#38388;&#30340;&#20869;&#22312;&#22797;&#26434;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.16317</link><description>&lt;p&gt;
PCA-Net&#65306;&#25805;&#20316;&#23398;&#20064;&#30340;&#22797;&#26434;&#24615;&#19978;&#19979;&#30028;
&lt;/p&gt;
&lt;p&gt;
Operator learning with PCA-Net: upper and lower complexity bounds. (arXiv:2303.16317v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16317
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21457;&#23637;&#20102;PCA-Net&#30340;&#36817;&#20284;&#29702;&#35770;&#65292;&#24471;&#20986;&#20102;&#36890;&#29992;&#36924;&#36817;&#32467;&#26524;&#65292;&#24182;&#35782;&#21035;&#20986;&#20102;&#20351;&#29992;PCA-Net&#36827;&#34892;&#39640;&#25928;&#25805;&#20316;&#23398;&#20064;&#30340;&#28508;&#22312;&#38556;&#30861;&#65306;&#36755;&#20986;&#20998;&#24067;&#30340;&#22797;&#26434;&#24615;&#21644;&#31639;&#23376;&#31354;&#38388;&#30340;&#20869;&#22312;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#31639;&#23376;&#22312;&#35745;&#31639;&#31185;&#23398;&#21644;&#24037;&#31243;&#20013;&#22791;&#21463;&#20851;&#27880;&#12290;PCA-Net&#26159;&#19968;&#31181;&#26368;&#36817;&#25552;&#20986;&#30340;&#31070;&#32463;&#31639;&#23376;&#26550;&#26500;&#65292;&#23427;&#23558;&#20027;&#25104;&#20998;&#20998;&#26512;(PCA)&#19982;&#31070;&#32463;&#32593;&#32476;&#30456;&#32467;&#21512;&#65292;&#20197;&#36924;&#36817;&#28508;&#22312;&#30340;&#31639;&#23376;&#12290;&#26412;&#25991;&#23545;&#36825;&#31181;&#26041;&#27861;&#36827;&#34892;&#20102;&#36817;&#20284;&#29702;&#35770;&#30340;&#21457;&#23637;&#65292;&#25913;&#36827;&#24182;&#26174;&#30528;&#25193;&#23637;&#20102;&#27492;&#26041;&#21521;&#30340;&#20197;&#21069;&#30340;&#24037;&#20316;&#12290;&#22312;&#23450;&#24615;&#30028;&#38480;&#26041;&#38754;&#65292;&#26412;&#25991;&#24471;&#20986;&#20102;&#26032;&#39062;&#30340;&#36890;&#29992;&#36924;&#36817;&#32467;&#26524;&#65292;&#22312;&#23545;&#28508;&#22312;&#31639;&#23376;&#21644;&#25968;&#25454;&#29983;&#25104;&#20998;&#24067;&#30340;&#26368;&#23567;&#20551;&#35774;&#30340;&#21069;&#25552;&#19979;&#12290;&#22312;&#23450;&#37327;&#38480;&#21046;&#26041;&#38754;&#65292;&#26412;&#25991;&#35782;&#21035;&#20102;&#20351;&#29992;PCA-Net&#36827;&#34892;&#39640;&#25928;&#25805;&#20316;&#23398;&#20064;&#30340;&#20004;&#20010;&#28508;&#22312;&#38556;&#30861;&#65292;&#36890;&#36807;&#23548;&#20986;&#19979;&#30028;&#36827;&#34892;&#20102;&#20005;&#26684;&#35777;&#26126;&#65292;&#31532;&#19968;&#20010;&#38556;&#30861;&#19982;&#36755;&#20986;&#20998;&#24067;&#30340;&#22797;&#26434;&#24615;&#26377;&#20851;&#65292;&#30001;PCA&#29305;&#24449;&#20540;&#30340;&#32531;&#24930;&#34928;&#20943;&#26469;&#34913;&#37327;&#65307;&#21478;&#19968;&#20010;&#38556;&#30861;&#28041;&#21450;&#26080;&#38480;&#32500;&#36755;&#20837;&#21644;&#36755;&#20986;&#31354;&#38388;&#20043;&#38388;&#30340;&#31639;&#23376;&#31354;&#38388;&#30340;&#20869;&#22312;&#22797;&#26434;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Neural operators are gaining attention in computational science and engineering. PCA-Net is a recently proposed neural operator architecture which combines principal component analysis (PCA) with neural networks to approximate an underlying operator. The present work develops approximation theory for this approach, improving and significantly extending previous work in this direction. In terms of qualitative bounds, this paper derives a novel universal approximation result, under minimal assumptions on the underlying operator and the data-generating distribution. In terms of quantitative bounds, two potential obstacles to efficient operator learning with PCA-Net are identified, and made rigorous through the derivation of lower complexity bounds; the first relates to the complexity of the output distribution, measured by a slow decay of the PCA eigenvalues. The other obstacle relates the inherent complexity of the space of operators between infinite-dimensional input and output spaces, 
&lt;/p&gt;</description></item><item><title>&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21453;&#20107;&#23454;&#22330;&#26223;&#27979;&#35797;&#26694;&#26550;&#65292;&#36890;&#36807;&#27604;&#36739;&#25968;&#25454;&#38598;&#20013;&#31867;&#20284;&#30340;&#20445;&#25252;&#21644;&#38750;&#20445;&#25252;&#23454;&#20363;&#26469;&#26816;&#27979;&#20998;&#31867;&#22120;&#20013;&#30340;&#27495;&#35270;&#65292;&#36890;&#36807;&#27604;&#36739;&#32452;&#38388;&#20915;&#31574;&#32467;&#26524;&#24046;&#24322;&#65292;&#26469;&#21457;&#29616;&#20010;&#20154;&#27495;&#35270;&#12290;&#35813;&#26694;&#26550;&#21487;&#20197;&#26356;&#22909;&#22320;&#23545;&#12300;&#32473;&#23450;&#24046;&#24322;&#30340;&#20844;&#24179;&#21407;&#21017;&#12301;&#36827;&#34892;&#25805;&#20316;&#65292;&#20197;&#25581;&#31034;&#22312;&#20844;&#24179;&#21407;&#21017;&#19979;&#30340;&#27495;&#35270;&#24046;&#24322;&#12290;</title><link>http://arxiv.org/abs/2302.11944</link><description>&lt;p&gt;
&#27979;&#35797;&#21453;&#20107;&#23454;&#22330;&#26223;&#65306;&#25581;&#31034;&#22312;&#20844;&#24179;&#21407;&#21017;&#19979;&#30340;&#27495;&#35270;&#24046;&#24322; (arXiv:2302.11944v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
Counterfactual Situation Testing: Uncovering Discrimination under Fairness given the Difference. (arXiv:2302.11944v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.11944
&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21453;&#20107;&#23454;&#22330;&#26223;&#27979;&#35797;&#26694;&#26550;&#65292;&#36890;&#36807;&#27604;&#36739;&#25968;&#25454;&#38598;&#20013;&#31867;&#20284;&#30340;&#20445;&#25252;&#21644;&#38750;&#20445;&#25252;&#23454;&#20363;&#26469;&#26816;&#27979;&#20998;&#31867;&#22120;&#20013;&#30340;&#27495;&#35270;&#65292;&#36890;&#36807;&#27604;&#36739;&#32452;&#38388;&#20915;&#31574;&#32467;&#26524;&#24046;&#24322;&#65292;&#26469;&#21457;&#29616;&#20010;&#20154;&#27495;&#35270;&#12290;&#35813;&#26694;&#26550;&#21487;&#20197;&#26356;&#22909;&#22320;&#23545;&#12300;&#32473;&#23450;&#24046;&#24322;&#30340;&#20844;&#24179;&#21407;&#21017;&#12301;&#36827;&#34892;&#25805;&#20316;&#65292;&#20197;&#25581;&#31034;&#22312;&#20844;&#24179;&#21407;&#21017;&#19979;&#30340;&#27495;&#35270;&#24046;&#24322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#34987;&#31216;&#20026;&#21453;&#20107;&#23454;&#22330;&#26223;&#27979;&#35797;(CST)&#30340;&#22240;&#26524;&#25968;&#25454;&#25366;&#25496;&#26694;&#26550;&#26469;&#26816;&#27979;&#20998;&#31867;&#22120;&#20013;&#30340;&#27495;&#35270;&#24773;&#20917;&#12290;CST&#26088;&#22312;&#20197;&#21487;&#25805;&#20316;&#19988;&#26377;&#24847;&#20041;&#30340;&#26041;&#24335;&#22238;&#31572;&#19968;&#31181;&#30452;&#35266;&#38382;&#39064;&#65306;&#8220;&#22914;&#26524;&#20010;&#20154;&#25110;&#25237;&#35785;&#20154;&#25152;&#23646;&#30340;&#21463;&#20445;&#25252;&#36523;&#20221;&#19981;&#21516;&#65292;&#27169;&#22411;&#30340;&#32467;&#26524;&#23558;&#20250;&#26159;&#20160;&#20040;&#65311;&#8221;&#23427;&#36890;&#36807;&#21453;&#20107;&#23454;&#25512;&#29702;&#26469;&#23545;&#27861;&#24459;&#22522;&#30784;&#30340;&#24773;&#26223;&#27979;&#35797;&#36827;&#34892;&#25193;&#23637;&#65292;&#20197;&#25805;&#20316;&#8220;&#32473;&#23450;&#24046;&#24322;&#30340;&#20844;&#24179;&#21407;&#21017;&#8221;&#30340;&#27010;&#24565;&#12290;&#23545;&#20110;&#20219;&#20309;&#25237;&#35785;&#20154;&#65292;&#25105;&#20204;&#22312;&#20998;&#31867;&#22120;&#20351;&#29992;&#30340;&#25968;&#25454;&#38598;&#20013;&#25214;&#21040;&#24182;&#27604;&#36739;&#30456;&#20284;&#30340;&#21463;&#20445;&#25252;&#21644;&#38750;&#21463;&#20445;&#25252;&#23454;&#20363;&#65292;&#26500;&#36896;&#25511;&#21046;&#32452;&#21644;&#27979;&#35797;&#32452;&#65292;&#20004;&#32452;&#30340;&#20915;&#31574;&#32467;&#26524;&#24046;&#24322;&#24847;&#21619;&#30528;&#28508;&#22312;&#30340;&#20010;&#20154;&#27495;&#35270;&#12290;&#19982;&#24773;&#22659;&#27979;&#35797;&#19981;&#21516;&#65292;&#24773;&#22659;&#27979;&#35797;&#26159;&#22260;&#32469;&#25237;&#35785;&#20154;&#26500;&#24314;&#20004;&#32452;&#65292;&#25105;&#20204;&#26681;&#25454;&#22240;&#26524;&#30693;&#35782;&#22312;&#25237;&#35785;&#20154;&#30340;&#21453;&#20107;&#23454;&#29983;&#25104;&#27979;&#35797;&#32452;&#12290;&#21453;&#20107;&#23454;&#26088;&#22312;&#21453;&#26144;&#21463;&#20445;&#25252;&#23646;&#24615;&#23545;&#32467;&#26524;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present counterfactual situation testing (CST), a causal data mining framework for detecting discrimination in classifiers. CST aims to answer in an actionable and meaningful way the intuitive question "what would have been the model outcome had the individual, or complainant, been of a different protected status?" It extends the legally-grounded situation testing of Thanh et al. (2011) by operationalizing the notion of fairness given the difference using counterfactual reasoning. For any complainant, we find and compare similar protected and non-protected instances in the dataset used by the classifier to construct a control and test group, where a difference between the decision outcomes of the two groups implies potential individual discrimination. Unlike situation testing, which builds both groups around the complainant, we build the test group on the complainant's counterfactual generated using causal knowledge. The counterfactual is intended to reflect how the protected attrib
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;"Nesterov's&#21152;&#36895;"&#30340;&#22806;&#25512;&#31639;&#27861;&#26469;&#36924;&#36817;&#20849;&#36229;&#21333;&#35843;&#21253;&#21547;&#20851;&#31995;&#30340;&#35299;&#65292;&#20998;&#21035;&#20026;&#20869;&#26031;&#29305;&#32599;&#22827;&#21152;&#36895;&#30340;Tseng&#21069;-&#21518;-&#21069;&#20998;&#35010;&#27861;&#21644;&#36807;&#21435;FBFS&#27861;&#65292;&#20004;&#31181;&#31639;&#27861;&#37117;&#36798;&#21040;&#20102;$\mathcal{O}(1/k)$&#30340;&#26368;&#32456;&#36845;&#20195;&#25910;&#25947;&#36895;&#24230;&#12290;</title><link>http://arxiv.org/abs/2302.04099</link><description>&lt;p&gt;
&#20855;&#26377;$\mathcal{O} (1/k)$&#26368;&#32456;&#36845;&#20195;&#25910;&#25947;&#36895;&#24230;&#30340;&#23545;&#20598;&#20122;&#26497;&#21333;&#35843;&#36882;&#25512;&#26041;&#27861;&#65292;&#29992;&#20110;&#20849;&#36229;&#21333;&#35843;&#21253;&#21547;&#20851;&#31995;
&lt;/p&gt;
&lt;p&gt;
Extragradient-Type Methods with $\mathcal{O} (1/k)$ Last-Iterate Convergence Rates for Co-Hypomonotone Inclusions. (arXiv:2302.04099v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.04099
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;"Nesterov's&#21152;&#36895;"&#30340;&#22806;&#25512;&#31639;&#27861;&#26469;&#36924;&#36817;&#20849;&#36229;&#21333;&#35843;&#21253;&#21547;&#20851;&#31995;&#30340;&#35299;&#65292;&#20998;&#21035;&#20026;&#20869;&#26031;&#29305;&#32599;&#22827;&#21152;&#36895;&#30340;Tseng&#21069;-&#21518;-&#21069;&#20998;&#35010;&#27861;&#21644;&#36807;&#21435;FBFS&#27861;&#65292;&#20004;&#31181;&#31639;&#27861;&#37117;&#36798;&#21040;&#20102;$\mathcal{O}(1/k)$&#30340;&#26368;&#32456;&#36845;&#20195;&#25910;&#25947;&#36895;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24320;&#21457;&#20102;&#20004;&#31181;"&#20869;&#26031;&#29305;&#32599;&#22827;&#21152;&#36895;"&#30340;&#21464;&#31181;&#22806;&#25512;&#27861;&#26469;&#36924;&#36817;&#30001;&#20004;&#20010;&#31639;&#23376;&#20043;&#21644;&#26500;&#25104;&#30340;&#20849;&#36229;&#21333;&#35843;&#21253;&#21547;&#20851;&#31995;&#30340;&#35299;&#65292;&#20854;&#20013;&#19968;&#20010;&#26159;Lipschitz&#36830;&#32493;&#30340;&#65292;&#21478;&#19968;&#20010;&#21487;&#33021;&#26159;&#22810;&#20540;&#30340;&#12290;&#31532;&#19968;&#31181;&#26041;&#26696;&#21487;&#20197;&#30475;&#20316;&#26159;&#26366;'s&#21069;-&#21518;-&#21069;&#20998;&#35010;&#31639;&#27861;&#30340;&#21152;&#36895;&#21464;&#31181;&#65292;&#32780;&#31532;&#20108;&#31181;&#26041;&#26696;&#26159;"Nesterov's&#21152;&#36895;&#21464;&#31181;&#30340;"&#36807;&#21435;FBFS&#26041;&#26696;&#65292;&#35813;&#26041;&#26696;&#21482;&#38656;&#35201;&#23545;Lipschitz&#31639;&#23376;&#36827;&#34892;&#19968;&#27425;&#35780;&#20272;&#21644;&#22810;&#20540;&#26144;&#23556;&#36827;&#34892;&#19968;&#27425;&#35299;&#31639;&#12290;&#22312;&#21442;&#25968;&#36866;&#24403;&#30340;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#22312;&#29702;&#35770;&#19978;&#35777;&#26126;&#20102;&#36825;&#20004;&#31181;&#31639;&#27861;&#22312;&#21097;&#20313;&#33539;&#25968;&#19978;&#23454;&#29616;&#20102;$\mathcal{O}(1/k)$&#30340;&#26368;&#32456;&#36845;&#20195;&#25910;&#25947;&#36895;&#24230;&#65292;&#20854;&#20013;$k$&#26159;&#36845;&#20195;&#35745;&#25968;&#22120;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#21487;&#20197;&#30475;&#20316;&#26159;&#29992;&#20110;&#26681;&#26597;&#25214;&#38382;&#39064;&#30340;&#26368;&#36817;&#19968;&#31867;Halpern&#22411;&#26041;&#27861;&#30340;&#26367;&#20195;&#26041;&#26696;&#12290;&#20026;&#20102;&#27604;&#36739;&#65292;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#20004;&#31181;&#26368;&#36817;&#30340;&#39069;&#22806;&#38170;&#23450;&#26799;&#24230;&#22411;&#26041;&#27861;&#30340;&#26032;&#25910;&#25947;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop two "Nesterov's accelerated" variants of the well-known extragradient method to approximate a solution of a co-hypomonotone inclusion constituted by the sum of two operators, where one is Lipschitz continuous and the other is possibly multivalued. The first scheme can be viewed as an accelerated variant of Tseng's forward-backward-forward splitting (FBFS) method, while the second one is a Nesterov's accelerated variant of the "past" FBFS scheme, which requires only one evaluation of the Lipschitz operator and one resolvent of the multivalued mapping. Under appropriate conditions on the parameters, we theoretically prove that both algorithms achieve $\mathcal{O}(1/k)$ last-iterate convergence rates on the residual norm, where $k$ is the iteration counter. Our results can be viewed as alternatives of a recent class of Halpern-type methods for root-finding problems. For comparison, we also provide a new convergence analysis of the two recent extra-anchored gradient-type methods
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#25551;&#32472;&#26080;&#23703;&#20301;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#22312;&#27604;&#20363;&#21306;&#22495;&#19979;&#30340;&#26679;&#26412;&#22806;&#39044;&#27979;&#39118;&#38505;&#65292;&#25361;&#25112;&#20102;&#20256;&#32479;&#35266;&#24565;&#65292;&#24182;&#21457;&#29616;&#19979;&#37319;&#26679;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#21487;&#20197;&#25913;&#21892;&#27867;&#21270;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#26368;&#20339;&#32553;&#30053;&#22270;&#22823;&#23567;&#24182;&#25552;&#20986;&#20102;&#23454;&#38469;&#23454;&#26045;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2302.01088</link><description>&lt;p&gt;
&#36890;&#36807;&#19979;&#37319;&#26679;&#65292;&#25551;&#32472;&#26080;&#23703;&#20301;&#32447;&#24615;&#22238;&#24402;&#65306;&#19979;&#37319;&#26679;&#30340;&#20316;&#29992;
&lt;/p&gt;
&lt;p&gt;
Sketched Ridgeless Linear Regression: The Role of Downsampling. (arXiv:2302.01088v2 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.01088
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#25551;&#32472;&#26080;&#23703;&#20301;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#22312;&#27604;&#20363;&#21306;&#22495;&#19979;&#30340;&#26679;&#26412;&#22806;&#39044;&#27979;&#39118;&#38505;&#65292;&#25361;&#25112;&#20102;&#20256;&#32479;&#35266;&#24565;&#65292;&#24182;&#21457;&#29616;&#19979;&#37319;&#26679;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#21487;&#20197;&#25913;&#21892;&#27867;&#21270;&#65292;&#25105;&#20204;&#30830;&#23450;&#20102;&#26368;&#20339;&#32553;&#30053;&#22270;&#22823;&#23567;&#24182;&#25552;&#20986;&#20102;&#23454;&#38469;&#23454;&#26045;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36807;&#24230;&#21442;&#25968;&#21270;&#36890;&#24120;&#26377;&#21161;&#20110;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#36807;&#24230;&#21442;&#25968;&#21270;&#30340;&#21452;&#37325;&#35270;&#35282;&#65292;&#24182;&#35748;&#20026;&#19979;&#37319;&#26679;&#20063;&#21487;&#20197;&#24110;&#21161;&#27867;&#21270;&#12290;&#25105;&#20204;&#38024;&#23545;&#27604;&#20363;&#21306;&#22495;$m\asymp n \asymp p$&#36827;&#34892;&#20102;&#30740;&#31350;&#65292;&#20854;&#20013;$m$&#34920;&#31034;&#32553;&#30053;&#22270;&#22823;&#23567;&#65292;$n$&#26159;&#26679;&#26412;&#22823;&#23567;&#65292;$p$&#26159;&#29305;&#24449;&#32500;&#24230;&#65292;&#30740;&#31350;&#20102;&#25551;&#32472;&#26080;&#23703;&#20301;&#26368;&#23567;&#20108;&#20056;&#20272;&#35745;&#22120;&#30340;&#20004;&#20010;&#26679;&#26412;&#22806;&#39044;&#27979;&#39118;&#38505;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#25361;&#25112;&#20102;&#20256;&#32479;&#35266;&#24565;&#65292;&#34920;&#26126;&#19979;&#37319;&#26679;&#19981;&#24635;&#26159;&#23545;&#27867;&#21270;&#26377;&#23475;&#65292;&#32780;&#22312;&#26576;&#20123;&#24773;&#20917;&#19979;&#23454;&#38469;&#19978;&#21487;&#20197;&#25913;&#21892;&#27867;&#21270;&#12290;&#25105;&#20204;&#30830;&#23450;&#20102;&#26368;&#23567;&#21270;&#26679;&#26412;&#22806;&#39044;&#27979;&#39118;&#38505;&#30340;&#26368;&#20339;&#32553;&#30053;&#22270;&#22823;&#23567;&#65292;&#24182;&#35777;&#26126;&#20102;&#26368;&#20248;&#32553;&#30053;&#22270;&#20272;&#35745;&#22120;&#26174;&#31034;&#20986;&#26356;&#31283;&#23450;&#30340;&#39118;&#38505;&#26354;&#32447;&#65292;&#28040;&#38500;&#20102;&#23436;&#20840;&#26679;&#26412;&#20272;&#35745;&#22120;&#30340;&#23792;&#20540;&#12290;&#20026;&#20102;&#20415;&#20110;&#23454;&#38469;&#23454;&#26045;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#30830;&#23450;&#26368;&#20339;&#32553;&#30053;&#22270;&#22823;&#23567;&#30340;&#32463;&#39564;&#26041;&#27861;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25193;&#23637;&#20102;&#25105;&#20204;&#30340;&#20998;&#26512;&#65292;&#28085;&#30422;&#20102;&#20013;&#24515;&#26497;&#38480;&#23450;&#29702;&#12290;
&lt;/p&gt;
&lt;p&gt;
Overparametrization often helps improve the generalization performance. This paper presents a dual view of overparametrization suggesting that downsampling may also help generalize. Focusing on the proportional regime $m\asymp n \asymp p$, where $m$ represents the sketching size, $n$ is the sample size, and $p$ is the feature dimensionality, we investigate two out-of-sample prediction risks of the sketched ridgeless least square estimator. Our findings challenge conventional beliefs by showing that downsampling does not always harm generalization but can actually improve it in certain cases. We identify the optimal sketching size that minimizes out-of-sample prediction risks and demonstrate that the optimally sketched estimator exhibits stabler risk curves, eliminating the peaks of those for the full-sample estimator. To facilitate practical implementation, we propose an empirical procedure to determine the optimal sketching size. Finally, we extend our analysis to cover central limit 
&lt;/p&gt;</description></item><item><title>&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#33021;&#22815;&#25918;&#22823;&#20915;&#31574;&#36793;&#30028;&#38468;&#36817;&#30340;&#23616;&#37096;&#21306;&#22495;&#65292;&#25913;&#21892;&#25972;&#20010;&#31995;&#32479;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2301.11375</link><description>&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#25918;&#22823;&#20915;&#31574;&#36793;&#30028;&#38468;&#36817;&#30340;&#21306;&#22495;
&lt;/p&gt;
&lt;p&gt;
Neural networks learn to magnify areas near decision boundaries. (arXiv:2301.11375v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.11375
&lt;/p&gt;
&lt;p&gt;
&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#33021;&#22815;&#25918;&#22823;&#20915;&#31574;&#36793;&#30028;&#38468;&#36817;&#30340;&#23616;&#37096;&#21306;&#22495;&#65292;&#25913;&#21892;&#25972;&#20010;&#31995;&#32479;&#30340;&#27867;&#21270;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#35757;&#32451;&#22914;&#20309;&#22609;&#36896;&#31070;&#32463;&#32593;&#32476;&#29305;&#24449;&#22270;&#35825;&#23548;&#30340;&#40654;&#26364;&#20960;&#20309;&#12290;&#22312;&#23485;&#24230;&#20026;&#26080;&#38480;&#30340;&#24773;&#20917;&#19979;&#65292;&#20855;&#26377;&#38543;&#26426;&#21442;&#25968;&#30340;&#31070;&#32463;&#32593;&#32476;&#22312;&#36755;&#20837;&#31354;&#38388;&#19978;&#24341;&#23548;&#39640;&#24230;&#23545;&#31216;&#30340;&#24230;&#37327;&#12290;&#35757;&#32451;&#20998;&#31867;&#20219;&#21153;&#30340;&#32593;&#32476;&#20013;&#30340;&#29305;&#24449;&#23398;&#20064;&#25918;&#22823;&#20102;&#27839;&#20915;&#31574;&#36793;&#30028;&#30340;&#23616;&#37096;&#21306;&#22495;&#12290;&#36825;&#20123;&#21464;&#21270;&#19982;&#20808;&#21069;&#25552;&#20986;&#30340;&#29992;&#20110;&#25163;&#21160;&#35843;&#25972;&#26680;&#26041;&#27861;&#20197;&#25913;&#21892;&#27867;&#21270;&#30340;&#20960;&#20309;&#26041;&#27861;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study how training molds the Riemannian geometry induced by neural network feature maps. At infinite width, neural networks with random parameters induce highly symmetric metrics on input space. Feature learning in networks trained to perform classification tasks magnifies local areas along decision boundaries. These changes are consistent with previously proposed geometric approaches for hand-tuning of kernel methods to improve generalization.
&lt;/p&gt;</description></item><item><title>&#39532;&#23572;&#21487;&#22827;&#20999;&#29255;Wasserstein&#65288;MSW&#65289;&#36317;&#31163;&#26159;&#19968;&#31181;&#26032;&#30340;SW&#36317;&#31163;&#23478;&#26063;&#65292;&#36890;&#36807;&#22312;&#25237;&#24433;&#26041;&#21521;&#19978;&#26045;&#21152;&#19968;&#38454;&#39532;&#23572;&#21487;&#22827;&#32467;&#26500;&#65292;&#35299;&#20915;&#20102;&#20999;&#29255;Wasserstein&#65288;SW&#65289;&#36317;&#31163;&#20013;&#29420;&#31435;&#25237;&#24433;&#23548;&#33268;&#30340;&#20887;&#20313;&#25237;&#24433;&#30340;&#38382;&#39064;&#65292;&#24182;&#19988;&#20855;&#26377;&#36739;&#20302;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;&#65288;found in translation&#65289;</title><link>http://arxiv.org/abs/2301.03749</link><description>&lt;p&gt;
&#39532;&#23572;&#21487;&#22827;&#20999;&#29255;Wasserstein&#36317;&#31163;&#65306;&#36229;&#36234;&#29420;&#31435;&#25237;&#24433;
&lt;/p&gt;
&lt;p&gt;
Markovian Sliced Wasserstein Distances: Beyond Independent Projections. (arXiv:2301.03749v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.03749
&lt;/p&gt;
&lt;p&gt;
&#39532;&#23572;&#21487;&#22827;&#20999;&#29255;Wasserstein&#65288;MSW&#65289;&#36317;&#31163;&#26159;&#19968;&#31181;&#26032;&#30340;SW&#36317;&#31163;&#23478;&#26063;&#65292;&#36890;&#36807;&#22312;&#25237;&#24433;&#26041;&#21521;&#19978;&#26045;&#21152;&#19968;&#38454;&#39532;&#23572;&#21487;&#22827;&#32467;&#26500;&#65292;&#35299;&#20915;&#20102;&#20999;&#29255;Wasserstein&#65288;SW&#65289;&#36317;&#31163;&#20013;&#29420;&#31435;&#25237;&#24433;&#23548;&#33268;&#30340;&#20887;&#20313;&#25237;&#24433;&#30340;&#38382;&#39064;&#65292;&#24182;&#19988;&#20855;&#26377;&#36739;&#20302;&#30340;&#35745;&#31639;&#22797;&#26434;&#24230;&#12290;&#65288;found in translation&#65289;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20999;&#29255;Wasserstein&#65288;SW&#65289;&#36317;&#31163;&#30001;&#20110;&#29420;&#31435;&#30340;&#22343;&#21248;&#38543;&#26426;&#25237;&#24433;&#26041;&#21521;&#32780;&#23548;&#33268;&#20887;&#20313;&#25237;&#24433;&#12290;&#20026;&#20102;&#37096;&#20998;&#20811;&#26381;&#36825;&#20010;&#38382;&#39064;&#65292;&#26368;&#22823;K&#20999;&#29255;Wasserstein&#65288;Max-K-SW&#65289;&#36317;&#31163;&#65288;$K\geq1$&#65289;&#23547;&#27714;&#26368;&#20339;&#30340;&#21306;&#20998;&#27491;&#20132;&#25237;&#24433;&#26041;&#21521;&#12290;&#23613;&#31649;&#33021;&#22815;&#20943;&#23569;&#25237;&#24433;&#25968;&#37327;&#65292;&#20294;Max-K-SW&#30340;&#24230;&#37327;&#24615;&#22312;&#23454;&#36341;&#20013;&#19981;&#33021;&#20445;&#35777;&#65292;&#21407;&#22240;&#26159;&#20248;&#21270;&#30340;&#38750;&#26368;&#20248;&#24615;&#12290;&#27492;&#22806;&#65292;&#27491;&#20132;&#32422;&#26463;&#20063;&#22312;&#35745;&#31639;&#19978;&#26159;&#26114;&#36149;&#30340;&#65292;&#21487;&#33021;&#19981;&#22826;&#26377;&#25928;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;SW&#36317;&#31163;&#23478;&#26063;&#65292;&#31216;&#20026;&#39532;&#23572;&#21487;&#22827;&#20999;&#29255;Wasserstein&#65288;MSW&#65289;&#36317;&#31163;&#65292;&#23427;&#22312;&#25237;&#24433;&#26041;&#21521;&#19978;&#26045;&#21152;&#20102;&#19968;&#38454;&#39532;&#23572;&#21487;&#22827;&#32467;&#26500;&#12290;&#25105;&#20204;&#36890;&#36807;&#25351;&#23450;&#39532;&#23572;&#21487;&#22827;&#32467;&#26500;&#65292;&#21253;&#25324;&#20808;&#39564;&#20998;&#24067;&#12289;&#36716;&#31227;&#20998;&#24067;&#20197;&#21450;&#29123;&#28903;&#21644;&#31232;&#30095;&#21270;&#25216;&#26415;&#65292;&#35752;&#35770;&#20102;MSW&#30340;&#21508;&#31181;&#25104;&#21592;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#30740;&#31350;&#20102;MSW&#30340;&#29702;&#35770;&#24615;&#36136;&#65292;&#21253;&#25324;&#25299;&#25169;&#24615;&#36136;&#65288;found in translation&#65289;
&lt;/p&gt;
&lt;p&gt;
Sliced Wasserstein (SW) distance suffers from redundant projections due to independent uniform random projecting directions. To partially overcome the issue, max K sliced Wasserstein (Max-K-SW) distance ($K\geq 1$), seeks the best discriminative orthogonal projecting directions. Despite being able to reduce the number of projections, the metricity of Max-K-SW cannot be guaranteed in practice due to the non-optimality of the optimization. Moreover, the orthogonality constraint is also computationally expensive and might not be effective. To address the problem, we introduce a new family of SW distances, named Markovian sliced Wasserstein (MSW) distance, which imposes a first-order Markov structure on projecting directions. We discuss various members of MSW by specifying the Markov structure including the prior distribution, the transition distribution, and the burning and thinning technique. Moreover, we investigate the theoretical properties of MSW including topological properties (met
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25913;&#36827;&#20102;&#20808;&#21069;&#24369;&#19968;&#33268;&#24615;&#38543;&#26426;&#26862;&#26519;&#21464;&#20307;&#30340;&#35777;&#26126;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#22810;&#39033;&#24335;&#38543;&#26426;&#26862;&#26519;&#65288;DMRF&#65289;&#65292;&#24182;&#34920;&#26126;DMRF&#22312;&#20998;&#31867;&#21644;&#22238;&#24402;&#38382;&#39064;&#20013;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#23454;&#29616;&#20102;&#27010;&#29575;1&#30340;&#24378;&#19968;&#33268;&#24615;&#12290;</title><link>http://arxiv.org/abs/2211.15154</link><description>&lt;p&gt;
&#25968;&#25454;&#39537;&#21160;&#30340;&#22810;&#39033;&#24335;&#38543;&#26426;&#26862;&#26519;: &#19968;&#31181;&#20855;&#26377;&#24378;&#19968;&#33268;&#24615;&#30340;&#26032;&#38543;&#26426;&#26862;&#26519;&#21464;&#20307;
&lt;/p&gt;
&lt;p&gt;
Data-driven multinomial random forest: A new random forest variant with strong consistency. (arXiv:2211.15154v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.15154
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25913;&#36827;&#20102;&#20808;&#21069;&#24369;&#19968;&#33268;&#24615;&#38543;&#26426;&#26862;&#26519;&#21464;&#20307;&#30340;&#35777;&#26126;&#26041;&#27861;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#22810;&#39033;&#24335;&#38543;&#26426;&#26862;&#26519;&#65288;DMRF&#65289;&#65292;&#24182;&#34920;&#26126;DMRF&#22312;&#20998;&#31867;&#21644;&#22238;&#24402;&#38382;&#39064;&#20013;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#23454;&#29616;&#20102;&#27010;&#29575;1&#30340;&#24378;&#19968;&#33268;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#23558;&#19968;&#20123;&#20808;&#21069;&#24369;&#19968;&#33268;&#24615;&#38543;&#26426;&#26862;&#26519;&#21464;&#20307;&#30340;&#35777;&#26126;&#26041;&#27861;&#20462;&#25913;&#20026;&#24378;&#19968;&#33268;&#24615;&#35777;&#26126;&#26041;&#27861;&#65292;&#24182;&#25913;&#36827;&#20102;&#36825;&#20123;&#21464;&#20307;&#30340;&#25968;&#25454;&#21033;&#29992;&#65292;&#20197;&#33719;&#24471;&#26356;&#22909;&#30340;&#29702;&#35770;&#24615;&#36136;&#21644;&#23454;&#39564;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#22810;&#39033;&#24335;&#38543;&#26426;&#26862;&#26519;&#65288;DMRF&#65289;&#65292;&#20854;&#19982;BreimanRF&#65288;&#30001;Breiman&#25552;&#20986;&#65289;&#20855;&#26377;&#30456;&#21516;&#30340;&#22797;&#26434;&#24230;&#65292;&#21516;&#26102;&#20197;&#27010;&#29575;1&#28385;&#36275;&#24378;&#19968;&#33268;&#24615;&#12290;&#22312;&#20998;&#31867;&#21644;&#22238;&#24402;&#38382;&#39064;&#19978;&#65292;&#23427;&#27604;&#20808;&#21069;&#20165;&#28385;&#36275;&#24369;&#19968;&#33268;&#24615;&#30340;RF&#21464;&#20307;&#20855;&#26377;&#26356;&#22909;&#30340;&#24615;&#33021;&#65292;&#24182;&#19988;&#22312;&#22823;&#22810;&#25968;&#24773;&#20917;&#19979;&#29978;&#33267;&#36229;&#36807;&#20102;BreimanRF&#22312;&#20998;&#31867;&#20219;&#21153;&#19978;&#30340;&#34920;&#29616;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;DMRF&#26159;&#24403;&#21069;&#23454;&#29616;&#20102;&#27010;&#29575;1&#30340;&#24378;&#19968;&#33268;&#24615;&#30340;&#20302;&#22797;&#26434;&#24615;&#21644;&#39640;&#24615;&#33021;&#38543;&#26426;&#26862;&#26519;&#30340;&#19968;&#31181;&#21464;&#20307;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we modify the proof methods of some previously weakly consistent variants of random forests into strongly consistent proof methods, and improve the data utilization of these variants in order to obtain better theoretical properties and experimental performance. In addition, we propose a data-driven multinomial random forest (DMRF), which has the same complexity with BreimanRF (proposed by Breiman) while satisfying strong consistency with probability 1. It has better performance in classification and regression problems than previous RF variants that only satisfy weak consistency, and in most cases even surpasses BreimanRF in classification tasks. To the best of our knowledge, DMRF is currently a low-complexity and high-performing variation of random forests that achieves strong consistency with probability 1.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26377;&#25928;&#30340;&#32437;&#21521;&#32593;&#32476;&#20272;&#35745;&#26694;&#26550;&#65292;&#21033;&#29992;&#33258;&#36866;&#24212;&#21512;&#24182;&#12289;&#24352;&#37327;&#20998;&#35299;&#21644;&#28857;&#36807;&#31243;&#31561;&#26041;&#27861;&#26469;&#20943;&#23569;&#20272;&#35745;&#20559;&#24046;&#21644;&#26041;&#24046;&#12290;</title><link>http://arxiv.org/abs/2211.07866</link><description>&lt;p&gt;
&#33258;&#36866;&#24212;&#21512;&#24182;&#19979;&#30340;&#32437;&#21521;&#32593;&#32476;&#26377;&#25928;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Efficient Estimation for Longitudinal Network via Adaptive Merging. (arXiv:2211.07866v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.07866
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26377;&#25928;&#30340;&#32437;&#21521;&#32593;&#32476;&#20272;&#35745;&#26694;&#26550;&#65292;&#21033;&#29992;&#33258;&#36866;&#24212;&#21512;&#24182;&#12289;&#24352;&#37327;&#20998;&#35299;&#21644;&#28857;&#36807;&#31243;&#31561;&#26041;&#27861;&#26469;&#20943;&#23569;&#20272;&#35745;&#20559;&#24046;&#21644;&#26041;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32437;&#21521;&#32593;&#32476;&#30001;&#22810;&#20010;&#33410;&#28857;&#20043;&#38388;&#30340;&#26102;&#38388;&#36793;&#24207;&#21015;&#32452;&#25104;&#65292;&#20854;&#20013;&#26102;&#38388;&#36793;&#22312;&#23454;&#26102;&#20013;&#34987;&#35266;&#23519;&#21040;&#12290;&#38543;&#30528;&#22312;&#32447;&#31038;&#20132;&#24179;&#21488;&#21644;&#30005;&#23376;&#21830;&#21153;&#30340;&#20852;&#36215;&#65292;&#23427;&#24050;&#32463;&#21464;&#24471;&#26222;&#36941;&#65292;&#20294;&#22312;&#25991;&#29486;&#20013;&#24448;&#24448;&#34987;&#24573;&#30053;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26377;&#25928;&#30340;&#32437;&#21521;&#32593;&#32476;&#20272;&#35745;&#26694;&#26550;&#65292;&#21033;&#29992;&#33258;&#36866;&#24212;&#32593;&#32476;&#21512;&#24182;&#12289;&#24352;&#37327;&#20998;&#35299;&#21644;&#28857;&#36807;&#31243;&#30340;&#20248;&#21183;&#12290;&#23427;&#21512;&#24182;&#30456;&#37051;&#30340;&#31232;&#30095;&#32593;&#32476;&#65292;&#20197;&#25193;&#22823;&#35266;&#27979;&#36793;&#30340;&#25968;&#37327;&#24182;&#20943;&#23569;&#20272;&#35745;&#26041;&#24046;&#65292;&#21516;&#26102;&#36890;&#36807;&#21033;&#29992;&#26412;&#22320;&#26102;&#38388;&#32467;&#26500;&#36827;&#34892;&#33258;&#36866;&#24212;&#32593;&#32476;&#37051;&#22495;&#25511;&#21046;&#24341;&#20837;&#30340;&#20272;&#35745;&#20559;&#24046;&#12290;&#25552;&#20986;&#20102;&#19968;&#20010;&#25237;&#24433;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#26469;&#20419;&#36827;&#20272;&#35745;&#65292;&#20854;&#20013;&#27599;&#27425;&#36845;&#20195;&#30340;&#20272;&#35745;&#38169;&#35823;&#19978;&#30028;&#34987;&#24314;&#31435;&#12290;&#36827;&#34892;&#20102;&#24443;&#24213;&#30340;&#20998;&#26512;&#65292;&#20197;&#37327;&#21270;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#28176;&#36817;&#34892;&#20026;&#65292;&#32467;&#26524;&#34920;&#26126;&#23427;&#21487;&#20197;&#26174;&#30528;&#20943;&#23569;&#20272;&#35745;&#20559;&#24046;&#12290;
&lt;/p&gt;
&lt;p&gt;
Longitudinal network consists of a sequence of temporal edges among multiple nodes, where the temporal edges are observed in real time. It has become ubiquitous with the rise of online social platform and e-commerce, but largely under-investigated in literature. In this paper, we propose an efficient estimation framework for longitudinal network, leveraging strengths of adaptive network merging, tensor decomposition and point process. It merges neighboring sparse networks so as to enlarge the number of observed edges and reduce estimation variance, whereas the estimation bias introduced by network merging is controlled by exploiting local temporal structures for adaptive network neighborhood. A projected gradient descent algorithm is proposed to facilitate estimation, where the upper bound of the estimation error in each iteration is established. A thorough analysis is conducted to quantify the asymptotic behavior of the proposed method, which shows that it can significantly reduce the
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#20272;&#35745;&#22120;&#30340;&#31283;&#23450;&#24615;&#36275;&#20197;&#35828;&#26126;&#30041;&#19968;&#27861;&#20132;&#21449;&#39564;&#35777;&#26159;&#21487;&#38752;&#30340;&#65292;&#24182;&#36890;&#36807;&#25552;&#20379;&#38598;&#20013;&#30028;&#38480;&#36229;&#20986;Lipschitz&#36830;&#32493;&#24615;&#20551;&#35774;&#30340;&#25439;&#22833;&#20989;&#25968;&#25110;&#20272;&#35745;&#22120;&#65292;&#20026;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#30456;&#23545;&#20016;&#23500;&#30340;&#20998;&#24067;&#31867;&#12290;</title><link>http://arxiv.org/abs/2211.02478</link><description>&lt;p&gt;
&#29992;&#20110;&#30041;&#19968;&#27861;&#20132;&#21449;&#39564;&#35777;&#30340;&#38598;&#20013;&#19981;&#31561;&#24335;
&lt;/p&gt;
&lt;p&gt;
Concentration inequalities for leave-one-out cross validation. (arXiv:2211.02478v3 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.02478
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#20272;&#35745;&#22120;&#30340;&#31283;&#23450;&#24615;&#36275;&#20197;&#35828;&#26126;&#30041;&#19968;&#27861;&#20132;&#21449;&#39564;&#35777;&#26159;&#21487;&#38752;&#30340;&#65292;&#24182;&#36890;&#36807;&#25552;&#20379;&#38598;&#20013;&#30028;&#38480;&#36229;&#20986;Lipschitz&#36830;&#32493;&#24615;&#20551;&#35774;&#30340;&#25439;&#22833;&#20989;&#25968;&#25110;&#20272;&#35745;&#22120;&#65292;&#20026;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#30456;&#23545;&#20016;&#23500;&#30340;&#20998;&#24067;&#31867;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#20272;&#35745;&#22120;&#30340;&#31283;&#23450;&#24615;&#36275;&#20197;&#35828;&#26126;&#30041;&#19968;&#27861;&#20132;&#21449;&#39564;&#35777;&#26159;&#19968;&#20010;&#21487;&#38752;&#30340;&#36807;&#31243;&#65292;&#36890;&#36807;&#22312;&#19968;&#20010;&#36890;&#29992;&#30340;&#26694;&#26550;&#20013;&#25552;&#20379;&#38598;&#20013;&#30028;&#38480;&#12290;&#29305;&#21035;&#26159;&#65292;&#25105;&#20204;&#22312;&#25439;&#22833;&#20989;&#25968;&#25110;&#20272;&#35745;&#22120;&#19978;&#25552;&#20379;&#20102;&#36229;&#36807;Lipschitz&#36830;&#32493;&#24615;&#20551;&#35774;&#30340;&#38598;&#20013;&#30028;&#38480;&#12290;&#25105;&#20204;&#36890;&#36807;&#20381;&#36182;&#20855;&#26377;&#28385;&#36275;&#23545;&#25968;Sobolev&#19981;&#31561;&#24335;&#30340;&#20998;&#24067;&#30340;&#38543;&#26426;&#21464;&#37327;&#26469;&#33719;&#24471;&#25105;&#20204;&#30340;&#32467;&#26524;&#65292;&#36825;&#20026;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20010;&#30456;&#23545;&#20016;&#23500;&#30340;&#20998;&#24067;&#31867;&#12290;&#25105;&#20204;&#36890;&#36807;&#32771;&#34385;&#20960;&#20010;&#26377;&#36259;&#30340;&#20363;&#23376;&#26469;&#35828;&#26126;&#25105;&#20204;&#30340;&#26041;&#27861;&#65292;&#21253;&#25324;&#32447;&#24615;&#22238;&#24402;&#65292;&#26680;&#23494;&#24230;&#20272;&#35745;&#20197;&#21450;&#31283;&#23450;/&#25130;&#26029;&#20272;&#35745;&#22120;&#65292;&#20363;&#22914;&#31283;&#23450;&#30340;&#26680;&#22238;&#24402;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this article we prove that estimator stability is enough to show that leave-one-out cross validation is a sound procedure, by providing concentration bounds in a general framework. In particular, we provide concentration bounds beyond Lipschitz continuity assumptions on the loss or on the estimator. We obtain our results by relying on random variables with distribution satisfying the logarithmic Sobolev inequality, providing us a relatively rich class of distributions. We illustrate our method by considering several interesting examples, including linear regression, kernel density estimation, and stabilized/truncated estimators such as stabilized kernel regression.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#36890;&#36807;&#24418;&#24335;&#35777;&#26126;&#65292;&#23637;&#31034;&#20102;&#26368;&#20248;AdaBoost&#31639;&#27861;&#30340;&#20998;&#31867;&#22120;&#21644;&#36793;&#32536;&#30340;&#25910;&#25947;&#24615;&#36136;&#65292;&#32467;&#26524;&#19982;&#20960;&#21313;&#24180;&#30340;&#30740;&#31350;&#30456;&#19968;&#33268;&#12290;</title><link>http://arxiv.org/abs/2210.07808</link><description>&lt;p&gt;
&#26368;&#20248;AdaBoost&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;
&lt;/p&gt;
&lt;p&gt;
Optimal AdaBoost Converges. (arXiv:2210.07808v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.07808
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#36890;&#36807;&#24418;&#24335;&#35777;&#26126;&#65292;&#23637;&#31034;&#20102;&#26368;&#20248;AdaBoost&#31639;&#27861;&#30340;&#20998;&#31867;&#22120;&#21644;&#36793;&#32536;&#30340;&#25910;&#25947;&#24615;&#36136;&#65292;&#32467;&#26524;&#19982;&#20960;&#21313;&#24180;&#30340;&#30740;&#31350;&#30456;&#19968;&#33268;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#26159;&#20851;&#20110;AdaBoost&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#20998;&#31867;&#22120;&#21644;&#36793;&#32536;&#30340;&#25910;&#25947;&#24615;&#24615;&#36136;&#30340;&#24418;&#24335;&#35777;&#26126;&#30340;&#39044;&#21360;&#26412;&#38598;&#21512;&#12290;&#38024;&#23545;&#36825;&#20123;&#25910;&#25947;&#24615;&#24615;&#36136;&#30340;&#29468;&#24819;&#21644;&#29305;&#27530;&#24773;&#20917;&#24050;&#32463;&#32534;&#20889;&#20102;&#21508;&#31181;&#25968;&#23398;&#21644;&#35745;&#31639;&#26426;&#31185;&#23398;&#35770;&#25991;&#12290;&#27492;&#22806;&#65292;AdaBoost&#30340;&#36793;&#32536;&#22312;&#22260;&#32469;&#35813;&#31639;&#27861;&#30340;&#30740;&#31350;&#20013;&#21344;&#25454;&#37325;&#35201;&#22320;&#20301;&#12290;&#22312;&#26412;&#25991;&#30340;&#39030;&#28857;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;AdaBoost&#30340;&#20998;&#31867;&#22120;&#21644;&#36793;&#32536;&#22914;&#20309;&#25910;&#25947;&#21040;&#19982;&#20960;&#21313;&#24180;&#30340;&#30740;&#31350;&#30456;&#19968;&#33268;&#30340;&#20540;&#12290;&#22312;&#27492;&#20043;&#21518;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#19982;&#32452;&#21512;&#20998;&#31867;&#22120;&#30456;&#20851;&#30340;&#21508;&#31181;&#25968;&#37327;&#26159;&#22914;&#20309;&#25910;&#25947;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
The following work is a preprint collection of formal proofs regarding the convergence properties of the AdaBoost machine learning algorithm's classifier and margins. Various math and computer science papers have been written regarding conjectures and special cases of these convergence properties. Furthermore, the margins of AdaBoost feature prominently in the research surrounding the algorithm. At the zenith of this paper we present how AdaBoost's classifier and margins converge on a value that agrees with decades of research. After this, we show how various quantities associated with the combined classifier converge.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#33324;&#29702;&#35770;&#26469;&#38480;&#23450;POMDP&#19982;&#20854;&#30456;&#24212;&#30340;&#26377;&#38480;&#26679;&#26412;&#31890;&#23376;&#20449;&#24565;MDP(PB-MDP)&#36924;&#36817;&#20043;&#38388;&#30340;&#35823;&#24046;&#65292;&#24182;&#23558;&#20219;&#20309;&#37319;&#26679;MDP&#31639;&#27861;&#36866;&#24212;&#21040;POMDP&#20013;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#35299;&#20915;&#20855;&#26377;&#22823;&#30340;&#25110;&#36830;&#32493;&#29366;&#24577;&#31354;&#38388;&#30340;POMDP&#30340;&#24615;&#33021;&#21644;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2210.05015</link><description>&lt;p&gt;
&#31890;&#23376;&#20449;&#24565;&#36817;&#20284;POMDP&#30340;&#26368;&#20248;&#24615;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Optimality Guarantees for Particle Belief Approximation of POMDPs. (arXiv:2210.05015v3 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.05015
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#33324;&#29702;&#35770;&#26469;&#38480;&#23450;POMDP&#19982;&#20854;&#30456;&#24212;&#30340;&#26377;&#38480;&#26679;&#26412;&#31890;&#23376;&#20449;&#24565;MDP(PB-MDP)&#36924;&#36817;&#20043;&#38388;&#30340;&#35823;&#24046;&#65292;&#24182;&#23558;&#20219;&#20309;&#37319;&#26679;MDP&#31639;&#27861;&#36866;&#24212;&#21040;POMDP&#20013;&#65292;&#20174;&#32780;&#25552;&#39640;&#20102;&#35299;&#20915;&#20855;&#26377;&#22823;&#30340;&#25110;&#36830;&#32493;&#29366;&#24577;&#31354;&#38388;&#30340;POMDP&#30340;&#24615;&#33021;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37096;&#20998;&#21487;&#35266;&#23519;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;(POMDP)&#25552;&#20379;&#20102;&#29616;&#23454;&#20915;&#31574;&#21644;&#25511;&#21046;&#38382;&#39064;&#30340;&#28789;&#27963;&#34920;&#31034;&#12290;&#28982;&#32780;&#65292;POMDP&#30340;&#27714;&#35299;&#38750;&#24120;&#22256;&#38590;&#65292;&#29305;&#21035;&#26159;&#24403;&#29366;&#24577;&#21644;&#35266;&#27979;&#31354;&#38388;&#26159;&#36830;&#32493;&#25110;&#28151;&#21512;&#30340;&#26102;&#20505;&#65292;&#36825;&#22312;&#29289;&#29702;&#31995;&#32479;&#20013;&#32463;&#24120;&#21457;&#29983;&#12290;&#23613;&#31649;&#26368;&#36817;&#20351;&#29992;&#35266;&#27979;&#20284;&#28982;&#26435;&#37325;&#31574;&#21010;&#30340;&#22312;&#32447;&#37319;&#26679;POMDP&#31639;&#27861;&#34920;&#29616;&#20986;&#20102;&#23454;&#29992;&#30340;&#26377;&#25928;&#24615;&#65292;&#20294;&#20808;&#21069;&#24182;&#27809;&#26377;&#25552;&#20986;&#19968;&#33324;&#29702;&#35770;&#26469;&#21051;&#30011;&#36825;&#20123;&#31639;&#27861;&#20351;&#29992;&#30340;&#31890;&#23376;&#28388;&#27874;&#25216;&#26415;&#30340;&#36924;&#36817;&#35823;&#24046;&#12290;&#25105;&#20204;&#30340;&#20027;&#35201;&#36129;&#29486;&#26159;&#38480;&#23450;&#20219;&#20309;POMDP&#19982;&#20854;&#30456;&#24212;&#30340;&#26377;&#38480;&#26679;&#26412;&#31890;&#23376;&#20449;&#24565;MDP(PB-MDP)&#36924;&#36817;&#20043;&#38388;&#30340;&#35823;&#24046;&#12290;&#36825;&#31181;PB-MDP&#21644;POMDP&#20043;&#38388;&#30340;&#22522;&#30784;&#26725;&#26753;&#20351;&#24471;&#25105;&#20204;&#33021;&#22815;&#36890;&#36807;&#35299;&#20915;&#30456;&#24212;&#30340;&#31890;&#23376;&#20449;&#24565;MDP&#23558;&#20219;&#20309;&#37319;&#26679;MDP&#31639;&#27861;&#36866;&#24212;&#21040;POMDP&#20013;&#65292;&#20174;&#32780;&#23558;MDP&#31639;&#27861;&#30340;&#25910;&#25947;&#20445;&#35777;&#25193;&#23637;&#21040;POMDP&#20013;&#12290;&#22312;&#23454;&#36341;&#20013;&#65292;&#36825;&#21487;&#20197;&#25552;&#39640;&#22312;&#35299;&#20915;&#20855;&#26377;&#22823;&#30340;&#25110;&#36830;&#32493;&#29366;&#24577;&#31354;&#38388;&#30340;POMDP&#26102;&#30340;&#24615;&#33021;&#21644;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Partially observable Markov decision processes (POMDPs) provide a flexible representation for real-world decision and control problems. However, POMDPs are notoriously difficult to solve, especially when the state and observation spaces are continuous or hybrid, which is often the case for physical systems. While recent online sampling-based POMDP algorithms that plan with observation likelihood weighting have shown practical effectiveness, a general theory characterizing the approximation error of the particle filtering techniques that these algorithms use has not previously been proposed. Our main contribution is bounding the error between any POMDP and its corresponding finite sample particle belief MDP (PB-MDP) approximation. This fundamental bridge between PB-MDPs and POMDPs allows us to adapt any sampling-based MDP algorithm to a POMDP by solving the corresponding particle belief MDP, thereby extending the convergence guarantees of the MDP algorithm to the POMDP. Practically, thi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#23884;&#20837;&#27169;&#22411;&#65292;&#29992;&#20110;&#35299;&#20915;&#31614;&#21517;&#32593;&#32476;&#20013;&#30340;&#24179;&#34913;&#32467;&#26500;&#21644;&#24322;&#24120;&#25928;&#24212;&#65292;&#24182;&#22312;&#31038;&#21306;&#26816;&#27979;&#12289;&#24322;&#24120;&#26816;&#27979;&#21644;&#32593;&#32476;&#25512;&#26029;&#31561;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#33391;&#22909;&#34920;&#29616;&#12290;</title><link>http://arxiv.org/abs/2207.09324</link><description>&lt;p&gt;
&#24102;&#26377;&#21516;&#26102;&#26816;&#27979;&#31038;&#21306;&#21644;&#24322;&#24120;&#30340;&#31614;&#21517;&#32593;&#32476;&#23884;&#20837;&#21450;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Signed Network Embedding with Application to Simultaneous Detection of Communities and Anomalies. (arXiv:2207.09324v3 [cs.SI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2207.09324
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24320;&#21457;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#23884;&#20837;&#27169;&#22411;&#65292;&#29992;&#20110;&#35299;&#20915;&#31614;&#21517;&#32593;&#32476;&#20013;&#30340;&#24179;&#34913;&#32467;&#26500;&#21644;&#24322;&#24120;&#25928;&#24212;&#65292;&#24182;&#22312;&#31038;&#21306;&#26816;&#27979;&#12289;&#24322;&#24120;&#26816;&#27979;&#21644;&#32593;&#32476;&#25512;&#26029;&#31561;&#20219;&#21153;&#20013;&#21462;&#24471;&#20102;&#33391;&#22909;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#29616;&#23454;&#29983;&#27963;&#20013;&#65292;&#25105;&#20204;&#32463;&#24120;&#35266;&#23519;&#21040;&#24102;&#26377;&#38468;&#21152;&#31526;&#21495;&#20449;&#24687;&#30340;&#32593;&#32476;&#65292;&#28982;&#32780;&#36825;&#20123;&#20449;&#24687;&#22312;&#29616;&#26377;&#30340;&#32593;&#32476;&#27169;&#22411;&#20013;&#34987;&#22823;&#37096;&#20998;&#24573;&#35270;&#20102;&#12290;&#26412;&#25991;&#38024;&#23545;&#31614;&#21517;&#32593;&#32476;&#24320;&#21457;&#20102;&#19968;&#20010;&#32479;&#19968;&#30340;&#23884;&#20837;&#27169;&#22411;&#65292;&#20197;&#35299;&#24320;&#38169;&#32508;&#22797;&#26434;&#30340;&#24179;&#34913;&#32467;&#26500;&#21644;&#24322;&#24120;&#25928;&#24212;&#65292;&#20174;&#32780;&#21487;&#20197;&#26497;&#22823;&#22320;&#20419;&#36827;&#19979;&#28216;&#20998;&#26512;&#65292;&#21253;&#25324;&#31038;&#21306;&#26816;&#27979;&#12289;&#24322;&#24120;&#26816;&#27979;&#21644;&#32593;&#32476;&#25512;&#26029;&#12290;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#36890;&#36807;&#20302;&#31209;&#21152;&#31232;&#30095;&#30697;&#38453;&#20998;&#35299;&#25429;&#25417;&#24179;&#34913;&#32467;&#26500;&#21644;&#24322;&#24120;&#25928;&#24212;&#65292;&#24182;&#36890;&#36807;&#27491;&#21017;&#21270;&#26041;&#27861;&#32852;&#21512;&#20272;&#35745;&#20108;&#32773;&#12290;&#22312;&#32593;&#32476;&#23884;&#20837;&#12289;&#31038;&#21306;&#26816;&#27979;&#21644;&#24322;&#24120;&#26816;&#27979;&#26041;&#38754;&#65292;&#23427;&#30340;&#29702;&#35770;&#20445;&#35777;&#26159;&#24314;&#31435;&#22312;&#28176;&#36817;&#19968;&#33268;&#24615;&#21644;&#26377;&#38480;&#26679;&#26412;&#27010;&#29575;&#36793;&#30028;&#30340;&#22522;&#30784;&#19978;&#12290;&#25152;&#25552;&#20986;&#30340;&#23884;&#20837;&#27169;&#22411;&#30340;&#20248;&#21183;&#36824;&#36890;&#36807;&#23545;&#21512;&#25104;&#32593;&#32476;&#21644;&#22269;&#38469;&#20851;&#31995;&#32593;&#32476;&#36827;&#34892;&#24191;&#27867;&#30340;&#25968;&#20540;&#23454;&#39564;&#24471;&#21040;&#20102;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
Signed networks are frequently observed in real life with additional sign information associated with each edge, yet such information has been largely ignored in existing network models. This paper develops a unified embedding model for signed networks to disentangle the intertwined balance structure and anomaly effect, which can greatly facilitate the downstream analysis, including community detection, anomaly detection, and network inference. The proposed model captures both balance structure and anomaly effect through a low rank plus sparse matrix decomposition, which are jointly estimated via a regularized formulation. Its theoretical guarantees are established in terms of asymptotic consistency and finite-sample probability bounds for network embedding, community detection and anomaly detection. The advantage of the proposed embedding model is also demonstrated through extensive numerical experiments on both synthetic networks and an international relation network.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22806;&#26679;&#26412;&#27169;&#22411;&#35780;&#20272;&#30340;&#35786;&#26029;&#24037;&#20855;&#65292;&#21487;&#20197;&#36890;&#36807;&#26377;&#38480;&#30340;&#26657;&#20934;&#25968;&#25454;&#38598;&#26469;&#34920;&#24449;&#27169;&#22411;&#22312;&#26410;&#26469;&#22806;&#26679;&#26412;&#19978;&#30340;&#25439;&#22833;&#65292;&#24182;&#25552;&#20379;&#20102;&#31616;&#21333;&#26131;&#29992;&#19988;&#26131;&#20110;&#35299;&#37322;&#30340;&#26041;&#27861;&#12290;&#35813;&#24037;&#20855;&#21487;&#20197;&#37327;&#21270;&#20998;&#24067;&#36716;&#21464;&#30340;&#24433;&#21709;&#65292;&#20419;&#36827;&#22238;&#24402;&#20998;&#26512;&#65292;&#24110;&#21161;&#23454;&#29616;&#27169;&#22411;&#36873;&#25321;&#21644;&#36229;&#21442;&#25968;&#35843;&#20248;&#12290;</title><link>http://arxiv.org/abs/2206.10982</link><description>&lt;p&gt;
&#29992;&#20110;&#22806;&#26679;&#26412;&#27169;&#22411;&#35780;&#20272;&#30340;&#35786;&#26029;&#24037;&#20855;
&lt;/p&gt;
&lt;p&gt;
Diagnostic Tool for Out-of-Sample Model Evaluation. (arXiv:2206.10982v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.10982
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#22806;&#26679;&#26412;&#27169;&#22411;&#35780;&#20272;&#30340;&#35786;&#26029;&#24037;&#20855;&#65292;&#21487;&#20197;&#36890;&#36807;&#26377;&#38480;&#30340;&#26657;&#20934;&#25968;&#25454;&#38598;&#26469;&#34920;&#24449;&#27169;&#22411;&#22312;&#26410;&#26469;&#22806;&#26679;&#26412;&#19978;&#30340;&#25439;&#22833;&#65292;&#24182;&#25552;&#20379;&#20102;&#31616;&#21333;&#26131;&#29992;&#19988;&#26131;&#20110;&#35299;&#37322;&#30340;&#26041;&#27861;&#12290;&#35813;&#24037;&#20855;&#21487;&#20197;&#37327;&#21270;&#20998;&#24067;&#36716;&#21464;&#30340;&#24433;&#21709;&#65292;&#20419;&#36827;&#22238;&#24402;&#20998;&#26512;&#65292;&#24110;&#21161;&#23454;&#29616;&#27169;&#22411;&#36873;&#25321;&#21644;&#36229;&#21442;&#25968;&#35843;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#22411;&#36866;&#37197;&#24615;&#35780;&#20272;&#26159;&#26426;&#22120;&#23398;&#20064;&#30340;&#20851;&#38190;&#37096;&#20998;&#12290;&#26631;&#20934;&#33539;&#24335;&#26159;&#36890;&#36807;&#23545;&#35757;&#32451;&#25968;&#25454;&#19978;&#30340;&#36873;&#25321;&#25439;&#22833;&#20989;&#25968;&#36827;&#34892;&#24179;&#22343;&#65292;&#20197;&#23454;&#29616;&#22312;&#26410;&#26469;&#25968;&#25454;&#19978;&#33719;&#24471;&#23567;&#30340;&#25439;&#22833;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#32771;&#34385;&#20351;&#29992;&#26377;&#38480;&#30340;&#26657;&#20934;&#25968;&#25454;&#38598;&#26469;&#34920;&#24449;&#27169;&#22411;&#22312;&#26410;&#26469;&#22806;&#26679;&#26412;&#19978;&#30340;&#25439;&#22833;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#31616;&#21333;&#30340;&#27169;&#22411;&#35786;&#26029;&#24037;&#20855;&#65292;&#22312;&#24369;&#20551;&#35774;&#19979;&#25552;&#20379;&#26377;&#38480;&#26679;&#26412;&#30340;&#20445;&#35777;&#12290;&#35813;&#24037;&#20855;&#31616;&#21333;&#26131;&#29992;&#19988;&#26131;&#20110;&#35299;&#37322;&#12290;&#36890;&#36807;&#23637;&#31034;&#20960;&#20010;&#25968;&#20540;&#23454;&#39564;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25552;&#20986;&#30340;&#26041;&#27861;&#22914;&#20309;&#37327;&#21270;&#20998;&#24067;&#36716;&#21464;&#30340;&#24433;&#21709;&#65292;&#20419;&#36827;&#22238;&#24402;&#20998;&#26512;&#65292;&#20197;&#21450;&#23454;&#29616;&#27169;&#22411;&#36873;&#25321;&#21644;&#36229;&#21442;&#25968;&#35843;&#20248;&#12290;
&lt;/p&gt;
&lt;p&gt;
Assessment of model fitness is a key part of machine learning. The standard paradigm is to learn models by minimizing a chosen loss function averaged over training data, with the aim of achieving small losses on future data. In this paper, we consider the use of a finite calibration data set to characterize the future, out-of-sample losses of a model. We propose a simple model diagnostic tool that provides finite-sample guarantees under weak assumptions. The tool is simple to compute and to interpret. Several numerical experiments are presented to show how the proposed method quantifies the impact of distribution shifts, aids the analysis of regression, and enables model selection as well as hyper-parameter tuning.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#22522;&#20110;&#26143;&#24418;&#32454;&#32990;&#20316;&#29992;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#31361;&#35302;&#30340;&#31454;&#20105;&#21644;&#24378;&#24230;&#24179;&#34913;&#23454;&#29616;&#29616;&#26377;&#21644;&#35760;&#24518;&#24615;&#30340;&#22823;&#33041;&#21487;&#22609;&#24615;&#21644;&#31361;&#35302;&#24418;&#25104;&#65292;&#24182;&#25506;&#35752;&#20102;&#19982;&#20851;&#38190;&#26399;&#30456;&#20851;&#30340;&#31070;&#32463;&#32010;&#20081;&#21644;&#36127;&#38754;&#21644;&#27491;&#38754;&#35760;&#24518;&#30340;&#25345;&#20037;&#24615;&#23545;&#31361;&#35302;&#28608;&#27963;&#30340;&#24433;&#21709;&#12290;</title><link>http://arxiv.org/abs/2203.11740</link><description>&lt;p&gt;
&#22522;&#20110;&#26143;&#24418;&#32454;&#32990;&#23545;&#20851;&#38190;&#26399;&#30340;&#31070;&#32463;&#21487;&#22609;&#24615;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#29616;&#26377;&#21644;&#35760;&#24518;&#24615;&#30340;&#22823;&#33041;&#21487;&#22609;&#24615;&#21644;&#31361;&#35302;&#24418;&#25104;&#23454;&#29616;&#31361;&#35302;&#31454;&#20105;&#21644;&#24378;&#24230;&#24179;&#34913;&#12290;&#65288;arXiv: 2203.11740v12 [cs.NE] UPDATED&#65289;
&lt;/p&gt;
&lt;p&gt;
Plasticity Neural Network Based on Astrocytic effects at Critical Period, Synaptic Competition and Strength Rebalance by Current and Mnemonic Brain Plasticity and Synapse Formation. (arXiv:2203.11740v12 [cs.NE] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.11740
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#22522;&#20110;&#26143;&#24418;&#32454;&#32990;&#20316;&#29992;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#36890;&#36807;&#31361;&#35302;&#30340;&#31454;&#20105;&#21644;&#24378;&#24230;&#24179;&#34913;&#23454;&#29616;&#29616;&#26377;&#21644;&#35760;&#24518;&#24615;&#30340;&#22823;&#33041;&#21487;&#22609;&#24615;&#21644;&#31361;&#35302;&#24418;&#25104;&#65292;&#24182;&#25506;&#35752;&#20102;&#19982;&#20851;&#38190;&#26399;&#30456;&#20851;&#30340;&#31070;&#32463;&#32010;&#20081;&#21644;&#36127;&#38754;&#21644;&#27491;&#38754;&#35760;&#24518;&#30340;&#25345;&#20037;&#24615;&#23545;&#31361;&#35302;&#28608;&#27963;&#30340;&#24433;&#21709;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38500;&#20102;&#31361;&#35302;&#20849;&#20139;&#36830;&#25509;&#26435;&#37325;&#20043;&#22806;&#65292;PNN&#36824;&#21253;&#25324;&#31361;&#35302;&#26377;&#25928;&#33539;&#22260;&#30340;&#26435;&#37325;[14-25]&#12290;PNN&#32771;&#34385;&#31361;&#35302;&#24378;&#24230;&#24179;&#34913;&#22312;&#31361;&#35302;&#21534;&#22124;&#30340;&#21160;&#24577;&#21644;&#38271;&#24230;&#24120;&#25968;&#20043;&#21644;&#30340;&#38745;&#24577;&#20013;[14]&#65292;&#24182;&#21253;&#21547;&#20102;&#40060;&#32676;&#34892;&#20026;&#30340;&#20808;&#23548;&#34892;&#20026;&#12290;&#31361;&#35302;&#24418;&#25104;&#22312;&#23454;&#39564;&#21644;&#27169;&#25311;&#20013;&#20250;&#25233;&#21046;&#26641;&#31361;&#29983;&#25104;[15]&#12290;&#31867;&#20284;&#20110;Spring Boot&#20013;&#30340;&#24378;&#21046;&#38887;&#24615;&#65292;&#21453;&#21521;&#22238;&#36335;&#30340;&#35760;&#24518;&#25345;&#20037;&#24230;&#26799;&#24230;&#20063;&#23384;&#22312;&#12290;&#30456;&#23545;&#36739;&#22909;&#21644;&#36739;&#24046;&#30340;&#26799;&#24230;&#20449;&#24687;&#23384;&#20648;&#22312;&#31867;&#20284;&#20110;&#33041;&#35126;&#30340;&#35760;&#24518;&#30165;&#36857;&#32454;&#32990;&#20013;&#65292;&#22312;&#21453;&#21521;&#22238;&#36335;&#30340;&#31361;&#35302;&#24418;&#25104;&#20013;&#12290;&#20105;&#35758;&#35748;&#20026;&#20154;&#31867;&#28023;&#39532;&#31070;&#32463;&#20803;&#30340;&#20877;&#29983;&#33021;&#21147;&#26159;&#21542;&#25345;&#32493;&#21040;&#32769;&#24180;&#65292;&#24182;&#21487;&#33021;&#22312;&#21518;&#26399;&#36845;&#20195;&#20013;&#24418;&#25104;&#26032;&#30340;&#26356;&#38271;&#30340;&#22238;&#36335;[17,18]&#12290;&#20851;&#38381;&#20851;&#38190;&#26399;&#20250;&#23548;&#33268;&#31070;&#32463;&#32010;&#20081;&#22312;&#23454;&#39564;&#21644;&#27169;&#25311;&#20013;[19]&#12290;&#32771;&#34385;&#21040;&#36127;&#38754;&#21644;&#27491;&#38754;&#35760;&#24518;&#30340;&#25345;&#20037;&#24615;&#65292;&#26377;&#21161;&#20110;&#26356;&#22909;&#22320;&#28608;&#27963;&#31361;&#35302;&#12290;
&lt;/p&gt;
&lt;p&gt;
In addition to the weights of synaptic shared connections, PNN includes weights of synaptic effective ranges [14-25]. PNN considers synaptic strength balance in dynamic of phagocytosing of synapses and static of constant sum of synapses length [14], and includes the lead behavior of the school of fish. Synapse formation will inhibit dendrites generation in experiments and simulations [15]. The memory persistence gradient of retrograde circuit similar to the Enforcing Resilience in a Spring Boot. The relatively good and inferior gradient information stored in memory engram cells in synapse formation of retrograde circuit like the folds in brain [16]. The controversy was claimed if human hippocampal neurogenesis persists throughout aging, may have a new and longer circuit in late iteration [17,18]. Closing the critical period will cause neurological disorder in experiments and simulations [19]. Considering both negative and positive memories persistence help activate synapse better than 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#26102;&#24207;&#22810;&#20307;&#30456;&#20114;&#20316;&#29992;&#30340;&#25512;&#26029;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#25551;&#36848;&#34920;&#29616;&#20986;&#26102;&#38388;&#20381;&#36182;&#24615;&#21644;&#22810;&#20307;&#20381;&#36182;&#24615;&#30340;&#22797;&#26434;&#31995;&#32479;&#12290;&#36890;&#36807;&#23558;&#22810;&#20803;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#21160;&#21147;&#23398;&#20998;&#35299;&#20026;&#26102;&#24207;&#22810;&#20307;&#30456;&#20114;&#20316;&#29992;&#30340;&#38598;&#21512;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#25968;&#25454;&#20013;&#25552;&#21462;&#36825;&#20123;&#30456;&#20114;&#20316;&#29992;&#30340;&#31639;&#27861;&#65292;&#24182;&#39564;&#35777;&#20102;&#31639;&#27861;&#30340;&#31283;&#20581;&#24615;&#21644;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2111.14611</link><description>&lt;p&gt;
&#26102;&#24207;&#22810;&#20307;&#30456;&#20114;&#20316;&#29992;&#30340;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
Inference of time-ordered multibody interactions. (arXiv:2111.14611v2 [physics.soc-ph] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.14611
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#26102;&#24207;&#22810;&#20307;&#30456;&#20114;&#20316;&#29992;&#30340;&#25512;&#26029;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#21487;&#20197;&#25551;&#36848;&#34920;&#29616;&#20986;&#26102;&#38388;&#20381;&#36182;&#24615;&#21644;&#22810;&#20307;&#20381;&#36182;&#24615;&#30340;&#22797;&#26434;&#31995;&#32479;&#12290;&#36890;&#36807;&#23558;&#22810;&#20803;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#21160;&#21147;&#23398;&#20998;&#35299;&#20026;&#26102;&#24207;&#22810;&#20307;&#30456;&#20114;&#20316;&#29992;&#30340;&#38598;&#21512;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#25968;&#25454;&#20013;&#25552;&#21462;&#36825;&#20123;&#30456;&#20114;&#20316;&#29992;&#30340;&#31639;&#27861;&#65292;&#24182;&#39564;&#35777;&#20102;&#31639;&#27861;&#30340;&#31283;&#20581;&#24615;&#21644;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24341;&#20837;&#26102;&#24207;&#22810;&#20307;&#30456;&#20114;&#20316;&#29992;&#26469;&#25551;&#36848;&#34920;&#29616;&#20986;&#26102;&#38388;&#20381;&#36182;&#24615;&#21644;&#22810;&#20307;&#20381;&#36182;&#24615;&#30340;&#22797;&#26434;&#31995;&#32479;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;&#22810;&#20803;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#21160;&#21147;&#23398;&#20998;&#35299;&#20026;&#26102;&#24207;&#22810;&#20307;&#30456;&#20114;&#20316;&#29992;&#30340;&#38598;&#21512;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20174;&#25429;&#33719;&#33410;&#28857;&#29366;&#24577;&#31995;&#32479;&#32423;&#21160;&#21147;&#23398;&#30340;&#25968;&#25454;&#20013;&#25552;&#21462;&#36825;&#20123;&#30456;&#20114;&#20316;&#29992;&#30340;&#31639;&#27861;&#65292;&#20197;&#21450;&#19968;&#31181;&#29992;&#20110;&#34920;&#24449;&#30456;&#20114;&#20316;&#29992;&#38598;&#21512;&#22797;&#26434;&#24615;&#30340;&#24230;&#37327;&#26041;&#27861;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#22312;&#32479;&#35745;&#35823;&#24046;&#19979;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#31639;&#27861;&#30340;&#31283;&#20581;&#24615;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#25512;&#26029;&#31616;&#27905;&#30340;&#30456;&#20114;&#20316;&#29992;&#38598;&#21512;&#30340;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce time-ordered multibody interactions to describe complex systems manifesting temporal as well as multibody dependencies. First, we show how the dynamics of multivariate Markov chains can be decomposed in ensembles of time-ordered multibody interactions. Then, we present an algorithm to extract those interactions from data capturing the system-level dynamics of node states and a measure to characterize the complexity of interaction ensembles. Finally, we experimentally validate the robustness of our algorithm against statistical errors and its efficiency at inferring parsimonious interaction ensembles.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#21457;&#29616;&#20102;&#23545;&#25239;&#35757;&#32451;&#20013;&#23384;&#22312;&#30340;&#26631;&#31614;&#22122;&#22768;&#65292;&#24182;&#35299;&#37322;&#20102;&#20854;&#23545;&#40065;&#26834;&#36807;&#24230;&#25311;&#21512;&#30340;&#26222;&#36941;&#23384;&#22312;&#20197;&#21450;&#25200;&#21160;&#21322;&#24452;&#21644;&#25968;&#25454;&#36136;&#37327;&#30340;&#20381;&#36182;&#24615;&#12290;&#36890;&#36807;&#35813;&#35770;&#25991;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#33258;&#21160;&#26657;&#20934;&#26631;&#31614;&#20197;&#24212;&#23545;&#26631;&#31614;&#22122;&#22768;&#21644;&#40065;&#26834;&#36807;&#24230;&#25311;&#21512;&#12290;</title><link>http://arxiv.org/abs/2110.03135</link><description>&lt;p&gt;
&#23545;&#25239;&#35757;&#32451;&#20013;&#30340;&#26631;&#31614;&#22122;&#22768;&#65306;&#30740;&#31350;&#40065;&#26834;&#36807;&#24230;&#25311;&#21512;&#30340;&#26032;&#35270;&#35282;
&lt;/p&gt;
&lt;p&gt;
Label Noise in Adversarial Training: A Novel Perspective to Study Robust Overfitting. (arXiv:2110.03135v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.03135
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#21457;&#29616;&#20102;&#23545;&#25239;&#35757;&#32451;&#20013;&#23384;&#22312;&#30340;&#26631;&#31614;&#22122;&#22768;&#65292;&#24182;&#35299;&#37322;&#20102;&#20854;&#23545;&#40065;&#26834;&#36807;&#24230;&#25311;&#21512;&#30340;&#26222;&#36941;&#23384;&#22312;&#20197;&#21450;&#25200;&#21160;&#21322;&#24452;&#21644;&#25968;&#25454;&#36136;&#37327;&#30340;&#20381;&#36182;&#24615;&#12290;&#36890;&#36807;&#35813;&#35770;&#25991;&#25552;&#20986;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#33258;&#21160;&#26657;&#20934;&#26631;&#31614;&#20197;&#24212;&#23545;&#26631;&#31614;&#22122;&#22768;&#21644;&#40065;&#26834;&#36807;&#24230;&#25311;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#23637;&#31034;&#20102;&#22312;&#23545;&#25239;&#35757;&#32451;&#20013;&#23384;&#22312;&#26631;&#31614;&#22122;&#22768;&#12290;&#36825;&#31181;&#26631;&#31614;&#22122;&#22768;&#26159;&#30001;&#20110;&#23545;&#25239;&#26679;&#26412;&#30340;&#30495;&#23454;&#26631;&#31614;&#20998;&#24067;&#19982;&#20174;&#24178;&#20928;&#26679;&#26412;&#32487;&#25215;&#30340;&#26631;&#31614;&#20043;&#38388;&#30340;&#19981;&#21305;&#37197;&#36896;&#25104;&#30340; - &#30495;&#23454;&#26631;&#31614;&#20998;&#24067;&#34987;&#23545;&#25239;&#25200;&#21160;&#25197;&#26354;&#65292;&#20294;&#20174;&#24178;&#20928;&#26679;&#26412;&#32487;&#25215;&#26631;&#31614;&#30340;&#24120;&#35265;&#20570;&#27861;&#21364;&#24573;&#30053;&#20102;&#36825;&#19968;&#28857;&#12290;&#35748;&#35782;&#21040;&#26631;&#31614;&#22122;&#22768;&#26377;&#21161;&#20110;&#27934;&#23519;&#23545;&#25239;&#35757;&#32451;&#20013;&#40065;&#26834;&#36807;&#24230;&#25311;&#21512;&#30340;&#26222;&#36941;&#23384;&#22312;&#65292;&#24182;&#35299;&#37322;&#20102;&#20854;&#23545;&#25200;&#21160;&#21322;&#24452;&#21644;&#25968;&#25454;&#36136;&#37327;&#30340;&#22855;&#29305;&#20381;&#36182;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#26631;&#31614;&#22122;&#22768;&#35270;&#35282;&#19982;&#25105;&#20204;&#23545;&#23545;&#25239;&#35757;&#32451;&#20013;&#32426;&#20803;&#21452;&#19979;&#38477;&#29616;&#35937;&#30340;&#35266;&#23519;&#30456;&#21563;&#21512;&#12290;&#22312;&#25105;&#20204;&#30340;&#20998;&#26512;&#25351;&#23548;&#19979;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26041;&#27861;&#26469;&#33258;&#21160;&#26657;&#20934;&#26631;&#31614;&#20197;&#24212;&#23545;&#26631;&#31614;&#22122;&#22768;&#21644;&#40065;&#26834;&#36807;&#24230;&#25311;&#21512;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21508;&#31181;&#27169;&#22411;&#21644;&#25968;&#25454;&#38598;&#19978;&#23454;&#29616;&#20102;&#19968;&#33268;&#30340;&#24615;&#33021;&#25552;&#21319;&#65292;&#32780;&#19981;&#24341;&#20837;&#26032;&#30340;&#36229;&#21442;&#25968;&#25110;&#39069;&#22806;&#30340;&#35843;&#25972;&#12290;
&lt;/p&gt;
&lt;p&gt;
We show that label noise exists in adversarial training. Such label noise is due to the mismatch between the true label distribution of adversarial examples and the label inherited from clean examples - the true label distribution is distorted by the adversarial perturbation, but is neglected by the common practice that inherits labels from clean examples. Recognizing label noise sheds insights on the prevalence of robust overfitting in adversarial training, and explains its intriguing dependence on perturbation radius and data quality. Also, our label noise perspective aligns well with our observations of the epoch-wise double descent in adversarial training. Guided by our analyses, we proposed a method to automatically calibrate the label to address the label noise and robust overfitting. Our method achieves consistent performance improvements across various models and datasets without introducing new hyper-parameters or additional tuning.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;BEAUTY&#26041;&#27861;&#36827;&#34892;&#20998;&#24067;&#26080;&#20851;&#30340;&#25311;&#21512;&#20248;&#24230;&#26816;&#39564;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#20108;&#36827;&#21046;&#23637;&#24320;&#36924;&#36817;&#29305;&#24449;&#20989;&#25968;&#65292;&#24182;&#23558;&#35768;&#22810;&#37325;&#35201;&#30340;&#29420;&#31435;&#24615;&#26816;&#39564;&#32479;&#19968;&#36215;&#26469;&#12290;&#20351;&#29992;&#25968;&#25454;&#33258;&#36866;&#24212;&#26435;&#37325;&#30340;BEAST&#26816;&#39564;&#25552;&#20379;&#20102;&#31283;&#20581;&#30340;&#21151;&#25928;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#34892;&#21151;&#25928;&#30340;&#21442;&#32771;&#12290;</title><link>http://arxiv.org/abs/2103.00674</link><description>&lt;p&gt;
BEAUTY&#21160;&#21147;&#30340;BEAST
&lt;/p&gt;
&lt;p&gt;
BEAUTY Powered BEAST. (arXiv:2103.00674v5 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2103.00674
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#20351;&#29992;BEAUTY&#26041;&#27861;&#36827;&#34892;&#20998;&#24067;&#26080;&#20851;&#30340;&#25311;&#21512;&#20248;&#24230;&#26816;&#39564;&#12290;&#35813;&#26041;&#27861;&#36890;&#36807;&#20108;&#36827;&#21046;&#23637;&#24320;&#36924;&#36817;&#29305;&#24449;&#20989;&#25968;&#65292;&#24182;&#23558;&#35768;&#22810;&#37325;&#35201;&#30340;&#29420;&#31435;&#24615;&#26816;&#39564;&#32479;&#19968;&#36215;&#26469;&#12290;&#20351;&#29992;&#25968;&#25454;&#33258;&#36866;&#24212;&#26435;&#37325;&#30340;BEAST&#26816;&#39564;&#25552;&#20379;&#20102;&#31283;&#20581;&#30340;&#21151;&#25928;&#65292;&#21516;&#26102;&#25552;&#20986;&#20102;&#19968;&#20010;&#21487;&#34892;&#21151;&#25928;&#30340;&#21442;&#32771;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#20351;&#29992;&#25552;&#20986;&#30340;&#20108;&#36827;&#21046;&#23637;&#24320;&#36817;&#20284;&#22343;&#21248;&#24615;&#65288;BEAUTY&#65289;&#26041;&#27861;&#30340;&#26080;&#20998;&#24067;&#25311;&#21512;&#20248;&#24230;&#26816;&#39564;&#12290;&#35813;&#26041;&#27861;&#25512;&#24191;&#20102;&#33879;&#21517;&#30340;&#27431;&#25289;&#20844;&#24335;&#65292;&#24182;&#36890;&#36807;&#26399;&#26395;&#30340;&#20108;&#36827;&#21046;&#20132;&#20114;&#30340;&#32447;&#24615;&#32452;&#21512;&#26469;&#36924;&#36817;&#20219;&#20309;&#32852;&#21512;&#20998;&#24067;&#20989;&#25968;&#30340;&#29305;&#24449;&#20989;&#25968;&#12290;&#36825;&#20010;&#26032;&#39062;&#30340;&#29702;&#35770;&#36890;&#36807;&#29305;&#23450;&#30340;&#20108;&#27425;&#23545;&#31216;&#32479;&#35745;&#30340;&#36924;&#36817;&#65292;&#23558;&#35768;&#22810;&#37325;&#35201;&#30340;&#29420;&#31435;&#24615;&#26816;&#39564;&#32479;&#19968;&#36215;&#26469;&#65292;&#20854;&#20013;&#30830;&#23450;&#24615;&#26435;&#37325;&#30697;&#38453;&#34920;&#24449;&#27599;&#20010;&#26816;&#39564;&#30340;&#21151;&#25928;&#24615;&#36136;&#12290;&#20026;&#20102;&#33719;&#24471;&#31283;&#20581;&#30340;&#21151;&#25928;&#65292;&#25105;&#20204;&#20351;&#29992;&#25968;&#25454;&#33258;&#36866;&#24212;&#26435;&#37325;&#26469;&#26816;&#39564;&#26816;&#39564;&#32479;&#35745;&#37327;&#65292;&#31216;&#20026;&#20108;&#36827;&#21046;&#23637;&#24320;&#33258;&#36866;&#24212;&#23545;&#31216;&#24615;&#26816;&#39564;&#65288;BEAST&#65289;&#12290;&#21033;&#29992;&#20108;&#36827;&#21046;&#23637;&#24320;&#36807;&#31243;&#30340;&#24615;&#36136;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22343;&#21248;&#24615;&#30340;Neyman-Pearson&#26816;&#39564;&#21487;&#20197;&#36890;&#36807;oracle&#21152;&#26435;&#21644;&#30340;&#23545;&#31216;&#24615;&#32479;&#35745;&#37327;&#26469;&#36817;&#20284;&#12290;&#20855;&#26377;&#36825;&#20010;oracle&#30340;BEAST&#25552;&#20379;&#20102;&#21487;&#34892;&#21151;&#25928;&#30340;&#21442;&#32771;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study distribution-free goodness-of-fit tests with the proposed Binary Expansion Approximation of UniformiTY (BEAUTY) approach. This method generalizes the renowned Euler's formula, and approximates the characteristic function of any copula through a linear combination of expectations of binary interactions from marginal binary expansions. This novel theory enables a unification of many important tests of independence via approximations from specific quadratic forms of symmetry statistics, where the deterministic weight matrix characterizes the power properties of each test. To achieve a robust power, we examine test statistics with data-adaptive weights, referred to as the Binary Expansion Adaptive Symmetry Test (BEAST). Using properties of the binary expansion filtration, we demonstrate that the Neyman-Pearson test of uniformity can be approximated by an oracle weighted sum of symmetry statistics. The BEAST with this oracle provides a useful benchmark of feasible power. To approac
&lt;/p&gt;</description></item><item><title>Ansor&#26159;&#19968;&#20010;&#38024;&#23545;&#28145;&#24230;&#23398;&#20064;&#24212;&#29992;&#30340;&#24352;&#37327;&#31243;&#24207;&#29983;&#25104;&#26694;&#26550;&#65292;&#36890;&#36807;&#37319;&#26679;&#31243;&#24207;&#21644;&#20351;&#29992;&#36827;&#21270;&#25628;&#32034;&#21644;&#23398;&#20064;&#30340;&#25104;&#26412;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#65292;&#33021;&#22815;&#39640;&#25928;&#22320;&#25214;&#21040;&#39640;&#24615;&#33021;&#30340;&#24352;&#37327;&#31243;&#24207;&#12290;</title><link>http://arxiv.org/abs/2006.06762</link><description>&lt;p&gt;
Ansor: &#29983;&#25104;&#29992;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#39640;&#24615;&#33021;&#24352;&#37327;&#31243;&#24207;
&lt;/p&gt;
&lt;p&gt;
Ansor: Generating High-Performance Tensor Programs for Deep Learning. (arXiv:2006.06762v5 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2006.06762
&lt;/p&gt;
&lt;p&gt;
Ansor&#26159;&#19968;&#20010;&#38024;&#23545;&#28145;&#24230;&#23398;&#20064;&#24212;&#29992;&#30340;&#24352;&#37327;&#31243;&#24207;&#29983;&#25104;&#26694;&#26550;&#65292;&#36890;&#36807;&#37319;&#26679;&#31243;&#24207;&#21644;&#20351;&#29992;&#36827;&#21270;&#25628;&#32034;&#21644;&#23398;&#20064;&#30340;&#25104;&#26412;&#27169;&#22411;&#36827;&#34892;&#24494;&#35843;&#65292;&#33021;&#22815;&#39640;&#25928;&#22320;&#25214;&#21040;&#39640;&#24615;&#33021;&#30340;&#24352;&#37327;&#31243;&#24207;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#39640;&#24615;&#33021;&#30340;&#24352;&#37327;&#31243;&#24207;&#23545;&#20110;&#20445;&#35777;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#39640;&#25928;&#25191;&#34892;&#33267;&#20851;&#37325;&#35201;&#12290;&#28982;&#32780;&#65292;&#20026;&#19981;&#21516;&#30340;&#36816;&#31639;&#31526;&#22312;&#21508;&#31181;&#30828;&#20214;&#24179;&#21488;&#19978;&#33719;&#24471;&#39640;&#24615;&#33021;&#24352;&#37327;&#31243;&#24207;&#26159;&#38750;&#24120;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#12290;&#30446;&#21069;&#65292;&#28145;&#24230;&#23398;&#20064;&#31995;&#32479;&#20381;&#36182;&#20110;&#20379;&#24212;&#21830;&#25552;&#20379;&#30340;&#20869;&#26680;&#24211;&#25110;&#21508;&#31181;&#25628;&#32034;&#31574;&#30053;&#26469;&#33719;&#21462;&#39640;&#24615;&#33021;&#30340;&#24352;&#37327;&#31243;&#24207;&#12290;&#36825;&#20123;&#26041;&#27861;&#35201;&#20040;&#38656;&#35201;&#22823;&#37327;&#30340;&#24037;&#31243;&#24037;&#20316;&#26469;&#24320;&#21457;&#29305;&#23450;&#20110;&#24179;&#21488;&#30340;&#20248;&#21270;&#20195;&#30721;&#65292;&#35201;&#20040;&#30001;&#20110;&#21463;&#38480;&#30340;&#25628;&#32034;&#31354;&#38388;&#21644;&#26080;&#25928;&#30340;&#25506;&#32034;&#31574;&#30053;&#32780;&#26080;&#27861;&#25214;&#21040;&#39640;&#24615;&#33021;&#30340;&#31243;&#24207;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;Ansor&#30340;&#24352;&#37327;&#31243;&#24207;&#29983;&#25104;&#26694;&#26550;&#65292;&#29992;&#20110;&#28145;&#24230;&#23398;&#20064;&#24212;&#29992;&#12290;&#19982;&#29616;&#26377;&#30340;&#25628;&#32034;&#31574;&#30053;&#30456;&#27604;&#65292;Ansor&#36890;&#36807;&#20174;&#25628;&#32034;&#31354;&#38388;&#30340;&#20998;&#23618;&#34920;&#31034;&#20013;&#37319;&#26679;&#31243;&#24207;&#26469;&#25506;&#32034;&#26356;&#22810;&#30340;&#20248;&#21270;&#32452;&#21512;&#12290;&#28982;&#21518;&#65292;Ansor&#20351;&#29992;&#36827;&#21270;&#25628;&#32034;&#21644;&#23398;&#20064;&#30340;&#25104;&#26412;&#27169;&#22411;&#26469;&#23545;&#37319;&#26679;&#20986;&#30340;&#31243;&#24207;&#36827;&#34892;&#24494;&#35843;&#65292;&#20197;&#25214;&#21040;&#26368;&#20339;&#31243;&#24207;&#12290;
&lt;/p&gt;
&lt;p&gt;
High-performance tensor programs are crucial to guarantee efficient execution of deep neural networks. However, obtaining performant tensor programs for different operators on various hardware platforms is notoriously challenging. Currently, deep learning systems rely on vendor-provided kernel libraries or various search strategies to get performant tensor programs. These approaches either require significant engineering effort to develop platform-specific optimization code or fall short of finding high-performance programs due to restricted search space and ineffective exploration strategy.  We present Ansor, a tensor program generation framework for deep learning applications. Compared with existing search strategies, Ansor explores many more optimization combinations by sampling programs from a hierarchical representation of the search space. Ansor then fine-tunes the sampled programs with evolutionary search and a learned cost model to identify the best programs. Ansor can find hig
&lt;/p&gt;</description></item></channel></rss>