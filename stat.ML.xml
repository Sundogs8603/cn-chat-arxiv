<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22823;&#35268;&#27169;&#32972;&#26223;&#22270;&#20013;&#26597;&#25214;&#22810;&#20010;&#23884;&#20837;&#30340;&#27169;&#26495;&#22270;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#36845;&#20195;&#24809;&#32602;&#30456;&#20284;&#24230;&#30697;&#38453;&#26469;&#23454;&#29616;&#22810;&#26679;&#21270;&#21305;&#37197;&#30340;&#21457;&#29616;&#65292;&#24182;&#25552;&#20986;&#20102;&#31639;&#27861;&#21152;&#36895;&#25514;&#26045;&#12290;&#22312;&#29702;&#35770;&#39564;&#35777;&#21644;&#23454;&#39564;&#35777;&#26126;&#20013;&#65292;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#21487;&#34892;&#24615;&#21644;&#23454;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.13451</link><description>&lt;p&gt;
&#25235;&#20303;&#23427;&#20204;&#65306;&#22270;&#21305;&#37197;&#21305;&#37197;&#28388;&#27874;&#20013;&#30340;&#35299;&#20915;&#26041;&#26696;&#22810;&#26679;&#21270;
&lt;/p&gt;
&lt;p&gt;
Gotta match 'em all: Solution diversification in graph matching matched filters. (arXiv:2308.13451v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13451
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#22823;&#35268;&#27169;&#32972;&#26223;&#22270;&#20013;&#26597;&#25214;&#22810;&#20010;&#23884;&#20837;&#30340;&#27169;&#26495;&#22270;&#30340;&#26032;&#26041;&#27861;&#65292;&#36890;&#36807;&#36845;&#20195;&#24809;&#32602;&#30456;&#20284;&#24230;&#30697;&#38453;&#26469;&#23454;&#29616;&#22810;&#26679;&#21270;&#21305;&#37197;&#30340;&#21457;&#29616;&#65292;&#24182;&#25552;&#20986;&#20102;&#31639;&#27861;&#21152;&#36895;&#25514;&#26045;&#12290;&#22312;&#29702;&#35770;&#39564;&#35777;&#21644;&#23454;&#39564;&#35777;&#26126;&#20013;&#65292;&#35777;&#26126;&#20102;&#35813;&#26041;&#27861;&#30340;&#21487;&#34892;&#24615;&#21644;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22312;&#38750;&#24120;&#22823;&#30340;&#32972;&#26223;&#22270;&#20013;&#26597;&#25214;&#22810;&#20010;&#23884;&#20837;&#22312;&#20854;&#20013;&#30340;&#27169;&#26495;&#22270;&#30340;&#26032;&#26041;&#27861;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;Sussman&#31561;&#20154;&#25552;&#20986;&#30340;&#22270;&#21305;&#37197;&#21305;&#37197;&#28388;&#27874;&#25216;&#26415;&#65292;&#36890;&#36807;&#22312;&#21305;&#37197;&#28388;&#27874;&#31639;&#27861;&#20013;&#36845;&#20195;&#22320;&#24809;&#32602;&#21512;&#36866;&#30340;&#33410;&#28857;&#23545;&#30456;&#20284;&#24230;&#30697;&#38453;&#26469;&#23454;&#29616;&#22810;&#26679;&#21270;&#21305;&#37197;&#30340;&#21457;&#29616;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#31639;&#27861;&#21152;&#36895;&#65292;&#26497;&#22823;&#22320;&#25552;&#39640;&#20102;&#25105;&#20204;&#30340;&#21305;&#37197;&#28388;&#27874;&#26041;&#27861;&#30340;&#21487;&#25193;&#23637;&#24615;&#12290;&#25105;&#20204;&#22312;&#30456;&#20851;&#30340;Erdos-Renyi&#22270;&#35774;&#32622;&#20013;&#23545;&#25105;&#20204;&#30340;&#26041;&#27861;&#36827;&#34892;&#20102;&#29702;&#35770;&#19978;&#30340;&#39564;&#35777;&#65292;&#26174;&#31034;&#20854;&#22312;&#28201;&#21644;&#30340;&#27169;&#22411;&#26465;&#20214;&#19979;&#33021;&#22815;&#39034;&#24207;&#22320;&#21457;&#29616;&#22810;&#20010;&#27169;&#26495;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#20351;&#29992;&#27169;&#25311;&#27169;&#22411;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#65288;&#21253;&#25324;&#20154;&#33041;&#36830;&#25509;&#32452;&#21644;&#22823;&#22411;&#20132;&#26131;&#30693;&#35782;&#24211;&#65289;&#36827;&#34892;&#20102;&#22823;&#37327;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present a novel approach for finding multiple noisily embedded template graphs in a very large background graph. Our method builds upon the graph-matching-matched-filter technique proposed in Sussman et al., with the discovery of multiple diverse matchings being achieved by iteratively penalizing a suitable node-pair similarity matrix in the matched filter algorithm. In addition, we propose algorithmic speed-ups that greatly enhance the scalability of our matched-filter approach. We present theoretical justification of our methodology in the setting of correlated Erdos-Renyi graphs, showing its ability to sequentially discover multiple templates under mild model conditions. We additionally demonstrate our method's utility via extensive experiments both using simulated models and real-world dataset, include human brain connectomes and a large transactional knowledge base.
&lt;/p&gt;</description></item><item><title>&#36825;&#31687;&#35770;&#25991;&#36890;&#36807;&#20998;&#26512;&#32447;&#24615;&#27169;&#22411;&#65292;&#25506;&#35752;&#20102;&#22810;&#23618;&#31070;&#32463;&#32593;&#32476;&#34892;&#20026;&#30340;&#23398;&#20064;&#12290;&#30740;&#31350;&#20351;&#29992;&#20102;&#32447;&#24615;&#22238;&#24402;&#12289;&#26680;&#23725;&#22238;&#24402;&#12289;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#21644;&#31070;&#32463;&#20999;&#32447;&#27169;&#22411;&#31561;&#22235;&#20010;&#32447;&#24615;&#21270;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#12290;&#30740;&#31350;&#36824;&#35752;&#35770;&#20102;&#32447;&#24615;&#29702;&#35770;&#30340;&#23616;&#38480;&#24615;&#21644;&#20854;&#20182;&#26041;&#27861;&#22914;&#20309;&#20811;&#26381;&#36825;&#20123;&#23616;&#38480;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.13431</link><description>&lt;p&gt;
&#32447;&#24615;&#21270;&#31070;&#32463;&#32593;&#32476;&#30340;&#20845;&#20010;&#35762;&#24231;
&lt;/p&gt;
&lt;p&gt;
Six Lectures on Linearized Neural Networks. (arXiv:2308.13431v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13431
&lt;/p&gt;
&lt;p&gt;
&#36825;&#31687;&#35770;&#25991;&#36890;&#36807;&#20998;&#26512;&#32447;&#24615;&#27169;&#22411;&#65292;&#25506;&#35752;&#20102;&#22810;&#23618;&#31070;&#32463;&#32593;&#32476;&#34892;&#20026;&#30340;&#23398;&#20064;&#12290;&#30740;&#31350;&#20351;&#29992;&#20102;&#32447;&#24615;&#22238;&#24402;&#12289;&#26680;&#23725;&#22238;&#24402;&#12289;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#21644;&#31070;&#32463;&#20999;&#32447;&#27169;&#22411;&#31561;&#22235;&#20010;&#32447;&#24615;&#21270;&#31070;&#32463;&#32593;&#32476;&#27169;&#22411;&#12290;&#30740;&#31350;&#36824;&#35752;&#35770;&#20102;&#32447;&#24615;&#29702;&#35770;&#30340;&#23616;&#38480;&#24615;&#21644;&#20854;&#20182;&#26041;&#27861;&#22914;&#20309;&#20811;&#26381;&#36825;&#20123;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#36825;&#20845;&#20010;&#35762;&#24231;&#20013;&#65292;&#25105;&#20204;&#20174;&#32447;&#24615;&#27169;&#22411;&#30340;&#20998;&#26512;&#20013;&#25506;&#35752;&#20102;&#23545;&#22810;&#23618;&#31070;&#32463;&#32593;&#32476;&#34892;&#20026;&#30340;&#23398;&#20064;&#12290;&#25105;&#20204;&#39318;&#20808;&#22238;&#39038;&#20102;&#36890;&#36807;&#25152;&#35859;&#30340;&#25042;&#24816;&#27169;&#24335;&#23558;&#31070;&#32463;&#32593;&#32476;&#19982;&#32447;&#24615;&#27169;&#22411;&#30456;&#23545;&#24212;&#30340;&#24773;&#20917;&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#22238;&#39038;&#20102;&#32447;&#24615;&#21270;&#31070;&#32463;&#32593;&#32476;&#30340;&#22235;&#20010;&#27169;&#22411;&#65306;&#24102;&#26377;&#38598;&#20013;&#29305;&#24449;&#30340;&#32447;&#24615;&#22238;&#24402;&#65292;&#26680;&#23725;&#22238;&#24402;&#65292;&#38543;&#26426;&#29305;&#24449;&#27169;&#22411;&#21644;&#31070;&#32463;&#20999;&#32447;&#27169;&#22411;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#24378;&#35843;&#20102;&#32447;&#24615;&#29702;&#35770;&#30340;&#23616;&#38480;&#24615;&#65292;&#24182;&#35752;&#35770;&#20102;&#20854;&#20182;&#26041;&#27861;&#22914;&#20309;&#20811;&#26381;&#36825;&#20123;&#23616;&#38480;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In these six lectures, we examine what can be learnt about the behavior of multi-layer neural networks from the analysis of linear models. We first recall the correspondence between neural networks and linear models via the so-called lazy regime. We then review four models for linearized neural networks: linear regression with concentrated features, kernel ridge regression, random feature model and neural tangent model. Finally, we highlight the limitations of the linear theory and discuss how other approaches can overcome them.
&lt;/p&gt;</description></item><item><title>&#36825;&#39033;&#30740;&#31350;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#22522;&#20110;&#21021;&#22987;CT&#25195;&#25551;&#65292;&#25552;&#39640;&#20102;&#23545;&#39045;&#20869;&#21160;&#33033;&#30244;&#20986;&#34880;&#24739;&#32773;&#30340;&#27515;&#20129;&#29575;&#39044;&#27979;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2308.13373</link><description>&lt;p&gt;
&#22522;&#20110;&#21021;&#22987;CT&#25195;&#25551;&#30340;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#25552;&#39640;&#20102;&#39045;&#20869;&#21160;&#33033;&#30244;&#20986;&#34880;&#24739;&#32773;&#30340;&#27515;&#20129;&#29575;&#39044;&#27979;&#33021;&#21147;
&lt;/p&gt;
&lt;p&gt;
Enhanced Mortality Prediction In Patients With Subarachnoid Haemorrhage Using A Deep Learning Model Based On The Initial CT Scan. (arXiv:2308.13373v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13373
&lt;/p&gt;
&lt;p&gt;
&#36825;&#39033;&#30740;&#31350;&#20351;&#29992;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#22522;&#20110;&#21021;&#22987;CT&#25195;&#25551;&#65292;&#25552;&#39640;&#20102;&#23545;&#39045;&#20869;&#21160;&#33033;&#30244;&#20986;&#34880;&#24739;&#32773;&#30340;&#27515;&#20129;&#29575;&#39044;&#27979;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#30446;&#30340;&#65306;&#39045;&#20869;&#21160;&#33033;&#30244;&#20986;&#34880;&#65288;SAH&#65289;&#20855;&#26377;&#36739;&#39640;&#30340;&#21457;&#30149;&#29575;&#21644;&#27515;&#20129;&#29575;&#12290;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#65288;CNN&#65289;&#26159;&#19968;&#31181;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#65292;&#33021;&#22815;&#20174;&#24433;&#20687;&#25968;&#25454;&#20013;&#29983;&#25104;&#38750;&#24120;&#20934;&#30830;&#30340;&#39044;&#27979;&#12290;&#26412;&#30740;&#31350;&#26088;&#22312;&#36890;&#36807;&#23545;&#21021;&#22987;CT&#25195;&#25551;&#36827;&#34892;CNN&#31639;&#27861;&#22788;&#29702;&#65292;&#39044;&#27979;SAH&#24739;&#32773;&#30340;&#27515;&#20129;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;
PURPOSE: Subarachnoid hemorrhage (SAH) entails high morbidity and mortality rates. Convolutional neural networks (CNN), a form of deep learning, are capable of generating highly accurate predictions from imaging data. Our objective was to predict mortality in SAH patients by processing the initial CT scan on a CNN based algorithm.  METHODS: Retrospective multicentric study of a consecutive cohort of patients with SAH between 2011-2022. Demographic, clinical and radiological variables were analyzed. Pre-processed baseline CT scan images were used as the input for training a CNN using AUCMEDI Framework. Our model's architecture leverages the DenseNet-121 structure, employing transfer learning principles. The output variable was mortality in the first three months. Performance of the model was evaluated by statistical parameters conventionally used in studies involving artificial intelligence methods.  RESULTS: Images from 219 patients were processed, 175 for training and validation of th
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25299;&#25169;&#27169;&#22411;&#65292;&#29992;&#20110;&#22312;&#31070;&#32463;&#32593;&#32476;&#20013;&#32534;&#30721;&#37096;&#20998;&#31561;&#21464;&#24615;&#65292;&#24182;&#30740;&#31350;&#20102;&#30456;&#24212;&#30340;&#27979;&#37327;&#31354;&#38388;&#21644;P-GENEO&#31354;&#38388;&#30340;&#24615;&#36136;&#12290;</title><link>http://arxiv.org/abs/2308.13357</link><description>&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#21644;&#25968;&#25454;&#20998;&#26512;&#20013;&#30340;&#37096;&#20998;&#31561;&#21464;&#24615;&#30340;&#25299;&#25169;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A topological model for partial equivariance in deep learning and data analysis. (arXiv:2308.13357v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13357
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25299;&#25169;&#27169;&#22411;&#65292;&#29992;&#20110;&#22312;&#31070;&#32463;&#32593;&#32476;&#20013;&#32534;&#30721;&#37096;&#20998;&#31561;&#21464;&#24615;&#65292;&#24182;&#30740;&#31350;&#20102;&#30456;&#24212;&#30340;&#27979;&#37327;&#31354;&#38388;&#21644;P-GENEO&#31354;&#38388;&#30340;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25299;&#25169;&#27169;&#22411;&#65292;&#29992;&#20110;&#22312;&#31070;&#32463;&#32593;&#32476;&#20013;&#32534;&#30721;&#37096;&#20998;&#31561;&#21464;&#24615;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31867;&#31216;&#20026;P-GENEO&#30340;&#36816;&#31639;&#31526;&#65292;&#20197;&#38750;&#25193;&#24352;&#30340;&#26041;&#24335;&#25913;&#21464;&#36890;&#36807;&#27979;&#37327;&#34920;&#31034;&#30340;&#25968;&#25454;&#65292;&#24182;&#36981;&#24490;&#19968;&#23450;&#38598;&#21512;&#30340;&#21464;&#25442;&#20316;&#29992;&#12290;&#22914;&#26524;&#21464;&#25442;&#20316;&#29992;&#30340;&#38598;&#21512;&#26159;&#19968;&#20010;&#32676;&#65292;&#21017;&#24471;&#21040;&#25152;&#35859;&#30340;GENEO&#12290;&#28982;&#21518;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#21463;&#26576;&#20123;&#33258;&#26144;&#23556;&#20316;&#29992;&#30340;&#27979;&#37327;&#31354;&#38388;&#20197;&#21450;&#36825;&#20123;&#31354;&#38388;&#20043;&#38388;&#30340;P-GENEO&#31354;&#38388;&#12290;&#25105;&#20204;&#22312;&#23427;&#20204;&#19978;&#23450;&#20041;&#20102;&#20266;&#24230;&#37327;&#65292;&#24182;&#23637;&#31034;&#20102;&#19968;&#20123;&#32467;&#26524;&#31354;&#38388;&#30340;&#24615;&#36136;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#36825;&#20123;&#31354;&#38388;&#20855;&#26377;&#20415;&#21033;&#30340;&#36924;&#36817;&#21644;&#20984;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this article, we propose a topological model to encode partial equivariance in neural networks. To this end, we introduce a class of operators, called P-GENEOs, that change data expressed by measurements, respecting the action of certain sets of transformations, in a non-expansive way. If the set of transformations acting is a group, then we obtain the so-called GENEOs. We then study the spaces of measurements, whose domains are subject to the action of certain self-maps, and the space of P-GENEOs between these spaces. We define pseudo-metrics on them and show some properties of the resulting spaces. In particular, we show how such spaces have convenient approximation and convexity properties.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#25512;&#29702;&#30340;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#65288;PINN&#65289;&#12290;&#35813;&#26041;&#27861;&#37319;&#29992;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#65292;&#36890;&#36807;&#35745;&#31639;&#35777;&#25454;&#26469;&#20248;&#21270;&#27169;&#22411;&#24182;&#35299;&#20915;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2308.13222</link><description>&lt;p&gt;
&#29992;&#20110;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#30340;&#36125;&#21494;&#26031;&#25512;&#29702;
&lt;/p&gt;
&lt;p&gt;
Bayesian Reasoning for Physics Informed Neural Networks. (arXiv:2308.13222v1 [physics.comp-ph])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13222
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#25512;&#29702;&#30340;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#26041;&#27861;&#65288;PINN&#65289;&#12290;&#35813;&#26041;&#27861;&#37319;&#29992;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#65292;&#36890;&#36807;&#35745;&#31639;&#35777;&#25454;&#26469;&#20248;&#21270;&#27169;&#22411;&#24182;&#35299;&#20915;&#19981;&#30830;&#23450;&#24615;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#36125;&#21494;&#26031;&#20844;&#24335;&#30340;&#29289;&#29702;&#20449;&#24687;&#31070;&#32463;&#32593;&#32476;&#65288;PINN&#65289;&#26041;&#27861;&#12290;&#25105;&#20204;&#37319;&#29992;&#20102;MacKay&#22312;Neural Computation&#65288;1992&#24180;&#65289;&#20013;&#25552;&#20986;&#30340;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#12290;&#36890;&#36807;&#25289;&#26222;&#25289;&#26031;&#36817;&#20284;&#27861;&#65292;&#24471;&#21040;&#21518;&#39564;&#23494;&#24230;&#12290;&#23545;&#20110;&#27599;&#20010;&#27169;&#22411;&#65288;&#25311;&#21512;&#65289;&#65292;&#35745;&#31639;&#25152;&#35859;&#30340;&#35777;&#25454;&#12290;&#23427;&#26159;&#19968;&#31181;&#20998;&#31867;&#20551;&#35774;&#30340;&#24230;&#37327;&#12290;&#26368;&#20248;&#35299;&#20855;&#26377;&#26368;&#22823;&#30340;&#35777;&#25454;&#20540;&#12290;&#36125;&#21494;&#26031;&#26694;&#26550;&#20351;&#25105;&#20204;&#33021;&#22815;&#25511;&#21046;&#36793;&#30028;&#23545;&#24635;&#25439;&#22833;&#30340;&#24433;&#21709;&#12290;&#20107;&#23454;&#19978;&#65292;&#36125;&#21494;&#26031;&#31639;&#27861;&#36890;&#36807;&#24494;&#35843;&#25439;&#22833;&#32452;&#20214;&#30340;&#30456;&#23545;&#26435;&#37325;&#12290;&#25105;&#20204;&#35299;&#20915;&#20102;&#28909;&#21147;&#23398;&#12289;&#27874;&#21160;&#21644;Burger&#26041;&#31243;&#12290;&#25152;&#24471;&#32467;&#26524;&#19982;&#31934;&#30830;&#35299;&#22522;&#26412;&#19968;&#33268;&#12290;&#25152;&#26377;&#35299;&#37117;&#25552;&#20379;&#20102;&#22312;&#36125;&#21494;&#26031;&#26694;&#26550;&#20869;&#35745;&#31639;&#30340;&#19981;&#30830;&#23450;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Physics informed neural network (PINN) approach in Bayesian formulation is presented. We adopt the Bayesian neural network framework formulated by MacKay (Neural Computation 4 (3) (1992) 448). The posterior densities are obtained from Laplace approximation. For each model (fit), the so-called evidence is computed. It is a measure that classifies the hypothesis. The most optimal solution has the maximal value of the evidence. The Bayesian framework allows us to control the impact of the boundary contribution to the total loss. Indeed, the relative weights of loss components are fine-tuned by the Bayesian algorithm. We solve heat, wave, and Burger's equations. The obtained results are in good agreement with the exact solutions. All solutions are provided with the uncertainties computed within the Bayesian framework.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#21487;&#21152;&#27169;&#22411;&#65292;&#29992;&#20110;&#20272;&#35745;&#21487;&#35299;&#37322;&#30340;&#20540;&#20989;&#25968;&#65292;&#24182;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#20855;&#26377;&#24212;&#29992;&#20215;&#20540;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#20811;&#26381;&#20256;&#32479;&#27169;&#22411;&#30340;&#32447;&#24615;&#20551;&#35774;&#38480;&#21046;&#65292;&#21516;&#26102;&#25552;&#20379;&#36739;&#24378;&#30340;&#20915;&#31574;&#24314;&#35758;&#35299;&#37322;&#24615;&#12290;</title><link>http://arxiv.org/abs/2308.13135</link><description>&lt;p&gt;
&#38750;&#21442;&#25968;&#21487;&#21152;&#20540;&#20989;&#25968;&#65306;&#20855;&#26377;&#21487;&#35299;&#37322;&#24615;&#30340;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#21450;&#20854;&#22312;&#22806;&#31185;&#25163;&#26415;&#24674;&#22797;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Nonparametric Additive Value Functions: Interpretable Reinforcement Learning with an Application to Surgical Recovery. (arXiv:2308.13135v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13135
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#21487;&#21152;&#27169;&#22411;&#65292;&#29992;&#20110;&#20272;&#35745;&#21487;&#35299;&#37322;&#30340;&#20540;&#20989;&#25968;&#65292;&#24182;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#20855;&#26377;&#24212;&#29992;&#20215;&#20540;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#20811;&#26381;&#20256;&#32479;&#27169;&#22411;&#30340;&#32447;&#24615;&#20551;&#35774;&#38480;&#21046;&#65292;&#21516;&#26102;&#25552;&#20379;&#36739;&#24378;&#30340;&#20915;&#31574;&#24314;&#35758;&#35299;&#37322;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#21442;&#25968;&#21487;&#21152;&#27169;&#22411;&#65292;&#29992;&#20110;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#20272;&#35745;&#21487;&#35299;&#37322;&#30340;&#20540;&#20989;&#25968;&#12290;&#23398;&#20064;&#20381;&#38752;&#25968;&#23383;&#34920;&#22411;&#29305;&#24449;&#30340;&#26377;&#25928;&#33258;&#36866;&#24212;&#20020;&#24202;&#24178;&#39044;&#26159;&#21307;&#21153;&#20154;&#21592;&#37325;&#35270;&#30340;&#38382;&#39064;&#12290;&#22312;&#33034;&#26609;&#25163;&#26415;&#26041;&#38754;&#65292;&#20851;&#20110;&#24739;&#32773;&#36816;&#21160;&#33021;&#21147;&#24674;&#22797;&#30340;&#19981;&#21516;&#26415;&#21518;&#24674;&#22797;&#24314;&#35758;&#21487;&#33021;&#20250;&#23548;&#33268;&#24739;&#32773;&#24674;&#22797;&#31243;&#24230;&#30340;&#26174;&#33879;&#21464;&#21270;&#12290;&#34429;&#28982;&#24378;&#21270;&#23398;&#20064;&#22312;&#28216;&#25103;&#31561;&#39046;&#22495;&#21462;&#24471;&#20102;&#24191;&#27867;&#25104;&#21151;&#65292;&#20294;&#26368;&#36817;&#30340;&#26041;&#27861;&#20005;&#37325;&#20381;&#36182;&#20110;&#40657;&#30418;&#26041;&#27861;&#65292;&#22914;&#31070;&#32463;&#32593;&#32476;&#12290;&#19981;&#24184;&#30340;&#26159;&#65292;&#36825;&#20123;&#26041;&#27861;&#38459;&#30861;&#20102;&#32771;&#23519;&#27599;&#20010;&#29305;&#24449;&#23545;&#20110;&#20135;&#29983;&#26368;&#32456;&#24314;&#35758;&#20915;&#31574;&#30340;&#36129;&#29486;&#12290;&#34429;&#28982;&#22312;&#32463;&#20856;&#31639;&#27861;&#65288;&#22914;&#26368;&#23567;&#20108;&#20056;&#31574;&#30053;&#36845;&#20195;&#65289;&#20013;&#21487;&#20197;&#36731;&#26494;&#25552;&#20379;&#36825;&#26679;&#30340;&#35299;&#37322;&#65292;&#20294;&#22522;&#26412;&#30340;&#32447;&#24615;&#20551;&#35774;&#38459;&#27490;&#20102;&#23398;&#20064;&#29305;&#24449;&#20043;&#38388;&#30340;&#39640;&#38454;&#28789;&#27963;&#20132;&#20114;&#20316;&#29992;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26041;&#27861;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#28789;&#27963;&#30340;&#25216;&#26415;&#26469;&#20811;&#26381;&#36825;&#20123;&#38480;&#21046;&#65292;&#24182;&#33021;&#22815;&#24471;&#21040;&#35299;&#37322;&#24615;&#24378;&#30340;&#20915;&#31574;&#24314;&#35758;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a nonparametric additive model for estimating interpretable value functions in reinforcement learning. Learning effective adaptive clinical interventions that rely on digital phenotyping features is a major for concern medical practitioners. With respect to spine surgery, different post-operative recovery recommendations concerning patient mobilization can lead to significant variation in patient recovery. While reinforcement learning has achieved widespread success in domains such as games, recent methods heavily rely on black-box methods, such neural networks. Unfortunately, these methods hinder the ability of examining the contribution each feature makes in producing the final suggested decision. While such interpretations are easily provided in classical algorithms such as Least Squares Policy Iteration, basic linearity assumptions prevent learning higher-order flexible interactions between features. In this paper, we present a novel method that offers a flexible techniq
&lt;/p&gt;</description></item><item><title>&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#24322;&#24120;&#26816;&#27979;&#26159;&#19968;&#20010;&#30740;&#31350;&#39046;&#22495;&#65292;&#20294;&#30446;&#21069;&#23384;&#22312;&#32452;&#32455;&#19981;&#22815;&#26377;&#24207;&#21644;&#35780;&#20272;&#21327;&#35758;&#26377;&#32570;&#38519;&#30340;&#38382;&#39064;&#12290;&#25991;&#31456;&#35780;&#20272;&#20102;&#35768;&#22810;&#26368;&#36817;&#31639;&#27861;&#30340;&#24615;&#33021;&#65292;&#24182;&#25351;&#20986;&#20102;&#38024;&#23545;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#24322;&#24120;&#26816;&#27979;&#30340;&#35780;&#20272;&#21327;&#35758;&#23384;&#22312;&#30340;&#38382;&#39064;&#21450;&#22914;&#20309;&#32531;&#35299;&#36825;&#20123;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2308.13068</link><description>&lt;p&gt;
&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#24322;&#24120;&#26816;&#27979;: &#28843;&#37239;&#31639;&#27861;&#21644;&#26377;&#32570;&#38519;&#30340;&#35780;&#20272;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Multivariate Time Series Anomaly Detection: Fancy Algorithms and Flawed Evaluation Methodology. (arXiv:2308.13068v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2308.13068
&lt;/p&gt;
&lt;p&gt;
&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#24322;&#24120;&#26816;&#27979;&#26159;&#19968;&#20010;&#30740;&#31350;&#39046;&#22495;&#65292;&#20294;&#30446;&#21069;&#23384;&#22312;&#32452;&#32455;&#19981;&#22815;&#26377;&#24207;&#21644;&#35780;&#20272;&#21327;&#35758;&#26377;&#32570;&#38519;&#30340;&#38382;&#39064;&#12290;&#25991;&#31456;&#35780;&#20272;&#20102;&#35768;&#22810;&#26368;&#36817;&#31639;&#27861;&#30340;&#24615;&#33021;&#65292;&#24182;&#25351;&#20986;&#20102;&#38024;&#23545;&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#24322;&#24120;&#26816;&#27979;&#30340;&#35780;&#20272;&#21327;&#35758;&#23384;&#22312;&#30340;&#38382;&#39064;&#21450;&#22914;&#20309;&#32531;&#35299;&#36825;&#20123;&#38382;&#39064;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22810;&#20803;&#26102;&#38388;&#24207;&#21015;&#65288;MVTS&#65289;&#30340;&#24322;&#24120;&#26816;&#27979;&#26159;&#19968;&#20010;&#38271;&#26399;&#23384;&#22312;&#19988;&#20855;&#26377;&#25361;&#25112;&#24615;&#30340;&#30740;&#31350;&#35838;&#39064;&#65292;&#36817;&#24180;&#26469;&#21560;&#24341;&#20102;&#24037;&#19994;&#30028;&#21644;&#23398;&#26415;&#30028;&#30340;&#22823;&#37327;&#30740;&#31350;&#21162;&#21147;&#12290;&#28982;&#32780;&#65292;&#23545;&#25991;&#29486;&#30340;&#20180;&#32454;&#30740;&#31350;&#35753;&#25105;&#20204;&#24847;&#35782;&#21040;&#65306;1&#65289;&#35813;&#39046;&#22495;&#30340;&#31038;&#21306;&#27963;&#36291;&#65292;&#20294;&#24182;&#19981;&#20687;&#35745;&#31639;&#26426;&#35270;&#35273;&#65288;CV&#65289;&#21644;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#31561;&#20854;&#20182;&#26426;&#22120;&#23398;&#20064;&#39046;&#22495;&#37027;&#26679;&#32452;&#32455;&#26377;&#24207;&#65307;2&#65289;&#22823;&#22810;&#25968;&#25552;&#20986;&#30340;&#35299;&#20915;&#26041;&#26696;&#20351;&#29992;&#19981;&#21512;&#36866;&#25110;&#23384;&#22312;&#26126;&#26174;&#32570;&#38519;&#30340;&#35780;&#20272;&#21327;&#35758;&#36827;&#34892;&#35780;&#20272;&#65292;&#32570;&#20047;&#31185;&#23398;&#22522;&#30784;&#12290;&#20854;&#20013;&#19968;&#20010;&#38750;&#24120;&#27969;&#34892;&#30340;&#21327;&#35758;&#65292;&#21363;&#25152;&#35859;&#30340; \pa &#21327;&#35758;&#65292;&#26159;&#22914;&#27492;&#26377;&#32570;&#38519;&#65292;&#20197;&#33267;&#20110;&#38543;&#26426;&#29468;&#27979;&#21487;&#20197;&#26174;&#31034;&#31995;&#32479;&#22320;&#20248;&#20110;&#36804;&#20170;&#20026;&#27490;&#24320;&#21457;&#30340;\emph{&#25152;&#26377;}&#31639;&#27861;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#26356;&#20581;&#22766;&#30340;&#21327;&#35758;&#23545;&#35768;&#22810;&#26368;&#36817;&#30340;&#31639;&#27861;&#36827;&#34892;&#22238;&#39038;&#21644;&#35780;&#20272;&#65292;&#24182;&#35752;&#35770;&#22312;MVTS&#24322;&#24120;&#26816;&#27979;&#30340;&#32972;&#26223;&#19979;&#65292;&#19968;&#20010;&#26412;&#26469;&#24456;&#22909;&#30340;&#21327;&#35758;&#21487;&#33021;&#23384;&#22312;&#30340;&#38382;&#39064;&#20197;&#21450;&#22914;&#20309;&#20943;&#36731;&#36825;&#20123;&#38382;&#39064;&#12290;&#25105;&#20204;&#36824;&#23545;&#22522;&#20934;&#25968;&#25454;&#38598;&#34920;&#36798;&#20102;&#20851;&#20999;&#12290;
&lt;/p&gt;
&lt;p&gt;
Multivariate Time Series (MVTS) anomaly detection is a long-standing and challenging research topic that has attracted tremendous research effort from both industry and academia recently. However, a careful study of the literature makes us realize that 1) the community is active but not as organized as other sibling machine learning communities such as Computer Vision (CV) and Natural Language Processing (NLP), and 2) most proposed solutions are evaluated using either inappropriate or highly flawed protocols, with an apparent lack of scientific foundation. So flawed is one very popular protocol, the so-called \pa protocol, that a random guess can be shown to systematically outperform \emph{all} algorithms developed so far. In this paper, we review and evaluate many recent algorithms using more robust protocols and discuss how a normally good protocol may have weaknesses in the context of MVTS anomaly detection and how to mitigate them. We also share our concerns about benchmark dataset
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37327;&#23376;&#26680;&#28151;&#21512;&#26041;&#27861;&#65292;&#21487;&#20197;&#29992;&#20110;&#34920;&#31034;&#36830;&#32493;&#21644;&#31163;&#25955;&#38543;&#26426;&#21464;&#37327;&#30340;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#12290;&#35813;&#26694;&#26550;&#20801;&#35768;&#26500;&#24314;&#21487;&#24494;&#20998;&#30340;&#27169;&#22411;&#65292;&#36866;&#29992;&#20110;&#23494;&#24230;&#20272;&#35745;&#12289;&#25512;&#29702;&#21644;&#37319;&#26679;&#65292;&#20197;&#21450;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#65292;&#21253;&#25324;&#29983;&#25104;&#24314;&#27169;&#21644;&#21028;&#21035;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2305.18204</link><description>&lt;p&gt;
&#27010;&#29575;&#28145;&#24230;&#23398;&#20064;&#30340;&#37327;&#23376;&#26680;&#28151;&#21512;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Quantum Kernel Mixtures for Probabilistic Deep Learning. (arXiv:2305.18204v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2305.18204
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#37327;&#23376;&#26680;&#28151;&#21512;&#26041;&#27861;&#65292;&#21487;&#20197;&#29992;&#20110;&#34920;&#31034;&#36830;&#32493;&#21644;&#31163;&#25955;&#38543;&#26426;&#21464;&#37327;&#30340;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#12290;&#35813;&#26694;&#26550;&#20801;&#35768;&#26500;&#24314;&#21487;&#24494;&#20998;&#30340;&#27169;&#22411;&#65292;&#36866;&#29992;&#20110;&#23494;&#24230;&#20272;&#35745;&#12289;&#25512;&#29702;&#21644;&#37319;&#26679;&#65292;&#20197;&#21450;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#65292;&#21253;&#25324;&#29983;&#25104;&#24314;&#27169;&#21644;&#21028;&#21035;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27010;&#29575;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#8212;&#8212;&#37327;&#23376;&#26680;&#28151;&#21512;&#65292;&#23427;&#26159;&#20174;&#37327;&#23376;&#23494;&#24230;&#30697;&#38453;&#30340;&#25968;&#23398;&#24418;&#24335;&#20013;&#25512;&#23548;&#20986;&#26469;&#30340;&#12290;&#35813;&#26041;&#27861;&#25552;&#20379;&#20102;&#19968;&#31181;&#31616;&#21333;&#32780;&#26377;&#25928;&#30340;&#26426;&#21046;&#65292;&#29992;&#20110;&#34920;&#31034;&#36830;&#32493;&#21644;&#31163;&#25955;&#38543;&#26426;&#21464;&#37327;&#30340;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#12290;&#35813;&#26694;&#26550;&#20801;&#35768;&#26500;&#24314;&#21487;&#24494;&#20998;&#30340;&#27169;&#22411;&#65292;&#29992;&#20110;&#23494;&#24230;&#20272;&#35745;&#12289;&#25512;&#29702;&#21644;&#37319;&#26679;&#65292;&#20174;&#32780;&#33021;&#22815;&#25972;&#21512;&#21040;&#31471;&#21040;&#31471;&#30340;&#28145;&#24230;&#31070;&#32463;&#27169;&#22411;&#20013;&#12290;&#36890;&#36807;&#36825;&#26679;&#20570;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#22810;&#21151;&#33021;&#30340;&#36793;&#38469;&#21644;&#32852;&#21512;&#27010;&#29575;&#20998;&#24067;&#34920;&#31034;&#65292;&#21487;&#20197;&#24320;&#21457;&#19968;&#31181;&#21487;&#24494;&#20998;&#30340;&#12289;&#32452;&#21512;&#30340;&#21644;&#21487;&#36870;&#30340;&#25512;&#29702;&#36807;&#31243;&#65292;&#28085;&#30422;&#20102;&#24191;&#27867;&#30340;&#26426;&#22120;&#23398;&#20064;&#20219;&#21153;&#65292;&#21253;&#25324;&#23494;&#24230;&#20272;&#35745;&#12289;&#21028;&#21035;&#23398;&#20064;&#21644;&#29983;&#25104;&#24314;&#27169;&#12290;&#25105;&#20204;&#36890;&#36807;&#20004;&#20010;&#31034;&#20363;&#26469;&#35828;&#26126;&#35813;&#26694;&#26550;&#30340;&#24191;&#27867;&#36866;&#29992;&#24615;&#65306;&#19968;&#20010;&#22270;&#20687;&#20998;&#31867;&#27169;&#22411;&#65292;&#23427;&#21487;&#20197;&#33258;&#28982;&#22320;&#36716;&#21270;&#20026;&#26465;&#20214;&#29983;&#25104;&#27169;&#22411;&#65292;&#24471;&#30410;&#20110;&#37327;&#23376;&#26680;&#28151;&#21512;&#30340;&#34920;&#31034;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper presents a novel approach to probabilistic deep learning (PDL), quantum kernel mixtures, derived from the mathematical formalism of quantum density matrices, which provides a simpler yet effective mechanism for representing joint probability distributions of both continuous and discrete random variables. The framework allows for the construction of differentiable models for density estimation, inference, and sampling, enabling integration into end-to-end deep neural models. In doing so, we provide a versatile representation of marginal and joint probability distributions that allows us to develop a differentiable, compositional, and reversible inference procedure that covers a wide range of machine learning tasks, including density estimation, discriminative learning, and generative modeling. We illustrate the broad applicability of the framework with two examples: an image classification model, which can be naturally transformed into a conditional generative model thanks to
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#8220;&#30830;&#23450;&#24615;ADVI&#8221;&#65288;DADVI&#65289;&#65292;&#23427;&#29992;&#19968;&#31181;&#22266;&#23450;&#30340;&#33945;&#29305;&#21345;&#32599;&#36817;&#20284;&#26367;&#25442;&#20102;&#22343;&#20540;&#22330;&#21464;&#20998;&#36125;&#21494;&#26031;&#65288;MFVB&#65289;&#30340;&#19981;&#21487;&#35299;&#30446;&#26631;&#65292;&#21487;&#20197;&#20351;&#29992;&#29616;&#25104;&#30340;&#20108;&#38454;&#20248;&#21270;&#65292;&#36866;&#29992;&#20110;&#26356;&#20934;&#30830;&#30340;&#21518;&#39564;&#32447;&#24615;&#21709;&#24212;&#65288;LR&#65289;&#21327;&#26041;&#24046;&#20272;&#35745;&#65292;&#22312;&#26576;&#20123;&#24120;&#35265;&#30340;&#32479;&#35745;&#38382;&#39064;&#31867;&#21035;&#19978;&#25928;&#26524;&#26356;&#22909;&#12290;</title><link>http://arxiv.org/abs/2304.05527</link><description>&lt;p&gt;
&#19968;&#31181;&#20351;&#29992;&#30830;&#23450;&#24615;&#30446;&#26631;&#30340;&#40657;&#21283;&#23376;&#21464;&#20998;&#25512;&#26029;&#65306;&#26356;&#24555;&#65292;&#26356;&#31934;&#30830;&#65292;&#26356;&#40657;&#12290;
&lt;/p&gt;
&lt;p&gt;
Black Box Variational Inference with a Deterministic Objective: Faster, More Accurate, and Even More Black Box. (arXiv:2304.05527v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05527
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#8220;&#30830;&#23450;&#24615;ADVI&#8221;&#65288;DADVI&#65289;&#65292;&#23427;&#29992;&#19968;&#31181;&#22266;&#23450;&#30340;&#33945;&#29305;&#21345;&#32599;&#36817;&#20284;&#26367;&#25442;&#20102;&#22343;&#20540;&#22330;&#21464;&#20998;&#36125;&#21494;&#26031;&#65288;MFVB&#65289;&#30340;&#19981;&#21487;&#35299;&#30446;&#26631;&#65292;&#21487;&#20197;&#20351;&#29992;&#29616;&#25104;&#30340;&#20108;&#38454;&#20248;&#21270;&#65292;&#36866;&#29992;&#20110;&#26356;&#20934;&#30830;&#30340;&#21518;&#39564;&#32447;&#24615;&#21709;&#24212;&#65288;LR&#65289;&#21327;&#26041;&#24046;&#20272;&#35745;&#65292;&#22312;&#26576;&#20123;&#24120;&#35265;&#30340;&#32479;&#35745;&#38382;&#39064;&#31867;&#21035;&#19978;&#25928;&#26524;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33258;&#21160;&#24494;&#20998;&#21464;&#20998;&#25512;&#26029;&#65288;ADVI&#65289;&#25552;&#20379;&#20102;&#22810;&#31181;&#29616;&#20195;&#27010;&#29575;&#32534;&#31243;&#35821;&#35328;&#20013;&#24555;&#36895;&#26131;&#29992;&#30340;&#21518;&#39564;&#36817;&#20284;&#26041;&#27861;&#12290;&#28982;&#32780;&#23427;&#30340;&#38543;&#26426;&#20248;&#21270;&#22120;&#32570;&#20047;&#26126;&#30830;&#30340;&#25910;&#25947;&#26631;&#20934;&#65292;&#24182;&#19988;&#38656;&#35201;&#35843;&#25972;&#21442;&#25968;&#12290;&#27492;&#22806;&#65292;ADVI&#32487;&#25215;&#20102;&#22343;&#20540;&#22330;&#21464;&#20998;&#36125;&#21494;&#26031;&#65288;MFVB&#65289;&#30340;&#36739;&#24046;&#21518;&#39564;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#8220;&#30830;&#23450;&#24615;ADVI&#8221;&#65288;DADVI&#65289;&#26469;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#12290;DADVI&#29992;&#22266;&#23450;&#30340;&#33945;&#29305;&#21345;&#32599;&#36817;&#20284;&#26367;&#25442;&#20102;MFVB&#30340;&#19981;&#21487;&#35299;&#30446;&#26631;&#65292;&#36825;&#19968;&#25216;&#26415;&#22312;&#38543;&#26426;&#20248;&#21270;&#25991;&#29486;&#20013;&#34987;&#31216;&#20026;&#8220;&#26679;&#26412;&#24179;&#22343;&#36817;&#20284;&#8221;&#65288;SAA&#65289;&#12290;&#36890;&#36807;&#20248;&#21270;&#36817;&#20284;&#20294;&#30830;&#23450;&#30340;&#30446;&#26631;&#65292;DADVI&#21487;&#20197;&#20351;&#29992;&#29616;&#25104;&#30340;&#20108;&#38454;&#20248;&#21270;&#65292;&#32780;&#19988;&#19982;&#26631;&#20934;&#22343;&#20540;&#22330;ADVI&#19981;&#21516;&#30340;&#26159;&#65292;&#21487;&#20197;&#36866;&#29992;&#20110;&#26356;&#20934;&#30830;&#30340;&#21518;&#39564;&#32447;&#24615;&#21709;&#24212;&#65288;LR&#65289;&#21327;&#26041;&#24046;&#20272;&#35745;&#12290;&#19982;&#29616;&#26377;&#30340;&#26368;&#22351;&#24773;&#20917;&#29702;&#35770;&#30456;&#21453;&#65292;&#25105;&#20204;&#34920;&#26126;&#65292;&#22312;&#26576;&#20123;&#24120;&#35265;&#30340;&#32479;&#35745;&#38382;&#39064;&#31867;&#21035;&#19978;&#65292;DADVI&#21644;SAA&#21487;&#20197;&#34920;&#29616;&#24471;&#26356;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;
Automatic differentiation variational inference (ADVI) offers fast and easy-to-use posterior approximation in multiple modern probabilistic programming languages. However, its stochastic optimizer lacks clear convergence criteria and requires tuning parameters. Moreover, ADVI inherits the poor posterior uncertainty estimates of mean-field variational Bayes (MFVB). We introduce ``deterministic ADVI'' (DADVI) to address these issues. DADVI replaces the intractable MFVB objective with a fixed Monte Carlo approximation, a technique known in the stochastic optimization literature as the ``sample average approximation'' (SAA). By optimizing an approximate but deterministic objective, DADVI can use off-the-shelf second-order optimization, and, unlike standard mean-field ADVI, is amenable to more accurate posterior linear response (LR) covariance estimates. In contrast to existing worst-case theory, we show that, on certain classes of common statistical problems, DADVI and the SAA can perform 
&lt;/p&gt;</description></item><item><title>StepMix&#26159;&#19968;&#20010;&#29992;&#20110;&#22806;&#37096;&#21464;&#37327;&#24191;&#20041;&#28151;&#21512;&#27169;&#22411;&#30340;&#20266;&#20284;&#28982;&#20272;&#35745;&#30340;Python&#21253;&#65292;&#25552;&#20379;&#20102;&#21333;&#27493;&#21644;&#36880;&#27493;&#20272;&#35745;&#26041;&#27861;&#65292;&#24110;&#21161;&#20174;&#19994;&#20154;&#21592;&#36827;&#34892;&#27169;&#22411;&#20272;&#35745;&#12289;&#36873;&#25321;&#21644;&#35299;&#37322;&#12290;</title><link>http://arxiv.org/abs/2304.03853</link><description>&lt;p&gt;
StepMix: &#19968;&#20010;&#29992;&#20110;&#22806;&#37096;&#21464;&#37327;&#24191;&#20041;&#28151;&#21512;&#27169;&#22411;&#30340;&#20266;&#20284;&#28982;&#20272;&#35745;&#30340;Python&#21253;
&lt;/p&gt;
&lt;p&gt;
StepMix: A Python Package for Pseudo-Likelihood Estimation of Generalized Mixture Models with External Variables. (arXiv:2304.03853v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.03853
&lt;/p&gt;
&lt;p&gt;
StepMix&#26159;&#19968;&#20010;&#29992;&#20110;&#22806;&#37096;&#21464;&#37327;&#24191;&#20041;&#28151;&#21512;&#27169;&#22411;&#30340;&#20266;&#20284;&#28982;&#20272;&#35745;&#30340;Python&#21253;&#65292;&#25552;&#20379;&#20102;&#21333;&#27493;&#21644;&#36880;&#27493;&#20272;&#35745;&#26041;&#27861;&#65292;&#24110;&#21161;&#20174;&#19994;&#20154;&#21592;&#36827;&#34892;&#27169;&#22411;&#20272;&#35745;&#12289;&#36873;&#25321;&#21644;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
StepMix&#26159;&#19968;&#20010;&#29992;&#20110;&#24191;&#20041;&#26377;&#38480;&#28151;&#21512;&#27169;&#22411;(&#28508;&#22312;&#21078;&#38754;&#21644;&#28508;&#22312;&#31867;&#20998;&#26512;)&#19982;&#22806;&#37096;&#21464;&#37327;(&#21327;&#21464;&#37327;&#21644;&#36828;&#31243;&#32467;&#26524;)&#30340;&#20266;&#20284;&#28982;&#20272;&#35745;(&#21333;&#27493;&#12289;&#20004;&#27493;&#21644;&#19977;&#27493;&#26041;&#27861;)&#30340;&#24320;&#28304;&#36719;&#20214;&#21253;&#12290;&#22312;&#35768;&#22810;&#31038;&#20250;&#31185;&#23398;&#30340;&#24212;&#29992;&#20013;&#65292;&#20027;&#35201;&#30446;&#26631;&#19981;&#20165;&#26159;&#23558;&#20010;&#20307;&#32858;&#31867;&#25104;&#28508;&#22312;&#31867;&#21035;&#65292;&#36824;&#21253;&#25324;&#20351;&#29992;&#36825;&#20123;&#31867;&#21035;&#26469;&#24320;&#21457;&#26356;&#22797;&#26434;&#30340;&#32479;&#35745;&#27169;&#22411;&#12290;&#36825;&#20123;&#27169;&#22411;&#36890;&#24120;&#20998;&#20026;&#19968;&#20010;&#23558;&#28508;&#22312;&#31867;&#21035;&#19982;&#35266;&#23519;&#25351;&#26631;&#30456;&#20851;&#32852;&#30340;&#27979;&#37327;&#27169;&#22411;&#21644;&#19968;&#20010;&#23558;&#21327;&#21464;&#37327;&#21644;&#32467;&#26524;&#21464;&#37327;&#19982;&#28508;&#22312;&#31867;&#21035;&#30456;&#20851;&#32852;&#30340;&#32467;&#26500;&#27169;&#22411;&#12290;&#27979;&#37327;&#21644;&#32467;&#26500;&#27169;&#22411;&#21487;&#20197;&#20351;&#29992;&#25152;&#35859;&#30340;&#19968;&#27493;&#27861;&#20849;&#21516;&#20272;&#35745;&#65292;&#20063;&#21487;&#20197;&#20351;&#29992;&#36880;&#27493;&#26041;&#27861;&#36880;&#27493;&#20272;&#35745;&#65292;&#23545;&#20110;&#20174;&#19994;&#20154;&#21592;&#26469;&#35828;&#65292;&#36825;&#20123;&#26041;&#27861;&#22312;&#20272;&#35745;&#28508;&#22312;&#31867;&#21035;&#30340;&#21487;&#35299;&#37322;&#24615;&#26041;&#38754;&#20855;&#26377;&#26174;&#33879;&#20248;&#21183;&#12290;&#38500;&#20102;&#19968;&#27493;&#27861;&#65292;StepMix&#36824;&#23454;&#29616;&#20102;&#25991;&#29486;&#20013;&#25552;&#20986;&#30340;&#26368;&#37325;&#35201;&#30340;&#36880;&#27493;&#20272;&#35745;&#26041;&#27861;&#65292;&#25552;&#20379;&#20102;&#29992;&#25143;&#21451;&#22909;&#30340;&#30028;&#38754;&#65292;&#26041;&#20415;&#27169;&#22411;&#30340;&#20272;&#35745;&#12289;&#36873;&#25321;&#21644;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
StepMix is an open-source software package for the pseudo-likelihood estimation (one-, two- and three-step approaches) of generalized finite mixture models (latent profile and latent class analysis) with external variables (covariates and distal outcomes). In many applications in social sciences, the main objective is not only to cluster individuals into latent classes, but also to use these classes to develop more complex statistical models. These models generally divide into a measurement model that relates the latent classes to observed indicators, and a structural model that relates covariates and outcome variables to the latent classes. The measurement and structural models can be estimated jointly using the so-called one-step approach or sequentially using stepwise methods, which present significant advantages for practitioners regarding the interpretability of the estimated latent classes. In addition to the one-step approach, StepMix implements the most important stepwise estim
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#36890;&#36807;PDSketch&#35821;&#35328;&#21644;&#21487;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#23454;&#29616;&#20102;&#27169;&#22411;&#30340;&#23398;&#20064;&#21644;&#22312;&#32447;&#35268;&#21010;&#65292;&#21152;&#36895;&#20102;&#26426;&#22120;&#20154;&#30340;&#28789;&#27963;&#24615;&#21644;&#36890;&#29992;&#24615;&#12290;</title><link>http://arxiv.org/abs/2303.05501</link><description>&lt;p&gt;
PDSketch: &#38598;&#25104;&#35268;&#21010;&#39046;&#22495;&#32534;&#31243;&#21644;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
PDSketch: Integrated Planning Domain Programming and Learning. (arXiv:2303.05501v2 [cs.AI] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.05501
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#36890;&#36807;PDSketch&#35821;&#35328;&#21644;&#21487;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#65292;&#23454;&#29616;&#20102;&#27169;&#22411;&#30340;&#23398;&#20064;&#21644;&#22312;&#32447;&#35268;&#21010;&#65292;&#21152;&#36895;&#20102;&#26426;&#22120;&#20154;&#30340;&#28789;&#27963;&#24615;&#21644;&#36890;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#27169;&#22411;&#23398;&#20064;&#21644;&#22312;&#32447;&#35268;&#21010;&#26041;&#27861;&#65292;&#20197;&#26500;&#24314;&#28789;&#27963;&#21644;&#36890;&#29992;&#30340;&#26426;&#22120;&#20154;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#22914;&#20309;&#21033;&#29992;&#24213;&#23618;&#29615;&#22659;&#36716;&#25442;&#27169;&#22411;&#20013;&#30340;&#23616;&#37096;&#24615;&#21644;&#31232;&#30095;&#32467;&#26500;&#65292;&#20197;&#25552;&#39640;&#27169;&#22411;&#27867;&#21270;&#33021;&#21147;&#12289;&#25968;&#25454;&#25928;&#29575;&#21644;&#36816;&#34892;&#25928;&#29575;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22495;&#23450;&#20041;&#35821;&#35328;&#65292;&#21517;&#20026;PDSketch&#12290;&#23427;&#20801;&#35768;&#29992;&#25143;&#28789;&#27963;&#22320;&#23450;&#20041;&#36716;&#25442;&#27169;&#22411;&#20013;&#30340;&#39640;&#32423;&#32467;&#26500;&#65292;&#20363;&#22914;&#23545;&#35937;&#21644;&#29305;&#24449;&#30340;&#20381;&#36182;&#20851;&#31995;&#65292;&#31867;&#20284;&#20110;&#31243;&#24207;&#21592;&#20351;&#29992;TensorFlow&#25110;PyTorch&#25351;&#23450;&#21367;&#31215;&#31070;&#32463;&#32593;&#32476;&#30340;&#26680;&#22823;&#23567;&#21644;&#38544;&#34255;&#32500;&#24230;&#30340;&#26041;&#24335;&#12290;&#36716;&#25442;&#27169;&#22411;&#30340;&#32454;&#33410;&#23558;&#30001;&#21487;&#35757;&#32451;&#30340;&#31070;&#32463;&#32593;&#32476;&#22635;&#20805;&#12290;&#22522;&#20110;&#23450;&#20041;&#30340;&#32467;&#26500;&#21644;&#23398;&#20064;&#21442;&#25968;&#65292;PDSketch&#33258;&#21160;&#29983;&#25104;&#19982;&#22495;&#26080;&#20851;&#30340;&#35268;&#21010;&#21551;&#21457;&#24335;&#31639;&#27861;&#65292;&#26080;&#38656;&#39069;&#22806;&#30340;&#35757;&#32451;&#12290;&#34893;&#29983;&#30340;&#21551;&#21457;&#24335;&#31639;&#27861;&#21152;&#36895;&#20102;&#23545;&#26032;&#30446;&#26631;&#30340;&#35268;&#21010;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies a model learning and online planning approach towards building flexible and general robots. Specifically, we investigate how to exploit the locality and sparsity structures in the underlying environmental transition model to improve model generalization, data-efficiency, and runtime-efficiency. We present a new domain definition language, named PDSketch. It allows users to flexibly define high-level structures in the transition models, such as object and feature dependencies, in a way similar to how programmers use TensorFlow or PyTorch to specify kernel sizes and hidden dimensions of a convolutional neural network. The details of the transition model will be filled in by trainable neural networks. Based on the defined structures and learned parameters, PDSketch automatically generates domain-independent planning heuristics without additional training. The derived heuristics accelerate the performance-time planning for novel goals.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#25193;&#25955;&#27169;&#22411;(DPDMs)&#65292;&#36890;&#36807;&#24046;&#20998;&#38544;&#31169;&#35757;&#32451;&#29983;&#25104;&#27169;&#22411;&#65292;&#23454;&#29616;&#23545;&#38544;&#31169;&#30340;&#20445;&#25252;&#65292;&#22312;&#22270;&#20687;&#29983;&#25104;&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20248;&#36234;&#65292;&#33021;&#22815;&#22312;&#26631;&#20934;&#27979;&#35797;&#20013;&#19982;&#29305;&#23450;&#20219;&#21153;&#30340;DP-SGD&#35757;&#32451;&#30340;&#20998;&#31867;&#22120;&#30456;&#23218;&#32654;&#12290;</title><link>http://arxiv.org/abs/2210.09929</link><description>&lt;p&gt;
&#24046;&#20998;&#38544;&#31169;&#25193;&#25955;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Differentially Private Diffusion Models. (arXiv:2210.09929v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2210.09929
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#31181;&#24046;&#20998;&#38544;&#31169;&#25193;&#25955;&#27169;&#22411;(DPDMs)&#65292;&#36890;&#36807;&#24046;&#20998;&#38544;&#31169;&#35757;&#32451;&#29983;&#25104;&#27169;&#22411;&#65292;&#23454;&#29616;&#23545;&#38544;&#31169;&#30340;&#20445;&#25252;&#65292;&#22312;&#22270;&#20687;&#29983;&#25104;&#22522;&#20934;&#27979;&#35797;&#20013;&#34920;&#29616;&#20248;&#36234;&#65292;&#33021;&#22815;&#22312;&#26631;&#20934;&#27979;&#35797;&#20013;&#19982;&#29305;&#23450;&#20219;&#21153;&#30340;DP-SGD&#35757;&#32451;&#30340;&#20998;&#31867;&#22120;&#30456;&#23218;&#32654;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29616;&#20195;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20381;&#36182;&#20110;&#36234;&#26469;&#36234;&#22823;&#30340;&#35757;&#32451;&#25968;&#25454;&#38598;&#65292;&#28982;&#32780;&#22312;&#28041;&#21450;&#38544;&#31169;&#30340;&#39046;&#22495;&#65292;&#25968;&#25454;&#36890;&#24120;&#26159;&#26377;&#38480;&#30340;&#12290;&#36890;&#36807;&#24046;&#20998;&#38544;&#31169;&#35757;&#32451;&#30340;&#29983;&#25104;&#27169;&#22411;&#21487;&#20197;&#32469;&#36807;&#36825;&#19968;&#25361;&#25112;&#65292;&#25552;&#20379;&#23545;&#21512;&#25104;&#25968;&#25454;&#30340;&#35775;&#38382;&#12290;&#26412;&#25991;&#22312;&#25193;&#25955;&#27169;&#22411;&#30340;&#26368;&#26032;&#25104;&#21151;&#22522;&#30784;&#19978;&#65292;&#24341;&#20837;&#20102;&#24046;&#20998;&#38544;&#31169;&#25193;&#25955;&#27169;&#22411;(DPDMs)&#65292;&#20351;&#29992;&#24046;&#20998;&#38544;&#31169;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;(DP-SGD)&#26469;&#23454;&#29616;&#38544;&#31169;&#20445;&#25252;&#12290;&#25105;&#20204;&#30740;&#31350;&#20102;DPDM&#20013;&#30340;&#21442;&#25968;&#21270;&#21644;&#37319;&#26679;&#31639;&#27861;&#65292;&#24182;&#25552;&#20986;&#20102;&#22122;&#22768;&#22810;&#26679;&#24615;&#65292;&#36825;&#26159;&#19968;&#20010;&#38024;&#23545;DM&#35757;&#32451;&#30340;&#24378;&#22823;&#25913;&#36827;&#12290;&#25105;&#20204;&#22312;&#22270;&#20687;&#29983;&#25104;&#22522;&#20934;&#27979;&#35797;&#20013;&#39564;&#35777;&#20102;&#25105;&#20204;&#30340;&#26032;&#39062;DPDMs&#65292;&#24182;&#22312;&#25152;&#26377;&#23454;&#39564;&#35777;&#26126;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;&#27492;&#22806;&#65292;&#22312;&#26631;&#20934;&#22522;&#20934;&#27979;&#35797;&#20013;&#65292;&#20351;&#29992;DPDM&#29983;&#25104;&#30340;&#21512;&#25104;&#25968;&#25454;&#35757;&#32451;&#30340;&#20998;&#31867;&#22120;&#34920;&#29616;&#19982;&#29305;&#23450;&#20219;&#21153;&#30340;DP-SGD&#35757;&#32451;&#30340;&#20998;&#31867;&#22120;&#30456;&#24403;&#65292;&#36825;&#22312;&#20197;&#24448;&#30340;&#30740;&#31350;&#20013;&#27809;&#26377;&#34987;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
While modern machine learning models rely on increasingly large training datasets, data is often limited in privacy-sensitive domains. Generative models trained with differential privacy (DP) on sensitive data can sidestep this challenge, providing access to synthetic data instead. We build on the recent success of diffusion models (DMs) and introduce Differentially Private Diffusion Models (DPDMs), which enforce privacy using differentially private stochastic gradient descent (DP-SGD). We investigate the DM parameterization and the sampling algorithm, which turn out to be crucial ingredients in DPDMs, and propose noise multiplicity, a powerful modification of DP-SGD tailored to the training of DMs. We validate our novel DPDMs on image generation benchmarks and achieve state-of-the-art performance in all experiments. Moreover, on standard benchmarks, classifiers trained on DPDM-generated synthetic data perform on par with task-specific DP-SGD-trained classifiers, which has not been dem
&lt;/p&gt;</description></item><item><title>&#20248;&#21270;&#38382;&#39064;&#20013;&#30340;&#23637;&#24320;&#27714;&#23548;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#65292;&#26412;&#25991;&#23545;&#20854;&#22312;&#26799;&#24230;&#19979;&#38477;&#21644; Chebyshev &#26041;&#27861;&#20013;&#30340;&#20108;&#27425;&#30446;&#26631;&#25552;&#20379;&#20102;&#38750;&#28176;&#36827;&#25910;&#25947;&#36895;&#29575;&#20998;&#26512;&#65292;&#21457;&#29616;&#25105;&#20204;&#35201;&#30830;&#20445;&#38597;&#21487;&#27604;&#30697;&#38453;&#30340;&#25910;&#25947;&#65292;&#23601;&#24517;&#39035;&#38754;&#20020;&#23637;&#24320;&#27714;&#23548;&#30340;&#35781;&#21650;&#65292;&#21363;&#35201;&#20040;&#36873;&#25321;&#22823;&#30340;&#23398;&#20064;&#29575;&#23548;&#33268;&#24555;&#36895;&#28176;&#36827;&#25910;&#25947;&#20294;&#31639;&#27861;&#26377;&#36739;&#38271;&#30340;&#21021;&#22987;&#38454;&#27573;&#65292;&#35201;&#20040;&#36873;&#25321;&#36739;&#23567;&#30340;&#23398;&#20064;&#29575;&#23548;&#33268;&#21363;&#26102;&#20294;&#36739;&#24930;&#30340;&#25910;&#25947;&#12290;</title><link>http://arxiv.org/abs/2209.13271</link><description>&lt;p&gt;
&#23637;&#24320;&#30340;&#35781;&#21650;&#65306;&#31995;&#32479;&#20248;&#21270;&#30340;&#19981;&#21516;&#21270;&#36895;&#29575;
&lt;/p&gt;
&lt;p&gt;
The Curse of Unrolling: Rate of Differentiating Through Optimization. (arXiv:2209.13271v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.13271
&lt;/p&gt;
&lt;p&gt;
&#20248;&#21270;&#38382;&#39064;&#20013;&#30340;&#23637;&#24320;&#27714;&#23548;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#37325;&#35201;&#38382;&#39064;&#65292;&#26412;&#25991;&#23545;&#20854;&#22312;&#26799;&#24230;&#19979;&#38477;&#21644; Chebyshev &#26041;&#27861;&#20013;&#30340;&#20108;&#27425;&#30446;&#26631;&#25552;&#20379;&#20102;&#38750;&#28176;&#36827;&#25910;&#25947;&#36895;&#29575;&#20998;&#26512;&#65292;&#21457;&#29616;&#25105;&#20204;&#35201;&#30830;&#20445;&#38597;&#21487;&#27604;&#30697;&#38453;&#30340;&#25910;&#25947;&#65292;&#23601;&#24517;&#39035;&#38754;&#20020;&#23637;&#24320;&#27714;&#23548;&#30340;&#35781;&#21650;&#65292;&#21363;&#35201;&#20040;&#36873;&#25321;&#22823;&#30340;&#23398;&#20064;&#29575;&#23548;&#33268;&#24555;&#36895;&#28176;&#36827;&#25910;&#25947;&#20294;&#31639;&#27861;&#26377;&#36739;&#38271;&#30340;&#21021;&#22987;&#38454;&#27573;&#65292;&#35201;&#20040;&#36873;&#25321;&#36739;&#23567;&#30340;&#23398;&#20064;&#29575;&#23548;&#33268;&#21363;&#26102;&#20294;&#36739;&#24930;&#30340;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35745;&#31639;&#20248;&#21270;&#38382;&#39064;&#35299;&#30340;&#38597;&#21487;&#27604;&#30697;&#38453;&#26159;&#26426;&#22120;&#23398;&#20064;&#20013;&#30340;&#19968;&#20010;&#20013;&#24515;&#38382;&#39064;&#65292;&#22312;&#36229;&#21442;&#25968;&#20248;&#21270;&#12289;&#20803;&#23398;&#20064;&#12289;&#20248;&#21270;&#20316;&#20026;&#19968;&#31181;&#23618;&#20197;&#21450;&#25968;&#25454;&#38598;&#33976;&#39311;&#31561;&#26041;&#38754;&#26377;&#30528;&#24191;&#27867;&#24212;&#29992;&#12290;&#23637;&#24320;&#27714;&#23548;&#26159;&#19968;&#31181;&#27969;&#34892;&#30340;&#21551;&#21457;&#24335;&#26041;&#27861;&#65292;&#23427;&#20351;&#29992;&#36845;&#20195;&#27714;&#35299;&#22120;&#36817;&#20284;&#27714;&#35299;&#35299;&#65292;&#24182;&#36890;&#36807;&#35745;&#31639;&#36335;&#24452;&#36827;&#34892;&#19981;&#21516;&#21270;&#12290;&#26412;&#25991;&#38024;&#23545;&#26799;&#24230;&#19979;&#38477;&#21644;Chebyshev&#26041;&#27861;&#20013;&#20108;&#27425;&#30446;&#26631;&#25552;&#20379;&#20102;&#35813;&#26041;&#27861;&#30340;&#38750;&#28176;&#36827;&#25910;&#25947;&#36895;&#29575;&#20998;&#26512;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#20026;&#20102;&#30830;&#20445;&#38597;&#21487;&#27604;&#30697;&#38453;&#30340;&#25910;&#25947;&#65292;&#25105;&#20204;&#21487;&#20197;&#36873;&#25321;1&#65289;&#36873;&#25321;&#22823;&#30340;&#23398;&#20064;&#29575;&#65292;&#23548;&#33268;&#24555;&#36895;&#30340;&#28176;&#36827;&#25910;&#25947;&#65292;&#20294;&#21487;&#33021;&#20250;&#25509;&#21463;&#31639;&#27861;&#20855;&#26377;&#20219;&#24847;&#38271;&#30340;&#21021;&#22987;&#38454;&#27573;&#65292;&#25110;&#32773;2&#65289;&#36873;&#25321;&#36739;&#23567;&#30340;&#23398;&#20064;&#29575;&#65292;&#23548;&#33268;&#21363;&#26102;&#20294;&#36739;&#24930;&#30340;&#25910;&#25947;&#12290;&#25105;&#20204;&#31216;&#20043;&#20026;&#23637;&#24320;&#30340;&#35781;&#21650;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#35752;&#35770;&#20102;&#19982;&#27492;&#26041;&#27861;&#30456;&#20851;&#30340;&#24320;&#25918;&#38382;&#39064;&#65292;&#20363;&#22914;&#23548;&#20986;&#23454;&#29992;&#30340;&#26356;&#26032;&#35268;&#21017;&#12290;
&lt;/p&gt;
&lt;p&gt;
Computing the Jacobian of the solution of an optimization problem is a central problem in machine learning, with applications in hyperparameter optimization, meta-learning, optimization as a layer, and dataset distillation, to name a few. Unrolled differentiation is a popular heuristic that approximates the solution using an iterative solver and differentiates it through the computational path. This work provides a non-asymptotic convergence-rate analysis of this approach on quadratic objectives for gradient descent and the Chebyshev method. We show that to ensure convergence of the Jacobian, we can either 1) choose a large learning rate leading to a fast asymptotic convergence but accept that the algorithm may have an arbitrarily long burn-in phase or 2) choose a smaller learning rate leading to an immediate but slower convergence. We refer to this phenomenon as the curse of unrolling. Finally, we discuss open problems relative to this approach, such as deriving a practical update rul
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#36807;&#31243;&#20013;&#30340;&#23616;&#37096;&#24377;&#24615;&#21160;&#21147;&#23398;&#12290;&#36890;&#36807;&#23545;&#29616;&#26377;$S_{\rm rel}$&#23450;&#20041;&#30340;&#20840;&#38754;&#30740;&#31350;&#24182;&#25552;&#20986;&#26032;&#30340;&#23450;&#20041;&#65292;&#25105;&#20204;&#21457;&#29616;&#26032;&#30340;&#23450;&#20041;&#33021;&#26356;&#25935;&#38160;&#22320;&#26816;&#27979;&#20986;&#26435;&#37325;&#26356;&#26032;&#26356;&#20559;&#21521;&#20110;&#22312;&#19982;&#26679;&#26412;&#25968;&#25454;&#21516;&#19968;&#31867;&#21035;&#20869;&#36827;&#34892;&#39044;&#27979;&#21464;&#21270;&#30340;&#29305;&#24615;&#12290;</title><link>http://arxiv.org/abs/2111.01166</link><description>&lt;p&gt;
&#35757;&#32451;&#31070;&#32463;&#32593;&#32476;&#26102;&#30340;&#23616;&#37096;&#24377;&#24615;&#21160;&#21147;&#23398;&#12290;
&lt;/p&gt;
&lt;p&gt;
Dynamics of Local Elasticity During Training of Neural Nets. (arXiv:2111.01166v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2111.01166
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#36807;&#31243;&#20013;&#30340;&#23616;&#37096;&#24377;&#24615;&#21160;&#21147;&#23398;&#12290;&#36890;&#36807;&#23545;&#29616;&#26377;$S_{\rm rel}$&#23450;&#20041;&#30340;&#20840;&#38754;&#30740;&#31350;&#24182;&#25552;&#20986;&#26032;&#30340;&#23450;&#20041;&#65292;&#25105;&#20204;&#21457;&#29616;&#26032;&#30340;&#23450;&#20041;&#33021;&#26356;&#25935;&#38160;&#22320;&#26816;&#27979;&#20986;&#26435;&#37325;&#26356;&#26032;&#26356;&#20559;&#21521;&#20110;&#22312;&#19982;&#26679;&#26412;&#25968;&#25454;&#21516;&#19968;&#31867;&#21035;&#20869;&#36827;&#34892;&#39044;&#27979;&#21464;&#21270;&#30340;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26368;&#36817;&#30340;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#21457;&#29616;&#20102;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#36712;&#36857;&#22312;&#26435;&#37325;&#31354;&#38388;&#20013;&#30340;&#19968;&#20010;&#23646;&#24615;&#65292;&#21363;&#8220;&#23616;&#37096;&#24377;&#24615;&#8221;&#65288;&#34920;&#31034;&#20026;$S_{\rm rel}$&#65289;&#12290;&#23616;&#37096;&#24377;&#24615;&#35797;&#22270;&#37327;&#21270;&#26679;&#26412;&#25968;&#25454;&#28857;&#23545;&#39044;&#27979;&#32467;&#26524;&#22312;&#20854;&#20182;&#25968;&#25454;&#28857;&#19978;&#30340;&#24433;&#21709;&#20256;&#25773;&#12290;&#22312;&#26412;&#30740;&#31350;&#20013;&#65292;&#25105;&#20204;&#23545;&#24050;&#26377;&#30340;$S_{\rm rel}$&#23450;&#20041;&#36827;&#34892;&#20102;&#20840;&#38754;&#30740;&#31350;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340;&#23450;&#20041;&#65292;&#35299;&#20915;&#20102;&#21407;&#22987;&#23450;&#20041;&#22312;&#20998;&#31867;&#35774;&#32622;&#20013;&#30340;&#23616;&#38480;&#24615;&#12290;&#36890;&#36807;&#22312;SVHN&#65292;CIFAR-10&#21644;CIFAR-100&#19978;&#36827;&#34892;&#21508;&#31181;&#26368;&#20808;&#36827;&#30340;&#31070;&#32463;&#32593;&#32476;&#35757;&#32451;&#23454;&#39564;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#26032;&#30340;$S_{\rm rel}$&#23450;&#20041;&#30456;&#27604;&#20110;&#21407;&#22987;&#23450;&#20041;&#26356;&#21152;&#25935;&#38160;&#22320;&#26816;&#27979;&#20986;&#26435;&#37325;&#26356;&#26032;&#26356;&#20559;&#21521;&#20110;&#22312;&#19982;&#26679;&#26412;&#25968;&#25454;&#21516;&#19968;&#31867;&#21035;&#20869;&#36827;&#34892;&#39044;&#27979;&#21464;&#21270;&#30340;&#29305;&#24615;&#12290;&#22312;&#31070;&#32463;&#22238;&#24402;&#23454;&#39564;&#20013;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#21407;&#22987;$S_{\rm rel}$&#26174;&#31034;&#20986;&#19968;&#20010;2&#38454;&#27573;&#34892;&#20026;--&#36890;&#36807;&#21021;&#22987;&#24377;&#24615;&#38454;&#27573;&#36827;&#34892;&#35757;&#32451;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the recent past, a property of neural training trajectories in weight-space had been isolated, that of "local elasticity" (denoted as $S_{\rm rel}$). Local elasticity attempts to quantify the propagation of the influence of a sampled data point on the prediction at another data. In this work, we embark on a comprehensive study of the existing notion of $S_{\rm rel}$ and also propose a new definition that addresses the limitations that we point out for the original definition in the classification setting. On various state-of-the-art neural network training on SVHN, CIFAR-10 and CIFAR-100 we demonstrate how our new proposal of $S_{\rm rel}$, as opposed to the original definition, much more sharply detects the property of the weight updates preferring to make prediction changes within the same class as the sampled data.  In neural regression experiments we demonstrate that the original $S_{\rm rel}$ reveals a $2-$phase behavior -- that the training proceeds via an initial elastic phas
&lt;/p&gt;</description></item><item><title>&#36825;&#20010;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#38750;&#20984;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#30340;&#22359;&#20027;&#23548;&#26497;&#23567;&#21270;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#20351;&#29992;&#24378;&#20984;&#26367;&#20195;&#20989;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#35813;&#31639;&#27861;&#21487;&#20197;&#22312;&#19968;&#23450;&#36845;&#20195;&#27425;&#25968;&#20869;&#25910;&#25947;&#21040;&#19968;&#20010;&#31283;&#23450;&#28857;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#20449;&#20219;&#22495;&#21464;&#20307;&#65292;&#21487;&#20197;&#22788;&#29702;&#21482;&#20855;&#22791;&#20984;&#24615;&#30340;&#26367;&#20195;&#20989;&#25968;&#12290;</title><link>http://arxiv.org/abs/2012.03503</link><description>&lt;p&gt;
&#24102;&#26377;&#36882;&#20943;&#21322;&#24452;&#30340;&#22359;&#20027;&#23548;&#26497;&#23567;&#21270;&#26041;&#27861;&#29992;&#20110;&#32422;&#26463;&#38750;&#20984;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Block majorization-minimization with diminishing radius for constrained nonconvex optimization. (arXiv:2012.03503v4 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2012.03503
&lt;/p&gt;
&lt;p&gt;
&#36825;&#20010;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#29992;&#20110;&#38750;&#20984;&#32422;&#26463;&#20248;&#21270;&#38382;&#39064;&#30340;&#22359;&#20027;&#23548;&#26497;&#23567;&#21270;&#31639;&#27861;&#65292;&#24182;&#35777;&#26126;&#20102;&#22312;&#20351;&#29992;&#24378;&#20984;&#26367;&#20195;&#20989;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#35813;&#31639;&#27861;&#21487;&#20197;&#22312;&#19968;&#23450;&#36845;&#20195;&#27425;&#25968;&#20869;&#25910;&#25947;&#21040;&#19968;&#20010;&#31283;&#23450;&#28857;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#20449;&#20219;&#22495;&#21464;&#20307;&#65292;&#21487;&#20197;&#22788;&#29702;&#21482;&#20855;&#22791;&#20984;&#24615;&#30340;&#26367;&#20195;&#20989;&#25968;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22359;&#20027;&#23548;&#26497;&#23567;&#21270;&#65288;BMM&#65289;&#26159;&#19968;&#31181;&#31616;&#21333;&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#29992;&#20110;&#38750;&#20984;&#32422;&#26463;&#20248;&#21270;&#65292;&#22312;&#27599;&#20010;&#22359;&#22352;&#26631;&#19978;&#39034;&#24207;&#26368;&#23567;&#21270;&#30446;&#26631;&#20989;&#25968;&#30340;&#20027;&#23548;&#26367;&#20195;&#20989;&#25968;&#65292;&#32780;&#20854;&#20182;&#22352;&#26631;&#20445;&#25345;&#22266;&#23450;&#12290;BMM&#21253;&#25324;&#19968;&#22823;&#31867;&#20248;&#21270;&#31639;&#27861;&#65292;&#22914;&#22359;&#22352;&#26631;&#19979;&#38477;&#21450;&#20854;&#36817;&#31471;&#28857;&#21464;&#20307;&#65292;&#26399;&#26395;&#26368;&#22823;&#21270;&#21644;&#22359;&#25237;&#24433;&#26799;&#24230;&#19979;&#38477;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#23545;&#20110;&#19968;&#33324;&#32422;&#26463;&#38750;&#20984;&#20248;&#21270;&#65292;&#20351;&#29992;&#24378;&#20984;&#26367;&#20195;&#20989;&#25968;&#30340;BMM&#21487;&#20197;&#22312;$O(\epsilon^{-2}(\log \epsilon^{-1})^{2})$&#27425;&#36845;&#20195;&#20013;&#20135;&#29983;&#19968;&#20010;$\epsilon$-&#31283;&#23450;&#28857;&#65292;&#24182;&#28176;&#36817;&#25910;&#25947;&#20110;&#31283;&#23450;&#28857;&#38598;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#20449;&#20219;&#22495;&#21464;&#20307;&#30340;BMM&#65292;&#21487;&#20197;&#22788;&#29702;&#21482;&#20855;&#22791;&#20984;&#24615;&#30340;&#26367;&#20195;&#20989;&#25968;&#65292;&#24182;&#20173;&#28982;&#33719;&#24471;&#30456;&#21516;&#30340;&#36845;&#20195;&#22797;&#26434;&#24230;&#21644;&#28176;&#36817;&#31283;&#23450;&#24615;&#12290;&#36825;&#20123;&#32467;&#26524;&#20855;&#26377;&#40065;&#26834;&#24615;&#65292;&#21363;&#20351;&#20984;&#23376;&#38382;&#39064;&#30340;&#27714;&#35299;&#26159;&#38750;&#31934;&#30830;&#30340;&#65292;&#21482;&#35201;&#26368;&#20248;&#38388;&#38553;&#28385;&#36275;&#35201;&#27714;&#12290;
&lt;/p&gt;
&lt;p&gt;
Block majorization-minimization (BMM) is a simple iterative algorithm for nonconvex constrained optimization that sequentially minimizes majorizing surrogates of the objective function in each block coordinate while the other coordinates are held fixed. BMM entails a large class of optimization algorithms such as block coordinate descent and its proximal-point variant, expectation-minimization, and block projected gradient descent. We establish that for general constrained nonconvex optimization, BMM with strongly convex surrogates can produce an $\epsilon$-stationary point within $O(\epsilon^{-2}(\log \epsilon^{-1})^{2})$ iterations and asymptotically converges to the set of stationary points. Furthermore, we propose a trust-region variant of BMM that can handle surrogates that are only convex and still obtain the same iteration complexity and asymptotic stationarity. These results hold robustly even when the convex sub-problems are inexactly solved as long as the optimality gaps are 
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#22312;&#39640;&#32500;&#24230;&#30340;&#35823;&#24046;&#21464;&#37327;&#22266;&#23450;&#35774;&#35745;&#29615;&#22659;&#20013;&#20998;&#26512;&#20102;&#20027;&#25104;&#20998;&#22238;&#24402;&#27169;&#22411;&#35782;&#21035;&#21644;&#26679;&#26412;&#22806;&#39044;&#27979;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20248;&#20110;&#24050;&#30693;&#26368;&#20339;&#36895;&#29575;&#30340;&#38750;&#28176;&#36827;&#39044;&#27979;&#20445;&#35777;&#12290;&#22312;&#20998;&#26512;&#36807;&#31243;&#20013;&#65292;&#24341;&#20837;&#20102;&#19968;&#31181;&#33258;&#28982;&#30340;&#32447;&#24615;&#20195;&#25968;&#26465;&#20214;&#26469;&#36991;&#20813;&#26679;&#26412;&#22806;&#39044;&#27979;&#30340;&#20998;&#24067;&#20551;&#35774;&#65292;&#24182;&#26500;&#24314;&#20102;&#19968;&#20010;&#20551;&#35774;&#26816;&#39564;&#26469;&#26816;&#26597;&#35813;&#26465;&#20214;&#22312;&#23454;&#36341;&#20013;&#30340;&#21487;&#34892;&#24615;&#12290;&#21516;&#26102;&#65292;&#35813;&#35770;&#25991;&#30340;&#32467;&#26524;&#20063;&#23545;&#21512;&#25104;&#23545;&#29031;&#30740;&#31350;&#25552;&#20379;&#20102;&#26032;&#30340;&#21457;&#29616;&#12290;</title><link>http://arxiv.org/abs/2010.14449</link><description>&lt;p&gt;
&#20851;&#20110;&#20027;&#25104;&#20998;&#22238;&#24402;&#27169;&#22411;&#35782;&#21035;&#21644;&#26679;&#26412;&#22806;&#39044;&#27979;&#30340;&#30740;&#31350;: &#24212;&#29992;&#20110;&#21512;&#25104;&#23545;&#29031;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On Model Identification and Out-of-Sample Prediction of Principal Component Regression: Applications to Synthetic Controls. (arXiv:2010.14449v5 [math.ST] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2010.14449
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#22312;&#39640;&#32500;&#24230;&#30340;&#35823;&#24046;&#21464;&#37327;&#22266;&#23450;&#35774;&#35745;&#29615;&#22659;&#20013;&#20998;&#26512;&#20102;&#20027;&#25104;&#20998;&#22238;&#24402;&#27169;&#22411;&#35782;&#21035;&#21644;&#26679;&#26412;&#22806;&#39044;&#27979;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#20248;&#20110;&#24050;&#30693;&#26368;&#20339;&#36895;&#29575;&#30340;&#38750;&#28176;&#36827;&#39044;&#27979;&#20445;&#35777;&#12290;&#22312;&#20998;&#26512;&#36807;&#31243;&#20013;&#65292;&#24341;&#20837;&#20102;&#19968;&#31181;&#33258;&#28982;&#30340;&#32447;&#24615;&#20195;&#25968;&#26465;&#20214;&#26469;&#36991;&#20813;&#26679;&#26412;&#22806;&#39044;&#27979;&#30340;&#20998;&#24067;&#20551;&#35774;&#65292;&#24182;&#26500;&#24314;&#20102;&#19968;&#20010;&#20551;&#35774;&#26816;&#39564;&#26469;&#26816;&#26597;&#35813;&#26465;&#20214;&#22312;&#23454;&#36341;&#20013;&#30340;&#21487;&#34892;&#24615;&#12290;&#21516;&#26102;&#65292;&#35813;&#35770;&#25991;&#30340;&#32467;&#26524;&#20063;&#23545;&#21512;&#25104;&#23545;&#29031;&#30740;&#31350;&#25552;&#20379;&#20102;&#26032;&#30340;&#21457;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#22312;&#39640;&#32500;&#24230;&#30340;&#35823;&#24046;&#21464;&#37327;&#22266;&#23450;&#35774;&#35745;&#29615;&#22659;&#20013;&#20998;&#26512;&#20102;&#20027;&#25104;&#20998;&#22238;&#24402;(PCR)&#12290;&#22312;&#36866;&#24403;&#30340;&#26465;&#20214;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;PCR&#33021;&#22815;&#19968;&#33268;&#22320;&#35782;&#21035;&#20986;&#20855;&#26377;&#26368;&#23567;L2&#33539;&#25968;&#30340;&#21807;&#19968;&#27169;&#22411;&#12290;&#36825;&#20123;&#32467;&#26524;&#20351;&#25105;&#20204;&#33021;&#22815;&#24314;&#31435;&#36215;&#20248;&#20110;&#24050;&#30693;&#26368;&#20339;&#36895;&#29575;&#30340;&#38750;&#28176;&#36827;&#30340;&#26679;&#26412;&#22806;&#39044;&#27979;&#20445;&#35777;&#12290;&#22312;&#25105;&#20204;&#30340;&#20998;&#26512;&#36807;&#31243;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#33258;&#28982;&#30340;&#32447;&#24615;&#20195;&#25968;&#26465;&#20214;&#65292;&#32852;&#31995;&#20102;&#26679;&#26412;&#20869;&#21644;&#26679;&#26412;&#22806;&#30340;&#21327;&#21464;&#37327;&#65292;&#20174;&#32780;&#36991;&#20813;&#20102;&#23545;&#26679;&#26412;&#22806;&#39044;&#27979;&#30340;&#20998;&#24067;&#20551;&#35774;&#12290;&#25105;&#20204;&#30340;&#27169;&#25311;&#23454;&#39564;&#35777;&#26126;&#20102;&#27492;&#26465;&#20214;&#22312;&#27867;&#21270;&#26041;&#38754;&#30340;&#37325;&#35201;&#24615;&#65292;&#21363;&#20351;&#22312;&#21327;&#21464;&#37327;&#28418;&#31227;&#30340;&#24773;&#20917;&#19979;&#20063;&#26159;&#22914;&#27492;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#26500;&#24314;&#20102;&#19968;&#20010;&#20551;&#35774;&#26816;&#39564;&#26469;&#26816;&#26597;&#36825;&#20010;&#26465;&#20214;&#22312;&#23454;&#36341;&#20013;&#26159;&#21542;&#25104;&#31435;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#36824;&#20026;&#21512;&#25104;&#23545;&#29031;&#25991;&#29486;&#25552;&#20379;&#20102;&#26032;&#30340;&#21457;&#29616;&#65292;&#21512;&#25104;&#23545;&#29031;&#26159;&#19968;&#31181;&#20027;&#35201;&#30340;&#25919;&#31574;&#35780;&#20272;&#26041;&#27861;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#25105;&#20204;&#22312;&#22266;&#23450;&#35774;&#35745;&#29615;&#22659;&#20013;&#30340;&#39044;&#27979;&#20445;&#35777;&#23578;&#26410;&#34987;&#30740;&#31350;&#36807;&#12290;
&lt;/p&gt;
&lt;p&gt;
We analyze principal component regression (PCR) in a high-dimensional error-in-variables setting with fixed design. Under suitable conditions, we show that PCR consistently identifies the unique model with minimum $\ell_2$-norm. These results enable us to establish non-asymptotic out-of-sample prediction guarantees that improve upon the best known rates. In the course of our analysis, we introduce a natural linear algebraic condition between the in- and out-of-sample covariates, which allows us to avoid distributional assumptions for out-of-sample predictions. Our simulations illustrate the importance of this condition for generalization, even under covariate shifts. Accordingly, we construct a hypothesis test to check when this conditions holds in practice. As a byproduct, our results also lead to novel results for the synthetic controls literature, a leading approach for policy evaluation. To the best of our knowledge, our prediction guarantees for the fixed design setting have been 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#25913;&#36827;&#29256;&#26412;&#30340;&#38543;&#26426;&#26368;&#23567;&#20108;&#20056;&#20540;&#36845;&#20195;&#65288;RLSVI&#65289;&#31639;&#27861;&#65292;&#36890;&#36807;&#23545;&#34892;&#21160;&#20540;&#20989;&#25968;&#30340;&#26368;&#23567;&#20108;&#20056;&#36924;&#36817;&#36827;&#34892;&#25200;&#21160;&#65292;&#35825;&#23548;&#20986;&#20102;&#25506;&#32034;&#36807;&#31243;&#12290;&#22312;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20855;&#26377;&#20302;&#31209;&#36716;&#31227;&#21160;&#24577;&#30340;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;RLSVI&#30340;&#39057;&#29575;&#21518;&#24724;&#19978;&#30028;&#20026;$\widetilde O(d^2 H^2 \sqrt{T})$&#12290;&#36825;&#26159;&#23545;&#20110;&#24102;&#26377;&#20989;&#25968;&#36924;&#36817;&#30340;&#38543;&#26426;&#25506;&#32034;&#30340;&#39318;&#20010;&#39057;&#29575;&#21518;&#24724;&#20998;&#26512;&#12290;</title><link>http://arxiv.org/abs/1911.00567</link><description>&lt;p&gt;
&#38543;&#26426;&#26368;&#23567;&#20108;&#20056;&#20540;&#36845;&#20195;&#30340;&#39057;&#29575;&#21518;&#24724;&#30028;&#38480;
&lt;/p&gt;
&lt;p&gt;
Frequentist Regret Bounds for Randomized Least-Squares Value Iteration. (arXiv:1911.00567v6 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/1911.00567
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#31181;&#25913;&#36827;&#29256;&#26412;&#30340;&#38543;&#26426;&#26368;&#23567;&#20108;&#20056;&#20540;&#36845;&#20195;&#65288;RLSVI&#65289;&#31639;&#27861;&#65292;&#36890;&#36807;&#23545;&#34892;&#21160;&#20540;&#20989;&#25968;&#30340;&#26368;&#23567;&#20108;&#20056;&#36924;&#36817;&#36827;&#34892;&#25200;&#21160;&#65292;&#35825;&#23548;&#20986;&#20102;&#25506;&#32034;&#36807;&#31243;&#12290;&#22312;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20855;&#26377;&#20302;&#31209;&#36716;&#31227;&#21160;&#24577;&#30340;&#20551;&#35774;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;RLSVI&#30340;&#39057;&#29575;&#21518;&#24724;&#19978;&#30028;&#20026;$\widetilde O(d^2 H^2 \sqrt{T})$&#12290;&#36825;&#26159;&#23545;&#20110;&#24102;&#26377;&#20989;&#25968;&#36924;&#36817;&#30340;&#38543;&#26426;&#25506;&#32034;&#30340;&#39318;&#20010;&#39057;&#29575;&#21518;&#24724;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#26377;&#38480;&#26102;&#38388;&#22495;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#25506;&#32034;-&#21033;&#29992;&#22256;&#22659;&#12290;&#24403;&#29366;&#24577;&#31354;&#38388;&#24456;&#22823;&#25110;&#36830;&#32493;&#26102;&#65292;&#20256;&#32479;&#30340;&#34920;&#26684;&#26041;&#27861;&#19981;&#21487;&#34892;&#65292;&#24517;&#39035;&#37319;&#29992;&#20989;&#25968;&#36924;&#36817;&#30340;&#24418;&#24335;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#20048;&#35266;&#21021;&#22987;&#21270;&#30340;&#25913;&#36827;&#29256;&#26412;&#30340;&#38543;&#26426;&#26368;&#23567;&#20108;&#20056;&#20540;&#36845;&#20195;&#65288;RLSVI&#65289;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#26159;&#19968;&#31181;&#26080;&#27169;&#22411;&#31639;&#27861;&#65292;&#20854;&#20013;&#25506;&#32034;&#26159;&#36890;&#36807;&#25200;&#21160;&#34892;&#21160;&#20540;&#20989;&#25968;&#30340;&#26368;&#23567;&#20108;&#20056;&#36924;&#36817;&#26469;&#35825;&#23548;&#30340;&#12290;&#22312;&#20551;&#35774;&#39532;&#23572;&#21487;&#22827;&#20915;&#31574;&#36807;&#31243;&#20855;&#26377;&#20302;&#31209;&#36716;&#31227;&#21160;&#24577;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;RLSVI&#30340;&#39057;&#29575;&#21518;&#24724;&#23558;&#19978;&#30028;&#20026;$\widetilde O(d^2 H^2 \sqrt{T})$&#65292;&#20854;&#20013;$ d $&#26159;&#29305;&#24449;&#32500;&#24230;&#65292;$ H $&#26159;&#26102;&#38388;&#38480;&#21046;&#65292;$ T $&#26159;&#24635;&#27493;&#25968;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#26159;&#23545;&#20110;&#24102;&#26377;&#20989;&#25968;&#36924;&#36817;&#30340;&#38543;&#26426;&#25506;&#32034;&#30340;&#31532;&#19968;&#20010;&#39057;&#29575;&#21518;&#24724;&#20998;&#26512;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the exploration-exploitation dilemma in finite-horizon reinforcement learning (RL). When the state space is large or continuous, traditional tabular approaches are unfeasible and some form of function approximation is mandatory. In this paper, we introduce an optimistically-initialized variant of the popular randomized least-squares value iteration (RLSVI), a model-free algorithm where exploration is induced by perturbing the least-squares approximation of the action-value function. Under the assumption that the Markov decision process has low-rank transition dynamics, we prove that the frequentist regret of RLSVI is upper-bounded by $\widetilde O(d^2 H^2 \sqrt{T})$ where $ d $ are the feature dimension, $ H $ is the horizon, and $ T $ is the total number of steps. To the best of our knowledge, this is the first frequentist regret analysis for randomized exploration with function approximation.
&lt;/p&gt;</description></item></channel></rss>