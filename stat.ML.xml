<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#25104;&#21151;&#30340;&#23398;&#20064;Narrow One-Hidden-Layer ReLU&#32593;&#32476;&#30340;&#31639;&#27861;&#65292;&#32780;&#19981;&#38656;&#35201;&#39069;&#22806;&#30340;&#20551;&#35774;&#65292;&#24182;&#20351;&#29992;&#20102;&#20998;&#26512;&#39640;&#38454;&#30697;&#24352;&#37327;&#30340;&#38543;&#26426;&#25910;&#32553;&#30340;&#26041;&#27861;&#65292;&#20351;&#24471;&#21487;&#20197;&#21457;&#29616;&#21333;&#20010;&#31070;&#32463;&#20803;&#12290;</title><link>http://arxiv.org/abs/2304.10524</link><description>&lt;p&gt;
&#23398;&#20064;&#31364;&#30340;&#21333;&#38544;&#34255;&#23618;ReLU&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Learning Narrow One-Hidden-Layer ReLU Networks. (arXiv:2304.10524v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10524
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22312;&#22810;&#39033;&#24335;&#26102;&#38388;&#20869;&#25104;&#21151;&#30340;&#23398;&#20064;Narrow One-Hidden-Layer ReLU&#32593;&#32476;&#30340;&#31639;&#27861;&#65292;&#32780;&#19981;&#38656;&#35201;&#39069;&#22806;&#30340;&#20551;&#35774;&#65292;&#24182;&#20351;&#29992;&#20102;&#20998;&#26512;&#39640;&#38454;&#30697;&#24352;&#37327;&#30340;&#38543;&#26426;&#25910;&#32553;&#30340;&#26041;&#27861;&#65292;&#20351;&#24471;&#21487;&#20197;&#21457;&#29616;&#21333;&#20010;&#31070;&#32463;&#20803;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#20102;&#19968;&#20010;&#32463;&#36807;&#20805;&#20998;&#30740;&#31350;&#30340;&#38382;&#39064;&#8212;&#8212;&#20851;&#20110;&#22312;$d$&#32500;&#36755;&#20837;&#19978;&#30340;&#39640;&#26031;&#20998;&#24067;&#20013;&#65292;&#23398;&#20064;$k$&#20010;ReLU&#28608;&#27963;&#30340;&#32447;&#24615;&#32452;&#21512;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#22312;$k$&#20026;&#24120;&#25968;&#26102;&#25104;&#21151;&#30340;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#12290;&#25152;&#26377;&#20043;&#21069;&#22810;&#39033;&#24335;&#26102;&#38388;&#30340;&#23398;&#20064;&#22120;&#37117;&#38656;&#35201;&#23545;&#32593;&#32476;&#36827;&#34892;&#39069;&#22806;&#30340;&#20551;&#35774;&#65292;&#27604;&#22914;&#27491;&#31995;&#25968;&#31995;&#21512;&#25110;&#38544;&#34255;&#26435;&#37325;&#21521;&#37327;&#30340;&#30697;&#38453;&#33391;&#22909;&#23450;&#20041;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22522;&#20110;&#20998;&#26512;&#39640;&#38454;&#30697;&#24352;&#37327;&#30340;&#38543;&#26426;&#25910;&#32553;&#12290;&#25105;&#20204;&#37319;&#29992;&#22810;&#23610;&#24230;&#20998;&#26512;&#26469;&#35777;&#26126;&#36275;&#22815;&#25509;&#36817;&#30340;&#31070;&#32463;&#20803;&#21487;&#20197;&#34987;&#21512;&#24182;&#22312;&#19968;&#36215;&#65292;&#20174;&#32780;&#35268;&#36991;&#20102;&#20197;&#21069;&#24037;&#20316;&#20013;&#23384;&#22312;&#30340;&#23450;&#24615;&#38382;&#39064;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#35774;&#35745;&#19968;&#20010;&#36845;&#20195;&#36807;&#31243;&#26469;&#21457;&#29616;&#21333;&#20010;&#31070;&#32463;&#20803;&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the well-studied problem of learning a linear combination of $k$ ReLU activations with respect to a Gaussian distribution on inputs in $d$ dimensions. We give the first polynomial-time algorithm that succeeds whenever $k$ is a constant. All prior polynomial-time learners require additional assumptions on the network, such as positive combining coefficients or the matrix of hidden weight vectors being well-conditioned.  Our approach is based on analyzing random contractions of higher-order moment tensors. We use a multi-scale analysis to argue that sufficiently close neurons can be collapsed together, sidestepping the conditioning issues present in prior work. This allows us to design an iterative procedure to discover individual neurons.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25237;&#24433;&#36817;&#31471;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;(PPGD)&#65292;&#25104;&#21151;&#22320;&#35299;&#20915;&#20102;&#19968;&#31867;&#38750;&#20984;&#38750;&#20809;&#28369;&#20248;&#21270;&#38382;&#39064;&#12290;&#35813;&#31639;&#27861;&#21487;&#20197;&#23454;&#29616;&#23616;&#37096;&#24555;&#36895;&#25910;&#25947;&#65292;&#24403;&#36845;&#20195;&#27425;&#25968; $k \geq k_0$ &#26102;&#65292;PPGD &#21487;&#20197;&#20197; $\cO(1/k^2)$ &#30340;&#24555;&#36895;&#25910;&#25947;&#29575;&#25910;&#25947;&#12290;</title><link>http://arxiv.org/abs/2304.10499</link><description>&lt;p&gt;
&#19968;&#31867;&#38750;&#20984;&#38750;&#20809;&#28369;&#20248;&#21270;&#38382;&#39064;&#30340;&#25237;&#24433;&#36817;&#31471;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;&#65306;&#19981;&#38656;&#35201; Kurdyka-Lojasiewicz&#65288;KL&#65289;&#24615;&#36136;&#20063;&#33021;&#23454;&#29616;&#24555;&#36895;&#25910;&#25947;
&lt;/p&gt;
&lt;p&gt;
Projective Proximal Gradient Descent for A Class of Nonconvex Nonsmooth Optimization Problems: Fast Convergence Without Kurdyka-Lojasiewicz (KL) Property. (arXiv:2304.10499v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10499
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25237;&#24433;&#36817;&#31471;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;(PPGD)&#65292;&#25104;&#21151;&#22320;&#35299;&#20915;&#20102;&#19968;&#31867;&#38750;&#20984;&#38750;&#20809;&#28369;&#20248;&#21270;&#38382;&#39064;&#12290;&#35813;&#31639;&#27861;&#21487;&#20197;&#23454;&#29616;&#23616;&#37096;&#24555;&#36895;&#25910;&#25947;&#65292;&#24403;&#36845;&#20195;&#27425;&#25968; $k \geq k_0$ &#26102;&#65292;PPGD &#21487;&#20197;&#20197; $\cO(1/k^2)$ &#30340;&#24555;&#36895;&#25910;&#25947;&#29575;&#25910;&#25947;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38750;&#20984;&#38750;&#20809;&#28369;&#20248;&#21270;&#38382;&#39064;&#22312;&#32479;&#35745;&#23398;&#21644;&#26426;&#22120;&#23398;&#20064;&#20013;&#20855;&#26377;&#37325;&#35201;&#24847;&#20041;&#19988;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#35299;&#20915;&#19968;&#31867;&#38750;&#20984;&#38750;&#20809;&#28369;&#20248;&#21270;&#38382;&#39064;&#30340;&#25237;&#24433;&#36817;&#31471;&#26799;&#24230;&#19979;&#38477;&#31639;&#27861;(PPGD)&#65292;&#20854;&#20013;&#38750;&#20984;&#24615;&#21644;&#38750;&#20809;&#28369;&#24615;&#28304;&#33258;&#19968;&#20010;&#38750;&#20984;&#20294;&#20998;&#27573;&#20984;&#30340;&#38750;&#20809;&#28369;&#27491;&#21017;&#21270;&#39033;&#12290;&#19982;&#29616;&#26377;&#22522;&#20110; Kurdyka-\L{}ojasiewicz (K\L{}) &#24615;&#36136;&#23545;&#38750;&#20984;&#38750;&#20809;&#28369;&#38382;&#39064;&#36827;&#34892;&#21152;&#36895; PGD &#26041;&#27861;&#30340;&#25910;&#25947;&#20998;&#26512;&#19981;&#21516;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#29702;&#35770;&#20998;&#26512;&#65292;&#35777;&#26126;&#20102; PPGD &#22312;&#28201;&#21644;&#20551;&#35774;&#19979;&#22312;&#19968;&#31867;&#38750;&#20984;&#38750;&#20809;&#28369;&#38382;&#39064;&#20013;&#23454;&#29616;&#20102;&#24555;&#36895;&#23616;&#37096;&#25910;&#25947;&#12290;&#35777;&#26126;&#20102;&#24403;&#36845;&#20195;&#27425;&#25968; $k \geq k_0$ &#26102;&#65292;PPGD &#21487;&#20197;&#20197; $\cO(1/k^2)$ &#30340;&#24555;&#36895;&#25910;&#25947;&#29575;&#25910;&#25947;&#65292;&#20854;&#20013; $k_0$ &#26159;&#19968;&#20010;&#26377;&#38480;&#30340;&#24120;&#25968;&#12290;&#35813;&#31639;&#27861;&#22312;&#20809;&#28369;&#19988;&#20984;&#30446;&#26631;&#20989;&#25968;&#30340;&#19968;&#38454;&#26041;&#27861;&#20855;&#26377;&#21033;&#26222;&#24076;&#33576;&#36830;&#32493;&#26799;&#24230;&#30340;&#24773;&#20917;&#19979;&#23454;&#29616;&#20102;&#23616;&#37096; Nesterov &#30340;&#26368;&#20248;&#25910;&#25947;&#36895;&#24230;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;......&#65288;&#27492;&#22788;&#30465;&#30053;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Nonconvex and nonsmooth optimization problems are important and challenging for statistics and machine learning. In this paper, we propose Projected Proximal Gradient Descent (PPGD) which solves a class of nonconvex and nonsmooth optimization problems, where the nonconvexity and nonsmoothness come from a nonsmooth regularization term which is nonconvex but piecewise convex. In contrast with existing convergence analysis of accelerated PGD methods for nonconvex and nonsmooth problems based on the Kurdyka-\L{}ojasiewicz (K\L{}) property, we provide a new theoretical analysis showing local fast convergence of PPGD. It is proved that PPGD achieves a fast convergence rate of $\cO(1/k^2)$ when the iteration number $k \ge k_0$ for a finite $k_0$ on a class of nonconvex and nonsmooth problems under mild assumptions, which is locally Nesterov's optimal convergence rate of first-order methods on smooth and convex objective function with Lipschitz continuous gradient. Experimental results demonst
&lt;/p&gt;</description></item><item><title>&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30340;&#20027;&#35201;&#29942;&#39048;&#22312;&#20110;&#39640;&#26102;&#38388;&#24046;&#35823;&#24046;&#30340;&#39564;&#35777;&#38598;&#19978;&#20986;&#29616;&#20102;&#20005;&#37325;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2304.10466</link><description>&lt;p&gt;
&#39640;&#25928;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#38656;&#35201;&#25233;&#21046;&#36807;&#25311;&#21512;
&lt;/p&gt;
&lt;p&gt;
Efficient Deep Reinforcement Learning Requires Regulating Overfitting. (arXiv:2304.10466v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10466
&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#30340;&#20027;&#35201;&#29942;&#39048;&#22312;&#20110;&#39640;&#26102;&#38388;&#24046;&#35823;&#24046;&#30340;&#39564;&#35777;&#38598;&#19978;&#20986;&#29616;&#20102;&#20005;&#37325;&#36807;&#25311;&#21512;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#19982;&#29615;&#22659;&#30340;&#20132;&#20114;&#25910;&#38598;&#26377;&#38480;&#30340;&#25968;&#25454;&#36827;&#34892;&#31574;&#30053;&#23398;&#20064;&#30340;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#65292;&#38656;&#35201;&#27491;&#30830;&#30340;&#27491;&#21017;&#21270;&#25216;&#24039;&#25165;&#33021;&#23454;&#29616;&#25968;&#25454;&#39640;&#25928;&#21033;&#29992;&#12290;&#26412;&#25991;&#36890;&#36807;&#26816;&#39564;&#20960;&#31181;&#20551;&#35774;&#65292;&#22914;&#38750;&#31283;&#24577;&#24615;&#12289;&#36807;&#24230;&#21160;&#20316;&#20998;&#24067;&#20559;&#31227;&#21644;&#36807;&#25311;&#21512;&#31561;&#65292;&#35797;&#22270;&#29702;&#35299;&#22312;&#26679;&#26412;&#39640;&#25928;&#30340;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#20013;&#20027;&#35201;&#30340;&#29942;&#39048;&#12290;&#25105;&#20204;&#23545;DeepMind&#25511;&#21046;&#22871;&#20214;&#65288;DMC&#65289;&#20219;&#21153;&#36827;&#34892;&#20102;&#24443;&#24213;&#30340;&#23454;&#35777;&#20998;&#26512;&#65292;&#20197;&#19968;&#31181;&#26377;&#25511;&#21046;&#12289;&#31995;&#32479;&#30340;&#26041;&#24335;&#23637;&#31034;&#20102;&#23545;&#36716;&#25442;&#30340;&#39564;&#35777;&#38598;&#30340;&#39640;&#26102;&#38388;&#24046;&#65288;TD&#65289;&#35823;&#24046;&#26159;&#20005;&#37325;&#24433;&#21709;&#28145;&#24230;&#24378;&#21270;&#23398;&#20064;&#31639;&#27861;&#24615;&#33021;&#30340;&#20027;&#35201;&#32618;&#39745;&#31096;&#39318;&#65292;&#32780;&#20808;&#21069;&#30340;&#26041;&#27861;......(&#26410;&#23436;&#25972;&#32763;&#35793;)
&lt;/p&gt;
&lt;p&gt;
Deep reinforcement learning algorithms that learn policies by trial-and-error must learn from limited amounts of data collected by actively interacting with the environment. While many prior works have shown that proper regularization techniques are crucial for enabling data-efficient RL, a general understanding of the bottlenecks in data-efficient RL has remained unclear. Consequently, it has been difficult to devise a universal technique that works well across all domains. In this paper, we attempt to understand the primary bottleneck in sample-efficient deep RL by examining several potential hypotheses such as non-stationarity, excessive action distribution shift, and overfitting. We perform thorough empirical analysis on state-based DeepMind control suite (DMC) tasks in a controlled and systematic way to show that high temporal-difference (TD) error on the validation set of transitions is the main culprit that severely affects the performance of deep RL algorithms, and prior method
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#26032;&#22411;&#30340;&#21160;&#24577;&#20998;&#37197;&#38382;&#39064;&#8212;&#8212;&#20572;&#27490;&#36172;&#21338;&#26426;&#27169;&#22411;&#65292;&#25552;&#20986;&#20102;&#23545;&#20110;&#32463;&#20856;&#30340;Gittins&#25351;&#25968;&#20998;&#35299;&#32467;&#26524;&#21644;&#26368;&#26032;&#32467;&#26524;&#30340;&#26032;&#35777;&#26126;&#12290;</title><link>http://arxiv.org/abs/2304.10302</link><description>&lt;p&gt;
&#20572;&#27490;&#22810;&#33218;&#36172;&#21338;&#26426;&#27169;&#22411;&#30340;&#26368;&#20248;&#28608;&#27963;&#12290;
&lt;/p&gt;
&lt;p&gt;
Optimal Activation of Halting Multi-Armed Bandit Models. (arXiv:2304.10302v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10302
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#26032;&#22411;&#30340;&#21160;&#24577;&#20998;&#37197;&#38382;&#39064;&#8212;&#8212;&#20572;&#27490;&#36172;&#21338;&#26426;&#27169;&#22411;&#65292;&#25552;&#20986;&#20102;&#23545;&#20110;&#32463;&#20856;&#30340;Gittins&#25351;&#25968;&#20998;&#35299;&#32467;&#26524;&#21644;&#26368;&#26032;&#32467;&#26524;&#30340;&#26032;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#21160;&#24577;&#20998;&#37197;&#38382;&#39064;&#8212;&#8212;&#20572;&#27490;&#36172;&#21338;&#26426;&#27169;&#22411;&#12290;&#20316;&#20026;&#24212;&#29992;&#65292;&#25105;&#20204;&#33719;&#24471;&#20102;&#23545;&#20110;&#32463;&#20856;&#30340;Gittins&#25351;&#25968;&#20998;&#35299;&#32467;&#26524;&#21644;&#20316;&#32773;&#22312;&#8220;&#26222;&#36941;&#25240;&#26087;&#21644;&#25215;&#35834;&#19979;&#30340;&#22810;&#33218;&#36172;&#21338;&#26426;&#8221;&#30340;&#26368;&#26032;&#32467;&#26524;&#30340;&#26032;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
We study new types of dynamic allocation problems the {\sl Halting Bandit} models. As an application, we obtain new proofs for the classic Gittins index decomposition result and recent results of the authors in `Multi-armed bandits under general depreciation and commitment.'
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#21457;&#29616;&#65292;&#36890;&#36807;&#35843;&#25972;&#20998;&#31867;&#22120;&#25130;&#26029;&#28857;&#32780;&#19981;&#36827;&#34892;&#25968;&#25454;&#22686;&#24378;&#21487;&#20197;&#22312;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#31867;&#20284;&#20110;&#36807;&#37319;&#26679;&#25216;&#26415;&#30340;&#32467;&#26524;&#65292;&#20026;&#22788;&#29702;&#19981;&#24179;&#34913;&#25968;&#25454;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#24605;&#36335;&#12290;</title><link>http://arxiv.org/abs/2304.10283</link><description>&lt;p&gt;
&#25968;&#25454;&#22686;&#24378;&#23545;&#19981;&#24179;&#34913;&#25991;&#26412;&#25968;&#25454;&#38598;&#39044;&#27979;&#30340;&#26377;&#25928;&#24615;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Is augmentation effective to improve prediction in imbalanced text datasets?. (arXiv:2304.10283v1 [cs.CL])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10283
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#21457;&#29616;&#65292;&#36890;&#36807;&#35843;&#25972;&#20998;&#31867;&#22120;&#25130;&#26029;&#28857;&#32780;&#19981;&#36827;&#34892;&#25968;&#25454;&#22686;&#24378;&#21487;&#20197;&#22312;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#31867;&#20284;&#20110;&#36807;&#37319;&#26679;&#25216;&#26415;&#30340;&#32467;&#26524;&#65292;&#20026;&#22788;&#29702;&#19981;&#24179;&#34913;&#25968;&#25454;&#25552;&#20379;&#20102;&#19968;&#31181;&#26032;&#30340;&#24605;&#36335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#23545;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26500;&#25104;&#20102;&#37325;&#22823;&#25361;&#25112;&#65292;&#24448;&#24448;&#23548;&#33268;&#39044;&#27979;&#26377;&#20559;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#65288;NLP&#65289;&#20013;&#24191;&#27867;&#20351;&#29992;&#25968;&#25454;&#22686;&#24378;&#25216;&#26415;&#20026;&#23569;&#25968;&#31867;&#29983;&#25104;&#26032;&#26679;&#26412;&#12290;&#28982;&#32780;&#65292;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36136;&#30097;&#20102;&#25968;&#25454;&#22686;&#24378;&#24635;&#26159;&#24517;&#35201;&#26469;&#25552;&#39640;&#19981;&#24179;&#34913;&#25968;&#25454;&#38598;&#39044;&#27979;&#30340;&#24120;&#35265;&#20551;&#35774;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#35748;&#20026;&#36890;&#36807;&#35843;&#25972;&#20998;&#31867;&#22120;&#25130;&#26029;&#28857;&#32780;&#19981;&#36827;&#34892;&#25968;&#25454;&#22686;&#24378;&#21487;&#20197;&#20135;&#29983;&#19982;&#36807;&#37319;&#26679;&#25216;&#26415;&#31867;&#20284;&#30340;&#32467;&#26524;&#12290;&#25105;&#20204;&#30340;&#30740;&#31350;&#25552;&#20379;&#20102;&#29702;&#35770;&#21644;&#23454;&#35777;&#35777;&#25454;&#25903;&#25345;&#36825;&#19968;&#20027;&#24352;&#12290;&#25105;&#20204;&#30340;&#21457;&#29616;&#26377;&#21161;&#20110;&#26356;&#22909;&#22320;&#20102;&#35299;&#22788;&#29702;&#19981;&#24179;&#34913;&#25968;&#25454;&#30340;&#19981;&#21516;&#26041;&#27861;&#30340;&#20248;&#21183;&#21644;&#23616;&#38480;&#24615;&#65292;&#24182;&#24110;&#21161;&#30740;&#31350;&#20154;&#21592;&#21644;&#23454;&#36341;&#32773;&#20026;&#32473;&#23450;&#20219;&#21153;&#20570;&#20986;&#26126;&#26234;&#30340;&#20915;&#31574;&#12290;
&lt;/p&gt;
&lt;p&gt;
Imbalanced datasets present a significant challenge for machine learning models, often leading to biased predictions. To address this issue, data augmentation techniques are widely used in natural language processing (NLP) to generate new samples for the minority class. However, in this paper, we challenge the common assumption that data augmentation is always necessary to improve predictions on imbalanced datasets. Instead, we argue that adjusting the classifier cutoffs without data augmentation can produce similar results to oversampling techniques. Our study provides theoretical and empirical evidence to support this claim. Our findings contribute to a better understanding of the strengths and limitations of different approaches to dealing with imbalanced data, and help researchers and practitioners make informed decisions about which methods to use for a given task.
&lt;/p&gt;</description></item><item><title>PED-ANOVA &#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340; f-ANOVA &#20844;&#24335;&#65292;&#33021;&#22815;&#22312;&#20219;&#24847;&#23376;&#31354;&#38388;&#20013;&#39640;&#25928;&#22320;&#35745;&#31639;&#36229;&#21442;&#25968;&#30340;&#37325;&#35201;&#24615;&#65292;&#26377;&#21161;&#20110;&#28145;&#24230;&#23398;&#20064;&#20013;&#22909;&#30340;&#36229;&#21442;&#25968;&#31354;&#38388;&#35774;&#35745;&#12290;</title><link>http://arxiv.org/abs/2304.10255</link><description>&lt;p&gt;
PED-ANOVA: &#22312;&#20219;&#24847;&#23376;&#31354;&#38388;&#20013;&#39640;&#25928;&#37327;&#21270;&#36229;&#21442;&#25968;&#37325;&#35201;&#24615;
&lt;/p&gt;
&lt;p&gt;
PED-ANOVA: Efficiently Quantifying Hyperparameter Importance in Arbitrary Subspaces. (arXiv:2304.10255v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10255
&lt;/p&gt;
&lt;p&gt;
PED-ANOVA &#25552;&#20986;&#20102;&#19968;&#20010;&#26032;&#30340; f-ANOVA &#20844;&#24335;&#65292;&#33021;&#22815;&#22312;&#20219;&#24847;&#23376;&#31354;&#38388;&#20013;&#39640;&#25928;&#22320;&#35745;&#31639;&#36229;&#21442;&#25968;&#30340;&#37325;&#35201;&#24615;&#65292;&#26377;&#21161;&#20110;&#28145;&#24230;&#23398;&#20064;&#20013;&#22909;&#30340;&#36229;&#21442;&#25968;&#31354;&#38388;&#35774;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#20013;&#36229;&#21442;&#25968;&#20248;&#21270;&#30340;&#27969;&#34892;&#20351;&#24471;&#22909;&#30340;&#36229;&#21442;&#25968;&#31354;&#38388;&#35774;&#35745;&#23545;&#20110;&#35757;&#32451;&#24378;&#27169;&#22411;&#33267;&#20851;&#37325;&#35201;&#65292;&#32780;&#22909;&#30340;&#36229;&#21442;&#25968;&#31354;&#38388;&#35774;&#35745;&#21448;&#20005;&#37325;&#20381;&#36182;&#20110;&#20102;&#35299;&#19981;&#21516;&#36229;&#21442;&#25968;&#30340;&#20316;&#29992;&#12290;&#36825;&#28608;&#21457;&#20102;&#20851;&#20110;&#36229;&#21442;&#25968;&#37325;&#35201;&#24615;&#30340;&#30740;&#31350;&#65292;&#20363;&#22914;&#20351;&#29992;&#21151;&#33021;&#26041;&#24046;&#20998;&#26512; (f-ANOVA) &#30340;&#27969;&#34892;&#26041;&#27861;&#12290;&#28982;&#32780;&#65292;&#21407;&#22987;&#30340; f-ANOVA &#20844;&#24335;&#19981;&#36866;&#29992;&#20110;&#31639;&#27861;&#35774;&#35745;&#24072;&#26368;&#30456;&#20851;&#30340;&#23376;&#31354;&#38388;&#65292;&#20363;&#22914;&#30001;&#26368;&#20339;&#24615;&#33021;&#23450;&#20041;&#30340;&#23376;&#31354;&#38388;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102;&#19968;&#20010;&#26032;&#30340;&#38024;&#23545;&#20219;&#24847;&#23376;&#31354;&#38388;&#30340; f-ANOVA &#20844;&#24335;&#65292;&#24182;&#25552;&#20986;&#20102;&#19968;&#20010;&#31639;&#27861;&#65292;&#20351;&#29992; Pearson &#25955;&#24230; (PED) &#23454;&#29616;&#36229;&#21442;&#25968;&#37325;&#35201;&#24615;&#30340;&#38381;&#24335;&#35745;&#31639;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#36825;&#20010;&#26032;&#31639;&#27861;&#65292;&#31216;&#20026; PED-ANOVA&#65292;&#33021;&#22815;&#25104;&#21151;&#22320;&#35782;&#21035;&#19981;&#21516;&#23376;&#31354;&#38388;&#20013;&#37325;&#35201;&#30340;&#36229;&#21442;&#25968;&#65292;&#21516;&#26102;&#35745;&#31639;&#25928;&#29575;&#26497;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
The recent rise in popularity of Hyperparameter Optimization (HPO) for deep learning has highlighted the role that good hyperparameter (HP) space design can play in training strong models. In turn, designing a good HP space is critically dependent on understanding the role of different HPs. This motivates research on HP Importance (HPI), e.g., with the popular method of functional ANOVA (f-ANOVA). However, the original f-ANOVA formulation is inapplicable to the subspaces most relevant to algorithm designers, such as those defined by top performance. To overcome this problem, we derive a novel formulation of f-ANOVA for arbitrary subspaces and propose an algorithm that uses Pearson divergence (PED) to enable a closed-form computation of HPI. We demonstrate that this new algorithm, dubbed PED-ANOVA, is able to successfully identify important HPs in different subspaces while also being extremely computationally efficient.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#32553;&#20943;&#31639;&#27861;&#22312;&#22823;&#35268;&#27169;&#23545;&#31216;&#23574;&#23792;&#24352;&#37327;&#19978;&#30340;&#24212;&#29992;&#65292;&#25552;&#20379;&#20102;&#22312;&#23384;&#22312;&#38750;&#24179;&#20961;&#30456;&#20851;&#24615;&#24773;&#20917;&#19979;&#30340;&#31934;&#30830;&#34920;&#29616;&#65292;&#21487;&#29992;&#20110;&#35774;&#35745;&#26356;&#26377;&#25928;&#30340;&#20449;&#21495;&#20272;&#35745;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2304.10248</link><description>&lt;p&gt;
&#22823;&#35268;&#27169;&#23545;&#31216;&#23574;&#23792;&#24352;&#37327;&#19978;&#30340;Hotelling&#32553;&#20943;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Hotelling Deflation on Large Symmetric Spiked Tensors. (arXiv:2304.10248v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10248
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#32553;&#20943;&#31639;&#27861;&#22312;&#22823;&#35268;&#27169;&#23545;&#31216;&#23574;&#23792;&#24352;&#37327;&#19978;&#30340;&#24212;&#29992;&#65292;&#25552;&#20379;&#20102;&#22312;&#23384;&#22312;&#38750;&#24179;&#20961;&#30456;&#20851;&#24615;&#24773;&#20917;&#19979;&#30340;&#31934;&#30830;&#34920;&#29616;&#65292;&#21487;&#29992;&#20110;&#35774;&#35745;&#26356;&#26377;&#25928;&#30340;&#20449;&#21495;&#20272;&#35745;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24403;&#24212;&#29992;&#20110;&#20272;&#35745;&#21463;&#21152;&#24615;&#39640;&#26031;&#22122;&#22768;&#27745;&#26579;&#30340;&#22823;&#24352;&#37327;&#20013;&#21253;&#21547;&#30340;&#20302;&#31209;&#23545;&#31216;&#23574;&#23792;&#26102;&#30340;&#32553;&#20943;&#31639;&#27861;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#22312;&#20551;&#23450;&#23574;&#23792;&#20998;&#37327;&#23384;&#22312;&#38750;&#24179;&#20961;&#65288;&#22266;&#23450;&#65289;&#30456;&#20851;&#24615;&#30340;&#24773;&#20917;&#19979;&#65292;&#25552;&#20379;&#20102;&#23545;&#32553;&#20943;&#31639;&#27861;&#22312;&#22823;&#32500;&#24773;&#20917;&#19979;&#34920;&#29616;&#30340;&#31934;&#30830;&#21051;&#30011;&#65292;&#20854;&#20013;&#21253;&#25324;&#36890;&#36807;&#36830;&#32493;&#30340;&#31209;-1&#36924;&#36817;&#33719;&#24471;&#30340;&#21521;&#37327;&#30340;&#23545;&#40784;&#24773;&#20917;&#21450;&#20854;&#20272;&#35745;&#30340;&#26435;&#37325;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#21487;&#35753;&#20154;&#20204;&#29702;&#35299;&#22122;&#22768;&#24178;&#25200;&#19979;&#30340;&#32553;&#20943;&#26426;&#21046;&#65292;&#24182;&#21487;&#29992;&#20110;&#35774;&#35745;&#26356;&#26377;&#25928;&#30340;&#20449;&#21495;&#20272;&#35745;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the deflation algorithm when applied to estimate a low-rank symmetric spike contained in a large tensor corrupted by additive Gaussian noise. Specifically, we provide a precise characterization of the large-dimensional performance of deflation in terms of the alignments of the vectors obtained by successive rank-1 approximation and of their estimated weights, assuming non-trivial (fixed) correlations among spike components. Our analysis allows an understanding of the deflation mechanism in the presence of noise and can be exploited for designing more efficient signal estimation methods.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Kaczmarz&#30340;IHT&#65288;KZIHT&#65289;&#30340;&#28151;&#21512;&#26041;&#27861;&#65292;&#24182;&#22312;&#20351;&#29992;&#37325;&#27927;&#25968;&#25454;&#37319;&#26679;&#26041;&#26696;&#26102;&#35777;&#26126;&#20854;&#32447;&#24615;&#25910;&#25947;&#24615;&#65292;&#20855;&#26377;&#31232;&#30095;&#32422;&#26463;&#30340;&#31995;&#32479;&#30340;&#35299;&#12290;&#21516;&#26102;&#65292;&#36824;&#25552;&#20986;&#20102;Kaczmarz&#21608;&#26399;&#38408;&#20540;&#65288;KZPT&#65289;&#26041;&#27861;&#25512;&#24191;&#20102;KZIHT&#30340;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2304.10123</link><description>&lt;p&gt;
&#31232;&#30095;&#32422;&#26463;&#19979;&#37325;&#27927;Kaczmarz&#26041;&#27861;&#30340;&#32447;&#24615;&#25910;&#25947;
&lt;/p&gt;
&lt;p&gt;
Linear Convergence of Reshuffling Kaczmarz Methods With Sparse Constraints. (arXiv:2304.10123v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10123
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Kaczmarz&#30340;IHT&#65288;KZIHT&#65289;&#30340;&#28151;&#21512;&#26041;&#27861;&#65292;&#24182;&#22312;&#20351;&#29992;&#37325;&#27927;&#25968;&#25454;&#37319;&#26679;&#26041;&#26696;&#26102;&#35777;&#26126;&#20854;&#32447;&#24615;&#25910;&#25947;&#24615;&#65292;&#20855;&#26377;&#31232;&#30095;&#32422;&#26463;&#30340;&#31995;&#32479;&#30340;&#35299;&#12290;&#21516;&#26102;&#65292;&#36824;&#25552;&#20986;&#20102;Kaczmarz&#21608;&#26399;&#38408;&#20540;&#65288;KZPT&#65289;&#26041;&#27861;&#25512;&#24191;&#20102;KZIHT&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
Kaczmarz&#26041;&#27861;&#65288;KZ&#65289;&#21450;&#20854;&#21464;&#20307;&#26159;&#19968;&#31867;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#26041;&#27861;&#65292;&#30001;&#20110;&#20854;&#31616;&#21333;&#39640;&#25928;&#22320;&#35299;&#20915;&#32447;&#24615;&#26041;&#31243;&#32452;&#32780;&#34987;&#24191;&#27867;&#30740;&#31350;&#12290;&#36845;&#20195;&#38408;&#20540;&#65288;IHT&#65289;&#26041;&#27861;&#22312;&#22810;&#20010;&#30740;&#31350;&#39046;&#22495;&#20013;&#24191;&#21463;&#27426;&#36814;&#65292;&#21253;&#25324;&#21387;&#32553;&#24863;&#30693;&#25110;&#31232;&#30095;&#32447;&#24615;&#22238;&#24402;&#65292;&#24102;&#26377;&#39069;&#22806;&#32467;&#26500;&#30340;&#26426;&#22120;&#23398;&#20064;&#20197;&#21450;&#24102;&#26377;&#38750;&#20984;&#32422;&#26463;&#30340;&#20248;&#21270;&#12290;&#26368;&#36817;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21517;&#20026;&#22522;&#20110;Kaczmarz&#30340;IHT&#65288;KZIHT&#65289;&#30340;&#28151;&#21512;&#26041;&#27861;&#65292;&#32467;&#21512;&#20102;&#20004;&#31181;&#26041;&#27861;&#30340;&#20248;&#28857;&#65292;&#20294;&#23427;&#30340;&#29702;&#35770;&#20445;&#35777;&#32570;&#22833;&#12290;&#26412;&#25991;&#36890;&#36807;&#23637;&#31034;&#24403;&#20351;&#29992;&#37325;&#27927;&#25968;&#25454;&#37319;&#26679;&#26041;&#26696;&#26102;&#65292;KZIHT&#32447;&#24615;&#22320;&#25910;&#25947;&#21040;&#20855;&#26377;&#31232;&#30095;&#32422;&#26463;&#30340;&#31995;&#32479;&#30340;&#35299;&#65292;&#24182;&#25552;&#20379;&#20102;KZIHT&#30340;&#31532;&#19968;&#20010;&#29702;&#35770;&#25910;&#25947;&#20445;&#35777;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#20102;Kaczmarz&#21608;&#26399;&#38408;&#20540;&#65288;KZPT&#65289;&#26041;&#27861;&#65292;&#23427;&#36890;&#36807;&#24212;&#29992;&#38408;&#20540;&#25805;&#20316;&#26469;&#25512;&#24191;KZIHT&#12290;
&lt;/p&gt;
&lt;p&gt;
The Kaczmarz method (KZ) and its variants, which are types of stochastic gradient descent (SGD) methods, have been extensively studied due to their simplicity and efficiency in solving linear equation systems. The iterative thresholding (IHT) method has gained popularity in various research fields, including compressed sensing or sparse linear regression, machine learning with additional structure, and optimization with nonconvex constraints. Recently, a hybrid method called Kaczmarz-based IHT (KZIHT) has been proposed, combining the benefits of both approaches, but its theoretical guarantees are missing. In this paper, we provide the first theoretical convergence guarantees for KZIHT by showing that it converges linearly to the solution of a system with sparsity constraints up to optimal statistical bias when the reshuffling data sampling scheme is used. We also propose the Kaczmarz with periodic thresholding (KZPT) method, which generalizes KZIHT by applying the thresholding operatio
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31867;&#26356;&#24191;&#27867;&#30340;&#19968;&#38454;&#31639;&#27861;&#65292;&#36890;&#36807;&#26032;&#30340;&#31163;&#25955;&#26446;&#20122;&#26222;&#35834;&#22827;&#20998;&#26512;&#24314;&#31435;&#36275;&#22815;&#26465;&#20214;&#65292;&#23454;&#29616;&#20102;&#19982;Nesterov&#26041;&#27861;&#31867;&#20284;&#30340;&#21152;&#36895;&#25910;&#25947;&#36895;&#24230;&#12290;&#27492;&#22806;&#65292;&#36824;&#25552;&#20986;&#20102;&#21704;&#23494;&#39039;&#21161;&#29702;&#26799;&#24230;&#26041;&#27861;&#26469;&#35299;&#37322;&#21152;&#36895;&#26465;&#20214;&#30340;&#24847;&#20041;&#12290;</title><link>http://arxiv.org/abs/2304.10063</link><description>&lt;p&gt;
&#29702;&#35299;&#21152;&#36895;&#26799;&#24230;&#26041;&#27861;&#65306;&#26446;&#20122;&#26222;&#35834;&#22827;&#20998;&#26512;&#21644;&#21704;&#23494;&#39039;&#21161;&#29702;&#35299;&#37322;
&lt;/p&gt;
&lt;p&gt;
Understanding Accelerated Gradient Methods: Lyapunov Analyses and Hamiltonian Assisted Interpretations. (arXiv:2304.10063v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10063
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31867;&#26356;&#24191;&#27867;&#30340;&#19968;&#38454;&#31639;&#27861;&#65292;&#36890;&#36807;&#26032;&#30340;&#31163;&#25955;&#26446;&#20122;&#26222;&#35834;&#22827;&#20998;&#26512;&#24314;&#31435;&#36275;&#22815;&#26465;&#20214;&#65292;&#23454;&#29616;&#20102;&#19982;Nesterov&#26041;&#27861;&#31867;&#20284;&#30340;&#21152;&#36895;&#25910;&#25947;&#36895;&#24230;&#12290;&#27492;&#22806;&#65292;&#36824;&#25552;&#20986;&#20102;&#21704;&#23494;&#39039;&#21161;&#29702;&#26799;&#24230;&#26041;&#27861;&#26469;&#35299;&#37322;&#21152;&#36895;&#26465;&#20214;&#30340;&#24847;&#20041;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#31867;&#27604;&#20043;&#21069;&#30740;&#31350;&#30340;&#26356;&#21152;&#24191;&#27867;&#30340;&#19968;&#38454;&#31639;&#27861;&#65292;&#29992;&#20110;&#26368;&#23567;&#21270;&#24179;&#28369;&#19988;&#24378;&#20984;&#25110;&#24179;&#28369;&#20984;&#20989;&#25968;&#12290;&#25105;&#20204;&#36890;&#36807;&#26032;&#30340;&#31163;&#25955;&#26446;&#20122;&#26222;&#35834;&#22827;&#20998;&#26512;&#24314;&#31435;&#36275;&#22815;&#26465;&#20214;&#65292;&#20351;&#20854;&#36798;&#21040;&#21152;&#36895;&#25910;&#25947;&#36895;&#24230;&#65292;&#36825;&#19982;&#22312;&#24378;&#21644;&#19968;&#33324;&#30340;&#20984;&#35774;&#32622;&#20013;&#19982;Nesterov&#30340;&#26041;&#27861;&#30456;&#21305;&#37197;&#12290;&#25509;&#19979;&#26469;&#65292;&#25105;&#20204;&#30740;&#31350;&#20102;&#26497;&#38480;&#26222;&#36890;&#24494;&#20998;&#26041;&#31243;&#30340;&#25910;&#25947;&#24615;&#65292;&#24182;&#25351;&#20986;&#20102;&#30456;&#24212;&#31639;&#27861;&#21644;&#24494;&#20998;&#26041;&#31243;&#30340;&#25910;&#25947;&#24615;&#36136;&#20043;&#38388;&#30446;&#21069;&#26126;&#26174;&#30340;&#24046;&#36317;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#30340;&#31163;&#25955;&#31639;&#27861;&#8212;&#8212;&#21704;&#23494;&#39039;&#21161;&#29702;&#26799;&#24230;&#26041;&#27861;&#8212;&#8212;&#35813;&#26041;&#27861;&#30452;&#25509;&#22522;&#20110;&#19968;&#20010;&#21704;&#23494;&#39039;&#20989;&#25968;&#21644;&#22810;&#20010;&#21487;&#35299;&#37322;&#30340;&#25805;&#20316;&#65292;&#28982;&#21518;&#28436;&#31034;&#20102;&#25105;&#20204;&#21152;&#36895;&#26465;&#20214;&#30340;&#26377;&#24847;&#20041;&#21644;&#32479;&#19968;&#30340;&#35299;&#37322;&#12290;
&lt;/p&gt;
&lt;p&gt;
We formulate two classes of first-order algorithms more general than previously studied for minimizing smooth and strongly convex or, respectively, smooth and convex functions. We establish sufficient conditions, via new discrete Lyapunov analyses, for achieving accelerated convergence rates which match Nesterov's methods in the strongly and general convex settings. Next, we study the convergence of limiting ordinary differential equations (ODEs) and point out currently notable gaps between the convergence properties of the corresponding algorithms and ODEs. Finally, we propose a novel class of discrete algorithms, called the Hamiltonian assisted gradient method, directly based on a Hamiltonian function and several interpretable operations, and then demonstrate meaningful and unified interpretations of our acceleration conditions.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#40065;&#26834;&#25439;&#22833;&#20989;&#25968; $\mathcal{L}_{\sigma}$ &#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#21487;&#29992;&#20316;&#22312;&#32447;&#26368;&#23567;&#20108;&#20056;&#22238;&#24402;&#30340;&#40065;&#26834;&#26367;&#20195;&#26041;&#26696;&#12290;&#24182;&#35777;&#26126;&#20102;&#22312;&#36866;&#24403;&#36873;&#25321;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#35813;&#31639;&#27861;&#20855;&#26377;&#26080;&#23481;&#37327;&#20381;&#36182;&#30340;&#26368;&#20248;&#24615;&#25910;&#25947;&#24615;&#20197;&#21450;&#24378;&#25910;&#25947;&#30340;&#26368;&#20248;&#23481;&#37327;&#20381;&#36182;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2304.10060</link><description>&lt;p&gt;
&#40065;&#26834;&#24615;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#30340;&#26368;&#20248;&#24615;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Optimality of Robust Online Learning. (arXiv:2304.10060v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10060
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#40065;&#26834;&#25439;&#22833;&#20989;&#25968; $\mathcal{L}_{\sigma}$ &#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#65292;&#21487;&#29992;&#20316;&#22312;&#32447;&#26368;&#23567;&#20108;&#20056;&#22238;&#24402;&#30340;&#40065;&#26834;&#26367;&#20195;&#26041;&#26696;&#12290;&#24182;&#35777;&#26126;&#20102;&#22312;&#36866;&#24403;&#36873;&#25321;&#21442;&#25968;&#30340;&#24773;&#20917;&#19979;&#65292;&#35813;&#31639;&#27861;&#20855;&#26377;&#26080;&#23481;&#37327;&#20381;&#36182;&#30340;&#26368;&#20248;&#24615;&#25910;&#25947;&#24615;&#20197;&#21450;&#24378;&#25910;&#25947;&#30340;&#26368;&#20248;&#23481;&#37327;&#20381;&#36182;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22312;&#20877;&#29983;&#26680;&#24076;&#23572;&#20271;&#29305;&#31354;&#38388;&#19978;&#20351;&#29992;&#40065;&#26834;&#25439;&#22833;&#20989;&#25968; $\mathcal{L}_{\sigma}$ &#36827;&#34892;&#22238;&#24402;&#30340;&#22312;&#32447;&#23398;&#20064;&#31639;&#27861;&#12290;&#36825;&#20010;&#28041;&#21450;&#21040;&#32553;&#25918;&#21442;&#25968; $\sigma&gt;0$ &#30340;&#25439;&#22833;&#20989;&#25968;&#21487;&#20197;&#35206;&#30422;&#19968;&#31995;&#21015;&#24120;&#29992;&#30340;&#40065;&#26834;&#25439;&#22833;&#20989;&#25968;&#12290;&#25552;&#20986;&#30340;&#31639;&#27861;&#26159;&#38024;&#23545;&#22312;&#32447;&#26368;&#23567;&#20108;&#20056;&#22238;&#24402;&#30340;&#40065;&#26834;&#26367;&#20195;&#26041;&#26696;&#65292;&#26088;&#22312;&#20272;&#35745;&#26465;&#20214;&#22343;&#20540;&#20989;&#25968;&#12290;&#22312;&#36873;&#25321;&#36866;&#24403;&#30340; $\sigma$ &#21644;&#27493;&#38271;&#30340;&#24773;&#20917;&#19979;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#35813;&#22312;&#32447;&#31639;&#27861;&#30340;&#26368;&#32456;&#36845;&#20195;&#21487;&#20197;&#22312;&#22343;&#26041;&#36317;&#31163;&#19978;&#23454;&#29616;&#26080;&#23481;&#37327;&#20381;&#36182;&#30340;&#25910;&#25947;&#26368;&#20248;&#24615;&#12290;&#27492;&#22806;&#65292;&#22914;&#26524;&#24050;&#30693;&#24213;&#23618;&#20989;&#25968;&#31354;&#38388;&#30340;&#20854;&#20182;&#20449;&#24687;&#65292;&#21017;&#25105;&#20204;&#36824;&#24314;&#31435;&#20102;&#24378;&#25910;&#25947;&#30340;&#26368;&#20248;&#23481;&#37327;&#20381;&#36182;&#36895;&#29575;&#12290;&#25454;&#25105;&#20204;&#25152;&#30693;&#65292;&#36825;&#20004;&#20010;&#32467;&#26524;&#37117;&#26159;&#22312;&#32447;&#23398;&#20064;&#29616;&#26377;&#25991;&#29486;&#20013;&#30340;&#26032;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study an online learning algorithm with a robust loss function $\mathcal{L}_{\sigma}$ for regression over a reproducing kernel Hilbert space (RKHS). The loss function $\mathcal{L}_{\sigma}$ involving a scaling parameter $\sigma&gt;0$ can cover a wide range of commonly used robust losses. The proposed algorithm is then a robust alternative for online least squares regression aiming to estimate the conditional mean function. For properly chosen $\sigma$ and step size, we show that the last iterate of this online algorithm can achieve optimal capacity independent convergence in the mean square distance. Moreover, if additional information on the underlying function space is known, we also establish optimal capacity dependent rates for strong convergence in RKHS. To the best of our knowledge, both of the two results are new to the existing literature of online learning.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#22522;&#20110;&#26680;&#20989;&#25968;&#30340;&#27169;&#24577;&#32479;&#35745;&#26041;&#27861;&#30340;&#26368;&#20248;&#26680;&#20989;&#25968;&#30340;&#36873;&#25321;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#65288;&#22810;&#20803;&#65289;&#26368;&#20248;&#26680;&#20989;&#25968;&#65292;&#22312;&#26576;&#20010;&#26680;&#20989;&#25968;&#31867;&#21035;&#20013;&#20351;&#24471;&#20854;&#35299;&#26512;&#24471;&#21040;&#30340;&#28176;&#36817;&#35823;&#24046;&#20934;&#21017;&#26368;&#23567;&#21270;&#12290;</title><link>http://arxiv.org/abs/2304.10046</link><description>&lt;p&gt;
&#22522;&#20110;&#26680;&#30340;&#27169;&#24577;&#32479;&#35745;&#26041;&#27861;&#30340;&#26368;&#20248;&#26680;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
Optimal Kernel for Kernel-Based Modal Statistical Methods. (arXiv:2304.10046v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10046
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#22522;&#20110;&#26680;&#20989;&#25968;&#30340;&#27169;&#24577;&#32479;&#35745;&#26041;&#27861;&#30340;&#26368;&#20248;&#26680;&#20989;&#25968;&#30340;&#36873;&#25321;&#38382;&#39064;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#65288;&#22810;&#20803;&#65289;&#26368;&#20248;&#26680;&#20989;&#25968;&#65292;&#22312;&#26576;&#20010;&#26680;&#20989;&#25968;&#31867;&#21035;&#20013;&#20351;&#24471;&#20854;&#35299;&#26512;&#24471;&#21040;&#30340;&#28176;&#36817;&#35823;&#24046;&#20934;&#21017;&#26368;&#23567;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#26680;&#20989;&#25968;&#30340;&#27169;&#24577;&#32479;&#35745;&#26041;&#27861;&#21253;&#25324;&#27169;&#24577;&#20272;&#35745;&#12289;&#22238;&#24402;&#21644;&#32858;&#31867;&#12290;&#36825;&#20123;&#26041;&#27861;&#30340;&#20272;&#35745;&#20934;&#30830;&#24615;&#21462;&#20915;&#20110;&#25152;&#20351;&#29992;&#30340;&#26680;&#20989;&#25968;&#21644;&#24102;&#23485;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#26680;&#20989;&#25968;&#36873;&#25321;&#23545;&#36825;&#20123;&#26041;&#27861;&#20272;&#35745;&#20934;&#30830;&#24615;&#30340;&#24433;&#21709;&#12290;&#29305;&#21035;&#22320;&#65292;&#24403;&#20351;&#29992;&#26368;&#20248;&#24102;&#23485;&#26102;&#65292;&#26412;&#25991;&#29702;&#35770;&#19978;&#23637;&#31034;&#20102;&#19968;&#31181;&#65288;&#22810;&#20803;&#65289;&#26368;&#20248;&#26680;&#20989;&#25968;&#65292;&#20854;&#22312;&#23450;&#20041;&#20026;&#20854;&#31526;&#21495;&#21464;&#21270;&#25968;&#37327;&#30340;&#26576;&#20010;&#26680;&#20989;&#25968;&#31867;&#21035;&#20013;&#65292;&#20351;&#24471;&#20854;&#35299;&#26512;&#24471;&#21040;&#30340;&#28176;&#36817;&#35823;&#24046;&#20934;&#21017;&#26368;&#23567;&#21270;&#12290;
&lt;/p&gt;
&lt;p&gt;
Kernel-based modal statistical methods include mode estimation, regression, and clustering. Estimation accuracy of these methods depends on the kernel used as well as the bandwidth. We study effect of the selection of the kernel function to the estimation accuracy of these methods. In particular, we theoretically show a (multivariate) optimal kernel that minimizes its analytically-obtained asymptotic error criterion when using an optimal bandwidth, among a certain kernel class defined via the number of its sign changes.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#27835;&#30103;&#19981;&#26381;&#20174;&#24615;&#25552;&#20986;&#20102;&#19968;&#31181;&#21322;&#21442;&#25968;&#26694;&#26550;&#26469;&#35780;&#20272;&#22240;&#26524;&#20013;&#20171;&#25928;&#24212;&#65292;&#25552;&#20986;&#20102;&#19968;&#32452;&#20551;&#35774;&#26469;&#35782;&#21035;&#33258;&#28982;&#20013;&#20171;&#25928;&#24212;&#24182;&#25512;&#23548;&#20986;&#25104;&#20493;&#31283;&#20581;&#20272;&#35745;&#22120;&#12290;</title><link>http://arxiv.org/abs/2304.10025</link><description>&lt;p&gt;
&#29992;&#20110;&#22240;&#26524;&#20013;&#20171;&#20998;&#26512;&#20013;&#20855;&#26377;&#27835;&#30103;&#19981;&#26381;&#20174;&#24615;&#30340;&#35782;&#21035;&#21644;&#20493;&#22686;&#31283;&#20581;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Identification and multiply robust estimation in causal mediation analysis with treatment noncompliance. (arXiv:2304.10025v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.10025
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#27835;&#30103;&#19981;&#26381;&#20174;&#24615;&#25552;&#20986;&#20102;&#19968;&#31181;&#21322;&#21442;&#25968;&#26694;&#26550;&#26469;&#35780;&#20272;&#22240;&#26524;&#20013;&#20171;&#25928;&#24212;&#65292;&#25552;&#20986;&#20102;&#19968;&#32452;&#20551;&#35774;&#26469;&#35782;&#21035;&#33258;&#28982;&#20013;&#20171;&#25928;&#24212;&#24182;&#25512;&#23548;&#20986;&#25104;&#20493;&#31283;&#20581;&#20272;&#35745;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#23454;&#39564;&#21644;&#35266;&#23519;&#30740;&#31350;&#20013;&#65292;&#20154;&#20204;&#36890;&#24120;&#23545;&#20102;&#35299;&#24178;&#39044;&#26041;&#26696;&#22914;&#20309;&#25913;&#21892;&#26368;&#32456;&#32467;&#26524;&#30340;&#28508;&#22312;&#26426;&#21046;&#24863;&#20852;&#36259;&#12290;&#22240;&#26524;&#20013;&#20171;&#20998;&#26512;&#26088;&#22312;&#36798;&#21040;&#27492;&#30446;&#30340;&#65292;&#20294;&#20027;&#35201;&#38480;&#20110;&#27835;&#30103;&#23436;&#20840;&#26381;&#20174;&#30340;&#24773;&#20917;&#65292;&#21482;&#26377;&#23569;&#25968;&#24773;&#20917;&#38656;&#35201;&#25490;&#38500;&#38480;&#21046;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24314;&#31435;&#20102;&#19968;&#20010;&#21322;&#21442;&#25968;&#26694;&#26550;&#65292;&#29992;&#20110;&#22312;&#26080;&#38656;&#25490;&#38500;&#38480;&#21046;&#30340;&#24773;&#20917;&#19979;&#35780;&#20272;&#20855;&#26377;&#27835;&#30103;&#19981;&#26381;&#20174;&#24615;&#30340;&#22240;&#26524;&#20013;&#20171;&#25928;&#24212;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#32452;&#20551;&#35774;&#26469;&#35782;&#21035;&#25972;&#20010;&#30740;&#31350;&#20154;&#32676;&#30340;&#33258;&#28982;&#20013;&#20171;&#25928;&#24212;&#65292;&#24182;&#36827;&#19968;&#27493;&#38024;&#23545;&#30001;&#28508;&#22312;&#26381;&#20174;&#34892;&#20026;&#29305;&#24449;&#21270;&#30340;&#20122;&#20154;&#32676;&#20013;&#30340;&#20027;&#35201;&#33258;&#28982;&#20013;&#20171;&#25928;&#24212;&#36827;&#34892;&#35782;&#21035;&#12290;&#25105;&#20204;&#25512;&#23548;&#20986;&#20102;&#20027;&#35201;&#33258;&#28982;&#20013;&#20171;&#25928;&#24212;&#20272;&#35745;&#37327;&#30340;&#26377;&#25928;&#24433;&#21709;&#20989;&#25968;&#65292;&#36825;&#28608;&#21169;&#20102;&#19968;&#32452;&#20493;&#22686;&#31283;&#20581;&#20272;&#35745;&#22120;&#36827;&#34892;&#25512;&#35770;&#12290;&#36825;&#20123;&#34987;&#35782;&#21035;&#20272;&#35745;&#37327;&#30340;&#21322;&#21442;&#25968;&#25928;&#29575;&#29702;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
In experimental and observational studies, there is often interest in understanding the potential mechanism by which an intervention program improves the final outcome. Causal mediation analyses have been developed for this purpose but are primarily restricted to the case of perfect treatment compliance, with a few exceptions that require exclusion restriction. In this article, we establish a semiparametric framework for assessing causal mediation in the presence of treatment noncompliance without exclusion restriction. We propose a set of assumptions to identify the natural mediation effects for the entire study population and further, for the principal natural mediation effects within subpopulations characterized by the potential compliance behaviour. We derive the efficient influence functions for the principal natural mediation effect estimands, which motivate a set of multiply robust estimators for inference. The semiparametric efficiency theory for the identified estimands is der
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21644;&#36164;&#20135;&#29305;&#23450;&#22240;&#32032;&#22312;&#39044;&#27979;&#34892;&#19994;&#22238;&#25253;&#21644;&#27979;&#37327;&#34892;&#19994;&#29305;&#23450;&#39118;&#38505;&#28322;&#20215;&#26041;&#38754;&#33719;&#24471;&#26356;&#22823;&#32463;&#27982;&#25910;&#30410;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#22411;&#22312;&#32447;&#38598;&#25104;&#31639;&#27861;&#26469;&#23398;&#20064;&#20248;&#21270;&#39044;&#27979;&#24615;&#33021;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#38382;&#39064;&#21644;&#21487;&#33021;&#30340;&#40657;&#30418;&#27169;&#22411;&#31995;&#32479;&#12290;</title><link>http://arxiv.org/abs/2304.09947</link><description>&lt;p&gt;
&#22312;&#32447;&#27169;&#22411;&#38598;&#25104;&#23545;&#26368;&#20248;&#39044;&#27979;&#24615;&#33021;&#30340;&#24212;&#29992;&#21644;&#34892;&#19994;&#36718;&#25442;&#31574;&#30053;
&lt;/p&gt;
&lt;p&gt;
Online Ensemble of Models for Optimal Predictive Performance with Applications to Sector Rotation Strategy. (arXiv:2304.09947v1 [q-fin.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09947
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#21644;&#36164;&#20135;&#29305;&#23450;&#22240;&#32032;&#22312;&#39044;&#27979;&#34892;&#19994;&#22238;&#25253;&#21644;&#27979;&#37327;&#34892;&#19994;&#29305;&#23450;&#39118;&#38505;&#28322;&#20215;&#26041;&#38754;&#33719;&#24471;&#26356;&#22823;&#32463;&#27982;&#25910;&#30410;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#22411;&#22312;&#32447;&#38598;&#25104;&#31639;&#27861;&#26469;&#23398;&#20064;&#20248;&#21270;&#39044;&#27979;&#24615;&#33021;&#65292;&#29305;&#21035;&#36866;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#38382;&#39064;&#21644;&#21487;&#33021;&#30340;&#40657;&#30418;&#27169;&#22411;&#31995;&#32479;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36164;&#20135;&#29305;&#23450;&#22240;&#32032;&#36890;&#24120;&#29992;&#20110;&#39044;&#27979;&#37329;&#34701;&#22238;&#25253;&#24182;&#37327;&#21270;&#36164;&#20135;&#29305;&#23450;&#39118;&#38505;&#28322;&#20215;&#12290;&#25105;&#20204;&#20351;&#29992;&#21508;&#31181;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#35777;&#26126;&#65292;&#36825;&#20123;&#22240;&#32032;&#21253;&#21547;&#30340;&#20449;&#24687;&#21487;&#20197;&#22312;&#39044;&#27979;&#34892;&#19994;&#22238;&#25253;&#21644;&#27979;&#37327;&#34892;&#19994;&#29305;&#23450;&#39118;&#38505;&#28322;&#20215;&#26041;&#38754;&#24102;&#26469;&#26356;&#22823;&#30340;&#32463;&#27982;&#25910;&#30410;&#12290;&#20026;&#20102;&#21033;&#29992;&#19981;&#21516;&#34892;&#19994;&#34920;&#29616;&#30340;&#21333;&#20010;&#27169;&#22411;&#30340;&#24378;&#39044;&#27979;&#32467;&#26524;&#65292;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#26032;&#22411;&#22312;&#32447;&#38598;&#25104;&#31639;&#27861;&#65292;&#35813;&#31639;&#27861;&#23398;&#20064;&#20248;&#21270;&#39044;&#27979;&#24615;&#33021;&#12290;&#35813;&#31639;&#27861;&#38543;&#30528;&#26102;&#38388;&#30340;&#25512;&#31227;&#19981;&#26029;&#36866;&#24212;&#65292;&#36890;&#36807;&#20998;&#26512;&#23427;&#20204;&#26368;&#36817;&#30340;&#39044;&#27979;&#24615;&#33021;&#26469;&#30830;&#23450;&#20010;&#20307;&#27169;&#22411;&#30340;&#26368;&#20339;&#32452;&#21512;&#12290;&#36825;&#20351;&#23427;&#29305;&#21035;&#36866;&#29992;&#20110;&#26102;&#38388;&#24207;&#21015;&#38382;&#39064;&#65292;&#28378;&#21160;&#31383;&#21475;&#22238;&#27979;&#31243;&#24207;&#21644;&#21487;&#33021;&#30340;&#40657;&#30418;&#27169;&#22411;&#31995;&#32479;&#12290;&#25105;&#20204;&#25512;&#23548;&#20986;&#26368;&#20248;&#22686;&#30410;&#20989;&#25968;&#65292;&#29992;&#26679;&#26412;&#22806;R&#24179;&#26041;&#24230;&#37327;&#34920;&#36798;&#30456;&#24212;&#30340;&#36951;&#25022;&#30028;&#65292;&#24182;&#25512;&#23548;&#20986;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;
Asset-specific factors are commonly used to forecast financial returns and quantify asset-specific risk premia. Using various machine learning models, we demonstrate that the information contained in these factors leads to even larger economic gains in terms of forecasts of sector returns and the measurement of sector-specific risk premia. To capitalize on the strong predictive results of individual models for the performance of different sectors, we develop a novel online ensemble algorithm that learns to optimize predictive performance. The algorithm continuously adapts over time to determine the optimal combination of individual models by solely analyzing their most recent prediction performance. This makes it particularly suited for time series problems, rolling window backtesting procedures, and systems of potentially black-box models. We derive the optimal gain function, express the corresponding regret bounds in terms of the out-of-sample R-squared measure, and derive optimal le
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#20445;&#30041;&#35889;&#30340;&#25968;&#25454;&#21387;&#32553;&#26469;&#21152;&#36895;&#25903;&#25345;&#21521;&#37327;&#32858;&#31867;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#32858;&#31867;&#36895;&#24230;&#32780;&#19981;&#29306;&#29298;&#32858;&#31867;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2304.09868</link><description>&lt;p&gt;
&#36890;&#36807;&#20445;&#30041;&#35889;&#30340;&#25968;&#25454;&#21387;&#32553;&#21152;&#36895;&#25903;&#25345;&#21521;&#37327;&#32858;&#31867;
&lt;/p&gt;
&lt;p&gt;
Accelerate Support Vector Clustering via Spectrum-Preserving Data Compression?. (arXiv:2304.09868v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.09868
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36890;&#36807;&#20445;&#30041;&#35889;&#30340;&#25968;&#25454;&#21387;&#32553;&#26469;&#21152;&#36895;&#25903;&#25345;&#21521;&#37327;&#32858;&#31867;&#30340;&#26041;&#27861;&#65292;&#21487;&#20197;&#26174;&#33879;&#25552;&#39640;&#32858;&#31867;&#36895;&#24230;&#32780;&#19981;&#29306;&#29298;&#32858;&#31867;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25903;&#25345;&#21521;&#37327;&#32858;&#31867;&#26159;&#19968;&#31181;&#37325;&#35201;&#30340;&#32858;&#31867;&#26041;&#27861;&#65292;&#20294;&#26159;&#30001;&#20110;&#20854;&#35745;&#31639;&#26114;&#36149;&#30340;&#31751;&#20998;&#37197;&#27493;&#39588;&#65292;&#23427;&#38754;&#20020;&#30528;&#21487;&#20280;&#32553;&#24615;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#20445;&#30041;&#35889;&#30340;&#25968;&#25454;&#21387;&#32553;&#26469;&#21152;&#36895;&#25903;&#25345;&#21521;&#37327;&#32858;&#31867;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#23558;&#21407;&#22987;&#25968;&#25454;&#38598;&#21387;&#32553;&#25104;&#23569;&#37327;&#35889;&#34920;&#31034;&#30340;&#32858;&#21512;&#25968;&#25454;&#28857;&#65292;&#28982;&#21518;&#22312;&#21387;&#32553;&#21518;&#30340;&#25968;&#25454;&#38598;&#19978;&#25191;&#34892;&#26631;&#20934;&#30340;&#25903;&#25345;&#21521;&#37327;&#32858;&#31867;&#65292;&#26368;&#21518;&#23558;&#21387;&#32553;&#25968;&#25454;&#38598;&#30340;&#32858;&#31867;&#32467;&#26524;&#26144;&#23556;&#22238;&#21407;&#22987;&#25968;&#25454;&#38598;&#20197;&#21457;&#29616;&#31751;&#12290;&#25105;&#20204;&#22312;&#30495;&#23454;&#25968;&#25454;&#38598;&#19978;&#30340;&#22823;&#37327;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#30456;&#36739;&#20110;&#26631;&#20934;&#25903;&#25345;&#21521;&#37327;&#32858;&#31867;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22823;&#22823;&#25552;&#39640;&#20102;&#36895;&#24230;&#65292;&#32780;&#19981;&#20250;&#25439;&#22833;&#32858;&#31867;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
Support vector clustering is an important clustering method. However, it suffers from a scalability issue due to its computational expensive cluster assignment step. In this paper we accelertate the support vector clustering via spectrum-preserving data compression. Specifically, we first compress the original data set into a small amount of spectrally representative aggregated data points. Then, we perform standard support vector clustering on the compressed data set. Finally, we map the clustering results of the compressed data set back to discover the clusters in the original data set. Our extensive experimental results on real-world data set demonstrate dramatically speedups over standard support vector clustering without sacrificing clustering quality.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#12289;&#32431;&#24046;&#20998;&#38544;&#31169;&#20272;&#35745;&#22120;&#65292;&#21487;&#20197;&#22312;$\{0,1\}^d$&#19978;&#20934;&#30830;&#20272;&#35745;&#20108;&#20803;&#31215;&#20998;&#24067;&#30340;&#22343;&#20540;&#65292;&#36798;&#21040;&#20102;&#26368;&#20248;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;</title><link>http://arxiv.org/abs/2304.06787</link><description>&lt;p&gt;
&#20108;&#20803;&#31215;&#20998;&#24067;&#30340;&#22810;&#39033;&#24335;&#26102;&#38388;&#21644;&#32431;&#24046;&#20998;&#38544;&#31169;&#20272;&#35745;&#22120;
&lt;/p&gt;
&lt;p&gt;
A Polynomial Time, Pure Differentially Private Estimator for Binary Product Distributions. (arXiv:2304.06787v1 [cs.DS])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.06787
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#12289;&#32431;&#24046;&#20998;&#38544;&#31169;&#20272;&#35745;&#22120;&#65292;&#21487;&#20197;&#22312;$\{0,1\}^d$&#19978;&#20934;&#30830;&#20272;&#35745;&#20108;&#20803;&#31215;&#20998;&#24067;&#30340;&#22343;&#20540;&#65292;&#36798;&#21040;&#20102;&#26368;&#20248;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#20010;&#949;-&#24046;&#20998;&#38544;&#31169;&#12289;&#35745;&#31639;&#26377;&#25928;&#30340;&#31639;&#27861;&#65292;&#21487;&#20197;&#22312;&#24635;&#21464;&#21270;&#36317;&#31163;&#19979;&#20934;&#30830;&#22320;&#20272;&#35745;$\{0,1\}^d$&#19978;&#30340;&#20056;&#31215;&#20998;&#24067;&#30340;&#22343;&#20540;&#65292;&#21516;&#26102;&#22312;&#22810;&#39033;&#24335;&#23545;&#25968;&#22240;&#23376;&#20869;&#33719;&#24471;&#20102;&#26368;&#20248;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#20043;&#21069;&#30340;&#24037;&#20316;&#35201;&#20040;&#22312;&#26356;&#24369;&#30340;&#38544;&#31169;&#27010;&#24565;&#19979;&#26377;&#25928;&#22320;&#35299;&#20915;&#20102;&#36825;&#20010;&#38382;&#39064;&#65292;&#35201;&#20040;&#22312;&#25351;&#25968;&#32423;&#36816;&#34892;&#26102;&#38388;&#20869;&#26368;&#20248;&#22320;&#35299;&#20915;&#20102;&#36825;&#20010;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present the first $\varepsilon$-differentially private, computationally efficient algorithm that estimates the means of product distributions over $\{0,1\}^d$ accurately in total-variation distance, whilst attaining the optimal sample complexity to within polylogarithmic factors. The prior work had either solved this problem efficiently and optimally under weaker notions of privacy, or had solved it optimally while having exponential running times.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#25968;&#25454;&#22240;&#26524;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#21516;&#26102;&#22788;&#29702;&#19968;&#32452;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#65292;&#29983;&#25104;&#19968;&#20010;&#21333;&#19968;&#30340;&#22240;&#26524;&#39537;&#21160;&#38598;&#65292;&#24182;&#19988;&#21487;&#20197;&#36807;&#28388;&#25481;&#22240;&#26524;&#34394;&#20551;&#38142;&#25509;&#65292;&#26368;&#32456;&#36755;&#20837;&#21040;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#39044;&#27979;&#30446;&#26631;&#12290;</title><link>http://arxiv.org/abs/2304.05294</link><description>&lt;p&gt;
&#20351;&#29992;&#22810;&#25968;&#25454;&#22240;&#26524;&#25512;&#26029;&#36873;&#25321;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#30340;&#24378;&#20581;&#29305;&#24449;
&lt;/p&gt;
&lt;p&gt;
Selecting Robust Features for Machine Learning Applications using Multidata Causal Discovery. (arXiv:2304.05294v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.05294
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22810;&#25968;&#25454;&#22240;&#26524;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#65292;&#23427;&#21487;&#20197;&#21516;&#26102;&#22788;&#29702;&#19968;&#32452;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#65292;&#29983;&#25104;&#19968;&#20010;&#21333;&#19968;&#30340;&#22240;&#26524;&#39537;&#21160;&#38598;&#65292;&#24182;&#19988;&#21487;&#20197;&#36807;&#28388;&#25481;&#22240;&#26524;&#34394;&#20551;&#38142;&#25509;&#65292;&#26368;&#32456;&#36755;&#20837;&#21040;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#20013;&#39044;&#27979;&#30446;&#26631;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24378;&#20581;&#30340;&#29305;&#24449;&#36873;&#25321;&#23545;&#20110;&#21019;&#24314;&#21487;&#38752;&#21644;&#21487;&#35299;&#37322;&#30340;&#26426;&#22120;&#23398;&#20064;&#65288;ML&#65289;&#27169;&#22411;&#33267;&#20851;&#37325;&#35201;&#12290;&#22312;&#39046;&#22495;&#30693;&#35782;&#26377;&#38480;&#12289;&#28508;&#22312;&#20132;&#20114;&#26410;&#30693;&#30340;&#24773;&#20917;&#19979;&#35774;&#35745;&#32479;&#35745;&#39044;&#27979;&#27169;&#22411;&#26102;&#65292;&#36873;&#25321;&#26368;&#20248;&#29305;&#24449;&#38598;&#36890;&#24120;&#24456;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#22810;&#25968;&#25454;&#65288;M&#65289;&#22240;&#26524;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#65292;&#23427;&#21516;&#26102;&#22788;&#29702;&#19968;&#32452;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#38598;&#65292;&#24182;&#29983;&#25104;&#19968;&#20010;&#21333;&#19968;&#30340;&#22240;&#26524;&#39537;&#21160;&#38598;&#12290;&#35813;&#26041;&#27861;&#20351;&#29992;Tigramite Python&#21253;&#20013;&#23454;&#29616;&#30340;&#22240;&#26524;&#21457;&#29616;&#31639;&#27861;PC1&#25110;PCMCI&#12290;&#36825;&#20123;&#31639;&#27861;&#21033;&#29992;&#26465;&#20214;&#29420;&#31435;&#24615;&#27979;&#35797;&#25512;&#26029;&#22240;&#26524;&#22270;&#30340;&#37096;&#20998;&#12290;&#25105;&#20204;&#30340;&#22240;&#26524;&#29305;&#24449;&#36873;&#25321;&#26041;&#27861;&#22312;&#23558;&#21097;&#20313;&#22240;&#26524;&#29305;&#24449;&#20316;&#20026;&#36755;&#20837;&#20256;&#36882;&#32473;ML&#27169;&#22411;&#65288;&#22810;&#20803;&#32447;&#24615;&#22238;&#24402;&#65292;&#38543;&#26426;&#26862;&#26519;&#65289;&#39044;&#27979;&#30446;&#26631;&#20043;&#21069;&#65292;&#36807;&#28388;&#25481;&#22240;&#26524;&#34394;&#20551;&#38142;&#25509;&#12290;&#25105;&#20204;&#23558;&#35813;&#26694;&#26550;&#24212;&#29992;&#20110;&#39044;&#27979;&#35199;&#22826;&#24179;&#27915;&#28909;&#24102;&#22320;&#21306;&#30340;&#22320;&#38663;&#24378;&#24230;&#12290;
&lt;/p&gt;
&lt;p&gt;
Robust feature selection is vital for creating reliable and interpretable Machine Learning (ML) models. When designing statistical prediction models in cases where domain knowledge is limited and underlying interactions are unknown, choosing the optimal set of features is often difficult. To mitigate this issue, we introduce a Multidata (M) causal feature selection approach that simultaneously processes an ensemble of time series datasets and produces a single set of causal drivers. This approach uses the causal discovery algorithms PC1 or PCMCI that are implemented in the Tigramite Python package. These algorithms utilize conditional independence tests to infer parts of the causal graph. Our causal feature selection approach filters out causally-spurious links before passing the remaining causal features as inputs to ML models (Multiple linear regression, Random Forest) that predict the targets. We apply our framework to the statistical intensity prediction of Western Pacific Tropical
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#29366;&#24577;&#32858;&#21512;&#26041;&#27861;&#26469;&#38477;&#20302;&#21160;&#24577;&#31163;&#25955;&#36873;&#25321;&#27169;&#22411;&#30340;&#20272;&#35745;&#35745;&#31639;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#39318;&#20808;&#21033;&#29992;&#21453;&#21521;&#24378;&#21270;&#23398;&#20064;&#20272;&#35745;&#20195;&#29702;Q&#20989;&#25968;&#65292;&#28982;&#21518;&#29992;&#32858;&#31867;&#31639;&#27861;&#36873;&#25321;&#37325;&#35201;&#30340;&#29366;&#24577;&#32858;&#21512;&#65292;&#26368;&#32456;&#21033;&#29992;&#23884;&#22871;&#22266;&#23450;&#28857;&#31639;&#27861;&#36827;&#34892;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2304.04916</link><description>&lt;p&gt;
&#19968;&#31181;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#29366;&#24577;&#32858;&#21512;&#26041;&#27861;&#29992;&#20110;&#21160;&#24577;&#31163;&#25955;&#36873;&#25321;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
A Data-Driven State Aggregation Approach for Dynamic Discrete Choice Models. (arXiv:2304.04916v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.04916
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#25968;&#25454;&#39537;&#21160;&#30340;&#29366;&#24577;&#32858;&#21512;&#26041;&#27861;&#26469;&#38477;&#20302;&#21160;&#24577;&#31163;&#25955;&#36873;&#25321;&#27169;&#22411;&#30340;&#20272;&#35745;&#35745;&#31639;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#65292;&#39318;&#20808;&#21033;&#29992;&#21453;&#21521;&#24378;&#21270;&#23398;&#20064;&#20272;&#35745;&#20195;&#29702;Q&#20989;&#25968;&#65292;&#28982;&#21518;&#29992;&#32858;&#31867;&#31639;&#27861;&#36873;&#25321;&#37325;&#35201;&#30340;&#29366;&#24577;&#32858;&#21512;&#65292;&#26368;&#32456;&#21033;&#29992;&#23884;&#22871;&#22266;&#23450;&#28857;&#31639;&#27861;&#36827;&#34892;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#30740;&#31350;&#20102;&#21160;&#24577;&#31163;&#25955;&#36873;&#25321;&#27169;&#22411;&#65292;&#20854;&#20013;&#19968;&#20010;&#24120;&#35265;&#30340;&#38382;&#39064;&#26159;&#20351;&#29992;&#20195;&#29702;&#34892;&#20026;&#25968;&#25454;&#20272;&#35745;&#20195;&#29702;&#22870;&#21169;&#20989;&#25968;&#65288;&#20063;&#31216;&#20026;&#8220;&#32467;&#26500;&#21442;&#25968;&#8221;&#65289;&#30340;&#21442;&#25968;&#12290;&#36825;&#31181;&#27169;&#22411;&#30340;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#38656;&#35201;&#21160;&#24577;&#35268;&#21010;&#65292;&#36825;&#21463;&#21040;&#32500;&#24230;&#28798;&#38590;&#30340;&#38480;&#21046;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#31639;&#27861;&#65292;&#25552;&#20379;&#20102;&#19968;&#31181;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#27861;&#26469;&#36873;&#25321;&#21644;&#32858;&#21512;&#29366;&#24577;&#65292;&#38477;&#20302;&#20102;&#20272;&#35745;&#30340;&#35745;&#31639;&#21644;&#26679;&#26412;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#20998;&#20004;&#20010;&#38454;&#27573;&#12290;&#22312;&#31532;&#19968;&#38454;&#27573;&#20013;&#65292;&#25105;&#20204;&#20351;&#29992;&#28789;&#27963;&#30340;&#21453;&#21521;&#24378;&#21270;&#23398;&#20064;&#26041;&#27861;&#26469;&#20272;&#35745;&#20195;&#29702;Q&#20989;&#25968;&#12290;&#25105;&#20204;&#20351;&#29992;&#36825;&#20123;&#20272;&#35745;&#30340;Q&#20989;&#25968;&#65292;&#20197;&#21450;&#19968;&#20010;&#32858;&#31867;&#31639;&#27861;&#65292;&#36873;&#25321;&#20102;&#19968;&#20123;&#26368;&#20026;&#37325;&#35201;&#30340;&#29366;&#24577;&#65292;&#36825;&#20123;&#29366;&#24577;&#23545;&#20110;&#39537;&#21160;Q&#20989;&#25968;&#30340;&#21464;&#21270;&#26368;&#20026;&#20851;&#38190;&#12290;&#22312;&#31532;&#20108;&#38454;&#27573;&#65292;&#21033;&#29992;&#36825;&#20123;&#34987;&#36873;&#25321;&#30340;&#8220;&#32858;&#21512;&#8221;&#29366;&#24577;&#65292;&#25105;&#20204;&#20351;&#29992;&#24120;&#29992;&#30340;&#23884;&#22871;&#22266;&#23450;&#28857;&#31639;&#27861;&#36827;&#34892;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#12290;&#25152;&#25552;&#20986;&#30340;&#20108;&#38454;&#27573;&#26041;&#27861;&#23454;&#29616;&#20102;...
&lt;/p&gt;
&lt;p&gt;
We study dynamic discrete choice models, where a commonly studied problem involves estimating parameters of agent reward functions (also known as "structural" parameters), using agent behavioral data. Maximum likelihood estimation for such models requires dynamic programming, which is limited by the curse of dimensionality. In this work, we present a novel algorithm that provides a data-driven method for selecting and aggregating states, which lowers the computational and sample complexity of estimation. Our method works in two stages. In the first stage, we use a flexible inverse reinforcement learning approach to estimate agent Q-functions. We use these estimated Q-functions, along with a clustering algorithm, to select a subset of states that are the most pivotal for driving changes in Q-functions. In the second stage, with these selected "aggregated" states, we conduct maximum likelihood estimation using a commonly used nested fixed-point algorithm. The proposed two-stage approach 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#38024;&#23545;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#65292;&#35777;&#26126;&#20102;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#30340;Bayesian&#33258;&#30001;&#33021;&#26159;&#26377;&#30028;&#30340;&#65292;&#35828;&#26126;Bayesian&#24191;&#20041;&#35823;&#24046;&#19981;&#20250;&#22686;&#21152;&#12290;</title><link>http://arxiv.org/abs/2303.15739</link><description>&lt;p&gt;
&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#22312;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#30340;&#36125;&#21494;&#26031;&#33258;&#30001;&#33021;
&lt;/p&gt;
&lt;p&gt;
Bayesian Free Energy of Deep ReLU Neural Network in Overparametrized Cases. (arXiv:2303.15739v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.15739
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#38024;&#23545;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#65292;&#35777;&#26126;&#20102;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#30340;Bayesian&#33258;&#30001;&#33021;&#26159;&#26377;&#30028;&#30340;&#65292;&#35828;&#26126;Bayesian&#24191;&#20041;&#35823;&#24046;&#19981;&#20250;&#22686;&#21152;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#20154;&#24037;&#26234;&#33021;&#30340;&#35768;&#22810;&#30740;&#31350;&#39046;&#22495;&#20013;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#24050;&#34987;&#35777;&#26126;&#21487;&#29992;&#20110;&#20272;&#35745;&#39640;&#32500;&#36755;&#20837;&#31354;&#38388;&#20013;&#30340;&#26410;&#30693;&#20989;&#25968;&#12290;&#28982;&#32780;&#65292;&#23427;&#20204;&#30340;&#27867;&#21270;&#24615;&#33021;&#23578;&#26410;&#20174;&#29702;&#35770;&#35282;&#24230;&#23436;&#20840;&#28548;&#28165;&#65292;&#22240;&#20026;&#23427;&#20204;&#26159;&#19981;&#21487;&#35782;&#21035;&#30340;&#21644;&#22855;&#24322;&#30340;&#23398;&#20064;&#26426;&#22120;&#12290;&#27492;&#22806;&#65292;ReLU&#20989;&#25968;&#19981;&#21487;&#24494;&#65292;&#22855;&#24322;&#23398;&#20064;&#29702;&#35770;&#20013;&#30340;&#20195;&#25968;&#25110;&#35299;&#26512;&#26041;&#27861;&#26080;&#27861;&#24212;&#29992;&#20110;&#23427;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#36807;&#21442;&#25968;&#21270;&#24773;&#20917;&#19979;&#30340;&#28145;&#24230;ReLU&#31070;&#32463;&#32593;&#32476;&#65292;&#24182;&#35777;&#26126;&#20102;Bayesian&#33258;&#30001;&#33021;&#26159;&#26377;&#30028;&#30340;&#65292;&#21363;&#20351;&#23618;&#25968;&#27604;&#20272;&#35745;&#26410;&#30693;&#25968;&#25454;&#29983;&#25104;&#20989;&#25968;&#25152;&#24517;&#38656;&#30340;&#23618;&#25968;&#26356;&#22810;&#12290;&#30001;&#20110;Bayesian&#24191;&#20041;&#35823;&#24046;&#31561;&#20110;&#26679;&#26412;&#22823;&#23567;&#30340;&#33258;&#30001;&#33021;&#22686;&#21152;&#65292;&#22240;&#27492;&#25105;&#20204;&#30340;&#32467;&#26524;&#20063;&#34920;&#26126;&#65292;Bayesian&#24191;&#20041;&#35823;&#24046;&#19981;&#20250;&#22686;&#21152;&#12290;
&lt;/p&gt;
&lt;p&gt;
In many research fields in artificial intelligence, it has been shown that deep neural networks are useful to estimate unknown functions on high dimensional input spaces. However, their generalization performance is not yet completely clarified from the theoretical point of view because they are nonidentifiable and singular learning machines. Moreover, a ReLU function is not differentiable, to which algebraic or analytic methods in singular learning theory cannot be applied. In this paper, we study a deep ReLU neural network in overparametrized cases and prove that the Bayesian free energy, which is equal to the minus log marginal likelihoodor the Bayesian stochastic complexity, is bounded even if the number of layers are larger than necessary to estimate an unknown data-generating function. Since the Bayesian generalization error is equal to the increase of the free energy as a function of a sample size, our result also shows that the Bayesian generalization error does not increase ev
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25193;&#23637;&#20102;&#20449;&#24687;&#22330;&#29702;&#35770;(IFT)&#21040;&#29289;&#29702;&#20449;&#24687;&#22330;&#29702;&#35770;(PIFT)&#65292;&#23558;&#25551;&#36848;&#22330;&#30340;&#29289;&#29702;&#23450;&#24459;&#30340;&#20449;&#24687;&#32534;&#30721;&#20026;&#20989;&#25968;&#20808;&#39564;&#12290;&#20174;&#36825;&#20010;PIFT&#24471;&#20986;&#30340;&#21518;&#39564;&#19982;&#20219;&#20309;&#25968;&#20540;&#26041;&#26696;&#26080;&#20851;&#65292;&#24182;&#19988;&#21487;&#20197;&#25429;&#25417;&#22810;&#31181;&#27169;&#24335;&#12290;</title><link>http://arxiv.org/abs/2301.07609</link><description>&lt;p&gt;
&#29289;&#29702;&#23398;&#30693;&#35782;&#20316;&#20026;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#27169;&#22411;&#30340;&#20449;&#24687;&#22330;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Physics-informed Information Field Theory for Modeling Physical Systems with Uncertainty Quantification. (arXiv:2301.07609v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2301.07609
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25193;&#23637;&#20102;&#20449;&#24687;&#22330;&#29702;&#35770;(IFT)&#21040;&#29289;&#29702;&#20449;&#24687;&#22330;&#29702;&#35770;(PIFT)&#65292;&#23558;&#25551;&#36848;&#22330;&#30340;&#29289;&#29702;&#23450;&#24459;&#30340;&#20449;&#24687;&#32534;&#30721;&#20026;&#20989;&#25968;&#20808;&#39564;&#12290;&#20174;&#36825;&#20010;PIFT&#24471;&#20986;&#30340;&#21518;&#39564;&#19982;&#20219;&#20309;&#25968;&#20540;&#26041;&#26696;&#26080;&#20851;&#65292;&#24182;&#19988;&#21487;&#20197;&#25429;&#25417;&#22810;&#31181;&#27169;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#27861;&#32467;&#21512;&#29289;&#29702;&#23398;&#30693;&#35782;&#26159;&#24314;&#27169;&#31995;&#32479;&#30340;&#24378;&#26377;&#21147;&#25216;&#26415;&#12290;&#27492;&#31867;&#27169;&#22411;&#30340;&#30446;&#26631;&#26159;&#36890;&#36807;&#23558;&#27979;&#37327;&#32467;&#26524;&#19982;&#24050;&#30693;&#29289;&#29702;&#23450;&#24459;&#30456;&#32467;&#21512;&#65292;&#39640;&#25928;&#22320;&#27714;&#35299;&#22522;&#26412;&#22330;&#12290;&#30001;&#20110;&#35768;&#22810;&#31995;&#32479;&#21253;&#21547;&#26410;&#30693;&#20803;&#32032;&#65292;&#22914;&#32570;&#22833;&#21442;&#25968;&#12289;&#22024;&#26434;&#25968;&#25454;&#25110;&#19981;&#23436;&#25972;&#30340;&#29289;&#29702;&#23450;&#24459;&#65292;&#22240;&#27492;&#36825;&#36890;&#24120;&#34987;&#35270;&#20026;&#19968;&#31181;&#19981;&#30830;&#23450;&#24615;&#37327;&#21270;&#38382;&#39064;&#12290;&#22788;&#29702;&#25152;&#26377;&#21464;&#37327;&#30340;&#24120;&#35265;&#25216;&#26415;&#36890;&#24120;&#21462;&#20915;&#20110;&#29992;&#20110;&#36817;&#20284;&#21518;&#39564;&#30340;&#25968;&#20540;&#26041;&#26696;&#65292;&#24182;&#19988;&#24076;&#26395;&#26377;&#19968;&#31181;&#19981;&#20381;&#36182;&#20110;&#20219;&#20309;&#31163;&#25955;&#21270;&#30340;&#26041;&#27861;&#12290;&#20449;&#24687;&#22330;&#29702;&#35770;&#65288;IFT&#65289;&#25552;&#20379;&#20102;&#23545;&#19981;&#19968;&#23450;&#26159;&#39640;&#26031;&#22330;&#30340;&#22330;&#36827;&#34892;&#32479;&#35745;&#23398;&#30340;&#24037;&#20855;&#12290;&#25105;&#20204;&#36890;&#36807;&#23558;&#25551;&#36848;&#22330;&#30340;&#29289;&#29702;&#23450;&#24459;&#30340;&#20449;&#24687;&#32534;&#30721;&#20026;&#20989;&#25968;&#20808;&#39564;&#26469;&#25193;&#23637;IFT&#21040;&#29289;&#29702;&#20449;&#24687;&#22330;&#29702;&#35770;&#65288;PIFT&#65289;&#12290;&#20174;&#36825;&#20010;PIFT&#24471;&#20986;&#30340;&#21518;&#39564;&#19982;&#20219;&#20309;&#25968;&#20540;&#26041;&#26696;&#26080;&#20851;&#65292;&#24182;&#19988;&#21487;&#20197;&#25429;&#25417;&#22810;&#31181;&#27169;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Data-driven approaches coupled with physical knowledge are powerful techniques to model systems. The goal of such models is to efficiently solve for the underlying field by combining measurements with known physical laws. As many systems contain unknown elements, such as missing parameters, noisy data, or incomplete physical laws, this is widely approached as an uncertainty quantification problem. The common techniques to handle all the variables typically depend on the numerical scheme used to approximate the posterior, and it is desirable to have a method which is independent of any such discretization. Information field theory (IFT) provides the tools necessary to perform statistics over fields that are not necessarily Gaussian. We extend IFT to physics-informed IFT (PIFT) by encoding the functional priors with information about the physical laws which describe the field. The posteriors derived from this PIFT remain independent of any numerical scheme and can capture multiple modes,
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Nystr&#246;m&#22411;&#26041;&#27861;&#30340;&#39044;&#22788;&#29702;&#22120;&#26500;&#24314;&#26694;&#26550;&#65292;&#23454;&#29616;&#20102;&#22312;&#20302;&#25968;&#25454;&#33539;&#22260;&#20869;&#39640;&#25928;&#37325;&#26500;&#26680;&#26426;&#22120;&#21147;&#22330;&#65292;&#24182;&#22312;&#24102;&#26377;&#25968;&#19975;&#20010;&#22521;&#35757;&#28857;&#30340;&#21270;&#23398;&#31995;&#32479;&#20013;&#33719;&#24471;&#20102;&#31283;&#23450;&#21644;&#20934;&#30830;&#30340;&#32467;&#26524;&#12290;</title><link>http://arxiv.org/abs/2212.12737</link><description>&lt;p&gt;
&#29992;&#36229;&#32447;&#24615;&#25910;&#25947;&#37325;&#26500;&#22522;&#20110;&#26680;&#30340;&#26426;&#22120;&#23398;&#20064;&#21147;&#22330;
&lt;/p&gt;
&lt;p&gt;
Reconstructing Kernel-based Machine Learning Force Fields with Super-linear Convergence. (arXiv:2212.12737v2 [physics.chem-ph] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.12737
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;Nystr&#246;m&#22411;&#26041;&#27861;&#30340;&#39044;&#22788;&#29702;&#22120;&#26500;&#24314;&#26694;&#26550;&#65292;&#23454;&#29616;&#20102;&#22312;&#20302;&#25968;&#25454;&#33539;&#22260;&#20869;&#39640;&#25928;&#37325;&#26500;&#26680;&#26426;&#22120;&#21147;&#22330;&#65292;&#24182;&#22312;&#24102;&#26377;&#25968;&#19975;&#20010;&#22521;&#35757;&#28857;&#30340;&#21270;&#23398;&#31995;&#32479;&#20013;&#33719;&#24471;&#20102;&#31283;&#23450;&#21644;&#20934;&#30830;&#30340;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26680;&#26426;&#22120;&#22312;&#37327;&#23376;&#21270;&#23398;&#39046;&#22495;&#25345;&#32493;&#21462;&#24471;&#36827;&#23637;&#65292;&#23588;&#20854;&#22312;&#21147;&#22330;&#37325;&#26500;&#30340;&#20302;&#25968;&#25454;&#33539;&#22260;&#20869;&#24050;&#34987;&#35777;&#26126;&#25104;&#21151;&#12290;&#36825;&#26159;&#22240;&#20026;&#21487;&#20197;&#23558;&#35768;&#22810;&#38024;&#23545;&#29289;&#29702;&#23545;&#31216;&#24615;&#30340;&#31561;&#21464;&#24615;&#21644;&#19981;&#21464;&#24615;&#21512;&#24182;&#21040;&#26680;&#20989;&#25968;&#20013;&#20197;&#34917;&#20607;&#26356;&#22823;&#30340;&#25968;&#25454;&#38598;&#12290;&#20294;&#26159;&#65292;&#26680;&#26426;&#22120;&#30340;&#21487;&#25193;&#23637;&#24615;&#21463;&#21040;&#20854;&#20108;&#27425;&#20869;&#23384;&#21644;&#19982;&#35757;&#32451;&#28857;&#25968;&#25104;&#31435;&#26041;&#20851;&#31995;&#30340;&#38480;&#21046;&#12290;&#34429;&#28982;&#24050;&#30693;&#36845;&#20195;&#30340;Krylov&#23376;&#31354;&#38388;&#27714;&#35299;&#22120;&#21487;&#20197;&#20811;&#26381;&#36825;&#20123;&#36127;&#25285;&#65292;&#20294;&#23427;&#20204;&#30340;&#25910;&#25947;&#20851;&#38190;&#21462;&#20915;&#20110;&#26377;&#25928;&#30340;&#39044;&#22788;&#29702;&#22120;&#65292;&#36825;&#22312;&#23454;&#36341;&#20013;&#24456;&#38590;&#23454;&#29616;&#12290;&#26377;&#25928;&#30340;&#39044;&#22788;&#29702;&#22120;&#38656;&#35201;&#20197;&#35745;&#31639;&#20415;&#23452;&#21644;&#25968;&#20540;&#40065;&#26834;&#30340;&#26041;&#24335;&#37096;&#20998;&#39044;&#35299;&#23398;&#20064;&#38382;&#39064;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#32771;&#34385;&#20102;Nystr&#246;m&#22411;&#26041;&#27861;&#31867;&#30340;&#24191;&#27867;&#26041;&#27861;&#65292;&#20197;&#22522;&#20110;&#26368;&#21021;&#26680;&#20989;&#25968;&#30340;&#36234;&#26469;&#36234;&#22797;&#26434;&#30340;&#20302;&#31209;&#36817;&#20284;&#26500;&#24314;&#39044;&#22788;&#29702;&#22120;&#12290;
&lt;/p&gt;
&lt;p&gt;
Kernel machines have sustained continuous progress in the field of quantum chemistry. In particular, they have proven to be successful in the low-data regime of force field reconstruction. This is because many equivariances and invariances due to physical symmetries can be incorporated into the kernel function to compensate for much larger datasets. So far, the scalability of kernel machines has however been hindered by its quadratic memory and cubical runtime complexity in the number of training points. While it is known, that iterative Krylov subspace solvers can overcome these burdens, their convergence crucially relies on effective preconditioners, which are elusive in practice. Effective preconditioners need to partially pre-solve the learning problem in a computationally cheap and numerically robust manner. Here, we consider the broad class of Nystr\"om-type methods to construct preconditioners based on successively more sophisticated low-rank approximations of the original kerne
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;PowRL&#26694;&#26550;&#26469;&#36890;&#36807;&#24378;&#21270;&#23398;&#20064;&#26469;&#26377;&#25928;&#24212;&#23545;&#30005;&#21147;&#32593;&#32476;&#20013;&#30340;&#19981;&#30830;&#23450;&#24773;&#20917;&#65292;&#24182;&#20445;&#25345;&#30005;&#32593;&#30340;&#21487;&#38752;&#36816;&#34892;&#12290;</title><link>http://arxiv.org/abs/2212.02397</link><description>&lt;p&gt;
PowRL&#65306;&#29992;&#20110;&#31283;&#20581;&#31649;&#29702;&#30005;&#21147;&#32593;&#32476;&#30340;&#24378;&#21270;&#23398;&#20064;&#26694;&#26550;
&lt;/p&gt;
&lt;p&gt;
PowRL: A Reinforcement Learning Framework for Robust Management of Power Networks. (arXiv:2212.02397v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.02397
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;PowRL&#26694;&#26550;&#26469;&#36890;&#36807;&#24378;&#21270;&#23398;&#20064;&#26469;&#26377;&#25928;&#24212;&#23545;&#30005;&#21147;&#32593;&#32476;&#20013;&#30340;&#19981;&#30830;&#23450;&#24773;&#20917;&#65292;&#24182;&#20445;&#25345;&#30005;&#32593;&#30340;&#21487;&#38752;&#36816;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19990;&#30028;&#21508;&#22320;&#30340;&#30005;&#21147;&#32593;&#32476;&#36890;&#36807;&#20026;&#22810;&#20010;&#34892;&#19994;&#12289;&#20225;&#19994;&#21644;&#23478;&#24237;&#28040;&#36153;&#32773;&#25552;&#20379;&#19981;&#38388;&#26029;&#12289;&#21487;&#38752;&#21644;&#26080;&#26242;&#24577;&#30005;&#21147;&#21457;&#25381;&#30528;&#37325;&#35201;&#30340;&#31038;&#20250;&#21644;&#32463;&#27982;&#20316;&#29992;&#12290;&#38543;&#30528;&#21487;&#20877;&#29983;&#33021;&#28304;&#21644;&#30005;&#21160;&#36710;&#20135;&#29983;&#30340;&#19981;&#30830;&#23450;&#21457;&#30005;&#21644;&#39640;&#24230;&#21160;&#24577;&#36127;&#36733;&#38656;&#27714;&#30340;&#20986;&#29616;&#65292;&#36890;&#36807;&#36866;&#24403;&#30340;&#30636;&#24577;&#31283;&#23450;&#38382;&#39064;&#31649;&#29702;&#26469;&#30830;&#20445;&#30005;&#21147;&#32593;&#32476;&#30340;&#31283;&#20581;&#36816;&#34892;&#21464;&#24471;&#36234;&#26469;&#36234;&#37325;&#35201;&#65292;&#24182;&#23558;&#20572;&#30005;&#20107;&#20214;&#38480;&#21046;&#22312;&#22320;&#26041;&#33539;&#22260;&#20869;&#12290;&#26412;&#25991;&#24341;&#20837;&#20102;&#19968;&#20010;&#21517;&#20026;PowRL&#30340;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#26694;&#26550;&#65292;&#20197;&#32531;&#35299;&#24847;&#22806;&#32593;&#32476;&#20107;&#20214;&#30340;&#24433;&#21709;&#65292;&#24182;&#21487;&#38752;&#22320;&#22312;&#32593;&#32476;&#19978;&#38543;&#26102;&#32500;&#25345;&#30005;&#21147;&#12290;PowRL&#21033;&#29992;&#26032;&#39062;&#30340;&#36229;&#36127;&#33655;&#31649;&#29702;&#21551;&#21457;&#24335;&#20197;&#21450;&#22522;&#20110;RL&#25552;&#20379;&#30340;&#26368;&#20248;&#25299;&#25169;&#36873;&#25321;&#20915;&#31574;&#65292;&#20197;&#30830;&#20445;&#30005;&#32593;&#22312;&#21464;&#21270;&#21644;&#19981;&#30830;&#23450;&#26465;&#20214;&#19979;&#23433;&#20840;&#12289;&#21487;&#38752;&#22320;&#36816;&#34892;&#65288;&#26080;&#36229;&#36733;&#32447;&#36335;&#21644;&#26080;&#20572;&#30005;&#20107;&#20214;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Power grids, across the world, play an important societal and economical role by providing uninterrupted, reliable and transient-free power to several industries, businesses and household consumers. With the advent of renewable power resources and EVs resulting into uncertain generation and highly dynamic load demands, it has become ever so important to ensure robust operation of power networks through suitable management of transient stability issues and localize the events of blackouts. In the light of ever increasing stress on the modern grid infrastructure and the grid operators, this paper presents a reinforcement learning (RL) framework, PowRL, to mitigate the effects of unexpected network events, as well as reliably maintain electricity everywhere on the network at all times. The PowRL leverages a novel heuristic for overload management, along with the RL-guided decision making on optimal topology selection to ensure that the grid is operated safely and reliably (with no overloa
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#27169;&#22411;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#26041;&#27861;&#65292;&#21487;&#20197;&#19982;&#20219;&#24847;&#39044;&#27979;&#20989;&#25968;&#19968;&#36215;&#20351;&#29992;&#65292;&#19981;&#38656;&#35201;&#35775;&#38382;&#39044;&#27979;&#20989;&#25968;&#65292;&#21487;&#29992;&#20110;&#30740;&#31350;&#27169;&#22411;&#27531;&#24046;&#12290;&#24341;&#20837;&#20102;Cohort Shapley&#30340;&#31215;&#20998;&#26799;&#24230;&#29256;&#26412;&#65288;IGCS&#65289;&#65292;&#20351;&#24471;&#22312;&#20108;&#20803;&#39044;&#27979;&#22120;&#24773;&#20917;&#19979;&#20063;&#21487;&#20197;&#20351;&#29992;IG&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2211.08414</link><description>&lt;p&gt;
&#39640;&#32500;&#25968;&#25454;&#30340;&#26080;&#27169;&#22411;&#21464;&#37327;&#37325;&#35201;&#24615;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
Model free variable importance for high dimensional data. (arXiv:2211.08414v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.08414
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26080;&#27169;&#22411;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#26041;&#27861;&#65292;&#21487;&#20197;&#19982;&#20219;&#24847;&#39044;&#27979;&#20989;&#25968;&#19968;&#36215;&#20351;&#29992;&#65292;&#19981;&#38656;&#35201;&#35775;&#38382;&#39044;&#27979;&#20989;&#25968;&#65292;&#21487;&#29992;&#20110;&#30740;&#31350;&#27169;&#22411;&#27531;&#24046;&#12290;&#24341;&#20837;&#20102;Cohort Shapley&#30340;&#31215;&#20998;&#26799;&#24230;&#29256;&#26412;&#65288;IGCS&#65289;&#65292;&#20351;&#24471;&#22312;&#20108;&#20803;&#39044;&#27979;&#22120;&#24773;&#20917;&#19979;&#20063;&#21487;&#20197;&#20351;&#29992;IG&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#27169;&#22411;&#19981;&#21487;&#30693;&#30340;&#21464;&#37327;&#37325;&#35201;&#24615;&#26041;&#27861;&#21487;&#19982;&#20219;&#24847;&#39044;&#27979;&#20989;&#25968;&#19968;&#36215;&#20351;&#29992;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#20123;&#26080;&#27169;&#22411;&#26041;&#27861;&#65292;&#19981;&#38656;&#35201;&#35775;&#38382;&#39044;&#27979;&#20989;&#25968;&#12290;&#36825;&#22312;&#39044;&#27979;&#20989;&#25968;&#26159;&#19987;&#26377;&#30340;&#19988;&#19981;&#21487;&#29992;&#25110;&#26497;&#20854;&#26114;&#36149;&#26102;&#24456;&#26377;&#29992;&#12290;&#24403;&#23545;&#27169;&#22411;&#30340;&#27531;&#24046;&#36827;&#34892;&#30740;&#31350;&#26102;&#20063;&#24456;&#26377;&#29992;&#12290;Cohort Shapley&#65288;CS&#65289;&#26041;&#27861;&#26159;&#26080;&#27169;&#22411;&#26041;&#27861;&#65292;&#20294;&#22312;&#36755;&#20837;&#31354;&#38388;&#30340;&#32500;&#25968;&#19978;&#20855;&#26377;&#25351;&#25968;&#25104;&#26412;&#12290;Frye&#31561;&#20154;&#65288;2020&#65289;&#30340;&#30417;&#30563;&#27969;&#24418;&#19978;Shapley&#26041;&#27861;&#20063;&#26159;&#26080;&#27169;&#22411;&#30340;&#65292;&#20294;&#35201;&#27714;&#36755;&#20837;&#31532;&#20108;&#20010;&#40657;&#21283;&#23376;&#27169;&#22411;&#65292;&#35813;&#27169;&#22411;&#24517;&#39035;&#20026;Shapley&#20540;&#38382;&#39064;&#36827;&#34892;&#35757;&#32451;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;Cohort Shapley&#30340;&#31215;&#20998;&#26799;&#24230;&#65288;IG&#65289;&#29256;&#26412;&#65292;&#31216;&#20026;IGCS&#65292;&#25104;&#26412;&#20026;$\mathcal{O}(nd)$&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#22312;&#32477;&#22823;&#22810;&#25968;&#30456;&#20851;&#21333;&#20803;&#30340;&#31435;&#26041;&#20307;&#19978;&#65292;IGCS&#20540;&#20989;&#25968;&#25509;&#36817;&#22810;&#32447;&#24615;&#20989;&#25968;&#65292;&#20854;&#20013;IGCS&#21305;&#37197;CS&#12290;IGCS&#30340;&#21478;&#19968;&#20010;&#22909;&#22788;&#26159;&#23427;&#20801;&#35768;&#20351;&#29992;&#20108;&#20803;&#39044;&#27979;&#22120;&#36827;&#34892;IG&#26041;&#27861;&#12290;&#25105;&#20204;&#20351;&#29992;&#19968;&#20123;&#38754;&#31215;...
&lt;/p&gt;
&lt;p&gt;
A model-agnostic variable importance method can be used with arbitrary prediction functions. Here we present some model-free methods that do not require access to the prediction function. This is useful when that function is proprietary and not available, or just extremely expensive. It is also useful when studying residuals from a model. The cohort Shapley (CS) method is model-free but has exponential cost in the dimension of the input space. A supervised on-manifold Shapley method from Frye et al. (2020) is also model free but requires as input a second black box model that has to be trained for the Shapley value problem. We introduce an integrated gradient (IG) version of cohort Shapley, called IGCS, with cost $\mathcal{O}(nd)$. We show that over the vast majority of the relevant unit cube that the IGCS value function is close to a multilinear function for which IGCS matches CS. Another benefit of IGCS is that is allows IG methods to be used with binary predictors. We use some area 
&lt;/p&gt;</description></item><item><title>&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#33021;&#22815;&#20998;&#26512;&#22797;&#26434;&#33258;&#28982;&#36807;&#31243;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65292;&#25918;&#26494;&#20102;&#20256;&#32479;&#31616;&#21270;&#20551;&#35774;&#30340;&#38480;&#21046;&#65292;&#20855;&#22791;&#21487;&#35299;&#37322;&#24615;&#21644;&#28789;&#27963;&#30340;&#20989;&#25968;&#36924;&#36817;&#33021;&#21147;&#65292;&#33021;&#22815;&#24212;&#29992;&#20110;&#20154;&#31867;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#65292;&#25913;&#36827;&#25968;&#25454;&#35299;&#37322;&#21147;&#21644;&#25506;&#32034;&#24615;&#20998;&#26512;&#33021;&#21147;&#12290;</title><link>http://arxiv.org/abs/2209.12128</link><description>&lt;p&gt;
&#19968;&#31181;&#20998;&#26512;&#36830;&#32493;&#26102;&#38388;&#31995;&#32479;&#30340;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A Deep Learning Approach to Analyzing Continuous-Time Systems. (arXiv:2209.12128v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.12128
&lt;/p&gt;
&lt;p&gt;
&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#33021;&#22815;&#20998;&#26512;&#22797;&#26434;&#33258;&#28982;&#36807;&#31243;&#30340;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#65292;&#25918;&#26494;&#20102;&#20256;&#32479;&#31616;&#21270;&#20551;&#35774;&#30340;&#38480;&#21046;&#65292;&#20855;&#22791;&#21487;&#35299;&#37322;&#24615;&#21644;&#28789;&#27963;&#30340;&#20989;&#25968;&#36924;&#36817;&#33021;&#21147;&#65292;&#33021;&#22815;&#24212;&#29992;&#20110;&#20154;&#31867;&#35821;&#35328;&#22788;&#29702;&#39046;&#22495;&#65292;&#25913;&#36827;&#25968;&#25454;&#35299;&#37322;&#21147;&#21644;&#25506;&#32034;&#24615;&#20998;&#26512;&#33021;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#31185;&#23398;&#23478;&#36890;&#24120;&#20351;&#29992;&#26102;&#38388;&#24207;&#21015;&#25968;&#25454;&#26469;&#30740;&#31350;&#22797;&#26434;&#30340;&#33258;&#28982;&#36807;&#31243;&#65292;&#20294;&#22238;&#24402;&#20998;&#26512;&#24120;&#24120;&#20551;&#35774;&#36807;&#20110;&#31616;&#21333;&#21270;&#30340;&#21160;&#21147;&#23398;&#12290;&#28145;&#24230;&#23398;&#20064;&#30340;&#26368;&#36817;&#36827;&#23637;&#65292;&#22312;&#22797;&#26434;&#36807;&#31243;&#27169;&#22411;&#30340;&#24615;&#33021;&#19978;&#21462;&#24471;&#20102;&#24778;&#20154;&#30340;&#25552;&#39640;&#65292;&#20294;&#28145;&#24230;&#23398;&#20064;&#36890;&#24120;&#19981;&#29992;&#20110;&#31185;&#23398;&#20998;&#26512;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#28145;&#24230;&#23398;&#20064;&#21487;&#20197;&#29992;&#20110;&#20998;&#26512;&#22797;&#26434;&#30340;&#36807;&#31243;&#65292;&#25552;&#20379;&#28789;&#27963;&#30340;&#20989;&#25968;&#36924;&#36817;&#24182;&#20855;&#26377;&#21487;&#35299;&#37322;&#24615;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#25918;&#26494;&#20102;&#20256;&#32479;&#31616;&#21270;&#20551;&#35774;&#65288;&#22914;&#32447;&#24615;&#12289;&#24179;&#31283;&#21644;&#21516;&#26041;&#24046;&#24615;&#65289;&#65292;&#36825;&#20123;&#20551;&#35774;&#23545;&#35768;&#22810;&#33258;&#28982;&#31995;&#32479;&#32780;&#35328;&#26159;&#19981;&#21487;&#34892;&#30340;&#65292;&#21487;&#33021;&#20250;&#20005;&#37325;&#24433;&#21709;&#25968;&#25454;&#30340;&#35299;&#37322;&#12290;&#25105;&#20204;&#22312;&#20154;&#31867;&#35821;&#35328;&#22788;&#29702;&#26041;&#38754;&#36827;&#34892;&#20102;&#27169;&#22411;&#35780;&#20272;&#65292;&#36825;&#26159;&#19968;&#20010;&#20855;&#26377;&#22797;&#26434;&#36830;&#32493;&#21160;&#21147;&#23398;&#30340;&#39046;&#22495;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#22312;&#34892;&#20026;&#21644;&#31070;&#32463;&#24433;&#20687;&#25968;&#25454;&#19978;&#26377;&#26174;&#33879;&#30340;&#25913;&#36827;&#65292;&#24182;&#19988;&#25105;&#20204;&#23637;&#31034;&#20102;&#25105;&#20204;&#30340;&#27169;&#22411;&#21487;&#20197;&#22312;&#25511;&#21046;&#22810;&#31181;&#28151;&#26434;&#23454;&#39564;&#35774;&#32622;&#30340;&#28151;&#26434;&#22240;&#32032;&#21644;&#32570;&#22833;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#65292;&#21457;&#29616;&#25506;&#32034;&#24615;&#20998;&#26512;&#20013;&#30340;&#26032;&#27169;&#24335;&#12290;
&lt;/p&gt;
&lt;p&gt;
Scientists often use observational time series data to study complex natural processes, but regression analyses often assume simplistic dynamics. Recent advances in deep learning have yielded startling improvements to the performance of models of complex processes, but deep learning is generally not used for scientific analysis. Here we show that deep learning can be used to analyze complex processes, providing flexible function approximation while preserving interpretability. Our approach relaxes standard simplifying assumptions (e.g., linearity, stationarity, and homoscedasticity) that are implausible for many natural systems and may critically affect the interpretation of data. We evaluate our model on incremental human language processing, a domain with complex continuous dynamics. We demonstrate substantial improvements on behavioral and neuroimaging data, and we show that our model enables discovery of novel patterns in exploratory analyses, controls for diverse confounds in conf
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35782;&#21035;&#21442;&#25968;&#27169;&#22411;&#30340;&#27010;&#29575;&#26080;&#30417;&#30563;&#23398;&#20064;&#26032;&#26041;&#27861;&#65292;&#21487;&#20197;&#28789;&#27963;&#22320;&#23398;&#20064;&#35782;&#21035;&#27169;&#22411;&#65292;&#25429;&#25417;&#35266;&#27979;&#20043;&#38388;&#30340;&#28508;&#22312;&#30456;&#20851;&#24615;&#65292;&#20026;&#22270;&#20687;&#20998;&#31867;&#21644;&#28508;&#22312;&#20998;&#37197;&#38382;&#39064;&#25552;&#20379;&#20102;&#26377;&#25928;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2209.05661</link><description>&lt;p&gt;
&#26080;&#30417;&#30563;&#34920;&#24449;&#23398;&#20064;&#20013;&#30340;&#35782;&#21035;&#21442;&#25968;&#27010;&#29575;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Unsupervised representation learning with recognition-parametrised probabilistic models. (arXiv:2209.05661v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.05661
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35782;&#21035;&#21442;&#25968;&#27169;&#22411;&#30340;&#27010;&#29575;&#26080;&#30417;&#30563;&#23398;&#20064;&#26032;&#26041;&#27861;&#65292;&#21487;&#20197;&#28789;&#27963;&#22320;&#23398;&#20064;&#35782;&#21035;&#27169;&#22411;&#65292;&#25429;&#25417;&#35266;&#27979;&#20043;&#38388;&#30340;&#28508;&#22312;&#30456;&#20851;&#24615;&#65292;&#20026;&#22270;&#20687;&#20998;&#31867;&#21644;&#28508;&#22312;&#20998;&#37197;&#38382;&#39064;&#25552;&#20379;&#20102;&#26377;&#25928;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#35782;&#21035;&#21442;&#25968;&#27169;&#22411;&#65288;RPM&#65289;&#30340;&#27010;&#29575;&#26080;&#30417;&#30563;&#23398;&#20064;&#26032;&#26041;&#27861;&#65306;&#20316;&#20026;&#20851;&#20110;&#35266;&#23519;&#21464;&#37327;&#21644;&#28508;&#22312;&#21464;&#37327;&#30340;&#32852;&#21512;&#20998;&#24067;&#30340;&#24402;&#19968;&#21270;&#21322;&#21442;&#25968;&#21270;&#20551;&#35774;&#31867;&#12290;&#22312;&#35266;&#23519;&#20540;&#22312;&#32473;&#23450;&#28508;&#22312;&#21464;&#37327;&#30340;&#26465;&#20214;&#19979;&#26159;&#26465;&#20214;&#29420;&#31435;&#30340;&#20851;&#38190;&#20551;&#35774;&#19979;&#65292;RPM&#23558;&#21442;&#25968;&#20808;&#39564;&#21644;&#35266;&#27979;&#26465;&#20214;&#19979;&#30340;&#28508;&#22312;&#20998;&#24067;&#19982;&#38750;&#21442;&#25968;&#35266;&#27979;&#36793;&#32536;&#30456;&#32467;&#21512;&#12290;&#35813;&#26041;&#27861;&#21487;&#20197;&#24471;&#21040;&#28789;&#27963;&#30340;&#23398;&#20064;&#35782;&#21035;&#27169;&#22411;&#65292;&#25429;&#25417;&#20102;&#35266;&#27979;&#20043;&#38388;&#30340;&#28508;&#22312;&#30456;&#20851;&#24615;&#65292;&#32780;&#19981;&#38656;&#35201;&#26174;&#24335;&#30340;&#21442;&#25968;&#29983;&#25104;&#27169;&#22411;&#12290;&#23545;&#20110;&#31163;&#25955;&#28508;&#21464;&#37327;&#65292;RPM&#20801;&#35768;&#36827;&#34892;&#31934;&#30830;&#30340;&#26368;&#22823;&#20284;&#28982;&#23398;&#20064;&#65292;&#21363;&#20351;&#26159;&#22522;&#20110;&#24378;&#22823;&#30340;&#31070;&#32463;&#32593;&#32476;&#35782;&#21035;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#36866;&#29992;&#20110;&#36830;&#32493;&#28508;&#21464;&#37327;&#24773;&#20917;&#30340;&#26377;&#25928;&#36817;&#20284;&#26041;&#27861;&#12290;&#23454;&#39564;&#23637;&#31034;&#20102;RPM&#22312;&#39640;&#32500;&#25968;&#25454;&#19978;&#30340;&#26377;&#25928;&#24615;&#65292;&#23398;&#20064;&#20174;&#24369;&#38388;&#25509;&#30417;&#30563;&#20013;&#30340;&#22270;&#20687;&#20998;&#31867;&#65307;&#30452;&#25509;&#22270;&#20687;&#32423;&#28508;&#22312;&#29380;&#21033;&#20811;&#38647;&#20998;&#37197;&#30340;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;
We introduce a new approach to probabilistic unsupervised learning based on the recognition-parametrised model (RPM): a normalised semi-parametric hypothesis class for joint distributions over observed and latent variables. Under the key assumption that observations are conditionally independent given latents, the RPM combines parametric prior and observation-conditioned latent distributions with non-parametric observation marginals. This approach leads to a flexible learnt recognition model capturing latent dependence between observations, without the need for an explicit, parametric generative model. The RPM admits exact maximum-likelihood learning for discrete latents, even for powerful neural-network-based recognition. We develop effective approximations applicable in the continuous-latent case. Experiments demonstrate the effectiveness of the RPM on high-dimensional data, learning image classification from weak indirect supervision; direct image-level latent Dirichlet allocation; 
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#30740;&#31350;&#20102; ELBO &#25910;&#25947;&#21040;&#29109;&#21644;&#30340;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#23545;&#20110;&#19968;&#31867;&#24191;&#27867;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;ELBO &#22312;&#25152;&#26377;&#23398;&#20064;&#30340;&#31283;&#23450;&#28857;&#22788;&#37117;&#31561;&#20110;&#19968;&#31995;&#21015;&#29109;&#30340;&#21644;&#65292;&#20026;&#26080;&#30417;&#30563;&#23398;&#20064;&#30340;&#23398;&#20064;&#31639;&#27861;&#30340;&#22522;&#26412;&#23646;&#24615;&#25552;&#20379;&#20102;&#28145;&#20837;&#30340;&#27934;&#23519;&#12290;</title><link>http://arxiv.org/abs/2209.03077</link><description>&lt;p&gt;
&#20851;&#20110;ELBO&#25910;&#25947;&#21040;&#29109;&#21644;&#30340;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
On the Convergence of the ELBO to Entropy Sums. (arXiv:2209.03077v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2209.03077
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102; ELBO &#25910;&#25947;&#21040;&#29109;&#21644;&#30340;&#38382;&#39064;&#65292;&#35777;&#26126;&#20102;&#23545;&#20110;&#19968;&#31867;&#24191;&#27867;&#30340;&#29983;&#25104;&#27169;&#22411;&#65292;ELBO &#22312;&#25152;&#26377;&#23398;&#20064;&#30340;&#31283;&#23450;&#28857;&#22788;&#37117;&#31561;&#20110;&#19968;&#31995;&#21015;&#29109;&#30340;&#21644;&#65292;&#20026;&#26080;&#30417;&#30563;&#23398;&#20064;&#30340;&#23398;&#20064;&#31639;&#27861;&#30340;&#22522;&#26412;&#23646;&#24615;&#25552;&#20379;&#20102;&#28145;&#20837;&#30340;&#27934;&#23519;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#19979;&#30028;&#65288;&#21448;&#31216;ELBO&#25110;&#33258;&#30001;&#33021;&#65289;&#26159;&#35768;&#22810;&#32463;&#20856;&#21644;&#26032;&#39062;&#30340;&#26080;&#30417;&#30563;&#23398;&#20064;&#31639;&#27861;&#30340;&#26680;&#24515;&#30446;&#26631;&#12290;&#23398;&#20064;&#31639;&#27861;&#21487;&#20197;&#25913;&#21464;&#27169;&#22411;&#21442;&#25968;&#65292;&#20351;&#21464;&#20998;&#19979;&#30028;&#22686;&#21152;&#12290;&#36890;&#24120;&#65292;&#23398;&#20064;&#36827;&#34892;&#21040;&#21442;&#25968;&#25910;&#25947;&#21040;&#25509;&#36817;&#23398;&#20064;&#21160;&#24577;&#30340;&#31283;&#23450;&#28857;&#20540;&#12290;&#22312;&#26412;&#25991;&#30340;&#29702;&#35770;&#36129;&#29486;&#20013;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#65288;&#23545;&#20110;&#19968;&#31867;&#38750;&#24120;&#24191;&#27867;&#30340;&#29983;&#25104;&#27169;&#22411;&#65289;&#65292;&#21464;&#20998;&#19979;&#30028;&#22312;&#25152;&#26377;&#23398;&#20064;&#30340;&#31283;&#23450;&#28857;&#22788;&#22343;&#31561;&#20110;&#19968;&#31995;&#21015;&#29109;&#30340;&#21644;&#12290;&#23545;&#20110;&#20855;&#26377;&#19968;&#32452;&#28508;&#22312;&#21464;&#37327;&#21644;&#19968;&#32452;&#35266;&#27979;&#21464;&#37327;&#30340;&#26631;&#20934;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#65292;&#36825;&#20010;&#21644;&#21253;&#25324;&#19977;&#20010;&#29109;: (A) &#21464;&#20998;&#20998;&#24067;&#30340;&#29109;&#65288;&#24179;&#22343;&#29109;&#65289;&#65292;(B) &#27169;&#22411;&#20808;&#39564;&#20998;&#24067;&#30340;&#36127;&#29109;&#21644; (C) &#21487;&#35266;&#27979;&#20998;&#24067;&#30340;&#65288;&#26399;&#26395;&#65289;&#36127;&#29109;&#12290;&#25152;&#24471;&#21040;&#30340;&#32467;&#26524;&#36866;&#29992;&#20110;&#21253;&#25324;&#65306;&#26377;&#38480;&#25968;&#37327;&#30340;&#25968;&#25454;&#28857;&#65292;&#22312;&#23398;&#20064;&#30340;&#20219;&#24847;&#38454;&#27573;&#21644;&#21508;&#31181;&#19981;&#21516;&#30340;&#29983;&#25104;&#27169;&#22411;&#31561;&#30495;&#23454;&#26465;&#20214;&#12290;&#26412;&#30740;&#31350;&#20026;&#26080;&#30417;&#30563;&#23398;&#20064;&#30340;&#23398;&#20064;&#31639;&#27861;&#30340;&#22522;&#26412;&#23646;&#24615;&#25552;&#20379;&#20102;&#28145;&#20837;&#27934;&#23519;&#65292;&#26159;&#23545;&#20248;&#21270;&#25512;&#29702;&#21644;&#23398;&#20064;&#30340;&#29702;&#35770;&#20998;&#26512;&#30340;&#31532;&#19968;&#27493;&#12290;
&lt;/p&gt;
&lt;p&gt;
The variational lower bound (a.k.a. ELBO or free energy) is the central objective for many established as well as many novel algorithms for unsupervised learning. Learning algorithms change model parameters such that the variational lower bound increases. Learning usually proceeds until parameters have converged to values close to a stationary point of the learning dynamics. In this purely theoretical contribution, we show that (for a very large class of generative models) the variational lower bound is at all stationary points of learning equal to a sum of entropies. For standard machine learning models with one set of latents and one set observed variables, the sum consists of three entropies: (A) the (average) entropy of the variational distributions, (B) the negative entropy of the model's prior distribution, and (C) the (expected) negative entropy of the observable distributions. The obtained result applies under realistic conditions including: finite numbers of data points, at an
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36830;&#32493;&#29983;&#25104;&#31070;&#32463;&#32593;&#32476;(CGNN)&#30340;&#27169;&#22411;&#65292;&#20351;&#29992;&#26465;&#20214;&#20445;&#35777;CGNN&#26159;&#21333;&#23556;&#30340;&#65292;&#20854;&#29983;&#25104;&#27969;&#24418;&#34987;&#29992;&#20110;&#27714;&#35299;&#21453;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#31283;&#20581;&#24615;&#12290;</title><link>http://arxiv.org/abs/2205.14627</link><description>&lt;p&gt;
&#36830;&#32493;&#29983;&#25104;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Continuous Generative Neural Networks. (arXiv:2205.14627v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.14627
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#36830;&#32493;&#29983;&#25104;&#31070;&#32463;&#32593;&#32476;(CGNN)&#30340;&#27169;&#22411;&#65292;&#20351;&#29992;&#26465;&#20214;&#20445;&#35777;CGNN&#26159;&#21333;&#23556;&#30340;&#65292;&#20854;&#29983;&#25104;&#27969;&#24418;&#34987;&#29992;&#20110;&#27714;&#35299;&#21453;&#38382;&#39064;&#65292;&#24182;&#35777;&#26126;&#20102;&#20854;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#21644;&#31283;&#20581;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#24182;&#30740;&#31350;&#20102;&#19968;&#31181;&#36830;&#32493;&#29983;&#25104;&#31070;&#32463;&#32593;&#32476;&#65288;CGNN&#65289;&#65292;&#21363;&#36830;&#32493;&#24773;&#22659;&#19979;&#30340;&#29983;&#25104;&#27169;&#22411;&#65306;CGNN&#30340;&#36755;&#20986;&#23646;&#20110;&#26080;&#38480;&#32500;&#20989;&#25968;&#31354;&#38388;&#12290;&#35813;&#26550;&#26500;&#21463;DCGAN&#30340;&#21551;&#21457;&#65292;&#37319;&#29992;&#19968;&#20010;&#20840;&#36830;&#25509;&#23618;&#65292;&#22810;&#20010;&#21367;&#31215;&#23618;&#21644;&#38750;&#32447;&#24615;&#28608;&#27963;&#20989;&#25968;&#12290;&#22312;&#36830;&#32493;&#30340;$L^2$&#24773;&#22659;&#19979;&#65292;&#27599;&#23618;&#31354;&#38388;&#30340;&#32500;&#24230;&#34987;&#32039;&#25903;&#23567;&#27874;&#30340;&#22810;&#37325;&#20998;&#36776;&#29575;&#20998;&#26512;&#30340;&#23610;&#24230;&#25152;&#20195;&#26367;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#20851;&#20110;&#21367;&#31215;&#28388;&#27874;&#22120;&#21644;&#38750;&#32447;&#24615;&#30340;&#26465;&#20214;&#65292;&#20445;&#35777;CGNN&#26159;&#21333;&#23556;&#30340;&#12290;&#35813;&#29702;&#35770;&#24212;&#29992;&#20110;&#21453;&#38382;&#39064;&#65292;&#24182;&#20801;&#35768;&#23548;&#20986;&#19968;&#20010;CGNN&#29983;&#25104;&#27969;&#24418;&#30340;&#65288;&#21487;&#33021;&#38750;&#32447;&#24615;&#30340;&#65289;&#26080;&#38480;&#32500;&#21453;&#38382;&#39064;&#30340;Lipschitz&#31283;&#23450;&#24615;&#20272;&#35745;&#12290;&#21253;&#25324;&#20449;&#21495;&#21435;&#27169;&#31946;&#22312;&#20869;&#30340;&#22810;&#20010;&#25968;&#20540;&#27169;&#25311;&#35777;&#26126;&#24182;&#39564;&#35777;&#20102;&#36825;&#19968;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we present and study Continuous Generative Neural Networks (CGNNs), namely, generative models in the continuous setting: the output of a CGNN belongs to an infinite-dimensional function space. The architecture is inspired by DCGAN, with one fully connected layer, several convolutional layers and nonlinear activation functions. In the continuous $L^2$ setting, the dimensions of the spaces of each layer are replaced by the scales of a multiresolution analysis of a compactly supported wavelet. We present conditions on the convolutional filters and on the nonlinearity that guarantee that a CGNN is injective. This theory finds applications to inverse problems, and allows for deriving Lipschitz stability estimates for (possibly nonlinear) infinite-dimensional inverse problems with unknowns belonging to the manifold generated by a CGNN. Several numerical simulations, including signal deblurring, illustrate and validate this approach.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32473;&#20986;&#20102;&#31532;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#65292;&#33021;&#22312;&#36866;&#24230;&#25968;&#37327;&#30340;&#32422;&#26463;&#19979;&#20351;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#36867;&#33073;&#39640;&#32500;&#39532;&#38797;&#28857;&#12290;</title><link>http://arxiv.org/abs/2205.13753</link><description>&lt;p&gt;
HOUDINI: &#20174;&#36866;&#24230;&#32422;&#26463;&#30340;&#39532;&#38797;&#28857;&#20013;&#36867;&#33073;
&lt;/p&gt;
&lt;p&gt;
HOUDINI: Escaping from Moderately Constrained Saddles. (arXiv:2205.13753v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.13753
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32473;&#20986;&#20102;&#31532;&#19968;&#20010;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#65292;&#33021;&#22312;&#36866;&#24230;&#25968;&#37327;&#30340;&#32422;&#26463;&#19979;&#20351;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#36867;&#33073;&#39640;&#32500;&#39532;&#38797;&#28857;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32473;&#20986;&#20102;&#31532;&#19968;&#20010;&#22312;&#36866;&#24230;&#25968;&#37327;&#30340;&#32422;&#26463;&#19979;&#20174;&#39640;&#32500;&#39532;&#38797;&#28857;&#20013;&#36867;&#33073;&#30340;&#22810;&#39033;&#24335;&#26102;&#38388;&#31639;&#27861;&#12290;&#32473;&#23450;&#20809;&#28369;&#20989;&#25968;$f \colon \mathbb R^d \to \mathbb R$&#30340;&#26799;&#24230;&#35775;&#38382;&#26435;&#38480;&#65292;&#25105;&#20204;&#23637;&#31034;&#20102;&#65288;&#24102;&#22122;&#22768;&#30340;&#65289;&#26799;&#24230;&#19979;&#38477;&#26041;&#27861;&#21487;&#20197;&#22312;&#23545;&#25968;&#20010;&#19981;&#31561;&#24335;&#32422;&#26463;&#19979;&#36867;&#33073;&#39532;&#38797;&#28857;&#12290;&#36825;&#26159;&#23545; Ge &#31561;&#20154;&#30340;&#31361;&#30772;&#24615;&#24037;&#20316;&#30340;&#20027;&#35201;&#24320;&#25918;&#38382;&#39064;&#30340;&#39318;&#27425;&#26377;&#24418;&#36827;&#23637;&#65288;&#26080;&#38656;&#20381;&#36182; NP-Oracle &#25110;&#25913;&#21464;&#23450;&#20041;&#26469;&#20165;&#32771;&#34385;&#29305;&#23450;&#32422;&#26463;&#65289;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#36866;&#29992;&#20110;&#27491;&#21017;&#26799;&#24230;&#19979;&#38477;&#21644;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#12290;
&lt;/p&gt;
&lt;p&gt;
We give the first polynomial time algorithms for escaping from high-dimensional saddle points under a moderate number of constraints. Given gradient access to a smooth function $f \colon \mathbb R^d \to \mathbb R$ we show that (noisy) gradient descent methods can escape from saddle points under a logarithmic number of inequality constraints. This constitutes the first tangible progress (without reliance on NP-oracles or altering the definitions to only account for certain constraints) on the main open question of the breakthrough work of Ge et al. who showed an analogous result for unconstrained and equality-constrained problems. Our results hold for both regular and stochastic gradient descent.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36890;&#20449;&#25928;&#29575;&#39640;&#30340;&#33258;&#36866;&#24212;&#32852;&#37030;&#23398;&#20064;&#26041;&#27861;&#65288;FedCAMS&#65289;&#65292;&#21487;&#20197;&#35299;&#20915;&#32852;&#37030;&#23398;&#20064;&#20013;&#30001;&#20110;&#37325;&#22797;&#30340;&#26381;&#21153;&#22120;-&#23458;&#25143;&#31471;&#21516;&#27493;&#32780;&#20135;&#29983;&#30340;&#22823;&#37327;&#36890;&#20449;&#24320;&#38144;&#21644;&#22522;&#20110; SGD &#30340;&#27169;&#22411;&#26356;&#26032;&#32570;&#20047;&#36866;&#24212;&#24615;&#31561;&#35832;&#22810;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2205.02719</link><description>&lt;p&gt;
&#36890;&#20449;&#25928;&#29575;&#39640;&#30340;&#33258;&#36866;&#24212;&#32852;&#37030;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Communication-Efficient Adaptive Federated Learning. (arXiv:2205.02719v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.02719
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36890;&#20449;&#25928;&#29575;&#39640;&#30340;&#33258;&#36866;&#24212;&#32852;&#37030;&#23398;&#20064;&#26041;&#27861;&#65288;FedCAMS&#65289;&#65292;&#21487;&#20197;&#35299;&#20915;&#32852;&#37030;&#23398;&#20064;&#20013;&#30001;&#20110;&#37325;&#22797;&#30340;&#26381;&#21153;&#22120;-&#23458;&#25143;&#31471;&#21516;&#27493;&#32780;&#20135;&#29983;&#30340;&#22823;&#37327;&#36890;&#20449;&#24320;&#38144;&#21644;&#22522;&#20110; SGD &#30340;&#27169;&#22411;&#26356;&#26032;&#32570;&#20047;&#36866;&#24212;&#24615;&#31561;&#35832;&#22810;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#26159;&#19968;&#31181;&#26426;&#22120;&#23398;&#20064;&#35757;&#32451;&#26041;&#24335;&#65292;&#20351;&#24471;&#23458;&#25143;&#31471;&#21487;&#20197;&#22312;&#19981;&#20849;&#20139;&#26412;&#22320;&#25968;&#25454;&#30340;&#24773;&#20917;&#19979;&#20849;&#21516;&#35757;&#32451;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#23454;&#38469;&#20013;&#23454;&#29616;&#32852;&#37030;&#23398;&#20064;&#20173;&#38754;&#20020;&#35768;&#22810;&#25361;&#25112;&#65292;&#22914;&#30001;&#20110;&#37325;&#22797;&#30340;&#26381;&#21153;&#22120;-&#23458;&#25143;&#31471;&#21516;&#27493;&#32780;&#20135;&#29983;&#30340;&#22823;&#37327;&#36890;&#20449;&#24320;&#38144;&#20197;&#21450;&#22522;&#20110; SGD &#30340;&#27169;&#22411;&#26356;&#26032;&#32570;&#20047;&#36866;&#24212;&#24615;&#12290;&#23613;&#31649;&#24050;&#32463;&#25552;&#20986;&#20102;&#21508;&#31181;&#26041;&#27861;&#26469;&#36890;&#36807;&#26799;&#24230;&#21387;&#32553;&#25110;&#37327;&#21270;&#26469;&#20943;&#23569;&#36890;&#20449;&#25104;&#26412;&#65292;&#24182;&#25552;&#20986;&#20102;FedAdam&#31561;&#32852;&#37030;&#29256;&#26412;&#30340;&#33258;&#36866;&#24212;&#20248;&#21270;&#22120;&#26469;&#22686;&#21152;&#26356;&#22810;&#30340;&#36866;&#24212;&#24615;&#65292;&#20294;&#24403;&#21069;&#30340;&#32852;&#37030;&#23398;&#20064;&#26694;&#26550;&#20173;&#26080;&#27861;&#21516;&#26102;&#35299;&#20915;&#19978;&#36848;&#25152;&#26377;&#25361;&#25112;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36890;&#20449;&#25928;&#29575;&#39640;&#30340;&#33258;&#36866;&#24212;&#32852;&#37030;&#23398;&#20064;&#26041;&#27861;&#65288;FedCAMS&#65289;&#65292;&#20855;&#26377;&#29702;&#35770;&#19978;&#30340;&#25910;&#25947;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated learning is a machine learning training paradigm that enables clients to jointly train models without sharing their own localized data. However, the implementation of federated learning in practice still faces numerous challenges, such as the large communication overhead due to the repetitive server-client synchronization and the lack of adaptivity by SGD-based model updates. Despite that various methods have been proposed for reducing the communication cost by gradient compression or quantization, and the federated versions of adaptive optimizers such as FedAdam are proposed to add more adaptivity, the current federated learning framework still cannot solve the aforementioned challenges all at once. In this paper, we propose a novel communication-efficient adaptive federated learning method (FedCAMS) with theoretical convergence guarantees. We show that in the nonconvex stochastic optimization setting, our proposed FedCAMS achieves the same convergence rate of $O(\frac{1}{\s
&lt;/p&gt;</description></item><item><title>&#25991;&#31456;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31215;&#20998;&#27010;&#29575;&#24230;&#37327;&#30340;&#20004;&#26679;&#26412;&#26816;&#39564;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#20302;&#32500;&#27969;&#24418;&#19978;&#25903;&#25345;&#30340;&#39640;&#32500;&#26679;&#26412;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#32479;&#35745;&#21151;&#29575;&#26041;&#38754;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2205.02043</link><description>&lt;p&gt;
&#27969;&#24418;&#20004;&#26679;&#26412;&#26816;&#39564;&#30740;&#31350;&#65306;&#31070;&#32463;&#32593;&#32476;&#30340;&#31215;&#20998;&#27010;&#29575;&#24230;&#37327;
&lt;/p&gt;
&lt;p&gt;
A Manifold Two-Sample Test Study: Integral Probability Metric with Neural Networks. (arXiv:2205.02043v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.02043
&lt;/p&gt;
&lt;p&gt;
&#25991;&#31456;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31215;&#20998;&#27010;&#29575;&#24230;&#37327;&#30340;&#20004;&#26679;&#26412;&#26816;&#39564;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#20302;&#32500;&#27969;&#24418;&#19978;&#25903;&#25345;&#30340;&#39640;&#32500;&#26679;&#26412;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25152;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#32479;&#35745;&#21151;&#29575;&#26041;&#38754;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20004;&#26679;&#26412;&#26816;&#39564;&#26159;&#19968;&#31181;&#37325;&#35201;&#30340;&#26041;&#27861;&#65292;&#26088;&#22312;&#30830;&#23450;&#20004;&#20010;&#35266;&#27979;&#38598;&#21512;&#26159;&#21542;&#36981;&#24490;&#30456;&#21516;&#30340;&#20998;&#24067;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#31215;&#20998;&#27010;&#29575;&#24230;&#37327;&#65288;IPM&#65289;&#30340;&#20004;&#26679;&#26412;&#26816;&#39564;&#65292;&#36866;&#29992;&#20110;&#20302;&#32500;&#27969;&#24418;&#19978;&#25903;&#25345;&#30340;&#39640;&#32500;&#26679;&#26412;&#12290;&#25105;&#20204;&#36890;&#36807;&#26679;&#26412;&#25968;$n$&#21644;&#27969;&#24418;&#20869;&#22312;&#32500;&#24230;$d$&#30340;&#32467;&#26500;&#34920;&#24449;&#20102;&#25152;&#25552;&#20986;&#30340;&#26816;&#39564;&#30340;&#29305;&#24615;&#12290;&#24403;&#32473;&#23450;&#19968;&#20010;&#22270;&#38598;&#26102;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#20004;&#27493;&#26816;&#39564;&#20197;&#35782;&#21035;&#19968;&#33324;&#20998;&#24067;&#20043;&#38388;&#30340;&#24046;&#24322;&#65292;&#20854;&#22312;$n^{-1/\max\{d,2\}}$&#30340;&#39034;&#24207;&#20013;&#23454;&#29616;&#20102;&#31532;&#20108;&#31867;&#22411;&#39118;&#38505;&#12290;&#24403;&#26410;&#32473;&#20986;&#22270;&#38598;&#26102;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;H\"older IPM&#26816;&#39564;&#65292;&#36866;&#29992;&#20110;&#20855;&#26377;$(s,\beta)$&#8208;H\"older&#23494;&#24230;&#30340;&#25968;&#25454;&#20998;&#24067;&#65292;&#20854;&#22312;$n^{-(s+\beta)/d}$&#30340;&#39034;&#24207;&#20013;&#23454;&#29616;&#20102;&#31532;&#20108;&#31867;&#22411;&#39118;&#38505;&#12290;&#20026;&#20102;&#20943;&#36731;&#35780;&#20272;H\"older IPM&#30340;&#37325;&#35745;&#31639;&#36127;&#25285;&#65292;&#25105;&#20204;&#20351;&#29992;&#31070;&#32463;&#32593;&#32476;&#26469;&#36924;&#36817;H\"older&#20989;&#25968;&#31867;&#12290;&#22522;&#20110;&#31070;&#32463;&#32593;&#32476;&#30340;&#36924;&#36817;&#29702;&#35770;&#65292;&#25105;&#20204;&#21487;&#20197;&#35777;&#26126;&#25152;&#25552;&#20986;&#30340;&#31070;&#32463;&#32593;&#32476;H\"older IPM&#27979;&#35797;&#20855;&#26377;&#19968;&#33268;&#30340;&#25928;&#29575;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#25552;&#20986;&#30340;&#26041;&#27861;&#22312;&#32479;&#35745;&#21151;&#29575;&#26041;&#38754;&#20248;&#20110;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Two-sample tests are important areas aiming to determine whether two collections of observations follow the same distribution or not. We propose two-sample tests based on integral probability metric (IPM) for high-dimensional samples supported on a low-dimensional manifold. We characterize the properties of proposed tests with respect to the number of samples $n$ and the structure of the manifold with intrinsic dimension $d$. When an atlas is given, we propose two-step test to identify the difference between general distributions, which achieves the type-II risk in the order of $n^{-1/\max\{d,2\}}$. When an atlas is not given, we propose H\"older IPM test that applies for data distributions with $(s,\beta)$-H\"older densities, which achieves the type-II risk in the order of $n^{-(s+\beta)/d}$. To mitigate the heavy computation burden of evaluating the H\"older IPM, we approximate the H\"older function class using neural networks. Based on the approximation theory of neural networks, we
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992;&#26680;&#26041;&#27861;&#26500;&#36896;&#19981;&#30830;&#23450;&#24615;&#38598;&#65292;&#22312;&#36125;&#21494;&#26031;&#35774;&#32622;&#21644;Neyman-Pearson&#35774;&#32622;&#20013;&#20998;&#21035;&#30740;&#31350;&#20102;&#26368;&#23567;&#21270;&#26368;&#22351;&#24773;&#20917;&#19979;&#38169;&#35823;&#27010;&#29575;&#21644;&#25511;&#21046;&#38169;&#35823;&#27010;&#29575;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;MMD&#30340;&#19968;&#31995;&#21015;&#27979;&#35797;&#12290;</title><link>http://arxiv.org/abs/2203.12777</link><description>&lt;p&gt;
&#26680;&#40065;&#26834;&#20551;&#35774;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Kernel Robust Hypothesis Testing. (arXiv:2203.12777v2 [eess.SP] CROSS LISTED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2203.12777
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#26680;&#26041;&#27861;&#26500;&#36896;&#19981;&#30830;&#23450;&#24615;&#38598;&#65292;&#22312;&#36125;&#21494;&#26031;&#35774;&#32622;&#21644;Neyman-Pearson&#35774;&#32622;&#20013;&#20998;&#21035;&#30740;&#31350;&#20102;&#26368;&#23567;&#21270;&#26368;&#22351;&#24773;&#20917;&#19979;&#38169;&#35823;&#27010;&#29575;&#21644;&#25511;&#21046;&#38169;&#35823;&#27010;&#29575;&#30340;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#20102;&#22522;&#20110;MMD&#30340;&#19968;&#31995;&#21015;&#27979;&#35797;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#30740;&#31350;&#20102;&#40065;&#26834;&#20551;&#35774;&#26816;&#39564;&#38382;&#39064;&#65292;&#22312;&#38646;&#20551;&#35774;&#21644;&#22791;&#25321;&#20551;&#35774;&#19979;&#65292;&#25968;&#25454;&#29983;&#25104;&#20998;&#24067;&#34987;&#20551;&#35774;&#22312;&#26576;&#20123;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#20013;&#65292;&#24182;&#26088;&#22312;&#35774;&#35745;&#19968;&#31181;&#27979;&#35797;&#65292;&#22312;&#19981;&#30830;&#23450;&#24615;&#38598;&#21512;&#20013;&#34920;&#29616;&#26368;&#20248;&#12290;&#26412;&#25991;&#23558;&#20351;&#29992;&#26680;&#26041;&#27861;&#20197;&#25968;&#25454;&#39537;&#21160;&#30340;&#26041;&#24335;&#26500;&#36896;&#19981;&#30830;&#23450;&#24615;&#38598;&#65292;&#21363;&#20197;&#26469;&#33258;&#38646;&#20551;&#35774;&#21644;&#22791;&#25321;&#20551;&#35774;&#30340;&#35757;&#32451;&#26679;&#26412;&#30340;&#32463;&#39564;&#20998;&#24067;&#20026;&#20013;&#24515;&#65292;&#24182;&#36890;&#36807;&#26680;&#22343;&#20540;&#23884;&#20837;&#30340;&#36317;&#31163;&#26469;&#32422;&#26463;&#65292;&#21363;&#26368;&#22823;&#24179;&#22343;&#24046;&#24322;&#65288;MMD&#65289;&#12290;&#21516;&#26102;&#65292;&#26412;&#25991;&#36824;&#30740;&#31350;&#20102;&#36125;&#21494;&#26031;&#35774;&#32622;&#21644;Neyman-Pearson&#35774;&#32622;&#12290;&#23545;&#20110;&#36125;&#21494;&#26031;&#35774;&#32622;&#65292;&#21363;&#30446;&#26631;&#26159;&#26368;&#23567;&#21270;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#38169;&#35823;&#27010;&#29575;&#65292;&#24403;&#23383;&#27597;&#34920;&#26159;&#26377;&#38480;&#30340;&#26102;&#65292;&#39318;&#20808;&#24471;&#21040;&#20102;&#26368;&#20339;&#27979;&#35797;&#12290;&#24403;&#23383;&#27597;&#34920;&#26159;&#26080;&#38480;&#30340;&#26102;&#65292;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#34892;&#30340;&#36817;&#20284;&#26041;&#27861;&#26469;&#37327;&#21270;&#26368;&#22351;&#24773;&#20917;&#19979;&#30340;&#38169;&#35823;&#27010;&#29575;&#12290;&#23545;&#20110;Neyman-Pearson&#35774;&#32622;&#65292;&#21363;&#30446;&#26631;&#26159;&#22312;&#26368;&#23567;&#21270;&#31532;&#20108;&#31867;&#38169;&#35823;&#27010;&#29575;&#30340;&#21516;&#26102;&#25511;&#21046;&#22312;&#32473;&#23450;&#27700;&#24179;&#19979;&#30340;&#31532;&#19968;&#31867;&#38169;&#35823;&#27010;&#29575;&#65292;&#25552;&#20986;&#20102;&#19968;&#31995;&#21015;&#22522;&#20110;MMD&#30340;&#27979;&#35797;&#65292;&#24182;&#30740;&#31350;&#20102;&#23427;&#20204;&#30340;&#28176;&#36817;&#29305;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The problem of robust hypothesis testing is studied, where under the null and the alternative hypotheses, the data-generating distributions are assumed to be in some uncertainty sets, and the goal is to design a test that performs well under the worst-case distributions over the uncertainty sets. In this paper, uncertainty sets are constructed in a data-driven manner using kernel method, i.e., they are centered around empirical distributions of training samples from the null and alternative hypotheses, respectively; and are constrained via the distance between kernel mean embeddings of distributions in the reproducing kernel Hilbert space, i.e., maximum mean discrepancy (MMD). The Bayesian setting and the Neyman-Pearson setting are investigated. For the Bayesian setting where the goal is to minimize the worst-case error probability, an optimal test is firstly obtained when the alphabet is finite. When the alphabet is infinite, a tractable approximation is proposed to quantify the worst
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#30340;&#21098;&#20999;Gossip&#31639;&#27861;&#26159;&#31532;&#19968;&#20010;&#33021;&#22815;&#22312;&#26631;&#20934;&#20551;&#35774;&#19979;&#35777;&#26126;&#25910;&#25947;&#21040;&#38750;&#20984;&#30446;&#26631;&#30340;$O(\delta_{max} \zeta^2 /\gamma^2)$&#37051;&#22495;&#30340;&#31639;&#27861;&#65292;&#24182;&#22312;&#22823;&#37327;&#25915;&#20987;&#19979;&#34920;&#29616;&#33391;&#22909;&#12290;</title><link>http://arxiv.org/abs/2202.01545</link><description>&lt;p&gt;
&#21098;&#20999;Gossip&#22312;&#25308;&#21344;&#24237;&#40065;&#26834;&#30340;&#20998;&#25955;&#24335;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Byzantine-Robust Decentralized Learning via ClippedGossip. (arXiv:2202.01545v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.01545
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#30340;&#21098;&#20999;Gossip&#31639;&#27861;&#26159;&#31532;&#19968;&#20010;&#33021;&#22815;&#22312;&#26631;&#20934;&#20551;&#35774;&#19979;&#35777;&#26126;&#25910;&#25947;&#21040;&#38750;&#20984;&#30446;&#26631;&#30340;$O(\delta_{max} \zeta^2 /\gamma^2)$&#37051;&#22495;&#30340;&#31639;&#27861;&#65292;&#24182;&#22312;&#22823;&#37327;&#25915;&#20987;&#19979;&#34920;&#29616;&#33391;&#22909;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#20219;&#24847;&#36890;&#20449;&#22270;&#19978;&#36827;&#34892;&#25308;&#21344;&#24237;&#40065;&#26834;&#30340;&#20998;&#25955;&#24335;&#35757;&#32451;&#30340;&#33392;&#24040;&#20219;&#21153;&#12290;&#19982;&#32852;&#37030;&#23398;&#20064;&#36890;&#36807;&#26381;&#21153;&#22120;&#36827;&#34892;&#36890;&#20449;&#30340;&#26041;&#24335;&#19981;&#21516;&#65292;&#20998;&#25955;&#24335;&#29615;&#22659;&#20013;&#30340;workers&#21482;&#33021;&#19982;&#23427;&#20204;&#30340;&#37051;&#23621;&#20132;&#27969;&#65292;&#36825;&#20351;&#24471;&#36798;&#25104;&#20849;&#35782;&#21644;&#21327;&#20316;&#35757;&#32451;&#26356;&#21152;&#22256;&#38590;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#29992;&#20110;&#25308;&#21344;&#24237;&#40065;&#26834;&#20849;&#35782;&#21644;&#20248;&#21270;&#30340;&#21098;&#20999;Gossip&#31639;&#27861;&#65292;&#23427;&#26159;&#31532;&#19968;&#20010;&#22312;&#26631;&#20934;&#20551;&#35774;&#19979;&#21487;&#20197;&#35777;&#26126;&#25910;&#25947;&#21040;&#38750;&#20984;&#30446;&#26631;&#30340;$O(\delta_{max} \zeta^2 /\gamma^2)$&#37051;&#22495;&#30340;&#31639;&#27861;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#22312;&#22823;&#37327;&#25915;&#20987;&#19979;&#35777;&#26126;&#20102;&#21098;&#20999;Gossip&#30340;&#40723;&#33310;&#20154;&#24515;&#30340;&#23454;&#35777;&#34920;&#29616;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we study the challenging task of Byzantine-robust decentralized training on arbitrary communication graphs. Unlike federated learning where workers communicate through a server, workers in the decentralized environment can only talk to their neighbors, making it harder to reach consensus and benefit from collaborative training. To address these issues, we propose a ClippedGossip algorithm for Byzantine-robust consensus and optimization, which is the first to provably converge to a $O(\delta_{\max}\zeta^2/\gamma^2)$ neighborhood of the stationary point for non-convex objectives under standard assumptions. Finally, we demonstrate the encouraging empirical performance of ClippedGossip under a large number of attacks.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#36793;&#30028;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;BGNNs&#65289;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#34920;&#31034;&#19977;&#32500;&#39063;&#31890;&#27969;&#21160;&#30340;&#22797;&#26434;&#20960;&#20309;&#24418;&#29366;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#39044;&#27979;&#21644;&#35745;&#31639;&#12290;</title><link>http://arxiv.org/abs/2106.11299</link><description>&lt;p&gt;
&#36793;&#30028;&#22270;&#31070;&#32463;&#32593;&#32476;&#29992;&#20110; 3D &#27169;&#25311;
&lt;/p&gt;
&lt;p&gt;
Boundary Graph Neural Networks for 3D Simulations. (arXiv:2106.11299v7 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.11299
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#36793;&#30028;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;BGNNs&#65289;&#65292;&#33021;&#22815;&#26377;&#25928;&#22320;&#34920;&#31034;&#19977;&#32500;&#39063;&#31890;&#27969;&#21160;&#30340;&#22797;&#26434;&#20960;&#20309;&#24418;&#29366;&#65292;&#20174;&#32780;&#23454;&#29616;&#20102;&#39640;&#25928;&#30340;&#39044;&#27979;&#21644;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22823;&#37327;&#25968;&#25454;&#30340;&#20986;&#29616;&#20351;&#24471;&#26426;&#22120;&#23398;&#20064;&#22312;&#33258;&#28982;&#31185;&#23398;&#21644;&#24037;&#31243;&#23398;&#26041;&#38754;&#20855;&#26377;&#20102;&#21487;&#35266;&#30340;&#21160;&#21147;&#65292;&#28982;&#32780;&#23545;&#29289;&#29702;&#36807;&#31243;&#36827;&#34892;&#24314;&#27169;&#36890;&#24120;&#24456;&#22256;&#38590;&#12290;&#20854;&#20013;&#19968;&#20010;&#29305;&#21035;&#26840;&#25163;&#30340;&#38382;&#39064;&#26159;&#22914;&#20309;&#26377;&#25928;&#22320;&#34920;&#31034;&#20960;&#20309;&#36793;&#30028;&#12290;&#19977;&#35282;&#21270;&#30340;&#20960;&#20309;&#36793;&#30028;&#22312;&#24037;&#31243;&#24212;&#29992;&#20013;&#24471;&#21040;&#20102;&#24191;&#27867;&#29702;&#35299;&#21644;&#20351;&#29992;&#12290;&#28982;&#32780;&#65292;&#22522;&#20110;&#23427;&#20204;&#30340;&#23610;&#23544;&#21644;&#26041;&#21521;&#30340;&#24322;&#36136;&#24615;&#65292;&#23558;&#23427;&#20204;&#38598;&#25104;&#21040;&#26426;&#22120;&#23398;&#20064;&#26041;&#27861;&#20013;&#36890;&#24120;&#21313;&#20998;&#22256;&#38590;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26377;&#25928;&#30340;&#29702;&#35770;&#26469;&#24314;&#27169;&#31890;&#23376;&#19982;&#36793;&#30028;&#30340;&#30456;&#20114;&#20316;&#29992;&#65292;&#20174;&#32780;&#25512;&#23548;&#20986;&#20102;&#25105;&#20204;&#30340;&#26032;&#22411;&#36793;&#30028;&#22270;&#31070;&#32463;&#32593;&#32476;&#65288;BGNNs&#65289;&#65292;&#35813;&#32593;&#32476;&#21160;&#24577;&#22320;&#20462;&#25913;&#22270;&#32467;&#26500;&#20197;&#28385;&#36275;&#36793;&#30028;&#26465;&#20214;&#12290;&#26032;&#30340; BGNNs &#22312;&#22797;&#26434;&#30340;&#19977;&#32500;&#39063;&#31890;&#27969;&#21160;&#36807;&#31243;&#65288;&#22914;&#28431;&#26007;&#12289;&#26059;&#36716;&#40723;&#21644;&#25605;&#25292;&#22120;&#65289;&#20013;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#36825;&#20123;&#36807;&#31243;&#37117;&#26159;&#29616;&#20195;&#24037;&#19994;&#26426;&#26800;&#30340;&#26631;&#20934;&#32452;&#20214;&#65292;&#20294;&#20854;&#20960;&#20309;&#24418;&#29366;&#20173;&#28982;&#21313;&#20998;&#22797;&#26434;&#12290;BGNNs &#22312;&#35745;&#31639;&#25928;&#29575;&#21644;&#39044;&#27979;&#20934;&#30830;&#29575;&#26041;&#38754;&#37117;&#24471;&#21040;&#20102;&#35780;&#20272;&#12290;
&lt;/p&gt;
&lt;p&gt;
The abundance of data has given machine learning considerable momentum in natural sciences and engineering, though modeling of physical processes is often difficult. A particularly tough problem is the efficient representation of geometric boundaries. Triangularized geometric boundaries are well understood and ubiquitous in engineering applications. However, it is notoriously difficult to integrate them into machine learning approaches due to their heterogeneity with respect to size and orientation. In this work, we introduce an effective theory to model particle-boundary interactions, which leads to our new Boundary Graph Neural Networks (BGNNs) that dynamically modify graph structures to obey boundary conditions. The new BGNNs are tested on complex 3D granular flow processes of hoppers, rotating drums and mixers, which are all standard components of modern industrial machinery but still have complicated geometry. BGNNs are evaluated in terms of computational efficiency as well as pre
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#21333;&#20010;&#31070;&#32463;&#20803;&#30340;&#26032;&#22411;&#38750;&#21442;&#25968;&#20998;&#20301;&#25968;&#20272;&#35745;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#23567;&#26679;&#26412;&#22823;&#23567;&#21644;&#30495;&#23454;&#19990;&#30028;&#23454;&#39564;&#20013;&#30340;&#20248;&#36234;&#34920;&#29616;&#34920;&#26126;&#20854;&#21487;&#20197;&#28040;&#38500;&#19982;&#27169;&#22411;&#35268;&#33539;&#30456;&#20851;&#30340;&#33258;&#30001;&#24230;&#65292;&#24182;&#25552;&#20379;&#26356;&#22909;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;</title><link>http://arxiv.org/abs/2106.03702</link><description>&lt;p&gt;
&#21333;&#20010;&#31070;&#32463;&#20803;&#33021;&#21542;&#23398;&#20064;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#65311;
&lt;/p&gt;
&lt;p&gt;
Can a single neuron learn predictive uncertainty?. (arXiv:2106.03702v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.03702
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#21333;&#20010;&#31070;&#32463;&#20803;&#30340;&#26032;&#22411;&#38750;&#21442;&#25968;&#20998;&#20301;&#25968;&#20272;&#35745;&#26041;&#27861;&#65292;&#35813;&#26041;&#27861;&#22312;&#23567;&#26679;&#26412;&#22823;&#23567;&#21644;&#30495;&#23454;&#19990;&#30028;&#23454;&#39564;&#20013;&#30340;&#20248;&#36234;&#34920;&#29616;&#34920;&#26126;&#20854;&#21487;&#20197;&#28040;&#38500;&#19982;&#27169;&#22411;&#35268;&#33539;&#30456;&#20851;&#30340;&#33258;&#30001;&#24230;&#65292;&#24182;&#25552;&#20379;&#26356;&#22909;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#37319;&#29992;&#28145;&#24230;&#23398;&#20064;&#26041;&#27861;&#36827;&#34892;&#30340;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#26088;&#22312;&#20998;&#31163;&#25105;&#20204;&#36890;&#36807;&#27979;&#37327;&#25152;&#35266;&#23519;&#21040;&#30340;&#19990;&#30028;&#29366;&#24577;&#30340;&#19981;&#30830;&#23450;&#24615;&#65288;&#23458;&#35266;&#32456;&#28857;&#65289;&#19982;&#27169;&#22411;&#35268;&#33539;&#21644;&#35757;&#32451;&#36807;&#31243;&#29992;&#20110;&#39044;&#27979;&#36825;&#31181;&#29366;&#24577;&#30340;&#26041;&#24335;&#30456;&#28151;&#28102;&#30340;&#31243;&#24230;&#65288;&#20027;&#35266;&#25163;&#27573;&#65289;--&#20363;&#22914;&#31070;&#32463;&#20803;&#30340;&#25968;&#37327;&#65292;&#28145;&#24230;&#65292;&#36830;&#25509;&#65292;&#20808;&#39564;&#20998;&#24067;&#65288;&#22914;&#26524;&#27169;&#22411;&#26159;&#36125;&#21494;&#26031;&#30340;&#65289;&#65292;&#26435;&#37325;&#21021;&#22987;&#21270;&#31561;&#12290;&#36825;&#24341;&#20986;&#20102;&#19968;&#20010;&#38382;&#39064;&#65292;&#21363;&#22312;&#20173;&#33021;&#25429;&#33719;&#23458;&#35266;&#32456;&#28857;&#30340;&#21069;&#25552;&#19979;&#65292;&#33021;&#21542;&#28040;&#38500;&#19982;&#36825;&#20123;&#35268;&#33539;&#30456;&#20851;&#30340;&#33258;&#30001;&#24230;&#12290;&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#22522;&#20110;&#26368;&#31616;&#21333;&#30340;&#31070;&#32463;&#32593;&#32476;&#32467;&#26500;&#8212;&#21333;&#20010;&#31070;&#32463;&#20803;&#8212;&#30340;&#36830;&#32493;&#38543;&#26426;&#21464;&#37327;&#30340;&#26032;&#22411;&#38750;&#21442;&#25968;&#20998;&#20301;&#25968;&#20272;&#35745;&#26041;&#27861;&#12290;&#39318;&#20808;&#65292;&#22312;&#21512;&#25104;&#23454;&#39564;&#20013;&#65292;&#35813;&#26041;&#27861;&#23637;&#29616;&#20102;&#23427;&#30340;&#20248;&#21183;&#65292;&#23427;&#23558;&#36890;&#36807;&#25490;&#24207;&#39034;&#24207;&#32479;&#35745;&#37327;&#24471;&#21040;&#30340;&#20998;&#20301;&#25968;&#20272;&#35745;&#32467;&#26524;&#65288;&#29305;&#21035;&#26159;&#23545;&#20110;&#23567;&#26679;&#26412;&#22823;&#23567;&#65289;&#19982;&#20998;&#20301;&#22238;&#24402;&#36827;&#34892;&#20102;&#27604;&#36739;&#12290;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#23454;&#39564;&#20013;&#65292;&#35813;&#26041;&#27861;&#34987;&#35777;&#26126;&#21487;&#20197;&#36890;&#36807;&#38477;&#20302;&#36229;&#20986;&#20998;&#24067;&#33539;&#22260;&#30340;&#25968;&#25454;&#20013;&#39044;&#27979;&#26041;&#24046;&#30340;&#20302;&#20272;&#26469;&#20026;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#25552;&#20379;&#26356;&#22909;&#30340;&#39044;&#27979;&#19981;&#30830;&#23450;&#24615;&#20272;&#35745;&#12290;
&lt;/p&gt;
&lt;p&gt;
Uncertainty estimation methods using deep learning approaches strive against separating how uncertain the state of the world manifests to us via measurement (objective end) from the way this gets scrambled with the model specification and training procedure used to predict such state (subjective means) -- e.g., number of neurons, depth, connections, priors (if the model is bayesian), weight initialization, etc. This poses the question of the extent to which one can eliminate the degrees of freedom associated with these specifications and still being able to capture the objective end. Here, a novel non-parametric quantile estimation method for continuous random variables is introduced, based on the simplest neural network architecture with one degree of freedom: a single neuron. Its advantage is first shown in synthetic experiments comparing with the quantile estimation achieved from ranking the order statistics (specifically for small sample size) and with quantile regression. In real-
&lt;/p&gt;</description></item><item><title>&#26631;&#20934;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#30340;ELBO&#22312;&#31283;&#23450;&#28857;&#22788;&#21487;&#20197;&#20197;&#38381;&#21512;&#24418;&#24335;&#35745;&#31639;&#65292;&#25910;&#25947;&#20110;&#19977;&#20010;&#29109;&#20043;&#21644;&#12290;&#65288;&#20854;&#20013;&#19968;&#20010;&#29109;&#20026;&#20808;&#39564;&#20998;&#24067;&#30340;&#29109;&#65292;&#19968;&#20010;&#20026;&#21487;&#35266;&#27979;&#20998;&#24067;&#30340;&#29109;&#65292;&#19968;&#20010;&#20026;&#21464;&#20998;&#20998;&#24067;&#30340;&#24179;&#22343;&#29109;&#65292;&#25104;&#26524;&#35777;&#26126;&#20102;ELBO&#22312;&#31283;&#23450;&#28857;&#22788;&#31561;&#20110;&#29109;&#12290;&#65289;</title><link>http://arxiv.org/abs/2010.14860</link><description>&lt;p&gt;
&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#30340;ELBO&#25910;&#25947;&#20110;&#19977;&#20010;&#29109;&#20043;&#21644;&#12290;
&lt;/p&gt;
&lt;p&gt;
The ELBO of Variational Autoencoders Converges to a Sum of Three Entropies. (arXiv:2010.14860v5 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2010.14860
&lt;/p&gt;
&lt;p&gt;
&#26631;&#20934;&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;&#30340;ELBO&#22312;&#31283;&#23450;&#28857;&#22788;&#21487;&#20197;&#20197;&#38381;&#21512;&#24418;&#24335;&#35745;&#31639;&#65292;&#25910;&#25947;&#20110;&#19977;&#20010;&#29109;&#20043;&#21644;&#12290;&#65288;&#20854;&#20013;&#19968;&#20010;&#29109;&#20026;&#20808;&#39564;&#20998;&#24067;&#30340;&#29109;&#65292;&#19968;&#20010;&#20026;&#21487;&#35266;&#27979;&#20998;&#24067;&#30340;&#29109;&#65292;&#19968;&#20010;&#20026;&#21464;&#20998;&#20998;&#24067;&#30340;&#24179;&#22343;&#29109;&#65292;&#25104;&#26524;&#35777;&#26126;&#20102;ELBO&#22312;&#31283;&#23450;&#28857;&#22788;&#31561;&#20110;&#29109;&#12290;&#65289;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#33258;&#32534;&#30721;&#22120;(VAEs)&#30340;&#20013;&#24515;&#30446;&#26631;&#20989;&#25968;&#26159;&#20854;&#21464;&#20998;&#19979;&#30028;(ELBO)&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#23545;&#20110;&#26631;&#20934;(&#21363;&#39640;&#26031;)VAEs&#65292;ELBO&#25910;&#25947;&#20110;&#30001;&#19977;&#20010;&#29109;&#20043;&#21644;&#32473;&#20986;&#30340;&#20540;&#65306;(&#20808;&#39564;&#20998;&#24067;&#30340;&#36127;)&#29109;&#12289;&#21487;&#35266;&#27979;&#20998;&#24067;&#30340;&#39044;&#26399;(&#36127;)&#29109;&#20197;&#21450;&#21464;&#20998;&#20998;&#24067;&#30340;&#24179;&#22343;&#29109;(&#21518;&#32773;&#24050;&#32463;&#26159;ELBO&#30340;&#19968;&#37096;&#20998;)&#12290;&#25105;&#20204;&#30340;&#25512;&#23548;&#32467;&#26524;&#31934;&#30830;&#65292;&#36866;&#29992;&#20110;&#32534;&#30721;&#22120;&#21644;&#35299;&#30721;&#22120;&#30340;&#23567;&#22411;&#21644;&#22797;&#26434;&#28145;&#24230;&#32593;&#32476;&#65292;&#24182;&#36866;&#29992;&#20110;&#26377;&#38480;&#21644;&#26080;&#38480;&#25968;&#37327;&#30340;&#25968;&#25454;&#28857;&#20197;&#21450;&#20219;&#20309;&#31283;&#23450;&#28857;(&#21253;&#25324;&#23616;&#37096;&#26368;&#22823;&#20540;&#21644;&#38797;&#28857;)&#12290;&#35813;&#32467;&#26524;&#24847;&#21619;&#30528;&#23545;&#20110;&#26631;&#20934;VAEs&#65292;ELBO&#22312;&#31283;&#23450;&#28857;&#26102;&#36890;&#24120;&#21487;&#20197;&#20197;&#38381;&#21512;&#24418;&#24335;&#35745;&#31639;&#65292;&#32780;&#21407;&#22987;ELBO&#38656;&#35201;&#25968;&#20540;&#31215;&#20998;&#36817;&#20284;&#12290;&#20316;&#20026;&#20027;&#35201;&#36129;&#29486;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;VAEs&#30340;ELBO&#22312;&#31283;&#23450;&#28857;&#22788;&#31561;&#20110;&#29109;&#30340;&#35777;&#26126;&#12290;
&lt;/p&gt;
&lt;p&gt;
The central objective function of a variational autoencoder (VAE) is its variational lower bound (the ELBO). Here we show that for standard (i.e., Gaussian) VAEs the ELBO converges to a value given by the sum of three entropies: the (negative) entropy of the prior distribution, the expected (negative) entropy of the observable distribution, and the average entropy of the variational distributions (the latter is already part of the ELBO). Our derived analytical results are exact and apply for small as well as for intricate deep networks for encoder and decoder. Furthermore, they apply for finitely and infinitely many data points and at any stationary point (including local maxima and saddle points). The result implies that the ELBO can for standard VAEs often be computed in closed-form at stationary points while the original ELBO requires numerical approximations of integrals. As a main contribution, we provide the proof that the ELBO for VAEs is at stationary points equal to entropy su
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23450;&#20041;&#26469;&#25551;&#36848;&#23545;&#25239;&#35757;&#32451;&#20013;&#26799;&#24230;&#30340;&#20248;&#36873;&#26041;&#21521;&#65292;&#21033;&#29992;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#30340;&#25351;&#26631;&#26469;&#35780;&#20272;&#23545;&#40784;&#24773;&#20917;&#65292;&#24182;&#34920;&#26126;&#22312;&#23545;&#40784;&#26041;&#21521;&#19978;&#30340;&#38480;&#21046;&#21487;&#20197;&#36827;&#19968;&#27493;&#25552;&#39640;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#12290;</title><link>http://arxiv.org/abs/2009.04709</link><description>&lt;p&gt;
&#22522;&#20110;&#25237;&#24433;&#26799;&#24230;&#19979;&#38477;&#30340;&#23545;&#25239;&#35757;&#32451;&#20013;&#26799;&#24230;&#26041;&#21521;&#30340;&#37327;&#21270;&#30740;&#31350;
&lt;/p&gt;
&lt;p&gt;
Quantifying the Preferential Direction of the Model Gradient in Adversarial Training With Projected Gradient Descent. (arXiv:2009.04709v5 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2009.04709
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23450;&#20041;&#26469;&#25551;&#36848;&#23545;&#25239;&#35757;&#32451;&#20013;&#26799;&#24230;&#30340;&#20248;&#36873;&#26041;&#21521;&#65292;&#21033;&#29992;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#30340;&#25351;&#26631;&#26469;&#35780;&#20272;&#23545;&#40784;&#24773;&#20917;&#65292;&#24182;&#34920;&#26126;&#22312;&#23545;&#40784;&#26041;&#21521;&#19978;&#30340;&#38480;&#21046;&#21487;&#20197;&#36827;&#19968;&#27493;&#25552;&#39640;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#25239;&#35757;&#32451;&#65292;&#23588;&#20854;&#26159;&#25237;&#24433;&#26799;&#24230;&#19979;&#38477;&#65288;PGD&#65289;&#65292;&#24050;&#34987;&#35777;&#26126;&#26159;&#25552;&#39640;&#23545;&#25239;&#24615;&#25915;&#20987;&#40065;&#26834;&#24615;&#30340;&#26377;&#25928;&#26041;&#27861;&#12290;&#22312;&#23545;&#25239;&#35757;&#32451;&#21518;&#65292;&#27169;&#22411;&#23545;&#20854;&#36755;&#20837;&#30340;&#26799;&#24230;&#20855;&#26377;&#20248;&#36873;&#26041;&#21521;&#12290;&#28982;&#32780;&#65292;&#23545;&#40784;&#26041;&#21521;&#24182;&#27809;&#26377;&#24471;&#21040;&#25968;&#23398;&#19978;&#30340;&#24456;&#22909;&#25551;&#36848;&#65292;&#36825;&#20351;&#24471;&#20854;&#38590;&#20197;&#36827;&#34892;&#23450;&#37327;&#35780;&#20272;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#23450;&#20041;&#65292;&#23558;&#20854;&#35270;&#20026;&#25351;&#21521;&#20915;&#31574;&#31354;&#38388;&#20013;&#26368;&#36817;&#38169;&#35823;&#31867;&#25903;&#25345;&#38598;&#30340;&#26368;&#36817;&#28857;&#30340;&#21521;&#37327;&#26041;&#21521;&#12290;&#20026;&#20102;&#35780;&#20272;&#23545;&#25239;&#35757;&#32451;&#21518;&#27169;&#22411;&#19982;&#27492;&#26041;&#21521;&#30340;&#23545;&#40784;&#24773;&#20917;&#65292;&#25105;&#20204;&#24212;&#29992;&#20102;&#19968;&#31181;&#25351;&#26631;&#65292;&#35813;&#25351;&#26631;&#20351;&#29992;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#26469;&#20135;&#29983;&#26368;&#23567;&#27531;&#24046;&#65292;&#20197;&#25913;&#21464;&#22270;&#20687;&#20013;&#30340;&#31867;&#21035;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;PGD&#35757;&#32451;&#30340;&#27169;&#22411;&#30456;&#27604;&#22522;&#32447;&#20855;&#26377;&#26356;&#39640;&#30340;&#23545;&#40784;&#24230;&#65292;&#32780;&#25105;&#20204;&#30340;&#25351;&#26631;&#21576;&#29616;&#27604;&#31454;&#20105;&#25351;&#26631;&#20844;&#24335;&#26356;&#39640;&#30340;&#23545;&#40784;&#24230;&#20540;&#65292;&#24182;&#19988;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#24378;&#21046;&#25191;&#34892;&#36825;&#20010;&#23545;&#40784;&#26041;&#21521;&#21487;&#20197;&#36827;&#19968;&#27493;&#25552;&#39640;&#27169;&#22411;&#30340;&#40065;&#26834;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Adversarial training, especially projected gradient descent (PGD), has proven to be a successful approach for improving robustness against adversarial attacks. After adversarial training, gradients of models with respect to their inputs have a preferential direction. However, the direction of alignment is not mathematically well established, making it difficult to evaluate quantitatively. We propose a novel definition of this direction as the direction of the vector pointing toward the closest point of the support of the closest inaccurate class in decision space. To evaluate the alignment with this direction after adversarial training, we apply a metric that uses generative adversarial networks to produce the smallest residual needed to change the class present in the image. We show that PGD-trained models have a higher alignment than the baseline according to our definition, that our metric presents higher alignment values than a competing metric formulation, and that enforcing this 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27969;&#30340;&#24490;&#29615;&#28151;&#21512;&#23494;&#24230;&#32593;&#32476;&#65292;&#36890;&#36807;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#19978;&#23450;&#20041;&#19968;&#20010;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65292;&#23558;&#24490;&#29615;&#28151;&#21512;&#23494;&#24230;&#32593;&#32476;&#25512;&#24191;&#21040;&#38750;&#32447;&#24615;&#21464;&#25442;&#30340;&#30446;&#26631;&#24207;&#21015;&#19978;&#65292;&#35813;&#27169;&#22411;&#22312;&#22270;&#20687;&#24207;&#21015;&#30340;&#25311;&#21512;&#24230;&#19978;&#34920;&#29616;&#26174;&#33879;&#65292;&#20855;&#26377;&#26174;&#33879;&#30340;&#24314;&#27169;&#33021;&#21147;&#65292;&#22312;&#23545;&#25968;&#20284;&#28982;&#24230;&#37327;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2008.02144</link><description>&lt;p&gt;
FRMDN: &#22522;&#20110;&#27969;&#30340;&#24490;&#29615;&#28151;&#21512;&#23494;&#24230;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
FRMDN: Flow-based Recurrent Mixture Density Network. (arXiv:2008.02144v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2008.02144
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#27969;&#30340;&#24490;&#29615;&#28151;&#21512;&#23494;&#24230;&#32593;&#32476;&#65292;&#36890;&#36807;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#19978;&#23450;&#20041;&#19968;&#20010;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65292;&#23558;&#24490;&#29615;&#28151;&#21512;&#23494;&#24230;&#32593;&#32476;&#25512;&#24191;&#21040;&#38750;&#32447;&#24615;&#21464;&#25442;&#30340;&#30446;&#26631;&#24207;&#21015;&#19978;&#65292;&#35813;&#27169;&#22411;&#22312;&#22270;&#20687;&#24207;&#21015;&#30340;&#25311;&#21512;&#24230;&#19978;&#34920;&#29616;&#26174;&#33879;&#65292;&#20855;&#26377;&#26174;&#33879;&#30340;&#24314;&#27169;&#33021;&#21147;&#65292;&#22312;&#23545;&#25968;&#20284;&#28982;&#24230;&#37327;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper proposes a flow-based recurrent mixture density network (FRMDN) that generalizes recurrent mixture density networks by defining a Gaussian mixture model on a non-linearly transformed target sequence in each time-step. The model significantly improves the fit to image sequences and outperforms other state-of-the-art methods in terms of the log-likelihood.
&lt;/p&gt;
&lt;p&gt;
&#24490;&#29615;&#28151;&#21512;&#23494;&#24230;&#32593;&#32476;&#26159;&#19968;&#31867;&#37325;&#35201;&#30340;&#27010;&#29575;&#27169;&#22411;&#65292;&#24191;&#27867;&#24212;&#29992;&#20110;&#24207;&#21015;&#24314;&#27169;&#21644;&#24207;&#21015;&#21040;&#24207;&#21015;&#26144;&#23556;&#24212;&#29992;&#20013;&#12290;&#22312;&#36825;&#31867;&#27169;&#22411;&#20013;&#65292;&#30446;&#26631;&#24207;&#21015;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#30340;&#23494;&#24230;&#30001;&#20855;&#26377;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#21442;&#25968;&#30340;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#24314;&#27169;&#12290;&#26412;&#25991;&#36890;&#36807;&#22312;&#27599;&#20010;&#26102;&#38388;&#27493;&#19978;&#23450;&#20041;&#19968;&#20010;&#39640;&#26031;&#28151;&#21512;&#27169;&#22411;&#65292;&#23558;&#24490;&#29615;&#28151;&#21512;&#23494;&#24230;&#32593;&#32476;&#25512;&#24191;&#21040;&#38750;&#32447;&#24615;&#21464;&#25442;&#30340;&#30446;&#26631;&#24207;&#21015;&#19978;&#12290;&#38750;&#32447;&#24615;&#21464;&#25442;&#31354;&#38388;&#26159;&#36890;&#36807;&#24402;&#19968;&#21270;&#27969;&#21019;&#24314;&#30340;&#12290;&#25105;&#20204;&#35266;&#23519;&#21040;&#65292;&#35813;&#27169;&#22411;&#26174;&#33879;&#25552;&#39640;&#20102;&#22270;&#20687;&#24207;&#21015;&#30340;&#25311;&#21512;&#24230;&#65292;&#29992;&#23545;&#25968;&#20284;&#28982;&#24230;&#37327;&#12290;&#25105;&#20204;&#36824;&#23558;&#25152;&#25552;&#20986;&#30340;&#27169;&#22411;&#24212;&#29992;&#20110;&#19968;&#20123;&#35821;&#38899;&#21644;&#22270;&#20687;&#25968;&#25454;&#65292;&#24182;&#35266;&#23519;&#21040;&#35813;&#27169;&#22411;&#20855;&#26377;&#26174;&#33879;&#30340;&#24314;&#27169;&#33021;&#21147;&#65292;&#22312;&#23545;&#25968;&#20284;&#28982;&#24230;&#37327;&#26041;&#38754;&#20248;&#20110;&#20854;&#20182;&#26368;&#20808;&#36827;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
The class of recurrent mixture density networks is an important class of probabilistic models used extensively in sequence modeling and sequence-to-sequence mapping applications. In this class of models, the density of a target sequence in each time-step is modeled by a Gaussian mixture model with the parameters given by a recurrent neural network. In this paper, we generalize recurrent mixture density networks by defining a Gaussian mixture model on a non-linearly transformed target sequence in each time-step. The non-linearly transformed space is created by normalizing flow. We observed that this model significantly improves the fit to image sequences measured by the log-likelihood. We also applied the proposed model on some speech and image data, and observed that the model has significant modeling power outperforming other state-of-the-art methods in terms of the log-likelihood.
&lt;/p&gt;</description></item></channel></rss>