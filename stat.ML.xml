<rss version="2.0"><channel><title>Chat Arxiv stat.ML</title><link>https://github.com/qhduan/cn-chat-arxiv</link><description>This is arxiv RSS feed for stat.ML</description><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29702;&#35770;&#26469;&#25551;&#36848;&#38750;&#36127;&#36229;&#39532;&#27663;&#36807;&#31243;&#65292;&#24182;&#25512;&#23548;&#20986;&#19968;&#20010;&#26032;&#30340;&#26497;&#22823;&#19981;&#31561;&#24335;&#65292;&#36866;&#29992;&#20110;&#38750;&#21487;&#31215;&#24773;&#20917;&#65292;&#24182;&#35828;&#26126;&#20102;&#28151;&#21512;&#26041;&#27861;&#30340;&#25193;&#23637;&#20197;&#21450;&#35813;&#29702;&#35770;&#22312;&#39034;&#24207;&#32479;&#35745;&#20013;&#30340;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2304.01163</link><description>&lt;p&gt;
&#38750;&#21487;&#31215;&#38750;&#36127;&#36229;&#39532;&#27663;&#36807;&#31243;&#30340;&#25193;&#23637;&#32500;&#23572;&#19981;&#31561;&#24335;
&lt;/p&gt;
&lt;p&gt;
The extended Ville's inequality for nonintegrable nonnegative supermartingales. (arXiv:2304.01163v1 [math.PR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01163
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#29702;&#35770;&#26469;&#25551;&#36848;&#38750;&#36127;&#36229;&#39532;&#27663;&#36807;&#31243;&#65292;&#24182;&#25512;&#23548;&#20986;&#19968;&#20010;&#26032;&#30340;&#26497;&#22823;&#19981;&#31561;&#24335;&#65292;&#36866;&#29992;&#20110;&#38750;&#21487;&#31215;&#24773;&#20917;&#65292;&#24182;&#35828;&#26126;&#20102;&#28151;&#21512;&#26041;&#27861;&#30340;&#25193;&#23637;&#20197;&#21450;&#35813;&#29702;&#35770;&#22312;&#39034;&#24207;&#32479;&#35745;&#20013;&#30340;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#22312; Robbins &#30340;&#21021;&#22987;&#24037;&#20316;&#22522;&#30784;&#19978;&#65292;&#20005;&#23494;&#22320;&#25552;&#20986;&#20102;&#19968;&#31181;&#38750;&#36127;&#36229;&#39532;&#27663;&#36807;&#31243;&#30340;&#25193;&#23637;&#29702;&#35770;&#65292;&#19981;&#38656;&#35201;&#21487;&#31215;&#24615;&#25110;&#26377;&#38480;&#24615;&#12290;&#29305;&#21035;&#22320;&#65292;&#25105;&#20204;&#25512;&#23548;&#20102; Robbins &#39044;&#31034;&#30340;&#19968;&#20010;&#20851;&#38190;&#26497;&#22823;&#19981;&#31561;&#24335;&#65292;&#31216;&#20026;&#25193;&#23637;&#32500;&#23572;&#19981;&#31561;&#24335;&#65292;&#23427;&#21152;&#24378;&#20102;&#32463;&#20856;&#30340;&#32500;&#23572;&#19981;&#31561;&#24335;&#65288;&#36866;&#29992;&#20110;&#21487;&#31215;&#38750;&#36127;&#36229;&#39532;&#27663;&#36807;&#31243;&#65289;&#65292;&#24182;&#36866;&#29992;&#20110;&#25105;&#20204;&#30340;&#38750;&#21487;&#31215;&#35774;&#32622;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#28151;&#21512;&#26041;&#27861;&#30340;&#25193;&#23637;&#65292;&#36866;&#29992;&#20110;&#25105;&#20204;&#25193;&#23637;&#30340;&#38750;&#36127;&#36229;&#39532;&#27663;&#36807;&#31243;&#30340; $\sigma$- &#26377;&#38480;&#28151;&#21512;&#12290;&#25105;&#20204;&#20171;&#32461;&#20102;&#25105;&#20204;&#29702;&#35770;&#22312;&#39034;&#24207;&#32479;&#35745;&#20013;&#30340;&#19968;&#20123;&#24212;&#29992;&#65292;&#22914;&#22312;&#25512;&#23548;&#38750;&#21442;&#25968;&#32622;&#20449;&#24207;&#21015;&#21644;&#65288;&#25193;&#23637;&#65289;e-&#36807;&#31243;&#20013;&#20351;&#29992;&#19981;&#36866;&#24403;&#28151;&#21512;&#65288;&#20808;&#39564;&#65289;&#12290;
&lt;/p&gt;
&lt;p&gt;
Following initial work by Robbins, we rigorously present an extended theory of nonnegative supermartingales, requiring neither integrability nor finiteness. In particular, we derive a key maximal inequality foreshadowed by Robbins, which we call the extended Ville's inequality, that strengthens the classical Ville's inequality (for integrable nonnegative supermartingales), and also applies to our nonintegrable setting. We derive an extension of the method of mixtures, which applies to $\sigma$-finite mixtures of our extended nonnegative supermartingales. We present some implications of our theory for sequential statistics, such as the use of improper mixtures (priors) in deriving nonparametric confidence sequences and (extended) e-processes.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#22522;&#20110;copula&#29702;&#35770;&#65292;&#37319;&#29992;&#39640;&#32500;&#20998;&#24067;&#36317;&#31163;&#21644;&#25490;&#21015;&#32479;&#35745;&#26041;&#27861;&#30740;&#31350;&#19968;&#20010;&#35774;&#35745;&#23454;&#39564;&#20013;&#21442;&#25968;&#23545;&#26448;&#26009;&#24494;&#35266;&#32467;&#26500;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#20102;&#33609;&#37240;&#37240;&#24230;&#21644;&#20914;&#21387;&#39034;&#24207;&#23545;&#29983;&#25104;&#30340;&#27687;&#21270;&#38042;&#24494;&#35266;&#32467;&#26500;&#26377;&#24433;&#21709;&#65292;&#21516;&#26102;&#26816;&#27979;&#21040;&#36807;&#24230;&#30340;&#21452;&#21464;&#37327;&#25928;&#24212;&#12290;</title><link>http://arxiv.org/abs/2304.01120</link><description>&lt;p&gt;
&#37319;&#29992;&#25968;&#37327;&#34920;&#31034;&#21644;&#39640;&#32500;&#24230;&#20998;&#24067;&#36317;&#31163;&#26816;&#27979;&#21512;&#25104;&#21442;&#25968;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Synthesis parameter effect detection using quantitative representations and high dimensional distribution distances. (arXiv:2304.01120v1 [cond-mat.mtrl-sci])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01120
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#22522;&#20110;copula&#29702;&#35770;&#65292;&#37319;&#29992;&#39640;&#32500;&#20998;&#24067;&#36317;&#31163;&#21644;&#25490;&#21015;&#32479;&#35745;&#26041;&#27861;&#30740;&#31350;&#19968;&#20010;&#35774;&#35745;&#23454;&#39564;&#20013;&#21442;&#25968;&#23545;&#26448;&#26009;&#24494;&#35266;&#32467;&#26500;&#30340;&#24433;&#21709;&#65292;&#21457;&#29616;&#20102;&#33609;&#37240;&#37240;&#24230;&#21644;&#20914;&#21387;&#39034;&#24207;&#23545;&#29983;&#25104;&#30340;&#27687;&#21270;&#38042;&#24494;&#35266;&#32467;&#26500;&#26377;&#24433;&#21709;&#65292;&#21516;&#26102;&#26816;&#27979;&#21040;&#36807;&#24230;&#30340;&#21452;&#21464;&#37327;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26816;&#27979;&#21512;&#25104;&#36807;&#31243;&#21442;&#25968;&#23545;&#26448;&#26009;&#24494;&#35266;&#32467;&#26500;&#30340;&#24433;&#21709;&#26159;&#26448;&#26009;&#31185;&#23398;&#20013;&#19968;&#20010;&#37325;&#35201;&#20294;&#38590;&#20197;&#25417;&#25720;&#30340;&#30446;&#26631;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#22522;&#20110;&#26893;&#34987;&#29702;&#35770;&#12289;&#39640;&#32500;&#20998;&#24067;&#36317;&#31163;&#21644;&#25490;&#21015;&#32479;&#35745;&#30340;&#26041;&#27861;&#65292;&#20998;&#26512;&#20102;&#19968;&#20010;&#21512;&#25104;&#27687;&#21270;&#38042;&#30340;&#35774;&#35745;&#23454;&#39564;&#20013;&#30340;&#21442;&#25968;&#25928;&#24212;&#65292;&#20174;&#32780;&#26816;&#27979;&#21040;&#20914;&#21387;&#39034;&#24207;&#21644;&#33609;&#37240;&#37240;&#24230;&#23545;&#29983;&#25104;&#30340;&#27687;&#21270;&#38042;&#24494;&#35266;&#32467;&#26500;&#30340;&#24433;&#21709;&#65292;&#36825;&#19982;&#25991;&#29486;&#30456;&#31526;&#12290;&#25105;&#20204;&#36824;&#26816;&#27979;&#21040;&#37240;&#27987;&#24230;&#12289;&#20914;&#21387;&#39034;&#24207;&#21644;&#27785;&#28096;&#28201;&#24230;&#20043;&#38388;&#30340;&#36807;&#24230;&#21452;&#21464;&#37327;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
Detection of effects of the parameters of the synthetic process on the microstructure of materials is an important, yet elusive goal of materials science. We develop a method for detecting effects based on copula theory, high dimensional distribution distances, and permutational statistics to analyze a designed experiment synthesizing plutonium oxide from Pu(III) Oxalate. We detect effects of strike order and oxalic acid feed on the microstructure of the resulting plutonium oxide, which match the literature well. We also detect excess bivariate effects between the pairs of acid concentration, strike order and precipitation temperature.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#31070;&#32463;&#25511;&#21046;&#21464;&#37327;&#30340;&#26041;&#24046;&#32553;&#20943;&#26041;&#27861;&#65292;&#25512;&#23548;&#24182;&#24471;&#20986;&#20102;&#22312;&#21508;&#31181;&#36941;&#21382;&#24615;&#20551;&#35774;&#19979;&#28176;&#36817;&#26041;&#24046;&#30340;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#12290;</title><link>http://arxiv.org/abs/2304.01111</link><description>&lt;p&gt;
&#31070;&#32463;&#25511;&#21046;&#21464;&#37327;&#22312;MCMC&#20013;&#30340;&#29702;&#35770;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Theoretical guarantees for neural control variates in MCMC. (arXiv:2304.01111v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01111
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#31070;&#32463;&#25511;&#21046;&#21464;&#37327;&#30340;&#26041;&#24046;&#32553;&#20943;&#26041;&#27861;&#65292;&#25512;&#23548;&#24182;&#24471;&#20986;&#20102;&#22312;&#21508;&#31181;&#36941;&#21382;&#24615;&#20551;&#35774;&#19979;&#28176;&#36817;&#26041;&#24046;&#30340;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#21152;&#24615;&#25511;&#21046;&#21464;&#37327;&#21644;&#26368;&#23567;&#21270;&#28176;&#36817;&#26041;&#24046;&#30340;&#39532;&#23572;&#21487;&#22827;&#38142;&#26041;&#24046;&#32553;&#20943;&#26041;&#27861;&#12290;&#25105;&#20204;&#19987;&#27880;&#20110;&#25511;&#21046;&#21464;&#37327;&#34920;&#31034;&#20026;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#30340;&#29305;&#23450;&#24773;&#20917;&#12290;&#22312;&#22522;&#30784;&#39532;&#23572;&#21487;&#22827;&#38142;&#30340;&#21508;&#31181;&#36941;&#21382;&#24615;&#20551;&#35774;&#19979;&#65292;&#25512;&#23548;&#20102;&#28176;&#36817;&#26041;&#24046;&#30340;&#26368;&#20248;&#25910;&#25947;&#36895;&#29575;&#12290;&#35813;&#26041;&#27861;&#20381;&#36182;&#20110;&#26041;&#24046;&#32553;&#20943;&#31639;&#27861;&#21644;&#20989;&#25968;&#36924;&#36817;&#29702;&#35770;&#30340;&#38543;&#26426;&#35823;&#24046;&#30340;&#26368;&#26032;&#25104;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this paper, we propose a variance reduction approach for Markov chains based on additive control variates and the minimization of an appropriate estimate for the asymptotic variance. We focus on the particular case when control variates are represented as deep neural networks. We derive the optimal convergence rate of the asymptotic variance under various ergodicity assumptions on the underlying Markov chain. The proposed approach relies upon recent results on the stochastic errors of variance reduction algorithms and function approximation theory.
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31867;&#22522;&#20110;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#21709;&#24212;&#20989;&#25968;&#30340;&#38750;&#32447;&#24615;INGARCH&#27169;&#22411;&#65292;&#33021;&#22815;&#26356;&#22909;&#22320;&#20998;&#26512;&#35745;&#25968;&#26102;&#38388;&#24207;&#21015;&#65292;&#24182;&#22312;&#23454;&#35777;&#20998;&#26512;&#20013;&#24471;&#21040;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2304.01025</link><description>&lt;p&gt;
&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#19982;&#35745;&#25968;&#26102;&#38388;&#24207;&#21015;&#65306;&#19968;&#31867;&#38750;&#32447;&#24615;INGARCH&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Artificial neural networks and time series of counts: A class of nonlinear INGARCH models. (arXiv:2304.01025v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.01025
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31867;&#22522;&#20110;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#21709;&#24212;&#20989;&#25968;&#30340;&#38750;&#32447;&#24615;INGARCH&#27169;&#22411;&#65292;&#33021;&#22815;&#26356;&#22909;&#22320;&#20998;&#26512;&#35745;&#25968;&#26102;&#38388;&#24207;&#21015;&#65292;&#24182;&#22312;&#23454;&#35777;&#20998;&#26512;&#20013;&#24471;&#21040;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35745;&#25968;&#26102;&#38388;&#24207;&#21015;&#32463;&#24120;&#20351;&#29992;&#20855;&#26377;&#26465;&#20214;&#24322;&#26041;&#24046;&#24615;&#65288;INGARCH&#65289;&#30340;&#24191;&#20041;&#25972;&#25968;&#20540;&#33258;&#22238;&#24402;&#27169;&#22411;&#36827;&#34892;&#20998;&#26512;&#12290;&#36825;&#20123;&#27169;&#22411;&#20351;&#29992;&#21709;&#24212;&#20989;&#25968;&#23558;&#36807;&#21435;&#35266;&#27979;&#21521;&#37327;&#21644;&#36807;&#21435;&#26465;&#20214;&#26399;&#26395;&#26144;&#23556;&#21040;&#29616;&#22312;&#35266;&#27979;&#30340;&#26465;&#20214;&#26399;&#26395;&#12290;&#26412;&#25991;&#23637;&#31034;&#20102;&#22914;&#20309;&#23558;INGARCH&#27169;&#22411;&#19982;&#20154;&#24037;&#31070;&#32463;&#32593;&#32476;&#65288;ANN&#65289;&#21709;&#24212;&#20989;&#25968;&#30456;&#32467;&#21512;&#65292;&#20197;&#33719;&#24471;&#19968;&#31867;&#38750;&#32447;&#24615;INGARCH&#27169;&#22411;&#12290;ANN&#26694;&#26550;&#20801;&#35768;&#23558;&#35768;&#22810;&#29616;&#26377;&#30340;INGARCH&#27169;&#22411;&#35299;&#37322;&#20026;&#30456;&#24212;&#31070;&#32463;&#27169;&#22411;&#30340;&#36864;&#21270;&#29256;&#26412;&#12290;&#32473;&#20986;&#20102;&#26368;&#22823;&#20284;&#28982;&#20272;&#35745;&#12289;&#36793;&#38469;&#25928;&#24212;&#21644;&#32622;&#20449;&#21306;&#38388;&#30340;&#35814;&#32454;&#20449;&#24687;&#12290;&#35745;&#25968;&#26102;&#38388;&#24207;&#21015;&#30340;&#23454;&#35777;&#20998;&#26512;&#34920;&#26126;&#65292;&#31070;&#32463;INGARCH&#27169;&#22411;&#33021;&#22815;&#22312;&#20449;&#24687;&#25439;&#22833;&#26041;&#38754;&#32988;&#36807;&#21512;&#29702;&#30340;&#36864;&#21270;&#31454;&#20105;&#27169;&#22411;&#12290;
&lt;/p&gt;
&lt;p&gt;
Time series of counts are frequently analyzed using generalized integer-valued autoregressive models with conditional heteroskedasticity (INGARCH). These models employ response functions to map a vector of past observations and past conditional expectations to the conditional expectation of the present observation. In this paper, it is shown how INGARCH models can be combined with artificial neural network (ANN) response functions to obtain a class of nonlinear INGARCH models. The ANN framework allows for the interpretation of many existing INGARCH models as a degenerate version of a corresponding neural model. Details on maximum likelihood estimation, marginal effects and confidence intervals are given. The empirical analysis of time series of bounded and unbounded counts reveals that the neural INGARCH models are able to outperform reasonable degenerate competitor models in terms of the information loss.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#33258;&#21160;&#29983;&#25104;&#30340;&#35757;&#32451;&#25968;&#25454;&#21644;&#24555;&#36895;&#30340;&#20154;&#24037;&#35270;&#35273;&#26816;&#26597;&#65292;&#25552;&#39640;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#31934;&#24230;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#20445;&#25345;&#26102;&#38388;&#12289;&#31934;&#21147;&#21644;&#25104;&#26412;&#20302;&#65292;&#20854;&#31934;&#24230;&#21644;&#36895;&#24230;&#22312;&#20154;&#31867;&#22269;&#38469;&#26631;&#20934;&#65288;ISIC&#65289;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;</title><link>http://arxiv.org/abs/2304.00990</link><description>&lt;p&gt;
&#36845;&#20195;&#31934;&#28860;&#21644;&#32479;&#35745;&#32467;&#26524;&#39564;&#35777;&#30340;&#39640;&#25928;&#20154;&#26426;&#20132;&#20114;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Efficient human-in-loop deep learning model training with iterative refinement and statistical result validation. (arXiv:2304.00990v1 [cs.CV])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.00990
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21033;&#29992;&#33258;&#21160;&#29983;&#25104;&#30340;&#35757;&#32451;&#25968;&#25454;&#21644;&#24555;&#36895;&#30340;&#20154;&#24037;&#35270;&#35273;&#26816;&#26597;&#65292;&#25552;&#39640;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#31934;&#24230;&#30340;&#26041;&#27861;&#65292;&#21516;&#26102;&#20445;&#25345;&#26102;&#38388;&#12289;&#31934;&#21147;&#21644;&#25104;&#26412;&#20302;&#65292;&#20854;&#31934;&#24230;&#21644;&#36895;&#24230;&#22312;&#20154;&#31867;&#22269;&#38469;&#26631;&#20934;&#65288;ISIC&#65289;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26631;&#27880;&#21644;&#26631;&#31614;&#26159;&#28145;&#24230;&#23398;&#20064;&#22312;&#21307;&#30103;&#25968;&#25454;&#24212;&#29992;&#20013;&#26368;&#22823;&#30340;&#25361;&#25112;&#20043;&#19968;&#12290;&#30446;&#21069;&#30340;&#27969;&#31243;&#26102;&#38388;&#21644;&#25104;&#26412;&#37117;&#24456;&#39640;&#65292;&#22240;&#27492;&#38480;&#21046;&#20102;&#25216;&#26415;&#30340;&#24191;&#27867;&#24212;&#29992;&#12290;&#27492;&#22806;&#65292;&#39564;&#35777;&#35745;&#37327;&#24615;&#33021;&#25913;&#36827;&#26159;&#21542;&#26174;&#33879;&#23545;&#20110;&#36873;&#25321;&#26368;&#20339;&#27169;&#22411;&#38750;&#24120;&#37325;&#35201;&#12290;&#26412;&#25991;&#23637;&#31034;&#20102;&#19968;&#31181;&#26041;&#27861;&#65292;&#29992;&#20110;&#21019;&#24314;&#20998;&#21106;&#65292;&#36825;&#26159;&#36229;&#22768;&#25104;&#20687;&#26426;&#22120;&#23398;&#20064;&#27969;&#31243;&#25968;&#25454;&#28165;&#29702;&#30340;&#24517;&#35201;&#37096;&#20998;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#20010;&#22235;&#27493;&#26041;&#27861;&#65292;&#21033;&#29992;&#33258;&#21160;&#29983;&#25104;&#30340;&#35757;&#32451;&#25968;&#25454;&#21644;&#24555;&#36895;&#30340;&#20154;&#24037;&#35270;&#35273;&#26816;&#26597;&#65292;&#25552;&#39640;&#27169;&#22411;&#31934;&#24230;&#65292;&#21516;&#26102;&#20445;&#25345;&#26102;&#38388;&#12289;&#31934;&#21147;&#21644;&#25104;&#26412;&#20302;&#12290;&#25105;&#20204;&#36824;&#23637;&#31034;&#20102;&#22810;&#27425;&#36816;&#34892;&#23454;&#39564;&#65292;&#20197;&#20801;&#35768;&#20351;&#29992;&#32479;&#35745;&#20998;&#26512;&#12290;&#36136;&#37327;&#36739;&#24046;&#30340;&#33258;&#21160;&#22320;&#38754;&#30495;&#23454;&#25968;&#25454;&#21644;&#24555;&#36895;&#30340;&#35270;&#35273;&#26816;&#26597;&#26377;&#25928;&#22320;&#35757;&#32451;&#20102;&#19968;&#20010;&#21021;&#22987;&#22522;&#30784;&#27169;&#22411;&#65292;&#32780;&#21518;&#29992;&#19968;&#23567;&#37096;&#20998;&#26356;&#26114;&#36149;&#30340;&#20154;&#24037;&#29983;&#25104;&#30340;&#22320;&#38754;&#30495;&#23454;&#25968;&#25454;&#36827;&#34892;&#31934;&#28860;&#12290;&#26412;&#26041;&#27861;&#36827;&#34892;&#20102;&#28436;&#31034;&#65292;&#20854;&#31934;&#24230;&#21644;&#36895;&#24230;&#22312;&#20154;&#31867;&#22269;&#38469;&#26631;&#20934;&#65288;ISIC&#65289;&#25968;&#25454;&#38598;&#19978;&#24471;&#21040;&#20102;&#39564;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;
Annotation and labeling of images are some of the biggest challenges in applying deep learning to medical data. Current processes are time and cost-intensive and, therefore, a limiting factor for the wide adoption of the technology. Additionally validating that measured performance improvements are significant is important to select the best model. In this paper, we demonstrate a method for creating segmentations, a necessary part of a data cleaning for ultrasound imaging machine learning pipelines. We propose a four-step method to leverage automatically generated training data and fast human visual checks to improve model accuracy while keeping the time/effort and cost low. We also showcase running experiments multiple times to allow the usage of statistical analysis. Poor quality automated ground truth data and quick visual inspections efficiently train an initial base model, which is refined using a small set of more expensive human-generated ground truth data. The method is demonst
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36845;&#20195;&#31639;&#27861;IDBM&#65292;&#29992;&#20110;&#35299;&#20915;&#21160;&#24577;Schr\"odinger&#26725;&#38382;&#39064;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#22312;&#27599;&#19968;&#27493;&#26377;&#25928;&#22320;&#32806;&#21512;&#30446;&#26631;&#24230;&#37327;&#65292;&#24182;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#34920;&#29616;&#20986;&#31454;&#20105;&#21147;&#12290;&#27492;&#22806;&#65292;&#36824;&#35752;&#35770;&#20102;&#20351;&#29992;&#25193;&#25955;&#36807;&#31243;&#30340;&#26102;&#38388;&#21453;&#28436;&#26469;&#23450;&#20041;&#19968;&#20010;&#36817;&#20284;&#20256;&#36755;&#31616;&#21333;&#20998;&#24067;&#21040;&#30446;&#26631;&#20998;&#24067;&#30340;&#29983;&#25104;&#36807;&#31243;&#30340;&#26368;&#26032;&#36827;&#23637;&#12290;</title><link>http://arxiv.org/abs/2304.00917</link><description>&lt;p&gt;
&#25193;&#25955;&#26725;&#28151;&#21512;&#20256;&#36755;&#12289;&#34203;&#23450;&#35860;&#26725;&#38382;&#39064;&#21644;&#29983;&#25104;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Diffusion Bridge Mixture Transports, Schr\"odinger Bridge Problems and Generative Modeling. (arXiv:2304.00917v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.00917
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#36845;&#20195;&#31639;&#27861;IDBM&#65292;&#29992;&#20110;&#35299;&#20915;&#21160;&#24577;Schr\"odinger&#26725;&#38382;&#39064;&#65292;&#35813;&#31639;&#27861;&#33021;&#22815;&#22312;&#27599;&#19968;&#27493;&#26377;&#25928;&#22320;&#32806;&#21512;&#30446;&#26631;&#24230;&#37327;&#65292;&#24182;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#34920;&#29616;&#20986;&#31454;&#20105;&#21147;&#12290;&#27492;&#22806;&#65292;&#36824;&#35752;&#35770;&#20102;&#20351;&#29992;&#25193;&#25955;&#36807;&#31243;&#30340;&#26102;&#38388;&#21453;&#28436;&#26469;&#23450;&#20041;&#19968;&#20010;&#36817;&#20284;&#20256;&#36755;&#31616;&#21333;&#20998;&#24067;&#21040;&#30446;&#26631;&#20998;&#24067;&#30340;&#29983;&#25104;&#36807;&#31243;&#30340;&#26368;&#26032;&#36827;&#23637;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21160;&#24577;&#34203;&#23450;&#35860;&#26725;&#38382;&#39064;&#23547;&#27714;&#23450;&#20041;&#22312;&#20004;&#20010;&#30446;&#26631;&#27010;&#29575;&#20998;&#24067;&#20043;&#38388;&#30340;&#20256;&#36755;&#30340;&#38543;&#26426;&#36807;&#31243;&#65292;&#21516;&#26102;&#26368;&#20248;&#22320;&#28385;&#36275;&#26368;&#25509;&#36817;&#21442;&#32771;&#36807;&#31243;&#30340;Kullback-Leibler&#25955;&#24230;&#30340;&#20934;&#21017;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#22522;&#20110;&#37319;&#26679;&#30340;&#36845;&#20195;&#31639;&#27861;&#65292;&#21363;&#36845;&#20195;&#25193;&#25955;&#26725;&#28151;&#21512;&#20256;&#36755;&#65288;IDBM&#65289;&#65292;&#26088;&#22312;&#35299;&#20915;&#21160;&#24577;&#34203;&#23450;&#35860;&#26725;&#38382;&#39064;&#12290;IDBM&#36807;&#31243;&#34920;&#29616;&#20986;&#22312;&#27599;&#19968;&#27493;&#23454;&#29616;&#30446;&#26631;&#24230;&#37327;&#20043;&#38388;&#30340;&#26377;&#25928;&#32806;&#21512;&#30340;&#26377;&#21560;&#24341;&#21147;&#30340;&#23646;&#24615;&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;IDBM&#36807;&#31243;&#30340;&#21021;&#22987;&#29702;&#35770;&#30740;&#31350;&#65292;&#24314;&#31435;&#20102;&#20854;&#25910;&#25947;&#24615;&#36136;&#12290;&#29702;&#35770;&#21457;&#29616;&#36890;&#36807;&#35768;&#22810;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;IDBM&#36807;&#31243;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#20986;&#33394;&#30340;&#24615;&#33021;&#12290;&#29983;&#25104;&#24314;&#27169;&#26041;&#38754;&#30340;&#26368;&#26032;&#36827;&#23637;&#20351;&#29992;&#25193;&#25955;&#36807;&#31243;&#30340;&#26102;&#38388;&#21453;&#28436;&#26469;&#23450;&#20041;&#19968;&#20010;&#36817;&#20284;&#20256;&#36755;&#31616;&#21333;&#20998;&#24067;&#21040;&#30446;&#26631;&#20998;&#24067;&#30340;&#29983;&#25104;&#36807;&#31243;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#65292;&#31216;&#20026;&#36845;&#20195;&#25193;&#25955;&#26725;&#28151;&#21512;&#20256;&#36755;&#65288;IDBM&#65289;&#65292;&#29992;&#20110;&#35299;&#20915;&#21160;&#24577;&#34203;&#23450;&#35860;&#26725;&#38382;&#39064;&#12290;IDBM&#22312;&#27599;&#19968;&#27493;&#23454;&#29616;&#30446;&#26631;&#24230;&#37327;&#20043;&#38388;&#30340;&#26377;&#25928;&#32806;&#21512;&#65292;&#24182;&#19988;&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#34920;&#29616;&#20986;&#33391;&#22909;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#30340;&#29702;&#35770;&#30740;&#31350;&#35777;&#26126;&#20102;IDBM&#31639;&#27861;&#30340;&#25910;&#25947;&#24615;&#36136;&#12290;&#36890;&#36807;&#35768;&#22810;&#25968;&#20540;&#23454;&#39564;&#36827;&#19968;&#27493;&#35828;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#31639;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;&#27492;&#22806;&#65292;&#36824;&#35752;&#35770;&#20102;&#29983;&#25104;&#24314;&#27169;&#26041;&#38754;&#30340;&#26368;&#26032;&#36827;&#23637;&#65292;&#23427;&#20351;&#29992;&#25193;&#25955;&#36807;&#31243;&#30340;&#26102;&#38388;&#21453;&#28436;&#26469;&#36817;&#20284;&#30446;&#26631;&#20998;&#24067;&#12290;
&lt;/p&gt;
&lt;p&gt;
The dynamic Schr\"odinger bridge problem seeks a stochastic process that defines a transport between two target probability measures, while optimally satisfying the criteria of being closest, in terms of Kullback-Leibler divergence, to a reference process.  We propose a novel sampling-based iterative algorithm, the iterated diffusion bridge mixture transport (IDBM), aimed at solving the dynamic Schr\"odinger bridge problem. The IDBM procedure exhibits the attractive property of realizing a valid coupling between the target measures at each step. We perform an initial theoretical investigation of the IDBM procedure, establishing its convergence properties. The theoretical findings are complemented by numerous numerical experiments illustrating the competitive performance of the IDBM procedure across various applications.  Recent advancements in generative modeling employ the time-reversal of a diffusion process to define a generative process that approximately transports a simple distri
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#32452;&#21512;&#20248;&#21270;&#22686;&#24378;&#30340;&#26426;&#22120;&#23398;&#20064;&#27969;&#31243;&#65292;&#29992;&#20110;&#35299;&#20915;&#20855;&#26377;&#35843;&#24230;&#27874;&#30340;&#21160;&#24577;&#36710;&#36742;&#36335;&#24452;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#22312; NeurIPS 2022 &#36710;&#36742;&#36335;&#24452;&#35268;&#21010;&#31454;&#36187;&#20013;&#33719;&#24471;&#31532;&#19968;&#21517;&#65292;&#35777;&#26126;&#20102;&#20854;&#22312;&#35813;&#38382;&#39064;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.00789</link><description>&lt;p&gt;
&#21033;&#29992;&#32452;&#21512;&#20248;&#21270;&#22686;&#24378;&#30340;&#26426;&#22120;&#23398;&#20064;&#35299;&#20915;&#24102;&#26102;&#38388;&#31383;&#30340;&#21160;&#24577;&#36710;&#36742;&#36335;&#24452;&#38382;&#39064;
&lt;/p&gt;
&lt;p&gt;
Combinatorial Optimization enriched Machine Learning to solve the Dynamic Vehicle Routing Problem with Time Windows. (arXiv:2304.00789v1 [math.OC])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.00789
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#21033;&#29992;&#32452;&#21512;&#20248;&#21270;&#22686;&#24378;&#30340;&#26426;&#22120;&#23398;&#20064;&#27969;&#31243;&#65292;&#29992;&#20110;&#35299;&#20915;&#20855;&#26377;&#35843;&#24230;&#27874;&#30340;&#21160;&#24577;&#36710;&#36742;&#36335;&#24452;&#38382;&#39064;&#12290;&#35813;&#26041;&#27861;&#22312; NeurIPS 2022 &#36710;&#36742;&#36335;&#24452;&#35268;&#21010;&#31454;&#36187;&#20013;&#33719;&#24471;&#31532;&#19968;&#21517;&#65292;&#35777;&#26126;&#20102;&#20854;&#22312;&#35813;&#38382;&#39064;&#19978;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#30005;&#23376;&#21830;&#21153;&#30340;&#21457;&#23637;&#21644;&#23458;&#25143;&#23545;&#29289;&#27969;&#26381;&#21153;&#30340;&#35201;&#27714;&#22686;&#21152;&#65292;&#29289;&#27969;&#26381;&#21153;&#25552;&#20379;&#21830;&#22312;&#26085;&#24120;&#35268;&#21010;&#20013;&#38754;&#20020;&#26032;&#30340;&#22797;&#26434;&#24615;&#65292;&#20027;&#35201;&#26159;&#30001;&#20110;&#26377;&#25928;&#22320;&#22788;&#29702;&#24403;&#22825;&#30340;&#37197;&#36865;&#12290;&#29616;&#26377;&#30340;&#22810;&#38454;&#27573;&#38543;&#26426;&#20248;&#21270;&#26041;&#27861;&#20801;&#35768;&#35299;&#20915;&#24213;&#23618;&#30340;&#21160;&#24577;&#36710;&#36742;&#36335;&#24452;&#38382;&#39064;&#65292;&#20294;&#35201;&#20040;&#35745;&#31639;&#25104;&#26412;&#22312;&#22312;&#32447;&#35774;&#32622;&#20013;&#22826;&#39640;&#65292;&#35201;&#20040;&#65288;&#22312;&#24378;&#21270;&#23398;&#20064;&#30340;&#24773;&#20917;&#19979;&#65289;&#38590;&#20197;&#22312;&#39640;&#32500;&#32452;&#21512;&#38382;&#39064;&#19978;&#34920;&#29616;&#33391;&#22909;&#12290;&#20026;&#20102;&#20943;&#36731;&#36825;&#20123;&#32570;&#28857;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#26426;&#22120;&#23398;&#20064;&#27969;&#31243;&#65292;&#20854;&#20013;&#21253;&#21547;&#20102;&#19968;&#20010;&#32452;&#21512;&#20248;&#21270;&#23618;&#12290;&#25105;&#20204;&#23558;&#36825;&#20010;&#36890;&#29992;&#27969;&#31243;&#24212;&#29992;&#20110;&#20855;&#26377;&#35843;&#24230;&#27874;&#30340;&#21160;&#24577;&#36710;&#36742;&#36335;&#24452;&#38382;&#39064;&#65292;&#36825;&#20010;&#38382;&#39064;&#26368;&#36817;&#34987;&#25512;&#24191;&#21040;NeurIPS 2022&#30340;EURO meets NeurIPS&#36710;&#36742;&#36335;&#24452;&#35268;&#21010;&#31454;&#36187;&#20013;&#12290;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#36825;&#20010;&#27604;&#36187;&#20013;&#25490;&#21517;&#31532;&#19968;&#65292;&#36229;&#36807;&#20102;&#25152;&#26377;&#20854;&#20182;&#26041;&#27861;&#26469;&#35299;&#20915;&#25152;&#25552;&#20986;&#30340;&#21160;&#24577;&#36710;&#36742;&#36335;&#24452;&#38382;&#39064;&#12290;&#36890;&#36807;&#36825;&#39033;&#24037;&#20316;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;&#22522;&#20110;&#32452;&#21512;&#20248;&#21270;&#22686;&#24378;&#30340;&#26426;&#22120;&#23398;&#20064;&#22312;&#21160;&#24577;&#36710;&#36742;&#36335;&#24452;&#38382;&#39064;&#20013;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
With the rise of e-commerce and increasing customer requirements, logistics service providers face a new complexity in their daily planning, mainly due to efficiently handling same day deliveries. Existing multi-stage stochastic optimization approaches that allow to solve the underlying dynamic vehicle routing problem are either computationally too expensive for an application in online settings, or -- in the case of reinforcement learning -- struggle to perform well on high-dimensional combinatorial problems. To mitigate these drawbacks, we propose a novel machine learning pipeline that incorporates a combinatorial optimization layer. We apply this general pipeline to a dynamic vehicle routing problem with dispatching waves, which was recently promoted in the EURO Meets NeurIPS Vehicle Routing Competition at NeurIPS 2022. Our methodology ranked first in this competition, outperforming all other approaches in solving the proposed dynamic vehicle routing problem. With this work, we prov
&lt;/p&gt;</description></item><item><title>&#35770;&#25991;&#20171;&#32461;&#20102;&#22312;&#32447;&#38543;&#26426;&#29275;&#39039;&#31639;&#27861;&#29992;&#20110;&#20272;&#35745;&#38543;&#26426;&#21464;&#37327;&#30340;&#20960;&#20309;&#20013;&#20301;&#25968;&#65292;&#35813;&#26041;&#27861;&#26159;&#19968;&#31181;&#40065;&#26834;&#30340;&#20013;&#24515;&#36235;&#21183;&#25351;&#26631;&#65292;&#22312;&#22823;&#37327;&#25968;&#25454;&#26679;&#26412;&#20013;&#20855;&#26377;&#24191;&#27867;&#24212;&#29992;&#12290;</title><link>http://arxiv.org/abs/2304.00770</link><description>&lt;p&gt;
&#22312;&#32447;&#38543;&#26426;&#29275;&#39039;&#27861;&#20272;&#35745;&#20960;&#20309;&#20013;&#20301;&#25968;&#21450;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Online stochastic Newton methods for estimating the geometric median and applications. (arXiv:2304.00770v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.00770
&lt;/p&gt;
&lt;p&gt;
&#35770;&#25991;&#20171;&#32461;&#20102;&#22312;&#32447;&#38543;&#26426;&#29275;&#39039;&#31639;&#27861;&#29992;&#20110;&#20272;&#35745;&#38543;&#26426;&#21464;&#37327;&#30340;&#20960;&#20309;&#20013;&#20301;&#25968;&#65292;&#35813;&#26041;&#27861;&#26159;&#19968;&#31181;&#40065;&#26834;&#30340;&#20013;&#24515;&#36235;&#21183;&#25351;&#26631;&#65292;&#22312;&#22823;&#37327;&#25968;&#25454;&#26679;&#26412;&#20013;&#20855;&#26377;&#24191;&#27867;&#24212;&#29992;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#22823;&#26679;&#26412;&#30340;&#32972;&#26223;&#19979;&#65292;&#23569;&#25968;&#20010;&#20307;&#21487;&#33021;&#20250;&#30772;&#22351;&#20687;&#24179;&#22343;&#25968;&#36825;&#26679;&#30340;&#22522;&#26412;&#32479;&#35745;&#25351;&#26631;&#12290;&#33258;&#21160;&#26816;&#27979;&#36825;&#20123;&#38750;&#20856;&#22411;&#20010;&#20307;&#26159;&#22256;&#38590;&#30340;&#65292;&#26367;&#20195;&#31574;&#30053;&#26159;&#20351;&#29992;&#40065;&#26834;&#24615;&#26041;&#27861;&#12290;&#26412;&#25991;&#37325;&#28857;&#30740;&#31350;&#38543;&#26426;&#21464;&#37327;&#30340;&#20960;&#20309;&#20013;&#20301;&#25968;&#20272;&#35745;&#65292;&#23427;&#26159;&#19968;&#20010;&#40065;&#26834;&#30340;&#20013;&#24515;&#36235;&#21183;&#25351;&#26631;&#12290;&#20026;&#20102;&#22788;&#29702;&#39034;&#24207;&#21040;&#36798;&#30340;&#22823;&#37327;&#25968;&#25454;&#26679;&#26412;&#65292;&#24341;&#20837;&#20102;&#20272;&#35745;&#20960;&#20309;&#20013;&#20301;&#25968;&#30340;&#22312;&#32447;&#38543;&#26426;&#29275;&#39039;&#31639;&#27861;&#65292;&#24182;&#32473;&#20986;&#20102;&#23427;&#20204;&#30340;&#25910;&#25947;&#36895;&#24230;&#12290;&#30001;&#20110;&#20013;&#20301;&#25968;&#21644;&#28023;&#26862;&#30697;&#38453;&#30340;&#20272;&#35745;&#21487;&#20197;&#36882;&#24402;&#26356;&#26032;&#65292;&#22240;&#27492;&#25105;&#20204;&#36824;&#30830;&#23450;&#20102;&#20013;&#20301;&#25968;&#22312;&#20219;&#20309;&#25351;&#23450;&#26041;&#21521;&#19978;&#30340;&#32622;&#20449;&#21306;&#38388;&#65292;&#24182;&#36827;&#34892;&#22312;&#32447;&#32479;&#35745;&#26816;&#39564;&#12290;
&lt;/p&gt;
&lt;p&gt;
In the context of large samples, a small number of individuals might spoil basic statistical indicators like the mean. It is difficult to detect automatically these atypical individuals, and an alternative strategy is using robust approaches. This paper focuses on estimating the geometric median of a random variable, which is a robust indicator of central tendency. In order to deal with large samples of data arriving sequentially, online stochastic Newton algorithms for estimating the geometric median are introduced and we give their rates of convergence. Since estimates of the median and those of the Hessian matrix can be recursively updated, we also determine confidences intervals of the median in any designated direction and perform online statistical tests.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#38024;&#23545;&#22312;&#32447;&#26368;&#23567;&#20108;&#20056;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#31639;&#27861;&#65292;&#20197;&#25968;&#25454;&#29983;&#25104;&#27169;&#22411;&#30340;&#24615;&#36136;&#20026;&#22522;&#30784;&#65292;&#24314;&#31435;&#20102;&#39640;&#32500;&#32553;&#25918;&#26497;&#38480;&#19982;&#27874;&#21160;&#27169;&#22411;&#12290;&#22312;&#20302;&#12289;&#20013;&#12289;&#39640;&#22122;&#22768;&#35774;&#32622;&#38454;&#27573;&#65292;&#25581;&#31034;&#20102;&#36845;&#20195;&#30340;&#31934;&#30830;&#19977;&#38454;&#27573;&#30456;&#21464;&#12290;</title><link>http://arxiv.org/abs/2304.00707</link><description>&lt;p&gt;
&#20855;&#26377;&#24179;&#28369;&#21327;&#26041;&#24046;&#30340;&#22312;&#32447;&#26368;&#23567;&#20108;&#20056;SGD&#31639;&#27861;&#30340;&#39640;&#32500;&#32553;&#25918;&#26497;&#38480;&#19982;&#27874;&#21160;
&lt;/p&gt;
&lt;p&gt;
High-dimensional scaling limits and fluctuations of online least-squares SGD with smooth covariance. (arXiv:2304.00707v1 [math.PR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.00707
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#38024;&#23545;&#22312;&#32447;&#26368;&#23567;&#20108;&#20056;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#31639;&#27861;&#65292;&#20197;&#25968;&#25454;&#29983;&#25104;&#27169;&#22411;&#30340;&#24615;&#36136;&#20026;&#22522;&#30784;&#65292;&#24314;&#31435;&#20102;&#39640;&#32500;&#32553;&#25918;&#26497;&#38480;&#19982;&#27874;&#21160;&#27169;&#22411;&#12290;&#22312;&#20302;&#12289;&#20013;&#12289;&#39640;&#22122;&#22768;&#35774;&#32622;&#38454;&#27573;&#65292;&#25581;&#31034;&#20102;&#36845;&#20195;&#30340;&#31934;&#30830;&#19977;&#38454;&#27573;&#30456;&#21464;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32771;&#34385;&#25968;&#25454;&#29983;&#25104;&#27169;&#22411;&#30340;&#24615;&#36136;&#65292;&#23548;&#20986;&#20102;&#22312;&#32447;&#26368;&#23567;&#20108;&#20056;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#65288;SGD&#65289;&#31639;&#27861;&#30340;&#39640;&#32500;&#32553;&#25918;&#26497;&#38480;&#19982;&#27874;&#21160;&#12290;&#25105;&#20204;&#23558;SGD&#36845;&#20195;&#35270;&#20026;&#30456;&#20114;&#20316;&#29992;&#30340;&#31890;&#23376;&#31995;&#32479;&#65292;&#20854;&#20013;&#26399;&#26395;&#30456;&#20114;&#20316;&#29992;&#30001;&#36755;&#20837;&#30340;&#21327;&#26041;&#24046;&#32467;&#26500;&#34920;&#24449;&#12290;&#25105;&#20204;&#20551;&#35774;&#23545;&#25152;&#26377;&#36798;&#21040;&#20843;&#38454;&#30697;&#30340;&#30697;&#39034;&#28369;&#65292;&#19988;&#26080;&#38656;&#26174;&#24335;&#20551;&#35774;&#39640;&#26031;&#24615;&#65292;&#23601;&#33021;&#22815;&#24314;&#31435;&#26080;&#31351;&#32500;&#30340;&#26222;&#36890;&#24494;&#20998;&#26041;&#31243;&#65288;ODEs&#65289;&#25110;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#65288;SDEs&#65289;&#30340;&#39640;&#32500;&#32553;&#25918;&#26497;&#38480;&#21644;&#27874;&#21160;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#25581;&#31034;&#20102;&#36845;&#20195;&#30340;&#31934;&#30830;&#19977;&#38454;&#27573;&#30456;&#21464;&#65307;&#24403;&#22122;&#22768;&#26041;&#24046;&#20174;&#20302;&#12289;&#20013;&#12289;&#39640;&#22122;&#22768;&#35774;&#32622;&#26102;&#65292;&#23427;&#20174;&#36712;&#36947;&#36816;&#21160;&#21464;&#20026;&#25193;&#25955;&#36816;&#21160;&#65292;&#26368;&#32456;&#21464;&#20026;&#32431;&#38543;&#26426;&#36816;&#21160;&#12290;&#22312;&#20302;&#22122;&#22768;&#35774;&#32622;&#19979;&#65292;&#25105;&#20204;&#36827;&#19968;&#27493;&#34920;&#24449;&#20102;&#31934;&#30830;&#30340;&#27874;&#21160;&#12290;
&lt;/p&gt;
&lt;p&gt;
We derive high-dimensional scaling limits and fluctuations for the online least-squares Stochastic Gradient Descent (SGD) algorithm by taking the properties of the data generating model explicitly into consideration. Our approach treats the SGD iterates as an interacting particle system, where the expected interaction is characterized by the covariance structure of the input. Assuming smoothness conditions on moments of order up to eight orders, and without explicitly assuming Gaussianity, we establish the high-dimensional scaling limits and fluctuations in the form of infinite-dimensional Ordinary Differential Equations (ODEs) or Stochastic Differential Equations (SDEs). Our results reveal a precise three-step phase transition of the iterates; it goes from being ballistic, to diffusive, and finally to purely random behavior, as the noise variance goes from low, to moderate and finally to very-high noise setting. In the low-noise setting, we further characterize the precise fluctuation
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26102;&#38388;&#20449;&#24687;&#19982;&#30697;&#38453;&#21078;&#38754;&#30340;&#22312;&#32447;&#38146;&#31163;&#23376;&#30005;&#27744;&#33181;&#37096;&#36215;&#22987;&#28857;&#35782;&#21035;&#26041;&#27861;&#65292;&#21487;&#20351;&#29992;&#26131;&#37319;&#38598;&#30340;&#27979;&#37327;&#25968;&#25454;&#65292;&#20026;&#30005;&#27744;&#24615;&#33021;&#21464;&#21270;&#25552;&#20379;&#26089;&#26399;&#39044;&#35686;&#12290;</title><link>http://arxiv.org/abs/2304.00691</link><description>&lt;p&gt;
&#22522;&#20110;&#30697;&#38453;&#21078;&#38754;&#30340;&#38146;&#31163;&#23376;&#30005;&#27744;&#22312;&#32447;&#33181;&#37096;&#36215;&#22987;&#26816;&#27979;
&lt;/p&gt;
&lt;p&gt;
Lithium-ion Battery Online Knee Onset Detection by Matrix Profile. (arXiv:2304.00691v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.00691
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#26102;&#38388;&#20449;&#24687;&#19982;&#30697;&#38453;&#21078;&#38754;&#30340;&#22312;&#32447;&#38146;&#31163;&#23376;&#30005;&#27744;&#33181;&#37096;&#36215;&#22987;&#28857;&#35782;&#21035;&#26041;&#27861;&#65292;&#21487;&#20351;&#29992;&#26131;&#37319;&#38598;&#30340;&#27979;&#37327;&#25968;&#25454;&#65292;&#20026;&#30005;&#27744;&#24615;&#33021;&#21464;&#21270;&#25552;&#20379;&#26089;&#26399;&#39044;&#35686;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38146;&#31163;&#23376;&#30005;&#27744;&#20250;&#22312;&#21040;&#36798;&#33181;&#37096;&#36215;&#22987;&#28857;&#21518;&#36880;&#28176;&#24694;&#21270;&#24182;&#21152;&#36895;&#34928;&#20943;&#33267;&#23551;&#21629;&#32467;&#26463;&#21069;&#12290;&#22312;&#25552;&#20379;&#30005;&#27744;&#24615;&#33021;&#21464;&#21270;&#30340;&#26089;&#26399;&#39044;&#35686;&#26041;&#38754;&#65292;&#33181;&#37096;&#36215;&#22987;&#28857;&#20855;&#26377;&#20851;&#38190;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#30446;&#21069;&#20165;&#26377;&#26377;&#38480;&#30340;&#25991;&#29486;&#30740;&#31350;&#20102;&#22312;&#32447;&#33181;&#37096;&#36215;&#22987;&#28857;&#30340;&#35782;&#21035;&#12290;&#27492;&#22806;&#65292;&#20351;&#29992;&#26131;&#20110;&#37319;&#38598;&#30340;&#27979;&#37327;&#25968;&#25454;&#36827;&#34892;&#35782;&#21035;&#26159;&#38750;&#24120;&#24517;&#35201;&#30340;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20123;&#25361;&#25112;&#65292;&#36890;&#36807;&#21033;&#29992;&#25918;&#30005;&#25968;&#25454;&#20013;&#30340;&#26102;&#38388;&#20449;&#24687;&#65292;&#24320;&#21457;&#20102;&#19968;&#31181;&#22312;&#32447;&#33181;&#37096;&#36215;&#22987;&#28857;&#35782;&#21035;&#26041;&#27861;&#12290;&#39318;&#20808;&#65292;&#21033;&#29992;&#21160;&#24577;&#26102;&#38388;&#35268;&#25972;&#25552;&#21462;&#20174;&#36731;&#24494;&#30952;&#25439;&#38454;&#27573;&#24320;&#22987;&#30340;&#25918;&#30005;&#30005;&#21387;&#21608;&#26399;&#20013;&#30340;&#26102;&#38388;&#21160;&#24577;&#21464;&#21270;&#12290;&#28982;&#21518;&#65292;&#22312;&#23376;&#24207;&#21015;&#30456;&#20284;&#24615;&#25628;&#32034;&#26399;&#38388;&#65292;&#21033;&#29992;&#30697;&#38453;&#21078;&#38754;&#26292;&#38706;&#24322;&#24120;&#12290;&#24403;&#26032;&#21608;&#26399;&#30340;&#26102;&#38388;&#21160;&#24577;&#36229;&#36807;&#25511;&#21046;&#26497;&#38480;&#19988;&#21078;&#38754;&#25351;&#25968;&#34920;&#31034;&#20986;&#21046;&#24230;&#21464;&#21270;&#26102;&#65292;&#26816;&#27979;&#21040;&#33181;&#37096;&#36215;&#22987;&#28857;&#12290;&#26368;&#21518;&#65292;&#37319;&#29992;&#23454;&#39564;&#32467;&#26524;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#26041;&#27861;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Lithium-ion batteries (LiBs) degrade slightly until the knee onset, after which the deterioration accelerates to end of life (EOL). The knee onset, which marks the initiation of the accelerated degradation rate, is crucial in providing an early warning of the battery's performance changes. However, there is only limited literature on online knee onset identification. Furthermore, it is good to perform such identification using easily collected measurements. To solve these challenges, an online knee onset identification method is developed by exploiting the temporal information within the discharge data. First, the temporal dynamics embedded in the discharge voltage cycles from the slight degradation stage are extracted by the dynamic time warping. Second, the anomaly is exposed by Matrix Profile during subsequence similarity search. The knee onset is detected when the temporal dynamics of the new cycle exceed the control limit and the profile index indicates a change in regime. Finally
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#30340;&#25512;&#33616;&#29289;&#21697;&#26041;&#27861;&#65292;&#21463;&#21040;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#25216;&#26415;&#30340;&#21551;&#21457;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#22788;&#29702;&#29992;&#25143;&#22810;&#27425;&#19982;&#21516;&#19968;&#29289;&#21697;&#20132;&#20114;&#25110;&#29992;&#25143;&#20559;&#22909;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#24773;&#20917;&#12290;</title><link>http://arxiv.org/abs/2304.00578</link><description>&lt;p&gt;
&#38754;&#21521;&#22810;&#27425;&#37325;&#22797;&#29992;&#25143;-&#29289;&#21697;&#20132;&#20114;&#30340;&#24207;&#21015;&#24863;&#30693;&#29289;&#21697;&#25512;&#33616;
&lt;/p&gt;
&lt;p&gt;
Sequence-aware item recommendations for multiply repeated user-item interactions. (arXiv:2304.00578v1 [cs.IR])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.00578
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#30340;&#25512;&#33616;&#29289;&#21697;&#26041;&#27861;&#65292;&#21463;&#21040;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#25216;&#26415;&#30340;&#21551;&#21457;&#65292;&#21487;&#20197;&#26377;&#25928;&#22320;&#22788;&#29702;&#29992;&#25143;&#22810;&#27425;&#19982;&#21516;&#19968;&#29289;&#21697;&#20132;&#20114;&#25110;&#29992;&#25143;&#20559;&#22909;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25512;&#33616;&#31995;&#32479;&#26159;&#26426;&#22120;&#23398;&#20064;&#21644;&#25968;&#25454;&#31185;&#23398;&#26368;&#25104;&#21151;&#30340;&#24212;&#29992;&#20043;&#19968;&#65292;&#22312;&#30005;&#23376;&#21830;&#21153;&#12289;&#23186;&#20307;&#27969;&#20869;&#23481;&#12289;&#30005;&#23376;&#37038;&#20214;&#33829;&#38144;&#31561;&#21508;&#31181;&#24212;&#29992;&#39046;&#22495;&#21462;&#24471;&#20102;&#25104;&#21151;&#12290;&#36825;&#20123;&#31995;&#32479;&#30340;&#20027;&#35201;&#30446;&#26631;&#26159;&#20998;&#26512;&#36807;&#21435;&#30340;&#29992;&#25143;&#34892;&#20026;&#26469;&#39044;&#27979;&#21738;&#20123;&#29289;&#21697;&#26368;&#21463;&#29992;&#25143;&#21916;&#29233;&#12290;&#23427;&#20204;&#36890;&#24120;&#20351;&#29992;&#30697;&#38453;&#23436;&#25104;&#25216;&#26415;&#65288;&#22914;&#21327;&#21516;&#36807;&#28388;&#25110;&#30697;&#38453;&#20998;&#35299;&#65289;&#36827;&#34892;&#26500;&#24314;&#12290;&#28982;&#32780;&#65292;&#23613;&#31649;&#22312;&#35768;&#22810;&#23454;&#38469;&#24212;&#29992;&#20013;&#36825;&#20123;&#26041;&#27861;&#21462;&#24471;&#20102;&#24040;&#22823;&#25104;&#21151;&#65292;&#20294;&#22312;&#29992;&#25143;&#21487;&#33021;&#22810;&#27425;&#19982;&#21516;&#19968;&#29289;&#21697;&#36827;&#34892;&#20132;&#20114;&#25110;&#29992;&#25143;&#20559;&#22909;&#38543;&#26102;&#38388;&#21464;&#21270;&#30340;&#24773;&#20917;&#19979;&#65292;&#23427;&#20204;&#30340;&#26377;&#25928;&#24615;&#20173;&#28982;&#21463;&#21040;&#38480;&#21046;&#12290;&#25105;&#20204;&#21463;&#21040;&#33258;&#28982;&#35821;&#35328;&#22788;&#29702;&#25216;&#26415;&#22788;&#29702;&#21644;&#20998;&#26512;&#25991;&#26412;&#24207;&#21015;&#30340;&#21551;&#21457;&#65292;&#35774;&#35745;&#20102;&#19968;&#31181;&#26032;&#26041;&#27861;&#26469;&#25512;&#33616;&#29289;&#21697;&#12290;
&lt;/p&gt;
&lt;p&gt;
Recommender systems are one of the most successful applications of machine learning and data science. They are successful in a wide variety of application domains, including e-commerce, media streaming content, email marketing, and virtually every industry where personalisation facilitates better user experience or boosts sales and customer engagement. The main goal of these systems is to analyse past user behaviour to predict which items are of most interest to users. They are typically built with the use of matrix-completion techniques such as collaborative filtering or matrix factorisation. However, although these approaches have achieved tremendous success in numerous real-world applications, their effectiveness is still limited when users might interact multiple times with the same items, or when user preferences change over time.  We were inspired by the approach that Natural Language Processing techniques take to compress, process, and analyse sequences of text. We designed a re
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26102;&#24207;&#26694;&#26550;&#65292;&#33021;&#22815;&#39044;&#27979;&#38750;&#21512;&#21516;&#24773;&#20917;&#19979;&#21738;&#20123;&#23458;&#25143;&#23384;&#22312;&#27969;&#22833;&#39118;&#38505;&#65292;&#36825;&#31181;&#27169;&#22411;&#21482;&#38656;&#35201;&#22522;&#20110;&#23458;&#25143;&#34892;&#20026;&#23601;&#33021;&#33719;&#24471;&#20855;&#26377;&#20010;&#20307;&#29305;&#24449;&#30340;&#29983;&#23384;&#27169;&#22411;&#65292;&#36991;&#20813;&#20102;&#32321;&#29712;&#32780;&#32791;&#26102;&#30340;&#29305;&#24449;&#24037;&#31243;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2304.00575</link><description>&lt;p&gt;
&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#26102;&#24207;&#26694;&#26550;&#30340;&#38646;&#21806;&#23458;&#25143;&#27969;&#22833;&#24314;&#27169;
&lt;/p&gt;
&lt;p&gt;
Modelling customer churn for the retail industry in a deep learning based sequential framework. (arXiv:2304.00575v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.00575
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#22522;&#20110;&#28145;&#24230;&#23398;&#20064;&#30340;&#26102;&#24207;&#26694;&#26550;&#65292;&#33021;&#22815;&#39044;&#27979;&#38750;&#21512;&#21516;&#24773;&#20917;&#19979;&#21738;&#20123;&#23458;&#25143;&#23384;&#22312;&#27969;&#22833;&#39118;&#38505;&#65292;&#36825;&#31181;&#27169;&#22411;&#21482;&#38656;&#35201;&#22522;&#20110;&#23458;&#25143;&#34892;&#20026;&#23601;&#33021;&#33719;&#24471;&#20855;&#26377;&#20010;&#20307;&#29305;&#24449;&#30340;&#29983;&#23384;&#27169;&#22411;&#65292;&#36991;&#20813;&#20102;&#32321;&#29712;&#32780;&#32791;&#26102;&#30340;&#29305;&#24449;&#24037;&#31243;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#30528;&#19990;&#30028;&#21508;&#22320;&#30340;&#38646;&#21806;&#21830;&#22686;&#21152;&#38024;&#23545;&#19981;&#21516;&#21463;&#20247;&#30340;&#23450;&#21521;&#33829;&#38144;&#27963;&#21160;&#65292;&#20934;&#30830;&#39044;&#27979;&#21738;&#20123;&#23458;&#25143;&#26368;&#26377;&#21487;&#33021;&#27969;&#22833;&#23545;&#20110;&#33829;&#38144;&#22242;&#38431;&#26469;&#35828;&#33267;&#20851;&#37325;&#35201;&#65292;&#20197;&#22686;&#21152;&#19994;&#21153;&#21033;&#28070;&#12290;&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#28145;&#24230;&#29983;&#23384;&#26694;&#26550;&#65292;&#29992;&#20110;&#39044;&#27979;&#21738;&#20123;&#23458;&#25143;&#22312;&#38750;&#21512;&#21516;&#24773;&#20917;&#19979;&#20572;&#27490;&#19982;&#38646;&#21806;&#20844;&#21496;&#36141;&#20080;&#12290;&#36890;&#36807;&#21033;&#29992;&#24490;&#29615;&#31070;&#32463;&#32593;&#32476;&#23398;&#20064;&#29983;&#23384;&#27169;&#22411;&#21442;&#25968;&#65292;&#25105;&#20204;&#33021;&#22815;&#20165;&#22522;&#20110;&#23458;&#25143;&#34892;&#20026;&#33719;&#21462;&#22522;&#20110;&#20010;&#20307;&#27700;&#24179;&#28040;&#36153;&#34892;&#20026;&#30340;&#29983;&#23384;&#27169;&#22411;&#65292;&#36991;&#20813;&#35757;&#32451;&#26426;&#22120;&#23398;&#20064;&#27169;&#22411;&#26102;&#32791;&#26102;&#30340;&#29305;&#24449;&#24037;&#31243;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
As retailers around the world increase efforts in developing targeted marketing campaigns for different audiences, predicting accurately which customers are most likely to churn ahead of time is crucial for marketing teams in order to increase business profits. This work presents a deep survival framework to predict which customers are at risk of stopping to purchase with retail companies in non-contractual settings. By leveraging the survival model parameters to be learnt by recurrent neural networks, we are able to obtain individual level survival models for purchasing behaviour based only on individual customer behaviour and avoid time-consuming feature engineering processes usually done when training machine learning models.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;copula&#30340;&#23494;&#24230;&#20272;&#35745;&#27169;&#22411;&#65292;&#21487;&#20197;&#22788;&#29702;&#22810;&#20803;&#30456;&#20851;&#24615;&#30340;&#38646;&#33192;&#32960;&#36830;&#32493;&#21464;&#37327;&#65292;&#24341;&#20837;&#30699;&#27491;&#39640;&#26031;copula&#20197;&#24212;&#23545;&#32465;&#23450;&#25968;&#25454;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#39640;&#25928;&#30340;&#26041;&#27861;&#36827;&#34892;&#21442;&#25968;&#20272;&#35745;&#21644;&#21487;&#33021;&#24615;&#35745;&#31639;&#12290;</title><link>http://arxiv.org/abs/2304.00537</link><description>&lt;p&gt;
&#22522;&#20110;Copula&#30340;&#22810;&#20803;&#38646;&#33192;&#32960;&#36830;&#32493;&#25968;&#25454;&#23494;&#24230;&#20272;&#35745;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Copula-Based Density Estimation Models for Multivariate Zero-Inflated Continuous Data. (arXiv:2304.00537v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.00537
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;copula&#30340;&#23494;&#24230;&#20272;&#35745;&#27169;&#22411;&#65292;&#21487;&#20197;&#22788;&#29702;&#22810;&#20803;&#30456;&#20851;&#24615;&#30340;&#38646;&#33192;&#32960;&#36830;&#32493;&#21464;&#37327;&#65292;&#24341;&#20837;&#30699;&#27491;&#39640;&#26031;copula&#20197;&#24212;&#23545;&#32465;&#23450;&#25968;&#25454;&#38382;&#39064;&#65292;&#24182;&#25552;&#20986;&#39640;&#25928;&#30340;&#26041;&#27861;&#36827;&#34892;&#21442;&#25968;&#20272;&#35745;&#21644;&#21487;&#33021;&#24615;&#35745;&#31639;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38646;&#33192;&#32960;&#36830;&#32493;&#25968;&#25454;&#22312;&#35768;&#22810;&#39046;&#22495;&#20013;&#26222;&#36941;&#20986;&#29616;&#65292;&#20854;&#20013;&#35266;&#23519;&#21040;&#35768;&#22810;&#23436;&#20840;&#20026;&#38646;&#20540;&#25968;&#25454;&#65292;&#32780;&#20854;&#20182;&#25968;&#25454;&#21017;&#20197;&#36830;&#32493;&#26041;&#24335;&#20998;&#24067;&#12290;&#30001;&#20110;&#20854;&#20998;&#24067;&#20013;&#31163;&#25955;&#21644;&#36830;&#32493;&#30340;&#28151;&#21512;&#32467;&#26500;&#65292;&#22810;&#20803;&#24773;&#20917;&#19979;&#30340;&#32479;&#35745;&#20998;&#26512;&#38750;&#24120;&#20855;&#26377;&#25361;&#25112;&#24615;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;&#20004;&#31181;&#22522;&#20110;copula&#30340;&#23494;&#24230;&#20272;&#35745;&#27169;&#22411;&#65292;&#21487;&#20197;&#22788;&#29702;&#38646;&#33192;&#32960;&#36830;&#32493;&#21464;&#37327;&#20043;&#38388;&#30340;&#22810;&#20803;&#30456;&#20851;&#24615;&#12290;&#20026;&#20102;&#20811;&#26381;&#30001;&#20110;&#38646;&#33192;&#32960;&#25968;&#25454;&#20013;&#30340;&#32465;&#23450;&#25968;&#25454;&#38382;&#39064;&#20351;&#29992;copulas&#30340;&#22256;&#38590;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#31867;&#22411;&#30340;copula&#65292;&#21363;&#30699;&#27491;&#39640;&#26031;copula&#65292;&#24182;&#25552;&#20986;&#20102;&#21442;&#25968;&#20272;&#35745;&#21644;&#21487;&#33021;&#24615;&#35745;&#31639;&#30340;&#39640;&#25928;&#26041;&#27861;&#12290;&#25968;&#20540;&#23454;&#39564;&#35777;&#26126;&#20102;&#25105;&#20204;&#30340;&#25552;&#35758;&#30456;&#23545;&#20110;&#20256;&#32479;&#23494;&#24230;&#20272;&#35745;&#26041;&#27861;&#30340;&#20248;&#36234;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Zero-inflated continuous data ubiquitously appear in many fields, in which lots of exactly zero-valued data are observed while others distribute continuously. Due to the mixed structure of discreteness and continuity in its distribution, statistical analysis is challenging especially for multivariate case. In this paper, we propose two copula-based density estimation models that can cope with multivariate correlation among zero-inflated continuous variables. In order to overcome the difficulty in the use of copulas due to the tied-data problem in zero-inflated data, we propose a new type of copula, rectified Gaussian copula, and present efficient methods for parameter estimation and likelihood computation. Numerical experiments demonstrates the superiority of our proposals compared to conventional density estimation methods.
&lt;/p&gt;</description></item><item><title>TSCI &#25552;&#20986;&#20102;&#26080;&#25928;&#20202;&#22120;&#26465;&#20214;&#19979;&#20351;&#29992;&#20004;&#38454;&#27573;&#31639;&#27861;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#65292;&#19981;&#38656;&#35201;&#24378;&#35782;&#21035;&#20551;&#35774;&#65292;&#21487;&#36890;&#36807;&#25968;&#25454;&#33258;&#36866;&#24212;&#26041;&#24335;&#25429;&#25417;&#20202;&#22120;&#36829;&#35268;&#34892;&#20026;&#12290;</title><link>http://arxiv.org/abs/2304.00513</link><description>&lt;p&gt;
TSCI&#65306;&#20351;&#29992;&#20004;&#38454;&#27573;&#26354;&#29575;&#35782;&#21035;&#22312;&#26080;&#25928;&#20202;&#22120;&#19979;&#25191;&#34892;&#22240;&#26524;&#25512;&#26029;
&lt;/p&gt;
&lt;p&gt;
TSCI: two stage curvature identification for causal inference with invalid instruments. (arXiv:2304.00513v1 [stat.ME])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.00513
&lt;/p&gt;
&lt;p&gt;
TSCI &#25552;&#20986;&#20102;&#26080;&#25928;&#20202;&#22120;&#26465;&#20214;&#19979;&#20351;&#29992;&#20004;&#38454;&#27573;&#31639;&#27861;&#36827;&#34892;&#22240;&#26524;&#25512;&#26029;&#65292;&#19981;&#38656;&#35201;&#24378;&#35782;&#21035;&#20551;&#35774;&#65292;&#21487;&#36890;&#36807;&#25968;&#25454;&#33258;&#36866;&#24212;&#26041;&#24335;&#25429;&#25417;&#20202;&#22120;&#36829;&#35268;&#34892;&#20026;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
TSCI &#22312; R &#32479;&#35745;&#35745;&#31639;&#29615;&#22659;&#20013;&#25191;&#34892;&#35266;&#27979;&#25968;&#25454;&#19979;&#30340;&#27835;&#30103;&#25928;&#24212;&#20272;&#35745;&#65292;&#21363;&#20351;&#20202;&#22120;&#26080;&#25928;&#20063;&#21487;&#26377;&#25928;&#36816;&#34892;&#12290;&#29616;&#26377;&#30340;&#20202;&#22120;&#21464;&#37327;&#26041;&#27861;&#20381;&#36182;&#20110;&#24378;&#19988;&#38590;&#20197;&#39564;&#35777;&#30340;&#35782;&#21035;&#20551;&#35774;&#65292;&#36825;&#38480;&#21046;&#20102;&#23427;&#20204;&#30340;&#23454;&#38469;&#24212;&#29992;&#12290;TSCI &#19981;&#38656;&#35201;&#32463;&#20856;&#30340;&#20202;&#22120;&#21464;&#37327;&#35782;&#21035;&#26465;&#20214;&#65292;&#36890;&#36807;&#20004;&#38454;&#27573;&#31639;&#27861;&#23454;&#29616;&#12290;&#22312;&#31532;&#19968;&#38454;&#27573;&#65292;&#26426;&#22120;&#23398;&#20064;&#29992;&#20110;&#22788;&#29702;&#27835;&#30103;&#27169;&#22411;&#20013;&#30340;&#38750;&#32447;&#24615;&#21644;&#20132;&#20114;&#20316;&#29992;&#12290;&#22312;&#31532;&#20108;&#38454;&#27573;&#65292;&#36890;&#36807;&#25968;&#25454;&#33258;&#36866;&#24212;&#26041;&#24335;&#36873;&#25321;&#31354;&#38388;&#26469;&#25429;&#25417;&#20202;&#22120;&#36829;&#35268;&#34892;&#20026;&#65292;&#28982;&#21518;&#23558;&#36825;&#20123;&#36829;&#35268;&#34892;&#20026;&#25237;&#24433;&#20986;&#26469;&#20197;&#20272;&#35745;&#27835;&#30103;&#25928;&#24212;&#12290;
&lt;/p&gt;
&lt;p&gt;
TSCI implements treatment effect estimation from observational data under invalid instruments in the R statistical computing environment. Existing instrumental variable approaches rely on arguably strong and untestable identification assumptions, which limits their practical application. TSCI does not require the classical instrumental variable identification conditions and is effective even if all instruments are invalid. TSCI implements a two-stage algorithm. In the first stage, machine learning is used to cope with nonlinearities and interactions in the treatment model. In the second stage, a space to capture the instrument violations is selected in a data-adaptive way. These violations are then projected out to estimate the treatment effect.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#35777;&#26126;&#20102;&#19968;&#31867;&#26032;&#30340;&#27010;&#24565;&#31867;&#21035;&#30340;&#20648;&#22791;&#35745;&#31639;&#36924;&#36817;&#21644;&#27867;&#21270;&#36793;&#30028;&#65292;&#20351;&#24471;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#23454;&#29616;&#24615;&#33021;&#12290;</title><link>http://arxiv.org/abs/2304.00490</link><description>&lt;p&gt;
&#26080;&#38480;&#32500;&#20648;&#22791;&#35745;&#31639;
&lt;/p&gt;
&lt;p&gt;
Infinite-dimensional reservoir computing. (arXiv:2304.00490v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.00490
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#19968;&#31867;&#26032;&#30340;&#27010;&#24565;&#31867;&#21035;&#30340;&#20648;&#22791;&#35745;&#31639;&#36924;&#36817;&#21644;&#27867;&#21270;&#36793;&#30028;&#65292;&#20351;&#24471;&#26426;&#22120;&#23398;&#20064;&#31639;&#27861;&#20855;&#26377;&#26356;&#22909;&#30340;&#23454;&#29616;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35777;&#26126;&#20102;&#19968;&#31867;&#26032;&#30340;&#27010;&#24565;&#31867;&#21035;&#30340;&#20648;&#22791;&#35745;&#31639;&#36924;&#36817;&#21644;&#27867;&#21270;&#36793;&#30028;&#65292;&#23558;&#25152;&#35859;&#30340;&#24191;&#20041;Barron&#20989;&#25968;&#25193;&#23637;&#21040;&#21160;&#24577;&#29615;&#22659;&#12290;&#36825;&#20010;&#26032;&#31867;&#21035;&#30340;&#29305;&#24449;&#26159;&#20855;&#26377;&#26576;&#31181;&#31215;&#20998;&#34920;&#31034;&#30340;&#35835;&#20986;&#65292;&#24314;&#31435;&#22312;&#26080;&#38480;&#32500;&#29366;&#24577;&#31354;&#38388;&#31995;&#32479;&#19978;&#12290;&#32467;&#26524;&#34920;&#26126;&#65292;&#36825;&#20010;&#31867;&#21035;&#38750;&#24120;&#20016;&#23500;&#65292;&#24182;&#20855;&#26377;&#26377;&#29992;&#30340;&#29305;&#28857;&#21644;&#20840;&#23616;&#36924;&#36817;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;
Reservoir computing approximation and generalization bounds are proved for a new concept class of input/output systems that extends the so-called generalized Barron functionals to a dynamic context. This new class is characterized by the readouts with a certain integral representation built on infinite-dimensional state-space systems. It is shown that this class is very rich and possesses useful features and universal approximation properties. The reservoir architectures used for the approximation and estimation of elements in the new class are randomly generated echo state networks with either linear or ReLU activation functions. Their readouts are built using randomly generated neural networks in which only the output layer is trained (extreme learning machines or random feature neural networks). The results in the paper yield a fully implementable recurrent neural network-based learning algorithm with provable convergence guarantees that do not suffer from the curse of dimensionalit
&lt;/p&gt;</description></item><item><title>&#36890;&#36807;&#19968;&#20010;&#26032;&#30340;&#20844;&#24335;&#65292;&#26412;&#25991;&#29702;&#35770;&#20998;&#26512;&#20102;&#22522;&#20110;&#26680;&#30340;&#23545;&#27604;&#23398;&#20064;&#25439;&#22833;&#30340;&#29305;&#28857;&#65292;&#35777;&#26126;&#20102;&#23427;&#33021;&#25551;&#36848;&#23398;&#20064;&#34920;&#31034;&#30340;&#32467;&#26500;&#21644;&#34920;&#29616;&#65292;&#25552;&#20379;&#19968;&#20010;&#26032;&#30340;&#38480;&#21046;&#26041;&#27861;&#65292;&#24182;&#22312;&#22810;&#20010;&#22522;&#20934;&#27979;&#35797;&#20013;&#39564;&#35777;&#20854;&#26377;&#25928;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.00395</link><description>&lt;p&gt;
&#36890;&#36807;&#30456;&#20284;&#24615;&#32467;&#26500;&#35299;&#26512;&#23545;&#27604;&#23398;&#20064;&#26426;&#21046;&#65306;&#29702;&#35770;&#20998;&#26512;
&lt;/p&gt;
&lt;p&gt;
Towards Understanding the Mechanism of Contrastive Learning via Similarity Structure: A Theoretical Analysis. (arXiv:2304.00395v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.00395
&lt;/p&gt;
&lt;p&gt;
&#36890;&#36807;&#19968;&#20010;&#26032;&#30340;&#20844;&#24335;&#65292;&#26412;&#25991;&#29702;&#35770;&#20998;&#26512;&#20102;&#22522;&#20110;&#26680;&#30340;&#23545;&#27604;&#23398;&#20064;&#25439;&#22833;&#30340;&#29305;&#28857;&#65292;&#35777;&#26126;&#20102;&#23427;&#33021;&#25551;&#36848;&#23398;&#20064;&#34920;&#31034;&#30340;&#32467;&#26500;&#21644;&#34920;&#29616;&#65292;&#25552;&#20379;&#19968;&#20010;&#26032;&#30340;&#38480;&#21046;&#26041;&#27861;&#65292;&#24182;&#22312;&#22810;&#20010;&#22522;&#20934;&#27979;&#35797;&#20013;&#39564;&#35777;&#20854;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#27604;&#23398;&#20064;&#26159;&#19968;&#31181;&#26377;&#25928;&#30340;&#33258;&#30417;&#30563;&#34920;&#31034;&#23398;&#20064;&#26041;&#27861;&#12290;&#34429;&#28982;&#36817;&#26399;&#30340;&#30740;&#31350;&#22312;&#29702;&#35770;&#19978;&#23545;&#23545;&#27604;&#23398;&#20064;&#26377;&#20102;&#19968;&#23450;&#30340;&#20102;&#35299;&#65292;&#20294;&#23545;&#20110;&#22914;&#20309;&#34920;&#24449;&#23398;&#20064;&#34920;&#31034;&#30340;&#32858;&#31867;&#20173;&#28982;&#26377;&#38480;&#12290;&#26412;&#25991;&#26088;&#22312;&#20174;&#29702;&#35770;&#35282;&#24230;&#38416;&#26126;&#36825;&#31181;&#32858;&#31867;&#30340;&#29305;&#24449;&#12290;&#20026;&#27492;&#65292;&#25105;&#20204;&#32771;&#34385;&#19968;&#31181;&#22522;&#20110;&#26680;&#30340;&#23545;&#27604;&#23398;&#20064;&#26694;&#26550;&#65292;&#31216;&#20026;&#26680;&#23545;&#27604;&#23398;&#20064;&#65288;KCL&#65289;&#65292;&#26680;&#20989;&#25968;&#22312;&#23558;&#25105;&#20204;&#30340;&#29702;&#35770;&#32467;&#26524;&#24212;&#29992;&#20110;&#20854;&#20182;&#26694;&#26550;&#26102;&#36215;&#37325;&#35201;&#20316;&#29992;&#12290;&#25105;&#20204;&#21033;&#29992;&#32479;&#35745;&#20381;&#36182;&#35266;&#28857;&#24341;&#20837;&#19968;&#20010;&#23398;&#20064;&#34920;&#31034;&#30340;&#30456;&#20284;&#24615;&#32467;&#26500;&#30340;&#20844;&#24335;&#12290;&#25105;&#20204;&#36890;&#36807;&#36825;&#20010;&#20844;&#24335;&#30740;&#31350;&#20102;&#22522;&#20110;&#26680;&#30340;&#23545;&#27604;&#25439;&#22833;&#30340;&#29702;&#35770;&#24615;&#36136;&#12290;&#25105;&#20204;&#39318;&#20808;&#35777;&#26126;&#36825;&#20010;&#20844;&#24335;&#34920;&#24449;&#20102;&#21033;&#29992;&#26680;&#23545;&#27604;&#23398;&#20064;&#26694;&#26550;&#23398;&#20064;&#30340;&#34920;&#31034;&#32467;&#26500;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#19968;&#20010;&#26032;&#30340;&#19978;&#30028;&#65292;&#23545;&#20110;&#36127;&#26679;&#26412;&#30340;&#36793;&#38469;&#20998;&#24067;&#26377;&#19968;&#20010;&#28201;&#21644;&#30340;&#26465;&#20214;&#65292;&#26399;&#26395;&#23545;&#27604;&#25439;&#22833;&#21463;&#21040;&#38480;&#21046;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#30830;&#23450;&#20102;&#22522;&#20110;&#26680;&#30340;&#23545;&#27604;&#25439;&#22833;&#26159;&#19968;&#31181;&#26032;&#30340;&#20449;&#24687;&#35770;&#19979;&#30028;&#30340;&#29305;&#20363;&#65292;&#36825;&#20419;&#20351;&#25105;&#20204;&#24320;&#21457;&#19968;&#20010;&#26032;&#30340;&#30446;&#26631;&#65292;&#21487;&#20197;&#36827;&#19968;&#27493;&#32422;&#26463;&#23398;&#20064;&#34920;&#31034;&#22312;&#36755;&#20837;&#30340;&#20146;&#23494;&#24615;&#21644;&#19981;&#21516;&#26679;&#26412;&#20043;&#38388;&#30340;&#21487;&#20998;&#24615;&#26041;&#38754;&#12290;&#26368;&#21518;&#65292;&#25105;&#20204;&#22312;&#20960;&#20010;&#22522;&#20934;&#27979;&#35797;&#19978;&#36827;&#34892;&#20102;&#23454;&#39564;&#65292;&#36825;&#20123;&#23454;&#39564;&#25903;&#25345;&#25105;&#20204;&#30340;&#29702;&#35770;&#21457;&#29616;&#65292;&#24182;&#34920;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#30446;&#26631;&#30340;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
Contrastive learning is an efficient approach to self-supervised representation learning. Although recent studies have made progress in the theoretical understanding of contrastive learning, the investigation of how to characterize the clusters of the learned representations is still limited. In this paper, we aim to elucidate the characterization from theoretical perspectives. To this end, we consider a kernel-based contrastive learning framework termed Kernel Contrastive Learning (KCL), where kernel functions play an important role when applying our theoretical results to other frameworks. We introduce a formulation of the similarity structure of learned representations by utilizing a statistical dependency viewpoint. We investigate the theoretical properties of the kernel-based contrastive loss via this formulation. We first prove that the formulation characterizes the structure of representations learned with the kernel-based contrastive learning framework. We show a new upper boun
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#38750;&#24179;&#31283;&#24378;&#21270;&#23398;&#20064;&#29615;&#22659;&#30340;&#31639;&#27861;&#65292;&#31216;&#20026;R-BOCPD-UCRL2&#65292;&#23427;&#20351;&#29992;&#20102;&#19968;&#31181;&#37325;&#26032;&#21551;&#21160;&#30340;&#36125;&#21494;&#26031;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#31639;&#27861;&#65288;R-BOCPD&#65289;&#65292;&#24182;&#22312;&#22810;&#39033;&#24335;&#20998;&#24067;&#37319;&#26679;&#30340;MDP&#19978;&#25552;&#20379;&#20102;&#36739;&#20248;&#31168;&#30340;&#24615;&#33021;&#20445;&#35777;&#12290;</title><link>http://arxiv.org/abs/2304.00232</link><description>&lt;p&gt;
&#37325;&#21551;&#36125;&#21494;&#26031;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#29992;&#20110;&#38750;&#24179;&#31283;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;
&lt;/p&gt;
&lt;p&gt;
Restarted Bayesian Online Change-point Detection for Non-Stationary Markov Decision Processes. (arXiv:2304.00232v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.00232
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;&#38750;&#24179;&#31283;&#24378;&#21270;&#23398;&#20064;&#29615;&#22659;&#30340;&#31639;&#27861;&#65292;&#31216;&#20026;R-BOCPD-UCRL2&#65292;&#23427;&#20351;&#29992;&#20102;&#19968;&#31181;&#37325;&#26032;&#21551;&#21160;&#30340;&#36125;&#21494;&#26031;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#31639;&#27861;&#65288;R-BOCPD&#65289;&#65292;&#24182;&#22312;&#22810;&#39033;&#24335;&#20998;&#24067;&#37319;&#26679;&#30340;MDP&#19978;&#25552;&#20379;&#20102;&#36739;&#20248;&#31168;&#30340;&#24615;&#33021;&#20445;&#35777;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#32771;&#34385;&#22312;&#19968;&#20010;&#38750;&#24179;&#31283;&#30340;&#24378;&#21270;&#23398;&#20064;&#65288;RL&#65289;&#29615;&#22659;&#20013;&#36827;&#34892;&#23398;&#20064;&#30340;&#38382;&#39064;&#65292;&#20854;&#20013;&#35813;&#35774;&#32622;&#21487;&#20197;&#34987;&#23436;&#20840;&#25551;&#36848;&#20026;&#20998;&#27573;&#24179;&#31283;&#30340;&#31163;&#25955;&#26102;&#38388;&#39532;&#23572;&#31185;&#22827;&#20915;&#31574;&#36807;&#31243;&#65288;MDP&#65289;&#12290;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#37325;&#26032;&#21551;&#21160;&#30340;&#36125;&#21494;&#26031;&#22312;&#32447;&#21464;&#28857;&#26816;&#27979;&#31639;&#27861;&#65288;R-BOCPD&#65289;&#21464;&#20307;&#65292;&#35813;&#31639;&#27861;&#36866;&#29992;&#20110;&#20174;&#26356;&#19968;&#33324;&#30340;&#22810;&#39033;&#24335;&#20998;&#24067;&#20013;&#29983;&#25104;&#30340;&#36755;&#20837;&#27969;&#65292;&#24182;&#22312;&#35823;&#35686;&#29575;&#21644;&#26816;&#27979;&#24310;&#36831;&#26041;&#38754;&#25552;&#20379;&#25509;&#36817;&#26368;&#20248;&#30340;&#29702;&#35770;&#20445;&#35777;&#12290;&#22522;&#20110;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#20174;&#22810;&#39033;&#24335;&#20998;&#24067;&#20013;&#37319;&#26679;&#30340;&#29366;&#24577;&#36716;&#31227;&#20869;&#26680;&#30340;MDPs&#30340;&#25913;&#36827;&#29256;&#26412;UCRL2&#31639;&#27861;&#65292;&#25105;&#20204;&#31216;&#20043;&#20026;R-BOCPD-UCRL2&#12290;&#25105;&#20204;&#36827;&#34892;&#20102;&#26377;&#38480;&#26102;&#38388;&#30340;&#24615;&#33021;&#20998;&#26512;&#65292;&#24182;&#34920;&#26126;R-BOCPD-UCRL2&#20855;&#26377;&#26377;&#21033;&#30340;&#36951;&#25022;&#30028;&#30340;$O\left(D O \sqrt{A T K_T \log\left (\frac{T}{\delta} \right) + \frac{K_T \log \frac{K_T}{\delta}}{\min\limits_\ell \: \mathbf{KL}\left( {\mathbf{\theta}^{(\ell+1)}}\mid\mid{\mathbf{\theta}^{(\ell)}}\right)}}\right)$&#12290;
&lt;/p&gt;
&lt;p&gt;
We consider the problem of learning in a non-stationary reinforcement learning (RL) environment, where the setting can be fully described by a piecewise stationary discrete-time Markov decision process (MDP). We introduce a variant of the Restarted Bayesian Online Change-Point Detection algorithm (R-BOCPD) that operates on input streams originating from the more general multinomial distribution and provides near-optimal theoretical guarantees in terms of false-alarm rate and detection delay. Based on this, we propose an improved version of the UCRL2 algorithm for MDPs with state transition kernel sampled from a multinomial distribution, which we call R-BOCPD-UCRL2. We perform a finite-time performance analysis and show that R-BOCPD-UCRL2 enjoys a favorable regret bound of $O\left(D O \sqrt{A T K_T \log\left (\frac{T}{\delta} \right) + \frac{K_T \log \frac{K_T}{\delta}}{\min\limits_\ell \: \mathbf{KL}\left( {\mathbf{\theta}^{(\ell+1)}}\mid\mid{\mathbf{\theta}^{(\ell)}}\right)}}\right)$,
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#22411;&#25193;&#25955;&#26144;&#23556;&#31890;&#23376;&#31995;&#32479;(DMPS)&#65292;&#21487;&#20197;&#29992;&#20110;&#39640;&#25928;&#29983;&#25104;&#24314;&#27169;&#65292;&#23454;&#39564;&#34920;&#26126;&#22312;&#21253;&#21547;&#27969;&#24418;&#32467;&#26500;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#27604;&#20854;&#20182;&#26041;&#27861;&#26356;&#22909;&#30340;&#25928;&#26524;&#12290;</title><link>http://arxiv.org/abs/2304.00200</link><description>&lt;p&gt;
&#22522;&#20110;&#25193;&#25955;&#26144;&#23556;&#30340;&#31890;&#23376;&#31995;&#32479;&#29992;&#20110;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Diffusion map particle systems for generative modeling. (arXiv:2304.00200v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.00200
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#19968;&#31181;&#26032;&#22411;&#25193;&#25955;&#26144;&#23556;&#31890;&#23376;&#31995;&#32479;(DMPS)&#65292;&#21487;&#20197;&#29992;&#20110;&#39640;&#25928;&#29983;&#25104;&#24314;&#27169;&#65292;&#23454;&#39564;&#34920;&#26126;&#22312;&#21253;&#21547;&#27969;&#24418;&#32467;&#26500;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#21462;&#24471;&#20102;&#27604;&#20854;&#20182;&#26041;&#27861;&#26356;&#22909;&#30340;&#25928;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#25193;&#25955;&#26144;&#23556;&#31890;&#23376;&#31995;&#32479;(DMPS)&#65292;&#29992;&#20110;&#29983;&#25104;&#24314;&#27169;&#65292;&#35813;&#26041;&#27861;&#22522;&#20110;&#25193;&#25955;&#26144;&#23556;&#21644;Laplacian&#35843;&#25972;&#30340;Wasserstein&#26799;&#24230;&#19979;&#38477;&#65288;LAWGD&#65289;&#12290;&#25193;&#25955;&#26144;&#23556;&#34987;&#29992;&#26469;&#20174;&#26679;&#26412;&#20013;&#36817;&#20284;Langevin&#25193;&#25955;&#36807;&#31243;&#30340;&#29983;&#25104;&#22120;&#65292;&#20174;&#32780;&#23398;&#20064;&#28508;&#22312;&#30340;&#25968;&#25454;&#29983;&#25104;&#27969;&#24418;&#12290;&#21478;&#19968;&#26041;&#38754;&#65292;LAWGD&#33021;&#22815;&#22312;&#21512;&#36866;&#30340;&#26680;&#20989;&#25968;&#36873;&#25321;&#19979;&#39640;&#25928;&#22320;&#20174;&#30446;&#26631;&#20998;&#24067;&#20013;&#25277;&#26679;&#65292;&#25105;&#20204;&#22312;&#36825;&#37324;&#36890;&#36807;&#25193;&#25955;&#26144;&#23556;&#35745;&#31639;&#29983;&#25104;&#22120;&#30340;&#35889;&#36924;&#36817;&#26469;&#26500;&#36896;&#26680;&#20989;&#25968;&#12290;&#25968;&#20540;&#23454;&#39564;&#34920;&#26126;&#65292;&#25105;&#20204;&#30340;&#26041;&#27861;&#22312;&#21253;&#25324;&#20855;&#26377;&#27969;&#24418;&#32467;&#26500;&#30340;&#21512;&#25104;&#25968;&#25454;&#38598;&#19978;&#20248;&#20110;&#20854;&#20182;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a novel diffusion map particle system (DMPS) for generative modeling, based on diffusion maps and Laplacian-adjusted Wasserstein gradient descent (LAWGD). Diffusion maps are used to approximate the generator of the Langevin diffusion process from samples, and hence to learn the underlying data-generating manifold. On the other hand, LAWGD enables efficient sampling from the target distribution given a suitable choice of kernel, which we construct here via a spectral approximation of the generator, computed with diffusion maps. Numerical experiments show that our method outperforms others on synthetic datasets, including examples with manifold structure.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#27969;&#24418;&#23398;&#20064;&#20013;&#24212;&#29992;&#26080;&#30896;&#25758;&#36816;&#36755;&#22270;&#30340;&#26041;&#27861;&#65292;&#20854;&#21487;&#20197;&#27604;OT&#22270;&#26356;&#20415;&#23452;&#22320;&#35745;&#31639;&#36317;&#31163;&#65292;&#24182;&#25552;&#20379;&#21333;&#20010;&#27010;&#29575;&#27979;&#24230;&#30340;&#24179;&#31227;&#21644;&#20280;&#32553;&#30340;&#31561;&#36317;&#24615;&#12290;</title><link>http://arxiv.org/abs/2304.00199</link><description>&lt;p&gt;
&#26080;&#30896;&#25758;&#36816;&#36755;&#22270;&#22312;&#27969;&#34892;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Applications of No-Collision Transportation Maps in Manifold Learning. (arXiv:2304.00199v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.00199
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#22312;&#27969;&#24418;&#23398;&#20064;&#20013;&#24212;&#29992;&#26080;&#30896;&#25758;&#36816;&#36755;&#22270;&#30340;&#26041;&#27861;&#65292;&#20854;&#21487;&#20197;&#27604;OT&#22270;&#26356;&#20415;&#23452;&#22320;&#35745;&#31639;&#36317;&#31163;&#65292;&#24182;&#25552;&#20379;&#21333;&#20010;&#27010;&#29575;&#27979;&#24230;&#30340;&#24179;&#31227;&#21644;&#20280;&#32553;&#30340;&#31561;&#36317;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#24341;&#20837;&#20110;[Nurbekyan et al.&#65292;2020]&#30340;&#26080;&#30896;&#25758;&#36816;&#36755;&#22270;&#22312;&#22270;&#20687;&#25968;&#25454;&#30340;&#27969;&#24418;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;&#12290;&#36817;&#24180;&#26469;&#65292;&#22312;&#34920;&#31034;&#31867;&#20284;&#36816;&#21160;&#25110;&#21464;&#24418;&#29616;&#35937;&#30340;&#25968;&#25454;&#20013;&#65292;&#24212;&#29992;&#22522;&#20110;&#36816;&#36755;&#30340;&#36317;&#31163;&#21644;&#29305;&#24449;&#30340;&#30740;&#31350;&#22823;&#24133;&#22686;&#21152;&#12290;&#20107;&#23454;&#19978;&#65292;&#22266;&#23450;&#20301;&#32622;&#27604;&#36739;&#24378;&#24230;&#36890;&#24120;&#26080;&#27861;&#26174;&#31034;&#25968;&#25454;&#32467;&#26500;&#12290;&#22312;[Nurbekyan et al.&#65292;2020]&#20013;&#24320;&#21457;&#30340;&#26080;&#30896;&#25758;&#22270;&#21644;&#36317;&#31163;&#31867;&#20284;&#20110;&#26368;&#20248;&#20256;&#36755;(OT)&#22270;&#30340;&#20960;&#20309;&#29305;&#24449;&#20294;&#30001;&#20110;&#26080;&#38656;&#20248;&#21270;&#65292;&#35745;&#31639;&#25104;&#26412;&#35201;&#20415;&#23452;&#24471;&#22810;&#12290;&#26412;&#25991;&#35777;&#26126;&#26080;&#30896;&#25758;&#36317;&#31163;&#25552;&#20379;&#21333;&#20010;&#27010;&#29575;&#27979;&#24230;&#30340;&#24179;&#31227;(&#20998;&#21035;&#26159;&#20280;&#32553;)&#21644;&#35013;&#22791;&#27431;&#20960;&#37324;&#24471;&#36317;&#31163;&#30340;&#24179;&#31227;(&#20998;&#21035;&#26159;&#20280;&#32553;)&#21521;&#37327;&#20043;&#38388;&#30340;&#31561;&#36317;&#24615;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#65292;&#26080;&#30896;&#25758;&#36816;&#36755;&#22270;&#20197;&#21450;OT&#21644;&#32447;&#24615;OT&#22270;&#65292;&#19968;&#33324;&#26469;&#35828;&#19981;&#33021;&#20026;&#26059;&#36716;&#25552;&#20379;&#31561;&#36317;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
In this work, we investigate applications of no-collision transportation maps introduced in [Nurbekyan et. al., 2020] in manifold learning for image data. Recently, there has been a surge in applying transportation-based distances and features for data representing motion-like or deformation-like phenomena. Indeed, comparing intensities at fixed locations often does not reveal the data structure. No-collision maps and distances developed in [Nurbekyan et. al., 2020] are sensitive to geometric features similar to optimal transportation (OT) maps but much cheaper to compute due to the absence of optimization. In this work, we prove that no-collision distances provide an isometry between translations (respectively dilations) of a single probability measure and the translation (respectively dilation) vectors equipped with a Euclidean distance. Furthermore, we prove that no-collision transportation maps, as well as OT and linearized OT maps, do not in general provide an isometry for rotatio
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;Transformer&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#23454;&#29616;&#31526;&#21495;&#28040;&#24687;&#20256;&#36882;&#21644;&#20851;&#31995;&#25512;&#29702;&#65292;&#24182;&#36890;&#36807;&#20851;&#31995;&#20132;&#21449;&#27880;&#24847;&#21147;&#26426;&#21046;&#23454;&#29616;&#24863;&#24615;&#29366;&#24577;&#19982;&#25277;&#35937;&#29366;&#24577;&#20043;&#38388;&#30340;&#32465;&#23450;&#12290;</title><link>http://arxiv.org/abs/2304.00195</link><description>&lt;p&gt;
&#25277;&#35937;&#22120;&#65306;&#22522;&#20110;Transformer&#30340;&#31526;&#21495;&#28040;&#24687;&#20256;&#36882;&#21644;&#20851;&#31995;&#25512;&#29702;&#27169;&#22359;
&lt;/p&gt;
&lt;p&gt;
Abstractors: Transformer Modules for Symbolic Message Passing and Relational Reasoning. (arXiv:2304.00195v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2304.00195
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#22522;&#20110;Transformer&#30340;&#26694;&#26550;&#65292;&#29992;&#20110;&#23454;&#29616;&#31526;&#21495;&#28040;&#24687;&#20256;&#36882;&#21644;&#20851;&#31995;&#25512;&#29702;&#65292;&#24182;&#36890;&#36807;&#20851;&#31995;&#20132;&#21449;&#27880;&#24847;&#21147;&#26426;&#21046;&#23454;&#29616;&#24863;&#24615;&#29366;&#24577;&#19982;&#25277;&#35937;&#29366;&#24577;&#20043;&#38388;&#30340;&#32465;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#26694;&#26550;&#65292;&#23558;&#20851;&#31995;&#23398;&#20064;&#36716;&#21270;&#20026;Transformer&#27169;&#22411;&#65292;&#24182;&#36890;&#36807;&#20851;&#31995;&#20132;&#21449;&#27880;&#24847;&#21147;&#26426;&#21046;&#23454;&#29616;&#24863;&#24615;&#29366;&#24577;&#19982;&#25277;&#35937;&#29366;&#24577;&#20043;&#38388;&#30340;&#32465;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;
A framework is proposed that casts relational learning in terms of transformers, implementing binding between sensory states and abstract states with relational cross attention mechanisms.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;Hilbert-Valued&#21442;&#25968;&#36827;&#34892;&#19968;&#27493;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#19968;&#31181;&#36866;&#29992;&#20110;&#32570;&#20047;&#37325;&#29616;&#26680;&#30340;Hilbert&#31354;&#38388;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;</title><link>http://arxiv.org/abs/2303.16711</link><description>&lt;p&gt;
Hilbert-Valued&#21442;&#25968;&#30340;&#19968;&#27493;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
One-Step Estimation of Differentiable Hilbert-Valued Parameters. (arXiv:2303.16711v1 [math.ST])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.16711
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20171;&#32461;&#20102;&#19968;&#31181;&#38024;&#23545;Hilbert-Valued&#21442;&#25968;&#36827;&#34892;&#19968;&#27493;&#20272;&#35745;&#30340;&#26041;&#27861;&#65292;&#24182;&#25552;&#20379;&#19968;&#31181;&#36866;&#29992;&#20110;&#32570;&#20047;&#37325;&#29616;&#26680;&#30340;Hilbert&#31354;&#38388;&#30340;&#35299;&#20915;&#26041;&#26696;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#23545;&#20809;&#28369;Hilbert-Valued&#21442;&#25968;&#30340;&#20272;&#35745;&#22120;&#65292;&#20854;&#20013;&#20809;&#28369;&#24615;&#30001;&#36880;&#36335;&#24452;&#21487;&#24494;&#26465;&#20214;&#34920;&#24449;&#12290;&#24403;&#21442;&#25968;&#31354;&#38388;&#26159;&#37325;&#29616;&#26680;Hilbert&#31354;&#38388;&#26102;&#65292;&#25105;&#20204;&#25552;&#20379;&#20102;&#19968;&#31181;&#33719;&#21462;&#39640;&#25928;&#21644;&#30456;&#20851;&#32622;&#20449;&#21306;&#38388;&#30340;&#26041;&#27861;&#12290;&#36825;&#20123;&#20272;&#35745;&#22120;&#23545;&#24212;&#20110;&#22522;&#20110;Hilbert-Valued&#26377;&#25928;&#24433;&#21709;&#20989;&#25968;&#30340;&#20132;&#21449;&#19968;&#27493;&#20272;&#35745;&#22120;&#30340;&#27010;&#25324;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#29702;&#35770;&#20445;&#35777;&#65292;&#21363;&#20351;&#20351;&#29992;&#20219;&#24847;&#30340;&#36741;&#21161;&#20989;&#25968;&#20272;&#35745;&#22120;&#65292;&#21253;&#25324;&#22522;&#20110;&#26426;&#22120;&#23398;&#20064;&#25216;&#26415;&#30340;&#20272;&#35745;&#22120;&#12290;&#25105;&#20204;&#34920;&#26126;&#65292;&#21363;&#20351;&#32570;&#20047;&#37325;&#29616;&#26680;&#30340;Hilbert&#31354;&#38388;&#65292;&#21482;&#35201;&#21442;&#25968;&#20855;&#26377;&#39640;&#25928;&#30340;&#24433;&#21709;&#20989;&#25968;&#65292;&#36825;&#20123;&#32467;&#26524;&#33258;&#28982;&#22320;&#21487;&#20197;&#25193;&#23637;&#21040;&#35813;&#31354;&#38388;&#12290;&#28982;&#32780;&#65292;&#25105;&#20204;&#20063;&#25581;&#31034;&#20102;&#19981;&#24184;&#30340;&#20107;&#23454;&#65292;&#24403;&#19981;&#23384;&#22312;&#37325;&#29616;&#26680;&#26102;&#65292;&#35768;&#22810;&#26377;&#36259;&#30340;&#21442;&#25968;&#21363;&#20351;&#23427;&#20204;&#22312;&#36335;&#24452;&#19978;&#26159;&#21487;&#24494;&#30340;&#65292;&#20063;&#32570;&#20047;&#26377;&#25928;&#30340;&#24433;&#21709;&#20989;&#25968;&#12290;&#20026;&#20102;&#22788;&#29702;&#36825;&#20123;&#24773;&#20917;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#27491;&#21017;&#21270;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
We present estimators for smooth Hilbert-valued parameters, where smoothness is characterized by a pathwise differentiability condition. When the parameter space is a reproducing kernel Hilbert space, we provide a means to obtain efficient, root-n rate estimators and corresponding confidence sets. These estimators correspond to generalizations of cross-fitted one-step estimators based on Hilbert-valued efficient influence functions. We give theoretical guarantees even when arbitrary estimators of nuisance functions are used, including those based on machine learning techniques. We show that these results naturally extend to Hilbert spaces that lack a reproducing kernel, as long as the parameter has an efficient influence function. However, we also uncover the unfortunate fact that, when there is no reproducing kernel, many interesting parameters fail to have an efficient influence function, even though they are pathwise differentiable. To handle these cases, we propose a regularized on
&lt;/p&gt;</description></item><item><title>TRAK&#26159;&#19968;&#31181;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#12289;&#21487;&#24494;&#27169;&#22411;&#30340;&#25968;&#25454;&#24402;&#22240;&#26041;&#27861;&#65292;&#26082;&#26377;&#25928;&#21448;&#35745;&#31639;&#37327;&#21487;&#34892;&#12290;</title><link>http://arxiv.org/abs/2303.14186</link><description>&lt;p&gt;
TRAK: &#21051;&#30011;&#22823;&#35268;&#27169;&#27169;&#22411;&#34892;&#20026;
&lt;/p&gt;
&lt;p&gt;
TRAK: Attributing Model Behavior at Scale. (arXiv:2303.14186v1 [stat.ML])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.14186
&lt;/p&gt;
&lt;p&gt;
TRAK&#26159;&#19968;&#31181;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#12289;&#21487;&#24494;&#27169;&#22411;&#30340;&#25968;&#25454;&#24402;&#22240;&#26041;&#27861;&#65292;&#26082;&#26377;&#25928;&#21448;&#35745;&#31639;&#37327;&#21487;&#34892;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25968;&#25454;&#24402;&#22240;&#30340;&#30446;&#26631;&#26159;&#36861;&#36394;&#27169;&#22411;&#39044;&#27979;&#32467;&#26524;&#30340;&#21407;&#22987;&#35757;&#32451;&#25968;&#25454;&#12290;&#34429;&#28982;&#24050;&#32463;&#26377;&#24456;&#22810;&#24037;&#20316;&#33268;&#21147;&#20110;&#23454;&#29616;&#36825;&#19968;&#30446;&#26631;&#65292;&#20294;&#29616;&#26377;&#26041;&#27861;&#24448;&#24448;&#35201;&#27714;&#29992;&#25143;&#22312;&#35745;&#31639;&#25928;&#29575;&#21644;&#20934;&#30830;&#24615;&#20043;&#38388;&#20570;&#20986;&#36873;&#25321;&#12290;&#20063;&#23601;&#26159;&#35828;&#65292;&#22312;&#38750;&#20984;&#22330;&#26223;&#65288;&#20363;&#22914;&#65292;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#39046;&#22495;&#65289;&#20013;&#65292;&#35745;&#31639;&#37327;&#21487;&#34892;&#30340;&#26041;&#27861;&#21487;&#33021;&#38590;&#20197;&#20934;&#30830;&#22320;&#24402;&#22240;&#27169;&#22411;&#39044;&#27979;&#32467;&#26524;&#65292;&#32780;&#22312;&#36825;&#31867;&#22330;&#26223;&#20013;&#26377;&#25928;&#30340;&#26041;&#27861;&#21017;&#38656;&#35201;&#35757;&#32451;&#25968;&#21315;&#20010;&#27169;&#22411;&#65292;&#36825;&#20351;&#24471;&#23427;&#20204;&#22312;&#22823;&#22411;&#27169;&#22411;&#25110;&#25968;&#25454;&#38598;&#20013;&#23454;&#38469;&#24212;&#29992;&#20855;&#26377;&#19981;&#21487;&#34892;&#24615;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#20171;&#32461;&#20102;TRAK&#65288;&#38543;&#26426;&#25237;&#24433;&#26680;&#36861;&#36394;&#65289;&#65292;&#36825;&#26159;&#19968;&#31181;&#25968;&#25454;&#24402;&#22240;&#26041;&#27861;&#65292;&#36866;&#29992;&#20110;&#22823;&#35268;&#27169;&#12289;&#21487;&#24494;&#27169;&#22411;&#65292;&#26082;&#26377;&#25928;&#21448;&#35745;&#31639;&#37327;&#21487;&#34892;&#12290;&#20855;&#20307;&#26469;&#35828;&#65292;&#36890;&#36807;&#20165;&#20351;&#29992;&#23569;&#37327;&#35757;&#32451;&#27169;&#22411;&#65292;TRAK &#21487;&#20197;&#21305;&#37197;&#38656;&#35201;&#35757;&#32451;&#25968;&#21315;&#27169;&#22411;&#25165;&#33021;&#24471;&#21040;&#30340;&#24402;&#22240;&#26041;&#27861;&#30340;&#24615;&#33021;&#12290;&#25105;&#20204;&#35770;&#35777;&#20102;TRAK &#22312;&#21508;&#31181;&#27169;&#24335;&#21644;&#35268;&#27169;&#19978;&#30340;&#23454;&#29992;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The goal of data attribution is to trace model predictions back to training data. Despite a long line of work towards this goal, existing approaches to data attribution tend to force users to choose between computational tractability and efficacy. That is, computationally tractable methods can struggle with accurately attributing model predictions in non-convex settings (e.g., in the context of deep neural networks), while methods that are effective in such regimes require training thousands of models, which makes them impractical for large models or datasets.  In this work, we introduce TRAK (Tracing with the Randomly-projected After Kernel), a data attribution method that is both effective and computationally tractable for large-scale, differentiable models. In particular, by leveraging only a handful of trained models, TRAK can match the performance of attribution methods that require training thousands of models. We demonstrate the utility of TRAK across various modalities and scal
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#36890;&#29992;&#27169;&#22411;&#8212;&#8212;&#19981;&#23450;&#27010;&#29575;&#31070;&#32463;&#32593;&#32476;&#65307;&#23427;&#21487;&#20197;&#36827;&#34892;&#26080;&#30417;&#30563;&#32858;&#31867;&#21644;&#20351;&#29992;&#24456;&#23567;&#30340;&#31070;&#32463;&#32593;&#32476;&#22788;&#29702;&#22823;&#35268;&#27169;&#20998;&#31867;&#65292;&#20854;&#29702;&#35770;&#20248;&#21183;&#20307;&#29616;&#22312;&#26032;&#30340;&#27010;&#29575;&#29702;&#35770;&#21644;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#20013;&#12290;</title><link>http://arxiv.org/abs/2303.11536</link><description>&lt;p&gt;
&#19981;&#23450;&#27010;&#29575;&#31070;&#32463;&#32593;&#32476;
&lt;/p&gt;
&lt;p&gt;
Indeterminate Probability Neural Network. (arXiv:2303.11536v1 [cs.LG])
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.11536
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#22411;&#36890;&#29992;&#27169;&#22411;&#8212;&#8212;&#19981;&#23450;&#27010;&#29575;&#31070;&#32463;&#32593;&#32476;&#65307;&#23427;&#21487;&#20197;&#36827;&#34892;&#26080;&#30417;&#30563;&#32858;&#31867;&#21644;&#20351;&#29992;&#24456;&#23567;&#30340;&#31070;&#32463;&#32593;&#32476;&#22788;&#29702;&#22823;&#35268;&#27169;&#20998;&#31867;&#65292;&#20854;&#29702;&#35770;&#20248;&#21183;&#20307;&#29616;&#22312;&#26032;&#30340;&#27010;&#29575;&#29702;&#35770;&#21644;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#31216;&#20026;IPNN&#30340;&#26032;&#22411;&#36890;&#29992;&#27169;&#22411;&#65292;&#23427;&#23558;&#31070;&#32463;&#32593;&#32476;&#21644;&#27010;&#29575;&#35770;&#32467;&#21512;&#22312;&#19968;&#36215;&#12290;&#22312;&#20256;&#32479;&#27010;&#29575;&#35770;&#20013;&#65292;&#27010;&#29575;&#30340;&#35745;&#31639;&#26159;&#22522;&#20110;&#20107;&#20214;&#30340;&#21457;&#29983;&#65292;&#32780;&#36825;&#22312;&#24403;&#21069;&#30340;&#31070;&#32463;&#32593;&#32476;&#20013;&#20960;&#20046;&#19981;&#20351;&#29992;&#12290;&#22240;&#27492;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#27010;&#29575;&#29702;&#35770;&#65292;&#23427;&#26159;&#32463;&#20856;&#27010;&#29575;&#35770;&#30340;&#25193;&#23637;&#65292;&#24182;&#20351;&#32463;&#20856;&#27010;&#29575;&#35770;&#25104;&#20026;&#25105;&#20204;&#29702;&#35770;&#30340;&#19968;&#31181;&#29305;&#27530;&#24773;&#20917;&#12290;&#27492;&#22806;&#65292;&#23545;&#20110;&#25105;&#20204;&#25552;&#20986;&#30340;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#65292;&#31070;&#32463;&#32593;&#32476;&#30340;&#36755;&#20986;&#34987;&#23450;&#20041;&#20026;&#27010;&#29575;&#20107;&#20214;&#65292;&#24182;&#22522;&#20110;&#36825;&#20123;&#20107;&#20214;&#30340;&#32479;&#35745;&#20998;&#26512;&#65292;&#25512;&#23548;&#20986;&#20998;&#31867;&#20219;&#21153;&#30340;&#25512;&#29702;&#27169;&#22411;&#12290;IPNN&#23637;&#29616;&#20102;&#26032;&#30340;&#29305;&#24615;&#65306;&#23427;&#22312;&#36827;&#34892;&#20998;&#31867;&#30340;&#21516;&#26102;&#21487;&#20197;&#25191;&#34892;&#26080;&#30417;&#30563;&#32858;&#31867;&#12290;&#27492;&#22806;&#65292;IPNN&#33021;&#22815;&#20351;&#29992;&#38750;&#24120;&#23567;&#30340;&#31070;&#32463;&#32593;&#32476;&#36827;&#34892;&#38750;&#24120;&#22823;&#30340;&#20998;&#31867;&#65292;&#20363;&#22914;100&#20010;&#36755;&#20986;&#33410;&#28857;&#30340;&#27169;&#22411;&#21487;&#20197;&#20998;&#31867;10&#20159;&#31867;&#21035;&#12290;&#29702;&#35770;&#20248;&#21183;&#20307;&#29616;&#22312;&#26032;&#30340;&#27010;&#29575;&#29702;&#35770;&#21644;&#31070;&#32463;&#32593;&#32476;&#26694;&#26550;&#20013;&#65292;&#24182;&#19988;&#23454;&#39564;&#32467;&#26524;&#23637;&#31034;&#20102;IPNN&#22312;&#21508;&#31181;&#24212;&#29992;&#20013;&#30340;&#28508;&#21147;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose a new general model called IPNN - Indeterminate Probability Neural Network, which combines neural network and probability theory together. In the classical probability theory, the calculation of probability is based on the occurrence of events, which is hardly used in current neural networks. In this paper, we propose a new general probability theory, which is an extension of classical probability theory, and makes classical probability theory a special case to our theory. Besides, for our proposed neural network framework, the output of neural network is defined as probability events, and based on the statistical analysis of these events, the inference model for classification task is deduced. IPNN shows new property: It can perform unsupervised clustering while doing classification. Besides, IPNN is capable of making very large classification with very small neural network, e.g. model with 100 output nodes can classify 10 billion categories. Theoretical advantages are refl
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#21033;&#29992;&#20195;&#25968;&#20960;&#20309;&#26041;&#27861;&#32473;&#20986;&#20102;&#24352;&#37327;&#20998;&#35299;&#30340;&#23454;&#23545;&#25968;&#20856;&#33539;&#38408;&#20540;&#30340;&#19978;&#30028;&#65292;&#24182;&#25512;&#23548;&#20102;&#20854;&#22312;&#36125;&#21494;&#26031;&#25512;&#26029;&#20013;&#30340;&#24212;&#29992;&#29702;&#35770;&#35823;&#24046;&#65292;&#25581;&#31034;&#20102;&#24352;&#37327;&#20998;&#35299;&#30340;&#25968;&#23398;&#24615;&#36136;&#12290;</title><link>http://arxiv.org/abs/2303.05731</link><description>&lt;p&gt;
&#24352;&#37327;&#20998;&#35299;&#30340;&#23454;&#23545;&#25968;&#20856;&#33539;&#38408;&#20540;&#30340;&#19978;&#30028;&#21450;&#20854;&#22312;&#36125;&#21494;&#26031;&#25512;&#26029;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Upper Bound of Real Log Canonical Threshold of Tensor Decomposition and its Application to Bayesian Inference. (arXiv:2303.05731v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.05731
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#21033;&#29992;&#20195;&#25968;&#20960;&#20309;&#26041;&#27861;&#32473;&#20986;&#20102;&#24352;&#37327;&#20998;&#35299;&#30340;&#23454;&#23545;&#25968;&#20856;&#33539;&#38408;&#20540;&#30340;&#19978;&#30028;&#65292;&#24182;&#25512;&#23548;&#20102;&#20854;&#22312;&#36125;&#21494;&#26031;&#25512;&#26029;&#20013;&#30340;&#24212;&#29992;&#29702;&#35770;&#35823;&#24046;&#65292;&#25581;&#31034;&#20102;&#24352;&#37327;&#20998;&#35299;&#30340;&#25968;&#23398;&#24615;&#36136;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#24352;&#37327;&#20998;&#35299;&#29616;&#22312;&#34987;&#29992;&#20110;&#25968;&#25454;&#20998;&#26512;&#12289;&#20449;&#24687;&#21387;&#32553;&#21644;&#30693;&#35782;&#24674;&#22797;&#12290;&#28982;&#32780;&#65292;&#24352;&#37327;&#20998;&#35299;&#30340;&#25968;&#23398;&#24615;&#36136;&#23578;&#26410;&#23436;&#20840;&#38416;&#26126;&#65292;&#22240;&#20026;&#23427;&#26159;&#19968;&#31181;&#22855;&#24322;&#23398;&#20064;&#26426;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#21033;&#29992;&#20195;&#25968;&#20960;&#20309;&#26041;&#27861;&#32473;&#20986;&#20102;&#24352;&#37327;&#20998;&#35299;&#30340;&#23454;&#23545;&#25968;&#20856;&#33539;&#38408;&#20540;(RLCT)&#30340;&#19978;&#30028;&#65292;&#24182;&#20174;&#29702;&#35770;&#19978;&#25512;&#23548;&#20102;&#20854;&#36125;&#21494;&#26031;&#27867;&#21270;&#35823;&#24046;&#12290;&#25105;&#20204;&#36824;&#36890;&#36807;&#25968;&#20540;&#23454;&#39564;&#32473;&#20986;&#20102;&#20854;&#25968;&#23398;&#24615;&#36136;&#30340;&#32771;&#34385;&#12290;
&lt;/p&gt;
&lt;p&gt;
Tensor decomposition is now being used for data analysis, information compression, and knowledge recovery. However, the mathematical property of tensor decomposition is not yet fully clarified because it is one of singular learning machines. In this paper, we give the upper bound of its real log canonical threshold (RLCT) of the tensor decomposition by using an algebraic geometrical method and derive its Bayesian generalization error theoretically. We also give considerations about its mathematical property through numerical experiments.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26102;&#38388;&#24207;&#21015;&#29983;&#25104;&#26041;&#27861;&#65292;&#20351;&#29992;&#21521;&#37327;&#37327;&#21270;&#25216;&#26415;&#21644;&#21452;&#21521;&#21464;&#21387;&#22120;&#27169;&#22411;&#26469;&#29983;&#25104;&#36136;&#37327;&#26356;&#22909;&#12289;&#27169;&#22359;&#21270;&#21464;&#21270;&#26356;&#24555;&#30340;&#21512;&#25104;&#20449;&#21495;&#12290;</title><link>http://arxiv.org/abs/2303.04743</link><description>&lt;p&gt;
&#24102;&#26377;&#21452;&#21521;&#20808;&#39564;&#27169;&#22411;&#30340;&#21521;&#37327;&#37327;&#21270;&#26102;&#38388;&#24207;&#21015;&#29983;&#25104;
&lt;/p&gt;
&lt;p&gt;
Vector Quantized Time Series Generation with a Bidirectional Prior Model. (arXiv:2303.04743v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2303.04743
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26102;&#38388;&#24207;&#21015;&#29983;&#25104;&#26041;&#27861;&#65292;&#20351;&#29992;&#21521;&#37327;&#37327;&#21270;&#25216;&#26415;&#21644;&#21452;&#21521;&#21464;&#21387;&#22120;&#27169;&#22411;&#26469;&#29983;&#25104;&#36136;&#37327;&#26356;&#22909;&#12289;&#27169;&#22359;&#21270;&#21464;&#21270;&#26356;&#24555;&#30340;&#21512;&#25104;&#20449;&#21495;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26102;&#38388;&#24207;&#21015;&#29983;&#25104;&#30740;&#31350;&#20027;&#35201;&#38598;&#20013;&#22312;&#20351;&#29992;&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#19982;&#36882;&#24402;&#31070;&#32463;&#32593;&#32476;&#65288;RNN&#65289;&#21464;&#20307;&#30456;&#32467;&#21512;&#12290;&#28982;&#32780;&#65292;&#35757;&#32451; GAN &#30340;&#22522;&#26412;&#38480;&#21046;&#21644;&#25361;&#25112;&#20173;&#28982;&#23384;&#22312;&#12290;&#27492;&#22806;&#65292;RNN&#26063;&#36890;&#24120;&#22312;&#36828;&#31243;&#26102;&#38388;&#27493;&#20043;&#38388;&#30340;&#26102;&#38388;&#19968;&#33268;&#24615;&#26041;&#38754;&#23384;&#22312;&#22256;&#38590;&#12290;&#21463;&#21040;&#22270;&#20687;&#29983;&#25104;&#39046;&#22495;&#25104;&#21151;&#30340;&#21551;&#21457;&#65292;&#25105;&#20204;&#25552;&#20986; TimeVQVAE&#65292;&#36825;&#26159;&#25105;&#20204;&#25152;&#30693;&#36947;&#30340;&#31532;&#19968;&#20010;&#20351;&#29992;&#21521;&#37327;&#37327;&#21270;&#65288;VQ&#65289;&#25216;&#26415;&#35299;&#20915; TSG &#38382;&#39064;&#30340;&#24037;&#20316;&#12290;&#27492;&#22806;&#65292;&#31163;&#25955;&#28508;&#22312;&#31354;&#38388;&#30340;&#20808;&#39564;&#20351;&#29992;&#21452;&#21521;&#21464;&#21387;&#22120;&#27169;&#22411;&#36827;&#34892;&#23398;&#20064;&#65292;&#21487;&#20197;&#26356;&#22909;&#22320;&#25429;&#25417;&#20840;&#23616;&#26102;&#38388;&#19968;&#33268;&#24615;&#12290;&#25105;&#20204;&#36824;&#25552;&#20986;&#22312;&#26102;&#38388; - &#39057;&#29575;&#22495;&#20013;&#36827;&#34892; VQ &#24314;&#27169;&#65292;&#20998;&#20026;&#20302;&#39057;&#65288;LF&#65289;&#21644;&#39640;&#39057;&#65288;HF&#65289;&#12290;&#36825;&#20351;&#25105;&#20204;&#33021;&#22815;&#20445;&#30041;&#26102;&#38388;&#24207;&#21015;&#30340;&#37325;&#35201;&#29305;&#24449;&#65292;&#24182;&#29983;&#25104;&#36136;&#37327;&#26356;&#22909;&#12289;&#27169;&#22359;&#24615;&#21464;&#21270;&#26356;&#24555;&#30340;&#26032;&#21512;&#25104;&#20449;&#21495;&#12290;
&lt;/p&gt;
&lt;p&gt;
Time series generation (TSG) studies have mainly focused on the use of Generative Adversarial Networks (GANs) combined with recurrent neural network (RNN) variants. However, the fundamental limitations and challenges of training GANs still remain. In addition, the RNN-family typically has difficulties with temporal consistency between distant timesteps. Motivated by the successes in the image generation (IMG) domain, we propose TimeVQVAE, the first work, to our knowledge, that uses vector quantization (VQ) techniques to address the TSG problem. Moreover, the priors of the discrete latent spaces are learned with bidirectional transformer models that can better capture global temporal consistency. We also propose VQ modeling in a time-frequency domain, separated into low-frequency (LF) and high-frequency (HF). This allows us to retain important characteristics of the time series and, in turn, generate new synthetic signals that are of better quality, with sharper changes in modularity, t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#24320;&#21019;&#24615;&#22320;&#30740;&#31350;&#20102;&#20849;&#20139;&#26368;&#36817;&#37051;&#22270;&#21644;&#22270;&#25289;&#26222;&#25289;&#26031;&#31639;&#23376;&#65292;&#35777;&#26126;&#20102;&#20849;&#20139;&#26368;&#36817;&#37051;&#22270;&#25289;&#26222;&#25289;&#26031;&#31639;&#23376;&#21644; k &#36817;&#37051;&#22270;&#25289;&#26222;&#25289;&#26031;&#31639;&#23376;&#20855;&#26377;&#30456;&#21516;&#30340;&#36830;&#32493;&#26497;&#38480;&#65292;&#21516;&#26102;&#21457;&#29616;&#23427;&#20204;&#30340;&#22270;&#25289;&#26222;&#25289;&#26031;&#31639;&#23376;&#36880;&#28857;&#25910;&#25947;&#36895;&#29575;&#19982; $(k/n)^{1/m}$ &#25104;&#32447;&#24615;&#20851;&#31995;&#12290;</title><link>http://arxiv.org/abs/2302.12399</link><description>&lt;p&gt;
&#22522;&#20110;&#20849;&#20139;&#26368;&#36817;&#37051;&#20449;&#24687;&#30340;&#22270;&#25289;&#26222;&#25289;&#26031;&#31639;&#23376;&#21644;&#22522;&#20110; k &#36817;&#37051;&#22270;&#30340;&#22270;&#25289;&#26222;&#25289;&#26031;&#31639;&#23376;&#20855;&#26377;&#30456;&#21516;&#30340;&#26497;&#38480;
&lt;/p&gt;
&lt;p&gt;
Graph Laplacians on Shared Nearest Neighbor graphs and graph Laplacians on $k$-Nearest Neighbor graphs having the same limit. (arXiv:2302.12399v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.12399
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#24320;&#21019;&#24615;&#22320;&#30740;&#31350;&#20102;&#20849;&#20139;&#26368;&#36817;&#37051;&#22270;&#21644;&#22270;&#25289;&#26222;&#25289;&#26031;&#31639;&#23376;&#65292;&#35777;&#26126;&#20102;&#20849;&#20139;&#26368;&#36817;&#37051;&#22270;&#25289;&#26222;&#25289;&#26031;&#31639;&#23376;&#21644; k &#36817;&#37051;&#22270;&#25289;&#26222;&#25289;&#26031;&#31639;&#23376;&#20855;&#26377;&#30456;&#21516;&#30340;&#36830;&#32493;&#26497;&#38480;&#65292;&#21516;&#26102;&#21457;&#29616;&#23427;&#20204;&#30340;&#22270;&#25289;&#26222;&#25289;&#26031;&#31639;&#23376;&#36880;&#28857;&#25910;&#25947;&#36895;&#29575;&#19982; $(k/n)^{1/m}$ &#25104;&#32447;&#24615;&#20851;&#31995;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20849;&#20139;&#26368;&#36817;&#37051;&#22270;&#26159;&#19968;&#31181;&#20351;&#29992;&#20849;&#20139;&#26368;&#36817;&#37051;&#20449;&#24687;&#26500;&#24314;&#30340;&#22270;&#24418;&#32467;&#26500;&#65292;&#20854;&#26159;&#19968;&#31181;&#22522;&#20110;&#20027;&#35201;&#30340; k &#36817;&#37051;&#24230;&#37327;&#35825;&#23548;&#30340;&#25490;&#21517;&#30340;&#20108;&#32423;&#30456;&#20284;&#24230;&#27979;&#37327;&#12290;SNN &#27979;&#37327;&#34987;&#35748;&#20026;&#27604;&#20256;&#32479;&#36317;&#31163;&#27979;&#37327;&#27861;&#26356;&#19981;&#23481;&#26131;&#21463;&#21040;&#32500;&#25968;&#35781;&#21650;&#30340;&#24433;&#21709;&#65292;&#22240;&#27492;&#20351;&#29992; SNN &#22270;&#30340;&#26041;&#27861;&#24050;&#32463;&#34987;&#24191;&#27867;&#24212;&#29992;&#20110;&#24212;&#29992;&#31243;&#24207;&#20013;&#65292;&#29305;&#21035;&#26159;&#22312;&#32858;&#31867;&#39640;&#32500;&#25968;&#25454;&#38598;&#21644;&#22312;&#39640;&#32500;&#25968;&#25454;&#23376;&#31354;&#38388;&#20013;&#26597;&#25214;&#24322;&#24120;&#20540;&#20013;&#12290;&#23613;&#31649;&#22914;&#27492;&#65292;&#20173;&#26410;&#23545; SNN &#22270;&#21644;&#22270;&#25289;&#26222;&#25289;&#26031;&#31639;&#23376;&#36827;&#34892;&#29702;&#35770;&#30740;&#31350;&#12290;&#22312;&#36825;&#39033;&#24320;&#21019;&#24615;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#39318;&#27425;&#22312;&#36825;&#20010;&#26041;&#21521;&#19978;&#20570;&#20986;&#20102;&#36129;&#29486;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102; SNN &#22270;&#25289;&#26222;&#25289;&#26031;&#31639;&#23376;&#30340;&#22823;&#35268;&#27169;&#28176;&#36817;&#24615;&#36798;&#21040;&#20102;&#19968;&#33268;&#30340;&#36830;&#32493;&#26497;&#38480;&#65307;&#36825;&#20010;&#26497;&#38480;&#19982; k &#36817;&#37051;&#22270;&#25289;&#26222;&#25289;&#26031;&#31639;&#23376;&#30340;&#26497;&#38480;&#30456;&#21516;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#22270;&#25289;&#26222;&#25289;&#26031;&#31639;&#23376;&#30340;&#36880;&#28857;&#25910;&#25947;&#36895;&#29575;&#19982; $(k/n)^{1/m}$ &#25104;&#32447;&#24615;&#20851;&#31995;&#65292;&#27010;&#29575;&#39640;&#12290;
&lt;/p&gt;
&lt;p&gt;
A Shared Nearest Neighbor (SNN) graph is a type of graph construction using shared nearest neighbor information, which is a secondary similarity measure based on the rankings induced by a primary $k$-nearest neighbor ($k$-NN) measure. SNN measures have been touted as being less prone to the curse of dimensionality than conventional distance measures, and thus methods using SNN graphs have been widely used in applications, particularly in clustering high-dimensional data sets and in finding outliers in subspaces of high dimensional data. Despite this, the theoretical study of SNN graphs and graph Laplacians remains unexplored. In this pioneering work, we make the first contribution in this direction. We show that large scale asymptotics of an SNN graph Laplacian reach a consistent continuum limit; this limit is the same as that of a $k$-NN graph Laplacian. Moreover, we show that the pointwise convergence rate of the graph Laplacian is linear with respect to $(k/n)^{1/m}$ with high proba
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;I$^2$SB&#65292;&#30452;&#25509;&#23398;&#20064;&#20004;&#20010;&#32473;&#23450;&#20998;&#24067;&#20043;&#38388;&#30340;&#38750;&#32447;&#24615;&#25193;&#25955;&#36807;&#31243;&#12290;&#36890;&#36807;&#36793;&#30028;&#23545;&#27714;&#35299;&#30340;&#26041;&#27861;&#20351;&#24471;I$^2$SB&#35757;&#32451;&#25104;&#20026;&#19968;&#31181;&#26080;&#38656;&#27169;&#25311;&#30340;&#38750;&#32447;&#24615;&#25193;&#25955;&#26694;&#26550;&#65292;&#22312;&#21508;&#31181;&#22270;&#20687;&#24674;&#22797;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#34920;&#29616;&#20248;&#20110;&#26631;&#20934;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#65292;&#24182;&#20855;&#26377;&#26356;&#21487;&#35299;&#37322;&#30340;&#29983;&#25104;&#36807;&#31243;&#12290;</title><link>http://arxiv.org/abs/2302.05872</link><description>&lt;p&gt;
I$^2$SB&#65306;&#22270;&#20687;&#21040;&#22270;&#20687;&#30340;Schr\"odinger&#26725;
&lt;/p&gt;
&lt;p&gt;
I$^2$SB: Image-to-Image Schr\"odinger Bridge. (arXiv:2302.05872v2 [cs.CV] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2302.05872
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;I$^2$SB&#65292;&#30452;&#25509;&#23398;&#20064;&#20004;&#20010;&#32473;&#23450;&#20998;&#24067;&#20043;&#38388;&#30340;&#38750;&#32447;&#24615;&#25193;&#25955;&#36807;&#31243;&#12290;&#36890;&#36807;&#36793;&#30028;&#23545;&#27714;&#35299;&#30340;&#26041;&#27861;&#20351;&#24471;I$^2$SB&#35757;&#32451;&#25104;&#20026;&#19968;&#31181;&#26080;&#38656;&#27169;&#25311;&#30340;&#38750;&#32447;&#24615;&#25193;&#25955;&#26694;&#26550;&#65292;&#22312;&#21508;&#31181;&#22270;&#20687;&#24674;&#22797;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#34920;&#29616;&#20248;&#20110;&#26631;&#20934;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#65292;&#24182;&#20855;&#26377;&#26356;&#21487;&#35299;&#37322;&#30340;&#29983;&#25104;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#65292;&#21363;&#22270;&#20687;&#21040;&#22270;&#20687;&#30340;Schr\"odinger&#26725;&#65288;I$^2$SB&#65289;&#65292;&#30452;&#25509;&#23398;&#20064;&#20004;&#20010;&#32473;&#23450;&#20998;&#24067;&#20043;&#38388;&#30340;&#38750;&#32447;&#24615;&#25193;&#25955;&#36807;&#31243;&#12290;&#36825;&#20123;&#25193;&#25955;&#26725;&#23545;&#20110;&#22270;&#20687;&#24674;&#22797;&#29305;&#21035;&#26377;&#29992;&#65292;&#22240;&#20026;&#36864;&#21270;&#22270;&#20687;&#26159;&#37325;&#26500;&#28165;&#26224;&#22270;&#20687;&#30340;&#32467;&#26500;&#20449;&#24687;&#20808;&#39564;&#12290; I$^2$SB&#23646;&#20110;&#19968;&#31867;&#21487;&#22788;&#29702;&#30340;Schr\"odinger&#26725;&#27169;&#22411;&#65292;&#23427;&#26159;&#24471;&#20998;&#27169;&#22411;&#30340;&#38750;&#32447;&#24615;&#25193;&#23637;&#65292;&#20854;&#36793;&#30028;&#23545;&#30340;&#36793;&#32536;&#20998;&#24067;&#21487;&#20197;&#22312;&#35299;&#26512;&#19978;&#35745;&#31639;&#12290;&#36825;&#31181;&#36890;&#36807;&#36793;&#30028;&#23545;&#27714;&#35299;&#30340;&#26041;&#27861;&#20351;&#24471;I$^2$SB&#35757;&#32451;&#25104;&#20026;&#19968;&#31181;&#26080;&#38656;&#27169;&#25311;&#30340;&#38750;&#32447;&#24615;&#25193;&#25955;&#26694;&#26550;&#65292;&#36827;&#32780;&#37319;&#29992;&#22312;&#26631;&#20934;&#25193;&#25955;&#27169;&#22411;&#20013;&#20351;&#29992;&#30340;&#23454;&#29992;&#25216;&#26415;&#65292;&#20351;&#24471;I$^2$SB&#35757;&#32451;&#20855;&#26377;&#21487;&#25193;&#23637;&#24615;&#12290;&#22312;ImageNet 256x256&#19978;&#65292;&#25105;&#20204;&#39564;&#35777;&#20102;I$^2$SB&#22312;&#21508;&#31181;&#22270;&#20687;&#24674;&#22797;&#20219;&#21153;&#20013;&#30340;&#24615;&#33021;&#65292;&#21253;&#25324;&#20462;&#22797;&#65292;&#36229;&#20998;&#36776;&#29575;&#65292;&#21435;&#27169;&#31946;&#21644;JPEG&#24674;&#22797;&#65292;&#24182;&#34920;&#26126;I$^2$SB&#36229;&#36807;&#20102;&#26631;&#20934;&#26465;&#20214;&#25193;&#25955;&#27169;&#22411;&#65292;&#20855;&#26377;&#26356;&#21487;&#35299;&#37322;&#30340;&#29983;&#25104;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
We propose Image-to-Image Schr\"odinger Bridge (I$^2$SB), a new class of conditional diffusion models that directly learn the nonlinear diffusion processes between two given distributions. These diffusion bridges are particularly useful for image restoration, as the degraded images are structurally informative priors for reconstructing the clean images. I$^2$SB belongs to a tractable class of Schr\"odinger bridge, the nonlinear extension to score-based models, whose marginal distributions can be computed analytically given boundary pairs. This results in a simulation-free framework for nonlinear diffusions, where the I$^2$SB training becomes scalable by adopting practical techniques used in standard diffusion models. We validate I$^2$SB in solving various image restoration tasks, including inpainting, super-resolution, deblurring, and JPEG restoration on ImageNet 256x256 and show that I$^2$SB surpasses standard conditional diffusion models with more interpretable generative processes. 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#20351;&#29992;&#29289;&#29702;&#23398;&#30693;&#35782;&#25351;&#23548;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#26041;&#27861;&#65292;&#35299;&#20915;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#27714;&#35299;&#22120;&#26080;&#27861;&#37327;&#21270;&#36817;&#20284;&#35823;&#24046;&#30340;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2212.12474</link><description>&lt;p&gt;
&#29289;&#29702;&#23398;&#30693;&#35782;&#25351;&#23548;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#24212;&#29992;&#20110;&#35299;&#20915;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;
&lt;/p&gt;
&lt;p&gt;
Physics-Informed Gaussian Process Regression Generalizes Linear PDE Solvers. (arXiv:2212.12474v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2212.12474
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#20351;&#29992;&#29289;&#29702;&#23398;&#30693;&#35782;&#25351;&#23548;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#26041;&#27861;&#65292;&#35299;&#20915;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#27714;&#35299;&#22120;&#26080;&#27861;&#37327;&#21270;&#36817;&#20284;&#35823;&#24046;&#30340;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#26159;&#19968;&#31867;&#37325;&#35201;&#19988;&#24191;&#27867;&#24212;&#29992;&#30340;&#26426;&#26800;&#27169;&#22411;&#65292;&#25551;&#36848;&#20102;&#29289;&#29702;&#36807;&#31243;&#65292;&#20363;&#22914;&#28909;&#20256;&#23548;&#12289;&#30005;&#30913;&#23398;&#21644;&#27874;&#20256;&#25773;&#31561;&#12290;&#23454;&#36341;&#20013;&#65292;&#36890;&#24120;&#20351;&#29992;&#22522;&#20110;&#31163;&#25955;&#21270;&#30340;&#19987;&#38376;&#25968;&#20540;&#26041;&#27861;&#26469;&#35299;&#20915;&#20559;&#24494;&#20998;&#26041;&#31243;&#12290;&#36825;&#20123;&#27714;&#35299;&#22120;&#36890;&#24120;&#20351;&#29992;&#26410;&#30693;&#27169;&#22411;&#21442;&#25968;&#30340;&#20272;&#35745;&#20540;&#20197;&#21450;&#22914;&#26524;&#21487;&#29992;&#30340;&#35805;&#65292;&#29289;&#29702;&#27979;&#37327;&#20540;&#29992;&#20110;&#21021;&#22987;&#21270;&#12290;&#36825;&#20123;&#27714;&#35299;&#22120;&#32463;&#24120;&#23884;&#20837;&#21040;&#20855;&#26377;&#19979;&#28216;&#24212;&#29992;&#30340;&#26356;&#22823;&#30340;&#31185;&#23398;&#27169;&#22411;&#20013;&#65292;&#22240;&#27492;&#35823;&#24046;&#37327;&#21270;&#36215;&#30528;&#20851;&#38190;&#20316;&#29992;&#12290;&#28982;&#32780;&#65292;&#32463;&#20856;&#30340;&#20559;&#24494;&#20998;&#26041;&#31243;&#27714;&#35299;&#22120;&#24573;&#30053;&#21442;&#25968;&#21644;&#27979;&#37327;&#19981;&#30830;&#23450;&#24615;&#65292;&#21487;&#33021;&#26080;&#27861;&#20135;&#29983;&#19968;&#33268;&#24615;&#30340;&#20272;&#35745;&#20540;&#65292;&#20197;&#29992;&#20110;&#35745;&#31639;&#20854;&#22266;&#26377;&#30340;&#36924;&#36817;&#35823;&#24046;&#12290;&#26412;&#25991;&#36890;&#36807;&#23558;&#27714;&#35299;&#32447;&#24615;&#20559;&#24494;&#20998;&#26041;&#31243;&#35299;&#37322;&#20026;&#29289;&#29702;&#23398;&#30693;&#35782;&#25351;&#23548;&#30340;&#39640;&#26031;&#36807;&#31243;&#22238;&#24402;&#26469;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#30340;&#26694;&#26550;&#22522;&#20110;&#39640;&#26031;&#36807;&#31243;&#25512;&#29702;&#23450;&#29702;&#30340;&#19968;&#20010;&#20851;&#38190;&#25512;&#24191;&#65292;&#35813;&#23450;&#29702;&#36866;&#29992;&#20110;&#36890;&#36807;&#20219;&#24847;&#30028;&#38754;&#36827;&#34892;&#35266;&#23519;&#30340;&#24773;&#20917;&#12290;
&lt;/p&gt;
&lt;p&gt;
Linear partial differential equations (PDEs) are an important, widely applied class of mechanistic models, describing physical processes such as heat transfer, electromagnetism, and wave propagation. In practice, specialized numerical methods based on discretization are used to solve PDEs. They generally use an estimate of the unknown model parameters and, if available, physical measurements for initialization. Such solvers are often embedded into larger scientific models with a downstream application and thus error quantification plays a key role. However, by ignoring parameter and measurement uncertainty, classical PDE solvers may fail to produce consistent estimates of their inherent approximation error. In this work, we approach this problem in a principled fashion by interpreting solving linear PDEs as physics-informed Gaussian process (GP) regression. Our framework is based on a key generalization of the Gaussian process inference theorem to observations made via an arbitrary bou
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#31232;&#26377;&#20107;&#20214;&#30340;&#26032;&#30340;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#65292;&#22522;&#20110;&#25910;&#38598;&#21040;&#30340;&#26102;&#38388;&#19981;&#21464;&#21160;&#24577;&#31995;&#32479;&#30340;&#25968;&#25454;&#65292;&#26500;&#24314;&#20102;&#21472;&#21152;&#25968;&#25454;&#38598;&#21644;&#26465;&#20214;&#29420;&#31435;&#24615;&#26816;&#39564;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#25581;&#31034;&#22312;&#21464;&#37327;&#31532;&#19968;&#27425;&#32463;&#21382;&#20302;&#27010;&#29575;&#23454;&#29616;&#26102;&#25165;&#20250;&#26174;&#29616;&#30340;&#22240;&#26524;&#20851;&#31995;&#65292;&#20855;&#26377;&#24456;&#22909;&#30340;&#21487;&#34892;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;</title><link>http://arxiv.org/abs/2211.16596</link><description>&lt;p&gt;
&#38754;&#21521;&#31232;&#26377;&#20107;&#20214;&#30340;&#21160;&#24577;&#22240;&#26524;&#21457;&#29616;&#65306;&#19968;&#31181;&#38750;&#21442;&#25968;&#26465;&#20214;&#29420;&#31435;&#24615;&#26816;&#39564;
&lt;/p&gt;
&lt;p&gt;
Towards Dynamic Causal Discovery with Rare Events: A Nonparametric Conditional Independence Test. (arXiv:2211.16596v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.16596
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#38024;&#23545;&#31232;&#26377;&#20107;&#20214;&#30340;&#26032;&#30340;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#65292;&#22522;&#20110;&#25910;&#38598;&#21040;&#30340;&#26102;&#38388;&#19981;&#21464;&#21160;&#24577;&#31995;&#32479;&#30340;&#25968;&#25454;&#65292;&#26500;&#24314;&#20102;&#21472;&#21152;&#25968;&#25454;&#38598;&#21644;&#26465;&#20214;&#29420;&#31435;&#24615;&#26816;&#39564;&#30340;&#26041;&#27861;&#12290;&#35813;&#26041;&#27861;&#33021;&#22815;&#25581;&#31034;&#22312;&#21464;&#37327;&#31532;&#19968;&#27425;&#32463;&#21382;&#20302;&#27010;&#29575;&#23454;&#29616;&#26102;&#25165;&#20250;&#26174;&#29616;&#30340;&#22240;&#26524;&#20851;&#31995;&#65292;&#20855;&#26377;&#24456;&#22909;&#30340;&#21487;&#34892;&#24615;&#21644;&#21487;&#25193;&#23637;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#19982;&#31232;&#26377;&#20107;&#20214;&#30456;&#20851;&#32852;&#30340;&#22240;&#26524;&#29616;&#35937;&#22312;&#35768;&#22810;&#24037;&#31243;&#38382;&#39064;&#20013;&#37117;&#23384;&#22312;&#65292;&#20363;&#22914;&#38024;&#23545;&#39118;&#38505;&#30340;&#23433;&#20840;&#20998;&#26512;&#12289;&#20107;&#25925;&#20998;&#26512;&#21644;&#39044;&#38450;&#20197;&#21450;&#26497;&#20540;&#29702;&#35770;&#31561;&#12290;&#28982;&#32780;&#65292;&#24403;&#21069;&#30340;&#22240;&#26524;&#21457;&#29616;&#26041;&#27861;&#24448;&#24448;&#26080;&#27861;&#21457;&#29616;&#22312;&#38543;&#26426;&#21464;&#37327;&#20043;&#38388;&#30340;&#21407;&#22240;&#32852;&#31995;&#65292;&#29305;&#21035;&#26159;&#22312;&#21464;&#21160;&#29615;&#22659;&#19979;&#65292;&#20165;&#22312;&#21464;&#37327;&#31532;&#19968;&#27425;&#32463;&#21382;&#20302;&#27010;&#29575;&#23454;&#29616;&#26102;&#25165;&#20250;&#26174;&#29616;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#24341;&#20837;&#20102;&#19968;&#31181;&#26032;&#30340;&#32479;&#35745;&#29420;&#31435;&#24615;&#26816;&#39564;&#26041;&#27861;&#65292;&#29992;&#20110;&#20174;&#21457;&#29983;&#31232;&#26377;&#20294;&#20855;&#26377;&#37325;&#35201;&#24433;&#21709;&#30340;&#26102;&#38388;&#19981;&#21464;&#21160;&#24577;&#31995;&#32479;&#25910;&#38598;&#30340;&#25968;&#25454;&#20013;&#36827;&#34892;&#22240;&#26524;&#25506;&#32034;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#25105;&#20204;&#21033;&#29992;&#24213;&#23618;&#25968;&#25454;&#30340;&#26102;&#38388;&#19981;&#21464;&#24615;&#26469;&#26500;&#24314;&#19968;&#20010;&#21472;&#21152;&#30340;&#25968;&#25454;&#38598;&#65292;&#20854;&#20013;&#21253;&#25324;&#22312;&#19981;&#21516;&#26102;&#38388;&#27493;&#39588;&#20043;&#21069;&#31232;&#26377;&#20107;&#20214;&#21457;&#29983;&#21069;&#31995;&#32479;&#29366;&#24577;&#30340;&#25968;&#25454;&#12290;&#28982;&#21518;&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#22312;&#37325;&#26032;&#32452;&#32455;&#30340;&#25968;&#25454;&#19978;&#36827;&#34892;&#26465;&#20214;&#29420;&#31435;&#24615;&#26816;&#39564;&#30340;&#26041;&#27861;&#12290;&#25105;&#20204;&#25552;&#20379;&#20102;&#25105;&#20204;&#26041;&#27861;&#19968;&#33268;&#24615;&#30340;&#38750;&#28176;&#36817;&#26679;&#26412;&#22797;&#26434;&#24230;&#30028;&#38480;&#65292;&#24182;&#39564;&#35777;&#20102;&#23427;&#22312;&#21508;&#31181;&#27169;&#25311;&#21644;&#30495;&#23454;&#19990;&#30028;&#25968;&#25454;&#38598;&#19978;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Causal phenomena associated with rare events occur across a wide range of engineering problems, such as risk-sensitive safety analysis, accident analysis and prevention, and extreme value theory. However, current methods for causal discovery are often unable to uncover causal links, between random variables in a dynamic setting, that manifest only when the variables first experience low-probability realizations. To address this issue, we introduce a novel statistical independence test on data collected from time-invariant dynamical systems in which rare but consequential events occur. In particular, we exploit the time-invariance of the underlying data to construct a superimposed dataset of the system state before rare events happen at different timesteps. We then design a conditional independence test on the reorganized data. We provide non-asymptotic sample complexity bounds for the consistency of our method, and validate its performance across various simulated and real-world datase
&lt;/p&gt;</description></item><item><title>&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25910;&#30410;&#20989;&#25968;&#65292;&#21487;&#20197;&#20165;&#20351;&#29992;&#27604;&#36739;&#26469;&#34913;&#37327;&#22522;&#20110;&#27604;&#36739;&#30340;&#20998;&#23618;&#32858;&#31867;&#30340;&#36136;&#37327;&#12290;</title><link>http://arxiv.org/abs/2211.16459</link><description>&lt;p&gt;
&#22522;&#20110;&#27604;&#36739;&#30340;&#23618;&#27425;&#32858;&#31867;&#30340;&#25910;&#30410;&#20989;&#25968;
&lt;/p&gt;
&lt;p&gt;
A Revenue Function for Comparison-Based Hierarchical Clustering. (arXiv:2211.16459v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.16459
&lt;/p&gt;
&lt;p&gt;
&#26412;&#35770;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25910;&#30410;&#20989;&#25968;&#65292;&#21487;&#20197;&#20165;&#20351;&#29992;&#27604;&#36739;&#26469;&#34913;&#37327;&#22522;&#20110;&#27604;&#36739;&#30340;&#20998;&#23618;&#32858;&#31867;&#30340;&#36136;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22522;&#20110;&#27604;&#36739;&#30340;&#23398;&#20064;&#35299;&#20915;&#30340;&#38382;&#39064;&#26159;&#24403;&#25105;&#20204;&#21482;&#26377;&#24418;&#24335;&#20026;&#8220;&#30446;&#26631;A&#19982;B&#30456;&#27604;&#36739;&#27604;C&#26356;&#30456;&#20284;&#8221;&#36825;&#26679;&#30340;&#27604;&#36739;&#65292;&#32780;&#27809;&#26377;&#26174;&#24335;&#29305;&#24449;&#25110;&#25104;&#23545;&#30456;&#20284;&#24230;&#26102;&#30340;&#23398;&#20064;&#38382;&#39064;&#12290;&#26368;&#36817;&#65292;&#24050;&#32463;&#35777;&#26126;&#22312;&#23618;&#27425;&#32858;&#31867;&#20013;&#65292;&#21487;&#20197;&#30452;&#25509;&#20351;&#29992;&#36825;&#26679;&#30340;&#27604;&#36739;&#23454;&#29616;&#21333;&#19968;&#21644;&#23436;&#20840;&#38142;&#25509;&#65292;&#21516;&#26102;&#24050;&#32463;&#25552;&#20986;&#20102;&#20960;&#31181;&#31639;&#27861;&#26469;&#27169;&#25311;&#24179;&#22343;&#38142;&#25509;&#30340;&#34892;&#20026;&#12290;&#22240;&#27492;&#65292;&#20351;&#29992;&#20165;&#27604;&#36739;&#25214;&#21040;&#23618;&#27425;&#32467;&#26500;&#65288;&#25110;&#26641;&#29366;&#22270;&#65289;&#26159;&#19968;&#20010;&#34987;&#20805;&#20998;&#29702;&#35299;&#30340;&#38382;&#39064;&#12290;&#28982;&#32780;&#65292;&#24403;&#27809;&#26377;&#22522;&#20934;&#20107;&#23454;&#25110;&#26174;&#24335;&#30456;&#20284;&#24615;&#26102;&#65292;&#35780;&#20272;&#23427;&#20204;&#30340;&#24847;&#20041;&#20173;&#28982;&#26159;&#19968;&#20010;&#24320;&#25918;&#24615;&#30340;&#38382;&#39064;&#12290;&#22312;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#36890;&#36807;&#25552;&#20986;&#19968;&#20010;&#26032;&#30340;&#25910;&#30410;&#20989;&#25968;&#26469;&#24357;&#34917;&#36825;&#19968;&#24046;&#36317;&#65292;&#35813;&#20989;&#25968;&#20801;&#35768;&#25105;&#20204;&#20165;&#20351;&#29992;&#27604;&#36739;&#26469;&#34913;&#37327;&#26641;&#29366;&#22270;&#30340;&#22909;&#22351;&#12290;&#25991;&#31456;&#36824;&#34920;&#26126;&#65292;&#35813;&#20989;&#25968;&#19982;&#20351;&#29992;&#25104;&#23545;&#30456;&#20284;&#24615;&#30340;&#23618;&#27425;&#32858;&#31867;&#30340;Dasgupta&#25104;&#26412;&#23494;&#20999;&#30456;&#20851;&#12290;&#22312;&#29702;&#35770;&#26041;&#38754;&#65292;&#25105;&#20204;&#20351;&#29992;&#25317;&#26377;&#22909;&#30340;&#24615;&#36136;&#30340;&#25910;&#30410;&#20989;&#25968;&#26469;&#20998;&#26512;&#27604;&#36739;&#30340;&#30456;&#20851;&#24615;&#65292;&#24182;&#25512;&#23548;&#20102;&#19968;&#20123;&#39640;&#26031;&#36807;&#31243;&#30340;&#30456;&#20851;&#32467;&#35770;&#12290;
&lt;/p&gt;
&lt;p&gt;
Comparison-based learning addresses the problem of learning when, instead of explicit features or pairwise similarities, one only has access to comparisons of the form: \emph{Object $A$ is more similar to $B$ than to $C$.} Recently, it has been shown that, in Hierarchical Clustering, single and complete linkage can be directly implemented using only such comparisons while several algorithms have been proposed to emulate the behaviour of average linkage. Hence, finding hierarchies (or dendrograms) using only comparisons is a well understood problem. However, evaluating their meaningfulness when no ground-truth nor explicit similarities are available remains an open question.  In this paper, we bridge this gap by proposing a new revenue function that allows one to measure the goodness of dendrograms using only comparisons. We show that this function is closely related to Dasgupta's cost for hierarchical clustering that uses pairwise similarities. On the theoretical side, we use the propo
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#37327;&#21270;&#20102;&#26631;&#31614;&#22122;&#22768;&#23545;FL&#30340;&#24433;&#21709;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#38543;&#30528;&#22122;&#22768;&#27700;&#24179;&#30340;&#22686;&#21152;&#65292;&#20840;&#23616;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#20250;&#32447;&#24615;&#19979;&#38477;&#65292;&#21516;&#26102;&#20250;&#23548;&#33268;FL&#35757;&#32451;&#30340;&#25910;&#25947;&#36895;&#24230;&#20943;&#32531;&#21644;&#20840;&#23616;&#27169;&#22411;&#36807;&#25311;&#21512;&#12290;</title><link>http://arxiv.org/abs/2211.07816</link><description>&lt;p&gt;
&#35770;&#25991;&#26631;&#39064;&#65306;&#37327;&#21270;&#26631;&#31614;&#22122;&#22768;&#23545;&#32852;&#37030;&#23398;&#20064;&#30340;&#24433;&#21709;
&lt;/p&gt;
&lt;p&gt;
Quantifying the Impact of Label Noise on Federated Learning. (arXiv:2211.07816v7 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.07816
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#37327;&#21270;&#20102;&#26631;&#31614;&#22122;&#22768;&#23545;FL&#30340;&#24433;&#21709;&#12290;&#23454;&#39564;&#32467;&#26524;&#34920;&#26126;&#65292;&#38543;&#30528;&#22122;&#22768;&#27700;&#24179;&#30340;&#22686;&#21152;&#65292;&#20840;&#23616;&#27169;&#22411;&#30340;&#20934;&#30830;&#24615;&#20250;&#32447;&#24615;&#19979;&#38477;&#65292;&#21516;&#26102;&#20250;&#23548;&#33268;FL&#35757;&#32451;&#30340;&#25910;&#25947;&#36895;&#24230;&#20943;&#32531;&#21644;&#20840;&#23616;&#27169;&#22411;&#36807;&#25311;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#32852;&#37030;&#23398;&#20064;&#26159;&#19968;&#31181;&#20998;&#24067;&#24335;&#26426;&#22120;&#23398;&#20064;&#33539;&#20363;&#65292;&#23458;&#25143;&#31471;&#21487;&#20197;&#20351;&#29992;&#26412;&#22320;&#65288;&#20154;&#20026;&#29983;&#25104;&#30340;&#65289;&#25968;&#25454;&#38598;&#21327;&#21516;&#35757;&#32451;&#27169;&#22411;&#12290;&#28982;&#32780;&#65292;&#29616;&#26377;&#30740;&#31350;&#38598;&#20013;&#22312;FL&#31639;&#27861;&#30340;&#24320;&#21457;&#19978;&#20197;&#35299;&#20915;&#23458;&#25143;&#31471;&#20043;&#38388;&#30340;&#25968;&#25454;&#24322;&#36136;&#24615;&#65292;&#32780;&#22312;FL&#20013;&#25968;&#25454;&#36136;&#37327;&#65288;&#22914;&#26631;&#31614;&#22122;&#22768;&#65289;&#36825;&#19968;&#37325;&#35201;&#38382;&#39064;&#34987;&#24573;&#35270;&#12290;&#26412;&#25991;&#26088;&#22312;&#36890;&#36807;&#23545;&#26631;&#31614;&#22122;&#22768;&#23545;FL&#30340;&#24433;&#21709;&#36827;&#34892;&#23450;&#37327;&#30740;&#31350;&#26469;&#22635;&#34917;&#36825;&#19968;&#31354;&#30333;&#12290;&#25105;&#20204;&#25512;&#23548;&#20102;&#19968;&#31181;&#19978;&#30028;&#26469;&#34913;&#37327;&#23458;&#25143;&#31471;&#26631;&#31614;&#22122;&#22768;&#27700;&#24179;&#23545;&#27867;&#21270;&#35823;&#24046;&#30340;&#24433;&#21709;&#65292;&#24182;&#20351;&#29992;&#21508;&#31181;FL&#31639;&#27861;&#22312;MNIST&#21644;CIFAR-10&#25968;&#25454;&#38598;&#19978;&#36827;&#34892;&#23454;&#39564;&#12290;&#25105;&#20204;&#30340;&#23454;&#35777;&#32467;&#26524;&#34920;&#26126;&#65292;&#38543;&#30528;&#22122;&#22768;&#27700;&#24179;&#30340;&#22686;&#21152;&#65292;&#20840;&#23616;&#27169;&#22411;&#20934;&#30830;&#24615;&#20250;&#32447;&#24615;&#19979;&#38477;&#65292;&#36825;&#19982;&#25105;&#20204;&#30340;&#29702;&#35770;&#20998;&#26512;&#30456;&#19968;&#33268;&#12290;&#25105;&#20204;&#36827;&#19968;&#27493;&#21457;&#29616;&#65292;&#22312;&#26631;&#31614;&#22122;&#22768;&#36739;&#39640;&#26102;&#65292;&#26631;&#31614;&#22122;&#22768;&#20250;&#20943;&#32531;FL&#35757;&#32451;&#30340;&#25910;&#25947;&#36895;&#24230;&#65292;&#24182;&#23548;&#33268;&#20840;&#23616;&#27169;&#22411;&#36807;&#25311;&#21512;&#12290;
&lt;/p&gt;
&lt;p&gt;
Federated Learning (FL) is a distributed machine learning paradigm where clients collaboratively train a model using their local (human-generated) datasets. While existing studies focus on FL algorithm development to tackle data heterogeneity across clients, the important issue of data quality (e.g., label noise) in FL is overlooked. This paper aims to fill this gap by providing a quantitative study on the impact of label noise on FL. We derive an upper bound for the generalization error that is linear in the clients' label noise level. Then we conduct experiments on MNIST and CIFAR-10 datasets using various FL algorithms. Our empirical results show that the global model accuracy linearly decreases as the noise level increases, which is consistent with our theoretical analysis. We further find that label noise slows down the convergence of FL training, and the global model tends to overfit when the noise level is high.
&lt;/p&gt;</description></item><item><title>&#35813;&#35770;&#25991;&#25552;&#20986;&#30340;&#22686;&#24378;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#33021;&#22815;&#27169;&#25311;&#22823;&#37327;&#23439;&#35266;&#32463;&#27982;&#21644;&#37329;&#34701;&#21464;&#37327;&#30340;&#36890;&#29992;&#38750;&#32447;&#24615;&#21644;&#26102;&#38388;&#21464;&#21270;&#65292;&#20855;&#26377;&#28508;&#22312;&#30340;&#25919;&#31574;&#20915;&#31574;&#24212;&#29992;&#20215;&#20540;&#12290;</title><link>http://arxiv.org/abs/2211.04752</link><description>&lt;p&gt;
&#22686;&#24378;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#22312;&#23439;&#35266;&#32463;&#27982;&#21644;&#37329;&#34701;&#39046;&#22495;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Enhanced Bayesian Neural Networks for Macroeconomics and Finance. (arXiv:2211.04752v3 [econ.EM] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2211.04752
&lt;/p&gt;
&lt;p&gt;
&#35813;&#35770;&#25991;&#25552;&#20986;&#30340;&#22686;&#24378;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476;&#33021;&#22815;&#27169;&#25311;&#22823;&#37327;&#23439;&#35266;&#32463;&#27982;&#21644;&#37329;&#34701;&#21464;&#37327;&#30340;&#36890;&#29992;&#38750;&#32447;&#24615;&#21644;&#26102;&#38388;&#21464;&#21270;&#65292;&#20855;&#26377;&#28508;&#22312;&#30340;&#25919;&#31574;&#20915;&#31574;&#24212;&#29992;&#20215;&#20540;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#24320;&#21457;&#20102;&#36125;&#21494;&#26031;&#31070;&#32463;&#32593;&#32476; (BNNs)&#65292;&#23427;&#20204;&#33021;&#22815;&#27169;&#25311;&#21487;&#33021;&#21253;&#21547;&#22823;&#37327;&#23439;&#35266;&#32463;&#27982;&#21644;&#37329;&#34701;&#21464;&#37327;&#30340;&#36890;&#29992;&#38750;&#32447;&#24615;&#21644;&#26102;&#38388;&#21464;&#21270;&#12290;&#20174;&#26041;&#27861;&#35770;&#19978;&#35762;&#65292;&#25105;&#20204;&#20801;&#35768;&#23545;&#32593;&#32476;&#36827;&#34892;&#19968;&#33324;&#35268;&#26684;&#30340;&#35828;&#26126;&#65292;&#21487;&#20197;&#24212;&#29992;&#20110;&#23494;&#38598;&#25110;&#31232;&#30095;&#25968;&#25454;&#38598;&#65292;&#24182;&#32467;&#21512;&#21508;&#31181;&#28608;&#27963;&#21151;&#33021;&#12289;&#21487;&#33021;&#38750;&#24120;&#22810;&#30340;&#31070;&#32463;&#20803;&#21644;&#35823;&#24046;&#39033;&#30340;&#38543;&#26426;&#27874;&#21160;&#12290;&#20174;&#35745;&#31639;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#25105;&#20204;&#20026;&#24341;&#20837;&#30340;&#36890;&#29992;BNNs&#24320;&#21457;&#20102;&#24555;&#36895;&#39640;&#25928;&#30340;&#20272;&#35745;&#31639;&#27861;&#12290;&#20174;&#23454;&#35777;&#30340;&#35282;&#24230;&#26469;&#30475;&#65292;&#25105;&#20204;&#29992;&#27169;&#25311;&#25968;&#25454;&#21644;&#19968;&#32452;&#24120;&#35265;&#30340;&#23439;&#35266;&#37329;&#34701;&#24212;&#29992;&#26469;&#23637;&#31034;&#25105;&#20204;&#30340;BNNs&#21487;&#20197;&#23454;&#38469;&#20351;&#29992;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#35266;&#27979;&#30446;&#26631;&#21464;&#37327;&#30340;&#27178;&#25130;&#38754;&#25110;&#26102;&#38388;&#24207;&#21015;&#20998;&#24067;&#30340;&#23614;&#37096;&#65292;&#35813;&#26041;&#27861;&#29305;&#21035;&#36866;&#29992;&#20110;&#22312;&#19981;&#23547;&#24120;&#30340;&#26102;&#38388;&#20570;&#20986;&#20915;&#31574;&#26041;&#38754;&#20855;&#26377;&#20449;&#24687;&#37327;&#12290;
&lt;/p&gt;
&lt;p&gt;
We develop Bayesian neural networks (BNNs) that permit to model generic nonlinearities and time variation for (possibly large sets of) macroeconomic and financial variables. From a methodological point of view, we allow for a general specification of networks that can be applied to either dense or sparse datasets, and combines various activation functions, a possibly very large number of neurons, and stochastic volatility (SV) for the error term. From a computational point of view, we develop fast and efficient estimation algorithms for the general BNNs we introduce. From an empirical point of view, we show both with simulated data and with a set of common macro and financial applications that our BNNs can be of practical use, particularly so for observations in the tails of the cross-sectional or time series distributions of the target variables, which makes the method particularly informative for policy making in uncommon times.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#32508;&#36848;&#20102;&#35299;&#20915;&#24179;&#28369;&#65288;&#24378;&#65289;&#21333;&#35843;&#38543;&#26426;&#21464;&#20998;&#19981;&#31561;&#24335;&#30340;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2208.13592</link><description>&lt;p&gt;
&#24179;&#28369;&#21333;&#35843;&#38543;&#26426;&#21464;&#20998;&#19981;&#31561;&#24335;&#19982;&#38797;&#28857;&#38382;&#39064;&#65306;&#32508;&#36848;
&lt;/p&gt;
&lt;p&gt;
Smooth Monotone Stochastic Variational Inequalities and Saddle Point Problems: A Survey. (arXiv:2208.13592v3 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.13592
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#35299;&#20915;&#24179;&#28369;&#65288;&#24378;&#65289;&#21333;&#35843;&#38543;&#26426;&#21464;&#20998;&#19981;&#31561;&#24335;&#30340;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#32508;&#36848;&#20102;&#35299;&#20915;&#24179;&#28369;&#65288;&#24378;&#65289;&#21333;&#35843;&#38543;&#26426;&#21464;&#20998;&#19981;&#31561;&#24335;&#30340;&#26041;&#27861;&#12290;&#39318;&#20808;&#65292;&#25105;&#20204;&#32473;&#20986;&#20102;&#38543;&#26426;&#26041;&#27861;&#26368;&#32456;&#28436;&#21464;&#30340;&#30830;&#23450;&#24615;&#22522;&#30784;&#12290;&#28982;&#21518;&#25105;&#20204;&#22238;&#39038;&#20102;&#19968;&#33324;&#38543;&#26426;&#20844;&#24335;&#30340;&#26041;&#27861;&#65292;&#30475;&#30475;&#26377;&#38480;&#21644;&#35774;&#32622;&#12290;&#26368;&#21518;&#37096;&#20998;&#26159;&#33268;&#21147;&#20110;&#21508;&#31181;&#26368;&#36817;&#30340;&#65288;&#19981;&#19968;&#23450;&#26159;&#38543;&#26426;&#30340;&#65289;&#31639;&#27861;&#21464;&#20998;&#19981;&#31561;&#24335;&#30340;&#36827;&#27493;&#30340;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper is a survey of methods for solving smooth (strongly) monotone stochastic variational inequalities. To begin with, we give the deterministic foundation from which the stochastic methods eventually evolved. Then we review methods for the general stochastic formulation, and look at the finite sum setup. The last parts of the paper are devoted to various recent (not necessarily stochastic) advances in algorithms for variational inequalities.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#32447;&#24615;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#30340;&#22240;&#26524;&#36172;&#21338;&#31639;&#27861;&#65292;&#25682;&#24323;&#20102;&#24050;&#30693;&#24178;&#39044;&#20998;&#24067;&#25110;&#20854;&#36793;&#32536;&#20998;&#24067;&#30340;&#20551;&#35774;&#12290;</title><link>http://arxiv.org/abs/2208.12764</link><description>&lt;p&gt;
&#32447;&#24615;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#30340;&#22240;&#26524;&#36172;&#21338;&#31639;&#27861;
&lt;/p&gt;
&lt;p&gt;
Causal Bandits for Linear Structural Equation Models. (arXiv:2208.12764v3 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.12764
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#38024;&#23545;&#32447;&#24615;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#30340;&#22240;&#26524;&#36172;&#21338;&#31639;&#27861;&#65292;&#25682;&#24323;&#20102;&#24050;&#30693;&#24178;&#39044;&#20998;&#24067;&#25110;&#20854;&#36793;&#32536;&#20998;&#24067;&#30340;&#20551;&#35774;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;&#35774;&#35745;&#26368;&#20248;&#24178;&#39044;&#39034;&#24207;&#65292;&#20197;&#26368;&#23567;&#21270;&#20851;&#20110;&#21518;&#35265;&#26368;&#20339;&#24178;&#39044;&#30340;&#32047;&#31215;&#36951;&#25022;&#30340;&#38382;&#39064;&#12290;&#36825;&#26159;&#19968;&#20010;&#22240;&#26524;&#36172;&#21338;&#38382;&#39064;&#65292;&#20027;&#35201;&#20851;&#27880;&#32447;&#24615;&#32467;&#26500;&#26041;&#31243;&#27169;&#22411;&#65288;SEM&#65289;&#21644;&#36719;&#24178;&#39044;&#30340;&#22240;&#26524;&#36172;&#21338;&#38382;&#39064;&#12290;&#20551;&#35774;&#22270;&#30340;&#32467;&#26500;&#24050;&#30693;&#24182;&#19988;&#20855;&#26377;N&#20010;&#33410;&#28857;&#65292;&#27599;&#20010;&#33410;&#28857;&#20551;&#35774;&#20004;&#20010;&#32447;&#24615;&#26426;&#21046;&#65292;&#19968;&#20010;&#36719;&#24178;&#39044;&#21644;&#19968;&#20010;&#35266;&#27979;&#20540;&#65292;&#20849;&#20135;&#29983;$2^N$&#31181;&#21487;&#33021;&#24178;&#39044;&#12290;&#22823;&#37096;&#20998;&#29616;&#26377;&#30340;&#22240;&#26524;&#36172;&#21338;&#31639;&#27861;&#20551;&#35774;&#33267;&#23569;&#24050;&#32463;&#23436;&#20840;&#25351;&#23450;&#20102;&#22870;&#21169;&#33410;&#28857;&#30340;&#29238;&#33410;&#28857;&#24178;&#39044;&#20998;&#24067;&#12290;&#28982;&#32780;&#65292;&#22312;&#20013;&#31561;&#22823;&#23567;&#30340;&#22270;&#20013;&#65292;&#38656;&#35201;&#33719;&#24471;$2^N$&#20010;&#24178;&#39044;&#20998;&#24067;&#65288;&#27599;&#20010;&#24178;&#39044;&#23545;&#24212;&#19968;&#20010;&#24178;&#39044;&#20998;&#24067;&#65289;&#65292;&#36825;&#21464;&#24471;&#19981;&#20999;&#23454;&#38469;&#12290;&#26412;&#25991;&#25682;&#24323;&#20102;&#30693;&#36947;&#36825;&#20123;&#20998;&#24067;&#25110;&#20854;&#36793;&#32536;&#20998;&#24067;&#30340;&#20551;&#35774;&#65292;&#20026;&#39057;&#29575;&#27966;&#25552;&#20986;&#20102;&#20004;&#31181;&#31639;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper studies the problem of designing an optimal sequence of interventions in a causal graphical model to minimize cumulative regret with respect to the best intervention in hindsight. This is, naturally, posed as a causal bandit problem. The focus is on causal bandits for linear structural equation models (SEMs) and soft interventions. It is assumed that the graph's structure is known and has $N$ nodes. Two linear mechanisms, one soft intervention and one observational, are assumed for each node, giving rise to $2^N$ possible interventions. Majority of the existing causal bandit algorithms assume that at least the interventional distributions of the reward node's parents are fully specified. However, there are $2^N$ such distributions (one corresponding to each intervention), acquiring which becomes prohibitive even in moderate-sized graphs. This paper dispenses with the assumption of knowing these distributions or their marginals. Two algorithms are proposed for the frequentist
&lt;/p&gt;</description></item><item><title>&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29992;&#20110;&#20248;&#21270;&#30340;&#20449;&#24687;&#20016;&#23500;&#21327;&#26041;&#24046;&#20989;&#25968;&#65292;&#21033;&#29992;&#38750;&#24179;&#31283;&#24615;&#26469;&#32534;&#30721;&#23545;&#25628;&#32034;&#31354;&#38388;&#20013;&#26576;&#20123;&#21306;&#22495;&#30340;&#20559;&#22909;&#65292;&#24182;&#22312;&#20248;&#21270;&#36807;&#31243;&#20013;&#33258;&#36866;&#24212;&#22320;&#20419;&#36827;&#23616;&#37096;&#25506;&#32034;&#65292;&#20197;&#25552;&#39640;&#36125;&#21494;&#26031;&#20248;&#21270;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#30340;&#26679;&#26412;&#25928;&#29575;&#12290;</title><link>http://arxiv.org/abs/2208.02704</link><description>&lt;p&gt;
&#24102;&#20449;&#24687;&#21327;&#26041;&#24046;&#30340;&#36125;&#21494;&#26031;&#20248;&#21270;
&lt;/p&gt;
&lt;p&gt;
Bayesian Optimization with Informative Covariance. (arXiv:2208.02704v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2208.02704
&lt;/p&gt;
&lt;p&gt;
&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29992;&#20110;&#20248;&#21270;&#30340;&#20449;&#24687;&#20016;&#23500;&#21327;&#26041;&#24046;&#20989;&#25968;&#65292;&#21033;&#29992;&#38750;&#24179;&#31283;&#24615;&#26469;&#32534;&#30721;&#23545;&#25628;&#32034;&#31354;&#38388;&#20013;&#26576;&#20123;&#21306;&#22495;&#30340;&#20559;&#22909;&#65292;&#24182;&#22312;&#20248;&#21270;&#36807;&#31243;&#20013;&#33258;&#36866;&#24212;&#22320;&#20419;&#36827;&#23616;&#37096;&#25506;&#32034;&#65292;&#20197;&#25552;&#39640;&#36125;&#21494;&#26031;&#20248;&#21270;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#30340;&#26679;&#26412;&#25928;&#29575;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#36125;&#21494;&#26031;&#20248;&#21270;&#26159;&#19968;&#31181;&#22788;&#29702;&#26410;&#30693;&#21644;&#26114;&#36149;&#30446;&#26631;&#30340;&#20840;&#23616;&#20248;&#21270;&#26041;&#27861;&#12290;&#23427;&#23558;&#19968;&#20010;&#25311;&#21512;&#36125;&#21494;&#26031;&#22238;&#24402;&#27169;&#22411;&#19982;&#19968;&#20010;&#25910;&#33719;&#20989;&#25968;&#32467;&#21512;&#36215;&#26469;&#65292;&#20197;&#20915;&#23450;&#22312;&#21738;&#37324;&#35780;&#20272;&#30446;&#26631;&#12290;&#20856;&#22411;&#30340;&#22238;&#24402;&#27169;&#22411;&#30001;&#20855;&#26377;&#24179;&#31283;&#21327;&#26041;&#24046;&#20989;&#25968;&#30340;&#39640;&#26031;&#36807;&#31243;&#34920;&#31034;&#12290;&#28982;&#32780;&#65292;&#36825;&#20123;&#20989;&#25968;&#26080;&#27861;&#34920;&#36798;&#36755;&#20837;&#30456;&#20851;&#30340;&#20808;&#39564;&#20449;&#24687;&#65292;&#21253;&#25324;&#26368;&#20248;&#28857;&#21487;&#33021;&#20986;&#29616;&#30340;&#20301;&#32622;&#12290;&#24179;&#31283;&#27169;&#22411;&#30340;&#26222;&#21450;&#23548;&#33268;&#20102;&#36890;&#36807;&#20449;&#24687;&#20016;&#23500;&#30340;&#22343;&#20540;&#20989;&#25968;&#21033;&#29992;&#20808;&#39564;&#20449;&#24687;&#30340;&#24120;&#35265;&#20570;&#27861;&#12290;&#26412;&#25991;&#20013;&#65292;&#25105;&#20204;&#24378;&#35843;&#36825;&#20123;&#27169;&#22411;&#22312;&#39640;&#32500;&#24773;&#20917;&#19979;&#21487;&#33021;&#34920;&#29616;&#19981;&#20339;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#39062;&#30340;&#29992;&#20110;&#20248;&#21270;&#30340;&#20449;&#24687;&#20016;&#23500;&#21327;&#26041;&#24046;&#20989;&#25968;&#65292;&#21033;&#29992;&#38750;&#24179;&#31283;&#24615;&#26469;&#32534;&#30721;&#23545;&#25628;&#32034;&#31354;&#38388;&#20013;&#26576;&#20123;&#21306;&#22495;&#30340;&#20559;&#22909;&#65292;&#24182;&#22312;&#20248;&#21270;&#36807;&#31243;&#20013;&#33258;&#36866;&#24212;&#22320;&#20419;&#36827;&#23616;&#37096;&#25506;&#32034;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#25152;&#25552;&#20986;&#30340;&#20989;&#25968;&#21487;&#20197;&#25552;&#39640;&#36125;&#21494;&#26031;&#20248;&#21270;&#22312;&#39640;&#32500;&#31354;&#38388;&#20013;&#30340;&#26679;&#26412;&#25928;&#29575;&#65292;&#22312;&#22522;&#20934;&#38382;&#39064;&#20013;&#36798;&#21040;&#20102;&#26368;&#20808;&#36827;&#30340;&#24615;&#33021;&#12290;
&lt;/p&gt;
&lt;p&gt;
Bayesian optimization is a methodology for global optimization of unknown and expensive objectives. It combines a surrogate Bayesian regression model with an acquisition function to decide where to evaluate the objective. Typical regression models are given by Gaussian processes with stationary covariance functions. However, these functions are unable to express prior input-dependent information, including possible locations of the optimum. The ubiquity of stationary models has led to the common practice of exploiting prior information via informative mean functions. In this paper, we highlight that these models can perform poorly, especially in high dimensions. We propose novel informative covariance functions for optimization, leveraging nonstationarity to encode preferences for certain regions of the search space and adaptively promote local exploration during optimization. We demonstrate that the proposed functions can increase the sample efficiency of Bayesian optimization in high
&lt;/p&gt;</description></item><item><title>&#30740;&#31350;&#34920;&#26126;&#65292;&#24403;&#27809;&#26377;&#20854;&#20182;&#27491;&#21017;&#21270;&#25216;&#26415;&#26102;&#65292;&#37325;&#26032;&#21021;&#22987;&#21270;&#31070;&#32463;&#32593;&#32476;&#26377;&#21161;&#20110;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#12290;&#20294;&#26159;&#65292;&#24403;&#23427;&#19982;&#20854;&#20182;&#27491;&#21017;&#21270;&#25216;&#26415;&#19968;&#36215;&#20351;&#29992;&#26102;&#65292;&#23545;&#27867;&#21270;&#24615;&#33021;&#30340;&#39069;&#22806;&#24110;&#21161;&#24456;&#23567;&#65292;&#23613;&#31649;&#26368;&#20339;&#27867;&#21270;&#24615;&#33021;&#21464;&#24471;&#26356;&#21152;&#31283;&#23450;&#12290;</title><link>http://arxiv.org/abs/2206.10011</link><description>&lt;p&gt;
&#20309;&#26102;&#37325;&#26032;&#21021;&#22987;&#21270;&#31070;&#32463;&#32593;&#32476;&#26159;&#26377;&#25928;&#30340;&#65311;
&lt;/p&gt;
&lt;p&gt;
When Does Re-initialization Work?. (arXiv:2206.10011v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.10011
&lt;/p&gt;
&lt;p&gt;
&#30740;&#31350;&#34920;&#26126;&#65292;&#24403;&#27809;&#26377;&#20854;&#20182;&#27491;&#21017;&#21270;&#25216;&#26415;&#26102;&#65292;&#37325;&#26032;&#21021;&#22987;&#21270;&#31070;&#32463;&#32593;&#32476;&#26377;&#21161;&#20110;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#12290;&#20294;&#26159;&#65292;&#24403;&#23427;&#19982;&#20854;&#20182;&#27491;&#21017;&#21270;&#25216;&#26415;&#19968;&#36215;&#20351;&#29992;&#26102;&#65292;&#23545;&#27867;&#21270;&#24615;&#33021;&#30340;&#39069;&#22806;&#24110;&#21161;&#24456;&#23567;&#65292;&#23613;&#31649;&#26368;&#20339;&#27867;&#21270;&#24615;&#33021;&#21464;&#24471;&#26356;&#21152;&#31283;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#22312;&#26368;&#36817;&#30340;&#30740;&#31350;&#20013;&#35266;&#23519;&#21040;&#65292;&#37325;&#26032;&#21021;&#22987;&#21270;&#31070;&#32463;&#32593;&#32476;&#22312;&#35757;&#32451;&#36807;&#31243;&#20013;&#26377;&#21161;&#20110;&#25552;&#39640;&#27867;&#21270;&#24615;&#33021;&#12290;&#28982;&#32780;&#65292;&#22312;&#28145;&#24230;&#23398;&#20064;&#23454;&#36341;&#20013;&#65292;&#36825;&#31181;&#26041;&#27861;&#24182;&#19981;&#34987;&#24191;&#27867;&#37319;&#29992;&#65292;&#20063;&#19981;&#24120;&#29992;&#20110;&#26368;&#20808;&#36827;&#30340;&#35757;&#32451;&#21327;&#35758;&#20013;&#12290;&#22240;&#27492;&#65292;&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#38382;&#39064;&#65292;&#21363;&#37325;&#26032;&#21021;&#22987;&#21270;&#20160;&#20040;&#26102;&#20505;&#26377;&#25928;&#65292;&#26159;&#21542;&#24212;&#35813;&#19982;&#25968;&#25454;&#22686;&#24378;&#12289;&#26435;&#37325;&#34928;&#20943;&#21644;&#23398;&#20064;&#29575;&#35843;&#25972;&#31561;&#27491;&#21017;&#21270;&#25216;&#26415;&#19968;&#36215;&#20351;&#29992;&#12290;&#26412;&#30740;&#31350;&#23545;&#26631;&#20934;&#35757;&#32451;&#19982;&#19968;&#20123;&#37325;&#26032;&#21021;&#22987;&#21270;&#26041;&#27861;&#36827;&#34892;&#20102;&#24191;&#27867;&#30340;&#23454;&#35777;&#27604;&#36739;&#65292;&#35757;&#32451;&#20102;&#36229;&#36807;15,000&#20010;&#27169;&#22411;&#65292;&#24182;&#22312;&#21508;&#31181;&#22270;&#20687;&#20998;&#31867;&#22522;&#20934;&#19978;&#36827;&#34892;&#20102;&#27979;&#35797;&#65292;&#20197;&#22238;&#31572;&#36825;&#20010;&#38382;&#39064;&#12290;&#25105;&#20204;&#39318;&#20808;&#30830;&#23450;&#65292;&#24403;&#27809;&#26377;&#20219;&#20309;&#20854;&#20182;&#27491;&#21017;&#21270;&#23384;&#22312;&#26102;&#65292;&#36825;&#20123;&#26041;&#27861;&#21487;&#20197;&#22312;&#27867;&#21270;&#26041;&#38754;&#25345;&#32493;&#25913;&#21892;&#12290;&#28982;&#32780;&#65292;&#24403;&#36825;&#20123;&#26041;&#27861;&#19982;&#20854;&#20182;&#32463;&#36807;&#31934;&#24515;&#35843;&#25972;&#30340;&#27491;&#21017;&#21270;&#25216;&#26415;&#19968;&#36215;&#20351;&#29992;&#26102;&#65292;&#37325;&#26032;&#21021;&#22987;&#21270;&#26041;&#27861;&#23545;&#27867;&#21270;&#24615;&#33021;&#20960;&#20046;&#27809;&#26377;&#39069;&#22806;&#30340;&#24110;&#21161;&#65292;&#23613;&#31649;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#26368;&#20339;&#27867;&#21270;&#24615;&#33021;&#21464;&#24471;&#26356;&#21152;&#31283;&#23450;&#12290;
&lt;/p&gt;
&lt;p&gt;
Re-initializing a neural network during training has been observed to improve generalization in recent works. Yet it is neither widely adopted in deep learning practice nor is it often used in state-of-the-art training protocols. This raises the question of when re-initialization works, and whether it should be used together with regularization techniques such as data augmentation, weight decay and learning rate schedules. In this work, we conduct an extensive empirical comparison of standard training with a selection of re-initialization methods to answer this question, training over 15,000 models on a variety of image classification benchmarks. We first establish that such methods are consistently beneficial for generalization in the absence of any other regularization. However, when deployed alongside other carefully tuned regularization techniques, re-initialization methods offer little to no added benefit for generalization, although optimal generalization performance becomes less
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#21457;&#29616;&#33391;&#24615;&#36807;&#25311;&#21512;&#22312;&#23384;&#22312;&#26631;&#31614;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#21487;&#33021;&#20250;&#22833;&#36133;&#65292;&#25552;&#37266;&#26410;&#26469;&#38656;&#35201;&#29702;&#35299;&#27424;&#25311;&#21512;&#21046;&#24230;&#19979;&#30340;&#38544;&#24335;&#20559;&#35265;&#12290;</title><link>http://arxiv.org/abs/2206.00501</link><description>&lt;p&gt;
&#20998;&#31867;&#20013;&#30340;&#33391;&#24615;&#36807;&#25311;&#21512;&#65306;&#26356;&#22823;&#27169;&#22411;&#30340;&#21457;&#29616;&#21487;&#35777;&#26126;&#23545;&#25239;&#26631;&#31614;&#22122;&#22768;
&lt;/p&gt;
&lt;p&gt;
Benign Overfitting in Classification: Provably Counter Label Noise with Larger Models. (arXiv:2206.00501v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2206.00501
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#21457;&#29616;&#33391;&#24615;&#36807;&#25311;&#21512;&#22312;&#23384;&#22312;&#26631;&#31614;&#22122;&#22768;&#30340;&#24773;&#20917;&#19979;&#21487;&#33021;&#20250;&#22833;&#36133;&#65292;&#25552;&#37266;&#26410;&#26469;&#38656;&#35201;&#29702;&#35299;&#27424;&#25311;&#21512;&#21046;&#24230;&#19979;&#30340;&#38544;&#24335;&#20559;&#35265;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#33391;&#24615;&#36807;&#25311;&#21512;&#30340;&#30740;&#31350;&#20026;&#36229;&#21442;&#25968;&#21270;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#30340;&#25104;&#21151;&#25552;&#20379;&#20102;&#35265;&#35299;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#36807;&#25311;&#21512;&#26159;&#21542;&#22312;&#30495;&#23454;&#19990;&#30028;&#30340;&#20998;&#31867;&#20219;&#21153;&#20013;&#30495;&#30340;&#26159;&#33391;&#24615;&#30340;&#12290;&#25105;&#20204;&#24320;&#22987;&#35266;&#23519;&#21040;&#19968;&#20010; ResNet &#27169;&#22411;&#22312; Cifar10 &#19978;&#34920;&#29616;&#33391;&#22909;&#65292;&#20294;&#22312; ImageNet &#19978;&#21017;&#19981;&#33391;&#12290;&#20026;&#20102;&#20102;&#35299;&#20026;&#20160;&#20040;&#33391;&#24615;&#36807;&#25311;&#21512;&#22312; ImageNet &#23454;&#39564;&#20013;&#22833;&#36133;&#65292;&#25105;&#20204;&#22312;&#19968;&#20010;&#27604;&#25968;&#25454;&#28857;&#25968;&#37327;&#19981;&#26126;&#26174;&#22823;&#30340;&#38480;&#23450;&#26465;&#20214;&#19979;&#20174;&#29702;&#35770;&#19978;&#20998;&#26512;&#20102;&#33391;&#24615;&#36807;&#25311;&#21512;&#12290;&#22312;&#36825;&#20010;&#36731;&#24494;&#36229;&#21442;&#25968;&#21270;&#30340;&#35774;&#32622;&#19979;&#65292;&#25105;&#20204;&#30340;&#20998;&#26512;&#21457;&#29616;&#20102;&#19968;&#20010;&#30456;&#21464;&#65306;&#19982;&#20043;&#21069;&#30340;&#37325;&#36229;&#21442;&#25968;&#21270;&#35774;&#32622;&#19981;&#21516;&#65292;&#24403;&#23384;&#22312;&#26631;&#31614;&#22122;&#22768;&#26102;&#65292;&#33391;&#24615;&#36807;&#25311;&#21512;&#29616;&#22312;&#21487;&#33021;&#20250;&#22833;&#36133;&#12290;&#25105;&#20204;&#30340;&#20998;&#26512;&#35299;&#37322;&#20102;&#25105;&#20204;&#30340;&#32463;&#39564;&#35266;&#23519;&#65292;&#24182;&#36890;&#36807;&#19968;&#32452; ResNet &#30340;&#25511;&#21046;&#23454;&#39564;&#36827;&#34892;&#20102;&#39564;&#35777;&#12290;&#25105;&#20204;&#30340;&#24037;&#20316;&#24378;&#35843;&#20102;&#29702;&#35299;&#27424;&#25311;&#21512;&#21046;&#24230;&#19979;&#30340;&#38544;&#24335;&#20559;&#35265;&#30340;&#37325;&#35201;&#24615;&#65292;&#20316;&#20026;&#26410;&#26469;&#30340;&#19968;&#20010;&#26041;&#21521;&#12290;
&lt;/p&gt;
&lt;p&gt;
Studies on benign overfitting provide insights for the success of overparameterized deep learning models. In this work, we examine whether overfitting is truly benign in real-world classification tasks. We start with the observation that a ResNet model overfits benignly on Cifar10 but not benignly on ImageNet. To understand why benign overfitting fails in the ImageNet experiment, we theoretically analyze benign overfitting under a more restrictive setup where the number of parameters is not significantly larger than the number of data points. Under this mild overparameterization setup, our analysis identifies a phase change: unlike in the previous heavy overparameterization settings, benign overfitting can now fail in the presence of label noise. Our analysis explains our empirical observations, and is validated by a set of control experiments with ResNets. Our work highlights the importance of understanding implicit bias in underfitting regimes as a future direction.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#24635;&#32467;&#34913;&#37327;&#26631;&#20934;&#8212;&#8212;&#24179;&#22343;&#35843;&#25972;&#20851;&#32852;&#24230;&#65288;AAA&#65289;&#65292;&#29992;&#20110;&#35780;&#20272;&#19968;&#20010;&#20855;&#26377;&#28151;&#28102;&#24433;&#21709;&#30340;&#24322;&#36136;&#32676;&#20307;&#20013;&#30340;&#20851;&#32852;&#31243;&#24230;&#12290;&#24182;&#19988;&#25105;&#20204;&#25552;&#20986;&#20102;&#39640;&#25928;&#30340;&#20272;&#35745;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#21508;&#31181;&#37319;&#26679;&#22330;&#26223;&#12290;</title><link>http://arxiv.org/abs/2205.14048</link><description>&lt;p&gt;
&#24179;&#22343;&#35843;&#25972;&#20851;&#32852;&#24230;&#65306;&#39640;&#32500;&#28151;&#28102;&#22240;&#32032;&#30340;&#39640;&#25928;&#20272;&#35745;
&lt;/p&gt;
&lt;p&gt;
Average Adjusted Association: Efficient Estimation with High Dimensional Confounders. (arXiv:2205.14048v2 [stat.ME] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2205.14048
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;&#19968;&#20010;&#24635;&#32467;&#34913;&#37327;&#26631;&#20934;&#8212;&#8212;&#24179;&#22343;&#35843;&#25972;&#20851;&#32852;&#24230;&#65288;AAA&#65289;&#65292;&#29992;&#20110;&#35780;&#20272;&#19968;&#20010;&#20855;&#26377;&#28151;&#28102;&#24433;&#21709;&#30340;&#24322;&#36136;&#32676;&#20307;&#20013;&#30340;&#20851;&#32852;&#31243;&#24230;&#12290;&#24182;&#19988;&#25105;&#20204;&#25552;&#20986;&#20102;&#39640;&#25928;&#30340;&#20272;&#35745;&#26041;&#27861;&#65292;&#21487;&#29992;&#20110;&#21508;&#31181;&#37319;&#26679;&#22330;&#26223;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#23545;&#25968;&#27604;&#29575;&#26159;&#34913;&#37327;&#20108;&#20803;&#32467;&#26524;&#21644;&#26292;&#38706;&#21464;&#37327;&#20851;&#32852;&#24230;&#30340;&#19968;&#31181;&#26082;&#23450;&#25351;&#26631;&#12290;&#23613;&#31649;&#20854;&#34987;&#24191;&#27867;&#20351;&#29992;&#65292;&#20294;&#26377;&#20851;&#22914;&#20309;&#36890;&#36807;&#24179;&#22343;&#26041;&#24335;&#24635;&#32467;&#20855;&#26377;&#28151;&#28102;&#22240;&#32032;&#30340;&#23545;&#25968;&#27604;&#29575;&#30340;&#35752;&#35770;&#21364;&#24456;&#26377;&#38480;&#12290;&#20026;&#20102;&#35299;&#20915;&#36825;&#20010;&#38382;&#39064;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#24179;&#22343;&#35843;&#25972;&#20851;&#32852;&#24230;&#65288;AAA&#65289;&#65292;&#23427;&#26159;&#19968;&#20010;&#35843;&#25972;&#20102;&#35266;&#23519;&#21040;&#30340;&#28151;&#28102;&#22240;&#32032;&#30340;&#24322;&#36136;&#32676;&#20307;&#20013;&#30340;&#20851;&#32852;&#24230;&#30340;&#24635;&#32467;&#34913;&#37327;&#26631;&#20934;&#12290;&#20026;&#20102;&#26041;&#20415;&#20351;&#29992;&#65292;&#25105;&#20204;&#36824;&#24320;&#21457;&#20102;&#39640;&#25928;&#30340;&#21452;&#37325;/&#26080;&#20559;&#26426;&#22120;&#23398;&#20064;&#65288;DML&#65289;AAA&#20272;&#35745;&#22120;&#12290;&#25105;&#20204;&#30340;DML&#20272;&#35745;&#22120;&#20351;&#29992;&#20102;&#20004;&#31181;&#31561;&#25928;&#30340;&#26377;&#25928;&#24433;&#21709;&#20989;&#25968;&#24418;&#24335;&#65292;&#24182;&#36866;&#29992;&#20110;&#21508;&#31181;&#37319;&#26679;&#22330;&#26223;&#65292;&#21253;&#25324;&#38543;&#26426;&#37319;&#26679;&#65292;&#22522;&#20110;&#32467;&#26524;&#30340;&#37319;&#26679;&#21644;&#22522;&#20110;&#26292;&#38706;&#30340;&#37319;&#26679;&#12290;&#36890;&#36807;&#30495;&#23454;&#25968;&#25454;&#21644;&#27169;&#25311;&#65292;&#25105;&#20204;&#35777;&#26126;&#20102;&#25105;&#20204;&#25552;&#20986;&#30340;&#20272;&#31639;&#26041;&#27861;&#22312;&#27979;&#37327;AAA&#26041;&#38754;&#30340;&#23454;&#29992;&#24615;&#21644;&#26377;&#25928;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The log odds ratio is a well-established metric for evaluating the association between binary outcome and exposure variables. Despite its widespread use, there has been limited discussion on how to summarize the log odds ratio as a function of confounders through averaging. To address this issue, we propose the Average Adjusted Association (AAA), which is a summary measure of association in a heterogeneous population, adjusted for observed confounders. To facilitate the use of it, we also develop efficient double/debiased machine learning (DML) estimators of the AAA. Our DML estimators use two equivalent forms of the efficient influence function, and are applicable in various sampling scenarios, including random sampling, outcome-based sampling, and exposure-based sampling. Through real data and simulations, we demonstrate the practicality and effectiveness of our proposed estimators in measuring the AAA.
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25214;&#21040;&#20102;&#24102;&#26435;&#37325;&#34928;&#20943;&#21644;&#38543;&#26426;&#31070;&#32463;&#20803;&#30340;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#20840;&#23616;&#26368;&#23567;&#20540;&#30340;&#35299;&#26512;&#34920;&#36798;&#24335;&#65292;&#32467;&#26524;&#34920;&#26126;&#26435;&#37325;&#34928;&#20943;&#19982;&#27169;&#22411;&#26550;&#26500;&#30340;&#24378;&#28872;&#20132;&#20114;&#20316;&#29992;&#20250;&#22312;&#22810;&#20110;1&#20010;&#38544;&#34255;&#23618;&#30340;&#32593;&#32476;&#20013;&#21019;&#24314;&#19981;&#33391;&#26497;&#23567;&#20540;&#65292;&#24182;&#34920;&#26126;&#24120;&#35265;&#30340;&#28145;&#24230;&#23398;&#20064;&#21021;&#22987;&#21270;&#26041;&#27861;&#26080;&#27861;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#32531;&#35299;&#31070;&#32463;&#32593;&#32476;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2202.04777</link><description>&lt;p&gt;
&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#30340;&#31934;&#30830;&#35299;&#26512;&#35299;
&lt;/p&gt;
&lt;p&gt;
Exact Solutions of a Deep Linear Network. (arXiv:2202.04777v6 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.04777
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25214;&#21040;&#20102;&#24102;&#26435;&#37325;&#34928;&#20943;&#21644;&#38543;&#26426;&#31070;&#32463;&#20803;&#30340;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#20840;&#23616;&#26368;&#23567;&#20540;&#30340;&#35299;&#26512;&#34920;&#36798;&#24335;&#65292;&#32467;&#26524;&#34920;&#26126;&#26435;&#37325;&#34928;&#20943;&#19982;&#27169;&#22411;&#26550;&#26500;&#30340;&#24378;&#28872;&#20132;&#20114;&#20316;&#29992;&#20250;&#22312;&#22810;&#20110;1&#20010;&#38544;&#34255;&#23618;&#30340;&#32593;&#32476;&#20013;&#21019;&#24314;&#19981;&#33391;&#26497;&#23567;&#20540;&#65292;&#24182;&#34920;&#26126;&#24120;&#35265;&#30340;&#28145;&#24230;&#23398;&#20064;&#21021;&#22987;&#21270;&#26041;&#27861;&#26080;&#27861;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#32531;&#35299;&#31070;&#32463;&#32593;&#32476;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25214;&#21040;&#20102;&#24102;&#26435;&#37325;&#34928;&#20943;&#21644;&#38543;&#26426;&#31070;&#32463;&#20803;&#30340;&#28145;&#24230;&#32447;&#24615;&#32593;&#32476;&#20840;&#23616;&#26368;&#23567;&#20540;&#30340;&#35299;&#26512;&#34920;&#36798;&#24335;&#65292;&#36825;&#26159;&#29702;&#35299;&#31070;&#32463;&#32593;&#32476;&#29702;&#35770;&#20013;&#30340;&#22522;&#30784;&#27169;&#22411;&#12290;&#25105;&#20204;&#30340;&#32467;&#26524;&#34920;&#26126;&#65292;&#22312;&#28145;&#24230;&#31070;&#32463;&#32593;&#32476;&#26550;&#26500;&#20013;&#65292;&#38646;&#26159;&#19968;&#20010;&#29305;&#27530;&#30340;&#28857;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#26435;&#37325;&#34928;&#20943;&#19982;&#27169;&#22411;&#26550;&#26500;&#30340;&#24378;&#28872;&#20132;&#20114;&#20316;&#29992;&#65292;&#24182;&#33021;&#22815;&#22312;&#20855;&#26377;&#36229;&#36807; $1$ &#20010;&#38544;&#34255;&#23618;&#30340;&#32593;&#32476;&#20013;&#21019;&#24314;&#19981;&#33391;&#26497;&#23567;&#20540;&#65292;&#36825;&#19982;&#20165;&#26377; $1$ &#20010;&#38544;&#34255;&#23618;&#30340;&#32593;&#32476;&#26377;&#36136;&#30340;&#19981;&#21516;&#12290;&#23454;&#38469;&#19978;&#65292;&#25105;&#20204;&#30340;&#32467;&#26524;&#24847;&#21619;&#30528;&#24120;&#35265;&#30340;&#28145;&#24230;&#23398;&#20064;&#21021;&#22987;&#21270;&#26041;&#27861;&#26080;&#27861;&#22312;&#19968;&#33324;&#24773;&#20917;&#19979;&#32531;&#35299;&#31070;&#32463;&#32593;&#32476;&#30340;&#20248;&#21270;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;
This work finds the analytical expression of the global minima of a deep linear network with weight decay and stochastic neurons, a fundamental model for understanding the landscape of neural networks. Our result implies that zero is a special point in deep neural network architecture. We show that weight decay strongly interacts with the model architecture and can create bad minima at zero in a network with more than $1$ hidden layer, qualitatively different from a network with only $1$ hidden layer. Practically, our result implies that common deep learning initialization methods are insufficient to ease the optimization of neural networks in general.
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#31995;&#21015;&#65292;&#21487;&#20197;&#26356;&#24555;&#36895;&#22320;&#22312;&#19981;&#23436;&#32654;&#20449;&#24687;&#24191;&#20041;&#21338;&#24328;&#20013;&#25214;&#21040;&#19968;&#20010;&#36817;&#20284;&#26368;&#20248;&#35299;&#12290;</title><link>http://arxiv.org/abs/2202.01752</link><description>&lt;p&gt;
&#19981;&#23436;&#32654;&#20449;&#24687;&#21338;&#24328;&#20013;&#30340;&#36817;&#20284;&#26368;&#20248;&#23398;&#20064;
&lt;/p&gt;
&lt;p&gt;
Near-Optimal Learning of Extensive-Form Games with Imperfect Information. (arXiv:2202.01752v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2202.01752
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#31639;&#27861;&#31995;&#21015;&#65292;&#21487;&#20197;&#26356;&#24555;&#36895;&#22320;&#22312;&#19981;&#23436;&#32654;&#20449;&#24687;&#24191;&#20041;&#21338;&#24328;&#20013;&#25214;&#21040;&#19968;&#20010;&#36817;&#20284;&#26368;&#20248;&#35299;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#35299;&#20915;&#20102;&#23398;&#20064;&#19981;&#23436;&#32654;&#20449;&#24687;&#24191;&#20041;&#21338;&#24328;&#30340;&#36817;&#20284;&#26368;&#20248;&#31639;&#27861;&#35774;&#35745;&#30340;&#24320;&#25918;&#24615;&#38382;&#39064;&#12290;&#25105;&#20204;&#25552;&#20986;&#20102;&#31532;&#19968;&#31181;&#31639;&#27861;&#31995;&#21015;&#65292;&#20165;&#38656;&#35201; $\widetilde{\mathcal{O}}((XA+YB)/\varepsilon^2)$ &#23616;&#28216;&#25103;&#21363;&#21487;&#22312;&#20004;&#20154;&#38646;&#21644;&#21338;&#24328;&#20013;&#25214;&#21040;&#19968;&#20010; $\varepsilon$-&#36817;&#20284;&#32435;&#20160;&#22343;&#34913;&#65292;&#20854;&#20013; $X,Y$ &#26159;&#20449;&#24687;&#38598;&#30340;&#25968;&#37327;&#65292;$A,B$ &#26159;&#20004;&#21517;&#29609;&#23478;&#30340;&#34892;&#21160;&#25968;&#12290;&#36825;&#27604;&#24050;&#30693;&#30340;&#26679;&#26412;&#22797;&#26434;&#24230; $\widetilde{\mathcal{O}}((X^2A+Y^2B)/\varepsilon^2)$ &#26377;&#30528; $\widetilde{\mathcal{O}}(\max\{X, Y\})$ &#30340;&#24040;&#22823;&#25913;&#36827;&#65292;&#24182;&#19988;&#22312;&#23545;&#25968;&#22240;&#23376;&#20869;&#19982;&#20449;&#24687;&#29702;&#35770;&#19979;&#38480;&#19968;&#33268;&#12290;&#25105;&#20204;&#36890;&#36807;&#20004;&#31181;&#26032;&#31639;&#27861;&#23454;&#29616;&#20102;&#36825;&#31181;&#26679;&#26412;&#22797;&#26434;&#24230;&#65306;&#24179;&#34913;&#22312;&#32447;&#38236;&#38754;&#19979;&#38477;&#21644;&#24179;&#34913;&#21453;&#20107;&#23454;&#21518;&#24724;&#26368;&#23567;&#21270;&#12290;&#36825;&#20004;&#31181;&#31639;&#27861;&#37117;&#20381;&#36182;&#20110;&#23558;&#8220;&#24179;&#34913;&#25506;&#32034;&#31574;&#30053;&#8221;&#38598;&#25104;&#21040;&#23427;&#20204;&#30340;&#32463;&#20856;&#23545;&#25163;&#20013;&#30340;&#26032;&#26041;&#27861;&#12290;&#27492;&#22806;&#65292;&#25105;&#20204;&#36824;&#23558;&#25105;&#20204;&#30340;&#32467;&#26524;&#25193;&#23637;&#21040;&#20102;&#26356;&#24191;&#27867;&#30340;&#25903;&#25345;&#19981;&#23436;&#32654;&#20449;&#24687;&#21338;&#24328;&#30340;&#20108;&#20154;&#21338;&#24328;&#21644;&#22810;&#20154;&#21338;&#24328;&#20013;&#12290;
&lt;/p&gt;
&lt;p&gt;
This paper resolves the open question of designing near-optimal algorithms for learning imperfect-information extensive-form games from bandit feedback. We present the first line of algorithms that require only $\widetilde{\mathcal{O}}((XA+YB)/\varepsilon^2)$ episodes of play to find an $\varepsilon$-approximate Nash equilibrium in two-player zero-sum games, where $X,Y$ are the number of information sets and $A,B$ are the number of actions for the two players. This improves upon the best known sample complexity of $\widetilde{\mathcal{O}}((X^2A+Y^2B)/\varepsilon^2)$ by a factor of $\widetilde{\mathcal{O}}(\max\{X, Y\})$, and matches the information-theoretic lower bound up to logarithmic factors. We achieve this sample complexity by two new algorithms: Balanced Online Mirror Descent, and Balanced Counterfactual Regret Minimization. Both algorithms rely on novel approaches of integrating \emph{balanced exploration policies} into their classical counterparts. We also extend our results t
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35745;&#31639;&#26694;&#26550;&#65292;&#29992;&#20110;&#22522;&#20110;&#27491;&#21521;-&#21453;&#21521;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#29702;&#35770;&#23545;&#34203;&#23450;&#35860;&#26725;&#36827;&#34892;&#20284;&#28982;&#35757;&#32451;&#12290;&#36890;&#36807;&#36825;&#20010;&#26694;&#26550;&#65292;&#21487;&#20197;&#26500;&#24314;SB&#30340;&#20284;&#28982;&#30446;&#26631;&#65292;&#36825;&#21487;&#20197;&#25104;&#20026;&#29616;&#20195;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#35757;&#32451;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;</title><link>http://arxiv.org/abs/2110.11291</link><description>&lt;p&gt;
&#21033;&#29992;&#27491;&#21521;-&#21453;&#21521;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#29702;&#35770;&#23545;&#34203;&#23450;&#35860;&#26725;&#36827;&#34892;&#20284;&#28982;&#35757;&#32451;
&lt;/p&gt;
&lt;p&gt;
Likelihood Training of Schr\"odinger Bridge using Forward-Backward SDEs Theory. (arXiv:2110.11291v5 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.11291
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35745;&#31639;&#26694;&#26550;&#65292;&#29992;&#20110;&#22522;&#20110;&#27491;&#21521;-&#21453;&#21521;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#29702;&#35770;&#23545;&#34203;&#23450;&#35860;&#26725;&#36827;&#34892;&#20284;&#28982;&#35757;&#32451;&#12290;&#36890;&#36807;&#36825;&#20010;&#26694;&#26550;&#65292;&#21487;&#20197;&#26500;&#24314;SB&#30340;&#20284;&#28982;&#30446;&#26631;&#65292;&#36825;&#21487;&#20197;&#25104;&#20026;&#29616;&#20195;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#35757;&#32451;&#30340;&#26367;&#20195;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#34203;&#23450;&#35860;&#26725;&#65288;SB&#65289;&#26159;&#19968;&#31181;&#29109;&#27491;&#21017;&#21270;&#30340;&#26368;&#20248;&#36755;&#36816;&#38382;&#39064;&#65292;&#19982;&#22522;&#20110;&#20998;&#25968;&#30340;&#29983;&#25104;&#27169;&#22411;&#65288;SGM&#65289;&#30456;&#27604;&#65292;&#22312;&#28145;&#24230;&#29983;&#25104;&#24314;&#27169;&#20013;&#30001;&#20110;&#20854;&#25968;&#23398;&#28789;&#27963;&#24615;&#32780;&#36234;&#26469;&#36234;&#21463;&#21040;&#20851;&#27880;&#12290;&#28982;&#32780;&#65292;&#23578;&#19981;&#28165;&#26970;SB&#30340;&#20248;&#21270;&#21407;&#21017;&#26159;&#21542;&#19982;&#29616;&#20195;&#28145;&#24230;&#29983;&#25104;&#27169;&#22411;&#30340;&#35757;&#32451;&#30456;&#20851;&#65292;&#21518;&#32773;&#36890;&#24120;&#20381;&#36182;&#20110;&#26500;&#24314;&#23545;&#25968;&#20284;&#28982;&#30446;&#26631;&#12290;&#36825;&#24341;&#21457;&#20102;&#20851;&#20110;SB&#27169;&#22411;&#20316;&#20026;&#29983;&#25104;&#24212;&#29992;&#30340;&#21407;&#21017;&#24615;&#26367;&#20195;&#26041;&#27861;&#30340;&#36866;&#29992;&#24615;&#38382;&#39064;&#12290;&#22312;&#26412;&#24037;&#20316;&#20013;&#65292;&#25105;&#20204;&#25552;&#20986;&#20102;&#19968;&#31181;&#26032;&#30340;&#35745;&#31639;&#26694;&#26550;&#65292;&#29992;&#20110;&#22522;&#20110;&#27491;&#21521;-&#21453;&#21521;&#38543;&#26426;&#24494;&#20998;&#26041;&#31243;&#29702;&#35770;&#23545;SB&#27169;&#22411;&#36827;&#34892;&#20284;&#28982;&#35757;&#32451;&#8212;&#8212;&#36825;&#26159;&#19968;&#31181;&#20986;&#29616;&#22312;&#38543;&#26426;&#26368;&#20248;&#25511;&#21046;&#20013;&#30340;&#25968;&#23398;&#26041;&#27861;&#65292;&#23427;&#23558;SB&#30340;&#26368;&#20248;&#24615;&#26465;&#20214;&#36716;&#21270;&#20026;&#19968;&#32452;SDE&#12290;&#20851;&#38190;&#26159;&#65292;&#36825;&#20123;SDE&#21487;&#20197;&#29992;&#20110;&#26500;&#24314;SB&#30340;&#20284;&#28982;&#30446;&#26631;&#65292;&#20196;&#20154;&#24778;&#35766;&#30340;&#26159;&#65292;&#23427;&#24191;&#20041;&#22320;&#25512;&#24191;&#20102;SGM&#30340;&#19968;&#20123;&#29305;&#27530;&#24773;&#20917;&#12290;&#36825;&#23548;&#33268;&#20102;&#19968;&#31181;&#26032;&#30340;&#20248;&#21270;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Schr\"odinger Bridge (SB) is an entropy-regularized optimal transport problem that has received increasing attention in deep generative modeling for its mathematical flexibility compared to the Scored-based Generative Model (SGM). However, it remains unclear whether the optimization principle of SB relates to the modern training of deep generative models, which often rely on constructing log-likelihood objectives.This raises questions on the suitability of SB models as a principled alternative for generative applications. In this work, we present a novel computational framework for likelihood training of SB models grounded on Forward-Backward Stochastic Differential Equations Theory - a mathematical methodology appeared in stochastic optimal control that transforms the optimality condition of SB into a set of SDEs. Crucially, these SDEs can be used to construct the likelihood objectives for SB that, surprisingly, generalizes the ones for SGM as special cases. This leads to a new optimi
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#25237;&#36164;&#32452;&#21512;&#31574;&#30053;&#65292;&#38754;&#21521;&#22823;&#35268;&#27169;&#24182;&#34892;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#35299;&#20915;&#24182;&#34892;&#35774;&#35745;&#36873;&#25321;&#22797;&#26434;&#24615;&#38382;&#39064;&#65292;&#36866;&#29992;&#20110;&#22122;&#22768;&#40657;&#30418;&#20989;&#25968;&#65292;&#21333;&#30446;&#26631;&#21644;&#22810;&#30446;&#26631;&#20248;&#21270;&#20219;&#21153;&#12290;</title><link>http://arxiv.org/abs/2110.09334</link><description>&lt;p&gt;
&#19968;&#31181;&#38754;&#21521;&#22823;&#35268;&#27169;&#24182;&#34892;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#25237;&#36164;&#32452;&#21512;&#26041;&#27861;
&lt;/p&gt;
&lt;p&gt;
A portfolio approach to massively parallel Bayesian optimization. (arXiv:2110.09334v2 [math.OC] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.09334
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#25237;&#36164;&#32452;&#21512;&#31574;&#30053;&#65292;&#38754;&#21521;&#22823;&#35268;&#27169;&#24182;&#34892;&#36125;&#21494;&#26031;&#20248;&#21270;&#65292;&#35299;&#20915;&#24182;&#34892;&#35774;&#35745;&#36873;&#25321;&#22797;&#26434;&#24615;&#38382;&#39064;&#65292;&#36866;&#29992;&#20110;&#22122;&#22768;&#40657;&#30418;&#20989;&#25968;&#65292;&#21333;&#30446;&#26631;&#21644;&#22810;&#30446;&#26631;&#20248;&#21270;&#20219;&#21153;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#20026;&#20102;&#32553;&#30701;&#20248;&#21270;&#30740;&#31350;&#30340;&#26102;&#38388;&#65292;&#19968;&#31181;&#26041;&#27861;&#26159;&#24182;&#34892;&#35780;&#20272;&#35774;&#35745;&#65292;&#32780;&#19981;&#26159;&#36880;&#20010;&#35780;&#20272;&#12290;&#38024;&#23545;&#26114;&#36149;&#30340;&#40657;&#30418;&#20989;&#25968;&#65292;&#24050;&#32463;&#25552;&#20986;&#20102;&#36125;&#21494;&#26031;&#20248;&#21270;&#30340;&#25209;&#22788;&#29702;&#29256;&#26412;&#12290;&#23427;&#20204;&#36890;&#36807;&#24314;&#31435;&#40657;&#30418;&#20989;&#25968;&#30340;&#20195;&#29702;&#27169;&#22411;&#65292;&#36890;&#36807;&#22635;&#20805;&#20934;&#21017;&#21516;&#26102;&#36873;&#25321;&#22810;&#20010;&#35774;&#35745;&#12290;&#23613;&#31649;&#29616;&#22312;&#26377;&#26356;&#22810;&#30340;&#35745;&#31639;&#36164;&#28304;&#21487;&#20197;&#25903;&#25345;&#22823;&#35268;&#27169;&#24182;&#34892;&#24615;&#65292;&#20294;&#36873;&#25321;&#20960;&#21313;&#20010;&#24182;&#34892;&#35774;&#35745;&#30340;&#31574;&#30053;&#30001;&#20110;&#36873;&#25321;&#26356;&#22810;&#35774;&#35745;&#30340;&#22797;&#26434;&#24615;&#32780;&#21464;&#24471;&#26377;&#38480;&#12290;&#24403;&#40657;&#30418;&#21448;&#20855;&#26377;&#22122;&#22768;&#26102;&#65292;&#38656;&#35201;&#26356;&#22810;&#30340;&#35780;&#20272;&#20197;&#21450;&#37325;&#22797;&#23454;&#39564;&#65292;&#36825;&#21464;&#24471;&#26356;&#21152;&#20851;&#38190;&#12290;&#22312;&#36825;&#37324;&#65292;&#25105;&#20204;&#25552;&#20986;&#19968;&#31181;&#21487;&#25193;&#23637;&#30340;&#31574;&#30053;&#65292;&#21487;&#20197;&#26412;&#22320;&#19982;&#22823;&#35268;&#27169;&#25209;&#22788;&#29702;&#20445;&#25345;&#21516;&#27493;&#65292;&#19987;&#27880;&#20110;&#25506;&#32034;/&#24320;&#21457;&#26435;&#34913;&#21644;&#25237;&#36164;&#32452;&#21512;&#20998;&#37197;&#12290;&#25105;&#20204;&#23558;&#36825;&#31181;&#26041;&#27861;&#19982;&#30456;&#20851;&#26041;&#27861;&#22312;&#22122;&#22768;&#20989;&#25968;&#12289;&#21333;&#30446;&#26631;&#21644;&#22810;&#30446;&#26631;&#20248;&#21270;&#20219;&#21153;&#19978;&#36827;&#34892;&#27604;&#36739;&#12290;
&lt;/p&gt;
&lt;p&gt;
One way to reduce the time of conducting optimization studies is to evaluate designs in parallel rather than just one-at-a-time. For expensive-to-evaluate black-boxes, batch versions of Bayesian optimization have been proposed. They work by building a surrogate model of the black-box to simultaneously select multiple designs via an infill criterion. Still, despite the increased availability of computing resources that enable large-scale parallelism, the strategies that work for selecting a few tens of parallel designs for evaluations become limiting due to the complexity of selecting more designs. It is even more crucial when the black-box is noisy, necessitating more evaluations as well as repeating experiments. Here we propose a scalable strategy that can keep up with massive batching natively, focused on the exploration/exploitation trade-off and a portfolio allocation. We compare the approach with related methods on noisy functions, for mono and multi-objective optimization tasks. 
&lt;/p&gt;</description></item><item><title>&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;MASHA1&#21644;MASHA2&#26041;&#27861;&#65292;&#21487;&#20197;&#20943;&#23569;&#22312;&#20998;&#24067;&#24335;&#35757;&#32451;&#20013;&#30340;&#36890;&#20449;&#37327;&#65292;&#24182;&#22312;&#33719;&#24471;&#21487;&#27604;&#24615;&#36136;&#37327;&#30340;&#27169;&#22411;&#30340;&#21516;&#26102;&#65292;&#35299;&#20915;&#21464;&#20998;&#19981;&#31561;&#24335;&#21644;&#38797;&#28857;&#38382;&#39064;&#12290;</title><link>http://arxiv.org/abs/2110.03313</link><description>&lt;p&gt;
&#21387;&#32553;&#36890;&#35759;&#35299;&#20915;&#21464;&#20998;&#19981;&#31561;&#24335;&#30340;&#20998;&#24067;&#24335;&#26041;&#27861;&#21450;&#29702;&#35770;&#20445;&#35777;
&lt;/p&gt;
&lt;p&gt;
Distributed Methods with Compressed Communication for Solving Variational Inequalities, with Theoretical Guarantees. (arXiv:2110.03313v3 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2110.03313
&lt;/p&gt;
&lt;p&gt;
&#26412;&#30740;&#31350;&#25552;&#20986;&#20102;MASHA1&#21644;MASHA2&#26041;&#27861;&#65292;&#21487;&#20197;&#20943;&#23569;&#22312;&#20998;&#24067;&#24335;&#35757;&#32451;&#20013;&#30340;&#36890;&#20449;&#37327;&#65292;&#24182;&#22312;&#33719;&#24471;&#21487;&#27604;&#24615;&#36136;&#37327;&#30340;&#27169;&#22411;&#30340;&#21516;&#26102;&#65292;&#35299;&#20915;&#21464;&#20998;&#19981;&#31561;&#24335;&#21644;&#38797;&#28857;&#38382;&#39064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#21464;&#20998;&#19981;&#31561;&#24335;&#21644;&#38797;&#28857;&#38382;&#39064;&#22312;&#26426;&#22120;&#23398;&#20064;&#24212;&#29992;&#20013;&#36234;&#26469;&#36234;&#21463;&#20851;&#27880;&#65292;&#21253;&#25324;&#23545;&#25239;&#24615;&#23398;&#20064;&#12289;GAN&#12289;&#36816;&#36755;&#21644;&#24378;&#21270;&#20248;&#21270;&#31561;&#26041;&#38754;&#12290;&#20026;&#20102;&#35757;&#32451;&#39640;&#24615;&#33021;&#27169;&#22411;&#65292;&#38656;&#35201;&#20381;&#36182;&#20110;&#24182;&#34892;&#21644;&#20998;&#24067;&#24335;&#35745;&#31639;&#12290;&#28982;&#32780;&#65292;&#22312;&#20998;&#24067;&#24335;&#35757;&#32451;&#20013;&#65292;&#35745;&#31639;&#33410;&#28857;&#20043;&#38388;&#30340;&#36890;&#20449;&#25104;&#20026;&#35757;&#32451;&#30340;&#20851;&#38190;&#29942;&#39048;&#65292;&#29305;&#21035;&#26159;&#23545;&#20110;&#39640;&#32500;&#24230;&#21644;&#36807;&#21442;&#25968;&#21270;&#27169;&#22411;&#12290;&#22240;&#27492;&#65292;&#37325;&#35201;&#30340;&#26159;&#20351;&#29992;&#21487;&#20197;&#20943;&#23569;&#20256;&#36755;&#20449;&#24687;&#37327;&#30340;&#31574;&#30053;&#26469;&#38477;&#20302;&#35757;&#32451;&#20013;&#30340;&#36890;&#20449;&#37327;&#65292;&#21516;&#26102;&#33719;&#24471;&#20855;&#26377;&#21487;&#27604;&#24615;&#36136;&#37327;&#30340;&#27169;&#22411;&#12290;&#26412;&#25991;&#25552;&#20986;&#20102;MASHA1&#21644;MASHA2&#31561;&#22522;&#20110;&#21387;&#32553;&#36890;&#35759;&#30340;&#29702;&#35770;&#26041;&#27861;&#65292;&#29992;&#20110;&#35299;&#20915;&#21464;&#20998;&#19981;&#31561;&#24335;&#21644;&#38797;&#28857;&#38382;&#39064;&#30340;&#20998;&#24067;&#24335;&#26041;&#27861;&#12290;
&lt;/p&gt;
&lt;p&gt;
Variational inequalities in general and saddle point problems in particular are increasingly relevant in machine learning applications, including adversarial learning, GANs, transport and robust optimization. With increasing data and problem sizes necessary to train high performing models across various applications, we need to rely on parallel and distributed computing. However, in distributed training, communication among the compute nodes is a key bottleneck during training, and this problem is exacerbated for high dimensional and over-parameterized models. Due to these considerations, it is important to equip existing methods with strategies that would allow to reduce the volume of transmitted information during training while obtaining a model of comparable quality. In this paper, we present the first theoretically grounded distributed methods for solving variational inequalities and saddle point problems using compressed communication: MASHA1 and MASHA2. Our theory and methods al
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25209;&#37327;&#24322;&#27493;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#65292;&#23427;&#21487;&#20197;&#22312;&#20869;&#23384;&#38656;&#27714;&#21644;&#26102;&#38388;&#22797;&#26434;&#24230;&#20043;&#38388;&#36827;&#34892;&#26435;&#34913;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#21487;&#20197;&#20351;&#29992;&#36739;&#24369;&#20551;&#35774;&#35777;&#26126;&#25910;&#25947;&#30340;&#19968;&#33324;&#26041;&#27861;&#65307;&#22312;&#24378;&#21270;&#23398;&#20064;&#39046;&#22495;&#65292;&#25105;&#20204;&#20351;&#29992;&#27492;&#26041;&#27861;&#35777;&#26126;&#20102;SARSA&#31639;&#27861;&#30340;&#25209;&#37327;&#24322;&#27493;&#29256;&#26412;&#30340;&#25910;&#25947;&#24615;&#12290;</title><link>http://arxiv.org/abs/2109.03445</link><description>&lt;p&gt;
&#25209;&#37327;&#24322;&#27493;&#38543;&#26426;&#36924;&#36817;&#30340;&#25910;&#25947;&#24615;&#21450;&#22312;&#24378;&#21270;&#23398;&#20064;&#20013;&#30340;&#24212;&#29992;
&lt;/p&gt;
&lt;p&gt;
Convergence of Batch Asynchronous Stochastic Approximation With Applications to Reinforcement Learning. (arXiv:2109.03445v4 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2109.03445
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#31181;&#25209;&#37327;&#24322;&#27493;&#38543;&#26426;&#36924;&#36817;&#31639;&#27861;&#65292;&#23427;&#21487;&#20197;&#22312;&#20869;&#23384;&#38656;&#27714;&#21644;&#26102;&#38388;&#22797;&#26434;&#24230;&#20043;&#38388;&#36827;&#34892;&#26435;&#34913;&#65292;&#21516;&#26102;&#25552;&#20379;&#20102;&#21487;&#20197;&#20351;&#29992;&#36739;&#24369;&#20551;&#35774;&#35777;&#26126;&#25910;&#25947;&#30340;&#19968;&#33324;&#26041;&#27861;&#65307;&#22312;&#24378;&#21270;&#23398;&#20064;&#39046;&#22495;&#65292;&#25105;&#20204;&#20351;&#29992;&#27492;&#26041;&#27861;&#35777;&#26126;&#20102;SARSA&#31639;&#27861;&#30340;&#25209;&#37327;&#24322;&#27493;&#29256;&#26412;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#38543;&#26426;&#36924;&#36817;&#65288;SA&#65289;&#31639;&#27861;&#26159;&#19968;&#31181;&#24191;&#27867;&#20351;&#29992;&#30340;&#27010;&#29575;&#26041;&#27861;&#65292;&#29992;&#20110;&#22312;&#20165;&#21487;&#29992;&#20989;&#25968;&#30340;&#26377;&#22122;&#27979;&#37327;&#24773;&#20917;&#19979;&#25214;&#21040;&#38646;&#28857;&#25110;&#22266;&#23450;&#28857;&#12290;&#30446;&#21069;&#30340;&#25991;&#29486;&#20013;&#65292;&#21306;&#20998;&#8220;&#21516;&#27493;&#8221;&#26356;&#26032;&#21644;&#8220;&#24322;&#27493;&#8221;&#26356;&#26032;&#65292;&#22312;&#8220;&#21516;&#27493;&#8221;&#26356;&#26032;&#20013;&#65292;&#27599;&#20010;&#29468;&#27979;&#30340;&#32452;&#20214;&#37117;&#20250;&#22312;&#27599;&#20010;&#26102;&#38388;&#26356;&#26032;&#65292;&#32780;&#22312;&#8220;&#24322;&#27493;&#8221;&#26356;&#26032;&#20013;&#65292;&#20165;&#26356;&#26032;&#19968;&#20010;&#32452;&#20214;&#12290;&#26412;&#25991;&#30740;&#31350;&#20102;&#19968;&#31181;&#20013;&#38388;&#24773;&#20917;&#65292;&#31216;&#20026;&#8220;&#25209;&#37327;&#24322;&#27493;&#38543;&#26426;&#36924;&#36817;&#8221;&#65288;BASA&#65289;&#65292;&#22312;&#36825;&#31181;&#24773;&#20917;&#19979;&#65292;&#27599;&#20010;&#26102;&#38388;&#28857;&#20165;&#26356;&#26032;&#8220;&#24403;&#21069;&#20272;&#35745;&#35299;&#8221;&#30340;&#19968;&#20123;&#20294;&#19981;&#26159;&#20840;&#37096;&#30340;&#32452;&#20214;&#12290;BASA&#20801;&#35768;&#29992;&#25143;&#22312;&#20869;&#23384;&#38656;&#27714;&#21644;&#26102;&#38388;&#22797;&#26434;&#24230;&#20043;&#38388;&#36827;&#34892;&#26435;&#34913;&#12290;&#25105;&#20204;&#24320;&#21457;&#20102;&#19968;&#31181;&#36890;&#29992;&#26041;&#27861;&#65292;&#35777;&#26126;&#27492;&#31867;&#31639;&#27861;&#25910;&#25947;&#20110;&#25152;&#30740;&#31350;&#26144;&#23556;&#30340;&#22266;&#23450;&#28857;&#12290;&#36825;&#20123;&#25910;&#25947;&#35777;&#26126;&#20351;&#29992;&#27604;&#29616;&#26377;&#32467;&#26524;&#26356;&#24369;&#30340;&#20551;&#35774;&#12290;&#20855;&#20307;&#32780;&#35328;&#65292;&#29616;&#26377;&#30340;&#25910;&#25947;&#35777;&#26126;&#35201;&#27714;&#27493;&#38271;&#21442;&#25968;&#20197;&#36866;&#24403;&#30340;&#36895;&#29575;&#19979;&#38477;&#12290;&#30456;&#21453;&#65292;&#25105;&#20204;&#20165;&#35201;&#27714;&#27599;&#20010;&#32452;&#20214;&#20855;&#26377;&#36275;&#22815;&#30340;&#26356;&#26032;&#39057;&#29575;&#12290;&#25105;&#20204;&#22312;&#24378;&#21270;&#23398;&#20064;&#39046;&#22495;&#23637;&#31034;&#20102;&#25105;&#20204;&#26041;&#27861;&#30340;&#26377;&#29992;&#24615;&#65292;&#35777;&#26126;&#20102;&#24191;&#27867;&#20351;&#29992;&#30340;SARSA&#31639;&#27861;&#30340;&#25209;&#37327;&#24322;&#27493;&#29256;&#26412;&#30340;&#25910;&#25947;&#24615;&#12290;
&lt;/p&gt;
&lt;p&gt;
The stochastic approximation (SA) algorithm is a widely used probabilistic method for finding a zero or a fixed point of a vector-valued funtion, when only noisy measurements of the function are available. In the literature to date, one makes a distinction between ``synchronous'' updating, whereby every component of the current guess is updated at each time, and ``asynchronous'' updating, whereby only one component is updated. In this paper, we study an intermediate situation that we call ``batch asynchronous stochastic approximation'' (BASA), in which, at each time instant, \textit{some but not all} components of the current estimated solution are updated. BASA allows the user to trade off memory requirements against time complexity. We develop a general methodology for proving that such algorithms converge to the fixed point of the map under study. These convergence proofs make use of weaker hypotheses than existing results. Specifically, existing convergence proofs require that the 
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#30740;&#31350;&#20102;GAN&#22914;&#20309;&#26377;&#25928;&#22320;&#23398;&#20064;&#37027;&#20123;&#25509;&#36817;&#30495;&#23454;&#22270;&#20687;&#20998;&#24067;&#30340;&#20998;&#23618;&#29983;&#25104;&#20998;&#24067;&#65292;&#24403;&#19968;&#20010;&#20998;&#24067;&#20855;&#26377;&#21069;&#21521;&#36229;&#20998;&#36776;&#29575;&#32467;&#26500;&#26102;&#65292;&#36890;&#36807;SGDA&#31616;&#21333;&#22320;&#35757;&#32451;GAN&#23601;&#33021;&#22815;&#23454;&#29616;&#39640;&#25928;&#23398;&#20064;&#12290;</title><link>http://arxiv.org/abs/2106.02619</link><description>&lt;p&gt;
&#21069;&#21521;&#36229;&#20998;&#36776;&#29575;&#65306;GAN&#22914;&#20309;&#23398;&#20064;&#36924;&#36817;&#30495;&#23454;&#19990;&#30028;&#20998;&#24067;&#30340;&#20998;&#23618;&#29983;&#25104;&#27169;&#22411;
&lt;/p&gt;
&lt;p&gt;
Forward Super-Resolution: How Can GANs Learn Hierarchical Generative Models for Real-World Distributions. (arXiv:2106.02619v2 [cs.LG] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2106.02619
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#30740;&#31350;&#20102;GAN&#22914;&#20309;&#26377;&#25928;&#22320;&#23398;&#20064;&#37027;&#20123;&#25509;&#36817;&#30495;&#23454;&#22270;&#20687;&#20998;&#24067;&#30340;&#20998;&#23618;&#29983;&#25104;&#20998;&#24067;&#65292;&#24403;&#19968;&#20010;&#20998;&#24067;&#20855;&#26377;&#21069;&#21521;&#36229;&#20998;&#36776;&#29575;&#32467;&#26500;&#26102;&#65292;&#36890;&#36807;SGDA&#31616;&#21333;&#22320;&#35757;&#32451;GAN&#23601;&#33021;&#22815;&#23454;&#29616;&#39640;&#25928;&#23398;&#20064;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#29983;&#25104;&#23545;&#25239;&#32593;&#32476;&#65288;GAN&#65289;&#26159;&#23398;&#20064;&#39640;&#22797;&#26434;&#24230;&#30495;&#23454;&#19990;&#30028;&#20998;&#24067;&#30340;&#26368;&#25104;&#21151;&#27169;&#22411;&#20043;&#19968;&#12290;&#28982;&#32780;&#65292;&#30001;&#20110;&#26368;&#23567;&#26368;&#22823;&#35757;&#32451;&#30446;&#26631;&#30340;&#39640;&#24230;&#38750;&#20984;&#12289;&#38750;&#20985;&#29305;&#24615;&#65292;GAN&#22312;&#29702;&#35770;&#19978;&#20173;&#28982;&#26159;&#28145;&#24230;&#23398;&#20064;&#27169;&#22411;&#20013;&#26368;&#38590;&#29702;&#35299;&#30340;&#12290;&#26412;&#25991;&#27491;&#24335;&#30740;&#31350;&#20102;GAN&#22914;&#20309;&#26377;&#25928;&#22320;&#23398;&#20064;&#37027;&#20123;&#25509;&#36817;&#30495;&#23454;&#22270;&#20687;&#20998;&#24067;&#30340;&#20998;&#23618;&#29983;&#25104;&#20998;&#24067;&#12290;&#25105;&#20204;&#35777;&#26126;&#20102;&#65292;&#24403;&#19968;&#20010;&#20998;&#24067;&#20855;&#26377;&#25105;&#20204;&#25152;&#31216;&#30340;&#21069;&#21521;&#36229;&#20998;&#36776;&#29575;&#32467;&#26500;&#26102;&#65292;&#36890;&#36807;&#38543;&#26426;&#26799;&#24230;&#19979;&#38477;&#19978;&#21319;&#65288;SGDA&#65289;&#31616;&#21333;&#22320;&#35757;&#32451;GAN&#23601;&#33021;&#22815;&#26377;&#25928;&#22320;&#23398;&#20064;&#36825;&#20010;&#20998;&#24067;&#65292;&#26080;&#35770;&#26159;&#26679;&#26412;&#36824;&#26159;&#26102;&#38388;&#22797;&#26434;&#24230;&#12290;&#25105;&#20204;&#36824;&#25552;&#20379;&#20102;&#23454;&#35777;&#35777;&#25454;&#65292;&#34920;&#26126;&#25105;&#20204;&#25152;&#20551;&#35774;&#30340;&#8220;&#21069;&#21521;&#36229;&#20998;&#36776;&#29575;&#8221;&#22312;&#23454;&#36341;&#20013;&#38750;&#24120;&#33258;&#28982;&#65292;&#32780;&#25105;&#20204;&#22312;&#26412;&#25991;&#20013;&#30740;&#31350;&#30340;&#24213;&#23618;&#23398;&#20064;&#26426;&#21046;&#65288;&#36890;&#36807;SGDA&#29702;&#35770;&#19978;&#20801;&#35768;&#25105;&#20204;&#39640;&#25928;&#22320;&#35757;&#32451;GAN&#65289;&#27169;&#25311;&#20102;&#23454;&#38469;&#30340;&#23398;&#20064;&#36807;&#31243;&#12290;
&lt;/p&gt;
&lt;p&gt;
Generative adversarial networks (GANs) are among the most successful models for learning high-complexity, real-world distributions. However, in theory, due to the highly non-convex, non-concave landscape of the minmax training objective, GAN remains one of the least understood deep learning models. In this work, we formally study how GANs can efficiently learn certain hierarchically generated distributions that are close to the distribution of real-life images. We prove that when a distribution has a structure that we refer to as Forward Super-Resolution, then simply training generative adversarial networks using stochastic gradient descent ascent (SGDA) can learn this distribution efficiently, both in sample and time complexities. We also provide empirical evidence that our assumption "forward super-resolution" is very natural in practice, and the underlying learning mechanisms that we study in this paper (to allow us efficiently train GAN via SGDA in theory) simulates the actual lear
&lt;/p&gt;</description></item><item><title>&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25968;&#23398;&#29702;&#35770;&#26694;&#26550;&#21644;&#25968;&#20540;&#26041;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#26102;&#38388;&#36793;&#32536;&#26679;&#26412;&#25512;&#26029;&#20986;&#38543;&#26426;&#36807;&#31243;&#30340;&#36712;&#36857;&#65292;&#29305;&#21035;&#26159;&#23427;&#21487;&#20197;&#24212;&#29992;&#20110;&#21333;&#32454;&#32990;RNA&#27979;&#24207;&#25968;&#25454;&#30340;&#20998;&#26512;&#21644;&#36712;&#36857;&#25512;&#26029;&#12290;</title><link>http://arxiv.org/abs/2102.09204</link><description>&lt;p&gt;
&#25506;&#32034;&#36712;&#36857;&#25512;&#26029;&#30340;&#25968;&#23398;&#29702;&#35770;
&lt;/p&gt;
&lt;p&gt;
Towards a mathematical theory of trajectory inference. (arXiv:2102.09204v2 [stat.ML] UPDATED)
&lt;/p&gt;
&lt;p&gt;
http://arxiv.org/abs/2102.09204
&lt;/p&gt;
&lt;p&gt;
&#26412;&#25991;&#25552;&#20986;&#20102;&#19968;&#20010;&#25968;&#23398;&#29702;&#35770;&#26694;&#26550;&#21644;&#25968;&#20540;&#26041;&#27861;&#65292;&#21487;&#20197;&#36890;&#36807;&#26102;&#38388;&#36793;&#32536;&#26679;&#26412;&#25512;&#26029;&#20986;&#38543;&#26426;&#36807;&#31243;&#30340;&#36712;&#36857;&#65292;&#29305;&#21035;&#26159;&#23427;&#21487;&#20197;&#24212;&#29992;&#20110;&#21333;&#32454;&#32990;RNA&#27979;&#24207;&#25968;&#25454;&#30340;&#20998;&#26512;&#21644;&#36712;&#36857;&#25512;&#26029;&#12290;
&lt;/p&gt;
&lt;p&gt;

&lt;/p&gt;
&lt;p&gt;
&#25105;&#20204;&#35774;&#35745;&#20102;&#19968;&#20010;&#29702;&#35770;&#26694;&#26550;&#21644;&#25968;&#20540;&#26041;&#27861;&#65292;&#21487;&#20197;&#20174;&#38543;&#26426;&#36807;&#31243;&#30340;&#26102;&#38388;&#36793;&#32536;&#26679;&#26412;&#20013;&#25512;&#26029;&#20854;&#36712;&#36857;&#12290;&#36825;&#20010;&#38382;&#39064;&#20986;&#29616;&#22312;&#21333;&#32454;&#32990;RNA&#27979;&#24207;&#25968;&#25454;&#30340;&#20998;&#26512;&#20013;&#65292;&#23427;&#25552;&#20379;&#20102;&#32454;&#32990;&#29366;&#24577;&#30340;&#39640;&#32500;&#24230;&#27979;&#37327;&#65292;&#20294;&#19981;&#33021;&#36319;&#36394;&#32454;&#32990;&#30340;&#26102;&#38388;&#36712;&#36857;&#12290;&#25105;&#20204;&#35777;&#26126;&#65292;&#23545;&#20110;&#19968;&#31867;&#38543;&#26426;&#36807;&#31243;&#65292;&#21487;&#20197;&#20174;&#27599;&#20010;&#26102;&#38388;&#28857;&#30340;&#26102;&#38388;&#36793;&#32536;&#30340;&#26377;&#38480;&#26679;&#26412;&#20013;&#24674;&#22797;&#20986;&#30495;&#23454;&#36712;&#36857;&#65292;&#24182;&#25552;&#20379;&#19968;&#20010;&#22312;&#23454;&#36341;&#20013;&#39640;&#25928;&#22320;&#25191;&#34892;&#27492;&#25805;&#20316;&#30340;&#31639;&#27861;&#12290;&#25105;&#20204;&#24320;&#21457;&#30340;&#26041;&#27861;&#65292;&#20840;&#23616;Waddington-OT(gWOT)&#65292;&#21487;&#20197;&#36890;&#36807;&#28041;&#21450;&#29109;&#27491;&#21017;&#21270;&#26368;&#20248;&#20256;&#36755;&#30340;&#25152;&#26377;&#26102;&#38388;&#28857;&#30340;&#20840;&#23616;&#24179;&#28369;&#20984;&#20248;&#21270;&#38382;&#39064;&#26469;&#35299;&#20915;&#12290;&#25105;&#20204;&#23637;&#31034;&#20102;&#35813;&#38382;&#39064;&#21487;&#20197;&#22312;&#23454;&#36341;&#20013;&#39640;&#25928;&#22320;&#35299;&#20915;&#65292;&#24182;&#23637;&#31034;&#20102;&#22312;&#20960;&#20010;&#21512;&#25104;&#21644;&#23454;&#38469;&#25968;&#25454;&#38598;&#19978;&#30340;&#33391;&#22909;&#37325;&#24314;&#32467;&#26524;&#12290;
&lt;/p&gt;
&lt;p&gt;
We devise a theoretical framework and a numerical method to infer trajectories of a stochastic process from samples of its temporal marginals. This problem arises in the analysis of single cell RNA-sequencing data, which provide high dimensional measurements of cell states but cannot track the trajectories of the cells over time. We prove that for a class of stochastic processes it is possible to recover the ground truth trajectories from limited samples of the temporal marginals at each time-point, and provide an efficient algorithm to do so in practice. The method we develop, Global Waddington-OT (gWOT), boils down to a smooth convex optimization problem posed globally over all time-points involving entropy-regularized optimal transport. We demonstrate that this problem can be solved efficiently in practice and yields good reconstructions, as we show on several synthetic and real datasets.
&lt;/p&gt;</description></item></channel></rss>